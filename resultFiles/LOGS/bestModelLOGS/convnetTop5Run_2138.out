CNNModel CHEMBL3983 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	389
Number of inactive compounds :	389
---------------------------------
Run id: CNNModel_CHEMBL3983_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3983_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 476
Validation samples: 149
--
Training Step: 1  | time: 23.771s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/476
[A[ATraining Step: 2  | total loss: [1m[32m0.62384[0m[0m | time: 47.629s
[2K
| Adam | epoch: 001 | loss: 0.62384 - acc: 0.4781 -- iter: 064/476
[A[ATraining Step: 3  | total loss: [1m[32m0.68326[0m[0m | time: 54.899s
[2K
| Adam | epoch: 001 | loss: 0.68326 - acc: 0.4193 -- iter: 096/476
[A[ATraining Step: 4  | total loss: [1m[32m0.68966[0m[0m | time: 59.978s
[2K
| Adam | epoch: 001 | loss: 0.68966 - acc: 0.5267 -- iter: 128/476
[A[ATraining Step: 5  | total loss: [1m[32m0.69225[0m[0m | time: 61.106s
[2K
| Adam | epoch: 001 | loss: 0.69225 - acc: 0.5082 -- iter: 160/476
[A[ATraining Step: 6  | total loss: [1m[32m0.69300[0m[0m | time: 62.386s
[2K
| Adam | epoch: 001 | loss: 0.69300 - acc: 0.5029 -- iter: 192/476
[A[ATraining Step: 7  | total loss: [1m[32m0.68920[0m[0m | time: 63.467s
[2K
| Adam | epoch: 001 | loss: 0.68920 - acc: 0.6137 -- iter: 224/476
[A[ATraining Step: 8  | total loss: [1m[32m0.69652[0m[0m | time: 64.631s
[2K
| Adam | epoch: 001 | loss: 0.69652 - acc: 0.4618 -- iter: 256/476
[A[ATraining Step: 9  | total loss: [1m[32m0.69600[0m[0m | time: 65.844s
[2K
| Adam | epoch: 001 | loss: 0.69600 - acc: 0.4490 -- iter: 288/476
[A[ATraining Step: 10  | total loss: [1m[32m0.69400[0m[0m | time: 67.201s
[2K
| Adam | epoch: 001 | loss: 0.69400 - acc: 0.4901 -- iter: 320/476
[A[ATraining Step: 11  | total loss: [1m[32m0.69552[0m[0m | time: 68.444s
[2K
| Adam | epoch: 001 | loss: 0.69552 - acc: 0.4356 -- iter: 352/476
[A[ATraining Step: 12  | total loss: [1m[32m0.69358[0m[0m | time: 69.385s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.5068 -- iter: 384/476
[A[ATraining Step: 13  | total loss: [1m[32m0.69311[0m[0m | time: 70.817s
[2K
| Adam | epoch: 001 | loss: 0.69311 - acc: 0.5306 -- iter: 416/476
[A[ATraining Step: 14  | total loss: [1m[32m0.69244[0m[0m | time: 72.062s
[2K
| Adam | epoch: 001 | loss: 0.69244 - acc: 0.5565 -- iter: 448/476
[A[ATraining Step: 15  | total loss: [1m[32m0.69208[0m[0m | time: 112.912s
[2K
| Adam | epoch: 001 | loss: 0.69208 - acc: 0.5588 | val_loss: 0.69464 - val_acc: 0.4497 -- iter: 476/476
--
Training Step: 16  | total loss: [1m[32m0.69131[0m[0m | time: 19.550s
[2K
| Adam | epoch: 002 | loss: 0.69131 - acc: 0.5903 -- iter: 032/476
[A[ATraining Step: 17  | total loss: [1m[32m0.69076[0m[0m | time: 42.850s
[2K
| Adam | epoch: 002 | loss: 0.69076 - acc: 0.6092 -- iter: 064/476
[A[ATraining Step: 18  | total loss: [1m[32m0.69234[0m[0m | time: 70.588s
[2K
| Adam | epoch: 002 | loss: 0.69234 - acc: 0.5498 -- iter: 096/476
[A[ATraining Step: 19  | total loss: [1m[32m0.69321[0m[0m | time: 83.224s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5228 -- iter: 128/476
[A[ATraining Step: 20  | total loss: [1m[32m0.69522[0m[0m | time: 96.538s
[2K
| Adam | epoch: 002 | loss: 0.69522 - acc: 0.4753 -- iter: 160/476
[A[ATraining Step: 21  | total loss: [1m[32m0.69414[0m[0m | time: 99.503s
[2K
| Adam | epoch: 002 | loss: 0.69414 - acc: 0.4926 -- iter: 192/476
[A[ATraining Step: 22  | total loss: [1m[32m0.69468[0m[0m | time: 100.699s
[2K
| Adam | epoch: 002 | loss: 0.69468 - acc: 0.4761 -- iter: 224/476
[A[ATraining Step: 23  | total loss: [1m[32m0.69377[0m[0m | time: 101.936s
[2K
| Adam | epoch: 002 | loss: 0.69377 - acc: 0.5012 -- iter: 256/476
[A[ATraining Step: 24  | total loss: [1m[32m0.69414[0m[0m | time: 103.059s
[2K
| Adam | epoch: 002 | loss: 0.69414 - acc: 0.4833 -- iter: 288/476
[A[ATraining Step: 25  | total loss: [1m[32m0.69414[0m[0m | time: 104.001s
[2K
| Adam | epoch: 002 | loss: 0.69414 - acc: 0.4793 -- iter: 320/476
[A[ATraining Step: 26  | total loss: [1m[32m0.69297[0m[0m | time: 104.937s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5179 -- iter: 352/476
[A[ATraining Step: 27  | total loss: [1m[32m0.69196[0m[0m | time: 106.195s
[2K
| Adam | epoch: 002 | loss: 0.69196 - acc: 0.5535 -- iter: 384/476
[A[ATraining Step: 28  | total loss: [1m[32m0.69204[0m[0m | time: 107.288s
[2K
| Adam | epoch: 002 | loss: 0.69204 - acc: 0.5479 -- iter: 416/476
[A[ATraining Step: 29  | total loss: [1m[32m0.69189[0m[0m | time: 108.371s
[2K
| Adam | epoch: 002 | loss: 0.69189 - acc: 0.5515 -- iter: 448/476
[A[ATraining Step: 30  | total loss: [1m[32m0.69349[0m[0m | time: 110.781s
[2K
| Adam | epoch: 002 | loss: 0.69349 - acc: 0.5023 | val_loss: 0.69510 - val_acc: 0.4497 -- iter: 476/476
--
Training Step: 31  | total loss: [1m[32m0.69241[0m[0m | time: 13.304s
[2K
| Adam | epoch: 003 | loss: 0.69241 - acc: 0.5306 -- iter: 032/476
[A[ATraining Step: 32  | total loss: [1m[32m0.69146[0m[0m | time: 15.448s
[2K
| Adam | epoch: 003 | loss: 0.69146 - acc: 0.5558 -- iter: 064/476
[A[ATraining Step: 33  | total loss: [1m[32m0.69064[0m[0m | time: 18.874s
[2K
| Adam | epoch: 003 | loss: 0.69064 - acc: 0.5749 -- iter: 096/476
[A[ATraining Step: 34  | total loss: [1m[32m0.69077[0m[0m | time: 27.596s
[2K
| Adam | epoch: 003 | loss: 0.69077 - acc: 0.5656 -- iter: 128/476
[A[ATraining Step: 35  | total loss: [1m[32m0.68998[0m[0m | time: 33.187s
[2K
| Adam | epoch: 003 | loss: 0.68998 - acc: 0.5780 -- iter: 160/476
[A[ATraining Step: 36  | total loss: [1m[32m0.69235[0m[0m | time: 49.334s
[2K
| Adam | epoch: 003 | loss: 0.69235 - acc: 0.5365 -- iter: 192/476
[A[ATraining Step: 37  | total loss: [1m[32m0.69439[0m[0m | time: 50.417s
[2K
| Adam | epoch: 003 | loss: 0.69439 - acc: 0.5042 -- iter: 224/476
[A[ATraining Step: 38  | total loss: [1m[32m0.69298[0m[0m | time: 51.421s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5217 -- iter: 256/476
[A[ATraining Step: 39  | total loss: [1m[32m0.69216[0m[0m | time: 52.701s
[2K
| Adam | epoch: 003 | loss: 0.69216 - acc: 0.5295 -- iter: 288/476
[A[ATraining Step: 40  | total loss: [1m[32m0.69501[0m[0m | time: 53.824s
[2K
| Adam | epoch: 003 | loss: 0.69501 - acc: 0.4888 -- iter: 320/476
[A[ATraining Step: 41  | total loss: [1m[32m0.69406[0m[0m | time: 55.163s
[2K
| Adam | epoch: 003 | loss: 0.69406 - acc: 0.5024 -- iter: 352/476
[A[ATraining Step: 42  | total loss: [1m[32m0.69391[0m[0m | time: 56.435s
[2K
| Adam | epoch: 003 | loss: 0.69391 - acc: 0.5019 -- iter: 384/476
[A[ATraining Step: 43  | total loss: [1m[32m0.69317[0m[0m | time: 57.550s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.5126 -- iter: 416/476
[A[ATraining Step: 44  | total loss: [1m[32m0.69349[0m[0m | time: 58.815s
[2K
| Adam | epoch: 003 | loss: 0.69349 - acc: 0.5050 -- iter: 448/476
[A[ATraining Step: 45  | total loss: [1m[32m0.69354[0m[0m | time: 61.387s
[2K
| Adam | epoch: 003 | loss: 0.69354 - acc: 0.5042 | val_loss: 0.69566 - val_acc: 0.4497 -- iter: 476/476
--
Training Step: 46  | total loss: [1m[32m0.69354[0m[0m | time: 1.790s
[2K
| Adam | epoch: 004 | loss: 0.69354 - acc: 0.5035 -- iter: 032/476
[A[ATraining Step: 47  | total loss: [1m[32m0.69276[0m[0m | time: 2.700s
[2K
| Adam | epoch: 004 | loss: 0.69276 - acc: 0.5183 -- iter: 064/476
[A[ATraining Step: 48  | total loss: [1m[32m0.69238[0m[0m | time: 3.664s
[2K
| Adam | epoch: 004 | loss: 0.69238 - acc: 0.5268 -- iter: 096/476
[A[ATraining Step: 49  | total loss: [1m[32m0.69189[0m[0m | time: 4.871s
[2K
| Adam | epoch: 004 | loss: 0.69189 - acc: 0.5338 -- iter: 128/476
[A[ATraining Step: 50  | total loss: [1m[32m0.69308[0m[0m | time: 6.059s
[2K
| Adam | epoch: 004 | loss: 0.69308 - acc: 0.5092 -- iter: 160/476
[A[ATraining Step: 51  | total loss: [1m[32m0.69360[0m[0m | time: 7.301s
[2K
| Adam | epoch: 004 | loss: 0.69360 - acc: 0.4983 -- iter: 192/476
[A[ATraining Step: 52  | total loss: [1m[32m0.69289[0m[0m | time: 8.598s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5126 -- iter: 224/476
[A[ATraining Step: 53  | total loss: [1m[32m0.69274[0m[0m | time: 9.788s
[2K
| Adam | epoch: 004 | loss: 0.69274 - acc: 0.5153 -- iter: 256/476
[A[ATraining Step: 54  | total loss: [1m[32m0.69311[0m[0m | time: 10.760s
[2K
| Adam | epoch: 004 | loss: 0.69311 - acc: 0.5040 -- iter: 288/476
[A[ATraining Step: 55  | total loss: [1m[32m0.69344[0m[0m | time: 12.348s
[2K
| Adam | epoch: 004 | loss: 0.69344 - acc: 0.4945 -- iter: 320/476
[A[ATraining Step: 56  | total loss: [1m[32m0.69303[0m[0m | time: 13.806s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5041 -- iter: 352/476
[A[ATraining Step: 57  | total loss: [1m[32m0.69268[0m[0m | time: 16.977s
[2K
| Adam | epoch: 004 | loss: 0.69268 - acc: 0.5122 -- iter: 384/476
[A[ATraining Step: 58  | total loss: [1m[32m0.69273[0m[0m | time: 18.512s
[2K
| Adam | epoch: 004 | loss: 0.69273 - acc: 0.5105 -- iter: 416/476
[A[ATraining Step: 59  | total loss: [1m[32m0.69224[0m[0m | time: 33.554s
[2K
| Adam | epoch: 004 | loss: 0.69224 - acc: 0.5217 -- iter: 448/476
[A[ATraining Step: 60  | total loss: [1m[32m0.69252[0m[0m | time: 116.388s
[2K
| Adam | epoch: 004 | loss: 0.69252 - acc: 0.5147 | val_loss: 0.69481 - val_acc: 0.4497 -- iter: 476/476
--
Training Step: 61  | total loss: [1m[32m0.69265[0m[0m | time: 10.587s
[2K
| Adam | epoch: 005 | loss: 0.69265 - acc: 0.5087 -- iter: 032/476
[A[ATraining Step: 62  | total loss: [1m[32m0.69205[0m[0m | time: 33.139s
[2K
| Adam | epoch: 005 | loss: 0.69205 - acc: 0.5196 -- iter: 064/476
[A[ATraining Step: 63  | total loss: [1m[32m0.69171[0m[0m | time: 41.738s
[2K
| Adam | epoch: 005 | loss: 0.69171 - acc: 0.5251 -- iter: 096/476
[A[ATraining Step: 64  | total loss: [1m[32m0.69145[0m[0m | time: 53.182s
[2K
| Adam | epoch: 005 | loss: 0.69145 - acc: 0.5264 -- iter: 128/476
[A[ATraining Step: 65  | total loss: [1m[32m0.69128[0m[0m | time: 60.936s
[2K
| Adam | epoch: 005 | loss: 0.69128 - acc: 0.5275 -- iter: 160/476
[A[ATraining Step: 66  | total loss: [1m[32m0.69153[0m[0m | time: 75.855s
[2K
| Adam | epoch: 005 | loss: 0.69153 - acc: 0.5204 -- iter: 192/476
[A[ATraining Step: 67  | total loss: [1m[32m0.69151[0m[0m | time: 90.349s
[2K
| Adam | epoch: 005 | loss: 0.69151 - acc: 0.5179 -- iter: 224/476
[A[ATraining Step: 68  | total loss: [1m[32m0.69112[0m[0m | time: 97.833s
[2K
| Adam | epoch: 005 | loss: 0.69112 - acc: 0.5232 -- iter: 256/476
[A[ATraining Step: 69  | total loss: [1m[32m0.69098[0m[0m | time: 99.004s
[2K
| Adam | epoch: 005 | loss: 0.69098 - acc: 0.5242 -- iter: 288/476
[A[ATraining Step: 70  | total loss: [1m[32m0.69123[0m[0m | time: 100.182s
[2K
| Adam | epoch: 005 | loss: 0.69123 - acc: 0.5178 -- iter: 320/476
[A[ATraining Step: 71  | total loss: [1m[32m0.69134[0m[0m | time: 101.362s
[2K
| Adam | epoch: 005 | loss: 0.69134 - acc: 0.5122 -- iter: 352/476
[A[ATraining Step: 72  | total loss: [1m[32m0.69174[0m[0m | time: 102.549s
[2K
| Adam | epoch: 005 | loss: 0.69174 - acc: 0.4968 -- iter: 384/476
[A[ATraining Step: 73  | total loss: [1m[32m0.69159[0m[0m | time: 103.910s
[2K
| Adam | epoch: 005 | loss: 0.69159 - acc: 0.5041 -- iter: 416/476
[A[ATraining Step: 74  | total loss: [1m[32m0.69152[0m[0m | time: 105.226s
[2K
| Adam | epoch: 005 | loss: 0.69152 - acc: 0.5276 -- iter: 448/476
[A[ATraining Step: 75  | total loss: [1m[32m0.69128[0m[0m | time: 107.936s
[2K
| Adam | epoch: 005 | loss: 0.69128 - acc: 0.5450 | val_loss: 0.69137 - val_acc: 0.4497 -- iter: 476/476
--
Training Step: 76  | total loss: [1m[32m0.69119[0m[0m | time: 4.849s
[2K
| Adam | epoch: 006 | loss: 0.69119 - acc: 0.5368 -- iter: 032/476
[A[ATraining Step: 77  | total loss: [1m[32m0.69138[0m[0m | time: 28.871s
[2K
| Adam | epoch: 006 | loss: 0.69138 - acc: 0.5230 -- iter: 064/476
[A[ATraining Step: 78  | total loss: [1m[32m0.69029[0m[0m | time: 46.035s
[2K
| Adam | epoch: 006 | loss: 0.69029 - acc: 0.5369 -- iter: 096/476
[A[ATraining Step: 79  | total loss: [1m[32m0.68986[0m[0m | time: 60.451s
[2K
| Adam | epoch: 006 | loss: 0.68986 - acc: 0.5363 -- iter: 128/476
[A[ATraining Step: 80  | total loss: [1m[32m0.68735[0m[0m | time: 72.391s
[2K
| Adam | epoch: 006 | loss: 0.68735 - acc: 0.5509 -- iter: 160/476
[A[ATraining Step: 81  | total loss: [1m[32m0.68365[0m[0m | time: 80.713s
[2K
| Adam | epoch: 006 | loss: 0.68365 - acc: 0.5638 -- iter: 192/476
[A[ATraining Step: 82  | total loss: [1m[32m0.68640[0m[0m | time: 87.031s
[2K
| Adam | epoch: 006 | loss: 0.68640 - acc: 0.5543 -- iter: 224/476
[A[ATraining Step: 83  | total loss: [1m[32m0.68445[0m[0m | time: 89.389s
[2K
| Adam | epoch: 006 | loss: 0.68445 - acc: 0.5582 -- iter: 256/476
[A[ATraining Step: 84  | total loss: [1m[32m0.68691[0m[0m | time: 97.788s
[2K
| Adam | epoch: 006 | loss: 0.68691 - acc: 0.5524 -- iter: 288/476
[A[ATraining Step: 85  | total loss: [1m[32m0.68903[0m[0m | time: 98.837s
[2K
| Adam | epoch: 006 | loss: 0.68903 - acc: 0.5409 -- iter: 320/476
[A[ATraining Step: 86  | total loss: [1m[32m0.68663[0m[0m | time: 99.904s
[2K
| Adam | epoch: 006 | loss: 0.68663 - acc: 0.5462 -- iter: 352/476
[A[ATraining Step: 87  | total loss: [1m[32m0.68538[0m[0m | time: 101.119s
[2K
| Adam | epoch: 006 | loss: 0.68538 - acc: 0.5603 -- iter: 384/476
[A[ATraining Step: 88  | total loss: [1m[32m0.68466[0m[0m | time: 102.318s
[2K
| Adam | epoch: 006 | loss: 0.68466 - acc: 0.5762 -- iter: 416/476
[A[ATraining Step: 89  | total loss: [1m[32m0.68358[0m[0m | time: 103.714s
[2K
| Adam | epoch: 006 | loss: 0.68358 - acc: 0.5904 -- iter: 448/476
[A[ATraining Step: 90  | total loss: [1m[32m0.68037[0m[0m | time: 106.701s
[2K
| Adam | epoch: 006 | loss: 0.68037 - acc: 0.6095 | val_loss: 0.65307 - val_acc: 0.7383 -- iter: 476/476
--
Training Step: 91  | total loss: [1m[32m0.67867[0m[0m | time: 14.848s
[2K
| Adam | epoch: 007 | loss: 0.67867 - acc: 0.6204 -- iter: 032/476
[A[ATraining Step: 92  | total loss: [1m[32m0.67603[0m[0m | time: 21.946s
[2K
| Adam | epoch: 007 | loss: 0.67603 - acc: 0.6303 -- iter: 064/476
[A[ATraining Step: 93  | total loss: [1m[32m0.67409[0m[0m | time: 33.431s
[2K
| Adam | epoch: 007 | loss: 0.67409 - acc: 0.6235 -- iter: 096/476
[A[ATraining Step: 94  | total loss: [1m[32m0.67139[0m[0m | time: 43.023s
[2K
| Adam | epoch: 007 | loss: 0.67139 - acc: 0.6299 -- iter: 128/476
[A[ATraining Step: 95  | total loss: [1m[32m0.66670[0m[0m | time: 49.921s
[2K
| Adam | epoch: 007 | loss: 0.66670 - acc: 0.6325 -- iter: 160/476
[A[ATraining Step: 96  | total loss: [1m[32m0.66489[0m[0m | time: 57.710s
[2K
| Adam | epoch: 007 | loss: 0.66489 - acc: 0.6228 -- iter: 192/476
[A[ATraining Step: 97  | total loss: [1m[32m0.65942[0m[0m | time: 65.259s
[2K
| Adam | epoch: 007 | loss: 0.65942 - acc: 0.6284 -- iter: 224/476
[A[ATraining Step: 98  | total loss: [1m[32m0.65492[0m[0m | time: 75.043s
[2K
| Adam | epoch: 007 | loss: 0.65492 - acc: 0.6312 -- iter: 256/476
[A[ATraining Step: 99  | total loss: [1m[32m0.64685[0m[0m | time: 81.209s
[2K
| Adam | epoch: 007 | loss: 0.64685 - acc: 0.6493 -- iter: 288/476
[A[ATraining Step: 100  | total loss: [1m[32m0.63711[0m[0m | time: 82.281s
[2K
| Adam | epoch: 007 | loss: 0.63711 - acc: 0.6656 -- iter: 320/476
[A[ATraining Step: 101  | total loss: [1m[32m0.62521[0m[0m | time: 83.431s
[2K
| Adam | epoch: 007 | loss: 0.62521 - acc: 0.6835 -- iter: 352/476
[A[ATraining Step: 102  | total loss: [1m[32m0.61638[0m[0m | time: 84.433s
[2K
| Adam | epoch: 007 | loss: 0.61638 - acc: 0.6932 -- iter: 384/476
[A[ATraining Step: 103  | total loss: [1m[32m0.62293[0m[0m | time: 85.591s
[2K
| Adam | epoch: 007 | loss: 0.62293 - acc: 0.6864 -- iter: 416/476
[A[ATraining Step: 104  | total loss: [1m[32m0.63804[0m[0m | time: 86.772s
[2K
| Adam | epoch: 007 | loss: 0.63804 - acc: 0.6678 -- iter: 448/476
[A[ATraining Step: 105  | total loss: [1m[32m0.61368[0m[0m | time: 88.992s
[2K
| Adam | epoch: 007 | loss: 0.61368 - acc: 0.6885 | val_loss: 0.60955 - val_acc: 0.6577 -- iter: 476/476
--
Training Step: 106  | total loss: [1m[32m0.60483[0m[0m | time: 1.407s
[2K
| Adam | epoch: 008 | loss: 0.60483 - acc: 0.6978 -- iter: 032/476
[A[ATraining Step: 107  | total loss: [1m[32m0.61854[0m[0m | time: 5.985s
[2K
| Adam | epoch: 008 | loss: 0.61854 - acc: 0.6967 -- iter: 064/476
[A[ATraining Step: 108  | total loss: [1m[32m0.61919[0m[0m | time: 20.605s
[2K
| Adam | epoch: 008 | loss: 0.61919 - acc: 0.6896 -- iter: 096/476
[A[ATraining Step: 109  | total loss: [1m[32m0.60189[0m[0m | time: 30.672s
[2K
| Adam | epoch: 008 | loss: 0.60189 - acc: 0.6956 -- iter: 128/476
[A[ATraining Step: 110  | total loss: [1m[32m0.58217[0m[0m | time: 45.374s
[2K
| Adam | epoch: 008 | loss: 0.58217 - acc: 0.7136 -- iter: 160/476
[A[ATraining Step: 111  | total loss: [1m[32m0.56312[0m[0m | time: 52.801s
[2K
| Adam | epoch: 008 | loss: 0.56312 - acc: 0.7266 -- iter: 192/476
[A[ATraining Step: 112  | total loss: [1m[32m0.55555[0m[0m | time: 69.173s
[2K
| Adam | epoch: 008 | loss: 0.55555 - acc: 0.7325 -- iter: 224/476
[A[ATraining Step: 113  | total loss: [1m[32m0.54235[0m[0m | time: 73.534s
[2K
| Adam | epoch: 008 | loss: 0.54235 - acc: 0.7414 -- iter: 256/476
[A[ATraining Step: 114  | total loss: [1m[32m0.54308[0m[0m | time: 82.950s
[2K
| Adam | epoch: 008 | loss: 0.54308 - acc: 0.7454 -- iter: 288/476
[A[ATraining Step: 115  | total loss: [1m[32m0.53349[0m[0m | time: 96.411s
[2K
| Adam | epoch: 008 | loss: 0.53349 - acc: 0.7490 -- iter: 320/476
[A[ATraining Step: 116  | total loss: [1m[32m0.53144[0m[0m | time: 111.827s
[2K
| Adam | epoch: 008 | loss: 0.53144 - acc: 0.7491 -- iter: 352/476
[A[ATraining Step: 117  | total loss: [1m[32m0.53349[0m[0m | time: 121.811s
[2K
| Adam | epoch: 008 | loss: 0.53349 - acc: 0.7492 -- iter: 384/476
[A[ATraining Step: 118  | total loss: [1m[32m0.53496[0m[0m | time: 126.299s
[2K
| Adam | epoch: 008 | loss: 0.53496 - acc: 0.7461 -- iter: 416/476
[A[ATraining Step: 119  | total loss: [1m[32m0.53265[0m[0m | time: 129.283s
[2K
| Adam | epoch: 008 | loss: 0.53265 - acc: 0.7465 -- iter: 448/476
[A[ATraining Step: 120  | total loss: [1m[32m0.53189[0m[0m | time: 132.296s
[2K
| Adam | epoch: 008 | loss: 0.53189 - acc: 0.7469 | val_loss: 0.66471 - val_acc: 0.6711 -- iter: 476/476
--
Training Step: 121  | total loss: [1m[32m0.54258[0m[0m | time: 1.213s
[2K
| Adam | epoch: 009 | loss: 0.54258 - acc: 0.7347 -- iter: 032/476
[A[ATraining Step: 122  | total loss: [1m[32m0.55267[0m[0m | time: 2.558s
[2K
| Adam | epoch: 009 | loss: 0.55267 - acc: 0.7299 -- iter: 064/476
[A[ATraining Step: 123  | total loss: [1m[32m0.54546[0m[0m | time: 3.879s
[2K
| Adam | epoch: 009 | loss: 0.54546 - acc: 0.7320 -- iter: 096/476
[A[ATraining Step: 124  | total loss: [1m[32m0.53748[0m[0m | time: 5.085s
[2K
| Adam | epoch: 009 | loss: 0.53748 - acc: 0.7338 -- iter: 128/476
[A[ATraining Step: 125  | total loss: [1m[32m0.52940[0m[0m | time: 6.536s
[2K
| Adam | epoch: 009 | loss: 0.52940 - acc: 0.7448 -- iter: 160/476
[A[ATraining Step: 126  | total loss: [1m[32m0.52364[0m[0m | time: 7.662s
[2K
| Adam | epoch: 009 | loss: 0.52364 - acc: 0.7484 -- iter: 192/476
[A[ATraining Step: 127  | total loss: [1m[32m0.51211[0m[0m | time: 9.478s
[2K
| Adam | epoch: 009 | loss: 0.51211 - acc: 0.7579 -- iter: 224/476
[A[ATraining Step: 128  | total loss: [1m[32m0.50823[0m[0m | time: 12.556s
[2K
| Adam | epoch: 009 | loss: 0.50823 - acc: 0.7607 -- iter: 256/476
[A[ATraining Step: 129  | total loss: [1m[32m0.50150[0m[0m | time: 15.982s
[2K
| Adam | epoch: 009 | loss: 0.50150 - acc: 0.7739 -- iter: 288/476
[A[ATraining Step: 130  | total loss: [1m[32m0.48497[0m[0m | time: 27.358s
[2K
| Adam | epoch: 009 | loss: 0.48497 - acc: 0.7872 -- iter: 320/476
[A[ATraining Step: 131  | total loss: [1m[32m0.46604[0m[0m | time: 40.547s
[2K
| Adam | epoch: 009 | loss: 0.46604 - acc: 0.7959 -- iter: 352/476
[A[ATraining Step: 132  | total loss: [1m[32m0.49732[0m[0m | time: 43.409s
[2K
| Adam | epoch: 009 | loss: 0.49732 - acc: 0.7757 -- iter: 384/476
[A[ATraining Step: 133  | total loss: [1m[32m0.49565[0m[0m | time: 62.949s
[2K
| Adam | epoch: 009 | loss: 0.49565 - acc: 0.7732 -- iter: 416/476
[A[ATraining Step: 134  | total loss: [1m[32m0.47436[0m[0m | time: 72.402s
[2K
| Adam | epoch: 009 | loss: 0.47436 - acc: 0.7802 -- iter: 448/476
[A[ATraining Step: 135  | total loss: [1m[32m0.46661[0m[0m | time: 88.945s
[2K
| Adam | epoch: 009 | loss: 0.46661 - acc: 0.7866 | val_loss: 0.53017 - val_acc: 0.7919 -- iter: 476/476
--
Training Step: 136  | total loss: [1m[32m0.46815[0m[0m | time: 1.160s
[2K
| Adam | epoch: 010 | loss: 0.46815 - acc: 0.7860 -- iter: 032/476
[A[ATraining Step: 137  | total loss: [1m[32m0.45394[0m[0m | time: 2.340s
[2K
| Adam | epoch: 010 | loss: 0.45394 - acc: 0.7918 -- iter: 064/476
[A[ATraining Step: 138  | total loss: [1m[32m0.44974[0m[0m | time: 3.574s
[2K
| Adam | epoch: 010 | loss: 0.44974 - acc: 0.7970 -- iter: 096/476
[A[ATraining Step: 139  | total loss: [1m[32m0.43966[0m[0m | time: 4.771s
[2K
| Adam | epoch: 010 | loss: 0.43966 - acc: 0.8017 -- iter: 128/476
[A[ATraining Step: 140  | total loss: [1m[32m0.43193[0m[0m | time: 5.866s
[2K
| Adam | epoch: 010 | loss: 0.43193 - acc: 0.8059 -- iter: 160/476
[A[ATraining Step: 141  | total loss: [1m[32m0.43702[0m[0m | time: 7.122s
[2K
| Adam | epoch: 010 | loss: 0.43702 - acc: 0.8097 -- iter: 192/476
[A[ATraining Step: 142  | total loss: [1m[32m0.44547[0m[0m | time: 8.129s
[2K
| Adam | epoch: 010 | loss: 0.44547 - acc: 0.8006 -- iter: 224/476
[A[ATraining Step: 143  | total loss: [1m[32m0.43225[0m[0m | time: 9.029s
[2K
| Adam | epoch: 010 | loss: 0.43225 - acc: 0.8080 -- iter: 256/476
[A[ATraining Step: 144  | total loss: [1m[32m0.42670[0m[0m | time: 10.003s
[2K
| Adam | epoch: 010 | loss: 0.42670 - acc: 0.8165 -- iter: 288/476
[A[ATraining Step: 145  | total loss: [1m[32m0.41442[0m[0m | time: 11.109s
[2K
| Adam | epoch: 010 | loss: 0.41442 - acc: 0.8277 -- iter: 320/476
[A[ATraining Step: 146  | total loss: [1m[32m0.41124[0m[0m | time: 11.983s
[2K
| Adam | epoch: 010 | loss: 0.41124 - acc: 0.8324 -- iter: 352/476
[A[ATraining Step: 147  | total loss: [1m[32m0.40921[0m[0m | time: 12.763s
[2K
| Adam | epoch: 010 | loss: 0.40921 - acc: 0.8273 -- iter: 384/476
[A[ATraining Step: 148  | total loss: [1m[32m0.39589[0m[0m | time: 13.853s
[2K
| Adam | epoch: 010 | loss: 0.39589 - acc: 0.8352 -- iter: 416/476
[A[ATraining Step: 149  | total loss: [1m[32m0.39331[0m[0m | time: 14.863s
[2K
| Adam | epoch: 010 | loss: 0.39331 - acc: 0.8392 -- iter: 448/476
[A[ATraining Step: 150  | total loss: [1m[32m0.38764[0m[0m | time: 16.900s
[2K
| Adam | epoch: 010 | loss: 0.38764 - acc: 0.8396 | val_loss: 0.47861 - val_acc: 0.7987 -- iter: 476/476
--
Training Step: 151  | total loss: [1m[32m0.38524[0m[0m | time: 1.347s
[2K
| Adam | epoch: 011 | loss: 0.38524 - acc: 0.8432 -- iter: 032/476
[A[ATraining Step: 152  | total loss: [1m[32m0.37129[0m[0m | time: 2.566s
[2K
| Adam | epoch: 011 | loss: 0.37129 - acc: 0.8526 -- iter: 064/476
[A[ATraining Step: 153  | total loss: [1m[32m0.36070[0m[0m | time: 3.765s
[2K
| Adam | epoch: 011 | loss: 0.36070 - acc: 0.8549 -- iter: 096/476
[A[ATraining Step: 154  | total loss: [1m[32m0.35289[0m[0m | time: 4.935s
[2K
| Adam | epoch: 011 | loss: 0.35289 - acc: 0.8631 -- iter: 128/476
[A[ATraining Step: 155  | total loss: [1m[32m0.34075[0m[0m | time: 6.222s
[2K
| Adam | epoch: 011 | loss: 0.34075 - acc: 0.8706 -- iter: 160/476
[A[ATraining Step: 156  | total loss: [1m[32m0.34768[0m[0m | time: 7.386s
[2K
| Adam | epoch: 011 | loss: 0.34768 - acc: 0.8741 -- iter: 192/476
[A[ATraining Step: 157  | total loss: [1m[32m0.34041[0m[0m | time: 8.264s
[2K
| Adam | epoch: 011 | loss: 0.34041 - acc: 0.8773 -- iter: 224/476
[A[ATraining Step: 158  | total loss: [1m[32m0.36227[0m[0m | time: 9.143s
[2K
| Adam | epoch: 011 | loss: 0.36227 - acc: 0.8646 -- iter: 256/476
[A[ATraining Step: 159  | total loss: [1m[32m0.36269[0m[0m | time: 9.874s
[2K
| Adam | epoch: 011 | loss: 0.36269 - acc: 0.8563 -- iter: 288/476
[A[ATraining Step: 160  | total loss: [1m[32m0.36099[0m[0m | time: 10.555s
[2K
| Adam | epoch: 011 | loss: 0.36099 - acc: 0.8564 -- iter: 320/476
[A[ATraining Step: 161  | total loss: [1m[32m0.34711[0m[0m | time: 11.461s
[2K
| Adam | epoch: 011 | loss: 0.34711 - acc: 0.8636 -- iter: 352/476
[A[ATraining Step: 162  | total loss: [1m[32m0.35301[0m[0m | time: 12.298s
[2K
| Adam | epoch: 011 | loss: 0.35301 - acc: 0.8553 -- iter: 384/476
[A[ATraining Step: 163  | total loss: [1m[32m0.35796[0m[0m | time: 13.103s
[2K
| Adam | epoch: 011 | loss: 0.35796 - acc: 0.8511 -- iter: 416/476
[A[ATraining Step: 164  | total loss: [1m[32m0.34842[0m[0m | time: 13.939s
[2K
| Adam | epoch: 011 | loss: 0.34842 - acc: 0.8597 -- iter: 448/476
[A[ATraining Step: 165  | total loss: [1m[32m0.35014[0m[0m | time: 15.750s
[2K
| Adam | epoch: 011 | loss: 0.35014 - acc: 0.8644 | val_loss: 0.72218 - val_acc: 0.6980 -- iter: 476/476
--
Training Step: 166  | total loss: [1m[32m0.33962[0m[0m | time: 0.849s
[2K
| Adam | epoch: 012 | loss: 0.33962 - acc: 0.8654 -- iter: 032/476
[A[ATraining Step: 167  | total loss: [1m[32m0.35374[0m[0m | time: 1.674s
[2K
| Adam | epoch: 012 | loss: 0.35374 - acc: 0.8601 -- iter: 064/476
[A[ATraining Step: 168  | total loss: [1m[32m0.35034[0m[0m | time: 2.518s
[2K
| Adam | epoch: 012 | loss: 0.35034 - acc: 0.8585 -- iter: 096/476
[A[ATraining Step: 169  | total loss: [1m[32m0.34491[0m[0m | time: 3.394s
[2K
| Adam | epoch: 012 | loss: 0.34491 - acc: 0.8539 -- iter: 128/476
[A[ATraining Step: 170  | total loss: [1m[32m0.32595[0m[0m | time: 4.238s
[2K
| Adam | epoch: 012 | loss: 0.32595 - acc: 0.8685 -- iter: 160/476
[A[ATraining Step: 171  | total loss: [1m[32m0.31667[0m[0m | time: 5.080s
[2K
| Adam | epoch: 012 | loss: 0.31667 - acc: 0.8692 -- iter: 192/476
[A[ATraining Step: 172  | total loss: [1m[32m0.31468[0m[0m | time: 5.901s
[2K
| Adam | epoch: 012 | loss: 0.31468 - acc: 0.8697 -- iter: 224/476
[A[ATraining Step: 173  | total loss: [1m[32m0.31966[0m[0m | time: 6.717s
[2K
| Adam | epoch: 012 | loss: 0.31966 - acc: 0.8703 -- iter: 256/476
[A[ATraining Step: 174  | total loss: [1m[32m0.32067[0m[0m | time: 7.514s
[2K
| Adam | epoch: 012 | loss: 0.32067 - acc: 0.8739 -- iter: 288/476
[A[ATraining Step: 175  | total loss: [1m[32m0.30917[0m[0m | time: 8.350s
[2K
| Adam | epoch: 012 | loss: 0.30917 - acc: 0.8802 -- iter: 320/476
[A[ATraining Step: 176  | total loss: [1m[32m0.30107[0m[0m | time: 9.102s
[2K
| Adam | epoch: 012 | loss: 0.30107 - acc: 0.8886 -- iter: 352/476
[A[ATraining Step: 177  | total loss: [1m[32m0.29092[0m[0m | time: 9.941s
[2K
| Adam | epoch: 012 | loss: 0.29092 - acc: 0.8926 -- iter: 384/476
[A[ATraining Step: 178  | total loss: [1m[32m0.27975[0m[0m | time: 10.754s
[2K
| Adam | epoch: 012 | loss: 0.27975 - acc: 0.9002 -- iter: 416/476
[A[ATraining Step: 179  | total loss: [1m[32m0.27735[0m[0m | time: 11.530s
[2K
| Adam | epoch: 012 | loss: 0.27735 - acc: 0.9008 -- iter: 448/476
[A[ATraining Step: 180  | total loss: [1m[32m0.27495[0m[0m | time: 13.376s
[2K
| Adam | epoch: 012 | loss: 0.27495 - acc: 0.8983 | val_loss: 0.51439 - val_acc: 0.8054 -- iter: 476/476
--
Training Step: 181  | total loss: [1m[32m0.27137[0m[0m | time: 0.844s
[2K
| Adam | epoch: 013 | loss: 0.27137 - acc: 0.8991 -- iter: 032/476
[A[ATraining Step: 182  | total loss: [1m[32m0.27801[0m[0m | time: 1.654s
[2K
| Adam | epoch: 013 | loss: 0.27801 - acc: 0.8873 -- iter: 064/476
[A[ATraining Step: 183  | total loss: [1m[32m0.28692[0m[0m | time: 2.476s
[2K
| Adam | epoch: 013 | loss: 0.28692 - acc: 0.8860 -- iter: 096/476
[A[ATraining Step: 184  | total loss: [1m[32m0.26933[0m[0m | time: 3.271s
[2K
| Adam | epoch: 013 | loss: 0.26933 - acc: 0.8974 -- iter: 128/476
[A[ATraining Step: 185  | total loss: [1m[32m0.25500[0m[0m | time: 4.087s
[2K
| Adam | epoch: 013 | loss: 0.25500 - acc: 0.9077 -- iter: 160/476
[A[ATraining Step: 186  | total loss: [1m[32m0.24983[0m[0m | time: 4.951s
[2K
| Adam | epoch: 013 | loss: 0.24983 - acc: 0.9076 -- iter: 192/476
[A[ATraining Step: 187  | total loss: [1m[32m0.24494[0m[0m | time: 5.791s
[2K
| Adam | epoch: 013 | loss: 0.24494 - acc: 0.9137 -- iter: 224/476
[A[ATraining Step: 188  | total loss: [1m[32m0.23893[0m[0m | time: 6.603s
[2K
| Adam | epoch: 013 | loss: 0.23893 - acc: 0.9161 -- iter: 256/476
[A[ATraining Step: 189  | total loss: [1m[32m0.22241[0m[0m | time: 7.681s
[2K
| Adam | epoch: 013 | loss: 0.22241 - acc: 0.9245 -- iter: 288/476
[A[ATraining Step: 190  | total loss: [1m[32m0.20909[0m[0m | time: 8.700s
[2K
| Adam | epoch: 013 | loss: 0.20909 - acc: 0.9289 -- iter: 320/476
[A[ATraining Step: 191  | total loss: [1m[32m0.19827[0m[0m | time: 9.662s
[2K
| Adam | epoch: 013 | loss: 0.19827 - acc: 0.9329 -- iter: 352/476
[A[ATraining Step: 192  | total loss: [1m[32m0.19140[0m[0m | time: 10.587s
[2K
| Adam | epoch: 013 | loss: 0.19140 - acc: 0.9360 -- iter: 384/476
[A[ATraining Step: 193  | total loss: [1m[32m0.18338[0m[0m | time: 11.821s
[2K
| Adam | epoch: 013 | loss: 0.18338 - acc: 0.9388 -- iter: 416/476
[A[ATraining Step: 194  | total loss: [1m[32m0.17312[0m[0m | time: 12.939s
[2K
| Adam | epoch: 013 | loss: 0.17312 - acc: 0.9450 -- iter: 448/476
[A[ATraining Step: 195  | total loss: [1m[32m0.17462[0m[0m | time: 16.370s
[2K
| Adam | epoch: 013 | loss: 0.17462 - acc: 0.9411 | val_loss: 0.54052 - val_acc: 0.8322 -- iter: 476/476
--
Training Step: 196  | total loss: [1m[32m0.17614[0m[0m | time: 2.242s
[2K
| Adam | epoch: 014 | loss: 0.17614 - acc: 0.9376 -- iter: 032/476
[A[ATraining Step: 197  | total loss: [1m[32m0.17652[0m[0m | time: 15.477s
[2K
| Adam | epoch: 014 | loss: 0.17652 - acc: 0.9345 -- iter: 064/476
[A[ATraining Step: 198  | total loss: [1m[32m0.18106[0m[0m | time: 29.043s
[2K
| Adam | epoch: 014 | loss: 0.18106 - acc: 0.9254 -- iter: 096/476
[A[ATraining Step: 199  | total loss: [1m[32m0.17315[0m[0m | time: 36.081s
[2K
| Adam | epoch: 014 | loss: 0.17315 - acc: 0.9266 -- iter: 128/476
[A[ATraining Step: 200  | total loss: [1m[32m0.17394[0m[0m | time: 44.377s
[2K
| Adam | epoch: 014 | loss: 0.17394 - acc: 0.9246 | val_loss: 0.46897 - val_acc: 0.8591 -- iter: 160/476
--
Training Step: 201  | total loss: [1m[32m0.17542[0m[0m | time: 45.718s
[2K
| Adam | epoch: 014 | loss: 0.17542 - acc: 0.9259 -- iter: 192/476
[A[ATraining Step: 202  | total loss: [1m[32m0.17303[0m[0m | time: 47.068s
[2K
| Adam | epoch: 014 | loss: 0.17303 - acc: 0.9270 -- iter: 224/476
[A[ATraining Step: 203  | total loss: [1m[32m0.16934[0m[0m | time: 48.463s
[2K
| Adam | epoch: 014 | loss: 0.16934 - acc: 0.9312 -- iter: 256/476
[A[ATraining Step: 204  | total loss: [1m[32m0.16339[0m[0m | time: 49.614s
[2K
| Adam | epoch: 014 | loss: 0.16339 - acc: 0.9350 -- iter: 288/476
[A[ATraining Step: 205  | total loss: [1m[32m0.15740[0m[0m | time: 50.587s
[2K
| Adam | epoch: 014 | loss: 0.15740 - acc: 0.9383 -- iter: 320/476
[A[ATraining Step: 206  | total loss: [1m[32m0.16741[0m[0m | time: 51.941s
[2K
| Adam | epoch: 014 | loss: 0.16741 - acc: 0.9382 -- iter: 352/476
[A[ATraining Step: 207  | total loss: [1m[32m0.16039[0m[0m | time: 53.250s
[2K
| Adam | epoch: 014 | loss: 0.16039 - acc: 0.9413 -- iter: 384/476
[A[ATraining Step: 208  | total loss: [1m[32m0.16798[0m[0m | time: 55.780s
[2K
| Adam | epoch: 014 | loss: 0.16798 - acc: 0.9436 -- iter: 416/476
[A[ATraining Step: 209  | total loss: [1m[32m0.15665[0m[0m | time: 62.220s
[2K
| Adam | epoch: 014 | loss: 0.15665 - acc: 0.9492 -- iter: 448/476
[A[ATraining Step: 210  | total loss: [1m[32m0.15129[0m[0m | time: 90.550s
[2K
| Adam | epoch: 014 | loss: 0.15129 - acc: 0.9481 | val_loss: 0.45442 - val_acc: 0.8322 -- iter: 476/476
--
Training Step: 211  | total loss: [1m[32m0.13935[0m[0m | time: 1.177s
[2K
| Adam | epoch: 015 | loss: 0.13935 - acc: 0.9533 -- iter: 032/476
[A[ATraining Step: 212  | total loss: [1m[32m0.13217[0m[0m | time: 2.313s
[2K
| Adam | epoch: 015 | loss: 0.13217 - acc: 0.9548 -- iter: 064/476
[A[ATraining Step: 213  | total loss: [1m[32m0.12709[0m[0m | time: 3.442s
[2K
| Adam | epoch: 015 | loss: 0.12709 - acc: 0.9562 -- iter: 096/476
[A[ATraining Step: 214  | total loss: [1m[32m0.11899[0m[0m | time: 4.756s
[2K
| Adam | epoch: 015 | loss: 0.11899 - acc: 0.9606 -- iter: 128/476
[A[ATraining Step: 215  | total loss: [1m[32m0.11094[0m[0m | time: 5.812s
[2K
| Adam | epoch: 015 | loss: 0.11094 - acc: 0.9645 -- iter: 160/476
[A[ATraining Step: 216  | total loss: [1m[32m0.11193[0m[0m | time: 7.062s
[2K
| Adam | epoch: 015 | loss: 0.11193 - acc: 0.9649 -- iter: 192/476
[A[ATraining Step: 217  | total loss: [1m[32m0.11191[0m[0m | time: 8.337s
[2K
| Adam | epoch: 015 | loss: 0.11191 - acc: 0.9591 -- iter: 224/476
[A[ATraining Step: 218  | total loss: [1m[32m0.10958[0m[0m | time: 9.729s
[2K
| Adam | epoch: 015 | loss: 0.10958 - acc: 0.9600 -- iter: 256/476
[A[ATraining Step: 219  | total loss: [1m[32m0.12133[0m[0m | time: 10.897s
[2K
| Adam | epoch: 015 | loss: 0.12133 - acc: 0.9578 -- iter: 288/476
[A[ATraining Step: 220  | total loss: [1m[32m0.13328[0m[0m | time: 14.842s
[2K
| Adam | epoch: 015 | loss: 0.13328 - acc: 0.9589 -- iter: 320/476
[A[ATraining Step: 221  | total loss: [1m[32m0.12960[0m[0m | time: 17.447s
[2K
| Adam | epoch: 015 | loss: 0.12960 - acc: 0.9599 -- iter: 352/476
[A[ATraining Step: 222  | total loss: [1m[32m0.12382[0m[0m | time: 18.605s
[2K
| Adam | epoch: 015 | loss: 0.12382 - acc: 0.9608 -- iter: 384/476
[A[ATraining Step: 223  | total loss: [1m[32m0.14406[0m[0m | time: 19.669s
[2K
| Adam | epoch: 015 | loss: 0.14406 - acc: 0.9491 -- iter: 416/476
[A[ATraining Step: 224  | total loss: [1m[32m0.19394[0m[0m | time: 20.681s
[2K
| Adam | epoch: 015 | loss: 0.19394 - acc: 0.9399 -- iter: 448/476
[A[ATraining Step: 225  | total loss: [1m[32m0.18180[0m[0m | time: 23.208s
[2K
| Adam | epoch: 015 | loss: 0.18180 - acc: 0.9459 | val_loss: 0.61280 - val_acc: 0.8188 -- iter: 476/476
--
Validation AUC:0.8998907899526757
Validation AUPRC:0.9315184796687023
Test AUC:0.9206349206349207
Test AUPRC:0.9275774980889794
BestTestF1Score	0.88	0.77	0.89	0.88	0.89	64	9	68	8	0.05
BestTestMCCScore	0.87	0.76	0.88	0.89	0.86	62	8	69	10	0.07
BestTestAccuracyScore	0.87	0.76	0.88	0.89	0.86	62	8	69	10	0.07
BestValidationF1Score	0.88	0.73	0.87	0.88	0.88	72	10	57	10	0.05
BestValidationMCC	0.88	0.73	0.87	0.89	0.87	71	9	58	11	0.07
BestValidationAccuracy	0.88	0.73	0.87	0.89	0.87	71	9	58	11	0.07
TestPredictions (Threshold:0.07)
CHEMBL1082152,FN,ACT,0.05999999865889549	CHEMBL488811,FP,INACT,0.7099999785423279	CHEMBL3330260,TP,ACT,0.7200000286102295	CHEMBL3410073,TP,ACT,0.47999998927116394	CHEMBL2392392,TN,INACT,0.009999999776482582	CHEMBL558859,TN,INACT,0.009999999776482582	CHEMBL3422091,TP,ACT,1.0	CHEMBL3609567,TN,INACT,0.009999999776482582	CHEMBL3691629,TN,INACT,0.019999999552965164	CHEMBL522760,TN,INACT,0.0	CHEMBL3691660,TN,INACT,0.019999999552965164	CHEMBL2392378,TN,INACT,0.009999999776482582	CHEMBL3109940,TP,ACT,0.20000000298023224	CHEMBL1908395,FN,ACT,0.05000000074505806	CHEMBL1241674,FN,ACT,0.009999999776482582	CHEMBL1910756,TN,INACT,0.0	CHEMBL550856,TN,INACT,0.0	CHEMBL335938,TN,INACT,0.009999999776482582	CHEMBL3330277,TP,ACT,0.9700000286102295	CHEMBL3092030,TP,ACT,0.9300000071525574	CHEMBL1877245,TN,INACT,0.0	CHEMBL488646,FP,INACT,0.9300000071525574	CHEMBL3609568,TN,INACT,0.0	CHEMBL3596524,TN,INACT,0.009999999776482582	CHEMBL3421972,TP,ACT,0.6399999856948853	CHEMBL498705,FP,INACT,0.36000001430511475	CHEMBL2420909,TN,INACT,0.009999999776482582	CHEMBL3818403,TP,ACT,0.9399999976158142	CHEMBL1171329,TN,INACT,0.0	CHEMBL1688211,TN,INACT,0.019999999552965164	CHEMBL2047958,TP,ACT,0.9900000095367432	CHEMBL3330255,TP,ACT,0.9599999785423279	CHEMBL3422053,TP,ACT,0.9399999976158142	CHEMBL3680501,TN,INACT,0.009999999776482582	CHEMBL3330272,TP,ACT,1.0	CHEMBL487526,TN,INACT,0.009999999776482582	CHEMBL3703179,TP,ACT,0.15000000596046448	CHEMBL100500,TN,INACT,0.0	CHEMBL2047960,TP,ACT,0.18000000715255737	CHEMBL3109960,FN,ACT,0.019999999552965164	CHEMBL3422081,TP,ACT,0.6899999976158142	CHEMBL1910602,TN,INACT,0.009999999776482582	CHEMBL1331627,TN,INACT,0.0	CHEMBL1288582,FN,ACT,0.0	CHEMBL2089255,TP,ACT,0.8500000238418579	CHEMBL2348175,TN,INACT,0.0	CHEMBL3680497,TN,INACT,0.019999999552965164	CHEMBL509435,FP,INACT,0.3199999928474426	CHEMBL604748,TN,INACT,0.009999999776482582	CHEMBL521734,TN,INACT,0.019999999552965164	CHEMBL1922121,TN,INACT,0.009999999776482582	CHEMBL3680461,TN,INACT,0.0	CHEMBL457179,TN,INACT,0.009999999776482582	CHEMBL3659984,TN,INACT,0.009999999776482582	CHEMBL608533,TP,ACT,0.8799999952316284	CHEMBL1258663,TN,INACT,0.009999999776482582	CHEMBL1270522,TN,INACT,0.03999999910593033	CHEMBL3422072,TP,ACT,0.9200000166893005	CHEMBL2047970,TP,ACT,0.9100000262260437	CHEMBL2163616,TN,INACT,0.019999999552965164	CHEMBL3666766,TP,ACT,0.800000011920929	CHEMBL178397,TN,INACT,0.0	CHEMBL2164716,TN,INACT,0.0	CHEMBL233349,TN,INACT,0.029999999329447746	CHEMBL3810345,TP,ACT,0.8999999761581421	CHEMBL2380587,TP,ACT,0.9300000071525574	CHEMBL38380,TN,INACT,0.009999999776482582	CHEMBL3109955,TP,ACT,0.8899999856948853	CHEMBL3330270,TP,ACT,0.9599999785423279	CHEMBL23507,TN,INACT,0.05000000074505806	CHEMBL1336,FN,ACT,0.0	CHEMBL1807300,TP,ACT,0.9200000166893005	CHEMBL3410065,TP,ACT,0.8399999737739563	CHEMBL1910761,TN,INACT,0.019999999552965164	CHEMBL454973,TN,INACT,0.0	CHEMBL3665668,TN,INACT,0.009999999776482582	CHEMBL312078,TN,INACT,0.009999999776482582	CHEMBL2047964,TP,ACT,0.800000011920929	CHEMBL464552,FN,ACT,0.03999999910593033	CHEMBL3330264,TP,ACT,0.949999988079071	CHEMBL3422093,TP,ACT,1.0	CHEMBL2029514,FP,INACT,0.15000000596046448	CHEMBL402355,TN,INACT,0.009999999776482582	CHEMBL3330278,TP,ACT,0.9599999785423279	CHEMBL3342105,TN,INACT,0.009999999776482582	CHEMBL3109935,TP,ACT,0.75	CHEMBL362455,TN,INACT,0.0	CHEMBL3422063,TP,ACT,0.9800000190734863	CHEMBL3809487,TP,ACT,0.14000000059604645	CHEMBL1807302,TP,ACT,0.9300000071525574	CHEMBL3092037,TP,ACT,0.25	CHEMBL78223,TN,INACT,0.009999999776482582	CHEMBL3109932,TP,ACT,0.3799999952316284	CHEMBL2392240,TN,INACT,0.0	CHEMBL2392238,TN,INACT,0.0	CHEMBL390066,TN,INACT,0.0	CHEMBL3818533,TP,ACT,0.9100000262260437	CHEMBL88326,FP,INACT,0.28999999165534973	CHEMBL3810175,TP,ACT,0.17000000178813934	CHEMBL3665664,TN,INACT,0.009999999776482582	CHEMBL3693949,TN,INACT,0.03999999910593033	CHEMBL3092038,TP,ACT,0.25999999046325684	CHEMBL3410071,TP,ACT,0.9700000286102295	CHEMBL1688210,TN,INACT,0.019999999552965164	CHEMBL131098,TN,INACT,0.009999999776482582	CHEMBL3330244,TP,ACT,0.07000000029802322	CHEMBL1808336,TP,ACT,0.8799999952316284	CHEMBL3703183,TP,ACT,0.49000000953674316	CHEMBL2380581,TP,ACT,0.6000000238418579	CHEMBL3809210,TP,ACT,0.9100000262260437	CHEMBL1688204,FP,INACT,0.11999999731779099	CHEMBL3818733,TP,ACT,0.9599999785423279	CHEMBL2048079,TP,ACT,0.8399999737739563	CHEMBL1808338,TP,ACT,0.9599999785423279	CHEMBL191003,FN,ACT,0.029999999329447746	CHEMBL2380578,TP,ACT,0.44999998807907104	CHEMBL3422095,TP,ACT,1.0	CHEMBL490251,TN,INACT,0.009999999776482582	CHEMBL317281,TN,INACT,0.0	CHEMBL2380579,TP,ACT,0.9900000095367432	CHEMBL1784649,TN,INACT,0.009999999776482582	CHEMBL3330262,TP,ACT,0.4000000059604645	CHEMBL3422096,TP,ACT,1.0	CHEMBL3819182,TP,ACT,0.8700000047683716	CHEMBL418793,TN,INACT,0.0	CHEMBL2029510,TN,INACT,0.029999999329447746	CHEMBL3809531,FN,ACT,0.019999999552965164	CHEMBL3109941,TP,ACT,0.6299999952316284	CHEMBL266540,TN,INACT,0.029999999329447746	CHEMBL495758,TN,INACT,0.009999999776482582	CHEMBL151,TN,INACT,0.0	CHEMBL230011,FN,ACT,0.0	CHEMBL1688212,TN,INACT,0.03999999910593033	CHEMBL172973,TN,INACT,0.009999999776482582	CHEMBL3623844,TN,INACT,0.0	CHEMBL573578,TN,INACT,0.0	CHEMBL3085242,TN,INACT,0.009999999776482582	CHEMBL3808500,TP,ACT,0.9100000262260437	CHEMBL1688209,TN,INACT,0.009999999776482582	CHEMBL3109953,TP,ACT,0.9800000190734863	CHEMBL2047966,TP,ACT,0.8700000047683716	CHEMBL3666769,TP,ACT,0.23999999463558197	CHEMBL101557,TN,INACT,0.019999999552965164	CHEMBL2047950,TP,ACT,0.9900000095367432	CHEMBL1641989,TN,INACT,0.029999999329447746	CHEMBL230761,FP,INACT,0.8899999856948853	CHEMBL3703181,TP,ACT,0.6200000047683716	CHEMBL3703188,TP,ACT,1.0	CHEMBL322640,TN,INACT,0.0	

