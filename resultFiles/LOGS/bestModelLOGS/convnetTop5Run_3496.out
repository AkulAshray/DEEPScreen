CNNModel CHEMBL3157 adam 0.0005 15 32 0 0.8 False True
Number of active compounds :	485
Number of inactive compounds :	485
---------------------------------
Run id: CNNModel_CHEMBL3157_adam_0.0005_15_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3157_adam_0.0005_15_32_0.8_True/
---------------------------------
Training samples: 598
Validation samples: 188
--
Training Step: 1  | time: 1.467s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/598
[A[ATraining Step: 2  | total loss: [1m[32m0.62399[0m[0m | time: 2.544s
[2K
| Adam | epoch: 001 | loss: 0.62399 - acc: 0.3937 -- iter: 064/598
[A[ATraining Step: 3  | total loss: [1m[32m0.68035[0m[0m | time: 3.652s
[2K
| Adam | epoch: 001 | loss: 0.68035 - acc: 0.5063 -- iter: 096/598
[A[ATraining Step: 4  | total loss: [1m[32m0.69007[0m[0m | time: 4.695s
[2K
| Adam | epoch: 001 | loss: 0.69007 - acc: 0.5016 -- iter: 128/598
[A[ATraining Step: 5  | total loss: [1m[32m0.69083[0m[0m | time: 5.629s
[2K
| Adam | epoch: 001 | loss: 0.69083 - acc: 0.6087 -- iter: 160/598
[A[ATraining Step: 6  | total loss: [1m[32m0.69172[0m[0m | time: 6.244s
[2K
| Adam | epoch: 001 | loss: 0.69172 - acc: 0.5589 -- iter: 192/598
[A[ATraining Step: 7  | total loss: [1m[32m0.68957[0m[0m | time: 6.890s
[2K
| Adam | epoch: 001 | loss: 0.68957 - acc: 0.5611 -- iter: 224/598
[A[ATraining Step: 8  | total loss: [1m[32m0.70584[0m[0m | time: 7.528s
[2K
| Adam | epoch: 001 | loss: 0.70584 - acc: 0.4564 -- iter: 256/598
[A[ATraining Step: 9  | total loss: [1m[32m0.69379[0m[0m | time: 8.157s
[2K
| Adam | epoch: 001 | loss: 0.69379 - acc: 0.5291 -- iter: 288/598
[A[ATraining Step: 10  | total loss: [1m[32m0.69874[0m[0m | time: 8.779s
[2K
| Adam | epoch: 001 | loss: 0.69874 - acc: 0.4677 -- iter: 320/598
[A[ATraining Step: 11  | total loss: [1m[32m0.69702[0m[0m | time: 9.384s
[2K
| Adam | epoch: 001 | loss: 0.69702 - acc: 0.4682 -- iter: 352/598
[A[ATraining Step: 12  | total loss: [1m[32m0.69621[0m[0m | time: 9.998s
[2K
| Adam | epoch: 001 | loss: 0.69621 - acc: 0.4684 -- iter: 384/598
[A[ATraining Step: 13  | total loss: [1m[32m0.69473[0m[0m | time: 10.652s
[2K
| Adam | epoch: 001 | loss: 0.69473 - acc: 0.4820 -- iter: 416/598
[A[ATraining Step: 14  | total loss: [1m[32m0.69556[0m[0m | time: 11.273s
[2K
| Adam | epoch: 001 | loss: 0.69556 - acc: 0.4382 -- iter: 448/598
[A[ATraining Step: 15  | total loss: [1m[32m0.69382[0m[0m | time: 11.900s
[2K
| Adam | epoch: 001 | loss: 0.69382 - acc: 0.5113 -- iter: 480/598
[A[ATraining Step: 16  | total loss: [1m[32m0.69345[0m[0m | time: 12.499s
[2K
| Adam | epoch: 001 | loss: 0.69345 - acc: 0.5305 -- iter: 512/598
[A[ATraining Step: 17  | total loss: [1m[32m0.69319[0m[0m | time: 13.128s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5308 -- iter: 544/598
[A[ATraining Step: 18  | total loss: [1m[32m0.69285[0m[0m | time: 13.736s
[2K
| Adam | epoch: 001 | loss: 0.69285 - acc: 0.5634 -- iter: 576/598
[A[ATraining Step: 19  | total loss: [1m[32m0.69303[0m[0m | time: 15.192s
[2K
| Adam | epoch: 001 | loss: 0.69303 - acc: 0.5318 | val_loss: 0.69338 - val_acc: 0.4787 -- iter: 598/598
--
Training Step: 20  | total loss: [1m[32m0.69301[0m[0m | time: 0.450s
[2K
| Adam | epoch: 002 | loss: 0.69301 - acc: 0.5362 -- iter: 032/598
[A[ATraining Step: 21  | total loss: [1m[32m0.69289[0m[0m | time: 1.078s
[2K
| Adam | epoch: 002 | loss: 0.69289 - acc: 0.5391 -- iter: 064/598
[A[ATraining Step: 22  | total loss: [1m[32m0.69245[0m[0m | time: 1.693s
[2K
| Adam | epoch: 002 | loss: 0.69245 - acc: 0.5649 -- iter: 096/598
[A[ATraining Step: 23  | total loss: [1m[32m0.69254[0m[0m | time: 2.351s
[2K
| Adam | epoch: 002 | loss: 0.69254 - acc: 0.5551 -- iter: 128/598
[A[ATraining Step: 24  | total loss: [1m[32m0.69201[0m[0m | time: 2.963s
[2K
| Adam | epoch: 002 | loss: 0.69201 - acc: 0.5748 -- iter: 160/598
[A[ATraining Step: 25  | total loss: [1m[32m0.69208[0m[0m | time: 3.582s
[2K
| Adam | epoch: 002 | loss: 0.69208 - acc: 0.5629 -- iter: 192/598
[A[ATraining Step: 26  | total loss: [1m[32m0.69325[0m[0m | time: 4.211s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5132 -- iter: 224/598
[A[ATraining Step: 27  | total loss: [1m[32m0.69185[0m[0m | time: 4.814s
[2K
| Adam | epoch: 002 | loss: 0.69185 - acc: 0.5580 -- iter: 256/598
[A[ATraining Step: 28  | total loss: [1m[32m0.69320[0m[0m | time: 5.427s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5122 -- iter: 288/598
[A[ATraining Step: 29  | total loss: [1m[32m0.69271[0m[0m | time: 6.053s
[2K
| Adam | epoch: 002 | loss: 0.69271 - acc: 0.5245 -- iter: 320/598
[A[ATraining Step: 30  | total loss: [1m[32m0.69186[0m[0m | time: 6.685s
[2K
| Adam | epoch: 002 | loss: 0.69186 - acc: 0.5483 -- iter: 352/598
[A[ATraining Step: 31  | total loss: [1m[32m0.69190[0m[0m | time: 7.312s
[2K
| Adam | epoch: 002 | loss: 0.69190 - acc: 0.5443 -- iter: 384/598
[A[ATraining Step: 32  | total loss: [1m[32m0.69133[0m[0m | time: 8.320s
[2K
| Adam | epoch: 002 | loss: 0.69133 - acc: 0.5555 -- iter: 416/598
[A[ATraining Step: 33  | total loss: [1m[32m0.69182[0m[0m | time: 9.413s
[2K
| Adam | epoch: 002 | loss: 0.69182 - acc: 0.5433 -- iter: 448/598
[A[ATraining Step: 34  | total loss: [1m[32m0.69112[0m[0m | time: 10.450s
[2K
| Adam | epoch: 002 | loss: 0.69112 - acc: 0.5541 -- iter: 480/598
[A[ATraining Step: 35  | total loss: [1m[32m0.69213[0m[0m | time: 11.273s
[2K
| Adam | epoch: 002 | loss: 0.69213 - acc: 0.5362 -- iter: 512/598
[A[ATraining Step: 36  | total loss: [1m[32m0.69249[0m[0m | time: 12.176s
[2K
| Adam | epoch: 002 | loss: 0.69249 - acc: 0.5288 -- iter: 544/598
[A[ATraining Step: 37  | total loss: [1m[32m0.69391[0m[0m | time: 13.126s
[2K
| Adam | epoch: 002 | loss: 0.69391 - acc: 0.5043 -- iter: 576/598
[A[ATraining Step: 38  | total loss: [1m[32m0.69506[0m[0m | time: 15.101s
[2K
| Adam | epoch: 002 | loss: 0.69506 - acc: 0.4851 | val_loss: 0.69473 - val_acc: 0.4787 -- iter: 598/598
--
Training Step: 39  | total loss: [1m[32m0.69206[0m[0m | time: 0.697s
[2K
| Adam | epoch: 003 | loss: 0.69206 - acc: 0.5299 -- iter: 032/598
[A[ATraining Step: 40  | total loss: [1m[32m0.69188[0m[0m | time: 1.264s
[2K
| Adam | epoch: 003 | loss: 0.69188 - acc: 0.5328 -- iter: 064/598
[A[ATraining Step: 41  | total loss: [1m[32m0.69164[0m[0m | time: 2.362s
[2K
| Adam | epoch: 003 | loss: 0.69164 - acc: 0.5351 -- iter: 096/598
[A[ATraining Step: 42  | total loss: [1m[32m0.69313[0m[0m | time: 3.540s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5119 -- iter: 128/598
[A[ATraining Step: 43  | total loss: [1m[32m0.69275[0m[0m | time: 4.502s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5153 -- iter: 160/598
[A[ATraining Step: 44  | total loss: [1m[32m0.69250[0m[0m | time: 5.381s
[2K
| Adam | epoch: 003 | loss: 0.69250 - acc: 0.5181 -- iter: 192/598
[A[ATraining Step: 45  | total loss: [1m[32m0.69415[0m[0m | time: 6.327s
[2K
| Adam | epoch: 003 | loss: 0.69415 - acc: 0.4938 -- iter: 224/598
[A[ATraining Step: 46  | total loss: [1m[32m0.69464[0m[0m | time: 7.277s
[2K
| Adam | epoch: 003 | loss: 0.69464 - acc: 0.4844 -- iter: 256/598
[A[ATraining Step: 47  | total loss: [1m[32m0.69445[0m[0m | time: 8.235s
[2K
| Adam | epoch: 003 | loss: 0.69445 - acc: 0.4870 -- iter: 288/598
[A[ATraining Step: 48  | total loss: [1m[32m0.69266[0m[0m | time: 9.287s
[2K
| Adam | epoch: 003 | loss: 0.69266 - acc: 0.5192 -- iter: 320/598
[A[ATraining Step: 49  | total loss: [1m[32m0.69326[0m[0m | time: 10.374s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5063 -- iter: 352/598
[A[ATraining Step: 50  | total loss: [1m[32m0.69185[0m[0m | time: 11.299s
[2K
| Adam | epoch: 003 | loss: 0.69185 - acc: 0.5344 -- iter: 384/598
[A[ATraining Step: 51  | total loss: [1m[32m0.69203[0m[0m | time: 12.381s
[2K
| Adam | epoch: 003 | loss: 0.69203 - acc: 0.5292 -- iter: 416/598
[A[ATraining Step: 52  | total loss: [1m[32m0.69230[0m[0m | time: 13.452s
[2K
| Adam | epoch: 003 | loss: 0.69230 - acc: 0.5201 -- iter: 448/598
[A[ATraining Step: 53  | total loss: [1m[32m0.69256[0m[0m | time: 14.341s
[2K
| Adam | epoch: 003 | loss: 0.69256 - acc: 0.5125 -- iter: 480/598
[A[ATraining Step: 54  | total loss: [1m[32m0.69206[0m[0m | time: 15.201s
[2K
| Adam | epoch: 003 | loss: 0.69206 - acc: 0.5198 -- iter: 512/598
[A[ATraining Step: 55  | total loss: [1m[32m0.69293[0m[0m | time: 16.153s
[2K
| Adam | epoch: 003 | loss: 0.69293 - acc: 0.5036 -- iter: 544/598
[A[ATraining Step: 56  | total loss: [1m[32m0.69254[0m[0m | time: 17.094s
[2K
| Adam | epoch: 003 | loss: 0.69254 - acc: 0.5075 -- iter: 576/598
[A[ATraining Step: 57  | total loss: [1m[32m0.69219[0m[0m | time: 19.103s
[2K
| Adam | epoch: 003 | loss: 0.69219 - acc: 0.5151 | val_loss: 0.69324 - val_acc: 0.4787 -- iter: 598/598
--
Training Step: 58  | total loss: [1m[32m0.69339[0m[0m | time: 0.922s
[2K
| Adam | epoch: 004 | loss: 0.69339 - acc: 0.4917 -- iter: 032/598
[A[ATraining Step: 59  | total loss: [1m[32m0.69349[0m[0m | time: 1.691s
[2K
| Adam | epoch: 004 | loss: 0.69349 - acc: 0.4886 -- iter: 064/598
[A[ATraining Step: 60  | total loss: [1m[32m0.69287[0m[0m | time: 2.454s
[2K
| Adam | epoch: 004 | loss: 0.69287 - acc: 0.5022 -- iter: 096/598
[A[ATraining Step: 61  | total loss: [1m[32m0.69227[0m[0m | time: 3.495s
[2K
| Adam | epoch: 004 | loss: 0.69227 - acc: 0.5137 -- iter: 128/598
[A[ATraining Step: 62  | total loss: [1m[32m0.69198[0m[0m | time: 4.259s
[2K
| Adam | epoch: 004 | loss: 0.69198 - acc: 0.5160 -- iter: 160/598
[A[ATraining Step: 63  | total loss: [1m[32m0.69184[0m[0m | time: 5.162s
[2K
| Adam | epoch: 004 | loss: 0.69184 - acc: 0.5140 -- iter: 192/598
[A[ATraining Step: 64  | total loss: [1m[32m0.69150[0m[0m | time: 6.092s
[2K
| Adam | epoch: 004 | loss: 0.69150 - acc: 0.5161 -- iter: 224/598
[A[ATraining Step: 65  | total loss: [1m[32m0.69092[0m[0m | time: 7.048s
[2K
| Adam | epoch: 004 | loss: 0.69092 - acc: 0.5218 -- iter: 256/598
[A[ATraining Step: 66  | total loss: [1m[32m0.69029[0m[0m | time: 8.031s
[2K
| Adam | epoch: 004 | loss: 0.69029 - acc: 0.5268 -- iter: 288/598
[A[ATraining Step: 67  | total loss: [1m[32m0.69004[0m[0m | time: 9.063s
[2K
| Adam | epoch: 004 | loss: 0.69004 - acc: 0.5273 -- iter: 320/598
[A[ATraining Step: 68  | total loss: [1m[32m0.69068[0m[0m | time: 10.009s
[2K
| Adam | epoch: 004 | loss: 0.69068 - acc: 0.5204 -- iter: 352/598
[A[ATraining Step: 69  | total loss: [1m[32m0.69049[0m[0m | time: 10.847s
[2K
| Adam | epoch: 004 | loss: 0.69049 - acc: 0.5180 -- iter: 384/598
[A[ATraining Step: 70  | total loss: [1m[32m0.68977[0m[0m | time: 11.855s
[2K
| Adam | epoch: 004 | loss: 0.68977 - acc: 0.5195 -- iter: 416/598
[A[ATraining Step: 71  | total loss: [1m[32m0.68861[0m[0m | time: 12.923s
[2K
| Adam | epoch: 004 | loss: 0.68861 - acc: 0.5244 -- iter: 448/598
[A[ATraining Step: 72  | total loss: [1m[32m0.68994[0m[0m | time: 13.963s
[2K
| Adam | epoch: 004 | loss: 0.68994 - acc: 0.5076 -- iter: 480/598
[A[ATraining Step: 73  | total loss: [1m[32m0.68826[0m[0m | time: 15.056s
[2K
| Adam | epoch: 004 | loss: 0.68826 - acc: 0.5137 -- iter: 512/598
[A[ATraining Step: 74  | total loss: [1m[32m0.68833[0m[0m | time: 16.049s
[2K
| Adam | epoch: 004 | loss: 0.68833 - acc: 0.5019 -- iter: 544/598
[A[ATraining Step: 75  | total loss: [1m[32m0.68627[0m[0m | time: 17.113s
[2K
| Adam | epoch: 004 | loss: 0.68627 - acc: 0.5051 -- iter: 576/598
[A[ATraining Step: 76  | total loss: [1m[32m0.68432[0m[0m | time: 19.116s
[2K
| Adam | epoch: 004 | loss: 0.68432 - acc: 0.5046 | val_loss: 0.67672 - val_acc: 0.4787 -- iter: 598/598
--
Training Step: 77  | total loss: [1m[32m0.68142[0m[0m | time: 0.611s
[2K
| Adam | epoch: 005 | loss: 0.68142 - acc: 0.5074 -- iter: 032/598
[A[ATraining Step: 78  | total loss: [1m[32m0.68027[0m[0m | time: 1.229s
[2K
| Adam | epoch: 005 | loss: 0.68027 - acc: 0.5066 -- iter: 064/598
[A[ATraining Step: 79  | total loss: [1m[32m0.67709[0m[0m | time: 1.660s
[2K
| Adam | epoch: 005 | loss: 0.67709 - acc: 0.5124 -- iter: 096/598
[A[ATraining Step: 80  | total loss: [1m[32m0.67670[0m[0m | time: 2.085s
[2K
| Adam | epoch: 005 | loss: 0.67670 - acc: 0.5297 -- iter: 128/598
[A[ATraining Step: 81  | total loss: [1m[32m0.67524[0m[0m | time: 2.702s
[2K
| Adam | epoch: 005 | loss: 0.67524 - acc: 0.5405 -- iter: 160/598
[A[ATraining Step: 82  | total loss: [1m[32m0.67311[0m[0m | time: 3.321s
[2K
| Adam | epoch: 005 | loss: 0.67311 - acc: 0.5427 -- iter: 192/598
[A[ATraining Step: 83  | total loss: [1m[32m0.66543[0m[0m | time: 3.942s
[2K
| Adam | epoch: 005 | loss: 0.66543 - acc: 0.5634 -- iter: 224/598
[A[ATraining Step: 84  | total loss: [1m[32m0.66652[0m[0m | time: 4.549s
[2K
| Adam | epoch: 005 | loss: 0.66652 - acc: 0.5665 -- iter: 256/598
[A[ATraining Step: 85  | total loss: [1m[32m0.66000[0m[0m | time: 5.159s
[2K
| Adam | epoch: 005 | loss: 0.66000 - acc: 0.5848 -- iter: 288/598
[A[ATraining Step: 86  | total loss: [1m[32m0.65485[0m[0m | time: 5.772s
[2K
| Adam | epoch: 005 | loss: 0.65485 - acc: 0.6013 -- iter: 320/598
[A[ATraining Step: 87  | total loss: [1m[32m0.65008[0m[0m | time: 6.409s
[2K
| Adam | epoch: 005 | loss: 0.65008 - acc: 0.6162 -- iter: 352/598
[A[ATraining Step: 88  | total loss: [1m[32m0.64946[0m[0m | time: 7.027s
[2K
| Adam | epoch: 005 | loss: 0.64946 - acc: 0.6171 -- iter: 384/598
[A[ATraining Step: 89  | total loss: [1m[32m0.64360[0m[0m | time: 7.636s
[2K
| Adam | epoch: 005 | loss: 0.64360 - acc: 0.6179 -- iter: 416/598
[A[ATraining Step: 90  | total loss: [1m[32m0.63425[0m[0m | time: 8.724s
[2K
| Adam | epoch: 005 | loss: 0.63425 - acc: 0.6311 -- iter: 448/598
[A[ATraining Step: 91  | total loss: [1m[32m0.62894[0m[0m | time: 9.752s
[2K
| Adam | epoch: 005 | loss: 0.62894 - acc: 0.6430 -- iter: 480/598
[A[ATraining Step: 92  | total loss: [1m[32m0.62992[0m[0m | time: 10.774s
[2K
| Adam | epoch: 005 | loss: 0.62992 - acc: 0.6474 -- iter: 512/598
[A[ATraining Step: 93  | total loss: [1m[32m0.61872[0m[0m | time: 11.621s
[2K
| Adam | epoch: 005 | loss: 0.61872 - acc: 0.6702 -- iter: 544/598
[A[ATraining Step: 94  | total loss: [1m[32m0.60874[0m[0m | time: 12.555s
[2K
| Adam | epoch: 005 | loss: 0.60874 - acc: 0.6750 -- iter: 576/598
[A[ATraining Step: 95  | total loss: [1m[32m0.59638[0m[0m | time: 14.511s
[2K
| Adam | epoch: 005 | loss: 0.59638 - acc: 0.6888 | val_loss: 0.52066 - val_acc: 0.7660 -- iter: 598/598
--
Training Step: 96  | total loss: [1m[32m0.58977[0m[0m | time: 0.909s
[2K
| Adam | epoch: 006 | loss: 0.58977 - acc: 0.6949 -- iter: 032/598
[A[ATraining Step: 97  | total loss: [1m[32m0.58341[0m[0m | time: 1.866s
[2K
| Adam | epoch: 006 | loss: 0.58341 - acc: 0.7067 -- iter: 064/598
[A[ATraining Step: 98  | total loss: [1m[32m0.57093[0m[0m | time: 2.949s
[2K
| Adam | epoch: 006 | loss: 0.57093 - acc: 0.7204 -- iter: 096/598
[A[ATraining Step: 99  | total loss: [1m[32m0.58611[0m[0m | time: 3.756s
[2K
| Adam | epoch: 006 | loss: 0.58611 - acc: 0.7015 -- iter: 128/598
[A[ATraining Step: 100  | total loss: [1m[32m0.58887[0m[0m | time: 4.380s
[2K
| Adam | epoch: 006 | loss: 0.58887 - acc: 0.6995 -- iter: 160/598
[A[ATraining Step: 101  | total loss: [1m[32m0.57713[0m[0m | time: 5.216s
[2K
| Adam | epoch: 006 | loss: 0.57713 - acc: 0.7114 -- iter: 192/598
[A[ATraining Step: 102  | total loss: [1m[32m0.55213[0m[0m | time: 6.119s
[2K
| Adam | epoch: 006 | loss: 0.55213 - acc: 0.7277 -- iter: 224/598
[A[ATraining Step: 103  | total loss: [1m[32m0.56427[0m[0m | time: 7.069s
[2K
| Adam | epoch: 006 | loss: 0.56427 - acc: 0.7237 -- iter: 256/598
[A[ATraining Step: 104  | total loss: [1m[32m0.57962[0m[0m | time: 8.074s
[2K
| Adam | epoch: 006 | loss: 0.57962 - acc: 0.7076 -- iter: 288/598
[A[ATraining Step: 105  | total loss: [1m[32m0.55439[0m[0m | time: 9.113s
[2K
| Adam | epoch: 006 | loss: 0.55439 - acc: 0.7243 -- iter: 320/598
[A[ATraining Step: 106  | total loss: [1m[32m0.55110[0m[0m | time: 10.087s
[2K
| Adam | epoch: 006 | loss: 0.55110 - acc: 0.7300 -- iter: 352/598
[A[ATraining Step: 107  | total loss: [1m[32m0.55792[0m[0m | time: 10.983s
[2K
| Adam | epoch: 006 | loss: 0.55792 - acc: 0.7101 -- iter: 384/598
[A[ATraining Step: 108  | total loss: [1m[32m0.55900[0m[0m | time: 12.031s
[2K
| Adam | epoch: 006 | loss: 0.55900 - acc: 0.7141 -- iter: 416/598
[A[ATraining Step: 109  | total loss: [1m[32m0.54295[0m[0m | time: 13.121s
[2K
| Adam | epoch: 006 | loss: 0.54295 - acc: 0.7271 -- iter: 448/598
[A[ATraining Step: 110  | total loss: [1m[32m0.52593[0m[0m | time: 14.043s
[2K
| Adam | epoch: 006 | loss: 0.52593 - acc: 0.7325 -- iter: 480/598
[A[ATraining Step: 111  | total loss: [1m[32m0.52118[0m[0m | time: 14.896s
[2K
| Adam | epoch: 006 | loss: 0.52118 - acc: 0.7280 -- iter: 512/598
[A[ATraining Step: 112  | total loss: [1m[32m0.51740[0m[0m | time: 15.885s
[2K
| Adam | epoch: 006 | loss: 0.51740 - acc: 0.7271 -- iter: 544/598
[A[ATraining Step: 113  | total loss: [1m[32m0.51068[0m[0m | time: 16.834s
[2K
| Adam | epoch: 006 | loss: 0.51068 - acc: 0.7325 -- iter: 576/598
[A[ATraining Step: 114  | total loss: [1m[32m0.50962[0m[0m | time: 18.827s
[2K
| Adam | epoch: 006 | loss: 0.50962 - acc: 0.7342 | val_loss: 0.46879 - val_acc: 0.7819 -- iter: 598/598
--
Training Step: 115  | total loss: [1m[32m0.50121[0m[0m | time: 1.028s
[2K
| Adam | epoch: 007 | loss: 0.50121 - acc: 0.7452 -- iter: 032/598
[A[ATraining Step: 116  | total loss: [1m[32m0.49894[0m[0m | time: 2.144s
[2K
| Adam | epoch: 007 | loss: 0.49894 - acc: 0.7457 -- iter: 064/598
[A[ATraining Step: 117  | total loss: [1m[32m0.49494[0m[0m | time: 3.192s
[2K
| Adam | epoch: 007 | loss: 0.49494 - acc: 0.7492 -- iter: 096/598
[A[ATraining Step: 118  | total loss: [1m[32m0.47966[0m[0m | time: 4.023s
[2K
| Adam | epoch: 007 | loss: 0.47966 - acc: 0.7618 -- iter: 128/598
[A[ATraining Step: 119  | total loss: [1m[32m0.46488[0m[0m | time: 4.668s
[2K
| Adam | epoch: 007 | loss: 0.46488 - acc: 0.7700 -- iter: 160/598
[A[ATraining Step: 120  | total loss: [1m[32m0.45490[0m[0m | time: 5.337s
[2K
| Adam | epoch: 007 | loss: 0.45490 - acc: 0.7748 -- iter: 192/598
[A[ATraining Step: 121  | total loss: [1m[32m0.44702[0m[0m | time: 6.271s
[2K
| Adam | epoch: 007 | loss: 0.44702 - acc: 0.7792 -- iter: 224/598
[A[ATraining Step: 122  | total loss: [1m[32m0.44191[0m[0m | time: 7.207s
[2K
| Adam | epoch: 007 | loss: 0.44191 - acc: 0.7825 -- iter: 256/598
[A[ATraining Step: 123  | total loss: [1m[32m0.42393[0m[0m | time: 8.279s
[2K
| Adam | epoch: 007 | loss: 0.42393 - acc: 0.7917 -- iter: 288/598
[A[ATraining Step: 124  | total loss: [1m[32m0.41369[0m[0m | time: 9.324s
[2K
| Adam | epoch: 007 | loss: 0.41369 - acc: 0.8032 -- iter: 320/598
[A[ATraining Step: 125  | total loss: [1m[32m0.41412[0m[0m | time: 10.181s
[2K
| Adam | epoch: 007 | loss: 0.41412 - acc: 0.8073 -- iter: 352/598
[A[ATraining Step: 126  | total loss: [1m[32m0.42962[0m[0m | time: 11.256s
[2K
| Adam | epoch: 007 | loss: 0.42962 - acc: 0.8078 -- iter: 384/598
[A[ATraining Step: 127  | total loss: [1m[32m0.40305[0m[0m | time: 12.344s
[2K
| Adam | epoch: 007 | loss: 0.40305 - acc: 0.8176 -- iter: 416/598
[A[ATraining Step: 128  | total loss: [1m[32m0.41982[0m[0m | time: 13.256s
[2K
| Adam | epoch: 007 | loss: 0.41982 - acc: 0.8171 -- iter: 448/598
[A[ATraining Step: 129  | total loss: [1m[32m0.39746[0m[0m | time: 14.141s
[2K
| Adam | epoch: 007 | loss: 0.39746 - acc: 0.8291 -- iter: 480/598
[A[ATraining Step: 130  | total loss: [1m[32m0.39850[0m[0m | time: 15.104s
[2K
| Adam | epoch: 007 | loss: 0.39850 - acc: 0.8306 -- iter: 512/598
[A[ATraining Step: 131  | total loss: [1m[32m0.38384[0m[0m | time: 16.070s
[2K
| Adam | epoch: 007 | loss: 0.38384 - acc: 0.8413 -- iter: 544/598
[A[ATraining Step: 132  | total loss: [1m[32m0.38797[0m[0m | time: 17.054s
[2K
| Adam | epoch: 007 | loss: 0.38797 - acc: 0.8415 -- iter: 576/598
[A[ATraining Step: 133  | total loss: [1m[32m0.37774[0m[0m | time: 19.172s
[2K
| Adam | epoch: 007 | loss: 0.37774 - acc: 0.8511 | val_loss: 0.37221 - val_acc: 0.8138 -- iter: 598/598
--
Training Step: 134  | total loss: [1m[32m0.38583[0m[0m | time: 1.170s
[2K
| Adam | epoch: 008 | loss: 0.38583 - acc: 0.8473 -- iter: 032/598
[A[ATraining Step: 135  | total loss: [1m[32m0.37161[0m[0m | time: 2.004s
[2K
| Adam | epoch: 008 | loss: 0.37161 - acc: 0.8563 -- iter: 064/598
[A[ATraining Step: 136  | total loss: [1m[32m0.37033[0m[0m | time: 2.897s
[2K
| Adam | epoch: 008 | loss: 0.37033 - acc: 0.8582 -- iter: 096/598
[A[ATraining Step: 137  | total loss: [1m[32m0.35934[0m[0m | time: 3.887s
[2K
| Adam | epoch: 008 | loss: 0.35934 - acc: 0.8599 -- iter: 128/598
[A[ATraining Step: 138  | total loss: [1m[32m0.36109[0m[0m | time: 4.862s
[2K
| Adam | epoch: 008 | loss: 0.36109 - acc: 0.8582 -- iter: 160/598
[A[ATraining Step: 139  | total loss: [1m[32m0.34964[0m[0m | time: 5.573s
[2K
| Adam | epoch: 008 | loss: 0.34964 - acc: 0.8599 -- iter: 192/598
[A[ATraining Step: 140  | total loss: [1m[32m0.32825[0m[0m | time: 6.349s
[2K
| Adam | epoch: 008 | loss: 0.32825 - acc: 0.8739 -- iter: 224/598
[A[ATraining Step: 141  | total loss: [1m[32m0.30789[0m[0m | time: 7.318s
[2K
| Adam | epoch: 008 | loss: 0.30789 - acc: 0.8865 -- iter: 256/598
[A[ATraining Step: 142  | total loss: [1m[32m0.29569[0m[0m | time: 8.169s
[2K
| Adam | epoch: 008 | loss: 0.29569 - acc: 0.8885 -- iter: 288/598
[A[ATraining Step: 143  | total loss: [1m[32m0.29578[0m[0m | time: 9.292s
[2K
| Adam | epoch: 008 | loss: 0.29578 - acc: 0.8840 -- iter: 320/598
[A[ATraining Step: 144  | total loss: [1m[32m0.29500[0m[0m | time: 10.344s
[2K
| Adam | epoch: 008 | loss: 0.29500 - acc: 0.8800 -- iter: 352/598
[A[ATraining Step: 145  | total loss: [1m[32m0.29366[0m[0m | time: 11.272s
[2K
| Adam | epoch: 008 | loss: 0.29366 - acc: 0.8826 -- iter: 384/598
[A[ATraining Step: 146  | total loss: [1m[32m0.29065[0m[0m | time: 12.172s
[2K
| Adam | epoch: 008 | loss: 0.29065 - acc: 0.8850 -- iter: 416/598
[A[ATraining Step: 147  | total loss: [1m[32m0.27728[0m[0m | time: 13.105s
[2K
| Adam | epoch: 008 | loss: 0.27728 - acc: 0.8934 -- iter: 448/598
[A[ATraining Step: 148  | total loss: [1m[32m0.29457[0m[0m | time: 14.083s
[2K
| Adam | epoch: 008 | loss: 0.29457 - acc: 0.8915 -- iter: 480/598
[A[ATraining Step: 149  | total loss: [1m[32m0.27280[0m[0m | time: 15.058s
[2K
| Adam | epoch: 008 | loss: 0.27280 - acc: 0.9024 -- iter: 512/598
[A[ATraining Step: 150  | total loss: [1m[32m0.26901[0m[0m | time: 16.144s
[2K
| Adam | epoch: 008 | loss: 0.26901 - acc: 0.8996 -- iter: 544/598
[A[ATraining Step: 151  | total loss: [1m[32m0.25900[0m[0m | time: 17.150s
[2K
| Adam | epoch: 008 | loss: 0.25900 - acc: 0.9065 -- iter: 576/598
[A[ATraining Step: 152  | total loss: [1m[32m0.25359[0m[0m | time: 19.070s
[2K
| Adam | epoch: 008 | loss: 0.25359 - acc: 0.9096 | val_loss: 0.30146 - val_acc: 0.8723 -- iter: 598/598
--
Training Step: 153  | total loss: [1m[32m0.24033[0m[0m | time: 0.958s
[2K
| Adam | epoch: 009 | loss: 0.24033 - acc: 0.9124 -- iter: 032/598
[A[ATraining Step: 154  | total loss: [1m[32m0.22985[0m[0m | time: 1.916s
[2K
| Adam | epoch: 009 | loss: 0.22985 - acc: 0.9181 -- iter: 064/598
[A[ATraining Step: 155  | total loss: [1m[32m0.24146[0m[0m | time: 2.840s
[2K
| Adam | epoch: 009 | loss: 0.24146 - acc: 0.9044 -- iter: 096/598
[A[ATraining Step: 156  | total loss: [1m[32m0.22349[0m[0m | time: 3.951s
[2K
| Adam | epoch: 009 | loss: 0.22349 - acc: 0.9108 -- iter: 128/598
[A[ATraining Step: 157  | total loss: [1m[32m0.23680[0m[0m | time: 4.956s
[2K
| Adam | epoch: 009 | loss: 0.23680 - acc: 0.9010 -- iter: 160/598
[A[ATraining Step: 158  | total loss: [1m[32m0.23131[0m[0m | time: 5.864s
[2K
| Adam | epoch: 009 | loss: 0.23131 - acc: 0.9046 -- iter: 192/598
[A[ATraining Step: 159  | total loss: [1m[32m0.24873[0m[0m | time: 6.636s
[2K
| Adam | epoch: 009 | loss: 0.24873 - acc: 0.8954 -- iter: 224/598
[A[ATraining Step: 160  | total loss: [1m[32m0.24731[0m[0m | time: 7.455s
[2K
| Adam | epoch: 009 | loss: 0.24731 - acc: 0.8922 -- iter: 256/598
[A[ATraining Step: 161  | total loss: [1m[32m0.24611[0m[0m | time: 8.440s
[2K
| Adam | epoch: 009 | loss: 0.24611 - acc: 0.8894 -- iter: 288/598
[A[ATraining Step: 162  | total loss: [1m[32m0.22795[0m[0m | time: 9.280s
[2K
| Adam | epoch: 009 | loss: 0.22795 - acc: 0.9004 -- iter: 320/598
[A[ATraining Step: 163  | total loss: [1m[32m0.22972[0m[0m | time: 10.204s
[2K
| Adam | epoch: 009 | loss: 0.22972 - acc: 0.9010 -- iter: 352/598
[A[ATraining Step: 164  | total loss: [1m[32m0.22008[0m[0m | time: 11.093s
[2K
| Adam | epoch: 009 | loss: 0.22008 - acc: 0.9078 -- iter: 384/598
[A[ATraining Step: 165  | total loss: [1m[32m0.21573[0m[0m | time: 12.034s
[2K
| Adam | epoch: 009 | loss: 0.21573 - acc: 0.9076 -- iter: 416/598
[A[ATraining Step: 166  | total loss: [1m[32m0.22729[0m[0m | time: 13.171s
[2K
| Adam | epoch: 009 | loss: 0.22729 - acc: 0.9106 -- iter: 448/598
[A[ATraining Step: 167  | total loss: [1m[32m0.24266[0m[0m | time: 14.064s
[2K
| Adam | epoch: 009 | loss: 0.24266 - acc: 0.9039 -- iter: 480/598
[A[ATraining Step: 168  | total loss: [1m[32m0.24220[0m[0m | time: 15.163s
[2K
| Adam | epoch: 009 | loss: 0.24220 - acc: 0.9104 -- iter: 512/598
[A[ATraining Step: 169  | total loss: [1m[32m0.23872[0m[0m | time: 16.247s
[2K
| Adam | epoch: 009 | loss: 0.23872 - acc: 0.9131 -- iter: 544/598
[A[ATraining Step: 170  | total loss: [1m[32m0.23604[0m[0m | time: 17.153s
[2K
| Adam | epoch: 009 | loss: 0.23604 - acc: 0.9124 -- iter: 576/598
[A[ATraining Step: 171  | total loss: [1m[32m0.22507[0m[0m | time: 19.038s
[2K
| Adam | epoch: 009 | loss: 0.22507 - acc: 0.9149 | val_loss: 0.29496 - val_acc: 0.8936 -- iter: 598/598
--
Training Step: 172  | total loss: [1m[32m0.21353[0m[0m | time: 1.083s
[2K
| Adam | epoch: 010 | loss: 0.21353 - acc: 0.9172 -- iter: 032/598
[A[ATraining Step: 173  | total loss: [1m[32m0.19834[0m[0m | time: 2.092s
[2K
| Adam | epoch: 010 | loss: 0.19834 - acc: 0.9255 -- iter: 064/598
[A[ATraining Step: 174  | total loss: [1m[32m0.19440[0m[0m | time: 2.982s
[2K
| Adam | epoch: 010 | loss: 0.19440 - acc: 0.9298 -- iter: 096/598
[A[ATraining Step: 175  | total loss: [1m[32m0.18225[0m[0m | time: 4.003s
[2K
| Adam | epoch: 010 | loss: 0.18225 - acc: 0.9368 -- iter: 128/598
[A[ATraining Step: 176  | total loss: [1m[32m0.17251[0m[0m | time: 5.035s
[2K
| Adam | epoch: 010 | loss: 0.17251 - acc: 0.9400 -- iter: 160/598
[A[ATraining Step: 177  | total loss: [1m[32m0.18362[0m[0m | time: 6.086s
[2K
| Adam | epoch: 010 | loss: 0.18362 - acc: 0.9366 -- iter: 192/598
[A[ATraining Step: 178  | total loss: [1m[32m0.17344[0m[0m | time: 7.227s
[2K
| Adam | epoch: 010 | loss: 0.17344 - acc: 0.9399 -- iter: 224/598
[A[ATraining Step: 179  | total loss: [1m[32m0.17181[0m[0m | time: 7.975s
[2K
| Adam | epoch: 010 | loss: 0.17181 - acc: 0.9396 -- iter: 256/598
[A[ATraining Step: 180  | total loss: [1m[32m0.15809[0m[0m | time: 8.692s
[2K
| Adam | epoch: 010 | loss: 0.15809 - acc: 0.9457 -- iter: 288/598
[A[ATraining Step: 181  | total loss: [1m[32m0.14520[0m[0m | time: 9.671s
[2K
| Adam | epoch: 010 | loss: 0.14520 - acc: 0.9511 -- iter: 320/598
[A[ATraining Step: 182  | total loss: [1m[32m0.13851[0m[0m | time: 10.505s
[2K
| Adam | epoch: 010 | loss: 0.13851 - acc: 0.9529 -- iter: 352/598
[A[ATraining Step: 183  | total loss: [1m[32m0.13550[0m[0m | time: 11.123s
[2K
| Adam | epoch: 010 | loss: 0.13550 - acc: 0.9513 -- iter: 384/598
[A[ATraining Step: 184  | total loss: [1m[32m0.13365[0m[0m | time: 11.729s
[2K
| Adam | epoch: 010 | loss: 0.13365 - acc: 0.9531 -- iter: 416/598
[A[ATraining Step: 185  | total loss: [1m[32m0.13326[0m[0m | time: 12.360s
[2K
| Adam | epoch: 010 | loss: 0.13326 - acc: 0.9515 -- iter: 448/598
[A[ATraining Step: 186  | total loss: [1m[32m0.14356[0m[0m | time: 12.965s
[2K
| Adam | epoch: 010 | loss: 0.14356 - acc: 0.9501 -- iter: 480/598
[A[ATraining Step: 187  | total loss: [1m[32m0.15907[0m[0m | time: 13.573s
[2K
| Adam | epoch: 010 | loss: 0.15907 - acc: 0.9488 -- iter: 512/598
[A[ATraining Step: 188  | total loss: [1m[32m0.17777[0m[0m | time: 14.214s
[2K
| Adam | epoch: 010 | loss: 0.17777 - acc: 0.9446 -- iter: 544/598
[A[ATraining Step: 189  | total loss: [1m[32m0.17082[0m[0m | time: 14.821s
[2K
| Adam | epoch: 010 | loss: 0.17082 - acc: 0.9470 -- iter: 576/598
[A[ATraining Step: 190  | total loss: [1m[32m0.16002[0m[0m | time: 16.455s
[2K
| Adam | epoch: 010 | loss: 0.16002 - acc: 0.9492 | val_loss: 0.35288 - val_acc: 0.8511 -- iter: 598/598
--
Training Step: 191  | total loss: [1m[32m0.15368[0m[0m | time: 0.616s
[2K
| Adam | epoch: 011 | loss: 0.15368 - acc: 0.9480 -- iter: 032/598
[A[ATraining Step: 192  | total loss: [1m[32m0.14829[0m[0m | time: 1.239s
[2K
| Adam | epoch: 011 | loss: 0.14829 - acc: 0.9532 -- iter: 064/598
[A[ATraining Step: 193  | total loss: [1m[32m0.14028[0m[0m | time: 1.838s
[2K
| Adam | epoch: 011 | loss: 0.14028 - acc: 0.9548 -- iter: 096/598
[A[ATraining Step: 194  | total loss: [1m[32m0.13260[0m[0m | time: 2.451s
[2K
| Adam | epoch: 011 | loss: 0.13260 - acc: 0.9593 -- iter: 128/598
[A[ATraining Step: 195  | total loss: [1m[32m0.12400[0m[0m | time: 3.062s
[2K
| Adam | epoch: 011 | loss: 0.12400 - acc: 0.9634 -- iter: 160/598
[A[ATraining Step: 196  | total loss: [1m[32m0.11377[0m[0m | time: 3.683s
[2K
| Adam | epoch: 011 | loss: 0.11377 - acc: 0.9670 -- iter: 192/598
[A[ATraining Step: 197  | total loss: [1m[32m0.11224[0m[0m | time: 4.283s
[2K
| Adam | epoch: 011 | loss: 0.11224 - acc: 0.9641 -- iter: 224/598
[A[ATraining Step: 198  | total loss: [1m[32m0.10759[0m[0m | time: 4.898s
[2K
| Adam | epoch: 011 | loss: 0.10759 - acc: 0.9645 -- iter: 256/598
[A[ATraining Step: 199  | total loss: [1m[32m0.10198[0m[0m | time: 5.333s
[2K
| Adam | epoch: 011 | loss: 0.10198 - acc: 0.9650 -- iter: 288/598
[A[ATraining Step: 200  | total loss: [1m[32m0.09916[0m[0m | time: 6.775s
[2K
| Adam | epoch: 011 | loss: 0.09916 - acc: 0.9639 | val_loss: 0.27196 - val_acc: 0.9096 -- iter: 320/598
--
Training Step: 201  | total loss: [1m[32m0.09424[0m[0m | time: 7.374s
[2K
| Adam | epoch: 011 | loss: 0.09424 - acc: 0.9675 -- iter: 352/598
[A[ATraining Step: 202  | total loss: [1m[32m0.09278[0m[0m | time: 7.993s
[2K
| Adam | epoch: 011 | loss: 0.09278 - acc: 0.9676 -- iter: 384/598
[A[ATraining Step: 203  | total loss: [1m[32m0.10070[0m[0m | time: 8.604s
[2K
| Adam | epoch: 011 | loss: 0.10070 - acc: 0.9584 -- iter: 416/598
[A[ATraining Step: 204  | total loss: [1m[32m0.09463[0m[0m | time: 9.227s
[2K
| Adam | epoch: 011 | loss: 0.09463 - acc: 0.9625 -- iter: 448/598
[A[ATraining Step: 205  | total loss: [1m[32m0.09785[0m[0m | time: 9.830s
[2K
| Adam | epoch: 011 | loss: 0.09785 - acc: 0.9600 -- iter: 480/598
[A[ATraining Step: 206  | total loss: [1m[32m0.09395[0m[0m | time: 10.428s
[2K
| Adam | epoch: 011 | loss: 0.09395 - acc: 0.9609 -- iter: 512/598
[A[ATraining Step: 207  | total loss: [1m[32m0.08559[0m[0m | time: 11.044s
[2K
| Adam | epoch: 011 | loss: 0.08559 - acc: 0.9648 -- iter: 544/598
[A[ATraining Step: 208  | total loss: [1m[32m0.11700[0m[0m | time: 11.637s
[2K
| Adam | epoch: 011 | loss: 0.11700 - acc: 0.9590 -- iter: 576/598
[A[ATraining Step: 209  | total loss: [1m[32m0.10982[0m[0m | time: 13.276s
[2K
| Adam | epoch: 011 | loss: 0.10982 - acc: 0.9599 | val_loss: 0.34141 - val_acc: 0.8883 -- iter: 598/598
--
Training Step: 210  | total loss: [1m[32m0.10035[0m[0m | time: 1.109s
[2K
| Adam | epoch: 012 | loss: 0.10035 - acc: 0.9639 -- iter: 032/598
[A[ATraining Step: 211  | total loss: [1m[32m0.09652[0m[0m | time: 2.225s
[2K
| Adam | epoch: 012 | loss: 0.09652 - acc: 0.9644 -- iter: 064/598
[A[ATraining Step: 212  | total loss: [1m[32m0.09065[0m[0m | time: 3.415s
[2K
| Adam | epoch: 012 | loss: 0.09065 - acc: 0.9680 -- iter: 096/598
[A[ATraining Step: 213  | total loss: [1m[32m0.08623[0m[0m | time: 4.619s
[2K
| Adam | epoch: 012 | loss: 0.08623 - acc: 0.9712 -- iter: 128/598
[A[ATraining Step: 214  | total loss: [1m[32m0.08162[0m[0m | time: 5.752s
[2K
| Adam | epoch: 012 | loss: 0.08162 - acc: 0.9741 -- iter: 160/598
[A[ATraining Step: 215  | total loss: [1m[32m0.07883[0m[0m | time: 6.934s
[2K
| Adam | epoch: 012 | loss: 0.07883 - acc: 0.9735 -- iter: 192/598
[A[ATraining Step: 216  | total loss: [1m[32m0.07443[0m[0m | time: 8.241s
[2K
| Adam | epoch: 012 | loss: 0.07443 - acc: 0.9762 -- iter: 224/598
[A[ATraining Step: 217  | total loss: [1m[32m0.06825[0m[0m | time: 9.453s
[2K
| Adam | epoch: 012 | loss: 0.06825 - acc: 0.9786 -- iter: 256/598
[A[ATraining Step: 218  | total loss: [1m[32m0.06795[0m[0m | time: 10.818s
[2K
| Adam | epoch: 012 | loss: 0.06795 - acc: 0.9776 -- iter: 288/598
[A[ATraining Step: 219  | total loss: [1m[32m0.06394[0m[0m | time: 11.729s
[2K
| Adam | epoch: 012 | loss: 0.06394 - acc: 0.9798 -- iter: 320/598
[A[ATraining Step: 220  | total loss: [1m[32m0.06517[0m[0m | time: 12.662s
[2K
| Adam | epoch: 012 | loss: 0.06517 - acc: 0.9773 -- iter: 352/598
[A[ATraining Step: 221  | total loss: [1m[32m0.06283[0m[0m | time: 13.863s
[2K
| Adam | epoch: 012 | loss: 0.06283 - acc: 0.9796 -- iter: 384/598
[A[ATraining Step: 222  | total loss: [1m[32m0.05864[0m[0m | time: 14.618s
[2K
| Adam | epoch: 012 | loss: 0.05864 - acc: 0.9816 -- iter: 416/598
[A[ATraining Step: 223  | total loss: [1m[32m0.05570[0m[0m | time: 15.232s
[2K
| Adam | epoch: 012 | loss: 0.05570 - acc: 0.9834 -- iter: 448/598
[A[ATraining Step: 224  | total loss: [1m[32m0.05480[0m[0m | time: 15.844s
[2K
| Adam | epoch: 012 | loss: 0.05480 - acc: 0.9820 -- iter: 480/598
[A[ATraining Step: 225  | total loss: [1m[32m0.05247[0m[0m | time: 16.455s
[2K
| Adam | epoch: 012 | loss: 0.05247 - acc: 0.9838 -- iter: 512/598
[A[ATraining Step: 226  | total loss: [1m[32m0.04883[0m[0m | time: 17.094s
[2K
| Adam | epoch: 012 | loss: 0.04883 - acc: 0.9854 -- iter: 544/598
[A[ATraining Step: 227  | total loss: [1m[32m0.04508[0m[0m | time: 17.714s
[2K
| Adam | epoch: 012 | loss: 0.04508 - acc: 0.9869 -- iter: 576/598
[A[ATraining Step: 228  | total loss: [1m[32m0.04507[0m[0m | time: 19.330s
[2K
| Adam | epoch: 012 | loss: 0.04507 - acc: 0.9851 | val_loss: 0.33071 - val_acc: 0.8989 -- iter: 598/598
--
Training Step: 229  | total loss: [1m[32m0.04223[0m[0m | time: 0.608s
[2K
| Adam | epoch: 013 | loss: 0.04223 - acc: 0.9865 -- iter: 032/598
[A[ATraining Step: 230  | total loss: [1m[32m0.03862[0m[0m | time: 1.204s
[2K
| Adam | epoch: 013 | loss: 0.03862 - acc: 0.9879 -- iter: 064/598
[A[ATraining Step: 231  | total loss: [1m[32m0.05075[0m[0m | time: 1.800s
[2K
| Adam | epoch: 013 | loss: 0.05075 - acc: 0.9860 -- iter: 096/598
[A[ATraining Step: 232  | total loss: [1m[32m0.04642[0m[0m | time: 2.406s
[2K
| Adam | epoch: 013 | loss: 0.04642 - acc: 0.9874 -- iter: 128/598
[A[ATraining Step: 233  | total loss: [1m[32m0.04247[0m[0m | time: 3.009s
[2K
| Adam | epoch: 013 | loss: 0.04247 - acc: 0.9886 -- iter: 160/598
[A[ATraining Step: 234  | total loss: [1m[32m0.04005[0m[0m | time: 3.631s
[2K
| Adam | epoch: 013 | loss: 0.04005 - acc: 0.9898 -- iter: 192/598
[A[ATraining Step: 235  | total loss: [1m[32m0.04222[0m[0m | time: 4.235s
[2K
| Adam | epoch: 013 | loss: 0.04222 - acc: 0.9877 -- iter: 224/598
[A[ATraining Step: 236  | total loss: [1m[32m0.03892[0m[0m | time: 4.836s
[2K
| Adam | epoch: 013 | loss: 0.03892 - acc: 0.9889 -- iter: 256/598
[A[ATraining Step: 237  | total loss: [1m[32m0.04118[0m[0m | time: 5.440s
[2K
| Adam | epoch: 013 | loss: 0.04118 - acc: 0.9900 -- iter: 288/598
[A[ATraining Step: 238  | total loss: [1m[32m0.03815[0m[0m | time: 6.052s
[2K
| Adam | epoch: 013 | loss: 0.03815 - acc: 0.9910 -- iter: 320/598
[A[ATraining Step: 239  | total loss: [1m[32m0.04194[0m[0m | time: 6.496s
[2K
| Adam | epoch: 013 | loss: 0.04194 - acc: 0.9888 -- iter: 352/598
[A[ATraining Step: 240  | total loss: [1m[32m0.05312[0m[0m | time: 6.917s
[2K
| Adam | epoch: 013 | loss: 0.05312 - acc: 0.9854 -- iter: 384/598
[A[ATraining Step: 241  | total loss: [1m[32m0.06280[0m[0m | time: 7.518s
[2K
| Adam | epoch: 013 | loss: 0.06280 - acc: 0.9777 -- iter: 416/598
[A[ATraining Step: 242  | total loss: [1m[32m0.06062[0m[0m | time: 8.127s
[2K
| Adam | epoch: 013 | loss: 0.06062 - acc: 0.9800 -- iter: 448/598
[A[ATraining Step: 243  | total loss: [1m[32m0.05775[0m[0m | time: 8.741s
[2K
| Adam | epoch: 013 | loss: 0.05775 - acc: 0.9820 -- iter: 480/598
[A[ATraining Step: 244  | total loss: [1m[32m0.05285[0m[0m | time: 9.359s
[2K
| Adam | epoch: 013 | loss: 0.05285 - acc: 0.9838 -- iter: 512/598
[A[ATraining Step: 245  | total loss: [1m[32m0.06307[0m[0m | time: 9.978s
[2K
| Adam | epoch: 013 | loss: 0.06307 - acc: 0.9760 -- iter: 544/598
[A[ATraining Step: 246  | total loss: [1m[32m0.06668[0m[0m | time: 10.576s
[2K
| Adam | epoch: 013 | loss: 0.06668 - acc: 0.9753 -- iter: 576/598
[A[ATraining Step: 247  | total loss: [1m[32m0.06119[0m[0m | time: 12.185s
[2K
| Adam | epoch: 013 | loss: 0.06119 - acc: 0.9778 | val_loss: 0.43555 - val_acc: 0.8777 -- iter: 598/598
--
Training Step: 248  | total loss: [1m[32m0.06010[0m[0m | time: 0.619s
[2K
| Adam | epoch: 014 | loss: 0.06010 - acc: 0.9769 -- iter: 032/598
[A[ATraining Step: 249  | total loss: [1m[32m0.05859[0m[0m | time: 1.221s
[2K
| Adam | epoch: 014 | loss: 0.05859 - acc: 0.9792 -- iter: 064/598
[A[ATraining Step: 250  | total loss: [1m[32m0.05533[0m[0m | time: 1.834s
[2K
| Adam | epoch: 014 | loss: 0.05533 - acc: 0.9813 -- iter: 096/598
[A[ATraining Step: 251  | total loss: [1m[32m0.05024[0m[0m | time: 2.439s
[2K
| Adam | epoch: 014 | loss: 0.05024 - acc: 0.9831 -- iter: 128/598
[A[ATraining Step: 252  | total loss: [1m[32m0.04663[0m[0m | time: 3.056s
[2K
| Adam | epoch: 014 | loss: 0.04663 - acc: 0.9848 -- iter: 160/598
[A[ATraining Step: 253  | total loss: [1m[32m0.05395[0m[0m | time: 3.678s
[2K
| Adam | epoch: 014 | loss: 0.05395 - acc: 0.9770 -- iter: 192/598
[A[ATraining Step: 254  | total loss: [1m[32m0.06767[0m[0m | time: 4.286s
[2K
| Adam | epoch: 014 | loss: 0.06767 - acc: 0.9699 -- iter: 224/598
[A[ATraining Step: 255  | total loss: [1m[32m0.06293[0m[0m | time: 4.921s
[2K
| Adam | epoch: 014 | loss: 0.06293 - acc: 0.9729 -- iter: 256/598
[A[ATraining Step: 256  | total loss: [1m[32m0.06040[0m[0m | time: 5.526s
[2K
| Adam | epoch: 014 | loss: 0.06040 - acc: 0.9725 -- iter: 288/598
[A[ATraining Step: 257  | total loss: [1m[32m0.06607[0m[0m | time: 6.127s
[2K
| Adam | epoch: 014 | loss: 0.06607 - acc: 0.9690 -- iter: 320/598
[A[ATraining Step: 258  | total loss: [1m[32m0.06356[0m[0m | time: 6.740s
[2K
| Adam | epoch: 014 | loss: 0.06356 - acc: 0.9690 -- iter: 352/598
[A[ATraining Step: 259  | total loss: [1m[32m0.05746[0m[0m | time: 7.180s
[2K
| Adam | epoch: 014 | loss: 0.05746 - acc: 0.9721 -- iter: 384/598
[A[ATraining Step: 260  | total loss: [1m[32m0.05215[0m[0m | time: 7.604s
[2K
| Adam | epoch: 014 | loss: 0.05215 - acc: 0.9749 -- iter: 416/598
[A[ATraining Step: 261  | total loss: [1m[32m0.04789[0m[0m | time: 8.213s
[2K
| Adam | epoch: 014 | loss: 0.04789 - acc: 0.9774 -- iter: 448/598
[A[ATraining Step: 262  | total loss: [1m[32m0.05981[0m[0m | time: 8.846s
[2K
| Adam | epoch: 014 | loss: 0.05981 - acc: 0.9734 -- iter: 480/598
[A[ATraining Step: 263  | total loss: [1m[32m0.05601[0m[0m | time: 9.456s
[2K
| Adam | epoch: 014 | loss: 0.05601 - acc: 0.9760 -- iter: 512/598
[A[ATraining Step: 264  | total loss: [1m[32m0.05238[0m[0m | time: 10.047s
[2K
| Adam | epoch: 014 | loss: 0.05238 - acc: 0.9784 -- iter: 544/598
[A[ATraining Step: 265  | total loss: [1m[32m0.04759[0m[0m | time: 10.635s
[2K
| Adam | epoch: 014 | loss: 0.04759 - acc: 0.9806 -- iter: 576/598
[A[ATraining Step: 266  | total loss: [1m[32m0.05901[0m[0m | time: 12.224s
[2K
| Adam | epoch: 014 | loss: 0.05901 - acc: 0.9763 | val_loss: 0.36238 - val_acc: 0.8830 -- iter: 598/598
--
Training Step: 267  | total loss: [1m[32m0.05729[0m[0m | time: 0.602s
[2K
| Adam | epoch: 015 | loss: 0.05729 - acc: 0.9787 -- iter: 032/598
[A[ATraining Step: 268  | total loss: [1m[32m0.10237[0m[0m | time: 1.204s
[2K
| Adam | epoch: 015 | loss: 0.10237 - acc: 0.9745 -- iter: 064/598
[A[ATraining Step: 269  | total loss: [1m[32m0.09291[0m[0m | time: 1.817s
[2K
| Adam | epoch: 015 | loss: 0.09291 - acc: 0.9771 -- iter: 096/598
[A[ATraining Step: 270  | total loss: [1m[32m0.08400[0m[0m | time: 2.430s
[2K
| Adam | epoch: 015 | loss: 0.08400 - acc: 0.9794 -- iter: 128/598
[A[ATraining Step: 271  | total loss: [1m[32m0.07715[0m[0m | time: 3.030s
[2K
| Adam | epoch: 015 | loss: 0.07715 - acc: 0.9814 -- iter: 160/598
[A[ATraining Step: 272  | total loss: [1m[32m0.08415[0m[0m | time: 3.631s
[2K
| Adam | epoch: 015 | loss: 0.08415 - acc: 0.9770 -- iter: 192/598
[A[ATraining Step: 273  | total loss: [1m[32m0.07859[0m[0m | time: 4.243s
[2K
| Adam | epoch: 015 | loss: 0.07859 - acc: 0.9793 -- iter: 224/598
[A[ATraining Step: 274  | total loss: [1m[32m0.07156[0m[0m | time: 4.850s
[2K
| Adam | epoch: 015 | loss: 0.07156 - acc: 0.9814 -- iter: 256/598
[A[ATraining Step: 275  | total loss: [1m[32m0.06603[0m[0m | time: 5.442s
[2K
| Adam | epoch: 015 | loss: 0.06603 - acc: 0.9833 -- iter: 288/598
[A[ATraining Step: 276  | total loss: [1m[32m0.06134[0m[0m | time: 6.039s
[2K
| Adam | epoch: 015 | loss: 0.06134 - acc: 0.9849 -- iter: 320/598
[A[ATraining Step: 277  | total loss: [1m[32m0.06251[0m[0m | time: 6.642s
[2K
| Adam | epoch: 015 | loss: 0.06251 - acc: 0.9833 -- iter: 352/598
[A[ATraining Step: 278  | total loss: [1m[32m0.05898[0m[0m | time: 7.250s
[2K
| Adam | epoch: 015 | loss: 0.05898 - acc: 0.9850 -- iter: 384/598
[A[ATraining Step: 279  | total loss: [1m[32m0.05435[0m[0m | time: 7.664s
[2K
| Adam | epoch: 015 | loss: 0.05435 - acc: 0.9865 -- iter: 416/598
[A[ATraining Step: 280  | total loss: [1m[32m0.04999[0m[0m | time: 8.087s
[2K
| Adam | epoch: 015 | loss: 0.04999 - acc: 0.9878 -- iter: 448/598
[A[ATraining Step: 281  | total loss: [1m[32m0.04693[0m[0m | time: 8.714s
[2K
| Adam | epoch: 015 | loss: 0.04693 - acc: 0.9891 -- iter: 480/598
[A[ATraining Step: 282  | total loss: [1m[32m0.04508[0m[0m | time: 9.317s
[2K
| Adam | epoch: 015 | loss: 0.04508 - acc: 0.9902 -- iter: 512/598
[A[ATraining Step: 283  | total loss: [1m[32m0.04411[0m[0m | time: 9.922s
[2K
| Adam | epoch: 015 | loss: 0.04411 - acc: 0.9911 -- iter: 544/598
[A[ATraining Step: 284  | total loss: [1m[32m0.04195[0m[0m | time: 10.519s
[2K
| Adam | epoch: 015 | loss: 0.04195 - acc: 0.9920 -- iter: 576/598
[A[ATraining Step: 285  | total loss: [1m[32m0.03829[0m[0m | time: 12.136s
[2K
| Adam | epoch: 015 | loss: 0.03829 - acc: 0.9928 | val_loss: 0.42052 - val_acc: 0.8777 -- iter: 598/598
--
Validation AUC:0.9571428571428571
Validation AUPRC:0.9599164530050424
Test AUC:0.9734012450481041
Test AUPRC:0.967455012505811
BestTestF1Score	0.93	0.85	0.93	0.89	0.97	90	11	84	3	0.88
BestTestMCCScore	0.93	0.85	0.93	0.89	0.97	90	11	84	3	0.88
BestTestAccuracyScore	0.93	0.86	0.93	0.9	0.97	90	10	85	3	0.95
BestValidationF1Score	0.93	0.84	0.92	0.9	0.95	93	10	80	5	0.88
BestValidationMCC	0.93	0.84	0.92	0.9	0.95	93	10	80	5	0.88
BestValidationAccuracy	0.92	0.84	0.92	0.91	0.94	92	9	81	6	0.95
TestPredictions (Threshold:0.88)
CHEMBL379083,TP,ACT,1.0	CHEMBL322547,TN,INACT,0.0	CHEMBL542472,TP,ACT,1.0	CHEMBL113472,TN,INACT,0.0	CHEMBL110053,TN,INACT,0.0	CHEMBL114478,TN,INACT,0.03999999910593033	CHEMBL132860,TP,ACT,1.0	CHEMBL545255,TP,ACT,1.0	CHEMBL559825,TP,ACT,0.9900000095367432	CHEMBL220591,TP,ACT,1.0	CHEMBL140984,TN,INACT,0.0	CHEMBL131263,TP,ACT,1.0	CHEMBL413040,FP,INACT,1.0	CHEMBL310361,TN,INACT,0.009999999776482582	CHEMBL245319,TN,INACT,0.009999999776482582	CHEMBL104223,TN,INACT,0.009999999776482582	CHEMBL295005,TP,ACT,1.0	CHEMBL450729,TN,INACT,0.009999999776482582	CHEMBL544134,TP,ACT,1.0	CHEMBL537683,TP,ACT,1.0	CHEMBL78137,TN,INACT,0.0	CHEMBL251541,TN,INACT,0.3199999928474426	CHEMBL9746,TN,INACT,0.05999999865889549	CHEMBL290431,TP,ACT,1.0	CHEMBL2392354,TP,ACT,1.0	CHEMBL72738,FP,INACT,0.9900000095367432	CHEMBL310425,TN,INACT,0.09000000357627869	CHEMBL209038,TP,ACT,1.0	CHEMBL538784,TP,ACT,1.0	CHEMBL240875,TP,ACT,1.0	CHEMBL284727,TP,ACT,1.0	CHEMBL542096,TP,ACT,1.0	CHEMBL130782,TP,ACT,1.0	CHEMBL158078,TN,INACT,0.0	CHEMBL296245,TN,INACT,0.0	CHEMBL563516,TP,ACT,1.0	CHEMBL78601,TN,INACT,0.0	CHEMBL555493,FN,ACT,0.7900000214576721	CHEMBL303538,TN,INACT,0.0	CHEMBL142015,TP,ACT,1.0	CHEMBL169553,TN,INACT,0.05999999865889549	CHEMBL355851,TN,INACT,0.0	CHEMBL539629,TP,ACT,0.9900000095367432	CHEMBL296865,TP,ACT,1.0	CHEMBL3142391,TP,ACT,0.9900000095367432	CHEMBL303258,TP,ACT,1.0	CHEMBL151619,TN,INACT,0.5699999928474426	CHEMBL1956876,TP,ACT,1.0	CHEMBL594376,TN,INACT,0.05000000074505806	CHEMBL99331,TN,INACT,0.009999999776482582	CHEMBL42359,TN,INACT,0.009999999776482582	CHEMBL3143949,TP,ACT,1.0	CHEMBL329861,TN,INACT,0.019999999552965164	CHEMBL1983100,TN,INACT,0.05000000074505806	CHEMBL432334,TN,INACT,0.019999999552965164	CHEMBL537834,FP,INACT,0.9900000095367432	CHEMBL1765667,FP,INACT,0.9900000095367432	CHEMBL89445,TN,INACT,0.0	CHEMBL267094,TN,INACT,0.0	CHEMBL386697,TP,ACT,0.9900000095367432	CHEMBL21311,TP,ACT,1.0	CHEMBL342195,TP,ACT,1.0	CHEMBL209346,TP,ACT,1.0	CHEMBL308243,TN,INACT,0.18000000715255737	CHEMBL282426,TN,INACT,0.019999999552965164	CHEMBL172788,TN,INACT,0.03999999910593033	CHEMBL218152,FP,INACT,0.9399999976158142	CHEMBL543898,TP,ACT,1.0	CHEMBL3215972,TP,ACT,0.9900000095367432	CHEMBL444322,TP,ACT,1.0	CHEMBL220596,TP,ACT,1.0	CHEMBL284726,FN,ACT,0.05999999865889549	CHEMBL559436,TP,ACT,0.9900000095367432	CHEMBL80807,TN,INACT,0.03999999910593033	CHEMBL292181,TP,ACT,1.0	CHEMBL2105864,TP,ACT,1.0	CHEMBL77962,TN,INACT,0.019999999552965164	CHEMBL1765671,TN,INACT,0.8100000023841858	CHEMBL408846,TP,ACT,1.0	CHEMBL387452,TP,ACT,1.0	CHEMBL303204,FP,INACT,1.0	CHEMBL156814,TN,INACT,0.6700000166893005	CHEMBL130438,TP,ACT,1.0	CHEMBL3038095,TP,ACT,1.0	CHEMBL21509,TN,INACT,0.3499999940395355	CHEMBL3216408,TP,ACT,1.0	CHEMBL72710,TN,INACT,0.0	CHEMBL422701,TN,INACT,0.3199999928474426	CHEMBL264751,TP,ACT,1.0	CHEMBL27702,TP,ACT,1.0	CHEMBL537927,TP,ACT,1.0	CHEMBL540895,TP,ACT,0.9900000095367432	CHEMBL3780633,TN,INACT,0.14000000059604645	CHEMBL2398752,TN,INACT,0.4300000071525574	CHEMBL563861,TP,ACT,1.0	CHEMBL2112592,TN,INACT,0.009999999776482582	CHEMBL82249,TN,INACT,0.7099999785423279	CHEMBL1956853,TP,ACT,1.0	CHEMBL404557,TN,INACT,0.03999999910593033	CHEMBL539792,TP,ACT,1.0	CHEMBL74066,TN,INACT,0.0	CHEMBL555465,TP,ACT,1.0	CHEMBL55632,TP,ACT,1.0	CHEMBL515170,TN,INACT,0.0	CHEMBL332405,TN,INACT,0.47999998927116394	CHEMBL444128,FP,INACT,0.9599999785423279	CHEMBL3774617,TP,ACT,1.0	CHEMBL323421,TP,ACT,0.9599999785423279	CHEMBL241279,TN,INACT,0.0	CHEMBL3323005,TN,INACT,0.05000000074505806	CHEMBL104,TN,INACT,0.009999999776482582	CHEMBL329701,TP,ACT,0.9900000095367432	CHEMBL80532,TN,INACT,0.10000000149011612	CHEMBL461502,TN,INACT,0.009999999776482582	CHEMBL2370509,TN,INACT,0.49000000953674316	CHEMBL311781,TN,INACT,0.0	CHEMBL221691,TN,INACT,0.3700000047683716	CHEMBL72841,TN,INACT,0.0	CHEMBL541758,TP,ACT,1.0	CHEMBL3215541,TP,ACT,0.9900000095367432	CHEMBL45875,TN,INACT,0.009999999776482582	CHEMBL538531,TP,ACT,1.0	CHEMBL218749,TP,ACT,1.0	CHEMBL540896,FP,INACT,0.9800000190734863	CHEMBL553762,TP,ACT,0.9900000095367432	CHEMBL246585,TN,INACT,0.1899999976158142	CHEMBL3216859,TP,ACT,0.9900000095367432	CHEMBL312266,TN,INACT,0.009999999776482582	CHEMBL312567,TN,INACT,0.0	CHEMBL3038105,TP,ACT,0.9800000190734863	CHEMBL375576,TP,ACT,1.0	CHEMBL383989,TP,ACT,0.9900000095367432	CHEMBL80438,TN,INACT,0.009999999776482582	CHEMBL207692,TP,ACT,1.0	CHEMBL3218122,TN,INACT,0.4000000059604645	CHEMBL3215979,TP,ACT,1.0	CHEMBL296291,TN,INACT,0.019999999552965164	CHEMBL342256,TN,INACT,0.03999999910593033	CHEMBL564341,TP,ACT,1.0	CHEMBL63937,TN,INACT,0.009999999776482582	CHEMBL123124,FN,ACT,0.7699999809265137	CHEMBL143697,TP,ACT,1.0	CHEMBL1916635,FP,INACT,1.0	CHEMBL554254,TP,ACT,1.0	CHEMBL330885,TN,INACT,0.14000000059604645	CHEMBL1956862,TP,ACT,0.9900000095367432	CHEMBL10211,TN,INACT,0.0	CHEMBL228144,TN,INACT,0.07999999821186066	CHEMBL97393,TP,ACT,1.0	CHEMBL62703,TN,INACT,0.15000000596046448	CHEMBL558279,TP,ACT,1.0	CHEMBL446693,TN,INACT,0.25999999046325684	CHEMBL168223,TN,INACT,0.0	CHEMBL218540,TP,ACT,1.0	CHEMBL141354,TN,INACT,0.0	CHEMBL544599,TP,ACT,1.0	CHEMBL26847,TP,ACT,1.0	CHEMBL428148,TP,ACT,1.0	CHEMBL539924,TP,ACT,0.9800000190734863	CHEMBL220693,TP,ACT,1.0	CHEMBL352925,TN,INACT,0.019999999552965164	CHEMBL1956855,TP,ACT,1.0	CHEMBL2112221,TP,ACT,1.0	CHEMBL142295,TN,INACT,0.009999999776482582	CHEMBL297215,TN,INACT,0.019999999552965164	CHEMBL141365,TN,INACT,0.0	CHEMBL538865,TP,ACT,1.0	CHEMBL540640,TP,ACT,1.0	CHEMBL21937,TN,INACT,0.009999999776482582	CHEMBL299538,TN,INACT,0.0	CHEMBL460470,TN,INACT,0.009999999776482582	CHEMBL2373213,TN,INACT,0.6800000071525574	CHEMBL298320,TP,ACT,1.0	CHEMBL293874,FP,INACT,1.0	CHEMBL80180,TN,INACT,0.0	CHEMBL322537,TN,INACT,0.0	CHEMBL417719,TN,INACT,0.5699999928474426	CHEMBL1956869,TP,ACT,1.0	CHEMBL543685,TP,ACT,1.0	CHEMBL544549,TP,ACT,1.0	CHEMBL1907839,TN,INACT,0.0	CHEMBL106163,TN,INACT,0.5799999833106995	CHEMBL545021,TP,ACT,0.9900000095367432	CHEMBL542173,TP,ACT,1.0	CHEMBL221285,TP,ACT,1.0	CHEMBL41446,TP,ACT,1.0	CHEMBL403029,FP,INACT,0.9800000190734863	CHEMBL423482,TP,ACT,1.0	

