CNNModel CHEMBL3942 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	161
Number of inactive compounds :	161
---------------------------------
Run id: CNNModel_CHEMBL3942_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3942_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 184
Validation samples: 58
--
Training Step: 1  | time: 0.772s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/184
[A[ATraining Step: 2  | total loss: [1m[32m0.62380[0m[0m | time: 1.378s
[2K
| Adam | epoch: 001 | loss: 0.62380 - acc: 0.4500 -- iter: 064/184
[A[ATraining Step: 3  | total loss: [1m[32m0.67674[0m[0m | time: 1.987s
[2K
| Adam | epoch: 001 | loss: 0.67674 - acc: 0.6187 -- iter: 096/184
[A[ATraining Step: 4  | total loss: [1m[32m0.68978[0m[0m | time: 2.797s
[2K
| Adam | epoch: 001 | loss: 0.68978 - acc: 0.5297 -- iter: 128/184
[A[ATraining Step: 5  | total loss: [1m[32m0.69199[0m[0m | time: 3.411s
[2K
| Adam | epoch: 001 | loss: 0.69199 - acc: 0.5091 -- iter: 160/184
[A[ATraining Step: 6  | total loss: [1m[32m0.69662[0m[0m | time: 4.915s
[2K
| Adam | epoch: 001 | loss: 0.69662 - acc: 0.4832 | val_loss: 0.69644 - val_acc: 0.4828 -- iter: 184/184
--
Training Step: 7  | total loss: [1m[32m0.68583[0m[0m | time: 0.467s
[2K
| Adam | epoch: 002 | loss: 0.68583 - acc: 0.5683 -- iter: 032/184
[A[ATraining Step: 8  | total loss: [1m[32m0.68053[0m[0m | time: 1.115s
[2K
| Adam | epoch: 002 | loss: 0.68053 - acc: 0.6002 -- iter: 064/184
[A[ATraining Step: 9  | total loss: [1m[32m0.68446[0m[0m | time: 1.761s
[2K
| Adam | epoch: 002 | loss: 0.68446 - acc: 0.5637 -- iter: 096/184
[A[ATraining Step: 10  | total loss: [1m[32m0.69746[0m[0m | time: 2.383s
[2K
| Adam | epoch: 002 | loss: 0.69746 - acc: 0.5162 -- iter: 128/184
[A[ATraining Step: 11  | total loss: [1m[32m0.68617[0m[0m | time: 3.009s
[2K
| Adam | epoch: 002 | loss: 0.68617 - acc: 0.5529 -- iter: 160/184
[A[ATraining Step: 12  | total loss: [1m[32m0.70187[0m[0m | time: 4.650s
[2K
| Adam | epoch: 002 | loss: 0.70187 - acc: 0.4869 | val_loss: 0.69599 - val_acc: 0.4828 -- iter: 184/184
--
Training Step: 13  | total loss: [1m[32m0.69332[0m[0m | time: 0.504s
[2K
| Adam | epoch: 003 | loss: 0.69332 - acc: 0.5193 -- iter: 032/184
[A[ATraining Step: 14  | total loss: [1m[32m0.68138[0m[0m | time: 0.961s
[2K
| Adam | epoch: 003 | loss: 0.68138 - acc: 0.5796 -- iter: 064/184
[A[ATraining Step: 15  | total loss: [1m[32m0.67483[0m[0m | time: 1.570s
[2K
| Adam | epoch: 003 | loss: 0.67483 - acc: 0.6137 -- iter: 096/184
[A[ATraining Step: 16  | total loss: [1m[32m0.67456[0m[0m | time: 2.187s
[2K
| Adam | epoch: 003 | loss: 0.67456 - acc: 0.6062 -- iter: 128/184
[A[ATraining Step: 17  | total loss: [1m[32m0.67686[0m[0m | time: 2.819s
[2K
| Adam | epoch: 003 | loss: 0.67686 - acc: 0.5905 -- iter: 160/184
[A[ATraining Step: 18  | total loss: [1m[32m0.68079[0m[0m | time: 4.441s
[2K
| Adam | epoch: 003 | loss: 0.68079 - acc: 0.5700 | val_loss: 0.71048 - val_acc: 0.4828 -- iter: 184/184
--
Training Step: 19  | total loss: [1m[32m0.68055[0m[0m | time: 0.603s
[2K
| Adam | epoch: 004 | loss: 0.68055 - acc: 0.5675 -- iter: 032/184
[A[ATraining Step: 20  | total loss: [1m[32m0.69399[0m[0m | time: 1.056s
[2K
| Adam | epoch: 004 | loss: 0.69399 - acc: 0.5257 -- iter: 064/184
[A[ATraining Step: 21  | total loss: [1m[32m0.67739[0m[0m | time: 1.531s
[2K
| Adam | epoch: 004 | loss: 0.67739 - acc: 0.5694 -- iter: 096/184
[A[ATraining Step: 22  | total loss: [1m[32m0.66650[0m[0m | time: 2.132s
[2K
| Adam | epoch: 004 | loss: 0.66650 - acc: 0.5986 -- iter: 128/184
[A[ATraining Step: 23  | total loss: [1m[32m0.67276[0m[0m | time: 2.717s
[2K
| Adam | epoch: 004 | loss: 0.67276 - acc: 0.5791 -- iter: 160/184
[A[ATraining Step: 24  | total loss: [1m[32m0.67018[0m[0m | time: 4.347s
[2K
| Adam | epoch: 004 | loss: 0.67018 - acc: 0.5832 | val_loss: 0.70852 - val_acc: 0.4828 -- iter: 184/184
--
Training Step: 25  | total loss: [1m[32m0.66965[0m[0m | time: 0.606s
[2K
| Adam | epoch: 005 | loss: 0.66965 - acc: 0.5775 -- iter: 032/184
[A[ATraining Step: 26  | total loss: [1m[32m0.66612[0m[0m | time: 1.209s
[2K
| Adam | epoch: 005 | loss: 0.66612 - acc: 0.5818 -- iter: 064/184
[A[ATraining Step: 27  | total loss: [1m[32m0.67566[0m[0m | time: 1.665s
[2K
| Adam | epoch: 005 | loss: 0.67566 - acc: 0.5608 -- iter: 096/184
[A[ATraining Step: 28  | total loss: [1m[32m0.67732[0m[0m | time: 2.118s
[2K
| Adam | epoch: 005 | loss: 0.67732 - acc: 0.5560 -- iter: 128/184
[A[ATraining Step: 29  | total loss: [1m[32m0.67650[0m[0m | time: 2.714s
[2K
| Adam | epoch: 005 | loss: 0.67650 - acc: 0.5525 -- iter: 160/184
[A[ATraining Step: 30  | total loss: [1m[32m0.68073[0m[0m | time: 4.322s
[2K
| Adam | epoch: 005 | loss: 0.68073 - acc: 0.5327 | val_loss: 0.68444 - val_acc: 0.4828 -- iter: 184/184
--
Training Step: 31  | total loss: [1m[32m0.68784[0m[0m | time: 0.606s
[2K
| Adam | epoch: 006 | loss: 0.68784 - acc: 0.4963 -- iter: 032/184
[A[ATraining Step: 32  | total loss: [1m[32m0.68250[0m[0m | time: 1.204s
[2K
| Adam | epoch: 006 | loss: 0.68250 - acc: 0.5323 -- iter: 064/184
[A[ATraining Step: 33  | total loss: [1m[32m0.68169[0m[0m | time: 1.805s
[2K
| Adam | epoch: 006 | loss: 0.68169 - acc: 0.5321 -- iter: 096/184
[A[ATraining Step: 34  | total loss: [1m[32m0.68007[0m[0m | time: 2.274s
[2K
| Adam | epoch: 006 | loss: 0.68007 - acc: 0.5386 -- iter: 128/184
[A[ATraining Step: 35  | total loss: [1m[32m0.67634[0m[0m | time: 2.762s
[2K
| Adam | epoch: 006 | loss: 0.67634 - acc: 0.5654 -- iter: 160/184
[A[ATraining Step: 36  | total loss: [1m[32m0.67106[0m[0m | time: 4.370s
[2K
| Adam | epoch: 006 | loss: 0.67106 - acc: 0.5861 | val_loss: 0.68101 - val_acc: 0.4828 -- iter: 184/184
--
Training Step: 37  | total loss: [1m[32m0.67169[0m[0m | time: 0.623s
[2K
| Adam | epoch: 007 | loss: 0.67169 - acc: 0.5689 -- iter: 032/184
[A[ATraining Step: 38  | total loss: [1m[32m0.67424[0m[0m | time: 1.222s
[2K
| Adam | epoch: 007 | loss: 0.67424 - acc: 0.5493 -- iter: 064/184
[A[ATraining Step: 39  | total loss: [1m[32m0.66648[0m[0m | time: 1.837s
[2K
| Adam | epoch: 007 | loss: 0.66648 - acc: 0.5578 -- iter: 096/184
[A[ATraining Step: 40  | total loss: [1m[32m0.66676[0m[0m | time: 2.442s
[2K
| Adam | epoch: 007 | loss: 0.66676 - acc: 0.5528 -- iter: 128/184
[A[ATraining Step: 41  | total loss: [1m[32m0.67456[0m[0m | time: 2.898s
[2K
| Adam | epoch: 007 | loss: 0.67456 - acc: 0.5374 -- iter: 160/184
[A[ATraining Step: 42  | total loss: [1m[32m0.67288[0m[0m | time: 4.378s
[2K
| Adam | epoch: 007 | loss: 0.67288 - acc: 0.5307 | val_loss: 0.65937 - val_acc: 0.4828 -- iter: 184/184
--
Training Step: 43  | total loss: [1m[32m0.66967[0m[0m | time: 0.629s
[2K
| Adam | epoch: 008 | loss: 0.66967 - acc: 0.5252 -- iter: 032/184
[A[ATraining Step: 44  | total loss: [1m[32m0.65830[0m[0m | time: 1.251s
[2K
| Adam | epoch: 008 | loss: 0.65830 - acc: 0.5533 -- iter: 064/184
[A[ATraining Step: 45  | total loss: [1m[32m0.65726[0m[0m | time: 1.861s
[2K
| Adam | epoch: 008 | loss: 0.65726 - acc: 0.5549 -- iter: 096/184
[A[ATraining Step: 46  | total loss: [1m[32m0.65226[0m[0m | time: 2.468s
[2K
| Adam | epoch: 008 | loss: 0.65226 - acc: 0.5509 -- iter: 128/184
[A[ATraining Step: 47  | total loss: [1m[32m0.65329[0m[0m | time: 3.089s
[2K
| Adam | epoch: 008 | loss: 0.65329 - acc: 0.5375 -- iter: 160/184
[A[ATraining Step: 48  | total loss: [1m[32m0.64596[0m[0m | time: 4.583s
[2K
| Adam | epoch: 008 | loss: 0.64596 - acc: 0.5415 | val_loss: 0.61884 - val_acc: 0.5000 -- iter: 184/184
--
Training Step: 49  | total loss: [1m[32m0.63843[0m[0m | time: 0.462s
[2K
| Adam | epoch: 009 | loss: 0.63843 - acc: 0.5350 -- iter: 032/184
[A[ATraining Step: 50  | total loss: [1m[32m0.62883[0m[0m | time: 1.062s
[2K
| Adam | epoch: 009 | loss: 0.62883 - acc: 0.5360 -- iter: 064/184
[A[ATraining Step: 51  | total loss: [1m[32m0.61313[0m[0m | time: 1.672s
[2K
| Adam | epoch: 009 | loss: 0.61313 - acc: 0.5543 -- iter: 096/184
[A[ATraining Step: 52  | total loss: [1m[32m0.61928[0m[0m | time: 2.282s
[2K
| Adam | epoch: 009 | loss: 0.61928 - acc: 0.5462 -- iter: 128/184
[A[ATraining Step: 53  | total loss: [1m[32m0.59678[0m[0m | time: 2.885s
[2K
| Adam | epoch: 009 | loss: 0.59678 - acc: 0.5947 -- iter: 160/184
[A[ATraining Step: 54  | total loss: [1m[32m0.58908[0m[0m | time: 4.502s
[2K
| Adam | epoch: 009 | loss: 0.58908 - acc: 0.6218 | val_loss: 0.57098 - val_acc: 0.6379 -- iter: 184/184
--
Training Step: 55  | total loss: [1m[32m0.57373[0m[0m | time: 0.466s
[2K
| Adam | epoch: 010 | loss: 0.57373 - acc: 0.6401 -- iter: 032/184
[A[ATraining Step: 56  | total loss: [1m[32m0.58527[0m[0m | time: 0.932s
[2K
| Adam | epoch: 010 | loss: 0.58527 - acc: 0.6497 -- iter: 064/184
[A[ATraining Step: 57  | total loss: [1m[32m0.58725[0m[0m | time: 1.535s
[2K
| Adam | epoch: 010 | loss: 0.58725 - acc: 0.6578 -- iter: 096/184
[A[ATraining Step: 58  | total loss: [1m[32m0.58585[0m[0m | time: 2.134s
[2K
| Adam | epoch: 010 | loss: 0.58585 - acc: 0.6874 -- iter: 128/184
[A[ATraining Step: 59  | total loss: [1m[32m0.58190[0m[0m | time: 2.734s
[2K
| Adam | epoch: 010 | loss: 0.58190 - acc: 0.7084 -- iter: 160/184
[A[ATraining Step: 60  | total loss: [1m[32m0.56928[0m[0m | time: 4.334s
[2K
| Adam | epoch: 010 | loss: 0.56928 - acc: 0.7346 | val_loss: 0.63548 - val_acc: 0.6379 -- iter: 184/184
--
Training Step: 61  | total loss: [1m[32m0.55647[0m[0m | time: 0.622s
[2K
| Adam | epoch: 011 | loss: 0.55647 - acc: 0.7448 -- iter: 032/184
[A[ATraining Step: 62  | total loss: [1m[32m0.56396[0m[0m | time: 1.081s
[2K
| Adam | epoch: 011 | loss: 0.56396 - acc: 0.7374 -- iter: 064/184
[A[ATraining Step: 63  | total loss: [1m[32m0.53287[0m[0m | time: 1.536s
[2K
| Adam | epoch: 011 | loss: 0.53287 - acc: 0.7707 -- iter: 096/184
[A[ATraining Step: 64  | total loss: [1m[32m0.50879[0m[0m | time: 2.144s
[2K
| Adam | epoch: 011 | loss: 0.50879 - acc: 0.7941 -- iter: 128/184
[A[ATraining Step: 65  | total loss: [1m[32m0.49762[0m[0m | time: 2.772s
[2K
| Adam | epoch: 011 | loss: 0.49762 - acc: 0.8003 -- iter: 160/184
[A[ATraining Step: 66  | total loss: [1m[32m0.49440[0m[0m | time: 4.398s
[2K
| Adam | epoch: 011 | loss: 0.49440 - acc: 0.8094 | val_loss: 0.39290 - val_acc: 0.8793 -- iter: 184/184
--
Training Step: 67  | total loss: [1m[32m0.46748[0m[0m | time: 0.643s
[2K
| Adam | epoch: 012 | loss: 0.46748 - acc: 0.8322 -- iter: 032/184
[A[ATraining Step: 68  | total loss: [1m[32m0.45492[0m[0m | time: 1.251s
[2K
| Adam | epoch: 012 | loss: 0.45492 - acc: 0.8410 -- iter: 064/184
[A[ATraining Step: 69  | total loss: [1m[32m0.44819[0m[0m | time: 1.718s
[2K
| Adam | epoch: 012 | loss: 0.44819 - acc: 0.8340 -- iter: 096/184
[A[ATraining Step: 70  | total loss: [1m[32m0.44651[0m[0m | time: 2.176s
[2K
| Adam | epoch: 012 | loss: 0.44651 - acc: 0.8339 -- iter: 128/184
[A[ATraining Step: 71  | total loss: [1m[32m0.43778[0m[0m | time: 2.795s
[2K
| Adam | epoch: 012 | loss: 0.43778 - acc: 0.8291 -- iter: 160/184
[A[ATraining Step: 72  | total loss: [1m[32m0.40985[0m[0m | time: 4.402s
[2K
| Adam | epoch: 012 | loss: 0.40985 - acc: 0.8413 | val_loss: 0.31581 - val_acc: 0.8966 -- iter: 184/184
--
Training Step: 73  | total loss: [1m[32m0.40625[0m[0m | time: 0.613s
[2K
| Adam | epoch: 013 | loss: 0.40625 - acc: 0.8451 -- iter: 032/184
[A[ATraining Step: 74  | total loss: [1m[32m0.39120[0m[0m | time: 1.232s
[2K
| Adam | epoch: 013 | loss: 0.39120 - acc: 0.8483 -- iter: 064/184
[A[ATraining Step: 75  | total loss: [1m[32m0.40761[0m[0m | time: 1.840s
[2K
| Adam | epoch: 013 | loss: 0.40761 - acc: 0.8377 -- iter: 096/184
[A[ATraining Step: 76  | total loss: [1m[32m0.39544[0m[0m | time: 2.297s
[2K
| Adam | epoch: 013 | loss: 0.39544 - acc: 0.8417 -- iter: 128/184
[A[ATraining Step: 77  | total loss: [1m[32m0.38779[0m[0m | time: 2.752s
[2K
| Adam | epoch: 013 | loss: 0.38779 - acc: 0.8452 -- iter: 160/184
[A[ATraining Step: 78  | total loss: [1m[32m0.39819[0m[0m | time: 4.366s
[2K
| Adam | epoch: 013 | loss: 0.39819 - acc: 0.8396 | val_loss: 0.31151 - val_acc: 0.9138 -- iter: 184/184
--
Training Step: 79  | total loss: [1m[32m0.38854[0m[0m | time: 0.599s
[2K
| Adam | epoch: 014 | loss: 0.38854 - acc: 0.8465 -- iter: 032/184
[A[ATraining Step: 80  | total loss: [1m[32m0.38363[0m[0m | time: 1.209s
[2K
| Adam | epoch: 014 | loss: 0.38363 - acc: 0.8430 -- iter: 064/184
[A[ATraining Step: 81  | total loss: [1m[32m0.35982[0m[0m | time: 1.820s
[2K
| Adam | epoch: 014 | loss: 0.35982 - acc: 0.8557 -- iter: 096/184
[A[ATraining Step: 82  | total loss: [1m[32m0.35701[0m[0m | time: 2.420s
[2K
| Adam | epoch: 014 | loss: 0.35701 - acc: 0.8545 -- iter: 128/184
[A[ATraining Step: 83  | total loss: [1m[32m0.33740[0m[0m | time: 2.892s
[2K
| Adam | epoch: 014 | loss: 0.33740 - acc: 0.8628 -- iter: 160/184
[A[ATraining Step: 84  | total loss: [1m[32m0.31478[0m[0m | time: 4.349s
[2K
| Adam | epoch: 014 | loss: 0.31478 - acc: 0.8765 | val_loss: 0.31983 - val_acc: 0.9138 -- iter: 184/184
--
Training Step: 85  | total loss: [1m[32m0.29563[0m[0m | time: 0.618s
[2K
| Adam | epoch: 015 | loss: 0.29563 - acc: 0.8889 -- iter: 032/184
[A[ATraining Step: 86  | total loss: [1m[32m0.27886[0m[0m | time: 1.211s
[2K
| Adam | epoch: 015 | loss: 0.27886 - acc: 0.8938 -- iter: 064/184
[A[ATraining Step: 87  | total loss: [1m[32m0.26603[0m[0m | time: 1.819s
[2K
| Adam | epoch: 015 | loss: 0.26603 - acc: 0.9013 -- iter: 096/184
[A[ATraining Step: 88  | total loss: [1m[32m0.28541[0m[0m | time: 2.437s
[2K
| Adam | epoch: 015 | loss: 0.28541 - acc: 0.8924 -- iter: 128/184
[A[ATraining Step: 89  | total loss: [1m[32m0.26613[0m[0m | time: 3.031s
[2K
| Adam | epoch: 015 | loss: 0.26613 - acc: 0.9000 -- iter: 160/184
[A[ATraining Step: 90  | total loss: [1m[32m0.24989[0m[0m | time: 4.495s
[2K
| Adam | epoch: 015 | loss: 0.24989 - acc: 0.9069 | val_loss: 0.52711 - val_acc: 0.8103 -- iter: 184/184
--
Training Step: 91  | total loss: [1m[32m0.24020[0m[0m | time: 0.463s
[2K
| Adam | epoch: 016 | loss: 0.24020 - acc: 0.9079 -- iter: 032/184
[A[ATraining Step: 92  | total loss: [1m[32m0.23356[0m[0m | time: 1.058s
[2K
| Adam | epoch: 016 | loss: 0.23356 - acc: 0.9046 -- iter: 064/184
[A[ATraining Step: 93  | total loss: [1m[32m0.22925[0m[0m | time: 1.656s
[2K
| Adam | epoch: 016 | loss: 0.22925 - acc: 0.9047 -- iter: 096/184
[A[ATraining Step: 94  | total loss: [1m[32m0.21296[0m[0m | time: 2.262s
[2K
| Adam | epoch: 016 | loss: 0.21296 - acc: 0.9143 -- iter: 128/184
[A[ATraining Step: 95  | total loss: [1m[32m0.21765[0m[0m | time: 2.872s
[2K
| Adam | epoch: 016 | loss: 0.21765 - acc: 0.9103 -- iter: 160/184
[A[ATraining Step: 96  | total loss: [1m[32m0.20545[0m[0m | time: 4.483s
[2K
| Adam | epoch: 016 | loss: 0.20545 - acc: 0.9162 | val_loss: 0.46447 - val_acc: 0.8276 -- iter: 184/184
--
Training Step: 97  | total loss: [1m[32m0.19740[0m[0m | time: 0.461s
[2K
| Adam | epoch: 017 | loss: 0.19740 - acc: 0.9183 -- iter: 032/184
[A[ATraining Step: 98  | total loss: [1m[32m0.18573[0m[0m | time: 0.921s
[2K
| Adam | epoch: 017 | loss: 0.18573 - acc: 0.9223 -- iter: 064/184
[A[ATraining Step: 99  | total loss: [1m[32m0.17979[0m[0m | time: 1.539s
[2K
| Adam | epoch: 017 | loss: 0.17979 - acc: 0.9218 -- iter: 096/184
[A[ATraining Step: 100  | total loss: [1m[32m0.19776[0m[0m | time: 2.156s
[2K
| Adam | epoch: 017 | loss: 0.19776 - acc: 0.9171 -- iter: 128/184
[A[ATraining Step: 101  | total loss: [1m[32m0.19317[0m[0m | time: 2.757s
[2K
| Adam | epoch: 017 | loss: 0.19317 - acc: 0.9191 -- iter: 160/184
[A[ATraining Step: 102  | total loss: [1m[32m0.19341[0m[0m | time: 4.367s
[2K
| Adam | epoch: 017 | loss: 0.19341 - acc: 0.9210 | val_loss: 0.29430 - val_acc: 0.8621 -- iter: 184/184
--
Training Step: 103  | total loss: [1m[32m0.19816[0m[0m | time: 0.632s
[2K
| Adam | epoch: 018 | loss: 0.19816 - acc: 0.9164 -- iter: 032/184
[A[ATraining Step: 104  | total loss: [1m[32m0.18434[0m[0m | time: 1.078s
[2K
| Adam | epoch: 018 | loss: 0.18434 - acc: 0.9216 -- iter: 064/184
[A[ATraining Step: 105  | total loss: [1m[32m0.17840[0m[0m | time: 1.547s
[2K
| Adam | epoch: 018 | loss: 0.17840 - acc: 0.9253 -- iter: 096/184
[A[ATraining Step: 106  | total loss: [1m[32m0.17303[0m[0m | time: 2.163s
[2K
| Adam | epoch: 018 | loss: 0.17303 - acc: 0.9244 -- iter: 128/184
[A[ATraining Step: 107  | total loss: [1m[32m0.16155[0m[0m | time: 2.769s
[2K
| Adam | epoch: 018 | loss: 0.16155 - acc: 0.9288 -- iter: 160/184
[A[ATraining Step: 108  | total loss: [1m[32m0.17369[0m[0m | time: 4.386s
[2K
| Adam | epoch: 018 | loss: 0.17369 - acc: 0.9328 | val_loss: 0.26191 - val_acc: 0.9138 -- iter: 184/184
--
Training Step: 109  | total loss: [1m[32m0.16566[0m[0m | time: 0.611s
[2K
| Adam | epoch: 019 | loss: 0.16566 - acc: 0.9364 -- iter: 032/184
[A[ATraining Step: 110  | total loss: [1m[32m0.15373[0m[0m | time: 1.215s
[2K
| Adam | epoch: 019 | loss: 0.15373 - acc: 0.9428 -- iter: 064/184
[A[ATraining Step: 111  | total loss: [1m[32m0.14456[0m[0m | time: 1.672s
[2K
| Adam | epoch: 019 | loss: 0.14456 - acc: 0.9454 -- iter: 096/184
[A[ATraining Step: 112  | total loss: [1m[32m0.13738[0m[0m | time: 2.127s
[2K
| Adam | epoch: 019 | loss: 0.13738 - acc: 0.9467 -- iter: 128/184
[A[ATraining Step: 113  | total loss: [1m[32m0.13074[0m[0m | time: 2.739s
[2K
| Adam | epoch: 019 | loss: 0.13074 - acc: 0.9478 -- iter: 160/184
[A[ATraining Step: 114  | total loss: [1m[32m0.12719[0m[0m | time: 4.339s
[2K
| Adam | epoch: 019 | loss: 0.12719 - acc: 0.9468 | val_loss: 0.39197 - val_acc: 0.8793 -- iter: 184/184
--
Training Step: 115  | total loss: [1m[32m0.12991[0m[0m | time: 0.616s
[2K
| Adam | epoch: 020 | loss: 0.12991 - acc: 0.9490 -- iter: 032/184
[A[ATraining Step: 116  | total loss: [1m[32m0.12780[0m[0m | time: 1.239s
[2K
| Adam | epoch: 020 | loss: 0.12780 - acc: 0.9479 -- iter: 064/184
[A[ATraining Step: 117  | total loss: [1m[32m0.11964[0m[0m | time: 1.845s
[2K
| Adam | epoch: 020 | loss: 0.11964 - acc: 0.9499 -- iter: 096/184
[A[ATraining Step: 118  | total loss: [1m[32m0.11151[0m[0m | time: 2.292s
[2K
| Adam | epoch: 020 | loss: 0.11151 - acc: 0.9549 -- iter: 128/184
[A[ATraining Step: 119  | total loss: [1m[32m0.10707[0m[0m | time: 2.753s
[2K
| Adam | epoch: 020 | loss: 0.10707 - acc: 0.9553 -- iter: 160/184
[A[ATraining Step: 120  | total loss: [1m[32m0.10301[0m[0m | time: 4.344s
[2K
| Adam | epoch: 020 | loss: 0.10301 - acc: 0.9598 | val_loss: 0.28639 - val_acc: 0.9310 -- iter: 184/184
--
Training Step: 121  | total loss: [1m[32m0.09434[0m[0m | time: 0.623s
[2K
| Adam | epoch: 021 | loss: 0.09434 - acc: 0.9638 -- iter: 032/184
[A[ATraining Step: 122  | total loss: [1m[32m0.10656[0m[0m | time: 1.266s
[2K
| Adam | epoch: 021 | loss: 0.10656 - acc: 0.9643 -- iter: 064/184
[A[ATraining Step: 123  | total loss: [1m[32m0.09898[0m[0m | time: 1.878s
[2K
| Adam | epoch: 021 | loss: 0.09898 - acc: 0.9679 -- iter: 096/184
[A[ATraining Step: 124  | total loss: [1m[32m0.09365[0m[0m | time: 2.494s
[2K
| Adam | epoch: 021 | loss: 0.09365 - acc: 0.9711 -- iter: 128/184
[A[ATraining Step: 125  | total loss: [1m[32m0.08556[0m[0m | time: 2.952s
[2K
| Adam | epoch: 021 | loss: 0.08556 - acc: 0.9740 -- iter: 160/184
[A[ATraining Step: 126  | total loss: [1m[32m0.08162[0m[0m | time: 4.427s
[2K
| Adam | epoch: 021 | loss: 0.08162 - acc: 0.9724 | val_loss: 0.38514 - val_acc: 0.8793 -- iter: 184/184
--
Training Step: 127  | total loss: [1m[32m0.07502[0m[0m | time: 0.621s
[2K
| Adam | epoch: 022 | loss: 0.07502 - acc: 0.9752 -- iter: 032/184
[A[ATraining Step: 128  | total loss: [1m[32m0.07405[0m[0m | time: 1.216s
[2K
| Adam | epoch: 022 | loss: 0.07405 - acc: 0.9745 -- iter: 064/184
[A[ATraining Step: 129  | total loss: [1m[32m0.11007[0m[0m | time: 1.826s
[2K
| Adam | epoch: 022 | loss: 0.11007 - acc: 0.9708 -- iter: 096/184
[A[ATraining Step: 130  | total loss: [1m[32m0.10014[0m[0m | time: 2.431s
[2K
| Adam | epoch: 022 | loss: 0.10014 - acc: 0.9737 -- iter: 128/184
[A[ATraining Step: 131  | total loss: [1m[32m0.09633[0m[0m | time: 3.081s
[2K
| Adam | epoch: 022 | loss: 0.09633 - acc: 0.9732 -- iter: 160/184
[A[ATraining Step: 132  | total loss: [1m[32m0.09808[0m[0m | time: 4.541s
[2K
| Adam | epoch: 022 | loss: 0.09808 - acc: 0.9697 | val_loss: 0.48177 - val_acc: 0.8276 -- iter: 184/184
--
Training Step: 133  | total loss: [1m[32m0.08944[0m[0m | time: 0.496s
[2K
| Adam | epoch: 023 | loss: 0.08944 - acc: 0.9727 -- iter: 032/184
[A[ATraining Step: 134  | total loss: [1m[32m0.08361[0m[0m | time: 1.103s
[2K
| Adam | epoch: 023 | loss: 0.08361 - acc: 0.9754 -- iter: 064/184
[A[ATraining Step: 135  | total loss: [1m[32m0.08120[0m[0m | time: 1.712s
[2K
| Adam | epoch: 023 | loss: 0.08120 - acc: 0.9779 -- iter: 096/184
[A[ATraining Step: 136  | total loss: [1m[32m0.09758[0m[0m | time: 2.351s
[2K
| Adam | epoch: 023 | loss: 0.09758 - acc: 0.9770 -- iter: 128/184
[A[ATraining Step: 137  | total loss: [1m[32m0.08989[0m[0m | time: 2.947s
[2K
| Adam | epoch: 023 | loss: 0.08989 - acc: 0.9793 -- iter: 160/184
[A[ATraining Step: 138  | total loss: [1m[32m0.08829[0m[0m | time: 4.555s
[2K
| Adam | epoch: 023 | loss: 0.08829 - acc: 0.9813 | val_loss: 0.31617 - val_acc: 0.9138 -- iter: 184/184
--
Training Step: 139  | total loss: [1m[32m0.08705[0m[0m | time: 0.459s
[2K
| Adam | epoch: 024 | loss: 0.08705 - acc: 0.9801 -- iter: 032/184
[A[ATraining Step: 140  | total loss: [1m[32m0.07969[0m[0m | time: 0.929s
[2K
| Adam | epoch: 024 | loss: 0.07969 - acc: 0.9821 -- iter: 064/184
[A[ATraining Step: 141  | total loss: [1m[32m0.07313[0m[0m | time: 1.538s
[2K
| Adam | epoch: 024 | loss: 0.07313 - acc: 0.9839 -- iter: 096/184
[A[ATraining Step: 142  | total loss: [1m[32m0.07554[0m[0m | time: 2.162s
[2K
| Adam | epoch: 024 | loss: 0.07554 - acc: 0.9824 -- iter: 128/184
[A[ATraining Step: 143  | total loss: [1m[32m0.08044[0m[0m | time: 2.767s
[2K
| Adam | epoch: 024 | loss: 0.08044 - acc: 0.9779 -- iter: 160/184
[A[ATraining Step: 144  | total loss: [1m[32m0.07425[0m[0m | time: 4.379s
[2K
| Adam | epoch: 024 | loss: 0.07425 - acc: 0.9801 | val_loss: 0.33769 - val_acc: 0.9138 -- iter: 184/184
--
Training Step: 145  | total loss: [1m[32m0.06793[0m[0m | time: 0.607s
[2K
| Adam | epoch: 025 | loss: 0.06793 - acc: 0.9821 -- iter: 032/184
[A[ATraining Step: 146  | total loss: [1m[32m0.06176[0m[0m | time: 1.067s
[2K
| Adam | epoch: 025 | loss: 0.06176 - acc: 0.9839 -- iter: 064/184
[A[ATraining Step: 147  | total loss: [1m[32m0.05901[0m[0m | time: 1.553s
[2K
| Adam | epoch: 025 | loss: 0.05901 - acc: 0.9855 -- iter: 096/184
[A[ATraining Step: 148  | total loss: [1m[32m0.05532[0m[0m | time: 2.186s
[2K
| Adam | epoch: 025 | loss: 0.05532 - acc: 0.9869 -- iter: 128/184
[A[ATraining Step: 149  | total loss: [1m[32m0.05104[0m[0m | time: 2.806s
[2K
| Adam | epoch: 025 | loss: 0.05104 - acc: 0.9882 -- iter: 160/184
[A[ATraining Step: 150  | total loss: [1m[32m0.06107[0m[0m | time: 4.436s
[2K
| Adam | epoch: 025 | loss: 0.06107 - acc: 0.9863 | val_loss: 0.41836 - val_acc: 0.8793 -- iter: 184/184
--
Training Step: 151  | total loss: [1m[32m0.05694[0m[0m | time: 0.620s
[2K
| Adam | epoch: 026 | loss: 0.05694 - acc: 0.9877 -- iter: 032/184
[A[ATraining Step: 152  | total loss: [1m[32m0.05349[0m[0m | time: 1.231s
[2K
| Adam | epoch: 026 | loss: 0.05349 - acc: 0.9889 -- iter: 064/184
[A[ATraining Step: 153  | total loss: [1m[32m0.05384[0m[0m | time: 1.694s
[2K
| Adam | epoch: 026 | loss: 0.05384 - acc: 0.9869 -- iter: 096/184
[A[ATraining Step: 154  | total loss: [1m[32m0.04880[0m[0m | time: 2.151s
[2K
| Adam | epoch: 026 | loss: 0.04880 - acc: 0.9882 -- iter: 128/184
[A[ATraining Step: 155  | total loss: [1m[32m0.04436[0m[0m | time: 2.757s
[2K
| Adam | epoch: 026 | loss: 0.04436 - acc: 0.9894 -- iter: 160/184
[A[ATraining Step: 156  | total loss: [1m[32m0.04072[0m[0m | time: 4.438s
[2K
| Adam | epoch: 026 | loss: 0.04072 - acc: 0.9904 | val_loss: 0.38913 - val_acc: 0.8793 -- iter: 184/184
--
Training Step: 157  | total loss: [1m[32m0.03983[0m[0m | time: 0.759s
[2K
| Adam | epoch: 027 | loss: 0.03983 - acc: 0.9914 -- iter: 032/184
[A[ATraining Step: 158  | total loss: [1m[32m0.03814[0m[0m | time: 1.482s
[2K
| Adam | epoch: 027 | loss: 0.03814 - acc: 0.9923 -- iter: 064/184
[A[ATraining Step: 159  | total loss: [1m[32m0.03596[0m[0m | time: 2.202s
[2K
| Adam | epoch: 027 | loss: 0.03596 - acc: 0.9930 -- iter: 096/184
[A[ATraining Step: 160  | total loss: [1m[32m0.03276[0m[0m | time: 2.745s
[2K
| Adam | epoch: 027 | loss: 0.03276 - acc: 0.9937 -- iter: 128/184
[A[ATraining Step: 161  | total loss: [1m[32m0.03128[0m[0m | time: 3.362s
[2K
| Adam | epoch: 027 | loss: 0.03128 - acc: 0.9944 -- iter: 160/184
[A[ATraining Step: 162  | total loss: [1m[32m0.03095[0m[0m | time: 4.969s
[2K
| Adam | epoch: 027 | loss: 0.03095 - acc: 0.9949 | val_loss: 0.31199 - val_acc: 0.9138 -- iter: 184/184
--
Training Step: 163  | total loss: [1m[32m0.02915[0m[0m | time: 0.745s
[2K
| Adam | epoch: 028 | loss: 0.02915 - acc: 0.9954 -- iter: 032/184
[A[ATraining Step: 164  | total loss: [1m[32m0.09669[0m[0m | time: 1.473s
[2K
| Adam | epoch: 028 | loss: 0.09669 - acc: 0.9896 -- iter: 064/184
[A[ATraining Step: 165  | total loss: [1m[32m0.08746[0m[0m | time: 2.197s
[2K
| Adam | epoch: 028 | loss: 0.08746 - acc: 0.9907 -- iter: 096/184
[A[ATraining Step: 166  | total loss: [1m[32m0.09253[0m[0m | time: 2.902s
[2K
| Adam | epoch: 028 | loss: 0.09253 - acc: 0.9854 -- iter: 128/184
[A[ATraining Step: 167  | total loss: [1m[32m0.08701[0m[0m | time: 3.465s
[2K
| Adam | epoch: 028 | loss: 0.08701 - acc: 0.9868 -- iter: 160/184
[A[ATraining Step: 168  | total loss: [1m[32m0.08070[0m[0m | time: 5.018s
[2K
| Adam | epoch: 028 | loss: 0.08070 - acc: 0.9881 | val_loss: 0.37625 - val_acc: 0.8966 -- iter: 184/184
--
Training Step: 169  | total loss: [1m[32m0.07333[0m[0m | time: 0.643s
[2K
| Adam | epoch: 029 | loss: 0.07333 - acc: 0.9893 -- iter: 032/184
[A[ATraining Step: 170  | total loss: [1m[32m0.06671[0m[0m | time: 1.413s
[2K
| Adam | epoch: 029 | loss: 0.06671 - acc: 0.9904 -- iter: 064/184
[A[ATraining Step: 171  | total loss: [1m[32m0.07255[0m[0m | time: 2.143s
[2K
| Adam | epoch: 029 | loss: 0.07255 - acc: 0.9882 -- iter: 096/184
[A[ATraining Step: 172  | total loss: [1m[32m0.08031[0m[0m | time: 2.958s
[2K
| Adam | epoch: 029 | loss: 0.08031 - acc: 0.9800 -- iter: 128/184
[A[ATraining Step: 173  | total loss: [1m[32m0.07814[0m[0m | time: 3.754s
[2K
| Adam | epoch: 029 | loss: 0.07814 - acc: 0.9820 -- iter: 160/184
[A[ATraining Step: 174  | total loss: [1m[32m0.07228[0m[0m | time: 5.298s
[2K
| Adam | epoch: 029 | loss: 0.07228 - acc: 0.9838 | val_loss: 0.32165 - val_acc: 0.9138 -- iter: 184/184
--
Training Step: 175  | total loss: [1m[32m0.06571[0m[0m | time: 0.483s
[2K
| Adam | epoch: 030 | loss: 0.06571 - acc: 0.9854 -- iter: 032/184
[A[ATraining Step: 176  | total loss: [1m[32m0.06030[0m[0m | time: 1.100s
[2K
| Adam | epoch: 030 | loss: 0.06030 - acc: 0.9869 -- iter: 064/184
[A[ATraining Step: 177  | total loss: [1m[32m0.06123[0m[0m | time: 1.707s
[2K
| Adam | epoch: 030 | loss: 0.06123 - acc: 0.9851 -- iter: 096/184
[A[ATraining Step: 178  | total loss: [1m[32m0.07993[0m[0m | time: 2.428s
[2K
| Adam | epoch: 030 | loss: 0.07993 - acc: 0.9834 -- iter: 128/184
[A[ATraining Step: 179  | total loss: [1m[32m0.07639[0m[0m | time: 3.108s
[2K
| Adam | epoch: 030 | loss: 0.07639 - acc: 0.9820 -- iter: 160/184
[A[ATraining Step: 180  | total loss: [1m[32m0.06987[0m[0m | time: 4.891s
[2K
| Adam | epoch: 030 | loss: 0.06987 - acc: 0.9838 | val_loss: 0.33683 - val_acc: 0.9138 -- iter: 184/184
--
Validation AUC:0.9654761904761905
Validation AUPRC:0.9341475999745505
Test AUC:0.984375
Test AUPRC:0.987313519308705
BestTestF1Score	0.94	0.87	0.93	0.89	1.0	32	4	22	0	0.76
BestTestMCCScore	0.94	0.87	0.93	0.89	1.0	32	4	22	0	0.76
BestTestAccuracyScore	0.95	0.9	0.95	0.94	0.97	31	2	24	1	0.92
BestValidationF1Score	0.95	0.9	0.95	0.9	1.0	28	3	27	0	0.76
BestValidationMCC	0.95	0.9	0.95	0.9	1.0	28	3	27	0	0.76
BestValidationAccuracy	0.95	0.9	0.95	0.93	0.96	27	2	28	1	0.92
TestPredictions (Threshold:0.76)
CHEMBL554092,TP,ACT,1.0	CHEMBL294370,TP,ACT,1.0	CHEMBL3633650,TN,INACT,0.029999999329447746	CHEMBL428532,TP,ACT,1.0	CHEMBL43330,FP,INACT,0.8500000238418579	CHEMBL314119,TP,ACT,1.0	CHEMBL303116,TP,ACT,0.9399999976158142	CHEMBL293726,TP,ACT,0.7900000214576721	CHEMBL437797,TP,ACT,0.9200000166893005	CHEMBL59615,TP,ACT,1.0	CHEMBL294649,TN,INACT,0.49000000953674316	CHEMBL311405,TP,ACT,1.0	CHEMBL303543,TP,ACT,1.0	CHEMBL298247,TP,ACT,1.0	CHEMBL279225,TN,INACT,0.10999999940395355	CHEMBL302844,TP,ACT,0.9900000095367432	CHEMBL42799,TN,INACT,0.0	CHEMBL356912,TP,ACT,1.0	CHEMBL451335,TN,INACT,0.009999999776482582	CHEMBL315814,TP,ACT,1.0	CHEMBL302892,TP,ACT,1.0	CHEMBL450463,TN,INACT,0.019999999552965164	CHEMBL296245,TN,INACT,0.0	CHEMBL59347,TN,INACT,0.4300000071525574	CHEMBL21937,TN,INACT,0.0	CHEMBL315982,TP,ACT,1.0	CHEMBL603858,FP,INACT,0.9100000262260437	CHEMBL295615,TP,ACT,1.0	CHEMBL305547,TP,ACT,1.0	CHEMBL545363,TN,INACT,0.009999999776482582	CHEMBL321228,TP,ACT,1.0	CHEMBL429238,FP,INACT,0.9900000095367432	CHEMBL62711,TP,ACT,1.0	CHEMBL2369767,TP,ACT,1.0	CHEMBL351387,TP,ACT,0.9700000286102295	CHEMBL446146,TP,ACT,1.0	CHEMBL293675,TP,ACT,0.9900000095367432	CHEMBL162095,TN,INACT,0.07999999821186066	CHEMBL303890,TP,ACT,1.0	CHEMBL21328,TN,INACT,0.11999999731779099	CHEMBL306267,TP,ACT,0.9800000190734863	CHEMBL3780633,TN,INACT,0.46000000834465027	CHEMBL2369493,FP,INACT,0.9599999785423279	CHEMBL227378,TN,INACT,0.009999999776482582	CHEMBL264384,TP,ACT,0.949999988079071	CHEMBL2115107,TP,ACT,1.0	CHEMBL2115415,TP,ACT,1.0	CHEMBL416069,TN,INACT,0.03999999910593033	CHEMBL191915,TN,INACT,0.009999999776482582	CHEMBL42586,TN,INACT,0.6399999856948853	CHEMBL417390,TP,ACT,1.0	CHEMBL553617,TP,ACT,1.0	CHEMBL217002,TN,INACT,0.009999999776482582	CHEMBL123099,TN,INACT,0.05999999865889549	CHEMBL404557,TN,INACT,0.009999999776482582	CHEMBL298612,TN,INACT,0.49000000953674316	CHEMBL264821,TP,ACT,1.0	CHEMBL279520,TN,INACT,0.0	

