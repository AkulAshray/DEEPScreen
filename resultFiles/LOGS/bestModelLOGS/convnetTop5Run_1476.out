ImageNetInceptionV2 CHEMBL2499 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	109
Number of inactive compounds :	109
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2499_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2499_adam_0.001_15_0.8/
---------------------------------
Training samples: 138
Validation samples: 44
--
Training Step: 1  | time: 47.367s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/138
[A[ATraining Step: 2  | total loss: [1m[32m0.63327[0m[0m | time: 204.465s
[2K
| Adam | epoch: 001 | loss: 0.63327 - acc: 0.4219 -- iter: 064/138
[A[ATraining Step: 3  | total loss: [1m[32m0.79174[0m[0m | time: 421.781s
[2K
| Adam | epoch: 001 | loss: 0.79174 - acc: 0.5114 -- iter: 096/138
[A[ATraining Step: 4  | total loss: [1m[32m1.00707[0m[0m | time: 576.516s
[2K
| Adam | epoch: 001 | loss: 1.00707 - acc: 0.5028 -- iter: 128/138
[A[ATraining Step: 5  | total loss: [1m[32m0.80617[0m[0m | time: 599.522s
[2K
| Adam | epoch: 001 | loss: 0.80617 - acc: 0.5658 | val_loss: 2.35122 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 6  | total loss: [1m[32m0.66560[0m[0m | time: 8.707s
[2K
| Adam | epoch: 002 | loss: 0.66560 - acc: 0.6521 -- iter: 032/138
[A[ATraining Step: 7  | total loss: [1m[32m0.40709[0m[0m | time: 57.282s
[2K
| Adam | epoch: 002 | loss: 0.40709 - acc: 0.8608 -- iter: 064/138
[A[ATraining Step: 8  | total loss: [1m[32m0.54162[0m[0m | time: 77.551s
[2K
| Adam | epoch: 002 | loss: 0.54162 - acc: 0.7282 -- iter: 096/138
[A[ATraining Step: 9  | total loss: [1m[32m0.58461[0m[0m | time: 91.774s
[2K
| Adam | epoch: 002 | loss: 0.58461 - acc: 0.6736 -- iter: 128/138
[A[ATraining Step: 10  | total loss: [1m[32m1.00102[0m[0m | time: 104.156s
[2K
| Adam | epoch: 002 | loss: 1.00102 - acc: 0.5399 | val_loss: 5.16092 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 11  | total loss: [1m[32m0.69859[0m[0m | time: 6.318s
[2K
| Adam | epoch: 003 | loss: 0.69859 - acc: 0.6838 -- iter: 032/138
[A[ATraining Step: 12  | total loss: [1m[32m0.70292[0m[0m | time: 11.472s
[2K
| Adam | epoch: 003 | loss: 0.70292 - acc: 0.6011 -- iter: 064/138
[A[ATraining Step: 13  | total loss: [1m[32m0.62295[0m[0m | time: 96.760s
[2K
| Adam | epoch: 003 | loss: 0.62295 - acc: 0.6435 -- iter: 096/138
[A[ATraining Step: 14  | total loss: [1m[32m0.80515[0m[0m | time: 253.081s
[2K
| Adam | epoch: 003 | loss: 0.80515 - acc: 0.5976 -- iter: 128/138
[A[ATraining Step: 15  | total loss: [1m[32m0.92265[0m[0m | time: 396.269s
[2K
| Adam | epoch: 003 | loss: 0.92265 - acc: 0.5838 | val_loss: 5.32937 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 16  | total loss: [1m[32m0.77100[0m[0m | time: 15.296s
[2K
| Adam | epoch: 004 | loss: 0.77100 - acc: 0.6227 -- iter: 032/138
[A[ATraining Step: 17  | total loss: [1m[32m0.62546[0m[0m | time: 21.780s
[2K
| Adam | epoch: 004 | loss: 0.62546 - acc: 0.7135 -- iter: 064/138
[A[ATraining Step: 18  | total loss: [1m[32m0.52824[0m[0m | time: 28.224s
[2K
| Adam | epoch: 004 | loss: 0.52824 - acc: 0.7435 -- iter: 096/138
[A[ATraining Step: 19  | total loss: [1m[32m0.45205[0m[0m | time: 42.243s
[2K
| Adam | epoch: 004 | loss: 0.45205 - acc: 0.7956 -- iter: 128/138
[A[ATraining Step: 20  | total loss: [1m[32m0.45928[0m[0m | time: 113.988s
[2K
| Adam | epoch: 004 | loss: 0.45928 - acc: 0.7609 | val_loss: 4.26996 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 21  | total loss: [1m[32m0.49689[0m[0m | time: 10.496s
[2K
| Adam | epoch: 005 | loss: 0.49689 - acc: 0.7381 -- iter: 032/138
[A[ATraining Step: 22  | total loss: [1m[32m0.43089[0m[0m | time: 56.531s
[2K
| Adam | epoch: 005 | loss: 0.43089 - acc: 0.7886 -- iter: 064/138
[A[ATraining Step: 23  | total loss: [1m[32m0.36271[0m[0m | time: 62.476s
[2K
| Adam | epoch: 005 | loss: 0.36271 - acc: 0.8227 -- iter: 096/138
[A[ATraining Step: 24  | total loss: [1m[32m0.27201[0m[0m | time: 69.072s
[2K
| Adam | epoch: 005 | loss: 0.27201 - acc: 0.8726 -- iter: 128/138
[A[ATraining Step: 25  | total loss: [1m[32m0.20524[0m[0m | time: 118.735s
[2K
| Adam | epoch: 005 | loss: 0.20524 - acc: 0.9073 | val_loss: 7.66198 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 26  | total loss: [1m[32m0.25473[0m[0m | time: 9.781s
[2K
| Adam | epoch: 006 | loss: 0.25473 - acc: 0.9070 -- iter: 032/138
[A[ATraining Step: 27  | total loss: [1m[32m0.23453[0m[0m | time: 105.037s
[2K
| Adam | epoch: 006 | loss: 0.23453 - acc: 0.9068 -- iter: 064/138
[A[ATraining Step: 28  | total loss: [1m[32m0.26765[0m[0m | time: 158.825s
[2K
| Adam | epoch: 006 | loss: 0.26765 - acc: 0.9067 -- iter: 096/138
[A[ATraining Step: 29  | total loss: [1m[32m0.21467[0m[0m | time: 165.131s
[2K
| Adam | epoch: 006 | loss: 0.21467 - acc: 0.9218 -- iter: 128/138
[A[ATraining Step: 30  | total loss: [1m[32m0.19678[0m[0m | time: 175.386s
[2K
| Adam | epoch: 006 | loss: 0.19678 - acc: 0.9166 | val_loss: 6.37624 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 31  | total loss: [1m[32m0.15547[0m[0m | time: 9.383s
[2K
| Adam | epoch: 007 | loss: 0.15547 - acc: 0.9359 -- iter: 032/138
[A[ATraining Step: 32  | total loss: [1m[32m0.15355[0m[0m | time: 19.097s
[2K
| Adam | epoch: 007 | loss: 0.15355 - acc: 0.9362 -- iter: 064/138
[A[ATraining Step: 33  | total loss: [1m[32m0.21342[0m[0m | time: 98.204s
[2K
| Adam | epoch: 007 | loss: 0.21342 - acc: 0.9159 -- iter: 096/138
[A[ATraining Step: 34  | total loss: [1m[32m0.21009[0m[0m | time: 165.555s
[2K
| Adam | epoch: 007 | loss: 0.21009 - acc: 0.9206 -- iter: 128/138
[A[ATraining Step: 35  | total loss: [1m[32m0.26008[0m[0m | time: 175.231s
[2K
| Adam | epoch: 007 | loss: 0.26008 - acc: 0.9045 | val_loss: 3.78045 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 36  | total loss: [1m[32m0.25784[0m[0m | time: 3.727s
[2K
| Adam | epoch: 008 | loss: 0.25784 - acc: 0.9036 -- iter: 032/138
[A[ATraining Step: 37  | total loss: [1m[32m0.22130[0m[0m | time: 13.421s
[2K
| Adam | epoch: 008 | loss: 0.22130 - acc: 0.9229 -- iter: 064/138
[A[ATraining Step: 38  | total loss: [1m[32m0.20825[0m[0m | time: 22.679s
[2K
| Adam | epoch: 008 | loss: 0.20825 - acc: 0.9318 -- iter: 096/138
[A[ATraining Step: 39  | total loss: [1m[32m0.18504[0m[0m | time: 32.269s
[2K
| Adam | epoch: 008 | loss: 0.18504 - acc: 0.9449 -- iter: 128/138
[A[ATraining Step: 40  | total loss: [1m[32m0.16829[0m[0m | time: 47.499s
[2K
| Adam | epoch: 008 | loss: 0.16829 - acc: 0.9494 | val_loss: 2.63265 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 41  | total loss: [1m[32m0.15122[0m[0m | time: 3.299s
[2K
| Adam | epoch: 009 | loss: 0.15122 - acc: 0.9529 -- iter: 032/138
[A[ATraining Step: 42  | total loss: [1m[32m0.12849[0m[0m | time: 6.629s
[2K
| Adam | epoch: 009 | loss: 0.12849 - acc: 0.9614 -- iter: 064/138
[A[ATraining Step: 43  | total loss: [1m[32m0.10893[0m[0m | time: 15.292s
[2K
| Adam | epoch: 009 | loss: 0.10893 - acc: 0.9682 -- iter: 096/138
[A[ATraining Step: 44  | total loss: [1m[32m0.10270[0m[0m | time: 24.054s
[2K
| Adam | epoch: 009 | loss: 0.10270 - acc: 0.9683 -- iter: 128/138
[A[ATraining Step: 45  | total loss: [1m[32m0.09041[0m[0m | time: 34.477s
[2K
| Adam | epoch: 009 | loss: 0.09041 - acc: 0.9737 | val_loss: 0.79304 - val_acc: 0.6818 -- iter: 138/138
--
Training Step: 46  | total loss: [1m[32m0.13135[0m[0m | time: 8.461s
[2K
| Adam | epoch: 010 | loss: 0.13135 - acc: 0.9677 -- iter: 032/138
[A[ATraining Step: 47  | total loss: [1m[32m0.11299[0m[0m | time: 11.664s
[2K
| Adam | epoch: 010 | loss: 0.11299 - acc: 0.9729 -- iter: 064/138
[A[ATraining Step: 48  | total loss: [1m[32m0.11707[0m[0m | time: 14.874s
[2K
| Adam | epoch: 010 | loss: 0.11707 - acc: 0.9773 -- iter: 096/138
[A[ATraining Step: 49  | total loss: [1m[32m0.10185[0m[0m | time: 23.509s
[2K
| Adam | epoch: 010 | loss: 0.10185 - acc: 0.9809 -- iter: 128/138
[A[ATraining Step: 50  | total loss: [1m[32m0.12084[0m[0m | time: 34.382s
[2K
| Adam | epoch: 010 | loss: 0.12084 - acc: 0.9741 | val_loss: 3.66067 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 51  | total loss: [1m[32m0.17512[0m[0m | time: 8.919s
[2K
| Adam | epoch: 011 | loss: 0.17512 - acc: 0.9590 -- iter: 032/138
[A[ATraining Step: 52  | total loss: [1m[32m0.25952[0m[0m | time: 17.508s
[2K
| Adam | epoch: 011 | loss: 0.25952 - acc: 0.9511 -- iter: 064/138
[A[ATraining Step: 53  | total loss: [1m[32m0.24793[0m[0m | time: 20.619s
[2K
| Adam | epoch: 011 | loss: 0.24793 - acc: 0.9491 -- iter: 096/138
[A[ATraining Step: 54  | total loss: [1m[32m0.22545[0m[0m | time: 23.791s
[2K
| Adam | epoch: 011 | loss: 0.22545 - acc: 0.9565 -- iter: 128/138
[A[ATraining Step: 55  | total loss: [1m[32m0.20250[0m[0m | time: 34.374s
[2K
| Adam | epoch: 011 | loss: 0.20250 - acc: 0.9627 | val_loss: 0.61623 - val_acc: 0.7955 -- iter: 138/138
--
Training Step: 56  | total loss: [1m[32m0.18625[0m[0m | time: 8.826s
[2K
| Adam | epoch: 012 | loss: 0.18625 - acc: 0.9679 -- iter: 032/138
[A[ATraining Step: 57  | total loss: [1m[32m0.16996[0m[0m | time: 17.607s
[2K
| Adam | epoch: 012 | loss: 0.16996 - acc: 0.9724 -- iter: 064/138
[A[ATraining Step: 58  | total loss: [1m[32m0.15480[0m[0m | time: 26.299s
[2K
| Adam | epoch: 012 | loss: 0.15480 - acc: 0.9762 -- iter: 096/138
[A[ATraining Step: 59  | total loss: [1m[32m0.13817[0m[0m | time: 29.502s
[2K
| Adam | epoch: 012 | loss: 0.13817 - acc: 0.9794 -- iter: 128/138
[A[ATraining Step: 60  | total loss: [1m[32m0.13416[0m[0m | time: 34.798s
[2K
| Adam | epoch: 012 | loss: 0.13416 - acc: 0.9821 | val_loss: 0.90648 - val_acc: 0.7727 -- iter: 138/138
--
Training Step: 61  | total loss: [1m[32m0.12072[0m[0m | time: 8.437s
[2K
| Adam | epoch: 013 | loss: 0.12072 - acc: 0.9844 -- iter: 032/138
[A[ATraining Step: 62  | total loss: [1m[32m0.10971[0m[0m | time: 16.812s
[2K
| Adam | epoch: 013 | loss: 0.10971 - acc: 0.9864 -- iter: 064/138
[A[ATraining Step: 63  | total loss: [1m[32m0.11901[0m[0m | time: 25.593s
[2K
| Adam | epoch: 013 | loss: 0.11901 - acc: 0.9802 -- iter: 096/138
[A[ATraining Step: 64  | total loss: [1m[32m0.12813[0m[0m | time: 34.798s
[2K
| Adam | epoch: 013 | loss: 0.12813 - acc: 0.9749 -- iter: 128/138
[A[ATraining Step: 65  | total loss: [1m[32m0.11643[0m[0m | time: 40.261s
[2K
| Adam | epoch: 013 | loss: 0.11643 - acc: 0.9780 | val_loss: 3.03966 - val_acc: 0.5227 -- iter: 138/138
--
Training Step: 66  | total loss: [1m[32m0.11082[0m[0m | time: 3.257s
[2K
| Adam | epoch: 014 | loss: 0.11082 - acc: 0.9807 -- iter: 032/138
[A[ATraining Step: 67  | total loss: [1m[32m0.09843[0m[0m | time: 11.863s
[2K
| Adam | epoch: 014 | loss: 0.09843 - acc: 0.9830 -- iter: 064/138
[A[ATraining Step: 68  | total loss: [1m[32m0.09019[0m[0m | time: 20.661s
[2K
| Adam | epoch: 014 | loss: 0.09019 - acc: 0.9850 -- iter: 096/138
[A[ATraining Step: 69  | total loss: [1m[32m0.08314[0m[0m | time: 29.451s
[2K
| Adam | epoch: 014 | loss: 0.08314 - acc: 0.9867 -- iter: 128/138
[A[ATraining Step: 70  | total loss: [1m[32m0.07770[0m[0m | time: 40.231s
[2K
| Adam | epoch: 014 | loss: 0.07770 - acc: 0.9883 | val_loss: 2.80047 - val_acc: 0.5455 -- iter: 138/138
--
Training Step: 71  | total loss: [1m[32m0.07133[0m[0m | time: 3.353s
[2K
| Adam | epoch: 015 | loss: 0.07133 - acc: 0.9896 -- iter: 032/138
[A[ATraining Step: 72  | total loss: [1m[32m0.07152[0m[0m | time: 6.742s
[2K
| Adam | epoch: 015 | loss: 0.07152 - acc: 0.9908 -- iter: 064/138
[A[ATraining Step: 73  | total loss: [1m[32m0.06528[0m[0m | time: 15.162s
[2K
| Adam | epoch: 015 | loss: 0.06528 - acc: 0.9918 -- iter: 096/138
[A[ATraining Step: 74  | total loss: [1m[32m0.07656[0m[0m | time: 23.996s
[2K
| Adam | epoch: 015 | loss: 0.07656 - acc: 0.9858 -- iter: 128/138
[A[ATraining Step: 75  | total loss: [1m[32m0.06888[0m[0m | time: 34.703s
[2K
| Adam | epoch: 015 | loss: 0.06888 - acc: 0.9874 | val_loss: 2.07058 - val_acc: 0.6136 -- iter: 138/138
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9627329192546584
Validation AUPRC:0.9533106340920312
Test AUC:0.9855072463768115
Test AUPRC:0.9891141385828824
BestTestF1Score	0.88	0.75	0.86	0.79	1.0	23	6	15	0	1.0
BestTestMCCScore	0.88	0.75	0.86	0.79	1.0	23	6	15	0	1.0
BestTestAccuracyScore	0.88	0.75	0.86	0.79	1.0	23	6	15	0	1.0
BestValidationF1Score	0.86	0.72	0.84	0.75	1.0	21	7	16	0	1.0
BestValidationMCC	0.86	0.72	0.84	0.75	1.0	21	7	16	0	1.0
BestValidationAccuracy	0.86	0.72	0.84	0.75	1.0	21	7	16	0	1.0
TestPredictions (Threshold:1.0)
CHEMBL1911003,TP,ACT,1.0	CHEMBL1242292,FP,INACT,1.0	CHEMBL2331660,TP,ACT,1.0	CHEMBL1911015,TP,ACT,1.0	CHEMBL1911006,TP,ACT,1.0	CHEMBL1234354,TP,ACT,1.0	CHEMBL1938640,TN,INACT,0.07000000029802322	CHEMBL1938635,FP,INACT,1.0	CHEMBL1242200,TN,INACT,0.9900000095367432	CHEMBL2331664,TP,ACT,1.0	CHEMBL1241441,TN,INACT,0.10000000149011612	CHEMBL1940247,TP,ACT,1.0	CHEMBL1910990,TP,ACT,1.0	CHEMBL1911125,TP,ACT,1.0	CHEMBL1909655,TP,ACT,1.0	CHEMBL1241490,TN,INACT,0.10999999940395355	CHEMBL1241680,TN,INACT,0.8600000143051147	CHEMBL1241269,TN,INACT,0.8399999737739563	CHEMBL2057729,TP,ACT,1.0	CHEMBL1241861,TN,INACT,0.949999988079071	CHEMBL1240545,TN,INACT,0.9900000095367432	CHEMBL1645097,TN,INACT,0.44999998807907104	CHEMBL3218405,TP,ACT,1.0	CHEMBL1911014,TP,ACT,1.0	CHEMBL3218943,TP,ACT,1.0	CHEMBL2158434,FP,INACT,1.0	CHEMBL2064567,FP,INACT,1.0	CHEMBL2375963,TP,ACT,1.0	CHEMBL3589320,FP,INACT,1.0	CHEMBL1327614,TN,INACT,0.8199999928474426	CHEMBL2375969,TP,ACT,1.0	CHEMBL2375960,TP,ACT,1.0	CHEMBL2375955,TP,ACT,1.0	CHEMBL2018413,FP,INACT,1.0	CHEMBL2375961,TP,ACT,1.0	CHEMBL1911117,TP,ACT,1.0	CHEMBL58782,TN,INACT,0.07000000029802322	CHEMBL1241771,TN,INACT,0.9900000095367432	CHEMBL1938639,TN,INACT,0.9900000095367432	CHEMBL1911000,TP,ACT,1.0	CHEMBL2158425,TN,INACT,0.800000011920929	CHEMBL1241240,TN,INACT,0.9900000095367432	CHEMBL3218404,TP,ACT,1.0	CHEMBL1940246,TP,ACT,1.0	

