CNNModel CHEMBL1744525 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	376
Number of inactive compounds :	376
---------------------------------
Run id: CNNModel_CHEMBL1744525_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1744525_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 477
Validation samples: 150
--
Training Step: 1  | time: 0.795s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/477
[A[ATraining Step: 2  | total loss: [1m[32m0.62376[0m[0m | time: 1.454s
[2K
| Adam | epoch: 001 | loss: 0.62376 - acc: 0.5906 -- iter: 064/477
[A[ATraining Step: 3  | total loss: [1m[32m0.68028[0m[0m | time: 2.121s
[2K
| Adam | epoch: 001 | loss: 0.68028 - acc: 0.5420 -- iter: 096/477
[A[ATraining Step: 4  | total loss: [1m[32m0.69063[0m[0m | time: 2.754s
[2K
| Adam | epoch: 001 | loss: 0.69063 - acc: 0.4871 -- iter: 128/477
[A[ATraining Step: 5  | total loss: [1m[32m0.69209[0m[0m | time: 3.441s
[2K
| Adam | epoch: 001 | loss: 0.69209 - acc: 0.5177 -- iter: 160/477
[A[ATraining Step: 6  | total loss: [1m[32m0.69242[0m[0m | time: 4.119s
[2K
| Adam | epoch: 001 | loss: 0.69242 - acc: 0.5264 -- iter: 192/477
[A[ATraining Step: 7  | total loss: [1m[32m0.69299[0m[0m | time: 4.791s
[2K
| Adam | epoch: 001 | loss: 0.69299 - acc: 0.4918 -- iter: 224/477
[A[ATraining Step: 8  | total loss: [1m[32m0.68991[0m[0m | time: 5.454s
[2K
| Adam | epoch: 001 | loss: 0.68991 - acc: 0.6370 -- iter: 256/477
[A[ATraining Step: 9  | total loss: [1m[32m0.69316[0m[0m | time: 6.125s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5149 -- iter: 288/477
[A[ATraining Step: 10  | total loss: [1m[32m0.69163[0m[0m | time: 6.815s
[2K
| Adam | epoch: 001 | loss: 0.69163 - acc: 0.5387 -- iter: 320/477
[A[ATraining Step: 11  | total loss: [1m[32m0.69361[0m[0m | time: 7.497s
[2K
| Adam | epoch: 001 | loss: 0.69361 - acc: 0.4908 -- iter: 352/477
[A[ATraining Step: 12  | total loss: [1m[32m0.69388[0m[0m | time: 8.164s
[2K
| Adam | epoch: 001 | loss: 0.69388 - acc: 0.4809 -- iter: 384/477
[A[ATraining Step: 13  | total loss: [1m[32m0.69058[0m[0m | time: 8.834s
[2K
| Adam | epoch: 001 | loss: 0.69058 - acc: 0.5426 -- iter: 416/477
[A[ATraining Step: 14  | total loss: [1m[32m0.69301[0m[0m | time: 9.531s
[2K
| Adam | epoch: 001 | loss: 0.69301 - acc: 0.4996 -- iter: 448/477
[A[ATraining Step: 15  | total loss: [1m[32m0.69234[0m[0m | time: 11.170s
[2K
| Adam | epoch: 001 | loss: 0.69234 - acc: 0.4998 | val_loss: 0.69390 - val_acc: 0.4333 -- iter: 477/477
--
Training Step: 16  | total loss: [1m[32m0.69198[0m[0m | time: 0.638s
[2K
| Adam | epoch: 002 | loss: 0.69198 - acc: 0.4934 -- iter: 032/477
[A[ATraining Step: 17  | total loss: [1m[32m0.69202[0m[0m | time: 1.330s
[2K
| Adam | epoch: 002 | loss: 0.69202 - acc: 0.4896 -- iter: 064/477
[A[ATraining Step: 18  | total loss: [1m[32m0.68833[0m[0m | time: 1.985s
[2K
| Adam | epoch: 002 | loss: 0.68833 - acc: 0.5581 -- iter: 096/477
[A[ATraining Step: 19  | total loss: [1m[32m0.68661[0m[0m | time: 2.660s
[2K
| Adam | epoch: 002 | loss: 0.68661 - acc: 0.5700 -- iter: 128/477
[A[ATraining Step: 20  | total loss: [1m[32m0.68628[0m[0m | time: 3.323s
[2K
| Adam | epoch: 002 | loss: 0.68628 - acc: 0.5575 -- iter: 160/477
[A[ATraining Step: 21  | total loss: [1m[32m0.68125[0m[0m | time: 3.977s
[2K
| Adam | epoch: 002 | loss: 0.68125 - acc: 0.5785 -- iter: 192/477
[A[ATraining Step: 22  | total loss: [1m[32m0.68184[0m[0m | time: 4.630s
[2K
| Adam | epoch: 002 | loss: 0.68184 - acc: 0.5643 -- iter: 224/477
[A[ATraining Step: 23  | total loss: [1m[32m0.68967[0m[0m | time: 5.291s
[2K
| Adam | epoch: 002 | loss: 0.68967 - acc: 0.5366 -- iter: 256/477
[A[ATraining Step: 24  | total loss: [1m[32m0.68624[0m[0m | time: 5.950s
[2K
| Adam | epoch: 002 | loss: 0.68624 - acc: 0.5439 -- iter: 288/477
[A[ATraining Step: 25  | total loss: [1m[32m0.69296[0m[0m | time: 6.591s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5063 -- iter: 320/477
[A[ATraining Step: 26  | total loss: [1m[32m0.68936[0m[0m | time: 7.245s
[2K
| Adam | epoch: 002 | loss: 0.68936 - acc: 0.5047 -- iter: 352/477
[A[ATraining Step: 27  | total loss: [1m[32m0.68870[0m[0m | time: 7.906s
[2K
| Adam | epoch: 002 | loss: 0.68870 - acc: 0.4954 -- iter: 384/477
[A[ATraining Step: 28  | total loss: [1m[32m0.68682[0m[0m | time: 8.561s
[2K
| Adam | epoch: 002 | loss: 0.68682 - acc: 0.5669 -- iter: 416/477
[A[ATraining Step: 29  | total loss: [1m[32m0.68540[0m[0m | time: 9.217s
[2K
| Adam | epoch: 002 | loss: 0.68540 - acc: 0.6418 -- iter: 448/477
[A[ATraining Step: 30  | total loss: [1m[32m0.68382[0m[0m | time: 10.875s
[2K
| Adam | epoch: 002 | loss: 0.68382 - acc: 0.6748 | val_loss: 0.66789 - val_acc: 0.6400 -- iter: 477/477
--
Training Step: 31  | total loss: [1m[32m0.68046[0m[0m | time: 0.615s
[2K
| Adam | epoch: 003 | loss: 0.68046 - acc: 0.7066 -- iter: 032/477
[A[ATraining Step: 32  | total loss: [1m[32m0.68067[0m[0m | time: 1.221s
[2K
| Adam | epoch: 003 | loss: 0.68067 - acc: 0.6640 -- iter: 064/477
[A[ATraining Step: 33  | total loss: [1m[32m0.67953[0m[0m | time: 1.879s
[2K
| Adam | epoch: 003 | loss: 0.67953 - acc: 0.6394 -- iter: 096/477
[A[ATraining Step: 34  | total loss: [1m[32m0.67267[0m[0m | time: 2.534s
[2K
| Adam | epoch: 003 | loss: 0.67267 - acc: 0.6564 -- iter: 128/477
[A[ATraining Step: 35  | total loss: [1m[32m0.66224[0m[0m | time: 3.209s
[2K
| Adam | epoch: 003 | loss: 0.66224 - acc: 0.6760 -- iter: 160/477
[A[ATraining Step: 36  | total loss: [1m[32m0.66270[0m[0m | time: 3.863s
[2K
| Adam | epoch: 003 | loss: 0.66270 - acc: 0.6592 -- iter: 192/477
[A[ATraining Step: 37  | total loss: [1m[32m0.65701[0m[0m | time: 4.579s
[2K
| Adam | epoch: 003 | loss: 0.65701 - acc: 0.6586 -- iter: 224/477
[A[ATraining Step: 38  | total loss: [1m[32m0.65990[0m[0m | time: 5.235s
[2K
| Adam | epoch: 003 | loss: 0.65990 - acc: 0.6520 -- iter: 256/477
[A[ATraining Step: 39  | total loss: [1m[32m0.64123[0m[0m | time: 5.890s
[2K
| Adam | epoch: 003 | loss: 0.64123 - acc: 0.6648 -- iter: 288/477
[A[ATraining Step: 40  | total loss: [1m[32m0.63010[0m[0m | time: 6.531s
[2K
| Adam | epoch: 003 | loss: 0.63010 - acc: 0.6690 -- iter: 320/477
[A[ATraining Step: 41  | total loss: [1m[32m0.62999[0m[0m | time: 7.185s
[2K
| Adam | epoch: 003 | loss: 0.62999 - acc: 0.6495 -- iter: 352/477
[A[ATraining Step: 42  | total loss: [1m[32m0.61593[0m[0m | time: 7.847s
[2K
| Adam | epoch: 003 | loss: 0.61593 - acc: 0.6788 -- iter: 384/477
[A[ATraining Step: 43  | total loss: [1m[32m0.59808[0m[0m | time: 8.501s
[2K
| Adam | epoch: 003 | loss: 0.59808 - acc: 0.7024 -- iter: 416/477
[A[ATraining Step: 44  | total loss: [1m[32m0.58229[0m[0m | time: 9.182s
[2K
| Adam | epoch: 003 | loss: 0.58229 - acc: 0.7269 -- iter: 448/477
[A[ATraining Step: 45  | total loss: [1m[32m0.57073[0m[0m | time: 10.848s
[2K
| Adam | epoch: 003 | loss: 0.57073 - acc: 0.7361 | val_loss: 0.62622 - val_acc: 0.6867 -- iter: 477/477
--
Training Step: 46  | total loss: [1m[32m0.55096[0m[0m | time: 0.664s
[2K
| Adam | epoch: 004 | loss: 0.55096 - acc: 0.7488 -- iter: 032/477
[A[ATraining Step: 47  | total loss: [1m[32m0.57409[0m[0m | time: 1.270s
[2K
| Adam | epoch: 004 | loss: 0.57409 - acc: 0.7183 -- iter: 064/477
[A[ATraining Step: 48  | total loss: [1m[32m0.55974[0m[0m | time: 1.877s
[2K
| Adam | epoch: 004 | loss: 0.55974 - acc: 0.7193 -- iter: 096/477
[A[ATraining Step: 49  | total loss: [1m[32m0.54388[0m[0m | time: 2.523s
[2K
| Adam | epoch: 004 | loss: 0.54388 - acc: 0.7364 -- iter: 128/477
[A[ATraining Step: 50  | total loss: [1m[32m0.54470[0m[0m | time: 3.179s
[2K
| Adam | epoch: 004 | loss: 0.54470 - acc: 0.7336 -- iter: 160/477
[A[ATraining Step: 51  | total loss: [1m[32m0.54449[0m[0m | time: 3.810s
[2K
| Adam | epoch: 004 | loss: 0.54449 - acc: 0.7409 -- iter: 192/477
[A[ATraining Step: 52  | total loss: [1m[32m0.54680[0m[0m | time: 4.460s
[2K
| Adam | epoch: 004 | loss: 0.54680 - acc: 0.7376 -- iter: 224/477
[A[ATraining Step: 53  | total loss: [1m[32m0.56249[0m[0m | time: 5.141s
[2K
| Adam | epoch: 004 | loss: 0.56249 - acc: 0.7302 -- iter: 256/477
[A[ATraining Step: 54  | total loss: [1m[32m0.54132[0m[0m | time: 5.804s
[2K
| Adam | epoch: 004 | loss: 0.54132 - acc: 0.7285 -- iter: 288/477
[A[ATraining Step: 55  | total loss: [1m[32m0.52750[0m[0m | time: 6.470s
[2K
| Adam | epoch: 004 | loss: 0.52750 - acc: 0.7271 -- iter: 320/477
[A[ATraining Step: 56  | total loss: [1m[32m0.51762[0m[0m | time: 7.127s
[2K
| Adam | epoch: 004 | loss: 0.51762 - acc: 0.7303 -- iter: 352/477
[A[ATraining Step: 57  | total loss: [1m[32m0.51653[0m[0m | time: 7.756s
[2K
| Adam | epoch: 004 | loss: 0.51653 - acc: 0.7374 -- iter: 384/477
[A[ATraining Step: 58  | total loss: [1m[32m0.51058[0m[0m | time: 8.414s
[2K
| Adam | epoch: 004 | loss: 0.51058 - acc: 0.7476 -- iter: 416/477
[A[ATraining Step: 59  | total loss: [1m[32m0.51332[0m[0m | time: 9.081s
[2K
| Adam | epoch: 004 | loss: 0.51332 - acc: 0.7522 -- iter: 448/477
[A[ATraining Step: 60  | total loss: [1m[32m0.49754[0m[0m | time: 10.752s
[2K
| Adam | epoch: 004 | loss: 0.49754 - acc: 0.7767 | val_loss: 0.43678 - val_acc: 0.8267 -- iter: 477/477
--
Training Step: 61  | total loss: [1m[32m0.50196[0m[0m | time: 0.706s
[2K
| Adam | epoch: 005 | loss: 0.50196 - acc: 0.7691 -- iter: 032/477
[A[ATraining Step: 62  | total loss: [1m[32m0.51689[0m[0m | time: 1.376s
[2K
| Adam | epoch: 005 | loss: 0.51689 - acc: 0.7546 -- iter: 064/477
[A[ATraining Step: 63  | total loss: [1m[32m0.50007[0m[0m | time: 1.971s
[2K
| Adam | epoch: 005 | loss: 0.50007 - acc: 0.7699 -- iter: 096/477
[A[ATraining Step: 64  | total loss: [1m[32m0.49852[0m[0m | time: 2.567s
[2K
| Adam | epoch: 005 | loss: 0.49852 - acc: 0.7642 -- iter: 128/477
[A[ATraining Step: 65  | total loss: [1m[32m0.49561[0m[0m | time: 3.214s
[2K
| Adam | epoch: 005 | loss: 0.49561 - acc: 0.7592 -- iter: 160/477
[A[ATraining Step: 66  | total loss: [1m[32m0.48885[0m[0m | time: 3.882s
[2K
| Adam | epoch: 005 | loss: 0.48885 - acc: 0.7543 -- iter: 192/477
[A[ATraining Step: 67  | total loss: [1m[32m0.48999[0m[0m | time: 4.579s
[2K
| Adam | epoch: 005 | loss: 0.48999 - acc: 0.7538 -- iter: 224/477
[A[ATraining Step: 68  | total loss: [1m[32m0.49098[0m[0m | time: 5.226s
[2K
| Adam | epoch: 005 | loss: 0.49098 - acc: 0.7533 -- iter: 256/477
[A[ATraining Step: 69  | total loss: [1m[32m0.50091[0m[0m | time: 5.898s
[2K
| Adam | epoch: 005 | loss: 0.50091 - acc: 0.7493 -- iter: 288/477
[A[ATraining Step: 70  | total loss: [1m[32m0.49444[0m[0m | time: 6.554s
[2K
| Adam | epoch: 005 | loss: 0.49444 - acc: 0.7566 -- iter: 320/477
[A[ATraining Step: 71  | total loss: [1m[32m0.49574[0m[0m | time: 7.210s
[2K
| Adam | epoch: 005 | loss: 0.49574 - acc: 0.7594 -- iter: 352/477
[A[ATraining Step: 72  | total loss: [1m[32m0.47086[0m[0m | time: 7.844s
[2K
| Adam | epoch: 005 | loss: 0.47086 - acc: 0.7724 -- iter: 384/477
[A[ATraining Step: 73  | total loss: [1m[32m0.46226[0m[0m | time: 8.507s
[2K
| Adam | epoch: 005 | loss: 0.46226 - acc: 0.7734 -- iter: 416/477
[A[ATraining Step: 74  | total loss: [1m[32m0.46549[0m[0m | time: 9.161s
[2K
| Adam | epoch: 005 | loss: 0.46549 - acc: 0.7811 -- iter: 448/477
[A[ATraining Step: 75  | total loss: [1m[32m0.45209[0m[0m | time: 10.798s
[2K
| Adam | epoch: 005 | loss: 0.45209 - acc: 0.7879 | val_loss: 0.35539 - val_acc: 0.8733 -- iter: 477/477
--
Training Step: 76  | total loss: [1m[32m0.44529[0m[0m | time: 0.664s
[2K
| Adam | epoch: 006 | loss: 0.44529 - acc: 0.7905 -- iter: 032/477
[A[ATraining Step: 77  | total loss: [1m[32m0.45037[0m[0m | time: 1.313s
[2K
| Adam | epoch: 006 | loss: 0.45037 - acc: 0.7862 -- iter: 064/477
[A[ATraining Step: 78  | total loss: [1m[32m0.45560[0m[0m | time: 1.966s
[2K
| Adam | epoch: 006 | loss: 0.45560 - acc: 0.7792 -- iter: 096/477
[A[ATraining Step: 79  | total loss: [1m[32m0.44585[0m[0m | time: 2.572s
[2K
| Adam | epoch: 006 | loss: 0.44585 - acc: 0.7794 -- iter: 128/477
[A[ATraining Step: 80  | total loss: [1m[32m0.43299[0m[0m | time: 3.182s
[2K
| Adam | epoch: 006 | loss: 0.43299 - acc: 0.7914 -- iter: 160/477
[A[ATraining Step: 81  | total loss: [1m[32m0.42512[0m[0m | time: 3.863s
[2K
| Adam | epoch: 006 | loss: 0.42512 - acc: 0.7985 -- iter: 192/477
[A[ATraining Step: 82  | total loss: [1m[32m0.40891[0m[0m | time: 4.518s
[2K
| Adam | epoch: 006 | loss: 0.40891 - acc: 0.8062 -- iter: 224/477
[A[ATraining Step: 83  | total loss: [1m[32m0.39967[0m[0m | time: 5.179s
[2K
| Adam | epoch: 006 | loss: 0.39967 - acc: 0.8162 -- iter: 256/477
[A[ATraining Step: 84  | total loss: [1m[32m0.38476[0m[0m | time: 5.848s
[2K
| Adam | epoch: 006 | loss: 0.38476 - acc: 0.8252 -- iter: 288/477
[A[ATraining Step: 85  | total loss: [1m[32m0.37450[0m[0m | time: 6.496s
[2K
| Adam | epoch: 006 | loss: 0.37450 - acc: 0.8270 -- iter: 320/477
[A[ATraining Step: 86  | total loss: [1m[32m0.38141[0m[0m | time: 7.147s
[2K
| Adam | epoch: 006 | loss: 0.38141 - acc: 0.8256 -- iter: 352/477
[A[ATraining Step: 87  | total loss: [1m[32m0.37612[0m[0m | time: 7.794s
[2K
| Adam | epoch: 006 | loss: 0.37612 - acc: 0.8305 -- iter: 384/477
[A[ATraining Step: 88  | total loss: [1m[32m0.37501[0m[0m | time: 8.455s
[2K
| Adam | epoch: 006 | loss: 0.37501 - acc: 0.8225 -- iter: 416/477
[A[ATraining Step: 89  | total loss: [1m[32m0.35268[0m[0m | time: 9.139s
[2K
| Adam | epoch: 006 | loss: 0.35268 - acc: 0.8371 -- iter: 448/477
[A[ATraining Step: 90  | total loss: [1m[32m0.37575[0m[0m | time: 10.787s
[2K
| Adam | epoch: 006 | loss: 0.37575 - acc: 0.8190 | val_loss: 0.34499 - val_acc: 0.8600 -- iter: 477/477
--
Training Step: 91  | total loss: [1m[32m0.37437[0m[0m | time: 0.666s
[2K
| Adam | epoch: 007 | loss: 0.37437 - acc: 0.8184 -- iter: 032/477
[A[ATraining Step: 92  | total loss: [1m[32m0.36670[0m[0m | time: 1.322s
[2K
| Adam | epoch: 007 | loss: 0.36670 - acc: 0.8240 -- iter: 064/477
[A[ATraining Step: 93  | total loss: [1m[32m0.35511[0m[0m | time: 1.971s
[2K
| Adam | epoch: 007 | loss: 0.35511 - acc: 0.8354 -- iter: 096/477
[A[ATraining Step: 94  | total loss: [1m[32m0.35407[0m[0m | time: 2.621s
[2K
| Adam | epoch: 007 | loss: 0.35407 - acc: 0.8393 -- iter: 128/477
[A[ATraining Step: 95  | total loss: [1m[32m0.35419[0m[0m | time: 3.226s
[2K
| Adam | epoch: 007 | loss: 0.35419 - acc: 0.8335 -- iter: 160/477
[A[ATraining Step: 96  | total loss: [1m[32m0.35830[0m[0m | time: 3.823s
[2K
| Adam | epoch: 007 | loss: 0.35830 - acc: 0.8295 -- iter: 192/477
[A[ATraining Step: 97  | total loss: [1m[32m0.35532[0m[0m | time: 4.492s
[2K
| Adam | epoch: 007 | loss: 0.35532 - acc: 0.8293 -- iter: 224/477
[A[ATraining Step: 98  | total loss: [1m[32m0.34956[0m[0m | time: 5.158s
[2K
| Adam | epoch: 007 | loss: 0.34956 - acc: 0.8339 -- iter: 256/477
[A[ATraining Step: 99  | total loss: [1m[32m0.34400[0m[0m | time: 5.809s
[2K
| Adam | epoch: 007 | loss: 0.34400 - acc: 0.8349 -- iter: 288/477
[A[ATraining Step: 100  | total loss: [1m[32m0.32963[0m[0m | time: 6.457s
[2K
| Adam | epoch: 007 | loss: 0.32963 - acc: 0.8420 -- iter: 320/477
[A[ATraining Step: 101  | total loss: [1m[32m0.33383[0m[0m | time: 7.095s
[2K
| Adam | epoch: 007 | loss: 0.33383 - acc: 0.8484 -- iter: 352/477
[A[ATraining Step: 102  | total loss: [1m[32m0.33256[0m[0m | time: 7.747s
[2K
| Adam | epoch: 007 | loss: 0.33256 - acc: 0.8417 -- iter: 384/477
[A[ATraining Step: 103  | total loss: [1m[32m0.32556[0m[0m | time: 8.397s
[2K
| Adam | epoch: 007 | loss: 0.32556 - acc: 0.8388 -- iter: 416/477
[A[ATraining Step: 104  | total loss: [1m[32m0.33106[0m[0m | time: 9.045s
[2K
| Adam | epoch: 007 | loss: 0.33106 - acc: 0.8330 -- iter: 448/477
[A[ATraining Step: 105  | total loss: [1m[32m0.32844[0m[0m | time: 10.700s
[2K
| Adam | epoch: 007 | loss: 0.32844 - acc: 0.8404 | val_loss: 0.22714 - val_acc: 0.9000 -- iter: 477/477
--
Training Step: 106  | total loss: [1m[32m0.31590[0m[0m | time: 0.684s
[2K
| Adam | epoch: 008 | loss: 0.31590 - acc: 0.8501 -- iter: 032/477
[A[ATraining Step: 107  | total loss: [1m[32m0.30692[0m[0m | time: 1.366s
[2K
| Adam | epoch: 008 | loss: 0.30692 - acc: 0.8557 -- iter: 064/477
[A[ATraining Step: 108  | total loss: [1m[32m0.29371[0m[0m | time: 2.044s
[2K
| Adam | epoch: 008 | loss: 0.29371 - acc: 0.8639 -- iter: 096/477
[A[ATraining Step: 109  | total loss: [1m[32m0.29580[0m[0m | time: 2.701s
[2K
| Adam | epoch: 008 | loss: 0.29580 - acc: 0.8650 -- iter: 128/477
[A[ATraining Step: 110  | total loss: [1m[32m0.28281[0m[0m | time: 3.370s
[2K
| Adam | epoch: 008 | loss: 0.28281 - acc: 0.8691 -- iter: 160/477
[A[ATraining Step: 111  | total loss: [1m[32m0.27785[0m[0m | time: 3.970s
[2K
| Adam | epoch: 008 | loss: 0.27785 - acc: 0.8728 -- iter: 192/477
[A[ATraining Step: 112  | total loss: [1m[32m0.27631[0m[0m | time: 4.566s
[2K
| Adam | epoch: 008 | loss: 0.27631 - acc: 0.8786 -- iter: 224/477
[A[ATraining Step: 113  | total loss: [1m[32m0.26382[0m[0m | time: 5.249s
[2K
| Adam | epoch: 008 | loss: 0.26382 - acc: 0.8873 -- iter: 256/477
[A[ATraining Step: 114  | total loss: [1m[32m0.27463[0m[0m | time: 5.905s
[2K
| Adam | epoch: 008 | loss: 0.27463 - acc: 0.8767 -- iter: 288/477
[A[ATraining Step: 115  | total loss: [1m[32m0.27194[0m[0m | time: 6.563s
[2K
| Adam | epoch: 008 | loss: 0.27194 - acc: 0.8734 -- iter: 320/477
[A[ATraining Step: 116  | total loss: [1m[32m0.25498[0m[0m | time: 7.243s
[2K
| Adam | epoch: 008 | loss: 0.25498 - acc: 0.8798 -- iter: 352/477
[A[ATraining Step: 117  | total loss: [1m[32m0.24850[0m[0m | time: 7.896s
[2K
| Adam | epoch: 008 | loss: 0.24850 - acc: 0.8856 -- iter: 384/477
[A[ATraining Step: 118  | total loss: [1m[32m0.23020[0m[0m | time: 8.535s
[2K
| Adam | epoch: 008 | loss: 0.23020 - acc: 0.8970 -- iter: 416/477
[A[ATraining Step: 119  | total loss: [1m[32m0.23338[0m[0m | time: 9.208s
[2K
| Adam | epoch: 008 | loss: 0.23338 - acc: 0.8948 -- iter: 448/477
[A[ATraining Step: 120  | total loss: [1m[32m0.21799[0m[0m | time: 10.857s
[2K
| Adam | epoch: 008 | loss: 0.21799 - acc: 0.9054 | val_loss: 0.28782 - val_acc: 0.8933 -- iter: 477/477
--
Training Step: 121  | total loss: [1m[32m0.21173[0m[0m | time: 0.663s
[2K
| Adam | epoch: 009 | loss: 0.21173 - acc: 0.9086 -- iter: 032/477
[A[ATraining Step: 122  | total loss: [1m[32m0.22174[0m[0m | time: 1.319s
[2K
| Adam | epoch: 009 | loss: 0.22174 - acc: 0.9052 -- iter: 064/477
[A[ATraining Step: 123  | total loss: [1m[32m0.21234[0m[0m | time: 1.961s
[2K
| Adam | epoch: 009 | loss: 0.21234 - acc: 0.9116 -- iter: 096/477
[A[ATraining Step: 124  | total loss: [1m[32m0.20360[0m[0m | time: 2.609s
[2K
| Adam | epoch: 009 | loss: 0.20360 - acc: 0.9173 -- iter: 128/477
[A[ATraining Step: 125  | total loss: [1m[32m0.23242[0m[0m | time: 3.278s
[2K
| Adam | epoch: 009 | loss: 0.23242 - acc: 0.9068 -- iter: 160/477
[A[ATraining Step: 126  | total loss: [1m[32m0.23118[0m[0m | time: 3.945s
[2K
| Adam | epoch: 009 | loss: 0.23118 - acc: 0.9036 -- iter: 192/477
[A[ATraining Step: 127  | total loss: [1m[32m0.22026[0m[0m | time: 4.538s
[2K
| Adam | epoch: 009 | loss: 0.22026 - acc: 0.9101 -- iter: 224/477
[A[ATraining Step: 128  | total loss: [1m[32m0.21196[0m[0m | time: 5.161s
[2K
| Adam | epoch: 009 | loss: 0.21196 - acc: 0.9157 -- iter: 256/477
[A[ATraining Step: 129  | total loss: [1m[32m0.20626[0m[0m | time: 5.812s
[2K
| Adam | epoch: 009 | loss: 0.20626 - acc: 0.9207 -- iter: 288/477
[A[ATraining Step: 130  | total loss: [1m[32m0.20376[0m[0m | time: 6.466s
[2K
| Adam | epoch: 009 | loss: 0.20376 - acc: 0.9192 -- iter: 320/477
[A[ATraining Step: 131  | total loss: [1m[32m0.19028[0m[0m | time: 7.117s
[2K
| Adam | epoch: 009 | loss: 0.19028 - acc: 0.9242 -- iter: 352/477
[A[ATraining Step: 132  | total loss: [1m[32m0.18115[0m[0m | time: 7.754s
[2K
| Adam | epoch: 009 | loss: 0.18115 - acc: 0.9286 -- iter: 384/477
[A[ATraining Step: 133  | total loss: [1m[32m0.17424[0m[0m | time: 8.425s
[2K
| Adam | epoch: 009 | loss: 0.17424 - acc: 0.9326 -- iter: 416/477
[A[ATraining Step: 134  | total loss: [1m[32m0.16113[0m[0m | time: 9.082s
[2K
| Adam | epoch: 009 | loss: 0.16113 - acc: 0.9394 -- iter: 448/477
[A[ATraining Step: 135  | total loss: [1m[32m0.15161[0m[0m | time: 10.727s
[2K
| Adam | epoch: 009 | loss: 0.15161 - acc: 0.9423 | val_loss: 0.26149 - val_acc: 0.9133 -- iter: 477/477
--
Training Step: 136  | total loss: [1m[32m0.17309[0m[0m | time: 0.648s
[2K
| Adam | epoch: 010 | loss: 0.17309 - acc: 0.9325 -- iter: 032/477
[A[ATraining Step: 137  | total loss: [1m[32m0.17272[0m[0m | time: 1.349s
[2K
| Adam | epoch: 010 | loss: 0.17272 - acc: 0.9298 -- iter: 064/477
[A[ATraining Step: 138  | total loss: [1m[32m0.18378[0m[0m | time: 2.020s
[2K
| Adam | epoch: 010 | loss: 0.18378 - acc: 0.9275 -- iter: 096/477
[A[ATraining Step: 139  | total loss: [1m[32m0.18249[0m[0m | time: 2.695s
[2K
| Adam | epoch: 010 | loss: 0.18249 - acc: 0.9285 -- iter: 128/477
[A[ATraining Step: 140  | total loss: [1m[32m0.17221[0m[0m | time: 3.339s
[2K
| Adam | epoch: 010 | loss: 0.17221 - acc: 0.9356 -- iter: 160/477
[A[ATraining Step: 141  | total loss: [1m[32m0.15761[0m[0m | time: 3.993s
[2K
| Adam | epoch: 010 | loss: 0.15761 - acc: 0.9421 -- iter: 192/477
[A[ATraining Step: 142  | total loss: [1m[32m0.16638[0m[0m | time: 4.664s
[2K
| Adam | epoch: 010 | loss: 0.16638 - acc: 0.9385 -- iter: 224/477
[A[ATraining Step: 143  | total loss: [1m[32m0.16137[0m[0m | time: 5.281s
[2K
| Adam | epoch: 010 | loss: 0.16137 - acc: 0.9415 -- iter: 256/477
[A[ATraining Step: 144  | total loss: [1m[32m0.15572[0m[0m | time: 5.896s
[2K
| Adam | epoch: 010 | loss: 0.15572 - acc: 0.9474 -- iter: 288/477
[A[ATraining Step: 145  | total loss: [1m[32m0.15689[0m[0m | time: 6.556s
[2K
| Adam | epoch: 010 | loss: 0.15689 - acc: 0.9423 -- iter: 320/477
[A[ATraining Step: 146  | total loss: [1m[32m0.15958[0m[0m | time: 7.225s
[2K
| Adam | epoch: 010 | loss: 0.15958 - acc: 0.9356 -- iter: 352/477
[A[ATraining Step: 147  | total loss: [1m[32m0.15320[0m[0m | time: 7.881s
[2K
| Adam | epoch: 010 | loss: 0.15320 - acc: 0.9357 -- iter: 384/477
[A[ATraining Step: 148  | total loss: [1m[32m0.15917[0m[0m | time: 8.534s
[2K
| Adam | epoch: 010 | loss: 0.15917 - acc: 0.9297 -- iter: 416/477
[A[ATraining Step: 149  | total loss: [1m[32m0.14673[0m[0m | time: 9.212s
[2K
| Adam | epoch: 010 | loss: 0.14673 - acc: 0.9367 -- iter: 448/477
[A[ATraining Step: 150  | total loss: [1m[32m0.14443[0m[0m | time: 10.885s
[2K
| Adam | epoch: 010 | loss: 0.14443 - acc: 0.9399 | val_loss: 0.24497 - val_acc: 0.9067 -- iter: 477/477
--
Training Step: 151  | total loss: [1m[32m0.13590[0m[0m | time: 0.688s
[2K
| Adam | epoch: 011 | loss: 0.13590 - acc: 0.9459 -- iter: 032/477
[A[ATraining Step: 152  | total loss: [1m[32m0.13686[0m[0m | time: 1.346s
[2K
| Adam | epoch: 011 | loss: 0.13686 - acc: 0.9482 -- iter: 064/477
[A[ATraining Step: 153  | total loss: [1m[32m0.13544[0m[0m | time: 2.041s
[2K
| Adam | epoch: 011 | loss: 0.13544 - acc: 0.9503 -- iter: 096/477
[A[ATraining Step: 154  | total loss: [1m[32m0.13228[0m[0m | time: 2.720s
[2K
| Adam | epoch: 011 | loss: 0.13228 - acc: 0.9490 -- iter: 128/477
[A[ATraining Step: 155  | total loss: [1m[32m0.12705[0m[0m | time: 3.387s
[2K
| Adam | epoch: 011 | loss: 0.12705 - acc: 0.9510 -- iter: 160/477
[A[ATraining Step: 156  | total loss: [1m[32m0.12008[0m[0m | time: 4.062s
[2K
| Adam | epoch: 011 | loss: 0.12008 - acc: 0.9559 -- iter: 192/477
[A[ATraining Step: 157  | total loss: [1m[32m0.12522[0m[0m | time: 4.713s
[2K
| Adam | epoch: 011 | loss: 0.12522 - acc: 0.9509 -- iter: 224/477
[A[ATraining Step: 158  | total loss: [1m[32m0.11907[0m[0m | time: 5.388s
[2K
| Adam | epoch: 011 | loss: 0.11907 - acc: 0.9558 -- iter: 256/477
[A[ATraining Step: 159  | total loss: [1m[32m0.11996[0m[0m | time: 5.989s
[2K
| Adam | epoch: 011 | loss: 0.11996 - acc: 0.9509 -- iter: 288/477
[A[ATraining Step: 160  | total loss: [1m[32m0.11730[0m[0m | time: 6.604s
[2K
| Adam | epoch: 011 | loss: 0.11730 - acc: 0.9523 -- iter: 320/477
[A[ATraining Step: 161  | total loss: [1m[32m0.10848[0m[0m | time: 7.262s
[2K
| Adam | epoch: 011 | loss: 0.10848 - acc: 0.9571 -- iter: 352/477
[A[ATraining Step: 162  | total loss: [1m[32m0.11379[0m[0m | time: 7.927s
[2K
| Adam | epoch: 011 | loss: 0.11379 - acc: 0.9583 -- iter: 384/477
[A[ATraining Step: 163  | total loss: [1m[32m0.10871[0m[0m | time: 8.584s
[2K
| Adam | epoch: 011 | loss: 0.10871 - acc: 0.9593 -- iter: 416/477
[A[ATraining Step: 164  | total loss: [1m[32m0.10228[0m[0m | time: 9.263s
[2K
| Adam | epoch: 011 | loss: 0.10228 - acc: 0.9634 -- iter: 448/477
[A[ATraining Step: 165  | total loss: [1m[32m0.10036[0m[0m | time: 10.930s
[2K
| Adam | epoch: 011 | loss: 0.10036 - acc: 0.9670 | val_loss: 0.18229 - val_acc: 0.9133 -- iter: 477/477
--
Training Step: 166  | total loss: [1m[32m0.10840[0m[0m | time: 0.680s
[2K
| Adam | epoch: 012 | loss: 0.10840 - acc: 0.9641 -- iter: 032/477
[A[ATraining Step: 167  | total loss: [1m[32m0.10058[0m[0m | time: 1.354s
[2K
| Adam | epoch: 012 | loss: 0.10058 - acc: 0.9677 -- iter: 064/477
[A[ATraining Step: 168  | total loss: [1m[32m0.09204[0m[0m | time: 2.031s
[2K
| Adam | epoch: 012 | loss: 0.09204 - acc: 0.9709 -- iter: 096/477
[A[ATraining Step: 169  | total loss: [1m[32m0.08861[0m[0m | time: 2.689s
[2K
| Adam | epoch: 012 | loss: 0.08861 - acc: 0.9707 -- iter: 128/477
[A[ATraining Step: 170  | total loss: [1m[32m0.09762[0m[0m | time: 3.343s
[2K
| Adam | epoch: 012 | loss: 0.09762 - acc: 0.9611 -- iter: 160/477
[A[ATraining Step: 171  | total loss: [1m[32m0.09058[0m[0m | time: 3.993s
[2K
| Adam | epoch: 012 | loss: 0.09058 - acc: 0.9650 -- iter: 192/477
[A[ATraining Step: 172  | total loss: [1m[32m0.09176[0m[0m | time: 4.652s
[2K
| Adam | epoch: 012 | loss: 0.09176 - acc: 0.9623 -- iter: 224/477
[A[ATraining Step: 173  | total loss: [1m[32m0.10341[0m[0m | time: 5.325s
[2K
| Adam | epoch: 012 | loss: 0.10341 - acc: 0.9629 -- iter: 256/477
[A[ATraining Step: 174  | total loss: [1m[32m0.09550[0m[0m | time: 5.974s
[2K
| Adam | epoch: 012 | loss: 0.09550 - acc: 0.9666 -- iter: 288/477
[A[ATraining Step: 175  | total loss: [1m[32m0.09896[0m[0m | time: 6.605s
[2K
| Adam | epoch: 012 | loss: 0.09896 - acc: 0.9637 -- iter: 320/477
[A[ATraining Step: 176  | total loss: [1m[32m0.10622[0m[0m | time: 7.246s
[2K
| Adam | epoch: 012 | loss: 0.10622 - acc: 0.9639 -- iter: 352/477
[A[ATraining Step: 177  | total loss: [1m[32m0.09754[0m[0m | time: 7.904s
[2K
| Adam | epoch: 012 | loss: 0.09754 - acc: 0.9675 -- iter: 384/477
[A[ATraining Step: 178  | total loss: [1m[32m0.09488[0m[0m | time: 8.560s
[2K
| Adam | epoch: 012 | loss: 0.09488 - acc: 0.9676 -- iter: 416/477
[A[ATraining Step: 179  | total loss: [1m[32m0.09113[0m[0m | time: 9.220s
[2K
| Adam | epoch: 012 | loss: 0.09113 - acc: 0.9677 -- iter: 448/477
[A[ATraining Step: 180  | total loss: [1m[32m0.08385[0m[0m | time: 10.876s
[2K
| Adam | epoch: 012 | loss: 0.08385 - acc: 0.9710 | val_loss: 0.19745 - val_acc: 0.8933 -- iter: 477/477
--
Training Step: 181  | total loss: [1m[32m0.08034[0m[0m | time: 0.667s
[2K
| Adam | epoch: 013 | loss: 0.08034 - acc: 0.9707 -- iter: 032/477
[A[ATraining Step: 182  | total loss: [1m[32m0.07643[0m[0m | time: 1.343s
[2K
| Adam | epoch: 013 | loss: 0.07643 - acc: 0.9737 -- iter: 064/477
[A[ATraining Step: 183  | total loss: [1m[32m0.06937[0m[0m | time: 1.999s
[2K
| Adam | epoch: 013 | loss: 0.06937 - acc: 0.9763 -- iter: 096/477
[A[ATraining Step: 184  | total loss: [1m[32m0.06428[0m[0m | time: 2.647s
[2K
| Adam | epoch: 013 | loss: 0.06428 - acc: 0.9787 -- iter: 128/477
[A[ATraining Step: 185  | total loss: [1m[32m0.06212[0m[0m | time: 3.331s
[2K
| Adam | epoch: 013 | loss: 0.06212 - acc: 0.9808 -- iter: 160/477
[A[ATraining Step: 186  | total loss: [1m[32m0.05970[0m[0m | time: 3.974s
[2K
| Adam | epoch: 013 | loss: 0.05970 - acc: 0.9827 -- iter: 192/477
[A[ATraining Step: 187  | total loss: [1m[32m0.05705[0m[0m | time: 4.635s
[2K
| Adam | epoch: 013 | loss: 0.05705 - acc: 0.9845 -- iter: 224/477
[A[ATraining Step: 188  | total loss: [1m[32m0.05393[0m[0m | time: 5.319s
[2K
| Adam | epoch: 013 | loss: 0.05393 - acc: 0.9860 -- iter: 256/477
[A[ATraining Step: 189  | total loss: [1m[32m0.05301[0m[0m | time: 5.961s
[2K
| Adam | epoch: 013 | loss: 0.05301 - acc: 0.9874 -- iter: 288/477
[A[ATraining Step: 190  | total loss: [1m[32m0.06253[0m[0m | time: 6.606s
[2K
| Adam | epoch: 013 | loss: 0.06253 - acc: 0.9824 -- iter: 320/477
[A[ATraining Step: 191  | total loss: [1m[32m0.07043[0m[0m | time: 7.205s
[2K
| Adam | epoch: 013 | loss: 0.07043 - acc: 0.9748 -- iter: 352/477
[A[ATraining Step: 192  | total loss: [1m[32m0.10010[0m[0m | time: 7.815s
[2K
| Adam | epoch: 013 | loss: 0.10010 - acc: 0.9739 -- iter: 384/477
[A[ATraining Step: 193  | total loss: [1m[32m0.09168[0m[0m | time: 8.463s
[2K
| Adam | epoch: 013 | loss: 0.09168 - acc: 0.9765 -- iter: 416/477
[A[ATraining Step: 194  | total loss: [1m[32m0.10795[0m[0m | time: 9.125s
[2K
| Adam | epoch: 013 | loss: 0.10795 - acc: 0.9663 -- iter: 448/477
[A[ATraining Step: 195  | total loss: [1m[32m0.10399[0m[0m | time: 10.764s
[2K
| Adam | epoch: 013 | loss: 0.10399 - acc: 0.9666 | val_loss: 0.28643 - val_acc: 0.9133 -- iter: 477/477
--
Training Step: 196  | total loss: [1m[32m0.09558[0m[0m | time: 0.642s
[2K
| Adam | epoch: 014 | loss: 0.09558 - acc: 0.9699 -- iter: 032/477
[A[ATraining Step: 197  | total loss: [1m[32m0.09076[0m[0m | time: 1.324s
[2K
| Adam | epoch: 014 | loss: 0.09076 - acc: 0.9698 -- iter: 064/477
[A[ATraining Step: 198  | total loss: [1m[32m0.10377[0m[0m | time: 1.984s
[2K
| Adam | epoch: 014 | loss: 0.10377 - acc: 0.9634 -- iter: 096/477
[A[ATraining Step: 199  | total loss: [1m[32m0.11488[0m[0m | time: 2.654s
[2K
| Adam | epoch: 014 | loss: 0.11488 - acc: 0.9577 -- iter: 128/477
[A[ATraining Step: 200  | total loss: [1m[32m0.10576[0m[0m | time: 4.328s
[2K
| Adam | epoch: 014 | loss: 0.10576 - acc: 0.9620 | val_loss: 0.45951 - val_acc: 0.8467 -- iter: 160/477
--
Training Step: 201  | total loss: [1m[32m0.10013[0m[0m | time: 5.006s
[2K
| Adam | epoch: 014 | loss: 0.10013 - acc: 0.9658 -- iter: 192/477
[A[ATraining Step: 202  | total loss: [1m[32m0.10545[0m[0m | time: 5.652s
[2K
| Adam | epoch: 014 | loss: 0.10545 - acc: 0.9598 -- iter: 224/477
[A[ATraining Step: 203  | total loss: [1m[32m0.12179[0m[0m | time: 6.316s
[2K
| Adam | epoch: 014 | loss: 0.12179 - acc: 0.9576 -- iter: 256/477
[A[ATraining Step: 204  | total loss: [1m[32m0.11310[0m[0m | time: 6.984s
[2K
| Adam | epoch: 014 | loss: 0.11310 - acc: 0.9618 -- iter: 288/477
[A[ATraining Step: 205  | total loss: [1m[32m0.10391[0m[0m | time: 7.656s
[2K
| Adam | epoch: 014 | loss: 0.10391 - acc: 0.9656 -- iter: 320/477
[A[ATraining Step: 206  | total loss: [1m[32m0.09711[0m[0m | time: 8.321s
[2K
| Adam | epoch: 014 | loss: 0.09711 - acc: 0.9691 -- iter: 352/477
[A[ATraining Step: 207  | total loss: [1m[32m0.10606[0m[0m | time: 8.913s
[2K
| Adam | epoch: 014 | loss: 0.10606 - acc: 0.9628 -- iter: 384/477
[A[ATraining Step: 208  | total loss: [1m[32m0.14525[0m[0m | time: 9.519s
[2K
| Adam | epoch: 014 | loss: 0.14525 - acc: 0.9596 -- iter: 416/477
[A[ATraining Step: 209  | total loss: [1m[32m0.13214[0m[0m | time: 10.208s
[2K
| Adam | epoch: 014 | loss: 0.13214 - acc: 0.9637 -- iter: 448/477
[A[ATraining Step: 210  | total loss: [1m[32m0.12021[0m[0m | time: 11.881s
[2K
| Adam | epoch: 014 | loss: 0.12021 - acc: 0.9673 | val_loss: 0.37514 - val_acc: 0.8733 -- iter: 477/477
--
Training Step: 211  | total loss: [1m[32m0.11068[0m[0m | time: 0.641s
[2K
| Adam | epoch: 015 | loss: 0.11068 - acc: 0.9706 -- iter: 032/477
[A[ATraining Step: 212  | total loss: [1m[32m0.11226[0m[0m | time: 1.294s
[2K
| Adam | epoch: 015 | loss: 0.11226 - acc: 0.9704 -- iter: 064/477
[A[ATraining Step: 213  | total loss: [1m[32m0.10597[0m[0m | time: 1.952s
[2K
| Adam | epoch: 015 | loss: 0.10597 - acc: 0.9733 -- iter: 096/477
[A[ATraining Step: 214  | total loss: [1m[32m0.09838[0m[0m | time: 2.631s
[2K
| Adam | epoch: 015 | loss: 0.09838 - acc: 0.9760 -- iter: 128/477
[A[ATraining Step: 215  | total loss: [1m[32m0.09614[0m[0m | time: 3.286s
[2K
| Adam | epoch: 015 | loss: 0.09614 - acc: 0.9753 -- iter: 160/477
[A[ATraining Step: 216  | total loss: [1m[32m0.09292[0m[0m | time: 3.945s
[2K
| Adam | epoch: 015 | loss: 0.09292 - acc: 0.9746 -- iter: 192/477
[A[ATraining Step: 217  | total loss: [1m[32m0.08592[0m[0m | time: 4.622s
[2K
| Adam | epoch: 015 | loss: 0.08592 - acc: 0.9772 -- iter: 224/477
[A[ATraining Step: 218  | total loss: [1m[32m0.08233[0m[0m | time: 5.298s
[2K
| Adam | epoch: 015 | loss: 0.08233 - acc: 0.9794 -- iter: 256/477
[A[ATraining Step: 219  | total loss: [1m[32m0.07854[0m[0m | time: 5.935s
[2K
| Adam | epoch: 015 | loss: 0.07854 - acc: 0.9815 -- iter: 288/477
[A[ATraining Step: 220  | total loss: [1m[32m0.07506[0m[0m | time: 6.589s
[2K
| Adam | epoch: 015 | loss: 0.07506 - acc: 0.9802 -- iter: 320/477
[A[ATraining Step: 221  | total loss: [1m[32m0.06860[0m[0m | time: 7.260s
[2K
| Adam | epoch: 015 | loss: 0.06860 - acc: 0.9822 -- iter: 352/477
[A[ATraining Step: 222  | total loss: [1m[32m0.07070[0m[0m | time: 7.895s
[2K
| Adam | epoch: 015 | loss: 0.07070 - acc: 0.9809 -- iter: 384/477
[A[ATraining Step: 223  | total loss: [1m[32m0.06568[0m[0m | time: 8.492s
[2K
| Adam | epoch: 015 | loss: 0.06568 - acc: 0.9828 -- iter: 416/477
[A[ATraining Step: 224  | total loss: [1m[32m0.05962[0m[0m | time: 9.109s
[2K
| Adam | epoch: 015 | loss: 0.05962 - acc: 0.9845 -- iter: 448/477
[A[ATraining Step: 225  | total loss: [1m[32m0.05428[0m[0m | time: 10.764s
[2K
| Adam | epoch: 015 | loss: 0.05428 - acc: 0.9860 | val_loss: 0.22937 - val_acc: 0.9200 -- iter: 477/477
--
Validation AUC:0.9833484162895927
Validation AUPRC:0.9822322983687843
Test AUC:0.9783549783549783
Test AUPRC:0.972146063422014
BestTestF1Score	0.93	0.87	0.93	0.9	0.95	63	7	77	3	0.81
BestTestMCCScore	0.93	0.87	0.93	0.9	0.95	63	7	77	3	0.81
BestTestAccuracyScore	0.93	0.87	0.93	0.9	0.95	63	7	77	3	0.81
BestValidationF1Score	0.94	0.89	0.95	0.93	0.95	62	5	80	3	0.81
BestValidationMCC	0.94	0.89	0.95	0.93	0.95	62	5	80	3	0.81
BestValidationAccuracy	0.94	0.89	0.95	0.93	0.95	62	5	80	3	0.81
TestPredictions (Threshold:0.81)
CHEMBL3116414,FP,INACT,1.0	CHEMBL2419528,TP,ACT,1.0	CHEMBL3752639,TP,ACT,1.0	CHEMBL1310039,TN,INACT,0.0	CHEMBL251005,TN,INACT,0.09000000357627869	CHEMBL1354748,TN,INACT,0.029999999329447746	CHEMBL108202,TN,INACT,0.019999999552965164	CHEMBL2391561,TP,ACT,1.0	CHEMBL2393183,TP,ACT,1.0	CHEMBL1471736,FP,INACT,0.9900000095367432	CHEMBL1801938,TP,ACT,0.9900000095367432	CHEMBL1801865,FN,ACT,0.4300000071525574	CHEMBL2419534,TP,ACT,1.0	CHEMBL2391587,TP,ACT,0.949999988079071	CHEMBL1386457,TN,INACT,0.0	CHEMBL3127525,TP,ACT,1.0	CHEMBL1550451,TN,INACT,0.009999999776482582	CHEMBL1801558,TP,ACT,1.0	CHEMBL2419503,TP,ACT,1.0	CHEMBL3094229,TP,ACT,0.9399999976158142	CHEMBL1533455,TN,INACT,0.4699999988079071	CHEMBL1338422,TN,INACT,0.0	CHEMBL3260357,TP,ACT,1.0	CHEMBL2419505,TP,ACT,1.0	CHEMBL2420642,TP,ACT,1.0	CHEMBL2420639,TP,ACT,0.9900000095367432	CHEMBL1098101,TN,INACT,0.009999999776482582	CHEMBL1394618,TN,INACT,0.14000000059604645	CHEMBL1473046,TN,INACT,0.0	CHEMBL1098104,TN,INACT,0.0	CHEMBL3116419,TN,INACT,0.1599999964237213	CHEMBL2419533,TP,ACT,1.0	CHEMBL1531156,TN,INACT,0.029999999329447746	CHEMBL1603586,TN,INACT,0.009999999776482582	CHEMBL3260347,TP,ACT,1.0	CHEMBL1362536,TN,INACT,0.019999999552965164	CHEMBL1462387,TN,INACT,0.019999999552965164	CHEMBL3127516,TN,INACT,0.009999999776482582	CHEMBL1334684,TN,INACT,0.029999999329447746	CHEMBL386614,TN,INACT,0.07999999821186066	CHEMBL2391554,TP,ACT,1.0	CHEMBL3094250,FN,ACT,0.07000000029802322	CHEMBL3127508,TP,ACT,1.0	CHEMBL1507894,TN,INACT,0.0	CHEMBL1801866,TP,ACT,0.8600000143051147	CHEMBL1594229,TN,INACT,0.20000000298023224	CHEMBL1412250,TP,ACT,1.0	CHEMBL1603321,TN,INACT,0.7599999904632568	CHEMBL2391567,TP,ACT,1.0	CHEMBL3394731,TP,ACT,1.0	CHEMBL2417797,TN,INACT,0.019999999552965164	CHEMBL1591937,FP,INACT,0.8899999856948853	CHEMBL3127499,TP,ACT,1.0	CHEMBL3116428,TP,ACT,0.8199999928474426	CHEMBL2420643,TP,ACT,1.0	CHEMBL1589854,FP,INACT,0.8100000023841858	CHEMBL1473745,TN,INACT,0.0	CHEMBL2391581,TP,ACT,1.0	CHEMBL1370718,TN,INACT,0.07000000029802322	CHEMBL1383060,TN,INACT,0.019999999552965164	CHEMBL1801565,TP,ACT,1.0	CHEMBL3116422,FP,INACT,0.9599999785423279	CHEMBL1498324,TN,INACT,0.009999999776482582	CHEMBL3116416,TP,ACT,0.9900000095367432	CHEMBL1338901,TN,INACT,0.0	CHEMBL3194497,TN,INACT,0.009999999776482582	CHEMBL1080550,TN,INACT,0.009999999776482582	CHEMBL3116420,TP,ACT,0.9800000190734863	CHEMBL3785581,TN,INACT,0.03999999910593033	CHEMBL3116399,TP,ACT,1.0	CHEMBL1590534,TN,INACT,0.009999999776482582	CHEMBL1342737,TN,INACT,0.019999999552965164	CHEMBL2391559,TP,ACT,1.0	CHEMBL2391562,TP,ACT,1.0	CHEMBL1801561,TP,ACT,0.9900000095367432	CHEMBL2417798,TP,ACT,0.8100000023841858	CHEMBL1343161,TN,INACT,0.0	CHEMBL1494030,TN,INACT,0.009999999776482582	CHEMBL1426486,TN,INACT,0.03999999910593033	CHEMBL1468750,TN,INACT,0.27000001072883606	CHEMBL1463084,TN,INACT,0.1899999976158142	CHEMBL1334011,TN,INACT,0.0	CHEMBL2419512,TP,ACT,1.0	CHEMBL3189671,TN,INACT,0.019999999552965164	CHEMBL1412456,TN,INACT,0.09000000357627869	CHEMBL2312397,TN,INACT,0.03999999910593033	CHEMBL2419520,TP,ACT,1.0	CHEMBL1468861,TN,INACT,0.05000000074505806	CHEMBL3116421,TP,ACT,1.0	CHEMBL1390609,TN,INACT,0.009999999776482582	CHEMBL1439533,TN,INACT,0.0	CHEMBL1418330,TN,INACT,0.019999999552965164	CHEMBL1522386,FP,INACT,0.9900000095367432	CHEMBL1589637,TN,INACT,0.17000000178813934	CHEMBL1391541,TN,INACT,0.0	CHEMBL1541408,TN,INACT,0.019999999552965164	CHEMBL3260353,TP,ACT,1.0	CHEMBL3116397,FN,ACT,0.47999998927116394	CHEMBL2419519,TP,ACT,1.0	CHEMBL212852,FP,INACT,1.0	CHEMBL2373047,TN,INACT,0.009999999776482582	CHEMBL3116412,TP,ACT,1.0	CHEMBL3193608,TN,INACT,0.009999999776482582	CHEMBL1472072,TN,INACT,0.009999999776482582	CHEMBL3127505,TP,ACT,1.0	CHEMBL1531279,TN,INACT,0.009999999776482582	CHEMBL1432372,TN,INACT,0.009999999776482582	CHEMBL1966622,TN,INACT,0.03999999910593033	CHEMBL2420640,TP,ACT,1.0	CHEMBL1370785,TN,INACT,0.0	CHEMBL2420644,TP,ACT,1.0	CHEMBL2393191,TP,ACT,1.0	CHEMBL3127497,TP,ACT,0.9399999976158142	CHEMBL2419535,TP,ACT,1.0	CHEMBL3098510,TP,ACT,1.0	CHEMBL3394715,TP,ACT,1.0	CHEMBL2420673,TP,ACT,1.0	CHEMBL2417788,TP,ACT,1.0	CHEMBL3260355,TP,ACT,1.0	CHEMBL3196514,TN,INACT,0.0	CHEMBL1508370,TN,INACT,0.009999999776482582	CHEMBL430193,TN,INACT,0.019999999552965164	CHEMBL2419530,TP,ACT,1.0	CHEMBL1417788,TN,INACT,0.11999999731779099	CHEMBL3127521,TP,ACT,1.0	CHEMBL1460825,TN,INACT,0.029999999329447746	CHEMBL1354701,TN,INACT,0.20000000298023224	CHEMBL2393186,TP,ACT,1.0	CHEMBL2419508,TP,ACT,1.0	CHEMBL1486018,TN,INACT,0.0	CHEMBL536972,TN,INACT,0.09000000357627869	CHEMBL1325385,TN,INACT,0.800000011920929	CHEMBL1393393,TN,INACT,0.019999999552965164	CHEMBL2420635,TP,ACT,1.0	CHEMBL17289,TP,ACT,0.9900000095367432	CHEMBL1323285,TN,INACT,0.05000000074505806	CHEMBL3208441,TN,INACT,0.0	CHEMBL2312398,TN,INACT,0.009999999776482582	CHEMBL1561303,TN,INACT,0.3499999940395355	CHEMBL2419518,TP,ACT,1.0	CHEMBL1890899,TN,INACT,0.550000011920929	CHEMBL3094238,TP,ACT,0.9800000190734863	CHEMBL1468530,TN,INACT,0.019999999552965164	CHEMBL1990804,TN,INACT,0.009999999776482582	CHEMBL2393164,TP,ACT,1.0	CHEMBL3190200,TN,INACT,0.019999999552965164	CHEMBL2393192,TP,ACT,1.0	CHEMBL1994048,TN,INACT,0.009999999776482582	CHEMBL3754708,TP,ACT,0.9800000190734863	CHEMBL1566678,TN,INACT,0.4399999976158142	

