CNNModel CHEMBL1899 adam 0.0005 30 128 0 0.6 False True
Number of active compounds :	400
Number of inactive compounds :	270
---------------------------------
Run id: CNNModel_CHEMBL1899_adam_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1899_adam_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 428
Validation samples: 134
--
Training Step: 1  | time: 0.829s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/428
[A[ATraining Step: 2  | total loss: [1m[32m0.62350[0m[0m | time: 1.499s
[2K
| Adam | epoch: 001 | loss: 0.62350 - acc: 0.5625 -- iter: 064/428
[A[ATraining Step: 3  | total loss: [1m[32m0.67894[0m[0m | time: 2.184s
[2K
| Adam | epoch: 001 | loss: 0.67894 - acc: 0.5881 -- iter: 096/428
[A[ATraining Step: 4  | total loss: [1m[32m0.68305[0m[0m | time: 2.857s
[2K
| Adam | epoch: 001 | loss: 0.68305 - acc: 0.6158 -- iter: 128/428
[A[ATraining Step: 5  | total loss: [1m[32m0.65988[0m[0m | time: 3.516s
[2K
| Adam | epoch: 001 | loss: 0.65988 - acc: 0.7087 -- iter: 160/428
[A[ATraining Step: 6  | total loss: [1m[32m0.65355[0m[0m | time: 4.193s
[2K
| Adam | epoch: 001 | loss: 0.65355 - acc: 0.6750 -- iter: 192/428
[A[ATraining Step: 7  | total loss: [1m[32m0.63059[0m[0m | time: 4.873s
[2K
| Adam | epoch: 001 | loss: 0.63059 - acc: 0.6825 -- iter: 224/428
[A[ATraining Step: 8  | total loss: [1m[32m0.70446[0m[0m | time: 5.529s
[2K
| Adam | epoch: 001 | loss: 0.70446 - acc: 0.6326 -- iter: 256/428
[A[ATraining Step: 9  | total loss: [1m[32m0.68261[0m[0m | time: 6.182s
[2K
| Adam | epoch: 001 | loss: 0.68261 - acc: 0.6451 -- iter: 288/428
[A[ATraining Step: 10  | total loss: [1m[32m0.70949[0m[0m | time: 6.846s
[2K
| Adam | epoch: 001 | loss: 0.70949 - acc: 0.5882 -- iter: 320/428
[A[ATraining Step: 11  | total loss: [1m[32m0.70948[0m[0m | time: 7.512s
[2K
| Adam | epoch: 001 | loss: 0.70948 - acc: 0.5612 -- iter: 352/428
[A[ATraining Step: 12  | total loss: [1m[32m0.69458[0m[0m | time: 8.181s
[2K
| Adam | epoch: 001 | loss: 0.69458 - acc: 0.5759 -- iter: 384/428
[A[ATraining Step: 13  | total loss: [1m[32m0.68806[0m[0m | time: 8.851s
[2K
| Adam | epoch: 001 | loss: 0.68806 - acc: 0.5835 -- iter: 416/428
[A[ATraining Step: 14  | total loss: [1m[32m0.67856[0m[0m | time: 10.132s
[2K
| Adam | epoch: 001 | loss: 0.67856 - acc: 0.6388 | val_loss: 0.68409 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 15  | total loss: [1m[32m0.68848[0m[0m | time: 0.269s
[2K
| Adam | epoch: 002 | loss: 0.68848 - acc: 0.5519 -- iter: 032/428
[A[ATraining Step: 16  | total loss: [1m[32m0.69322[0m[0m | time: 0.929s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5012 -- iter: 064/428
[A[ATraining Step: 17  | total loss: [1m[32m0.69372[0m[0m | time: 1.596s
[2K
| Adam | epoch: 002 | loss: 0.69372 - acc: 0.5008 -- iter: 096/428
[A[ATraining Step: 18  | total loss: [1m[32m0.69013[0m[0m | time: 2.253s
[2K
| Adam | epoch: 002 | loss: 0.69013 - acc: 0.5654 -- iter: 128/428
[A[ATraining Step: 19  | total loss: [1m[32m0.69181[0m[0m | time: 2.903s
[2K
| Adam | epoch: 002 | loss: 0.69181 - acc: 0.5332 -- iter: 160/428
[A[ATraining Step: 20  | total loss: [1m[32m0.69191[0m[0m | time: 3.567s
[2K
| Adam | epoch: 002 | loss: 0.69191 - acc: 0.5326 -- iter: 192/428
[A[ATraining Step: 21  | total loss: [1m[32m0.69229[0m[0m | time: 4.221s
[2K
| Adam | epoch: 002 | loss: 0.69229 - acc: 0.5225 -- iter: 224/428
[A[ATraining Step: 22  | total loss: [1m[32m0.69148[0m[0m | time: 4.918s
[2K
| Adam | epoch: 002 | loss: 0.69148 - acc: 0.5532 -- iter: 256/428
[A[ATraining Step: 23  | total loss: [1m[32m0.69074[0m[0m | time: 5.582s
[2K
| Adam | epoch: 002 | loss: 0.69074 - acc: 0.5741 -- iter: 288/428
[A[ATraining Step: 24  | total loss: [1m[32m0.69137[0m[0m | time: 6.285s
[2K
| Adam | epoch: 002 | loss: 0.69137 - acc: 0.5532 -- iter: 320/428
[A[ATraining Step: 25  | total loss: [1m[32m0.69133[0m[0m | time: 6.937s
[2K
| Adam | epoch: 002 | loss: 0.69133 - acc: 0.5558 -- iter: 352/428
[A[ATraining Step: 26  | total loss: [1m[32m0.68889[0m[0m | time: 7.603s
[2K
| Adam | epoch: 002 | loss: 0.68889 - acc: 0.6320 -- iter: 384/428
[A[ATraining Step: 27  | total loss: [1m[32m0.68969[0m[0m | time: 8.251s
[2K
| Adam | epoch: 002 | loss: 0.68969 - acc: 0.6061 -- iter: 416/428
[A[ATraining Step: 28  | total loss: [1m[32m0.68943[0m[0m | time: 9.903s
[2K
| Adam | epoch: 002 | loss: 0.68943 - acc: 0.6108 | val_loss: 0.68835 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 29  | total loss: [1m[32m0.69016[0m[0m | time: 0.286s
[2K
| Adam | epoch: 003 | loss: 0.69016 - acc: 0.5915 -- iter: 032/428
[A[ATraining Step: 30  | total loss: [1m[32m0.69011[0m[0m | time: 0.542s
[2K
| Adam | epoch: 003 | loss: 0.69011 - acc: 0.5895 -- iter: 064/428
[A[ATraining Step: 31  | total loss: [1m[32m0.68984[0m[0m | time: 1.215s
[2K
| Adam | epoch: 003 | loss: 0.68984 - acc: 0.5881 -- iter: 096/428
[A[ATraining Step: 32  | total loss: [1m[32m0.68837[0m[0m | time: 1.875s
[2K
| Adam | epoch: 003 | loss: 0.68837 - acc: 0.6105 -- iter: 128/428
[A[ATraining Step: 33  | total loss: [1m[32m0.68755[0m[0m | time: 2.534s
[2K
| Adam | epoch: 003 | loss: 0.68755 - acc: 0.6205 -- iter: 160/428
[A[ATraining Step: 34  | total loss: [1m[32m0.68578[0m[0m | time: 3.198s
[2K
| Adam | epoch: 003 | loss: 0.68578 - acc: 0.6416 -- iter: 192/428
[A[ATraining Step: 35  | total loss: [1m[32m0.68811[0m[0m | time: 3.875s
[2K
| Adam | epoch: 003 | loss: 0.68811 - acc: 0.6054 -- iter: 224/428
[A[ATraining Step: 36  | total loss: [1m[32m0.68888[0m[0m | time: 4.517s
[2K
| Adam | epoch: 003 | loss: 0.68888 - acc: 0.5902 -- iter: 256/428
[A[ATraining Step: 37  | total loss: [1m[32m0.68720[0m[0m | time: 5.191s
[2K
| Adam | epoch: 003 | loss: 0.68720 - acc: 0.6034 -- iter: 288/428
[A[ATraining Step: 38  | total loss: [1m[32m0.68806[0m[0m | time: 5.845s
[2K
| Adam | epoch: 003 | loss: 0.68806 - acc: 0.5893 -- iter: 320/428
[A[ATraining Step: 39  | total loss: [1m[32m0.68732[0m[0m | time: 6.491s
[2K
| Adam | epoch: 003 | loss: 0.68732 - acc: 0.5902 -- iter: 352/428
[A[ATraining Step: 40  | total loss: [1m[32m0.68505[0m[0m | time: 7.179s
[2K
| Adam | epoch: 003 | loss: 0.68505 - acc: 0.6026 -- iter: 384/428
[A[ATraining Step: 41  | total loss: [1m[32m0.68859[0m[0m | time: 7.835s
[2K
| Adam | epoch: 003 | loss: 0.68859 - acc: 0.5722 -- iter: 416/428
[A[ATraining Step: 42  | total loss: [1m[32m0.68903[0m[0m | time: 9.503s
[2K
| Adam | epoch: 003 | loss: 0.68903 - acc: 0.5649 | val_loss: 0.67803 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 43  | total loss: [1m[32m0.69402[0m[0m | time: 0.702s
[2K
| Adam | epoch: 004 | loss: 0.69402 - acc: 0.5314 -- iter: 032/428
[A[ATraining Step: 44  | total loss: [1m[32m0.69169[0m[0m | time: 0.963s
[2K
| Adam | epoch: 004 | loss: 0.69169 - acc: 0.5422 -- iter: 064/428
[A[ATraining Step: 45  | total loss: [1m[32m0.68777[0m[0m | time: 1.227s
[2K
| Adam | epoch: 004 | loss: 0.68777 - acc: 0.5633 -- iter: 096/428
[A[ATraining Step: 46  | total loss: [1m[32m0.68438[0m[0m | time: 1.879s
[2K
| Adam | epoch: 004 | loss: 0.68438 - acc: 0.5805 -- iter: 128/428
[A[ATraining Step: 47  | total loss: [1m[32m0.68167[0m[0m | time: 2.535s
[2K
| Adam | epoch: 004 | loss: 0.68167 - acc: 0.5929 -- iter: 160/428
[A[ATraining Step: 48  | total loss: [1m[32m0.68228[0m[0m | time: 3.193s
[2K
| Adam | epoch: 004 | loss: 0.68228 - acc: 0.5880 -- iter: 192/428
[A[ATraining Step: 49  | total loss: [1m[32m0.68373[0m[0m | time: 3.861s
[2K
| Adam | epoch: 004 | loss: 0.68373 - acc: 0.5791 -- iter: 224/428
[A[ATraining Step: 50  | total loss: [1m[32m0.67749[0m[0m | time: 4.528s
[2K
| Adam | epoch: 004 | loss: 0.67749 - acc: 0.6007 -- iter: 256/428
[A[ATraining Step: 51  | total loss: [1m[32m0.68455[0m[0m | time: 5.171s
[2K
| Adam | epoch: 004 | loss: 0.68455 - acc: 0.5758 -- iter: 288/428
[A[ATraining Step: 52  | total loss: [1m[32m0.68431[0m[0m | time: 5.831s
[2K
| Adam | epoch: 004 | loss: 0.68431 - acc: 0.5738 -- iter: 320/428
[A[ATraining Step: 53  | total loss: [1m[32m0.67954[0m[0m | time: 6.484s
[2K
| Adam | epoch: 004 | loss: 0.67954 - acc: 0.5860 -- iter: 352/428
[A[ATraining Step: 54  | total loss: [1m[32m0.67398[0m[0m | time: 7.133s
[2K
| Adam | epoch: 004 | loss: 0.67398 - acc: 0.6007 -- iter: 384/428
[A[ATraining Step: 55  | total loss: [1m[32m0.67281[0m[0m | time: 7.787s
[2K
| Adam | epoch: 004 | loss: 0.67281 - acc: 0.6042 -- iter: 416/428
[A[ATraining Step: 56  | total loss: [1m[32m0.66922[0m[0m | time: 9.444s
[2K
| Adam | epoch: 004 | loss: 0.66922 - acc: 0.6115 | val_loss: 0.66888 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 57  | total loss: [1m[32m0.67533[0m[0m | time: 0.678s
[2K
| Adam | epoch: 005 | loss: 0.67533 - acc: 0.6004 -- iter: 032/428
[A[ATraining Step: 58  | total loss: [1m[32m0.68298[0m[0m | time: 1.340s
[2K
| Adam | epoch: 005 | loss: 0.68298 - acc: 0.5867 -- iter: 064/428
[A[ATraining Step: 59  | total loss: [1m[32m0.67807[0m[0m | time: 1.602s
[2K
| Adam | epoch: 005 | loss: 0.67807 - acc: 0.5961 -- iter: 096/428
[A[ATraining Step: 60  | total loss: [1m[32m0.68936[0m[0m | time: 1.887s
[2K
| Adam | epoch: 005 | loss: 0.68936 - acc: 0.5723 -- iter: 128/428
[A[ATraining Step: 61  | total loss: [1m[32m0.69675[0m[0m | time: 2.557s
[2K
| Adam | epoch: 005 | loss: 0.69675 - acc: 0.5520 -- iter: 160/428
[A[ATraining Step: 62  | total loss: [1m[32m0.69684[0m[0m | time: 3.233s
[2K
| Adam | epoch: 005 | loss: 0.69684 - acc: 0.5493 -- iter: 192/428
[A[ATraining Step: 63  | total loss: [1m[32m0.69442[0m[0m | time: 3.900s
[2K
| Adam | epoch: 005 | loss: 0.69442 - acc: 0.5550 -- iter: 224/428
[A[ATraining Step: 64  | total loss: [1m[32m0.69242[0m[0m | time: 4.584s
[2K
| Adam | epoch: 005 | loss: 0.69242 - acc: 0.5598 -- iter: 256/428
[A[ATraining Step: 65  | total loss: [1m[32m0.69156[0m[0m | time: 5.222s
[2K
| Adam | epoch: 005 | loss: 0.69156 - acc: 0.5601 -- iter: 288/428
[A[ATraining Step: 66  | total loss: [1m[32m0.68971[0m[0m | time: 5.874s
[2K
| Adam | epoch: 005 | loss: 0.68971 - acc: 0.5680 -- iter: 320/428
[A[ATraining Step: 67  | total loss: [1m[32m0.68984[0m[0m | time: 6.530s
[2K
| Adam | epoch: 005 | loss: 0.68984 - acc: 0.5636 -- iter: 352/428
[A[ATraining Step: 68  | total loss: [1m[32m0.69154[0m[0m | time: 7.186s
[2K
| Adam | epoch: 005 | loss: 0.69154 - acc: 0.5487 -- iter: 384/428
[A[ATraining Step: 69  | total loss: [1m[32m0.69100[0m[0m | time: 7.841s
[2K
| Adam | epoch: 005 | loss: 0.69100 - acc: 0.5503 -- iter: 416/428
[A[ATraining Step: 70  | total loss: [1m[32m0.69013[0m[0m | time: 9.500s
[2K
| Adam | epoch: 005 | loss: 0.69013 - acc: 0.5553 | val_loss: 0.68226 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 71  | total loss: [1m[32m0.68781[0m[0m | time: 0.675s
[2K
| Adam | epoch: 006 | loss: 0.68781 - acc: 0.5739 -- iter: 032/428
[A[ATraining Step: 72  | total loss: [1m[32m0.68509[0m[0m | time: 1.346s
[2K
| Adam | epoch: 006 | loss: 0.68509 - acc: 0.5973 -- iter: 064/428
[A[ATraining Step: 73  | total loss: [1m[32m0.68576[0m[0m | time: 2.005s
[2K
| Adam | epoch: 006 | loss: 0.68576 - acc: 0.5899 -- iter: 096/428
[A[ATraining Step: 74  | total loss: [1m[32m0.68593[0m[0m | time: 2.267s
[2K
| Adam | epoch: 006 | loss: 0.68593 - acc: 0.5869 -- iter: 128/428
[A[ATraining Step: 75  | total loss: [1m[32m0.68791[0m[0m | time: 2.521s
[2K
| Adam | epoch: 006 | loss: 0.68791 - acc: 0.5685 -- iter: 160/428
[A[ATraining Step: 76  | total loss: [1m[32m0.68958[0m[0m | time: 3.158s
[2K
| Adam | epoch: 006 | loss: 0.68958 - acc: 0.5522 -- iter: 192/428
[A[ATraining Step: 77  | total loss: [1m[32m0.68903[0m[0m | time: 3.831s
[2K
| Adam | epoch: 006 | loss: 0.68903 - acc: 0.5566 -- iter: 224/428
[A[ATraining Step: 78  | total loss: [1m[32m0.68782[0m[0m | time: 4.487s
[2K
| Adam | epoch: 006 | loss: 0.68782 - acc: 0.5670 -- iter: 256/428
[A[ATraining Step: 79  | total loss: [1m[32m0.68788[0m[0m | time: 5.165s
[2K
| Adam | epoch: 006 | loss: 0.68788 - acc: 0.5666 -- iter: 288/428
[A[ATraining Step: 80  | total loss: [1m[32m0.68602[0m[0m | time: 5.831s
[2K
| Adam | epoch: 006 | loss: 0.68602 - acc: 0.5821 -- iter: 320/428
[A[ATraining Step: 81  | total loss: [1m[32m0.68727[0m[0m | time: 6.472s
[2K
| Adam | epoch: 006 | loss: 0.68727 - acc: 0.5707 -- iter: 352/428
[A[ATraining Step: 82  | total loss: [1m[32m0.68733[0m[0m | time: 7.139s
[2K
| Adam | epoch: 006 | loss: 0.68733 - acc: 0.5698 -- iter: 384/428
[A[ATraining Step: 83  | total loss: [1m[32m0.68694[0m[0m | time: 7.830s
[2K
| Adam | epoch: 006 | loss: 0.68694 - acc: 0.5722 -- iter: 416/428
[A[ATraining Step: 84  | total loss: [1m[32m0.68510[0m[0m | time: 9.494s
[2K
| Adam | epoch: 006 | loss: 0.68510 - acc: 0.5869 | val_loss: 0.68046 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 85  | total loss: [1m[32m0.68529[0m[0m | time: 0.645s
[2K
| Adam | epoch: 007 | loss: 0.68529 - acc: 0.5844 -- iter: 032/428
[A[ATraining Step: 86  | total loss: [1m[32m0.68427[0m[0m | time: 1.318s
[2K
| Adam | epoch: 007 | loss: 0.68427 - acc: 0.5916 -- iter: 064/428
[A[ATraining Step: 87  | total loss: [1m[32m0.68533[0m[0m | time: 1.957s
[2K
| Adam | epoch: 007 | loss: 0.68533 - acc: 0.5825 -- iter: 096/428
[A[ATraining Step: 88  | total loss: [1m[32m0.68718[0m[0m | time: 2.628s
[2K
| Adam | epoch: 007 | loss: 0.68718 - acc: 0.5680 -- iter: 128/428
[A[ATraining Step: 89  | total loss: [1m[32m0.68810[0m[0m | time: 2.885s
[2K
| Adam | epoch: 007 | loss: 0.68810 - acc: 0.5612 -- iter: 160/428
[A[ATraining Step: 90  | total loss: [1m[32m0.68636[0m[0m | time: 3.139s
[2K
| Adam | epoch: 007 | loss: 0.68636 - acc: 0.5717 -- iter: 192/428
[A[ATraining Step: 91  | total loss: [1m[32m0.68478[0m[0m | time: 3.812s
[2K
| Adam | epoch: 007 | loss: 0.68478 - acc: 0.5812 -- iter: 224/428
[A[ATraining Step: 92  | total loss: [1m[32m0.68348[0m[0m | time: 4.466s
[2K
| Adam | epoch: 007 | loss: 0.68348 - acc: 0.5887 -- iter: 256/428
[A[ATraining Step: 93  | total loss: [1m[32m0.68365[0m[0m | time: 5.101s
[2K
| Adam | epoch: 007 | loss: 0.68365 - acc: 0.5861 -- iter: 288/428
[A[ATraining Step: 94  | total loss: [1m[32m0.68552[0m[0m | time: 5.755s
[2K
| Adam | epoch: 007 | loss: 0.68552 - acc: 0.5744 -- iter: 320/428
[A[ATraining Step: 95  | total loss: [1m[32m0.68388[0m[0m | time: 6.455s
[2K
| Adam | epoch: 007 | loss: 0.68388 - acc: 0.5825 -- iter: 352/428
[A[ATraining Step: 96  | total loss: [1m[32m0.68528[0m[0m | time: 7.112s
[2K
| Adam | epoch: 007 | loss: 0.68528 - acc: 0.5743 -- iter: 384/428
[A[ATraining Step: 97  | total loss: [1m[32m0.68402[0m[0m | time: 7.763s
[2K
| Adam | epoch: 007 | loss: 0.68402 - acc: 0.5794 -- iter: 416/428
[A[ATraining Step: 98  | total loss: [1m[32m0.68350[0m[0m | time: 9.437s
[2K
| Adam | epoch: 007 | loss: 0.68350 - acc: 0.5808 | val_loss: 0.67394 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 99  | total loss: [1m[32m0.68228[0m[0m | time: 0.675s
[2K
| Adam | epoch: 008 | loss: 0.68228 - acc: 0.5852 -- iter: 032/428
[A[ATraining Step: 100  | total loss: [1m[32m0.68120[0m[0m | time: 1.343s
[2K
| Adam | epoch: 008 | loss: 0.68120 - acc: 0.5892 -- iter: 064/428
[A[ATraining Step: 101  | total loss: [1m[32m0.67856[0m[0m | time: 2.008s
[2K
| Adam | epoch: 008 | loss: 0.67856 - acc: 0.5990 -- iter: 096/428
[A[ATraining Step: 102  | total loss: [1m[32m0.67675[0m[0m | time: 2.652s
[2K
| Adam | epoch: 008 | loss: 0.67675 - acc: 0.6048 -- iter: 128/428
[A[ATraining Step: 103  | total loss: [1m[32m0.67754[0m[0m | time: 3.315s
[2K
| Adam | epoch: 008 | loss: 0.67754 - acc: 0.6005 -- iter: 160/428
[A[ATraining Step: 104  | total loss: [1m[32m0.67636[0m[0m | time: 3.581s
[2K
| Adam | epoch: 008 | loss: 0.67636 - acc: 0.6030 -- iter: 192/428
[A[ATraining Step: 105  | total loss: [1m[32m0.67966[0m[0m | time: 3.853s
[2K
| Adam | epoch: 008 | loss: 0.67966 - acc: 0.5927 -- iter: 224/428
[A[ATraining Step: 106  | total loss: [1m[32m0.68256[0m[0m | time: 4.529s
[2K
| Adam | epoch: 008 | loss: 0.68256 - acc: 0.5834 -- iter: 256/428
[A[ATraining Step: 107  | total loss: [1m[32m0.68166[0m[0m | time: 5.181s
[2K
| Adam | epoch: 008 | loss: 0.68166 - acc: 0.5844 -- iter: 288/428
[A[ATraining Step: 108  | total loss: [1m[32m0.68440[0m[0m | time: 5.845s
[2K
| Adam | epoch: 008 | loss: 0.68440 - acc: 0.5760 -- iter: 320/428
[A[ATraining Step: 109  | total loss: [1m[32m0.68205[0m[0m | time: 6.497s
[2K
| Adam | epoch: 008 | loss: 0.68205 - acc: 0.5809 -- iter: 352/428
[A[ATraining Step: 110  | total loss: [1m[32m0.68468[0m[0m | time: 7.161s
[2K
| Adam | epoch: 008 | loss: 0.68468 - acc: 0.5728 -- iter: 384/428
[A[ATraining Step: 111  | total loss: [1m[32m0.68266[0m[0m | time: 7.835s
[2K
| Adam | epoch: 008 | loss: 0.68266 - acc: 0.5780 -- iter: 416/428
[A[ATraining Step: 112  | total loss: [1m[32m0.68378[0m[0m | time: 9.498s
[2K
| Adam | epoch: 008 | loss: 0.68378 - acc: 0.5734 | val_loss: 0.66905 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 113  | total loss: [1m[32m0.68386[0m[0m | time: 0.678s
[2K
| Adam | epoch: 009 | loss: 0.68386 - acc: 0.5723 -- iter: 032/428
[A[ATraining Step: 114  | total loss: [1m[32m0.68095[0m[0m | time: 1.315s
[2K
| Adam | epoch: 009 | loss: 0.68095 - acc: 0.5807 -- iter: 064/428
[A[ATraining Step: 115  | total loss: [1m[32m0.68026[0m[0m | time: 2.002s
[2K
| Adam | epoch: 009 | loss: 0.68026 - acc: 0.5820 -- iter: 096/428
[A[ATraining Step: 116  | total loss: [1m[32m0.67845[0m[0m | time: 2.680s
[2K
| Adam | epoch: 009 | loss: 0.67845 - acc: 0.5863 -- iter: 128/428
[A[ATraining Step: 117  | total loss: [1m[32m0.67611[0m[0m | time: 3.339s
[2K
| Adam | epoch: 009 | loss: 0.67611 - acc: 0.5933 -- iter: 160/428
[A[ATraining Step: 118  | total loss: [1m[32m0.67471[0m[0m | time: 4.010s
[2K
| Adam | epoch: 009 | loss: 0.67471 - acc: 0.5964 -- iter: 192/428
[A[ATraining Step: 119  | total loss: [1m[32m0.67350[0m[0m | time: 4.273s
[2K
| Adam | epoch: 009 | loss: 0.67350 - acc: 0.5993 -- iter: 224/428
[A[ATraining Step: 120  | total loss: [1m[32m0.68357[0m[0m | time: 4.554s
[2K
| Adam | epoch: 009 | loss: 0.68357 - acc: 0.5727 -- iter: 256/428
[A[ATraining Step: 121  | total loss: [1m[32m0.69240[0m[0m | time: 5.199s
[2K
| Adam | epoch: 009 | loss: 0.69240 - acc: 0.5488 -- iter: 288/428
[A[ATraining Step: 122  | total loss: [1m[32m0.69059[0m[0m | time: 5.852s
[2K
| Adam | epoch: 009 | loss: 0.69059 - acc: 0.5533 -- iter: 320/428
[A[ATraining Step: 123  | total loss: [1m[32m0.69081[0m[0m | time: 6.536s
[2K
| Adam | epoch: 009 | loss: 0.69081 - acc: 0.5511 -- iter: 352/428
[A[ATraining Step: 124  | total loss: [1m[32m0.68763[0m[0m | time: 7.195s
[2K
| Adam | epoch: 009 | loss: 0.68763 - acc: 0.5616 -- iter: 384/428
[A[ATraining Step: 125  | total loss: [1m[32m0.68886[0m[0m | time: 7.851s
[2K
| Adam | epoch: 009 | loss: 0.68886 - acc: 0.5554 -- iter: 416/428
[A[ATraining Step: 126  | total loss: [1m[32m0.68690[0m[0m | time: 9.556s
[2K
| Adam | epoch: 009 | loss: 0.68690 - acc: 0.5624 | val_loss: 0.67385 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 127  | total loss: [1m[32m0.68673[0m[0m | time: 0.680s
[2K
| Adam | epoch: 010 | loss: 0.68673 - acc: 0.5624 -- iter: 032/428
[A[ATraining Step: 128  | total loss: [1m[32m0.68324[0m[0m | time: 1.343s
[2K
| Adam | epoch: 010 | loss: 0.68324 - acc: 0.5780 -- iter: 064/428
[A[ATraining Step: 129  | total loss: [1m[32m0.68220[0m[0m | time: 2.012s
[2K
| Adam | epoch: 010 | loss: 0.68220 - acc: 0.5827 -- iter: 096/428
[A[ATraining Step: 130  | total loss: [1m[32m0.68122[0m[0m | time: 2.686s
[2K
| Adam | epoch: 010 | loss: 0.68122 - acc: 0.5870 -- iter: 128/428
[A[ATraining Step: 131  | total loss: [1m[32m0.68076[0m[0m | time: 3.374s
[2K
| Adam | epoch: 010 | loss: 0.68076 - acc: 0.5876 -- iter: 160/428
[A[ATraining Step: 132  | total loss: [1m[32m0.68389[0m[0m | time: 4.052s
[2K
| Adam | epoch: 010 | loss: 0.68389 - acc: 0.5726 -- iter: 192/428
[A[ATraining Step: 133  | total loss: [1m[32m0.68193[0m[0m | time: 4.727s
[2K
| Adam | epoch: 010 | loss: 0.68193 - acc: 0.5810 -- iter: 224/428
[A[ATraining Step: 134  | total loss: [1m[32m0.68018[0m[0m | time: 4.992s
[2K
| Adam | epoch: 010 | loss: 0.68018 - acc: 0.5885 -- iter: 256/428
[A[ATraining Step: 135  | total loss: [1m[32m0.68607[0m[0m | time: 5.264s
[2K
| Adam | epoch: 010 | loss: 0.68607 - acc: 0.5630 -- iter: 288/428
[A[ATraining Step: 136  | total loss: [1m[32m0.69121[0m[0m | time: 5.924s
[2K
| Adam | epoch: 010 | loss: 0.69121 - acc: 0.5400 -- iter: 320/428
[A[ATraining Step: 137  | total loss: [1m[32m0.68920[0m[0m | time: 6.582s
[2K
| Adam | epoch: 010 | loss: 0.68920 - acc: 0.5485 -- iter: 352/428
[A[ATraining Step: 138  | total loss: [1m[32m0.68993[0m[0m | time: 7.248s
[2K
| Adam | epoch: 010 | loss: 0.68993 - acc: 0.5437 -- iter: 384/428
[A[ATraining Step: 139  | total loss: [1m[32m0.69004[0m[0m | time: 7.910s
[2K
| Adam | epoch: 010 | loss: 0.69004 - acc: 0.5424 -- iter: 416/428
[A[ATraining Step: 140  | total loss: [1m[32m0.68942[0m[0m | time: 9.569s
[2K
| Adam | epoch: 010 | loss: 0.68942 - acc: 0.5444 | val_loss: 0.67490 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 141  | total loss: [1m[32m0.68765[0m[0m | time: 0.654s
[2K
| Adam | epoch: 011 | loss: 0.68765 - acc: 0.5525 -- iter: 032/428
[A[ATraining Step: 142  | total loss: [1m[32m0.68742[0m[0m | time: 1.316s
[2K
| Adam | epoch: 011 | loss: 0.68742 - acc: 0.5535 -- iter: 064/428
[A[ATraining Step: 143  | total loss: [1m[32m0.68586[0m[0m | time: 1.981s
[2K
| Adam | epoch: 011 | loss: 0.68586 - acc: 0.5606 -- iter: 096/428
[A[ATraining Step: 144  | total loss: [1m[32m0.68633[0m[0m | time: 2.620s
[2K
| Adam | epoch: 011 | loss: 0.68633 - acc: 0.5577 -- iter: 128/428
[A[ATraining Step: 145  | total loss: [1m[32m0.68669[0m[0m | time: 3.274s
[2K
| Adam | epoch: 011 | loss: 0.68669 - acc: 0.5551 -- iter: 160/428
[A[ATraining Step: 146  | total loss: [1m[32m0.68327[0m[0m | time: 3.941s
[2K
| Adam | epoch: 011 | loss: 0.68327 - acc: 0.5714 -- iter: 192/428
[A[ATraining Step: 147  | total loss: [1m[32m0.68276[0m[0m | time: 4.587s
[2K
| Adam | epoch: 011 | loss: 0.68276 - acc: 0.5737 -- iter: 224/428
[A[ATraining Step: 148  | total loss: [1m[32m0.68284[0m[0m | time: 5.249s
[2K
| Adam | epoch: 011 | loss: 0.68284 - acc: 0.5725 -- iter: 256/428
[A[ATraining Step: 149  | total loss: [1m[32m0.68350[0m[0m | time: 5.524s
[2K
| Adam | epoch: 011 | loss: 0.68350 - acc: 0.5684 -- iter: 288/428
[A[ATraining Step: 150  | total loss: [1m[32m0.67726[0m[0m | time: 5.806s
[2K
| Adam | epoch: 011 | loss: 0.67726 - acc: 0.5949 -- iter: 320/428
[A[ATraining Step: 151  | total loss: [1m[32m0.67102[0m[0m | time: 6.477s
[2K
| Adam | epoch: 011 | loss: 0.67102 - acc: 0.6187 -- iter: 352/428
[A[ATraining Step: 152  | total loss: [1m[32m0.66767[0m[0m | time: 7.132s
[2K
| Adam | epoch: 011 | loss: 0.66767 - acc: 0.6287 -- iter: 384/428
[A[ATraining Step: 153  | total loss: [1m[32m0.67748[0m[0m | time: 7.795s
[2K
| Adam | epoch: 011 | loss: 0.67748 - acc: 0.5971 -- iter: 416/428
[A[ATraining Step: 154  | total loss: [1m[32m0.67236[0m[0m | time: 9.482s
[2K
| Adam | epoch: 011 | loss: 0.67236 - acc: 0.6093 | val_loss: 0.66371 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 155  | total loss: [1m[32m0.67218[0m[0m | time: 0.683s
[2K
| Adam | epoch: 012 | loss: 0.67218 - acc: 0.6077 -- iter: 032/428
[A[ATraining Step: 156  | total loss: [1m[32m0.66670[0m[0m | time: 1.335s
[2K
| Adam | epoch: 012 | loss: 0.66670 - acc: 0.6188 -- iter: 064/428
[A[ATraining Step: 157  | total loss: [1m[32m0.66859[0m[0m | time: 1.975s
[2K
| Adam | epoch: 012 | loss: 0.66859 - acc: 0.6132 -- iter: 096/428
[A[ATraining Step: 158  | total loss: [1m[32m0.66905[0m[0m | time: 2.642s
[2K
| Adam | epoch: 012 | loss: 0.66905 - acc: 0.6113 -- iter: 128/428
[A[ATraining Step: 159  | total loss: [1m[32m0.67782[0m[0m | time: 3.306s
[2K
| Adam | epoch: 012 | loss: 0.67782 - acc: 0.5970 -- iter: 160/428
[A[ATraining Step: 160  | total loss: [1m[32m0.67768[0m[0m | time: 3.960s
[2K
| Adam | epoch: 012 | loss: 0.67768 - acc: 0.5967 -- iter: 192/428
[A[ATraining Step: 161  | total loss: [1m[32m0.67906[0m[0m | time: 4.621s
[2K
| Adam | epoch: 012 | loss: 0.67906 - acc: 0.5933 -- iter: 224/428
[A[ATraining Step: 162  | total loss: [1m[32m0.67805[0m[0m | time: 5.265s
[2K
| Adam | epoch: 012 | loss: 0.67805 - acc: 0.5933 -- iter: 256/428
[A[ATraining Step: 163  | total loss: [1m[32m0.67598[0m[0m | time: 5.923s
[2K
| Adam | epoch: 012 | loss: 0.67598 - acc: 0.5965 -- iter: 288/428
[A[ATraining Step: 164  | total loss: [1m[32m0.67410[0m[0m | time: 6.206s
[2K
| Adam | epoch: 012 | loss: 0.67410 - acc: 0.5993 -- iter: 320/428
[A[ATraining Step: 165  | total loss: [1m[32m0.66800[0m[0m | time: 6.466s
[2K
| Adam | epoch: 012 | loss: 0.66800 - acc: 0.6144 -- iter: 352/428
[A[ATraining Step: 166  | total loss: [1m[32m0.66153[0m[0m | time: 7.108s
[2K
| Adam | epoch: 012 | loss: 0.66153 - acc: 0.6280 -- iter: 384/428
[A[ATraining Step: 167  | total loss: [1m[32m0.66212[0m[0m | time: 7.752s
[2K
| Adam | epoch: 012 | loss: 0.66212 - acc: 0.6245 -- iter: 416/428
[A[ATraining Step: 168  | total loss: [1m[32m0.66183[0m[0m | time: 9.405s
[2K
| Adam | epoch: 012 | loss: 0.66183 - acc: 0.6246 | val_loss: 0.65956 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 169  | total loss: [1m[32m0.66103[0m[0m | time: 0.672s
[2K
| Adam | epoch: 013 | loss: 0.66103 - acc: 0.6246 -- iter: 032/428
[A[ATraining Step: 170  | total loss: [1m[32m0.66522[0m[0m | time: 1.316s
[2K
| Adam | epoch: 013 | loss: 0.66522 - acc: 0.6153 -- iter: 064/428
[A[ATraining Step: 171  | total loss: [1m[32m0.67238[0m[0m | time: 1.976s
[2K
| Adam | epoch: 013 | loss: 0.67238 - acc: 0.6006 -- iter: 096/428
[A[ATraining Step: 172  | total loss: [1m[32m0.66702[0m[0m | time: 2.663s
[2K
| Adam | epoch: 013 | loss: 0.66702 - acc: 0.6093 -- iter: 128/428
[A[ATraining Step: 173  | total loss: [1m[32m0.66812[0m[0m | time: 3.328s
[2K
| Adam | epoch: 013 | loss: 0.66812 - acc: 0.6046 -- iter: 160/428
[A[ATraining Step: 174  | total loss: [1m[32m0.66793[0m[0m | time: 4.012s
[2K
| Adam | epoch: 013 | loss: 0.66793 - acc: 0.6035 -- iter: 192/428
[A[ATraining Step: 175  | total loss: [1m[32m0.66608[0m[0m | time: 4.669s
[2K
| Adam | epoch: 013 | loss: 0.66608 - acc: 0.6057 -- iter: 224/428
[A[ATraining Step: 176  | total loss: [1m[32m0.67234[0m[0m | time: 5.347s
[2K
| Adam | epoch: 013 | loss: 0.67234 - acc: 0.5920 -- iter: 256/428
[A[ATraining Step: 177  | total loss: [1m[32m0.67491[0m[0m | time: 6.013s
[2K
| Adam | epoch: 013 | loss: 0.67491 - acc: 0.5859 -- iter: 288/428
[A[ATraining Step: 178  | total loss: [1m[32m0.67876[0m[0m | time: 6.687s
[2K
| Adam | epoch: 013 | loss: 0.67876 - acc: 0.5742 -- iter: 320/428
[A[ATraining Step: 179  | total loss: [1m[32m0.67670[0m[0m | time: 6.943s
[2K
| Adam | epoch: 013 | loss: 0.67670 - acc: 0.5793 -- iter: 352/428
[A[ATraining Step: 180  | total loss: [1m[32m0.67592[0m[0m | time: 7.223s
[2K
| Adam | epoch: 013 | loss: 0.67592 - acc: 0.5797 -- iter: 384/428
[A[ATraining Step: 181  | total loss: [1m[32m0.67541[0m[0m | time: 7.903s
[2K
| Adam | epoch: 013 | loss: 0.67541 - acc: 0.5801 -- iter: 416/428
[A[ATraining Step: 182  | total loss: [1m[32m0.67401[0m[0m | time: 9.570s
[2K
| Adam | epoch: 013 | loss: 0.67401 - acc: 0.5846 | val_loss: 0.66234 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 183  | total loss: [1m[32m0.67294[0m[0m | time: 0.676s
[2K
| Adam | epoch: 014 | loss: 0.67294 - acc: 0.5886 -- iter: 032/428
[A[ATraining Step: 184  | total loss: [1m[32m0.67395[0m[0m | time: 1.364s
[2K
| Adam | epoch: 014 | loss: 0.67395 - acc: 0.5829 -- iter: 064/428
[A[ATraining Step: 185  | total loss: [1m[32m0.67444[0m[0m | time: 2.027s
[2K
| Adam | epoch: 014 | loss: 0.67444 - acc: 0.5808 -- iter: 096/428
[A[ATraining Step: 186  | total loss: [1m[32m0.67271[0m[0m | time: 2.714s
[2K
| Adam | epoch: 014 | loss: 0.67271 - acc: 0.5852 -- iter: 128/428
[A[ATraining Step: 187  | total loss: [1m[32m0.67365[0m[0m | time: 3.380s
[2K
| Adam | epoch: 014 | loss: 0.67365 - acc: 0.5798 -- iter: 160/428
[A[ATraining Step: 188  | total loss: [1m[32m0.67538[0m[0m | time: 4.054s
[2K
| Adam | epoch: 014 | loss: 0.67538 - acc: 0.5719 -- iter: 192/428
[A[ATraining Step: 189  | total loss: [1m[32m0.67112[0m[0m | time: 4.680s
[2K
| Adam | epoch: 014 | loss: 0.67112 - acc: 0.5803 -- iter: 224/428
[A[ATraining Step: 190  | total loss: [1m[32m0.67042[0m[0m | time: 5.374s
[2K
| Adam | epoch: 014 | loss: 0.67042 - acc: 0.5816 -- iter: 256/428
[A[ATraining Step: 191  | total loss: [1m[32m0.66521[0m[0m | time: 6.046s
[2K
| Adam | epoch: 014 | loss: 0.66521 - acc: 0.5922 -- iter: 288/428
[A[ATraining Step: 192  | total loss: [1m[32m0.66458[0m[0m | time: 6.715s
[2K
| Adam | epoch: 014 | loss: 0.66458 - acc: 0.5924 -- iter: 320/428
[A[ATraining Step: 193  | total loss: [1m[32m0.66977[0m[0m | time: 7.383s
[2K
| Adam | epoch: 014 | loss: 0.66977 - acc: 0.5831 -- iter: 352/428
[A[ATraining Step: 194  | total loss: [1m[32m0.66301[0m[0m | time: 7.647s
[2K
| Adam | epoch: 014 | loss: 0.66301 - acc: 0.5936 -- iter: 384/428
[A[ATraining Step: 195  | total loss: [1m[32m0.66393[0m[0m | time: 7.912s
[2K
| Adam | epoch: 014 | loss: 0.66393 - acc: 0.5926 -- iter: 416/428
[A[ATraining Step: 196  | total loss: [1m[32m0.66447[0m[0m | time: 9.615s
[2K
| Adam | epoch: 014 | loss: 0.66447 - acc: 0.5916 | val_loss: 0.63767 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 197  | total loss: [1m[32m0.66660[0m[0m | time: 0.651s
[2K
| Adam | epoch: 015 | loss: 0.66660 - acc: 0.5856 -- iter: 032/428
[A[ATraining Step: 198  | total loss: [1m[32m0.65681[0m[0m | time: 1.293s
[2K
| Adam | epoch: 015 | loss: 0.65681 - acc: 0.6020 -- iter: 064/428
[A[ATraining Step: 199  | total loss: [1m[32m0.65762[0m[0m | time: 1.955s
[2K
| Adam | epoch: 015 | loss: 0.65762 - acc: 0.5981 -- iter: 096/428
[A[ATraining Step: 200  | total loss: [1m[32m0.65628[0m[0m | time: 3.590s
[2K
| Adam | epoch: 015 | loss: 0.65628 - acc: 0.5976 | val_loss: 0.62927 - val_acc: 0.6119 -- iter: 128/428
--
Training Step: 201  | total loss: [1m[32m0.65439[0m[0m | time: 4.302s
[2K
| Adam | epoch: 015 | loss: 0.65439 - acc: 0.5973 -- iter: 160/428
[A[ATraining Step: 202  | total loss: [1m[32m0.65970[0m[0m | time: 4.937s
[2K
| Adam | epoch: 015 | loss: 0.65970 - acc: 0.5844 -- iter: 192/428
[A[ATraining Step: 203  | total loss: [1m[32m0.65421[0m[0m | time: 5.591s
[2K
| Adam | epoch: 015 | loss: 0.65421 - acc: 0.5947 -- iter: 224/428
[A[ATraining Step: 204  | total loss: [1m[32m0.64737[0m[0m | time: 6.250s
[2K
| Adam | epoch: 015 | loss: 0.64737 - acc: 0.6071 -- iter: 256/428
[A[ATraining Step: 205  | total loss: [1m[32m0.64570[0m[0m | time: 6.896s
[2K
| Adam | epoch: 015 | loss: 0.64570 - acc: 0.6058 -- iter: 288/428
[A[ATraining Step: 206  | total loss: [1m[32m0.64701[0m[0m | time: 7.549s
[2K
| Adam | epoch: 015 | loss: 0.64701 - acc: 0.5952 -- iter: 320/428
[A[ATraining Step: 207  | total loss: [1m[32m0.65402[0m[0m | time: 8.214s
[2K
| Adam | epoch: 015 | loss: 0.65402 - acc: 0.5794 -- iter: 352/428
[A[ATraining Step: 208  | total loss: [1m[32m0.64867[0m[0m | time: 8.869s
[2K
| Adam | epoch: 015 | loss: 0.64867 - acc: 0.5809 -- iter: 384/428
[A[ATraining Step: 209  | total loss: [1m[32m0.64849[0m[0m | time: 9.145s
[2K
| Adam | epoch: 015 | loss: 0.64849 - acc: 0.5759 -- iter: 416/428
[A[ATraining Step: 210  | total loss: [1m[32m0.64365[0m[0m | time: 10.422s
[2K
| Adam | epoch: 015 | loss: 0.64365 - acc: 0.5766 | val_loss: 0.58166 - val_acc: 0.6119 -- iter: 428/428
--
Training Step: 211  | total loss: [1m[32m0.63739[0m[0m | time: 0.701s
[2K
| Adam | epoch: 016 | loss: 0.63739 - acc: 0.5773 -- iter: 032/428
[A[ATraining Step: 212  | total loss: [1m[32m0.63487[0m[0m | time: 1.351s
[2K
| Adam | epoch: 016 | loss: 0.63487 - acc: 0.5727 -- iter: 064/428
[A[ATraining Step: 213  | total loss: [1m[32m0.63461[0m[0m | time: 1.983s
[2K
| Adam | epoch: 016 | loss: 0.63461 - acc: 0.5748 -- iter: 096/428
[A[ATraining Step: 214  | total loss: [1m[32m0.62528[0m[0m | time: 2.673s
[2K
| Adam | epoch: 016 | loss: 0.62528 - acc: 0.5923 -- iter: 128/428
[A[ATraining Step: 215  | total loss: [1m[32m0.61213[0m[0m | time: 3.339s
[2K
| Adam | epoch: 016 | loss: 0.61213 - acc: 0.6206 -- iter: 160/428
[A[ATraining Step: 216  | total loss: [1m[32m0.62615[0m[0m | time: 3.998s
[2K
| Adam | epoch: 016 | loss: 0.62615 - acc: 0.6085 -- iter: 192/428
[A[ATraining Step: 217  | total loss: [1m[32m0.62153[0m[0m | time: 4.694s
[2K
| Adam | epoch: 016 | loss: 0.62153 - acc: 0.6164 -- iter: 224/428
[A[ATraining Step: 218  | total loss: [1m[32m0.62620[0m[0m | time: 5.370s
[2K
| Adam | epoch: 016 | loss: 0.62620 - acc: 0.6110 -- iter: 256/428
[A[ATraining Step: 219  | total loss: [1m[32m0.63330[0m[0m | time: 6.038s
[2K
| Adam | epoch: 016 | loss: 0.63330 - acc: 0.6031 -- iter: 288/428
[A[ATraining Step: 220  | total loss: [1m[32m0.63920[0m[0m | time: 6.681s
[2K
| Adam | epoch: 016 | loss: 0.63920 - acc: 0.5990 -- iter: 320/428
[A[ATraining Step: 221  | total loss: [1m[32m0.63643[0m[0m | time: 7.338s
[2K
| Adam | epoch: 016 | loss: 0.63643 - acc: 0.6079 -- iter: 352/428
[A[ATraining Step: 222  | total loss: [1m[32m0.61736[0m[0m | time: 8.010s
[2K
| Adam | epoch: 016 | loss: 0.61736 - acc: 0.6221 -- iter: 384/428
[A[ATraining Step: 223  | total loss: [1m[32m0.63066[0m[0m | time: 8.675s
[2K
| Adam | epoch: 016 | loss: 0.63066 - acc: 0.6130 -- iter: 416/428
[A[ATraining Step: 224  | total loss: [1m[32m0.63967[0m[0m | time: 9.955s
[2K
| Adam | epoch: 016 | loss: 0.63967 - acc: 0.6142 | val_loss: 0.54970 - val_acc: 0.7761 -- iter: 428/428
--
Training Step: 225  | total loss: [1m[32m0.62495[0m[0m | time: 0.288s
[2K
| Adam | epoch: 017 | loss: 0.62495 - acc: 0.6194 -- iter: 032/428
[A[ATraining Step: 226  | total loss: [1m[32m0.61266[0m[0m | time: 0.958s
[2K
| Adam | epoch: 017 | loss: 0.61266 - acc: 0.6325 -- iter: 064/428
[A[ATraining Step: 227  | total loss: [1m[32m0.61276[0m[0m | time: 2.049s
[2K
| Adam | epoch: 017 | loss: 0.61276 - acc: 0.6599 -- iter: 096/428
[A[ATraining Step: 228  | total loss: [1m[32m0.61034[0m[0m | time: 3.856s
[2K
| Adam | epoch: 017 | loss: 0.61034 - acc: 0.6658 -- iter: 128/428
[A[ATraining Step: 229  | total loss: [1m[32m0.60835[0m[0m | time: 8.156s
[2K
| Adam | epoch: 017 | loss: 0.60835 - acc: 0.6711 -- iter: 160/428
[A[ATraining Step: 230  | total loss: [1m[32m0.59695[0m[0m | time: 9.853s
[2K
| Adam | epoch: 017 | loss: 0.59695 - acc: 0.6915 -- iter: 192/428
[A[ATraining Step: 231  | total loss: [1m[32m0.59433[0m[0m | time: 12.851s
[2K
| Adam | epoch: 017 | loss: 0.59433 - acc: 0.6942 -- iter: 224/428
[A[ATraining Step: 232  | total loss: [1m[32m0.59102[0m[0m | time: 15.246s
[2K
| Adam | epoch: 017 | loss: 0.59102 - acc: 0.6873 -- iter: 256/428
[A[ATraining Step: 233  | total loss: [1m[32m0.59710[0m[0m | time: 18.392s
[2K
| Adam | epoch: 017 | loss: 0.59710 - acc: 0.6810 -- iter: 288/428
[A[ATraining Step: 234  | total loss: [1m[32m0.58070[0m[0m | time: 20.334s
[2K
| Adam | epoch: 017 | loss: 0.58070 - acc: 0.6973 -- iter: 320/428
[A[ATraining Step: 235  | total loss: [1m[32m0.56771[0m[0m | time: 23.411s
[2K
| Adam | epoch: 017 | loss: 0.56771 - acc: 0.7120 -- iter: 352/428
[A[ATraining Step: 236  | total loss: [1m[32m0.55038[0m[0m | time: 24.321s
[2K
| Adam | epoch: 017 | loss: 0.55038 - acc: 0.7283 -- iter: 384/428
[A[ATraining Step: 237  | total loss: [1m[32m0.54804[0m[0m | time: 25.269s
[2K
| Adam | epoch: 017 | loss: 0.54804 - acc: 0.7304 -- iter: 416/428
[A[ATraining Step: 238  | total loss: [1m[32m0.54145[0m[0m | time: 27.315s
[2K
| Adam | epoch: 017 | loss: 0.54145 - acc: 0.7355 | val_loss: 0.48939 - val_acc: 0.7761 -- iter: 428/428
--
Training Step: 239  | total loss: [1m[32m0.53005[0m[0m | time: 0.467s
[2K
| Adam | epoch: 018 | loss: 0.53005 - acc: 0.7463 -- iter: 032/428
[A[ATraining Step: 240  | total loss: [1m[32m0.52705[0m[0m | time: 0.805s
[2K
| Adam | epoch: 018 | loss: 0.52705 - acc: 0.7550 -- iter: 064/428
[A[ATraining Step: 241  | total loss: [1m[32m0.52123[0m[0m | time: 1.565s
[2K
| Adam | epoch: 018 | loss: 0.52123 - acc: 0.7712 -- iter: 096/428
[A[ATraining Step: 242  | total loss: [1m[32m0.50594[0m[0m | time: 2.215s
[2K
| Adam | epoch: 018 | loss: 0.50594 - acc: 0.7847 -- iter: 128/428
[A[ATraining Step: 243  | total loss: [1m[32m0.50503[0m[0m | time: 3.419s
[2K
| Adam | epoch: 018 | loss: 0.50503 - acc: 0.7812 -- iter: 160/428
[A[ATraining Step: 244  | total loss: [1m[32m0.50926[0m[0m | time: 4.777s
[2K
| Adam | epoch: 018 | loss: 0.50926 - acc: 0.7781 -- iter: 192/428
[A[ATraining Step: 245  | total loss: [1m[32m0.49461[0m[0m | time: 6.492s
[2K
| Adam | epoch: 018 | loss: 0.49461 - acc: 0.7847 -- iter: 224/428
[A[ATraining Step: 246  | total loss: [1m[32m0.48813[0m[0m | time: 20.898s
[2K
| Adam | epoch: 018 | loss: 0.48813 - acc: 0.7843 -- iter: 256/428
[A[ATraining Step: 247  | total loss: [1m[32m0.50437[0m[0m | time: 24.301s
[2K
| Adam | epoch: 018 | loss: 0.50437 - acc: 0.7778 -- iter: 288/428
[A[ATraining Step: 248  | total loss: [1m[32m0.50642[0m[0m | time: 27.994s
[2K
| Adam | epoch: 018 | loss: 0.50642 - acc: 0.7719 -- iter: 320/428
[A[ATraining Step: 249  | total loss: [1m[32m0.50417[0m[0m | time: 35.331s
[2K
| Adam | epoch: 018 | loss: 0.50417 - acc: 0.7728 -- iter: 352/428
[A[ATraining Step: 250  | total loss: [1m[32m0.48518[0m[0m | time: 40.327s
[2K
| Adam | epoch: 018 | loss: 0.48518 - acc: 0.7862 -- iter: 384/428
[A[ATraining Step: 251  | total loss: [1m[32m0.51386[0m[0m | time: 45.836s
[2K
| Adam | epoch: 018 | loss: 0.51386 - acc: 0.7700 -- iter: 416/428
[A[ATraining Step: 252  | total loss: [1m[32m0.53366[0m[0m | time: 51.207s
[2K
| Adam | epoch: 018 | loss: 0.53366 - acc: 0.7493 | val_loss: 0.48444 - val_acc: 0.7836 -- iter: 428/428
--
Training Step: 253  | total loss: [1m[32m0.52141[0m[0m | time: 1.023s
[2K
| Adam | epoch: 019 | loss: 0.52141 - acc: 0.7587 -- iter: 032/428
[A[ATraining Step: 254  | total loss: [1m[32m0.50564[0m[0m | time: 1.580s
[2K
| Adam | epoch: 019 | loss: 0.50564 - acc: 0.7704 -- iter: 064/428
[A[ATraining Step: 255  | total loss: [1m[32m0.51431[0m[0m | time: 2.095s
[2K
| Adam | epoch: 019 | loss: 0.51431 - acc: 0.7600 -- iter: 096/428
[A[ATraining Step: 256  | total loss: [1m[32m0.51495[0m[0m | time: 3.255s
[2K
| Adam | epoch: 019 | loss: 0.51495 - acc: 0.7590 -- iter: 128/428
[A[ATraining Step: 257  | total loss: [1m[32m0.50828[0m[0m | time: 4.046s
[2K
| Adam | epoch: 019 | loss: 0.50828 - acc: 0.7643 -- iter: 160/428
[A[ATraining Step: 258  | total loss: [1m[32m0.50342[0m[0m | time: 5.317s
[2K
| Adam | epoch: 019 | loss: 0.50342 - acc: 0.7660 -- iter: 192/428
[A[ATraining Step: 259  | total loss: [1m[32m0.49396[0m[0m | time: 6.567s
[2K
| Adam | epoch: 019 | loss: 0.49396 - acc: 0.7738 -- iter: 224/428
[A[ATraining Step: 260  | total loss: [1m[32m0.49343[0m[0m | time: 13.200s
[2K
| Adam | epoch: 019 | loss: 0.49343 - acc: 0.7745 -- iter: 256/428
[A[ATraining Step: 261  | total loss: [1m[32m0.49700[0m[0m | time: 20.555s
[2K
| Adam | epoch: 019 | loss: 0.49700 - acc: 0.7783 -- iter: 288/428
[A[ATraining Step: 262  | total loss: [1m[32m0.48086[0m[0m | time: 25.449s
[2K
| Adam | epoch: 019 | loss: 0.48086 - acc: 0.7943 -- iter: 320/428
[A[ATraining Step: 263  | total loss: [1m[32m0.48281[0m[0m | time: 32.062s
[2K
| Adam | epoch: 019 | loss: 0.48281 - acc: 0.7898 -- iter: 352/428
[A[ATraining Step: 264  | total loss: [1m[32m0.48447[0m[0m | time: 37.990s
[2K
| Adam | epoch: 019 | loss: 0.48447 - acc: 0.7796 -- iter: 384/428
[A[ATraining Step: 265  | total loss: [1m[32m0.47640[0m[0m | time: 43.428s
[2K
| Adam | epoch: 019 | loss: 0.47640 - acc: 0.7829 -- iter: 416/428
[A[ATraining Step: 266  | total loss: [1m[32m0.48378[0m[0m | time: 63.616s
[2K
| Adam | epoch: 019 | loss: 0.48378 - acc: 0.7734 | val_loss: 0.54802 - val_acc: 0.7015 -- iter: 428/428
--
Training Step: 267  | total loss: [1m[32m0.48371[0m[0m | time: 4.727s
[2K
| Adam | epoch: 020 | loss: 0.48371 - acc: 0.7679 -- iter: 032/428
[A[ATraining Step: 268  | total loss: [1m[32m0.49313[0m[0m | time: 5.711s
[2K
| Adam | epoch: 020 | loss: 0.49313 - acc: 0.7536 -- iter: 064/428
[A[ATraining Step: 269  | total loss: [1m[32m0.49877[0m[0m | time: 6.121s
[2K
| Adam | epoch: 020 | loss: 0.49877 - acc: 0.7501 -- iter: 096/428
[A[ATraining Step: 270  | total loss: [1m[32m0.49396[0m[0m | time: 6.524s
[2K
| Adam | epoch: 020 | loss: 0.49396 - acc: 0.7584 -- iter: 128/428
[A[ATraining Step: 271  | total loss: [1m[32m0.48842[0m[0m | time: 7.554s
[2K
| Adam | epoch: 020 | loss: 0.48842 - acc: 0.7576 -- iter: 160/428
[A[ATraining Step: 272  | total loss: [1m[32m0.48462[0m[0m | time: 8.677s
[2K
| Adam | epoch: 020 | loss: 0.48462 - acc: 0.7631 -- iter: 192/428
[A[ATraining Step: 273  | total loss: [1m[32m0.46481[0m[0m | time: 9.802s
[2K
| Adam | epoch: 020 | loss: 0.46481 - acc: 0.7774 -- iter: 224/428
[A[ATraining Step: 274  | total loss: [1m[32m0.45520[0m[0m | time: 10.687s
[2K
| Adam | epoch: 020 | loss: 0.45520 - acc: 0.7840 -- iter: 256/428
[A[ATraining Step: 275  | total loss: [1m[32m0.45251[0m[0m | time: 11.842s
[2K
| Adam | epoch: 020 | loss: 0.45251 - acc: 0.7838 -- iter: 288/428
[A[ATraining Step: 276  | total loss: [1m[32m0.44469[0m[0m | time: 13.181s
[2K
| Adam | epoch: 020 | loss: 0.44469 - acc: 0.7929 -- iter: 320/428
[A[ATraining Step: 277  | total loss: [1m[32m0.43644[0m[0m | time: 14.296s
[2K
| Adam | epoch: 020 | loss: 0.43644 - acc: 0.7980 -- iter: 352/428
[A[ATraining Step: 278  | total loss: [1m[32m0.42399[0m[0m | time: 18.216s
[2K
| Adam | epoch: 020 | loss: 0.42399 - acc: 0.8088 -- iter: 384/428
[A[ATraining Step: 279  | total loss: [1m[32m0.43904[0m[0m | time: 22.347s
[2K
| Adam | epoch: 020 | loss: 0.43904 - acc: 0.7967 -- iter: 416/428
[A[ATraining Step: 280  | total loss: [1m[32m0.43545[0m[0m | time: 33.209s
[2K
| Adam | epoch: 020 | loss: 0.43545 - acc: 0.8014 | val_loss: 0.45038 - val_acc: 0.7687 -- iter: 428/428
--
Training Step: 281  | total loss: [1m[32m0.43901[0m[0m | time: 1.192s
[2K
| Adam | epoch: 021 | loss: 0.43901 - acc: 0.7994 -- iter: 032/428
[A[ATraining Step: 282  | total loss: [1m[32m0.43060[0m[0m | time: 2.368s
[2K
| Adam | epoch: 021 | loss: 0.43060 - acc: 0.8038 -- iter: 064/428
[A[ATraining Step: 283  | total loss: [1m[32m0.41634[0m[0m | time: 3.494s
[2K
| Adam | epoch: 021 | loss: 0.41634 - acc: 0.8109 -- iter: 096/428
[A[ATraining Step: 284  | total loss: [1m[32m0.41595[0m[0m | time: 3.865s
[2K
| Adam | epoch: 021 | loss: 0.41595 - acc: 0.8111 -- iter: 128/428
[A[ATraining Step: 285  | total loss: [1m[32m0.38885[0m[0m | time: 4.258s
[2K
| Adam | epoch: 021 | loss: 0.38885 - acc: 0.8300 -- iter: 160/428
[A[ATraining Step: 286  | total loss: [1m[32m0.36412[0m[0m | time: 5.544s
[2K
| Adam | epoch: 021 | loss: 0.36412 - acc: 0.8470 -- iter: 192/428
[A[ATraining Step: 287  | total loss: [1m[32m0.37031[0m[0m | time: 6.849s
[2K
| Adam | epoch: 021 | loss: 0.37031 - acc: 0.8467 -- iter: 224/428
[A[ATraining Step: 288  | total loss: [1m[32m0.36487[0m[0m | time: 7.891s
[2K
| Adam | epoch: 021 | loss: 0.36487 - acc: 0.8464 -- iter: 256/428
[A[ATraining Step: 289  | total loss: [1m[32m0.35851[0m[0m | time: 9.232s
[2K
| Adam | epoch: 021 | loss: 0.35851 - acc: 0.8524 -- iter: 288/428
[A[ATraining Step: 290  | total loss: [1m[32m0.34755[0m[0m | time: 16.617s
[2K
| Adam | epoch: 021 | loss: 0.34755 - acc: 0.8609 -- iter: 320/428
[A[ATraining Step: 291  | total loss: [1m[32m0.34260[0m[0m | time: 21.562s
[2K
| Adam | epoch: 021 | loss: 0.34260 - acc: 0.8623 -- iter: 352/428
[A[ATraining Step: 292  | total loss: [1m[32m0.35653[0m[0m | time: 22.505s
[2K
| Adam | epoch: 021 | loss: 0.35653 - acc: 0.8604 -- iter: 384/428
[A[ATraining Step: 293  | total loss: [1m[32m0.34106[0m[0m | time: 23.562s
[2K
| Adam | epoch: 021 | loss: 0.34106 - acc: 0.8650 -- iter: 416/428
[A[ATraining Step: 294  | total loss: [1m[32m0.34701[0m[0m | time: 25.620s
[2K
| Adam | epoch: 021 | loss: 0.34701 - acc: 0.8660 | val_loss: 0.45686 - val_acc: 0.7985 -- iter: 428/428
--
Training Step: 295  | total loss: [1m[32m0.33190[0m[0m | time: 1.372s
[2K
| Adam | epoch: 022 | loss: 0.33190 - acc: 0.8763 -- iter: 032/428
[A[ATraining Step: 296  | total loss: [1m[32m0.33612[0m[0m | time: 2.551s
[2K
| Adam | epoch: 022 | loss: 0.33612 - acc: 0.8699 -- iter: 064/428
[A[ATraining Step: 297  | total loss: [1m[32m0.33427[0m[0m | time: 4.561s
[2K
| Adam | epoch: 022 | loss: 0.33427 - acc: 0.8704 -- iter: 096/428
[A[ATraining Step: 298  | total loss: [1m[32m0.38954[0m[0m | time: 6.152s
[2K
| Adam | epoch: 022 | loss: 0.38954 - acc: 0.8584 -- iter: 128/428
[A[ATraining Step: 299  | total loss: [1m[32m0.37445[0m[0m | time: 8.681s
[2K
| Adam | epoch: 022 | loss: 0.37445 - acc: 0.8632 -- iter: 160/428
[A[ATraining Step: 300  | total loss: [1m[32m0.37389[0m[0m | time: 12.987s
[2K
| Adam | epoch: 022 | loss: 0.37389 - acc: 0.8602 -- iter: 192/428
[A[ATraining Step: 301  | total loss: [1m[32m0.37520[0m[0m | time: 19.271s
[2K
| Adam | epoch: 022 | loss: 0.37520 - acc: 0.8575 -- iter: 224/428
[A[ATraining Step: 302  | total loss: [1m[32m0.38882[0m[0m | time: 26.716s
[2K
| Adam | epoch: 022 | loss: 0.38882 - acc: 0.8405 -- iter: 256/428
[A[ATraining Step: 303  | total loss: [1m[32m0.37977[0m[0m | time: 32.327s
[2K
| Adam | epoch: 022 | loss: 0.37977 - acc: 0.8439 -- iter: 288/428
[A[ATraining Step: 304  | total loss: [1m[32m0.37488[0m[0m | time: 37.722s
[2K
| Adam | epoch: 022 | loss: 0.37488 - acc: 0.8502 -- iter: 320/428
[A[ATraining Step: 305  | total loss: [1m[32m0.36359[0m[0m | time: 41.317s
[2K
| Adam | epoch: 022 | loss: 0.36359 - acc: 0.8558 -- iter: 352/428
[A[ATraining Step: 306  | total loss: [1m[32m0.36048[0m[0m | time: 45.486s
[2K
| Adam | epoch: 022 | loss: 0.36048 - acc: 0.8546 -- iter: 384/428
[A[ATraining Step: 307  | total loss: [1m[32m0.35947[0m[0m | time: 49.173s
[2K
| Adam | epoch: 022 | loss: 0.35947 - acc: 0.8504 -- iter: 416/428
[A[ATraining Step: 308  | total loss: [1m[32m0.34677[0m[0m | time: 54.838s
[2K
| Adam | epoch: 022 | loss: 0.34677 - acc: 0.8591 | val_loss: 0.44860 - val_acc: 0.7761 -- iter: 428/428
--
Training Step: 309  | total loss: [1m[32m0.33965[0m[0m | time: 1.270s
[2K
| Adam | epoch: 023 | loss: 0.33965 - acc: 0.8638 -- iter: 032/428
[A[ATraining Step: 310  | total loss: [1m[32m0.32878[0m[0m | time: 2.296s
[2K
| Adam | epoch: 023 | loss: 0.32878 - acc: 0.8680 -- iter: 064/428
[A[ATraining Step: 311  | total loss: [1m[32m0.31824[0m[0m | time: 3.410s
[2K
| Adam | epoch: 023 | loss: 0.31824 - acc: 0.8750 -- iter: 096/428
[A[ATraining Step: 312  | total loss: [1m[32m0.31499[0m[0m | time: 4.839s
[2K
| Adam | epoch: 023 | loss: 0.31499 - acc: 0.8781 -- iter: 128/428
[A[ATraining Step: 313  | total loss: [1m[32m0.32332[0m[0m | time: 5.896s
[2K
| Adam | epoch: 023 | loss: 0.32332 - acc: 0.8747 -- iter: 160/428
[A[ATraining Step: 314  | total loss: [1m[32m0.31438[0m[0m | time: 9.007s
[2K
| Adam | epoch: 023 | loss: 0.31438 - acc: 0.8810 -- iter: 192/428
[A[ATraining Step: 315  | total loss: [1m[32m0.29708[0m[0m | time: 10.679s
[2K
| Adam | epoch: 023 | loss: 0.29708 - acc: 0.8929 -- iter: 224/428
[A[ATraining Step: 316  | total loss: [1m[32m0.27983[0m[0m | time: 16.534s
[2K
| Adam | epoch: 023 | loss: 0.27983 - acc: 0.9036 -- iter: 256/428
[A[ATraining Step: 317  | total loss: [1m[32m0.27352[0m[0m | time: 23.136s
[2K
| Adam | epoch: 023 | loss: 0.27352 - acc: 0.9038 -- iter: 288/428
[A[ATraining Step: 318  | total loss: [1m[32m0.26912[0m[0m | time: 30.782s
[2K
| Adam | epoch: 023 | loss: 0.26912 - acc: 0.9072 -- iter: 320/428
[A[ATraining Step: 319  | total loss: [1m[32m0.26686[0m[0m | time: 33.284s
[2K
| Adam | epoch: 023 | loss: 0.26686 - acc: 0.9040 -- iter: 352/428
[A[ATraining Step: 320  | total loss: [1m[32m0.26169[0m[0m | time: 35.874s
[2K
| Adam | epoch: 023 | loss: 0.26169 - acc: 0.9042 -- iter: 384/428
[A[ATraining Step: 321  | total loss: [1m[32m0.25551[0m[0m | time: 36.958s
[2K
| Adam | epoch: 023 | loss: 0.25551 - acc: 0.9044 -- iter: 416/428
[A[ATraining Step: 322  | total loss: [1m[32m0.25524[0m[0m | time: 38.953s
[2K
| Adam | epoch: 023 | loss: 0.25524 - acc: 0.9077 | val_loss: 0.50553 - val_acc: 0.7910 -- iter: 428/428
--
Training Step: 323  | total loss: [1m[32m0.24027[0m[0m | time: 1.015s
[2K
| Adam | epoch: 024 | loss: 0.24027 - acc: 0.9138 -- iter: 032/428
[A[ATraining Step: 324  | total loss: [1m[32m0.22473[0m[0m | time: 2.140s
[2K
| Adam | epoch: 024 | loss: 0.22473 - acc: 0.9193 -- iter: 064/428
[A[ATraining Step: 325  | total loss: [1m[32m0.24155[0m[0m | time: 3.503s
[2K
| Adam | epoch: 024 | loss: 0.24155 - acc: 0.9086 -- iter: 096/428
[A[ATraining Step: 326  | total loss: [1m[32m0.24986[0m[0m | time: 4.735s
[2K
| Adam | epoch: 024 | loss: 0.24986 - acc: 0.9022 -- iter: 128/428
[A[ATraining Step: 327  | total loss: [1m[32m0.24132[0m[0m | time: 7.267s
[2K
| Adam | epoch: 024 | loss: 0.24132 - acc: 0.9057 -- iter: 160/428
[A[ATraining Step: 328  | total loss: [1m[32m0.25024[0m[0m | time: 10.907s
[2K
| Adam | epoch: 024 | loss: 0.25024 - acc: 0.8995 -- iter: 192/428
[A[ATraining Step: 329  | total loss: [1m[32m0.25492[0m[0m | time: 13.642s
[2K
| Adam | epoch: 024 | loss: 0.25492 - acc: 0.9033 -- iter: 224/428
[A[ATraining Step: 330  | total loss: [1m[32m0.24105[0m[0m | time: 16.622s
[2K
| Adam | epoch: 024 | loss: 0.24105 - acc: 0.9130 -- iter: 256/428
[A[ATraining Step: 331  | total loss: [1m[32m0.22615[0m[0m | time: 21.772s
[2K
| Adam | epoch: 024 | loss: 0.22615 - acc: 0.9217 -- iter: 288/428
[A[ATraining Step: 332  | total loss: [1m[32m0.21539[0m[0m | time: 25.507s
[2K
| Adam | epoch: 024 | loss: 0.21539 - acc: 0.9264 -- iter: 320/428
[A[ATraining Step: 333  | total loss: [1m[32m0.20092[0m[0m | time: 31.355s
[2K
| Adam | epoch: 024 | loss: 0.20092 - acc: 0.9306 -- iter: 352/428
[A[ATraining Step: 334  | total loss: [1m[32m0.19215[0m[0m | time: 37.403s
[2K
| Adam | epoch: 024 | loss: 0.19215 - acc: 0.9344 -- iter: 384/428
[A[ATraining Step: 335  | total loss: [1m[32m0.19071[0m[0m | time: 39.301s
[2K
| Adam | epoch: 024 | loss: 0.19071 - acc: 0.9316 -- iter: 416/428
[A[ATraining Step: 336  | total loss: [1m[32m0.18602[0m[0m | time: 41.248s
[2K
| Adam | epoch: 024 | loss: 0.18602 - acc: 0.9322 | val_loss: 0.58536 - val_acc: 0.7687 -- iter: 428/428
--
Training Step: 337  | total loss: [1m[32m0.17756[0m[0m | time: 1.208s
[2K
| Adam | epoch: 025 | loss: 0.17756 - acc: 0.9359 -- iter: 032/428
[A[ATraining Step: 338  | total loss: [1m[32m0.16755[0m[0m | time: 2.322s
[2K
| Adam | epoch: 025 | loss: 0.16755 - acc: 0.9391 -- iter: 064/428
[A[ATraining Step: 339  | total loss: [1m[32m0.16328[0m[0m | time: 3.305s
[2K
| Adam | epoch: 025 | loss: 0.16328 - acc: 0.9421 -- iter: 096/428
[A[ATraining Step: 340  | total loss: [1m[32m0.16866[0m[0m | time: 4.322s
[2K
| Adam | epoch: 025 | loss: 0.16866 - acc: 0.9416 -- iter: 128/428
[A[ATraining Step: 341  | total loss: [1m[32m0.15839[0m[0m | time: 5.222s
[2K
| Adam | epoch: 025 | loss: 0.15839 - acc: 0.9444 -- iter: 160/428
[A[ATraining Step: 342  | total loss: [1m[32m0.15175[0m[0m | time: 6.163s
[2K
| Adam | epoch: 025 | loss: 0.15175 - acc: 0.9468 -- iter: 192/428
[A[ATraining Step: 343  | total loss: [1m[32m0.14350[0m[0m | time: 7.105s
[2K
| Adam | epoch: 025 | loss: 0.14350 - acc: 0.9490 -- iter: 224/428
[A[ATraining Step: 344  | total loss: [1m[32m0.14250[0m[0m | time: 7.474s
[2K
| Adam | epoch: 025 | loss: 0.14250 - acc: 0.9478 -- iter: 256/428
[A[ATraining Step: 345  | total loss: [1m[32m0.13241[0m[0m | time: 7.768s
[2K
| Adam | epoch: 025 | loss: 0.13241 - acc: 0.9531 -- iter: 288/428
[A[ATraining Step: 346  | total loss: [1m[32m0.12634[0m[0m | time: 8.457s
[2K
| Adam | epoch: 025 | loss: 0.12634 - acc: 0.9578 -- iter: 320/428
[A[ATraining Step: 347  | total loss: [1m[32m0.12636[0m[0m | time: 9.167s
[2K
| Adam | epoch: 025 | loss: 0.12636 - acc: 0.9589 -- iter: 352/428
[A[ATraining Step: 348  | total loss: [1m[32m0.12442[0m[0m | time: 9.865s
[2K
| Adam | epoch: 025 | loss: 0.12442 - acc: 0.9598 -- iter: 384/428
[A[ATraining Step: 349  | total loss: [1m[32m0.12952[0m[0m | time: 10.549s
[2K
| Adam | epoch: 025 | loss: 0.12952 - acc: 0.9514 -- iter: 416/428
[A[ATraining Step: 350  | total loss: [1m[32m0.13684[0m[0m | time: 12.218s
[2K
| Adam | epoch: 025 | loss: 0.13684 - acc: 0.9437 | val_loss: 0.55632 - val_acc: 0.7836 -- iter: 428/428
--
Training Step: 351  | total loss: [1m[32m0.13338[0m[0m | time: 1.170s
[2K
| Adam | epoch: 026 | loss: 0.13338 - acc: 0.9431 -- iter: 032/428
[A[ATraining Step: 352  | total loss: [1m[32m0.12873[0m[0m | time: 3.266s
[2K
| Adam | epoch: 026 | loss: 0.12873 - acc: 0.9457 -- iter: 064/428
[A[ATraining Step: 353  | total loss: [1m[32m0.11807[0m[0m | time: 10.787s
[2K
| Adam | epoch: 026 | loss: 0.11807 - acc: 0.9511 -- iter: 096/428
[A[ATraining Step: 354  | total loss: [1m[32m0.11535[0m[0m | time: 15.338s
[2K
| Adam | epoch: 026 | loss: 0.11535 - acc: 0.9529 -- iter: 128/428
[A[ATraining Step: 355  | total loss: [1m[32m0.10673[0m[0m | time: 19.822s
[2K
| Adam | epoch: 026 | loss: 0.10673 - acc: 0.9576 -- iter: 160/428
[A[ATraining Step: 356  | total loss: [1m[32m0.10158[0m[0m | time: 29.154s
[2K
| Adam | epoch: 026 | loss: 0.10158 - acc: 0.9587 -- iter: 192/428
[A[ATraining Step: 357  | total loss: [1m[32m0.10106[0m[0m | time: 34.716s
[2K
| Adam | epoch: 026 | loss: 0.10106 - acc: 0.9566 -- iter: 224/428
[A[ATraining Step: 358  | total loss: [1m[32m0.09572[0m[0m | time: 40.172s
[2K
| Adam | epoch: 026 | loss: 0.09572 - acc: 0.9609 -- iter: 256/428
[A[ATraining Step: 359  | total loss: [1m[32m0.09654[0m[0m | time: 43.082s
[2K
| Adam | epoch: 026 | loss: 0.09654 - acc: 0.9617 -- iter: 288/428
[A[ATraining Step: 360  | total loss: [1m[32m0.08775[0m[0m | time: 45.943s
[2K
| Adam | epoch: 026 | loss: 0.08775 - acc: 0.9655 -- iter: 320/428
[A[ATraining Step: 361  | total loss: [1m[32m0.07994[0m[0m | time: 53.084s
[2K
| Adam | epoch: 026 | loss: 0.07994 - acc: 0.9690 -- iter: 352/428
[A[ATraining Step: 362  | total loss: [1m[32m0.07734[0m[0m | time: 61.123s
[2K
| Adam | epoch: 026 | loss: 0.07734 - acc: 0.9721 -- iter: 384/428
[A[ATraining Step: 363  | total loss: [1m[32m0.07256[0m[0m | time: 67.296s
[2K
| Adam | epoch: 026 | loss: 0.07256 - acc: 0.9749 -- iter: 416/428
[A[ATraining Step: 364  | total loss: [1m[32m0.08183[0m[0m | time: 83.328s
[2K
| Adam | epoch: 026 | loss: 0.08183 - acc: 0.9743 | val_loss: 0.62886 - val_acc: 0.8060 -- iter: 428/428
--
Training Step: 365  | total loss: [1m[32m0.08100[0m[0m | time: 1.108s
[2K
| Adam | epoch: 027 | loss: 0.08100 - acc: 0.9706 -- iter: 032/428
[A[ATraining Step: 366  | total loss: [1m[32m0.07922[0m[0m | time: 2.265s
[2K
| Adam | epoch: 027 | loss: 0.07922 - acc: 0.9704 -- iter: 064/428
[A[ATraining Step: 367  | total loss: [1m[32m0.07253[0m[0m | time: 3.667s
[2K
| Adam | epoch: 027 | loss: 0.07253 - acc: 0.9734 -- iter: 096/428
[A[ATraining Step: 368  | total loss: [1m[32m0.07063[0m[0m | time: 4.638s
[2K
| Adam | epoch: 027 | loss: 0.07063 - acc: 0.9760 -- iter: 128/428
[A[ATraining Step: 369  | total loss: [1m[32m0.06590[0m[0m | time: 5.416s
[2K
| Adam | epoch: 027 | loss: 0.06590 - acc: 0.9784 -- iter: 160/428
[A[ATraining Step: 370  | total loss: [1m[32m0.06074[0m[0m | time: 6.315s
[2K
| Adam | epoch: 027 | loss: 0.06074 - acc: 0.9806 -- iter: 192/428
[A[ATraining Step: 371  | total loss: [1m[32m0.05971[0m[0m | time: 7.760s
[2K
| Adam | epoch: 027 | loss: 0.05971 - acc: 0.9794 -- iter: 224/428
[A[ATraining Step: 372  | total loss: [1m[32m0.05650[0m[0m | time: 8.939s
[2K
| Adam | epoch: 027 | loss: 0.05650 - acc: 0.9815 -- iter: 256/428
[A[ATraining Step: 373  | total loss: [1m[32m0.06268[0m[0m | time: 10.975s
[2K
| Adam | epoch: 027 | loss: 0.06268 - acc: 0.9739 -- iter: 288/428
[A[ATraining Step: 374  | total loss: [1m[32m0.06048[0m[0m | time: 12.839s
[2K
| Adam | epoch: 027 | loss: 0.06048 - acc: 0.9765 -- iter: 320/428
[A[ATraining Step: 375  | total loss: [1m[32m0.05611[0m[0m | time: 18.288s
[2K
| Adam | epoch: 027 | loss: 0.05611 - acc: 0.9789 -- iter: 352/428
[A[ATraining Step: 376  | total loss: [1m[32m0.05171[0m[0m | time: 27.989s
[2K
| Adam | epoch: 027 | loss: 0.05171 - acc: 0.9810 -- iter: 384/428
[A[ATraining Step: 377  | total loss: [1m[32m0.05059[0m[0m | time: 32.295s
[2K
| Adam | epoch: 027 | loss: 0.05059 - acc: 0.9829 -- iter: 416/428
[A[ATraining Step: 378  | total loss: [1m[32m0.06026[0m[0m | time: 52.432s
[2K
| Adam | epoch: 027 | loss: 0.06026 - acc: 0.9784 | val_loss: 0.77481 - val_acc: 0.8060 -- iter: 428/428
--
Training Step: 379  | total loss: [1m[32m0.05748[0m[0m | time: 2.531s
[2K
| Adam | epoch: 028 | loss: 0.05748 - acc: 0.9805 -- iter: 032/428
[A[ATraining Step: 380  | total loss: [1m[32m0.06531[0m[0m | time: 5.727s
[2K
| Adam | epoch: 028 | loss: 0.06531 - acc: 0.9793 -- iter: 064/428
[A[ATraining Step: 381  | total loss: [1m[32m0.06211[0m[0m | time: 9.953s
[2K
| Adam | epoch: 028 | loss: 0.06211 - acc: 0.9814 -- iter: 096/428
[A[ATraining Step: 382  | total loss: [1m[32m0.07963[0m[0m | time: 11.360s
[2K
| Adam | epoch: 028 | loss: 0.07963 - acc: 0.9708 -- iter: 128/428
[A[ATraining Step: 383  | total loss: [1m[32m0.07752[0m[0m | time: 12.797s
[2K
| Adam | epoch: 028 | loss: 0.07752 - acc: 0.9737 -- iter: 160/428
[A[ATraining Step: 384  | total loss: [1m[32m0.07461[0m[0m | time: 14.277s
[2K
| Adam | epoch: 028 | loss: 0.07461 - acc: 0.9763 -- iter: 192/428
[A[ATraining Step: 385  | total loss: [1m[32m0.09404[0m[0m | time: 15.844s
[2K
| Adam | epoch: 028 | loss: 0.09404 - acc: 0.9662 -- iter: 224/428
[A[ATraining Step: 386  | total loss: [1m[32m0.08650[0m[0m | time: 17.441s
[2K
| Adam | epoch: 028 | loss: 0.08650 - acc: 0.9696 -- iter: 256/428
[A[ATraining Step: 387  | total loss: [1m[32m0.08882[0m[0m | time: 18.945s
[2K
| Adam | epoch: 028 | loss: 0.08882 - acc: 0.9632 -- iter: 288/428
[A[ATraining Step: 388  | total loss: [1m[32m0.08048[0m[0m | time: 20.633s
[2K
| Adam | epoch: 028 | loss: 0.08048 - acc: 0.9669 -- iter: 320/428
[A[ATraining Step: 389  | total loss: [1m[32m0.07437[0m[0m | time: 21.254s
[2K
| Adam | epoch: 028 | loss: 0.07437 - acc: 0.9702 -- iter: 352/428
[A[ATraining Step: 390  | total loss: [1m[32m0.06860[0m[0m | time: 22.018s
[2K
| Adam | epoch: 028 | loss: 0.06860 - acc: 0.9732 -- iter: 384/428
[A[ATraining Step: 391  | total loss: [1m[32m0.06399[0m[0m | time: 23.710s
[2K
| Adam | epoch: 028 | loss: 0.06399 - acc: 0.9759 -- iter: 416/428
[A[ATraining Step: 392  | total loss: [1m[32m0.07351[0m[0m | time: 35.287s
[2K
| Adam | epoch: 028 | loss: 0.07351 - acc: 0.9720 | val_loss: 0.63455 - val_acc: 0.8134 -- iter: 428/428
--
Training Step: 393  | total loss: [1m[32m0.06833[0m[0m | time: 5.294s
[2K
| Adam | epoch: 029 | loss: 0.06833 - acc: 0.9748 -- iter: 032/428
[A[ATraining Step: 394  | total loss: [1m[32m0.06402[0m[0m | time: 11.239s
[2K
| Adam | epoch: 029 | loss: 0.06402 - acc: 0.9774 -- iter: 064/428
[A[ATraining Step: 395  | total loss: [1m[32m0.05925[0m[0m | time: 15.701s
[2K
| Adam | epoch: 029 | loss: 0.05925 - acc: 0.9796 -- iter: 096/428
[A[ATraining Step: 396  | total loss: [1m[32m0.07314[0m[0m | time: 19.885s
[2K
| Adam | epoch: 029 | loss: 0.07314 - acc: 0.9754 -- iter: 128/428
[A[ATraining Step: 397  | total loss: [1m[32m0.08174[0m[0m | time: 25.688s
[2K
| Adam | epoch: 029 | loss: 0.08174 - acc: 0.9685 -- iter: 160/428
[A[ATraining Step: 398  | total loss: [1m[32m0.07795[0m[0m | time: 30.572s
[2K
| Adam | epoch: 029 | loss: 0.07795 - acc: 0.9685 -- iter: 192/428
[A[ATraining Step: 399  | total loss: [1m[32m0.07154[0m[0m | time: 34.769s
[2K
| Adam | epoch: 029 | loss: 0.07154 - acc: 0.9717 -- iter: 224/428
[A[ATraining Step: 400  | total loss: [1m[32m0.07667[0m[0m | time: 42.124s
[2K
| Adam | epoch: 029 | loss: 0.07667 - acc: 0.9714 | val_loss: 0.78759 - val_acc: 0.7836 -- iter: 256/428
--
Training Step: 401  | total loss: [1m[32m0.08676[0m[0m | time: 43.691s
[2K
| Adam | epoch: 029 | loss: 0.08676 - acc: 0.9680 -- iter: 288/428
[A[ATraining Step: 402  | total loss: [1m[32m0.10060[0m[0m | time: 45.286s
[2K
| Adam | epoch: 029 | loss: 0.10060 - acc: 0.9618 -- iter: 320/428
[A[ATraining Step: 403  | total loss: [1m[32m0.09142[0m[0m | time: 46.927s
[2K
| Adam | epoch: 029 | loss: 0.09142 - acc: 0.9656 -- iter: 352/428
[A[ATraining Step: 404  | total loss: [1m[32m0.08460[0m[0m | time: 47.753s
[2K
| Adam | epoch: 029 | loss: 0.08460 - acc: 0.9691 -- iter: 384/428
[A[ATraining Step: 405  | total loss: [1m[32m0.10244[0m[0m | time: 48.358s
[2K
| Adam | epoch: 029 | loss: 0.10244 - acc: 0.9638 -- iter: 416/428
[A[ATraining Step: 406  | total loss: [1m[32m0.10957[0m[0m | time: 51.716s
[2K
| Adam | epoch: 029 | loss: 0.10957 - acc: 0.9591 | val_loss: 0.67063 - val_acc: 0.7612 -- iter: 428/428
--
Training Step: 407  | total loss: [1m[32m0.10993[0m[0m | time: 1.737s
[2K
| Adam | epoch: 030 | loss: 0.10993 - acc: 0.9601 -- iter: 032/428
[A[ATraining Step: 408  | total loss: [1m[32m0.09961[0m[0m | time: 3.269s
[2K
| Adam | epoch: 030 | loss: 0.09961 - acc: 0.9641 -- iter: 064/428
[A[ATraining Step: 409  | total loss: [1m[32m0.09434[0m[0m | time: 4.621s
[2K
| Adam | epoch: 030 | loss: 0.09434 - acc: 0.9645 -- iter: 096/428
[A[ATraining Step: 410  | total loss: [1m[32m0.09105[0m[0m | time: 6.541s
[2K
| Adam | epoch: 030 | loss: 0.09105 - acc: 0.9650 -- iter: 128/428
[A[ATraining Step: 411  | total loss: [1m[32m0.08270[0m[0m | time: 8.307s
[2K
| Adam | epoch: 030 | loss: 0.08270 - acc: 0.9685 -- iter: 160/428
[A[ATraining Step: 412  | total loss: [1m[32m0.07810[0m[0m | time: 10.406s
[2K
| Adam | epoch: 030 | loss: 0.07810 - acc: 0.9685 -- iter: 192/428
[A[ATraining Step: 413  | total loss: [1m[32m0.07459[0m[0m | time: 13.746s
[2K
| Adam | epoch: 030 | loss: 0.07459 - acc: 0.9716 -- iter: 224/428
[A[ATraining Step: 414  | total loss: [1m[32m0.07528[0m[0m | time: 17.412s
[2K
| Adam | epoch: 030 | loss: 0.07528 - acc: 0.9714 -- iter: 256/428
[A[ATraining Step: 415  | total loss: [1m[32m0.07003[0m[0m | time: 21.014s
[2K
| Adam | epoch: 030 | loss: 0.07003 - acc: 0.9742 -- iter: 288/428
[A[ATraining Step: 416  | total loss: [1m[32m0.06532[0m[0m | time: 23.680s
[2K
| Adam | epoch: 030 | loss: 0.06532 - acc: 0.9768 -- iter: 320/428
[A[ATraining Step: 417  | total loss: [1m[32m0.06508[0m[0m | time: 29.443s
[2K
| Adam | epoch: 030 | loss: 0.06508 - acc: 0.9760 -- iter: 352/428
[A[ATraining Step: 418  | total loss: [1m[32m0.08621[0m[0m | time: 31.688s
[2K
| Adam | epoch: 030 | loss: 0.08621 - acc: 0.9753 -- iter: 384/428
[A[ATraining Step: 419  | total loss: [1m[32m0.07819[0m[0m | time: 32.292s
[2K
| Adam | epoch: 030 | loss: 0.07819 - acc: 0.9777 -- iter: 416/428
[A[ATraining Step: 420  | total loss: [1m[32m0.07497[0m[0m | time: 34.597s
[2K
| Adam | epoch: 030 | loss: 0.07497 - acc: 0.9800 | val_loss: 0.60780 - val_acc: 0.8507 -- iter: 428/428
--
Validation AUC:0.8923545966228893
Validation AUPRC:0.9312416025357357
Test AUC:0.9020408163265305
Test AUPRC:0.9394113841901959
BestTestF1Score	0.88	0.64	0.84	0.82	0.94	80	17	32	5	0.46
BestTestMCCScore	0.88	0.64	0.84	0.82	0.94	80	17	32	5	0.46
BestTestAccuracyScore	0.88	0.64	0.84	0.84	0.92	78	15	34	7	0.63
BestValidationF1Score	0.88	0.68	0.85	0.84	0.93	76	14	38	6	0.46
BestValidationMCC	0.88	0.68	0.85	0.84	0.93	76	14	38	6	0.46
BestValidationAccuracy	0.88	0.68	0.85	0.85	0.91	75	13	39	7	0.63
TestPredictions (Threshold:0.46)
CHEMBL3084440,TP,ACT,1.0	CHEMBL2402900,TN,INACT,0.009999999776482582	CHEMBL3261478,TP,ACT,1.0	CHEMBL1917230,TN,INACT,0.05000000074505806	CHEMBL558226,TP,ACT,1.0	CHEMBL376289,FP,INACT,0.5600000023841858	CHEMBL449444,FP,INACT,0.8999999761581421	CHEMBL2205041,TP,ACT,1.0	CHEMBL2402897,TN,INACT,0.05000000074505806	CHEMBL3084780,TP,ACT,1.0	CHEMBL2409484,TN,INACT,0.0	CHEMBL2169973,TP,ACT,0.9900000095367432	CHEMBL511699,TP,ACT,0.9900000095367432	CHEMBL2058420,FN,ACT,0.03999999910593033	CHEMBL388212,TP,ACT,0.9900000095367432	CHEMBL1277282,TP,ACT,1.0	CHEMBL596951,TP,ACT,0.9900000095367432	CHEMBL2441755,TN,INACT,0.009999999776482582	CHEMBL3679406,TP,ACT,1.0	CHEMBL2204362,TP,ACT,1.0	CHEMBL333465,TN,INACT,0.0	CHEMBL1277281,TP,ACT,1.0	CHEMBL2169972,TP,ACT,1.0	CHEMBL3335594,FP,INACT,0.9700000286102295	CHEMBL471712,TP,ACT,0.9599999785423279	CHEMBL3673253,TP,ACT,0.9700000286102295	CHEMBL490073,TP,ACT,1.0	CHEMBL379302,TP,ACT,1.0	CHEMBL297283,TN,INACT,0.0	CHEMBL480798,FP,INACT,0.5699999928474426	CHEMBL519673,TN,INACT,0.03999999910593033	CHEMBL1945843,TP,ACT,1.0	CHEMBL1271790,TP,ACT,1.0	CHEMBL1272121,TP,ACT,1.0	CHEMBL3084765,TP,ACT,0.9900000095367432	CHEMBL570710,TP,ACT,1.0	CHEMBL18041,TP,ACT,0.9900000095367432	CHEMBL364005,FN,ACT,0.009999999776482582	CHEMBL3337656,TN,INACT,0.009999999776482582	CHEMBL3289075,FP,INACT,0.9399999976158142	CHEMBL3673250,TP,ACT,1.0	CHEMBL599011,TP,ACT,0.9900000095367432	CHEMBL1958328,TP,ACT,1.0	CHEMBL1643895,TP,ACT,1.0	CHEMBL569357,TP,ACT,1.0	CHEMBL1276832,TP,ACT,1.0	CHEMBL480797,TN,INACT,0.05999999865889549	CHEMBL2440690,TN,INACT,0.009999999776482582	CHEMBL1256531,FP,INACT,0.7300000190734863	CHEMBL3084430,TP,ACT,0.8199999928474426	CHEMBL3084767,TP,ACT,0.9900000095367432	CHEMBL461729,TP,ACT,1.0	CHEMBL599012,FN,ACT,0.009999999776482582	CHEMBL329179,TP,ACT,0.8899999856948853	CHEMBL3335591,FP,INACT,0.9599999785423279	CHEMBL422505,TN,INACT,0.009999999776482582	CHEMBL596758,TP,ACT,0.9800000190734863	CHEMBL1278087,TP,ACT,1.0	CHEMBL572249,TP,ACT,1.0	CHEMBL53194,FP,INACT,0.9200000166893005	CHEMBL154960,TN,INACT,0.0	CHEMBL156519,FP,INACT,0.8399999737739563	CHEMBL430886,TN,INACT,0.019999999552965164	CHEMBL290938,TP,ACT,1.0	CHEMBL3673254,TP,ACT,1.0	CHEMBL2205046,TP,ACT,1.0	CHEMBL1272177,TP,ACT,1.0	CHEMBL3608512,TN,INACT,0.029999999329447746	CHEMBL3133541,TN,INACT,0.4000000059604645	CHEMBL3261481,TP,ACT,1.0	CHEMBL1958322,TP,ACT,0.9900000095367432	CHEMBL1947048,FP,INACT,0.9900000095367432	CHEMBL2151439,TP,ACT,0.6100000143051147	CHEMBL3679390,TP,ACT,1.0	CHEMBL3274624,FP,INACT,1.0	CHEMBL1163516,TN,INACT,0.009999999776482582	CHEMBL488379,TN,INACT,0.009999999776482582	CHEMBL15056,TP,ACT,1.0	CHEMBL385227,TN,INACT,0.0	CHEMBL378349,TP,ACT,1.0	CHEMBL508949,TN,INACT,0.019999999552965164	CHEMBL3084781,TP,ACT,1.0	CHEMBL3084436,TP,ACT,0.8799999952316284	CHEMBL1276833,TP,ACT,1.0	CHEMBL3679395,TP,ACT,1.0	CHEMBL1958329,TP,ACT,1.0	CHEMBL585567,TP,ACT,1.0	CHEMBL519609,FN,ACT,0.019999999552965164	CHEMBL3108952,FP,INACT,1.0	CHEMBL93919,TP,ACT,0.9900000095367432	CHEMBL122317,TN,INACT,0.029999999329447746	CHEMBL2112852,TN,INACT,0.07999999821186066	CHEMBL3084773,TP,ACT,1.0	CHEMBL2402889,FP,INACT,0.8600000143051147	CHEMBL2204363,TP,ACT,1.0	CHEMBL3679401,TP,ACT,0.9800000190734863	CHEMBL2381567,FP,INACT,0.9100000262260437	CHEMBL3084766,TP,ACT,1.0	CHEMBL2179520,TN,INACT,0.009999999776482582	CHEMBL611036,TN,INACT,0.10999999940395355	CHEMBL1277187,TP,ACT,1.0	CHEMBL597984,TP,ACT,0.6899999976158142	CHEMBL388049,TN,INACT,0.0	CHEMBL327104,FP,INACT,0.9599999785423279	CHEMBL2205039,TP,ACT,1.0	CHEMBL457965,TN,INACT,0.05000000074505806	CHEMBL3084759,TP,ACT,1.0	CHEMBL305582,TP,ACT,0.46000000834465027	CHEMBL2169965,TP,ACT,1.0	CHEMBL2058426,TP,ACT,1.0	CHEMBL3261480,TP,ACT,0.9900000095367432	CHEMBL489271,TP,ACT,1.0	CHEMBL498186,FP,INACT,0.9900000095367432	CHEMBL3679400,TP,ACT,1.0	CHEMBL3093187,TP,ACT,0.9800000190734863	CHEMBL2169975,TP,ACT,1.0	CHEMBL274413,FP,INACT,0.9700000286102295	CHEMBL611082,TP,ACT,0.6800000071525574	CHEMBL19019,TN,INACT,0.0	CHEMBL1643892,TP,ACT,0.9900000095367432	CHEMBL1163517,TN,INACT,0.3499999940395355	CHEMBL2205032,TP,ACT,0.9900000095367432	CHEMBL1938900,TN,INACT,0.0	CHEMBL2441756,TN,INACT,0.009999999776482582	CHEMBL2440692,TN,INACT,0.009999999776482582	CHEMBL2205031,TP,ACT,1.0	CHEMBL1277558,TP,ACT,0.9900000095367432	CHEMBL2402899,TN,INACT,0.07000000029802322	CHEMBL481153,FN,ACT,0.03999999910593033	CHEMBL2204365,TP,ACT,1.0	CHEMBL177611,TP,ACT,0.9599999785423279	CHEMBL1278175,TP,ACT,1.0	CHEMBL444985,TP,ACT,0.75	CHEMBL3084442,TP,ACT,0.6399999856948853	

