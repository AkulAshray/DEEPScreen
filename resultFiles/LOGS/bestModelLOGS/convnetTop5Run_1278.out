ImageNetInceptionV2 CHEMBL2563 RMSprop 0.0005 15 0 0 0.8 False True
Number of active compounds :	114
Number of inactive compounds :	114
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2563_RMSprop_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2563_RMSprop_0.0005_15_0.8/
---------------------------------
Training samples: 133
Validation samples: 42
--
Training Step: 1  | time: 59.061s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/133
[A[ATraining Step: 2  | total loss: [1m[32m0.62921[0m[0m | time: 68.523s
[2K
| RMSProp | epoch: 001 | loss: 0.62921 - acc: 0.4500 -- iter: 064/133
[A[ATraining Step: 3  | total loss: [1m[32m0.70547[0m[0m | time: 76.856s
[2K
| RMSProp | epoch: 001 | loss: 0.70547 - acc: 0.4142 -- iter: 096/133
[A[ATraining Step: 4  | total loss: [1m[32m0.72479[0m[0m | time: 84.764s
[2K
| RMSProp | epoch: 001 | loss: 0.72479 - acc: 0.4082 -- iter: 128/133
[A[ATraining Step: 5  | total loss: [1m[32m0.70112[0m[0m | time: 94.300s
[2K
| RMSProp | epoch: 001 | loss: 0.70112 - acc: 0.4934 | val_loss: 0.70562 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 6  | total loss: [1m[32m0.71452[0m[0m | time: 3.869s
[2K
| RMSProp | epoch: 002 | loss: 0.71452 - acc: 0.4334 -- iter: 032/133
[A[ATraining Step: 7  | total loss: [1m[32m0.70007[0m[0m | time: 16.297s
[2K
| RMSProp | epoch: 002 | loss: 0.70007 - acc: 0.4133 -- iter: 064/133
[A[ATraining Step: 8  | total loss: [1m[32m0.70513[0m[0m | time: 29.095s
[2K
| RMSProp | epoch: 002 | loss: 0.70513 - acc: 0.4445 -- iter: 096/133
[A[ATraining Step: 9  | total loss: [1m[32m0.71445[0m[0m | time: 36.905s
[2K
| RMSProp | epoch: 002 | loss: 0.71445 - acc: 0.4243 -- iter: 128/133
[A[ATraining Step: 10  | total loss: [1m[32m0.70458[0m[0m | time: 46.822s
[2K
| RMSProp | epoch: 002 | loss: 0.70458 - acc: 0.4778 | val_loss: 0.70586 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 11  | total loss: [1m[32m0.70059[0m[0m | time: 3.731s
[2K
| RMSProp | epoch: 003 | loss: 0.70059 - acc: 0.4735 -- iter: 032/133
[A[ATraining Step: 12  | total loss: [1m[32m0.72341[0m[0m | time: 7.228s
[2K
| RMSProp | epoch: 003 | loss: 0.72341 - acc: 0.3504 -- iter: 064/133
[A[ATraining Step: 13  | total loss: [1m[32m0.72400[0m[0m | time: 19.869s
[2K
| RMSProp | epoch: 003 | loss: 0.72400 - acc: 0.2860 -- iter: 096/133
[A[ATraining Step: 14  | total loss: [1m[32m0.70889[0m[0m | time: 32.526s
[2K
| RMSProp | epoch: 003 | loss: 0.70889 - acc: 0.3863 -- iter: 128/133
[A[ATraining Step: 15  | total loss: [1m[32m0.69747[0m[0m | time: 46.079s
[2K
| RMSProp | epoch: 003 | loss: 0.69747 - acc: 0.4552 | val_loss: 0.69666 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 16  | total loss: [1m[32m0.67679[0m[0m | time: 18.322s
[2K
| RMSProp | epoch: 004 | loss: 0.67679 - acc: 0.5423 -- iter: 032/133
[A[ATraining Step: 17  | total loss: [1m[32m0.67481[0m[0m | time: 22.392s
[2K
| RMSProp | epoch: 004 | loss: 0.67481 - acc: 0.5608 -- iter: 064/133
[A[ATraining Step: 18  | total loss: [1m[32m0.66130[0m[0m | time: 25.984s
[2K
| RMSProp | epoch: 004 | loss: 0.66130 - acc: 0.6436 -- iter: 096/133
[A[ATraining Step: 19  | total loss: [1m[32m0.66022[0m[0m | time: 38.741s
[2K
| RMSProp | epoch: 004 | loss: 0.66022 - acc: 0.6958 -- iter: 128/133
[A[ATraining Step: 20  | total loss: [1m[32m0.68180[0m[0m | time: 68.106s
[2K
| RMSProp | epoch: 004 | loss: 0.68180 - acc: 0.6529 | val_loss: 0.70071 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 21  | total loss: [1m[32m0.68948[0m[0m | time: 36.458s
[2K
| RMSProp | epoch: 005 | loss: 0.68948 - acc: 0.6055 -- iter: 032/133
[A[ATraining Step: 22  | total loss: [1m[32m0.68440[0m[0m | time: 105.163s
[2K
| RMSProp | epoch: 005 | loss: 0.68440 - acc: 0.6113 -- iter: 064/133
[A[ATraining Step: 23  | total loss: [1m[32m0.67960[0m[0m | time: 127.044s
[2K
| RMSProp | epoch: 005 | loss: 0.67960 - acc: 0.6153 -- iter: 096/133
[A[ATraining Step: 24  | total loss: [1m[32m0.69203[0m[0m | time: 132.572s
[2K
| RMSProp | epoch: 005 | loss: 0.69203 - acc: 0.4985 -- iter: 128/133
[A[ATraining Step: 25  | total loss: [1m[32m0.66551[0m[0m | time: 260.120s
[2K
| RMSProp | epoch: 005 | loss: 0.66551 - acc: 0.6353 | val_loss: 0.70312 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 26  | total loss: [1m[32m0.67327[0m[0m | time: 14.994s
[2K
| RMSProp | epoch: 006 | loss: 0.67327 - acc: 0.5995 -- iter: 032/133
[A[ATraining Step: 27  | total loss: [1m[32m0.68134[0m[0m | time: 22.965s
[2K
| RMSProp | epoch: 006 | loss: 0.68134 - acc: 0.5659 -- iter: 064/133
[A[ATraining Step: 28  | total loss: [1m[32m0.67621[0m[0m | time: 31.217s
[2K
| RMSProp | epoch: 006 | loss: 0.67621 - acc: 0.5806 -- iter: 096/133
[A[ATraining Step: 29  | total loss: [1m[32m0.67098[0m[0m | time: 33.212s
[2K
| RMSProp | epoch: 006 | loss: 0.67098 - acc: 0.5914 -- iter: 128/133
[A[ATraining Step: 30  | total loss: [1m[32m0.66920[0m[0m | time: 39.133s
[2K
| RMSProp | epoch: 006 | loss: 0.66920 - acc: 0.5461 | val_loss: 0.72960 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 31  | total loss: [1m[32m0.64945[0m[0m | time: 181.262s
[2K
| RMSProp | epoch: 007 | loss: 0.64945 - acc: 0.6047 -- iter: 032/133
[A[ATraining Step: 32  | total loss: [1m[32m0.66909[0m[0m | time: 257.628s
[2K
| RMSProp | epoch: 007 | loss: 0.66909 - acc: 0.5741 -- iter: 064/133
[A[ATraining Step: 33  | total loss: [1m[32m0.67937[0m[0m | time: 342.007s
[2K
| RMSProp | epoch: 007 | loss: 0.67937 - acc: 0.5578 -- iter: 096/133
[A[ATraining Step: 34  | total loss: [1m[32m0.68485[0m[0m | time: 367.950s
[2K
| RMSProp | epoch: 007 | loss: 0.68485 - acc: 0.5454 -- iter: 128/133
[A[ATraining Step: 35  | total loss: [1m[32m0.68447[0m[0m | time: 374.765s
[2K
| RMSProp | epoch: 007 | loss: 0.68447 - acc: 0.5425 | val_loss: 0.70516 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 36  | total loss: [1m[32m0.66654[0m[0m | time: 5.416s
[2K
| RMSProp | epoch: 008 | loss: 0.66654 - acc: 0.6361 -- iter: 032/133
[A[ATraining Step: 37  | total loss: [1m[32m0.65040[0m[0m | time: 34.088s
[2K
| RMSProp | epoch: 008 | loss: 0.65040 - acc: 0.6688 -- iter: 064/133
[A[ATraining Step: 38  | total loss: [1m[32m0.64854[0m[0m | time: 47.583s
[2K
| RMSProp | epoch: 008 | loss: 0.64854 - acc: 0.6664 -- iter: 096/133
[A[ATraining Step: 39  | total loss: [1m[32m0.65687[0m[0m | time: 60.555s
[2K
| RMSProp | epoch: 008 | loss: 0.65687 - acc: 0.6345 -- iter: 128/133
[A[ATraining Step: 40  | total loss: [1m[32m0.66431[0m[0m | time: 83.464s
[2K
| RMSProp | epoch: 008 | loss: 0.66431 - acc: 0.6152 | val_loss: 0.69657 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 41  | total loss: [1m[32m0.66670[0m[0m | time: 3.518s
[2K
| RMSProp | epoch: 009 | loss: 0.66670 - acc: 0.5825 -- iter: 032/133
[A[ATraining Step: 42  | total loss: [1m[32m0.66393[0m[0m | time: 7.133s
[2K
| RMSProp | epoch: 009 | loss: 0.66393 - acc: 0.5857 -- iter: 064/133
[A[ATraining Step: 43  | total loss: [1m[32m0.64047[0m[0m | time: 25.777s
[2K
| RMSProp | epoch: 009 | loss: 0.64047 - acc: 0.6588 -- iter: 096/133
[A[ATraining Step: 44  | total loss: [1m[32m0.64021[0m[0m | time: 55.220s
[2K
| RMSProp | epoch: 009 | loss: 0.64021 - acc: 0.6692 -- iter: 128/133
[A[ATraining Step: 45  | total loss: [1m[32m0.64805[0m[0m | time: 78.729s
[2K
| RMSProp | epoch: 009 | loss: 0.64805 - acc: 0.6617 | val_loss: 0.70975 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 46  | total loss: [1m[32m0.64318[0m[0m | time: 13.123s
[2K
| RMSProp | epoch: 010 | loss: 0.64318 - acc: 0.6868 -- iter: 032/133
[A[ATraining Step: 47  | total loss: [1m[32m0.63534[0m[0m | time: 16.534s
[2K
| RMSProp | epoch: 010 | loss: 0.63534 - acc: 0.7023 -- iter: 064/133
[A[ATraining Step: 48  | total loss: [1m[32m0.63669[0m[0m | time: 19.941s
[2K
| RMSProp | epoch: 010 | loss: 0.63669 - acc: 0.7180 -- iter: 096/133
[A[ATraining Step: 49  | total loss: [1m[32m0.61250[0m[0m | time: 30.932s
[2K
| RMSProp | epoch: 010 | loss: 0.61250 - acc: 0.7625 -- iter: 128/133
[A[ATraining Step: 50  | total loss: [1m[32m0.62865[0m[0m | time: 56.598s
[2K
| RMSProp | epoch: 010 | loss: 0.62865 - acc: 0.7169 | val_loss: 0.69279 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 51  | total loss: [1m[32m0.62638[0m[0m | time: 17.835s
[2K
| RMSProp | epoch: 011 | loss: 0.62638 - acc: 0.7124 -- iter: 032/133
[A[ATraining Step: 52  | total loss: [1m[32m0.62698[0m[0m | time: 41.083s
[2K
| RMSProp | epoch: 011 | loss: 0.62698 - acc: 0.7134 -- iter: 064/133
[A[ATraining Step: 53  | total loss: [1m[32m0.62483[0m[0m | time: 46.350s
[2K
| RMSProp | epoch: 011 | loss: 0.62483 - acc: 0.7188 -- iter: 096/133
[A[ATraining Step: 54  | total loss: [1m[32m0.62417[0m[0m | time: 50.385s
[2K
| RMSProp | epoch: 011 | loss: 0.62417 - acc: 0.7306 -- iter: 128/133
[A[ATraining Step: 55  | total loss: [1m[32m0.60767[0m[0m | time: 60.869s
[2K
| RMSProp | epoch: 011 | loss: 0.60767 - acc: 0.7691 | val_loss: 0.69016 - val_acc: 0.5238 -- iter: 133/133
--
Training Step: 56  | total loss: [1m[32m0.61107[0m[0m | time: 16.289s
[2K
| RMSProp | epoch: 012 | loss: 0.61107 - acc: 0.7532 -- iter: 032/133
[A[ATraining Step: 57  | total loss: [1m[32m0.61736[0m[0m | time: 85.814s
[2K
| RMSProp | epoch: 012 | loss: 0.61736 - acc: 0.7398 -- iter: 064/133
[A[ATraining Step: 58  | total loss: [1m[32m0.61135[0m[0m | time: 112.739s
[2K
| RMSProp | epoch: 012 | loss: 0.61135 - acc: 0.7241 -- iter: 096/133
[A[ATraining Step: 59  | total loss: [1m[32m0.61879[0m[0m | time: 117.730s
[2K
| RMSProp | epoch: 012 | loss: 0.61879 - acc: 0.6898 -- iter: 128/133
[A[ATraining Step: 60  | total loss: [1m[32m0.61706[0m[0m | time: 128.211s
[2K
| RMSProp | epoch: 012 | loss: 0.61706 - acc: 0.6779 | val_loss: 0.91573 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 61  | total loss: [1m[32m0.59647[0m[0m | time: 11.692s
[2K
| RMSProp | epoch: 013 | loss: 0.59647 - acc: 0.7199 -- iter: 032/133
[A[ATraining Step: 62  | total loss: [1m[32m0.60361[0m[0m | time: 24.510s
[2K
| RMSProp | epoch: 013 | loss: 0.60361 - acc: 0.7198 -- iter: 064/133
[A[ATraining Step: 63  | total loss: [1m[32m0.61402[0m[0m | time: 38.598s
[2K
| RMSProp | epoch: 013 | loss: 0.61402 - acc: 0.6880 -- iter: 096/133
[A[ATraining Step: 64  | total loss: [1m[32m0.60793[0m[0m | time: 59.736s
[2K
| RMSProp | epoch: 013 | loss: 0.60793 - acc: 0.6957 -- iter: 128/133
[A[ATraining Step: 65  | total loss: [1m[32m0.60293[0m[0m | time: 69.916s
[2K
| RMSProp | epoch: 013 | loss: 0.60293 - acc: 0.6947 | val_loss: 0.71295 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 66  | total loss: [1m[32m0.60405[0m[0m | time: 4.803s
[2K
| RMSProp | epoch: 014 | loss: 0.60405 - acc: 0.7075 -- iter: 032/133
[A[ATraining Step: 67  | total loss: [1m[32m0.58531[0m[0m | time: 19.185s
[2K
| RMSProp | epoch: 014 | loss: 0.58531 - acc: 0.7426 -- iter: 064/133
[A[ATraining Step: 68  | total loss: [1m[32m0.59243[0m[0m | time: 32.611s
[2K
| RMSProp | epoch: 014 | loss: 0.59243 - acc: 0.7102 -- iter: 096/133
[A[ATraining Step: 69  | total loss: [1m[32m0.59856[0m[0m | time: 58.546s
[2K
| RMSProp | epoch: 014 | loss: 0.59856 - acc: 0.6893 -- iter: 128/133
[A[ATraining Step: 70  | total loss: [1m[32m0.59480[0m[0m | time: 105.746s
[2K
| RMSProp | epoch: 014 | loss: 0.59480 - acc: 0.6855 | val_loss: 0.76267 - val_acc: 0.5000 -- iter: 133/133
--
Training Step: 71  | total loss: [1m[32m0.59134[0m[0m | time: 3.565s
[2K
| RMSProp | epoch: 015 | loss: 0.59134 - acc: 0.6928 -- iter: 032/133
[A[ATraining Step: 72  | total loss: [1m[32m0.59180[0m[0m | time: 6.615s
[2K
| RMSProp | epoch: 015 | loss: 0.59180 - acc: 0.7049 -- iter: 064/133
[A[ATraining Step: 73  | total loss: [1m[32m0.57329[0m[0m | time: 23.288s
[2K
| RMSProp | epoch: 015 | loss: 0.57329 - acc: 0.7377 -- iter: 096/133
[A[ATraining Step: 74  | total loss: [1m[32m0.57657[0m[0m | time: 36.318s
[2K
| RMSProp | epoch: 015 | loss: 0.57657 - acc: 0.7253 -- iter: 128/133
[A[ATraining Step: 75  | total loss: [1m[32m0.57241[0m[0m | time: 52.730s
[2K
| RMSProp | epoch: 015 | loss: 0.57241 - acc: 0.7449 | val_loss: 0.67318 - val_acc: 0.5952 -- iter: 133/133
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.6235827664399093
Validation AUPRC:0.6461611457452718
Test AUC:0.7847222222222222
Test AUPRC:0.7801040547792113
BestTestF1Score	0.68	0.37	0.62	0.53	0.94	17	15	9	1	0.49
BestTestMCCScore	0.61	0.36	0.69	0.67	0.56	10	5	19	8	0.52
BestTestAccuracyScore	0.61	0.36	0.69	0.67	0.56	10	5	19	8	0.52
BestValidationF1Score	0.69	0.24	0.6	0.56	0.9	19	15	6	2	0.49
BestValidationMCC	0.5	0.27	0.62	0.73	0.38	8	3	18	13	0.52
BestValidationAccuracy	0.5	0.27	0.62	0.73	0.38	8	3	18	13	0.52
TestPredictions (Threshold:0.52)
CHEMBL3338418,TN,INACT,0.49000000953674316	CHEMBL518821,FN,ACT,0.49000000953674316	CHEMBL489332,TP,ACT,0.550000011920929	CHEMBL1830420,TP,ACT,0.6000000238418579	CHEMBL1083086,FN,ACT,0.4000000059604645	CHEMBL583967,TP,ACT,0.5299999713897705	CHEMBL3220925,FP,INACT,0.5299999713897705	CHEMBL1800246,TN,INACT,0.47999998927116394	CHEMBL561209,FP,INACT,0.5400000214576721	CHEMBL402363,FN,ACT,0.5199999809265137	CHEMBL3110005,TP,ACT,0.5699999928474426	CHEMBL1934907,TN,INACT,0.4699999988079071	CHEMBL1767041,TN,INACT,0.47999998927116394	CHEMBL1631912,FN,ACT,0.5199999809265137	CHEMBL3233755,FN,ACT,0.5099999904632568	CHEMBL2047682,TN,INACT,0.47999998927116394	CHEMBL3262727,FN,ACT,0.5199999809265137	CHEMBL447964,TN,INACT,0.49000000953674316	CHEMBL1213492,TP,ACT,0.550000011920929	CHEMBL3670668,TP,ACT,0.6000000238418579	CHEMBL470843,FP,INACT,0.5299999713897705	CHEMBL1800383,TN,INACT,0.44999998807907104	CHEMBL1213457,TP,ACT,0.5699999928474426	CHEMBL251011,TP,ACT,0.5699999928474426	CHEMBL1164241,TN,INACT,0.49000000953674316	CHEMBL1767044,TN,INACT,0.44999998807907104	CHEMBL3235787,TN,INACT,0.5	CHEMBL472345,TN,INACT,0.49000000953674316	CHEMBL216641,TP,ACT,0.550000011920929	CHEMBL2312164,FN,ACT,0.49000000953674316	CHEMBL515285,TN,INACT,0.49000000953674316	CHEMBL1767036,TN,INACT,0.4699999988079071	CHEMBL1767038,TN,INACT,0.4699999988079071	CHEMBL3110007,FP,INACT,0.5299999713897705	CHEMBL574594,FN,ACT,0.5	CHEMBL585365,TP,ACT,0.5299999713897705	CHEMBL512179,TN,INACT,0.5199999809265137	CHEMBL1934896,TN,INACT,0.5099999904632568	CHEMBL2413294,TN,INACT,0.5099999904632568	CHEMBL1934894,TN,INACT,0.47999998927116394	CHEMBL1767043,TN,INACT,0.5199999809265137	CHEMBL3260857,FP,INACT,0.550000011920929	

