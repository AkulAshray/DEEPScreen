ImageNetInceptionV2 CHEMBL4261 adam 0.0001 30 0 0 0.6 False True
Number of active compounds :	131
Number of inactive compounds :	131
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4261_adam_0.0001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4261_adam_0.0001_30_0.6/
---------------------------------
Training samples: 167
Validation samples: 53
--
Training Step: 1  | time: 65.271s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/167
[A[ATraining Step: 2  | total loss: [1m[32m0.67300[0m[0m | time: 80.800s
[2K
| Adam | epoch: 001 | loss: 0.67300 - acc: 0.4781 -- iter: 064/167
[A[ATraining Step: 3  | total loss: [1m[32m0.69861[0m[0m | time: 96.167s
[2K
| Adam | epoch: 001 | loss: 0.69861 - acc: 0.5727 -- iter: 096/167
[A[ATraining Step: 4  | total loss: [1m[32m0.63776[0m[0m | time: 111.441s
[2K
| Adam | epoch: 001 | loss: 0.63776 - acc: 0.7057 -- iter: 128/167
[A[ATraining Step: 5  | total loss: [1m[32m0.61782[0m[0m | time: 126.656s
[2K
| Adam | epoch: 001 | loss: 0.61782 - acc: 0.7147 -- iter: 160/167
[A[ATraining Step: 6  | total loss: [1m[32m0.65662[0m[0m | time: 148.012s
[2K
| Adam | epoch: 001 | loss: 0.65662 - acc: 0.6570 | val_loss: 0.76247 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 7  | total loss: [1m[32m0.59034[0m[0m | time: 4.597s
[2K
| Adam | epoch: 002 | loss: 0.59034 - acc: 0.6914 -- iter: 032/167
[A[ATraining Step: 8  | total loss: [1m[32m0.44842[0m[0m | time: 18.629s
[2K
| Adam | epoch: 002 | loss: 0.44842 - acc: 0.7846 -- iter: 064/167
[A[ATraining Step: 9  | total loss: [1m[32m0.51532[0m[0m | time: 32.838s
[2K
| Adam | epoch: 002 | loss: 0.51532 - acc: 0.7167 -- iter: 096/167
[A[ATraining Step: 10  | total loss: [1m[32m0.49822[0m[0m | time: 50.094s
[2K
| Adam | epoch: 002 | loss: 0.49822 - acc: 0.7958 -- iter: 128/167
[A[ATraining Step: 11  | total loss: [1m[32m0.46250[0m[0m | time: 63.470s
[2K
| Adam | epoch: 002 | loss: 0.46250 - acc: 0.8185 -- iter: 160/167
[A[ATraining Step: 12  | total loss: [1m[32m0.46072[0m[0m | time: 79.854s
[2K
| Adam | epoch: 002 | loss: 0.46072 - acc: 0.7877 | val_loss: 0.96687 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 13  | total loss: [1m[32m0.44577[0m[0m | time: 4.838s
[2K
| Adam | epoch: 003 | loss: 0.44577 - acc: 0.8117 -- iter: 032/167
[A[ATraining Step: 14  | total loss: [1m[32m0.56093[0m[0m | time: 9.361s
[2K
| Adam | epoch: 003 | loss: 0.56093 - acc: 0.6550 -- iter: 064/167
[A[ATraining Step: 15  | total loss: [1m[32m0.52907[0m[0m | time: 22.852s
[2K
| Adam | epoch: 003 | loss: 0.52907 - acc: 0.7341 -- iter: 096/167
[A[ATraining Step: 16  | total loss: [1m[32m0.49793[0m[0m | time: 37.048s
[2K
| Adam | epoch: 003 | loss: 0.49793 - acc: 0.7518 -- iter: 128/167
[A[ATraining Step: 17  | total loss: [1m[32m0.39621[0m[0m | time: 51.295s
[2K
| Adam | epoch: 003 | loss: 0.39621 - acc: 0.8299 -- iter: 160/167
[A[ATraining Step: 18  | total loss: [1m[32m0.33516[0m[0m | time: 69.272s
[2K
| Adam | epoch: 003 | loss: 0.33516 - acc: 0.8671 | val_loss: 0.99573 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 19  | total loss: [1m[32m0.29109[0m[0m | time: 14.462s
[2K
| Adam | epoch: 004 | loss: 0.29109 - acc: 0.9010 -- iter: 032/167
[A[ATraining Step: 20  | total loss: [1m[32m0.25155[0m[0m | time: 18.963s
[2K
| Adam | epoch: 004 | loss: 0.25155 - acc: 0.9228 -- iter: 064/167
[A[ATraining Step: 21  | total loss: [1m[32m0.25059[0m[0m | time: 23.874s
[2K
| Adam | epoch: 004 | loss: 0.25059 - acc: 0.9024 -- iter: 096/167
[A[ATraining Step: 22  | total loss: [1m[32m0.20891[0m[0m | time: 38.134s
[2K
| Adam | epoch: 004 | loss: 0.20891 - acc: 0.9317 -- iter: 128/167
[A[ATraining Step: 23  | total loss: [1m[32m0.21618[0m[0m | time: 52.460s
[2K
| Adam | epoch: 004 | loss: 0.21618 - acc: 0.9243 -- iter: 160/167
[A[ATraining Step: 24  | total loss: [1m[32m0.19870[0m[0m | time: 77.812s
[2K
| Adam | epoch: 004 | loss: 0.19870 - acc: 0.9368 | val_loss: 1.21512 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 25  | total loss: [1m[32m0.17017[0m[0m | time: 14.126s
[2K
| Adam | epoch: 005 | loss: 0.17017 - acc: 0.9540 -- iter: 032/167
[A[ATraining Step: 26  | total loss: [1m[32m0.14162[0m[0m | time: 33.256s
[2K
| Adam | epoch: 005 | loss: 0.14162 - acc: 0.9662 -- iter: 064/167
[A[ATraining Step: 27  | total loss: [1m[32m0.12486[0m[0m | time: 38.249s
[2K
| Adam | epoch: 005 | loss: 0.12486 - acc: 0.9749 -- iter: 096/167
[A[ATraining Step: 28  | total loss: [1m[32m0.12336[0m[0m | time: 42.612s
[2K
| Adam | epoch: 005 | loss: 0.12336 - acc: 0.9812 -- iter: 128/167
[A[ATraining Step: 29  | total loss: [1m[32m0.10800[0m[0m | time: 56.953s
[2K
| Adam | epoch: 005 | loss: 0.10800 - acc: 0.9858 -- iter: 160/167
[A[ATraining Step: 30  | total loss: [1m[32m0.09202[0m[0m | time: 76.110s
[2K
| Adam | epoch: 005 | loss: 0.09202 - acc: 0.9891 | val_loss: 1.60820 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 31  | total loss: [1m[32m0.10379[0m[0m | time: 13.883s
[2K
| Adam | epoch: 006 | loss: 0.10379 - acc: 0.9844 -- iter: 032/167
[A[ATraining Step: 32  | total loss: [1m[32m0.08565[0m[0m | time: 28.084s
[2K
| Adam | epoch: 006 | loss: 0.08565 - acc: 0.9879 -- iter: 064/167
[A[ATraining Step: 33  | total loss: [1m[32m0.06927[0m[0m | time: 42.437s
[2K
| Adam | epoch: 006 | loss: 0.06927 - acc: 0.9906 -- iter: 096/167
[A[ATraining Step: 34  | total loss: [1m[32m0.06071[0m[0m | time: 47.018s
[2K
| Adam | epoch: 006 | loss: 0.06071 - acc: 0.9926 -- iter: 128/167
[A[ATraining Step: 35  | total loss: [1m[32m0.05581[0m[0m | time: 51.897s
[2K
| Adam | epoch: 006 | loss: 0.05581 - acc: 0.9941 -- iter: 160/167
[A[ATraining Step: 36  | total loss: [1m[32m0.04979[0m[0m | time: 70.214s
[2K
| Adam | epoch: 006 | loss: 0.04979 - acc: 0.9953 | val_loss: 2.22767 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 37  | total loss: [1m[32m0.04293[0m[0m | time: 14.453s
[2K
| Adam | epoch: 007 | loss: 0.04293 - acc: 0.9963 -- iter: 032/167
[A[ATraining Step: 38  | total loss: [1m[32m0.03704[0m[0m | time: 27.820s
[2K
| Adam | epoch: 007 | loss: 0.03704 - acc: 0.9970 -- iter: 064/167
[A[ATraining Step: 39  | total loss: [1m[32m0.03121[0m[0m | time: 42.047s
[2K
| Adam | epoch: 007 | loss: 0.03121 - acc: 0.9976 -- iter: 096/167
[A[ATraining Step: 40  | total loss: [1m[32m0.02608[0m[0m | time: 56.494s
[2K
| Adam | epoch: 007 | loss: 0.02608 - acc: 0.9980 -- iter: 128/167
[A[ATraining Step: 41  | total loss: [1m[32m0.02197[0m[0m | time: 61.252s
[2K
| Adam | epoch: 007 | loss: 0.02197 - acc: 0.9984 -- iter: 160/167
[A[ATraining Step: 42  | total loss: [1m[32m0.03667[0m[0m | time: 69.775s
[2K
| Adam | epoch: 007 | loss: 0.03667 - acc: 0.9987 | val_loss: 2.79219 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 43  | total loss: [1m[32m0.03213[0m[0m | time: 15.371s
[2K
| Adam | epoch: 008 | loss: 0.03213 - acc: 0.9989 -- iter: 032/167
[A[ATraining Step: 44  | total loss: [1m[32m0.03414[0m[0m | time: 30.083s
[2K
| Adam | epoch: 008 | loss: 0.03414 - acc: 0.9937 -- iter: 064/167
[A[ATraining Step: 45  | total loss: [1m[32m0.07118[0m[0m | time: 45.175s
[2K
| Adam | epoch: 008 | loss: 0.07118 - acc: 0.9895 -- iter: 096/167
[A[ATraining Step: 46  | total loss: [1m[32m0.05972[0m[0m | time: 60.394s
[2K
| Adam | epoch: 008 | loss: 0.05972 - acc: 0.9912 -- iter: 128/167
[A[ATraining Step: 47  | total loss: [1m[32m0.05034[0m[0m | time: 70.882s
[2K
| Adam | epoch: 008 | loss: 0.05034 - acc: 0.9927 -- iter: 160/167
[A[ATraining Step: 48  | total loss: [1m[32m0.04256[0m[0m | time: 76.718s
[2K
| Adam | epoch: 008 | loss: 0.04256 - acc: 0.9938 | val_loss: 3.10431 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 49  | total loss: [1m[32m0.04215[0m[0m | time: 5.098s
[2K
| Adam | epoch: 009 | loss: 0.04215 - acc: 0.9948 -- iter: 032/167
[A[ATraining Step: 50  | total loss: [1m[32m0.03600[0m[0m | time: 18.785s
[2K
| Adam | epoch: 009 | loss: 0.03600 - acc: 0.9956 -- iter: 064/167
[A[ATraining Step: 51  | total loss: [1m[32m0.03138[0m[0m | time: 34.933s
[2K
| Adam | epoch: 009 | loss: 0.03138 - acc: 0.9963 -- iter: 096/167
[A[ATraining Step: 52  | total loss: [1m[32m0.02706[0m[0m | time: 58.809s
[2K
| Adam | epoch: 009 | loss: 0.02706 - acc: 0.9968 -- iter: 128/167
[A[ATraining Step: 53  | total loss: [1m[32m0.02340[0m[0m | time: 72.844s
[2K
| Adam | epoch: 009 | loss: 0.02340 - acc: 0.9973 -- iter: 160/167
[A[ATraining Step: 54  | total loss: [1m[32m0.02093[0m[0m | time: 123.266s
[2K
| Adam | epoch: 009 | loss: 0.02093 - acc: 0.9977 | val_loss: 2.59477 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 55  | total loss: [1m[32m0.05108[0m[0m | time: 7.712s
[2K
| Adam | epoch: 010 | loss: 0.05108 - acc: 0.9936 -- iter: 032/167
[A[ATraining Step: 56  | total loss: [1m[32m0.05118[0m[0m | time: 15.275s
[2K
| Adam | epoch: 010 | loss: 0.05118 - acc: 0.9945 -- iter: 064/167
[A[ATraining Step: 57  | total loss: [1m[32m0.04821[0m[0m | time: 98.670s
[2K
| Adam | epoch: 010 | loss: 0.04821 - acc: 0.9952 -- iter: 096/167
[A[ATraining Step: 58  | total loss: [1m[32m0.04213[0m[0m | time: 181.743s
[2K
| Adam | epoch: 010 | loss: 0.04213 - acc: 0.9959 -- iter: 128/167
[A[ATraining Step: 59  | total loss: [1m[32m0.11445[0m[0m | time: 239.082s
[2K
| Adam | epoch: 010 | loss: 0.11445 - acc: 0.9838 -- iter: 160/167
[A[ATraining Step: 60  | total loss: [1m[32m0.10353[0m[0m | time: 260.439s
[2K
| Adam | epoch: 010 | loss: 0.10353 - acc: 0.9860 | val_loss: 2.32936 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 61  | total loss: [1m[32m0.09226[0m[0m | time: 14.140s
[2K
| Adam | epoch: 011 | loss: 0.09226 - acc: 0.9878 -- iter: 032/167
[A[ATraining Step: 62  | total loss: [1m[32m0.08373[0m[0m | time: 19.182s
[2K
| Adam | epoch: 011 | loss: 0.08373 - acc: 0.9894 -- iter: 064/167
[A[ATraining Step: 63  | total loss: [1m[32m0.07534[0m[0m | time: 24.592s
[2K
| Adam | epoch: 011 | loss: 0.07534 - acc: 0.9907 -- iter: 096/167
[A[ATraining Step: 64  | total loss: [1m[32m0.06718[0m[0m | time: 57.123s
[2K
| Adam | epoch: 011 | loss: 0.06718 - acc: 0.9919 -- iter: 128/167
[A[ATraining Step: 65  | total loss: [1m[32m0.07958[0m[0m | time: 96.852s
[2K
| Adam | epoch: 011 | loss: 0.07958 - acc: 0.9890 -- iter: 160/167
[A[ATraining Step: 66  | total loss: [1m[32m0.13449[0m[0m | time: 133.263s
[2K
| Adam | epoch: 011 | loss: 0.13449 - acc: 0.9752 | val_loss: 1.54300 - val_acc: 0.6415 -- iter: 167/167
--
Training Step: 67  | total loss: [1m[32m0.12431[0m[0m | time: 15.637s
[2K
| Adam | epoch: 012 | loss: 0.12431 - acc: 0.9781 -- iter: 032/167
[A[ATraining Step: 68  | total loss: [1m[32m0.11195[0m[0m | time: 29.437s
[2K
| Adam | epoch: 012 | loss: 0.11195 - acc: 0.9807 -- iter: 064/167
[A[ATraining Step: 69  | total loss: [1m[32m0.12027[0m[0m | time: 34.522s
[2K
| Adam | epoch: 012 | loss: 0.12027 - acc: 0.9793 -- iter: 096/167
[A[ATraining Step: 70  | total loss: [1m[32m0.10730[0m[0m | time: 40.185s
[2K
| Adam | epoch: 012 | loss: 0.10730 - acc: 0.9817 -- iter: 128/167
[A[ATraining Step: 71  | total loss: [1m[32m0.09582[0m[0m | time: 66.567s
[2K
| Adam | epoch: 012 | loss: 0.09582 - acc: 0.9838 -- iter: 160/167
[A[ATraining Step: 72  | total loss: [1m[32m0.09261[0m[0m | time: 95.422s
[2K
| Adam | epoch: 012 | loss: 0.09261 - acc: 0.9821 | val_loss: 1.25897 - val_acc: 0.6604 -- iter: 167/167
--
Training Step: 73  | total loss: [1m[32m0.11966[0m[0m | time: 16.072s
[2K
| Adam | epoch: 013 | loss: 0.11966 - acc: 0.9771 -- iter: 032/167
[A[ATraining Step: 74  | total loss: [1m[32m0.11865[0m[0m | time: 29.932s
[2K
| Adam | epoch: 013 | loss: 0.11865 - acc: 0.9728 -- iter: 064/167
[A[ATraining Step: 75  | total loss: [1m[32m0.11761[0m[0m | time: 77.561s
[2K
| Adam | epoch: 013 | loss: 0.11761 - acc: 0.9724 -- iter: 096/167
[A[ATraining Step: 76  | total loss: [1m[32m0.11195[0m[0m | time: 82.855s
[2K
| Adam | epoch: 013 | loss: 0.11195 - acc: 0.9720 -- iter: 128/167
[A[ATraining Step: 77  | total loss: [1m[32m0.10168[0m[0m | time: 88.349s
[2K
| Adam | epoch: 013 | loss: 0.10168 - acc: 0.9749 -- iter: 160/167
[A[ATraining Step: 78  | total loss: [1m[32m0.09200[0m[0m | time: 125.594s
[2K
| Adam | epoch: 013 | loss: 0.09200 - acc: 0.9776 | val_loss: 2.45033 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 79  | total loss: [1m[32m0.08393[0m[0m | time: 19.703s
[2K
| Adam | epoch: 014 | loss: 0.08393 - acc: 0.9799 -- iter: 032/167
[A[ATraining Step: 80  | total loss: [1m[32m0.12156[0m[0m | time: 33.903s
[2K
| Adam | epoch: 014 | loss: 0.12156 - acc: 0.9755 -- iter: 064/167
[A[ATraining Step: 81  | total loss: [1m[32m0.11226[0m[0m | time: 48.792s
[2K
| Adam | epoch: 014 | loss: 0.11226 - acc: 0.9780 -- iter: 096/167
[A[ATraining Step: 82  | total loss: [1m[32m0.10784[0m[0m | time: 122.229s
[2K
| Adam | epoch: 014 | loss: 0.10784 - acc: 0.9771 -- iter: 128/167
[A[ATraining Step: 83  | total loss: [1m[32m0.09921[0m[0m | time: 128.491s
[2K
| Adam | epoch: 014 | loss: 0.09921 - acc: 0.9794 -- iter: 160/167
[A[ATraining Step: 84  | total loss: [1m[32m0.09641[0m[0m | time: 140.347s
[2K
| Adam | epoch: 014 | loss: 0.09641 - acc: 0.9814 | val_loss: 1.42457 - val_acc: 0.5849 -- iter: 167/167
--
Training Step: 85  | total loss: [1m[32m0.08893[0m[0m | time: 27.504s
[2K
| Adam | epoch: 015 | loss: 0.08893 - acc: 0.9833 -- iter: 032/167
[A[ATraining Step: 86  | total loss: [1m[32m0.08183[0m[0m | time: 45.954s
[2K
| Adam | epoch: 015 | loss: 0.08183 - acc: 0.9850 -- iter: 064/167
[A[ATraining Step: 87  | total loss: [1m[32m0.08302[0m[0m | time: 59.684s
[2K
| Adam | epoch: 015 | loss: 0.08302 - acc: 0.9833 -- iter: 096/167
[A[ATraining Step: 88  | total loss: [1m[32m0.07814[0m[0m | time: 74.681s
[2K
| Adam | epoch: 015 | loss: 0.07814 - acc: 0.9850 -- iter: 128/167
[A[ATraining Step: 89  | total loss: [1m[32m0.07152[0m[0m | time: 94.308s
[2K
| Adam | epoch: 015 | loss: 0.07152 - acc: 0.9865 -- iter: 160/167
[A[ATraining Step: 90  | total loss: [1m[32m0.06606[0m[0m | time: 107.201s
[2K
| Adam | epoch: 015 | loss: 0.06606 - acc: 0.9879 | val_loss: 0.58241 - val_acc: 0.7925 -- iter: 167/167
--
Training Step: 91  | total loss: [1m[32m0.08931[0m[0m | time: 6.711s
[2K
| Adam | epoch: 016 | loss: 0.08931 - acc: 0.9748 -- iter: 032/167
[A[ATraining Step: 92  | total loss: [1m[32m0.08812[0m[0m | time: 25.218s
[2K
| Adam | epoch: 016 | loss: 0.08812 - acc: 0.9773 -- iter: 064/167
[A[ATraining Step: 93  | total loss: [1m[32m0.08072[0m[0m | time: 38.475s
[2K
| Adam | epoch: 016 | loss: 0.08072 - acc: 0.9796 -- iter: 096/167
[A[ATraining Step: 94  | total loss: [1m[32m0.07401[0m[0m | time: 54.253s
[2K
| Adam | epoch: 016 | loss: 0.07401 - acc: 0.9816 -- iter: 128/167
[A[ATraining Step: 95  | total loss: [1m[32m0.07236[0m[0m | time: 80.558s
[2K
| Adam | epoch: 016 | loss: 0.07236 - acc: 0.9835 -- iter: 160/167
[A[ATraining Step: 96  | total loss: [1m[32m0.07053[0m[0m | time: 106.567s
[2K
| Adam | epoch: 016 | loss: 0.07053 - acc: 0.9851 | val_loss: 0.62286 - val_acc: 0.7925 -- iter: 167/167
--
Training Step: 97  | total loss: [1m[32m0.06402[0m[0m | time: 6.875s
[2K
| Adam | epoch: 017 | loss: 0.06402 - acc: 0.9866 -- iter: 032/167
[A[ATraining Step: 98  | total loss: [1m[32m0.05836[0m[0m | time: 13.752s
[2K
| Adam | epoch: 017 | loss: 0.05836 - acc: 0.9879 -- iter: 064/167
[A[ATraining Step: 99  | total loss: [1m[32m0.05298[0m[0m | time: 27.852s
[2K
| Adam | epoch: 017 | loss: 0.05298 - acc: 0.9891 -- iter: 096/167
[A[ATraining Step: 100  | total loss: [1m[32m0.06640[0m[0m | time: 41.879s
[2K
| Adam | epoch: 017 | loss: 0.06640 - acc: 0.9871 -- iter: 128/167
[A[ATraining Step: 101  | total loss: [1m[32m0.06078[0m[0m | time: 100.185s
[2K
| Adam | epoch: 017 | loss: 0.06078 - acc: 0.9884 -- iter: 160/167
[A[ATraining Step: 102  | total loss: [1m[32m0.06022[0m[0m | time: 125.909s
[2K
| Adam | epoch: 017 | loss: 0.06022 - acc: 0.9864 | val_loss: 2.62937 - val_acc: 0.5472 -- iter: 167/167
--
Training Step: 103  | total loss: [1m[32m0.05616[0m[0m | time: 17.844s
[2K
| Adam | epoch: 018 | loss: 0.05616 - acc: 0.9878 -- iter: 032/167
[A[ATraining Step: 104  | total loss: [1m[32m0.05682[0m[0m | time: 23.604s
[2K
| Adam | epoch: 018 | loss: 0.05682 - acc: 0.9859 -- iter: 064/167
[A[ATraining Step: 105  | total loss: [1m[32m0.05295[0m[0m | time: 29.016s
[2K
| Adam | epoch: 018 | loss: 0.05295 - acc: 0.9873 -- iter: 096/167
[A[ATraining Step: 106  | total loss: [1m[32m0.04889[0m[0m | time: 42.502s
[2K
| Adam | epoch: 018 | loss: 0.04889 - acc: 0.9886 -- iter: 128/167
[A[ATraining Step: 107  | total loss: [1m[32m0.04972[0m[0m | time: 56.251s
[2K
| Adam | epoch: 018 | loss: 0.04972 - acc: 0.9866 -- iter: 160/167
[A[ATraining Step: 108  | total loss: [1m[32m0.07818[0m[0m | time: 77.797s
[2K
| Adam | epoch: 018 | loss: 0.07818 - acc: 0.9817 | val_loss: 0.50897 - val_acc: 0.7736 -- iter: 167/167
--
Training Step: 109  | total loss: [1m[32m0.07314[0m[0m | time: 29.857s
[2K
| Adam | epoch: 019 | loss: 0.07314 - acc: 0.9835 -- iter: 032/167
[A[ATraining Step: 110  | total loss: [1m[32m0.06812[0m[0m | time: 63.208s
[2K
| Adam | epoch: 019 | loss: 0.06812 - acc: 0.9852 -- iter: 064/167
[A[ATraining Step: 111  | total loss: [1m[32m0.06254[0m[0m | time: 70.195s
[2K
| Adam | epoch: 019 | loss: 0.06254 - acc: 0.9866 -- iter: 096/167
[A[ATraining Step: 112  | total loss: [1m[32m0.06962[0m[0m | time: 77.042s
[2K
| Adam | epoch: 019 | loss: 0.06962 - acc: 0.9737 -- iter: 128/167
[A[ATraining Step: 113  | total loss: [1m[32m0.06401[0m[0m | time: 101.460s
[2K
| Adam | epoch: 019 | loss: 0.06401 - acc: 0.9763 -- iter: 160/167
[A[ATraining Step: 114  | total loss: [1m[32m0.07340[0m[0m | time: 121.357s
[2K
| Adam | epoch: 019 | loss: 0.07340 - acc: 0.9756 | val_loss: 0.91067 - val_acc: 0.7547 -- iter: 167/167
--
Training Step: 115  | total loss: [1m[32m0.10759[0m[0m | time: 17.937s
[2K
| Adam | epoch: 020 | loss: 0.10759 - acc: 0.9749 -- iter: 032/167
[A[ATraining Step: 116  | total loss: [1m[32m0.09715[0m[0m | time: 37.780s
[2K
| Adam | epoch: 020 | loss: 0.09715 - acc: 0.9774 -- iter: 064/167
[A[ATraining Step: 117  | total loss: [1m[32m0.08896[0m[0m | time: 56.654s
[2K
| Adam | epoch: 020 | loss: 0.08896 - acc: 0.9797 -- iter: 096/167
[A[ATraining Step: 118  | total loss: [1m[32m0.08046[0m[0m | time: 63.232s
[2K
| Adam | epoch: 020 | loss: 0.08046 - acc: 0.9817 -- iter: 128/167
[A[ATraining Step: 119  | total loss: [1m[32m0.07263[0m[0m | time: 69.933s
[2K
| Adam | epoch: 020 | loss: 0.07263 - acc: 0.9835 -- iter: 160/167
[A[ATraining Step: 120  | total loss: [1m[32m0.06553[0m[0m | time: 96.317s
[2K
| Adam | epoch: 020 | loss: 0.06553 - acc: 0.9852 | val_loss: 3.84551 - val_acc: 0.4717 -- iter: 167/167
--
Training Step: 121  | total loss: [1m[32m0.07238[0m[0m | time: 13.317s
[2K
| Adam | epoch: 021 | loss: 0.07238 - acc: 0.9804 -- iter: 032/167
[A[ATraining Step: 122  | total loss: [1m[32m0.08252[0m[0m | time: 22.762s
[2K
| Adam | epoch: 021 | loss: 0.08252 - acc: 0.9792 -- iter: 064/167
[A[ATraining Step: 123  | total loss: [1m[32m0.07479[0m[0m | time: 32.240s
[2K
| Adam | epoch: 021 | loss: 0.07479 - acc: 0.9813 -- iter: 096/167
[A[ATraining Step: 124  | total loss: [1m[32m0.06801[0m[0m | time: 47.762s
[2K
| Adam | epoch: 021 | loss: 0.06801 - acc: 0.9832 -- iter: 128/167
[A[ATraining Step: 125  | total loss: [1m[32m0.07009[0m[0m | time: 54.285s
[2K
| Adam | epoch: 021 | loss: 0.07009 - acc: 0.9817 -- iter: 160/167
[A[ATraining Step: 126  | total loss: [1m[32m0.06320[0m[0m | time: 67.473s
[2K
| Adam | epoch: 021 | loss: 0.06320 - acc: 0.9836 | val_loss: 3.04372 - val_acc: 0.4906 -- iter: 167/167
--
Training Step: 127  | total loss: [1m[32m0.05706[0m[0m | time: 19.076s
[2K
| Adam | epoch: 022 | loss: 0.05706 - acc: 0.9852 -- iter: 032/167
[A[ATraining Step: 128  | total loss: [1m[32m0.05184[0m[0m | time: 36.850s
[2K
| Adam | epoch: 022 | loss: 0.05184 - acc: 0.9867 -- iter: 064/167
[A[ATraining Step: 129  | total loss: [1m[32m0.04854[0m[0m | time: 51.141s
[2K
| Adam | epoch: 022 | loss: 0.04854 - acc: 0.9880 -- iter: 096/167
[A[ATraining Step: 130  | total loss: [1m[32m0.04420[0m[0m | time: 66.454s
[2K
| Adam | epoch: 022 | loss: 0.04420 - acc: 0.9892 -- iter: 128/167
[A[ATraining Step: 131  | total loss: [1m[32m0.04032[0m[0m | time: 117.746s
[2K
| Adam | epoch: 022 | loss: 0.04032 - acc: 0.9903 -- iter: 160/167
[A[ATraining Step: 132  | total loss: [1m[32m0.03680[0m[0m | time: 129.129s
[2K
| Adam | epoch: 022 | loss: 0.03680 - acc: 0.9913 | val_loss: 1.27406 - val_acc: 0.6415 -- iter: 167/167
--
Training Step: 133  | total loss: [1m[32m0.12471[0m[0m | time: 6.571s
[2K
| Adam | epoch: 023 | loss: 0.12471 - acc: 0.9636 -- iter: 032/167
[A[ATraining Step: 134  | total loss: [1m[32m0.14814[0m[0m | time: 25.290s
[2K
| Adam | epoch: 023 | loss: 0.14814 - acc: 0.9386 -- iter: 064/167
[A[ATraining Step: 135  | total loss: [1m[32m0.13412[0m[0m | time: 44.243s
[2K
| Adam | epoch: 023 | loss: 0.13412 - acc: 0.9448 -- iter: 096/167
[A[ATraining Step: 136  | total loss: [1m[32m0.16618[0m[0m | time: 58.014s
[2K
| Adam | epoch: 023 | loss: 0.16618 - acc: 0.9440 -- iter: 128/167
[A[ATraining Step: 137  | total loss: [1m[32m0.15023[0m[0m | time: 73.962s
[2K
| Adam | epoch: 023 | loss: 0.15023 - acc: 0.9496 -- iter: 160/167
[A[ATraining Step: 138  | total loss: [1m[32m0.13577[0m[0m | time: 99.680s
[2K
| Adam | epoch: 023 | loss: 0.13577 - acc: 0.9547 | val_loss: 0.66042 - val_acc: 0.7736 -- iter: 167/167
--
Training Step: 139  | total loss: [1m[32m0.12484[0m[0m | time: 6.551s
[2K
| Adam | epoch: 024 | loss: 0.12484 - acc: 0.9592 -- iter: 032/167
[A[ATraining Step: 140  | total loss: [1m[32m0.11333[0m[0m | time: 13.026s
[2K
| Adam | epoch: 024 | loss: 0.11333 - acc: 0.9633 -- iter: 064/167
[A[ATraining Step: 141  | total loss: [1m[32m0.10319[0m[0m | time: 37.015s
[2K
| Adam | epoch: 024 | loss: 0.10319 - acc: 0.9670 -- iter: 096/167
[A[ATraining Step: 142  | total loss: [1m[32m0.09398[0m[0m | time: 54.001s
[2K
| Adam | epoch: 024 | loss: 0.09398 - acc: 0.9703 -- iter: 128/167
[A[ATraining Step: 143  | total loss: [1m[32m0.10855[0m[0m | time: 67.474s
[2K
| Adam | epoch: 024 | loss: 0.10855 - acc: 0.9639 -- iter: 160/167
[A[ATraining Step: 144  | total loss: [1m[32m0.10077[0m[0m | time: 92.350s
[2K
| Adam | epoch: 024 | loss: 0.10077 - acc: 0.9675 | val_loss: 0.66862 - val_acc: 0.8302 -- iter: 167/167
--
Training Step: 145  | total loss: [1m[32m0.09227[0m[0m | time: 18.510s
[2K
| Adam | epoch: 025 | loss: 0.09227 - acc: 0.9707 -- iter: 032/167
[A[ATraining Step: 146  | total loss: [1m[32m0.10607[0m[0m | time: 24.771s
[2K
| Adam | epoch: 025 | loss: 0.10607 - acc: 0.9705 -- iter: 064/167
[A[ATraining Step: 147  | total loss: [1m[32m0.10145[0m[0m | time: 31.546s
[2K
| Adam | epoch: 025 | loss: 0.10145 - acc: 0.9735 -- iter: 096/167
[A[ATraining Step: 148  | total loss: [1m[32m0.09317[0m[0m | time: 46.309s
[2K
| Adam | epoch: 025 | loss: 0.09317 - acc: 0.9761 -- iter: 128/167
[A[ATraining Step: 149  | total loss: [1m[32m0.08476[0m[0m | time: 59.964s
[2K
| Adam | epoch: 025 | loss: 0.08476 - acc: 0.9785 -- iter: 160/167
[A[ATraining Step: 150  | total loss: [1m[32m0.13221[0m[0m | time: 90.366s
[2K
| Adam | epoch: 025 | loss: 0.13221 - acc: 0.9744 | val_loss: 0.84631 - val_acc: 0.7925 -- iter: 167/167
--
Training Step: 151  | total loss: [1m[32m0.11986[0m[0m | time: 20.426s
[2K
| Adam | epoch: 026 | loss: 0.11986 - acc: 0.9770 -- iter: 032/167
[A[ATraining Step: 152  | total loss: [1m[32m0.11016[0m[0m | time: 37.952s
[2K
| Adam | epoch: 026 | loss: 0.11016 - acc: 0.9793 -- iter: 064/167
[A[ATraining Step: 153  | total loss: [1m[32m0.09960[0m[0m | time: 44.588s
[2K
| Adam | epoch: 026 | loss: 0.09960 - acc: 0.9813 -- iter: 096/167
[A[ATraining Step: 154  | total loss: [1m[32m0.09045[0m[0m | time: 51.171s
[2K
| Adam | epoch: 026 | loss: 0.09045 - acc: 0.9832 -- iter: 128/167
[A[ATraining Step: 155  | total loss: [1m[32m0.08213[0m[0m | time: 66.114s
[2K
| Adam | epoch: 026 | loss: 0.08213 - acc: 0.9849 -- iter: 160/167
[A[ATraining Step: 156  | total loss: [1m[32m0.08303[0m[0m | time: 83.708s
[2K
| Adam | epoch: 026 | loss: 0.08303 - acc: 0.9833 | val_loss: 0.78881 - val_acc: 0.7170 -- iter: 167/167
--
Training Step: 157  | total loss: [1m[32m0.08963[0m[0m | time: 12.872s
[2K
| Adam | epoch: 027 | loss: 0.08963 - acc: 0.9818 -- iter: 032/167
[A[ATraining Step: 158  | total loss: [1m[32m0.08687[0m[0m | time: 25.846s
[2K
| Adam | epoch: 027 | loss: 0.08687 - acc: 0.9805 -- iter: 064/167
[A[ATraining Step: 159  | total loss: [1m[32m0.08059[0m[0m | time: 38.862s
[2K
| Adam | epoch: 027 | loss: 0.08059 - acc: 0.9825 -- iter: 096/167
[A[ATraining Step: 160  | total loss: [1m[32m0.07312[0m[0m | time: 42.913s
[2K
| Adam | epoch: 027 | loss: 0.07312 - acc: 0.9842 -- iter: 128/167
[A[ATraining Step: 161  | total loss: [1m[32m0.06963[0m[0m | time: 47.255s
[2K
| Adam | epoch: 027 | loss: 0.06963 - acc: 0.9858 -- iter: 160/167
[A[ATraining Step: 162  | total loss: [1m[32m0.06342[0m[0m | time: 63.615s
[2K
| Adam | epoch: 027 | loss: 0.06342 - acc: 0.9872 | val_loss: 1.34625 - val_acc: 0.6226 -- iter: 167/167
--
Training Step: 163  | total loss: [1m[32m0.06864[0m[0m | time: 12.685s
[2K
| Adam | epoch: 028 | loss: 0.06864 - acc: 0.9854 -- iter: 032/167
[A[ATraining Step: 164  | total loss: [1m[32m0.23543[0m[0m | time: 25.791s
[2K
| Adam | epoch: 028 | loss: 0.23543 - acc: 0.9587 -- iter: 064/167
[A[ATraining Step: 165  | total loss: [1m[32m0.21443[0m[0m | time: 38.792s
[2K
| Adam | epoch: 028 | loss: 0.21443 - acc: 0.9628 -- iter: 096/167
[A[ATraining Step: 166  | total loss: [1m[32m0.19388[0m[0m | time: 51.929s
[2K
| Adam | epoch: 028 | loss: 0.19388 - acc: 0.9666 -- iter: 128/167
[A[ATraining Step: 167  | total loss: [1m[32m0.17702[0m[0m | time: 56.253s
[2K
| Adam | epoch: 028 | loss: 0.17702 - acc: 0.9699 -- iter: 160/167
[A[ATraining Step: 168  | total loss: [1m[32m0.18759[0m[0m | time: 63.563s
[2K
| Adam | epoch: 028 | loss: 0.18759 - acc: 0.9729 | val_loss: 3.20383 - val_acc: 0.4906 -- iter: 167/167
--
Training Step: 169  | total loss: [1m[32m0.18617[0m[0m | time: 13.071s
[2K
| Adam | epoch: 029 | loss: 0.18617 - acc: 0.9756 -- iter: 032/167
[A[ATraining Step: 170  | total loss: [1m[32m0.17196[0m[0m | time: 26.085s
[2K
| Adam | epoch: 029 | loss: 0.17196 - acc: 0.9781 -- iter: 064/167
[A[ATraining Step: 171  | total loss: [1m[32m0.15966[0m[0m | time: 39.671s
[2K
| Adam | epoch: 029 | loss: 0.15966 - acc: 0.9803 -- iter: 096/167
[A[ATraining Step: 172  | total loss: [1m[32m0.14598[0m[0m | time: 53.053s
[2K
| Adam | epoch: 029 | loss: 0.14598 - acc: 0.9822 -- iter: 128/167
[A[ATraining Step: 173  | total loss: [1m[32m0.13359[0m[0m | time: 66.539s
[2K
| Adam | epoch: 029 | loss: 0.13359 - acc: 0.9840 -- iter: 160/167
[A[ATraining Step: 174  | total loss: [1m[32m0.12133[0m[0m | time: 74.290s
[2K
| Adam | epoch: 029 | loss: 0.12133 - acc: 0.9856 | val_loss: 1.01587 - val_acc: 0.7925 -- iter: 167/167
--
Training Step: 175  | total loss: [1m[32m0.10997[0m[0m | time: 4.296s
[2K
| Adam | epoch: 030 | loss: 0.10997 - acc: 0.9870 -- iter: 032/167
[A[ATraining Step: 176  | total loss: [1m[32m0.09947[0m[0m | time: 17.441s
[2K
| Adam | epoch: 030 | loss: 0.09947 - acc: 0.9883 -- iter: 064/167
[A[ATraining Step: 177  | total loss: [1m[32m0.09048[0m[0m | time: 30.200s
[2K
| Adam | epoch: 030 | loss: 0.09048 - acc: 0.9895 -- iter: 096/167
[A[ATraining Step: 178  | total loss: [1m[32m0.15745[0m[0m | time: 42.997s
[2K
| Adam | epoch: 030 | loss: 0.15745 - acc: 0.9781 -- iter: 128/167
[A[ATraining Step: 179  | total loss: [1m[32m0.14260[0m[0m | time: 55.941s
[2K
| Adam | epoch: 030 | loss: 0.14260 - acc: 0.9802 -- iter: 160/167
[A[ATraining Step: 180  | total loss: [1m[32m0.13133[0m[0m | time: 73.938s
[2K
| Adam | epoch: 030 | loss: 0.13133 - acc: 0.9791 | val_loss: 0.98815 - val_acc: 0.7547 -- iter: 167/167
--
Validation AUC:0.85
Validation AUPRC:0.8051268851201414
Test AUC:0.8840579710144927
Test AUPRC:0.8621518128777125
BestTestF1Score	0.83	0.57	0.79	0.79	0.87	26	7	16	4	0.01
BestTestMCCScore	0.83	0.57	0.79	0.79	0.87	26	7	16	4	0.01
BestTestAccuracyScore	0.83	0.57	0.79	0.79	0.87	26	7	16	4	0.01
BestValidationF1Score	0.81	0.62	0.81	0.78	0.84	21	6	22	4	0.01
BestValidationMCC	0.81	0.62	0.81	0.78	0.84	21	6	22	4	0.01
BestValidationAccuracy	0.81	0.62	0.81	0.78	0.84	21	6	22	4	0.01
TestPredictions (Threshold:0.01)
CHEMBL1782072,FN,ACT,0.009999999776482582	CHEMBL2134094,TP,ACT,0.5899999737739563	CHEMBL1505546,TN,INACT,0.0	CHEMBL1783623,FP,INACT,0.49000000953674316	CHEMBL459438,TN,INACT,0.0	CHEMBL98869,TN,INACT,0.009999999776482582	CHEMBL603712,FP,INACT,0.029999999329447746	CHEMBL2178409,TP,ACT,0.03999999910593033	CHEMBL2135309,TP,ACT,1.0	CHEMBL230984,TN,INACT,0.0	CHEMBL1836240,FP,INACT,1.0	CHEMBL1271866,TP,ACT,0.03999999910593033	CHEMBL558940,FN,ACT,0.009999999776482582	CHEMBL387334,TN,INACT,0.0	CHEMBL1560590,TP,ACT,0.019999999552965164	CHEMBL246373,TN,INACT,0.0	CHEMBL2130848,TP,ACT,1.0	CHEMBL2323955,TP,ACT,0.33000001311302185	CHEMBL1795438,TP,ACT,0.1599999964237213	CHEMBL1836238,TP,ACT,1.0	CHEMBL568111,TN,INACT,0.0	CHEMBL3585466,TP,ACT,0.9200000166893005	CHEMBL603060,TP,ACT,0.8999999761581421	CHEMBL192365,TN,INACT,0.0	CHEMBL333985,TP,ACT,0.36000001430511475	CHEMBL600512,TP,ACT,0.9900000095367432	CHEMBL3215845,FP,INACT,0.029999999329447746	CHEMBL259198,FP,INACT,0.10000000149011612	CHEMBL2021541,TN,INACT,0.0	CHEMBL84,TP,ACT,0.05999999865889549	CHEMBL2141631,FN,ACT,0.009999999776482582	CHEMBL2178416,TP,ACT,0.9800000190734863	CHEMBL366173,TN,INACT,0.0	CHEMBL390194,TN,INACT,0.0	CHEMBL235198,FP,INACT,0.029999999329447746	CHEMBL2177118,TP,ACT,0.8100000023841858	CHEMBL2323956,TP,ACT,0.23000000417232513	CHEMBL1342148,FN,ACT,0.009999999776482582	CHEMBL1683117,FP,INACT,0.07000000029802322	CHEMBL2132069,TP,ACT,1.0	CHEMBL2323957,TP,ACT,0.14000000059604645	CHEMBL1836179,TP,ACT,0.8500000238418579	CHEMBL1836236,TP,ACT,0.9800000190734863	CHEMBL603103,TN,INACT,0.0	CHEMBL235553,TP,ACT,0.46000000834465027	CHEMBL1783633,TN,INACT,0.0	CHEMBL66518,TN,INACT,0.009999999776482582	CHEMBL536311,TN,INACT,0.0	CHEMBL1345388,TP,ACT,0.7799999713897705	CHEMBL196114,TN,INACT,0.0	CHEMBL2178410,TP,ACT,0.029999999329447746	CHEMBL1345685,TP,ACT,0.7699999809265137	CHEMBL1836233,TP,ACT,0.9300000071525574	

