ImageNetInceptionV2 CHEMBL3719 RMSprop 0.0005 15 0 0 0.8 False True
Number of active compounds :	147
Number of inactive compounds :	147
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3719_RMSprop_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3719_RMSprop_0.0005_15_0.8/
---------------------------------
Training samples: 166
Validation samples: 53
--
Training Step: 1  | time: 36.399s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/166
[A[ATraining Step: 2  | total loss: [1m[32m0.72598[0m[0m | time: 46.073s
[2K
| RMSProp | epoch: 001 | loss: 0.72598 - acc: 0.3094 -- iter: 064/166
[A[ATraining Step: 3  | total loss: [1m[32m0.80625[0m[0m | time: 54.913s
[2K
| RMSProp | epoch: 001 | loss: 0.80625 - acc: 0.2864 -- iter: 096/166
[A[ATraining Step: 4  | total loss: [1m[32m0.75753[0m[0m | time: 66.134s
[2K
| RMSProp | epoch: 001 | loss: 0.75753 - acc: 0.5169 -- iter: 128/166
[A[ATraining Step: 5  | total loss: [1m[32m0.80074[0m[0m | time: 76.130s
[2K
| RMSProp | epoch: 001 | loss: 0.80074 - acc: 0.4187 -- iter: 160/166
[A[ATraining Step: 6  | total loss: [1m[32m0.79351[0m[0m | time: 87.492s
[2K
| RMSProp | epoch: 001 | loss: 0.79351 - acc: 0.3303 | val_loss: 0.69983 - val_acc: 0.4906 -- iter: 166/166
--
Training Step: 7  | total loss: [1m[32m0.83252[0m[0m | time: 2.444s
[2K
| RMSProp | epoch: 002 | loss: 0.83252 - acc: 0.2321 -- iter: 032/166
[A[ATraining Step: 8  | total loss: [1m[32m0.83321[0m[0m | time: 12.271s
[2K
| RMSProp | epoch: 002 | loss: 0.83321 - acc: 0.1953 -- iter: 064/166
[A[ATraining Step: 9  | total loss: [1m[32m0.78974[0m[0m | time: 30.746s
[2K
| RMSProp | epoch: 002 | loss: 0.78974 - acc: 0.2739 -- iter: 096/166
[A[ATraining Step: 10  | total loss: [1m[32m0.75713[0m[0m | time: 38.572s
[2K
| RMSProp | epoch: 002 | loss: 0.75713 - acc: 0.3557 -- iter: 128/166
[A[ATraining Step: 11  | total loss: [1m[32m0.73938[0m[0m | time: 52.936s
[2K
| RMSProp | epoch: 002 | loss: 0.73938 - acc: 0.3796 -- iter: 160/166
[A[ATraining Step: 12  | total loss: [1m[32m0.73581[0m[0m | time: 63.431s
[2K
| RMSProp | epoch: 002 | loss: 0.73581 - acc: 0.4197 | val_loss: 0.69487 - val_acc: 0.4906 -- iter: 166/166
--
Training Step: 13  | total loss: [1m[32m0.71848[0m[0m | time: 2.335s
[2K
| RMSProp | epoch: 003 | loss: 0.71848 - acc: 0.5077 -- iter: 032/166
[A[ATraining Step: 14  | total loss: [1m[32m0.69435[0m[0m | time: 4.699s
[2K
| RMSProp | epoch: 003 | loss: 0.69435 - acc: 0.5727 -- iter: 064/166
[A[ATraining Step: 15  | total loss: [1m[32m0.68578[0m[0m | time: 15.554s
[2K
| RMSProp | epoch: 003 | loss: 0.68578 - acc: 0.6095 -- iter: 096/166
[A[ATraining Step: 16  | total loss: [1m[32m0.68555[0m[0m | time: 32.256s
[2K
| RMSProp | epoch: 003 | loss: 0.68555 - acc: 0.5802 -- iter: 128/166
[A[ATraining Step: 17  | total loss: [1m[32m0.67677[0m[0m | time: 51.584s
[2K
| RMSProp | epoch: 003 | loss: 0.67677 - acc: 0.5850 -- iter: 160/166
[A[ATraining Step: 18  | total loss: [1m[32m0.68783[0m[0m | time: 69.620s
[2K
| RMSProp | epoch: 003 | loss: 0.68783 - acc: 0.5664 | val_loss: 0.69101 - val_acc: 0.5094 -- iter: 166/166
--
Training Step: 19  | total loss: [1m[32m0.66086[0m[0m | time: 164.341s
[2K
| RMSProp | epoch: 004 | loss: 0.66086 - acc: 0.6484 -- iter: 032/166
[A[ATraining Step: 20  | total loss: [1m[32m0.65608[0m[0m | time: 190.003s
[2K
| RMSProp | epoch: 004 | loss: 0.65608 - acc: 0.6510 -- iter: 064/166
[A[ATraining Step: 21  | total loss: [1m[32m0.62712[0m[0m | time: 194.359s
[2K
| RMSProp | epoch: 004 | loss: 0.62712 - acc: 0.7076 -- iter: 096/166
[A[ATraining Step: 22  | total loss: [1m[32m0.59593[0m[0m | time: 368.576s
[2K
| RMSProp | epoch: 004 | loss: 0.59593 - acc: 0.7453 -- iter: 128/166
[A[ATraining Step: 23  | total loss: [1m[32m0.60896[0m[0m | time: 433.097s
[2K
| RMSProp | epoch: 004 | loss: 0.60896 - acc: 0.7013 -- iter: 160/166
[A[ATraining Step: 24  | total loss: [1m[32m0.60695[0m[0m | time: 478.956s
[2K
| RMSProp | epoch: 004 | loss: 0.60695 - acc: 0.7238 | val_loss: 0.69832 - val_acc: 0.5094 -- iter: 166/166
--
Training Step: 25  | total loss: [1m[32m0.61077[0m[0m | time: 53.362s
[2K
| RMSProp | epoch: 005 | loss: 0.61077 - acc: 0.7224 -- iter: 032/166
[A[ATraining Step: 26  | total loss: [1m[32m0.59788[0m[0m | time: 61.589s
[2K
| RMSProp | epoch: 005 | loss: 0.59788 - acc: 0.7545 -- iter: 064/166
[A[ATraining Step: 27  | total loss: [1m[32m0.59707[0m[0m | time: 64.705s
[2K
| RMSProp | epoch: 005 | loss: 0.59707 - acc: 0.7534 -- iter: 096/166
[A[ATraining Step: 28  | total loss: [1m[32m0.54622[0m[0m | time: 68.409s
[2K
| RMSProp | epoch: 005 | loss: 0.54622 - acc: 0.8150 -- iter: 128/166
[A[ATraining Step: 29  | total loss: [1m[32m0.50663[0m[0m | time: 76.572s
[2K
| RMSProp | epoch: 005 | loss: 0.50663 - acc: 0.8600 -- iter: 160/166
[A[ATraining Step: 30  | total loss: [1m[32m0.52184[0m[0m | time: 104.014s
[2K
| RMSProp | epoch: 005 | loss: 0.52184 - acc: 0.8266 | val_loss: 0.74564 - val_acc: 0.5094 -- iter: 166/166
--
Training Step: 31  | total loss: [1m[32m0.52770[0m[0m | time: 206.031s
[2K
| RMSProp | epoch: 006 | loss: 0.52770 - acc: 0.8161 -- iter: 032/166
[A[ATraining Step: 32  | total loss: [1m[32m0.52881[0m[0m | time: 343.523s
[2K
| RMSProp | epoch: 006 | loss: 0.52881 - acc: 0.8083 -- iter: 064/166
[A[ATraining Step: 33  | total loss: [1m[32m0.52838[0m[0m | time: 513.866s
[2K
| RMSProp | epoch: 006 | loss: 0.52838 - acc: 0.8161 -- iter: 096/166
[A[ATraining Step: 34  | total loss: [1m[32m0.51931[0m[0m | time: 517.604s
[2K
| RMSProp | epoch: 006 | loss: 0.51931 - acc: 0.8153 -- iter: 128/166
[A[ATraining Step: 35  | total loss: [1m[32m0.49143[0m[0m | time: 521.506s
[2K
| RMSProp | epoch: 006 | loss: 0.49143 - acc: 0.8540 -- iter: 160/166
[A[ATraining Step: 36  | total loss: [1m[32m0.46884[0m[0m | time: 553.078s
[2K
| RMSProp | epoch: 006 | loss: 0.46884 - acc: 0.8838 | val_loss: 0.71782 - val_acc: 0.5094 -- iter: 166/166
--
Training Step: 37  | total loss: [1m[32m0.46016[0m[0m | time: 8.472s
[2K
| RMSProp | epoch: 007 | loss: 0.46016 - acc: 0.8758 -- iter: 032/166
[A[ATraining Step: 38  | total loss: [1m[32m0.44809[0m[0m | time: 16.661s
[2K
| RMSProp | epoch: 007 | loss: 0.44809 - acc: 0.8818 -- iter: 064/166
[A[ATraining Step: 39  | total loss: [1m[32m0.43883[0m[0m | time: 25.794s
[2K
| RMSProp | epoch: 007 | loss: 0.43883 - acc: 0.8924 -- iter: 096/166
[A[ATraining Step: 40  | total loss: [1m[32m0.41964[0m[0m | time: 63.965s
[2K
| RMSProp | epoch: 007 | loss: 0.41964 - acc: 0.8950 -- iter: 128/166
[A[ATraining Step: 41  | total loss: [1m[32m0.41583[0m[0m | time: 76.555s
[2K
| RMSProp | epoch: 007 | loss: 0.41583 - acc: 0.8913 -- iter: 160/166
[A[ATraining Step: 42  | total loss: [1m[32m0.43223[0m[0m | time: 84.410s
[2K
| RMSProp | epoch: 007 | loss: 0.43223 - acc: 0.8509 | val_loss: 0.59185 - val_acc: 0.5472 -- iter: 166/166
--
Training Step: 43  | total loss: [1m[32m0.41503[0m[0m | time: 13.245s
[2K
| RMSProp | epoch: 008 | loss: 0.41503 - acc: 0.8478 -- iter: 032/166
[A[ATraining Step: 44  | total loss: [1m[32m0.44304[0m[0m | time: 35.416s
[2K
| RMSProp | epoch: 008 | loss: 0.44304 - acc: 0.8255 -- iter: 064/166
[A[ATraining Step: 45  | total loss: [1m[32m0.44810[0m[0m | time: 44.083s
[2K
| RMSProp | epoch: 008 | loss: 0.44810 - acc: 0.8233 -- iter: 096/166
[A[ATraining Step: 46  | total loss: [1m[32m0.43026[0m[0m | time: 52.279s
[2K
| RMSProp | epoch: 008 | loss: 0.43026 - acc: 0.8423 -- iter: 128/166
[A[ATraining Step: 47  | total loss: [1m[32m0.45017[0m[0m | time: 60.362s
[2K
| RMSProp | epoch: 008 | loss: 0.45017 - acc: 0.8067 -- iter: 160/166
[A[ATraining Step: 48  | total loss: [1m[32m0.43593[0m[0m | time: 65.284s
[2K
| RMSProp | epoch: 008 | loss: 0.43593 - acc: 0.8227 | val_loss: 0.52665 - val_acc: 0.6038 -- iter: 166/166
--
Training Step: 49  | total loss: [1m[32m0.43497[0m[0m | time: 3.793s
[2K
| RMSProp | epoch: 009 | loss: 0.43497 - acc: 0.7981 -- iter: 032/166
[A[ATraining Step: 50  | total loss: [1m[32m0.40593[0m[0m | time: 50.196s
[2K
| RMSProp | epoch: 009 | loss: 0.40593 - acc: 0.8294 -- iter: 064/166
[A[ATraining Step: 51  | total loss: [1m[32m0.38062[0m[0m | time: 258.005s
[2K
| RMSProp | epoch: 009 | loss: 0.38062 - acc: 0.8507 -- iter: 096/166
[A[ATraining Step: 52  | total loss: [1m[32m0.38022[0m[0m | time: 366.707s
[2K
| RMSProp | epoch: 009 | loss: 0.38022 - acc: 0.8543 -- iter: 128/166
[A[ATraining Step: 53  | total loss: [1m[32m0.36425[0m[0m | time: 464.341s
[2K
| RMSProp | epoch: 009 | loss: 0.36425 - acc: 0.8574 -- iter: 160/166
[A[ATraining Step: 54  | total loss: [1m[32m0.34462[0m[0m | time: 484.736s
[2K
| RMSProp | epoch: 009 | loss: 0.34462 - acc: 0.8735 | val_loss: 0.36671 - val_acc: 0.9245 -- iter: 166/166
--
Training Step: 55  | total loss: [1m[32m0.32925[0m[0m | time: 29.033s
[2K
| RMSProp | epoch: 010 | loss: 0.32925 - acc: 0.8871 -- iter: 032/166
[A[ATraining Step: 56  | total loss: [1m[32m0.31921[0m[0m | time: 34.866s
[2K
| RMSProp | epoch: 010 | loss: 0.31921 - acc: 0.9030 -- iter: 064/166
[A[ATraining Step: 57  | total loss: [1m[32m0.29543[0m[0m | time: 78.238s
[2K
| RMSProp | epoch: 010 | loss: 0.29543 - acc: 0.9164 -- iter: 096/166
[A[ATraining Step: 58  | total loss: [1m[32m0.32709[0m[0m | time: 220.998s
[2K
| RMSProp | epoch: 010 | loss: 0.32709 - acc: 0.8895 -- iter: 128/166
[A[ATraining Step: 59  | total loss: [1m[32m0.30769[0m[0m | time: 324.858s
[2K
| RMSProp | epoch: 010 | loss: 0.30769 - acc: 0.8959 -- iter: 160/166
[A[ATraining Step: 60  | total loss: [1m[32m0.29090[0m[0m | time: 449.224s
[2K
| RMSProp | epoch: 010 | loss: 0.29090 - acc: 0.9056 | val_loss: 0.29079 - val_acc: 0.9434 -- iter: 166/166
--
Training Step: 61  | total loss: [1m[32m0.30003[0m[0m | time: 14.780s
[2K
| RMSProp | epoch: 011 | loss: 0.30003 - acc: 0.8975 -- iter: 032/166
[A[ATraining Step: 62  | total loss: [1m[32m0.29739[0m[0m | time: 18.503s
[2K
| RMSProp | epoch: 011 | loss: 0.29739 - acc: 0.8986 -- iter: 064/166
[A[ATraining Step: 63  | total loss: [1m[32m0.29399[0m[0m | time: 21.872s
[2K
| RMSProp | epoch: 011 | loss: 0.29399 - acc: 0.8904 -- iter: 096/166
[A[ATraining Step: 64  | total loss: [1m[32m0.27135[0m[0m | time: 35.522s
[2K
| RMSProp | epoch: 011 | loss: 0.27135 - acc: 0.9041 -- iter: 128/166
[A[ATraining Step: 65  | total loss: [1m[32m0.27035[0m[0m | time: 165.450s
[2K
| RMSProp | epoch: 011 | loss: 0.27035 - acc: 0.9005 -- iter: 160/166
[A[ATraining Step: 66  | total loss: [1m[32m0.26983[0m[0m | time: 201.240s
[2K
| RMSProp | epoch: 011 | loss: 0.26983 - acc: 0.8974 | val_loss: 0.35184 - val_acc: 0.8491 -- iter: 166/166
--
Training Step: 67  | total loss: [1m[32m0.25630[0m[0m | time: 21.639s
[2K
| RMSProp | epoch: 012 | loss: 0.25630 - acc: 0.9022 -- iter: 032/166
[A[ATraining Step: 68  | total loss: [1m[32m0.24264[0m[0m | time: 53.859s
[2K
| RMSProp | epoch: 012 | loss: 0.24264 - acc: 0.9101 -- iter: 064/166
[A[ATraining Step: 69  | total loss: [1m[32m0.23396[0m[0m | time: 59.431s
[2K
| RMSProp | epoch: 012 | loss: 0.23396 - acc: 0.9096 -- iter: 096/166
[A[ATraining Step: 70  | total loss: [1m[32m0.21470[0m[0m | time: 65.324s
[2K
| RMSProp | epoch: 012 | loss: 0.21470 - acc: 0.9201 -- iter: 128/166
[A[ATraining Step: 71  | total loss: [1m[32m0.19506[0m[0m | time: 163.347s
[2K
| RMSProp | epoch: 012 | loss: 0.19506 - acc: 0.9292 -- iter: 160/166
[A[ATraining Step: 72  | total loss: [1m[32m0.19054[0m[0m | time: 181.428s
[2K
| RMSProp | epoch: 012 | loss: 0.19054 - acc: 0.9301 | val_loss: 0.32669 - val_acc: 0.9057 -- iter: 166/166
--
Training Step: 73  | total loss: [1m[32m0.20130[0m[0m | time: 18.952s
[2K
| RMSProp | epoch: 013 | loss: 0.20130 - acc: 0.9275 -- iter: 032/166
[A[ATraining Step: 74  | total loss: [1m[32m0.19827[0m[0m | time: 38.493s
[2K
| RMSProp | epoch: 013 | loss: 0.19827 - acc: 0.9286 -- iter: 064/166
[A[ATraining Step: 75  | total loss: [1m[32m0.18957[0m[0m | time: 55.651s
[2K
| RMSProp | epoch: 013 | loss: 0.18957 - acc: 0.9329 -- iter: 096/166
[A[ATraining Step: 76  | total loss: [1m[32m0.17704[0m[0m | time: 60.831s
[2K
| RMSProp | epoch: 013 | loss: 0.17704 - acc: 0.9368 -- iter: 128/166
[A[ATraining Step: 77  | total loss: [1m[32m0.16809[0m[0m | time: 66.619s
[2K
| RMSProp | epoch: 013 | loss: 0.16809 - acc: 0.9434 -- iter: 160/166
[A[ATraining Step: 78  | total loss: [1m[32m0.15386[0m[0m | time: 92.540s
[2K
| RMSProp | epoch: 013 | loss: 0.15386 - acc: 0.9494 | val_loss: 0.64734 - val_acc: 0.7170 -- iter: 166/166
--
Training Step: 79  | total loss: [1m[32m0.15785[0m[0m | time: 11.886s
[2K
| RMSProp | epoch: 014 | loss: 0.15785 - acc: 0.9449 -- iter: 032/166
[A[ATraining Step: 80  | total loss: [1m[32m0.14939[0m[0m | time: 22.290s
[2K
| RMSProp | epoch: 014 | loss: 0.14939 - acc: 0.9505 -- iter: 064/166
[A[ATraining Step: 81  | total loss: [1m[32m0.14053[0m[0m | time: 33.013s
[2K
| RMSProp | epoch: 014 | loss: 0.14053 - acc: 0.9555 -- iter: 096/166
[A[ATraining Step: 82  | total loss: [1m[32m0.13553[0m[0m | time: 47.643s
[2K
| RMSProp | epoch: 014 | loss: 0.13553 - acc: 0.9537 -- iter: 128/166
[A[ATraining Step: 83  | total loss: [1m[32m0.12526[0m[0m | time: 52.163s
[2K
| RMSProp | epoch: 014 | loss: 0.12526 - acc: 0.9584 -- iter: 160/166
[A[ATraining Step: 84  | total loss: [1m[32m0.15160[0m[0m | time: 61.748s
[2K
| RMSProp | epoch: 014 | loss: 0.15160 - acc: 0.9625 | val_loss: 0.33361 - val_acc: 0.9245 -- iter: 166/166
--
Training Step: 85  | total loss: [1m[32m0.14506[0m[0m | time: 15.715s
[2K
| RMSProp | epoch: 015 | loss: 0.14506 - acc: 0.9663 -- iter: 032/166
[A[ATraining Step: 86  | total loss: [1m[32m0.14983[0m[0m | time: 29.783s
[2K
| RMSProp | epoch: 015 | loss: 0.14983 - acc: 0.9603 -- iter: 064/166
[A[ATraining Step: 87  | total loss: [1m[32m0.20810[0m[0m | time: 45.561s
[2K
| RMSProp | epoch: 015 | loss: 0.20810 - acc: 0.9486 -- iter: 096/166
[A[ATraining Step: 88  | total loss: [1m[32m0.19996[0m[0m | time: 62.022s
[2K
| RMSProp | epoch: 015 | loss: 0.19996 - acc: 0.9538 -- iter: 128/166
[A[ATraining Step: 89  | total loss: [1m[32m0.18470[0m[0m | time: 75.322s
[2K
| RMSProp | epoch: 015 | loss: 0.18470 - acc: 0.9584 -- iter: 160/166
[A[ATraining Step: 90  | total loss: [1m[32m0.17403[0m[0m | time: 82.469s
[2K
| RMSProp | epoch: 015 | loss: 0.17403 - acc: 0.9594 | val_loss: 0.40265 - val_acc: 0.8302 -- iter: 166/166
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9800569800569802
Validation AUPRC:0.9726414231492951
Test AUC:0.9985714285714286
Test AUPRC:0.9984615384615385
BestTestF1Score	0.98	0.96	0.98	0.96	1.0	25	1	27	0	0.87
BestTestMCCScore	0.98	0.96	0.98	0.96	1.0	25	1	27	0	0.87
BestTestAccuracyScore	0.98	0.96	0.98	0.96	1.0	25	1	27	0	0.87
BestValidationF1Score	0.98	0.96	0.98	0.96	1.0	26	1	26	0	0.87
BestValidationMCC	0.98	0.96	0.98	0.96	1.0	26	1	26	0	0.87
BestValidationAccuracy	0.98	0.96	0.98	0.96	1.0	26	1	26	0	0.87
TestPredictions (Threshold:0.87)
CHEMBL2369982,TP,ACT,1.0	CHEMBL2391353,TN,INACT,0.019999999552965164	CHEMBL413465,TP,ACT,1.0	CHEMBL45305,TN,INACT,0.10999999940395355	CHEMBL347364,TP,ACT,1.0	CHEMBL3633665,TN,INACT,0.44999998807907104	CHEMBL2324200,TN,INACT,0.3799999952316284	CHEMBL3577982,TP,ACT,1.0	CHEMBL165012,TN,INACT,0.019999999552965164	CHEMBL298612,TN,INACT,0.17000000178813934	CHEMBL3577986,TP,ACT,1.0	CHEMBL323517,TN,INACT,0.07999999821186066	CHEMBL3582445,TP,ACT,0.9900000095367432	CHEMBL3582443,TP,ACT,1.0	CHEMBL2371150,TN,INACT,0.6499999761581421	CHEMBL1258999,TN,INACT,0.10000000149011612	CHEMBL2323529,TP,ACT,1.0	CHEMBL2369959,TP,ACT,1.0	CHEMBL346925,TP,ACT,1.0	CHEMBL306645,FP,INACT,0.949999988079071	CHEMBL2042401,TN,INACT,0.029999999329447746	CHEMBL430239,TP,ACT,0.9900000095367432	CHEMBL352779,TN,INACT,0.07999999821186066	CHEMBL552615,TN,INACT,0.05999999865889549	CHEMBL228144,TN,INACT,0.029999999329447746	CHEMBL96871,TP,ACT,1.0	CHEMBL241082,TN,INACT,0.6600000262260437	CHEMBL129198,TN,INACT,0.07000000029802322	CHEMBL103817,TP,ACT,1.0	CHEMBL2369960,TP,ACT,1.0	CHEMBL227429,TN,INACT,0.4000000059604645	CHEMBL96531,TP,ACT,1.0	CHEMBL2323793,TP,ACT,1.0	CHEMBL3287322,TP,ACT,1.0	CHEMBL312958,TN,INACT,0.11999999731779099	CHEMBL594801,TN,INACT,0.07999999821186066	CHEMBL3287323,TP,ACT,0.9900000095367432	CHEMBL2369967,TP,ACT,1.0	CHEMBL2391356,TN,INACT,0.009999999776482582	CHEMBL3309718,TN,INACT,0.029999999329447746	CHEMBL357558,TP,ACT,1.0	CHEMBL1688111,TP,ACT,1.0	CHEMBL152986,TP,ACT,0.9800000190734863	CHEMBL2096693,TP,ACT,0.8700000047683716	CHEMBL21328,TN,INACT,0.23999999463558197	CHEMBL330885,TN,INACT,0.18000000715255737	CHEMBL123099,TN,INACT,0.800000011920929	CHEMBL3799955,TP,ACT,1.0	CHEMBL329847,TP,ACT,1.0	CHEMBL1180343,TN,INACT,0.5899999737739563	CHEMBL241279,TN,INACT,0.2199999988079071	CHEMBL62660,TN,INACT,0.05999999865889549	CHEMBL100624,TN,INACT,0.7300000190734863	

