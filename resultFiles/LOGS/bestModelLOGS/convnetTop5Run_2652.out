ImageNetInceptionV2 CHEMBL2489 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	178
Number of inactive compounds :	178
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2489_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2489_adam_0.0005_30_0.8/
---------------------------------
Training samples: 222
Validation samples: 70
--
Training Step: 1  | time: 104.350s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/222
[A[ATraining Step: 2  | total loss: [1m[32m0.69796[0m[0m | time: 116.315s
[2K
| Adam | epoch: 001 | loss: 0.69796 - acc: 0.4781 -- iter: 064/222
[A[ATraining Step: 3  | total loss: [1m[32m0.81577[0m[0m | time: 127.030s
[2K
| Adam | epoch: 001 | loss: 0.81577 - acc: 0.5727 -- iter: 096/222
[A[ATraining Step: 4  | total loss: [1m[32m0.63205[0m[0m | time: 138.292s
[2K
| Adam | epoch: 001 | loss: 0.63205 - acc: 0.6822 -- iter: 128/222
[A[ATraining Step: 5  | total loss: [1m[32m0.59703[0m[0m | time: 163.199s
[2K
| Adam | epoch: 001 | loss: 0.59703 - acc: 0.6426 -- iter: 160/222
[A[ATraining Step: 6  | total loss: [1m[32m0.57533[0m[0m | time: 204.068s
[2K
| Adam | epoch: 001 | loss: 0.57533 - acc: 0.7317 -- iter: 192/222
[A[ATraining Step: 7  | total loss: [1m[32m0.50250[0m[0m | time: 244.171s
[2K
| Adam | epoch: 001 | loss: 0.50250 - acc: 0.8552 | val_loss: 2.65863 - val_acc: 0.4857 -- iter: 222/222
--
Training Step: 8  | total loss: [1m[32m0.34087[0m[0m | time: 64.957s
[2K
| Adam | epoch: 002 | loss: 0.34087 - acc: 0.9179 -- iter: 032/222
[A[ATraining Step: 9  | total loss: [1m[32m0.20223[0m[0m | time: 138.480s
[2K
| Adam | epoch: 002 | loss: 0.20223 - acc: 0.9614 -- iter: 064/222
[A[ATraining Step: 10  | total loss: [1m[32m0.27062[0m[0m | time: 160.571s
[2K
| Adam | epoch: 002 | loss: 0.27062 - acc: 0.9182 -- iter: 096/222
[A[ATraining Step: 11  | total loss: [1m[32m0.28539[0m[0m | time: 177.903s
[2K
| Adam | epoch: 002 | loss: 0.28539 - acc: 0.9125 -- iter: 128/222
[A[ATraining Step: 12  | total loss: [1m[32m0.34058[0m[0m | time: 193.268s
[2K
| Adam | epoch: 002 | loss: 0.34058 - acc: 0.8535 -- iter: 160/222
[A[ATraining Step: 13  | total loss: [1m[32m0.28811[0m[0m | time: 207.835s
[2K
| Adam | epoch: 002 | loss: 0.28811 - acc: 0.8761 -- iter: 192/222
[A[ATraining Step: 14  | total loss: [1m[32m0.34238[0m[0m | time: 222.672s
[2K
| Adam | epoch: 002 | loss: 0.34238 - acc: 0.8245 | val_loss: 5.29209 - val_acc: 0.4857 -- iter: 222/222
--
Training Step: 15  | total loss: [1m[32m0.33112[0m[0m | time: 11.710s
[2K
| Adam | epoch: 003 | loss: 0.33112 - acc: 0.8565 -- iter: 032/222
[A[ATraining Step: 16  | total loss: [1m[32m0.28892[0m[0m | time: 23.903s
[2K
| Adam | epoch: 003 | loss: 0.28892 - acc: 0.8853 -- iter: 064/222
[A[ATraining Step: 17  | total loss: [1m[32m0.20855[0m[0m | time: 36.320s
[2K
| Adam | epoch: 003 | loss: 0.20855 - acc: 0.9146 -- iter: 096/222
[A[ATraining Step: 18  | total loss: [1m[32m0.20494[0m[0m | time: 48.969s
[2K
| Adam | epoch: 003 | loss: 0.20494 - acc: 0.9117 -- iter: 128/222
[A[ATraining Step: 19  | total loss: [1m[32m0.16053[0m[0m | time: 61.344s
[2K
| Adam | epoch: 003 | loss: 0.16053 - acc: 0.9411 -- iter: 160/222
[A[ATraining Step: 20  | total loss: [1m[32m0.22019[0m[0m | time: 69.334s
[2K
| Adam | epoch: 003 | loss: 0.22019 - acc: 0.9299 -- iter: 192/222
[A[ATraining Step: 21  | total loss: [1m[32m0.19650[0m[0m | time: 80.590s
[2K
| Adam | epoch: 003 | loss: 0.19650 - acc: 0.9420 | val_loss: 4.35411 - val_acc: 0.4857 -- iter: 222/222
--
Training Step: 22  | total loss: [1m[32m0.19468[0m[0m | time: 12.181s
[2K
| Adam | epoch: 004 | loss: 0.19468 - acc: 0.9313 -- iter: 032/222
[A[ATraining Step: 23  | total loss: [1m[32m0.17694[0m[0m | time: 23.694s
[2K
| Adam | epoch: 004 | loss: 0.17694 - acc: 0.9421 -- iter: 064/222
[A[ATraining Step: 24  | total loss: [1m[32m0.17320[0m[0m | time: 35.628s
[2K
| Adam | epoch: 004 | loss: 0.17320 - acc: 0.9490 -- iter: 096/222
[A[ATraining Step: 25  | total loss: [1m[32m0.13824[0m[0m | time: 47.225s
[2K
| Adam | epoch: 004 | loss: 0.13824 - acc: 0.9629 -- iter: 128/222
[A[ATraining Step: 26  | total loss: [1m[32m0.13990[0m[0m | time: 55.319s
[2K
| Adam | epoch: 004 | loss: 0.13990 - acc: 0.9562 -- iter: 160/222
[A[ATraining Step: 27  | total loss: [1m[32m0.12146[0m[0m | time: 63.435s
[2K
| Adam | epoch: 004 | loss: 0.12146 - acc: 0.9675 -- iter: 192/222
[A[ATraining Step: 28  | total loss: [1m[32m0.14158[0m[0m | time: 76.804s
[2K
| Adam | epoch: 004 | loss: 0.14158 - acc: 0.9522 | val_loss: 5.99889 - val_acc: 0.4857 -- iter: 222/222
--
Training Step: 29  | total loss: [1m[32m0.19826[0m[0m | time: 12.803s
[2K
| Adam | epoch: 005 | loss: 0.19826 - acc: 0.9486 -- iter: 032/222
[A[ATraining Step: 30  | total loss: [1m[32m0.16877[0m[0m | time: 25.506s
[2K
| Adam | epoch: 005 | loss: 0.16877 - acc: 0.9534 -- iter: 064/222
[A[ATraining Step: 31  | total loss: [1m[32m0.21061[0m[0m | time: 35.548s
[2K
| Adam | epoch: 005 | loss: 0.21061 - acc: 0.9209 -- iter: 096/222
[A[ATraining Step: 32  | total loss: [1m[32m0.41716[0m[0m | time: 43.291s
[2K
| Adam | epoch: 005 | loss: 0.41716 - acc: 0.8937 -- iter: 128/222
[A[ATraining Step: 33  | total loss: [1m[32m0.35039[0m[0m | time: 51.438s
[2K
| Adam | epoch: 005 | loss: 0.35039 - acc: 0.9024 -- iter: 160/222
[A[ATraining Step: 34  | total loss: [1m[32m0.31707[0m[0m | time: 61.185s
[2K
| Adam | epoch: 005 | loss: 0.31707 - acc: 0.9099 -- iter: 192/222
[A[ATraining Step: 35  | total loss: [1m[32m0.26001[0m[0m | time: 78.984s
[2K
| Adam | epoch: 005 | loss: 0.26001 - acc: 0.9222 | val_loss: 1.48072 - val_acc: 0.4714 -- iter: 222/222
--
Training Step: 36  | total loss: [1m[32m0.24041[0m[0m | time: 13.596s
[2K
| Adam | epoch: 006 | loss: 0.24041 - acc: 0.9126 -- iter: 032/222
[A[ATraining Step: 37  | total loss: [1m[32m0.20961[0m[0m | time: 23.638s
[2K
| Adam | epoch: 006 | loss: 0.20961 - acc: 0.9238 -- iter: 064/222
[A[ATraining Step: 38  | total loss: [1m[32m0.22038[0m[0m | time: 31.642s
[2K
| Adam | epoch: 006 | loss: 0.22038 - acc: 0.9143 -- iter: 096/222
[A[ATraining Step: 39  | total loss: [1m[32m0.20033[0m[0m | time: 39.318s
[2K
| Adam | epoch: 006 | loss: 0.20033 - acc: 0.9247 -- iter: 128/222
[A[ATraining Step: 40  | total loss: [1m[32m0.20405[0m[0m | time: 48.376s
[2K
| Adam | epoch: 006 | loss: 0.20405 - acc: 0.9263 -- iter: 160/222
[A[ATraining Step: 41  | total loss: [1m[32m0.17998[0m[0m | time: 60.836s
[2K
| Adam | epoch: 006 | loss: 0.17998 - acc: 0.9398 -- iter: 192/222
[A[ATraining Step: 42  | total loss: [1m[32m0.16668[0m[0m | time: 77.764s
[2K
| Adam | epoch: 006 | loss: 0.16668 - acc: 0.9450 | val_loss: 1.70379 - val_acc: 0.4714 -- iter: 222/222
--
Training Step: 43  | total loss: [1m[32m0.14683[0m[0m | time: 9.618s
[2K
| Adam | epoch: 007 | loss: 0.14683 - acc: 0.9547 -- iter: 032/222
[A[ATraining Step: 44  | total loss: [1m[32m0.16732[0m[0m | time: 17.736s
[2K
| Adam | epoch: 007 | loss: 0.16732 - acc: 0.9464 -- iter: 064/222
[A[ATraining Step: 45  | total loss: [1m[32m0.14507[0m[0m | time: 25.850s
[2K
| Adam | epoch: 007 | loss: 0.14507 - acc: 0.9555 -- iter: 096/222
[A[ATraining Step: 46  | total loss: [1m[32m0.12958[0m[0m | time: 37.970s
[2K
| Adam | epoch: 007 | loss: 0.12958 - acc: 0.9577 -- iter: 128/222
[A[ATraining Step: 47  | total loss: [1m[32m0.11577[0m[0m | time: 49.694s
[2K
| Adam | epoch: 007 | loss: 0.11577 - acc: 0.9646 -- iter: 160/222
[A[ATraining Step: 48  | total loss: [1m[32m0.10172[0m[0m | time: 61.524s
[2K
| Adam | epoch: 007 | loss: 0.10172 - acc: 0.9703 -- iter: 192/222
[A[ATraining Step: 49  | total loss: [1m[32m0.08970[0m[0m | time: 79.036s
[2K
| Adam | epoch: 007 | loss: 0.08970 - acc: 0.9750 | val_loss: 0.86628 - val_acc: 0.6571 -- iter: 222/222
--
Training Step: 50  | total loss: [1m[32m0.07732[0m[0m | time: 8.044s
[2K
| Adam | epoch: 008 | loss: 0.07732 - acc: 0.9789 -- iter: 032/222
[A[ATraining Step: 51  | total loss: [1m[32m0.07574[0m[0m | time: 16.326s
[2K
| Adam | epoch: 008 | loss: 0.07574 - acc: 0.9773 -- iter: 064/222
[A[ATraining Step: 52  | total loss: [1m[32m0.06599[0m[0m | time: 29.540s
[2K
| Adam | epoch: 008 | loss: 0.06599 - acc: 0.9807 -- iter: 096/222
[A[ATraining Step: 53  | total loss: [1m[32m0.05813[0m[0m | time: 41.672s
[2K
| Adam | epoch: 008 | loss: 0.05813 - acc: 0.9836 -- iter: 128/222
[A[ATraining Step: 54  | total loss: [1m[32m0.06672[0m[0m | time: 54.048s
[2K
| Adam | epoch: 008 | loss: 0.06672 - acc: 0.9814 -- iter: 160/222
[A[ATraining Step: 55  | total loss: [1m[32m0.09750[0m[0m | time: 66.266s
[2K
| Adam | epoch: 008 | loss: 0.09750 - acc: 0.9707 -- iter: 192/222
[A[ATraining Step: 56  | total loss: [1m[32m0.08749[0m[0m | time: 83.025s
[2K
| Adam | epoch: 008 | loss: 0.08749 - acc: 0.9748 | val_loss: 0.52292 - val_acc: 0.7857 -- iter: 222/222
--
Training Step: 57  | total loss: [1m[32m0.07819[0m[0m | time: 12.473s
[2K
| Adam | epoch: 009 | loss: 0.07819 - acc: 0.9783 -- iter: 032/222
[A[ATraining Step: 58  | total loss: [1m[32m0.06949[0m[0m | time: 25.075s
[2K
| Adam | epoch: 009 | loss: 0.06949 - acc: 0.9813 -- iter: 064/222
[A[ATraining Step: 59  | total loss: [1m[32m0.06056[0m[0m | time: 37.208s
[2K
| Adam | epoch: 009 | loss: 0.06056 - acc: 0.9838 -- iter: 096/222
[A[ATraining Step: 60  | total loss: [1m[32m0.07407[0m[0m | time: 49.537s
[2K
| Adam | epoch: 009 | loss: 0.07407 - acc: 0.9818 -- iter: 128/222
[A[ATraining Step: 61  | total loss: [1m[32m0.08124[0m[0m | time: 61.828s
[2K
| Adam | epoch: 009 | loss: 0.08124 - acc: 0.9760 -- iter: 160/222
[A[ATraining Step: 62  | total loss: [1m[32m0.07146[0m[0m | time: 73.061s
[2K
| Adam | epoch: 009 | loss: 0.07146 - acc: 0.9791 -- iter: 192/222
[A[ATraining Step: 63  | total loss: [1m[32m0.07278[0m[0m | time: 84.022s
[2K
| Adam | epoch: 009 | loss: 0.07278 - acc: 0.9778 | val_loss: 1.17684 - val_acc: 0.7429 -- iter: 222/222
--
Training Step: 64  | total loss: [1m[32m0.07957[0m[0m | time: 7.729s
[2K
| Adam | epoch: 010 | loss: 0.07957 - acc: 0.9764 -- iter: 032/222
[A[ATraining Step: 65  | total loss: [1m[32m0.07130[0m[0m | time: 15.735s
[2K
| Adam | epoch: 010 | loss: 0.07130 - acc: 0.9793 -- iter: 064/222
[A[ATraining Step: 66  | total loss: [1m[32m0.06356[0m[0m | time: 23.639s
[2K
| Adam | epoch: 010 | loss: 0.06356 - acc: 0.9818 -- iter: 096/222
[A[ATraining Step: 67  | total loss: [1m[32m0.08563[0m[0m | time: 31.712s
[2K
| Adam | epoch: 010 | loss: 0.08563 - acc: 0.9765 -- iter: 128/222
[A[ATraining Step: 68  | total loss: [1m[32m0.08223[0m[0m | time: 39.608s
[2K
| Adam | epoch: 010 | loss: 0.08223 - acc: 0.9756 -- iter: 160/222
[A[ATraining Step: 69  | total loss: [1m[32m0.08120[0m[0m | time: 47.505s
[2K
| Adam | epoch: 010 | loss: 0.08120 - acc: 0.9748 -- iter: 192/222
[A[ATraining Step: 70  | total loss: [1m[32m0.08086[0m[0m | time: 58.735s
[2K
| Adam | epoch: 010 | loss: 0.08086 - acc: 0.9741 | val_loss: 7.55256 - val_acc: 0.5143 -- iter: 222/222
--
Training Step: 71  | total loss: [1m[32m0.07627[0m[0m | time: 7.513s
[2K
| Adam | epoch: 011 | loss: 0.07627 - acc: 0.9770 -- iter: 032/222
[A[ATraining Step: 72  | total loss: [1m[32m0.11036[0m[0m | time: 15.060s
[2K
| Adam | epoch: 011 | loss: 0.11036 - acc: 0.9721 -- iter: 064/222
[A[ATraining Step: 73  | total loss: [1m[32m0.10480[0m[0m | time: 23.004s
[2K
| Adam | epoch: 011 | loss: 0.10480 - acc: 0.9752 -- iter: 096/222
[A[ATraining Step: 74  | total loss: [1m[32m0.10154[0m[0m | time: 31.070s
[2K
| Adam | epoch: 011 | loss: 0.10154 - acc: 0.9745 -- iter: 128/222
[A[ATraining Step: 75  | total loss: [1m[32m0.11224[0m[0m | time: 38.984s
[2K
| Adam | epoch: 011 | loss: 0.11224 - acc: 0.9671 -- iter: 160/222
[A[ATraining Step: 76  | total loss: [1m[32m0.10160[0m[0m | time: 46.808s
[2K
| Adam | epoch: 011 | loss: 0.10160 - acc: 0.9706 -- iter: 192/222
[A[ATraining Step: 77  | total loss: [1m[32m0.09408[0m[0m | time: 57.861s
[2K
| Adam | epoch: 011 | loss: 0.09408 - acc: 0.9737 | val_loss: 2.34974 - val_acc: 0.5571 -- iter: 222/222
--
Training Step: 78  | total loss: [1m[32m0.10094[0m[0m | time: 7.805s
[2K
| Adam | epoch: 012 | loss: 0.10094 - acc: 0.9667 -- iter: 032/222
[A[ATraining Step: 79  | total loss: [1m[32m0.10166[0m[0m | time: 15.459s
[2K
| Adam | epoch: 012 | loss: 0.10166 - acc: 0.9669 -- iter: 064/222
[A[ATraining Step: 80  | total loss: [1m[32m0.09716[0m[0m | time: 23.151s
[2K
| Adam | epoch: 012 | loss: 0.09716 - acc: 0.9669 -- iter: 096/222
[A[ATraining Step: 81  | total loss: [1m[32m0.08906[0m[0m | time: 31.153s
[2K
| Adam | epoch: 012 | loss: 0.08906 - acc: 0.9702 -- iter: 128/222
[A[ATraining Step: 82  | total loss: [1m[32m0.09338[0m[0m | time: 39.031s
[2K
| Adam | epoch: 012 | loss: 0.09338 - acc: 0.9669 -- iter: 160/222
[A[ATraining Step: 83  | total loss: [1m[32m0.08569[0m[0m | time: 46.974s
[2K
| Adam | epoch: 012 | loss: 0.08569 - acc: 0.9703 -- iter: 192/222
[A[ATraining Step: 84  | total loss: [1m[32m0.07934[0m[0m | time: 58.133s
[2K
| Adam | epoch: 012 | loss: 0.07934 - acc: 0.9732 | val_loss: 2.13238 - val_acc: 0.5286 -- iter: 222/222
--
Training Step: 85  | total loss: [1m[32m0.07338[0m[0m | time: 8.092s
[2K
| Adam | epoch: 013 | loss: 0.07338 - acc: 0.9759 -- iter: 032/222
[A[ATraining Step: 86  | total loss: [1m[32m0.08586[0m[0m | time: 16.179s
[2K
| Adam | epoch: 013 | loss: 0.08586 - acc: 0.9721 -- iter: 064/222
[A[ATraining Step: 87  | total loss: [1m[32m0.08543[0m[0m | time: 23.701s
[2K
| Adam | epoch: 013 | loss: 0.08543 - acc: 0.9717 -- iter: 096/222
[A[ATraining Step: 88  | total loss: [1m[32m0.09845[0m[0m | time: 31.204s
[2K
| Adam | epoch: 013 | loss: 0.09845 - acc: 0.9712 -- iter: 128/222
[A[ATraining Step: 89  | total loss: [1m[32m0.09122[0m[0m | time: 39.151s
[2K
| Adam | epoch: 013 | loss: 0.09122 - acc: 0.9741 -- iter: 160/222
[A[ATraining Step: 90  | total loss: [1m[32m0.08323[0m[0m | time: 47.385s
[2K
| Adam | epoch: 013 | loss: 0.08323 - acc: 0.9767 -- iter: 192/222
[A[ATraining Step: 91  | total loss: [1m[32m0.07652[0m[0m | time: 58.391s
[2K
| Adam | epoch: 013 | loss: 0.07652 - acc: 0.9790 | val_loss: 0.63818 - val_acc: 0.8000 -- iter: 222/222
--
Training Step: 92  | total loss: [1m[32m0.06924[0m[0m | time: 8.149s
[2K
| Adam | epoch: 014 | loss: 0.06924 - acc: 0.9811 -- iter: 032/222
[A[ATraining Step: 93  | total loss: [1m[32m0.06326[0m[0m | time: 16.089s
[2K
| Adam | epoch: 014 | loss: 0.06326 - acc: 0.9830 -- iter: 064/222
[A[ATraining Step: 94  | total loss: [1m[32m0.06419[0m[0m | time: 24.017s
[2K
| Adam | epoch: 014 | loss: 0.06419 - acc: 0.9816 -- iter: 096/222
[A[ATraining Step: 95  | total loss: [1m[32m0.05809[0m[0m | time: 31.570s
[2K
| Adam | epoch: 014 | loss: 0.05809 - acc: 0.9834 -- iter: 128/222
[A[ATraining Step: 96  | total loss: [1m[32m0.06803[0m[0m | time: 39.134s
[2K
| Adam | epoch: 014 | loss: 0.06803 - acc: 0.9817 -- iter: 160/222
[A[ATraining Step: 97  | total loss: [1m[32m0.06157[0m[0m | time: 47.084s
[2K
| Adam | epoch: 014 | loss: 0.06157 - acc: 0.9836 -- iter: 192/222
[A[ATraining Step: 98  | total loss: [1m[32m0.05861[0m[0m | time: 58.110s
[2K
| Adam | epoch: 014 | loss: 0.05861 - acc: 0.9852 | val_loss: 0.58211 - val_acc: 0.8000 -- iter: 222/222
--
Training Step: 99  | total loss: [1m[32m0.06434[0m[0m | time: 8.197s
[2K
| Adam | epoch: 015 | loss: 0.06434 - acc: 0.9836 -- iter: 032/222
[A[ATraining Step: 100  | total loss: [1m[32m0.07711[0m[0m | time: 16.056s
[2K
| Adam | epoch: 015 | loss: 0.07711 - acc: 0.9790 -- iter: 064/222
[A[ATraining Step: 101  | total loss: [1m[32m0.08852[0m[0m | time: 24.131s
[2K
| Adam | epoch: 015 | loss: 0.08852 - acc: 0.9779 -- iter: 096/222
[A[ATraining Step: 102  | total loss: [1m[32m0.08191[0m[0m | time: 31.898s
[2K
| Adam | epoch: 015 | loss: 0.08191 - acc: 0.9801 -- iter: 128/222
[A[ATraining Step: 103  | total loss: [1m[32m0.09995[0m[0m | time: 39.527s
[2K
| Adam | epoch: 015 | loss: 0.09995 - acc: 0.9790 -- iter: 160/222
[A[ATraining Step: 104  | total loss: [1m[32m0.10663[0m[0m | time: 46.979s
[2K
| Adam | epoch: 015 | loss: 0.10663 - acc: 0.9778 -- iter: 192/222
[A[ATraining Step: 105  | total loss: [1m[32m0.09648[0m[0m | time: 58.135s
[2K
| Adam | epoch: 015 | loss: 0.09648 - acc: 0.9800 | val_loss: 0.40814 - val_acc: 0.8143 -- iter: 222/222
--
Training Step: 106  | total loss: [1m[32m0.09580[0m[0m | time: 8.132s
[2K
| Adam | epoch: 016 | loss: 0.09580 - acc: 0.9789 -- iter: 032/222
[A[ATraining Step: 107  | total loss: [1m[32m0.09726[0m[0m | time: 16.186s
[2K
| Adam | epoch: 016 | loss: 0.09726 - acc: 0.9747 -- iter: 064/222
[A[ATraining Step: 108  | total loss: [1m[32m0.08851[0m[0m | time: 24.065s
[2K
| Adam | epoch: 016 | loss: 0.08851 - acc: 0.9773 -- iter: 096/222
[A[ATraining Step: 109  | total loss: [1m[32m0.08143[0m[0m | time: 32.134s
[2K
| Adam | epoch: 016 | loss: 0.08143 - acc: 0.9795 -- iter: 128/222
[A[ATraining Step: 110  | total loss: [1m[32m0.08083[0m[0m | time: 39.954s
[2K
| Adam | epoch: 016 | loss: 0.08083 - acc: 0.9785 -- iter: 160/222
[A[ATraining Step: 111  | total loss: [1m[32m0.08509[0m[0m | time: 47.431s
[2K
| Adam | epoch: 016 | loss: 0.08509 - acc: 0.9775 -- iter: 192/222
[A[ATraining Step: 112  | total loss: [1m[32m0.13318[0m[0m | time: 58.162s
[2K
| Adam | epoch: 016 | loss: 0.13318 - acc: 0.9731 | val_loss: 0.63483 - val_acc: 0.7714 -- iter: 222/222
--
Training Step: 113  | total loss: [1m[32m0.12121[0m[0m | time: 8.022s
[2K
| Adam | epoch: 017 | loss: 0.12121 - acc: 0.9758 -- iter: 032/222
[A[ATraining Step: 114  | total loss: [1m[32m0.11860[0m[0m | time: 15.985s
[2K
| Adam | epoch: 017 | loss: 0.11860 - acc: 0.9719 -- iter: 064/222
[A[ATraining Step: 115  | total loss: [1m[32m0.10972[0m[0m | time: 23.844s
[2K
| Adam | epoch: 017 | loss: 0.10972 - acc: 0.9747 -- iter: 096/222
[A[ATraining Step: 116  | total loss: [1m[32m0.11558[0m[0m | time: 31.686s
[2K
| Adam | epoch: 017 | loss: 0.11558 - acc: 0.9741 -- iter: 128/222
[A[ATraining Step: 117  | total loss: [1m[32m0.11182[0m[0m | time: 39.636s
[2K
| Adam | epoch: 017 | loss: 0.11182 - acc: 0.9736 -- iter: 160/222
[A[ATraining Step: 118  | total loss: [1m[32m0.10652[0m[0m | time: 47.555s
[2K
| Adam | epoch: 017 | loss: 0.10652 - acc: 0.9762 -- iter: 192/222
[A[ATraining Step: 119  | total loss: [1m[32m0.10097[0m[0m | time: 58.429s
[2K
| Adam | epoch: 017 | loss: 0.10097 - acc: 0.9755 | val_loss: 0.65641 - val_acc: 0.7571 -- iter: 222/222
--
Training Step: 120  | total loss: [1m[32m0.10294[0m[0m | time: 7.557s
[2K
| Adam | epoch: 018 | loss: 0.10294 - acc: 0.9746 -- iter: 032/222
[A[ATraining Step: 121  | total loss: [1m[32m0.09477[0m[0m | time: 15.419s
[2K
| Adam | epoch: 018 | loss: 0.09477 - acc: 0.9772 -- iter: 064/222
[A[ATraining Step: 122  | total loss: [1m[32m0.09983[0m[0m | time: 23.220s
[2K
| Adam | epoch: 018 | loss: 0.09983 - acc: 0.9732 -- iter: 096/222
[A[ATraining Step: 123  | total loss: [1m[32m0.09404[0m[0m | time: 31.062s
[2K
| Adam | epoch: 018 | loss: 0.09404 - acc: 0.9759 -- iter: 128/222
[A[ATraining Step: 124  | total loss: [1m[32m0.08926[0m[0m | time: 38.978s
[2K
| Adam | epoch: 018 | loss: 0.08926 - acc: 0.9752 -- iter: 160/222
[A[ATraining Step: 125  | total loss: [1m[32m0.08491[0m[0m | time: 46.943s
[2K
| Adam | epoch: 018 | loss: 0.08491 - acc: 0.9776 -- iter: 192/222
[A[ATraining Step: 126  | total loss: [1m[32m0.08332[0m[0m | time: 57.936s
[2K
| Adam | epoch: 018 | loss: 0.08332 - acc: 0.9799 | val_loss: 0.24998 - val_acc: 0.8857 -- iter: 222/222
--
Training Step: 127  | total loss: [1m[32m0.07649[0m[0m | time: 7.632s
[2K
| Adam | epoch: 019 | loss: 0.07649 - acc: 0.9819 -- iter: 032/222
[A[ATraining Step: 128  | total loss: [1m[32m0.09763[0m[0m | time: 15.281s
[2K
| Adam | epoch: 019 | loss: 0.09763 - acc: 0.9770 -- iter: 064/222
[A[ATraining Step: 129  | total loss: [1m[32m0.08971[0m[0m | time: 23.116s
[2K
| Adam | epoch: 019 | loss: 0.08971 - acc: 0.9793 -- iter: 096/222
[A[ATraining Step: 130  | total loss: [1m[32m0.08401[0m[0m | time: 31.055s
[2K
| Adam | epoch: 019 | loss: 0.08401 - acc: 0.9783 -- iter: 128/222
[A[ATraining Step: 131  | total loss: [1m[32m0.07858[0m[0m | time: 38.971s
[2K
| Adam | epoch: 019 | loss: 0.07858 - acc: 0.9804 -- iter: 160/222
[A[ATraining Step: 132  | total loss: [1m[32m0.07568[0m[0m | time: 46.965s
[2K
| Adam | epoch: 019 | loss: 0.07568 - acc: 0.9793 -- iter: 192/222
[A[ATraining Step: 133  | total loss: [1m[32m0.07009[0m[0m | time: 57.938s
[2K
| Adam | epoch: 019 | loss: 0.07009 - acc: 0.9813 | val_loss: 0.53458 - val_acc: 0.8000 -- iter: 222/222
--
Training Step: 134  | total loss: [1m[32m0.06573[0m[0m | time: 7.950s
[2K
| Adam | epoch: 020 | loss: 0.06573 - acc: 0.9832 -- iter: 032/222
[A[ATraining Step: 135  | total loss: [1m[32m0.06852[0m[0m | time: 15.596s
[2K
| Adam | epoch: 020 | loss: 0.06852 - acc: 0.9818 -- iter: 064/222
[A[ATraining Step: 136  | total loss: [1m[32m0.06228[0m[0m | time: 23.185s
[2K
| Adam | epoch: 020 | loss: 0.06228 - acc: 0.9836 -- iter: 096/222
[A[ATraining Step: 137  | total loss: [1m[32m0.05658[0m[0m | time: 31.221s
[2K
| Adam | epoch: 020 | loss: 0.05658 - acc: 0.9852 -- iter: 128/222
[A[ATraining Step: 138  | total loss: [1m[32m0.05210[0m[0m | time: 39.182s
[2K
| Adam | epoch: 020 | loss: 0.05210 - acc: 0.9867 -- iter: 160/222
[A[ATraining Step: 139  | total loss: [1m[32m0.05098[0m[0m | time: 46.977s
[2K
| Adam | epoch: 020 | loss: 0.05098 - acc: 0.9849 -- iter: 192/222
[A[ATraining Step: 140  | total loss: [1m[32m0.04666[0m[0m | time: 58.142s
[2K
| Adam | epoch: 020 | loss: 0.04666 - acc: 0.9864 | val_loss: 0.88095 - val_acc: 0.7143 -- iter: 222/222
--
Training Step: 141  | total loss: [1m[32m0.04879[0m[0m | time: 8.046s
[2K
| Adam | epoch: 021 | loss: 0.04879 - acc: 0.9847 -- iter: 032/222
[A[ATraining Step: 142  | total loss: [1m[32m0.04414[0m[0m | time: 15.897s
[2K
| Adam | epoch: 021 | loss: 0.04414 - acc: 0.9862 -- iter: 064/222
[A[ATraining Step: 143  | total loss: [1m[32m0.04661[0m[0m | time: 23.535s
[2K
| Adam | epoch: 021 | loss: 0.04661 - acc: 0.9844 -- iter: 096/222
[A[ATraining Step: 144  | total loss: [1m[32m0.06893[0m[0m | time: 31.059s
[2K
| Adam | epoch: 021 | loss: 0.06893 - acc: 0.9827 -- iter: 128/222
[A[ATraining Step: 145  | total loss: [1m[32m0.06301[0m[0m | time: 38.920s
[2K
| Adam | epoch: 021 | loss: 0.06301 - acc: 0.9844 -- iter: 160/222
[A[ATraining Step: 146  | total loss: [1m[32m0.05759[0m[0m | time: 46.830s
[2K
| Adam | epoch: 021 | loss: 0.05759 - acc: 0.9860 -- iter: 192/222
[A[ATraining Step: 147  | total loss: [1m[32m0.05244[0m[0m | time: 57.918s
[2K
| Adam | epoch: 021 | loss: 0.05244 - acc: 0.9874 | val_loss: 0.40219 - val_acc: 0.8000 -- iter: 222/222
--
Training Step: 148  | total loss: [1m[32m0.04805[0m[0m | time: 7.911s
[2K
| Adam | epoch: 022 | loss: 0.04805 - acc: 0.9886 -- iter: 032/222
[A[ATraining Step: 149  | total loss: [1m[32m0.05516[0m[0m | time: 16.126s
[2K
| Adam | epoch: 022 | loss: 0.05516 - acc: 0.9866 -- iter: 064/222
[A[ATraining Step: 150  | total loss: [1m[32m0.05015[0m[0m | time: 24.178s
[2K
| Adam | epoch: 022 | loss: 0.05015 - acc: 0.9880 -- iter: 096/222
[A[ATraining Step: 151  | total loss: [1m[32m0.05213[0m[0m | time: 31.673s
[2K
| Adam | epoch: 022 | loss: 0.05213 - acc: 0.9861 -- iter: 128/222
[A[ATraining Step: 152  | total loss: [1m[32m0.10686[0m[0m | time: 39.128s
[2K
| Adam | epoch: 022 | loss: 0.10686 - acc: 0.9774 -- iter: 160/222
[A[ATraining Step: 153  | total loss: [1m[32m0.09792[0m[0m | time: 46.902s
[2K
| Adam | epoch: 022 | loss: 0.09792 - acc: 0.9797 -- iter: 192/222
[A[ATraining Step: 154  | total loss: [1m[32m0.08918[0m[0m | time: 57.939s
[2K
| Adam | epoch: 022 | loss: 0.08918 - acc: 0.9817 | val_loss: 0.52188 - val_acc: 0.7857 -- iter: 222/222
--
Training Step: 155  | total loss: [1m[32m0.09431[0m[0m | time: 7.912s
[2K
| Adam | epoch: 023 | loss: 0.09431 - acc: 0.9804 -- iter: 032/222
[A[ATraining Step: 156  | total loss: [1m[32m0.09795[0m[0m | time: 15.810s
[2K
| Adam | epoch: 023 | loss: 0.09795 - acc: 0.9761 -- iter: 064/222
[A[ATraining Step: 157  | total loss: [1m[32m0.09495[0m[0m | time: 23.629s
[2K
| Adam | epoch: 023 | loss: 0.09495 - acc: 0.9754 -- iter: 096/222
[A[ATraining Step: 158  | total loss: [1m[32m0.08645[0m[0m | time: 31.589s
[2K
| Adam | epoch: 023 | loss: 0.08645 - acc: 0.9779 -- iter: 128/222
[A[ATraining Step: 159  | total loss: [1m[32m0.07890[0m[0m | time: 39.186s
[2K
| Adam | epoch: 023 | loss: 0.07890 - acc: 0.9801 -- iter: 160/222
[A[ATraining Step: 160  | total loss: [1m[32m0.07361[0m[0m | time: 46.795s
[2K
| Adam | epoch: 023 | loss: 0.07361 - acc: 0.9821 -- iter: 192/222
[A[ATraining Step: 161  | total loss: [1m[32m0.06872[0m[0m | time: 57.775s
[2K
| Adam | epoch: 023 | loss: 0.06872 - acc: 0.9839 | val_loss: 1.44736 - val_acc: 0.7429 -- iter: 222/222
--
Training Step: 162  | total loss: [1m[32m0.06403[0m[0m | time: 7.979s
[2K
| Adam | epoch: 024 | loss: 0.06403 - acc: 0.9855 -- iter: 032/222
[A[ATraining Step: 163  | total loss: [1m[32m0.06570[0m[0m | time: 15.963s
[2K
| Adam | epoch: 024 | loss: 0.06570 - acc: 0.9838 -- iter: 064/222
[A[ATraining Step: 164  | total loss: [1m[32m0.06047[0m[0m | time: 23.831s
[2K
| Adam | epoch: 024 | loss: 0.06047 - acc: 0.9854 -- iter: 096/222
[A[ATraining Step: 165  | total loss: [1m[32m0.05581[0m[0m | time: 31.871s
[2K
| Adam | epoch: 024 | loss: 0.05581 - acc: 0.9869 -- iter: 128/222
[A[ATraining Step: 166  | total loss: [1m[32m0.05140[0m[0m | time: 39.670s
[2K
| Adam | epoch: 024 | loss: 0.05140 - acc: 0.9882 -- iter: 160/222
[A[ATraining Step: 167  | total loss: [1m[32m0.05250[0m[0m | time: 47.160s
[2K
| Adam | epoch: 024 | loss: 0.05250 - acc: 0.9862 -- iter: 192/222
[A[ATraining Step: 168  | total loss: [1m[32m0.06419[0m[0m | time: 57.812s
[2K
| Adam | epoch: 024 | loss: 0.06419 - acc: 0.9843 | val_loss: 1.31797 - val_acc: 0.6714 -- iter: 222/222
--
Training Step: 169  | total loss: [1m[32m0.05927[0m[0m | time: 7.848s
[2K
| Adam | epoch: 025 | loss: 0.05927 - acc: 0.9859 -- iter: 032/222
[A[ATraining Step: 170  | total loss: [1m[32m0.05559[0m[0m | time: 15.775s
[2K
| Adam | epoch: 025 | loss: 0.05559 - acc: 0.9873 -- iter: 064/222
[A[ATraining Step: 171  | total loss: [1m[32m0.05095[0m[0m | time: 23.547s
[2K
| Adam | epoch: 025 | loss: 0.05095 - acc: 0.9885 -- iter: 096/222
[A[ATraining Step: 172  | total loss: [1m[32m0.04795[0m[0m | time: 31.579s
[2K
| Adam | epoch: 025 | loss: 0.04795 - acc: 0.9897 -- iter: 128/222
[A[ATraining Step: 173  | total loss: [1m[32m0.04385[0m[0m | time: 39.550s
[2K
| Adam | epoch: 025 | loss: 0.04385 - acc: 0.9907 -- iter: 160/222
[A[ATraining Step: 174  | total loss: [1m[32m0.05162[0m[0m | time: 47.582s
[2K
| Adam | epoch: 025 | loss: 0.05162 - acc: 0.9885 -- iter: 192/222
[A[ATraining Step: 175  | total loss: [1m[32m0.04807[0m[0m | time: 58.249s
[2K
| Adam | epoch: 025 | loss: 0.04807 - acc: 0.9897 | val_loss: 0.76627 - val_acc: 0.7714 -- iter: 222/222
--
Training Step: 176  | total loss: [1m[32m0.09438[0m[0m | time: 7.479s
[2K
| Adam | epoch: 026 | loss: 0.09438 - acc: 0.9840 -- iter: 032/222
[A[ATraining Step: 177  | total loss: [1m[32m0.08664[0m[0m | time: 15.508s
[2K
| Adam | epoch: 026 | loss: 0.08664 - acc: 0.9856 -- iter: 064/222
[A[ATraining Step: 178  | total loss: [1m[32m0.07851[0m[0m | time: 23.370s
[2K
| Adam | epoch: 026 | loss: 0.07851 - acc: 0.9871 -- iter: 096/222
[A[ATraining Step: 179  | total loss: [1m[32m0.07122[0m[0m | time: 31.266s
[2K
| Adam | epoch: 026 | loss: 0.07122 - acc: 0.9884 -- iter: 128/222
[A[ATraining Step: 180  | total loss: [1m[32m0.06798[0m[0m | time: 39.293s
[2K
| Adam | epoch: 026 | loss: 0.06798 - acc: 0.9864 -- iter: 160/222
[A[ATraining Step: 181  | total loss: [1m[32m0.06274[0m[0m | time: 47.217s
[2K
| Adam | epoch: 026 | loss: 0.06274 - acc: 0.9878 -- iter: 192/222
[A[ATraining Step: 182  | total loss: [1m[32m0.05922[0m[0m | time: 58.245s
[2K
| Adam | epoch: 026 | loss: 0.05922 - acc: 0.9890 | val_loss: 0.29009 - val_acc: 0.9000 -- iter: 222/222
--
Training Step: 183  | total loss: [1m[32m0.06642[0m[0m | time: 7.544s
[2K
| Adam | epoch: 027 | loss: 0.06642 - acc: 0.9838 -- iter: 032/222
[A[ATraining Step: 184  | total loss: [1m[32m0.06155[0m[0m | time: 15.153s
[2K
| Adam | epoch: 027 | loss: 0.06155 - acc: 0.9855 -- iter: 064/222
[A[ATraining Step: 185  | total loss: [1m[32m0.05612[0m[0m | time: 23.240s
[2K
| Adam | epoch: 027 | loss: 0.05612 - acc: 0.9869 -- iter: 096/222
[A[ATraining Step: 186  | total loss: [1m[32m0.05085[0m[0m | time: 31.270s
[2K
| Adam | epoch: 027 | loss: 0.05085 - acc: 0.9882 -- iter: 128/222
[A[ATraining Step: 187  | total loss: [1m[32m0.04620[0m[0m | time: 39.099s
[2K
| Adam | epoch: 027 | loss: 0.04620 - acc: 0.9894 -- iter: 160/222
[A[ATraining Step: 188  | total loss: [1m[32m0.04210[0m[0m | time: 47.038s
[2K
| Adam | epoch: 027 | loss: 0.04210 - acc: 0.9905 -- iter: 192/222
[A[ATraining Step: 189  | total loss: [1m[32m0.03877[0m[0m | time: 58.067s
[2K
| Adam | epoch: 027 | loss: 0.03877 - acc: 0.9914 | val_loss: 0.21854 - val_acc: 0.9143 -- iter: 222/222
--
Training Step: 190  | total loss: [1m[32m0.03907[0m[0m | time: 8.163s
[2K
| Adam | epoch: 028 | loss: 0.03907 - acc: 0.9891 -- iter: 032/222
[A[ATraining Step: 191  | total loss: [1m[32m0.03881[0m[0m | time: 15.684s
[2K
| Adam | epoch: 028 | loss: 0.03881 - acc: 0.9871 -- iter: 064/222
[A[ATraining Step: 192  | total loss: [1m[32m0.03713[0m[0m | time: 23.242s
[2K
| Adam | epoch: 028 | loss: 0.03713 - acc: 0.9884 -- iter: 096/222
[A[ATraining Step: 193  | total loss: [1m[32m0.03449[0m[0m | time: 31.181s
[2K
| Adam | epoch: 028 | loss: 0.03449 - acc: 0.9896 -- iter: 128/222
[A[ATraining Step: 194  | total loss: [1m[32m0.03161[0m[0m | time: 39.151s
[2K
| Adam | epoch: 028 | loss: 0.03161 - acc: 0.9906 -- iter: 160/222
[A[ATraining Step: 195  | total loss: [1m[32m0.02920[0m[0m | time: 47.120s
[2K
| Adam | epoch: 028 | loss: 0.02920 - acc: 0.9915 -- iter: 192/222
[A[ATraining Step: 196  | total loss: [1m[32m0.02715[0m[0m | time: 58.306s
[2K
| Adam | epoch: 028 | loss: 0.02715 - acc: 0.9924 | val_loss: 0.23969 - val_acc: 0.9143 -- iter: 222/222
--
Training Step: 197  | total loss: [1m[32m0.02728[0m[0m | time: 7.899s
[2K
| Adam | epoch: 029 | loss: 0.02728 - acc: 0.9900 -- iter: 032/222
[A[ATraining Step: 198  | total loss: [1m[32m0.03292[0m[0m | time: 15.727s
[2K
| Adam | epoch: 029 | loss: 0.03292 - acc: 0.9879 -- iter: 064/222
[A[ATraining Step: 199  | total loss: [1m[32m0.03017[0m[0m | time: 23.328s
[2K
| Adam | epoch: 029 | loss: 0.03017 - acc: 0.9891 -- iter: 096/222
[A[ATraining Step: 200  | total loss: [1m[32m0.04228[0m[0m | time: 34.205s
[2K
| Adam | epoch: 029 | loss: 0.04228 - acc: 0.9869 | val_loss: 0.37281 - val_acc: 0.8714 -- iter: 128/222
--
Training Step: 201  | total loss: [1m[32m0.04704[0m[0m | time: 41.901s
[2K
| Adam | epoch: 029 | loss: 0.04704 - acc: 0.9848 -- iter: 160/222
[A[ATraining Step: 202  | total loss: [1m[32m0.04275[0m[0m | time: 49.821s
[2K
| Adam | epoch: 029 | loss: 0.04275 - acc: 0.9864 -- iter: 192/222
[A[ATraining Step: 203  | total loss: [1m[32m0.03999[0m[0m | time: 60.637s
[2K
| Adam | epoch: 029 | loss: 0.03999 - acc: 0.9877 | val_loss: 0.26716 - val_acc: 0.8714 -- iter: 222/222
--
Training Step: 204  | total loss: [1m[32m0.03803[0m[0m | time: 7.850s
[2K
| Adam | epoch: 030 | loss: 0.03803 - acc: 0.9889 -- iter: 032/222
[A[ATraining Step: 205  | total loss: [1m[32m0.03558[0m[0m | time: 15.810s
[2K
| Adam | epoch: 030 | loss: 0.03558 - acc: 0.9901 -- iter: 064/222
[A[ATraining Step: 206  | total loss: [1m[32m0.03340[0m[0m | time: 23.682s
[2K
| Adam | epoch: 030 | loss: 0.03340 - acc: 0.9910 -- iter: 096/222
[A[ATraining Step: 207  | total loss: [1m[32m0.03201[0m[0m | time: 31.132s
[2K
| Adam | epoch: 030 | loss: 0.03201 - acc: 0.9919 -- iter: 128/222
[A[ATraining Step: 208  | total loss: [1m[32m0.07150[0m[0m | time: 38.814s
[2K
| Adam | epoch: 030 | loss: 0.07150 - acc: 0.9861 -- iter: 160/222
[A[ATraining Step: 209  | total loss: [1m[32m0.06477[0m[0m | time: 46.546s
[2K
| Adam | epoch: 030 | loss: 0.06477 - acc: 0.9875 -- iter: 192/222
[A[ATraining Step: 210  | total loss: [1m[32m0.05885[0m[0m | time: 57.554s
[2K
| Adam | epoch: 030 | loss: 0.05885 - acc: 0.9887 | val_loss: 0.30154 - val_acc: 0.8857 -- iter: 222/222
--
Validation AUC:0.9697712418300654
Validation AUPRC:0.9759806984716165
Test AUC:0.95616211745244
Test AUPRC:0.9358713923176044
BestTestF1Score	0.89	0.8	0.9	0.88	0.9	28	4	35	3	0.23
BestTestMCCScore	0.89	0.8	0.9	0.88	0.9	28	4	35	3	0.23
BestTestAccuracyScore	0.89	0.8	0.9	0.88	0.9	28	4	35	3	0.23
BestValidationF1Score	0.91	0.83	0.91	0.94	0.89	32	2	32	4	0.23
BestValidationMCC	0.91	0.83	0.91	0.94	0.89	32	2	32	4	0.23
BestValidationAccuracy	0.91	0.83	0.91	0.94	0.89	32	2	32	4	0.23
TestPredictions (Threshold:0.23)
CHEMBL2322893,TN,INACT,0.0	CHEMBL2114229,TN,INACT,0.09000000357627869	CHEMBL1929543,TP,ACT,0.9700000286102295	CHEMBL3403340,TN,INACT,0.009999999776482582	CHEMBL1929540,TP,ACT,1.0	CHEMBL417171,TN,INACT,0.029999999329447746	CHEMBL415879,TN,INACT,0.0	CHEMBL39879,TN,INACT,0.0	CHEMBL45418,TN,INACT,0.0	CHEMBL64187,TP,ACT,0.9900000095367432	CHEMBL49932,TN,INACT,0.0	CHEMBL121289,TN,INACT,0.05000000074505806	CHEMBL1094419,TP,ACT,1.0	CHEMBL1929528,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.0	CHEMBL280223,TN,INACT,0.019999999552965164	CHEMBL2398752,TN,INACT,0.009999999776482582	CHEMBL64557,TP,ACT,1.0	CHEMBL1929526,TP,ACT,1.0	CHEMBL1916700,TN,INACT,0.009999999776482582	CHEMBL365908,TP,ACT,1.0	CHEMBL42586,FP,INACT,0.3799999952316284	CHEMBL223744,TN,INACT,0.0	CHEMBL589973,TN,INACT,0.009999999776482582	CHEMBL2331806,TN,INACT,0.0	CHEMBL1094157,TP,ACT,1.0	CHEMBL297335,TN,INACT,0.1599999964237213	CHEMBL1929551,TP,ACT,0.9700000286102295	CHEMBL439934,TP,ACT,1.0	CHEMBL117036,TN,INACT,0.0	CHEMBL420359,TN,INACT,0.009999999776482582	CHEMBL62888,TP,ACT,0.9900000095367432	CHEMBL484778,TN,INACT,0.11999999731779099	CHEMBL596745,TP,ACT,1.0	CHEMBL10404,TN,INACT,0.0	CHEMBL1094470,FN,ACT,0.14000000059604645	CHEMBL482018,TN,INACT,0.0	CHEMBL1929530,TP,ACT,0.949999988079071	CHEMBL293697,FN,ACT,0.03999999910593033	CHEMBL54125,TN,INACT,0.0	CHEMBL314616,TN,INACT,0.14000000059604645	CHEMBL548,TP,ACT,0.7900000214576721	CHEMBL1957434,TP,ACT,0.7599999904632568	CHEMBL2037291,TP,ACT,0.36000001430511475	CHEMBL2397389,TN,INACT,0.0	CHEMBL382197,FP,INACT,0.6399999856948853	CHEMBL1092431,TP,ACT,0.8299999833106995	CHEMBL1095065,TP,ACT,0.8299999833106995	CHEMBL2036312,TP,ACT,1.0	CHEMBL2036315,TP,ACT,0.9900000095367432	CHEMBL1929549,TP,ACT,0.9599999785423279	CHEMBL1933726,TP,ACT,0.6700000166893005	CHEMBL361812,TN,INACT,0.009999999776482582	CHEMBL3403335,TN,INACT,0.0	CHEMBL42129,FP,INACT,1.0	CHEMBL64188,TP,ACT,0.9900000095367432	CHEMBL245319,TN,INACT,0.009999999776482582	CHEMBL3403339,TN,INACT,0.029999999329447746	CHEMBL220820,TN,INACT,0.10999999940395355	CHEMBL1957431,FN,ACT,0.07999999821186066	CHEMBL595159,TP,ACT,0.9399999976158142	CHEMBL1088284,TN,INACT,0.0	CHEMBL1813276,TP,ACT,0.9599999785423279	CHEMBL327597,TN,INACT,0.20999999344348907	CHEMBL2237151,TN,INACT,0.0	CHEMBL64804,TP,ACT,0.6800000071525574	CHEMBL1237297,FP,INACT,0.4099999964237213	CHEMBL293647,TP,ACT,0.4000000059604645	CHEMBL118619,TN,INACT,0.07999999821186066	CHEMBL302447,TN,INACT,0.0	

