ImageNetInceptionV2 CHEMBL3272 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	127
Number of inactive compounds :	127
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3272_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3272_adam_0.0005_15_0.8/
---------------------------------
Training samples: 162
Validation samples: 51
--
Training Step: 1  | time: 150.584s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/162
[A[ATraining Step: 2  | total loss: [1m[32m0.67456[0m[0m | time: 270.275s
[2K
| Adam | epoch: 001 | loss: 0.67456 - acc: 0.3094 -- iter: 064/162
[A[ATraining Step: 3  | total loss: [1m[32m1.06633[0m[0m | time: 562.127s
[2K
| Adam | epoch: 001 | loss: 1.06633 - acc: 0.5165 -- iter: 096/162
[A[ATraining Step: 4  | total loss: [1m[32m1.05245[0m[0m | time: 742.162s
[2K
| Adam | epoch: 001 | loss: 1.05245 - acc: 0.5510 -- iter: 128/162
[A[ATraining Step: 5  | total loss: [1m[32m0.81760[0m[0m | time: 1040.175s
[2K
| Adam | epoch: 001 | loss: 0.81760 - acc: 0.5806 -- iter: 160/162
[A[ATraining Step: 6  | total loss: [1m[32m0.67854[0m[0m | time: 1055.638s
[2K
| Adam | epoch: 001 | loss: 0.67854 - acc: 0.6493 | val_loss: 0.73780 - val_acc: 0.5686 -- iter: 162/162
--
Training Step: 7  | total loss: [1m[32m0.62964[0m[0m | time: 10.584s
[2K
| Adam | epoch: 002 | loss: 0.62964 - acc: 0.8597 -- iter: 032/162
[A[ATraining Step: 8  | total loss: [1m[32m0.30747[0m[0m | time: 341.320s
[2K
| Adam | epoch: 002 | loss: 0.30747 - acc: 0.9386 -- iter: 064/162
[A[ATraining Step: 9  | total loss: [1m[32m0.45980[0m[0m | time: 561.363s
[2K
| Adam | epoch: 002 | loss: 0.45980 - acc: 0.8057 -- iter: 096/162
[A[ATraining Step: 10  | total loss: [1m[32m0.54142[0m[0m | time: 692.174s
[2K
| Adam | epoch: 002 | loss: 0.54142 - acc: 0.7310 -- iter: 128/162
[A[ATraining Step: 11  | total loss: [1m[32m0.44470[0m[0m | time: 983.904s
[2K
| Adam | epoch: 002 | loss: 0.44470 - acc: 0.7992 -- iter: 160/162
[A[ATraining Step: 12  | total loss: [1m[32m0.41428[0m[0m | time: 1155.753s
[2K
| Adam | epoch: 002 | loss: 0.41428 - acc: 0.8474 | val_loss: 0.88081 - val_acc: 0.5686 -- iter: 162/162
--
Training Step: 13  | total loss: [1m[32m0.37852[0m[0m | time: 2.973s
[2K
| Adam | epoch: 003 | loss: 0.37852 - acc: 0.8592 -- iter: 032/162
[A[ATraining Step: 14  | total loss: [1m[32m0.44717[0m[0m | time: 5.637s
[2K
| Adam | epoch: 003 | loss: 0.44717 - acc: 0.9168 -- iter: 064/162
[A[ATraining Step: 15  | total loss: [1m[32m0.50239[0m[0m | time: 88.759s
[2K
| Adam | epoch: 003 | loss: 0.50239 - acc: 0.7537 -- iter: 096/162
[A[ATraining Step: 16  | total loss: [1m[32m0.49647[0m[0m | time: 413.952s
[2K
| Adam | epoch: 003 | loss: 0.49647 - acc: 0.7640 -- iter: 128/162
[A[ATraining Step: 17  | total loss: [1m[32m0.71326[0m[0m | time: 435.751s
[2K
| Adam | epoch: 003 | loss: 0.71326 - acc: 0.7140 -- iter: 160/162
[A[ATraining Step: 18  | total loss: [1m[32m0.51548[0m[0m | time: 504.547s
[2K
| Adam | epoch: 003 | loss: 0.51548 - acc: 0.8130 | val_loss: 0.95335 - val_acc: 0.5686 -- iter: 162/162
--
Training Step: 19  | total loss: [1m[32m0.49288[0m[0m | time: 34.268s
[2K
| Adam | epoch: 004 | loss: 0.49288 - acc: 0.8128 -- iter: 032/162
[A[ATraining Step: 20  | total loss: [1m[32m0.46091[0m[0m | time: 37.239s
[2K
| Adam | epoch: 004 | loss: 0.46091 - acc: 0.8228 -- iter: 064/162
[A[ATraining Step: 21  | total loss: [1m[32m0.32518[0m[0m | time: 39.983s
[2K
| Adam | epoch: 004 | loss: 0.32518 - acc: 0.8778 -- iter: 096/162
[A[ATraining Step: 22  | total loss: [1m[32m0.23127[0m[0m | time: 136.441s
[2K
| Adam | epoch: 004 | loss: 0.23127 - acc: 0.9144 -- iter: 128/162
[A[ATraining Step: 23  | total loss: [1m[32m0.37192[0m[0m | time: 160.035s
[2K
| Adam | epoch: 004 | loss: 0.37192 - acc: 0.8486 -- iter: 160/162
[A[ATraining Step: 24  | total loss: [1m[32m0.36720[0m[0m | time: 184.217s
[2K
| Adam | epoch: 004 | loss: 0.36720 - acc: 0.8560 | val_loss: 1.06626 - val_acc: 0.5686 -- iter: 162/162
--
Training Step: 25  | total loss: [1m[32m0.30324[0m[0m | time: 23.568s
[2K
| Adam | epoch: 005 | loss: 0.30324 - acc: 0.8867 -- iter: 032/162
[A[ATraining Step: 26  | total loss: [1m[32m0.26888[0m[0m | time: 210.641s
[2K
| Adam | epoch: 005 | loss: 0.26888 - acc: 0.9085 -- iter: 064/162
[A[ATraining Step: 27  | total loss: [1m[32m0.29571[0m[0m | time: 213.379s
[2K
| Adam | epoch: 005 | loss: 0.29571 - acc: 0.8918 -- iter: 096/162
[A[ATraining Step: 28  | total loss: [1m[32m0.36174[0m[0m | time: 216.224s
[2K
| Adam | epoch: 005 | loss: 0.36174 - acc: 0.7939 -- iter: 128/162
[A[ATraining Step: 29  | total loss: [1m[32m0.39116[0m[0m | time: 244.217s
[2K
| Adam | epoch: 005 | loss: 0.39116 - acc: 0.7224 -- iter: 160/162
[A[ATraining Step: 30  | total loss: [1m[32m0.39271[0m[0m | time: 280.964s
[2K
| Adam | epoch: 005 | loss: 0.39271 - acc: 0.7511 | val_loss: 1.63275 - val_acc: 0.5686 -- iter: 162/162
--
Training Step: 31  | total loss: [1m[32m0.37225[0m[0m | time: 34.429s
[2K
| Adam | epoch: 006 | loss: 0.37225 - acc: 0.7797 -- iter: 032/162
[A[ATraining Step: 32  | total loss: [1m[32m0.30406[0m[0m | time: 51.738s
[2K
| Adam | epoch: 006 | loss: 0.30406 - acc: 0.8293 -- iter: 064/162
[A[ATraining Step: 33  | total loss: [1m[32m0.32707[0m[0m | time: 90.754s
[2K
| Adam | epoch: 006 | loss: 0.32707 - acc: 0.8050 -- iter: 096/162
[A[ATraining Step: 34  | total loss: [1m[32m0.28104[0m[0m | time: 93.407s
[2K
| Adam | epoch: 006 | loss: 0.28104 - acc: 0.8468 -- iter: 128/162
[A[ATraining Step: 35  | total loss: [1m[32m0.24145[0m[0m | time: 96.351s
[2K
| Adam | epoch: 006 | loss: 0.24145 - acc: 0.8789 -- iter: 160/162
[A[ATraining Step: 36  | total loss: [1m[32m0.19796[0m[0m | time: 128.471s
[2K
| Adam | epoch: 006 | loss: 0.19796 - acc: 0.9036 | val_loss: 0.80597 - val_acc: 0.5098 -- iter: 162/162
--
Training Step: 37  | total loss: [1m[32m0.17595[0m[0m | time: 36.704s
[2K
| Adam | epoch: 007 | loss: 0.17595 - acc: 0.9167 -- iter: 032/162
[A[ATraining Step: 38  | total loss: [1m[32m0.52878[0m[0m | time: 55.381s
[2K
| Adam | epoch: 007 | loss: 0.52878 - acc: 0.8596 -- iter: 064/162
[A[ATraining Step: 39  | total loss: [1m[32m0.44012[0m[0m | time: 77.870s
[2K
| Adam | epoch: 007 | loss: 0.44012 - acc: 0.8865 -- iter: 096/162
[A[ATraining Step: 40  | total loss: [1m[32m0.37599[0m[0m | time: 245.276s
[2K
| Adam | epoch: 007 | loss: 0.37599 - acc: 0.9019 -- iter: 128/162
[A[ATraining Step: 41  | total loss: [1m[32m0.31295[0m[0m | time: 247.228s
[2K
| Adam | epoch: 007 | loss: 0.31295 - acc: 0.9199 -- iter: 160/162
[A[ATraining Step: 42  | total loss: [1m[32m0.26225[0m[0m | time: 252.772s
[2K
| Adam | epoch: 007 | loss: 0.26225 - acc: 0.9343 | val_loss: 1.12384 - val_acc: 0.2941 -- iter: 162/162
--
Training Step: 43  | total loss: [1m[32m0.21803[0m[0m | time: 36.006s
[2K
| Adam | epoch: 008 | loss: 0.21803 - acc: 0.9459 -- iter: 032/162
[A[ATraining Step: 44  | total loss: [1m[32m0.19377[0m[0m | time: 133.724s
[2K
| Adam | epoch: 008 | loss: 0.19377 - acc: 0.9553 -- iter: 064/162
[A[ATraining Step: 45  | total loss: [1m[32m0.16688[0m[0m | time: 165.748s
[2K
| Adam | epoch: 008 | loss: 0.16688 - acc: 0.9629 -- iter: 096/162
[A[ATraining Step: 46  | total loss: [1m[32m0.14584[0m[0m | time: 193.213s
[2K
| Adam | epoch: 008 | loss: 0.14584 - acc: 0.9691 -- iter: 128/162
[A[ATraining Step: 47  | total loss: [1m[32m0.13389[0m[0m | time: 246.024s
[2K
| Adam | epoch: 008 | loss: 0.13389 - acc: 0.9690 -- iter: 160/162
[A[ATraining Step: 48  | total loss: [1m[32m0.11793[0m[0m | time: 251.455s
[2K
| Adam | epoch: 008 | loss: 0.11793 - acc: 0.9740 | val_loss: 1.84640 - val_acc: 0.4118 -- iter: 162/162
--
Training Step: 49  | total loss: [1m[32m0.28432[0m[0m | time: 2.616s
[2K
| Adam | epoch: 009 | loss: 0.28432 - acc: 0.8992 -- iter: 032/162
[A[ATraining Step: 50  | total loss: [1m[32m0.57346[0m[0m | time: 20.088s
[2K
| Adam | epoch: 009 | loss: 0.57346 - acc: 0.8372 -- iter: 064/162
[A[ATraining Step: 51  | total loss: [1m[32m0.49171[0m[0m | time: 42.461s
[2K
| Adam | epoch: 009 | loss: 0.49171 - acc: 0.8620 -- iter: 096/162
[A[ATraining Step: 52  | total loss: [1m[32m0.46795[0m[0m | time: 61.474s
[2K
| Adam | epoch: 009 | loss: 0.46795 - acc: 0.8687 -- iter: 128/162
[A[ATraining Step: 53  | total loss: [1m[32m0.40595[0m[0m | time: 78.450s
[2K
| Adam | epoch: 009 | loss: 0.40595 - acc: 0.8881 -- iter: 160/162
[A[ATraining Step: 54  | total loss: [1m[32m0.37857[0m[0m | time: 100.923s
[2K
| Adam | epoch: 009 | loss: 0.37857 - acc: 0.8907 | val_loss: 1.27950 - val_acc: 0.5294 -- iter: 162/162
--
Training Step: 55  | total loss: [1m[32m0.32978[0m[0m | time: 2.453s
[2K
| Adam | epoch: 010 | loss: 0.32978 - acc: 0.9063 -- iter: 032/162
[A[ATraining Step: 56  | total loss: [1m[32m0.28435[0m[0m | time: 5.060s
[2K
| Adam | epoch: 010 | loss: 0.28435 - acc: 0.9195 -- iter: 064/162
[A[ATraining Step: 57  | total loss: [1m[32m0.24589[0m[0m | time: 51.786s
[2K
| Adam | epoch: 010 | loss: 0.24589 - acc: 0.9306 -- iter: 096/162
[A[ATraining Step: 58  | total loss: [1m[32m0.23857[0m[0m | time: 64.408s
[2K
| Adam | epoch: 010 | loss: 0.23857 - acc: 0.9273 -- iter: 128/162
[A[ATraining Step: 59  | total loss: [1m[32m0.21802[0m[0m | time: 89.724s
[2K
| Adam | epoch: 010 | loss: 0.21802 - acc: 0.9329 -- iter: 160/162
[A[ATraining Step: 60  | total loss: [1m[32m0.19193[0m[0m | time: 125.454s
[2K
| Adam | epoch: 010 | loss: 0.19193 - acc: 0.9418 | val_loss: 0.70069 - val_acc: 0.7843 -- iter: 162/162
--
Training Step: 61  | total loss: [1m[32m0.18165[0m[0m | time: 17.747s
[2K
| Adam | epoch: 011 | loss: 0.18165 - acc: 0.9453 -- iter: 032/162
[A[ATraining Step: 62  | total loss: [1m[32m0.16200[0m[0m | time: 20.818s
[2K
| Adam | epoch: 011 | loss: 0.16200 - acc: 0.9523 -- iter: 064/162
[A[ATraining Step: 63  | total loss: [1m[32m0.23232[0m[0m | time: 23.196s
[2K
| Adam | epoch: 011 | loss: 0.23232 - acc: 0.8950 -- iter: 096/162
[A[ATraining Step: 64  | total loss: [1m[32m0.31430[0m[0m | time: 40.634s
[2K
| Adam | epoch: 011 | loss: 0.31430 - acc: 0.8456 -- iter: 128/162
[A[ATraining Step: 65  | total loss: [1m[32m0.29570[0m[0m | time: 54.190s
[2K
| Adam | epoch: 011 | loss: 0.29570 - acc: 0.8531 -- iter: 160/162
[A[ATraining Step: 66  | total loss: [1m[32m0.30149[0m[0m | time: 75.925s
[2K
| Adam | epoch: 011 | loss: 0.30149 - acc: 0.8595 | val_loss: 1.41009 - val_acc: 0.6275 -- iter: 162/162
--
Training Step: 67  | total loss: [1m[32m0.30122[0m[0m | time: 27.116s
[2K
| Adam | epoch: 012 | loss: 0.30122 - acc: 0.8539 -- iter: 032/162
[A[ATraining Step: 68  | total loss: [1m[32m0.27193[0m[0m | time: 86.755s
[2K
| Adam | epoch: 012 | loss: 0.27193 - acc: 0.8712 -- iter: 064/162
[A[ATraining Step: 69  | total loss: [1m[32m0.24618[0m[0m | time: 89.660s
[2K
| Adam | epoch: 012 | loss: 0.24618 - acc: 0.8863 -- iter: 096/162
[A[ATraining Step: 70  | total loss: [1m[32m0.22151[0m[0m | time: 92.113s
[2K
| Adam | epoch: 012 | loss: 0.22151 - acc: 0.8994 -- iter: 128/162
[A[ATraining Step: 71  | total loss: [1m[32m0.19758[0m[0m | time: 108.588s
[2K
| Adam | epoch: 012 | loss: 0.19758 - acc: 0.9108 -- iter: 160/162
[A[ATraining Step: 72  | total loss: [1m[32m0.17865[0m[0m | time: 134.397s
[2K
| Adam | epoch: 012 | loss: 0.17865 - acc: 0.9209 | val_loss: 0.87844 - val_acc: 0.7647 -- iter: 162/162
--
Training Step: 73  | total loss: [1m[32m0.23620[0m[0m | time: 18.996s
[2K
| Adam | epoch: 013 | loss: 0.23620 - acc: 0.9088 -- iter: 032/162
[A[ATraining Step: 74  | total loss: [1m[32m0.21544[0m[0m | time: 36.985s
[2K
| Adam | epoch: 013 | loss: 0.21544 - acc: 0.9188 -- iter: 064/162
[A[ATraining Step: 75  | total loss: [1m[32m0.20579[0m[0m | time: 45.805s
[2K
| Adam | epoch: 013 | loss: 0.20579 - acc: 0.9243 -- iter: 096/162
[A[ATraining Step: 76  | total loss: [1m[32m0.20443[0m[0m | time: 47.045s
[2K
| Adam | epoch: 013 | loss: 0.20443 - acc: 0.9257 -- iter: 128/162
[A[ATraining Step: 77  | total loss: [1m[32m0.18366[0m[0m | time: 48.235s
[2K
| Adam | epoch: 013 | loss: 0.18366 - acc: 0.9335 -- iter: 160/162
[A[ATraining Step: 78  | total loss: [1m[32m0.16529[0m[0m | time: 66.176s
[2K
| Adam | epoch: 013 | loss: 0.16529 - acc: 0.9405 | val_loss: 1.89491 - val_acc: 0.5098 -- iter: 162/162
--
Training Step: 79  | total loss: [1m[32m0.15755[0m[0m | time: 18.773s
[2K
| Adam | epoch: 014 | loss: 0.15755 - acc: 0.9434 -- iter: 032/162
[A[ATraining Step: 80  | total loss: [1m[32m0.15998[0m[0m | time: 36.685s
[2K
| Adam | epoch: 014 | loss: 0.15998 - acc: 0.9396 -- iter: 064/162
[A[ATraining Step: 81  | total loss: [1m[32m0.15448[0m[0m | time: 94.804s
[2K
| Adam | epoch: 014 | loss: 0.15448 - acc: 0.9426 -- iter: 096/162
[A[ATraining Step: 82  | total loss: [1m[32m0.14307[0m[0m | time: 128.751s
[2K
| Adam | epoch: 014 | loss: 0.14307 - acc: 0.9483 -- iter: 128/162
[A[ATraining Step: 83  | total loss: [1m[32m0.13259[0m[0m | time: 131.590s
[2K
| Adam | epoch: 014 | loss: 0.13259 - acc: 0.9535 -- iter: 160/162
[A[ATraining Step: 84  | total loss: [1m[32m0.11946[0m[0m | time: 139.608s
[2K
| Adam | epoch: 014 | loss: 0.11946 - acc: 0.9581 | val_loss: 1.39866 - val_acc: 0.5882 -- iter: 162/162
--
Training Step: 85  | total loss: [1m[32m0.10766[0m[0m | time: 21.504s
[2K
| Adam | epoch: 015 | loss: 0.10766 - acc: 0.9623 -- iter: 032/162
[A[ATraining Step: 86  | total loss: [1m[32m0.10879[0m[0m | time: 48.276s
[2K
| Adam | epoch: 015 | loss: 0.10879 - acc: 0.9630 -- iter: 064/162
[A[ATraining Step: 87  | total loss: [1m[32m0.16550[0m[0m | time: 72.287s
[2K
| Adam | epoch: 015 | loss: 0.16550 - acc: 0.9573 -- iter: 096/162
[A[ATraining Step: 88  | total loss: [1m[32m0.15115[0m[0m | time: 90.547s
[2K
| Adam | epoch: 015 | loss: 0.15115 - acc: 0.9616 -- iter: 128/162
[A[ATraining Step: 89  | total loss: [1m[32m0.13816[0m[0m | time: 108.837s
[2K
| Adam | epoch: 015 | loss: 0.13816 - acc: 0.9654 -- iter: 160/162
[A[ATraining Step: 90  | total loss: [1m[32m0.12724[0m[0m | time: 114.666s
[2K
| Adam | epoch: 015 | loss: 0.12724 - acc: 0.9689 | val_loss: 0.67040 - val_acc: 0.8235 -- iter: 162/162
--
Validation AUC:0.8495297805642633
Validation AUPRC:0.8814791229000555
Test AUC:0.8664596273291926
Test AUPRC:0.8841964591857637
BestTestF1Score	0.82	0.65	0.82	0.77	0.87	20	6	22	3	0.63
BestTestMCCScore	0.78	0.6	0.8	0.78	0.78	18	5	23	5	0.75
BestTestAccuracyScore	0.78	0.6	0.8	0.78	0.78	18	5	23	5	0.75
BestValidationF1Score	0.87	0.68	0.84	0.84	0.9	26	5	17	3	0.63
BestValidationMCC	0.86	0.68	0.84	0.86	0.86	25	4	18	4	0.75
BestValidationAccuracy	0.86	0.68	0.84	0.86	0.86	25	4	18	4	0.75
TestPredictions (Threshold:0.75)
CHEMBL200569,TN,INACT,0.0	CHEMBL2437294,TN,INACT,0.019999999552965164	CHEMBL210523,TN,INACT,0.4000000059604645	CHEMBL1668601,TP,ACT,0.9100000262260437	CHEMBL3093947,FP,INACT,0.9700000286102295	CHEMBL3648414,TP,ACT,0.9599999785423279	CHEMBL218394,FN,ACT,0.3100000023841858	CHEMBL599872,TN,INACT,0.0	CHEMBL3661025,TN,INACT,0.6299999952316284	CHEMBL199358,TN,INACT,0.3799999952316284	CHEMBL2042457,TP,ACT,1.0	CHEMBL567134,FP,INACT,0.9800000190734863	CHEMBL193582,TP,ACT,0.9900000095367432	CHEMBL559238,TP,ACT,1.0	CHEMBL3142936,TN,INACT,0.0	CHEMBL1289305,TP,ACT,0.9599999785423279	CHEMBL2042450,TP,ACT,1.0	CHEMBL200166,TN,INACT,0.4099999964237213	CHEMBL188929,FN,ACT,0.30000001192092896	CHEMBL2316612,TN,INACT,0.699999988079071	CHEMBL549378,TP,ACT,1.0	CHEMBL565079,FN,ACT,0.6800000071525574	CHEMBL379772,TN,INACT,0.019999999552965164	CHEMBL2373062,TN,INACT,0.05999999865889549	CHEMBL371064,TN,INACT,0.36000001430511475	CHEMBL401175,FP,INACT,0.9800000190734863	CHEMBL501355,FP,INACT,0.9700000286102295	CHEMBL2042454,TP,ACT,1.0	CHEMBL3354497,TN,INACT,0.4000000059604645	CHEMBL557920,TP,ACT,0.9900000095367432	CHEMBL446669,TN,INACT,0.019999999552965164	CHEMBL3648415,TP,ACT,0.9900000095367432	CHEMBL3314609,TN,INACT,0.029999999329447746	CHEMBL3354494,TN,INACT,0.5899999737739563	CHEMBL1289644,TP,ACT,0.9900000095367432	CHEMBL3142835,TN,INACT,0.05999999865889549	CHEMBL2382005,TN,INACT,0.05000000074505806	CHEMBL75971,TN,INACT,0.5099999904632568	CHEMBL551121,TP,ACT,1.0	CHEMBL200506,TN,INACT,0.6000000238418579	CHEMBL196896,FN,ACT,0.009999999776482582	CHEMBL556421,TP,ACT,1.0	CHEMBL2373044,TN,INACT,0.18000000715255737	CHEMBL549365,TP,ACT,1.0	CHEMBL3648404,TP,ACT,0.9900000095367432	CHEMBL62923,TN,INACT,0.3799999952316284	CHEMBL2373050,TN,INACT,0.07000000029802322	CHEMBL554065,FN,ACT,0.6399999856948853	CHEMBL390643,TP,ACT,1.0	CHEMBL482168,FP,INACT,0.8899999856948853	CHEMBL230478,TP,ACT,0.8700000047683716	

