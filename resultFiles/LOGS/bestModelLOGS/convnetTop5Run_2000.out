ImageNetInceptionV2 CHEMBL3018 adam 0.001 5 0 0 0.8 False True
Number of active compounds :	309
Number of inactive compounds :	309
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3018_adam_0.001_5_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3018_adam_0.001_5_0.8/
---------------------------------
Training samples: 393
Validation samples: 124
--
Training Step: 1  | time: 36.656s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/393
[A[ATraining Step: 2  | total loss: [1m[32m0.73194[0m[0m | time: 44.716s
[2K
| Adam | epoch: 001 | loss: 0.73194 - acc: 0.3937 -- iter: 064/393
[A[ATraining Step: 3  | total loss: [1m[32m0.78199[0m[0m | time: 52.713s
[2K
| Adam | epoch: 001 | loss: 0.78199 - acc: 0.6085 -- iter: 096/393
[A[ATraining Step: 4  | total loss: [1m[32m0.70739[0m[0m | time: 60.718s
[2K
| Adam | epoch: 001 | loss: 0.70739 - acc: 0.5506 -- iter: 128/393
[A[ATraining Step: 5  | total loss: [1m[32m0.69484[0m[0m | time: 68.715s
[2K
| Adam | epoch: 001 | loss: 0.69484 - acc: 0.6454 -- iter: 160/393
[A[ATraining Step: 6  | total loss: [1m[32m0.69904[0m[0m | time: 76.811s
[2K
| Adam | epoch: 001 | loss: 0.69904 - acc: 0.5720 -- iter: 192/393
[A[ATraining Step: 7  | total loss: [1m[32m0.66178[0m[0m | time: 85.001s
[2K
| Adam | epoch: 001 | loss: 0.66178 - acc: 0.6413 -- iter: 224/393
[A[ATraining Step: 8  | total loss: [1m[32m0.70641[0m[0m | time: 93.201s
[2K
| Adam | epoch: 001 | loss: 0.70641 - acc: 0.5091 -- iter: 256/393
[A[ATraining Step: 9  | total loss: [1m[32m0.68615[0m[0m | time: 101.345s
[2K
| Adam | epoch: 001 | loss: 0.68615 - acc: 0.5539 -- iter: 288/393
[A[ATraining Step: 10  | total loss: [1m[32m0.59780[0m[0m | time: 109.384s
[2K
| Adam | epoch: 001 | loss: 0.59780 - acc: 0.6363 -- iter: 320/393
[A[ATraining Step: 11  | total loss: [1m[32m0.52597[0m[0m | time: 117.532s
[2K
| Adam | epoch: 001 | loss: 0.52597 - acc: 0.7198 -- iter: 352/393
[A[ATraining Step: 12  | total loss: [1m[32m0.62965[0m[0m | time: 125.772s
[2K
| Adam | epoch: 001 | loss: 0.62965 - acc: 0.6771 -- iter: 384/393
[A[ATraining Step: 13  | total loss: [1m[32m0.62565[0m[0m | time: 140.020s
[2K
| Adam | epoch: 001 | loss: 0.62565 - acc: 0.6816 | val_loss: 1.32509 - val_acc: 0.4839 -- iter: 393/393
--
Training Step: 14  | total loss: [1m[32m0.62144[0m[0m | time: 2.997s
[2K
| Adam | epoch: 002 | loss: 0.62144 - acc: 0.7209 -- iter: 032/393
[A[ATraining Step: 15  | total loss: [1m[32m0.52802[0m[0m | time: 11.031s
[2K
| Adam | epoch: 002 | loss: 0.52802 - acc: 0.7867 -- iter: 064/393
[A[ATraining Step: 16  | total loss: [1m[32m0.56073[0m[0m | time: 19.148s
[2K
| Adam | epoch: 002 | loss: 0.56073 - acc: 0.7495 -- iter: 096/393
[A[ATraining Step: 17  | total loss: [1m[32m0.67904[0m[0m | time: 27.357s
[2K
| Adam | epoch: 002 | loss: 0.67904 - acc: 0.6259 -- iter: 128/393
[A[ATraining Step: 18  | total loss: [1m[32m0.63963[0m[0m | time: 35.524s
[2K
| Adam | epoch: 002 | loss: 0.63963 - acc: 0.6256 -- iter: 160/393
[A[ATraining Step: 19  | total loss: [1m[32m0.59415[0m[0m | time: 43.966s
[2K
| Adam | epoch: 002 | loss: 0.59415 - acc: 0.6775 -- iter: 192/393
[A[ATraining Step: 20  | total loss: [1m[32m0.55242[0m[0m | time: 52.087s
[2K
| Adam | epoch: 002 | loss: 0.55242 - acc: 0.7108 -- iter: 224/393
[A[ATraining Step: 21  | total loss: [1m[32m0.58706[0m[0m | time: 60.211s
[2K
| Adam | epoch: 002 | loss: 0.58706 - acc: 0.6745 -- iter: 256/393
[A[ATraining Step: 22  | total loss: [1m[32m0.66151[0m[0m | time: 68.325s
[2K
| Adam | epoch: 002 | loss: 0.66151 - acc: 0.6971 -- iter: 288/393
[A[ATraining Step: 23  | total loss: [1m[32m0.71034[0m[0m | time: 76.387s
[2K
| Adam | epoch: 002 | loss: 0.71034 - acc: 0.6943 -- iter: 320/393
[A[ATraining Step: 24  | total loss: [1m[32m0.62140[0m[0m | time: 84.670s
[2K
| Adam | epoch: 002 | loss: 0.62140 - acc: 0.7276 -- iter: 352/393
[A[ATraining Step: 25  | total loss: [1m[32m0.58306[0m[0m | time: 92.794s
[2K
| Adam | epoch: 002 | loss: 0.58306 - acc: 0.7337 -- iter: 384/393
[A[ATraining Step: 26  | total loss: [1m[32m0.60189[0m[0m | time: 106.557s
[2K
| Adam | epoch: 002 | loss: 0.60189 - acc: 0.7049 | val_loss: 1.16006 - val_acc: 0.5161 -- iter: 393/393
--
Training Step: 27  | total loss: [1m[32m0.56932[0m[0m | time: 3.008s
[2K
| Adam | epoch: 003 | loss: 0.56932 - acc: 0.7245 -- iter: 032/393
[A[ATraining Step: 28  | total loss: [1m[32m0.55440[0m[0m | time: 5.983s
[2K
| Adam | epoch: 003 | loss: 0.55440 - acc: 0.7379 -- iter: 064/393
[A[ATraining Step: 29  | total loss: [1m[32m0.49110[0m[0m | time: 14.248s
[2K
| Adam | epoch: 003 | loss: 0.49110 - acc: 0.8016 -- iter: 096/393
[A[ATraining Step: 30  | total loss: [1m[32m0.47340[0m[0m | time: 22.607s
[2K
| Adam | epoch: 003 | loss: 0.47340 - acc: 0.8042 -- iter: 128/393
[A[ATraining Step: 31  | total loss: [1m[32m0.48238[0m[0m | time: 30.941s
[2K
| Adam | epoch: 003 | loss: 0.48238 - acc: 0.7845 -- iter: 160/393
[A[ATraining Step: 32  | total loss: [1m[32m0.46697[0m[0m | time: 39.213s
[2K
| Adam | epoch: 003 | loss: 0.46697 - acc: 0.7908 -- iter: 192/393
[A[ATraining Step: 33  | total loss: [1m[32m0.44890[0m[0m | time: 47.511s
[2K
| Adam | epoch: 003 | loss: 0.44890 - acc: 0.8024 -- iter: 224/393
[A[ATraining Step: 34  | total loss: [1m[32m0.47202[0m[0m | time: 55.848s
[2K
| Adam | epoch: 003 | loss: 0.47202 - acc: 0.7912 -- iter: 256/393
[A[ATraining Step: 35  | total loss: [1m[32m0.45239[0m[0m | time: 64.130s
[2K
| Adam | epoch: 003 | loss: 0.45239 - acc: 0.7760 -- iter: 288/393
[A[ATraining Step: 36  | total loss: [1m[32m0.46691[0m[0m | time: 72.539s
[2K
| Adam | epoch: 003 | loss: 0.46691 - acc: 0.7771 -- iter: 320/393
[A[ATraining Step: 37  | total loss: [1m[32m0.45320[0m[0m | time: 80.840s
[2K
| Adam | epoch: 003 | loss: 0.45320 - acc: 0.7842 -- iter: 352/393
[A[ATraining Step: 38  | total loss: [1m[32m0.46989[0m[0m | time: 89.257s
[2K
| Adam | epoch: 003 | loss: 0.46989 - acc: 0.7775 -- iter: 384/393
[A[ATraining Step: 39  | total loss: [1m[32m0.46412[0m[0m | time: 103.084s
[2K
| Adam | epoch: 003 | loss: 0.46412 - acc: 0.7782 | val_loss: 1.54816 - val_acc: 0.5161 -- iter: 393/393
--
Training Step: 40  | total loss: [1m[32m0.43797[0m[0m | time: 8.340s
[2K
| Adam | epoch: 004 | loss: 0.43797 - acc: 0.7964 -- iter: 032/393
[A[ATraining Step: 41  | total loss: [1m[32m0.41985[0m[0m | time: 11.314s
[2K
| Adam | epoch: 004 | loss: 0.41985 - acc: 0.8051 -- iter: 064/393
[A[ATraining Step: 42  | total loss: [1m[32m0.40168[0m[0m | time: 14.400s
[2K
| Adam | epoch: 004 | loss: 0.40168 - acc: 0.8201 -- iter: 096/393
[A[ATraining Step: 43  | total loss: [1m[32m0.36453[0m[0m | time: 22.840s
[2K
| Adam | epoch: 004 | loss: 0.36453 - acc: 0.8519 -- iter: 128/393
[A[ATraining Step: 44  | total loss: [1m[32m0.39001[0m[0m | time: 31.288s
[2K
| Adam | epoch: 004 | loss: 0.39001 - acc: 0.8126 -- iter: 160/393
[A[ATraining Step: 45  | total loss: [1m[32m0.37812[0m[0m | time: 39.802s
[2K
| Adam | epoch: 004 | loss: 0.37812 - acc: 0.8232 -- iter: 192/393
[A[ATraining Step: 46  | total loss: [1m[32m0.38222[0m[0m | time: 48.340s
[2K
| Adam | epoch: 004 | loss: 0.38222 - acc: 0.8162 -- iter: 224/393
[A[ATraining Step: 47  | total loss: [1m[32m0.38827[0m[0m | time: 56.703s
[2K
| Adam | epoch: 004 | loss: 0.38827 - acc: 0.8105 -- iter: 256/393
[A[ATraining Step: 48  | total loss: [1m[32m0.36086[0m[0m | time: 64.977s
[2K
| Adam | epoch: 004 | loss: 0.36086 - acc: 0.8158 -- iter: 288/393
[A[ATraining Step: 49  | total loss: [1m[32m0.35915[0m[0m | time: 73.294s
[2K
| Adam | epoch: 004 | loss: 0.35915 - acc: 0.8202 -- iter: 320/393
[A[ATraining Step: 50  | total loss: [1m[32m0.37726[0m[0m | time: 81.672s
[2K
| Adam | epoch: 004 | loss: 0.37726 - acc: 0.8142 -- iter: 352/393
[A[ATraining Step: 51  | total loss: [1m[32m0.34839[0m[0m | time: 89.930s
[2K
| Adam | epoch: 004 | loss: 0.34839 - acc: 0.8330 -- iter: 384/393
[A[ATraining Step: 52  | total loss: [1m[32m0.33793[0m[0m | time: 103.864s
[2K
| Adam | epoch: 004 | loss: 0.33793 - acc: 0.8487 | val_loss: 2.10410 - val_acc: 0.5161 -- iter: 393/393
--
Training Step: 53  | total loss: [1m[32m0.31971[0m[0m | time: 8.529s
[2K
| Adam | epoch: 005 | loss: 0.31971 - acc: 0.8618 -- iter: 032/393
[A[ATraining Step: 54  | total loss: [1m[32m0.32579[0m[0m | time: 16.934s
[2K
| Adam | epoch: 005 | loss: 0.32579 - acc: 0.8592 -- iter: 064/393
[A[ATraining Step: 55  | total loss: [1m[32m0.32283[0m[0m | time: 19.955s
[2K
| Adam | epoch: 005 | loss: 0.32283 - acc: 0.8614 -- iter: 096/393
[A[ATraining Step: 56  | total loss: [1m[32m0.28208[0m[0m | time: 22.871s
[2K
| Adam | epoch: 005 | loss: 0.28208 - acc: 0.8809 -- iter: 128/393
[A[ATraining Step: 57  | total loss: [1m[32m0.24592[0m[0m | time: 31.281s
[2K
| Adam | epoch: 005 | loss: 0.24592 - acc: 0.8974 -- iter: 160/393
[A[ATraining Step: 58  | total loss: [1m[32m0.25569[0m[0m | time: 39.855s
[2K
| Adam | epoch: 005 | loss: 0.25569 - acc: 0.8858 -- iter: 192/393
[A[ATraining Step: 59  | total loss: [1m[32m0.26112[0m[0m | time: 48.328s
[2K
| Adam | epoch: 005 | loss: 0.26112 - acc: 0.8886 -- iter: 224/393
[A[ATraining Step: 60  | total loss: [1m[32m0.25968[0m[0m | time: 56.625s
[2K
| Adam | epoch: 005 | loss: 0.25968 - acc: 0.8868 -- iter: 256/393
[A[ATraining Step: 61  | total loss: [1m[32m0.26516[0m[0m | time: 65.167s
[2K
| Adam | epoch: 005 | loss: 0.26516 - acc: 0.8812 -- iter: 288/393
[A[ATraining Step: 62  | total loss: [1m[32m0.26135[0m[0m | time: 73.557s
[2K
| Adam | epoch: 005 | loss: 0.26135 - acc: 0.8884 -- iter: 320/393
[A[ATraining Step: 63  | total loss: [1m[32m0.26047[0m[0m | time: 82.091s
[2K
| Adam | epoch: 005 | loss: 0.26047 - acc: 0.8907 -- iter: 352/393
[A[ATraining Step: 64  | total loss: [1m[32m0.26763[0m[0m | time: 90.524s
[2K
| Adam | epoch: 005 | loss: 0.26763 - acc: 0.8848 -- iter: 384/393
[A[ATraining Step: 65  | total loss: [1m[32m0.28981[0m[0m | time: 104.428s
[2K
| Adam | epoch: 005 | loss: 0.28981 - acc: 0.8682 | val_loss: 2.07973 - val_acc: 0.5242 -- iter: 393/393
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8196614583333334
Validation AUPRC:0.8197068244514513
Test AUC:0.919947848761408
Test AUPRC:0.9354305430365337
BestTestF1Score	0.79	0.56	0.77	0.7	0.9	53	23	42	6	0.99
BestTestMCCScore	0.82	0.65	0.82	0.78	0.86	51	14	51	8	1.0
BestTestAccuracyScore	0.82	0.65	0.82	0.78	0.86	51	14	51	8	1.0
BestValidationF1Score	0.78	0.54	0.77	0.72	0.85	51	20	44	9	0.99
BestValidationMCC	0.77	0.55	0.77	0.76	0.78	47	15	49	13	1.0
BestValidationAccuracy	0.77	0.55	0.77	0.76	0.78	47	15	49	13	1.0
TestPredictions (Threshold:1.0)
CHEMBL110645,FP,INACT,1.0	CHEMBL212401,FP,INACT,1.0	CHEMBL3125572,FP,INACT,1.0	CHEMBL309394,FP,INACT,1.0	CHEMBL380221,TP,ACT,1.0	CHEMBL3099875,TN,INACT,0.9700000286102295	CHEMBL208464,TN,INACT,0.5099999904632568	CHEMBL198362,FN,ACT,0.9800000190734863	CHEMBL3356595,TP,ACT,1.0	CHEMBL2087345,TN,INACT,0.9900000095367432	CHEMBL409191,TP,ACT,1.0	CHEMBL451066,FP,INACT,1.0	CHEMBL60160,TN,INACT,0.8100000023841858	CHEMBL212014,TP,ACT,1.0	CHEMBL27305,TN,INACT,0.8799999952316284	CHEMBL7126,TN,INACT,0.75	CHEMBL156775,TN,INACT,0.8600000143051147	CHEMBL379586,TP,ACT,1.0	CHEMBL3632760,FN,ACT,0.9700000286102295	CHEMBL3219100,TP,ACT,1.0	CHEMBL3356591,TP,ACT,1.0	CHEMBL3143643,FP,INACT,1.0	CHEMBL379960,TP,ACT,1.0	CHEMBL3423213,TN,INACT,0.05999999865889549	CHEMBL3780208,TP,ACT,1.0	CHEMBL1704776,TN,INACT,0.7900000214576721	CHEMBL52932,TN,INACT,0.7400000095367432	CHEMBL212616,TP,ACT,1.0	CHEMBL506502,TN,INACT,0.8999999761581421	CHEMBL3219090,TP,ACT,1.0	CHEMBL1256178,TN,INACT,0.949999988079071	CHEMBL1401508,TN,INACT,0.9900000095367432	CHEMBL497067,FP,INACT,1.0	CHEMBL2367632,FP,INACT,1.0	CHEMBL3219077,TP,ACT,1.0	CHEMBL3423008,TN,INACT,0.019999999552965164	CHEMBL3325624,TN,INACT,0.9599999785423279	CHEMBL3219081,TP,ACT,1.0	CHEMBL2417904,FP,INACT,1.0	CHEMBL211401,TP,ACT,1.0	CHEMBL120012,TN,INACT,0.5199999809265137	CHEMBL3289019,TP,ACT,1.0	CHEMBL3594082,FN,ACT,0.7799999713897705	CHEMBL3289299,TP,ACT,1.0	CHEMBL3289297,FN,ACT,0.8100000023841858	CHEMBL394723,TP,ACT,1.0	CHEMBL3289033,TP,ACT,1.0	CHEMBL332426,TN,INACT,0.41999998688697815	CHEMBL3706846,TP,ACT,1.0	CHEMBL410952,FN,ACT,0.9800000190734863	CHEMBL512118,TP,ACT,1.0	CHEMBL64708,TN,INACT,0.6100000143051147	CHEMBL3354677,TP,ACT,1.0	CHEMBL3289016,TP,ACT,1.0	CHEMBL214368,TN,INACT,0.8600000143051147	CHEMBL3219076,TP,ACT,1.0	CHEMBL443990,TP,ACT,1.0	CHEMBL109251,FP,INACT,1.0	CHEMBL1644912,TN,INACT,0.7599999904632568	CHEMBL3100168,TP,ACT,1.0	CHEMBL379957,TP,ACT,1.0	CHEMBL208586,TP,ACT,1.0	CHEMBL3354686,TP,ACT,1.0	CHEMBL1289860,TN,INACT,0.9800000190734863	CHEMBL3403528,TP,ACT,1.0	CHEMBL2159301,FP,INACT,1.0	CHEMBL1464645,TN,INACT,0.7300000190734863	CHEMBL3706844,TP,ACT,1.0	CHEMBL61933,TN,INACT,0.4699999988079071	CHEMBL2372656,FP,INACT,1.0	CHEMBL1833982,TN,INACT,0.4000000059604645	CHEMBL3408410,TN,INACT,0.9900000095367432	CHEMBL210386,TP,ACT,1.0	CHEMBL46148,TN,INACT,0.8500000238418579	CHEMBL231087,TN,INACT,0.949999988079071	CHEMBL3099874,TN,INACT,0.9800000190734863	CHEMBL438959,TP,ACT,1.0	CHEMBL3219101,TP,ACT,1.0	CHEMBL338615,TN,INACT,0.9900000095367432	CHEMBL2159275,TN,INACT,0.9900000095367432	CHEMBL179189,TN,INACT,0.9900000095367432	CHEMBL2372702,TN,INACT,0.9900000095367432	CHEMBL290025,FP,INACT,1.0	CHEMBL554824,TN,INACT,0.9900000095367432	CHEMBL516786,TP,ACT,1.0	CHEMBL279400,TN,INACT,0.9200000166893005	CHEMBL461441,TP,ACT,1.0	CHEMBL2159391,TN,INACT,0.8700000047683716	CHEMBL1346897,TN,INACT,0.949999988079071	CHEMBL3219072,TP,ACT,1.0	CHEMBL103102,TN,INACT,0.12999999523162842	CHEMBL107955,TP,ACT,1.0	CHEMBL539993,TN,INACT,0.6700000166893005	CHEMBL345710,TN,INACT,0.949999988079071	CHEMBL3099870,TN,INACT,0.8199999928474426	CHEMBL3655697,TP,ACT,1.0	CHEMBL3109168,TN,INACT,0.5199999809265137	CHEMBL3099813,TP,ACT,1.0	CHEMBL2159294,TN,INACT,0.9300000071525574	CHEMBL3289302,TP,ACT,1.0	CHEMBL310871,TN,INACT,0.949999988079071	CHEMBL3289020,TP,ACT,1.0	CHEMBL435213,TN,INACT,0.9800000190734863	CHEMBL1462676,FP,INACT,1.0	CHEMBL2159291,TN,INACT,0.17000000178813934	CHEMBL3099589,TP,ACT,1.0	CHEMBL3219091,TP,ACT,1.0	CHEMBL3354681,TP,ACT,1.0	CHEMBL1313808,TN,INACT,0.49000000953674316	CHEMBL3356596,FN,ACT,0.9900000095367432	CHEMBL1532635,TN,INACT,0.9100000262260437	CHEMBL211939,TP,ACT,1.0	CHEMBL3219086,TP,ACT,1.0	CHEMBL3828410,FN,ACT,0.6700000166893005	CHEMBL1824558,TN,INACT,0.8899999856948853	CHEMBL281719,TN,INACT,0.9399999976158142	CHEMBL513339,TP,ACT,1.0	CHEMBL209334,TP,ACT,1.0	CHEMBL512935,TN,INACT,0.9200000166893005	CHEMBL3219088,TP,ACT,1.0	CHEMBL3352840,FN,ACT,0.9900000095367432	CHEMBL492342,TP,ACT,1.0	CHEMBL24713,TN,INACT,0.9900000095367432	CHEMBL3289036,TP,ACT,1.0	

