ImageNetInceptionV2 CHEMBL3192 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	355
Number of inactive compounds :	237
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3192_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3192_adam_0.0005_15_0.6/
---------------------------------
Training samples: 375
Validation samples: 118
--
Training Step: 1  | time: 159.615s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/375
[A[ATraining Step: 2  | total loss: [1m[32m0.61768[0m[0m | time: 311.585s
[2K
| Adam | epoch: 001 | loss: 0.61768 - acc: 0.4500 -- iter: 064/375
[A[ATraining Step: 3  | total loss: [1m[32m0.63050[0m[0m | time: 406.937s
[2K
| Adam | epoch: 001 | loss: 0.63050 - acc: 0.4909 -- iter: 096/375
[A[ATraining Step: 4  | total loss: [1m[32m0.78290[0m[0m | time: 556.222s
[2K
| Adam | epoch: 001 | loss: 0.78290 - acc: 0.5680 -- iter: 128/375
[A[ATraining Step: 5  | total loss: [1m[32m0.73216[0m[0m | time: 676.647s
[2K
| Adam | epoch: 001 | loss: 0.73216 - acc: 0.5858 -- iter: 160/375
[A[ATraining Step: 6  | total loss: [1m[32m0.81348[0m[0m | time: 713.066s
[2K
| Adam | epoch: 001 | loss: 0.81348 - acc: 0.5307 -- iter: 192/375
[A[ATraining Step: 7  | total loss: [1m[32m0.76679[0m[0m | time: 735.497s
[2K
| Adam | epoch: 001 | loss: 0.76679 - acc: 0.5685 -- iter: 224/375
[A[ATraining Step: 8  | total loss: [1m[32m0.82705[0m[0m | time: 800.428s
[2K
| Adam | epoch: 001 | loss: 0.82705 - acc: 0.4597 -- iter: 256/375
[A[ATraining Step: 9  | total loss: [1m[32m0.72357[0m[0m | time: 841.878s
[2K
| Adam | epoch: 001 | loss: 0.72357 - acc: 0.5637 -- iter: 288/375
[A[ATraining Step: 10  | total loss: [1m[32m0.67491[0m[0m | time: 874.554s
[2K
| Adam | epoch: 001 | loss: 0.67491 - acc: 0.6100 -- iter: 320/375
[A[ATraining Step: 11  | total loss: [1m[32m0.63852[0m[0m | time: 910.215s
[2K
| Adam | epoch: 001 | loss: 0.63852 - acc: 0.6615 -- iter: 352/375
[A[ATraining Step: 12  | total loss: [1m[32m0.61194[0m[0m | time: 940.176s
[2K
| Adam | epoch: 001 | loss: 0.61194 - acc: 0.6873 | val_loss: 0.81297 - val_acc: 0.3475 -- iter: 375/375
--
Training Step: 13  | total loss: [1m[32m0.59810[0m[0m | time: 10.778s
[2K
| Adam | epoch: 002 | loss: 0.59810 - acc: 0.6909 -- iter: 032/375
[A[ATraining Step: 14  | total loss: [1m[32m0.53814[0m[0m | time: 32.670s
[2K
| Adam | epoch: 002 | loss: 0.53814 - acc: 0.7640 -- iter: 064/375
[A[ATraining Step: 15  | total loss: [1m[32m0.56709[0m[0m | time: 60.077s
[2K
| Adam | epoch: 002 | loss: 0.56709 - acc: 0.7218 -- iter: 096/375
[A[ATraining Step: 16  | total loss: [1m[32m0.60201[0m[0m | time: 86.303s
[2K
| Adam | epoch: 002 | loss: 0.60201 - acc: 0.6972 -- iter: 128/375
[A[ATraining Step: 17  | total loss: [1m[32m0.63313[0m[0m | time: 107.744s
[2K
| Adam | epoch: 002 | loss: 0.63313 - acc: 0.6600 -- iter: 160/375
[A[ATraining Step: 18  | total loss: [1m[32m0.63700[0m[0m | time: 125.158s
[2K
| Adam | epoch: 002 | loss: 0.63700 - acc: 0.6695 -- iter: 192/375
[A[ATraining Step: 19  | total loss: [1m[32m0.67036[0m[0m | time: 140.933s
[2K
| Adam | epoch: 002 | loss: 0.67036 - acc: 0.6651 -- iter: 224/375
[A[ATraining Step: 20  | total loss: [1m[32m0.66107[0m[0m | time: 164.843s
[2K
| Adam | epoch: 002 | loss: 0.66107 - acc: 0.6723 -- iter: 256/375
[A[ATraining Step: 21  | total loss: [1m[32m0.60944[0m[0m | time: 178.676s
[2K
| Adam | epoch: 002 | loss: 0.60944 - acc: 0.6964 -- iter: 288/375
[A[ATraining Step: 22  | total loss: [1m[32m0.64858[0m[0m | time: 191.960s
[2K
| Adam | epoch: 002 | loss: 0.64858 - acc: 0.7031 -- iter: 320/375
[A[ATraining Step: 23  | total loss: [1m[32m0.62743[0m[0m | time: 205.277s
[2K
| Adam | epoch: 002 | loss: 0.62743 - acc: 0.6895 -- iter: 352/375
[A[ATraining Step: 24  | total loss: [1m[32m0.58732[0m[0m | time: 219.995s
[2K
| Adam | epoch: 002 | loss: 0.58732 - acc: 0.7153 | val_loss: 0.74424 - val_acc: 0.6525 -- iter: 375/375
--
Training Step: 25  | total loss: [1m[32m0.55519[0m[0m | time: 10.264s
[2K
| Adam | epoch: 003 | loss: 0.55519 - acc: 0.7418 -- iter: 032/375
[A[ATraining Step: 26  | total loss: [1m[32m0.50077[0m[0m | time: 20.187s
[2K
| Adam | epoch: 003 | loss: 0.50077 - acc: 0.7641 -- iter: 064/375
[A[ATraining Step: 27  | total loss: [1m[32m0.45337[0m[0m | time: 60.994s
[2K
| Adam | epoch: 003 | loss: 0.45337 - acc: 0.8024 -- iter: 096/375
[A[ATraining Step: 28  | total loss: [1m[32m0.46671[0m[0m | time: 77.841s
[2K
| Adam | epoch: 003 | loss: 0.46671 - acc: 0.8049 -- iter: 128/375
[A[ATraining Step: 29  | total loss: [1m[32m0.50061[0m[0m | time: 90.820s
[2K
| Adam | epoch: 003 | loss: 0.50061 - acc: 0.7688 -- iter: 160/375
[A[ATraining Step: 30  | total loss: [1m[32m0.47750[0m[0m | time: 105.521s
[2K
| Adam | epoch: 003 | loss: 0.47750 - acc: 0.7865 -- iter: 192/375
[A[ATraining Step: 31  | total loss: [1m[32m0.48305[0m[0m | time: 121.940s
[2K
| Adam | epoch: 003 | loss: 0.48305 - acc: 0.7853 -- iter: 224/375
[A[ATraining Step: 32  | total loss: [1m[32m0.54082[0m[0m | time: 136.039s
[2K
| Adam | epoch: 003 | loss: 0.54082 - acc: 0.7633 -- iter: 256/375
[A[ATraining Step: 33  | total loss: [1m[32m0.53225[0m[0m | time: 148.393s
[2K
| Adam | epoch: 003 | loss: 0.53225 - acc: 0.7810 -- iter: 288/375
[A[ATraining Step: 34  | total loss: [1m[32m0.47312[0m[0m | time: 169.871s
[2K
| Adam | epoch: 003 | loss: 0.47312 - acc: 0.8145 -- iter: 320/375
[A[ATraining Step: 35  | total loss: [1m[32m0.44746[0m[0m | time: 190.110s
[2K
| Adam | epoch: 003 | loss: 0.44746 - acc: 0.8337 -- iter: 352/375
[A[ATraining Step: 36  | total loss: [1m[32m0.43988[0m[0m | time: 218.771s
[2K
| Adam | epoch: 003 | loss: 0.43988 - acc: 0.8230 | val_loss: 0.86270 - val_acc: 0.6441 -- iter: 375/375
--
Training Step: 37  | total loss: [1m[32m0.40111[0m[0m | time: 19.231s
[2K
| Adam | epoch: 004 | loss: 0.40111 - acc: 0.8459 -- iter: 032/375
[A[ATraining Step: 38  | total loss: [1m[32m0.39657[0m[0m | time: 31.421s
[2K
| Adam | epoch: 004 | loss: 0.39657 - acc: 0.8516 -- iter: 064/375
[A[ATraining Step: 39  | total loss: [1m[32m0.36612[0m[0m | time: 46.982s
[2K
| Adam | epoch: 004 | loss: 0.36612 - acc: 0.8633 -- iter: 096/375
[A[ATraining Step: 40  | total loss: [1m[32m0.31225[0m[0m | time: 96.719s
[2K
| Adam | epoch: 004 | loss: 0.31225 - acc: 0.8890 -- iter: 128/375
[A[ATraining Step: 41  | total loss: [1m[32m0.28588[0m[0m | time: 147.570s
[2K
| Adam | epoch: 004 | loss: 0.28588 - acc: 0.9036 -- iter: 160/375
[A[ATraining Step: 42  | total loss: [1m[32m0.28332[0m[0m | time: 266.318s
[2K
| Adam | epoch: 004 | loss: 0.28332 - acc: 0.9041 -- iter: 192/375
[A[ATraining Step: 43  | total loss: [1m[32m0.26860[0m[0m | time: 373.719s
[2K
| Adam | epoch: 004 | loss: 0.26860 - acc: 0.9045 -- iter: 224/375
[A[ATraining Step: 44  | total loss: [1m[32m0.25604[0m[0m | time: 421.423s
[2K
| Adam | epoch: 004 | loss: 0.25604 - acc: 0.9048 -- iter: 256/375
[A[ATraining Step: 45  | total loss: [1m[32m0.24602[0m[0m | time: 470.663s
[2K
| Adam | epoch: 004 | loss: 0.24602 - acc: 0.9050 -- iter: 288/375
[A[ATraining Step: 46  | total loss: [1m[32m0.24209[0m[0m | time: 485.864s
[2K
| Adam | epoch: 004 | loss: 0.24209 - acc: 0.9052 -- iter: 320/375
[A[ATraining Step: 47  | total loss: [1m[32m0.21125[0m[0m | time: 501.763s
[2K
| Adam | epoch: 004 | loss: 0.21125 - acc: 0.9207 -- iter: 352/375
[A[ATraining Step: 48  | total loss: [1m[32m0.22604[0m[0m | time: 522.377s
[2K
| Adam | epoch: 004 | loss: 0.22604 - acc: 0.9184 | val_loss: 0.48824 - val_acc: 0.7458 -- iter: 375/375
--
Training Step: 49  | total loss: [1m[32m0.21221[0m[0m | time: 15.280s
[2K
| Adam | epoch: 005 | loss: 0.21221 - acc: 0.9264 -- iter: 032/375
[A[ATraining Step: 50  | total loss: [1m[32m0.19089[0m[0m | time: 29.756s
[2K
| Adam | epoch: 005 | loss: 0.19089 - acc: 0.9329 -- iter: 064/375
[A[ATraining Step: 51  | total loss: [1m[32m0.18208[0m[0m | time: 41.574s
[2K
| Adam | epoch: 005 | loss: 0.18208 - acc: 0.9384 -- iter: 096/375
[A[ATraining Step: 52  | total loss: [1m[32m0.18606[0m[0m | time: 52.085s
[2K
| Adam | epoch: 005 | loss: 0.18606 - acc: 0.9346 -- iter: 128/375
[A[ATraining Step: 53  | total loss: [1m[32m0.16199[0m[0m | time: 113.985s
[2K
| Adam | epoch: 005 | loss: 0.16199 - acc: 0.9442 -- iter: 160/375
[A[ATraining Step: 54  | total loss: [1m[32m0.16207[0m[0m | time: 128.499s
[2K
| Adam | epoch: 005 | loss: 0.16207 - acc: 0.9433 -- iter: 192/375
[A[ATraining Step: 55  | total loss: [1m[32m0.15852[0m[0m | time: 143.545s
[2K
| Adam | epoch: 005 | loss: 0.15852 - acc: 0.9424 -- iter: 224/375
[A[ATraining Step: 56  | total loss: [1m[32m0.20146[0m[0m | time: 158.275s
[2K
| Adam | epoch: 005 | loss: 0.20146 - acc: 0.9286 -- iter: 256/375
[A[ATraining Step: 57  | total loss: [1m[32m0.21838[0m[0m | time: 173.418s
[2K
| Adam | epoch: 005 | loss: 0.21838 - acc: 0.9298 -- iter: 288/375
[A[ATraining Step: 58  | total loss: [1m[32m0.22574[0m[0m | time: 187.491s
[2K
| Adam | epoch: 005 | loss: 0.22574 - acc: 0.9223 -- iter: 320/375
[A[ATraining Step: 59  | total loss: [1m[32m0.22606[0m[0m | time: 201.752s
[2K
| Adam | epoch: 005 | loss: 0.22606 - acc: 0.9286 -- iter: 352/375
[A[ATraining Step: 60  | total loss: [1m[32m0.20997[0m[0m | time: 223.863s
[2K
| Adam | epoch: 005 | loss: 0.20997 - acc: 0.9297 | val_loss: 0.83371 - val_acc: 0.5678 -- iter: 375/375
--
Training Step: 61  | total loss: [1m[32m0.20700[0m[0m | time: 12.298s
[2K
| Adam | epoch: 006 | loss: 0.20700 - acc: 0.9308 -- iter: 032/375
[A[ATraining Step: 62  | total loss: [1m[32m0.19139[0m[0m | time: 24.742s
[2K
| Adam | epoch: 006 | loss: 0.19139 - acc: 0.9356 -- iter: 064/375
[A[ATraining Step: 63  | total loss: [1m[32m0.17668[0m[0m | time: 37.019s
[2K
| Adam | epoch: 006 | loss: 0.17668 - acc: 0.9438 -- iter: 096/375
[A[ATraining Step: 64  | total loss: [1m[32m0.20729[0m[0m | time: 46.197s
[2K
| Adam | epoch: 006 | loss: 0.20729 - acc: 0.9274 -- iter: 128/375
[A[ATraining Step: 65  | total loss: [1m[32m0.23498[0m[0m | time: 56.268s
[2K
| Adam | epoch: 006 | loss: 0.23498 - acc: 0.9095 -- iter: 160/375
[A[ATraining Step: 66  | total loss: [1m[32m0.23334[0m[0m | time: 68.444s
[2K
| Adam | epoch: 006 | loss: 0.23334 - acc: 0.9100 -- iter: 192/375
[A[ATraining Step: 67  | total loss: [1m[32m0.21868[0m[0m | time: 80.693s
[2K
| Adam | epoch: 006 | loss: 0.21868 - acc: 0.9133 -- iter: 224/375
[A[ATraining Step: 68  | total loss: [1m[32m0.20550[0m[0m | time: 93.021s
[2K
| Adam | epoch: 006 | loss: 0.20550 - acc: 0.9161 -- iter: 256/375
[A[ATraining Step: 69  | total loss: [1m[32m0.22266[0m[0m | time: 105.072s
[2K
| Adam | epoch: 006 | loss: 0.22266 - acc: 0.9150 -- iter: 288/375
[A[ATraining Step: 70  | total loss: [1m[32m0.20070[0m[0m | time: 117.232s
[2K
| Adam | epoch: 006 | loss: 0.20070 - acc: 0.9248 -- iter: 320/375
[A[ATraining Step: 71  | total loss: [1m[32m0.20081[0m[0m | time: 128.843s
[2K
| Adam | epoch: 006 | loss: 0.20081 - acc: 0.9227 -- iter: 352/375
[A[ATraining Step: 72  | total loss: [1m[32m0.19021[0m[0m | time: 150.346s
[2K
| Adam | epoch: 006 | loss: 0.19021 - acc: 0.9279 | val_loss: 2.08364 - val_acc: 0.6525 -- iter: 375/375
--
Training Step: 73  | total loss: [1m[32m0.17600[0m[0m | time: 12.018s
[2K
| Adam | epoch: 007 | loss: 0.17600 - acc: 0.9359 -- iter: 032/375
[A[ATraining Step: 74  | total loss: [1m[32m0.18961[0m[0m | time: 24.442s
[2K
| Adam | epoch: 007 | loss: 0.18961 - acc: 0.9326 -- iter: 064/375
[A[ATraining Step: 75  | total loss: [1m[32m0.17540[0m[0m | time: 36.670s
[2K
| Adam | epoch: 007 | loss: 0.17540 - acc: 0.9365 -- iter: 096/375
[A[ATraining Step: 76  | total loss: [1m[32m0.15907[0m[0m | time: 48.751s
[2K
| Adam | epoch: 007 | loss: 0.15907 - acc: 0.9433 -- iter: 128/375
[A[ATraining Step: 77  | total loss: [1m[32m0.15710[0m[0m | time: 58.183s
[2K
| Adam | epoch: 007 | loss: 0.15710 - acc: 0.9361 -- iter: 160/375
[A[ATraining Step: 78  | total loss: [1m[32m0.15177[0m[0m | time: 67.745s
[2K
| Adam | epoch: 007 | loss: 0.15177 - acc: 0.9382 -- iter: 192/375
[A[ATraining Step: 79  | total loss: [1m[32m0.13799[0m[0m | time: 80.053s
[2K
| Adam | epoch: 007 | loss: 0.13799 - acc: 0.9446 -- iter: 224/375
[A[ATraining Step: 80  | total loss: [1m[32m0.13492[0m[0m | time: 92.180s
[2K
| Adam | epoch: 007 | loss: 0.13492 - acc: 0.9471 -- iter: 256/375
[A[ATraining Step: 81  | total loss: [1m[32m0.14390[0m[0m | time: 103.864s
[2K
| Adam | epoch: 007 | loss: 0.14390 - acc: 0.9493 -- iter: 288/375
[A[ATraining Step: 82  | total loss: [1m[32m0.14018[0m[0m | time: 115.466s
[2K
| Adam | epoch: 007 | loss: 0.14018 - acc: 0.9512 -- iter: 320/375
[A[ATraining Step: 83  | total loss: [1m[32m0.15959[0m[0m | time: 127.799s
[2K
| Adam | epoch: 007 | loss: 0.15959 - acc: 0.9405 -- iter: 352/375
[A[ATraining Step: 84  | total loss: [1m[32m0.20391[0m[0m | time: 148.580s
[2K
| Adam | epoch: 007 | loss: 0.20391 - acc: 0.9277 | val_loss: 0.56048 - val_acc: 0.7797 -- iter: 375/375
--
Training Step: 85  | total loss: [1m[32m0.21761[0m[0m | time: 12.623s
[2K
| Adam | epoch: 008 | loss: 0.21761 - acc: 0.9193 -- iter: 032/375
[A[ATraining Step: 86  | total loss: [1m[32m0.23436[0m[0m | time: 24.434s
[2K
| Adam | epoch: 008 | loss: 0.23436 - acc: 0.9149 -- iter: 064/375
[A[ATraining Step: 87  | total loss: [1m[32m0.23489[0m[0m | time: 36.751s
[2K
| Adam | epoch: 008 | loss: 0.23489 - acc: 0.9171 -- iter: 096/375
[A[ATraining Step: 88  | total loss: [1m[32m0.22126[0m[0m | time: 48.981s
[2K
| Adam | epoch: 008 | loss: 0.22126 - acc: 0.9223 -- iter: 128/375
[A[ATraining Step: 89  | total loss: [1m[32m0.20573[0m[0m | time: 61.074s
[2K
| Adam | epoch: 008 | loss: 0.20573 - acc: 0.9301 -- iter: 160/375
[A[ATraining Step: 90  | total loss: [1m[32m0.19950[0m[0m | time: 70.612s
[2K
| Adam | epoch: 008 | loss: 0.19950 - acc: 0.9308 -- iter: 192/375
[A[ATraining Step: 91  | total loss: [1m[32m0.20031[0m[0m | time: 81.172s
[2K
| Adam | epoch: 008 | loss: 0.20031 - acc: 0.9334 -- iter: 224/375
[A[ATraining Step: 92  | total loss: [1m[32m0.18808[0m[0m | time: 92.409s
[2K
| Adam | epoch: 008 | loss: 0.18808 - acc: 0.9357 -- iter: 256/375
[A[ATraining Step: 93  | total loss: [1m[32m0.17856[0m[0m | time: 100.498s
[2K
| Adam | epoch: 008 | loss: 0.17856 - acc: 0.9390 -- iter: 288/375
[A[ATraining Step: 94  | total loss: [1m[32m0.16636[0m[0m | time: 110.628s
[2K
| Adam | epoch: 008 | loss: 0.16636 - acc: 0.9420 -- iter: 320/375
[A[ATraining Step: 95  | total loss: [1m[32m0.15731[0m[0m | time: 123.108s
[2K
| Adam | epoch: 008 | loss: 0.15731 - acc: 0.9446 -- iter: 352/375
[A[ATraining Step: 96  | total loss: [1m[32m0.15879[0m[0m | time: 143.845s
[2K
| Adam | epoch: 008 | loss: 0.15879 - acc: 0.9439 | val_loss: 3.16071 - val_acc: 0.6525 -- iter: 375/375
--
Training Step: 97  | total loss: [1m[32m0.16716[0m[0m | time: 11.865s
[2K
| Adam | epoch: 009 | loss: 0.16716 - acc: 0.9433 -- iter: 032/375
[A[ATraining Step: 98  | total loss: [1m[32m0.18010[0m[0m | time: 20.088s
[2K
| Adam | epoch: 009 | loss: 0.18010 - acc: 0.9396 -- iter: 064/375
[A[ATraining Step: 99  | total loss: [1m[32m0.17708[0m[0m | time: 28.230s
[2K
| Adam | epoch: 009 | loss: 0.17708 - acc: 0.9425 -- iter: 096/375
[A[ATraining Step: 100  | total loss: [1m[32m0.17434[0m[0m | time: 36.491s
[2K
| Adam | epoch: 009 | loss: 0.17434 - acc: 0.9451 -- iter: 128/375
[A[ATraining Step: 101  | total loss: [1m[32m0.17677[0m[0m | time: 48.519s
[2K
| Adam | epoch: 009 | loss: 0.17677 - acc: 0.9475 -- iter: 160/375
[A[ATraining Step: 102  | total loss: [1m[32m0.16428[0m[0m | time: 60.838s
[2K
| Adam | epoch: 009 | loss: 0.16428 - acc: 0.9496 -- iter: 192/375
[A[ATraining Step: 103  | total loss: [1m[32m0.15636[0m[0m | time: 70.064s
[2K
| Adam | epoch: 009 | loss: 0.15636 - acc: 0.9515 -- iter: 224/375
[A[ATraining Step: 104  | total loss: [1m[32m0.15287[0m[0m | time: 79.641s
[2K
| Adam | epoch: 009 | loss: 0.15287 - acc: 0.9520 -- iter: 256/375
[A[ATraining Step: 105  | total loss: [1m[32m0.13875[0m[0m | time: 91.836s
[2K
| Adam | epoch: 009 | loss: 0.13875 - acc: 0.9568 -- iter: 288/375
[A[ATraining Step: 106  | total loss: [1m[32m0.12887[0m[0m | time: 104.721s
[2K
| Adam | epoch: 009 | loss: 0.12887 - acc: 0.9611 -- iter: 320/375
[A[ATraining Step: 107  | total loss: [1m[32m0.12521[0m[0m | time: 116.798s
[2K
| Adam | epoch: 009 | loss: 0.12521 - acc: 0.9619 -- iter: 352/375
[A[ATraining Step: 108  | total loss: [1m[32m0.13505[0m[0m | time: 137.761s
[2K
| Adam | epoch: 009 | loss: 0.13505 - acc: 0.9595 | val_loss: 4.47391 - val_acc: 0.6525 -- iter: 375/375
--
Training Step: 109  | total loss: [1m[32m0.12659[0m[0m | time: 12.149s
[2K
| Adam | epoch: 010 | loss: 0.12659 - acc: 0.9604 -- iter: 032/375
[A[ATraining Step: 110  | total loss: [1m[32m0.11595[0m[0m | time: 24.155s
[2K
| Adam | epoch: 010 | loss: 0.11595 - acc: 0.9644 -- iter: 064/375
[A[ATraining Step: 111  | total loss: [1m[32m0.11822[0m[0m | time: 36.319s
[2K
| Adam | epoch: 010 | loss: 0.11822 - acc: 0.9648 -- iter: 096/375
[A[ATraining Step: 112  | total loss: [1m[32m0.11778[0m[0m | time: 47.841s
[2K
| Adam | epoch: 010 | loss: 0.11778 - acc: 0.9652 -- iter: 128/375
[A[ATraining Step: 113  | total loss: [1m[32m0.11153[0m[0m | time: 60.110s
[2K
| Adam | epoch: 010 | loss: 0.11153 - acc: 0.9655 -- iter: 160/375
[A[ATraining Step: 114  | total loss: [1m[32m0.10927[0m[0m | time: 71.610s
[2K
| Adam | epoch: 010 | loss: 0.10927 - acc: 0.9659 -- iter: 192/375
[A[ATraining Step: 115  | total loss: [1m[32m0.11582[0m[0m | time: 83.929s
[2K
| Adam | epoch: 010 | loss: 0.11582 - acc: 0.9599 -- iter: 224/375
[A[ATraining Step: 116  | total loss: [1m[32m0.15514[0m[0m | time: 93.219s
[2K
| Adam | epoch: 010 | loss: 0.15514 - acc: 0.9608 -- iter: 256/375
[A[ATraining Step: 117  | total loss: [1m[32m0.14269[0m[0m | time: 102.368s
[2K
| Adam | epoch: 010 | loss: 0.14269 - acc: 0.9647 -- iter: 288/375
[A[ATraining Step: 118  | total loss: [1m[32m0.13004[0m[0m | time: 114.628s
[2K
| Adam | epoch: 010 | loss: 0.13004 - acc: 0.9682 -- iter: 320/375
[A[ATraining Step: 119  | total loss: [1m[32m0.13088[0m[0m | time: 126.836s
[2K
| Adam | epoch: 010 | loss: 0.13088 - acc: 0.9652 -- iter: 352/375
[A[ATraining Step: 120  | total loss: [1m[32m0.12295[0m[0m | time: 147.409s
[2K
| Adam | epoch: 010 | loss: 0.12295 - acc: 0.9655 | val_loss: 1.07564 - val_acc: 0.7034 -- iter: 375/375
--
Training Step: 121  | total loss: [1m[32m0.11585[0m[0m | time: 11.858s
[2K
| Adam | epoch: 011 | loss: 0.11585 - acc: 0.9690 -- iter: 032/375
[A[ATraining Step: 122  | total loss: [1m[32m0.10734[0m[0m | time: 24.048s
[2K
| Adam | epoch: 011 | loss: 0.10734 - acc: 0.9721 -- iter: 064/375
[A[ATraining Step: 123  | total loss: [1m[32m0.09905[0m[0m | time: 37.359s
[2K
| Adam | epoch: 011 | loss: 0.09905 - acc: 0.9749 -- iter: 096/375
[A[ATraining Step: 124  | total loss: [1m[32m0.12554[0m[0m | time: 48.140s
[2K
| Adam | epoch: 011 | loss: 0.12554 - acc: 0.9743 -- iter: 128/375
[A[ATraining Step: 125  | total loss: [1m[32m0.13580[0m[0m | time: 56.625s
[2K
| Adam | epoch: 011 | loss: 0.13580 - acc: 0.9737 -- iter: 160/375
[A[ATraining Step: 126  | total loss: [1m[32m0.12387[0m[0m | time: 64.821s
[2K
| Adam | epoch: 011 | loss: 0.12387 - acc: 0.9763 -- iter: 192/375
[A[ATraining Step: 127  | total loss: [1m[32m0.13918[0m[0m | time: 74.630s
[2K
| Adam | epoch: 011 | loss: 0.13918 - acc: 0.9693 -- iter: 224/375
[A[ATraining Step: 128  | total loss: [1m[32m0.13847[0m[0m | time: 86.815s
[2K
| Adam | epoch: 011 | loss: 0.13847 - acc: 0.9630 -- iter: 256/375
[A[ATraining Step: 129  | total loss: [1m[32m0.13286[0m[0m | time: 96.554s
[2K
| Adam | epoch: 011 | loss: 0.13286 - acc: 0.9636 -- iter: 288/375
[A[ATraining Step: 130  | total loss: [1m[32m0.12570[0m[0m | time: 105.429s
[2K
| Adam | epoch: 011 | loss: 0.12570 - acc: 0.9629 -- iter: 320/375
[A[ATraining Step: 131  | total loss: [1m[32m0.11604[0m[0m | time: 117.462s
[2K
| Adam | epoch: 011 | loss: 0.11604 - acc: 0.9666 -- iter: 352/375
[A[ATraining Step: 132  | total loss: [1m[32m0.11084[0m[0m | time: 137.960s
[2K
| Adam | epoch: 011 | loss: 0.11084 - acc: 0.9699 | val_loss: 3.04659 - val_acc: 0.3729 -- iter: 375/375
--
Training Step: 133  | total loss: [1m[32m0.12872[0m[0m | time: 12.052s
[2K
| Adam | epoch: 012 | loss: 0.12872 - acc: 0.9636 -- iter: 032/375
[A[ATraining Step: 134  | total loss: [1m[32m0.13666[0m[0m | time: 24.182s
[2K
| Adam | epoch: 012 | loss: 0.13666 - acc: 0.9547 -- iter: 064/375
[A[ATraining Step: 135  | total loss: [1m[32m0.12918[0m[0m | time: 36.639s
[2K
| Adam | epoch: 012 | loss: 0.12918 - acc: 0.9592 -- iter: 096/375
[A[ATraining Step: 136  | total loss: [1m[32m0.12429[0m[0m | time: 49.021s
[2K
| Adam | epoch: 012 | loss: 0.12429 - acc: 0.9602 -- iter: 128/375
[A[ATraining Step: 137  | total loss: [1m[32m0.25871[0m[0m | time: 61.237s
[2K
| Adam | epoch: 012 | loss: 0.25871 - acc: 0.9454 -- iter: 160/375
[A[ATraining Step: 138  | total loss: [1m[32m0.23396[0m[0m | time: 73.667s
[2K
| Adam | epoch: 012 | loss: 0.23396 - acc: 0.9509 -- iter: 192/375
[A[ATraining Step: 139  | total loss: [1m[32m0.21998[0m[0m | time: 85.468s
[2K
| Adam | epoch: 012 | loss: 0.21998 - acc: 0.9527 -- iter: 224/375
[A[ATraining Step: 140  | total loss: [1m[32m0.23744[0m[0m | time: 97.238s
[2K
| Adam | epoch: 012 | loss: 0.23744 - acc: 0.9418 -- iter: 256/375
[A[ATraining Step: 141  | total loss: [1m[32m0.22530[0m[0m | time: 109.381s
[2K
| Adam | epoch: 012 | loss: 0.22530 - acc: 0.9413 -- iter: 288/375
[A[ATraining Step: 142  | total loss: [1m[32m0.22299[0m[0m | time: 118.739s
[2K
| Adam | epoch: 012 | loss: 0.22299 - acc: 0.9378 -- iter: 320/375
[A[ATraining Step: 143  | total loss: [1m[32m0.20476[0m[0m | time: 128.177s
[2K
| Adam | epoch: 012 | loss: 0.20476 - acc: 0.9441 -- iter: 352/375
[A[ATraining Step: 144  | total loss: [1m[32m0.18637[0m[0m | time: 148.787s
[2K
| Adam | epoch: 012 | loss: 0.18637 - acc: 0.9496 | val_loss: 0.78703 - val_acc: 0.7203 -- iter: 375/375
--
Training Step: 145  | total loss: [1m[32m0.17392[0m[0m | time: 12.056s
[2K
| Adam | epoch: 013 | loss: 0.17392 - acc: 0.9547 -- iter: 032/375
[A[ATraining Step: 146  | total loss: [1m[32m0.17150[0m[0m | time: 23.776s
[2K
| Adam | epoch: 013 | loss: 0.17150 - acc: 0.9498 -- iter: 064/375
[A[ATraining Step: 147  | total loss: [1m[32m0.16185[0m[0m | time: 35.622s
[2K
| Adam | epoch: 013 | loss: 0.16185 - acc: 0.9517 -- iter: 096/375
[A[ATraining Step: 148  | total loss: [1m[32m0.15162[0m[0m | time: 47.473s
[2K
| Adam | epoch: 013 | loss: 0.15162 - acc: 0.9534 -- iter: 128/375
[A[ATraining Step: 149  | total loss: [1m[32m0.14756[0m[0m | time: 59.468s
[2K
| Adam | epoch: 013 | loss: 0.14756 - acc: 0.9550 -- iter: 160/375
[A[ATraining Step: 150  | total loss: [1m[32m0.16128[0m[0m | time: 72.606s
[2K
| Adam | epoch: 013 | loss: 0.16128 - acc: 0.9563 -- iter: 192/375
[A[ATraining Step: 151  | total loss: [1m[32m0.15844[0m[0m | time: 82.586s
[2K
| Adam | epoch: 013 | loss: 0.15844 - acc: 0.9545 -- iter: 224/375
[A[ATraining Step: 152  | total loss: [1m[32m0.15240[0m[0m | time: 90.652s
[2K
| Adam | epoch: 013 | loss: 0.15240 - acc: 0.9528 -- iter: 256/375
[A[ATraining Step: 153  | total loss: [1m[32m0.13904[0m[0m | time: 99.043s
[2K
| Adam | epoch: 013 | loss: 0.13904 - acc: 0.9575 -- iter: 288/375
[A[ATraining Step: 154  | total loss: [1m[32m0.13537[0m[0m | time: 111.458s
[2K
| Adam | epoch: 013 | loss: 0.13537 - acc: 0.9586 -- iter: 320/375
[A[ATraining Step: 155  | total loss: [1m[32m0.12695[0m[0m | time: 120.548s
[2K
| Adam | epoch: 013 | loss: 0.12695 - acc: 0.9628 -- iter: 352/375
[A[ATraining Step: 156  | total loss: [1m[32m0.11958[0m[0m | time: 138.616s
[2K
| Adam | epoch: 013 | loss: 0.11958 - acc: 0.9665 | val_loss: 1.09860 - val_acc: 0.7034 -- iter: 375/375
--
Training Step: 157  | total loss: [1m[32m0.11030[0m[0m | time: 12.053s
[2K
| Adam | epoch: 014 | loss: 0.11030 - acc: 0.9698 -- iter: 032/375
[A[ATraining Step: 158  | total loss: [1m[32m0.10892[0m[0m | time: 23.983s
[2K
| Adam | epoch: 014 | loss: 0.10892 - acc: 0.9697 -- iter: 064/375
[A[ATraining Step: 159  | total loss: [1m[32m0.11905[0m[0m | time: 36.221s
[2K
| Adam | epoch: 014 | loss: 0.11905 - acc: 0.9696 -- iter: 096/375
[A[ATraining Step: 160  | total loss: [1m[32m0.11689[0m[0m | time: 48.318s
[2K
| Adam | epoch: 014 | loss: 0.11689 - acc: 0.9664 -- iter: 128/375
[A[ATraining Step: 161  | total loss: [1m[32m0.11554[0m[0m | time: 60.535s
[2K
| Adam | epoch: 014 | loss: 0.11554 - acc: 0.9666 -- iter: 160/375
[A[ATraining Step: 162  | total loss: [1m[32m0.10760[0m[0m | time: 72.661s
[2K
| Adam | epoch: 014 | loss: 0.10760 - acc: 0.9700 -- iter: 192/375
[A[ATraining Step: 163  | total loss: [1m[32m0.13021[0m[0m | time: 84.642s
[2K
| Adam | epoch: 014 | loss: 0.13021 - acc: 0.9636 -- iter: 224/375
[A[ATraining Step: 164  | total loss: [1m[32m0.13794[0m[0m | time: 96.330s
[2K
| Adam | epoch: 014 | loss: 0.13794 - acc: 0.9579 -- iter: 256/375
[A[ATraining Step: 165  | total loss: [1m[32m0.14205[0m[0m | time: 108.281s
[2K
| Adam | epoch: 014 | loss: 0.14205 - acc: 0.9558 -- iter: 288/375
[A[ATraining Step: 166  | total loss: [1m[32m0.13103[0m[0m | time: 120.208s
[2K
| Adam | epoch: 014 | loss: 0.13103 - acc: 0.9603 -- iter: 320/375
[A[ATraining Step: 167  | total loss: [1m[32m0.11985[0m[0m | time: 131.934s
[2K
| Adam | epoch: 014 | loss: 0.11985 - acc: 0.9642 -- iter: 352/375
[A[ATraining Step: 168  | total loss: [1m[32m0.11179[0m[0m | time: 149.676s
[2K
| Adam | epoch: 014 | loss: 0.11179 - acc: 0.9678 | val_loss: 0.73208 - val_acc: 0.7288 -- iter: 375/375
--
Training Step: 169  | total loss: [1m[32m0.11532[0m[0m | time: 8.999s
[2K
| Adam | epoch: 015 | loss: 0.11532 - acc: 0.9580 -- iter: 032/375
[A[ATraining Step: 170  | total loss: [1m[32m0.10789[0m[0m | time: 21.304s
[2K
| Adam | epoch: 015 | loss: 0.10789 - acc: 0.9622 -- iter: 064/375
[A[ATraining Step: 171  | total loss: [1m[32m0.12768[0m[0m | time: 33.549s
[2K
| Adam | epoch: 015 | loss: 0.12768 - acc: 0.9566 -- iter: 096/375
[A[ATraining Step: 172  | total loss: [1m[32m0.12167[0m[0m | time: 45.586s
[2K
| Adam | epoch: 015 | loss: 0.12167 - acc: 0.9578 -- iter: 128/375
[A[ATraining Step: 173  | total loss: [1m[32m0.11249[0m[0m | time: 57.627s
[2K
| Adam | epoch: 015 | loss: 0.11249 - acc: 0.9620 -- iter: 160/375
[A[ATraining Step: 174  | total loss: [1m[32m0.10532[0m[0m | time: 69.756s
[2K
| Adam | epoch: 015 | loss: 0.10532 - acc: 0.9658 -- iter: 192/375
[A[ATraining Step: 175  | total loss: [1m[32m0.09983[0m[0m | time: 82.154s
[2K
| Adam | epoch: 015 | loss: 0.09983 - acc: 0.9661 -- iter: 224/375
[A[ATraining Step: 176  | total loss: [1m[32m0.11991[0m[0m | time: 95.524s
[2K
| Adam | epoch: 015 | loss: 0.11991 - acc: 0.9508 -- iter: 256/375
[A[ATraining Step: 177  | total loss: [1m[32m0.10933[0m[0m | time: 104.321s
[2K
| Adam | epoch: 015 | loss: 0.10933 - acc: 0.9557 -- iter: 288/375
[A[ATraining Step: 178  | total loss: [1m[32m0.10352[0m[0m | time: 112.538s
[2K
| Adam | epoch: 015 | loss: 0.10352 - acc: 0.9601 -- iter: 320/375
[A[ATraining Step: 179  | total loss: [1m[32m0.09479[0m[0m | time: 120.594s
[2K
| Adam | epoch: 015 | loss: 0.09479 - acc: 0.9641 -- iter: 352/375
[A[ATraining Step: 180  | total loss: [1m[32m0.09286[0m[0m | time: 140.463s
[2K
| Adam | epoch: 015 | loss: 0.09286 - acc: 0.9646 | val_loss: 1.30971 - val_acc: 0.5932 -- iter: 375/375
--
Validation AUC:0.800126702565727
Validation AUPRC:0.8772736922553116
Test AUC:0.7546620046620047
Test AUPRC:0.7835836538007414
BestTestF1Score	0.76	0.41	0.71	0.71	0.82	54	22	30	12	0.01
BestTestMCCScore	0.76	0.41	0.71	0.71	0.82	54	22	30	12	0.01
BestTestAccuracyScore	0.76	0.41	0.71	0.71	0.82	54	22	30	12	0.01
BestValidationF1Score	0.83	0.46	0.76	0.79	0.87	67	18	23	10	0.01
BestValidationMCC	0.83	0.46	0.76	0.79	0.87	67	18	23	10	0.01
BestValidationAccuracy	0.83	0.46	0.76	0.79	0.87	67	18	23	10	0.01
TestPredictions (Threshold:0.01)
CHEMBL2018294,FP,INACT,0.019999999552965164	CHEMBL563287,FP,INACT,0.3499999940395355	CHEMBL387924,TP,ACT,0.8100000023841858	CHEMBL2417785,TN,INACT,0.0	CHEMBL552465,TP,ACT,0.15000000596046448	CHEMBL1767038,TN,INACT,0.0	CHEMBL235674,FP,INACT,0.10999999940395355	CHEMBL599432,TP,ACT,0.41999998688697815	CHEMBL2407723,TP,ACT,0.029999999329447746	CHEMBL3605506,FP,INACT,0.18000000715255737	CHEMBL1800376,TN,INACT,0.0	CHEMBL2408241,FN,ACT,0.0	CHEMBL604097,TP,ACT,0.9599999785423279	CHEMBL1800246,TN,INACT,0.0	CHEMBL1630109,FN,ACT,0.0	CHEMBL186311,TN,INACT,0.009999999776482582	CHEMBL1096985,FP,INACT,0.8199999928474426	CHEMBL2235660,FN,ACT,0.0	CHEMBL1934897,FP,INACT,0.07999999821186066	CHEMBL3585967,TP,ACT,0.15000000596046448	CHEMBL2170172,TN,INACT,0.0	CHEMBL3770763,TN,INACT,0.0	CHEMBL1097744,TN,INACT,0.0	CHEMBL2425968,TP,ACT,0.029999999329447746	CHEMBL3415445,TP,ACT,1.0	CHEMBL564916,FP,INACT,0.5	CHEMBL467793,TP,ACT,0.8700000047683716	CHEMBL1095120,TP,ACT,0.949999988079071	CHEMBL154517,TN,INACT,0.009999999776482582	CHEMBL3648272,FN,ACT,0.009999999776482582	CHEMBL3311466,TP,ACT,0.949999988079071	CHEMBL3605501,TN,INACT,0.0	CHEMBL2413289,FP,INACT,0.6100000143051147	CHEMBL2323290,FP,INACT,0.9399999976158142	CHEMBL2413320,TN,INACT,0.0	CHEMBL3585958,TP,ACT,0.3799999952316284	CHEMBL483693,TP,ACT,0.30000001192092896	CHEMBL468842,TP,ACT,0.8799999952316284	CHEMBL3797597,FN,ACT,0.0	CHEMBL3645375,TP,ACT,0.07000000029802322	CHEMBL1934907,FP,INACT,0.4300000071525574	CHEMBL235911,FP,INACT,0.019999999552965164	CHEMBL259826,FP,INACT,0.019999999552965164	CHEMBL1095076,TP,ACT,0.9900000095367432	CHEMBL2047680,TN,INACT,0.0	CHEMBL1171228,FP,INACT,0.3100000023841858	CHEMBL152162,TP,ACT,0.36000001430511475	CHEMBL3769820,TN,INACT,0.0	CHEMBL242533,TP,ACT,0.15000000596046448	CHEMBL2407730,TP,ACT,1.0	CHEMBL3694298,TP,ACT,0.07999999821186066	CHEMBL2431912,TP,ACT,0.029999999329447746	CHEMBL2148012,TN,INACT,0.0	CHEMBL569946,TP,ACT,0.6299999952316284	CHEMBL3648315,TP,ACT,0.019999999552965164	CHEMBL3605505,FP,INACT,0.1599999964237213	CHEMBL605117,TP,ACT,0.09000000357627869	CHEMBL1835671,FP,INACT,0.019999999552965164	CHEMBL272401,TP,ACT,0.09000000357627869	CHEMBL592440,TP,ACT,0.5799999833106995	CHEMBL1767042,TN,INACT,0.0	CHEMBL470470,TN,INACT,0.0	CHEMBL3645369,TP,ACT,0.28999999165534973	CHEMBL471041,TP,ACT,0.20999999344348907	CHEMBL319248,FN,ACT,0.0	CHEMBL3775662,TP,ACT,1.0	CHEMBL490446,TP,ACT,0.09000000357627869	CHEMBL1771486,TP,ACT,0.9800000190734863	CHEMBL213071,TN,INACT,0.0	CHEMBL326433,TP,ACT,0.3100000023841858	CHEMBL3220925,FP,INACT,0.9800000190734863	CHEMBL3745758,TP,ACT,0.23000000417232513	CHEMBL604920,TP,ACT,0.9599999785423279	CHEMBL3110284,TP,ACT,0.029999999329447746	CHEMBL460963,TP,ACT,0.8100000023841858	CHEMBL3828518,TP,ACT,0.11999999731779099	CHEMBL2047676,TN,INACT,0.0	CHEMBL2408778,FN,ACT,0.009999999776482582	CHEMBL3110022,FP,INACT,0.029999999329447746	CHEMBL1934903,TN,INACT,0.0	CHEMBL561483,TP,ACT,0.7799999713897705	CHEMBL3356920,TP,ACT,0.949999988079071	CHEMBL491926,TN,INACT,0.0	CHEMBL1095400,TP,ACT,0.7099999785423279	CHEMBL1836145,FP,INACT,0.23999999463558197	CHEMBL2148008,FN,ACT,0.009999999776482582	CHEMBL439842,FP,INACT,0.5400000214576721	CHEMBL2148014,FN,ACT,0.0	CHEMBL3770119,FP,INACT,0.05000000074505806	CHEMBL1771484,TP,ACT,0.05999999865889549	CHEMBL454025,FN,ACT,0.009999999776482582	CHEMBL3800287,FN,ACT,0.009999999776482582	CHEMBL101167,TP,ACT,0.8100000023841858	CHEMBL1798006,TP,ACT,0.8799999952316284	CHEMBL227118,TP,ACT,0.10999999940395355	CHEMBL227119,TP,ACT,0.18000000715255737	CHEMBL479842,TP,ACT,0.9100000262260437	CHEMBL1767046,TN,INACT,0.009999999776482582	CHEMBL3110285,TP,ACT,0.20999999344348907	CHEMBL1164244,TN,INACT,0.0	CHEMBL1469,TN,INACT,0.0	CHEMBL487253,TP,ACT,0.1599999964237213	CHEMBL3605503,TP,ACT,0.029999999329447746	CHEMBL3593716,TN,INACT,0.0	CHEMBL1307946,TN,INACT,0.0	CHEMBL513160,TP,ACT,0.5	CHEMBL3421750,TP,ACT,0.28999999165534973	CHEMBL505199,TN,INACT,0.0	CHEMBL3648264,TP,ACT,0.5199999809265137	CHEMBL1934891,FP,INACT,0.800000011920929	CHEMBL3218563,TN,INACT,0.0	CHEMBL1243289,TN,INACT,0.009999999776482582	CHEMBL2147944,TN,INACT,0.0	CHEMBL1938433,TP,ACT,1.0	CHEMBL1668018,FP,INACT,0.10999999940395355	CHEMBL95916,FN,ACT,0.0	CHEMBL471043,TP,ACT,0.09000000357627869	CHEMBL3771009,TN,INACT,0.0	

