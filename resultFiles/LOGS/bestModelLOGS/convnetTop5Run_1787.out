CNNModel CHEMBL1865 adam 0.0005 30 256 0 0.6 False True
Number of active compounds :	274
Number of inactive compounds :	183
---------------------------------
Run id: CNNModel_CHEMBL1865_adam_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1865_adam_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 292
Validation samples: 92
--
Training Step: 1  | time: 0.931s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/292
[A[ATraining Step: 2  | total loss: [1m[32m0.62336[0m[0m | time: 1.668s
[2K
| Adam | epoch: 001 | loss: 0.62336 - acc: 0.6187 -- iter: 064/292
[A[ATraining Step: 3  | total loss: [1m[32m0.67829[0m[0m | time: 2.399s
[2K
| Adam | epoch: 001 | loss: 0.67829 - acc: 0.5727 -- iter: 096/292
[A[ATraining Step: 4  | total loss: [1m[32m0.68501[0m[0m | time: 3.125s
[2K
| Adam | epoch: 001 | loss: 0.68501 - acc: 0.5651 -- iter: 128/292
[A[ATraining Step: 5  | total loss: [1m[32m0.69574[0m[0m | time: 3.883s
[2K
| Adam | epoch: 001 | loss: 0.69574 - acc: 0.5200 -- iter: 160/292
[A[ATraining Step: 6  | total loss: [1m[32m0.68917[0m[0m | time: 4.668s
[2K
| Adam | epoch: 001 | loss: 0.68917 - acc: 0.5473 -- iter: 192/292
[A[ATraining Step: 7  | total loss: [1m[32m0.68983[0m[0m | time: 5.409s
[2K
| Adam | epoch: 001 | loss: 0.68983 - acc: 0.5377 -- iter: 224/292
[A[ATraining Step: 8  | total loss: [1m[32m0.67733[0m[0m | time: 6.155s
[2K
| Adam | epoch: 001 | loss: 0.67733 - acc: 0.6044 -- iter: 256/292
[A[ATraining Step: 9  | total loss: [1m[32m0.67704[0m[0m | time: 6.933s
[2K
| Adam | epoch: 001 | loss: 0.67704 - acc: 0.5988 -- iter: 288/292
[A[ATraining Step: 10  | total loss: [1m[32m0.66044[0m[0m | time: 8.126s
[2K
| Adam | epoch: 001 | loss: 0.66044 - acc: 0.6431 | val_loss: 0.64748 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 11  | total loss: [1m[32m0.69144[0m[0m | time: 0.169s
[2K
| Adam | epoch: 002 | loss: 0.69144 - acc: 0.5753 -- iter: 032/292
[A[ATraining Step: 12  | total loss: [1m[32m0.76547[0m[0m | time: 0.929s
[2K
| Adam | epoch: 002 | loss: 0.76547 - acc: 0.4289 -- iter: 064/292
[A[ATraining Step: 13  | total loss: [1m[32m0.75819[0m[0m | time: 1.736s
[2K
| Adam | epoch: 002 | loss: 0.75819 - acc: 0.4192 -- iter: 096/292
[A[ATraining Step: 14  | total loss: [1m[32m0.72547[0m[0m | time: 2.497s
[2K
| Adam | epoch: 002 | loss: 0.72547 - acc: 0.4906 -- iter: 128/292
[A[ATraining Step: 15  | total loss: [1m[32m0.71685[0m[0m | time: 3.257s
[2K
| Adam | epoch: 002 | loss: 0.71685 - acc: 0.4821 -- iter: 160/292
[A[ATraining Step: 16  | total loss: [1m[32m0.69854[0m[0m | time: 4.060s
[2K
| Adam | epoch: 002 | loss: 0.69854 - acc: 0.5708 -- iter: 192/292
[A[ATraining Step: 17  | total loss: [1m[32m0.69103[0m[0m | time: 4.816s
[2K
| Adam | epoch: 002 | loss: 0.69103 - acc: 0.6128 -- iter: 224/292
[A[ATraining Step: 18  | total loss: [1m[32m0.68892[0m[0m | time: 5.573s
[2K
| Adam | epoch: 002 | loss: 0.68892 - acc: 0.6170 -- iter: 256/292
[A[ATraining Step: 19  | total loss: [1m[32m0.68860[0m[0m | time: 6.323s
[2K
| Adam | epoch: 002 | loss: 0.68860 - acc: 0.6093 -- iter: 288/292
[A[ATraining Step: 20  | total loss: [1m[32m0.68833[0m[0m | time: 8.072s
[2K
| Adam | epoch: 002 | loss: 0.68833 - acc: 0.6043 | val_loss: 0.68508 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 21  | total loss: [1m[32m0.68678[0m[0m | time: 0.127s
[2K
| Adam | epoch: 003 | loss: 0.68678 - acc: 0.6301 -- iter: 032/292
[A[ATraining Step: 22  | total loss: [1m[32m0.69267[0m[0m | time: 0.239s
[2K
| Adam | epoch: 003 | loss: 0.69267 - acc: 0.5161 -- iter: 064/292
[A[ATraining Step: 23  | total loss: [1m[32m0.68924[0m[0m | time: 1.019s
[2K
| Adam | epoch: 003 | loss: 0.68924 - acc: 0.5840 -- iter: 096/292
[A[ATraining Step: 24  | total loss: [1m[32m0.68772[0m[0m | time: 2.087s
[2K
| Adam | epoch: 003 | loss: 0.68772 - acc: 0.6131 -- iter: 128/292
[A[ATraining Step: 25  | total loss: [1m[32m0.68836[0m[0m | time: 3.176s
[2K
| Adam | epoch: 003 | loss: 0.68836 - acc: 0.5993 -- iter: 160/292
[A[ATraining Step: 26  | total loss: [1m[32m0.68975[0m[0m | time: 4.220s
[2K
| Adam | epoch: 003 | loss: 0.68975 - acc: 0.5730 -- iter: 192/292
[A[ATraining Step: 27  | total loss: [1m[32m0.68851[0m[0m | time: 4.869s
[2K
| Adam | epoch: 003 | loss: 0.68851 - acc: 0.5944 -- iter: 224/292
[A[ATraining Step: 28  | total loss: [1m[32m0.68964[0m[0m | time: 5.493s
[2K
| Adam | epoch: 003 | loss: 0.68964 - acc: 0.5708 -- iter: 256/292
[A[ATraining Step: 29  | total loss: [1m[32m0.68878[0m[0m | time: 6.216s
[2K
| Adam | epoch: 003 | loss: 0.68878 - acc: 0.5840 -- iter: 288/292
[A[ATraining Step: 30  | total loss: [1m[32m0.68996[0m[0m | time: 8.001s
[2K
| Adam | epoch: 003 | loss: 0.68996 - acc: 0.5641 | val_loss: 0.68345 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 31  | total loss: [1m[32m0.68897[0m[0m | time: 0.896s
[2K
| Adam | epoch: 004 | loss: 0.68897 - acc: 0.5782 -- iter: 032/292
[A[ATraining Step: 32  | total loss: [1m[32m0.68770[0m[0m | time: 1.038s
[2K
| Adam | epoch: 004 | loss: 0.68770 - acc: 0.5957 -- iter: 064/292
[A[ATraining Step: 33  | total loss: [1m[32m0.68499[0m[0m | time: 1.172s
[2K
| Adam | epoch: 004 | loss: 0.68499 - acc: 0.6296 -- iter: 096/292
[A[ATraining Step: 34  | total loss: [1m[32m0.68251[0m[0m | time: 1.895s
[2K
| Adam | epoch: 004 | loss: 0.68251 - acc: 0.6554 -- iter: 128/292
[A[ATraining Step: 35  | total loss: [1m[32m0.68201[0m[0m | time: 2.640s
[2K
| Adam | epoch: 004 | loss: 0.68201 - acc: 0.6556 -- iter: 160/292
[A[ATraining Step: 36  | total loss: [1m[32m0.67719[0m[0m | time: 3.389s
[2K
| Adam | epoch: 004 | loss: 0.67719 - acc: 0.6941 -- iter: 192/292
[A[ATraining Step: 37  | total loss: [1m[32m0.67537[0m[0m | time: 4.131s
[2K
| Adam | epoch: 004 | loss: 0.67537 - acc: 0.6990 -- iter: 224/292
[A[ATraining Step: 38  | total loss: [1m[32m0.67901[0m[0m | time: 4.849s
[2K
| Adam | epoch: 004 | loss: 0.67901 - acc: 0.6601 -- iter: 256/292
[A[ATraining Step: 39  | total loss: [1m[32m0.67956[0m[0m | time: 5.582s
[2K
| Adam | epoch: 004 | loss: 0.67956 - acc: 0.6474 -- iter: 288/292
[A[ATraining Step: 40  | total loss: [1m[32m0.68318[0m[0m | time: 7.452s
[2K
| Adam | epoch: 004 | loss: 0.68318 - acc: 0.6197 | val_loss: 0.66286 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 41  | total loss: [1m[32m0.68335[0m[0m | time: 0.631s
[2K
| Adam | epoch: 005 | loss: 0.68335 - acc: 0.6092 -- iter: 032/292
[A[ATraining Step: 42  | total loss: [1m[32m0.68657[0m[0m | time: 1.410s
[2K
| Adam | epoch: 005 | loss: 0.68657 - acc: 0.5896 -- iter: 064/292
[A[ATraining Step: 43  | total loss: [1m[32m0.69311[0m[0m | time: 1.582s
[2K
| Adam | epoch: 005 | loss: 0.69311 - acc: 0.5572 -- iter: 096/292
[A[ATraining Step: 44  | total loss: [1m[32m0.67204[0m[0m | time: 1.701s
[2K
| Adam | epoch: 005 | loss: 0.67204 - acc: 0.6338 -- iter: 128/292
[A[ATraining Step: 45  | total loss: [1m[32m0.67755[0m[0m | time: 2.426s
[2K
| Adam | epoch: 005 | loss: 0.67755 - acc: 0.6111 -- iter: 160/292
[A[ATraining Step: 46  | total loss: [1m[32m0.67911[0m[0m | time: 3.189s
[2K
| Adam | epoch: 005 | loss: 0.67911 - acc: 0.6030 -- iter: 192/292
[A[ATraining Step: 47  | total loss: [1m[32m0.66957[0m[0m | time: 3.921s
[2K
| Adam | epoch: 005 | loss: 0.66957 - acc: 0.6271 -- iter: 224/292
[A[ATraining Step: 48  | total loss: [1m[32m0.67027[0m[0m | time: 4.658s
[2K
| Adam | epoch: 005 | loss: 0.67027 - acc: 0.6217 -- iter: 256/292
[A[ATraining Step: 49  | total loss: [1m[32m0.67771[0m[0m | time: 5.416s
[2K
| Adam | epoch: 005 | loss: 0.67771 - acc: 0.6025 -- iter: 288/292
[A[ATraining Step: 50  | total loss: [1m[32m0.67801[0m[0m | time: 7.173s
[2K
| Adam | epoch: 005 | loss: 0.67801 - acc: 0.6011 | val_loss: 0.64924 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 51  | total loss: [1m[32m0.68255[0m[0m | time: 0.760s
[2K
| Adam | epoch: 006 | loss: 0.68255 - acc: 0.5905 -- iter: 032/292
[A[ATraining Step: 52  | total loss: [1m[32m0.68604[0m[0m | time: 1.487s
[2K
| Adam | epoch: 006 | loss: 0.68604 - acc: 0.5816 -- iter: 064/292
[A[ATraining Step: 53  | total loss: [1m[32m0.68880[0m[0m | time: 2.210s
[2K
| Adam | epoch: 006 | loss: 0.68880 - acc: 0.5742 -- iter: 096/292
[A[ATraining Step: 54  | total loss: [1m[32m0.67746[0m[0m | time: 2.327s
[2K
| Adam | epoch: 006 | loss: 0.67746 - acc: 0.5997 -- iter: 128/292
[A[ATraining Step: 55  | total loss: [1m[32m0.68244[0m[0m | time: 2.431s
[2K
| Adam | epoch: 006 | loss: 0.68244 - acc: 0.5854 -- iter: 160/292
[A[ATraining Step: 56  | total loss: [1m[32m0.67341[0m[0m | time: 3.183s
[2K
| Adam | epoch: 006 | loss: 0.67341 - acc: 0.6086 -- iter: 192/292
[A[ATraining Step: 57  | total loss: [1m[32m0.66891[0m[0m | time: 3.924s
[2K
| Adam | epoch: 006 | loss: 0.66891 - acc: 0.6195 -- iter: 224/292
[A[ATraining Step: 58  | total loss: [1m[32m0.67800[0m[0m | time: 4.658s
[2K
| Adam | epoch: 006 | loss: 0.67800 - acc: 0.5947 -- iter: 256/292
[A[ATraining Step: 59  | total loss: [1m[32m0.67477[0m[0m | time: 5.392s
[2K
| Adam | epoch: 006 | loss: 0.67477 - acc: 0.6030 -- iter: 288/292
[A[ATraining Step: 60  | total loss: [1m[32m0.67504[0m[0m | time: 7.170s
[2K
| Adam | epoch: 006 | loss: 0.67504 - acc: 0.6017 | val_loss: 0.65345 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 61  | total loss: [1m[32m0.67529[0m[0m | time: 0.776s
[2K
| Adam | epoch: 007 | loss: 0.67529 - acc: 0.6007 -- iter: 032/292
[A[ATraining Step: 62  | total loss: [1m[32m0.67680[0m[0m | time: 1.669s
[2K
| Adam | epoch: 007 | loss: 0.67680 - acc: 0.5958 -- iter: 064/292
[A[ATraining Step: 63  | total loss: [1m[32m0.67334[0m[0m | time: 2.518s
[2K
| Adam | epoch: 007 | loss: 0.67334 - acc: 0.6035 -- iter: 096/292
[A[ATraining Step: 64  | total loss: [1m[32m0.67529[0m[0m | time: 3.401s
[2K
| Adam | epoch: 007 | loss: 0.67529 - acc: 0.5983 -- iter: 128/292
[A[ATraining Step: 65  | total loss: [1m[32m0.67670[0m[0m | time: 3.520s
[2K
| Adam | epoch: 007 | loss: 0.67670 - acc: 0.5939 -- iter: 160/292
[A[ATraining Step: 66  | total loss: [1m[32m0.66937[0m[0m | time: 3.639s
[2K
| Adam | epoch: 007 | loss: 0.66937 - acc: 0.6129 -- iter: 192/292
[A[ATraining Step: 67  | total loss: [1m[32m0.67445[0m[0m | time: 4.536s
[2K
| Adam | epoch: 007 | loss: 0.67445 - acc: 0.5994 -- iter: 224/292
[A[ATraining Step: 68  | total loss: [1m[32m0.68027[0m[0m | time: 5.378s
[2K
| Adam | epoch: 007 | loss: 0.68027 - acc: 0.5839 -- iter: 256/292
[A[ATraining Step: 69  | total loss: [1m[32m0.67840[0m[0m | time: 6.244s
[2K
| Adam | epoch: 007 | loss: 0.67840 - acc: 0.5887 -- iter: 288/292
[A[ATraining Step: 70  | total loss: [1m[32m0.67670[0m[0m | time: 7.972s
[2K
| Adam | epoch: 007 | loss: 0.67670 - acc: 0.5929 | val_loss: 0.65439 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 71  | total loss: [1m[32m0.67549[0m[0m | time: 0.904s
[2K
| Adam | epoch: 008 | loss: 0.67549 - acc: 0.5965 -- iter: 032/292
[A[ATraining Step: 72  | total loss: [1m[32m0.67680[0m[0m | time: 1.835s
[2K
| Adam | epoch: 008 | loss: 0.67680 - acc: 0.5927 -- iter: 064/292
[A[ATraining Step: 73  | total loss: [1m[32m0.67763[0m[0m | time: 2.733s
[2K
| Adam | epoch: 008 | loss: 0.67763 - acc: 0.5894 -- iter: 096/292
[A[ATraining Step: 74  | total loss: [1m[32m0.67749[0m[0m | time: 3.676s
[2K
| Adam | epoch: 008 | loss: 0.67749 - acc: 0.5898 -- iter: 128/292
[A[ATraining Step: 75  | total loss: [1m[32m0.67475[0m[0m | time: 4.541s
[2K
| Adam | epoch: 008 | loss: 0.67475 - acc: 0.5970 -- iter: 160/292
[A[ATraining Step: 76  | total loss: [1m[32m0.67379[0m[0m | time: 4.664s
[2K
| Adam | epoch: 008 | loss: 0.67379 - acc: 0.6000 -- iter: 192/292
[A[ATraining Step: 77  | total loss: [1m[32m0.67730[0m[0m | time: 4.794s
[2K
| Adam | epoch: 008 | loss: 0.67730 - acc: 0.5894 -- iter: 224/292
[A[ATraining Step: 78  | total loss: [1m[32m0.66237[0m[0m | time: 5.592s
[2K
| Adam | epoch: 008 | loss: 0.66237 - acc: 0.6324 -- iter: 256/292
[A[ATraining Step: 79  | total loss: [1m[32m0.66373[0m[0m | time: 6.480s
[2K
| Adam | epoch: 008 | loss: 0.66373 - acc: 0.6284 -- iter: 288/292
[A[ATraining Step: 80  | total loss: [1m[32m0.66930[0m[0m | time: 8.426s
[2K
| Adam | epoch: 008 | loss: 0.66930 - acc: 0.6153 | val_loss: 0.64854 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 81  | total loss: [1m[32m0.67274[0m[0m | time: 0.878s
[2K
| Adam | epoch: 009 | loss: 0.67274 - acc: 0.6068 -- iter: 032/292
[A[ATraining Step: 82  | total loss: [1m[32m0.67300[0m[0m | time: 1.663s
[2K
| Adam | epoch: 009 | loss: 0.67300 - acc: 0.6055 -- iter: 064/292
[A[ATraining Step: 83  | total loss: [1m[32m0.67801[0m[0m | time: 2.473s
[2K
| Adam | epoch: 009 | loss: 0.67801 - acc: 0.5949 -- iter: 096/292
[A[ATraining Step: 84  | total loss: [1m[32m0.67932[0m[0m | time: 3.351s
[2K
| Adam | epoch: 009 | loss: 0.67932 - acc: 0.5917 -- iter: 128/292
[A[ATraining Step: 85  | total loss: [1m[32m0.67787[0m[0m | time: 4.221s
[2K
| Adam | epoch: 009 | loss: 0.67787 - acc: 0.5950 -- iter: 160/292
[A[ATraining Step: 86  | total loss: [1m[32m0.67389[0m[0m | time: 5.145s
[2K
| Adam | epoch: 009 | loss: 0.67389 - acc: 0.6043 -- iter: 192/292
[A[ATraining Step: 87  | total loss: [1m[32m0.67047[0m[0m | time: 5.302s
[2K
| Adam | epoch: 009 | loss: 0.67047 - acc: 0.6126 -- iter: 224/292
[A[ATraining Step: 88  | total loss: [1m[32m0.65476[0m[0m | time: 5.462s
[2K
| Adam | epoch: 009 | loss: 0.65476 - acc: 0.6513 -- iter: 256/292
[A[ATraining Step: 89  | total loss: [1m[32m0.66106[0m[0m | time: 6.322s
[2K
| Adam | epoch: 009 | loss: 0.66106 - acc: 0.6362 -- iter: 288/292
[A[ATraining Step: 90  | total loss: [1m[32m0.66129[0m[0m | time: 8.081s
[2K
| Adam | epoch: 009 | loss: 0.66129 - acc: 0.6351 | val_loss: 0.64654 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 91  | total loss: [1m[32m0.66520[0m[0m | time: 0.895s
[2K
| Adam | epoch: 010 | loss: 0.66520 - acc: 0.6278 -- iter: 032/292
[A[ATraining Step: 92  | total loss: [1m[32m0.66827[0m[0m | time: 1.845s
[2K
| Adam | epoch: 010 | loss: 0.66827 - acc: 0.6213 -- iter: 064/292
[A[ATraining Step: 93  | total loss: [1m[32m0.66752[0m[0m | time: 2.763s
[2K
| Adam | epoch: 010 | loss: 0.66752 - acc: 0.6217 -- iter: 096/292
[A[ATraining Step: 94  | total loss: [1m[32m0.67549[0m[0m | time: 3.509s
[2K
| Adam | epoch: 010 | loss: 0.67549 - acc: 0.6064 -- iter: 128/292
[A[ATraining Step: 95  | total loss: [1m[32m0.68232[0m[0m | time: 4.269s
[2K
| Adam | epoch: 010 | loss: 0.68232 - acc: 0.5926 -- iter: 160/292
[A[ATraining Step: 96  | total loss: [1m[32m0.68056[0m[0m | time: 5.145s
[2K
| Adam | epoch: 010 | loss: 0.68056 - acc: 0.5958 -- iter: 192/292
[A[ATraining Step: 97  | total loss: [1m[32m0.67732[0m[0m | time: 6.066s
[2K
| Adam | epoch: 010 | loss: 0.67732 - acc: 0.6019 -- iter: 224/292
[A[ATraining Step: 98  | total loss: [1m[32m0.67163[0m[0m | time: 6.173s
[2K
| Adam | epoch: 010 | loss: 0.67163 - acc: 0.6167 -- iter: 256/292
[A[ATraining Step: 99  | total loss: [1m[32m0.67528[0m[0m | time: 6.398s
[2K
| Adam | epoch: 010 | loss: 0.67528 - acc: 0.6050 -- iter: 288/292
[A[ATraining Step: 100  | total loss: [1m[32m0.66983[0m[0m | time: 8.328s
[2K
| Adam | epoch: 010 | loss: 0.66983 - acc: 0.6195 | val_loss: 0.65698 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 101  | total loss: [1m[32m0.66822[0m[0m | time: 0.773s
[2K
| Adam | epoch: 011 | loss: 0.66822 - acc: 0.6232 -- iter: 032/292
[A[ATraining Step: 102  | total loss: [1m[32m0.67115[0m[0m | time: 1.609s
[2K
| Adam | epoch: 011 | loss: 0.67115 - acc: 0.6140 -- iter: 064/292
[A[ATraining Step: 103  | total loss: [1m[32m0.66835[0m[0m | time: 2.523s
[2K
| Adam | epoch: 011 | loss: 0.66835 - acc: 0.6214 -- iter: 096/292
[A[ATraining Step: 104  | total loss: [1m[32m0.66812[0m[0m | time: 3.403s
[2K
| Adam | epoch: 011 | loss: 0.66812 - acc: 0.6217 -- iter: 128/292
[A[ATraining Step: 105  | total loss: [1m[32m0.67398[0m[0m | time: 4.289s
[2K
| Adam | epoch: 011 | loss: 0.67398 - acc: 0.6033 -- iter: 160/292
[A[ATraining Step: 106  | total loss: [1m[32m0.67402[0m[0m | time: 5.144s
[2K
| Adam | epoch: 011 | loss: 0.67402 - acc: 0.6023 -- iter: 192/292
[A[ATraining Step: 107  | total loss: [1m[32m0.67184[0m[0m | time: 6.125s
[2K
| Adam | epoch: 011 | loss: 0.67184 - acc: 0.6077 -- iter: 224/292
[A[ATraining Step: 108  | total loss: [1m[32m0.67455[0m[0m | time: 7.196s
[2K
| Adam | epoch: 011 | loss: 0.67455 - acc: 0.6001 -- iter: 256/292
[A[ATraining Step: 109  | total loss: [1m[32m0.67425[0m[0m | time: 7.385s
[2K
| Adam | epoch: 011 | loss: 0.67425 - acc: 0.5995 -- iter: 288/292
[A[ATraining Step: 110  | total loss: [1m[32m0.66943[0m[0m | time: 8.579s
[2K
| Adam | epoch: 011 | loss: 0.66943 - acc: 0.6145 | val_loss: 0.65138 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 111  | total loss: [1m[32m0.66453[0m[0m | time: 0.754s
[2K
| Adam | epoch: 012 | loss: 0.66453 - acc: 0.6281 -- iter: 032/292
[A[ATraining Step: 112  | total loss: [1m[32m0.65879[0m[0m | time: 1.687s
[2K
| Adam | epoch: 012 | loss: 0.65879 - acc: 0.6402 -- iter: 064/292
[A[ATraining Step: 113  | total loss: [1m[32m0.66642[0m[0m | time: 2.615s
[2K
| Adam | epoch: 012 | loss: 0.66642 - acc: 0.6231 -- iter: 096/292
[A[ATraining Step: 114  | total loss: [1m[32m0.66631[0m[0m | time: 3.506s
[2K
| Adam | epoch: 012 | loss: 0.66631 - acc: 0.6233 -- iter: 128/292
[A[ATraining Step: 115  | total loss: [1m[32m0.66424[0m[0m | time: 4.297s
[2K
| Adam | epoch: 012 | loss: 0.66424 - acc: 0.6266 -- iter: 160/292
[A[ATraining Step: 116  | total loss: [1m[32m0.66221[0m[0m | time: 5.078s
[2K
| Adam | epoch: 012 | loss: 0.66221 - acc: 0.6296 -- iter: 192/292
[A[ATraining Step: 117  | total loss: [1m[32m0.66024[0m[0m | time: 6.055s
[2K
| Adam | epoch: 012 | loss: 0.66024 - acc: 0.6322 -- iter: 224/292
[A[ATraining Step: 118  | total loss: [1m[32m0.67433[0m[0m | time: 7.009s
[2K
| Adam | epoch: 012 | loss: 0.67433 - acc: 0.6096 -- iter: 256/292
[A[ATraining Step: 119  | total loss: [1m[32m0.68242[0m[0m | time: 7.934s
[2K
| Adam | epoch: 012 | loss: 0.68242 - acc: 0.5955 -- iter: 288/292
[A[ATraining Step: 120  | total loss: [1m[32m0.67999[0m[0m | time: 9.055s
[2K
| Adam | epoch: 012 | loss: 0.67999 - acc: 0.5985 | val_loss: 0.65111 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 121  | total loss: [1m[32m0.67273[0m[0m | time: 0.200s
[2K
| Adam | epoch: 013 | loss: 0.67273 - acc: 0.6136 -- iter: 032/292
[A[ATraining Step: 122  | total loss: [1m[32m0.67551[0m[0m | time: 0.985s
[2K
| Adam | epoch: 013 | loss: 0.67551 - acc: 0.6023 -- iter: 064/292
[A[ATraining Step: 123  | total loss: [1m[32m0.68269[0m[0m | time: 1.827s
[2K
| Adam | epoch: 013 | loss: 0.68269 - acc: 0.5827 -- iter: 096/292
[A[ATraining Step: 124  | total loss: [1m[32m0.68183[0m[0m | time: 2.859s
[2K
| Adam | epoch: 013 | loss: 0.68183 - acc: 0.5838 -- iter: 128/292
[A[ATraining Step: 125  | total loss: [1m[32m0.68290[0m[0m | time: 3.876s
[2K
| Adam | epoch: 013 | loss: 0.68290 - acc: 0.5785 -- iter: 160/292
[A[ATraining Step: 126  | total loss: [1m[32m0.68221[0m[0m | time: 4.918s
[2K
| Adam | epoch: 013 | loss: 0.68221 - acc: 0.5800 -- iter: 192/292
[A[ATraining Step: 127  | total loss: [1m[32m0.68312[0m[0m | time: 5.898s
[2K
| Adam | epoch: 013 | loss: 0.68312 - acc: 0.5752 -- iter: 224/292
[A[ATraining Step: 128  | total loss: [1m[32m0.68119[0m[0m | time: 6.789s
[2K
| Adam | epoch: 013 | loss: 0.68119 - acc: 0.5833 -- iter: 256/292
[A[ATraining Step: 129  | total loss: [1m[32m0.67765[0m[0m | time: 7.542s
[2K
| Adam | epoch: 013 | loss: 0.67765 - acc: 0.5999 -- iter: 288/292
[A[ATraining Step: 130  | total loss: [1m[32m0.67515[0m[0m | time: 9.451s
[2K
| Adam | epoch: 013 | loss: 0.67515 - acc: 0.6118 | val_loss: 0.66608 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 131  | total loss: [1m[32m0.67611[0m[0m | time: 0.121s
[2K
| Adam | epoch: 014 | loss: 0.67611 - acc: 0.6069 -- iter: 032/292
[A[ATraining Step: 132  | total loss: [1m[32m0.67786[0m[0m | time: 0.348s
[2K
| Adam | epoch: 014 | loss: 0.67786 - acc: 0.5962 -- iter: 064/292
[A[ATraining Step: 133  | total loss: [1m[32m0.67999[0m[0m | time: 1.245s
[2K
| Adam | epoch: 014 | loss: 0.67999 - acc: 0.5866 -- iter: 096/292
[A[ATraining Step: 134  | total loss: [1m[32m0.68033[0m[0m | time: 2.059s
[2K
| Adam | epoch: 014 | loss: 0.68033 - acc: 0.5842 -- iter: 128/292
[A[ATraining Step: 135  | total loss: [1m[32m0.68140[0m[0m | time: 2.801s
[2K
| Adam | epoch: 014 | loss: 0.68140 - acc: 0.5789 -- iter: 160/292
[A[ATraining Step: 136  | total loss: [1m[32m0.68088[0m[0m | time: 3.547s
[2K
| Adam | epoch: 014 | loss: 0.68088 - acc: 0.5804 -- iter: 192/292
[A[ATraining Step: 137  | total loss: [1m[32m0.67758[0m[0m | time: 4.404s
[2K
| Adam | epoch: 014 | loss: 0.67758 - acc: 0.5942 -- iter: 224/292
[A[ATraining Step: 138  | total loss: [1m[32m0.67280[0m[0m | time: 5.308s
[2K
| Adam | epoch: 014 | loss: 0.67280 - acc: 0.6160 -- iter: 256/292
[A[ATraining Step: 139  | total loss: [1m[32m0.67449[0m[0m | time: 6.186s
[2K
| Adam | epoch: 014 | loss: 0.67449 - acc: 0.6076 -- iter: 288/292
[A[ATraining Step: 140  | total loss: [1m[32m0.67459[0m[0m | time: 8.135s
[2K
| Adam | epoch: 014 | loss: 0.67459 - acc: 0.6062 | val_loss: 0.65967 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 141  | total loss: [1m[32m0.67538[0m[0m | time: 0.738s
[2K
| Adam | epoch: 015 | loss: 0.67538 - acc: 0.6018 -- iter: 032/292
[A[ATraining Step: 142  | total loss: [1m[32m0.67953[0m[0m | time: 1.023s
[2K
| Adam | epoch: 015 | loss: 0.67953 - acc: 0.5854 -- iter: 064/292
[A[ATraining Step: 143  | total loss: [1m[32m0.68208[0m[0m | time: 1.190s
[2K
| Adam | epoch: 015 | loss: 0.68208 - acc: 0.5768 -- iter: 096/292
[A[ATraining Step: 144  | total loss: [1m[32m0.69100[0m[0m | time: 2.066s
[2K
| Adam | epoch: 015 | loss: 0.69100 - acc: 0.5442 -- iter: 128/292
[A[ATraining Step: 145  | total loss: [1m[32m0.69006[0m[0m | time: 2.973s
[2K
| Adam | epoch: 015 | loss: 0.69006 - acc: 0.5460 -- iter: 160/292
[A[ATraining Step: 146  | total loss: [1m[32m0.68842[0m[0m | time: 3.774s
[2K
| Adam | epoch: 015 | loss: 0.68842 - acc: 0.5508 -- iter: 192/292
[A[ATraining Step: 147  | total loss: [1m[32m0.68855[0m[0m | time: 4.709s
[2K
| Adam | epoch: 015 | loss: 0.68855 - acc: 0.5488 -- iter: 224/292
[A[ATraining Step: 148  | total loss: [1m[32m0.68784[0m[0m | time: 5.586s
[2K
| Adam | epoch: 015 | loss: 0.68784 - acc: 0.5502 -- iter: 256/292
[A[ATraining Step: 149  | total loss: [1m[32m0.68704[0m[0m | time: 6.345s
[2K
| Adam | epoch: 015 | loss: 0.68704 - acc: 0.5514 -- iter: 288/292
[A[ATraining Step: 150  | total loss: [1m[32m0.68397[0m[0m | time: 8.090s
[2K
| Adam | epoch: 015 | loss: 0.68397 - acc: 0.5650 | val_loss: 0.66475 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 151  | total loss: [1m[32m0.68386[0m[0m | time: 0.933s
[2K
| Adam | epoch: 016 | loss: 0.68386 - acc: 0.5648 -- iter: 032/292
[A[ATraining Step: 152  | total loss: [1m[32m0.68167[0m[0m | time: 1.825s
[2K
| Adam | epoch: 016 | loss: 0.68167 - acc: 0.5739 -- iter: 064/292
[A[ATraining Step: 153  | total loss: [1m[32m0.67967[0m[0m | time: 2.033s
[2K
| Adam | epoch: 016 | loss: 0.67967 - acc: 0.5822 -- iter: 096/292
[A[ATraining Step: 154  | total loss: [1m[32m0.68660[0m[0m | time: 2.165s
[2K
| Adam | epoch: 016 | loss: 0.68660 - acc: 0.5489 -- iter: 128/292
[A[ATraining Step: 155  | total loss: [1m[32m0.68170[0m[0m | time: 2.951s
[2K
| Adam | epoch: 016 | loss: 0.68170 - acc: 0.5690 -- iter: 160/292
[A[ATraining Step: 156  | total loss: [1m[32m0.68016[0m[0m | time: 3.805s
[2K
| Adam | epoch: 016 | loss: 0.68016 - acc: 0.5746 -- iter: 192/292
[A[ATraining Step: 157  | total loss: [1m[32m0.67955[0m[0m | time: 4.727s
[2K
| Adam | epoch: 016 | loss: 0.67955 - acc: 0.5766 -- iter: 224/292
[A[ATraining Step: 158  | total loss: [1m[32m0.68166[0m[0m | time: 5.669s
[2K
| Adam | epoch: 016 | loss: 0.68166 - acc: 0.5658 -- iter: 256/292
[A[ATraining Step: 159  | total loss: [1m[32m0.68317[0m[0m | time: 6.632s
[2K
| Adam | epoch: 016 | loss: 0.68317 - acc: 0.5592 -- iter: 288/292
[A[ATraining Step: 160  | total loss: [1m[32m0.68132[0m[0m | time: 8.606s
[2K
| Adam | epoch: 016 | loss: 0.68132 - acc: 0.5658 | val_loss: 0.66033 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 161  | total loss: [1m[32m0.67927[0m[0m | time: 0.775s
[2K
| Adam | epoch: 017 | loss: 0.67927 - acc: 0.5717 -- iter: 032/292
[A[ATraining Step: 162  | total loss: [1m[32m0.67827[0m[0m | time: 1.605s
[2K
| Adam | epoch: 017 | loss: 0.67827 - acc: 0.5739 -- iter: 064/292
[A[ATraining Step: 163  | total loss: [1m[32m0.67647[0m[0m | time: 2.464s
[2K
| Adam | epoch: 017 | loss: 0.67647 - acc: 0.5790 -- iter: 096/292
[A[ATraining Step: 164  | total loss: [1m[32m0.67377[0m[0m | time: 2.618s
[2K
| Adam | epoch: 017 | loss: 0.67377 - acc: 0.5867 -- iter: 128/292
[A[ATraining Step: 165  | total loss: [1m[32m0.66621[0m[0m | time: 2.758s
[2K
| Adam | epoch: 017 | loss: 0.66621 - acc: 0.6031 -- iter: 160/292
[A[ATraining Step: 166  | total loss: [1m[32m0.66151[0m[0m | time: 3.678s
[2K
| Adam | epoch: 017 | loss: 0.66151 - acc: 0.6178 -- iter: 192/292
[A[ATraining Step: 167  | total loss: [1m[32m0.66302[0m[0m | time: 4.589s
[2K
| Adam | epoch: 017 | loss: 0.66302 - acc: 0.6154 -- iter: 224/292
[A[ATraining Step: 168  | total loss: [1m[32m0.66377[0m[0m | time: 5.483s
[2K
| Adam | epoch: 017 | loss: 0.66377 - acc: 0.6132 -- iter: 256/292
[A[ATraining Step: 169  | total loss: [1m[32m0.66846[0m[0m | time: 6.366s
[2K
| Adam | epoch: 017 | loss: 0.66846 - acc: 0.6050 -- iter: 288/292
[A[ATraining Step: 170  | total loss: [1m[32m0.66502[0m[0m | time: 8.153s
[2K
| Adam | epoch: 017 | loss: 0.66502 - acc: 0.6101 | val_loss: 0.64223 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 171  | total loss: [1m[32m0.66213[0m[0m | time: 1.012s
[2K
| Adam | epoch: 018 | loss: 0.66213 - acc: 0.6116 -- iter: 032/292
[A[ATraining Step: 172  | total loss: [1m[32m0.66278[0m[0m | time: 1.961s
[2K
| Adam | epoch: 018 | loss: 0.66278 - acc: 0.6098 -- iter: 064/292
[A[ATraining Step: 173  | total loss: [1m[32m0.66281[0m[0m | time: 2.892s
[2K
| Adam | epoch: 018 | loss: 0.66281 - acc: 0.6082 -- iter: 096/292
[A[ATraining Step: 174  | total loss: [1m[32m0.66626[0m[0m | time: 3.851s
[2K
| Adam | epoch: 018 | loss: 0.66626 - acc: 0.5943 -- iter: 128/292
[A[ATraining Step: 175  | total loss: [1m[32m0.66423[0m[0m | time: 4.064s
[2K
| Adam | epoch: 018 | loss: 0.66423 - acc: 0.6005 -- iter: 160/292
[A[ATraining Step: 176  | total loss: [1m[32m0.65949[0m[0m | time: 4.286s
[2K
| Adam | epoch: 018 | loss: 0.65949 - acc: 0.6154 -- iter: 192/292
[A[ATraining Step: 177  | total loss: [1m[32m0.65497[0m[0m | time: 5.646s
[2K
| Adam | epoch: 018 | loss: 0.65497 - acc: 0.6289 -- iter: 224/292
[A[ATraining Step: 178  | total loss: [1m[32m0.65232[0m[0m | time: 6.797s
[2K
| Adam | epoch: 018 | loss: 0.65232 - acc: 0.6316 -- iter: 256/292
[A[ATraining Step: 179  | total loss: [1m[32m0.65729[0m[0m | time: 7.597s
[2K
| Adam | epoch: 018 | loss: 0.65729 - acc: 0.6185 -- iter: 288/292
[A[ATraining Step: 180  | total loss: [1m[32m0.65993[0m[0m | time: 9.438s
[2K
| Adam | epoch: 018 | loss: 0.65993 - acc: 0.6097 | val_loss: 0.63690 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 181  | total loss: [1m[32m0.65466[0m[0m | time: 0.798s
[2K
| Adam | epoch: 019 | loss: 0.65466 - acc: 0.6144 -- iter: 032/292
[A[ATraining Step: 182  | total loss: [1m[32m0.66139[0m[0m | time: 1.819s
[2K
| Adam | epoch: 019 | loss: 0.66139 - acc: 0.5998 -- iter: 064/292
[A[ATraining Step: 183  | total loss: [1m[32m0.65913[0m[0m | time: 2.822s
[2K
| Adam | epoch: 019 | loss: 0.65913 - acc: 0.6023 -- iter: 096/292
[A[ATraining Step: 184  | total loss: [1m[32m0.65905[0m[0m | time: 3.783s
[2K
| Adam | epoch: 019 | loss: 0.65905 - acc: 0.5952 -- iter: 128/292
[A[ATraining Step: 185  | total loss: [1m[32m0.65583[0m[0m | time: 4.713s
[2K
| Adam | epoch: 019 | loss: 0.65583 - acc: 0.5982 -- iter: 160/292
[A[ATraining Step: 186  | total loss: [1m[32m0.64934[0m[0m | time: 4.860s
[2K
| Adam | epoch: 019 | loss: 0.64934 - acc: 0.6134 -- iter: 192/292
[A[ATraining Step: 187  | total loss: [1m[32m0.65494[0m[0m | time: 4.995s
[2K
| Adam | epoch: 019 | loss: 0.65494 - acc: 0.6020 -- iter: 224/292
[A[ATraining Step: 188  | total loss: [1m[32m0.65914[0m[0m | time: 5.936s
[2K
| Adam | epoch: 019 | loss: 0.65914 - acc: 0.5918 -- iter: 256/292
[A[ATraining Step: 189  | total loss: [1m[32m0.65488[0m[0m | time: 6.674s
[2K
| Adam | epoch: 019 | loss: 0.65488 - acc: 0.5952 -- iter: 288/292
[A[ATraining Step: 190  | total loss: [1m[32m0.64725[0m[0m | time: 8.502s
[2K
| Adam | epoch: 019 | loss: 0.64725 - acc: 0.6044 | val_loss: 0.62412 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 191  | total loss: [1m[32m0.64295[0m[0m | time: 0.857s
[2K
| Adam | epoch: 020 | loss: 0.64295 - acc: 0.6002 -- iter: 032/292
[A[ATraining Step: 192  | total loss: [1m[32m0.65254[0m[0m | time: 1.965s
[2K
| Adam | epoch: 020 | loss: 0.65254 - acc: 0.5808 -- iter: 064/292
[A[ATraining Step: 193  | total loss: [1m[32m0.64636[0m[0m | time: 2.802s
[2K
| Adam | epoch: 020 | loss: 0.64636 - acc: 0.5790 -- iter: 096/292
[A[ATraining Step: 194  | total loss: [1m[32m0.64240[0m[0m | time: 3.543s
[2K
| Adam | epoch: 020 | loss: 0.64240 - acc: 0.5930 -- iter: 128/292
[A[ATraining Step: 195  | total loss: [1m[32m0.64343[0m[0m | time: 4.495s
[2K
| Adam | epoch: 020 | loss: 0.64343 - acc: 0.5993 -- iter: 160/292
[A[ATraining Step: 196  | total loss: [1m[32m0.64116[0m[0m | time: 5.398s
[2K
| Adam | epoch: 020 | loss: 0.64116 - acc: 0.6019 -- iter: 192/292
[A[ATraining Step: 197  | total loss: [1m[32m0.64067[0m[0m | time: 5.516s
[2K
| Adam | epoch: 020 | loss: 0.64067 - acc: 0.6135 -- iter: 224/292
[A[ATraining Step: 198  | total loss: [1m[32m0.64160[0m[0m | time: 5.632s
[2K
| Adam | epoch: 020 | loss: 0.64160 - acc: 0.6022 -- iter: 256/292
[A[ATraining Step: 199  | total loss: [1m[32m0.66760[0m[0m | time: 6.626s
[2K
| Adam | epoch: 020 | loss: 0.66760 - acc: 0.5920 -- iter: 288/292
[A[ATraining Step: 200  | total loss: [1m[32m0.65992[0m[0m | time: 8.683s
[2K
| Adam | epoch: 020 | loss: 0.65992 - acc: 0.6109 | val_loss: 0.75819 - val_acc: 0.3587 -- iter: 292/292
--
Training Step: 201  | total loss: [1m[32m0.65809[0m[0m | time: 0.908s
[2K
| Adam | epoch: 021 | loss: 0.65809 - acc: 0.6186 -- iter: 032/292
[A[ATraining Step: 202  | total loss: [1m[32m0.66688[0m[0m | time: 1.816s
[2K
| Adam | epoch: 021 | loss: 0.66688 - acc: 0.5942 -- iter: 064/292
[A[ATraining Step: 203  | total loss: [1m[32m0.66972[0m[0m | time: 2.807s
[2K
| Adam | epoch: 021 | loss: 0.66972 - acc: 0.5879 -- iter: 096/292
[A[ATraining Step: 204  | total loss: [1m[32m0.67392[0m[0m | time: 3.718s
[2K
| Adam | epoch: 021 | loss: 0.67392 - acc: 0.5729 -- iter: 128/292
[A[ATraining Step: 205  | total loss: [1m[32m0.67466[0m[0m | time: 4.618s
[2K
| Adam | epoch: 021 | loss: 0.67466 - acc: 0.5687 -- iter: 160/292
[A[ATraining Step: 206  | total loss: [1m[32m0.67560[0m[0m | time: 5.601s
[2K
| Adam | epoch: 021 | loss: 0.67560 - acc: 0.5618 -- iter: 192/292
[A[ATraining Step: 207  | total loss: [1m[32m0.67071[0m[0m | time: 6.396s
[2K
| Adam | epoch: 021 | loss: 0.67071 - acc: 0.5838 -- iter: 224/292
[A[ATraining Step: 208  | total loss: [1m[32m0.66682[0m[0m | time: 6.501s
[2K
| Adam | epoch: 021 | loss: 0.66682 - acc: 0.5973 -- iter: 256/292
[A[ATraining Step: 209  | total loss: [1m[32m0.67233[0m[0m | time: 6.606s
[2K
| Adam | epoch: 021 | loss: 0.67233 - acc: 0.5625 -- iter: 288/292
[A[ATraining Step: 210  | total loss: [1m[32m0.65771[0m[0m | time: 8.411s
[2K
| Adam | epoch: 021 | loss: 0.65771 - acc: 0.6063 | val_loss: 0.62642 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 211  | total loss: [1m[32m0.65533[0m[0m | time: 1.002s
[2K
| Adam | epoch: 022 | loss: 0.65533 - acc: 0.6050 -- iter: 032/292
[A[ATraining Step: 212  | total loss: [1m[32m0.65604[0m[0m | time: 1.989s
[2K
| Adam | epoch: 022 | loss: 0.65604 - acc: 0.6070 -- iter: 064/292
[A[ATraining Step: 213  | total loss: [1m[32m0.64946[0m[0m | time: 2.947s
[2K
| Adam | epoch: 022 | loss: 0.64946 - acc: 0.6120 -- iter: 096/292
[A[ATraining Step: 214  | total loss: [1m[32m0.63699[0m[0m | time: 3.809s
[2K
| Adam | epoch: 022 | loss: 0.63699 - acc: 0.6258 -- iter: 128/292
[A[ATraining Step: 215  | total loss: [1m[32m0.63923[0m[0m | time: 4.578s
[2K
| Adam | epoch: 022 | loss: 0.63923 - acc: 0.6226 -- iter: 160/292
[A[ATraining Step: 216  | total loss: [1m[32m0.65358[0m[0m | time: 5.353s
[2K
| Adam | epoch: 022 | loss: 0.65358 - acc: 0.6072 -- iter: 192/292
[A[ATraining Step: 217  | total loss: [1m[32m0.66363[0m[0m | time: 6.319s
[2K
| Adam | epoch: 022 | loss: 0.66363 - acc: 0.5933 -- iter: 224/292
[A[ATraining Step: 218  | total loss: [1m[32m0.65520[0m[0m | time: 7.282s
[2K
| Adam | epoch: 022 | loss: 0.65520 - acc: 0.5934 -- iter: 256/292
[A[ATraining Step: 219  | total loss: [1m[32m0.65667[0m[0m | time: 7.468s
[2K
| Adam | epoch: 022 | loss: 0.65667 - acc: 0.5872 -- iter: 288/292
[A[ATraining Step: 220  | total loss: [1m[32m0.64548[0m[0m | time: 8.642s
[2K
| Adam | epoch: 022 | loss: 0.64548 - acc: 0.6284 | val_loss: 0.63140 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 221  | total loss: [1m[32m0.64360[0m[0m | time: 1.136s
[2K
| Adam | epoch: 023 | loss: 0.64360 - acc: 0.6406 -- iter: 032/292
[A[ATraining Step: 222  | total loss: [1m[32m0.64787[0m[0m | time: 1.995s
[2K
| Adam | epoch: 023 | loss: 0.64787 - acc: 0.6297 -- iter: 064/292
[A[ATraining Step: 223  | total loss: [1m[32m0.64297[0m[0m | time: 2.822s
[2K
| Adam | epoch: 023 | loss: 0.64297 - acc: 0.6323 -- iter: 096/292
[A[ATraining Step: 224  | total loss: [1m[32m0.64736[0m[0m | time: 3.699s
[2K
| Adam | epoch: 023 | loss: 0.64736 - acc: 0.6191 -- iter: 128/292
[A[ATraining Step: 225  | total loss: [1m[32m0.64437[0m[0m | time: 4.635s
[2K
| Adam | epoch: 023 | loss: 0.64437 - acc: 0.6134 -- iter: 160/292
[A[ATraining Step: 226  | total loss: [1m[32m0.64612[0m[0m | time: 5.626s
[2K
| Adam | epoch: 023 | loss: 0.64612 - acc: 0.6021 -- iter: 192/292
[A[ATraining Step: 227  | total loss: [1m[32m0.63616[0m[0m | time: 6.472s
[2K
| Adam | epoch: 023 | loss: 0.63616 - acc: 0.6044 -- iter: 224/292
[A[ATraining Step: 228  | total loss: [1m[32m0.63512[0m[0m | time: 7.303s
[2K
| Adam | epoch: 023 | loss: 0.63512 - acc: 0.6064 -- iter: 256/292
[A[ATraining Step: 229  | total loss: [1m[32m0.62207[0m[0m | time: 8.330s
[2K
| Adam | epoch: 023 | loss: 0.62207 - acc: 0.6145 -- iter: 288/292
[A[ATraining Step: 230  | total loss: [1m[32m0.61500[0m[0m | time: 9.541s
[2K
| Adam | epoch: 023 | loss: 0.61500 - acc: 0.6187 | val_loss: 0.62648 - val_acc: 0.6522 -- iter: 292/292
--
Training Step: 231  | total loss: [1m[32m0.60055[0m[0m | time: 0.171s
[2K
| Adam | epoch: 024 | loss: 0.60055 - acc: 0.6318 -- iter: 032/292
[A[ATraining Step: 232  | total loss: [1m[32m0.61372[0m[0m | time: 1.171s
[2K
| Adam | epoch: 024 | loss: 0.61372 - acc: 0.6437 -- iter: 064/292
[A[ATraining Step: 233  | total loss: [1m[32m0.60055[0m[0m | time: 1.984s
[2K
| Adam | epoch: 024 | loss: 0.60055 - acc: 0.6512 -- iter: 096/292
[A[ATraining Step: 234  | total loss: [1m[32m0.59630[0m[0m | time: 2.900s
[2K
| Adam | epoch: 024 | loss: 0.59630 - acc: 0.6611 -- iter: 128/292
[A[ATraining Step: 235  | total loss: [1m[32m0.59546[0m[0m | time: 4.077s
[2K
| Adam | epoch: 024 | loss: 0.59546 - acc: 0.6731 -- iter: 160/292
[A[ATraining Step: 236  | total loss: [1m[32m0.58963[0m[0m | time: 5.106s
[2K
| Adam | epoch: 024 | loss: 0.58963 - acc: 0.6901 -- iter: 192/292
[A[ATraining Step: 237  | total loss: [1m[32m0.58706[0m[0m | time: 6.021s
[2K
| Adam | epoch: 024 | loss: 0.58706 - acc: 0.6961 -- iter: 224/292
[A[ATraining Step: 238  | total loss: [1m[32m0.59160[0m[0m | time: 6.952s
[2K
| Adam | epoch: 024 | loss: 0.59160 - acc: 0.7046 -- iter: 256/292
[A[ATraining Step: 239  | total loss: [1m[32m0.58609[0m[0m | time: 7.880s
[2K
| Adam | epoch: 024 | loss: 0.58609 - acc: 0.7123 -- iter: 288/292
[A[ATraining Step: 240  | total loss: [1m[32m0.59159[0m[0m | time: 9.667s
[2K
| Adam | epoch: 024 | loss: 0.59159 - acc: 0.7067 | val_loss: 0.63470 - val_acc: 0.7283 -- iter: 292/292
--
Training Step: 241  | total loss: [1m[32m0.58313[0m[0m | time: 0.131s
[2K
| Adam | epoch: 025 | loss: 0.58313 - acc: 0.7173 -- iter: 032/292
[A[ATraining Step: 242  | total loss: [1m[32m0.58509[0m[0m | time: 0.307s
[2K
| Adam | epoch: 025 | loss: 0.58509 - acc: 0.6955 -- iter: 064/292
[A[ATraining Step: 243  | total loss: [1m[32m0.61765[0m[0m | time: 1.297s
[2K
| Adam | epoch: 025 | loss: 0.61765 - acc: 0.7010 -- iter: 096/292
[A[ATraining Step: 244  | total loss: [1m[32m0.60121[0m[0m | time: 2.277s
[2K
| Adam | epoch: 025 | loss: 0.60121 - acc: 0.7153 -- iter: 128/292
[A[ATraining Step: 245  | total loss: [1m[32m0.59696[0m[0m | time: 3.084s
[2K
| Adam | epoch: 025 | loss: 0.59696 - acc: 0.7156 -- iter: 160/292
[A[ATraining Step: 246  | total loss: [1m[32m0.58502[0m[0m | time: 3.945s
[2K
| Adam | epoch: 025 | loss: 0.58502 - acc: 0.7191 -- iter: 192/292
[A[ATraining Step: 247  | total loss: [1m[32m0.57857[0m[0m | time: 4.994s
[2K
| Adam | epoch: 025 | loss: 0.57857 - acc: 0.7159 -- iter: 224/292
[A[ATraining Step: 248  | total loss: [1m[32m0.57110[0m[0m | time: 6.060s
[2K
| Adam | epoch: 025 | loss: 0.57110 - acc: 0.7193 -- iter: 256/292
[A[ATraining Step: 249  | total loss: [1m[32m0.57263[0m[0m | time: 7.214s
[2K
| Adam | epoch: 025 | loss: 0.57263 - acc: 0.7130 -- iter: 288/292
[A[ATraining Step: 250  | total loss: [1m[32m0.55893[0m[0m | time: 9.752s
[2K
| Adam | epoch: 025 | loss: 0.55893 - acc: 0.7355 | val_loss: 0.71589 - val_acc: 0.5543 -- iter: 292/292
--
Training Step: 251  | total loss: [1m[32m0.55787[0m[0m | time: 0.720s
[2K
| Adam | epoch: 026 | loss: 0.55787 - acc: 0.7338 -- iter: 032/292
[A[ATraining Step: 252  | total loss: [1m[32m0.56965[0m[0m | time: 0.862s
[2K
| Adam | epoch: 026 | loss: 0.56965 - acc: 0.7229 -- iter: 064/292
[A[ATraining Step: 253  | total loss: [1m[32m0.57447[0m[0m | time: 0.984s
[2K
| Adam | epoch: 026 | loss: 0.57447 - acc: 0.7006 -- iter: 096/292
[A[ATraining Step: 254  | total loss: [1m[32m0.56744[0m[0m | time: 1.984s
[2K
| Adam | epoch: 026 | loss: 0.56744 - acc: 0.7056 -- iter: 128/292
[A[ATraining Step: 255  | total loss: [1m[32m0.56395[0m[0m | time: 3.093s
[2K
| Adam | epoch: 026 | loss: 0.56395 - acc: 0.7100 -- iter: 160/292
[A[ATraining Step: 256  | total loss: [1m[32m0.54547[0m[0m | time: 4.130s
[2K
| Adam | epoch: 026 | loss: 0.54547 - acc: 0.7171 -- iter: 192/292
[A[ATraining Step: 257  | total loss: [1m[32m0.54083[0m[0m | time: 5.185s
[2K
| Adam | epoch: 026 | loss: 0.54083 - acc: 0.7235 -- iter: 224/292
[A[ATraining Step: 258  | total loss: [1m[32m0.54849[0m[0m | time: 6.208s
[2K
| Adam | epoch: 026 | loss: 0.54849 - acc: 0.7231 -- iter: 256/292
[A[ATraining Step: 259  | total loss: [1m[32m0.55244[0m[0m | time: 7.175s
[2K
| Adam | epoch: 026 | loss: 0.55244 - acc: 0.7195 -- iter: 288/292
[A[ATraining Step: 260  | total loss: [1m[32m0.54012[0m[0m | time: 9.021s
[2K
| Adam | epoch: 026 | loss: 0.54012 - acc: 0.7288 | val_loss: 0.70308 - val_acc: 0.5978 -- iter: 292/292
--
Training Step: 261  | total loss: [1m[32m0.52275[0m[0m | time: 0.853s
[2K
| Adam | epoch: 027 | loss: 0.52275 - acc: 0.7465 -- iter: 032/292
[A[ATraining Step: 262  | total loss: [1m[32m0.53141[0m[0m | time: 1.617s
[2K
| Adam | epoch: 027 | loss: 0.53141 - acc: 0.7344 -- iter: 064/292
[A[ATraining Step: 263  | total loss: [1m[32m0.54174[0m[0m | time: 1.737s
[2K
| Adam | epoch: 027 | loss: 0.54174 - acc: 0.7328 -- iter: 096/292
[A[ATraining Step: 264  | total loss: [1m[32m0.52459[0m[0m | time: 1.843s
[2K
| Adam | epoch: 027 | loss: 0.52459 - acc: 0.7595 -- iter: 128/292
[A[ATraining Step: 265  | total loss: [1m[32m0.53017[0m[0m | time: 2.595s
[2K
| Adam | epoch: 027 | loss: 0.53017 - acc: 0.7336 -- iter: 160/292
[A[ATraining Step: 266  | total loss: [1m[32m0.52116[0m[0m | time: 3.364s
[2K
| Adam | epoch: 027 | loss: 0.52116 - acc: 0.7477 -- iter: 192/292
[A[ATraining Step: 267  | total loss: [1m[32m0.50605[0m[0m | time: 4.107s
[2K
| Adam | epoch: 027 | loss: 0.50605 - acc: 0.7573 -- iter: 224/292
[A[ATraining Step: 268  | total loss: [1m[32m0.49795[0m[0m | time: 4.838s
[2K
| Adam | epoch: 027 | loss: 0.49795 - acc: 0.7597 -- iter: 256/292
[A[ATraining Step: 269  | total loss: [1m[32m0.50791[0m[0m | time: 5.590s
[2K
| Adam | epoch: 027 | loss: 0.50791 - acc: 0.7525 -- iter: 288/292
[A[ATraining Step: 270  | total loss: [1m[32m0.51123[0m[0m | time: 7.335s
[2K
| Adam | epoch: 027 | loss: 0.51123 - acc: 0.7429 | val_loss: 0.61496 - val_acc: 0.7391 -- iter: 292/292
--
Training Step: 271  | total loss: [1m[32m0.49393[0m[0m | time: 0.757s
[2K
| Adam | epoch: 028 | loss: 0.49393 - acc: 0.7561 -- iter: 032/292
[A[ATraining Step: 272  | total loss: [1m[32m0.48085[0m[0m | time: 1.498s
[2K
| Adam | epoch: 028 | loss: 0.48085 - acc: 0.7586 -- iter: 064/292
[A[ATraining Step: 273  | total loss: [1m[32m0.47052[0m[0m | time: 2.234s
[2K
| Adam | epoch: 028 | loss: 0.47052 - acc: 0.7640 -- iter: 096/292
[A[ATraining Step: 274  | total loss: [1m[32m0.46954[0m[0m | time: 2.337s
[2K
| Adam | epoch: 028 | loss: 0.46954 - acc: 0.7720 -- iter: 128/292
[A[ATraining Step: 275  | total loss: [1m[32m0.44676[0m[0m | time: 2.440s
[2K
| Adam | epoch: 028 | loss: 0.44676 - acc: 0.7948 -- iter: 160/292
[A[ATraining Step: 276  | total loss: [1m[32m0.50703[0m[0m | time: 3.212s
[2K
| Adam | epoch: 028 | loss: 0.50703 - acc: 0.7903 -- iter: 192/292
[A[ATraining Step: 277  | total loss: [1m[32m0.48755[0m[0m | time: 4.038s
[2K
| Adam | epoch: 028 | loss: 0.48755 - acc: 0.8019 -- iter: 224/292
[A[ATraining Step: 278  | total loss: [1m[32m0.47594[0m[0m | time: 4.828s
[2K
| Adam | epoch: 028 | loss: 0.47594 - acc: 0.8061 -- iter: 256/292
[A[ATraining Step: 279  | total loss: [1m[32m0.47006[0m[0m | time: 5.606s
[2K
| Adam | epoch: 028 | loss: 0.47006 - acc: 0.8067 -- iter: 288/292
[A[ATraining Step: 280  | total loss: [1m[32m0.46132[0m[0m | time: 7.387s
[2K
| Adam | epoch: 028 | loss: 0.46132 - acc: 0.8073 | val_loss: 0.59073 - val_acc: 0.7500 -- iter: 292/292
--
Training Step: 281  | total loss: [1m[32m0.45111[0m[0m | time: 0.796s
[2K
| Adam | epoch: 029 | loss: 0.45111 - acc: 0.8141 -- iter: 032/292
[A[ATraining Step: 282  | total loss: [1m[32m0.44241[0m[0m | time: 1.546s
[2K
| Adam | epoch: 029 | loss: 0.44241 - acc: 0.8077 -- iter: 064/292
[A[ATraining Step: 283  | total loss: [1m[32m0.44393[0m[0m | time: 2.340s
[2K
| Adam | epoch: 029 | loss: 0.44393 - acc: 0.8081 -- iter: 096/292
[A[ATraining Step: 284  | total loss: [1m[32m0.42624[0m[0m | time: 3.094s
[2K
| Adam | epoch: 029 | loss: 0.42624 - acc: 0.8242 -- iter: 128/292
[A[ATraining Step: 285  | total loss: [1m[32m0.42238[0m[0m | time: 3.193s
[2K
| Adam | epoch: 029 | loss: 0.42238 - acc: 0.8262 -- iter: 160/292
[A[ATraining Step: 286  | total loss: [1m[32m0.40705[0m[0m | time: 3.326s
[2K
| Adam | epoch: 029 | loss: 0.40705 - acc: 0.8435 -- iter: 192/292
[A[ATraining Step: 287  | total loss: [1m[32m0.39368[0m[0m | time: 4.047s
[2K
| Adam | epoch: 029 | loss: 0.39368 - acc: 0.8592 -- iter: 224/292
[A[ATraining Step: 288  | total loss: [1m[32m0.38283[0m[0m | time: 4.841s
[2K
| Adam | epoch: 029 | loss: 0.38283 - acc: 0.8670 -- iter: 256/292
[A[ATraining Step: 289  | total loss: [1m[32m0.37300[0m[0m | time: 5.615s
[2K
| Adam | epoch: 029 | loss: 0.37300 - acc: 0.8741 -- iter: 288/292
[A[ATraining Step: 290  | total loss: [1m[32m0.36524[0m[0m | time: 7.361s
[2K
| Adam | epoch: 029 | loss: 0.36524 - acc: 0.8742 | val_loss: 0.67381 - val_acc: 0.7717 -- iter: 292/292
--
Training Step: 291  | total loss: [1m[32m0.40559[0m[0m | time: 0.776s
[2K
| Adam | epoch: 030 | loss: 0.40559 - acc: 0.8492 -- iter: 032/292
[A[ATraining Step: 292  | total loss: [1m[32m0.38050[0m[0m | time: 1.605s
[2K
| Adam | epoch: 030 | loss: 0.38050 - acc: 0.8581 -- iter: 064/292
[A[ATraining Step: 293  | total loss: [1m[32m0.38235[0m[0m | time: 2.415s
[2K
| Adam | epoch: 030 | loss: 0.38235 - acc: 0.8535 -- iter: 096/292
[A[ATraining Step: 294  | total loss: [1m[32m0.37915[0m[0m | time: 3.199s
[2K
| Adam | epoch: 030 | loss: 0.37915 - acc: 0.8557 -- iter: 128/292
[A[ATraining Step: 295  | total loss: [1m[32m0.37124[0m[0m | time: 3.972s
[2K
| Adam | epoch: 030 | loss: 0.37124 - acc: 0.8576 -- iter: 160/292
[A[ATraining Step: 296  | total loss: [1m[32m0.35912[0m[0m | time: 4.140s
[2K
| Adam | epoch: 030 | loss: 0.35912 - acc: 0.8687 -- iter: 192/292
[A[ATraining Step: 297  | total loss: [1m[32m0.33044[0m[0m | time: 4.280s
[2K
| Adam | epoch: 030 | loss: 0.33044 - acc: 0.8818 -- iter: 224/292
[A[ATraining Step: 298  | total loss: [1m[32m0.38720[0m[0m | time: 5.000s
[2K
| Adam | epoch: 030 | loss: 0.38720 - acc: 0.8687 -- iter: 256/292
[A[ATraining Step: 299  | total loss: [1m[32m0.37341[0m[0m | time: 5.760s
[2K
| Adam | epoch: 030 | loss: 0.37341 - acc: 0.8693 -- iter: 288/292
[A[ATraining Step: 300  | total loss: [1m[32m0.37287[0m[0m | time: 7.500s
[2K
| Adam | epoch: 030 | loss: 0.37287 - acc: 0.8699 | val_loss: 0.70402 - val_acc: 0.6630 -- iter: 292/292
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7255208333333334
Validation AUPRC:0.7599559899298793
Test AUC:0.8026124818577649
Test AUPRC:0.8346183786419097
BestTestF1Score	0.79	0.46	0.74	0.74	0.85	45	16	23	8	0.2
BestTestMCCScore	0.79	0.46	0.74	0.74	0.85	45	16	23	8	0.2
BestTestAccuracyScore	0.79	0.46	0.74	0.74	0.85	45	16	23	8	0.2
BestValidationF1Score	0.83	0.45	0.76	0.77	0.9	54	16	16	6	0.2
BestValidationMCC	0.83	0.45	0.76	0.77	0.9	54	16	16	6	0.2
BestValidationAccuracy	0.83	0.45	0.76	0.77	0.9	54	16	16	6	0.2
TestPredictions (Threshold:0.2)
CHEMBL3670664,TP,ACT,0.8399999737739563	CHEMBL2323287,TN,INACT,0.10999999940395355	CHEMBL1767043,TN,INACT,0.05000000074505806	CHEMBL3260857,TP,ACT,0.4300000071525574	CHEMBL484073,FN,ACT,0.10000000149011612	CHEMBL3692652,TP,ACT,0.9599999785423279	CHEMBL389688,TP,ACT,0.9599999785423279	CHEMBL461142,FN,ACT,0.11999999731779099	CHEMBL1767029,TN,INACT,0.07000000029802322	CHEMBL3605495,TN,INACT,0.029999999329447746	CHEMBL3693713,TP,ACT,0.9599999785423279	CHEMBL482358,TP,ACT,0.8899999856948853	CHEMBL3605496,TN,INACT,0.03999999910593033	CHEMBL3417292,FP,INACT,0.33000001311302185	CHEMBL3640667,TP,ACT,0.8799999952316284	CHEMBL2381518,FN,ACT,0.07000000029802322	CHEMBL3235464,FP,INACT,0.5400000214576721	CHEMBL1934902,TN,INACT,0.05999999865889549	CHEMBL1088735,TP,ACT,0.3100000023841858	CHEMBL505199,TN,INACT,0.05999999865889549	CHEMBL1171228,FP,INACT,0.6899999976158142	CHEMBL1214763,TP,ACT,0.25	CHEMBL3318732,FP,INACT,0.3199999928474426	CHEMBL3770029,TP,ACT,0.8999999761581421	CHEMBL3605493,TN,INACT,0.03999999910593033	CHEMBL3357482,TP,ACT,0.28999999165534973	CHEMBL561909,TN,INACT,0.05999999865889549	CHEMBL1767047,FP,INACT,0.28999999165534973	CHEMBL3693783,TP,ACT,0.8100000023841858	CHEMBL3735736,TP,ACT,0.2199999988079071	CHEMBL3655966,TP,ACT,0.9599999785423279	CHEMBL515295,FN,ACT,0.07000000029802322	CHEMBL481538,TP,ACT,0.9599999785423279	CHEMBL3415449,FP,INACT,0.9599999785423279	CHEMBL3759791,TP,ACT,0.8500000238418579	CHEMBL1164225,FP,INACT,0.20000000298023224	CHEMBL2431902,TP,ACT,0.7400000095367432	CHEMBL1097761,TP,ACT,0.9100000262260437	CHEMBL1091475,TP,ACT,0.7699999809265137	CHEMBL492140,TN,INACT,0.05000000074505806	CHEMBL256655,FP,INACT,0.28999999165534973	CHEMBL470470,TP,ACT,0.9300000071525574	CHEMBL2407734,TN,INACT,0.029999999329447746	CHEMBL3314862,TP,ACT,0.30000001192092896	CHEMBL1767041,TN,INACT,0.07000000029802322	CHEMBL3109980,TN,INACT,0.05999999865889549	CHEMBL3656004,TP,ACT,0.9399999976158142	CHEMBL2408696,TP,ACT,0.3199999928474426	CHEMBL140000,TP,ACT,0.25	CHEMBL1767035,TN,INACT,0.07000000029802322	CHEMBL2046612,TN,INACT,0.10999999940395355	CHEMBL515432,FP,INACT,0.5799999833106995	CHEMBL1098042,TP,ACT,0.23000000417232513	CHEMBL3621293,TP,ACT,0.7900000214576721	CHEMBL513589,FP,INACT,0.9100000262260437	CHEMBL468527,FN,ACT,0.07000000029802322	CHEMBL3110023,TN,INACT,0.05000000074505806	CHEMBL1094152,TP,ACT,0.8899999856948853	CHEMBL503,FP,INACT,0.4099999964237213	CHEMBL1836143,TP,ACT,0.3799999952316284	CHEMBL3110278,FN,ACT,0.11999999731779099	CHEMBL16300,TP,ACT,0.6299999952316284	CHEMBL3310510,TN,INACT,0.12999999523162842	CHEMBL492097,TP,ACT,0.8799999952316284	CHEMBL3110285,TP,ACT,0.699999988079071	CHEMBL1478023,TN,INACT,0.1599999964237213	CHEMBL3655949,TP,ACT,0.75	CHEMBL2381520,FN,ACT,0.07000000029802322	CHEMBL3589351,TP,ACT,0.7599999904632568	CHEMBL3527525,TN,INACT,0.05000000074505806	CHEMBL3356938,FP,INACT,0.27000001072883606	CHEMBL3692645,TP,ACT,0.4699999988079071	CHEMBL2011672,TN,INACT,0.09000000357627869	CHEMBL1934891,FP,INACT,0.36000001430511475	CHEMBL585554,TP,ACT,0.9200000166893005	CHEMBL2323290,FP,INACT,0.3199999928474426	CHEMBL1934890,TN,INACT,0.10999999940395355	CHEMBL469134,FN,ACT,0.05000000074505806	CHEMBL1808672,FP,INACT,0.25999999046325684	CHEMBL2011674,TN,INACT,0.15000000596046448	CHEMBL3356929,TP,ACT,0.8700000047683716	CHEMBL3655926,TP,ACT,0.49000000953674316	CHEMBL451289,TP,ACT,0.2800000011920929	CHEMBL3693731,TP,ACT,0.7400000095367432	CHEMBL481955,TP,ACT,0.20999999344348907	CHEMBL2323289,TN,INACT,0.07999999821186066	CHEMBL442661,FP,INACT,0.4300000071525574	CHEMBL3098695,TP,ACT,0.8799999952316284	CHEMBL356066,TP,ACT,0.23999999463558197	CHEMBL3759166,TP,ACT,0.550000011920929	CHEMBL3601332,TP,ACT,0.8700000047683716	CHEMBL3353064,TP,ACT,0.8399999737739563	

