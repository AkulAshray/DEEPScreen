CNNModel CHEMBL1936 adam 0.0005 15 256 0 0.8 False True
Number of active compounds :	824
Number of inactive compounds :	824
---------------------------------
Run id: CNNModel_CHEMBL1936_adam_0.0005_15_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1936_adam_0.0005_15_256_0.8_True/
---------------------------------
Training samples: 1001
Validation samples: 314
--
Training Step: 1  | time: 1.487s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1001
[A[ATraining Step: 2  | total loss: [1m[32m0.62387[0m[0m | time: 2.286s
[2K
| Adam | epoch: 001 | loss: 0.62387 - acc: 0.3656 -- iter: 0064/1001
[A[ATraining Step: 3  | total loss: [1m[32m0.68013[0m[0m | time: 3.261s
[2K
| Adam | epoch: 001 | loss: 0.68013 - acc: 0.5011 -- iter: 0096/1001
[A[ATraining Step: 4  | total loss: [1m[32m0.68894[0m[0m | time: 4.193s
[2K
| Adam | epoch: 001 | loss: 0.68894 - acc: 0.5237 -- iter: 0128/1001
[A[ATraining Step: 5  | total loss: [1m[32m0.69043[0m[0m | time: 5.145s
[2K
| Adam | epoch: 001 | loss: 0.69043 - acc: 0.5289 -- iter: 0160/1001
[A[ATraining Step: 6  | total loss: [1m[32m0.69330[0m[0m | time: 6.142s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.5103 -- iter: 0192/1001
[A[ATraining Step: 7  | total loss: [1m[32m0.69172[0m[0m | time: 7.141s
[2K
| Adam | epoch: 001 | loss: 0.69172 - acc: 0.5229 -- iter: 0224/1001
[A[ATraining Step: 8  | total loss: [1m[32m0.68133[0m[0m | time: 8.148s
[2K
| Adam | epoch: 001 | loss: 0.68133 - acc: 0.5979 -- iter: 0256/1001
[A[ATraining Step: 9  | total loss: [1m[32m0.69370[0m[0m | time: 9.259s
[2K
| Adam | epoch: 001 | loss: 0.69370 - acc: 0.5295 -- iter: 0288/1001
[A[ATraining Step: 10  | total loss: [1m[32m0.68106[0m[0m | time: 10.406s
[2K
| Adam | epoch: 001 | loss: 0.68106 - acc: 0.5773 -- iter: 0320/1001
[A[ATraining Step: 11  | total loss: [1m[32m0.68301[0m[0m | time: 11.573s
[2K
| Adam | epoch: 001 | loss: 0.68301 - acc: 0.5703 -- iter: 0352/1001
[A[ATraining Step: 12  | total loss: [1m[32m0.69125[0m[0m | time: 13.370s
[2K
| Adam | epoch: 001 | loss: 0.69125 - acc: 0.5386 -- iter: 0384/1001
[A[ATraining Step: 13  | total loss: [1m[32m0.69442[0m[0m | time: 14.441s
[2K
| Adam | epoch: 001 | loss: 0.69442 - acc: 0.5355 -- iter: 0416/1001
[A[ATraining Step: 14  | total loss: [1m[32m0.70219[0m[0m | time: 15.414s
[2K
| Adam | epoch: 001 | loss: 0.70219 - acc: 0.4954 -- iter: 0448/1001
[A[ATraining Step: 15  | total loss: [1m[32m0.70375[0m[0m | time: 16.445s
[2K
| Adam | epoch: 001 | loss: 0.70375 - acc: 0.4727 -- iter: 0480/1001
[A[ATraining Step: 16  | total loss: [1m[32m0.70252[0m[0m | time: 17.466s
[2K
| Adam | epoch: 001 | loss: 0.70252 - acc: 0.4595 -- iter: 0512/1001
[A[ATraining Step: 17  | total loss: [1m[32m0.69718[0m[0m | time: 18.510s
[2K
| Adam | epoch: 001 | loss: 0.69718 - acc: 0.4966 -- iter: 0544/1001
[A[ATraining Step: 18  | total loss: [1m[32m0.69522[0m[0m | time: 19.601s
[2K
| Adam | epoch: 001 | loss: 0.69522 - acc: 0.5086 -- iter: 0576/1001
[A[ATraining Step: 19  | total loss: [1m[32m0.69375[0m[0m | time: 20.799s
[2K
| Adam | epoch: 001 | loss: 0.69375 - acc: 0.5370 -- iter: 0608/1001
[A[ATraining Step: 20  | total loss: [1m[32m0.69290[0m[0m | time: 21.882s
[2K
| Adam | epoch: 001 | loss: 0.69290 - acc: 0.5753 -- iter: 0640/1001
[A[ATraining Step: 21  | total loss: [1m[32m0.69290[0m[0m | time: 23.032s
[2K
| Adam | epoch: 001 | loss: 0.69290 - acc: 0.5616 -- iter: 0672/1001
[A[ATraining Step: 22  | total loss: [1m[32m0.69308[0m[0m | time: 24.244s
[2K
| Adam | epoch: 001 | loss: 0.69308 - acc: 0.5150 -- iter: 0704/1001
[A[ATraining Step: 23  | total loss: [1m[32m0.69310[0m[0m | time: 25.500s
[2K
| Adam | epoch: 001 | loss: 0.69310 - acc: 0.5016 -- iter: 0736/1001
[A[ATraining Step: 24  | total loss: [1m[32m0.69334[0m[0m | time: 28.039s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.4924 -- iter: 0768/1001
[A[ATraining Step: 25  | total loss: [1m[32m0.69320[0m[0m | time: 32.552s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5115 -- iter: 0800/1001
[A[ATraining Step: 26  | total loss: [1m[32m0.69318[0m[0m | time: 33.409s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.5167 -- iter: 0832/1001
[A[ATraining Step: 27  | total loss: [1m[32m0.69302[0m[0m | time: 34.503s
[2K
| Adam | epoch: 001 | loss: 0.69302 - acc: 0.5446 -- iter: 0864/1001
[A[ATraining Step: 28  | total loss: [1m[32m0.69320[0m[0m | time: 35.625s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5100 -- iter: 0896/1001
[A[ATraining Step: 29  | total loss: [1m[32m0.69306[0m[0m | time: 36.681s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.5152 -- iter: 0928/1001
[A[ATraining Step: 30  | total loss: [1m[32m0.69336[0m[0m | time: 37.850s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4820 -- iter: 0960/1001
[A[ATraining Step: 31  | total loss: [1m[32m0.69337[0m[0m | time: 38.959s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.4717 -- iter: 0992/1001
[A[ATraining Step: 32  | total loss: [1m[32m0.69331[0m[0m | time: 41.583s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4710 | val_loss: 0.69317 - val_acc: 0.4809 -- iter: 1001/1001
--
Training Step: 33  | total loss: [1m[32m0.69321[0m[0m | time: 0.430s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5140 -- iter: 0032/1001
[A[ATraining Step: 34  | total loss: [1m[32m0.69322[0m[0m | time: 1.655s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4991 -- iter: 0064/1001
[A[ATraining Step: 35  | total loss: [1m[32m0.69326[0m[0m | time: 2.593s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4731 -- iter: 0096/1001
[A[ATraining Step: 36  | total loss: [1m[32m0.69321[0m[0m | time: 3.342s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4978 -- iter: 0128/1001
[A[ATraining Step: 37  | total loss: [1m[32m0.69321[0m[0m | time: 4.110s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4795 -- iter: 0160/1001
[A[ATraining Step: 38  | total loss: [1m[32m0.69317[0m[0m | time: 4.847s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.5018 -- iter: 0192/1001
[A[ATraining Step: 39  | total loss: [1m[32m0.69317[0m[0m | time: 5.571s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.4895 -- iter: 0224/1001
[A[ATraining Step: 40  | total loss: [1m[32m0.69314[0m[0m | time: 6.315s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.4973 -- iter: 0256/1001
[A[ATraining Step: 41  | total loss: [1m[32m0.69314[0m[0m | time: 7.036s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5036 -- iter: 0288/1001
[A[ATraining Step: 42  | total loss: [1m[32m0.69315[0m[0m | time: 7.795s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.4973 -- iter: 0320/1001
[A[ATraining Step: 43  | total loss: [1m[32m0.69308[0m[0m | time: 8.564s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5088 -- iter: 0352/1001
[A[ATraining Step: 44  | total loss: [1m[32m0.69295[0m[0m | time: 9.304s
[2K
| Adam | epoch: 002 | loss: 0.69295 - acc: 0.5289 -- iter: 0384/1001
[A[ATraining Step: 45  | total loss: [1m[32m0.69308[0m[0m | time: 10.072s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5081 -- iter: 0416/1001
[A[ATraining Step: 46  | total loss: [1m[32m0.69300[0m[0m | time: 10.834s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5172 -- iter: 0448/1001
[A[ATraining Step: 47  | total loss: [1m[32m0.69314[0m[0m | time: 11.544s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5041 -- iter: 0480/1001
[A[ATraining Step: 48  | total loss: [1m[32m0.69315[0m[0m | time: 12.297s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5035 -- iter: 0512/1001
[A[ATraining Step: 49  | total loss: [1m[32m0.69321[0m[0m | time: 13.003s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4980 -- iter: 0544/1001
[A[ATraining Step: 50  | total loss: [1m[32m0.69325[0m[0m | time: 13.731s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4934 -- iter: 0576/1001
[A[ATraining Step: 51  | total loss: [1m[32m0.69305[0m[0m | time: 14.470s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5087 -- iter: 0608/1001
[A[ATraining Step: 52  | total loss: [1m[32m0.69334[0m[0m | time: 15.245s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4840 -- iter: 0640/1001
[A[ATraining Step: 53  | total loss: [1m[32m0.69318[0m[0m | time: 15.986s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.4956 -- iter: 0672/1001
[A[ATraining Step: 54  | total loss: [1m[32m0.69340[0m[0m | time: 16.718s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.4781 -- iter: 0704/1001
[A[ATraining Step: 55  | total loss: [1m[32m0.69345[0m[0m | time: 17.437s
[2K
| Adam | epoch: 002 | loss: 0.69345 - acc: 0.4723 -- iter: 0736/1001
[A[ATraining Step: 56  | total loss: [1m[32m0.69326[0m[0m | time: 18.327s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4938 -- iter: 0768/1001
[A[ATraining Step: 57  | total loss: [1m[32m0.69323[0m[0m | time: 19.145s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.4946 -- iter: 0800/1001
[A[ATraining Step: 58  | total loss: [1m[32m0.69306[0m[0m | time: 19.752s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5124 -- iter: 0832/1001
[A[ATraining Step: 59  | total loss: [1m[32m0.69315[0m[0m | time: 20.397s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5023 -- iter: 0864/1001
[A[ATraining Step: 60  | total loss: [1m[32m0.69302[0m[0m | time: 21.150s
[2K
| Adam | epoch: 002 | loss: 0.69302 - acc: 0.5144 -- iter: 0896/1001
[A[ATraining Step: 61  | total loss: [1m[32m0.69297[0m[0m | time: 21.904s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5166 -- iter: 0928/1001
[A[ATraining Step: 62  | total loss: [1m[32m0.69292[0m[0m | time: 23.103s
[2K
| Adam | epoch: 002 | loss: 0.69292 - acc: 0.5225 -- iter: 0960/1001
[A[ATraining Step: 63  | total loss: [1m[32m0.69282[0m[0m | time: 24.347s
[2K
| Adam | epoch: 002 | loss: 0.69282 - acc: 0.5276 -- iter: 0992/1001
[A[ATraining Step: 64  | total loss: [1m[32m0.69278[0m[0m | time: 30.545s
[2K
| Adam | epoch: 002 | loss: 0.69278 - acc: 0.5281 | val_loss: 0.69346 - val_acc: 0.4809 -- iter: 1001/1001
--
Training Step: 65  | total loss: [1m[32m0.69277[0m[0m | time: 0.366s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5284 -- iter: 0032/1001
[A[ATraining Step: 66  | total loss: [1m[32m0.69299[0m[0m | time: 0.787s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5182 -- iter: 0064/1001
[A[ATraining Step: 67  | total loss: [1m[32m0.69285[0m[0m | time: 1.866s
[2K
| Adam | epoch: 003 | loss: 0.69285 - acc: 0.5227 -- iter: 0096/1001
[A[ATraining Step: 68  | total loss: [1m[32m0.69252[0m[0m | time: 3.162s
[2K
| Adam | epoch: 003 | loss: 0.69252 - acc: 0.5348 -- iter: 0128/1001
[A[ATraining Step: 69  | total loss: [1m[32m0.69205[0m[0m | time: 4.425s
[2K
| Adam | epoch: 003 | loss: 0.69205 - acc: 0.5527 -- iter: 0160/1001
[A[ATraining Step: 70  | total loss: [1m[32m0.69239[0m[0m | time: 5.519s
[2K
| Adam | epoch: 003 | loss: 0.69239 - acc: 0.5394 -- iter: 0192/1001
[A[ATraining Step: 71  | total loss: [1m[32m0.69218[0m[0m | time: 6.637s
[2K
| Adam | epoch: 003 | loss: 0.69218 - acc: 0.5420 -- iter: 0224/1001
[A[ATraining Step: 72  | total loss: [1m[32m0.69270[0m[0m | time: 7.875s
[2K
| Adam | epoch: 003 | loss: 0.69270 - acc: 0.5267 -- iter: 0256/1001
[A[ATraining Step: 73  | total loss: [1m[32m0.69203[0m[0m | time: 9.125s
[2K
| Adam | epoch: 003 | loss: 0.69203 - acc: 0.5411 -- iter: 0288/1001
[A[ATraining Step: 74  | total loss: [1m[32m0.69181[0m[0m | time: 12.867s
[2K
| Adam | epoch: 003 | loss: 0.69181 - acc: 0.5435 -- iter: 0320/1001
[A[ATraining Step: 75  | total loss: [1m[32m0.69056[0m[0m | time: 14.008s
[2K
| Adam | epoch: 003 | loss: 0.69056 - acc: 0.5659 -- iter: 0352/1001
[A[ATraining Step: 76  | total loss: [1m[32m0.69104[0m[0m | time: 15.070s
[2K
| Adam | epoch: 003 | loss: 0.69104 - acc: 0.5555 -- iter: 0384/1001
[A[ATraining Step: 77  | total loss: [1m[32m0.69178[0m[0m | time: 16.363s
[2K
| Adam | epoch: 003 | loss: 0.69178 - acc: 0.5430 -- iter: 0416/1001
[A[ATraining Step: 78  | total loss: [1m[32m0.69196[0m[0m | time: 17.529s
[2K
| Adam | epoch: 003 | loss: 0.69196 - acc: 0.5385 -- iter: 0448/1001
[A[ATraining Step: 79  | total loss: [1m[32m0.69089[0m[0m | time: 18.922s
[2K
| Adam | epoch: 003 | loss: 0.69089 - acc: 0.5474 -- iter: 0480/1001
[A[ATraining Step: 80  | total loss: [1m[32m0.69004[0m[0m | time: 19.909s
[2K
| Adam | epoch: 003 | loss: 0.69004 - acc: 0.5522 -- iter: 0512/1001
[A[ATraining Step: 81  | total loss: [1m[32m0.68922[0m[0m | time: 20.839s
[2K
| Adam | epoch: 003 | loss: 0.68922 - acc: 0.5564 -- iter: 0544/1001
[A[ATraining Step: 82  | total loss: [1m[32m0.69385[0m[0m | time: 22.020s
[2K
| Adam | epoch: 003 | loss: 0.69385 - acc: 0.5289 -- iter: 0576/1001
[A[ATraining Step: 83  | total loss: [1m[32m0.69289[0m[0m | time: 23.309s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.5322 -- iter: 0608/1001
[A[ATraining Step: 84  | total loss: [1m[32m0.69129[0m[0m | time: 24.476s
[2K
| Adam | epoch: 003 | loss: 0.69129 - acc: 0.5415 -- iter: 0640/1001
[A[ATraining Step: 85  | total loss: [1m[32m0.69295[0m[0m | time: 29.684s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5280 -- iter: 0672/1001
[A[ATraining Step: 86  | total loss: [1m[32m0.69275[0m[0m | time: 30.721s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5283 -- iter: 0704/1001
[A[ATraining Step: 87  | total loss: [1m[32m0.69292[0m[0m | time: 31.796s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5255 -- iter: 0736/1001
[A[ATraining Step: 88  | total loss: [1m[32m0.69407[0m[0m | time: 32.855s
[2K
| Adam | epoch: 003 | loss: 0.69407 - acc: 0.5135 -- iter: 0768/1001
[A[ATraining Step: 89  | total loss: [1m[32m0.69239[0m[0m | time: 33.895s
[2K
| Adam | epoch: 003 | loss: 0.69239 - acc: 0.5278 -- iter: 0800/1001
[A[ATraining Step: 90  | total loss: [1m[32m0.69304[0m[0m | time: 35.080s
[2K
| Adam | epoch: 003 | loss: 0.69304 - acc: 0.5188 -- iter: 0832/1001
[A[ATraining Step: 91  | total loss: [1m[32m0.69246[0m[0m | time: 36.354s
[2K
| Adam | epoch: 003 | loss: 0.69246 - acc: 0.5232 -- iter: 0864/1001
[A[ATraining Step: 92  | total loss: [1m[32m0.69189[0m[0m | time: 37.398s
[2K
| Adam | epoch: 003 | loss: 0.69189 - acc: 0.5271 -- iter: 0896/1001
[A[ATraining Step: 93  | total loss: [1m[32m0.69256[0m[0m | time: 38.516s
[2K
| Adam | epoch: 003 | loss: 0.69256 - acc: 0.5181 -- iter: 0928/1001
[A[ATraining Step: 94  | total loss: [1m[32m0.69342[0m[0m | time: 39.440s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.5069 -- iter: 0960/1001
[A[ATraining Step: 95  | total loss: [1m[32m0.69405[0m[0m | time: 40.398s
[2K
| Adam | epoch: 003 | loss: 0.69405 - acc: 0.4969 -- iter: 0992/1001
[A[ATraining Step: 96  | total loss: [1m[32m0.69467[0m[0m | time: 43.189s
[2K
| Adam | epoch: 003 | loss: 0.69467 - acc: 0.4878 | val_loss: 0.69376 - val_acc: 0.4809 -- iter: 1001/1001
--
Training Step: 97  | total loss: [1m[32m0.69527[0m[0m | time: 1.010s
[2K
| Adam | epoch: 004 | loss: 0.69527 - acc: 0.4734 -- iter: 0032/1001
[A[ATraining Step: 98  | total loss: [1m[32m0.69492[0m[0m | time: 1.297s
[2K
| Adam | epoch: 004 | loss: 0.69492 - acc: 0.4792 -- iter: 0064/1001
[A[ATraining Step: 99  | total loss: [1m[32m0.69446[0m[0m | time: 1.674s
[2K
| Adam | epoch: 004 | loss: 0.69446 - acc: 0.4868 -- iter: 0096/1001
[A[ATraining Step: 100  | total loss: [1m[32m0.69407[0m[0m | time: 3.030s
[2K
| Adam | epoch: 004 | loss: 0.69407 - acc: 0.4937 -- iter: 0128/1001
[A[ATraining Step: 101  | total loss: [1m[32m0.69410[0m[0m | time: 4.518s
[2K
| Adam | epoch: 004 | loss: 0.69410 - acc: 0.4881 -- iter: 0160/1001
[A[ATraining Step: 102  | total loss: [1m[32m0.69399[0m[0m | time: 5.441s
[2K
| Adam | epoch: 004 | loss: 0.69399 - acc: 0.4861 -- iter: 0192/1001
[A[ATraining Step: 103  | total loss: [1m[32m0.69391[0m[0m | time: 8.176s
[2K
| Adam | epoch: 004 | loss: 0.69391 - acc: 0.4875 -- iter: 0224/1001
[A[ATraining Step: 104  | total loss: [1m[32m0.69354[0m[0m | time: 8.995s
[2K
| Adam | epoch: 004 | loss: 0.69354 - acc: 0.5013 -- iter: 0256/1001
[A[ATraining Step: 105  | total loss: [1m[32m0.69315[0m[0m | time: 10.052s
[2K
| Adam | epoch: 004 | loss: 0.69315 - acc: 0.5168 -- iter: 0288/1001
[A[ATraining Step: 106  | total loss: [1m[32m0.69308[0m[0m | time: 11.066s
[2K
| Adam | epoch: 004 | loss: 0.69308 - acc: 0.5182 -- iter: 0320/1001
[A[ATraining Step: 107  | total loss: [1m[32m0.69313[0m[0m | time: 12.176s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.5133 -- iter: 0352/1001
[A[ATraining Step: 108  | total loss: [1m[32m0.69327[0m[0m | time: 13.332s
[2K
| Adam | epoch: 004 | loss: 0.69327 - acc: 0.5057 -- iter: 0384/1001
[A[ATraining Step: 109  | total loss: [1m[32m0.69317[0m[0m | time: 14.563s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5083 -- iter: 0416/1001
[A[ATraining Step: 110  | total loss: [1m[32m0.69329[0m[0m | time: 15.758s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.5012 -- iter: 0448/1001
[A[ATraining Step: 111  | total loss: [1m[32m0.69292[0m[0m | time: 16.736s
[2K
| Adam | epoch: 004 | loss: 0.69292 - acc: 0.5104 -- iter: 0480/1001
[A[ATraining Step: 112  | total loss: [1m[32m0.69282[0m[0m | time: 17.997s
[2K
| Adam | epoch: 004 | loss: 0.69282 - acc: 0.5125 -- iter: 0512/1001
[A[ATraining Step: 113  | total loss: [1m[32m0.69284[0m[0m | time: 19.330s
[2K
| Adam | epoch: 004 | loss: 0.69284 - acc: 0.5113 -- iter: 0544/1001
[A[ATraining Step: 114  | total loss: [1m[32m0.69258[0m[0m | time: 22.408s
[2K
| Adam | epoch: 004 | loss: 0.69258 - acc: 0.5164 -- iter: 0576/1001
[A[ATraining Step: 115  | total loss: [1m[32m0.69240[0m[0m | time: 31.907s
[2K
| Adam | epoch: 004 | loss: 0.69240 - acc: 0.5179 -- iter: 0608/1001
[A[ATraining Step: 116  | total loss: [1m[32m0.69199[0m[0m | time: 32.902s
[2K
| Adam | epoch: 004 | loss: 0.69199 - acc: 0.5255 -- iter: 0640/1001
[A[ATraining Step: 117  | total loss: [1m[32m0.69117[0m[0m | time: 34.039s
[2K
| Adam | epoch: 004 | loss: 0.69117 - acc: 0.5417 -- iter: 0672/1001
[A[ATraining Step: 118  | total loss: [1m[32m0.69127[0m[0m | time: 35.168s
[2K
| Adam | epoch: 004 | loss: 0.69127 - acc: 0.5375 -- iter: 0704/1001
[A[ATraining Step: 119  | total loss: [1m[32m0.69193[0m[0m | time: 36.257s
[2K
| Adam | epoch: 004 | loss: 0.69193 - acc: 0.5275 -- iter: 0736/1001
[A[ATraining Step: 120  | total loss: [1m[32m0.69191[0m[0m | time: 37.479s
[2K
| Adam | epoch: 004 | loss: 0.69191 - acc: 0.5247 -- iter: 0768/1001
[A[ATraining Step: 121  | total loss: [1m[32m0.69239[0m[0m | time: 38.736s
[2K
| Adam | epoch: 004 | loss: 0.69239 - acc: 0.5160 -- iter: 0800/1001
[A[ATraining Step: 122  | total loss: [1m[32m0.69244[0m[0m | time: 39.798s
[2K
| Adam | epoch: 004 | loss: 0.69244 - acc: 0.5144 -- iter: 0832/1001
[A[ATraining Step: 123  | total loss: [1m[32m0.69235[0m[0m | time: 40.965s
[2K
| Adam | epoch: 004 | loss: 0.69235 - acc: 0.5099 -- iter: 0864/1001
[A[ATraining Step: 124  | total loss: [1m[32m0.69300[0m[0m | time: 42.132s
[2K
| Adam | epoch: 004 | loss: 0.69300 - acc: 0.4995 -- iter: 0896/1001
[A[ATraining Step: 125  | total loss: [1m[32m0.69325[0m[0m | time: 43.246s
[2K
| Adam | epoch: 004 | loss: 0.69325 - acc: 0.4902 -- iter: 0928/1001
[A[ATraining Step: 126  | total loss: [1m[32m0.69302[0m[0m | time: 44.379s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.4880 -- iter: 0960/1001
[A[ATraining Step: 127  | total loss: [1m[32m0.69279[0m[0m | time: 45.355s
[2K
| Adam | epoch: 004 | loss: 0.69279 - acc: 0.5017 -- iter: 0992/1001
[A[ATraining Step: 128  | total loss: [1m[32m0.69265[0m[0m | time: 47.179s
[2K
| Adam | epoch: 004 | loss: 0.69265 - acc: 0.5109 | val_loss: 0.68966 - val_acc: 0.6338 -- iter: 1001/1001
--
Training Step: 129  | total loss: [1m[32m0.69250[0m[0m | time: 0.736s
[2K
| Adam | epoch: 005 | loss: 0.69250 - acc: 0.5161 -- iter: 0032/1001
[A[ATraining Step: 130  | total loss: [1m[32m0.69189[0m[0m | time: 1.483s
[2K
| Adam | epoch: 005 | loss: 0.69189 - acc: 0.5332 -- iter: 0064/1001
[A[ATraining Step: 131  | total loss: [1m[32m0.69162[0m[0m | time: 1.737s
[2K
| Adam | epoch: 005 | loss: 0.69162 - acc: 0.5268 -- iter: 0096/1001
[A[ATraining Step: 132  | total loss: [1m[32m0.68844[0m[0m | time: 1.992s
[2K
| Adam | epoch: 005 | loss: 0.68844 - acc: 0.5630 -- iter: 0128/1001
[A[ATraining Step: 133  | total loss: [1m[32m0.68895[0m[0m | time: 2.730s
[2K
| Adam | epoch: 005 | loss: 0.68895 - acc: 0.5400 -- iter: 0160/1001
[A[ATraining Step: 134  | total loss: [1m[32m0.68882[0m[0m | time: 3.521s
[2K
| Adam | epoch: 005 | loss: 0.68882 - acc: 0.5391 -- iter: 0192/1001
[A[ATraining Step: 135  | total loss: [1m[32m0.68844[0m[0m | time: 4.297s
[2K
| Adam | epoch: 005 | loss: 0.68844 - acc: 0.5384 -- iter: 0224/1001
[A[ATraining Step: 136  | total loss: [1m[32m0.69073[0m[0m | time: 4.972s
[2K
| Adam | epoch: 005 | loss: 0.69073 - acc: 0.5283 -- iter: 0256/1001
[A[ATraining Step: 137  | total loss: [1m[32m0.69086[0m[0m | time: 5.797s
[2K
| Adam | epoch: 005 | loss: 0.69086 - acc: 0.5317 -- iter: 0288/1001
[A[ATraining Step: 138  | total loss: [1m[32m0.68889[0m[0m | time: 6.599s
[2K
| Adam | epoch: 005 | loss: 0.68889 - acc: 0.5441 -- iter: 0320/1001
[A[ATraining Step: 139  | total loss: [1m[32m0.68724[0m[0m | time: 7.409s
[2K
| Adam | epoch: 005 | loss: 0.68724 - acc: 0.5522 -- iter: 0352/1001
[A[ATraining Step: 140  | total loss: [1m[32m0.68515[0m[0m | time: 8.268s
[2K
| Adam | epoch: 005 | loss: 0.68515 - acc: 0.5501 -- iter: 0384/1001
[A[ATraining Step: 141  | total loss: [1m[32m0.68497[0m[0m | time: 9.051s
[2K
| Adam | epoch: 005 | loss: 0.68497 - acc: 0.5576 -- iter: 0416/1001
[A[ATraining Step: 142  | total loss: [1m[32m0.68144[0m[0m | time: 9.834s
[2K
| Adam | epoch: 005 | loss: 0.68144 - acc: 0.5581 -- iter: 0448/1001
[A[ATraining Step: 143  | total loss: [1m[32m0.68448[0m[0m | time: 10.691s
[2K
| Adam | epoch: 005 | loss: 0.68448 - acc: 0.5492 -- iter: 0480/1001
[A[ATraining Step: 144  | total loss: [1m[32m0.68150[0m[0m | time: 11.443s
[2K
| Adam | epoch: 005 | loss: 0.68150 - acc: 0.5505 -- iter: 0512/1001
[A[ATraining Step: 145  | total loss: [1m[32m0.68249[0m[0m | time: 12.203s
[2K
| Adam | epoch: 005 | loss: 0.68249 - acc: 0.5611 -- iter: 0544/1001
[A[ATraining Step: 146  | total loss: [1m[32m0.68469[0m[0m | time: 12.972s
[2K
| Adam | epoch: 005 | loss: 0.68469 - acc: 0.5487 -- iter: 0576/1001
[A[ATraining Step: 147  | total loss: [1m[32m0.68377[0m[0m | time: 14.145s
[2K
| Adam | epoch: 005 | loss: 0.68377 - acc: 0.5501 -- iter: 0608/1001
[A[ATraining Step: 148  | total loss: [1m[32m0.68318[0m[0m | time: 15.340s
[2K
| Adam | epoch: 005 | loss: 0.68318 - acc: 0.5482 -- iter: 0640/1001
[A[ATraining Step: 149  | total loss: [1m[32m0.67901[0m[0m | time: 16.865s
[2K
| Adam | epoch: 005 | loss: 0.67901 - acc: 0.5684 -- iter: 0672/1001
[A[ATraining Step: 150  | total loss: [1m[32m0.67795[0m[0m | time: 17.903s
[2K
| Adam | epoch: 005 | loss: 0.67795 - acc: 0.5772 -- iter: 0704/1001
[A[ATraining Step: 151  | total loss: [1m[32m0.67604[0m[0m | time: 18.896s
[2K
| Adam | epoch: 005 | loss: 0.67604 - acc: 0.5788 -- iter: 0736/1001
[A[ATraining Step: 152  | total loss: [1m[32m0.67102[0m[0m | time: 19.874s
[2K
| Adam | epoch: 005 | loss: 0.67102 - acc: 0.5803 -- iter: 0768/1001
[A[ATraining Step: 153  | total loss: [1m[32m0.67058[0m[0m | time: 20.933s
[2K
| Adam | epoch: 005 | loss: 0.67058 - acc: 0.5942 -- iter: 0800/1001
[A[ATraining Step: 154  | total loss: [1m[32m0.66454[0m[0m | time: 22.017s
[2K
| Adam | epoch: 005 | loss: 0.66454 - acc: 0.6004 -- iter: 0832/1001
[A[ATraining Step: 155  | total loss: [1m[32m0.66870[0m[0m | time: 23.284s
[2K
| Adam | epoch: 005 | loss: 0.66870 - acc: 0.5966 -- iter: 0864/1001
[A[ATraining Step: 156  | total loss: [1m[32m0.66233[0m[0m | time: 24.515s
[2K
| Adam | epoch: 005 | loss: 0.66233 - acc: 0.6057 -- iter: 0896/1001
[A[ATraining Step: 157  | total loss: [1m[32m0.65824[0m[0m | time: 25.668s
[2K
| Adam | epoch: 005 | loss: 0.65824 - acc: 0.6107 -- iter: 0928/1001
[A[ATraining Step: 158  | total loss: [1m[32m0.67119[0m[0m | time: 26.866s
[2K
| Adam | epoch: 005 | loss: 0.67119 - acc: 0.5934 -- iter: 0960/1001
[A[ATraining Step: 159  | total loss: [1m[32m0.65510[0m[0m | time: 28.141s
[2K
| Adam | epoch: 005 | loss: 0.65510 - acc: 0.6153 -- iter: 0992/1001
[A[ATraining Step: 160  | total loss: [1m[32m0.67293[0m[0m | time: 30.989s
[2K
| Adam | epoch: 005 | loss: 0.67293 - acc: 0.5975 | val_loss: 0.70185 - val_acc: 0.5287 -- iter: 1001/1001
--
Training Step: 161  | total loss: [1m[32m0.68574[0m[0m | time: 1.259s
[2K
| Adam | epoch: 006 | loss: 0.68574 - acc: 0.5815 -- iter: 0032/1001
[A[ATraining Step: 162  | total loss: [1m[32m0.68017[0m[0m | time: 2.521s
[2K
| Adam | epoch: 006 | loss: 0.68017 - acc: 0.5734 -- iter: 0064/1001
[A[ATraining Step: 163  | total loss: [1m[32m0.67121[0m[0m | time: 3.930s
[2K
| Adam | epoch: 006 | loss: 0.67121 - acc: 0.5879 -- iter: 0096/1001
[A[ATraining Step: 164  | total loss: [1m[32m0.66607[0m[0m | time: 4.276s
[2K
| Adam | epoch: 006 | loss: 0.66607 - acc: 0.6010 -- iter: 0128/1001
[A[ATraining Step: 165  | total loss: [1m[32m0.65700[0m[0m | time: 4.764s
[2K
| Adam | epoch: 006 | loss: 0.65700 - acc: 0.6298 -- iter: 0160/1001
[A[ATraining Step: 166  | total loss: [1m[32m0.65144[0m[0m | time: 5.870s
[2K
| Adam | epoch: 006 | loss: 0.65144 - acc: 0.6446 -- iter: 0192/1001
[A[ATraining Step: 167  | total loss: [1m[32m0.65236[0m[0m | time: 7.219s
[2K
| Adam | epoch: 006 | loss: 0.65236 - acc: 0.6395 -- iter: 0224/1001
[A[ATraining Step: 168  | total loss: [1m[32m0.65228[0m[0m | time: 8.366s
[2K
| Adam | epoch: 006 | loss: 0.65228 - acc: 0.6381 -- iter: 0256/1001
[A[ATraining Step: 169  | total loss: [1m[32m0.64906[0m[0m | time: 9.284s
[2K
| Adam | epoch: 006 | loss: 0.64906 - acc: 0.6492 -- iter: 0288/1001
[A[ATraining Step: 170  | total loss: [1m[32m0.64829[0m[0m | time: 10.303s
[2K
| Adam | epoch: 006 | loss: 0.64829 - acc: 0.6499 -- iter: 0320/1001
[A[ATraining Step: 171  | total loss: [1m[32m0.65140[0m[0m | time: 11.507s
[2K
| Adam | epoch: 006 | loss: 0.65140 - acc: 0.6443 -- iter: 0352/1001
[A[ATraining Step: 172  | total loss: [1m[32m0.64404[0m[0m | time: 12.667s
[2K
| Adam | epoch: 006 | loss: 0.64404 - acc: 0.6580 -- iter: 0384/1001
[A[ATraining Step: 173  | total loss: [1m[32m0.64110[0m[0m | time: 13.941s
[2K
| Adam | epoch: 006 | loss: 0.64110 - acc: 0.6610 -- iter: 0416/1001
[A[ATraining Step: 174  | total loss: [1m[32m0.63662[0m[0m | time: 14.998s
[2K
| Adam | epoch: 006 | loss: 0.63662 - acc: 0.6636 -- iter: 0448/1001
[A[ATraining Step: 175  | total loss: [1m[32m0.63673[0m[0m | time: 16.049s
[2K
| Adam | epoch: 006 | loss: 0.63673 - acc: 0.6691 -- iter: 0480/1001
[A[ATraining Step: 176  | total loss: [1m[32m0.63648[0m[0m | time: 17.009s
[2K
| Adam | epoch: 006 | loss: 0.63648 - acc: 0.6741 -- iter: 0512/1001
[A[ATraining Step: 177  | total loss: [1m[32m0.63903[0m[0m | time: 18.187s
[2K
| Adam | epoch: 006 | loss: 0.63903 - acc: 0.6723 -- iter: 0544/1001
[A[ATraining Step: 178  | total loss: [1m[32m0.62882[0m[0m | time: 19.406s
[2K
| Adam | epoch: 006 | loss: 0.62882 - acc: 0.6832 -- iter: 0576/1001
[A[ATraining Step: 179  | total loss: [1m[32m0.63783[0m[0m | time: 20.659s
[2K
| Adam | epoch: 006 | loss: 0.63783 - acc: 0.6618 -- iter: 0608/1001
[A[ATraining Step: 180  | total loss: [1m[32m0.64205[0m[0m | time: 21.772s
[2K
| Adam | epoch: 006 | loss: 0.64205 - acc: 0.6518 -- iter: 0640/1001
[A[ATraining Step: 181  | total loss: [1m[32m0.63548[0m[0m | time: 22.927s
[2K
| Adam | epoch: 006 | loss: 0.63548 - acc: 0.6554 -- iter: 0672/1001
[A[ATraining Step: 182  | total loss: [1m[32m0.64164[0m[0m | time: 24.090s
[2K
| Adam | epoch: 006 | loss: 0.64164 - acc: 0.6367 -- iter: 0704/1001
[A[ATraining Step: 183  | total loss: [1m[32m0.63119[0m[0m | time: 25.283s
[2K
| Adam | epoch: 006 | loss: 0.63119 - acc: 0.6512 -- iter: 0736/1001
[A[ATraining Step: 184  | total loss: [1m[32m0.62486[0m[0m | time: 26.473s
[2K
| Adam | epoch: 006 | loss: 0.62486 - acc: 0.6611 -- iter: 0768/1001
[A[ATraining Step: 185  | total loss: [1m[32m0.61839[0m[0m | time: 27.640s
[2K
| Adam | epoch: 006 | loss: 0.61839 - acc: 0.6700 -- iter: 0800/1001
[A[ATraining Step: 186  | total loss: [1m[32m0.60584[0m[0m | time: 28.554s
[2K
| Adam | epoch: 006 | loss: 0.60584 - acc: 0.6842 -- iter: 0832/1001
[A[ATraining Step: 187  | total loss: [1m[32m0.60700[0m[0m | time: 29.770s
[2K
| Adam | epoch: 006 | loss: 0.60700 - acc: 0.6783 -- iter: 0864/1001
[A[ATraining Step: 188  | total loss: [1m[32m0.59597[0m[0m | time: 30.817s
[2K
| Adam | epoch: 006 | loss: 0.59597 - acc: 0.6886 -- iter: 0896/1001
[A[ATraining Step: 189  | total loss: [1m[32m0.60167[0m[0m | time: 31.749s
[2K
| Adam | epoch: 006 | loss: 0.60167 - acc: 0.6854 -- iter: 0928/1001
[A[ATraining Step: 190  | total loss: [1m[32m0.60661[0m[0m | time: 32.798s
[2K
| Adam | epoch: 006 | loss: 0.60661 - acc: 0.6762 -- iter: 0960/1001
[A[ATraining Step: 191  | total loss: [1m[32m0.59531[0m[0m | time: 33.978s
[2K
| Adam | epoch: 006 | loss: 0.59531 - acc: 0.6898 -- iter: 0992/1001
[A[ATraining Step: 192  | total loss: [1m[32m0.58459[0m[0m | time: 36.856s
[2K
| Adam | epoch: 006 | loss: 0.58459 - acc: 0.7052 | val_loss: 0.56350 - val_acc: 0.6975 -- iter: 1001/1001
--
Training Step: 193  | total loss: [1m[32m0.58105[0m[0m | time: 1.213s
[2K
| Adam | epoch: 007 | loss: 0.58105 - acc: 0.7066 -- iter: 0032/1001
[A[ATraining Step: 194  | total loss: [1m[32m0.57928[0m[0m | time: 2.023s
[2K
| Adam | epoch: 007 | loss: 0.57928 - acc: 0.7140 -- iter: 0064/1001
[A[ATraining Step: 195  | total loss: [1m[32m0.57457[0m[0m | time: 3.017s
[2K
| Adam | epoch: 007 | loss: 0.57457 - acc: 0.7114 -- iter: 0096/1001
[A[ATraining Step: 196  | total loss: [1m[32m0.60570[0m[0m | time: 4.092s
[2K
| Adam | epoch: 007 | loss: 0.60570 - acc: 0.6934 -- iter: 0128/1001
[A[ATraining Step: 197  | total loss: [1m[32m0.59230[0m[0m | time: 4.436s
[2K
| Adam | epoch: 007 | loss: 0.59230 - acc: 0.7022 -- iter: 0160/1001
[A[ATraining Step: 198  | total loss: [1m[32m0.57316[0m[0m | time: 4.815s
[2K
| Adam | epoch: 007 | loss: 0.57316 - acc: 0.7097 -- iter: 0192/1001
[A[ATraining Step: 199  | total loss: [1m[32m0.57254[0m[0m | time: 6.006s
[2K
| Adam | epoch: 007 | loss: 0.57254 - acc: 0.7165 -- iter: 0224/1001
[A[ATraining Step: 200  | total loss: [1m[32m0.57279[0m[0m | time: 9.668s
[2K
| Adam | epoch: 007 | loss: 0.57279 - acc: 0.7167 | val_loss: 0.55858 - val_acc: 0.7420 -- iter: 0256/1001
--
Training Step: 201  | total loss: [1m[32m0.56877[0m[0m | time: 11.078s
[2K
| Adam | epoch: 007 | loss: 0.56877 - acc: 0.7169 -- iter: 0288/1001
[A[ATraining Step: 202  | total loss: [1m[32m0.57271[0m[0m | time: 12.231s
[2K
| Adam | epoch: 007 | loss: 0.57271 - acc: 0.7140 -- iter: 0320/1001
[A[ATraining Step: 203  | total loss: [1m[32m0.59138[0m[0m | time: 13.029s
[2K
| Adam | epoch: 007 | loss: 0.59138 - acc: 0.7051 -- iter: 0352/1001
[A[ATraining Step: 204  | total loss: [1m[32m0.58776[0m[0m | time: 13.785s
[2K
| Adam | epoch: 007 | loss: 0.58776 - acc: 0.7127 -- iter: 0384/1001
[A[ATraining Step: 205  | total loss: [1m[32m0.58380[0m[0m | time: 14.648s
[2K
| Adam | epoch: 007 | loss: 0.58380 - acc: 0.7196 -- iter: 0416/1001
[A[ATraining Step: 206  | total loss: [1m[32m0.56806[0m[0m | time: 15.396s
[2K
| Adam | epoch: 007 | loss: 0.56806 - acc: 0.7289 -- iter: 0448/1001
[A[ATraining Step: 207  | total loss: [1m[32m0.57734[0m[0m | time: 16.136s
[2K
| Adam | epoch: 007 | loss: 0.57734 - acc: 0.7247 -- iter: 0480/1001
[A[ATraining Step: 208  | total loss: [1m[32m0.57127[0m[0m | time: 16.910s
[2K
| Adam | epoch: 007 | loss: 0.57127 - acc: 0.7273 -- iter: 0512/1001
[A[ATraining Step: 209  | total loss: [1m[32m0.55882[0m[0m | time: 17.690s
[2K
| Adam | epoch: 007 | loss: 0.55882 - acc: 0.7295 -- iter: 0544/1001
[A[ATraining Step: 210  | total loss: [1m[32m0.55467[0m[0m | time: 18.489s
[2K
| Adam | epoch: 007 | loss: 0.55467 - acc: 0.7378 -- iter: 0576/1001
[A[ATraining Step: 211  | total loss: [1m[32m0.55465[0m[0m | time: 19.242s
[2K
| Adam | epoch: 007 | loss: 0.55465 - acc: 0.7328 -- iter: 0608/1001
[A[ATraining Step: 212  | total loss: [1m[32m0.55271[0m[0m | time: 20.012s
[2K
| Adam | epoch: 007 | loss: 0.55271 - acc: 0.7314 -- iter: 0640/1001
[A[ATraining Step: 213  | total loss: [1m[32m0.55832[0m[0m | time: 20.750s
[2K
| Adam | epoch: 007 | loss: 0.55832 - acc: 0.7301 -- iter: 0672/1001
[A[ATraining Step: 214  | total loss: [1m[32m0.55490[0m[0m | time: 21.469s
[2K
| Adam | epoch: 007 | loss: 0.55490 - acc: 0.7352 -- iter: 0704/1001
[A[ATraining Step: 215  | total loss: [1m[32m0.54998[0m[0m | time: 22.192s
[2K
| Adam | epoch: 007 | loss: 0.54998 - acc: 0.7336 -- iter: 0736/1001
[A[ATraining Step: 216  | total loss: [1m[32m0.53358[0m[0m | time: 23.115s
[2K
| Adam | epoch: 007 | loss: 0.53358 - acc: 0.7477 -- iter: 0768/1001
[A[ATraining Step: 217  | total loss: [1m[32m0.53302[0m[0m | time: 23.890s
[2K
| Adam | epoch: 007 | loss: 0.53302 - acc: 0.7542 -- iter: 0800/1001
[A[ATraining Step: 218  | total loss: [1m[32m0.52620[0m[0m | time: 24.509s
[2K
| Adam | epoch: 007 | loss: 0.52620 - acc: 0.7632 -- iter: 0832/1001
[A[ATraining Step: 219  | total loss: [1m[32m0.51037[0m[0m | time: 25.184s
[2K
| Adam | epoch: 007 | loss: 0.51037 - acc: 0.7743 -- iter: 0864/1001
[A[ATraining Step: 220  | total loss: [1m[32m0.51384[0m[0m | time: 25.924s
[2K
| Adam | epoch: 007 | loss: 0.51384 - acc: 0.7625 -- iter: 0896/1001
[A[ATraining Step: 221  | total loss: [1m[32m0.50806[0m[0m | time: 26.691s
[2K
| Adam | epoch: 007 | loss: 0.50806 - acc: 0.7644 -- iter: 0928/1001
[A[ATraining Step: 222  | total loss: [1m[32m0.51891[0m[0m | time: 27.469s
[2K
| Adam | epoch: 007 | loss: 0.51891 - acc: 0.7536 -- iter: 0960/1001
[A[ATraining Step: 223  | total loss: [1m[32m0.52346[0m[0m | time: 28.209s
[2K
| Adam | epoch: 007 | loss: 0.52346 - acc: 0.7376 -- iter: 0992/1001
[A[ATraining Step: 224  | total loss: [1m[32m0.52731[0m[0m | time: 30.405s
[2K
| Adam | epoch: 007 | loss: 0.52731 - acc: 0.7420 | val_loss: 0.62760 - val_acc: 0.6911 -- iter: 1001/1001
--
Training Step: 225  | total loss: [1m[32m0.51623[0m[0m | time: 1.268s
[2K
| Adam | epoch: 008 | loss: 0.51623 - acc: 0.7553 -- iter: 0032/1001
[A[ATraining Step: 226  | total loss: [1m[32m0.52844[0m[0m | time: 2.715s
[2K
| Adam | epoch: 008 | loss: 0.52844 - acc: 0.7547 -- iter: 0064/1001
[A[ATraining Step: 227  | total loss: [1m[32m0.53034[0m[0m | time: 3.856s
[2K
| Adam | epoch: 008 | loss: 0.53034 - acc: 0.7543 -- iter: 0096/1001
[A[ATraining Step: 228  | total loss: [1m[32m0.53659[0m[0m | time: 4.825s
[2K
| Adam | epoch: 008 | loss: 0.53659 - acc: 0.7507 -- iter: 0128/1001
[A[ATraining Step: 229  | total loss: [1m[32m0.53602[0m[0m | time: 5.854s
[2K
| Adam | epoch: 008 | loss: 0.53602 - acc: 0.7444 -- iter: 0160/1001
[A[ATraining Step: 230  | total loss: [1m[32m0.52915[0m[0m | time: 6.197s
[2K
| Adam | epoch: 008 | loss: 0.52915 - acc: 0.7512 -- iter: 0192/1001
[A[ATraining Step: 231  | total loss: [1m[32m0.51311[0m[0m | time: 6.582s
[2K
| Adam | epoch: 008 | loss: 0.51311 - acc: 0.7650 -- iter: 0224/1001
[A[ATraining Step: 232  | total loss: [1m[32m0.52601[0m[0m | time: 7.623s
[2K
| Adam | epoch: 008 | loss: 0.52601 - acc: 0.7663 -- iter: 0256/1001
[A[ATraining Step: 233  | total loss: [1m[32m0.52690[0m[0m | time: 8.721s
[2K
| Adam | epoch: 008 | loss: 0.52690 - acc: 0.7615 -- iter: 0288/1001
[A[ATraining Step: 234  | total loss: [1m[32m0.52466[0m[0m | time: 9.911s
[2K
| Adam | epoch: 008 | loss: 0.52466 - acc: 0.7572 -- iter: 0320/1001
[A[ATraining Step: 235  | total loss: [1m[32m0.52022[0m[0m | time: 11.138s
[2K
| Adam | epoch: 008 | loss: 0.52022 - acc: 0.7628 -- iter: 0352/1001
[A[ATraining Step: 236  | total loss: [1m[32m0.51293[0m[0m | time: 12.183s
[2K
| Adam | epoch: 008 | loss: 0.51293 - acc: 0.7677 -- iter: 0384/1001
[A[ATraining Step: 237  | total loss: [1m[32m0.49994[0m[0m | time: 13.259s
[2K
| Adam | epoch: 008 | loss: 0.49994 - acc: 0.7753 -- iter: 0416/1001
[A[ATraining Step: 238  | total loss: [1m[32m0.50584[0m[0m | time: 14.446s
[2K
| Adam | epoch: 008 | loss: 0.50584 - acc: 0.7759 -- iter: 0448/1001
[A[ATraining Step: 239  | total loss: [1m[32m0.51189[0m[0m | time: 15.822s
[2K
| Adam | epoch: 008 | loss: 0.51189 - acc: 0.7702 -- iter: 0480/1001
[A[ATraining Step: 240  | total loss: [1m[32m0.49370[0m[0m | time: 17.511s
[2K
| Adam | epoch: 008 | loss: 0.49370 - acc: 0.7838 -- iter: 0512/1001
[A[ATraining Step: 241  | total loss: [1m[32m0.49677[0m[0m | time: 18.324s
[2K
| Adam | epoch: 008 | loss: 0.49677 - acc: 0.7867 -- iter: 0544/1001
[A[ATraining Step: 242  | total loss: [1m[32m0.50416[0m[0m | time: 19.412s
[2K
| Adam | epoch: 008 | loss: 0.50416 - acc: 0.7736 -- iter: 0576/1001
[A[ATraining Step: 243  | total loss: [1m[32m0.49643[0m[0m | time: 20.621s
[2K
| Adam | epoch: 008 | loss: 0.49643 - acc: 0.7775 -- iter: 0608/1001
[A[ATraining Step: 244  | total loss: [1m[32m0.49780[0m[0m | time: 21.652s
[2K
| Adam | epoch: 008 | loss: 0.49780 - acc: 0.7810 -- iter: 0640/1001
[A[ATraining Step: 245  | total loss: [1m[32m0.49701[0m[0m | time: 22.814s
[2K
| Adam | epoch: 008 | loss: 0.49701 - acc: 0.7779 -- iter: 0672/1001
[A[ATraining Step: 246  | total loss: [1m[32m0.48421[0m[0m | time: 24.085s
[2K
| Adam | epoch: 008 | loss: 0.48421 - acc: 0.7845 -- iter: 0704/1001
[A[ATraining Step: 247  | total loss: [1m[32m0.47441[0m[0m | time: 25.125s
[2K
| Adam | epoch: 008 | loss: 0.47441 - acc: 0.7842 -- iter: 0736/1001
[A[ATraining Step: 248  | total loss: [1m[32m0.47634[0m[0m | time: 26.310s
[2K
| Adam | epoch: 008 | loss: 0.47634 - acc: 0.7870 -- iter: 0768/1001
[A[ATraining Step: 249  | total loss: [1m[32m0.47509[0m[0m | time: 27.494s
[2K
| Adam | epoch: 008 | loss: 0.47509 - acc: 0.7802 -- iter: 0800/1001
[A[ATraining Step: 250  | total loss: [1m[32m0.46319[0m[0m | time: 28.682s
[2K
| Adam | epoch: 008 | loss: 0.46319 - acc: 0.7928 -- iter: 0832/1001
[A[ATraining Step: 251  | total loss: [1m[32m0.45361[0m[0m | time: 29.711s
[2K
| Adam | epoch: 008 | loss: 0.45361 - acc: 0.8010 -- iter: 0864/1001
[A[ATraining Step: 252  | total loss: [1m[32m0.46052[0m[0m | time: 30.921s
[2K
| Adam | epoch: 008 | loss: 0.46052 - acc: 0.7928 -- iter: 0896/1001
[A[ATraining Step: 253  | total loss: [1m[32m0.44439[0m[0m | time: 32.048s
[2K
| Adam | epoch: 008 | loss: 0.44439 - acc: 0.8041 -- iter: 0928/1001
[A[ATraining Step: 254  | total loss: [1m[32m0.42827[0m[0m | time: 33.201s
[2K
| Adam | epoch: 008 | loss: 0.42827 - acc: 0.8112 -- iter: 0960/1001
[A[ATraining Step: 255  | total loss: [1m[32m0.43473[0m[0m | time: 34.328s
[2K
| Adam | epoch: 008 | loss: 0.43473 - acc: 0.8113 -- iter: 0992/1001
[A[ATraining Step: 256  | total loss: [1m[32m0.41786[0m[0m | time: 37.503s
[2K
| Adam | epoch: 008 | loss: 0.41786 - acc: 0.8208 | val_loss: 0.46134 - val_acc: 0.7898 -- iter: 1001/1001
--
Training Step: 257  | total loss: [1m[32m0.40663[0m[0m | time: 1.167s
[2K
| Adam | epoch: 009 | loss: 0.40663 - acc: 0.8325 -- iter: 0032/1001
[A[ATraining Step: 258  | total loss: [1m[32m0.40225[0m[0m | time: 2.213s
[2K
| Adam | epoch: 009 | loss: 0.40225 - acc: 0.8368 -- iter: 0064/1001
[A[ATraining Step: 259  | total loss: [1m[32m0.39710[0m[0m | time: 3.544s
[2K
| Adam | epoch: 009 | loss: 0.39710 - acc: 0.8375 -- iter: 0096/1001
[A[ATraining Step: 260  | total loss: [1m[32m0.39634[0m[0m | time: 4.537s
[2K
| Adam | epoch: 009 | loss: 0.39634 - acc: 0.8256 -- iter: 0128/1001
[A[ATraining Step: 261  | total loss: [1m[32m0.39910[0m[0m | time: 5.496s
[2K
| Adam | epoch: 009 | loss: 0.39910 - acc: 0.8243 -- iter: 0160/1001
[A[ATraining Step: 262  | total loss: [1m[32m0.39250[0m[0m | time: 6.469s
[2K
| Adam | epoch: 009 | loss: 0.39250 - acc: 0.8325 -- iter: 0192/1001
[A[ATraining Step: 263  | total loss: [1m[32m0.37619[0m[0m | time: 6.874s
[2K
| Adam | epoch: 009 | loss: 0.37619 - acc: 0.8430 -- iter: 0224/1001
[A[ATraining Step: 264  | total loss: [1m[32m0.40685[0m[0m | time: 7.329s
[2K
| Adam | epoch: 009 | loss: 0.40685 - acc: 0.8365 -- iter: 0256/1001
[A[ATraining Step: 265  | total loss: [1m[32m0.50972[0m[0m | time: 8.686s
[2K
| Adam | epoch: 009 | loss: 0.50972 - acc: 0.8084 -- iter: 0288/1001
[A[ATraining Step: 266  | total loss: [1m[32m0.50008[0m[0m | time: 9.975s
[2K
| Adam | epoch: 009 | loss: 0.50008 - acc: 0.8150 -- iter: 0320/1001
[A[ATraining Step: 267  | total loss: [1m[32m0.47359[0m[0m | time: 11.057s
[2K
| Adam | epoch: 009 | loss: 0.47359 - acc: 0.8210 -- iter: 0352/1001
[A[ATraining Step: 268  | total loss: [1m[32m0.48959[0m[0m | time: 12.149s
[2K
| Adam | epoch: 009 | loss: 0.48959 - acc: 0.8108 -- iter: 0384/1001
[A[ATraining Step: 269  | total loss: [1m[32m0.48411[0m[0m | time: 13.430s
[2K
| Adam | epoch: 009 | loss: 0.48411 - acc: 0.8110 -- iter: 0416/1001
[A[ATraining Step: 270  | total loss: [1m[32m0.47965[0m[0m | time: 14.595s
[2K
| Adam | epoch: 009 | loss: 0.47965 - acc: 0.8049 -- iter: 0448/1001
[A[ATraining Step: 271  | total loss: [1m[32m0.45615[0m[0m | time: 15.700s
[2K
| Adam | epoch: 009 | loss: 0.45615 - acc: 0.8150 -- iter: 0480/1001
[A[ATraining Step: 272  | total loss: [1m[32m0.45919[0m[0m | time: 16.856s
[2K
| Adam | epoch: 009 | loss: 0.45919 - acc: 0.8148 -- iter: 0512/1001
[A[ATraining Step: 273  | total loss: [1m[32m0.44530[0m[0m | time: 18.146s
[2K
| Adam | epoch: 009 | loss: 0.44530 - acc: 0.8208 -- iter: 0544/1001
[A[ATraining Step: 274  | total loss: [1m[32m0.44460[0m[0m | time: 19.202s
[2K
| Adam | epoch: 009 | loss: 0.44460 - acc: 0.8200 -- iter: 0576/1001
[A[ATraining Step: 275  | total loss: [1m[32m0.43667[0m[0m | time: 20.362s
[2K
| Adam | epoch: 009 | loss: 0.43667 - acc: 0.8286 -- iter: 0608/1001
[A[ATraining Step: 276  | total loss: [1m[32m0.44203[0m[0m | time: 21.304s
[2K
| Adam | epoch: 009 | loss: 0.44203 - acc: 0.8207 -- iter: 0640/1001
[A[ATraining Step: 277  | total loss: [1m[32m0.43979[0m[0m | time: 22.242s
[2K
| Adam | epoch: 009 | loss: 0.43979 - acc: 0.8074 -- iter: 0672/1001
[A[ATraining Step: 278  | total loss: [1m[32m0.44330[0m[0m | time: 23.311s
[2K
| Adam | epoch: 009 | loss: 0.44330 - acc: 0.8048 -- iter: 0704/1001
[A[ATraining Step: 279  | total loss: [1m[32m0.42216[0m[0m | time: 24.329s
[2K
| Adam | epoch: 009 | loss: 0.42216 - acc: 0.8212 -- iter: 0736/1001
[A[ATraining Step: 280  | total loss: [1m[32m0.41982[0m[0m | time: 25.398s
[2K
| Adam | epoch: 009 | loss: 0.41982 - acc: 0.8203 -- iter: 0768/1001
[A[ATraining Step: 281  | total loss: [1m[32m0.42088[0m[0m | time: 26.362s
[2K
| Adam | epoch: 009 | loss: 0.42088 - acc: 0.8164 -- iter: 0800/1001
[A[ATraining Step: 282  | total loss: [1m[32m0.42952[0m[0m | time: 27.423s
[2K
| Adam | epoch: 009 | loss: 0.42952 - acc: 0.8098 -- iter: 0832/1001
[A[ATraining Step: 283  | total loss: [1m[32m0.42673[0m[0m | time: 28.419s
[2K
| Adam | epoch: 009 | loss: 0.42673 - acc: 0.8100 -- iter: 0864/1001
[A[ATraining Step: 284  | total loss: [1m[32m0.41936[0m[0m | time: 29.625s
[2K
| Adam | epoch: 009 | loss: 0.41936 - acc: 0.8134 -- iter: 0896/1001
[A[ATraining Step: 285  | total loss: [1m[32m0.41491[0m[0m | time: 30.913s
[2K
| Adam | epoch: 009 | loss: 0.41491 - acc: 0.8164 -- iter: 0928/1001
[A[ATraining Step: 286  | total loss: [1m[32m0.40163[0m[0m | time: 32.329s
[2K
| Adam | epoch: 009 | loss: 0.40163 - acc: 0.8254 -- iter: 0960/1001
[A[ATraining Step: 287  | total loss: [1m[32m0.40254[0m[0m | time: 33.445s
[2K
| Adam | epoch: 009 | loss: 0.40254 - acc: 0.8273 -- iter: 0992/1001
[A[ATraining Step: 288  | total loss: [1m[32m0.40050[0m[0m | time: 35.728s
[2K
| Adam | epoch: 009 | loss: 0.40050 - acc: 0.8289 | val_loss: 0.46272 - val_acc: 0.7866 -- iter: 1001/1001
--
Training Step: 289  | total loss: [1m[32m0.37600[0m[0m | time: 0.789s
[2K
| Adam | epoch: 010 | loss: 0.37600 - acc: 0.8429 -- iter: 0032/1001
[A[ATraining Step: 290  | total loss: [1m[32m0.36209[0m[0m | time: 1.531s
[2K
| Adam | epoch: 010 | loss: 0.36209 - acc: 0.8524 -- iter: 0064/1001
[A[ATraining Step: 291  | total loss: [1m[32m0.36270[0m[0m | time: 2.270s
[2K
| Adam | epoch: 010 | loss: 0.36270 - acc: 0.8484 -- iter: 0096/1001
[A[ATraining Step: 292  | total loss: [1m[32m0.35461[0m[0m | time: 3.044s
[2K
| Adam | epoch: 010 | loss: 0.35461 - acc: 0.8479 -- iter: 0128/1001
[A[ATraining Step: 293  | total loss: [1m[32m0.36514[0m[0m | time: 3.834s
[2K
| Adam | epoch: 010 | loss: 0.36514 - acc: 0.8381 -- iter: 0160/1001
[A[ATraining Step: 294  | total loss: [1m[32m0.36304[0m[0m | time: 4.578s
[2K
| Adam | epoch: 010 | loss: 0.36304 - acc: 0.8387 -- iter: 0192/1001
[A[ATraining Step: 295  | total loss: [1m[32m0.34829[0m[0m | time: 5.434s
[2K
| Adam | epoch: 010 | loss: 0.34829 - acc: 0.8517 -- iter: 0224/1001
[A[ATraining Step: 296  | total loss: [1m[32m0.33867[0m[0m | time: 5.671s
[2K
| Adam | epoch: 010 | loss: 0.33867 - acc: 0.8571 -- iter: 0256/1001
[A[ATraining Step: 297  | total loss: [1m[32m0.34420[0m[0m | time: 5.919s
[2K
| Adam | epoch: 010 | loss: 0.34420 - acc: 0.8381 -- iter: 0288/1001
[A[ATraining Step: 298  | total loss: [1m[32m0.36236[0m[0m | time: 6.764s
[2K
| Adam | epoch: 010 | loss: 0.36236 - acc: 0.8321 -- iter: 0320/1001
[A[ATraining Step: 299  | total loss: [1m[32m0.34444[0m[0m | time: 7.522s
[2K
| Adam | epoch: 010 | loss: 0.34444 - acc: 0.8457 -- iter: 0352/1001
[A[ATraining Step: 300  | total loss: [1m[32m0.33006[0m[0m | time: 8.370s
[2K
| Adam | epoch: 010 | loss: 0.33006 - acc: 0.8549 -- iter: 0384/1001
[A[ATraining Step: 301  | total loss: [1m[32m0.33128[0m[0m | time: 9.209s
[2K
| Adam | epoch: 010 | loss: 0.33128 - acc: 0.8569 -- iter: 0416/1001
[A[ATraining Step: 302  | total loss: [1m[32m0.32152[0m[0m | time: 9.987s
[2K
| Adam | epoch: 010 | loss: 0.32152 - acc: 0.8619 -- iter: 0448/1001
[A[ATraining Step: 303  | total loss: [1m[32m0.30223[0m[0m | time: 10.769s
[2K
| Adam | epoch: 010 | loss: 0.30223 - acc: 0.8725 -- iter: 0480/1001
[A[ATraining Step: 304  | total loss: [1m[32m0.31139[0m[0m | time: 11.532s
[2K
| Adam | epoch: 010 | loss: 0.31139 - acc: 0.8665 -- iter: 0512/1001
[A[ATraining Step: 305  | total loss: [1m[32m0.30723[0m[0m | time: 12.250s
[2K
| Adam | epoch: 010 | loss: 0.30723 - acc: 0.8705 -- iter: 0544/1001
[A[ATraining Step: 306  | total loss: [1m[32m0.30129[0m[0m | time: 12.990s
[2K
| Adam | epoch: 010 | loss: 0.30129 - acc: 0.8741 -- iter: 0576/1001
[A[ATraining Step: 307  | total loss: [1m[32m0.29967[0m[0m | time: 13.873s
[2K
| Adam | epoch: 010 | loss: 0.29967 - acc: 0.8773 -- iter: 0608/1001
[A[ATraining Step: 308  | total loss: [1m[32m0.29523[0m[0m | time: 14.729s
[2K
| Adam | epoch: 010 | loss: 0.29523 - acc: 0.8802 -- iter: 0640/1001
[A[ATraining Step: 309  | total loss: [1m[32m0.28804[0m[0m | time: 15.389s
[2K
| Adam | epoch: 010 | loss: 0.28804 - acc: 0.8828 -- iter: 0672/1001
[A[ATraining Step: 310  | total loss: [1m[32m0.28200[0m[0m | time: 16.018s
[2K
| Adam | epoch: 010 | loss: 0.28200 - acc: 0.8820 -- iter: 0704/1001
[A[ATraining Step: 311  | total loss: [1m[32m0.28821[0m[0m | time: 16.698s
[2K
| Adam | epoch: 010 | loss: 0.28821 - acc: 0.8751 -- iter: 0736/1001
[A[ATraining Step: 312  | total loss: [1m[32m0.28127[0m[0m | time: 17.549s
[2K
| Adam | epoch: 010 | loss: 0.28127 - acc: 0.8782 -- iter: 0768/1001
[A[ATraining Step: 313  | total loss: [1m[32m0.27083[0m[0m | time: 18.327s
[2K
| Adam | epoch: 010 | loss: 0.27083 - acc: 0.8841 -- iter: 0800/1001
[A[ATraining Step: 314  | total loss: [1m[32m0.25423[0m[0m | time: 19.116s
[2K
| Adam | epoch: 010 | loss: 0.25423 - acc: 0.8926 -- iter: 0832/1001
[A[ATraining Step: 315  | total loss: [1m[32m0.26493[0m[0m | time: 19.892s
[2K
| Adam | epoch: 010 | loss: 0.26493 - acc: 0.8877 -- iter: 0864/1001
[A[ATraining Step: 316  | total loss: [1m[32m0.25706[0m[0m | time: 20.635s
[2K
| Adam | epoch: 010 | loss: 0.25706 - acc: 0.8927 -- iter: 0896/1001
[A[ATraining Step: 317  | total loss: [1m[32m0.27100[0m[0m | time: 21.419s
[2K
| Adam | epoch: 010 | loss: 0.27100 - acc: 0.8847 -- iter: 0928/1001
[A[ATraining Step: 318  | total loss: [1m[32m0.27894[0m[0m | time: 22.135s
[2K
| Adam | epoch: 010 | loss: 0.27894 - acc: 0.8806 -- iter: 0960/1001
[A[ATraining Step: 319  | total loss: [1m[32m0.27740[0m[0m | time: 22.902s
[2K
| Adam | epoch: 010 | loss: 0.27740 - acc: 0.8800 -- iter: 0992/1001
[A[ATraining Step: 320  | total loss: [1m[32m0.30969[0m[0m | time: 24.961s
[2K
| Adam | epoch: 010 | loss: 0.30969 - acc: 0.8670 | val_loss: 0.59317 - val_acc: 0.7611 -- iter: 1001/1001
--
Training Step: 321  | total loss: [1m[32m0.30491[0m[0m | time: 0.751s
[2K
| Adam | epoch: 011 | loss: 0.30491 - acc: 0.8709 -- iter: 0032/1001
[A[ATraining Step: 322  | total loss: [1m[32m0.28925[0m[0m | time: 1.696s
[2K
| Adam | epoch: 011 | loss: 0.28925 - acc: 0.8776 -- iter: 0064/1001
[A[ATraining Step: 323  | total loss: [1m[32m0.28690[0m[0m | time: 2.893s
[2K
| Adam | epoch: 011 | loss: 0.28690 - acc: 0.8773 -- iter: 0096/1001
[A[ATraining Step: 324  | total loss: [1m[32m0.29186[0m[0m | time: 4.005s
[2K
| Adam | epoch: 011 | loss: 0.29186 - acc: 0.8677 -- iter: 0128/1001
[A[ATraining Step: 325  | total loss: [1m[32m0.30192[0m[0m | time: 5.181s
[2K
| Adam | epoch: 011 | loss: 0.30192 - acc: 0.8653 -- iter: 0160/1001
[A[ATraining Step: 326  | total loss: [1m[32m0.29224[0m[0m | time: 6.720s
[2K
| Adam | epoch: 011 | loss: 0.29224 - acc: 0.8725 -- iter: 0192/1001
[A[ATraining Step: 327  | total loss: [1m[32m0.28385[0m[0m | time: 7.743s
[2K
| Adam | epoch: 011 | loss: 0.28385 - acc: 0.8759 -- iter: 0224/1001
[A[ATraining Step: 328  | total loss: [1m[32m0.27004[0m[0m | time: 8.881s
[2K
| Adam | epoch: 011 | loss: 0.27004 - acc: 0.8821 -- iter: 0256/1001
[A[ATraining Step: 329  | total loss: [1m[32m0.27014[0m[0m | time: 9.204s
[2K
| Adam | epoch: 011 | loss: 0.27014 - acc: 0.8876 -- iter: 0288/1001
[A[ATraining Step: 330  | total loss: [1m[32m0.25607[0m[0m | time: 9.532s
[2K
| Adam | epoch: 011 | loss: 0.25607 - acc: 0.8989 -- iter: 0320/1001
[A[ATraining Step: 331  | total loss: [1m[32m0.32153[0m[0m | time: 10.650s
[2K
| Adam | epoch: 011 | loss: 0.32153 - acc: 0.8867 -- iter: 0352/1001
[A[ATraining Step: 332  | total loss: [1m[32m0.32050[0m[0m | time: 11.912s
[2K
| Adam | epoch: 011 | loss: 0.32050 - acc: 0.8887 -- iter: 0384/1001
[A[ATraining Step: 333  | total loss: [1m[32m0.30953[0m[0m | time: 13.071s
[2K
| Adam | epoch: 011 | loss: 0.30953 - acc: 0.8905 -- iter: 0416/1001
[A[ATraining Step: 334  | total loss: [1m[32m0.29856[0m[0m | time: 13.954s
[2K
| Adam | epoch: 011 | loss: 0.29856 - acc: 0.8889 -- iter: 0448/1001
[A[ATraining Step: 335  | total loss: [1m[32m0.28171[0m[0m | time: 15.007s
[2K
| Adam | epoch: 011 | loss: 0.28171 - acc: 0.8969 -- iter: 0480/1001
[A[ATraining Step: 336  | total loss: [1m[32m0.27246[0m[0m | time: 16.247s
[2K
| Adam | epoch: 011 | loss: 0.27246 - acc: 0.9010 -- iter: 0512/1001
[A[ATraining Step: 337  | total loss: [1m[32m0.25822[0m[0m | time: 17.528s
[2K
| Adam | epoch: 011 | loss: 0.25822 - acc: 0.9046 -- iter: 0544/1001
[A[ATraining Step: 338  | total loss: [1m[32m0.24702[0m[0m | time: 18.489s
[2K
| Adam | epoch: 011 | loss: 0.24702 - acc: 0.9110 -- iter: 0576/1001
[A[ATraining Step: 339  | total loss: [1m[32m0.23406[0m[0m | time: 19.626s
[2K
| Adam | epoch: 011 | loss: 0.23406 - acc: 0.9168 -- iter: 0608/1001
[A[ATraining Step: 340  | total loss: [1m[32m0.23571[0m[0m | time: 20.702s
[2K
| Adam | epoch: 011 | loss: 0.23571 - acc: 0.9126 -- iter: 0640/1001
[A[ATraining Step: 341  | total loss: [1m[32m0.23578[0m[0m | time: 21.732s
[2K
| Adam | epoch: 011 | loss: 0.23578 - acc: 0.9120 -- iter: 0672/1001
[A[ATraining Step: 342  | total loss: [1m[32m0.21967[0m[0m | time: 22.906s
[2K
| Adam | epoch: 011 | loss: 0.21967 - acc: 0.9208 -- iter: 0704/1001
[A[ATraining Step: 343  | total loss: [1m[32m0.21301[0m[0m | time: 24.088s
[2K
| Adam | epoch: 011 | loss: 0.21301 - acc: 0.9256 -- iter: 0736/1001
[A[ATraining Step: 344  | total loss: [1m[32m0.21080[0m[0m | time: 25.301s
[2K
| Adam | epoch: 011 | loss: 0.21080 - acc: 0.9268 -- iter: 0768/1001
[A[ATraining Step: 345  | total loss: [1m[32m0.20187[0m[0m | time: 26.455s
[2K
| Adam | epoch: 011 | loss: 0.20187 - acc: 0.9278 -- iter: 0800/1001
[A[ATraining Step: 346  | total loss: [1m[32m0.20465[0m[0m | time: 27.549s
[2K
| Adam | epoch: 011 | loss: 0.20465 - acc: 0.9319 -- iter: 0832/1001
[A[ATraining Step: 347  | total loss: [1m[32m0.20439[0m[0m | time: 28.789s
[2K
| Adam | epoch: 011 | loss: 0.20439 - acc: 0.9294 -- iter: 0864/1001
[A[ATraining Step: 348  | total loss: [1m[32m0.20121[0m[0m | time: 30.111s
[2K
| Adam | epoch: 011 | loss: 0.20121 - acc: 0.9302 -- iter: 0896/1001
[A[ATraining Step: 349  | total loss: [1m[32m0.19767[0m[0m | time: 31.111s
[2K
| Adam | epoch: 011 | loss: 0.19767 - acc: 0.9309 -- iter: 0928/1001
[A[ATraining Step: 350  | total loss: [1m[32m0.19794[0m[0m | time: 32.083s
[2K
| Adam | epoch: 011 | loss: 0.19794 - acc: 0.9316 -- iter: 0960/1001
[A[ATraining Step: 351  | total loss: [1m[32m0.21948[0m[0m | time: 33.297s
[2K
| Adam | epoch: 011 | loss: 0.21948 - acc: 0.9134 -- iter: 0992/1001
[A[ATraining Step: 352  | total loss: [1m[32m0.20491[0m[0m | time: 36.565s
[2K
| Adam | epoch: 011 | loss: 0.20491 - acc: 0.9221 | val_loss: 0.59007 - val_acc: 0.7866 -- iter: 1001/1001
--
Training Step: 353  | total loss: [1m[32m0.20088[0m[0m | time: 1.236s
[2K
| Adam | epoch: 012 | loss: 0.20088 - acc: 0.9267 -- iter: 0032/1001
[A[ATraining Step: 354  | total loss: [1m[32m0.19351[0m[0m | time: 2.199s
[2K
| Adam | epoch: 012 | loss: 0.19351 - acc: 0.9309 -- iter: 0064/1001
[A[ATraining Step: 355  | total loss: [1m[32m0.19347[0m[0m | time: 3.028s
[2K
| Adam | epoch: 012 | loss: 0.19347 - acc: 0.9316 -- iter: 0096/1001
[A[ATraining Step: 356  | total loss: [1m[32m0.18686[0m[0m | time: 4.549s
[2K
| Adam | epoch: 012 | loss: 0.18686 - acc: 0.9322 -- iter: 0128/1001
[A[ATraining Step: 357  | total loss: [1m[32m0.17870[0m[0m | time: 5.839s
[2K
| Adam | epoch: 012 | loss: 0.17870 - acc: 0.9390 -- iter: 0160/1001
[A[ATraining Step: 358  | total loss: [1m[32m0.17249[0m[0m | time: 6.820s
[2K
| Adam | epoch: 012 | loss: 0.17249 - acc: 0.9388 -- iter: 0192/1001
[A[ATraining Step: 359  | total loss: [1m[32m0.18125[0m[0m | time: 7.853s
[2K
| Adam | epoch: 012 | loss: 0.18125 - acc: 0.9324 -- iter: 0224/1001
[A[ATraining Step: 360  | total loss: [1m[32m0.16704[0m[0m | time: 8.794s
[2K
| Adam | epoch: 012 | loss: 0.16704 - acc: 0.9392 -- iter: 0256/1001
[A[ATraining Step: 361  | total loss: [1m[32m0.17396[0m[0m | time: 9.672s
[2K
| Adam | epoch: 012 | loss: 0.17396 - acc: 0.9390 -- iter: 0288/1001
[A[ATraining Step: 362  | total loss: [1m[32m0.18627[0m[0m | time: 9.960s
[2K
| Adam | epoch: 012 | loss: 0.18627 - acc: 0.9326 -- iter: 0320/1001
[A[ATraining Step: 363  | total loss: [1m[32m0.17354[0m[0m | time: 10.338s
[2K
| Adam | epoch: 012 | loss: 0.17354 - acc: 0.9394 -- iter: 0352/1001
[A[ATraining Step: 364  | total loss: [1m[32m0.26187[0m[0m | time: 11.359s
[2K
| Adam | epoch: 012 | loss: 0.26187 - acc: 0.9121 -- iter: 0384/1001
[A[ATraining Step: 365  | total loss: [1m[32m0.24343[0m[0m | time: 12.554s
[2K
| Adam | epoch: 012 | loss: 0.24343 - acc: 0.9178 -- iter: 0416/1001
[A[ATraining Step: 366  | total loss: [1m[32m0.22619[0m[0m | time: 13.418s
[2K
| Adam | epoch: 012 | loss: 0.22619 - acc: 0.9260 -- iter: 0448/1001
[A[ATraining Step: 367  | total loss: [1m[32m0.22246[0m[0m | time: 14.331s
[2K
| Adam | epoch: 012 | loss: 0.22246 - acc: 0.9271 -- iter: 0480/1001
[A[ATraining Step: 368  | total loss: [1m[32m0.20966[0m[0m | time: 15.303s
[2K
| Adam | epoch: 012 | loss: 0.20966 - acc: 0.9282 -- iter: 0512/1001
[A[ATraining Step: 369  | total loss: [1m[32m0.20340[0m[0m | time: 16.295s
[2K
| Adam | epoch: 012 | loss: 0.20340 - acc: 0.9260 -- iter: 0544/1001
[A[ATraining Step: 370  | total loss: [1m[32m0.18889[0m[0m | time: 17.396s
[2K
| Adam | epoch: 012 | loss: 0.18889 - acc: 0.9334 -- iter: 0576/1001
[A[ATraining Step: 371  | total loss: [1m[32m0.18824[0m[0m | time: 18.337s
[2K
| Adam | epoch: 012 | loss: 0.18824 - acc: 0.9244 -- iter: 0608/1001
[A[ATraining Step: 372  | total loss: [1m[32m0.17315[0m[0m | time: 19.263s
[2K
| Adam | epoch: 012 | loss: 0.17315 - acc: 0.9320 -- iter: 0640/1001
[A[ATraining Step: 373  | total loss: [1m[32m0.18203[0m[0m | time: 20.356s
[2K
| Adam | epoch: 012 | loss: 0.18203 - acc: 0.9325 -- iter: 0672/1001
[A[ATraining Step: 374  | total loss: [1m[32m0.17062[0m[0m | time: 21.540s
[2K
| Adam | epoch: 012 | loss: 0.17062 - acc: 0.9362 -- iter: 0704/1001
[A[ATraining Step: 375  | total loss: [1m[32m0.16409[0m[0m | time: 22.594s
[2K
| Adam | epoch: 012 | loss: 0.16409 - acc: 0.9363 -- iter: 0736/1001
[A[ATraining Step: 376  | total loss: [1m[32m0.15440[0m[0m | time: 23.566s
[2K
| Adam | epoch: 012 | loss: 0.15440 - acc: 0.9427 -- iter: 0768/1001
[A[ATraining Step: 377  | total loss: [1m[32m0.14504[0m[0m | time: 24.561s
[2K
| Adam | epoch: 012 | loss: 0.14504 - acc: 0.9484 -- iter: 0800/1001
[A[ATraining Step: 378  | total loss: [1m[32m0.14300[0m[0m | time: 25.605s
[2K
| Adam | epoch: 012 | loss: 0.14300 - acc: 0.9473 -- iter: 0832/1001
[A[ATraining Step: 379  | total loss: [1m[32m0.14047[0m[0m | time: 26.625s
[2K
| Adam | epoch: 012 | loss: 0.14047 - acc: 0.9494 -- iter: 0864/1001
[A[ATraining Step: 380  | total loss: [1m[32m0.13577[0m[0m | time: 27.637s
[2K
| Adam | epoch: 012 | loss: 0.13577 - acc: 0.9514 -- iter: 0896/1001
[A[ATraining Step: 381  | total loss: [1m[32m0.13217[0m[0m | time: 28.528s
[2K
| Adam | epoch: 012 | loss: 0.13217 - acc: 0.9500 -- iter: 0928/1001
[A[ATraining Step: 382  | total loss: [1m[32m0.13694[0m[0m | time: 29.483s
[2K
| Adam | epoch: 012 | loss: 0.13694 - acc: 0.9487 -- iter: 0960/1001
[A[ATraining Step: 383  | total loss: [1m[32m0.14421[0m[0m | time: 30.313s
[2K
| Adam | epoch: 012 | loss: 0.14421 - acc: 0.9476 -- iter: 0992/1001
[A[ATraining Step: 384  | total loss: [1m[32m0.14534[0m[0m | time: 32.538s
[2K
| Adam | epoch: 012 | loss: 0.14534 - acc: 0.9435 | val_loss: 0.49675 - val_acc: 0.8280 -- iter: 1001/1001
--
Training Step: 385  | total loss: [1m[32m0.13826[0m[0m | time: 1.081s
[2K
| Adam | epoch: 013 | loss: 0.13826 - acc: 0.9460 -- iter: 0032/1001
[A[ATraining Step: 386  | total loss: [1m[32m0.13645[0m[0m | time: 2.059s
[2K
| Adam | epoch: 013 | loss: 0.13645 - acc: 0.9483 -- iter: 0064/1001
[A[ATraining Step: 387  | total loss: [1m[32m0.14301[0m[0m | time: 2.735s
[2K
| Adam | epoch: 013 | loss: 0.14301 - acc: 0.9503 -- iter: 0096/1001
[A[ATraining Step: 388  | total loss: [1m[32m0.13768[0m[0m | time: 3.372s
[2K
| Adam | epoch: 013 | loss: 0.13768 - acc: 0.9522 -- iter: 0128/1001
[A[ATraining Step: 389  | total loss: [1m[32m0.12876[0m[0m | time: 4.026s
[2K
| Adam | epoch: 013 | loss: 0.12876 - acc: 0.9570 -- iter: 0160/1001
[A[ATraining Step: 390  | total loss: [1m[32m0.12638[0m[0m | time: 4.635s
[2K
| Adam | epoch: 013 | loss: 0.12638 - acc: 0.9550 -- iter: 0192/1001
[A[ATraining Step: 391  | total loss: [1m[32m0.12120[0m[0m | time: 5.240s
[2K
| Adam | epoch: 013 | loss: 0.12120 - acc: 0.9564 -- iter: 0224/1001
[A[ATraining Step: 392  | total loss: [1m[32m0.11313[0m[0m | time: 5.871s
[2K
| Adam | epoch: 013 | loss: 0.11313 - acc: 0.9576 -- iter: 0256/1001
[A[ATraining Step: 393  | total loss: [1m[32m0.10453[0m[0m | time: 6.495s
[2K
| Adam | epoch: 013 | loss: 0.10453 - acc: 0.9619 -- iter: 0288/1001
[A[ATraining Step: 394  | total loss: [1m[32m0.09833[0m[0m | time: 7.119s
[2K
| Adam | epoch: 013 | loss: 0.09833 - acc: 0.9657 -- iter: 0320/1001
[A[ATraining Step: 395  | total loss: [1m[32m0.09079[0m[0m | time: 7.338s
[2K
| Adam | epoch: 013 | loss: 0.09079 - acc: 0.9691 -- iter: 0352/1001
[A[ATraining Step: 396  | total loss: [1m[32m0.08333[0m[0m | time: 7.536s
[2K
| Adam | epoch: 013 | loss: 0.08333 - acc: 0.9722 -- iter: 0384/1001
[A[ATraining Step: 397  | total loss: [1m[32m0.13609[0m[0m | time: 8.161s
[2K
| Adam | epoch: 013 | loss: 0.13609 - acc: 0.9639 -- iter: 0416/1001
[A[ATraining Step: 398  | total loss: [1m[32m0.12873[0m[0m | time: 8.799s
[2K
| Adam | epoch: 013 | loss: 0.12873 - acc: 0.9644 -- iter: 0448/1001
[A[ATraining Step: 399  | total loss: [1m[32m0.11780[0m[0m | time: 9.408s
[2K
| Adam | epoch: 013 | loss: 0.11780 - acc: 0.9679 -- iter: 0480/1001
[A[ATraining Step: 400  | total loss: [1m[32m0.11699[0m[0m | time: 11.136s
[2K
| Adam | epoch: 013 | loss: 0.11699 - acc: 0.9618 | val_loss: 0.90790 - val_acc: 0.7516 -- iter: 0512/1001
--
Training Step: 401  | total loss: [1m[32m0.10594[0m[0m | time: 11.779s
[2K
| Adam | epoch: 013 | loss: 0.10594 - acc: 0.9656 -- iter: 0544/1001
[A[ATraining Step: 402  | total loss: [1m[32m0.14189[0m[0m | time: 12.409s
[2K
| Adam | epoch: 013 | loss: 0.14189 - acc: 0.9534 -- iter: 0576/1001
[A[ATraining Step: 403  | total loss: [1m[32m0.14582[0m[0m | time: 13.061s
[2K
| Adam | epoch: 013 | loss: 0.14582 - acc: 0.9456 -- iter: 0608/1001
[A[ATraining Step: 404  | total loss: [1m[32m0.13628[0m[0m | time: 13.748s
[2K
| Adam | epoch: 013 | loss: 0.13628 - acc: 0.9510 -- iter: 0640/1001
[A[ATraining Step: 405  | total loss: [1m[32m0.13218[0m[0m | time: 14.391s
[2K
| Adam | epoch: 013 | loss: 0.13218 - acc: 0.9496 -- iter: 0672/1001
[A[ATraining Step: 406  | total loss: [1m[32m0.12539[0m[0m | time: 15.029s
[2K
| Adam | epoch: 013 | loss: 0.12539 - acc: 0.9516 -- iter: 0704/1001
[A[ATraining Step: 407  | total loss: [1m[32m0.11579[0m[0m | time: 15.671s
[2K
| Adam | epoch: 013 | loss: 0.11579 - acc: 0.9564 -- iter: 0736/1001
[A[ATraining Step: 408  | total loss: [1m[32m0.12273[0m[0m | time: 16.366s
[2K
| Adam | epoch: 013 | loss: 0.12273 - acc: 0.9545 -- iter: 0768/1001
[A[ATraining Step: 409  | total loss: [1m[32m0.11968[0m[0m | time: 16.987s
[2K
| Adam | epoch: 013 | loss: 0.11968 - acc: 0.9528 -- iter: 0800/1001
[A[ATraining Step: 410  | total loss: [1m[32m0.10989[0m[0m | time: 17.606s
[2K
| Adam | epoch: 013 | loss: 0.10989 - acc: 0.9575 -- iter: 0832/1001
[A[ATraining Step: 411  | total loss: [1m[32m0.10889[0m[0m | time: 18.208s
[2K
| Adam | epoch: 013 | loss: 0.10889 - acc: 0.9587 -- iter: 0864/1001
[A[ATraining Step: 412  | total loss: [1m[32m0.10474[0m[0m | time: 18.859s
[2K
| Adam | epoch: 013 | loss: 0.10474 - acc: 0.9597 -- iter: 0896/1001
[A[ATraining Step: 413  | total loss: [1m[32m0.09961[0m[0m | time: 19.477s
[2K
| Adam | epoch: 013 | loss: 0.09961 - acc: 0.9637 -- iter: 0928/1001
[A[ATraining Step: 414  | total loss: [1m[32m0.10293[0m[0m | time: 20.077s
[2K
| Adam | epoch: 013 | loss: 0.10293 - acc: 0.9580 -- iter: 0960/1001
[A[ATraining Step: 415  | total loss: [1m[32m0.10257[0m[0m | time: 20.690s
[2K
| Adam | epoch: 013 | loss: 0.10257 - acc: 0.9590 -- iter: 0992/1001
[A[ATraining Step: 416  | total loss: [1m[32m0.10243[0m[0m | time: 22.433s
[2K
| Adam | epoch: 013 | loss: 0.10243 - acc: 0.9600 | val_loss: 0.81562 - val_acc: 0.7484 -- iter: 1001/1001
--
Training Step: 417  | total loss: [1m[32m0.11681[0m[0m | time: 0.873s
[2K
| Adam | epoch: 014 | loss: 0.11681 - acc: 0.9515 -- iter: 0032/1001
[A[ATraining Step: 418  | total loss: [1m[32m0.11605[0m[0m | time: 1.925s
[2K
| Adam | epoch: 014 | loss: 0.11605 - acc: 0.9501 -- iter: 0064/1001
[A[ATraining Step: 419  | total loss: [1m[32m0.10880[0m[0m | time: 3.008s
[2K
| Adam | epoch: 014 | loss: 0.10880 - acc: 0.9551 -- iter: 0096/1001
[A[ATraining Step: 420  | total loss: [1m[32m0.09952[0m[0m | time: 4.201s
[2K
| Adam | epoch: 014 | loss: 0.09952 - acc: 0.9596 -- iter: 0128/1001
[A[ATraining Step: 421  | total loss: [1m[32m0.09442[0m[0m | time: 5.071s
[2K
| Adam | epoch: 014 | loss: 0.09442 - acc: 0.9636 -- iter: 0160/1001
[A[ATraining Step: 422  | total loss: [1m[32m0.12372[0m[0m | time: 5.993s
[2K
| Adam | epoch: 014 | loss: 0.12372 - acc: 0.9516 -- iter: 0192/1001
[A[ATraining Step: 423  | total loss: [1m[32m0.13502[0m[0m | time: 6.901s
[2K
| Adam | epoch: 014 | loss: 0.13502 - acc: 0.9440 -- iter: 0224/1001
[A[ATraining Step: 424  | total loss: [1m[32m0.13674[0m[0m | time: 7.850s
[2K
| Adam | epoch: 014 | loss: 0.13674 - acc: 0.9433 -- iter: 0256/1001
[A[ATraining Step: 425  | total loss: [1m[32m0.12620[0m[0m | time: 8.849s
[2K
| Adam | epoch: 014 | loss: 0.12620 - acc: 0.9490 -- iter: 0288/1001
[A[ATraining Step: 426  | total loss: [1m[32m0.13740[0m[0m | time: 9.871s
[2K
| Adam | epoch: 014 | loss: 0.13740 - acc: 0.9447 -- iter: 0320/1001
[A[ATraining Step: 427  | total loss: [1m[32m0.15159[0m[0m | time: 10.889s
[2K
| Adam | epoch: 014 | loss: 0.15159 - acc: 0.9409 -- iter: 0352/1001
[A[ATraining Step: 428  | total loss: [1m[32m0.16928[0m[0m | time: 11.158s
[2K
| Adam | epoch: 014 | loss: 0.16928 - acc: 0.9312 -- iter: 0384/1001
[A[ATraining Step: 429  | total loss: [1m[32m0.15439[0m[0m | time: 11.451s
[2K
| Adam | epoch: 014 | loss: 0.15439 - acc: 0.9380 -- iter: 0416/1001
[A[ATraining Step: 430  | total loss: [1m[32m0.13979[0m[0m | time: 12.553s
[2K
| Adam | epoch: 014 | loss: 0.13979 - acc: 0.9442 -- iter: 0448/1001
[A[ATraining Step: 431  | total loss: [1m[32m0.13273[0m[0m | time: 13.720s
[2K
| Adam | epoch: 014 | loss: 0.13273 - acc: 0.9467 -- iter: 0480/1001
[A[ATraining Step: 432  | total loss: [1m[32m0.12210[0m[0m | time: 14.593s
[2K
| Adam | epoch: 014 | loss: 0.12210 - acc: 0.9520 -- iter: 0512/1001
[A[ATraining Step: 433  | total loss: [1m[32m0.12243[0m[0m | time: 15.526s
[2K
| Adam | epoch: 014 | loss: 0.12243 - acc: 0.9506 -- iter: 0544/1001
[A[ATraining Step: 434  | total loss: [1m[32m0.11719[0m[0m | time: 16.532s
[2K
| Adam | epoch: 014 | loss: 0.11719 - acc: 0.9524 -- iter: 0576/1001
[A[ATraining Step: 435  | total loss: [1m[32m0.10841[0m[0m | time: 17.554s
[2K
| Adam | epoch: 014 | loss: 0.10841 - acc: 0.9571 -- iter: 0608/1001
[A[ATraining Step: 436  | total loss: [1m[32m0.11473[0m[0m | time: 18.543s
[2K
| Adam | epoch: 014 | loss: 0.11473 - acc: 0.9552 -- iter: 0640/1001
[A[ATraining Step: 437  | total loss: [1m[32m0.12023[0m[0m | time: 19.604s
[2K
| Adam | epoch: 014 | loss: 0.12023 - acc: 0.9534 -- iter: 0672/1001
[A[ATraining Step: 438  | total loss: [1m[32m0.11171[0m[0m | time: 20.545s
[2K
| Adam | epoch: 014 | loss: 0.11171 - acc: 0.9581 -- iter: 0704/1001
[A[ATraining Step: 439  | total loss: [1m[32m0.10307[0m[0m | time: 21.609s
[2K
| Adam | epoch: 014 | loss: 0.10307 - acc: 0.9623 -- iter: 0736/1001
[A[ATraining Step: 440  | total loss: [1m[32m0.09668[0m[0m | time: 22.748s
[2K
| Adam | epoch: 014 | loss: 0.09668 - acc: 0.9660 -- iter: 0768/1001
[A[ATraining Step: 441  | total loss: [1m[32m0.09031[0m[0m | time: 23.745s
[2K
| Adam | epoch: 014 | loss: 0.09031 - acc: 0.9694 -- iter: 0800/1001
[A[ATraining Step: 442  | total loss: [1m[32m0.08330[0m[0m | time: 24.685s
[2K
| Adam | epoch: 014 | loss: 0.08330 - acc: 0.9725 -- iter: 0832/1001
[A[ATraining Step: 443  | total loss: [1m[32m0.09080[0m[0m | time: 25.593s
[2K
| Adam | epoch: 014 | loss: 0.09080 - acc: 0.9721 -- iter: 0864/1001
[A[ATraining Step: 444  | total loss: [1m[32m0.08598[0m[0m | time: 26.533s
[2K
| Adam | epoch: 014 | loss: 0.08598 - acc: 0.9749 -- iter: 0896/1001
[A[ATraining Step: 445  | total loss: [1m[32m0.08052[0m[0m | time: 27.460s
[2K
| Adam | epoch: 014 | loss: 0.08052 - acc: 0.9774 -- iter: 0928/1001
[A[ATraining Step: 446  | total loss: [1m[32m0.07375[0m[0m | time: 28.526s
[2K
| Adam | epoch: 014 | loss: 0.07375 - acc: 0.9797 -- iter: 0960/1001
[A[ATraining Step: 447  | total loss: [1m[32m0.07680[0m[0m | time: 29.530s
[2K
| Adam | epoch: 014 | loss: 0.07680 - acc: 0.9786 -- iter: 0992/1001
[A[ATraining Step: 448  | total loss: [1m[32m0.07223[0m[0m | time: 32.102s
[2K
| Adam | epoch: 014 | loss: 0.07223 - acc: 0.9807 | val_loss: 0.87445 - val_acc: 0.7803 -- iter: 1001/1001
--
Training Step: 449  | total loss: [1m[32m0.07791[0m[0m | time: 0.948s
[2K
| Adam | epoch: 015 | loss: 0.07791 - acc: 0.9764 -- iter: 0032/1001
[A[ATraining Step: 450  | total loss: [1m[32m0.07532[0m[0m | time: 1.915s
[2K
| Adam | epoch: 015 | loss: 0.07532 - acc: 0.9756 -- iter: 0064/1001
[A[ATraining Step: 451  | total loss: [1m[32m0.06934[0m[0m | time: 2.989s
[2K
| Adam | epoch: 015 | loss: 0.06934 - acc: 0.9781 -- iter: 0096/1001
[A[ATraining Step: 452  | total loss: [1m[32m0.07207[0m[0m | time: 3.985s
[2K
| Adam | epoch: 015 | loss: 0.07207 - acc: 0.9771 -- iter: 0128/1001
[A[ATraining Step: 453  | total loss: [1m[32m0.06782[0m[0m | time: 4.941s
[2K
| Adam | epoch: 015 | loss: 0.06782 - acc: 0.9794 -- iter: 0160/1001
[A[ATraining Step: 454  | total loss: [1m[32m0.07428[0m[0m | time: 6.083s
[2K
| Adam | epoch: 015 | loss: 0.07428 - acc: 0.9784 -- iter: 0192/1001
[A[ATraining Step: 455  | total loss: [1m[32m0.07926[0m[0m | time: 7.233s
[2K
| Adam | epoch: 015 | loss: 0.07926 - acc: 0.9774 -- iter: 0224/1001
[A[ATraining Step: 456  | total loss: [1m[32m0.09440[0m[0m | time: 8.030s
[2K
| Adam | epoch: 015 | loss: 0.09440 - acc: 0.9703 -- iter: 0256/1001
[A[ATraining Step: 457  | total loss: [1m[32m0.08726[0m[0m | time: 8.944s
[2K
| Adam | epoch: 015 | loss: 0.08726 - acc: 0.9733 -- iter: 0288/1001
[A[ATraining Step: 458  | total loss: [1m[32m0.08374[0m[0m | time: 9.972s
[2K
| Adam | epoch: 015 | loss: 0.08374 - acc: 0.9759 -- iter: 0320/1001
[A[ATraining Step: 459  | total loss: [1m[32m0.09880[0m[0m | time: 10.943s
[2K
| Adam | epoch: 015 | loss: 0.09880 - acc: 0.9658 -- iter: 0352/1001
[A[ATraining Step: 460  | total loss: [1m[32m0.10620[0m[0m | time: 12.029s
[2K
| Adam | epoch: 015 | loss: 0.10620 - acc: 0.9630 -- iter: 0384/1001
[A[ATraining Step: 461  | total loss: [1m[32m0.09804[0m[0m | time: 12.397s
[2K
| Adam | epoch: 015 | loss: 0.09804 - acc: 0.9667 -- iter: 0416/1001
[A[ATraining Step: 462  | total loss: [1m[32m0.08911[0m[0m | time: 12.738s
[2K
| Adam | epoch: 015 | loss: 0.08911 - acc: 0.9700 -- iter: 0448/1001
[A[ATraining Step: 463  | total loss: [1m[32m0.08089[0m[0m | time: 13.634s
[2K
| Adam | epoch: 015 | loss: 0.08089 - acc: 0.9730 -- iter: 0480/1001
[A[ATraining Step: 464  | total loss: [1m[32m0.07751[0m[0m | time: 14.548s
[2K
| Adam | epoch: 015 | loss: 0.07751 - acc: 0.9757 -- iter: 0512/1001
[A[ATraining Step: 465  | total loss: [1m[32m0.07861[0m[0m | time: 15.645s
[2K
| Adam | epoch: 015 | loss: 0.07861 - acc: 0.9750 -- iter: 0544/1001
[A[ATraining Step: 466  | total loss: [1m[32m0.07331[0m[0m | time: 16.704s
[2K
| Adam | epoch: 015 | loss: 0.07331 - acc: 0.9775 -- iter: 0576/1001
[A[ATraining Step: 467  | total loss: [1m[32m0.06877[0m[0m | time: 17.493s
[2K
| Adam | epoch: 015 | loss: 0.06877 - acc: 0.9798 -- iter: 0608/1001
[A[ATraining Step: 468  | total loss: [1m[32m0.06270[0m[0m | time: 18.385s
[2K
| Adam | epoch: 015 | loss: 0.06270 - acc: 0.9818 -- iter: 0640/1001
[A[ATraining Step: 469  | total loss: [1m[32m0.06398[0m[0m | time: 19.338s
[2K
| Adam | epoch: 015 | loss: 0.06398 - acc: 0.9805 -- iter: 0672/1001
[A[ATraining Step: 470  | total loss: [1m[32m0.08777[0m[0m | time: 20.327s
[2K
| Adam | epoch: 015 | loss: 0.08777 - acc: 0.9731 -- iter: 0704/1001
[A[ATraining Step: 471  | total loss: [1m[32m0.08021[0m[0m | time: 21.335s
[2K
| Adam | epoch: 015 | loss: 0.08021 - acc: 0.9758 -- iter: 0736/1001
[A[ATraining Step: 472  | total loss: [1m[32m0.07784[0m[0m | time: 22.340s
[2K
| Adam | epoch: 015 | loss: 0.07784 - acc: 0.9782 -- iter: 0768/1001
[A[ATraining Step: 473  | total loss: [1m[32m0.07205[0m[0m | time: 23.261s
[2K
| Adam | epoch: 015 | loss: 0.07205 - acc: 0.9804 -- iter: 0800/1001
[A[ATraining Step: 474  | total loss: [1m[32m0.06556[0m[0m | time: 24.163s
[2K
| Adam | epoch: 015 | loss: 0.06556 - acc: 0.9823 -- iter: 0832/1001
[A[ATraining Step: 475  | total loss: [1m[32m0.06257[0m[0m | time: 25.228s
[2K
| Adam | epoch: 015 | loss: 0.06257 - acc: 0.9810 -- iter: 0864/1001
[A[ATraining Step: 476  | total loss: [1m[32m0.05871[0m[0m | time: 26.362s
[2K
| Adam | epoch: 015 | loss: 0.05871 - acc: 0.9829 -- iter: 0896/1001
[A[ATraining Step: 477  | total loss: [1m[32m0.05553[0m[0m | time: 27.303s
[2K
| Adam | epoch: 015 | loss: 0.05553 - acc: 0.9846 -- iter: 0928/1001
[A[ATraining Step: 478  | total loss: [1m[32m0.05139[0m[0m | time: 27.908s
[2K
| Adam | epoch: 015 | loss: 0.05139 - acc: 0.9861 -- iter: 0960/1001
[A[ATraining Step: 479  | total loss: [1m[32m0.04701[0m[0m | time: 28.527s
[2K
| Adam | epoch: 015 | loss: 0.04701 - acc: 0.9875 -- iter: 0992/1001
[A[ATraining Step: 480  | total loss: [1m[32m0.04845[0m[0m | time: 30.304s
[2K
| Adam | epoch: 015 | loss: 0.04845 - acc: 0.9856 | val_loss: 0.68293 - val_acc: 0.8121 -- iter: 1001/1001
--
Validation AUC:0.9046845163125178
Validation AUPRC:0.9101422684956897
Test AUC:0.8895023105549422
Test AUPRC:0.8883691530764756
BestTestF1Score	0.82	0.66	0.83	0.81	0.82	117	27	144	26	0.2
BestTestMCCScore	0.82	0.66	0.83	0.81	0.82	117	27	144	26	0.2
BestTestAccuracyScore	0.82	0.66	0.83	0.81	0.82	117	27	144	26	0.2
BestValidationF1Score	0.84	0.69	0.84	0.88	0.8	130	17	134	33	0.2
BestValidationMCC	0.84	0.69	0.84	0.88	0.8	130	17	134	33	0.2
BestValidationAccuracy	0.84	0.69	0.84	0.88	0.8	130	17	134	33	0.2
TestPredictions (Threshold:0.2)
CHEMBL248256,TP,ACT,0.9700000286102295	CHEMBL3263998,FP,INACT,0.9100000262260437	CHEMBL565366,FN,ACT,0.0	CHEMBL1087054,TN,INACT,0.0	CHEMBL584052,FN,ACT,0.009999999776482582	CHEMBL71884,TN,INACT,0.029999999329447746	CHEMBL396586,TP,ACT,0.9800000190734863	CHEMBL301845,TN,INACT,0.09000000357627869	CHEMBL213430,TP,ACT,1.0	CHEMBL1087055,TN,INACT,0.0	CHEMBL2331602,TP,ACT,1.0	CHEMBL214063,TP,ACT,0.6399999856948853	CHEMBL77298,TN,INACT,0.0	CHEMBL422564,TN,INACT,0.009999999776482582	CHEMBL226131,TN,INACT,0.009999999776482582	CHEMBL223572,TP,ACT,1.0	CHEMBL515258,TN,INACT,0.009999999776482582	CHEMBL57229,TN,INACT,0.0	CHEMBL522905,TP,ACT,1.0	CHEMBL403661,FN,ACT,0.0	CHEMBL1829272,TN,INACT,0.0	CHEMBL558475,TN,INACT,0.009999999776482582	CHEMBL89505,TN,INACT,0.0	CHEMBL126699,TP,ACT,0.9900000095367432	CHEMBL1835864,FN,ACT,0.0	CHEMBL1910273,TN,INACT,0.009999999776482582	CHEMBL1276890,TP,ACT,0.8600000143051147	CHEMBL2047243,TN,INACT,0.0	CHEMBL3098312,TN,INACT,0.0	CHEMBL1240703,TP,ACT,0.9900000095367432	CHEMBL1933552,FP,INACT,0.3199999928474426	CHEMBL435054,TN,INACT,0.0	CHEMBL141238,TN,INACT,0.0	CHEMBL3086175,TP,ACT,0.949999988079071	CHEMBL1821883,TN,INACT,0.0	CHEMBL1241679,TN,INACT,0.0	CHEMBL590962,TN,INACT,0.0	CHEMBL94581,TN,INACT,0.0	CHEMBL195748,TN,INACT,0.009999999776482582	CHEMBL218061,TN,INACT,0.0	CHEMBL3690077,TP,ACT,0.5299999713897705	CHEMBL485321,TN,INACT,0.0	CHEMBL40275,TN,INACT,0.18000000715255737	CHEMBL137653,FP,INACT,0.9900000095367432	CHEMBL271386,TP,ACT,1.0	CHEMBL1641996,TN,INACT,0.0	CHEMBL543600,TN,INACT,0.009999999776482582	CHEMBL2409775,TP,ACT,0.9700000286102295	CHEMBL247618,TP,ACT,0.9599999785423279	CHEMBL293749,TN,INACT,0.0	CHEMBL598911,TN,INACT,0.0	CHEMBL1171638,TN,INACT,0.0	CHEMBL1242665,TN,INACT,0.0	CHEMBL238617,TN,INACT,0.0	CHEMBL3582441,TP,ACT,0.5099999904632568	CHEMBL1092013,TP,ACT,1.0	CHEMBL1242112,TN,INACT,0.009999999776482582	CHEMBL1944931,FP,INACT,0.9599999785423279	CHEMBL314021,TN,INACT,0.03999999910593033	CHEMBL3358994,TP,ACT,1.0	CHEMBL358243,TN,INACT,0.0	CHEMBL412391,TN,INACT,0.0	CHEMBL272453,TP,ACT,1.0	CHEMBL1172815,TP,ACT,1.0	CHEMBL3425865,FN,ACT,0.019999999552965164	CHEMBL342280,FP,INACT,0.949999988079071	CHEMBL282444,FN,ACT,0.019999999552965164	CHEMBL1172147,TN,INACT,0.019999999552965164	CHEMBL2158230,TP,ACT,1.0	CHEMBL308134,TN,INACT,0.0	CHEMBL425363,FP,INACT,0.8700000047683716	CHEMBL291313,TN,INACT,0.0	CHEMBL312451,TN,INACT,0.009999999776482582	CHEMBL1683951,FP,INACT,0.3100000023841858	CHEMBL259247,TP,ACT,1.0	CHEMBL1095130,TN,INACT,0.0	CHEMBL406375,FN,ACT,0.0	CHEMBL77869,TN,INACT,0.0	CHEMBL87746,TN,INACT,0.0	CHEMBL2337362,TN,INACT,0.0	CHEMBL2148120,TP,ACT,1.0	CHEMBL591706,TN,INACT,0.0	CHEMBL1828880,TN,INACT,0.05999999865889549	CHEMBL2348996,TP,ACT,0.9599999785423279	CHEMBL3237858,FP,INACT,0.9300000071525574	CHEMBL2337372,TN,INACT,0.0	CHEMBL3116440,TP,ACT,1.0	CHEMBL3746776,TP,ACT,1.0	CHEMBL246423,TP,ACT,0.9900000095367432	CHEMBL3114018,TP,ACT,0.9900000095367432	CHEMBL430206,TN,INACT,0.029999999329447746	CHEMBL490823,TP,ACT,1.0	CHEMBL45663,TN,INACT,0.0	CHEMBL545315,TP,ACT,0.25999999046325684	CHEMBL2337366,TN,INACT,0.0	CHEMBL497001,TN,INACT,0.0	CHEMBL1944641,FP,INACT,0.3100000023841858	CHEMBL491418,TP,ACT,1.0	CHEMBL190443,TN,INACT,0.0	CHEMBL3098318,TN,INACT,0.07000000029802322	CHEMBL293913,TN,INACT,0.0	CHEMBL3353406,FP,INACT,0.20000000298023224	CHEMBL2180602,TP,ACT,1.0	CHEMBL553,FN,ACT,0.07000000029802322	CHEMBL189059,FP,INACT,0.8500000238418579	CHEMBL322464,FP,INACT,0.38999998569488525	CHEMBL1230609,TP,ACT,0.9800000190734863	CHEMBL3319469,TP,ACT,1.0	CHEMBL93464,TN,INACT,0.009999999776482582	CHEMBL1172602,TN,INACT,0.0	CHEMBL1076330,TN,INACT,0.0	CHEMBL19978,TN,INACT,0.009999999776482582	CHEMBL2437299,TN,INACT,0.0	CHEMBL280998,FP,INACT,0.5799999833106995	CHEMBL525744,TP,ACT,0.9900000095367432	CHEMBL1738705,TN,INACT,0.0	CHEMBL473825,TN,INACT,0.14000000059604645	CHEMBL3628816,TN,INACT,0.0	CHEMBL1944930,TN,INACT,0.0	CHEMBL101253,TP,ACT,0.9800000190734863	CHEMBL197610,TP,ACT,1.0	CHEMBL1161235,TN,INACT,0.0	CHEMBL375967,TN,INACT,0.0	CHEMBL1336,TP,ACT,1.0	CHEMBL602471,TN,INACT,0.0	CHEMBL2437296,TN,INACT,0.009999999776482582	CHEMBL1765777,TP,ACT,0.9900000095367432	CHEMBL3781538,TN,INACT,0.009999999776482582	CHEMBL149401,TN,INACT,0.0	CHEMBL106966,TP,ACT,1.0	CHEMBL3319449,TP,ACT,1.0	CHEMBL277430,TN,INACT,0.0	CHEMBL3085972,TP,ACT,1.0	CHEMBL430090,TP,ACT,0.7599999904632568	CHEMBL246424,TP,ACT,0.6200000047683716	CHEMBL491238,TP,ACT,0.9900000095367432	CHEMBL3319463,TP,ACT,1.0	CHEMBL1929554,TN,INACT,0.0	CHEMBL1171364,FN,ACT,0.0	CHEMBL589503,TN,INACT,0.0	CHEMBL1765782,TP,ACT,1.0	CHEMBL2086760,FN,ACT,0.0	CHEMBL3680625,TP,ACT,0.9900000095367432	CHEMBL374044,TP,ACT,1.0	CHEMBL1765775,TP,ACT,0.5	CHEMBL2337368,TN,INACT,0.0	CHEMBL404367,TP,ACT,1.0	CHEMBL194321,TP,ACT,1.0	CHEMBL3319448,TP,ACT,1.0	CHEMBL2336030,TP,ACT,0.8399999737739563	CHEMBL156555,TN,INACT,0.0	CHEMBL1094475,TN,INACT,0.0	CHEMBL3222125,TN,INACT,0.0	CHEMBL2047245,TN,INACT,0.0	CHEMBL2430250,TP,ACT,0.9399999976158142	CHEMBL3217993,FP,INACT,0.4699999988079071	CHEMBL589832,FP,INACT,0.9399999976158142	CHEMBL246166,TP,ACT,0.8899999856948853	CHEMBL307179,TN,INACT,0.0	CHEMBL334439,TN,INACT,0.0	CHEMBL327127,TP,ACT,0.9300000071525574	CHEMBL474863,TN,INACT,0.0	CHEMBL492809,TP,ACT,0.36000001430511475	CHEMBL3680623,TP,ACT,0.9900000095367432	CHEMBL470808,TP,ACT,0.9300000071525574	CHEMBL384939,FP,INACT,0.5099999904632568	CHEMBL1651522,TP,ACT,1.0	CHEMBL3683258,TP,ACT,0.2800000011920929	CHEMBL345730,TN,INACT,0.0	CHEMBL489786,TP,ACT,1.0	CHEMBL80171,FP,INACT,0.44999998807907104	CHEMBL3690080,TP,ACT,1.0	CHEMBL1241948,TN,INACT,0.0	CHEMBL150581,TN,INACT,0.03999999910593033	CHEMBL406660,TP,ACT,1.0	CHEMBL214109,FN,ACT,0.009999999776482582	CHEMBL3622193,FN,ACT,0.0	CHEMBL1908395,TP,ACT,0.9900000095367432	CHEMBL150894,FN,ACT,0.0	CHEMBL371379,TP,ACT,0.4000000059604645	CHEMBL3358999,FN,ACT,0.0	CHEMBL505394,TP,ACT,1.0	CHEMBL219887,TP,ACT,1.0	CHEMBL2336011,TP,ACT,0.5600000023841858	CHEMBL345641,TN,INACT,0.0	CHEMBL2312645,FP,INACT,0.550000011920929	CHEMBL2336020,TP,ACT,1.0	CHEMBL2335379,TN,INACT,0.0	CHEMBL520839,TN,INACT,0.0	CHEMBL1945498,FN,ACT,0.0	CHEMBL190496,TN,INACT,0.09000000357627869	CHEMBL274926,TN,INACT,0.0	CHEMBL598727,TN,INACT,0.0	CHEMBL2377495,TN,INACT,0.009999999776482582	CHEMBL450622,FP,INACT,0.6700000166893005	CHEMBL403706,FN,ACT,0.10999999940395355	CHEMBL247389,TP,ACT,0.9800000190734863	CHEMBL1945450,TN,INACT,0.0	CHEMBL247030,TP,ACT,1.0	CHEMBL1929555,TN,INACT,0.0	CHEMBL304271,TN,INACT,0.009999999776482582	CHEMBL379088,TP,ACT,1.0	CHEMBL248397,TP,ACT,1.0	CHEMBL1956897,TN,INACT,0.009999999776482582	CHEMBL591050,TN,INACT,0.0	CHEMBL1242025,FP,INACT,0.9900000095367432	CHEMBL329642,TN,INACT,0.009999999776482582	CHEMBL189691,TN,INACT,0.14000000059604645	CHEMBL3633690,TN,INACT,0.15000000596046448	CHEMBL3335371,TP,ACT,0.41999998688697815	CHEMBL373882,TN,INACT,0.009999999776482582	CHEMBL3236512,TN,INACT,0.0	CHEMBL217091,FP,INACT,0.949999988079071	CHEMBL77555,TP,ACT,0.6600000262260437	CHEMBL506033,TP,ACT,1.0	CHEMBL2346680,FP,INACT,1.0	CHEMBL3358993,FP,INACT,1.0	CHEMBL3099593,TN,INACT,0.05999999865889549	CHEMBL3133826,FP,INACT,0.9200000166893005	CHEMBL3237851,FP,INACT,0.9800000190734863	CHEMBL2347053,FN,ACT,0.0	CHEMBL153526,TN,INACT,0.0	CHEMBL3680619,TP,ACT,0.3799999952316284	CHEMBL1240683,TN,INACT,0.0	CHEMBL1242118,TN,INACT,0.0	CHEMBL13485,FN,ACT,0.0	CHEMBL3109337,TP,ACT,0.9900000095367432	CHEMBL86531,TN,INACT,0.0	CHEMBL564575,TN,INACT,0.0	CHEMBL373845,TP,ACT,1.0	CHEMBL3628808,TP,ACT,1.0	CHEMBL3326099,TP,ACT,0.3199999928474426	CHEMBL1241863,TN,INACT,0.0	CHEMBL213909,TP,ACT,0.7300000190734863	CHEMBL590877,TN,INACT,0.009999999776482582	CHEMBL3361128,TN,INACT,0.0	CHEMBL442273,TP,ACT,1.0	CHEMBL3402237,TN,INACT,0.0	CHEMBL3628818,FP,INACT,0.7300000190734863	CHEMBL1916951,TN,INACT,0.0	CHEMBL272425,TP,ACT,0.9900000095367432	CHEMBL245968,FN,ACT,0.07999999821186066	CHEMBL477560,FN,ACT,0.0	CHEMBL270489,TP,ACT,1.0	CHEMBL215152,TP,ACT,0.9700000286102295	CHEMBL269894,TP,ACT,1.0	CHEMBL2036726,TN,INACT,0.0	CHEMBL599027,TN,INACT,0.0	CHEMBL2047251,TN,INACT,0.0	CHEMBL247585,TP,ACT,1.0	CHEMBL3319455,TP,ACT,1.0	CHEMBL379218,FN,ACT,0.1899999976158142	CHEMBL2337365,TN,INACT,0.0	CHEMBL445636,TP,ACT,0.9399999976158142	CHEMBL3690074,FN,ACT,0.07000000029802322	CHEMBL372174,TP,ACT,1.0	CHEMBL3319452,TP,ACT,1.0	CHEMBL328452,TN,INACT,0.0	CHEMBL535,FN,ACT,0.0	CHEMBL345862,TN,INACT,0.07999999821186066	CHEMBL3319475,TP,ACT,1.0	CHEMBL589259,TN,INACT,0.1599999964237213	CHEMBL3114022,TP,ACT,1.0	CHEMBL213230,FP,INACT,0.9900000095367432	CHEMBL1910268,TN,INACT,0.0	CHEMBL524322,TN,INACT,0.0	CHEMBL442384,TN,INACT,0.029999999329447746	CHEMBL501368,TN,INACT,0.0	CHEMBL200586,TN,INACT,0.0	CHEMBL389147,TN,INACT,0.019999999552965164	CHEMBL339856,TN,INACT,0.1599999964237213	CHEMBL503074,TN,INACT,0.0	CHEMBL461140,TP,ACT,0.9900000095367432	CHEMBL1241683,TN,INACT,0.0	CHEMBL270506,TP,ACT,1.0	CHEMBL3632719,TP,ACT,0.9700000286102295	CHEMBL481248,TN,INACT,0.009999999776482582	CHEMBL3319445,TP,ACT,1.0	CHEMBL69358,TN,INACT,0.019999999552965164	CHEMBL2203434,TP,ACT,0.9900000095367432	CHEMBL601719,FN,ACT,0.14000000059604645	CHEMBL2046883,TP,ACT,0.9800000190734863	CHEMBL524820,TN,INACT,0.0	CHEMBL3233607,TN,INACT,0.0	CHEMBL3358991,TN,INACT,0.0	CHEMBL3309402,TP,ACT,0.46000000834465027	CHEMBL289277,TN,INACT,0.0	CHEMBL1765717,TP,ACT,0.38999998569488525	CHEMBL470483,TP,ACT,1.0	CHEMBL453057,TP,ACT,1.0	CHEMBL348146,TN,INACT,0.0	CHEMBL482489,TN,INACT,0.0	CHEMBL515432,TN,INACT,0.009999999776482582	CHEMBL1765780,TP,ACT,1.0	CHEMBL86631,TN,INACT,0.0	CHEMBL212762,TP,ACT,0.7900000214576721	CHEMBL3632717,TP,ACT,0.5899999737739563	CHEMBL319894,TP,ACT,0.8199999928474426	CHEMBL3104852,TN,INACT,0.0	CHEMBL1945804,TP,ACT,1.0	CHEMBL2047247,TN,INACT,0.0	CHEMBL1173174,TP,ACT,1.0	CHEMBL2047244,TN,INACT,0.0	CHEMBL497290,TN,INACT,0.0	CHEMBL602645,TN,INACT,0.019999999552965164	CHEMBL86432,TN,INACT,0.03999999910593033	CHEMBL523816,TP,ACT,1.0	CHEMBL1681932,FN,ACT,0.10999999940395355	CHEMBL431006,TP,ACT,0.9100000262260437	CHEMBL412102,TP,ACT,1.0	CHEMBL1277161,FN,ACT,0.009999999776482582	CHEMBL505610,TN,INACT,0.009999999776482582	CHEMBL425749,TP,ACT,1.0	CHEMBL553824,TP,ACT,0.7599999904632568	

