CNNModel CHEMBL1981 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	554
Number of inactive compounds :	554
---------------------------------
Run id: CNNModel_CHEMBL1981_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1981_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 708
Validation samples: 222
--
Training Step: 1  | time: 2.969s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/708
[A[ATraining Step: 2  | total loss: [1m[32m0.62366[0m[0m | time: 5.344s
[2K
| Adam | epoch: 001 | loss: 0.62366 - acc: 0.4500 -- iter: 064/708
[A[ATraining Step: 3  | total loss: [1m[32m0.68421[0m[0m | time: 7.836s
[2K
| Adam | epoch: 001 | loss: 0.68421 - acc: 0.3886 -- iter: 096/708
[A[ATraining Step: 4  | total loss: [1m[32m0.69059[0m[0m | time: 9.714s
[2K
| Adam | epoch: 001 | loss: 0.69059 - acc: 0.4722 -- iter: 128/708
[A[ATraining Step: 5  | total loss: [1m[32m0.69118[0m[0m | time: 11.617s
[2K
| Adam | epoch: 001 | loss: 0.69118 - acc: 0.5563 -- iter: 160/708
[A[ATraining Step: 6  | total loss: [1m[32m0.69333[0m[0m | time: 13.582s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.5000 -- iter: 192/708
[A[ATraining Step: 7  | total loss: [1m[32m0.69631[0m[0m | time: 15.146s
[2K
| Adam | epoch: 001 | loss: 0.69631 - acc: 0.4063 -- iter: 224/708
[A[ATraining Step: 8  | total loss: [1m[32m0.69452[0m[0m | time: 16.478s
[2K
| Adam | epoch: 001 | loss: 0.69452 - acc: 0.4590 -- iter: 256/708
[A[ATraining Step: 9  | total loss: [1m[32m0.69467[0m[0m | time: 18.140s
[2K
| Adam | epoch: 001 | loss: 0.69467 - acc: 0.4145 -- iter: 288/708
[A[ATraining Step: 10  | total loss: [1m[32m0.69437[0m[0m | time: 20.757s
[2K
| Adam | epoch: 001 | loss: 0.69437 - acc: 0.3948 -- iter: 320/708
[A[ATraining Step: 11  | total loss: [1m[32m0.69378[0m[0m | time: 23.196s
[2K
| Adam | epoch: 001 | loss: 0.69378 - acc: 0.4742 -- iter: 352/708
[A[ATraining Step: 12  | total loss: [1m[32m0.69346[0m[0m | time: 24.704s
[2K
| Adam | epoch: 001 | loss: 0.69346 - acc: 0.4858 -- iter: 384/708
[A[ATraining Step: 13  | total loss: [1m[32m0.69316[0m[0m | time: 28.246s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5053 -- iter: 416/708
[A[ATraining Step: 14  | total loss: [1m[32m0.69255[0m[0m | time: 30.378s
[2K
| Adam | epoch: 001 | loss: 0.69255 - acc: 0.5415 -- iter: 448/708
[A[ATraining Step: 15  | total loss: [1m[32m0.69328[0m[0m | time: 33.315s
[2K
| Adam | epoch: 001 | loss: 0.69328 - acc: 0.5008 -- iter: 480/708
[A[ATraining Step: 16  | total loss: [1m[32m0.69267[0m[0m | time: 35.237s
[2K
| Adam | epoch: 001 | loss: 0.69267 - acc: 0.5239 -- iter: 512/708
[A[ATraining Step: 17  | total loss: [1m[32m0.69252[0m[0m | time: 38.398s
[2K
| Adam | epoch: 001 | loss: 0.69252 - acc: 0.5266 -- iter: 544/708
[A[ATraining Step: 18  | total loss: [1m[32m0.69278[0m[0m | time: 41.065s
[2K
| Adam | epoch: 001 | loss: 0.69278 - acc: 0.5174 -- iter: 576/708
[A[ATraining Step: 19  | total loss: [1m[32m0.69377[0m[0m | time: 45.342s
[2K
| Adam | epoch: 001 | loss: 0.69377 - acc: 0.5012 -- iter: 608/708
[A[ATraining Step: 20  | total loss: [1m[32m0.69187[0m[0m | time: 47.034s
[2K
| Adam | epoch: 001 | loss: 0.69187 - acc: 0.5309 -- iter: 640/708
[A[ATraining Step: 21  | total loss: [1m[32m0.69110[0m[0m | time: 50.307s
[2K
| Adam | epoch: 001 | loss: 0.69110 - acc: 0.5407 -- iter: 672/708
[A[ATraining Step: 22  | total loss: [1m[32m0.69295[0m[0m | time: 51.702s
[2K
| Adam | epoch: 001 | loss: 0.69295 - acc: 0.5191 -- iter: 704/708
[A[ATraining Step: 23  | total loss: [1m[32m0.68984[0m[0m | time: 53.230s
[2K
| Adam | epoch: 001 | loss: 0.68984 - acc: 0.5499 | val_loss: 0.69479 - val_acc: 0.4955 -- iter: 708/708
--
Training Step: 24  | total loss: [1m[32m0.69917[0m[0m | time: 0.266s
[2K
| Adam | epoch: 002 | loss: 0.69917 - acc: 0.4655 -- iter: 032/708
[A[ATraining Step: 25  | total loss: [1m[32m0.70511[0m[0m | time: 1.116s
[2K
| Adam | epoch: 002 | loss: 0.70511 - acc: 0.4067 -- iter: 064/708
[A[ATraining Step: 26  | total loss: [1m[32m0.70030[0m[0m | time: 2.130s
[2K
| Adam | epoch: 002 | loss: 0.70030 - acc: 0.4562 -- iter: 096/708
[A[ATraining Step: 27  | total loss: [1m[32m0.69843[0m[0m | time: 3.181s
[2K
| Adam | epoch: 002 | loss: 0.69843 - acc: 0.4675 -- iter: 128/708
[A[ATraining Step: 28  | total loss: [1m[32m0.69849[0m[0m | time: 4.214s
[2K
| Adam | epoch: 002 | loss: 0.69849 - acc: 0.4444 -- iter: 160/708
[A[ATraining Step: 29  | total loss: [1m[32m0.69634[0m[0m | time: 5.162s
[2K
| Adam | epoch: 002 | loss: 0.69634 - acc: 0.4883 -- iter: 192/708
[A[ATraining Step: 30  | total loss: [1m[32m0.69563[0m[0m | time: 6.163s
[2K
| Adam | epoch: 002 | loss: 0.69563 - acc: 0.4911 -- iter: 224/708
[A[ATraining Step: 31  | total loss: [1m[32m0.69494[0m[0m | time: 7.085s
[2K
| Adam | epoch: 002 | loss: 0.69494 - acc: 0.5003 -- iter: 256/708
[A[ATraining Step: 32  | total loss: [1m[32m0.69494[0m[0m | time: 8.102s
[2K
| Adam | epoch: 002 | loss: 0.69494 - acc: 0.4792 -- iter: 288/708
[A[ATraining Step: 33  | total loss: [1m[32m0.69420[0m[0m | time: 9.109s
[2K
| Adam | epoch: 002 | loss: 0.69420 - acc: 0.5043 -- iter: 320/708
[A[ATraining Step: 34  | total loss: [1m[32m0.69418[0m[0m | time: 10.152s
[2K
| Adam | epoch: 002 | loss: 0.69418 - acc: 0.4900 -- iter: 352/708
[A[ATraining Step: 35  | total loss: [1m[32m0.69397[0m[0m | time: 11.288s
[2K
| Adam | epoch: 002 | loss: 0.69397 - acc: 0.4921 -- iter: 384/708
[A[ATraining Step: 36  | total loss: [1m[32m0.69346[0m[0m | time: 12.367s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.5193 -- iter: 416/708
[A[ATraining Step: 37  | total loss: [1m[32m0.69339[0m[0m | time: 13.256s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.5154 -- iter: 448/708
[A[ATraining Step: 38  | total loss: [1m[32m0.69357[0m[0m | time: 14.325s
[2K
| Adam | epoch: 002 | loss: 0.69357 - acc: 0.4941 -- iter: 480/708
[A[ATraining Step: 39  | total loss: [1m[32m0.69350[0m[0m | time: 15.274s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.4952 -- iter: 512/708
[A[ATraining Step: 40  | total loss: [1m[32m0.69348[0m[0m | time: 16.217s
[2K
| Adam | epoch: 002 | loss: 0.69348 - acc: 0.4902 -- iter: 544/708
[A[ATraining Step: 41  | total loss: [1m[32m0.69346[0m[0m | time: 17.143s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.4863 -- iter: 576/708
[A[ATraining Step: 42  | total loss: [1m[32m0.69361[0m[0m | time: 18.063s
[2K
| Adam | epoch: 002 | loss: 0.69361 - acc: 0.4663 -- iter: 608/708
[A[ATraining Step: 43  | total loss: [1m[32m0.69348[0m[0m | time: 19.048s
[2K
| Adam | epoch: 002 | loss: 0.69348 - acc: 0.4777 -- iter: 640/708
[A[ATraining Step: 44  | total loss: [1m[32m0.69347[0m[0m | time: 19.952s
[2K
| Adam | epoch: 002 | loss: 0.69347 - acc: 0.4762 -- iter: 672/708
[A[ATraining Step: 45  | total loss: [1m[32m0.69327[0m[0m | time: 20.819s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.5068 -- iter: 704/708
[A[ATraining Step: 46  | total loss: [1m[32m0.69319[0m[0m | time: 23.139s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5160 | val_loss: 0.69317 - val_acc: 0.4955 -- iter: 708/708
--
Training Step: 47  | total loss: [1m[32m0.69324[0m[0m | time: 0.137s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.5032 -- iter: 032/708
[A[ATraining Step: 48  | total loss: [1m[32m0.69302[0m[0m | time: 0.271s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5429 -- iter: 064/708
[A[ATraining Step: 49  | total loss: [1m[32m0.69277[0m[0m | time: 1.316s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5756 -- iter: 096/708
[A[ATraining Step: 50  | total loss: [1m[32m0.69284[0m[0m | time: 2.249s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5638 -- iter: 128/708
[A[ATraining Step: 51  | total loss: [1m[32m0.69284[0m[0m | time: 3.082s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5589 -- iter: 160/708
[A[ATraining Step: 52  | total loss: [1m[32m0.69302[0m[0m | time: 3.978s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5407 -- iter: 192/708
[A[ATraining Step: 53  | total loss: [1m[32m0.69299[0m[0m | time: 4.917s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5393 -- iter: 224/708
[A[ATraining Step: 54  | total loss: [1m[32m0.69294[0m[0m | time: 5.789s
[2K
| Adam | epoch: 003 | loss: 0.69294 - acc: 0.5381 -- iter: 256/708
[A[ATraining Step: 55  | total loss: [1m[32m0.69291[0m[0m | time: 6.642s
[2K
| Adam | epoch: 003 | loss: 0.69291 - acc: 0.5371 -- iter: 288/708
[A[ATraining Step: 56  | total loss: [1m[32m0.69300[0m[0m | time: 7.522s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5275 -- iter: 320/708
[A[ATraining Step: 57  | total loss: [1m[32m0.69270[0m[0m | time: 8.432s
[2K
| Adam | epoch: 003 | loss: 0.69270 - acc: 0.5410 -- iter: 352/708
[A[ATraining Step: 58  | total loss: [1m[32m0.69231[0m[0m | time: 9.337s
[2K
| Adam | epoch: 003 | loss: 0.69231 - acc: 0.5567 -- iter: 384/708
[A[ATraining Step: 59  | total loss: [1m[32m0.69263[0m[0m | time: 10.227s
[2K
| Adam | epoch: 003 | loss: 0.69263 - acc: 0.5407 -- iter: 416/708
[A[ATraining Step: 60  | total loss: [1m[32m0.69256[0m[0m | time: 11.239s
[2K
| Adam | epoch: 003 | loss: 0.69256 - acc: 0.5395 -- iter: 448/708
[A[ATraining Step: 61  | total loss: [1m[32m0.69250[0m[0m | time: 12.188s
[2K
| Adam | epoch: 003 | loss: 0.69250 - acc: 0.5384 -- iter: 480/708
[A[ATraining Step: 62  | total loss: [1m[32m0.69235[0m[0m | time: 12.991s
[2K
| Adam | epoch: 003 | loss: 0.69235 - acc: 0.5415 -- iter: 512/708
[A[ATraining Step: 63  | total loss: [1m[32m0.69246[0m[0m | time: 13.830s
[2K
| Adam | epoch: 003 | loss: 0.69246 - acc: 0.5362 -- iter: 544/708
[A[ATraining Step: 64  | total loss: [1m[32m0.69203[0m[0m | time: 14.648s
[2K
| Adam | epoch: 003 | loss: 0.69203 - acc: 0.5434 -- iter: 576/708
[A[ATraining Step: 65  | total loss: [1m[32m0.69063[0m[0m | time: 15.556s
[2K
| Adam | epoch: 003 | loss: 0.69063 - acc: 0.5650 -- iter: 608/708
[A[ATraining Step: 66  | total loss: [1m[32m0.69164[0m[0m | time: 16.483s
[2K
| Adam | epoch: 003 | loss: 0.69164 - acc: 0.5495 -- iter: 640/708
[A[ATraining Step: 67  | total loss: [1m[32m0.69225[0m[0m | time: 17.405s
[2K
| Adam | epoch: 003 | loss: 0.69225 - acc: 0.5398 -- iter: 672/708
[A[ATraining Step: 68  | total loss: [1m[32m0.69244[0m[0m | time: 18.312s
[2K
| Adam | epoch: 003 | loss: 0.69244 - acc: 0.5351 -- iter: 704/708
[A[ATraining Step: 69  | total loss: [1m[32m0.69216[0m[0m | time: 20.495s
[2K
| Adam | epoch: 003 | loss: 0.69216 - acc: 0.5347 | val_loss: 0.69585 - val_acc: 0.4955 -- iter: 708/708
--
Training Step: 70  | total loss: [1m[32m0.69000[0m[0m | time: 0.857s
[2K
| Adam | epoch: 004 | loss: 0.69000 - acc: 0.5523 -- iter: 032/708
[A[ATraining Step: 71  | total loss: [1m[32m0.69243[0m[0m | time: 0.977s
[2K
| Adam | epoch: 004 | loss: 0.69243 - acc: 0.5321 -- iter: 064/708
[A[ATraining Step: 72  | total loss: [1m[32m0.69271[0m[0m | time: 1.209s
[2K
| Adam | epoch: 004 | loss: 0.69271 - acc: 0.5285 -- iter: 096/708
[A[ATraining Step: 73  | total loss: [1m[32m0.69297[0m[0m | time: 2.103s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5253 -- iter: 128/708
[A[ATraining Step: 74  | total loss: [1m[32m0.69059[0m[0m | time: 2.924s
[2K
| Adam | epoch: 004 | loss: 0.69059 - acc: 0.5431 -- iter: 160/708
[A[ATraining Step: 75  | total loss: [1m[32m0.68877[0m[0m | time: 3.776s
[2K
| Adam | epoch: 004 | loss: 0.68877 - acc: 0.5554 -- iter: 192/708
[A[ATraining Step: 76  | total loss: [1m[32m0.69011[0m[0m | time: 4.646s
[2K
| Adam | epoch: 004 | loss: 0.69011 - acc: 0.5461 -- iter: 224/708
[A[ATraining Step: 77  | total loss: [1m[32m0.69141[0m[0m | time: 5.448s
[2K
| Adam | epoch: 004 | loss: 0.69141 - acc: 0.5379 -- iter: 256/708
[A[ATraining Step: 78  | total loss: [1m[32m0.69250[0m[0m | time: 6.447s
[2K
| Adam | epoch: 004 | loss: 0.69250 - acc: 0.5307 -- iter: 288/708
[A[ATraining Step: 79  | total loss: [1m[32m0.69526[0m[0m | time: 7.350s
[2K
| Adam | epoch: 004 | loss: 0.69526 - acc: 0.5113 -- iter: 320/708
[A[ATraining Step: 80  | total loss: [1m[32m0.69484[0m[0m | time: 8.187s
[2K
| Adam | epoch: 004 | loss: 0.69484 - acc: 0.5134 -- iter: 352/708
[A[ATraining Step: 81  | total loss: [1m[32m0.69355[0m[0m | time: 9.087s
[2K
| Adam | epoch: 004 | loss: 0.69355 - acc: 0.5247 -- iter: 384/708
[A[ATraining Step: 82  | total loss: [1m[32m0.69386[0m[0m | time: 10.075s
[2K
| Adam | epoch: 004 | loss: 0.69386 - acc: 0.5191 -- iter: 416/708
[A[ATraining Step: 83  | total loss: [1m[32m0.69488[0m[0m | time: 10.963s
[2K
| Adam | epoch: 004 | loss: 0.69488 - acc: 0.5047 -- iter: 448/708
[A[ATraining Step: 84  | total loss: [1m[32m0.69455[0m[0m | time: 11.820s
[2K
| Adam | epoch: 004 | loss: 0.69455 - acc: 0.5073 -- iter: 480/708
[A[ATraining Step: 85  | total loss: [1m[32m0.69497[0m[0m | time: 12.807s
[2K
| Adam | epoch: 004 | loss: 0.69497 - acc: 0.4972 -- iter: 512/708
[A[ATraining Step: 86  | total loss: [1m[32m0.69464[0m[0m | time: 13.677s
[2K
| Adam | epoch: 004 | loss: 0.69464 - acc: 0.5006 -- iter: 544/708
[A[ATraining Step: 87  | total loss: [1m[32m0.69453[0m[0m | time: 14.553s
[2K
| Adam | epoch: 004 | loss: 0.69453 - acc: 0.5006 -- iter: 576/708
[A[ATraining Step: 88  | total loss: [1m[32m0.69419[0m[0m | time: 15.454s
[2K
| Adam | epoch: 004 | loss: 0.69419 - acc: 0.5068 -- iter: 608/708
[A[ATraining Step: 89  | total loss: [1m[32m0.69364[0m[0m | time: 16.321s
[2K
| Adam | epoch: 004 | loss: 0.69364 - acc: 0.5186 -- iter: 640/708
[A[ATraining Step: 90  | total loss: [1m[32m0.69346[0m[0m | time: 17.193s
[2K
| Adam | epoch: 004 | loss: 0.69346 - acc: 0.5198 -- iter: 672/708
[A[ATraining Step: 91  | total loss: [1m[32m0.69320[0m[0m | time: 18.099s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.5241 -- iter: 704/708
[A[ATraining Step: 92  | total loss: [1m[32m0.69341[0m[0m | time: 20.353s
[2K
| Adam | epoch: 004 | loss: 0.69341 - acc: 0.5154 | val_loss: 0.69336 - val_acc: 0.4955 -- iter: 708/708
--
Training Step: 93  | total loss: [1m[32m0.69340[0m[0m | time: 0.856s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.5139 -- iter: 032/708
[A[ATraining Step: 94  | total loss: [1m[32m0.69316[0m[0m | time: 1.752s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.5188 -- iter: 064/708
[A[ATraining Step: 95  | total loss: [1m[32m0.69316[0m[0m | time: 1.881s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.5169 -- iter: 096/708
[A[ATraining Step: 96  | total loss: [1m[32m0.69322[0m[0m | time: 2.013s
[2K
| Adam | epoch: 005 | loss: 0.69322 - acc: 0.5152 -- iter: 128/708
[A[ATraining Step: 97  | total loss: [1m[32m0.69320[0m[0m | time: 2.969s
[2K
| Adam | epoch: 005 | loss: 0.69320 - acc: 0.5137 -- iter: 160/708
[A[ATraining Step: 98  | total loss: [1m[32m0.69362[0m[0m | time: 3.765s
[2K
| Adam | epoch: 005 | loss: 0.69362 - acc: 0.4998 -- iter: 192/708
[A[ATraining Step: 99  | total loss: [1m[32m0.69367[0m[0m | time: 4.619s
[2K
| Adam | epoch: 005 | loss: 0.69367 - acc: 0.4967 -- iter: 224/708
[A[ATraining Step: 100  | total loss: [1m[32m0.69313[0m[0m | time: 5.455s
[2K
| Adam | epoch: 005 | loss: 0.69313 - acc: 0.5127 -- iter: 256/708
[A[ATraining Step: 101  | total loss: [1m[32m0.69345[0m[0m | time: 6.330s
[2K
| Adam | epoch: 005 | loss: 0.69345 - acc: 0.5020 -- iter: 288/708
[A[ATraining Step: 102  | total loss: [1m[32m0.69371[0m[0m | time: 7.216s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.4924 -- iter: 320/708
[A[ATraining Step: 103  | total loss: [1m[32m0.69302[0m[0m | time: 8.010s
[2K
| Adam | epoch: 005 | loss: 0.69302 - acc: 0.5151 -- iter: 352/708
[A[ATraining Step: 104  | total loss: [1m[32m0.69294[0m[0m | time: 8.912s
[2K
| Adam | epoch: 005 | loss: 0.69294 - acc: 0.5167 -- iter: 384/708
[A[ATraining Step: 105  | total loss: [1m[32m0.69295[0m[0m | time: 9.757s
[2K
| Adam | epoch: 005 | loss: 0.69295 - acc: 0.5150 -- iter: 416/708
[A[ATraining Step: 106  | total loss: [1m[32m0.69286[0m[0m | time: 10.690s
[2K
| Adam | epoch: 005 | loss: 0.69286 - acc: 0.5166 -- iter: 448/708
[A[ATraining Step: 107  | total loss: [1m[32m0.69243[0m[0m | time: 11.553s
[2K
| Adam | epoch: 005 | loss: 0.69243 - acc: 0.5306 -- iter: 480/708
[A[ATraining Step: 108  | total loss: [1m[32m0.69270[0m[0m | time: 12.360s
[2K
| Adam | epoch: 005 | loss: 0.69270 - acc: 0.5213 -- iter: 512/708
[A[ATraining Step: 109  | total loss: [1m[32m0.69305[0m[0m | time: 13.302s
[2K
| Adam | epoch: 005 | loss: 0.69305 - acc: 0.5098 -- iter: 544/708
[A[ATraining Step: 110  | total loss: [1m[32m0.69265[0m[0m | time: 14.102s
[2K
| Adam | epoch: 005 | loss: 0.69265 - acc: 0.5213 -- iter: 576/708
[A[ATraining Step: 111  | total loss: [1m[32m0.69312[0m[0m | time: 14.979s
[2K
| Adam | epoch: 005 | loss: 0.69312 - acc: 0.5067 -- iter: 608/708
[A[ATraining Step: 112  | total loss: [1m[32m0.69321[0m[0m | time: 15.822s
[2K
| Adam | epoch: 005 | loss: 0.69321 - acc: 0.5029 -- iter: 640/708
[A[ATraining Step: 113  | total loss: [1m[32m0.69338[0m[0m | time: 16.736s
[2K
| Adam | epoch: 005 | loss: 0.69338 - acc: 0.4963 -- iter: 672/708
[A[ATraining Step: 114  | total loss: [1m[32m0.69343[0m[0m | time: 17.575s
[2K
| Adam | epoch: 005 | loss: 0.69343 - acc: 0.4936 -- iter: 704/708
[A[ATraining Step: 115  | total loss: [1m[32m0.69307[0m[0m | time: 19.560s
[2K
| Adam | epoch: 005 | loss: 0.69307 - acc: 0.5036 | val_loss: 0.69314 - val_acc: 0.4955 -- iter: 708/708
--
Training Step: 116  | total loss: [1m[32m0.69297[0m[0m | time: 0.986s
[2K
| Adam | epoch: 006 | loss: 0.69297 - acc: 0.5064 -- iter: 032/708
[A[ATraining Step: 117  | total loss: [1m[32m0.69266[0m[0m | time: 1.917s
[2K
| Adam | epoch: 006 | loss: 0.69266 - acc: 0.5151 -- iter: 064/708
[A[ATraining Step: 118  | total loss: [1m[32m0.69289[0m[0m | time: 2.770s
[2K
| Adam | epoch: 006 | loss: 0.69289 - acc: 0.5073 -- iter: 096/708
[A[ATraining Step: 119  | total loss: [1m[32m0.69309[0m[0m | time: 2.956s
[2K
| Adam | epoch: 006 | loss: 0.69309 - acc: 0.5004 -- iter: 128/708
[A[ATraining Step: 120  | total loss: [1m[32m0.69227[0m[0m | time: 3.097s
[2K
| Adam | epoch: 006 | loss: 0.69227 - acc: 0.5253 -- iter: 160/708
[A[ATraining Step: 121  | total loss: [1m[32m0.69153[0m[0m | time: 4.054s
[2K
| Adam | epoch: 006 | loss: 0.69153 - acc: 0.5478 -- iter: 192/708
[A[ATraining Step: 122  | total loss: [1m[32m0.69131[0m[0m | time: 4.741s
[2K
| Adam | epoch: 006 | loss: 0.69131 - acc: 0.5524 -- iter: 224/708
[A[ATraining Step: 123  | total loss: [1m[32m0.69109[0m[0m | time: 5.674s
[2K
| Adam | epoch: 006 | loss: 0.69109 - acc: 0.5565 -- iter: 256/708
[A[ATraining Step: 124  | total loss: [1m[32m0.69187[0m[0m | time: 6.633s
[2K
| Adam | epoch: 006 | loss: 0.69187 - acc: 0.5384 -- iter: 288/708
[A[ATraining Step: 125  | total loss: [1m[32m0.69227[0m[0m | time: 7.386s
[2K
| Adam | epoch: 006 | loss: 0.69227 - acc: 0.5283 -- iter: 320/708
[A[ATraining Step: 126  | total loss: [1m[32m0.69175[0m[0m | time: 8.313s
[2K
| Adam | epoch: 006 | loss: 0.69175 - acc: 0.5380 -- iter: 352/708
[A[ATraining Step: 127  | total loss: [1m[32m0.69104[0m[0m | time: 9.240s
[2K
| Adam | epoch: 006 | loss: 0.69104 - acc: 0.5498 -- iter: 384/708
[A[ATraining Step: 128  | total loss: [1m[32m0.69165[0m[0m | time: 10.207s
[2K
| Adam | epoch: 006 | loss: 0.69165 - acc: 0.5386 -- iter: 416/708
[A[ATraining Step: 129  | total loss: [1m[32m0.69199[0m[0m | time: 11.026s
[2K
| Adam | epoch: 006 | loss: 0.69199 - acc: 0.5316 -- iter: 448/708
[A[ATraining Step: 130  | total loss: [1m[32m0.69138[0m[0m | time: 11.954s
[2K
| Adam | epoch: 006 | loss: 0.69138 - acc: 0.5378 -- iter: 480/708
[A[ATraining Step: 131  | total loss: [1m[32m0.69157[0m[0m | time: 12.865s
[2K
| Adam | epoch: 006 | loss: 0.69157 - acc: 0.5340 -- iter: 512/708
[A[ATraining Step: 132  | total loss: [1m[32m0.69124[0m[0m | time: 13.695s
[2K
| Adam | epoch: 006 | loss: 0.69124 - acc: 0.5369 -- iter: 544/708
[A[ATraining Step: 133  | total loss: [1m[32m0.69157[0m[0m | time: 14.596s
[2K
| Adam | epoch: 006 | loss: 0.69157 - acc: 0.5301 -- iter: 576/708
[A[ATraining Step: 134  | total loss: [1m[32m0.69111[0m[0m | time: 15.350s
[2K
| Adam | epoch: 006 | loss: 0.69111 - acc: 0.5333 -- iter: 608/708
[A[ATraining Step: 135  | total loss: [1m[32m0.69126[0m[0m | time: 16.261s
[2K
| Adam | epoch: 006 | loss: 0.69126 - acc: 0.5300 -- iter: 640/708
[A[ATraining Step: 136  | total loss: [1m[32m0.69067[0m[0m | time: 17.183s
[2K
| Adam | epoch: 006 | loss: 0.69067 - acc: 0.5332 -- iter: 672/708
[A[ATraining Step: 137  | total loss: [1m[32m0.69237[0m[0m | time: 18.124s
[2K
| Adam | epoch: 006 | loss: 0.69237 - acc: 0.5174 -- iter: 704/708
[A[ATraining Step: 138  | total loss: [1m[32m0.69251[0m[0m | time: 20.000s
[2K
| Adam | epoch: 006 | loss: 0.69251 - acc: 0.5157 | val_loss: 0.69213 - val_acc: 0.4955 -- iter: 708/708
--
Training Step: 139  | total loss: [1m[32m0.69346[0m[0m | time: 0.899s
[2K
| Adam | epoch: 007 | loss: 0.69346 - acc: 0.5047 -- iter: 032/708
[A[ATraining Step: 140  | total loss: [1m[32m0.69336[0m[0m | time: 1.708s
[2K
| Adam | epoch: 007 | loss: 0.69336 - acc: 0.5011 -- iter: 064/708
[A[ATraining Step: 141  | total loss: [1m[32m0.69272[0m[0m | time: 2.536s
[2K
| Adam | epoch: 007 | loss: 0.69272 - acc: 0.5073 -- iter: 096/708
[A[ATraining Step: 142  | total loss: [1m[32m0.69098[0m[0m | time: 3.455s
[2K
| Adam | epoch: 007 | loss: 0.69098 - acc: 0.5253 -- iter: 128/708
[A[ATraining Step: 143  | total loss: [1m[32m0.68979[0m[0m | time: 3.652s
[2K
| Adam | epoch: 007 | loss: 0.68979 - acc: 0.5353 -- iter: 160/708
[A[ATraining Step: 144  | total loss: [1m[32m0.68982[0m[0m | time: 3.835s
[2K
| Adam | epoch: 007 | loss: 0.68982 - acc: 0.5317 -- iter: 192/708
[A[ATraining Step: 145  | total loss: [1m[32m0.68987[0m[0m | time: 4.688s
[2K
| Adam | epoch: 007 | loss: 0.68987 - acc: 0.5286 -- iter: 224/708
[A[ATraining Step: 146  | total loss: [1m[32m0.69041[0m[0m | time: 5.535s
[2K
| Adam | epoch: 007 | loss: 0.69041 - acc: 0.5226 -- iter: 256/708
[A[ATraining Step: 147  | total loss: [1m[32m0.69089[0m[0m | time: 6.375s
[2K
| Adam | epoch: 007 | loss: 0.69089 - acc: 0.5172 -- iter: 288/708
[A[ATraining Step: 148  | total loss: [1m[32m0.69115[0m[0m | time: 7.163s
[2K
| Adam | epoch: 007 | loss: 0.69115 - acc: 0.5123 -- iter: 320/708
[A[ATraining Step: 149  | total loss: [1m[32m0.68897[0m[0m | time: 8.060s
[2K
| Adam | epoch: 007 | loss: 0.68897 - acc: 0.5236 -- iter: 352/708
[A[ATraining Step: 150  | total loss: [1m[32m0.68907[0m[0m | time: 8.928s
[2K
| Adam | epoch: 007 | loss: 0.68907 - acc: 0.5181 -- iter: 384/708
[A[ATraining Step: 151  | total loss: [1m[32m0.69008[0m[0m | time: 9.818s
[2K
| Adam | epoch: 007 | loss: 0.69008 - acc: 0.5101 -- iter: 416/708
[A[ATraining Step: 152  | total loss: [1m[32m0.68947[0m[0m | time: 10.763s
[2K
| Adam | epoch: 007 | loss: 0.68947 - acc: 0.5122 -- iter: 448/708
[A[ATraining Step: 153  | total loss: [1m[32m0.69025[0m[0m | time: 11.742s
[2K
| Adam | epoch: 007 | loss: 0.69025 - acc: 0.5047 -- iter: 480/708
[A[ATraining Step: 154  | total loss: [1m[32m0.68707[0m[0m | time: 12.621s
[2K
| Adam | epoch: 007 | loss: 0.68707 - acc: 0.5167 -- iter: 512/708
[A[ATraining Step: 155  | total loss: [1m[32m0.68617[0m[0m | time: 13.442s
[2K
| Adam | epoch: 007 | loss: 0.68617 - acc: 0.5182 -- iter: 544/708
[A[ATraining Step: 156  | total loss: [1m[32m0.68415[0m[0m | time: 14.371s
[2K
| Adam | epoch: 007 | loss: 0.68415 - acc: 0.5226 -- iter: 576/708
[A[ATraining Step: 157  | total loss: [1m[32m0.68078[0m[0m | time: 15.303s
[2K
| Adam | epoch: 007 | loss: 0.68078 - acc: 0.5297 -- iter: 608/708
[A[ATraining Step: 158  | total loss: [1m[32m0.68031[0m[0m | time: 16.063s
[2K
| Adam | epoch: 007 | loss: 0.68031 - acc: 0.5268 -- iter: 640/708
[A[ATraining Step: 159  | total loss: [1m[32m0.68236[0m[0m | time: 17.014s
[2K
| Adam | epoch: 007 | loss: 0.68236 - acc: 0.5210 -- iter: 672/708
[A[ATraining Step: 160  | total loss: [1m[32m0.68055[0m[0m | time: 17.835s
[2K
| Adam | epoch: 007 | loss: 0.68055 - acc: 0.5220 -- iter: 704/708
[A[ATraining Step: 161  | total loss: [1m[32m0.67741[0m[0m | time: 19.802s
[2K
| Adam | epoch: 007 | loss: 0.67741 - acc: 0.5292 | val_loss: 0.66177 - val_acc: 0.4955 -- iter: 708/708
--
Training Step: 162  | total loss: [1m[32m0.67719[0m[0m | time: 0.872s
[2K
| Adam | epoch: 008 | loss: 0.67719 - acc: 0.5138 -- iter: 032/708
[A[ATraining Step: 163  | total loss: [1m[32m0.67290[0m[0m | time: 1.736s
[2K
| Adam | epoch: 008 | loss: 0.67290 - acc: 0.5249 -- iter: 064/708
[A[ATraining Step: 164  | total loss: [1m[32m0.66991[0m[0m | time: 2.631s
[2K
| Adam | epoch: 008 | loss: 0.66991 - acc: 0.5224 -- iter: 096/708
[A[ATraining Step: 165  | total loss: [1m[32m0.66158[0m[0m | time: 3.529s
[2K
| Adam | epoch: 008 | loss: 0.66158 - acc: 0.5326 -- iter: 128/708
[A[ATraining Step: 166  | total loss: [1m[32m0.66229[0m[0m | time: 4.461s
[2K
| Adam | epoch: 008 | loss: 0.66229 - acc: 0.5200 -- iter: 160/708
[A[ATraining Step: 167  | total loss: [1m[32m0.65535[0m[0m | time: 4.611s
[2K
| Adam | epoch: 008 | loss: 0.65535 - acc: 0.5274 -- iter: 192/708
[A[ATraining Step: 168  | total loss: [1m[32m0.66166[0m[0m | time: 4.732s
[2K
| Adam | epoch: 008 | loss: 0.66166 - acc: 0.5246 -- iter: 224/708
[A[ATraining Step: 169  | total loss: [1m[32m0.66310[0m[0m | time: 5.758s
[2K
| Adam | epoch: 008 | loss: 0.66310 - acc: 0.5222 -- iter: 256/708
[A[ATraining Step: 170  | total loss: [1m[32m0.66538[0m[0m | time: 6.556s
[2K
| Adam | epoch: 008 | loss: 0.66538 - acc: 0.5387 -- iter: 288/708
[A[ATraining Step: 171  | total loss: [1m[32m0.66642[0m[0m | time: 7.405s
[2K
| Adam | epoch: 008 | loss: 0.66642 - acc: 0.5505 -- iter: 320/708
[A[ATraining Step: 172  | total loss: [1m[32m0.66413[0m[0m | time: 8.286s
[2K
| Adam | epoch: 008 | loss: 0.66413 - acc: 0.5673 -- iter: 352/708
[A[ATraining Step: 173  | total loss: [1m[32m0.66447[0m[0m | time: 9.262s
[2K
| Adam | epoch: 008 | loss: 0.66447 - acc: 0.5668 -- iter: 384/708
[A[ATraining Step: 174  | total loss: [1m[32m0.65165[0m[0m | time: 10.118s
[2K
| Adam | epoch: 008 | loss: 0.65165 - acc: 0.5758 -- iter: 416/708
[A[ATraining Step: 175  | total loss: [1m[32m0.66879[0m[0m | time: 10.936s
[2K
| Adam | epoch: 008 | loss: 0.66879 - acc: 0.5744 -- iter: 448/708
[A[ATraining Step: 176  | total loss: [1m[32m0.65139[0m[0m | time: 11.784s
[2K
| Adam | epoch: 008 | loss: 0.65139 - acc: 0.5857 -- iter: 480/708
[A[ATraining Step: 177  | total loss: [1m[32m0.64386[0m[0m | time: 12.679s
[2K
| Adam | epoch: 008 | loss: 0.64386 - acc: 0.6022 -- iter: 512/708
[A[ATraining Step: 178  | total loss: [1m[32m0.64287[0m[0m | time: 13.569s
[2K
| Adam | epoch: 008 | loss: 0.64287 - acc: 0.6107 -- iter: 544/708
[A[ATraining Step: 179  | total loss: [1m[32m0.64401[0m[0m | time: 14.435s
[2K
| Adam | epoch: 008 | loss: 0.64401 - acc: 0.6153 -- iter: 576/708
[A[ATraining Step: 180  | total loss: [1m[32m0.64155[0m[0m | time: 15.274s
[2K
| Adam | epoch: 008 | loss: 0.64155 - acc: 0.6194 -- iter: 608/708
[A[ATraining Step: 181  | total loss: [1m[32m0.63428[0m[0m | time: 16.100s
[2K
| Adam | epoch: 008 | loss: 0.63428 - acc: 0.6355 -- iter: 640/708
[A[ATraining Step: 182  | total loss: [1m[32m0.63473[0m[0m | time: 17.059s
[2K
| Adam | epoch: 008 | loss: 0.63473 - acc: 0.6345 -- iter: 672/708
[A[ATraining Step: 183  | total loss: [1m[32m0.64549[0m[0m | time: 17.789s
[2K
| Adam | epoch: 008 | loss: 0.64549 - acc: 0.6273 -- iter: 704/708
[A[ATraining Step: 184  | total loss: [1m[32m0.64268[0m[0m | time: 20.003s
[2K
| Adam | epoch: 008 | loss: 0.64268 - acc: 0.6364 | val_loss: 0.59991 - val_acc: 0.7297 -- iter: 708/708
--
Training Step: 185  | total loss: [1m[32m0.63870[0m[0m | time: 0.900s
[2K
| Adam | epoch: 009 | loss: 0.63870 - acc: 0.6415 -- iter: 032/708
[A[ATraining Step: 186  | total loss: [1m[32m0.63143[0m[0m | time: 1.715s
[2K
| Adam | epoch: 009 | loss: 0.63143 - acc: 0.6493 -- iter: 064/708
[A[ATraining Step: 187  | total loss: [1m[32m0.61762[0m[0m | time: 2.608s
[2K
| Adam | epoch: 009 | loss: 0.61762 - acc: 0.6656 -- iter: 096/708
[A[ATraining Step: 188  | total loss: [1m[32m0.61172[0m[0m | time: 3.474s
[2K
| Adam | epoch: 009 | loss: 0.61172 - acc: 0.6740 -- iter: 128/708
[A[ATraining Step: 189  | total loss: [1m[32m0.60256[0m[0m | time: 4.290s
[2K
| Adam | epoch: 009 | loss: 0.60256 - acc: 0.6754 -- iter: 160/708
[A[ATraining Step: 190  | total loss: [1m[32m0.59527[0m[0m | time: 5.127s
[2K
| Adam | epoch: 009 | loss: 0.59527 - acc: 0.6735 -- iter: 192/708
[A[ATraining Step: 191  | total loss: [1m[32m0.59829[0m[0m | time: 5.262s
[2K
| Adam | epoch: 009 | loss: 0.59829 - acc: 0.6686 -- iter: 224/708
[A[ATraining Step: 192  | total loss: [1m[32m0.64186[0m[0m | time: 5.466s
[2K
| Adam | epoch: 009 | loss: 0.64186 - acc: 0.6268 -- iter: 256/708
[A[ATraining Step: 193  | total loss: [1m[32m0.65557[0m[0m | time: 6.442s
[2K
| Adam | epoch: 009 | loss: 0.65557 - acc: 0.6141 -- iter: 288/708
[A[ATraining Step: 194  | total loss: [1m[32m0.66861[0m[0m | time: 7.326s
[2K
| Adam | epoch: 009 | loss: 0.66861 - acc: 0.6058 -- iter: 320/708
[A[ATraining Step: 195  | total loss: [1m[32m0.68786[0m[0m | time: 8.042s
[2K
| Adam | epoch: 009 | loss: 0.68786 - acc: 0.5952 -- iter: 352/708
[A[ATraining Step: 196  | total loss: [1m[32m0.71631[0m[0m | time: 8.940s
[2K
| Adam | epoch: 009 | loss: 0.71631 - acc: 0.5732 -- iter: 384/708
[A[ATraining Step: 197  | total loss: [1m[32m0.71911[0m[0m | time: 9.908s
[2K
| Adam | epoch: 009 | loss: 0.71911 - acc: 0.5659 -- iter: 416/708
[A[ATraining Step: 198  | total loss: [1m[32m0.72025[0m[0m | time: 10.819s
[2K
| Adam | epoch: 009 | loss: 0.72025 - acc: 0.5562 -- iter: 448/708
[A[ATraining Step: 199  | total loss: [1m[32m0.71370[0m[0m | time: 11.696s
[2K
| Adam | epoch: 009 | loss: 0.71370 - acc: 0.5630 -- iter: 480/708
[A[ATraining Step: 200  | total loss: [1m[32m0.70958[0m[0m | time: 13.783s
[2K
| Adam | epoch: 009 | loss: 0.70958 - acc: 0.5661 | val_loss: 0.66985 - val_acc: 0.6802 -- iter: 512/708
--
Training Step: 201  | total loss: [1m[32m0.70570[0m[0m | time: 14.660s
[2K
| Adam | epoch: 009 | loss: 0.70570 - acc: 0.5689 -- iter: 544/708
[A[ATraining Step: 202  | total loss: [1m[32m0.70226[0m[0m | time: 15.562s
[2K
| Adam | epoch: 009 | loss: 0.70226 - acc: 0.5807 -- iter: 576/708
[A[ATraining Step: 203  | total loss: [1m[32m0.69706[0m[0m | time: 16.466s
[2K
| Adam | epoch: 009 | loss: 0.69706 - acc: 0.6133 -- iter: 608/708
[A[ATraining Step: 204  | total loss: [1m[32m0.69337[0m[0m | time: 17.349s
[2K
| Adam | epoch: 009 | loss: 0.69337 - acc: 0.6332 -- iter: 640/708
[A[ATraining Step: 205  | total loss: [1m[32m0.68971[0m[0m | time: 18.306s
[2K
| Adam | epoch: 009 | loss: 0.68971 - acc: 0.6386 -- iter: 672/708
[A[ATraining Step: 206  | total loss: [1m[32m0.68602[0m[0m | time: 19.144s
[2K
| Adam | epoch: 009 | loss: 0.68602 - acc: 0.6467 -- iter: 704/708
[A[ATraining Step: 207  | total loss: [1m[32m0.68111[0m[0m | time: 21.182s
[2K
| Adam | epoch: 009 | loss: 0.68111 - acc: 0.6507 | val_loss: 0.64684 - val_acc: 0.5946 -- iter: 708/708
--
Training Step: 208  | total loss: [1m[32m0.67838[0m[0m | time: 0.940s
[2K
| Adam | epoch: 010 | loss: 0.67838 - acc: 0.6482 -- iter: 032/708
[A[ATraining Step: 209  | total loss: [1m[32m0.67223[0m[0m | time: 1.779s
[2K
| Adam | epoch: 010 | loss: 0.67223 - acc: 0.6552 -- iter: 064/708
[A[ATraining Step: 210  | total loss: [1m[32m0.67119[0m[0m | time: 2.669s
[2K
| Adam | epoch: 010 | loss: 0.67119 - acc: 0.6460 -- iter: 096/708
[A[ATraining Step: 211  | total loss: [1m[32m0.66584[0m[0m | time: 3.529s
[2K
| Adam | epoch: 010 | loss: 0.66584 - acc: 0.6532 -- iter: 128/708
[A[ATraining Step: 212  | total loss: [1m[32m0.66130[0m[0m | time: 4.436s
[2K
| Adam | epoch: 010 | loss: 0.66130 - acc: 0.6629 -- iter: 160/708
[A[ATraining Step: 213  | total loss: [1m[32m0.65633[0m[0m | time: 5.287s
[2K
| Adam | epoch: 010 | loss: 0.65633 - acc: 0.6685 -- iter: 192/708
[A[ATraining Step: 214  | total loss: [1m[32m0.64737[0m[0m | time: 6.156s
[2K
| Adam | epoch: 010 | loss: 0.64737 - acc: 0.6798 -- iter: 224/708
[A[ATraining Step: 215  | total loss: [1m[32m0.64041[0m[0m | time: 6.296s
[2K
| Adam | epoch: 010 | loss: 0.64041 - acc: 0.6930 -- iter: 256/708
[A[ATraining Step: 216  | total loss: [1m[32m0.64322[0m[0m | time: 6.421s
[2K
| Adam | epoch: 010 | loss: 0.64322 - acc: 0.6987 -- iter: 288/708
[A[ATraining Step: 217  | total loss: [1m[32m0.63217[0m[0m | time: 7.311s
[2K
| Adam | epoch: 010 | loss: 0.63217 - acc: 0.7289 -- iter: 320/708
[A[ATraining Step: 218  | total loss: [1m[32m0.62391[0m[0m | time: 8.180s
[2K
| Adam | epoch: 010 | loss: 0.62391 - acc: 0.7372 -- iter: 352/708
[A[ATraining Step: 219  | total loss: [1m[32m0.63429[0m[0m | time: 9.157s
[2K
| Adam | epoch: 010 | loss: 0.63429 - acc: 0.7166 -- iter: 384/708
[A[ATraining Step: 220  | total loss: [1m[32m0.64051[0m[0m | time: 10.024s
[2K
| Adam | epoch: 010 | loss: 0.64051 - acc: 0.7012 -- iter: 416/708
[A[ATraining Step: 221  | total loss: [1m[32m0.62678[0m[0m | time: 10.920s
[2K
| Adam | epoch: 010 | loss: 0.62678 - acc: 0.7155 -- iter: 448/708
[A[ATraining Step: 222  | total loss: [1m[32m0.61346[0m[0m | time: 11.757s
[2K
| Adam | epoch: 010 | loss: 0.61346 - acc: 0.7189 -- iter: 480/708
[A[ATraining Step: 223  | total loss: [1m[32m0.62131[0m[0m | time: 12.731s
[2K
| Adam | epoch: 010 | loss: 0.62131 - acc: 0.7095 -- iter: 512/708
[A[ATraining Step: 224  | total loss: [1m[32m0.62004[0m[0m | time: 13.662s
[2K
| Adam | epoch: 010 | loss: 0.62004 - acc: 0.7073 -- iter: 544/708
[A[ATraining Step: 225  | total loss: [1m[32m0.60907[0m[0m | time: 14.631s
[2K
| Adam | epoch: 010 | loss: 0.60907 - acc: 0.7116 -- iter: 576/708
[A[ATraining Step: 226  | total loss: [1m[32m0.60495[0m[0m | time: 15.560s
[2K
| Adam | epoch: 010 | loss: 0.60495 - acc: 0.7092 -- iter: 608/708
[A[ATraining Step: 227  | total loss: [1m[32m0.60019[0m[0m | time: 16.425s
[2K
| Adam | epoch: 010 | loss: 0.60019 - acc: 0.7133 -- iter: 640/708
[A[ATraining Step: 228  | total loss: [1m[32m0.58709[0m[0m | time: 17.297s
[2K
| Adam | epoch: 010 | loss: 0.58709 - acc: 0.7263 -- iter: 672/708
[A[ATraining Step: 229  | total loss: [1m[32m0.59397[0m[0m | time: 18.151s
[2K
| Adam | epoch: 010 | loss: 0.59397 - acc: 0.7131 -- iter: 704/708
[A[ATraining Step: 230  | total loss: [1m[32m0.58745[0m[0m | time: 20.297s
[2K
| Adam | epoch: 010 | loss: 0.58745 - acc: 0.7261 | val_loss: 0.53019 - val_acc: 0.7658 -- iter: 708/708
--
Training Step: 231  | total loss: [1m[32m0.57604[0m[0m | time: 0.919s
[2K
| Adam | epoch: 011 | loss: 0.57604 - acc: 0.7316 -- iter: 032/708
[A[ATraining Step: 232  | total loss: [1m[32m0.56761[0m[0m | time: 1.925s
[2K
| Adam | epoch: 011 | loss: 0.56761 - acc: 0.7304 -- iter: 064/708
[A[ATraining Step: 233  | total loss: [1m[32m0.56778[0m[0m | time: 2.799s
[2K
| Adam | epoch: 011 | loss: 0.56778 - acc: 0.7229 -- iter: 096/708
[A[ATraining Step: 234  | total loss: [1m[32m0.55218[0m[0m | time: 3.638s
[2K
| Adam | epoch: 011 | loss: 0.55218 - acc: 0.7319 -- iter: 128/708
[A[ATraining Step: 235  | total loss: [1m[32m0.55178[0m[0m | time: 4.561s
[2K
| Adam | epoch: 011 | loss: 0.55178 - acc: 0.7400 -- iter: 160/708
[A[ATraining Step: 236  | total loss: [1m[32m0.54035[0m[0m | time: 5.417s
[2K
| Adam | epoch: 011 | loss: 0.54035 - acc: 0.7472 -- iter: 192/708
[A[ATraining Step: 237  | total loss: [1m[32m0.53715[0m[0m | time: 6.291s
[2K
| Adam | epoch: 011 | loss: 0.53715 - acc: 0.7506 -- iter: 224/708
[A[ATraining Step: 238  | total loss: [1m[32m0.53990[0m[0m | time: 7.232s
[2K
| Adam | epoch: 011 | loss: 0.53990 - acc: 0.7443 -- iter: 256/708
[A[ATraining Step: 239  | total loss: [1m[32m0.53584[0m[0m | time: 7.346s
[2K
| Adam | epoch: 011 | loss: 0.53584 - acc: 0.7417 -- iter: 288/708
[A[ATraining Step: 240  | total loss: [1m[32m0.53597[0m[0m | time: 7.451s
[2K
| Adam | epoch: 011 | loss: 0.53597 - acc: 0.7426 -- iter: 320/708
[A[ATraining Step: 241  | total loss: [1m[32m0.51464[0m[0m | time: 8.330s
[2K
| Adam | epoch: 011 | loss: 0.51464 - acc: 0.7433 -- iter: 352/708
[A[ATraining Step: 242  | total loss: [1m[32m0.53671[0m[0m | time: 9.288s
[2K
| Adam | epoch: 011 | loss: 0.53671 - acc: 0.7284 -- iter: 384/708
[A[ATraining Step: 243  | total loss: [1m[32m0.59880[0m[0m | time: 10.211s
[2K
| Adam | epoch: 011 | loss: 0.59880 - acc: 0.6930 -- iter: 416/708
[A[ATraining Step: 244  | total loss: [1m[32m0.61612[0m[0m | time: 11.028s
[2K
| Adam | epoch: 011 | loss: 0.61612 - acc: 0.6831 -- iter: 448/708
[A[ATraining Step: 245  | total loss: [1m[32m0.60753[0m[0m | time: 11.847s
[2K
| Adam | epoch: 011 | loss: 0.60753 - acc: 0.6960 -- iter: 480/708
[A[ATraining Step: 246  | total loss: [1m[32m0.58576[0m[0m | time: 12.632s
[2K
| Adam | epoch: 011 | loss: 0.58576 - acc: 0.7108 -- iter: 512/708
[A[ATraining Step: 247  | total loss: [1m[32m0.59974[0m[0m | time: 13.526s
[2K
| Adam | epoch: 011 | loss: 0.59974 - acc: 0.7022 -- iter: 544/708
[A[ATraining Step: 248  | total loss: [1m[32m0.60781[0m[0m | time: 14.325s
[2K
| Adam | epoch: 011 | loss: 0.60781 - acc: 0.6945 -- iter: 576/708
[A[ATraining Step: 249  | total loss: [1m[32m0.60547[0m[0m | time: 15.194s
[2K
| Adam | epoch: 011 | loss: 0.60547 - acc: 0.6938 -- iter: 608/708
[A[ATraining Step: 250  | total loss: [1m[32m0.60822[0m[0m | time: 16.123s
[2K
| Adam | epoch: 011 | loss: 0.60822 - acc: 0.6963 -- iter: 640/708
[A[ATraining Step: 251  | total loss: [1m[32m0.59974[0m[0m | time: 16.978s
[2K
| Adam | epoch: 011 | loss: 0.59974 - acc: 0.7048 -- iter: 672/708
[A[ATraining Step: 252  | total loss: [1m[32m0.59377[0m[0m | time: 17.867s
[2K
| Adam | epoch: 011 | loss: 0.59377 - acc: 0.7031 -- iter: 704/708
[A[ATraining Step: 253  | total loss: [1m[32m0.58996[0m[0m | time: 19.896s
[2K
| Adam | epoch: 011 | loss: 0.58996 - acc: 0.7078 | val_loss: 0.68713 - val_acc: 0.5631 -- iter: 708/708
--
Training Step: 254  | total loss: [1m[32m0.59735[0m[0m | time: 0.887s
[2K
| Adam | epoch: 012 | loss: 0.59735 - acc: 0.6995 -- iter: 032/708
[A[ATraining Step: 255  | total loss: [1m[32m0.59659[0m[0m | time: 1.726s
[2K
| Adam | epoch: 012 | loss: 0.59659 - acc: 0.6920 -- iter: 064/708
[A[ATraining Step: 256  | total loss: [1m[32m0.59416[0m[0m | time: 2.580s
[2K
| Adam | epoch: 012 | loss: 0.59416 - acc: 0.7010 -- iter: 096/708
[A[ATraining Step: 257  | total loss: [1m[32m0.59180[0m[0m | time: 3.443s
[2K
| Adam | epoch: 012 | loss: 0.59180 - acc: 0.7027 -- iter: 128/708
[A[ATraining Step: 258  | total loss: [1m[32m0.59376[0m[0m | time: 4.355s
[2K
| Adam | epoch: 012 | loss: 0.59376 - acc: 0.6918 -- iter: 160/708
[A[ATraining Step: 259  | total loss: [1m[32m0.58832[0m[0m | time: 5.226s
[2K
| Adam | epoch: 012 | loss: 0.58832 - acc: 0.7008 -- iter: 192/708
[A[ATraining Step: 260  | total loss: [1m[32m0.59347[0m[0m | time: 6.033s
[2K
| Adam | epoch: 012 | loss: 0.59347 - acc: 0.6932 -- iter: 224/708
[A[ATraining Step: 261  | total loss: [1m[32m0.58945[0m[0m | time: 6.885s
[2K
| Adam | epoch: 012 | loss: 0.58945 - acc: 0.6895 -- iter: 256/708
[A[ATraining Step: 262  | total loss: [1m[32m0.59761[0m[0m | time: 7.756s
[2K
| Adam | epoch: 012 | loss: 0.59761 - acc: 0.6799 -- iter: 288/708
[A[ATraining Step: 263  | total loss: [1m[32m0.59545[0m[0m | time: 7.929s
[2K
| Adam | epoch: 012 | loss: 0.59545 - acc: 0.6838 -- iter: 320/708
[A[ATraining Step: 264  | total loss: [1m[32m0.59486[0m[0m | time: 8.096s
[2K
| Adam | epoch: 012 | loss: 0.59486 - acc: 0.6654 -- iter: 352/708
[A[ATraining Step: 265  | total loss: [1m[32m0.58342[0m[0m | time: 8.972s
[2K
| Adam | epoch: 012 | loss: 0.58342 - acc: 0.6989 -- iter: 384/708
[A[ATraining Step: 266  | total loss: [1m[32m0.57152[0m[0m | time: 9.934s
[2K
| Adam | epoch: 012 | loss: 0.57152 - acc: 0.7134 -- iter: 416/708
[A[ATraining Step: 267  | total loss: [1m[32m0.57172[0m[0m | time: 10.830s
[2K
| Adam | epoch: 012 | loss: 0.57172 - acc: 0.7139 -- iter: 448/708
[A[ATraining Step: 268  | total loss: [1m[32m0.56609[0m[0m | time: 11.666s
[2K
| Adam | epoch: 012 | loss: 0.56609 - acc: 0.7175 -- iter: 480/708
[A[ATraining Step: 269  | total loss: [1m[32m0.57369[0m[0m | time: 12.537s
[2K
| Adam | epoch: 012 | loss: 0.57369 - acc: 0.7114 -- iter: 512/708
[A[ATraining Step: 270  | total loss: [1m[32m0.58615[0m[0m | time: 13.373s
[2K
| Adam | epoch: 012 | loss: 0.58615 - acc: 0.6996 -- iter: 544/708
[A[ATraining Step: 271  | total loss: [1m[32m0.57823[0m[0m | time: 14.262s
[2K
| Adam | epoch: 012 | loss: 0.57823 - acc: 0.7172 -- iter: 576/708
[A[ATraining Step: 272  | total loss: [1m[32m0.56838[0m[0m | time: 15.128s
[2K
| Adam | epoch: 012 | loss: 0.56838 - acc: 0.7329 -- iter: 608/708
[A[ATraining Step: 273  | total loss: [1m[32m0.56160[0m[0m | time: 16.009s
[2K
| Adam | epoch: 012 | loss: 0.56160 - acc: 0.7315 -- iter: 640/708
[A[ATraining Step: 274  | total loss: [1m[32m0.56367[0m[0m | time: 16.855s
[2K
| Adam | epoch: 012 | loss: 0.56367 - acc: 0.7303 -- iter: 672/708
[A[ATraining Step: 275  | total loss: [1m[32m0.56186[0m[0m | time: 17.658s
[2K
| Adam | epoch: 012 | loss: 0.56186 - acc: 0.7291 -- iter: 704/708
[A[ATraining Step: 276  | total loss: [1m[32m0.55702[0m[0m | time: 19.679s
[2K
| Adam | epoch: 012 | loss: 0.55702 - acc: 0.7343 | val_loss: 0.55360 - val_acc: 0.7342 -- iter: 708/708
--
Training Step: 277  | total loss: [1m[32m0.54941[0m[0m | time: 0.912s
[2K
| Adam | epoch: 013 | loss: 0.54941 - acc: 0.7421 -- iter: 032/708
[A[ATraining Step: 278  | total loss: [1m[32m0.53889[0m[0m | time: 1.855s
[2K
| Adam | epoch: 013 | loss: 0.53889 - acc: 0.7460 -- iter: 064/708
[A[ATraining Step: 279  | total loss: [1m[32m0.52828[0m[0m | time: 2.726s
[2K
| Adam | epoch: 013 | loss: 0.52828 - acc: 0.7496 -- iter: 096/708
[A[ATraining Step: 280  | total loss: [1m[32m0.53354[0m[0m | time: 3.679s
[2K
| Adam | epoch: 013 | loss: 0.53354 - acc: 0.7496 -- iter: 128/708
[A[ATraining Step: 281  | total loss: [1m[32m0.53850[0m[0m | time: 4.578s
[2K
| Adam | epoch: 013 | loss: 0.53850 - acc: 0.7434 -- iter: 160/708
[A[ATraining Step: 282  | total loss: [1m[32m0.52247[0m[0m | time: 5.434s
[2K
| Adam | epoch: 013 | loss: 0.52247 - acc: 0.7566 -- iter: 192/708
[A[ATraining Step: 283  | total loss: [1m[32m0.50389[0m[0m | time: 6.316s
[2K
| Adam | epoch: 013 | loss: 0.50389 - acc: 0.7684 -- iter: 224/708
[A[ATraining Step: 284  | total loss: [1m[32m0.52180[0m[0m | time: 7.154s
[2K
| Adam | epoch: 013 | loss: 0.52180 - acc: 0.7509 -- iter: 256/708
[A[ATraining Step: 285  | total loss: [1m[32m0.52523[0m[0m | time: 8.028s
[2K
| Adam | epoch: 013 | loss: 0.52523 - acc: 0.7446 -- iter: 288/708
[A[ATraining Step: 286  | total loss: [1m[32m0.51804[0m[0m | time: 8.859s
[2K
| Adam | epoch: 013 | loss: 0.51804 - acc: 0.7483 -- iter: 320/708
[A[ATraining Step: 287  | total loss: [1m[32m0.51008[0m[0m | time: 8.984s
[2K
| Adam | epoch: 013 | loss: 0.51008 - acc: 0.7547 -- iter: 352/708
[A[ATraining Step: 288  | total loss: [1m[32m0.56233[0m[0m | time: 9.213s
[2K
| Adam | epoch: 013 | loss: 0.56233 - acc: 0.7042 -- iter: 384/708
[A[ATraining Step: 289  | total loss: [1m[32m0.56748[0m[0m | time: 10.096s
[2K
| Adam | epoch: 013 | loss: 0.56748 - acc: 0.6838 -- iter: 416/708
[A[ATraining Step: 290  | total loss: [1m[32m0.61636[0m[0m | time: 10.893s
[2K
| Adam | epoch: 013 | loss: 0.61636 - acc: 0.6623 -- iter: 448/708
[A[ATraining Step: 291  | total loss: [1m[32m0.61432[0m[0m | time: 11.741s
[2K
| Adam | epoch: 013 | loss: 0.61432 - acc: 0.6648 -- iter: 480/708
[A[ATraining Step: 292  | total loss: [1m[32m0.65692[0m[0m | time: 12.683s
[2K
| Adam | epoch: 013 | loss: 0.65692 - acc: 0.6421 -- iter: 512/708
[A[ATraining Step: 293  | total loss: [1m[32m0.67609[0m[0m | time: 13.530s
[2K
| Adam | epoch: 013 | loss: 0.67609 - acc: 0.6247 -- iter: 544/708
[A[ATraining Step: 294  | total loss: [1m[32m0.66136[0m[0m | time: 14.416s
[2K
| Adam | epoch: 013 | loss: 0.66136 - acc: 0.6373 -- iter: 576/708
[A[ATraining Step: 295  | total loss: [1m[32m0.64490[0m[0m | time: 15.415s
[2K
| Adam | epoch: 013 | loss: 0.64490 - acc: 0.6485 -- iter: 608/708
[A[ATraining Step: 296  | total loss: [1m[32m0.62433[0m[0m | time: 16.362s
[2K
| Adam | epoch: 013 | loss: 0.62433 - acc: 0.6712 -- iter: 640/708
[A[ATraining Step: 297  | total loss: [1m[32m0.61894[0m[0m | time: 17.159s
[2K
| Adam | epoch: 013 | loss: 0.61894 - acc: 0.6791 -- iter: 672/708
[A[ATraining Step: 298  | total loss: [1m[32m0.61489[0m[0m | time: 18.054s
[2K
| Adam | epoch: 013 | loss: 0.61489 - acc: 0.6799 -- iter: 704/708
[A[ATraining Step: 299  | total loss: [1m[32m0.60557[0m[0m | time: 19.976s
[2K
| Adam | epoch: 013 | loss: 0.60557 - acc: 0.6900 | val_loss: 0.55796 - val_acc: 0.7523 -- iter: 708/708
--
Training Step: 300  | total loss: [1m[32m0.59980[0m[0m | time: 0.876s
[2K
| Adam | epoch: 014 | loss: 0.59980 - acc: 0.6992 -- iter: 032/708
[A[ATraining Step: 301  | total loss: [1m[32m0.58812[0m[0m | time: 1.728s
[2K
| Adam | epoch: 014 | loss: 0.58812 - acc: 0.7136 -- iter: 064/708
[A[ATraining Step: 302  | total loss: [1m[32m0.58677[0m[0m | time: 2.728s
[2K
| Adam | epoch: 014 | loss: 0.58677 - acc: 0.7110 -- iter: 096/708
[A[ATraining Step: 303  | total loss: [1m[32m0.58967[0m[0m | time: 3.585s
[2K
| Adam | epoch: 014 | loss: 0.58967 - acc: 0.7087 -- iter: 128/708
[A[ATraining Step: 304  | total loss: [1m[32m0.57928[0m[0m | time: 4.395s
[2K
| Adam | epoch: 014 | loss: 0.57928 - acc: 0.7190 -- iter: 160/708
[A[ATraining Step: 305  | total loss: [1m[32m0.56958[0m[0m | time: 5.264s
[2K
| Adam | epoch: 014 | loss: 0.56958 - acc: 0.7315 -- iter: 192/708
[A[ATraining Step: 306  | total loss: [1m[32m0.55984[0m[0m | time: 6.148s
[2K
| Adam | epoch: 014 | loss: 0.55984 - acc: 0.7427 -- iter: 224/708
[A[ATraining Step: 307  | total loss: [1m[32m0.55244[0m[0m | time: 6.985s
[2K
| Adam | epoch: 014 | loss: 0.55244 - acc: 0.7466 -- iter: 256/708
[A[ATraining Step: 308  | total loss: [1m[32m0.54189[0m[0m | time: 7.860s
[2K
| Adam | epoch: 014 | loss: 0.54189 - acc: 0.7563 -- iter: 288/708
[A[ATraining Step: 309  | total loss: [1m[32m0.52836[0m[0m | time: 8.697s
[2K
| Adam | epoch: 014 | loss: 0.52836 - acc: 0.7682 -- iter: 320/708
[A[ATraining Step: 310  | total loss: [1m[32m0.52717[0m[0m | time: 9.546s
[2K
| Adam | epoch: 014 | loss: 0.52717 - acc: 0.7695 -- iter: 352/708
[A[ATraining Step: 311  | total loss: [1m[32m0.51947[0m[0m | time: 9.666s
[2K
| Adam | epoch: 014 | loss: 0.51947 - acc: 0.7769 -- iter: 384/708
[A[ATraining Step: 312  | total loss: [1m[32m0.51396[0m[0m | time: 9.770s
[2K
| Adam | epoch: 014 | loss: 0.51396 - acc: 0.7742 -- iter: 416/708
[A[ATraining Step: 313  | total loss: [1m[32m0.50550[0m[0m | time: 10.617s
[2K
| Adam | epoch: 014 | loss: 0.50550 - acc: 0.7718 -- iter: 448/708
[A[ATraining Step: 314  | total loss: [1m[32m0.49852[0m[0m | time: 11.520s
[2K
| Adam | epoch: 014 | loss: 0.49852 - acc: 0.7759 -- iter: 480/708
[A[ATraining Step: 315  | total loss: [1m[32m0.50540[0m[0m | time: 12.450s
[2K
| Adam | epoch: 014 | loss: 0.50540 - acc: 0.7733 -- iter: 512/708
[A[ATraining Step: 316  | total loss: [1m[32m0.50521[0m[0m | time: 13.394s
[2K
| Adam | epoch: 014 | loss: 0.50521 - acc: 0.7772 -- iter: 544/708
[A[ATraining Step: 317  | total loss: [1m[32m0.50769[0m[0m | time: 14.254s
[2K
| Adam | epoch: 014 | loss: 0.50769 - acc: 0.7745 -- iter: 576/708
[A[ATraining Step: 318  | total loss: [1m[32m0.49301[0m[0m | time: 15.112s
[2K
| Adam | epoch: 014 | loss: 0.49301 - acc: 0.7814 -- iter: 608/708
[A[ATraining Step: 319  | total loss: [1m[32m0.48517[0m[0m | time: 16.252s
[2K
| Adam | epoch: 014 | loss: 0.48517 - acc: 0.7876 -- iter: 640/708
[A[ATraining Step: 320  | total loss: [1m[32m0.48896[0m[0m | time: 18.203s
[2K
| Adam | epoch: 014 | loss: 0.48896 - acc: 0.7808 -- iter: 672/708
[A[ATraining Step: 321  | total loss: [1m[32m0.47557[0m[0m | time: 19.166s
[2K
| Adam | epoch: 014 | loss: 0.47557 - acc: 0.7808 -- iter: 704/708
[A[ATraining Step: 322  | total loss: [1m[32m0.46721[0m[0m | time: 21.471s
[2K
| Adam | epoch: 014 | loss: 0.46721 - acc: 0.7871 | val_loss: 0.52318 - val_acc: 0.7658 -- iter: 708/708
--
Training Step: 323  | total loss: [1m[32m0.45843[0m[0m | time: 0.864s
[2K
| Adam | epoch: 015 | loss: 0.45843 - acc: 0.7928 -- iter: 032/708
[A[ATraining Step: 324  | total loss: [1m[32m0.45053[0m[0m | time: 3.762s
[2K
| Adam | epoch: 015 | loss: 0.45053 - acc: 0.8010 -- iter: 064/708
[A[ATraining Step: 325  | total loss: [1m[32m0.43617[0m[0m | time: 4.775s
[2K
| Adam | epoch: 015 | loss: 0.43617 - acc: 0.8053 -- iter: 096/708
[A[ATraining Step: 326  | total loss: [1m[32m0.44867[0m[0m | time: 5.630s
[2K
| Adam | epoch: 015 | loss: 0.44867 - acc: 0.7997 -- iter: 128/708
[A[ATraining Step: 327  | total loss: [1m[32m0.44007[0m[0m | time: 6.530s
[2K
| Adam | epoch: 015 | loss: 0.44007 - acc: 0.8073 -- iter: 160/708
[A[ATraining Step: 328  | total loss: [1m[32m0.43001[0m[0m | time: 7.355s
[2K
| Adam | epoch: 015 | loss: 0.43001 - acc: 0.8078 -- iter: 192/708
[A[ATraining Step: 329  | total loss: [1m[32m0.41149[0m[0m | time: 8.193s
[2K
| Adam | epoch: 015 | loss: 0.41149 - acc: 0.8145 -- iter: 224/708
[A[ATraining Step: 330  | total loss: [1m[32m0.42880[0m[0m | time: 9.043s
[2K
| Adam | epoch: 015 | loss: 0.42880 - acc: 0.8081 -- iter: 256/708
[A[ATraining Step: 331  | total loss: [1m[32m0.42423[0m[0m | time: 9.882s
[2K
| Adam | epoch: 015 | loss: 0.42423 - acc: 0.8085 -- iter: 288/708
[A[ATraining Step: 332  | total loss: [1m[32m0.43462[0m[0m | time: 10.768s
[2K
| Adam | epoch: 015 | loss: 0.43462 - acc: 0.8089 -- iter: 320/708
[A[ATraining Step: 333  | total loss: [1m[32m0.44321[0m[0m | time: 11.609s
[2K
| Adam | epoch: 015 | loss: 0.44321 - acc: 0.8093 -- iter: 352/708
[A[ATraining Step: 334  | total loss: [1m[32m0.44938[0m[0m | time: 12.451s
[2K
| Adam | epoch: 015 | loss: 0.44938 - acc: 0.8096 -- iter: 384/708
[A[ATraining Step: 335  | total loss: [1m[32m0.44434[0m[0m | time: 12.581s
[2K
| Adam | epoch: 015 | loss: 0.44434 - acc: 0.8068 -- iter: 416/708
[A[ATraining Step: 336  | total loss: [1m[32m0.42149[0m[0m | time: 12.707s
[2K
| Adam | epoch: 015 | loss: 0.42149 - acc: 0.8261 -- iter: 448/708
[A[ATraining Step: 337  | total loss: [1m[32m0.39906[0m[0m | time: 13.620s
[2K
| Adam | epoch: 015 | loss: 0.39906 - acc: 0.8435 -- iter: 480/708
[A[ATraining Step: 338  | total loss: [1m[32m0.41282[0m[0m | time: 14.508s
[2K
| Adam | epoch: 015 | loss: 0.41282 - acc: 0.8372 -- iter: 512/708
[A[ATraining Step: 339  | total loss: [1m[32m0.41482[0m[0m | time: 15.439s
[2K
| Adam | epoch: 015 | loss: 0.41482 - acc: 0.8379 -- iter: 544/708
[A[ATraining Step: 340  | total loss: [1m[32m0.40164[0m[0m | time: 16.251s
[2K
| Adam | epoch: 015 | loss: 0.40164 - acc: 0.8447 -- iter: 576/708
[A[ATraining Step: 341  | total loss: [1m[32m0.39918[0m[0m | time: 17.198s
[2K
| Adam | epoch: 015 | loss: 0.39918 - acc: 0.8446 -- iter: 608/708
[A[ATraining Step: 342  | total loss: [1m[32m0.39600[0m[0m | time: 17.884s
[2K
| Adam | epoch: 015 | loss: 0.39600 - acc: 0.8414 -- iter: 640/708
[A[ATraining Step: 343  | total loss: [1m[32m0.40668[0m[0m | time: 18.799s
[2K
| Adam | epoch: 015 | loss: 0.40668 - acc: 0.8292 -- iter: 672/708
[A[ATraining Step: 344  | total loss: [1m[32m0.40963[0m[0m | time: 19.619s
[2K
| Adam | epoch: 015 | loss: 0.40963 - acc: 0.8244 -- iter: 704/708
[A[ATraining Step: 345  | total loss: [1m[32m0.40840[0m[0m | time: 21.582s
[2K
| Adam | epoch: 015 | loss: 0.40840 - acc: 0.8263 | val_loss: 0.51430 - val_acc: 0.7568 -- iter: 708/708
--
2018-08-01 16:01:34.285451: W tensorflow/core/framework/allocator.cc:101] Allocation of 2010602496 exceeds 10% of system memory.
2018-08-01 16:01:35.193322: W tensorflow/core/framework/allocator.cc:101] Allocation of 2010602496 exceeds 10% of system memory.
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8705357142857143
Validation AUPRC:0.8493908074153411
Test AUC:0.9340918325883787
Test AUPRC:0.9356555961673161
BestTestF1Score	0.85	0.69	0.85	0.82	0.87	93	20	95	14	0.7
BestTestMCCScore	0.85	0.69	0.85	0.82	0.87	93	20	95	14	0.7
BestTestAccuracyScore	0.84	0.69	0.84	0.82	0.86	92	20	95	15	0.72
BestValidationF1Score	0.82	0.62	0.81	0.78	0.85	94	26	86	16	0.7
BestValidationMCC	0.82	0.62	0.81	0.78	0.85	94	26	86	16	0.7
BestValidationAccuracy	0.82	0.62	0.81	0.79	0.85	93	25	87	17	0.72
TestPredictions (Threshold:0.7)
CHEMBL1922985,FN,ACT,0.5	CHEMBL501256,TN,INACT,0.09000000357627869	CHEMBL3745929,TN,INACT,0.6299999952316284	CHEMBL3237943,FP,INACT,0.7900000214576721	CHEMBL1644813,TP,ACT,0.9700000286102295	CHEMBL2337362,TN,INACT,0.4699999988079071	CHEMBL3218858,TP,ACT,0.8999999761581421	CHEMBL1939484,TP,ACT,0.8299999833106995	CHEMBL494743,TP,ACT,0.9300000071525574	CHEMBL589259,TN,INACT,0.6000000238418579	CHEMBL232148,TN,INACT,0.2800000011920929	CHEMBL3822982,FN,ACT,0.4399999976158142	CHEMBL591252,TN,INACT,0.25	CHEMBL1630115,TP,ACT,0.9599999785423279	CHEMBL1642139,TP,ACT,0.9300000071525574	CHEMBL1809044,TP,ACT,0.7799999713897705	CHEMBL114073,FP,INACT,0.8100000023841858	CHEMBL3823045,FN,ACT,0.6800000071525574	CHEMBL1087054,FP,INACT,0.8100000023841858	CHEMBL489344,TN,INACT,0.3199999928474426	CHEMBL1910758,TN,INACT,0.5600000023841858	CHEMBL1644805,TP,ACT,0.9900000095367432	CHEMBL110065,TN,INACT,0.12999999523162842	CHEMBL523780,FP,INACT,0.8799999952316284	CHEMBL1683951,TN,INACT,0.10999999940395355	CHEMBL1077107,TN,INACT,0.4399999976158142	CHEMBL2426288,TN,INACT,0.4300000071525574	CHEMBL3133911,FP,INACT,0.8899999856948853	CHEMBL3218851,TP,ACT,0.8999999761581421	CHEMBL1934353,TP,ACT,0.9900000095367432	CHEMBL493319,TP,ACT,0.949999988079071	CHEMBL1910278,TN,INACT,0.23000000417232513	CHEMBL1910754,FP,INACT,0.8500000238418579	CHEMBL1095776,FP,INACT,0.800000011920929	CHEMBL489627,TN,INACT,0.10000000149011612	CHEMBL1076471,TP,ACT,0.949999988079071	CHEMBL131098,TN,INACT,0.11999999731779099	CHEMBL1644802,TP,ACT,0.9900000095367432	CHEMBL53898,TN,INACT,0.11999999731779099	CHEMBL552136,TN,INACT,0.4300000071525574	CHEMBL485202,TP,ACT,0.9200000166893005	CHEMBL1945460,TP,ACT,0.9800000190734863	CHEMBL3628818,TN,INACT,0.6499999761581421	CHEMBL1939485,TP,ACT,0.9599999785423279	CHEMBL102136,TN,INACT,0.11999999731779099	CHEMBL483602,TP,ACT,0.8999999761581421	CHEMBL489430,TN,INACT,0.36000001430511475	CHEMBL1922986,TP,ACT,0.8299999833106995	CHEMBL3691660,FP,INACT,0.8999999761581421	CHEMBL2163623,FP,INACT,0.8299999833106995	CHEMBL1830265,FP,INACT,0.8299999833106995	CHEMBL514941,TP,ACT,0.9399999976158142	CHEMBL519116,TP,ACT,0.8899999856948853	CHEMBL324439,TN,INACT,0.25	CHEMBL269528,TN,INACT,0.30000001192092896	CHEMBL1796258,TP,ACT,0.8999999761581421	CHEMBL277667,TN,INACT,0.36000001430511475	CHEMBL592240,TN,INACT,0.09000000357627869	CHEMBL245966,TN,INACT,0.28999999165534973	CHEMBL493537,TP,ACT,0.949999988079071	CHEMBL246167,TN,INACT,0.33000001311302185	CHEMBL3823836,TP,ACT,0.9599999785423279	CHEMBL1944960,FN,ACT,0.5799999833106995	CHEMBL1939488,TP,ACT,0.9800000190734863	CHEMBL1939487,TP,ACT,0.9900000095367432	CHEMBL317398,TN,INACT,0.5099999904632568	CHEMBL1944957,TP,ACT,0.7200000286102295	CHEMBL1822521,TP,ACT,0.9900000095367432	CHEMBL1088028,TP,ACT,0.9900000095367432	CHEMBL456797,TN,INACT,0.15000000596046448	CHEMBL456759,TN,INACT,0.14000000059604645	CHEMBL2403833,TP,ACT,0.8999999761581421	CHEMBL1939489,TP,ACT,0.9800000190734863	CHEMBL2158529,TP,ACT,0.8999999761581421	CHEMBL2042827,TP,ACT,0.8100000023841858	CHEMBL445420,TN,INACT,0.11999999731779099	CHEMBL1630108,TP,ACT,0.9800000190734863	CHEMBL2312645,TN,INACT,0.5799999833106995	CHEMBL401930,TP,ACT,0.949999988079071	CHEMBL3787112,FN,ACT,0.5400000214576721	CHEMBL78249,TN,INACT,0.27000001072883606	CHEMBL274926,TN,INACT,0.2199999988079071	CHEMBL3353405,TP,ACT,0.8700000047683716	CHEMBL131695,TN,INACT,0.18000000715255737	CHEMBL3421636,TN,INACT,0.23999999463558197	CHEMBL55979,TN,INACT,0.33000001311302185	CHEMBL1094808,FP,INACT,0.8600000143051147	CHEMBL457180,TN,INACT,0.23999999463558197	CHEMBL464552,TP,ACT,0.8100000023841858	CHEMBL62701,FP,INACT,0.7599999904632568	CHEMBL100675,TN,INACT,0.10000000149011612	CHEMBL589119,TN,INACT,0.46000000834465027	CHEMBL559882,TN,INACT,0.47999998927116394	CHEMBL2062563,TN,INACT,0.15000000596046448	CHEMBL1944956,FN,ACT,0.550000011920929	CHEMBL589503,TN,INACT,0.3400000035762787	CHEMBL487737,TN,INACT,0.5799999833106995	CHEMBL1822512,TP,ACT,0.7699999809265137	CHEMBL450383,TN,INACT,0.20000000298023224	CHEMBL202830,TP,ACT,0.7699999809265137	CHEMBL557525,TN,INACT,0.6299999952316284	CHEMBL327725,TN,INACT,0.25	CHEMBL2403843,TP,ACT,0.8799999952316284	CHEMBL606245,TN,INACT,0.18000000715255737	CHEMBL1683957,FP,INACT,0.9200000166893005	CHEMBL279481,TN,INACT,0.23999999463558197	CHEMBL291986,TN,INACT,0.11999999731779099	CHEMBL2348165,TN,INACT,0.07999999821186066	CHEMBL1944954,FN,ACT,0.41999998688697815	CHEMBL1630110,TP,ACT,1.0	CHEMBL494135,TP,ACT,0.8700000047683716	CHEMBL1973716,TN,INACT,0.4399999976158142	CHEMBL563948,TN,INACT,0.6800000071525574	CHEMBL3287898,TP,ACT,0.9900000095367432	CHEMBL481884,TP,ACT,0.9700000286102295	CHEMBL154911,TN,INACT,0.14000000059604645	CHEMBL557456,TN,INACT,0.07000000029802322	CHEMBL3823864,TP,ACT,0.8799999952316284	CHEMBL3353409,FP,INACT,0.8100000023841858	CHEMBL519698,TP,ACT,0.9100000262260437	CHEMBL3824326,TP,ACT,0.8799999952316284	CHEMBL77869,TN,INACT,0.1599999964237213	CHEMBL3823078,TP,ACT,0.9599999785423279	CHEMBL1823653,TN,INACT,0.27000001072883606	CHEMBL77298,TN,INACT,0.18000000715255737	CHEMBL1241684,TN,INACT,0.23999999463558197	CHEMBL3691604,FP,INACT,0.8199999928474426	CHEMBL1946212,TP,ACT,0.800000011920929	CHEMBL373882,TP,ACT,0.9200000166893005	CHEMBL598000,TN,INACT,0.6200000047683716	CHEMBL3421974,TN,INACT,0.550000011920929	CHEMBL592224,TN,INACT,0.6000000238418579	CHEMBL590023,TN,INACT,0.27000001072883606	CHEMBL1240829,FN,ACT,0.550000011920929	CHEMBL336330,TN,INACT,0.5600000023841858	CHEMBL209148,TP,ACT,0.9300000071525574	CHEMBL228862,TN,INACT,0.09000000357627869	CHEMBL141238,TN,INACT,0.5099999904632568	CHEMBL525538,TN,INACT,0.550000011920929	CHEMBL522711,TP,ACT,0.8700000047683716	CHEMBL1221415,TN,INACT,0.27000001072883606	CHEMBL1161235,TN,INACT,0.28999999165534973	CHEMBL317281,TN,INACT,0.10000000149011612	CHEMBL487785,TP,ACT,0.9399999976158142	CHEMBL115895,FP,INACT,0.75	CHEMBL1087002,TP,ACT,0.9900000095367432	CHEMBL3133834,TN,INACT,0.18000000715255737	CHEMBL331137,FN,ACT,0.5099999904632568	CHEMBL233958,FP,INACT,0.7200000286102295	CHEMBL3823016,TP,ACT,0.9700000286102295	CHEMBL1614712,TP,ACT,0.8899999856948853	CHEMBL2348167,TN,INACT,0.09000000357627869	CHEMBL3806196,TP,ACT,0.9800000190734863	CHEMBL481720,TP,ACT,0.9800000190734863	CHEMBL3218857,TP,ACT,0.8899999856948853	CHEMBL180022,TP,ACT,0.8600000143051147	CHEMBL323015,TN,INACT,0.20000000298023224	CHEMBL1630107,TP,ACT,0.9900000095367432	CHEMBL315701,TN,INACT,0.10000000149011612	CHEMBL2403847,TP,ACT,0.8899999856948853	CHEMBL67655,TN,INACT,0.5099999904632568	CHEMBL104,TN,INACT,0.18000000715255737	CHEMBL2042694,TP,ACT,0.7099999785423279	CHEMBL1939491,TP,ACT,0.9599999785423279	CHEMBL1910756,TN,INACT,0.41999998688697815	CHEMBL1642144,TP,ACT,0.9800000190734863	CHEMBL463384,TN,INACT,0.3499999940395355	CHEMBL1630113,TP,ACT,0.9800000190734863	CHEMBL1828882,TN,INACT,0.12999999523162842	CHEMBL319709,TN,INACT,0.5799999833106995	CHEMBL3823235,TP,ACT,0.9300000071525574	CHEMBL1822523,TP,ACT,0.9700000286102295	CHEMBL3218861,TP,ACT,0.8999999761581421	CHEMBL492931,TP,ACT,0.9599999785423279	CHEMBL335966,TN,INACT,0.1599999964237213	CHEMBL1945644,TN,INACT,0.3400000035762787	CHEMBL1088348,FP,INACT,0.8199999928474426	CHEMBL487526,TN,INACT,0.5400000214576721	CHEMBL1822513,TP,ACT,0.8500000238418579	CHEMBL589847,TN,INACT,0.23000000417232513	CHEMBL101779,FP,INACT,0.7900000214576721	CHEMBL2403841,TP,ACT,0.8999999761581421	CHEMBL2172308,TP,ACT,0.8700000047683716	CHEMBL2403837,TP,ACT,0.8600000143051147	CHEMBL3805516,TP,ACT,0.9800000190734863	CHEMBL1241670,TP,ACT,0.7699999809265137	CHEMBL1939492,TP,ACT,0.9599999785423279	CHEMBL3823577,TP,ACT,0.9599999785423279	CHEMBL1075628,TP,ACT,0.9599999785423279	CHEMBL3824308,TP,ACT,0.7900000214576721	CHEMBL549792,TN,INACT,0.07000000029802322	CHEMBL3822524,TP,ACT,0.9800000190734863	CHEMBL1939481,TP,ACT,0.8999999761581421	CHEMBL1240683,FP,INACT,0.9100000262260437	CHEMBL1944953,FN,ACT,0.44999998807907104	CHEMBL1241391,TN,INACT,0.5299999713897705	CHEMBL1939320,TP,ACT,0.9399999976158142	CHEMBL314021,TN,INACT,0.15000000596046448	CHEMBL521155,TN,INACT,0.17000000178813934	CHEMBL591440,TN,INACT,0.11999999731779099	CHEMBL456965,TN,INACT,0.10000000149011612	CHEMBL483403,TP,ACT,0.9399999976158142	CHEMBL551663,TN,INACT,0.3100000023841858	CHEMBL3263959,TP,ACT,0.8299999833106995	CHEMBL177688,FN,ACT,0.38999998569488525	CHEMBL3806043,TP,ACT,0.9900000095367432	CHEMBL1908397,FN,ACT,0.3199999928474426	CHEMBL590877,TN,INACT,0.09000000357627869	CHEMBL2163616,TN,INACT,0.6100000143051147	CHEMBL177298,FN,ACT,0.6299999952316284	CHEMBL600828,TN,INACT,0.5	CHEMBL3823603,TP,ACT,0.75	CHEMBL3824185,TP,ACT,0.8999999761581421	CHEMBL2348170,TN,INACT,0.07999999821186066	CHEMBL2088094,FN,ACT,0.6100000143051147	CHEMBL457886,TP,ACT,0.9300000071525574	CHEMBL482169,TP,ACT,0.9399999976158142	CHEMBL1642145,TP,ACT,0.9700000286102295	CHEMBL3822475,TP,ACT,0.9599999785423279	CHEMBL1642149,TP,ACT,0.9599999785423279	CHEMBL169757,TN,INACT,0.2800000011920929	CHEMBL3805129,TP,ACT,0.9599999785423279	

