CNNModel CHEMBL3816 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	210
Number of inactive compounds :	140
---------------------------------
Run id: CNNModel_CHEMBL3816_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3816_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 224
Validation samples: 70
--
Training Step: 1  | time: 0.792s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/224
[A[ATraining Step: 2  | total loss: [1m[32m0.62357[0m[0m | time: 1.394s
[2K
| Adam | epoch: 001 | loss: 0.62357 - acc: 0.5062 -- iter: 064/224
[A[ATraining Step: 3  | total loss: [1m[32m0.67779[0m[0m | time: 2.014s
[2K
| Adam | epoch: 001 | loss: 0.67779 - acc: 0.6034 -- iter: 096/224
[A[ATraining Step: 4  | total loss: [1m[32m0.68415[0m[0m | time: 2.621s
[2K
| Adam | epoch: 001 | loss: 0.68415 - acc: 0.5962 -- iter: 128/224
[A[ATraining Step: 5  | total loss: [1m[32m0.68926[0m[0m | time: 3.389s
[2K
| Adam | epoch: 001 | loss: 0.68926 - acc: 0.5512 -- iter: 160/224
[A[ATraining Step: 6  | total loss: [1m[32m0.65898[0m[0m | time: 4.104s
[2K
| Adam | epoch: 001 | loss: 0.65898 - acc: 0.6589 -- iter: 192/224
[A[ATraining Step: 7  | total loss: [1m[32m0.70445[0m[0m | time: 5.837s
[2K
| Adam | epoch: 001 | loss: 0.70445 - acc: 0.5448 | val_loss: 0.67247 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 8  | total loss: [1m[32m0.70195[0m[0m | time: 0.756s
[2K
| Adam | epoch: 002 | loss: 0.70195 - acc: 0.5372 -- iter: 032/224
[A[ATraining Step: 9  | total loss: [1m[32m0.69832[0m[0m | time: 1.537s
[2K
| Adam | epoch: 002 | loss: 0.69832 - acc: 0.5340 -- iter: 064/224
[A[ATraining Step: 10  | total loss: [1m[32m0.70106[0m[0m | time: 2.296s
[2K
| Adam | epoch: 002 | loss: 0.70106 - acc: 0.5170 -- iter: 096/224
[A[ATraining Step: 11  | total loss: [1m[32m0.67657[0m[0m | time: 3.048s
[2K
| Adam | epoch: 002 | loss: 0.67657 - acc: 0.6274 -- iter: 128/224
[A[ATraining Step: 12  | total loss: [1m[32m0.67521[0m[0m | time: 3.794s
[2K
| Adam | epoch: 002 | loss: 0.67521 - acc: 0.6263 -- iter: 160/224
[A[ATraining Step: 13  | total loss: [1m[32m0.67271[0m[0m | time: 4.524s
[2K
| Adam | epoch: 002 | loss: 0.67271 - acc: 0.6391 -- iter: 192/224
[A[ATraining Step: 14  | total loss: [1m[32m0.66505[0m[0m | time: 6.142s
[2K
| Adam | epoch: 002 | loss: 0.66505 - acc: 0.6717 | val_loss: 0.67415 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 15  | total loss: [1m[32m0.67857[0m[0m | time: 0.625s
[2K
| Adam | epoch: 003 | loss: 0.67857 - acc: 0.6045 -- iter: 032/224
[A[ATraining Step: 16  | total loss: [1m[32m0.66795[0m[0m | time: 1.227s
[2K
| Adam | epoch: 003 | loss: 0.66795 - acc: 0.6356 -- iter: 064/224
[A[ATraining Step: 17  | total loss: [1m[32m0.65940[0m[0m | time: 1.838s
[2K
| Adam | epoch: 003 | loss: 0.65940 - acc: 0.6543 -- iter: 096/224
[A[ATraining Step: 18  | total loss: [1m[32m0.65485[0m[0m | time: 2.439s
[2K
| Adam | epoch: 003 | loss: 0.65485 - acc: 0.6550 -- iter: 128/224
[A[ATraining Step: 19  | total loss: [1m[32m0.67523[0m[0m | time: 3.048s
[2K
| Adam | epoch: 003 | loss: 0.67523 - acc: 0.6137 -- iter: 160/224
[A[ATraining Step: 20  | total loss: [1m[32m0.67858[0m[0m | time: 3.650s
[2K
| Adam | epoch: 003 | loss: 0.67858 - acc: 0.6073 -- iter: 192/224
[A[ATraining Step: 21  | total loss: [1m[32m0.69799[0m[0m | time: 5.264s
[2K
| Adam | epoch: 003 | loss: 0.69799 - acc: 0.5740 | val_loss: 0.67127 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 22  | total loss: [1m[32m0.70260[0m[0m | time: 0.614s
[2K
| Adam | epoch: 004 | loss: 0.70260 - acc: 0.5612 -- iter: 032/224
[A[ATraining Step: 23  | total loss: [1m[32m0.67192[0m[0m | time: 1.237s
[2K
| Adam | epoch: 004 | loss: 0.67192 - acc: 0.6251 -- iter: 064/224
[A[ATraining Step: 24  | total loss: [1m[32m0.67347[0m[0m | time: 1.839s
[2K
| Adam | epoch: 004 | loss: 0.67347 - acc: 0.6163 -- iter: 096/224
[A[ATraining Step: 25  | total loss: [1m[32m0.67383[0m[0m | time: 2.436s
[2K
| Adam | epoch: 004 | loss: 0.67383 - acc: 0.6101 -- iter: 128/224
[A[ATraining Step: 26  | total loss: [1m[32m0.66013[0m[0m | time: 3.071s
[2K
| Adam | epoch: 004 | loss: 0.66013 - acc: 0.6471 -- iter: 160/224
[A[ATraining Step: 27  | total loss: [1m[32m0.66671[0m[0m | time: 3.676s
[2K
| Adam | epoch: 004 | loss: 0.66671 - acc: 0.6254 -- iter: 192/224
[A[ATraining Step: 28  | total loss: [1m[32m0.67149[0m[0m | time: 5.293s
[2K
| Adam | epoch: 004 | loss: 0.67149 - acc: 0.6097 | val_loss: 0.67093 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 29  | total loss: [1m[32m0.67208[0m[0m | time: 0.628s
[2K
| Adam | epoch: 005 | loss: 0.67208 - acc: 0.6058 -- iter: 032/224
[A[ATraining Step: 30  | total loss: [1m[32m0.67300[0m[0m | time: 1.224s
[2K
| Adam | epoch: 005 | loss: 0.67300 - acc: 0.6029 -- iter: 064/224
[A[ATraining Step: 31  | total loss: [1m[32m0.67051[0m[0m | time: 1.848s
[2K
| Adam | epoch: 005 | loss: 0.67051 - acc: 0.6080 -- iter: 096/224
[A[ATraining Step: 32  | total loss: [1m[32m0.66576[0m[0m | time: 2.462s
[2K
| Adam | epoch: 005 | loss: 0.66576 - acc: 0.6189 -- iter: 128/224
[A[ATraining Step: 33  | total loss: [1m[32m0.66117[0m[0m | time: 3.090s
[2K
| Adam | epoch: 005 | loss: 0.66117 - acc: 0.6271 -- iter: 160/224
[A[ATraining Step: 34  | total loss: [1m[32m0.65093[0m[0m | time: 3.724s
[2K
| Adam | epoch: 005 | loss: 0.65093 - acc: 0.6467 -- iter: 192/224
[A[ATraining Step: 35  | total loss: [1m[32m0.65995[0m[0m | time: 5.347s
[2K
| Adam | epoch: 005 | loss: 0.65995 - acc: 0.6291 | val_loss: 0.67439 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 36  | total loss: [1m[32m0.66459[0m[0m | time: 0.610s
[2K
| Adam | epoch: 006 | loss: 0.66459 - acc: 0.6219 -- iter: 032/224
[A[ATraining Step: 37  | total loss: [1m[32m0.66729[0m[0m | time: 1.203s
[2K
| Adam | epoch: 006 | loss: 0.66729 - acc: 0.6162 -- iter: 064/224
[A[ATraining Step: 38  | total loss: [1m[32m0.66474[0m[0m | time: 1.806s
[2K
| Adam | epoch: 006 | loss: 0.66474 - acc: 0.6180 -- iter: 096/224
[A[ATraining Step: 39  | total loss: [1m[32m0.67336[0m[0m | time: 2.420s
[2K
| Adam | epoch: 006 | loss: 0.67336 - acc: 0.6014 -- iter: 128/224
[A[ATraining Step: 40  | total loss: [1m[32m0.66786[0m[0m | time: 3.039s
[2K
| Adam | epoch: 006 | loss: 0.66786 - acc: 0.6116 -- iter: 160/224
[A[ATraining Step: 41  | total loss: [1m[32m0.66379[0m[0m | time: 3.658s
[2K
| Adam | epoch: 006 | loss: 0.66379 - acc: 0.6198 -- iter: 192/224
[A[ATraining Step: 42  | total loss: [1m[32m0.65982[0m[0m | time: 5.270s
[2K
| Adam | epoch: 006 | loss: 0.65982 - acc: 0.6264 | val_loss: 0.66699 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 43  | total loss: [1m[32m0.65239[0m[0m | time: 0.620s
[2K
| Adam | epoch: 007 | loss: 0.65239 - acc: 0.6427 -- iter: 032/224
[A[ATraining Step: 44  | total loss: [1m[32m0.66082[0m[0m | time: 1.227s
[2K
| Adam | epoch: 007 | loss: 0.66082 - acc: 0.6234 -- iter: 064/224
[A[ATraining Step: 45  | total loss: [1m[32m0.65974[0m[0m | time: 1.863s
[2K
| Adam | epoch: 007 | loss: 0.65974 - acc: 0.6237 -- iter: 096/224
[A[ATraining Step: 46  | total loss: [1m[32m0.66641[0m[0m | time: 2.486s
[2K
| Adam | epoch: 007 | loss: 0.66641 - acc: 0.6083 -- iter: 128/224
[A[ATraining Step: 47  | total loss: [1m[32m0.66922[0m[0m | time: 3.109s
[2K
| Adam | epoch: 007 | loss: 0.66922 - acc: 0.6008 -- iter: 160/224
[A[ATraining Step: 48  | total loss: [1m[32m0.67079[0m[0m | time: 3.718s
[2K
| Adam | epoch: 007 | loss: 0.67079 - acc: 0.5946 -- iter: 192/224
[A[ATraining Step: 49  | total loss: [1m[32m0.67135[0m[0m | time: 5.343s
[2K
| Adam | epoch: 007 | loss: 0.67135 - acc: 0.5896 | val_loss: 0.66331 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 50  | total loss: [1m[32m0.66609[0m[0m | time: 0.631s
[2K
| Adam | epoch: 008 | loss: 0.66609 - acc: 0.6048 -- iter: 032/224
[A[ATraining Step: 51  | total loss: [1m[32m0.66556[0m[0m | time: 1.239s
[2K
| Adam | epoch: 008 | loss: 0.66556 - acc: 0.6031 -- iter: 064/224
[A[ATraining Step: 52  | total loss: [1m[32m0.66296[0m[0m | time: 1.854s
[2K
| Adam | epoch: 008 | loss: 0.66296 - acc: 0.6064 -- iter: 096/224
[A[ATraining Step: 53  | total loss: [1m[32m0.66517[0m[0m | time: 2.463s
[2K
| Adam | epoch: 008 | loss: 0.66517 - acc: 0.5999 -- iter: 128/224
[A[ATraining Step: 54  | total loss: [1m[32m0.66424[0m[0m | time: 3.062s
[2K
| Adam | epoch: 008 | loss: 0.66424 - acc: 0.5990 -- iter: 160/224
[A[ATraining Step: 55  | total loss: [1m[32m0.65979[0m[0m | time: 3.661s
[2K
| Adam | epoch: 008 | loss: 0.65979 - acc: 0.6072 -- iter: 192/224
[A[ATraining Step: 56  | total loss: [1m[32m0.65393[0m[0m | time: 5.276s
[2K
| Adam | epoch: 008 | loss: 0.65393 - acc: 0.6185 | val_loss: 0.66417 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 57  | total loss: [1m[32m0.64779[0m[0m | time: 0.621s
[2K
| Adam | epoch: 009 | loss: 0.64779 - acc: 0.6280 -- iter: 032/224
[A[ATraining Step: 58  | total loss: [1m[32m0.64542[0m[0m | time: 1.223s
[2K
| Adam | epoch: 009 | loss: 0.64542 - acc: 0.6276 -- iter: 064/224
[A[ATraining Step: 59  | total loss: [1m[32m0.65437[0m[0m | time: 1.824s
[2K
| Adam | epoch: 009 | loss: 0.65437 - acc: 0.6189 -- iter: 096/224
[A[ATraining Step: 60  | total loss: [1m[32m0.65900[0m[0m | time: 2.432s
[2K
| Adam | epoch: 009 | loss: 0.65900 - acc: 0.6114 -- iter: 128/224
[A[ATraining Step: 61  | total loss: [1m[32m0.65843[0m[0m | time: 3.042s
[2K
| Adam | epoch: 009 | loss: 0.65843 - acc: 0.6091 -- iter: 160/224
[A[ATraining Step: 62  | total loss: [1m[32m0.65930[0m[0m | time: 3.647s
[2K
| Adam | epoch: 009 | loss: 0.65930 - acc: 0.5991 -- iter: 192/224
[A[ATraining Step: 63  | total loss: [1m[32m0.65327[0m[0m | time: 5.245s
[2K
| Adam | epoch: 009 | loss: 0.65327 - acc: 0.6143 | val_loss: 0.64439 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 64  | total loss: [1m[32m0.65260[0m[0m | time: 0.636s
[2K
| Adam | epoch: 010 | loss: 0.65260 - acc: 0.6156 -- iter: 032/224
[A[ATraining Step: 65  | total loss: [1m[32m0.65114[0m[0m | time: 1.243s
[2K
| Adam | epoch: 010 | loss: 0.65114 - acc: 0.6168 -- iter: 064/224
[A[ATraining Step: 66  | total loss: [1m[32m0.64797[0m[0m | time: 1.851s
[2K
| Adam | epoch: 010 | loss: 0.64797 - acc: 0.6216 -- iter: 096/224
[A[ATraining Step: 67  | total loss: [1m[32m0.65264[0m[0m | time: 2.463s
[2K
| Adam | epoch: 010 | loss: 0.65264 - acc: 0.6032 -- iter: 128/224
[A[ATraining Step: 68  | total loss: [1m[32m0.65627[0m[0m | time: 3.069s
[2K
| Adam | epoch: 010 | loss: 0.65627 - acc: 0.5873 -- iter: 160/224
[A[ATraining Step: 69  | total loss: [1m[32m0.64510[0m[0m | time: 3.668s
[2K
| Adam | epoch: 010 | loss: 0.64510 - acc: 0.6027 -- iter: 192/224
[A[ATraining Step: 70  | total loss: [1m[32m0.63957[0m[0m | time: 5.275s
[2K
| Adam | epoch: 010 | loss: 0.63957 - acc: 0.6052 | val_loss: 0.61159 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 71  | total loss: [1m[32m0.63017[0m[0m | time: 0.622s
[2K
| Adam | epoch: 011 | loss: 0.63017 - acc: 0.6182 -- iter: 032/224
[A[ATraining Step: 72  | total loss: [1m[32m0.63085[0m[0m | time: 1.228s
[2K
| Adam | epoch: 011 | loss: 0.63085 - acc: 0.6154 -- iter: 064/224
[A[ATraining Step: 73  | total loss: [1m[32m0.62775[0m[0m | time: 1.824s
[2K
| Adam | epoch: 011 | loss: 0.62775 - acc: 0.6130 -- iter: 096/224
[A[ATraining Step: 74  | total loss: [1m[32m0.61528[0m[0m | time: 2.430s
[2K
| Adam | epoch: 011 | loss: 0.61528 - acc: 0.6315 -- iter: 128/224
[A[ATraining Step: 75  | total loss: [1m[32m0.61288[0m[0m | time: 3.037s
[2K
| Adam | epoch: 011 | loss: 0.61288 - acc: 0.6240 -- iter: 160/224
[A[ATraining Step: 76  | total loss: [1m[32m0.60643[0m[0m | time: 3.635s
[2K
| Adam | epoch: 011 | loss: 0.60643 - acc: 0.6141 -- iter: 192/224
[A[ATraining Step: 77  | total loss: [1m[32m0.60424[0m[0m | time: 5.239s
[2K
| Adam | epoch: 011 | loss: 0.60424 - acc: 0.6086 | val_loss: 0.53529 - val_acc: 0.6000 -- iter: 224/224
--
Training Step: 78  | total loss: [1m[32m0.59631[0m[0m | time: 0.613s
[2K
| Adam | epoch: 012 | loss: 0.59631 - acc: 0.6103 -- iter: 032/224
[A[ATraining Step: 79  | total loss: [1m[32m0.59206[0m[0m | time: 1.212s
[2K
| Adam | epoch: 012 | loss: 0.59206 - acc: 0.6118 -- iter: 064/224
[A[ATraining Step: 80  | total loss: [1m[32m0.58283[0m[0m | time: 1.830s
[2K
| Adam | epoch: 012 | loss: 0.58283 - acc: 0.6164 -- iter: 096/224
[A[ATraining Step: 81  | total loss: [1m[32m0.57385[0m[0m | time: 2.447s
[2K
| Adam | epoch: 012 | loss: 0.57385 - acc: 0.6204 -- iter: 128/224
[A[ATraining Step: 82  | total loss: [1m[32m0.55912[0m[0m | time: 3.063s
[2K
| Adam | epoch: 012 | loss: 0.55912 - acc: 0.6209 -- iter: 160/224
[A[ATraining Step: 83  | total loss: [1m[32m0.53830[0m[0m | time: 3.658s
[2K
| Adam | epoch: 012 | loss: 0.53830 - acc: 0.6338 -- iter: 192/224
[A[ATraining Step: 84  | total loss: [1m[32m0.55147[0m[0m | time: 5.277s
[2K
| Adam | epoch: 012 | loss: 0.55147 - acc: 0.6204 | val_loss: 0.50428 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 85  | total loss: [1m[32m0.55626[0m[0m | time: 0.602s
[2K
| Adam | epoch: 013 | loss: 0.55626 - acc: 0.6302 -- iter: 032/224
[A[ATraining Step: 86  | total loss: [1m[32m0.55200[0m[0m | time: 1.210s
[2K
| Adam | epoch: 013 | loss: 0.55200 - acc: 0.6485 -- iter: 064/224
[A[ATraining Step: 87  | total loss: [1m[32m0.55453[0m[0m | time: 1.816s
[2K
| Adam | epoch: 013 | loss: 0.55453 - acc: 0.6649 -- iter: 096/224
[A[ATraining Step: 88  | total loss: [1m[32m0.55976[0m[0m | time: 2.413s
[2K
| Adam | epoch: 013 | loss: 0.55976 - acc: 0.6578 -- iter: 128/224
[A[ATraining Step: 89  | total loss: [1m[32m0.55912[0m[0m | time: 3.024s
[2K
| Adam | epoch: 013 | loss: 0.55912 - acc: 0.6607 -- iter: 160/224
[A[ATraining Step: 90  | total loss: [1m[32m0.56412[0m[0m | time: 3.641s
[2K
| Adam | epoch: 013 | loss: 0.56412 - acc: 0.6665 -- iter: 192/224
[A[ATraining Step: 91  | total loss: [1m[32m0.55060[0m[0m | time: 5.239s
[2K
| Adam | epoch: 013 | loss: 0.55060 - acc: 0.6811 | val_loss: 0.52995 - val_acc: 0.6857 -- iter: 224/224
--
Training Step: 92  | total loss: [1m[32m0.53733[0m[0m | time: 0.739s
[2K
| Adam | epoch: 014 | loss: 0.53733 - acc: 0.7005 -- iter: 032/224
[A[ATraining Step: 93  | total loss: [1m[32m0.52650[0m[0m | time: 1.346s
[2K
| Adam | epoch: 014 | loss: 0.52650 - acc: 0.7148 -- iter: 064/224
[A[ATraining Step: 94  | total loss: [1m[32m0.51616[0m[0m | time: 1.951s
[2K
| Adam | epoch: 014 | loss: 0.51616 - acc: 0.7277 -- iter: 096/224
[A[ATraining Step: 95  | total loss: [1m[32m0.51526[0m[0m | time: 2.563s
[2K
| Adam | epoch: 014 | loss: 0.51526 - acc: 0.7300 -- iter: 128/224
[A[ATraining Step: 96  | total loss: [1m[32m0.50587[0m[0m | time: 3.165s
[2K
| Adam | epoch: 014 | loss: 0.50587 - acc: 0.7413 -- iter: 160/224
[A[ATraining Step: 97  | total loss: [1m[32m0.49707[0m[0m | time: 3.759s
[2K
| Adam | epoch: 014 | loss: 0.49707 - acc: 0.7578 -- iter: 192/224
[A[ATraining Step: 98  | total loss: [1m[32m0.49353[0m[0m | time: 5.365s
[2K
| Adam | epoch: 014 | loss: 0.49353 - acc: 0.7695 | val_loss: 0.50134 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 99  | total loss: [1m[32m0.49071[0m[0m | time: 0.642s
[2K
| Adam | epoch: 015 | loss: 0.49071 - acc: 0.7770 -- iter: 032/224
[A[ATraining Step: 100  | total loss: [1m[32m0.47186[0m[0m | time: 1.277s
[2K
| Adam | epoch: 015 | loss: 0.47186 - acc: 0.7930 -- iter: 064/224
[A[ATraining Step: 101  | total loss: [1m[32m0.46375[0m[0m | time: 1.892s
[2K
| Adam | epoch: 015 | loss: 0.46375 - acc: 0.7918 -- iter: 096/224
[A[ATraining Step: 102  | total loss: [1m[32m0.47001[0m[0m | time: 2.493s
[2K
| Adam | epoch: 015 | loss: 0.47001 - acc: 0.7939 -- iter: 128/224
[A[ATraining Step: 103  | total loss: [1m[32m0.46828[0m[0m | time: 3.090s
[2K
| Adam | epoch: 015 | loss: 0.46828 - acc: 0.7958 -- iter: 160/224
[A[ATraining Step: 104  | total loss: [1m[32m0.46144[0m[0m | time: 3.704s
[2K
| Adam | epoch: 015 | loss: 0.46144 - acc: 0.8037 -- iter: 192/224
[A[ATraining Step: 105  | total loss: [1m[32m0.44179[0m[0m | time: 5.314s
[2K
| Adam | epoch: 015 | loss: 0.44179 - acc: 0.8202 | val_loss: 0.56721 - val_acc: 0.7714 -- iter: 224/224
--
Training Step: 106  | total loss: [1m[32m0.44910[0m[0m | time: 0.612s
[2K
| Adam | epoch: 016 | loss: 0.44910 - acc: 0.8194 -- iter: 032/224
[A[ATraining Step: 107  | total loss: [1m[32m0.43274[0m[0m | time: 1.210s
[2K
| Adam | epoch: 016 | loss: 0.43274 - acc: 0.8281 -- iter: 064/224
[A[ATraining Step: 108  | total loss: [1m[32m0.44582[0m[0m | time: 1.812s
[2K
| Adam | epoch: 016 | loss: 0.44582 - acc: 0.8203 -- iter: 096/224
[A[ATraining Step: 109  | total loss: [1m[32m0.43866[0m[0m | time: 2.424s
[2K
| Adam | epoch: 016 | loss: 0.43866 - acc: 0.8195 -- iter: 128/224
[A[ATraining Step: 110  | total loss: [1m[32m0.42871[0m[0m | time: 3.023s
[2K
| Adam | epoch: 016 | loss: 0.42871 - acc: 0.8219 -- iter: 160/224
[A[ATraining Step: 111  | total loss: [1m[32m0.42444[0m[0m | time: 3.639s
[2K
| Adam | epoch: 016 | loss: 0.42444 - acc: 0.8210 -- iter: 192/224
[A[ATraining Step: 112  | total loss: [1m[32m0.45400[0m[0m | time: 5.239s
[2K
| Adam | epoch: 016 | loss: 0.45400 - acc: 0.8045 | val_loss: 0.60329 - val_acc: 0.7286 -- iter: 224/224
--
Training Step: 113  | total loss: [1m[32m0.47920[0m[0m | time: 0.602s
[2K
| Adam | epoch: 017 | loss: 0.47920 - acc: 0.7897 -- iter: 032/224
[A[ATraining Step: 114  | total loss: [1m[32m0.46032[0m[0m | time: 1.204s
[2K
| Adam | epoch: 017 | loss: 0.46032 - acc: 0.8014 -- iter: 064/224
[A[ATraining Step: 115  | total loss: [1m[32m0.44720[0m[0m | time: 1.811s
[2K
| Adam | epoch: 017 | loss: 0.44720 - acc: 0.8118 -- iter: 096/224
[A[ATraining Step: 116  | total loss: [1m[32m0.44375[0m[0m | time: 2.410s
[2K
| Adam | epoch: 017 | loss: 0.44375 - acc: 0.8150 -- iter: 128/224
[A[ATraining Step: 117  | total loss: [1m[32m0.42645[0m[0m | time: 3.039s
[2K
| Adam | epoch: 017 | loss: 0.42645 - acc: 0.8210 -- iter: 160/224
[A[ATraining Step: 118  | total loss: [1m[32m0.41863[0m[0m | time: 3.657s
[2K
| Adam | epoch: 017 | loss: 0.41863 - acc: 0.8233 -- iter: 192/224
[A[ATraining Step: 119  | total loss: [1m[32m0.43102[0m[0m | time: 5.241s
[2K
| Adam | epoch: 017 | loss: 0.43102 - acc: 0.8191 | val_loss: 0.58235 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 120  | total loss: [1m[32m0.43410[0m[0m | time: 0.623s
[2K
| Adam | epoch: 018 | loss: 0.43410 - acc: 0.8216 -- iter: 032/224
[A[ATraining Step: 121  | total loss: [1m[32m0.42233[0m[0m | time: 1.220s
[2K
| Adam | epoch: 018 | loss: 0.42233 - acc: 0.8269 -- iter: 064/224
[A[ATraining Step: 122  | total loss: [1m[32m0.42590[0m[0m | time: 1.828s
[2K
| Adam | epoch: 018 | loss: 0.42590 - acc: 0.8223 -- iter: 096/224
[A[ATraining Step: 123  | total loss: [1m[32m0.41126[0m[0m | time: 2.455s
[2K
| Adam | epoch: 018 | loss: 0.41126 - acc: 0.8307 -- iter: 128/224
[A[ATraining Step: 124  | total loss: [1m[32m0.39634[0m[0m | time: 3.065s
[2K
| Adam | epoch: 018 | loss: 0.39634 - acc: 0.8414 -- iter: 160/224
[A[ATraining Step: 125  | total loss: [1m[32m0.38468[0m[0m | time: 3.668s
[2K
| Adam | epoch: 018 | loss: 0.38468 - acc: 0.8510 -- iter: 192/224
[A[ATraining Step: 126  | total loss: [1m[32m0.38652[0m[0m | time: 5.273s
[2K
| Adam | epoch: 018 | loss: 0.38652 - acc: 0.8534 | val_loss: 0.51111 - val_acc: 0.7714 -- iter: 224/224
--
Training Step: 127  | total loss: [1m[32m0.38041[0m[0m | time: 0.652s
[2K
| Adam | epoch: 019 | loss: 0.38041 - acc: 0.8587 -- iter: 032/224
[A[ATraining Step: 128  | total loss: [1m[32m0.35931[0m[0m | time: 1.257s
[2K
| Adam | epoch: 019 | loss: 0.35931 - acc: 0.8728 -- iter: 064/224
[A[ATraining Step: 129  | total loss: [1m[32m0.33872[0m[0m | time: 1.867s
[2K
| Adam | epoch: 019 | loss: 0.33872 - acc: 0.8855 -- iter: 096/224
[A[ATraining Step: 130  | total loss: [1m[32m0.32681[0m[0m | time: 2.467s
[2K
| Adam | epoch: 019 | loss: 0.32681 - acc: 0.8907 -- iter: 128/224
[A[ATraining Step: 131  | total loss: [1m[32m0.32519[0m[0m | time: 3.061s
[2K
| Adam | epoch: 019 | loss: 0.32519 - acc: 0.8923 -- iter: 160/224
[A[ATraining Step: 132  | total loss: [1m[32m0.33514[0m[0m | time: 3.662s
[2K
| Adam | epoch: 019 | loss: 0.33514 - acc: 0.8812 -- iter: 192/224
[A[ATraining Step: 133  | total loss: [1m[32m0.34318[0m[0m | time: 5.267s
[2K
| Adam | epoch: 019 | loss: 0.34318 - acc: 0.8837 | val_loss: 0.55780 - val_acc: 0.8000 -- iter: 224/224
--
Training Step: 134  | total loss: [1m[32m0.36247[0m[0m | time: 0.617s
[2K
| Adam | epoch: 020 | loss: 0.36247 - acc: 0.8766 -- iter: 032/224
[A[ATraining Step: 135  | total loss: [1m[32m0.34251[0m[0m | time: 1.226s
[2K
| Adam | epoch: 020 | loss: 0.34251 - acc: 0.8858 -- iter: 064/224
[A[ATraining Step: 136  | total loss: [1m[32m0.33764[0m[0m | time: 1.837s
[2K
| Adam | epoch: 020 | loss: 0.33764 - acc: 0.8847 -- iter: 096/224
[A[ATraining Step: 137  | total loss: [1m[32m0.32528[0m[0m | time: 2.444s
[2K
| Adam | epoch: 020 | loss: 0.32528 - acc: 0.8900 -- iter: 128/224
[A[ATraining Step: 138  | total loss: [1m[32m0.31008[0m[0m | time: 3.043s
[2K
| Adam | epoch: 020 | loss: 0.31008 - acc: 0.8947 -- iter: 160/224
[A[ATraining Step: 139  | total loss: [1m[32m0.33403[0m[0m | time: 3.654s
[2K
| Adam | epoch: 020 | loss: 0.33403 - acc: 0.8771 -- iter: 192/224
[A[ATraining Step: 140  | total loss: [1m[32m0.32812[0m[0m | time: 5.261s
[2K
| Adam | epoch: 020 | loss: 0.32812 - acc: 0.8769 | val_loss: 0.54848 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 141  | total loss: [1m[32m0.32938[0m[0m | time: 0.642s
[2K
| Adam | epoch: 021 | loss: 0.32938 - acc: 0.8736 -- iter: 032/224
[A[ATraining Step: 142  | total loss: [1m[32m0.33305[0m[0m | time: 1.259s
[2K
| Adam | epoch: 021 | loss: 0.33305 - acc: 0.8737 -- iter: 064/224
[A[ATraining Step: 143  | total loss: [1m[32m0.33096[0m[0m | time: 1.871s
[2K
| Adam | epoch: 021 | loss: 0.33096 - acc: 0.8739 -- iter: 096/224
[A[ATraining Step: 144  | total loss: [1m[32m0.34316[0m[0m | time: 2.483s
[2K
| Adam | epoch: 021 | loss: 0.34316 - acc: 0.8677 -- iter: 128/224
[A[ATraining Step: 145  | total loss: [1m[32m0.35673[0m[0m | time: 3.086s
[2K
| Adam | epoch: 021 | loss: 0.35673 - acc: 0.8622 -- iter: 160/224
[A[ATraining Step: 146  | total loss: [1m[32m0.33871[0m[0m | time: 3.697s
[2K
| Adam | epoch: 021 | loss: 0.33871 - acc: 0.8729 -- iter: 192/224
[A[ATraining Step: 147  | total loss: [1m[32m0.34601[0m[0m | time: 5.319s
[2K
| Adam | epoch: 021 | loss: 0.34601 - acc: 0.8700 | val_loss: 0.60618 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 148  | total loss: [1m[32m0.32587[0m[0m | time: 0.619s
[2K
| Adam | epoch: 022 | loss: 0.32587 - acc: 0.8798 -- iter: 032/224
[A[ATraining Step: 149  | total loss: [1m[32m0.32002[0m[0m | time: 1.215s
[2K
| Adam | epoch: 022 | loss: 0.32002 - acc: 0.8825 -- iter: 064/224
[A[ATraining Step: 150  | total loss: [1m[32m0.32844[0m[0m | time: 1.821s
[2K
| Adam | epoch: 022 | loss: 0.32844 - acc: 0.8755 -- iter: 096/224
[A[ATraining Step: 151  | total loss: [1m[32m0.31910[0m[0m | time: 2.437s
[2K
| Adam | epoch: 022 | loss: 0.31910 - acc: 0.8817 -- iter: 128/224
[A[ATraining Step: 152  | total loss: [1m[32m0.32174[0m[0m | time: 3.055s
[2K
| Adam | epoch: 022 | loss: 0.32174 - acc: 0.8779 -- iter: 160/224
[A[ATraining Step: 153  | total loss: [1m[32m0.31700[0m[0m | time: 3.642s
[2K
| Adam | epoch: 022 | loss: 0.31700 - acc: 0.8807 -- iter: 192/224
[A[ATraining Step: 154  | total loss: [1m[32m0.30598[0m[0m | time: 5.246s
[2K
| Adam | epoch: 022 | loss: 0.30598 - acc: 0.8895 | val_loss: 0.55588 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 155  | total loss: [1m[32m0.31879[0m[0m | time: 0.648s
[2K
| Adam | epoch: 023 | loss: 0.31879 - acc: 0.8818 -- iter: 032/224
[A[ATraining Step: 156  | total loss: [1m[32m0.31458[0m[0m | time: 1.238s
[2K
| Adam | epoch: 023 | loss: 0.31458 - acc: 0.8843 -- iter: 064/224
[A[ATraining Step: 157  | total loss: [1m[32m0.29275[0m[0m | time: 1.871s
[2K
| Adam | epoch: 023 | loss: 0.29275 - acc: 0.8958 -- iter: 096/224
[A[ATraining Step: 158  | total loss: [1m[32m0.28322[0m[0m | time: 2.471s
[2K
| Adam | epoch: 023 | loss: 0.28322 - acc: 0.9000 -- iter: 128/224
[A[ATraining Step: 159  | total loss: [1m[32m0.27346[0m[0m | time: 3.073s
[2K
| Adam | epoch: 023 | loss: 0.27346 - acc: 0.9069 -- iter: 160/224
[A[ATraining Step: 160  | total loss: [1m[32m0.27393[0m[0m | time: 3.688s
[2K
| Adam | epoch: 023 | loss: 0.27393 - acc: 0.9006 -- iter: 192/224
[A[ATraining Step: 161  | total loss: [1m[32m0.26716[0m[0m | time: 5.319s
[2K
| Adam | epoch: 023 | loss: 0.26716 - acc: 0.8980 | val_loss: 0.59010 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 162  | total loss: [1m[32m0.26341[0m[0m | time: 0.623s
[2K
| Adam | epoch: 024 | loss: 0.26341 - acc: 0.9020 -- iter: 032/224
[A[ATraining Step: 163  | total loss: [1m[32m0.26485[0m[0m | time: 1.235s
[2K
| Adam | epoch: 024 | loss: 0.26485 - acc: 0.9024 -- iter: 064/224
[A[ATraining Step: 164  | total loss: [1m[32m0.25988[0m[0m | time: 1.835s
[2K
| Adam | epoch: 024 | loss: 0.25988 - acc: 0.9059 -- iter: 096/224
[A[ATraining Step: 165  | total loss: [1m[32m0.25179[0m[0m | time: 2.460s
[2K
| Adam | epoch: 024 | loss: 0.25179 - acc: 0.9122 -- iter: 128/224
[A[ATraining Step: 166  | total loss: [1m[32m0.23398[0m[0m | time: 3.075s
[2K
| Adam | epoch: 024 | loss: 0.23398 - acc: 0.9210 -- iter: 160/224
[A[ATraining Step: 167  | total loss: [1m[32m0.23524[0m[0m | time: 3.677s
[2K
| Adam | epoch: 024 | loss: 0.23524 - acc: 0.9132 -- iter: 192/224
[A[ATraining Step: 168  | total loss: [1m[32m0.24189[0m[0m | time: 5.275s
[2K
| Adam | epoch: 024 | loss: 0.24189 - acc: 0.9188 | val_loss: 0.70136 - val_acc: 0.8143 -- iter: 224/224
--
Training Step: 169  | total loss: [1m[32m0.22985[0m[0m | time: 0.621s
[2K
| Adam | epoch: 025 | loss: 0.22985 - acc: 0.9238 -- iter: 032/224
[A[ATraining Step: 170  | total loss: [1m[32m0.23149[0m[0m | time: 1.221s
[2K
| Adam | epoch: 025 | loss: 0.23149 - acc: 0.9189 -- iter: 064/224
[A[ATraining Step: 171  | total loss: [1m[32m0.21571[0m[0m | time: 1.823s
[2K
| Adam | epoch: 025 | loss: 0.21571 - acc: 0.9270 -- iter: 096/224
[A[ATraining Step: 172  | total loss: [1m[32m0.20297[0m[0m | time: 2.432s
[2K
| Adam | epoch: 025 | loss: 0.20297 - acc: 0.9312 -- iter: 128/224
[A[ATraining Step: 173  | total loss: [1m[32m0.20743[0m[0m | time: 3.042s
[2K
| Adam | epoch: 025 | loss: 0.20743 - acc: 0.9287 -- iter: 160/224
[A[ATraining Step: 174  | total loss: [1m[32m0.19989[0m[0m | time: 3.640s
[2K
| Adam | epoch: 025 | loss: 0.19989 - acc: 0.9327 -- iter: 192/224
[A[ATraining Step: 175  | total loss: [1m[32m0.19317[0m[0m | time: 5.235s
[2K
| Adam | epoch: 025 | loss: 0.19317 - acc: 0.9332 | val_loss: 0.76125 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 176  | total loss: [1m[32m0.19824[0m[0m | time: 0.639s
[2K
| Adam | epoch: 026 | loss: 0.19824 - acc: 0.9305 -- iter: 032/224
[A[ATraining Step: 177  | total loss: [1m[32m0.19256[0m[0m | time: 1.248s
[2K
| Adam | epoch: 026 | loss: 0.19256 - acc: 0.9343 -- iter: 064/224
[A[ATraining Step: 178  | total loss: [1m[32m0.18683[0m[0m | time: 1.857s
[2K
| Adam | epoch: 026 | loss: 0.18683 - acc: 0.9409 -- iter: 096/224
[A[ATraining Step: 179  | total loss: [1m[32m0.18403[0m[0m | time: 2.979s
[2K
| Adam | epoch: 026 | loss: 0.18403 - acc: 0.9405 -- iter: 128/224
[A[ATraining Step: 180  | total loss: [1m[32m0.17076[0m[0m | time: 3.614s
[2K
| Adam | epoch: 026 | loss: 0.17076 - acc: 0.9465 -- iter: 160/224
[A[ATraining Step: 181  | total loss: [1m[32m0.16287[0m[0m | time: 4.219s
[2K
| Adam | epoch: 026 | loss: 0.16287 - acc: 0.9456 -- iter: 192/224
[A[ATraining Step: 182  | total loss: [1m[32m0.15495[0m[0m | time: 5.829s
[2K
| Adam | epoch: 026 | loss: 0.15495 - acc: 0.9448 | val_loss: 0.91848 - val_acc: 0.7571 -- iter: 224/224
--
Training Step: 183  | total loss: [1m[32m0.23570[0m[0m | time: 0.595s
[2K
| Adam | epoch: 027 | loss: 0.23570 - acc: 0.9222 -- iter: 032/224
[A[ATraining Step: 184  | total loss: [1m[32m0.25468[0m[0m | time: 1.225s
[2K
| Adam | epoch: 027 | loss: 0.25468 - acc: 0.9143 -- iter: 064/224
[A[ATraining Step: 185  | total loss: [1m[32m0.24368[0m[0m | time: 1.845s
[2K
| Adam | epoch: 027 | loss: 0.24368 - acc: 0.9135 -- iter: 096/224
[A[ATraining Step: 186  | total loss: [1m[32m0.23479[0m[0m | time: 2.457s
[2K
| Adam | epoch: 027 | loss: 0.23479 - acc: 0.9159 -- iter: 128/224
[A[ATraining Step: 187  | total loss: [1m[32m0.22144[0m[0m | time: 3.067s
[2K
| Adam | epoch: 027 | loss: 0.22144 - acc: 0.9212 -- iter: 160/224
[A[ATraining Step: 188  | total loss: [1m[32m0.22590[0m[0m | time: 3.668s
[2K
| Adam | epoch: 027 | loss: 0.22590 - acc: 0.9228 -- iter: 192/224
[A[ATraining Step: 189  | total loss: [1m[32m0.21031[0m[0m | time: 5.277s
[2K
| Adam | epoch: 027 | loss: 0.21031 - acc: 0.9306 | val_loss: 0.75673 - val_acc: 0.7571 -- iter: 224/224
--
Training Step: 190  | total loss: [1m[32m0.20559[0m[0m | time: 0.632s
[2K
| Adam | epoch: 028 | loss: 0.20559 - acc: 0.9312 -- iter: 032/224
[A[ATraining Step: 191  | total loss: [1m[32m0.21010[0m[0m | time: 1.239s
[2K
| Adam | epoch: 028 | loss: 0.21010 - acc: 0.9319 -- iter: 064/224
[A[ATraining Step: 192  | total loss: [1m[32m0.22932[0m[0m | time: 1.848s
[2K
| Adam | epoch: 028 | loss: 0.22932 - acc: 0.9262 -- iter: 096/224
[A[ATraining Step: 193  | total loss: [1m[32m0.21568[0m[0m | time: 2.452s
[2K
| Adam | epoch: 028 | loss: 0.21568 - acc: 0.9304 -- iter: 128/224
[A[ATraining Step: 194  | total loss: [1m[32m0.21131[0m[0m | time: 3.070s
[2K
| Adam | epoch: 028 | loss: 0.21131 - acc: 0.9311 -- iter: 160/224
[A[ATraining Step: 195  | total loss: [1m[32m0.19728[0m[0m | time: 3.678s
[2K
| Adam | epoch: 028 | loss: 0.19728 - acc: 0.9349 -- iter: 192/224
[A[ATraining Step: 196  | total loss: [1m[32m0.18113[0m[0m | time: 5.298s
[2K
| Adam | epoch: 028 | loss: 0.18113 - acc: 0.9414 | val_loss: 0.76777 - val_acc: 0.7714 -- iter: 224/224
--
Training Step: 197  | total loss: [1m[32m0.18580[0m[0m | time: 0.640s
[2K
| Adam | epoch: 029 | loss: 0.18580 - acc: 0.9379 -- iter: 032/224
[A[ATraining Step: 198  | total loss: [1m[32m0.18296[0m[0m | time: 1.253s
[2K
| Adam | epoch: 029 | loss: 0.18296 - acc: 0.9347 -- iter: 064/224
[A[ATraining Step: 199  | total loss: [1m[32m0.18618[0m[0m | time: 1.864s
[2K
| Adam | epoch: 029 | loss: 0.18618 - acc: 0.9319 -- iter: 096/224
[A[ATraining Step: 200  | total loss: [1m[32m0.20038[0m[0m | time: 3.464s
[2K
| Adam | epoch: 029 | loss: 0.20038 - acc: 0.9293 | val_loss: 0.64559 - val_acc: 0.8000 -- iter: 128/224
--
Training Step: 201  | total loss: [1m[32m0.19658[0m[0m | time: 4.064s
[2K
| Adam | epoch: 029 | loss: 0.19658 - acc: 0.9333 -- iter: 160/224
[A[ATraining Step: 202  | total loss: [1m[32m0.18569[0m[0m | time: 4.697s
[2K
| Adam | epoch: 029 | loss: 0.18569 - acc: 0.9368 -- iter: 192/224
[A[ATraining Step: 203  | total loss: [1m[32m0.17043[0m[0m | time: 6.310s
[2K
| Adam | epoch: 029 | loss: 0.17043 - acc: 0.9431 | val_loss: 0.69925 - val_acc: 0.7857 -- iter: 224/224
--
Training Step: 204  | total loss: [1m[32m0.16491[0m[0m | time: 0.609s
[2K
| Adam | epoch: 030 | loss: 0.16491 - acc: 0.9457 -- iter: 032/224
[A[ATraining Step: 205  | total loss: [1m[32m0.16026[0m[0m | time: 1.222s
[2K
| Adam | epoch: 030 | loss: 0.16026 - acc: 0.9480 -- iter: 064/224
[A[ATraining Step: 206  | total loss: [1m[32m0.15031[0m[0m | time: 1.826s
[2K
| Adam | epoch: 030 | loss: 0.15031 - acc: 0.9532 -- iter: 096/224
[A[ATraining Step: 207  | total loss: [1m[32m0.14866[0m[0m | time: 2.438s
[2K
| Adam | epoch: 030 | loss: 0.14866 - acc: 0.9548 -- iter: 128/224
[A[ATraining Step: 208  | total loss: [1m[32m0.17276[0m[0m | time: 3.047s
[2K
| Adam | epoch: 030 | loss: 0.17276 - acc: 0.9530 -- iter: 160/224
[A[ATraining Step: 209  | total loss: [1m[32m0.15916[0m[0m | time: 3.653s
[2K
| Adam | epoch: 030 | loss: 0.15916 - acc: 0.9577 -- iter: 192/224
[A[ATraining Step: 210  | total loss: [1m[32m0.15224[0m[0m | time: 5.250s
[2K
| Adam | epoch: 030 | loss: 0.15224 - acc: 0.9588 | val_loss: 0.71541 - val_acc: 0.7857 -- iter: 224/224
--
Validation AUC:0.8061224489795918
Validation AUPRC:0.8594506525795799
Test AUC:0.9555921052631579
Test AUPRC:0.9746253172831759
BestTestF1Score	0.91	0.8	0.9	0.9	0.92	35	4	28	3	0.15
BestTestMCCScore	0.9	0.81	0.9	0.97	0.84	32	1	31	6	0.69
BestTestAccuracyScore	0.9	0.81	0.9	0.97	0.84	32	1	31	6	0.69
BestValidationF1Score	0.84	0.58	0.8	0.8	0.88	37	9	19	5	0.15
BestValidationMCC	0.83	0.59	0.8	0.85	0.81	34	6	22	8	0.69
BestValidationAccuracy	0.83	0.59	0.8	0.85	0.81	34	6	22	8	0.69
TestPredictions (Threshold:0.69)
CHEMBL223204,FN,ACT,0.6600000262260437	CHEMBL504912,TP,ACT,0.9800000190734863	CHEMBL482959,TP,ACT,0.9900000095367432	CHEMBL375551,TP,ACT,0.8999999761581421	CHEMBL520836,TP,ACT,0.9800000190734863	CHEMBL343362,TN,INACT,0.009999999776482582	CHEMBL502458,TP,ACT,1.0	CHEMBL220806,TP,ACT,0.9599999785423279	CHEMBL220735,TP,ACT,0.7599999904632568	CHEMBL3327091,TP,ACT,1.0	CHEMBL439687,TN,INACT,0.009999999776482582	CHEMBL433361,TN,INACT,0.019999999552965164	CHEMBL28120,TN,INACT,0.20000000298023224	CHEMBL448722,TP,ACT,1.0	CHEMBL208401,TP,ACT,0.9800000190734863	CHEMBL557975,TN,INACT,0.019999999552965164	CHEMBL436943,TN,INACT,0.029999999329447746	CHEMBL503141,TP,ACT,0.9700000286102295	CHEMBL488320,TP,ACT,0.9300000071525574	CHEMBL78679,TN,INACT,0.09000000357627869	CHEMBL95190,FN,ACT,0.03999999910593033	CHEMBL3326961,TP,ACT,0.9900000095367432	CHEMBL370113,TP,ACT,0.8899999856948853	CHEMBL375430,FN,ACT,0.550000011920929	CHEMBL374649,TP,ACT,0.9599999785423279	CHEMBL139858,TP,ACT,0.8299999833106995	CHEMBL472006,TN,INACT,0.029999999329447746	CHEMBL260248,TP,ACT,0.9599999785423279	CHEMBL45477,FP,INACT,0.7400000095367432	CHEMBL1080994,TN,INACT,0.18000000715255737	CHEMBL513379,TN,INACT,0.019999999552965164	CHEMBL173459,TN,INACT,0.019999999552965164	CHEMBL117114,TN,INACT,0.029999999329447746	CHEMBL3753675,TN,INACT,0.05000000074505806	CHEMBL268905,TP,ACT,0.9700000286102295	CHEMBL452094,TP,ACT,0.9900000095367432	CHEMBL488671,TN,INACT,0.019999999552965164	CHEMBL52680,TN,INACT,0.019999999552965164	CHEMBL424386,FN,ACT,0.019999999552965164	CHEMBL608435,TP,ACT,0.949999988079071	CHEMBL334902,TN,INACT,0.009999999776482582	CHEMBL302304,TN,INACT,0.009999999776482582	CHEMBL142141,TN,INACT,0.23999999463558197	CHEMBL509553,TN,INACT,0.009999999776482582	CHEMBL268434,TP,ACT,1.0	CHEMBL3326949,TP,ACT,0.9599999785423279	CHEMBL375995,TN,INACT,0.009999999776482582	CHEMBL204302,TP,ACT,0.9900000095367432	CHEMBL2113332,TN,INACT,0.019999999552965164	CHEMBL504084,TP,ACT,0.9800000190734863	CHEMBL451024,TP,ACT,0.9599999785423279	CHEMBL301741,TN,INACT,0.019999999552965164	CHEMBL3327092,TP,ACT,0.9900000095367432	CHEMBL149604,TN,INACT,0.009999999776482582	CHEMBL510044,TP,ACT,0.949999988079071	CHEMBL55890,TN,INACT,0.009999999776482582	CHEMBL3326956,TP,ACT,0.9399999976158142	CHEMBL444877,TN,INACT,0.019999999552965164	CHEMBL484953,TP,ACT,0.9900000095367432	CHEMBL447045,TP,ACT,0.9700000286102295	CHEMBL269787,TP,ACT,0.9800000190734863	CHEMBL138705,FN,ACT,0.009999999776482582	CHEMBL27582,TN,INACT,0.029999999329447746	CHEMBL367625,TN,INACT,0.029999999329447746	CHEMBL306883,TN,INACT,0.009999999776482582	CHEMBL342927,TN,INACT,0.11999999731779099	CHEMBL492828,TN,INACT,0.029999999329447746	CHEMBL448596,FN,ACT,0.25	CHEMBL3326950,TP,ACT,1.0	CHEMBL278071,TN,INACT,0.03999999910593033	

