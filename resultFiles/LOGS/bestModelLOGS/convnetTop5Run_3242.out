CNNModel CHEMBL2693 adam 0.001 30 256 0 0.8 False True
Number of active compounds :	125
Number of inactive compounds :	125
---------------------------------
Run id: CNNModel_CHEMBL2693_adam_0.001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2693_adam_0.001_30_256_0.8_True/
---------------------------------
Training samples: 160
Validation samples: 50
--
Training Step: 1  | time: 0.745s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/160
[A[ATraining Step: 2  | total loss: [1m[32m0.62393[0m[0m | time: 1.377s
[2K
| Adam | epoch: 001 | loss: 0.62393 - acc: 0.4500 -- iter: 064/160
[A[ATraining Step: 3  | total loss: [1m[32m0.67978[0m[0m | time: 1.954s
[2K
| Adam | epoch: 001 | loss: 0.67978 - acc: 0.5165 -- iter: 096/160
[A[ATraining Step: 4  | total loss: [1m[32m0.69386[0m[0m | time: 2.566s
[2K
| Adam | epoch: 001 | loss: 0.69386 - acc: 0.4807 -- iter: 128/160
[A[ATraining Step: 5  | total loss: [1m[32m0.68910[0m[0m | time: 4.207s
[2K
| Adam | epoch: 001 | loss: 0.68910 - acc: 0.5806 | val_loss: 0.71872 - val_acc: 0.3800 -- iter: 160/160
--
Training Step: 6  | total loss: [1m[32m0.68227[0m[0m | time: 0.641s
[2K
| Adam | epoch: 002 | loss: 0.68227 - acc: 0.6493 -- iter: 032/160
[A[ATraining Step: 7  | total loss: [1m[32m0.67099[0m[0m | time: 1.249s
[2K
| Adam | epoch: 002 | loss: 0.67099 - acc: 0.6722 -- iter: 064/160
[A[ATraining Step: 8  | total loss: [1m[32m0.70224[0m[0m | time: 1.858s
[2K
| Adam | epoch: 002 | loss: 0.70224 - acc: 0.5578 -- iter: 096/160
[A[ATraining Step: 9  | total loss: [1m[32m0.69906[0m[0m | time: 2.479s
[2K
| Adam | epoch: 002 | loss: 0.69906 - acc: 0.5437 -- iter: 128/160
[A[ATraining Step: 10  | total loss: [1m[32m0.67920[0m[0m | time: 4.111s
[2K
| Adam | epoch: 002 | loss: 0.67920 - acc: 0.6000 | val_loss: 0.72750 - val_acc: 0.3800 -- iter: 160/160
--
Training Step: 11  | total loss: [1m[32m0.69015[0m[0m | time: 0.616s
[2K
| Adam | epoch: 003 | loss: 0.69015 - acc: 0.5526 -- iter: 032/160
[A[ATraining Step: 12  | total loss: [1m[32m0.68450[0m[0m | time: 1.228s
[2K
| Adam | epoch: 003 | loss: 0.68450 - acc: 0.5711 -- iter: 064/160
[A[ATraining Step: 13  | total loss: [1m[32m0.68168[0m[0m | time: 1.837s
[2K
| Adam | epoch: 003 | loss: 0.68168 - acc: 0.5808 -- iter: 096/160
[A[ATraining Step: 14  | total loss: [1m[32m0.68602[0m[0m | time: 2.452s
[2K
| Adam | epoch: 003 | loss: 0.68602 - acc: 0.5605 -- iter: 128/160
[A[ATraining Step: 15  | total loss: [1m[32m0.69036[0m[0m | time: 4.059s
[2K
| Adam | epoch: 003 | loss: 0.69036 - acc: 0.5369 | val_loss: 0.71982 - val_acc: 0.3800 -- iter: 160/160
--
Training Step: 16  | total loss: [1m[32m0.68530[0m[0m | time: 0.631s
[2K
| Adam | epoch: 004 | loss: 0.68530 - acc: 0.5582 -- iter: 032/160
[A[ATraining Step: 17  | total loss: [1m[32m0.68073[0m[0m | time: 1.269s
[2K
| Adam | epoch: 004 | loss: 0.68073 - acc: 0.5822 -- iter: 064/160
[A[ATraining Step: 18  | total loss: [1m[32m0.68249[0m[0m | time: 1.879s
[2K
| Adam | epoch: 004 | loss: 0.68249 - acc: 0.5754 -- iter: 096/160
[A[ATraining Step: 19  | total loss: [1m[32m0.68315[0m[0m | time: 2.491s
[2K
| Adam | epoch: 004 | loss: 0.68315 - acc: 0.5711 -- iter: 128/160
[A[ATraining Step: 20  | total loss: [1m[32m0.69636[0m[0m | time: 4.117s
[2K
| Adam | epoch: 004 | loss: 0.69636 - acc: 0.5181 | val_loss: 0.72173 - val_acc: 0.3800 -- iter: 160/160
--
Training Step: 21  | total loss: [1m[32m0.69016[0m[0m | time: 0.620s
[2K
| Adam | epoch: 005 | loss: 0.69016 - acc: 0.5416 -- iter: 032/160
[A[ATraining Step: 22  | total loss: [1m[32m0.69050[0m[0m | time: 1.231s
[2K
| Adam | epoch: 005 | loss: 0.69050 - acc: 0.5385 -- iter: 064/160
[A[ATraining Step: 23  | total loss: [1m[32m0.68617[0m[0m | time: 1.841s
[2K
| Adam | epoch: 005 | loss: 0.68617 - acc: 0.5545 -- iter: 096/160
[A[ATraining Step: 24  | total loss: [1m[32m0.68756[0m[0m | time: 2.426s
[2K
| Adam | epoch: 005 | loss: 0.68756 - acc: 0.5480 -- iter: 128/160
[A[ATraining Step: 25  | total loss: [1m[32m0.68841[0m[0m | time: 4.036s
[2K
| Adam | epoch: 005 | loss: 0.68841 - acc: 0.5434 | val_loss: 0.71584 - val_acc: 0.3800 -- iter: 160/160
--
Training Step: 26  | total loss: [1m[32m0.68428[0m[0m | time: 0.677s
[2K
| Adam | epoch: 006 | loss: 0.68428 - acc: 0.5650 -- iter: 032/160
[A[ATraining Step: 27  | total loss: [1m[32m0.68675[0m[0m | time: 1.291s
[2K
| Adam | epoch: 006 | loss: 0.68675 - acc: 0.5483 -- iter: 064/160
[A[ATraining Step: 28  | total loss: [1m[32m0.68281[0m[0m | time: 1.896s
[2K
| Adam | epoch: 006 | loss: 0.68281 - acc: 0.5675 -- iter: 096/160
[A[ATraining Step: 29  | total loss: [1m[32m0.68677[0m[0m | time: 2.501s
[2K
| Adam | epoch: 006 | loss: 0.68677 - acc: 0.5435 -- iter: 128/160
[A[ATraining Step: 30  | total loss: [1m[32m0.68194[0m[0m | time: 4.104s
[2K
| Adam | epoch: 006 | loss: 0.68194 - acc: 0.5628 | val_loss: 0.73458 - val_acc: 0.3800 -- iter: 160/160
--
Training Step: 31  | total loss: [1m[32m0.67755[0m[0m | time: 0.612s
[2K
| Adam | epoch: 007 | loss: 0.67755 - acc: 0.5771 -- iter: 032/160
[A[ATraining Step: 32  | total loss: [1m[32m0.67833[0m[0m | time: 1.220s
[2K
| Adam | epoch: 007 | loss: 0.67833 - acc: 0.5738 -- iter: 064/160
[A[ATraining Step: 33  | total loss: [1m[32m0.68379[0m[0m | time: 1.835s
[2K
| Adam | epoch: 007 | loss: 0.68379 - acc: 0.5576 -- iter: 096/160
[A[ATraining Step: 34  | total loss: [1m[32m0.68340[0m[0m | time: 2.450s
[2K
| Adam | epoch: 007 | loss: 0.68340 - acc: 0.5520 -- iter: 128/160
[A[ATraining Step: 35  | total loss: [1m[32m0.67188[0m[0m | time: 4.059s
[2K
| Adam | epoch: 007 | loss: 0.67188 - acc: 0.5869 | val_loss: 0.74726 - val_acc: 0.3800 -- iter: 160/160
--
Training Step: 36  | total loss: [1m[32m0.67096[0m[0m | time: 0.627s
[2K
| Adam | epoch: 008 | loss: 0.67096 - acc: 0.5819 -- iter: 032/160
[A[ATraining Step: 37  | total loss: [1m[32m0.66979[0m[0m | time: 1.240s
[2K
| Adam | epoch: 008 | loss: 0.66979 - acc: 0.5780 -- iter: 064/160
[A[ATraining Step: 38  | total loss: [1m[32m0.67972[0m[0m | time: 1.856s
[2K
| Adam | epoch: 008 | loss: 0.67972 - acc: 0.5505 -- iter: 096/160
[A[ATraining Step: 39  | total loss: [1m[32m0.67822[0m[0m | time: 2.472s
[2K
| Adam | epoch: 008 | loss: 0.67822 - acc: 0.5468 -- iter: 128/160
[A[ATraining Step: 40  | total loss: [1m[32m0.67830[0m[0m | time: 4.082s
[2K
| Adam | epoch: 008 | loss: 0.67830 - acc: 0.5498 | val_loss: 0.69363 - val_acc: 0.3800 -- iter: 160/160
--
Training Step: 41  | total loss: [1m[32m0.67816[0m[0m | time: 0.604s
[2K
| Adam | epoch: 009 | loss: 0.67816 - acc: 0.5406 -- iter: 032/160
[A[ATraining Step: 42  | total loss: [1m[32m0.67542[0m[0m | time: 1.194s
[2K
| Adam | epoch: 009 | loss: 0.67542 - acc: 0.5446 -- iter: 064/160
[A[ATraining Step: 43  | total loss: [1m[32m0.67013[0m[0m | time: 1.796s
[2K
| Adam | epoch: 009 | loss: 0.67013 - acc: 0.5477 -- iter: 096/160
[A[ATraining Step: 44  | total loss: [1m[32m0.65911[0m[0m | time: 2.415s
[2K
| Adam | epoch: 009 | loss: 0.65911 - acc: 0.5557 -- iter: 128/160
[A[ATraining Step: 45  | total loss: [1m[32m0.65323[0m[0m | time: 4.035s
[2K
| Adam | epoch: 009 | loss: 0.65323 - acc: 0.5569 | val_loss: 0.66205 - val_acc: 0.7000 -- iter: 160/160
--
Training Step: 46  | total loss: [1m[32m0.66151[0m[0m | time: 0.615s
[2K
| Adam | epoch: 010 | loss: 0.66151 - acc: 0.5474 -- iter: 032/160
[A[ATraining Step: 47  | total loss: [1m[32m0.64940[0m[0m | time: 1.242s
[2K
| Adam | epoch: 010 | loss: 0.64940 - acc: 0.5754 -- iter: 064/160
[A[ATraining Step: 48  | total loss: [1m[32m0.64152[0m[0m | time: 1.837s
[2K
| Adam | epoch: 010 | loss: 0.64152 - acc: 0.6085 -- iter: 096/160
[A[ATraining Step: 49  | total loss: [1m[32m0.62159[0m[0m | time: 2.454s
[2K
| Adam | epoch: 010 | loss: 0.62159 - acc: 0.6456 -- iter: 128/160
[A[ATraining Step: 50  | total loss: [1m[32m0.63155[0m[0m | time: 4.069s
[2K
| Adam | epoch: 010 | loss: 0.63155 - acc: 0.6230 | val_loss: 0.71388 - val_acc: 0.7200 -- iter: 160/160
--
Training Step: 51  | total loss: [1m[32m0.62207[0m[0m | time: 0.610s
[2K
| Adam | epoch: 011 | loss: 0.62207 - acc: 0.6376 -- iter: 032/160
[A[ATraining Step: 52  | total loss: [1m[32m0.59802[0m[0m | time: 1.208s
[2K
| Adam | epoch: 011 | loss: 0.59802 - acc: 0.6639 -- iter: 064/160
[A[ATraining Step: 53  | total loss: [1m[32m0.59029[0m[0m | time: 1.813s
[2K
| Adam | epoch: 011 | loss: 0.59029 - acc: 0.6858 -- iter: 096/160
[A[ATraining Step: 54  | total loss: [1m[32m0.58027[0m[0m | time: 2.440s
[2K
| Adam | epoch: 011 | loss: 0.58027 - acc: 0.6997 -- iter: 128/160
[A[ATraining Step: 55  | total loss: [1m[32m0.56778[0m[0m | time: 4.055s
[2K
| Adam | epoch: 011 | loss: 0.56778 - acc: 0.7158 | val_loss: 0.51999 - val_acc: 0.8200 -- iter: 160/160
--
Training Step: 56  | total loss: [1m[32m0.58211[0m[0m | time: 0.649s
[2K
| Adam | epoch: 012 | loss: 0.58211 - acc: 0.7030 -- iter: 032/160
[A[ATraining Step: 57  | total loss: [1m[32m0.58229[0m[0m | time: 1.249s
[2K
| Adam | epoch: 012 | loss: 0.58229 - acc: 0.6965 -- iter: 064/160
[A[ATraining Step: 58  | total loss: [1m[32m0.55575[0m[0m | time: 1.963s
[2K
| Adam | epoch: 012 | loss: 0.55575 - acc: 0.7209 -- iter: 096/160
[A[ATraining Step: 59  | total loss: [1m[32m0.54583[0m[0m | time: 2.590s
[2K
| Adam | epoch: 012 | loss: 0.54583 - acc: 0.7206 -- iter: 128/160
[A[ATraining Step: 60  | total loss: [1m[32m0.53921[0m[0m | time: 4.201s
[2K
| Adam | epoch: 012 | loss: 0.53921 - acc: 0.7245 | val_loss: 0.46097 - val_acc: 0.8000 -- iter: 160/160
--
Training Step: 61  | total loss: [1m[32m0.52676[0m[0m | time: 0.625s
[2K
| Adam | epoch: 013 | loss: 0.52676 - acc: 0.7400 -- iter: 032/160
[A[ATraining Step: 62  | total loss: [1m[32m0.54393[0m[0m | time: 1.270s
[2K
| Adam | epoch: 013 | loss: 0.54393 - acc: 0.7293 -- iter: 064/160
[A[ATraining Step: 63  | total loss: [1m[32m0.54071[0m[0m | time: 1.889s
[2K
| Adam | epoch: 013 | loss: 0.54071 - acc: 0.7279 -- iter: 096/160
[A[ATraining Step: 64  | total loss: [1m[32m0.52499[0m[0m | time: 2.503s
[2K
| Adam | epoch: 013 | loss: 0.52499 - acc: 0.7346 -- iter: 128/160
[A[ATraining Step: 65  | total loss: [1m[32m0.52623[0m[0m | time: 4.098s
[2K
| Adam | epoch: 013 | loss: 0.52623 - acc: 0.7249 | val_loss: 0.51965 - val_acc: 0.8200 -- iter: 160/160
--
Training Step: 66  | total loss: [1m[32m0.52105[0m[0m | time: 0.610s
[2K
| Adam | epoch: 014 | loss: 0.52105 - acc: 0.7318 -- iter: 032/160
[A[ATraining Step: 67  | total loss: [1m[32m0.51510[0m[0m | time: 1.212s
[2K
| Adam | epoch: 014 | loss: 0.51510 - acc: 0.7377 -- iter: 064/160
[A[ATraining Step: 68  | total loss: [1m[32m0.48216[0m[0m | time: 1.815s
[2K
| Adam | epoch: 014 | loss: 0.48216 - acc: 0.7614 -- iter: 096/160
[A[ATraining Step: 69  | total loss: [1m[32m0.47095[0m[0m | time: 2.423s
[2K
| Adam | epoch: 014 | loss: 0.47095 - acc: 0.7674 -- iter: 128/160
[A[ATraining Step: 70  | total loss: [1m[32m0.46319[0m[0m | time: 4.036s
[2K
| Adam | epoch: 014 | loss: 0.46319 - acc: 0.7726 | val_loss: 0.57435 - val_acc: 0.8400 -- iter: 160/160
--
Training Step: 71  | total loss: [1m[32m0.44998[0m[0m | time: 0.630s
[2K
| Adam | epoch: 015 | loss: 0.44998 - acc: 0.7771 -- iter: 032/160
[A[ATraining Step: 72  | total loss: [1m[32m0.43123[0m[0m | time: 1.272s
[2K
| Adam | epoch: 015 | loss: 0.43123 - acc: 0.7881 -- iter: 064/160
[A[ATraining Step: 73  | total loss: [1m[32m0.40779[0m[0m | time: 1.886s
[2K
| Adam | epoch: 015 | loss: 0.40779 - acc: 0.8047 -- iter: 096/160
[A[ATraining Step: 74  | total loss: [1m[32m0.40452[0m[0m | time: 2.503s
[2K
| Adam | epoch: 015 | loss: 0.40452 - acc: 0.8056 -- iter: 128/160
[A[ATraining Step: 75  | total loss: [1m[32m0.39662[0m[0m | time: 4.213s
[2K
| Adam | epoch: 015 | loss: 0.39662 - acc: 0.8097 | val_loss: 0.62708 - val_acc: 0.8800 -- iter: 160/160
--
Training Step: 76  | total loss: [1m[32m0.38464[0m[0m | time: 0.620s
[2K
| Adam | epoch: 016 | loss: 0.38464 - acc: 0.8167 -- iter: 032/160
[A[ATraining Step: 77  | total loss: [1m[32m0.36258[0m[0m | time: 1.212s
[2K
| Adam | epoch: 016 | loss: 0.36258 - acc: 0.8295 -- iter: 064/160
[A[ATraining Step: 78  | total loss: [1m[32m0.35040[0m[0m | time: 1.824s
[2K
| Adam | epoch: 016 | loss: 0.35040 - acc: 0.8375 -- iter: 096/160
[A[ATraining Step: 79  | total loss: [1m[32m0.33746[0m[0m | time: 2.424s
[2K
| Adam | epoch: 016 | loss: 0.33746 - acc: 0.8446 -- iter: 128/160
[A[ATraining Step: 80  | total loss: [1m[32m0.31944[0m[0m | time: 4.032s
[2K
| Adam | epoch: 016 | loss: 0.31944 - acc: 0.8541 | val_loss: 0.44710 - val_acc: 0.8600 -- iter: 160/160
--
Training Step: 81  | total loss: [1m[32m0.30381[0m[0m | time: 0.605s
[2K
| Adam | epoch: 017 | loss: 0.30381 - acc: 0.8562 -- iter: 032/160
[A[ATraining Step: 82  | total loss: [1m[32m0.29711[0m[0m | time: 1.214s
[2K
| Adam | epoch: 017 | loss: 0.29711 - acc: 0.8612 -- iter: 064/160
[A[ATraining Step: 83  | total loss: [1m[32m0.29037[0m[0m | time: 1.841s
[2K
| Adam | epoch: 017 | loss: 0.29037 - acc: 0.8657 -- iter: 096/160
[A[ATraining Step: 84  | total loss: [1m[32m0.26805[0m[0m | time: 2.447s
[2K
| Adam | epoch: 017 | loss: 0.26805 - acc: 0.8760 -- iter: 128/160
[A[ATraining Step: 85  | total loss: [1m[32m0.25227[0m[0m | time: 4.052s
[2K
| Adam | epoch: 017 | loss: 0.25227 - acc: 0.8853 | val_loss: 0.52913 - val_acc: 0.8600 -- iter: 160/160
--
Training Step: 86  | total loss: [1m[32m0.24744[0m[0m | time: 0.612s
[2K
| Adam | epoch: 018 | loss: 0.24744 - acc: 0.8874 -- iter: 032/160
[A[ATraining Step: 87  | total loss: [1m[32m0.23284[0m[0m | time: 1.219s
[2K
| Adam | epoch: 018 | loss: 0.23284 - acc: 0.8924 -- iter: 064/160
[A[ATraining Step: 88  | total loss: [1m[32m0.22901[0m[0m | time: 1.836s
[2K
| Adam | epoch: 018 | loss: 0.22901 - acc: 0.8969 -- iter: 096/160
[A[ATraining Step: 89  | total loss: [1m[32m0.22728[0m[0m | time: 2.432s
[2K
| Adam | epoch: 018 | loss: 0.22728 - acc: 0.8979 -- iter: 128/160
[A[ATraining Step: 90  | total loss: [1m[32m0.21971[0m[0m | time: 4.031s
[2K
| Adam | epoch: 018 | loss: 0.21971 - acc: 0.9018 | val_loss: 0.94949 - val_acc: 0.8200 -- iter: 160/160
--
Training Step: 91  | total loss: [1m[32m0.21253[0m[0m | time: 0.621s
[2K
| Adam | epoch: 019 | loss: 0.21253 - acc: 0.9023 -- iter: 032/160
[A[ATraining Step: 92  | total loss: [1m[32m0.20282[0m[0m | time: 1.248s
[2K
| Adam | epoch: 019 | loss: 0.20282 - acc: 0.9058 -- iter: 064/160
[A[ATraining Step: 93  | total loss: [1m[32m0.19087[0m[0m | time: 1.847s
[2K
| Adam | epoch: 019 | loss: 0.19087 - acc: 0.9121 -- iter: 096/160
[A[ATraining Step: 94  | total loss: [1m[32m0.22823[0m[0m | time: 2.452s
[2K
| Adam | epoch: 019 | loss: 0.22823 - acc: 0.9053 -- iter: 128/160
[A[ATraining Step: 95  | total loss: [1m[32m0.22073[0m[0m | time: 4.062s
[2K
| Adam | epoch: 019 | loss: 0.22073 - acc: 0.9116 | val_loss: 0.86630 - val_acc: 0.7600 -- iter: 160/160
--
Training Step: 96  | total loss: [1m[32m0.20393[0m[0m | time: 0.614s
[2K
| Adam | epoch: 020 | loss: 0.20393 - acc: 0.9173 -- iter: 032/160
[A[ATraining Step: 97  | total loss: [1m[32m0.19106[0m[0m | time: 1.213s
[2K
| Adam | epoch: 020 | loss: 0.19106 - acc: 0.9256 -- iter: 064/160
[A[ATraining Step: 98  | total loss: [1m[32m0.18136[0m[0m | time: 1.828s
[2K
| Adam | epoch: 020 | loss: 0.18136 - acc: 0.9299 -- iter: 096/160
[A[ATraining Step: 99  | total loss: [1m[32m0.16760[0m[0m | time: 2.445s
[2K
| Adam | epoch: 020 | loss: 0.16760 - acc: 0.9369 -- iter: 128/160
[A[ATraining Step: 100  | total loss: [1m[32m0.16025[0m[0m | time: 4.059s
[2K
| Adam | epoch: 020 | loss: 0.16025 - acc: 0.9370 | val_loss: 0.79137 - val_acc: 0.8600 -- iter: 160/160
--
Training Step: 101  | total loss: [1m[32m0.14628[0m[0m | time: 0.613s
[2K
| Adam | epoch: 021 | loss: 0.14628 - acc: 0.9433 -- iter: 032/160
[A[ATraining Step: 102  | total loss: [1m[32m0.13747[0m[0m | time: 1.253s
[2K
| Adam | epoch: 021 | loss: 0.13747 - acc: 0.9458 -- iter: 064/160
[A[ATraining Step: 103  | total loss: [1m[32m0.12668[0m[0m | time: 1.867s
[2K
| Adam | epoch: 021 | loss: 0.12668 - acc: 0.9512 -- iter: 096/160
[A[ATraining Step: 104  | total loss: [1m[32m0.12360[0m[0m | time: 2.492s
[2K
| Adam | epoch: 021 | loss: 0.12360 - acc: 0.9530 -- iter: 128/160
[A[ATraining Step: 105  | total loss: [1m[32m0.11413[0m[0m | time: 4.109s
[2K
| Adam | epoch: 021 | loss: 0.11413 - acc: 0.9546 | val_loss: 0.64908 - val_acc: 0.8800 -- iter: 160/160
--
Training Step: 106  | total loss: [1m[32m0.14363[0m[0m | time: 0.635s
[2K
| Adam | epoch: 022 | loss: 0.14363 - acc: 0.9560 -- iter: 032/160
[A[ATraining Step: 107  | total loss: [1m[32m0.13120[0m[0m | time: 1.248s
[2K
| Adam | epoch: 022 | loss: 0.13120 - acc: 0.9604 -- iter: 064/160
[A[ATraining Step: 108  | total loss: [1m[32m0.11870[0m[0m | time: 1.853s
[2K
| Adam | epoch: 022 | loss: 0.11870 - acc: 0.9643 -- iter: 096/160
[A[ATraining Step: 109  | total loss: [1m[32m0.10768[0m[0m | time: 2.441s
[2K
| Adam | epoch: 022 | loss: 0.10768 - acc: 0.9679 -- iter: 128/160
[A[ATraining Step: 110  | total loss: [1m[32m0.10281[0m[0m | time: 4.132s
[2K
| Adam | epoch: 022 | loss: 0.10281 - acc: 0.9680 | val_loss: 1.21813 - val_acc: 0.6800 -- iter: 160/160
--
Training Step: 111  | total loss: [1m[32m0.09659[0m[0m | time: 0.627s
[2K
| Adam | epoch: 023 | loss: 0.09659 - acc: 0.9681 -- iter: 032/160
[A[ATraining Step: 112  | total loss: [1m[32m0.09370[0m[0m | time: 1.245s
[2K
| Adam | epoch: 023 | loss: 0.09370 - acc: 0.9713 -- iter: 064/160
[A[ATraining Step: 113  | total loss: [1m[32m0.09689[0m[0m | time: 1.849s
[2K
| Adam | epoch: 023 | loss: 0.09689 - acc: 0.9710 -- iter: 096/160
[A[ATraining Step: 114  | total loss: [1m[32m0.08796[0m[0m | time: 2.444s
[2K
| Adam | epoch: 023 | loss: 0.08796 - acc: 0.9739 -- iter: 128/160
[A[ATraining Step: 115  | total loss: [1m[32m0.08298[0m[0m | time: 4.038s
[2K
| Adam | epoch: 023 | loss: 0.08298 - acc: 0.9765 | val_loss: 0.40973 - val_acc: 0.8800 -- iter: 160/160
--
Training Step: 116  | total loss: [1m[32m0.08811[0m[0m | time: 0.617s
[2K
| Adam | epoch: 024 | loss: 0.08811 - acc: 0.9726 -- iter: 032/160
[A[ATraining Step: 117  | total loss: [1m[32m0.08373[0m[0m | time: 1.225s
[2K
| Adam | epoch: 024 | loss: 0.08373 - acc: 0.9754 -- iter: 064/160
[A[ATraining Step: 118  | total loss: [1m[32m0.08010[0m[0m | time: 1.834s
[2K
| Adam | epoch: 024 | loss: 0.08010 - acc: 0.9747 -- iter: 096/160
[A[ATraining Step: 119  | total loss: [1m[32m0.07597[0m[0m | time: 2.436s
[2K
| Adam | epoch: 024 | loss: 0.07597 - acc: 0.9772 -- iter: 128/160
[A[ATraining Step: 120  | total loss: [1m[32m0.07326[0m[0m | time: 4.041s
[2K
| Adam | epoch: 024 | loss: 0.07326 - acc: 0.9795 | val_loss: 0.55883 - val_acc: 0.8800 -- iter: 160/160
--
Training Step: 121  | total loss: [1m[32m0.06640[0m[0m | time: 0.613s
[2K
| Adam | epoch: 025 | loss: 0.06640 - acc: 0.9816 -- iter: 032/160
[A[ATraining Step: 122  | total loss: [1m[32m0.06017[0m[0m | time: 1.215s
[2K
| Adam | epoch: 025 | loss: 0.06017 - acc: 0.9834 -- iter: 064/160
[A[ATraining Step: 123  | total loss: [1m[32m0.05735[0m[0m | time: 1.827s
[2K
| Adam | epoch: 025 | loss: 0.05735 - acc: 0.9851 -- iter: 096/160
[A[ATraining Step: 124  | total loss: [1m[32m0.05297[0m[0m | time: 2.440s
[2K
| Adam | epoch: 025 | loss: 0.05297 - acc: 0.9866 -- iter: 128/160
[A[ATraining Step: 125  | total loss: [1m[32m0.05471[0m[0m | time: 4.038s
[2K
| Adam | epoch: 025 | loss: 0.05471 - acc: 0.9848 | val_loss: 0.84002 - val_acc: 0.8600 -- iter: 160/160
--
Training Step: 126  | total loss: [1m[32m0.05024[0m[0m | time: 0.608s
[2K
| Adam | epoch: 026 | loss: 0.05024 - acc: 0.9863 -- iter: 032/160
[A[ATraining Step: 127  | total loss: [1m[32m0.04621[0m[0m | time: 1.233s
[2K
| Adam | epoch: 026 | loss: 0.04621 - acc: 0.9877 -- iter: 064/160
[A[ATraining Step: 128  | total loss: [1m[32m0.05316[0m[0m | time: 1.841s
[2K
| Adam | epoch: 026 | loss: 0.05316 - acc: 0.9795 -- iter: 096/160
[A[ATraining Step: 129  | total loss: [1m[32m0.04876[0m[0m | time: 2.440s
[2K
| Adam | epoch: 026 | loss: 0.04876 - acc: 0.9816 -- iter: 128/160
[A[ATraining Step: 130  | total loss: [1m[32m0.08090[0m[0m | time: 4.056s
[2K
| Adam | epoch: 026 | loss: 0.08090 - acc: 0.9803 | val_loss: 0.74472 - val_acc: 0.8600 -- iter: 160/160
--
Training Step: 131  | total loss: [1m[32m0.07327[0m[0m | time: 0.672s
[2K
| Adam | epoch: 027 | loss: 0.07327 - acc: 0.9823 -- iter: 032/160
[A[ATraining Step: 132  | total loss: [1m[32m0.06644[0m[0m | time: 1.271s
[2K
| Adam | epoch: 027 | loss: 0.06644 - acc: 0.9840 -- iter: 064/160
[A[ATraining Step: 133  | total loss: [1m[32m0.06112[0m[0m | time: 1.901s
[2K
| Adam | epoch: 027 | loss: 0.06112 - acc: 0.9856 -- iter: 096/160
[A[ATraining Step: 134  | total loss: [1m[32m0.05769[0m[0m | time: 2.501s
[2K
| Adam | epoch: 027 | loss: 0.05769 - acc: 0.9871 -- iter: 128/160
[A[ATraining Step: 135  | total loss: [1m[32m0.05852[0m[0m | time: 4.105s
[2K
| Adam | epoch: 027 | loss: 0.05852 - acc: 0.9852 | val_loss: 0.75901 - val_acc: 0.8600 -- iter: 160/160
--
Training Step: 136  | total loss: [1m[32m0.05544[0m[0m | time: 0.620s
[2K
| Adam | epoch: 028 | loss: 0.05544 - acc: 0.9836 -- iter: 032/160
[A[ATraining Step: 137  | total loss: [1m[32m0.05170[0m[0m | time: 1.219s
[2K
| Adam | epoch: 028 | loss: 0.05170 - acc: 0.9852 -- iter: 064/160
[A[ATraining Step: 138  | total loss: [1m[32m0.04765[0m[0m | time: 1.825s
[2K
| Adam | epoch: 028 | loss: 0.04765 - acc: 0.9867 -- iter: 096/160
[A[ATraining Step: 139  | total loss: [1m[32m0.04446[0m[0m | time: 2.435s
[2K
| Adam | epoch: 028 | loss: 0.04446 - acc: 0.9880 -- iter: 128/160
[A[ATraining Step: 140  | total loss: [1m[32m0.05345[0m[0m | time: 4.043s
[2K
| Adam | epoch: 028 | loss: 0.05345 - acc: 0.9830 | val_loss: 1.06978 - val_acc: 0.7400 -- iter: 160/160
--
Training Step: 141  | total loss: [1m[32m0.04887[0m[0m | time: 0.609s
[2K
| Adam | epoch: 029 | loss: 0.04887 - acc: 0.9847 -- iter: 032/160
[A[ATraining Step: 142  | total loss: [1m[32m0.04628[0m[0m | time: 1.224s
[2K
| Adam | epoch: 029 | loss: 0.04628 - acc: 0.9862 -- iter: 064/160
[A[ATraining Step: 143  | total loss: [1m[32m0.04212[0m[0m | time: 1.839s
[2K
| Adam | epoch: 029 | loss: 0.04212 - acc: 0.9876 -- iter: 096/160
[A[ATraining Step: 144  | total loss: [1m[32m0.03830[0m[0m | time: 2.442s
[2K
| Adam | epoch: 029 | loss: 0.03830 - acc: 0.9888 -- iter: 128/160
[A[ATraining Step: 145  | total loss: [1m[32m0.03469[0m[0m | time: 4.060s
[2K
| Adam | epoch: 029 | loss: 0.03469 - acc: 0.9900 | val_loss: 0.70878 - val_acc: 0.8800 -- iter: 160/160
--
Training Step: 146  | total loss: [1m[32m0.03142[0m[0m | time: 0.628s
[2K
| Adam | epoch: 030 | loss: 0.03142 - acc: 0.9910 -- iter: 032/160
[A[ATraining Step: 147  | total loss: [1m[32m0.02847[0m[0m | time: 1.230s
[2K
| Adam | epoch: 030 | loss: 0.02847 - acc: 0.9919 -- iter: 064/160
[A[ATraining Step: 148  | total loss: [1m[32m0.04784[0m[0m | time: 1.832s
[2K
| Adam | epoch: 030 | loss: 0.04784 - acc: 0.9895 -- iter: 096/160
[A[ATraining Step: 149  | total loss: [1m[32m0.04331[0m[0m | time: 2.432s
[2K
| Adam | epoch: 030 | loss: 0.04331 - acc: 0.9906 -- iter: 128/160
[A[ATraining Step: 150  | total loss: [1m[32m0.03960[0m[0m | time: 4.071s
[2K
| Adam | epoch: 030 | loss: 0.03960 - acc: 0.9915 | val_loss: 0.76950 - val_acc: 0.8800 -- iter: 160/160
--
Validation AUC:0.9354838709677419
Validation AUPRC:0.9692528371665999
Test AUC:0.8896103896103896
Test AUPRC:0.8575106777772571
BestTestF1Score	0.87	0.72	0.86	0.89	0.86	24	3	19	4	0.77
BestTestMCCScore	0.87	0.72	0.86	0.89	0.86	24	3	19	4	0.77
BestTestAccuracyScore	0.87	0.72	0.86	0.89	0.86	24	3	19	4	0.77
BestValidationF1Score	0.92	0.8	0.9	0.96	0.87	27	1	18	4	0.77
BestValidationMCC	0.92	0.8	0.9	0.96	0.87	27	1	18	4	0.77
BestValidationAccuracy	0.92	0.8	0.9	0.96	0.87	27	1	18	4	0.77
TestPredictions (Threshold:0.77)
CHEMBL516281,TN,INACT,0.0	CHEMBL499779,TP,ACT,1.0	CHEMBL3416696,TP,ACT,0.949999988079071	CHEMBL3416719,TP,ACT,1.0	CHEMBL1819444,FP,INACT,1.0	CHEMBL574273,TN,INACT,0.009999999776482582	CHEMBL574756,TN,INACT,0.0	CHEMBL296494,TN,INACT,0.0	CHEMBL2376117,TN,INACT,0.28999999165534973	CHEMBL1277623,FN,ACT,0.0	CHEMBL3416691,TP,ACT,1.0	CHEMBL3261750,TN,INACT,0.0	CHEMBL574757,TN,INACT,0.0	CHEMBL395354,TN,INACT,0.0	CHEMBL408132,TP,ACT,1.0	CHEMBL474850,TN,INACT,0.6200000047683716	CHEMBL501693,TP,ACT,0.9800000190734863	CHEMBL3416695,FN,ACT,0.009999999776482582	CHEMBL448920,FN,ACT,0.17000000178813934	CHEMBL2420382,TP,ACT,1.0	CHEMBL1782887,TP,ACT,1.0	CHEMBL245398,FP,INACT,0.9800000190734863	CHEMBL470072,TN,INACT,0.009999999776482582	CHEMBL1782883,TP,ACT,1.0	CHEMBL1077589,TP,ACT,1.0	CHEMBL1782885,TP,ACT,1.0	CHEMBL355434,TP,ACT,1.0	CHEMBL3416726,TP,ACT,1.0	CHEMBL3416721,TP,ACT,1.0	CHEMBL575672,TN,INACT,0.0	CHEMBL3740862,FP,INACT,0.7799999713897705	CHEMBL1604159,TP,ACT,1.0	CHEMBL3416731,FN,ACT,0.0	CHEMBL3261764,TN,INACT,0.0	CHEMBL3416692,TP,ACT,1.0	CHEMBL260622,TP,ACT,1.0	CHEMBL498743,TN,INACT,0.0	CHEMBL1782888,TP,ACT,1.0	CHEMBL3806100,TN,INACT,0.0	CHEMBL3125942,TP,ACT,0.8799999952316284	CHEMBL3416685,TP,ACT,0.9900000095367432	CHEMBL69238,TN,INACT,0.0	CHEMBL1830511,TN,INACT,0.0	CHEMBL497922,TN,INACT,0.0	CHEMBL1275683,TP,ACT,0.9900000095367432	CHEMBL69146,TN,INACT,0.0	CHEMBL3261762,TN,INACT,0.0	CHEMBL3416704,TP,ACT,0.9700000286102295	CHEMBL3416578,TP,ACT,1.0	CHEMBL1077583,TP,ACT,0.9599999785423279	

