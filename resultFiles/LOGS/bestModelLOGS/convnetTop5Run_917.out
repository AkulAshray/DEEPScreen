CNNModel CHEMBL4599 adam 0.001 15 32 0 0.6 False True
Number of active compounds :	447
Number of inactive compounds :	447
---------------------------------
Run id: CNNModel_CHEMBL4599_adam_0.001_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4599_adam_0.001_15_32_0.6_True/
---------------------------------
Training samples: 504
Validation samples: 158
--
Training Step: 1  | time: 1.144s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/504
[A[ATraining Step: 2  | total loss: [1m[32m0.62349[0m[0m | time: 2.043s
[2K
| Adam | epoch: 001 | loss: 0.62349 - acc: 0.4781 -- iter: 064/504
[A[ATraining Step: 3  | total loss: [1m[32m0.67881[0m[0m | time: 2.986s
[2K
| Adam | epoch: 001 | loss: 0.67881 - acc: 0.5216 -- iter: 096/504
[A[ATraining Step: 4  | total loss: [1m[32m0.71045[0m[0m | time: 3.876s
[2K
| Adam | epoch: 001 | loss: 0.71045 - acc: 0.4351 -- iter: 128/504
[A[ATraining Step: 5  | total loss: [1m[32m0.70227[0m[0m | time: 4.920s
[2K
| Adam | epoch: 001 | loss: 0.70227 - acc: 0.4368 -- iter: 160/504
[A[ATraining Step: 6  | total loss: [1m[32m0.69607[0m[0m | time: 6.025s
[2K
| Adam | epoch: 001 | loss: 0.69607 - acc: 0.5779 -- iter: 192/504
[A[ATraining Step: 7  | total loss: [1m[32m0.69397[0m[0m | time: 6.856s
[2K
| Adam | epoch: 001 | loss: 0.69397 - acc: 0.5499 -- iter: 224/504
[A[ATraining Step: 8  | total loss: [1m[32m0.69489[0m[0m | time: 7.733s
[2K
| Adam | epoch: 001 | loss: 0.69489 - acc: 0.4691 -- iter: 256/504
[A[ATraining Step: 9  | total loss: [1m[32m0.69364[0m[0m | time: 8.652s
[2K
| Adam | epoch: 001 | loss: 0.69364 - acc: 0.5020 -- iter: 288/504
[A[ATraining Step: 10  | total loss: [1m[32m0.69300[0m[0m | time: 9.571s
[2K
| Adam | epoch: 001 | loss: 0.69300 - acc: 0.5166 -- iter: 320/504
[A[ATraining Step: 11  | total loss: [1m[32m0.69502[0m[0m | time: 10.514s
[2K
| Adam | epoch: 001 | loss: 0.69502 - acc: 0.4495 -- iter: 352/504
[A[ATraining Step: 12  | total loss: [1m[32m0.69461[0m[0m | time: 11.513s
[2K
| Adam | epoch: 001 | loss: 0.69461 - acc: 0.4582 -- iter: 384/504
[A[ATraining Step: 13  | total loss: [1m[32m0.69337[0m[0m | time: 12.475s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.5029 -- iter: 416/504
[A[ATraining Step: 14  | total loss: [1m[32m0.69331[0m[0m | time: 13.289s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.5017 -- iter: 448/504
[A[ATraining Step: 15  | total loss: [1m[32m0.69296[0m[0m | time: 14.244s
[2K
| Adam | epoch: 001 | loss: 0.69296 - acc: 0.5133 -- iter: 480/504
[A[ATraining Step: 16  | total loss: [1m[32m0.69281[0m[0m | time: 16.096s
[2K
| Adam | epoch: 001 | loss: 0.69281 - acc: 0.5200 | val_loss: 0.69075 - val_acc: 0.5759 -- iter: 504/504
--
Training Step: 17  | total loss: [1m[32m0.69175[0m[0m | time: 0.710s
[2K
| Adam | epoch: 002 | loss: 0.69175 - acc: 0.5578 -- iter: 032/504
[A[ATraining Step: 18  | total loss: [1m[32m0.69092[0m[0m | time: 1.669s
[2K
| Adam | epoch: 002 | loss: 0.69092 - acc: 0.5811 -- iter: 064/504
[A[ATraining Step: 19  | total loss: [1m[32m0.68959[0m[0m | time: 2.636s
[2K
| Adam | epoch: 002 | loss: 0.68959 - acc: 0.6061 -- iter: 096/504
[A[ATraining Step: 20  | total loss: [1m[32m0.69018[0m[0m | time: 3.554s
[2K
| Adam | epoch: 002 | loss: 0.69018 - acc: 0.5821 -- iter: 128/504
[A[ATraining Step: 21  | total loss: [1m[32m0.69277[0m[0m | time: 4.425s
[2K
| Adam | epoch: 002 | loss: 0.69277 - acc: 0.5372 -- iter: 160/504
[A[ATraining Step: 22  | total loss: [1m[32m0.69468[0m[0m | time: 5.425s
[2K
| Adam | epoch: 002 | loss: 0.69468 - acc: 0.5073 -- iter: 192/504
[A[ATraining Step: 23  | total loss: [1m[32m0.69788[0m[0m | time: 6.443s
[2K
| Adam | epoch: 002 | loss: 0.69788 - acc: 0.4598 -- iter: 224/504
[A[ATraining Step: 24  | total loss: [1m[32m0.69558[0m[0m | time: 7.448s
[2K
| Adam | epoch: 002 | loss: 0.69558 - acc: 0.4887 -- iter: 256/504
[A[ATraining Step: 25  | total loss: [1m[32m0.69235[0m[0m | time: 8.189s
[2K
| Adam | epoch: 002 | loss: 0.69235 - acc: 0.5344 -- iter: 288/504
[A[ATraining Step: 26  | total loss: [1m[32m0.69316[0m[0m | time: 9.116s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5170 -- iter: 320/504
[A[ATraining Step: 27  | total loss: [1m[32m0.69622[0m[0m | time: 10.003s
[2K
| Adam | epoch: 002 | loss: 0.69622 - acc: 0.4644 -- iter: 352/504
[A[ATraining Step: 28  | total loss: [1m[32m0.69689[0m[0m | time: 10.953s
[2K
| Adam | epoch: 002 | loss: 0.69689 - acc: 0.4499 -- iter: 384/504
[A[ATraining Step: 29  | total loss: [1m[32m0.69445[0m[0m | time: 11.879s
[2K
| Adam | epoch: 002 | loss: 0.69445 - acc: 0.4925 -- iter: 416/504
[A[ATraining Step: 30  | total loss: [1m[32m0.69244[0m[0m | time: 12.923s
[2K
| Adam | epoch: 002 | loss: 0.69244 - acc: 0.5313 -- iter: 448/504
[A[ATraining Step: 31  | total loss: [1m[32m0.69231[0m[0m | time: 13.916s
[2K
| Adam | epoch: 002 | loss: 0.69231 - acc: 0.5313 -- iter: 480/504
[A[ATraining Step: 32  | total loss: [1m[32m0.69331[0m[0m | time: 15.830s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.5102 | val_loss: 0.68939 - val_acc: 0.5759 -- iter: 504/504
--
Training Step: 33  | total loss: [1m[32m0.69159[0m[0m | time: 0.661s
[2K
| Adam | epoch: 003 | loss: 0.69159 - acc: 0.5422 -- iter: 032/504
[A[ATraining Step: 34  | total loss: [1m[32m0.69055[0m[0m | time: 1.312s
[2K
| Adam | epoch: 003 | loss: 0.69055 - acc: 0.5600 -- iter: 064/504
[A[ATraining Step: 35  | total loss: [1m[32m0.68971[0m[0m | time: 2.177s
[2K
| Adam | epoch: 003 | loss: 0.68971 - acc: 0.5736 -- iter: 096/504
[A[ATraining Step: 36  | total loss: [1m[32m0.69159[0m[0m | time: 3.079s
[2K
| Adam | epoch: 003 | loss: 0.69159 - acc: 0.5394 -- iter: 128/504
[A[ATraining Step: 37  | total loss: [1m[32m0.69118[0m[0m | time: 3.980s
[2K
| Adam | epoch: 003 | loss: 0.69118 - acc: 0.5440 -- iter: 160/504
[A[ATraining Step: 38  | total loss: [1m[32m0.69243[0m[0m | time: 4.954s
[2K
| Adam | epoch: 003 | loss: 0.69243 - acc: 0.5231 -- iter: 192/504
[A[ATraining Step: 39  | total loss: [1m[32m0.69340[0m[0m | time: 5.937s
[2K
| Adam | epoch: 003 | loss: 0.69340 - acc: 0.5067 -- iter: 224/504
[A[ATraining Step: 40  | total loss: [1m[32m0.69224[0m[0m | time: 6.814s
[2K
| Adam | epoch: 003 | loss: 0.69224 - acc: 0.5231 -- iter: 256/504
[A[ATraining Step: 41  | total loss: [1m[32m0.69365[0m[0m | time: 7.773s
[2K
| Adam | epoch: 003 | loss: 0.69365 - acc: 0.5016 -- iter: 288/504
[A[ATraining Step: 42  | total loss: [1m[32m0.69275[0m[0m | time: 8.832s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5126 -- iter: 320/504
[A[ATraining Step: 43  | total loss: [1m[32m0.69316[0m[0m | time: 9.911s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.5048 -- iter: 352/504
[A[ATraining Step: 44  | total loss: [1m[32m0.69451[0m[0m | time: 10.974s
[2K
| Adam | epoch: 003 | loss: 0.69451 - acc: 0.4824 -- iter: 384/504
[A[ATraining Step: 45  | total loss: [1m[32m0.69317[0m[0m | time: 11.864s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.5013 -- iter: 416/504
[A[ATraining Step: 46  | total loss: [1m[32m0.69209[0m[0m | time: 12.736s
[2K
| Adam | epoch: 003 | loss: 0.69209 - acc: 0.5167 -- iter: 448/504
[A[ATraining Step: 47  | total loss: [1m[32m0.69134[0m[0m | time: 13.636s
[2K
| Adam | epoch: 003 | loss: 0.69134 - acc: 0.5242 -- iter: 480/504
[A[ATraining Step: 48  | total loss: [1m[32m0.69218[0m[0m | time: 15.517s
[2K
| Adam | epoch: 003 | loss: 0.69218 - acc: 0.5103 | val_loss: 0.68330 - val_acc: 0.5759 -- iter: 504/504
--
Training Step: 49  | total loss: [1m[32m0.69056[0m[0m | time: 1.115s
[2K
| Adam | epoch: 004 | loss: 0.69056 - acc: 0.5234 -- iter: 032/504
[A[ATraining Step: 50  | total loss: [1m[32m0.68814[0m[0m | time: 1.879s
[2K
| Adam | epoch: 004 | loss: 0.68814 - acc: 0.5440 -- iter: 064/504
[A[ATraining Step: 51  | total loss: [1m[32m0.68523[0m[0m | time: 2.630s
[2K
| Adam | epoch: 004 | loss: 0.68523 - acc: 0.5628 -- iter: 096/504
[A[ATraining Step: 52  | total loss: [1m[32m0.68126[0m[0m | time: 3.457s
[2K
| Adam | epoch: 004 | loss: 0.68126 - acc: 0.5783 -- iter: 128/504
[A[ATraining Step: 53  | total loss: [1m[32m0.68298[0m[0m | time: 4.405s
[2K
| Adam | epoch: 004 | loss: 0.68298 - acc: 0.5668 -- iter: 160/504
[A[ATraining Step: 54  | total loss: [1m[32m0.68850[0m[0m | time: 5.334s
[2K
| Adam | epoch: 004 | loss: 0.68850 - acc: 0.5435 -- iter: 192/504
[A[ATraining Step: 55  | total loss: [1m[32m0.68384[0m[0m | time: 6.250s
[2K
| Adam | epoch: 004 | loss: 0.68384 - acc: 0.5551 -- iter: 224/504
[A[ATraining Step: 56  | total loss: [1m[32m0.68181[0m[0m | time: 7.236s
[2K
| Adam | epoch: 004 | loss: 0.68181 - acc: 0.5518 -- iter: 256/504
[A[ATraining Step: 57  | total loss: [1m[32m0.67764[0m[0m | time: 8.257s
[2K
| Adam | epoch: 004 | loss: 0.67764 - acc: 0.5489 -- iter: 288/504
[A[ATraining Step: 58  | total loss: [1m[32m0.67919[0m[0m | time: 9.158s
[2K
| Adam | epoch: 004 | loss: 0.67919 - acc: 0.5209 -- iter: 320/504
[A[ATraining Step: 59  | total loss: [1m[32m0.67606[0m[0m | time: 10.104s
[2K
| Adam | epoch: 004 | loss: 0.67606 - acc: 0.5601 -- iter: 352/504
[A[ATraining Step: 60  | total loss: [1m[32m0.67415[0m[0m | time: 11.164s
[2K
| Adam | epoch: 004 | loss: 0.67415 - acc: 0.5687 -- iter: 384/504
[A[ATraining Step: 61  | total loss: [1m[32m0.66454[0m[0m | time: 12.233s
[2K
| Adam | epoch: 004 | loss: 0.66454 - acc: 0.5842 -- iter: 416/504
[A[ATraining Step: 62  | total loss: [1m[32m0.65891[0m[0m | time: 13.026s
[2K
| Adam | epoch: 004 | loss: 0.65891 - acc: 0.5814 -- iter: 448/504
[A[ATraining Step: 63  | total loss: [1m[32m0.64990[0m[0m | time: 13.891s
[2K
| Adam | epoch: 004 | loss: 0.64990 - acc: 0.5949 -- iter: 480/504
[A[ATraining Step: 64  | total loss: [1m[32m0.63690[0m[0m | time: 15.839s
[2K
| Adam | epoch: 004 | loss: 0.63690 - acc: 0.6025 | val_loss: 0.62775 - val_acc: 0.6329 -- iter: 504/504
--
Training Step: 65  | total loss: [1m[32m0.62960[0m[0m | time: 1.050s
[2K
| Adam | epoch: 005 | loss: 0.62960 - acc: 0.6169 -- iter: 032/504
[A[ATraining Step: 66  | total loss: [1m[32m0.62760[0m[0m | time: 2.113s
[2K
| Adam | epoch: 005 | loss: 0.62760 - acc: 0.6331 -- iter: 064/504
[A[ATraining Step: 67  | total loss: [1m[32m0.62097[0m[0m | time: 2.771s
[2K
| Adam | epoch: 005 | loss: 0.62097 - acc: 0.6433 -- iter: 096/504
[A[ATraining Step: 68  | total loss: [1m[32m0.62245[0m[0m | time: 3.412s
[2K
| Adam | epoch: 005 | loss: 0.62245 - acc: 0.6461 -- iter: 128/504
[A[ATraining Step: 69  | total loss: [1m[32m0.61256[0m[0m | time: 4.332s
[2K
| Adam | epoch: 005 | loss: 0.61256 - acc: 0.6680 -- iter: 160/504
[A[ATraining Step: 70  | total loss: [1m[32m0.62319[0m[0m | time: 5.301s
[2K
| Adam | epoch: 005 | loss: 0.62319 - acc: 0.6594 -- iter: 192/504
[A[ATraining Step: 71  | total loss: [1m[32m0.60813[0m[0m | time: 6.230s
[2K
| Adam | epoch: 005 | loss: 0.60813 - acc: 0.6769 -- iter: 224/504
[A[ATraining Step: 72  | total loss: [1m[32m0.59184[0m[0m | time: 7.230s
[2K
| Adam | epoch: 005 | loss: 0.59184 - acc: 0.6956 -- iter: 256/504
[A[ATraining Step: 73  | total loss: [1m[32m0.58631[0m[0m | time: 8.220s
[2K
| Adam | epoch: 005 | loss: 0.58631 - acc: 0.6913 -- iter: 288/504
[A[ATraining Step: 74  | total loss: [1m[32m0.56376[0m[0m | time: 9.111s
[2K
| Adam | epoch: 005 | loss: 0.56376 - acc: 0.7046 -- iter: 320/504
[A[ATraining Step: 75  | total loss: [1m[32m0.55788[0m[0m | time: 10.065s
[2K
| Adam | epoch: 005 | loss: 0.55788 - acc: 0.7095 -- iter: 352/504
[A[ATraining Step: 76  | total loss: [1m[32m0.55268[0m[0m | time: 11.101s
[2K
| Adam | epoch: 005 | loss: 0.55268 - acc: 0.7172 -- iter: 384/504
[A[ATraining Step: 77  | total loss: [1m[32m0.53967[0m[0m | time: 12.213s
[2K
| Adam | epoch: 005 | loss: 0.53967 - acc: 0.7273 -- iter: 416/504
[A[ATraining Step: 78  | total loss: [1m[32m0.53495[0m[0m | time: 12.948s
[2K
| Adam | epoch: 005 | loss: 0.53495 - acc: 0.7362 -- iter: 448/504
[A[ATraining Step: 79  | total loss: [1m[32m0.52376[0m[0m | time: 13.770s
[2K
| Adam | epoch: 005 | loss: 0.52376 - acc: 0.7441 -- iter: 480/504
[A[ATraining Step: 80  | total loss: [1m[32m0.51613[0m[0m | time: 15.647s
[2K
| Adam | epoch: 005 | loss: 0.51613 - acc: 0.7479 | val_loss: 0.73169 - val_acc: 0.6646 -- iter: 504/504
--
Training Step: 81  | total loss: [1m[32m0.51005[0m[0m | time: 0.920s
[2K
| Adam | epoch: 006 | loss: 0.51005 - acc: 0.7513 -- iter: 032/504
[A[ATraining Step: 82  | total loss: [1m[32m0.50459[0m[0m | time: 1.848s
[2K
| Adam | epoch: 006 | loss: 0.50459 - acc: 0.7511 -- iter: 064/504
[A[ATraining Step: 83  | total loss: [1m[32m0.51900[0m[0m | time: 2.903s
[2K
| Adam | epoch: 006 | loss: 0.51900 - acc: 0.7416 -- iter: 096/504
[A[ATraining Step: 84  | total loss: [1m[32m0.50377[0m[0m | time: 3.714s
[2K
| Adam | epoch: 006 | loss: 0.50377 - acc: 0.7487 -- iter: 128/504
[A[ATraining Step: 85  | total loss: [1m[32m0.51530[0m[0m | time: 4.386s
[2K
| Adam | epoch: 006 | loss: 0.51530 - acc: 0.7447 -- iter: 160/504
[A[ATraining Step: 86  | total loss: [1m[32m0.52908[0m[0m | time: 5.188s
[2K
| Adam | epoch: 006 | loss: 0.52908 - acc: 0.7327 -- iter: 192/504
[A[ATraining Step: 87  | total loss: [1m[32m0.53090[0m[0m | time: 6.083s
[2K
| Adam | epoch: 006 | loss: 0.53090 - acc: 0.7344 -- iter: 224/504
[A[ATraining Step: 88  | total loss: [1m[32m0.54021[0m[0m | time: 7.011s
[2K
| Adam | epoch: 006 | loss: 0.54021 - acc: 0.7235 -- iter: 256/504
[A[ATraining Step: 89  | total loss: [1m[32m0.52739[0m[0m | time: 7.920s
[2K
| Adam | epoch: 006 | loss: 0.52739 - acc: 0.7355 -- iter: 288/504
[A[ATraining Step: 90  | total loss: [1m[32m0.53455[0m[0m | time: 8.878s
[2K
| Adam | epoch: 006 | loss: 0.53455 - acc: 0.7370 -- iter: 320/504
[A[ATraining Step: 91  | total loss: [1m[32m0.51717[0m[0m | time: 9.889s
[2K
| Adam | epoch: 006 | loss: 0.51717 - acc: 0.7539 -- iter: 352/504
[A[ATraining Step: 92  | total loss: [1m[32m0.50269[0m[0m | time: 10.735s
[2K
| Adam | epoch: 006 | loss: 0.50269 - acc: 0.7629 -- iter: 384/504
[A[ATraining Step: 93  | total loss: [1m[32m0.49637[0m[0m | time: 11.598s
[2K
| Adam | epoch: 006 | loss: 0.49637 - acc: 0.7741 -- iter: 416/504
[A[ATraining Step: 94  | total loss: [1m[32m0.48528[0m[0m | time: 12.638s
[2K
| Adam | epoch: 006 | loss: 0.48528 - acc: 0.7842 -- iter: 448/504
[A[ATraining Step: 95  | total loss: [1m[32m0.47224[0m[0m | time: 13.646s
[2K
| Adam | epoch: 006 | loss: 0.47224 - acc: 0.7933 -- iter: 480/504
[A[ATraining Step: 96  | total loss: [1m[32m0.45309[0m[0m | time: 15.545s
[2K
| Adam | epoch: 006 | loss: 0.45309 - acc: 0.8108 | val_loss: 0.35795 - val_acc: 0.8734 -- iter: 504/504
--
Training Step: 97  | total loss: [1m[32m0.44191[0m[0m | time: 0.968s
[2K
| Adam | epoch: 007 | loss: 0.44191 - acc: 0.8235 -- iter: 032/504
[A[ATraining Step: 98  | total loss: [1m[32m0.43723[0m[0m | time: 1.968s
[2K
| Adam | epoch: 007 | loss: 0.43723 - acc: 0.8255 -- iter: 064/504
[A[ATraining Step: 99  | total loss: [1m[32m0.43032[0m[0m | time: 2.875s
[2K
| Adam | epoch: 007 | loss: 0.43032 - acc: 0.8242 -- iter: 096/504
[A[ATraining Step: 100  | total loss: [1m[32m0.42637[0m[0m | time: 3.681s
[2K
| Adam | epoch: 007 | loss: 0.42637 - acc: 0.8293 -- iter: 128/504
[A[ATraining Step: 101  | total loss: [1m[32m0.42017[0m[0m | time: 4.511s
[2K
| Adam | epoch: 007 | loss: 0.42017 - acc: 0.8339 -- iter: 160/504
[A[ATraining Step: 102  | total loss: [1m[32m0.40429[0m[0m | time: 5.368s
[2K
| Adam | epoch: 007 | loss: 0.40429 - acc: 0.8380 -- iter: 192/504
[A[ATraining Step: 103  | total loss: [1m[32m0.39426[0m[0m | time: 6.395s
[2K
| Adam | epoch: 007 | loss: 0.39426 - acc: 0.8417 -- iter: 224/504
[A[ATraining Step: 104  | total loss: [1m[32m0.39976[0m[0m | time: 7.165s
[2K
| Adam | epoch: 007 | loss: 0.39976 - acc: 0.8388 -- iter: 256/504
[A[ATraining Step: 105  | total loss: [1m[32m0.38971[0m[0m | time: 8.095s
[2K
| Adam | epoch: 007 | loss: 0.38971 - acc: 0.8455 -- iter: 288/504
[A[ATraining Step: 106  | total loss: [1m[32m0.37559[0m[0m | time: 9.072s
[2K
| Adam | epoch: 007 | loss: 0.37559 - acc: 0.8547 -- iter: 320/504
[A[ATraining Step: 107  | total loss: [1m[32m0.36813[0m[0m | time: 9.956s
[2K
| Adam | epoch: 007 | loss: 0.36813 - acc: 0.8567 -- iter: 352/504
[A[ATraining Step: 108  | total loss: [1m[32m0.35837[0m[0m | time: 10.863s
[2K
| Adam | epoch: 007 | loss: 0.35837 - acc: 0.8648 -- iter: 384/504
[A[ATraining Step: 109  | total loss: [1m[32m0.34955[0m[0m | time: 11.847s
[2K
| Adam | epoch: 007 | loss: 0.34955 - acc: 0.8627 -- iter: 416/504
[A[ATraining Step: 110  | total loss: [1m[32m0.33398[0m[0m | time: 12.785s
[2K
| Adam | epoch: 007 | loss: 0.33398 - acc: 0.8702 -- iter: 448/504
[A[ATraining Step: 111  | total loss: [1m[32m0.33851[0m[0m | time: 13.579s
[2K
| Adam | epoch: 007 | loss: 0.33851 - acc: 0.8707 -- iter: 480/504
[A[ATraining Step: 112  | total loss: [1m[32m0.33453[0m[0m | time: 15.647s
[2K
| Adam | epoch: 007 | loss: 0.33453 - acc: 0.8742 | val_loss: 0.29015 - val_acc: 0.8861 -- iter: 504/504
--
Training Step: 113  | total loss: [1m[32m0.32677[0m[0m | time: 0.938s
[2K
| Adam | epoch: 008 | loss: 0.32677 - acc: 0.8743 -- iter: 032/504
[A[ATraining Step: 114  | total loss: [1m[32m0.32250[0m[0m | time: 1.874s
[2K
| Adam | epoch: 008 | loss: 0.32250 - acc: 0.8806 -- iter: 064/504
[A[ATraining Step: 115  | total loss: [1m[32m0.30954[0m[0m | time: 2.853s
[2K
| Adam | epoch: 008 | loss: 0.30954 - acc: 0.8832 -- iter: 096/504
[A[ATraining Step: 116  | total loss: [1m[32m0.31291[0m[0m | time: 3.916s
[2K
| Adam | epoch: 008 | loss: 0.31291 - acc: 0.8761 -- iter: 128/504
[A[ATraining Step: 117  | total loss: [1m[32m0.30510[0m[0m | time: 4.803s
[2K
| Adam | epoch: 008 | loss: 0.30510 - acc: 0.8791 -- iter: 160/504
[A[ATraining Step: 118  | total loss: [1m[32m0.31228[0m[0m | time: 5.513s
[2K
| Adam | epoch: 008 | loss: 0.31228 - acc: 0.8756 -- iter: 192/504
[A[ATraining Step: 119  | total loss: [1m[32m0.29483[0m[0m | time: 6.310s
[2K
| Adam | epoch: 008 | loss: 0.29483 - acc: 0.8839 -- iter: 224/504
[A[ATraining Step: 120  | total loss: [1m[32m0.27752[0m[0m | time: 7.362s
[2K
| Adam | epoch: 008 | loss: 0.27752 - acc: 0.8955 -- iter: 256/504
[A[ATraining Step: 121  | total loss: [1m[32m0.27837[0m[0m | time: 8.286s
[2K
| Adam | epoch: 008 | loss: 0.27837 - acc: 0.8966 -- iter: 288/504
[A[ATraining Step: 122  | total loss: [1m[32m0.26845[0m[0m | time: 9.138s
[2K
| Adam | epoch: 008 | loss: 0.26845 - acc: 0.9038 -- iter: 320/504
[A[ATraining Step: 123  | total loss: [1m[32m0.25309[0m[0m | time: 10.058s
[2K
| Adam | epoch: 008 | loss: 0.25309 - acc: 0.9134 -- iter: 352/504
[A[ATraining Step: 124  | total loss: [1m[32m0.28647[0m[0m | time: 10.970s
[2K
| Adam | epoch: 008 | loss: 0.28647 - acc: 0.8971 -- iter: 384/504
[A[ATraining Step: 125  | total loss: [1m[32m0.29006[0m[0m | time: 11.875s
[2K
| Adam | epoch: 008 | loss: 0.29006 - acc: 0.8949 -- iter: 416/504
[A[ATraining Step: 126  | total loss: [1m[32m0.27609[0m[0m | time: 12.910s
[2K
| Adam | epoch: 008 | loss: 0.27609 - acc: 0.8991 -- iter: 448/504
[A[ATraining Step: 127  | total loss: [1m[32m0.28621[0m[0m | time: 13.911s
[2K
| Adam | epoch: 008 | loss: 0.28621 - acc: 0.8936 -- iter: 480/504
[A[ATraining Step: 128  | total loss: [1m[32m0.26732[0m[0m | time: 15.791s
[2K
| Adam | epoch: 008 | loss: 0.26732 - acc: 0.9011 | val_loss: 0.24598 - val_acc: 0.8987 -- iter: 504/504
--
Training Step: 129  | total loss: [1m[32m0.26007[0m[0m | time: 0.906s
[2K
| Adam | epoch: 009 | loss: 0.26007 - acc: 0.9016 -- iter: 032/504
[A[ATraining Step: 130  | total loss: [1m[32m0.24867[0m[0m | time: 1.811s
[2K
| Adam | epoch: 009 | loss: 0.24867 - acc: 0.9083 -- iter: 064/504
[A[ATraining Step: 131  | total loss: [1m[32m0.24258[0m[0m | time: 2.696s
[2K
| Adam | epoch: 009 | loss: 0.24258 - acc: 0.9112 -- iter: 096/504
[A[ATraining Step: 132  | total loss: [1m[32m0.23525[0m[0m | time: 3.613s
[2K
| Adam | epoch: 009 | loss: 0.23525 - acc: 0.9139 -- iter: 128/504
[A[ATraining Step: 133  | total loss: [1m[32m0.25501[0m[0m | time: 4.639s
[2K
| Adam | epoch: 009 | loss: 0.25501 - acc: 0.9037 -- iter: 160/504
[A[ATraining Step: 134  | total loss: [1m[32m0.25042[0m[0m | time: 5.598s
[2K
| Adam | epoch: 009 | loss: 0.25042 - acc: 0.9071 -- iter: 192/504
[A[ATraining Step: 135  | total loss: [1m[32m0.24760[0m[0m | time: 6.203s
[2K
| Adam | epoch: 009 | loss: 0.24760 - acc: 0.9039 -- iter: 224/504
[A[ATraining Step: 136  | total loss: [1m[32m0.23107[0m[0m | time: 6.965s
[2K
| Adam | epoch: 009 | loss: 0.23107 - acc: 0.9135 -- iter: 256/504
[A[ATraining Step: 137  | total loss: [1m[32m0.21598[0m[0m | time: 8.015s
[2K
| Adam | epoch: 009 | loss: 0.21598 - acc: 0.9222 -- iter: 288/504
[A[ATraining Step: 138  | total loss: [1m[32m0.23737[0m[0m | time: 9.090s
[2K
| Adam | epoch: 009 | loss: 0.23737 - acc: 0.9206 -- iter: 320/504
[A[ATraining Step: 139  | total loss: [1m[32m0.23972[0m[0m | time: 9.846s
[2K
| Adam | epoch: 009 | loss: 0.23972 - acc: 0.9129 -- iter: 352/504
[A[ATraining Step: 140  | total loss: [1m[32m0.23249[0m[0m | time: 10.747s
[2K
| Adam | epoch: 009 | loss: 0.23249 - acc: 0.9185 -- iter: 384/504
[A[ATraining Step: 141  | total loss: [1m[32m0.22998[0m[0m | time: 11.641s
[2K
| Adam | epoch: 009 | loss: 0.22998 - acc: 0.9172 -- iter: 416/504
[A[ATraining Step: 142  | total loss: [1m[32m0.22015[0m[0m | time: 12.547s
[2K
| Adam | epoch: 009 | loss: 0.22015 - acc: 0.9193 -- iter: 448/504
[A[ATraining Step: 143  | total loss: [1m[32m0.21527[0m[0m | time: 13.531s
[2K
| Adam | epoch: 009 | loss: 0.21527 - acc: 0.9211 -- iter: 480/504
[A[ATraining Step: 144  | total loss: [1m[32m0.20675[0m[0m | time: 15.527s
[2K
| Adam | epoch: 009 | loss: 0.20675 - acc: 0.9259 | val_loss: 0.31824 - val_acc: 0.8671 -- iter: 504/504
--
Training Step: 145  | total loss: [1m[32m0.20128[0m[0m | time: 1.072s
[2K
| Adam | epoch: 010 | loss: 0.20128 - acc: 0.9302 -- iter: 032/504
[A[ATraining Step: 146  | total loss: [1m[32m0.20174[0m[0m | time: 2.088s
[2K
| Adam | epoch: 010 | loss: 0.20174 - acc: 0.9309 -- iter: 064/504
[A[ATraining Step: 147  | total loss: [1m[32m0.18471[0m[0m | time: 2.894s
[2K
| Adam | epoch: 010 | loss: 0.18471 - acc: 0.9378 -- iter: 096/504
[A[ATraining Step: 148  | total loss: [1m[32m0.18164[0m[0m | time: 3.834s
[2K
| Adam | epoch: 010 | loss: 0.18164 - acc: 0.9378 -- iter: 128/504
[A[ATraining Step: 149  | total loss: [1m[32m0.19953[0m[0m | time: 4.757s
[2K
| Adam | epoch: 010 | loss: 0.19953 - acc: 0.9346 -- iter: 160/504
[A[ATraining Step: 150  | total loss: [1m[32m0.19419[0m[0m | time: 5.676s
[2K
| Adam | epoch: 010 | loss: 0.19419 - acc: 0.9380 -- iter: 192/504
[A[ATraining Step: 151  | total loss: [1m[32m0.17888[0m[0m | time: 6.661s
[2K
| Adam | epoch: 010 | loss: 0.17888 - acc: 0.9442 -- iter: 224/504
[A[ATraining Step: 152  | total loss: [1m[32m0.19057[0m[0m | time: 7.377s
[2K
| Adam | epoch: 010 | loss: 0.19057 - acc: 0.9404 -- iter: 256/504
[A[ATraining Step: 153  | total loss: [1m[32m0.18248[0m[0m | time: 8.146s
[2K
| Adam | epoch: 010 | loss: 0.18248 - acc: 0.9422 -- iter: 288/504
[A[ATraining Step: 154  | total loss: [1m[32m0.17441[0m[0m | time: 8.981s
[2K
| Adam | epoch: 010 | loss: 0.17441 - acc: 0.9438 -- iter: 320/504
[A[ATraining Step: 155  | total loss: [1m[32m0.17731[0m[0m | time: 9.996s
[2K
| Adam | epoch: 010 | loss: 0.17731 - acc: 0.9401 -- iter: 352/504
[A[ATraining Step: 156  | total loss: [1m[32m0.18082[0m[0m | time: 11.032s
[2K
| Adam | epoch: 010 | loss: 0.18082 - acc: 0.9367 -- iter: 384/504
[A[ATraining Step: 157  | total loss: [1m[32m0.17717[0m[0m | time: 12.102s
[2K
| Adam | epoch: 010 | loss: 0.17717 - acc: 0.9368 -- iter: 416/504
[A[ATraining Step: 158  | total loss: [1m[32m0.18241[0m[0m | time: 12.823s
[2K
| Adam | epoch: 010 | loss: 0.18241 - acc: 0.9337 -- iter: 448/504
[A[ATraining Step: 159  | total loss: [1m[32m0.17366[0m[0m | time: 13.664s
[2K
| Adam | epoch: 010 | loss: 0.17366 - acc: 0.9372 -- iter: 480/504
[A[ATraining Step: 160  | total loss: [1m[32m0.16105[0m[0m | time: 15.596s
[2K
| Adam | epoch: 010 | loss: 0.16105 - acc: 0.9435 | val_loss: 0.23957 - val_acc: 0.8924 -- iter: 504/504
--
Training Step: 161  | total loss: [1m[32m0.15827[0m[0m | time: 0.934s
[2K
| Adam | epoch: 011 | loss: 0.15827 - acc: 0.9460 -- iter: 032/504
[A[ATraining Step: 162  | total loss: [1m[32m0.14981[0m[0m | time: 1.769s
[2K
| Adam | epoch: 011 | loss: 0.14981 - acc: 0.9483 -- iter: 064/504
[A[ATraining Step: 163  | total loss: [1m[32m0.14219[0m[0m | time: 2.815s
[2K
| Adam | epoch: 011 | loss: 0.14219 - acc: 0.9503 -- iter: 096/504
[A[ATraining Step: 164  | total loss: [1m[32m0.14625[0m[0m | time: 3.818s
[2K
| Adam | epoch: 011 | loss: 0.14625 - acc: 0.9459 -- iter: 128/504
[A[ATraining Step: 165  | total loss: [1m[32m0.14276[0m[0m | time: 4.701s
[2K
| Adam | epoch: 011 | loss: 0.14276 - acc: 0.9451 -- iter: 160/504
[A[ATraining Step: 166  | total loss: [1m[32m0.15311[0m[0m | time: 5.505s
[2K
| Adam | epoch: 011 | loss: 0.15311 - acc: 0.9412 -- iter: 192/504
[A[ATraining Step: 167  | total loss: [1m[32m0.14791[0m[0m | time: 6.380s
[2K
| Adam | epoch: 011 | loss: 0.14791 - acc: 0.9408 -- iter: 224/504
[A[ATraining Step: 168  | total loss: [1m[32m0.13851[0m[0m | time: 7.293s
[2K
| Adam | epoch: 011 | loss: 0.13851 - acc: 0.9468 -- iter: 256/504
[A[ATraining Step: 169  | total loss: [1m[32m0.14569[0m[0m | time: 8.026s
[2K
| Adam | epoch: 011 | loss: 0.14569 - acc: 0.9427 -- iter: 288/504
[A[ATraining Step: 170  | total loss: [1m[32m0.13667[0m[0m | time: 8.750s
[2K
| Adam | epoch: 011 | loss: 0.13667 - acc: 0.9484 -- iter: 320/504
[A[ATraining Step: 171  | total loss: [1m[32m0.13183[0m[0m | time: 9.766s
[2K
| Adam | epoch: 011 | loss: 0.13183 - acc: 0.9453 -- iter: 352/504
[A[ATraining Step: 172  | total loss: [1m[32m0.12740[0m[0m | time: 10.731s
[2K
| Adam | epoch: 011 | loss: 0.12740 - acc: 0.9476 -- iter: 384/504
[A[ATraining Step: 173  | total loss: [1m[32m0.11595[0m[0m | time: 11.644s
[2K
| Adam | epoch: 011 | loss: 0.11595 - acc: 0.9528 -- iter: 416/504
[A[ATraining Step: 174  | total loss: [1m[32m0.10733[0m[0m | time: 12.606s
[2K
| Adam | epoch: 011 | loss: 0.10733 - acc: 0.9576 -- iter: 448/504
[A[ATraining Step: 175  | total loss: [1m[32m0.11348[0m[0m | time: 13.688s
[2K
| Adam | epoch: 011 | loss: 0.11348 - acc: 0.9556 -- iter: 480/504
[A[ATraining Step: 176  | total loss: [1m[32m0.10957[0m[0m | time: 15.705s
[2K
| Adam | epoch: 011 | loss: 0.10957 - acc: 0.9569 | val_loss: 0.20995 - val_acc: 0.9114 -- iter: 504/504
--
Training Step: 177  | total loss: [1m[32m0.11146[0m[0m | time: 0.930s
[2K
| Adam | epoch: 012 | loss: 0.11146 - acc: 0.9581 -- iter: 032/504
[A[ATraining Step: 178  | total loss: [1m[32m0.10216[0m[0m | time: 1.904s
[2K
| Adam | epoch: 012 | loss: 0.10216 - acc: 0.9623 -- iter: 064/504
[A[ATraining Step: 179  | total loss: [1m[32m0.11640[0m[0m | time: 2.951s
[2K
| Adam | epoch: 012 | loss: 0.11640 - acc: 0.9567 -- iter: 096/504
[A[ATraining Step: 180  | total loss: [1m[32m0.11326[0m[0m | time: 3.829s
[2K
| Adam | epoch: 012 | loss: 0.11326 - acc: 0.9579 -- iter: 128/504
[A[ATraining Step: 181  | total loss: [1m[32m0.10409[0m[0m | time: 4.757s
[2K
| Adam | epoch: 012 | loss: 0.10409 - acc: 0.9621 -- iter: 160/504
[A[ATraining Step: 182  | total loss: [1m[32m0.09776[0m[0m | time: 5.778s
[2K
| Adam | epoch: 012 | loss: 0.09776 - acc: 0.9659 -- iter: 192/504
[A[ATraining Step: 183  | total loss: [1m[32m0.09105[0m[0m | time: 6.769s
[2K
| Adam | epoch: 012 | loss: 0.09105 - acc: 0.9693 -- iter: 224/504
[A[ATraining Step: 184  | total loss: [1m[32m0.09198[0m[0m | time: 7.575s
[2K
| Adam | epoch: 012 | loss: 0.09198 - acc: 0.9692 -- iter: 256/504
[A[ATraining Step: 185  | total loss: [1m[32m0.08982[0m[0m | time: 8.425s
[2K
| Adam | epoch: 012 | loss: 0.08982 - acc: 0.9692 -- iter: 288/504
[A[ATraining Step: 186  | total loss: [1m[32m0.08285[0m[0m | time: 9.113s
[2K
| Adam | epoch: 012 | loss: 0.08285 - acc: 0.9723 -- iter: 320/504
[A[ATraining Step: 187  | total loss: [1m[32m0.11795[0m[0m | time: 9.828s
[2K
| Adam | epoch: 012 | loss: 0.11795 - acc: 0.9667 -- iter: 352/504
[A[ATraining Step: 188  | total loss: [1m[32m0.13900[0m[0m | time: 10.729s
[2K
| Adam | epoch: 012 | loss: 0.13900 - acc: 0.9617 -- iter: 384/504
[A[ATraining Step: 189  | total loss: [1m[32m0.15156[0m[0m | time: 11.754s
[2K
| Adam | epoch: 012 | loss: 0.15156 - acc: 0.9499 -- iter: 416/504
[A[ATraining Step: 190  | total loss: [1m[32m0.15378[0m[0m | time: 12.757s
[2K
| Adam | epoch: 012 | loss: 0.15378 - acc: 0.9455 -- iter: 448/504
[A[ATraining Step: 191  | total loss: [1m[32m0.14046[0m[0m | time: 13.648s
[2K
| Adam | epoch: 012 | loss: 0.14046 - acc: 0.9510 -- iter: 480/504
[A[ATraining Step: 192  | total loss: [1m[32m0.17037[0m[0m | time: 15.602s
[2K
| Adam | epoch: 012 | loss: 0.17037 - acc: 0.9309 | val_loss: 0.24218 - val_acc: 0.8987 -- iter: 504/504
--
Training Step: 193  | total loss: [1m[32m0.17864[0m[0m | time: 0.838s
[2K
| Adam | epoch: 013 | loss: 0.17864 - acc: 0.9222 -- iter: 032/504
[A[ATraining Step: 194  | total loss: [1m[32m0.17055[0m[0m | time: 1.697s
[2K
| Adam | epoch: 013 | loss: 0.17055 - acc: 0.9268 -- iter: 064/504
[A[ATraining Step: 195  | total loss: [1m[32m0.16029[0m[0m | time: 2.573s
[2K
| Adam | epoch: 013 | loss: 0.16029 - acc: 0.9310 -- iter: 096/504
[A[ATraining Step: 196  | total loss: [1m[32m0.16876[0m[0m | time: 3.442s
[2K
| Adam | epoch: 013 | loss: 0.16876 - acc: 0.9254 -- iter: 128/504
[A[ATraining Step: 197  | total loss: [1m[32m0.16028[0m[0m | time: 4.338s
[2K
| Adam | epoch: 013 | loss: 0.16028 - acc: 0.9298 -- iter: 160/504
[A[ATraining Step: 198  | total loss: [1m[32m0.15183[0m[0m | time: 5.331s
[2K
| Adam | epoch: 013 | loss: 0.15183 - acc: 0.9337 -- iter: 192/504
[A[ATraining Step: 199  | total loss: [1m[32m0.14061[0m[0m | time: 6.246s
[2K
| Adam | epoch: 013 | loss: 0.14061 - acc: 0.9403 -- iter: 224/504
[A[ATraining Step: 200  | total loss: [1m[32m0.15437[0m[0m | time: 8.170s
[2K
| Adam | epoch: 013 | loss: 0.15437 - acc: 0.9338 | val_loss: 0.19035 - val_acc: 0.9241 -- iter: 256/504
--
Training Step: 201  | total loss: [1m[32m0.15748[0m[0m | time: 9.128s
[2K
| Adam | epoch: 013 | loss: 0.15748 - acc: 0.9279 -- iter: 288/504
[A[ATraining Step: 202  | total loss: [1m[32m0.14476[0m[0m | time: 9.942s
[2K
| Adam | epoch: 013 | loss: 0.14476 - acc: 0.9351 -- iter: 320/504
[A[ATraining Step: 203  | total loss: [1m[32m0.13528[0m[0m | time: 10.603s
[2K
| Adam | epoch: 013 | loss: 0.13528 - acc: 0.9416 -- iter: 352/504
[A[ATraining Step: 204  | total loss: [1m[32m0.13123[0m[0m | time: 11.317s
[2K
| Adam | epoch: 013 | loss: 0.13123 - acc: 0.9433 -- iter: 384/504
[A[ATraining Step: 205  | total loss: [1m[32m0.12482[0m[0m | time: 12.200s
[2K
| Adam | epoch: 013 | loss: 0.12482 - acc: 0.9448 -- iter: 416/504
[A[ATraining Step: 206  | total loss: [1m[32m0.14559[0m[0m | time: 13.115s
[2K
| Adam | epoch: 013 | loss: 0.14559 - acc: 0.9440 -- iter: 448/504
[A[ATraining Step: 207  | total loss: [1m[32m0.13410[0m[0m | time: 14.168s
[2K
| Adam | epoch: 013 | loss: 0.13410 - acc: 0.9496 -- iter: 480/504
[A[ATraining Step: 208  | total loss: [1m[32m0.12320[0m[0m | time: 16.134s
[2K
| Adam | epoch: 013 | loss: 0.12320 - acc: 0.9547 | val_loss: 0.25800 - val_acc: 0.9304 -- iter: 504/504
--
Training Step: 209  | total loss: [1m[32m0.11720[0m[0m | time: 0.749s
[2K
| Adam | epoch: 014 | loss: 0.11720 - acc: 0.9561 -- iter: 032/504
[A[ATraining Step: 210  | total loss: [1m[32m0.11210[0m[0m | time: 1.630s
[2K
| Adam | epoch: 014 | loss: 0.11210 - acc: 0.9573 -- iter: 064/504
[A[ATraining Step: 211  | total loss: [1m[32m0.10209[0m[0m | time: 2.511s
[2K
| Adam | epoch: 014 | loss: 0.10209 - acc: 0.9616 -- iter: 096/504
[A[ATraining Step: 212  | total loss: [1m[32m0.09358[0m[0m | time: 3.435s
[2K
| Adam | epoch: 014 | loss: 0.09358 - acc: 0.9655 -- iter: 128/504
[A[ATraining Step: 213  | total loss: [1m[32m0.08494[0m[0m | time: 4.340s
[2K
| Adam | epoch: 014 | loss: 0.08494 - acc: 0.9689 -- iter: 160/504
[A[ATraining Step: 214  | total loss: [1m[32m0.07869[0m[0m | time: 5.361s
[2K
| Adam | epoch: 014 | loss: 0.07869 - acc: 0.9720 -- iter: 192/504
[A[ATraining Step: 215  | total loss: [1m[32m0.07518[0m[0m | time: 6.352s
[2K
| Adam | epoch: 014 | loss: 0.07518 - acc: 0.9748 -- iter: 224/504
[A[ATraining Step: 216  | total loss: [1m[32m0.07525[0m[0m | time: 7.231s
[2K
| Adam | epoch: 014 | loss: 0.07525 - acc: 0.9742 -- iter: 256/504
[A[ATraining Step: 217  | total loss: [1m[32m0.07915[0m[0m | time: 8.641s
[2K
| Adam | epoch: 014 | loss: 0.07915 - acc: 0.9737 -- iter: 288/504
[A[ATraining Step: 218  | total loss: [1m[32m0.07210[0m[0m | time: 9.757s
[2K
| Adam | epoch: 014 | loss: 0.07210 - acc: 0.9763 -- iter: 320/504
[A[ATraining Step: 219  | total loss: [1m[32m0.07345[0m[0m | time: 10.562s
[2K
| Adam | epoch: 014 | loss: 0.07345 - acc: 0.9755 -- iter: 352/504
[A[ATraining Step: 220  | total loss: [1m[32m0.06987[0m[0m | time: 11.176s
[2K
| Adam | epoch: 014 | loss: 0.06987 - acc: 0.9780 -- iter: 384/504
[A[ATraining Step: 221  | total loss: [1m[32m0.06365[0m[0m | time: 11.889s
[2K
| Adam | epoch: 014 | loss: 0.06365 - acc: 0.9802 -- iter: 416/504
[A[ATraining Step: 222  | total loss: [1m[32m0.05809[0m[0m | time: 12.852s
[2K
| Adam | epoch: 014 | loss: 0.05809 - acc: 0.9822 -- iter: 448/504
[A[ATraining Step: 223  | total loss: [1m[32m0.07723[0m[0m | time: 13.803s
[2K
| Adam | epoch: 014 | loss: 0.07723 - acc: 0.9777 -- iter: 480/504
[A[ATraining Step: 224  | total loss: [1m[32m0.07001[0m[0m | time: 15.743s
[2K
| Adam | epoch: 014 | loss: 0.07001 - acc: 0.9799 | val_loss: 0.27787 - val_acc: 0.9051 -- iter: 504/504
--
Training Step: 225  | total loss: [1m[32m0.06393[0m[0m | time: 0.991s
[2K
| Adam | epoch: 015 | loss: 0.06393 - acc: 0.9819 -- iter: 032/504
[A[ATraining Step: 226  | total loss: [1m[32m0.06266[0m[0m | time: 2.014s
[2K
| Adam | epoch: 015 | loss: 0.06266 - acc: 0.9806 -- iter: 064/504
[A[ATraining Step: 227  | total loss: [1m[32m0.05715[0m[0m | time: 3.064s
[2K
| Adam | epoch: 015 | loss: 0.05715 - acc: 0.9826 -- iter: 096/504
[A[ATraining Step: 228  | total loss: [1m[32m0.05295[0m[0m | time: 3.829s
[2K
| Adam | epoch: 015 | loss: 0.05295 - acc: 0.9843 -- iter: 128/504
[A[ATraining Step: 229  | total loss: [1m[32m0.04896[0m[0m | time: 4.672s
[2K
| Adam | epoch: 015 | loss: 0.04896 - acc: 0.9859 -- iter: 160/504
[A[ATraining Step: 230  | total loss: [1m[32m0.06104[0m[0m | time: 5.624s
[2K
| Adam | epoch: 015 | loss: 0.06104 - acc: 0.9842 -- iter: 192/504
[A[ATraining Step: 231  | total loss: [1m[32m0.05638[0m[0m | time: 6.553s
[2K
| Adam | epoch: 015 | loss: 0.05638 - acc: 0.9857 -- iter: 224/504
[A[ATraining Step: 232  | total loss: [1m[32m0.05188[0m[0m | time: 7.444s
[2K
| Adam | epoch: 015 | loss: 0.05188 - acc: 0.9872 -- iter: 256/504
[A[ATraining Step: 233  | total loss: [1m[32m0.04783[0m[0m | time: 8.408s
[2K
| Adam | epoch: 015 | loss: 0.04783 - acc: 0.9885 -- iter: 288/504
[A[ATraining Step: 234  | total loss: [1m[32m0.04380[0m[0m | time: 9.373s
[2K
| Adam | epoch: 015 | loss: 0.04380 - acc: 0.9896 -- iter: 320/504
[A[ATraining Step: 235  | total loss: [1m[32m0.04040[0m[0m | time: 10.280s
[2K
| Adam | epoch: 015 | loss: 0.04040 - acc: 0.9906 -- iter: 352/504
[A[ATraining Step: 236  | total loss: [1m[32m0.03798[0m[0m | time: 11.385s
[2K
| Adam | epoch: 015 | loss: 0.03798 - acc: 0.9916 -- iter: 384/504
[A[ATraining Step: 237  | total loss: [1m[32m0.03666[0m[0m | time: 12.232s
[2K
| Adam | epoch: 015 | loss: 0.03666 - acc: 0.9924 -- iter: 416/504
[A[ATraining Step: 238  | total loss: [1m[32m0.03377[0m[0m | time: 13.041s
[2K
| Adam | epoch: 015 | loss: 0.03377 - acc: 0.9932 -- iter: 448/504
[A[ATraining Step: 239  | total loss: [1m[32m0.03097[0m[0m | time: 13.822s
[2K
| Adam | epoch: 015 | loss: 0.03097 - acc: 0.9939 -- iter: 480/504
[A[ATraining Step: 240  | total loss: [1m[32m0.02810[0m[0m | time: 15.649s
[2K
| Adam | epoch: 015 | loss: 0.02810 - acc: 0.9945 | val_loss: 0.25393 - val_acc: 0.9114 -- iter: 504/504
--
Validation AUC:0.9703132688207315
Validation AUPRC:0.9828079359524375
Test AUC:0.9887550200803213
Test AUPRC:0.990766863045028
BestTestF1Score	0.93	0.86	0.93	0.92	0.95	79	7	68	4	0.25
BestTestMCCScore	0.94	0.88	0.94	0.99	0.89	74	1	74	9	0.94
BestTestAccuracyScore	0.94	0.88	0.94	0.99	0.89	74	1	74	9	0.94
BestValidationF1Score	0.93	0.84	0.92	0.93	0.93	85	6	61	6	0.25
BestValidationMCC	0.93	0.86	0.92	1.0	0.87	79	0	67	12	0.94
BestValidationAccuracy	0.93	0.86	0.92	1.0	0.87	79	0	67	12	0.94
TestPredictions (Threshold:0.94)
CHEMBL3651305,TP,ACT,1.0	CHEMBL3651323,TP,ACT,1.0	CHEMBL502156,TP,ACT,1.0	CHEMBL3655135,TP,ACT,1.0	CHEMBL3651357,TP,ACT,0.9800000190734863	CHEMBL3655277,TP,ACT,1.0	CHEMBL315701,TN,INACT,0.019999999552965164	CHEMBL459220,TP,ACT,1.0	CHEMBL3655165,FN,ACT,0.30000001192092896	CHEMBL3655218,TP,ACT,1.0	CHEMBL2420909,TN,INACT,0.0	CHEMBL1688219,TN,INACT,0.0	CHEMBL550608,TN,INACT,0.0	CHEMBL3639599,TN,INACT,0.0	CHEMBL2325954,TP,ACT,1.0	CHEMBL487055,FN,ACT,0.029999999329447746	CHEMBL3651372,TP,ACT,1.0	CHEMBL3655149,TP,ACT,1.0	CHEMBL3655129,TP,ACT,1.0	CHEMBL592224,TN,INACT,0.0	CHEMBL2325936,TP,ACT,1.0	CHEMBL488646,TN,INACT,0.15000000596046448	CHEMBL104264,TN,INACT,0.0	CHEMBL2087880,TP,ACT,1.0	CHEMBL3426869,TP,ACT,0.9700000286102295	CHEMBL3655155,TP,ACT,1.0	CHEMBL3655201,TP,ACT,1.0	CHEMBL201307,FP,INACT,0.949999988079071	CHEMBL3651349,TP,ACT,1.0	CHEMBL1784649,TN,INACT,0.0	CHEMBL223393,TN,INACT,0.6600000262260437	CHEMBL487526,TN,INACT,0.0	CHEMBL3655195,TP,ACT,1.0	CHEMBL2070409,TN,INACT,0.0	CHEMBL3655255,TP,ACT,1.0	CHEMBL490251,TN,INACT,0.009999999776482582	CHEMBL2087877,TP,ACT,1.0	CHEMBL394490,TP,ACT,1.0	CHEMBL3655196,TP,ACT,1.0	CHEMBL53898,TN,INACT,0.1899999976158142	CHEMBL3680394,TN,INACT,0.0	CHEMBL2385543,TN,INACT,0.0	CHEMBL3426873,TP,ACT,0.9900000095367432	CHEMBL1448,TN,INACT,0.0	CHEMBL132369,TN,INACT,0.0	CHEMBL247880,TP,ACT,0.9800000190734863	CHEMBL114073,TN,INACT,0.0	CHEMBL3217993,TN,INACT,0.07999999821186066	CHEMBL271138,TN,INACT,0.0	CHEMBL2325944,TP,ACT,1.0	CHEMBL592141,TN,INACT,0.0	CHEMBL541445,TN,INACT,0.0	CHEMBL3655110,TP,ACT,1.0	CHEMBL3680484,TN,INACT,0.0	CHEMBL523780,TN,INACT,0.009999999776482582	CHEMBL386051,FN,ACT,0.03999999910593033	CHEMBL2325960,TP,ACT,1.0	CHEMBL3661094,TN,INACT,0.019999999552965164	CHEMBL2325967,TP,ACT,1.0	CHEMBL3665668,TN,INACT,0.0	CHEMBL3421980,TN,INACT,0.0	CHEMBL489430,TN,INACT,0.0	CHEMBL3426860,FN,ACT,0.05999999865889549	CHEMBL600048,TN,INACT,0.0	CHEMBL2392235,TN,INACT,0.0	CHEMBL116012,TN,INACT,0.009999999776482582	CHEMBL3655271,TP,ACT,1.0	CHEMBL2163624,TN,INACT,0.03999999910593033	CHEMBL55360,TN,INACT,0.029999999329447746	CHEMBL78223,TN,INACT,0.0	CHEMBL259850,TN,INACT,0.0	CHEMBL178133,TN,INACT,0.7200000286102295	CHEMBL1222565,TN,INACT,0.4000000059604645	CHEMBL3651368,TP,ACT,1.0	CHEMBL498705,TN,INACT,0.5699999928474426	CHEMBL3655270,TP,ACT,1.0	CHEMBL133477,TN,INACT,0.7799999713897705	CHEMBL3655225,TP,ACT,1.0	CHEMBL462189,FN,ACT,0.6600000262260437	CHEMBL3665665,TN,INACT,0.009999999776482582	CHEMBL3655232,TP,ACT,1.0	CHEMBL264666,TN,INACT,0.0	CHEMBL3102933,TN,INACT,0.0	CHEMBL2087878,TP,ACT,1.0	CHEMBL2087884,TP,ACT,1.0	CHEMBL312078,TN,INACT,0.0	CHEMBL437754,TP,ACT,1.0	CHEMBL2087662,TP,ACT,1.0	CHEMBL3651360,TP,ACT,1.0	CHEMBL2325945,TP,ACT,1.0	CHEMBL247866,FN,ACT,0.8999999761581421	CHEMBL2348180,TN,INACT,0.0	CHEMBL3651307,TP,ACT,1.0	CHEMBL3655156,TP,ACT,1.0	CHEMBL521381,TP,ACT,1.0	CHEMBL1829275,TN,INACT,0.0	CHEMBL1087421,TN,INACT,0.009999999776482582	CHEMBL3651342,TP,ACT,1.0	CHEMBL3651324,TP,ACT,1.0	CHEMBL337454,TN,INACT,0.0	CHEMBL362455,TN,INACT,0.009999999776482582	CHEMBL3655193,TP,ACT,1.0	CHEMBL3651373,TP,ACT,1.0	CHEMBL3655279,TP,ACT,1.0	CHEMBL141238,TN,INACT,0.0	CHEMBL2087657,TP,ACT,1.0	CHEMBL563281,TN,INACT,0.0	CHEMBL1721885,FN,ACT,0.9300000071525574	CHEMBL315546,TN,INACT,0.0	CHEMBL3655170,TP,ACT,1.0	CHEMBL2087667,TP,ACT,1.0	CHEMBL1908397,FN,ACT,0.019999999552965164	CHEMBL3655235,TP,ACT,1.0	CHEMBL3665656,TN,INACT,0.029999999329447746	CHEMBL3545110,TN,INACT,0.009999999776482582	CHEMBL2029520,TN,INACT,0.0	CHEMBL3655164,TP,ACT,1.0	CHEMBL603494,TN,INACT,0.009999999776482582	CHEMBL77732,TN,INACT,0.0	CHEMBL573578,TN,INACT,0.0	CHEMBL269528,TN,INACT,0.0	CHEMBL522760,TN,INACT,0.009999999776482582	CHEMBL3655278,TP,ACT,1.0	CHEMBL1828880,TN,INACT,0.0	CHEMBL3655207,TP,ACT,0.9800000190734863	CHEMBL3655109,TP,ACT,1.0	CHEMBL228862,TN,INACT,0.0	CHEMBL3651333,TP,ACT,1.0	CHEMBL458333,TP,ACT,1.0	CHEMBL2325955,TP,ACT,1.0	CHEMBL245966,TN,INACT,0.0	CHEMBL1929238,TN,INACT,0.27000001072883606	CHEMBL551318,TN,INACT,0.0	CHEMBL1829274,TN,INACT,0.0	CHEMBL2325957,TP,ACT,1.0	CHEMBL247677,TP,ACT,0.9900000095367432	CHEMBL104,TN,INACT,0.009999999776482582	CHEMBL462365,FN,ACT,0.3199999928474426	CHEMBL3655206,TP,ACT,1.0	CHEMBL3651384,TP,ACT,1.0	CHEMBL3651380,TP,ACT,1.0	CHEMBL3651315,TP,ACT,1.0	CHEMBL3421636,TN,INACT,0.07999999821186066	CHEMBL504331,TP,ACT,1.0	CHEMBL3655198,TP,ACT,1.0	CHEMBL1258663,TN,INACT,0.009999999776482582	CHEMBL3651313,TP,ACT,1.0	CHEMBL116211,TN,INACT,0.0	CHEMBL3675452,TN,INACT,0.0	CHEMBL2087653,TP,ACT,1.0	CHEMBL2029514,TN,INACT,0.0	CHEMBL3655153,TP,ACT,1.0	CHEMBL460472,TN,INACT,0.0	CHEMBL3651337,TP,ACT,1.0	CHEMBL261143,TN,INACT,0.009999999776482582	CHEMBL3651335,TP,ACT,1.0	CHEMBL3655181,TP,ACT,0.9800000190734863	CHEMBL3655185,TP,ACT,1.0	

