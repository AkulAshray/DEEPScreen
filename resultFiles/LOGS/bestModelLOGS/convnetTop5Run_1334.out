CNNModel CHEMBL3130 adam 0.0005 30 256 0 0.6 False True
Number of active compounds :	372
Number of inactive compounds :	248
---------------------------------
Run id: CNNModel_CHEMBL3130_adam_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3130_adam_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 372
Validation samples: 117
--
Training Step: 1  | time: 11.626s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/372
[A[ATraining Step: 2  | total loss: [1m[32m0.62286[0m[0m | time: 31.782s
[2K
| Adam | epoch: 001 | loss: 0.62286 - acc: 0.6187 -- iter: 064/372
[A[ATraining Step: 3  | total loss: [1m[32m0.68037[0m[0m | time: 32.977s
[2K
| Adam | epoch: 001 | loss: 0.68037 - acc: 0.5216 -- iter: 096/372
[A[ATraining Step: 4  | total loss: [1m[32m0.68980[0m[0m | time: 34.219s
[2K
| Adam | epoch: 001 | loss: 0.68980 - acc: 0.5288 -- iter: 128/372
[A[ATraining Step: 5  | total loss: [1m[32m0.69601[0m[0m | time: 35.452s
[2K
| Adam | epoch: 001 | loss: 0.69601 - acc: 0.4872 -- iter: 160/372
[A[ATraining Step: 6  | total loss: [1m[32m0.68979[0m[0m | time: 36.981s
[2K
| Adam | epoch: 001 | loss: 0.68979 - acc: 0.5557 -- iter: 192/372
[A[ATraining Step: 7  | total loss: [1m[32m0.68892[0m[0m | time: 38.562s
[2K
| Adam | epoch: 001 | loss: 0.68892 - acc: 0.5598 -- iter: 224/372
[A[ATraining Step: 8  | total loss: [1m[32m0.69202[0m[0m | time: 39.908s
[2K
| Adam | epoch: 001 | loss: 0.69202 - acc: 0.5262 -- iter: 256/372
[A[ATraining Step: 9  | total loss: [1m[32m0.69274[0m[0m | time: 41.456s
[2K
| Adam | epoch: 001 | loss: 0.69274 - acc: 0.5123 -- iter: 288/372
[A[ATraining Step: 10  | total loss: [1m[32m0.69643[0m[0m | time: 43.068s
[2K
| Adam | epoch: 001 | loss: 0.69643 - acc: 0.4905 -- iter: 320/372
[A[ATraining Step: 11  | total loss: [1m[32m0.69079[0m[0m | time: 44.406s
[2K
| Adam | epoch: 001 | loss: 0.69079 - acc: 0.5394 -- iter: 352/372
[A[ATraining Step: 12  | total loss: [1m[32m0.68307[0m[0m | time: 129.599s
[2K
| Adam | epoch: 001 | loss: 0.68307 - acc: 0.6061 | val_loss: 0.68603 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 13  | total loss: [1m[32m0.68169[0m[0m | time: 51.667s
[2K
| Adam | epoch: 002 | loss: 0.68169 - acc: 0.6035 -- iter: 032/372
[A[ATraining Step: 14  | total loss: [1m[32m0.67954[0m[0m | time: 101.976s
[2K
| Adam | epoch: 002 | loss: 0.67954 - acc: 0.6020 -- iter: 064/372
[A[ATraining Step: 15  | total loss: [1m[32m0.67367[0m[0m | time: 103.327s
[2K
| Adam | epoch: 002 | loss: 0.67367 - acc: 0.6110 -- iter: 096/372
[A[ATraining Step: 16  | total loss: [1m[32m0.66653[0m[0m | time: 104.501s
[2K
| Adam | epoch: 002 | loss: 0.66653 - acc: 0.6163 -- iter: 128/372
[A[ATraining Step: 17  | total loss: [1m[32m0.67702[0m[0m | time: 105.830s
[2K
| Adam | epoch: 002 | loss: 0.67702 - acc: 0.6082 -- iter: 160/372
[A[ATraining Step: 18  | total loss: [1m[32m0.68014[0m[0m | time: 107.169s
[2K
| Adam | epoch: 002 | loss: 0.68014 - acc: 0.6032 -- iter: 192/372
[A[ATraining Step: 19  | total loss: [1m[32m0.70093[0m[0m | time: 108.495s
[2K
| Adam | epoch: 002 | loss: 0.70093 - acc: 0.5584 -- iter: 224/372
[A[ATraining Step: 20  | total loss: [1m[32m0.70578[0m[0m | time: 110.175s
[2K
| Adam | epoch: 002 | loss: 0.70578 - acc: 0.5296 -- iter: 256/372
[A[ATraining Step: 21  | total loss: [1m[32m0.70515[0m[0m | time: 111.641s
[2K
| Adam | epoch: 002 | loss: 0.70515 - acc: 0.5107 -- iter: 288/372
[A[ATraining Step: 22  | total loss: [1m[32m0.69842[0m[0m | time: 112.980s
[2K
| Adam | epoch: 002 | loss: 0.69842 - acc: 0.5356 -- iter: 320/372
[A[ATraining Step: 23  | total loss: [1m[32m0.69648[0m[0m | time: 114.367s
[2K
| Adam | epoch: 002 | loss: 0.69648 - acc: 0.5343 -- iter: 352/372
[A[ATraining Step: 24  | total loss: [1m[32m0.69323[0m[0m | time: 117.033s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.5774 | val_loss: 0.69149 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 25  | total loss: [1m[32m0.69235[0m[0m | time: 0.963s
[2K
| Adam | epoch: 003 | loss: 0.69235 - acc: 0.5819 -- iter: 032/372
[A[ATraining Step: 26  | total loss: [1m[32m0.69250[0m[0m | time: 11.455s
[2K
| Adam | epoch: 003 | loss: 0.69250 - acc: 0.5602 -- iter: 064/372
[A[ATraining Step: 27  | total loss: [1m[32m0.69274[0m[0m | time: 33.611s
[2K
| Adam | epoch: 003 | loss: 0.69274 - acc: 0.5447 -- iter: 096/372
[A[ATraining Step: 28  | total loss: [1m[32m0.69244[0m[0m | time: 85.381s
[2K
| Adam | epoch: 003 | loss: 0.69244 - acc: 0.5492 -- iter: 128/372
[A[ATraining Step: 29  | total loss: [1m[32m0.69186[0m[0m | time: 151.682s
[2K
| Adam | epoch: 003 | loss: 0.69186 - acc: 0.5676 -- iter: 160/372
[A[ATraining Step: 30  | total loss: [1m[32m0.69140[0m[0m | time: 176.338s
[2K
| Adam | epoch: 003 | loss: 0.69140 - acc: 0.5812 -- iter: 192/372
[A[ATraining Step: 31  | total loss: [1m[32m0.69161[0m[0m | time: 177.523s
[2K
| Adam | epoch: 003 | loss: 0.69161 - acc: 0.5697 -- iter: 224/372
[A[ATraining Step: 32  | total loss: [1m[32m0.69132[0m[0m | time: 178.811s
[2K
| Adam | epoch: 003 | loss: 0.69132 - acc: 0.5751 -- iter: 256/372
[A[ATraining Step: 33  | total loss: [1m[32m0.69087[0m[0m | time: 180.126s
[2K
| Adam | epoch: 003 | loss: 0.69087 - acc: 0.5860 -- iter: 288/372
[A[ATraining Step: 34  | total loss: [1m[32m0.69044[0m[0m | time: 181.530s
[2K
| Adam | epoch: 003 | loss: 0.69044 - acc: 0.5944 -- iter: 320/372
[A[ATraining Step: 35  | total loss: [1m[32m0.69105[0m[0m | time: 183.069s
[2K
| Adam | epoch: 003 | loss: 0.69105 - acc: 0.5746 -- iter: 352/372
[A[ATraining Step: 36  | total loss: [1m[32m0.69049[0m[0m | time: 185.513s
[2K
| Adam | epoch: 003 | loss: 0.69049 - acc: 0.5849 | val_loss: 0.69077 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 37  | total loss: [1m[32m0.69021[0m[0m | time: 1.468s
[2K
| Adam | epoch: 004 | loss: 0.69021 - acc: 0.5867 -- iter: 032/372
[A[ATraining Step: 38  | total loss: [1m[32m0.68881[0m[0m | time: 2.562s
[2K
| Adam | epoch: 004 | loss: 0.68881 - acc: 0.6125 -- iter: 064/372
[A[ATraining Step: 39  | total loss: [1m[32m0.68824[0m[0m | time: 3.632s
[2K
| Adam | epoch: 004 | loss: 0.68824 - acc: 0.6197 -- iter: 096/372
[A[ATraining Step: 40  | total loss: [1m[32m0.68764[0m[0m | time: 5.043s
[2K
| Adam | epoch: 004 | loss: 0.68764 - acc: 0.6254 -- iter: 128/372
[A[ATraining Step: 41  | total loss: [1m[32m0.68806[0m[0m | time: 6.543s
[2K
| Adam | epoch: 004 | loss: 0.68806 - acc: 0.6138 -- iter: 160/372
[A[ATraining Step: 42  | total loss: [1m[32m0.69019[0m[0m | time: 7.996s
[2K
| Adam | epoch: 004 | loss: 0.69019 - acc: 0.5765 -- iter: 192/372
[A[ATraining Step: 43  | total loss: [1m[32m0.69030[0m[0m | time: 31.770s
[2K
| Adam | epoch: 004 | loss: 0.69030 - acc: 0.5685 -- iter: 224/372
[A[ATraining Step: 44  | total loss: [1m[32m0.68969[0m[0m | time: 58.413s
[2K
| Adam | epoch: 004 | loss: 0.68969 - acc: 0.5729 -- iter: 256/372
[A[ATraining Step: 45  | total loss: [1m[32m0.69176[0m[0m | time: 69.515s
[2K
| Adam | epoch: 004 | loss: 0.69176 - acc: 0.5446 -- iter: 288/372
[A[ATraining Step: 46  | total loss: [1m[32m0.69119[0m[0m | time: 70.936s
[2K
| Adam | epoch: 004 | loss: 0.69119 - acc: 0.5476 -- iter: 320/372
[A[ATraining Step: 47  | total loss: [1m[32m0.69033[0m[0m | time: 72.146s
[2K
| Adam | epoch: 004 | loss: 0.69033 - acc: 0.5551 -- iter: 352/372
[A[ATraining Step: 48  | total loss: [1m[32m0.68725[0m[0m | time: 74.508s
[2K
| Adam | epoch: 004 | loss: 0.68725 - acc: 0.5864 | val_loss: 0.68850 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 49  | total loss: [1m[32m0.68686[0m[0m | time: 1.608s
[2K
| Adam | epoch: 005 | loss: 0.68686 - acc: 0.5876 -- iter: 032/372
[A[ATraining Step: 50  | total loss: [1m[32m0.68532[0m[0m | time: 3.031s
[2K
| Adam | epoch: 005 | loss: 0.68532 - acc: 0.5982 -- iter: 064/372
[A[ATraining Step: 51  | total loss: [1m[32m0.68734[0m[0m | time: 3.892s
[2K
| Adam | epoch: 005 | loss: 0.68734 - acc: 0.5785 -- iter: 096/372
[A[ATraining Step: 52  | total loss: [1m[32m0.68746[0m[0m | time: 4.892s
[2K
| Adam | epoch: 005 | loss: 0.68746 - acc: 0.5742 -- iter: 128/372
[A[ATraining Step: 53  | total loss: [1m[32m0.68778[0m[0m | time: 6.428s
[2K
| Adam | epoch: 005 | loss: 0.68778 - acc: 0.5706 -- iter: 160/372
[A[ATraining Step: 54  | total loss: [1m[32m0.69050[0m[0m | time: 7.915s
[2K
| Adam | epoch: 005 | loss: 0.69050 - acc: 0.5513 -- iter: 192/372
[A[ATraining Step: 55  | total loss: [1m[32m0.69136[0m[0m | time: 9.521s
[2K
| Adam | epoch: 005 | loss: 0.69136 - acc: 0.5440 -- iter: 224/372
[A[ATraining Step: 56  | total loss: [1m[32m0.69062[0m[0m | time: 10.920s
[2K
| Adam | epoch: 005 | loss: 0.69062 - acc: 0.5466 -- iter: 256/372
[A[ATraining Step: 57  | total loss: [1m[32m0.68871[0m[0m | time: 12.309s
[2K
| Adam | epoch: 005 | loss: 0.68871 - acc: 0.5574 -- iter: 288/372
[A[ATraining Step: 58  | total loss: [1m[32m0.68968[0m[0m | time: 13.824s
[2K
| Adam | epoch: 005 | loss: 0.68968 - acc: 0.5496 -- iter: 320/372
[A[ATraining Step: 59  | total loss: [1m[32m0.68928[0m[0m | time: 15.230s
[2K
| Adam | epoch: 005 | loss: 0.68928 - acc: 0.5513 -- iter: 352/372
[A[ATraining Step: 60  | total loss: [1m[32m0.68939[0m[0m | time: 17.435s
[2K
| Adam | epoch: 005 | loss: 0.68939 - acc: 0.5487 | val_loss: 0.68691 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 61  | total loss: [1m[32m0.68820[0m[0m | time: 1.391s
[2K
| Adam | epoch: 006 | loss: 0.68820 - acc: 0.5546 -- iter: 032/372
[A[ATraining Step: 62  | total loss: [1m[32m0.68738[0m[0m | time: 2.849s
[2K
| Adam | epoch: 006 | loss: 0.68738 - acc: 0.5596 -- iter: 064/372
[A[ATraining Step: 63  | total loss: [1m[32m0.68167[0m[0m | time: 4.172s
[2K
| Adam | epoch: 006 | loss: 0.68167 - acc: 0.5877 -- iter: 096/372
[A[ATraining Step: 64  | total loss: [1m[32m0.68123[0m[0m | time: 5.269s
[2K
| Adam | epoch: 006 | loss: 0.68123 - acc: 0.5885 -- iter: 128/372
[A[ATraining Step: 65  | total loss: [1m[32m0.68044[0m[0m | time: 6.357s
[2K
| Adam | epoch: 006 | loss: 0.68044 - acc: 0.5899 -- iter: 160/372
[A[ATraining Step: 66  | total loss: [1m[32m0.67972[0m[0m | time: 7.900s
[2K
| Adam | epoch: 006 | loss: 0.67972 - acc: 0.5911 -- iter: 192/372
[A[ATraining Step: 67  | total loss: [1m[32m0.68721[0m[0m | time: 9.357s
[2K
| Adam | epoch: 006 | loss: 0.68721 - acc: 0.5727 -- iter: 224/372
[A[ATraining Step: 68  | total loss: [1m[32m0.68724[0m[0m | time: 10.662s
[2K
| Adam | epoch: 006 | loss: 0.68724 - acc: 0.5715 -- iter: 256/372
[A[ATraining Step: 69  | total loss: [1m[32m0.68852[0m[0m | time: 14.872s
[2K
| Adam | epoch: 006 | loss: 0.68852 - acc: 0.5668 -- iter: 288/372
[A[ATraining Step: 70  | total loss: [1m[32m0.69259[0m[0m | time: 16.340s
[2K
| Adam | epoch: 006 | loss: 0.69259 - acc: 0.5519 -- iter: 320/372
[A[ATraining Step: 71  | total loss: [1m[32m0.69076[0m[0m | time: 18.408s
[2K
| Adam | epoch: 006 | loss: 0.69076 - acc: 0.5566 -- iter: 352/372
[A[ATraining Step: 72  | total loss: [1m[32m0.69101[0m[0m | time: 23.826s
[2K
| Adam | epoch: 006 | loss: 0.69101 - acc: 0.5538 | val_loss: 0.68684 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 73  | total loss: [1m[32m0.68975[0m[0m | time: 1.435s
[2K
| Adam | epoch: 007 | loss: 0.68975 - acc: 0.5582 -- iter: 032/372
[A[ATraining Step: 74  | total loss: [1m[32m0.69258[0m[0m | time: 2.760s
[2K
| Adam | epoch: 007 | loss: 0.69258 - acc: 0.5415 -- iter: 064/372
[A[ATraining Step: 75  | total loss: [1m[32m0.69010[0m[0m | time: 4.173s
[2K
| Adam | epoch: 007 | loss: 0.69010 - acc: 0.5540 -- iter: 096/372
[A[ATraining Step: 76  | total loss: [1m[32m0.68978[0m[0m | time: 5.576s
[2K
| Adam | epoch: 007 | loss: 0.68978 - acc: 0.5549 -- iter: 128/372
[A[ATraining Step: 77  | total loss: [1m[32m0.68784[0m[0m | time: 6.516s
[2K
| Adam | epoch: 007 | loss: 0.68784 - acc: 0.5656 -- iter: 160/372
[A[ATraining Step: 78  | total loss: [1m[32m0.68633[0m[0m | time: 7.539s
[2K
| Adam | epoch: 007 | loss: 0.68633 - acc: 0.5745 -- iter: 192/372
[A[ATraining Step: 79  | total loss: [1m[32m0.68492[0m[0m | time: 8.869s
[2K
| Adam | epoch: 007 | loss: 0.68492 - acc: 0.5823 -- iter: 224/372
[A[ATraining Step: 80  | total loss: [1m[32m0.68516[0m[0m | time: 9.931s
[2K
| Adam | epoch: 007 | loss: 0.68516 - acc: 0.5802 -- iter: 256/372
[A[ATraining Step: 81  | total loss: [1m[32m0.68763[0m[0m | time: 11.197s
[2K
| Adam | epoch: 007 | loss: 0.68763 - acc: 0.5626 -- iter: 288/372
[A[ATraining Step: 82  | total loss: [1m[32m0.68601[0m[0m | time: 12.551s
[2K
| Adam | epoch: 007 | loss: 0.68601 - acc: 0.5720 -- iter: 320/372
[A[ATraining Step: 83  | total loss: [1m[32m0.68746[0m[0m | time: 13.671s
[2K
| Adam | epoch: 007 | loss: 0.68746 - acc: 0.5617 -- iter: 352/372
[A[ATraining Step: 84  | total loss: [1m[32m0.68539[0m[0m | time: 15.502s
[2K
| Adam | epoch: 007 | loss: 0.68539 - acc: 0.5743 | val_loss: 0.68731 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 85  | total loss: [1m[32m0.68408[0m[0m | time: 1.085s
[2K
| Adam | epoch: 008 | loss: 0.68408 - acc: 0.5825 -- iter: 032/372
[A[ATraining Step: 86  | total loss: [1m[32m0.68629[0m[0m | time: 2.174s
[2K
| Adam | epoch: 008 | loss: 0.68629 - acc: 0.5680 -- iter: 064/372
[A[ATraining Step: 87  | total loss: [1m[32m0.68480[0m[0m | time: 3.346s
[2K
| Adam | epoch: 008 | loss: 0.68480 - acc: 0.5768 -- iter: 096/372
[A[ATraining Step: 88  | total loss: [1m[32m0.68437[0m[0m | time: 4.492s
[2K
| Adam | epoch: 008 | loss: 0.68437 - acc: 0.5785 -- iter: 128/372
[A[ATraining Step: 89  | total loss: [1m[32m0.68234[0m[0m | time: 5.423s
[2K
| Adam | epoch: 008 | loss: 0.68234 - acc: 0.5894 -- iter: 160/372
[A[ATraining Step: 90  | total loss: [1m[32m0.68371[0m[0m | time: 6.239s
[2K
| Adam | epoch: 008 | loss: 0.68371 - acc: 0.5805 -- iter: 192/372
[A[ATraining Step: 91  | total loss: [1m[32m0.68509[0m[0m | time: 7.100s
[2K
| Adam | epoch: 008 | loss: 0.68509 - acc: 0.5724 -- iter: 224/372
[A[ATraining Step: 92  | total loss: [1m[32m0.68642[0m[0m | time: 8.501s
[2K
| Adam | epoch: 008 | loss: 0.68642 - acc: 0.5652 -- iter: 256/372
[A[ATraining Step: 93  | total loss: [1m[32m0.68581[0m[0m | time: 9.620s
[2K
| Adam | epoch: 008 | loss: 0.68581 - acc: 0.5680 -- iter: 288/372
[A[ATraining Step: 94  | total loss: [1m[32m0.68700[0m[0m | time: 10.495s
[2K
| Adam | epoch: 008 | loss: 0.68700 - acc: 0.5612 -- iter: 320/372
[A[ATraining Step: 95  | total loss: [1m[32m0.68863[0m[0m | time: 11.455s
[2K
| Adam | epoch: 008 | loss: 0.68863 - acc: 0.5520 -- iter: 352/372
[A[ATraining Step: 96  | total loss: [1m[32m0.68643[0m[0m | time: 13.489s
[2K
| Adam | epoch: 008 | loss: 0.68643 - acc: 0.5624 | val_loss: 0.68682 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 97  | total loss: [1m[32m0.68696[0m[0m | time: 1.261s
[2K
| Adam | epoch: 009 | loss: 0.68696 - acc: 0.5593 -- iter: 032/372
[A[ATraining Step: 98  | total loss: [1m[32m0.68751[0m[0m | time: 2.359s
[2K
| Adam | epoch: 009 | loss: 0.68751 - acc: 0.5565 -- iter: 064/372
[A[ATraining Step: 99  | total loss: [1m[32m0.68851[0m[0m | time: 3.368s
[2K
| Adam | epoch: 009 | loss: 0.68851 - acc: 0.5508 -- iter: 096/372
[A[ATraining Step: 100  | total loss: [1m[32m0.68504[0m[0m | time: 4.679s
[2K
| Adam | epoch: 009 | loss: 0.68504 - acc: 0.5676 -- iter: 128/372
[A[ATraining Step: 101  | total loss: [1m[32m0.68755[0m[0m | time: 6.379s
[2K
| Adam | epoch: 009 | loss: 0.68755 - acc: 0.5546 -- iter: 160/372
[A[ATraining Step: 102  | total loss: [1m[32m0.68873[0m[0m | time: 7.876s
[2K
| Adam | epoch: 009 | loss: 0.68873 - acc: 0.5492 -- iter: 192/372
[A[ATraining Step: 103  | total loss: [1m[32m0.68833[0m[0m | time: 13.603s
[2K
| Adam | epoch: 009 | loss: 0.68833 - acc: 0.5505 -- iter: 224/372
[A[ATraining Step: 104  | total loss: [1m[32m0.68626[0m[0m | time: 30.320s
[2K
| Adam | epoch: 009 | loss: 0.68626 - acc: 0.5604 -- iter: 256/372
[A[ATraining Step: 105  | total loss: [1m[32m0.68436[0m[0m | time: 31.540s
[2K
| Adam | epoch: 009 | loss: 0.68436 - acc: 0.5694 -- iter: 288/372
[A[ATraining Step: 106  | total loss: [1m[32m0.68513[0m[0m | time: 32.905s
[2K
| Adam | epoch: 009 | loss: 0.68513 - acc: 0.5656 -- iter: 320/372
[A[ATraining Step: 107  | total loss: [1m[32m0.68232[0m[0m | time: 34.316s
[2K
| Adam | epoch: 009 | loss: 0.68232 - acc: 0.5778 -- iter: 352/372
[A[ATraining Step: 108  | total loss: [1m[32m0.68119[0m[0m | time: 36.814s
[2K
| Adam | epoch: 009 | loss: 0.68119 - acc: 0.5825 | val_loss: 0.68661 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 109  | total loss: [1m[32m0.68146[0m[0m | time: 1.601s
[2K
| Adam | epoch: 010 | loss: 0.68146 - acc: 0.5805 -- iter: 032/372
[A[ATraining Step: 110  | total loss: [1m[32m0.68251[0m[0m | time: 3.335s
[2K
| Adam | epoch: 010 | loss: 0.68251 - acc: 0.5756 -- iter: 064/372
[A[ATraining Step: 111  | total loss: [1m[32m0.68264[0m[0m | time: 4.719s
[2K
| Adam | epoch: 010 | loss: 0.68264 - acc: 0.5743 -- iter: 096/372
[A[ATraining Step: 112  | total loss: [1m[32m0.68778[0m[0m | time: 6.352s
[2K
| Adam | epoch: 010 | loss: 0.68778 - acc: 0.5543 -- iter: 128/372
[A[ATraining Step: 113  | total loss: [1m[32m0.68483[0m[0m | time: 7.787s
[2K
| Adam | epoch: 010 | loss: 0.68483 - acc: 0.5645 -- iter: 160/372
[A[ATraining Step: 114  | total loss: [1m[32m0.68405[0m[0m | time: 9.201s
[2K
| Adam | epoch: 010 | loss: 0.68405 - acc: 0.5675 -- iter: 192/372
[A[ATraining Step: 115  | total loss: [1m[32m0.67888[0m[0m | time: 10.597s
[2K
| Adam | epoch: 010 | loss: 0.67888 - acc: 0.5857 -- iter: 224/372
[A[ATraining Step: 116  | total loss: [1m[32m0.68431[0m[0m | time: 11.587s
[2K
| Adam | epoch: 010 | loss: 0.68431 - acc: 0.5678 -- iter: 256/372
[A[ATraining Step: 117  | total loss: [1m[32m0.68313[0m[0m | time: 12.439s
[2K
| Adam | epoch: 010 | loss: 0.68313 - acc: 0.5710 -- iter: 288/372
[A[ATraining Step: 118  | total loss: [1m[32m0.68213[0m[0m | time: 13.811s
[2K
| Adam | epoch: 010 | loss: 0.68213 - acc: 0.5739 -- iter: 320/372
[A[ATraining Step: 119  | total loss: [1m[32m0.68354[0m[0m | time: 15.255s
[2K
| Adam | epoch: 010 | loss: 0.68354 - acc: 0.5696 -- iter: 352/372
[A[ATraining Step: 120  | total loss: [1m[32m0.68575[0m[0m | time: 17.939s
[2K
| Adam | epoch: 010 | loss: 0.68575 - acc: 0.5627 | val_loss: 0.68720 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 121  | total loss: [1m[32m0.67981[0m[0m | time: 1.331s
[2K
| Adam | epoch: 011 | loss: 0.67981 - acc: 0.5814 -- iter: 032/372
[A[ATraining Step: 122  | total loss: [1m[32m0.67834[0m[0m | time: 2.802s
[2K
| Adam | epoch: 011 | loss: 0.67834 - acc: 0.5858 -- iter: 064/372
[A[ATraining Step: 123  | total loss: [1m[32m0.68236[0m[0m | time: 4.135s
[2K
| Adam | epoch: 011 | loss: 0.68236 - acc: 0.5741 -- iter: 096/372
[A[ATraining Step: 124  | total loss: [1m[32m0.68489[0m[0m | time: 5.661s
[2K
| Adam | epoch: 011 | loss: 0.68489 - acc: 0.5666 -- iter: 128/372
[A[ATraining Step: 125  | total loss: [1m[32m0.68923[0m[0m | time: 7.173s
[2K
| Adam | epoch: 011 | loss: 0.68923 - acc: 0.5537 -- iter: 160/372
[A[ATraining Step: 126  | total loss: [1m[32m0.68887[0m[0m | time: 8.616s
[2K
| Adam | epoch: 011 | loss: 0.68887 - acc: 0.5546 -- iter: 192/372
[A[ATraining Step: 127  | total loss: [1m[32m0.68757[0m[0m | time: 10.032s
[2K
| Adam | epoch: 011 | loss: 0.68757 - acc: 0.5585 -- iter: 224/372
[A[ATraining Step: 128  | total loss: [1m[32m0.68646[0m[0m | time: 11.299s
[2K
| Adam | epoch: 011 | loss: 0.68646 - acc: 0.5620 -- iter: 256/372
[A[ATraining Step: 129  | total loss: [1m[32m0.68396[0m[0m | time: 12.206s
[2K
| Adam | epoch: 011 | loss: 0.68396 - acc: 0.5715 -- iter: 288/372
[A[ATraining Step: 130  | total loss: [1m[32m0.68421[0m[0m | time: 13.160s
[2K
| Adam | epoch: 011 | loss: 0.68421 - acc: 0.5693 -- iter: 320/372
[A[ATraining Step: 131  | total loss: [1m[32m0.68468[0m[0m | time: 14.566s
[2K
| Adam | epoch: 011 | loss: 0.68468 - acc: 0.5674 -- iter: 352/372
[A[ATraining Step: 132  | total loss: [1m[32m0.68317[0m[0m | time: 17.007s
[2K
| Adam | epoch: 011 | loss: 0.68317 - acc: 0.5731 | val_loss: 0.68624 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 133  | total loss: [1m[32m0.68553[0m[0m | time: 16.267s
[2K
| Adam | epoch: 012 | loss: 0.68553 - acc: 0.5627 -- iter: 032/372
[A[ATraining Step: 134  | total loss: [1m[32m0.68530[0m[0m | time: 17.667s
[2K
| Adam | epoch: 012 | loss: 0.68530 - acc: 0.5627 -- iter: 064/372
[A[ATraining Step: 135  | total loss: [1m[32m0.68153[0m[0m | time: 19.112s
[2K
| Adam | epoch: 012 | loss: 0.68153 - acc: 0.5783 -- iter: 096/372
[A[ATraining Step: 136  | total loss: [1m[32m0.68261[0m[0m | time: 20.564s
[2K
| Adam | epoch: 012 | loss: 0.68261 - acc: 0.5736 -- iter: 128/372
[A[ATraining Step: 137  | total loss: [1m[32m0.68354[0m[0m | time: 22.148s
[2K
| Adam | epoch: 012 | loss: 0.68354 - acc: 0.5694 -- iter: 160/372
[A[ATraining Step: 138  | total loss: [1m[32m0.68221[0m[0m | time: 23.568s
[2K
| Adam | epoch: 012 | loss: 0.68221 - acc: 0.5749 -- iter: 192/372
[A[ATraining Step: 139  | total loss: [1m[32m0.68229[0m[0m | time: 25.288s
[2K
| Adam | epoch: 012 | loss: 0.68229 - acc: 0.5737 -- iter: 224/372
[A[ATraining Step: 140  | total loss: [1m[32m0.68245[0m[0m | time: 26.802s
[2K
| Adam | epoch: 012 | loss: 0.68245 - acc: 0.5726 -- iter: 256/372
[A[ATraining Step: 141  | total loss: [1m[32m0.68169[0m[0m | time: 28.041s
[2K
| Adam | epoch: 012 | loss: 0.68169 - acc: 0.5747 -- iter: 288/372
[A[ATraining Step: 142  | total loss: [1m[32m0.68518[0m[0m | time: 28.943s
[2K
| Adam | epoch: 012 | loss: 0.68518 - acc: 0.5610 -- iter: 320/372
[A[ATraining Step: 143  | total loss: [1m[32m0.68399[0m[0m | time: 29.942s
[2K
| Adam | epoch: 012 | loss: 0.68399 - acc: 0.5649 -- iter: 352/372
[A[ATraining Step: 144  | total loss: [1m[32m0.68286[0m[0m | time: 32.405s
[2K
| Adam | epoch: 012 | loss: 0.68286 - acc: 0.5684 | val_loss: 0.68557 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 145  | total loss: [1m[32m0.68308[0m[0m | time: 1.603s
[2K
| Adam | epoch: 013 | loss: 0.68308 - acc: 0.5678 -- iter: 032/372
[A[ATraining Step: 146  | total loss: [1m[32m0.68318[0m[0m | time: 2.958s
[2K
| Adam | epoch: 013 | loss: 0.68318 - acc: 0.5673 -- iter: 064/372
[A[ATraining Step: 147  | total loss: [1m[32m0.68234[0m[0m | time: 4.372s
[2K
| Adam | epoch: 013 | loss: 0.68234 - acc: 0.5699 -- iter: 096/372
[A[ATraining Step: 148  | total loss: [1m[32m0.68229[0m[0m | time: 5.824s
[2K
| Adam | epoch: 013 | loss: 0.68229 - acc: 0.5692 -- iter: 128/372
[A[ATraining Step: 149  | total loss: [1m[32m0.68044[0m[0m | time: 7.375s
[2K
| Adam | epoch: 013 | loss: 0.68044 - acc: 0.5748 -- iter: 160/372
[A[ATraining Step: 150  | total loss: [1m[32m0.67807[0m[0m | time: 8.967s
[2K
| Adam | epoch: 013 | loss: 0.67807 - acc: 0.5829 -- iter: 192/372
[A[ATraining Step: 151  | total loss: [1m[32m0.68069[0m[0m | time: 10.621s
[2K
| Adam | epoch: 013 | loss: 0.68069 - acc: 0.5746 -- iter: 224/372
[A[ATraining Step: 152  | total loss: [1m[32m0.68328[0m[0m | time: 11.998s
[2K
| Adam | epoch: 013 | loss: 0.68328 - acc: 0.5672 -- iter: 256/372
[A[ATraining Step: 153  | total loss: [1m[32m0.68842[0m[0m | time: 13.520s
[2K
| Adam | epoch: 013 | loss: 0.68842 - acc: 0.5511 -- iter: 288/372
[A[ATraining Step: 154  | total loss: [1m[32m0.68770[0m[0m | time: 15.137s
[2K
| Adam | epoch: 013 | loss: 0.68770 - acc: 0.5522 -- iter: 320/372
[A[ATraining Step: 155  | total loss: [1m[32m0.68371[0m[0m | time: 16.136s
[2K
| Adam | epoch: 013 | loss: 0.68371 - acc: 0.5657 -- iter: 352/372
[A[ATraining Step: 156  | total loss: [1m[32m0.68254[0m[0m | time: 18.247s
[2K
| Adam | epoch: 013 | loss: 0.68254 - acc: 0.5692 | val_loss: 0.68388 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 157  | total loss: [1m[32m0.68152[0m[0m | time: 2.023s
[2K
| Adam | epoch: 014 | loss: 0.68152 - acc: 0.5722 -- iter: 032/372
[A[ATraining Step: 158  | total loss: [1m[32m0.68156[0m[0m | time: 3.590s
[2K
| Adam | epoch: 014 | loss: 0.68156 - acc: 0.5713 -- iter: 064/372
[A[ATraining Step: 159  | total loss: [1m[32m0.68364[0m[0m | time: 4.898s
[2K
| Adam | epoch: 014 | loss: 0.68364 - acc: 0.5641 -- iter: 096/372
[A[ATraining Step: 160  | total loss: [1m[32m0.68636[0m[0m | time: 6.248s
[2K
| Adam | epoch: 014 | loss: 0.68636 - acc: 0.5546 -- iter: 128/372
[A[ATraining Step: 161  | total loss: [1m[32m0.68163[0m[0m | time: 7.752s
[2K
| Adam | epoch: 014 | loss: 0.68163 - acc: 0.5710 -- iter: 160/372
[A[ATraining Step: 162  | total loss: [1m[32m0.67904[0m[0m | time: 9.266s
[2K
| Adam | epoch: 014 | loss: 0.67904 - acc: 0.5795 -- iter: 192/372
[A[ATraining Step: 163  | total loss: [1m[32m0.68015[0m[0m | time: 10.886s
[2K
| Adam | epoch: 014 | loss: 0.68015 - acc: 0.5747 -- iter: 224/372
[A[ATraining Step: 164  | total loss: [1m[32m0.68272[0m[0m | time: 12.275s
[2K
| Adam | epoch: 014 | loss: 0.68272 - acc: 0.5641 -- iter: 256/372
[A[ATraining Step: 165  | total loss: [1m[32m0.68151[0m[0m | time: 13.540s
[2K
| Adam | epoch: 014 | loss: 0.68151 - acc: 0.5671 -- iter: 288/372
[A[ATraining Step: 166  | total loss: [1m[32m0.67865[0m[0m | time: 15.176s
[2K
| Adam | epoch: 014 | loss: 0.67865 - acc: 0.5760 -- iter: 320/372
[A[ATraining Step: 167  | total loss: [1m[32m0.68362[0m[0m | time: 16.674s
[2K
| Adam | epoch: 014 | loss: 0.68362 - acc: 0.5590 -- iter: 352/372
[A[ATraining Step: 168  | total loss: [1m[32m0.68254[0m[0m | time: 18.554s
[2K
| Adam | epoch: 014 | loss: 0.68254 - acc: 0.5625 | val_loss: 0.67932 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 169  | total loss: [1m[32m0.67968[0m[0m | time: 0.865s
[2K
| Adam | epoch: 015 | loss: 0.67968 - acc: 0.5712 -- iter: 032/372
[A[ATraining Step: 170  | total loss: [1m[32m0.67693[0m[0m | time: 2.450s
[2K
| Adam | epoch: 015 | loss: 0.67693 - acc: 0.5791 -- iter: 064/372
[A[ATraining Step: 171  | total loss: [1m[32m0.67206[0m[0m | time: 4.048s
[2K
| Adam | epoch: 015 | loss: 0.67206 - acc: 0.5900 -- iter: 096/372
[A[ATraining Step: 172  | total loss: [1m[32m0.66858[0m[0m | time: 5.576s
[2K
| Adam | epoch: 015 | loss: 0.66858 - acc: 0.5966 -- iter: 128/372
[A[ATraining Step: 173  | total loss: [1m[32m0.66977[0m[0m | time: 7.136s
[2K
| Adam | epoch: 015 | loss: 0.66977 - acc: 0.5932 -- iter: 160/372
[A[ATraining Step: 174  | total loss: [1m[32m0.67532[0m[0m | time: 8.733s
[2K
| Adam | epoch: 015 | loss: 0.67532 - acc: 0.5870 -- iter: 192/372
[A[ATraining Step: 175  | total loss: [1m[32m0.67952[0m[0m | time: 10.425s
[2K
| Adam | epoch: 015 | loss: 0.67952 - acc: 0.5783 -- iter: 224/372
[A[ATraining Step: 176  | total loss: [1m[32m0.68024[0m[0m | time: 11.758s
[2K
| Adam | epoch: 015 | loss: 0.68024 - acc: 0.5767 -- iter: 256/372
[A[ATraining Step: 177  | total loss: [1m[32m0.67887[0m[0m | time: 13.070s
[2K
| Adam | epoch: 015 | loss: 0.67887 - acc: 0.5784 -- iter: 288/372
[A[ATraining Step: 178  | total loss: [1m[32m0.68074[0m[0m | time: 14.466s
[2K
| Adam | epoch: 015 | loss: 0.68074 - acc: 0.5706 -- iter: 320/372
[A[ATraining Step: 179  | total loss: [1m[32m0.67975[0m[0m | time: 15.827s
[2K
| Adam | epoch: 015 | loss: 0.67975 - acc: 0.5729 -- iter: 352/372
[A[ATraining Step: 180  | total loss: [1m[32m0.68080[0m[0m | time: 18.397s
[2K
| Adam | epoch: 015 | loss: 0.68080 - acc: 0.5687 | val_loss: 0.68410 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 181  | total loss: [1m[32m0.67886[0m[0m | time: 0.894s
[2K
| Adam | epoch: 016 | loss: 0.67886 - acc: 0.5806 -- iter: 032/372
[A[ATraining Step: 182  | total loss: [1m[32m0.67663[0m[0m | time: 1.731s
[2K
| Adam | epoch: 016 | loss: 0.67663 - acc: 0.5925 -- iter: 064/372
[A[ATraining Step: 183  | total loss: [1m[32m0.67464[0m[0m | time: 2.746s
[2K
| Adam | epoch: 016 | loss: 0.67464 - acc: 0.6033 -- iter: 096/372
[A[ATraining Step: 184  | total loss: [1m[32m0.67654[0m[0m | time: 3.955s
[2K
| Adam | epoch: 016 | loss: 0.67654 - acc: 0.5930 -- iter: 128/372
[A[ATraining Step: 185  | total loss: [1m[32m0.67675[0m[0m | time: 5.199s
[2K
| Adam | epoch: 016 | loss: 0.67675 - acc: 0.5899 -- iter: 160/372
[A[ATraining Step: 186  | total loss: [1m[32m0.67965[0m[0m | time: 6.464s
[2K
| Adam | epoch: 016 | loss: 0.67965 - acc: 0.5747 -- iter: 192/372
[A[ATraining Step: 187  | total loss: [1m[32m0.67817[0m[0m | time: 7.350s
[2K
| Adam | epoch: 016 | loss: 0.67817 - acc: 0.5797 -- iter: 224/372
[A[ATraining Step: 188  | total loss: [1m[32m0.67770[0m[0m | time: 8.347s
[2K
| Adam | epoch: 016 | loss: 0.67770 - acc: 0.5780 -- iter: 256/372
[A[ATraining Step: 189  | total loss: [1m[32m0.67749[0m[0m | time: 9.362s
[2K
| Adam | epoch: 016 | loss: 0.67749 - acc: 0.5764 -- iter: 288/372
[A[ATraining Step: 190  | total loss: [1m[32m0.67880[0m[0m | time: 10.456s
[2K
| Adam | epoch: 016 | loss: 0.67880 - acc: 0.5688 -- iter: 320/372
[A[ATraining Step: 191  | total loss: [1m[32m0.67683[0m[0m | time: 11.593s
[2K
| Adam | epoch: 016 | loss: 0.67683 - acc: 0.5744 -- iter: 352/372
[A[ATraining Step: 192  | total loss: [1m[32m0.67347[0m[0m | time: 13.811s
[2K
| Adam | epoch: 016 | loss: 0.67347 - acc: 0.5795 | val_loss: 0.67126 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 193  | total loss: [1m[32m0.67249[0m[0m | time: 1.295s
[2K
| Adam | epoch: 017 | loss: 0.67249 - acc: 0.5778 -- iter: 032/372
[A[ATraining Step: 194  | total loss: [1m[32m0.67205[0m[0m | time: 2.191s
[2K
| Adam | epoch: 017 | loss: 0.67205 - acc: 0.5794 -- iter: 064/372
[A[ATraining Step: 195  | total loss: [1m[32m0.66837[0m[0m | time: 3.094s
[2K
| Adam | epoch: 017 | loss: 0.66837 - acc: 0.5864 -- iter: 096/372
[A[ATraining Step: 196  | total loss: [1m[32m0.66538[0m[0m | time: 4.114s
[2K
| Adam | epoch: 017 | loss: 0.66538 - acc: 0.5928 -- iter: 128/372
[A[ATraining Step: 197  | total loss: [1m[32m0.67498[0m[0m | time: 5.107s
[2K
| Adam | epoch: 017 | loss: 0.67498 - acc: 0.5773 -- iter: 160/372
[A[ATraining Step: 198  | total loss: [1m[32m0.68072[0m[0m | time: 6.120s
[2K
| Adam | epoch: 017 | loss: 0.68072 - acc: 0.5664 -- iter: 192/372
[A[ATraining Step: 199  | total loss: [1m[32m0.67577[0m[0m | time: 7.233s
[2K
| Adam | epoch: 017 | loss: 0.67577 - acc: 0.5754 -- iter: 224/372
[A[ATraining Step: 200  | total loss: [1m[32m0.67455[0m[0m | time: 9.465s
[2K
| Adam | epoch: 017 | loss: 0.67455 - acc: 0.5772 | val_loss: 0.66911 - val_acc: 0.5556 -- iter: 256/372
--
Training Step: 201  | total loss: [1m[32m0.67353[0m[0m | time: 11.198s
[2K
| Adam | epoch: 017 | loss: 0.67353 - acc: 0.5758 -- iter: 288/372
[A[ATraining Step: 202  | total loss: [1m[32m0.67137[0m[0m | time: 12.788s
[2K
| Adam | epoch: 017 | loss: 0.67137 - acc: 0.5776 -- iter: 320/372
[A[ATraining Step: 203  | total loss: [1m[32m0.67135[0m[0m | time: 14.408s
[2K
| Adam | epoch: 017 | loss: 0.67135 - acc: 0.5729 -- iter: 352/372
[A[ATraining Step: 204  | total loss: [1m[32m0.66860[0m[0m | time: 75.903s
[2K
| Adam | epoch: 017 | loss: 0.66860 - acc: 0.5750 | val_loss: 0.65690 - val_acc: 0.5556 -- iter: 372/372
--
Training Step: 205  | total loss: [1m[32m0.66931[0m[0m | time: 11.075s
[2K
| Adam | epoch: 018 | loss: 0.66931 - acc: 0.5738 -- iter: 032/372
[A[ATraining Step: 206  | total loss: [1m[32m0.66056[0m[0m | time: 12.216s
[2K
| Adam | epoch: 018 | loss: 0.66056 - acc: 0.5883 -- iter: 064/372
[A[ATraining Step: 207  | total loss: [1m[32m0.65623[0m[0m | time: 12.999s
[2K
| Adam | epoch: 018 | loss: 0.65623 - acc: 0.5919 -- iter: 096/372
[A[ATraining Step: 208  | total loss: [1m[32m0.65869[0m[0m | time: 13.845s
[2K
| Adam | epoch: 018 | loss: 0.65869 - acc: 0.5827 -- iter: 128/372
[A[ATraining Step: 209  | total loss: [1m[32m0.65960[0m[0m | time: 15.214s
[2K
| Adam | epoch: 018 | loss: 0.65960 - acc: 0.5745 -- iter: 160/372
[A[ATraining Step: 210  | total loss: [1m[32m0.66366[0m[0m | time: 16.717s
[2K
| Adam | epoch: 018 | loss: 0.66366 - acc: 0.5639 -- iter: 192/372
[A[ATraining Step: 211  | total loss: [1m[32m0.66212[0m[0m | time: 18.204s
[2K
| Adam | epoch: 018 | loss: 0.66212 - acc: 0.5638 -- iter: 224/372
[A[ATraining Step: 212  | total loss: [1m[32m0.66148[0m[0m | time: 19.654s
[2K
| Adam | epoch: 018 | loss: 0.66148 - acc: 0.5636 -- iter: 256/372
[A[ATraining Step: 213  | total loss: [1m[32m0.65959[0m[0m | time: 21.075s
[2K
| Adam | epoch: 018 | loss: 0.65959 - acc: 0.5635 -- iter: 288/372
[A[ATraining Step: 214  | total loss: [1m[32m0.65999[0m[0m | time: 22.580s
[2K
| Adam | epoch: 018 | loss: 0.65999 - acc: 0.5572 -- iter: 320/372
[A[ATraining Step: 215  | total loss: [1m[32m0.65407[0m[0m | time: 24.063s
[2K
| Adam | epoch: 018 | loss: 0.65407 - acc: 0.5639 -- iter: 352/372
[A[ATraining Step: 216  | total loss: [1m[32m0.65692[0m[0m | time: 26.624s
[2K
| Adam | epoch: 018 | loss: 0.65692 - acc: 0.5638 | val_loss: 0.62822 - val_acc: 0.6667 -- iter: 372/372
--
Training Step: 217  | total loss: [1m[32m0.65179[0m[0m | time: 1.419s
[2K
| Adam | epoch: 019 | loss: 0.65179 - acc: 0.5793 -- iter: 032/372
[A[ATraining Step: 218  | total loss: [1m[32m0.64666[0m[0m | time: 2.538s
[2K
| Adam | epoch: 019 | loss: 0.64666 - acc: 0.5901 -- iter: 064/372
[A[ATraining Step: 219  | total loss: [1m[32m0.63603[0m[0m | time: 3.847s
[2K
| Adam | epoch: 019 | loss: 0.63603 - acc: 0.6030 -- iter: 096/372
[A[ATraining Step: 220  | total loss: [1m[32m0.62294[0m[0m | time: 4.779s
[2K
| Adam | epoch: 019 | loss: 0.62294 - acc: 0.6239 -- iter: 128/372
[A[ATraining Step: 221  | total loss: [1m[32m0.61734[0m[0m | time: 5.578s
[2K
| Adam | epoch: 019 | loss: 0.61734 - acc: 0.6365 -- iter: 160/372
[A[ATraining Step: 222  | total loss: [1m[32m0.61440[0m[0m | time: 7.025s
[2K
| Adam | epoch: 019 | loss: 0.61440 - acc: 0.6479 -- iter: 192/372
[A[ATraining Step: 223  | total loss: [1m[32m0.65631[0m[0m | time: 8.430s
[2K
| Adam | epoch: 019 | loss: 0.65631 - acc: 0.6175 -- iter: 224/372
[A[ATraining Step: 224  | total loss: [1m[32m0.66098[0m[0m | time: 9.787s
[2K
| Adam | epoch: 019 | loss: 0.66098 - acc: 0.6120 -- iter: 256/372
[A[ATraining Step: 225  | total loss: [1m[32m0.65470[0m[0m | time: 11.083s
[2K
| Adam | epoch: 019 | loss: 0.65470 - acc: 0.6164 -- iter: 288/372
[A[ATraining Step: 226  | total loss: [1m[32m0.65478[0m[0m | time: 12.558s
[2K
| Adam | epoch: 019 | loss: 0.65478 - acc: 0.6141 -- iter: 320/372
[A[ATraining Step: 227  | total loss: [1m[32m0.65266[0m[0m | time: 13.811s
[2K
| Adam | epoch: 019 | loss: 0.65266 - acc: 0.6246 -- iter: 352/372
[A[ATraining Step: 228  | total loss: [1m[32m0.65085[0m[0m | time: 16.679s
[2K
| Adam | epoch: 019 | loss: 0.65085 - acc: 0.6340 | val_loss: 0.65054 - val_acc: 0.6667 -- iter: 372/372
--
Training Step: 229  | total loss: [1m[32m0.65080[0m[0m | time: 1.680s
[2K
| Adam | epoch: 020 | loss: 0.65080 - acc: 0.6394 -- iter: 032/372
[A[ATraining Step: 230  | total loss: [1m[32m0.65147[0m[0m | time: 3.067s
[2K
| Adam | epoch: 020 | loss: 0.65147 - acc: 0.6379 -- iter: 064/372
[A[ATraining Step: 231  | total loss: [1m[32m0.65049[0m[0m | time: 4.485s
[2K
| Adam | epoch: 020 | loss: 0.65049 - acc: 0.6429 -- iter: 096/372
[A[ATraining Step: 232  | total loss: [1m[32m0.64437[0m[0m | time: 16.051s
[2K
| Adam | epoch: 020 | loss: 0.64437 - acc: 0.6630 -- iter: 128/372
[A[ATraining Step: 233  | total loss: [1m[32m0.64220[0m[0m | time: 16.810s
[2K
| Adam | epoch: 020 | loss: 0.64220 - acc: 0.6592 -- iter: 160/372
[A[ATraining Step: 234  | total loss: [1m[32m0.64124[0m[0m | time: 17.582s
[2K
| Adam | epoch: 020 | loss: 0.64124 - acc: 0.6583 -- iter: 192/372
[A[ATraining Step: 235  | total loss: [1m[32m0.63722[0m[0m | time: 18.929s
[2K
| Adam | epoch: 020 | loss: 0.63722 - acc: 0.6674 -- iter: 224/372
[A[ATraining Step: 236  | total loss: [1m[32m0.63508[0m[0m | time: 20.305s
[2K
| Adam | epoch: 020 | loss: 0.63508 - acc: 0.6694 -- iter: 256/372
[A[ATraining Step: 237  | total loss: [1m[32m0.63592[0m[0m | time: 21.774s
[2K
| Adam | epoch: 020 | loss: 0.63592 - acc: 0.6712 -- iter: 288/372
[A[ATraining Step: 238  | total loss: [1m[32m0.62832[0m[0m | time: 23.188s
[2K
| Adam | epoch: 020 | loss: 0.62832 - acc: 0.6791 -- iter: 320/372
[A[ATraining Step: 239  | total loss: [1m[32m0.63062[0m[0m | time: 24.674s
[2K
| Adam | epoch: 020 | loss: 0.63062 - acc: 0.6675 -- iter: 352/372
[A[ATraining Step: 240  | total loss: [1m[32m0.62205[0m[0m | time: 27.281s
[2K
| Adam | epoch: 020 | loss: 0.62205 - acc: 0.6788 | val_loss: 0.55907 - val_acc: 0.7350 -- iter: 372/372
--
Training Step: 241  | total loss: [1m[32m0.60489[0m[0m | time: 1.524s
[2K
| Adam | epoch: 021 | loss: 0.60489 - acc: 0.7047 -- iter: 032/372
[A[ATraining Step: 242  | total loss: [1m[32m0.60070[0m[0m | time: 2.945s
[2K
| Adam | epoch: 021 | loss: 0.60070 - acc: 0.7124 -- iter: 064/372
[A[ATraining Step: 243  | total loss: [1m[32m0.60731[0m[0m | time: 4.425s
[2K
| Adam | epoch: 021 | loss: 0.60731 - acc: 0.7005 -- iter: 096/372
[A[ATraining Step: 244  | total loss: [1m[32m0.60579[0m[0m | time: 5.664s
[2K
| Adam | epoch: 021 | loss: 0.60579 - acc: 0.6898 -- iter: 128/372
[A[ATraining Step: 245  | total loss: [1m[32m0.60511[0m[0m | time: 7.003s
[2K
| Adam | epoch: 021 | loss: 0.60511 - acc: 0.6896 -- iter: 160/372
[A[ATraining Step: 246  | total loss: [1m[32m0.59562[0m[0m | time: 7.943s
[2K
| Adam | epoch: 021 | loss: 0.59562 - acc: 0.6956 -- iter: 192/372
[A[ATraining Step: 247  | total loss: [1m[32m0.57252[0m[0m | time: 8.964s
[2K
| Adam | epoch: 021 | loss: 0.57252 - acc: 0.7161 -- iter: 224/372
[A[ATraining Step: 248  | total loss: [1m[32m0.54935[0m[0m | time: 10.444s
[2K
| Adam | epoch: 021 | loss: 0.54935 - acc: 0.7295 -- iter: 256/372
[A[ATraining Step: 249  | total loss: [1m[32m0.57269[0m[0m | time: 12.010s
[2K
| Adam | epoch: 021 | loss: 0.57269 - acc: 0.7034 -- iter: 288/372
[A[ATraining Step: 250  | total loss: [1m[32m0.57148[0m[0m | time: 13.556s
[2K
| Adam | epoch: 021 | loss: 0.57148 - acc: 0.7049 -- iter: 320/372
[A[ATraining Step: 251  | total loss: [1m[32m0.56232[0m[0m | time: 15.256s
[2K
| Adam | epoch: 021 | loss: 0.56232 - acc: 0.7126 -- iter: 352/372
[A[ATraining Step: 252  | total loss: [1m[32m0.58223[0m[0m | time: 17.809s
[2K
| Adam | epoch: 021 | loss: 0.58223 - acc: 0.7038 | val_loss: 0.56525 - val_acc: 0.7265 -- iter: 372/372
--
Training Step: 253  | total loss: [1m[32m0.59634[0m[0m | time: 1.343s
[2K
| Adam | epoch: 022 | loss: 0.59634 - acc: 0.6959 -- iter: 032/372
[A[ATraining Step: 254  | total loss: [1m[32m0.62908[0m[0m | time: 2.750s
[2K
| Adam | epoch: 022 | loss: 0.62908 - acc: 0.6701 -- iter: 064/372
[A[ATraining Step: 255  | total loss: [1m[32m0.62075[0m[0m | time: 5.046s
[2K
| Adam | epoch: 022 | loss: 0.62075 - acc: 0.6812 -- iter: 096/372
[A[ATraining Step: 256  | total loss: [1m[32m0.60256[0m[0m | time: 6.218s
[2K
| Adam | epoch: 022 | loss: 0.60256 - acc: 0.6975 -- iter: 128/372
[A[ATraining Step: 257  | total loss: [1m[32m0.59902[0m[0m | time: 7.542s
[2K
| Adam | epoch: 022 | loss: 0.59902 - acc: 0.7027 -- iter: 160/372
[A[ATraining Step: 258  | total loss: [1m[32m0.60041[0m[0m | time: 8.900s
[2K
| Adam | epoch: 022 | loss: 0.60041 - acc: 0.7012 -- iter: 192/372
[A[ATraining Step: 259  | total loss: [1m[32m0.59551[0m[0m | time: 9.970s
[2K
| Adam | epoch: 022 | loss: 0.59551 - acc: 0.7092 -- iter: 224/372
[A[ATraining Step: 260  | total loss: [1m[32m0.58591[0m[0m | time: 10.983s
[2K
| Adam | epoch: 022 | loss: 0.58591 - acc: 0.7233 -- iter: 256/372
[A[ATraining Step: 261  | total loss: [1m[32m0.57706[0m[0m | time: 12.633s
[2K
| Adam | epoch: 022 | loss: 0.57706 - acc: 0.7409 -- iter: 288/372
[A[ATraining Step: 262  | total loss: [1m[32m0.57079[0m[0m | time: 14.044s
[2K
| Adam | epoch: 022 | loss: 0.57079 - acc: 0.7481 -- iter: 320/372
[A[ATraining Step: 263  | total loss: [1m[32m0.56394[0m[0m | time: 15.827s
[2K
| Adam | epoch: 022 | loss: 0.56394 - acc: 0.7545 -- iter: 352/372
[A[ATraining Step: 264  | total loss: [1m[32m0.56150[0m[0m | time: 18.490s
[2K
| Adam | epoch: 022 | loss: 0.56150 - acc: 0.7635 | val_loss: 0.52163 - val_acc: 0.7778 -- iter: 372/372
--
Training Step: 265  | total loss: [1m[32m0.55346[0m[0m | time: 1.202s
[2K
| Adam | epoch: 023 | loss: 0.55346 - acc: 0.7652 -- iter: 032/372
[A[ATraining Step: 266  | total loss: [1m[32m0.54440[0m[0m | time: 2.822s
[2K
| Adam | epoch: 023 | loss: 0.54440 - acc: 0.7668 -- iter: 064/372
[A[ATraining Step: 267  | total loss: [1m[32m0.53338[0m[0m | time: 7.513s
[2K
| Adam | epoch: 023 | loss: 0.53338 - acc: 0.7745 -- iter: 096/372
[A[ATraining Step: 268  | total loss: [1m[32m0.52110[0m[0m | time: 8.902s
[2K
| Adam | epoch: 023 | loss: 0.52110 - acc: 0.7721 -- iter: 128/372
[A[ATraining Step: 269  | total loss: [1m[32m0.50844[0m[0m | time: 10.264s
[2K
| Adam | epoch: 023 | loss: 0.50844 - acc: 0.7824 -- iter: 160/372
[A[ATraining Step: 270  | total loss: [1m[32m0.50085[0m[0m | time: 11.926s
[2K
| Adam | epoch: 023 | loss: 0.50085 - acc: 0.7885 -- iter: 192/372
[A[ATraining Step: 271  | total loss: [1m[32m0.49033[0m[0m | time: 13.468s
[2K
| Adam | epoch: 023 | loss: 0.49033 - acc: 0.7847 -- iter: 224/372
[A[ATraining Step: 272  | total loss: [1m[32m0.46952[0m[0m | time: 14.644s
[2K
| Adam | epoch: 023 | loss: 0.46952 - acc: 0.7999 -- iter: 256/372
[A[ATraining Step: 273  | total loss: [1m[32m0.47477[0m[0m | time: 15.765s
[2K
| Adam | epoch: 023 | loss: 0.47477 - acc: 0.7999 -- iter: 288/372
[A[ATraining Step: 274  | total loss: [1m[32m0.47606[0m[0m | time: 17.060s
[2K
| Adam | epoch: 023 | loss: 0.47606 - acc: 0.7950 -- iter: 320/372
[A[ATraining Step: 275  | total loss: [1m[32m0.49719[0m[0m | time: 18.233s
[2K
| Adam | epoch: 023 | loss: 0.49719 - acc: 0.7811 -- iter: 352/372
[A[ATraining Step: 276  | total loss: [1m[32m0.51283[0m[0m | time: 20.756s
[2K
| Adam | epoch: 023 | loss: 0.51283 - acc: 0.7717 | val_loss: 0.47897 - val_acc: 0.7949 -- iter: 372/372
--
Training Step: 277  | total loss: [1m[32m0.50174[0m[0m | time: 1.402s
[2K
| Adam | epoch: 024 | loss: 0.50174 - acc: 0.7758 -- iter: 032/372
[A[ATraining Step: 278  | total loss: [1m[32m0.49553[0m[0m | time: 2.711s
[2K
| Adam | epoch: 024 | loss: 0.49553 - acc: 0.7732 -- iter: 064/372
[A[ATraining Step: 279  | total loss: [1m[32m0.48210[0m[0m | time: 3.936s
[2K
| Adam | epoch: 024 | loss: 0.48210 - acc: 0.7803 -- iter: 096/372
[A[ATraining Step: 280  | total loss: [1m[32m0.45279[0m[0m | time: 5.017s
[2K
| Adam | epoch: 024 | loss: 0.45279 - acc: 0.7960 -- iter: 128/372
[A[ATraining Step: 281  | total loss: [1m[32m0.44829[0m[0m | time: 6.140s
[2K
| Adam | epoch: 024 | loss: 0.44829 - acc: 0.7945 -- iter: 160/372
[A[ATraining Step: 282  | total loss: [1m[32m0.44712[0m[0m | time: 7.424s
[2K
| Adam | epoch: 024 | loss: 0.44712 - acc: 0.7932 -- iter: 192/372
[A[ATraining Step: 283  | total loss: [1m[32m0.43885[0m[0m | time: 8.766s
[2K
| Adam | epoch: 024 | loss: 0.43885 - acc: 0.8014 -- iter: 224/372
[A[ATraining Step: 284  | total loss: [1m[32m0.42809[0m[0m | time: 9.751s
[2K
| Adam | epoch: 024 | loss: 0.42809 - acc: 0.8119 -- iter: 256/372
[A[ATraining Step: 285  | total loss: [1m[32m0.41247[0m[0m | time: 10.392s
[2K
| Adam | epoch: 024 | loss: 0.41247 - acc: 0.8182 -- iter: 288/372
[A[ATraining Step: 286  | total loss: [1m[32m0.38879[0m[0m | time: 11.009s
[2K
| Adam | epoch: 024 | loss: 0.38879 - acc: 0.8364 -- iter: 320/372
[A[ATraining Step: 287  | total loss: [1m[32m0.36621[0m[0m | time: 12.061s
[2K
| Adam | epoch: 024 | loss: 0.36621 - acc: 0.8527 -- iter: 352/372
[A[ATraining Step: 288  | total loss: [1m[32m0.36361[0m[0m | time: 14.108s
[2K
| Adam | epoch: 024 | loss: 0.36361 - acc: 0.8550 | val_loss: 0.47270 - val_acc: 0.7692 -- iter: 372/372
--
Training Step: 289  | total loss: [1m[32m0.35475[0m[0m | time: 1.167s
[2K
| Adam | epoch: 025 | loss: 0.35475 - acc: 0.8601 -- iter: 032/372
[A[ATraining Step: 290  | total loss: [1m[32m0.38178[0m[0m | time: 2.147s
[2K
| Adam | epoch: 025 | loss: 0.38178 - acc: 0.8459 -- iter: 064/372
[A[ATraining Step: 291  | total loss: [1m[32m0.37840[0m[0m | time: 3.443s
[2K
| Adam | epoch: 025 | loss: 0.37840 - acc: 0.8426 -- iter: 096/372
[A[ATraining Step: 292  | total loss: [1m[32m0.38876[0m[0m | time: 4.752s
[2K
| Adam | epoch: 025 | loss: 0.38876 - acc: 0.8333 -- iter: 128/372
[A[ATraining Step: 293  | total loss: [1m[32m0.37249[0m[0m | time: 5.993s
[2K
| Adam | epoch: 025 | loss: 0.37249 - acc: 0.8406 -- iter: 160/372
[A[ATraining Step: 294  | total loss: [1m[32m0.35345[0m[0m | time: 6.903s
[2K
| Adam | epoch: 025 | loss: 0.35345 - acc: 0.8566 -- iter: 192/372
[A[ATraining Step: 295  | total loss: [1m[32m0.35375[0m[0m | time: 7.876s
[2K
| Adam | epoch: 025 | loss: 0.35375 - acc: 0.8584 -- iter: 224/372
[A[ATraining Step: 296  | total loss: [1m[32m0.34692[0m[0m | time: 8.862s
[2K
| Adam | epoch: 025 | loss: 0.34692 - acc: 0.8569 -- iter: 256/372
[A[ATraining Step: 297  | total loss: [1m[32m0.35910[0m[0m | time: 9.843s
[2K
| Adam | epoch: 025 | loss: 0.35910 - acc: 0.8525 -- iter: 288/372
[A[ATraining Step: 298  | total loss: [1m[32m0.34924[0m[0m | time: 10.491s
[2K
| Adam | epoch: 025 | loss: 0.34924 - acc: 0.8548 -- iter: 320/372
[A[ATraining Step: 299  | total loss: [1m[32m0.37238[0m[0m | time: 11.197s
[2K
| Adam | epoch: 025 | loss: 0.37238 - acc: 0.8393 -- iter: 352/372
[A[ATraining Step: 300  | total loss: [1m[32m0.38225[0m[0m | time: 13.448s
[2K
| Adam | epoch: 025 | loss: 0.38225 - acc: 0.8353 | val_loss: 0.47365 - val_acc: 0.7692 -- iter: 372/372
--
Training Step: 301  | total loss: [1m[32m0.37208[0m[0m | time: 1.544s
[2K
| Adam | epoch: 026 | loss: 0.37208 - acc: 0.8424 -- iter: 032/372
[A[ATraining Step: 302  | total loss: [1m[32m0.36963[0m[0m | time: 3.113s
[2K
| Adam | epoch: 026 | loss: 0.36963 - acc: 0.8426 -- iter: 064/372
[A[ATraining Step: 303  | total loss: [1m[32m0.36888[0m[0m | time: 4.578s
[2K
| Adam | epoch: 026 | loss: 0.36888 - acc: 0.8396 -- iter: 096/372
[A[ATraining Step: 304  | total loss: [1m[32m0.34999[0m[0m | time: 12.284s
[2K
| Adam | epoch: 026 | loss: 0.34999 - acc: 0.8525 -- iter: 128/372
[A[ATraining Step: 305  | total loss: [1m[32m0.33095[0m[0m | time: 25.918s
[2K
| Adam | epoch: 026 | loss: 0.33095 - acc: 0.8579 -- iter: 160/372
[A[ATraining Step: 306  | total loss: [1m[32m0.34596[0m[0m | time: 27.136s
[2K
| Adam | epoch: 026 | loss: 0.34596 - acc: 0.8502 -- iter: 192/372
[A[ATraining Step: 307  | total loss: [1m[32m0.33405[0m[0m | time: 28.484s
[2K
| Adam | epoch: 026 | loss: 0.33405 - acc: 0.8558 -- iter: 224/372
[A[ATraining Step: 308  | total loss: [1m[32m0.32744[0m[0m | time: 29.871s
[2K
| Adam | epoch: 026 | loss: 0.32744 - acc: 0.8577 -- iter: 256/372
[A[ATraining Step: 309  | total loss: [1m[32m0.31520[0m[0m | time: 31.246s
[2K
| Adam | epoch: 026 | loss: 0.31520 - acc: 0.8657 -- iter: 288/372
[A[ATraining Step: 310  | total loss: [1m[32m0.31499[0m[0m | time: 32.813s
[2K
| Adam | epoch: 026 | loss: 0.31499 - acc: 0.8635 -- iter: 320/372
[A[ATraining Step: 311  | total loss: [1m[32m0.30223[0m[0m | time: 33.756s
[2K
| Adam | epoch: 026 | loss: 0.30223 - acc: 0.8709 -- iter: 352/372
[A[ATraining Step: 312  | total loss: [1m[32m0.29649[0m[0m | time: 35.810s
[2K
| Adam | epoch: 026 | loss: 0.29649 - acc: 0.8738 | val_loss: 0.53706 - val_acc: 0.7949 -- iter: 372/372
--
Training Step: 313  | total loss: [1m[32m0.29098[0m[0m | time: 1.639s
[2K
| Adam | epoch: 027 | loss: 0.29098 - acc: 0.8714 -- iter: 032/372
[A[ATraining Step: 314  | total loss: [1m[32m0.30131[0m[0m | time: 3.236s
[2K
| Adam | epoch: 027 | loss: 0.30131 - acc: 0.8655 -- iter: 064/372
[A[ATraining Step: 315  | total loss: [1m[32m0.28974[0m[0m | time: 4.753s
[2K
| Adam | epoch: 027 | loss: 0.28974 - acc: 0.8696 -- iter: 096/372
[A[ATraining Step: 316  | total loss: [1m[32m0.27889[0m[0m | time: 6.217s
[2K
| Adam | epoch: 027 | loss: 0.27889 - acc: 0.8764 -- iter: 128/372
[A[ATraining Step: 317  | total loss: [1m[32m0.27304[0m[0m | time: 7.735s
[2K
| Adam | epoch: 027 | loss: 0.27304 - acc: 0.8825 -- iter: 160/372
[A[ATraining Step: 318  | total loss: [1m[32m0.25880[0m[0m | time: 9.233s
[2K
| Adam | epoch: 027 | loss: 0.25880 - acc: 0.8911 -- iter: 192/372
[A[ATraining Step: 319  | total loss: [1m[32m0.30121[0m[0m | time: 10.507s
[2K
| Adam | epoch: 027 | loss: 0.30121 - acc: 0.8864 -- iter: 224/372
[A[ATraining Step: 320  | total loss: [1m[32m0.28610[0m[0m | time: 11.971s
[2K
| Adam | epoch: 027 | loss: 0.28610 - acc: 0.8946 -- iter: 256/372
[A[ATraining Step: 321  | total loss: [1m[32m0.27679[0m[0m | time: 13.638s
[2K
| Adam | epoch: 027 | loss: 0.27679 - acc: 0.8958 -- iter: 288/372
[A[ATraining Step: 322  | total loss: [1m[32m0.25966[0m[0m | time: 15.206s
[2K
| Adam | epoch: 027 | loss: 0.25966 - acc: 0.9031 -- iter: 320/372
[A[ATraining Step: 323  | total loss: [1m[32m0.25444[0m[0m | time: 16.619s
[2K
| Adam | epoch: 027 | loss: 0.25444 - acc: 0.9065 -- iter: 352/372
[A[ATraining Step: 324  | total loss: [1m[32m0.24361[0m[0m | time: 18.708s
[2K
| Adam | epoch: 027 | loss: 0.24361 - acc: 0.9096 | val_loss: 0.44932 - val_acc: 0.7692 -- iter: 372/372
--
Training Step: 325  | total loss: [1m[32m0.22950[0m[0m | time: 1.158s
[2K
| Adam | epoch: 028 | loss: 0.22950 - acc: 0.9187 -- iter: 032/372
[A[ATraining Step: 326  | total loss: [1m[32m0.21513[0m[0m | time: 2.328s
[2K
| Adam | epoch: 028 | loss: 0.21513 - acc: 0.9268 -- iter: 064/372
[A[ATraining Step: 327  | total loss: [1m[32m0.21118[0m[0m | time: 3.747s
[2K
| Adam | epoch: 028 | loss: 0.21118 - acc: 0.9247 -- iter: 096/372
[A[ATraining Step: 328  | total loss: [1m[32m0.20225[0m[0m | time: 5.132s
[2K
| Adam | epoch: 028 | loss: 0.20225 - acc: 0.9291 -- iter: 128/372
[A[ATraining Step: 329  | total loss: [1m[32m0.20103[0m[0m | time: 6.533s
[2K
| Adam | epoch: 028 | loss: 0.20103 - acc: 0.9300 -- iter: 160/372
[A[ATraining Step: 330  | total loss: [1m[32m0.19094[0m[0m | time: 7.955s
[2K
| Adam | epoch: 028 | loss: 0.19094 - acc: 0.9339 -- iter: 192/372
[A[ATraining Step: 331  | total loss: [1m[32m0.18700[0m[0m | time: 9.205s
[2K
| Adam | epoch: 028 | loss: 0.18700 - acc: 0.9311 -- iter: 224/372
[A[ATraining Step: 332  | total loss: [1m[32m0.20414[0m[0m | time: 10.684s
[2K
| Adam | epoch: 028 | loss: 0.20414 - acc: 0.9255 -- iter: 256/372
[A[ATraining Step: 333  | total loss: [1m[32m0.20011[0m[0m | time: 12.141s
[2K
| Adam | epoch: 028 | loss: 0.20011 - acc: 0.9267 -- iter: 288/372
[A[ATraining Step: 334  | total loss: [1m[32m0.18209[0m[0m | time: 13.400s
[2K
| Adam | epoch: 028 | loss: 0.18209 - acc: 0.9340 -- iter: 320/372
[A[ATraining Step: 335  | total loss: [1m[32m0.17312[0m[0m | time: 14.650s
[2K
| Adam | epoch: 028 | loss: 0.17312 - acc: 0.9375 -- iter: 352/372
[A[ATraining Step: 336  | total loss: [1m[32m0.18544[0m[0m | time: 17.092s
[2K
| Adam | epoch: 028 | loss: 0.18544 - acc: 0.9219 | val_loss: 0.50143 - val_acc: 0.7949 -- iter: 372/372
--
Training Step: 337  | total loss: [1m[32m0.20416[0m[0m | time: 1.014s
[2K
| Adam | epoch: 029 | loss: 0.20416 - acc: 0.9109 -- iter: 032/372
[A[ATraining Step: 338  | total loss: [1m[32m0.20177[0m[0m | time: 1.858s
[2K
| Adam | epoch: 029 | loss: 0.20177 - acc: 0.9048 -- iter: 064/372
[A[ATraining Step: 339  | total loss: [1m[32m0.19438[0m[0m | time: 3.463s
[2K
| Adam | epoch: 029 | loss: 0.19438 - acc: 0.9094 -- iter: 096/372
[A[ATraining Step: 340  | total loss: [1m[32m0.19127[0m[0m | time: 5.069s
[2K
| Adam | epoch: 029 | loss: 0.19127 - acc: 0.9122 -- iter: 128/372
[A[ATraining Step: 341  | total loss: [1m[32m0.18902[0m[0m | time: 6.681s
[2K
| Adam | epoch: 029 | loss: 0.18902 - acc: 0.9147 -- iter: 160/372
[A[ATraining Step: 342  | total loss: [1m[32m0.17577[0m[0m | time: 7.956s
[2K
| Adam | epoch: 029 | loss: 0.17577 - acc: 0.9232 -- iter: 192/372
[A[ATraining Step: 343  | total loss: [1m[32m0.16714[0m[0m | time: 26.235s
[2K
| Adam | epoch: 029 | loss: 0.16714 - acc: 0.9309 -- iter: 224/372
[A[ATraining Step: 344  | total loss: [1m[32m0.15601[0m[0m | time: 27.343s
[2K
| Adam | epoch: 029 | loss: 0.15601 - acc: 0.9378 -- iter: 256/372
[A[ATraining Step: 345  | total loss: [1m[32m0.16125[0m[0m | time: 28.698s
[2K
| Adam | epoch: 029 | loss: 0.16125 - acc: 0.9284 -- iter: 288/372
[A[ATraining Step: 346  | total loss: [1m[32m0.14895[0m[0m | time: 30.071s
[2K
| Adam | epoch: 029 | loss: 0.14895 - acc: 0.9356 -- iter: 320/372
[A[ATraining Step: 347  | total loss: [1m[32m0.13858[0m[0m | time: 31.550s
[2K
| Adam | epoch: 029 | loss: 0.13858 - acc: 0.9420 -- iter: 352/372
[A[ATraining Step: 348  | total loss: [1m[32m0.13073[0m[0m | time: 34.368s
[2K
| Adam | epoch: 029 | loss: 0.13073 - acc: 0.9447 | val_loss: 0.44045 - val_acc: 0.8205 -- iter: 372/372
--
Training Step: 349  | total loss: [1m[32m0.12970[0m[0m | time: 1.554s
[2K
| Adam | epoch: 030 | loss: 0.12970 - acc: 0.9471 -- iter: 032/372
[A[ATraining Step: 350  | total loss: [1m[32m0.12215[0m[0m | time: 2.490s
[2K
| Adam | epoch: 030 | loss: 0.12215 - acc: 0.9493 -- iter: 064/372
[A[ATraining Step: 351  | total loss: [1m[32m0.11330[0m[0m | time: 3.463s
[2K
| Adam | epoch: 030 | loss: 0.11330 - acc: 0.9543 -- iter: 096/372
[A[ATraining Step: 352  | total loss: [1m[32m0.10544[0m[0m | time: 5.173s
[2K
| Adam | epoch: 030 | loss: 0.10544 - acc: 0.9589 -- iter: 128/372
[A[ATraining Step: 353  | total loss: [1m[32m0.10347[0m[0m | time: 6.777s
[2K
| Adam | epoch: 030 | loss: 0.10347 - acc: 0.9599 -- iter: 160/372
[A[ATraining Step: 354  | total loss: [1m[32m0.09928[0m[0m | time: 8.048s
[2K
| Adam | epoch: 030 | loss: 0.09928 - acc: 0.9576 -- iter: 192/372
[A[ATraining Step: 355  | total loss: [1m[32m0.09839[0m[0m | time: 9.274s
[2K
| Adam | epoch: 030 | loss: 0.09839 - acc: 0.9588 -- iter: 224/372
[A[ATraining Step: 356  | total loss: [1m[32m0.09259[0m[0m | time: 24.701s
[2K
| Adam | epoch: 030 | loss: 0.09259 - acc: 0.9629 -- iter: 256/372
[A[ATraining Step: 357  | total loss: [1m[32m0.09097[0m[0m | time: 64.170s
[2K
| Adam | epoch: 030 | loss: 0.09097 - acc: 0.9666 -- iter: 288/372
[A[ATraining Step: 358  | total loss: [1m[32m0.08599[0m[0m | time: 65.334s
[2K
| Adam | epoch: 030 | loss: 0.08599 - acc: 0.9699 -- iter: 320/372
[A[ATraining Step: 359  | total loss: [1m[32m0.08067[0m[0m | time: 66.771s
[2K
| Adam | epoch: 030 | loss: 0.08067 - acc: 0.9729 -- iter: 352/372
[A[ATraining Step: 360  | total loss: [1m[32m0.07796[0m[0m | time: 69.114s
[2K
| Adam | epoch: 030 | loss: 0.07796 - acc: 0.9756 | val_loss: 0.57731 - val_acc: 0.7949 -- iter: 372/372
--
Validation AUC:0.9059171597633137
Validation AUPRC:0.9276255583264514
Test AUC:0.887806411062225
Test AUPRC:0.9172062022989078
BestTestF1Score	0.84	0.51	0.78	0.76	0.95	70	22	21	4	0.27
BestTestMCCScore	0.88	0.7	0.85	0.91	0.85	63	6	37	11	0.91
BestTestAccuracyScore	0.88	0.7	0.85	0.91	0.85	63	6	37	11	0.91
BestValidationF1Score	0.85	0.63	0.81	0.77	0.95	62	19	33	3	0.27
BestValidationMCC	0.84	0.66	0.83	0.86	0.83	54	9	43	11	0.91
BestValidationAccuracy	0.84	0.66	0.83	0.86	0.83	54	9	43	11	0.91
TestPredictions (Threshold:0.91)
CHEMBL244770,FP,INACT,1.0	CHEMBL1242659,TP,ACT,1.0	CHEMBL1762243,TN,INACT,0.20000000298023224	CHEMBL1241864,TN,INACT,0.8999999761581421	CHEMBL1615278,TP,ACT,0.9900000095367432	CHEMBL2216856,TP,ACT,1.0	CHEMBL2064333,TP,ACT,0.9300000071525574	CHEMBL3585601,FN,ACT,0.699999988079071	CHEMBL466106,TN,INACT,0.009999999776482582	CHEMBL1928558,FN,ACT,0.8600000143051147	CHEMBL2158424,TN,INACT,0.0	CHEMBL2165022,TP,ACT,1.0	CHEMBL3643381,TP,ACT,1.0	CHEMBL568574,FP,INACT,1.0	CHEMBL3787614,TP,ACT,0.9900000095367432	CHEMBL3643382,TP,ACT,1.0	CHEMBL3704699,TP,ACT,1.0	CHEMBL1928721,TP,ACT,0.9900000095367432	CHEMBL449786,FN,ACT,0.14000000059604645	CHEMBL1910989,FN,ACT,0.019999999552965164	CHEMBL3600697,TN,INACT,0.5400000214576721	CHEMBL221459,TN,INACT,0.25	CHEMBL512309,TN,INACT,0.0	CHEMBL2216862,TP,ACT,1.0	CHEMBL566895,TN,INACT,0.8500000238418579	CHEMBL2089102,TP,ACT,0.9900000095367432	CHEMBL3408278,TP,ACT,1.0	CHEMBL3704664,TP,ACT,0.9200000166893005	CHEMBL467553,TP,ACT,1.0	CHEMBL3643409,TP,ACT,1.0	CHEMBL3600689,TN,INACT,0.699999988079071	CHEMBL1684984,FN,ACT,0.8299999833106995	CHEMBL2064330,FN,ACT,0.8299999833106995	CHEMBL3600782,TN,INACT,0.5699999928474426	CHEMBL1511858,TN,INACT,0.009999999776482582	CHEMBL2171941,TP,ACT,1.0	CHEMBL3109143,TP,ACT,1.0	CHEMBL3704681,TP,ACT,0.9900000095367432	CHEMBL3643367,TP,ACT,1.0	CHEMBL211113,TN,INACT,0.0	CHEMBL74343,TN,INACT,0.8799999952316284	CHEMBL3360219,TN,INACT,0.14000000059604645	CHEMBL1241144,TN,INACT,0.05000000074505806	CHEMBL3600766,TN,INACT,0.8799999952316284	CHEMBL2151924,TP,ACT,1.0	CHEMBL3704663,TP,ACT,1.0	CHEMBL3765457,TP,ACT,1.0	CHEMBL1242567,TP,ACT,0.9800000190734863	CHEMBL2171920,TP,ACT,1.0	CHEMBL3290307,TP,ACT,0.9800000190734863	CHEMBL1645098,TN,INACT,0.23000000417232513	CHEMBL1760168,TP,ACT,1.0	CHEMBL3600702,TN,INACT,0.7699999809265137	CHEMBL3221627,TN,INACT,0.10999999940395355	CHEMBL2071330,TP,ACT,0.9399999976158142	CHEMBL2152148,TP,ACT,1.0	CHEMBL3355016,TP,ACT,1.0	CHEMBL2418960,TN,INACT,0.8999999761581421	CHEMBL2171936,TP,ACT,0.9800000190734863	CHEMBL2418354,TP,ACT,0.9900000095367432	CHEMBL3763878,TP,ACT,0.9399999976158142	CHEMBL1083810,TP,ACT,1.0	CHEMBL3134280,TP,ACT,1.0	CHEMBL1241585,TN,INACT,0.25999999046325684	CHEMBL3643357,TP,ACT,1.0	CHEMBL2171918,TP,ACT,1.0	CHEMBL3643384,TP,ACT,1.0	CHEMBL1645102,TN,INACT,0.4000000059604645	CHEMBL69869,TN,INACT,0.8999999761581421	CHEMBL3704659,TP,ACT,1.0	CHEMBL2152144,TP,ACT,1.0	CHEMBL561907,TN,INACT,0.33000001311302185	CHEMBL2152137,TP,ACT,0.9900000095367432	CHEMBL1241104,TN,INACT,0.009999999776482582	CHEMBL2152139,TP,ACT,1.0	CHEMBL3752335,TN,INACT,0.0	CHEMBL3360227,TN,INACT,0.1899999976158142	CHEMBL2030446,TN,INACT,0.8700000047683716	CHEMBL1242291,FN,ACT,0.0	CHEMBL3769747,TP,ACT,0.9700000286102295	CHEMBL3753037,TN,INACT,0.0	CHEMBL2171938,TP,ACT,1.0	CHEMBL466957,TN,INACT,0.6299999952316284	CHEMBL3112851,TP,ACT,1.0	CHEMBL3642829,TP,ACT,1.0	CHEMBL1241490,FN,ACT,0.8999999761581421	CHEMBL3112858,TP,ACT,0.9900000095367432	CHEMBL2069328,FN,ACT,0.05999999865889549	CHEMBL498002,TP,ACT,1.0	CHEMBL226031,TN,INACT,0.7099999785423279	CHEMBL1765740,FP,INACT,0.9900000095367432	CHEMBL3109138,TP,ACT,1.0	CHEMBL3360221,FP,INACT,0.9800000190734863	CHEMBL3704697,TP,ACT,1.0	CHEMBL469052,FN,ACT,0.27000001072883606	CHEMBL2414297,TP,ACT,0.9700000286102295	CHEMBL2165009,TP,ACT,0.9900000095367432	CHEMBL3680922,FN,ACT,0.7400000095367432	CHEMBL3798556,TN,INACT,0.0	CHEMBL3600769,TN,INACT,0.8700000047683716	CHEMBL2071631,TN,INACT,0.07000000029802322	CHEMBL3408265,TP,ACT,1.0	CHEMBL2216891,TP,ACT,1.0	CHEMBL58782,TN,INACT,0.029999999329447746	CHEMBL1241389,TP,ACT,0.9200000166893005	CHEMBL3608929,TP,ACT,1.0	CHEMBL2071642,FP,INACT,0.9900000095367432	CHEMBL514869,TP,ACT,0.9900000095367432	CHEMBL3589323,FP,INACT,0.9599999785423279	CHEMBL3704710,TP,ACT,1.0	CHEMBL2165021,TP,ACT,1.0	CHEMBL2322335,TP,ACT,1.0	CHEMBL3643389,TP,ACT,1.0	CHEMBL3770144,TP,ACT,0.9900000095367432	CHEMBL511807,TN,INACT,0.0	CHEMBL2158435,TN,INACT,0.0	CHEMBL1242666,TP,ACT,0.9900000095367432	

