ImageNetInceptionV2 CHEMBL252 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	1231
Number of inactive compounds :	1231
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL252_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL252_adam_0.0005_15_0.8/
---------------------------------
Training samples: 1554
Validation samples: 486
--
Training Step: 1  | time: 86.378s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1554
[A[ATraining Step: 2  | total loss: [1m[32m0.64007[0m[0m | time: 128.725s
[2K
| Adam | epoch: 001 | loss: 0.64007 - acc: 0.5062 -- iter: 0064/1554
[A[ATraining Step: 3  | total loss: [1m[32m1.15092[0m[0m | time: 137.855s
[2K
| Adam | epoch: 001 | loss: 1.15092 - acc: 0.5523 -- iter: 0096/1554
[A[ATraining Step: 4  | total loss: [1m[32m0.76884[0m[0m | time: 174.780s
[2K
| Adam | epoch: 001 | loss: 0.76884 - acc: 0.7006 -- iter: 0128/1554
[A[ATraining Step: 5  | total loss: [1m[32m0.76465[0m[0m | time: 220.243s
[2K
| Adam | epoch: 001 | loss: 0.76465 - acc: 0.6915 -- iter: 0160/1554
[A[ATraining Step: 6  | total loss: [1m[32m0.64440[0m[0m | time: 237.004s
[2K
| Adam | epoch: 001 | loss: 0.64440 - acc: 0.7090 -- iter: 0192/1554
[A[ATraining Step: 7  | total loss: [1m[32m0.68806[0m[0m | time: 253.682s
[2K
| Adam | epoch: 001 | loss: 0.68806 - acc: 0.6399 -- iter: 0224/1554
[A[ATraining Step: 8  | total loss: [1m[32m0.66871[0m[0m | time: 275.851s
[2K
| Adam | epoch: 001 | loss: 0.66871 - acc: 0.5963 -- iter: 0256/1554
[A[ATraining Step: 9  | total loss: [1m[32m0.64511[0m[0m | time: 289.606s
[2K
| Adam | epoch: 001 | loss: 0.64511 - acc: 0.6281 -- iter: 0288/1554
[A[ATraining Step: 10  | total loss: [1m[32m0.62746[0m[0m | time: 308.002s
[2K
| Adam | epoch: 001 | loss: 0.62746 - acc: 0.6265 -- iter: 0320/1554
[A[ATraining Step: 11  | total loss: [1m[32m0.61112[0m[0m | time: 327.288s
[2K
| Adam | epoch: 001 | loss: 0.61112 - acc: 0.6554 -- iter: 0352/1554
[A[ATraining Step: 12  | total loss: [1m[32m0.65421[0m[0m | time: 340.901s
[2K
| Adam | epoch: 001 | loss: 0.65421 - acc: 0.5995 -- iter: 0384/1554
[A[ATraining Step: 13  | total loss: [1m[32m0.63426[0m[0m | time: 359.495s
[2K
| Adam | epoch: 001 | loss: 0.63426 - acc: 0.6372 -- iter: 0416/1554
[A[ATraining Step: 14  | total loss: [1m[32m0.61788[0m[0m | time: 377.182s
[2K
| Adam | epoch: 001 | loss: 0.61788 - acc: 0.6322 -- iter: 0448/1554
[A[ATraining Step: 15  | total loss: [1m[32m0.57431[0m[0m | time: 389.091s
[2K
| Adam | epoch: 001 | loss: 0.57431 - acc: 0.6783 -- iter: 0480/1554
[A[ATraining Step: 16  | total loss: [1m[32m0.59843[0m[0m | time: 403.430s
[2K
| Adam | epoch: 001 | loss: 0.59843 - acc: 0.6935 -- iter: 0512/1554
[A[ATraining Step: 17  | total loss: [1m[32m0.60206[0m[0m | time: 415.860s
[2K
| Adam | epoch: 001 | loss: 0.60206 - acc: 0.6801 -- iter: 0544/1554
[A[ATraining Step: 18  | total loss: [1m[32m0.57844[0m[0m | time: 435.705s
[2K
| Adam | epoch: 001 | loss: 0.57844 - acc: 0.6826 -- iter: 0576/1554
[A[ATraining Step: 19  | total loss: [1m[32m0.55705[0m[0m | time: 450.930s
[2K
| Adam | epoch: 001 | loss: 0.55705 - acc: 0.7363 -- iter: 0608/1554
[A[ATraining Step: 20  | total loss: [1m[32m0.53632[0m[0m | time: 466.658s
[2K
| Adam | epoch: 001 | loss: 0.53632 - acc: 0.7407 -- iter: 0640/1554
[A[ATraining Step: 21  | total loss: [1m[32m0.52959[0m[0m | time: 485.664s
[2K
| Adam | epoch: 001 | loss: 0.52959 - acc: 0.7533 -- iter: 0672/1554
[A[ATraining Step: 22  | total loss: [1m[32m0.49376[0m[0m | time: 498.154s
[2K
| Adam | epoch: 001 | loss: 0.49376 - acc: 0.7804 -- iter: 0704/1554
[A[ATraining Step: 23  | total loss: [1m[32m0.46444[0m[0m | time: 512.945s
[2K
| Adam | epoch: 001 | loss: 0.46444 - acc: 0.7988 -- iter: 0736/1554
[A[ATraining Step: 24  | total loss: [1m[32m0.46980[0m[0m | time: 527.982s
[2K
| Adam | epoch: 001 | loss: 0.46980 - acc: 0.8027 -- iter: 0768/1554
[A[ATraining Step: 25  | total loss: [1m[32m0.48039[0m[0m | time: 545.331s
[2K
| Adam | epoch: 001 | loss: 0.48039 - acc: 0.8053 -- iter: 0800/1554
[A[ATraining Step: 26  | total loss: [1m[32m0.48508[0m[0m | time: 564.059s
[2K
| Adam | epoch: 001 | loss: 0.48508 - acc: 0.8155 -- iter: 0832/1554
[A[ATraining Step: 27  | total loss: [1m[32m0.49646[0m[0m | time: 576.364s
[2K
| Adam | epoch: 001 | loss: 0.49646 - acc: 0.7987 -- iter: 0864/1554
[A[ATraining Step: 28  | total loss: [1m[32m0.49343[0m[0m | time: 604.148s
[2K
| Adam | epoch: 001 | loss: 0.49343 - acc: 0.7865 -- iter: 0896/1554
[A[ATraining Step: 29  | total loss: [1m[32m0.46644[0m[0m | time: 615.512s
[2K
| Adam | epoch: 001 | loss: 0.46644 - acc: 0.8004 -- iter: 0928/1554
[A[ATraining Step: 30  | total loss: [1m[32m0.42064[0m[0m | time: 626.944s
[2K
| Adam | epoch: 001 | loss: 0.42064 - acc: 0.8255 -- iter: 0960/1554
[A[ATraining Step: 31  | total loss: [1m[32m0.39078[0m[0m | time: 638.418s
[2K
| Adam | epoch: 001 | loss: 0.39078 - acc: 0.8441 -- iter: 0992/1554
[A[ATraining Step: 32  | total loss: [1m[32m0.40330[0m[0m | time: 650.923s
[2K
| Adam | epoch: 001 | loss: 0.40330 - acc: 0.8511 -- iter: 1024/1554
[A[ATraining Step: 33  | total loss: [1m[32m0.41233[0m[0m | time: 662.967s
[2K
| Adam | epoch: 001 | loss: 0.41233 - acc: 0.8426 -- iter: 1056/1554
[A[ATraining Step: 34  | total loss: [1m[32m0.38419[0m[0m | time: 676.508s
[2K
| Adam | epoch: 001 | loss: 0.38419 - acc: 0.8495 -- iter: 1088/1554
[A[ATraining Step: 35  | total loss: [1m[32m0.36247[0m[0m | time: 688.877s
[2K
| Adam | epoch: 001 | loss: 0.36247 - acc: 0.8549 -- iter: 1120/1554
[A[ATraining Step: 36  | total loss: [1m[32m0.38736[0m[0m | time: 700.059s
[2K
| Adam | epoch: 001 | loss: 0.38736 - acc: 0.8398 -- iter: 1152/1554
[A[ATraining Step: 37  | total loss: [1m[32m0.43117[0m[0m | time: 708.112s
[2K
| Adam | epoch: 001 | loss: 0.43117 - acc: 0.8406 -- iter: 1184/1554
[A[ATraining Step: 38  | total loss: [1m[32m0.42606[0m[0m | time: 716.353s
[2K
| Adam | epoch: 001 | loss: 0.42606 - acc: 0.8351 -- iter: 1216/1554
[A[ATraining Step: 39  | total loss: [1m[32m0.38582[0m[0m | time: 726.256s
[2K
| Adam | epoch: 001 | loss: 0.38582 - acc: 0.8607 -- iter: 1248/1554
[A[ATraining Step: 40  | total loss: [1m[32m0.38698[0m[0m | time: 738.039s
[2K
| Adam | epoch: 001 | loss: 0.38698 - acc: 0.8517 -- iter: 1280/1554
[A[ATraining Step: 41  | total loss: [1m[32m0.36548[0m[0m | time: 749.468s
[2K
| Adam | epoch: 001 | loss: 0.36548 - acc: 0.8617 -- iter: 1312/1554
[A[ATraining Step: 42  | total loss: [1m[32m0.35604[0m[0m | time: 761.936s
[2K
| Adam | epoch: 001 | loss: 0.35604 - acc: 0.8528 -- iter: 1344/1554
[A[ATraining Step: 43  | total loss: [1m[32m0.37790[0m[0m | time: 791.588s
[2K
| Adam | epoch: 001 | loss: 0.37790 - acc: 0.8402 -- iter: 1376/1554
[A[ATraining Step: 44  | total loss: [1m[32m0.36027[0m[0m | time: 803.521s
[2K
| Adam | epoch: 001 | loss: 0.36027 - acc: 0.8516 -- iter: 1408/1554
[A[ATraining Step: 45  | total loss: [1m[32m0.36345[0m[0m | time: 814.936s
[2K
| Adam | epoch: 001 | loss: 0.36345 - acc: 0.8503 -- iter: 1440/1554
[A[ATraining Step: 46  | total loss: [1m[32m0.37264[0m[0m | time: 826.803s
[2K
| Adam | epoch: 001 | loss: 0.37264 - acc: 0.8544 -- iter: 1472/1554
[A[ATraining Step: 47  | total loss: [1m[32m0.35315[0m[0m | time: 838.792s
[2K
| Adam | epoch: 001 | loss: 0.35315 - acc: 0.8731 -- iter: 1504/1554
[A[ATraining Step: 48  | total loss: [1m[32m0.35836[0m[0m | time: 850.781s
[2K
| Adam | epoch: 001 | loss: 0.35836 - acc: 0.8835 -- iter: 1536/1554
[A[ATraining Step: 49  | total loss: [1m[32m0.37471[0m[0m | time: 901.203s
[2K
| Adam | epoch: 001 | loss: 0.37471 - acc: 0.8772 | val_loss: 0.48364 - val_acc: 0.8086 -- iter: 1554/1554
--
Training Step: 50  | total loss: [1m[32m0.42824[0m[0m | time: 7.347s
[2K
| Adam | epoch: 002 | loss: 0.42824 - acc: 0.8531 -- iter: 0032/1554
[A[ATraining Step: 51  | total loss: [1m[32m0.43707[0m[0m | time: 19.213s
[2K
| Adam | epoch: 002 | loss: 0.43707 - acc: 0.8417 -- iter: 0064/1554
[A[ATraining Step: 52  | total loss: [1m[32m0.43571[0m[0m | time: 33.175s
[2K
| Adam | epoch: 002 | loss: 0.43571 - acc: 0.8420 -- iter: 0096/1554
[A[ATraining Step: 53  | total loss: [1m[32m0.40782[0m[0m | time: 45.015s
[2K
| Adam | epoch: 002 | loss: 0.40782 - acc: 0.8561 -- iter: 0128/1554
[A[ATraining Step: 54  | total loss: [1m[32m0.40267[0m[0m | time: 83.390s
[2K
| Adam | epoch: 002 | loss: 0.40267 - acc: 0.8543 -- iter: 0160/1554
[A[ATraining Step: 55  | total loss: [1m[32m0.41635[0m[0m | time: 95.321s
[2K
| Adam | epoch: 002 | loss: 0.41635 - acc: 0.8349 -- iter: 0192/1554
[A[ATraining Step: 56  | total loss: [1m[32m0.41017[0m[0m | time: 106.899s
[2K
| Adam | epoch: 002 | loss: 0.41017 - acc: 0.8318 -- iter: 0224/1554
[A[ATraining Step: 57  | total loss: [1m[32m0.44543[0m[0m | time: 118.650s
[2K
| Adam | epoch: 002 | loss: 0.44543 - acc: 0.8161 -- iter: 0256/1554
[A[ATraining Step: 58  | total loss: [1m[32m0.40630[0m[0m | time: 130.239s
[2K
| Adam | epoch: 002 | loss: 0.40630 - acc: 0.8412 -- iter: 0288/1554
[A[ATraining Step: 59  | total loss: [1m[32m0.39424[0m[0m | time: 143.612s
[2K
| Adam | epoch: 002 | loss: 0.39424 - acc: 0.8415 -- iter: 0320/1554
[A[ATraining Step: 60  | total loss: [1m[32m0.40127[0m[0m | time: 156.516s
[2K
| Adam | epoch: 002 | loss: 0.40127 - acc: 0.8377 -- iter: 0352/1554
[A[ATraining Step: 61  | total loss: [1m[32m0.40434[0m[0m | time: 168.224s
[2K
| Adam | epoch: 002 | loss: 0.40434 - acc: 0.8385 -- iter: 0384/1554
[A[ATraining Step: 62  | total loss: [1m[32m0.39661[0m[0m | time: 180.574s
[2K
| Adam | epoch: 002 | loss: 0.39661 - acc: 0.8392 -- iter: 0416/1554
[A[ATraining Step: 63  | total loss: [1m[32m0.39201[0m[0m | time: 192.045s
[2K
| Adam | epoch: 002 | loss: 0.39201 - acc: 0.8397 -- iter: 0448/1554
[A[ATraining Step: 64  | total loss: [1m[32m0.39908[0m[0m | time: 203.831s
[2K
| Adam | epoch: 002 | loss: 0.39908 - acc: 0.8324 -- iter: 0480/1554
[A[ATraining Step: 65  | total loss: [1m[32m0.39994[0m[0m | time: 215.914s
[2K
| Adam | epoch: 002 | loss: 0.39994 - acc: 0.8300 -- iter: 0512/1554
[A[ATraining Step: 66  | total loss: [1m[32m0.38794[0m[0m | time: 225.401s
[2K
| Adam | epoch: 002 | loss: 0.38794 - acc: 0.8392 -- iter: 0544/1554
[A[ATraining Step: 67  | total loss: [1m[32m0.39638[0m[0m | time: 233.821s
[2K
| Adam | epoch: 002 | loss: 0.39638 - acc: 0.8323 -- iter: 0576/1554
[A[ATraining Step: 68  | total loss: [1m[32m0.37347[0m[0m | time: 241.816s
[2K
| Adam | epoch: 002 | loss: 0.37347 - acc: 0.8447 -- iter: 0608/1554
[A[ATraining Step: 69  | total loss: [1m[32m0.38397[0m[0m | time: 276.689s
[2K
| Adam | epoch: 002 | loss: 0.38397 - acc: 0.8337 -- iter: 0640/1554
[A[ATraining Step: 70  | total loss: [1m[32m0.39981[0m[0m | time: 287.953s
[2K
| Adam | epoch: 002 | loss: 0.39981 - acc: 0.8348 -- iter: 0672/1554
[A[ATraining Step: 71  | total loss: [1m[32m0.37972[0m[0m | time: 299.378s
[2K
| Adam | epoch: 002 | loss: 0.37972 - acc: 0.8465 -- iter: 0704/1554
[A[ATraining Step: 72  | total loss: [1m[32m0.37598[0m[0m | time: 311.145s
[2K
| Adam | epoch: 002 | loss: 0.37598 - acc: 0.8533 -- iter: 0736/1554
[A[ATraining Step: 73  | total loss: [1m[32m0.35016[0m[0m | time: 322.918s
[2K
| Adam | epoch: 002 | loss: 0.35016 - acc: 0.8696 -- iter: 0768/1554
[A[ATraining Step: 74  | total loss: [1m[32m0.34467[0m[0m | time: 335.587s
[2K
| Adam | epoch: 002 | loss: 0.34467 - acc: 0.8667 -- iter: 0800/1554
[A[ATraining Step: 75  | total loss: [1m[32m0.33954[0m[0m | time: 370.318s
[2K
| Adam | epoch: 002 | loss: 0.33954 - acc: 0.8642 -- iter: 0832/1554
[A[ATraining Step: 76  | total loss: [1m[32m0.33595[0m[0m | time: 381.854s
[2K
| Adam | epoch: 002 | loss: 0.33595 - acc: 0.8620 -- iter: 0864/1554
[A[ATraining Step: 77  | total loss: [1m[32m0.32923[0m[0m | time: 393.338s
[2K
| Adam | epoch: 002 | loss: 0.32923 - acc: 0.8667 -- iter: 0896/1554
[A[ATraining Step: 78  | total loss: [1m[32m0.32193[0m[0m | time: 404.641s
[2K
| Adam | epoch: 002 | loss: 0.32193 - acc: 0.8709 -- iter: 0928/1554
[A[ATraining Step: 79  | total loss: [1m[32m0.30072[0m[0m | time: 416.632s
[2K
| Adam | epoch: 002 | loss: 0.30072 - acc: 0.8778 -- iter: 0960/1554
[A[ATraining Step: 80  | total loss: [1m[32m0.29275[0m[0m | time: 429.094s
[2K
| Adam | epoch: 002 | loss: 0.29275 - acc: 0.8839 -- iter: 0992/1554
[A[ATraining Step: 81  | total loss: [1m[32m0.29303[0m[0m | time: 440.712s
[2K
| Adam | epoch: 002 | loss: 0.29303 - acc: 0.8830 -- iter: 1024/1554
[A[ATraining Step: 82  | total loss: [1m[32m0.29435[0m[0m | time: 451.813s
[2K
| Adam | epoch: 002 | loss: 0.29435 - acc: 0.8822 -- iter: 1056/1554
[A[ATraining Step: 83  | total loss: [1m[32m0.29584[0m[0m | time: 477.601s
[2K
| Adam | epoch: 002 | loss: 0.29584 - acc: 0.8783 -- iter: 1088/1554
[A[ATraining Step: 84  | total loss: [1m[32m0.28601[0m[0m | time: 506.525s
[2K
| Adam | epoch: 002 | loss: 0.28601 - acc: 0.8842 -- iter: 1120/1554
[A[ATraining Step: 85  | total loss: [1m[32m0.26587[0m[0m | time: 518.077s
[2K
| Adam | epoch: 002 | loss: 0.26587 - acc: 0.8958 -- iter: 1152/1554
[A[ATraining Step: 86  | total loss: [1m[32m0.27028[0m[0m | time: 529.420s
[2K
| Adam | epoch: 002 | loss: 0.27028 - acc: 0.8906 -- iter: 1184/1554
[A[ATraining Step: 87  | total loss: [1m[32m0.26292[0m[0m | time: 540.761s
[2K
| Adam | epoch: 002 | loss: 0.26292 - acc: 0.8953 -- iter: 1216/1554
[A[ATraining Step: 88  | total loss: [1m[32m0.24696[0m[0m | time: 552.553s
[2K
| Adam | epoch: 002 | loss: 0.24696 - acc: 0.9058 -- iter: 1248/1554
[A[ATraining Step: 89  | total loss: [1m[32m0.24606[0m[0m | time: 564.883s
[2K
| Adam | epoch: 002 | loss: 0.24606 - acc: 0.9058 -- iter: 1280/1554
[A[ATraining Step: 90  | total loss: [1m[32m0.25670[0m[0m | time: 575.972s
[2K
| Adam | epoch: 002 | loss: 0.25670 - acc: 0.9027 -- iter: 1312/1554
[A[ATraining Step: 91  | total loss: [1m[32m0.26456[0m[0m | time: 587.383s
[2K
| Adam | epoch: 002 | loss: 0.26456 - acc: 0.9031 -- iter: 1344/1554
[A[ATraining Step: 92  | total loss: [1m[32m0.27073[0m[0m | time: 598.606s
[2K
| Adam | epoch: 002 | loss: 0.27073 - acc: 0.9003 -- iter: 1376/1554
[A[ATraining Step: 93  | total loss: [1m[32m0.25737[0m[0m | time: 609.799s
[2K
| Adam | epoch: 002 | loss: 0.25737 - acc: 0.9071 -- iter: 1408/1554
[A[ATraining Step: 94  | total loss: [1m[32m0.25673[0m[0m | time: 621.422s
[2K
| Adam | epoch: 002 | loss: 0.25673 - acc: 0.9102 -- iter: 1440/1554
[A[ATraining Step: 95  | total loss: [1m[32m0.25567[0m[0m | time: 633.113s
[2K
| Adam | epoch: 002 | loss: 0.25567 - acc: 0.9066 -- iter: 1472/1554
[A[ATraining Step: 96  | total loss: [1m[32m0.24449[0m[0m | time: 645.426s
[2K
| Adam | epoch: 002 | loss: 0.24449 - acc: 0.9097 -- iter: 1504/1554
[A[ATraining Step: 97  | total loss: [1m[32m0.23398[0m[0m | time: 656.358s
[2K
| Adam | epoch: 002 | loss: 0.23398 - acc: 0.9188 -- iter: 1536/1554
[A[ATraining Step: 98  | total loss: [1m[32m0.23474[0m[0m | time: 695.611s
[2K
| Adam | epoch: 002 | loss: 0.23474 - acc: 0.9175 | val_loss: 0.41339 - val_acc: 0.8210 -- iter: 1554/1554
--
Training Step: 99  | total loss: [1m[32m0.25124[0m[0m | time: 7.379s
[2K
| Adam | epoch: 003 | loss: 0.25124 - acc: 0.9008 -- iter: 0032/1554
[A[ATraining Step: 100  | total loss: [1m[32m0.28940[0m[0m | time: 15.560s
[2K
| Adam | epoch: 003 | loss: 0.28940 - acc: 0.8940 -- iter: 0064/1554
[A[ATraining Step: 101  | total loss: [1m[32m0.28653[0m[0m | time: 27.714s
[2K
| Adam | epoch: 003 | loss: 0.28653 - acc: 0.8991 -- iter: 0096/1554
[A[ATraining Step: 102  | total loss: [1m[32m0.31591[0m[0m | time: 35.998s
[2K
| Adam | epoch: 003 | loss: 0.31591 - acc: 0.8842 -- iter: 0128/1554
[A[ATraining Step: 103  | total loss: [1m[32m0.30770[0m[0m | time: 44.267s
[2K
| Adam | epoch: 003 | loss: 0.30770 - acc: 0.8926 -- iter: 0160/1554
[A[ATraining Step: 104  | total loss: [1m[32m0.29145[0m[0m | time: 52.797s
[2K
| Adam | epoch: 003 | loss: 0.29145 - acc: 0.9002 -- iter: 0192/1554
[A[ATraining Step: 105  | total loss: [1m[32m0.28289[0m[0m | time: 68.084s
[2K
| Adam | epoch: 003 | loss: 0.28289 - acc: 0.8977 -- iter: 0224/1554
[A[ATraining Step: 106  | total loss: [1m[32m0.27410[0m[0m | time: 79.605s
[2K
| Adam | epoch: 003 | loss: 0.27410 - acc: 0.9017 -- iter: 0256/1554
[A[ATraining Step: 107  | total loss: [1m[32m0.27513[0m[0m | time: 97.291s
[2K
| Adam | epoch: 003 | loss: 0.27513 - acc: 0.9053 -- iter: 0288/1554
[A[ATraining Step: 108  | total loss: [1m[32m0.27209[0m[0m | time: 108.793s
[2K
| Adam | epoch: 003 | loss: 0.27209 - acc: 0.9054 -- iter: 0320/1554
[A[ATraining Step: 109  | total loss: [1m[32m0.25068[0m[0m | time: 120.125s
[2K
| Adam | epoch: 003 | loss: 0.25068 - acc: 0.9148 -- iter: 0352/1554
[A[ATraining Step: 110  | total loss: [1m[32m0.25217[0m[0m | time: 131.665s
[2K
| Adam | epoch: 003 | loss: 0.25217 - acc: 0.9171 -- iter: 0384/1554
[A[ATraining Step: 111  | total loss: [1m[32m0.26341[0m[0m | time: 142.895s
[2K
| Adam | epoch: 003 | loss: 0.26341 - acc: 0.9129 -- iter: 0416/1554
[A[ATraining Step: 112  | total loss: [1m[32m0.25684[0m[0m | time: 157.139s
[2K
| Adam | epoch: 003 | loss: 0.25684 - acc: 0.9153 -- iter: 0448/1554
[A[ATraining Step: 113  | total loss: [1m[32m0.28378[0m[0m | time: 169.912s
[2K
| Adam | epoch: 003 | loss: 0.28378 - acc: 0.9082 -- iter: 0480/1554
[A[ATraining Step: 114  | total loss: [1m[32m0.31313[0m[0m | time: 190.067s
[2K
| Adam | epoch: 003 | loss: 0.31313 - acc: 0.8986 -- iter: 0512/1554
[A[ATraining Step: 115  | total loss: [1m[32m0.31383[0m[0m | time: 201.722s
[2K
| Adam | epoch: 003 | loss: 0.31383 - acc: 0.8931 -- iter: 0544/1554
[A[ATraining Step: 116  | total loss: [1m[32m0.29384[0m[0m | time: 213.111s
[2K
| Adam | epoch: 003 | loss: 0.29384 - acc: 0.9007 -- iter: 0576/1554
[A[ATraining Step: 117  | total loss: [1m[32m0.28271[0m[0m | time: 224.962s
[2K
| Adam | epoch: 003 | loss: 0.28271 - acc: 0.9012 -- iter: 0608/1554
[A[ATraining Step: 118  | total loss: [1m[32m0.27793[0m[0m | time: 236.538s
[2K
| Adam | epoch: 003 | loss: 0.27793 - acc: 0.8955 -- iter: 0640/1554
[A[ATraining Step: 119  | total loss: [1m[32m0.28197[0m[0m | time: 247.524s
[2K
| Adam | epoch: 003 | loss: 0.28197 - acc: 0.8966 -- iter: 0672/1554
[A[ATraining Step: 120  | total loss: [1m[32m0.27161[0m[0m | time: 258.765s
[2K
| Adam | epoch: 003 | loss: 0.27161 - acc: 0.9038 -- iter: 0704/1554
[A[ATraining Step: 121  | total loss: [1m[32m0.25774[0m[0m | time: 270.858s
[2K
| Adam | epoch: 003 | loss: 0.25774 - acc: 0.9103 -- iter: 0736/1554
[A[ATraining Step: 122  | total loss: [1m[32m0.24160[0m[0m | time: 282.427s
[2K
| Adam | epoch: 003 | loss: 0.24160 - acc: 0.9161 -- iter: 0768/1554
[A[ATraining Step: 123  | total loss: [1m[32m0.22505[0m[0m | time: 293.560s
[2K
| Adam | epoch: 003 | loss: 0.22505 - acc: 0.9245 -- iter: 0800/1554
[A[ATraining Step: 124  | total loss: [1m[32m0.23027[0m[0m | time: 305.146s
[2K
| Adam | epoch: 003 | loss: 0.23027 - acc: 0.9227 -- iter: 0832/1554
[A[ATraining Step: 125  | total loss: [1m[32m0.22398[0m[0m | time: 316.693s
[2K
| Adam | epoch: 003 | loss: 0.22398 - acc: 0.9273 -- iter: 0864/1554
[A[ATraining Step: 126  | total loss: [1m[32m0.21257[0m[0m | time: 328.148s
[2K
| Adam | epoch: 003 | loss: 0.21257 - acc: 0.9314 -- iter: 0896/1554
[A[ATraining Step: 127  | total loss: [1m[32m0.21021[0m[0m | time: 339.308s
[2K
| Adam | epoch: 003 | loss: 0.21021 - acc: 0.9320 -- iter: 0928/1554
[A[ATraining Step: 128  | total loss: [1m[32m0.19920[0m[0m | time: 351.789s
[2K
| Adam | epoch: 003 | loss: 0.19920 - acc: 0.9388 -- iter: 0960/1554
[A[ATraining Step: 129  | total loss: [1m[32m0.19525[0m[0m | time: 363.258s
[2K
| Adam | epoch: 003 | loss: 0.19525 - acc: 0.9387 -- iter: 0992/1554
[A[ATraining Step: 130  | total loss: [1m[32m0.20242[0m[0m | time: 374.535s
[2K
| Adam | epoch: 003 | loss: 0.20242 - acc: 0.9355 -- iter: 1024/1554
[A[ATraining Step: 131  | total loss: [1m[32m0.19982[0m[0m | time: 386.165s
[2K
| Adam | epoch: 003 | loss: 0.19982 - acc: 0.9357 -- iter: 1056/1554
[A[ATraining Step: 132  | total loss: [1m[32m0.19610[0m[0m | time: 397.693s
[2K
| Adam | epoch: 003 | loss: 0.19610 - acc: 0.9390 -- iter: 1088/1554
[A[ATraining Step: 133  | total loss: [1m[32m0.18830[0m[0m | time: 408.867s
[2K
| Adam | epoch: 003 | loss: 0.18830 - acc: 0.9388 -- iter: 1120/1554
[A[ATraining Step: 134  | total loss: [1m[32m0.17983[0m[0m | time: 420.392s
[2K
| Adam | epoch: 003 | loss: 0.17983 - acc: 0.9418 -- iter: 1152/1554
[A[ATraining Step: 135  | total loss: [1m[32m0.18765[0m[0m | time: 432.128s
[2K
| Adam | epoch: 003 | loss: 0.18765 - acc: 0.9383 -- iter: 1184/1554
[A[ATraining Step: 136  | total loss: [1m[32m0.18903[0m[0m | time: 443.319s
[2K
| Adam | epoch: 003 | loss: 0.18903 - acc: 0.9351 -- iter: 1216/1554
[A[ATraining Step: 137  | total loss: [1m[32m0.18927[0m[0m | time: 477.113s
[2K
| Adam | epoch: 003 | loss: 0.18927 - acc: 0.9384 -- iter: 1248/1554
[A[ATraining Step: 138  | total loss: [1m[32m0.19611[0m[0m | time: 489.391s
[2K
| Adam | epoch: 003 | loss: 0.19611 - acc: 0.9352 -- iter: 1280/1554
[A[ATraining Step: 139  | total loss: [1m[32m0.19872[0m[0m | time: 501.355s
[2K
| Adam | epoch: 003 | loss: 0.19872 - acc: 0.9323 -- iter: 1312/1554
[A[ATraining Step: 140  | total loss: [1m[32m0.21269[0m[0m | time: 509.237s
[2K
| Adam | epoch: 003 | loss: 0.21269 - acc: 0.9266 -- iter: 1344/1554
[A[ATraining Step: 141  | total loss: [1m[32m0.20518[0m[0m | time: 517.410s
[2K
| Adam | epoch: 003 | loss: 0.20518 - acc: 0.9308 -- iter: 1376/1554
[A[ATraining Step: 142  | total loss: [1m[32m0.19049[0m[0m | time: 525.554s
[2K
| Adam | epoch: 003 | loss: 0.19049 - acc: 0.9346 -- iter: 1408/1554
[A[ATraining Step: 143  | total loss: [1m[32m0.21958[0m[0m | time: 536.162s
[2K
| Adam | epoch: 003 | loss: 0.21958 - acc: 0.9286 -- iter: 1440/1554
[A[ATraining Step: 144  | total loss: [1m[32m0.21531[0m[0m | time: 553.265s
[2K
| Adam | epoch: 003 | loss: 0.21531 - acc: 0.9326 -- iter: 1472/1554
[A[ATraining Step: 145  | total loss: [1m[32m0.20246[0m[0m | time: 567.270s
[2K
| Adam | epoch: 003 | loss: 0.20246 - acc: 0.9331 -- iter: 1504/1554
[A[ATraining Step: 146  | total loss: [1m[32m0.28538[0m[0m | time: 575.006s
[2K
| Adam | epoch: 003 | loss: 0.28538 - acc: 0.9117 -- iter: 1536/1554
[A[ATraining Step: 147  | total loss: [1m[32m0.27826[0m[0m | time: 604.340s
[2K
| Adam | epoch: 003 | loss: 0.27826 - acc: 0.9112 | val_loss: 4.44068 - val_acc: 0.5000 -- iter: 1554/1554
--
Training Step: 148  | total loss: [1m[32m0.28142[0m[0m | time: 7.968s
[2K
| Adam | epoch: 004 | loss: 0.28142 - acc: 0.9075 -- iter: 0032/1554
[A[ATraining Step: 149  | total loss: [1m[32m0.27271[0m[0m | time: 13.039s
[2K
| Adam | epoch: 004 | loss: 0.27271 - acc: 0.9074 -- iter: 0064/1554
[A[ATraining Step: 150  | total loss: [1m[32m0.25735[0m[0m | time: 17.974s
[2K
| Adam | epoch: 004 | loss: 0.25735 - acc: 0.9111 -- iter: 0096/1554
[A[ATraining Step: 151  | total loss: [1m[32m0.23658[0m[0m | time: 25.704s
[2K
| Adam | epoch: 004 | loss: 0.23658 - acc: 0.9200 -- iter: 0128/1554
[A[ATraining Step: 152  | total loss: [1m[32m0.25898[0m[0m | time: 33.590s
[2K
| Adam | epoch: 004 | loss: 0.25898 - acc: 0.9092 -- iter: 0160/1554
[A[ATraining Step: 153  | total loss: [1m[32m0.24226[0m[0m | time: 41.469s
[2K
| Adam | epoch: 004 | loss: 0.24226 - acc: 0.9152 -- iter: 0192/1554
[A[ATraining Step: 154  | total loss: [1m[32m0.25852[0m[0m | time: 49.418s
[2K
| Adam | epoch: 004 | loss: 0.25852 - acc: 0.9049 -- iter: 0224/1554
[A[ATraining Step: 155  | total loss: [1m[32m0.24263[0m[0m | time: 57.138s
[2K
| Adam | epoch: 004 | loss: 0.24263 - acc: 0.9113 -- iter: 0256/1554
[A[ATraining Step: 156  | total loss: [1m[32m0.24363[0m[0m | time: 64.986s
[2K
| Adam | epoch: 004 | loss: 0.24363 - acc: 0.9077 -- iter: 0288/1554
[A[ATraining Step: 157  | total loss: [1m[32m0.27120[0m[0m | time: 72.847s
[2K
| Adam | epoch: 004 | loss: 0.27120 - acc: 0.8950 -- iter: 0320/1554
[A[ATraining Step: 158  | total loss: [1m[32m0.26991[0m[0m | time: 80.763s
[2K
| Adam | epoch: 004 | loss: 0.26991 - acc: 0.8962 -- iter: 0352/1554
[A[ATraining Step: 159  | total loss: [1m[32m0.27217[0m[0m | time: 88.631s
[2K
| Adam | epoch: 004 | loss: 0.27217 - acc: 0.8940 -- iter: 0384/1554
[A[ATraining Step: 160  | total loss: [1m[32m0.27006[0m[0m | time: 96.480s
[2K
| Adam | epoch: 004 | loss: 0.27006 - acc: 0.8953 -- iter: 0416/1554
[A[ATraining Step: 161  | total loss: [1m[32m0.26070[0m[0m | time: 104.552s
[2K
| Adam | epoch: 004 | loss: 0.26070 - acc: 0.8995 -- iter: 0448/1554
[A[ATraining Step: 162  | total loss: [1m[32m0.24632[0m[0m | time: 112.378s
[2K
| Adam | epoch: 004 | loss: 0.24632 - acc: 0.9064 -- iter: 0480/1554
[A[ATraining Step: 163  | total loss: [1m[32m0.25363[0m[0m | time: 120.247s
[2K
| Adam | epoch: 004 | loss: 0.25363 - acc: 0.9064 -- iter: 0512/1554
[A[ATraining Step: 164  | total loss: [1m[32m0.26226[0m[0m | time: 128.077s
[2K
| Adam | epoch: 004 | loss: 0.26226 - acc: 0.9064 -- iter: 0544/1554
[A[ATraining Step: 165  | total loss: [1m[32m0.24815[0m[0m | time: 135.963s
[2K
| Adam | epoch: 004 | loss: 0.24815 - acc: 0.9126 -- iter: 0576/1554
[A[ATraining Step: 166  | total loss: [1m[32m0.23456[0m[0m | time: 143.671s
[2K
| Adam | epoch: 004 | loss: 0.23456 - acc: 0.9182 -- iter: 0608/1554
[A[ATraining Step: 167  | total loss: [1m[32m0.21885[0m[0m | time: 151.550s
[2K
| Adam | epoch: 004 | loss: 0.21885 - acc: 0.9264 -- iter: 0640/1554
[A[ATraining Step: 168  | total loss: [1m[32m0.21418[0m[0m | time: 159.317s
[2K
| Adam | epoch: 004 | loss: 0.21418 - acc: 0.9306 -- iter: 0672/1554
[A[ATraining Step: 169  | total loss: [1m[32m0.20127[0m[0m | time: 167.326s
[2K
| Adam | epoch: 004 | loss: 0.20127 - acc: 0.9345 -- iter: 0704/1554
[A[ATraining Step: 170  | total loss: [1m[32m0.22602[0m[0m | time: 175.273s
[2K
| Adam | epoch: 004 | loss: 0.22602 - acc: 0.9285 -- iter: 0736/1554
[A[ATraining Step: 171  | total loss: [1m[32m0.22095[0m[0m | time: 183.148s
[2K
| Adam | epoch: 004 | loss: 0.22095 - acc: 0.9263 -- iter: 0768/1554
[A[ATraining Step: 172  | total loss: [1m[32m0.21074[0m[0m | time: 191.028s
[2K
| Adam | epoch: 004 | loss: 0.21074 - acc: 0.9274 -- iter: 0800/1554
[A[ATraining Step: 173  | total loss: [1m[32m0.20122[0m[0m | time: 199.136s
[2K
| Adam | epoch: 004 | loss: 0.20122 - acc: 0.9315 -- iter: 0832/1554
[A[ATraining Step: 174  | total loss: [1m[32m0.19352[0m[0m | time: 206.970s
[2K
| Adam | epoch: 004 | loss: 0.19352 - acc: 0.9353 -- iter: 0864/1554
[A[ATraining Step: 175  | total loss: [1m[32m0.18007[0m[0m | time: 214.900s
[2K
| Adam | epoch: 004 | loss: 0.18007 - acc: 0.9386 -- iter: 0896/1554
[A[ATraining Step: 176  | total loss: [1m[32m0.16958[0m[0m | time: 222.919s
[2K
| Adam | epoch: 004 | loss: 0.16958 - acc: 0.9447 -- iter: 0928/1554
[A[ATraining Step: 177  | total loss: [1m[32m0.16516[0m[0m | time: 230.749s
[2K
| Adam | epoch: 004 | loss: 0.16516 - acc: 0.9409 -- iter: 0960/1554
[A[ATraining Step: 178  | total loss: [1m[32m0.16622[0m[0m | time: 238.685s
[2K
| Adam | epoch: 004 | loss: 0.16622 - acc: 0.9406 -- iter: 0992/1554
[A[ATraining Step: 179  | total loss: [1m[32m0.16097[0m[0m | time: 246.560s
[2K
| Adam | epoch: 004 | loss: 0.16097 - acc: 0.9434 -- iter: 1024/1554
[A[ATraining Step: 180  | total loss: [1m[32m0.14932[0m[0m | time: 254.610s
[2K
| Adam | epoch: 004 | loss: 0.14932 - acc: 0.9490 -- iter: 1056/1554
[A[ATraining Step: 181  | total loss: [1m[32m0.13899[0m[0m | time: 262.587s
[2K
| Adam | epoch: 004 | loss: 0.13899 - acc: 0.9541 -- iter: 1088/1554
[A[ATraining Step: 182  | total loss: [1m[32m0.13749[0m[0m | time: 270.595s
[2K
| Adam | epoch: 004 | loss: 0.13749 - acc: 0.9525 -- iter: 1120/1554
[A[ATraining Step: 183  | total loss: [1m[32m0.14708[0m[0m | time: 278.537s
[2K
| Adam | epoch: 004 | loss: 0.14708 - acc: 0.9510 -- iter: 1152/1554
[A[ATraining Step: 184  | total loss: [1m[32m0.16724[0m[0m | time: 286.217s
[2K
| Adam | epoch: 004 | loss: 0.16724 - acc: 0.9403 -- iter: 1184/1554
[A[ATraining Step: 185  | total loss: [1m[32m0.16741[0m[0m | time: 294.173s
[2K
| Adam | epoch: 004 | loss: 0.16741 - acc: 0.9431 -- iter: 1216/1554
[A[ATraining Step: 186  | total loss: [1m[32m0.18348[0m[0m | time: 302.001s
[2K
| Adam | epoch: 004 | loss: 0.18348 - acc: 0.9363 -- iter: 1248/1554
[A[ATraining Step: 187  | total loss: [1m[32m0.17086[0m[0m | time: 310.067s
[2K
| Adam | epoch: 004 | loss: 0.17086 - acc: 0.9395 -- iter: 1280/1554
[A[ATraining Step: 188  | total loss: [1m[32m0.16693[0m[0m | time: 318.008s
[2K
| Adam | epoch: 004 | loss: 0.16693 - acc: 0.9362 -- iter: 1312/1554
[A[ATraining Step: 189  | total loss: [1m[32m0.15946[0m[0m | time: 325.957s
[2K
| Adam | epoch: 004 | loss: 0.15946 - acc: 0.9395 -- iter: 1344/1554
[A[ATraining Step: 190  | total loss: [1m[32m0.16047[0m[0m | time: 333.752s
[2K
| Adam | epoch: 004 | loss: 0.16047 - acc: 0.9361 -- iter: 1376/1554
[A[ATraining Step: 191  | total loss: [1m[32m0.15263[0m[0m | time: 341.702s
[2K
| Adam | epoch: 004 | loss: 0.15263 - acc: 0.9394 -- iter: 1408/1554
[A[ATraining Step: 192  | total loss: [1m[32m0.16428[0m[0m | time: 349.510s
[2K
| Adam | epoch: 004 | loss: 0.16428 - acc: 0.9361 -- iter: 1440/1554
[A[ATraining Step: 193  | total loss: [1m[32m0.15742[0m[0m | time: 357.429s
[2K
| Adam | epoch: 004 | loss: 0.15742 - acc: 0.9362 -- iter: 1472/1554
[A[ATraining Step: 194  | total loss: [1m[32m0.18980[0m[0m | time: 365.441s
[2K
| Adam | epoch: 004 | loss: 0.18980 - acc: 0.9270 -- iter: 1504/1554
[A[ATraining Step: 195  | total loss: [1m[32m0.19094[0m[0m | time: 373.533s
[2K
| Adam | epoch: 004 | loss: 0.19094 - acc: 0.9249 -- iter: 1536/1554
[A[ATraining Step: 196  | total loss: [1m[32m0.18152[0m[0m | time: 402.920s
[2K
| Adam | epoch: 004 | loss: 0.18152 - acc: 0.9293 | val_loss: 0.47509 - val_acc: 0.8498 -- iter: 1554/1554
--
Training Step: 197  | total loss: [1m[32m0.17899[0m[0m | time: 7.956s
[2K
| Adam | epoch: 005 | loss: 0.17899 - acc: 0.9332 -- iter: 0032/1554
[A[ATraining Step: 198  | total loss: [1m[32m0.16671[0m[0m | time: 15.846s
[2K
| Adam | epoch: 005 | loss: 0.16671 - acc: 0.9399 -- iter: 0064/1554
[A[ATraining Step: 199  | total loss: [1m[32m0.15586[0m[0m | time: 20.918s
[2K
| Adam | epoch: 005 | loss: 0.15586 - acc: 0.9459 -- iter: 0096/1554
[A[ATraining Step: 200  | total loss: [1m[32m0.18809[0m[0m | time: 47.154s
[2K
| Adam | epoch: 005 | loss: 0.18809 - acc: 0.9402 | val_loss: 1.27638 - val_acc: 0.6173 -- iter: 0128/1554
--
Training Step: 201  | total loss: [1m[32m0.19077[0m[0m | time: 55.161s
[2K
| Adam | epoch: 005 | loss: 0.19077 - acc: 0.9406 -- iter: 0160/1554
[A[ATraining Step: 202  | total loss: [1m[32m0.18909[0m[0m | time: 62.976s
[2K
| Adam | epoch: 005 | loss: 0.18909 - acc: 0.9403 -- iter: 0192/1554
[A[ATraining Step: 203  | total loss: [1m[32m0.18481[0m[0m | time: 70.853s
[2K
| Adam | epoch: 005 | loss: 0.18481 - acc: 0.9400 -- iter: 0224/1554
[A[ATraining Step: 204  | total loss: [1m[32m0.18321[0m[0m | time: 78.928s
[2K
| Adam | epoch: 005 | loss: 0.18321 - acc: 0.9367 -- iter: 0256/1554
[A[ATraining Step: 205  | total loss: [1m[32m0.17378[0m[0m | time: 86.791s
[2K
| Adam | epoch: 005 | loss: 0.17378 - acc: 0.9367 -- iter: 0288/1554
[A[ATraining Step: 206  | total loss: [1m[32m0.17509[0m[0m | time: 94.552s
[2K
| Adam | epoch: 005 | loss: 0.17509 - acc: 0.9337 -- iter: 0320/1554
[A[ATraining Step: 207  | total loss: [1m[32m0.21046[0m[0m | time: 102.485s
[2K
| Adam | epoch: 005 | loss: 0.21046 - acc: 0.9247 -- iter: 0352/1554
[A[ATraining Step: 208  | total loss: [1m[32m0.23134[0m[0m | time: 110.434s
[2K
| Adam | epoch: 005 | loss: 0.23134 - acc: 0.9166 -- iter: 0384/1554
[A[ATraining Step: 209  | total loss: [1m[32m0.22889[0m[0m | time: 118.453s
[2K
| Adam | epoch: 005 | loss: 0.22889 - acc: 0.9187 -- iter: 0416/1554
[A[ATraining Step: 210  | total loss: [1m[32m0.27425[0m[0m | time: 126.208s
[2K
| Adam | epoch: 005 | loss: 0.27425 - acc: 0.9081 -- iter: 0448/1554
[A[ATraining Step: 211  | total loss: [1m[32m0.27441[0m[0m | time: 134.246s
[2K
| Adam | epoch: 005 | loss: 0.27441 - acc: 0.9079 -- iter: 0480/1554
[A[ATraining Step: 212  | total loss: [1m[32m0.27149[0m[0m | time: 142.230s
[2K
| Adam | epoch: 005 | loss: 0.27149 - acc: 0.9015 -- iter: 0512/1554
[A[ATraining Step: 213  | total loss: [1m[32m0.26533[0m[0m | time: 150.366s
[2K
| Adam | epoch: 005 | loss: 0.26533 - acc: 0.9051 -- iter: 0544/1554
[A[ATraining Step: 214  | total loss: [1m[32m0.25241[0m[0m | time: 158.150s
[2K
| Adam | epoch: 005 | loss: 0.25241 - acc: 0.9083 -- iter: 0576/1554
[A[ATraining Step: 215  | total loss: [1m[32m0.26075[0m[0m | time: 166.087s
[2K
| Adam | epoch: 005 | loss: 0.26075 - acc: 0.8987 -- iter: 0608/1554
[A[ATraining Step: 216  | total loss: [1m[32m0.26719[0m[0m | time: 173.841s
[2K
| Adam | epoch: 005 | loss: 0.26719 - acc: 0.8964 -- iter: 0640/1554
[A[ATraining Step: 217  | total loss: [1m[32m0.24798[0m[0m | time: 181.843s
[2K
| Adam | epoch: 005 | loss: 0.24798 - acc: 0.9067 -- iter: 0672/1554
[A[ATraining Step: 218  | total loss: [1m[32m0.24253[0m[0m | time: 189.551s
[2K
| Adam | epoch: 005 | loss: 0.24253 - acc: 0.9098 -- iter: 0704/1554
[A[ATraining Step: 219  | total loss: [1m[32m0.23042[0m[0m | time: 197.421s
[2K
| Adam | epoch: 005 | loss: 0.23042 - acc: 0.9157 -- iter: 0736/1554
[A[ATraining Step: 220  | total loss: [1m[32m0.22068[0m[0m | time: 205.238s
[2K
| Adam | epoch: 005 | loss: 0.22068 - acc: 0.9210 -- iter: 0768/1554
[A[ATraining Step: 221  | total loss: [1m[32m0.21899[0m[0m | time: 213.019s
[2K
| Adam | epoch: 005 | loss: 0.21899 - acc: 0.9227 -- iter: 0800/1554
[A[ATraining Step: 222  | total loss: [1m[32m0.23948[0m[0m | time: 220.888s
[2K
| Adam | epoch: 005 | loss: 0.23948 - acc: 0.9148 -- iter: 0832/1554
[A[ATraining Step: 223  | total loss: [1m[32m0.23746[0m[0m | time: 228.733s
[2K
| Adam | epoch: 005 | loss: 0.23746 - acc: 0.9139 -- iter: 0864/1554
[A[ATraining Step: 224  | total loss: [1m[32m0.25321[0m[0m | time: 236.535s
[2K
| Adam | epoch: 005 | loss: 0.25321 - acc: 0.9069 -- iter: 0896/1554
[A[ATraining Step: 225  | total loss: [1m[32m0.26002[0m[0m | time: 244.546s
[2K
| Adam | epoch: 005 | loss: 0.26002 - acc: 0.9100 -- iter: 0928/1554
[A[ATraining Step: 226  | total loss: [1m[32m0.24405[0m[0m | time: 252.454s
[2K
| Adam | epoch: 005 | loss: 0.24405 - acc: 0.9127 -- iter: 0960/1554
[A[ATraining Step: 227  | total loss: [1m[32m0.23282[0m[0m | time: 260.211s
[2K
| Adam | epoch: 005 | loss: 0.23282 - acc: 0.9152 -- iter: 0992/1554
[A[ATraining Step: 228  | total loss: [1m[32m0.21642[0m[0m | time: 268.110s
[2K
| Adam | epoch: 005 | loss: 0.21642 - acc: 0.9237 -- iter: 1024/1554
[A[ATraining Step: 229  | total loss: [1m[32m0.21745[0m[0m | time: 275.961s
[2K
| Adam | epoch: 005 | loss: 0.21745 - acc: 0.9251 -- iter: 1056/1554
[A[ATraining Step: 230  | total loss: [1m[32m0.20979[0m[0m | time: 283.760s
[2K
| Adam | epoch: 005 | loss: 0.20979 - acc: 0.9294 -- iter: 1088/1554
[A[ATraining Step: 231  | total loss: [1m[32m0.20713[0m[0m | time: 291.539s
[2K
| Adam | epoch: 005 | loss: 0.20713 - acc: 0.9302 -- iter: 1120/1554
[A[ATraining Step: 232  | total loss: [1m[32m0.18927[0m[0m | time: 299.366s
[2K
| Adam | epoch: 005 | loss: 0.18927 - acc: 0.9372 -- iter: 1152/1554
[A[ATraining Step: 233  | total loss: [1m[32m0.18158[0m[0m | time: 307.322s
[2K
| Adam | epoch: 005 | loss: 0.18158 - acc: 0.9404 -- iter: 1184/1554
[A[ATraining Step: 234  | total loss: [1m[32m0.17659[0m[0m | time: 315.379s
[2K
| Adam | epoch: 005 | loss: 0.17659 - acc: 0.9432 -- iter: 1216/1554
[A[ATraining Step: 235  | total loss: [1m[32m0.16887[0m[0m | time: 323.177s
[2K
| Adam | epoch: 005 | loss: 0.16887 - acc: 0.9426 -- iter: 1248/1554
[A[ATraining Step: 236  | total loss: [1m[32m0.18452[0m[0m | time: 331.114s
[2K
| Adam | epoch: 005 | loss: 0.18452 - acc: 0.9359 -- iter: 1280/1554
[A[ATraining Step: 237  | total loss: [1m[32m0.16819[0m[0m | time: 338.807s
[2K
| Adam | epoch: 005 | loss: 0.16819 - acc: 0.9423 -- iter: 1312/1554
[A[ATraining Step: 238  | total loss: [1m[32m0.16053[0m[0m | time: 346.709s
[2K
| Adam | epoch: 005 | loss: 0.16053 - acc: 0.9449 -- iter: 1344/1554
[A[ATraining Step: 239  | total loss: [1m[32m0.15105[0m[0m | time: 354.701s
[2K
| Adam | epoch: 005 | loss: 0.15105 - acc: 0.9473 -- iter: 1376/1554
[A[ATraining Step: 240  | total loss: [1m[32m0.14947[0m[0m | time: 362.503s
[2K
| Adam | epoch: 005 | loss: 0.14947 - acc: 0.9463 -- iter: 1408/1554
[A[ATraining Step: 241  | total loss: [1m[32m0.14811[0m[0m | time: 370.409s
[2K
| Adam | epoch: 005 | loss: 0.14811 - acc: 0.9486 -- iter: 1440/1554
[A[ATraining Step: 242  | total loss: [1m[32m0.16239[0m[0m | time: 378.292s
[2K
| Adam | epoch: 005 | loss: 0.16239 - acc: 0.9443 -- iter: 1472/1554
[A[ATraining Step: 243  | total loss: [1m[32m0.17204[0m[0m | time: 386.379s
[2K
| Adam | epoch: 005 | loss: 0.17204 - acc: 0.9405 -- iter: 1504/1554
[A[ATraining Step: 244  | total loss: [1m[32m0.16646[0m[0m | time: 394.226s
[2K
| Adam | epoch: 005 | loss: 0.16646 - acc: 0.9402 -- iter: 1536/1554
[A[ATraining Step: 245  | total loss: [1m[32m0.16050[0m[0m | time: 423.468s
[2K
| Adam | epoch: 005 | loss: 0.16050 - acc: 0.9400 | val_loss: 0.66434 - val_acc: 0.7922 -- iter: 1554/1554
--
Training Step: 246  | total loss: [1m[32m0.16645[0m[0m | time: 7.871s
[2K
| Adam | epoch: 006 | loss: 0.16645 - acc: 0.9428 -- iter: 0032/1554
[A[ATraining Step: 247  | total loss: [1m[32m0.15658[0m[0m | time: 15.689s
[2K
| Adam | epoch: 006 | loss: 0.15658 - acc: 0.9454 -- iter: 0064/1554
[A[ATraining Step: 248  | total loss: [1m[32m0.14798[0m[0m | time: 23.456s
[2K
| Adam | epoch: 006 | loss: 0.14798 - acc: 0.9509 -- iter: 0096/1554
[A[ATraining Step: 249  | total loss: [1m[32m0.14445[0m[0m | time: 28.482s
[2K
| Adam | epoch: 006 | loss: 0.14445 - acc: 0.9495 -- iter: 0128/1554
[A[ATraining Step: 250  | total loss: [1m[32m0.16675[0m[0m | time: 33.594s
[2K
| Adam | epoch: 006 | loss: 0.16675 - acc: 0.9435 -- iter: 0160/1554
[A[ATraining Step: 251  | total loss: [1m[32m0.15513[0m[0m | time: 41.440s
[2K
| Adam | epoch: 006 | loss: 0.15513 - acc: 0.9491 -- iter: 0192/1554
[A[ATraining Step: 252  | total loss: [1m[32m0.16959[0m[0m | time: 49.475s
[2K
| Adam | epoch: 006 | loss: 0.16959 - acc: 0.9511 -- iter: 0224/1554
[A[ATraining Step: 253  | total loss: [1m[32m0.16230[0m[0m | time: 57.321s
[2K
| Adam | epoch: 006 | loss: 0.16230 - acc: 0.9529 -- iter: 0256/1554
[A[ATraining Step: 254  | total loss: [1m[32m0.16045[0m[0m | time: 65.272s
[2K
| Adam | epoch: 006 | loss: 0.16045 - acc: 0.9544 -- iter: 0288/1554
[A[ATraining Step: 255  | total loss: [1m[32m0.15640[0m[0m | time: 73.185s
[2K
| Adam | epoch: 006 | loss: 0.15640 - acc: 0.9528 -- iter: 0320/1554
[A[ATraining Step: 256  | total loss: [1m[32m0.16434[0m[0m | time: 81.131s
[2K
| Adam | epoch: 006 | loss: 0.16434 - acc: 0.9512 -- iter: 0352/1554
[A[ATraining Step: 257  | total loss: [1m[32m0.16809[0m[0m | time: 88.806s
[2K
| Adam | epoch: 006 | loss: 0.16809 - acc: 0.9467 -- iter: 0384/1554
[A[ATraining Step: 258  | total loss: [1m[32m0.16484[0m[0m | time: 96.629s
[2K
| Adam | epoch: 006 | loss: 0.16484 - acc: 0.9458 -- iter: 0416/1554
[A[ATraining Step: 259  | total loss: [1m[32m0.16926[0m[0m | time: 104.580s
[2K
| Adam | epoch: 006 | loss: 0.16926 - acc: 0.9419 -- iter: 0448/1554
[A[ATraining Step: 260  | total loss: [1m[32m0.17349[0m[0m | time: 112.402s
[2K
| Adam | epoch: 006 | loss: 0.17349 - acc: 0.9383 -- iter: 0480/1554
[A[ATraining Step: 261  | total loss: [1m[32m0.19558[0m[0m | time: 120.339s
[2K
| Adam | epoch: 006 | loss: 0.19558 - acc: 0.9320 -- iter: 0512/1554
[A[ATraining Step: 262  | total loss: [1m[32m0.21090[0m[0m | time: 128.266s
[2K
| Adam | epoch: 006 | loss: 0.21090 - acc: 0.9294 -- iter: 0544/1554
[A[ATraining Step: 263  | total loss: [1m[32m0.21124[0m[0m | time: 136.247s
[2K
| Adam | epoch: 006 | loss: 0.21124 - acc: 0.9333 -- iter: 0576/1554
[A[ATraining Step: 264  | total loss: [1m[32m0.20710[0m[0m | time: 144.100s
[2K
| Adam | epoch: 006 | loss: 0.20710 - acc: 0.9306 -- iter: 0608/1554
[A[ATraining Step: 265  | total loss: [1m[32m0.20296[0m[0m | time: 152.099s
[2K
| Adam | epoch: 006 | loss: 0.20296 - acc: 0.9282 -- iter: 0640/1554
[A[ATraining Step: 266  | total loss: [1m[32m0.19216[0m[0m | time: 160.081s
[2K
| Adam | epoch: 006 | loss: 0.19216 - acc: 0.9354 -- iter: 0672/1554
[A[ATraining Step: 267  | total loss: [1m[32m0.20169[0m[0m | time: 168.015s
[2K
| Adam | epoch: 006 | loss: 0.20169 - acc: 0.9293 -- iter: 0704/1554
[A[ATraining Step: 268  | total loss: [1m[32m0.22160[0m[0m | time: 175.886s
[2K
| Adam | epoch: 006 | loss: 0.22160 - acc: 0.9239 -- iter: 0736/1554
[A[ATraining Step: 269  | total loss: [1m[32m0.20903[0m[0m | time: 183.739s
[2K
| Adam | epoch: 006 | loss: 0.20903 - acc: 0.9284 -- iter: 0768/1554
[A[ATraining Step: 270  | total loss: [1m[32m0.21653[0m[0m | time: 191.553s
[2K
| Adam | epoch: 006 | loss: 0.21653 - acc: 0.9230 -- iter: 0800/1554
[A[ATraining Step: 271  | total loss: [1m[32m0.20713[0m[0m | time: 199.472s
[2K
| Adam | epoch: 006 | loss: 0.20713 - acc: 0.9276 -- iter: 0832/1554
[A[ATraining Step: 272  | total loss: [1m[32m0.19421[0m[0m | time: 207.387s
[2K
| Adam | epoch: 006 | loss: 0.19421 - acc: 0.9317 -- iter: 0864/1554
[A[ATraining Step: 273  | total loss: [1m[32m0.18992[0m[0m | time: 215.354s
[2K
| Adam | epoch: 006 | loss: 0.18992 - acc: 0.9323 -- iter: 0896/1554
[A[ATraining Step: 274  | total loss: [1m[32m0.20238[0m[0m | time: 223.142s
[2K
| Adam | epoch: 006 | loss: 0.20238 - acc: 0.9266 -- iter: 0928/1554
[A[ATraining Step: 275  | total loss: [1m[32m0.19418[0m[0m | time: 230.981s
[2K
| Adam | epoch: 006 | loss: 0.19418 - acc: 0.9308 -- iter: 0960/1554
[A[ATraining Step: 276  | total loss: [1m[32m0.18061[0m[0m | time: 238.734s
[2K
| Adam | epoch: 006 | loss: 0.18061 - acc: 0.9346 -- iter: 0992/1554
[A[ATraining Step: 277  | total loss: [1m[32m0.17283[0m[0m | time: 246.563s
[2K
| Adam | epoch: 006 | loss: 0.17283 - acc: 0.9349 -- iter: 1024/1554
[A[ATraining Step: 278  | total loss: [1m[32m0.16120[0m[0m | time: 254.502s
[2K
| Adam | epoch: 006 | loss: 0.16120 - acc: 0.9383 -- iter: 1056/1554
[A[ATraining Step: 279  | total loss: [1m[32m0.15665[0m[0m | time: 262.560s
[2K
| Adam | epoch: 006 | loss: 0.15665 - acc: 0.9413 -- iter: 1088/1554
[A[ATraining Step: 280  | total loss: [1m[32m0.15697[0m[0m | time: 270.497s
[2K
| Adam | epoch: 006 | loss: 0.15697 - acc: 0.9409 -- iter: 1120/1554
[A[ATraining Step: 281  | total loss: [1m[32m0.14695[0m[0m | time: 278.473s
[2K
| Adam | epoch: 006 | loss: 0.14695 - acc: 0.9468 -- iter: 1152/1554
[A[ATraining Step: 282  | total loss: [1m[32m0.14582[0m[0m | time: 286.532s
[2K
| Adam | epoch: 006 | loss: 0.14582 - acc: 0.9428 -- iter: 1184/1554
[A[ATraining Step: 283  | total loss: [1m[32m0.14025[0m[0m | time: 294.500s
[2K
| Adam | epoch: 006 | loss: 0.14025 - acc: 0.9454 -- iter: 1216/1554
[A[ATraining Step: 284  | total loss: [1m[32m0.13381[0m[0m | time: 302.473s
[2K
| Adam | epoch: 006 | loss: 0.13381 - acc: 0.9477 -- iter: 1248/1554
[A[ATraining Step: 285  | total loss: [1m[32m0.12580[0m[0m | time: 310.284s
[2K
| Adam | epoch: 006 | loss: 0.12580 - acc: 0.9529 -- iter: 1280/1554
[A[ATraining Step: 286  | total loss: [1m[32m0.12075[0m[0m | time: 318.157s
[2K
| Adam | epoch: 006 | loss: 0.12075 - acc: 0.9545 -- iter: 1312/1554
[A[ATraining Step: 287  | total loss: [1m[32m0.13482[0m[0m | time: 326.111s
[2K
| Adam | epoch: 006 | loss: 0.13482 - acc: 0.9528 -- iter: 1344/1554
[A[ATraining Step: 288  | total loss: [1m[32m0.12318[0m[0m | time: 334.260s
[2K
| Adam | epoch: 006 | loss: 0.12318 - acc: 0.9575 -- iter: 1376/1554
[A[ATraining Step: 289  | total loss: [1m[32m0.12018[0m[0m | time: 342.035s
[2K
| Adam | epoch: 006 | loss: 0.12018 - acc: 0.9555 -- iter: 1408/1554
[A[ATraining Step: 290  | total loss: [1m[32m0.11122[0m[0m | time: 349.869s
[2K
| Adam | epoch: 006 | loss: 0.11122 - acc: 0.9600 -- iter: 1440/1554
[A[ATraining Step: 291  | total loss: [1m[32m0.10796[0m[0m | time: 357.769s
[2K
| Adam | epoch: 006 | loss: 0.10796 - acc: 0.9640 -- iter: 1472/1554
[A[ATraining Step: 292  | total loss: [1m[32m0.09944[0m[0m | time: 365.741s
[2K
| Adam | epoch: 006 | loss: 0.09944 - acc: 0.9676 -- iter: 1504/1554
[A[ATraining Step: 293  | total loss: [1m[32m0.10205[0m[0m | time: 373.571s
[2K
| Adam | epoch: 006 | loss: 0.10205 - acc: 0.9646 -- iter: 1536/1554
[A[ATraining Step: 294  | total loss: [1m[32m0.10403[0m[0m | time: 402.597s
[2K
| Adam | epoch: 006 | loss: 0.10403 - acc: 0.9650 | val_loss: 0.36001 - val_acc: 0.8683 -- iter: 1554/1554
--
Training Step: 295  | total loss: [1m[32m0.10091[0m[0m | time: 7.703s
[2K
| Adam | epoch: 007 | loss: 0.10091 - acc: 0.9654 -- iter: 0032/1554
[A[ATraining Step: 296  | total loss: [1m[32m0.09768[0m[0m | time: 15.577s
[2K
| Adam | epoch: 007 | loss: 0.09768 - acc: 0.9657 -- iter: 0064/1554
[A[ATraining Step: 297  | total loss: [1m[32m0.09483[0m[0m | time: 23.454s
[2K
| Adam | epoch: 007 | loss: 0.09483 - acc: 0.9629 -- iter: 0096/1554
[A[ATraining Step: 298  | total loss: [1m[32m0.08891[0m[0m | time: 31.486s
[2K
| Adam | epoch: 007 | loss: 0.08891 - acc: 0.9635 -- iter: 0128/1554
[A[ATraining Step: 299  | total loss: [1m[32m0.08435[0m[0m | time: 36.425s
[2K
| Adam | epoch: 007 | loss: 0.08435 - acc: 0.9671 -- iter: 0160/1554
[A[ATraining Step: 300  | total loss: [1m[32m0.10334[0m[0m | time: 41.454s
[2K
| Adam | epoch: 007 | loss: 0.10334 - acc: 0.9537 -- iter: 0192/1554
[A[ATraining Step: 301  | total loss: [1m[32m0.10208[0m[0m | time: 49.214s
[2K
| Adam | epoch: 007 | loss: 0.10208 - acc: 0.9584 -- iter: 0224/1554
[A[ATraining Step: 302  | total loss: [1m[32m0.10187[0m[0m | time: 57.196s
[2K
| Adam | epoch: 007 | loss: 0.10187 - acc: 0.9563 -- iter: 0256/1554
[A[ATraining Step: 303  | total loss: [1m[32m0.09437[0m[0m | time: 64.978s
[2K
| Adam | epoch: 007 | loss: 0.09437 - acc: 0.9607 -- iter: 0288/1554
[A[ATraining Step: 304  | total loss: [1m[32m0.10469[0m[0m | time: 72.930s
[2K
| Adam | epoch: 007 | loss: 0.10469 - acc: 0.9552 -- iter: 0320/1554
[A[ATraining Step: 305  | total loss: [1m[32m0.10153[0m[0m | time: 80.797s
[2K
| Adam | epoch: 007 | loss: 0.10153 - acc: 0.9566 -- iter: 0352/1554
[A[ATraining Step: 306  | total loss: [1m[32m0.09486[0m[0m | time: 88.749s
[2K
| Adam | epoch: 007 | loss: 0.09486 - acc: 0.9578 -- iter: 0384/1554
[A[ATraining Step: 307  | total loss: [1m[32m0.09041[0m[0m | time: 96.721s
[2K
| Adam | epoch: 007 | loss: 0.09041 - acc: 0.9620 -- iter: 0416/1554
[A[ATraining Step: 308  | total loss: [1m[32m0.08865[0m[0m | time: 104.556s
[2K
| Adam | epoch: 007 | loss: 0.08865 - acc: 0.9627 -- iter: 0448/1554
[A[ATraining Step: 309  | total loss: [1m[32m0.08873[0m[0m | time: 112.476s
[2K
| Adam | epoch: 007 | loss: 0.08873 - acc: 0.9633 -- iter: 0480/1554
[A[ATraining Step: 310  | total loss: [1m[32m0.08953[0m[0m | time: 120.342s
[2K
| Adam | epoch: 007 | loss: 0.08953 - acc: 0.9638 -- iter: 0512/1554
[A[ATraining Step: 311  | total loss: [1m[32m0.09016[0m[0m | time: 128.307s
[2K
| Adam | epoch: 007 | loss: 0.09016 - acc: 0.9643 -- iter: 0544/1554
[A[ATraining Step: 312  | total loss: [1m[32m0.09033[0m[0m | time: 136.156s
[2K
| Adam | epoch: 007 | loss: 0.09033 - acc: 0.9648 -- iter: 0576/1554
[A[ATraining Step: 313  | total loss: [1m[32m0.10852[0m[0m | time: 143.940s
[2K
| Adam | epoch: 007 | loss: 0.10852 - acc: 0.9620 -- iter: 0608/1554
[A[ATraining Step: 314  | total loss: [1m[32m0.10916[0m[0m | time: 151.948s
[2K
| Adam | epoch: 007 | loss: 0.10916 - acc: 0.9627 -- iter: 0640/1554
[A[ATraining Step: 315  | total loss: [1m[32m0.10310[0m[0m | time: 159.957s
[2K
| Adam | epoch: 007 | loss: 0.10310 - acc: 0.9664 -- iter: 0672/1554
[A[ATraining Step: 316  | total loss: [1m[32m0.10476[0m[0m | time: 167.970s
[2K
| Adam | epoch: 007 | loss: 0.10476 - acc: 0.9635 -- iter: 0704/1554
[A[ATraining Step: 317  | total loss: [1m[32m0.10519[0m[0m | time: 175.789s
[2K
| Adam | epoch: 007 | loss: 0.10519 - acc: 0.9641 -- iter: 0736/1554
[A[ATraining Step: 318  | total loss: [1m[32m0.10547[0m[0m | time: 183.742s
[2K
| Adam | epoch: 007 | loss: 0.10547 - acc: 0.9614 -- iter: 0768/1554
[A[ATraining Step: 319  | total loss: [1m[32m0.09920[0m[0m | time: 191.715s
[2K
| Adam | epoch: 007 | loss: 0.09920 - acc: 0.9653 -- iter: 0800/1554
[A[ATraining Step: 320  | total loss: [1m[32m0.10000[0m[0m | time: 199.615s
[2K
| Adam | epoch: 007 | loss: 0.10000 - acc: 0.9625 -- iter: 0832/1554
[A[ATraining Step: 321  | total loss: [1m[32m0.11196[0m[0m | time: 207.415s
[2K
| Adam | epoch: 007 | loss: 0.11196 - acc: 0.9600 -- iter: 0864/1554
[A[ATraining Step: 322  | total loss: [1m[32m0.10303[0m[0m | time: 215.308s
[2K
| Adam | epoch: 007 | loss: 0.10303 - acc: 0.9640 -- iter: 0896/1554
[A[ATraining Step: 323  | total loss: [1m[32m0.09870[0m[0m | time: 223.146s
[2K
| Adam | epoch: 007 | loss: 0.09870 - acc: 0.9645 -- iter: 0928/1554
[A[ATraining Step: 324  | total loss: [1m[32m0.09027[0m[0m | time: 230.995s
[2K
| Adam | epoch: 007 | loss: 0.09027 - acc: 0.9680 -- iter: 0960/1554
[A[ATraining Step: 325  | total loss: [1m[32m0.08811[0m[0m | time: 238.889s
[2K
| Adam | epoch: 007 | loss: 0.08811 - acc: 0.9681 -- iter: 0992/1554
[A[ATraining Step: 326  | total loss: [1m[32m0.08272[0m[0m | time: 246.698s
[2K
| Adam | epoch: 007 | loss: 0.08272 - acc: 0.9713 -- iter: 1024/1554
[A[ATraining Step: 327  | total loss: [1m[32m0.07698[0m[0m | time: 254.711s
[2K
| Adam | epoch: 007 | loss: 0.07698 - acc: 0.9742 -- iter: 1056/1554
[A[ATraining Step: 328  | total loss: [1m[32m0.09142[0m[0m | time: 262.508s
[2K
| Adam | epoch: 007 | loss: 0.09142 - acc: 0.9705 -- iter: 1088/1554
[A[ATraining Step: 329  | total loss: [1m[32m0.08457[0m[0m | time: 270.448s
[2K
| Adam | epoch: 007 | loss: 0.08457 - acc: 0.9734 -- iter: 1120/1554
[A[ATraining Step: 330  | total loss: [1m[32m0.07895[0m[0m | time: 278.271s
[2K
| Adam | epoch: 007 | loss: 0.07895 - acc: 0.9761 -- iter: 1152/1554
[A[ATraining Step: 331  | total loss: [1m[32m0.07309[0m[0m | time: 286.194s
[2K
| Adam | epoch: 007 | loss: 0.07309 - acc: 0.9785 -- iter: 1184/1554
[A[ATraining Step: 332  | total loss: [1m[32m0.08053[0m[0m | time: 294.020s
[2K
| Adam | epoch: 007 | loss: 0.08053 - acc: 0.9744 -- iter: 1216/1554
[A[ATraining Step: 333  | total loss: [1m[32m0.07373[0m[0m | time: 301.957s
[2K
| Adam | epoch: 007 | loss: 0.07373 - acc: 0.9770 -- iter: 1248/1554
[A[ATraining Step: 334  | total loss: [1m[32m0.07350[0m[0m | time: 309.850s
[2K
| Adam | epoch: 007 | loss: 0.07350 - acc: 0.9761 -- iter: 1280/1554
[A[ATraining Step: 335  | total loss: [1m[32m0.06891[0m[0m | time: 317.792s
[2K
| Adam | epoch: 007 | loss: 0.06891 - acc: 0.9785 -- iter: 1312/1554
[A[ATraining Step: 336  | total loss: [1m[32m0.06390[0m[0m | time: 325.695s
[2K
| Adam | epoch: 007 | loss: 0.06390 - acc: 0.9807 -- iter: 1344/1554
[A[ATraining Step: 337  | total loss: [1m[32m0.06293[0m[0m | time: 333.706s
[2K
| Adam | epoch: 007 | loss: 0.06293 - acc: 0.9795 -- iter: 1376/1554
[A[ATraining Step: 338  | total loss: [1m[32m0.07301[0m[0m | time: 341.819s
[2K
| Adam | epoch: 007 | loss: 0.07301 - acc: 0.9690 -- iter: 1408/1554
[A[ATraining Step: 339  | total loss: [1m[32m0.07835[0m[0m | time: 349.650s
[2K
| Adam | epoch: 007 | loss: 0.07835 - acc: 0.9690 -- iter: 1440/1554
[A[ATraining Step: 340  | total loss: [1m[32m0.07299[0m[0m | time: 357.361s
[2K
| Adam | epoch: 007 | loss: 0.07299 - acc: 0.9721 -- iter: 1472/1554
[A[ATraining Step: 341  | total loss: [1m[32m0.07385[0m[0m | time: 365.053s
[2K
| Adam | epoch: 007 | loss: 0.07385 - acc: 0.9686 -- iter: 1504/1554
[A[ATraining Step: 342  | total loss: [1m[32m0.10746[0m[0m | time: 372.961s
[2K
| Adam | epoch: 007 | loss: 0.10746 - acc: 0.9655 -- iter: 1536/1554
[A[ATraining Step: 343  | total loss: [1m[32m0.09825[0m[0m | time: 402.220s
[2K
| Adam | epoch: 007 | loss: 0.09825 - acc: 0.9690 | val_loss: 1.15749 - val_acc: 0.7798 -- iter: 1554/1554
--
Training Step: 344  | total loss: [1m[32m0.09841[0m[0m | time: 8.189s
[2K
| Adam | epoch: 008 | loss: 0.09841 - acc: 0.9690 -- iter: 0032/1554
[A[ATraining Step: 345  | total loss: [1m[32m0.09844[0m[0m | time: 15.974s
[2K
| Adam | epoch: 008 | loss: 0.09844 - acc: 0.9658 -- iter: 0064/1554
[A[ATraining Step: 346  | total loss: [1m[32m0.09148[0m[0m | time: 23.859s
[2K
| Adam | epoch: 008 | loss: 0.09148 - acc: 0.9692 -- iter: 0096/1554
[A[ATraining Step: 347  | total loss: [1m[32m0.08873[0m[0m | time: 31.622s
[2K
| Adam | epoch: 008 | loss: 0.08873 - acc: 0.9723 -- iter: 0128/1554
[A[ATraining Step: 348  | total loss: [1m[32m0.08395[0m[0m | time: 39.414s
[2K
| Adam | epoch: 008 | loss: 0.08395 - acc: 0.9719 -- iter: 0160/1554
[A[ATraining Step: 349  | total loss: [1m[32m0.09716[0m[0m | time: 44.442s
[2K
| Adam | epoch: 008 | loss: 0.09716 - acc: 0.9685 -- iter: 0192/1554
[A[ATraining Step: 350  | total loss: [1m[32m0.09223[0m[0m | time: 49.492s
[2K
| Adam | epoch: 008 | loss: 0.09223 - acc: 0.9661 -- iter: 0224/1554
[A[ATraining Step: 351  | total loss: [1m[32m0.08348[0m[0m | time: 57.350s
[2K
| Adam | epoch: 008 | loss: 0.08348 - acc: 0.9695 -- iter: 0256/1554
[A[ATraining Step: 352  | total loss: [1m[32m0.07808[0m[0m | time: 65.202s
[2K
| Adam | epoch: 008 | loss: 0.07808 - acc: 0.9725 -- iter: 0288/1554
[A[ATraining Step: 353  | total loss: [1m[32m0.07558[0m[0m | time: 73.133s
[2K
| Adam | epoch: 008 | loss: 0.07558 - acc: 0.9722 -- iter: 0320/1554
[A[ATraining Step: 354  | total loss: [1m[32m0.08328[0m[0m | time: 81.030s
[2K
| Adam | epoch: 008 | loss: 0.08328 - acc: 0.9656 -- iter: 0352/1554
[A[ATraining Step: 355  | total loss: [1m[32m0.10958[0m[0m | time: 88.979s
[2K
| Adam | epoch: 008 | loss: 0.10958 - acc: 0.9534 -- iter: 0384/1554
[A[ATraining Step: 356  | total loss: [1m[32m0.10054[0m[0m | time: 96.877s
[2K
| Adam | epoch: 008 | loss: 0.10054 - acc: 0.9580 -- iter: 0416/1554
[A[ATraining Step: 357  | total loss: [1m[32m0.09981[0m[0m | time: 104.690s
[2K
| Adam | epoch: 008 | loss: 0.09981 - acc: 0.9560 -- iter: 0448/1554
[A[ATraining Step: 358  | total loss: [1m[32m0.11258[0m[0m | time: 112.428s
[2K
| Adam | epoch: 008 | loss: 0.11258 - acc: 0.9479 -- iter: 0480/1554
[A[ATraining Step: 359  | total loss: [1m[32m0.11207[0m[0m | time: 120.286s
[2K
| Adam | epoch: 008 | loss: 0.11207 - acc: 0.9469 -- iter: 0512/1554
[A[ATraining Step: 360  | total loss: [1m[32m0.10951[0m[0m | time: 128.072s
[2K
| Adam | epoch: 008 | loss: 0.10951 - acc: 0.9490 -- iter: 0544/1554
[A[ATraining Step: 361  | total loss: [1m[32m0.10282[0m[0m | time: 136.037s
[2K
| Adam | epoch: 008 | loss: 0.10282 - acc: 0.9541 -- iter: 0576/1554
[A[ATraining Step: 362  | total loss: [1m[32m0.09480[0m[0m | time: 143.901s
[2K
| Adam | epoch: 008 | loss: 0.09480 - acc: 0.9587 -- iter: 0608/1554
[A[ATraining Step: 363  | total loss: [1m[32m0.09608[0m[0m | time: 152.027s
[2K
| Adam | epoch: 008 | loss: 0.09608 - acc: 0.9566 -- iter: 0640/1554
[A[ATraining Step: 364  | total loss: [1m[32m0.09562[0m[0m | time: 159.786s
[2K
| Adam | epoch: 008 | loss: 0.09562 - acc: 0.9547 -- iter: 0672/1554
[A[ATraining Step: 365  | total loss: [1m[32m0.09402[0m[0m | time: 167.736s
[2K
| Adam | epoch: 008 | loss: 0.09402 - acc: 0.9592 -- iter: 0704/1554
[A[ATraining Step: 366  | total loss: [1m[32m0.08692[0m[0m | time: 175.761s
[2K
| Adam | epoch: 008 | loss: 0.08692 - acc: 0.9633 -- iter: 0736/1554
[A[ATraining Step: 367  | total loss: [1m[32m0.08948[0m[0m | time: 183.640s
[2K
| Adam | epoch: 008 | loss: 0.08948 - acc: 0.9607 -- iter: 0768/1554
[A[ATraining Step: 368  | total loss: [1m[32m0.08555[0m[0m | time: 191.656s
[2K
| Adam | epoch: 008 | loss: 0.08555 - acc: 0.9646 -- iter: 0800/1554
[A[ATraining Step: 369  | total loss: [1m[32m0.08316[0m[0m | time: 199.428s
[2K
| Adam | epoch: 008 | loss: 0.08316 - acc: 0.9682 -- iter: 0832/1554
[A[ATraining Step: 370  | total loss: [1m[32m0.08149[0m[0m | time: 207.332s
[2K
| Adam | epoch: 008 | loss: 0.08149 - acc: 0.9651 -- iter: 0864/1554
[A[ATraining Step: 371  | total loss: [1m[32m0.08440[0m[0m | time: 215.299s
[2K
| Adam | epoch: 008 | loss: 0.08440 - acc: 0.9655 -- iter: 0896/1554
[A[ATraining Step: 372  | total loss: [1m[32m0.07677[0m[0m | time: 223.219s
[2K
| Adam | epoch: 008 | loss: 0.07677 - acc: 0.9689 -- iter: 0928/1554
[A[ATraining Step: 373  | total loss: [1m[32m0.07248[0m[0m | time: 231.004s
[2K
| Adam | epoch: 008 | loss: 0.07248 - acc: 0.9720 -- iter: 0960/1554
[A[ATraining Step: 374  | total loss: [1m[32m0.06827[0m[0m | time: 238.799s
[2K
| Adam | epoch: 008 | loss: 0.06827 - acc: 0.9717 -- iter: 0992/1554
[A[ATraining Step: 375  | total loss: [1m[32m0.07161[0m[0m | time: 246.661s
[2K
| Adam | epoch: 008 | loss: 0.07161 - acc: 0.9683 -- iter: 1024/1554
[A[ATraining Step: 376  | total loss: [1m[32m0.06746[0m[0m | time: 254.520s
[2K
| Adam | epoch: 008 | loss: 0.06746 - acc: 0.9715 -- iter: 1056/1554
[A[ATraining Step: 377  | total loss: [1m[32m0.06617[0m[0m | time: 262.505s
[2K
| Adam | epoch: 008 | loss: 0.06617 - acc: 0.9743 -- iter: 1088/1554
[A[ATraining Step: 378  | total loss: [1m[32m0.06467[0m[0m | time: 270.236s
[2K
| Adam | epoch: 008 | loss: 0.06467 - acc: 0.9738 -- iter: 1120/1554
[A[ATraining Step: 379  | total loss: [1m[32m0.06114[0m[0m | time: 277.980s
[2K
| Adam | epoch: 008 | loss: 0.06114 - acc: 0.9764 -- iter: 1152/1554
[A[ATraining Step: 380  | total loss: [1m[32m0.05683[0m[0m | time: 285.852s
[2K
| Adam | epoch: 008 | loss: 0.05683 - acc: 0.9787 -- iter: 1184/1554
[A[ATraining Step: 381  | total loss: [1m[32m0.05192[0m[0m | time: 293.726s
[2K
| Adam | epoch: 008 | loss: 0.05192 - acc: 0.9809 -- iter: 1216/1554
[A[ATraining Step: 382  | total loss: [1m[32m0.06173[0m[0m | time: 301.682s
[2K
| Adam | epoch: 008 | loss: 0.06173 - acc: 0.9734 -- iter: 1248/1554
[A[ATraining Step: 383  | total loss: [1m[32m0.06215[0m[0m | time: 309.510s
[2K
| Adam | epoch: 008 | loss: 0.06215 - acc: 0.9698 -- iter: 1280/1554
[A[ATraining Step: 384  | total loss: [1m[32m0.05656[0m[0m | time: 317.477s
[2K
| Adam | epoch: 008 | loss: 0.05656 - acc: 0.9728 -- iter: 1312/1554
[A[ATraining Step: 385  | total loss: [1m[32m0.05196[0m[0m | time: 325.421s
[2K
| Adam | epoch: 008 | loss: 0.05196 - acc: 0.9756 -- iter: 1344/1554
[A[ATraining Step: 386  | total loss: [1m[32m0.05437[0m[0m | time: 333.181s
[2K
| Adam | epoch: 008 | loss: 0.05437 - acc: 0.9749 -- iter: 1376/1554
[A[ATraining Step: 387  | total loss: [1m[32m0.05223[0m[0m | time: 341.076s
[2K
| Adam | epoch: 008 | loss: 0.05223 - acc: 0.9774 -- iter: 1408/1554
[A[ATraining Step: 388  | total loss: [1m[32m0.05132[0m[0m | time: 348.868s
[2K
| Adam | epoch: 008 | loss: 0.05132 - acc: 0.9796 -- iter: 1440/1554
[A[ATraining Step: 389  | total loss: [1m[32m0.04851[0m[0m | time: 356.676s
[2K
| Adam | epoch: 008 | loss: 0.04851 - acc: 0.9817 -- iter: 1472/1554
[A[ATraining Step: 390  | total loss: [1m[32m0.05791[0m[0m | time: 364.614s
[2K
| Adam | epoch: 008 | loss: 0.05791 - acc: 0.9804 -- iter: 1504/1554
[A[ATraining Step: 391  | total loss: [1m[32m0.06286[0m[0m | time: 372.442s
[2K
| Adam | epoch: 008 | loss: 0.06286 - acc: 0.9761 -- iter: 1536/1554
[A[ATraining Step: 392  | total loss: [1m[32m0.05775[0m[0m | time: 401.653s
[2K
| Adam | epoch: 008 | loss: 0.05775 - acc: 0.9785 | val_loss: 0.65643 - val_acc: 0.8128 -- iter: 1554/1554
--
Training Step: 393  | total loss: [1m[32m0.05767[0m[0m | time: 7.902s
[2K
| Adam | epoch: 009 | loss: 0.05767 - acc: 0.9775 -- iter: 0032/1554
[A[ATraining Step: 394  | total loss: [1m[32m0.05257[0m[0m | time: 15.720s
[2K
| Adam | epoch: 009 | loss: 0.05257 - acc: 0.9798 -- iter: 0064/1554
[A[ATraining Step: 395  | total loss: [1m[32m0.04773[0m[0m | time: 23.538s
[2K
| Adam | epoch: 009 | loss: 0.04773 - acc: 0.9818 -- iter: 0096/1554
[A[ATraining Step: 396  | total loss: [1m[32m0.05062[0m[0m | time: 31.490s
[2K
| Adam | epoch: 009 | loss: 0.05062 - acc: 0.9805 -- iter: 0128/1554
[A[ATraining Step: 397  | total loss: [1m[32m0.04781[0m[0m | time: 39.202s
[2K
| Adam | epoch: 009 | loss: 0.04781 - acc: 0.9824 -- iter: 0160/1554
[A[ATraining Step: 398  | total loss: [1m[32m0.04511[0m[0m | time: 47.049s
[2K
| Adam | epoch: 009 | loss: 0.04511 - acc: 0.9842 -- iter: 0192/1554
[A[ATraining Step: 399  | total loss: [1m[32m0.06044[0m[0m | time: 51.998s
[2K
| Adam | epoch: 009 | loss: 0.06044 - acc: 0.9795 -- iter: 0224/1554
[A[ATraining Step: 400  | total loss: [1m[32m0.05531[0m[0m | time: 78.313s
[2K
| Adam | epoch: 009 | loss: 0.05531 - acc: 0.9816 | val_loss: 1.01792 - val_acc: 0.6996 -- iter: 0256/1554
--
Training Step: 401  | total loss: [1m[32m0.05047[0m[0m | time: 86.125s
[2K
| Adam | epoch: 009 | loss: 0.05047 - acc: 0.9834 -- iter: 0288/1554
[A[ATraining Step: 402  | total loss: [1m[32m0.05756[0m[0m | time: 94.147s
[2K
| Adam | epoch: 009 | loss: 0.05756 - acc: 0.9788 -- iter: 0320/1554
[A[ATraining Step: 403  | total loss: [1m[32m0.05652[0m[0m | time: 102.091s
[2K
| Adam | epoch: 009 | loss: 0.05652 - acc: 0.9778 -- iter: 0352/1554
[A[ATraining Step: 404  | total loss: [1m[32m0.05204[0m[0m | time: 109.959s
[2K
| Adam | epoch: 009 | loss: 0.05204 - acc: 0.9800 -- iter: 0384/1554
[A[ATraining Step: 405  | total loss: [1m[32m0.05050[0m[0m | time: 117.847s
[2K
| Adam | epoch: 009 | loss: 0.05050 - acc: 0.9820 -- iter: 0416/1554
[A[ATraining Step: 406  | total loss: [1m[32m0.06027[0m[0m | time: 125.583s
[2K
| Adam | epoch: 009 | loss: 0.06027 - acc: 0.9776 -- iter: 0448/1554
[A[ATraining Step: 407  | total loss: [1m[32m0.07303[0m[0m | time: 133.513s
[2K
| Adam | epoch: 009 | loss: 0.07303 - acc: 0.9736 -- iter: 0480/1554
[A[ATraining Step: 408  | total loss: [1m[32m0.07083[0m[0m | time: 141.363s
[2K
| Adam | epoch: 009 | loss: 0.07083 - acc: 0.9731 -- iter: 0512/1554
[A[ATraining Step: 409  | total loss: [1m[32m0.06423[0m[0m | time: 149.315s
[2K
| Adam | epoch: 009 | loss: 0.06423 - acc: 0.9758 -- iter: 0544/1554
[A[ATraining Step: 410  | total loss: [1m[32m0.06603[0m[0m | time: 157.163s
[2K
| Adam | epoch: 009 | loss: 0.06603 - acc: 0.9720 -- iter: 0576/1554
[A[ATraining Step: 411  | total loss: [1m[32m0.06295[0m[0m | time: 165.212s
[2K
| Adam | epoch: 009 | loss: 0.06295 - acc: 0.9748 -- iter: 0608/1554
[A[ATraining Step: 412  | total loss: [1m[32m0.05703[0m[0m | time: 173.034s
[2K
| Adam | epoch: 009 | loss: 0.05703 - acc: 0.9773 -- iter: 0640/1554
[A[ATraining Step: 413  | total loss: [1m[32m0.05499[0m[0m | time: 180.872s
[2K
| Adam | epoch: 009 | loss: 0.05499 - acc: 0.9796 -- iter: 0672/1554
[A[ATraining Step: 414  | total loss: [1m[32m0.07067[0m[0m | time: 188.857s
[2K
| Adam | epoch: 009 | loss: 0.07067 - acc: 0.9753 -- iter: 0704/1554
[A[ATraining Step: 415  | total loss: [1m[32m0.07811[0m[0m | time: 196.765s
[2K
| Adam | epoch: 009 | loss: 0.07811 - acc: 0.9684 -- iter: 0736/1554
[A[ATraining Step: 416  | total loss: [1m[32m0.07611[0m[0m | time: 204.608s
[2K
| Adam | epoch: 009 | loss: 0.07611 - acc: 0.9685 -- iter: 0768/1554
[A[ATraining Step: 417  | total loss: [1m[32m0.07081[0m[0m | time: 212.332s
[2K
| Adam | epoch: 009 | loss: 0.07081 - acc: 0.9716 -- iter: 0800/1554
[A[ATraining Step: 418  | total loss: [1m[32m0.11656[0m[0m | time: 220.280s
[2K
| Adam | epoch: 009 | loss: 0.11656 - acc: 0.9557 -- iter: 0832/1554
[A[ATraining Step: 419  | total loss: [1m[32m0.10583[0m[0m | time: 228.105s
[2K
| Adam | epoch: 009 | loss: 0.10583 - acc: 0.9601 -- iter: 0864/1554
[A[ATraining Step: 420  | total loss: [1m[32m0.10005[0m[0m | time: 236.045s
[2K
| Adam | epoch: 009 | loss: 0.10005 - acc: 0.9641 -- iter: 0896/1554
[A[ATraining Step: 421  | total loss: [1m[32m0.10682[0m[0m | time: 243.929s
[2K
| Adam | epoch: 009 | loss: 0.10682 - acc: 0.9615 -- iter: 0928/1554
[A[ATraining Step: 422  | total loss: [1m[32m0.10448[0m[0m | time: 251.733s
[2K
| Adam | epoch: 009 | loss: 0.10448 - acc: 0.9622 -- iter: 0960/1554
[A[ATraining Step: 423  | total loss: [1m[32m0.09713[0m[0m | time: 259.685s
[2K
| Adam | epoch: 009 | loss: 0.09713 - acc: 0.9628 -- iter: 0992/1554
[A[ATraining Step: 424  | total loss: [1m[32m0.09067[0m[0m | time: 267.468s
[2K
| Adam | epoch: 009 | loss: 0.09067 - acc: 0.9666 -- iter: 1024/1554
[A[ATraining Step: 425  | total loss: [1m[32m0.08248[0m[0m | time: 275.499s
[2K
| Adam | epoch: 009 | loss: 0.08248 - acc: 0.9699 -- iter: 1056/1554
[A[ATraining Step: 426  | total loss: [1m[32m0.07527[0m[0m | time: 283.218s
[2K
| Adam | epoch: 009 | loss: 0.07527 - acc: 0.9729 -- iter: 1088/1554
[A[ATraining Step: 427  | total loss: [1m[32m0.07603[0m[0m | time: 291.094s
[2K
| Adam | epoch: 009 | loss: 0.07603 - acc: 0.9694 -- iter: 1120/1554
[A[ATraining Step: 428  | total loss: [1m[32m0.06991[0m[0m | time: 298.924s
[2K
| Adam | epoch: 009 | loss: 0.06991 - acc: 0.9724 -- iter: 1152/1554
[A[ATraining Step: 429  | total loss: [1m[32m0.06788[0m[0m | time: 306.976s
[2K
| Adam | epoch: 009 | loss: 0.06788 - acc: 0.9721 -- iter: 1184/1554
[A[ATraining Step: 430  | total loss: [1m[32m0.06889[0m[0m | time: 314.846s
[2K
| Adam | epoch: 009 | loss: 0.06889 - acc: 0.9749 -- iter: 1216/1554
[A[ATraining Step: 431  | total loss: [1m[32m0.06399[0m[0m | time: 322.681s
[2K
| Adam | epoch: 009 | loss: 0.06399 - acc: 0.9774 -- iter: 1248/1554
[A[ATraining Step: 432  | total loss: [1m[32m0.05990[0m[0m | time: 330.287s
[2K
| Adam | epoch: 009 | loss: 0.05990 - acc: 0.9796 -- iter: 1280/1554
[A[ATraining Step: 433  | total loss: [1m[32m0.05569[0m[0m | time: 338.124s
[2K
| Adam | epoch: 009 | loss: 0.05569 - acc: 0.9817 -- iter: 1312/1554
[A[ATraining Step: 434  | total loss: [1m[32m0.05126[0m[0m | time: 345.938s
[2K
| Adam | epoch: 009 | loss: 0.05126 - acc: 0.9835 -- iter: 1344/1554
[A[ATraining Step: 435  | total loss: [1m[32m0.05037[0m[0m | time: 353.880s
[2K
| Adam | epoch: 009 | loss: 0.05037 - acc: 0.9852 -- iter: 1376/1554
[A[ATraining Step: 436  | total loss: [1m[32m0.05993[0m[0m | time: 361.604s
[2K
| Adam | epoch: 009 | loss: 0.05993 - acc: 0.9835 -- iter: 1408/1554
[A[ATraining Step: 437  | total loss: [1m[32m0.05827[0m[0m | time: 369.466s
[2K
| Adam | epoch: 009 | loss: 0.05827 - acc: 0.9852 -- iter: 1440/1554
[A[ATraining Step: 438  | total loss: [1m[32m0.05856[0m[0m | time: 377.325s
[2K
| Adam | epoch: 009 | loss: 0.05856 - acc: 0.9835 -- iter: 1472/1554
[A[ATraining Step: 439  | total loss: [1m[32m0.05866[0m[0m | time: 385.194s
[2K
| Adam | epoch: 009 | loss: 0.05866 - acc: 0.9820 -- iter: 1504/1554
[A[ATraining Step: 440  | total loss: [1m[32m0.05366[0m[0m | time: 393.143s
[2K
| Adam | epoch: 009 | loss: 0.05366 - acc: 0.9838 -- iter: 1536/1554
[A[ATraining Step: 441  | total loss: [1m[32m0.05014[0m[0m | time: 422.483s
[2K
| Adam | epoch: 009 | loss: 0.05014 - acc: 0.9855 | val_loss: 0.38007 - val_acc: 0.8745 -- iter: 1554/1554
--
Training Step: 442  | total loss: [1m[32m0.06231[0m[0m | time: 7.791s
[2K
| Adam | epoch: 010 | loss: 0.06231 - acc: 0.9838 -- iter: 0032/1554
[A[ATraining Step: 443  | total loss: [1m[32m0.06111[0m[0m | time: 15.411s
[2K
| Adam | epoch: 010 | loss: 0.06111 - acc: 0.9823 -- iter: 0064/1554
[A[ATraining Step: 444  | total loss: [1m[32m0.05529[0m[0m | time: 23.339s
[2K
| Adam | epoch: 010 | loss: 0.05529 - acc: 0.9841 -- iter: 0096/1554
[A[ATraining Step: 445  | total loss: [1m[32m0.05099[0m[0m | time: 31.120s
[2K
| Adam | epoch: 010 | loss: 0.05099 - acc: 0.9856 -- iter: 0128/1554
[A[ATraining Step: 446  | total loss: [1m[32m0.05001[0m[0m | time: 38.895s
[2K
| Adam | epoch: 010 | loss: 0.05001 - acc: 0.9871 -- iter: 0160/1554
[A[ATraining Step: 447  | total loss: [1m[32m0.05731[0m[0m | time: 46.788s
[2K
| Adam | epoch: 010 | loss: 0.05731 - acc: 0.9853 -- iter: 0192/1554
[A[ATraining Step: 448  | total loss: [1m[32m0.06140[0m[0m | time: 54.793s
[2K
| Adam | epoch: 010 | loss: 0.06140 - acc: 0.9805 -- iter: 0224/1554
[A[ATraining Step: 449  | total loss: [1m[32m0.05941[0m[0m | time: 59.790s
[2K
| Adam | epoch: 010 | loss: 0.05941 - acc: 0.9793 -- iter: 0256/1554
[A[ATraining Step: 450  | total loss: [1m[32m0.05499[0m[0m | time: 64.828s
[2K
| Adam | epoch: 010 | loss: 0.05499 - acc: 0.9814 -- iter: 0288/1554
[A[ATraining Step: 451  | total loss: [1m[32m0.05033[0m[0m | time: 72.586s
[2K
| Adam | epoch: 010 | loss: 0.05033 - acc: 0.9832 -- iter: 0320/1554
[A[ATraining Step: 452  | total loss: [1m[32m0.04673[0m[0m | time: 80.517s
[2K
| Adam | epoch: 010 | loss: 0.04673 - acc: 0.9849 -- iter: 0352/1554
[A[ATraining Step: 453  | total loss: [1m[32m0.04423[0m[0m | time: 88.249s
[2K
| Adam | epoch: 010 | loss: 0.04423 - acc: 0.9864 -- iter: 0384/1554
[A[ATraining Step: 454  | total loss: [1m[32m0.04245[0m[0m | time: 96.070s
[2K
| Adam | epoch: 010 | loss: 0.04245 - acc: 0.9878 -- iter: 0416/1554
[A[ATraining Step: 455  | total loss: [1m[32m0.09806[0m[0m | time: 103.898s
[2K
| Adam | epoch: 010 | loss: 0.09806 - acc: 0.9765 -- iter: 0448/1554
[A[ATraining Step: 456  | total loss: [1m[32m0.11205[0m[0m | time: 111.803s
[2K
| Adam | epoch: 010 | loss: 0.11205 - acc: 0.9664 -- iter: 0480/1554
[A[ATraining Step: 457  | total loss: [1m[32m0.10191[0m[0m | time: 119.703s
[2K
| Adam | epoch: 010 | loss: 0.10191 - acc: 0.9697 -- iter: 0512/1554
[A[ATraining Step: 458  | total loss: [1m[32m0.09296[0m[0m | time: 127.639s
[2K
| Adam | epoch: 010 | loss: 0.09296 - acc: 0.9727 -- iter: 0544/1554
[A[ATraining Step: 459  | total loss: [1m[32m0.10214[0m[0m | time: 135.597s
[2K
| Adam | epoch: 010 | loss: 0.10214 - acc: 0.9661 -- iter: 0576/1554
[A[ATraining Step: 460  | total loss: [1m[32m0.10157[0m[0m | time: 143.311s
[2K
| Adam | epoch: 010 | loss: 0.10157 - acc: 0.9664 -- iter: 0608/1554
[A[ATraining Step: 461  | total loss: [1m[32m0.11302[0m[0m | time: 151.079s
[2K
| Adam | epoch: 010 | loss: 0.11302 - acc: 0.9635 -- iter: 0640/1554
[A[ATraining Step: 462  | total loss: [1m[32m0.10847[0m[0m | time: 158.876s
[2K
| Adam | epoch: 010 | loss: 0.10847 - acc: 0.9640 -- iter: 0672/1554
[A[ATraining Step: 463  | total loss: [1m[32m0.10549[0m[0m | time: 166.765s
[2K
| Adam | epoch: 010 | loss: 0.10549 - acc: 0.9614 -- iter: 0704/1554
[A[ATraining Step: 464  | total loss: [1m[32m0.09945[0m[0m | time: 174.550s
[2K
| Adam | epoch: 010 | loss: 0.09945 - acc: 0.9621 -- iter: 0736/1554
[A[ATraining Step: 465  | total loss: [1m[32m0.10304[0m[0m | time: 182.608s
[2K
| Adam | epoch: 010 | loss: 0.10304 - acc: 0.9596 -- iter: 0768/1554
[A[ATraining Step: 466  | total loss: [1m[32m0.09999[0m[0m | time: 190.583s
[2K
| Adam | epoch: 010 | loss: 0.09999 - acc: 0.9605 -- iter: 0800/1554
[A[ATraining Step: 467  | total loss: [1m[32m0.09944[0m[0m | time: 198.471s
[2K
| Adam | epoch: 010 | loss: 0.09944 - acc: 0.9582 -- iter: 0832/1554
[A[ATraining Step: 468  | total loss: [1m[32m0.10980[0m[0m | time: 206.595s
[2K
| Adam | epoch: 010 | loss: 0.10980 - acc: 0.9562 -- iter: 0864/1554
[A[ATraining Step: 469  | total loss: [1m[32m0.10084[0m[0m | time: 214.503s
[2K
| Adam | epoch: 010 | loss: 0.10084 - acc: 0.9605 -- iter: 0896/1554
[A[ATraining Step: 470  | total loss: [1m[32m0.09447[0m[0m | time: 222.170s
[2K
| Adam | epoch: 010 | loss: 0.09447 - acc: 0.9645 -- iter: 0928/1554
[A[ATraining Step: 471  | total loss: [1m[32m0.09652[0m[0m | time: 229.923s
[2K
| Adam | epoch: 010 | loss: 0.09652 - acc: 0.9618 -- iter: 0960/1554
[A[ATraining Step: 472  | total loss: [1m[32m0.09886[0m[0m | time: 237.872s
[2K
| Adam | epoch: 010 | loss: 0.09886 - acc: 0.9594 -- iter: 0992/1554
[A[ATraining Step: 473  | total loss: [1m[32m0.09098[0m[0m | time: 245.695s
[2K
| Adam | epoch: 010 | loss: 0.09098 - acc: 0.9634 -- iter: 1024/1554
[A[ATraining Step: 474  | total loss: [1m[32m0.08332[0m[0m | time: 253.562s
[2K
| Adam | epoch: 010 | loss: 0.08332 - acc: 0.9671 -- iter: 1056/1554
[A[ATraining Step: 475  | total loss: [1m[32m0.08155[0m[0m | time: 261.547s
[2K
| Adam | epoch: 010 | loss: 0.08155 - acc: 0.9704 -- iter: 1088/1554
[A[ATraining Step: 476  | total loss: [1m[32m0.07597[0m[0m | time: 269.463s
[2K
| Adam | epoch: 010 | loss: 0.07597 - acc: 0.9733 -- iter: 1120/1554
[A[ATraining Step: 477  | total loss: [1m[32m0.07520[0m[0m | time: 277.318s
[2K
| Adam | epoch: 010 | loss: 0.07520 - acc: 0.9760 -- iter: 1152/1554
[A[ATraining Step: 478  | total loss: [1m[32m0.07383[0m[0m | time: 285.198s
[2K
| Adam | epoch: 010 | loss: 0.07383 - acc: 0.9753 -- iter: 1184/1554
[A[ATraining Step: 479  | total loss: [1m[32m0.06910[0m[0m | time: 293.092s
[2K
| Adam | epoch: 010 | loss: 0.06910 - acc: 0.9778 -- iter: 1216/1554
[A[ATraining Step: 480  | total loss: [1m[32m0.07875[0m[0m | time: 301.096s
[2K
| Adam | epoch: 010 | loss: 0.07875 - acc: 0.9706 -- iter: 1248/1554
[A[ATraining Step: 481  | total loss: [1m[32m0.07375[0m[0m | time: 308.960s
[2K
| Adam | epoch: 010 | loss: 0.07375 - acc: 0.9735 -- iter: 1280/1554
[A[ATraining Step: 482  | total loss: [1m[32m0.07012[0m[0m | time: 316.846s
[2K
| Adam | epoch: 010 | loss: 0.07012 - acc: 0.9762 -- iter: 1312/1554
[A[ATraining Step: 483  | total loss: [1m[32m0.06355[0m[0m | time: 324.763s
[2K
| Adam | epoch: 010 | loss: 0.06355 - acc: 0.9786 -- iter: 1344/1554
[A[ATraining Step: 484  | total loss: [1m[32m0.06360[0m[0m | time: 332.708s
[2K
| Adam | epoch: 010 | loss: 0.06360 - acc: 0.9776 -- iter: 1376/1554
[A[ATraining Step: 485  | total loss: [1m[32m0.09133[0m[0m | time: 340.684s
[2K
| Adam | epoch: 010 | loss: 0.09133 - acc: 0.9705 -- iter: 1408/1554
[A[ATraining Step: 486  | total loss: [1m[32m0.09448[0m[0m | time: 348.653s
[2K
| Adam | epoch: 010 | loss: 0.09448 - acc: 0.9703 -- iter: 1440/1554
[A[ATraining Step: 487  | total loss: [1m[32m0.09117[0m[0m | time: 356.552s
[2K
| Adam | epoch: 010 | loss: 0.09117 - acc: 0.9733 -- iter: 1472/1554
[A[ATraining Step: 488  | total loss: [1m[32m0.08433[0m[0m | time: 364.563s
[2K
| Adam | epoch: 010 | loss: 0.08433 - acc: 0.9759 -- iter: 1504/1554
[A[ATraining Step: 489  | total loss: [1m[32m0.07910[0m[0m | time: 372.300s
[2K
| Adam | epoch: 010 | loss: 0.07910 - acc: 0.9783 -- iter: 1536/1554
[A[ATraining Step: 490  | total loss: [1m[32m0.07233[0m[0m | time: 401.518s
[2K
| Adam | epoch: 010 | loss: 0.07233 - acc: 0.9805 | val_loss: 0.77057 - val_acc: 0.8210 -- iter: 1554/1554
--
Training Step: 491  | total loss: [1m[32m0.06868[0m[0m | time: 7.965s
[2K
| Adam | epoch: 011 | loss: 0.06868 - acc: 0.9825 -- iter: 0032/1554
[A[ATraining Step: 492  | total loss: [1m[32m0.06330[0m[0m | time: 15.811s
[2K
| Adam | epoch: 011 | loss: 0.06330 - acc: 0.9842 -- iter: 0064/1554
[A[ATraining Step: 493  | total loss: [1m[32m0.06095[0m[0m | time: 23.668s
[2K
| Adam | epoch: 011 | loss: 0.06095 - acc: 0.9858 -- iter: 0096/1554
[A[ATraining Step: 494  | total loss: [1m[32m0.05769[0m[0m | time: 31.520s
[2K
| Adam | epoch: 011 | loss: 0.05769 - acc: 0.9872 -- iter: 0128/1554
[A[ATraining Step: 495  | total loss: [1m[32m0.05250[0m[0m | time: 39.524s
[2K
| Adam | epoch: 011 | loss: 0.05250 - acc: 0.9885 -- iter: 0160/1554
[A[ATraining Step: 496  | total loss: [1m[32m0.05619[0m[0m | time: 47.409s
[2K
| Adam | epoch: 011 | loss: 0.05619 - acc: 0.9865 -- iter: 0192/1554
[A[ATraining Step: 497  | total loss: [1m[32m0.05126[0m[0m | time: 55.380s
[2K
| Adam | epoch: 011 | loss: 0.05126 - acc: 0.9879 -- iter: 0224/1554
[A[ATraining Step: 498  | total loss: [1m[32m0.04771[0m[0m | time: 63.156s
[2K
| Adam | epoch: 011 | loss: 0.04771 - acc: 0.9891 -- iter: 0256/1554
[A[ATraining Step: 499  | total loss: [1m[32m0.04654[0m[0m | time: 68.194s
[2K
| Adam | epoch: 011 | loss: 0.04654 - acc: 0.9902 -- iter: 0288/1554
[A[ATraining Step: 500  | total loss: [1m[32m0.04823[0m[0m | time: 73.195s
[2K
| Adam | epoch: 011 | loss: 0.04823 - acc: 0.9856 -- iter: 0320/1554
[A[ATraining Step: 501  | total loss: [1m[32m0.04426[0m[0m | time: 81.058s
[2K
| Adam | epoch: 011 | loss: 0.04426 - acc: 0.9870 -- iter: 0352/1554
[A[ATraining Step: 502  | total loss: [1m[32m0.04275[0m[0m | time: 88.968s
[2K
| Adam | epoch: 011 | loss: 0.04275 - acc: 0.9883 -- iter: 0384/1554
[A[ATraining Step: 503  | total loss: [1m[32m0.03919[0m[0m | time: 96.975s
[2K
| Adam | epoch: 011 | loss: 0.03919 - acc: 0.9895 -- iter: 0416/1554
[A[ATraining Step: 504  | total loss: [1m[32m0.03959[0m[0m | time: 104.961s
[2K
| Adam | epoch: 011 | loss: 0.03959 - acc: 0.9874 -- iter: 0448/1554
[A[ATraining Step: 505  | total loss: [1m[32m0.03983[0m[0m | time: 112.800s
[2K
| Adam | epoch: 011 | loss: 0.03983 - acc: 0.9856 -- iter: 0480/1554
[A[ATraining Step: 506  | total loss: [1m[32m0.04331[0m[0m | time: 120.652s
[2K
| Adam | epoch: 011 | loss: 0.04331 - acc: 0.9839 -- iter: 0512/1554
[A[ATraining Step: 507  | total loss: [1m[32m0.04266[0m[0m | time: 128.531s
[2K
| Adam | epoch: 011 | loss: 0.04266 - acc: 0.9855 -- iter: 0544/1554
[A[ATraining Step: 508  | total loss: [1m[32m0.04949[0m[0m | time: 136.391s
[2K
| Adam | epoch: 011 | loss: 0.04949 - acc: 0.9838 -- iter: 0576/1554
[A[ATraining Step: 509  | total loss: [1m[32m0.06461[0m[0m | time: 144.173s
[2K
| Adam | epoch: 011 | loss: 0.06461 - acc: 0.9761 -- iter: 0608/1554
[A[ATraining Step: 510  | total loss: [1m[32m0.08032[0m[0m | time: 151.983s
[2K
| Adam | epoch: 011 | loss: 0.08032 - acc: 0.9753 -- iter: 0640/1554
[A[ATraining Step: 511  | total loss: [1m[32m0.07831[0m[0m | time: 159.930s
[2K
| Adam | epoch: 011 | loss: 0.07831 - acc: 0.9747 -- iter: 0672/1554
[A[ATraining Step: 512  | total loss: [1m[32m0.09298[0m[0m | time: 167.971s
[2K
| Adam | epoch: 011 | loss: 0.09298 - acc: 0.9678 -- iter: 0704/1554
[A[ATraining Step: 513  | total loss: [1m[32m0.08630[0m[0m | time: 175.846s
[2K
| Adam | epoch: 011 | loss: 0.08630 - acc: 0.9710 -- iter: 0736/1554
[A[ATraining Step: 514  | total loss: [1m[32m0.10090[0m[0m | time: 183.702s
[2K
| Adam | epoch: 011 | loss: 0.10090 - acc: 0.9677 -- iter: 0768/1554
[A[ATraining Step: 515  | total loss: [1m[32m0.11275[0m[0m | time: 191.818s
[2K
| Adam | epoch: 011 | loss: 0.11275 - acc: 0.9678 -- iter: 0800/1554
[A[ATraining Step: 516  | total loss: [1m[32m0.10250[0m[0m | time: 199.748s
[2K
| Adam | epoch: 011 | loss: 0.10250 - acc: 0.9710 -- iter: 0832/1554
[A[ATraining Step: 517  | total loss: [1m[32m0.09606[0m[0m | time: 207.677s
[2K
| Adam | epoch: 011 | loss: 0.09606 - acc: 0.9739 -- iter: 0864/1554
[A[ATraining Step: 518  | total loss: [1m[32m0.10917[0m[0m | time: 215.646s
[2K
| Adam | epoch: 011 | loss: 0.10917 - acc: 0.9734 -- iter: 0896/1554
[A[ATraining Step: 519  | total loss: [1m[32m0.10347[0m[0m | time: 223.555s
[2K
| Adam | epoch: 011 | loss: 0.10347 - acc: 0.9729 -- iter: 0928/1554
[A[ATraining Step: 520  | total loss: [1m[32m0.09943[0m[0m | time: 231.478s
[2K
| Adam | epoch: 011 | loss: 0.09943 - acc: 0.9756 -- iter: 0960/1554
[A[ATraining Step: 521  | total loss: [1m[32m0.09733[0m[0m | time: 239.397s
[2K
| Adam | epoch: 011 | loss: 0.09733 - acc: 0.9750 -- iter: 0992/1554
[A[ATraining Step: 522  | total loss: [1m[32m0.09023[0m[0m | time: 247.237s
[2K
| Adam | epoch: 011 | loss: 0.09023 - acc: 0.9775 -- iter: 1024/1554
[A[ATraining Step: 523  | total loss: [1m[32m0.10610[0m[0m | time: 255.230s
[2K
| Adam | epoch: 011 | loss: 0.10610 - acc: 0.9735 -- iter: 1056/1554
[A[ATraining Step: 524  | total loss: [1m[32m0.09671[0m[0m | time: 263.178s
[2K
| Adam | epoch: 011 | loss: 0.09671 - acc: 0.9761 -- iter: 1088/1554
[A[ATraining Step: 525  | total loss: [1m[32m0.09444[0m[0m | time: 271.047s
[2K
| Adam | epoch: 011 | loss: 0.09444 - acc: 0.9754 -- iter: 1120/1554
[A[ATraining Step: 526  | total loss: [1m[32m0.08658[0m[0m | time: 278.959s
[2K
| Adam | epoch: 011 | loss: 0.08658 - acc: 0.9778 -- iter: 1152/1554
[A[ATraining Step: 527  | total loss: [1m[32m0.08154[0m[0m | time: 286.851s
[2K
| Adam | epoch: 011 | loss: 0.08154 - acc: 0.9769 -- iter: 1184/1554
[A[ATraining Step: 528  | total loss: [1m[32m0.07942[0m[0m | time: 294.814s
[2K
| Adam | epoch: 011 | loss: 0.07942 - acc: 0.9792 -- iter: 1216/1554
[A[ATraining Step: 529  | total loss: [1m[32m0.07318[0m[0m | time: 302.854s
[2K
| Adam | epoch: 011 | loss: 0.07318 - acc: 0.9813 -- iter: 1248/1554
[A[ATraining Step: 530  | total loss: [1m[32m0.06680[0m[0m | time: 310.949s
[2K
| Adam | epoch: 011 | loss: 0.06680 - acc: 0.9832 -- iter: 1280/1554
[A[ATraining Step: 531  | total loss: [1m[32m0.06940[0m[0m | time: 319.012s
[2K
| Adam | epoch: 011 | loss: 0.06940 - acc: 0.9817 -- iter: 1312/1554
[A[ATraining Step: 532  | total loss: [1m[32m0.06355[0m[0m | time: 326.974s
[2K
| Adam | epoch: 011 | loss: 0.06355 - acc: 0.9836 -- iter: 1344/1554
[A[ATraining Step: 533  | total loss: [1m[32m0.05884[0m[0m | time: 335.024s
[2K
| Adam | epoch: 011 | loss: 0.05884 - acc: 0.9852 -- iter: 1376/1554
[A[ATraining Step: 534  | total loss: [1m[32m0.05476[0m[0m | time: 343.004s
[2K
| Adam | epoch: 011 | loss: 0.05476 - acc: 0.9867 -- iter: 1408/1554
[A[ATraining Step: 535  | total loss: [1m[32m0.05001[0m[0m | time: 350.848s
[2K
| Adam | epoch: 011 | loss: 0.05001 - acc: 0.9880 -- iter: 1440/1554
[A[ATraining Step: 536  | total loss: [1m[32m0.04691[0m[0m | time: 358.640s
[2K
| Adam | epoch: 011 | loss: 0.04691 - acc: 0.9892 -- iter: 1472/1554
[A[ATraining Step: 537  | total loss: [1m[32m0.04323[0m[0m | time: 366.567s
[2K
| Adam | epoch: 011 | loss: 0.04323 - acc: 0.9903 -- iter: 1504/1554
[A[ATraining Step: 538  | total loss: [1m[32m0.04044[0m[0m | time: 374.374s
[2K
| Adam | epoch: 011 | loss: 0.04044 - acc: 0.9913 -- iter: 1536/1554
[A[ATraining Step: 539  | total loss: [1m[32m0.03738[0m[0m | time: 403.737s
[2K
| Adam | epoch: 011 | loss: 0.03738 - acc: 0.9921 | val_loss: 0.46306 - val_acc: 0.8580 -- iter: 1554/1554
--
Training Step: 540  | total loss: [1m[32m0.03476[0m[0m | time: 7.944s
[2K
| Adam | epoch: 012 | loss: 0.03476 - acc: 0.9929 -- iter: 0032/1554
[A[ATraining Step: 541  | total loss: [1m[32m0.03341[0m[0m | time: 15.854s
[2K
| Adam | epoch: 012 | loss: 0.03341 - acc: 0.9936 -- iter: 0064/1554
[A[ATraining Step: 542  | total loss: [1m[32m0.03408[0m[0m | time: 23.717s
[2K
| Adam | epoch: 012 | loss: 0.03408 - acc: 0.9943 -- iter: 0096/1554
[A[ATraining Step: 543  | total loss: [1m[32m0.03205[0m[0m | time: 31.542s
[2K
| Adam | epoch: 012 | loss: 0.03205 - acc: 0.9948 -- iter: 0128/1554
[A[ATraining Step: 544  | total loss: [1m[32m0.03033[0m[0m | time: 39.479s
[2K
| Adam | epoch: 012 | loss: 0.03033 - acc: 0.9954 -- iter: 0160/1554
[A[ATraining Step: 545  | total loss: [1m[32m0.05913[0m[0m | time: 47.491s
[2K
| Adam | epoch: 012 | loss: 0.05913 - acc: 0.9864 -- iter: 0192/1554
[A[ATraining Step: 546  | total loss: [1m[32m0.05525[0m[0m | time: 55.343s
[2K
| Adam | epoch: 012 | loss: 0.05525 - acc: 0.9878 -- iter: 0224/1554
[A[ATraining Step: 547  | total loss: [1m[32m0.05929[0m[0m | time: 63.250s
[2K
| Adam | epoch: 012 | loss: 0.05929 - acc: 0.9859 -- iter: 0256/1554
[A[ATraining Step: 548  | total loss: [1m[32m0.05547[0m[0m | time: 71.291s
[2K
| Adam | epoch: 012 | loss: 0.05547 - acc: 0.9873 -- iter: 0288/1554
[A[ATraining Step: 549  | total loss: [1m[32m0.05295[0m[0m | time: 76.263s
[2K
| Adam | epoch: 012 | loss: 0.05295 - acc: 0.9886 -- iter: 0320/1554
[A[ATraining Step: 550  | total loss: [1m[32m0.05005[0m[0m | time: 81.374s
[2K
| Adam | epoch: 012 | loss: 0.05005 - acc: 0.9897 -- iter: 0352/1554
[A[ATraining Step: 551  | total loss: [1m[32m0.04573[0m[0m | time: 89.177s
[2K
| Adam | epoch: 012 | loss: 0.04573 - acc: 0.9907 -- iter: 0384/1554
[A[ATraining Step: 552  | total loss: [1m[32m0.05124[0m[0m | time: 97.195s
[2K
| Adam | epoch: 012 | loss: 0.05124 - acc: 0.9885 -- iter: 0416/1554
[A[ATraining Step: 553  | total loss: [1m[32m0.05670[0m[0m | time: 105.072s
[2K
| Adam | epoch: 012 | loss: 0.05670 - acc: 0.9866 -- iter: 0448/1554
[A[ATraining Step: 554  | total loss: [1m[32m0.05508[0m[0m | time: 113.137s
[2K
| Adam | epoch: 012 | loss: 0.05508 - acc: 0.9848 -- iter: 0480/1554
[A[ATraining Step: 555  | total loss: [1m[32m0.06390[0m[0m | time: 120.916s
[2K
| Adam | epoch: 012 | loss: 0.06390 - acc: 0.9832 -- iter: 0512/1554
[A[ATraining Step: 556  | total loss: [1m[32m0.09379[0m[0m | time: 129.005s
[2K
| Adam | epoch: 012 | loss: 0.09379 - acc: 0.9724 -- iter: 0544/1554
[A[ATraining Step: 557  | total loss: [1m[32m0.09089[0m[0m | time: 136.942s
[2K
| Adam | epoch: 012 | loss: 0.09089 - acc: 0.9720 -- iter: 0576/1554
[A[ATraining Step: 558  | total loss: [1m[32m0.08342[0m[0m | time: 144.990s
[2K
| Adam | epoch: 012 | loss: 0.08342 - acc: 0.9748 -- iter: 0608/1554
[A[ATraining Step: 559  | total loss: [1m[32m0.07608[0m[0m | time: 152.841s
[2K
| Adam | epoch: 012 | loss: 0.07608 - acc: 0.9773 -- iter: 0640/1554
[A[ATraining Step: 560  | total loss: [1m[32m0.06995[0m[0m | time: 160.771s
[2K
| Adam | epoch: 012 | loss: 0.06995 - acc: 0.9796 -- iter: 0672/1554
[A[ATraining Step: 561  | total loss: [1m[32m0.07082[0m[0m | time: 168.639s
[2K
| Adam | epoch: 012 | loss: 0.07082 - acc: 0.9785 -- iter: 0704/1554
[A[ATraining Step: 562  | total loss: [1m[32m0.07160[0m[0m | time: 176.606s
[2K
| Adam | epoch: 012 | loss: 0.07160 - acc: 0.9775 -- iter: 0736/1554
[A[ATraining Step: 563  | total loss: [1m[32m0.06584[0m[0m | time: 184.485s
[2K
| Adam | epoch: 012 | loss: 0.06584 - acc: 0.9798 -- iter: 0768/1554
[A[ATraining Step: 564  | total loss: [1m[32m0.06154[0m[0m | time: 192.474s
[2K
| Adam | epoch: 012 | loss: 0.06154 - acc: 0.9818 -- iter: 0800/1554
[A[ATraining Step: 565  | total loss: [1m[32m0.05655[0m[0m | time: 200.397s
[2K
| Adam | epoch: 012 | loss: 0.05655 - acc: 0.9836 -- iter: 0832/1554
[A[ATraining Step: 566  | total loss: [1m[32m0.05231[0m[0m | time: 208.157s
[2K
| Adam | epoch: 012 | loss: 0.05231 - acc: 0.9853 -- iter: 0864/1554
[A[ATraining Step: 567  | total loss: [1m[32m0.05456[0m[0m | time: 216.101s
[2K
| Adam | epoch: 012 | loss: 0.05456 - acc: 0.9836 -- iter: 0896/1554
[A[ATraining Step: 568  | total loss: [1m[32m0.05131[0m[0m | time: 224.123s
[2K
| Adam | epoch: 012 | loss: 0.05131 - acc: 0.9852 -- iter: 0928/1554
[A[ATraining Step: 569  | total loss: [1m[32m0.04930[0m[0m | time: 231.920s
[2K
| Adam | epoch: 012 | loss: 0.04930 - acc: 0.9836 -- iter: 0960/1554
[A[ATraining Step: 570  | total loss: [1m[32m0.05004[0m[0m | time: 239.806s
[2K
| Adam | epoch: 012 | loss: 0.05004 - acc: 0.9821 -- iter: 0992/1554
[A[ATraining Step: 571  | total loss: [1m[32m0.05185[0m[0m | time: 247.735s
[2K
| Adam | epoch: 012 | loss: 0.05185 - acc: 0.9777 -- iter: 1024/1554
[A[ATraining Step: 572  | total loss: [1m[32m0.04910[0m[0m | time: 255.582s
[2K
| Adam | epoch: 012 | loss: 0.04910 - acc: 0.9799 -- iter: 1056/1554
[A[ATraining Step: 573  | total loss: [1m[32m0.04625[0m[0m | time: 263.442s
[2K
| Adam | epoch: 012 | loss: 0.04625 - acc: 0.9819 -- iter: 1088/1554
[A[ATraining Step: 574  | total loss: [1m[32m0.05245[0m[0m | time: 271.465s
[2K
| Adam | epoch: 012 | loss: 0.05245 - acc: 0.9775 -- iter: 1120/1554
[A[ATraining Step: 575  | total loss: [1m[32m0.05811[0m[0m | time: 279.448s
[2K
| Adam | epoch: 012 | loss: 0.05811 - acc: 0.9735 -- iter: 1152/1554
[A[ATraining Step: 576  | total loss: [1m[32m0.05561[0m[0m | time: 287.262s
[2K
| Adam | epoch: 012 | loss: 0.05561 - acc: 0.9761 -- iter: 1184/1554
[A[ATraining Step: 577  | total loss: [1m[32m0.05091[0m[0m | time: 295.233s
[2K
| Adam | epoch: 012 | loss: 0.05091 - acc: 0.9785 -- iter: 1216/1554
[A[ATraining Step: 578  | total loss: [1m[32m0.04831[0m[0m | time: 303.065s
[2K
| Adam | epoch: 012 | loss: 0.04831 - acc: 0.9807 -- iter: 1248/1554
[A[ATraining Step: 579  | total loss: [1m[32m0.04556[0m[0m | time: 311.039s
[2K
| Adam | epoch: 012 | loss: 0.04556 - acc: 0.9826 -- iter: 1280/1554
[A[ATraining Step: 580  | total loss: [1m[32m0.05036[0m[0m | time: 319.015s
[2K
| Adam | epoch: 012 | loss: 0.05036 - acc: 0.9812 -- iter: 1312/1554
[A[ATraining Step: 581  | total loss: [1m[32m0.04575[0m[0m | time: 326.822s
[2K
| Adam | epoch: 012 | loss: 0.04575 - acc: 0.9831 -- iter: 1344/1554
[A[ATraining Step: 582  | total loss: [1m[32m0.04271[0m[0m | time: 334.668s
[2K
| Adam | epoch: 012 | loss: 0.04271 - acc: 0.9848 -- iter: 1376/1554
[A[ATraining Step: 583  | total loss: [1m[32m0.05082[0m[0m | time: 342.623s
[2K
| Adam | epoch: 012 | loss: 0.05082 - acc: 0.9800 -- iter: 1408/1554
[A[ATraining Step: 584  | total loss: [1m[32m0.06680[0m[0m | time: 350.461s
[2K
| Adam | epoch: 012 | loss: 0.06680 - acc: 0.9758 -- iter: 1440/1554
[A[ATraining Step: 585  | total loss: [1m[32m0.06767[0m[0m | time: 358.419s
[2K
| Adam | epoch: 012 | loss: 0.06767 - acc: 0.9751 -- iter: 1472/1554
[A[ATraining Step: 586  | total loss: [1m[32m0.06460[0m[0m | time: 366.324s
[2K
| Adam | epoch: 012 | loss: 0.06460 - acc: 0.9776 -- iter: 1504/1554
[A[ATraining Step: 587  | total loss: [1m[32m0.05859[0m[0m | time: 374.208s
[2K
| Adam | epoch: 012 | loss: 0.05859 - acc: 0.9798 -- iter: 1536/1554
[A[ATraining Step: 588  | total loss: [1m[32m0.05408[0m[0m | time: 403.573s
[2K
| Adam | epoch: 012 | loss: 0.05408 - acc: 0.9818 | val_loss: 0.61402 - val_acc: 0.8416 -- iter: 1554/1554
--
Training Step: 589  | total loss: [1m[32m0.05581[0m[0m | time: 8.098s
[2K
| Adam | epoch: 013 | loss: 0.05581 - acc: 0.9805 -- iter: 0032/1554
[A[ATraining Step: 590  | total loss: [1m[32m0.05095[0m[0m | time: 16.025s
[2K
| Adam | epoch: 013 | loss: 0.05095 - acc: 0.9825 -- iter: 0064/1554
[A[ATraining Step: 591  | total loss: [1m[32m0.04761[0m[0m | time: 24.009s
[2K
| Adam | epoch: 013 | loss: 0.04761 - acc: 0.9842 -- iter: 0096/1554
[A[ATraining Step: 592  | total loss: [1m[32m0.04828[0m[0m | time: 31.955s
[2K
| Adam | epoch: 013 | loss: 0.04828 - acc: 0.9827 -- iter: 0128/1554
[A[ATraining Step: 593  | total loss: [1m[32m0.04993[0m[0m | time: 39.926s
[2K
| Adam | epoch: 013 | loss: 0.04993 - acc: 0.9813 -- iter: 0160/1554
[A[ATraining Step: 594  | total loss: [1m[32m0.05844[0m[0m | time: 47.748s
[2K
| Adam | epoch: 013 | loss: 0.05844 - acc: 0.9800 -- iter: 0192/1554
[A[ATraining Step: 595  | total loss: [1m[32m0.05326[0m[0m | time: 55.615s
[2K
| Adam | epoch: 013 | loss: 0.05326 - acc: 0.9820 -- iter: 0224/1554
[A[ATraining Step: 596  | total loss: [1m[32m0.04857[0m[0m | time: 63.446s
[2K
| Adam | epoch: 013 | loss: 0.04857 - acc: 0.9838 -- iter: 0256/1554
[A[ATraining Step: 597  | total loss: [1m[32m0.04544[0m[0m | time: 71.324s
[2K
| Adam | epoch: 013 | loss: 0.04544 - acc: 0.9854 -- iter: 0288/1554
[A[ATraining Step: 598  | total loss: [1m[32m0.05546[0m[0m | time: 79.306s
[2K
| Adam | epoch: 013 | loss: 0.05546 - acc: 0.9807 -- iter: 0320/1554
[A[ATraining Step: 599  | total loss: [1m[32m0.05070[0m[0m | time: 84.203s
[2K
| Adam | epoch: 013 | loss: 0.05070 - acc: 0.9826 -- iter: 0352/1554
[A[ATraining Step: 600  | total loss: [1m[32m0.04614[0m[0m | time: 110.758s
[2K
| Adam | epoch: 013 | loss: 0.04614 - acc: 0.9843 | val_loss: 4.52572 - val_acc: 0.5823 -- iter: 0384/1554
--
Training Step: 601  | total loss: [1m[32m0.04188[0m[0m | time: 118.594s
[2K
| Adam | epoch: 013 | loss: 0.04188 - acc: 0.9859 -- iter: 0416/1554
[A[ATraining Step: 602  | total loss: [1m[32m0.04057[0m[0m | time: 126.715s
[2K
| Adam | epoch: 013 | loss: 0.04057 - acc: 0.9873 -- iter: 0448/1554
[A[ATraining Step: 603  | total loss: [1m[32m0.04216[0m[0m | time: 134.650s
[2K
| Adam | epoch: 013 | loss: 0.04216 - acc: 0.9854 -- iter: 0480/1554
[A[ATraining Step: 604  | total loss: [1m[32m0.05519[0m[0m | time: 142.637s
[2K
| Adam | epoch: 013 | loss: 0.05519 - acc: 0.9807 -- iter: 0512/1554
[A[ATraining Step: 605  | total loss: [1m[32m0.05164[0m[0m | time: 150.473s
[2K
| Adam | epoch: 013 | loss: 0.05164 - acc: 0.9826 -- iter: 0544/1554
[A[ATraining Step: 606  | total loss: [1m[32m0.06862[0m[0m | time: 158.438s
[2K
| Adam | epoch: 013 | loss: 0.06862 - acc: 0.9812 -- iter: 0576/1554
[A[ATraining Step: 607  | total loss: [1m[32m0.07199[0m[0m | time: 166.337s
[2K
| Adam | epoch: 013 | loss: 0.07199 - acc: 0.9800 -- iter: 0608/1554
[A[ATraining Step: 608  | total loss: [1m[32m0.06711[0m[0m | time: 174.345s
[2K
| Adam | epoch: 013 | loss: 0.06711 - acc: 0.9820 -- iter: 0640/1554
[A[ATraining Step: 609  | total loss: [1m[32m0.06209[0m[0m | time: 182.191s
[2K
| Adam | epoch: 013 | loss: 0.06209 - acc: 0.9838 -- iter: 0672/1554
[A[ATraining Step: 610  | total loss: [1m[32m0.06301[0m[0m | time: 190.009s
[2K
| Adam | epoch: 013 | loss: 0.06301 - acc: 0.9823 -- iter: 0704/1554
[A[ATraining Step: 611  | total loss: [1m[32m0.05762[0m[0m | time: 197.817s
[2K
| Adam | epoch: 013 | loss: 0.05762 - acc: 0.9840 -- iter: 0736/1554
[A[ATraining Step: 612  | total loss: [1m[32m0.06492[0m[0m | time: 205.735s
[2K
| Adam | epoch: 013 | loss: 0.06492 - acc: 0.9794 -- iter: 0768/1554
[A[ATraining Step: 613  | total loss: [1m[32m0.06716[0m[0m | time: 213.844s
[2K
| Adam | epoch: 013 | loss: 0.06716 - acc: 0.9783 -- iter: 0800/1554
[A[ATraining Step: 614  | total loss: [1m[32m0.06117[0m[0m | time: 221.758s
[2K
| Adam | epoch: 013 | loss: 0.06117 - acc: 0.9805 -- iter: 0832/1554
[A[ATraining Step: 615  | total loss: [1m[32m0.05974[0m[0m | time: 229.935s
[2K
| Adam | epoch: 013 | loss: 0.05974 - acc: 0.9824 -- iter: 0864/1554
[A[ATraining Step: 616  | total loss: [1m[32m0.06937[0m[0m | time: 238.081s
[2K
| Adam | epoch: 013 | loss: 0.06937 - acc: 0.9779 -- iter: 0896/1554
[A[ATraining Step: 617  | total loss: [1m[32m0.07135[0m[0m | time: 246.052s
[2K
| Adam | epoch: 013 | loss: 0.07135 - acc: 0.9770 -- iter: 0928/1554
[A[ATraining Step: 618  | total loss: [1m[32m0.06467[0m[0m | time: 253.952s
[2K
| Adam | epoch: 013 | loss: 0.06467 - acc: 0.9793 -- iter: 0960/1554
[A[ATraining Step: 619  | total loss: [1m[32m0.05976[0m[0m | time: 262.032s
[2K
| Adam | epoch: 013 | loss: 0.05976 - acc: 0.9814 -- iter: 0992/1554
[A[ATraining Step: 620  | total loss: [1m[32m0.05559[0m[0m | time: 270.124s
[2K
| Adam | epoch: 013 | loss: 0.05559 - acc: 0.9833 -- iter: 1024/1554
[A[ATraining Step: 621  | total loss: [1m[32m0.05165[0m[0m | time: 278.005s
[2K
| Adam | epoch: 013 | loss: 0.05165 - acc: 0.9849 -- iter: 1056/1554
[A[ATraining Step: 622  | total loss: [1m[32m0.05349[0m[0m | time: 286.101s
[2K
| Adam | epoch: 013 | loss: 0.05349 - acc: 0.9833 -- iter: 1088/1554
[A[ATraining Step: 623  | total loss: [1m[32m0.05076[0m[0m | time: 293.967s
[2K
| Adam | epoch: 013 | loss: 0.05076 - acc: 0.9850 -- iter: 1120/1554
[A[ATraining Step: 624  | total loss: [1m[32m0.06473[0m[0m | time: 301.934s
[2K
| Adam | epoch: 013 | loss: 0.06473 - acc: 0.9834 -- iter: 1152/1554
[A[ATraining Step: 625  | total loss: [1m[32m0.06036[0m[0m | time: 309.917s
[2K
| Adam | epoch: 013 | loss: 0.06036 - acc: 0.9850 -- iter: 1184/1554
[A[ATraining Step: 626  | total loss: [1m[32m0.05539[0m[0m | time: 317.972s
[2K
| Adam | epoch: 013 | loss: 0.05539 - acc: 0.9865 -- iter: 1216/1554
[A[ATraining Step: 627  | total loss: [1m[32m0.05463[0m[0m | time: 325.844s
[2K
| Adam | epoch: 013 | loss: 0.05463 - acc: 0.9879 -- iter: 1248/1554
[A[ATraining Step: 628  | total loss: [1m[32m0.05774[0m[0m | time: 333.696s
[2K
| Adam | epoch: 013 | loss: 0.05774 - acc: 0.9828 -- iter: 1280/1554
[A[ATraining Step: 629  | total loss: [1m[32m0.06098[0m[0m | time: 341.653s
[2K
| Adam | epoch: 013 | loss: 0.06098 - acc: 0.9783 -- iter: 1312/1554
[A[ATraining Step: 630  | total loss: [1m[32m0.06587[0m[0m | time: 349.520s
[2K
| Adam | epoch: 013 | loss: 0.06587 - acc: 0.9742 -- iter: 1344/1554
[A[ATraining Step: 631  | total loss: [1m[32m0.06590[0m[0m | time: 357.512s
[2K
| Adam | epoch: 013 | loss: 0.06590 - acc: 0.9737 -- iter: 1376/1554
[A[ATraining Step: 632  | total loss: [1m[32m0.06279[0m[0m | time: 365.424s
[2K
| Adam | epoch: 013 | loss: 0.06279 - acc: 0.9763 -- iter: 1408/1554
[A[ATraining Step: 633  | total loss: [1m[32m0.05767[0m[0m | time: 373.294s
[2K
| Adam | epoch: 013 | loss: 0.05767 - acc: 0.9787 -- iter: 1440/1554
[A[ATraining Step: 634  | total loss: [1m[32m0.07929[0m[0m | time: 381.153s
[2K
| Adam | epoch: 013 | loss: 0.07929 - acc: 0.9714 -- iter: 1472/1554
[A[ATraining Step: 635  | total loss: [1m[32m0.07277[0m[0m | time: 389.208s
[2K
| Adam | epoch: 013 | loss: 0.07277 - acc: 0.9743 -- iter: 1504/1554
[A[ATraining Step: 636  | total loss: [1m[32m0.07085[0m[0m | time: 396.990s
[2K
| Adam | epoch: 013 | loss: 0.07085 - acc: 0.9769 -- iter: 1536/1554
[A[ATraining Step: 637  | total loss: [1m[32m0.06567[0m[0m | time: 426.384s
[2K
| Adam | epoch: 013 | loss: 0.06567 - acc: 0.9792 | val_loss: 1.02388 - val_acc: 0.8066 -- iter: 1554/1554
--
Training Step: 638  | total loss: [1m[32m0.06405[0m[0m | time: 8.121s
[2K
| Adam | epoch: 014 | loss: 0.06405 - acc: 0.9781 -- iter: 0032/1554
[A[ATraining Step: 639  | total loss: [1m[32m0.05915[0m[0m | time: 16.179s
[2K
| Adam | epoch: 014 | loss: 0.05915 - acc: 0.9803 -- iter: 0064/1554
[A[ATraining Step: 640  | total loss: [1m[32m0.06114[0m[0m | time: 24.196s
[2K
| Adam | epoch: 014 | loss: 0.06114 - acc: 0.9760 -- iter: 0096/1554
[A[ATraining Step: 641  | total loss: [1m[32m0.05647[0m[0m | time: 32.215s
[2K
| Adam | epoch: 014 | loss: 0.05647 - acc: 0.9784 -- iter: 0128/1554
[A[ATraining Step: 642  | total loss: [1m[32m0.06120[0m[0m | time: 40.123s
[2K
| Adam | epoch: 014 | loss: 0.06120 - acc: 0.9743 -- iter: 0160/1554
[A[ATraining Step: 643  | total loss: [1m[32m0.09276[0m[0m | time: 48.053s
[2K
| Adam | epoch: 014 | loss: 0.09276 - acc: 0.9738 -- iter: 0192/1554
[A[ATraining Step: 644  | total loss: [1m[32m0.08711[0m[0m | time: 55.949s
[2K
| Adam | epoch: 014 | loss: 0.08711 - acc: 0.9764 -- iter: 0224/1554
[A[ATraining Step: 645  | total loss: [1m[32m0.08033[0m[0m | time: 63.824s
[2K
| Adam | epoch: 014 | loss: 0.08033 - acc: 0.9788 -- iter: 0256/1554
[A[ATraining Step: 646  | total loss: [1m[32m0.07842[0m[0m | time: 71.907s
[2K
| Adam | epoch: 014 | loss: 0.07842 - acc: 0.9778 -- iter: 0288/1554
[A[ATraining Step: 647  | total loss: [1m[32m0.07273[0m[0m | time: 79.805s
[2K
| Adam | epoch: 014 | loss: 0.07273 - acc: 0.9800 -- iter: 0320/1554
[A[ATraining Step: 648  | total loss: [1m[32m0.06585[0m[0m | time: 87.682s
[2K
| Adam | epoch: 014 | loss: 0.06585 - acc: 0.9820 -- iter: 0352/1554
[A[ATraining Step: 649  | total loss: [1m[32m0.06209[0m[0m | time: 92.707s
[2K
| Adam | epoch: 014 | loss: 0.06209 - acc: 0.9838 -- iter: 0384/1554
[A[ATraining Step: 650  | total loss: [1m[32m0.05753[0m[0m | time: 97.624s
[2K
| Adam | epoch: 014 | loss: 0.05753 - acc: 0.9854 -- iter: 0416/1554
[A[ATraining Step: 651  | total loss: [1m[32m0.05270[0m[0m | time: 105.737s
[2K
| Adam | epoch: 014 | loss: 0.05270 - acc: 0.9869 -- iter: 0448/1554
[A[ATraining Step: 652  | total loss: [1m[32m0.05151[0m[0m | time: 113.742s
[2K
| Adam | epoch: 014 | loss: 0.05151 - acc: 0.9882 -- iter: 0480/1554
[A[ATraining Step: 653  | total loss: [1m[32m0.05647[0m[0m | time: 121.617s
[2K
| Adam | epoch: 014 | loss: 0.05647 - acc: 0.9862 -- iter: 0512/1554
[A[ATraining Step: 654  | total loss: [1m[32m0.05391[0m[0m | time: 129.562s
[2K
| Adam | epoch: 014 | loss: 0.05391 - acc: 0.9845 -- iter: 0544/1554
[A[ATraining Step: 655  | total loss: [1m[32m0.06289[0m[0m | time: 137.689s
[2K
| Adam | epoch: 014 | loss: 0.06289 - acc: 0.9798 -- iter: 0576/1554
[A[ATraining Step: 656  | total loss: [1m[32m0.05764[0m[0m | time: 145.576s
[2K
| Adam | epoch: 014 | loss: 0.05764 - acc: 0.9818 -- iter: 0608/1554
[A[ATraining Step: 657  | total loss: [1m[32m0.05262[0m[0m | time: 153.546s
[2K
| Adam | epoch: 014 | loss: 0.05262 - acc: 0.9836 -- iter: 0640/1554
[A[ATraining Step: 658  | total loss: [1m[32m0.04790[0m[0m | time: 161.574s
[2K
| Adam | epoch: 014 | loss: 0.04790 - acc: 0.9853 -- iter: 0672/1554
[A[ATraining Step: 659  | total loss: [1m[32m0.04369[0m[0m | time: 169.519s
[2K
| Adam | epoch: 014 | loss: 0.04369 - acc: 0.9867 -- iter: 0704/1554
[A[ATraining Step: 660  | total loss: [1m[32m0.04501[0m[0m | time: 177.221s
[2K
| Adam | epoch: 014 | loss: 0.04501 - acc: 0.9818 -- iter: 0736/1554
[A[ATraining Step: 661  | total loss: [1m[32m0.04136[0m[0m | time: 185.309s
[2K
| Adam | epoch: 014 | loss: 0.04136 - acc: 0.9836 -- iter: 0768/1554
[A[ATraining Step: 662  | total loss: [1m[32m0.03847[0m[0m | time: 193.471s
[2K
| Adam | epoch: 014 | loss: 0.03847 - acc: 0.9853 -- iter: 0800/1554
[A[ATraining Step: 663  | total loss: [1m[32m0.04297[0m[0m | time: 201.455s
[2K
| Adam | epoch: 014 | loss: 0.04297 - acc: 0.9836 -- iter: 0832/1554
[A[ATraining Step: 664  | total loss: [1m[32m0.04920[0m[0m | time: 209.468s
[2K
| Adam | epoch: 014 | loss: 0.04920 - acc: 0.9821 -- iter: 0864/1554
[A[ATraining Step: 665  | total loss: [1m[32m0.06149[0m[0m | time: 217.485s
[2K
| Adam | epoch: 014 | loss: 0.06149 - acc: 0.9777 -- iter: 0896/1554
[A[ATraining Step: 666  | total loss: [1m[32m0.06081[0m[0m | time: 225.472s
[2K
| Adam | epoch: 014 | loss: 0.06081 - acc: 0.9768 -- iter: 0928/1554
[A[ATraining Step: 667  | total loss: [1m[32m0.06988[0m[0m | time: 233.463s
[2K
| Adam | epoch: 014 | loss: 0.06988 - acc: 0.9697 -- iter: 0960/1554
[A[ATraining Step: 668  | total loss: [1m[32m0.06359[0m[0m | time: 241.503s
[2K
| Adam | epoch: 014 | loss: 0.06359 - acc: 0.9728 -- iter: 0992/1554
[A[ATraining Step: 669  | total loss: [1m[32m0.05825[0m[0m | time: 249.360s
[2K
| Adam | epoch: 014 | loss: 0.05825 - acc: 0.9755 -- iter: 1024/1554
[A[ATraining Step: 670  | total loss: [1m[32m0.05369[0m[0m | time: 257.186s
[2K
| Adam | epoch: 014 | loss: 0.05369 - acc: 0.9779 -- iter: 1056/1554
[A[ATraining Step: 671  | total loss: [1m[32m0.06050[0m[0m | time: 265.273s
[2K
| Adam | epoch: 014 | loss: 0.06050 - acc: 0.9770 -- iter: 1088/1554
[A[ATraining Step: 672  | total loss: [1m[32m0.05645[0m[0m | time: 273.065s
[2K
| Adam | epoch: 014 | loss: 0.05645 - acc: 0.9793 -- iter: 1120/1554
[A[ATraining Step: 673  | total loss: [1m[32m0.05201[0m[0m | time: 280.994s
[2K
| Adam | epoch: 014 | loss: 0.05201 - acc: 0.9814 -- iter: 1152/1554
[A[ATraining Step: 674  | total loss: [1m[32m0.04946[0m[0m | time: 288.985s
[2K
| Adam | epoch: 014 | loss: 0.04946 - acc: 0.9832 -- iter: 1184/1554
[A[ATraining Step: 675  | total loss: [1m[32m0.04480[0m[0m | time: 297.120s
[2K
| Adam | epoch: 014 | loss: 0.04480 - acc: 0.9849 -- iter: 1216/1554
[A[ATraining Step: 676  | total loss: [1m[32m0.04209[0m[0m | time: 305.023s
[2K
| Adam | epoch: 014 | loss: 0.04209 - acc: 0.9864 -- iter: 1248/1554
[A[ATraining Step: 677  | total loss: [1m[32m0.05808[0m[0m | time: 313.032s
[2K
| Adam | epoch: 014 | loss: 0.05808 - acc: 0.9753 -- iter: 1280/1554
[A[ATraining Step: 678  | total loss: [1m[32m0.05611[0m[0m | time: 320.921s
[2K
| Adam | epoch: 014 | loss: 0.05611 - acc: 0.9778 -- iter: 1312/1554
[A[ATraining Step: 679  | total loss: [1m[32m0.05100[0m[0m | time: 328.937s
[2K
| Adam | epoch: 014 | loss: 0.05100 - acc: 0.9800 -- iter: 1344/1554
[A[ATraining Step: 680  | total loss: [1m[32m0.04647[0m[0m | time: 336.853s
[2K
| Adam | epoch: 014 | loss: 0.04647 - acc: 0.9820 -- iter: 1376/1554
[A[ATraining Step: 681  | total loss: [1m[32m0.04235[0m[0m | time: 344.849s
[2K
| Adam | epoch: 014 | loss: 0.04235 - acc: 0.9838 -- iter: 1408/1554
[A[ATraining Step: 682  | total loss: [1m[32m0.04250[0m[0m | time: 352.953s
[2K
| Adam | epoch: 014 | loss: 0.04250 - acc: 0.9823 -- iter: 1440/1554
[A[ATraining Step: 683  | total loss: [1m[32m0.04006[0m[0m | time: 361.019s
[2K
| Adam | epoch: 014 | loss: 0.04006 - acc: 0.9841 -- iter: 1472/1554
[A[ATraining Step: 684  | total loss: [1m[32m0.03887[0m[0m | time: 368.869s
[2K
| Adam | epoch: 014 | loss: 0.03887 - acc: 0.9856 -- iter: 1504/1554
[A[ATraining Step: 685  | total loss: [1m[32m0.04638[0m[0m | time: 376.989s
[2K
| Adam | epoch: 014 | loss: 0.04638 - acc: 0.9840 -- iter: 1536/1554
[A[ATraining Step: 686  | total loss: [1m[32m0.04265[0m[0m | time: 406.332s
[2K
| Adam | epoch: 014 | loss: 0.04265 - acc: 0.9856 | val_loss: 1.74367 - val_acc: 0.7387 -- iter: 1554/1554
--
Training Step: 687  | total loss: [1m[32m0.03974[0m[0m | time: 7.804s
[2K
| Adam | epoch: 015 | loss: 0.03974 - acc: 0.9870 -- iter: 0032/1554
[A[ATraining Step: 688  | total loss: [1m[32m0.04394[0m[0m | time: 15.818s
[2K
| Adam | epoch: 015 | loss: 0.04394 - acc: 0.9852 -- iter: 0064/1554
[A[ATraining Step: 689  | total loss: [1m[32m0.04071[0m[0m | time: 23.828s
[2K
| Adam | epoch: 015 | loss: 0.04071 - acc: 0.9867 -- iter: 0096/1554
[A[ATraining Step: 690  | total loss: [1m[32m0.04525[0m[0m | time: 31.805s
[2K
| Adam | epoch: 015 | loss: 0.04525 - acc: 0.9849 -- iter: 0128/1554
[A[ATraining Step: 691  | total loss: [1m[32m0.04771[0m[0m | time: 39.743s
[2K
| Adam | epoch: 015 | loss: 0.04771 - acc: 0.9833 -- iter: 0160/1554
[A[ATraining Step: 692  | total loss: [1m[32m0.04315[0m[0m | time: 47.702s
[2K
| Adam | epoch: 015 | loss: 0.04315 - acc: 0.9849 -- iter: 0192/1554
[A[ATraining Step: 693  | total loss: [1m[32m0.03984[0m[0m | time: 55.517s
[2K
| Adam | epoch: 015 | loss: 0.03984 - acc: 0.9864 -- iter: 0224/1554
[A[ATraining Step: 694  | total loss: [1m[32m0.03662[0m[0m | time: 63.290s
[2K
| Adam | epoch: 015 | loss: 0.03662 - acc: 0.9878 -- iter: 0256/1554
[A[ATraining Step: 695  | total loss: [1m[32m0.03447[0m[0m | time: 71.266s
[2K
| Adam | epoch: 015 | loss: 0.03447 - acc: 0.9890 -- iter: 0288/1554
[A[ATraining Step: 696  | total loss: [1m[32m0.03121[0m[0m | time: 79.222s
[2K
| Adam | epoch: 015 | loss: 0.03121 - acc: 0.9901 -- iter: 0320/1554
[A[ATraining Step: 697  | total loss: [1m[32m0.03519[0m[0m | time: 87.212s
[2K
| Adam | epoch: 015 | loss: 0.03519 - acc: 0.9880 -- iter: 0352/1554
[A[ATraining Step: 698  | total loss: [1m[32m0.03222[0m[0m | time: 95.219s
[2K
| Adam | epoch: 015 | loss: 0.03222 - acc: 0.9892 -- iter: 0384/1554
[A[ATraining Step: 699  | total loss: [1m[32m0.03025[0m[0m | time: 100.309s
[2K
| Adam | epoch: 015 | loss: 0.03025 - acc: 0.9903 -- iter: 0416/1554
[A[ATraining Step: 700  | total loss: [1m[32m0.02783[0m[0m | time: 105.346s
[2K
| Adam | epoch: 015 | loss: 0.02783 - acc: 0.9912 -- iter: 0448/1554
[A[ATraining Step: 701  | total loss: [1m[32m0.02536[0m[0m | time: 113.388s
[2K
| Adam | epoch: 015 | loss: 0.02536 - acc: 0.9921 -- iter: 0480/1554
[A[ATraining Step: 702  | total loss: [1m[32m0.02843[0m[0m | time: 121.637s
[2K
| Adam | epoch: 015 | loss: 0.02843 - acc: 0.9898 -- iter: 0512/1554
[A[ATraining Step: 703  | total loss: [1m[32m0.02594[0m[0m | time: 129.463s
[2K
| Adam | epoch: 015 | loss: 0.02594 - acc: 0.9908 -- iter: 0544/1554
[A[ATraining Step: 704  | total loss: [1m[32m0.02598[0m[0m | time: 137.431s
[2K
| Adam | epoch: 015 | loss: 0.02598 - acc: 0.9917 -- iter: 0576/1554
[A[ATraining Step: 705  | total loss: [1m[32m0.02488[0m[0m | time: 145.294s
[2K
| Adam | epoch: 015 | loss: 0.02488 - acc: 0.9925 -- iter: 0608/1554
[A[ATraining Step: 706  | total loss: [1m[32m0.02702[0m[0m | time: 153.350s
[2K
| Adam | epoch: 015 | loss: 0.02702 - acc: 0.9902 -- iter: 0640/1554
[A[ATraining Step: 707  | total loss: [1m[32m0.02951[0m[0m | time: 161.320s
[2K
| Adam | epoch: 015 | loss: 0.02951 - acc: 0.9880 -- iter: 0672/1554
[A[ATraining Step: 708  | total loss: [1m[32m0.02752[0m[0m | time: 169.280s
[2K
| Adam | epoch: 015 | loss: 0.02752 - acc: 0.9892 -- iter: 0704/1554
[A[ATraining Step: 709  | total loss: [1m[32m0.03596[0m[0m | time: 177.221s
[2K
| Adam | epoch: 015 | loss: 0.03596 - acc: 0.9872 -- iter: 0736/1554
[A[ATraining Step: 710  | total loss: [1m[32m0.03306[0m[0m | time: 185.174s
[2K
| Adam | epoch: 015 | loss: 0.03306 - acc: 0.9885 -- iter: 0768/1554
[A[ATraining Step: 711  | total loss: [1m[32m0.03476[0m[0m | time: 193.066s
[2K
| Adam | epoch: 015 | loss: 0.03476 - acc: 0.9865 -- iter: 0800/1554
[A[ATraining Step: 712  | total loss: [1m[32m0.03734[0m[0m | time: 201.067s
[2K
| Adam | epoch: 015 | loss: 0.03734 - acc: 0.9847 -- iter: 0832/1554
[A[ATraining Step: 713  | total loss: [1m[32m0.03723[0m[0m | time: 209.151s
[2K
| Adam | epoch: 015 | loss: 0.03723 - acc: 0.9831 -- iter: 0864/1554
[A[ATraining Step: 714  | total loss: [1m[32m0.03418[0m[0m | time: 216.975s
[2K
| Adam | epoch: 015 | loss: 0.03418 - acc: 0.9848 -- iter: 0896/1554
[A[ATraining Step: 715  | total loss: [1m[32m0.03087[0m[0m | time: 225.035s
[2K
| Adam | epoch: 015 | loss: 0.03087 - acc: 0.9863 -- iter: 0928/1554
[A[ATraining Step: 716  | total loss: [1m[32m0.07529[0m[0m | time: 232.870s
[2K
| Adam | epoch: 015 | loss: 0.07529 - acc: 0.9814 -- iter: 0960/1554
[A[ATraining Step: 717  | total loss: [1m[32m0.07089[0m[0m | time: 240.804s
[2K
| Adam | epoch: 015 | loss: 0.07089 - acc: 0.9833 -- iter: 0992/1554
[A[ATraining Step: 718  | total loss: [1m[32m0.10476[0m[0m | time: 248.688s
[2K
| Adam | epoch: 015 | loss: 0.10476 - acc: 0.9818 -- iter: 1024/1554
[A[ATraining Step: 719  | total loss: [1m[32m0.09921[0m[0m | time: 256.437s
[2K
| Adam | epoch: 015 | loss: 0.09921 - acc: 0.9837 -- iter: 1056/1554
[A[ATraining Step: 720  | total loss: [1m[32m0.09119[0m[0m | time: 264.536s
[2K
| Adam | epoch: 015 | loss: 0.09119 - acc: 0.9853 -- iter: 1088/1554
[A[ATraining Step: 721  | total loss: [1m[32m0.08237[0m[0m | time: 272.416s
[2K
| Adam | epoch: 015 | loss: 0.08237 - acc: 0.9868 -- iter: 1120/1554
[A[ATraining Step: 722  | total loss: [1m[32m0.07777[0m[0m | time: 280.354s
[2K
| Adam | epoch: 015 | loss: 0.07777 - acc: 0.9850 -- iter: 1152/1554
[A[ATraining Step: 723  | total loss: [1m[32m0.08014[0m[0m | time: 288.269s
[2K
| Adam | epoch: 015 | loss: 0.08014 - acc: 0.9833 -- iter: 1184/1554
[A[ATraining Step: 724  | total loss: [1m[32m0.07340[0m[0m | time: 296.301s
[2K
| Adam | epoch: 015 | loss: 0.07340 - acc: 0.9850 -- iter: 1216/1554
[A[ATraining Step: 725  | total loss: [1m[32m0.06812[0m[0m | time: 304.341s
[2K
| Adam | epoch: 015 | loss: 0.06812 - acc: 0.9865 -- iter: 1248/1554
[A[ATraining Step: 726  | total loss: [1m[32m0.07410[0m[0m | time: 312.307s
[2K
| Adam | epoch: 015 | loss: 0.07410 - acc: 0.9847 -- iter: 1280/1554
[A[ATraining Step: 727  | total loss: [1m[32m0.06767[0m[0m | time: 320.142s
[2K
| Adam | epoch: 015 | loss: 0.06767 - acc: 0.9863 -- iter: 1312/1554
[A[ATraining Step: 728  | total loss: [1m[32m0.06814[0m[0m | time: 328.080s
[2K
| Adam | epoch: 015 | loss: 0.06814 - acc: 0.9845 -- iter: 1344/1554
[A[ATraining Step: 729  | total loss: [1m[32m0.06576[0m[0m | time: 336.130s
[2K
| Adam | epoch: 015 | loss: 0.06576 - acc: 0.9829 -- iter: 1376/1554
[A[ATraining Step: 730  | total loss: [1m[32m0.06836[0m[0m | time: 344.170s
[2K
| Adam | epoch: 015 | loss: 0.06836 - acc: 0.9784 -- iter: 1408/1554
[A[ATraining Step: 731  | total loss: [1m[32m0.06235[0m[0m | time: 351.978s
[2K
| Adam | epoch: 015 | loss: 0.06235 - acc: 0.9805 -- iter: 1440/1554
[A[ATraining Step: 732  | total loss: [1m[32m0.06714[0m[0m | time: 359.794s
[2K
| Adam | epoch: 015 | loss: 0.06714 - acc: 0.9794 -- iter: 1472/1554
[A[ATraining Step: 733  | total loss: [1m[32m0.06151[0m[0m | time: 367.975s
[2K
| Adam | epoch: 015 | loss: 0.06151 - acc: 0.9814 -- iter: 1504/1554
[A[ATraining Step: 734  | total loss: [1m[32m0.05570[0m[0m | time: 376.043s
[2K
| Adam | epoch: 015 | loss: 0.05570 - acc: 0.9833 -- iter: 1536/1554
[A[ATraining Step: 735  | total loss: [1m[32m0.05058[0m[0m | time: 405.614s
[2K
| Adam | epoch: 015 | loss: 0.05058 - acc: 0.9850 | val_loss: 0.46774 - val_acc: 0.8704 -- iter: 1554/1554
--
Validation AUC:0.944859354095751
Validation AUPRC:0.9444696283805908
Test AUC:0.9478361340968174
Test AUPRC:0.9354842041051034
BestTestF1Score	0.87	0.76	0.88	0.9	0.84	192	22	235	37	0.77
BestTestMCCScore	0.87	0.76	0.88	0.9	0.84	192	22	235	37	0.77
BestTestAccuracyScore	0.87	0.76	0.88	0.9	0.84	192	22	235	37	0.77
BestValidationF1Score	0.88	0.76	0.88	0.9	0.85	207	22	221	36	0.77
BestValidationMCC	0.88	0.76	0.88	0.9	0.85	207	22	221	36	0.77
BestValidationAccuracy	0.88	0.76	0.88	0.9	0.85	207	22	221	36	0.77
TestPredictions (Threshold:0.77)
CHEMBL315658,TP,ACT,1.0	CHEMBL216046,TN,INACT,0.0	CHEMBL251997,TN,INACT,0.019999999552965164	CHEMBL368828,TP,ACT,1.0	CHEMBL295557,TP,ACT,1.0	CHEMBL3735302,TP,ACT,1.0	CHEMBL298664,TP,ACT,1.0	CHEMBL123099,TN,INACT,0.0	CHEMBL307471,TP,ACT,1.0	CHEMBL318146,TP,ACT,1.0	CHEMBL285814,TN,INACT,0.6899999976158142	CHEMBL95489,TN,INACT,0.0	CHEMBL1259241,TN,INACT,0.0	CHEMBL1417160,TN,INACT,0.0	CHEMBL6399,TP,ACT,1.0	CHEMBL61792,TN,INACT,0.0	CHEMBL3775234,FN,ACT,0.550000011920929	CHEMBL431172,TN,INACT,0.0	CHEMBL328089,FN,ACT,0.07999999821186066	CHEMBL332144,TP,ACT,1.0	CHEMBL2163448,FP,INACT,0.9599999785423279	CHEMBL67536,TP,ACT,1.0	CHEMBL222287,TN,INACT,0.0	CHEMBL77090,FN,ACT,0.009999999776482582	CHEMBL104,TN,INACT,0.0	CHEMBL72295,FP,INACT,1.0	CHEMBL316247,FP,INACT,0.9800000190734863	CHEMBL63760,TN,INACT,0.0	CHEMBL27065,TN,INACT,0.5699999928474426	CHEMBL420359,TN,INACT,0.0	CHEMBL6400,TP,ACT,1.0	CHEMBL170335,TN,INACT,0.0	CHEMBL2165326,FN,ACT,0.38999998569488525	CHEMBL433221,TP,ACT,0.9900000095367432	CHEMBL109206,TN,INACT,0.550000011920929	CHEMBL71070,TP,ACT,1.0	CHEMBL69832,TP,ACT,0.9900000095367432	CHEMBL281451,TP,ACT,1.0	CHEMBL60401,TN,INACT,0.0	CHEMBL3144604,TN,INACT,0.009999999776482582	CHEMBL2370509,TN,INACT,0.0	CHEMBL275471,TP,ACT,1.0	CHEMBL177111,TP,ACT,1.0	CHEMBL367093,FN,ACT,0.3799999952316284	CHEMBL59597,TN,INACT,0.0	CHEMBL28586,TP,ACT,1.0	CHEMBL173059,TN,INACT,0.0	CHEMBL303390,TP,ACT,0.8999999761581421	CHEMBL3290985,TN,INACT,0.009999999776482582	CHEMBL302974,TP,ACT,1.0	CHEMBL299983,TN,INACT,0.0	CHEMBL584,TN,INACT,0.18000000715255737	CHEMBL100874,TN,INACT,0.019999999552965164	CHEMBL514895,TN,INACT,0.0	CHEMBL156814,TN,INACT,0.0	CHEMBL308102,TP,ACT,1.0	CHEMBL440961,FP,INACT,1.0	CHEMBL1076554,TN,INACT,0.0	CHEMBL2370238,TN,INACT,0.0	CHEMBL329890,TP,ACT,1.0	CHEMBL2163710,TP,ACT,0.9900000095367432	CHEMBL3338850,TN,INACT,0.0	CHEMBL6778,TP,ACT,1.0	CHEMBL368641,FP,INACT,0.9900000095367432	CHEMBL3752947,TP,ACT,1.0	CHEMBL47040,TN,INACT,0.0	CHEMBL140006,TN,INACT,0.03999999910593033	CHEMBL3590085,TN,INACT,0.0	CHEMBL149241,FP,INACT,1.0	CHEMBL1272137,TP,ACT,1.0	CHEMBL316589,TN,INACT,0.0	CHEMBL70310,TP,ACT,1.0	CHEMBL6624,TP,ACT,0.8600000143051147	CHEMBL100264,TN,INACT,0.009999999776482582	CHEMBL3144831,TN,INACT,0.27000001072883606	CHEMBL305602,TP,ACT,1.0	CHEMBL111612,TP,ACT,0.8299999833106995	CHEMBL29420,TP,ACT,1.0	CHEMBL320236,TP,ACT,0.8299999833106995	CHEMBL16373,TN,INACT,0.0	CHEMBL302468,TN,INACT,0.0	CHEMBL3751986,TP,ACT,1.0	CHEMBL3604300,TN,INACT,0.0	CHEMBL434284,TN,INACT,0.0	CHEMBL78499,TP,ACT,1.0	CHEMBL48031,TP,ACT,1.0	CHEMBL227429,TN,INACT,0.0	CHEMBL73835,TP,ACT,0.8999999761581421	CHEMBL10374,TP,ACT,1.0	CHEMBL72410,TP,ACT,1.0	CHEMBL2431131,TN,INACT,0.009999999776482582	CHEMBL80626,TN,INACT,0.0	CHEMBL375781,TN,INACT,0.0	CHEMBL28563,TP,ACT,1.0	CHEMBL3315196,TN,INACT,0.0	CHEMBL366680,FN,ACT,0.4699999988079071	CHEMBL319719,FN,ACT,0.019999999552965164	CHEMBL274243,TP,ACT,1.0	CHEMBL398039,TN,INACT,0.0	CHEMBL3335537,TN,INACT,0.0	CHEMBL502593,FP,INACT,0.9800000190734863	CHEMBL343969,TN,INACT,0.0	CHEMBL283200,TP,ACT,1.0	CHEMBL12106,TP,ACT,1.0	CHEMBL15675,TN,INACT,0.0	CHEMBL266077,TN,INACT,0.3799999952316284	CHEMBL2203713,TN,INACT,0.009999999776482582	CHEMBL42359,TN,INACT,0.0	CHEMBL295583,TP,ACT,1.0	CHEMBL295651,TN,INACT,0.0	CHEMBL608816,TN,INACT,0.0	CHEMBL65531,FN,ACT,0.1899999976158142	CHEMBL312187,TP,ACT,0.8299999833106995	CHEMBL1263,TN,INACT,0.0	CHEMBL510201,TN,INACT,0.0	CHEMBL173743,TP,ACT,0.9599999785423279	CHEMBL106483,TN,INACT,0.0	CHEMBL11528,TP,ACT,1.0	CHEMBL367024,FP,INACT,0.9900000095367432	CHEMBL305558,TN,INACT,0.0	CHEMBL407933,TP,ACT,1.0	CHEMBL59,TN,INACT,0.0	CHEMBL91073,FN,ACT,0.7099999785423279	CHEMBL485576,TN,INACT,0.0	CHEMBL318221,TN,INACT,0.0	CHEMBL70203,TP,ACT,0.9800000190734863	CHEMBL358020,FP,INACT,0.8199999928474426	CHEMBL316012,TP,ACT,1.0	CHEMBL23529,TN,INACT,0.0	CHEMBL393675,TN,INACT,0.019999999552965164	CHEMBL555990,TN,INACT,0.0	CHEMBL553082,TN,INACT,0.0	CHEMBL66893,TP,ACT,0.8100000023841858	CHEMBL3326660,TN,INACT,0.5799999833106995	CHEMBL2113067,TN,INACT,0.0	CHEMBL10588,TP,ACT,1.0	CHEMBL111023,TN,INACT,0.1899999976158142	CHEMBL290454,TN,INACT,0.4699999988079071	CHEMBL196866,TN,INACT,0.0	CHEMBL413040,TN,INACT,0.0	CHEMBL29775,TP,ACT,1.0	CHEMBL9141,FN,ACT,0.23000000417232513	CHEMBL11152,TP,ACT,1.0	CHEMBL414085,TN,INACT,0.019999999552965164	CHEMBL302872,TP,ACT,1.0	CHEMBL557840,TN,INACT,0.0	CHEMBL386152,TN,INACT,0.46000000834465027	CHEMBL228738,TN,INACT,0.07000000029802322	CHEMBL101742,TP,ACT,0.9700000286102295	CHEMBL21502,TN,INACT,0.0	CHEMBL296074,TP,ACT,1.0	CHEMBL2372075,TN,INACT,0.0	CHEMBL285819,TN,INACT,0.10999999940395355	CHEMBL2163713,TP,ACT,0.9700000286102295	CHEMBL177179,FN,ACT,0.5400000214576721	CHEMBL89688,TP,ACT,0.9700000286102295	CHEMBL524064,TN,INACT,0.7099999785423279	CHEMBL72473,TP,ACT,1.0	CHEMBL542877,TN,INACT,0.019999999552965164	CHEMBL105263,TN,INACT,0.0	CHEMBL2261602,TP,ACT,1.0	CHEMBL594801,TN,INACT,0.0	CHEMBL2369493,TN,INACT,0.029999999329447746	CHEMBL307034,TN,INACT,0.0	CHEMBL3753458,TP,ACT,0.949999988079071	CHEMBL300926,FP,INACT,0.9200000166893005	CHEMBL48261,TP,ACT,1.0	CHEMBL2112592,TN,INACT,0.0	CHEMBL3764306,TN,INACT,0.0	CHEMBL2436719,TN,INACT,0.009999999776482582	CHEMBL304714,TN,INACT,0.0	CHEMBL60559,TN,INACT,0.0	CHEMBL64120,TN,INACT,0.0	CHEMBL73373,TP,ACT,1.0	CHEMBL37427,TP,ACT,1.0	CHEMBL273529,TP,ACT,1.0	CHEMBL423405,TN,INACT,0.0	CHEMBL73042,TP,ACT,1.0	CHEMBL366872,TP,ACT,0.8500000238418579	CHEMBL3290986,TN,INACT,0.0	CHEMBL39057,TP,ACT,0.9800000190734863	CHEMBL241080,TN,INACT,0.0	CHEMBL428504,TP,ACT,0.9800000190734863	CHEMBL311138,TP,ACT,0.9399999976158142	CHEMBL354082,TP,ACT,0.9900000095367432	CHEMBL367017,TP,ACT,1.0	CHEMBL2376800,TN,INACT,0.0	CHEMBL47008,TP,ACT,1.0	CHEMBL109094,TN,INACT,0.0	CHEMBL368847,TN,INACT,0.2199999988079071	CHEMBL172760,TN,INACT,0.05000000074505806	CHEMBL286808,FN,ACT,0.0	CHEMBL374602,TN,INACT,0.0	CHEMBL368853,FP,INACT,0.9900000095367432	CHEMBL1793925,TP,ACT,0.9900000095367432	CHEMBL429019,FN,ACT,0.0	CHEMBL104223,TP,ACT,1.0	CHEMBL2111789,TN,INACT,0.0	CHEMBL1907840,TN,INACT,0.0	CHEMBL367382,TP,ACT,1.0	CHEMBL316792,TN,INACT,0.019999999552965164	CHEMBL1381098,TN,INACT,0.0	CHEMBL319452,TP,ACT,1.0	CHEMBL175228,TP,ACT,0.9599999785423279	CHEMBL2163724,TP,ACT,1.0	CHEMBL602474,TN,INACT,0.0	CHEMBL2165339,TP,ACT,0.8399999737739563	CHEMBL8923,TP,ACT,0.9900000095367432	CHEMBL353502,TN,INACT,0.0	CHEMBL1766941,TN,INACT,0.029999999329447746	CHEMBL527880,TN,INACT,0.0	CHEMBL304778,TP,ACT,0.9700000286102295	CHEMBL51138,TN,INACT,0.0	CHEMBL58058,TP,ACT,1.0	CHEMBL106846,TP,ACT,1.0	CHEMBL174413,TP,ACT,1.0	CHEMBL445101,TP,ACT,1.0	CHEMBL48120,TP,ACT,1.0	CHEMBL215434,TN,INACT,0.029999999329447746	CHEMBL287683,TP,ACT,1.0	CHEMBL266996,TN,INACT,0.5899999737739563	CHEMBL104551,TN,INACT,0.0	CHEMBL390842,TN,INACT,0.0	CHEMBL1082036,TN,INACT,0.0	CHEMBL1766944,TN,INACT,0.12999999523162842	CHEMBL3315201,TN,INACT,0.0	CHEMBL47450,TP,ACT,1.0	CHEMBL3736037,TP,ACT,1.0	CHEMBL385492,TP,ACT,1.0	CHEMBL250713,TN,INACT,0.0	CHEMBL435385,TP,ACT,1.0	CHEMBL170229,TP,ACT,0.800000011920929	CHEMBL387200,TP,ACT,1.0	CHEMBL73272,TN,INACT,0.0	CHEMBL336081,TN,INACT,0.0	CHEMBL418326,TP,ACT,1.0	CHEMBL2391353,TN,INACT,0.0	CHEMBL3665431,TN,INACT,0.0	CHEMBL22513,TP,ACT,1.0	CHEMBL286014,TP,ACT,1.0	CHEMBL263342,TN,INACT,0.0	CHEMBL3343013,TN,INACT,0.0	CHEMBL312958,TN,INACT,0.0	CHEMBL3633665,TN,INACT,0.0	CHEMBL123994,TP,ACT,1.0	CHEMBL80342,FN,ACT,0.7699999809265137	CHEMBL175616,TP,ACT,1.0	CHEMBL284656,TP,ACT,1.0	CHEMBL3327373,TN,INACT,0.0	CHEMBL143761,TN,INACT,0.0	CHEMBL62948,TN,INACT,0.0	CHEMBL274370,TP,ACT,1.0	CHEMBL2442635,TN,INACT,0.0	CHEMBL10846,TP,ACT,1.0	CHEMBL317716,TP,ACT,1.0	CHEMBL286395,FN,ACT,0.41999998688697815	CHEMBL420029,TP,ACT,0.9700000286102295	CHEMBL10016,TP,ACT,1.0	CHEMBL1205177,FN,ACT,0.0	CHEMBL62840,TN,INACT,0.0	CHEMBL105268,TN,INACT,0.0	CHEMBL381108,TN,INACT,0.029999999329447746	CHEMBL283648,TP,ACT,1.0	CHEMBL62527,TN,INACT,0.0	CHEMBL21616,TN,INACT,0.0	CHEMBL320569,TN,INACT,0.019999999552965164	CHEMBL241460,FN,ACT,0.019999999552965164	CHEMBL216082,TP,ACT,1.0	CHEMBL1791272,FP,INACT,1.0	CHEMBL289687,FN,ACT,0.33000001311302185	CHEMBL104947,TN,INACT,0.0	CHEMBL27262,FP,INACT,0.9900000095367432	CHEMBL444128,TN,INACT,0.0	CHEMBL3604299,TN,INACT,0.009999999776482582	CHEMBL277285,TN,INACT,0.0	CHEMBL495854,TN,INACT,0.019999999552965164	CHEMBL118553,TN,INACT,0.07999999821186066	CHEMBL336033,TP,ACT,1.0	CHEMBL313984,TP,ACT,1.0	CHEMBL286800,TN,INACT,0.0	CHEMBL112325,FP,INACT,0.9800000190734863	CHEMBL405178,TP,ACT,1.0	CHEMBL78601,TP,ACT,1.0	CHEMBL1766946,TN,INACT,0.10999999940395355	CHEMBL319031,TP,ACT,1.0	CHEMBL312750,TN,INACT,0.009999999776482582	CHEMBL250715,TN,INACT,0.0	CHEMBL47620,TP,ACT,1.0	CHEMBL1766825,TN,INACT,0.0	CHEMBL1921995,TN,INACT,0.09000000357627869	CHEMBL306218,FN,ACT,0.14000000059604645	CHEMBL10607,TP,ACT,1.0	CHEMBL351531,TN,INACT,0.0	CHEMBL1793928,TP,ACT,1.0	CHEMBL47404,TP,ACT,0.9100000262260437	CHEMBL11162,TP,ACT,1.0	CHEMBL169675,TN,INACT,0.0	CHEMBL3342363,TN,INACT,0.0	CHEMBL366911,TN,INACT,0.10000000149011612	CHEMBL148853,FP,INACT,1.0	CHEMBL524026,TN,INACT,0.30000001192092896	CHEMBL303386,TN,INACT,0.029999999329447746	CHEMBL611496,TN,INACT,0.0	CHEMBL411925,TP,ACT,1.0	CHEMBL2163919,TN,INACT,0.5099999904632568	CHEMBL10457,TP,ACT,1.0	CHEMBL34328,TN,INACT,0.0	CHEMBL29710,TP,ACT,0.9900000095367432	CHEMBL177070,TP,ACT,0.9900000095367432	CHEMBL311216,TP,ACT,0.9800000190734863	CHEMBL717,TN,INACT,0.009999999776482582	CHEMBL11706,TP,ACT,1.0	CHEMBL2165330,TP,ACT,0.9100000262260437	CHEMBL3238446,TN,INACT,0.0	CHEMBL3218120,TN,INACT,0.009999999776482582	CHEMBL121647,TP,ACT,1.0	CHEMBL2261356,TP,ACT,1.0	CHEMBL59931,TN,INACT,0.0	CHEMBL2261600,TP,ACT,1.0	CHEMBL37920,TP,ACT,1.0	CHEMBL404888,TN,INACT,0.05000000074505806	CHEMBL2163711,FN,ACT,0.029999999329447746	CHEMBL3290984,TN,INACT,0.0	CHEMBL540360,TN,INACT,0.0	CHEMBL2370253,FN,ACT,0.009999999776482582	CHEMBL23418,TP,ACT,0.9300000071525574	CHEMBL305270,TP,ACT,0.9800000190734863	CHEMBL76623,FN,ACT,0.20000000298023224	CHEMBL3604309,TN,INACT,0.0	CHEMBL542544,TN,INACT,0.0	CHEMBL539334,TN,INACT,0.0	CHEMBL68738,TN,INACT,0.27000001072883606	CHEMBL2431726,TN,INACT,0.0	CHEMBL3665436,TN,INACT,0.0	CHEMBL291404,TP,ACT,1.0	CHEMBL6412,TP,ACT,1.0	CHEMBL59733,TN,INACT,0.0	CHEMBL2324200,TN,INACT,0.5	CHEMBL417651,TP,ACT,1.0	CHEMBL62601,TN,INACT,0.5600000023841858	CHEMBL295697,TP,ACT,0.9200000166893005	CHEMBL352396,TP,ACT,1.0	CHEMBL9168,FP,INACT,0.7900000214576721	CHEMBL173336,FN,ACT,0.7200000286102295	CHEMBL322920,TP,ACT,1.0	CHEMBL415176,FP,INACT,0.800000011920929	CHEMBL2163723,TP,ACT,1.0	CHEMBL276018,TP,ACT,1.0	CHEMBL128360,TN,INACT,0.0	CHEMBL426218,TP,ACT,0.9900000095367432	CHEMBL3290766,TN,INACT,0.0	CHEMBL41686,TN,INACT,0.0	CHEMBL62115,TN,INACT,0.0	CHEMBL503924,TN,INACT,0.0	CHEMBL293874,TN,INACT,0.0	CHEMBL417246,TP,ACT,1.0	CHEMBL2372077,TN,INACT,0.0	CHEMBL1083787,TN,INACT,0.0	CHEMBL172666,TP,ACT,0.9800000190734863	CHEMBL67325,TP,ACT,1.0	CHEMBL2431237,TN,INACT,0.029999999329447746	CHEMBL368339,FP,INACT,0.9800000190734863	CHEMBL319036,FN,ACT,0.4099999964237213	CHEMBL432815,TP,ACT,1.0	CHEMBL2261362,TP,ACT,1.0	CHEMBL309692,TP,ACT,0.8500000238418579	CHEMBL2165335,FN,ACT,0.7099999785423279	CHEMBL414917,TP,ACT,1.0	CHEMBL294087,TN,INACT,0.0	CHEMBL3633040,TP,ACT,1.0	CHEMBL367958,TP,ACT,1.0	CHEMBL284887,TN,INACT,0.0	CHEMBL554692,TN,INACT,0.0	CHEMBL73096,TN,INACT,0.0	CHEMBL2163726,TP,ACT,1.0	CHEMBL494093,TN,INACT,0.029999999329447746	CHEMBL330003,TP,ACT,1.0	CHEMBL316523,TP,ACT,1.0	CHEMBL80945,TN,INACT,0.009999999776482582	CHEMBL2163691,TP,ACT,0.949999988079071	CHEMBL286737,TN,INACT,0.0	CHEMBL10951,TP,ACT,1.0	CHEMBL76438,TP,ACT,1.0	CHEMBL122832,TP,ACT,0.800000011920929	CHEMBL255793,TN,INACT,0.0	CHEMBL28920,TP,ACT,1.0	CHEMBL2261358,TP,ACT,1.0	CHEMBL3735236,FN,ACT,0.05000000074505806	CHEMBL424371,TP,ACT,0.9700000286102295	CHEMBL217002,TN,INACT,0.0	CHEMBL173557,TP,ACT,1.0	CHEMBL275545,FN,ACT,0.7400000095367432	CHEMBL368945,TP,ACT,1.0	CHEMBL283320,TN,INACT,0.0	CHEMBL176997,TP,ACT,1.0	CHEMBL59413,TN,INACT,0.0	CHEMBL406279,TP,ACT,1.0	CHEMBL9228,FP,INACT,0.9800000190734863	CHEMBL2369736,FN,ACT,0.23000000417232513	CHEMBL2376804,TN,INACT,0.6800000071525574	CHEMBL63631,TN,INACT,0.0	CHEMBL332645,TN,INACT,0.28999999165534973	CHEMBL142295,TN,INACT,0.0	CHEMBL78552,TP,ACT,1.0	CHEMBL3327368,TN,INACT,0.0	CHEMBL291516,TN,INACT,0.0	CHEMBL279493,TN,INACT,0.4399999976158142	CHEMBL10733,TP,ACT,1.0	CHEMBL281963,TN,INACT,0.0	CHEMBL105515,TN,INACT,0.0	CHEMBL433619,TP,ACT,1.0	CHEMBL384248,FP,INACT,1.0	CHEMBL109926,FN,ACT,0.2800000011920929	CHEMBL45305,TN,INACT,0.0	CHEMBL435901,TN,INACT,0.0	CHEMBL328517,TP,ACT,1.0	CHEMBL367339,TP,ACT,1.0	CHEMBL367033,FN,ACT,0.029999999329447746	CHEMBL349505,TN,INACT,0.0	CHEMBL12779,TP,ACT,1.0	CHEMBL2442639,TN,INACT,0.0	CHEMBL1743758,TN,INACT,0.0	CHEMBL10901,TP,ACT,1.0	CHEMBL2163917,TN,INACT,0.4399999976158142	CHEMBL3218124,TN,INACT,0.0	CHEMBL1271691,TP,ACT,1.0	CHEMBL78830,TP,ACT,0.8600000143051147	CHEMBL2431109,TN,INACT,0.009999999776482582	CHEMBL111277,TP,ACT,0.9800000190734863	CHEMBL2163695,FN,ACT,0.17000000178813934	CHEMBL336437,TN,INACT,0.0	CHEMBL332289,FN,ACT,0.7400000095367432	CHEMBL254505,TN,INACT,0.029999999329447746	CHEMBL63937,TP,ACT,1.0	CHEMBL25977,FP,INACT,1.0	CHEMBL3735797,FP,INACT,1.0	CHEMBL368383,FN,ACT,0.07999999821186066	CHEMBL291602,TN,INACT,0.029999999329447746	CHEMBL316968,TN,INACT,0.0	CHEMBL10744,TP,ACT,1.0	CHEMBL80980,FN,ACT,0.5899999737739563	CHEMBL316561,TN,INACT,0.0	CHEMBL3350741,TN,INACT,0.7599999904632568	CHEMBL149763,TP,ACT,1.0	CHEMBL296129,TP,ACT,0.9800000190734863	CHEMBL10151,TP,ACT,1.0	CHEMBL305980,TP,ACT,1.0	CHEMBL354126,TN,INACT,0.009999999776482582	CHEMBL322537,FN,ACT,0.09000000357627869	CHEMBL434674,TN,INACT,0.009999999776482582	CHEMBL273613,TP,ACT,1.0	CHEMBL426912,TN,INACT,0.0	CHEMBL124208,TN,INACT,0.0	CHEMBL1269101,TP,ACT,1.0	CHEMBL62808,TN,INACT,0.0	CHEMBL2163717,TP,ACT,0.9599999785423279	CHEMBL240888,TN,INACT,0.009999999776482582	CHEMBL1091778,TN,INACT,0.009999999776482582	CHEMBL10092,TP,ACT,1.0	CHEMBL2370066,TP,ACT,1.0	CHEMBL3327367,TN,INACT,0.009999999776482582	CHEMBL300750,TN,INACT,0.03999999910593033	CHEMBL286621,TP,ACT,1.0	CHEMBL303204,TN,INACT,0.009999999776482582	CHEMBL111218,TN,INACT,0.0	CHEMBL2431106,TN,INACT,0.0	CHEMBL6568,TN,INACT,0.0	CHEMBL78929,FN,ACT,0.019999999552965164	CHEMBL15936,TN,INACT,0.0	CHEMBL282667,TN,INACT,0.0	CHEMBL109786,TN,INACT,0.0	CHEMBL174699,TP,ACT,1.0	CHEMBL3753134,TP,ACT,1.0	CHEMBL557576,TN,INACT,0.0	CHEMBL435810,TN,INACT,0.0	CHEMBL76360,TP,ACT,1.0	CHEMBL149391,TN,INACT,0.25999999046325684	CHEMBL170121,FN,ACT,0.20000000298023224	CHEMBL556868,TN,INACT,0.12999999523162842	CHEMBL23444,TP,ACT,0.9700000286102295	CHEMBL44544,TP,ACT,1.0	CHEMBL3753406,TP,ACT,1.0	CHEMBL302564,TP,ACT,1.0	CHEMBL3410301,TN,INACT,0.0	CHEMBL423666,TN,INACT,0.0	CHEMBL10915,TP,ACT,1.0	

