CNNModel CHEMBL4439 adam 0.001 15 256 0 0.6 False True
Number of active compounds :	663
Number of inactive compounds :	663
---------------------------------
Run id: CNNModel_CHEMBL4439_adam_0.001_15_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4439_adam_0.001_15_256_0.6_True/
---------------------------------
Training samples: 839
Validation samples: 263
--
Training Step: 1  | time: 2.176s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/839
[A[ATraining Step: 2  | total loss: [1m[32m0.62399[0m[0m | time: 4.630s
[2K
| Adam | epoch: 001 | loss: 0.62399 - acc: 0.3656 -- iter: 064/839
[A[ATraining Step: 3  | total loss: [1m[32m0.68075[0m[0m | time: 17.686s
[2K
| Adam | epoch: 001 | loss: 0.68075 - acc: 0.4756 -- iter: 096/839
[A[ATraining Step: 4  | total loss: [1m[32m0.69153[0m[0m | time: 18.906s
[2K
| Adam | epoch: 001 | loss: 0.69153 - acc: 0.4470 -- iter: 128/839
[A[ATraining Step: 5  | total loss: [1m[32m0.69218[0m[0m | time: 20.289s
[2K
| Adam | epoch: 001 | loss: 0.69218 - acc: 0.5270 -- iter: 160/839
[A[ATraining Step: 6  | total loss: [1m[32m0.69219[0m[0m | time: 21.611s
[2K
| Adam | epoch: 001 | loss: 0.69219 - acc: 0.5498 -- iter: 192/839
[A[ATraining Step: 7  | total loss: [1m[32m0.69089[0m[0m | time: 22.964s
[2K
| Adam | epoch: 001 | loss: 0.69089 - acc: 0.5762 -- iter: 224/839
[A[ATraining Step: 8  | total loss: [1m[32m0.69430[0m[0m | time: 24.505s
[2K
| Adam | epoch: 001 | loss: 0.69430 - acc: 0.5157 -- iter: 256/839
[A[ATraining Step: 9  | total loss: [1m[32m0.69279[0m[0m | time: 25.796s
[2K
| Adam | epoch: 001 | loss: 0.69279 - acc: 0.5240 -- iter: 288/839
[A[ATraining Step: 10  | total loss: [1m[32m0.70050[0m[0m | time: 27.649s
[2K
| Adam | epoch: 001 | loss: 0.70050 - acc: 0.4339 -- iter: 320/839
[A[ATraining Step: 11  | total loss: [1m[32m0.69581[0m[0m | time: 29.135s
[2K
| Adam | epoch: 001 | loss: 0.69581 - acc: 0.4948 -- iter: 352/839
[A[ATraining Step: 12  | total loss: [1m[32m0.69413[0m[0m | time: 30.597s
[2K
| Adam | epoch: 001 | loss: 0.69413 - acc: 0.5112 -- iter: 384/839
[A[ATraining Step: 13  | total loss: [1m[32m0.69285[0m[0m | time: 32.140s
[2K
| Adam | epoch: 001 | loss: 0.69285 - acc: 0.5332 -- iter: 416/839
[A[ATraining Step: 14  | total loss: [1m[32m0.69336[0m[0m | time: 35.540s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.5068 -- iter: 448/839
[A[ATraining Step: 15  | total loss: [1m[32m0.69331[0m[0m | time: 37.133s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.5042 -- iter: 480/839
[A[ATraining Step: 16  | total loss: [1m[32m0.69258[0m[0m | time: 38.555s
[2K
| Adam | epoch: 001 | loss: 0.69258 - acc: 0.5378 -- iter: 512/839
[A[ATraining Step: 17  | total loss: [1m[32m0.69302[0m[0m | time: 44.260s
[2K
| Adam | epoch: 001 | loss: 0.69302 - acc: 0.5129 -- iter: 544/839
[A[ATraining Step: 18  | total loss: [1m[32m0.69370[0m[0m | time: 46.957s
[2K
| Adam | epoch: 001 | loss: 0.69370 - acc: 0.4868 -- iter: 576/839
[A[ATraining Step: 19  | total loss: [1m[32m0.69461[0m[0m | time: 52.189s
[2K
| Adam | epoch: 001 | loss: 0.69461 - acc: 0.4495 -- iter: 608/839
[A[ATraining Step: 20  | total loss: [1m[32m0.69358[0m[0m | time: 53.641s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.4959 -- iter: 640/839
[A[ATraining Step: 21  | total loss: [1m[32m0.69363[0m[0m | time: 55.177s
[2K
| Adam | epoch: 001 | loss: 0.69363 - acc: 0.4875 -- iter: 672/839
[A[ATraining Step: 22  | total loss: [1m[32m0.69352[0m[0m | time: 56.582s
[2K
| Adam | epoch: 001 | loss: 0.69352 - acc: 0.4912 -- iter: 704/839
[A[ATraining Step: 23  | total loss: [1m[32m0.69319[0m[0m | time: 57.929s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5119 -- iter: 736/839
[A[ATraining Step: 24  | total loss: [1m[32m0.69340[0m[0m | time: 59.510s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.4910 -- iter: 768/839
[A[ATraining Step: 25  | total loss: [1m[32m0.69254[0m[0m | time: 61.022s
[2K
| Adam | epoch: 001 | loss: 0.69254 - acc: 0.5531 -- iter: 800/839
[A[ATraining Step: 26  | total loss: [1m[32m0.69272[0m[0m | time: 62.621s
[2K
| Adam | epoch: 001 | loss: 0.69272 - acc: 0.5390 -- iter: 832/839
[A[ATraining Step: 27  | total loss: [1m[32m0.69241[0m[0m | time: 73.626s
[2K
| Adam | epoch: 001 | loss: 0.69241 - acc: 0.5531 | val_loss: 0.69357 - val_acc: 0.4829 -- iter: 839/839
--
Training Step: 28  | total loss: [1m[32m0.69303[0m[0m | time: 0.459s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5220 -- iter: 032/839
[A[ATraining Step: 29  | total loss: [1m[32m0.69350[0m[0m | time: 1.984s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.4993 -- iter: 064/839
[A[ATraining Step: 30  | total loss: [1m[32m0.69451[0m[0m | time: 3.235s
[2K
| Adam | epoch: 002 | loss: 0.69451 - acc: 0.4550 -- iter: 096/839
[A[ATraining Step: 31  | total loss: [1m[32m0.69457[0m[0m | time: 4.583s
[2K
| Adam | epoch: 002 | loss: 0.69457 - acc: 0.4438 -- iter: 128/839
[A[ATraining Step: 32  | total loss: [1m[32m0.69413[0m[0m | time: 5.940s
[2K
| Adam | epoch: 002 | loss: 0.69413 - acc: 0.4635 -- iter: 160/839
[A[ATraining Step: 33  | total loss: [1m[32m0.69364[0m[0m | time: 7.185s
[2K
| Adam | epoch: 002 | loss: 0.69364 - acc: 0.4921 -- iter: 192/839
[A[ATraining Step: 34  | total loss: [1m[32m0.69362[0m[0m | time: 8.630s
[2K
| Adam | epoch: 002 | loss: 0.69362 - acc: 0.4871 -- iter: 224/839
[A[ATraining Step: 35  | total loss: [1m[32m0.69339[0m[0m | time: 10.308s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.4963 -- iter: 256/839
[A[ATraining Step: 36  | total loss: [1m[32m0.69345[0m[0m | time: 12.042s
[2K
| Adam | epoch: 002 | loss: 0.69345 - acc: 0.4843 -- iter: 288/839
[A[ATraining Step: 37  | total loss: [1m[32m0.69327[0m[0m | time: 13.522s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4999 -- iter: 320/839
[A[ATraining Step: 38  | total loss: [1m[32m0.69330[0m[0m | time: 16.279s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4877 -- iter: 352/839
[A[ATraining Step: 39  | total loss: [1m[32m0.69315[0m[0m | time: 17.749s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5140 -- iter: 384/839
[A[ATraining Step: 40  | total loss: [1m[32m0.69312[0m[0m | time: 19.246s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5055 -- iter: 416/839
[A[ATraining Step: 41  | total loss: [1m[32m0.69314[0m[0m | time: 20.805s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.4988 -- iter: 448/839
[A[ATraining Step: 42  | total loss: [1m[32m0.69296[0m[0m | time: 22.359s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5102 -- iter: 480/839
[A[ATraining Step: 43  | total loss: [1m[32m0.69280[0m[0m | time: 24.109s
[2K
| Adam | epoch: 002 | loss: 0.69280 - acc: 0.5250 -- iter: 512/839
[A[ATraining Step: 44  | total loss: [1m[32m0.69298[0m[0m | time: 25.712s
[2K
| Adam | epoch: 002 | loss: 0.69298 - acc: 0.5044 -- iter: 544/839
[A[ATraining Step: 45  | total loss: [1m[32m0.69272[0m[0m | time: 27.066s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5090 -- iter: 576/839
[A[ATraining Step: 46  | total loss: [1m[32m0.69235[0m[0m | time: 28.463s
[2K
| Adam | epoch: 002 | loss: 0.69235 - acc: 0.5283 -- iter: 608/839
[A[ATraining Step: 47  | total loss: [1m[32m0.69221[0m[0m | time: 30.084s
[2K
| Adam | epoch: 002 | loss: 0.69221 - acc: 0.5237 -- iter: 640/839
[A[ATraining Step: 48  | total loss: [1m[32m0.69229[0m[0m | time: 31.578s
[2K
| Adam | epoch: 002 | loss: 0.69229 - acc: 0.5149 -- iter: 672/839
[A[ATraining Step: 49  | total loss: [1m[32m0.69221[0m[0m | time: 33.186s
[2K
| Adam | epoch: 002 | loss: 0.69221 - acc: 0.4928 -- iter: 704/839
[A[ATraining Step: 50  | total loss: [1m[32m0.69146[0m[0m | time: 36.630s
[2K
| Adam | epoch: 002 | loss: 0.69146 - acc: 0.5084 -- iter: 736/839
[A[ATraining Step: 51  | total loss: [1m[32m0.69121[0m[0m | time: 43.105s
[2K
| Adam | epoch: 002 | loss: 0.69121 - acc: 0.5215 -- iter: 768/839
[A[ATraining Step: 52  | total loss: [1m[32m0.69002[0m[0m | time: 44.519s
[2K
| Adam | epoch: 002 | loss: 0.69002 - acc: 0.5464 -- iter: 800/839
[A[ATraining Step: 53  | total loss: [1m[32m0.68818[0m[0m | time: 45.884s
[2K
| Adam | epoch: 002 | loss: 0.68818 - acc: 0.5718 -- iter: 832/839
[A[ATraining Step: 54  | total loss: [1m[32m0.68994[0m[0m | time: 49.957s
[2K
| Adam | epoch: 002 | loss: 0.68994 - acc: 0.5478 | val_loss: 0.68069 - val_acc: 0.4905 -- iter: 839/839
--
Training Step: 55  | total loss: [1m[32m0.68615[0m[0m | time: 0.542s
[2K
| Adam | epoch: 003 | loss: 0.68615 - acc: 0.5499 -- iter: 032/839
[A[ATraining Step: 56  | total loss: [1m[32m0.67576[0m[0m | time: 0.943s
[2K
| Adam | epoch: 003 | loss: 0.67576 - acc: 0.5931 -- iter: 064/839
[A[ATraining Step: 57  | total loss: [1m[32m0.65874[0m[0m | time: 2.541s
[2K
| Adam | epoch: 003 | loss: 0.65874 - acc: 0.6296 -- iter: 096/839
[A[ATraining Step: 58  | total loss: [1m[32m0.66849[0m[0m | time: 4.174s
[2K
| Adam | epoch: 003 | loss: 0.66849 - acc: 0.6205 -- iter: 128/839
[A[ATraining Step: 59  | total loss: [1m[32m0.68820[0m[0m | time: 8.656s
[2K
| Adam | epoch: 003 | loss: 0.68820 - acc: 0.6001 -- iter: 160/839
[A[ATraining Step: 60  | total loss: [1m[32m0.70420[0m[0m | time: 22.011s
[2K
| Adam | epoch: 003 | loss: 0.70420 - acc: 0.5703 -- iter: 192/839
[A[ATraining Step: 61  | total loss: [1m[32m0.70719[0m[0m | time: 29.906s
[2K
| Adam | epoch: 003 | loss: 0.70719 - acc: 0.5489 -- iter: 224/839
[A[ATraining Step: 62  | total loss: [1m[32m0.70578[0m[0m | time: 31.320s
[2K
| Adam | epoch: 003 | loss: 0.70578 - acc: 0.5346 -- iter: 256/839
[A[ATraining Step: 63  | total loss: [1m[32m0.70201[0m[0m | time: 32.474s
[2K
| Adam | epoch: 003 | loss: 0.70201 - acc: 0.5460 -- iter: 288/839
[A[ATraining Step: 64  | total loss: [1m[32m0.69911[0m[0m | time: 33.772s
[2K
| Adam | epoch: 003 | loss: 0.69911 - acc: 0.5715 -- iter: 320/839
[A[ATraining Step: 65  | total loss: [1m[32m0.69785[0m[0m | time: 35.239s
[2K
| Adam | epoch: 003 | loss: 0.69785 - acc: 0.5743 -- iter: 352/839
[A[ATraining Step: 66  | total loss: [1m[32m0.69653[0m[0m | time: 36.737s
[2K
| Adam | epoch: 003 | loss: 0.69653 - acc: 0.5728 -- iter: 384/839
[A[ATraining Step: 67  | total loss: [1m[32m0.69540[0m[0m | time: 38.255s
[2K
| Adam | epoch: 003 | loss: 0.69540 - acc: 0.5679 -- iter: 416/839
[A[ATraining Step: 68  | total loss: [1m[32m0.69356[0m[0m | time: 39.693s
[2K
| Adam | epoch: 003 | loss: 0.69356 - acc: 0.5783 -- iter: 448/839
[A[ATraining Step: 69  | total loss: [1m[32m0.69383[0m[0m | time: 41.207s
[2K
| Adam | epoch: 003 | loss: 0.69383 - acc: 0.5582 -- iter: 480/839
[A[ATraining Step: 70  | total loss: [1m[32m0.69443[0m[0m | time: 42.473s
[2K
| Adam | epoch: 003 | loss: 0.69443 - acc: 0.5371 -- iter: 512/839
[A[ATraining Step: 71  | total loss: [1m[32m0.69360[0m[0m | time: 44.138s
[2K
| Adam | epoch: 003 | loss: 0.69360 - acc: 0.5364 -- iter: 544/839
[A[ATraining Step: 72  | total loss: [1m[32m0.69328[0m[0m | time: 45.623s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.5393 -- iter: 576/839
[A[ATraining Step: 73  | total loss: [1m[32m0.69250[0m[0m | time: 47.209s
[2K
| Adam | epoch: 003 | loss: 0.69250 - acc: 0.5593 -- iter: 608/839
[A[ATraining Step: 74  | total loss: [1m[32m0.69151[0m[0m | time: 49.028s
[2K
| Adam | epoch: 003 | loss: 0.69151 - acc: 0.5734 -- iter: 640/839
[A[ATraining Step: 75  | total loss: [1m[32m0.69103[0m[0m | time: 51.890s
[2K
| Adam | epoch: 003 | loss: 0.69103 - acc: 0.5823 -- iter: 672/839
[A[ATraining Step: 76  | total loss: [1m[32m0.68988[0m[0m | time: 53.254s
[2K
| Adam | epoch: 003 | loss: 0.68988 - acc: 0.5903 -- iter: 704/839
[A[ATraining Step: 77  | total loss: [1m[32m0.68987[0m[0m | time: 54.681s
[2K
| Adam | epoch: 003 | loss: 0.68987 - acc: 0.5840 -- iter: 736/839
[A[ATraining Step: 78  | total loss: [1m[32m0.68887[0m[0m | time: 56.183s
[2K
| Adam | epoch: 003 | loss: 0.68887 - acc: 0.5916 -- iter: 768/839
[A[ATraining Step: 79  | total loss: [1m[32m0.68815[0m[0m | time: 57.772s
[2K
| Adam | epoch: 003 | loss: 0.68815 - acc: 0.5983 -- iter: 800/839
[A[ATraining Step: 80  | total loss: [1m[32m0.68632[0m[0m | time: 59.327s
[2K
| Adam | epoch: 003 | loss: 0.68632 - acc: 0.6106 -- iter: 832/839
[A[ATraining Step: 81  | total loss: [1m[32m0.68480[0m[0m | time: 63.089s
[2K
| Adam | epoch: 003 | loss: 0.68480 - acc: 0.6247 | val_loss: 0.65225 - val_acc: 0.6882 -- iter: 839/839
--
Training Step: 82  | total loss: [1m[32m0.68472[0m[0m | time: 1.454s
[2K
| Adam | epoch: 004 | loss: 0.68472 - acc: 0.6247 -- iter: 032/839
[A[ATraining Step: 83  | total loss: [1m[32m0.68436[0m[0m | time: 2.210s
[2K
| Adam | epoch: 004 | loss: 0.68436 - acc: 0.6091 -- iter: 064/839
[A[ATraining Step: 84  | total loss: [1m[32m0.67779[0m[0m | time: 2.544s
[2K
| Adam | epoch: 004 | loss: 0.67779 - acc: 0.6339 -- iter: 096/839
[A[ATraining Step: 85  | total loss: [1m[32m0.66957[0m[0m | time: 8.926s
[2K
| Adam | epoch: 004 | loss: 0.66957 - acc: 0.6562 -- iter: 128/839
[A[ATraining Step: 86  | total loss: [1m[32m0.67159[0m[0m | time: 10.110s
[2K
| Adam | epoch: 004 | loss: 0.67159 - acc: 0.6469 -- iter: 160/839
[A[ATraining Step: 87  | total loss: [1m[32m0.65782[0m[0m | time: 11.511s
[2K
| Adam | epoch: 004 | loss: 0.65782 - acc: 0.6634 -- iter: 192/839
[A[ATraining Step: 88  | total loss: [1m[32m0.65201[0m[0m | time: 12.879s
[2K
| Adam | epoch: 004 | loss: 0.65201 - acc: 0.6658 -- iter: 224/839
[A[ATraining Step: 89  | total loss: [1m[32m0.64624[0m[0m | time: 14.366s
[2K
| Adam | epoch: 004 | loss: 0.64624 - acc: 0.6680 -- iter: 256/839
[A[ATraining Step: 90  | total loss: [1m[32m0.64106[0m[0m | time: 16.162s
[2K
| Adam | epoch: 004 | loss: 0.64106 - acc: 0.6700 -- iter: 288/839
[A[ATraining Step: 91  | total loss: [1m[32m0.62413[0m[0m | time: 17.615s
[2K
| Adam | epoch: 004 | loss: 0.62413 - acc: 0.6842 -- iter: 320/839
[A[ATraining Step: 92  | total loss: [1m[32m0.62841[0m[0m | time: 19.144s
[2K
| Adam | epoch: 004 | loss: 0.62841 - acc: 0.6720 -- iter: 352/839
[A[ATraining Step: 93  | total loss: [1m[32m0.61219[0m[0m | time: 20.742s
[2K
| Adam | epoch: 004 | loss: 0.61219 - acc: 0.6830 -- iter: 384/839
[A[ATraining Step: 94  | total loss: [1m[32m0.62551[0m[0m | time: 22.043s
[2K
| Adam | epoch: 004 | loss: 0.62551 - acc: 0.6803 -- iter: 416/839
[A[ATraining Step: 95  | total loss: [1m[32m0.61094[0m[0m | time: 23.464s
[2K
| Adam | epoch: 004 | loss: 0.61094 - acc: 0.6841 -- iter: 448/839
[A[ATraining Step: 96  | total loss: [1m[32m0.60297[0m[0m | time: 25.059s
[2K
| Adam | epoch: 004 | loss: 0.60297 - acc: 0.6876 -- iter: 480/839
[A[ATraining Step: 97  | total loss: [1m[32m0.60659[0m[0m | time: 26.588s
[2K
| Adam | epoch: 004 | loss: 0.60659 - acc: 0.6876 -- iter: 512/839
[A[ATraining Step: 98  | total loss: [1m[32m0.59648[0m[0m | time: 29.575s
[2K
| Adam | epoch: 004 | loss: 0.59648 - acc: 0.6907 -- iter: 544/839
[A[ATraining Step: 99  | total loss: [1m[32m0.58752[0m[0m | time: 33.782s
[2K
| Adam | epoch: 004 | loss: 0.58752 - acc: 0.6935 -- iter: 576/839
[A[ATraining Step: 100  | total loss: [1m[32m0.59966[0m[0m | time: 35.755s
[2K
| Adam | epoch: 004 | loss: 0.59966 - acc: 0.6867 -- iter: 608/839
[A[ATraining Step: 101  | total loss: [1m[32m0.59812[0m[0m | time: 42.161s
[2K
| Adam | epoch: 004 | loss: 0.59812 - acc: 0.6742 -- iter: 640/839
[A[ATraining Step: 102  | total loss: [1m[32m0.58685[0m[0m | time: 43.362s
[2K
| Adam | epoch: 004 | loss: 0.58685 - acc: 0.6818 -- iter: 672/839
[A[ATraining Step: 103  | total loss: [1m[32m0.58006[0m[0m | time: 45.113s
[2K
| Adam | epoch: 004 | loss: 0.58006 - acc: 0.6824 -- iter: 704/839
[A[ATraining Step: 104  | total loss: [1m[32m0.59976[0m[0m | time: 46.626s
[2K
| Adam | epoch: 004 | loss: 0.59976 - acc: 0.6673 -- iter: 736/839
[A[ATraining Step: 105  | total loss: [1m[32m0.61024[0m[0m | time: 48.118s
[2K
| Adam | epoch: 004 | loss: 0.61024 - acc: 0.6505 -- iter: 768/839
[A[ATraining Step: 106  | total loss: [1m[32m0.60937[0m[0m | time: 49.527s
[2K
| Adam | epoch: 004 | loss: 0.60937 - acc: 0.6542 -- iter: 800/839
[A[ATraining Step: 107  | total loss: [1m[32m0.60946[0m[0m | time: 56.112s
[2K
| Adam | epoch: 004 | loss: 0.60946 - acc: 0.6544 -- iter: 832/839
[A[ATraining Step: 108  | total loss: [1m[32m0.60907[0m[0m | time: 59.835s
[2K
| Adam | epoch: 004 | loss: 0.60907 - acc: 0.6671 | val_loss: 0.61842 - val_acc: 0.6806 -- iter: 839/839
--
Training Step: 109  | total loss: [1m[32m0.60917[0m[0m | time: 1.633s
[2K
| Adam | epoch: 005 | loss: 0.60917 - acc: 0.6660 -- iter: 032/839
[A[ATraining Step: 110  | total loss: [1m[32m0.59850[0m[0m | time: 3.272s
[2K
| Adam | epoch: 005 | loss: 0.59850 - acc: 0.6901 -- iter: 064/839
[A[ATraining Step: 111  | total loss: [1m[32m0.59563[0m[0m | time: 3.703s
[2K
| Adam | epoch: 005 | loss: 0.59563 - acc: 0.6898 -- iter: 096/839
[A[ATraining Step: 112  | total loss: [1m[32m0.58894[0m[0m | time: 4.551s
[2K
| Adam | epoch: 005 | loss: 0.58894 - acc: 0.7065 -- iter: 128/839
[A[ATraining Step: 113  | total loss: [1m[32m0.58159[0m[0m | time: 12.318s
[2K
| Adam | epoch: 005 | loss: 0.58159 - acc: 0.7216 -- iter: 160/839
[A[ATraining Step: 114  | total loss: [1m[32m0.58109[0m[0m | time: 13.672s
[2K
| Adam | epoch: 005 | loss: 0.58109 - acc: 0.7244 -- iter: 192/839
[A[ATraining Step: 115  | total loss: [1m[32m0.60725[0m[0m | time: 15.197s
[2K
| Adam | epoch: 005 | loss: 0.60725 - acc: 0.7082 -- iter: 224/839
[A[ATraining Step: 116  | total loss: [1m[32m0.60402[0m[0m | time: 16.915s
[2K
| Adam | epoch: 005 | loss: 0.60402 - acc: 0.7062 -- iter: 256/839
[A[ATraining Step: 117  | total loss: [1m[32m0.59611[0m[0m | time: 18.568s
[2K
| Adam | epoch: 005 | loss: 0.59611 - acc: 0.7074 -- iter: 288/839
[A[ATraining Step: 118  | total loss: [1m[32m0.59541[0m[0m | time: 24.769s
[2K
| Adam | epoch: 005 | loss: 0.59541 - acc: 0.7117 -- iter: 320/839
[A[ATraining Step: 119  | total loss: [1m[32m0.59257[0m[0m | time: 31.392s
[2K
| Adam | epoch: 005 | loss: 0.59257 - acc: 0.7124 -- iter: 352/839
[A[ATraining Step: 120  | total loss: [1m[32m0.59042[0m[0m | time: 33.113s
[2K
| Adam | epoch: 005 | loss: 0.59042 - acc: 0.7099 -- iter: 384/839
[A[ATraining Step: 121  | total loss: [1m[32m0.57961[0m[0m | time: 34.490s
[2K
| Adam | epoch: 005 | loss: 0.57961 - acc: 0.7264 -- iter: 416/839
[A[ATraining Step: 122  | total loss: [1m[32m0.57646[0m[0m | time: 36.058s
[2K
| Adam | epoch: 005 | loss: 0.57646 - acc: 0.7256 -- iter: 448/839
[A[ATraining Step: 123  | total loss: [1m[32m0.58707[0m[0m | time: 37.509s
[2K
| Adam | epoch: 005 | loss: 0.58707 - acc: 0.7187 -- iter: 480/839
[A[ATraining Step: 124  | total loss: [1m[32m0.59272[0m[0m | time: 39.237s
[2K
| Adam | epoch: 005 | loss: 0.59272 - acc: 0.7187 -- iter: 512/839
[A[ATraining Step: 125  | total loss: [1m[32m0.60175[0m[0m | time: 40.888s
[2K
| Adam | epoch: 005 | loss: 0.60175 - acc: 0.7000 -- iter: 544/839
[A[ATraining Step: 126  | total loss: [1m[32m0.59097[0m[0m | time: 42.426s
[2K
| Adam | epoch: 005 | loss: 0.59097 - acc: 0.7081 -- iter: 576/839
[A[ATraining Step: 127  | total loss: [1m[32m0.57914[0m[0m | time: 44.248s
[2K
| Adam | epoch: 005 | loss: 0.57914 - acc: 0.7092 -- iter: 608/839
[A[ATraining Step: 128  | total loss: [1m[32m0.57522[0m[0m | time: 50.371s
[2K
| Adam | epoch: 005 | loss: 0.57522 - acc: 0.7070 -- iter: 640/839
[A[ATraining Step: 129  | total loss: [1m[32m0.56925[0m[0m | time: 51.721s
[2K
| Adam | epoch: 005 | loss: 0.56925 - acc: 0.7175 -- iter: 672/839
[A[ATraining Step: 130  | total loss: [1m[32m0.57325[0m[0m | time: 53.133s
[2K
| Adam | epoch: 005 | loss: 0.57325 - acc: 0.7114 -- iter: 704/839
[A[ATraining Step: 131  | total loss: [1m[32m0.56010[0m[0m | time: 54.419s
[2K
| Adam | epoch: 005 | loss: 0.56010 - acc: 0.7246 -- iter: 736/839
[A[ATraining Step: 132  | total loss: [1m[32m0.54998[0m[0m | time: 55.753s
[2K
| Adam | epoch: 005 | loss: 0.54998 - acc: 0.7334 -- iter: 768/839
[A[ATraining Step: 133  | total loss: [1m[32m0.53682[0m[0m | time: 57.045s
[2K
| Adam | epoch: 005 | loss: 0.53682 - acc: 0.7445 -- iter: 800/839
[A[ATraining Step: 134  | total loss: [1m[32m0.53081[0m[0m | time: 58.525s
[2K
| Adam | epoch: 005 | loss: 0.53081 - acc: 0.7419 -- iter: 832/839
[A[ATraining Step: 135  | total loss: [1m[32m0.51502[0m[0m | time: 62.114s
[2K
| Adam | epoch: 005 | loss: 0.51502 - acc: 0.7521 | val_loss: 0.47421 - val_acc: 0.7643 -- iter: 839/839
--
Training Step: 136  | total loss: [1m[32m0.51017[0m[0m | time: 1.427s
[2K
| Adam | epoch: 006 | loss: 0.51017 - acc: 0.7487 -- iter: 032/839
[A[ATraining Step: 137  | total loss: [1m[32m0.50058[0m[0m | time: 2.827s
[2K
| Adam | epoch: 006 | loss: 0.50058 - acc: 0.7520 -- iter: 064/839
[A[ATraining Step: 138  | total loss: [1m[32m0.49418[0m[0m | time: 4.277s
[2K
| Adam | epoch: 006 | loss: 0.49418 - acc: 0.7674 -- iter: 096/839
[A[ATraining Step: 139  | total loss: [1m[32m0.48328[0m[0m | time: 4.690s
[2K
| Adam | epoch: 006 | loss: 0.48328 - acc: 0.7719 -- iter: 128/839
[A[ATraining Step: 140  | total loss: [1m[32m0.49355[0m[0m | time: 5.213s
[2K
| Adam | epoch: 006 | loss: 0.49355 - acc: 0.7519 -- iter: 160/839
[A[ATraining Step: 141  | total loss: [1m[32m0.49054[0m[0m | time: 6.931s
[2K
| Adam | epoch: 006 | loss: 0.49054 - acc: 0.7624 -- iter: 192/839
[A[ATraining Step: 142  | total loss: [1m[32m0.49973[0m[0m | time: 8.389s
[2K
| Adam | epoch: 006 | loss: 0.49973 - acc: 0.7612 -- iter: 224/839
[A[ATraining Step: 143  | total loss: [1m[32m0.49612[0m[0m | time: 9.706s
[2K
| Adam | epoch: 006 | loss: 0.49612 - acc: 0.7600 -- iter: 256/839
[A[ATraining Step: 144  | total loss: [1m[32m0.50274[0m[0m | time: 10.695s
[2K
| Adam | epoch: 006 | loss: 0.50274 - acc: 0.7590 -- iter: 288/839
[A[ATraining Step: 145  | total loss: [1m[32m0.48758[0m[0m | time: 12.029s
[2K
| Adam | epoch: 006 | loss: 0.48758 - acc: 0.7675 -- iter: 320/839
[A[ATraining Step: 146  | total loss: [1m[32m0.48611[0m[0m | time: 13.040s
[2K
| Adam | epoch: 006 | loss: 0.48611 - acc: 0.7689 -- iter: 352/839
[A[ATraining Step: 147  | total loss: [1m[32m0.50164[0m[0m | time: 14.025s
[2K
| Adam | epoch: 006 | loss: 0.50164 - acc: 0.7576 -- iter: 384/839
[A[ATraining Step: 148  | total loss: [1m[32m0.49338[0m[0m | time: 15.088s
[2K
| Adam | epoch: 006 | loss: 0.49338 - acc: 0.7694 -- iter: 416/839
[A[ATraining Step: 149  | total loss: [1m[32m0.49227[0m[0m | time: 16.238s
[2K
| Adam | epoch: 006 | loss: 0.49227 - acc: 0.7706 -- iter: 448/839
[A[ATraining Step: 150  | total loss: [1m[32m0.48593[0m[0m | time: 17.412s
[2K
| Adam | epoch: 006 | loss: 0.48593 - acc: 0.7747 -- iter: 480/839
[A[ATraining Step: 151  | total loss: [1m[32m0.47955[0m[0m | time: 18.545s
[2K
| Adam | epoch: 006 | loss: 0.47955 - acc: 0.7816 -- iter: 512/839
[A[ATraining Step: 152  | total loss: [1m[32m0.46675[0m[0m | time: 19.735s
[2K
| Adam | epoch: 006 | loss: 0.46675 - acc: 0.7941 -- iter: 544/839
[A[ATraining Step: 153  | total loss: [1m[32m0.46317[0m[0m | time: 21.076s
[2K
| Adam | epoch: 006 | loss: 0.46317 - acc: 0.7866 -- iter: 576/839
[A[ATraining Step: 154  | total loss: [1m[32m0.44308[0m[0m | time: 22.449s
[2K
| Adam | epoch: 006 | loss: 0.44308 - acc: 0.8017 -- iter: 608/839
[A[ATraining Step: 155  | total loss: [1m[32m0.44314[0m[0m | time: 23.704s
[2K
| Adam | epoch: 006 | loss: 0.44314 - acc: 0.7965 -- iter: 640/839
[A[ATraining Step: 156  | total loss: [1m[32m0.44507[0m[0m | time: 24.637s
[2K
| Adam | epoch: 006 | loss: 0.44507 - acc: 0.7918 -- iter: 672/839
[A[ATraining Step: 157  | total loss: [1m[32m0.43960[0m[0m | time: 25.725s
[2K
| Adam | epoch: 006 | loss: 0.43960 - acc: 0.7970 -- iter: 704/839
[A[ATraining Step: 158  | total loss: [1m[32m0.43508[0m[0m | time: 26.787s
[2K
| Adam | epoch: 006 | loss: 0.43508 - acc: 0.8017 -- iter: 736/839
[A[ATraining Step: 159  | total loss: [1m[32m0.43085[0m[0m | time: 27.840s
[2K
| Adam | epoch: 006 | loss: 0.43085 - acc: 0.7934 -- iter: 768/839
[A[ATraining Step: 160  | total loss: [1m[32m0.42284[0m[0m | time: 28.957s
[2K
| Adam | epoch: 006 | loss: 0.42284 - acc: 0.8016 -- iter: 800/839
[A[ATraining Step: 161  | total loss: [1m[32m0.43480[0m[0m | time: 30.034s
[2K
| Adam | epoch: 006 | loss: 0.43480 - acc: 0.7964 -- iter: 832/839
[A[ATraining Step: 162  | total loss: [1m[32m0.42677[0m[0m | time: 32.853s
[2K
| Adam | epoch: 006 | loss: 0.42677 - acc: 0.8011 | val_loss: 0.44426 - val_acc: 0.7985 -- iter: 839/839
--
Training Step: 163  | total loss: [1m[32m0.42097[0m[0m | time: 1.590s
[2K
| Adam | epoch: 007 | loss: 0.42097 - acc: 0.8085 -- iter: 032/839
[A[ATraining Step: 164  | total loss: [1m[32m0.45011[0m[0m | time: 2.931s
[2K
| Adam | epoch: 007 | loss: 0.45011 - acc: 0.7902 -- iter: 064/839
[A[ATraining Step: 165  | total loss: [1m[32m0.46083[0m[0m | time: 4.217s
[2K
| Adam | epoch: 007 | loss: 0.46083 - acc: 0.7830 -- iter: 096/839
[A[ATraining Step: 166  | total loss: [1m[32m0.43655[0m[0m | time: 5.633s
[2K
| Adam | epoch: 007 | loss: 0.43655 - acc: 0.7954 -- iter: 128/839
[A[ATraining Step: 167  | total loss: [1m[32m0.41300[0m[0m | time: 6.048s
[2K
| Adam | epoch: 007 | loss: 0.41300 - acc: 0.8127 -- iter: 160/839
[A[ATraining Step: 168  | total loss: [1m[32m0.41036[0m[0m | time: 6.376s
[2K
| Adam | epoch: 007 | loss: 0.41036 - acc: 0.8314 -- iter: 192/839
[A[ATraining Step: 169  | total loss: [1m[32m0.40348[0m[0m | time: 7.549s
[2K
| Adam | epoch: 007 | loss: 0.40348 - acc: 0.8483 -- iter: 224/839
[A[ATraining Step: 170  | total loss: [1m[32m0.39559[0m[0m | time: 8.862s
[2K
| Adam | epoch: 007 | loss: 0.39559 - acc: 0.8416 -- iter: 256/839
[A[ATraining Step: 171  | total loss: [1m[32m0.38457[0m[0m | time: 10.227s
[2K
| Adam | epoch: 007 | loss: 0.38457 - acc: 0.8480 -- iter: 288/839
[A[ATraining Step: 172  | total loss: [1m[32m0.37020[0m[0m | time: 11.615s
[2K
| Adam | epoch: 007 | loss: 0.37020 - acc: 0.8507 -- iter: 320/839
[A[ATraining Step: 173  | total loss: [1m[32m0.37796[0m[0m | time: 13.274s
[2K
| Adam | epoch: 007 | loss: 0.37796 - acc: 0.8438 -- iter: 352/839
[A[ATraining Step: 174  | total loss: [1m[32m0.41897[0m[0m | time: 15.088s
[2K
| Adam | epoch: 007 | loss: 0.41897 - acc: 0.8157 -- iter: 384/839
[A[ATraining Step: 175  | total loss: [1m[32m0.41700[0m[0m | time: 16.580s
[2K
| Adam | epoch: 007 | loss: 0.41700 - acc: 0.8185 -- iter: 416/839
[A[ATraining Step: 176  | total loss: [1m[32m0.42006[0m[0m | time: 18.212s
[2K
| Adam | epoch: 007 | loss: 0.42006 - acc: 0.8179 -- iter: 448/839
[A[ATraining Step: 177  | total loss: [1m[32m0.41939[0m[0m | time: 21.124s
[2K
| Adam | epoch: 007 | loss: 0.41939 - acc: 0.8205 -- iter: 480/839
[A[ATraining Step: 178  | total loss: [1m[32m0.41090[0m[0m | time: 24.285s
[2K
| Adam | epoch: 007 | loss: 0.41090 - acc: 0.8197 -- iter: 512/839
[A[ATraining Step: 179  | total loss: [1m[32m0.41471[0m[0m | time: 25.771s
[2K
| Adam | epoch: 007 | loss: 0.41471 - acc: 0.8158 -- iter: 544/839
[A[ATraining Step: 180  | total loss: [1m[32m0.40663[0m[0m | time: 27.218s
[2K
| Adam | epoch: 007 | loss: 0.40663 - acc: 0.8186 -- iter: 576/839
[A[ATraining Step: 181  | total loss: [1m[32m0.42279[0m[0m | time: 38.041s
[2K
| Adam | epoch: 007 | loss: 0.42279 - acc: 0.8118 -- iter: 608/839
[A[ATraining Step: 182  | total loss: [1m[32m0.42529[0m[0m | time: 39.243s
[2K
| Adam | epoch: 007 | loss: 0.42529 - acc: 0.8181 -- iter: 640/839
[A[ATraining Step: 183  | total loss: [1m[32m0.41343[0m[0m | time: 40.652s
[2K
| Adam | epoch: 007 | loss: 0.41343 - acc: 0.8300 -- iter: 672/839
[A[ATraining Step: 184  | total loss: [1m[32m0.40663[0m[0m | time: 42.219s
[2K
| Adam | epoch: 007 | loss: 0.40663 - acc: 0.8345 -- iter: 704/839
[A[ATraining Step: 185  | total loss: [1m[32m0.40240[0m[0m | time: 43.762s
[2K
| Adam | epoch: 007 | loss: 0.40240 - acc: 0.8323 -- iter: 736/839
[A[ATraining Step: 186  | total loss: [1m[32m0.41462[0m[0m | time: 45.162s
[2K
| Adam | epoch: 007 | loss: 0.41462 - acc: 0.8210 -- iter: 768/839
[A[ATraining Step: 187  | total loss: [1m[32m0.41881[0m[0m | time: 46.771s
[2K
| Adam | epoch: 007 | loss: 0.41881 - acc: 0.8170 -- iter: 800/839
[A[ATraining Step: 188  | total loss: [1m[32m0.42608[0m[0m | time: 48.259s
[2K
| Adam | epoch: 007 | loss: 0.42608 - acc: 0.8040 -- iter: 832/839
[A[ATraining Step: 189  | total loss: [1m[32m0.42363[0m[0m | time: 55.584s
[2K
| Adam | epoch: 007 | loss: 0.42363 - acc: 0.8080 | val_loss: 0.41114 - val_acc: 0.8061 -- iter: 839/839
--
Training Step: 190  | total loss: [1m[32m0.42100[0m[0m | time: 1.506s
[2K
| Adam | epoch: 008 | loss: 0.42100 - acc: 0.8053 -- iter: 032/839
[A[ATraining Step: 191  | total loss: [1m[32m0.42555[0m[0m | time: 4.863s
[2K
| Adam | epoch: 008 | loss: 0.42555 - acc: 0.7998 -- iter: 064/839
[A[ATraining Step: 192  | total loss: [1m[32m0.45337[0m[0m | time: 8.074s
[2K
| Adam | epoch: 008 | loss: 0.45337 - acc: 0.7854 -- iter: 096/839
[A[ATraining Step: 193  | total loss: [1m[32m0.43596[0m[0m | time: 9.655s
[2K
| Adam | epoch: 008 | loss: 0.43596 - acc: 0.8007 -- iter: 128/839
[A[ATraining Step: 194  | total loss: [1m[32m0.43122[0m[0m | time: 11.276s
[2K
| Adam | epoch: 008 | loss: 0.43122 - acc: 0.8018 -- iter: 160/839
[A[ATraining Step: 195  | total loss: [1m[32m0.41785[0m[0m | time: 11.662s
[2K
| Adam | epoch: 008 | loss: 0.41785 - acc: 0.8060 -- iter: 192/839
[A[ATraining Step: 196  | total loss: [1m[32m0.43482[0m[0m | time: 12.112s
[2K
| Adam | epoch: 008 | loss: 0.43482 - acc: 0.7826 -- iter: 224/839
[A[ATraining Step: 197  | total loss: [1m[32m0.43465[0m[0m | time: 13.718s
[2K
| Adam | epoch: 008 | loss: 0.43465 - acc: 0.8043 -- iter: 256/839
[A[ATraining Step: 198  | total loss: [1m[32m0.42819[0m[0m | time: 15.193s
[2K
| Adam | epoch: 008 | loss: 0.42819 - acc: 0.8051 -- iter: 288/839
[A[ATraining Step: 199  | total loss: [1m[32m0.41428[0m[0m | time: 16.660s
[2K
| Adam | epoch: 008 | loss: 0.41428 - acc: 0.8184 -- iter: 320/839
[A[ATraining Step: 200  | total loss: [1m[32m0.40791[0m[0m | time: 23.998s
[2K
| Adam | epoch: 008 | loss: 0.40791 - acc: 0.8272 | val_loss: 0.54075 - val_acc: 0.7605 -- iter: 352/839
--
Training Step: 201  | total loss: [1m[32m0.39852[0m[0m | time: 25.517s
[2K
| Adam | epoch: 008 | loss: 0.39852 - acc: 0.8288 -- iter: 384/839
[A[ATraining Step: 202  | total loss: [1m[32m0.39261[0m[0m | time: 27.032s
[2K
| Adam | epoch: 008 | loss: 0.39261 - acc: 0.8334 -- iter: 416/839
[A[ATraining Step: 203  | total loss: [1m[32m0.38311[0m[0m | time: 28.564s
[2K
| Adam | epoch: 008 | loss: 0.38311 - acc: 0.8376 -- iter: 448/839
[A[ATraining Step: 204  | total loss: [1m[32m0.38253[0m[0m | time: 30.164s
[2K
| Adam | epoch: 008 | loss: 0.38253 - acc: 0.8382 -- iter: 480/839
[A[ATraining Step: 205  | total loss: [1m[32m0.36453[0m[0m | time: 31.811s
[2K
| Adam | epoch: 008 | loss: 0.36453 - acc: 0.8513 -- iter: 512/839
[A[ATraining Step: 206  | total loss: [1m[32m0.34630[0m[0m | time: 33.410s
[2K
| Adam | epoch: 008 | loss: 0.34630 - acc: 0.8568 -- iter: 544/839
[A[ATraining Step: 207  | total loss: [1m[32m0.35779[0m[0m | time: 34.929s
[2K
| Adam | epoch: 008 | loss: 0.35779 - acc: 0.8492 -- iter: 576/839
[A[ATraining Step: 208  | total loss: [1m[32m0.34643[0m[0m | time: 36.548s
[2K
| Adam | epoch: 008 | loss: 0.34643 - acc: 0.8580 -- iter: 608/839
[A[ATraining Step: 209  | total loss: [1m[32m0.34767[0m[0m | time: 38.182s
[2K
| Adam | epoch: 008 | loss: 0.34767 - acc: 0.8566 -- iter: 640/839
[A[ATraining Step: 210  | total loss: [1m[32m0.35599[0m[0m | time: 39.792s
[2K
| Adam | epoch: 008 | loss: 0.35599 - acc: 0.8522 -- iter: 672/839
[A[ATraining Step: 211  | total loss: [1m[32m0.35483[0m[0m | time: 41.271s
[2K
| Adam | epoch: 008 | loss: 0.35483 - acc: 0.8545 -- iter: 704/839
[A[ATraining Step: 212  | total loss: [1m[32m0.36534[0m[0m | time: 42.796s
[2K
| Adam | epoch: 008 | loss: 0.36534 - acc: 0.8472 -- iter: 736/839
[A[ATraining Step: 213  | total loss: [1m[32m0.35847[0m[0m | time: 44.070s
[2K
| Adam | epoch: 008 | loss: 0.35847 - acc: 0.8499 -- iter: 768/839
[A[ATraining Step: 214  | total loss: [1m[32m0.34544[0m[0m | time: 45.368s
[2K
| Adam | epoch: 008 | loss: 0.34544 - acc: 0.8556 -- iter: 800/839
[A[ATraining Step: 215  | total loss: [1m[32m0.34846[0m[0m | time: 46.463s
[2K
| Adam | epoch: 008 | loss: 0.34846 - acc: 0.8575 -- iter: 832/839
[A[ATraining Step: 216  | total loss: [1m[32m0.34842[0m[0m | time: 49.434s
[2K
| Adam | epoch: 008 | loss: 0.34842 - acc: 0.8593 | val_loss: 0.37388 - val_acc: 0.8365 -- iter: 839/839
--
Training Step: 217  | total loss: [1m[32m0.34703[0m[0m | time: 1.420s
[2K
| Adam | epoch: 009 | loss: 0.34703 - acc: 0.8608 -- iter: 032/839
[A[ATraining Step: 218  | total loss: [1m[32m0.34799[0m[0m | time: 2.557s
[2K
| Adam | epoch: 009 | loss: 0.34799 - acc: 0.8623 -- iter: 064/839
[A[ATraining Step: 219  | total loss: [1m[32m0.34620[0m[0m | time: 3.639s
[2K
| Adam | epoch: 009 | loss: 0.34620 - acc: 0.8635 -- iter: 096/839
[A[ATraining Step: 220  | total loss: [1m[32m0.38222[0m[0m | time: 4.806s
[2K
| Adam | epoch: 009 | loss: 0.38222 - acc: 0.8428 -- iter: 128/839
[A[ATraining Step: 221  | total loss: [1m[32m0.36852[0m[0m | time: 5.935s
[2K
| Adam | epoch: 009 | loss: 0.36852 - acc: 0.8491 -- iter: 160/839
[A[ATraining Step: 222  | total loss: [1m[32m0.35366[0m[0m | time: 6.999s
[2K
| Adam | epoch: 009 | loss: 0.35366 - acc: 0.8580 -- iter: 192/839
[A[ATraining Step: 223  | total loss: [1m[32m0.34508[0m[0m | time: 7.276s
[2K
| Adam | epoch: 009 | loss: 0.34508 - acc: 0.8659 -- iter: 224/839
[A[ATraining Step: 224  | total loss: [1m[32m0.32293[0m[0m | time: 7.608s
[2K
| Adam | epoch: 009 | loss: 0.32293 - acc: 0.8793 -- iter: 256/839
[A[ATraining Step: 225  | total loss: [1m[32m0.30027[0m[0m | time: 8.867s
[2K
| Adam | epoch: 009 | loss: 0.30027 - acc: 0.8914 -- iter: 288/839
[A[ATraining Step: 226  | total loss: [1m[32m0.28973[0m[0m | time: 10.070s
[2K
| Adam | epoch: 009 | loss: 0.28973 - acc: 0.8929 -- iter: 320/839
[A[ATraining Step: 227  | total loss: [1m[32m0.30443[0m[0m | time: 11.407s
[2K
| Adam | epoch: 009 | loss: 0.30443 - acc: 0.8817 -- iter: 352/839
[A[ATraining Step: 228  | total loss: [1m[32m0.28579[0m[0m | time: 12.911s
[2K
| Adam | epoch: 009 | loss: 0.28579 - acc: 0.8904 -- iter: 384/839
[A[ATraining Step: 229  | total loss: [1m[32m0.27383[0m[0m | time: 14.315s
[2K
| Adam | epoch: 009 | loss: 0.27383 - acc: 0.8951 -- iter: 416/839
[A[ATraining Step: 230  | total loss: [1m[32m0.25228[0m[0m | time: 15.626s
[2K
| Adam | epoch: 009 | loss: 0.25228 - acc: 0.9025 -- iter: 448/839
[A[ATraining Step: 231  | total loss: [1m[32m0.23392[0m[0m | time: 16.658s
[2K
| Adam | epoch: 009 | loss: 0.23392 - acc: 0.9122 -- iter: 480/839
[A[ATraining Step: 232  | total loss: [1m[32m0.22080[0m[0m | time: 17.836s
[2K
| Adam | epoch: 009 | loss: 0.22080 - acc: 0.9179 -- iter: 512/839
[A[ATraining Step: 233  | total loss: [1m[32m0.23519[0m[0m | time: 19.109s
[2K
| Adam | epoch: 009 | loss: 0.23519 - acc: 0.9074 -- iter: 544/839
[A[ATraining Step: 234  | total loss: [1m[32m0.23381[0m[0m | time: 20.306s
[2K
| Adam | epoch: 009 | loss: 0.23381 - acc: 0.9041 -- iter: 576/839
[A[ATraining Step: 235  | total loss: [1m[32m0.24883[0m[0m | time: 22.062s
[2K
| Adam | epoch: 009 | loss: 0.24883 - acc: 0.9012 -- iter: 608/839
[A[ATraining Step: 236  | total loss: [1m[32m0.24092[0m[0m | time: 23.822s
[2K
| Adam | epoch: 009 | loss: 0.24092 - acc: 0.9017 -- iter: 640/839
[A[ATraining Step: 237  | total loss: [1m[32m0.22878[0m[0m | time: 25.460s
[2K
| Adam | epoch: 009 | loss: 0.22878 - acc: 0.9053 -- iter: 672/839
[A[ATraining Step: 238  | total loss: [1m[32m0.23202[0m[0m | time: 26.862s
[2K
| Adam | epoch: 009 | loss: 0.23202 - acc: 0.9023 -- iter: 704/839
[A[ATraining Step: 239  | total loss: [1m[32m0.27335[0m[0m | time: 28.439s
[2K
| Adam | epoch: 009 | loss: 0.27335 - acc: 0.8902 -- iter: 736/839
[A[ATraining Step: 240  | total loss: [1m[32m0.29807[0m[0m | time: 30.089s
[2K
| Adam | epoch: 009 | loss: 0.29807 - acc: 0.8824 -- iter: 768/839
[A[ATraining Step: 241  | total loss: [1m[32m0.28225[0m[0m | time: 31.820s
[2K
| Adam | epoch: 009 | loss: 0.28225 - acc: 0.8848 -- iter: 800/839
[A[ATraining Step: 242  | total loss: [1m[32m0.27968[0m[0m | time: 33.660s
[2K
| Adam | epoch: 009 | loss: 0.27968 - acc: 0.8869 -- iter: 832/839
[A[ATraining Step: 243  | total loss: [1m[32m0.29642[0m[0m | time: 36.894s
[2K
| Adam | epoch: 009 | loss: 0.29642 - acc: 0.8857 | val_loss: 0.34705 - val_acc: 0.8403 -- iter: 839/839
--
Training Step: 244  | total loss: [1m[32m0.30243[0m[0m | time: 1.690s
[2K
| Adam | epoch: 010 | loss: 0.30243 - acc: 0.8847 -- iter: 032/839
[A[ATraining Step: 245  | total loss: [1m[32m0.30673[0m[0m | time: 3.512s
[2K
| Adam | epoch: 010 | loss: 0.30673 - acc: 0.8806 -- iter: 064/839
[A[ATraining Step: 246  | total loss: [1m[32m0.32237[0m[0m | time: 5.181s
[2K
| Adam | epoch: 010 | loss: 0.32237 - acc: 0.8706 -- iter: 096/839
[A[ATraining Step: 247  | total loss: [1m[32m0.33413[0m[0m | time: 6.620s
[2K
| Adam | epoch: 010 | loss: 0.33413 - acc: 0.8711 -- iter: 128/839
[A[ATraining Step: 248  | total loss: [1m[32m0.33446[0m[0m | time: 8.162s
[2K
| Adam | epoch: 010 | loss: 0.33446 - acc: 0.8683 -- iter: 160/839
[A[ATraining Step: 249  | total loss: [1m[32m0.33363[0m[0m | time: 9.806s
[2K
| Adam | epoch: 010 | loss: 0.33363 - acc: 0.8721 -- iter: 192/839
[A[ATraining Step: 250  | total loss: [1m[32m0.32761[0m[0m | time: 11.393s
[2K
| Adam | epoch: 010 | loss: 0.32761 - acc: 0.8787 -- iter: 224/839
[A[ATraining Step: 251  | total loss: [1m[32m0.31698[0m[0m | time: 11.815s
[2K
| Adam | epoch: 010 | loss: 0.31698 - acc: 0.8846 -- iter: 256/839
[A[ATraining Step: 252  | total loss: [1m[32m0.30704[0m[0m | time: 12.299s
[2K
| Adam | epoch: 010 | loss: 0.30704 - acc: 0.8818 -- iter: 288/839
[A[ATraining Step: 253  | total loss: [1m[32m0.29649[0m[0m | time: 17.409s
[2K
| Adam | epoch: 010 | loss: 0.29649 - acc: 0.8793 -- iter: 320/839
[A[ATraining Step: 254  | total loss: [1m[32m0.30340[0m[0m | time: 18.836s
[2K
| Adam | epoch: 010 | loss: 0.30340 - acc: 0.8758 -- iter: 352/839
[A[ATraining Step: 255  | total loss: [1m[32m0.29444[0m[0m | time: 20.097s
[2K
| Adam | epoch: 010 | loss: 0.29444 - acc: 0.8820 -- iter: 384/839
[A[ATraining Step: 256  | total loss: [1m[32m0.27948[0m[0m | time: 21.644s
[2K
| Adam | epoch: 010 | loss: 0.27948 - acc: 0.8906 -- iter: 416/839
[A[ATraining Step: 257  | total loss: [1m[32m0.27128[0m[0m | time: 23.080s
[2K
| Adam | epoch: 010 | loss: 0.27128 - acc: 0.8953 -- iter: 448/839
[A[ATraining Step: 258  | total loss: [1m[32m0.26799[0m[0m | time: 24.603s
[2K
| Adam | epoch: 010 | loss: 0.26799 - acc: 0.8995 -- iter: 480/839
[A[ATraining Step: 259  | total loss: [1m[32m0.25668[0m[0m | time: 26.354s
[2K
| Adam | epoch: 010 | loss: 0.25668 - acc: 0.9065 -- iter: 512/839
[A[ATraining Step: 260  | total loss: [1m[32m0.25089[0m[0m | time: 28.000s
[2K
| Adam | epoch: 010 | loss: 0.25089 - acc: 0.9096 -- iter: 544/839
[A[ATraining Step: 261  | total loss: [1m[32m0.25197[0m[0m | time: 29.644s
[2K
| Adam | epoch: 010 | loss: 0.25197 - acc: 0.9092 -- iter: 576/839
[A[ATraining Step: 262  | total loss: [1m[32m0.24850[0m[0m | time: 30.942s
[2K
| Adam | epoch: 010 | loss: 0.24850 - acc: 0.9121 -- iter: 608/839
[A[ATraining Step: 263  | total loss: [1m[32m0.24311[0m[0m | time: 32.503s
[2K
| Adam | epoch: 010 | loss: 0.24311 - acc: 0.9146 -- iter: 640/839
[A[ATraining Step: 264  | total loss: [1m[32m0.22849[0m[0m | time: 34.215s
[2K
| Adam | epoch: 010 | loss: 0.22849 - acc: 0.9200 -- iter: 672/839
[A[ATraining Step: 265  | total loss: [1m[32m0.21805[0m[0m | time: 40.149s
[2K
| Adam | epoch: 010 | loss: 0.21805 - acc: 0.9218 -- iter: 704/839
[A[ATraining Step: 266  | total loss: [1m[32m0.21628[0m[0m | time: 44.725s
[2K
| Adam | epoch: 010 | loss: 0.21628 - acc: 0.9171 -- iter: 736/839
[A[ATraining Step: 267  | total loss: [1m[32m0.20616[0m[0m | time: 47.059s
[2K
| Adam | epoch: 010 | loss: 0.20616 - acc: 0.9223 -- iter: 768/839
[A[ATraining Step: 268  | total loss: [1m[32m0.20840[0m[0m | time: 48.549s
[2K
| Adam | epoch: 010 | loss: 0.20840 - acc: 0.9175 -- iter: 800/839
[A[ATraining Step: 269  | total loss: [1m[32m0.21761[0m[0m | time: 49.914s
[2K
| Adam | epoch: 010 | loss: 0.21761 - acc: 0.9102 -- iter: 832/839
[A[ATraining Step: 270  | total loss: [1m[32m0.21175[0m[0m | time: 54.220s
[2K
| Adam | epoch: 010 | loss: 0.21175 - acc: 0.9129 | val_loss: 0.41735 - val_acc: 0.8593 -- iter: 839/839
--
Training Step: 271  | total loss: [1m[32m0.19401[0m[0m | time: 1.391s
[2K
| Adam | epoch: 011 | loss: 0.19401 - acc: 0.9216 -- iter: 032/839
[A[ATraining Step: 272  | total loss: [1m[32m0.19811[0m[0m | time: 2.788s
[2K
| Adam | epoch: 011 | loss: 0.19811 - acc: 0.9201 -- iter: 064/839
[A[ATraining Step: 273  | total loss: [1m[32m0.19946[0m[0m | time: 4.347s
[2K
| Adam | epoch: 011 | loss: 0.19946 - acc: 0.9187 -- iter: 096/839
[A[ATraining Step: 274  | total loss: [1m[32m0.19337[0m[0m | time: 5.948s
[2K
| Adam | epoch: 011 | loss: 0.19337 - acc: 0.9206 -- iter: 128/839
[A[ATraining Step: 275  | total loss: [1m[32m0.18459[0m[0m | time: 7.460s
[2K
| Adam | epoch: 011 | loss: 0.18459 - acc: 0.9254 -- iter: 160/839
[A[ATraining Step: 276  | total loss: [1m[32m0.33615[0m[0m | time: 10.766s
[2K
| Adam | epoch: 011 | loss: 0.33615 - acc: 0.8922 -- iter: 192/839
[A[ATraining Step: 277  | total loss: [1m[32m0.31613[0m[0m | time: 12.312s
[2K
| Adam | epoch: 011 | loss: 0.31613 - acc: 0.8967 -- iter: 224/839
[A[ATraining Step: 278  | total loss: [1m[32m0.30831[0m[0m | time: 13.836s
[2K
| Adam | epoch: 011 | loss: 0.30831 - acc: 0.8946 -- iter: 256/839
[A[ATraining Step: 279  | total loss: [1m[32m0.28960[0m[0m | time: 14.139s
[2K
| Adam | epoch: 011 | loss: 0.28960 - acc: 0.9020 -- iter: 288/839
[A[ATraining Step: 280  | total loss: [1m[32m0.28275[0m[0m | time: 14.452s
[2K
| Adam | epoch: 011 | loss: 0.28275 - acc: 0.8975 -- iter: 320/839
[A[ATraining Step: 281  | total loss: [1m[32m0.26823[0m[0m | time: 15.952s
[2K
| Adam | epoch: 011 | loss: 0.26823 - acc: 0.9078 -- iter: 352/839
[A[ATraining Step: 282  | total loss: [1m[32m0.27218[0m[0m | time: 17.390s
[2K
| Adam | epoch: 011 | loss: 0.27218 - acc: 0.9045 -- iter: 384/839
[A[ATraining Step: 283  | total loss: [1m[32m0.25781[0m[0m | time: 19.157s
[2K
| Adam | epoch: 011 | loss: 0.25781 - acc: 0.9109 -- iter: 416/839
[A[ATraining Step: 284  | total loss: [1m[32m0.25577[0m[0m | time: 20.790s
[2K
| Adam | epoch: 011 | loss: 0.25577 - acc: 0.9104 -- iter: 448/839
[A[ATraining Step: 285  | total loss: [1m[32m0.26151[0m[0m | time: 22.088s
[2K
| Adam | epoch: 011 | loss: 0.26151 - acc: 0.9038 -- iter: 480/839
[A[ATraining Step: 286  | total loss: [1m[32m0.25097[0m[0m | time: 23.597s
[2K
| Adam | epoch: 011 | loss: 0.25097 - acc: 0.9103 -- iter: 512/839
[A[ATraining Step: 287  | total loss: [1m[32m0.24340[0m[0m | time: 25.130s
[2K
| Adam | epoch: 011 | loss: 0.24340 - acc: 0.9161 -- iter: 544/839
[A[ATraining Step: 288  | total loss: [1m[32m0.23489[0m[0m | time: 26.705s
[2K
| Adam | epoch: 011 | loss: 0.23489 - acc: 0.9214 -- iter: 576/839
[A[ATraining Step: 289  | total loss: [1m[32m0.22213[0m[0m | time: 28.110s
[2K
| Adam | epoch: 011 | loss: 0.22213 - acc: 0.9261 -- iter: 608/839
[A[ATraining Step: 290  | total loss: [1m[32m0.21103[0m[0m | time: 29.513s
[2K
| Adam | epoch: 011 | loss: 0.21103 - acc: 0.9304 -- iter: 640/839
[A[ATraining Step: 291  | total loss: [1m[32m0.21107[0m[0m | time: 31.010s
[2K
| Adam | epoch: 011 | loss: 0.21107 - acc: 0.9280 -- iter: 672/839
[A[ATraining Step: 292  | total loss: [1m[32m0.21141[0m[0m | time: 32.553s
[2K
| Adam | epoch: 011 | loss: 0.21141 - acc: 0.9258 -- iter: 704/839
[A[ATraining Step: 293  | total loss: [1m[32m0.20117[0m[0m | time: 34.061s
[2K
| Adam | epoch: 011 | loss: 0.20117 - acc: 0.9301 -- iter: 736/839
[A[ATraining Step: 294  | total loss: [1m[32m0.19150[0m[0m | time: 35.750s
[2K
| Adam | epoch: 011 | loss: 0.19150 - acc: 0.9340 -- iter: 768/839
[A[ATraining Step: 295  | total loss: [1m[32m0.18074[0m[0m | time: 37.348s
[2K
| Adam | epoch: 011 | loss: 0.18074 - acc: 0.9406 -- iter: 800/839
[A[ATraining Step: 296  | total loss: [1m[32m0.18858[0m[0m | time: 39.155s
[2K
| Adam | epoch: 011 | loss: 0.18858 - acc: 0.9371 -- iter: 832/839
[A[ATraining Step: 297  | total loss: [1m[32m0.18355[0m[0m | time: 42.827s
[2K
| Adam | epoch: 011 | loss: 0.18355 - acc: 0.9372 | val_loss: 0.39415 - val_acc: 0.8593 -- iter: 839/839
--
Training Step: 298  | total loss: [1m[32m0.16889[0m[0m | time: 1.498s
[2K
| Adam | epoch: 012 | loss: 0.16889 - acc: 0.9435 -- iter: 032/839
[A[ATraining Step: 299  | total loss: [1m[32m0.16120[0m[0m | time: 2.973s
[2K
| Adam | epoch: 012 | loss: 0.16120 - acc: 0.9429 -- iter: 064/839
[A[ATraining Step: 300  | total loss: [1m[32m0.16932[0m[0m | time: 4.641s
[2K
| Adam | epoch: 012 | loss: 0.16932 - acc: 0.9423 -- iter: 096/839
[A[ATraining Step: 301  | total loss: [1m[32m0.17304[0m[0m | time: 6.182s
[2K
| Adam | epoch: 012 | loss: 0.17304 - acc: 0.9418 -- iter: 128/839
[A[ATraining Step: 302  | total loss: [1m[32m0.16883[0m[0m | time: 7.883s
[2K
| Adam | epoch: 012 | loss: 0.16883 - acc: 0.9414 -- iter: 160/839
[A[ATraining Step: 303  | total loss: [1m[32m0.17433[0m[0m | time: 9.747s
[2K
| Adam | epoch: 012 | loss: 0.17433 - acc: 0.9379 -- iter: 192/839
[A[ATraining Step: 304  | total loss: [1m[32m0.17307[0m[0m | time: 11.440s
[2K
| Adam | epoch: 012 | loss: 0.17307 - acc: 0.9347 -- iter: 224/839
[A[ATraining Step: 305  | total loss: [1m[32m0.18450[0m[0m | time: 13.094s
[2K
| Adam | epoch: 012 | loss: 0.18450 - acc: 0.9256 -- iter: 256/839
[A[ATraining Step: 306  | total loss: [1m[32m0.18957[0m[0m | time: 14.776s
[2K
| Adam | epoch: 012 | loss: 0.18957 - acc: 0.9237 -- iter: 288/839
[A[ATraining Step: 307  | total loss: [1m[32m0.17376[0m[0m | time: 15.194s
[2K
| Adam | epoch: 012 | loss: 0.17376 - acc: 0.9313 -- iter: 320/839
[A[ATraining Step: 308  | total loss: [1m[32m0.15842[0m[0m | time: 15.693s
[2K
| Adam | epoch: 012 | loss: 0.15842 - acc: 0.9382 -- iter: 352/839
[A[ATraining Step: 309  | total loss: [1m[32m0.14383[0m[0m | time: 17.110s
[2K
| Adam | epoch: 012 | loss: 0.14383 - acc: 0.9444 -- iter: 384/839
[A[ATraining Step: 310  | total loss: [1m[32m0.16682[0m[0m | time: 18.377s
[2K
| Adam | epoch: 012 | loss: 0.16682 - acc: 0.9343 -- iter: 416/839
[A[ATraining Step: 311  | total loss: [1m[32m0.19312[0m[0m | time: 19.802s
[2K
| Adam | epoch: 012 | loss: 0.19312 - acc: 0.9284 -- iter: 448/839
[A[ATraining Step: 312  | total loss: [1m[32m0.21014[0m[0m | time: 21.161s
[2K
| Adam | epoch: 012 | loss: 0.21014 - acc: 0.9199 -- iter: 480/839
[A[ATraining Step: 313  | total loss: [1m[32m0.19434[0m[0m | time: 22.462s
[2K
| Adam | epoch: 012 | loss: 0.19434 - acc: 0.9279 -- iter: 512/839
[A[ATraining Step: 314  | total loss: [1m[32m0.17860[0m[0m | time: 23.659s
[2K
| Adam | epoch: 012 | loss: 0.17860 - acc: 0.9351 -- iter: 544/839
[A[ATraining Step: 315  | total loss: [1m[32m0.17834[0m[0m | time: 25.031s
[2K
| Adam | epoch: 012 | loss: 0.17834 - acc: 0.9354 -- iter: 576/839
[A[ATraining Step: 316  | total loss: [1m[32m0.20380[0m[0m | time: 26.402s
[2K
| Adam | epoch: 012 | loss: 0.20380 - acc: 0.9200 -- iter: 608/839
[A[ATraining Step: 317  | total loss: [1m[32m0.20265[0m[0m | time: 27.768s
[2K
| Adam | epoch: 012 | loss: 0.20265 - acc: 0.9186 -- iter: 640/839
[A[ATraining Step: 318  | total loss: [1m[32m0.19163[0m[0m | time: 29.016s
[2K
| Adam | epoch: 012 | loss: 0.19163 - acc: 0.9267 -- iter: 672/839
[A[ATraining Step: 319  | total loss: [1m[32m0.17778[0m[0m | time: 30.669s
[2K
| Adam | epoch: 012 | loss: 0.17778 - acc: 0.9341 -- iter: 704/839
[A[ATraining Step: 320  | total loss: [1m[32m0.16447[0m[0m | time: 32.197s
[2K
| Adam | epoch: 012 | loss: 0.16447 - acc: 0.9406 -- iter: 736/839
[A[ATraining Step: 321  | total loss: [1m[32m0.16831[0m[0m | time: 33.788s
[2K
| Adam | epoch: 012 | loss: 0.16831 - acc: 0.9403 -- iter: 768/839
[A[ATraining Step: 322  | total loss: [1m[32m0.18181[0m[0m | time: 34.946s
[2K
| Adam | epoch: 012 | loss: 0.18181 - acc: 0.9338 -- iter: 800/839
[A[ATraining Step: 323  | total loss: [1m[32m0.16889[0m[0m | time: 36.347s
[2K
| Adam | epoch: 012 | loss: 0.16889 - acc: 0.9404 -- iter: 832/839
[A[ATraining Step: 324  | total loss: [1m[32m0.16351[0m[0m | time: 40.437s
[2K
| Adam | epoch: 012 | loss: 0.16351 - acc: 0.9401 | val_loss: 0.31934 - val_acc: 0.8745 -- iter: 839/839
--
Training Step: 325  | total loss: [1m[32m0.15157[0m[0m | time: 1.844s
[2K
| Adam | epoch: 013 | loss: 0.15157 - acc: 0.9461 -- iter: 032/839
[A[ATraining Step: 326  | total loss: [1m[32m0.14208[0m[0m | time: 4.032s
[2K
| Adam | epoch: 013 | loss: 0.14208 - acc: 0.9515 -- iter: 064/839
[A[ATraining Step: 327  | total loss: [1m[32m0.13358[0m[0m | time: 9.616s
[2K
| Adam | epoch: 013 | loss: 0.13358 - acc: 0.9564 -- iter: 096/839
[A[ATraining Step: 328  | total loss: [1m[32m0.13239[0m[0m | time: 16.080s
[2K
| Adam | epoch: 013 | loss: 0.13239 - acc: 0.9576 -- iter: 128/839
[A[ATraining Step: 329  | total loss: [1m[32m0.13079[0m[0m | time: 17.888s
[2K
| Adam | epoch: 013 | loss: 0.13079 - acc: 0.9587 -- iter: 160/839
[A[ATraining Step: 330  | total loss: [1m[32m0.13040[0m[0m | time: 19.643s
[2K
| Adam | epoch: 013 | loss: 0.13040 - acc: 0.9566 -- iter: 192/839
[A[ATraining Step: 331  | total loss: [1m[32m0.13453[0m[0m | time: 21.546s
[2K
| Adam | epoch: 013 | loss: 0.13453 - acc: 0.9547 -- iter: 224/839
[A[ATraining Step: 332  | total loss: [1m[32m0.13361[0m[0m | time: 23.836s
[2K
| Adam | epoch: 013 | loss: 0.13361 - acc: 0.9530 -- iter: 256/839
[A[ATraining Step: 333  | total loss: [1m[32m0.12680[0m[0m | time: 25.608s
[2K
| Adam | epoch: 013 | loss: 0.12680 - acc: 0.9577 -- iter: 288/839
[A[ATraining Step: 334  | total loss: [1m[32m0.12431[0m[0m | time: 27.333s
[2K
| Adam | epoch: 013 | loss: 0.12431 - acc: 0.9588 -- iter: 320/839
[A[ATraining Step: 335  | total loss: [1m[32m0.12139[0m[0m | time: 27.907s
[2K
| Adam | epoch: 013 | loss: 0.12139 - acc: 0.9598 -- iter: 352/839
[A[ATraining Step: 336  | total loss: [1m[32m0.11499[0m[0m | time: 28.471s
[2K
| Adam | epoch: 013 | loss: 0.11499 - acc: 0.9638 -- iter: 384/839
[A[ATraining Step: 337  | total loss: [1m[32m0.10518[0m[0m | time: 30.268s
[2K
| Adam | epoch: 013 | loss: 0.10518 - acc: 0.9674 -- iter: 416/839
[A[ATraining Step: 338  | total loss: [1m[32m0.11525[0m[0m | time: 32.001s
[2K
| Adam | epoch: 013 | loss: 0.11525 - acc: 0.9644 -- iter: 448/839
[A[ATraining Step: 339  | total loss: [1m[32m0.11346[0m[0m | time: 33.679s
[2K
| Adam | epoch: 013 | loss: 0.11346 - acc: 0.9617 -- iter: 480/839
[A[ATraining Step: 340  | total loss: [1m[32m0.10629[0m[0m | time: 35.188s
[2K
| Adam | epoch: 013 | loss: 0.10629 - acc: 0.9656 -- iter: 512/839
[A[ATraining Step: 341  | total loss: [1m[32m0.09732[0m[0m | time: 36.874s
[2K
| Adam | epoch: 013 | loss: 0.09732 - acc: 0.9690 -- iter: 544/839
[A[ATraining Step: 342  | total loss: [1m[32m0.09125[0m[0m | time: 38.473s
[2K
| Adam | epoch: 013 | loss: 0.09125 - acc: 0.9721 -- iter: 576/839
[A[ATraining Step: 343  | total loss: [1m[32m0.08524[0m[0m | time: 40.296s
[2K
| Adam | epoch: 013 | loss: 0.08524 - acc: 0.9749 -- iter: 608/839
[A[ATraining Step: 344  | total loss: [1m[32m0.08695[0m[0m | time: 41.952s
[2K
| Adam | epoch: 013 | loss: 0.08695 - acc: 0.9743 -- iter: 640/839
[A[ATraining Step: 345  | total loss: [1m[32m0.08248[0m[0m | time: 43.748s
[2K
| Adam | epoch: 013 | loss: 0.08248 - acc: 0.9737 -- iter: 672/839
[A[ATraining Step: 346  | total loss: [1m[32m0.07741[0m[0m | time: 45.624s
[2K
| Adam | epoch: 013 | loss: 0.07741 - acc: 0.9764 -- iter: 704/839
[A[ATraining Step: 347  | total loss: [1m[32m0.07600[0m[0m | time: 47.305s
[2K
| Adam | epoch: 013 | loss: 0.07600 - acc: 0.9725 -- iter: 736/839
[A[ATraining Step: 348  | total loss: [1m[32m0.07018[0m[0m | time: 48.806s
[2K
| Adam | epoch: 013 | loss: 0.07018 - acc: 0.9752 -- iter: 768/839
[A[ATraining Step: 349  | total loss: [1m[32m0.06387[0m[0m | time: 50.666s
[2K
| Adam | epoch: 013 | loss: 0.06387 - acc: 0.9777 -- iter: 800/839
[A[ATraining Step: 350  | total loss: [1m[32m0.07617[0m[0m | time: 52.674s
[2K
| Adam | epoch: 013 | loss: 0.07617 - acc: 0.9737 -- iter: 832/839
[A[ATraining Step: 351  | total loss: [1m[32m0.06994[0m[0m | time: 69.960s
[2K
| Adam | epoch: 013 | loss: 0.06994 - acc: 0.9763 | val_loss: 0.36010 - val_acc: 0.8783 -- iter: 839/839
--
Training Step: 352  | total loss: [1m[32m0.06479[0m[0m | time: 1.349s
[2K
| Adam | epoch: 014 | loss: 0.06479 - acc: 0.9787 -- iter: 032/839
[A[ATraining Step: 353  | total loss: [1m[32m0.05883[0m[0m | time: 3.063s
[2K
| Adam | epoch: 014 | loss: 0.05883 - acc: 0.9808 -- iter: 064/839
[A[ATraining Step: 354  | total loss: [1m[32m0.05709[0m[0m | time: 4.500s
[2K
| Adam | epoch: 014 | loss: 0.05709 - acc: 0.9796 -- iter: 096/839
[A[ATraining Step: 355  | total loss: [1m[32m0.06791[0m[0m | time: 6.113s
[2K
| Adam | epoch: 014 | loss: 0.06791 - acc: 0.9723 -- iter: 128/839
[A[ATraining Step: 356  | total loss: [1m[32m0.07721[0m[0m | time: 7.525s
[2K
| Adam | epoch: 014 | loss: 0.07721 - acc: 0.9719 -- iter: 160/839
[A[ATraining Step: 357  | total loss: [1m[32m0.07218[0m[0m | time: 8.927s
[2K
| Adam | epoch: 014 | loss: 0.07218 - acc: 0.9747 -- iter: 192/839
[A[ATraining Step: 358  | total loss: [1m[32m0.06875[0m[0m | time: 10.349s
[2K
| Adam | epoch: 014 | loss: 0.06875 - acc: 0.9773 -- iter: 224/839
[A[ATraining Step: 359  | total loss: [1m[32m0.06633[0m[0m | time: 12.034s
[2K
| Adam | epoch: 014 | loss: 0.06633 - acc: 0.9764 -- iter: 256/839
[A[ATraining Step: 360  | total loss: [1m[32m0.06213[0m[0m | time: 13.700s
[2K
| Adam | epoch: 014 | loss: 0.06213 - acc: 0.9788 -- iter: 288/839
[A[ATraining Step: 361  | total loss: [1m[32m0.06518[0m[0m | time: 15.219s
[2K
| Adam | epoch: 014 | loss: 0.06518 - acc: 0.9746 -- iter: 320/839
[A[ATraining Step: 362  | total loss: [1m[32m0.06006[0m[0m | time: 16.801s
[2K
| Adam | epoch: 014 | loss: 0.06006 - acc: 0.9772 -- iter: 352/839
[A[ATraining Step: 363  | total loss: [1m[32m0.05506[0m[0m | time: 17.324s
[2K
| Adam | epoch: 014 | loss: 0.05506 - acc: 0.9795 -- iter: 384/839
[A[ATraining Step: 364  | total loss: [1m[32m0.04966[0m[0m | time: 17.608s
[2K
| Adam | epoch: 014 | loss: 0.04966 - acc: 0.9815 -- iter: 416/839
[A[ATraining Step: 365  | total loss: [1m[32m0.04480[0m[0m | time: 18.977s
[2K
| Adam | epoch: 014 | loss: 0.04480 - acc: 0.9834 -- iter: 448/839
[A[ATraining Step: 366  | total loss: [1m[32m0.05108[0m[0m | time: 20.392s
[2K
| Adam | epoch: 014 | loss: 0.05108 - acc: 0.9819 -- iter: 480/839
[A[ATraining Step: 367  | total loss: [1m[32m0.07313[0m[0m | time: 21.730s
[2K
| Adam | epoch: 014 | loss: 0.07313 - acc: 0.9775 -- iter: 512/839
[A[ATraining Step: 368  | total loss: [1m[32m0.07205[0m[0m | time: 23.368s
[2K
| Adam | epoch: 014 | loss: 0.07205 - acc: 0.9766 -- iter: 544/839
[A[ATraining Step: 369  | total loss: [1m[32m0.06599[0m[0m | time: 24.873s
[2K
| Adam | epoch: 014 | loss: 0.06599 - acc: 0.9789 -- iter: 576/839
[A[ATraining Step: 370  | total loss: [1m[32m0.05991[0m[0m | time: 26.547s
[2K
| Adam | epoch: 014 | loss: 0.05991 - acc: 0.9810 -- iter: 608/839
[A[ATraining Step: 371  | total loss: [1m[32m0.05480[0m[0m | time: 27.764s
[2K
| Adam | epoch: 014 | loss: 0.05480 - acc: 0.9829 -- iter: 640/839
[A[ATraining Step: 372  | total loss: [1m[32m0.05356[0m[0m | time: 29.256s
[2K
| Adam | epoch: 014 | loss: 0.05356 - acc: 0.9846 -- iter: 672/839
[A[ATraining Step: 373  | total loss: [1m[32m0.04919[0m[0m | time: 30.688s
[2K
| Adam | epoch: 014 | loss: 0.04919 - acc: 0.9862 -- iter: 704/839
[A[ATraining Step: 374  | total loss: [1m[32m0.04505[0m[0m | time: 32.254s
[2K
| Adam | epoch: 014 | loss: 0.04505 - acc: 0.9876 -- iter: 736/839
[A[ATraining Step: 375  | total loss: [1m[32m0.04136[0m[0m | time: 33.925s
[2K
| Adam | epoch: 014 | loss: 0.04136 - acc: 0.9888 -- iter: 768/839
[A[ATraining Step: 376  | total loss: [1m[32m0.03819[0m[0m | time: 35.424s
[2K
| Adam | epoch: 014 | loss: 0.03819 - acc: 0.9899 -- iter: 800/839
[A[ATraining Step: 377  | total loss: [1m[32m0.03580[0m[0m | time: 36.846s
[2K
| Adam | epoch: 014 | loss: 0.03580 - acc: 0.9909 -- iter: 832/839
[A[ATraining Step: 378  | total loss: [1m[32m0.03376[0m[0m | time: 40.612s
[2K
| Adam | epoch: 014 | loss: 0.03376 - acc: 0.9918 | val_loss: 0.51332 - val_acc: 0.8365 -- iter: 839/839
--
Training Step: 379  | total loss: [1m[32m0.03272[0m[0m | time: 1.437s
[2K
| Adam | epoch: 015 | loss: 0.03272 - acc: 0.9927 -- iter: 032/839
[A[ATraining Step: 380  | total loss: [1m[32m0.03306[0m[0m | time: 2.632s
[2K
| Adam | epoch: 015 | loss: 0.03306 - acc: 0.9934 -- iter: 064/839
[A[ATraining Step: 381  | total loss: [1m[32m0.03280[0m[0m | time: 4.050s
[2K
| Adam | epoch: 015 | loss: 0.03280 - acc: 0.9940 -- iter: 096/839
[A[ATraining Step: 382  | total loss: [1m[32m0.02996[0m[0m | time: 5.494s
[2K
| Adam | epoch: 015 | loss: 0.02996 - acc: 0.9946 -- iter: 128/839
[A[ATraining Step: 383  | total loss: [1m[32m0.02876[0m[0m | time: 6.997s
[2K
| Adam | epoch: 015 | loss: 0.02876 - acc: 0.9952 -- iter: 160/839
[A[ATraining Step: 384  | total loss: [1m[32m0.02772[0m[0m | time: 8.369s
[2K
| Adam | epoch: 015 | loss: 0.02772 - acc: 0.9957 -- iter: 192/839
[A[ATraining Step: 385  | total loss: [1m[32m0.02523[0m[0m | time: 9.953s
[2K
| Adam | epoch: 015 | loss: 0.02523 - acc: 0.9961 -- iter: 224/839
[A[ATraining Step: 386  | total loss: [1m[32m0.02315[0m[0m | time: 11.637s
[2K
| Adam | epoch: 015 | loss: 0.02315 - acc: 0.9965 -- iter: 256/839
[A[ATraining Step: 387  | total loss: [1m[32m0.03035[0m[0m | time: 13.087s
[2K
| Adam | epoch: 015 | loss: 0.03035 - acc: 0.9937 -- iter: 288/839
[A[ATraining Step: 388  | total loss: [1m[32m0.02861[0m[0m | time: 14.491s
[2K
| Adam | epoch: 015 | loss: 0.02861 - acc: 0.9943 -- iter: 320/839
[A[ATraining Step: 389  | total loss: [1m[32m0.02668[0m[0m | time: 15.676s
[2K
| Adam | epoch: 015 | loss: 0.02668 - acc: 0.9949 -- iter: 352/839
[A[ATraining Step: 390  | total loss: [1m[32m0.02427[0m[0m | time: 17.062s
[2K
| Adam | epoch: 015 | loss: 0.02427 - acc: 0.9954 -- iter: 384/839
[A[ATraining Step: 391  | total loss: [1m[32m0.02463[0m[0m | time: 17.502s
[2K
| Adam | epoch: 015 | loss: 0.02463 - acc: 0.9959 -- iter: 416/839
[A[ATraining Step: 392  | total loss: [1m[32m0.02393[0m[0m | time: 17.890s
[2K
| Adam | epoch: 015 | loss: 0.02393 - acc: 0.9963 -- iter: 448/839
[A[ATraining Step: 393  | total loss: [1m[32m0.02205[0m[0m | time: 19.477s
[2K
| Adam | epoch: 015 | loss: 0.02205 - acc: 0.9967 -- iter: 480/839
[A[ATraining Step: 394  | total loss: [1m[32m0.02283[0m[0m | time: 21.067s
[2K
| Adam | epoch: 015 | loss: 0.02283 - acc: 0.9970 -- iter: 512/839
[A[ATraining Step: 395  | total loss: [1m[32m0.02064[0m[0m | time: 22.802s
[2K
| Adam | epoch: 015 | loss: 0.02064 - acc: 0.9973 -- iter: 544/839
[A[ATraining Step: 396  | total loss: [1m[32m0.02557[0m[0m | time: 23.976s
[2K
| Adam | epoch: 015 | loss: 0.02557 - acc: 0.9944 -- iter: 576/839
[A[ATraining Step: 397  | total loss: [1m[32m0.02714[0m[0m | time: 25.299s
[2K
| Adam | epoch: 015 | loss: 0.02714 - acc: 0.9919 -- iter: 608/839
[A[ATraining Step: 398  | total loss: [1m[32m0.02735[0m[0m | time: 26.744s
[2K
| Adam | epoch: 015 | loss: 0.02735 - acc: 0.9927 -- iter: 640/839
[A[ATraining Step: 399  | total loss: [1m[32m0.02821[0m[0m | time: 28.400s
[2K
| Adam | epoch: 015 | loss: 0.02821 - acc: 0.9934 -- iter: 672/839
[A[ATraining Step: 400  | total loss: [1m[32m0.02809[0m[0m | time: 35.305s
[2K
| Adam | epoch: 015 | loss: 0.02809 - acc: 0.9941 | val_loss: 0.43676 - val_acc: 0.8669 -- iter: 704/839
--
Training Step: 401  | total loss: [1m[32m0.02560[0m[0m | time: 36.978s
[2K
| Adam | epoch: 015 | loss: 0.02560 - acc: 0.9947 -- iter: 736/839
[A[ATraining Step: 402  | total loss: [1m[32m0.02315[0m[0m | time: 38.383s
[2K
| Adam | epoch: 015 | loss: 0.02315 - acc: 0.9952 -- iter: 768/839
[A[ATraining Step: 403  | total loss: [1m[32m0.02108[0m[0m | time: 39.836s
[2K
| Adam | epoch: 015 | loss: 0.02108 - acc: 0.9957 -- iter: 800/839
[A[ATraining Step: 404  | total loss: [1m[32m0.02035[0m[0m | time: 41.456s
[2K
| Adam | epoch: 015 | loss: 0.02035 - acc: 0.9961 -- iter: 832/839
[A[ATraining Step: 405  | total loss: [1m[32m0.02450[0m[0m | time: 45.592s
[2K
| Adam | epoch: 015 | loss: 0.02450 - acc: 0.9934 | val_loss: 0.58250 - val_acc: 0.8403 -- iter: 839/839
--
Validation AUC:0.9517137563686892
Validation AUPRC:0.9600723673440598
Test AUC:0.946840579710145
Test AUPRC:0.956069301378422
BestTestF1Score	0.87	0.77	0.88	0.92	0.82	103	9	129	22	1.0
BestTestMCCScore	0.87	0.77	0.88	0.92	0.82	103	9	129	22	1.0
BestTestAccuracyScore	0.87	0.77	0.88	0.92	0.82	103	9	129	22	1.0
BestValidationF1Score	0.88	0.79	0.89	0.95	0.82	104	5	131	23	1.0
BestValidationMCC	0.88	0.79	0.89	0.95	0.82	104	5	131	23	1.0
BestValidationAccuracy	0.88	0.79	0.89	0.95	0.82	104	5	131	23	1.0
TestPredictions (Threshold:1.0)
CHEMBL1172697,TN,INACT,0.0	CHEMBL382799,TP,ACT,1.0	CHEMBL3325480,TN,INACT,0.3400000035762787	CHEMBL405681,TN,INACT,0.10000000149011612	CHEMBL103838,TN,INACT,0.0	CHEMBL592224,TN,INACT,0.7900000214576721	CHEMBL335628,TN,INACT,0.009999999776482582	CHEMBL2208016,TP,ACT,1.0	CHEMBL2087978,TP,ACT,1.0	CHEMBL229546,TP,ACT,1.0	CHEMBL1790311,TN,INACT,0.9700000286102295	CHEMBL1272289,TP,ACT,1.0	CHEMBL129153,FN,ACT,0.7699999809265137	CHEMBL3260585,TP,ACT,1.0	CHEMBL1668412,TN,INACT,0.0	CHEMBL3689079,TN,INACT,0.6800000071525574	CHEMBL76076,TN,INACT,0.009999999776482582	CHEMBL572878,FN,ACT,0.0	CHEMBL269339,TP,ACT,1.0	CHEMBL78698,TN,INACT,0.0	CHEMBL1271578,FN,ACT,0.9300000071525574	CHEMBL2207996,TP,ACT,1.0	CHEMBL3781538,TN,INACT,0.9800000190734863	CHEMBL139269,TN,INACT,0.009999999776482582	CHEMBL2208008,TP,ACT,1.0	CHEMBL1271470,TP,ACT,1.0	CHEMBL158797,TN,INACT,0.009999999776482582	CHEMBL3341788,FP,INACT,1.0	CHEMBL3237858,TN,INACT,0.7400000095367432	CHEMBL2088099,TN,INACT,0.0	CHEMBL2088110,TN,INACT,0.10000000149011612	CHEMBL130871,TN,INACT,0.75	CHEMBL2024691,FN,ACT,0.9800000190734863	CHEMBL1762181,TN,INACT,0.05999999865889549	CHEMBL2087981,TP,ACT,1.0	CHEMBL241750,TN,INACT,0.0	CHEMBL128000,TN,INACT,0.0	CHEMBL1097190,TN,INACT,0.0	CHEMBL1835536,TP,ACT,1.0	CHEMBL457077,TN,INACT,0.9900000095367432	CHEMBL136289,TN,INACT,0.0	CHEMBL1241772,TN,INACT,0.009999999776482582	CHEMBL1277990,TN,INACT,0.0	CHEMBL3260574,TP,ACT,1.0	CHEMBL1161235,TN,INACT,0.9399999976158142	CHEMBL3421978,FP,INACT,1.0	CHEMBL240093,TN,INACT,0.10999999940395355	CHEMBL3260629,TP,ACT,1.0	CHEMBL2435043,FN,ACT,0.9900000095367432	CHEMBL3260611,TP,ACT,1.0	CHEMBL126180,FN,ACT,0.0	CHEMBL1092013,TN,INACT,0.9599999785423279	CHEMBL2088218,TP,ACT,1.0	CHEMBL2312649,TN,INACT,0.019999999552965164	CHEMBL1796179,TN,INACT,0.0	CHEMBL132006,TN,INACT,0.0	CHEMBL274926,TN,INACT,0.5299999713897705	CHEMBL261762,TP,ACT,1.0	CHEMBL101682,FP,INACT,1.0	CHEMBL3260572,TP,ACT,1.0	CHEMBL2312645,TN,INACT,0.6200000047683716	CHEMBL315701,TN,INACT,0.0	CHEMBL2208017,TP,ACT,1.0	CHEMBL316239,TN,INACT,0.0	CHEMBL1779748,TN,INACT,0.03999999910593033	CHEMBL502279,TN,INACT,0.15000000596046448	CHEMBL566440,FP,INACT,1.0	CHEMBL409158,TP,ACT,1.0	CHEMBL2087986,TP,ACT,1.0	CHEMBL571451,TP,ACT,1.0	CHEMBL230232,TN,INACT,0.0	CHEMBL2147366,TN,INACT,0.0	CHEMBL3260588,TP,ACT,1.0	CHEMBL556746,TN,INACT,0.009999999776482582	CHEMBL296407,TN,INACT,0.0	CHEMBL229547,TP,ACT,1.0	CHEMBL2435040,TP,ACT,1.0	CHEMBL511451,TN,INACT,0.009999999776482582	CHEMBL73829,TN,INACT,0.8700000047683716	CHEMBL1172947,TN,INACT,0.0	CHEMBL495617,TN,INACT,0.0	CHEMBL186966,TP,ACT,1.0	CHEMBL3260579,TP,ACT,1.0	CHEMBL1779752,TN,INACT,0.07000000029802322	CHEMBL389079,TP,ACT,1.0	CHEMBL1765876,TP,ACT,1.0	CHEMBL1684373,TN,INACT,0.18000000715255737	CHEMBL2208238,TP,ACT,1.0	CHEMBL1835535,TP,ACT,1.0	CHEMBL387747,TP,ACT,1.0	CHEMBL574413,FN,ACT,0.949999988079071	CHEMBL551838,TN,INACT,0.0	CHEMBL1241583,TN,INACT,0.3799999952316284	CHEMBL279003,TN,INACT,0.0	CHEMBL1765759,FN,ACT,0.9900000095367432	CHEMBL346901,TN,INACT,0.009999999776482582	CHEMBL3707019,TP,ACT,1.0	CHEMBL3260564,TP,ACT,1.0	CHEMBL552634,TN,INACT,0.0	CHEMBL2147367,TN,INACT,0.0	CHEMBL215417,TN,INACT,0.8500000238418579	CHEMBL500149,FN,ACT,0.9900000095367432	CHEMBL1271910,FN,ACT,0.9900000095367432	CHEMBL3260607,TP,ACT,1.0	CHEMBL1164957,TP,ACT,1.0	CHEMBL55592,TN,INACT,0.0	CHEMBL3260594,TP,ACT,1.0	CHEMBL1957655,TP,ACT,1.0	CHEMBL541777,TP,ACT,1.0	CHEMBL592999,TP,ACT,1.0	CHEMBL1254309,TN,INACT,0.009999999776482582	CHEMBL3260577,TP,ACT,1.0	CHEMBL256835,TN,INACT,0.019999999552965164	CHEMBL117369,TN,INACT,0.0	CHEMBL1081198,TN,INACT,0.009999999776482582	CHEMBL3260565,TP,ACT,1.0	CHEMBL31184,TN,INACT,0.7300000190734863	CHEMBL519976,TN,INACT,0.0	CHEMBL1241864,TN,INACT,0.9399999976158142	CHEMBL3104853,TN,INACT,0.5600000023841858	CHEMBL2208014,TP,ACT,1.0	CHEMBL2087976,TP,ACT,1.0	CHEMBL310726,TN,INACT,0.03999999910593033	CHEMBL1957672,TP,ACT,1.0	CHEMBL430262,TN,INACT,0.8399999737739563	CHEMBL3260608,TP,ACT,1.0	CHEMBL421138,TN,INACT,0.5400000214576721	CHEMBL1272128,TP,ACT,1.0	CHEMBL585700,TP,ACT,1.0	CHEMBL609582,FN,ACT,0.9900000095367432	CHEMBL134042,TN,INACT,0.0	CHEMBL480583,TP,ACT,1.0	CHEMBL121795,TP,ACT,1.0	CHEMBL81146,TN,INACT,0.9700000286102295	CHEMBL93464,TN,INACT,0.0	CHEMBL573735,TP,ACT,1.0	CHEMBL383523,TP,ACT,1.0	CHEMBL1779738,TN,INACT,0.029999999329447746	CHEMBL3260603,TP,ACT,1.0	CHEMBL2087985,TP,ACT,1.0	CHEMBL1765762,TP,ACT,1.0	CHEMBL2024684,TP,ACT,1.0	CHEMBL430206,TN,INACT,0.009999999776482582	CHEMBL204838,TP,ACT,1.0	CHEMBL1828882,TN,INACT,0.0	CHEMBL1272022,FN,ACT,0.20999999344348907	CHEMBL28,TN,INACT,0.4099999964237213	CHEMBL56671,TN,INACT,0.05000000074505806	CHEMBL3341792,TP,ACT,1.0	CHEMBL3260573,TP,ACT,1.0	CHEMBL3260617,TP,ACT,1.0	CHEMBL2435035,TP,ACT,1.0	CHEMBL1835525,TP,ACT,1.0	CHEMBL3704655,TP,ACT,1.0	CHEMBL595332,TP,ACT,1.0	CHEMBL277697,TN,INACT,0.9100000262260437	CHEMBL165751,TN,INACT,0.1599999964237213	CHEMBL3260618,TP,ACT,1.0	CHEMBL3634709,TP,ACT,1.0	CHEMBL502835,FN,ACT,0.9900000095367432	CHEMBL1254224,TN,INACT,0.0	CHEMBL1835712,FN,ACT,0.9900000095367432	CHEMBL336949,TN,INACT,0.9599999785423279	CHEMBL2321907,FN,ACT,0.9300000071525574	CHEMBL377717,TP,ACT,1.0	CHEMBL2435039,TP,ACT,1.0	CHEMBL316967,TN,INACT,0.0	CHEMBL7350,TN,INACT,0.0	CHEMBL606632,TP,ACT,1.0	CHEMBL564746,TN,INACT,0.0	CHEMBL1688215,FN,ACT,0.9200000166893005	CHEMBL428647,TN,INACT,0.0	CHEMBL269341,TP,ACT,1.0	CHEMBL2011292,TN,INACT,0.46000000834465027	CHEMBL1933749,FP,INACT,1.0	CHEMBL589120,FP,INACT,1.0	CHEMBL311740,TN,INACT,0.029999999329447746	CHEMBL3260901,TP,ACT,1.0	CHEMBL106379,TN,INACT,0.0	CHEMBL1172147,TN,INACT,0.8799999952316284	CHEMBL3335245,TN,INACT,0.0	CHEMBL1957667,TP,ACT,1.0	CHEMBL1253945,TN,INACT,0.03999999910593033	CHEMBL2112638,TN,INACT,0.0	CHEMBL2028663,TP,ACT,1.0	CHEMBL3823628,TN,INACT,0.0	CHEMBL269528,FP,INACT,1.0	CHEMBL3261094,TP,ACT,1.0	CHEMBL26128,TN,INACT,0.0	CHEMBL1272182,TP,ACT,1.0	CHEMBL3634800,TP,ACT,1.0	CHEMBL113690,TN,INACT,0.029999999329447746	CHEMBL1933738,TN,INACT,0.25	CHEMBL519590,TN,INACT,0.11999999731779099	CHEMBL1271631,TP,ACT,1.0	CHEMBL205652,TN,INACT,0.05000000074505806	CHEMBL76813,TN,INACT,0.0	CHEMBL2207988,FN,ACT,0.14000000059604645	CHEMBL1271796,TP,ACT,1.0	CHEMBL267228,TP,ACT,1.0	CHEMBL436944,TP,ACT,1.0	CHEMBL1093100,FP,INACT,1.0	CHEMBL582791,TP,ACT,1.0	CHEMBL3335244,TN,INACT,0.10000000149011612	CHEMBL1796178,TN,INACT,0.0	CHEMBL1271471,FN,ACT,0.1899999976158142	CHEMBL1791365,TN,INACT,0.0	CHEMBL101795,TN,INACT,0.2800000011920929	CHEMBL481546,TP,ACT,1.0	CHEMBL3260597,TP,ACT,1.0	CHEMBL1933737,FP,INACT,1.0	CHEMBL2024687,FN,ACT,0.8299999833106995	CHEMBL150581,TN,INACT,0.0	CHEMBL3707020,TP,ACT,1.0	CHEMBL232542,TN,INACT,0.03999999910593033	CHEMBL381532,TP,ACT,1.0	CHEMBL1957623,TP,ACT,1.0	CHEMBL1242117,TN,INACT,0.0	CHEMBL551031,TN,INACT,0.0	CHEMBL205156,TP,ACT,1.0	CHEMBL1796175,TN,INACT,0.0	CHEMBL2011296,TN,INACT,0.0	CHEMBL564235,TN,INACT,0.0	CHEMBL1242665,TN,INACT,0.05000000074505806	CHEMBL3260590,TP,ACT,1.0	CHEMBL560815,TP,ACT,1.0	CHEMBL129760,FN,ACT,0.019999999552965164	CHEMBL202943,TP,ACT,1.0	CHEMBL496862,TP,ACT,1.0	CHEMBL1766456,TP,ACT,1.0	CHEMBL1835526,TP,ACT,1.0	CHEMBL600048,TN,INACT,0.9900000095367432	CHEMBL341534,TP,ACT,1.0	CHEMBL598025,TN,INACT,0.0	CHEMBL1835521,TP,ACT,1.0	CHEMBL310580,TN,INACT,0.03999999910593033	CHEMBL3421974,TN,INACT,0.4399999976158142	CHEMBL435054,TN,INACT,0.41999998688697815	CHEMBL2207989,TP,ACT,1.0	CHEMBL7137,TN,INACT,0.0	CHEMBL482729,FN,ACT,0.0	CHEMBL1835112,TP,ACT,1.0	CHEMBL3260591,TP,ACT,1.0	CHEMBL1824446,TP,ACT,1.0	CHEMBL390156,TN,INACT,0.07000000029802322	CHEMBL1276308,TN,INACT,0.019999999552965164	CHEMBL1173789,TN,INACT,0.05999999865889549	CHEMBL395665,TN,INACT,0.009999999776482582	CHEMBL52654,TN,INACT,0.9800000190734863	CHEMBL2335377,TN,INACT,0.009999999776482582	CHEMBL203866,TN,INACT,0.0	CHEMBL337978,FN,ACT,0.9900000095367432	CHEMBL409356,TP,ACT,1.0	CHEMBL323564,TN,INACT,0.019999999552965164	CHEMBL132399,TN,INACT,0.17000000178813934	CHEMBL103667,TN,INACT,0.9900000095367432	CHEMBL405008,TN,INACT,0.0	CHEMBL1957653,TP,ACT,1.0	CHEMBL480582,TP,ACT,1.0	CHEMBL3612749,TN,INACT,0.0	CHEMBL3260902,TP,ACT,1.0	CHEMBL117488,TN,INACT,0.7400000095367432	CHEMBL1242025,TN,INACT,0.0	

