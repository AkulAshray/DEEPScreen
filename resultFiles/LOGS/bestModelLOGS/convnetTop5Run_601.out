ImageNetInceptionV2 CHEMBL2008 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	186
Number of inactive compounds :	186
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2008_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2008_adam_0.001_15_0.6/
---------------------------------
Training samples: 236
Validation samples: 74
--
Training Step: 1  | time: 63.173s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/236
[A[ATraining Step: 2  | total loss: [1m[32m0.74719[0m[0m | time: 76.185s
[2K
| Adam | epoch: 001 | loss: 0.74719 - acc: 0.4500 -- iter: 064/236
[A[ATraining Step: 3  | total loss: [1m[32m1.19180[0m[0m | time: 88.352s
[2K
| Adam | epoch: 001 | loss: 1.19180 - acc: 0.5676 -- iter: 096/236
[A[ATraining Step: 4  | total loss: [1m[32m0.75233[0m[0m | time: 100.637s
[2K
| Adam | epoch: 001 | loss: 0.75233 - acc: 0.6341 -- iter: 128/236
[A[ATraining Step: 5  | total loss: [1m[32m0.61960[0m[0m | time: 112.883s
[2K
| Adam | epoch: 001 | loss: 0.61960 - acc: 0.7360 -- iter: 160/236
[A[ATraining Step: 6  | total loss: [1m[32m0.42162[0m[0m | time: 124.821s
[2K
| Adam | epoch: 001 | loss: 0.42162 - acc: 0.8454 -- iter: 192/236
[A[ATraining Step: 7  | total loss: [1m[32m0.31733[0m[0m | time: 137.295s
[2K
| Adam | epoch: 001 | loss: 0.31733 - acc: 0.9007 -- iter: 224/236
[A[ATraining Step: 8  | total loss: [1m[32m0.37391[0m[0m | time: 160.880s
[2K
| Adam | epoch: 001 | loss: 0.37391 - acc: 0.8335 | val_loss: 0.80434 - val_acc: 0.5135 -- iter: 236/236
--
Training Step: 9  | total loss: [1m[32m0.34511[0m[0m | time: 5.709s
[2K
| Adam | epoch: 002 | loss: 0.34511 - acc: 0.8775 -- iter: 032/236
[A[ATraining Step: 10  | total loss: [1m[32m0.19547[0m[0m | time: 17.488s
[2K
| Adam | epoch: 002 | loss: 0.19547 - acc: 0.9388 -- iter: 064/236
[A[ATraining Step: 11  | total loss: [1m[32m0.42889[0m[0m | time: 29.424s
[2K
| Adam | epoch: 002 | loss: 0.42889 - acc: 0.8493 -- iter: 096/236
[A[ATraining Step: 12  | total loss: [1m[32m0.48674[0m[0m | time: 41.471s
[2K
| Adam | epoch: 002 | loss: 0.48674 - acc: 0.7906 -- iter: 128/236
[A[ATraining Step: 13  | total loss: [1m[32m0.39653[0m[0m | time: 53.532s
[2K
| Adam | epoch: 002 | loss: 0.39653 - acc: 0.8402 -- iter: 160/236
[A[ATraining Step: 14  | total loss: [1m[32m0.34380[0m[0m | time: 65.534s
[2K
| Adam | epoch: 002 | loss: 0.34380 - acc: 0.8288 -- iter: 192/236
[A[ATraining Step: 15  | total loss: [1m[32m0.40070[0m[0m | time: 76.895s
[2K
| Adam | epoch: 002 | loss: 0.40070 - acc: 0.8347 -- iter: 224/236
[A[ATraining Step: 16  | total loss: [1m[32m0.34557[0m[0m | time: 96.280s
[2K
| Adam | epoch: 002 | loss: 0.34557 - acc: 0.8732 | val_loss: 0.94723 - val_acc: 0.5135 -- iter: 236/236
--
Training Step: 17  | total loss: [1m[32m0.35985[0m[0m | time: 6.020s
[2K
| Adam | epoch: 003 | loss: 0.35985 - acc: 0.8514 -- iter: 032/236
[A[ATraining Step: 18  | total loss: [1m[32m0.27082[0m[0m | time: 12.348s
[2K
| Adam | epoch: 003 | loss: 0.27082 - acc: 0.9028 -- iter: 064/236
[A[ATraining Step: 19  | total loss: [1m[32m0.22088[0m[0m | time: 27.325s
[2K
| Adam | epoch: 003 | loss: 0.22088 - acc: 0.9352 -- iter: 096/236
[A[ATraining Step: 20  | total loss: [1m[32m0.21684[0m[0m | time: 42.558s
[2K
| Adam | epoch: 003 | loss: 0.21684 - acc: 0.9359 -- iter: 128/236
[A[ATraining Step: 21  | total loss: [1m[32m0.25360[0m[0m | time: 57.354s
[2K
| Adam | epoch: 003 | loss: 0.25360 - acc: 0.9073 -- iter: 160/236
[A[ATraining Step: 22  | total loss: [1m[32m0.22286[0m[0m | time: 72.745s
[2K
| Adam | epoch: 003 | loss: 0.22286 - acc: 0.9164 -- iter: 192/236
[A[ATraining Step: 23  | total loss: [1m[32m0.18280[0m[0m | time: 87.556s
[2K
| Adam | epoch: 003 | loss: 0.18280 - acc: 0.9316 -- iter: 224/236
[A[ATraining Step: 24  | total loss: [1m[32m0.14432[0m[0m | time: 109.552s
[2K
| Adam | epoch: 003 | loss: 0.14432 - acc: 0.9508 | val_loss: 1.66547 - val_acc: 0.5135 -- iter: 236/236
--
Training Step: 25  | total loss: [1m[32m0.12493[0m[0m | time: 14.819s
[2K
| Adam | epoch: 004 | loss: 0.12493 - acc: 0.9642 -- iter: 032/236
[A[ATraining Step: 26  | total loss: [1m[32m0.14043[0m[0m | time: 21.602s
[2K
| Adam | epoch: 004 | loss: 0.14043 - acc: 0.9654 -- iter: 064/236
[A[ATraining Step: 27  | total loss: [1m[32m0.25227[0m[0m | time: 28.450s
[2K
| Adam | epoch: 004 | loss: 0.25227 - acc: 0.9100 -- iter: 096/236
[A[ATraining Step: 28  | total loss: [1m[32m0.22470[0m[0m | time: 43.439s
[2K
| Adam | epoch: 004 | loss: 0.22470 - acc: 0.9325 -- iter: 128/236
[A[ATraining Step: 29  | total loss: [1m[32m0.17997[0m[0m | time: 57.981s
[2K
| Adam | epoch: 004 | loss: 0.17997 - acc: 0.9489 -- iter: 160/236
[A[ATraining Step: 30  | total loss: [1m[32m0.18117[0m[0m | time: 72.831s
[2K
| Adam | epoch: 004 | loss: 0.18117 - acc: 0.9536 -- iter: 192/236
[A[ATraining Step: 31  | total loss: [1m[32m0.19613[0m[0m | time: 87.574s
[2K
| Adam | epoch: 004 | loss: 0.19613 - acc: 0.9427 -- iter: 224/236
[A[ATraining Step: 32  | total loss: [1m[32m0.15738[0m[0m | time: 107.209s
[2K
| Adam | epoch: 004 | loss: 0.15738 - acc: 0.9556 | val_loss: 1.25374 - val_acc: 0.5135 -- iter: 236/236
--
Training Step: 33  | total loss: [1m[32m0.13229[0m[0m | time: 12.628s
[2K
| Adam | epoch: 005 | loss: 0.13229 - acc: 0.9585 -- iter: 032/236
[A[ATraining Step: 34  | total loss: [1m[32m0.13097[0m[0m | time: 28.710s
[2K
| Adam | epoch: 005 | loss: 0.13097 - acc: 0.9540 -- iter: 064/236
[A[ATraining Step: 35  | total loss: [1m[32m0.15320[0m[0m | time: 34.276s
[2K
| Adam | epoch: 005 | loss: 0.15320 - acc: 0.9309 -- iter: 096/236
[A[ATraining Step: 36  | total loss: [1m[32m0.13590[0m[0m | time: 39.956s
[2K
| Adam | epoch: 005 | loss: 0.13590 - acc: 0.9450 -- iter: 128/236
[A[ATraining Step: 37  | total loss: [1m[32m0.11565[0m[0m | time: 54.982s
[2K
| Adam | epoch: 005 | loss: 0.11565 - acc: 0.9560 -- iter: 160/236
[A[ATraining Step: 38  | total loss: [1m[32m0.24628[0m[0m | time: 72.371s
[2K
| Adam | epoch: 005 | loss: 0.24628 - acc: 0.9157 -- iter: 192/236
[A[ATraining Step: 39  | total loss: [1m[32m0.20785[0m[0m | time: 84.044s
[2K
| Adam | epoch: 005 | loss: 0.20785 - acc: 0.9319 -- iter: 224/236
[A[ATraining Step: 40  | total loss: [1m[32m0.17869[0m[0m | time: 101.662s
[2K
| Adam | epoch: 005 | loss: 0.17869 - acc: 0.9388 | val_loss: 1.43810 - val_acc: 0.4324 -- iter: 236/236
--
Training Step: 41  | total loss: [1m[32m0.17638[0m[0m | time: 11.918s
[2K
| Adam | epoch: 006 | loss: 0.17638 - acc: 0.9443 -- iter: 032/236
[A[ATraining Step: 42  | total loss: [1m[32m0.14720[0m[0m | time: 19.914s
[2K
| Adam | epoch: 006 | loss: 0.14720 - acc: 0.9543 -- iter: 064/236
[A[ATraining Step: 43  | total loss: [1m[32m0.13022[0m[0m | time: 30.262s
[2K
| Adam | epoch: 006 | loss: 0.13022 - acc: 0.9569 -- iter: 096/236
[A[ATraining Step: 44  | total loss: [1m[32m0.12024[0m[0m | time: 36.214s
[2K
| Adam | epoch: 006 | loss: 0.12024 - acc: 0.9589 -- iter: 128/236
[A[ATraining Step: 45  | total loss: [1m[32m0.10947[0m[0m | time: 41.647s
[2K
| Adam | epoch: 006 | loss: 0.10947 - acc: 0.9659 -- iter: 160/236
[A[ATraining Step: 46  | total loss: [1m[32m0.09358[0m[0m | time: 53.320s
[2K
| Adam | epoch: 006 | loss: 0.09358 - acc: 0.9716 -- iter: 192/236
[A[ATraining Step: 47  | total loss: [1m[32m0.08716[0m[0m | time: 65.169s
[2K
| Adam | epoch: 006 | loss: 0.08716 - acc: 0.9711 -- iter: 224/236
[A[ATraining Step: 48  | total loss: [1m[32m0.08073[0m[0m | time: 82.511s
[2K
| Adam | epoch: 006 | loss: 0.08073 - acc: 0.9707 | val_loss: 2.75772 - val_acc: 0.4865 -- iter: 236/236
--
Training Step: 49  | total loss: [1m[32m0.16415[0m[0m | time: 12.144s
[2K
| Adam | epoch: 007 | loss: 0.16415 - acc: 0.9507 -- iter: 032/236
[A[ATraining Step: 50  | total loss: [1m[32m0.15122[0m[0m | time: 24.197s
[2K
| Adam | epoch: 007 | loss: 0.15122 - acc: 0.9535 -- iter: 064/236
[A[ATraining Step: 51  | total loss: [1m[32m0.12898[0m[0m | time: 36.226s
[2K
| Adam | epoch: 007 | loss: 0.12898 - acc: 0.9606 -- iter: 096/236
[A[ATraining Step: 52  | total loss: [1m[32m0.11132[0m[0m | time: 48.206s
[2K
| Adam | epoch: 007 | loss: 0.11132 - acc: 0.9665 -- iter: 128/236
[A[ATraining Step: 53  | total loss: [1m[32m0.12233[0m[0m | time: 54.253s
[2K
| Adam | epoch: 007 | loss: 0.12233 - acc: 0.9576 -- iter: 160/236
[A[ATraining Step: 54  | total loss: [1m[32m0.10678[0m[0m | time: 59.568s
[2K
| Adam | epoch: 007 | loss: 0.10678 - acc: 0.9638 -- iter: 192/236
[A[ATraining Step: 55  | total loss: [1m[32m0.09200[0m[0m | time: 71.518s
[2K
| Adam | epoch: 007 | loss: 0.09200 - acc: 0.9689 -- iter: 224/236
[A[ATraining Step: 56  | total loss: [1m[32m0.10944[0m[0m | time: 89.081s
[2K
| Adam | epoch: 007 | loss: 0.10944 - acc: 0.9645 | val_loss: 0.70511 - val_acc: 0.6892 -- iter: 236/236
--
Training Step: 57  | total loss: [1m[32m0.12292[0m[0m | time: 11.694s
[2K
| Adam | epoch: 008 | loss: 0.12292 - acc: 0.9564 -- iter: 032/236
[A[ATraining Step: 58  | total loss: [1m[32m0.10919[0m[0m | time: 23.972s
[2K
| Adam | epoch: 008 | loss: 0.10919 - acc: 0.9624 -- iter: 064/236
[A[ATraining Step: 59  | total loss: [1m[32m0.09988[0m[0m | time: 36.085s
[2K
| Adam | epoch: 008 | loss: 0.09988 - acc: 0.9674 -- iter: 096/236
[A[ATraining Step: 60  | total loss: [1m[32m0.09087[0m[0m | time: 48.352s
[2K
| Adam | epoch: 008 | loss: 0.09087 - acc: 0.9717 -- iter: 128/236
[A[ATraining Step: 61  | total loss: [1m[32m0.09302[0m[0m | time: 60.279s
[2K
| Adam | epoch: 008 | loss: 0.09302 - acc: 0.9673 -- iter: 160/236
[A[ATraining Step: 62  | total loss: [1m[32m0.09321[0m[0m | time: 66.306s
[2K
| Adam | epoch: 008 | loss: 0.09321 - acc: 0.9635 -- iter: 192/236
[A[ATraining Step: 63  | total loss: [1m[32m0.18067[0m[0m | time: 72.112s
[2K
| Adam | epoch: 008 | loss: 0.18067 - acc: 0.9364 -- iter: 224/236
[A[ATraining Step: 64  | total loss: [1m[32m0.21352[0m[0m | time: 89.206s
[2K
| Adam | epoch: 008 | loss: 0.21352 - acc: 0.9131 | val_loss: 1.00273 - val_acc: 0.7703 -- iter: 236/236
--
Training Step: 65  | total loss: [1m[32m0.21060[0m[0m | time: 12.710s
[2K
| Adam | epoch: 009 | loss: 0.21060 - acc: 0.9200 -- iter: 032/236
[A[ATraining Step: 66  | total loss: [1m[32m0.19531[0m[0m | time: 25.596s
[2K
| Adam | epoch: 009 | loss: 0.19531 - acc: 0.9259 -- iter: 064/236
[A[ATraining Step: 67  | total loss: [1m[32m0.21121[0m[0m | time: 34.576s
[2K
| Adam | epoch: 009 | loss: 0.21121 - acc: 0.9310 -- iter: 096/236
[A[ATraining Step: 68  | total loss: [1m[32m0.20446[0m[0m | time: 42.515s
[2K
| Adam | epoch: 009 | loss: 0.20446 - acc: 0.9281 -- iter: 128/236
[A[ATraining Step: 69  | total loss: [1m[32m0.19687[0m[0m | time: 50.226s
[2K
| Adam | epoch: 009 | loss: 0.19687 - acc: 0.9292 -- iter: 160/236
[A[ATraining Step: 70  | total loss: [1m[32m0.17551[0m[0m | time: 59.514s
[2K
| Adam | epoch: 009 | loss: 0.17551 - acc: 0.9374 -- iter: 192/236
[A[ATraining Step: 71  | total loss: [1m[32m0.18326[0m[0m | time: 65.383s
[2K
| Adam | epoch: 009 | loss: 0.18326 - acc: 0.9338 -- iter: 224/236
[A[ATraining Step: 72  | total loss: [1m[32m0.19465[0m[0m | time: 76.214s
[2K
| Adam | epoch: 009 | loss: 0.19465 - acc: 0.9319 | val_loss: 2.58392 - val_acc: 0.6216 -- iter: 236/236
--
Training Step: 73  | total loss: [1m[32m0.18466[0m[0m | time: 11.922s
[2K
| Adam | epoch: 010 | loss: 0.18466 - acc: 0.9302 -- iter: 032/236
[A[ATraining Step: 74  | total loss: [1m[32m0.19270[0m[0m | time: 24.045s
[2K
| Adam | epoch: 010 | loss: 0.19270 - acc: 0.9241 -- iter: 064/236
[A[ATraining Step: 75  | total loss: [1m[32m0.17654[0m[0m | time: 35.489s
[2K
| Adam | epoch: 010 | loss: 0.17654 - acc: 0.9324 -- iter: 096/236
[A[ATraining Step: 76  | total loss: [1m[32m0.18388[0m[0m | time: 46.596s
[2K
| Adam | epoch: 010 | loss: 0.18388 - acc: 0.9296 -- iter: 128/236
[A[ATraining Step: 77  | total loss: [1m[32m0.17755[0m[0m | time: 58.724s
[2K
| Adam | epoch: 010 | loss: 0.17755 - acc: 0.9337 -- iter: 160/236
[A[ATraining Step: 78  | total loss: [1m[32m0.18831[0m[0m | time: 70.759s
[2K
| Adam | epoch: 010 | loss: 0.18831 - acc: 0.9308 -- iter: 192/236
[A[ATraining Step: 79  | total loss: [1m[32m0.17805[0m[0m | time: 82.629s
[2K
| Adam | epoch: 010 | loss: 0.17805 - acc: 0.9348 -- iter: 224/236
[A[ATraining Step: 80  | total loss: [1m[32m0.18040[0m[0m | time: 93.477s
[2K
| Adam | epoch: 010 | loss: 0.18040 - acc: 0.9382 | val_loss: 10.63913 - val_acc: 0.5135 -- iter: 236/236
--
Training Step: 81  | total loss: [1m[32m0.19377[0m[0m | time: 5.955s
[2K
| Adam | epoch: 011 | loss: 0.19377 - acc: 0.9276 -- iter: 032/236
[A[ATraining Step: 82  | total loss: [1m[32m0.17930[0m[0m | time: 18.026s
[2K
| Adam | epoch: 011 | loss: 0.17930 - acc: 0.9349 -- iter: 064/236
[A[ATraining Step: 83  | total loss: [1m[32m0.18946[0m[0m | time: 30.251s
[2K
| Adam | epoch: 011 | loss: 0.18946 - acc: 0.9320 -- iter: 096/236
[A[ATraining Step: 84  | total loss: [1m[32m0.20657[0m[0m | time: 42.249s
[2K
| Adam | epoch: 011 | loss: 0.20657 - acc: 0.9263 -- iter: 128/236
[A[ATraining Step: 85  | total loss: [1m[32m0.22428[0m[0m | time: 54.453s
[2K
| Adam | epoch: 011 | loss: 0.22428 - acc: 0.9274 -- iter: 160/236
[A[ATraining Step: 86  | total loss: [1m[32m0.21720[0m[0m | time: 66.496s
[2K
| Adam | epoch: 011 | loss: 0.21720 - acc: 0.9222 -- iter: 192/236
[A[ATraining Step: 87  | total loss: [1m[32m0.20080[0m[0m | time: 78.352s
[2K
| Adam | epoch: 011 | loss: 0.20080 - acc: 0.9300 -- iter: 224/236
[A[ATraining Step: 88  | total loss: [1m[32m0.18294[0m[0m | time: 95.369s
[2K
| Adam | epoch: 011 | loss: 0.18294 - acc: 0.9370 | val_loss: 0.24522 - val_acc: 0.9054 -- iter: 236/236
--
Training Step: 89  | total loss: [1m[32m0.18538[0m[0m | time: 5.881s
[2K
| Adam | epoch: 012 | loss: 0.18538 - acc: 0.9339 -- iter: 032/236
[A[ATraining Step: 90  | total loss: [1m[32m0.17735[0m[0m | time: 11.424s
[2K
| Adam | epoch: 012 | loss: 0.17735 - acc: 0.9405 -- iter: 064/236
[A[ATraining Step: 91  | total loss: [1m[32m0.16443[0m[0m | time: 23.738s
[2K
| Adam | epoch: 012 | loss: 0.16443 - acc: 0.9465 -- iter: 096/236
[A[ATraining Step: 92  | total loss: [1m[32m0.17273[0m[0m | time: 35.641s
[2K
| Adam | epoch: 012 | loss: 0.17273 - acc: 0.9393 -- iter: 128/236
[A[ATraining Step: 93  | total loss: [1m[32m0.16982[0m[0m | time: 47.612s
[2K
| Adam | epoch: 012 | loss: 0.16982 - acc: 0.9391 -- iter: 160/236
[A[ATraining Step: 94  | total loss: [1m[32m0.19528[0m[0m | time: 59.651s
[2K
| Adam | epoch: 012 | loss: 0.19528 - acc: 0.9421 -- iter: 192/236
[A[ATraining Step: 95  | total loss: [1m[32m0.18493[0m[0m | time: 71.582s
[2K
| Adam | epoch: 012 | loss: 0.18493 - acc: 0.9416 -- iter: 224/236
[A[ATraining Step: 96  | total loss: [1m[32m0.17160[0m[0m | time: 88.573s
[2K
| Adam | epoch: 012 | loss: 0.17160 - acc: 0.9475 | val_loss: 0.33885 - val_acc: 0.8919 -- iter: 236/236
--
Training Step: 97  | total loss: [1m[32m0.16773[0m[0m | time: 12.209s
[2K
| Adam | epoch: 013 | loss: 0.16773 - acc: 0.9465 -- iter: 032/236
[A[ATraining Step: 98  | total loss: [1m[32m0.16030[0m[0m | time: 18.063s
[2K
| Adam | epoch: 013 | loss: 0.16030 - acc: 0.9487 -- iter: 064/236
[A[ATraining Step: 99  | total loss: [1m[32m0.15948[0m[0m | time: 23.669s
[2K
| Adam | epoch: 013 | loss: 0.15948 - acc: 0.9455 -- iter: 096/236
[A[ATraining Step: 100  | total loss: [1m[32m0.14608[0m[0m | time: 35.577s
[2K
| Adam | epoch: 013 | loss: 0.14608 - acc: 0.9509 -- iter: 128/236
[A[ATraining Step: 101  | total loss: [1m[32m0.13752[0m[0m | time: 47.774s
[2K
| Adam | epoch: 013 | loss: 0.13752 - acc: 0.9559 -- iter: 160/236
[A[ATraining Step: 102  | total loss: [1m[32m0.15161[0m[0m | time: 59.817s
[2K
| Adam | epoch: 013 | loss: 0.15161 - acc: 0.9478 -- iter: 192/236
[A[ATraining Step: 103  | total loss: [1m[32m0.16286[0m[0m | time: 71.783s
[2K
| Adam | epoch: 013 | loss: 0.16286 - acc: 0.9467 -- iter: 224/236
[A[ATraining Step: 104  | total loss: [1m[32m0.15246[0m[0m | time: 88.840s
[2K
| Adam | epoch: 013 | loss: 0.15246 - acc: 0.9521 | val_loss: 2.94903 - val_acc: 0.6081 -- iter: 236/236
--
Training Step: 105  | total loss: [1m[32m0.15321[0m[0m | time: 12.061s
[2K
| Adam | epoch: 014 | loss: 0.15321 - acc: 0.9506 -- iter: 032/236
[A[ATraining Step: 106  | total loss: [1m[32m0.15442[0m[0m | time: 23.955s
[2K
| Adam | epoch: 014 | loss: 0.15442 - acc: 0.9524 -- iter: 064/236
[A[ATraining Step: 107  | total loss: [1m[32m0.14581[0m[0m | time: 29.865s
[2K
| Adam | epoch: 014 | loss: 0.14581 - acc: 0.9541 -- iter: 096/236
[A[ATraining Step: 108  | total loss: [1m[32m0.13515[0m[0m | time: 35.368s
[2K
| Adam | epoch: 014 | loss: 0.13515 - acc: 0.9587 -- iter: 128/236
[A[ATraining Step: 109  | total loss: [1m[32m0.12253[0m[0m | time: 47.523s
[2K
| Adam | epoch: 014 | loss: 0.12253 - acc: 0.9628 -- iter: 160/236
[A[ATraining Step: 110  | total loss: [1m[32m0.11509[0m[0m | time: 59.388s
[2K
| Adam | epoch: 014 | loss: 0.11509 - acc: 0.9634 -- iter: 192/236
[A[ATraining Step: 111  | total loss: [1m[32m0.10688[0m[0m | time: 71.191s
[2K
| Adam | epoch: 014 | loss: 0.10688 - acc: 0.9670 -- iter: 224/236
[A[ATraining Step: 112  | total loss: [1m[32m0.19703[0m[0m | time: 88.909s
[2K
| Adam | epoch: 014 | loss: 0.19703 - acc: 0.9547 | val_loss: 1.07473 - val_acc: 0.7027 -- iter: 236/236
--
Training Step: 113  | total loss: [1m[32m0.18181[0m[0m | time: 11.970s
[2K
| Adam | epoch: 015 | loss: 0.18181 - acc: 0.9592 -- iter: 032/236
[A[ATraining Step: 114  | total loss: [1m[32m0.17772[0m[0m | time: 23.914s
[2K
| Adam | epoch: 015 | loss: 0.17772 - acc: 0.9539 -- iter: 064/236
[A[ATraining Step: 115  | total loss: [1m[32m0.16821[0m[0m | time: 35.697s
[2K
| Adam | epoch: 015 | loss: 0.16821 - acc: 0.9554 -- iter: 096/236
[A[ATraining Step: 116  | total loss: [1m[32m0.15779[0m[0m | time: 41.359s
[2K
| Adam | epoch: 015 | loss: 0.15779 - acc: 0.9599 -- iter: 128/236
[A[ATraining Step: 117  | total loss: [1m[32m0.15045[0m[0m | time: 46.855s
[2K
| Adam | epoch: 015 | loss: 0.15045 - acc: 0.9556 -- iter: 160/236
[A[ATraining Step: 118  | total loss: [1m[32m0.13912[0m[0m | time: 58.946s
[2K
| Adam | epoch: 015 | loss: 0.13912 - acc: 0.9600 -- iter: 192/236
[A[ATraining Step: 119  | total loss: [1m[32m0.13404[0m[0m | time: 70.661s
[2K
| Adam | epoch: 015 | loss: 0.13404 - acc: 0.9609 -- iter: 224/236
[A[ATraining Step: 120  | total loss: [1m[32m0.12748[0m[0m | time: 88.141s
[2K
| Adam | epoch: 015 | loss: 0.12748 - acc: 0.9648 | val_loss: 0.23034 - val_acc: 0.9459 -- iter: 236/236
--
Validation AUC:0.966374269005848
Validation AUPRC:0.973203246208509
Test AUC:0.992609016999261
Test AUPRC:0.9912109788446686
BestTestF1Score	0.96	0.92	0.96	0.94	0.97	32	2	39	1	0.67
BestTestMCCScore	0.96	0.92	0.96	0.94	0.97	32	2	39	1	0.67
BestTestAccuracyScore	0.96	0.92	0.96	0.94	0.97	32	2	39	1	0.67
BestValidationF1Score	0.96	0.92	0.96	0.95	0.97	37	2	34	1	0.67
BestValidationMCC	0.96	0.92	0.96	0.95	0.97	37	2	34	1	0.67
BestValidationAccuracy	0.96	0.92	0.96	0.95	0.97	37	2	34	1	0.67
TestPredictions (Threshold:0.67)
CHEMBL2204699,TN,INACT,0.11999999731779099	CHEMBL2348887,TN,INACT,0.009999999776482582	CHEMBL1173474,TN,INACT,0.019999999552965164	CHEMBL356326,TP,ACT,0.9700000286102295	CHEMBL492047,TN,INACT,0.3499999940395355	CHEMBL683,TN,INACT,0.0	CHEMBL2204695,TN,INACT,0.550000011920929	CHEMBL157272,TP,ACT,1.0	CHEMBL285179,TP,ACT,0.9700000286102295	CHEMBL2348879,TN,INACT,0.0	CHEMBL234659,FP,INACT,0.8500000238418579	CHEMBL80271,TP,ACT,1.0	CHEMBL2204697,TN,INACT,0.25	CHEMBL1327417,TN,INACT,0.20000000298023224	CHEMBL36768,TP,ACT,1.0	CHEMBL2204687,TN,INACT,0.18000000715255737	CHEMBL394913,TN,INACT,0.029999999329447746	CHEMBL1808553,TN,INACT,0.0	CHEMBL134375,TP,ACT,1.0	CHEMBL491039,TN,INACT,0.029999999329447746	CHEMBL596544,TN,INACT,0.3499999940395355	CHEMBL396873,TN,INACT,0.12999999523162842	CHEMBL119030,TN,INACT,0.6600000262260437	CHEMBL133725,TP,ACT,0.9900000095367432	CHEMBL118754,TP,ACT,0.9800000190734863	CHEMBL2070846,TN,INACT,0.09000000357627869	CHEMBL326911,TP,ACT,0.949999988079071	CHEMBL489597,TN,INACT,0.009999999776482582	CHEMBL165417,TP,ACT,1.0	CHEMBL424190,TP,ACT,1.0	CHEMBL130577,TP,ACT,0.8999999761581421	CHEMBL258818,TN,INACT,0.17000000178813934	CHEMBL484264,TN,INACT,0.0	CHEMBL237600,TN,INACT,0.14000000059604645	CHEMBL32505,TP,ACT,0.9900000095367432	CHEMBL335242,TP,ACT,0.9900000095367432	CHEMBL133915,TP,ACT,0.949999988079071	CHEMBL337859,FN,ACT,0.5799999833106995	CHEMBL82293,TN,INACT,0.029999999329447746	CHEMBL125587,TP,ACT,0.9800000190734863	CHEMBL156997,TP,ACT,1.0	CHEMBL75848,TP,ACT,0.9900000095367432	CHEMBL1173381,TN,INACT,0.009999999776482582	CHEMBL131810,TP,ACT,0.9900000095367432	CHEMBL284167,TP,ACT,0.6800000071525574	CHEMBL458899,TN,INACT,0.20999999344348907	CHEMBL147545,TP,ACT,0.9900000095367432	CHEMBL2011540,TN,INACT,0.20999999344348907	CHEMBL146646,TP,ACT,1.0	CHEMBL1080699,TN,INACT,0.05000000074505806	CHEMBL3752848,FP,INACT,0.8399999737739563	CHEMBL89241,TP,ACT,0.9900000095367432	CHEMBL34292,TP,ACT,1.0	CHEMBL237611,TN,INACT,0.019999999552965164	CHEMBL1956361,TN,INACT,0.0	CHEMBL3109600,TN,INACT,0.5899999737739563	CHEMBL75732,TP,ACT,1.0	CHEMBL358145,TP,ACT,1.0	CHEMBL430616,TP,ACT,1.0	CHEMBL107498,TN,INACT,0.019999999552965164	CHEMBL236543,TN,INACT,0.12999999523162842	CHEMBL2070853,TN,INACT,0.10999999940395355	CHEMBL2011538,TN,INACT,0.25	CHEMBL1164770,TN,INACT,0.23000000417232513	CHEMBL74218,TP,ACT,0.6700000166893005	CHEMBL235113,TN,INACT,0.05999999865889549	CHEMBL470587,TP,ACT,0.8199999928474426	CHEMBL2204683,TN,INACT,0.03999999910593033	CHEMBL398106,TN,INACT,0.15000000596046448	CHEMBL486176,TN,INACT,0.07999999821186066	CHEMBL89253,TP,ACT,0.8899999856948853	CHEMBL575075,TN,INACT,0.1899999976158142	CHEMBL345298,TP,ACT,1.0	CHEMBL421773,TP,ACT,1.0	

