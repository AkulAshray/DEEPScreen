CNNModel CHEMBL223 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	1138
Number of inactive compounds :	1138
---------------------------------
Run id: CNNModel_CHEMBL223_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL223_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 1395
Validation samples: 437
--
Training Step: 1  | time: 1.375s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1395
[A[ATraining Step: 2  | total loss: [1m[32m0.62373[0m[0m | time: 2.356s
[2K
| Adam | epoch: 001 | loss: 0.62373 - acc: 0.4781 -- iter: 0064/1395
[A[ATraining Step: 3  | total loss: [1m[32m0.68185[0m[0m | time: 3.299s
[2K
| Adam | epoch: 001 | loss: 0.68185 - acc: 0.4449 -- iter: 0096/1395
[A[ATraining Step: 4  | total loss: [1m[32m0.68986[0m[0m | time: 4.318s
[2K
| Adam | epoch: 001 | loss: 0.68986 - acc: 0.4862 -- iter: 0128/1395
[A[ATraining Step: 5  | total loss: [1m[32m0.69165[0m[0m | time: 5.490s
[2K
| Adam | epoch: 001 | loss: 0.69165 - acc: 0.5823 -- iter: 0160/1395
[A[ATraining Step: 6  | total loss: [1m[32m0.69326[0m[0m | time: 6.568s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.5294 -- iter: 0192/1395
[A[ATraining Step: 7  | total loss: [1m[32m0.69239[0m[0m | time: 7.659s
[2K
| Adam | epoch: 001 | loss: 0.69239 - acc: 0.5305 -- iter: 0224/1395
[A[ATraining Step: 8  | total loss: [1m[32m0.69064[0m[0m | time: 8.634s
[2K
| Adam | epoch: 001 | loss: 0.69064 - acc: 0.5485 -- iter: 0256/1395
[A[ATraining Step: 9  | total loss: [1m[32m0.68732[0m[0m | time: 9.818s
[2K
| Adam | epoch: 001 | loss: 0.68732 - acc: 0.5725 -- iter: 0288/1395
[A[ATraining Step: 10  | total loss: [1m[32m0.68618[0m[0m | time: 13.970s
[2K
| Adam | epoch: 001 | loss: 0.68618 - acc: 0.5675 -- iter: 0320/1395
[A[ATraining Step: 11  | total loss: [1m[32m0.68597[0m[0m | time: 25.994s
[2K
| Adam | epoch: 001 | loss: 0.68597 - acc: 0.5651 -- iter: 0352/1395
[A[ATraining Step: 12  | total loss: [1m[32m0.70843[0m[0m | time: 42.620s
[2K
| Adam | epoch: 001 | loss: 0.70843 - acc: 0.5077 -- iter: 0384/1395
[A[ATraining Step: 13  | total loss: [1m[32m0.70239[0m[0m | time: 62.793s
[2K
| Adam | epoch: 001 | loss: 0.70239 - acc: 0.5178 -- iter: 0416/1395
[A[ATraining Step: 14  | total loss: [1m[32m0.70007[0m[0m | time: 78.958s
[2K
| Adam | epoch: 001 | loss: 0.70007 - acc: 0.5105 -- iter: 0448/1395
[A[ATraining Step: 15  | total loss: [1m[32m0.69639[0m[0m | time: 95.801s
[2K
| Adam | epoch: 001 | loss: 0.69639 - acc: 0.5186 -- iter: 0480/1395
[A[ATraining Step: 16  | total loss: [1m[32m0.69551[0m[0m | time: 107.798s
[2K
| Adam | epoch: 001 | loss: 0.69551 - acc: 0.5116 -- iter: 0512/1395
[A[ATraining Step: 17  | total loss: [1m[32m0.69535[0m[0m | time: 122.122s
[2K
| Adam | epoch: 001 | loss: 0.69535 - acc: 0.4962 -- iter: 0544/1395
[A[ATraining Step: 18  | total loss: [1m[32m0.69525[0m[0m | time: 133.596s
[2K
| Adam | epoch: 001 | loss: 0.69525 - acc: 0.4867 -- iter: 0576/1395
[A[ATraining Step: 19  | total loss: [1m[32m0.69325[0m[0m | time: 134.542s
[2K
| Adam | epoch: 001 | loss: 0.69325 - acc: 0.5328 -- iter: 0608/1395
[A[ATraining Step: 20  | total loss: [1m[32m0.69225[0m[0m | time: 135.532s
[2K
| Adam | epoch: 001 | loss: 0.69225 - acc: 0.5624 -- iter: 0640/1395
[A[ATraining Step: 21  | total loss: [1m[32m0.69376[0m[0m | time: 136.513s
[2K
| Adam | epoch: 001 | loss: 0.69376 - acc: 0.4849 -- iter: 0672/1395
[A[ATraining Step: 22  | total loss: [1m[32m0.69442[0m[0m | time: 137.625s
[2K
| Adam | epoch: 001 | loss: 0.69442 - acc: 0.4425 -- iter: 0704/1395
[A[ATraining Step: 23  | total loss: [1m[32m0.69420[0m[0m | time: 138.652s
[2K
| Adam | epoch: 001 | loss: 0.69420 - acc: 0.4411 -- iter: 0736/1395
[A[ATraining Step: 24  | total loss: [1m[32m0.69403[0m[0m | time: 139.971s
[2K
| Adam | epoch: 001 | loss: 0.69403 - acc: 0.4489 -- iter: 0768/1395
[A[ATraining Step: 25  | total loss: [1m[32m0.69379[0m[0m | time: 141.155s
[2K
| Adam | epoch: 001 | loss: 0.69379 - acc: 0.4713 -- iter: 0800/1395
[A[ATraining Step: 26  | total loss: [1m[32m0.69363[0m[0m | time: 142.333s
[2K
| Adam | epoch: 001 | loss: 0.69363 - acc: 0.4789 -- iter: 0832/1395
[A[ATraining Step: 27  | total loss: [1m[32m0.69351[0m[0m | time: 143.424s
[2K
| Adam | epoch: 001 | loss: 0.69351 - acc: 0.4763 -- iter: 0864/1395
[A[ATraining Step: 28  | total loss: [1m[32m0.69348[0m[0m | time: 144.523s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.4744 -- iter: 0896/1395
[A[ATraining Step: 29  | total loss: [1m[32m0.69336[0m[0m | time: 145.687s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.5034 -- iter: 0928/1395
[A[ATraining Step: 30  | total loss: [1m[32m0.69329[0m[0m | time: 152.788s
[2K
| Adam | epoch: 001 | loss: 0.69329 - acc: 0.5100 -- iter: 0960/1395
[A[ATraining Step: 31  | total loss: [1m[32m0.69328[0m[0m | time: 155.603s
[2K
| Adam | epoch: 001 | loss: 0.69328 - acc: 0.5149 -- iter: 0992/1395
[A[ATraining Step: 32  | total loss: [1m[32m0.69319[0m[0m | time: 164.265s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5256 -- iter: 1024/1395
[A[ATraining Step: 33  | total loss: [1m[32m0.69320[0m[0m | time: 171.544s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5200 -- iter: 1056/1395
[A[ATraining Step: 34  | total loss: [1m[32m0.69320[0m[0m | time: 186.305s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5157 -- iter: 1088/1395
[A[ATraining Step: 35  | total loss: [1m[32m0.69319[0m[0m | time: 198.311s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5124 -- iter: 1120/1395
[A[ATraining Step: 36  | total loss: [1m[32m0.69311[0m[0m | time: 203.171s
[2K
| Adam | epoch: 001 | loss: 0.69311 - acc: 0.5163 -- iter: 1152/1395
[A[ATraining Step: 37  | total loss: [1m[32m0.69297[0m[0m | time: 205.588s
[2K
| Adam | epoch: 001 | loss: 0.69297 - acc: 0.5255 -- iter: 1184/1395
[A[ATraining Step: 38  | total loss: [1m[32m0.69324[0m[0m | time: 206.697s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.5083 -- iter: 1216/1395
[A[ATraining Step: 39  | total loss: [1m[32m0.69342[0m[0m | time: 207.990s
[2K
| Adam | epoch: 001 | loss: 0.69342 - acc: 0.4947 -- iter: 1248/1395
[A[ATraining Step: 40  | total loss: [1m[32m0.69368[0m[0m | time: 209.115s
[2K
| Adam | epoch: 001 | loss: 0.69368 - acc: 0.4782 -- iter: 1280/1395
[A[ATraining Step: 41  | total loss: [1m[32m0.69350[0m[0m | time: 210.189s
[2K
| Adam | epoch: 001 | loss: 0.69350 - acc: 0.4879 -- iter: 1312/1395
[A[ATraining Step: 42  | total loss: [1m[32m0.69355[0m[0m | time: 211.349s
[2K
| Adam | epoch: 001 | loss: 0.69355 - acc: 0.4845 -- iter: 1344/1395
[A[ATraining Step: 43  | total loss: [1m[32m0.69368[0m[0m | time: 212.434s
[2K
| Adam | epoch: 001 | loss: 0.69368 - acc: 0.4707 -- iter: 1376/1395
[A[ATraining Step: 44  | total loss: [1m[32m0.69355[0m[0m | time: 216.186s
[2K
| Adam | epoch: 001 | loss: 0.69355 - acc: 0.4811 | val_loss: 0.69359 - val_acc: 0.4485 -- iter: 1395/1395
--
Training Step: 45  | total loss: [1m[32m0.69353[0m[0m | time: 1.018s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.4799 -- iter: 0032/1395
[A[ATraining Step: 46  | total loss: [1m[32m0.69350[0m[0m | time: 19.909s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.4788 -- iter: 0064/1395
[A[ATraining Step: 47  | total loss: [1m[32m0.69362[0m[0m | time: 31.043s
[2K
| Adam | epoch: 002 | loss: 0.69362 - acc: 0.4567 -- iter: 0096/1395
[A[ATraining Step: 48  | total loss: [1m[32m0.69344[0m[0m | time: 42.601s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.4938 -- iter: 0128/1395
[A[ATraining Step: 49  | total loss: [1m[32m0.69341[0m[0m | time: 55.138s
[2K
| Adam | epoch: 002 | loss: 0.69341 - acc: 0.4849 -- iter: 0160/1395
[A[ATraining Step: 50  | total loss: [1m[32m0.69342[0m[0m | time: 61.924s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4776 -- iter: 0192/1395
[A[ATraining Step: 51  | total loss: [1m[32m0.69336[0m[0m | time: 68.152s
[2K
| Adam | epoch: 002 | loss: 0.69336 - acc: 0.4905 -- iter: 0224/1395
[A[ATraining Step: 52  | total loss: [1m[32m0.69332[0m[0m | time: 75.612s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4966 -- iter: 0256/1395
[A[ATraining Step: 53  | total loss: [1m[32m0.69328[0m[0m | time: 76.753s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.5064 -- iter: 0288/1395
[A[ATraining Step: 54  | total loss: [1m[32m0.69326[0m[0m | time: 77.731s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.5054 -- iter: 0320/1395
[A[ATraining Step: 55  | total loss: [1m[32m0.69320[0m[0m | time: 78.800s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5091 -- iter: 0352/1395
[A[ATraining Step: 56  | total loss: [1m[32m0.69317[0m[0m | time: 79.900s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.5078 -- iter: 0384/1395
[A[ATraining Step: 57  | total loss: [1m[32m0.69315[0m[0m | time: 80.976s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5068 -- iter: 0416/1395
[A[ATraining Step: 58  | total loss: [1m[32m0.69330[0m[0m | time: 81.977s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4930 -- iter: 0448/1395
[A[ATraining Step: 59  | total loss: [1m[32m0.69344[0m[0m | time: 83.120s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.4814 -- iter: 0480/1395
[A[ATraining Step: 60  | total loss: [1m[32m0.69331[0m[0m | time: 84.207s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4921 -- iter: 0512/1395
[A[ATraining Step: 61  | total loss: [1m[32m0.69324[0m[0m | time: 85.251s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4972 -- iter: 0544/1395
[A[ATraining Step: 62  | total loss: [1m[32m0.69318[0m[0m | time: 86.219s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5016 -- iter: 0576/1395
[A[ATraining Step: 63  | total loss: [1m[32m0.69297[0m[0m | time: 87.165s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5172 -- iter: 0608/1395
[A[ATraining Step: 64  | total loss: [1m[32m0.69305[0m[0m | time: 88.079s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5112 -- iter: 0640/1395
[A[ATraining Step: 65  | total loss: [1m[32m0.69300[0m[0m | time: 88.814s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5137 -- iter: 0672/1395
[A[ATraining Step: 66  | total loss: [1m[32m0.69283[0m[0m | time: 89.651s
[2K
| Adam | epoch: 002 | loss: 0.69283 - acc: 0.5234 -- iter: 0704/1395
[A[ATraining Step: 67  | total loss: [1m[32m0.69294[0m[0m | time: 90.397s
[2K
| Adam | epoch: 002 | loss: 0.69294 - acc: 0.5168 -- iter: 0736/1395
[A[ATraining Step: 68  | total loss: [1m[32m0.69272[0m[0m | time: 91.279s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5259 -- iter: 0768/1395
[A[ATraining Step: 69  | total loss: [1m[32m0.69276[0m[0m | time: 92.094s
[2K
| Adam | epoch: 002 | loss: 0.69276 - acc: 0.5229 -- iter: 0800/1395
[A[ATraining Step: 70  | total loss: [1m[32m0.69292[0m[0m | time: 92.923s
[2K
| Adam | epoch: 002 | loss: 0.69292 - acc: 0.5167 -- iter: 0832/1395
[A[ATraining Step: 71  | total loss: [1m[32m0.69287[0m[0m | time: 93.733s
[2K
| Adam | epoch: 002 | loss: 0.69287 - acc: 0.5183 -- iter: 0864/1395
[A[ATraining Step: 72  | total loss: [1m[32m0.69281[0m[0m | time: 94.508s
[2K
| Adam | epoch: 002 | loss: 0.69281 - acc: 0.5198 -- iter: 0896/1395
[A[ATraining Step: 73  | total loss: [1m[32m0.69296[0m[0m | time: 95.364s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5141 -- iter: 0928/1395
[A[ATraining Step: 74  | total loss: [1m[32m0.69287[0m[0m | time: 96.145s
[2K
| Adam | epoch: 002 | loss: 0.69287 - acc: 0.5160 -- iter: 0960/1395
[A[ATraining Step: 75  | total loss: [1m[32m0.69312[0m[0m | time: 97.297s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5075 -- iter: 0992/1395
[A[ATraining Step: 76  | total loss: [1m[32m0.69383[0m[0m | time: 98.415s
[2K
| Adam | epoch: 002 | loss: 0.69383 - acc: 0.4866 -- iter: 1024/1395
[A[ATraining Step: 77  | total loss: [1m[32m0.69393[0m[0m | time: 99.724s
[2K
| Adam | epoch: 002 | loss: 0.69393 - acc: 0.4814 -- iter: 1056/1395
[A[ATraining Step: 78  | total loss: [1m[32m0.69392[0m[0m | time: 100.857s
[2K
| Adam | epoch: 002 | loss: 0.69392 - acc: 0.4801 -- iter: 1088/1395
[A[ATraining Step: 79  | total loss: [1m[32m0.69408[0m[0m | time: 102.022s
[2K
| Adam | epoch: 002 | loss: 0.69408 - acc: 0.4724 -- iter: 1120/1395
[A[ATraining Step: 80  | total loss: [1m[32m0.69406[0m[0m | time: 103.178s
[2K
| Adam | epoch: 002 | loss: 0.69406 - acc: 0.4721 -- iter: 1152/1395
[A[ATraining Step: 81  | total loss: [1m[32m0.69408[0m[0m | time: 104.384s
[2K
| Adam | epoch: 002 | loss: 0.69408 - acc: 0.4686 -- iter: 1184/1395
[A[ATraining Step: 82  | total loss: [1m[32m0.69376[0m[0m | time: 105.581s
[2K
| Adam | epoch: 002 | loss: 0.69376 - acc: 0.4873 -- iter: 1216/1395
[A[ATraining Step: 83  | total loss: [1m[32m0.69342[0m[0m | time: 106.535s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.5073 -- iter: 1248/1395
[A[ATraining Step: 84  | total loss: [1m[32m0.69325[0m[0m | time: 107.354s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5160 -- iter: 1280/1395
[A[ATraining Step: 85  | total loss: [1m[32m0.69340[0m[0m | time: 108.136s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.5050 -- iter: 1312/1395
[A[ATraining Step: 86  | total loss: [1m[32m0.69347[0m[0m | time: 108.948s
[2K
| Adam | epoch: 002 | loss: 0.69347 - acc: 0.4983 -- iter: 1344/1395
[A[ATraining Step: 87  | total loss: [1m[32m0.69339[0m[0m | time: 109.713s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.5016 -- iter: 1376/1395
[A[ATraining Step: 88  | total loss: [1m[32m0.69316[0m[0m | time: 112.347s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5139 | val_loss: 0.69229 - val_acc: 0.5515 -- iter: 1395/1395
--
Training Step: 89  | total loss: [1m[32m0.69284[0m[0m | time: 0.581s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5344 -- iter: 0032/1395
[A[ATraining Step: 90  | total loss: [1m[32m0.69292[0m[0m | time: 1.203s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5283 -- iter: 0064/1395
[A[ATraining Step: 91  | total loss: [1m[32m0.69302[0m[0m | time: 1.949s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5229 -- iter: 0096/1395
[A[ATraining Step: 92  | total loss: [1m[32m0.69297[0m[0m | time: 2.705s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5237 -- iter: 0128/1395
[A[ATraining Step: 93  | total loss: [1m[32m0.69267[0m[0m | time: 3.451s
[2K
| Adam | epoch: 003 | loss: 0.69267 - acc: 0.5370 -- iter: 0160/1395
[A[ATraining Step: 94  | total loss: [1m[32m0.69293[0m[0m | time: 4.289s
[2K
| Adam | epoch: 003 | loss: 0.69293 - acc: 0.5239 -- iter: 0192/1395
[A[ATraining Step: 95  | total loss: [1m[32m0.69294[0m[0m | time: 5.144s
[2K
| Adam | epoch: 003 | loss: 0.69294 - acc: 0.5215 -- iter: 0224/1395
[A[ATraining Step: 96  | total loss: [1m[32m0.69281[0m[0m | time: 5.944s
[2K
| Adam | epoch: 003 | loss: 0.69281 - acc: 0.5256 -- iter: 0256/1395
[A[ATraining Step: 97  | total loss: [1m[32m0.69309[0m[0m | time: 6.756s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5137 -- iter: 0288/1395
[A[ATraining Step: 98  | total loss: [1m[32m0.69302[0m[0m | time: 7.545s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5154 -- iter: 0320/1395
[A[ATraining Step: 99  | total loss: [1m[32m0.69328[0m[0m | time: 8.296s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.5045 -- iter: 0352/1395
[A[ATraining Step: 100  | total loss: [1m[32m0.69326[0m[0m | time: 9.136s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5041 -- iter: 0384/1395
[A[ATraining Step: 101  | total loss: [1m[32m0.69343[0m[0m | time: 9.856s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.4974 -- iter: 0416/1395
[A[ATraining Step: 102  | total loss: [1m[32m0.69357[0m[0m | time: 10.697s
[2K
| Adam | epoch: 003 | loss: 0.69357 - acc: 0.4914 -- iter: 0448/1395
[A[ATraining Step: 103  | total loss: [1m[32m0.69412[0m[0m | time: 11.435s
[2K
| Adam | epoch: 003 | loss: 0.69412 - acc: 0.4673 -- iter: 0480/1395
[A[ATraining Step: 104  | total loss: [1m[32m0.69408[0m[0m | time: 12.303s
[2K
| Adam | epoch: 003 | loss: 0.69408 - acc: 0.4674 -- iter: 0512/1395
[A[ATraining Step: 105  | total loss: [1m[32m0.69410[0m[0m | time: 13.136s
[2K
| Adam | epoch: 003 | loss: 0.69410 - acc: 0.4644 -- iter: 0544/1395
[A[ATraining Step: 106  | total loss: [1m[32m0.69411[0m[0m | time: 13.997s
[2K
| Adam | epoch: 003 | loss: 0.69411 - acc: 0.4617 -- iter: 0576/1395
[A[ATraining Step: 107  | total loss: [1m[32m0.69406[0m[0m | time: 14.778s
[2K
| Adam | epoch: 003 | loss: 0.69406 - acc: 0.4624 -- iter: 0608/1395
[A[ATraining Step: 108  | total loss: [1m[32m0.69399[0m[0m | time: 15.634s
[2K
| Adam | epoch: 003 | loss: 0.69399 - acc: 0.4631 -- iter: 0640/1395
[A[ATraining Step: 109  | total loss: [1m[32m0.69384[0m[0m | time: 16.485s
[2K
| Adam | epoch: 003 | loss: 0.69384 - acc: 0.4761 -- iter: 0672/1395
[A[ATraining Step: 110  | total loss: [1m[32m0.69371[0m[0m | time: 17.327s
[2K
| Adam | epoch: 003 | loss: 0.69371 - acc: 0.4879 -- iter: 0704/1395
[A[ATraining Step: 111  | total loss: [1m[32m0.69369[0m[0m | time: 18.102s
[2K
| Adam | epoch: 003 | loss: 0.69369 - acc: 0.4829 -- iter: 0736/1395
[A[ATraining Step: 112  | total loss: [1m[32m0.69361[0m[0m | time: 18.949s
[2K
| Adam | epoch: 003 | loss: 0.69361 - acc: 0.4877 -- iter: 0768/1395
[A[ATraining Step: 113  | total loss: [1m[32m0.69355[0m[0m | time: 19.767s
[2K
| Adam | epoch: 003 | loss: 0.69355 - acc: 0.4889 -- iter: 0800/1395
[A[ATraining Step: 114  | total loss: [1m[32m0.69346[0m[0m | time: 20.571s
[2K
| Adam | epoch: 003 | loss: 0.69346 - acc: 0.4994 -- iter: 0832/1395
[A[ATraining Step: 115  | total loss: [1m[32m0.69343[0m[0m | time: 21.354s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.4995 -- iter: 0864/1395
[A[ATraining Step: 116  | total loss: [1m[32m0.69336[0m[0m | time: 22.151s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.5058 -- iter: 0896/1395
[A[ATraining Step: 117  | total loss: [1m[32m0.69326[0m[0m | time: 22.889s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5208 -- iter: 0928/1395
[A[ATraining Step: 118  | total loss: [1m[32m0.69324[0m[0m | time: 23.845s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.5219 -- iter: 0960/1395
[A[ATraining Step: 119  | total loss: [1m[32m0.69324[0m[0m | time: 24.757s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.5166 -- iter: 0992/1395
[A[ATraining Step: 120  | total loss: [1m[32m0.69327[0m[0m | time: 25.781s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.5118 -- iter: 1024/1395
[A[ATraining Step: 121  | total loss: [1m[32m0.69323[0m[0m | time: 26.864s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.5137 -- iter: 1056/1395
[A[ATraining Step: 122  | total loss: [1m[32m0.69325[0m[0m | time: 27.963s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.5092 -- iter: 1088/1395
[A[ATraining Step: 123  | total loss: [1m[32m0.69321[0m[0m | time: 36.335s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.5114 -- iter: 1120/1395
[A[ATraining Step: 124  | total loss: [1m[32m0.69312[0m[0m | time: 42.960s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.5165 -- iter: 1152/1395
[A[ATraining Step: 125  | total loss: [1m[32m0.69308[0m[0m | time: 49.945s
[2K
| Adam | epoch: 003 | loss: 0.69308 - acc: 0.5180 -- iter: 1184/1395
[A[ATraining Step: 126  | total loss: [1m[32m0.69309[0m[0m | time: 57.471s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5162 -- iter: 1216/1395
[A[ATraining Step: 127  | total loss: [1m[32m0.69315[0m[0m | time: 63.573s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5083 -- iter: 1248/1395
[A[ATraining Step: 128  | total loss: [1m[32m0.69298[0m[0m | time: 75.147s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5200 -- iter: 1280/1395
[A[ATraining Step: 129  | total loss: [1m[32m0.69289[0m[0m | time: 91.732s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.5242 -- iter: 1312/1395
[A[ATraining Step: 130  | total loss: [1m[32m0.69294[0m[0m | time: 113.733s
[2K
| Adam | epoch: 003 | loss: 0.69294 - acc: 0.5187 -- iter: 1344/1395
[A[ATraining Step: 131  | total loss: [1m[32m0.69290[0m[0m | time: 124.072s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5200 -- iter: 1376/1395
[A[ATraining Step: 132  | total loss: [1m[32m0.69282[0m[0m | time: 159.263s
[2K
| Adam | epoch: 003 | loss: 0.69282 - acc: 0.5242 | val_loss: 0.69204 - val_acc: 0.5515 -- iter: 1395/1395
--
Training Step: 133  | total loss: [1m[32m0.69300[0m[0m | time: 1.138s
[2K
| Adam | epoch: 004 | loss: 0.69300 - acc: 0.5124 -- iter: 0032/1395
[A[ATraining Step: 134  | total loss: [1m[32m0.69305[0m[0m | time: 1.844s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5080 -- iter: 0064/1395
[A[ATraining Step: 135  | total loss: [1m[32m0.69280[0m[0m | time: 2.527s
[2K
| Adam | epoch: 004 | loss: 0.69280 - acc: 0.5204 -- iter: 0096/1395
[A[ATraining Step: 136  | total loss: [1m[32m0.69259[0m[0m | time: 3.522s
[2K
| Adam | epoch: 004 | loss: 0.69259 - acc: 0.5315 -- iter: 0128/1395
[A[ATraining Step: 137  | total loss: [1m[32m0.69271[0m[0m | time: 4.723s
[2K
| Adam | epoch: 004 | loss: 0.69271 - acc: 0.5252 -- iter: 0160/1395
[A[ATraining Step: 138  | total loss: [1m[32m0.69249[0m[0m | time: 5.914s
[2K
| Adam | epoch: 004 | loss: 0.69249 - acc: 0.5321 -- iter: 0192/1395
[A[ATraining Step: 139  | total loss: [1m[32m0.69267[0m[0m | time: 7.062s
[2K
| Adam | epoch: 004 | loss: 0.69267 - acc: 0.5226 -- iter: 0224/1395
[A[ATraining Step: 140  | total loss: [1m[32m0.69236[0m[0m | time: 8.197s
[2K
| Adam | epoch: 004 | loss: 0.69236 - acc: 0.5329 -- iter: 0256/1395
[A[ATraining Step: 141  | total loss: [1m[32m0.69203[0m[0m | time: 9.495s
[2K
| Adam | epoch: 004 | loss: 0.69203 - acc: 0.5421 -- iter: 0288/1395
[A[ATraining Step: 142  | total loss: [1m[32m0.69217[0m[0m | time: 11.072s
[2K
| Adam | epoch: 004 | loss: 0.69217 - acc: 0.5347 -- iter: 0320/1395
[A[ATraining Step: 143  | total loss: [1m[32m0.69220[0m[0m | time: 18.745s
[2K
| Adam | epoch: 004 | loss: 0.69220 - acc: 0.5313 -- iter: 0352/1395
[A[ATraining Step: 144  | total loss: [1m[32m0.69224[0m[0m | time: 31.030s
[2K
| Adam | epoch: 004 | loss: 0.69224 - acc: 0.5250 -- iter: 0384/1395
[A[ATraining Step: 145  | total loss: [1m[32m0.69273[0m[0m | time: 35.001s
[2K
| Adam | epoch: 004 | loss: 0.69273 - acc: 0.5006 -- iter: 0416/1395
[A[ATraining Step: 146  | total loss: [1m[32m0.69261[0m[0m | time: 48.438s
[2K
| Adam | epoch: 004 | loss: 0.69261 - acc: 0.5037 -- iter: 0448/1395
[A[ATraining Step: 147  | total loss: [1m[32m0.69258[0m[0m | time: 57.463s
[2K
| Adam | epoch: 004 | loss: 0.69258 - acc: 0.5221 -- iter: 0480/1395
[A[ATraining Step: 148  | total loss: [1m[32m0.69254[0m[0m | time: 62.962s
[2K
| Adam | epoch: 004 | loss: 0.69254 - acc: 0.5355 -- iter: 0512/1395
[A[ATraining Step: 149  | total loss: [1m[32m0.69230[0m[0m | time: 70.409s
[2K
| Adam | epoch: 004 | loss: 0.69230 - acc: 0.5476 -- iter: 0544/1395
[A[ATraining Step: 150  | total loss: [1m[32m0.69216[0m[0m | time: 78.680s
[2K
| Adam | epoch: 004 | loss: 0.69216 - acc: 0.5491 -- iter: 0576/1395
[A[ATraining Step: 151  | total loss: [1m[32m0.69178[0m[0m | time: 84.488s
[2K
| Adam | epoch: 004 | loss: 0.69178 - acc: 0.5504 -- iter: 0608/1395
[A[ATraining Step: 152  | total loss: [1m[32m0.69105[0m[0m | time: 94.797s
[2K
| Adam | epoch: 004 | loss: 0.69105 - acc: 0.5579 -- iter: 0640/1395
[A[ATraining Step: 153  | total loss: [1m[32m0.69046[0m[0m | time: 101.842s
[2K
| Adam | epoch: 004 | loss: 0.69046 - acc: 0.5583 -- iter: 0672/1395
[A[ATraining Step: 154  | total loss: [1m[32m0.68954[0m[0m | time: 107.273s
[2K
| Adam | epoch: 004 | loss: 0.68954 - acc: 0.5619 -- iter: 0704/1395
[A[ATraining Step: 155  | total loss: [1m[32m0.68984[0m[0m | time: 111.065s
[2K
| Adam | epoch: 004 | loss: 0.68984 - acc: 0.5557 -- iter: 0736/1395
[A[ATraining Step: 156  | total loss: [1m[32m0.68939[0m[0m | time: 112.160s
[2K
| Adam | epoch: 004 | loss: 0.68939 - acc: 0.5564 -- iter: 0768/1395
[A[ATraining Step: 157  | total loss: [1m[32m0.69035[0m[0m | time: 113.289s
[2K
| Adam | epoch: 004 | loss: 0.69035 - acc: 0.5445 -- iter: 0800/1395
[A[ATraining Step: 158  | total loss: [1m[32m0.69095[0m[0m | time: 114.394s
[2K
| Adam | epoch: 004 | loss: 0.69095 - acc: 0.5338 -- iter: 0832/1395
[A[ATraining Step: 159  | total loss: [1m[32m0.68930[0m[0m | time: 115.444s
[2K
| Adam | epoch: 004 | loss: 0.68930 - acc: 0.5554 -- iter: 0864/1395
[A[ATraining Step: 160  | total loss: [1m[32m0.68917[0m[0m | time: 116.574s
[2K
| Adam | epoch: 004 | loss: 0.68917 - acc: 0.5499 -- iter: 0896/1395
[A[ATraining Step: 161  | total loss: [1m[32m0.68823[0m[0m | time: 117.870s
[2K
| Adam | epoch: 004 | loss: 0.68823 - acc: 0.5605 -- iter: 0928/1395
[A[ATraining Step: 162  | total loss: [1m[32m0.68648[0m[0m | time: 119.027s
[2K
| Adam | epoch: 004 | loss: 0.68648 - acc: 0.5638 -- iter: 0960/1395
[A[ATraining Step: 163  | total loss: [1m[32m0.68453[0m[0m | time: 120.290s
[2K
| Adam | epoch: 004 | loss: 0.68453 - acc: 0.5731 -- iter: 0992/1395
[A[ATraining Step: 164  | total loss: [1m[32m0.68205[0m[0m | time: 121.631s
[2K
| Adam | epoch: 004 | loss: 0.68205 - acc: 0.5845 -- iter: 1024/1395
[A[ATraining Step: 165  | total loss: [1m[32m0.67976[0m[0m | time: 125.141s
[2K
| Adam | epoch: 004 | loss: 0.67976 - acc: 0.5886 -- iter: 1056/1395
[A[ATraining Step: 166  | total loss: [1m[32m0.67684[0m[0m | time: 130.621s
[2K
| Adam | epoch: 004 | loss: 0.67684 - acc: 0.5922 -- iter: 1088/1395
[A[ATraining Step: 167  | total loss: [1m[32m0.67557[0m[0m | time: 136.959s
[2K
| Adam | epoch: 004 | loss: 0.67557 - acc: 0.5986 -- iter: 1120/1395
[A[ATraining Step: 168  | total loss: [1m[32m0.66796[0m[0m | time: 143.094s
[2K
| Adam | epoch: 004 | loss: 0.66796 - acc: 0.6106 -- iter: 1152/1395
[A[ATraining Step: 169  | total loss: [1m[32m0.66548[0m[0m | time: 150.304s
[2K
| Adam | epoch: 004 | loss: 0.66548 - acc: 0.6058 -- iter: 1184/1395
[A[ATraining Step: 170  | total loss: [1m[32m0.66582[0m[0m | time: 152.468s
[2K
| Adam | epoch: 004 | loss: 0.66582 - acc: 0.6077 -- iter: 1216/1395
[A[ATraining Step: 171  | total loss: [1m[32m0.65105[0m[0m | time: 156.374s
[2K
| Adam | epoch: 004 | loss: 0.65105 - acc: 0.6251 -- iter: 1248/1395
[A[ATraining Step: 172  | total loss: [1m[32m0.64498[0m[0m | time: 157.572s
[2K
| Adam | epoch: 004 | loss: 0.64498 - acc: 0.6282 -- iter: 1280/1395
[A[ATraining Step: 173  | total loss: [1m[32m0.64758[0m[0m | time: 158.835s
[2K
| Adam | epoch: 004 | loss: 0.64758 - acc: 0.6279 -- iter: 1312/1395
[A[ATraining Step: 174  | total loss: [1m[32m0.63847[0m[0m | time: 159.857s
[2K
| Adam | epoch: 004 | loss: 0.63847 - acc: 0.6338 -- iter: 1344/1395
[A[ATraining Step: 175  | total loss: [1m[32m0.62787[0m[0m | time: 161.018s
[2K
| Adam | epoch: 004 | loss: 0.62787 - acc: 0.6392 -- iter: 1376/1395
[A[ATraining Step: 176  | total loss: [1m[32m0.62765[0m[0m | time: 165.410s
[2K
| Adam | epoch: 004 | loss: 0.62765 - acc: 0.6409 | val_loss: 0.55650 - val_acc: 0.7117 -- iter: 1395/1395
--
Training Step: 177  | total loss: [1m[32m0.61242[0m[0m | time: 1.289s
[2K
| Adam | epoch: 005 | loss: 0.61242 - acc: 0.6549 -- iter: 0032/1395
[A[ATraining Step: 178  | total loss: [1m[32m0.60792[0m[0m | time: 2.661s
[2K
| Adam | epoch: 005 | loss: 0.60792 - acc: 0.6613 -- iter: 0064/1395
[A[ATraining Step: 179  | total loss: [1m[32m0.59417[0m[0m | time: 7.592s
[2K
| Adam | epoch: 005 | loss: 0.59417 - acc: 0.6764 -- iter: 0096/1395
[A[ATraining Step: 180  | total loss: [1m[32m0.60172[0m[0m | time: 8.333s
[2K
| Adam | epoch: 005 | loss: 0.60172 - acc: 0.6720 -- iter: 0128/1395
[A[ATraining Step: 181  | total loss: [1m[32m0.60595[0m[0m | time: 9.431s
[2K
| Adam | epoch: 005 | loss: 0.60595 - acc: 0.6627 -- iter: 0160/1395
[A[ATraining Step: 182  | total loss: [1m[32m0.60401[0m[0m | time: 10.515s
[2K
| Adam | epoch: 005 | loss: 0.60401 - acc: 0.6651 -- iter: 0192/1395
[A[ATraining Step: 183  | total loss: [1m[32m0.58809[0m[0m | time: 11.678s
[2K
| Adam | epoch: 005 | loss: 0.58809 - acc: 0.6736 -- iter: 0224/1395
[A[ATraining Step: 184  | total loss: [1m[32m0.59353[0m[0m | time: 12.753s
[2K
| Adam | epoch: 005 | loss: 0.59353 - acc: 0.6656 -- iter: 0256/1395
[A[ATraining Step: 185  | total loss: [1m[32m0.58686[0m[0m | time: 13.888s
[2K
| Adam | epoch: 005 | loss: 0.58686 - acc: 0.6709 -- iter: 0288/1395
[A[ATraining Step: 186  | total loss: [1m[32m0.57139[0m[0m | time: 15.090s
[2K
| Adam | epoch: 005 | loss: 0.57139 - acc: 0.6851 -- iter: 0320/1395
[A[ATraining Step: 187  | total loss: [1m[32m0.58663[0m[0m | time: 16.143s
[2K
| Adam | epoch: 005 | loss: 0.58663 - acc: 0.6728 -- iter: 0352/1395
[A[ATraining Step: 188  | total loss: [1m[32m0.59570[0m[0m | time: 17.291s
[2K
| Adam | epoch: 005 | loss: 0.59570 - acc: 0.6649 -- iter: 0384/1395
[A[ATraining Step: 189  | total loss: [1m[32m0.59965[0m[0m | time: 18.527s
[2K
| Adam | epoch: 005 | loss: 0.59965 - acc: 0.6578 -- iter: 0416/1395
[A[ATraining Step: 190  | total loss: [1m[32m0.60510[0m[0m | time: 19.666s
[2K
| Adam | epoch: 005 | loss: 0.60510 - acc: 0.6577 -- iter: 0448/1395
[A[ATraining Step: 191  | total loss: [1m[32m0.60781[0m[0m | time: 20.603s
[2K
| Adam | epoch: 005 | loss: 0.60781 - acc: 0.6606 -- iter: 0480/1395
[A[ATraining Step: 192  | total loss: [1m[32m0.61050[0m[0m | time: 21.666s
[2K
| Adam | epoch: 005 | loss: 0.61050 - acc: 0.6602 -- iter: 0512/1395
[A[ATraining Step: 193  | total loss: [1m[32m0.60790[0m[0m | time: 22.811s
[2K
| Adam | epoch: 005 | loss: 0.60790 - acc: 0.6629 -- iter: 0544/1395
[A[ATraining Step: 194  | total loss: [1m[32m0.60477[0m[0m | time: 24.010s
[2K
| Adam | epoch: 005 | loss: 0.60477 - acc: 0.6748 -- iter: 0576/1395
[A[ATraining Step: 195  | total loss: [1m[32m0.60670[0m[0m | time: 25.054s
[2K
| Adam | epoch: 005 | loss: 0.60670 - acc: 0.6792 -- iter: 0608/1395
[A[ATraining Step: 196  | total loss: [1m[32m0.60148[0m[0m | time: 26.359s
[2K
| Adam | epoch: 005 | loss: 0.60148 - acc: 0.6894 -- iter: 0640/1395
[A[ATraining Step: 197  | total loss: [1m[32m0.59704[0m[0m | time: 27.609s
[2K
| Adam | epoch: 005 | loss: 0.59704 - acc: 0.6954 -- iter: 0672/1395
[A[ATraining Step: 198  | total loss: [1m[32m0.59636[0m[0m | time: 28.698s
[2K
| Adam | epoch: 005 | loss: 0.59636 - acc: 0.6946 -- iter: 0704/1395
[A[ATraining Step: 199  | total loss: [1m[32m0.58261[0m[0m | time: 29.796s
[2K
| Adam | epoch: 005 | loss: 0.58261 - acc: 0.7064 -- iter: 0736/1395
[A[ATraining Step: 200  | total loss: [1m[32m0.57120[0m[0m | time: 56.663s
[2K
| Adam | epoch: 005 | loss: 0.57120 - acc: 0.7264 | val_loss: 0.51175 - val_acc: 0.7826 -- iter: 0768/1395
--
Training Step: 201  | total loss: [1m[32m0.56080[0m[0m | time: 57.893s
[2K
| Adam | epoch: 005 | loss: 0.56080 - acc: 0.7381 -- iter: 0800/1395
[A[ATraining Step: 202  | total loss: [1m[32m0.55203[0m[0m | time: 58.989s
[2K
| Adam | epoch: 005 | loss: 0.55203 - acc: 0.7456 -- iter: 0832/1395
[A[ATraining Step: 203  | total loss: [1m[32m0.55339[0m[0m | time: 60.103s
[2K
| Adam | epoch: 005 | loss: 0.55339 - acc: 0.7491 -- iter: 0864/1395
[A[ATraining Step: 204  | total loss: [1m[32m0.53871[0m[0m | time: 61.180s
[2K
| Adam | epoch: 005 | loss: 0.53871 - acc: 0.7524 -- iter: 0896/1395
[A[ATraining Step: 205  | total loss: [1m[32m0.53945[0m[0m | time: 62.407s
[2K
| Adam | epoch: 005 | loss: 0.53945 - acc: 0.7521 -- iter: 0928/1395
[A[ATraining Step: 206  | total loss: [1m[32m0.55043[0m[0m | time: 63.561s
[2K
| Adam | epoch: 005 | loss: 0.55043 - acc: 0.7425 -- iter: 0960/1395
[A[ATraining Step: 207  | total loss: [1m[32m0.54233[0m[0m | time: 64.566s
[2K
| Adam | epoch: 005 | loss: 0.54233 - acc: 0.7589 -- iter: 0992/1395
[A[ATraining Step: 208  | total loss: [1m[32m0.55675[0m[0m | time: 65.664s
[2K
| Adam | epoch: 005 | loss: 0.55675 - acc: 0.7424 -- iter: 1024/1395
[A[ATraining Step: 209  | total loss: [1m[32m0.56816[0m[0m | time: 66.906s
[2K
| Adam | epoch: 005 | loss: 0.56816 - acc: 0.7307 -- iter: 1056/1395
[A[ATraining Step: 210  | total loss: [1m[32m0.55581[0m[0m | time: 68.116s
[2K
| Adam | epoch: 005 | loss: 0.55581 - acc: 0.7357 -- iter: 1088/1395
[A[ATraining Step: 211  | total loss: [1m[32m0.54950[0m[0m | time: 70.892s
[2K
| Adam | epoch: 005 | loss: 0.54950 - acc: 0.7340 -- iter: 1120/1395
[A[ATraining Step: 212  | total loss: [1m[32m0.55414[0m[0m | time: 73.242s
[2K
| Adam | epoch: 005 | loss: 0.55414 - acc: 0.7387 -- iter: 1152/1395
[A[ATraining Step: 213  | total loss: [1m[32m0.56325[0m[0m | time: 74.308s
[2K
| Adam | epoch: 005 | loss: 0.56325 - acc: 0.7367 -- iter: 1184/1395
[A[ATraining Step: 214  | total loss: [1m[32m0.55667[0m[0m | time: 75.526s
[2K
| Adam | epoch: 005 | loss: 0.55667 - acc: 0.7349 -- iter: 1216/1395
[A[ATraining Step: 215  | total loss: [1m[32m0.55083[0m[0m | time: 76.719s
[2K
| Adam | epoch: 005 | loss: 0.55083 - acc: 0.7364 -- iter: 1248/1395
[A[ATraining Step: 216  | total loss: [1m[32m0.54705[0m[0m | time: 77.928s
[2K
| Adam | epoch: 005 | loss: 0.54705 - acc: 0.7316 -- iter: 1280/1395
[A[ATraining Step: 217  | total loss: [1m[32m0.57661[0m[0m | time: 79.109s
[2K
| Adam | epoch: 005 | loss: 0.57661 - acc: 0.7084 -- iter: 1312/1395
[A[ATraining Step: 218  | total loss: [1m[32m0.58150[0m[0m | time: 80.217s
[2K
| Adam | epoch: 005 | loss: 0.58150 - acc: 0.6907 -- iter: 1344/1395
[A[ATraining Step: 219  | total loss: [1m[32m0.56394[0m[0m | time: 81.341s
[2K
| Adam | epoch: 005 | loss: 0.56394 - acc: 0.7029 -- iter: 1376/1395
[A[ATraining Step: 220  | total loss: [1m[32m0.55488[0m[0m | time: 90.174s
[2K
| Adam | epoch: 005 | loss: 0.55488 - acc: 0.7138 | val_loss: 0.54018 - val_acc: 0.7391 -- iter: 1395/1395
--
Training Step: 221  | total loss: [1m[32m0.54211[0m[0m | time: 1.163s
[2K
| Adam | epoch: 006 | loss: 0.54211 - acc: 0.7299 -- iter: 0032/1395
[A[ATraining Step: 222  | total loss: [1m[32m0.54744[0m[0m | time: 2.358s
[2K
| Adam | epoch: 006 | loss: 0.54744 - acc: 0.7257 -- iter: 0064/1395
[A[ATraining Step: 223  | total loss: [1m[32m0.53639[0m[0m | time: 3.494s
[2K
| Adam | epoch: 006 | loss: 0.53639 - acc: 0.7344 -- iter: 0096/1395
[A[ATraining Step: 224  | total loss: [1m[32m0.53624[0m[0m | time: 4.173s
[2K
| Adam | epoch: 006 | loss: 0.53624 - acc: 0.7328 -- iter: 0128/1395
[A[ATraining Step: 225  | total loss: [1m[32m0.51775[0m[0m | time: 4.953s
[2K
| Adam | epoch: 006 | loss: 0.51775 - acc: 0.7490 -- iter: 0160/1395
[A[ATraining Step: 226  | total loss: [1m[32m0.50517[0m[0m | time: 5.971s
[2K
| Adam | epoch: 006 | loss: 0.50517 - acc: 0.7478 -- iter: 0192/1395
[A[ATraining Step: 227  | total loss: [1m[32m0.50423[0m[0m | time: 7.222s
[2K
| Adam | epoch: 006 | loss: 0.50423 - acc: 0.7449 -- iter: 0224/1395
[A[ATraining Step: 228  | total loss: [1m[32m0.48638[0m[0m | time: 8.341s
[2K
| Adam | epoch: 006 | loss: 0.48638 - acc: 0.7579 -- iter: 0256/1395
[A[ATraining Step: 229  | total loss: [1m[32m0.49779[0m[0m | time: 9.662s
[2K
| Adam | epoch: 006 | loss: 0.49779 - acc: 0.7446 -- iter: 0288/1395
[A[ATraining Step: 230  | total loss: [1m[32m0.49705[0m[0m | time: 10.904s
[2K
| Adam | epoch: 006 | loss: 0.49705 - acc: 0.7545 -- iter: 0320/1395
[A[ATraining Step: 231  | total loss: [1m[32m0.50150[0m[0m | time: 15.566s
[2K
| Adam | epoch: 006 | loss: 0.50150 - acc: 0.7541 -- iter: 0352/1395
[A[ATraining Step: 232  | total loss: [1m[32m0.48627[0m[0m | time: 20.296s
[2K
| Adam | epoch: 006 | loss: 0.48627 - acc: 0.7630 -- iter: 0384/1395
[A[ATraining Step: 233  | total loss: [1m[32m0.49160[0m[0m | time: 23.984s
[2K
| Adam | epoch: 006 | loss: 0.49160 - acc: 0.7649 -- iter: 0416/1395
[A[ATraining Step: 234  | total loss: [1m[32m0.48330[0m[0m | time: 33.186s
[2K
| Adam | epoch: 006 | loss: 0.48330 - acc: 0.7727 -- iter: 0448/1395
[A[ATraining Step: 235  | total loss: [1m[32m0.48832[0m[0m | time: 35.465s
[2K
| Adam | epoch: 006 | loss: 0.48832 - acc: 0.7673 -- iter: 0480/1395
[A[ATraining Step: 236  | total loss: [1m[32m0.48106[0m[0m | time: 36.628s
[2K
| Adam | epoch: 006 | loss: 0.48106 - acc: 0.7719 -- iter: 0512/1395
[A[ATraining Step: 237  | total loss: [1m[32m0.49347[0m[0m | time: 37.761s
[2K
| Adam | epoch: 006 | loss: 0.49347 - acc: 0.7634 -- iter: 0544/1395
[A[ATraining Step: 238  | total loss: [1m[32m0.46858[0m[0m | time: 38.923s
[2K
| Adam | epoch: 006 | loss: 0.46858 - acc: 0.7871 -- iter: 0576/1395
[A[ATraining Step: 239  | total loss: [1m[32m0.47196[0m[0m | time: 40.085s
[2K
| Adam | epoch: 006 | loss: 0.47196 - acc: 0.7803 -- iter: 0608/1395
[A[ATraining Step: 240  | total loss: [1m[32m0.46195[0m[0m | time: 41.363s
[2K
| Adam | epoch: 006 | loss: 0.46195 - acc: 0.7866 -- iter: 0640/1395
[A[ATraining Step: 241  | total loss: [1m[32m0.46802[0m[0m | time: 42.657s
[2K
| Adam | epoch: 006 | loss: 0.46802 - acc: 0.7798 -- iter: 0672/1395
[A[ATraining Step: 242  | total loss: [1m[32m0.44824[0m[0m | time: 43.755s
[2K
| Adam | epoch: 006 | loss: 0.44824 - acc: 0.7925 -- iter: 0704/1395
[A[ATraining Step: 243  | total loss: [1m[32m0.44836[0m[0m | time: 45.028s
[2K
| Adam | epoch: 006 | loss: 0.44836 - acc: 0.7913 -- iter: 0736/1395
[A[ATraining Step: 244  | total loss: [1m[32m0.44580[0m[0m | time: 46.365s
[2K
| Adam | epoch: 006 | loss: 0.44580 - acc: 0.7997 -- iter: 0768/1395
[A[ATraining Step: 245  | total loss: [1m[32m0.42672[0m[0m | time: 50.352s
[2K
| Adam | epoch: 006 | loss: 0.42672 - acc: 0.8135 -- iter: 0800/1395
[A[ATraining Step: 246  | total loss: [1m[32m0.41240[0m[0m | time: 53.229s
[2K
| Adam | epoch: 006 | loss: 0.41240 - acc: 0.8196 -- iter: 0832/1395
[A[ATraining Step: 247  | total loss: [1m[32m0.41322[0m[0m | time: 61.053s
[2K
| Adam | epoch: 006 | loss: 0.41322 - acc: 0.8220 -- iter: 0864/1395
[A[ATraining Step: 248  | total loss: [1m[32m0.42264[0m[0m | time: 69.816s
[2K
| Adam | epoch: 006 | loss: 0.42264 - acc: 0.8211 -- iter: 0896/1395
[A[ATraining Step: 249  | total loss: [1m[32m0.41112[0m[0m | time: 74.787s
[2K
| Adam | epoch: 006 | loss: 0.41112 - acc: 0.8265 -- iter: 0928/1395
[A[ATraining Step: 250  | total loss: [1m[32m0.40071[0m[0m | time: 80.057s
[2K
| Adam | epoch: 006 | loss: 0.40071 - acc: 0.8251 -- iter: 0960/1395
[A[ATraining Step: 251  | total loss: [1m[32m0.39608[0m[0m | time: 81.198s
[2K
| Adam | epoch: 006 | loss: 0.39608 - acc: 0.8301 -- iter: 0992/1395
[A[ATraining Step: 252  | total loss: [1m[32m0.41636[0m[0m | time: 82.311s
[2K
| Adam | epoch: 006 | loss: 0.41636 - acc: 0.8252 -- iter: 1024/1395
[A[ATraining Step: 253  | total loss: [1m[32m0.41077[0m[0m | time: 83.354s
[2K
| Adam | epoch: 006 | loss: 0.41077 - acc: 0.8270 -- iter: 1056/1395
[A[ATraining Step: 254  | total loss: [1m[32m0.40211[0m[0m | time: 84.570s
[2K
| Adam | epoch: 006 | loss: 0.40211 - acc: 0.8318 -- iter: 1088/1395
[A[ATraining Step: 255  | total loss: [1m[32m0.39587[0m[0m | time: 85.643s
[2K
| Adam | epoch: 006 | loss: 0.39587 - acc: 0.8330 -- iter: 1120/1395
[A[ATraining Step: 256  | total loss: [1m[32m0.40987[0m[0m | time: 86.813s
[2K
| Adam | epoch: 006 | loss: 0.40987 - acc: 0.8279 -- iter: 1152/1395
[A[ATraining Step: 257  | total loss: [1m[32m0.43231[0m[0m | time: 87.983s
[2K
| Adam | epoch: 006 | loss: 0.43231 - acc: 0.8076 -- iter: 1184/1395
[A[ATraining Step: 258  | total loss: [1m[32m0.44782[0m[0m | time: 89.150s
[2K
| Adam | epoch: 006 | loss: 0.44782 - acc: 0.7987 -- iter: 1216/1395
[A[ATraining Step: 259  | total loss: [1m[32m0.45113[0m[0m | time: 90.333s
[2K
| Adam | epoch: 006 | loss: 0.45113 - acc: 0.7969 -- iter: 1248/1395
[A[ATraining Step: 260  | total loss: [1m[32m0.45762[0m[0m | time: 91.580s
[2K
| Adam | epoch: 006 | loss: 0.45762 - acc: 0.7954 -- iter: 1280/1395
[A[ATraining Step: 261  | total loss: [1m[32m0.45134[0m[0m | time: 92.671s
[2K
| Adam | epoch: 006 | loss: 0.45134 - acc: 0.8033 -- iter: 1312/1395
[A[ATraining Step: 262  | total loss: [1m[32m0.45956[0m[0m | time: 93.754s
[2K
| Adam | epoch: 006 | loss: 0.45956 - acc: 0.8043 -- iter: 1344/1395
[A[ATraining Step: 263  | total loss: [1m[32m0.44732[0m[0m | time: 94.932s
[2K
| Adam | epoch: 006 | loss: 0.44732 - acc: 0.8145 -- iter: 1376/1395
[A[ATraining Step: 264  | total loss: [1m[32m0.44744[0m[0m | time: 99.349s
[2K
| Adam | epoch: 006 | loss: 0.44744 - acc: 0.8205 | val_loss: 0.58395 - val_acc: 0.7002 -- iter: 1395/1395
--
Training Step: 265  | total loss: [1m[32m0.46363[0m[0m | time: 1.158s
[2K
| Adam | epoch: 007 | loss: 0.46363 - acc: 0.8166 -- iter: 0032/1395
[A[ATraining Step: 266  | total loss: [1m[32m0.47259[0m[0m | time: 2.406s
[2K
| Adam | epoch: 007 | loss: 0.47259 - acc: 0.8005 -- iter: 0064/1395
[A[ATraining Step: 267  | total loss: [1m[32m0.47273[0m[0m | time: 3.630s
[2K
| Adam | epoch: 007 | loss: 0.47273 - acc: 0.7924 -- iter: 0096/1395
[A[ATraining Step: 268  | total loss: [1m[32m0.45315[0m[0m | time: 5.060s
[2K
| Adam | epoch: 007 | loss: 0.45315 - acc: 0.8038 -- iter: 0128/1395
[A[ATraining Step: 269  | total loss: [1m[32m0.46099[0m[0m | time: 5.684s
[2K
| Adam | epoch: 007 | loss: 0.46099 - acc: 0.7953 -- iter: 0160/1395
[A[ATraining Step: 270  | total loss: [1m[32m0.45187[0m[0m | time: 6.275s
[2K
| Adam | epoch: 007 | loss: 0.45187 - acc: 0.7999 -- iter: 0192/1395
[A[ATraining Step: 271  | total loss: [1m[32m0.44510[0m[0m | time: 7.392s
[2K
| Adam | epoch: 007 | loss: 0.44510 - acc: 0.7989 -- iter: 0224/1395
[A[ATraining Step: 272  | total loss: [1m[32m0.45672[0m[0m | time: 8.611s
[2K
| Adam | epoch: 007 | loss: 0.45672 - acc: 0.7878 -- iter: 0256/1395
[A[ATraining Step: 273  | total loss: [1m[32m0.46787[0m[0m | time: 9.706s
[2K
| Adam | epoch: 007 | loss: 0.46787 - acc: 0.7840 -- iter: 0288/1395
[A[ATraining Step: 274  | total loss: [1m[32m0.46199[0m[0m | time: 10.901s
[2K
| Adam | epoch: 007 | loss: 0.46199 - acc: 0.7931 -- iter: 0320/1395
[A[ATraining Step: 275  | total loss: [1m[32m0.45256[0m[0m | time: 12.170s
[2K
| Adam | epoch: 007 | loss: 0.45256 - acc: 0.7981 -- iter: 0352/1395
[A[ATraining Step: 276  | total loss: [1m[32m0.43781[0m[0m | time: 13.289s
[2K
| Adam | epoch: 007 | loss: 0.43781 - acc: 0.8058 -- iter: 0384/1395
[A[ATraining Step: 277  | total loss: [1m[32m0.45834[0m[0m | time: 14.370s
[2K
| Adam | epoch: 007 | loss: 0.45834 - acc: 0.7971 -- iter: 0416/1395
[A[ATraining Step: 278  | total loss: [1m[32m0.46332[0m[0m | time: 15.591s
[2K
| Adam | epoch: 007 | loss: 0.46332 - acc: 0.7955 -- iter: 0448/1395
[A[ATraining Step: 279  | total loss: [1m[32m0.46009[0m[0m | time: 16.832s
[2K
| Adam | epoch: 007 | loss: 0.46009 - acc: 0.7941 -- iter: 0480/1395
[A[ATraining Step: 280  | total loss: [1m[32m0.47232[0m[0m | time: 17.835s
[2K
| Adam | epoch: 007 | loss: 0.47232 - acc: 0.7928 -- iter: 0512/1395
[A[ATraining Step: 281  | total loss: [1m[32m0.45673[0m[0m | time: 18.818s
[2K
| Adam | epoch: 007 | loss: 0.45673 - acc: 0.8042 -- iter: 0544/1395
[A[ATraining Step: 282  | total loss: [1m[32m0.45150[0m[0m | time: 19.977s
[2K
| Adam | epoch: 007 | loss: 0.45150 - acc: 0.8112 -- iter: 0576/1395
[A[ATraining Step: 283  | total loss: [1m[32m0.44833[0m[0m | time: 21.066s
[2K
| Adam | epoch: 007 | loss: 0.44833 - acc: 0.8145 -- iter: 0608/1395
[A[ATraining Step: 284  | total loss: [1m[32m0.43421[0m[0m | time: 22.206s
[2K
| Adam | epoch: 007 | loss: 0.43421 - acc: 0.8268 -- iter: 0640/1395
[A[ATraining Step: 285  | total loss: [1m[32m0.42818[0m[0m | time: 23.475s
[2K
| Adam | epoch: 007 | loss: 0.42818 - acc: 0.8222 -- iter: 0672/1395
[A[ATraining Step: 286  | total loss: [1m[32m0.41891[0m[0m | time: 24.693s
[2K
| Adam | epoch: 007 | loss: 0.41891 - acc: 0.8306 -- iter: 0704/1395
[A[ATraining Step: 287  | total loss: [1m[32m0.42677[0m[0m | time: 25.840s
[2K
| Adam | epoch: 007 | loss: 0.42677 - acc: 0.8195 -- iter: 0736/1395
[A[ATraining Step: 288  | total loss: [1m[32m0.41846[0m[0m | time: 27.090s
[2K
| Adam | epoch: 007 | loss: 0.41846 - acc: 0.8219 -- iter: 0768/1395
[A[ATraining Step: 289  | total loss: [1m[32m0.39960[0m[0m | time: 28.308s
[2K
| Adam | epoch: 007 | loss: 0.39960 - acc: 0.8303 -- iter: 0800/1395
[A[ATraining Step: 290  | total loss: [1m[32m0.38943[0m[0m | time: 29.506s
[2K
| Adam | epoch: 007 | loss: 0.38943 - acc: 0.8379 -- iter: 0832/1395
[A[ATraining Step: 291  | total loss: [1m[32m0.38695[0m[0m | time: 33.140s
[2K
| Adam | epoch: 007 | loss: 0.38695 - acc: 0.8385 -- iter: 0864/1395
[A[ATraining Step: 292  | total loss: [1m[32m0.37324[0m[0m | time: 35.020s
[2K
| Adam | epoch: 007 | loss: 0.37324 - acc: 0.8484 -- iter: 0896/1395
[A[ATraining Step: 293  | total loss: [1m[32m0.37215[0m[0m | time: 41.751s
[2K
| Adam | epoch: 007 | loss: 0.37215 - acc: 0.8479 -- iter: 0928/1395
[A[ATraining Step: 294  | total loss: [1m[32m0.38216[0m[0m | time: 42.841s
[2K
| Adam | epoch: 007 | loss: 0.38216 - acc: 0.8444 -- iter: 0960/1395
[A[ATraining Step: 295  | total loss: [1m[32m0.36476[0m[0m | time: 43.962s
[2K
| Adam | epoch: 007 | loss: 0.36476 - acc: 0.8537 -- iter: 0992/1395
[A[ATraining Step: 296  | total loss: [1m[32m0.38089[0m[0m | time: 45.117s
[2K
| Adam | epoch: 007 | loss: 0.38089 - acc: 0.8402 -- iter: 1024/1395
[A[ATraining Step: 297  | total loss: [1m[32m0.38133[0m[0m | time: 46.331s
[2K
| Adam | epoch: 007 | loss: 0.38133 - acc: 0.8374 -- iter: 1056/1395
[A[ATraining Step: 298  | total loss: [1m[32m0.36489[0m[0m | time: 47.580s
[2K
| Adam | epoch: 007 | loss: 0.36489 - acc: 0.8443 -- iter: 1088/1395
[A[ATraining Step: 299  | total loss: [1m[32m0.39322[0m[0m | time: 48.785s
[2K
| Adam | epoch: 007 | loss: 0.39322 - acc: 0.8318 -- iter: 1120/1395
[A[ATraining Step: 300  | total loss: [1m[32m0.38152[0m[0m | time: 49.931s
[2K
| Adam | epoch: 007 | loss: 0.38152 - acc: 0.8392 -- iter: 1152/1395
[A[ATraining Step: 301  | total loss: [1m[32m0.38551[0m[0m | time: 51.236s
[2K
| Adam | epoch: 007 | loss: 0.38551 - acc: 0.8365 -- iter: 1184/1395
[A[ATraining Step: 302  | total loss: [1m[32m0.37423[0m[0m | time: 52.516s
[2K
| Adam | epoch: 007 | loss: 0.37423 - acc: 0.8498 -- iter: 1216/1395
[A[ATraining Step: 303  | total loss: [1m[32m0.36755[0m[0m | time: 53.738s
[2K
| Adam | epoch: 007 | loss: 0.36755 - acc: 0.8523 -- iter: 1248/1395
[A[ATraining Step: 304  | total loss: [1m[32m0.36883[0m[0m | time: 54.958s
[2K
| Adam | epoch: 007 | loss: 0.36883 - acc: 0.8514 -- iter: 1280/1395
[A[ATraining Step: 305  | total loss: [1m[32m0.36724[0m[0m | time: 56.137s
[2K
| Adam | epoch: 007 | loss: 0.36724 - acc: 0.8507 -- iter: 1312/1395
[A[ATraining Step: 306  | total loss: [1m[32m0.37209[0m[0m | time: 57.388s
[2K
| Adam | epoch: 007 | loss: 0.37209 - acc: 0.8500 -- iter: 1344/1395
[A[ATraining Step: 307  | total loss: [1m[32m0.36879[0m[0m | time: 58.680s
[2K
| Adam | epoch: 007 | loss: 0.36879 - acc: 0.8493 -- iter: 1376/1395
[A[ATraining Step: 308  | total loss: [1m[32m0.37459[0m[0m | time: 62.353s
[2K
| Adam | epoch: 007 | loss: 0.37459 - acc: 0.8457 | val_loss: 0.52703 - val_acc: 0.7666 -- iter: 1395/1395
--
Training Step: 309  | total loss: [1m[32m0.36783[0m[0m | time: 0.769s
[2K
| Adam | epoch: 008 | loss: 0.36783 - acc: 0.8455 -- iter: 0032/1395
[A[ATraining Step: 310  | total loss: [1m[32m0.37154[0m[0m | time: 1.624s
[2K
| Adam | epoch: 008 | loss: 0.37154 - acc: 0.8359 -- iter: 0064/1395
[A[ATraining Step: 311  | total loss: [1m[32m0.36767[0m[0m | time: 2.394s
[2K
| Adam | epoch: 008 | loss: 0.36767 - acc: 0.8398 -- iter: 0096/1395
[A[ATraining Step: 312  | total loss: [1m[32m0.37250[0m[0m | time: 3.255s
[2K
| Adam | epoch: 008 | loss: 0.37250 - acc: 0.8402 -- iter: 0128/1395
[A[ATraining Step: 313  | total loss: [1m[32m0.37279[0m[0m | time: 4.054s
[2K
| Adam | epoch: 008 | loss: 0.37279 - acc: 0.8375 -- iter: 0160/1395
[A[ATraining Step: 314  | total loss: [1m[32m0.39258[0m[0m | time: 4.562s
[2K
| Adam | epoch: 008 | loss: 0.39258 - acc: 0.8287 -- iter: 0192/1395
[A[ATraining Step: 315  | total loss: [1m[32m0.37898[0m[0m | time: 5.076s
[2K
| Adam | epoch: 008 | loss: 0.37898 - acc: 0.8353 -- iter: 0224/1395
[A[ATraining Step: 316  | total loss: [1m[32m0.36564[0m[0m | time: 5.819s
[2K
| Adam | epoch: 008 | loss: 0.36564 - acc: 0.8413 -- iter: 0256/1395
[A[ATraining Step: 317  | total loss: [1m[32m0.37745[0m[0m | time: 6.682s
[2K
| Adam | epoch: 008 | loss: 0.37745 - acc: 0.8384 -- iter: 0288/1395
[A[ATraining Step: 318  | total loss: [1m[32m0.37668[0m[0m | time: 7.582s
[2K
| Adam | epoch: 008 | loss: 0.37668 - acc: 0.8389 -- iter: 0320/1395
[A[ATraining Step: 319  | total loss: [1m[32m0.37378[0m[0m | time: 8.450s
[2K
| Adam | epoch: 008 | loss: 0.37378 - acc: 0.8425 -- iter: 0352/1395
[A[ATraining Step: 320  | total loss: [1m[32m0.38127[0m[0m | time: 9.275s
[2K
| Adam | epoch: 008 | loss: 0.38127 - acc: 0.8364 -- iter: 0384/1395
[A[ATraining Step: 321  | total loss: [1m[32m0.38687[0m[0m | time: 10.079s
[2K
| Adam | epoch: 008 | loss: 0.38687 - acc: 0.8309 -- iter: 0416/1395
[A[ATraining Step: 322  | total loss: [1m[32m0.39623[0m[0m | time: 10.917s
[2K
| Adam | epoch: 008 | loss: 0.39623 - acc: 0.8197 -- iter: 0448/1395
[A[ATraining Step: 323  | total loss: [1m[32m0.38776[0m[0m | time: 11.727s
[2K
| Adam | epoch: 008 | loss: 0.38776 - acc: 0.8283 -- iter: 0480/1395
[A[ATraining Step: 324  | total loss: [1m[32m0.38213[0m[0m | time: 12.590s
[2K
| Adam | epoch: 008 | loss: 0.38213 - acc: 0.8330 -- iter: 0512/1395
[A[ATraining Step: 325  | total loss: [1m[32m0.36709[0m[0m | time: 13.395s
[2K
| Adam | epoch: 008 | loss: 0.36709 - acc: 0.8403 -- iter: 0544/1395
[A[ATraining Step: 326  | total loss: [1m[32m0.36380[0m[0m | time: 14.234s
[2K
| Adam | epoch: 008 | loss: 0.36380 - acc: 0.8469 -- iter: 0576/1395
[A[ATraining Step: 327  | total loss: [1m[32m0.36065[0m[0m | time: 15.064s
[2K
| Adam | epoch: 008 | loss: 0.36065 - acc: 0.8528 -- iter: 0608/1395
[A[ATraining Step: 328  | total loss: [1m[32m0.38758[0m[0m | time: 15.823s
[2K
| Adam | epoch: 008 | loss: 0.38758 - acc: 0.8426 -- iter: 0640/1395
[A[ATraining Step: 329  | total loss: [1m[32m0.38877[0m[0m | time: 16.691s
[2K
| Adam | epoch: 008 | loss: 0.38877 - acc: 0.8458 -- iter: 0672/1395
[A[ATraining Step: 330  | total loss: [1m[32m0.38226[0m[0m | time: 17.678s
[2K
| Adam | epoch: 008 | loss: 0.38226 - acc: 0.8456 -- iter: 0704/1395
[A[ATraining Step: 331  | total loss: [1m[32m0.37731[0m[0m | time: 18.624s
[2K
| Adam | epoch: 008 | loss: 0.37731 - acc: 0.8454 -- iter: 0736/1395
[A[ATraining Step: 332  | total loss: [1m[32m0.37329[0m[0m | time: 19.614s
[2K
| Adam | epoch: 008 | loss: 0.37329 - acc: 0.8484 -- iter: 0768/1395
[A[ATraining Step: 333  | total loss: [1m[32m0.38323[0m[0m | time: 20.632s
[2K
| Adam | epoch: 008 | loss: 0.38323 - acc: 0.8479 -- iter: 0800/1395
[A[ATraining Step: 334  | total loss: [1m[32m0.38279[0m[0m | time: 21.657s
[2K
| Adam | epoch: 008 | loss: 0.38279 - acc: 0.8475 -- iter: 0832/1395
[A[ATraining Step: 335  | total loss: [1m[32m0.36868[0m[0m | time: 22.702s
[2K
| Adam | epoch: 008 | loss: 0.36868 - acc: 0.8534 -- iter: 0864/1395
[A[ATraining Step: 336  | total loss: [1m[32m0.35509[0m[0m | time: 23.825s
[2K
| Adam | epoch: 008 | loss: 0.35509 - acc: 0.8587 -- iter: 0896/1395
[A[ATraining Step: 337  | total loss: [1m[32m0.34942[0m[0m | time: 25.061s
[2K
| Adam | epoch: 008 | loss: 0.34942 - acc: 0.8603 -- iter: 0928/1395
[A[ATraining Step: 338  | total loss: [1m[32m0.34766[0m[0m | time: 26.276s
[2K
| Adam | epoch: 008 | loss: 0.34766 - acc: 0.8618 -- iter: 0960/1395
[A[ATraining Step: 339  | total loss: [1m[32m0.34358[0m[0m | time: 30.186s
[2K
| Adam | epoch: 008 | loss: 0.34358 - acc: 0.8662 -- iter: 0992/1395
[A[ATraining Step: 340  | total loss: [1m[32m0.34456[0m[0m | time: 31.277s
[2K
| Adam | epoch: 008 | loss: 0.34456 - acc: 0.8671 -- iter: 1024/1395
[A[ATraining Step: 341  | total loss: [1m[32m0.32717[0m[0m | time: 32.405s
[2K
| Adam | epoch: 008 | loss: 0.32717 - acc: 0.8773 -- iter: 1056/1395
[A[ATraining Step: 342  | total loss: [1m[32m0.32249[0m[0m | time: 33.482s
[2K
| Adam | epoch: 008 | loss: 0.32249 - acc: 0.8802 -- iter: 1088/1395
[A[ATraining Step: 343  | total loss: [1m[32m0.32583[0m[0m | time: 34.866s
[2K
| Adam | epoch: 008 | loss: 0.32583 - acc: 0.8796 -- iter: 1120/1395
[A[ATraining Step: 344  | total loss: [1m[32m0.32192[0m[0m | time: 36.200s
[2K
| Adam | epoch: 008 | loss: 0.32192 - acc: 0.8854 -- iter: 1152/1395
[A[ATraining Step: 345  | total loss: [1m[32m0.32259[0m[0m | time: 37.314s
[2K
| Adam | epoch: 008 | loss: 0.32259 - acc: 0.8813 -- iter: 1184/1395
[A[ATraining Step: 346  | total loss: [1m[32m0.30495[0m[0m | time: 38.507s
[2K
| Adam | epoch: 008 | loss: 0.30495 - acc: 0.8900 -- iter: 1216/1395
[A[ATraining Step: 347  | total loss: [1m[32m0.30722[0m[0m | time: 39.602s
[2K
| Adam | epoch: 008 | loss: 0.30722 - acc: 0.8916 -- iter: 1248/1395
[A[ATraining Step: 348  | total loss: [1m[32m0.31770[0m[0m | time: 40.998s
[2K
| Adam | epoch: 008 | loss: 0.31770 - acc: 0.8900 -- iter: 1280/1395
[A[ATraining Step: 349  | total loss: [1m[32m0.33324[0m[0m | time: 42.309s
[2K
| Adam | epoch: 008 | loss: 0.33324 - acc: 0.8853 -- iter: 1312/1395
[A[ATraining Step: 350  | total loss: [1m[32m0.33111[0m[0m | time: 43.659s
[2K
| Adam | epoch: 008 | loss: 0.33111 - acc: 0.8843 -- iter: 1344/1395
[A[ATraining Step: 351  | total loss: [1m[32m0.33266[0m[0m | time: 47.890s
[2K
| Adam | epoch: 008 | loss: 0.33266 - acc: 0.8834 -- iter: 1376/1395
[A[ATraining Step: 352  | total loss: [1m[32m0.33373[0m[0m | time: 88.300s
[2K
| Adam | epoch: 008 | loss: 0.33373 - acc: 0.8857 | val_loss: 0.50933 - val_acc: 0.7735 -- iter: 1395/1395
--
Training Step: 353  | total loss: [1m[32m0.33102[0m[0m | time: 1.140s
[2K
| Adam | epoch: 009 | loss: 0.33102 - acc: 0.8846 -- iter: 0032/1395
[A[ATraining Step: 354  | total loss: [1m[32m0.31730[0m[0m | time: 2.336s
[2K
| Adam | epoch: 009 | loss: 0.31730 - acc: 0.8899 -- iter: 0064/1395
[A[ATraining Step: 355  | total loss: [1m[32m0.32597[0m[0m | time: 3.474s
[2K
| Adam | epoch: 009 | loss: 0.32597 - acc: 0.8884 -- iter: 0096/1395
[A[ATraining Step: 356  | total loss: [1m[32m0.31933[0m[0m | time: 4.734s
[2K
| Adam | epoch: 009 | loss: 0.31933 - acc: 0.8839 -- iter: 0128/1395
[A[ATraining Step: 357  | total loss: [1m[32m0.32400[0m[0m | time: 5.978s
[2K
| Adam | epoch: 009 | loss: 0.32400 - acc: 0.8768 -- iter: 0160/1395
[A[ATraining Step: 358  | total loss: [1m[32m0.32814[0m[0m | time: 7.091s
[2K
| Adam | epoch: 009 | loss: 0.32814 - acc: 0.8735 -- iter: 0192/1395
[A[ATraining Step: 359  | total loss: [1m[32m0.31995[0m[0m | time: 7.675s
[2K
| Adam | epoch: 009 | loss: 0.31995 - acc: 0.8799 -- iter: 0224/1395
[A[ATraining Step: 360  | total loss: [1m[32m0.30262[0m[0m | time: 8.470s
[2K
| Adam | epoch: 009 | loss: 0.30262 - acc: 0.8866 -- iter: 0256/1395
[A[ATraining Step: 361  | total loss: [1m[32m0.28418[0m[0m | time: 9.678s
[2K
| Adam | epoch: 009 | loss: 0.28418 - acc: 0.8927 -- iter: 0288/1395
[A[ATraining Step: 362  | total loss: [1m[32m0.27817[0m[0m | time: 10.872s
[2K
| Adam | epoch: 009 | loss: 0.27817 - acc: 0.8941 -- iter: 0320/1395
[A[ATraining Step: 363  | total loss: [1m[32m0.27149[0m[0m | time: 11.759s
[2K
| Adam | epoch: 009 | loss: 0.27149 - acc: 0.8953 -- iter: 0352/1395
[A[ATraining Step: 364  | total loss: [1m[32m0.28363[0m[0m | time: 12.832s
[2K
| Adam | epoch: 009 | loss: 0.28363 - acc: 0.8839 -- iter: 0384/1395
[A[ATraining Step: 365  | total loss: [1m[32m0.27329[0m[0m | time: 14.012s
[2K
| Adam | epoch: 009 | loss: 0.27329 - acc: 0.8830 -- iter: 0416/1395
[A[ATraining Step: 366  | total loss: [1m[32m0.26375[0m[0m | time: 15.124s
[2K
| Adam | epoch: 009 | loss: 0.26375 - acc: 0.8884 -- iter: 0448/1395
[A[ATraining Step: 367  | total loss: [1m[32m0.26667[0m[0m | time: 16.216s
[2K
| Adam | epoch: 009 | loss: 0.26667 - acc: 0.8840 -- iter: 0480/1395
[A[ATraining Step: 368  | total loss: [1m[32m0.28748[0m[0m | time: 17.450s
[2K
| Adam | epoch: 009 | loss: 0.28748 - acc: 0.8737 -- iter: 0512/1395
[A[ATraining Step: 369  | total loss: [1m[32m0.31563[0m[0m | time: 18.686s
[2K
| Adam | epoch: 009 | loss: 0.31563 - acc: 0.8582 -- iter: 0544/1395
[A[ATraining Step: 370  | total loss: [1m[32m0.32251[0m[0m | time: 19.815s
[2K
| Adam | epoch: 009 | loss: 0.32251 - acc: 0.8505 -- iter: 0576/1395
[A[ATraining Step: 371  | total loss: [1m[32m0.31261[0m[0m | time: 21.104s
[2K
| Adam | epoch: 009 | loss: 0.31261 - acc: 0.8592 -- iter: 0608/1395
[A[ATraining Step: 372  | total loss: [1m[32m0.29530[0m[0m | time: 22.287s
[2K
| Adam | epoch: 009 | loss: 0.29530 - acc: 0.8702 -- iter: 0640/1395
[A[ATraining Step: 373  | total loss: [1m[32m0.29979[0m[0m | time: 23.986s
[2K
| Adam | epoch: 009 | loss: 0.29979 - acc: 0.8738 -- iter: 0672/1395
[A[ATraining Step: 374  | total loss: [1m[32m0.28889[0m[0m | time: 31.232s
[2K
| Adam | epoch: 009 | loss: 0.28889 - acc: 0.8801 -- iter: 0704/1395
[A[ATraining Step: 375  | total loss: [1m[32m0.28168[0m[0m | time: 34.983s
[2K
| Adam | epoch: 009 | loss: 0.28168 - acc: 0.8890 -- iter: 0736/1395
[A[ATraining Step: 376  | total loss: [1m[32m0.27729[0m[0m | time: 40.739s
[2K
| Adam | epoch: 009 | loss: 0.27729 - acc: 0.8939 -- iter: 0768/1395
[A[ATraining Step: 377  | total loss: [1m[32m0.26821[0m[0m | time: 47.174s
[2K
| Adam | epoch: 009 | loss: 0.26821 - acc: 0.8982 -- iter: 0800/1395
[A[ATraining Step: 378  | total loss: [1m[32m0.25031[0m[0m | time: 51.081s
[2K
| Adam | epoch: 009 | loss: 0.25031 - acc: 0.9084 -- iter: 0832/1395
[A[ATraining Step: 379  | total loss: [1m[32m0.25662[0m[0m | time: 52.852s
[2K
| Adam | epoch: 009 | loss: 0.25662 - acc: 0.9082 -- iter: 0864/1395
[A[ATraining Step: 380  | total loss: [1m[32m0.26475[0m[0m | time: 53.790s
[2K
| Adam | epoch: 009 | loss: 0.26475 - acc: 0.9080 -- iter: 0896/1395
[A[ATraining Step: 381  | total loss: [1m[32m0.25882[0m[0m | time: 54.901s
[2K
| Adam | epoch: 009 | loss: 0.25882 - acc: 0.9141 -- iter: 0928/1395
[A[ATraining Step: 382  | total loss: [1m[32m0.25379[0m[0m | time: 56.179s
[2K
| Adam | epoch: 009 | loss: 0.25379 - acc: 0.9133 -- iter: 0960/1395
[A[ATraining Step: 383  | total loss: [1m[32m0.24229[0m[0m | time: 57.372s
[2K
| Adam | epoch: 009 | loss: 0.24229 - acc: 0.9188 -- iter: 0992/1395
[A[ATraining Step: 384  | total loss: [1m[32m0.24783[0m[0m | time: 58.426s
[2K
| Adam | epoch: 009 | loss: 0.24783 - acc: 0.9207 -- iter: 1024/1395
[A[ATraining Step: 385  | total loss: [1m[32m0.24128[0m[0m | time: 59.516s
[2K
| Adam | epoch: 009 | loss: 0.24128 - acc: 0.9224 -- iter: 1056/1395
[A[ATraining Step: 386  | total loss: [1m[32m0.23530[0m[0m | time: 60.639s
[2K
| Adam | epoch: 009 | loss: 0.23530 - acc: 0.9239 -- iter: 1088/1395
[A[ATraining Step: 387  | total loss: [1m[32m0.23104[0m[0m | time: 61.598s
[2K
| Adam | epoch: 009 | loss: 0.23104 - acc: 0.9253 -- iter: 1120/1395
[A[ATraining Step: 388  | total loss: [1m[32m0.21916[0m[0m | time: 62.887s
[2K
| Adam | epoch: 009 | loss: 0.21916 - acc: 0.9327 -- iter: 1152/1395
[A[ATraining Step: 389  | total loss: [1m[32m0.24822[0m[0m | time: 64.081s
[2K
| Adam | epoch: 009 | loss: 0.24822 - acc: 0.9270 -- iter: 1184/1395
[A[ATraining Step: 390  | total loss: [1m[32m0.25154[0m[0m | time: 65.129s
[2K
| Adam | epoch: 009 | loss: 0.25154 - acc: 0.9218 -- iter: 1216/1395
[A[ATraining Step: 391  | total loss: [1m[32m0.25426[0m[0m | time: 66.054s
[2K
| Adam | epoch: 009 | loss: 0.25426 - acc: 0.9202 -- iter: 1248/1395
[A[ATraining Step: 392  | total loss: [1m[32m0.26426[0m[0m | time: 67.136s
[2K
| Adam | epoch: 009 | loss: 0.26426 - acc: 0.9063 -- iter: 1280/1395
[A[ATraining Step: 393  | total loss: [1m[32m0.26416[0m[0m | time: 68.217s
[2K
| Adam | epoch: 009 | loss: 0.26416 - acc: 0.9094 -- iter: 1312/1395
[A[ATraining Step: 394  | total loss: [1m[32m0.25365[0m[0m | time: 69.387s
[2K
| Adam | epoch: 009 | loss: 0.25365 - acc: 0.9060 -- iter: 1344/1395
[A[ATraining Step: 395  | total loss: [1m[32m0.26008[0m[0m | time: 70.491s
[2K
| Adam | epoch: 009 | loss: 0.26008 - acc: 0.9029 -- iter: 1376/1395
[A[ATraining Step: 396  | total loss: [1m[32m0.25572[0m[0m | time: 74.752s
[2K
| Adam | epoch: 009 | loss: 0.25572 - acc: 0.9063 | val_loss: 0.39027 - val_acc: 0.8581 -- iter: 1395/1395
--
Training Step: 397  | total loss: [1m[32m0.27065[0m[0m | time: 1.173s
[2K
| Adam | epoch: 010 | loss: 0.27065 - acc: 0.8970 -- iter: 0032/1395
[A[ATraining Step: 398  | total loss: [1m[32m0.26286[0m[0m | time: 2.398s
[2K
| Adam | epoch: 010 | loss: 0.26286 - acc: 0.9041 -- iter: 0064/1395
[A[ATraining Step: 399  | total loss: [1m[32m0.24816[0m[0m | time: 3.574s
[2K
| Adam | epoch: 010 | loss: 0.24816 - acc: 0.9106 -- iter: 0096/1395
[A[ATraining Step: 400  | total loss: [1m[32m0.24211[0m[0m | time: 7.865s
[2K
| Adam | epoch: 010 | loss: 0.24211 - acc: 0.9070 | val_loss: 0.39259 - val_acc: 0.8513 -- iter: 0128/1395
--
Training Step: 401  | total loss: [1m[32m0.24462[0m[0m | time: 9.108s
[2K
| Adam | epoch: 010 | loss: 0.24462 - acc: 0.9070 -- iter: 0160/1395
[A[ATraining Step: 402  | total loss: [1m[32m0.24877[0m[0m | time: 10.320s
[2K
| Adam | epoch: 010 | loss: 0.24877 - acc: 0.9100 -- iter: 0192/1395
[A[ATraining Step: 403  | total loss: [1m[32m0.24735[0m[0m | time: 11.219s
[2K
| Adam | epoch: 010 | loss: 0.24735 - acc: 0.9096 -- iter: 0224/1395
[A[ATraining Step: 404  | total loss: [1m[32m0.25429[0m[0m | time: 11.902s
[2K
| Adam | epoch: 010 | loss: 0.25429 - acc: 0.9062 -- iter: 0256/1395
[A[ATraining Step: 405  | total loss: [1m[32m0.26553[0m[0m | time: 12.599s
[2K
| Adam | epoch: 010 | loss: 0.26553 - acc: 0.8998 -- iter: 0288/1395
[A[ATraining Step: 406  | total loss: [1m[32m0.27192[0m[0m | time: 13.745s
[2K
| Adam | epoch: 010 | loss: 0.27192 - acc: 0.8993 -- iter: 0320/1395
[A[ATraining Step: 407  | total loss: [1m[32m0.26165[0m[0m | time: 14.881s
[2K
| Adam | epoch: 010 | loss: 0.26165 - acc: 0.9031 -- iter: 0352/1395
[A[ATraining Step: 408  | total loss: [1m[32m0.25806[0m[0m | time: 16.061s
[2K
| Adam | epoch: 010 | loss: 0.25806 - acc: 0.9065 -- iter: 0384/1395
[A[ATraining Step: 409  | total loss: [1m[32m0.25217[0m[0m | time: 17.211s
[2K
| Adam | epoch: 010 | loss: 0.25217 - acc: 0.9128 -- iter: 0416/1395
[A[ATraining Step: 410  | total loss: [1m[32m0.25746[0m[0m | time: 18.402s
[2K
| Adam | epoch: 010 | loss: 0.25746 - acc: 0.9152 -- iter: 0448/1395
[A[ATraining Step: 411  | total loss: [1m[32m0.26605[0m[0m | time: 19.538s
[2K
| Adam | epoch: 010 | loss: 0.26605 - acc: 0.9175 -- iter: 0480/1395
[A[ATraining Step: 412  | total loss: [1m[32m0.26361[0m[0m | time: 20.742s
[2K
| Adam | epoch: 010 | loss: 0.26361 - acc: 0.9163 -- iter: 0512/1395
[A[ATraining Step: 413  | total loss: [1m[32m0.25833[0m[0m | time: 21.888s
[2K
| Adam | epoch: 010 | loss: 0.25833 - acc: 0.9185 -- iter: 0544/1395
[A[ATraining Step: 414  | total loss: [1m[32m0.26854[0m[0m | time: 23.107s
[2K
| Adam | epoch: 010 | loss: 0.26854 - acc: 0.9079 -- iter: 0576/1395
[A[ATraining Step: 415  | total loss: [1m[32m0.25521[0m[0m | time: 24.095s
[2K
| Adam | epoch: 010 | loss: 0.25521 - acc: 0.9139 -- iter: 0608/1395
[A[ATraining Step: 416  | total loss: [1m[32m0.24707[0m[0m | time: 25.104s
[2K
| Adam | epoch: 010 | loss: 0.24707 - acc: 0.9163 -- iter: 0640/1395
[A[ATraining Step: 417  | total loss: [1m[32m0.24197[0m[0m | time: 26.087s
[2K
| Adam | epoch: 010 | loss: 0.24197 - acc: 0.9153 -- iter: 0672/1395
[A[ATraining Step: 418  | total loss: [1m[32m0.23671[0m[0m | time: 27.390s
[2K
| Adam | epoch: 010 | loss: 0.23671 - acc: 0.9175 -- iter: 0704/1395
[A[ATraining Step: 419  | total loss: [1m[32m0.22338[0m[0m | time: 28.591s
[2K
| Adam | epoch: 010 | loss: 0.22338 - acc: 0.9258 -- iter: 0736/1395
[A[ATraining Step: 420  | total loss: [1m[32m0.22227[0m[0m | time: 29.894s
[2K
| Adam | epoch: 010 | loss: 0.22227 - acc: 0.9269 -- iter: 0768/1395
[A[ATraining Step: 421  | total loss: [1m[32m0.22175[0m[0m | time: 30.988s
[2K
| Adam | epoch: 010 | loss: 0.22175 - acc: 0.9249 -- iter: 0800/1395
[A[ATraining Step: 422  | total loss: [1m[32m0.21114[0m[0m | time: 32.244s
[2K
| Adam | epoch: 010 | loss: 0.21114 - acc: 0.9293 -- iter: 0832/1395
[A[ATraining Step: 423  | total loss: [1m[32m0.21185[0m[0m | time: 33.594s
[2K
| Adam | epoch: 010 | loss: 0.21185 - acc: 0.9301 -- iter: 0864/1395
[A[ATraining Step: 424  | total loss: [1m[32m0.20097[0m[0m | time: 34.940s
[2K
| Adam | epoch: 010 | loss: 0.20097 - acc: 0.9371 -- iter: 0896/1395
[A[ATraining Step: 425  | total loss: [1m[32m0.20941[0m[0m | time: 40.313s
[2K
| Adam | epoch: 010 | loss: 0.20941 - acc: 0.9277 -- iter: 0928/1395
[A[ATraining Step: 426  | total loss: [1m[32m0.19752[0m[0m | time: 47.934s
[2K
| Adam | epoch: 010 | loss: 0.19752 - acc: 0.9318 -- iter: 0960/1395
[A[ATraining Step: 427  | total loss: [1m[32m0.18460[0m[0m | time: 53.215s
[2K
| Adam | epoch: 010 | loss: 0.18460 - acc: 0.9355 -- iter: 0992/1395
[A[ATraining Step: 428  | total loss: [1m[32m0.17061[0m[0m | time: 57.747s
[2K
| Adam | epoch: 010 | loss: 0.17061 - acc: 0.9420 -- iter: 1024/1395
[A[ATraining Step: 429  | total loss: [1m[32m0.17421[0m[0m | time: 58.820s
[2K
| Adam | epoch: 010 | loss: 0.17421 - acc: 0.9415 -- iter: 1056/1395
[A[ATraining Step: 430  | total loss: [1m[32m0.18105[0m[0m | time: 59.963s
[2K
| Adam | epoch: 010 | loss: 0.18105 - acc: 0.9380 -- iter: 1088/1395
[A[ATraining Step: 431  | total loss: [1m[32m0.17983[0m[0m | time: 61.109s
[2K
| Adam | epoch: 010 | loss: 0.17983 - acc: 0.9348 -- iter: 1120/1395
[A[ATraining Step: 432  | total loss: [1m[32m0.18759[0m[0m | time: 62.199s
[2K
| Adam | epoch: 010 | loss: 0.18759 - acc: 0.9382 -- iter: 1152/1395
[A[ATraining Step: 433  | total loss: [1m[32m0.19532[0m[0m | time: 63.450s
[2K
| Adam | epoch: 010 | loss: 0.19532 - acc: 0.9413 -- iter: 1184/1395
[A[ATraining Step: 434  | total loss: [1m[32m0.20289[0m[0m | time: 64.634s
[2K
| Adam | epoch: 010 | loss: 0.20289 - acc: 0.9378 -- iter: 1216/1395
[A[ATraining Step: 435  | total loss: [1m[32m0.19781[0m[0m | time: 65.774s
[2K
| Adam | epoch: 010 | loss: 0.19781 - acc: 0.9377 -- iter: 1248/1395
[A[ATraining Step: 436  | total loss: [1m[32m0.19100[0m[0m | time: 66.896s
[2K
| Adam | epoch: 010 | loss: 0.19100 - acc: 0.9377 -- iter: 1280/1395
[A[ATraining Step: 437  | total loss: [1m[32m0.18824[0m[0m | time: 68.135s
[2K
| Adam | epoch: 010 | loss: 0.18824 - acc: 0.9377 -- iter: 1312/1395
[A[ATraining Step: 438  | total loss: [1m[32m0.19806[0m[0m | time: 69.285s
[2K
| Adam | epoch: 010 | loss: 0.19806 - acc: 0.9283 -- iter: 1344/1395
[A[ATraining Step: 439  | total loss: [1m[32m0.19614[0m[0m | time: 73.698s
[2K
| Adam | epoch: 010 | loss: 0.19614 - acc: 0.9230 -- iter: 1376/1395
[A[ATraining Step: 440  | total loss: [1m[32m0.20630[0m[0m | time: 101.984s
[2K
| Adam | epoch: 010 | loss: 0.20630 - acc: 0.9182 | val_loss: 0.40038 - val_acc: 0.8490 -- iter: 1395/1395
--
Training Step: 441  | total loss: [1m[32m0.19565[0m[0m | time: 1.126s
[2K
| Adam | epoch: 011 | loss: 0.19565 - acc: 0.9232 -- iter: 0032/1395
[A[ATraining Step: 442  | total loss: [1m[32m0.18641[0m[0m | time: 2.313s
[2K
| Adam | epoch: 011 | loss: 0.18641 - acc: 0.9247 -- iter: 0064/1395
[A[ATraining Step: 443  | total loss: [1m[32m0.22874[0m[0m | time: 3.527s
[2K
| Adam | epoch: 011 | loss: 0.22874 - acc: 0.9166 -- iter: 0096/1395
[A[ATraining Step: 444  | total loss: [1m[32m0.22204[0m[0m | time: 4.757s
[2K
| Adam | epoch: 011 | loss: 0.22204 - acc: 0.9155 -- iter: 0128/1395
[A[ATraining Step: 445  | total loss: [1m[32m0.21846[0m[0m | time: 6.049s
[2K
| Adam | epoch: 011 | loss: 0.21846 - acc: 0.9177 -- iter: 0160/1395
[A[ATraining Step: 446  | total loss: [1m[32m0.21612[0m[0m | time: 7.253s
[2K
| Adam | epoch: 011 | loss: 0.21612 - acc: 0.9197 -- iter: 0192/1395
[A[ATraining Step: 447  | total loss: [1m[32m0.21725[0m[0m | time: 8.381s
[2K
| Adam | epoch: 011 | loss: 0.21725 - acc: 0.9184 -- iter: 0224/1395
[A[ATraining Step: 448  | total loss: [1m[32m0.22860[0m[0m | time: 9.270s
[2K
| Adam | epoch: 011 | loss: 0.22860 - acc: 0.9078 -- iter: 0256/1395
[A[ATraining Step: 449  | total loss: [1m[32m0.23284[0m[0m | time: 9.940s
[2K
| Adam | epoch: 011 | loss: 0.23284 - acc: 0.9076 -- iter: 0288/1395
[A[ATraining Step: 450  | total loss: [1m[32m0.22575[0m[0m | time: 10.581s
[2K
| Adam | epoch: 011 | loss: 0.22575 - acc: 0.9116 -- iter: 0320/1395
[A[ATraining Step: 451  | total loss: [1m[32m0.21198[0m[0m | time: 11.681s
[2K
| Adam | epoch: 011 | loss: 0.21198 - acc: 0.9204 -- iter: 0352/1395
[A[ATraining Step: 452  | total loss: [1m[32m0.23607[0m[0m | time: 12.839s
[2K
| Adam | epoch: 011 | loss: 0.23607 - acc: 0.9065 -- iter: 0384/1395
[A[ATraining Step: 453  | total loss: [1m[32m0.27193[0m[0m | time: 14.006s
[2K
| Adam | epoch: 011 | loss: 0.27193 - acc: 0.8909 -- iter: 0416/1395
[A[ATraining Step: 454  | total loss: [1m[32m0.28813[0m[0m | time: 15.186s
[2K
| Adam | epoch: 011 | loss: 0.28813 - acc: 0.8830 -- iter: 0448/1395
[A[ATraining Step: 455  | total loss: [1m[32m0.29657[0m[0m | time: 16.404s
[2K
| Adam | epoch: 011 | loss: 0.29657 - acc: 0.8791 -- iter: 0480/1395
[A[ATraining Step: 456  | total loss: [1m[32m0.27392[0m[0m | time: 17.508s
[2K
| Adam | epoch: 011 | loss: 0.27392 - acc: 0.8912 -- iter: 0512/1395
[A[ATraining Step: 457  | total loss: [1m[32m0.27126[0m[0m | time: 18.650s
[2K
| Adam | epoch: 011 | loss: 0.27126 - acc: 0.8927 -- iter: 0544/1395
[A[ATraining Step: 458  | total loss: [1m[32m0.27567[0m[0m | time: 19.926s
[2K
| Adam | epoch: 011 | loss: 0.27567 - acc: 0.8878 -- iter: 0576/1395
[A[ATraining Step: 459  | total loss: [1m[32m0.28622[0m[0m | time: 21.195s
[2K
| Adam | epoch: 011 | loss: 0.28622 - acc: 0.8865 -- iter: 0608/1395
[A[ATraining Step: 460  | total loss: [1m[32m0.28390[0m[0m | time: 22.076s
[2K
| Adam | epoch: 011 | loss: 0.28390 - acc: 0.8885 -- iter: 0640/1395
[A[ATraining Step: 461  | total loss: [1m[32m0.27178[0m[0m | time: 23.200s
[2K
| Adam | epoch: 011 | loss: 0.27178 - acc: 0.8965 -- iter: 0672/1395
[A[ATraining Step: 462  | total loss: [1m[32m0.27689[0m[0m | time: 24.363s
[2K
| Adam | epoch: 011 | loss: 0.27689 - acc: 0.8912 -- iter: 0704/1395
[A[ATraining Step: 463  | total loss: [1m[32m0.28578[0m[0m | time: 25.478s
[2K
| Adam | epoch: 011 | loss: 0.28578 - acc: 0.8927 -- iter: 0736/1395
[A[ATraining Step: 464  | total loss: [1m[32m0.28682[0m[0m | time: 26.638s
[2K
| Adam | epoch: 011 | loss: 0.28682 - acc: 0.8910 -- iter: 0768/1395
[A[ATraining Step: 465  | total loss: [1m[32m0.29926[0m[0m | time: 27.914s
[2K
| Adam | epoch: 011 | loss: 0.29926 - acc: 0.8800 -- iter: 0800/1395
[A[ATraining Step: 466  | total loss: [1m[32m0.31400[0m[0m | time: 28.991s
[2K
| Adam | epoch: 011 | loss: 0.31400 - acc: 0.8670 -- iter: 0832/1395
[A[ATraining Step: 467  | total loss: [1m[32m0.32147[0m[0m | time: 30.075s
[2K
| Adam | epoch: 011 | loss: 0.32147 - acc: 0.8615 -- iter: 0864/1395
[A[ATraining Step: 468  | total loss: [1m[32m0.30358[0m[0m | time: 31.294s
[2K
| Adam | epoch: 011 | loss: 0.30358 - acc: 0.8723 -- iter: 0896/1395
[A[ATraining Step: 469  | total loss: [1m[32m0.28235[0m[0m | time: 32.655s
[2K
| Adam | epoch: 011 | loss: 0.28235 - acc: 0.8850 -- iter: 0928/1395
[A[ATraining Step: 470  | total loss: [1m[32m0.28405[0m[0m | time: 36.534s
[2K
| Adam | epoch: 011 | loss: 0.28405 - acc: 0.8840 -- iter: 0960/1395
[A[ATraining Step: 471  | total loss: [1m[32m0.28402[0m[0m | time: 41.983s
[2K
| Adam | epoch: 011 | loss: 0.28402 - acc: 0.8863 -- iter: 0992/1395
[A[ATraining Step: 472  | total loss: [1m[32m0.28364[0m[0m | time: 48.683s
[2K
| Adam | epoch: 011 | loss: 0.28364 - acc: 0.8883 -- iter: 1024/1395
[A[ATraining Step: 473  | total loss: [1m[32m0.28240[0m[0m | time: 55.335s
[2K
| Adam | epoch: 011 | loss: 0.28240 - acc: 0.8932 -- iter: 1056/1395
[A[ATraining Step: 474  | total loss: [1m[32m0.29643[0m[0m | time: 62.690s
[2K
| Adam | epoch: 011 | loss: 0.29643 - acc: 0.8851 -- iter: 1088/1395
[A[ATraining Step: 475  | total loss: [1m[32m0.28121[0m[0m | time: 67.347s
[2K
| Adam | epoch: 011 | loss: 0.28121 - acc: 0.8904 -- iter: 1120/1395
[A[ATraining Step: 476  | total loss: [1m[32m0.29033[0m[0m | time: 69.930s
[2K
| Adam | epoch: 011 | loss: 0.29033 - acc: 0.8857 -- iter: 1152/1395
[A[ATraining Step: 477  | total loss: [1m[32m0.28398[0m[0m | time: 75.116s
[2K
| Adam | epoch: 011 | loss: 0.28398 - acc: 0.8877 -- iter: 1184/1395
[A[ATraining Step: 478  | total loss: [1m[32m0.26570[0m[0m | time: 76.954s
[2K
| Adam | epoch: 011 | loss: 0.26570 - acc: 0.8958 -- iter: 1216/1395
[A[ATraining Step: 479  | total loss: [1m[32m0.25720[0m[0m | time: 78.056s
[2K
| Adam | epoch: 011 | loss: 0.25720 - acc: 0.9000 -- iter: 1248/1395
[A[ATraining Step: 480  | total loss: [1m[32m0.26166[0m[0m | time: 79.267s
[2K
| Adam | epoch: 011 | loss: 0.26166 - acc: 0.8975 -- iter: 1280/1395
[A[ATraining Step: 481  | total loss: [1m[32m0.24546[0m[0m | time: 80.443s
[2K
| Adam | epoch: 011 | loss: 0.24546 - acc: 0.9078 -- iter: 1312/1395
[A[ATraining Step: 482  | total loss: [1m[32m0.24053[0m[0m | time: 81.562s
[2K
| Adam | epoch: 011 | loss: 0.24053 - acc: 0.9076 -- iter: 1344/1395
[A[ATraining Step: 483  | total loss: [1m[32m0.23723[0m[0m | time: 82.781s
[2K
| Adam | epoch: 011 | loss: 0.23723 - acc: 0.9106 -- iter: 1376/1395
[A[ATraining Step: 484  | total loss: [1m[32m0.22908[0m[0m | time: 87.089s
[2K
| Adam | epoch: 011 | loss: 0.22908 - acc: 0.9133 | val_loss: 0.48886 - val_acc: 0.8192 -- iter: 1395/1395
--
Training Step: 485  | total loss: [1m[32m0.21318[0m[0m | time: 1.404s
[2K
| Adam | epoch: 012 | loss: 0.21318 - acc: 0.9220 -- iter: 0032/1395
[A[ATraining Step: 486  | total loss: [1m[32m0.20684[0m[0m | time: 2.671s
[2K
| Adam | epoch: 012 | loss: 0.20684 - acc: 0.9266 -- iter: 0064/1395
[A[ATraining Step: 487  | total loss: [1m[32m0.19723[0m[0m | time: 3.928s
[2K
| Adam | epoch: 012 | loss: 0.19723 - acc: 0.9309 -- iter: 0096/1395
[A[ATraining Step: 488  | total loss: [1m[32m0.18665[0m[0m | time: 5.172s
[2K
| Adam | epoch: 012 | loss: 0.18665 - acc: 0.9346 -- iter: 0128/1395
[A[ATraining Step: 489  | total loss: [1m[32m0.19475[0m[0m | time: 6.309s
[2K
| Adam | epoch: 012 | loss: 0.19475 - acc: 0.9287 -- iter: 0160/1395
[A[ATraining Step: 490  | total loss: [1m[32m0.18598[0m[0m | time: 7.141s
[2K
| Adam | epoch: 012 | loss: 0.18598 - acc: 0.9327 -- iter: 0192/1395
[A[ATraining Step: 491  | total loss: [1m[32m0.19184[0m[0m | time: 7.943s
[2K
| Adam | epoch: 012 | loss: 0.19184 - acc: 0.9269 -- iter: 0224/1395
[A[ATraining Step: 492  | total loss: [1m[32m0.18193[0m[0m | time: 8.770s
[2K
| Adam | epoch: 012 | loss: 0.18193 - acc: 0.9311 -- iter: 0256/1395
[A[ATraining Step: 493  | total loss: [1m[32m0.18185[0m[0m | time: 9.572s
[2K
| Adam | epoch: 012 | loss: 0.18185 - acc: 0.9317 -- iter: 0288/1395
[A[ATraining Step: 494  | total loss: [1m[32m0.17870[0m[0m | time: 10.084s
[2K
| Adam | epoch: 012 | loss: 0.17870 - acc: 0.9354 -- iter: 0320/1395
[A[ATraining Step: 495  | total loss: [1m[32m0.17668[0m[0m | time: 10.580s
[2K
| Adam | epoch: 012 | loss: 0.17668 - acc: 0.9314 -- iter: 0352/1395
[A[ATraining Step: 496  | total loss: [1m[32m0.16783[0m[0m | time: 11.426s
[2K
| Adam | epoch: 012 | loss: 0.16783 - acc: 0.9382 -- iter: 0384/1395
[A[ATraining Step: 497  | total loss: [1m[32m0.15935[0m[0m | time: 12.258s
[2K
| Adam | epoch: 012 | loss: 0.15935 - acc: 0.9413 -- iter: 0416/1395
[A[ATraining Step: 498  | total loss: [1m[32m0.16463[0m[0m | time: 13.075s
[2K
| Adam | epoch: 012 | loss: 0.16463 - acc: 0.9409 -- iter: 0448/1395
[A[ATraining Step: 499  | total loss: [1m[32m0.15077[0m[0m | time: 13.941s
[2K
| Adam | epoch: 012 | loss: 0.15077 - acc: 0.9468 -- iter: 0480/1395
[A[ATraining Step: 500  | total loss: [1m[32m0.15274[0m[0m | time: 14.781s
[2K
| Adam | epoch: 012 | loss: 0.15274 - acc: 0.9459 -- iter: 0512/1395
[A[ATraining Step: 501  | total loss: [1m[32m0.14171[0m[0m | time: 15.615s
[2K
| Adam | epoch: 012 | loss: 0.14171 - acc: 0.9513 -- iter: 0544/1395
[A[ATraining Step: 502  | total loss: [1m[32m0.13542[0m[0m | time: 16.468s
[2K
| Adam | epoch: 012 | loss: 0.13542 - acc: 0.9530 -- iter: 0576/1395
[A[ATraining Step: 503  | total loss: [1m[32m0.14555[0m[0m | time: 17.336s
[2K
| Adam | epoch: 012 | loss: 0.14555 - acc: 0.9546 -- iter: 0608/1395
[A[ATraining Step: 504  | total loss: [1m[32m0.15078[0m[0m | time: 18.143s
[2K
| Adam | epoch: 012 | loss: 0.15078 - acc: 0.9529 -- iter: 0640/1395
[A[ATraining Step: 505  | total loss: [1m[32m0.14769[0m[0m | time: 18.964s
[2K
| Adam | epoch: 012 | loss: 0.14769 - acc: 0.9514 -- iter: 0672/1395
[A[ATraining Step: 506  | total loss: [1m[32m0.16111[0m[0m | time: 19.783s
[2K
| Adam | epoch: 012 | loss: 0.16111 - acc: 0.9437 -- iter: 0704/1395
[A[ATraining Step: 507  | total loss: [1m[32m0.16124[0m[0m | time: 20.555s
[2K
| Adam | epoch: 012 | loss: 0.16124 - acc: 0.9431 -- iter: 0736/1395
[A[ATraining Step: 508  | total loss: [1m[32m0.18898[0m[0m | time: 21.440s
[2K
| Adam | epoch: 012 | loss: 0.18898 - acc: 0.9394 -- iter: 0768/1395
[A[ATraining Step: 509  | total loss: [1m[32m0.17354[0m[0m | time: 22.294s
[2K
| Adam | epoch: 012 | loss: 0.17354 - acc: 0.9455 -- iter: 0800/1395
[A[ATraining Step: 510  | total loss: [1m[32m0.16460[0m[0m | time: 23.183s
[2K
| Adam | epoch: 012 | loss: 0.16460 - acc: 0.9478 -- iter: 0832/1395
[A[ATraining Step: 511  | total loss: [1m[32m0.16528[0m[0m | time: 24.013s
[2K
| Adam | epoch: 012 | loss: 0.16528 - acc: 0.9468 -- iter: 0864/1395
[A[ATraining Step: 512  | total loss: [1m[32m0.16695[0m[0m | time: 24.826s
[2K
| Adam | epoch: 012 | loss: 0.16695 - acc: 0.9458 -- iter: 0896/1395
[A[ATraining Step: 513  | total loss: [1m[32m0.16755[0m[0m | time: 25.735s
[2K
| Adam | epoch: 012 | loss: 0.16755 - acc: 0.9450 -- iter: 0928/1395
[A[ATraining Step: 514  | total loss: [1m[32m0.15717[0m[0m | time: 26.585s
[2K
| Adam | epoch: 012 | loss: 0.15717 - acc: 0.9505 -- iter: 0960/1395
[A[ATraining Step: 515  | total loss: [1m[32m0.14518[0m[0m | time: 27.412s
[2K
| Adam | epoch: 012 | loss: 0.14518 - acc: 0.9555 -- iter: 0992/1395
[A[ATraining Step: 516  | total loss: [1m[32m0.16172[0m[0m | time: 28.269s
[2K
| Adam | epoch: 012 | loss: 0.16172 - acc: 0.9474 -- iter: 1024/1395
[A[ATraining Step: 517  | total loss: [1m[32m0.16009[0m[0m | time: 29.097s
[2K
| Adam | epoch: 012 | loss: 0.16009 - acc: 0.9433 -- iter: 1056/1395
[A[ATraining Step: 518  | total loss: [1m[32m0.15105[0m[0m | time: 29.953s
[2K
| Adam | epoch: 012 | loss: 0.15105 - acc: 0.9490 -- iter: 1088/1395
[A[ATraining Step: 519  | total loss: [1m[32m0.13932[0m[0m | time: 30.956s
[2K
| Adam | epoch: 012 | loss: 0.13932 - acc: 0.9541 -- iter: 1120/1395
[A[ATraining Step: 520  | total loss: [1m[32m0.12780[0m[0m | time: 31.848s
[2K
| Adam | epoch: 012 | loss: 0.12780 - acc: 0.9587 -- iter: 1152/1395
[A[ATraining Step: 521  | total loss: [1m[32m0.13834[0m[0m | time: 32.582s
[2K
| Adam | epoch: 012 | loss: 0.13834 - acc: 0.9534 -- iter: 1184/1395
[A[ATraining Step: 522  | total loss: [1m[32m0.15714[0m[0m | time: 33.308s
[2K
| Adam | epoch: 012 | loss: 0.15714 - acc: 0.9425 -- iter: 1216/1395
[A[ATraining Step: 523  | total loss: [1m[32m0.15381[0m[0m | time: 34.016s
[2K
| Adam | epoch: 012 | loss: 0.15381 - acc: 0.9420 -- iter: 1248/1395
[A[ATraining Step: 524  | total loss: [1m[32m0.15353[0m[0m | time: 34.790s
[2K
| Adam | epoch: 012 | loss: 0.15353 - acc: 0.9446 -- iter: 1280/1395
[A[ATraining Step: 525  | total loss: [1m[32m0.17741[0m[0m | time: 35.663s
[2K
| Adam | epoch: 012 | loss: 0.17741 - acc: 0.9345 -- iter: 1312/1395
[A[ATraining Step: 526  | total loss: [1m[32m0.17549[0m[0m | time: 36.486s
[2K
| Adam | epoch: 012 | loss: 0.17549 - acc: 0.9348 -- iter: 1344/1395
[A[ATraining Step: 527  | total loss: [1m[32m0.16894[0m[0m | time: 37.294s
[2K
| Adam | epoch: 012 | loss: 0.16894 - acc: 0.9382 -- iter: 1376/1395
[A[ATraining Step: 528  | total loss: [1m[32m0.17000[0m[0m | time: 41.530s
[2K
| Adam | epoch: 012 | loss: 0.17000 - acc: 0.9382 | val_loss: 0.37292 - val_acc: 0.8627 -- iter: 1395/1395
--
Training Step: 529  | total loss: [1m[32m0.17359[0m[0m | time: 1.111s
[2K
| Adam | epoch: 013 | loss: 0.17359 - acc: 0.9350 -- iter: 0032/1395
[A[ATraining Step: 530  | total loss: [1m[32m0.16172[0m[0m | time: 2.335s
[2K
| Adam | epoch: 013 | loss: 0.16172 - acc: 0.9415 -- iter: 0064/1395
[A[ATraining Step: 531  | total loss: [1m[32m0.17665[0m[0m | time: 3.548s
[2K
| Adam | epoch: 013 | loss: 0.17665 - acc: 0.9348 -- iter: 0096/1395
[A[ATraining Step: 532  | total loss: [1m[32m0.17143[0m[0m | time: 4.698s
[2K
| Adam | epoch: 013 | loss: 0.17143 - acc: 0.9382 -- iter: 0128/1395
[A[ATraining Step: 533  | total loss: [1m[32m0.17349[0m[0m | time: 5.733s
[2K
| Adam | epoch: 013 | loss: 0.17349 - acc: 0.9350 -- iter: 0160/1395
[A[ATraining Step: 534  | total loss: [1m[32m0.16299[0m[0m | time: 6.735s
[2K
| Adam | epoch: 013 | loss: 0.16299 - acc: 0.9384 -- iter: 0192/1395
[A[ATraining Step: 535  | total loss: [1m[32m0.15749[0m[0m | time: 7.762s
[2K
| Adam | epoch: 013 | loss: 0.15749 - acc: 0.9383 -- iter: 0224/1395
[A[ATraining Step: 536  | total loss: [1m[32m0.14936[0m[0m | time: 8.932s
[2K
| Adam | epoch: 013 | loss: 0.14936 - acc: 0.9413 -- iter: 0256/1395
[A[ATraining Step: 537  | total loss: [1m[32m0.14994[0m[0m | time: 9.891s
[2K
| Adam | epoch: 013 | loss: 0.14994 - acc: 0.9441 -- iter: 0288/1395
[A[ATraining Step: 538  | total loss: [1m[32m0.14695[0m[0m | time: 10.906s
[2K
| Adam | epoch: 013 | loss: 0.14695 - acc: 0.9466 -- iter: 0320/1395
[A[ATraining Step: 539  | total loss: [1m[32m0.14148[0m[0m | time: 11.632s
[2K
| Adam | epoch: 013 | loss: 0.14148 - acc: 0.9488 -- iter: 0352/1395
[A[ATraining Step: 540  | total loss: [1m[32m0.13811[0m[0m | time: 12.455s
[2K
| Adam | epoch: 013 | loss: 0.13811 - acc: 0.9539 -- iter: 0384/1395
[A[ATraining Step: 541  | total loss: [1m[32m0.13220[0m[0m | time: 13.775s
[2K
| Adam | epoch: 013 | loss: 0.13220 - acc: 0.9585 -- iter: 0416/1395
[A[ATraining Step: 542  | total loss: [1m[32m0.12303[0m[0m | time: 14.859s
[2K
| Adam | epoch: 013 | loss: 0.12303 - acc: 0.9627 -- iter: 0448/1395
[A[ATraining Step: 543  | total loss: [1m[32m0.15100[0m[0m | time: 19.325s
[2K
| Adam | epoch: 013 | loss: 0.15100 - acc: 0.9508 -- iter: 0480/1395
[A[ATraining Step: 544  | total loss: [1m[32m0.16274[0m[0m | time: 23.094s
[2K
| Adam | epoch: 013 | loss: 0.16274 - acc: 0.9463 -- iter: 0512/1395
[A[ATraining Step: 545  | total loss: [1m[32m0.16331[0m[0m | time: 26.761s
[2K
| Adam | epoch: 013 | loss: 0.16331 - acc: 0.9423 -- iter: 0544/1395
[A[ATraining Step: 546  | total loss: [1m[32m0.17068[0m[0m | time: 27.879s
[2K
| Adam | epoch: 013 | loss: 0.17068 - acc: 0.9450 -- iter: 0576/1395
[A[ATraining Step: 547  | total loss: [1m[32m0.15955[0m[0m | time: 28.874s
[2K
| Adam | epoch: 013 | loss: 0.15955 - acc: 0.9505 -- iter: 0608/1395
[A[ATraining Step: 548  | total loss: [1m[32m0.14961[0m[0m | time: 29.843s
[2K
| Adam | epoch: 013 | loss: 0.14961 - acc: 0.9554 -- iter: 0640/1395
[A[ATraining Step: 549  | total loss: [1m[32m0.15038[0m[0m | time: 31.063s
[2K
| Adam | epoch: 013 | loss: 0.15038 - acc: 0.9567 -- iter: 0672/1395
[A[ATraining Step: 550  | total loss: [1m[32m0.14727[0m[0m | time: 32.287s
[2K
| Adam | epoch: 013 | loss: 0.14727 - acc: 0.9579 -- iter: 0704/1395
[A[ATraining Step: 551  | total loss: [1m[32m0.13981[0m[0m | time: 33.524s
[2K
| Adam | epoch: 013 | loss: 0.13981 - acc: 0.9590 -- iter: 0736/1395
[A[ATraining Step: 552  | total loss: [1m[32m0.13573[0m[0m | time: 34.740s
[2K
| Adam | epoch: 013 | loss: 0.13573 - acc: 0.9600 -- iter: 0768/1395
[A[ATraining Step: 553  | total loss: [1m[32m0.13582[0m[0m | time: 35.900s
[2K
| Adam | epoch: 013 | loss: 0.13582 - acc: 0.9577 -- iter: 0800/1395
[A[ATraining Step: 554  | total loss: [1m[32m0.12708[0m[0m | time: 37.133s
[2K
| Adam | epoch: 013 | loss: 0.12708 - acc: 0.9588 -- iter: 0832/1395
[A[ATraining Step: 555  | total loss: [1m[32m0.11662[0m[0m | time: 38.416s
[2K
| Adam | epoch: 013 | loss: 0.11662 - acc: 0.9630 -- iter: 0864/1395
[A[ATraining Step: 556  | total loss: [1m[32m0.10793[0m[0m | time: 39.356s
[2K
| Adam | epoch: 013 | loss: 0.10793 - acc: 0.9667 -- iter: 0896/1395
[A[ATraining Step: 557  | total loss: [1m[32m0.10205[0m[0m | time: 40.486s
[2K
| Adam | epoch: 013 | loss: 0.10205 - acc: 0.9700 -- iter: 0928/1395
[A[ATraining Step: 558  | total loss: [1m[32m0.09356[0m[0m | time: 41.507s
[2K
| Adam | epoch: 013 | loss: 0.09356 - acc: 0.9730 -- iter: 0960/1395
[A[ATraining Step: 559  | total loss: [1m[32m0.10128[0m[0m | time: 42.574s
[2K
| Adam | epoch: 013 | loss: 0.10128 - acc: 0.9726 -- iter: 0992/1395
[A[ATraining Step: 560  | total loss: [1m[32m0.09945[0m[0m | time: 43.769s
[2K
| Adam | epoch: 013 | loss: 0.09945 - acc: 0.9722 -- iter: 1024/1395
[A[ATraining Step: 561  | total loss: [1m[32m0.09387[0m[0m | time: 45.088s
[2K
| Adam | epoch: 013 | loss: 0.09387 - acc: 0.9718 -- iter: 1056/1395
[A[ATraining Step: 562  | total loss: [1m[32m0.08812[0m[0m | time: 46.437s
[2K
| Adam | epoch: 013 | loss: 0.08812 - acc: 0.9747 -- iter: 1088/1395
[A[ATraining Step: 563  | total loss: [1m[32m0.09289[0m[0m | time: 47.633s
[2K
| Adam | epoch: 013 | loss: 0.09289 - acc: 0.9741 -- iter: 1120/1395
[A[ATraining Step: 564  | total loss: [1m[32m0.10698[0m[0m | time: 48.817s
[2K
| Adam | epoch: 013 | loss: 0.10698 - acc: 0.9735 -- iter: 1152/1395
[A[ATraining Step: 565  | total loss: [1m[32m0.11098[0m[0m | time: 49.874s
[2K
| Adam | epoch: 013 | loss: 0.11098 - acc: 0.9731 -- iter: 1184/1395
[A[ATraining Step: 566  | total loss: [1m[32m0.10812[0m[0m | time: 50.761s
[2K
| Adam | epoch: 013 | loss: 0.10812 - acc: 0.9726 -- iter: 1216/1395
[A[ATraining Step: 567  | total loss: [1m[32m0.10039[0m[0m | time: 51.790s
[2K
| Adam | epoch: 013 | loss: 0.10039 - acc: 0.9754 -- iter: 1248/1395
[A[ATraining Step: 568  | total loss: [1m[32m0.10554[0m[0m | time: 52.866s
[2K
| Adam | epoch: 013 | loss: 0.10554 - acc: 0.9716 -- iter: 1280/1395
[A[ATraining Step: 569  | total loss: [1m[32m0.12224[0m[0m | time: 53.993s
[2K
| Adam | epoch: 013 | loss: 0.12224 - acc: 0.9682 -- iter: 1312/1395
[A[ATraining Step: 570  | total loss: [1m[32m0.11834[0m[0m | time: 55.007s
[2K
| Adam | epoch: 013 | loss: 0.11834 - acc: 0.9714 -- iter: 1344/1395
[A[ATraining Step: 571  | total loss: [1m[32m0.11942[0m[0m | time: 56.237s
[2K
| Adam | epoch: 013 | loss: 0.11942 - acc: 0.9711 -- iter: 1376/1395
[A[ATraining Step: 572  | total loss: [1m[32m0.11059[0m[0m | time: 60.545s
[2K
| Adam | epoch: 013 | loss: 0.11059 - acc: 0.9740 | val_loss: 0.42299 - val_acc: 0.8467 -- iter: 1395/1395
--
Training Step: 573  | total loss: [1m[32m0.10217[0m[0m | time: 1.023s
[2K
| Adam | epoch: 014 | loss: 0.10217 - acc: 0.9766 -- iter: 0032/1395
[A[ATraining Step: 574  | total loss: [1m[32m0.09376[0m[0m | time: 2.137s
[2K
| Adam | epoch: 014 | loss: 0.09376 - acc: 0.9789 -- iter: 0064/1395
[A[ATraining Step: 575  | total loss: [1m[32m0.09911[0m[0m | time: 3.312s
[2K
| Adam | epoch: 014 | loss: 0.09911 - acc: 0.9779 -- iter: 0096/1395
[A[ATraining Step: 576  | total loss: [1m[32m0.09143[0m[0m | time: 4.479s
[2K
| Adam | epoch: 014 | loss: 0.09143 - acc: 0.9801 -- iter: 0128/1395
[A[ATraining Step: 577  | total loss: [1m[32m0.10347[0m[0m | time: 5.549s
[2K
| Adam | epoch: 014 | loss: 0.10347 - acc: 0.9790 -- iter: 0160/1395
[A[ATraining Step: 578  | total loss: [1m[32m0.09882[0m[0m | time: 6.778s
[2K
| Adam | epoch: 014 | loss: 0.09882 - acc: 0.9811 -- iter: 0192/1395
[A[ATraining Step: 579  | total loss: [1m[32m0.09052[0m[0m | time: 8.042s
[2K
| Adam | epoch: 014 | loss: 0.09052 - acc: 0.9830 -- iter: 0224/1395
[A[ATraining Step: 580  | total loss: [1m[32m0.10443[0m[0m | time: 9.139s
[2K
| Adam | epoch: 014 | loss: 0.10443 - acc: 0.9753 -- iter: 0256/1395
[A[ATraining Step: 581  | total loss: [1m[32m0.11185[0m[0m | time: 10.343s
[2K
| Adam | epoch: 014 | loss: 0.11185 - acc: 0.9684 -- iter: 0288/1395
[A[ATraining Step: 582  | total loss: [1m[32m0.10422[0m[0m | time: 11.667s
[2K
| Adam | epoch: 014 | loss: 0.10422 - acc: 0.9716 -- iter: 0320/1395
[A[ATraining Step: 583  | total loss: [1m[32m0.09594[0m[0m | time: 12.812s
[2K
| Adam | epoch: 014 | loss: 0.09594 - acc: 0.9744 -- iter: 0352/1395
[A[ATraining Step: 584  | total loss: [1m[32m0.08918[0m[0m | time: 13.469s
[2K
| Adam | epoch: 014 | loss: 0.08918 - acc: 0.9770 -- iter: 0384/1395
[A[ATraining Step: 585  | total loss: [1m[32m0.08242[0m[0m | time: 14.107s
[2K
| Adam | epoch: 014 | loss: 0.08242 - acc: 0.9793 -- iter: 0416/1395
[A[ATraining Step: 586  | total loss: [1m[32m0.07612[0m[0m | time: 15.262s
[2K
| Adam | epoch: 014 | loss: 0.07612 - acc: 0.9813 -- iter: 0448/1395
[A[ATraining Step: 587  | total loss: [1m[32m0.07226[0m[0m | time: 16.482s
[2K
| Adam | epoch: 014 | loss: 0.07226 - acc: 0.9832 -- iter: 0480/1395
[A[ATraining Step: 588  | total loss: [1m[32m0.07714[0m[0m | time: 17.588s
[2K
| Adam | epoch: 014 | loss: 0.07714 - acc: 0.9818 -- iter: 0512/1395
[A[ATraining Step: 589  | total loss: [1m[32m0.07183[0m[0m | time: 18.745s
[2K
| Adam | epoch: 014 | loss: 0.07183 - acc: 0.9836 -- iter: 0544/1395
[A[ATraining Step: 590  | total loss: [1m[32m0.07242[0m[0m | time: 19.905s
[2K
| Adam | epoch: 014 | loss: 0.07242 - acc: 0.9821 -- iter: 0576/1395
[A[ATraining Step: 591  | total loss: [1m[32m0.07264[0m[0m | time: 21.097s
[2K
| Adam | epoch: 014 | loss: 0.07264 - acc: 0.9808 -- iter: 0608/1395
[A[ATraining Step: 592  | total loss: [1m[32m0.06620[0m[0m | time: 22.288s
[2K
| Adam | epoch: 014 | loss: 0.06620 - acc: 0.9827 -- iter: 0640/1395
[A[ATraining Step: 593  | total loss: [1m[32m0.07849[0m[0m | time: 23.577s
[2K
| Adam | epoch: 014 | loss: 0.07849 - acc: 0.9782 -- iter: 0672/1395
[A[ATraining Step: 594  | total loss: [1m[32m0.09136[0m[0m | time: 24.795s
[2K
| Adam | epoch: 014 | loss: 0.09136 - acc: 0.9710 -- iter: 0704/1395
[A[ATraining Step: 595  | total loss: [1m[32m0.08625[0m[0m | time: 25.741s
[2K
| Adam | epoch: 014 | loss: 0.08625 - acc: 0.9739 -- iter: 0736/1395
[A[ATraining Step: 596  | total loss: [1m[32m0.09345[0m[0m | time: 26.859s
[2K
| Adam | epoch: 014 | loss: 0.09345 - acc: 0.9702 -- iter: 0768/1395
[A[ATraining Step: 597  | total loss: [1m[32m0.10573[0m[0m | time: 28.008s
[2K
| Adam | epoch: 014 | loss: 0.10573 - acc: 0.9638 -- iter: 0800/1395
[A[ATraining Step: 598  | total loss: [1m[32m0.11601[0m[0m | time: 29.253s
[2K
| Adam | epoch: 014 | loss: 0.11601 - acc: 0.9581 -- iter: 0832/1395
[A[ATraining Step: 599  | total loss: [1m[32m0.12096[0m[0m | time: 30.505s
[2K
| Adam | epoch: 014 | loss: 0.12096 - acc: 0.9560 -- iter: 0864/1395
[A[ATraining Step: 600  | total loss: [1m[32m0.11015[0m[0m | time: 34.709s
[2K
| Adam | epoch: 014 | loss: 0.11015 - acc: 0.9604 | val_loss: 0.41927 - val_acc: 0.8764 -- iter: 0896/1395
--
Training Step: 601  | total loss: [1m[32m0.10066[0m[0m | time: 35.686s
[2K
| Adam | epoch: 014 | loss: 0.10066 - acc: 0.9644 -- iter: 0928/1395
[A[ATraining Step: 602  | total loss: [1m[32m0.09168[0m[0m | time: 36.776s
[2K
| Adam | epoch: 014 | loss: 0.09168 - acc: 0.9679 -- iter: 0960/1395
[A[ATraining Step: 603  | total loss: [1m[32m0.09846[0m[0m | time: 37.925s
[2K
| Adam | epoch: 014 | loss: 0.09846 - acc: 0.9680 -- iter: 0992/1395
[A[ATraining Step: 604  | total loss: [1m[32m0.09070[0m[0m | time: 39.052s
[2K
| Adam | epoch: 014 | loss: 0.09070 - acc: 0.9712 -- iter: 1024/1395
[A[ATraining Step: 605  | total loss: [1m[32m0.08655[0m[0m | time: 40.077s
[2K
| Adam | epoch: 014 | loss: 0.08655 - acc: 0.9710 -- iter: 1056/1395
[A[ATraining Step: 606  | total loss: [1m[32m0.07933[0m[0m | time: 41.202s
[2K
| Adam | epoch: 014 | loss: 0.07933 - acc: 0.9739 -- iter: 1088/1395
[A[ATraining Step: 607  | total loss: [1m[32m0.08720[0m[0m | time: 42.372s
[2K
| Adam | epoch: 014 | loss: 0.08720 - acc: 0.9702 -- iter: 1120/1395
[A[ATraining Step: 608  | total loss: [1m[32m0.08418[0m[0m | time: 43.568s
[2K
| Adam | epoch: 014 | loss: 0.08418 - acc: 0.9701 -- iter: 1152/1395
[A[ATraining Step: 609  | total loss: [1m[32m0.10347[0m[0m | time: 44.756s
[2K
| Adam | epoch: 014 | loss: 0.10347 - acc: 0.9575 -- iter: 1184/1395
[A[ATraining Step: 610  | total loss: [1m[32m0.09861[0m[0m | time: 45.892s
[2K
| Adam | epoch: 014 | loss: 0.09861 - acc: 0.9617 -- iter: 1216/1395
[A[ATraining Step: 611  | total loss: [1m[32m0.09158[0m[0m | time: 47.117s
[2K
| Adam | epoch: 014 | loss: 0.09158 - acc: 0.9655 -- iter: 1248/1395
[A[ATraining Step: 612  | total loss: [1m[32m0.08377[0m[0m | time: 48.006s
[2K
| Adam | epoch: 014 | loss: 0.08377 - acc: 0.9690 -- iter: 1280/1395
[A[ATraining Step: 613  | total loss: [1m[32m0.09005[0m[0m | time: 49.102s
[2K
| Adam | epoch: 014 | loss: 0.09005 - acc: 0.9627 -- iter: 1312/1395
[A[ATraining Step: 614  | total loss: [1m[32m0.09603[0m[0m | time: 50.202s
[2K
| Adam | epoch: 014 | loss: 0.09603 - acc: 0.9633 -- iter: 1344/1395
[A[ATraining Step: 615  | total loss: [1m[32m0.08861[0m[0m | time: 51.327s
[2K
| Adam | epoch: 014 | loss: 0.08861 - acc: 0.9670 -- iter: 1376/1395
[A[ATraining Step: 616  | total loss: [1m[32m0.08223[0m[0m | time: 55.740s
[2K
| Adam | epoch: 014 | loss: 0.08223 - acc: 0.9703 | val_loss: 0.52150 - val_acc: 0.8330 -- iter: 1395/1395
--
Training Step: 617  | total loss: [1m[32m0.07703[0m[0m | time: 1.215s
[2K
| Adam | epoch: 015 | loss: 0.07703 - acc: 0.9733 -- iter: 0032/1395
[A[ATraining Step: 618  | total loss: [1m[32m0.07473[0m[0m | time: 2.336s
[2K
| Adam | epoch: 015 | loss: 0.07473 - acc: 0.9728 -- iter: 0064/1395
[A[ATraining Step: 619  | total loss: [1m[32m0.08357[0m[0m | time: 3.405s
[2K
| Adam | epoch: 015 | loss: 0.08357 - acc: 0.9693 -- iter: 0096/1395
[A[ATraining Step: 620  | total loss: [1m[32m0.08354[0m[0m | time: 4.574s
[2K
| Adam | epoch: 015 | loss: 0.08354 - acc: 0.9692 -- iter: 0128/1395
[A[ATraining Step: 621  | total loss: [1m[32m0.08144[0m[0m | time: 5.686s
[2K
| Adam | epoch: 015 | loss: 0.08144 - acc: 0.9692 -- iter: 0160/1395
[A[ATraining Step: 622  | total loss: [1m[32m0.07545[0m[0m | time: 6.775s
[2K
| Adam | epoch: 015 | loss: 0.07545 - acc: 0.9723 -- iter: 0192/1395
[A[ATraining Step: 623  | total loss: [1m[32m0.07090[0m[0m | time: 8.004s
[2K
| Adam | epoch: 015 | loss: 0.07090 - acc: 0.9750 -- iter: 0224/1395
[A[ATraining Step: 624  | total loss: [1m[32m0.06577[0m[0m | time: 9.233s
[2K
| Adam | epoch: 015 | loss: 0.06577 - acc: 0.9775 -- iter: 0256/1395
[A[ATraining Step: 625  | total loss: [1m[32m0.07375[0m[0m | time: 10.461s
[2K
| Adam | epoch: 015 | loss: 0.07375 - acc: 0.9735 -- iter: 0288/1395
[A[ATraining Step: 626  | total loss: [1m[32m0.08321[0m[0m | time: 11.804s
[2K
| Adam | epoch: 015 | loss: 0.08321 - acc: 0.9730 -- iter: 0320/1395
[A[ATraining Step: 627  | total loss: [1m[32m0.09417[0m[0m | time: 13.175s
[2K
| Adam | epoch: 015 | loss: 0.09417 - acc: 0.9695 -- iter: 0352/1395
[A[ATraining Step: 628  | total loss: [1m[32m0.08650[0m[0m | time: 14.373s
[2K
| Adam | epoch: 015 | loss: 0.08650 - acc: 0.9725 -- iter: 0384/1395
[A[ATraining Step: 629  | total loss: [1m[32m0.08121[0m[0m | time: 14.947s
[2K
| Adam | epoch: 015 | loss: 0.08121 - acc: 0.9753 -- iter: 0416/1395
[A[ATraining Step: 630  | total loss: [1m[32m0.08922[0m[0m | time: 15.471s
[2K
| Adam | epoch: 015 | loss: 0.08922 - acc: 0.9725 -- iter: 0448/1395
[A[ATraining Step: 631  | total loss: [1m[32m0.09477[0m[0m | time: 16.521s
[2K
| Adam | epoch: 015 | loss: 0.09477 - acc: 0.9700 -- iter: 0480/1395
[A[ATraining Step: 632  | total loss: [1m[32m0.08741[0m[0m | time: 17.654s
[2K
| Adam | epoch: 015 | loss: 0.08741 - acc: 0.9730 -- iter: 0512/1395
[A[ATraining Step: 633  | total loss: [1m[32m0.08715[0m[0m | time: 18.695s
[2K
| Adam | epoch: 015 | loss: 0.08715 - acc: 0.9726 -- iter: 0544/1395
[A[ATraining Step: 634  | total loss: [1m[32m0.09033[0m[0m | time: 19.799s
[2K
| Adam | epoch: 015 | loss: 0.09033 - acc: 0.9691 -- iter: 0576/1395
[A[ATraining Step: 635  | total loss: [1m[32m0.10533[0m[0m | time: 21.008s
[2K
| Adam | epoch: 015 | loss: 0.10533 - acc: 0.9690 -- iter: 0608/1395
[A[ATraining Step: 636  | total loss: [1m[32m0.09867[0m[0m | time: 22.379s
[2K
| Adam | epoch: 015 | loss: 0.09867 - acc: 0.9721 -- iter: 0640/1395
[A[ATraining Step: 637  | total loss: [1m[32m0.09134[0m[0m | time: 23.513s
[2K
| Adam | epoch: 015 | loss: 0.09134 - acc: 0.9749 -- iter: 0672/1395
[A[ATraining Step: 638  | total loss: [1m[32m0.08414[0m[0m | time: 24.783s
[2K
| Adam | epoch: 015 | loss: 0.08414 - acc: 0.9774 -- iter: 0704/1395
[A[ATraining Step: 639  | total loss: [1m[32m0.08998[0m[0m | time: 25.996s
[2K
| Adam | epoch: 015 | loss: 0.08998 - acc: 0.9734 -- iter: 0736/1395
[A[ATraining Step: 640  | total loss: [1m[32m0.08286[0m[0m | time: 26.989s
[2K
| Adam | epoch: 015 | loss: 0.08286 - acc: 0.9761 -- iter: 0768/1395
[A[ATraining Step: 641  | total loss: [1m[32m0.08250[0m[0m | time: 28.015s
[2K
| Adam | epoch: 015 | loss: 0.08250 - acc: 0.9754 -- iter: 0800/1395
[A[ATraining Step: 642  | total loss: [1m[32m0.07632[0m[0m | time: 29.102s
[2K
| Adam | epoch: 015 | loss: 0.07632 - acc: 0.9778 -- iter: 0832/1395
[A[ATraining Step: 643  | total loss: [1m[32m0.08139[0m[0m | time: 30.202s
[2K
| Adam | epoch: 015 | loss: 0.08139 - acc: 0.9769 -- iter: 0864/1395
[A[ATraining Step: 644  | total loss: [1m[32m0.08073[0m[0m | time: 31.354s
[2K
| Adam | epoch: 015 | loss: 0.08073 - acc: 0.9761 -- iter: 0896/1395
[A[ATraining Step: 645  | total loss: [1m[32m0.07779[0m[0m | time: 32.478s
[2K
| Adam | epoch: 015 | loss: 0.07779 - acc: 0.9785 -- iter: 0928/1395
[A[ATraining Step: 646  | total loss: [1m[32m0.07209[0m[0m | time: 33.691s
[2K
| Adam | epoch: 015 | loss: 0.07209 - acc: 0.9806 -- iter: 0960/1395
[A[ATraining Step: 647  | total loss: [1m[32m0.07915[0m[0m | time: 34.896s
[2K
| Adam | epoch: 015 | loss: 0.07915 - acc: 0.9794 -- iter: 0992/1395
[A[ATraining Step: 648  | total loss: [1m[32m0.07289[0m[0m | time: 35.853s
[2K
| Adam | epoch: 015 | loss: 0.07289 - acc: 0.9815 -- iter: 1024/1395
[A[ATraining Step: 649  | total loss: [1m[32m0.06787[0m[0m | time: 37.264s
[2K
| Adam | epoch: 015 | loss: 0.06787 - acc: 0.9834 -- iter: 1056/1395
[A[ATraining Step: 650  | total loss: [1m[32m0.06686[0m[0m | time: 38.530s
[2K
| Adam | epoch: 015 | loss: 0.06686 - acc: 0.9819 -- iter: 1088/1395
[A[ATraining Step: 651  | total loss: [1m[32m0.06121[0m[0m | time: 39.622s
[2K
| Adam | epoch: 015 | loss: 0.06121 - acc: 0.9837 -- iter: 1120/1395
[A[ATraining Step: 652  | total loss: [1m[32m0.05772[0m[0m | time: 40.858s
[2K
| Adam | epoch: 015 | loss: 0.05772 - acc: 0.9853 -- iter: 1152/1395
[A[ATraining Step: 653  | total loss: [1m[32m0.05303[0m[0m | time: 42.034s
[2K
| Adam | epoch: 015 | loss: 0.05303 - acc: 0.9868 -- iter: 1184/1395
[A[ATraining Step: 654  | total loss: [1m[32m0.05616[0m[0m | time: 43.054s
[2K
| Adam | epoch: 015 | loss: 0.05616 - acc: 0.9850 -- iter: 1216/1395
[A[ATraining Step: 655  | total loss: [1m[32m0.05099[0m[0m | time: 44.189s
[2K
| Adam | epoch: 015 | loss: 0.05099 - acc: 0.9865 -- iter: 1248/1395
[A[ATraining Step: 656  | total loss: [1m[32m0.04968[0m[0m | time: 45.359s
[2K
| Adam | epoch: 015 | loss: 0.04968 - acc: 0.9878 -- iter: 1280/1395
[A[ATraining Step: 657  | total loss: [1m[32m0.04573[0m[0m | time: 46.566s
[2K
| Adam | epoch: 015 | loss: 0.04573 - acc: 0.9891 -- iter: 1312/1395
[A[ATraining Step: 658  | total loss: [1m[32m0.04169[0m[0m | time: 47.674s
[2K
| Adam | epoch: 015 | loss: 0.04169 - acc: 0.9902 -- iter: 1344/1395
[A[ATraining Step: 659  | total loss: [1m[32m0.05302[0m[0m | time: 48.748s
[2K
| Adam | epoch: 015 | loss: 0.05302 - acc: 0.9849 -- iter: 1376/1395
[A[ATraining Step: 660  | total loss: [1m[32m0.06265[0m[0m | time: 53.316s
[2K
| Adam | epoch: 015 | loss: 0.06265 - acc: 0.9802 | val_loss: 0.48240 - val_acc: 0.8787 -- iter: 1395/1395
--
2018-08-01 22:46:35.197816: W tensorflow/core/framework/allocator.cc:101] Allocation of 3957807616 exceeds 10% of system memory.
2018-08-01 22:46:45.298063: W tensorflow/core/framework/allocator.cc:101] Allocation of 3957807616 exceeds 10% of system memory.
Validation AUC:0.9339486832077231
Validation AUPRC:0.9245606439774529
Test AUC:0.9564465806560418
Test AUPRC:0.9539489216863057
BestTestF1Score	0.89	0.81	0.9	0.93	0.86	173	14	222	28	0.44
BestTestMCCScore	0.89	0.8	0.9	0.92	0.86	172	14	222	29	0.47
BestTestAccuracyScore	0.89	0.8	0.9	0.92	0.86	172	14	222	29	0.47
BestValidationF1Score	0.86	0.76	0.88	0.91	0.83	162	17	224	34	0.44
BestValidationMCC	0.86	0.76	0.88	0.91	0.82	161	16	225	35	0.47
BestValidationAccuracy	0.86	0.76	0.88	0.91	0.82	161	16	225	35	0.47
TestPredictions (Threshold:0.47)
CHEMBL3298747,TP,ACT,0.9800000190734863	CHEMBL60435,TN,INACT,0.0	CHEMBL3739533,TP,ACT,0.9100000262260437	CHEMBL24777,TP,ACT,0.9900000095367432	CHEMBL64727,TN,INACT,0.009999999776482582	CHEMBL304591,TP,ACT,0.9800000190734863	CHEMBL49,TP,ACT,0.9399999976158142	CHEMBL171108,TN,INACT,0.0	CHEMBL1242542,TP,ACT,0.9700000286102295	CHEMBL267336,FN,ACT,0.0	CHEMBL301077,TP,ACT,1.0	CHEMBL926,FN,ACT,0.0	CHEMBL330003,TN,INACT,0.0	CHEMBL303339,TN,INACT,0.0	CHEMBL335971,TN,INACT,0.0	CHEMBL100624,TN,INACT,0.0	CHEMBL42129,TN,INACT,0.0	CHEMBL1242724,TP,ACT,0.9900000095367432	CHEMBL70691,TP,ACT,0.9200000166893005	CHEMBL301726,TP,ACT,1.0	CHEMBL145338,TP,ACT,1.0	CHEMBL3234532,TN,INACT,0.0	CHEMBL1203850,TP,ACT,1.0	CHEMBL3741260,TP,ACT,1.0	CHEMBL3298018,FN,ACT,0.05000000074505806	CHEMBL236832,TP,ACT,1.0	CHEMBL125588,TN,INACT,0.009999999776482582	CHEMBL199080,TP,ACT,1.0	CHEMBL516334,FP,INACT,1.0	CHEMBL42763,TP,ACT,0.9900000095367432	CHEMBL107680,FP,INACT,0.8199999928474426	CHEMBL1944689,FN,ACT,0.3799999952316284	CHEMBL140984,TN,INACT,0.0	CHEMBL154023,TP,ACT,0.9900000095367432	CHEMBL389390,TN,INACT,0.0	CHEMBL145746,TP,ACT,1.0	CHEMBL40317,TN,INACT,0.0	CHEMBL3403333,TN,INACT,0.009999999776482582	CHEMBL1258371,TN,INACT,0.05000000074505806	CHEMBL112777,TN,INACT,0.0	CHEMBL357439,TP,ACT,0.5099999904632568	CHEMBL327626,TN,INACT,0.07000000029802322	CHEMBL62066,TN,INACT,0.0	CHEMBL177860,TN,INACT,0.33000001311302185	CHEMBL62911,TN,INACT,0.009999999776482582	CHEMBL62601,TN,INACT,0.0	CHEMBL1630941,TP,ACT,0.9800000190734863	CHEMBL493285,TP,ACT,1.0	CHEMBL52485,TN,INACT,0.0	CHEMBL296395,TN,INACT,0.0	CHEMBL65461,TN,INACT,0.0	CHEMBL292189,TP,ACT,1.0	CHEMBL126472,TN,INACT,0.07999999821186066	CHEMBL2441082,FN,ACT,0.05000000074505806	CHEMBL173629,TN,INACT,0.0	CHEMBL287562,TN,INACT,0.0	CHEMBL54885,TN,INACT,0.0	CHEMBL303204,TN,INACT,0.0	CHEMBL1944692,TP,ACT,0.5899999737739563	CHEMBL80505,TN,INACT,0.009999999776482582	CHEMBL357172,TP,ACT,1.0	CHEMBL3586323,TN,INACT,0.0	CHEMBL298203,TN,INACT,0.0	CHEMBL3809093,TP,ACT,0.8899999856948853	CHEMBL262217,TP,ACT,1.0	CHEMBL228389,TP,ACT,1.0	CHEMBL105594,TN,INACT,0.0	CHEMBL3800485,TP,ACT,1.0	CHEMBL417350,TP,ACT,1.0	CHEMBL423260,TN,INACT,0.009999999776482582	CHEMBL77618,TP,ACT,1.0	CHEMBL13735,TP,ACT,0.9900000095367432	CHEMBL26782,TN,INACT,0.0	CHEMBL11467,TN,INACT,0.0	CHEMBL41818,TN,INACT,0.0	CHEMBL147365,TN,INACT,0.0	CHEMBL3342854,TP,ACT,0.9900000095367432	CHEMBL76949,TN,INACT,0.09000000357627869	CHEMBL180343,TN,INACT,0.0	CHEMBL467094,FN,ACT,0.009999999776482582	CHEMBL6437,FN,ACT,0.009999999776482582	CHEMBL1254914,FN,ACT,0.4300000071525574	CHEMBL327597,TN,INACT,0.0	CHEMBL3104091,TP,ACT,0.9100000262260437	CHEMBL220221,TP,ACT,1.0	CHEMBL300725,TN,INACT,0.0	CHEMBL3298745,TP,ACT,0.9900000095367432	CHEMBL296715,TN,INACT,0.0	CHEMBL2093084,TN,INACT,0.0	CHEMBL369359,TN,INACT,0.0	CHEMBL174463,TN,INACT,0.009999999776482582	CHEMBL387832,TP,ACT,1.0	CHEMBL351531,TN,INACT,0.009999999776482582	CHEMBL264761,TN,INACT,0.0	CHEMBL3115577,TN,INACT,0.0	CHEMBL109206,TN,INACT,0.0	CHEMBL3403339,TN,INACT,0.0	CHEMBL273890,FP,INACT,0.9800000190734863	CHEMBL133257,TN,INACT,0.0	CHEMBL316968,TN,INACT,0.0	CHEMBL3808981,TP,ACT,0.9900000095367432	CHEMBL323854,TN,INACT,0.0	CHEMBL301559,TN,INACT,0.0	CHEMBL539334,TN,INACT,0.0	CHEMBL135973,FN,ACT,0.10000000149011612	CHEMBL144938,TP,ACT,1.0	CHEMBL84165,TN,INACT,0.0	CHEMBL54266,TN,INACT,0.0	CHEMBL233814,TP,ACT,1.0	CHEMBL78080,TN,INACT,0.0	CHEMBL106487,TN,INACT,0.0	CHEMBL72147,FN,ACT,0.10000000149011612	CHEMBL284965,TN,INACT,0.0	CHEMBL116700,TP,ACT,1.0	CHEMBL3335536,TN,INACT,0.0	CHEMBL964,FP,INACT,0.9700000286102295	CHEMBL330401,TP,ACT,0.8700000047683716	CHEMBL281214,TN,INACT,0.0	CHEMBL494908,TP,ACT,0.9900000095367432	CHEMBL417215,TN,INACT,0.0	CHEMBL78929,TN,INACT,0.07000000029802322	CHEMBL3342867,TP,ACT,1.0	CHEMBL558890,TP,ACT,0.7099999785423279	CHEMBL303369,TN,INACT,0.0	CHEMBL219718,TP,ACT,0.8700000047683716	CHEMBL53675,TP,ACT,0.9599999785423279	CHEMBL97436,TN,INACT,0.0	CHEMBL157138,FN,ACT,0.009999999776482582	CHEMBL12127,TP,ACT,0.9900000095367432	CHEMBL1946778,TP,ACT,0.6299999952316284	CHEMBL10494,TN,INACT,0.029999999329447746	CHEMBL145394,TP,ACT,1.0	CHEMBL2164609,TN,INACT,0.0	CHEMBL396271,TN,INACT,0.0	CHEMBL310250,TN,INACT,0.0	CHEMBL3290971,TN,INACT,0.0	CHEMBL3342865,TP,ACT,0.9900000095367432	CHEMBL15936,TN,INACT,0.0	CHEMBL12344,FP,INACT,0.8999999761581421	CHEMBL1084009,TN,INACT,0.0	CHEMBL293577,TN,INACT,0.0	CHEMBL88628,TP,ACT,1.0	CHEMBL299539,TP,ACT,1.0	CHEMBL594803,TN,INACT,0.0	CHEMBL2443005,TN,INACT,0.0	CHEMBL3298021,TP,ACT,0.9800000190734863	CHEMBL445,TP,ACT,0.9800000190734863	CHEMBL326877,TN,INACT,0.0	CHEMBL3084424,TN,INACT,0.0	CHEMBL299524,TN,INACT,0.0	CHEMBL72841,TN,INACT,0.029999999329447746	CHEMBL3797529,TP,ACT,1.0	CHEMBL1774995,TP,ACT,0.7900000214576721	CHEMBL172788,TN,INACT,0.0	CHEMBL313990,TP,ACT,0.9900000095367432	CHEMBL54051,TN,INACT,0.0	CHEMBL146983,TN,INACT,0.009999999776482582	CHEMBL197159,TN,INACT,0.009999999776482582	CHEMBL358785,TP,ACT,1.0	CHEMBL43905,TP,ACT,1.0	CHEMBL429697,TP,ACT,0.7099999785423279	CHEMBL96467,TP,ACT,1.0	CHEMBL357131,TP,ACT,1.0	CHEMBL279516,TP,ACT,1.0	CHEMBL1946785,FN,ACT,0.27000001072883606	CHEMBL1255086,FN,ACT,0.009999999776482582	CHEMBL109926,TN,INACT,0.0	CHEMBL1796037,TP,ACT,1.0	CHEMBL95727,TN,INACT,0.0	CHEMBL137478,TN,INACT,0.029999999329447746	CHEMBL2261608,FN,ACT,0.09000000357627869	CHEMBL243692,TP,ACT,0.5299999713897705	CHEMBL10347,TP,ACT,0.6499999761581421	CHEMBL40796,TN,INACT,0.0	CHEMBL24586,TN,INACT,0.0	CHEMBL320569,TN,INACT,0.0	CHEMBL302359,TN,INACT,0.0	CHEMBL69848,TP,ACT,1.0	CHEMBL419617,TN,INACT,0.009999999776482582	CHEMBL1744267,TP,ACT,0.9900000095367432	CHEMBL303538,TN,INACT,0.009999999776482582	CHEMBL41959,TP,ACT,0.5899999737739563	CHEMBL394642,TN,INACT,0.41999998688697815	CHEMBL387825,TN,INACT,0.0	CHEMBL401798,TN,INACT,0.10999999940395355	CHEMBL320174,TN,INACT,0.009999999776482582	CHEMBL2419770,TP,ACT,0.9900000095367432	CHEMBL88629,TN,INACT,0.0	CHEMBL150696,FP,INACT,1.0	CHEMBL359141,TN,INACT,0.009999999776482582	CHEMBL512542,TN,INACT,0.0	CHEMBL123349,FN,ACT,0.019999999552965164	CHEMBL47018,TN,INACT,0.0	CHEMBL51888,TN,INACT,0.0	CHEMBL70840,TN,INACT,0.0	CHEMBL95191,FN,ACT,0.009999999776482582	CHEMBL177546,TN,INACT,0.009999999776482582	CHEMBL62660,TN,INACT,0.0	CHEMBL68203,TP,ACT,0.9700000286102295	CHEMBL298838,TP,ACT,0.8799999952316284	CHEMBL3808408,TP,ACT,1.0	CHEMBL442740,TN,INACT,0.3700000047683716	CHEMBL39334,TN,INACT,0.0	CHEMBL306792,TP,ACT,1.0	CHEMBL357828,TP,ACT,1.0	CHEMBL51074,TP,ACT,0.6200000047683716	CHEMBL461087,TN,INACT,0.0	CHEMBL1946787,TP,ACT,0.9599999785423279	CHEMBL7185,TN,INACT,0.0	CHEMBL33720,TN,INACT,0.0	CHEMBL125365,TP,ACT,0.8600000143051147	CHEMBL440864,TN,INACT,0.0	CHEMBL74283,FN,ACT,0.4399999976158142	CHEMBL272873,TN,INACT,0.0	CHEMBL301707,TP,ACT,1.0	CHEMBL80458,TP,ACT,0.9900000095367432	CHEMBL41844,TP,ACT,1.0	CHEMBL513277,TN,INACT,0.019999999552965164	CHEMBL357077,TN,INACT,0.0	CHEMBL64321,TN,INACT,0.0	CHEMBL279520,TN,INACT,0.0	CHEMBL290860,TP,ACT,1.0	CHEMBL142398,TP,ACT,1.0	CHEMBL1789975,TP,ACT,0.9700000286102295	CHEMBL275469,TP,ACT,1.0	CHEMBL104848,TN,INACT,0.0	CHEMBL229085,TP,ACT,1.0	CHEMBL80036,TP,ACT,0.5400000214576721	CHEMBL41948,TN,INACT,0.0	CHEMBL114074,TN,INACT,0.0	CHEMBL1945040,TP,ACT,1.0	CHEMBL344154,TN,INACT,0.05000000074505806	CHEMBL45418,TN,INACT,0.0	CHEMBL1744292,TP,ACT,0.5899999737739563	CHEMBL105483,TN,INACT,0.0	CHEMBL343969,FP,INACT,0.5199999809265137	CHEMBL320736,TP,ACT,1.0	CHEMBL160932,TN,INACT,0.0	CHEMBL1796028,TP,ACT,1.0	CHEMBL3342860,TP,ACT,0.9800000190734863	CHEMBL405292,TN,INACT,0.019999999552965164	CHEMBL323951,TN,INACT,0.0	CHEMBL37736,TN,INACT,0.019999999552965164	CHEMBL44134,TN,INACT,0.0	CHEMBL91,FN,ACT,0.46000000834465027	CHEMBL320779,TN,INACT,0.27000001072883606	CHEMBL1255003,TP,ACT,1.0	CHEMBL420205,TP,ACT,0.9599999785423279	CHEMBL321644,TN,INACT,0.0	CHEMBL79161,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.009999999776482582	CHEMBL3342875,FN,ACT,0.0	CHEMBL329861,TN,INACT,0.0	CHEMBL40966,TN,INACT,0.009999999776482582	CHEMBL307326,TN,INACT,0.009999999776482582	CHEMBL3342869,FN,ACT,0.0	CHEMBL144114,TN,INACT,0.029999999329447746	CHEMBL251997,TN,INACT,0.0	CHEMBL310425,FP,INACT,0.7300000190734863	CHEMBL3809840,TP,ACT,1.0	CHEMBL90420,TP,ACT,1.0	CHEMBL53520,TN,INACT,0.0	CHEMBL312266,TN,INACT,0.0	CHEMBL95263,TP,ACT,0.9800000190734863	CHEMBL305558,TN,INACT,0.0	CHEMBL66789,TN,INACT,0.0	CHEMBL8809,TN,INACT,0.009999999776482582	CHEMBL1910140,TP,ACT,1.0	CHEMBL345951,TN,INACT,0.0	CHEMBL602474,TN,INACT,0.05000000074505806	CHEMBL43064,FN,ACT,0.0	CHEMBL431631,TP,ACT,0.6399999856948853	CHEMBL3343979,TP,ACT,1.0	CHEMBL193337,TN,INACT,0.009999999776482582	CHEMBL2153556,TP,ACT,1.0	CHEMBL214552,TP,ACT,0.9900000095367432	CHEMBL132179,TN,INACT,0.0	CHEMBL23529,TN,INACT,0.009999999776482582	CHEMBL144534,TP,ACT,1.0	CHEMBL3799155,TP,ACT,1.0	CHEMBL292365,TP,ACT,1.0	CHEMBL233582,TP,ACT,1.0	CHEMBL394139,TP,ACT,1.0	CHEMBL234669,TP,ACT,1.0	CHEMBL40986,TN,INACT,0.0	CHEMBL228390,TP,ACT,1.0	CHEMBL236617,TP,ACT,1.0	CHEMBL358595,TP,ACT,1.0	CHEMBL3342853,TP,ACT,1.0	CHEMBL111694,TN,INACT,0.0	CHEMBL68746,TP,ACT,1.0	CHEMBL169553,TN,INACT,0.009999999776482582	CHEMBL78669,TN,INACT,0.0	CHEMBL83272,TP,ACT,1.0	CHEMBL81173,TP,ACT,1.0	CHEMBL1626,FN,ACT,0.029999999329447746	CHEMBL156661,TP,ACT,1.0	CHEMBL1077168,TP,ACT,1.0	CHEMBL1201203,FN,ACT,0.4300000071525574	CHEMBL145574,TP,ACT,1.0	CHEMBL522460,TP,ACT,0.9800000190734863	CHEMBL43512,TN,INACT,0.009999999776482582	CHEMBL3799486,TP,ACT,1.0	CHEMBL145525,TP,ACT,1.0	CHEMBL3099661,TN,INACT,0.0	CHEMBL59590,TP,ACT,1.0	CHEMBL633,TN,INACT,0.0	CHEMBL3810198,TP,ACT,1.0	CHEMBL2443006,TN,INACT,0.0	CHEMBL1945300,FN,ACT,0.0	CHEMBL438915,TN,INACT,0.0	CHEMBL3809314,TP,ACT,1.0	CHEMBL293956,TN,INACT,0.0	CHEMBL252232,TN,INACT,0.0	CHEMBL302150,TN,INACT,0.0	CHEMBL3423400,TN,INACT,0.009999999776482582	CHEMBL298286,TN,INACT,0.019999999552965164	CHEMBL1946781,FN,ACT,0.4000000059604645	CHEMBL3342873,TP,ACT,0.9900000095367432	CHEMBL74066,TN,INACT,0.0	CHEMBL3349545,TP,ACT,0.8999999761581421	CHEMBL429644,TN,INACT,0.0	CHEMBL229615,TN,INACT,0.0	CHEMBL392377,TP,ACT,1.0	CHEMBL91405,FN,ACT,0.11999999731779099	CHEMBL283535,TN,INACT,0.0	CHEMBL315974,TN,INACT,0.0	CHEMBL593620,TN,INACT,0.009999999776482582	CHEMBL1944691,TP,ACT,1.0	CHEMBL723,TP,ACT,1.0	CHEMBL3741161,TP,ACT,1.0	CHEMBL1945042,TP,ACT,1.0	CHEMBL145562,TP,ACT,0.9800000190734863	CHEMBL90374,TN,INACT,0.0	CHEMBL14149,FP,INACT,0.9900000095367432	CHEMBL229390,TN,INACT,0.0	CHEMBL257957,TN,INACT,0.009999999776482582	CHEMBL552615,TN,INACT,0.0	CHEMBL160626,TN,INACT,0.0	CHEMBL233407,TP,ACT,1.0	CHEMBL92539,TN,INACT,0.0	CHEMBL199186,TN,INACT,0.0	CHEMBL145072,TP,ACT,1.0	CHEMBL314960,TP,ACT,1.0	CHEMBL452150,TN,INACT,0.03999999910593033	CHEMBL65710,TN,INACT,0.009999999776482582	CHEMBL56331,TP,ACT,0.9300000071525574	CHEMBL342062,TP,ACT,1.0	CHEMBL31410,TP,ACT,0.5600000023841858	CHEMBL446693,TN,INACT,0.3799999952316284	CHEMBL431362,TP,ACT,1.0	CHEMBL91415,TP,ACT,1.0	CHEMBL169631,TN,INACT,0.0	CHEMBL3741079,TP,ACT,1.0	CHEMBL49932,TN,INACT,0.0	CHEMBL44615,TN,INACT,0.0	CHEMBL3342861,TP,ACT,1.0	CHEMBL1076625,TN,INACT,0.0	CHEMBL47040,TN,INACT,0.2199999988079071	CHEMBL340501,TN,INACT,0.029999999329447746	CHEMBL413040,TN,INACT,0.0	CHEMBL389129,FP,INACT,0.949999988079071	CHEMBL2062860,TN,INACT,0.0	CHEMBL3740019,TP,ACT,1.0	CHEMBL400404,TN,INACT,0.009999999776482582	CHEMBL709,TP,ACT,0.9800000190734863	CHEMBL145553,TP,ACT,1.0	CHEMBL162095,TN,INACT,0.0	CHEMBL593443,TN,INACT,0.009999999776482582	CHEMBL79817,FN,ACT,0.0	CHEMBL594801,TN,INACT,0.009999999776482582	CHEMBL200136,TP,ACT,1.0	CHEMBL291306,TN,INACT,0.0	CHEMBL3800636,TN,INACT,0.12999999523162842	CHEMBL228334,TP,ACT,1.0	CHEMBL303203,TN,INACT,0.0	CHEMBL3341769,TP,ACT,0.8600000143051147	CHEMBL593685,TN,INACT,0.009999999776482582	CHEMBL238402,TP,ACT,1.0	CHEMBL1782794,TN,INACT,0.0	CHEMBL2112853,FN,ACT,0.10999999940395355	CHEMBL62716,TN,INACT,0.0	CHEMBL351183,TN,INACT,0.0	CHEMBL291951,TP,ACT,1.0	CHEMBL323517,TN,INACT,0.0	CHEMBL95986,TN,INACT,0.019999999552965164	CHEMBL1796033,TP,ACT,1.0	CHEMBL3403336,TN,INACT,0.38999998569488525	CHEMBL352779,TN,INACT,0.0	CHEMBL3809532,TP,ACT,0.8199999928474426	CHEMBL334933,TN,INACT,0.019999999552965164	CHEMBL391107,TP,ACT,1.0	CHEMBL3764306,TN,INACT,0.30000001192092896	CHEMBL78785,TP,ACT,1.0	CHEMBL51675,TN,INACT,0.17000000178813934	CHEMBL554950,TN,INACT,0.0	CHEMBL3799912,TP,ACT,1.0	CHEMBL284912,TN,INACT,0.0	CHEMBL298713,TP,ACT,1.0	CHEMBL432026,TP,ACT,0.9900000095367432	CHEMBL1169493,FN,ACT,0.3400000035762787	CHEMBL78601,TN,INACT,0.0	CHEMBL212631,TN,INACT,0.41999998688697815	CHEMBL280223,TN,INACT,0.0	CHEMBL717,FP,INACT,0.7599999904632568	CHEMBL59,TN,INACT,0.0	CHEMBL95736,TP,ACT,1.0	CHEMBL266290,TN,INACT,0.009999999776482582	CHEMBL143341,TN,INACT,0.0	CHEMBL105515,TN,INACT,0.019999999552965164	CHEMBL256041,TP,ACT,0.9900000095367432	CHEMBL432144,TN,INACT,0.0	CHEMBL493486,TP,ACT,0.9900000095367432	CHEMBL193620,TP,ACT,0.8899999856948853	CHEMBL1644484,TN,INACT,0.0	CHEMBL561262,FP,INACT,0.8899999856948853	CHEMBL629,TP,ACT,0.9900000095367432	CHEMBL3810110,TP,ACT,1.0	CHEMBL151668,FP,INACT,1.0	CHEMBL112770,TN,INACT,0.0	CHEMBL218079,TP,ACT,1.0	CHEMBL327931,TP,ACT,1.0	CHEMBL305371,TN,INACT,0.0	CHEMBL2425370,FP,INACT,0.5099999904632568	CHEMBL145793,TP,ACT,0.8500000238418579	CHEMBL565799,TN,INACT,0.0	CHEMBL359433,TP,ACT,1.0	CHEMBL429623,TP,ACT,1.0	CHEMBL309017,TN,INACT,0.05000000074505806	CHEMBL10879,TN,INACT,0.0	CHEMBL444128,TN,INACT,0.0	CHEMBL442059,TP,ACT,1.0	CHEMBL233592,TP,ACT,1.0	CHEMBL481415,TN,INACT,0.009999999776482582	CHEMBL52625,TN,INACT,0.0	CHEMBL354748,TN,INACT,0.009999999776482582	CHEMBL284103,TP,ACT,1.0	

