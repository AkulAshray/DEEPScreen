CNNModel CHEMBL3772 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	379
Number of inactive compounds :	379
---------------------------------
Run id: CNNModel_CHEMBL3772_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3772_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 480
Validation samples: 150
--
Training Step: 1  | time: 0.787s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/480
[A[ATraining Step: 2  | total loss: [1m[32m0.62384[0m[0m | time: 1.398s
[2K
| Adam | epoch: 001 | loss: 0.62384 - acc: 0.3937 -- iter: 064/480
[A[ATraining Step: 3  | total loss: [1m[32m0.68081[0m[0m | time: 2.012s
[2K
| Adam | epoch: 001 | loss: 0.68081 - acc: 0.4551 -- iter: 096/480
[A[ATraining Step: 4  | total loss: [1m[32m0.69165[0m[0m | time: 2.613s
[2K
| Adam | epoch: 001 | loss: 0.69165 - acc: 0.4185 -- iter: 128/480
[A[ATraining Step: 5  | total loss: [1m[32m0.69182[0m[0m | time: 3.210s
[2K
| Adam | epoch: 001 | loss: 0.69182 - acc: 0.5398 -- iter: 160/480
[A[ATraining Step: 6  | total loss: [1m[32m0.69228[0m[0m | time: 3.830s
[2K
| Adam | epoch: 001 | loss: 0.69228 - acc: 0.5343 -- iter: 192/480
[A[ATraining Step: 7  | total loss: [1m[32m0.69240[0m[0m | time: 4.435s
[2K
| Adam | epoch: 001 | loss: 0.69240 - acc: 0.5325 -- iter: 224/480
[A[ATraining Step: 8  | total loss: [1m[32m0.69053[0m[0m | time: 5.058s
[2K
| Adam | epoch: 001 | loss: 0.69053 - acc: 0.5845 -- iter: 256/480
[A[ATraining Step: 9  | total loss: [1m[32m0.69207[0m[0m | time: 5.698s
[2K
| Adam | epoch: 001 | loss: 0.69207 - acc: 0.5398 -- iter: 288/480
[A[ATraining Step: 10  | total loss: [1m[32m0.69815[0m[0m | time: 6.334s
[2K
| Adam | epoch: 001 | loss: 0.69815 - acc: 0.4574 -- iter: 320/480
[A[ATraining Step: 11  | total loss: [1m[32m0.69761[0m[0m | time: 6.950s
[2K
| Adam | epoch: 001 | loss: 0.69761 - acc: 0.4480 -- iter: 352/480
[A[ATraining Step: 12  | total loss: [1m[32m0.69326[0m[0m | time: 7.557s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.5276 -- iter: 384/480
[A[ATraining Step: 13  | total loss: [1m[32m0.69060[0m[0m | time: 8.171s
[2K
| Adam | epoch: 001 | loss: 0.69060 - acc: 0.5828 -- iter: 416/480
[A[ATraining Step: 14  | total loss: [1m[32m0.69021[0m[0m | time: 8.791s
[2K
| Adam | epoch: 001 | loss: 0.69021 - acc: 0.5873 -- iter: 448/480
[A[ATraining Step: 15  | total loss: [1m[32m0.69094[0m[0m | time: 10.425s
[2K
| Adam | epoch: 001 | loss: 0.69094 - acc: 0.5531 | val_loss: 0.69812 - val_acc: 0.4400 -- iter: 480/480
--
Training Step: 16  | total loss: [1m[32m0.68984[0m[0m | time: 0.617s
[2K
| Adam | epoch: 002 | loss: 0.68984 - acc: 0.5684 -- iter: 032/480
[A[ATraining Step: 17  | total loss: [1m[32m0.68830[0m[0m | time: 1.226s
[2K
| Adam | epoch: 002 | loss: 0.68830 - acc: 0.5775 -- iter: 064/480
[A[ATraining Step: 18  | total loss: [1m[32m0.69022[0m[0m | time: 1.838s
[2K
| Adam | epoch: 002 | loss: 0.69022 - acc: 0.5507 -- iter: 096/480
[A[ATraining Step: 19  | total loss: [1m[32m0.68892[0m[0m | time: 2.457s
[2K
| Adam | epoch: 002 | loss: 0.68892 - acc: 0.5546 -- iter: 128/480
[A[ATraining Step: 20  | total loss: [1m[32m0.68198[0m[0m | time: 3.053s
[2K
| Adam | epoch: 002 | loss: 0.68198 - acc: 0.5873 -- iter: 160/480
[A[ATraining Step: 21  | total loss: [1m[32m0.68662[0m[0m | time: 3.664s
[2K
| Adam | epoch: 002 | loss: 0.68662 - acc: 0.5602 -- iter: 192/480
[A[ATraining Step: 22  | total loss: [1m[32m0.69162[0m[0m | time: 4.264s
[2K
| Adam | epoch: 002 | loss: 0.69162 - acc: 0.5421 -- iter: 224/480
[A[ATraining Step: 23  | total loss: [1m[32m0.68269[0m[0m | time: 4.874s
[2K
| Adam | epoch: 002 | loss: 0.68269 - acc: 0.5662 -- iter: 256/480
[A[ATraining Step: 24  | total loss: [1m[32m0.67733[0m[0m | time: 5.478s
[2K
| Adam | epoch: 002 | loss: 0.67733 - acc: 0.5827 -- iter: 288/480
[A[ATraining Step: 25  | total loss: [1m[32m0.67839[0m[0m | time: 6.092s
[2K
| Adam | epoch: 002 | loss: 0.67839 - acc: 0.5772 -- iter: 320/480
[A[ATraining Step: 26  | total loss: [1m[32m0.67400[0m[0m | time: 6.700s
[2K
| Adam | epoch: 002 | loss: 0.67400 - acc: 0.5899 -- iter: 352/480
[A[ATraining Step: 27  | total loss: [1m[32m0.68594[0m[0m | time: 7.311s
[2K
| Adam | epoch: 002 | loss: 0.68594 - acc: 0.5668 -- iter: 384/480
[A[ATraining Step: 28  | total loss: [1m[32m0.71583[0m[0m | time: 7.915s
[2K
| Adam | epoch: 002 | loss: 0.71583 - acc: 0.4954 -- iter: 416/480
[A[ATraining Step: 29  | total loss: [1m[32m0.70964[0m[0m | time: 8.525s
[2K
| Adam | epoch: 002 | loss: 0.70964 - acc: 0.5041 -- iter: 448/480
[A[ATraining Step: 30  | total loss: [1m[32m0.70624[0m[0m | time: 10.153s
[2K
| Adam | epoch: 002 | loss: 0.70624 - acc: 0.5031 | val_loss: 0.69715 - val_acc: 0.4400 -- iter: 480/480
--
Training Step: 31  | total loss: [1m[32m0.70794[0m[0m | time: 0.757s
[2K
| Adam | epoch: 003 | loss: 0.70794 - acc: 0.4664 -- iter: 032/480
[A[ATraining Step: 32  | total loss: [1m[32m0.70221[0m[0m | time: 1.468s
[2K
| Adam | epoch: 003 | loss: 0.70221 - acc: 0.5020 -- iter: 064/480
[A[ATraining Step: 33  | total loss: [1m[32m0.69850[0m[0m | time: 2.191s
[2K
| Adam | epoch: 003 | loss: 0.69850 - acc: 0.5290 -- iter: 096/480
[A[ATraining Step: 34  | total loss: [1m[32m0.69654[0m[0m | time: 2.918s
[2K
| Adam | epoch: 003 | loss: 0.69654 - acc: 0.5429 -- iter: 128/480
[A[ATraining Step: 35  | total loss: [1m[32m0.69525[0m[0m | time: 3.667s
[2K
| Adam | epoch: 003 | loss: 0.69525 - acc: 0.5470 -- iter: 160/480
[A[ATraining Step: 36  | total loss: [1m[32m0.69498[0m[0m | time: 4.387s
[2K
| Adam | epoch: 003 | loss: 0.69498 - acc: 0.5310 -- iter: 192/480
[A[ATraining Step: 37  | total loss: [1m[32m0.69438[0m[0m | time: 5.112s
[2K
| Adam | epoch: 003 | loss: 0.69438 - acc: 0.5310 -- iter: 224/480
[A[ATraining Step: 38  | total loss: [1m[32m0.69390[0m[0m | time: 5.850s
[2K
| Adam | epoch: 003 | loss: 0.69390 - acc: 0.5311 -- iter: 256/480
[A[ATraining Step: 39  | total loss: [1m[32m0.69397[0m[0m | time: 6.597s
[2K
| Adam | epoch: 003 | loss: 0.69397 - acc: 0.5132 -- iter: 288/480
[A[ATraining Step: 40  | total loss: [1m[32m0.69397[0m[0m | time: 7.272s
[2K
| Adam | epoch: 003 | loss: 0.69397 - acc: 0.4990 -- iter: 320/480
[A[ATraining Step: 41  | total loss: [1m[32m0.69391[0m[0m | time: 8.173s
[2K
| Adam | epoch: 003 | loss: 0.69391 - acc: 0.4934 -- iter: 352/480
[A[ATraining Step: 42  | total loss: [1m[32m0.69364[0m[0m | time: 8.784s
[2K
| Adam | epoch: 003 | loss: 0.69364 - acc: 0.5002 -- iter: 384/480
[A[ATraining Step: 43  | total loss: [1m[32m0.69317[0m[0m | time: 9.374s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.5223 -- iter: 416/480
[A[ATraining Step: 44  | total loss: [1m[32m0.69301[0m[0m | time: 9.978s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5238 -- iter: 448/480
[A[ATraining Step: 45  | total loss: [1m[32m0.69274[0m[0m | time: 11.595s
[2K
| Adam | epoch: 003 | loss: 0.69274 - acc: 0.5357 | val_loss: 0.69373 - val_acc: 0.4400 -- iter: 480/480
--
Training Step: 46  | total loss: [1m[32m0.69272[0m[0m | time: 0.720s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.5297 -- iter: 032/480
[A[ATraining Step: 47  | total loss: [1m[32m0.69282[0m[0m | time: 1.439s
[2K
| Adam | epoch: 004 | loss: 0.69282 - acc: 0.5198 -- iter: 064/480
[A[ATraining Step: 48  | total loss: [1m[32m0.69242[0m[0m | time: 2.174s
[2K
| Adam | epoch: 004 | loss: 0.69242 - acc: 0.5367 -- iter: 096/480
[A[ATraining Step: 49  | total loss: [1m[32m0.69208[0m[0m | time: 2.886s
[2K
| Adam | epoch: 004 | loss: 0.69208 - acc: 0.5506 -- iter: 128/480
[A[ATraining Step: 50  | total loss: [1m[32m0.69204[0m[0m | time: 3.620s
[2K
| Adam | epoch: 004 | loss: 0.69204 - acc: 0.5476 -- iter: 160/480
[A[ATraining Step: 51  | total loss: [1m[32m0.69213[0m[0m | time: 4.366s
[2K
| Adam | epoch: 004 | loss: 0.69213 - acc: 0.5404 -- iter: 192/480
[A[ATraining Step: 52  | total loss: [1m[32m0.69224[0m[0m | time: 5.074s
[2K
| Adam | epoch: 004 | loss: 0.69224 - acc: 0.5296 -- iter: 224/480
[A[ATraining Step: 53  | total loss: [1m[32m0.69229[0m[0m | time: 5.828s
[2K
| Adam | epoch: 004 | loss: 0.69229 - acc: 0.5252 -- iter: 256/480
[A[ATraining Step: 54  | total loss: [1m[32m0.69214[0m[0m | time: 6.552s
[2K
| Adam | epoch: 004 | loss: 0.69214 - acc: 0.5261 -- iter: 288/480
[A[ATraining Step: 55  | total loss: [1m[32m0.69201[0m[0m | time: 7.354s
[2K
| Adam | epoch: 004 | loss: 0.69201 - acc: 0.5313 -- iter: 320/480
[A[ATraining Step: 56  | total loss: [1m[32m0.69155[0m[0m | time: 7.972s
[2K
| Adam | epoch: 004 | loss: 0.69155 - acc: 0.5577 -- iter: 352/480
[A[ATraining Step: 57  | total loss: [1m[32m0.69140[0m[0m | time: 8.578s
[2K
| Adam | epoch: 004 | loss: 0.69140 - acc: 0.5497 -- iter: 384/480
[A[ATraining Step: 58  | total loss: [1m[32m0.69127[0m[0m | time: 9.182s
[2K
| Adam | epoch: 004 | loss: 0.69127 - acc: 0.5514 -- iter: 416/480
[A[ATraining Step: 59  | total loss: [1m[32m0.69193[0m[0m | time: 9.786s
[2K
| Adam | epoch: 004 | loss: 0.69193 - acc: 0.5277 -- iter: 448/480
[A[ATraining Step: 60  | total loss: [1m[32m0.69126[0m[0m | time: 11.425s
[2K
| Adam | epoch: 004 | loss: 0.69126 - acc: 0.5447 | val_loss: 0.69257 - val_acc: 0.4400 -- iter: 480/480
--
Training Step: 61  | total loss: [1m[32m0.69206[0m[0m | time: 0.739s
[2K
| Adam | epoch: 005 | loss: 0.69206 - acc: 0.5185 -- iter: 032/480
[A[ATraining Step: 62  | total loss: [1m[32m0.69159[0m[0m | time: 1.501s
[2K
| Adam | epoch: 005 | loss: 0.69159 - acc: 0.5161 -- iter: 064/480
[A[ATraining Step: 63  | total loss: [1m[32m0.69112[0m[0m | time: 2.263s
[2K
| Adam | epoch: 005 | loss: 0.69112 - acc: 0.5181 -- iter: 096/480
[A[ATraining Step: 64  | total loss: [1m[32m0.69089[0m[0m | time: 3.038s
[2K
| Adam | epoch: 005 | loss: 0.69089 - acc: 0.5314 -- iter: 128/480
[A[ATraining Step: 65  | total loss: [1m[32m0.69053[0m[0m | time: 3.785s
[2K
| Adam | epoch: 005 | loss: 0.69053 - acc: 0.5507 -- iter: 160/480
[A[ATraining Step: 66  | total loss: [1m[32m0.69002[0m[0m | time: 4.514s
[2K
| Adam | epoch: 005 | loss: 0.69002 - acc: 0.5711 -- iter: 192/480
[A[ATraining Step: 67  | total loss: [1m[32m0.68927[0m[0m | time: 5.284s
[2K
| Adam | epoch: 005 | loss: 0.68927 - acc: 0.5888 -- iter: 224/480
[A[ATraining Step: 68  | total loss: [1m[32m0.68825[0m[0m | time: 6.005s
[2K
| Adam | epoch: 005 | loss: 0.68825 - acc: 0.6079 -- iter: 256/480
[A[ATraining Step: 69  | total loss: [1m[32m0.68751[0m[0m | time: 6.851s
[2K
| Adam | epoch: 005 | loss: 0.68751 - acc: 0.6209 -- iter: 288/480
[A[ATraining Step: 70  | total loss: [1m[32m0.68716[0m[0m | time: 7.498s
[2K
| Adam | epoch: 005 | loss: 0.68716 - acc: 0.6250 -- iter: 320/480
[A[ATraining Step: 71  | total loss: [1m[32m0.68609[0m[0m | time: 8.093s
[2K
| Adam | epoch: 005 | loss: 0.68609 - acc: 0.6285 -- iter: 352/480
[A[ATraining Step: 72  | total loss: [1m[32m0.68599[0m[0m | time: 8.713s
[2K
| Adam | epoch: 005 | loss: 0.68599 - acc: 0.6246 -- iter: 384/480
[A[ATraining Step: 73  | total loss: [1m[32m0.68527[0m[0m | time: 9.319s
[2K
| Adam | epoch: 005 | loss: 0.68527 - acc: 0.6212 -- iter: 416/480
[A[ATraining Step: 74  | total loss: [1m[32m0.68362[0m[0m | time: 9.934s
[2K
| Adam | epoch: 005 | loss: 0.68362 - acc: 0.6285 -- iter: 448/480
[A[ATraining Step: 75  | total loss: [1m[32m0.68391[0m[0m | time: 11.549s
[2K
| Adam | epoch: 005 | loss: 0.68391 - acc: 0.6179 | val_loss: 0.65998 - val_acc: 0.6667 -- iter: 480/480
--
Training Step: 76  | total loss: [1m[32m0.68260[0m[0m | time: 0.723s
[2K
| Adam | epoch: 006 | loss: 0.68260 - acc: 0.6187 -- iter: 032/480
[A[ATraining Step: 77  | total loss: [1m[32m0.67731[0m[0m | time: 1.491s
[2K
| Adam | epoch: 006 | loss: 0.67731 - acc: 0.6359 -- iter: 064/480
[A[ATraining Step: 78  | total loss: [1m[32m0.67822[0m[0m | time: 2.223s
[2K
| Adam | epoch: 006 | loss: 0.67822 - acc: 0.6282 -- iter: 096/480
[A[ATraining Step: 79  | total loss: [1m[32m0.67635[0m[0m | time: 2.984s
[2K
| Adam | epoch: 006 | loss: 0.67635 - acc: 0.6311 -- iter: 128/480
[A[ATraining Step: 80  | total loss: [1m[32m0.67396[0m[0m | time: 3.732s
[2K
| Adam | epoch: 006 | loss: 0.67396 - acc: 0.6401 -- iter: 160/480
[A[ATraining Step: 81  | total loss: [1m[32m0.67195[0m[0m | time: 4.494s
[2K
| Adam | epoch: 006 | loss: 0.67195 - acc: 0.6449 -- iter: 192/480
[A[ATraining Step: 82  | total loss: [1m[32m0.66913[0m[0m | time: 5.238s
[2K
| Adam | epoch: 006 | loss: 0.66913 - acc: 0.6491 -- iter: 224/480
[A[ATraining Step: 83  | total loss: [1m[32m0.66424[0m[0m | time: 6.001s
[2K
| Adam | epoch: 006 | loss: 0.66424 - acc: 0.6530 -- iter: 256/480
[A[ATraining Step: 84  | total loss: [1m[32m0.66199[0m[0m | time: 6.608s
[2K
| Adam | epoch: 006 | loss: 0.66199 - acc: 0.6533 -- iter: 288/480
[A[ATraining Step: 85  | total loss: [1m[32m0.65998[0m[0m | time: 7.231s
[2K
| Adam | epoch: 006 | loss: 0.65998 - acc: 0.6567 -- iter: 320/480
[A[ATraining Step: 86  | total loss: [1m[32m0.65510[0m[0m | time: 7.826s
[2K
| Adam | epoch: 006 | loss: 0.65510 - acc: 0.6692 -- iter: 352/480
[A[ATraining Step: 87  | total loss: [1m[32m0.65110[0m[0m | time: 8.423s
[2K
| Adam | epoch: 006 | loss: 0.65110 - acc: 0.6679 -- iter: 384/480
[A[ATraining Step: 88  | total loss: [1m[32m0.64276[0m[0m | time: 9.035s
[2K
| Adam | epoch: 006 | loss: 0.64276 - acc: 0.6698 -- iter: 416/480
[A[ATraining Step: 89  | total loss: [1m[32m0.63249[0m[0m | time: 9.628s
[2K
| Adam | epoch: 006 | loss: 0.63249 - acc: 0.6810 -- iter: 448/480
[A[ATraining Step: 90  | total loss: [1m[32m0.62621[0m[0m | time: 11.385s
[2K
| Adam | epoch: 006 | loss: 0.62621 - acc: 0.6785 | val_loss: 0.54633 - val_acc: 0.7400 -- iter: 480/480
--
Training Step: 91  | total loss: [1m[32m0.62111[0m[0m | time: 0.748s
[2K
| Adam | epoch: 007 | loss: 0.62111 - acc: 0.6794 -- iter: 032/480
[A[ATraining Step: 92  | total loss: [1m[32m0.61720[0m[0m | time: 1.482s
[2K
| Adam | epoch: 007 | loss: 0.61720 - acc: 0.6865 -- iter: 064/480
[A[ATraining Step: 93  | total loss: [1m[32m0.61627[0m[0m | time: 2.203s
[2K
| Adam | epoch: 007 | loss: 0.61627 - acc: 0.6866 -- iter: 096/480
[A[ATraining Step: 94  | total loss: [1m[32m0.61850[0m[0m | time: 2.948s
[2K
| Adam | epoch: 007 | loss: 0.61850 - acc: 0.6804 -- iter: 128/480
[A[ATraining Step: 95  | total loss: [1m[32m0.61418[0m[0m | time: 3.714s
[2K
| Adam | epoch: 007 | loss: 0.61418 - acc: 0.6749 -- iter: 160/480
[A[ATraining Step: 96  | total loss: [1m[32m0.60773[0m[0m | time: 4.553s
[2K
| Adam | epoch: 007 | loss: 0.60773 - acc: 0.6730 -- iter: 192/480
[A[ATraining Step: 97  | total loss: [1m[32m0.60176[0m[0m | time: 5.146s
[2K
| Adam | epoch: 007 | loss: 0.60176 - acc: 0.6776 -- iter: 224/480
[A[ATraining Step: 98  | total loss: [1m[32m0.58996[0m[0m | time: 5.752s
[2K
| Adam | epoch: 007 | loss: 0.58996 - acc: 0.6848 -- iter: 256/480
[A[ATraining Step: 99  | total loss: [1m[32m0.58458[0m[0m | time: 6.356s
[2K
| Adam | epoch: 007 | loss: 0.58458 - acc: 0.6945 -- iter: 288/480
[A[ATraining Step: 100  | total loss: [1m[32m0.57028[0m[0m | time: 6.960s
[2K
| Adam | epoch: 007 | loss: 0.57028 - acc: 0.7000 -- iter: 320/480
[A[ATraining Step: 101  | total loss: [1m[32m0.55157[0m[0m | time: 7.571s
[2K
| Adam | epoch: 007 | loss: 0.55157 - acc: 0.7144 -- iter: 352/480
[A[ATraining Step: 102  | total loss: [1m[32m0.54711[0m[0m | time: 8.166s
[2K
| Adam | epoch: 007 | loss: 0.54711 - acc: 0.7148 -- iter: 384/480
[A[ATraining Step: 103  | total loss: [1m[32m0.53192[0m[0m | time: 8.783s
[2K
| Adam | epoch: 007 | loss: 0.53192 - acc: 0.7308 -- iter: 416/480
[A[ATraining Step: 104  | total loss: [1m[32m0.54404[0m[0m | time: 9.986s
[2K
| Adam | epoch: 007 | loss: 0.54404 - acc: 0.7265 -- iter: 448/480
[A[ATraining Step: 105  | total loss: [1m[32m0.52859[0m[0m | time: 11.614s
[2K
| Adam | epoch: 007 | loss: 0.52859 - acc: 0.7320 | val_loss: 0.68681 - val_acc: 0.6667 -- iter: 480/480
--
Training Step: 106  | total loss: [1m[32m0.52156[0m[0m | time: 0.610s
[2K
| Adam | epoch: 008 | loss: 0.52156 - acc: 0.7369 -- iter: 032/480
[A[ATraining Step: 107  | total loss: [1m[32m0.51701[0m[0m | time: 1.246s
[2K
| Adam | epoch: 008 | loss: 0.51701 - acc: 0.7445 -- iter: 064/480
[A[ATraining Step: 108  | total loss: [1m[32m0.53538[0m[0m | time: 1.894s
[2K
| Adam | epoch: 008 | loss: 0.53538 - acc: 0.7294 -- iter: 096/480
[A[ATraining Step: 109  | total loss: [1m[32m0.52885[0m[0m | time: 2.492s
[2K
| Adam | epoch: 008 | loss: 0.52885 - acc: 0.7408 -- iter: 128/480
[A[ATraining Step: 110  | total loss: [1m[32m0.53552[0m[0m | time: 3.107s
[2K
| Adam | epoch: 008 | loss: 0.53552 - acc: 0.7355 -- iter: 160/480
[A[ATraining Step: 111  | total loss: [1m[32m0.56319[0m[0m | time: 3.707s
[2K
| Adam | epoch: 008 | loss: 0.56319 - acc: 0.7182 -- iter: 192/480
[A[ATraining Step: 112  | total loss: [1m[32m0.56110[0m[0m | time: 4.306s
[2K
| Adam | epoch: 008 | loss: 0.56110 - acc: 0.7245 -- iter: 224/480
[A[ATraining Step: 113  | total loss: [1m[32m0.55157[0m[0m | time: 4.912s
[2K
| Adam | epoch: 008 | loss: 0.55157 - acc: 0.7364 -- iter: 256/480
[A[ATraining Step: 114  | total loss: [1m[32m0.55303[0m[0m | time: 5.509s
[2K
| Adam | epoch: 008 | loss: 0.55303 - acc: 0.7347 -- iter: 288/480
[A[ATraining Step: 115  | total loss: [1m[32m0.53707[0m[0m | time: 6.117s
[2K
| Adam | epoch: 008 | loss: 0.53707 - acc: 0.7487 -- iter: 320/480
[A[ATraining Step: 116  | total loss: [1m[32m0.55501[0m[0m | time: 6.755s
[2K
| Adam | epoch: 008 | loss: 0.55501 - acc: 0.7332 -- iter: 352/480
[A[ATraining Step: 117  | total loss: [1m[32m0.54853[0m[0m | time: 7.361s
[2K
| Adam | epoch: 008 | loss: 0.54853 - acc: 0.7318 -- iter: 384/480
[A[ATraining Step: 118  | total loss: [1m[32m0.54450[0m[0m | time: 7.971s
[2K
| Adam | epoch: 008 | loss: 0.54450 - acc: 0.7336 -- iter: 416/480
[A[ATraining Step: 119  | total loss: [1m[32m0.54797[0m[0m | time: 8.583s
[2K
| Adam | epoch: 008 | loss: 0.54797 - acc: 0.7290 -- iter: 448/480
[A[ATraining Step: 120  | total loss: [1m[32m0.53729[0m[0m | time: 10.197s
[2K
| Adam | epoch: 008 | loss: 0.53729 - acc: 0.7311 | val_loss: 0.52834 - val_acc: 0.7133 -- iter: 480/480
--
Training Step: 121  | total loss: [1m[32m0.52567[0m[0m | time: 0.610s
[2K
| Adam | epoch: 009 | loss: 0.52567 - acc: 0.7392 -- iter: 032/480
[A[ATraining Step: 122  | total loss: [1m[32m0.51729[0m[0m | time: 1.208s
[2K
| Adam | epoch: 009 | loss: 0.51729 - acc: 0.7465 -- iter: 064/480
[A[ATraining Step: 123  | total loss: [1m[32m0.50738[0m[0m | time: 1.821s
[2K
| Adam | epoch: 009 | loss: 0.50738 - acc: 0.7500 -- iter: 096/480
[A[ATraining Step: 124  | total loss: [1m[32m0.51928[0m[0m | time: 2.425s
[2K
| Adam | epoch: 009 | loss: 0.51928 - acc: 0.7406 -- iter: 128/480
[A[ATraining Step: 125  | total loss: [1m[32m0.51444[0m[0m | time: 3.034s
[2K
| Adam | epoch: 009 | loss: 0.51444 - acc: 0.7478 -- iter: 160/480
[A[ATraining Step: 126  | total loss: [1m[32m0.50728[0m[0m | time: 3.636s
[2K
| Adam | epoch: 009 | loss: 0.50728 - acc: 0.7574 -- iter: 192/480
[A[ATraining Step: 127  | total loss: [1m[32m0.50814[0m[0m | time: 4.240s
[2K
| Adam | epoch: 009 | loss: 0.50814 - acc: 0.7598 -- iter: 224/480
[A[ATraining Step: 128  | total loss: [1m[32m0.49787[0m[0m | time: 4.870s
[2K
| Adam | epoch: 009 | loss: 0.49787 - acc: 0.7713 -- iter: 256/480
[A[ATraining Step: 129  | total loss: [1m[32m0.48595[0m[0m | time: 5.471s
[2K
| Adam | epoch: 009 | loss: 0.48595 - acc: 0.7817 -- iter: 288/480
[A[ATraining Step: 130  | total loss: [1m[32m0.47689[0m[0m | time: 6.080s
[2K
| Adam | epoch: 009 | loss: 0.47689 - acc: 0.7848 -- iter: 320/480
[A[ATraining Step: 131  | total loss: [1m[32m0.46565[0m[0m | time: 6.678s
[2K
| Adam | epoch: 009 | loss: 0.46565 - acc: 0.7907 -- iter: 352/480
[A[ATraining Step: 132  | total loss: [1m[32m0.45367[0m[0m | time: 7.294s
[2K
| Adam | epoch: 009 | loss: 0.45367 - acc: 0.7991 -- iter: 384/480
[A[ATraining Step: 133  | total loss: [1m[32m0.44925[0m[0m | time: 8.056s
[2K
| Adam | epoch: 009 | loss: 0.44925 - acc: 0.7973 -- iter: 416/480
[A[ATraining Step: 134  | total loss: [1m[32m0.44627[0m[0m | time: 8.681s
[2K
| Adam | epoch: 009 | loss: 0.44627 - acc: 0.7926 -- iter: 448/480
[A[ATraining Step: 135  | total loss: [1m[32m0.44591[0m[0m | time: 10.290s
[2K
| Adam | epoch: 009 | loss: 0.44591 - acc: 0.7946 | val_loss: 0.49757 - val_acc: 0.7800 -- iter: 480/480
--
Training Step: 136  | total loss: [1m[32m0.44090[0m[0m | time: 0.623s
[2K
| Adam | epoch: 010 | loss: 0.44090 - acc: 0.7995 -- iter: 032/480
[A[ATraining Step: 137  | total loss: [1m[32m0.43275[0m[0m | time: 1.232s
[2K
| Adam | epoch: 010 | loss: 0.43275 - acc: 0.8070 -- iter: 064/480
[A[ATraining Step: 138  | total loss: [1m[32m0.44406[0m[0m | time: 1.854s
[2K
| Adam | epoch: 010 | loss: 0.44406 - acc: 0.7982 -- iter: 096/480
[A[ATraining Step: 139  | total loss: [1m[32m0.44630[0m[0m | time: 2.467s
[2K
| Adam | epoch: 010 | loss: 0.44630 - acc: 0.7934 -- iter: 128/480
[A[ATraining Step: 140  | total loss: [1m[32m0.44543[0m[0m | time: 3.072s
[2K
| Adam | epoch: 010 | loss: 0.44543 - acc: 0.7922 -- iter: 160/480
[A[ATraining Step: 141  | total loss: [1m[32m0.43568[0m[0m | time: 3.683s
[2K
| Adam | epoch: 010 | loss: 0.43568 - acc: 0.7942 -- iter: 192/480
[A[ATraining Step: 142  | total loss: [1m[32m0.41791[0m[0m | time: 4.294s
[2K
| Adam | epoch: 010 | loss: 0.41791 - acc: 0.8023 -- iter: 224/480
[A[ATraining Step: 143  | total loss: [1m[32m0.41112[0m[0m | time: 4.915s
[2K
| Adam | epoch: 010 | loss: 0.41112 - acc: 0.8096 -- iter: 256/480
[A[ATraining Step: 144  | total loss: [1m[32m0.40655[0m[0m | time: 5.520s
[2K
| Adam | epoch: 010 | loss: 0.40655 - acc: 0.8099 -- iter: 288/480
[A[ATraining Step: 145  | total loss: [1m[32m0.39725[0m[0m | time: 6.126s
[2K
| Adam | epoch: 010 | loss: 0.39725 - acc: 0.8132 -- iter: 320/480
[A[ATraining Step: 146  | total loss: [1m[32m0.38254[0m[0m | time: 6.739s
[2K
| Adam | epoch: 010 | loss: 0.38254 - acc: 0.8257 -- iter: 352/480
[A[ATraining Step: 147  | total loss: [1m[32m0.37461[0m[0m | time: 7.352s
[2K
| Adam | epoch: 010 | loss: 0.37461 - acc: 0.8306 -- iter: 384/480
[A[ATraining Step: 148  | total loss: [1m[32m0.37326[0m[0m | time: 7.978s
[2K
| Adam | epoch: 010 | loss: 0.37326 - acc: 0.8382 -- iter: 416/480
[A[ATraining Step: 149  | total loss: [1m[32m0.35179[0m[0m | time: 8.578s
[2K
| Adam | epoch: 010 | loss: 0.35179 - acc: 0.8544 -- iter: 448/480
[A[ATraining Step: 150  | total loss: [1m[32m0.34365[0m[0m | time: 10.175s
[2K
| Adam | epoch: 010 | loss: 0.34365 - acc: 0.8564 | val_loss: 0.34643 - val_acc: 0.8467 -- iter: 480/480
--
Training Step: 151  | total loss: [1m[32m0.33549[0m[0m | time: 0.614s
[2K
| Adam | epoch: 011 | loss: 0.33549 - acc: 0.8645 -- iter: 032/480
[A[ATraining Step: 152  | total loss: [1m[32m0.32770[0m[0m | time: 1.216s
[2K
| Adam | epoch: 011 | loss: 0.32770 - acc: 0.8656 -- iter: 064/480
[A[ATraining Step: 153  | total loss: [1m[32m0.32221[0m[0m | time: 1.841s
[2K
| Adam | epoch: 011 | loss: 0.32221 - acc: 0.8603 -- iter: 096/480
[A[ATraining Step: 154  | total loss: [1m[32m0.31947[0m[0m | time: 2.452s
[2K
| Adam | epoch: 011 | loss: 0.31947 - acc: 0.8617 -- iter: 128/480
[A[ATraining Step: 155  | total loss: [1m[32m0.33107[0m[0m | time: 3.059s
[2K
| Adam | epoch: 011 | loss: 0.33107 - acc: 0.8506 -- iter: 160/480
[A[ATraining Step: 156  | total loss: [1m[32m0.33057[0m[0m | time: 3.667s
[2K
| Adam | epoch: 011 | loss: 0.33057 - acc: 0.8499 -- iter: 192/480
[A[ATraining Step: 157  | total loss: [1m[32m0.32405[0m[0m | time: 4.270s
[2K
| Adam | epoch: 011 | loss: 0.32405 - acc: 0.8524 -- iter: 224/480
[A[ATraining Step: 158  | total loss: [1m[32m0.31172[0m[0m | time: 4.864s
[2K
| Adam | epoch: 011 | loss: 0.31172 - acc: 0.8547 -- iter: 256/480
[A[ATraining Step: 159  | total loss: [1m[32m0.30854[0m[0m | time: 5.492s
[2K
| Adam | epoch: 011 | loss: 0.30854 - acc: 0.8536 -- iter: 288/480
[A[ATraining Step: 160  | total loss: [1m[32m0.29584[0m[0m | time: 6.090s
[2K
| Adam | epoch: 011 | loss: 0.29584 - acc: 0.8620 -- iter: 320/480
[A[ATraining Step: 161  | total loss: [1m[32m0.28398[0m[0m | time: 6.692s
[2K
| Adam | epoch: 011 | loss: 0.28398 - acc: 0.8695 -- iter: 352/480
[A[ATraining Step: 162  | total loss: [1m[32m0.29167[0m[0m | time: 7.293s
[2K
| Adam | epoch: 011 | loss: 0.29167 - acc: 0.8638 -- iter: 384/480
[A[ATraining Step: 163  | total loss: [1m[32m0.27791[0m[0m | time: 7.900s
[2K
| Adam | epoch: 011 | loss: 0.27791 - acc: 0.8681 -- iter: 416/480
[A[ATraining Step: 164  | total loss: [1m[32m0.26657[0m[0m | time: 8.539s
[2K
| Adam | epoch: 011 | loss: 0.26657 - acc: 0.8781 -- iter: 448/480
[A[ATraining Step: 165  | total loss: [1m[32m0.26877[0m[0m | time: 10.144s
[2K
| Adam | epoch: 011 | loss: 0.26877 - acc: 0.8809 | val_loss: 0.34886 - val_acc: 0.8467 -- iter: 480/480
--
Training Step: 166  | total loss: [1m[32m0.25619[0m[0m | time: 0.606s
[2K
| Adam | epoch: 012 | loss: 0.25619 - acc: 0.8897 -- iter: 032/480
[A[ATraining Step: 167  | total loss: [1m[32m0.24594[0m[0m | time: 1.213s
[2K
| Adam | epoch: 012 | loss: 0.24594 - acc: 0.8976 -- iter: 064/480
[A[ATraining Step: 168  | total loss: [1m[32m0.23467[0m[0m | time: 1.820s
[2K
| Adam | epoch: 012 | loss: 0.23467 - acc: 0.9047 -- iter: 096/480
[A[ATraining Step: 169  | total loss: [1m[32m0.22398[0m[0m | time: 2.433s
[2K
| Adam | epoch: 012 | loss: 0.22398 - acc: 0.9111 -- iter: 128/480
[A[ATraining Step: 170  | total loss: [1m[32m0.22111[0m[0m | time: 3.045s
[2K
| Adam | epoch: 012 | loss: 0.22111 - acc: 0.9106 -- iter: 160/480
[A[ATraining Step: 171  | total loss: [1m[32m0.20880[0m[0m | time: 3.663s
[2K
| Adam | epoch: 012 | loss: 0.20880 - acc: 0.9196 -- iter: 192/480
[A[ATraining Step: 172  | total loss: [1m[32m0.20527[0m[0m | time: 4.269s
[2K
| Adam | epoch: 012 | loss: 0.20527 - acc: 0.9214 -- iter: 224/480
[A[ATraining Step: 173  | total loss: [1m[32m0.19806[0m[0m | time: 4.874s
[2K
| Adam | epoch: 012 | loss: 0.19806 - acc: 0.9230 -- iter: 256/480
[A[ATraining Step: 174  | total loss: [1m[32m0.19744[0m[0m | time: 5.477s
[2K
| Adam | epoch: 012 | loss: 0.19744 - acc: 0.9276 -- iter: 288/480
[A[ATraining Step: 175  | total loss: [1m[32m0.20228[0m[0m | time: 6.081s
[2K
| Adam | epoch: 012 | loss: 0.20228 - acc: 0.9286 -- iter: 320/480
[A[ATraining Step: 176  | total loss: [1m[32m0.20986[0m[0m | time: 6.688s
[2K
| Adam | epoch: 012 | loss: 0.20986 - acc: 0.9295 -- iter: 352/480
[A[ATraining Step: 177  | total loss: [1m[32m0.20133[0m[0m | time: 7.282s
[2K
| Adam | epoch: 012 | loss: 0.20133 - acc: 0.9365 -- iter: 384/480
[A[ATraining Step: 178  | total loss: [1m[32m0.19195[0m[0m | time: 7.902s
[2K
| Adam | epoch: 012 | loss: 0.19195 - acc: 0.9366 -- iter: 416/480
[A[ATraining Step: 179  | total loss: [1m[32m0.17937[0m[0m | time: 8.533s
[2K
| Adam | epoch: 012 | loss: 0.17937 - acc: 0.9398 -- iter: 448/480
[A[ATraining Step: 180  | total loss: [1m[32m0.17632[0m[0m | time: 10.144s
[2K
| Adam | epoch: 012 | loss: 0.17632 - acc: 0.9365 | val_loss: 0.29567 - val_acc: 0.8867 -- iter: 480/480
--
Training Step: 181  | total loss: [1m[32m0.16988[0m[0m | time: 0.606s
[2K
| Adam | epoch: 013 | loss: 0.16988 - acc: 0.9397 -- iter: 032/480
[A[ATraining Step: 182  | total loss: [1m[32m0.16146[0m[0m | time: 1.239s
[2K
| Adam | epoch: 013 | loss: 0.16146 - acc: 0.9426 -- iter: 064/480
[A[ATraining Step: 183  | total loss: [1m[32m0.15436[0m[0m | time: 1.847s
[2K
| Adam | epoch: 013 | loss: 0.15436 - acc: 0.9483 -- iter: 096/480
[A[ATraining Step: 184  | total loss: [1m[32m0.14505[0m[0m | time: 2.451s
[2K
| Adam | epoch: 013 | loss: 0.14505 - acc: 0.9535 -- iter: 128/480
[A[ATraining Step: 185  | total loss: [1m[32m0.14151[0m[0m | time: 3.053s
[2K
| Adam | epoch: 013 | loss: 0.14151 - acc: 0.9519 -- iter: 160/480
[A[ATraining Step: 186  | total loss: [1m[32m0.13432[0m[0m | time: 3.658s
[2K
| Adam | epoch: 013 | loss: 0.13432 - acc: 0.9536 -- iter: 192/480
[A[ATraining Step: 187  | total loss: [1m[32m0.12580[0m[0m | time: 4.263s
[2K
| Adam | epoch: 013 | loss: 0.12580 - acc: 0.9582 -- iter: 224/480
[A[ATraining Step: 188  | total loss: [1m[32m0.11677[0m[0m | time: 4.897s
[2K
| Adam | epoch: 013 | loss: 0.11677 - acc: 0.9624 -- iter: 256/480
[A[ATraining Step: 189  | total loss: [1m[32m0.10972[0m[0m | time: 5.525s
[2K
| Adam | epoch: 013 | loss: 0.10972 - acc: 0.9662 -- iter: 288/480
[A[ATraining Step: 190  | total loss: [1m[32m0.11269[0m[0m | time: 6.138s
[2K
| Adam | epoch: 013 | loss: 0.11269 - acc: 0.9664 -- iter: 320/480
[A[ATraining Step: 191  | total loss: [1m[32m0.10490[0m[0m | time: 6.758s
[2K
| Adam | epoch: 013 | loss: 0.10490 - acc: 0.9698 -- iter: 352/480
[A[ATraining Step: 192  | total loss: [1m[32m0.11725[0m[0m | time: 7.364s
[2K
| Adam | epoch: 013 | loss: 0.11725 - acc: 0.9697 -- iter: 384/480
[A[ATraining Step: 193  | total loss: [1m[32m0.10987[0m[0m | time: 7.974s
[2K
| Adam | epoch: 013 | loss: 0.10987 - acc: 0.9727 -- iter: 416/480
[A[ATraining Step: 194  | total loss: [1m[32m0.10363[0m[0m | time: 8.581s
[2K
| Adam | epoch: 013 | loss: 0.10363 - acc: 0.9754 -- iter: 448/480
[A[ATraining Step: 195  | total loss: [1m[32m0.10046[0m[0m | time: 10.197s
[2K
| Adam | epoch: 013 | loss: 0.10046 - acc: 0.9779 | val_loss: 0.34690 - val_acc: 0.8533 -- iter: 480/480
--
Training Step: 196  | total loss: [1m[32m0.09716[0m[0m | time: 0.639s
[2K
| Adam | epoch: 014 | loss: 0.09716 - acc: 0.9770 -- iter: 032/480
[A[ATraining Step: 197  | total loss: [1m[32m0.09308[0m[0m | time: 1.254s
[2K
| Adam | epoch: 014 | loss: 0.09308 - acc: 0.9793 -- iter: 064/480
[A[ATraining Step: 198  | total loss: [1m[32m0.08618[0m[0m | time: 1.862s
[2K
| Adam | epoch: 014 | loss: 0.08618 - acc: 0.9814 -- iter: 096/480
[A[ATraining Step: 199  | total loss: [1m[32m0.07916[0m[0m | time: 2.467s
[2K
| Adam | epoch: 014 | loss: 0.07916 - acc: 0.9832 -- iter: 128/480
[A[ATraining Step: 200  | total loss: [1m[32m0.07632[0m[0m | time: 4.086s
[2K
| Adam | epoch: 014 | loss: 0.07632 - acc: 0.9849 | val_loss: 0.34829 - val_acc: 0.8733 -- iter: 160/480
--
Training Step: 201  | total loss: [1m[32m0.07461[0m[0m | time: 4.707s
[2K
| Adam | epoch: 014 | loss: 0.07461 - acc: 0.9864 -- iter: 192/480
[A[ATraining Step: 202  | total loss: [1m[32m0.07502[0m[0m | time: 5.307s
[2K
| Adam | epoch: 014 | loss: 0.07502 - acc: 0.9846 -- iter: 224/480
[A[ATraining Step: 203  | total loss: [1m[32m0.06977[0m[0m | time: 5.917s
[2K
| Adam | epoch: 014 | loss: 0.06977 - acc: 0.9862 -- iter: 256/480
[A[ATraining Step: 204  | total loss: [1m[32m0.06837[0m[0m | time: 6.535s
[2K
| Adam | epoch: 014 | loss: 0.06837 - acc: 0.9844 -- iter: 288/480
[A[ATraining Step: 205  | total loss: [1m[32m0.06714[0m[0m | time: 7.140s
[2K
| Adam | epoch: 014 | loss: 0.06714 - acc: 0.9829 -- iter: 320/480
[A[ATraining Step: 206  | total loss: [1m[32m0.06365[0m[0m | time: 7.774s
[2K
| Adam | epoch: 014 | loss: 0.06365 - acc: 0.9846 -- iter: 352/480
[A[ATraining Step: 207  | total loss: [1m[32m0.05908[0m[0m | time: 8.354s
[2K
| Adam | epoch: 014 | loss: 0.05908 - acc: 0.9861 -- iter: 384/480
[A[ATraining Step: 208  | total loss: [1m[32m0.07102[0m[0m | time: 8.960s
[2K
| Adam | epoch: 014 | loss: 0.07102 - acc: 0.9813 -- iter: 416/480
[A[ATraining Step: 209  | total loss: [1m[32m0.07411[0m[0m | time: 9.561s
[2K
| Adam | epoch: 014 | loss: 0.07411 - acc: 0.9769 -- iter: 448/480
[A[ATraining Step: 210  | total loss: [1m[32m0.09874[0m[0m | time: 11.174s
[2K
| Adam | epoch: 014 | loss: 0.09874 - acc: 0.9573 | val_loss: 0.36648 - val_acc: 0.8867 -- iter: 480/480
--
Training Step: 211  | total loss: [1m[32m0.09089[0m[0m | time: 0.612s
[2K
| Adam | epoch: 015 | loss: 0.09089 - acc: 0.9616 -- iter: 032/480
[A[ATraining Step: 212  | total loss: [1m[32m0.08535[0m[0m | time: 1.217s
[2K
| Adam | epoch: 015 | loss: 0.08535 - acc: 0.9623 -- iter: 064/480
[A[ATraining Step: 213  | total loss: [1m[32m0.08084[0m[0m | time: 1.825s
[2K
| Adam | epoch: 015 | loss: 0.08084 - acc: 0.9661 -- iter: 096/480
[A[ATraining Step: 214  | total loss: [1m[32m0.07645[0m[0m | time: 2.430s
[2K
| Adam | epoch: 015 | loss: 0.07645 - acc: 0.9663 -- iter: 128/480
[A[ATraining Step: 215  | total loss: [1m[32m0.07310[0m[0m | time: 3.029s
[2K
| Adam | epoch: 015 | loss: 0.07310 - acc: 0.9666 -- iter: 160/480
[A[ATraining Step: 216  | total loss: [1m[32m0.06717[0m[0m | time: 3.635s
[2K
| Adam | epoch: 015 | loss: 0.06717 - acc: 0.9699 -- iter: 192/480
[A[ATraining Step: 217  | total loss: [1m[32m0.06214[0m[0m | time: 4.255s
[2K
| Adam | epoch: 015 | loss: 0.06214 - acc: 0.9729 -- iter: 224/480
[A[ATraining Step: 218  | total loss: [1m[32m0.05802[0m[0m | time: 4.855s
[2K
| Adam | epoch: 015 | loss: 0.05802 - acc: 0.9756 -- iter: 256/480
[A[ATraining Step: 219  | total loss: [1m[32m0.05387[0m[0m | time: 5.462s
[2K
| Adam | epoch: 015 | loss: 0.05387 - acc: 0.9781 -- iter: 288/480
[A[ATraining Step: 220  | total loss: [1m[32m0.05146[0m[0m | time: 6.074s
[2K
| Adam | epoch: 015 | loss: 0.05146 - acc: 0.9803 -- iter: 320/480
[A[ATraining Step: 221  | total loss: [1m[32m0.04690[0m[0m | time: 6.673s
[2K
| Adam | epoch: 015 | loss: 0.04690 - acc: 0.9822 -- iter: 352/480
[A[ATraining Step: 222  | total loss: [1m[32m0.04307[0m[0m | time: 7.279s
[2K
| Adam | epoch: 015 | loss: 0.04307 - acc: 0.9840 -- iter: 384/480
[A[ATraining Step: 223  | total loss: [1m[32m0.04302[0m[0m | time: 7.877s
[2K
| Adam | epoch: 015 | loss: 0.04302 - acc: 0.9856 -- iter: 416/480
[A[ATraining Step: 224  | total loss: [1m[32m0.05084[0m[0m | time: 8.486s
[2K
| Adam | epoch: 015 | loss: 0.05084 - acc: 0.9777 -- iter: 448/480
[A[ATraining Step: 225  | total loss: [1m[32m0.05843[0m[0m | time: 10.103s
[2K
| Adam | epoch: 015 | loss: 0.05843 - acc: 0.9737 | val_loss: 0.61205 - val_acc: 0.8600 -- iter: 480/480
--
Validation AUC:0.950036075036075
Validation AUPRC:0.9672299070752131
Test AUC:0.9664
Test AUPRC:0.9682728020081012
BestTestF1Score	0.89	0.76	0.88	0.84	0.93	70	13	62	5	0.01
BestTestMCCScore	0.9	0.8	0.9	0.91	0.89	67	7	68	8	0.07
BestTestAccuracyScore	0.9	0.8	0.9	0.91	0.89	67	7	68	8	0.07
BestValidationF1Score	0.89	0.76	0.88	0.88	0.9	76	10	56	8	0.01
BestValidationMCC	0.89	0.77	0.88	0.95	0.83	70	4	62	14	0.07
BestValidationAccuracy	0.89	0.77	0.88	0.95	0.83	70	4	62	14	0.07
TestPredictions (Threshold:0.07)
CHEMBL3758942,TP,ACT,1.0	CHEMBL267929,TN,INACT,0.009999999776482582	CHEMBL178690,TP,ACT,0.9800000190734863	CHEMBL63927,FP,INACT,0.949999988079071	CHEMBL356855,TN,INACT,0.0	CHEMBL3634433,TP,ACT,1.0	CHEMBL154535,TN,INACT,0.0	CHEMBL1095704,TN,INACT,0.0	CHEMBL58027,FP,INACT,0.3199999928474426	CHEMBL236442,TN,INACT,0.0	CHEMBL2334978,TP,ACT,1.0	CHEMBL3634444,TP,ACT,1.0	CHEMBL244584,FP,INACT,0.10999999940395355	CHEMBL3644425,TP,ACT,0.07000000029802322	CHEMBL237693,TN,INACT,0.0	CHEMBL3785392,TP,ACT,1.0	CHEMBL260328,TN,INACT,0.0	CHEMBL334842,TN,INACT,0.0	CHEMBL2426078,TN,INACT,0.0	CHEMBL2115152,TN,INACT,0.0	CHEMBL3758216,TP,ACT,1.0	CHEMBL156667,TN,INACT,0.0	CHEMBL3702449,TP,ACT,1.0	CHEMBL1258796,TP,ACT,1.0	CHEMBL3422892,FN,ACT,0.009999999776482582	CHEMBL3702433,TP,ACT,1.0	CHEMBL2021372,TN,INACT,0.05000000074505806	CHEMBL1257415,TP,ACT,1.0	CHEMBL2424674,TN,INACT,0.0	CHEMBL3401729,TN,INACT,0.0	CHEMBL3702372,TP,ACT,0.800000011920929	CHEMBL13260,TN,INACT,0.0	CHEMBL303415,TN,INACT,0.019999999552965164	CHEMBL2397374,TP,ACT,1.0	CHEMBL64819,TN,INACT,0.0	CHEMBL3422881,TP,ACT,0.2800000011920929	CHEMBL2418380,TP,ACT,0.8199999928474426	CHEMBL1779887,TN,INACT,0.0	CHEMBL486062,FP,INACT,0.12999999523162842	CHEMBL2011870,TP,ACT,0.9900000095367432	CHEMBL3758683,TP,ACT,1.0	CHEMBL1258915,TP,ACT,0.9300000071525574	CHEMBL3634431,TP,ACT,1.0	CHEMBL3797793,FN,ACT,0.009999999776482582	CHEMBL112248,TN,INACT,0.0	CHEMBL442076,TN,INACT,0.0	CHEMBL3702411,TP,ACT,0.9900000095367432	CHEMBL114027,TN,INACT,0.0	CHEMBL1098101,TN,INACT,0.0	CHEMBL557092,TN,INACT,0.0	CHEMBL237315,TN,INACT,0.0	CHEMBL3702358,TP,ACT,0.9200000166893005	CHEMBL2312397,TN,INACT,0.0	CHEMBL39372,TN,INACT,0.0	CHEMBL156768,TN,INACT,0.0	CHEMBL3422875,TP,ACT,0.17000000178813934	CHEMBL1234889,FN,ACT,0.0	CHEMBL3644401,TP,ACT,0.8999999761581421	CHEMBL3634447,TP,ACT,1.0	CHEMBL233709,TP,ACT,0.9900000095367432	CHEMBL3422874,TP,ACT,0.9399999976158142	CHEMBL3122225,FP,INACT,0.75	CHEMBL3702444,TP,ACT,0.7799999713897705	CHEMBL360728,TP,ACT,0.949999988079071	CHEMBL392094,TN,INACT,0.019999999552965164	CHEMBL238158,TN,INACT,0.0	CHEMBL391706,TN,INACT,0.0	CHEMBL3785210,TP,ACT,0.9900000095367432	CHEMBL3702364,TP,ACT,0.8500000238418579	CHEMBL3401722,TN,INACT,0.0	CHEMBL2426075,TN,INACT,0.0	CHEMBL3628115,TP,ACT,1.0	CHEMBL3702422,TP,ACT,0.7400000095367432	CHEMBL2397379,TP,ACT,0.8299999833106995	CHEMBL3785499,TP,ACT,1.0	CHEMBL2334987,TP,ACT,0.23999999463558197	CHEMBL1484616,TP,ACT,0.6499999761581421	CHEMBL408899,TN,INACT,0.0	CHEMBL3758587,TP,ACT,1.0	CHEMBL2397378,TP,ACT,0.949999988079071	CHEMBL187941,FP,INACT,0.47999998927116394	CHEMBL8967,TN,INACT,0.009999999776482582	CHEMBL3644399,TP,ACT,0.6700000166893005	CHEMBL2426098,TN,INACT,0.0	CHEMBL46527,TN,INACT,0.0	CHEMBL323713,TN,INACT,0.0	CHEMBL3122224,TP,ACT,0.23999999463558197	CHEMBL94990,TN,INACT,0.0	CHEMBL399071,TN,INACT,0.009999999776482582	CHEMBL2426097,TN,INACT,0.0	CHEMBL3786400,TP,ACT,1.0	CHEMBL112014,TN,INACT,0.0	CHEMBL2425976,TN,INACT,0.0	CHEMBL3422885,TP,ACT,0.23999999463558197	CHEMBL2397341,TP,ACT,0.9900000095367432	CHEMBL1645348,FN,ACT,0.03999999910593033	CHEMBL269776,TN,INACT,0.0	CHEMBL2397364,FN,ACT,0.03999999910593033	CHEMBL341209,TN,INACT,0.0	CHEMBL3702360,TP,ACT,0.7300000190734863	CHEMBL94987,TN,INACT,0.0	CHEMBL378945,TN,INACT,0.0	CHEMBL107768,TN,INACT,0.0	CHEMBL2397342,TP,ACT,0.8999999761581421	CHEMBL154700,TN,INACT,0.0	CHEMBL3401721,TN,INACT,0.019999999552965164	CHEMBL1771388,FN,ACT,0.05000000074505806	CHEMBL236020,TN,INACT,0.0	CHEMBL3634414,TP,ACT,1.0	CHEMBL2397344,TP,ACT,0.9599999785423279	CHEMBL2397376,TP,ACT,1.0	CHEMBL260122,TN,INACT,0.0	CHEMBL394647,TN,INACT,0.0	CHEMBL237079,FP,INACT,0.10000000149011612	CHEMBL3644424,TP,ACT,0.9200000166893005	CHEMBL3785400,TP,ACT,1.0	CHEMBL3634416,TP,ACT,1.0	CHEMBL3330807,TP,ACT,0.9399999976158142	CHEMBL611036,TN,INACT,0.0	CHEMBL3759289,TP,ACT,1.0	CHEMBL116357,TN,INACT,0.0	CHEMBL295427,TN,INACT,0.0	CHEMBL2426069,TN,INACT,0.0	CHEMBL56155,TN,INACT,0.0	CHEMBL2112963,TP,ACT,1.0	CHEMBL3702452,TP,ACT,0.9399999976158142	CHEMBL2418370,TP,ACT,0.6299999952316284	CHEMBL3760068,TP,ACT,1.0	CHEMBL235802,TN,INACT,0.0	CHEMBL3760018,TP,ACT,0.9900000095367432	CHEMBL2440692,TN,INACT,0.009999999776482582	CHEMBL3702381,TP,ACT,0.7099999785423279	CHEMBL3786026,TN,INACT,0.0	CHEMBL3759878,TP,ACT,1.0	CHEMBL264709,TN,INACT,0.0	CHEMBL2418360,FN,ACT,0.009999999776482582	CHEMBL3644362,TP,ACT,0.9599999785423279	CHEMBL235592,TN,INACT,0.0	CHEMBL3634438,TP,ACT,1.0	CHEMBL3634449,TP,ACT,1.0	CHEMBL3758364,TP,ACT,1.0	CHEMBL253161,TN,INACT,0.0	CHEMBL392420,TN,INACT,0.0	CHEMBL3644380,TP,ACT,0.9900000095367432	CHEMBL2418362,FN,ACT,0.0	CHEMBL269689,TN,INACT,0.0	CHEMBL83,TN,INACT,0.019999999552965164	CHEMBL198310,TN,INACT,0.0	CHEMBL64417,TN,INACT,0.05000000074505806	CHEMBL353547,TP,ACT,0.07000000029802322	

