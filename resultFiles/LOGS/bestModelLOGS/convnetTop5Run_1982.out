CNNModel CHEMBL4462 adam 0.0005 30 256 0 0.8 False True
Number of active compounds :	325
Number of inactive compounds :	292
---------------------------------
Run id: CNNModel_CHEMBL4462_adam_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4462_adam_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 389
Validation samples: 122
--
Training Step: 1  | time: 1.157s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/389
[A[ATraining Step: 2  | total loss: [1m[32m0.62394[0m[0m | time: 1.987s
[2K
| Adam | epoch: 001 | loss: 0.62394 - acc: 0.4781 -- iter: 064/389
[A[ATraining Step: 3  | total loss: [1m[32m0.68106[0m[0m | time: 2.877s
[2K
| Adam | epoch: 001 | loss: 0.68106 - acc: 0.4449 -- iter: 096/389
[A[ATraining Step: 4  | total loss: [1m[32m0.69018[0m[0m | time: 3.789s
[2K
| Adam | epoch: 001 | loss: 0.69018 - acc: 0.5331 -- iter: 128/389
[A[ATraining Step: 5  | total loss: [1m[32m0.69214[0m[0m | time: 4.722s
[2K
| Adam | epoch: 001 | loss: 0.69214 - acc: 0.5751 -- iter: 160/389
[A[ATraining Step: 6  | total loss: [1m[32m0.69374[0m[0m | time: 5.618s
[2K
| Adam | epoch: 001 | loss: 0.69374 - acc: 0.4264 -- iter: 192/389
[A[ATraining Step: 7  | total loss: [1m[32m0.69342[0m[0m | time: 6.436s
[2K
| Adam | epoch: 001 | loss: 0.69342 - acc: 0.4893 -- iter: 224/389
[A[ATraining Step: 8  | total loss: [1m[32m0.69347[0m[0m | time: 7.381s
[2K
| Adam | epoch: 001 | loss: 0.69347 - acc: 0.4602 -- iter: 256/389
[A[ATraining Step: 9  | total loss: [1m[32m0.69316[0m[0m | time: 8.422s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5474 -- iter: 288/389
[A[ATraining Step: 10  | total loss: [1m[32m0.69281[0m[0m | time: 9.429s
[2K
| Adam | epoch: 001 | loss: 0.69281 - acc: 0.6018 -- iter: 320/389
[A[ATraining Step: 11  | total loss: [1m[32m0.69283[0m[0m | time: 10.158s
[2K
| Adam | epoch: 001 | loss: 0.69283 - acc: 0.5536 -- iter: 352/389
[A[ATraining Step: 12  | total loss: [1m[32m0.69414[0m[0m | time: 11.003s
[2K
| Adam | epoch: 001 | loss: 0.69414 - acc: 0.4732 -- iter: 384/389
[A[ATraining Step: 13  | total loss: [1m[32m0.69357[0m[0m | time: 12.242s
[2K
| Adam | epoch: 001 | loss: 0.69357 - acc: 0.4847 | val_loss: 0.69192 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 14  | total loss: [1m[32m0.68912[0m[0m | time: 0.186s
[2K
| Adam | epoch: 002 | loss: 0.68912 - acc: 0.6955 -- iter: 032/389
[A[ATraining Step: 15  | total loss: [1m[32m0.68417[0m[0m | time: 1.075s
[2K
| Adam | epoch: 002 | loss: 0.68417 - acc: 0.8147 -- iter: 064/389
[A[ATraining Step: 16  | total loss: [1m[32m0.68859[0m[0m | time: 1.985s
[2K
| Adam | epoch: 002 | loss: 0.68859 - acc: 0.6849 -- iter: 096/389
[A[ATraining Step: 17  | total loss: [1m[32m0.68821[0m[0m | time: 2.917s
[2K
| Adam | epoch: 002 | loss: 0.68821 - acc: 0.6409 -- iter: 128/389
[A[ATraining Step: 18  | total loss: [1m[32m0.69229[0m[0m | time: 3.743s
[2K
| Adam | epoch: 002 | loss: 0.69229 - acc: 0.5813 -- iter: 160/389
[A[ATraining Step: 19  | total loss: [1m[32m0.69602[0m[0m | time: 4.715s
[2K
| Adam | epoch: 002 | loss: 0.69602 - acc: 0.5438 -- iter: 192/389
[A[ATraining Step: 20  | total loss: [1m[32m0.69617[0m[0m | time: 5.758s
[2K
| Adam | epoch: 002 | loss: 0.69617 - acc: 0.5297 -- iter: 224/389
[A[ATraining Step: 21  | total loss: [1m[32m0.68966[0m[0m | time: 6.732s
[2K
| Adam | epoch: 002 | loss: 0.68966 - acc: 0.5593 -- iter: 256/389
[A[ATraining Step: 22  | total loss: [1m[32m0.68878[0m[0m | time: 7.448s
[2K
| Adam | epoch: 002 | loss: 0.68878 - acc: 0.5602 -- iter: 288/389
[A[ATraining Step: 23  | total loss: [1m[32m0.69043[0m[0m | time: 8.252s
[2K
| Adam | epoch: 002 | loss: 0.69043 - acc: 0.5428 -- iter: 320/389
[A[ATraining Step: 24  | total loss: [1m[32m0.68743[0m[0m | time: 9.092s
[2K
| Adam | epoch: 002 | loss: 0.68743 - acc: 0.5571 -- iter: 352/389
[A[ATraining Step: 25  | total loss: [1m[32m0.68983[0m[0m | time: 9.958s
[2K
| Adam | epoch: 002 | loss: 0.68983 - acc: 0.5415 -- iter: 384/389
[A[ATraining Step: 26  | total loss: [1m[32m0.68668[0m[0m | time: 11.818s
[2K
| Adam | epoch: 002 | loss: 0.68668 - acc: 0.5553 | val_loss: 0.69018 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 27  | total loss: [1m[32m0.69295[0m[0m | time: 0.197s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5250 -- iter: 032/389
[A[ATraining Step: 28  | total loss: [1m[32m0.70090[0m[0m | time: 0.378s
[2K
| Adam | epoch: 003 | loss: 0.70090 - acc: 0.4938 -- iter: 064/389
[A[ATraining Step: 29  | total loss: [1m[32m0.70382[0m[0m | time: 1.269s
[2K
| Adam | epoch: 003 | loss: 0.70382 - acc: 0.4710 -- iter: 096/389
[A[ATraining Step: 30  | total loss: [1m[32m0.69903[0m[0m | time: 2.280s
[2K
| Adam | epoch: 003 | loss: 0.69903 - acc: 0.5001 -- iter: 128/389
[A[ATraining Step: 31  | total loss: [1m[32m0.69790[0m[0m | time: 3.292s
[2K
| Adam | epoch: 003 | loss: 0.69790 - acc: 0.5000 -- iter: 160/389
[A[ATraining Step: 32  | total loss: [1m[32m0.69613[0m[0m | time: 4.306s
[2K
| Adam | epoch: 003 | loss: 0.69613 - acc: 0.5141 -- iter: 192/389
[A[ATraining Step: 33  | total loss: [1m[32m0.69631[0m[0m | time: 5.350s
[2K
| Adam | epoch: 003 | loss: 0.69631 - acc: 0.4973 -- iter: 224/389
[A[ATraining Step: 34  | total loss: [1m[32m0.69472[0m[0m | time: 6.354s
[2K
| Adam | epoch: 003 | loss: 0.69472 - acc: 0.5180 -- iter: 256/389
[A[ATraining Step: 35  | total loss: [1m[32m0.69431[0m[0m | time: 7.349s
[2K
| Adam | epoch: 003 | loss: 0.69431 - acc: 0.5207 -- iter: 288/389
[A[ATraining Step: 36  | total loss: [1m[32m0.69551[0m[0m | time: 8.347s
[2K
| Adam | epoch: 003 | loss: 0.69551 - acc: 0.4781 -- iter: 320/389
[A[ATraining Step: 37  | total loss: [1m[32m0.69434[0m[0m | time: 9.333s
[2K
| Adam | epoch: 003 | loss: 0.69434 - acc: 0.5075 -- iter: 352/389
[A[ATraining Step: 38  | total loss: [1m[32m0.69333[0m[0m | time: 10.344s
[2K
| Adam | epoch: 003 | loss: 0.69333 - acc: 0.5366 -- iter: 384/389
[A[ATraining Step: 39  | total loss: [1m[32m0.69382[0m[0m | time: 12.426s
[2K
| Adam | epoch: 003 | loss: 0.69382 - acc: 0.5117 | val_loss: 0.69219 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 40  | total loss: [1m[32m0.69370[0m[0m | time: 0.989s
[2K
| Adam | epoch: 004 | loss: 0.69370 - acc: 0.5095 -- iter: 032/389
[A[ATraining Step: 41  | total loss: [1m[32m0.69325[0m[0m | time: 1.198s
[2K
| Adam | epoch: 004 | loss: 0.69325 - acc: 0.5249 -- iter: 064/389
[A[ATraining Step: 42  | total loss: [1m[32m0.69187[0m[0m | time: 1.430s
[2K
| Adam | epoch: 004 | loss: 0.69187 - acc: 0.5745 -- iter: 096/389
[A[ATraining Step: 43  | total loss: [1m[32m0.69069[0m[0m | time: 2.447s
[2K
| Adam | epoch: 004 | loss: 0.69069 - acc: 0.6143 -- iter: 128/389
[A[ATraining Step: 44  | total loss: [1m[32m0.69126[0m[0m | time: 3.185s
[2K
| Adam | epoch: 004 | loss: 0.69126 - acc: 0.5891 -- iter: 160/389
[A[ATraining Step: 45  | total loss: [1m[32m0.69165[0m[0m | time: 3.818s
[2K
| Adam | epoch: 004 | loss: 0.69165 - acc: 0.5739 -- iter: 192/389
[A[ATraining Step: 46  | total loss: [1m[32m0.69174[0m[0m | time: 4.444s
[2K
| Adam | epoch: 004 | loss: 0.69174 - acc: 0.5668 -- iter: 224/389
[A[ATraining Step: 47  | total loss: [1m[32m0.69254[0m[0m | time: 5.054s
[2K
| Adam | epoch: 004 | loss: 0.69254 - acc: 0.5406 -- iter: 256/389
[A[ATraining Step: 48  | total loss: [1m[32m0.69287[0m[0m | time: 5.707s
[2K
| Adam | epoch: 004 | loss: 0.69287 - acc: 0.5290 -- iter: 288/389
[A[ATraining Step: 49  | total loss: [1m[32m0.69296[0m[0m | time: 6.329s
[2K
| Adam | epoch: 004 | loss: 0.69296 - acc: 0.5244 -- iter: 320/389
[A[ATraining Step: 50  | total loss: [1m[32m0.69210[0m[0m | time: 6.948s
[2K
| Adam | epoch: 004 | loss: 0.69210 - acc: 0.5449 -- iter: 352/389
[A[ATraining Step: 51  | total loss: [1m[32m0.69210[0m[0m | time: 7.583s
[2K
| Adam | epoch: 004 | loss: 0.69210 - acc: 0.5428 -- iter: 384/389
[A[ATraining Step: 52  | total loss: [1m[32m0.69174[0m[0m | time: 9.214s
[2K
| Adam | epoch: 004 | loss: 0.69174 - acc: 0.5504 | val_loss: 0.69160 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 53  | total loss: [1m[32m0.69218[0m[0m | time: 0.641s
[2K
| Adam | epoch: 005 | loss: 0.69218 - acc: 0.5384 -- iter: 032/389
[A[ATraining Step: 54  | total loss: [1m[32m0.69291[0m[0m | time: 1.279s
[2K
| Adam | epoch: 005 | loss: 0.69291 - acc: 0.5192 -- iter: 064/389
[A[ATraining Step: 55  | total loss: [1m[32m0.69222[0m[0m | time: 1.418s
[2K
| Adam | epoch: 005 | loss: 0.69222 - acc: 0.5343 -- iter: 096/389
[A[ATraining Step: 56  | total loss: [1m[32m0.69184[0m[0m | time: 1.554s
[2K
| Adam | epoch: 005 | loss: 0.69184 - acc: 0.5436 -- iter: 128/389
[A[ATraining Step: 57  | total loss: [1m[32m0.69151[0m[0m | time: 2.169s
[2K
| Adam | epoch: 005 | loss: 0.69151 - acc: 0.5514 -- iter: 160/389
[A[ATraining Step: 58  | total loss: [1m[32m0.69156[0m[0m | time: 2.790s
[2K
| Adam | epoch: 005 | loss: 0.69156 - acc: 0.5486 -- iter: 192/389
[A[ATraining Step: 59  | total loss: [1m[32m0.69183[0m[0m | time: 3.402s
[2K
| Adam | epoch: 005 | loss: 0.69183 - acc: 0.5421 -- iter: 224/389
[A[ATraining Step: 60  | total loss: [1m[32m0.69205[0m[0m | time: 4.051s
[2K
| Adam | epoch: 005 | loss: 0.69205 - acc: 0.5365 -- iter: 256/389
[A[ATraining Step: 61  | total loss: [1m[32m0.69243[0m[0m | time: 4.675s
[2K
| Adam | epoch: 005 | loss: 0.69243 - acc: 0.5277 -- iter: 288/389
[A[ATraining Step: 62  | total loss: [1m[32m0.69212[0m[0m | time: 5.287s
[2K
| Adam | epoch: 005 | loss: 0.69212 - acc: 0.5322 -- iter: 320/389
[A[ATraining Step: 63  | total loss: [1m[32m0.69163[0m[0m | time: 5.939s
[2K
| Adam | epoch: 005 | loss: 0.69163 - acc: 0.5400 -- iter: 352/389
[A[ATraining Step: 64  | total loss: [1m[32m0.69206[0m[0m | time: 6.569s
[2K
| Adam | epoch: 005 | loss: 0.69206 - acc: 0.5311 -- iter: 384/389
[A[ATraining Step: 65  | total loss: [1m[32m0.69201[0m[0m | time: 8.194s
[2K
| Adam | epoch: 005 | loss: 0.69201 - acc: 0.5311 | val_loss: 0.69095 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 66  | total loss: [1m[32m0.69084[0m[0m | time: 1.026s
[2K
| Adam | epoch: 006 | loss: 0.69084 - acc: 0.5501 -- iter: 032/389
[A[ATraining Step: 67  | total loss: [1m[32m0.69064[0m[0m | time: 1.874s
[2K
| Adam | epoch: 006 | loss: 0.69064 - acc: 0.5516 -- iter: 064/389
[A[ATraining Step: 68  | total loss: [1m[32m0.69100[0m[0m | time: 2.701s
[2K
| Adam | epoch: 006 | loss: 0.69100 - acc: 0.5455 -- iter: 096/389
[A[ATraining Step: 69  | total loss: [1m[32m0.69183[0m[0m | time: 2.898s
[2K
| Adam | epoch: 006 | loss: 0.69183 - acc: 0.5329 -- iter: 128/389
[A[ATraining Step: 70  | total loss: [1m[32m0.68942[0m[0m | time: 3.102s
[2K
| Adam | epoch: 006 | loss: 0.68942 - acc: 0.5637 -- iter: 160/389
[A[ATraining Step: 71  | total loss: [1m[32m0.68714[0m[0m | time: 3.984s
[2K
| Adam | epoch: 006 | loss: 0.68714 - acc: 0.5906 -- iter: 192/389
[A[ATraining Step: 72  | total loss: [1m[32m0.68928[0m[0m | time: 4.905s
[2K
| Adam | epoch: 006 | loss: 0.68928 - acc: 0.5664 -- iter: 224/389
[A[ATraining Step: 73  | total loss: [1m[32m0.68939[0m[0m | time: 5.823s
[2K
| Adam | epoch: 006 | loss: 0.68939 - acc: 0.5625 -- iter: 256/389
[A[ATraining Step: 74  | total loss: [1m[32m0.69030[0m[0m | time: 6.723s
[2K
| Adam | epoch: 006 | loss: 0.69030 - acc: 0.5522 -- iter: 288/389
[A[ATraining Step: 75  | total loss: [1m[32m0.69032[0m[0m | time: 7.669s
[2K
| Adam | epoch: 006 | loss: 0.69032 - acc: 0.5499 -- iter: 320/389
[A[ATraining Step: 76  | total loss: [1m[32m0.69082[0m[0m | time: 8.582s
[2K
| Adam | epoch: 006 | loss: 0.69082 - acc: 0.5446 -- iter: 352/389
[A[ATraining Step: 77  | total loss: [1m[32m0.69125[0m[0m | time: 9.484s
[2K
| Adam | epoch: 006 | loss: 0.69125 - acc: 0.5398 -- iter: 384/389
[A[ATraining Step: 78  | total loss: [1m[32m0.68962[0m[0m | time: 11.513s
[2K
| Adam | epoch: 006 | loss: 0.68962 - acc: 0.5520 | val_loss: 0.68963 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 79  | total loss: [1m[32m0.69068[0m[0m | time: 0.869s
[2K
| Adam | epoch: 007 | loss: 0.69068 - acc: 0.5434 -- iter: 032/389
[A[ATraining Step: 80  | total loss: [1m[32m0.69108[0m[0m | time: 1.779s
[2K
| Adam | epoch: 007 | loss: 0.69108 - acc: 0.5390 -- iter: 064/389
[A[ATraining Step: 81  | total loss: [1m[32m0.69416[0m[0m | time: 2.673s
[2K
| Adam | epoch: 007 | loss: 0.69416 - acc: 0.5161 -- iter: 096/389
[A[ATraining Step: 82  | total loss: [1m[32m0.69464[0m[0m | time: 3.592s
[2K
| Adam | epoch: 007 | loss: 0.69464 - acc: 0.5113 -- iter: 128/389
[A[ATraining Step: 83  | total loss: [1m[32m0.69438[0m[0m | time: 3.779s
[2K
| Adam | epoch: 007 | loss: 0.69438 - acc: 0.5133 -- iter: 160/389
[A[ATraining Step: 84  | total loss: [1m[32m0.69350[0m[0m | time: 3.965s
[2K
| Adam | epoch: 007 | loss: 0.69350 - acc: 0.5220 -- iter: 192/389
[A[ATraining Step: 85  | total loss: [1m[32m0.69261[0m[0m | time: 4.919s
[2K
| Adam | epoch: 007 | loss: 0.69261 - acc: 0.5298 -- iter: 224/389
[A[ATraining Step: 86  | total loss: [1m[32m0.69193[0m[0m | time: 5.808s
[2K
| Adam | epoch: 007 | loss: 0.69193 - acc: 0.5362 -- iter: 256/389
[A[ATraining Step: 87  | total loss: [1m[32m0.69158[0m[0m | time: 6.608s
[2K
| Adam | epoch: 007 | loss: 0.69158 - acc: 0.5388 -- iter: 288/389
[A[ATraining Step: 88  | total loss: [1m[32m0.69210[0m[0m | time: 7.711s
[2K
| Adam | epoch: 007 | loss: 0.69210 - acc: 0.5318 -- iter: 320/389
[A[ATraining Step: 89  | total loss: [1m[32m0.69112[0m[0m | time: 8.782s
[2K
| Adam | epoch: 007 | loss: 0.69112 - acc: 0.5411 -- iter: 352/389
[A[ATraining Step: 90  | total loss: [1m[32m0.69112[0m[0m | time: 9.619s
[2K
| Adam | epoch: 007 | loss: 0.69112 - acc: 0.5401 -- iter: 384/389
[A[ATraining Step: 91  | total loss: [1m[32m0.68971[0m[0m | time: 11.444s
[2K
| Adam | epoch: 007 | loss: 0.68971 - acc: 0.5549 | val_loss: 0.69002 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 92  | total loss: [1m[32m0.69009[0m[0m | time: 0.882s
[2K
| Adam | epoch: 008 | loss: 0.69009 - acc: 0.5494 -- iter: 032/389
[A[ATraining Step: 93  | total loss: [1m[32m0.69083[0m[0m | time: 1.794s
[2K
| Adam | epoch: 008 | loss: 0.69083 - acc: 0.5413 -- iter: 064/389
[A[ATraining Step: 94  | total loss: [1m[32m0.69149[0m[0m | time: 2.688s
[2K
| Adam | epoch: 008 | loss: 0.69149 - acc: 0.5341 -- iter: 096/389
[A[ATraining Step: 95  | total loss: [1m[32m0.69111[0m[0m | time: 3.625s
[2K
| Adam | epoch: 008 | loss: 0.69111 - acc: 0.5369 -- iter: 128/389
[A[ATraining Step: 96  | total loss: [1m[32m0.69204[0m[0m | time: 4.440s
[2K
| Adam | epoch: 008 | loss: 0.69204 - acc: 0.5270 -- iter: 160/389
[A[ATraining Step: 97  | total loss: [1m[32m0.69131[0m[0m | time: 4.715s
[2K
| Adam | epoch: 008 | loss: 0.69131 - acc: 0.5336 -- iter: 192/389
[A[ATraining Step: 98  | total loss: [1m[32m0.69054[0m[0m | time: 4.945s
[2K
| Adam | epoch: 008 | loss: 0.69054 - acc: 0.5403 -- iter: 224/389
[A[ATraining Step: 99  | total loss: [1m[32m0.68983[0m[0m | time: 6.069s
[2K
| Adam | epoch: 008 | loss: 0.68983 - acc: 0.5463 -- iter: 256/389
[A[ATraining Step: 100  | total loss: [1m[32m0.68861[0m[0m | time: 7.110s
[2K
| Adam | epoch: 008 | loss: 0.68861 - acc: 0.5573 -- iter: 288/389
[A[ATraining Step: 101  | total loss: [1m[32m0.68736[0m[0m | time: 7.899s
[2K
| Adam | epoch: 008 | loss: 0.68736 - acc: 0.5672 -- iter: 320/389
[A[ATraining Step: 102  | total loss: [1m[32m0.68763[0m[0m | time: 8.729s
[2K
| Adam | epoch: 008 | loss: 0.68763 - acc: 0.5636 -- iter: 352/389
[A[ATraining Step: 103  | total loss: [1m[32m0.68701[0m[0m | time: 9.595s
[2K
| Adam | epoch: 008 | loss: 0.68701 - acc: 0.5666 -- iter: 384/389
[A[ATraining Step: 104  | total loss: [1m[32m0.68879[0m[0m | time: 11.532s
[2K
| Adam | epoch: 008 | loss: 0.68879 - acc: 0.5537 | val_loss: 0.68882 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 105  | total loss: [1m[32m0.68944[0m[0m | time: 0.899s
[2K
| Adam | epoch: 009 | loss: 0.68944 - acc: 0.5483 -- iter: 032/389
[A[ATraining Step: 106  | total loss: [1m[32m0.69318[0m[0m | time: 1.763s
[2K
| Adam | epoch: 009 | loss: 0.69318 - acc: 0.5247 -- iter: 064/389
[A[ATraining Step: 107  | total loss: [1m[32m0.69339[0m[0m | time: 2.808s
[2K
| Adam | epoch: 009 | loss: 0.69339 - acc: 0.5223 -- iter: 096/389
[A[ATraining Step: 108  | total loss: [1m[32m0.69211[0m[0m | time: 3.798s
[2K
| Adam | epoch: 009 | loss: 0.69211 - acc: 0.5294 -- iter: 128/389
[A[ATraining Step: 109  | total loss: [1m[32m0.69064[0m[0m | time: 4.781s
[2K
| Adam | epoch: 009 | loss: 0.69064 - acc: 0.5390 -- iter: 160/389
[A[ATraining Step: 110  | total loss: [1m[32m0.68804[0m[0m | time: 5.513s
[2K
| Adam | epoch: 009 | loss: 0.68804 - acc: 0.5569 -- iter: 192/389
[A[ATraining Step: 111  | total loss: [1m[32m0.68972[0m[0m | time: 5.719s
[2K
| Adam | epoch: 009 | loss: 0.68972 - acc: 0.5450 -- iter: 224/389
[A[ATraining Step: 112  | total loss: [1m[32m0.68576[0m[0m | time: 5.905s
[2K
| Adam | epoch: 009 | loss: 0.68576 - acc: 0.5705 -- iter: 256/389
[A[ATraining Step: 113  | total loss: [1m[32m0.68153[0m[0m | time: 6.798s
[2K
| Adam | epoch: 009 | loss: 0.68153 - acc: 0.5934 -- iter: 288/389
[A[ATraining Step: 114  | total loss: [1m[32m0.68371[0m[0m | time: 7.669s
[2K
| Adam | epoch: 009 | loss: 0.68371 - acc: 0.5810 -- iter: 320/389
[A[ATraining Step: 115  | total loss: [1m[32m0.68369[0m[0m | time: 8.524s
[2K
| Adam | epoch: 009 | loss: 0.68369 - acc: 0.5791 -- iter: 352/389
[A[ATraining Step: 116  | total loss: [1m[32m0.68444[0m[0m | time: 9.443s
[2K
| Adam | epoch: 009 | loss: 0.68444 - acc: 0.5743 -- iter: 384/389
[A[ATraining Step: 117  | total loss: [1m[32m0.68803[0m[0m | time: 11.359s
[2K
| Adam | epoch: 009 | loss: 0.68803 - acc: 0.5607 | val_loss: 0.68823 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 118  | total loss: [1m[32m0.68932[0m[0m | time: 1.039s
[2K
| Adam | epoch: 010 | loss: 0.68932 - acc: 0.5546 -- iter: 032/389
[A[ATraining Step: 119  | total loss: [1m[32m0.69100[0m[0m | time: 2.119s
[2K
| Adam | epoch: 010 | loss: 0.69100 - acc: 0.5460 -- iter: 064/389
[A[ATraining Step: 120  | total loss: [1m[32m0.69442[0m[0m | time: 2.895s
[2K
| Adam | epoch: 010 | loss: 0.69442 - acc: 0.5289 -- iter: 096/389
[A[ATraining Step: 121  | total loss: [1m[32m0.69450[0m[0m | time: 3.782s
[2K
| Adam | epoch: 010 | loss: 0.69450 - acc: 0.5260 -- iter: 128/389
[A[ATraining Step: 122  | total loss: [1m[32m0.69399[0m[0m | time: 4.695s
[2K
| Adam | epoch: 010 | loss: 0.69399 - acc: 0.5265 -- iter: 160/389
[A[ATraining Step: 123  | total loss: [1m[32m0.69562[0m[0m | time: 5.594s
[2K
| Adam | epoch: 010 | loss: 0.69562 - acc: 0.5114 -- iter: 192/389
[A[ATraining Step: 124  | total loss: [1m[32m0.69510[0m[0m | time: 6.482s
[2K
| Adam | epoch: 010 | loss: 0.69510 - acc: 0.5134 -- iter: 224/389
[A[ATraining Step: 125  | total loss: [1m[32m0.69594[0m[0m | time: 6.671s
[2K
| Adam | epoch: 010 | loss: 0.69594 - acc: 0.5027 -- iter: 256/389
[A[ATraining Step: 126  | total loss: [1m[32m0.69672[0m[0m | time: 6.881s
[2K
| Adam | epoch: 010 | loss: 0.69672 - acc: 0.4924 -- iter: 288/389
[A[ATraining Step: 127  | total loss: [1m[32m0.69735[0m[0m | time: 7.792s
[2K
| Adam | epoch: 010 | loss: 0.69735 - acc: 0.4832 -- iter: 320/389
[A[ATraining Step: 128  | total loss: [1m[32m0.69625[0m[0m | time: 8.689s
[2K
| Adam | epoch: 010 | loss: 0.69625 - acc: 0.4942 -- iter: 352/389
[A[ATraining Step: 129  | total loss: [1m[32m0.69504[0m[0m | time: 9.569s
[2K
| Adam | epoch: 010 | loss: 0.69504 - acc: 0.5073 -- iter: 384/389
[A[ATraining Step: 130  | total loss: [1m[32m0.69393[0m[0m | time: 11.454s
[2K
| Adam | epoch: 010 | loss: 0.69393 - acc: 0.5191 | val_loss: 0.69047 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 131  | total loss: [1m[32m0.69266[0m[0m | time: 0.765s
[2K
| Adam | epoch: 011 | loss: 0.69266 - acc: 0.5328 -- iter: 032/389
[A[ATraining Step: 132  | total loss: [1m[32m0.69358[0m[0m | time: 1.639s
[2K
| Adam | epoch: 011 | loss: 0.69358 - acc: 0.5201 -- iter: 064/389
[A[ATraining Step: 133  | total loss: [1m[32m0.69310[0m[0m | time: 2.535s
[2K
| Adam | epoch: 011 | loss: 0.69310 - acc: 0.5244 -- iter: 096/389
[A[ATraining Step: 134  | total loss: [1m[32m0.69286[0m[0m | time: 3.396s
[2K
| Adam | epoch: 011 | loss: 0.69286 - acc: 0.5251 -- iter: 128/389
[A[ATraining Step: 135  | total loss: [1m[32m0.69357[0m[0m | time: 4.300s
[2K
| Adam | epoch: 011 | loss: 0.69357 - acc: 0.5163 -- iter: 160/389
[A[ATraining Step: 136  | total loss: [1m[32m0.69387[0m[0m | time: 5.219s
[2K
| Adam | epoch: 011 | loss: 0.69387 - acc: 0.5115 -- iter: 192/389
[A[ATraining Step: 137  | total loss: [1m[32m0.69447[0m[0m | time: 6.124s
[2K
| Adam | epoch: 011 | loss: 0.69447 - acc: 0.5041 -- iter: 224/389
[A[ATraining Step: 138  | total loss: [1m[32m0.69443[0m[0m | time: 7.003s
[2K
| Adam | epoch: 011 | loss: 0.69443 - acc: 0.5037 -- iter: 256/389
[A[ATraining Step: 139  | total loss: [1m[32m0.69392[0m[0m | time: 7.179s
[2K
| Adam | epoch: 011 | loss: 0.69392 - acc: 0.5096 -- iter: 288/389
[A[ATraining Step: 140  | total loss: [1m[32m0.69473[0m[0m | time: 7.365s
[2K
| Adam | epoch: 011 | loss: 0.69473 - acc: 0.4986 -- iter: 320/389
[A[ATraining Step: 141  | total loss: [1m[32m0.69529[0m[0m | time: 8.260s
[2K
| Adam | epoch: 011 | loss: 0.69529 - acc: 0.4888 -- iter: 352/389
[A[ATraining Step: 142  | total loss: [1m[32m0.69579[0m[0m | time: 9.253s
[2K
| Adam | epoch: 011 | loss: 0.69579 - acc: 0.4805 -- iter: 384/389
[A[ATraining Step: 143  | total loss: [1m[32m0.69535[0m[0m | time: 11.340s
[2K
| Adam | epoch: 011 | loss: 0.69535 - acc: 0.4856 | val_loss: 0.69115 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 144  | total loss: [1m[32m0.69498[0m[0m | time: 0.866s
[2K
| Adam | epoch: 012 | loss: 0.69498 - acc: 0.4902 -- iter: 032/389
[A[ATraining Step: 145  | total loss: [1m[32m0.69467[0m[0m | time: 1.749s
[2K
| Adam | epoch: 012 | loss: 0.69467 - acc: 0.4943 -- iter: 064/389
[A[ATraining Step: 146  | total loss: [1m[32m0.69437[0m[0m | time: 2.616s
[2K
| Adam | epoch: 012 | loss: 0.69437 - acc: 0.4980 -- iter: 096/389
[A[ATraining Step: 147  | total loss: [1m[32m0.69446[0m[0m | time: 3.533s
[2K
| Adam | epoch: 012 | loss: 0.69446 - acc: 0.4950 -- iter: 128/389
[A[ATraining Step: 148  | total loss: [1m[32m0.69352[0m[0m | time: 4.407s
[2K
| Adam | epoch: 012 | loss: 0.69352 - acc: 0.5112 -- iter: 160/389
[A[ATraining Step: 149  | total loss: [1m[32m0.69267[0m[0m | time: 5.416s
[2K
| Adam | epoch: 012 | loss: 0.69267 - acc: 0.5257 -- iter: 192/389
[A[ATraining Step: 150  | total loss: [1m[32m0.69238[0m[0m | time: 6.444s
[2K
| Adam | epoch: 012 | loss: 0.69238 - acc: 0.5294 -- iter: 224/389
[A[ATraining Step: 151  | total loss: [1m[32m0.69211[0m[0m | time: 7.441s
[2K
| Adam | epoch: 012 | loss: 0.69211 - acc: 0.5327 -- iter: 256/389
[A[ATraining Step: 152  | total loss: [1m[32m0.69307[0m[0m | time: 8.178s
[2K
| Adam | epoch: 012 | loss: 0.69307 - acc: 0.5169 -- iter: 288/389
[A[ATraining Step: 153  | total loss: [1m[32m0.69274[0m[0m | time: 8.360s
[2K
| Adam | epoch: 012 | loss: 0.69274 - acc: 0.5215 -- iter: 320/389
[A[ATraining Step: 154  | total loss: [1m[32m0.69222[0m[0m | time: 8.547s
[2K
| Adam | epoch: 012 | loss: 0.69222 - acc: 0.5293 -- iter: 352/389
[A[ATraining Step: 155  | total loss: [1m[32m0.69178[0m[0m | time: 9.420s
[2K
| Adam | epoch: 012 | loss: 0.69178 - acc: 0.5364 -- iter: 384/389
[A[ATraining Step: 156  | total loss: [1m[32m0.69154[0m[0m | time: 11.391s
[2K
| Adam | epoch: 012 | loss: 0.69154 - acc: 0.5390 | val_loss: 0.69085 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 157  | total loss: [1m[32m0.69308[0m[0m | time: 0.854s
[2K
| Adam | epoch: 013 | loss: 0.69308 - acc: 0.5163 -- iter: 032/389
[A[ATraining Step: 158  | total loss: [1m[32m0.69269[0m[0m | time: 1.693s
[2K
| Adam | epoch: 013 | loss: 0.69269 - acc: 0.5210 -- iter: 064/389
[A[ATraining Step: 159  | total loss: [1m[32m0.69341[0m[0m | time: 2.737s
[2K
| Adam | epoch: 013 | loss: 0.69341 - acc: 0.5095 -- iter: 096/389
[A[ATraining Step: 160  | total loss: [1m[32m0.69344[0m[0m | time: 3.772s
[2K
| Adam | epoch: 013 | loss: 0.69344 - acc: 0.5085 -- iter: 128/389
[A[ATraining Step: 161  | total loss: [1m[32m0.69261[0m[0m | time: 4.593s
[2K
| Adam | epoch: 013 | loss: 0.69261 - acc: 0.5202 -- iter: 160/389
[A[ATraining Step: 162  | total loss: [1m[32m0.69161[0m[0m | time: 5.469s
[2K
| Adam | epoch: 013 | loss: 0.69161 - acc: 0.5338 -- iter: 192/389
[A[ATraining Step: 163  | total loss: [1m[32m0.69138[0m[0m | time: 6.335s
[2K
| Adam | epoch: 013 | loss: 0.69138 - acc: 0.5367 -- iter: 224/389
[A[ATraining Step: 164  | total loss: [1m[32m0.69229[0m[0m | time: 7.283s
[2K
| Adam | epoch: 013 | loss: 0.69229 - acc: 0.5236 -- iter: 256/389
[A[ATraining Step: 165  | total loss: [1m[32m0.69175[0m[0m | time: 8.172s
[2K
| Adam | epoch: 013 | loss: 0.69175 - acc: 0.5306 -- iter: 288/389
[A[ATraining Step: 166  | total loss: [1m[32m0.69147[0m[0m | time: 9.111s
[2K
| Adam | epoch: 013 | loss: 0.69147 - acc: 0.5338 -- iter: 320/389
[A[ATraining Step: 167  | total loss: [1m[32m0.69196[0m[0m | time: 9.316s
[2K
| Adam | epoch: 013 | loss: 0.69196 - acc: 0.5273 -- iter: 352/389
[A[ATraining Step: 168  | total loss: [1m[32m0.68983[0m[0m | time: 9.532s
[2K
| Adam | epoch: 013 | loss: 0.68983 - acc: 0.5546 -- iter: 384/389
[A[ATraining Step: 169  | total loss: [1m[32m0.68777[0m[0m | time: 11.447s
[2K
| Adam | epoch: 013 | loss: 0.68777 - acc: 0.5791 | val_loss: 0.69004 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 170  | total loss: [1m[32m0.68779[0m[0m | time: 1.064s
[2K
| Adam | epoch: 014 | loss: 0.68779 - acc: 0.5775 -- iter: 032/389
[A[ATraining Step: 171  | total loss: [1m[32m0.68842[0m[0m | time: 1.775s
[2K
| Adam | epoch: 014 | loss: 0.68842 - acc: 0.5697 -- iter: 064/389
[A[ATraining Step: 172  | total loss: [1m[32m0.68943[0m[0m | time: 2.593s
[2K
| Adam | epoch: 014 | loss: 0.68943 - acc: 0.5596 -- iter: 096/389
[A[ATraining Step: 173  | total loss: [1m[32m0.68879[0m[0m | time: 3.440s
[2K
| Adam | epoch: 014 | loss: 0.68879 - acc: 0.5630 -- iter: 128/389
[A[ATraining Step: 174  | total loss: [1m[32m0.68797[0m[0m | time: 4.320s
[2K
| Adam | epoch: 014 | loss: 0.68797 - acc: 0.5661 -- iter: 160/389
[A[ATraining Step: 175  | total loss: [1m[32m0.68658[0m[0m | time: 5.196s
[2K
| Adam | epoch: 014 | loss: 0.68658 - acc: 0.5720 -- iter: 192/389
[A[ATraining Step: 176  | total loss: [1m[32m0.69168[0m[0m | time: 6.093s
[2K
| Adam | epoch: 014 | loss: 0.69168 - acc: 0.5492 -- iter: 224/389
[A[ATraining Step: 177  | total loss: [1m[32m0.69241[0m[0m | time: 7.016s
[2K
| Adam | epoch: 014 | loss: 0.69241 - acc: 0.5443 -- iter: 256/389
[A[ATraining Step: 178  | total loss: [1m[32m0.69250[0m[0m | time: 7.973s
[2K
| Adam | epoch: 014 | loss: 0.69250 - acc: 0.5430 -- iter: 288/389
[A[ATraining Step: 179  | total loss: [1m[32m0.69295[0m[0m | time: 8.850s
[2K
| Adam | epoch: 014 | loss: 0.69295 - acc: 0.5387 -- iter: 320/389
[A[ATraining Step: 180  | total loss: [1m[32m0.69263[0m[0m | time: 9.764s
[2K
| Adam | epoch: 014 | loss: 0.69263 - acc: 0.5379 -- iter: 352/389
[A[ATraining Step: 181  | total loss: [1m[32m0.69371[0m[0m | time: 9.997s
[2K
| Adam | epoch: 014 | loss: 0.69371 - acc: 0.5279 -- iter: 384/389
[A[ATraining Step: 182  | total loss: [1m[32m0.69730[0m[0m | time: 11.233s
[2K
| Adam | epoch: 014 | loss: 0.69730 - acc: 0.4951 | val_loss: 0.69029 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 183  | total loss: [1m[32m0.70011[0m[0m | time: 0.834s
[2K
| Adam | epoch: 015 | loss: 0.70011 - acc: 0.4656 -- iter: 032/389
[A[ATraining Step: 184  | total loss: [1m[32m0.69805[0m[0m | time: 1.689s
[2K
| Adam | epoch: 015 | loss: 0.69805 - acc: 0.4846 -- iter: 064/389
[A[ATraining Step: 185  | total loss: [1m[32m0.69652[0m[0m | time: 2.547s
[2K
| Adam | epoch: 015 | loss: 0.69652 - acc: 0.4987 -- iter: 096/389
[A[ATraining Step: 186  | total loss: [1m[32m0.69626[0m[0m | time: 3.380s
[2K
| Adam | epoch: 015 | loss: 0.69626 - acc: 0.4988 -- iter: 128/389
[A[ATraining Step: 187  | total loss: [1m[32m0.69575[0m[0m | time: 4.288s
[2K
| Adam | epoch: 015 | loss: 0.69575 - acc: 0.5021 -- iter: 160/389
[A[ATraining Step: 188  | total loss: [1m[32m0.69531[0m[0m | time: 5.175s
[2K
| Adam | epoch: 015 | loss: 0.69531 - acc: 0.5050 -- iter: 192/389
[A[ATraining Step: 189  | total loss: [1m[32m0.69491[0m[0m | time: 6.086s
[2K
| Adam | epoch: 015 | loss: 0.69491 - acc: 0.5076 -- iter: 224/389
[A[ATraining Step: 190  | total loss: [1m[32m0.69526[0m[0m | time: 6.963s
[2K
| Adam | epoch: 015 | loss: 0.69526 - acc: 0.5006 -- iter: 256/389
[A[ATraining Step: 191  | total loss: [1m[32m0.69509[0m[0m | time: 7.837s
[2K
| Adam | epoch: 015 | loss: 0.69509 - acc: 0.5005 -- iter: 288/389
[A[ATraining Step: 192  | total loss: [1m[32m0.69431[0m[0m | time: 8.907s
[2K
| Adam | epoch: 015 | loss: 0.69431 - acc: 0.5099 -- iter: 320/389
[A[ATraining Step: 193  | total loss: [1m[32m0.69363[0m[0m | time: 9.981s
[2K
| Adam | epoch: 015 | loss: 0.69363 - acc: 0.5182 -- iter: 352/389
[A[ATraining Step: 194  | total loss: [1m[32m0.69358[0m[0m | time: 10.758s
[2K
| Adam | epoch: 015 | loss: 0.69358 - acc: 0.5164 -- iter: 384/389
[A[ATraining Step: 195  | total loss: [1m[32m0.69316[0m[0m | time: 11.952s
[2K
| Adam | epoch: 015 | loss: 0.69316 - acc: 0.5210 | val_loss: 0.69068 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 196  | total loss: [1m[32m0.69257[0m[0m | time: 0.203s
[2K
| Adam | epoch: 016 | loss: 0.69257 - acc: 0.5289 -- iter: 032/389
[A[ATraining Step: 197  | total loss: [1m[32m0.69198[0m[0m | time: 1.160s
[2K
| Adam | epoch: 016 | loss: 0.69198 - acc: 0.5360 -- iter: 064/389
[A[ATraining Step: 198  | total loss: [1m[32m0.69307[0m[0m | time: 2.135s
[2K
| Adam | epoch: 016 | loss: 0.69307 - acc: 0.5199 -- iter: 096/389
[A[ATraining Step: 199  | total loss: [1m[32m0.69311[0m[0m | time: 3.038s
[2K
| Adam | epoch: 016 | loss: 0.69311 - acc: 0.5179 -- iter: 128/389
[A[ATraining Step: 200  | total loss: [1m[32m0.69224[0m[0m | time: 4.926s
[2K
| Adam | epoch: 016 | loss: 0.69224 - acc: 0.5286 | val_loss: 0.69045 - val_acc: 0.5410 -- iter: 160/389
--
Training Step: 201  | total loss: [1m[32m0.69284[0m[0m | time: 5.861s
[2K
| Adam | epoch: 016 | loss: 0.69284 - acc: 0.5195 -- iter: 192/389
[A[ATraining Step: 202  | total loss: [1m[32m0.69194[0m[0m | time: 6.690s
[2K
| Adam | epoch: 016 | loss: 0.69194 - acc: 0.5301 -- iter: 224/389
[A[ATraining Step: 203  | total loss: [1m[32m0.69208[0m[0m | time: 7.609s
[2K
| Adam | epoch: 016 | loss: 0.69208 - acc: 0.5271 -- iter: 256/389
[A[ATraining Step: 204  | total loss: [1m[32m0.69293[0m[0m | time: 8.554s
[2K
| Adam | epoch: 016 | loss: 0.69293 - acc: 0.5150 -- iter: 288/389
[A[ATraining Step: 205  | total loss: [1m[32m0.69269[0m[0m | time: 9.439s
[2K
| Adam | epoch: 016 | loss: 0.69269 - acc: 0.5166 -- iter: 320/389
[A[ATraining Step: 206  | total loss: [1m[32m0.69179[0m[0m | time: 10.336s
[2K
| Adam | epoch: 016 | loss: 0.69179 - acc: 0.5275 -- iter: 352/389
[A[ATraining Step: 207  | total loss: [1m[32m0.69115[0m[0m | time: 11.277s
[2K
| Adam | epoch: 016 | loss: 0.69115 - acc: 0.5341 -- iter: 384/389
[A[ATraining Step: 208  | total loss: [1m[32m0.69070[0m[0m | time: 13.255s
[2K
| Adam | epoch: 016 | loss: 0.69070 - acc: 0.5369 | val_loss: 0.68872 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 209  | total loss: [1m[32m0.69124[0m[0m | time: 0.251s
[2K
| Adam | epoch: 017 | loss: 0.69124 - acc: 0.5301 -- iter: 032/389
[A[ATraining Step: 210  | total loss: [1m[32m0.69240[0m[0m | time: 0.490s
[2K
| Adam | epoch: 017 | loss: 0.69240 - acc: 0.5171 -- iter: 064/389
[A[ATraining Step: 211  | total loss: [1m[32m0.69346[0m[0m | time: 1.490s
[2K
| Adam | epoch: 017 | loss: 0.69346 - acc: 0.5054 -- iter: 096/389
[A[ATraining Step: 212  | total loss: [1m[32m0.69252[0m[0m | time: 2.209s
[2K
| Adam | epoch: 017 | loss: 0.69252 - acc: 0.5142 -- iter: 128/389
[A[ATraining Step: 213  | total loss: [1m[32m0.69310[0m[0m | time: 3.029s
[2K
| Adam | epoch: 017 | loss: 0.69310 - acc: 0.5066 -- iter: 160/389
[A[ATraining Step: 214  | total loss: [1m[32m0.69413[0m[0m | time: 3.902s
[2K
| Adam | epoch: 017 | loss: 0.69413 - acc: 0.4934 -- iter: 192/389
[A[ATraining Step: 215  | total loss: [1m[32m0.69230[0m[0m | time: 4.815s
[2K
| Adam | epoch: 017 | loss: 0.69230 - acc: 0.5128 -- iter: 224/389
[A[ATraining Step: 216  | total loss: [1m[32m0.69298[0m[0m | time: 5.722s
[2K
| Adam | epoch: 017 | loss: 0.69298 - acc: 0.5053 -- iter: 256/389
[A[ATraining Step: 217  | total loss: [1m[32m0.69278[0m[0m | time: 6.663s
[2K
| Adam | epoch: 017 | loss: 0.69278 - acc: 0.5047 -- iter: 288/389
[A[ATraining Step: 218  | total loss: [1m[32m0.69173[0m[0m | time: 7.550s
[2K
| Adam | epoch: 017 | loss: 0.69173 - acc: 0.5136 -- iter: 320/389
[A[ATraining Step: 219  | total loss: [1m[32m0.69223[0m[0m | time: 8.450s
[2K
| Adam | epoch: 017 | loss: 0.69223 - acc: 0.5029 -- iter: 352/389
[A[ATraining Step: 220  | total loss: [1m[32m0.69233[0m[0m | time: 9.339s
[2K
| Adam | epoch: 017 | loss: 0.69233 - acc: 0.4995 -- iter: 384/389
[A[ATraining Step: 221  | total loss: [1m[32m0.69201[0m[0m | time: 11.310s
[2K
| Adam | epoch: 017 | loss: 0.69201 - acc: 0.4995 | val_loss: 0.68249 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 222  | total loss: [1m[32m0.69253[0m[0m | time: 0.887s
[2K
| Adam | epoch: 018 | loss: 0.69253 - acc: 0.4933 -- iter: 032/389
[A[ATraining Step: 223  | total loss: [1m[32m0.69010[0m[0m | time: 1.079s
[2K
| Adam | epoch: 018 | loss: 0.69010 - acc: 0.5065 -- iter: 064/389
[A[ATraining Step: 224  | total loss: [1m[32m0.68718[0m[0m | time: 1.270s
[2K
| Adam | epoch: 018 | loss: 0.68718 - acc: 0.5359 -- iter: 096/389
[A[ATraining Step: 225  | total loss: [1m[32m0.68302[0m[0m | time: 2.156s
[2K
| Adam | epoch: 018 | loss: 0.68302 - acc: 0.5623 -- iter: 128/389
[A[ATraining Step: 226  | total loss: [1m[32m0.68006[0m[0m | time: 3.055s
[2K
| Adam | epoch: 018 | loss: 0.68006 - acc: 0.5685 -- iter: 160/389
[A[ATraining Step: 227  | total loss: [1m[32m0.67833[0m[0m | time: 3.968s
[2K
| Adam | epoch: 018 | loss: 0.67833 - acc: 0.5711 -- iter: 192/389
[A[ATraining Step: 228  | total loss: [1m[32m0.68685[0m[0m | time: 4.925s
[2K
| Adam | epoch: 018 | loss: 0.68685 - acc: 0.5577 -- iter: 224/389
[A[ATraining Step: 229  | total loss: [1m[32m0.68972[0m[0m | time: 5.891s
[2K
| Adam | epoch: 018 | loss: 0.68972 - acc: 0.5488 -- iter: 256/389
[A[ATraining Step: 230  | total loss: [1m[32m0.69179[0m[0m | time: 6.808s
[2K
| Adam | epoch: 018 | loss: 0.69179 - acc: 0.5377 -- iter: 288/389
[A[ATraining Step: 231  | total loss: [1m[32m0.69287[0m[0m | time: 7.697s
[2K
| Adam | epoch: 018 | loss: 0.69287 - acc: 0.5277 -- iter: 320/389
[A[ATraining Step: 232  | total loss: [1m[32m0.69193[0m[0m | time: 8.763s
[2K
| Adam | epoch: 018 | loss: 0.69193 - acc: 0.5280 -- iter: 352/389
[A[ATraining Step: 233  | total loss: [1m[32m0.68990[0m[0m | time: 9.783s
[2K
| Adam | epoch: 018 | loss: 0.68990 - acc: 0.5408 -- iter: 384/389
[A[ATraining Step: 234  | total loss: [1m[32m0.68951[0m[0m | time: 11.510s
[2K
| Adam | epoch: 018 | loss: 0.68951 - acc: 0.5399 | val_loss: 0.68686 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 235  | total loss: [1m[32m0.68950[0m[0m | time: 0.865s
[2K
| Adam | epoch: 019 | loss: 0.68950 - acc: 0.5359 -- iter: 032/389
[A[ATraining Step: 236  | total loss: [1m[32m0.69024[0m[0m | time: 1.722s
[2K
| Adam | epoch: 019 | loss: 0.69024 - acc: 0.5198 -- iter: 064/389
[A[ATraining Step: 237  | total loss: [1m[32m0.68958[0m[0m | time: 1.924s
[2K
| Adam | epoch: 019 | loss: 0.68958 - acc: 0.5241 -- iter: 096/389
[A[ATraining Step: 238  | total loss: [1m[32m0.68845[0m[0m | time: 2.132s
[2K
| Adam | epoch: 019 | loss: 0.68845 - acc: 0.5517 -- iter: 128/389
[A[ATraining Step: 239  | total loss: [1m[32m0.68705[0m[0m | time: 2.976s
[2K
| Adam | epoch: 019 | loss: 0.68705 - acc: 0.5765 -- iter: 160/389
[A[ATraining Step: 240  | total loss: [1m[32m0.68610[0m[0m | time: 3.860s
[2K
| Adam | epoch: 019 | loss: 0.68610 - acc: 0.5814 -- iter: 192/389
[A[ATraining Step: 241  | total loss: [1m[32m0.68691[0m[0m | time: 4.738s
[2K
| Adam | epoch: 019 | loss: 0.68691 - acc: 0.5670 -- iter: 224/389
[A[ATraining Step: 242  | total loss: [1m[32m0.68729[0m[0m | time: 5.641s
[2K
| Adam | epoch: 019 | loss: 0.68729 - acc: 0.5603 -- iter: 256/389
[A[ATraining Step: 243  | total loss: [1m[32m0.68646[0m[0m | time: 6.666s
[2K
| Adam | epoch: 019 | loss: 0.68646 - acc: 0.5574 -- iter: 288/389
[A[ATraining Step: 244  | total loss: [1m[32m0.68651[0m[0m | time: 7.736s
[2K
| Adam | epoch: 019 | loss: 0.68651 - acc: 0.5548 -- iter: 320/389
[A[ATraining Step: 245  | total loss: [1m[32m0.68914[0m[0m | time: 8.486s
[2K
| Adam | epoch: 019 | loss: 0.68914 - acc: 0.5337 -- iter: 352/389
[A[ATraining Step: 246  | total loss: [1m[32m0.68754[0m[0m | time: 9.329s
[2K
| Adam | epoch: 019 | loss: 0.68754 - acc: 0.5334 -- iter: 384/389
[A[ATraining Step: 247  | total loss: [1m[32m0.68338[0m[0m | time: 11.209s
[2K
| Adam | epoch: 019 | loss: 0.68338 - acc: 0.5551 | val_loss: 0.67033 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 248  | total loss: [1m[32m0.68425[0m[0m | time: 0.873s
[2K
| Adam | epoch: 020 | loss: 0.68425 - acc: 0.5464 -- iter: 032/389
[A[ATraining Step: 249  | total loss: [1m[32m0.68281[0m[0m | time: 1.774s
[2K
| Adam | epoch: 020 | loss: 0.68281 - acc: 0.5480 -- iter: 064/389
[A[ATraining Step: 250  | total loss: [1m[32m0.67829[0m[0m | time: 2.627s
[2K
| Adam | epoch: 020 | loss: 0.67829 - acc: 0.5589 -- iter: 096/389
[A[ATraining Step: 251  | total loss: [1m[32m0.67630[0m[0m | time: 2.789s
[2K
| Adam | epoch: 020 | loss: 0.67630 - acc: 0.5624 -- iter: 128/389
[A[ATraining Step: 252  | total loss: [1m[32m0.67293[0m[0m | time: 2.983s
[2K
| Adam | epoch: 020 | loss: 0.67293 - acc: 0.5661 -- iter: 160/389
[A[ATraining Step: 253  | total loss: [1m[32m0.66799[0m[0m | time: 4.080s
[2K
| Adam | epoch: 020 | loss: 0.66799 - acc: 0.5695 -- iter: 192/389
[A[ATraining Step: 254  | total loss: [1m[32m0.67233[0m[0m | time: 5.207s
[2K
| Adam | epoch: 020 | loss: 0.67233 - acc: 0.5626 -- iter: 224/389
[A[ATraining Step: 255  | total loss: [1m[32m0.67125[0m[0m | time: 5.994s
[2K
| Adam | epoch: 020 | loss: 0.67125 - acc: 0.5594 -- iter: 256/389
[A[ATraining Step: 256  | total loss: [1m[32m0.66815[0m[0m | time: 6.823s
[2K
| Adam | epoch: 020 | loss: 0.66815 - acc: 0.5566 -- iter: 288/389
[A[ATraining Step: 257  | total loss: [1m[32m0.66798[0m[0m | time: 7.728s
[2K
| Adam | epoch: 020 | loss: 0.66798 - acc: 0.5541 -- iter: 320/389
[A[ATraining Step: 258  | total loss: [1m[32m0.66585[0m[0m | time: 8.619s
[2K
| Adam | epoch: 020 | loss: 0.66585 - acc: 0.5518 -- iter: 352/389
[A[ATraining Step: 259  | total loss: [1m[32m0.66424[0m[0m | time: 9.477s
[2K
| Adam | epoch: 020 | loss: 0.66424 - acc: 0.5497 -- iter: 384/389
[A[ATraining Step: 260  | total loss: [1m[32m0.66438[0m[0m | time: 11.408s
[2K
| Adam | epoch: 020 | loss: 0.66438 - acc: 0.5323 | val_loss: 0.62823 - val_acc: 0.5410 -- iter: 389/389
--
Training Step: 261  | total loss: [1m[32m0.66272[0m[0m | time: 0.880s
[2K
| Adam | epoch: 021 | loss: 0.66272 - acc: 0.5228 -- iter: 032/389
[A[ATraining Step: 262  | total loss: [1m[32m0.65718[0m[0m | time: 1.969s
[2K
| Adam | epoch: 021 | loss: 0.65718 - acc: 0.5330 -- iter: 064/389
[A[ATraining Step: 263  | total loss: [1m[32m0.65834[0m[0m | time: 3.019s
[2K
| Adam | epoch: 021 | loss: 0.65834 - acc: 0.5203 -- iter: 096/389
[A[ATraining Step: 264  | total loss: [1m[32m0.65203[0m[0m | time: 3.820s
[2K
| Adam | epoch: 021 | loss: 0.65203 - acc: 0.5402 -- iter: 128/389
[A[ATraining Step: 265  | total loss: [1m[32m0.64981[0m[0m | time: 4.004s
[2K
| Adam | epoch: 021 | loss: 0.64981 - acc: 0.5580 -- iter: 160/389
[A[ATraining Step: 266  | total loss: [1m[32m0.65568[0m[0m | time: 4.176s
[2K
| Adam | epoch: 021 | loss: 0.65568 - acc: 0.5622 -- iter: 192/389
[A[ATraining Step: 267  | total loss: [1m[32m0.65478[0m[0m | time: 5.062s
[2K
| Adam | epoch: 021 | loss: 0.65478 - acc: 0.5860 -- iter: 224/389
[A[ATraining Step: 268  | total loss: [1m[32m0.64818[0m[0m | time: 6.000s
[2K
| Adam | epoch: 021 | loss: 0.64818 - acc: 0.6024 -- iter: 256/389
[A[ATraining Step: 269  | total loss: [1m[32m0.65631[0m[0m | time: 6.890s
[2K
| Adam | epoch: 021 | loss: 0.65631 - acc: 0.5859 -- iter: 288/389
[A[ATraining Step: 270  | total loss: [1m[32m0.66344[0m[0m | time: 7.850s
[2K
| Adam | epoch: 021 | loss: 0.66344 - acc: 0.5711 -- iter: 320/389
[A[ATraining Step: 271  | total loss: [1m[32m0.66333[0m[0m | time: 8.767s
[2K
| Adam | epoch: 021 | loss: 0.66333 - acc: 0.5702 -- iter: 352/389
[A[ATraining Step: 272  | total loss: [1m[32m0.65594[0m[0m | time: 9.753s
[2K
| Adam | epoch: 021 | loss: 0.65594 - acc: 0.5819 -- iter: 384/389
[A[ATraining Step: 273  | total loss: [1m[32m0.64229[0m[0m | time: 11.600s
[2K
| Adam | epoch: 021 | loss: 0.64229 - acc: 0.5987 | val_loss: 0.73418 - val_acc: 0.6230 -- iter: 389/389
--
Training Step: 274  | total loss: [1m[32m0.64227[0m[0m | time: 0.879s
[2K
| Adam | epoch: 022 | loss: 0.64227 - acc: 0.6107 -- iter: 032/389
[A[ATraining Step: 275  | total loss: [1m[32m0.64177[0m[0m | time: 1.734s
[2K
| Adam | epoch: 022 | loss: 0.64177 - acc: 0.6059 -- iter: 064/389
[A[ATraining Step: 276  | total loss: [1m[32m0.63863[0m[0m | time: 2.612s
[2K
| Adam | epoch: 022 | loss: 0.63863 - acc: 0.6172 -- iter: 096/389
[A[ATraining Step: 277  | total loss: [1m[32m0.62625[0m[0m | time: 3.586s
[2K
| Adam | epoch: 022 | loss: 0.62625 - acc: 0.6305 -- iter: 128/389
[A[ATraining Step: 278  | total loss: [1m[32m0.62021[0m[0m | time: 4.466s
[2K
| Adam | epoch: 022 | loss: 0.62021 - acc: 0.6456 -- iter: 160/389
[A[ATraining Step: 279  | total loss: [1m[32m0.61685[0m[0m | time: 4.670s
[2K
| Adam | epoch: 022 | loss: 0.61685 - acc: 0.6466 -- iter: 192/389
[A[ATraining Step: 280  | total loss: [1m[32m0.62871[0m[0m | time: 4.877s
[2K
| Adam | epoch: 022 | loss: 0.62871 - acc: 0.6220 -- iter: 224/389
[A[ATraining Step: 281  | total loss: [1m[32m0.63472[0m[0m | time: 5.711s
[2K
| Adam | epoch: 022 | loss: 0.63472 - acc: 0.5998 -- iter: 256/389
[A[ATraining Step: 282  | total loss: [1m[32m0.63868[0m[0m | time: 6.811s
[2K
| Adam | epoch: 022 | loss: 0.63868 - acc: 0.5929 -- iter: 288/389
[A[ATraining Step: 283  | total loss: [1m[32m0.64660[0m[0m | time: 7.894s
[2K
| Adam | epoch: 022 | loss: 0.64660 - acc: 0.5774 -- iter: 320/389
[A[ATraining Step: 284  | total loss: [1m[32m0.64920[0m[0m | time: 8.769s
[2K
| Adam | epoch: 022 | loss: 0.64920 - acc: 0.5728 -- iter: 352/389
[A[ATraining Step: 285  | total loss: [1m[32m0.65499[0m[0m | time: 9.604s
[2K
| Adam | epoch: 022 | loss: 0.65499 - acc: 0.5655 -- iter: 384/389
[A[ATraining Step: 286  | total loss: [1m[32m0.65843[0m[0m | time: 11.463s
[2K
| Adam | epoch: 022 | loss: 0.65843 - acc: 0.5589 | val_loss: 0.62415 - val_acc: 0.6311 -- iter: 389/389
--
Training Step: 287  | total loss: [1m[32m0.65567[0m[0m | time: 0.923s
[2K
| Adam | epoch: 023 | loss: 0.65567 - acc: 0.5718 -- iter: 032/389
[A[ATraining Step: 288  | total loss: [1m[32m0.65445[0m[0m | time: 1.902s
[2K
| Adam | epoch: 023 | loss: 0.65445 - acc: 0.5709 -- iter: 064/389
[A[ATraining Step: 289  | total loss: [1m[32m0.64759[0m[0m | time: 2.757s
[2K
| Adam | epoch: 023 | loss: 0.64759 - acc: 0.5982 -- iter: 096/389
[A[ATraining Step: 290  | total loss: [1m[32m0.64172[0m[0m | time: 3.738s
[2K
| Adam | epoch: 023 | loss: 0.64172 - acc: 0.6008 -- iter: 128/389
[A[ATraining Step: 291  | total loss: [1m[32m0.63141[0m[0m | time: 4.794s
[2K
| Adam | epoch: 023 | loss: 0.63141 - acc: 0.6126 -- iter: 160/389
[A[ATraining Step: 292  | total loss: [1m[32m0.63142[0m[0m | time: 5.810s
[2K
| Adam | epoch: 023 | loss: 0.63142 - acc: 0.6076 -- iter: 192/389
[A[ATraining Step: 293  | total loss: [1m[32m0.61972[0m[0m | time: 5.941s
[2K
| Adam | epoch: 023 | loss: 0.61972 - acc: 0.6187 -- iter: 224/389
[A[ATraining Step: 294  | total loss: [1m[32m0.62348[0m[0m | time: 6.073s
[2K
| Adam | epoch: 023 | loss: 0.62348 - acc: 0.6169 -- iter: 256/389
[A[ATraining Step: 295  | total loss: [1m[32m0.62614[0m[0m | time: 6.909s
[2K
| Adam | epoch: 023 | loss: 0.62614 - acc: 0.6152 -- iter: 288/389
[A[ATraining Step: 296  | total loss: [1m[32m0.61462[0m[0m | time: 7.782s
[2K
| Adam | epoch: 023 | loss: 0.61462 - acc: 0.6349 -- iter: 320/389
[A[ATraining Step: 297  | total loss: [1m[32m0.60939[0m[0m | time: 8.679s
[2K
| Adam | epoch: 023 | loss: 0.60939 - acc: 0.6433 -- iter: 352/389
[A[ATraining Step: 298  | total loss: [1m[32m0.61001[0m[0m | time: 9.621s
[2K
| Adam | epoch: 023 | loss: 0.61001 - acc: 0.6571 -- iter: 384/389
[A[ATraining Step: 299  | total loss: [1m[32m0.60581[0m[0m | time: 11.617s
[2K
| Adam | epoch: 023 | loss: 0.60581 - acc: 0.6601 | val_loss: 0.57409 - val_acc: 0.6721 -- iter: 389/389
--
Training Step: 300  | total loss: [1m[32m0.59481[0m[0m | time: 1.026s
[2K
| Adam | epoch: 024 | loss: 0.59481 - acc: 0.6660 -- iter: 032/389
[A[ATraining Step: 301  | total loss: [1m[32m0.58548[0m[0m | time: 2.140s
[2K
| Adam | epoch: 024 | loss: 0.58548 - acc: 0.6775 -- iter: 064/389
[A[ATraining Step: 302  | total loss: [1m[32m0.57626[0m[0m | time: 3.074s
[2K
| Adam | epoch: 024 | loss: 0.57626 - acc: 0.6941 -- iter: 096/389
[A[ATraining Step: 303  | total loss: [1m[32m0.57063[0m[0m | time: 3.907s
[2K
| Adam | epoch: 024 | loss: 0.57063 - acc: 0.7028 -- iter: 128/389
[A[ATraining Step: 304  | total loss: [1m[32m0.62395[0m[0m | time: 4.784s
[2K
| Adam | epoch: 024 | loss: 0.62395 - acc: 0.6857 -- iter: 160/389
[A[ATraining Step: 305  | total loss: [1m[32m0.61373[0m[0m | time: 5.712s
[2K
| Adam | epoch: 024 | loss: 0.61373 - acc: 0.6952 -- iter: 192/389
[A[ATraining Step: 306  | total loss: [1m[32m0.61031[0m[0m | time: 6.704s
[2K
| Adam | epoch: 024 | loss: 0.61031 - acc: 0.6882 -- iter: 224/389
[A[ATraining Step: 307  | total loss: [1m[32m0.59478[0m[0m | time: 6.896s
[2K
| Adam | epoch: 024 | loss: 0.59478 - acc: 0.7069 -- iter: 256/389
[A[ATraining Step: 308  | total loss: [1m[32m0.59088[0m[0m | time: 7.085s
[2K
| Adam | epoch: 024 | loss: 0.59088 - acc: 0.6962 -- iter: 288/389
[A[ATraining Step: 309  | total loss: [1m[32m0.57890[0m[0m | time: 8.004s
[2K
| Adam | epoch: 024 | loss: 0.57890 - acc: 0.7066 -- iter: 320/389
[A[ATraining Step: 310  | total loss: [1m[32m0.56235[0m[0m | time: 8.919s
[2K
| Adam | epoch: 024 | loss: 0.56235 - acc: 0.7172 -- iter: 352/389
[A[ATraining Step: 311  | total loss: [1m[32m0.57099[0m[0m | time: 9.804s
[2K
| Adam | epoch: 024 | loss: 0.57099 - acc: 0.7111 -- iter: 384/389
[A[ATraining Step: 312  | total loss: [1m[32m0.56311[0m[0m | time: 11.652s
[2K
| Adam | epoch: 024 | loss: 0.56311 - acc: 0.7181 | val_loss: 0.56344 - val_acc: 0.6639 -- iter: 389/389
--
Training Step: 313  | total loss: [1m[32m0.56508[0m[0m | time: 0.873s
[2K
| Adam | epoch: 025 | loss: 0.56508 - acc: 0.7119 -- iter: 032/389
[A[ATraining Step: 314  | total loss: [1m[32m0.54685[0m[0m | time: 1.708s
[2K
| Adam | epoch: 025 | loss: 0.54685 - acc: 0.7314 -- iter: 064/389
[A[ATraining Step: 315  | total loss: [1m[32m0.52855[0m[0m | time: 2.589s
[2K
| Adam | epoch: 025 | loss: 0.52855 - acc: 0.7457 -- iter: 096/389
[A[ATraining Step: 316  | total loss: [1m[32m0.52526[0m[0m | time: 3.475s
[2K
| Adam | epoch: 025 | loss: 0.52526 - acc: 0.7493 -- iter: 128/389
[A[ATraining Step: 317  | total loss: [1m[32m0.52909[0m[0m | time: 4.366s
[2K
| Adam | epoch: 025 | loss: 0.52909 - acc: 0.7431 -- iter: 160/389
[A[ATraining Step: 318  | total loss: [1m[32m0.52268[0m[0m | time: 5.275s
[2K
| Adam | epoch: 025 | loss: 0.52268 - acc: 0.7438 -- iter: 192/389
[A[ATraining Step: 319  | total loss: [1m[32m0.52042[0m[0m | time: 6.198s
[2K
| Adam | epoch: 025 | loss: 0.52042 - acc: 0.7444 -- iter: 224/389
[A[ATraining Step: 320  | total loss: [1m[32m0.51033[0m[0m | time: 7.172s
[2K
| Adam | epoch: 025 | loss: 0.51033 - acc: 0.7450 -- iter: 256/389
[A[ATraining Step: 321  | total loss: [1m[32m0.51145[0m[0m | time: 7.358s
[2K
| Adam | epoch: 025 | loss: 0.51145 - acc: 0.7423 -- iter: 288/389
[A[ATraining Step: 322  | total loss: [1m[32m0.48517[0m[0m | time: 7.540s
[2K
| Adam | epoch: 025 | loss: 0.48517 - acc: 0.7681 -- iter: 320/389
[A[ATraining Step: 323  | total loss: [1m[32m0.45498[0m[0m | time: 8.375s
[2K
| Adam | epoch: 025 | loss: 0.45498 - acc: 0.7913 -- iter: 352/389
[A[ATraining Step: 324  | total loss: [1m[32m0.45601[0m[0m | time: 9.248s
[2K
| Adam | epoch: 025 | loss: 0.45601 - acc: 0.7903 -- iter: 384/389
[A[ATraining Step: 325  | total loss: [1m[32m0.45060[0m[0m | time: 11.244s
[2K
| Adam | epoch: 025 | loss: 0.45060 - acc: 0.7956 | val_loss: 0.60963 - val_acc: 0.6721 -- iter: 389/389
--
Training Step: 326  | total loss: [1m[32m0.46170[0m[0m | time: 1.055s
[2K
| Adam | epoch: 026 | loss: 0.46170 - acc: 0.7879 -- iter: 032/389
[A[ATraining Step: 327  | total loss: [1m[32m0.45024[0m[0m | time: 1.991s
[2K
| Adam | epoch: 026 | loss: 0.45024 - acc: 0.7935 -- iter: 064/389
[A[ATraining Step: 328  | total loss: [1m[32m0.45431[0m[0m | time: 3.001s
[2K
| Adam | epoch: 026 | loss: 0.45431 - acc: 0.7861 -- iter: 096/389
[A[ATraining Step: 329  | total loss: [1m[32m0.45104[0m[0m | time: 4.005s
[2K
| Adam | epoch: 026 | loss: 0.45104 - acc: 0.7824 -- iter: 128/389
[A[ATraining Step: 330  | total loss: [1m[32m0.44650[0m[0m | time: 4.968s
[2K
| Adam | epoch: 026 | loss: 0.44650 - acc: 0.7886 -- iter: 160/389
[A[ATraining Step: 331  | total loss: [1m[32m0.45705[0m[0m | time: 5.935s
[2K
| Adam | epoch: 026 | loss: 0.45705 - acc: 0.7816 -- iter: 192/389
[A[ATraining Step: 332  | total loss: [1m[32m0.54814[0m[0m | time: 6.936s
[2K
| Adam | epoch: 026 | loss: 0.54814 - acc: 0.7597 -- iter: 224/389
[A[ATraining Step: 333  | total loss: [1m[32m0.51648[0m[0m | time: 7.938s
[2K
| Adam | epoch: 026 | loss: 0.51648 - acc: 0.7806 -- iter: 256/389
[A[ATraining Step: 334  | total loss: [1m[32m0.51107[0m[0m | time: 8.936s
[2K
| Adam | epoch: 026 | loss: 0.51107 - acc: 0.7807 -- iter: 288/389
[A[ATraining Step: 335  | total loss: [1m[32m0.50338[0m[0m | time: 9.149s
[2K
| Adam | epoch: 026 | loss: 0.50338 - acc: 0.7870 -- iter: 320/389
[A[ATraining Step: 336  | total loss: [1m[32m0.50462[0m[0m | time: 9.369s
[2K
| Adam | epoch: 026 | loss: 0.50462 - acc: 0.7883 -- iter: 352/389
[A[ATraining Step: 337  | total loss: [1m[32m0.49611[0m[0m | time: 10.311s
[2K
| Adam | epoch: 026 | loss: 0.49611 - acc: 0.7894 -- iter: 384/389
[A[ATraining Step: 338  | total loss: [1m[32m0.48291[0m[0m | time: 12.315s
[2K
| Adam | epoch: 026 | loss: 0.48291 - acc: 0.8011 | val_loss: 0.54451 - val_acc: 0.7377 -- iter: 389/389
--
Training Step: 339  | total loss: [1m[32m0.46940[0m[0m | time: 0.628s
[2K
| Adam | epoch: 027 | loss: 0.46940 - acc: 0.8148 -- iter: 032/389
[A[ATraining Step: 340  | total loss: [1m[32m0.45939[0m[0m | time: 1.256s
[2K
| Adam | epoch: 027 | loss: 0.45939 - acc: 0.8145 -- iter: 064/389
[A[ATraining Step: 341  | total loss: [1m[32m0.45325[0m[0m | time: 1.867s
[2K
| Adam | epoch: 027 | loss: 0.45325 - acc: 0.8206 -- iter: 096/389
[A[ATraining Step: 342  | total loss: [1m[32m0.46485[0m[0m | time: 2.497s
[2K
| Adam | epoch: 027 | loss: 0.46485 - acc: 0.8073 -- iter: 128/389
[A[ATraining Step: 343  | total loss: [1m[32m0.46383[0m[0m | time: 3.122s
[2K
| Adam | epoch: 027 | loss: 0.46383 - acc: 0.8109 -- iter: 160/389
[A[ATraining Step: 344  | total loss: [1m[32m0.45186[0m[0m | time: 3.755s
[2K
| Adam | epoch: 027 | loss: 0.45186 - acc: 0.8142 -- iter: 192/389
[A[ATraining Step: 345  | total loss: [1m[32m0.44045[0m[0m | time: 4.420s
[2K
| Adam | epoch: 027 | loss: 0.44045 - acc: 0.8234 -- iter: 224/389
[A[ATraining Step: 346  | total loss: [1m[32m0.42853[0m[0m | time: 5.084s
[2K
| Adam | epoch: 027 | loss: 0.42853 - acc: 0.8317 -- iter: 256/389
[A[ATraining Step: 347  | total loss: [1m[32m0.43759[0m[0m | time: 5.701s
[2K
| Adam | epoch: 027 | loss: 0.43759 - acc: 0.8266 -- iter: 288/389
[A[ATraining Step: 348  | total loss: [1m[32m0.44303[0m[0m | time: 6.324s
[2K
| Adam | epoch: 027 | loss: 0.44303 - acc: 0.8190 -- iter: 320/389
[A[ATraining Step: 349  | total loss: [1m[32m0.43822[0m[0m | time: 6.476s
[2K
| Adam | epoch: 027 | loss: 0.43822 - acc: 0.8215 -- iter: 352/389
[A[ATraining Step: 350  | total loss: [1m[32m0.43106[0m[0m | time: 6.601s
[2K
| Adam | epoch: 027 | loss: 0.43106 - acc: 0.8193 -- iter: 384/389
[A[ATraining Step: 351  | total loss: [1m[32m0.41576[0m[0m | time: 8.251s
[2K
| Adam | epoch: 027 | loss: 0.41576 - acc: 0.8374 | val_loss: 0.59002 - val_acc: 0.7459 -- iter: 389/389
--
Training Step: 352  | total loss: [1m[32m0.40497[0m[0m | time: 0.640s
[2K
| Adam | epoch: 028 | loss: 0.40497 - acc: 0.8380 -- iter: 032/389
[A[ATraining Step: 353  | total loss: [1m[32m0.39878[0m[0m | time: 1.264s
[2K
| Adam | epoch: 028 | loss: 0.39878 - acc: 0.8355 -- iter: 064/389
[A[ATraining Step: 354  | total loss: [1m[32m0.38238[0m[0m | time: 1.880s
[2K
| Adam | epoch: 028 | loss: 0.38238 - acc: 0.8425 -- iter: 096/389
[A[ATraining Step: 355  | total loss: [1m[32m0.38184[0m[0m | time: 2.500s
[2K
| Adam | epoch: 028 | loss: 0.38184 - acc: 0.8427 -- iter: 128/389
[A[ATraining Step: 356  | total loss: [1m[32m0.39455[0m[0m | time: 3.136s
[2K
| Adam | epoch: 028 | loss: 0.39455 - acc: 0.8334 -- iter: 160/389
[A[ATraining Step: 357  | total loss: [1m[32m0.39238[0m[0m | time: 3.745s
[2K
| Adam | epoch: 028 | loss: 0.39238 - acc: 0.8344 -- iter: 192/389
[A[ATraining Step: 358  | total loss: [1m[32m0.39846[0m[0m | time: 4.395s
[2K
| Adam | epoch: 028 | loss: 0.39846 - acc: 0.8385 -- iter: 224/389
[A[ATraining Step: 359  | total loss: [1m[32m0.38895[0m[0m | time: 5.013s
[2K
| Adam | epoch: 028 | loss: 0.38895 - acc: 0.8421 -- iter: 256/389
[A[ATraining Step: 360  | total loss: [1m[32m0.39328[0m[0m | time: 5.657s
[2K
| Adam | epoch: 028 | loss: 0.39328 - acc: 0.8454 -- iter: 288/389
[A[ATraining Step: 361  | total loss: [1m[32m0.37590[0m[0m | time: 6.272s
[2K
| Adam | epoch: 028 | loss: 0.37590 - acc: 0.8515 -- iter: 320/389
[A[ATraining Step: 362  | total loss: [1m[32m0.37434[0m[0m | time: 6.916s
[2K
| Adam | epoch: 028 | loss: 0.37434 - acc: 0.8539 -- iter: 352/389
[A[ATraining Step: 363  | total loss: [1m[32m0.37404[0m[0m | time: 7.045s
[2K
| Adam | epoch: 028 | loss: 0.37404 - acc: 0.8560 -- iter: 384/389
[A[ATraining Step: 364  | total loss: [1m[32m0.44218[0m[0m | time: 8.191s
[2K
| Adam | epoch: 028 | loss: 0.44218 - acc: 0.8104 | val_loss: 0.73801 - val_acc: 0.6639 -- iter: 389/389
--
Training Step: 365  | total loss: [1m[32m0.46822[0m[0m | time: 1.027s
[2K
| Adam | epoch: 029 | loss: 0.46822 - acc: 0.7693 -- iter: 032/389
[A[ATraining Step: 366  | total loss: [1m[32m0.49197[0m[0m | time: 1.793s
[2K
| Adam | epoch: 029 | loss: 0.49197 - acc: 0.7580 -- iter: 064/389
[A[ATraining Step: 367  | total loss: [1m[32m0.50155[0m[0m | time: 2.630s
[2K
| Adam | epoch: 029 | loss: 0.50155 - acc: 0.7479 -- iter: 096/389
[A[ATraining Step: 368  | total loss: [1m[32m0.48624[0m[0m | time: 3.497s
[2K
| Adam | epoch: 029 | loss: 0.48624 - acc: 0.7543 -- iter: 128/389
[A[ATraining Step: 369  | total loss: [1m[32m0.47997[0m[0m | time: 4.385s
[2K
| Adam | epoch: 029 | loss: 0.47997 - acc: 0.7570 -- iter: 160/389
[A[ATraining Step: 370  | total loss: [1m[32m0.46509[0m[0m | time: 5.260s
[2K
| Adam | epoch: 029 | loss: 0.46509 - acc: 0.7719 -- iter: 192/389
[A[ATraining Step: 371  | total loss: [1m[32m0.46041[0m[0m | time: 6.210s
[2K
| Adam | epoch: 029 | loss: 0.46041 - acc: 0.7760 -- iter: 224/389
[A[ATraining Step: 372  | total loss: [1m[32m0.46316[0m[0m | time: 7.200s
[2K
| Adam | epoch: 029 | loss: 0.46316 - acc: 0.7703 -- iter: 256/389
[A[ATraining Step: 373  | total loss: [1m[32m0.46578[0m[0m | time: 8.148s
[2K
| Adam | epoch: 029 | loss: 0.46578 - acc: 0.7651 -- iter: 288/389
[A[ATraining Step: 374  | total loss: [1m[32m0.46283[0m[0m | time: 8.953s
[2K
| Adam | epoch: 029 | loss: 0.46283 - acc: 0.7730 -- iter: 320/389
[A[ATraining Step: 375  | total loss: [1m[32m0.45268[0m[0m | time: 10.034s
[2K
| Adam | epoch: 029 | loss: 0.45268 - acc: 0.7894 -- iter: 352/389
[A[ATraining Step: 376  | total loss: [1m[32m0.45175[0m[0m | time: 11.060s
[2K
| Adam | epoch: 029 | loss: 0.45175 - acc: 0.7886 -- iter: 384/389
[A[ATraining Step: 377  | total loss: [1m[32m0.44673[0m[0m | time: 12.299s
[2K
| Adam | epoch: 029 | loss: 0.44673 - acc: 0.7910 | val_loss: 0.50597 - val_acc: 0.7377 -- iter: 389/389
--
Training Step: 378  | total loss: [1m[32m0.42790[0m[0m | time: 0.203s
[2K
| Adam | epoch: 030 | loss: 0.42790 - acc: 0.8119 -- iter: 032/389
[A[ATraining Step: 379  | total loss: [1m[32m0.40623[0m[0m | time: 1.047s
[2K
| Adam | epoch: 030 | loss: 0.40623 - acc: 0.8307 -- iter: 064/389
[A[ATraining Step: 380  | total loss: [1m[32m0.39807[0m[0m | time: 1.907s
[2K
| Adam | epoch: 030 | loss: 0.39807 - acc: 0.8383 -- iter: 096/389
[A[ATraining Step: 381  | total loss: [1m[32m0.39444[0m[0m | time: 2.848s
[2K
| Adam | epoch: 030 | loss: 0.39444 - acc: 0.8357 -- iter: 128/389
[A[ATraining Step: 382  | total loss: [1m[32m0.39820[0m[0m | time: 3.836s
[2K
| Adam | epoch: 030 | loss: 0.39820 - acc: 0.8365 -- iter: 160/389
[A[ATraining Step: 383  | total loss: [1m[32m0.38399[0m[0m | time: 4.756s
[2K
| Adam | epoch: 030 | loss: 0.38399 - acc: 0.8435 -- iter: 192/389
[A[ATraining Step: 384  | total loss: [1m[32m0.38740[0m[0m | time: 5.667s
[2K
| Adam | epoch: 030 | loss: 0.38740 - acc: 0.8435 -- iter: 224/389
[A[ATraining Step: 385  | total loss: [1m[32m0.38224[0m[0m | time: 6.687s
[2K
| Adam | epoch: 030 | loss: 0.38224 - acc: 0.8466 -- iter: 256/389
[A[ATraining Step: 386  | total loss: [1m[32m0.36267[0m[0m | time: 7.753s
[2K
| Adam | epoch: 030 | loss: 0.36267 - acc: 0.8557 -- iter: 288/389
[A[ATraining Step: 387  | total loss: [1m[32m0.36546[0m[0m | time: 8.593s
[2K
| Adam | epoch: 030 | loss: 0.36546 - acc: 0.8545 -- iter: 320/389
[A[ATraining Step: 388  | total loss: [1m[32m0.36327[0m[0m | time: 9.407s
[2K
| Adam | epoch: 030 | loss: 0.36327 - acc: 0.8535 -- iter: 352/389
[A[ATraining Step: 389  | total loss: [1m[32m0.36540[0m[0m | time: 10.261s
[2K
| Adam | epoch: 030 | loss: 0.36540 - acc: 0.8494 -- iter: 384/389
[A[ATraining Step: 390  | total loss: [1m[32m0.36864[0m[0m | time: 12.117s
[2K
| Adam | epoch: 030 | loss: 0.36864 - acc: 0.8425 | val_loss: 0.75061 - val_acc: 0.7049 -- iter: 389/389
--
Validation AUC:0.8222402597402598
Validation AUPRC:0.8628453303650567
Test AUC:0.8456989247311828
Test AUPRC:0.8739250519934594
BestTestF1Score	0.8	0.65	0.82	0.9	0.72	43	5	57	17	0.17
BestTestMCCScore	0.8	0.65	0.82	0.9	0.72	43	5	57	17	0.17
BestTestAccuracyScore	0.8	0.65	0.82	0.9	0.72	43	5	57	17	0.17
BestValidationF1Score	0.79	0.61	0.8	0.89	0.71	47	6	50	19	0.17
BestValidationMCC	0.79	0.61	0.8	0.89	0.71	47	6	50	19	0.17
BestValidationAccuracy	0.79	0.61	0.8	0.89	0.71	47	6	50	19	0.17
TestPredictions (Threshold:0.17)
CHEMBL2152615,TP,ACT,0.949999988079071	CHEMBL112265,TN,INACT,0.03999999910593033	CHEMBL402446,TP,ACT,0.6299999952316284	CHEMBL3805574,TP,ACT,0.9800000190734863	CHEMBL3769991,TP,ACT,0.9200000166893005	CHEMBL3805835,TP,ACT,1.0	CHEMBL2152579,TN,INACT,0.05000000074505806	CHEMBL1339743,TN,INACT,0.019999999552965164	CHEMBL3805687,TP,ACT,0.9900000095367432	CHEMBL86537,TN,INACT,0.07999999821186066	CHEMBL2152595,TN,INACT,0.07000000029802322	CHEMBL3770797,TP,ACT,0.8500000238418579	CHEMBL1945266,TN,INACT,0.05000000074505806	CHEMBL3311071,TN,INACT,0.03999999910593033	CHEMBL3427770,TP,ACT,0.46000000834465027	CHEMBL3770426,TP,ACT,0.800000011920929	CHEMBL1945131,TN,INACT,0.03999999910593033	CHEMBL2152620,TP,ACT,0.9800000190734863	CHEMBL596656,TN,INACT,0.05999999865889549	CHEMBL438203,TP,ACT,0.20999999344348907	CHEMBL373134,TN,INACT,0.05999999865889549	CHEMBL3806092,TP,ACT,0.9800000190734863	CHEMBL2152578,TN,INACT,0.05000000074505806	CHEMBL3408980,TN,INACT,0.03999999910593033	CHEMBL512966,FP,INACT,0.9599999785423279	CHEMBL3805072,TP,ACT,0.9900000095367432	CHEMBL2332054,TP,ACT,0.9700000286102295	CHEMBL3781129,TP,ACT,0.3400000035762787	CHEMBL3771012,TP,ACT,0.5299999713897705	CHEMBL3608449,FN,ACT,0.009999999776482582	CHEMBL3609646,FN,ACT,0.10000000149011612	CHEMBL291725,TN,INACT,0.05000000074505806	CHEMBL3698623,TN,INACT,0.03999999910593033	CHEMBL522622,TN,INACT,0.029999999329447746	CHEMBL3222152,TN,INACT,0.05000000074505806	CHEMBL3608448,FN,ACT,0.03999999910593033	CHEMBL522620,TP,ACT,0.3100000023841858	CHEMBL3311072,TN,INACT,0.029999999329447746	CHEMBL3401172,TN,INACT,0.05000000074505806	CHEMBL3805331,TP,ACT,0.6200000047683716	CHEMBL3311069,TN,INACT,0.029999999329447746	CHEMBL420311,TN,INACT,0.03999999910593033	CHEMBL3408821,TP,ACT,0.7799999713897705	CHEMBL3236969,TP,ACT,1.0	CHEMBL3805997,TP,ACT,0.6200000047683716	CHEMBL3343533,TP,ACT,0.30000001192092896	CHEMBL2314705,TN,INACT,0.05000000074505806	CHEMBL596655,TN,INACT,0.009999999776482582	CHEMBL3360221,TN,INACT,0.05999999865889549	CHEMBL380797,TN,INACT,0.019999999552965164	CHEMBL3804923,TP,ACT,0.9900000095367432	CHEMBL165,TN,INACT,0.05000000074505806	CHEMBL1945672,TN,INACT,0.03999999910593033	CHEMBL270110,TP,ACT,0.20999999344348907	CHEMBL1715925,FN,ACT,0.05999999865889549	CHEMBL1254458,TN,INACT,0.03999999910593033	CHEMBL491896,TN,INACT,0.05999999865889549	CHEMBL3771035,TP,ACT,0.9700000286102295	CHEMBL3805728,TP,ACT,0.949999988079071	CHEMBL1374426,TN,INACT,0.07999999821186066	CHEMBL2181515,TN,INACT,0.05000000074505806	CHEMBL407517,FN,ACT,0.09000000357627869	CHEMBL3358387,TP,ACT,0.6299999952316284	CHEMBL448638,TN,INACT,0.05999999865889549	CHEMBL2017559,TN,INACT,0.029999999329447746	CHEMBL521807,FP,INACT,0.23000000417232513	CHEMBL3806211,TP,ACT,0.9900000095367432	CHEMBL1797920,TN,INACT,0.05000000074505806	CHEMBL3806001,TP,ACT,0.8799999952316284	CHEMBL228175,FN,ACT,0.029999999329447746	CHEMBL3350587,TN,INACT,0.03999999910593033	CHEMBL3222156,TN,INACT,0.05999999865889549	CHEMBL1945265,FN,ACT,0.03999999910593033	CHEMBL2332037,FN,ACT,0.029999999329447746	CHEMBL3311084,TN,INACT,0.019999999552965164	CHEMBL3805740,TP,ACT,0.9700000286102295	CHEMBL490736,TN,INACT,0.07999999821186066	CHEMBL491106,TN,INACT,0.05999999865889549	CHEMBL3769691,FN,ACT,0.1599999964237213	CHEMBL3781645,TP,ACT,0.3499999940395355	CHEMBL1835299,TP,ACT,0.1899999976158142	CHEMBL1945133,TN,INACT,0.05000000074505806	CHEMBL3220454,FN,ACT,0.05000000074505806	CHEMBL3806268,TP,ACT,1.0	CHEMBL298346,FP,INACT,0.17000000178813934	CHEMBL3805427,TP,ACT,0.9700000286102295	CHEMBL3806002,TP,ACT,0.5799999833106995	CHEMBL3310818,TN,INACT,0.029999999329447746	CHEMBL1962669,TN,INACT,0.03999999910593033	CHEMBL3754317,FN,ACT,0.029999999329447746	CHEMBL3311076,TN,INACT,0.10000000149011612	CHEMBL570186,TN,INACT,0.07000000029802322	CHEMBL492925,FN,ACT,0.05999999865889549	CHEMBL3752305,TN,INACT,0.03999999910593033	CHEMBL1797739,TN,INACT,0.03999999910593033	CHEMBL3311068,TN,INACT,0.029999999329447746	CHEMBL1254035,FN,ACT,0.10000000149011612	CHEMBL2152605,TN,INACT,0.029999999329447746	CHEMBL407321,TP,ACT,0.20999999344348907	CHEMBL3354205,FN,ACT,0.05999999865889549	CHEMBL3805426,TP,ACT,0.9800000190734863	CHEMBL3770731,FP,INACT,0.9700000286102295	CHEMBL449883,TN,INACT,0.14000000059604645	CHEMBL265502,TP,ACT,0.3199999928474426	CHEMBL3805112,TP,ACT,0.699999988079071	CHEMBL493160,TN,INACT,0.03999999910593033	CHEMBL2332039,FN,ACT,0.07000000029802322	CHEMBL2314701,TN,INACT,0.05999999865889549	CHEMBL1254304,TN,INACT,0.07999999821186066	CHEMBL226115,TN,INACT,0.09000000357627869	CHEMBL3109656,TN,INACT,0.12999999523162842	CHEMBL3350586,TN,INACT,0.029999999329447746	CHEMBL3236133,FN,ACT,0.019999999552965164	CHEMBL3580805,TP,ACT,0.9700000286102295	CHEMBL2164018,TP,ACT,0.75	CHEMBL200850,FN,ACT,0.11999999731779099	CHEMBL452893,FP,INACT,0.3100000023841858	CHEMBL474872,TN,INACT,0.09000000357627869	CHEMBL1797726,TP,ACT,0.2199999988079071	CHEMBL2338811,TP,ACT,0.8899999856948853	CHEMBL263467,TN,INACT,0.07000000029802322	CHEMBL425294,TN,INACT,0.07000000029802322	

