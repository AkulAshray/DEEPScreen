CNNModel CHEMBL6115 adam 0.0005 15 256 0 0.6 False True
Number of active compounds :	295
Number of inactive compounds :	197
---------------------------------
Run id: CNNModel_CHEMBL6115_adam_0.0005_15_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL6115_adam_0.0005_15_256_0.6_True/
---------------------------------
Training samples: 304
Validation samples: 96
--
Training Step: 1  | time: 0.759s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/304
[A[ATraining Step: 2  | total loss: [1m[32m0.62399[0m[0m | time: 1.366s
[2K
| Adam | epoch: 001 | loss: 0.62399 - acc: 0.3375 -- iter: 064/304
[A[ATraining Step: 3  | total loss: [1m[32m0.68077[0m[0m | time: 1.974s
[2K
| Adam | epoch: 001 | loss: 0.68077 - acc: 0.4449 -- iter: 096/304
[A[ATraining Step: 4  | total loss: [1m[32m0.69009[0m[0m | time: 2.585s
[2K
| Adam | epoch: 001 | loss: 0.69009 - acc: 0.4393 -- iter: 128/304
[A[ATraining Step: 5  | total loss: [1m[32m0.69063[0m[0m | time: 3.193s
[2K
| Adam | epoch: 001 | loss: 0.69063 - acc: 0.6111 -- iter: 160/304
[A[ATraining Step: 6  | total loss: [1m[32m0.68477[0m[0m | time: 3.802s
[2K
| Adam | epoch: 001 | loss: 0.68477 - acc: 0.7406 -- iter: 192/304
[A[ATraining Step: 7  | total loss: [1m[32m0.69006[0m[0m | time: 4.420s
[2K
| Adam | epoch: 001 | loss: 0.69006 - acc: 0.5962 -- iter: 224/304
[A[ATraining Step: 8  | total loss: [1m[32m0.68787[0m[0m | time: 5.035s
[2K
| Adam | epoch: 001 | loss: 0.68787 - acc: 0.5773 -- iter: 256/304
[A[ATraining Step: 9  | total loss: [1m[32m0.68566[0m[0m | time: 5.655s
[2K
| Adam | epoch: 001 | loss: 0.68566 - acc: 0.5694 -- iter: 288/304
[A[ATraining Step: 10  | total loss: [1m[32m0.66913[0m[0m | time: 7.028s
[2K
| Adam | epoch: 001 | loss: 0.66913 - acc: 0.6128 | val_loss: 0.71646 - val_acc: 0.5521 -- iter: 304/304
--
Training Step: 11  | total loss: [1m[32m0.66240[0m[0m | time: 0.323s
[2K
| Adam | epoch: 002 | loss: 0.66240 - acc: 0.6186 -- iter: 032/304
[A[ATraining Step: 12  | total loss: [1m[32m0.68257[0m[0m | time: 0.930s
[2K
| Adam | epoch: 002 | loss: 0.68257 - acc: 0.5934 -- iter: 064/304
[A[ATraining Step: 13  | total loss: [1m[32m0.70234[0m[0m | time: 1.546s
[2K
| Adam | epoch: 002 | loss: 0.70234 - acc: 0.5667 -- iter: 096/304
[A[ATraining Step: 14  | total loss: [1m[32m0.69118[0m[0m | time: 2.149s
[2K
| Adam | epoch: 002 | loss: 0.69118 - acc: 0.5778 -- iter: 128/304
[A[ATraining Step: 15  | total loss: [1m[32m0.68420[0m[0m | time: 2.752s
[2K
| Adam | epoch: 002 | loss: 0.68420 - acc: 0.5840 -- iter: 160/304
[A[ATraining Step: 16  | total loss: [1m[32m0.67265[0m[0m | time: 3.355s
[2K
| Adam | epoch: 002 | loss: 0.67265 - acc: 0.6111 -- iter: 192/304
[A[ATraining Step: 17  | total loss: [1m[32m0.66333[0m[0m | time: 3.963s
[2K
| Adam | epoch: 002 | loss: 0.66333 - acc: 0.6386 -- iter: 224/304
[A[ATraining Step: 18  | total loss: [1m[32m0.67494[0m[0m | time: 4.580s
[2K
| Adam | epoch: 002 | loss: 0.67494 - acc: 0.5906 -- iter: 256/304
[A[ATraining Step: 19  | total loss: [1m[32m0.67253[0m[0m | time: 5.187s
[2K
| Adam | epoch: 002 | loss: 0.67253 - acc: 0.6021 -- iter: 288/304
[A[ATraining Step: 20  | total loss: [1m[32m0.67532[0m[0m | time: 6.801s
[2K
| Adam | epoch: 002 | loss: 0.67532 - acc: 0.5894 | val_loss: 0.68240 - val_acc: 0.5521 -- iter: 304/304
--
Training Step: 21  | total loss: [1m[32m0.67764[0m[0m | time: 0.325s
[2K
| Adam | epoch: 003 | loss: 0.67764 - acc: 0.5810 -- iter: 032/304
[A[ATraining Step: 22  | total loss: [1m[32m0.67927[0m[0m | time: 0.641s
[2K
| Adam | epoch: 003 | loss: 0.67927 - acc: 0.5755 -- iter: 064/304
[A[ATraining Step: 23  | total loss: [1m[32m0.67567[0m[0m | time: 1.247s
[2K
| Adam | epoch: 003 | loss: 0.67567 - acc: 0.5898 -- iter: 096/304
[A[ATraining Step: 24  | total loss: [1m[32m0.68403[0m[0m | time: 1.863s
[2K
| Adam | epoch: 003 | loss: 0.68403 - acc: 0.5558 -- iter: 128/304
[A[ATraining Step: 25  | total loss: [1m[32m0.66816[0m[0m | time: 2.469s
[2K
| Adam | epoch: 003 | loss: 0.66816 - acc: 0.6088 -- iter: 160/304
[A[ATraining Step: 26  | total loss: [1m[32m0.67318[0m[0m | time: 3.079s
[2K
| Adam | epoch: 003 | loss: 0.67318 - acc: 0.5882 -- iter: 192/304
[A[ATraining Step: 27  | total loss: [1m[32m0.67495[0m[0m | time: 3.698s
[2K
| Adam | epoch: 003 | loss: 0.67495 - acc: 0.5816 -- iter: 224/304
[A[ATraining Step: 28  | total loss: [1m[32m0.67206[0m[0m | time: 4.329s
[2K
| Adam | epoch: 003 | loss: 0.67206 - acc: 0.5847 -- iter: 256/304
[A[ATraining Step: 29  | total loss: [1m[32m0.67127[0m[0m | time: 4.932s
[2K
| Adam | epoch: 003 | loss: 0.67127 - acc: 0.5869 -- iter: 288/304
[A[ATraining Step: 30  | total loss: [1m[32m0.66671[0m[0m | time: 6.571s
[2K
| Adam | epoch: 003 | loss: 0.66671 - acc: 0.5959 | val_loss: 0.68017 - val_acc: 0.5521 -- iter: 304/304
--
Training Step: 31  | total loss: [1m[32m0.67695[0m[0m | time: 0.616s
[2K
| Adam | epoch: 004 | loss: 0.67695 - acc: 0.5738 -- iter: 032/304
[A[ATraining Step: 32  | total loss: [1m[32m0.66735[0m[0m | time: 0.940s
[2K
| Adam | epoch: 004 | loss: 0.66735 - acc: 0.5923 -- iter: 064/304
[A[ATraining Step: 33  | total loss: [1m[32m0.66248[0m[0m | time: 1.262s
[2K
| Adam | epoch: 004 | loss: 0.66248 - acc: 0.5995 -- iter: 096/304
[A[ATraining Step: 34  | total loss: [1m[32m0.65789[0m[0m | time: 1.887s
[2K
| Adam | epoch: 004 | loss: 0.65789 - acc: 0.6050 -- iter: 128/304
[A[ATraining Step: 35  | total loss: [1m[32m0.65949[0m[0m | time: 2.498s
[2K
| Adam | epoch: 004 | loss: 0.65949 - acc: 0.6026 -- iter: 160/304
[A[ATraining Step: 36  | total loss: [1m[32m0.64409[0m[0m | time: 3.097s
[2K
| Adam | epoch: 004 | loss: 0.64409 - acc: 0.6264 -- iter: 192/304
[A[ATraining Step: 37  | total loss: [1m[32m0.66297[0m[0m | time: 3.702s
[2K
| Adam | epoch: 004 | loss: 0.66297 - acc: 0.5948 -- iter: 224/304
[A[ATraining Step: 38  | total loss: [1m[32m0.67630[0m[0m | time: 4.306s
[2K
| Adam | epoch: 004 | loss: 0.67630 - acc: 0.5702 -- iter: 256/304
[A[ATraining Step: 39  | total loss: [1m[32m0.67383[0m[0m | time: 4.914s
[2K
| Adam | epoch: 004 | loss: 0.67383 - acc: 0.5687 -- iter: 288/304
[A[ATraining Step: 40  | total loss: [1m[32m0.66491[0m[0m | time: 6.509s
[2K
| Adam | epoch: 004 | loss: 0.66491 - acc: 0.5851 | val_loss: 0.66148 - val_acc: 0.5521 -- iter: 304/304
--
Training Step: 41  | total loss: [1m[32m0.65801[0m[0m | time: 0.604s
[2K
| Adam | epoch: 005 | loss: 0.65801 - acc: 0.5982 -- iter: 032/304
[A[ATraining Step: 42  | total loss: [1m[32m0.65478[0m[0m | time: 1.196s
[2K
| Adam | epoch: 005 | loss: 0.65478 - acc: 0.6030 -- iter: 064/304
[A[ATraining Step: 43  | total loss: [1m[32m0.65732[0m[0m | time: 1.518s
[2K
| Adam | epoch: 005 | loss: 0.65732 - acc: 0.5903 -- iter: 096/304
[A[ATraining Step: 44  | total loss: [1m[32m0.65286[0m[0m | time: 1.839s
[2K
| Adam | epoch: 005 | loss: 0.65286 - acc: 0.5963 -- iter: 128/304
[A[ATraining Step: 45  | total loss: [1m[32m0.64812[0m[0m | time: 2.433s
[2K
| Adam | epoch: 005 | loss: 0.64812 - acc: 0.6012 -- iter: 160/304
[A[ATraining Step: 46  | total loss: [1m[32m0.64590[0m[0m | time: 3.032s
[2K
| Adam | epoch: 005 | loss: 0.64590 - acc: 0.6000 -- iter: 192/304
[A[ATraining Step: 47  | total loss: [1m[32m0.64081[0m[0m | time: 3.632s
[2K
| Adam | epoch: 005 | loss: 0.64081 - acc: 0.6041 -- iter: 224/304
[A[ATraining Step: 48  | total loss: [1m[32m0.63058[0m[0m | time: 4.233s
[2K
| Adam | epoch: 005 | loss: 0.63058 - acc: 0.6125 -- iter: 256/304
[A[ATraining Step: 49  | total loss: [1m[32m0.63379[0m[0m | time: 4.863s
[2K
| Adam | epoch: 005 | loss: 0.63379 - acc: 0.6046 -- iter: 288/304
[A[ATraining Step: 50  | total loss: [1m[32m0.62813[0m[0m | time: 6.468s
[2K
| Adam | epoch: 005 | loss: 0.62813 - acc: 0.6077 | val_loss: 0.61585 - val_acc: 0.5521 -- iter: 304/304
--
Training Step: 51  | total loss: [1m[32m0.64028[0m[0m | time: 0.613s
[2K
| Adam | epoch: 006 | loss: 0.64028 - acc: 0.5865 -- iter: 032/304
[A[ATraining Step: 52  | total loss: [1m[32m0.63576[0m[0m | time: 1.218s
[2K
| Adam | epoch: 006 | loss: 0.63576 - acc: 0.5829 -- iter: 064/304
[A[ATraining Step: 53  | total loss: [1m[32m0.62219[0m[0m | time: 1.820s
[2K
| Adam | epoch: 006 | loss: 0.62219 - acc: 0.5984 -- iter: 096/304
[A[ATraining Step: 54  | total loss: [1m[32m0.62009[0m[0m | time: 2.136s
[2K
| Adam | epoch: 006 | loss: 0.62009 - acc: 0.5932 -- iter: 128/304
[A[ATraining Step: 55  | total loss: [1m[32m0.62094[0m[0m | time: 2.467s
[2K
| Adam | epoch: 006 | loss: 0.62094 - acc: 0.5798 -- iter: 160/304
[A[ATraining Step: 56  | total loss: [1m[32m0.61726[0m[0m | time: 3.070s
[2K
| Adam | epoch: 006 | loss: 0.61726 - acc: 0.5686 -- iter: 192/304
[A[ATraining Step: 57  | total loss: [1m[32m0.60984[0m[0m | time: 3.678s
[2K
| Adam | epoch: 006 | loss: 0.60984 - acc: 0.5721 -- iter: 224/304
[A[ATraining Step: 58  | total loss: [1m[32m0.59219[0m[0m | time: 4.298s
[2K
| Adam | epoch: 006 | loss: 0.59219 - acc: 0.6006 -- iter: 256/304
[A[ATraining Step: 59  | total loss: [1m[32m0.58756[0m[0m | time: 4.909s
[2K
| Adam | epoch: 006 | loss: 0.58756 - acc: 0.5955 -- iter: 288/304
[A[ATraining Step: 60  | total loss: [1m[32m0.58413[0m[0m | time: 6.535s
[2K
| Adam | epoch: 006 | loss: 0.58413 - acc: 0.5870 | val_loss: 0.47641 - val_acc: 0.7292 -- iter: 304/304
--
Training Step: 61  | total loss: [1m[32m0.56342[0m[0m | time: 0.606s
[2K
| Adam | epoch: 007 | loss: 0.56342 - acc: 0.6001 -- iter: 032/304
[A[ATraining Step: 62  | total loss: [1m[32m0.54813[0m[0m | time: 1.206s
[2K
| Adam | epoch: 007 | loss: 0.54813 - acc: 0.6194 -- iter: 064/304
[A[ATraining Step: 63  | total loss: [1m[32m0.53613[0m[0m | time: 1.808s
[2K
| Adam | epoch: 007 | loss: 0.53613 - acc: 0.6557 -- iter: 096/304
[A[ATraining Step: 64  | total loss: [1m[32m0.52300[0m[0m | time: 2.380s
[2K
| Adam | epoch: 007 | loss: 0.52300 - acc: 0.6871 -- iter: 128/304
[A[ATraining Step: 65  | total loss: [1m[32m0.51963[0m[0m | time: 2.693s
[2K
| Adam | epoch: 007 | loss: 0.51963 - acc: 0.7064 -- iter: 160/304
[A[ATraining Step: 66  | total loss: [1m[32m0.50418[0m[0m | time: 3.011s
[2K
| Adam | epoch: 007 | loss: 0.50418 - acc: 0.7269 -- iter: 192/304
[A[ATraining Step: 67  | total loss: [1m[32m0.50024[0m[0m | time: 3.640s
[2K
| Adam | epoch: 007 | loss: 0.50024 - acc: 0.7222 -- iter: 224/304
[A[ATraining Step: 68  | total loss: [1m[32m0.46735[0m[0m | time: 4.249s
[2K
| Adam | epoch: 007 | loss: 0.46735 - acc: 0.7514 -- iter: 256/304
[A[ATraining Step: 69  | total loss: [1m[32m0.45384[0m[0m | time: 4.844s
[2K
| Adam | epoch: 007 | loss: 0.45384 - acc: 0.7658 -- iter: 288/304
[A[ATraining Step: 70  | total loss: [1m[32m0.44677[0m[0m | time: 6.469s
[2K
| Adam | epoch: 007 | loss: 0.44677 - acc: 0.7676 | val_loss: 0.29031 - val_acc: 0.8750 -- iter: 304/304
--
Training Step: 71  | total loss: [1m[32m0.41464[0m[0m | time: 0.598s
[2K
| Adam | epoch: 008 | loss: 0.41464 - acc: 0.7834 -- iter: 032/304
[A[ATraining Step: 72  | total loss: [1m[32m0.39613[0m[0m | time: 1.204s
[2K
| Adam | epoch: 008 | loss: 0.39613 - acc: 0.7972 -- iter: 064/304
[A[ATraining Step: 73  | total loss: [1m[32m0.37725[0m[0m | time: 1.817s
[2K
| Adam | epoch: 008 | loss: 0.37725 - acc: 0.8093 -- iter: 096/304
[A[ATraining Step: 74  | total loss: [1m[32m0.39108[0m[0m | time: 2.411s
[2K
| Adam | epoch: 008 | loss: 0.39108 - acc: 0.8097 -- iter: 128/304
[A[ATraining Step: 75  | total loss: [1m[32m0.39095[0m[0m | time: 3.010s
[2K
| Adam | epoch: 008 | loss: 0.39095 - acc: 0.8100 -- iter: 160/304
[A[ATraining Step: 76  | total loss: [1m[32m0.37588[0m[0m | time: 3.335s
[2K
| Adam | epoch: 008 | loss: 0.37588 - acc: 0.8203 -- iter: 192/304
[A[ATraining Step: 77  | total loss: [1m[32m0.36009[0m[0m | time: 3.648s
[2K
| Adam | epoch: 008 | loss: 0.36009 - acc: 0.8327 -- iter: 224/304
[A[ATraining Step: 78  | total loss: [1m[32m0.38439[0m[0m | time: 4.252s
[2K
| Adam | epoch: 008 | loss: 0.38439 - acc: 0.8306 -- iter: 256/304
[A[ATraining Step: 79  | total loss: [1m[32m0.37271[0m[0m | time: 4.858s
[2K
| Adam | epoch: 008 | loss: 0.37271 - acc: 0.8352 -- iter: 288/304
[A[ATraining Step: 80  | total loss: [1m[32m0.35168[0m[0m | time: 6.476s
[2K
| Adam | epoch: 008 | loss: 0.35168 - acc: 0.8456 | val_loss: 0.25071 - val_acc: 0.9062 -- iter: 304/304
--
Training Step: 81  | total loss: [1m[32m0.33322[0m[0m | time: 0.602s
[2K
| Adam | epoch: 009 | loss: 0.33322 - acc: 0.8549 -- iter: 032/304
[A[ATraining Step: 82  | total loss: [1m[32m0.31793[0m[0m | time: 1.203s
[2K
| Adam | epoch: 009 | loss: 0.31793 - acc: 0.8632 -- iter: 064/304
[A[ATraining Step: 83  | total loss: [1m[32m0.31605[0m[0m | time: 1.803s
[2K
| Adam | epoch: 009 | loss: 0.31605 - acc: 0.8612 -- iter: 096/304
[A[ATraining Step: 84  | total loss: [1m[32m0.30666[0m[0m | time: 2.403s
[2K
| Adam | epoch: 009 | loss: 0.30666 - acc: 0.8626 -- iter: 128/304
[A[ATraining Step: 85  | total loss: [1m[32m0.28710[0m[0m | time: 3.028s
[2K
| Adam | epoch: 009 | loss: 0.28710 - acc: 0.8732 -- iter: 160/304
[A[ATraining Step: 86  | total loss: [1m[32m0.27659[0m[0m | time: 3.627s
[2K
| Adam | epoch: 009 | loss: 0.27659 - acc: 0.8797 -- iter: 192/304
[A[ATraining Step: 87  | total loss: [1m[32m0.27981[0m[0m | time: 3.962s
[2K
| Adam | epoch: 009 | loss: 0.27981 - acc: 0.8761 -- iter: 224/304
[A[ATraining Step: 88  | total loss: [1m[32m0.25571[0m[0m | time: 4.280s
[2K
| Adam | epoch: 009 | loss: 0.25571 - acc: 0.8885 -- iter: 256/304
[A[ATraining Step: 89  | total loss: [1m[32m0.25704[0m[0m | time: 4.877s
[2K
| Adam | epoch: 009 | loss: 0.25704 - acc: 0.8934 -- iter: 288/304
[A[ATraining Step: 90  | total loss: [1m[32m0.25725[0m[0m | time: 6.483s
[2K
| Adam | epoch: 009 | loss: 0.25725 - acc: 0.8884 | val_loss: 0.24521 - val_acc: 0.9271 -- iter: 304/304
--
Training Step: 91  | total loss: [1m[32m0.24398[0m[0m | time: 0.640s
[2K
| Adam | epoch: 010 | loss: 0.24398 - acc: 0.8933 -- iter: 032/304
[A[ATraining Step: 92  | total loss: [1m[32m0.22771[0m[0m | time: 1.247s
[2K
| Adam | epoch: 010 | loss: 0.22771 - acc: 0.9009 -- iter: 064/304
[A[ATraining Step: 93  | total loss: [1m[32m0.22343[0m[0m | time: 1.879s
[2K
| Adam | epoch: 010 | loss: 0.22343 - acc: 0.9076 -- iter: 096/304
[A[ATraining Step: 94  | total loss: [1m[32m0.21046[0m[0m | time: 2.480s
[2K
| Adam | epoch: 010 | loss: 0.21046 - acc: 0.9169 -- iter: 128/304
[A[ATraining Step: 95  | total loss: [1m[32m0.20514[0m[0m | time: 3.092s
[2K
| Adam | epoch: 010 | loss: 0.20514 - acc: 0.9158 -- iter: 160/304
[A[ATraining Step: 96  | total loss: [1m[32m0.20017[0m[0m | time: 3.700s
[2K
| Adam | epoch: 010 | loss: 0.20017 - acc: 0.9180 -- iter: 192/304
[A[ATraining Step: 97  | total loss: [1m[32m0.20545[0m[0m | time: 4.303s
[2K
| Adam | epoch: 010 | loss: 0.20545 - acc: 0.9199 -- iter: 224/304
[A[ATraining Step: 98  | total loss: [1m[32m0.20018[0m[0m | time: 4.628s
[2K
| Adam | epoch: 010 | loss: 0.20018 - acc: 0.9217 -- iter: 256/304
[A[ATraining Step: 99  | total loss: [1m[32m0.18553[0m[0m | time: 4.944s
[2K
| Adam | epoch: 010 | loss: 0.18553 - acc: 0.9295 -- iter: 288/304
[A[ATraining Step: 100  | total loss: [1m[32m0.17818[0m[0m | time: 6.546s
[2K
| Adam | epoch: 010 | loss: 0.17818 - acc: 0.9303 | val_loss: 0.24641 - val_acc: 0.9062 -- iter: 304/304
--
Training Step: 101  | total loss: [1m[32m0.17414[0m[0m | time: 0.603s
[2K
| Adam | epoch: 011 | loss: 0.17414 - acc: 0.9310 -- iter: 032/304
[A[ATraining Step: 102  | total loss: [1m[32m0.16363[0m[0m | time: 1.205s
[2K
| Adam | epoch: 011 | loss: 0.16363 - acc: 0.9379 -- iter: 064/304
[A[ATraining Step: 103  | total loss: [1m[32m0.15476[0m[0m | time: 1.803s
[2K
| Adam | epoch: 011 | loss: 0.15476 - acc: 0.9410 -- iter: 096/304
[A[ATraining Step: 104  | total loss: [1m[32m0.14609[0m[0m | time: 2.398s
[2K
| Adam | epoch: 011 | loss: 0.14609 - acc: 0.9469 -- iter: 128/304
[A[ATraining Step: 105  | total loss: [1m[32m0.14076[0m[0m | time: 3.024s
[2K
| Adam | epoch: 011 | loss: 0.14076 - acc: 0.9491 -- iter: 160/304
[A[ATraining Step: 106  | total loss: [1m[32m0.15730[0m[0m | time: 3.629s
[2K
| Adam | epoch: 011 | loss: 0.15730 - acc: 0.9448 -- iter: 192/304
[A[ATraining Step: 107  | total loss: [1m[32m0.14887[0m[0m | time: 4.251s
[2K
| Adam | epoch: 011 | loss: 0.14887 - acc: 0.9472 -- iter: 224/304
[A[ATraining Step: 108  | total loss: [1m[32m0.15108[0m[0m | time: 4.878s
[2K
| Adam | epoch: 011 | loss: 0.15108 - acc: 0.9400 -- iter: 256/304
[A[ATraining Step: 109  | total loss: [1m[32m0.15623[0m[0m | time: 5.195s
[2K
| Adam | epoch: 011 | loss: 0.15623 - acc: 0.9397 -- iter: 288/304
[A[ATraining Step: 110  | total loss: [1m[32m0.14430[0m[0m | time: 6.519s
[2K
| Adam | epoch: 011 | loss: 0.14430 - acc: 0.9458 | val_loss: 0.26915 - val_acc: 0.8958 -- iter: 304/304
--
Training Step: 111  | total loss: [1m[32m0.19029[0m[0m | time: 0.619s
[2K
| Adam | epoch: 012 | loss: 0.19029 - acc: 0.9387 -- iter: 032/304
[A[ATraining Step: 112  | total loss: [1m[32m0.19792[0m[0m | time: 1.221s
[2K
| Adam | epoch: 012 | loss: 0.19792 - acc: 0.9354 -- iter: 064/304
[A[ATraining Step: 113  | total loss: [1m[32m0.18421[0m[0m | time: 1.867s
[2K
| Adam | epoch: 012 | loss: 0.18421 - acc: 0.9388 -- iter: 096/304
[A[ATraining Step: 114  | total loss: [1m[32m0.17987[0m[0m | time: 2.515s
[2K
| Adam | epoch: 012 | loss: 0.17987 - acc: 0.9386 -- iter: 128/304
[A[ATraining Step: 115  | total loss: [1m[32m0.16690[0m[0m | time: 3.114s
[2K
| Adam | epoch: 012 | loss: 0.16690 - acc: 0.9448 -- iter: 160/304
[A[ATraining Step: 116  | total loss: [1m[32m0.15897[0m[0m | time: 3.717s
[2K
| Adam | epoch: 012 | loss: 0.15897 - acc: 0.9441 -- iter: 192/304
[A[ATraining Step: 117  | total loss: [1m[32m0.15354[0m[0m | time: 4.317s
[2K
| Adam | epoch: 012 | loss: 0.15354 - acc: 0.9434 -- iter: 224/304
[A[ATraining Step: 118  | total loss: [1m[32m0.15038[0m[0m | time: 4.937s
[2K
| Adam | epoch: 012 | loss: 0.15038 - acc: 0.9459 -- iter: 256/304
[A[ATraining Step: 119  | total loss: [1m[32m0.14016[0m[0m | time: 5.539s
[2K
| Adam | epoch: 012 | loss: 0.14016 - acc: 0.9513 -- iter: 288/304
[A[ATraining Step: 120  | total loss: [1m[32m0.13234[0m[0m | time: 6.860s
[2K
| Adam | epoch: 012 | loss: 0.13234 - acc: 0.9562 | val_loss: 0.28946 - val_acc: 0.8958 -- iter: 304/304
--
Training Step: 121  | total loss: [1m[32m0.12162[0m[0m | time: 0.338s
[2K
| Adam | epoch: 013 | loss: 0.12162 - acc: 0.9606 -- iter: 032/304
[A[ATraining Step: 122  | total loss: [1m[32m0.12287[0m[0m | time: 0.945s
[2K
| Adam | epoch: 013 | loss: 0.12287 - acc: 0.9583 -- iter: 064/304
[A[ATraining Step: 123  | total loss: [1m[32m0.11588[0m[0m | time: 1.541s
[2K
| Adam | epoch: 013 | loss: 0.11588 - acc: 0.9624 -- iter: 096/304
[A[ATraining Step: 124  | total loss: [1m[32m0.11008[0m[0m | time: 2.151s
[2K
| Adam | epoch: 013 | loss: 0.11008 - acc: 0.9662 -- iter: 128/304
[A[ATraining Step: 125  | total loss: [1m[32m0.11512[0m[0m | time: 2.757s
[2K
| Adam | epoch: 013 | loss: 0.11512 - acc: 0.9633 -- iter: 160/304
[A[ATraining Step: 126  | total loss: [1m[32m0.10688[0m[0m | time: 3.362s
[2K
| Adam | epoch: 013 | loss: 0.10688 - acc: 0.9670 -- iter: 192/304
[A[ATraining Step: 127  | total loss: [1m[32m0.10721[0m[0m | time: 3.978s
[2K
| Adam | epoch: 013 | loss: 0.10721 - acc: 0.9672 -- iter: 224/304
[A[ATraining Step: 128  | total loss: [1m[32m0.11398[0m[0m | time: 4.588s
[2K
| Adam | epoch: 013 | loss: 0.11398 - acc: 0.9673 -- iter: 256/304
[A[ATraining Step: 129  | total loss: [1m[32m0.10422[0m[0m | time: 5.196s
[2K
| Adam | epoch: 013 | loss: 0.10422 - acc: 0.9706 -- iter: 288/304
[A[ATraining Step: 130  | total loss: [1m[32m0.09720[0m[0m | time: 6.806s
[2K
| Adam | epoch: 013 | loss: 0.09720 - acc: 0.9735 | val_loss: 0.26717 - val_acc: 0.9062 -- iter: 304/304
--
Training Step: 131  | total loss: [1m[32m0.09074[0m[0m | time: 0.317s
[2K
| Adam | epoch: 014 | loss: 0.09074 - acc: 0.9762 -- iter: 032/304
[A[ATraining Step: 132  | total loss: [1m[32m0.08656[0m[0m | time: 0.647s
[2K
| Adam | epoch: 014 | loss: 0.08656 - acc: 0.9786 -- iter: 064/304
[A[ATraining Step: 133  | total loss: [1m[32m0.10352[0m[0m | time: 1.249s
[2K
| Adam | epoch: 014 | loss: 0.10352 - acc: 0.9745 -- iter: 096/304
[A[ATraining Step: 134  | total loss: [1m[32m0.09950[0m[0m | time: 1.851s
[2K
| Adam | epoch: 014 | loss: 0.09950 - acc: 0.9739 -- iter: 128/304
[A[ATraining Step: 135  | total loss: [1m[32m0.09289[0m[0m | time: 2.456s
[2K
| Adam | epoch: 014 | loss: 0.09289 - acc: 0.9734 -- iter: 160/304
[A[ATraining Step: 136  | total loss: [1m[32m0.09086[0m[0m | time: 3.057s
[2K
| Adam | epoch: 014 | loss: 0.09086 - acc: 0.9698 -- iter: 192/304
[A[ATraining Step: 137  | total loss: [1m[32m0.09741[0m[0m | time: 3.656s
[2K
| Adam | epoch: 014 | loss: 0.09741 - acc: 0.9697 -- iter: 224/304
[A[ATraining Step: 138  | total loss: [1m[32m0.09125[0m[0m | time: 4.250s
[2K
| Adam | epoch: 014 | loss: 0.09125 - acc: 0.9727 -- iter: 256/304
[A[ATraining Step: 139  | total loss: [1m[32m0.08302[0m[0m | time: 4.860s
[2K
| Adam | epoch: 014 | loss: 0.08302 - acc: 0.9754 -- iter: 288/304
[A[ATraining Step: 140  | total loss: [1m[32m0.07847[0m[0m | time: 6.494s
[2K
| Adam | epoch: 014 | loss: 0.07847 - acc: 0.9779 | val_loss: 0.26063 - val_acc: 0.9167 -- iter: 304/304
--
Training Step: 141  | total loss: [1m[32m0.07516[0m[0m | time: 0.603s
[2K
| Adam | epoch: 015 | loss: 0.07516 - acc: 0.9801 -- iter: 032/304
[A[ATraining Step: 142  | total loss: [1m[32m0.06955[0m[0m | time: 0.927s
[2K
| Adam | epoch: 015 | loss: 0.06955 - acc: 0.9821 -- iter: 064/304
[A[ATraining Step: 143  | total loss: [1m[32m0.06341[0m[0m | time: 1.244s
[2K
| Adam | epoch: 015 | loss: 0.06341 - acc: 0.9839 -- iter: 096/304
[A[ATraining Step: 144  | total loss: [1m[32m0.06034[0m[0m | time: 1.844s
[2K
| Adam | epoch: 015 | loss: 0.06034 - acc: 0.9855 -- iter: 128/304
[A[ATraining Step: 145  | total loss: [1m[32m0.05838[0m[0m | time: 2.460s
[2K
| Adam | epoch: 015 | loss: 0.05838 - acc: 0.9870 -- iter: 160/304
[A[ATraining Step: 146  | total loss: [1m[32m0.05921[0m[0m | time: 3.058s
[2K
| Adam | epoch: 015 | loss: 0.05921 - acc: 0.9851 -- iter: 192/304
[A[ATraining Step: 147  | total loss: [1m[32m0.05660[0m[0m | time: 3.679s
[2K
| Adam | epoch: 015 | loss: 0.05660 - acc: 0.9866 -- iter: 224/304
[A[ATraining Step: 148  | total loss: [1m[32m0.07432[0m[0m | time: 4.291s
[2K
| Adam | epoch: 015 | loss: 0.07432 - acc: 0.9755 -- iter: 256/304
[A[ATraining Step: 149  | total loss: [1m[32m0.07434[0m[0m | time: 4.915s
[2K
| Adam | epoch: 015 | loss: 0.07434 - acc: 0.9748 -- iter: 288/304
[A[ATraining Step: 150  | total loss: [1m[32m0.06927[0m[0m | time: 6.521s
[2K
| Adam | epoch: 015 | loss: 0.06927 - acc: 0.9773 | val_loss: 0.29462 - val_acc: 0.9167 -- iter: 304/304
--
Validation AUC:0.9569986836331724
Validation AUPRC:0.9745781317659125
Test AUC:0.9715987173614292
Test AUPRC:0.9871646195018183
BestTestF1Score	0.95	0.87	0.94	0.98	0.92	54	1	36	5	0.14
BestTestMCCScore	0.96	0.9	0.95	1.0	0.92	54	0	37	5	0.56
BestTestAccuracyScore	0.96	0.9	0.95	1.0	0.92	54	0	37	5	0.56
BestValidationF1Score	0.92	0.83	0.92	0.92	0.92	49	4	39	4	0.14
BestValidationMCC	0.92	0.84	0.92	0.98	0.87	46	1	42	7	0.56
BestValidationAccuracy	0.92	0.84	0.92	0.98	0.87	46	1	42	7	0.56
TestPredictions (Threshold:0.56)
CHEMBL165808,TN,INACT,0.009999999776482582	CHEMBL3687791,TP,ACT,1.0	CHEMBL349073,TN,INACT,0.009999999776482582	CHEMBL552981,TN,INACT,0.009999999776482582	CHEMBL3687813,TP,ACT,1.0	CHEMBL3682906,TP,ACT,1.0	CHEMBL3682846,TP,ACT,0.9900000095367432	CHEMBL3682955,TP,ACT,1.0	CHEMBL3678019,TP,ACT,0.6899999976158142	CHEMBL3678004,TP,ACT,0.9200000166893005	CHEMBL3401004,TN,INACT,0.009999999776482582	CHEMBL3145336,TP,ACT,0.8700000047683716	CHEMBL282920,TN,INACT,0.0	CHEMBL168155,TN,INACT,0.0	CHEMBL3683024,TP,ACT,1.0	CHEMBL3678058,TP,ACT,0.9800000190734863	CHEMBL2338672,TN,INACT,0.029999999329447746	CHEMBL3682997,TP,ACT,1.0	CHEMBL536932,TN,INACT,0.0	CHEMBL3683029,TP,ACT,1.0	CHEMBL2171390,TP,ACT,0.9900000095367432	CHEMBL3401021,TN,INACT,0.009999999776482582	CHEMBL3677990,TP,ACT,1.0	CHEMBL284984,TN,INACT,0.0	CHEMBL3127010,TN,INACT,0.009999999776482582	CHEMBL3678051,TP,ACT,1.0	CHEMBL2177699,TN,INACT,0.0	CHEMBL3263350,TN,INACT,0.009999999776482582	CHEMBL89012,TN,INACT,0.019999999552965164	CHEMBL3687921,TP,ACT,0.8600000143051147	CHEMBL3687795,TP,ACT,1.0	CHEMBL3687895,TP,ACT,0.8999999761581421	CHEMBL3687952,TP,ACT,1.0	CHEMBL3678038,TP,ACT,0.9900000095367432	CHEMBL3687868,TP,ACT,0.5600000023841858	CHEMBL3682946,TP,ACT,1.0	CHEMBL3087807,TN,INACT,0.009999999776482582	CHEMBL2171397,TP,ACT,0.8799999952316284	CHEMBL350692,TN,INACT,0.03999999910593033	CHEMBL166410,TN,INACT,0.009999999776482582	CHEMBL3682913,TP,ACT,0.9800000190734863	CHEMBL3678023,FN,ACT,0.09000000357627869	CHEMBL3678062,TP,ACT,0.9399999976158142	CHEMBL127398,TN,INACT,0.009999999776482582	CHEMBL3687825,TP,ACT,1.0	CHEMBL3687907,TP,ACT,0.8100000023841858	CHEMBL3683051,TP,ACT,1.0	CHEMBL1081455,TN,INACT,0.009999999776482582	CHEMBL3682990,TP,ACT,1.0	CHEMBL3682939,TP,ACT,1.0	CHEMBL3687834,TP,ACT,1.0	CHEMBL3687935,TP,ACT,1.0	CHEMBL18432,TN,INACT,0.0	CHEMBL3687896,TP,ACT,0.9700000286102295	CHEMBL3687838,TP,ACT,1.0	CHEMBL3682930,TP,ACT,1.0	CHEMBL3682895,TP,ACT,1.0	CHEMBL1624646,TN,INACT,0.009999999776482582	CHEMBL3087797,TN,INACT,0.009999999776482582	CHEMBL3687799,TP,ACT,1.0	CHEMBL3687911,FN,ACT,0.0	CHEMBL3683006,TP,ACT,1.0	CHEMBL3687805,TP,ACT,1.0	CHEMBL3682995,TP,ACT,1.0	CHEMBL127917,TN,INACT,0.009999999776482582	CHEMBL3682882,TP,ACT,1.0	CHEMBL2159416,TN,INACT,0.009999999776482582	CHEMBL3145353,FN,ACT,0.09000000357627869	CHEMBL3682956,TP,ACT,1.0	CHEMBL19470,TN,INACT,0.0	CHEMBL53240,TN,INACT,0.009999999776482582	CHEMBL115697,TN,INACT,0.009999999776482582	CHEMBL3682965,TP,ACT,1.0	CHEMBL96861,TN,INACT,0.009999999776482582	CHEMBL166194,TN,INACT,0.009999999776482582	CHEMBL3678061,FN,ACT,0.009999999776482582	CHEMBL3678006,TP,ACT,0.5699999928474426	CHEMBL3682989,TP,ACT,1.0	CHEMBL3687760,TP,ACT,1.0	CHEMBL2286252,TN,INACT,0.009999999776482582	CHEMBL3687882,TP,ACT,0.7400000095367432	CHEMBL409858,TN,INACT,0.17000000178813934	CHEMBL172102,TN,INACT,0.009999999776482582	CHEMBL428683,TN,INACT,0.0	CHEMBL3682951,TP,ACT,1.0	CHEMBL3682936,TP,ACT,0.9800000190734863	CHEMBL119389,TN,INACT,0.009999999776482582	CHEMBL3145341,TP,ACT,0.9900000095367432	CHEMBL3683028,TP,ACT,1.0	CHEMBL3682993,TP,ACT,1.0	CHEMBL2171400,FN,ACT,0.009999999776482582	CHEMBL88140,TN,INACT,0.009999999776482582	CHEMBL118033,TN,INACT,0.029999999329447746	CHEMBL3087813,TN,INACT,0.009999999776482582	CHEMBL3687782,TP,ACT,1.0	CHEMBL3677998,TP,ACT,0.8399999737739563	

