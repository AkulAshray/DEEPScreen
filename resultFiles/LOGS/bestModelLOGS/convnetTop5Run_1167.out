ImageNetInceptionV2 CHEMBL4027 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	192
Number of inactive compounds :	192
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4027_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4027_adam_0.0005_15_0.6/
---------------------------------
Training samples: 240
Validation samples: 75
--
Training Step: 1  | time: 410.484s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/240
[A[ATraining Step: 2  | total loss: [1m[32m0.64084[0m[0m | time: 530.203s
[2K
| Adam | epoch: 001 | loss: 0.64084 - acc: 0.4500 -- iter: 064/240
[A[ATraining Step: 3  | total loss: [1m[32m0.66797[0m[0m | time: 681.585s
[2K
| Adam | epoch: 001 | loss: 0.66797 - acc: 0.5676 -- iter: 096/240
[A[ATraining Step: 4  | total loss: [1m[32m0.46975[0m[0m | time: 875.630s
[2K
| Adam | epoch: 001 | loss: 0.46975 - acc: 0.7513 -- iter: 128/240
[A[ATraining Step: 5  | total loss: [1m[32m0.35758[0m[0m | time: 908.581s
[2K
| Adam | epoch: 001 | loss: 0.35758 - acc: 0.8369 -- iter: 160/240
[A[ATraining Step: 6  | total loss: [1m[32m0.63854[0m[0m | time: 1002.145s
[2K
| Adam | epoch: 001 | loss: 0.63854 - acc: 0.8614 -- iter: 192/240
[A[ATraining Step: 7  | total loss: [1m[32m0.54659[0m[0m | time: 1168.780s
[2K
| Adam | epoch: 001 | loss: 0.54659 - acc: 0.8508 -- iter: 224/240
[A[ATraining Step: 8  | total loss: [1m[32m0.45074[0m[0m | time: 1283.476s
[2K
| Adam | epoch: 001 | loss: 0.45074 - acc: 0.7941 | val_loss: 0.94550 - val_acc: 0.4800 -- iter: 240/240
--
Training Step: 9  | total loss: [1m[32m0.40250[0m[0m | time: 30.482s
[2K
| Adam | epoch: 002 | loss: 0.40250 - acc: 0.8038 -- iter: 032/240
[A[ATraining Step: 10  | total loss: [1m[32m0.26975[0m[0m | time: 44.291s
[2K
| Adam | epoch: 002 | loss: 0.26975 - acc: 0.9019 -- iter: 064/240
[A[ATraining Step: 11  | total loss: [1m[32m0.26630[0m[0m | time: 59.586s
[2K
| Adam | epoch: 002 | loss: 0.26630 - acc: 0.8596 -- iter: 096/240
[A[ATraining Step: 12  | total loss: [1m[32m0.26441[0m[0m | time: 176.485s
[2K
| Adam | epoch: 002 | loss: 0.26441 - acc: 0.8806 -- iter: 128/240
[A[ATraining Step: 13  | total loss: [1m[32m0.21709[0m[0m | time: 249.203s
[2K
| Adam | epoch: 002 | loss: 0.21709 - acc: 0.9184 -- iter: 160/240
[A[ATraining Step: 14  | total loss: [1m[32m0.16775[0m[0m | time: 297.703s
[2K
| Adam | epoch: 002 | loss: 0.16775 - acc: 0.9518 -- iter: 192/240
[A[ATraining Step: 15  | total loss: [1m[32m0.13290[0m[0m | time: 370.020s
[2K
| Adam | epoch: 002 | loss: 0.13290 - acc: 0.9584 -- iter: 224/240
[A[ATraining Step: 16  | total loss: [1m[32m0.12074[0m[0m | time: 397.905s
[2K
| Adam | epoch: 002 | loss: 0.12074 - acc: 0.9623 | val_loss: 1.12723 - val_acc: 0.4800 -- iter: 240/240
--
Training Step: 17  | total loss: [1m[32m0.10861[0m[0m | time: 36.762s
[2K
| Adam | epoch: 003 | loss: 0.10861 - acc: 0.9646 -- iter: 032/240
[A[ATraining Step: 18  | total loss: [1m[32m0.15295[0m[0m | time: 46.866s
[2K
| Adam | epoch: 003 | loss: 0.15295 - acc: 0.9552 -- iter: 064/240
[A[ATraining Step: 19  | total loss: [1m[32m0.11328[0m[0m | time: 84.618s
[2K
| Adam | epoch: 003 | loss: 0.11328 - acc: 0.9702 -- iter: 096/240
[A[ATraining Step: 20  | total loss: [1m[32m0.09539[0m[0m | time: 120.424s
[2K
| Adam | epoch: 003 | loss: 0.09539 - acc: 0.9797 -- iter: 128/240
[A[ATraining Step: 21  | total loss: [1m[32m0.08866[0m[0m | time: 157.590s
[2K
| Adam | epoch: 003 | loss: 0.08866 - acc: 0.9763 -- iter: 160/240
[A[ATraining Step: 22  | total loss: [1m[32m0.07519[0m[0m | time: 173.044s
[2K
| Adam | epoch: 003 | loss: 0.07519 - acc: 0.9741 -- iter: 192/240
[A[ATraining Step: 23  | total loss: [1m[32m0.05875[0m[0m | time: 184.184s
[2K
| Adam | epoch: 003 | loss: 0.05875 - acc: 0.9816 -- iter: 224/240
[A[ATraining Step: 24  | total loss: [1m[32m0.06781[0m[0m | time: 227.016s
[2K
| Adam | epoch: 003 | loss: 0.06781 - acc: 0.9780 | val_loss: 0.91891 - val_acc: 0.4800 -- iter: 240/240
--
Training Step: 25  | total loss: [1m[32m0.05108[0m[0m | time: 60.380s
[2K
| Adam | epoch: 004 | loss: 0.05108 - acc: 0.9840 -- iter: 032/240
[A[ATraining Step: 26  | total loss: [1m[32m0.05077[0m[0m | time: 70.626s
[2K
| Adam | epoch: 004 | loss: 0.05077 - acc: 0.9800 -- iter: 064/240
[A[ATraining Step: 27  | total loss: [1m[32m0.06986[0m[0m | time: 80.551s
[2K
| Adam | epoch: 004 | loss: 0.06986 - acc: 0.9690 -- iter: 096/240
[A[ATraining Step: 28  | total loss: [1m[32m0.05673[0m[0m | time: 97.807s
[2K
| Adam | epoch: 004 | loss: 0.05673 - acc: 0.9768 -- iter: 128/240
[A[ATraining Step: 29  | total loss: [1m[32m0.09076[0m[0m | time: 106.949s
[2K
| Adam | epoch: 004 | loss: 0.09076 - acc: 0.9672 -- iter: 160/240
[A[ATraining Step: 30  | total loss: [1m[32m0.10394[0m[0m | time: 117.939s
[2K
| Adam | epoch: 004 | loss: 0.10394 - acc: 0.9676 -- iter: 192/240
[A[ATraining Step: 31  | total loss: [1m[32m0.22554[0m[0m | time: 153.428s
[2K
| Adam | epoch: 004 | loss: 0.22554 - acc: 0.9606 -- iter: 224/240
[A[ATraining Step: 32  | total loss: [1m[32m0.17654[0m[0m | time: 286.476s
[2K
| Adam | epoch: 004 | loss: 0.17654 - acc: 0.9695 | val_loss: 2.33189 - val_acc: 0.4800 -- iter: 240/240
--
Training Step: 33  | total loss: [1m[32m0.15345[0m[0m | time: 18.750s
[2K
| Adam | epoch: 005 | loss: 0.15345 - acc: 0.9762 -- iter: 032/240
[A[ATraining Step: 34  | total loss: [1m[32m0.13378[0m[0m | time: 60.340s
[2K
| Adam | epoch: 005 | loss: 0.13378 - acc: 0.9746 -- iter: 064/240
[A[ATraining Step: 35  | total loss: [1m[32m0.10771[0m[0m | time: 81.303s
[2K
| Adam | epoch: 005 | loss: 0.10771 - acc: 0.9799 -- iter: 096/240
[A[ATraining Step: 36  | total loss: [1m[32m0.08799[0m[0m | time: 90.684s
[2K
| Adam | epoch: 005 | loss: 0.08799 - acc: 0.9840 -- iter: 128/240
[A[ATraining Step: 37  | total loss: [1m[32m0.07290[0m[0m | time: 160.216s
[2K
| Adam | epoch: 005 | loss: 0.07290 - acc: 0.9872 -- iter: 160/240
[A[ATraining Step: 38  | total loss: [1m[32m0.10856[0m[0m | time: 182.847s
[2K
| Adam | epoch: 005 | loss: 0.10856 - acc: 0.9653 -- iter: 192/240
[A[ATraining Step: 39  | total loss: [1m[32m0.11789[0m[0m | time: 195.969s
[2K
| Adam | epoch: 005 | loss: 0.11789 - acc: 0.9599 -- iter: 224/240
[A[ATraining Step: 40  | total loss: [1m[32m0.14102[0m[0m | time: 210.506s
[2K
| Adam | epoch: 005 | loss: 0.14102 - acc: 0.9616 | val_loss: 4.50821 - val_acc: 0.4800 -- iter: 240/240
--
Training Step: 41  | total loss: [1m[32m0.11897[0m[0m | time: 22.961s
[2K
| Adam | epoch: 006 | loss: 0.11897 - acc: 0.9687 -- iter: 032/240
[A[ATraining Step: 42  | total loss: [1m[32m0.10594[0m[0m | time: 44.621s
[2K
| Adam | epoch: 006 | loss: 0.10594 - acc: 0.9743 -- iter: 064/240
[A[ATraining Step: 43  | total loss: [1m[32m0.09028[0m[0m | time: 58.902s
[2K
| Adam | epoch: 006 | loss: 0.09028 - acc: 0.9788 -- iter: 096/240
[A[ATraining Step: 44  | total loss: [1m[32m0.08468[0m[0m | time: 66.406s
[2K
| Adam | epoch: 006 | loss: 0.08468 - acc: 0.9825 -- iter: 128/240
[A[ATraining Step: 45  | total loss: [1m[32m0.07976[0m[0m | time: 72.804s
[2K
| Adam | epoch: 006 | loss: 0.07976 - acc: 0.9855 -- iter: 160/240
[A[ATraining Step: 46  | total loss: [1m[32m0.06925[0m[0m | time: 97.013s
[2K
| Adam | epoch: 006 | loss: 0.06925 - acc: 0.9879 -- iter: 192/240
[A[ATraining Step: 47  | total loss: [1m[32m0.06054[0m[0m | time: 179.496s
[2K
| Adam | epoch: 006 | loss: 0.06054 - acc: 0.9899 -- iter: 224/240
[A[ATraining Step: 48  | total loss: [1m[32m0.06681[0m[0m | time: 234.218s
[2K
| Adam | epoch: 006 | loss: 0.06681 - acc: 0.9815 | val_loss: 4.70542 - val_acc: 0.4800 -- iter: 240/240
--
Training Step: 49  | total loss: [1m[32m0.06637[0m[0m | time: 11.801s
[2K
| Adam | epoch: 007 | loss: 0.06637 - acc: 0.9844 -- iter: 032/240
[A[ATraining Step: 50  | total loss: [1m[32m0.05739[0m[0m | time: 21.381s
[2K
| Adam | epoch: 007 | loss: 0.05739 - acc: 0.9868 -- iter: 064/240
[A[ATraining Step: 51  | total loss: [1m[32m0.05067[0m[0m | time: 38.497s
[2K
| Adam | epoch: 007 | loss: 0.05067 - acc: 0.9888 -- iter: 096/240
[A[ATraining Step: 52  | total loss: [1m[32m0.06081[0m[0m | time: 63.500s
[2K
| Adam | epoch: 007 | loss: 0.06081 - acc: 0.9811 -- iter: 128/240
[A[ATraining Step: 53  | total loss: [1m[32m0.05551[0m[0m | time: 73.731s
[2K
| Adam | epoch: 007 | loss: 0.05551 - acc: 0.9839 -- iter: 160/240
[A[ATraining Step: 54  | total loss: [1m[32m0.04807[0m[0m | time: 84.332s
[2K
| Adam | epoch: 007 | loss: 0.04807 - acc: 0.9862 -- iter: 192/240
[A[ATraining Step: 55  | total loss: [1m[32m0.04201[0m[0m | time: 142.953s
[2K
| Adam | epoch: 007 | loss: 0.04201 - acc: 0.9882 -- iter: 224/240
[A[ATraining Step: 56  | total loss: [1m[32m0.04454[0m[0m | time: 164.623s
[2K
| Adam | epoch: 007 | loss: 0.04454 - acc: 0.9855 | val_loss: 1.63049 - val_acc: 0.6000 -- iter: 240/240
--
Training Step: 57  | total loss: [1m[32m0.04405[0m[0m | time: 17.595s
[2K
| Adam | epoch: 008 | loss: 0.04405 - acc: 0.9875 -- iter: 032/240
[A[ATraining Step: 58  | total loss: [1m[32m0.03905[0m[0m | time: 30.445s
[2K
| Adam | epoch: 008 | loss: 0.03905 - acc: 0.9892 -- iter: 064/240
[A[ATraining Step: 59  | total loss: [1m[32m0.03454[0m[0m | time: 45.165s
[2K
| Adam | epoch: 008 | loss: 0.03454 - acc: 0.9906 -- iter: 096/240
[A[ATraining Step: 60  | total loss: [1m[32m0.03146[0m[0m | time: 64.070s
[2K
| Adam | epoch: 008 | loss: 0.03146 - acc: 0.9919 -- iter: 128/240
[A[ATraining Step: 61  | total loss: [1m[32m0.02762[0m[0m | time: 77.419s
[2K
| Adam | epoch: 008 | loss: 0.02762 - acc: 0.9929 -- iter: 160/240
[A[ATraining Step: 62  | total loss: [1m[32m0.02584[0m[0m | time: 85.138s
[2K
| Adam | epoch: 008 | loss: 0.02584 - acc: 0.9938 -- iter: 192/240
[A[ATraining Step: 63  | total loss: [1m[32m0.02347[0m[0m | time: 94.294s
[2K
| Adam | epoch: 008 | loss: 0.02347 - acc: 0.9946 -- iter: 224/240
[A[ATraining Step: 64  | total loss: [1m[32m0.02099[0m[0m | time: 115.086s
[2K
| Adam | epoch: 008 | loss: 0.02099 - acc: 0.9953 | val_loss: 0.45524 - val_acc: 0.8667 -- iter: 240/240
--
Training Step: 65  | total loss: [1m[32m0.01875[0m[0m | time: 11.878s
[2K
| Adam | epoch: 009 | loss: 0.01875 - acc: 0.9959 -- iter: 032/240
[A[ATraining Step: 66  | total loss: [1m[32m0.01707[0m[0m | time: 26.372s
[2K
| Adam | epoch: 009 | loss: 0.01707 - acc: 0.9964 -- iter: 064/240
[A[ATraining Step: 67  | total loss: [1m[32m0.01655[0m[0m | time: 39.449s
[2K
| Adam | epoch: 009 | loss: 0.01655 - acc: 0.9968 -- iter: 096/240
[A[ATraining Step: 68  | total loss: [1m[32m0.01594[0m[0m | time: 53.408s
[2K
| Adam | epoch: 009 | loss: 0.01594 - acc: 0.9972 -- iter: 128/240
[A[ATraining Step: 69  | total loss: [1m[32m0.01426[0m[0m | time: 73.366s
[2K
| Adam | epoch: 009 | loss: 0.01426 - acc: 0.9975 -- iter: 160/240
[A[ATraining Step: 70  | total loss: [1m[32m0.01780[0m[0m | time: 91.033s
[2K
| Adam | epoch: 009 | loss: 0.01780 - acc: 0.9942 -- iter: 192/240
[A[ATraining Step: 71  | total loss: [1m[32m0.01623[0m[0m | time: 101.089s
[2K
| Adam | epoch: 009 | loss: 0.01623 - acc: 0.9949 -- iter: 224/240
[A[ATraining Step: 72  | total loss: [1m[32m0.01464[0m[0m | time: 113.368s
[2K
| Adam | epoch: 009 | loss: 0.01464 - acc: 0.9954 | val_loss: 1.61603 - val_acc: 0.7867 -- iter: 240/240
--
Training Step: 73  | total loss: [1m[32m0.01318[0m[0m | time: 14.541s
[2K
| Adam | epoch: 010 | loss: 0.01318 - acc: 0.9959 -- iter: 032/240
[A[ATraining Step: 74  | total loss: [1m[32m0.01200[0m[0m | time: 33.661s
[2K
| Adam | epoch: 010 | loss: 0.01200 - acc: 0.9964 -- iter: 064/240
[A[ATraining Step: 75  | total loss: [1m[32m0.01823[0m[0m | time: 51.352s
[2K
| Adam | epoch: 010 | loss: 0.01823 - acc: 0.9934 -- iter: 096/240
[A[ATraining Step: 76  | total loss: [1m[32m0.05254[0m[0m | time: 70.476s
[2K
| Adam | epoch: 010 | loss: 0.05254 - acc: 0.9908 -- iter: 128/240
[A[ATraining Step: 77  | total loss: [1m[32m0.04721[0m[0m | time: 87.463s
[2K
| Adam | epoch: 010 | loss: 0.04721 - acc: 0.9917 -- iter: 160/240
[A[ATraining Step: 78  | total loss: [1m[32m0.06056[0m[0m | time: 98.784s
[2K
| Adam | epoch: 010 | loss: 0.06056 - acc: 0.9861 -- iter: 192/240
[A[ATraining Step: 79  | total loss: [1m[32m0.05833[0m[0m | time: 107.489s
[2K
| Adam | epoch: 010 | loss: 0.05833 - acc: 0.9843 -- iter: 224/240
[A[ATraining Step: 80  | total loss: [1m[32m0.05411[0m[0m | time: 120.756s
[2K
| Adam | epoch: 010 | loss: 0.05411 - acc: 0.9859 | val_loss: 0.62475 - val_acc: 0.8533 -- iter: 240/240
--
Training Step: 81  | total loss: [1m[32m0.04883[0m[0m | time: 10.796s
[2K
| Adam | epoch: 011 | loss: 0.04883 - acc: 0.9873 -- iter: 032/240
[A[ATraining Step: 82  | total loss: [1m[32m0.04412[0m[0m | time: 29.818s
[2K
| Adam | epoch: 011 | loss: 0.04412 - acc: 0.9886 -- iter: 064/240
[A[ATraining Step: 83  | total loss: [1m[32m0.04456[0m[0m | time: 42.883s
[2K
| Adam | epoch: 011 | loss: 0.04456 - acc: 0.9866 -- iter: 096/240
[A[ATraining Step: 84  | total loss: [1m[32m0.04310[0m[0m | time: 51.786s
[2K
| Adam | epoch: 011 | loss: 0.04310 - acc: 0.9848 -- iter: 128/240
[A[ATraining Step: 85  | total loss: [1m[32m0.03952[0m[0m | time: 61.526s
[2K
| Adam | epoch: 011 | loss: 0.03952 - acc: 0.9863 -- iter: 160/240
[A[ATraining Step: 86  | total loss: [1m[32m0.03578[0m[0m | time: 75.093s
[2K
| Adam | epoch: 011 | loss: 0.03578 - acc: 0.9877 -- iter: 192/240
[A[ATraining Step: 87  | total loss: [1m[32m0.03342[0m[0m | time: 90.025s
[2K
| Adam | epoch: 011 | loss: 0.03342 - acc: 0.9889 -- iter: 224/240
[A[ATraining Step: 88  | total loss: [1m[32m0.03214[0m[0m | time: 108.789s
[2K
| Adam | epoch: 011 | loss: 0.03214 - acc: 0.9900 | val_loss: 2.82555 - val_acc: 0.6667 -- iter: 240/240
--
Training Step: 89  | total loss: [1m[32m0.03052[0m[0m | time: 4.851s
[2K
| Adam | epoch: 012 | loss: 0.03052 - acc: 0.9910 -- iter: 032/240
[A[ATraining Step: 90  | total loss: [1m[32m0.02786[0m[0m | time: 10.863s
[2K
| Adam | epoch: 012 | loss: 0.02786 - acc: 0.9919 -- iter: 064/240
[A[ATraining Step: 91  | total loss: [1m[32m0.02527[0m[0m | time: 22.973s
[2K
| Adam | epoch: 012 | loss: 0.02527 - acc: 0.9927 -- iter: 096/240
[A[ATraining Step: 92  | total loss: [1m[32m0.03071[0m[0m | time: 34.921s
[2K
| Adam | epoch: 012 | loss: 0.03071 - acc: 0.9903 -- iter: 128/240
[A[ATraining Step: 93  | total loss: [1m[32m0.02796[0m[0m | time: 47.730s
[2K
| Adam | epoch: 012 | loss: 0.02796 - acc: 0.9913 -- iter: 160/240
[A[ATraining Step: 94  | total loss: [1m[32m0.02580[0m[0m | time: 59.705s
[2K
| Adam | epoch: 012 | loss: 0.02580 - acc: 0.9922 -- iter: 192/240
[A[ATraining Step: 95  | total loss: [1m[32m0.02443[0m[0m | time: 68.145s
[2K
| Adam | epoch: 012 | loss: 0.02443 - acc: 0.9930 -- iter: 224/240
[A[ATraining Step: 96  | total loss: [1m[32m0.02219[0m[0m | time: 82.652s
[2K
| Adam | epoch: 012 | loss: 0.02219 - acc: 0.9937 | val_loss: 2.63326 - val_acc: 0.6933 -- iter: 240/240
--
Training Step: 97  | total loss: [1m[32m0.02128[0m[0m | time: 12.227s
[2K
| Adam | epoch: 013 | loss: 0.02128 - acc: 0.9943 -- iter: 032/240
[A[ATraining Step: 98  | total loss: [1m[32m0.01948[0m[0m | time: 17.020s
[2K
| Adam | epoch: 013 | loss: 0.01948 - acc: 0.9949 -- iter: 064/240
[A[ATraining Step: 99  | total loss: [1m[32m0.02038[0m[0m | time: 21.709s
[2K
| Adam | epoch: 013 | loss: 0.02038 - acc: 0.9954 -- iter: 096/240
[A[ATraining Step: 100  | total loss: [1m[32m0.01936[0m[0m | time: 30.253s
[2K
| Adam | epoch: 013 | loss: 0.01936 - acc: 0.9958 -- iter: 128/240
[A[ATraining Step: 101  | total loss: [1m[32m0.01788[0m[0m | time: 43.021s
[2K
| Adam | epoch: 013 | loss: 0.01788 - acc: 0.9963 -- iter: 160/240
[A[ATraining Step: 102  | total loss: [1m[32m0.02084[0m[0m | time: 55.973s
[2K
| Adam | epoch: 013 | loss: 0.02084 - acc: 0.9935 -- iter: 192/240
[A[ATraining Step: 103  | total loss: [1m[32m0.10655[0m[0m | time: 68.912s
[2K
| Adam | epoch: 013 | loss: 0.10655 - acc: 0.9848 -- iter: 224/240
[A[ATraining Step: 104  | total loss: [1m[32m0.10184[0m[0m | time: 83.860s
[2K
| Adam | epoch: 013 | loss: 0.10184 - acc: 0.9832 | val_loss: 0.63124 - val_acc: 0.8400 -- iter: 240/240
--
Training Step: 105  | total loss: [1m[32m0.09186[0m[0m | time: 12.713s
[2K
| Adam | epoch: 014 | loss: 0.09186 - acc: 0.9849 -- iter: 032/240
[A[ATraining Step: 106  | total loss: [1m[32m0.08545[0m[0m | time: 25.404s
[2K
| Adam | epoch: 014 | loss: 0.08545 - acc: 0.9832 -- iter: 064/240
[A[ATraining Step: 107  | total loss: [1m[32m0.07766[0m[0m | time: 33.001s
[2K
| Adam | epoch: 014 | loss: 0.07766 - acc: 0.9849 -- iter: 096/240
[A[ATraining Step: 108  | total loss: [1m[32m0.07364[0m[0m | time: 40.328s
[2K
| Adam | epoch: 014 | loss: 0.07364 - acc: 0.9864 -- iter: 128/240
[A[ATraining Step: 109  | total loss: [1m[32m0.06724[0m[0m | time: 51.315s
[2K
| Adam | epoch: 014 | loss: 0.06724 - acc: 0.9878 -- iter: 160/240
[A[ATraining Step: 110  | total loss: [1m[32m0.07346[0m[0m | time: 59.798s
[2K
| Adam | epoch: 014 | loss: 0.07346 - acc: 0.9828 -- iter: 192/240
[A[ATraining Step: 111  | total loss: [1m[32m0.06883[0m[0m | time: 68.490s
[2K
| Adam | epoch: 014 | loss: 0.06883 - acc: 0.9845 -- iter: 224/240
[A[ATraining Step: 112  | total loss: [1m[32m0.15945[0m[0m | time: 85.718s
[2K
| Adam | epoch: 014 | loss: 0.15945 - acc: 0.9673 | val_loss: 1.64059 - val_acc: 0.5067 -- iter: 240/240
--
Training Step: 113  | total loss: [1m[32m0.16078[0m[0m | time: 12.238s
[2K
| Adam | epoch: 015 | loss: 0.16078 - acc: 0.9674 -- iter: 032/240
[A[ATraining Step: 114  | total loss: [1m[32m0.14758[0m[0m | time: 20.775s
[2K
| Adam | epoch: 015 | loss: 0.14758 - acc: 0.9707 -- iter: 064/240
[A[ATraining Step: 115  | total loss: [1m[32m0.15827[0m[0m | time: 29.345s
[2K
| Adam | epoch: 015 | loss: 0.15827 - acc: 0.9674 -- iter: 096/240
[A[ATraining Step: 116  | total loss: [1m[32m0.14486[0m[0m | time: 34.489s
[2K
| Adam | epoch: 015 | loss: 0.14486 - acc: 0.9706 -- iter: 128/240
[A[ATraining Step: 117  | total loss: [1m[32m0.14279[0m[0m | time: 41.252s
[2K
| Adam | epoch: 015 | loss: 0.14279 - acc: 0.9673 -- iter: 160/240
[A[ATraining Step: 118  | total loss: [1m[32m0.13303[0m[0m | time: 53.787s
[2K
| Adam | epoch: 015 | loss: 0.13303 - acc: 0.9706 -- iter: 192/240
[A[ATraining Step: 119  | total loss: [1m[32m0.12345[0m[0m | time: 66.235s
[2K
| Adam | epoch: 015 | loss: 0.12345 - acc: 0.9735 -- iter: 224/240
[A[ATraining Step: 120  | total loss: [1m[32m0.11387[0m[0m | time: 83.591s
[2K
| Adam | epoch: 015 | loss: 0.11387 - acc: 0.9762 | val_loss: 0.78394 - val_acc: 0.8133 -- iter: 240/240
--
Validation AUC:0.9394586894586895
Validation AUPRC:0.9065738047216139
Test AUC:0.9648493543758967
Test AUPRC:0.9788494703128849
BestTestF1Score	0.94	0.87	0.93	0.95	0.93	38	2	32	3	0.99
BestTestMCCScore	0.94	0.87	0.93	0.95	0.93	38	2	32	3	0.99
BestTestAccuracyScore	0.94	0.87	0.93	0.95	0.93	38	2	32	3	0.99
BestValidationF1Score	0.91	0.81	0.91	0.9	0.92	36	4	32	3	0.99
BestValidationMCC	0.91	0.81	0.91	0.9	0.92	36	4	32	3	0.99
BestValidationAccuracy	0.91	0.81	0.91	0.9	0.92	36	4	32	3	0.99
TestPredictions (Threshold:0.99)
CHEMBL2419542,TP,ACT,1.0	CHEMBL2372525,TP,ACT,1.0	CHEMBL2419541,TP,ACT,1.0	CHEMBL436706,TP,ACT,1.0	CHEMBL406442,TP,ACT,1.0	CHEMBL294649,TN,INACT,0.05000000074505806	CHEMBL3138259,TP,ACT,1.0	CHEMBL281232,TN,INACT,0.009999999776482582	CHEMBL228144,TN,INACT,0.0	CHEMBL605906,TP,ACT,1.0	CHEMBL2113072,TN,INACT,0.9800000190734863	CHEMBL3608937,TP,ACT,1.0	CHEMBL357717,TP,ACT,1.0	CHEMBL2372516,TP,ACT,1.0	CHEMBL556537,TP,ACT,1.0	CHEMBL410808,TP,ACT,1.0	CHEMBL21509,TN,INACT,0.029999999329447746	CHEMBL356912,TP,ACT,1.0	CHEMBL23147,TP,ACT,1.0	CHEMBL2369493,TN,INACT,0.9700000286102295	CHEMBL346633,TP,ACT,1.0	CHEMBL557188,TP,ACT,1.0	CHEMBL353502,TN,INACT,0.6600000262260437	CHEMBL278135,TP,ACT,1.0	CHEMBL2370509,FP,INACT,0.9900000095367432	CHEMBL515170,TN,INACT,0.4099999964237213	CHEMBL3633663,TN,INACT,0.11999999731779099	CHEMBL168632,FP,INACT,0.9900000095367432	CHEMBL23360,TP,ACT,1.0	CHEMBL131171,TP,ACT,1.0	CHEMBL297776,TP,ACT,1.0	CHEMBL175698,TN,INACT,0.8999999761581421	CHEMBL43330,TN,INACT,0.9399999976158142	CHEMBL16192,TP,ACT,1.0	CHEMBL216813,TP,ACT,1.0	CHEMBL450729,TN,INACT,0.0	CHEMBL513277,TN,INACT,0.0	CHEMBL276294,TP,ACT,1.0	CHEMBL595022,TN,INACT,0.0	CHEMBL297335,TN,INACT,0.75	CHEMBL52448,TP,ACT,1.0	CHEMBL45305,TN,INACT,0.10000000149011612	CHEMBL389652,TP,ACT,1.0	CHEMBL1258999,TN,INACT,0.27000001072883606	CHEMBL23533,TP,ACT,1.0	CHEMBL420359,TN,INACT,0.8899999856948853	CHEMBL110053,TN,INACT,0.75	CHEMBL298203,TN,INACT,0.27000001072883606	CHEMBL109926,TN,INACT,0.6200000047683716	CHEMBL109206,TN,INACT,0.8600000143051147	CHEMBL330674,TN,INACT,0.019999999552965164	CHEMBL388265,TP,ACT,1.0	CHEMBL355851,TN,INACT,0.029999999329447746	CHEMBL545363,TN,INACT,0.03999999910593033	CHEMBL59,TN,INACT,0.009999999776482582	CHEMBL589543,FN,ACT,0.11999999731779099	CHEMBL396426,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.0	CHEMBL278294,TP,ACT,1.0	CHEMBL2371916,TP,ACT,1.0	CHEMBL331346,TP,ACT,1.0	CHEMBL58178,TP,ACT,1.0	CHEMBL350320,FN,ACT,0.14000000059604645	CHEMBL42360,TN,INACT,0.07999999821186066	CHEMBL261608,TP,ACT,1.0	CHEMBL589979,TP,ACT,1.0	CHEMBL2372339,TP,ACT,1.0	CHEMBL406812,TP,ACT,1.0	CHEMBL3609615,TP,ACT,1.0	CHEMBL295845,TP,ACT,1.0	CHEMBL40796,TN,INACT,0.009999999776482582	CHEMBL590518,FN,ACT,0.07000000029802322	CHEMBL2042551,TN,INACT,0.019999999552965164	CHEMBL295651,TN,INACT,0.019999999552965164	CHEMBL21937,TN,INACT,0.10000000149011612	

