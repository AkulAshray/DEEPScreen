CNNModel CHEMBL2039 RMSprop 0.0005 30 256 0 0.8 False True
Number of active compounds :	1377
Number of inactive compounds :	918
---------------------------------
Run id: CNNModel_CHEMBL2039_RMSprop_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2039_RMSprop_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 1443
Validation samples: 452
--
Training Step: 1  | time: 0.950s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1443
[A[ATraining Step: 2  | total loss: [1m[32m0.62336[0m[0m | time: 1.713s
[2K
| RMSProp | epoch: 001 | loss: 0.62336 - acc: 0.5344 -- iter: 0064/1443
[A[ATraining Step: 3  | total loss: [1m[32m0.67994[0m[0m | time: 2.441s
[2K
| RMSProp | epoch: 001 | loss: 0.67994 - acc: 0.6341 -- iter: 0096/1443
[A[ATraining Step: 4  | total loss: [1m[32m0.68976[0m[0m | time: 3.224s
[2K
| RMSProp | epoch: 001 | loss: 0.68976 - acc: 0.5804 -- iter: 0128/1443
[A[ATraining Step: 5  | total loss: [1m[32m0.69188[0m[0m | time: 3.991s
[2K
| RMSProp | epoch: 001 | loss: 0.69188 - acc: 0.5680 -- iter: 0160/1443
[A[ATraining Step: 6  | total loss: [1m[32m0.69249[0m[0m | time: 4.759s
[2K
| RMSProp | epoch: 001 | loss: 0.69249 - acc: 0.5645 -- iter: 0192/1443
[A[ATraining Step: 7  | total loss: [1m[32m0.69237[0m[0m | time: 5.499s
[2K
| RMSProp | epoch: 001 | loss: 0.69237 - acc: 0.6195 -- iter: 0224/1443
[A[ATraining Step: 8  | total loss: [1m[32m0.69269[0m[0m | time: 6.270s
[2K
| RMSProp | epoch: 001 | loss: 0.69269 - acc: 0.5699 -- iter: 0256/1443
[A[ATraining Step: 9  | total loss: [1m[32m0.69295[0m[0m | time: 6.992s
[2K
| RMSProp | epoch: 001 | loss: 0.69295 - acc: 0.5329 -- iter: 0288/1443
[A[ATraining Step: 10  | total loss: [1m[32m0.69254[0m[0m | time: 7.721s
[2K
| RMSProp | epoch: 001 | loss: 0.69254 - acc: 0.6102 -- iter: 0320/1443
[A[ATraining Step: 11  | total loss: [1m[32m0.69241[0m[0m | time: 8.547s
[2K
| RMSProp | epoch: 001 | loss: 0.69241 - acc: 0.6172 -- iter: 0352/1443
[A[ATraining Step: 12  | total loss: [1m[32m0.69286[0m[0m | time: 9.548s
[2K
| RMSProp | epoch: 001 | loss: 0.69286 - acc: 0.5504 -- iter: 0384/1443
[A[ATraining Step: 13  | total loss: [1m[32m0.69277[0m[0m | time: 10.309s
[2K
| RMSProp | epoch: 001 | loss: 0.69277 - acc: 0.5556 -- iter: 0416/1443
[A[ATraining Step: 14  | total loss: [1m[32m0.69272[0m[0m | time: 11.069s
[2K
| RMSProp | epoch: 001 | loss: 0.69272 - acc: 0.5712 -- iter: 0448/1443
[A[ATraining Step: 15  | total loss: [1m[32m0.69301[0m[0m | time: 11.820s
[2K
| RMSProp | epoch: 001 | loss: 0.69301 - acc: 0.5311 -- iter: 0480/1443
[A[ATraining Step: 16  | total loss: [1m[32m0.69299[0m[0m | time: 12.598s
[2K
| RMSProp | epoch: 001 | loss: 0.69299 - acc: 0.5312 -- iter: 0512/1443
[A[ATraining Step: 17  | total loss: [1m[32m0.69266[0m[0m | time: 13.392s
[2K
| RMSProp | epoch: 001 | loss: 0.69266 - acc: 0.5762 -- iter: 0544/1443
[A[ATraining Step: 18  | total loss: [1m[32m0.69270[0m[0m | time: 14.139s
[2K
| RMSProp | epoch: 001 | loss: 0.69270 - acc: 0.5606 -- iter: 0576/1443
[A[ATraining Step: 19  | total loss: [1m[32m0.69236[0m[0m | time: 14.886s
[2K
| RMSProp | epoch: 001 | loss: 0.69236 - acc: 0.6133 -- iter: 0608/1443
[A[ATraining Step: 20  | total loss: [1m[32m0.69246[0m[0m | time: 15.637s
[2K
| RMSProp | epoch: 001 | loss: 0.69246 - acc: 0.5970 -- iter: 0640/1443
[A[ATraining Step: 21  | total loss: [1m[32m0.69246[0m[0m | time: 16.375s
[2K
| RMSProp | epoch: 001 | loss: 0.69246 - acc: 0.5960 -- iter: 0672/1443
[A[ATraining Step: 22  | total loss: [1m[32m0.69235[0m[0m | time: 17.122s
[2K
| RMSProp | epoch: 001 | loss: 0.69235 - acc: 0.6047 -- iter: 0704/1443
[A[ATraining Step: 23  | total loss: [1m[32m0.69246[0m[0m | time: 17.842s
[2K
| RMSProp | epoch: 001 | loss: 0.69246 - acc: 0.5924 -- iter: 0736/1443
[A[ATraining Step: 24  | total loss: [1m[32m0.69273[0m[0m | time: 18.603s
[2K
| RMSProp | epoch: 001 | loss: 0.69273 - acc: 0.5577 -- iter: 0768/1443
[A[ATraining Step: 25  | total loss: [1m[32m0.69268[0m[0m | time: 19.365s
[2K
| RMSProp | epoch: 001 | loss: 0.69268 - acc: 0.5590 -- iter: 0800/1443
[A[ATraining Step: 26  | total loss: [1m[32m0.69297[0m[0m | time: 20.083s
[2K
| RMSProp | epoch: 001 | loss: 0.69297 - acc: 0.5268 -- iter: 0832/1443
[A[ATraining Step: 27  | total loss: [1m[32m0.69298[0m[0m | time: 20.793s
[2K
| RMSProp | epoch: 001 | loss: 0.69298 - acc: 0.5280 -- iter: 0864/1443
[A[ATraining Step: 28  | total loss: [1m[32m0.69276[0m[0m | time: 21.553s
[2K
| RMSProp | epoch: 001 | loss: 0.69276 - acc: 0.5522 -- iter: 0896/1443
[A[ATraining Step: 29  | total loss: [1m[32m0.69264[0m[0m | time: 22.355s
[2K
| RMSProp | epoch: 001 | loss: 0.69264 - acc: 0.5623 -- iter: 0928/1443
[A[ATraining Step: 30  | total loss: [1m[32m0.69232[0m[0m | time: 23.098s
[2K
| RMSProp | epoch: 001 | loss: 0.69232 - acc: 0.5920 -- iter: 0960/1443
[A[ATraining Step: 31  | total loss: [1m[32m0.69203[0m[0m | time: 23.835s
[2K
| RMSProp | epoch: 001 | loss: 0.69203 - acc: 0.6140 -- iter: 0992/1443
[A[ATraining Step: 32  | total loss: [1m[32m0.69170[0m[0m | time: 24.585s
[2K
| RMSProp | epoch: 001 | loss: 0.69170 - acc: 0.6376 -- iter: 1024/1443
[A[ATraining Step: 33  | total loss: [1m[32m0.69214[0m[0m | time: 25.341s
[2K
| RMSProp | epoch: 001 | loss: 0.69214 - acc: 0.6005 -- iter: 1056/1443
[A[ATraining Step: 34  | total loss: [1m[32m0.69240[0m[0m | time: 26.076s
[2K
| RMSProp | epoch: 001 | loss: 0.69240 - acc: 0.5723 -- iter: 1088/1443
[A[ATraining Step: 35  | total loss: [1m[32m0.69241[0m[0m | time: 26.813s
[2K
| RMSProp | epoch: 001 | loss: 0.69241 - acc: 0.5702 -- iter: 1120/1443
[A[ATraining Step: 36  | total loss: [1m[32m0.69201[0m[0m | time: 27.555s
[2K
| RMSProp | epoch: 001 | loss: 0.69201 - acc: 0.6006 -- iter: 1152/1443
[A[ATraining Step: 37  | total loss: [1m[32m0.69191[0m[0m | time: 28.291s
[2K
| RMSProp | epoch: 001 | loss: 0.69191 - acc: 0.6055 -- iter: 1184/1443
[A[ATraining Step: 38  | total loss: [1m[32m0.69207[0m[0m | time: 29.041s
[2K
| RMSProp | epoch: 001 | loss: 0.69207 - acc: 0.5910 -- iter: 1216/1443
[A[ATraining Step: 39  | total loss: [1m[32m0.69196[0m[0m | time: 29.790s
[2K
| RMSProp | epoch: 001 | loss: 0.69196 - acc: 0.5915 -- iter: 1248/1443
[A[ATraining Step: 40  | total loss: [1m[32m0.69217[0m[0m | time: 30.523s
[2K
| RMSProp | epoch: 001 | loss: 0.69217 - acc: 0.5743 -- iter: 1280/1443
[A[ATraining Step: 41  | total loss: [1m[32m0.69226[0m[0m | time: 31.281s
[2K
| RMSProp | epoch: 001 | loss: 0.69226 - acc: 0.5664 -- iter: 1312/1443
[A[ATraining Step: 42  | total loss: [1m[32m0.69241[0m[0m | time: 32.077s
[2K
| RMSProp | epoch: 001 | loss: 0.69241 - acc: 0.5545 -- iter: 1344/1443
[A[ATraining Step: 43  | total loss: [1m[32m0.69242[0m[0m | time: 32.841s
[2K
| RMSProp | epoch: 001 | loss: 0.69242 - acc: 0.5504 -- iter: 1376/1443
[A[ATraining Step: 44  | total loss: [1m[32m0.69186[0m[0m | time: 33.568s
[2K
| RMSProp | epoch: 001 | loss: 0.69186 - acc: 0.5849 -- iter: 1408/1443
[A[ATraining Step: 45  | total loss: [1m[32m0.69177[0m[0m | time: 34.307s
[2K
| RMSProp | epoch: 001 | loss: 0.69177 - acc: 0.5864 -- iter: 1440/1443
[A[ATraining Step: 46  | total loss: [1m[32m0.69232[0m[0m | time: 36.441s
[2K
| RMSProp | epoch: 001 | loss: 0.69232 - acc: 0.5564 | val_loss: 0.69119 - val_acc: 0.6018 -- iter: 1443/1443
--
Training Step: 47  | total loss: [1m[32m0.69200[0m[0m | time: 0.094s
[2K
| RMSProp | epoch: 002 | loss: 0.69200 - acc: 0.5744 -- iter: 0032/1443
[A[ATraining Step: 48  | total loss: [1m[32m0.69164[0m[0m | time: 0.802s
[2K
| RMSProp | epoch: 002 | loss: 0.69164 - acc: 0.5893 -- iter: 0064/1443
[A[ATraining Step: 49  | total loss: [1m[32m0.69128[0m[0m | time: 1.552s
[2K
| RMSProp | epoch: 002 | loss: 0.69128 - acc: 0.6048 -- iter: 0096/1443
[A[ATraining Step: 50  | total loss: [1m[32m0.69114[0m[0m | time: 2.307s
[2K
| RMSProp | epoch: 002 | loss: 0.69114 - acc: 0.6079 -- iter: 0128/1443
[A[ATraining Step: 51  | total loss: [1m[32m0.69124[0m[0m | time: 3.112s
[2K
| RMSProp | epoch: 002 | loss: 0.69124 - acc: 0.6010 -- iter: 0160/1443
[A[ATraining Step: 52  | total loss: [1m[32m0.69122[0m[0m | time: 3.905s
[2K
| RMSProp | epoch: 002 | loss: 0.69122 - acc: 0.5999 -- iter: 0192/1443
[A[ATraining Step: 53  | total loss: [1m[32m0.69106[0m[0m | time: 4.680s
[2K
| RMSProp | epoch: 002 | loss: 0.69106 - acc: 0.6036 -- iter: 0224/1443
[A[ATraining Step: 54  | total loss: [1m[32m0.69126[0m[0m | time: 5.426s
[2K
| RMSProp | epoch: 002 | loss: 0.69126 - acc: 0.5931 -- iter: 0256/1443
[A[ATraining Step: 55  | total loss: [1m[32m0.69118[0m[0m | time: 6.182s
[2K
| RMSProp | epoch: 002 | loss: 0.69118 - acc: 0.5932 -- iter: 0288/1443
[A[ATraining Step: 56  | total loss: [1m[32m0.69196[0m[0m | time: 6.926s
[2K
| RMSProp | epoch: 002 | loss: 0.69196 - acc: 0.5625 -- iter: 0320/1443
[A[ATraining Step: 57  | total loss: [1m[32m0.69156[0m[0m | time: 7.687s
[2K
| RMSProp | epoch: 002 | loss: 0.69156 - acc: 0.5755 -- iter: 0352/1443
[A[ATraining Step: 58  | total loss: [1m[32m0.69131[0m[0m | time: 8.445s
[2K
| RMSProp | epoch: 002 | loss: 0.69131 - acc: 0.5822 -- iter: 0384/1443
[A[ATraining Step: 59  | total loss: [1m[32m0.69087[0m[0m | time: 9.166s
[2K
| RMSProp | epoch: 002 | loss: 0.69087 - acc: 0.5964 -- iter: 0416/1443
[A[ATraining Step: 60  | total loss: [1m[32m0.69053[0m[0m | time: 9.895s
[2K
| RMSProp | epoch: 002 | loss: 0.69053 - acc: 0.6043 -- iter: 0448/1443
[A[ATraining Step: 61  | total loss: [1m[32m0.68996[0m[0m | time: 10.635s
[2K
| RMSProp | epoch: 002 | loss: 0.68996 - acc: 0.6192 -- iter: 0480/1443
[A[ATraining Step: 62  | total loss: [1m[32m0.68995[0m[0m | time: 11.394s
[2K
| RMSProp | epoch: 002 | loss: 0.68995 - acc: 0.6160 -- iter: 0512/1443
[A[ATraining Step: 63  | total loss: [1m[32m0.68981[0m[0m | time: 12.183s
[2K
| RMSProp | epoch: 002 | loss: 0.68981 - acc: 0.6171 -- iter: 0544/1443
[A[ATraining Step: 64  | total loss: [1m[32m0.69039[0m[0m | time: 12.941s
[2K
| RMSProp | epoch: 002 | loss: 0.69039 - acc: 0.5986 -- iter: 0576/1443
[A[ATraining Step: 65  | total loss: [1m[32m0.69017[0m[0m | time: 13.702s
[2K
| RMSProp | epoch: 002 | loss: 0.69017 - acc: 0.6018 -- iter: 0608/1443
[A[ATraining Step: 66  | total loss: [1m[32m0.69039[0m[0m | time: 14.426s
[2K
| RMSProp | epoch: 002 | loss: 0.69039 - acc: 0.5932 -- iter: 0640/1443
[A[ATraining Step: 67  | total loss: [1m[32m0.69043[0m[0m | time: 15.155s
[2K
| RMSProp | epoch: 002 | loss: 0.69043 - acc: 0.5895 -- iter: 0672/1443
[A[ATraining Step: 68  | total loss: [1m[32m0.69017[0m[0m | time: 15.877s
[2K
| RMSProp | epoch: 002 | loss: 0.69017 - acc: 0.5937 -- iter: 0704/1443
[A[ATraining Step: 69  | total loss: [1m[32m0.69084[0m[0m | time: 16.657s
[2K
| RMSProp | epoch: 002 | loss: 0.69084 - acc: 0.5755 -- iter: 0736/1443
[A[ATraining Step: 70  | total loss: [1m[32m0.69158[0m[0m | time: 17.444s
[2K
| RMSProp | epoch: 002 | loss: 0.69158 - acc: 0.5560 -- iter: 0768/1443
[A[ATraining Step: 71  | total loss: [1m[32m0.69220[0m[0m | time: 18.165s
[2K
| RMSProp | epoch: 002 | loss: 0.69220 - acc: 0.5389 -- iter: 0800/1443
[A[ATraining Step: 72  | total loss: [1m[32m0.69208[0m[0m | time: 18.939s
[2K
| RMSProp | epoch: 002 | loss: 0.69208 - acc: 0.5416 -- iter: 0832/1443
[A[ATraining Step: 73  | total loss: [1m[32m0.69169[0m[0m | time: 19.675s
[2K
| RMSProp | epoch: 002 | loss: 0.69169 - acc: 0.5508 -- iter: 0864/1443
[A[ATraining Step: 74  | total loss: [1m[32m0.69116[0m[0m | time: 20.471s
[2K
| RMSProp | epoch: 002 | loss: 0.69116 - acc: 0.5624 -- iter: 0896/1443
[A[ATraining Step: 75  | total loss: [1m[32m0.69110[0m[0m | time: 21.258s
[2K
| RMSProp | epoch: 002 | loss: 0.69110 - acc: 0.5624 -- iter: 0928/1443
[A[ATraining Step: 76  | total loss: [1m[32m0.69046[0m[0m | time: 22.024s
[2K
| RMSProp | epoch: 002 | loss: 0.69046 - acc: 0.5758 -- iter: 0960/1443
[A[ATraining Step: 77  | total loss: [1m[32m0.69046[0m[0m | time: 22.765s
[2K
| RMSProp | epoch: 002 | loss: 0.69046 - acc: 0.5744 -- iter: 0992/1443
[A[ATraining Step: 78  | total loss: [1m[32m0.69094[0m[0m | time: 23.492s
[2K
| RMSProp | epoch: 002 | loss: 0.69094 - acc: 0.5633 -- iter: 1024/1443
[A[ATraining Step: 79  | total loss: [1m[32m0.69044[0m[0m | time: 24.209s
[2K
| RMSProp | epoch: 002 | loss: 0.69044 - acc: 0.5730 -- iter: 1056/1443
[A[ATraining Step: 80  | total loss: [1m[32m0.69028[0m[0m | time: 24.942s
[2K
| RMSProp | epoch: 002 | loss: 0.69028 - acc: 0.5751 -- iter: 1088/1443
[A[ATraining Step: 81  | total loss: [1m[32m0.68995[0m[0m | time: 25.703s
[2K
| RMSProp | epoch: 002 | loss: 0.68995 - acc: 0.5801 -- iter: 1120/1443
[A[ATraining Step: 82  | total loss: [1m[32m0.69049[0m[0m | time: 26.552s
[2K
| RMSProp | epoch: 002 | loss: 0.69049 - acc: 0.5690 -- iter: 1152/1443
[A[ATraining Step: 83  | total loss: [1m[32m0.69028[0m[0m | time: 27.548s
[2K
| RMSProp | epoch: 002 | loss: 0.69028 - acc: 0.5715 -- iter: 1184/1443
[A[ATraining Step: 84  | total loss: [1m[32m0.69059[0m[0m | time: 28.280s
[2K
| RMSProp | epoch: 002 | loss: 0.69059 - acc: 0.5643 -- iter: 1216/1443
[A[ATraining Step: 85  | total loss: [1m[32m0.69017[0m[0m | time: 29.007s
[2K
| RMSProp | epoch: 002 | loss: 0.69017 - acc: 0.5704 -- iter: 1248/1443
[A[ATraining Step: 86  | total loss: [1m[32m0.68943[0m[0m | time: 29.773s
[2K
| RMSProp | epoch: 002 | loss: 0.68943 - acc: 0.5821 -- iter: 1280/1443
[A[ATraining Step: 87  | total loss: [1m[32m0.68947[0m[0m | time: 30.550s
[2K
| RMSProp | epoch: 002 | loss: 0.68947 - acc: 0.5801 -- iter: 1312/1443
[A[ATraining Step: 88  | total loss: [1m[32m0.68967[0m[0m | time: 31.280s
[2K
| RMSProp | epoch: 002 | loss: 0.68967 - acc: 0.5753 -- iter: 1344/1443
[A[ATraining Step: 89  | total loss: [1m[32m0.68889[0m[0m | time: 32.054s
[2K
| RMSProp | epoch: 002 | loss: 0.68889 - acc: 0.5865 -- iter: 1376/1443
[A[ATraining Step: 90  | total loss: [1m[32m0.68899[0m[0m | time: 32.801s
[2K
| RMSProp | epoch: 002 | loss: 0.68899 - acc: 0.5841 -- iter: 1408/1443
[A[ATraining Step: 91  | total loss: [1m[32m0.68797[0m[0m | time: 33.581s
[2K
| RMSProp | epoch: 002 | loss: 0.68797 - acc: 0.5975 -- iter: 1440/1443
[A[ATraining Step: 92  | total loss: [1m[32m0.68808[0m[0m | time: 36.038s
[2K
| RMSProp | epoch: 002 | loss: 0.68808 - acc: 0.5940 | val_loss: 0.68556 - val_acc: 0.6018 -- iter: 1443/1443
--
Training Step: 93  | total loss: [1m[32m0.68699[0m[0m | time: 0.099s
[2K
| RMSProp | epoch: 003 | loss: 0.68699 - acc: 0.6065 -- iter: 0032/1443
[A[ATraining Step: 94  | total loss: [1m[32m0.68364[0m[0m | time: 0.195s
[2K
| RMSProp | epoch: 003 | loss: 0.68364 - acc: 0.6459 -- iter: 0064/1443
[A[ATraining Step: 95  | total loss: [1m[32m0.67999[0m[0m | time: 0.945s
[2K
| RMSProp | epoch: 003 | loss: 0.67999 - acc: 0.6813 -- iter: 0096/1443
[A[ATraining Step: 96  | total loss: [1m[32m0.68078[0m[0m | time: 1.669s
[2K
| RMSProp | epoch: 003 | loss: 0.68078 - acc: 0.6694 -- iter: 0128/1443
[A[ATraining Step: 97  | total loss: [1m[32m0.68147[0m[0m | time: 2.389s
[2K
| RMSProp | epoch: 003 | loss: 0.68147 - acc: 0.6587 -- iter: 0160/1443
[A[ATraining Step: 98  | total loss: [1m[32m0.68320[0m[0m | time: 3.155s
[2K
| RMSProp | epoch: 003 | loss: 0.68320 - acc: 0.6397 -- iter: 0192/1443
[A[ATraining Step: 99  | total loss: [1m[32m0.68090[0m[0m | time: 3.905s
[2K
| RMSProp | epoch: 003 | loss: 0.68090 - acc: 0.6570 -- iter: 0224/1443
[A[ATraining Step: 100  | total loss: [1m[32m0.68004[0m[0m | time: 4.630s
[2K
| RMSProp | epoch: 003 | loss: 0.68004 - acc: 0.6600 -- iter: 0256/1443
[A[ATraining Step: 101  | total loss: [1m[32m0.68072[0m[0m | time: 5.357s
[2K
| RMSProp | epoch: 003 | loss: 0.68072 - acc: 0.6503 -- iter: 0288/1443
[A[ATraining Step: 102  | total loss: [1m[32m0.68133[0m[0m | time: 6.069s
[2K
| RMSProp | epoch: 003 | loss: 0.68133 - acc: 0.6415 -- iter: 0320/1443
[A[ATraining Step: 103  | total loss: [1m[32m0.68064[0m[0m | time: 6.785s
[2K
| RMSProp | epoch: 003 | loss: 0.68064 - acc: 0.6430 -- iter: 0352/1443
[A[ATraining Step: 104  | total loss: [1m[32m0.68260[0m[0m | time: 7.531s
[2K
| RMSProp | epoch: 003 | loss: 0.68260 - acc: 0.6256 -- iter: 0384/1443
[A[ATraining Step: 105  | total loss: [1m[32m0.68005[0m[0m | time: 8.267s
[2K
| RMSProp | epoch: 003 | loss: 0.68005 - acc: 0.6411 -- iter: 0416/1443
[A[ATraining Step: 106  | total loss: [1m[32m0.67827[0m[0m | time: 9.016s
[2K
| RMSProp | epoch: 003 | loss: 0.67827 - acc: 0.6489 -- iter: 0448/1443
[A[ATraining Step: 107  | total loss: [1m[32m0.68068[0m[0m | time: 9.781s
[2K
| RMSProp | epoch: 003 | loss: 0.68068 - acc: 0.6309 -- iter: 0480/1443
[A[ATraining Step: 108  | total loss: [1m[32m0.68332[0m[0m | time: 10.494s
[2K
| RMSProp | epoch: 003 | loss: 0.68332 - acc: 0.6115 -- iter: 0512/1443
[A[ATraining Step: 109  | total loss: [1m[32m0.68364[0m[0m | time: 11.235s
[2K
| RMSProp | epoch: 003 | loss: 0.68364 - acc: 0.6066 -- iter: 0544/1443
[A[ATraining Step: 110  | total loss: [1m[32m0.68153[0m[0m | time: 11.952s
[2K
| RMSProp | epoch: 003 | loss: 0.68153 - acc: 0.6178 -- iter: 0576/1443
[A[ATraining Step: 111  | total loss: [1m[32m0.67764[0m[0m | time: 12.684s
[2K
| RMSProp | epoch: 003 | loss: 0.67764 - acc: 0.6373 -- iter: 0608/1443
[A[ATraining Step: 112  | total loss: [1m[32m0.67647[0m[0m | time: 13.424s
[2K
| RMSProp | epoch: 003 | loss: 0.67647 - acc: 0.6392 -- iter: 0640/1443
[A[ATraining Step: 113  | total loss: [1m[32m0.67658[0m[0m | time: 14.130s
[2K
| RMSProp | epoch: 003 | loss: 0.67658 - acc: 0.6347 -- iter: 0672/1443
[A[ATraining Step: 114  | total loss: [1m[32m0.67762[0m[0m | time: 14.870s
[2K
| RMSProp | epoch: 003 | loss: 0.67762 - acc: 0.6274 -- iter: 0704/1443
[A[ATraining Step: 115  | total loss: [1m[32m0.67530[0m[0m | time: 15.614s
[2K
| RMSProp | epoch: 003 | loss: 0.67530 - acc: 0.6334 -- iter: 0736/1443
[A[ATraining Step: 116  | total loss: [1m[32m0.67360[0m[0m | time: 16.335s
[2K
| RMSProp | epoch: 003 | loss: 0.67360 - acc: 0.6357 -- iter: 0768/1443
[A[ATraining Step: 117  | total loss: [1m[32m0.67372[0m[0m | time: 17.080s
[2K
| RMSProp | epoch: 003 | loss: 0.67372 - acc: 0.6315 -- iter: 0800/1443
[A[ATraining Step: 118  | total loss: [1m[32m0.67191[0m[0m | time: 17.876s
[2K
| RMSProp | epoch: 003 | loss: 0.67191 - acc: 0.6340 -- iter: 0832/1443
[A[ATraining Step: 119  | total loss: [1m[32m0.67629[0m[0m | time: 18.868s
[2K
| RMSProp | epoch: 003 | loss: 0.67629 - acc: 0.6206 -- iter: 0864/1443
[A[ATraining Step: 120  | total loss: [1m[32m0.67911[0m[0m | time: 19.621s
[2K
| RMSProp | epoch: 003 | loss: 0.67911 - acc: 0.6085 -- iter: 0896/1443
[A[ATraining Step: 121  | total loss: [1m[32m0.67977[0m[0m | time: 20.365s
[2K
| RMSProp | epoch: 003 | loss: 0.67977 - acc: 0.6039 -- iter: 0928/1443
[A[ATraining Step: 122  | total loss: [1m[32m0.67861[0m[0m | time: 21.093s
[2K
| RMSProp | epoch: 003 | loss: 0.67861 - acc: 0.6060 -- iter: 0960/1443
[A[ATraining Step: 123  | total loss: [1m[32m0.67551[0m[0m | time: 21.819s
[2K
| RMSProp | epoch: 003 | loss: 0.67551 - acc: 0.6142 -- iter: 0992/1443
[A[ATraining Step: 124  | total loss: [1m[32m0.67671[0m[0m | time: 22.564s
[2K
| RMSProp | epoch: 003 | loss: 0.67671 - acc: 0.6090 -- iter: 1024/1443
[A[ATraining Step: 125  | total loss: [1m[32m0.67546[0m[0m | time: 23.329s
[2K
| RMSProp | epoch: 003 | loss: 0.67546 - acc: 0.6106 -- iter: 1056/1443
[A[ATraining Step: 126  | total loss: [1m[32m0.68041[0m[0m | time: 24.095s
[2K
| RMSProp | epoch: 003 | loss: 0.68041 - acc: 0.5964 -- iter: 1088/1443
[A[ATraining Step: 127  | total loss: [1m[32m0.68019[0m[0m | time: 24.856s
[2K
| RMSProp | epoch: 003 | loss: 0.68019 - acc: 0.5962 -- iter: 1120/1443
[A[ATraining Step: 128  | total loss: [1m[32m0.68144[0m[0m | time: 25.573s
[2K
| RMSProp | epoch: 003 | loss: 0.68144 - acc: 0.5897 -- iter: 1152/1443
[A[ATraining Step: 129  | total loss: [1m[32m0.68026[0m[0m | time: 26.331s
[2K
| RMSProp | epoch: 003 | loss: 0.68026 - acc: 0.5932 -- iter: 1184/1443
[A[ATraining Step: 130  | total loss: [1m[32m0.68085[0m[0m | time: 27.073s
[2K
| RMSProp | epoch: 003 | loss: 0.68085 - acc: 0.5901 -- iter: 1216/1443
[A[ATraining Step: 131  | total loss: [1m[32m0.67955[0m[0m | time: 27.841s
[2K
| RMSProp | epoch: 003 | loss: 0.67955 - acc: 0.5936 -- iter: 1248/1443
[A[ATraining Step: 132  | total loss: [1m[32m0.68511[0m[0m | time: 28.605s
[2K
| RMSProp | epoch: 003 | loss: 0.68511 - acc: 0.5749 -- iter: 1280/1443
[A[ATraining Step: 133  | total loss: [1m[32m0.68454[0m[0m | time: 29.350s
[2K
| RMSProp | epoch: 003 | loss: 0.68454 - acc: 0.5768 -- iter: 1312/1443
[A[ATraining Step: 134  | total loss: [1m[32m0.68068[0m[0m | time: 30.092s
[2K
| RMSProp | epoch: 003 | loss: 0.68068 - acc: 0.5941 -- iter: 1344/1443
[A[ATraining Step: 135  | total loss: [1m[32m0.68019[0m[0m | time: 30.833s
[2K
| RMSProp | epoch: 003 | loss: 0.68019 - acc: 0.5941 -- iter: 1376/1443
[A[ATraining Step: 136  | total loss: [1m[32m0.67669[0m[0m | time: 31.554s
[2K
| RMSProp | epoch: 003 | loss: 0.67669 - acc: 0.6034 -- iter: 1408/1443
[A[ATraining Step: 137  | total loss: [1m[32m0.68203[0m[0m | time: 32.273s
[2K
| RMSProp | epoch: 003 | loss: 0.68203 - acc: 0.5899 -- iter: 1440/1443
[A[ATraining Step: 138  | total loss: [1m[32m0.68308[0m[0m | time: 35.225s
[2K
| RMSProp | epoch: 003 | loss: 0.68308 - acc: 0.5841 | val_loss: 0.67687 - val_acc: 0.6018 -- iter: 1443/1443
--
Training Step: 139  | total loss: [1m[32m0.68469[0m[0m | time: 0.756s
[2K
| RMSProp | epoch: 004 | loss: 0.68469 - acc: 0.5757 -- iter: 0032/1443
[A[ATraining Step: 140  | total loss: [1m[32m0.68275[0m[0m | time: 0.875s
[2K
| RMSProp | epoch: 004 | loss: 0.68275 - acc: 0.5837 -- iter: 0064/1443
[A[ATraining Step: 141  | total loss: [1m[32m0.67165[0m[0m | time: 1.018s
[2K
| RMSProp | epoch: 004 | loss: 0.67165 - acc: 0.6253 -- iter: 0096/1443
[A[ATraining Step: 142  | total loss: [1m[32m0.64854[0m[0m | time: 1.769s
[2K
| RMSProp | epoch: 004 | loss: 0.64854 - acc: 0.6628 -- iter: 0128/1443
[A[ATraining Step: 143  | total loss: [1m[32m0.68151[0m[0m | time: 2.550s
[2K
| RMSProp | epoch: 004 | loss: 0.68151 - acc: 0.6528 -- iter: 0160/1443
[A[ATraining Step: 144  | total loss: [1m[32m0.68521[0m[0m | time: 3.274s
[2K
| RMSProp | epoch: 004 | loss: 0.68521 - acc: 0.6375 -- iter: 0192/1443
[A[ATraining Step: 145  | total loss: [1m[32m0.68524[0m[0m | time: 4.024s
[2K
| RMSProp | epoch: 004 | loss: 0.68524 - acc: 0.6300 -- iter: 0224/1443
[A[ATraining Step: 146  | total loss: [1m[32m0.68654[0m[0m | time: 4.775s
[2K
| RMSProp | epoch: 004 | loss: 0.68654 - acc: 0.6201 -- iter: 0256/1443
[A[ATraining Step: 147  | total loss: [1m[32m0.68973[0m[0m | time: 5.509s
[2K
| RMSProp | epoch: 004 | loss: 0.68973 - acc: 0.6050 -- iter: 0288/1443
[A[ATraining Step: 148  | total loss: [1m[32m0.69019[0m[0m | time: 6.225s
[2K
| RMSProp | epoch: 004 | loss: 0.69019 - acc: 0.5976 -- iter: 0320/1443
[A[ATraining Step: 149  | total loss: [1m[32m0.68638[0m[0m | time: 6.977s
[2K
| RMSProp | epoch: 004 | loss: 0.68638 - acc: 0.6066 -- iter: 0352/1443
[A[ATraining Step: 150  | total loss: [1m[32m0.68943[0m[0m | time: 7.690s
[2K
| RMSProp | epoch: 004 | loss: 0.68943 - acc: 0.5928 -- iter: 0384/1443
[A[ATraining Step: 151  | total loss: [1m[32m0.69230[0m[0m | time: 8.407s
[2K
| RMSProp | epoch: 004 | loss: 0.69230 - acc: 0.5773 -- iter: 0416/1443
[A[ATraining Step: 152  | total loss: [1m[32m0.68959[0m[0m | time: 9.152s
[2K
| RMSProp | epoch: 004 | loss: 0.68959 - acc: 0.5852 -- iter: 0448/1443
[A[ATraining Step: 153  | total loss: [1m[32m0.69001[0m[0m | time: 9.895s
[2K
| RMSProp | epoch: 004 | loss: 0.69001 - acc: 0.5798 -- iter: 0480/1443
[A[ATraining Step: 154  | total loss: [1m[32m0.69329[0m[0m | time: 10.636s
[2K
| RMSProp | epoch: 004 | loss: 0.69329 - acc: 0.5624 -- iter: 0512/1443
[A[ATraining Step: 155  | total loss: [1m[32m0.68922[0m[0m | time: 11.547s
[2K
| RMSProp | epoch: 004 | loss: 0.68922 - acc: 0.5812 -- iter: 0544/1443
[A[ATraining Step: 156  | total loss: [1m[32m0.68559[0m[0m | time: 12.514s
[2K
| RMSProp | epoch: 004 | loss: 0.68559 - acc: 0.5918 -- iter: 0576/1443
[A[ATraining Step: 157  | total loss: [1m[32m0.68371[0m[0m | time: 13.193s
[2K
| RMSProp | epoch: 004 | loss: 0.68371 - acc: 0.5951 -- iter: 0608/1443
[A[ATraining Step: 158  | total loss: [1m[32m0.67655[0m[0m | time: 13.910s
[2K
| RMSProp | epoch: 004 | loss: 0.67655 - acc: 0.6138 -- iter: 0640/1443
[A[ATraining Step: 159  | total loss: [1m[32m0.67794[0m[0m | time: 14.655s
[2K
| RMSProp | epoch: 004 | loss: 0.67794 - acc: 0.6086 -- iter: 0672/1443
[A[ATraining Step: 160  | total loss: [1m[32m0.67906[0m[0m | time: 15.441s
[2K
| RMSProp | epoch: 004 | loss: 0.67906 - acc: 0.6040 -- iter: 0704/1443
[A[ATraining Step: 161  | total loss: [1m[32m0.68228[0m[0m | time: 16.151s
[2K
| RMSProp | epoch: 004 | loss: 0.68228 - acc: 0.5936 -- iter: 0736/1443
[A[ATraining Step: 162  | total loss: [1m[32m0.68534[0m[0m | time: 16.912s
[2K
| RMSProp | epoch: 004 | loss: 0.68534 - acc: 0.5811 -- iter: 0768/1443
[A[ATraining Step: 163  | total loss: [1m[32m0.68386[0m[0m | time: 17.723s
[2K
| RMSProp | epoch: 004 | loss: 0.68386 - acc: 0.5855 -- iter: 0800/1443
[A[ATraining Step: 164  | total loss: [1m[32m0.68323[0m[0m | time: 18.444s
[2K
| RMSProp | epoch: 004 | loss: 0.68323 - acc: 0.5863 -- iter: 0832/1443
[A[ATraining Step: 165  | total loss: [1m[32m0.68154[0m[0m | time: 19.207s
[2K
| RMSProp | epoch: 004 | loss: 0.68154 - acc: 0.5902 -- iter: 0864/1443
[A[ATraining Step: 166  | total loss: [1m[32m0.67997[0m[0m | time: 19.990s
[2K
| RMSProp | epoch: 004 | loss: 0.67997 - acc: 0.5937 -- iter: 0896/1443
[A[ATraining Step: 167  | total loss: [1m[32m0.68131[0m[0m | time: 20.762s
[2K
| RMSProp | epoch: 004 | loss: 0.68131 - acc: 0.5874 -- iter: 0928/1443
[A[ATraining Step: 168  | total loss: [1m[32m0.68091[0m[0m | time: 21.520s
[2K
| RMSProp | epoch: 004 | loss: 0.68091 - acc: 0.5881 -- iter: 0960/1443
[A[ATraining Step: 169  | total loss: [1m[32m0.68222[0m[0m | time: 22.273s
[2K
| RMSProp | epoch: 004 | loss: 0.68222 - acc: 0.5824 -- iter: 0992/1443
[A[ATraining Step: 170  | total loss: [1m[32m0.68341[0m[0m | time: 23.032s
[2K
| RMSProp | epoch: 004 | loss: 0.68341 - acc: 0.5773 -- iter: 1024/1443
[A[ATraining Step: 171  | total loss: [1m[32m0.68500[0m[0m | time: 23.784s
[2K
| RMSProp | epoch: 004 | loss: 0.68500 - acc: 0.5695 -- iter: 1056/1443
[A[ATraining Step: 172  | total loss: [1m[32m0.68429[0m[0m | time: 24.543s
[2K
| RMSProp | epoch: 004 | loss: 0.68429 - acc: 0.5720 -- iter: 1088/1443
[A[ATraining Step: 173  | total loss: [1m[32m0.68291[0m[0m | time: 25.290s
[2K
| RMSProp | epoch: 004 | loss: 0.68291 - acc: 0.5773 -- iter: 1120/1443
[A[ATraining Step: 174  | total loss: [1m[32m0.68041[0m[0m | time: 26.072s
[2K
| RMSProp | epoch: 004 | loss: 0.68041 - acc: 0.5852 -- iter: 1152/1443
[A[ATraining Step: 175  | total loss: [1m[32m0.68452[0m[0m | time: 26.799s
[2K
| RMSProp | epoch: 004 | loss: 0.68452 - acc: 0.5735 -- iter: 1184/1443
[A[ATraining Step: 176  | total loss: [1m[32m0.68305[0m[0m | time: 27.525s
[2K
| RMSProp | epoch: 004 | loss: 0.68305 - acc: 0.5787 -- iter: 1216/1443
[A[ATraining Step: 177  | total loss: [1m[32m0.68592[0m[0m | time: 28.275s
[2K
| RMSProp | epoch: 004 | loss: 0.68592 - acc: 0.5677 -- iter: 1248/1443
[A[ATraining Step: 178  | total loss: [1m[32m0.68439[0m[0m | time: 28.996s
[2K
| RMSProp | epoch: 004 | loss: 0.68439 - acc: 0.5734 -- iter: 1280/1443
[A[ATraining Step: 179  | total loss: [1m[32m0.67732[0m[0m | time: 29.732s
[2K
| RMSProp | epoch: 004 | loss: 0.67732 - acc: 0.6004 -- iter: 1312/1443
[A[ATraining Step: 180  | total loss: [1m[32m0.67582[0m[0m | time: 30.448s
[2K
| RMSProp | epoch: 004 | loss: 0.67582 - acc: 0.6029 -- iter: 1344/1443
[A[ATraining Step: 181  | total loss: [1m[32m0.67593[0m[0m | time: 31.187s
[2K
| RMSProp | epoch: 004 | loss: 0.67593 - acc: 0.6020 -- iter: 1376/1443
[A[ATraining Step: 182  | total loss: [1m[32m0.67439[0m[0m | time: 31.953s
[2K
| RMSProp | epoch: 004 | loss: 0.67439 - acc: 0.6043 -- iter: 1408/1443
[A[ATraining Step: 183  | total loss: [1m[32m0.67603[0m[0m | time: 32.686s
[2K
| RMSProp | epoch: 004 | loss: 0.67603 - acc: 0.6001 -- iter: 1440/1443
[A[ATraining Step: 184  | total loss: [1m[32m0.67379[0m[0m | time: 35.197s
[2K
| RMSProp | epoch: 004 | loss: 0.67379 - acc: 0.6057 | val_loss: 0.67089 - val_acc: 0.6018 -- iter: 1443/1443
--
Training Step: 185  | total loss: [1m[32m0.67392[0m[0m | time: 0.761s
[2K
| RMSProp | epoch: 005 | loss: 0.67392 - acc: 0.6045 -- iter: 0032/1443
[A[ATraining Step: 186  | total loss: [1m[32m0.67273[0m[0m | time: 1.498s
[2K
| RMSProp | epoch: 005 | loss: 0.67273 - acc: 0.6066 -- iter: 0064/1443
[A[ATraining Step: 187  | total loss: [1m[32m0.67271[0m[0m | time: 1.608s
[2K
| RMSProp | epoch: 005 | loss: 0.67271 - acc: 0.6053 -- iter: 0096/1443
[A[ATraining Step: 188  | total loss: [1m[32m0.66909[0m[0m | time: 1.694s
[2K
| RMSProp | epoch: 005 | loss: 0.66909 - acc: 0.6114 -- iter: 0128/1443
[A[ATraining Step: 189  | total loss: [1m[32m0.66535[0m[0m | time: 2.419s
[2K
| RMSProp | epoch: 005 | loss: 0.66535 - acc: 0.6170 -- iter: 0160/1443
[A[ATraining Step: 190  | total loss: [1m[32m0.65373[0m[0m | time: 3.154s
[2K
| RMSProp | epoch: 005 | loss: 0.65373 - acc: 0.6334 -- iter: 0192/1443
[A[ATraining Step: 191  | total loss: [1m[32m0.68167[0m[0m | time: 4.104s
[2K
| RMSProp | epoch: 005 | loss: 0.68167 - acc: 0.6294 -- iter: 0224/1443
[A[ATraining Step: 192  | total loss: [1m[32m0.68734[0m[0m | time: 5.017s
[2K
| RMSProp | epoch: 005 | loss: 0.68734 - acc: 0.6102 -- iter: 0256/1443
[A[ATraining Step: 193  | total loss: [1m[32m0.68984[0m[0m | time: 5.787s
[2K
| RMSProp | epoch: 005 | loss: 0.68984 - acc: 0.5961 -- iter: 0288/1443
[A[ATraining Step: 194  | total loss: [1m[32m0.69066[0m[0m | time: 6.538s
[2K
| RMSProp | epoch: 005 | loss: 0.69066 - acc: 0.5865 -- iter: 0320/1443
[A[ATraining Step: 195  | total loss: [1m[32m0.68885[0m[0m | time: 7.269s
[2K
| RMSProp | epoch: 005 | loss: 0.68885 - acc: 0.5903 -- iter: 0352/1443
[A[ATraining Step: 196  | total loss: [1m[32m0.68814[0m[0m | time: 8.005s
[2K
| RMSProp | epoch: 005 | loss: 0.68814 - acc: 0.5875 -- iter: 0384/1443
[A[ATraining Step: 197  | total loss: [1m[32m0.68851[0m[0m | time: 8.754s
[2K
| RMSProp | epoch: 005 | loss: 0.68851 - acc: 0.5819 -- iter: 0416/1443
[A[ATraining Step: 198  | total loss: [1m[32m0.69116[0m[0m | time: 9.532s
[2K
| RMSProp | epoch: 005 | loss: 0.69116 - acc: 0.5675 -- iter: 0448/1443
[A[ATraining Step: 199  | total loss: [1m[32m0.69249[0m[0m | time: 10.263s
[2K
| RMSProp | epoch: 005 | loss: 0.69249 - acc: 0.5545 -- iter: 0480/1443
[A[ATraining Step: 200  | total loss: [1m[32m0.69157[0m[0m | time: 12.746s
[2K
| RMSProp | epoch: 005 | loss: 0.69157 - acc: 0.5584 | val_loss: 0.67328 - val_acc: 0.6018 -- iter: 0512/1443
--
Training Step: 201  | total loss: [1m[32m0.68935[0m[0m | time: 13.482s
[2K
| RMSProp | epoch: 005 | loss: 0.68935 - acc: 0.5682 -- iter: 0544/1443
[A[ATraining Step: 202  | total loss: [1m[32m0.68981[0m[0m | time: 14.231s
[2K
| RMSProp | epoch: 005 | loss: 0.68981 - acc: 0.5645 -- iter: 0576/1443
[A[ATraining Step: 203  | total loss: [1m[32m0.68704[0m[0m | time: 14.961s
[2K
| RMSProp | epoch: 005 | loss: 0.68704 - acc: 0.5737 -- iter: 0608/1443
[A[ATraining Step: 204  | total loss: [1m[32m0.68547[0m[0m | time: 15.720s
[2K
| RMSProp | epoch: 005 | loss: 0.68547 - acc: 0.5757 -- iter: 0640/1443
[A[ATraining Step: 205  | total loss: [1m[32m0.69206[0m[0m | time: 16.471s
[2K
| RMSProp | epoch: 005 | loss: 0.69206 - acc: 0.5556 -- iter: 0672/1443
[A[ATraining Step: 206  | total loss: [1m[32m0.69242[0m[0m | time: 17.227s
[2K
| RMSProp | epoch: 005 | loss: 0.69242 - acc: 0.5500 -- iter: 0704/1443
[A[ATraining Step: 207  | total loss: [1m[32m0.69113[0m[0m | time: 17.980s
[2K
| RMSProp | epoch: 005 | loss: 0.69113 - acc: 0.5544 -- iter: 0736/1443
[A[ATraining Step: 208  | total loss: [1m[32m0.68906[0m[0m | time: 18.732s
[2K
| RMSProp | epoch: 005 | loss: 0.68906 - acc: 0.5615 -- iter: 0768/1443
[A[ATraining Step: 209  | total loss: [1m[32m0.68987[0m[0m | time: 19.481s
[2K
| RMSProp | epoch: 005 | loss: 0.68987 - acc: 0.5553 -- iter: 0800/1443
[A[ATraining Step: 210  | total loss: [1m[32m0.68974[0m[0m | time: 20.201s
[2K
| RMSProp | epoch: 005 | loss: 0.68974 - acc: 0.5529 -- iter: 0832/1443
[A[ATraining Step: 211  | total loss: [1m[32m0.68910[0m[0m | time: 20.914s
[2K
| RMSProp | epoch: 005 | loss: 0.68910 - acc: 0.5539 -- iter: 0864/1443
[A[ATraining Step: 212  | total loss: [1m[32m0.68592[0m[0m | time: 21.644s
[2K
| RMSProp | epoch: 005 | loss: 0.68592 - acc: 0.5672 -- iter: 0896/1443
[A[ATraining Step: 213  | total loss: [1m[32m0.68332[0m[0m | time: 22.391s
[2K
| RMSProp | epoch: 005 | loss: 0.68332 - acc: 0.5730 -- iter: 0928/1443
[A[ATraining Step: 214  | total loss: [1m[32m0.68327[0m[0m | time: 23.118s
[2K
| RMSProp | epoch: 005 | loss: 0.68327 - acc: 0.5720 -- iter: 0960/1443
[A[ATraining Step: 215  | total loss: [1m[32m0.68278[0m[0m | time: 23.847s
[2K
| RMSProp | epoch: 005 | loss: 0.68278 - acc: 0.5710 -- iter: 0992/1443
[A[ATraining Step: 216  | total loss: [1m[32m0.68486[0m[0m | time: 24.592s
[2K
| RMSProp | epoch: 005 | loss: 0.68486 - acc: 0.5639 -- iter: 1024/1443
[A[ATraining Step: 217  | total loss: [1m[32m0.68182[0m[0m | time: 25.312s
[2K
| RMSProp | epoch: 005 | loss: 0.68182 - acc: 0.5763 -- iter: 1056/1443
[A[ATraining Step: 218  | total loss: [1m[32m0.67846[0m[0m | time: 26.038s
[2K
| RMSProp | epoch: 005 | loss: 0.67846 - acc: 0.5843 -- iter: 1088/1443
[A[ATraining Step: 219  | total loss: [1m[32m0.67700[0m[0m | time: 26.786s
[2K
| RMSProp | epoch: 005 | loss: 0.67700 - acc: 0.5852 -- iter: 1120/1443
[A[ATraining Step: 220  | total loss: [1m[32m0.67778[0m[0m | time: 27.517s
[2K
| RMSProp | epoch: 005 | loss: 0.67778 - acc: 0.5829 -- iter: 1152/1443
[A[ATraining Step: 221  | total loss: [1m[32m0.67933[0m[0m | time: 28.264s
[2K
| RMSProp | epoch: 005 | loss: 0.67933 - acc: 0.5778 -- iter: 1184/1443
[A[ATraining Step: 222  | total loss: [1m[32m0.67793[0m[0m | time: 28.983s
[2K
| RMSProp | epoch: 005 | loss: 0.67793 - acc: 0.5856 -- iter: 1216/1443
[A[ATraining Step: 223  | total loss: [1m[32m0.68231[0m[0m | time: 29.727s
[2K
| RMSProp | epoch: 005 | loss: 0.68231 - acc: 0.5739 -- iter: 1248/1443
[A[ATraining Step: 224  | total loss: [1m[32m0.67976[0m[0m | time: 30.507s
[2K
| RMSProp | epoch: 005 | loss: 0.67976 - acc: 0.5853 -- iter: 1280/1443
[A[ATraining Step: 225  | total loss: [1m[32m0.68331[0m[0m | time: 31.362s
[2K
| RMSProp | epoch: 005 | loss: 0.68331 - acc: 0.5705 -- iter: 1312/1443
[A[ATraining Step: 226  | total loss: [1m[32m0.68190[0m[0m | time: 32.418s
[2K
| RMSProp | epoch: 005 | loss: 0.68190 - acc: 0.5728 -- iter: 1344/1443
[A[ATraining Step: 227  | total loss: [1m[32m0.68146[0m[0m | time: 33.158s
[2K
| RMSProp | epoch: 005 | loss: 0.68146 - acc: 0.5718 -- iter: 1376/1443
[A[ATraining Step: 228  | total loss: [1m[32m0.67693[0m[0m | time: 33.911s
[2K
| RMSProp | epoch: 005 | loss: 0.67693 - acc: 0.5834 -- iter: 1408/1443
[A[ATraining Step: 229  | total loss: [1m[32m0.67421[0m[0m | time: 34.631s
[2K
| RMSProp | epoch: 005 | loss: 0.67421 - acc: 0.5875 -- iter: 1440/1443
[A[ATraining Step: 230  | total loss: [1m[32m0.66834[0m[0m | time: 37.149s
[2K
| RMSProp | epoch: 005 | loss: 0.66834 - acc: 0.5975 | val_loss: 0.86793 - val_acc: 0.6018 -- iter: 1443/1443
--
Training Step: 231  | total loss: [1m[32m0.65463[0m[0m | time: 0.792s
[2K
| RMSProp | epoch: 006 | loss: 0.65463 - acc: 0.6159 -- iter: 0032/1443
[A[ATraining Step: 232  | total loss: [1m[32m0.69293[0m[0m | time: 1.502s
[2K
| RMSProp | epoch: 006 | loss: 0.69293 - acc: 0.6043 -- iter: 0064/1443
[A[ATraining Step: 233  | total loss: [1m[32m0.69435[0m[0m | time: 2.260s
[2K
| RMSProp | epoch: 006 | loss: 0.69435 - acc: 0.5939 -- iter: 0096/1443
[A[ATraining Step: 234  | total loss: [1m[32m0.69003[0m[0m | time: 2.362s
[2K
| RMSProp | epoch: 006 | loss: 0.69003 - acc: 0.6001 -- iter: 0128/1443
[A[ATraining Step: 235  | total loss: [1m[32m0.69743[0m[0m | time: 2.460s
[2K
| RMSProp | epoch: 006 | loss: 0.69743 - acc: 0.5734 -- iter: 0160/1443
[A[ATraining Step: 236  | total loss: [1m[32m0.69988[0m[0m | time: 3.239s
[2K
| RMSProp | epoch: 006 | loss: 0.69988 - acc: 0.5494 -- iter: 0192/1443
[A[ATraining Step: 237  | total loss: [1m[32m0.69892[0m[0m | time: 4.002s
[2K
| RMSProp | epoch: 006 | loss: 0.69892 - acc: 0.5445 -- iter: 0224/1443
[A[ATraining Step: 238  | total loss: [1m[32m0.69504[0m[0m | time: 4.748s
[2K
| RMSProp | epoch: 006 | loss: 0.69504 - acc: 0.5525 -- iter: 0256/1443
[A[ATraining Step: 239  | total loss: [1m[32m0.69135[0m[0m | time: 5.507s
[2K
| RMSProp | epoch: 006 | loss: 0.69135 - acc: 0.5567 -- iter: 0288/1443
[A[ATraining Step: 240  | total loss: [1m[32m0.68853[0m[0m | time: 6.236s
[2K
| RMSProp | epoch: 006 | loss: 0.68853 - acc: 0.5572 -- iter: 0320/1443
[A[ATraining Step: 241  | total loss: [1m[32m0.68587[0m[0m | time: 7.007s
[2K
| RMSProp | epoch: 006 | loss: 0.68587 - acc: 0.5609 -- iter: 0352/1443
[A[ATraining Step: 242  | total loss: [1m[32m0.68948[0m[0m | time: 7.767s
[2K
| RMSProp | epoch: 006 | loss: 0.68948 - acc: 0.5517 -- iter: 0384/1443
[A[ATraining Step: 243  | total loss: [1m[32m0.68568[0m[0m | time: 8.516s
[2K
| RMSProp | epoch: 006 | loss: 0.68568 - acc: 0.5559 -- iter: 0416/1443
[A[ATraining Step: 244  | total loss: [1m[32m0.68489[0m[0m | time: 9.269s
[2K
| RMSProp | epoch: 006 | loss: 0.68489 - acc: 0.5565 -- iter: 0448/1443
[A[ATraining Step: 245  | total loss: [1m[32m0.68367[0m[0m | time: 10.031s
[2K
| RMSProp | epoch: 006 | loss: 0.68367 - acc: 0.5571 -- iter: 0480/1443
[A[ATraining Step: 246  | total loss: [1m[32m0.68141[0m[0m | time: 10.762s
[2K
| RMSProp | epoch: 006 | loss: 0.68141 - acc: 0.5671 -- iter: 0512/1443
[A[ATraining Step: 247  | total loss: [1m[32m0.67201[0m[0m | time: 11.514s
[2K
| RMSProp | epoch: 006 | loss: 0.67201 - acc: 0.5853 -- iter: 0544/1443
[A[ATraining Step: 248  | total loss: [1m[32m0.66928[0m[0m | time: 12.264s
[2K
| RMSProp | epoch: 006 | loss: 0.66928 - acc: 0.5893 -- iter: 0576/1443
[A[ATraining Step: 249  | total loss: [1m[32m0.66908[0m[0m | time: 12.984s
[2K
| RMSProp | epoch: 006 | loss: 0.66908 - acc: 0.5898 -- iter: 0608/1443
[A[ATraining Step: 250  | total loss: [1m[32m0.66576[0m[0m | time: 13.728s
[2K
| RMSProp | epoch: 006 | loss: 0.66576 - acc: 0.5995 -- iter: 0640/1443
[A[ATraining Step: 251  | total loss: [1m[32m0.66519[0m[0m | time: 14.468s
[2K
| RMSProp | epoch: 006 | loss: 0.66519 - acc: 0.5990 -- iter: 0672/1443
[A[ATraining Step: 252  | total loss: [1m[32m0.66272[0m[0m | time: 15.217s
[2K
| RMSProp | epoch: 006 | loss: 0.66272 - acc: 0.6047 -- iter: 0704/1443
[A[ATraining Step: 253  | total loss: [1m[32m0.65771[0m[0m | time: 15.940s
[2K
| RMSProp | epoch: 006 | loss: 0.65771 - acc: 0.6130 -- iter: 0736/1443
[A[ATraining Step: 254  | total loss: [1m[32m0.66300[0m[0m | time: 16.665s
[2K
| RMSProp | epoch: 006 | loss: 0.66300 - acc: 0.6017 -- iter: 0768/1443
[A[ATraining Step: 255  | total loss: [1m[32m0.66314[0m[0m | time: 17.381s
[2K
| RMSProp | epoch: 006 | loss: 0.66314 - acc: 0.6009 -- iter: 0800/1443
[A[ATraining Step: 256  | total loss: [1m[32m0.66354[0m[0m | time: 18.087s
[2K
| RMSProp | epoch: 006 | loss: 0.66354 - acc: 0.6033 -- iter: 0832/1443
[A[ATraining Step: 257  | total loss: [1m[32m0.67435[0m[0m | time: 18.816s
[2K
| RMSProp | epoch: 006 | loss: 0.67435 - acc: 0.5805 -- iter: 0864/1443
[A[ATraining Step: 258  | total loss: [1m[32m0.67456[0m[0m | time: 19.539s
[2K
| RMSProp | epoch: 006 | loss: 0.67456 - acc: 0.5818 -- iter: 0896/1443
[A[ATraining Step: 259  | total loss: [1m[32m0.67065[0m[0m | time: 20.294s
[2K
| RMSProp | epoch: 006 | loss: 0.67065 - acc: 0.6017 -- iter: 0928/1443
[A[ATraining Step: 260  | total loss: [1m[32m0.67186[0m[0m | time: 21.005s
[2K
| RMSProp | epoch: 006 | loss: 0.67186 - acc: 0.5978 -- iter: 0960/1443
[A[ATraining Step: 261  | total loss: [1m[32m0.66946[0m[0m | time: 21.833s
[2K
| RMSProp | epoch: 006 | loss: 0.66946 - acc: 0.6005 -- iter: 0992/1443
[A[ATraining Step: 262  | total loss: [1m[32m0.66492[0m[0m | time: 22.817s
[2K
| RMSProp | epoch: 006 | loss: 0.66492 - acc: 0.6061 -- iter: 1024/1443
[A[ATraining Step: 263  | total loss: [1m[32m0.66495[0m[0m | time: 23.532s
[2K
| RMSProp | epoch: 006 | loss: 0.66495 - acc: 0.6017 -- iter: 1056/1443
[A[ATraining Step: 264  | total loss: [1m[32m0.65867[0m[0m | time: 24.302s
[2K
| RMSProp | epoch: 006 | loss: 0.65867 - acc: 0.6103 -- iter: 1088/1443
[A[ATraining Step: 265  | total loss: [1m[32m0.64764[0m[0m | time: 25.023s
[2K
| RMSProp | epoch: 006 | loss: 0.64764 - acc: 0.6305 -- iter: 1120/1443
[A[ATraining Step: 266  | total loss: [1m[32m0.64646[0m[0m | time: 25.767s
[2K
| RMSProp | epoch: 006 | loss: 0.64646 - acc: 0.6269 -- iter: 1152/1443
[A[ATraining Step: 267  | total loss: [1m[32m0.64602[0m[0m | time: 26.484s
[2K
| RMSProp | epoch: 006 | loss: 0.64602 - acc: 0.6360 -- iter: 1184/1443
[A[ATraining Step: 268  | total loss: [1m[32m0.64811[0m[0m | time: 27.243s
[2K
| RMSProp | epoch: 006 | loss: 0.64811 - acc: 0.6318 -- iter: 1216/1443
[A[ATraining Step: 269  | total loss: [1m[32m0.64740[0m[0m | time: 27.972s
[2K
| RMSProp | epoch: 006 | loss: 0.64740 - acc: 0.6405 -- iter: 1248/1443
[A[ATraining Step: 270  | total loss: [1m[32m0.64662[0m[0m | time: 28.708s
[2K
| RMSProp | epoch: 006 | loss: 0.64662 - acc: 0.6390 -- iter: 1280/1443
[A[ATraining Step: 271  | total loss: [1m[32m0.64428[0m[0m | time: 29.467s
[2K
| RMSProp | epoch: 006 | loss: 0.64428 - acc: 0.6376 -- iter: 1312/1443
[A[ATraining Step: 272  | total loss: [1m[32m0.63400[0m[0m | time: 30.241s
[2K
| RMSProp | epoch: 006 | loss: 0.63400 - acc: 0.6519 -- iter: 1344/1443
[A[ATraining Step: 273  | total loss: [1m[32m0.63070[0m[0m | time: 31.045s
[2K
| RMSProp | epoch: 006 | loss: 0.63070 - acc: 0.6524 -- iter: 1376/1443
[A[ATraining Step: 274  | total loss: [1m[32m0.62388[0m[0m | time: 31.761s
[2K
| RMSProp | epoch: 006 | loss: 0.62388 - acc: 0.6590 -- iter: 1408/1443
[A[ATraining Step: 275  | total loss: [1m[32m0.61967[0m[0m | time: 32.511s
[2K
| RMSProp | epoch: 006 | loss: 0.61967 - acc: 0.6650 -- iter: 1440/1443
[A[ATraining Step: 276  | total loss: [1m[32m0.63037[0m[0m | time: 34.954s
[2K
| RMSProp | epoch: 006 | loss: 0.63037 - acc: 0.6579 | val_loss: 0.63603 - val_acc: 0.6593 -- iter: 1443/1443
--
Training Step: 277  | total loss: [1m[32m0.63408[0m[0m | time: 0.772s
[2K
| RMSProp | epoch: 007 | loss: 0.63408 - acc: 0.6514 -- iter: 0032/1443
[A[ATraining Step: 278  | total loss: [1m[32m0.63099[0m[0m | time: 1.509s
[2K
| RMSProp | epoch: 007 | loss: 0.63099 - acc: 0.6613 -- iter: 0064/1443
[A[ATraining Step: 279  | total loss: [1m[32m0.63369[0m[0m | time: 2.232s
[2K
| RMSProp | epoch: 007 | loss: 0.63369 - acc: 0.6545 -- iter: 0096/1443
[A[ATraining Step: 280  | total loss: [1m[32m0.62777[0m[0m | time: 2.992s
[2K
| RMSProp | epoch: 007 | loss: 0.62777 - acc: 0.6610 -- iter: 0128/1443
[A[ATraining Step: 281  | total loss: [1m[32m0.63719[0m[0m | time: 3.093s
[2K
| RMSProp | epoch: 007 | loss: 0.63719 - acc: 0.6574 -- iter: 0160/1443
[A[ATraining Step: 282  | total loss: [1m[32m0.63159[0m[0m | time: 3.242s
[2K
| RMSProp | epoch: 007 | loss: 0.63159 - acc: 0.6916 -- iter: 0192/1443
[A[ATraining Step: 283  | total loss: [1m[32m0.62179[0m[0m | time: 3.987s
[2K
| RMSProp | epoch: 007 | loss: 0.62179 - acc: 0.6891 -- iter: 0224/1443
[A[ATraining Step: 284  | total loss: [1m[32m0.61533[0m[0m | time: 4.756s
[2K
| RMSProp | epoch: 007 | loss: 0.61533 - acc: 0.6921 -- iter: 0256/1443
[A[ATraining Step: 285  | total loss: [1m[32m0.62982[0m[0m | time: 5.572s
[2K
| RMSProp | epoch: 007 | loss: 0.62982 - acc: 0.6791 -- iter: 0288/1443
[A[ATraining Step: 286  | total loss: [1m[32m0.63729[0m[0m | time: 6.296s
[2K
| RMSProp | epoch: 007 | loss: 0.63729 - acc: 0.6675 -- iter: 0320/1443
[A[ATraining Step: 287  | total loss: [1m[32m0.63625[0m[0m | time: 7.056s
[2K
| RMSProp | epoch: 007 | loss: 0.63625 - acc: 0.6695 -- iter: 0352/1443
[A[ATraining Step: 288  | total loss: [1m[32m0.63657[0m[0m | time: 7.899s
[2K
| RMSProp | epoch: 007 | loss: 0.63657 - acc: 0.6775 -- iter: 0384/1443
[A[ATraining Step: 289  | total loss: [1m[32m0.63680[0m[0m | time: 8.641s
[2K
| RMSProp | epoch: 007 | loss: 0.63680 - acc: 0.6754 -- iter: 0416/1443
[A[ATraining Step: 290  | total loss: [1m[32m0.62637[0m[0m | time: 9.423s
[2K
| RMSProp | epoch: 007 | loss: 0.62637 - acc: 0.6922 -- iter: 0448/1443
[A[ATraining Step: 291  | total loss: [1m[32m0.62546[0m[0m | time: 10.139s
[2K
| RMSProp | epoch: 007 | loss: 0.62546 - acc: 0.6886 -- iter: 0480/1443
[A[ATraining Step: 292  | total loss: [1m[32m0.62698[0m[0m | time: 10.928s
[2K
| RMSProp | epoch: 007 | loss: 0.62698 - acc: 0.6854 -- iter: 0512/1443
[A[ATraining Step: 293  | total loss: [1m[32m0.65103[0m[0m | time: 11.690s
[2K
| RMSProp | epoch: 007 | loss: 0.65103 - acc: 0.6606 -- iter: 0544/1443
[A[ATraining Step: 294  | total loss: [1m[32m0.64135[0m[0m | time: 12.415s
[2K
| RMSProp | epoch: 007 | loss: 0.64135 - acc: 0.6695 -- iter: 0576/1443
[A[ATraining Step: 295  | total loss: [1m[32m0.63615[0m[0m | time: 13.140s
[2K
| RMSProp | epoch: 007 | loss: 0.63615 - acc: 0.6682 -- iter: 0608/1443
[A[ATraining Step: 296  | total loss: [1m[32m0.64272[0m[0m | time: 14.023s
[2K
| RMSProp | epoch: 007 | loss: 0.64272 - acc: 0.6639 -- iter: 0640/1443
[A[ATraining Step: 297  | total loss: [1m[32m0.64846[0m[0m | time: 15.025s
[2K
| RMSProp | epoch: 007 | loss: 0.64846 - acc: 0.6475 -- iter: 0672/1443
[A[ATraining Step: 298  | total loss: [1m[32m0.63826[0m[0m | time: 15.759s
[2K
| RMSProp | epoch: 007 | loss: 0.63826 - acc: 0.6703 -- iter: 0704/1443
[A[ATraining Step: 299  | total loss: [1m[32m0.63180[0m[0m | time: 16.488s
[2K
| RMSProp | epoch: 007 | loss: 0.63180 - acc: 0.6782 -- iter: 0736/1443
[A[ATraining Step: 300  | total loss: [1m[32m0.61717[0m[0m | time: 17.222s
[2K
| RMSProp | epoch: 007 | loss: 0.61717 - acc: 0.6948 -- iter: 0768/1443
[A[ATraining Step: 301  | total loss: [1m[32m0.63088[0m[0m | time: 17.962s
[2K
| RMSProp | epoch: 007 | loss: 0.63088 - acc: 0.6847 -- iter: 0800/1443
[A[ATraining Step: 302  | total loss: [1m[32m0.63230[0m[0m | time: 18.715s
[2K
| RMSProp | epoch: 007 | loss: 0.63230 - acc: 0.6818 -- iter: 0832/1443
[A[ATraining Step: 303  | total loss: [1m[32m0.63542[0m[0m | time: 19.444s
[2K
| RMSProp | epoch: 007 | loss: 0.63542 - acc: 0.6793 -- iter: 0864/1443
[A[ATraining Step: 304  | total loss: [1m[32m0.62992[0m[0m | time: 20.190s
[2K
| RMSProp | epoch: 007 | loss: 0.62992 - acc: 0.6832 -- iter: 0896/1443
[A[ATraining Step: 305  | total loss: [1m[32m0.62365[0m[0m | time: 20.925s
[2K
| RMSProp | epoch: 007 | loss: 0.62365 - acc: 0.6868 -- iter: 0928/1443
[A[ATraining Step: 306  | total loss: [1m[32m0.61658[0m[0m | time: 21.692s
[2K
| RMSProp | epoch: 007 | loss: 0.61658 - acc: 0.6931 -- iter: 0960/1443
[A[ATraining Step: 307  | total loss: [1m[32m0.61936[0m[0m | time: 22.392s
[2K
| RMSProp | epoch: 007 | loss: 0.61936 - acc: 0.6894 -- iter: 0992/1443
[A[ATraining Step: 308  | total loss: [1m[32m0.61974[0m[0m | time: 23.100s
[2K
| RMSProp | epoch: 007 | loss: 0.61974 - acc: 0.6892 -- iter: 1024/1443
[A[ATraining Step: 309  | total loss: [1m[32m0.61988[0m[0m | time: 23.859s
[2K
| RMSProp | epoch: 007 | loss: 0.61988 - acc: 0.6891 -- iter: 1056/1443
[A[ATraining Step: 310  | total loss: [1m[32m0.60842[0m[0m | time: 24.615s
[2K
| RMSProp | epoch: 007 | loss: 0.60842 - acc: 0.6983 -- iter: 1088/1443
[A[ATraining Step: 311  | total loss: [1m[32m0.62045[0m[0m | time: 25.343s
[2K
| RMSProp | epoch: 007 | loss: 0.62045 - acc: 0.6784 -- iter: 1120/1443
[A[ATraining Step: 312  | total loss: [1m[32m0.61859[0m[0m | time: 26.060s
[2K
| RMSProp | epoch: 007 | loss: 0.61859 - acc: 0.6825 -- iter: 1152/1443
[A[ATraining Step: 313  | total loss: [1m[32m0.62594[0m[0m | time: 26.813s
[2K
| RMSProp | epoch: 007 | loss: 0.62594 - acc: 0.6674 -- iter: 1184/1443
[A[ATraining Step: 314  | total loss: [1m[32m0.62860[0m[0m | time: 27.557s
[2K
| RMSProp | epoch: 007 | loss: 0.62860 - acc: 0.6631 -- iter: 1216/1443
[A[ATraining Step: 315  | total loss: [1m[32m0.63196[0m[0m | time: 28.277s
[2K
| RMSProp | epoch: 007 | loss: 0.63196 - acc: 0.6593 -- iter: 1248/1443
[A[ATraining Step: 316  | total loss: [1m[32m0.62515[0m[0m | time: 29.011s
[2K
| RMSProp | epoch: 007 | loss: 0.62515 - acc: 0.6652 -- iter: 1280/1443
[A[ATraining Step: 317  | total loss: [1m[32m0.61528[0m[0m | time: 29.748s
[2K
| RMSProp | epoch: 007 | loss: 0.61528 - acc: 0.6706 -- iter: 1312/1443
[A[ATraining Step: 318  | total loss: [1m[32m0.61338[0m[0m | time: 30.503s
[2K
| RMSProp | epoch: 007 | loss: 0.61338 - acc: 0.6692 -- iter: 1344/1443
[A[ATraining Step: 319  | total loss: [1m[32m0.61565[0m[0m | time: 31.241s
[2K
| RMSProp | epoch: 007 | loss: 0.61565 - acc: 0.6710 -- iter: 1376/1443
[A[ATraining Step: 320  | total loss: [1m[32m0.61319[0m[0m | time: 31.966s
[2K
| RMSProp | epoch: 007 | loss: 0.61319 - acc: 0.6726 -- iter: 1408/1443
[A[ATraining Step: 321  | total loss: [1m[32m0.60769[0m[0m | time: 32.696s
[2K
| RMSProp | epoch: 007 | loss: 0.60769 - acc: 0.6773 -- iter: 1440/1443
[A[ATraining Step: 322  | total loss: [1m[32m0.62542[0m[0m | time: 35.126s
[2K
| RMSProp | epoch: 007 | loss: 0.62542 - acc: 0.6689 | val_loss: 0.62288 - val_acc: 0.6637 -- iter: 1443/1443
--
Training Step: 323  | total loss: [1m[32m0.62510[0m[0m | time: 0.758s
[2K
| RMSProp | epoch: 008 | loss: 0.62510 - acc: 0.6770 -- iter: 0032/1443
[A[ATraining Step: 324  | total loss: [1m[32m0.62009[0m[0m | time: 1.517s
[2K
| RMSProp | epoch: 008 | loss: 0.62009 - acc: 0.6749 -- iter: 0064/1443
[A[ATraining Step: 325  | total loss: [1m[32m0.61964[0m[0m | time: 2.241s
[2K
| RMSProp | epoch: 008 | loss: 0.61964 - acc: 0.6731 -- iter: 0096/1443
[A[ATraining Step: 326  | total loss: [1m[32m0.61602[0m[0m | time: 2.968s
[2K
| RMSProp | epoch: 008 | loss: 0.61602 - acc: 0.6776 -- iter: 0128/1443
[A[ATraining Step: 327  | total loss: [1m[32m0.61470[0m[0m | time: 3.721s
[2K
| RMSProp | epoch: 008 | loss: 0.61470 - acc: 0.6786 -- iter: 0160/1443
[A[ATraining Step: 328  | total loss: [1m[32m0.61848[0m[0m | time: 3.816s
[2K
| RMSProp | epoch: 008 | loss: 0.61848 - acc: 0.6733 -- iter: 0192/1443
[A[ATraining Step: 329  | total loss: [1m[32m0.64325[0m[0m | time: 3.905s
[2K
| RMSProp | epoch: 008 | loss: 0.64325 - acc: 0.6393 -- iter: 0224/1443
[A[ATraining Step: 330  | total loss: [1m[32m0.64023[0m[0m | time: 4.632s
[2K
| RMSProp | epoch: 008 | loss: 0.64023 - acc: 0.6753 -- iter: 0256/1443
[A[ATraining Step: 331  | total loss: [1m[32m0.63491[0m[0m | time: 5.405s
[2K
| RMSProp | epoch: 008 | loss: 0.63491 - acc: 0.6797 -- iter: 0288/1443
[A[ATraining Step: 332  | total loss: [1m[32m0.63752[0m[0m | time: 6.340s
[2K
| RMSProp | epoch: 008 | loss: 0.63752 - acc: 0.6711 -- iter: 0320/1443
[A[ATraining Step: 333  | total loss: [1m[32m0.63289[0m[0m | time: 7.227s
[2K
| RMSProp | epoch: 008 | loss: 0.63289 - acc: 0.6759 -- iter: 0352/1443
[A[ATraining Step: 334  | total loss: [1m[32m0.63618[0m[0m | time: 7.996s
[2K
| RMSProp | epoch: 008 | loss: 0.63618 - acc: 0.6645 -- iter: 0384/1443
[A[ATraining Step: 335  | total loss: [1m[32m0.62632[0m[0m | time: 8.735s
[2K
| RMSProp | epoch: 008 | loss: 0.62632 - acc: 0.6731 -- iter: 0416/1443
[A[ATraining Step: 336  | total loss: [1m[32m0.62462[0m[0m | time: 9.463s
[2K
| RMSProp | epoch: 008 | loss: 0.62462 - acc: 0.6745 -- iter: 0448/1443
[A[ATraining Step: 337  | total loss: [1m[32m0.61659[0m[0m | time: 10.194s
[2K
| RMSProp | epoch: 008 | loss: 0.61659 - acc: 0.6852 -- iter: 0480/1443
[A[ATraining Step: 338  | total loss: [1m[32m0.61615[0m[0m | time: 11.153s
[2K
| RMSProp | epoch: 008 | loss: 0.61615 - acc: 0.6854 -- iter: 0512/1443
[A[ATraining Step: 339  | total loss: [1m[32m0.62153[0m[0m | time: 12.119s
[2K
| RMSProp | epoch: 008 | loss: 0.62153 - acc: 0.6731 -- iter: 0544/1443
[A[ATraining Step: 340  | total loss: [1m[32m0.62704[0m[0m | time: 12.924s
[2K
| RMSProp | epoch: 008 | loss: 0.62704 - acc: 0.6683 -- iter: 0576/1443
[A[ATraining Step: 341  | total loss: [1m[32m0.63018[0m[0m | time: 13.624s
[2K
| RMSProp | epoch: 008 | loss: 0.63018 - acc: 0.6640 -- iter: 0608/1443
[A[ATraining Step: 342  | total loss: [1m[32m0.62419[0m[0m | time: 14.338s
[2K
| RMSProp | epoch: 008 | loss: 0.62419 - acc: 0.6695 -- iter: 0640/1443
[A[ATraining Step: 343  | total loss: [1m[32m0.61455[0m[0m | time: 15.168s
[2K
| RMSProp | epoch: 008 | loss: 0.61455 - acc: 0.6838 -- iter: 0672/1443
[A[ATraining Step: 344  | total loss: [1m[32m0.61516[0m[0m | time: 15.917s
[2K
| RMSProp | epoch: 008 | loss: 0.61516 - acc: 0.6841 -- iter: 0704/1443
[A[ATraining Step: 345  | total loss: [1m[32m0.60963[0m[0m | time: 16.693s
[2K
| RMSProp | epoch: 008 | loss: 0.60963 - acc: 0.6907 -- iter: 0736/1443
[A[ATraining Step: 346  | total loss: [1m[32m0.61625[0m[0m | time: 17.441s
[2K
| RMSProp | epoch: 008 | loss: 0.61625 - acc: 0.6810 -- iter: 0768/1443
[A[ATraining Step: 347  | total loss: [1m[32m0.61958[0m[0m | time: 18.202s
[2K
| RMSProp | epoch: 008 | loss: 0.61958 - acc: 0.6754 -- iter: 0800/1443
[A[ATraining Step: 348  | total loss: [1m[32m0.61989[0m[0m | time: 18.955s
[2K
| RMSProp | epoch: 008 | loss: 0.61989 - acc: 0.6766 -- iter: 0832/1443
[A[ATraining Step: 349  | total loss: [1m[32m0.62085[0m[0m | time: 19.703s
[2K
| RMSProp | epoch: 008 | loss: 0.62085 - acc: 0.6715 -- iter: 0864/1443
[A[ATraining Step: 350  | total loss: [1m[32m0.64267[0m[0m | time: 20.429s
[2K
| RMSProp | epoch: 008 | loss: 0.64267 - acc: 0.6356 -- iter: 0896/1443
[A[ATraining Step: 351  | total loss: [1m[32m0.64556[0m[0m | time: 21.201s
[2K
| RMSProp | epoch: 008 | loss: 0.64556 - acc: 0.6314 -- iter: 0928/1443
[A[ATraining Step: 352  | total loss: [1m[32m0.63422[0m[0m | time: 21.962s
[2K
| RMSProp | epoch: 008 | loss: 0.63422 - acc: 0.6526 -- iter: 0960/1443
[A[ATraining Step: 353  | total loss: [1m[32m0.62683[0m[0m | time: 22.701s
[2K
| RMSProp | epoch: 008 | loss: 0.62683 - acc: 0.6530 -- iter: 0992/1443
[A[ATraining Step: 354  | total loss: [1m[32m0.61857[0m[0m | time: 23.434s
[2K
| RMSProp | epoch: 008 | loss: 0.61857 - acc: 0.6564 -- iter: 1024/1443
[A[ATraining Step: 355  | total loss: [1m[32m0.60889[0m[0m | time: 24.172s
[2K
| RMSProp | epoch: 008 | loss: 0.60889 - acc: 0.6689 -- iter: 1056/1443
[A[ATraining Step: 356  | total loss: [1m[32m0.60838[0m[0m | time: 24.942s
[2K
| RMSProp | epoch: 008 | loss: 0.60838 - acc: 0.6739 -- iter: 1088/1443
[A[ATraining Step: 357  | total loss: [1m[32m0.60179[0m[0m | time: 25.664s
[2K
| RMSProp | epoch: 008 | loss: 0.60179 - acc: 0.6815 -- iter: 1120/1443
[A[ATraining Step: 358  | total loss: [1m[32m0.59229[0m[0m | time: 26.400s
[2K
| RMSProp | epoch: 008 | loss: 0.59229 - acc: 0.6884 -- iter: 1152/1443
[A[ATraining Step: 359  | total loss: [1m[32m0.60708[0m[0m | time: 27.113s
[2K
| RMSProp | epoch: 008 | loss: 0.60708 - acc: 0.6727 -- iter: 1184/1443
[A[ATraining Step: 360  | total loss: [1m[32m0.59952[0m[0m | time: 27.844s
[2K
| RMSProp | epoch: 008 | loss: 0.59952 - acc: 0.6835 -- iter: 1216/1443
[A[ATraining Step: 361  | total loss: [1m[32m0.58887[0m[0m | time: 28.587s
[2K
| RMSProp | epoch: 008 | loss: 0.58887 - acc: 0.6902 -- iter: 1248/1443
[A[ATraining Step: 362  | total loss: [1m[32m0.58169[0m[0m | time: 29.335s
[2K
| RMSProp | epoch: 008 | loss: 0.58169 - acc: 0.6993 -- iter: 1280/1443
[A[ATraining Step: 363  | total loss: [1m[32m0.56904[0m[0m | time: 30.070s
[2K
| RMSProp | epoch: 008 | loss: 0.56904 - acc: 0.7137 -- iter: 1312/1443
[A[ATraining Step: 364  | total loss: [1m[32m0.56506[0m[0m | time: 30.812s
[2K
| RMSProp | epoch: 008 | loss: 0.56506 - acc: 0.7173 -- iter: 1344/1443
[A[ATraining Step: 365  | total loss: [1m[32m0.58283[0m[0m | time: 31.515s
[2K
| RMSProp | epoch: 008 | loss: 0.58283 - acc: 0.7081 -- iter: 1376/1443
[A[ATraining Step: 366  | total loss: [1m[32m0.60188[0m[0m | time: 32.241s
[2K
| RMSProp | epoch: 008 | loss: 0.60188 - acc: 0.6842 -- iter: 1408/1443
[A[ATraining Step: 367  | total loss: [1m[32m0.60543[0m[0m | time: 32.988s
[2K
| RMSProp | epoch: 008 | loss: 0.60543 - acc: 0.6783 -- iter: 1440/1443
[A[ATraining Step: 368  | total loss: [1m[32m0.60508[0m[0m | time: 35.409s
[2K
| RMSProp | epoch: 008 | loss: 0.60508 - acc: 0.6792 | val_loss: 0.61390 - val_acc: 0.6836 -- iter: 1443/1443
--
Training Step: 369  | total loss: [1m[32m0.60462[0m[0m | time: 0.774s
[2K
| RMSProp | epoch: 009 | loss: 0.60462 - acc: 0.6800 -- iter: 0032/1443
[A[ATraining Step: 370  | total loss: [1m[32m0.60709[0m[0m | time: 1.594s
[2K
| RMSProp | epoch: 009 | loss: 0.60709 - acc: 0.6776 -- iter: 0064/1443
[A[ATraining Step: 371  | total loss: [1m[32m0.60509[0m[0m | time: 2.363s
[2K
| RMSProp | epoch: 009 | loss: 0.60509 - acc: 0.6786 -- iter: 0096/1443
[A[ATraining Step: 372  | total loss: [1m[32m0.59715[0m[0m | time: 3.189s
[2K
| RMSProp | epoch: 009 | loss: 0.59715 - acc: 0.6826 -- iter: 0128/1443
[A[ATraining Step: 373  | total loss: [1m[32m0.59858[0m[0m | time: 3.949s
[2K
| RMSProp | epoch: 009 | loss: 0.59858 - acc: 0.6800 -- iter: 0160/1443
[A[ATraining Step: 374  | total loss: [1m[32m0.59166[0m[0m | time: 4.796s
[2K
| RMSProp | epoch: 009 | loss: 0.59166 - acc: 0.6901 -- iter: 0192/1443
[A[ATraining Step: 375  | total loss: [1m[32m0.58435[0m[0m | time: 4.909s
[2K
| RMSProp | epoch: 009 | loss: 0.58435 - acc: 0.6992 -- iter: 0224/1443
[A[ATraining Step: 376  | total loss: [1m[32m0.59046[0m[0m | time: 5.027s
[2K
| RMSProp | epoch: 009 | loss: 0.59046 - acc: 0.6960 -- iter: 0256/1443
[A[ATraining Step: 377  | total loss: [1m[32m0.56485[0m[0m | time: 5.764s
[2K
| RMSProp | epoch: 009 | loss: 0.56485 - acc: 0.7264 -- iter: 0288/1443
[A[ATraining Step: 378  | total loss: [1m[32m0.58216[0m[0m | time: 6.582s
[2K
| RMSProp | epoch: 009 | loss: 0.58216 - acc: 0.7100 -- iter: 0320/1443
[A[ATraining Step: 379  | total loss: [1m[32m0.56105[0m[0m | time: 7.352s
[2K
| RMSProp | epoch: 009 | loss: 0.56105 - acc: 0.7327 -- iter: 0352/1443
[A[ATraining Step: 380  | total loss: [1m[32m0.59616[0m[0m | time: 8.099s
[2K
| RMSProp | epoch: 009 | loss: 0.59616 - acc: 0.7157 -- iter: 0384/1443
[A[ATraining Step: 381  | total loss: [1m[32m0.59748[0m[0m | time: 8.877s
[2K
| RMSProp | epoch: 009 | loss: 0.59748 - acc: 0.7066 -- iter: 0416/1443
[A[ATraining Step: 382  | total loss: [1m[32m0.59492[0m[0m | time: 9.640s
[2K
| RMSProp | epoch: 009 | loss: 0.59492 - acc: 0.7047 -- iter: 0448/1443
[A[ATraining Step: 383  | total loss: [1m[32m0.59615[0m[0m | time: 10.387s
[2K
| RMSProp | epoch: 009 | loss: 0.59615 - acc: 0.6968 -- iter: 0480/1443
[A[ATraining Step: 384  | total loss: [1m[32m0.59764[0m[0m | time: 11.160s
[2K
| RMSProp | epoch: 009 | loss: 0.59764 - acc: 0.6927 -- iter: 0512/1443
[A[ATraining Step: 385  | total loss: [1m[32m0.60181[0m[0m | time: 11.973s
[2K
| RMSProp | epoch: 009 | loss: 0.60181 - acc: 0.6828 -- iter: 0544/1443
[A[ATraining Step: 386  | total loss: [1m[32m0.58698[0m[0m | time: 12.742s
[2K
| RMSProp | epoch: 009 | loss: 0.58698 - acc: 0.7020 -- iter: 0576/1443
[A[ATraining Step: 387  | total loss: [1m[32m0.57343[0m[0m | time: 13.518s
[2K
| RMSProp | epoch: 009 | loss: 0.57343 - acc: 0.7131 -- iter: 0608/1443
[A[ATraining Step: 388  | total loss: [1m[32m0.57937[0m[0m | time: 14.258s
[2K
| RMSProp | epoch: 009 | loss: 0.57937 - acc: 0.7074 -- iter: 0640/1443
[A[ATraining Step: 389  | total loss: [1m[32m0.57874[0m[0m | time: 14.984s
[2K
| RMSProp | epoch: 009 | loss: 0.57874 - acc: 0.7117 -- iter: 0672/1443
[A[ATraining Step: 390  | total loss: [1m[32m0.56934[0m[0m | time: 15.749s
[2K
| RMSProp | epoch: 009 | loss: 0.56934 - acc: 0.7186 -- iter: 0704/1443
[A[ATraining Step: 391  | total loss: [1m[32m0.56568[0m[0m | time: 16.494s
[2K
| RMSProp | epoch: 009 | loss: 0.56568 - acc: 0.7218 -- iter: 0736/1443
[A[ATraining Step: 392  | total loss: [1m[32m0.55390[0m[0m | time: 17.221s
[2K
| RMSProp | epoch: 009 | loss: 0.55390 - acc: 0.7308 -- iter: 0768/1443
[A[ATraining Step: 393  | total loss: [1m[32m0.53544[0m[0m | time: 17.993s
[2K
| RMSProp | epoch: 009 | loss: 0.53544 - acc: 0.7452 -- iter: 0800/1443
[A[ATraining Step: 394  | total loss: [1m[32m0.53898[0m[0m | time: 18.784s
[2K
| RMSProp | epoch: 009 | loss: 0.53898 - acc: 0.7363 -- iter: 0832/1443
[A[ATraining Step: 395  | total loss: [1m[32m0.55033[0m[0m | time: 19.519s
[2K
| RMSProp | epoch: 009 | loss: 0.55033 - acc: 0.7283 -- iter: 0864/1443
[A[ATraining Step: 396  | total loss: [1m[32m0.56598[0m[0m | time: 20.295s
[2K
| RMSProp | epoch: 009 | loss: 0.56598 - acc: 0.7211 -- iter: 0896/1443
[A[ATraining Step: 397  | total loss: [1m[32m0.55411[0m[0m | time: 21.042s
[2K
| RMSProp | epoch: 009 | loss: 0.55411 - acc: 0.7396 -- iter: 0928/1443
[A[ATraining Step: 398  | total loss: [1m[32m0.54909[0m[0m | time: 21.821s
[2K
| RMSProp | epoch: 009 | loss: 0.54909 - acc: 0.7344 -- iter: 0960/1443
[A[ATraining Step: 399  | total loss: [1m[32m0.53845[0m[0m | time: 22.537s
[2K
| RMSProp | epoch: 009 | loss: 0.53845 - acc: 0.7422 -- iter: 0992/1443
[A[ATraining Step: 400  | total loss: [1m[32m0.54443[0m[0m | time: 24.936s
[2K
| RMSProp | epoch: 009 | loss: 0.54443 - acc: 0.7368 | val_loss: 0.59884 - val_acc: 0.6770 -- iter: 1024/1443
--
Training Step: 401  | total loss: [1m[32m0.54582[0m[0m | time: 25.725s
[2K
| RMSProp | epoch: 009 | loss: 0.54582 - acc: 0.7350 -- iter: 1056/1443
[A[ATraining Step: 402  | total loss: [1m[32m0.54296[0m[0m | time: 26.476s
[2K
| RMSProp | epoch: 009 | loss: 0.54296 - acc: 0.7333 -- iter: 1088/1443
[A[ATraining Step: 403  | total loss: [1m[32m0.55824[0m[0m | time: 27.241s
[2K
| RMSProp | epoch: 009 | loss: 0.55824 - acc: 0.7194 -- iter: 1120/1443
[A[ATraining Step: 404  | total loss: [1m[32m0.56415[0m[0m | time: 28.303s
[2K
| RMSProp | epoch: 009 | loss: 0.56415 - acc: 0.7162 -- iter: 1152/1443
[A[ATraining Step: 405  | total loss: [1m[32m0.56350[0m[0m | time: 28.946s
[2K
| RMSProp | epoch: 009 | loss: 0.56350 - acc: 0.7133 -- iter: 1184/1443
[A[ATraining Step: 406  | total loss: [1m[32m0.55688[0m[0m | time: 29.674s
[2K
| RMSProp | epoch: 009 | loss: 0.55688 - acc: 0.7232 -- iter: 1216/1443
[A[ATraining Step: 407  | total loss: [1m[32m0.56266[0m[0m | time: 30.431s
[2K
| RMSProp | epoch: 009 | loss: 0.56266 - acc: 0.7165 -- iter: 1248/1443
[A[ATraining Step: 408  | total loss: [1m[32m0.57239[0m[0m | time: 31.158s
[2K
| RMSProp | epoch: 009 | loss: 0.57239 - acc: 0.7136 -- iter: 1280/1443
[A[ATraining Step: 409  | total loss: [1m[32m0.56856[0m[0m | time: 31.892s
[2K
| RMSProp | epoch: 009 | loss: 0.56856 - acc: 0.7173 -- iter: 1312/1443
[A[ATraining Step: 410  | total loss: [1m[32m0.56782[0m[0m | time: 32.643s
[2K
| RMSProp | epoch: 009 | loss: 0.56782 - acc: 0.7112 -- iter: 1344/1443
[A[ATraining Step: 411  | total loss: [1m[32m0.56618[0m[0m | time: 33.358s
[2K
| RMSProp | epoch: 009 | loss: 0.56618 - acc: 0.7119 -- iter: 1376/1443
[A[ATraining Step: 412  | total loss: [1m[32m0.55393[0m[0m | time: 34.078s
[2K
| RMSProp | epoch: 009 | loss: 0.55393 - acc: 0.7314 -- iter: 1408/1443
[A[ATraining Step: 413  | total loss: [1m[32m0.55412[0m[0m | time: 34.822s
[2K
| RMSProp | epoch: 009 | loss: 0.55412 - acc: 0.7238 -- iter: 1440/1443
[A[ATraining Step: 414  | total loss: [1m[32m0.55092[0m[0m | time: 37.262s
[2K
| RMSProp | epoch: 009 | loss: 0.55092 - acc: 0.7233 | val_loss: 0.62795 - val_acc: 0.6814 -- iter: 1443/1443
--
Training Step: 415  | total loss: [1m[32m0.54823[0m[0m | time: 0.749s
[2K
| RMSProp | epoch: 010 | loss: 0.54823 - acc: 0.7260 -- iter: 0032/1443
[A[ATraining Step: 416  | total loss: [1m[32m0.53910[0m[0m | time: 1.531s
[2K
| RMSProp | epoch: 010 | loss: 0.53910 - acc: 0.7284 -- iter: 0064/1443
[A[ATraining Step: 417  | total loss: [1m[32m0.54213[0m[0m | time: 2.268s
[2K
| RMSProp | epoch: 010 | loss: 0.54213 - acc: 0.7243 -- iter: 0096/1443
[A[ATraining Step: 418  | total loss: [1m[32m0.56509[0m[0m | time: 2.994s
[2K
| RMSProp | epoch: 010 | loss: 0.56509 - acc: 0.7144 -- iter: 0128/1443
[A[ATraining Step: 419  | total loss: [1m[32m0.56638[0m[0m | time: 3.727s
[2K
| RMSProp | epoch: 010 | loss: 0.56638 - acc: 0.7054 -- iter: 0160/1443
[A[ATraining Step: 420  | total loss: [1m[32m0.58101[0m[0m | time: 4.487s
[2K
| RMSProp | epoch: 010 | loss: 0.58101 - acc: 0.6943 -- iter: 0192/1443
[A[ATraining Step: 421  | total loss: [1m[32m0.57730[0m[0m | time: 5.248s
[2K
| RMSProp | epoch: 010 | loss: 0.57730 - acc: 0.6967 -- iter: 0224/1443
[A[ATraining Step: 422  | total loss: [1m[32m0.58159[0m[0m | time: 5.344s
[2K
| RMSProp | epoch: 010 | loss: 0.58159 - acc: 0.6958 -- iter: 0256/1443
[A[ATraining Step: 423  | total loss: [1m[32m0.61279[0m[0m | time: 5.431s
[2K
| RMSProp | epoch: 010 | loss: 0.61279 - acc: 0.6596 -- iter: 0288/1443
[A[ATraining Step: 424  | total loss: [1m[32m0.61267[0m[0m | time: 6.186s
[2K
| RMSProp | epoch: 010 | loss: 0.61267 - acc: 0.6603 -- iter: 0320/1443
[A[ATraining Step: 425  | total loss: [1m[32m0.62433[0m[0m | time: 6.916s
[2K
| RMSProp | epoch: 010 | loss: 0.62433 - acc: 0.6411 -- iter: 0352/1443
[A[ATraining Step: 426  | total loss: [1m[32m0.61631[0m[0m | time: 7.649s
[2K
| RMSProp | epoch: 010 | loss: 0.61631 - acc: 0.6583 -- iter: 0384/1443
[A[ATraining Step: 427  | total loss: [1m[32m0.60429[0m[0m | time: 8.407s
[2K
| RMSProp | epoch: 010 | loss: 0.60429 - acc: 0.6737 -- iter: 0416/1443
[A[ATraining Step: 428  | total loss: [1m[32m0.59546[0m[0m | time: 9.123s
[2K
| RMSProp | epoch: 010 | loss: 0.59546 - acc: 0.6782 -- iter: 0448/1443
[A[ATraining Step: 429  | total loss: [1m[32m0.58824[0m[0m | time: 9.890s
[2K
| RMSProp | epoch: 010 | loss: 0.58824 - acc: 0.6916 -- iter: 0480/1443
[A[ATraining Step: 430  | total loss: [1m[32m0.58487[0m[0m | time: 10.625s
[2K
| RMSProp | epoch: 010 | loss: 0.58487 - acc: 0.6975 -- iter: 0512/1443
[A[ATraining Step: 431  | total loss: [1m[32m0.59133[0m[0m | time: 11.351s
[2K
| RMSProp | epoch: 010 | loss: 0.59133 - acc: 0.6871 -- iter: 0544/1443
[A[ATraining Step: 432  | total loss: [1m[32m0.61539[0m[0m | time: 12.096s
[2K
| RMSProp | epoch: 010 | loss: 0.61539 - acc: 0.6559 -- iter: 0576/1443
[A[ATraining Step: 433  | total loss: [1m[32m0.60066[0m[0m | time: 12.821s
[2K
| RMSProp | epoch: 010 | loss: 0.60066 - acc: 0.6747 -- iter: 0608/1443
[A[ATraining Step: 434  | total loss: [1m[32m0.58865[0m[0m | time: 13.592s
[2K
| RMSProp | epoch: 010 | loss: 0.58865 - acc: 0.6822 -- iter: 0640/1443
[A[ATraining Step: 435  | total loss: [1m[32m0.58299[0m[0m | time: 14.327s
[2K
| RMSProp | epoch: 010 | loss: 0.58299 - acc: 0.6890 -- iter: 0672/1443
[A[ATraining Step: 436  | total loss: [1m[32m0.57547[0m[0m | time: 15.059s
[2K
| RMSProp | epoch: 010 | loss: 0.57547 - acc: 0.6888 -- iter: 0704/1443
[A[ATraining Step: 437  | total loss: [1m[32m0.57411[0m[0m | time: 15.796s
[2K
| RMSProp | epoch: 010 | loss: 0.57411 - acc: 0.6887 -- iter: 0736/1443
[A[ATraining Step: 438  | total loss: [1m[32m0.56256[0m[0m | time: 16.526s
[2K
| RMSProp | epoch: 010 | loss: 0.56256 - acc: 0.7073 -- iter: 0768/1443
[A[ATraining Step: 439  | total loss: [1m[32m0.54377[0m[0m | time: 17.287s
[2K
| RMSProp | epoch: 010 | loss: 0.54377 - acc: 0.7272 -- iter: 0800/1443
[A[ATraining Step: 440  | total loss: [1m[32m0.54135[0m[0m | time: 18.104s
[2K
| RMSProp | epoch: 010 | loss: 0.54135 - acc: 0.7326 -- iter: 0832/1443
[A[ATraining Step: 441  | total loss: [1m[32m0.54394[0m[0m | time: 19.074s
[2K
| RMSProp | epoch: 010 | loss: 0.54394 - acc: 0.7312 -- iter: 0864/1443
[A[ATraining Step: 442  | total loss: [1m[32m0.54156[0m[0m | time: 19.809s
[2K
| RMSProp | epoch: 010 | loss: 0.54156 - acc: 0.7300 -- iter: 0896/1443
[A[ATraining Step: 443  | total loss: [1m[32m0.54031[0m[0m | time: 20.555s
[2K
| RMSProp | epoch: 010 | loss: 0.54031 - acc: 0.7351 -- iter: 0928/1443
[A[ATraining Step: 444  | total loss: [1m[32m0.55729[0m[0m | time: 21.307s
[2K
| RMSProp | epoch: 010 | loss: 0.55729 - acc: 0.7272 -- iter: 0960/1443
[A[ATraining Step: 445  | total loss: [1m[32m0.55826[0m[0m | time: 22.087s
[2K
| RMSProp | epoch: 010 | loss: 0.55826 - acc: 0.7326 -- iter: 0992/1443
[A[ATraining Step: 446  | total loss: [1m[32m0.54127[0m[0m | time: 22.873s
[2K
| RMSProp | epoch: 010 | loss: 0.54127 - acc: 0.7469 -- iter: 1024/1443
[A[ATraining Step: 447  | total loss: [1m[32m0.53060[0m[0m | time: 23.582s
[2K
| RMSProp | epoch: 010 | loss: 0.53060 - acc: 0.7566 -- iter: 1056/1443
[A[ATraining Step: 448  | total loss: [1m[32m0.53010[0m[0m | time: 24.323s
[2K
| RMSProp | epoch: 010 | loss: 0.53010 - acc: 0.7590 -- iter: 1088/1443
[A[ATraining Step: 449  | total loss: [1m[32m0.53406[0m[0m | time: 25.083s
[2K
| RMSProp | epoch: 010 | loss: 0.53406 - acc: 0.7519 -- iter: 1120/1443
[A[ATraining Step: 450  | total loss: [1m[32m0.54103[0m[0m | time: 25.857s
[2K
| RMSProp | epoch: 010 | loss: 0.54103 - acc: 0.7423 -- iter: 1152/1443
[A[ATraining Step: 451  | total loss: [1m[32m0.53078[0m[0m | time: 26.637s
[2K
| RMSProp | epoch: 010 | loss: 0.53078 - acc: 0.7493 -- iter: 1184/1443
[A[ATraining Step: 452  | total loss: [1m[32m0.52217[0m[0m | time: 27.391s
[2K
| RMSProp | epoch: 010 | loss: 0.52217 - acc: 0.7494 -- iter: 1216/1443
[A[ATraining Step: 453  | total loss: [1m[32m0.53510[0m[0m | time: 28.108s
[2K
| RMSProp | epoch: 010 | loss: 0.53510 - acc: 0.7401 -- iter: 1248/1443
[A[ATraining Step: 454  | total loss: [1m[32m0.54014[0m[0m | time: 28.823s
[2K
| RMSProp | epoch: 010 | loss: 0.54014 - acc: 0.7317 -- iter: 1280/1443
[A[ATraining Step: 455  | total loss: [1m[32m0.54640[0m[0m | time: 29.620s
[2K
| RMSProp | epoch: 010 | loss: 0.54640 - acc: 0.7210 -- iter: 1312/1443
[A[ATraining Step: 456  | total loss: [1m[32m0.54163[0m[0m | time: 30.415s
[2K
| RMSProp | epoch: 010 | loss: 0.54163 - acc: 0.7239 -- iter: 1344/1443
[A[ATraining Step: 457  | total loss: [1m[32m0.53018[0m[0m | time: 31.232s
[2K
| RMSProp | epoch: 010 | loss: 0.53018 - acc: 0.7328 -- iter: 1376/1443
[A[ATraining Step: 458  | total loss: [1m[32m0.53259[0m[0m | time: 31.958s
[2K
| RMSProp | epoch: 010 | loss: 0.53259 - acc: 0.7345 -- iter: 1408/1443
[A[ATraining Step: 459  | total loss: [1m[32m0.52974[0m[0m | time: 32.689s
[2K
| RMSProp | epoch: 010 | loss: 0.52974 - acc: 0.7329 -- iter: 1440/1443
[A[ATraining Step: 460  | total loss: [1m[32m0.54550[0m[0m | time: 35.130s
[2K
| RMSProp | epoch: 010 | loss: 0.54550 - acc: 0.7315 | val_loss: 0.60552 - val_acc: 0.6903 -- iter: 1443/1443
--
Training Step: 461  | total loss: [1m[32m0.54758[0m[0m | time: 0.726s
[2K
| RMSProp | epoch: 011 | loss: 0.54758 - acc: 0.7302 -- iter: 0032/1443
[A[ATraining Step: 462  | total loss: [1m[32m0.55244[0m[0m | time: 1.461s
[2K
| RMSProp | epoch: 011 | loss: 0.55244 - acc: 0.7166 -- iter: 0064/1443
[A[ATraining Step: 463  | total loss: [1m[32m0.55659[0m[0m | time: 2.199s
[2K
| RMSProp | epoch: 011 | loss: 0.55659 - acc: 0.7137 -- iter: 0096/1443
[A[ATraining Step: 464  | total loss: [1m[32m0.53827[0m[0m | time: 2.968s
[2K
| RMSProp | epoch: 011 | loss: 0.53827 - acc: 0.7267 -- iter: 0128/1443
[A[ATraining Step: 465  | total loss: [1m[32m0.55191[0m[0m | time: 3.705s
[2K
| RMSProp | epoch: 011 | loss: 0.55191 - acc: 0.7165 -- iter: 0160/1443
[A[ATraining Step: 466  | total loss: [1m[32m0.55077[0m[0m | time: 4.444s
[2K
| RMSProp | epoch: 011 | loss: 0.55077 - acc: 0.7167 -- iter: 0192/1443
[A[ATraining Step: 467  | total loss: [1m[32m0.54741[0m[0m | time: 5.264s
[2K
| RMSProp | epoch: 011 | loss: 0.54741 - acc: 0.7138 -- iter: 0224/1443
[A[ATraining Step: 468  | total loss: [1m[32m0.54442[0m[0m | time: 6.031s
[2K
| RMSProp | epoch: 011 | loss: 0.54442 - acc: 0.7112 -- iter: 0256/1443
[A[ATraining Step: 469  | total loss: [1m[32m0.55061[0m[0m | time: 6.120s
[2K
| RMSProp | epoch: 011 | loss: 0.55061 - acc: 0.7119 -- iter: 0288/1443
[A[ATraining Step: 470  | total loss: [1m[32m0.58436[0m[0m | time: 6.223s
[2K
| RMSProp | epoch: 011 | loss: 0.58436 - acc: 0.6741 -- iter: 0320/1443
[A[ATraining Step: 471  | total loss: [1m[32m0.57822[0m[0m | time: 7.010s
[2K
| RMSProp | epoch: 011 | loss: 0.57822 - acc: 0.6733 -- iter: 0352/1443
[A[ATraining Step: 472  | total loss: [1m[32m0.58666[0m[0m | time: 7.791s
[2K
| RMSProp | epoch: 011 | loss: 0.58666 - acc: 0.6685 -- iter: 0384/1443
[A[ATraining Step: 473  | total loss: [1m[32m0.59244[0m[0m | time: 8.588s
[2K
| RMSProp | epoch: 011 | loss: 0.59244 - acc: 0.6610 -- iter: 0416/1443
[A[ATraining Step: 474  | total loss: [1m[32m0.58651[0m[0m | time: 9.328s
[2K
| RMSProp | epoch: 011 | loss: 0.58651 - acc: 0.6731 -- iter: 0448/1443
[A[ATraining Step: 475  | total loss: [1m[32m0.57778[0m[0m | time: 10.092s
[2K
| RMSProp | epoch: 011 | loss: 0.57778 - acc: 0.6870 -- iter: 0480/1443
[A[ATraining Step: 476  | total loss: [1m[32m0.57422[0m[0m | time: 11.096s
[2K
| RMSProp | epoch: 011 | loss: 0.57422 - acc: 0.6964 -- iter: 0512/1443
[A[ATraining Step: 477  | total loss: [1m[32m0.57252[0m[0m | time: 11.992s
[2K
| RMSProp | epoch: 011 | loss: 0.57252 - acc: 0.6987 -- iter: 0544/1443
[A[ATraining Step: 478  | total loss: [1m[32m0.56196[0m[0m | time: 13.489s
[2K
| RMSProp | epoch: 011 | loss: 0.56196 - acc: 0.7163 -- iter: 0576/1443
[A[ATraining Step: 479  | total loss: [1m[32m0.55402[0m[0m | time: 14.524s
[2K
| RMSProp | epoch: 011 | loss: 0.55402 - acc: 0.7290 -- iter: 0608/1443
[A[ATraining Step: 480  | total loss: [1m[32m0.55947[0m[0m | time: 15.155s
[2K
| RMSProp | epoch: 011 | loss: 0.55947 - acc: 0.7311 -- iter: 0640/1443
[A[ATraining Step: 481  | total loss: [1m[32m0.56791[0m[0m | time: 15.776s
[2K
| RMSProp | epoch: 011 | loss: 0.56791 - acc: 0.7236 -- iter: 0672/1443
[A[ATraining Step: 482  | total loss: [1m[32m0.56847[0m[0m | time: 16.420s
[2K
| RMSProp | epoch: 011 | loss: 0.56847 - acc: 0.7169 -- iter: 0704/1443
[A[ATraining Step: 483  | total loss: [1m[32m0.55860[0m[0m | time: 17.037s
[2K
| RMSProp | epoch: 011 | loss: 0.55860 - acc: 0.7265 -- iter: 0736/1443
[A[ATraining Step: 484  | total loss: [1m[32m0.55190[0m[0m | time: 17.643s
[2K
| RMSProp | epoch: 011 | loss: 0.55190 - acc: 0.7257 -- iter: 0768/1443
[A[ATraining Step: 485  | total loss: [1m[32m0.53661[0m[0m | time: 18.270s
[2K
| RMSProp | epoch: 011 | loss: 0.53661 - acc: 0.7406 -- iter: 0800/1443
[A[ATraining Step: 486  | total loss: [1m[32m0.53904[0m[0m | time: 18.888s
[2K
| RMSProp | epoch: 011 | loss: 0.53904 - acc: 0.7416 -- iter: 0832/1443
[A[ATraining Step: 487  | total loss: [1m[32m0.53760[0m[0m | time: 19.498s
[2K
| RMSProp | epoch: 011 | loss: 0.53760 - acc: 0.7424 -- iter: 0864/1443
[A[ATraining Step: 488  | total loss: [1m[32m0.53631[0m[0m | time: 20.126s
[2K
| RMSProp | epoch: 011 | loss: 0.53631 - acc: 0.7432 -- iter: 0896/1443
[A[ATraining Step: 489  | total loss: [1m[32m0.52032[0m[0m | time: 20.734s
[2K
| RMSProp | epoch: 011 | loss: 0.52032 - acc: 0.7563 -- iter: 0928/1443
[A[ATraining Step: 490  | total loss: [1m[32m0.51555[0m[0m | time: 21.335s
[2K
| RMSProp | epoch: 011 | loss: 0.51555 - acc: 0.7526 -- iter: 0960/1443
[A[ATraining Step: 491  | total loss: [1m[32m0.52356[0m[0m | time: 21.978s
[2K
| RMSProp | epoch: 011 | loss: 0.52356 - acc: 0.7492 -- iter: 0992/1443
[A[ATraining Step: 492  | total loss: [1m[32m0.51142[0m[0m | time: 22.602s
[2K
| RMSProp | epoch: 011 | loss: 0.51142 - acc: 0.7587 -- iter: 1024/1443
[A[ATraining Step: 493  | total loss: [1m[32m0.50919[0m[0m | time: 23.223s
[2K
| RMSProp | epoch: 011 | loss: 0.50919 - acc: 0.7547 -- iter: 1056/1443
[A[ATraining Step: 494  | total loss: [1m[32m0.49298[0m[0m | time: 23.852s
[2K
| RMSProp | epoch: 011 | loss: 0.49298 - acc: 0.7667 -- iter: 1088/1443
[A[ATraining Step: 495  | total loss: [1m[32m0.49619[0m[0m | time: 24.471s
[2K
| RMSProp | epoch: 011 | loss: 0.49619 - acc: 0.7650 -- iter: 1120/1443
[A[ATraining Step: 496  | total loss: [1m[32m0.50182[0m[0m | time: 25.111s
[2K
| RMSProp | epoch: 011 | loss: 0.50182 - acc: 0.7573 -- iter: 1152/1443
[A[ATraining Step: 497  | total loss: [1m[32m0.49860[0m[0m | time: 25.727s
[2K
| RMSProp | epoch: 011 | loss: 0.49860 - acc: 0.7597 -- iter: 1184/1443
[A[ATraining Step: 498  | total loss: [1m[32m0.50210[0m[0m | time: 26.338s
[2K
| RMSProp | epoch: 011 | loss: 0.50210 - acc: 0.7587 -- iter: 1216/1443
[A[ATraining Step: 499  | total loss: [1m[32m0.51148[0m[0m | time: 26.956s
[2K
| RMSProp | epoch: 011 | loss: 0.51148 - acc: 0.7610 -- iter: 1248/1443
[A[ATraining Step: 500  | total loss: [1m[32m0.51793[0m[0m | time: 27.587s
[2K
| RMSProp | epoch: 011 | loss: 0.51793 - acc: 0.7630 -- iter: 1280/1443
[A[ATraining Step: 501  | total loss: [1m[32m0.51324[0m[0m | time: 28.202s
[2K
| RMSProp | epoch: 011 | loss: 0.51324 - acc: 0.7711 -- iter: 1312/1443
[A[ATraining Step: 502  | total loss: [1m[32m0.50402[0m[0m | time: 28.819s
[2K
| RMSProp | epoch: 011 | loss: 0.50402 - acc: 0.7783 -- iter: 1344/1443
[A[ATraining Step: 503  | total loss: [1m[32m0.48522[0m[0m | time: 29.429s
[2K
| RMSProp | epoch: 011 | loss: 0.48522 - acc: 0.7880 -- iter: 1376/1443
[A[ATraining Step: 504  | total loss: [1m[32m0.50193[0m[0m | time: 30.044s
[2K
| RMSProp | epoch: 011 | loss: 0.50193 - acc: 0.7780 -- iter: 1408/1443
[A[ATraining Step: 505  | total loss: [1m[32m0.54480[0m[0m | time: 30.644s
[2K
| RMSProp | epoch: 011 | loss: 0.54480 - acc: 0.7470 -- iter: 1440/1443
[A[ATraining Step: 506  | total loss: [1m[32m0.54452[0m[0m | time: 32.689s
[2K
| RMSProp | epoch: 011 | loss: 0.54452 - acc: 0.7505 | val_loss: 0.58844 - val_acc: 0.7212 -- iter: 1443/1443
--
Training Step: 507  | total loss: [1m[32m0.52598[0m[0m | time: 0.654s
[2K
| RMSProp | epoch: 012 | loss: 0.52598 - acc: 0.7660 -- iter: 0032/1443
[A[ATraining Step: 508  | total loss: [1m[32m0.52230[0m[0m | time: 1.264s
[2K
| RMSProp | epoch: 012 | loss: 0.52230 - acc: 0.7644 -- iter: 0064/1443
[A[ATraining Step: 509  | total loss: [1m[32m0.51831[0m[0m | time: 1.866s
[2K
| RMSProp | epoch: 012 | loss: 0.51831 - acc: 0.7661 -- iter: 0096/1443
[A[ATraining Step: 510  | total loss: [1m[32m0.51094[0m[0m | time: 2.481s
[2K
| RMSProp | epoch: 012 | loss: 0.51094 - acc: 0.7739 -- iter: 0128/1443
[A[ATraining Step: 511  | total loss: [1m[32m0.49968[0m[0m | time: 3.088s
[2K
| RMSProp | epoch: 012 | loss: 0.49968 - acc: 0.7809 -- iter: 0160/1443
[A[ATraining Step: 512  | total loss: [1m[32m0.52153[0m[0m | time: 3.694s
[2K
| RMSProp | epoch: 012 | loss: 0.52153 - acc: 0.7684 -- iter: 0192/1443
[A[ATraining Step: 513  | total loss: [1m[32m0.53678[0m[0m | time: 4.306s
[2K
| RMSProp | epoch: 012 | loss: 0.53678 - acc: 0.7509 -- iter: 0224/1443
[A[ATraining Step: 514  | total loss: [1m[32m0.54137[0m[0m | time: 4.922s
[2K
| RMSProp | epoch: 012 | loss: 0.54137 - acc: 0.7446 -- iter: 0256/1443
[A[ATraining Step: 515  | total loss: [1m[32m0.54606[0m[0m | time: 5.530s
[2K
| RMSProp | epoch: 012 | loss: 0.54606 - acc: 0.7389 -- iter: 0288/1443
[A[ATraining Step: 516  | total loss: [1m[32m0.55507[0m[0m | time: 5.615s
[2K
| RMSProp | epoch: 012 | loss: 0.55507 - acc: 0.7275 -- iter: 0320/1443
[A[ATraining Step: 517  | total loss: [1m[32m0.55042[0m[0m | time: 5.698s
[2K
| RMSProp | epoch: 012 | loss: 0.55042 - acc: 0.7214 -- iter: 0352/1443
[A[ATraining Step: 518  | total loss: [1m[32m0.51666[0m[0m | time: 6.303s
[2K
| RMSProp | epoch: 012 | loss: 0.51666 - acc: 0.7493 -- iter: 0384/1443
[A[ATraining Step: 519  | total loss: [1m[32m0.56020[0m[0m | time: 6.922s
[2K
| RMSProp | epoch: 012 | loss: 0.56020 - acc: 0.7306 -- iter: 0416/1443
[A[ATraining Step: 520  | total loss: [1m[32m0.56421[0m[0m | time: 7.553s
[2K
| RMSProp | epoch: 012 | loss: 0.56421 - acc: 0.7263 -- iter: 0448/1443
[A[ATraining Step: 521  | total loss: [1m[32m0.56295[0m[0m | time: 8.154s
[2K
| RMSProp | epoch: 012 | loss: 0.56295 - acc: 0.7318 -- iter: 0480/1443
[A[ATraining Step: 522  | total loss: [1m[32m0.56589[0m[0m | time: 8.764s
[2K
| RMSProp | epoch: 012 | loss: 0.56589 - acc: 0.7211 -- iter: 0512/1443
[A[ATraining Step: 523  | total loss: [1m[32m0.55838[0m[0m | time: 9.370s
[2K
| RMSProp | epoch: 012 | loss: 0.55838 - acc: 0.7209 -- iter: 0544/1443
[A[ATraining Step: 524  | total loss: [1m[32m0.54294[0m[0m | time: 9.977s
[2K
| RMSProp | epoch: 012 | loss: 0.54294 - acc: 0.7363 -- iter: 0576/1443
[A[ATraining Step: 525  | total loss: [1m[32m0.52725[0m[0m | time: 10.594s
[2K
| RMSProp | epoch: 012 | loss: 0.52725 - acc: 0.7533 -- iter: 0608/1443
[A[ATraining Step: 526  | total loss: [1m[32m0.51441[0m[0m | time: 11.200s
[2K
| RMSProp | epoch: 012 | loss: 0.51441 - acc: 0.7654 -- iter: 0640/1443
[A[ATraining Step: 527  | total loss: [1m[32m0.51889[0m[0m | time: 11.809s
[2K
| RMSProp | epoch: 012 | loss: 0.51889 - acc: 0.7608 -- iter: 0672/1443
[A[ATraining Step: 528  | total loss: [1m[32m0.53404[0m[0m | time: 12.416s
[2K
| RMSProp | epoch: 012 | loss: 0.53404 - acc: 0.7441 -- iter: 0704/1443
[A[ATraining Step: 529  | total loss: [1m[32m0.53216[0m[0m | time: 13.022s
[2K
| RMSProp | epoch: 012 | loss: 0.53216 - acc: 0.7415 -- iter: 0736/1443
[A[ATraining Step: 530  | total loss: [1m[32m0.52260[0m[0m | time: 13.625s
[2K
| RMSProp | epoch: 012 | loss: 0.52260 - acc: 0.7518 -- iter: 0768/1443
[A[ATraining Step: 531  | total loss: [1m[32m0.51234[0m[0m | time: 14.230s
[2K
| RMSProp | epoch: 012 | loss: 0.51234 - acc: 0.7547 -- iter: 0800/1443
[A[ATraining Step: 532  | total loss: [1m[32m0.50860[0m[0m | time: 14.836s
[2K
| RMSProp | epoch: 012 | loss: 0.50860 - acc: 0.7511 -- iter: 0832/1443
[A[ATraining Step: 533  | total loss: [1m[32m0.53076[0m[0m | time: 15.448s
[2K
| RMSProp | epoch: 012 | loss: 0.53076 - acc: 0.7323 -- iter: 0864/1443
[A[ATraining Step: 534  | total loss: [1m[32m0.52131[0m[0m | time: 16.063s
[2K
| RMSProp | epoch: 012 | loss: 0.52131 - acc: 0.7497 -- iter: 0896/1443
[A[ATraining Step: 535  | total loss: [1m[32m0.50886[0m[0m | time: 16.672s
[2K
| RMSProp | epoch: 012 | loss: 0.50886 - acc: 0.7591 -- iter: 0928/1443
[A[ATraining Step: 536  | total loss: [1m[32m0.51055[0m[0m | time: 17.281s
[2K
| RMSProp | epoch: 012 | loss: 0.51055 - acc: 0.7519 -- iter: 0960/1443
[A[ATraining Step: 537  | total loss: [1m[32m0.50974[0m[0m | time: 17.886s
[2K
| RMSProp | epoch: 012 | loss: 0.50974 - acc: 0.7580 -- iter: 0992/1443
[A[ATraining Step: 538  | total loss: [1m[32m0.50323[0m[0m | time: 18.486s
[2K
| RMSProp | epoch: 012 | loss: 0.50323 - acc: 0.7697 -- iter: 1024/1443
[A[ATraining Step: 539  | total loss: [1m[32m0.50008[0m[0m | time: 19.115s
[2K
| RMSProp | epoch: 012 | loss: 0.50008 - acc: 0.7646 -- iter: 1056/1443
[A[ATraining Step: 540  | total loss: [1m[32m0.49191[0m[0m | time: 19.725s
[2K
| RMSProp | epoch: 012 | loss: 0.49191 - acc: 0.7725 -- iter: 1088/1443
[A[ATraining Step: 541  | total loss: [1m[32m0.50146[0m[0m | time: 20.337s
[2K
| RMSProp | epoch: 012 | loss: 0.50146 - acc: 0.7577 -- iter: 1120/1443
[A[ATraining Step: 542  | total loss: [1m[32m0.51149[0m[0m | time: 20.944s
[2K
| RMSProp | epoch: 012 | loss: 0.51149 - acc: 0.7413 -- iter: 1152/1443
[A[ATraining Step: 543  | total loss: [1m[32m0.51532[0m[0m | time: 21.548s
[2K
| RMSProp | epoch: 012 | loss: 0.51532 - acc: 0.7422 -- iter: 1184/1443
[A[ATraining Step: 544  | total loss: [1m[32m0.50014[0m[0m | time: 22.180s
[2K
| RMSProp | epoch: 012 | loss: 0.50014 - acc: 0.7461 -- iter: 1216/1443
[A[ATraining Step: 545  | total loss: [1m[32m0.49556[0m[0m | time: 22.823s
[2K
| RMSProp | epoch: 012 | loss: 0.49556 - acc: 0.7559 -- iter: 1248/1443
[A[ATraining Step: 546  | total loss: [1m[32m0.50531[0m[0m | time: 23.437s
[2K
| RMSProp | epoch: 012 | loss: 0.50531 - acc: 0.7522 -- iter: 1280/1443
[A[ATraining Step: 547  | total loss: [1m[32m0.51264[0m[0m | time: 24.057s
[2K
| RMSProp | epoch: 012 | loss: 0.51264 - acc: 0.7488 -- iter: 1312/1443
[A[ATraining Step: 548  | total loss: [1m[32m0.51749[0m[0m | time: 24.677s
[2K
| RMSProp | epoch: 012 | loss: 0.51749 - acc: 0.7427 -- iter: 1344/1443
[A[ATraining Step: 549  | total loss: [1m[32m0.51172[0m[0m | time: 25.279s
[2K
| RMSProp | epoch: 012 | loss: 0.51172 - acc: 0.7497 -- iter: 1376/1443
[A[ATraining Step: 550  | total loss: [1m[32m0.51049[0m[0m | time: 25.919s
[2K
| RMSProp | epoch: 012 | loss: 0.51049 - acc: 0.7560 -- iter: 1408/1443
[A[ATraining Step: 551  | total loss: [1m[32m0.50546[0m[0m | time: 26.533s
[2K
| RMSProp | epoch: 012 | loss: 0.50546 - acc: 0.7616 -- iter: 1440/1443
[A[ATraining Step: 552  | total loss: [1m[32m0.50108[0m[0m | time: 28.588s
[2K
| RMSProp | epoch: 012 | loss: 0.50108 - acc: 0.7667 | val_loss: 0.59332 - val_acc: 0.7235 -- iter: 1443/1443
--
Training Step: 553  | total loss: [1m[32m0.49900[0m[0m | time: 0.642s
[2K
| RMSProp | epoch: 013 | loss: 0.49900 - acc: 0.7619 -- iter: 0032/1443
[A[ATraining Step: 554  | total loss: [1m[32m0.49232[0m[0m | time: 1.287s
[2K
| RMSProp | epoch: 013 | loss: 0.49232 - acc: 0.7607 -- iter: 0064/1443
[A[ATraining Step: 555  | total loss: [1m[32m0.47478[0m[0m | time: 1.919s
[2K
| RMSProp | epoch: 013 | loss: 0.47478 - acc: 0.7721 -- iter: 0096/1443
[A[ATraining Step: 556  | total loss: [1m[32m0.49290[0m[0m | time: 2.539s
[2K
| RMSProp | epoch: 013 | loss: 0.49290 - acc: 0.7668 -- iter: 0128/1443
[A[ATraining Step: 557  | total loss: [1m[32m0.53091[0m[0m | time: 3.145s
[2K
| RMSProp | epoch: 013 | loss: 0.53091 - acc: 0.7370 -- iter: 0160/1443
[A[ATraining Step: 558  | total loss: [1m[32m0.52773[0m[0m | time: 3.756s
[2K
| RMSProp | epoch: 013 | loss: 0.52773 - acc: 0.7383 -- iter: 0192/1443
[A[ATraining Step: 559  | total loss: [1m[32m0.51691[0m[0m | time: 4.359s
[2K
| RMSProp | epoch: 013 | loss: 0.51691 - acc: 0.7457 -- iter: 0224/1443
[A[ATraining Step: 560  | total loss: [1m[32m0.51390[0m[0m | time: 4.972s
[2K
| RMSProp | epoch: 013 | loss: 0.51390 - acc: 0.7493 -- iter: 0256/1443
[A[ATraining Step: 561  | total loss: [1m[32m0.49959[0m[0m | time: 5.582s
[2K
| RMSProp | epoch: 013 | loss: 0.49959 - acc: 0.7618 -- iter: 0288/1443
[A[ATraining Step: 562  | total loss: [1m[32m0.49748[0m[0m | time: 6.193s
[2K
| RMSProp | epoch: 013 | loss: 0.49748 - acc: 0.7607 -- iter: 0320/1443
[A[ATraining Step: 563  | total loss: [1m[32m0.49069[0m[0m | time: 6.280s
[2K
| RMSProp | epoch: 013 | loss: 0.49069 - acc: 0.7690 -- iter: 0352/1443
[A[ATraining Step: 564  | total loss: [1m[32m0.50463[0m[0m | time: 6.377s
[2K
| RMSProp | epoch: 013 | loss: 0.50463 - acc: 0.7587 -- iter: 0384/1443
[A[ATraining Step: 565  | total loss: [1m[32m0.48144[0m[0m | time: 6.991s
[2K
| RMSProp | epoch: 013 | loss: 0.48144 - acc: 0.7829 -- iter: 0416/1443
[A[ATraining Step: 566  | total loss: [1m[32m0.47028[0m[0m | time: 7.605s
[2K
| RMSProp | epoch: 013 | loss: 0.47028 - acc: 0.7921 -- iter: 0448/1443
[A[ATraining Step: 567  | total loss: [1m[32m0.47667[0m[0m | time: 8.223s
[2K
| RMSProp | epoch: 013 | loss: 0.47667 - acc: 0.7847 -- iter: 0480/1443
[A[ATraining Step: 568  | total loss: [1m[32m0.46374[0m[0m | time: 8.835s
[2K
| RMSProp | epoch: 013 | loss: 0.46374 - acc: 0.7906 -- iter: 0512/1443
[A[ATraining Step: 569  | total loss: [1m[32m0.48584[0m[0m | time: 9.455s
[2K
| RMSProp | epoch: 013 | loss: 0.48584 - acc: 0.7866 -- iter: 0544/1443
[A[ATraining Step: 570  | total loss: [1m[32m0.47504[0m[0m | time: 10.084s
[2K
| RMSProp | epoch: 013 | loss: 0.47504 - acc: 0.7923 -- iter: 0576/1443
[A[ATraining Step: 571  | total loss: [1m[32m0.47604[0m[0m | time: 10.709s
[2K
| RMSProp | epoch: 013 | loss: 0.47604 - acc: 0.7881 -- iter: 0608/1443
[A[ATraining Step: 572  | total loss: [1m[32m0.47071[0m[0m | time: 11.313s
[2K
| RMSProp | epoch: 013 | loss: 0.47071 - acc: 0.7905 -- iter: 0640/1443
[A[ATraining Step: 573  | total loss: [1m[32m0.48136[0m[0m | time: 11.933s
[2K
| RMSProp | epoch: 013 | loss: 0.48136 - acc: 0.7802 -- iter: 0672/1443
[A[ATraining Step: 574  | total loss: [1m[32m0.46273[0m[0m | time: 12.541s
[2K
| RMSProp | epoch: 013 | loss: 0.46273 - acc: 0.7991 -- iter: 0704/1443
[A[ATraining Step: 575  | total loss: [1m[32m0.44839[0m[0m | time: 13.142s
[2K
| RMSProp | epoch: 013 | loss: 0.44839 - acc: 0.8067 -- iter: 0736/1443
[A[ATraining Step: 576  | total loss: [1m[32m0.45415[0m[0m | time: 13.743s
[2K
| RMSProp | epoch: 013 | loss: 0.45415 - acc: 0.8010 -- iter: 0768/1443
[A[ATraining Step: 577  | total loss: [1m[32m0.46161[0m[0m | time: 14.350s
[2K
| RMSProp | epoch: 013 | loss: 0.46161 - acc: 0.7928 -- iter: 0800/1443
[A[ATraining Step: 578  | total loss: [1m[32m0.45278[0m[0m | time: 14.955s
[2K
| RMSProp | epoch: 013 | loss: 0.45278 - acc: 0.7979 -- iter: 0832/1443
[A[ATraining Step: 579  | total loss: [1m[32m0.49559[0m[0m | time: 15.583s
[2K
| RMSProp | epoch: 013 | loss: 0.49559 - acc: 0.7806 -- iter: 0864/1443
[A[ATraining Step: 580  | total loss: [1m[32m0.50268[0m[0m | time: 16.194s
[2K
| RMSProp | epoch: 013 | loss: 0.50268 - acc: 0.7713 -- iter: 0896/1443
[A[ATraining Step: 581  | total loss: [1m[32m0.49829[0m[0m | time: 16.802s
[2K
| RMSProp | epoch: 013 | loss: 0.49829 - acc: 0.7723 -- iter: 0928/1443
[A[ATraining Step: 582  | total loss: [1m[32m0.49305[0m[0m | time: 17.439s
[2K
| RMSProp | epoch: 013 | loss: 0.49305 - acc: 0.7732 -- iter: 0960/1443
[A[ATraining Step: 583  | total loss: [1m[32m0.49276[0m[0m | time: 18.041s
[2K
| RMSProp | epoch: 013 | loss: 0.49276 - acc: 0.7771 -- iter: 0992/1443
[A[ATraining Step: 584  | total loss: [1m[32m0.48287[0m[0m | time: 18.668s
[2K
| RMSProp | epoch: 013 | loss: 0.48287 - acc: 0.7900 -- iter: 1024/1443
[A[ATraining Step: 585  | total loss: [1m[32m0.48090[0m[0m | time: 19.281s
[2K
| RMSProp | epoch: 013 | loss: 0.48090 - acc: 0.7923 -- iter: 1056/1443
[A[ATraining Step: 586  | total loss: [1m[32m0.48072[0m[0m | time: 19.899s
[2K
| RMSProp | epoch: 013 | loss: 0.48072 - acc: 0.7974 -- iter: 1088/1443
[A[ATraining Step: 587  | total loss: [1m[32m0.47362[0m[0m | time: 20.496s
[2K
| RMSProp | epoch: 013 | loss: 0.47362 - acc: 0.8020 -- iter: 1120/1443
[A[ATraining Step: 588  | total loss: [1m[32m0.46718[0m[0m | time: 21.101s
[2K
| RMSProp | epoch: 013 | loss: 0.46718 - acc: 0.8062 -- iter: 1152/1443
[A[ATraining Step: 589  | total loss: [1m[32m0.45635[0m[0m | time: 21.752s
[2K
| RMSProp | epoch: 013 | loss: 0.45635 - acc: 0.8131 -- iter: 1184/1443
[A[ATraining Step: 590  | total loss: [1m[32m0.44447[0m[0m | time: 22.362s
[2K
| RMSProp | epoch: 013 | loss: 0.44447 - acc: 0.8162 -- iter: 1216/1443
[A[ATraining Step: 591  | total loss: [1m[32m0.42454[0m[0m | time: 22.980s
[2K
| RMSProp | epoch: 013 | loss: 0.42454 - acc: 0.8189 -- iter: 1248/1443
[A[ATraining Step: 592  | total loss: [1m[32m0.42704[0m[0m | time: 23.584s
[2K
| RMSProp | epoch: 013 | loss: 0.42704 - acc: 0.8152 -- iter: 1280/1443
[A[ATraining Step: 593  | total loss: [1m[32m0.43139[0m[0m | time: 24.190s
[2K
| RMSProp | epoch: 013 | loss: 0.43139 - acc: 0.8118 -- iter: 1312/1443
[A[ATraining Step: 594  | total loss: [1m[32m0.43364[0m[0m | time: 24.792s
[2K
| RMSProp | epoch: 013 | loss: 0.43364 - acc: 0.8025 -- iter: 1344/1443
[A[ATraining Step: 595  | total loss: [1m[32m0.43319[0m[0m | time: 25.396s
[2K
| RMSProp | epoch: 013 | loss: 0.43319 - acc: 0.8066 -- iter: 1376/1443
[A[ATraining Step: 596  | total loss: [1m[32m0.43285[0m[0m | time: 25.991s
[2K
| RMSProp | epoch: 013 | loss: 0.43285 - acc: 0.8041 -- iter: 1408/1443
[A[ATraining Step: 597  | total loss: [1m[32m0.42171[0m[0m | time: 26.599s
[2K
| RMSProp | epoch: 013 | loss: 0.42171 - acc: 0.8174 -- iter: 1440/1443
[A[ATraining Step: 598  | total loss: [1m[32m0.41375[0m[0m | time: 28.632s
[2K
| RMSProp | epoch: 013 | loss: 0.41375 - acc: 0.8232 | val_loss: 0.60520 - val_acc: 0.7146 -- iter: 1443/1443
--
Training Step: 599  | total loss: [1m[32m0.43412[0m[0m | time: 0.605s
[2K
| RMSProp | epoch: 014 | loss: 0.43412 - acc: 0.8096 -- iter: 0032/1443
[A[ATraining Step: 600  | total loss: [1m[32m0.43568[0m[0m | time: 2.631s
[2K
| RMSProp | epoch: 014 | loss: 0.43568 - acc: 0.8036 | val_loss: 0.63151 - val_acc: 0.7102 -- iter: 0064/1443
--
Training Step: 601  | total loss: [1m[32m0.43764[0m[0m | time: 3.240s
[2K
| RMSProp | epoch: 014 | loss: 0.43764 - acc: 0.7951 -- iter: 0096/1443
[A[ATraining Step: 602  | total loss: [1m[32m0.47383[0m[0m | time: 3.841s
[2K
| RMSProp | epoch: 014 | loss: 0.47383 - acc: 0.7719 -- iter: 0128/1443
[A[ATraining Step: 603  | total loss: [1m[32m0.47541[0m[0m | time: 4.456s
[2K
| RMSProp | epoch: 014 | loss: 0.47541 - acc: 0.7759 -- iter: 0160/1443
[A[ATraining Step: 604  | total loss: [1m[32m0.47418[0m[0m | time: 5.061s
[2K
| RMSProp | epoch: 014 | loss: 0.47418 - acc: 0.7827 -- iter: 0192/1443
[A[ATraining Step: 605  | total loss: [1m[32m0.46259[0m[0m | time: 5.680s
[2K
| RMSProp | epoch: 014 | loss: 0.46259 - acc: 0.7888 -- iter: 0224/1443
[A[ATraining Step: 606  | total loss: [1m[32m0.45438[0m[0m | time: 6.294s
[2K
| RMSProp | epoch: 014 | loss: 0.45438 - acc: 0.8037 -- iter: 0256/1443
[A[ATraining Step: 607  | total loss: [1m[32m0.45209[0m[0m | time: 6.899s
[2K
| RMSProp | epoch: 014 | loss: 0.45209 - acc: 0.8046 -- iter: 0288/1443
[A[ATraining Step: 608  | total loss: [1m[32m0.45842[0m[0m | time: 7.527s
[2K
| RMSProp | epoch: 014 | loss: 0.45842 - acc: 0.7991 -- iter: 0320/1443
[A[ATraining Step: 609  | total loss: [1m[32m0.45514[0m[0m | time: 8.157s
[2K
| RMSProp | epoch: 014 | loss: 0.45514 - acc: 0.7973 -- iter: 0352/1443
[A[ATraining Step: 610  | total loss: [1m[32m0.44014[0m[0m | time: 8.246s
[2K
| RMSProp | epoch: 014 | loss: 0.44014 - acc: 0.8051 -- iter: 0384/1443
[A[ATraining Step: 611  | total loss: [1m[32m0.47981[0m[0m | time: 8.335s
[2K
| RMSProp | epoch: 014 | loss: 0.47981 - acc: 0.7913 -- iter: 0416/1443
[A[ATraining Step: 612  | total loss: [1m[32m0.44490[0m[0m | time: 8.944s
[2K
| RMSProp | epoch: 014 | loss: 0.44490 - acc: 0.8121 -- iter: 0448/1443
[A[ATraining Step: 613  | total loss: [1m[32m0.43413[0m[0m | time: 9.558s
[2K
| RMSProp | epoch: 014 | loss: 0.43413 - acc: 0.8184 -- iter: 0480/1443
[A[ATraining Step: 614  | total loss: [1m[32m0.45013[0m[0m | time: 10.172s
[2K
| RMSProp | epoch: 014 | loss: 0.45013 - acc: 0.8084 -- iter: 0512/1443
[A[ATraining Step: 615  | total loss: [1m[32m0.43146[0m[0m | time: 10.802s
[2K
| RMSProp | epoch: 014 | loss: 0.43146 - acc: 0.8182 -- iter: 0544/1443
[A[ATraining Step: 616  | total loss: [1m[32m0.43985[0m[0m | time: 11.412s
[2K
| RMSProp | epoch: 014 | loss: 0.43985 - acc: 0.8083 -- iter: 0576/1443
[A[ATraining Step: 617  | total loss: [1m[32m0.44559[0m[0m | time: 12.047s
[2K
| RMSProp | epoch: 014 | loss: 0.44559 - acc: 0.8056 -- iter: 0608/1443
[A[ATraining Step: 618  | total loss: [1m[32m0.43644[0m[0m | time: 12.670s
[2K
| RMSProp | epoch: 014 | loss: 0.43644 - acc: 0.8125 -- iter: 0640/1443
[A[ATraining Step: 619  | total loss: [1m[32m0.44478[0m[0m | time: 13.285s
[2K
| RMSProp | epoch: 014 | loss: 0.44478 - acc: 0.8125 -- iter: 0672/1443
[A[ATraining Step: 620  | total loss: [1m[32m0.46064[0m[0m | time: 13.904s
[2K
| RMSProp | epoch: 014 | loss: 0.46064 - acc: 0.8000 -- iter: 0704/1443
[A[ATraining Step: 621  | total loss: [1m[32m0.46063[0m[0m | time: 14.516s
[2K
| RMSProp | epoch: 014 | loss: 0.46063 - acc: 0.8013 -- iter: 0736/1443
[A[ATraining Step: 622  | total loss: [1m[32m0.45028[0m[0m | time: 15.169s
[2K
| RMSProp | epoch: 014 | loss: 0.45028 - acc: 0.8055 -- iter: 0768/1443
[A[ATraining Step: 623  | total loss: [1m[32m0.44856[0m[0m | time: 15.798s
[2K
| RMSProp | epoch: 014 | loss: 0.44856 - acc: 0.8062 -- iter: 0800/1443
[A[ATraining Step: 624  | total loss: [1m[32m0.46860[0m[0m | time: 16.412s
[2K
| RMSProp | epoch: 014 | loss: 0.46860 - acc: 0.7850 -- iter: 0832/1443
[A[ATraining Step: 625  | total loss: [1m[32m0.46487[0m[0m | time: 17.037s
[2K
| RMSProp | epoch: 014 | loss: 0.46487 - acc: 0.7846 -- iter: 0864/1443
[A[ATraining Step: 626  | total loss: [1m[32m0.46198[0m[0m | time: 17.642s
[2K
| RMSProp | epoch: 014 | loss: 0.46198 - acc: 0.7936 -- iter: 0896/1443
[A[ATraining Step: 627  | total loss: [1m[32m0.46719[0m[0m | time: 18.288s
[2K
| RMSProp | epoch: 014 | loss: 0.46719 - acc: 0.7924 -- iter: 0928/1443
[A[ATraining Step: 628  | total loss: [1m[32m0.45929[0m[0m | time: 18.900s
[2K
| RMSProp | epoch: 014 | loss: 0.45929 - acc: 0.7882 -- iter: 0960/1443
[A[ATraining Step: 629  | total loss: [1m[32m0.45276[0m[0m | time: 19.520s
[2K
| RMSProp | epoch: 014 | loss: 0.45276 - acc: 0.7968 -- iter: 0992/1443
[A[ATraining Step: 630  | total loss: [1m[32m0.44334[0m[0m | time: 20.160s
[2K
| RMSProp | epoch: 014 | loss: 0.44334 - acc: 0.8047 -- iter: 1024/1443
[A[ATraining Step: 631  | total loss: [1m[32m0.44175[0m[0m | time: 20.816s
[2K
| RMSProp | epoch: 014 | loss: 0.44175 - acc: 0.8086 -- iter: 1056/1443
[A[ATraining Step: 632  | total loss: [1m[32m0.42816[0m[0m | time: 21.435s
[2K
| RMSProp | epoch: 014 | loss: 0.42816 - acc: 0.8152 -- iter: 1088/1443
[A[ATraining Step: 633  | total loss: [1m[32m0.43156[0m[0m | time: 22.063s
[2K
| RMSProp | epoch: 014 | loss: 0.43156 - acc: 0.8149 -- iter: 1120/1443
[A[ATraining Step: 634  | total loss: [1m[32m0.43528[0m[0m | time: 22.679s
[2K
| RMSProp | epoch: 014 | loss: 0.43528 - acc: 0.8116 -- iter: 1152/1443
[A[ATraining Step: 635  | total loss: [1m[32m0.42971[0m[0m | time: 23.294s
[2K
| RMSProp | epoch: 014 | loss: 0.42971 - acc: 0.8179 -- iter: 1184/1443
[A[ATraining Step: 636  | total loss: [1m[32m0.43254[0m[0m | time: 23.903s
[2K
| RMSProp | epoch: 014 | loss: 0.43254 - acc: 0.8174 -- iter: 1216/1443
[A[ATraining Step: 637  | total loss: [1m[32m0.41771[0m[0m | time: 24.512s
[2K
| RMSProp | epoch: 014 | loss: 0.41771 - acc: 0.8263 -- iter: 1248/1443
[A[ATraining Step: 638  | total loss: [1m[32m0.42458[0m[0m | time: 25.114s
[2K
| RMSProp | epoch: 014 | loss: 0.42458 - acc: 0.8218 -- iter: 1280/1443
[A[ATraining Step: 639  | total loss: [1m[32m0.42943[0m[0m | time: 25.738s
[2K
| RMSProp | epoch: 014 | loss: 0.42943 - acc: 0.8177 -- iter: 1312/1443
[A[ATraining Step: 640  | total loss: [1m[32m0.45088[0m[0m | time: 26.383s
[2K
| RMSProp | epoch: 014 | loss: 0.45088 - acc: 0.8047 -- iter: 1344/1443
[A[ATraining Step: 641  | total loss: [1m[32m0.44696[0m[0m | time: 27.014s
[2K
| RMSProp | epoch: 014 | loss: 0.44696 - acc: 0.8117 -- iter: 1376/1443
[A[ATraining Step: 642  | total loss: [1m[32m0.43955[0m[0m | time: 27.615s
[2K
| RMSProp | epoch: 014 | loss: 0.43955 - acc: 0.8149 -- iter: 1408/1443
[A[ATraining Step: 643  | total loss: [1m[32m0.42879[0m[0m | time: 28.227s
[2K
| RMSProp | epoch: 014 | loss: 0.42879 - acc: 0.8209 -- iter: 1440/1443
[A[ATraining Step: 644  | total loss: [1m[32m0.41649[0m[0m | time: 30.257s
[2K
| RMSProp | epoch: 014 | loss: 0.41649 - acc: 0.8201 | val_loss: 0.60246 - val_acc: 0.7080 -- iter: 1443/1443
--
Training Step: 645  | total loss: [1m[32m0.41936[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 015 | loss: 0.41936 - acc: 0.8193 -- iter: 0032/1443
[A[ATraining Step: 646  | total loss: [1m[32m0.40768[0m[0m | time: 1.221s
[2K
| RMSProp | epoch: 015 | loss: 0.40768 - acc: 0.8249 -- iter: 0064/1443
[A[ATraining Step: 647  | total loss: [1m[32m0.40856[0m[0m | time: 1.831s
[2K
| RMSProp | epoch: 015 | loss: 0.40856 - acc: 0.8268 -- iter: 0096/1443
[A[ATraining Step: 648  | total loss: [1m[32m0.42220[0m[0m | time: 2.432s
[2K
| RMSProp | epoch: 015 | loss: 0.42220 - acc: 0.8129 -- iter: 0128/1443
[A[ATraining Step: 649  | total loss: [1m[32m0.44269[0m[0m | time: 3.065s
[2K
| RMSProp | epoch: 015 | loss: 0.44269 - acc: 0.8003 -- iter: 0160/1443
[A[ATraining Step: 650  | total loss: [1m[32m0.43646[0m[0m | time: 3.666s
[2K
| RMSProp | epoch: 015 | loss: 0.43646 - acc: 0.8078 -- iter: 0192/1443
[A[ATraining Step: 651  | total loss: [1m[32m0.44523[0m[0m | time: 4.278s
[2K
| RMSProp | epoch: 015 | loss: 0.44523 - acc: 0.8020 -- iter: 0224/1443
[A[ATraining Step: 652  | total loss: [1m[32m0.44320[0m[0m | time: 4.882s
[2K
| RMSProp | epoch: 015 | loss: 0.44320 - acc: 0.7968 -- iter: 0256/1443
[A[ATraining Step: 653  | total loss: [1m[32m0.42983[0m[0m | time: 5.529s
[2K
| RMSProp | epoch: 015 | loss: 0.42983 - acc: 0.8078 -- iter: 0288/1443
[A[ATraining Step: 654  | total loss: [1m[32m0.42941[0m[0m | time: 6.160s
[2K
| RMSProp | epoch: 015 | loss: 0.42941 - acc: 0.8145 -- iter: 0320/1443
[A[ATraining Step: 655  | total loss: [1m[32m0.44505[0m[0m | time: 6.776s
[2K
| RMSProp | epoch: 015 | loss: 0.44505 - acc: 0.8049 -- iter: 0352/1443
[A[ATraining Step: 656  | total loss: [1m[32m0.44357[0m[0m | time: 7.388s
[2K
| RMSProp | epoch: 015 | loss: 0.44357 - acc: 0.8025 -- iter: 0384/1443
[A[ATraining Step: 657  | total loss: [1m[32m0.43372[0m[0m | time: 7.474s
[2K
| RMSProp | epoch: 015 | loss: 0.43372 - acc: 0.8098 -- iter: 0416/1443
[A[ATraining Step: 658  | total loss: [1m[32m0.40008[0m[0m | time: 7.563s
[2K
| RMSProp | epoch: 015 | loss: 0.40008 - acc: 0.8288 -- iter: 0448/1443
[A[ATraining Step: 659  | total loss: [1m[32m0.36322[0m[0m | time: 8.161s
[2K
| RMSProp | epoch: 015 | loss: 0.36322 - acc: 0.8459 -- iter: 0480/1443
[A[ATraining Step: 660  | total loss: [1m[32m0.35478[0m[0m | time: 8.777s
[2K
| RMSProp | epoch: 015 | loss: 0.35478 - acc: 0.8520 -- iter: 0512/1443
[A[ATraining Step: 661  | total loss: [1m[32m0.39749[0m[0m | time: 9.390s
[2K
| RMSProp | epoch: 015 | loss: 0.39749 - acc: 0.8355 -- iter: 0544/1443
[A[ATraining Step: 662  | total loss: [1m[32m0.40252[0m[0m | time: 10.012s
[2K
| RMSProp | epoch: 015 | loss: 0.40252 - acc: 0.8332 -- iter: 0576/1443
[A[ATraining Step: 663  | total loss: [1m[32m0.40225[0m[0m | time: 10.621s
[2K
| RMSProp | epoch: 015 | loss: 0.40225 - acc: 0.8343 -- iter: 0608/1443
[A[ATraining Step: 664  | total loss: [1m[32m0.42324[0m[0m | time: 11.237s
[2K
| RMSProp | epoch: 015 | loss: 0.42324 - acc: 0.8165 -- iter: 0640/1443
[A[ATraining Step: 665  | total loss: [1m[32m0.40795[0m[0m | time: 11.859s
[2K
| RMSProp | epoch: 015 | loss: 0.40795 - acc: 0.8192 -- iter: 0672/1443
[A[ATraining Step: 666  | total loss: [1m[32m0.40738[0m[0m | time: 12.483s
[2K
| RMSProp | epoch: 015 | loss: 0.40738 - acc: 0.8248 -- iter: 0704/1443
[A[ATraining Step: 667  | total loss: [1m[32m0.39887[0m[0m | time: 13.123s
[2K
| RMSProp | epoch: 015 | loss: 0.39887 - acc: 0.8329 -- iter: 0736/1443
[A[ATraining Step: 668  | total loss: [1m[32m0.39655[0m[0m | time: 13.733s
[2K
| RMSProp | epoch: 015 | loss: 0.39655 - acc: 0.8340 -- iter: 0768/1443
[A[ATraining Step: 669  | total loss: [1m[32m0.38060[0m[0m | time: 14.349s
[2K
| RMSProp | epoch: 015 | loss: 0.38060 - acc: 0.8412 -- iter: 0800/1443
[A[ATraining Step: 670  | total loss: [1m[32m0.38538[0m[0m | time: 14.956s
[2K
| RMSProp | epoch: 015 | loss: 0.38538 - acc: 0.8446 -- iter: 0832/1443
[A[ATraining Step: 671  | total loss: [1m[32m0.38929[0m[0m | time: 15.578s
[2K
| RMSProp | epoch: 015 | loss: 0.38929 - acc: 0.8414 -- iter: 0864/1443
[A[ATraining Step: 672  | total loss: [1m[32m0.36712[0m[0m | time: 16.204s
[2K
| RMSProp | epoch: 015 | loss: 0.36712 - acc: 0.8541 -- iter: 0896/1443
[A[ATraining Step: 673  | total loss: [1m[32m0.39408[0m[0m | time: 16.820s
[2K
| RMSProp | epoch: 015 | loss: 0.39408 - acc: 0.8500 -- iter: 0928/1443
[A[ATraining Step: 674  | total loss: [1m[32m0.41698[0m[0m | time: 17.451s
[2K
| RMSProp | epoch: 015 | loss: 0.41698 - acc: 0.8275 -- iter: 0960/1443
[A[ATraining Step: 675  | total loss: [1m[32m0.43189[0m[0m | time: 18.057s
[2K
| RMSProp | epoch: 015 | loss: 0.43189 - acc: 0.8103 -- iter: 0992/1443
[A[ATraining Step: 676  | total loss: [1m[32m0.42548[0m[0m | time: 18.669s
[2K
| RMSProp | epoch: 015 | loss: 0.42548 - acc: 0.8199 -- iter: 1024/1443
[A[ATraining Step: 677  | total loss: [1m[32m0.41746[0m[0m | time: 19.281s
[2K
| RMSProp | epoch: 015 | loss: 0.41746 - acc: 0.8254 -- iter: 1056/1443
[A[ATraining Step: 678  | total loss: [1m[32m0.40771[0m[0m | time: 19.894s
[2K
| RMSProp | epoch: 015 | loss: 0.40771 - acc: 0.8335 -- iter: 1088/1443
[A[ATraining Step: 679  | total loss: [1m[32m0.39838[0m[0m | time: 20.518s
[2K
| RMSProp | epoch: 015 | loss: 0.39838 - acc: 0.8439 -- iter: 1120/1443
[A[ATraining Step: 680  | total loss: [1m[32m0.39456[0m[0m | time: 21.124s
[2K
| RMSProp | epoch: 015 | loss: 0.39456 - acc: 0.8470 -- iter: 1152/1443
[A[ATraining Step: 681  | total loss: [1m[32m0.37757[0m[0m | time: 21.731s
[2K
| RMSProp | epoch: 015 | loss: 0.37757 - acc: 0.8592 -- iter: 1184/1443
[A[ATraining Step: 682  | total loss: [1m[32m0.39221[0m[0m | time: 22.344s
[2K
| RMSProp | epoch: 015 | loss: 0.39221 - acc: 0.8514 -- iter: 1216/1443
[A[ATraining Step: 683  | total loss: [1m[32m0.40153[0m[0m | time: 22.963s
[2K
| RMSProp | epoch: 015 | loss: 0.40153 - acc: 0.8475 -- iter: 1248/1443
[A[ATraining Step: 684  | total loss: [1m[32m0.40157[0m[0m | time: 23.574s
[2K
| RMSProp | epoch: 015 | loss: 0.40157 - acc: 0.8440 -- iter: 1280/1443
[A[ATraining Step: 685  | total loss: [1m[32m0.42318[0m[0m | time: 24.190s
[2K
| RMSProp | epoch: 015 | loss: 0.42318 - acc: 0.8346 -- iter: 1312/1443
[A[ATraining Step: 686  | total loss: [1m[32m0.40731[0m[0m | time: 24.806s
[2K
| RMSProp | epoch: 015 | loss: 0.40731 - acc: 0.8418 -- iter: 1344/1443
[A[ATraining Step: 687  | total loss: [1m[32m0.40706[0m[0m | time: 25.445s
[2K
| RMSProp | epoch: 015 | loss: 0.40706 - acc: 0.8388 -- iter: 1376/1443
[A[ATraining Step: 688  | total loss: [1m[32m0.39015[0m[0m | time: 26.065s
[2K
| RMSProp | epoch: 015 | loss: 0.39015 - acc: 0.8487 -- iter: 1408/1443
[A[ATraining Step: 689  | total loss: [1m[32m0.39233[0m[0m | time: 26.689s
[2K
| RMSProp | epoch: 015 | loss: 0.39233 - acc: 0.8482 -- iter: 1440/1443
[A[ATraining Step: 690  | total loss: [1m[32m0.39718[0m[0m | time: 28.744s
[2K
| RMSProp | epoch: 015 | loss: 0.39718 - acc: 0.8415 | val_loss: 0.63901 - val_acc: 0.6704 -- iter: 1443/1443
--
Training Step: 691  | total loss: [1m[32m0.40792[0m[0m | time: 0.630s
[2K
| RMSProp | epoch: 016 | loss: 0.40792 - acc: 0.8261 -- iter: 0032/1443
[A[ATraining Step: 692  | total loss: [1m[32m0.41637[0m[0m | time: 1.246s
[2K
| RMSProp | epoch: 016 | loss: 0.41637 - acc: 0.8216 -- iter: 0064/1443
[A[ATraining Step: 693  | total loss: [1m[32m0.40170[0m[0m | time: 1.866s
[2K
| RMSProp | epoch: 016 | loss: 0.40170 - acc: 0.8332 -- iter: 0096/1443
[A[ATraining Step: 694  | total loss: [1m[32m0.40498[0m[0m | time: 2.475s
[2K
| RMSProp | epoch: 016 | loss: 0.40498 - acc: 0.8280 -- iter: 0128/1443
[A[ATraining Step: 695  | total loss: [1m[32m0.40879[0m[0m | time: 3.121s
[2K
| RMSProp | epoch: 016 | loss: 0.40879 - acc: 0.8202 -- iter: 0160/1443
[A[ATraining Step: 696  | total loss: [1m[32m0.39644[0m[0m | time: 3.728s
[2K
| RMSProp | epoch: 016 | loss: 0.39644 - acc: 0.8257 -- iter: 0192/1443
[A[ATraining Step: 697  | total loss: [1m[32m0.39419[0m[0m | time: 4.339s
[2K
| RMSProp | epoch: 016 | loss: 0.39419 - acc: 0.8275 -- iter: 0224/1443
[A[ATraining Step: 698  | total loss: [1m[32m0.40596[0m[0m | time: 4.955s
[2K
| RMSProp | epoch: 016 | loss: 0.40596 - acc: 0.8229 -- iter: 0256/1443
[A[ATraining Step: 699  | total loss: [1m[32m0.43836[0m[0m | time: 5.578s
[2K
| RMSProp | epoch: 016 | loss: 0.43836 - acc: 0.7968 -- iter: 0288/1443
[A[ATraining Step: 700  | total loss: [1m[32m0.42969[0m[0m | time: 6.211s
[2K
| RMSProp | epoch: 016 | loss: 0.42969 - acc: 0.7984 -- iter: 0320/1443
[A[ATraining Step: 701  | total loss: [1m[32m0.41392[0m[0m | time: 6.815s
[2K
| RMSProp | epoch: 016 | loss: 0.41392 - acc: 0.8123 -- iter: 0352/1443
[A[ATraining Step: 702  | total loss: [1m[32m0.40751[0m[0m | time: 7.468s
[2K
| RMSProp | epoch: 016 | loss: 0.40751 - acc: 0.8186 -- iter: 0384/1443
[A[ATraining Step: 703  | total loss: [1m[32m0.38896[0m[0m | time: 8.082s
[2K
| RMSProp | epoch: 016 | loss: 0.38896 - acc: 0.8305 -- iter: 0416/1443
[A[ATraining Step: 704  | total loss: [1m[32m0.39949[0m[0m | time: 8.179s
[2K
| RMSProp | epoch: 016 | loss: 0.39949 - acc: 0.8287 -- iter: 0448/1443
[A[ATraining Step: 705  | total loss: [1m[32m0.37385[0m[0m | time: 8.279s
[2K
| RMSProp | epoch: 016 | loss: 0.37385 - acc: 0.8458 -- iter: 0480/1443
[A[ATraining Step: 706  | total loss: [1m[32m0.33968[0m[0m | time: 8.903s
[2K
| RMSProp | epoch: 016 | loss: 0.33968 - acc: 0.8612 -- iter: 0512/1443
[A[ATraining Step: 707  | total loss: [1m[32m0.31938[0m[0m | time: 9.524s
[2K
| RMSProp | epoch: 016 | loss: 0.31938 - acc: 0.8657 -- iter: 0544/1443
[A[ATraining Step: 708  | total loss: [1m[32m0.32942[0m[0m | time: 10.136s
[2K
| RMSProp | epoch: 016 | loss: 0.32942 - acc: 0.8635 -- iter: 0576/1443
[A[ATraining Step: 709  | total loss: [1m[32m0.39381[0m[0m | time: 10.744s
[2K
| RMSProp | epoch: 016 | loss: 0.39381 - acc: 0.8366 -- iter: 0608/1443
[A[ATraining Step: 710  | total loss: [1m[32m0.39085[0m[0m | time: 11.356s
[2K
| RMSProp | epoch: 016 | loss: 0.39085 - acc: 0.8373 -- iter: 0640/1443
[A[ATraining Step: 711  | total loss: [1m[32m0.39906[0m[0m | time: 11.984s
[2K
| RMSProp | epoch: 016 | loss: 0.39906 - acc: 0.8317 -- iter: 0672/1443
[A[ATraining Step: 712  | total loss: [1m[32m0.38441[0m[0m | time: 12.621s
[2K
| RMSProp | epoch: 016 | loss: 0.38441 - acc: 0.8423 -- iter: 0704/1443
[A[ATraining Step: 713  | total loss: [1m[32m0.39369[0m[0m | time: 13.241s
[2K
| RMSProp | epoch: 016 | loss: 0.39369 - acc: 0.8362 -- iter: 0736/1443
[A[ATraining Step: 714  | total loss: [1m[32m0.38386[0m[0m | time: 13.868s
[2K
| RMSProp | epoch: 016 | loss: 0.38386 - acc: 0.8400 -- iter: 0768/1443
[A[ATraining Step: 715  | total loss: [1m[32m0.36988[0m[0m | time: 14.476s
[2K
| RMSProp | epoch: 016 | loss: 0.36988 - acc: 0.8498 -- iter: 0800/1443
[A[ATraining Step: 716  | total loss: [1m[32m0.37249[0m[0m | time: 15.081s
[2K
| RMSProp | epoch: 016 | loss: 0.37249 - acc: 0.8492 -- iter: 0832/1443
[A[ATraining Step: 717  | total loss: [1m[32m0.36396[0m[0m | time: 15.693s
[2K
| RMSProp | epoch: 016 | loss: 0.36396 - acc: 0.8518 -- iter: 0864/1443
[A[ATraining Step: 718  | total loss: [1m[32m0.39561[0m[0m | time: 16.306s
[2K
| RMSProp | epoch: 016 | loss: 0.39561 - acc: 0.8385 -- iter: 0896/1443
[A[ATraining Step: 719  | total loss: [1m[32m0.38381[0m[0m | time: 16.925s
[2K
| RMSProp | epoch: 016 | loss: 0.38381 - acc: 0.8452 -- iter: 0928/1443
[A[ATraining Step: 720  | total loss: [1m[32m0.39201[0m[0m | time: 17.535s
[2K
| RMSProp | epoch: 016 | loss: 0.39201 - acc: 0.8388 -- iter: 0960/1443
[A[ATraining Step: 721  | total loss: [1m[32m0.38303[0m[0m | time: 18.137s
[2K
| RMSProp | epoch: 016 | loss: 0.38303 - acc: 0.8393 -- iter: 0992/1443
[A[ATraining Step: 722  | total loss: [1m[32m0.37285[0m[0m | time: 18.748s
[2K
| RMSProp | epoch: 016 | loss: 0.37285 - acc: 0.8429 -- iter: 1024/1443
[A[ATraining Step: 723  | total loss: [1m[32m0.35299[0m[0m | time: 19.364s
[2K
| RMSProp | epoch: 016 | loss: 0.35299 - acc: 0.8555 -- iter: 1056/1443
[A[ATraining Step: 724  | total loss: [1m[32m0.34208[0m[0m | time: 19.991s
[2K
| RMSProp | epoch: 016 | loss: 0.34208 - acc: 0.8606 -- iter: 1088/1443
[A[ATraining Step: 725  | total loss: [1m[32m0.34624[0m[0m | time: 20.620s
[2K
| RMSProp | epoch: 016 | loss: 0.34624 - acc: 0.8620 -- iter: 1120/1443
[A[ATraining Step: 726  | total loss: [1m[32m0.40034[0m[0m | time: 21.235s
[2K
| RMSProp | epoch: 016 | loss: 0.40034 - acc: 0.8446 -- iter: 1152/1443
[A[ATraining Step: 727  | total loss: [1m[32m0.39112[0m[0m | time: 21.852s
[2K
| RMSProp | epoch: 016 | loss: 0.39112 - acc: 0.8445 -- iter: 1184/1443
[A[ATraining Step: 728  | total loss: [1m[32m0.38169[0m[0m | time: 22.488s
[2K
| RMSProp | epoch: 016 | loss: 0.38169 - acc: 0.8507 -- iter: 1216/1443
[A[ATraining Step: 729  | total loss: [1m[32m0.36098[0m[0m | time: 23.113s
[2K
| RMSProp | epoch: 016 | loss: 0.36098 - acc: 0.8593 -- iter: 1248/1443
[A[ATraining Step: 730  | total loss: [1m[32m0.34676[0m[0m | time: 23.725s
[2K
| RMSProp | epoch: 016 | loss: 0.34676 - acc: 0.8640 -- iter: 1280/1443
[A[ATraining Step: 731  | total loss: [1m[32m0.37714[0m[0m | time: 24.369s
[2K
| RMSProp | epoch: 016 | loss: 0.37714 - acc: 0.8464 -- iter: 1312/1443
[A[ATraining Step: 732  | total loss: [1m[32m0.37473[0m[0m | time: 24.988s
[2K
| RMSProp | epoch: 016 | loss: 0.37473 - acc: 0.8461 -- iter: 1344/1443
[A[ATraining Step: 733  | total loss: [1m[32m0.36119[0m[0m | time: 25.626s
[2K
| RMSProp | epoch: 016 | loss: 0.36119 - acc: 0.8490 -- iter: 1376/1443
[A[ATraining Step: 734  | total loss: [1m[32m0.35428[0m[0m | time: 26.256s
[2K
| RMSProp | epoch: 016 | loss: 0.35428 - acc: 0.8485 -- iter: 1408/1443
[A[ATraining Step: 735  | total loss: [1m[32m0.35594[0m[0m | time: 26.870s
[2K
| RMSProp | epoch: 016 | loss: 0.35594 - acc: 0.8543 -- iter: 1440/1443
[A[ATraining Step: 736  | total loss: [1m[32m0.34328[0m[0m | time: 28.970s
[2K
| RMSProp | epoch: 016 | loss: 0.34328 - acc: 0.8595 | val_loss: 0.92973 - val_acc: 0.5863 -- iter: 1443/1443
--
Training Step: 737  | total loss: [1m[32m0.34587[0m[0m | time: 0.644s
[2K
| RMSProp | epoch: 017 | loss: 0.34587 - acc: 0.8516 -- iter: 0032/1443
[A[ATraining Step: 738  | total loss: [1m[32m0.37883[0m[0m | time: 1.276s
[2K
| RMSProp | epoch: 017 | loss: 0.37883 - acc: 0.8352 -- iter: 0064/1443
[A[ATraining Step: 739  | total loss: [1m[32m0.37024[0m[0m | time: 1.911s
[2K
| RMSProp | epoch: 017 | loss: 0.37024 - acc: 0.8392 -- iter: 0096/1443
[A[ATraining Step: 740  | total loss: [1m[32m0.36758[0m[0m | time: 2.547s
[2K
| RMSProp | epoch: 017 | loss: 0.36758 - acc: 0.8428 -- iter: 0128/1443
[A[ATraining Step: 741  | total loss: [1m[32m0.34962[0m[0m | time: 3.215s
[2K
| RMSProp | epoch: 017 | loss: 0.34962 - acc: 0.8523 -- iter: 0160/1443
[A[ATraining Step: 742  | total loss: [1m[32m0.35205[0m[0m | time: 3.896s
[2K
| RMSProp | epoch: 017 | loss: 0.35205 - acc: 0.8514 -- iter: 0192/1443
[A[ATraining Step: 743  | total loss: [1m[32m0.35770[0m[0m | time: 4.548s
[2K
| RMSProp | epoch: 017 | loss: 0.35770 - acc: 0.8444 -- iter: 0224/1443
[A[ATraining Step: 744  | total loss: [1m[32m0.35949[0m[0m | time: 5.183s
[2K
| RMSProp | epoch: 017 | loss: 0.35949 - acc: 0.8443 -- iter: 0256/1443
[A[ATraining Step: 745  | total loss: [1m[32m0.37440[0m[0m | time: 5.827s
[2K
| RMSProp | epoch: 017 | loss: 0.37440 - acc: 0.8411 -- iter: 0288/1443
[A[ATraining Step: 746  | total loss: [1m[32m0.38487[0m[0m | time: 6.469s
[2K
| RMSProp | epoch: 017 | loss: 0.38487 - acc: 0.8383 -- iter: 0320/1443
[A[ATraining Step: 747  | total loss: [1m[32m0.37294[0m[0m | time: 7.080s
[2K
| RMSProp | epoch: 017 | loss: 0.37294 - acc: 0.8451 -- iter: 0352/1443
[A[ATraining Step: 748  | total loss: [1m[32m0.36967[0m[0m | time: 7.701s
[2K
| RMSProp | epoch: 017 | loss: 0.36967 - acc: 0.8387 -- iter: 0384/1443
[A[ATraining Step: 749  | total loss: [1m[32m0.35990[0m[0m | time: 8.333s
[2K
| RMSProp | epoch: 017 | loss: 0.35990 - acc: 0.8423 -- iter: 0416/1443
[A[ATraining Step: 750  | total loss: [1m[32m0.35410[0m[0m | time: 8.970s
[2K
| RMSProp | epoch: 017 | loss: 0.35410 - acc: 0.8456 -- iter: 0448/1443
[A[ATraining Step: 751  | total loss: [1m[32m0.35500[0m[0m | time: 9.056s
[2K
| RMSProp | epoch: 017 | loss: 0.35500 - acc: 0.8423 -- iter: 0480/1443
[A[ATraining Step: 752  | total loss: [1m[32m0.35219[0m[0m | time: 9.149s
[2K
| RMSProp | epoch: 017 | loss: 0.35219 - acc: 0.8581 -- iter: 0512/1443
[A[ATraining Step: 753  | total loss: [1m[32m0.32061[0m[0m | time: 9.764s
[2K
| RMSProp | epoch: 017 | loss: 0.32061 - acc: 0.8722 -- iter: 0544/1443
[A[ATraining Step: 754  | total loss: [1m[32m0.34145[0m[0m | time: 10.400s
[2K
| RMSProp | epoch: 017 | loss: 0.34145 - acc: 0.8725 -- iter: 0576/1443
[A[ATraining Step: 755  | total loss: [1m[32m0.35644[0m[0m | time: 11.011s
[2K
| RMSProp | epoch: 017 | loss: 0.35644 - acc: 0.8634 -- iter: 0608/1443
[A[ATraining Step: 756  | total loss: [1m[32m0.37352[0m[0m | time: 11.626s
[2K
| RMSProp | epoch: 017 | loss: 0.37352 - acc: 0.8458 -- iter: 0640/1443
[A[ATraining Step: 757  | total loss: [1m[32m0.36789[0m[0m | time: 12.259s
[2K
| RMSProp | epoch: 017 | loss: 0.36789 - acc: 0.8487 -- iter: 0672/1443
[A[ATraining Step: 758  | total loss: [1m[32m0.36076[0m[0m | time: 12.877s
[2K
| RMSProp | epoch: 017 | loss: 0.36076 - acc: 0.8514 -- iter: 0704/1443
[A[ATraining Step: 759  | total loss: [1m[32m0.37444[0m[0m | time: 13.491s
[2K
| RMSProp | epoch: 017 | loss: 0.37444 - acc: 0.8443 -- iter: 0736/1443
[A[ATraining Step: 760  | total loss: [1m[32m0.36650[0m[0m | time: 14.126s
[2K
| RMSProp | epoch: 017 | loss: 0.36650 - acc: 0.8537 -- iter: 0768/1443
[A[ATraining Step: 761  | total loss: [1m[32m0.35447[0m[0m | time: 14.768s
[2K
| RMSProp | epoch: 017 | loss: 0.35447 - acc: 0.8589 -- iter: 0800/1443
[A[ATraining Step: 762  | total loss: [1m[32m0.37585[0m[0m | time: 15.405s
[2K
| RMSProp | epoch: 017 | loss: 0.37585 - acc: 0.8449 -- iter: 0832/1443
[A[ATraining Step: 763  | total loss: [1m[32m0.37192[0m[0m | time: 16.061s
[2K
| RMSProp | epoch: 017 | loss: 0.37192 - acc: 0.8479 -- iter: 0864/1443
[A[ATraining Step: 764  | total loss: [1m[32m0.38026[0m[0m | time: 16.694s
[2K
| RMSProp | epoch: 017 | loss: 0.38026 - acc: 0.8444 -- iter: 0896/1443
[A[ATraining Step: 765  | total loss: [1m[32m0.37663[0m[0m | time: 17.307s
[2K
| RMSProp | epoch: 017 | loss: 0.37663 - acc: 0.8443 -- iter: 0928/1443
[A[ATraining Step: 766  | total loss: [1m[32m0.38769[0m[0m | time: 17.938s
[2K
| RMSProp | epoch: 017 | loss: 0.38769 - acc: 0.8380 -- iter: 0960/1443
[A[ATraining Step: 767  | total loss: [1m[32m0.38030[0m[0m | time: 18.561s
[2K
| RMSProp | epoch: 017 | loss: 0.38030 - acc: 0.8417 -- iter: 0992/1443
[A[ATraining Step: 768  | total loss: [1m[32m0.36649[0m[0m | time: 19.167s
[2K
| RMSProp | epoch: 017 | loss: 0.36649 - acc: 0.8482 -- iter: 1024/1443
[A[ATraining Step: 769  | total loss: [1m[32m0.36711[0m[0m | time: 19.779s
[2K
| RMSProp | epoch: 017 | loss: 0.36711 - acc: 0.8477 -- iter: 1056/1443
[A[ATraining Step: 770  | total loss: [1m[32m0.35816[0m[0m | time: 20.384s
[2K
| RMSProp | epoch: 017 | loss: 0.35816 - acc: 0.8504 -- iter: 1088/1443
[A[ATraining Step: 771  | total loss: [1m[32m0.34571[0m[0m | time: 21.016s
[2K
| RMSProp | epoch: 017 | loss: 0.34571 - acc: 0.8560 -- iter: 1120/1443
[A[ATraining Step: 772  | total loss: [1m[32m0.33697[0m[0m | time: 21.628s
[2K
| RMSProp | epoch: 017 | loss: 0.33697 - acc: 0.8579 -- iter: 1152/1443
[A[ATraining Step: 773  | total loss: [1m[32m0.32537[0m[0m | time: 22.237s
[2K
| RMSProp | epoch: 017 | loss: 0.32537 - acc: 0.8659 -- iter: 1184/1443
[A[ATraining Step: 774  | total loss: [1m[32m0.31302[0m[0m | time: 22.863s
[2K
| RMSProp | epoch: 017 | loss: 0.31302 - acc: 0.8668 -- iter: 1216/1443
[A[ATraining Step: 775  | total loss: [1m[32m0.29229[0m[0m | time: 23.523s
[2K
| RMSProp | epoch: 017 | loss: 0.29229 - acc: 0.8801 -- iter: 1248/1443
[A[ATraining Step: 776  | total loss: [1m[32m0.27180[0m[0m | time: 24.153s
[2K
| RMSProp | epoch: 017 | loss: 0.27180 - acc: 0.8890 -- iter: 1280/1443
[A[ATraining Step: 777  | total loss: [1m[32m0.26135[0m[0m | time: 24.822s
[2K
| RMSProp | epoch: 017 | loss: 0.26135 - acc: 0.8938 -- iter: 1312/1443
[A[ATraining Step: 778  | total loss: [1m[32m0.24868[0m[0m | time: 25.466s
[2K
| RMSProp | epoch: 017 | loss: 0.24868 - acc: 0.9013 -- iter: 1344/1443
[A[ATraining Step: 779  | total loss: [1m[32m0.26007[0m[0m | time: 26.087s
[2K
| RMSProp | epoch: 017 | loss: 0.26007 - acc: 0.8956 -- iter: 1376/1443
[A[ATraining Step: 780  | total loss: [1m[32m0.25378[0m[0m | time: 26.707s
[2K
| RMSProp | epoch: 017 | loss: 0.25378 - acc: 0.8998 -- iter: 1408/1443
[A[ATraining Step: 781  | total loss: [1m[32m0.26333[0m[0m | time: 27.357s
[2K
| RMSProp | epoch: 017 | loss: 0.26333 - acc: 0.8973 -- iter: 1440/1443
[A[ATraining Step: 782  | total loss: [1m[32m0.30998[0m[0m | time: 29.408s
[2K
| RMSProp | epoch: 017 | loss: 0.30998 - acc: 0.8732 | val_loss: 0.61719 - val_acc: 0.7301 -- iter: 1443/1443
--
Training Step: 783  | total loss: [1m[32m0.30929[0m[0m | time: 0.611s
[2K
| RMSProp | epoch: 018 | loss: 0.30929 - acc: 0.8734 -- iter: 0032/1443
[A[ATraining Step: 784  | total loss: [1m[32m0.30472[0m[0m | time: 1.214s
[2K
| RMSProp | epoch: 018 | loss: 0.30472 - acc: 0.8735 -- iter: 0064/1443
[A[ATraining Step: 785  | total loss: [1m[32m0.32832[0m[0m | time: 1.819s
[2K
| RMSProp | epoch: 018 | loss: 0.32832 - acc: 0.8643 -- iter: 0096/1443
[A[ATraining Step: 786  | total loss: [1m[32m0.34686[0m[0m | time: 2.427s
[2K
| RMSProp | epoch: 018 | loss: 0.34686 - acc: 0.8529 -- iter: 0128/1443
[A[ATraining Step: 787  | total loss: [1m[32m0.34317[0m[0m | time: 3.059s
[2K
| RMSProp | epoch: 018 | loss: 0.34317 - acc: 0.8551 -- iter: 0160/1443
[A[ATraining Step: 788  | total loss: [1m[32m0.33549[0m[0m | time: 3.670s
[2K
| RMSProp | epoch: 018 | loss: 0.33549 - acc: 0.8571 -- iter: 0192/1443
[A[ATraining Step: 789  | total loss: [1m[32m0.31523[0m[0m | time: 4.284s
[2K
| RMSProp | epoch: 018 | loss: 0.31523 - acc: 0.8682 -- iter: 0224/1443
[A[ATraining Step: 790  | total loss: [1m[32m0.33502[0m[0m | time: 4.894s
[2K
| RMSProp | epoch: 018 | loss: 0.33502 - acc: 0.8564 -- iter: 0256/1443
[A[ATraining Step: 791  | total loss: [1m[32m0.32346[0m[0m | time: 5.508s
[2K
| RMSProp | epoch: 018 | loss: 0.32346 - acc: 0.8645 -- iter: 0288/1443
[A[ATraining Step: 792  | total loss: [1m[32m0.32580[0m[0m | time: 6.121s
[2K
| RMSProp | epoch: 018 | loss: 0.32580 - acc: 0.8624 -- iter: 0320/1443
[A[ATraining Step: 793  | total loss: [1m[32m0.34266[0m[0m | time: 6.724s
[2K
| RMSProp | epoch: 018 | loss: 0.34266 - acc: 0.8543 -- iter: 0352/1443
[A[ATraining Step: 794  | total loss: [1m[32m0.34068[0m[0m | time: 7.340s
[2K
| RMSProp | epoch: 018 | loss: 0.34068 - acc: 0.8564 -- iter: 0384/1443
[A[ATraining Step: 795  | total loss: [1m[32m0.33337[0m[0m | time: 7.948s
[2K
| RMSProp | epoch: 018 | loss: 0.33337 - acc: 0.8583 -- iter: 0416/1443
[A[ATraining Step: 796  | total loss: [1m[32m0.32898[0m[0m | time: 8.548s
[2K
| RMSProp | epoch: 018 | loss: 0.32898 - acc: 0.8599 -- iter: 0448/1443
[A[ATraining Step: 797  | total loss: [1m[32m0.33056[0m[0m | time: 9.158s
[2K
| RMSProp | epoch: 018 | loss: 0.33056 - acc: 0.8646 -- iter: 0480/1443
[A[ATraining Step: 798  | total loss: [1m[32m0.35924[0m[0m | time: 9.244s
[2K
| RMSProp | epoch: 018 | loss: 0.35924 - acc: 0.8531 -- iter: 0512/1443
[A[ATraining Step: 799  | total loss: [1m[32m0.34898[0m[0m | time: 9.330s
[2K
| RMSProp | epoch: 018 | loss: 0.34898 - acc: 0.8678 -- iter: 0544/1443
[A[ATraining Step: 800  | total loss: [1m[32m0.31556[0m[0m | time: 11.398s
[2K
| RMSProp | epoch: 018 | loss: 0.31556 - acc: 0.8810 | val_loss: 0.60073 - val_acc: 0.7257 -- iter: 0576/1443
--
Training Step: 801  | total loss: [1m[32m0.32339[0m[0m | time: 12.016s
[2K
| RMSProp | epoch: 018 | loss: 0.32339 - acc: 0.8804 -- iter: 0608/1443
[A[ATraining Step: 802  | total loss: [1m[32m0.32088[0m[0m | time: 12.624s
[2K
| RMSProp | epoch: 018 | loss: 0.32088 - acc: 0.8799 -- iter: 0640/1443
[A[ATraining Step: 803  | total loss: [1m[32m0.34270[0m[0m | time: 13.235s
[2K
| RMSProp | epoch: 018 | loss: 0.34270 - acc: 0.8700 -- iter: 0672/1443
[A[ATraining Step: 804  | total loss: [1m[32m0.32957[0m[0m | time: 13.850s
[2K
| RMSProp | epoch: 018 | loss: 0.32957 - acc: 0.8768 -- iter: 0704/1443
[A[ATraining Step: 805  | total loss: [1m[32m0.32777[0m[0m | time: 14.477s
[2K
| RMSProp | epoch: 018 | loss: 0.32777 - acc: 0.8703 -- iter: 0736/1443
[A[ATraining Step: 806  | total loss: [1m[32m0.33142[0m[0m | time: 15.115s
[2K
| RMSProp | epoch: 018 | loss: 0.33142 - acc: 0.8708 -- iter: 0768/1443
[A[ATraining Step: 807  | total loss: [1m[32m0.33088[0m[0m | time: 15.748s
[2K
| RMSProp | epoch: 018 | loss: 0.33088 - acc: 0.8743 -- iter: 0800/1443
[A[ATraining Step: 808  | total loss: [1m[32m0.32898[0m[0m | time: 16.380s
[2K
| RMSProp | epoch: 018 | loss: 0.32898 - acc: 0.8775 -- iter: 0832/1443
[A[ATraining Step: 809  | total loss: [1m[32m0.32701[0m[0m | time: 16.999s
[2K
| RMSProp | epoch: 018 | loss: 0.32701 - acc: 0.8835 -- iter: 0864/1443
[A[ATraining Step: 810  | total loss: [1m[32m0.32144[0m[0m | time: 17.614s
[2K
| RMSProp | epoch: 018 | loss: 0.32144 - acc: 0.8827 -- iter: 0896/1443
[A[ATraining Step: 811  | total loss: [1m[32m0.31654[0m[0m | time: 18.259s
[2K
| RMSProp | epoch: 018 | loss: 0.31654 - acc: 0.8850 -- iter: 0928/1443
[A[ATraining Step: 812  | total loss: [1m[32m0.31631[0m[0m | time: 18.864s
[2K
| RMSProp | epoch: 018 | loss: 0.31631 - acc: 0.8840 -- iter: 0960/1443
[A[ATraining Step: 813  | total loss: [1m[32m0.31917[0m[0m | time: 19.469s
[2K
| RMSProp | epoch: 018 | loss: 0.31917 - acc: 0.8800 -- iter: 0992/1443
[A[ATraining Step: 814  | total loss: [1m[32m0.31884[0m[0m | time: 20.100s
[2K
| RMSProp | epoch: 018 | loss: 0.31884 - acc: 0.8826 -- iter: 1024/1443
[A[ATraining Step: 815  | total loss: [1m[32m0.30945[0m[0m | time: 20.734s
[2K
| RMSProp | epoch: 018 | loss: 0.30945 - acc: 0.8850 -- iter: 1056/1443
[A[ATraining Step: 816  | total loss: [1m[32m0.30530[0m[0m | time: 21.345s
[2K
| RMSProp | epoch: 018 | loss: 0.30530 - acc: 0.8902 -- iter: 1088/1443
[A[ATraining Step: 817  | total loss: [1m[32m0.29551[0m[0m | time: 21.959s
[2K
| RMSProp | epoch: 018 | loss: 0.29551 - acc: 0.8981 -- iter: 1120/1443
[A[ATraining Step: 818  | total loss: [1m[32m0.28181[0m[0m | time: 22.574s
[2K
| RMSProp | epoch: 018 | loss: 0.28181 - acc: 0.9052 -- iter: 1152/1443
[A[ATraining Step: 819  | total loss: [1m[32m0.29351[0m[0m | time: 23.195s
[2K
| RMSProp | epoch: 018 | loss: 0.29351 - acc: 0.9021 -- iter: 1184/1443
[A[ATraining Step: 820  | total loss: [1m[32m0.28156[0m[0m | time: 23.805s
[2K
| RMSProp | epoch: 018 | loss: 0.28156 - acc: 0.9088 -- iter: 1216/1443
[A[ATraining Step: 821  | total loss: [1m[32m0.29247[0m[0m | time: 24.400s
[2K
| RMSProp | epoch: 018 | loss: 0.29247 - acc: 0.8992 -- iter: 1248/1443
[A[ATraining Step: 822  | total loss: [1m[32m0.28756[0m[0m | time: 25.012s
[2K
| RMSProp | epoch: 018 | loss: 0.28756 - acc: 0.9061 -- iter: 1280/1443
[A[ATraining Step: 823  | total loss: [1m[32m0.28622[0m[0m | time: 25.616s
[2K
| RMSProp | epoch: 018 | loss: 0.28622 - acc: 0.9061 -- iter: 1312/1443
[A[ATraining Step: 824  | total loss: [1m[32m0.28710[0m[0m | time: 26.261s
[2K
| RMSProp | epoch: 018 | loss: 0.28710 - acc: 0.9062 -- iter: 1344/1443
[A[ATraining Step: 825  | total loss: [1m[32m0.29266[0m[0m | time: 26.904s
[2K
| RMSProp | epoch: 018 | loss: 0.29266 - acc: 0.9062 -- iter: 1376/1443
[A[ATraining Step: 826  | total loss: [1m[32m0.28155[0m[0m | time: 27.506s
[2K
| RMSProp | epoch: 018 | loss: 0.28155 - acc: 0.9093 -- iter: 1408/1443
[A[ATraining Step: 827  | total loss: [1m[32m0.28588[0m[0m | time: 28.131s
[2K
| RMSProp | epoch: 018 | loss: 0.28588 - acc: 0.9059 -- iter: 1440/1443
[A[ATraining Step: 828  | total loss: [1m[32m0.29098[0m[0m | time: 30.187s
[2K
| RMSProp | epoch: 018 | loss: 0.29098 - acc: 0.8997 | val_loss: 0.69427 - val_acc: 0.6527 -- iter: 1443/1443
--
Training Step: 829  | total loss: [1m[32m0.30461[0m[0m | time: 0.608s
[2K
| RMSProp | epoch: 019 | loss: 0.30461 - acc: 0.8941 -- iter: 0032/1443
[A[ATraining Step: 830  | total loss: [1m[32m0.31560[0m[0m | time: 1.223s
[2K
| RMSProp | epoch: 019 | loss: 0.31560 - acc: 0.8859 -- iter: 0064/1443
[A[ATraining Step: 831  | total loss: [1m[32m0.29377[0m[0m | time: 1.834s
[2K
| RMSProp | epoch: 019 | loss: 0.29377 - acc: 0.8973 -- iter: 0096/1443
[A[ATraining Step: 832  | total loss: [1m[32m0.28403[0m[0m | time: 2.443s
[2K
| RMSProp | epoch: 019 | loss: 0.28403 - acc: 0.9013 -- iter: 0128/1443
[A[ATraining Step: 833  | total loss: [1m[32m0.26858[0m[0m | time: 3.079s
[2K
| RMSProp | epoch: 019 | loss: 0.26858 - acc: 0.9050 -- iter: 0160/1443
[A[ATraining Step: 834  | total loss: [1m[32m0.29494[0m[0m | time: 3.685s
[2K
| RMSProp | epoch: 019 | loss: 0.29494 - acc: 0.8988 -- iter: 0192/1443
[A[ATraining Step: 835  | total loss: [1m[32m0.30412[0m[0m | time: 4.303s
[2K
| RMSProp | epoch: 019 | loss: 0.30412 - acc: 0.8902 -- iter: 0224/1443
[A[ATraining Step: 836  | total loss: [1m[32m0.29702[0m[0m | time: 4.909s
[2K
| RMSProp | epoch: 019 | loss: 0.29702 - acc: 0.8918 -- iter: 0256/1443
[A[ATraining Step: 837  | total loss: [1m[32m0.30623[0m[0m | time: 5.535s
[2K
| RMSProp | epoch: 019 | loss: 0.30623 - acc: 0.8901 -- iter: 0288/1443
[A[ATraining Step: 838  | total loss: [1m[32m0.28798[0m[0m | time: 6.174s
[2K
| RMSProp | epoch: 019 | loss: 0.28798 - acc: 0.8980 -- iter: 0320/1443
[A[ATraining Step: 839  | total loss: [1m[32m0.30602[0m[0m | time: 6.807s
[2K
| RMSProp | epoch: 019 | loss: 0.30602 - acc: 0.8863 -- iter: 0352/1443
[A[ATraining Step: 840  | total loss: [1m[32m0.29639[0m[0m | time: 7.432s
[2K
| RMSProp | epoch: 019 | loss: 0.29639 - acc: 0.8914 -- iter: 0384/1443
[A[ATraining Step: 841  | total loss: [1m[32m0.28847[0m[0m | time: 8.042s
[2K
| RMSProp | epoch: 019 | loss: 0.28847 - acc: 0.8898 -- iter: 0416/1443
[A[ATraining Step: 842  | total loss: [1m[32m0.28185[0m[0m | time: 8.672s
[2K
| RMSProp | epoch: 019 | loss: 0.28185 - acc: 0.8914 -- iter: 0448/1443
[A[ATraining Step: 843  | total loss: [1m[32m0.29498[0m[0m | time: 9.275s
[2K
| RMSProp | epoch: 019 | loss: 0.29498 - acc: 0.8804 -- iter: 0480/1443
[A[ATraining Step: 844  | total loss: [1m[32m0.33586[0m[0m | time: 9.882s
[2K
| RMSProp | epoch: 019 | loss: 0.33586 - acc: 0.8611 -- iter: 0512/1443
[A[ATraining Step: 845  | total loss: [1m[32m0.31625[0m[0m | time: 9.972s
[2K
| RMSProp | epoch: 019 | loss: 0.31625 - acc: 0.8750 -- iter: 0544/1443
[A[ATraining Step: 846  | total loss: [1m[32m0.29771[0m[0m | time: 10.061s
[2K
| RMSProp | epoch: 019 | loss: 0.29771 - acc: 0.8875 -- iter: 0576/1443
[A[ATraining Step: 847  | total loss: [1m[32m0.27397[0m[0m | time: 10.706s
[2K
| RMSProp | epoch: 019 | loss: 0.27397 - acc: 0.8988 -- iter: 0608/1443
[A[ATraining Step: 848  | total loss: [1m[32m0.28099[0m[0m | time: 11.305s
[2K
| RMSProp | epoch: 019 | loss: 0.28099 - acc: 0.8964 -- iter: 0640/1443
[A[ATraining Step: 849  | total loss: [1m[32m0.39300[0m[0m | time: 11.915s
[2K
| RMSProp | epoch: 019 | loss: 0.39300 - acc: 0.8411 -- iter: 0672/1443
[A[ATraining Step: 850  | total loss: [1m[32m0.37233[0m[0m | time: 12.535s
[2K
| RMSProp | epoch: 019 | loss: 0.37233 - acc: 0.8508 -- iter: 0704/1443
[A[ATraining Step: 851  | total loss: [1m[32m0.36068[0m[0m | time: 13.149s
[2K
| RMSProp | epoch: 019 | loss: 0.36068 - acc: 0.8594 -- iter: 0736/1443
[A[ATraining Step: 852  | total loss: [1m[32m0.34372[0m[0m | time: 13.760s
[2K
| RMSProp | epoch: 019 | loss: 0.34372 - acc: 0.8610 -- iter: 0768/1443
[A[ATraining Step: 853  | total loss: [1m[32m0.32059[0m[0m | time: 14.389s
[2K
| RMSProp | epoch: 019 | loss: 0.32059 - acc: 0.8718 -- iter: 0800/1443
[A[ATraining Step: 854  | total loss: [1m[32m0.31096[0m[0m | time: 15.000s
[2K
| RMSProp | epoch: 019 | loss: 0.31096 - acc: 0.8658 -- iter: 0832/1443
[A[ATraining Step: 855  | total loss: [1m[32m0.31195[0m[0m | time: 15.618s
[2K
| RMSProp | epoch: 019 | loss: 0.31195 - acc: 0.8668 -- iter: 0864/1443
[A[ATraining Step: 856  | total loss: [1m[32m0.30404[0m[0m | time: 16.245s
[2K
| RMSProp | epoch: 019 | loss: 0.30404 - acc: 0.8738 -- iter: 0896/1443
[A[ATraining Step: 857  | total loss: [1m[32m0.28232[0m[0m | time: 16.882s
[2K
| RMSProp | epoch: 019 | loss: 0.28232 - acc: 0.8864 -- iter: 0928/1443
[A[ATraining Step: 858  | total loss: [1m[32m0.32859[0m[0m | time: 17.481s
[2K
| RMSProp | epoch: 019 | loss: 0.32859 - acc: 0.8728 -- iter: 0960/1443
[A[ATraining Step: 859  | total loss: [1m[32m0.32949[0m[0m | time: 18.115s
[2K
| RMSProp | epoch: 019 | loss: 0.32949 - acc: 0.8730 -- iter: 0992/1443
[A[ATraining Step: 860  | total loss: [1m[32m0.32208[0m[0m | time: 18.718s
[2K
| RMSProp | epoch: 019 | loss: 0.32208 - acc: 0.8763 -- iter: 1024/1443
[A[ATraining Step: 861  | total loss: [1m[32m0.33372[0m[0m | time: 19.338s
[2K
| RMSProp | epoch: 019 | loss: 0.33372 - acc: 0.8762 -- iter: 1056/1443
[A[ATraining Step: 862  | total loss: [1m[32m0.32800[0m[0m | time: 19.978s
[2K
| RMSProp | epoch: 019 | loss: 0.32800 - acc: 0.8730 -- iter: 1088/1443
[A[ATraining Step: 863  | total loss: [1m[32m0.32367[0m[0m | time: 20.596s
[2K
| RMSProp | epoch: 019 | loss: 0.32367 - acc: 0.8732 -- iter: 1120/1443
[A[ATraining Step: 864  | total loss: [1m[32m0.31035[0m[0m | time: 21.229s
[2K
| RMSProp | epoch: 019 | loss: 0.31035 - acc: 0.8827 -- iter: 1152/1443
[A[ATraining Step: 865  | total loss: [1m[32m0.29990[0m[0m | time: 21.843s
[2K
| RMSProp | epoch: 019 | loss: 0.29990 - acc: 0.8851 -- iter: 1184/1443
[A[ATraining Step: 866  | total loss: [1m[32m0.31362[0m[0m | time: 22.455s
[2K
| RMSProp | epoch: 019 | loss: 0.31362 - acc: 0.8747 -- iter: 1216/1443
[A[ATraining Step: 867  | total loss: [1m[32m0.30421[0m[0m | time: 23.062s
[2K
| RMSProp | epoch: 019 | loss: 0.30421 - acc: 0.8810 -- iter: 1248/1443
[A[ATraining Step: 868  | total loss: [1m[32m0.31875[0m[0m | time: 23.672s
[2K
| RMSProp | epoch: 019 | loss: 0.31875 - acc: 0.8835 -- iter: 1280/1443
[A[ATraining Step: 869  | total loss: [1m[32m0.30053[0m[0m | time: 24.283s
[2K
| RMSProp | epoch: 019 | loss: 0.30053 - acc: 0.8952 -- iter: 1312/1443
[A[ATraining Step: 870  | total loss: [1m[32m0.29560[0m[0m | time: 24.911s
[2K
| RMSProp | epoch: 019 | loss: 0.29560 - acc: 0.8963 -- iter: 1344/1443
[A[ATraining Step: 871  | total loss: [1m[32m0.30110[0m[0m | time: 25.537s
[2K
| RMSProp | epoch: 019 | loss: 0.30110 - acc: 0.8910 -- iter: 1376/1443
[A[ATraining Step: 872  | total loss: [1m[32m0.28915[0m[0m | time: 26.157s
[2K
| RMSProp | epoch: 019 | loss: 0.28915 - acc: 0.8988 -- iter: 1408/1443
[A[ATraining Step: 873  | total loss: [1m[32m0.31281[0m[0m | time: 26.759s
[2K
| RMSProp | epoch: 019 | loss: 0.31281 - acc: 0.8902 -- iter: 1440/1443
[A[ATraining Step: 874  | total loss: [1m[32m0.30544[0m[0m | time: 28.806s
[2K
| RMSProp | epoch: 019 | loss: 0.30544 - acc: 0.8949 | val_loss: 0.67708 - val_acc: 0.7080 -- iter: 1443/1443
--
Training Step: 875  | total loss: [1m[32m0.28660[0m[0m | time: 0.624s
[2K
| RMSProp | epoch: 020 | loss: 0.28660 - acc: 0.9054 -- iter: 0032/1443
[A[ATraining Step: 876  | total loss: [1m[32m0.28196[0m[0m | time: 1.238s
[2K
| RMSProp | epoch: 020 | loss: 0.28196 - acc: 0.9024 -- iter: 0064/1443
[A[ATraining Step: 877  | total loss: [1m[32m0.32904[0m[0m | time: 1.855s
[2K
| RMSProp | epoch: 020 | loss: 0.32904 - acc: 0.8809 -- iter: 0096/1443
[A[ATraining Step: 878  | total loss: [1m[32m0.32428[0m[0m | time: 2.499s
[2K
| RMSProp | epoch: 020 | loss: 0.32428 - acc: 0.8834 -- iter: 0128/1443
[A[ATraining Step: 879  | total loss: [1m[32m0.31515[0m[0m | time: 3.112s
[2K
| RMSProp | epoch: 020 | loss: 0.31515 - acc: 0.8826 -- iter: 0160/1443
[A[ATraining Step: 880  | total loss: [1m[32m0.32376[0m[0m | time: 3.721s
[2K
| RMSProp | epoch: 020 | loss: 0.32376 - acc: 0.8756 -- iter: 0192/1443
[A[ATraining Step: 881  | total loss: [1m[32m0.30700[0m[0m | time: 4.336s
[2K
| RMSProp | epoch: 020 | loss: 0.30700 - acc: 0.8849 -- iter: 0224/1443
[A[ATraining Step: 882  | total loss: [1m[32m0.31152[0m[0m | time: 4.969s
[2K
| RMSProp | epoch: 020 | loss: 0.31152 - acc: 0.8808 -- iter: 0256/1443
[A[ATraining Step: 883  | total loss: [1m[32m0.32096[0m[0m | time: 5.584s
[2K
| RMSProp | epoch: 020 | loss: 0.32096 - acc: 0.8802 -- iter: 0288/1443
[A[ATraining Step: 884  | total loss: [1m[32m0.30509[0m[0m | time: 6.214s
[2K
| RMSProp | epoch: 020 | loss: 0.30509 - acc: 0.8922 -- iter: 0320/1443
[A[ATraining Step: 885  | total loss: [1m[32m0.28833[0m[0m | time: 6.828s
[2K
| RMSProp | epoch: 020 | loss: 0.28833 - acc: 0.8998 -- iter: 0352/1443
[A[ATraining Step: 886  | total loss: [1m[32m0.31325[0m[0m | time: 7.447s
[2K
| RMSProp | epoch: 020 | loss: 0.31325 - acc: 0.8911 -- iter: 0384/1443
[A[ATraining Step: 887  | total loss: [1m[32m0.29895[0m[0m | time: 8.066s
[2K
| RMSProp | epoch: 020 | loss: 0.29895 - acc: 0.8989 -- iter: 0416/1443
[A[ATraining Step: 888  | total loss: [1m[32m0.28379[0m[0m | time: 8.680s
[2K
| RMSProp | epoch: 020 | loss: 0.28379 - acc: 0.9027 -- iter: 0448/1443
[A[ATraining Step: 889  | total loss: [1m[32m0.27204[0m[0m | time: 9.321s
[2K
| RMSProp | epoch: 020 | loss: 0.27204 - acc: 0.9093 -- iter: 0480/1443
[A[ATraining Step: 890  | total loss: [1m[32m0.29610[0m[0m | time: 9.929s
[2K
| RMSProp | epoch: 020 | loss: 0.29610 - acc: 0.8965 -- iter: 0512/1443
[A[ATraining Step: 891  | total loss: [1m[32m0.31122[0m[0m | time: 10.550s
[2K
| RMSProp | epoch: 020 | loss: 0.31122 - acc: 0.8850 -- iter: 0544/1443
[A[ATraining Step: 892  | total loss: [1m[32m0.30300[0m[0m | time: 10.637s
[2K
| RMSProp | epoch: 020 | loss: 0.30300 - acc: 0.8871 -- iter: 0576/1443
[A[ATraining Step: 893  | total loss: [1m[32m0.27888[0m[0m | time: 10.729s
[2K
| RMSProp | epoch: 020 | loss: 0.27888 - acc: 0.8984 -- iter: 0608/1443
[A[ATraining Step: 894  | total loss: [1m[32m0.25214[0m[0m | time: 11.333s
[2K
| RMSProp | epoch: 020 | loss: 0.25214 - acc: 0.9086 -- iter: 0640/1443
[A[ATraining Step: 895  | total loss: [1m[32m0.23294[0m[0m | time: 11.938s
[2K
| RMSProp | epoch: 020 | loss: 0.23294 - acc: 0.9146 -- iter: 0672/1443
[A[ATraining Step: 896  | total loss: [1m[32m0.26088[0m[0m | time: 12.565s
[2K
| RMSProp | epoch: 020 | loss: 0.26088 - acc: 0.8981 -- iter: 0704/1443
[A[ATraining Step: 897  | total loss: [1m[32m0.26023[0m[0m | time: 13.177s
[2K
| RMSProp | epoch: 020 | loss: 0.26023 - acc: 0.8958 -- iter: 0736/1443
[A[ATraining Step: 898  | total loss: [1m[32m0.25810[0m[0m | time: 13.807s
[2K
| RMSProp | epoch: 020 | loss: 0.25810 - acc: 0.8969 -- iter: 0768/1443
[A[ATraining Step: 899  | total loss: [1m[32m0.24471[0m[0m | time: 14.424s
[2K
| RMSProp | epoch: 020 | loss: 0.24471 - acc: 0.9040 -- iter: 0800/1443
[A[ATraining Step: 900  | total loss: [1m[32m0.22784[0m[0m | time: 15.063s
[2K
| RMSProp | epoch: 020 | loss: 0.22784 - acc: 0.9105 -- iter: 0832/1443
[A[ATraining Step: 901  | total loss: [1m[32m0.23922[0m[0m | time: 15.691s
[2K
| RMSProp | epoch: 020 | loss: 0.23922 - acc: 0.9038 -- iter: 0864/1443
[A[ATraining Step: 902  | total loss: [1m[32m0.27979[0m[0m | time: 16.316s
[2K
| RMSProp | epoch: 020 | loss: 0.27979 - acc: 0.8853 -- iter: 0896/1443
[A[ATraining Step: 903  | total loss: [1m[32m0.26541[0m[0m | time: 16.948s
[2K
| RMSProp | epoch: 020 | loss: 0.26541 - acc: 0.8968 -- iter: 0928/1443
[A[ATraining Step: 904  | total loss: [1m[32m0.25766[0m[0m | time: 17.566s
[2K
| RMSProp | epoch: 020 | loss: 0.25766 - acc: 0.9009 -- iter: 0960/1443
[A[ATraining Step: 905  | total loss: [1m[32m0.26269[0m[0m | time: 18.175s
[2K
| RMSProp | epoch: 020 | loss: 0.26269 - acc: 0.8952 -- iter: 0992/1443
[A[ATraining Step: 906  | total loss: [1m[32m0.30162[0m[0m | time: 18.787s
[2K
| RMSProp | epoch: 020 | loss: 0.30162 - acc: 0.8806 -- iter: 1024/1443
[A[ATraining Step: 907  | total loss: [1m[32m0.28851[0m[0m | time: 19.391s
[2K
| RMSProp | epoch: 020 | loss: 0.28851 - acc: 0.8895 -- iter: 1056/1443
[A[ATraining Step: 908  | total loss: [1m[32m0.28297[0m[0m | time: 20.017s
[2K
| RMSProp | epoch: 020 | loss: 0.28297 - acc: 0.8943 -- iter: 1088/1443
[A[ATraining Step: 909  | total loss: [1m[32m0.28499[0m[0m | time: 20.638s
[2K
| RMSProp | epoch: 020 | loss: 0.28499 - acc: 0.8892 -- iter: 1120/1443
[A[ATraining Step: 910  | total loss: [1m[32m0.26932[0m[0m | time: 21.257s
[2K
| RMSProp | epoch: 020 | loss: 0.26932 - acc: 0.9003 -- iter: 1152/1443
[A[ATraining Step: 911  | total loss: [1m[32m0.27804[0m[0m | time: 21.893s
[2K
| RMSProp | epoch: 020 | loss: 0.27804 - acc: 0.8978 -- iter: 1184/1443
[A[ATraining Step: 912  | total loss: [1m[32m0.30756[0m[0m | time: 22.522s
[2K
| RMSProp | epoch: 020 | loss: 0.30756 - acc: 0.8799 -- iter: 1216/1443
[A[ATraining Step: 913  | total loss: [1m[32m0.29182[0m[0m | time: 23.159s
[2K
| RMSProp | epoch: 020 | loss: 0.29182 - acc: 0.8887 -- iter: 1248/1443
[A[ATraining Step: 914  | total loss: [1m[32m0.28033[0m[0m | time: 23.764s
[2K
| RMSProp | epoch: 020 | loss: 0.28033 - acc: 0.8967 -- iter: 1280/1443
[A[ATraining Step: 915  | total loss: [1m[32m0.26420[0m[0m | time: 24.393s
[2K
| RMSProp | epoch: 020 | loss: 0.26420 - acc: 0.9039 -- iter: 1312/1443
[A[ATraining Step: 916  | total loss: [1m[32m0.25069[0m[0m | time: 25.032s
[2K
| RMSProp | epoch: 020 | loss: 0.25069 - acc: 0.9104 -- iter: 1344/1443
[A[ATraining Step: 917  | total loss: [1m[32m0.25326[0m[0m | time: 25.656s
[2K
| RMSProp | epoch: 020 | loss: 0.25326 - acc: 0.9100 -- iter: 1376/1443
[A[ATraining Step: 918  | total loss: [1m[32m0.27785[0m[0m | time: 26.276s
[2K
| RMSProp | epoch: 020 | loss: 0.27785 - acc: 0.8940 -- iter: 1408/1443
[A[ATraining Step: 919  | total loss: [1m[32m0.27273[0m[0m | time: 26.919s
[2K
| RMSProp | epoch: 020 | loss: 0.27273 - acc: 0.8921 -- iter: 1440/1443
[A[ATraining Step: 920  | total loss: [1m[32m0.25305[0m[0m | time: 29.058s
[2K
| RMSProp | epoch: 020 | loss: 0.25305 - acc: 0.9029 | val_loss: 0.78305 - val_acc: 0.7522 -- iter: 1443/1443
--
Training Step: 921  | total loss: [1m[32m0.23948[0m[0m | time: 0.653s
[2K
| RMSProp | epoch: 021 | loss: 0.23948 - acc: 0.9095 -- iter: 0032/1443
[A[ATraining Step: 922  | total loss: [1m[32m0.24079[0m[0m | time: 1.301s
[2K
| RMSProp | epoch: 021 | loss: 0.24079 - acc: 0.9092 -- iter: 0064/1443
[A[ATraining Step: 923  | total loss: [1m[32m0.25917[0m[0m | time: 1.909s
[2K
| RMSProp | epoch: 021 | loss: 0.25917 - acc: 0.9026 -- iter: 0096/1443
[A[ATraining Step: 924  | total loss: [1m[32m0.27716[0m[0m | time: 2.535s
[2K
| RMSProp | epoch: 021 | loss: 0.27716 - acc: 0.8967 -- iter: 0128/1443
[A[ATraining Step: 925  | total loss: [1m[32m0.26133[0m[0m | time: 3.158s
[2K
| RMSProp | epoch: 021 | loss: 0.26133 - acc: 0.9039 -- iter: 0160/1443
[A[ATraining Step: 926  | total loss: [1m[32m0.26157[0m[0m | time: 3.792s
[2K
| RMSProp | epoch: 021 | loss: 0.26157 - acc: 0.9073 -- iter: 0192/1443
[A[ATraining Step: 927  | total loss: [1m[32m0.25623[0m[0m | time: 4.419s
[2K
| RMSProp | epoch: 021 | loss: 0.25623 - acc: 0.9072 -- iter: 0224/1443
[A[ATraining Step: 928  | total loss: [1m[32m0.24829[0m[0m | time: 5.072s
[2K
| RMSProp | epoch: 021 | loss: 0.24829 - acc: 0.9071 -- iter: 0256/1443
[A[ATraining Step: 929  | total loss: [1m[32m0.23391[0m[0m | time: 5.693s
[2K
| RMSProp | epoch: 021 | loss: 0.23391 - acc: 0.9164 -- iter: 0288/1443
[A[ATraining Step: 930  | total loss: [1m[32m0.23414[0m[0m | time: 6.296s
[2K
| RMSProp | epoch: 021 | loss: 0.23414 - acc: 0.9154 -- iter: 0320/1443
[A[ATraining Step: 931  | total loss: [1m[32m0.21715[0m[0m | time: 6.919s
[2K
| RMSProp | epoch: 021 | loss: 0.21715 - acc: 0.9238 -- iter: 0352/1443
[A[ATraining Step: 932  | total loss: [1m[32m0.23842[0m[0m | time: 7.567s
[2K
| RMSProp | epoch: 021 | loss: 0.23842 - acc: 0.9221 -- iter: 0384/1443
[A[ATraining Step: 933  | total loss: [1m[32m0.22893[0m[0m | time: 8.191s
[2K
| RMSProp | epoch: 021 | loss: 0.22893 - acc: 0.9267 -- iter: 0416/1443
[A[ATraining Step: 934  | total loss: [1m[32m0.24249[0m[0m | time: 8.806s
[2K
| RMSProp | epoch: 021 | loss: 0.24249 - acc: 0.9184 -- iter: 0448/1443
[A[ATraining Step: 935  | total loss: [1m[32m0.24509[0m[0m | time: 9.424s
[2K
| RMSProp | epoch: 021 | loss: 0.24509 - acc: 0.9203 -- iter: 0480/1443
[A[ATraining Step: 936  | total loss: [1m[32m0.23598[0m[0m | time: 10.036s
[2K
| RMSProp | epoch: 021 | loss: 0.23598 - acc: 0.9252 -- iter: 0512/1443
[A[ATraining Step: 937  | total loss: [1m[32m0.23036[0m[0m | time: 10.676s
[2K
| RMSProp | epoch: 021 | loss: 0.23036 - acc: 0.9264 -- iter: 0544/1443
[A[ATraining Step: 938  | total loss: [1m[32m0.22762[0m[0m | time: 11.298s
[2K
| RMSProp | epoch: 021 | loss: 0.22762 - acc: 0.9213 -- iter: 0576/1443
[A[ATraining Step: 939  | total loss: [1m[32m0.23787[0m[0m | time: 11.398s
[2K
| RMSProp | epoch: 021 | loss: 0.23787 - acc: 0.9167 -- iter: 0608/1443
[A[ATraining Step: 940  | total loss: [1m[32m0.22873[0m[0m | time: 11.485s
[2K
| RMSProp | epoch: 021 | loss: 0.22873 - acc: 0.9250 -- iter: 0640/1443
[A[ATraining Step: 941  | total loss: [1m[32m0.20850[0m[0m | time: 12.111s
[2K
| RMSProp | epoch: 021 | loss: 0.20850 - acc: 0.9325 -- iter: 0672/1443
[A[ATraining Step: 942  | total loss: [1m[32m0.25355[0m[0m | time: 12.735s
[2K
| RMSProp | epoch: 021 | loss: 0.25355 - acc: 0.9142 -- iter: 0704/1443
[A[ATraining Step: 943  | total loss: [1m[32m0.24857[0m[0m | time: 13.348s
[2K
| RMSProp | epoch: 021 | loss: 0.24857 - acc: 0.9166 -- iter: 0736/1443
[A[ATraining Step: 944  | total loss: [1m[32m0.25237[0m[0m | time: 13.961s
[2K
| RMSProp | epoch: 021 | loss: 0.25237 - acc: 0.9124 -- iter: 0768/1443
[A[ATraining Step: 945  | total loss: [1m[32m0.25636[0m[0m | time: 14.577s
[2K
| RMSProp | epoch: 021 | loss: 0.25636 - acc: 0.9118 -- iter: 0800/1443
[A[ATraining Step: 946  | total loss: [1m[32m0.25589[0m[0m | time: 15.183s
[2K
| RMSProp | epoch: 021 | loss: 0.25589 - acc: 0.9081 -- iter: 0832/1443
[A[ATraining Step: 947  | total loss: [1m[32m0.25491[0m[0m | time: 15.791s
[2K
| RMSProp | epoch: 021 | loss: 0.25491 - acc: 0.9079 -- iter: 0864/1443
[A[ATraining Step: 948  | total loss: [1m[32m0.24118[0m[0m | time: 16.407s
[2K
| RMSProp | epoch: 021 | loss: 0.24118 - acc: 0.9109 -- iter: 0896/1443
[A[ATraining Step: 949  | total loss: [1m[32m0.23970[0m[0m | time: 17.013s
[2K
| RMSProp | epoch: 021 | loss: 0.23970 - acc: 0.9135 -- iter: 0928/1443
[A[ATraining Step: 950  | total loss: [1m[32m0.23243[0m[0m | time: 17.663s
[2K
| RMSProp | epoch: 021 | loss: 0.23243 - acc: 0.9159 -- iter: 0960/1443
[A[ATraining Step: 951  | total loss: [1m[32m0.22773[0m[0m | time: 18.297s
[2K
| RMSProp | epoch: 021 | loss: 0.22773 - acc: 0.9212 -- iter: 0992/1443
[A[ATraining Step: 952  | total loss: [1m[32m0.22463[0m[0m | time: 18.918s
[2K
| RMSProp | epoch: 021 | loss: 0.22463 - acc: 0.9260 -- iter: 1024/1443
[A[ATraining Step: 953  | total loss: [1m[32m0.22732[0m[0m | time: 19.525s
[2K
| RMSProp | epoch: 021 | loss: 0.22732 - acc: 0.9271 -- iter: 1056/1443
[A[ATraining Step: 954  | total loss: [1m[32m0.21850[0m[0m | time: 20.140s
[2K
| RMSProp | epoch: 021 | loss: 0.21850 - acc: 0.9282 -- iter: 1088/1443
[A[ATraining Step: 955  | total loss: [1m[32m0.21990[0m[0m | time: 20.758s
[2K
| RMSProp | epoch: 021 | loss: 0.21990 - acc: 0.9260 -- iter: 1120/1443
[A[ATraining Step: 956  | total loss: [1m[32m0.21622[0m[0m | time: 21.372s
[2K
| RMSProp | epoch: 021 | loss: 0.21622 - acc: 0.9271 -- iter: 1152/1443
[A[ATraining Step: 957  | total loss: [1m[32m0.20691[0m[0m | time: 21.979s
[2K
| RMSProp | epoch: 021 | loss: 0.20691 - acc: 0.9282 -- iter: 1184/1443
[A[ATraining Step: 958  | total loss: [1m[32m0.19604[0m[0m | time: 22.616s
[2K
| RMSProp | epoch: 021 | loss: 0.19604 - acc: 0.9322 -- iter: 1216/1443
[A[ATraining Step: 959  | total loss: [1m[32m0.20131[0m[0m | time: 23.240s
[2K
| RMSProp | epoch: 021 | loss: 0.20131 - acc: 0.9296 -- iter: 1248/1443
[A[ATraining Step: 960  | total loss: [1m[32m0.18782[0m[0m | time: 23.845s
[2K
| RMSProp | epoch: 021 | loss: 0.18782 - acc: 0.9367 -- iter: 1280/1443
[A[ATraining Step: 961  | total loss: [1m[32m0.18496[0m[0m | time: 24.458s
[2K
| RMSProp | epoch: 021 | loss: 0.18496 - acc: 0.9399 -- iter: 1312/1443
[A[ATraining Step: 962  | total loss: [1m[32m0.17420[0m[0m | time: 25.081s
[2K
| RMSProp | epoch: 021 | loss: 0.17420 - acc: 0.9428 -- iter: 1344/1443
[A[ATraining Step: 963  | total loss: [1m[32m0.16368[0m[0m | time: 25.698s
[2K
| RMSProp | epoch: 021 | loss: 0.16368 - acc: 0.9454 -- iter: 1376/1443
[A[ATraining Step: 964  | total loss: [1m[32m0.18323[0m[0m | time: 26.299s
[2K
| RMSProp | epoch: 021 | loss: 0.18323 - acc: 0.9352 -- iter: 1408/1443
[A[ATraining Step: 965  | total loss: [1m[32m0.20787[0m[0m | time: 26.917s
[2K
| RMSProp | epoch: 021 | loss: 0.20787 - acc: 0.9292 -- iter: 1440/1443
[A[ATraining Step: 966  | total loss: [1m[32m0.22595[0m[0m | time: 28.980s
[2K
| RMSProp | epoch: 021 | loss: 0.22595 - acc: 0.9175 | val_loss: 0.65942 - val_acc: 0.7544 -- iter: 1443/1443
--
Training Step: 967  | total loss: [1m[32m0.22537[0m[0m | time: 0.625s
[2K
| RMSProp | epoch: 022 | loss: 0.22537 - acc: 0.9101 -- iter: 0032/1443
[A[ATraining Step: 968  | total loss: [1m[32m0.22630[0m[0m | time: 1.235s
[2K
| RMSProp | epoch: 022 | loss: 0.22630 - acc: 0.9097 -- iter: 0064/1443
[A[ATraining Step: 969  | total loss: [1m[32m0.21584[0m[0m | time: 1.838s
[2K
| RMSProp | epoch: 022 | loss: 0.21584 - acc: 0.9125 -- iter: 0096/1443
[A[ATraining Step: 970  | total loss: [1m[32m0.20146[0m[0m | time: 2.458s
[2K
| RMSProp | epoch: 022 | loss: 0.20146 - acc: 0.9213 -- iter: 0128/1443
[A[ATraining Step: 971  | total loss: [1m[32m0.18484[0m[0m | time: 3.096s
[2K
| RMSProp | epoch: 022 | loss: 0.18484 - acc: 0.9291 -- iter: 0160/1443
[A[ATraining Step: 972  | total loss: [1m[32m0.20029[0m[0m | time: 3.699s
[2K
| RMSProp | epoch: 022 | loss: 0.20029 - acc: 0.9206 -- iter: 0192/1443
[A[ATraining Step: 973  | total loss: [1m[32m0.26365[0m[0m | time: 4.302s
[2K
| RMSProp | epoch: 022 | loss: 0.26365 - acc: 0.8910 -- iter: 0224/1443
[A[ATraining Step: 974  | total loss: [1m[32m0.27310[0m[0m | time: 4.924s
[2K
| RMSProp | epoch: 022 | loss: 0.27310 - acc: 0.8894 -- iter: 0256/1443
[A[ATraining Step: 975  | total loss: [1m[32m0.26554[0m[0m | time: 5.532s
[2K
| RMSProp | epoch: 022 | loss: 0.26554 - acc: 0.8911 -- iter: 0288/1443
[A[ATraining Step: 976  | total loss: [1m[32m0.25811[0m[0m | time: 6.157s
[2K
| RMSProp | epoch: 022 | loss: 0.25811 - acc: 0.8958 -- iter: 0320/1443
[A[ATraining Step: 977  | total loss: [1m[32m0.23531[0m[0m | time: 6.781s
[2K
| RMSProp | epoch: 022 | loss: 0.23531 - acc: 0.9062 -- iter: 0352/1443
[A[ATraining Step: 978  | total loss: [1m[32m0.24317[0m[0m | time: 7.401s
[2K
| RMSProp | epoch: 022 | loss: 0.24317 - acc: 0.9031 -- iter: 0384/1443
[A[ATraining Step: 979  | total loss: [1m[32m0.25918[0m[0m | time: 8.041s
[2K
| RMSProp | epoch: 022 | loss: 0.25918 - acc: 0.8971 -- iter: 0416/1443
[A[ATraining Step: 980  | total loss: [1m[32m0.25288[0m[0m | time: 8.643s
[2K
| RMSProp | epoch: 022 | loss: 0.25288 - acc: 0.8980 -- iter: 0448/1443
[A[ATraining Step: 981  | total loss: [1m[32m0.25552[0m[0m | time: 9.240s
[2K
| RMSProp | epoch: 022 | loss: 0.25552 - acc: 0.8926 -- iter: 0480/1443
[A[ATraining Step: 982  | total loss: [1m[32m0.25655[0m[0m | time: 9.854s
[2K
| RMSProp | epoch: 022 | loss: 0.25655 - acc: 0.8940 -- iter: 0512/1443
[A[ATraining Step: 983  | total loss: [1m[32m0.25697[0m[0m | time: 10.462s
[2K
| RMSProp | epoch: 022 | loss: 0.25697 - acc: 0.8983 -- iter: 0544/1443
[A[ATraining Step: 984  | total loss: [1m[32m0.25667[0m[0m | time: 11.076s
[2K
| RMSProp | epoch: 022 | loss: 0.25667 - acc: 0.9022 -- iter: 0576/1443
[A[ATraining Step: 985  | total loss: [1m[32m0.23974[0m[0m | time: 11.697s
[2K
| RMSProp | epoch: 022 | loss: 0.23974 - acc: 0.9089 -- iter: 0608/1443
[A[ATraining Step: 986  | total loss: [1m[32m0.23695[0m[0m | time: 11.782s
[2K
| RMSProp | epoch: 022 | loss: 0.23695 - acc: 0.9149 -- iter: 0640/1443
[A[ATraining Step: 987  | total loss: [1m[32m0.21489[0m[0m | time: 11.868s
[2K
| RMSProp | epoch: 022 | loss: 0.21489 - acc: 0.9234 -- iter: 0672/1443
[A[ATraining Step: 988  | total loss: [1m[32m0.19399[0m[0m | time: 12.475s
[2K
| RMSProp | epoch: 022 | loss: 0.19399 - acc: 0.9311 -- iter: 0704/1443
[A[ATraining Step: 989  | total loss: [1m[32m0.20519[0m[0m | time: 13.093s
[2K
| RMSProp | epoch: 022 | loss: 0.20519 - acc: 0.9286 -- iter: 0736/1443
[A[ATraining Step: 990  | total loss: [1m[32m0.20267[0m[0m | time: 13.702s
[2K
| RMSProp | epoch: 022 | loss: 0.20267 - acc: 0.9263 -- iter: 0768/1443
[A[ATraining Step: 991  | total loss: [1m[32m0.19581[0m[0m | time: 14.339s
[2K
| RMSProp | epoch: 022 | loss: 0.19581 - acc: 0.9306 -- iter: 0800/1443
[A[ATraining Step: 992  | total loss: [1m[32m0.19273[0m[0m | time: 14.993s
[2K
| RMSProp | epoch: 022 | loss: 0.19273 - acc: 0.9313 -- iter: 0832/1443
[A[ATraining Step: 993  | total loss: [1m[32m0.21782[0m[0m | time: 15.617s
[2K
| RMSProp | epoch: 022 | loss: 0.21782 - acc: 0.9194 -- iter: 0864/1443
[A[ATraining Step: 994  | total loss: [1m[32m0.22605[0m[0m | time: 16.228s
[2K
| RMSProp | epoch: 022 | loss: 0.22605 - acc: 0.9150 -- iter: 0896/1443
[A[ATraining Step: 995  | total loss: [1m[32m0.22685[0m[0m | time: 16.856s
[2K
| RMSProp | epoch: 022 | loss: 0.22685 - acc: 0.9110 -- iter: 0928/1443
[A[ATraining Step: 996  | total loss: [1m[32m0.21957[0m[0m | time: 17.472s
[2K
| RMSProp | epoch: 022 | loss: 0.21957 - acc: 0.9136 -- iter: 0960/1443
[A[ATraining Step: 997  | total loss: [1m[32m0.21340[0m[0m | time: 18.091s
[2K
| RMSProp | epoch: 022 | loss: 0.21340 - acc: 0.9191 -- iter: 0992/1443
[A[ATraining Step: 998  | total loss: [1m[32m0.19795[0m[0m | time: 18.714s
[2K
| RMSProp | epoch: 022 | loss: 0.19795 - acc: 0.9272 -- iter: 1024/1443
[A[ATraining Step: 999  | total loss: [1m[32m0.18442[0m[0m | time: 19.325s
[2K
| RMSProp | epoch: 022 | loss: 0.18442 - acc: 0.9314 -- iter: 1056/1443
[A[ATraining Step: 1000  | total loss: [1m[32m0.19162[0m[0m | time: 21.364s
[2K
| RMSProp | epoch: 022 | loss: 0.19162 - acc: 0.9226 | val_loss: 1.03989 - val_acc: 0.7190 -- iter: 1088/1443
--
Training Step: 1001  | total loss: [1m[32m0.19968[0m[0m | time: 21.972s
[2K
| RMSProp | epoch: 022 | loss: 0.19968 - acc: 0.9178 -- iter: 1120/1443
[A[ATraining Step: 1002  | total loss: [1m[32m0.27122[0m[0m | time: 22.602s
[2K
| RMSProp | epoch: 022 | loss: 0.27122 - acc: 0.8979 -- iter: 1152/1443
[A[ATraining Step: 1003  | total loss: [1m[32m0.25197[0m[0m | time: 23.217s
[2K
| RMSProp | epoch: 022 | loss: 0.25197 - acc: 0.9081 -- iter: 1184/1443
[A[ATraining Step: 1004  | total loss: [1m[32m0.23916[0m[0m | time: 23.824s
[2K
| RMSProp | epoch: 022 | loss: 0.23916 - acc: 0.9111 -- iter: 1216/1443
[A[ATraining Step: 1005  | total loss: [1m[32m0.24136[0m[0m | time: 24.456s
[2K
| RMSProp | epoch: 022 | loss: 0.24136 - acc: 0.9106 -- iter: 1248/1443
[A[ATraining Step: 1006  | total loss: [1m[32m0.23304[0m[0m | time: 25.061s
[2K
| RMSProp | epoch: 022 | loss: 0.23304 - acc: 0.9133 -- iter: 1280/1443
[A[ATraining Step: 1007  | total loss: [1m[32m0.22580[0m[0m | time: 25.672s
[2K
| RMSProp | epoch: 022 | loss: 0.22580 - acc: 0.9188 -- iter: 1312/1443
[A[ATraining Step: 1008  | total loss: [1m[32m0.20844[0m[0m | time: 26.280s
[2K
| RMSProp | epoch: 022 | loss: 0.20844 - acc: 0.9269 -- iter: 1344/1443
[A[ATraining Step: 1009  | total loss: [1m[32m0.20034[0m[0m | time: 26.897s
[2K
| RMSProp | epoch: 022 | loss: 0.20034 - acc: 0.9311 -- iter: 1376/1443
[A[ATraining Step: 1010  | total loss: [1m[32m0.18582[0m[0m | time: 27.509s
[2K
| RMSProp | epoch: 022 | loss: 0.18582 - acc: 0.9380 -- iter: 1408/1443
[A[ATraining Step: 1011  | total loss: [1m[32m0.18092[0m[0m | time: 28.155s
[2K
| RMSProp | epoch: 022 | loss: 0.18092 - acc: 0.9411 -- iter: 1440/1443
[A[ATraining Step: 1012  | total loss: [1m[32m0.20229[0m[0m | time: 30.208s
[2K
| RMSProp | epoch: 022 | loss: 0.20229 - acc: 0.9314 | val_loss: 0.78380 - val_acc: 0.7279 -- iter: 1443/1443
--
Training Step: 1013  | total loss: [1m[32m0.21538[0m[0m | time: 0.622s
[2K
| RMSProp | epoch: 023 | loss: 0.21538 - acc: 0.9226 -- iter: 0032/1443
[A[ATraining Step: 1014  | total loss: [1m[32m0.19987[0m[0m | time: 1.232s
[2K
| RMSProp | epoch: 023 | loss: 0.19987 - acc: 0.9303 -- iter: 0064/1443
[A[ATraining Step: 1015  | total loss: [1m[32m0.18412[0m[0m | time: 1.850s
[2K
| RMSProp | epoch: 023 | loss: 0.18412 - acc: 0.9373 -- iter: 0096/1443
[A[ATraining Step: 1016  | total loss: [1m[32m0.17631[0m[0m | time: 2.453s
[2K
| RMSProp | epoch: 023 | loss: 0.17631 - acc: 0.9404 -- iter: 0128/1443
[A[ATraining Step: 1017  | total loss: [1m[32m0.17858[0m[0m | time: 3.061s
[2K
| RMSProp | epoch: 023 | loss: 0.17858 - acc: 0.9370 -- iter: 0160/1443
[A[ATraining Step: 1018  | total loss: [1m[32m0.18640[0m[0m | time: 3.673s
[2K
| RMSProp | epoch: 023 | loss: 0.18640 - acc: 0.9308 -- iter: 0192/1443
[A[ATraining Step: 1019  | total loss: [1m[32m0.17464[0m[0m | time: 4.267s
[2K
| RMSProp | epoch: 023 | loss: 0.17464 - acc: 0.9346 -- iter: 0224/1443
[A[ATraining Step: 1020  | total loss: [1m[32m0.18058[0m[0m | time: 4.881s
[2K
| RMSProp | epoch: 023 | loss: 0.18058 - acc: 0.9318 -- iter: 0256/1443
[A[ATraining Step: 1021  | total loss: [1m[32m0.17952[0m[0m | time: 5.507s
[2K
| RMSProp | epoch: 023 | loss: 0.17952 - acc: 0.9324 -- iter: 0288/1443
[A[ATraining Step: 1022  | total loss: [1m[32m0.17262[0m[0m | time: 6.132s
[2K
| RMSProp | epoch: 023 | loss: 0.17262 - acc: 0.9329 -- iter: 0320/1443
[A[ATraining Step: 1023  | total loss: [1m[32m0.16205[0m[0m | time: 6.768s
[2K
| RMSProp | epoch: 023 | loss: 0.16205 - acc: 0.9396 -- iter: 0352/1443
[A[ATraining Step: 1024  | total loss: [1m[32m0.15426[0m[0m | time: 7.381s
[2K
| RMSProp | epoch: 023 | loss: 0.15426 - acc: 0.9425 -- iter: 0384/1443
[A[ATraining Step: 1025  | total loss: [1m[32m0.14906[0m[0m | time: 7.996s
[2K
| RMSProp | epoch: 023 | loss: 0.14906 - acc: 0.9451 -- iter: 0416/1443
[A[ATraining Step: 1026  | total loss: [1m[32m0.15046[0m[0m | time: 8.607s
[2K
| RMSProp | epoch: 023 | loss: 0.15046 - acc: 0.9475 -- iter: 0448/1443
[A[ATraining Step: 1027  | total loss: [1m[32m0.14728[0m[0m | time: 9.201s
[2K
| RMSProp | epoch: 023 | loss: 0.14728 - acc: 0.9496 -- iter: 0480/1443
[A[ATraining Step: 1028  | total loss: [1m[32m0.14569[0m[0m | time: 9.817s
[2K
| RMSProp | epoch: 023 | loss: 0.14569 - acc: 0.9453 -- iter: 0512/1443
[A[ATraining Step: 1029  | total loss: [1m[32m0.14175[0m[0m | time: 10.427s
[2K
| RMSProp | epoch: 023 | loss: 0.14175 - acc: 0.9476 -- iter: 0544/1443
[A[ATraining Step: 1030  | total loss: [1m[32m0.13735[0m[0m | time: 11.066s
[2K
| RMSProp | epoch: 023 | loss: 0.13735 - acc: 0.9497 -- iter: 0576/1443
[A[ATraining Step: 1031  | total loss: [1m[32m0.16648[0m[0m | time: 11.692s
[2K
| RMSProp | epoch: 023 | loss: 0.16648 - acc: 0.9454 -- iter: 0608/1443
[A[ATraining Step: 1032  | total loss: [1m[32m0.17946[0m[0m | time: 12.317s
[2K
| RMSProp | epoch: 023 | loss: 0.17946 - acc: 0.9415 -- iter: 0640/1443
[A[ATraining Step: 1033  | total loss: [1m[32m0.16810[0m[0m | time: 12.408s
[2K
| RMSProp | epoch: 023 | loss: 0.16810 - acc: 0.9473 -- iter: 0672/1443
[A[ATraining Step: 1034  | total loss: [1m[32m0.15778[0m[0m | time: 12.494s
[2K
| RMSProp | epoch: 023 | loss: 0.15778 - acc: 0.9526 -- iter: 0704/1443
[A[ATraining Step: 1035  | total loss: [1m[32m0.14215[0m[0m | time: 13.115s
[2K
| RMSProp | epoch: 023 | loss: 0.14215 - acc: 0.9573 -- iter: 0736/1443
[A[ATraining Step: 1036  | total loss: [1m[32m0.18687[0m[0m | time: 13.733s
[2K
| RMSProp | epoch: 023 | loss: 0.18687 - acc: 0.9460 -- iter: 0768/1443
[A[ATraining Step: 1037  | total loss: [1m[32m0.21234[0m[0m | time: 14.369s
[2K
| RMSProp | epoch: 023 | loss: 0.21234 - acc: 0.9326 -- iter: 0800/1443
[A[ATraining Step: 1038  | total loss: [1m[32m0.22664[0m[0m | time: 15.007s
[2K
| RMSProp | epoch: 023 | loss: 0.22664 - acc: 0.9300 -- iter: 0832/1443
[A[ATraining Step: 1039  | total loss: [1m[32m0.22816[0m[0m | time: 15.629s
[2K
| RMSProp | epoch: 023 | loss: 0.22816 - acc: 0.9307 -- iter: 0864/1443
[A[ATraining Step: 1040  | total loss: [1m[32m0.23444[0m[0m | time: 16.241s
[2K
| RMSProp | epoch: 023 | loss: 0.23444 - acc: 0.9283 -- iter: 0896/1443
[A[ATraining Step: 1041  | total loss: [1m[32m0.22161[0m[0m | time: 16.851s
[2K
| RMSProp | epoch: 023 | loss: 0.22161 - acc: 0.9355 -- iter: 0928/1443
[A[ATraining Step: 1042  | total loss: [1m[32m0.21718[0m[0m | time: 17.474s
[2K
| RMSProp | epoch: 023 | loss: 0.21718 - acc: 0.9388 -- iter: 0960/1443
[A[ATraining Step: 1043  | total loss: [1m[32m0.20783[0m[0m | time: 18.083s
[2K
| RMSProp | epoch: 023 | loss: 0.20783 - acc: 0.9387 -- iter: 0992/1443
[A[ATraining Step: 1044  | total loss: [1m[32m0.23421[0m[0m | time: 18.718s
[2K
| RMSProp | epoch: 023 | loss: 0.23421 - acc: 0.9292 -- iter: 1024/1443
[A[ATraining Step: 1045  | total loss: [1m[32m0.25445[0m[0m | time: 19.326s
[2K
| RMSProp | epoch: 023 | loss: 0.25445 - acc: 0.9206 -- iter: 1056/1443
[A[ATraining Step: 1046  | total loss: [1m[32m0.24426[0m[0m | time: 19.936s
[2K
| RMSProp | epoch: 023 | loss: 0.24426 - acc: 0.9192 -- iter: 1088/1443
[A[ATraining Step: 1047  | total loss: [1m[32m0.24170[0m[0m | time: 20.564s
[2K
| RMSProp | epoch: 023 | loss: 0.24170 - acc: 0.9179 -- iter: 1120/1443
[A[ATraining Step: 1048  | total loss: [1m[32m0.23662[0m[0m | time: 21.185s
[2K
| RMSProp | epoch: 023 | loss: 0.23662 - acc: 0.9167 -- iter: 1152/1443
[A[ATraining Step: 1049  | total loss: [1m[32m0.26514[0m[0m | time: 21.791s
[2K
| RMSProp | epoch: 023 | loss: 0.26514 - acc: 0.9001 -- iter: 1184/1443
[A[ATraining Step: 1050  | total loss: [1m[32m0.24960[0m[0m | time: 22.404s
[2K
| RMSProp | epoch: 023 | loss: 0.24960 - acc: 0.9069 -- iter: 1216/1443
[A[ATraining Step: 1051  | total loss: [1m[32m0.23670[0m[0m | time: 23.028s
[2K
| RMSProp | epoch: 023 | loss: 0.23670 - acc: 0.9131 -- iter: 1248/1443
[A[ATraining Step: 1052  | total loss: [1m[32m0.22075[0m[0m | time: 23.632s
[2K
| RMSProp | epoch: 023 | loss: 0.22075 - acc: 0.9187 -- iter: 1280/1443
[A[ATraining Step: 1053  | total loss: [1m[32m0.22341[0m[0m | time: 24.261s
[2K
| RMSProp | epoch: 023 | loss: 0.22341 - acc: 0.9206 -- iter: 1312/1443
[A[ATraining Step: 1054  | total loss: [1m[32m0.21877[0m[0m | time: 24.891s
[2K
| RMSProp | epoch: 023 | loss: 0.21877 - acc: 0.9223 -- iter: 1344/1443
[A[ATraining Step: 1055  | total loss: [1m[32m0.21928[0m[0m | time: 25.504s
[2K
| RMSProp | epoch: 023 | loss: 0.21928 - acc: 0.9207 -- iter: 1376/1443
[A[ATraining Step: 1056  | total loss: [1m[32m0.20898[0m[0m | time: 26.120s
[2K
| RMSProp | epoch: 023 | loss: 0.20898 - acc: 0.9255 -- iter: 1408/1443
[A[ATraining Step: 1057  | total loss: [1m[32m0.19986[0m[0m | time: 26.747s
[2K
| RMSProp | epoch: 023 | loss: 0.19986 - acc: 0.9298 -- iter: 1440/1443
[A[ATraining Step: 1058  | total loss: [1m[32m0.19393[0m[0m | time: 28.820s
[2K
| RMSProp | epoch: 023 | loss: 0.19393 - acc: 0.9337 | val_loss: 0.73565 - val_acc: 0.7190 -- iter: 1443/1443
--
Training Step: 1059  | total loss: [1m[32m0.19329[0m[0m | time: 0.652s
[2K
| RMSProp | epoch: 024 | loss: 0.19329 - acc: 0.9309 -- iter: 0032/1443
[A[ATraining Step: 1060  | total loss: [1m[32m0.18300[0m[0m | time: 1.259s
[2K
| RMSProp | epoch: 024 | loss: 0.18300 - acc: 0.9347 -- iter: 0064/1443
[A[ATraining Step: 1061  | total loss: [1m[32m0.16659[0m[0m | time: 1.872s
[2K
| RMSProp | epoch: 024 | loss: 0.16659 - acc: 0.9413 -- iter: 0096/1443
[A[ATraining Step: 1062  | total loss: [1m[32m0.17429[0m[0m | time: 2.493s
[2K
| RMSProp | epoch: 024 | loss: 0.17429 - acc: 0.9378 -- iter: 0128/1443
[A[ATraining Step: 1063  | total loss: [1m[32m0.19433[0m[0m | time: 3.108s
[2K
| RMSProp | epoch: 024 | loss: 0.19433 - acc: 0.9221 -- iter: 0160/1443
[A[ATraining Step: 1064  | total loss: [1m[32m0.20378[0m[0m | time: 3.710s
[2K
| RMSProp | epoch: 024 | loss: 0.20378 - acc: 0.9205 -- iter: 0192/1443
[A[ATraining Step: 1065  | total loss: [1m[32m0.21081[0m[0m | time: 4.315s
[2K
| RMSProp | epoch: 024 | loss: 0.21081 - acc: 0.9191 -- iter: 0224/1443
[A[ATraining Step: 1066  | total loss: [1m[32m0.20355[0m[0m | time: 4.918s
[2K
| RMSProp | epoch: 024 | loss: 0.20355 - acc: 0.9209 -- iter: 0256/1443
[A[ATraining Step: 1067  | total loss: [1m[32m0.19341[0m[0m | time: 5.529s
[2K
| RMSProp | epoch: 024 | loss: 0.19341 - acc: 0.9257 -- iter: 0288/1443
[A[ATraining Step: 1068  | total loss: [1m[32m0.18250[0m[0m | time: 6.156s
[2K
| RMSProp | epoch: 024 | loss: 0.18250 - acc: 0.9269 -- iter: 0320/1443
[A[ATraining Step: 1069  | total loss: [1m[32m0.17337[0m[0m | time: 6.795s
[2K
| RMSProp | epoch: 024 | loss: 0.17337 - acc: 0.9311 -- iter: 0352/1443
[A[ATraining Step: 1070  | total loss: [1m[32m0.17361[0m[0m | time: 7.407s
[2K
| RMSProp | epoch: 024 | loss: 0.17361 - acc: 0.9317 -- iter: 0384/1443
[A[ATraining Step: 1071  | total loss: [1m[32m0.17439[0m[0m | time: 8.038s
[2K
| RMSProp | epoch: 024 | loss: 0.17439 - acc: 0.9292 -- iter: 0416/1443
[A[ATraining Step: 1072  | total loss: [1m[32m0.16236[0m[0m | time: 8.643s
[2K
| RMSProp | epoch: 024 | loss: 0.16236 - acc: 0.9331 -- iter: 0448/1443
[A[ATraining Step: 1073  | total loss: [1m[32m0.15450[0m[0m | time: 9.255s
[2K
| RMSProp | epoch: 024 | loss: 0.15450 - acc: 0.9336 -- iter: 0480/1443
[A[ATraining Step: 1074  | total loss: [1m[32m0.17012[0m[0m | time: 9.866s
[2K
| RMSProp | epoch: 024 | loss: 0.17012 - acc: 0.9246 -- iter: 0512/1443
[A[ATraining Step: 1075  | total loss: [1m[32m0.19908[0m[0m | time: 10.491s
[2K
| RMSProp | epoch: 024 | loss: 0.19908 - acc: 0.9165 -- iter: 0544/1443
[A[ATraining Step: 1076  | total loss: [1m[32m0.18597[0m[0m | time: 11.104s
[2K
| RMSProp | epoch: 024 | loss: 0.18597 - acc: 0.9249 -- iter: 0576/1443
[A[ATraining Step: 1077  | total loss: [1m[32m0.20757[0m[0m | time: 11.732s
[2K
| RMSProp | epoch: 024 | loss: 0.20757 - acc: 0.9167 -- iter: 0608/1443
[A[ATraining Step: 1078  | total loss: [1m[32m0.20263[0m[0m | time: 12.354s
[2K
| RMSProp | epoch: 024 | loss: 0.20263 - acc: 0.9188 -- iter: 0640/1443
[A[ATraining Step: 1079  | total loss: [1m[32m0.20921[0m[0m | time: 12.971s
[2K
| RMSProp | epoch: 024 | loss: 0.20921 - acc: 0.9176 -- iter: 0672/1443
[A[ATraining Step: 1080  | total loss: [1m[32m0.20413[0m[0m | time: 13.061s
[2K
| RMSProp | epoch: 024 | loss: 0.20413 - acc: 0.9164 -- iter: 0704/1443
[A[ATraining Step: 1081  | total loss: [1m[32m0.18586[0m[0m | time: 13.151s
[2K
| RMSProp | epoch: 024 | loss: 0.18586 - acc: 0.9248 -- iter: 0736/1443
[A[ATraining Step: 1082  | total loss: [1m[32m0.16807[0m[0m | time: 13.766s
[2K
| RMSProp | epoch: 024 | loss: 0.16807 - acc: 0.9323 -- iter: 0768/1443
[A[ATraining Step: 1083  | total loss: [1m[32m0.18232[0m[0m | time: 14.382s
[2K
| RMSProp | epoch: 024 | loss: 0.18232 - acc: 0.9297 -- iter: 0800/1443
[A[ATraining Step: 1084  | total loss: [1m[32m0.18798[0m[0m | time: 15.023s
[2K
| RMSProp | epoch: 024 | loss: 0.18798 - acc: 0.9274 -- iter: 0832/1443
[A[ATraining Step: 1085  | total loss: [1m[32m0.18844[0m[0m | time: 15.647s
[2K
| RMSProp | epoch: 024 | loss: 0.18844 - acc: 0.9284 -- iter: 0864/1443
[A[ATraining Step: 1086  | total loss: [1m[32m0.18131[0m[0m | time: 16.252s
[2K
| RMSProp | epoch: 024 | loss: 0.18131 - acc: 0.9324 -- iter: 0896/1443
[A[ATraining Step: 1087  | total loss: [1m[32m0.17555[0m[0m | time: 16.875s
[2K
| RMSProp | epoch: 024 | loss: 0.17555 - acc: 0.9360 -- iter: 0928/1443
[A[ATraining Step: 1088  | total loss: [1m[32m0.16903[0m[0m | time: 17.493s
[2K
| RMSProp | epoch: 024 | loss: 0.16903 - acc: 0.9393 -- iter: 0960/1443
[A[ATraining Step: 1089  | total loss: [1m[32m0.19218[0m[0m | time: 18.106s
[2K
| RMSProp | epoch: 024 | loss: 0.19218 - acc: 0.9298 -- iter: 0992/1443
[A[ATraining Step: 1090  | total loss: [1m[32m0.19396[0m[0m | time: 18.720s
[2K
| RMSProp | epoch: 024 | loss: 0.19396 - acc: 0.9305 -- iter: 1024/1443
[A[ATraining Step: 1091  | total loss: [1m[32m0.20132[0m[0m | time: 19.321s
[2K
| RMSProp | epoch: 024 | loss: 0.20132 - acc: 0.9281 -- iter: 1056/1443
[A[ATraining Step: 1092  | total loss: [1m[32m0.21024[0m[0m | time: 19.925s
[2K
| RMSProp | epoch: 024 | loss: 0.21024 - acc: 0.9259 -- iter: 1088/1443
[A[ATraining Step: 1093  | total loss: [1m[32m0.22813[0m[0m | time: 20.535s
[2K
| RMSProp | epoch: 024 | loss: 0.22813 - acc: 0.9146 -- iter: 1120/1443
[A[ATraining Step: 1094  | total loss: [1m[32m0.22523[0m[0m | time: 21.152s
[2K
| RMSProp | epoch: 024 | loss: 0.22523 - acc: 0.9106 -- iter: 1152/1443
[A[ATraining Step: 1095  | total loss: [1m[32m0.21380[0m[0m | time: 21.773s
[2K
| RMSProp | epoch: 024 | loss: 0.21380 - acc: 0.9196 -- iter: 1184/1443
[A[ATraining Step: 1096  | total loss: [1m[32m0.21506[0m[0m | time: 22.390s
[2K
| RMSProp | epoch: 024 | loss: 0.21506 - acc: 0.9245 -- iter: 1216/1443
[A[ATraining Step: 1097  | total loss: [1m[32m0.20871[0m[0m | time: 23.021s
[2K
| RMSProp | epoch: 024 | loss: 0.20871 - acc: 0.9289 -- iter: 1248/1443
[A[ATraining Step: 1098  | total loss: [1m[32m0.24251[0m[0m | time: 23.632s
[2K
| RMSProp | epoch: 024 | loss: 0.24251 - acc: 0.9204 -- iter: 1280/1443
[A[ATraining Step: 1099  | total loss: [1m[32m0.23133[0m[0m | time: 24.267s
[2K
| RMSProp | epoch: 024 | loss: 0.23133 - acc: 0.9252 -- iter: 1312/1443
[A[ATraining Step: 1100  | total loss: [1m[32m0.23830[0m[0m | time: 24.893s
[2K
| RMSProp | epoch: 024 | loss: 0.23830 - acc: 0.9202 -- iter: 1344/1443
[A[ATraining Step: 1101  | total loss: [1m[32m0.23160[0m[0m | time: 25.506s
[2K
| RMSProp | epoch: 024 | loss: 0.23160 - acc: 0.9219 -- iter: 1376/1443
[A[ATraining Step: 1102  | total loss: [1m[32m0.22241[0m[0m | time: 26.134s
[2K
| RMSProp | epoch: 024 | loss: 0.22241 - acc: 0.9266 -- iter: 1408/1443
[A[ATraining Step: 1103  | total loss: [1m[32m0.21296[0m[0m | time: 26.745s
[2K
| RMSProp | epoch: 024 | loss: 0.21296 - acc: 0.9308 -- iter: 1440/1443
[A[ATraining Step: 1104  | total loss: [1m[32m0.20209[0m[0m | time: 28.876s
[2K
| RMSProp | epoch: 024 | loss: 0.20209 - acc: 0.9346 | val_loss: 0.86123 - val_acc: 0.7301 -- iter: 1443/1443
--
Training Step: 1105  | total loss: [1m[32m0.18790[0m[0m | time: 0.630s
[2K
| RMSProp | epoch: 025 | loss: 0.18790 - acc: 0.9412 -- iter: 0032/1443
[A[ATraining Step: 1106  | total loss: [1m[32m0.18490[0m[0m | time: 1.259s
[2K
| RMSProp | epoch: 025 | loss: 0.18490 - acc: 0.9408 -- iter: 0064/1443
[A[ATraining Step: 1107  | total loss: [1m[32m0.16804[0m[0m | time: 1.888s
[2K
| RMSProp | epoch: 025 | loss: 0.16804 - acc: 0.9467 -- iter: 0096/1443
[A[ATraining Step: 1108  | total loss: [1m[32m0.16663[0m[0m | time: 2.517s
[2K
| RMSProp | epoch: 025 | loss: 0.16663 - acc: 0.9458 -- iter: 0128/1443
[A[ATraining Step: 1109  | total loss: [1m[32m0.15965[0m[0m | time: 3.146s
[2K
| RMSProp | epoch: 025 | loss: 0.15965 - acc: 0.9450 -- iter: 0160/1443
[A[ATraining Step: 1110  | total loss: [1m[32m0.18683[0m[0m | time: 3.751s
[2K
| RMSProp | epoch: 025 | loss: 0.18683 - acc: 0.9380 -- iter: 0192/1443
[A[ATraining Step: 1111  | total loss: [1m[32m0.18080[0m[0m | time: 4.375s
[2K
| RMSProp | epoch: 025 | loss: 0.18080 - acc: 0.9410 -- iter: 0224/1443
[A[ATraining Step: 1112  | total loss: [1m[32m0.18924[0m[0m | time: 5.017s
[2K
| RMSProp | epoch: 025 | loss: 0.18924 - acc: 0.9313 -- iter: 0256/1443
[A[ATraining Step: 1113  | total loss: [1m[32m0.18535[0m[0m | time: 5.638s
[2K
| RMSProp | epoch: 025 | loss: 0.18535 - acc: 0.9319 -- iter: 0288/1443
[A[ATraining Step: 1114  | total loss: [1m[32m0.19736[0m[0m | time: 6.268s
[2K
| RMSProp | epoch: 025 | loss: 0.19736 - acc: 0.9262 -- iter: 0320/1443
[A[ATraining Step: 1115  | total loss: [1m[32m0.19321[0m[0m | time: 6.929s
[2K
| RMSProp | epoch: 025 | loss: 0.19321 - acc: 0.9305 -- iter: 0352/1443
[A[ATraining Step: 1116  | total loss: [1m[32m0.18136[0m[0m | time: 7.547s
[2K
| RMSProp | epoch: 025 | loss: 0.18136 - acc: 0.9343 -- iter: 0384/1443
[A[ATraining Step: 1117  | total loss: [1m[32m0.17047[0m[0m | time: 8.221s
[2K
| RMSProp | epoch: 025 | loss: 0.17047 - acc: 0.9378 -- iter: 0416/1443
[A[ATraining Step: 1118  | total loss: [1m[32m0.17071[0m[0m | time: 8.842s
[2K
| RMSProp | epoch: 025 | loss: 0.17071 - acc: 0.9377 -- iter: 0448/1443
[A[ATraining Step: 1119  | total loss: [1m[32m0.16715[0m[0m | time: 9.460s
[2K
| RMSProp | epoch: 025 | loss: 0.16715 - acc: 0.9408 -- iter: 0480/1443
[A[ATraining Step: 1120  | total loss: [1m[32m0.17484[0m[0m | time: 10.082s
[2K
| RMSProp | epoch: 025 | loss: 0.17484 - acc: 0.9374 -- iter: 0512/1443
[A[ATraining Step: 1121  | total loss: [1m[32m0.17433[0m[0m | time: 10.714s
[2K
| RMSProp | epoch: 025 | loss: 0.17433 - acc: 0.9343 -- iter: 0544/1443
[A[ATraining Step: 1122  | total loss: [1m[32m0.18444[0m[0m | time: 11.330s
[2K
| RMSProp | epoch: 025 | loss: 0.18444 - acc: 0.9221 -- iter: 0576/1443
[A[ATraining Step: 1123  | total loss: [1m[32m0.19233[0m[0m | time: 11.943s
[2K
| RMSProp | epoch: 025 | loss: 0.19233 - acc: 0.9174 -- iter: 0608/1443
[A[ATraining Step: 1124  | total loss: [1m[32m0.17899[0m[0m | time: 12.585s
[2K
| RMSProp | epoch: 025 | loss: 0.17899 - acc: 0.9256 -- iter: 0640/1443
[A[ATraining Step: 1125  | total loss: [1m[32m0.17662[0m[0m | time: 13.186s
[2K
| RMSProp | epoch: 025 | loss: 0.17662 - acc: 0.9237 -- iter: 0672/1443
[A[ATraining Step: 1126  | total loss: [1m[32m0.17540[0m[0m | time: 13.825s
[2K
| RMSProp | epoch: 025 | loss: 0.17540 - acc: 0.9282 -- iter: 0704/1443
[A[ATraining Step: 1127  | total loss: [1m[32m0.18346[0m[0m | time: 13.911s
[2K
| RMSProp | epoch: 025 | loss: 0.18346 - acc: 0.9260 -- iter: 0736/1443
[A[ATraining Step: 1128  | total loss: [1m[32m0.17107[0m[0m | time: 13.998s
[2K
| RMSProp | epoch: 025 | loss: 0.17107 - acc: 0.9334 -- iter: 0768/1443
[A[ATraining Step: 1129  | total loss: [1m[32m0.15463[0m[0m | time: 14.621s
[2K
| RMSProp | epoch: 025 | loss: 0.15463 - acc: 0.9401 -- iter: 0800/1443
[A[ATraining Step: 1130  | total loss: [1m[32m0.16161[0m[0m | time: 15.240s
[2K
| RMSProp | epoch: 025 | loss: 0.16161 - acc: 0.9367 -- iter: 0832/1443
[A[ATraining Step: 1131  | total loss: [1m[32m0.16545[0m[0m | time: 15.857s
[2K
| RMSProp | epoch: 025 | loss: 0.16545 - acc: 0.9368 -- iter: 0864/1443
[A[ATraining Step: 1132  | total loss: [1m[32m0.16465[0m[0m | time: 16.473s
[2K
| RMSProp | epoch: 025 | loss: 0.16465 - acc: 0.9368 -- iter: 0896/1443
[A[ATraining Step: 1133  | total loss: [1m[32m0.15196[0m[0m | time: 17.079s
[2K
| RMSProp | epoch: 025 | loss: 0.15196 - acc: 0.9432 -- iter: 0928/1443
[A[ATraining Step: 1134  | total loss: [1m[32m0.15335[0m[0m | time: 17.699s
[2K
| RMSProp | epoch: 025 | loss: 0.15335 - acc: 0.9457 -- iter: 0960/1443
[A[ATraining Step: 1135  | total loss: [1m[32m0.17830[0m[0m | time: 18.334s
[2K
| RMSProp | epoch: 025 | loss: 0.17830 - acc: 0.9355 -- iter: 0992/1443
[A[ATraining Step: 1136  | total loss: [1m[32m0.16774[0m[0m | time: 18.960s
[2K
| RMSProp | epoch: 025 | loss: 0.16774 - acc: 0.9388 -- iter: 1024/1443
[A[ATraining Step: 1137  | total loss: [1m[32m0.16331[0m[0m | time: 19.591s
[2K
| RMSProp | epoch: 025 | loss: 0.16331 - acc: 0.9418 -- iter: 1056/1443
[A[ATraining Step: 1138  | total loss: [1m[32m0.15644[0m[0m | time: 20.188s
[2K
| RMSProp | epoch: 025 | loss: 0.15644 - acc: 0.9445 -- iter: 1088/1443
[A[ATraining Step: 1139  | total loss: [1m[32m0.14840[0m[0m | time: 20.796s
[2K
| RMSProp | epoch: 025 | loss: 0.14840 - acc: 0.9469 -- iter: 1120/1443
[A[ATraining Step: 1140  | total loss: [1m[32m0.14175[0m[0m | time: 21.412s
[2K
| RMSProp | epoch: 025 | loss: 0.14175 - acc: 0.9491 -- iter: 1152/1443
[A[ATraining Step: 1141  | total loss: [1m[32m0.15788[0m[0m | time: 22.021s
[2K
| RMSProp | epoch: 025 | loss: 0.15788 - acc: 0.9448 -- iter: 1184/1443
[A[ATraining Step: 1142  | total loss: [1m[32m0.15263[0m[0m | time: 22.645s
[2K
| RMSProp | epoch: 025 | loss: 0.15263 - acc: 0.9504 -- iter: 1216/1443
[A[ATraining Step: 1143  | total loss: [1m[32m0.15831[0m[0m | time: 23.263s
[2K
| RMSProp | epoch: 025 | loss: 0.15831 - acc: 0.9491 -- iter: 1248/1443
[A[ATraining Step: 1144  | total loss: [1m[32m0.16278[0m[0m | time: 23.875s
[2K
| RMSProp | epoch: 025 | loss: 0.16278 - acc: 0.9479 -- iter: 1280/1443
[A[ATraining Step: 1145  | total loss: [1m[32m0.16878[0m[0m | time: 24.487s
[2K
| RMSProp | epoch: 025 | loss: 0.16878 - acc: 0.9437 -- iter: 1312/1443
[A[ATraining Step: 1146  | total loss: [1m[32m0.18893[0m[0m | time: 25.095s
[2K
| RMSProp | epoch: 025 | loss: 0.18893 - acc: 0.9337 -- iter: 1344/1443
[A[ATraining Step: 1147  | total loss: [1m[32m0.18945[0m[0m | time: 25.698s
[2K
| RMSProp | epoch: 025 | loss: 0.18945 - acc: 0.9310 -- iter: 1376/1443
[A[ATraining Step: 1148  | total loss: [1m[32m0.17831[0m[0m | time: 26.303s
[2K
| RMSProp | epoch: 025 | loss: 0.17831 - acc: 0.9348 -- iter: 1408/1443
[A[ATraining Step: 1149  | total loss: [1m[32m0.16506[0m[0m | time: 26.916s
[2K
| RMSProp | epoch: 025 | loss: 0.16506 - acc: 0.9382 -- iter: 1440/1443
[A[ATraining Step: 1150  | total loss: [1m[32m0.15552[0m[0m | time: 28.975s
[2K
| RMSProp | epoch: 025 | loss: 0.15552 - acc: 0.9412 | val_loss: 1.20644 - val_acc: 0.6350 -- iter: 1443/1443
--
Training Step: 1151  | total loss: [1m[32m0.16060[0m[0m | time: 0.637s
[2K
| RMSProp | epoch: 026 | loss: 0.16060 - acc: 0.9377 -- iter: 0032/1443
[A[ATraining Step: 1152  | total loss: [1m[32m0.16605[0m[0m | time: 1.273s
[2K
| RMSProp | epoch: 026 | loss: 0.16605 - acc: 0.9315 -- iter: 0064/1443
[A[ATraining Step: 1153  | total loss: [1m[32m0.16173[0m[0m | time: 1.900s
[2K
| RMSProp | epoch: 026 | loss: 0.16173 - acc: 0.9352 -- iter: 0096/1443
[A[ATraining Step: 1154  | total loss: [1m[32m0.17245[0m[0m | time: 2.507s
[2K
| RMSProp | epoch: 026 | loss: 0.17245 - acc: 0.9354 -- iter: 0128/1443
[A[ATraining Step: 1155  | total loss: [1m[32m0.16965[0m[0m | time: 3.120s
[2K
| RMSProp | epoch: 026 | loss: 0.16965 - acc: 0.9388 -- iter: 0160/1443
[A[ATraining Step: 1156  | total loss: [1m[32m0.15651[0m[0m | time: 3.748s
[2K
| RMSProp | epoch: 026 | loss: 0.15651 - acc: 0.9449 -- iter: 0192/1443
[A[ATraining Step: 1157  | total loss: [1m[32m0.15837[0m[0m | time: 4.353s
[2K
| RMSProp | epoch: 026 | loss: 0.15837 - acc: 0.9441 -- iter: 0224/1443
[A[ATraining Step: 1158  | total loss: [1m[32m0.15800[0m[0m | time: 4.964s
[2K
| RMSProp | epoch: 026 | loss: 0.15800 - acc: 0.9435 -- iter: 0256/1443
[A[ATraining Step: 1159  | total loss: [1m[32m0.15959[0m[0m | time: 5.567s
[2K
| RMSProp | epoch: 026 | loss: 0.15959 - acc: 0.9398 -- iter: 0288/1443
[A[ATraining Step: 1160  | total loss: [1m[32m0.15094[0m[0m | time: 6.188s
[2K
| RMSProp | epoch: 026 | loss: 0.15094 - acc: 0.9427 -- iter: 0320/1443
[A[ATraining Step: 1161  | total loss: [1m[32m0.14631[0m[0m | time: 6.796s
[2K
| RMSProp | epoch: 026 | loss: 0.14631 - acc: 0.9453 -- iter: 0352/1443
[A[ATraining Step: 1162  | total loss: [1m[32m0.15878[0m[0m | time: 7.399s
[2K
| RMSProp | epoch: 026 | loss: 0.15878 - acc: 0.9414 -- iter: 0384/1443
[A[ATraining Step: 1163  | total loss: [1m[32m0.15026[0m[0m | time: 8.005s
[2K
| RMSProp | epoch: 026 | loss: 0.15026 - acc: 0.9441 -- iter: 0416/1443
[A[ATraining Step: 1164  | total loss: [1m[32m0.17495[0m[0m | time: 8.605s
[2K
| RMSProp | epoch: 026 | loss: 0.17495 - acc: 0.9372 -- iter: 0448/1443
[A[ATraining Step: 1165  | total loss: [1m[32m0.17007[0m[0m | time: 9.224s
[2K
| RMSProp | epoch: 026 | loss: 0.17007 - acc: 0.9403 -- iter: 0480/1443
[A[ATraining Step: 1166  | total loss: [1m[32m0.15503[0m[0m | time: 9.824s
[2K
| RMSProp | epoch: 026 | loss: 0.15503 - acc: 0.9463 -- iter: 0512/1443
[A[ATraining Step: 1167  | total loss: [1m[32m0.16534[0m[0m | time: 10.425s
[2K
| RMSProp | epoch: 026 | loss: 0.16534 - acc: 0.9423 -- iter: 0544/1443
[A[ATraining Step: 1168  | total loss: [1m[32m0.16246[0m[0m | time: 11.026s
[2K
| RMSProp | epoch: 026 | loss: 0.16246 - acc: 0.9418 -- iter: 0576/1443
[A[ATraining Step: 1169  | total loss: [1m[32m0.17786[0m[0m | time: 11.651s
[2K
| RMSProp | epoch: 026 | loss: 0.17786 - acc: 0.9351 -- iter: 0608/1443
[A[ATraining Step: 1170  | total loss: [1m[32m0.17811[0m[0m | time: 12.270s
[2K
| RMSProp | epoch: 026 | loss: 0.17811 - acc: 0.9354 -- iter: 0640/1443
[A[ATraining Step: 1171  | total loss: [1m[32m0.17864[0m[0m | time: 12.874s
[2K
| RMSProp | epoch: 026 | loss: 0.17864 - acc: 0.9387 -- iter: 0672/1443
[A[ATraining Step: 1172  | total loss: [1m[32m0.16669[0m[0m | time: 13.505s
[2K
| RMSProp | epoch: 026 | loss: 0.16669 - acc: 0.9417 -- iter: 0704/1443
[A[ATraining Step: 1173  | total loss: [1m[32m0.16364[0m[0m | time: 14.155s
[2K
| RMSProp | epoch: 026 | loss: 0.16364 - acc: 0.9413 -- iter: 0736/1443
[A[ATraining Step: 1174  | total loss: [1m[32m0.18385[0m[0m | time: 14.241s
[2K
| RMSProp | epoch: 026 | loss: 0.18385 - acc: 0.9347 -- iter: 0768/1443
[A[ATraining Step: 1175  | total loss: [1m[32m0.16642[0m[0m | time: 14.331s
[2K
| RMSProp | epoch: 026 | loss: 0.16642 - acc: 0.9412 -- iter: 0800/1443
[A[ATraining Step: 1176  | total loss: [1m[32m0.15036[0m[0m | time: 14.941s
[2K
| RMSProp | epoch: 026 | loss: 0.15036 - acc: 0.9471 -- iter: 0832/1443
[A[ATraining Step: 1177  | total loss: [1m[32m0.16035[0m[0m | time: 15.571s
[2K
| RMSProp | epoch: 026 | loss: 0.16035 - acc: 0.9367 -- iter: 0864/1443
[A[ATraining Step: 1178  | total loss: [1m[32m0.15659[0m[0m | time: 16.187s
[2K
| RMSProp | epoch: 026 | loss: 0.15659 - acc: 0.9368 -- iter: 0896/1443
[A[ATraining Step: 1179  | total loss: [1m[32m0.18036[0m[0m | time: 16.840s
[2K
| RMSProp | epoch: 026 | loss: 0.18036 - acc: 0.9369 -- iter: 0928/1443
[A[ATraining Step: 1180  | total loss: [1m[32m0.17972[0m[0m | time: 17.471s
[2K
| RMSProp | epoch: 026 | loss: 0.17972 - acc: 0.9370 -- iter: 0960/1443
[A[ATraining Step: 1181  | total loss: [1m[32m0.18333[0m[0m | time: 18.094s
[2K
| RMSProp | epoch: 026 | loss: 0.18333 - acc: 0.9339 -- iter: 0992/1443
[A[ATraining Step: 1182  | total loss: [1m[32m0.17133[0m[0m | time: 18.707s
[2K
| RMSProp | epoch: 026 | loss: 0.17133 - acc: 0.9405 -- iter: 1024/1443
[A[ATraining Step: 1183  | total loss: [1m[32m0.17148[0m[0m | time: 19.322s
[2K
| RMSProp | epoch: 026 | loss: 0.17148 - acc: 0.9402 -- iter: 1056/1443
[A[ATraining Step: 1184  | total loss: [1m[32m0.15888[0m[0m | time: 19.961s
[2K
| RMSProp | epoch: 026 | loss: 0.15888 - acc: 0.9430 -- iter: 1088/1443
[A[ATraining Step: 1185  | total loss: [1m[32m0.14641[0m[0m | time: 20.596s
[2K
| RMSProp | epoch: 026 | loss: 0.14641 - acc: 0.9487 -- iter: 1120/1443
[A[ATraining Step: 1186  | total loss: [1m[32m0.16959[0m[0m | time: 21.211s
[2K
| RMSProp | epoch: 026 | loss: 0.16959 - acc: 0.9445 -- iter: 1152/1443
[A[ATraining Step: 1187  | total loss: [1m[32m0.17595[0m[0m | time: 21.831s
[2K
| RMSProp | epoch: 026 | loss: 0.17595 - acc: 0.9438 -- iter: 1184/1443
[A[ATraining Step: 1188  | total loss: [1m[32m0.17010[0m[0m | time: 22.474s
[2K
| RMSProp | epoch: 026 | loss: 0.17010 - acc: 0.9463 -- iter: 1216/1443
[A[ATraining Step: 1189  | total loss: [1m[32m0.16364[0m[0m | time: 23.086s
[2K
| RMSProp | epoch: 026 | loss: 0.16364 - acc: 0.9485 -- iter: 1248/1443
[A[ATraining Step: 1190  | total loss: [1m[32m0.17097[0m[0m | time: 23.716s
[2K
| RMSProp | epoch: 026 | loss: 0.17097 - acc: 0.9443 -- iter: 1280/1443
[A[ATraining Step: 1191  | total loss: [1m[32m0.17019[0m[0m | time: 24.332s
[2K
| RMSProp | epoch: 026 | loss: 0.17019 - acc: 0.9436 -- iter: 1312/1443
[A[ATraining Step: 1192  | total loss: [1m[32m0.15737[0m[0m | time: 24.937s
[2K
| RMSProp | epoch: 026 | loss: 0.15737 - acc: 0.9493 -- iter: 1344/1443
[A[ATraining Step: 1193  | total loss: [1m[32m0.14924[0m[0m | time: 25.561s
[2K
| RMSProp | epoch: 026 | loss: 0.14924 - acc: 0.9512 -- iter: 1376/1443
[A[ATraining Step: 1194  | total loss: [1m[32m0.16803[0m[0m | time: 26.182s
[2K
| RMSProp | epoch: 026 | loss: 0.16803 - acc: 0.9405 -- iter: 1408/1443
[A[ATraining Step: 1195  | total loss: [1m[32m0.16847[0m[0m | time: 26.808s
[2K
| RMSProp | epoch: 026 | loss: 0.16847 - acc: 0.9402 -- iter: 1440/1443
[A[ATraining Step: 1196  | total loss: [1m[32m0.17192[0m[0m | time: 28.839s
[2K
| RMSProp | epoch: 026 | loss: 0.17192 - acc: 0.9368 | val_loss: 0.79967 - val_acc: 0.7633 -- iter: 1443/1443
--
Training Step: 1197  | total loss: [1m[32m0.17120[0m[0m | time: 0.627s
[2K
| RMSProp | epoch: 027 | loss: 0.17120 - acc: 0.9400 -- iter: 0032/1443
[A[ATraining Step: 1198  | total loss: [1m[32m0.17563[0m[0m | time: 1.259s
[2K
| RMSProp | epoch: 027 | loss: 0.17563 - acc: 0.9397 -- iter: 0064/1443
[A[ATraining Step: 1199  | total loss: [1m[32m0.18240[0m[0m | time: 1.886s
[2K
| RMSProp | epoch: 027 | loss: 0.18240 - acc: 0.9364 -- iter: 0096/1443
[A[ATraining Step: 1200  | total loss: [1m[32m0.16843[0m[0m | time: 3.946s
[2K
| RMSProp | epoch: 027 | loss: 0.16843 - acc: 0.9427 | val_loss: 0.85699 - val_acc: 0.7544 -- iter: 0128/1443
--
Training Step: 1201  | total loss: [1m[32m0.15305[0m[0m | time: 4.583s
[2K
| RMSProp | epoch: 027 | loss: 0.15305 - acc: 0.9485 -- iter: 0160/1443
[A[ATraining Step: 1202  | total loss: [1m[32m0.14764[0m[0m | time: 5.195s
[2K
| RMSProp | epoch: 027 | loss: 0.14764 - acc: 0.9505 -- iter: 0192/1443
[A[ATraining Step: 1203  | total loss: [1m[32m0.13547[0m[0m | time: 5.807s
[2K
| RMSProp | epoch: 027 | loss: 0.13547 - acc: 0.9554 -- iter: 0224/1443
[A[ATraining Step: 1204  | total loss: [1m[32m0.13552[0m[0m | time: 6.439s
[2K
| RMSProp | epoch: 027 | loss: 0.13552 - acc: 0.9568 -- iter: 0256/1443
[A[ATraining Step: 1205  | total loss: [1m[32m0.13225[0m[0m | time: 7.061s
[2K
| RMSProp | epoch: 027 | loss: 0.13225 - acc: 0.9580 -- iter: 0288/1443
[A[ATraining Step: 1206  | total loss: [1m[32m0.12474[0m[0m | time: 7.668s
[2K
| RMSProp | epoch: 027 | loss: 0.12474 - acc: 0.9591 -- iter: 0320/1443
[A[ATraining Step: 1207  | total loss: [1m[32m0.12152[0m[0m | time: 8.271s
[2K
| RMSProp | epoch: 027 | loss: 0.12152 - acc: 0.9600 -- iter: 0352/1443
[A[ATraining Step: 1208  | total loss: [1m[32m0.12873[0m[0m | time: 8.884s
[2K
| RMSProp | epoch: 027 | loss: 0.12873 - acc: 0.9546 -- iter: 0384/1443
[A[ATraining Step: 1209  | total loss: [1m[32m0.12189[0m[0m | time: 9.507s
[2K
| RMSProp | epoch: 027 | loss: 0.12189 - acc: 0.9561 -- iter: 0416/1443
[A[ATraining Step: 1210  | total loss: [1m[32m0.12084[0m[0m | time: 10.118s
[2K
| RMSProp | epoch: 027 | loss: 0.12084 - acc: 0.9573 -- iter: 0448/1443
[A[ATraining Step: 1211  | total loss: [1m[32m0.13045[0m[0m | time: 10.730s
[2K
| RMSProp | epoch: 027 | loss: 0.13045 - acc: 0.9553 -- iter: 0480/1443
[A[ATraining Step: 1212  | total loss: [1m[32m0.12761[0m[0m | time: 11.351s
[2K
| RMSProp | epoch: 027 | loss: 0.12761 - acc: 0.9567 -- iter: 0512/1443
[A[ATraining Step: 1213  | total loss: [1m[32m0.12093[0m[0m | time: 11.947s
[2K
| RMSProp | epoch: 027 | loss: 0.12093 - acc: 0.9610 -- iter: 0544/1443
[A[ATraining Step: 1214  | total loss: [1m[32m0.13693[0m[0m | time: 12.581s
[2K
| RMSProp | epoch: 027 | loss: 0.13693 - acc: 0.9587 -- iter: 0576/1443
[A[ATraining Step: 1215  | total loss: [1m[32m0.12751[0m[0m | time: 13.188s
[2K
| RMSProp | epoch: 027 | loss: 0.12751 - acc: 0.9628 -- iter: 0608/1443
[A[ATraining Step: 1216  | total loss: [1m[32m0.12401[0m[0m | time: 13.836s
[2K
| RMSProp | epoch: 027 | loss: 0.12401 - acc: 0.9634 -- iter: 0640/1443
[A[ATraining Step: 1217  | total loss: [1m[32m0.13169[0m[0m | time: 14.460s
[2K
| RMSProp | epoch: 027 | loss: 0.13169 - acc: 0.9577 -- iter: 0672/1443
[A[ATraining Step: 1218  | total loss: [1m[32m0.15214[0m[0m | time: 15.059s
[2K
| RMSProp | epoch: 027 | loss: 0.15214 - acc: 0.9494 -- iter: 0704/1443
[A[ATraining Step: 1219  | total loss: [1m[32m0.14841[0m[0m | time: 15.677s
[2K
| RMSProp | epoch: 027 | loss: 0.14841 - acc: 0.9482 -- iter: 0736/1443
[A[ATraining Step: 1220  | total loss: [1m[32m0.14347[0m[0m | time: 16.279s
[2K
| RMSProp | epoch: 027 | loss: 0.14347 - acc: 0.9471 -- iter: 0768/1443
[A[ATraining Step: 1221  | total loss: [1m[32m0.13951[0m[0m | time: 16.363s
[2K
| RMSProp | epoch: 027 | loss: 0.13951 - acc: 0.9493 -- iter: 0800/1443
[A[ATraining Step: 1222  | total loss: [1m[32m0.12719[0m[0m | time: 16.466s
[2K
| RMSProp | epoch: 027 | loss: 0.12719 - acc: 0.9544 -- iter: 0832/1443
[A[ATraining Step: 1223  | total loss: [1m[32m0.11481[0m[0m | time: 17.077s
[2K
| RMSProp | epoch: 027 | loss: 0.11481 - acc: 0.9589 -- iter: 0864/1443
[A[ATraining Step: 1224  | total loss: [1m[32m0.13131[0m[0m | time: 17.699s
[2K
| RMSProp | epoch: 027 | loss: 0.13131 - acc: 0.9537 -- iter: 0896/1443
[A[ATraining Step: 1225  | total loss: [1m[32m0.12857[0m[0m | time: 18.323s
[2K
| RMSProp | epoch: 027 | loss: 0.12857 - acc: 0.9552 -- iter: 0928/1443
[A[ATraining Step: 1226  | total loss: [1m[32m0.13423[0m[0m | time: 18.940s
[2K
| RMSProp | epoch: 027 | loss: 0.13423 - acc: 0.9534 -- iter: 0960/1443
[A[ATraining Step: 1227  | total loss: [1m[32m0.14177[0m[0m | time: 19.551s
[2K
| RMSProp | epoch: 027 | loss: 0.14177 - acc: 0.9518 -- iter: 0992/1443
[A[ATraining Step: 1228  | total loss: [1m[32m0.14694[0m[0m | time: 20.177s
[2K
| RMSProp | epoch: 027 | loss: 0.14694 - acc: 0.9504 -- iter: 1024/1443
[A[ATraining Step: 1229  | total loss: [1m[32m0.13908[0m[0m | time: 20.783s
[2K
| RMSProp | epoch: 027 | loss: 0.13908 - acc: 0.9522 -- iter: 1056/1443
[A[ATraining Step: 1230  | total loss: [1m[32m0.13932[0m[0m | time: 21.426s
[2K
| RMSProp | epoch: 027 | loss: 0.13932 - acc: 0.9539 -- iter: 1088/1443
[A[ATraining Step: 1231  | total loss: [1m[32m0.13963[0m[0m | time: 22.046s
[2K
| RMSProp | epoch: 027 | loss: 0.13963 - acc: 0.9522 -- iter: 1120/1443
[A[ATraining Step: 1232  | total loss: [1m[32m0.13895[0m[0m | time: 22.658s
[2K
| RMSProp | epoch: 027 | loss: 0.13895 - acc: 0.9476 -- iter: 1152/1443
[A[ATraining Step: 1233  | total loss: [1m[32m0.13121[0m[0m | time: 23.273s
[2K
| RMSProp | epoch: 027 | loss: 0.13121 - acc: 0.9498 -- iter: 1184/1443
[A[ATraining Step: 1234  | total loss: [1m[32m0.14248[0m[0m | time: 23.893s
[2K
| RMSProp | epoch: 027 | loss: 0.14248 - acc: 0.9454 -- iter: 1216/1443
[A[ATraining Step: 1235  | total loss: [1m[32m0.15185[0m[0m | time: 24.517s
[2K
| RMSProp | epoch: 027 | loss: 0.15185 - acc: 0.9384 -- iter: 1248/1443
[A[ATraining Step: 1236  | total loss: [1m[32m0.15541[0m[0m | time: 25.125s
[2K
| RMSProp | epoch: 027 | loss: 0.15541 - acc: 0.9351 -- iter: 1280/1443
[A[ATraining Step: 1237  | total loss: [1m[32m0.15428[0m[0m | time: 25.735s
[2K
| RMSProp | epoch: 027 | loss: 0.15428 - acc: 0.9385 -- iter: 1312/1443
[A[ATraining Step: 1238  | total loss: [1m[32m0.15699[0m[0m | time: 26.358s
[2K
| RMSProp | epoch: 027 | loss: 0.15699 - acc: 0.9384 -- iter: 1344/1443
[A[ATraining Step: 1239  | total loss: [1m[32m0.16307[0m[0m | time: 26.976s
[2K
| RMSProp | epoch: 027 | loss: 0.16307 - acc: 0.9352 -- iter: 1376/1443
[A[ATraining Step: 1240  | total loss: [1m[32m0.15715[0m[0m | time: 27.582s
[2K
| RMSProp | epoch: 027 | loss: 0.15715 - acc: 0.9354 -- iter: 1408/1443
[A[ATraining Step: 1241  | total loss: [1m[32m0.15183[0m[0m | time: 28.206s
[2K
| RMSProp | epoch: 027 | loss: 0.15183 - acc: 0.9356 -- iter: 1440/1443
[A[ATraining Step: 1242  | total loss: [1m[32m0.16223[0m[0m | time: 30.268s
[2K
| RMSProp | epoch: 027 | loss: 0.16223 - acc: 0.9296 | val_loss: 0.77538 - val_acc: 0.7389 -- iter: 1443/1443
--
Training Step: 1243  | total loss: [1m[32m0.15695[0m[0m | time: 0.618s
[2K
| RMSProp | epoch: 028 | loss: 0.15695 - acc: 0.9335 -- iter: 0032/1443
[A[ATraining Step: 1244  | total loss: [1m[32m0.14437[0m[0m | time: 1.232s
[2K
| RMSProp | epoch: 028 | loss: 0.14437 - acc: 0.9401 -- iter: 0064/1443
[A[ATraining Step: 1245  | total loss: [1m[32m0.15099[0m[0m | time: 1.862s
[2K
| RMSProp | epoch: 028 | loss: 0.15099 - acc: 0.9399 -- iter: 0096/1443
[A[ATraining Step: 1246  | total loss: [1m[32m0.14526[0m[0m | time: 2.495s
[2K
| RMSProp | epoch: 028 | loss: 0.14526 - acc: 0.9428 -- iter: 0128/1443
[A[ATraining Step: 1247  | total loss: [1m[32m0.14036[0m[0m | time: 3.111s
[2K
| RMSProp | epoch: 028 | loss: 0.14036 - acc: 0.9454 -- iter: 0160/1443
[A[ATraining Step: 1248  | total loss: [1m[32m0.13495[0m[0m | time: 3.730s
[2K
| RMSProp | epoch: 028 | loss: 0.13495 - acc: 0.9477 -- iter: 0192/1443
[A[ATraining Step: 1249  | total loss: [1m[32m0.13023[0m[0m | time: 4.346s
[2K
| RMSProp | epoch: 028 | loss: 0.13023 - acc: 0.9467 -- iter: 0224/1443
[A[ATraining Step: 1250  | total loss: [1m[32m0.15030[0m[0m | time: 4.959s
[2K
| RMSProp | epoch: 028 | loss: 0.15030 - acc: 0.9395 -- iter: 0256/1443
[A[ATraining Step: 1251  | total loss: [1m[32m0.14699[0m[0m | time: 5.591s
[2K
| RMSProp | epoch: 028 | loss: 0.14699 - acc: 0.9393 -- iter: 0288/1443
[A[ATraining Step: 1252  | total loss: [1m[32m0.13763[0m[0m | time: 6.205s
[2K
| RMSProp | epoch: 028 | loss: 0.13763 - acc: 0.9423 -- iter: 0320/1443
[A[ATraining Step: 1253  | total loss: [1m[32m0.14442[0m[0m | time: 6.817s
[2K
| RMSProp | epoch: 028 | loss: 0.14442 - acc: 0.9387 -- iter: 0352/1443
[A[ATraining Step: 1254  | total loss: [1m[32m0.14007[0m[0m | time: 7.443s
[2K
| RMSProp | epoch: 028 | loss: 0.14007 - acc: 0.9417 -- iter: 0384/1443
[A[ATraining Step: 1255  | total loss: [1m[32m0.14241[0m[0m | time: 8.061s
[2K
| RMSProp | epoch: 028 | loss: 0.14241 - acc: 0.9412 -- iter: 0416/1443
[A[ATraining Step: 1256  | total loss: [1m[32m0.13937[0m[0m | time: 8.696s
[2K
| RMSProp | epoch: 028 | loss: 0.13937 - acc: 0.9440 -- iter: 0448/1443
[A[ATraining Step: 1257  | total loss: [1m[32m0.12949[0m[0m | time: 9.324s
[2K
| RMSProp | epoch: 028 | loss: 0.12949 - acc: 0.9496 -- iter: 0480/1443
[A[ATraining Step: 1258  | total loss: [1m[32m0.15223[0m[0m | time: 9.939s
[2K
| RMSProp | epoch: 028 | loss: 0.15223 - acc: 0.9484 -- iter: 0512/1443
[A[ATraining Step: 1259  | total loss: [1m[32m0.14731[0m[0m | time: 10.558s
[2K
| RMSProp | epoch: 028 | loss: 0.14731 - acc: 0.9504 -- iter: 0544/1443
[A[ATraining Step: 1260  | total loss: [1m[32m0.13993[0m[0m | time: 11.174s
[2K
| RMSProp | epoch: 028 | loss: 0.13993 - acc: 0.9491 -- iter: 0576/1443
[A[ATraining Step: 1261  | total loss: [1m[32m0.13327[0m[0m | time: 11.805s
[2K
| RMSProp | epoch: 028 | loss: 0.13327 - acc: 0.9511 -- iter: 0608/1443
[A[ATraining Step: 1262  | total loss: [1m[32m0.12373[0m[0m | time: 12.446s
[2K
| RMSProp | epoch: 028 | loss: 0.12373 - acc: 0.9560 -- iter: 0640/1443
[A[ATraining Step: 1263  | total loss: [1m[32m0.13025[0m[0m | time: 13.088s
[2K
| RMSProp | epoch: 028 | loss: 0.13025 - acc: 0.9510 -- iter: 0672/1443
[A[ATraining Step: 1264  | total loss: [1m[32m0.12111[0m[0m | time: 13.721s
[2K
| RMSProp | epoch: 028 | loss: 0.12111 - acc: 0.9559 -- iter: 0704/1443
[A[ATraining Step: 1265  | total loss: [1m[32m0.11125[0m[0m | time: 14.334s
[2K
| RMSProp | epoch: 028 | loss: 0.11125 - acc: 0.9603 -- iter: 0736/1443
[A[ATraining Step: 1266  | total loss: [1m[32m0.13294[0m[0m | time: 14.945s
[2K
| RMSProp | epoch: 028 | loss: 0.13294 - acc: 0.9580 -- iter: 0768/1443
[A[ATraining Step: 1267  | total loss: [1m[32m0.15964[0m[0m | time: 15.557s
[2K
| RMSProp | epoch: 028 | loss: 0.15964 - acc: 0.9466 -- iter: 0800/1443
[A[ATraining Step: 1268  | total loss: [1m[32m0.16754[0m[0m | time: 15.644s
[2K
| RMSProp | epoch: 028 | loss: 0.16754 - acc: 0.9426 -- iter: 0832/1443
[A[ATraining Step: 1269  | total loss: [1m[32m0.15110[0m[0m | time: 15.734s
[2K
| RMSProp | epoch: 028 | loss: 0.15110 - acc: 0.9483 -- iter: 0864/1443
[A[ATraining Step: 1270  | total loss: [1m[32m0.13619[0m[0m | time: 16.367s
[2K
| RMSProp | epoch: 028 | loss: 0.13619 - acc: 0.9535 -- iter: 0896/1443
[A[ATraining Step: 1271  | total loss: [1m[32m0.12671[0m[0m | time: 17.004s
[2K
| RMSProp | epoch: 028 | loss: 0.12671 - acc: 0.9550 -- iter: 0928/1443
[A[ATraining Step: 1272  | total loss: [1m[32m0.12903[0m[0m | time: 17.640s
[2K
| RMSProp | epoch: 028 | loss: 0.12903 - acc: 0.9533 -- iter: 0960/1443
[A[ATraining Step: 1273  | total loss: [1m[32m0.14354[0m[0m | time: 18.254s
[2K
| RMSProp | epoch: 028 | loss: 0.14354 - acc: 0.9423 -- iter: 0992/1443
[A[ATraining Step: 1274  | total loss: [1m[32m0.13864[0m[0m | time: 18.869s
[2K
| RMSProp | epoch: 028 | loss: 0.13864 - acc: 0.9418 -- iter: 1024/1443
[A[ATraining Step: 1275  | total loss: [1m[32m0.13057[0m[0m | time: 19.498s
[2K
| RMSProp | epoch: 028 | loss: 0.13057 - acc: 0.9476 -- iter: 1056/1443
[A[ATraining Step: 1276  | total loss: [1m[32m0.15460[0m[0m | time: 20.110s
[2K
| RMSProp | epoch: 028 | loss: 0.15460 - acc: 0.9435 -- iter: 1088/1443
[A[ATraining Step: 1277  | total loss: [1m[32m0.16116[0m[0m | time: 20.723s
[2K
| RMSProp | epoch: 028 | loss: 0.16116 - acc: 0.9367 -- iter: 1120/1443
[A[ATraining Step: 1278  | total loss: [1m[32m0.15766[0m[0m | time: 21.336s
[2K
| RMSProp | epoch: 028 | loss: 0.15766 - acc: 0.9399 -- iter: 1152/1443
[A[ATraining Step: 1279  | total loss: [1m[32m0.14771[0m[0m | time: 21.931s
[2K
| RMSProp | epoch: 028 | loss: 0.14771 - acc: 0.9459 -- iter: 1184/1443
[A[ATraining Step: 1280  | total loss: [1m[32m0.14876[0m[0m | time: 22.545s
[2K
| RMSProp | epoch: 028 | loss: 0.14876 - acc: 0.9450 -- iter: 1216/1443
[A[ATraining Step: 1281  | total loss: [1m[32m0.16007[0m[0m | time: 23.154s
[2K
| RMSProp | epoch: 028 | loss: 0.16007 - acc: 0.9443 -- iter: 1248/1443
[A[ATraining Step: 1282  | total loss: [1m[32m0.15895[0m[0m | time: 23.780s
[2K
| RMSProp | epoch: 028 | loss: 0.15895 - acc: 0.9436 -- iter: 1280/1443
[A[ATraining Step: 1283  | total loss: [1m[32m0.14974[0m[0m | time: 24.389s
[2K
| RMSProp | epoch: 028 | loss: 0.14974 - acc: 0.9461 -- iter: 1312/1443
[A[ATraining Step: 1284  | total loss: [1m[32m0.15779[0m[0m | time: 25.002s
[2K
| RMSProp | epoch: 028 | loss: 0.15779 - acc: 0.9421 -- iter: 1344/1443
[A[ATraining Step: 1285  | total loss: [1m[32m0.14775[0m[0m | time: 25.610s
[2K
| RMSProp | epoch: 028 | loss: 0.14775 - acc: 0.9448 -- iter: 1376/1443
[A[ATraining Step: 1286  | total loss: [1m[32m0.14906[0m[0m | time: 26.242s
[2K
| RMSProp | epoch: 028 | loss: 0.14906 - acc: 0.9472 -- iter: 1408/1443
[A[ATraining Step: 1287  | total loss: [1m[32m0.14594[0m[0m | time: 26.865s
[2K
| RMSProp | epoch: 028 | loss: 0.14594 - acc: 0.9462 -- iter: 1440/1443
[A[ATraining Step: 1288  | total loss: [1m[32m0.14587[0m[0m | time: 28.936s
[2K
| RMSProp | epoch: 028 | loss: 0.14587 - acc: 0.9485 | val_loss: 0.85210 - val_acc: 0.7500 -- iter: 1443/1443
--
Training Step: 1289  | total loss: [1m[32m0.13481[0m[0m | time: 0.622s
[2K
| RMSProp | epoch: 029 | loss: 0.13481 - acc: 0.9536 -- iter: 0032/1443
[A[ATraining Step: 1290  | total loss: [1m[32m0.13156[0m[0m | time: 1.239s
[2K
| RMSProp | epoch: 029 | loss: 0.13156 - acc: 0.9551 -- iter: 0064/1443
[A[ATraining Step: 1291  | total loss: [1m[32m0.11910[0m[0m | time: 1.853s
[2K
| RMSProp | epoch: 029 | loss: 0.11910 - acc: 0.9596 -- iter: 0096/1443
[A[ATraining Step: 1292  | total loss: [1m[32m0.11948[0m[0m | time: 2.475s
[2K
| RMSProp | epoch: 029 | loss: 0.11948 - acc: 0.9605 -- iter: 0128/1443
[A[ATraining Step: 1293  | total loss: [1m[32m0.12968[0m[0m | time: 3.122s
[2K
| RMSProp | epoch: 029 | loss: 0.12968 - acc: 0.9582 -- iter: 0160/1443
[A[ATraining Step: 1294  | total loss: [1m[32m0.15836[0m[0m | time: 3.738s
[2K
| RMSProp | epoch: 029 | loss: 0.15836 - acc: 0.9468 -- iter: 0192/1443
[A[ATraining Step: 1295  | total loss: [1m[32m0.15863[0m[0m | time: 4.357s
[2K
| RMSProp | epoch: 029 | loss: 0.15863 - acc: 0.9490 -- iter: 0224/1443
[A[ATraining Step: 1296  | total loss: [1m[32m0.14851[0m[0m | time: 4.997s
[2K
| RMSProp | epoch: 029 | loss: 0.14851 - acc: 0.9541 -- iter: 0256/1443
[A[ATraining Step: 1297  | total loss: [1m[32m0.13573[0m[0m | time: 5.610s
[2K
| RMSProp | epoch: 029 | loss: 0.13573 - acc: 0.9587 -- iter: 0288/1443
[A[ATraining Step: 1298  | total loss: [1m[32m0.14226[0m[0m | time: 6.227s
[2K
| RMSProp | epoch: 029 | loss: 0.14226 - acc: 0.9566 -- iter: 0320/1443
[A[ATraining Step: 1299  | total loss: [1m[32m0.13877[0m[0m | time: 6.856s
[2K
| RMSProp | epoch: 029 | loss: 0.13877 - acc: 0.9578 -- iter: 0352/1443
[A[ATraining Step: 1300  | total loss: [1m[32m0.13795[0m[0m | time: 7.483s
[2K
| RMSProp | epoch: 029 | loss: 0.13795 - acc: 0.9557 -- iter: 0384/1443
[A[ATraining Step: 1301  | total loss: [1m[32m0.13078[0m[0m | time: 8.119s
[2K
| RMSProp | epoch: 029 | loss: 0.13078 - acc: 0.9570 -- iter: 0416/1443
[A[ATraining Step: 1302  | total loss: [1m[32m0.13193[0m[0m | time: 8.756s
[2K
| RMSProp | epoch: 029 | loss: 0.13193 - acc: 0.9551 -- iter: 0448/1443
[A[ATraining Step: 1303  | total loss: [1m[32m0.13697[0m[0m | time: 9.375s
[2K
| RMSProp | epoch: 029 | loss: 0.13697 - acc: 0.9533 -- iter: 0480/1443
[A[ATraining Step: 1304  | total loss: [1m[32m0.14451[0m[0m | time: 9.985s
[2K
| RMSProp | epoch: 029 | loss: 0.14451 - acc: 0.9549 -- iter: 0512/1443
[A[ATraining Step: 1305  | total loss: [1m[32m0.13556[0m[0m | time: 10.600s
[2K
| RMSProp | epoch: 029 | loss: 0.13556 - acc: 0.9563 -- iter: 0544/1443
[A[ATraining Step: 1306  | total loss: [1m[32m0.12679[0m[0m | time: 11.217s
[2K
| RMSProp | epoch: 029 | loss: 0.12679 - acc: 0.9606 -- iter: 0576/1443
[A[ATraining Step: 1307  | total loss: [1m[32m0.11768[0m[0m | time: 11.834s
[2K
| RMSProp | epoch: 029 | loss: 0.11768 - acc: 0.9646 -- iter: 0608/1443
[A[ATraining Step: 1308  | total loss: [1m[32m0.11154[0m[0m | time: 12.471s
[2K
| RMSProp | epoch: 029 | loss: 0.11154 - acc: 0.9650 -- iter: 0640/1443
[A[ATraining Step: 1309  | total loss: [1m[32m0.10866[0m[0m | time: 13.082s
[2K
| RMSProp | epoch: 029 | loss: 0.10866 - acc: 0.9654 -- iter: 0672/1443
[A[ATraining Step: 1310  | total loss: [1m[32m0.12317[0m[0m | time: 13.691s
[2K
| RMSProp | epoch: 029 | loss: 0.12317 - acc: 0.9626 -- iter: 0704/1443
[A[ATraining Step: 1311  | total loss: [1m[32m0.14169[0m[0m | time: 14.311s
[2K
| RMSProp | epoch: 029 | loss: 0.14169 - acc: 0.9538 -- iter: 0736/1443
[A[ATraining Step: 1312  | total loss: [1m[32m0.14620[0m[0m | time: 14.956s
[2K
| RMSProp | epoch: 029 | loss: 0.14620 - acc: 0.9522 -- iter: 0768/1443
[A[ATraining Step: 1313  | total loss: [1m[32m0.15230[0m[0m | time: 15.571s
[2K
| RMSProp | epoch: 029 | loss: 0.15230 - acc: 0.9507 -- iter: 0800/1443
[A[ATraining Step: 1314  | total loss: [1m[32m0.15825[0m[0m | time: 16.193s
[2K
| RMSProp | epoch: 029 | loss: 0.15825 - acc: 0.9463 -- iter: 0832/1443
[A[ATraining Step: 1315  | total loss: [1m[32m0.15912[0m[0m | time: 16.278s
[2K
| RMSProp | epoch: 029 | loss: 0.15912 - acc: 0.9423 -- iter: 0864/1443
[A[ATraining Step: 1316  | total loss: [1m[32m0.14694[0m[0m | time: 16.364s
[2K
| RMSProp | epoch: 029 | loss: 0.14694 - acc: 0.9480 -- iter: 0896/1443
[A[ATraining Step: 1317  | total loss: [1m[32m0.13242[0m[0m | time: 16.975s
[2K
| RMSProp | epoch: 029 | loss: 0.13242 - acc: 0.9532 -- iter: 0928/1443
[A[ATraining Step: 1318  | total loss: [1m[32m0.13318[0m[0m | time: 17.591s
[2K
| RMSProp | epoch: 029 | loss: 0.13318 - acc: 0.9517 -- iter: 0960/1443
[A[ATraining Step: 1319  | total loss: [1m[32m0.17485[0m[0m | time: 18.190s
[2K
| RMSProp | epoch: 029 | loss: 0.17485 - acc: 0.9409 -- iter: 0992/1443
[A[ATraining Step: 1320  | total loss: [1m[32m0.16789[0m[0m | time: 18.813s
[2K
| RMSProp | epoch: 029 | loss: 0.16789 - acc: 0.9437 -- iter: 1024/1443
[A[ATraining Step: 1321  | total loss: [1m[32m0.16834[0m[0m | time: 19.419s
[2K
| RMSProp | epoch: 029 | loss: 0.16834 - acc: 0.9399 -- iter: 1056/1443
[A[ATraining Step: 1322  | total loss: [1m[32m0.17837[0m[0m | time: 20.030s
[2K
| RMSProp | epoch: 029 | loss: 0.17837 - acc: 0.9366 -- iter: 1088/1443
[A[ATraining Step: 1323  | total loss: [1m[32m0.18116[0m[0m | time: 20.660s
[2K
| RMSProp | epoch: 029 | loss: 0.18116 - acc: 0.9335 -- iter: 1120/1443
[A[ATraining Step: 1324  | total loss: [1m[32m0.17405[0m[0m | time: 21.266s
[2K
| RMSProp | epoch: 029 | loss: 0.17405 - acc: 0.9339 -- iter: 1152/1443
[A[ATraining Step: 1325  | total loss: [1m[32m0.15900[0m[0m | time: 21.868s
[2K
| RMSProp | epoch: 029 | loss: 0.15900 - acc: 0.9405 -- iter: 1184/1443
[A[ATraining Step: 1326  | total loss: [1m[32m0.16245[0m[0m | time: 22.509s
[2K
| RMSProp | epoch: 029 | loss: 0.16245 - acc: 0.9402 -- iter: 1216/1443
[A[ATraining Step: 1327  | total loss: [1m[32m0.16965[0m[0m | time: 23.139s
[2K
| RMSProp | epoch: 029 | loss: 0.16965 - acc: 0.9368 -- iter: 1248/1443
[A[ATraining Step: 1328  | total loss: [1m[32m0.15427[0m[0m | time: 23.749s
[2K
| RMSProp | epoch: 029 | loss: 0.15427 - acc: 0.9431 -- iter: 1280/1443
[A[ATraining Step: 1329  | total loss: [1m[32m0.14400[0m[0m | time: 24.373s
[2K
| RMSProp | epoch: 029 | loss: 0.14400 - acc: 0.9488 -- iter: 1312/1443
[A[ATraining Step: 1330  | total loss: [1m[32m0.14831[0m[0m | time: 24.978s
[2K
| RMSProp | epoch: 029 | loss: 0.14831 - acc: 0.9508 -- iter: 1344/1443
[A[ATraining Step: 1331  | total loss: [1m[32m0.21271[0m[0m | time: 25.607s
[2K
| RMSProp | epoch: 029 | loss: 0.21271 - acc: 0.9401 -- iter: 1376/1443
[A[ATraining Step: 1332  | total loss: [1m[32m0.20244[0m[0m | time: 26.231s
[2K
| RMSProp | epoch: 029 | loss: 0.20244 - acc: 0.9430 -- iter: 1408/1443
[A[ATraining Step: 1333  | total loss: [1m[32m0.19530[0m[0m | time: 26.841s
[2K
| RMSProp | epoch: 029 | loss: 0.19530 - acc: 0.9456 -- iter: 1440/1443
[A[ATraining Step: 1334  | total loss: [1m[32m0.17935[0m[0m | time: 28.869s
[2K
| RMSProp | epoch: 029 | loss: 0.17935 - acc: 0.9510 | val_loss: 0.86584 - val_acc: 0.7367 -- iter: 1443/1443
--
Training Step: 1335  | total loss: [1m[32m0.16353[0m[0m | time: 0.608s
[2K
| RMSProp | epoch: 030 | loss: 0.16353 - acc: 0.9559 -- iter: 0032/1443
[A[ATraining Step: 1336  | total loss: [1m[32m0.14914[0m[0m | time: 1.243s
[2K
| RMSProp | epoch: 030 | loss: 0.14914 - acc: 0.9603 -- iter: 0064/1443
[A[ATraining Step: 1337  | total loss: [1m[32m0.13553[0m[0m | time: 1.844s
[2K
| RMSProp | epoch: 030 | loss: 0.13553 - acc: 0.9643 -- iter: 0096/1443
[A[ATraining Step: 1338  | total loss: [1m[32m0.12295[0m[0m | time: 2.466s
[2K
| RMSProp | epoch: 030 | loss: 0.12295 - acc: 0.9679 -- iter: 0128/1443
[A[ATraining Step: 1339  | total loss: [1m[32m0.13116[0m[0m | time: 3.081s
[2K
| RMSProp | epoch: 030 | loss: 0.13116 - acc: 0.9648 -- iter: 0160/1443
[A[ATraining Step: 1340  | total loss: [1m[32m0.15550[0m[0m | time: 3.693s
[2K
| RMSProp | epoch: 030 | loss: 0.15550 - acc: 0.9621 -- iter: 0192/1443
[A[ATraining Step: 1341  | total loss: [1m[32m0.14348[0m[0m | time: 4.308s
[2K
| RMSProp | epoch: 030 | loss: 0.14348 - acc: 0.9659 -- iter: 0224/1443
[A[ATraining Step: 1342  | total loss: [1m[32m0.13358[0m[0m | time: 4.911s
[2K
| RMSProp | epoch: 030 | loss: 0.13358 - acc: 0.9693 -- iter: 0256/1443
[A[ATraining Step: 1343  | total loss: [1m[32m0.12337[0m[0m | time: 5.514s
[2K
| RMSProp | epoch: 030 | loss: 0.12337 - acc: 0.9724 -- iter: 0288/1443
[A[ATraining Step: 1344  | total loss: [1m[32m0.11869[0m[0m | time: 6.150s
[2K
| RMSProp | epoch: 030 | loss: 0.11869 - acc: 0.9720 -- iter: 0320/1443
[A[ATraining Step: 1345  | total loss: [1m[32m0.11874[0m[0m | time: 6.762s
[2K
| RMSProp | epoch: 030 | loss: 0.11874 - acc: 0.9717 -- iter: 0352/1443
[A[ATraining Step: 1346  | total loss: [1m[32m0.11171[0m[0m | time: 7.374s
[2K
| RMSProp | epoch: 030 | loss: 0.11171 - acc: 0.9745 -- iter: 0384/1443
[A[ATraining Step: 1347  | total loss: [1m[32m0.11752[0m[0m | time: 7.995s
[2K
| RMSProp | epoch: 030 | loss: 0.11752 - acc: 0.9708 -- iter: 0416/1443
[A[ATraining Step: 1348  | total loss: [1m[32m0.12109[0m[0m | time: 8.595s
[2K
| RMSProp | epoch: 030 | loss: 0.12109 - acc: 0.9675 -- iter: 0448/1443
[A[ATraining Step: 1349  | total loss: [1m[32m0.13871[0m[0m | time: 9.199s
[2K
| RMSProp | epoch: 030 | loss: 0.13871 - acc: 0.9551 -- iter: 0480/1443
[A[ATraining Step: 1350  | total loss: [1m[32m0.13055[0m[0m | time: 9.800s
[2K
| RMSProp | epoch: 030 | loss: 0.13055 - acc: 0.9596 -- iter: 0512/1443
[A[ATraining Step: 1351  | total loss: [1m[32m0.12619[0m[0m | time: 10.405s
[2K
| RMSProp | epoch: 030 | loss: 0.12619 - acc: 0.9574 -- iter: 0544/1443
[A[ATraining Step: 1352  | total loss: [1m[32m0.13712[0m[0m | time: 11.019s
[2K
| RMSProp | epoch: 030 | loss: 0.13712 - acc: 0.9554 -- iter: 0576/1443
[A[ATraining Step: 1353  | total loss: [1m[32m0.12957[0m[0m | time: 11.622s
[2K
| RMSProp | epoch: 030 | loss: 0.12957 - acc: 0.9567 -- iter: 0608/1443
[A[ATraining Step: 1354  | total loss: [1m[32m0.15644[0m[0m | time: 12.235s
[2K
| RMSProp | epoch: 030 | loss: 0.15644 - acc: 0.9486 -- iter: 0640/1443
[A[ATraining Step: 1355  | total loss: [1m[32m0.16391[0m[0m | time: 12.850s
[2K
| RMSProp | epoch: 030 | loss: 0.16391 - acc: 0.9443 -- iter: 0672/1443
[A[ATraining Step: 1356  | total loss: [1m[32m0.15755[0m[0m | time: 13.457s
[2K
| RMSProp | epoch: 030 | loss: 0.15755 - acc: 0.9468 -- iter: 0704/1443
[A[ATraining Step: 1357  | total loss: [1m[32m0.16238[0m[0m | time: 14.075s
[2K
| RMSProp | epoch: 030 | loss: 0.16238 - acc: 0.9458 -- iter: 0736/1443
[A[ATraining Step: 1358  | total loss: [1m[32m0.17236[0m[0m | time: 14.685s
[2K
| RMSProp | epoch: 030 | loss: 0.17236 - acc: 0.9450 -- iter: 0768/1443
[A[ATraining Step: 1359  | total loss: [1m[32m0.17944[0m[0m | time: 15.289s
[2K
| RMSProp | epoch: 030 | loss: 0.17944 - acc: 0.9380 -- iter: 0800/1443
[A[ATraining Step: 1360  | total loss: [1m[32m0.16867[0m[0m | time: 15.908s
[2K
| RMSProp | epoch: 030 | loss: 0.16867 - acc: 0.9411 -- iter: 0832/1443
[A[ATraining Step: 1361  | total loss: [1m[32m0.16983[0m[0m | time: 16.537s
[2K
| RMSProp | epoch: 030 | loss: 0.16983 - acc: 0.9407 -- iter: 0864/1443
[A[ATraining Step: 1362  | total loss: [1m[32m0.17236[0m[0m | time: 16.626s
[2K
| RMSProp | epoch: 030 | loss: 0.17236 - acc: 0.9404 -- iter: 0896/1443
[A[ATraining Step: 1363  | total loss: [1m[32m0.17188[0m[0m | time: 16.713s
[2K
| RMSProp | epoch: 030 | loss: 0.17188 - acc: 0.9464 -- iter: 0928/1443
[A[ATraining Step: 1364  | total loss: [1m[32m0.15545[0m[0m | time: 17.318s
[2K
| RMSProp | epoch: 030 | loss: 0.15545 - acc: 0.9517 -- iter: 0960/1443
[A[ATraining Step: 1365  | total loss: [1m[32m0.14501[0m[0m | time: 17.935s
[2K
| RMSProp | epoch: 030 | loss: 0.14501 - acc: 0.9566 -- iter: 0992/1443
[A[ATraining Step: 1366  | total loss: [1m[32m0.13533[0m[0m | time: 18.566s
[2K
| RMSProp | epoch: 030 | loss: 0.13533 - acc: 0.9578 -- iter: 1024/1443
[A[ATraining Step: 1367  | total loss: [1m[32m0.13500[0m[0m | time: 19.173s
[2K
| RMSProp | epoch: 030 | loss: 0.13500 - acc: 0.9557 -- iter: 1056/1443
[A[ATraining Step: 1368  | total loss: [1m[32m0.13774[0m[0m | time: 19.781s
[2K
| RMSProp | epoch: 030 | loss: 0.13774 - acc: 0.9539 -- iter: 1088/1443
[A[ATraining Step: 1369  | total loss: [1m[32m0.12855[0m[0m | time: 20.398s
[2K
| RMSProp | epoch: 030 | loss: 0.12855 - acc: 0.9585 -- iter: 1120/1443
[A[ATraining Step: 1370  | total loss: [1m[32m0.14618[0m[0m | time: 21.022s
[2K
| RMSProp | epoch: 030 | loss: 0.14618 - acc: 0.9533 -- iter: 1152/1443
[A[ATraining Step: 1371  | total loss: [1m[32m0.14799[0m[0m | time: 21.656s
[2K
| RMSProp | epoch: 030 | loss: 0.14799 - acc: 0.9517 -- iter: 1184/1443
[A[ATraining Step: 1372  | total loss: [1m[32m0.16352[0m[0m | time: 22.272s
[2K
| RMSProp | epoch: 030 | loss: 0.16352 - acc: 0.9440 -- iter: 1216/1443
[A[ATraining Step: 1373  | total loss: [1m[32m0.15155[0m[0m | time: 22.884s
[2K
| RMSProp | epoch: 030 | loss: 0.15155 - acc: 0.9496 -- iter: 1248/1443
[A[ATraining Step: 1374  | total loss: [1m[32m0.14111[0m[0m | time: 23.515s
[2K
| RMSProp | epoch: 030 | loss: 0.14111 - acc: 0.9547 -- iter: 1280/1443
[A[ATraining Step: 1375  | total loss: [1m[32m0.13939[0m[0m | time: 24.134s
[2K
| RMSProp | epoch: 030 | loss: 0.13939 - acc: 0.9561 -- iter: 1312/1443
[A[ATraining Step: 1376  | total loss: [1m[32m0.12822[0m[0m | time: 24.731s
[2K
| RMSProp | epoch: 030 | loss: 0.12822 - acc: 0.9605 -- iter: 1344/1443
[A[ATraining Step: 1377  | total loss: [1m[32m0.13591[0m[0m | time: 25.343s
[2K
| RMSProp | epoch: 030 | loss: 0.13591 - acc: 0.9582 -- iter: 1376/1443
[A[ATraining Step: 1378  | total loss: [1m[32m0.13963[0m[0m | time: 25.974s
[2K
| RMSProp | epoch: 030 | loss: 0.13963 - acc: 0.9592 -- iter: 1408/1443
[A[ATraining Step: 1379  | total loss: [1m[32m0.12898[0m[0m | time: 26.584s
[2K
| RMSProp | epoch: 030 | loss: 0.12898 - acc: 0.9633 -- iter: 1440/1443
[A[ATraining Step: 1380  | total loss: [1m[32m0.11682[0m[0m | time: 28.658s
[2K
| RMSProp | epoch: 030 | loss: 0.11682 - acc: 0.9670 | val_loss: 0.98357 - val_acc: 0.7500 -- iter: 1443/1443
--
Validation AUC:0.799795751633987
Validation AUPRC:0.8232411819422771
Test AUC:0.857380571235993
Test AUPRC:0.909127070850795
BestTestF1Score	0.83	0.51	0.78	0.79	0.88	252	66	100	34	0.18
BestTestMCCScore	0.84	0.54	0.79	0.82	0.86	247	55	111	39	0.34
BestTestAccuracyScore	0.84	0.54	0.79	0.82	0.86	247	55	111	39	0.34
BestValidationF1Score	0.81	0.48	0.75	0.75	0.88	239	78	102	33	0.18
BestValidationMCC	0.81	0.49	0.76	0.77	0.86	233	70	110	39	0.34
BestValidationAccuracy	0.81	0.49	0.76	0.77	0.86	233	70	110	39	0.34
TestPredictions (Threshold:0.34)
CHEMBL3415805,FN,ACT,0.019999999552965164	CHEMBL1243058,TP,ACT,0.9900000095367432	CHEMBL3741822,TP,ACT,1.0	CHEMBL1830148,TP,ACT,0.9900000095367432	CHEMBL3770019,TP,ACT,0.9800000190734863	CHEMBL1213914,TP,ACT,1.0	CHEMBL3415809,TN,INACT,0.20999999344348907	CHEMBL1682815,TP,ACT,1.0	CHEMBL3799754,FP,INACT,0.7400000095367432	CHEMBL169926,FP,INACT,0.9800000190734863	CHEMBL1079383,TN,INACT,0.0	CHEMBL3655319,TN,INACT,0.0	CHEMBL903,FN,ACT,0.0	CHEMBL161896,FN,ACT,0.2800000011920929	CHEMBL3134343,FP,INACT,0.8999999761581421	CHEMBL3651097,TN,INACT,0.23000000417232513	CHEMBL2204759,TP,ACT,0.9900000095367432	CHEMBL1642685,TP,ACT,0.9399999976158142	CHEMBL1253357,TN,INACT,0.0	CHEMBL2206104,TP,ACT,1.0	CHEMBL3781494,TN,INACT,0.03999999910593033	CHEMBL1830143,TP,ACT,0.9900000095367432	CHEMBL2151546,TP,ACT,1.0	CHEMBL1830147,TP,ACT,0.9900000095367432	CHEMBL1642673,TP,ACT,0.8700000047683716	CHEMBL513995,TN,INACT,0.0	CHEMBL1243059,TP,ACT,0.9900000095367432	CHEMBL1258955,TN,INACT,0.18000000715255737	CHEMBL490922,TP,ACT,0.9900000095367432	CHEMBL2417753,TP,ACT,1.0	CHEMBL3394492,TN,INACT,0.0	CHEMBL473309,TN,INACT,0.0	CHEMBL1830808,TN,INACT,0.05000000074505806	CHEMBL1222281,FN,ACT,0.10000000149011612	CHEMBL512676,TN,INACT,0.0	CHEMBL489080,TN,INACT,0.3100000023841858	CHEMBL564763,FP,INACT,0.949999988079071	CHEMBL3310024,TP,ACT,1.0	CHEMBL2391742,TP,ACT,0.9900000095367432	CHEMBL2382424,FN,ACT,0.0	CHEMBL3735165,TP,ACT,1.0	CHEMBL1801962,TP,ACT,0.8100000023841858	CHEMBL3394527,TP,ACT,1.0	CHEMBL1761760,TP,ACT,0.8899999856948853	CHEMBL496280,TP,ACT,0.8600000143051147	CHEMBL887,TP,ACT,0.9800000190734863	CHEMBL341850,FP,INACT,1.0	CHEMBL1213916,TP,ACT,1.0	CHEMBL537623,TN,INACT,0.0	CHEMBL2151549,TP,ACT,1.0	CHEMBL3288298,TP,ACT,1.0	CHEMBL386941,TP,ACT,0.9900000095367432	CHEMBL526693,TN,INACT,0.0	CHEMBL602464,TP,ACT,0.9800000190734863	CHEMBL3330338,TN,INACT,0.0	CHEMBL3134374,FP,INACT,0.36000001430511475	CHEMBL536059,TN,INACT,0.0	CHEMBL3288301,TP,ACT,1.0	CHEMBL3394544,TP,ACT,0.9800000190734863	CHEMBL2334503,TN,INACT,0.019999999552965164	CHEMBL602880,TP,ACT,0.9800000190734863	CHEMBL387778,TP,ACT,0.8999999761581421	CHEMBL517725,TN,INACT,0.0	CHEMBL3651141,FP,INACT,0.9800000190734863	CHEMBL1255021,FP,INACT,1.0	CHEMBL145511,FP,INACT,0.949999988079071	CHEMBL375539,TP,ACT,0.9900000095367432	CHEMBL3651109,FN,ACT,0.2800000011920929	CHEMBL562142,TN,INACT,0.019999999552965164	CHEMBL3218127,TP,ACT,0.9599999785423279	CHEMBL256699,TN,INACT,0.009999999776482582	CHEMBL185425,TN,INACT,0.11999999731779099	CHEMBL600596,TP,ACT,1.0	CHEMBL1766613,FP,INACT,0.9100000262260437	CHEMBL331290,TP,ACT,0.5099999904632568	CHEMBL1256153,TN,INACT,0.07000000029802322	CHEMBL596339,TN,INACT,0.05000000074505806	CHEMBL1760715,TP,ACT,1.0	CHEMBL3417301,TP,ACT,0.9800000190734863	CHEMBL147515,FP,INACT,0.9900000095367432	CHEMBL3764334,FP,INACT,0.7400000095367432	CHEMBL2417754,TP,ACT,1.0	CHEMBL3797630,TP,ACT,0.9399999976158142	CHEMBL2252346,TN,INACT,0.0	CHEMBL488074,TP,ACT,0.9399999976158142	CHEMBL2418212,TP,ACT,1.0	CHEMBL2058704,TP,ACT,0.9900000095367432	CHEMBL2204761,TP,ACT,0.9900000095367432	CHEMBL342724,TP,ACT,0.75	CHEMBL1221980,TP,ACT,0.949999988079071	CHEMBL151,FP,INACT,1.0	CHEMBL1823808,TN,INACT,0.019999999552965164	CHEMBL3415820,TP,ACT,1.0	CHEMBL2312987,TP,ACT,0.7400000095367432	CHEMBL2313291,TP,ACT,1.0	CHEMBL399353,TP,ACT,0.9900000095367432	CHEMBL511966,FP,INACT,0.9300000071525574	CHEMBL596228,TN,INACT,0.0	CHEMBL2151688,TP,ACT,1.0	CHEMBL599761,TP,ACT,1.0	CHEMBL1946826,TP,ACT,0.9800000190734863	CHEMBL568385,TN,INACT,0.0	CHEMBL3415790,FP,INACT,0.9800000190734863	CHEMBL3121863,TP,ACT,0.9900000095367432	CHEMBL239491,TN,INACT,0.0	CHEMBL471221,TP,ACT,0.8899999856948853	CHEMBL3780391,TP,ACT,0.9399999976158142	CHEMBL1917495,TN,INACT,0.10999999940395355	CHEMBL287749,FP,INACT,0.8700000047683716	CHEMBL2332210,FN,ACT,0.019999999552965164	CHEMBL510214,FP,INACT,0.8700000047683716	CHEMBL3770224,TP,ACT,1.0	CHEMBL3651578,TN,INACT,0.33000001311302185	CHEMBL466770,TP,ACT,0.9900000095367432	CHEMBL3398527,TP,ACT,0.8500000238418579	CHEMBL69728,TN,INACT,0.009999999776482582	CHEMBL600392,TP,ACT,1.0	CHEMBL597769,TN,INACT,0.23000000417232513	CHEMBL461146,TN,INACT,0.0	CHEMBL3121793,TP,ACT,0.9900000095367432	CHEMBL2418205,TP,ACT,0.9599999785423279	CHEMBL2313277,TP,ACT,1.0	CHEMBL573985,TN,INACT,0.0	CHEMBL126505,FN,ACT,0.05999999865889549	CHEMBL2029533,TP,ACT,0.9900000095367432	CHEMBL1830830,TP,ACT,0.9599999785423279	CHEMBL3094020,FP,INACT,0.8199999928474426	CHEMBL3093171,TP,ACT,0.9900000095367432	CHEMBL1830810,TN,INACT,0.15000000596046448	CHEMBL3652424,TP,ACT,0.9900000095367432	CHEMBL1830828,TP,ACT,0.4699999988079071	CHEMBL491888,TP,ACT,1.0	CHEMBL3417305,TP,ACT,0.9599999785423279	CHEMBL3781033,TN,INACT,0.0	CHEMBL1179,TP,ACT,0.9700000286102295	CHEMBL3299111,TP,ACT,0.5199999809265137	CHEMBL3219619,TP,ACT,0.9800000190734863	CHEMBL1325943,TP,ACT,0.9700000286102295	CHEMBL460269,TP,ACT,0.9900000095367432	CHEMBL116983,TN,INACT,0.0	CHEMBL2151673,TP,ACT,0.9900000095367432	CHEMBL456005,FP,INACT,0.8500000238418579	CHEMBL3770498,TP,ACT,1.0	CHEMBL1643124,TP,ACT,0.9900000095367432	CHEMBL248050,TP,ACT,0.9900000095367432	CHEMBL460599,FP,INACT,0.9599999785423279	CHEMBL1796807,TN,INACT,0.05000000074505806	CHEMBL460734,TN,INACT,0.009999999776482582	CHEMBL470312,TN,INACT,0.0	CHEMBL3605356,TP,ACT,0.9900000095367432	CHEMBL2093957,TP,ACT,1.0	CHEMBL3291015,TN,INACT,0.019999999552965164	CHEMBL220677,FP,INACT,0.9700000286102295	CHEMBL2332185,TP,ACT,0.9599999785423279	CHEMBL543218,TN,INACT,0.0	CHEMBL1253847,TP,ACT,0.9900000095367432	CHEMBL2418208,TP,ACT,0.9599999785423279	CHEMBL2206089,TP,ACT,1.0	CHEMBL537406,TN,INACT,0.019999999552965164	CHEMBL255230,TN,INACT,0.0	CHEMBL3800008,TP,ACT,1.0	CHEMBL247833,TP,ACT,0.9900000095367432	CHEMBL3735572,TP,ACT,1.0	CHEMBL1830133,TP,ACT,0.9900000095367432	CHEMBL161907,TP,ACT,0.9200000166893005	CHEMBL194732,FP,INACT,0.3499999940395355	CHEMBL3134341,TN,INACT,0.0	CHEMBL244661,TP,ACT,0.9399999976158142	CHEMBL2332184,TP,ACT,0.9900000095367432	CHEMBL1682818,TP,ACT,1.0	CHEMBL1254935,TP,ACT,1.0	CHEMBL597761,TN,INACT,0.019999999552965164	CHEMBL3736303,FN,ACT,0.0	CHEMBL490923,TP,ACT,1.0	CHEMBL2151684,TP,ACT,1.0	CHEMBL1642671,TP,ACT,0.8299999833106995	CHEMBL390406,TN,INACT,0.28999999165534973	CHEMBL1945160,TP,ACT,0.9900000095367432	CHEMBL3134339,TN,INACT,0.0	CHEMBL2088311,TP,ACT,0.949999988079071	CHEMBL1814070,TP,ACT,0.9800000190734863	CHEMBL3629811,TN,INACT,0.0	CHEMBL3769637,TP,ACT,0.9599999785423279	CHEMBL3782038,TP,ACT,0.9800000190734863	CHEMBL3800320,FN,ACT,0.0	CHEMBL13311,TN,INACT,0.10999999940395355	CHEMBL3763837,TP,ACT,0.9900000095367432	CHEMBL3651147,TP,ACT,0.9900000095367432	CHEMBL596254,TP,ACT,0.949999988079071	CHEMBL3586611,TP,ACT,1.0	CHEMBL2430707,TP,ACT,1.0	CHEMBL2151682,TP,ACT,1.0	CHEMBL187178,FP,INACT,0.36000001430511475	CHEMBL151369,TN,INACT,0.009999999776482582	CHEMBL151368,TN,INACT,0.0	CHEMBL1213911,TP,ACT,0.9900000095367432	CHEMBL158946,TN,INACT,0.0	CHEMBL513209,TP,ACT,0.9700000286102295	CHEMBL3585814,TN,INACT,0.05000000074505806	CHEMBL3132866,TN,INACT,0.09000000357627869	CHEMBL2088312,FP,INACT,0.949999988079071	CHEMBL509345,TP,ACT,1.0	CHEMBL598151,TP,ACT,1.0	CHEMBL3093238,TP,ACT,1.0	CHEMBL469783,FN,ACT,0.009999999776482582	CHEMBL2206096,TP,ACT,1.0	CHEMBL2376890,FN,ACT,0.0	CHEMBL3651591,TP,ACT,1.0	CHEMBL3775613,TN,INACT,0.0	CHEMBL489084,TN,INACT,0.05000000074505806	CHEMBL3288293,TP,ACT,1.0	CHEMBL3093214,FN,ACT,0.0	CHEMBL2440559,TN,INACT,0.009999999776482582	CHEMBL491469,TN,INACT,0.0	CHEMBL596768,TN,INACT,0.05000000074505806	CHEMBL597988,TN,INACT,0.33000001311302185	CHEMBL3586583,TP,ACT,0.9900000095367432	CHEMBL1945156,TP,ACT,0.9900000095367432	CHEMBL2206093,TP,ACT,1.0	CHEMBL3769905,TP,ACT,0.9800000190734863	CHEMBL356977,TP,ACT,1.0	CHEMBL550488,TP,ACT,0.9900000095367432	CHEMBL3740394,FP,INACT,0.7900000214576721	CHEMBL3121786,TP,ACT,0.9900000095367432	CHEMBL3093175,TP,ACT,0.9900000095367432	CHEMBL3319245,TP,ACT,0.9900000095367432	CHEMBL1253334,FP,INACT,0.36000001430511475	CHEMBL168600,FP,INACT,0.9599999785423279	CHEMBL3415818,TP,ACT,1.0	CHEMBL16648,FP,INACT,0.9800000190734863	CHEMBL538733,TN,INACT,0.0	CHEMBL495714,TP,ACT,1.0	CHEMBL2088302,TP,ACT,0.9700000286102295	CHEMBL1928855,FN,ACT,0.009999999776482582	CHEMBL570731,TP,ACT,0.9800000190734863	CHEMBL3297786,FP,INACT,0.4099999964237213	CHEMBL488072,FP,INACT,0.3700000047683716	CHEMBL2058421,FP,INACT,0.3499999940395355	CHEMBL487071,FP,INACT,0.5699999928474426	CHEMBL3330330,FN,ACT,0.019999999552965164	CHEMBL2177464,TN,INACT,0.009999999776482582	CHEMBL2204772,TP,ACT,0.9900000095367432	CHEMBL1243214,TP,ACT,0.9800000190734863	CHEMBL420523,FN,ACT,0.07000000029802322	CHEMBL2029538,TP,ACT,0.9900000095367432	CHEMBL48556,TN,INACT,0.019999999552965164	CHEMBL2334497,TN,INACT,0.0	CHEMBL597963,TN,INACT,0.029999999329447746	CHEMBL2391869,TP,ACT,1.0	CHEMBL439811,TP,ACT,1.0	CHEMBL3417306,TP,ACT,0.9900000095367432	CHEMBL2418207,TP,ACT,0.9800000190734863	CHEMBL1243152,TP,ACT,1.0	CHEMBL3787118,TN,INACT,0.0	CHEMBL3769915,FN,ACT,0.23000000417232513	CHEMBL1760719,TP,ACT,0.8999999761581421	CHEMBL3769644,TP,ACT,1.0	CHEMBL1917526,TN,INACT,0.0	CHEMBL1783714,TP,ACT,1.0	CHEMBL454378,TN,INACT,0.0	CHEMBL454159,TN,INACT,0.0	CHEMBL3288294,TP,ACT,1.0	CHEMBL1814065,TP,ACT,0.949999988079071	CHEMBL111264,FP,INACT,0.949999988079071	CHEMBL3655331,TN,INACT,0.0	CHEMBL1254551,FP,INACT,1.0	CHEMBL3218128,TP,ACT,0.9900000095367432	CHEMBL508175,TN,INACT,0.0	CHEMBL489720,TP,ACT,1.0	CHEMBL2417750,TP,ACT,0.9900000095367432	CHEMBL3629471,FP,INACT,0.9599999785423279	CHEMBL1830816,TP,ACT,0.7300000190734863	CHEMBL1339821,TP,ACT,1.0	CHEMBL257057,TN,INACT,0.0	CHEMBL2426045,FN,ACT,0.009999999776482582	CHEMBL340590,TP,ACT,0.9599999785423279	CHEMBL1594810,TN,INACT,0.0	CHEMBL241618,TP,ACT,0.9700000286102295	CHEMBL3394542,TP,ACT,0.9800000190734863	CHEMBL3613269,TP,ACT,0.9200000166893005	CHEMBL200640,TN,INACT,0.0	CHEMBL3394506,TN,INACT,0.0	CHEMBL1253763,TP,ACT,1.0	CHEMBL3288295,TP,ACT,1.0	CHEMBL3319247,TP,ACT,1.0	CHEMBL557213,TN,INACT,0.25	CHEMBL3319255,TP,ACT,1.0	CHEMBL279361,FP,INACT,0.8899999856948853	CHEMBL187247,TN,INACT,0.029999999329447746	CHEMBL513549,TP,ACT,0.949999988079071	CHEMBL3629468,FN,ACT,0.009999999776482582	CHEMBL512703,FN,ACT,0.03999999910593033	CHEMBL3780374,FP,INACT,0.9599999785423279	CHEMBL127880,TN,INACT,0.0	CHEMBL2206103,TP,ACT,1.0	CHEMBL382886,TN,INACT,0.0	CHEMBL392622,FP,INACT,0.8100000023841858	CHEMBL3360733,TP,ACT,1.0	CHEMBL3652411,TP,ACT,1.0	CHEMBL3319250,TP,ACT,1.0	CHEMBL2332183,TP,ACT,0.7599999904632568	CHEMBL2333926,TP,ACT,0.9599999785423279	CHEMBL3800292,FN,ACT,0.05000000074505806	CHEMBL56918,TP,ACT,0.9800000190734863	CHEMBL1814069,TP,ACT,0.9700000286102295	CHEMBL3394526,TP,ACT,1.0	CHEMBL2204763,TP,ACT,0.949999988079071	CHEMBL364917,TN,INACT,0.15000000596046448	CHEMBL1777849,TN,INACT,0.009999999776482582	CHEMBL82327,TN,INACT,0.029999999329447746	CHEMBL1934039,TP,ACT,0.7599999904632568	CHEMBL3401326,TN,INACT,0.0	CHEMBL390050,FP,INACT,0.6800000071525574	CHEMBL1830825,TP,ACT,0.9900000095367432	CHEMBL3134340,FP,INACT,0.9900000095367432	CHEMBL3133306,TN,INACT,0.07000000029802322	CHEMBL2204756,TP,ACT,1.0	CHEMBL2238457,FP,INACT,0.6600000262260437	CHEMBL3330334,FN,ACT,0.0	CHEMBL142799,TP,ACT,0.9900000095367432	CHEMBL1984764,TP,ACT,0.9900000095367432	CHEMBL598394,FN,ACT,0.009999999776482582	CHEMBL542265,TN,INACT,0.029999999329447746	CHEMBL513578,TN,INACT,0.0	CHEMBL3652426,TP,ACT,0.9900000095367432	CHEMBL1927667,TP,ACT,0.7599999904632568	CHEMBL2440540,TN,INACT,0.009999999776482582	CHEMBL1830129,TP,ACT,1.0	CHEMBL3108958,TN,INACT,0.019999999552965164	CHEMBL1830832,FP,INACT,0.9900000095367432	CHEMBL673,FN,ACT,0.019999999552965164	CHEMBL3770747,TP,ACT,1.0	CHEMBL3219621,TP,ACT,0.3499999940395355	CHEMBL483450,TP,ACT,0.9900000095367432	CHEMBL2158251,TP,ACT,0.9800000190734863	CHEMBL3319273,TP,ACT,1.0	CHEMBL3764211,TN,INACT,0.0	CHEMBL3605357,TP,ACT,0.9900000095367432	CHEMBL2151676,TP,ACT,1.0	CHEMBL2391870,TP,ACT,0.9900000095367432	CHEMBL2376885,FN,ACT,0.0	CHEMBL1643122,TP,ACT,0.9700000286102295	CHEMBL2158244,TP,ACT,1.0	CHEMBL1241294,TP,ACT,1.0	CHEMBL3651599,FN,ACT,0.0	CHEMBL3319243,TP,ACT,0.9700000286102295	CHEMBL1927679,TP,ACT,0.9900000095367432	CHEMBL3651587,TP,ACT,0.9100000262260437	CHEMBL544166,FP,INACT,0.5099999904632568	CHEMBL3401325,TN,INACT,0.2199999988079071	CHEMBL1926848,TN,INACT,0.009999999776482582	CHEMBL2151550,TP,ACT,0.8500000238418579	CHEMBL121,FN,ACT,0.10999999940395355	CHEMBL1830799,FP,INACT,0.6399999856948853	CHEMBL1814057,FN,ACT,0.009999999776482582	CHEMBL2236844,TP,ACT,1.0	CHEMBL1934042,TP,ACT,0.9900000095367432	CHEMBL2029549,TP,ACT,1.0	CHEMBL2023193,FN,ACT,0.0	CHEMBL3093167,TP,ACT,1.0	CHEMBL3770377,TP,ACT,1.0	CHEMBL3319257,TP,ACT,1.0	CHEMBL598187,FP,INACT,0.8100000023841858	CHEMBL2430706,TP,ACT,1.0	CHEMBL2332177,TP,ACT,0.9900000095367432	CHEMBL338035,FN,ACT,0.0	CHEMBL1461072,TP,ACT,1.0	CHEMBL266769,TN,INACT,0.25999999046325684	CHEMBL469024,FP,INACT,0.9900000095367432	CHEMBL1760720,TP,ACT,0.9700000286102295	CHEMBL1929419,TN,INACT,0.0	CHEMBL1254625,TP,ACT,1.0	CHEMBL1806761,TP,ACT,0.9800000190734863	CHEMBL338404,TP,ACT,0.8799999952316284	CHEMBL2376888,FN,ACT,0.0	CHEMBL1830819,TN,INACT,0.009999999776482582	CHEMBL500683,TP,ACT,0.3400000035762787	CHEMBL3310029,FN,ACT,0.019999999552965164	CHEMBL2440542,TN,INACT,0.009999999776482582	CHEMBL69099,TN,INACT,0.0	CHEMBL3769793,FN,ACT,0.009999999776482582	CHEMBL462229,TN,INACT,0.0	CHEMBL3741989,TP,ACT,1.0	CHEMBL1945155,TP,ACT,1.0	CHEMBL3093333,TP,ACT,0.9900000095367432	CHEMBL3330340,FN,ACT,0.10000000149011612	CHEMBL553599,FP,INACT,0.5699999928474426	CHEMBL3417293,TP,ACT,0.5899999737739563	CHEMBL2396878,FP,INACT,0.9700000286102295	CHEMBL1801958,TP,ACT,1.0	CHEMBL1830137,TN,INACT,0.009999999776482582	CHEMBL512719,TP,ACT,0.9900000095367432	CHEMBL3310026,TP,ACT,0.3400000035762787	CHEMBL3319246,TP,ACT,1.0	CHEMBL3218161,TP,ACT,1.0	CHEMBL3651116,TN,INACT,0.15000000596046448	CHEMBL1950710,FN,ACT,0.05000000074505806	CHEMBL1982267,FP,INACT,0.9900000095367432	CHEMBL3651148,TP,ACT,0.9100000262260437	CHEMBL1802004,TP,ACT,0.9900000095367432	CHEMBL1198953,TP,ACT,1.0	CHEMBL1213778,TP,ACT,1.0	CHEMBL2332171,TP,ACT,0.9900000095367432	CHEMBL1813518,TP,ACT,1.0	CHEMBL3219202,TP,ACT,0.9300000071525574	CHEMBL601205,TP,ACT,1.0	CHEMBL55934,FN,ACT,0.0	CHEMBL17643,TN,INACT,0.0	CHEMBL3735913,TP,ACT,0.9900000095367432	CHEMBL3764447,TP,ACT,1.0	CHEMBL3613276,TP,ACT,0.46000000834465027	CHEMBL3134332,FP,INACT,0.9399999976158142	CHEMBL1766556,TP,ACT,0.9800000190734863	CHEMBL2382426,FN,ACT,0.18000000715255737	CHEMBL3806317,FN,ACT,0.25999999046325684	CHEMBL2062882,TP,ACT,0.9599999785423279	CHEMBL469768,TP,ACT,0.9399999976158142	CHEMBL2417766,FP,INACT,0.9900000095367432	CHEMBL2204770,TP,ACT,1.0	CHEMBL597764,FP,INACT,0.9700000286102295	CHEMBL2088305,TP,ACT,0.9700000286102295	CHEMBL189117,FP,INACT,0.49000000953674316	CHEMBL46602,TN,INACT,0.009999999776482582	CHEMBL2204762,TP,ACT,1.0	CHEMBL453410,TP,ACT,0.9700000286102295	CHEMBL3133241,TN,INACT,0.0	CHEMBL585360,TN,INACT,0.0	CHEMBL3297785,FP,INACT,0.949999988079071	CHEMBL2204769,TP,ACT,1.0	CHEMBL2252344,TN,INACT,0.0	CHEMBL435101,TN,INACT,0.009999999776482582	CHEMBL3742390,TP,ACT,1.0	CHEMBL147524,TN,INACT,0.15000000596046448	CHEMBL333180,TP,ACT,0.9399999976158142	CHEMBL1987137,TP,ACT,0.9800000190734863	CHEMBL3651151,TP,ACT,0.9700000286102295	CHEMBL452001,TP,ACT,0.9900000095367432	CHEMBL111309,TP,ACT,1.0	CHEMBL186416,TN,INACT,0.029999999329447746	CHEMBL1766549,TP,ACT,0.7799999713897705	CHEMBL3586614,TP,ACT,1.0	CHEMBL491470,TN,INACT,0.0	CHEMBL2313279,TP,ACT,1.0	CHEMBL2440536,TN,INACT,0.0	CHEMBL3651140,TP,ACT,1.0	CHEMBL3093218,TP,ACT,0.9700000286102295	CHEMBL3220513,TP,ACT,0.7799999713897705	CHEMBL3605369,TP,ACT,0.9800000190734863	CHEMBL2058426,FN,ACT,0.07000000029802322	CHEMBL325761,TP,ACT,1.0	CHEMBL3770028,FP,INACT,0.9399999976158142	CHEMBL2420794,TP,ACT,1.0	

