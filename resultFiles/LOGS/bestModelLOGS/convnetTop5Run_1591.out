ImageNetInceptionV2 CHEMBL3025 adam 0.001 30 0 0 0.8 False True
Number of active compounds :	209
Number of inactive compounds :	209
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3025_adam_0.001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3025_adam_0.001_30_0.8/
---------------------------------
Training samples: 262
Validation samples: 82
--
Training Step: 1  | time: 212.657s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/262
[A[ATraining Step: 2  | total loss: [1m[32m0.65608[0m[0m | time: 230.091s
[2K
| Adam | epoch: 001 | loss: 0.65608 - acc: 0.5062 -- iter: 064/262
[A[ATraining Step: 3  | total loss: [1m[32m0.73961[0m[0m | time: 287.673s
[2K
| Adam | epoch: 001 | loss: 0.73961 - acc: 0.5267 -- iter: 096/262
[A[ATraining Step: 4  | total loss: [1m[32m0.98710[0m[0m | time: 308.496s
[2K
| Adam | epoch: 001 | loss: 0.98710 - acc: 0.5770 -- iter: 128/262
[A[ATraining Step: 5  | total loss: [1m[32m0.86777[0m[0m | time: 359.419s
[2K
| Adam | epoch: 001 | loss: 0.86777 - acc: 0.5021 -- iter: 160/262
[A[ATraining Step: 6  | total loss: [1m[32m0.80005[0m[0m | time: 374.677s
[2K
| Adam | epoch: 001 | loss: 0.80005 - acc: 0.5409 -- iter: 192/262
[A[ATraining Step: 7  | total loss: [1m[32m0.78330[0m[0m | time: 396.894s
[2K
| Adam | epoch: 001 | loss: 0.78330 - acc: 0.5351 -- iter: 224/262
[A[ATraining Step: 8  | total loss: [1m[32m0.69424[0m[0m | time: 414.881s
[2K
| Adam | epoch: 001 | loss: 0.69424 - acc: 0.6033 -- iter: 256/262
[A[ATraining Step: 9  | total loss: [1m[32m0.63490[0m[0m | time: 435.318s
[2K
| Adam | epoch: 001 | loss: 0.63490 - acc: 0.6809 | val_loss: 0.73126 - val_acc: 0.5244 -- iter: 262/262
--
Training Step: 10  | total loss: [1m[32m0.56500[0m[0m | time: 3.515s
[2K
| Adam | epoch: 002 | loss: 0.56500 - acc: 0.7571 -- iter: 032/262
[A[ATraining Step: 11  | total loss: [1m[32m0.42755[0m[0m | time: 24.214s
[2K
| Adam | epoch: 002 | loss: 0.42755 - acc: 0.8722 -- iter: 064/262
[A[ATraining Step: 12  | total loss: [1m[32m0.60051[0m[0m | time: 53.705s
[2K
| Adam | epoch: 002 | loss: 0.60051 - acc: 0.7328 -- iter: 096/262
[A[ATraining Step: 13  | total loss: [1m[32m0.65281[0m[0m | time: 95.242s
[2K
| Adam | epoch: 002 | loss: 0.65281 - acc: 0.7000 -- iter: 128/262
[A[ATraining Step: 14  | total loss: [1m[32m0.74501[0m[0m | time: 117.817s
[2K
| Adam | epoch: 002 | loss: 0.74501 - acc: 0.5798 -- iter: 160/262
[A[ATraining Step: 15  | total loss: [1m[32m0.79065[0m[0m | time: 131.721s
[2K
| Adam | epoch: 002 | loss: 0.79065 - acc: 0.5608 -- iter: 192/262
[A[ATraining Step: 16  | total loss: [1m[32m0.88605[0m[0m | time: 157.897s
[2K
| Adam | epoch: 002 | loss: 0.88605 - acc: 0.5380 -- iter: 224/262
[A[ATraining Step: 17  | total loss: [1m[32m0.75461[0m[0m | time: 179.122s
[2K
| Adam | epoch: 002 | loss: 0.75461 - acc: 0.6031 -- iter: 256/262
[A[ATraining Step: 18  | total loss: [1m[32m0.70520[0m[0m | time: 199.336s
[2K
| Adam | epoch: 002 | loss: 0.70520 - acc: 0.6215 | val_loss: 1.96010 - val_acc: 0.4756 -- iter: 262/262
--
Training Step: 19  | total loss: [1m[32m0.66721[0m[0m | time: 2.596s
[2K
| Adam | epoch: 003 | loss: 0.66721 - acc: 0.6227 -- iter: 032/262
[A[ATraining Step: 20  | total loss: [1m[32m0.63184[0m[0m | time: 6.290s
[2K
| Adam | epoch: 003 | loss: 0.63184 - acc: 0.6368 -- iter: 064/262
[A[ATraining Step: 21  | total loss: [1m[32m0.54844[0m[0m | time: 26.880s
[2K
| Adam | epoch: 003 | loss: 0.54844 - acc: 0.6978 -- iter: 096/262
[A[ATraining Step: 22  | total loss: [1m[32m0.53632[0m[0m | time: 43.759s
[2K
| Adam | epoch: 003 | loss: 0.53632 - acc: 0.7135 -- iter: 128/262
[A[ATraining Step: 23  | total loss: [1m[32m0.53732[0m[0m | time: 63.240s
[2K
| Adam | epoch: 003 | loss: 0.53732 - acc: 0.7241 -- iter: 160/262
[A[ATraining Step: 24  | total loss: [1m[32m0.53608[0m[0m | time: 77.337s
[2K
| Adam | epoch: 003 | loss: 0.53608 - acc: 0.7138 -- iter: 192/262
[A[ATraining Step: 25  | total loss: [1m[32m0.57686[0m[0m | time: 92.833s
[2K
| Adam | epoch: 003 | loss: 0.57686 - acc: 0.6640 -- iter: 224/262
[A[ATraining Step: 26  | total loss: [1m[32m0.56820[0m[0m | time: 108.100s
[2K
| Adam | epoch: 003 | loss: 0.56820 - acc: 0.6702 -- iter: 256/262
[A[ATraining Step: 27  | total loss: [1m[32m0.59717[0m[0m | time: 129.296s
[2K
| Adam | epoch: 003 | loss: 0.59717 - acc: 0.6425 | val_loss: 1.17550 - val_acc: 0.4756 -- iter: 262/262
--
Training Step: 28  | total loss: [1m[32m0.57780[0m[0m | time: 17.195s
[2K
| Adam | epoch: 004 | loss: 0.57780 - acc: 0.6616 -- iter: 032/262
[A[ATraining Step: 29  | total loss: [1m[32m0.57649[0m[0m | time: 20.693s
[2K
| Adam | epoch: 004 | loss: 0.57649 - acc: 0.6755 -- iter: 064/262
[A[ATraining Step: 30  | total loss: [1m[32m0.56956[0m[0m | time: 24.462s
[2K
| Adam | epoch: 004 | loss: 0.56956 - acc: 0.6734 -- iter: 096/262
[A[ATraining Step: 31  | total loss: [1m[32m0.48607[0m[0m | time: 120.987s
[2K
| Adam | epoch: 004 | loss: 0.48607 - acc: 0.7488 -- iter: 128/262
[A[ATraining Step: 32  | total loss: [1m[32m0.48149[0m[0m | time: 193.559s
[2K
| Adam | epoch: 004 | loss: 0.48149 - acc: 0.7561 -- iter: 160/262
[A[ATraining Step: 33  | total loss: [1m[32m0.57756[0m[0m | time: 209.385s
[2K
| Adam | epoch: 004 | loss: 0.57756 - acc: 0.7136 -- iter: 192/262
[A[ATraining Step: 34  | total loss: [1m[32m0.62777[0m[0m | time: 224.272s
[2K
| Adam | epoch: 004 | loss: 0.62777 - acc: 0.6946 -- iter: 224/262
[A[ATraining Step: 35  | total loss: [1m[32m0.65871[0m[0m | time: 237.179s
[2K
| Adam | epoch: 004 | loss: 0.65871 - acc: 0.6800 -- iter: 256/262
[A[ATraining Step: 36  | total loss: [1m[32m0.67087[0m[0m | time: 262.443s
[2K
| Adam | epoch: 004 | loss: 0.67087 - acc: 0.6688 | val_loss: 0.71670 - val_acc: 0.5122 -- iter: 262/262
--
Training Step: 37  | total loss: [1m[32m0.65837[0m[0m | time: 12.885s
[2K
| Adam | epoch: 005 | loss: 0.65837 - acc: 0.6725 -- iter: 032/262
[A[ATraining Step: 38  | total loss: [1m[32m0.59773[0m[0m | time: 25.956s
[2K
| Adam | epoch: 005 | loss: 0.59773 - acc: 0.7060 -- iter: 064/262
[A[ATraining Step: 39  | total loss: [1m[32m0.55172[0m[0m | time: 29.602s
[2K
| Adam | epoch: 005 | loss: 0.55172 - acc: 0.7384 -- iter: 096/262
[A[ATraining Step: 40  | total loss: [1m[32m0.53232[0m[0m | time: 33.476s
[2K
| Adam | epoch: 005 | loss: 0.53232 - acc: 0.7249 -- iter: 128/262
[A[ATraining Step: 41  | total loss: [1m[32m0.47587[0m[0m | time: 52.811s
[2K
| Adam | epoch: 005 | loss: 0.47587 - acc: 0.7755 -- iter: 160/262
[A[ATraining Step: 42  | total loss: [1m[32m0.48534[0m[0m | time: 68.343s
[2K
| Adam | epoch: 005 | loss: 0.48534 - acc: 0.7596 -- iter: 192/262
[A[ATraining Step: 43  | total loss: [1m[32m0.47286[0m[0m | time: 86.103s
[2K
| Adam | epoch: 005 | loss: 0.47286 - acc: 0.7745 -- iter: 224/262
[A[ATraining Step: 44  | total loss: [1m[32m0.46723[0m[0m | time: 99.336s
[2K
| Adam | epoch: 005 | loss: 0.46723 - acc: 0.7865 -- iter: 256/262
[A[ATraining Step: 45  | total loss: [1m[32m0.45351[0m[0m | time: 119.983s
[2K
| Adam | epoch: 005 | loss: 0.45351 - acc: 0.7962 | val_loss: 1.04155 - val_acc: 0.5244 -- iter: 262/262
--
Training Step: 46  | total loss: [1m[32m0.44072[0m[0m | time: 8.683s
[2K
| Adam | epoch: 006 | loss: 0.44072 - acc: 0.8145 -- iter: 032/262
[A[ATraining Step: 47  | total loss: [1m[32m0.45629[0m[0m | time: 19.879s
[2K
| Adam | epoch: 006 | loss: 0.45629 - acc: 0.8040 -- iter: 064/262
[A[ATraining Step: 48  | total loss: [1m[32m0.48334[0m[0m | time: 32.772s
[2K
| Adam | epoch: 006 | loss: 0.48334 - acc: 0.7853 -- iter: 096/262
[A[ATraining Step: 49  | total loss: [1m[32m0.43241[0m[0m | time: 36.482s
[2K
| Adam | epoch: 006 | loss: 0.43241 - acc: 0.8093 -- iter: 128/262
[A[ATraining Step: 50  | total loss: [1m[32m0.37314[0m[0m | time: 39.563s
[2K
| Adam | epoch: 006 | loss: 0.37314 - acc: 0.8389 -- iter: 160/262
[A[ATraining Step: 51  | total loss: [1m[32m0.32113[0m[0m | time: 51.384s
[2K
| Adam | epoch: 006 | loss: 0.32113 - acc: 0.8635 -- iter: 192/262
[A[ATraining Step: 52  | total loss: [1m[32m0.34977[0m[0m | time: 141.364s
[2K
| Adam | epoch: 006 | loss: 0.34977 - acc: 0.8324 -- iter: 224/262
[A[ATraining Step: 53  | total loss: [1m[32m0.38523[0m[0m | time: 228.897s
[2K
| Adam | epoch: 006 | loss: 0.38523 - acc: 0.8248 -- iter: 256/262
[A[ATraining Step: 54  | total loss: [1m[32m0.36997[0m[0m | time: 266.520s
[2K
| Adam | epoch: 006 | loss: 0.36997 - acc: 0.8321 | val_loss: 0.80509 - val_acc: 0.5244 -- iter: 262/262
--
Training Step: 55  | total loss: [1m[32m0.38064[0m[0m | time: 12.520s
[2K
| Adam | epoch: 007 | loss: 0.38064 - acc: 0.8204 -- iter: 032/262
[A[ATraining Step: 56  | total loss: [1m[32m0.40403[0m[0m | time: 25.410s
[2K
| Adam | epoch: 007 | loss: 0.40403 - acc: 0.8149 -- iter: 064/262
[A[ATraining Step: 57  | total loss: [1m[32m0.42764[0m[0m | time: 38.201s
[2K
| Adam | epoch: 007 | loss: 0.42764 - acc: 0.8059 -- iter: 096/262
[A[ATraining Step: 58  | total loss: [1m[32m0.40662[0m[0m | time: 50.941s
[2K
| Adam | epoch: 007 | loss: 0.40662 - acc: 0.8196 -- iter: 128/262
[A[ATraining Step: 59  | total loss: [1m[32m0.38611[0m[0m | time: 53.918s
[2K
| Adam | epoch: 007 | loss: 0.38611 - acc: 0.8228 -- iter: 160/262
[A[ATraining Step: 60  | total loss: [1m[32m0.34435[0m[0m | time: 57.536s
[2K
| Adam | epoch: 007 | loss: 0.34435 - acc: 0.8463 -- iter: 192/262
[A[ATraining Step: 61  | total loss: [1m[32m0.30603[0m[0m | time: 70.719s
[2K
| Adam | epoch: 007 | loss: 0.30603 - acc: 0.8663 -- iter: 224/262
[A[ATraining Step: 62  | total loss: [1m[32m0.33708[0m[0m | time: 83.790s
[2K
| Adam | epoch: 007 | loss: 0.33708 - acc: 0.8514 -- iter: 256/262
[A[ATraining Step: 63  | total loss: [1m[32m0.35343[0m[0m | time: 103.146s
[2K
| Adam | epoch: 007 | loss: 0.35343 - acc: 0.8425 | val_loss: 3.81199 - val_acc: 0.5488 -- iter: 262/262
--
Training Step: 64  | total loss: [1m[32m0.34902[0m[0m | time: 24.819s
[2K
| Adam | epoch: 008 | loss: 0.34902 - acc: 0.8387 -- iter: 032/262
[A[ATraining Step: 65  | total loss: [1m[32m0.33703[0m[0m | time: 52.068s
[2K
| Adam | epoch: 008 | loss: 0.33703 - acc: 0.8548 -- iter: 064/262
[A[ATraining Step: 66  | total loss: [1m[32m0.33104[0m[0m | time: 70.558s
[2K
| Adam | epoch: 008 | loss: 0.33104 - acc: 0.8610 -- iter: 096/262
[A[ATraining Step: 67  | total loss: [1m[32m0.34992[0m[0m | time: 82.776s
[2K
| Adam | epoch: 008 | loss: 0.34992 - acc: 0.8477 -- iter: 128/262
[A[ATraining Step: 68  | total loss: [1m[32m0.32815[0m[0m | time: 95.268s
[2K
| Adam | epoch: 008 | loss: 0.32815 - acc: 0.8620 -- iter: 160/262
[A[ATraining Step: 69  | total loss: [1m[32m0.32264[0m[0m | time: 98.744s
[2K
| Adam | epoch: 008 | loss: 0.32264 - acc: 0.8636 -- iter: 192/262
[A[ATraining Step: 70  | total loss: [1m[32m0.30505[0m[0m | time: 101.808s
[2K
| Adam | epoch: 008 | loss: 0.30505 - acc: 0.8601 -- iter: 224/262
[A[ATraining Step: 71  | total loss: [1m[32m0.27269[0m[0m | time: 114.691s
[2K
| Adam | epoch: 008 | loss: 0.27269 - acc: 0.8760 -- iter: 256/262
[A[ATraining Step: 72  | total loss: [1m[32m0.30235[0m[0m | time: 133.605s
[2K
| Adam | epoch: 008 | loss: 0.30235 - acc: 0.8689 | val_loss: 1.00135 - val_acc: 0.5732 -- iter: 262/262
--
Training Step: 73  | total loss: [1m[32m0.33281[0m[0m | time: 12.470s
[2K
| Adam | epoch: 009 | loss: 0.33281 - acc: 0.8557 -- iter: 032/262
[A[ATraining Step: 74  | total loss: [1m[32m0.32972[0m[0m | time: 25.363s
[2K
| Adam | epoch: 009 | loss: 0.32972 - acc: 0.8578 -- iter: 064/262
[A[ATraining Step: 75  | total loss: [1m[32m0.36242[0m[0m | time: 38.595s
[2K
| Adam | epoch: 009 | loss: 0.36242 - acc: 0.8393 -- iter: 096/262
[A[ATraining Step: 76  | total loss: [1m[32m0.35792[0m[0m | time: 51.227s
[2K
| Adam | epoch: 009 | loss: 0.35792 - acc: 0.8431 -- iter: 128/262
[A[ATraining Step: 77  | total loss: [1m[32m0.34569[0m[0m | time: 64.252s
[2K
| Adam | epoch: 009 | loss: 0.34569 - acc: 0.8531 -- iter: 160/262
[A[ATraining Step: 78  | total loss: [1m[32m0.32251[0m[0m | time: 76.869s
[2K
| Adam | epoch: 009 | loss: 0.32251 - acc: 0.8620 -- iter: 192/262
[A[ATraining Step: 79  | total loss: [1m[32m0.34458[0m[0m | time: 80.568s
[2K
| Adam | epoch: 009 | loss: 0.34458 - acc: 0.8504 -- iter: 224/262
[A[ATraining Step: 80  | total loss: [1m[32m0.32249[0m[0m | time: 83.958s
[2K
| Adam | epoch: 009 | loss: 0.32249 - acc: 0.8657 -- iter: 256/262
[A[ATraining Step: 81  | total loss: [1m[32m0.29618[0m[0m | time: 102.832s
[2K
| Adam | epoch: 009 | loss: 0.29618 - acc: 0.8793 | val_loss: 5.42964 - val_acc: 0.5244 -- iter: 262/262
--
Training Step: 82  | total loss: [1m[32m0.28395[0m[0m | time: 12.710s
[2K
| Adam | epoch: 010 | loss: 0.28395 - acc: 0.8820 -- iter: 032/262
[A[ATraining Step: 83  | total loss: [1m[32m0.27174[0m[0m | time: 25.445s
[2K
| Adam | epoch: 010 | loss: 0.27174 - acc: 0.8875 -- iter: 064/262
[A[ATraining Step: 84  | total loss: [1m[32m0.29561[0m[0m | time: 38.064s
[2K
| Adam | epoch: 010 | loss: 0.29561 - acc: 0.8706 -- iter: 096/262
[A[ATraining Step: 85  | total loss: [1m[32m0.29764[0m[0m | time: 51.110s
[2K
| Adam | epoch: 010 | loss: 0.29764 - acc: 0.8679 -- iter: 128/262
[A[ATraining Step: 86  | total loss: [1m[32m0.28380[0m[0m | time: 64.022s
[2K
| Adam | epoch: 010 | loss: 0.28380 - acc: 0.8749 -- iter: 160/262
[A[ATraining Step: 87  | total loss: [1m[32m0.27816[0m[0m | time: 76.666s
[2K
| Adam | epoch: 010 | loss: 0.27816 - acc: 0.8780 -- iter: 192/262
[A[ATraining Step: 88  | total loss: [1m[32m0.29440[0m[0m | time: 89.540s
[2K
| Adam | epoch: 010 | loss: 0.29440 - acc: 0.8746 -- iter: 224/262
[A[ATraining Step: 89  | total loss: [1m[32m0.28006[0m[0m | time: 92.867s
[2K
| Adam | epoch: 010 | loss: 0.28006 - acc: 0.8809 -- iter: 256/262
[A[ATraining Step: 90  | total loss: [1m[32m0.26350[0m[0m | time: 102.640s
[2K
| Adam | epoch: 010 | loss: 0.26350 - acc: 0.8928 | val_loss: 2.53788 - val_acc: 0.5122 -- iter: 262/262
--
Training Step: 91  | total loss: [1m[32m0.23989[0m[0m | time: 12.866s
[2K
| Adam | epoch: 011 | loss: 0.23989 - acc: 0.9035 -- iter: 032/262
[A[ATraining Step: 92  | total loss: [1m[32m0.22947[0m[0m | time: 25.679s
[2K
| Adam | epoch: 011 | loss: 0.22947 - acc: 0.9069 -- iter: 064/262
[A[ATraining Step: 93  | total loss: [1m[32m0.23762[0m[0m | time: 39.450s
[2K
| Adam | epoch: 011 | loss: 0.23762 - acc: 0.9006 -- iter: 096/262
[A[ATraining Step: 94  | total loss: [1m[32m0.27198[0m[0m | time: 53.399s
[2K
| Adam | epoch: 011 | loss: 0.27198 - acc: 0.8855 -- iter: 128/262
[A[ATraining Step: 95  | total loss: [1m[32m0.26487[0m[0m | time: 67.417s
[2K
| Adam | epoch: 011 | loss: 0.26487 - acc: 0.8939 -- iter: 160/262
[A[ATraining Step: 96  | total loss: [1m[32m0.25681[0m[0m | time: 77.861s
[2K
| Adam | epoch: 011 | loss: 0.25681 - acc: 0.8982 -- iter: 192/262
[A[ATraining Step: 97  | total loss: [1m[32m0.25887[0m[0m | time: 86.658s
[2K
| Adam | epoch: 011 | loss: 0.25887 - acc: 0.8990 -- iter: 224/262
[A[ATraining Step: 98  | total loss: [1m[32m0.26612[0m[0m | time: 95.094s
[2K
| Adam | epoch: 011 | loss: 0.26612 - acc: 0.8935 -- iter: 256/262
[A[ATraining Step: 99  | total loss: [1m[32m0.25629[0m[0m | time: 105.035s
[2K
| Adam | epoch: 011 | loss: 0.25629 - acc: 0.8917 | val_loss: 1.43547 - val_acc: 0.5000 -- iter: 262/262
--
Training Step: 100  | total loss: [1m[32m0.28480[0m[0m | time: 3.316s
[2K
| Adam | epoch: 012 | loss: 0.28480 - acc: 0.8692 -- iter: 032/262
[A[ATraining Step: 101  | total loss: [1m[32m0.29475[0m[0m | time: 15.572s
[2K
| Adam | epoch: 012 | loss: 0.29475 - acc: 0.8489 -- iter: 064/262
[A[ATraining Step: 102  | total loss: [1m[32m0.28057[0m[0m | time: 28.745s
[2K
| Adam | epoch: 012 | loss: 0.28057 - acc: 0.8609 -- iter: 096/262
[A[ATraining Step: 103  | total loss: [1m[32m0.27451[0m[0m | time: 41.448s
[2K
| Adam | epoch: 012 | loss: 0.27451 - acc: 0.8654 -- iter: 128/262
[A[ATraining Step: 104  | total loss: [1m[32m0.26364[0m[0m | time: 54.704s
[2K
| Adam | epoch: 012 | loss: 0.26364 - acc: 0.8726 -- iter: 160/262
[A[ATraining Step: 105  | total loss: [1m[32m0.25249[0m[0m | time: 67.986s
[2K
| Adam | epoch: 012 | loss: 0.25249 - acc: 0.8791 -- iter: 192/262
[A[ATraining Step: 106  | total loss: [1m[32m0.23618[0m[0m | time: 80.721s
[2K
| Adam | epoch: 012 | loss: 0.23618 - acc: 0.8881 -- iter: 224/262
[A[ATraining Step: 107  | total loss: [1m[32m0.23329[0m[0m | time: 93.638s
[2K
| Adam | epoch: 012 | loss: 0.23329 - acc: 0.8868 -- iter: 256/262
[A[ATraining Step: 108  | total loss: [1m[32m0.23449[0m[0m | time: 112.735s
[2K
| Adam | epoch: 012 | loss: 0.23449 - acc: 0.8887 | val_loss: 1.16513 - val_acc: 0.5976 -- iter: 262/262
--
Training Step: 109  | total loss: [1m[32m0.21650[0m[0m | time: 3.863s
[2K
| Adam | epoch: 013 | loss: 0.21650 - acc: 0.8999 -- iter: 032/262
[A[ATraining Step: 110  | total loss: [1m[32m0.21221[0m[0m | time: 7.413s
[2K
| Adam | epoch: 013 | loss: 0.21221 - acc: 0.9099 -- iter: 064/262
[A[ATraining Step: 111  | total loss: [1m[32m0.19789[0m[0m | time: 20.576s
[2K
| Adam | epoch: 013 | loss: 0.19789 - acc: 0.9189 -- iter: 096/262
[A[ATraining Step: 112  | total loss: [1m[32m0.19020[0m[0m | time: 33.730s
[2K
| Adam | epoch: 013 | loss: 0.19020 - acc: 0.9207 -- iter: 128/262
[A[ATraining Step: 113  | total loss: [1m[32m0.19230[0m[0m | time: 46.682s
[2K
| Adam | epoch: 013 | loss: 0.19230 - acc: 0.9193 -- iter: 160/262
[A[ATraining Step: 114  | total loss: [1m[32m0.19469[0m[0m | time: 59.263s
[2K
| Adam | epoch: 013 | loss: 0.19469 - acc: 0.9211 -- iter: 192/262
[A[ATraining Step: 115  | total loss: [1m[32m0.19132[0m[0m | time: 71.958s
[2K
| Adam | epoch: 013 | loss: 0.19132 - acc: 0.9228 -- iter: 224/262
[A[ATraining Step: 116  | total loss: [1m[32m0.23252[0m[0m | time: 84.515s
[2K
| Adam | epoch: 013 | loss: 0.23252 - acc: 0.9149 -- iter: 256/262
[A[ATraining Step: 117  | total loss: [1m[32m0.26564[0m[0m | time: 103.347s
[2K
| Adam | epoch: 013 | loss: 0.26564 - acc: 0.9077 | val_loss: 4.38529 - val_acc: 0.5976 -- iter: 262/262
--
Training Step: 118  | total loss: [1m[32m0.28763[0m[0m | time: 12.652s
[2K
| Adam | epoch: 014 | loss: 0.28763 - acc: 0.9045 -- iter: 032/262
[A[ATraining Step: 119  | total loss: [1m[32m0.27323[0m[0m | time: 16.063s
[2K
| Adam | epoch: 014 | loss: 0.27323 - acc: 0.9078 -- iter: 064/262
[A[ATraining Step: 120  | total loss: [1m[32m0.25959[0m[0m | time: 19.716s
[2K
| Adam | epoch: 014 | loss: 0.25959 - acc: 0.9170 -- iter: 096/262
[A[ATraining Step: 121  | total loss: [1m[32m0.23712[0m[0m | time: 32.967s
[2K
| Adam | epoch: 014 | loss: 0.23712 - acc: 0.9253 -- iter: 128/262
[A[ATraining Step: 122  | total loss: [1m[32m0.22952[0m[0m | time: 45.715s
[2K
| Adam | epoch: 014 | loss: 0.22952 - acc: 0.9265 -- iter: 160/262
[A[ATraining Step: 123  | total loss: [1m[32m0.25376[0m[0m | time: 58.901s
[2K
| Adam | epoch: 014 | loss: 0.25376 - acc: 0.9151 -- iter: 192/262
[A[ATraining Step: 124  | total loss: [1m[32m0.24827[0m[0m | time: 71.775s
[2K
| Adam | epoch: 014 | loss: 0.24827 - acc: 0.9111 -- iter: 224/262
[A[ATraining Step: 125  | total loss: [1m[32m0.26035[0m[0m | time: 84.356s
[2K
| Adam | epoch: 014 | loss: 0.26035 - acc: 0.9137 -- iter: 256/262
[A[ATraining Step: 126  | total loss: [1m[32m0.25941[0m[0m | time: 103.908s
[2K
| Adam | epoch: 014 | loss: 0.25941 - acc: 0.9130 | val_loss: 2.40809 - val_acc: 0.5854 -- iter: 262/262
--
Training Step: 127  | total loss: [1m[32m0.25873[0m[0m | time: 13.386s
[2K
| Adam | epoch: 015 | loss: 0.25873 - acc: 0.9123 -- iter: 032/262
[A[ATraining Step: 128  | total loss: [1m[32m0.26847[0m[0m | time: 26.784s
[2K
| Adam | epoch: 015 | loss: 0.26847 - acc: 0.9055 -- iter: 064/262
[A[ATraining Step: 129  | total loss: [1m[32m0.26202[0m[0m | time: 30.505s
[2K
| Adam | epoch: 015 | loss: 0.26202 - acc: 0.9055 -- iter: 096/262
[A[ATraining Step: 130  | total loss: [1m[32m0.27268[0m[0m | time: 34.024s
[2K
| Adam | epoch: 015 | loss: 0.27268 - acc: 0.8983 -- iter: 128/262
[A[ATraining Step: 131  | total loss: [1m[32m0.26299[0m[0m | time: 46.569s
[2K
| Adam | epoch: 015 | loss: 0.26299 - acc: 0.9085 -- iter: 160/262
[A[ATraining Step: 132  | total loss: [1m[32m0.24485[0m[0m | time: 59.573s
[2K
| Adam | epoch: 015 | loss: 0.24485 - acc: 0.9176 -- iter: 192/262
[A[ATraining Step: 133  | total loss: [1m[32m0.24991[0m[0m | time: 72.282s
[2K
| Adam | epoch: 015 | loss: 0.24991 - acc: 0.9102 -- iter: 224/262
[A[ATraining Step: 134  | total loss: [1m[32m0.24419[0m[0m | time: 85.388s
[2K
| Adam | epoch: 015 | loss: 0.24419 - acc: 0.9036 -- iter: 256/262
[A[ATraining Step: 135  | total loss: [1m[32m0.23282[0m[0m | time: 104.690s
[2K
| Adam | epoch: 015 | loss: 0.23282 - acc: 0.9101 | val_loss: 1.94628 - val_acc: 0.5976 -- iter: 262/262
--
Training Step: 136  | total loss: [1m[32m0.22914[0m[0m | time: 12.952s
[2K
| Adam | epoch: 016 | loss: 0.22914 - acc: 0.9129 -- iter: 032/262
[A[ATraining Step: 137  | total loss: [1m[32m0.21925[0m[0m | time: 25.722s
[2K
| Adam | epoch: 016 | loss: 0.21925 - acc: 0.9153 -- iter: 064/262
[A[ATraining Step: 138  | total loss: [1m[32m0.21886[0m[0m | time: 38.802s
[2K
| Adam | epoch: 016 | loss: 0.21886 - acc: 0.9175 -- iter: 096/262
[A[ATraining Step: 139  | total loss: [1m[32m0.20097[0m[0m | time: 42.561s
[2K
| Adam | epoch: 016 | loss: 0.20097 - acc: 0.9258 -- iter: 128/262
[A[ATraining Step: 140  | total loss: [1m[32m0.18387[0m[0m | time: 46.213s
[2K
| Adam | epoch: 016 | loss: 0.18387 - acc: 0.9332 -- iter: 160/262
[A[ATraining Step: 141  | total loss: [1m[32m0.16765[0m[0m | time: 59.324s
[2K
| Adam | epoch: 016 | loss: 0.16765 - acc: 0.9399 -- iter: 192/262
[A[ATraining Step: 142  | total loss: [1m[32m0.15819[0m[0m | time: 72.379s
[2K
| Adam | epoch: 016 | loss: 0.15819 - acc: 0.9428 -- iter: 224/262
[A[ATraining Step: 143  | total loss: [1m[32m0.15932[0m[0m | time: 85.109s
[2K
| Adam | epoch: 016 | loss: 0.15932 - acc: 0.9422 -- iter: 256/262
[A[ATraining Step: 144  | total loss: [1m[32m0.15041[0m[0m | time: 103.892s
[2K
| Adam | epoch: 016 | loss: 0.15041 - acc: 0.9449 | val_loss: 0.99018 - val_acc: 0.6829 -- iter: 262/262
--
Training Step: 145  | total loss: [1m[32m0.15337[0m[0m | time: 8.591s
[2K
| Adam | epoch: 017 | loss: 0.15337 - acc: 0.9473 -- iter: 032/262
[A[ATraining Step: 146  | total loss: [1m[32m0.15730[0m[0m | time: 17.004s
[2K
| Adam | epoch: 017 | loss: 0.15730 - acc: 0.9463 -- iter: 064/262
[A[ATraining Step: 147  | total loss: [1m[32m0.14908[0m[0m | time: 25.395s
[2K
| Adam | epoch: 017 | loss: 0.14908 - acc: 0.9485 -- iter: 096/262
[A[ATraining Step: 148  | total loss: [1m[32m0.17258[0m[0m | time: 37.392s
[2K
| Adam | epoch: 017 | loss: 0.17258 - acc: 0.9474 -- iter: 128/262
[A[ATraining Step: 149  | total loss: [1m[32m0.16069[0m[0m | time: 40.702s
[2K
| Adam | epoch: 017 | loss: 0.16069 - acc: 0.9496 -- iter: 160/262
[A[ATraining Step: 150  | total loss: [1m[32m0.14664[0m[0m | time: 43.675s
[2K
| Adam | epoch: 017 | loss: 0.14664 - acc: 0.9546 -- iter: 192/262
[A[ATraining Step: 151  | total loss: [1m[32m0.13380[0m[0m | time: 56.824s
[2K
| Adam | epoch: 017 | loss: 0.13380 - acc: 0.9592 -- iter: 224/262
[A[ATraining Step: 152  | total loss: [1m[32m0.12996[0m[0m | time: 69.557s
[2K
| Adam | epoch: 017 | loss: 0.12996 - acc: 0.9601 -- iter: 256/262
[A[ATraining Step: 153  | total loss: [1m[32m0.13713[0m[0m | time: 88.403s
[2K
| Adam | epoch: 017 | loss: 0.13713 - acc: 0.9516 | val_loss: 1.63163 - val_acc: 0.6098 -- iter: 262/262
--
Training Step: 154  | total loss: [1m[32m0.13150[0m[0m | time: 13.102s
[2K
| Adam | epoch: 018 | loss: 0.13150 - acc: 0.9533 -- iter: 032/262
[A[ATraining Step: 155  | total loss: [1m[32m0.14141[0m[0m | time: 26.296s
[2K
| Adam | epoch: 018 | loss: 0.14141 - acc: 0.9486 -- iter: 064/262
[A[ATraining Step: 156  | total loss: [1m[32m0.14388[0m[0m | time: 38.877s
[2K
| Adam | epoch: 018 | loss: 0.14388 - acc: 0.9475 -- iter: 096/262
[A[ATraining Step: 157  | total loss: [1m[32m0.13454[0m[0m | time: 51.506s
[2K
| Adam | epoch: 018 | loss: 0.13454 - acc: 0.9527 -- iter: 128/262
[A[ATraining Step: 158  | total loss: [1m[32m0.12945[0m[0m | time: 64.474s
[2K
| Adam | epoch: 018 | loss: 0.12945 - acc: 0.9575 -- iter: 160/262
[A[ATraining Step: 159  | total loss: [1m[32m0.12584[0m[0m | time: 68.250s
[2K
| Adam | epoch: 018 | loss: 0.12584 - acc: 0.9555 -- iter: 192/262
[A[ATraining Step: 160  | total loss: [1m[32m0.14399[0m[0m | time: 71.524s
[2K
| Adam | epoch: 018 | loss: 0.14399 - acc: 0.9433 -- iter: 224/262
[A[ATraining Step: 161  | total loss: [1m[32m0.14439[0m[0m | time: 84.240s
[2K
| Adam | epoch: 018 | loss: 0.14439 - acc: 0.9489 -- iter: 256/262
[A[ATraining Step: 162  | total loss: [1m[32m0.13803[0m[0m | time: 103.561s
[2K
| Adam | epoch: 018 | loss: 0.13803 - acc: 0.9478 | val_loss: 6.84519 - val_acc: 0.5244 -- iter: 262/262
--
Training Step: 163  | total loss: [1m[32m0.13630[0m[0m | time: 12.988s
[2K
| Adam | epoch: 019 | loss: 0.13630 - acc: 0.9468 -- iter: 032/262
[A[ATraining Step: 164  | total loss: [1m[32m0.13716[0m[0m | time: 25.799s
[2K
| Adam | epoch: 019 | loss: 0.13716 - acc: 0.9458 -- iter: 064/262
[A[ATraining Step: 165  | total loss: [1m[32m0.12913[0m[0m | time: 38.492s
[2K
| Adam | epoch: 019 | loss: 0.12913 - acc: 0.9513 -- iter: 096/262
[A[ATraining Step: 166  | total loss: [1m[32m0.12195[0m[0m | time: 51.528s
[2K
| Adam | epoch: 019 | loss: 0.12195 - acc: 0.9530 -- iter: 128/262
[A[ATraining Step: 167  | total loss: [1m[32m0.16697[0m[0m | time: 64.587s
[2K
| Adam | epoch: 019 | loss: 0.16697 - acc: 0.9452 -- iter: 160/262
[A[ATraining Step: 168  | total loss: [1m[32m0.16383[0m[0m | time: 77.574s
[2K
| Adam | epoch: 019 | loss: 0.16383 - acc: 0.9476 -- iter: 192/262
[A[ATraining Step: 169  | total loss: [1m[32m0.15253[0m[0m | time: 81.084s
[2K
| Adam | epoch: 019 | loss: 0.15253 - acc: 0.9497 -- iter: 224/262
[A[ATraining Step: 170  | total loss: [1m[32m0.16280[0m[0m | time: 84.549s
[2K
| Adam | epoch: 019 | loss: 0.16280 - acc: 0.9380 -- iter: 256/262
[A[ATraining Step: 171  | total loss: [1m[32m0.16149[0m[0m | time: 103.827s
[2K
| Adam | epoch: 019 | loss: 0.16149 - acc: 0.9442 | val_loss: 1.05832 - val_acc: 0.7317 -- iter: 262/262
--
Training Step: 172  | total loss: [1m[32m0.17654[0m[0m | time: 13.176s
[2K
| Adam | epoch: 020 | loss: 0.17654 - acc: 0.9373 -- iter: 032/262
[A[ATraining Step: 173  | total loss: [1m[32m0.18178[0m[0m | time: 25.772s
[2K
| Adam | epoch: 020 | loss: 0.18178 - acc: 0.9373 -- iter: 064/262
[A[ATraining Step: 174  | total loss: [1m[32m0.17797[0m[0m | time: 38.657s
[2K
| Adam | epoch: 020 | loss: 0.17797 - acc: 0.9373 -- iter: 096/262
[A[ATraining Step: 175  | total loss: [1m[32m0.16741[0m[0m | time: 51.805s
[2K
| Adam | epoch: 020 | loss: 0.16741 - acc: 0.9436 -- iter: 128/262
[A[ATraining Step: 176  | total loss: [1m[32m0.16957[0m[0m | time: 64.561s
[2K
| Adam | epoch: 020 | loss: 0.16957 - acc: 0.9461 -- iter: 160/262
[A[ATraining Step: 177  | total loss: [1m[32m0.17796[0m[0m | time: 77.468s
[2K
| Adam | epoch: 020 | loss: 0.17796 - acc: 0.9421 -- iter: 192/262
[A[ATraining Step: 178  | total loss: [1m[32m0.20296[0m[0m | time: 90.470s
[2K
| Adam | epoch: 020 | loss: 0.20296 - acc: 0.9261 -- iter: 224/262
[A[ATraining Step: 179  | total loss: [1m[32m0.19992[0m[0m | time: 94.169s
[2K
| Adam | epoch: 020 | loss: 0.19992 - acc: 0.9272 -- iter: 256/262
[A[ATraining Step: 180  | total loss: [1m[32m0.18734[0m[0m | time: 104.165s
[2K
| Adam | epoch: 020 | loss: 0.18734 - acc: 0.9345 | val_loss: 1.32871 - val_acc: 0.5854 -- iter: 262/262
--
Training Step: 181  | total loss: [1m[32m0.18093[0m[0m | time: 13.004s
[2K
| Adam | epoch: 021 | loss: 0.18093 - acc: 0.9410 -- iter: 032/262
[A[ATraining Step: 182  | total loss: [1m[32m0.16489[0m[0m | time: 25.811s
[2K
| Adam | epoch: 021 | loss: 0.16489 - acc: 0.9469 -- iter: 064/262
[A[ATraining Step: 183  | total loss: [1m[32m0.16446[0m[0m | time: 38.709s
[2K
| Adam | epoch: 021 | loss: 0.16446 - acc: 0.9460 -- iter: 096/262
[A[ATraining Step: 184  | total loss: [1m[32m0.15535[0m[0m | time: 51.311s
[2K
| Adam | epoch: 021 | loss: 0.15535 - acc: 0.9483 -- iter: 128/262
[A[ATraining Step: 185  | total loss: [1m[32m0.14331[0m[0m | time: 64.415s
[2K
| Adam | epoch: 021 | loss: 0.14331 - acc: 0.9503 -- iter: 160/262
[A[ATraining Step: 186  | total loss: [1m[32m0.17869[0m[0m | time: 76.960s
[2K
| Adam | epoch: 021 | loss: 0.17869 - acc: 0.9397 -- iter: 192/262
[A[ATraining Step: 187  | total loss: [1m[32m0.19767[0m[0m | time: 89.811s
[2K
| Adam | epoch: 021 | loss: 0.19767 - acc: 0.9269 -- iter: 224/262
[A[ATraining Step: 188  | total loss: [1m[32m0.43707[0m[0m | time: 102.865s
[2K
| Adam | epoch: 021 | loss: 0.43707 - acc: 0.8936 -- iter: 256/262
[A[ATraining Step: 189  | total loss: [1m[32m0.39661[0m[0m | time: 113.084s
[2K
| Adam | epoch: 021 | loss: 0.39661 - acc: 0.9043 | val_loss: 1.14285 - val_acc: 0.7073 -- iter: 262/262
--
Training Step: 190  | total loss: [1m[32m0.36890[0m[0m | time: 3.858s
[2K
| Adam | epoch: 022 | loss: 0.36890 - acc: 0.9138 -- iter: 032/262
[A[ATraining Step: 191  | total loss: [1m[32m0.33410[0m[0m | time: 16.446s
[2K
| Adam | epoch: 022 | loss: 0.33410 - acc: 0.9224 -- iter: 064/262
[A[ATraining Step: 192  | total loss: [1m[32m0.31784[0m[0m | time: 29.641s
[2K
| Adam | epoch: 022 | loss: 0.31784 - acc: 0.9208 -- iter: 096/262
[A[ATraining Step: 193  | total loss: [1m[32m0.31063[0m[0m | time: 42.471s
[2K
| Adam | epoch: 022 | loss: 0.31063 - acc: 0.9162 -- iter: 128/262
[A[ATraining Step: 194  | total loss: [1m[32m0.29399[0m[0m | time: 55.415s
[2K
| Adam | epoch: 022 | loss: 0.29399 - acc: 0.9184 -- iter: 160/262
[A[ATraining Step: 195  | total loss: [1m[32m0.27644[0m[0m | time: 69.175s
[2K
| Adam | epoch: 022 | loss: 0.27644 - acc: 0.9234 -- iter: 192/262
[A[ATraining Step: 196  | total loss: [1m[32m0.26048[0m[0m | time: 82.798s
[2K
| Adam | epoch: 022 | loss: 0.26048 - acc: 0.9279 -- iter: 224/262
[A[ATraining Step: 197  | total loss: [1m[32m0.27044[0m[0m | time: 96.662s
[2K
| Adam | epoch: 022 | loss: 0.27044 - acc: 0.9195 -- iter: 256/262
[A[ATraining Step: 198  | total loss: [1m[32m0.26717[0m[0m | time: 110.311s
[2K
| Adam | epoch: 022 | loss: 0.26717 - acc: 0.9213 | val_loss: 1.56233 - val_acc: 0.6098 -- iter: 262/262
--
Training Step: 199  | total loss: [1m[32m0.25517[0m[0m | time: 3.856s
[2K
| Adam | epoch: 023 | loss: 0.25517 - acc: 0.9198 -- iter: 032/262
[A[ATraining Step: 200  | total loss: [1m[32m0.23340[0m[0m | time: 14.727s
[2K
| Adam | epoch: 023 | loss: 0.23340 - acc: 0.9278 | val_loss: 1.88811 - val_acc: 0.5854 -- iter: 064/262
--
Training Step: 201  | total loss: [1m[32m0.21265[0m[0m | time: 27.394s
[2K
| Adam | epoch: 023 | loss: 0.21265 - acc: 0.9350 -- iter: 096/262
[A[ATraining Step: 202  | total loss: [1m[32m0.20653[0m[0m | time: 41.353s
[2K
| Adam | epoch: 023 | loss: 0.20653 - acc: 0.9322 -- iter: 128/262
[A[ATraining Step: 203  | total loss: [1m[32m0.19706[0m[0m | time: 60.002s
[2K
| Adam | epoch: 023 | loss: 0.19706 - acc: 0.9358 -- iter: 160/262
[A[ATraining Step: 204  | total loss: [1m[32m0.19097[0m[0m | time: 79.683s
[2K
| Adam | epoch: 023 | loss: 0.19097 - acc: 0.9360 -- iter: 192/262
[A[ATraining Step: 205  | total loss: [1m[32m0.18410[0m[0m | time: 99.197s
[2K
| Adam | epoch: 023 | loss: 0.18410 - acc: 0.9361 -- iter: 224/262
[A[ATraining Step: 206  | total loss: [1m[32m0.17223[0m[0m | time: 118.405s
[2K
| Adam | epoch: 023 | loss: 0.17223 - acc: 0.9425 -- iter: 256/262
[A[ATraining Step: 207  | total loss: [1m[32m0.16804[0m[0m | time: 148.683s
[2K
| Adam | epoch: 023 | loss: 0.16804 - acc: 0.9358 | val_loss: 1.30221 - val_acc: 0.6829 -- iter: 262/262
--
Training Step: 208  | total loss: [1m[32m0.15646[0m[0m | time: 20.567s
[2K
| Adam | epoch: 024 | loss: 0.15646 - acc: 0.9391 -- iter: 032/262
[A[ATraining Step: 209  | total loss: [1m[32m0.14557[0m[0m | time: 25.744s
[2K
| Adam | epoch: 024 | loss: 0.14557 - acc: 0.9452 -- iter: 064/262
[A[ATraining Step: 210  | total loss: [1m[32m0.23388[0m[0m | time: 31.498s
[2K
| Adam | epoch: 024 | loss: 0.23388 - acc: 0.9173 -- iter: 096/262
[A[ATraining Step: 211  | total loss: [1m[32m0.24925[0m[0m | time: 50.970s
[2K
| Adam | epoch: 024 | loss: 0.24925 - acc: 0.9089 -- iter: 128/262
[A[ATraining Step: 212  | total loss: [1m[32m0.23020[0m[0m | time: 69.869s
[2K
| Adam | epoch: 024 | loss: 0.23020 - acc: 0.9180 -- iter: 160/262
[A[ATraining Step: 213  | total loss: [1m[32m0.20960[0m[0m | time: 89.413s
[2K
| Adam | epoch: 024 | loss: 0.20960 - acc: 0.9262 -- iter: 192/262
[A[ATraining Step: 214  | total loss: [1m[32m0.19150[0m[0m | time: 108.883s
[2K
| Adam | epoch: 024 | loss: 0.19150 - acc: 0.9336 -- iter: 224/262
[A[ATraining Step: 215  | total loss: [1m[32m0.17459[0m[0m | time: 128.182s
[2K
| Adam | epoch: 024 | loss: 0.17459 - acc: 0.9402 -- iter: 256/262
[A[ATraining Step: 216  | total loss: [1m[32m0.15947[0m[0m | time: 157.020s
[2K
| Adam | epoch: 024 | loss: 0.15947 - acc: 0.9462 | val_loss: 1.07851 - val_acc: 0.7073 -- iter: 262/262
--
Training Step: 217  | total loss: [1m[32m0.16357[0m[0m | time: 19.294s
[2K
| Adam | epoch: 025 | loss: 0.16357 - acc: 0.9485 -- iter: 032/262
[A[ATraining Step: 218  | total loss: [1m[32m0.15004[0m[0m | time: 38.632s
[2K
| Adam | epoch: 025 | loss: 0.15004 - acc: 0.9536 -- iter: 064/262
[A[ATraining Step: 219  | total loss: [1m[32m0.13717[0m[0m | time: 43.515s
[2K
| Adam | epoch: 025 | loss: 0.13717 - acc: 0.9583 -- iter: 096/262
[A[ATraining Step: 220  | total loss: [1m[32m0.12426[0m[0m | time: 49.306s
[2K
| Adam | epoch: 025 | loss: 0.12426 - acc: 0.9624 -- iter: 128/262
[A[ATraining Step: 221  | total loss: [1m[32m0.11276[0m[0m | time: 68.677s
[2K
| Adam | epoch: 025 | loss: 0.11276 - acc: 0.9662 -- iter: 160/262
[A[ATraining Step: 222  | total loss: [1m[32m0.12186[0m[0m | time: 88.003s
[2K
| Adam | epoch: 025 | loss: 0.12186 - acc: 0.9602 -- iter: 192/262
[A[ATraining Step: 223  | total loss: [1m[32m0.11327[0m[0m | time: 107.002s
[2K
| Adam | epoch: 025 | loss: 0.11327 - acc: 0.9642 -- iter: 224/262
[A[ATraining Step: 224  | total loss: [1m[32m0.12023[0m[0m | time: 127.683s
[2K
| Adam | epoch: 025 | loss: 0.12023 - acc: 0.9646 -- iter: 256/262
[A[ATraining Step: 225  | total loss: [1m[32m0.12135[0m[0m | time: 157.115s
[2K
| Adam | epoch: 025 | loss: 0.12135 - acc: 0.9619 | val_loss: 1.20640 - val_acc: 0.6951 -- iter: 262/262
--
Training Step: 226  | total loss: [1m[32m0.12475[0m[0m | time: 19.033s
[2K
| Adam | epoch: 026 | loss: 0.12475 - acc: 0.9626 -- iter: 032/262
[A[ATraining Step: 227  | total loss: [1m[32m0.12066[0m[0m | time: 38.444s
[2K
| Adam | epoch: 026 | loss: 0.12066 - acc: 0.9632 -- iter: 064/262
[A[ATraining Step: 228  | total loss: [1m[32m0.11280[0m[0m | time: 57.490s
[2K
| Adam | epoch: 026 | loss: 0.11280 - acc: 0.9669 -- iter: 096/262
[A[ATraining Step: 229  | total loss: [1m[32m0.10317[0m[0m | time: 64.023s
[2K
| Adam | epoch: 026 | loss: 0.10317 - acc: 0.9702 -- iter: 128/262
[A[ATraining Step: 230  | total loss: [1m[32m0.10796[0m[0m | time: 70.158s
[2K
| Adam | epoch: 026 | loss: 0.10796 - acc: 0.9565 -- iter: 160/262
[A[ATraining Step: 231  | total loss: [1m[32m0.09805[0m[0m | time: 89.473s
[2K
| Adam | epoch: 026 | loss: 0.09805 - acc: 0.9609 -- iter: 192/262
[A[ATraining Step: 232  | total loss: [1m[32m0.09064[0m[0m | time: 108.098s
[2K
| Adam | epoch: 026 | loss: 0.09064 - acc: 0.9648 -- iter: 224/262
[A[ATraining Step: 233  | total loss: [1m[32m0.08305[0m[0m | time: 127.733s
[2K
| Adam | epoch: 026 | loss: 0.08305 - acc: 0.9683 -- iter: 256/262
[A[ATraining Step: 234  | total loss: [1m[32m0.07582[0m[0m | time: 157.256s
[2K
| Adam | epoch: 026 | loss: 0.07582 - acc: 0.9715 | val_loss: 2.33253 - val_acc: 0.6220 -- iter: 262/262
--
Training Step: 235  | total loss: [1m[32m0.07980[0m[0m | time: 19.179s
[2K
| Adam | epoch: 027 | loss: 0.07980 - acc: 0.9712 -- iter: 032/262
[A[ATraining Step: 236  | total loss: [1m[32m0.07540[0m[0m | time: 38.506s
[2K
| Adam | epoch: 027 | loss: 0.07540 - acc: 0.9741 -- iter: 064/262
[A[ATraining Step: 237  | total loss: [1m[32m0.08472[0m[0m | time: 58.090s
[2K
| Adam | epoch: 027 | loss: 0.08472 - acc: 0.9642 -- iter: 096/262
[A[ATraining Step: 238  | total loss: [1m[32m0.16563[0m[0m | time: 77.963s
[2K
| Adam | epoch: 027 | loss: 0.16563 - acc: 0.9553 -- iter: 128/262
[A[ATraining Step: 239  | total loss: [1m[32m0.16148[0m[0m | time: 83.167s
[2K
| Adam | epoch: 027 | loss: 0.16148 - acc: 0.9535 -- iter: 160/262
[A[ATraining Step: 240  | total loss: [1m[32m0.14874[0m[0m | time: 89.392s
[2K
| Adam | epoch: 027 | loss: 0.14874 - acc: 0.9581 -- iter: 192/262
[A[ATraining Step: 241  | total loss: [1m[32m0.13545[0m[0m | time: 108.395s
[2K
| Adam | epoch: 027 | loss: 0.13545 - acc: 0.9623 -- iter: 224/262
[A[ATraining Step: 242  | total loss: [1m[32m0.14082[0m[0m | time: 127.836s
[2K
| Adam | epoch: 027 | loss: 0.14082 - acc: 0.9630 -- iter: 256/262
[A[ATraining Step: 243  | total loss: [1m[32m0.14635[0m[0m | time: 157.368s
[2K
| Adam | epoch: 027 | loss: 0.14635 - acc: 0.9542 | val_loss: 3.41185 - val_acc: 0.6098 -- iter: 262/262
--
Training Step: 244  | total loss: [1m[32m0.13358[0m[0m | time: 20.927s
[2K
| Adam | epoch: 028 | loss: 0.13358 - acc: 0.9587 -- iter: 032/262
[A[ATraining Step: 245  | total loss: [1m[32m0.14938[0m[0m | time: 39.942s
[2K
| Adam | epoch: 028 | loss: 0.14938 - acc: 0.9597 -- iter: 064/262
[A[ATraining Step: 246  | total loss: [1m[32m0.14218[0m[0m | time: 58.446s
[2K
| Adam | epoch: 028 | loss: 0.14218 - acc: 0.9638 -- iter: 096/262
[A[ATraining Step: 247  | total loss: [1m[32m0.14047[0m[0m | time: 77.097s
[2K
| Adam | epoch: 028 | loss: 0.14047 - acc: 0.9643 -- iter: 128/262
[A[ATraining Step: 248  | total loss: [1m[32m0.14887[0m[0m | time: 96.232s
[2K
| Adam | epoch: 028 | loss: 0.14887 - acc: 0.9616 -- iter: 160/262
[A[ATraining Step: 249  | total loss: [1m[32m0.14568[0m[0m | time: 102.139s
[2K
| Adam | epoch: 028 | loss: 0.14568 - acc: 0.9592 -- iter: 192/262
[A[ATraining Step: 250  | total loss: [1m[32m0.13241[0m[0m | time: 105.809s
[2K
| Adam | epoch: 028 | loss: 0.13241 - acc: 0.9633 -- iter: 224/262
[A[ATraining Step: 251  | total loss: [1m[32m0.12002[0m[0m | time: 120.844s
[2K
| Adam | epoch: 028 | loss: 0.12002 - acc: 0.9669 -- iter: 256/262
[A[ATraining Step: 252  | total loss: [1m[32m0.11507[0m[0m | time: 150.301s
[2K
| Adam | epoch: 028 | loss: 0.11507 - acc: 0.9671 | val_loss: 4.43463 - val_acc: 0.5732 -- iter: 262/262
--
Training Step: 253  | total loss: [1m[32m0.11594[0m[0m | time: 14.429s
[2K
| Adam | epoch: 029 | loss: 0.11594 - acc: 0.9673 -- iter: 032/262
[A[ATraining Step: 254  | total loss: [1m[32m0.14232[0m[0m | time: 28.324s
[2K
| Adam | epoch: 029 | loss: 0.14232 - acc: 0.9549 -- iter: 064/262
[A[ATraining Step: 255  | total loss: [1m[32m0.18044[0m[0m | time: 43.521s
[2K
| Adam | epoch: 029 | loss: 0.18044 - acc: 0.9376 -- iter: 096/262
[A[ATraining Step: 256  | total loss: [1m[32m0.16932[0m[0m | time: 57.821s
[2K
| Adam | epoch: 029 | loss: 0.16932 - acc: 0.9407 -- iter: 128/262
[A[ATraining Step: 257  | total loss: [1m[32m0.15692[0m[0m | time: 74.051s
[2K
| Adam | epoch: 029 | loss: 0.15692 - acc: 0.9466 -- iter: 160/262
[A[ATraining Step: 258  | total loss: [1m[32m0.15458[0m[0m | time: 93.122s
[2K
| Adam | epoch: 029 | loss: 0.15458 - acc: 0.9488 -- iter: 192/262
[A[ATraining Step: 259  | total loss: [1m[32m0.14047[0m[0m | time: 98.737s
[2K
| Adam | epoch: 029 | loss: 0.14047 - acc: 0.9539 -- iter: 224/262
[A[ATraining Step: 260  | total loss: [1m[32m0.17584[0m[0m | time: 103.951s
[2K
| Adam | epoch: 029 | loss: 0.17584 - acc: 0.9252 -- iter: 256/262
[A[ATraining Step: 261  | total loss: [1m[32m0.17463[0m[0m | time: 153.672s
[2K
| Adam | epoch: 029 | loss: 0.17463 - acc: 0.9327 | val_loss: 0.97491 - val_acc: 0.6220 -- iter: 262/262
--
Training Step: 262  | total loss: [1m[32m0.16100[0m[0m | time: 18.164s
[2K
| Adam | epoch: 030 | loss: 0.16100 - acc: 0.9394 -- iter: 032/262
[A[ATraining Step: 263  | total loss: [1m[32m0.15531[0m[0m | time: 38.285s
[2K
| Adam | epoch: 030 | loss: 0.15531 - acc: 0.9392 -- iter: 064/262
[A[ATraining Step: 264  | total loss: [1m[32m0.16448[0m[0m | time: 58.494s
[2K
| Adam | epoch: 030 | loss: 0.16448 - acc: 0.9359 -- iter: 096/262
[A[ATraining Step: 265  | total loss: [1m[32m0.16031[0m[0m | time: 77.130s
[2K
| Adam | epoch: 030 | loss: 0.16031 - acc: 0.9392 -- iter: 128/262
[A[ATraining Step: 266  | total loss: [1m[32m0.15598[0m[0m | time: 96.098s
[2K
| Adam | epoch: 030 | loss: 0.15598 - acc: 0.9422 -- iter: 160/262
[A[ATraining Step: 267  | total loss: [1m[32m0.14580[0m[0m | time: 115.552s
[2K
| Adam | epoch: 030 | loss: 0.14580 - acc: 0.9480 -- iter: 192/262
[A[ATraining Step: 268  | total loss: [1m[32m0.15837[0m[0m | time: 134.362s
[2K
| Adam | epoch: 030 | loss: 0.15837 - acc: 0.9469 -- iter: 224/262
[A[ATraining Step: 269  | total loss: [1m[32m0.15581[0m[0m | time: 139.896s
[2K
| Adam | epoch: 030 | loss: 0.15581 - acc: 0.9460 -- iter: 256/262
[A[ATraining Step: 270  | total loss: [1m[32m0.14506[0m[0m | time: 155.261s
[2K
| Adam | epoch: 030 | loss: 0.14506 - acc: 0.9514 | val_loss: 1.12076 - val_acc: 0.7073 -- iter: 262/262
--
Validation AUC:0.7376267143709004
Validation AUPRC:0.7388499265996096
Test AUC:0.7351351351351352
Test AUPRC:0.6812673398855548
BestTestF1Score	0.64	0.41	0.71	0.72	0.57	21	8	37	16	0.15
BestTestMCCScore	0.64	0.41	0.71	0.72	0.57	21	8	37	16	0.15
BestTestAccuracyScore	0.64	0.41	0.71	0.72	0.57	21	8	37	16	0.15
BestValidationF1Score	0.7	0.44	0.72	0.71	0.69	27	11	32	12	0.15
BestValidationMCC	0.7	0.44	0.72	0.71	0.69	27	11	32	12	0.15
BestValidationAccuracy	0.7	0.44	0.72	0.71	0.69	27	11	32	12	0.15
TestPredictions (Threshold:0.15)
CHEMBL183913,FP,INACT,0.8899999856948853	CHEMBL3137759,TN,INACT,0.0	CHEMBL2042370,TN,INACT,0.0	CHEMBL941,TP,ACT,0.9800000190734863	CHEMBL3356274,TN,INACT,0.019999999552965164	CHEMBL261219,TN,INACT,0.0	CHEMBL577123,TN,INACT,0.14000000059604645	CHEMBL466083,TN,INACT,0.09000000357627869	CHEMBL19612,TP,ACT,0.23999999463558197	CHEMBL508732,FP,INACT,1.0	CHEMBL419,TP,ACT,0.5299999713897705	CHEMBL3356279,TN,INACT,0.029999999329447746	CHEMBL2179304,TP,ACT,1.0	CHEMBL2011000,TP,ACT,0.9300000071525574	CHEMBL432282,TN,INACT,0.029999999329447746	CHEMBL148680,TN,INACT,0.0	CHEMBL2443193,TP,ACT,1.0	CHEMBL1662,TN,INACT,0.0	CHEMBL1955873,TP,ACT,0.6600000262260437	CHEMBL140446,TN,INACT,0.019999999552965164	CHEMBL3628131,FN,ACT,0.0	CHEMBL456724,TP,ACT,0.9900000095367432	CHEMBL220492,FN,ACT,0.0	CHEMBL3110152,FP,INACT,0.4699999988079071	CHEMBL1822699,FN,ACT,0.019999999552965164	CHEMBL99641,TN,INACT,0.0	CHEMBL321586,TN,INACT,0.0	CHEMBL320840,TN,INACT,0.0	CHEMBL268809,TN,INACT,0.0	CHEMBL140820,FP,INACT,0.25999999046325684	CHEMBL1762648,TN,INACT,0.0	CHEMBL355320,TN,INACT,0.0	CHEMBL351692,TN,INACT,0.03999999910593033	CHEMBL65369,FN,ACT,0.019999999552965164	CHEMBL464987,TN,INACT,0.009999999776482582	CHEMBL2011156,TP,ACT,0.949999988079071	CHEMBL568416,TN,INACT,0.019999999552965164	CHEMBL186537,FP,INACT,1.0	CHEMBL2323136,FN,ACT,0.009999999776482582	CHEMBL303004,TP,ACT,0.6899999976158142	CHEMBL251680,FN,ACT,0.019999999552965164	CHEMBL123066,TN,INACT,0.0	CHEMBL2092896,TP,ACT,1.0	CHEMBL176495,FN,ACT,0.0	CHEMBL6705,FN,ACT,0.019999999552965164	CHEMBL448089,TN,INACT,0.10000000149011612	CHEMBL406,TP,ACT,0.25999999046325684	CHEMBL1414,FN,ACT,0.07000000029802322	CHEMBL50,FN,ACT,0.009999999776482582	CHEMBL593972,TP,ACT,0.9800000190734863	CHEMBL1356238,TP,ACT,0.9599999785423279	CHEMBL568385,FN,ACT,0.10000000149011612	CHEMBL1271573,TN,INACT,0.0	CHEMBL344181,TN,INACT,0.0	CHEMBL567139,TP,ACT,1.0	CHEMBL506166,TN,INACT,0.0	CHEMBL58323,FN,ACT,0.019999999552965164	CHEMBL124237,TN,INACT,0.009999999776482582	CHEMBL2443317,FN,ACT,0.05000000074505806	CHEMBL385073,TN,INACT,0.009999999776482582	CHEMBL3809848,TN,INACT,0.0	CHEMBL100873,TN,INACT,0.0	CHEMBL2443202,TP,ACT,0.9900000095367432	CHEMBL145781,TN,INACT,0.019999999552965164	CHEMBL2443192,TP,ACT,0.9900000095367432	CHEMBL3110154,FP,INACT,0.4699999988079071	CHEMBL568173,TP,ACT,0.8999999761581421	CHEMBL571514,FP,INACT,0.5299999713897705	CHEMBL305268,TN,INACT,0.009999999776482582	CHEMBL34696,TN,INACT,0.019999999552965164	CHEMBL596277,TP,ACT,0.9700000286102295	CHEMBL328910,TN,INACT,0.009999999776482582	CHEMBL307145,FN,ACT,0.0	CHEMBL6853,TP,ACT,0.9900000095367432	CHEMBL152994,TN,INACT,0.07999999821186066	CHEMBL183419,TN,INACT,0.0	CHEMBL122708,FN,ACT,0.0	CHEMBL316875,TN,INACT,0.0	CHEMBL328560,TP,ACT,0.9900000095367432	CHEMBL26,FN,ACT,0.07999999821186066	CHEMBL466517,FP,INACT,0.27000001072883606	CHEMBL191528,TN,INACT,0.03999999910593033	

