CNNModel CHEMBL2842 adam 0.0005 15 256 0 0.6 False True
Number of active compounds :	420
Number of inactive compounds :	280
---------------------------------
Run id: CNNModel_CHEMBL2842_adam_0.0005_15_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2842_adam_0.0005_15_256_0.6_True/
---------------------------------
Training samples: 448
Validation samples: 140
--
Training Step: 1  | time: 0.813s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/448
[A[ATraining Step: 2  | total loss: [1m[32m0.62395[0m[0m | time: 1.427s
[2K
| Adam | epoch: 001 | loss: 0.62395 - acc: 0.3937 -- iter: 064/448
[A[ATraining Step: 3  | total loss: [1m[32m0.67527[0m[0m | time: 2.026s
[2K
| Adam | epoch: 001 | loss: 0.67527 - acc: 0.6852 -- iter: 096/448
[A[ATraining Step: 4  | total loss: [1m[32m0.67958[0m[0m | time: 2.653s
[2K
| Adam | epoch: 001 | loss: 0.67958 - acc: 0.6635 -- iter: 128/448
[A[ATraining Step: 5  | total loss: [1m[32m0.68525[0m[0m | time: 3.295s
[2K
| Adam | epoch: 001 | loss: 0.68525 - acc: 0.5936 -- iter: 160/448
[A[ATraining Step: 6  | total loss: [1m[32m0.64110[0m[0m | time: 3.887s
[2K
| Adam | epoch: 001 | loss: 0.64110 - acc: 0.6941 -- iter: 192/448
[A[ATraining Step: 7  | total loss: [1m[32m0.70035[0m[0m | time: 4.477s
[2K
| Adam | epoch: 001 | loss: 0.70035 - acc: 0.5777 -- iter: 224/448
[A[ATraining Step: 8  | total loss: [1m[32m0.71791[0m[0m | time: 5.066s
[2K
| Adam | epoch: 001 | loss: 0.71791 - acc: 0.5340 -- iter: 256/448
[A[ATraining Step: 9  | total loss: [1m[32m0.66309[0m[0m | time: 5.663s
[2K
| Adam | epoch: 001 | loss: 0.66309 - acc: 0.6318 -- iter: 288/448
[A[ATraining Step: 10  | total loss: [1m[32m0.67659[0m[0m | time: 6.272s
[2K
| Adam | epoch: 001 | loss: 0.67659 - acc: 0.5971 -- iter: 320/448
[A[ATraining Step: 11  | total loss: [1m[32m0.68039[0m[0m | time: 6.878s
[2K
| Adam | epoch: 001 | loss: 0.68039 - acc: 0.5807 -- iter: 352/448
[A[ATraining Step: 12  | total loss: [1m[32m0.68269[0m[0m | time: 7.501s
[2K
| Adam | epoch: 001 | loss: 0.68269 - acc: 0.5725 -- iter: 384/448
[A[ATraining Step: 13  | total loss: [1m[32m0.67272[0m[0m | time: 8.097s
[2K
| Adam | epoch: 001 | loss: 0.67272 - acc: 0.6084 -- iter: 416/448
[A[ATraining Step: 14  | total loss: [1m[32m0.67371[0m[0m | time: 9.729s
[2K
| Adam | epoch: 001 | loss: 0.67371 - acc: 0.6024 | val_loss: 0.67329 - val_acc: 0.6071 -- iter: 448/448
--
Training Step: 15  | total loss: [1m[32m0.69107[0m[0m | time: 0.598s
[2K
| Adam | epoch: 002 | loss: 0.69107 - acc: 0.5379 -- iter: 032/448
[A[ATraining Step: 16  | total loss: [1m[32m0.69917[0m[0m | time: 1.193s
[2K
| Adam | epoch: 002 | loss: 0.69917 - acc: 0.5002 -- iter: 064/448
[A[ATraining Step: 17  | total loss: [1m[32m0.70763[0m[0m | time: 1.794s
[2K
| Adam | epoch: 002 | loss: 0.70763 - acc: 0.4552 -- iter: 096/448
[A[ATraining Step: 18  | total loss: [1m[32m0.69176[0m[0m | time: 2.383s
[2K
| Adam | epoch: 002 | loss: 0.69176 - acc: 0.5464 -- iter: 128/448
[A[ATraining Step: 19  | total loss: [1m[32m0.68271[0m[0m | time: 2.979s
[2K
| Adam | epoch: 002 | loss: 0.68271 - acc: 0.6038 -- iter: 160/448
[A[ATraining Step: 20  | total loss: [1m[32m0.68379[0m[0m | time: 3.580s
[2K
| Adam | epoch: 002 | loss: 0.68379 - acc: 0.5906 -- iter: 192/448
[A[ATraining Step: 21  | total loss: [1m[32m0.67959[0m[0m | time: 4.178s
[2K
| Adam | epoch: 002 | loss: 0.67959 - acc: 0.6206 -- iter: 224/448
[A[ATraining Step: 22  | total loss: [1m[32m0.67257[0m[0m | time: 4.778s
[2K
| Adam | epoch: 002 | loss: 0.67257 - acc: 0.6688 -- iter: 256/448
[A[ATraining Step: 23  | total loss: [1m[32m0.67061[0m[0m | time: 5.377s
[2K
| Adam | epoch: 002 | loss: 0.67061 - acc: 0.6742 -- iter: 288/448
[A[ATraining Step: 24  | total loss: [1m[32m0.67975[0m[0m | time: 6.000s
[2K
| Adam | epoch: 002 | loss: 0.67975 - acc: 0.6165 -- iter: 320/448
[A[ATraining Step: 25  | total loss: [1m[32m0.67563[0m[0m | time: 6.580s
[2K
| Adam | epoch: 002 | loss: 0.67563 - acc: 0.6273 -- iter: 352/448
[A[ATraining Step: 26  | total loss: [1m[32m0.67815[0m[0m | time: 7.187s
[2K
| Adam | epoch: 002 | loss: 0.67815 - acc: 0.6102 -- iter: 384/448
[A[ATraining Step: 27  | total loss: [1m[32m0.67496[0m[0m | time: 7.790s
[2K
| Adam | epoch: 002 | loss: 0.67496 - acc: 0.6140 -- iter: 416/448
[A[ATraining Step: 28  | total loss: [1m[32m0.67773[0m[0m | time: 9.405s
[2K
| Adam | epoch: 002 | loss: 0.67773 - acc: 0.6011 | val_loss: 0.66723 - val_acc: 0.6071 -- iter: 448/448
--
Training Step: 29  | total loss: [1m[32m0.68492[0m[0m | time: 0.600s
[2K
| Adam | epoch: 003 | loss: 0.68492 - acc: 0.5765 -- iter: 032/448
[A[ATraining Step: 30  | total loss: [1m[32m0.67955[0m[0m | time: 1.214s
[2K
| Adam | epoch: 003 | loss: 0.67955 - acc: 0.5880 -- iter: 064/448
[A[ATraining Step: 31  | total loss: [1m[32m0.67564[0m[0m | time: 1.796s
[2K
| Adam | epoch: 003 | loss: 0.67564 - acc: 0.5965 -- iter: 096/448
[A[ATraining Step: 32  | total loss: [1m[32m0.68422[0m[0m | time: 2.392s
[2K
| Adam | epoch: 003 | loss: 0.68422 - acc: 0.5748 -- iter: 128/448
[A[ATraining Step: 33  | total loss: [1m[32m0.68740[0m[0m | time: 2.985s
[2K
| Adam | epoch: 003 | loss: 0.68740 - acc: 0.5653 -- iter: 160/448
[A[ATraining Step: 34  | total loss: [1m[32m0.68470[0m[0m | time: 3.604s
[2K
| Adam | epoch: 003 | loss: 0.68470 - acc: 0.5714 -- iter: 192/448
[A[ATraining Step: 35  | total loss: [1m[32m0.68003[0m[0m | time: 4.206s
[2K
| Adam | epoch: 003 | loss: 0.68003 - acc: 0.5826 -- iter: 224/448
[A[ATraining Step: 36  | total loss: [1m[32m0.67774[0m[0m | time: 4.813s
[2K
| Adam | epoch: 003 | loss: 0.67774 - acc: 0.5849 -- iter: 256/448
[A[ATraining Step: 37  | total loss: [1m[32m0.67628[0m[0m | time: 5.413s
[2K
| Adam | epoch: 003 | loss: 0.67628 - acc: 0.5866 -- iter: 288/448
[A[ATraining Step: 38  | total loss: [1m[32m0.66546[0m[0m | time: 6.010s
[2K
| Adam | epoch: 003 | loss: 0.66546 - acc: 0.6186 -- iter: 320/448
[A[ATraining Step: 39  | total loss: [1m[32m0.65578[0m[0m | time: 6.607s
[2K
| Adam | epoch: 003 | loss: 0.65578 - acc: 0.6438 -- iter: 352/448
[A[ATraining Step: 40  | total loss: [1m[32m0.64525[0m[0m | time: 7.197s
[2K
| Adam | epoch: 003 | loss: 0.64525 - acc: 0.6637 -- iter: 384/448
[A[ATraining Step: 41  | total loss: [1m[32m0.65941[0m[0m | time: 7.800s
[2K
| Adam | epoch: 003 | loss: 0.65941 - acc: 0.6394 -- iter: 416/448
[A[ATraining Step: 42  | total loss: [1m[32m0.66062[0m[0m | time: 9.434s
[2K
| Adam | epoch: 003 | loss: 0.66062 - acc: 0.6368 | val_loss: 0.66991 - val_acc: 0.6071 -- iter: 448/448
--
Training Step: 43  | total loss: [1m[32m0.67238[0m[0m | time: 0.571s
[2K
| Adam | epoch: 004 | loss: 0.67238 - acc: 0.6182 -- iter: 032/448
[A[ATraining Step: 44  | total loss: [1m[32m0.66617[0m[0m | time: 1.166s
[2K
| Adam | epoch: 004 | loss: 0.66617 - acc: 0.6247 -- iter: 064/448
[A[ATraining Step: 45  | total loss: [1m[32m0.65489[0m[0m | time: 1.761s
[2K
| Adam | epoch: 004 | loss: 0.65489 - acc: 0.6407 -- iter: 096/448
[A[ATraining Step: 46  | total loss: [1m[32m0.64565[0m[0m | time: 2.374s
[2K
| Adam | epoch: 004 | loss: 0.64565 - acc: 0.6537 -- iter: 128/448
[A[ATraining Step: 47  | total loss: [1m[32m0.64775[0m[0m | time: 2.981s
[2K
| Adam | epoch: 004 | loss: 0.64775 - acc: 0.6490 -- iter: 160/448
[A[ATraining Step: 48  | total loss: [1m[32m0.64979[0m[0m | time: 3.575s
[2K
| Adam | epoch: 004 | loss: 0.64979 - acc: 0.6452 -- iter: 192/448
[A[ATraining Step: 49  | total loss: [1m[32m0.64806[0m[0m | time: 4.174s
[2K
| Adam | epoch: 004 | loss: 0.64806 - acc: 0.6469 -- iter: 224/448
[A[ATraining Step: 50  | total loss: [1m[32m0.64537[0m[0m | time: 4.769s
[2K
| Adam | epoch: 004 | loss: 0.64537 - acc: 0.6484 -- iter: 256/448
[A[ATraining Step: 51  | total loss: [1m[32m0.64015[0m[0m | time: 5.370s
[2K
| Adam | epoch: 004 | loss: 0.64015 - acc: 0.6543 -- iter: 288/448
[A[ATraining Step: 52  | total loss: [1m[32m0.64883[0m[0m | time: 5.964s
[2K
| Adam | epoch: 004 | loss: 0.64883 - acc: 0.6406 -- iter: 320/448
[A[ATraining Step: 53  | total loss: [1m[32m0.65210[0m[0m | time: 6.560s
[2K
| Adam | epoch: 004 | loss: 0.65210 - acc: 0.6336 -- iter: 352/448
[A[ATraining Step: 54  | total loss: [1m[32m0.66305[0m[0m | time: 7.152s
[2K
| Adam | epoch: 004 | loss: 0.66305 - acc: 0.6142 -- iter: 384/448
[A[ATraining Step: 55  | total loss: [1m[32m0.66216[0m[0m | time: 7.739s
[2K
| Adam | epoch: 004 | loss: 0.66216 - acc: 0.6158 -- iter: 416/448
[A[ATraining Step: 56  | total loss: [1m[32m0.66623[0m[0m | time: 9.361s
[2K
| Adam | epoch: 004 | loss: 0.66623 - acc: 0.6039 | val_loss: 0.66652 - val_acc: 0.6071 -- iter: 448/448
--
Training Step: 57  | total loss: [1m[32m0.66877[0m[0m | time: 0.591s
[2K
| Adam | epoch: 005 | loss: 0.66877 - acc: 0.5982 -- iter: 032/448
[A[ATraining Step: 58  | total loss: [1m[32m0.67394[0m[0m | time: 1.186s
[2K
| Adam | epoch: 005 | loss: 0.67394 - acc: 0.5805 -- iter: 064/448
[A[ATraining Step: 59  | total loss: [1m[32m0.67523[0m[0m | time: 1.788s
[2K
| Adam | epoch: 005 | loss: 0.67523 - acc: 0.5739 -- iter: 096/448
[A[ATraining Step: 60  | total loss: [1m[32m0.67446[0m[0m | time: 2.398s
[2K
| Adam | epoch: 005 | loss: 0.67446 - acc: 0.5807 -- iter: 128/448
[A[ATraining Step: 61  | total loss: [1m[32m0.67426[0m[0m | time: 2.990s
[2K
| Adam | epoch: 005 | loss: 0.67426 - acc: 0.5864 -- iter: 160/448
[A[ATraining Step: 62  | total loss: [1m[32m0.67484[0m[0m | time: 3.598s
[2K
| Adam | epoch: 005 | loss: 0.67484 - acc: 0.5874 -- iter: 192/448
[A[ATraining Step: 63  | total loss: [1m[32m0.67287[0m[0m | time: 4.201s
[2K
| Adam | epoch: 005 | loss: 0.67287 - acc: 0.6040 -- iter: 224/448
[A[ATraining Step: 64  | total loss: [1m[32m0.67135[0m[0m | time: 4.801s
[2K
| Adam | epoch: 005 | loss: 0.67135 - acc: 0.6184 -- iter: 256/448
[A[ATraining Step: 65  | total loss: [1m[32m0.67323[0m[0m | time: 5.409s
[2K
| Adam | epoch: 005 | loss: 0.67323 - acc: 0.6076 -- iter: 288/448
[A[ATraining Step: 66  | total loss: [1m[32m0.67404[0m[0m | time: 6.002s
[2K
| Adam | epoch: 005 | loss: 0.67404 - acc: 0.6021 -- iter: 320/448
[A[ATraining Step: 67  | total loss: [1m[32m0.67121[0m[0m | time: 6.593s
[2K
| Adam | epoch: 005 | loss: 0.67121 - acc: 0.6124 -- iter: 352/448
[A[ATraining Step: 68  | total loss: [1m[32m0.66951[0m[0m | time: 7.180s
[2K
| Adam | epoch: 005 | loss: 0.66951 - acc: 0.6176 -- iter: 384/448
[A[ATraining Step: 69  | total loss: [1m[32m0.67005[0m[0m | time: 7.787s
[2K
| Adam | epoch: 005 | loss: 0.67005 - acc: 0.6111 -- iter: 416/448
[A[ATraining Step: 70  | total loss: [1m[32m0.66532[0m[0m | time: 9.384s
[2K
| Adam | epoch: 005 | loss: 0.66532 - acc: 0.6200 | val_loss: 0.65563 - val_acc: 0.6071 -- iter: 448/448
--
Training Step: 71  | total loss: [1m[32m0.66684[0m[0m | time: 0.616s
[2K
| Adam | epoch: 006 | loss: 0.66684 - acc: 0.6134 -- iter: 032/448
[A[ATraining Step: 72  | total loss: [1m[32m0.66448[0m[0m | time: 1.214s
[2K
| Adam | epoch: 006 | loss: 0.66448 - acc: 0.6147 -- iter: 064/448
[A[ATraining Step: 73  | total loss: [1m[32m0.66407[0m[0m | time: 1.819s
[2K
| Adam | epoch: 006 | loss: 0.66407 - acc: 0.6159 -- iter: 096/448
[A[ATraining Step: 74  | total loss: [1m[32m0.67617[0m[0m | time: 2.436s
[2K
| Adam | epoch: 006 | loss: 0.67617 - acc: 0.5963 -- iter: 128/448
[A[ATraining Step: 75  | total loss: [1m[32m0.67656[0m[0m | time: 3.035s
[2K
| Adam | epoch: 006 | loss: 0.67656 - acc: 0.5926 -- iter: 160/448
[A[ATraining Step: 76  | total loss: [1m[32m0.67634[0m[0m | time: 3.632s
[2K
| Adam | epoch: 006 | loss: 0.67634 - acc: 0.5894 -- iter: 192/448
[A[ATraining Step: 77  | total loss: [1m[32m0.67261[0m[0m | time: 4.244s
[2K
| Adam | epoch: 006 | loss: 0.67261 - acc: 0.5932 -- iter: 224/448
[A[ATraining Step: 78  | total loss: [1m[32m0.66889[0m[0m | time: 4.847s
[2K
| Adam | epoch: 006 | loss: 0.66889 - acc: 0.6030 -- iter: 256/448
[A[ATraining Step: 79  | total loss: [1m[32m0.66728[0m[0m | time: 5.442s
[2K
| Adam | epoch: 006 | loss: 0.66728 - acc: 0.6053 -- iter: 288/448
[A[ATraining Step: 80  | total loss: [1m[32m0.66406[0m[0m | time: 6.040s
[2K
| Adam | epoch: 006 | loss: 0.66406 - acc: 0.6137 -- iter: 320/448
[A[ATraining Step: 81  | total loss: [1m[32m0.66623[0m[0m | time: 6.642s
[2K
| Adam | epoch: 006 | loss: 0.66623 - acc: 0.6054 -- iter: 352/448
[A[ATraining Step: 82  | total loss: [1m[32m0.66516[0m[0m | time: 7.235s
[2K
| Adam | epoch: 006 | loss: 0.66516 - acc: 0.6073 -- iter: 384/448
[A[ATraining Step: 83  | total loss: [1m[32m0.65924[0m[0m | time: 7.838s
[2K
| Adam | epoch: 006 | loss: 0.65924 - acc: 0.6185 -- iter: 416/448
[A[ATraining Step: 84  | total loss: [1m[32m0.65981[0m[0m | time: 9.454s
[2K
| Adam | epoch: 006 | loss: 0.65981 - acc: 0.6129 | val_loss: 0.64206 - val_acc: 0.6071 -- iter: 448/448
--
Training Step: 85  | total loss: [1m[32m0.66049[0m[0m | time: 0.607s
[2K
| Adam | epoch: 007 | loss: 0.66049 - acc: 0.6078 -- iter: 032/448
[A[ATraining Step: 86  | total loss: [1m[32m0.66068[0m[0m | time: 1.211s
[2K
| Adam | epoch: 007 | loss: 0.66068 - acc: 0.6002 -- iter: 064/448
[A[ATraining Step: 87  | total loss: [1m[32m0.65289[0m[0m | time: 1.842s
[2K
| Adam | epoch: 007 | loss: 0.65289 - acc: 0.6152 -- iter: 096/448
[A[ATraining Step: 88  | total loss: [1m[32m0.65366[0m[0m | time: 2.465s
[2K
| Adam | epoch: 007 | loss: 0.65366 - acc: 0.6099 -- iter: 128/448
[A[ATraining Step: 89  | total loss: [1m[32m0.65216[0m[0m | time: 3.085s
[2K
| Adam | epoch: 007 | loss: 0.65216 - acc: 0.6114 -- iter: 160/448
[A[ATraining Step: 90  | total loss: [1m[32m0.64541[0m[0m | time: 3.721s
[2K
| Adam | epoch: 007 | loss: 0.64541 - acc: 0.6190 -- iter: 192/448
[A[ATraining Step: 91  | total loss: [1m[32m0.63917[0m[0m | time: 4.314s
[2K
| Adam | epoch: 007 | loss: 0.63917 - acc: 0.6259 -- iter: 224/448
[A[ATraining Step: 92  | total loss: [1m[32m0.63424[0m[0m | time: 4.911s
[2K
| Adam | epoch: 007 | loss: 0.63424 - acc: 0.6320 -- iter: 256/448
[A[ATraining Step: 93  | total loss: [1m[32m0.64052[0m[0m | time: 5.533s
[2K
| Adam | epoch: 007 | loss: 0.64052 - acc: 0.6220 -- iter: 288/448
[A[ATraining Step: 94  | total loss: [1m[32m0.62515[0m[0m | time: 6.130s
[2K
| Adam | epoch: 007 | loss: 0.62515 - acc: 0.6379 -- iter: 320/448
[A[ATraining Step: 95  | total loss: [1m[32m0.62972[0m[0m | time: 6.742s
[2K
| Adam | epoch: 007 | loss: 0.62972 - acc: 0.6272 -- iter: 352/448
[A[ATraining Step: 96  | total loss: [1m[32m0.62994[0m[0m | time: 7.349s
[2K
| Adam | epoch: 007 | loss: 0.62994 - acc: 0.6301 -- iter: 384/448
[A[ATraining Step: 97  | total loss: [1m[32m0.62516[0m[0m | time: 7.950s
[2K
| Adam | epoch: 007 | loss: 0.62516 - acc: 0.6359 -- iter: 416/448
[A[ATraining Step: 98  | total loss: [1m[32m0.63598[0m[0m | time: 9.547s
[2K
| Adam | epoch: 007 | loss: 0.63598 - acc: 0.6160 | val_loss: 0.62103 - val_acc: 0.6071 -- iter: 448/448
--
Training Step: 99  | total loss: [1m[32m0.64039[0m[0m | time: 0.632s
[2K
| Adam | epoch: 008 | loss: 0.64039 - acc: 0.6044 -- iter: 032/448
[A[ATraining Step: 100  | total loss: [1m[32m0.63352[0m[0m | time: 1.245s
[2K
| Adam | epoch: 008 | loss: 0.63352 - acc: 0.6159 -- iter: 064/448
[A[ATraining Step: 101  | total loss: [1m[32m0.63345[0m[0m | time: 1.842s
[2K
| Adam | epoch: 008 | loss: 0.63345 - acc: 0.6105 -- iter: 096/448
[A[ATraining Step: 102  | total loss: [1m[32m0.63239[0m[0m | time: 2.445s
[2K
| Adam | epoch: 008 | loss: 0.63239 - acc: 0.6057 -- iter: 128/448
[A[ATraining Step: 103  | total loss: [1m[32m0.62918[0m[0m | time: 3.048s
[2K
| Adam | epoch: 008 | loss: 0.62918 - acc: 0.6108 -- iter: 160/448
[A[ATraining Step: 104  | total loss: [1m[32m0.63629[0m[0m | time: 3.645s
[2K
| Adam | epoch: 008 | loss: 0.63629 - acc: 0.5934 -- iter: 192/448
[A[ATraining Step: 105  | total loss: [1m[32m0.63223[0m[0m | time: 4.238s
[2K
| Adam | epoch: 008 | loss: 0.63223 - acc: 0.5935 -- iter: 224/448
[A[ATraining Step: 106  | total loss: [1m[32m0.62754[0m[0m | time: 4.851s
[2K
| Adam | epoch: 008 | loss: 0.62754 - acc: 0.5935 -- iter: 256/448
[A[ATraining Step: 107  | total loss: [1m[32m0.62780[0m[0m | time: 5.488s
[2K
| Adam | epoch: 008 | loss: 0.62780 - acc: 0.5935 -- iter: 288/448
[A[ATraining Step: 108  | total loss: [1m[32m0.62325[0m[0m | time: 6.085s
[2K
| Adam | epoch: 008 | loss: 0.62325 - acc: 0.5967 -- iter: 320/448
[A[ATraining Step: 109  | total loss: [1m[32m0.62145[0m[0m | time: 6.686s
[2K
| Adam | epoch: 008 | loss: 0.62145 - acc: 0.6026 -- iter: 352/448
[A[ATraining Step: 110  | total loss: [1m[32m0.61395[0m[0m | time: 7.297s
[2K
| Adam | epoch: 008 | loss: 0.61395 - acc: 0.6111 -- iter: 384/448
[A[ATraining Step: 111  | total loss: [1m[32m0.60424[0m[0m | time: 7.892s
[2K
| Adam | epoch: 008 | loss: 0.60424 - acc: 0.6375 -- iter: 416/448
[A[ATraining Step: 112  | total loss: [1m[32m0.60156[0m[0m | time: 9.495s
[2K
| Adam | epoch: 008 | loss: 0.60156 - acc: 0.6363 | val_loss: 0.55207 - val_acc: 0.7214 -- iter: 448/448
--
Training Step: 113  | total loss: [1m[32m0.58820[0m[0m | time: 0.596s
[2K
| Adam | epoch: 009 | loss: 0.58820 - acc: 0.6508 -- iter: 032/448
[A[ATraining Step: 114  | total loss: [1m[32m0.57915[0m[0m | time: 1.193s
[2K
| Adam | epoch: 009 | loss: 0.57915 - acc: 0.6638 -- iter: 064/448
[A[ATraining Step: 115  | total loss: [1m[32m0.57189[0m[0m | time: 1.789s
[2K
| Adam | epoch: 009 | loss: 0.57189 - acc: 0.6818 -- iter: 096/448
[A[ATraining Step: 116  | total loss: [1m[32m0.56798[0m[0m | time: 2.393s
[2K
| Adam | epoch: 009 | loss: 0.56798 - acc: 0.6855 -- iter: 128/448
[A[ATraining Step: 117  | total loss: [1m[32m0.57634[0m[0m | time: 2.989s
[2K
| Adam | epoch: 009 | loss: 0.57634 - acc: 0.6763 -- iter: 160/448
[A[ATraining Step: 118  | total loss: [1m[32m0.56796[0m[0m | time: 3.578s
[2K
| Adam | epoch: 009 | loss: 0.56796 - acc: 0.6868 -- iter: 192/448
[A[ATraining Step: 119  | total loss: [1m[32m0.56620[0m[0m | time: 4.185s
[2K
| Adam | epoch: 009 | loss: 0.56620 - acc: 0.6994 -- iter: 224/448
[A[ATraining Step: 120  | total loss: [1m[32m0.55205[0m[0m | time: 4.798s
[2K
| Adam | epoch: 009 | loss: 0.55205 - acc: 0.7169 -- iter: 256/448
[A[ATraining Step: 121  | total loss: [1m[32m0.53513[0m[0m | time: 5.405s
[2K
| Adam | epoch: 009 | loss: 0.53513 - acc: 0.7265 -- iter: 288/448
[A[ATraining Step: 122  | total loss: [1m[32m0.52254[0m[0m | time: 6.011s
[2K
| Adam | epoch: 009 | loss: 0.52254 - acc: 0.7320 -- iter: 320/448
[A[ATraining Step: 123  | total loss: [1m[32m0.50850[0m[0m | time: 6.633s
[2K
| Adam | epoch: 009 | loss: 0.50850 - acc: 0.7463 -- iter: 352/448
[A[ATraining Step: 124  | total loss: [1m[32m0.50935[0m[0m | time: 7.222s
[2K
| Adam | epoch: 009 | loss: 0.50935 - acc: 0.7466 -- iter: 384/448
[A[ATraining Step: 125  | total loss: [1m[32m0.51686[0m[0m | time: 7.818s
[2K
| Adam | epoch: 009 | loss: 0.51686 - acc: 0.7345 -- iter: 416/448
[A[ATraining Step: 126  | total loss: [1m[32m0.50953[0m[0m | time: 9.444s
[2K
| Adam | epoch: 009 | loss: 0.50953 - acc: 0.7454 | val_loss: 0.49140 - val_acc: 0.7500 -- iter: 448/448
--
Training Step: 127  | total loss: [1m[32m0.51340[0m[0m | time: 0.594s
[2K
| Adam | epoch: 010 | loss: 0.51340 - acc: 0.7490 -- iter: 032/448
[A[ATraining Step: 128  | total loss: [1m[32m0.50390[0m[0m | time: 1.193s
[2K
| Adam | epoch: 010 | loss: 0.50390 - acc: 0.7491 -- iter: 064/448
[A[ATraining Step: 129  | total loss: [1m[32m0.49726[0m[0m | time: 1.819s
[2K
| Adam | epoch: 010 | loss: 0.49726 - acc: 0.7523 -- iter: 096/448
[A[ATraining Step: 130  | total loss: [1m[32m0.48544[0m[0m | time: 2.417s
[2K
| Adam | epoch: 010 | loss: 0.48544 - acc: 0.7646 -- iter: 128/448
[A[ATraining Step: 131  | total loss: [1m[32m0.48492[0m[0m | time: 3.006s
[2K
| Adam | epoch: 010 | loss: 0.48492 - acc: 0.7662 -- iter: 160/448
[A[ATraining Step: 132  | total loss: [1m[32m0.48562[0m[0m | time: 3.601s
[2K
| Adam | epoch: 010 | loss: 0.48562 - acc: 0.7677 -- iter: 192/448
[A[ATraining Step: 133  | total loss: [1m[32m0.47684[0m[0m | time: 4.219s
[2K
| Adam | epoch: 010 | loss: 0.47684 - acc: 0.7722 -- iter: 224/448
[A[ATraining Step: 134  | total loss: [1m[32m0.46249[0m[0m | time: 4.822s
[2K
| Adam | epoch: 010 | loss: 0.46249 - acc: 0.7888 -- iter: 256/448
[A[ATraining Step: 135  | total loss: [1m[32m0.44811[0m[0m | time: 5.430s
[2K
| Adam | epoch: 010 | loss: 0.44811 - acc: 0.8005 -- iter: 288/448
[A[ATraining Step: 136  | total loss: [1m[32m0.43201[0m[0m | time: 6.025s
[2K
| Adam | epoch: 010 | loss: 0.43201 - acc: 0.8111 -- iter: 320/448
[A[ATraining Step: 137  | total loss: [1m[32m0.42779[0m[0m | time: 6.627s
[2K
| Adam | epoch: 010 | loss: 0.42779 - acc: 0.8112 -- iter: 352/448
[A[ATraining Step: 138  | total loss: [1m[32m0.43142[0m[0m | time: 7.240s
[2K
| Adam | epoch: 010 | loss: 0.43142 - acc: 0.8051 -- iter: 384/448
[A[ATraining Step: 139  | total loss: [1m[32m0.42390[0m[0m | time: 7.841s
[2K
| Adam | epoch: 010 | loss: 0.42390 - acc: 0.8058 -- iter: 416/448
[A[ATraining Step: 140  | total loss: [1m[32m0.40817[0m[0m | time: 9.434s
[2K
| Adam | epoch: 010 | loss: 0.40817 - acc: 0.8065 | val_loss: 0.41037 - val_acc: 0.8286 -- iter: 448/448
--
Training Step: 141  | total loss: [1m[32m0.40826[0m[0m | time: 0.616s
[2K
| Adam | epoch: 011 | loss: 0.40826 - acc: 0.8009 -- iter: 032/448
[A[ATraining Step: 142  | total loss: [1m[32m0.41894[0m[0m | time: 1.217s
[2K
| Adam | epoch: 011 | loss: 0.41894 - acc: 0.8020 -- iter: 064/448
[A[ATraining Step: 143  | total loss: [1m[32m0.41891[0m[0m | time: 1.815s
[2K
| Adam | epoch: 011 | loss: 0.41891 - acc: 0.7999 -- iter: 096/448
[A[ATraining Step: 144  | total loss: [1m[32m0.42861[0m[0m | time: 2.401s
[2K
| Adam | epoch: 011 | loss: 0.42861 - acc: 0.7918 -- iter: 128/448
[A[ATraining Step: 145  | total loss: [1m[32m0.40788[0m[0m | time: 2.996s
[2K
| Adam | epoch: 011 | loss: 0.40788 - acc: 0.8033 -- iter: 160/448
[A[ATraining Step: 146  | total loss: [1m[32m0.38063[0m[0m | time: 3.590s
[2K
| Adam | epoch: 011 | loss: 0.38063 - acc: 0.8136 -- iter: 192/448
[A[ATraining Step: 147  | total loss: [1m[32m0.42736[0m[0m | time: 4.201s
[2K
| Adam | epoch: 011 | loss: 0.42736 - acc: 0.7978 -- iter: 224/448
[A[ATraining Step: 148  | total loss: [1m[32m0.44657[0m[0m | time: 4.808s
[2K
| Adam | epoch: 011 | loss: 0.44657 - acc: 0.7899 -- iter: 256/448
[A[ATraining Step: 149  | total loss: [1m[32m0.42122[0m[0m | time: 5.404s
[2K
| Adam | epoch: 011 | loss: 0.42122 - acc: 0.8047 -- iter: 288/448
[A[ATraining Step: 150  | total loss: [1m[32m0.42241[0m[0m | time: 6.016s
[2K
| Adam | epoch: 011 | loss: 0.42241 - acc: 0.8055 -- iter: 320/448
[A[ATraining Step: 151  | total loss: [1m[32m0.43370[0m[0m | time: 6.614s
[2K
| Adam | epoch: 011 | loss: 0.43370 - acc: 0.8030 -- iter: 352/448
[A[ATraining Step: 152  | total loss: [1m[32m0.42865[0m[0m | time: 7.219s
[2K
| Adam | epoch: 011 | loss: 0.42865 - acc: 0.7977 -- iter: 384/448
[A[ATraining Step: 153  | total loss: [1m[32m0.41164[0m[0m | time: 7.818s
[2K
| Adam | epoch: 011 | loss: 0.41164 - acc: 0.8117 -- iter: 416/448
[A[ATraining Step: 154  | total loss: [1m[32m0.40906[0m[0m | time: 9.418s
[2K
| Adam | epoch: 011 | loss: 0.40906 - acc: 0.8118 | val_loss: 0.33155 - val_acc: 0.8500 -- iter: 448/448
--
Training Step: 155  | total loss: [1m[32m0.38967[0m[0m | time: 0.594s
[2K
| Adam | epoch: 012 | loss: 0.38967 - acc: 0.8212 -- iter: 032/448
[A[ATraining Step: 156  | total loss: [1m[32m0.38226[0m[0m | time: 1.194s
[2K
| Adam | epoch: 012 | loss: 0.38226 - acc: 0.8266 -- iter: 064/448
[A[ATraining Step: 157  | total loss: [1m[32m0.37152[0m[0m | time: 1.788s
[2K
| Adam | epoch: 012 | loss: 0.37152 - acc: 0.8346 -- iter: 096/448
[A[ATraining Step: 158  | total loss: [1m[32m0.35468[0m[0m | time: 2.386s
[2K
| Adam | epoch: 012 | loss: 0.35468 - acc: 0.8417 -- iter: 128/448
[A[ATraining Step: 159  | total loss: [1m[32m0.33882[0m[0m | time: 2.986s
[2K
| Adam | epoch: 012 | loss: 0.33882 - acc: 0.8513 -- iter: 160/448
[A[ATraining Step: 160  | total loss: [1m[32m0.34251[0m[0m | time: 3.584s
[2K
| Adam | epoch: 012 | loss: 0.34251 - acc: 0.8537 -- iter: 192/448
[A[ATraining Step: 161  | total loss: [1m[32m0.34030[0m[0m | time: 4.186s
[2K
| Adam | epoch: 012 | loss: 0.34030 - acc: 0.8589 -- iter: 224/448
[A[ATraining Step: 162  | total loss: [1m[32m0.32624[0m[0m | time: 4.786s
[2K
| Adam | epoch: 012 | loss: 0.32624 - acc: 0.8606 -- iter: 256/448
[A[ATraining Step: 163  | total loss: [1m[32m0.33350[0m[0m | time: 5.401s
[2K
| Adam | epoch: 012 | loss: 0.33350 - acc: 0.8651 -- iter: 288/448
[A[ATraining Step: 164  | total loss: [1m[32m0.32830[0m[0m | time: 5.999s
[2K
| Adam | epoch: 012 | loss: 0.32830 - acc: 0.8692 -- iter: 320/448
[A[ATraining Step: 165  | total loss: [1m[32m0.31074[0m[0m | time: 6.587s
[2K
| Adam | epoch: 012 | loss: 0.31074 - acc: 0.8729 -- iter: 352/448
[A[ATraining Step: 166  | total loss: [1m[32m0.29197[0m[0m | time: 7.214s
[2K
| Adam | epoch: 012 | loss: 0.29197 - acc: 0.8794 -- iter: 384/448
[A[ATraining Step: 167  | total loss: [1m[32m0.27832[0m[0m | time: 7.812s
[2K
| Adam | epoch: 012 | loss: 0.27832 - acc: 0.8852 -- iter: 416/448
[A[ATraining Step: 168  | total loss: [1m[32m0.27762[0m[0m | time: 9.428s
[2K
| Adam | epoch: 012 | loss: 0.27762 - acc: 0.8904 | val_loss: 0.34493 - val_acc: 0.8643 -- iter: 448/448
--
Training Step: 169  | total loss: [1m[32m0.27017[0m[0m | time: 0.590s
[2K
| Adam | epoch: 013 | loss: 0.27017 - acc: 0.8951 -- iter: 032/448
[A[ATraining Step: 170  | total loss: [1m[32m0.26952[0m[0m | time: 1.180s
[2K
| Adam | epoch: 013 | loss: 0.26952 - acc: 0.8931 -- iter: 064/448
[A[ATraining Step: 171  | total loss: [1m[32m0.26227[0m[0m | time: 1.771s
[2K
| Adam | epoch: 013 | loss: 0.26227 - acc: 0.8976 -- iter: 096/448
[A[ATraining Step: 172  | total loss: [1m[32m0.27168[0m[0m | time: 2.381s
[2K
| Adam | epoch: 013 | loss: 0.27168 - acc: 0.8922 -- iter: 128/448
[A[ATraining Step: 173  | total loss: [1m[32m0.26760[0m[0m | time: 2.979s
[2K
| Adam | epoch: 013 | loss: 0.26760 - acc: 0.8967 -- iter: 160/448
[A[ATraining Step: 174  | total loss: [1m[32m0.27205[0m[0m | time: 3.562s
[2K
| Adam | epoch: 013 | loss: 0.27205 - acc: 0.8977 -- iter: 192/448
[A[ATraining Step: 175  | total loss: [1m[32m0.26609[0m[0m | time: 4.158s
[2K
| Adam | epoch: 013 | loss: 0.26609 - acc: 0.8985 -- iter: 224/448
[A[ATraining Step: 176  | total loss: [1m[32m0.24948[0m[0m | time: 4.750s
[2K
| Adam | epoch: 013 | loss: 0.24948 - acc: 0.9087 -- iter: 256/448
[A[ATraining Step: 177  | total loss: [1m[32m0.23975[0m[0m | time: 5.348s
[2K
| Adam | epoch: 013 | loss: 0.23975 - acc: 0.9147 -- iter: 288/448
[A[ATraining Step: 178  | total loss: [1m[32m0.23782[0m[0m | time: 5.947s
[2K
| Adam | epoch: 013 | loss: 0.23782 - acc: 0.9170 -- iter: 320/448
[A[ATraining Step: 179  | total loss: [1m[32m0.22524[0m[0m | time: 6.544s
[2K
| Adam | epoch: 013 | loss: 0.22524 - acc: 0.9190 -- iter: 352/448
[A[ATraining Step: 180  | total loss: [1m[32m0.24067[0m[0m | time: 7.147s
[2K
| Adam | epoch: 013 | loss: 0.24067 - acc: 0.9115 -- iter: 384/448
[A[ATraining Step: 181  | total loss: [1m[32m0.23738[0m[0m | time: 7.747s
[2K
| Adam | epoch: 013 | loss: 0.23738 - acc: 0.9110 -- iter: 416/448
[A[ATraining Step: 182  | total loss: [1m[32m0.23096[0m[0m | time: 9.337s
[2K
| Adam | epoch: 013 | loss: 0.23096 - acc: 0.9136 | val_loss: 0.43889 - val_acc: 0.8286 -- iter: 448/448
--
Training Step: 183  | total loss: [1m[32m0.23824[0m[0m | time: 0.603s
[2K
| Adam | epoch: 014 | loss: 0.23824 - acc: 0.9098 -- iter: 032/448
[A[ATraining Step: 184  | total loss: [1m[32m0.23710[0m[0m | time: 1.232s
[2K
| Adam | epoch: 014 | loss: 0.23710 - acc: 0.9032 -- iter: 064/448
[A[ATraining Step: 185  | total loss: [1m[32m0.21923[0m[0m | time: 1.833s
[2K
| Adam | epoch: 014 | loss: 0.21923 - acc: 0.9128 -- iter: 096/448
[A[ATraining Step: 186  | total loss: [1m[32m0.22044[0m[0m | time: 2.434s
[2K
| Adam | epoch: 014 | loss: 0.22044 - acc: 0.9091 -- iter: 128/448
[A[ATraining Step: 187  | total loss: [1m[32m0.22741[0m[0m | time: 3.025s
[2K
| Adam | epoch: 014 | loss: 0.22741 - acc: 0.8963 -- iter: 160/448
[A[ATraining Step: 188  | total loss: [1m[32m0.22166[0m[0m | time: 3.617s
[2K
| Adam | epoch: 014 | loss: 0.22166 - acc: 0.9004 -- iter: 192/448
[A[ATraining Step: 189  | total loss: [1m[32m0.21900[0m[0m | time: 4.216s
[2K
| Adam | epoch: 014 | loss: 0.21900 - acc: 0.9010 -- iter: 224/448
[A[ATraining Step: 190  | total loss: [1m[32m0.21530[0m[0m | time: 4.804s
[2K
| Adam | epoch: 014 | loss: 0.21530 - acc: 0.9046 -- iter: 256/448
[A[ATraining Step: 191  | total loss: [1m[32m0.20791[0m[0m | time: 5.387s
[2K
| Adam | epoch: 014 | loss: 0.20791 - acc: 0.9110 -- iter: 288/448
[A[ATraining Step: 192  | total loss: [1m[32m0.19521[0m[0m | time: 5.992s
[2K
| Adam | epoch: 014 | loss: 0.19521 - acc: 0.9168 -- iter: 320/448
[A[ATraining Step: 193  | total loss: [1m[32m0.18307[0m[0m | time: 6.576s
[2K
| Adam | epoch: 014 | loss: 0.18307 - acc: 0.9220 -- iter: 352/448
[A[ATraining Step: 194  | total loss: [1m[32m0.17209[0m[0m | time: 7.167s
[2K
| Adam | epoch: 014 | loss: 0.17209 - acc: 0.9298 -- iter: 384/448
[A[ATraining Step: 195  | total loss: [1m[32m0.16649[0m[0m | time: 7.771s
[2K
| Adam | epoch: 014 | loss: 0.16649 - acc: 0.9306 -- iter: 416/448
[A[ATraining Step: 196  | total loss: [1m[32m0.15801[0m[0m | time: 9.365s
[2K
| Adam | epoch: 014 | loss: 0.15801 - acc: 0.9344 | val_loss: 0.30541 - val_acc: 0.9071 -- iter: 448/448
--
Training Step: 197  | total loss: [1m[32m0.15029[0m[0m | time: 0.600s
[2K
| Adam | epoch: 015 | loss: 0.15029 - acc: 0.9378 -- iter: 032/448
[A[ATraining Step: 198  | total loss: [1m[32m0.14740[0m[0m | time: 1.209s
[2K
| Adam | epoch: 015 | loss: 0.14740 - acc: 0.9409 -- iter: 064/448
[A[ATraining Step: 199  | total loss: [1m[32m0.14467[0m[0m | time: 1.818s
[2K
| Adam | epoch: 015 | loss: 0.14467 - acc: 0.9437 -- iter: 096/448
[A[ATraining Step: 200  | total loss: [1m[32m0.14321[0m[0m | time: 3.453s
[2K
| Adam | epoch: 015 | loss: 0.14321 - acc: 0.9431 | val_loss: 0.38679 - val_acc: 0.8714 -- iter: 128/448
--
Training Step: 201  | total loss: [1m[32m0.14929[0m[0m | time: 4.051s
[2K
| Adam | epoch: 015 | loss: 0.14929 - acc: 0.9394 -- iter: 160/448
[A[ATraining Step: 202  | total loss: [1m[32m0.14388[0m[0m | time: 4.647s
[2K
| Adam | epoch: 015 | loss: 0.14388 - acc: 0.9392 -- iter: 192/448
[A[ATraining Step: 203  | total loss: [1m[32m0.13968[0m[0m | time: 5.241s
[2K
| Adam | epoch: 015 | loss: 0.13968 - acc: 0.9390 -- iter: 224/448
[A[ATraining Step: 204  | total loss: [1m[32m0.13542[0m[0m | time: 5.839s
[2K
| Adam | epoch: 015 | loss: 0.13542 - acc: 0.9420 -- iter: 256/448
[A[ATraining Step: 205  | total loss: [1m[32m0.14263[0m[0m | time: 6.469s
[2K
| Adam | epoch: 015 | loss: 0.14263 - acc: 0.9384 -- iter: 288/448
[A[ATraining Step: 206  | total loss: [1m[32m0.14008[0m[0m | time: 7.067s
[2K
| Adam | epoch: 015 | loss: 0.14008 - acc: 0.9383 -- iter: 320/448
[A[ATraining Step: 207  | total loss: [1m[32m0.13055[0m[0m | time: 7.660s
[2K
| Adam | epoch: 015 | loss: 0.13055 - acc: 0.9445 -- iter: 352/448
[A[ATraining Step: 208  | total loss: [1m[32m0.15278[0m[0m | time: 8.258s
[2K
| Adam | epoch: 015 | loss: 0.15278 - acc: 0.9438 -- iter: 384/448
[A[ATraining Step: 209  | total loss: [1m[32m0.14091[0m[0m | time: 8.861s
[2K
| Adam | epoch: 015 | loss: 0.14091 - acc: 0.9494 -- iter: 416/448
[A[ATraining Step: 210  | total loss: [1m[32m0.13008[0m[0m | time: 10.466s
[2K
| Adam | epoch: 015 | loss: 0.13008 - acc: 0.9545 | val_loss: 0.32634 - val_acc: 0.9071 -- iter: 448/448
--
Validation AUC:0.9411764705882354
Validation AUPRC:0.9500091313632686
Test AUC:0.9579166666666667
Test AUPRC:0.9667802347877698
BestTestF1Score	0.91	0.78	0.89	0.87	0.96	77	12	48	3	0.3
BestTestMCCScore	0.91	0.78	0.89	0.87	0.96	77	12	48	3	0.3
BestTestAccuracyScore	0.91	0.78	0.89	0.87	0.96	77	12	48	3	0.3
BestValidationF1Score	0.94	0.84	0.92	0.91	0.96	82	8	47	3	0.3
BestValidationMCC	0.94	0.84	0.92	0.91	0.96	82	8	47	3	0.3
BestValidationAccuracy	0.94	0.84	0.92	0.91	0.96	82	8	47	3	0.3
TestPredictions (Threshold:0.3)
CHEMBL105546,TN,INACT,0.009999999776482582	CHEMBL3586394,TP,ACT,0.9900000095367432	CHEMBL1241584,FP,INACT,0.9599999785423279	CHEMBL3109117,TN,INACT,0.009999999776482582	CHEMBL2165269,TP,ACT,0.5	CHEMBL105218,TN,INACT,0.009999999776482582	CHEMBL2089115,FP,INACT,0.7900000214576721	CHEMBL1231371,TN,INACT,0.05999999865889549	CHEMBL1645096,TN,INACT,0.0	CHEMBL3670267,TP,ACT,1.0	CHEMBL3693415,TP,ACT,0.9300000071525574	CHEMBL551442,TP,ACT,0.9900000095367432	CHEMBL511807,TN,INACT,0.009999999776482582	CHEMBL3410672,TP,ACT,0.9900000095367432	CHEMBL3688971,TP,ACT,0.9700000286102295	CHEMBL1774374,TP,ACT,1.0	CHEMBL2172484,FN,ACT,0.25999999046325684	CHEMBL3646619,TP,ACT,0.9900000095367432	CHEMBL2206917,FN,ACT,0.12999999523162842	CHEMBL592461,TP,ACT,0.6800000071525574	CHEMBL3693390,TP,ACT,0.9800000190734863	CHEMBL3600781,FP,INACT,0.5299999713897705	CHEMBL3800448,TN,INACT,0.0	CHEMBL3648885,TP,ACT,1.0	CHEMBL3799345,TN,INACT,0.05999999865889549	CHEMBL2158432,TN,INACT,0.09000000357627869	CHEMBL113,TN,INACT,0.05999999865889549	CHEMBL2159931,TN,INACT,0.0	CHEMBL1201182,TP,ACT,1.0	CHEMBL3645899,TP,ACT,1.0	CHEMBL1945954,TP,ACT,1.0	CHEMBL3754379,TN,INACT,0.0	CHEMBL3643159,TP,ACT,1.0	CHEMBL3701106,TP,ACT,0.5899999737739563	CHEMBL2087474,TP,ACT,1.0	CHEMBL2159726,TN,INACT,0.029999999329447746	CHEMBL3646632,TP,ACT,0.9800000190734863	CHEMBL3648876,TP,ACT,1.0	CHEMBL2172479,TP,ACT,1.0	CHEMBL1728139,TN,INACT,0.0	CHEMBL3600784,FP,INACT,0.4099999964237213	CHEMBL3643251,TP,ACT,0.9399999976158142	CHEMBL3645830,TP,ACT,1.0	CHEMBL2165176,TN,INACT,0.009999999776482582	CHEMBL3645868,TP,ACT,1.0	CHEMBL3814414,TP,ACT,0.3499999940395355	CHEMBL3128210,TN,INACT,0.05000000074505806	CHEMBL538378,TP,ACT,1.0	CHEMBL1762244,FP,INACT,0.47999998927116394	CHEMBL1242474,FP,INACT,0.9900000095367432	CHEMBL209193,TN,INACT,0.05000000074505806	CHEMBL3653640,TP,ACT,1.0	CHEMBL3799956,TN,INACT,0.0	CHEMBL2158428,TN,INACT,0.0	CHEMBL244552,TN,INACT,0.07999999821186066	CHEMBL460137,TN,INACT,0.25	CHEMBL3643077,TP,ACT,1.0	CHEMBL1241389,TN,INACT,0.029999999329447746	CHEMBL469565,TN,INACT,0.009999999776482582	CHEMBL1242378,TN,INACT,0.2199999988079071	CHEMBL57283,FP,INACT,0.4399999976158142	CHEMBL2172632,TP,ACT,0.9800000190734863	CHEMBL3643232,TP,ACT,1.0	CHEMBL3648871,TP,ACT,0.9900000095367432	CHEMBL1093446,TP,ACT,0.5	CHEMBL2172475,TP,ACT,0.9900000095367432	CHEMBL3701070,TP,ACT,0.9599999785423279	CHEMBL1241488,TN,INACT,0.18000000715255737	CHEMBL3681124,TP,ACT,0.9900000095367432	CHEMBL3670189,FN,ACT,0.009999999776482582	CHEMBL3701143,TP,ACT,1.0	CHEMBL3653623,TP,ACT,0.9399999976158142	CHEMBL1255814,TP,ACT,1.0	CHEMBL1916045,TN,INACT,0.11999999731779099	CHEMBL1511858,FP,INACT,0.8299999833106995	CHEMBL1257716,TP,ACT,0.9800000190734863	CHEMBL1241767,TN,INACT,0.009999999776482582	CHEMBL2165182,TN,INACT,0.019999999552965164	CHEMBL3670228,TP,ACT,0.8700000047683716	CHEMBL1242292,TN,INACT,0.019999999552965164	CHEMBL3693430,TP,ACT,0.8999999761581421	CHEMBL3670264,TP,ACT,0.8199999928474426	CHEMBL3645866,TP,ACT,1.0	CHEMBL589142,TP,ACT,0.9900000095367432	CHEMBL565432,TN,INACT,0.0	CHEMBL1092546,TP,ACT,0.9800000190734863	CHEMBL1645095,TN,INACT,0.0	CHEMBL3600769,TN,INACT,0.009999999776482582	CHEMBL1097896,TP,ACT,0.9800000190734863	CHEMBL3109147,FP,INACT,0.9900000095367432	CHEMBL3112721,TP,ACT,1.0	CHEMBL3752335,TN,INACT,0.0	CHEMBL2158444,TN,INACT,0.0	CHEMBL3681126,TP,ACT,1.0	CHEMBL316835,FP,INACT,0.550000011920929	CHEMBL3645790,TP,ACT,1.0	CHEMBL3401245,TN,INACT,0.0	CHEMBL3643113,TP,ACT,1.0	CHEMBL3681152,TP,ACT,1.0	CHEMBL2165194,TN,INACT,0.0	CHEMBL3693407,TP,ACT,0.9900000095367432	CHEMBL2158443,TN,INACT,0.0	CHEMBL1774382,TP,ACT,1.0	CHEMBL3645982,TP,ACT,1.0	CHEMBL568574,TN,INACT,0.029999999329447746	CHEMBL3688994,TP,ACT,1.0	CHEMBL3693495,TP,ACT,0.9900000095367432	CHEMBL1241145,TN,INACT,0.009999999776482582	CHEMBL1946266,TP,ACT,0.9300000071525574	CHEMBL3600785,FP,INACT,0.9800000190734863	CHEMBL2206904,TP,ACT,0.9100000262260437	CHEMBL3681178,TP,ACT,1.0	CHEMBL1774941,TP,ACT,1.0	CHEMBL2158426,TN,INACT,0.009999999776482582	CHEMBL3645800,TP,ACT,1.0	CHEMBL3600766,TN,INACT,0.05999999865889549	CHEMBL3701171,TP,ACT,1.0	CHEMBL1090382,TP,ACT,0.6000000238418579	CHEMBL1241240,TN,INACT,0.18000000715255737	CHEMBL3753949,TN,INACT,0.009999999776482582	CHEMBL3765248,FP,INACT,0.44999998807907104	CHEMBL2064567,TN,INACT,0.10000000149011612	CHEMBL3693429,TP,ACT,1.0	CHEMBL1242574,TP,ACT,0.5099999904632568	CHEMBL3640956,TP,ACT,0.8199999928474426	CHEMBL1090153,TP,ACT,0.6800000071525574	CHEMBL3649439,TP,ACT,0.8600000143051147	CHEMBL3109122,TN,INACT,0.0	CHEMBL3640970,TP,ACT,0.9800000190734863	CHEMBL1098311,TP,ACT,0.8799999952316284	CHEMBL2018263,TN,INACT,0.0	CHEMBL3640931,TP,ACT,0.9399999976158142	CHEMBL3765681,TN,INACT,0.03999999910593033	CHEMBL3693575,TP,ACT,1.0	CHEMBL590325,TP,ACT,0.9100000262260437	CHEMBL3693380,TP,ACT,0.9800000190734863	CHEMBL3688947,TP,ACT,1.0	CHEMBL3643131,TP,ACT,1.0	CHEMBL1242204,TN,INACT,0.009999999776482582	CHEMBL3693489,TP,ACT,0.9900000095367432	

