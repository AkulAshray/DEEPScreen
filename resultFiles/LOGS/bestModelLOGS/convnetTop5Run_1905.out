CNNModel CHEMBL4975 adam 0.001 15 32 0 0.8 False True
Number of active compounds :	599
Number of inactive compounds :	599
---------------------------------
Run id: CNNModel_CHEMBL4975_adam_0.001_15_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4975_adam_0.001_15_32_0.8_True/
---------------------------------
Training samples: 736
Validation samples: 230
--
Training Step: 1  | time: 1.287s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/736
[A[ATraining Step: 2  | total loss: [1m[32m0.62336[0m[0m | time: 2.249s
[2K
| Adam | epoch: 001 | loss: 0.62336 - acc: 0.5062 -- iter: 064/736
[A[ATraining Step: 3  | total loss: [1m[32m0.67848[0m[0m | time: 3.268s
[2K
| Adam | epoch: 001 | loss: 0.67848 - acc: 0.5267 -- iter: 096/736
[A[ATraining Step: 4  | total loss: [1m[32m0.68962[0m[0m | time: 4.349s
[2K
| Adam | epoch: 001 | loss: 0.68962 - acc: 0.5301 -- iter: 128/736
[A[ATraining Step: 5  | total loss: [1m[32m0.69433[0m[0m | time: 5.210s
[2K
| Adam | epoch: 001 | loss: 0.69433 - acc: 0.5093 -- iter: 160/736
[A[ATraining Step: 6  | total loss: [1m[32m0.69246[0m[0m | time: 6.229s
[2K
| Adam | epoch: 001 | loss: 0.69246 - acc: 0.5234 -- iter: 192/736
[A[ATraining Step: 7  | total loss: [1m[32m0.69235[0m[0m | time: 7.322s
[2K
| Adam | epoch: 001 | loss: 0.69235 - acc: 0.5094 -- iter: 224/736
[A[ATraining Step: 8  | total loss: [1m[32m0.69434[0m[0m | time: 8.355s
[2K
| Adam | epoch: 001 | loss: 0.69434 - acc: 0.4514 -- iter: 256/736
[A[ATraining Step: 9  | total loss: [1m[32m0.69430[0m[0m | time: 9.154s
[2K
| Adam | epoch: 001 | loss: 0.69430 - acc: 0.4440 -- iter: 288/736
[A[ATraining Step: 10  | total loss: [1m[32m0.69363[0m[0m | time: 10.114s
[2K
| Adam | epoch: 001 | loss: 0.69363 - acc: 0.4720 -- iter: 320/736
[A[ATraining Step: 11  | total loss: [1m[32m0.69349[0m[0m | time: 11.051s
[2K
| Adam | epoch: 001 | loss: 0.69349 - acc: 0.4557 -- iter: 352/736
[A[ATraining Step: 12  | total loss: [1m[32m0.69307[0m[0m | time: 11.994s
[2K
| Adam | epoch: 001 | loss: 0.69307 - acc: 0.5319 -- iter: 384/736
[A[ATraining Step: 13  | total loss: [1m[32m0.69239[0m[0m | time: 12.936s
[2K
| Adam | epoch: 001 | loss: 0.69239 - acc: 0.5584 -- iter: 416/736
[A[ATraining Step: 14  | total loss: [1m[32m0.69250[0m[0m | time: 13.965s
[2K
| Adam | epoch: 001 | loss: 0.69250 - acc: 0.5473 -- iter: 448/736
[A[ATraining Step: 15  | total loss: [1m[32m0.68863[0m[0m | time: 14.911s
[2K
| Adam | epoch: 001 | loss: 0.68863 - acc: 0.6022 -- iter: 480/736
[A[ATraining Step: 16  | total loss: [1m[32m0.68818[0m[0m | time: 15.766s
[2K
| Adam | epoch: 001 | loss: 0.68818 - acc: 0.5873 -- iter: 512/736
[A[ATraining Step: 17  | total loss: [1m[32m0.68669[0m[0m | time: 16.811s
[2K
| Adam | epoch: 001 | loss: 0.68669 - acc: 0.5784 -- iter: 544/736
[A[ATraining Step: 18  | total loss: [1m[32m0.68387[0m[0m | time: 17.955s
[2K
| Adam | epoch: 001 | loss: 0.68387 - acc: 0.5837 -- iter: 576/736
[A[ATraining Step: 19  | total loss: [1m[32m0.69324[0m[0m | time: 18.878s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.5662 -- iter: 608/736
[A[ATraining Step: 20  | total loss: [1m[32m0.67945[0m[0m | time: 19.770s
[2K
| Adam | epoch: 001 | loss: 0.67945 - acc: 0.5952 -- iter: 640/736
[A[ATraining Step: 21  | total loss: [1m[32m0.67864[0m[0m | time: 20.678s
[2K
| Adam | epoch: 001 | loss: 0.67864 - acc: 0.5947 -- iter: 672/736
[A[ATraining Step: 22  | total loss: [1m[32m0.70071[0m[0m | time: 21.611s
[2K
| Adam | epoch: 001 | loss: 0.70071 - acc: 0.5288 -- iter: 704/736
[A[ATraining Step: 23  | total loss: [1m[32m0.69845[0m[0m | time: 23.985s
[2K
| Adam | epoch: 001 | loss: 0.69845 - acc: 0.5295 | val_loss: 0.69387 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 24  | total loss: [1m[32m0.69651[0m[0m | time: 1.060s
[2K
| Adam | epoch: 002 | loss: 0.69651 - acc: 0.5300 -- iter: 032/736
[A[ATraining Step: 25  | total loss: [1m[32m0.69520[0m[0m | time: 2.078s
[2K
| Adam | epoch: 002 | loss: 0.69520 - acc: 0.5303 -- iter: 064/736
[A[ATraining Step: 26  | total loss: [1m[32m0.69359[0m[0m | time: 2.874s
[2K
| Adam | epoch: 002 | loss: 0.69359 - acc: 0.5389 -- iter: 096/736
[A[ATraining Step: 27  | total loss: [1m[32m0.69265[0m[0m | time: 3.766s
[2K
| Adam | epoch: 002 | loss: 0.69265 - acc: 0.5449 -- iter: 128/736
[A[ATraining Step: 28  | total loss: [1m[32m0.69358[0m[0m | time: 4.680s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.5181 -- iter: 160/736
[A[ATraining Step: 29  | total loss: [1m[32m0.69357[0m[0m | time: 5.624s
[2K
| Adam | epoch: 002 | loss: 0.69357 - acc: 0.5137 -- iter: 192/736
[A[ATraining Step: 30  | total loss: [1m[32m0.69271[0m[0m | time: 6.538s
[2K
| Adam | epoch: 002 | loss: 0.69271 - acc: 0.5326 -- iter: 224/736
[A[ATraining Step: 31  | total loss: [1m[32m0.69265[0m[0m | time: 7.582s
[2K
| Adam | epoch: 002 | loss: 0.69265 - acc: 0.5323 -- iter: 256/736
[A[ATraining Step: 32  | total loss: [1m[32m0.69276[0m[0m | time: 8.630s
[2K
| Adam | epoch: 002 | loss: 0.69276 - acc: 0.5250 -- iter: 288/736
[A[ATraining Step: 33  | total loss: [1m[32m0.69372[0m[0m | time: 9.446s
[2K
| Adam | epoch: 002 | loss: 0.69372 - acc: 0.4921 -- iter: 320/736
[A[ATraining Step: 34  | total loss: [1m[32m0.69360[0m[0m | time: 10.345s
[2K
| Adam | epoch: 002 | loss: 0.69360 - acc: 0.4938 -- iter: 352/736
[A[ATraining Step: 35  | total loss: [1m[32m0.69307[0m[0m | time: 11.275s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5147 -- iter: 384/736
[A[ATraining Step: 36  | total loss: [1m[32m0.69350[0m[0m | time: 12.304s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.4925 -- iter: 416/736
[A[ATraining Step: 37  | total loss: [1m[32m0.69367[0m[0m | time: 13.210s
[2K
| Adam | epoch: 002 | loss: 0.69367 - acc: 0.4815 -- iter: 448/736
[A[ATraining Step: 38  | total loss: [1m[32m0.69367[0m[0m | time: 14.232s
[2K
| Adam | epoch: 002 | loss: 0.69367 - acc: 0.4790 -- iter: 480/736
[A[ATraining Step: 39  | total loss: [1m[32m0.69333[0m[0m | time: 15.320s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.5010 -- iter: 512/736
[A[ATraining Step: 40  | total loss: [1m[32m0.69325[0m[0m | time: 16.433s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5008 -- iter: 544/736
[A[ATraining Step: 41  | total loss: [1m[32m0.69322[0m[0m | time: 17.244s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5007 -- iter: 576/736
[A[ATraining Step: 42  | total loss: [1m[32m0.69342[0m[0m | time: 18.154s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4837 -- iter: 608/736
[A[ATraining Step: 43  | total loss: [1m[32m0.69324[0m[0m | time: 19.054s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.5031 -- iter: 640/736
[A[ATraining Step: 44  | total loss: [1m[32m0.69331[0m[0m | time: 19.994s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4863 -- iter: 672/736
[A[ATraining Step: 45  | total loss: [1m[32m0.69327[0m[0m | time: 21.034s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4940 -- iter: 704/736
[A[ATraining Step: 46  | total loss: [1m[32m0.69326[0m[0m | time: 23.184s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4950 | val_loss: 0.69314 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 47  | total loss: [1m[32m0.69328[0m[0m | time: 1.157s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.4753 -- iter: 032/736
[A[ATraining Step: 48  | total loss: [1m[32m0.69328[0m[0m | time: 2.070s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.4693 -- iter: 064/736
[A[ATraining Step: 49  | total loss: [1m[32m0.69328[0m[0m | time: 2.935s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.4642 -- iter: 096/736
[A[ATraining Step: 50  | total loss: [1m[32m0.69327[0m[0m | time: 3.890s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.4698 -- iter: 128/736
[A[ATraining Step: 51  | total loss: [1m[32m0.69315[0m[0m | time: 4.858s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5078 -- iter: 160/736
[A[ATraining Step: 52  | total loss: [1m[32m0.69309[0m[0m | time: 5.787s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5160 -- iter: 192/736
[A[ATraining Step: 53  | total loss: [1m[32m0.69310[0m[0m | time: 6.826s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5136 -- iter: 224/736
[A[ATraining Step: 54  | total loss: [1m[32m0.69263[0m[0m | time: 7.872s
[2K
| Adam | epoch: 003 | loss: 0.69263 - acc: 0.5434 -- iter: 256/736
[A[ATraining Step: 55  | total loss: [1m[32m0.69287[0m[0m | time: 8.651s
[2K
| Adam | epoch: 003 | loss: 0.69287 - acc: 0.5283 -- iter: 288/736
[A[ATraining Step: 56  | total loss: [1m[32m0.69271[0m[0m | time: 9.739s
[2K
| Adam | epoch: 003 | loss: 0.69271 - acc: 0.5331 -- iter: 320/736
[A[ATraining Step: 57  | total loss: [1m[32m0.69268[0m[0m | time: 10.830s
[2K
| Adam | epoch: 003 | loss: 0.69268 - acc: 0.5328 -- iter: 352/736
[A[ATraining Step: 58  | total loss: [1m[32m0.69296[0m[0m | time: 11.808s
[2K
| Adam | epoch: 003 | loss: 0.69296 - acc: 0.5198 -- iter: 384/736
[A[ATraining Step: 59  | total loss: [1m[32m0.69303[0m[0m | time: 12.693s
[2K
| Adam | epoch: 003 | loss: 0.69303 - acc: 0.5172 -- iter: 416/736
[A[ATraining Step: 60  | total loss: [1m[32m0.69292[0m[0m | time: 13.600s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5190 -- iter: 448/736
[A[ATraining Step: 61  | total loss: [1m[32m0.69298[0m[0m | time: 14.557s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5165 -- iter: 480/736
[A[ATraining Step: 62  | total loss: [1m[32m0.69240[0m[0m | time: 15.490s
[2K
| Adam | epoch: 003 | loss: 0.69240 - acc: 0.5305 -- iter: 512/736
[A[ATraining Step: 63  | total loss: [1m[32m0.69285[0m[0m | time: 16.611s
[2K
| Adam | epoch: 003 | loss: 0.69285 - acc: 0.5187 -- iter: 544/736
[A[ATraining Step: 64  | total loss: [1m[32m0.69206[0m[0m | time: 17.578s
[2K
| Adam | epoch: 003 | loss: 0.69206 - acc: 0.5359 -- iter: 576/736
[A[ATraining Step: 65  | total loss: [1m[32m0.69329[0m[0m | time: 18.419s
[2K
| Adam | epoch: 003 | loss: 0.69329 - acc: 0.5084 -- iter: 608/736
[A[ATraining Step: 66  | total loss: [1m[32m0.69352[0m[0m | time: 19.532s
[2K
| Adam | epoch: 003 | loss: 0.69352 - acc: 0.5035 -- iter: 640/736
[A[ATraining Step: 67  | total loss: [1m[32m0.69330[0m[0m | time: 20.634s
[2K
| Adam | epoch: 003 | loss: 0.69330 - acc: 0.5069 -- iter: 672/736
[A[ATraining Step: 68  | total loss: [1m[32m0.69332[0m[0m | time: 21.513s
[2K
| Adam | epoch: 003 | loss: 0.69332 - acc: 0.5061 -- iter: 704/736
[A[ATraining Step: 69  | total loss: [1m[32m0.69437[0m[0m | time: 23.425s
[2K
| Adam | epoch: 003 | loss: 0.69437 - acc: 0.4834 | val_loss: 0.69319 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 70  | total loss: [1m[32m0.69408[0m[0m | time: 1.014s
[2K
| Adam | epoch: 004 | loss: 0.69408 - acc: 0.4889 -- iter: 032/736
[A[ATraining Step: 71  | total loss: [1m[32m0.69386[0m[0m | time: 2.029s
[2K
| Adam | epoch: 004 | loss: 0.69386 - acc: 0.4938 -- iter: 064/736
[A[ATraining Step: 72  | total loss: [1m[32m0.69350[0m[0m | time: 2.968s
[2K
| Adam | epoch: 004 | loss: 0.69350 - acc: 0.5015 -- iter: 096/736
[A[ATraining Step: 73  | total loss: [1m[32m0.69319[0m[0m | time: 3.907s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.5083 -- iter: 128/736
[A[ATraining Step: 74  | total loss: [1m[32m0.69216[0m[0m | time: 4.977s
[2K
| Adam | epoch: 004 | loss: 0.69216 - acc: 0.5314 -- iter: 160/736
[A[ATraining Step: 75  | total loss: [1m[32m0.69213[0m[0m | time: 6.052s
[2K
| Adam | epoch: 004 | loss: 0.69213 - acc: 0.5314 -- iter: 192/736
[A[ATraining Step: 76  | total loss: [1m[32m0.69227[0m[0m | time: 6.859s
[2K
| Adam | epoch: 004 | loss: 0.69227 - acc: 0.5280 -- iter: 224/736
[A[ATraining Step: 77  | total loss: [1m[32m0.69175[0m[0m | time: 7.758s
[2K
| Adam | epoch: 004 | loss: 0.69175 - acc: 0.5383 -- iter: 256/736
[A[ATraining Step: 78  | total loss: [1m[32m0.69246[0m[0m | time: 8.674s
[2K
| Adam | epoch: 004 | loss: 0.69246 - acc: 0.5245 -- iter: 288/736
[A[ATraining Step: 79  | total loss: [1m[32m0.69288[0m[0m | time: 9.608s
[2K
| Adam | epoch: 004 | loss: 0.69288 - acc: 0.5155 -- iter: 320/736
[A[ATraining Step: 80  | total loss: [1m[32m0.69279[0m[0m | time: 10.620s
[2K
| Adam | epoch: 004 | loss: 0.69279 - acc: 0.5171 -- iter: 352/736
[A[ATraining Step: 81  | total loss: [1m[32m0.69217[0m[0m | time: 11.715s
[2K
| Adam | epoch: 004 | loss: 0.69217 - acc: 0.5280 -- iter: 384/736
[A[ATraining Step: 82  | total loss: [1m[32m0.69178[0m[0m | time: 12.643s
[2K
| Adam | epoch: 004 | loss: 0.69178 - acc: 0.5346 -- iter: 416/736
[A[ATraining Step: 83  | total loss: [1m[32m0.69107[0m[0m | time: 13.574s
[2K
| Adam | epoch: 004 | loss: 0.69107 - acc: 0.5467 -- iter: 448/736
[A[ATraining Step: 84  | total loss: [1m[32m0.69094[0m[0m | time: 14.605s
[2K
| Adam | epoch: 004 | loss: 0.69094 - acc: 0.5483 -- iter: 480/736
[A[ATraining Step: 85  | total loss: [1m[32m0.69098[0m[0m | time: 15.638s
[2K
| Adam | epoch: 004 | loss: 0.69098 - acc: 0.5466 -- iter: 512/736
[A[ATraining Step: 86  | total loss: [1m[32m0.69192[0m[0m | time: 16.738s
[2K
| Adam | epoch: 004 | loss: 0.69192 - acc: 0.5326 -- iter: 544/736
[A[ATraining Step: 87  | total loss: [1m[32m0.69234[0m[0m | time: 17.801s
[2K
| Adam | epoch: 004 | loss: 0.69234 - acc: 0.5262 -- iter: 576/736
[A[ATraining Step: 88  | total loss: [1m[32m0.69277[0m[0m | time: 18.755s
[2K
| Adam | epoch: 004 | loss: 0.69277 - acc: 0.5204 -- iter: 608/736
[A[ATraining Step: 89  | total loss: [1m[32m0.69218[0m[0m | time: 19.697s
[2K
| Adam | epoch: 004 | loss: 0.69218 - acc: 0.5278 -- iter: 640/736
[A[ATraining Step: 90  | total loss: [1m[32m0.69257[0m[0m | time: 20.727s
[2K
| Adam | epoch: 004 | loss: 0.69257 - acc: 0.5219 -- iter: 672/736
[A[ATraining Step: 91  | total loss: [1m[32m0.69266[0m[0m | time: 21.779s
[2K
| Adam | epoch: 004 | loss: 0.69266 - acc: 0.5197 -- iter: 704/736
[A[ATraining Step: 92  | total loss: [1m[32m0.69438[0m[0m | time: 23.489s
[2K
| Adam | epoch: 004 | loss: 0.69438 - acc: 0.4958 | val_loss: 0.69345 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 93  | total loss: [1m[32m0.69338[0m[0m | time: 0.621s
[2K
| Adam | epoch: 005 | loss: 0.69338 - acc: 0.5088 -- iter: 032/736
[A[ATraining Step: 94  | total loss: [1m[32m0.69382[0m[0m | time: 1.268s
[2K
| Adam | epoch: 005 | loss: 0.69382 - acc: 0.5016 -- iter: 064/736
[A[ATraining Step: 95  | total loss: [1m[32m0.69403[0m[0m | time: 1.890s
[2K
| Adam | epoch: 005 | loss: 0.69403 - acc: 0.4983 -- iter: 096/736
[A[ATraining Step: 96  | total loss: [1m[32m0.69379[0m[0m | time: 2.528s
[2K
| Adam | epoch: 005 | loss: 0.69379 - acc: 0.5016 -- iter: 128/736
[A[ATraining Step: 97  | total loss: [1m[32m0.69354[0m[0m | time: 3.148s
[2K
| Adam | epoch: 005 | loss: 0.69354 - acc: 0.5046 -- iter: 160/736
[A[ATraining Step: 98  | total loss: [1m[32m0.69256[0m[0m | time: 3.795s
[2K
| Adam | epoch: 005 | loss: 0.69256 - acc: 0.5198 -- iter: 192/736
[A[ATraining Step: 99  | total loss: [1m[32m0.69167[0m[0m | time: 4.427s
[2K
| Adam | epoch: 005 | loss: 0.69167 - acc: 0.5334 -- iter: 224/736
[A[ATraining Step: 100  | total loss: [1m[32m0.69107[0m[0m | time: 5.065s
[2K
| Adam | epoch: 005 | loss: 0.69107 - acc: 0.5426 -- iter: 256/736
[A[ATraining Step: 101  | total loss: [1m[32m0.69068[0m[0m | time: 5.670s
[2K
| Adam | epoch: 005 | loss: 0.69068 - acc: 0.5477 -- iter: 288/736
[A[ATraining Step: 102  | total loss: [1m[32m0.69189[0m[0m | time: 6.282s
[2K
| Adam | epoch: 005 | loss: 0.69189 - acc: 0.5304 -- iter: 320/736
[A[ATraining Step: 103  | total loss: [1m[32m0.69255[0m[0m | time: 6.910s
[2K
| Adam | epoch: 005 | loss: 0.69255 - acc: 0.5211 -- iter: 352/736
[A[ATraining Step: 104  | total loss: [1m[32m0.69195[0m[0m | time: 7.541s
[2K
| Adam | epoch: 005 | loss: 0.69195 - acc: 0.5284 -- iter: 384/736
[A[ATraining Step: 105  | total loss: [1m[32m0.69166[0m[0m | time: 8.155s
[2K
| Adam | epoch: 005 | loss: 0.69166 - acc: 0.5318 -- iter: 416/736
[A[ATraining Step: 106  | total loss: [1m[32m0.69188[0m[0m | time: 8.762s
[2K
| Adam | epoch: 005 | loss: 0.69188 - acc: 0.5286 -- iter: 448/736
[A[ATraining Step: 107  | total loss: [1m[32m0.69110[0m[0m | time: 9.383s
[2K
| Adam | epoch: 005 | loss: 0.69110 - acc: 0.5383 -- iter: 480/736
[A[ATraining Step: 108  | total loss: [1m[32m0.69016[0m[0m | time: 10.021s
[2K
| Adam | epoch: 005 | loss: 0.69016 - acc: 0.5501 -- iter: 512/736
[A[ATraining Step: 109  | total loss: [1m[32m0.69107[0m[0m | time: 10.640s
[2K
| Adam | epoch: 005 | loss: 0.69107 - acc: 0.5388 -- iter: 544/736
[A[ATraining Step: 110  | total loss: [1m[32m0.69160[0m[0m | time: 11.292s
[2K
| Adam | epoch: 005 | loss: 0.69160 - acc: 0.5318 -- iter: 576/736
[A[ATraining Step: 111  | total loss: [1m[32m0.69236[0m[0m | time: 11.911s
[2K
| Adam | epoch: 005 | loss: 0.69236 - acc: 0.5224 -- iter: 608/736
[A[ATraining Step: 112  | total loss: [1m[32m0.69279[0m[0m | time: 12.537s
[2K
| Adam | epoch: 005 | loss: 0.69279 - acc: 0.5170 -- iter: 640/736
[A[ATraining Step: 113  | total loss: [1m[32m0.69401[0m[0m | time: 13.150s
[2K
| Adam | epoch: 005 | loss: 0.69401 - acc: 0.5028 -- iter: 672/736
[A[ATraining Step: 114  | total loss: [1m[32m0.69370[0m[0m | time: 13.772s
[2K
| Adam | epoch: 005 | loss: 0.69370 - acc: 0.5056 -- iter: 704/736
[A[ATraining Step: 115  | total loss: [1m[32m0.69349[0m[0m | time: 15.665s
[2K
| Adam | epoch: 005 | loss: 0.69349 - acc: 0.5082 | val_loss: 0.69359 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 116  | total loss: [1m[32m0.69376[0m[0m | time: 0.828s
[2K
| Adam | epoch: 006 | loss: 0.69376 - acc: 0.5043 -- iter: 032/736
[A[ATraining Step: 117  | total loss: [1m[32m0.69400[0m[0m | time: 1.734s
[2K
| Adam | epoch: 006 | loss: 0.69400 - acc: 0.5007 -- iter: 064/736
[A[ATraining Step: 118  | total loss: [1m[32m0.69419[0m[0m | time: 2.757s
[2K
| Adam | epoch: 006 | loss: 0.69419 - acc: 0.4975 -- iter: 096/736
[A[ATraining Step: 119  | total loss: [1m[32m0.69416[0m[0m | time: 3.680s
[2K
| Adam | epoch: 006 | loss: 0.69416 - acc: 0.4978 -- iter: 128/736
[A[ATraining Step: 120  | total loss: [1m[32m0.69503[0m[0m | time: 4.641s
[2K
| Adam | epoch: 006 | loss: 0.69503 - acc: 0.4855 -- iter: 160/736
[A[ATraining Step: 121  | total loss: [1m[32m0.69582[0m[0m | time: 5.712s
[2K
| Adam | epoch: 006 | loss: 0.69582 - acc: 0.4744 -- iter: 192/736
[A[ATraining Step: 122  | total loss: [1m[32m0.69560[0m[0m | time: 6.618s
[2K
| Adam | epoch: 006 | loss: 0.69560 - acc: 0.4770 -- iter: 224/736
[A[ATraining Step: 123  | total loss: [1m[32m0.69501[0m[0m | time: 7.610s
[2K
| Adam | epoch: 006 | loss: 0.69501 - acc: 0.4855 -- iter: 256/736
[A[ATraining Step: 124  | total loss: [1m[32m0.69542[0m[0m | time: 8.707s
[2K
| Adam | epoch: 006 | loss: 0.69542 - acc: 0.4776 -- iter: 288/736
[A[ATraining Step: 125  | total loss: [1m[32m0.69434[0m[0m | time: 9.780s
[2K
| Adam | epoch: 006 | loss: 0.69434 - acc: 0.4955 -- iter: 320/736
[A[ATraining Step: 126  | total loss: [1m[32m0.69427[0m[0m | time: 10.580s
[2K
| Adam | epoch: 006 | loss: 0.69427 - acc: 0.4959 -- iter: 352/736
[A[ATraining Step: 127  | total loss: [1m[32m0.69422[0m[0m | time: 11.576s
[2K
| Adam | epoch: 006 | loss: 0.69422 - acc: 0.4963 -- iter: 384/736
[A[ATraining Step: 128  | total loss: [1m[32m0.69354[0m[0m | time: 12.537s
[2K
| Adam | epoch: 006 | loss: 0.69354 - acc: 0.5092 -- iter: 416/736
[A[ATraining Step: 129  | total loss: [1m[32m0.69279[0m[0m | time: 13.491s
[2K
| Adam | epoch: 006 | loss: 0.69279 - acc: 0.5239 -- iter: 448/736
[A[ATraining Step: 130  | total loss: [1m[32m0.69286[0m[0m | time: 14.545s
[2K
| Adam | epoch: 006 | loss: 0.69286 - acc: 0.5215 -- iter: 480/736
[A[ATraining Step: 131  | total loss: [1m[32m0.69183[0m[0m | time: 15.697s
[2K
| Adam | epoch: 006 | loss: 0.69183 - acc: 0.5412 -- iter: 512/736
[A[ATraining Step: 132  | total loss: [1m[32m0.69167[0m[0m | time: 16.550s
[2K
| Adam | epoch: 006 | loss: 0.69167 - acc: 0.5434 -- iter: 544/736
[A[ATraining Step: 133  | total loss: [1m[32m0.69172[0m[0m | time: 17.537s
[2K
| Adam | epoch: 006 | loss: 0.69172 - acc: 0.5422 -- iter: 576/736
[A[ATraining Step: 134  | total loss: [1m[32m0.69172[0m[0m | time: 18.582s
[2K
| Adam | epoch: 006 | loss: 0.69172 - acc: 0.5411 -- iter: 608/736
[A[ATraining Step: 135  | total loss: [1m[32m0.69151[0m[0m | time: 19.601s
[2K
| Adam | epoch: 006 | loss: 0.69151 - acc: 0.5432 -- iter: 640/736
[A[ATraining Step: 136  | total loss: [1m[32m0.69230[0m[0m | time: 20.417s
[2K
| Adam | epoch: 006 | loss: 0.69230 - acc: 0.5295 -- iter: 672/736
[A[ATraining Step: 137  | total loss: [1m[32m0.69224[0m[0m | time: 21.324s
[2K
| Adam | epoch: 006 | loss: 0.69224 - acc: 0.5297 -- iter: 704/736
[A[ATraining Step: 138  | total loss: [1m[32m0.69221[0m[0m | time: 23.382s
[2K
| Adam | epoch: 006 | loss: 0.69221 - acc: 0.5298 | val_loss: 0.69335 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 139  | total loss: [1m[32m0.69331[0m[0m | time: 0.969s
[2K
| Adam | epoch: 007 | loss: 0.69331 - acc: 0.5112 -- iter: 032/736
[A[ATraining Step: 140  | total loss: [1m[32m0.69390[0m[0m | time: 1.808s
[2K
| Adam | epoch: 007 | loss: 0.69390 - acc: 0.5007 -- iter: 064/736
[A[ATraining Step: 141  | total loss: [1m[32m0.69500[0m[0m | time: 2.914s
[2K
| Adam | epoch: 007 | loss: 0.69500 - acc: 0.4819 -- iter: 096/736
[A[ATraining Step: 142  | total loss: [1m[32m0.69468[0m[0m | time: 4.011s
[2K
| Adam | epoch: 007 | loss: 0.69468 - acc: 0.4868 -- iter: 128/736
[A[ATraining Step: 143  | total loss: [1m[32m0.69420[0m[0m | time: 4.938s
[2K
| Adam | epoch: 007 | loss: 0.69420 - acc: 0.4944 -- iter: 160/736
[A[ATraining Step: 144  | total loss: [1m[32m0.69397[0m[0m | time: 5.819s
[2K
| Adam | epoch: 007 | loss: 0.69397 - acc: 0.4981 -- iter: 192/736
[A[ATraining Step: 145  | total loss: [1m[32m0.69374[0m[0m | time: 6.740s
[2K
| Adam | epoch: 007 | loss: 0.69374 - acc: 0.5014 -- iter: 224/736
[A[ATraining Step: 146  | total loss: [1m[32m0.69341[0m[0m | time: 7.686s
[2K
| Adam | epoch: 007 | loss: 0.69341 - acc: 0.5075 -- iter: 256/736
[A[ATraining Step: 147  | total loss: [1m[32m0.69404[0m[0m | time: 8.681s
[2K
| Adam | epoch: 007 | loss: 0.69404 - acc: 0.4943 -- iter: 288/736
[A[ATraining Step: 148  | total loss: [1m[32m0.69321[0m[0m | time: 9.695s
[2K
| Adam | epoch: 007 | loss: 0.69321 - acc: 0.5105 -- iter: 320/736
[A[ATraining Step: 149  | total loss: [1m[32m0.69262[0m[0m | time: 10.757s
[2K
| Adam | epoch: 007 | loss: 0.69262 - acc: 0.5219 -- iter: 352/736
[A[ATraining Step: 150  | total loss: [1m[32m0.69210[0m[0m | time: 11.631s
[2K
| Adam | epoch: 007 | loss: 0.69210 - acc: 0.5322 -- iter: 384/736
[A[ATraining Step: 151  | total loss: [1m[32m0.69233[0m[0m | time: 12.738s
[2K
| Adam | epoch: 007 | loss: 0.69233 - acc: 0.5259 -- iter: 416/736
[A[ATraining Step: 152  | total loss: [1m[32m0.69212[0m[0m | time: 13.783s
[2K
| Adam | epoch: 007 | loss: 0.69212 - acc: 0.5295 -- iter: 448/736
[A[ATraining Step: 153  | total loss: [1m[32m0.69112[0m[0m | time: 14.698s
[2K
| Adam | epoch: 007 | loss: 0.69112 - acc: 0.5485 -- iter: 480/736
[A[ATraining Step: 154  | total loss: [1m[32m0.69136[0m[0m | time: 15.578s
[2K
| Adam | epoch: 007 | loss: 0.69136 - acc: 0.5436 -- iter: 512/736
[A[ATraining Step: 155  | total loss: [1m[32m0.69100[0m[0m | time: 16.516s
[2K
| Adam | epoch: 007 | loss: 0.69100 - acc: 0.5486 -- iter: 544/736
[A[ATraining Step: 156  | total loss: [1m[32m0.69125[0m[0m | time: 17.529s
[2K
| Adam | epoch: 007 | loss: 0.69125 - acc: 0.5438 -- iter: 576/736
[A[ATraining Step: 157  | total loss: [1m[32m0.69111[0m[0m | time: 18.444s
[2K
| Adam | epoch: 007 | loss: 0.69111 - acc: 0.5456 -- iter: 608/736
[A[ATraining Step: 158  | total loss: [1m[32m0.69124[0m[0m | time: 19.467s
[2K
| Adam | epoch: 007 | loss: 0.69124 - acc: 0.5442 -- iter: 640/736
[A[ATraining Step: 159  | total loss: [1m[32m0.69105[0m[0m | time: 20.482s
[2K
| Adam | epoch: 007 | loss: 0.69105 - acc: 0.5460 -- iter: 672/736
[A[ATraining Step: 160  | total loss: [1m[32m0.69153[0m[0m | time: 21.338s
[2K
| Adam | epoch: 007 | loss: 0.69153 - acc: 0.5383 -- iter: 704/736
[A[ATraining Step: 161  | total loss: [1m[32m0.69135[0m[0m | time: 23.686s
[2K
| Adam | epoch: 007 | loss: 0.69135 - acc: 0.5407 | val_loss: 0.69350 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 162  | total loss: [1m[32m0.69296[0m[0m | time: 0.904s
[2K
| Adam | epoch: 008 | loss: 0.69296 - acc: 0.5179 -- iter: 032/736
[A[ATraining Step: 163  | total loss: [1m[32m0.69192[0m[0m | time: 1.861s
[2K
| Adam | epoch: 008 | loss: 0.69192 - acc: 0.5317 -- iter: 064/736
[A[ATraining Step: 164  | total loss: [1m[32m0.69114[0m[0m | time: 2.852s
[2K
| Adam | epoch: 008 | loss: 0.69114 - acc: 0.5411 -- iter: 096/736
[A[ATraining Step: 165  | total loss: [1m[32m0.69168[0m[0m | time: 3.851s
[2K
| Adam | epoch: 008 | loss: 0.69168 - acc: 0.5338 -- iter: 128/736
[A[ATraining Step: 166  | total loss: [1m[32m0.69166[0m[0m | time: 4.905s
[2K
| Adam | epoch: 008 | loss: 0.69166 - acc: 0.5336 -- iter: 160/736
[A[ATraining Step: 167  | total loss: [1m[32m0.69211[0m[0m | time: 5.839s
[2K
| Adam | epoch: 008 | loss: 0.69211 - acc: 0.5271 -- iter: 192/736
[A[ATraining Step: 168  | total loss: [1m[32m0.69178[0m[0m | time: 6.817s
[2K
| Adam | epoch: 008 | loss: 0.69178 - acc: 0.5306 -- iter: 224/736
[A[ATraining Step: 169  | total loss: [1m[32m0.69153[0m[0m | time: 7.867s
[2K
| Adam | epoch: 008 | loss: 0.69153 - acc: 0.5338 -- iter: 256/736
[A[ATraining Step: 170  | total loss: [1m[32m0.69199[0m[0m | time: 8.908s
[2K
| Adam | epoch: 008 | loss: 0.69199 - acc: 0.5273 -- iter: 288/736
[A[ATraining Step: 171  | total loss: [1m[32m0.69138[0m[0m | time: 9.689s
[2K
| Adam | epoch: 008 | loss: 0.69138 - acc: 0.5340 -- iter: 320/736
[A[ATraining Step: 172  | total loss: [1m[32m0.69007[0m[0m | time: 10.582s
[2K
| Adam | epoch: 008 | loss: 0.69007 - acc: 0.5493 -- iter: 352/736
[A[ATraining Step: 173  | total loss: [1m[32m0.68934[0m[0m | time: 11.521s
[2K
| Adam | epoch: 008 | loss: 0.68934 - acc: 0.5569 -- iter: 384/736
[A[ATraining Step: 174  | total loss: [1m[32m0.68950[0m[0m | time: 12.457s
[2K
| Adam | epoch: 008 | loss: 0.68950 - acc: 0.5543 -- iter: 416/736
[A[ATraining Step: 175  | total loss: [1m[32m0.69060[0m[0m | time: 13.390s
[2K
| Adam | epoch: 008 | loss: 0.69060 - acc: 0.5426 -- iter: 448/736
[A[ATraining Step: 176  | total loss: [1m[32m0.68996[0m[0m | time: 14.490s
[2K
| Adam | epoch: 008 | loss: 0.68996 - acc: 0.5477 -- iter: 480/736
[A[ATraining Step: 177  | total loss: [1m[32m0.69069[0m[0m | time: 15.445s
[2K
| Adam | epoch: 008 | loss: 0.69069 - acc: 0.5398 -- iter: 512/736
[A[ATraining Step: 178  | total loss: [1m[32m0.69236[0m[0m | time: 16.363s
[2K
| Adam | epoch: 008 | loss: 0.69236 - acc: 0.5234 -- iter: 544/736
[A[ATraining Step: 179  | total loss: [1m[32m0.69257[0m[0m | time: 17.426s
[2K
| Adam | epoch: 008 | loss: 0.69257 - acc: 0.5210 -- iter: 576/736
[A[ATraining Step: 180  | total loss: [1m[32m0.69337[0m[0m | time: 18.456s
[2K
| Adam | epoch: 008 | loss: 0.69337 - acc: 0.5127 -- iter: 608/736
[A[ATraining Step: 181  | total loss: [1m[32m0.69284[0m[0m | time: 19.318s
[2K
| Adam | epoch: 008 | loss: 0.69284 - acc: 0.5177 -- iter: 640/736
[A[ATraining Step: 182  | total loss: [1m[32m0.69301[0m[0m | time: 20.227s
[2K
| Adam | epoch: 008 | loss: 0.69301 - acc: 0.5159 -- iter: 672/736
[A[ATraining Step: 183  | total loss: [1m[32m0.69244[0m[0m | time: 21.223s
[2K
| Adam | epoch: 008 | loss: 0.69244 - acc: 0.5206 -- iter: 704/736
[A[ATraining Step: 184  | total loss: [1m[32m0.69362[0m[0m | time: 23.345s
[2K
| Adam | epoch: 008 | loss: 0.69362 - acc: 0.5091 | val_loss: 0.69385 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 185  | total loss: [1m[32m0.69338[0m[0m | time: 0.936s
[2K
| Adam | epoch: 009 | loss: 0.69338 - acc: 0.5113 -- iter: 032/736
[A[ATraining Step: 186  | total loss: [1m[32m0.69228[0m[0m | time: 1.975s
[2K
| Adam | epoch: 009 | loss: 0.69228 - acc: 0.5227 -- iter: 064/736
[A[ATraining Step: 187  | total loss: [1m[32m0.69219[0m[0m | time: 3.104s
[2K
| Adam | epoch: 009 | loss: 0.69219 - acc: 0.5236 -- iter: 096/736
[A[ATraining Step: 188  | total loss: [1m[32m0.69278[0m[0m | time: 4.093s
[2K
| Adam | epoch: 009 | loss: 0.69278 - acc: 0.5181 -- iter: 128/736
[A[ATraining Step: 189  | total loss: [1m[32m0.69266[0m[0m | time: 4.950s
[2K
| Adam | epoch: 009 | loss: 0.69266 - acc: 0.5194 -- iter: 160/736
[A[ATraining Step: 190  | total loss: [1m[32m0.69339[0m[0m | time: 5.863s
[2K
| Adam | epoch: 009 | loss: 0.69339 - acc: 0.5112 -- iter: 192/736
[A[ATraining Step: 191  | total loss: [1m[32m0.69257[0m[0m | time: 6.811s
[2K
| Adam | epoch: 009 | loss: 0.69257 - acc: 0.5195 -- iter: 224/736
[A[ATraining Step: 192  | total loss: [1m[32m0.69248[0m[0m | time: 7.768s
[2K
| Adam | epoch: 009 | loss: 0.69248 - acc: 0.5206 -- iter: 256/736
[A[ATraining Step: 193  | total loss: [1m[32m0.69239[0m[0m | time: 8.829s
[2K
| Adam | epoch: 009 | loss: 0.69239 - acc: 0.5217 -- iter: 288/736
[A[ATraining Step: 194  | total loss: [1m[32m0.69192[0m[0m | time: 9.970s
[2K
| Adam | epoch: 009 | loss: 0.69192 - acc: 0.5258 -- iter: 320/736
[A[ATraining Step: 195  | total loss: [1m[32m0.69239[0m[0m | time: 10.865s
[2K
| Adam | epoch: 009 | loss: 0.69239 - acc: 0.5201 -- iter: 352/736
[A[ATraining Step: 196  | total loss: [1m[32m0.69348[0m[0m | time: 11.906s
[2K
| Adam | epoch: 009 | loss: 0.69348 - acc: 0.5087 -- iter: 384/736
[A[ATraining Step: 197  | total loss: [1m[32m0.69184[0m[0m | time: 12.993s
[2K
| Adam | epoch: 009 | loss: 0.69184 - acc: 0.5266 -- iter: 416/736
[A[ATraining Step: 198  | total loss: [1m[32m0.69263[0m[0m | time: 14.029s
[2K
| Adam | epoch: 009 | loss: 0.69263 - acc: 0.5177 -- iter: 448/736
[A[ATraining Step: 199  | total loss: [1m[32m0.69241[0m[0m | time: 14.818s
[2K
| Adam | epoch: 009 | loss: 0.69241 - acc: 0.5190 -- iter: 480/736
[A[ATraining Step: 200  | total loss: [1m[32m0.69048[0m[0m | time: 16.848s
[2K
| Adam | epoch: 009 | loss: 0.69048 - acc: 0.5390 | val_loss: 0.69378 - val_acc: 0.5043 -- iter: 512/736
--
Training Step: 201  | total loss: [1m[32m0.69023[0m[0m | time: 17.856s
[2K
| Adam | epoch: 009 | loss: 0.69023 - acc: 0.5413 -- iter: 544/736
[A[ATraining Step: 202  | total loss: [1m[32m0.69028[0m[0m | time: 18.910s
[2K
| Adam | epoch: 009 | loss: 0.69028 - acc: 0.5403 -- iter: 576/736
[A[ATraining Step: 203  | total loss: [1m[32m0.69205[0m[0m | time: 19.849s
[2K
| Adam | epoch: 009 | loss: 0.69205 - acc: 0.5238 -- iter: 608/736
[A[ATraining Step: 204  | total loss: [1m[32m0.69369[0m[0m | time: 20.789s
[2K
| Adam | epoch: 009 | loss: 0.69369 - acc: 0.5089 -- iter: 640/736
[A[ATraining Step: 205  | total loss: [1m[32m0.69398[0m[0m | time: 21.829s
[2K
| Adam | epoch: 009 | loss: 0.69398 - acc: 0.5049 -- iter: 672/736
[A[ATraining Step: 206  | total loss: [1m[32m0.69274[0m[0m | time: 22.683s
[2K
| Adam | epoch: 009 | loss: 0.69274 - acc: 0.5169 -- iter: 704/736
[A[ATraining Step: 207  | total loss: [1m[32m0.69195[0m[0m | time: 24.613s
[2K
| Adam | epoch: 009 | loss: 0.69195 - acc: 0.5246 | val_loss: 0.69350 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 208  | total loss: [1m[32m0.69272[0m[0m | time: 0.933s
[2K
| Adam | epoch: 010 | loss: 0.69272 - acc: 0.5159 -- iter: 032/736
[A[ATraining Step: 209  | total loss: [1m[32m0.69460[0m[0m | time: 1.939s
[2K
| Adam | epoch: 010 | loss: 0.69460 - acc: 0.4956 -- iter: 064/736
[A[ATraining Step: 210  | total loss: [1m[32m0.69339[0m[0m | time: 2.972s
[2K
| Adam | epoch: 010 | loss: 0.69339 - acc: 0.5085 -- iter: 096/736
[A[ATraining Step: 211  | total loss: [1m[32m0.69429[0m[0m | time: 3.781s
[2K
| Adam | epoch: 010 | loss: 0.69429 - acc: 0.4983 -- iter: 128/736
[A[ATraining Step: 212  | total loss: [1m[32m0.69390[0m[0m | time: 4.669s
[2K
| Adam | epoch: 010 | loss: 0.69390 - acc: 0.5016 -- iter: 160/736
[A[ATraining Step: 213  | total loss: [1m[32m0.69415[0m[0m | time: 5.576s
[2K
| Adam | epoch: 010 | loss: 0.69415 - acc: 0.4983 -- iter: 192/736
[A[ATraining Step: 214  | total loss: [1m[32m0.69283[0m[0m | time: 6.507s
[2K
| Adam | epoch: 010 | loss: 0.69283 - acc: 0.5141 -- iter: 224/736
[A[ATraining Step: 215  | total loss: [1m[32m0.69261[0m[0m | time: 7.455s
[2K
| Adam | epoch: 010 | loss: 0.69261 - acc: 0.5158 -- iter: 256/736
[A[ATraining Step: 216  | total loss: [1m[32m0.69219[0m[0m | time: 8.394s
[2K
| Adam | epoch: 010 | loss: 0.69219 - acc: 0.5205 -- iter: 288/736
[A[ATraining Step: 217  | total loss: [1m[32m0.69185[0m[0m | time: 9.423s
[2K
| Adam | epoch: 010 | loss: 0.69185 - acc: 0.5247 -- iter: 320/736
[A[ATraining Step: 218  | total loss: [1m[32m0.69068[0m[0m | time: 10.480s
[2K
| Adam | epoch: 010 | loss: 0.69068 - acc: 0.5378 -- iter: 352/736
[A[ATraining Step: 219  | total loss: [1m[32m0.69009[0m[0m | time: 11.343s
[2K
| Adam | epoch: 010 | loss: 0.69009 - acc: 0.5434 -- iter: 384/736
[A[ATraining Step: 220  | total loss: [1m[32m0.69108[0m[0m | time: 12.217s
[2K
| Adam | epoch: 010 | loss: 0.69108 - acc: 0.5328 -- iter: 416/736
[A[ATraining Step: 221  | total loss: [1m[32m0.69190[0m[0m | time: 13.209s
[2K
| Adam | epoch: 010 | loss: 0.69190 - acc: 0.5233 -- iter: 448/736
[A[ATraining Step: 222  | total loss: [1m[32m0.69200[0m[0m | time: 14.134s
[2K
| Adam | epoch: 010 | loss: 0.69200 - acc: 0.5210 -- iter: 480/736
[A[ATraining Step: 223  | total loss: [1m[32m0.69309[0m[0m | time: 15.135s
[2K
| Adam | epoch: 010 | loss: 0.69309 - acc: 0.5095 -- iter: 512/736
[A[ATraining Step: 224  | total loss: [1m[32m0.69221[0m[0m | time: 16.203s
[2K
| Adam | epoch: 010 | loss: 0.69221 - acc: 0.5179 -- iter: 544/736
[A[ATraining Step: 225  | total loss: [1m[32m0.69200[0m[0m | time: 17.084s
[2K
| Adam | epoch: 010 | loss: 0.69200 - acc: 0.5193 -- iter: 576/736
[A[ATraining Step: 226  | total loss: [1m[32m0.69115[0m[0m | time: 17.969s
[2K
| Adam | epoch: 010 | loss: 0.69115 - acc: 0.5267 -- iter: 608/736
[A[ATraining Step: 227  | total loss: [1m[32m0.69052[0m[0m | time: 19.058s
[2K
| Adam | epoch: 010 | loss: 0.69052 - acc: 0.5303 -- iter: 640/736
[A[ATraining Step: 228  | total loss: [1m[32m0.68880[0m[0m | time: 20.122s
[2K
| Adam | epoch: 010 | loss: 0.68880 - acc: 0.5429 -- iter: 672/736
[A[ATraining Step: 229  | total loss: [1m[32m0.68879[0m[0m | time: 21.072s
[2K
| Adam | epoch: 010 | loss: 0.68879 - acc: 0.5417 -- iter: 704/736
[A[ATraining Step: 230  | total loss: [1m[32m0.68919[0m[0m | time: 23.031s
[2K
| Adam | epoch: 010 | loss: 0.68919 - acc: 0.5375 | val_loss: 0.69135 - val_acc: 0.5043 -- iter: 736/736
--
Training Step: 231  | total loss: [1m[32m0.69017[0m[0m | time: 1.113s
[2K
| Adam | epoch: 011 | loss: 0.69017 - acc: 0.5307 -- iter: 032/736
[A[ATraining Step: 232  | total loss: [1m[32m0.68824[0m[0m | time: 2.081s
[2K
| Adam | epoch: 011 | loss: 0.68824 - acc: 0.5401 -- iter: 064/736
[A[ATraining Step: 233  | total loss: [1m[32m0.68805[0m[0m | time: 2.921s
[2K
| Adam | epoch: 011 | loss: 0.68805 - acc: 0.5361 -- iter: 096/736
[A[ATraining Step: 234  | total loss: [1m[32m0.68937[0m[0m | time: 4.004s
[2K
| Adam | epoch: 011 | loss: 0.68937 - acc: 0.5294 -- iter: 128/736
[A[ATraining Step: 235  | total loss: [1m[32m0.68561[0m[0m | time: 5.048s
[2K
| Adam | epoch: 011 | loss: 0.68561 - acc: 0.5452 -- iter: 160/736
[A[ATraining Step: 236  | total loss: [1m[32m0.68734[0m[0m | time: 5.971s
[2K
| Adam | epoch: 011 | loss: 0.68734 - acc: 0.5375 -- iter: 192/736
[A[ATraining Step: 237  | total loss: [1m[32m0.68651[0m[0m | time: 6.861s
[2K
| Adam | epoch: 011 | loss: 0.68651 - acc: 0.5338 -- iter: 224/736
[A[ATraining Step: 238  | total loss: [1m[32m0.68533[0m[0m | time: 7.833s
[2K
| Adam | epoch: 011 | loss: 0.68533 - acc: 0.5304 -- iter: 256/736
[A[ATraining Step: 239  | total loss: [1m[32m0.68582[0m[0m | time: 8.816s
[2K
| Adam | epoch: 011 | loss: 0.68582 - acc: 0.5242 -- iter: 288/736
[A[ATraining Step: 240  | total loss: [1m[32m0.68453[0m[0m | time: 9.827s
[2K
| Adam | epoch: 011 | loss: 0.68453 - acc: 0.5281 -- iter: 320/736
[A[ATraining Step: 241  | total loss: [1m[32m0.68128[0m[0m | time: 10.891s
[2K
| Adam | epoch: 011 | loss: 0.68128 - acc: 0.5315 -- iter: 352/736
[A[ATraining Step: 242  | total loss: [1m[32m0.68169[0m[0m | time: 11.756s
[2K
| Adam | epoch: 011 | loss: 0.68169 - acc: 0.5252 -- iter: 384/736
[A[ATraining Step: 243  | total loss: [1m[32m0.68006[0m[0m | time: 12.634s
[2K
| Adam | epoch: 011 | loss: 0.68006 - acc: 0.5352 -- iter: 416/736
[A[ATraining Step: 244  | total loss: [1m[32m0.67950[0m[0m | time: 13.728s
[2K
| Adam | epoch: 011 | loss: 0.67950 - acc: 0.5411 -- iter: 448/736
[A[ATraining Step: 245  | total loss: [1m[32m0.68296[0m[0m | time: 14.804s
[2K
| Adam | epoch: 011 | loss: 0.68296 - acc: 0.5276 -- iter: 480/736
[A[ATraining Step: 246  | total loss: [1m[32m0.67419[0m[0m | time: 15.664s
[2K
| Adam | epoch: 011 | loss: 0.67419 - acc: 0.5561 -- iter: 512/736
[A[ATraining Step: 247  | total loss: [1m[32m0.67338[0m[0m | time: 16.596s
[2K
| Adam | epoch: 011 | loss: 0.67338 - acc: 0.5536 -- iter: 544/736
[A[ATraining Step: 248  | total loss: [1m[32m0.66307[0m[0m | time: 17.569s
[2K
| Adam | epoch: 011 | loss: 0.66307 - acc: 0.5670 -- iter: 576/736
[A[ATraining Step: 249  | total loss: [1m[32m0.65578[0m[0m | time: 18.483s
[2K
| Adam | epoch: 011 | loss: 0.65578 - acc: 0.5853 -- iter: 608/736
[A[ATraining Step: 250  | total loss: [1m[32m0.65111[0m[0m | time: 19.378s
[2K
| Adam | epoch: 011 | loss: 0.65111 - acc: 0.5986 -- iter: 640/736
[A[ATraining Step: 251  | total loss: [1m[32m0.63775[0m[0m | time: 20.444s
[2K
| Adam | epoch: 011 | loss: 0.63775 - acc: 0.6231 -- iter: 672/736
[A[ATraining Step: 252  | total loss: [1m[32m0.63531[0m[0m | time: 21.426s
[2K
| Adam | epoch: 011 | loss: 0.63531 - acc: 0.6296 -- iter: 704/736
[A[ATraining Step: 253  | total loss: [1m[32m0.66227[0m[0m | time: 23.394s
[2K
| Adam | epoch: 011 | loss: 0.66227 - acc: 0.6166 | val_loss: 0.70606 - val_acc: 0.5565 -- iter: 736/736
--
Training Step: 254  | total loss: [1m[32m0.64865[0m[0m | time: 1.070s
[2K
| Adam | epoch: 012 | loss: 0.64865 - acc: 0.6268 -- iter: 032/736
[A[ATraining Step: 255  | total loss: [1m[32m0.66983[0m[0m | time: 2.102s
[2K
| Adam | epoch: 012 | loss: 0.66983 - acc: 0.6110 -- iter: 064/736
[A[ATraining Step: 256  | total loss: [1m[32m0.67768[0m[0m | time: 3.193s
[2K
| Adam | epoch: 012 | loss: 0.67768 - acc: 0.6030 -- iter: 096/736
[A[ATraining Step: 257  | total loss: [1m[32m0.67735[0m[0m | time: 4.235s
[2K
| Adam | epoch: 012 | loss: 0.67735 - acc: 0.5990 -- iter: 128/736
[A[ATraining Step: 258  | total loss: [1m[32m0.67474[0m[0m | time: 5.200s
[2K
| Adam | epoch: 012 | loss: 0.67474 - acc: 0.6016 -- iter: 160/736
[A[ATraining Step: 259  | total loss: [1m[32m0.67141[0m[0m | time: 5.954s
[2K
| Adam | epoch: 012 | loss: 0.67141 - acc: 0.6039 -- iter: 192/736
[A[ATraining Step: 260  | total loss: [1m[32m0.66835[0m[0m | time: 6.565s
[2K
| Adam | epoch: 012 | loss: 0.66835 - acc: 0.6217 -- iter: 224/736
[A[ATraining Step: 261  | total loss: [1m[32m0.66128[0m[0m | time: 7.187s
[2K
| Adam | epoch: 012 | loss: 0.66128 - acc: 0.6407 -- iter: 256/736
[A[ATraining Step: 262  | total loss: [1m[32m0.65618[0m[0m | time: 7.816s
[2K
| Adam | epoch: 012 | loss: 0.65618 - acc: 0.6485 -- iter: 288/736
[A[ATraining Step: 263  | total loss: [1m[32m0.64844[0m[0m | time: 8.436s
[2K
| Adam | epoch: 012 | loss: 0.64844 - acc: 0.6618 -- iter: 320/736
[A[ATraining Step: 264  | total loss: [1m[32m0.64105[0m[0m | time: 9.063s
[2K
| Adam | epoch: 012 | loss: 0.64105 - acc: 0.6738 -- iter: 352/736
[A[ATraining Step: 265  | total loss: [1m[32m0.63158[0m[0m | time: 9.770s
[2K
| Adam | epoch: 012 | loss: 0.63158 - acc: 0.6845 -- iter: 384/736
[A[ATraining Step: 266  | total loss: [1m[32m0.62067[0m[0m | time: 10.401s
[2K
| Adam | epoch: 012 | loss: 0.62067 - acc: 0.7004 -- iter: 416/736
[A[ATraining Step: 267  | total loss: [1m[32m0.61185[0m[0m | time: 11.021s
[2K
| Adam | epoch: 012 | loss: 0.61185 - acc: 0.7085 -- iter: 448/736
[A[ATraining Step: 268  | total loss: [1m[32m0.59852[0m[0m | time: 11.643s
[2K
| Adam | epoch: 012 | loss: 0.59852 - acc: 0.7158 -- iter: 480/736
[A[ATraining Step: 269  | total loss: [1m[32m0.59694[0m[0m | time: 12.282s
[2K
| Adam | epoch: 012 | loss: 0.59694 - acc: 0.7192 -- iter: 512/736
[A[ATraining Step: 270  | total loss: [1m[32m0.58943[0m[0m | time: 12.908s
[2K
| Adam | epoch: 012 | loss: 0.58943 - acc: 0.7098 -- iter: 544/736
[A[ATraining Step: 271  | total loss: [1m[32m0.59320[0m[0m | time: 13.528s
[2K
| Adam | epoch: 012 | loss: 0.59320 - acc: 0.7107 -- iter: 576/736
[A[ATraining Step: 272  | total loss: [1m[32m0.58846[0m[0m | time: 14.143s
[2K
| Adam | epoch: 012 | loss: 0.58846 - acc: 0.7115 -- iter: 608/736
[A[ATraining Step: 273  | total loss: [1m[32m0.56540[0m[0m | time: 14.783s
[2K
| Adam | epoch: 012 | loss: 0.56540 - acc: 0.7341 -- iter: 640/736
[A[ATraining Step: 274  | total loss: [1m[32m0.57054[0m[0m | time: 15.402s
[2K
| Adam | epoch: 012 | loss: 0.57054 - acc: 0.7263 -- iter: 672/736
[A[ATraining Step: 275  | total loss: [1m[32m0.57231[0m[0m | time: 16.022s
[2K
| Adam | epoch: 012 | loss: 0.57231 - acc: 0.7318 -- iter: 704/736
[A[ATraining Step: 276  | total loss: [1m[32m0.57667[0m[0m | time: 17.662s
[2K
| Adam | epoch: 012 | loss: 0.57667 - acc: 0.7305 | val_loss: 0.72496 - val_acc: 0.5565 -- iter: 736/736
--
Training Step: 277  | total loss: [1m[32m0.57735[0m[0m | time: 0.701s
[2K
| Adam | epoch: 013 | loss: 0.57735 - acc: 0.7293 -- iter: 032/736
[A[ATraining Step: 278  | total loss: [1m[32m0.60415[0m[0m | time: 1.309s
[2K
| Adam | epoch: 013 | loss: 0.60415 - acc: 0.7001 -- iter: 064/736
[A[ATraining Step: 279  | total loss: [1m[32m0.59253[0m[0m | time: 1.923s
[2K
| Adam | epoch: 013 | loss: 0.59253 - acc: 0.7114 -- iter: 096/736
[A[ATraining Step: 280  | total loss: [1m[32m0.58783[0m[0m | time: 2.563s
[2K
| Adam | epoch: 013 | loss: 0.58783 - acc: 0.7121 -- iter: 128/736
[A[ATraining Step: 281  | total loss: [1m[32m0.56271[0m[0m | time: 3.204s
[2K
| Adam | epoch: 013 | loss: 0.56271 - acc: 0.7347 -- iter: 160/736
[A[ATraining Step: 282  | total loss: [1m[32m0.56593[0m[0m | time: 3.813s
[2K
| Adam | epoch: 013 | loss: 0.56593 - acc: 0.7268 -- iter: 192/736
[A[ATraining Step: 283  | total loss: [1m[32m0.54936[0m[0m | time: 4.422s
[2K
| Adam | epoch: 013 | loss: 0.54936 - acc: 0.7354 -- iter: 224/736
[A[ATraining Step: 284  | total loss: [1m[32m0.54359[0m[0m | time: 5.055s
[2K
| Adam | epoch: 013 | loss: 0.54359 - acc: 0.7431 -- iter: 256/736
[A[ATraining Step: 285  | total loss: [1m[32m0.52655[0m[0m | time: 5.675s
[2K
| Adam | epoch: 013 | loss: 0.52655 - acc: 0.7563 -- iter: 288/736
[A[ATraining Step: 286  | total loss: [1m[32m0.51983[0m[0m | time: 6.300s
[2K
| Adam | epoch: 013 | loss: 0.51983 - acc: 0.7650 -- iter: 320/736
[A[ATraining Step: 287  | total loss: [1m[32m0.51266[0m[0m | time: 6.918s
[2K
| Adam | epoch: 013 | loss: 0.51266 - acc: 0.7729 -- iter: 352/736
[A[ATraining Step: 288  | total loss: [1m[32m0.49849[0m[0m | time: 7.540s
[2K
| Adam | epoch: 013 | loss: 0.49849 - acc: 0.7862 -- iter: 384/736
[A[ATraining Step: 289  | total loss: [1m[32m0.48082[0m[0m | time: 8.166s
[2K
| Adam | epoch: 013 | loss: 0.48082 - acc: 0.8014 -- iter: 416/736
[A[ATraining Step: 290  | total loss: [1m[32m0.46782[0m[0m | time: 8.787s
[2K
| Adam | epoch: 013 | loss: 0.46782 - acc: 0.8087 -- iter: 448/736
[A[ATraining Step: 291  | total loss: [1m[32m0.50506[0m[0m | time: 9.409s
[2K
| Adam | epoch: 013 | loss: 0.50506 - acc: 0.7904 -- iter: 480/736
[A[ATraining Step: 292  | total loss: [1m[32m0.50772[0m[0m | time: 10.029s
[2K
| Adam | epoch: 013 | loss: 0.50772 - acc: 0.7926 -- iter: 512/736
[A[ATraining Step: 293  | total loss: [1m[32m0.50173[0m[0m | time: 10.801s
[2K
| Adam | epoch: 013 | loss: 0.50173 - acc: 0.7946 -- iter: 544/736
[A[ATraining Step: 294  | total loss: [1m[32m0.50094[0m[0m | time: 12.182s
[2K
| Adam | epoch: 013 | loss: 0.50094 - acc: 0.7901 -- iter: 576/736
[A[ATraining Step: 295  | total loss: [1m[32m0.49180[0m[0m | time: 13.399s
[2K
| Adam | epoch: 013 | loss: 0.49180 - acc: 0.7923 -- iter: 608/736
[A[ATraining Step: 296  | total loss: [1m[32m0.48687[0m[0m | time: 14.849s
[2K
| Adam | epoch: 013 | loss: 0.48687 - acc: 0.7850 -- iter: 640/736
[A[ATraining Step: 297  | total loss: [1m[32m0.47435[0m[0m | time: 16.023s
[2K
| Adam | epoch: 013 | loss: 0.47435 - acc: 0.7909 -- iter: 672/736
[A[ATraining Step: 298  | total loss: [1m[32m0.48050[0m[0m | time: 17.144s
[2K
| Adam | epoch: 013 | loss: 0.48050 - acc: 0.7899 -- iter: 704/736
[A[ATraining Step: 299  | total loss: [1m[32m0.48244[0m[0m | time: 20.058s
[2K
| Adam | epoch: 013 | loss: 0.48244 - acc: 0.7859 | val_loss: 0.46599 - val_acc: 0.7913 -- iter: 736/736
--
Training Step: 300  | total loss: [1m[32m0.48800[0m[0m | time: 1.175s
[2K
| Adam | epoch: 014 | loss: 0.48800 - acc: 0.7823 -- iter: 032/736
[A[ATraining Step: 301  | total loss: [1m[32m0.47865[0m[0m | time: 2.412s
[2K
| Adam | epoch: 014 | loss: 0.47865 - acc: 0.7916 -- iter: 064/736
[A[ATraining Step: 302  | total loss: [1m[32m0.49639[0m[0m | time: 3.582s
[2K
| Adam | epoch: 014 | loss: 0.49639 - acc: 0.7843 -- iter: 096/736
[A[ATraining Step: 303  | total loss: [1m[32m0.48845[0m[0m | time: 4.298s
[2K
| Adam | epoch: 014 | loss: 0.48845 - acc: 0.7934 -- iter: 128/736
[A[ATraining Step: 304  | total loss: [1m[32m0.48346[0m[0m | time: 4.919s
[2K
| Adam | epoch: 014 | loss: 0.48346 - acc: 0.7922 -- iter: 160/736
[A[ATraining Step: 305  | total loss: [1m[32m0.46169[0m[0m | time: 5.545s
[2K
| Adam | epoch: 014 | loss: 0.46169 - acc: 0.8098 -- iter: 192/736
[A[ATraining Step: 306  | total loss: [1m[32m0.45250[0m[0m | time: 6.156s
[2K
| Adam | epoch: 014 | loss: 0.45250 - acc: 0.8132 -- iter: 224/736
[A[ATraining Step: 307  | total loss: [1m[32m0.44983[0m[0m | time: 6.768s
[2K
| Adam | epoch: 014 | loss: 0.44983 - acc: 0.8194 -- iter: 256/736
[A[ATraining Step: 308  | total loss: [1m[32m0.43307[0m[0m | time: 7.386s
[2K
| Adam | epoch: 014 | loss: 0.43307 - acc: 0.8281 -- iter: 288/736
[A[ATraining Step: 309  | total loss: [1m[32m0.41822[0m[0m | time: 8.016s
[2K
| Adam | epoch: 014 | loss: 0.41822 - acc: 0.8359 -- iter: 320/736
[A[ATraining Step: 310  | total loss: [1m[32m0.43140[0m[0m | time: 8.645s
[2K
| Adam | epoch: 014 | loss: 0.43140 - acc: 0.8273 -- iter: 352/736
[A[ATraining Step: 311  | total loss: [1m[32m0.44427[0m[0m | time: 9.248s
[2K
| Adam | epoch: 014 | loss: 0.44427 - acc: 0.8196 -- iter: 384/736
[A[ATraining Step: 312  | total loss: [1m[32m0.44127[0m[0m | time: 9.854s
[2K
| Adam | epoch: 014 | loss: 0.44127 - acc: 0.8189 -- iter: 416/736
[A[ATraining Step: 313  | total loss: [1m[32m0.43484[0m[0m | time: 10.464s
[2K
| Adam | epoch: 014 | loss: 0.43484 - acc: 0.8089 -- iter: 448/736
[A[ATraining Step: 314  | total loss: [1m[32m0.44055[0m[0m | time: 11.056s
[2K
| Adam | epoch: 014 | loss: 0.44055 - acc: 0.8061 -- iter: 480/736
[A[ATraining Step: 315  | total loss: [1m[32m0.43113[0m[0m | time: 11.663s
[2K
| Adam | epoch: 014 | loss: 0.43113 - acc: 0.8099 -- iter: 512/736
[A[ATraining Step: 316  | total loss: [1m[32m0.43428[0m[0m | time: 12.280s
[2K
| Adam | epoch: 014 | loss: 0.43428 - acc: 0.8039 -- iter: 544/736
[A[ATraining Step: 317  | total loss: [1m[32m0.42112[0m[0m | time: 12.884s
[2K
| Adam | epoch: 014 | loss: 0.42112 - acc: 0.8172 -- iter: 576/736
[A[ATraining Step: 318  | total loss: [1m[32m0.40328[0m[0m | time: 13.487s
[2K
| Adam | epoch: 014 | loss: 0.40328 - acc: 0.8293 -- iter: 608/736
[A[ATraining Step: 319  | total loss: [1m[32m0.38800[0m[0m | time: 14.102s
[2K
| Adam | epoch: 014 | loss: 0.38800 - acc: 0.8338 -- iter: 640/736
[A[ATraining Step: 320  | total loss: [1m[32m0.39041[0m[0m | time: 14.699s
[2K
| Adam | epoch: 014 | loss: 0.39041 - acc: 0.8380 -- iter: 672/736
[A[ATraining Step: 321  | total loss: [1m[32m0.39537[0m[0m | time: 15.304s
[2K
| Adam | epoch: 014 | loss: 0.39537 - acc: 0.8417 -- iter: 704/736
[A[ATraining Step: 322  | total loss: [1m[32m0.38267[0m[0m | time: 16.941s
[2K
| Adam | epoch: 014 | loss: 0.38267 - acc: 0.8512 | val_loss: 0.48367 - val_acc: 0.7739 -- iter: 736/736
--
Training Step: 323  | total loss: [1m[32m0.37497[0m[0m | time: 0.607s
[2K
| Adam | epoch: 015 | loss: 0.37497 - acc: 0.8567 -- iter: 032/736
[A[ATraining Step: 324  | total loss: [1m[32m0.37121[0m[0m | time: 1.209s
[2K
| Adam | epoch: 015 | loss: 0.37121 - acc: 0.8586 -- iter: 064/736
[A[ATraining Step: 325  | total loss: [1m[32m0.35337[0m[0m | time: 1.816s
[2K
| Adam | epoch: 015 | loss: 0.35337 - acc: 0.8665 -- iter: 096/736
[A[ATraining Step: 326  | total loss: [1m[32m0.34263[0m[0m | time: 2.424s
[2K
| Adam | epoch: 015 | loss: 0.34263 - acc: 0.8704 -- iter: 128/736
[A[ATraining Step: 327  | total loss: [1m[32m0.32943[0m[0m | time: 3.026s
[2K
| Adam | epoch: 015 | loss: 0.32943 - acc: 0.8771 -- iter: 160/736
[A[ATraining Step: 328  | total loss: [1m[32m0.34107[0m[0m | time: 3.630s
[2K
| Adam | epoch: 015 | loss: 0.34107 - acc: 0.8738 -- iter: 192/736
[A[ATraining Step: 329  | total loss: [1m[32m0.32893[0m[0m | time: 4.225s
[2K
| Adam | epoch: 015 | loss: 0.32893 - acc: 0.8833 -- iter: 224/736
[A[ATraining Step: 330  | total loss: [1m[32m0.32456[0m[0m | time: 4.829s
[2K
| Adam | epoch: 015 | loss: 0.32456 - acc: 0.8887 -- iter: 256/736
[A[ATraining Step: 331  | total loss: [1m[32m0.31527[0m[0m | time: 5.437s
[2K
| Adam | epoch: 015 | loss: 0.31527 - acc: 0.8873 -- iter: 288/736
[A[ATraining Step: 332  | total loss: [1m[32m0.31870[0m[0m | time: 6.085s
[2K
| Adam | epoch: 015 | loss: 0.31870 - acc: 0.8799 -- iter: 320/736
[A[ATraining Step: 333  | total loss: [1m[32m0.30571[0m[0m | time: 6.700s
[2K
| Adam | epoch: 015 | loss: 0.30571 - acc: 0.8856 -- iter: 352/736
[A[ATraining Step: 334  | total loss: [1m[32m0.30615[0m[0m | time: 7.311s
[2K
| Adam | epoch: 015 | loss: 0.30615 - acc: 0.8877 -- iter: 384/736
[A[ATraining Step: 335  | total loss: [1m[32m0.31501[0m[0m | time: 7.939s
[2K
| Adam | epoch: 015 | loss: 0.31501 - acc: 0.8864 -- iter: 416/736
[A[ATraining Step: 336  | total loss: [1m[32m0.29273[0m[0m | time: 8.572s
[2K
| Adam | epoch: 015 | loss: 0.29273 - acc: 0.8978 -- iter: 448/736
[A[ATraining Step: 337  | total loss: [1m[32m0.27533[0m[0m | time: 9.181s
[2K
| Adam | epoch: 015 | loss: 0.27533 - acc: 0.9049 -- iter: 480/736
[A[ATraining Step: 338  | total loss: [1m[32m0.28330[0m[0m | time: 9.806s
[2K
| Adam | epoch: 015 | loss: 0.28330 - acc: 0.9019 -- iter: 512/736
[A[ATraining Step: 339  | total loss: [1m[32m0.26142[0m[0m | time: 10.410s
[2K
| Adam | epoch: 015 | loss: 0.26142 - acc: 0.9117 -- iter: 544/736
[A[ATraining Step: 340  | total loss: [1m[32m0.26181[0m[0m | time: 11.074s
[2K
| Adam | epoch: 015 | loss: 0.26181 - acc: 0.9112 -- iter: 576/736
[A[ATraining Step: 341  | total loss: [1m[32m0.26296[0m[0m | time: 11.683s
[2K
| Adam | epoch: 015 | loss: 0.26296 - acc: 0.9138 -- iter: 608/736
[A[ATraining Step: 342  | total loss: [1m[32m0.26870[0m[0m | time: 12.294s
[2K
| Adam | epoch: 015 | loss: 0.26870 - acc: 0.9130 -- iter: 640/736
[A[ATraining Step: 343  | total loss: [1m[32m0.26471[0m[0m | time: 12.913s
[2K
| Adam | epoch: 015 | loss: 0.26471 - acc: 0.9155 -- iter: 672/736
[A[ATraining Step: 344  | total loss: [1m[32m0.26310[0m[0m | time: 13.527s
[2K
| Adam | epoch: 015 | loss: 0.26310 - acc: 0.9114 -- iter: 704/736
[A[ATraining Step: 345  | total loss: [1m[32m0.24931[0m[0m | time: 15.148s
[2K
| Adam | epoch: 015 | loss: 0.24931 - acc: 0.9172 | val_loss: 0.41468 - val_acc: 0.8087 -- iter: 736/736
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9188596491228069
Validation AUPRC:0.9266987733170984
Test AUC:0.9435893547653348
Test AUPRC:0.9566207917896123
BestTestF1Score	0.9	0.77	0.89	0.87	0.92	111	16	93	10	0.11
BestTestMCCScore	0.9	0.8	0.9	0.92	0.89	108	10	99	13	0.25
BestTestAccuracyScore	0.9	0.8	0.9	0.92	0.89	108	10	99	13	0.25
BestValidationF1Score	0.86	0.71	0.86	0.84	0.89	103	20	94	13	0.11
BestValidationMCC	0.85	0.71	0.86	0.88	0.83	96	13	101	20	0.25
BestValidationAccuracy	0.85	0.71	0.86	0.88	0.83	96	13	101	20	0.25
TestPredictions (Threshold:0.25)
CHEMBL45160,TN,INACT,0.07999999821186066	CHEMBL353502,TN,INACT,0.23999999463558197	CHEMBL152026,TP,ACT,0.8700000047683716	CHEMBL61792,TN,INACT,0.03999999910593033	CHEMBL254064,TP,ACT,0.36000001430511475	CHEMBL276603,TP,ACT,0.8399999737739563	CHEMBL147582,TP,ACT,0.9700000286102295	CHEMBL964,TN,INACT,0.03999999910593033	CHEMBL2113608,TP,ACT,0.9599999785423279	CHEMBL317270,TP,ACT,0.8899999856948853	CHEMBL3780633,TN,INACT,0.05000000074505806	CHEMBL196375,TP,ACT,0.6600000262260437	CHEMBL196138,TP,ACT,0.5299999713897705	CHEMBL389388,TP,ACT,0.9900000095367432	CHEMBL416537,TP,ACT,0.9700000286102295	CHEMBL461088,TN,INACT,0.05000000074505806	CHEMBL97344,FN,ACT,0.1599999964237213	CHEMBL2203713,FP,INACT,0.8500000238418579	CHEMBL294649,TN,INACT,0.05999999865889549	CHEMBL10895,TP,ACT,0.8899999856948853	CHEMBL101915,FP,INACT,0.8600000143051147	CHEMBL212458,FN,ACT,0.03999999910593033	CHEMBL227893,TP,ACT,0.6700000166893005	CHEMBL107680,TN,INACT,0.03999999910593033	CHEMBL413644,TN,INACT,0.10000000149011612	CHEMBL160626,TN,INACT,0.019999999552965164	CHEMBL377523,TP,ACT,0.9700000286102295	CHEMBL254897,TP,ACT,0.5	CHEMBL158859,TP,ACT,0.4300000071525574	CHEMBL312670,TN,INACT,0.05999999865889549	CHEMBL97663,TP,ACT,0.9900000095367432	CHEMBL273094,TP,ACT,0.9200000166893005	CHEMBL194956,TP,ACT,0.25	CHEMBL78080,TN,INACT,0.05000000074505806	CHEMBL96617,FN,ACT,0.07999999821186066	CHEMBL268071,TP,ACT,0.27000001072883606	CHEMBL274273,TP,ACT,0.9800000190734863	CHEMBL3109772,TN,INACT,0.05000000074505806	CHEMBL446693,TN,INACT,0.23000000417232513	CHEMBL89953,TN,INACT,0.09000000357627869	CHEMBL377542,TN,INACT,0.05000000074505806	CHEMBL484314,TP,ACT,0.9900000095367432	CHEMBL16488,TP,ACT,0.9800000190734863	CHEMBL104115,TP,ACT,0.9100000262260437	CHEMBL224313,TP,ACT,0.8899999856948853	CHEMBL474636,TP,ACT,0.9800000190734863	CHEMBL11154,TP,ACT,0.800000011920929	CHEMBL70728,TN,INACT,0.029999999329447746	CHEMBL1346,TN,INACT,0.029999999329447746	CHEMBL400190,TP,ACT,0.8799999952316284	CHEMBL333872,FN,ACT,0.03999999910593033	CHEMBL16195,FN,ACT,0.03999999910593033	CHEMBL1907924,FN,ACT,0.07999999821186066	CHEMBL519319,TP,ACT,0.9800000190734863	CHEMBL473839,TP,ACT,0.9800000190734863	CHEMBL269633,TP,ACT,0.9800000190734863	CHEMBL376588,TP,ACT,0.9100000262260437	CHEMBL100832,TP,ACT,0.7099999785423279	CHEMBL389644,TP,ACT,0.8100000023841858	CHEMBL378514,TP,ACT,0.9599999785423279	CHEMBL331540,TP,ACT,0.7300000190734863	CHEMBL74342,TN,INACT,0.07000000029802322	CHEMBL304888,TN,INACT,0.029999999329447746	CHEMBL320254,TN,INACT,0.05999999865889549	CHEMBL376747,TP,ACT,0.9700000286102295	CHEMBL144799,TP,ACT,0.4699999988079071	CHEMBL329293,TP,ACT,0.949999988079071	CHEMBL171108,FP,INACT,0.7300000190734863	CHEMBL149732,TP,ACT,0.9599999785423279	CHEMBL327626,TN,INACT,0.03999999910593033	CHEMBL323175,TN,INACT,0.07000000029802322	CHEMBL606495,FN,ACT,0.07999999821186066	CHEMBL514155,TP,ACT,0.9300000071525574	CHEMBL112877,TN,INACT,0.029999999329447746	CHEMBL461087,TN,INACT,0.03999999910593033	CHEMBL7493,TP,ACT,0.7699999809265137	CHEMBL321644,FP,INACT,0.4399999976158142	CHEMBL104377,TN,INACT,0.05000000074505806	CHEMBL16750,TP,ACT,0.9800000190734863	CHEMBL3739820,TN,INACT,0.029999999329447746	CHEMBL255791,TN,INACT,0.09000000357627869	CHEMBL104172,TN,INACT,0.05000000074505806	CHEMBL62660,TN,INACT,0.05000000074505806	CHEMBL334286,TP,ACT,0.8799999952316284	CHEMBL225026,TP,ACT,0.8999999761581421	CHEMBL274822,TN,INACT,0.05999999865889549	CHEMBL16833,TP,ACT,0.9800000190734863	CHEMBL3143400,TN,INACT,0.03999999910593033	CHEMBL21328,TN,INACT,0.029999999329447746	CHEMBL140495,TN,INACT,0.019999999552965164	CHEMBL322678,TN,INACT,0.029999999329447746	CHEMBL390096,TP,ACT,0.6399999856948853	CHEMBL119709,TP,ACT,0.8899999856948853	CHEMBL595265,TN,INACT,0.07000000029802322	CHEMBL309017,TN,INACT,0.019999999552965164	CHEMBL226719,TP,ACT,0.9900000095367432	CHEMBL589,TN,INACT,0.029999999329447746	CHEMBL162558,TP,ACT,0.4399999976158142	CHEMBL353304,FP,INACT,0.550000011920929	CHEMBL477,TN,INACT,0.14000000059604645	CHEMBL97665,TP,ACT,0.7200000286102295	CHEMBL328089,TN,INACT,0.029999999329447746	CHEMBL20168,TN,INACT,0.03999999910593033	CHEMBL162814,TP,ACT,0.4099999964237213	CHEMBL48120,FP,INACT,0.3199999928474426	CHEMBL98227,TP,ACT,0.9399999976158142	CHEMBL324652,TN,INACT,0.10000000149011612	CHEMBL169889,TN,INACT,0.05999999865889549	CHEMBL226866,TP,ACT,0.9700000286102295	CHEMBL11288,TP,ACT,0.9900000095367432	CHEMBL84545,TP,ACT,0.949999988079071	CHEMBL556506,TN,INACT,0.03999999910593033	CHEMBL345839,TP,ACT,0.9800000190734863	CHEMBL165175,TN,INACT,0.05000000074505806	CHEMBL100347,TP,ACT,0.6000000238418579	CHEMBL167335,TN,INACT,0.03999999910593033	CHEMBL140620,TN,INACT,0.03999999910593033	CHEMBL3323005,TN,INACT,0.05000000074505806	CHEMBL19808,TN,INACT,0.03999999910593033	CHEMBL224620,TP,ACT,0.8799999952316284	CHEMBL2112451,TN,INACT,0.019999999552965164	CHEMBL160396,TN,INACT,0.03999999910593033	CHEMBL209943,TP,ACT,0.44999998807907104	CHEMBL11342,TP,ACT,0.9800000190734863	CHEMBL104478,TP,ACT,0.9700000286102295	CHEMBL276401,TP,ACT,0.9700000286102295	CHEMBL104998,TP,ACT,0.9300000071525574	CHEMBL296927,TN,INACT,0.05000000074505806	CHEMBL281232,TN,INACT,0.05999999865889549	CHEMBL312958,TN,INACT,0.05000000074505806	CHEMBL319005,TN,INACT,0.03999999910593033	CHEMBL320093,TP,ACT,0.9399999976158142	CHEMBL197325,TP,ACT,0.8500000238418579	CHEMBL268701,TP,ACT,0.8600000143051147	CHEMBL66789,TN,INACT,0.03999999910593033	CHEMBL158423,TP,ACT,0.9399999976158142	CHEMBL1263,TN,INACT,0.05000000074505806	CHEMBL312266,TN,INACT,0.07000000029802322	CHEMBL316824,TP,ACT,0.9599999785423279	CHEMBL400331,TP,ACT,0.6200000047683716	CHEMBL284969,TP,ACT,0.8500000238418579	CHEMBL3633663,TN,INACT,0.07999999821186066	CHEMBL276227,TP,ACT,0.9300000071525574	CHEMBL197376,TP,ACT,0.75	CHEMBL152058,TP,ACT,0.9399999976158142	CHEMBL439335,TN,INACT,0.05000000074505806	CHEMBL3577342,TN,INACT,0.07999999821186066	CHEMBL353115,FN,ACT,0.10999999940395355	CHEMBL195357,TP,ACT,0.41999998688697815	CHEMBL104999,TP,ACT,0.5799999833106995	CHEMBL501756,TN,INACT,0.20999999344348907	CHEMBL161051,TP,ACT,0.75	CHEMBL16305,TP,ACT,0.9599999785423279	CHEMBL331946,TP,ACT,0.7300000190734863	CHEMBL352925,TN,INACT,0.05999999865889549	CHEMBL423918,TN,INACT,0.019999999552965164	CHEMBL276819,TN,INACT,0.07999999821186066	CHEMBL73164,TN,INACT,0.05000000074505806	CHEMBL196306,TP,ACT,0.699999988079071	CHEMBL110053,TN,INACT,0.029999999329447746	CHEMBL359141,TN,INACT,0.12999999523162842	CHEMBL15689,TN,INACT,0.05000000074505806	CHEMBL151619,FP,INACT,0.6299999952316284	CHEMBL16643,TP,ACT,0.9200000166893005	CHEMBL3335535,TN,INACT,0.05999999865889549	CHEMBL2391352,TN,INACT,0.03999999910593033	CHEMBL268026,TP,ACT,0.9900000095367432	CHEMBL1381098,TN,INACT,0.05999999865889549	CHEMBL2372075,TN,INACT,0.09000000357627869	CHEMBL2312346,TN,INACT,0.029999999329447746	CHEMBL108178,TP,ACT,0.9700000286102295	CHEMBL398544,TP,ACT,0.3199999928474426	CHEMBL330674,TN,INACT,0.07000000029802322	CHEMBL242203,TP,ACT,0.9399999976158142	CHEMBL16715,TP,ACT,0.4399999976158142	CHEMBL10801,TN,INACT,0.03999999910593033	CHEMBL147340,TN,INACT,0.05000000074505806	CHEMBL388344,TP,ACT,0.9900000095367432	CHEMBL312859,TP,ACT,0.9200000166893005	CHEMBL298612,TN,INACT,0.05999999865889549	CHEMBL278197,TP,ACT,0.9800000190734863	CHEMBL380162,FN,ACT,0.1599999964237213	CHEMBL7334,TP,ACT,0.8299999833106995	CHEMBL11054,TP,ACT,0.9800000190734863	CHEMBL3577344,TN,INACT,0.1599999964237213	CHEMBL336033,TN,INACT,0.029999999329447746	CHEMBL225523,TP,ACT,0.9700000286102295	CHEMBL152294,TP,ACT,0.8999999761581421	CHEMBL44615,TN,INACT,0.07000000029802322	CHEMBL224909,TP,ACT,0.9100000262260437	CHEMBL2113643,TP,ACT,0.9100000262260437	CHEMBL421782,FN,ACT,0.12999999523162842	CHEMBL441954,TP,ACT,0.7300000190734863	CHEMBL434284,TN,INACT,0.03999999910593033	CHEMBL224179,TP,ACT,0.9100000262260437	CHEMBL21508,TN,INACT,0.10000000149011612	CHEMBL379791,TP,ACT,0.9800000190734863	CHEMBL19095,TP,ACT,0.6100000143051147	CHEMBL167032,TN,INACT,0.029999999329447746	CHEMBL224621,TP,ACT,0.9700000286102295	CHEMBL557840,TN,INACT,0.07000000029802322	CHEMBL189192,TN,INACT,0.05999999865889549	CHEMBL101554,FN,ACT,0.09000000357627869	CHEMBL11240,TP,ACT,0.8600000143051147	CHEMBL227945,TP,ACT,0.9599999785423279	CHEMBL3290984,TN,INACT,0.03999999910593033	CHEMBL404557,TN,INACT,0.05000000074505806	CHEMBL475792,TP,ACT,0.9399999976158142	CHEMBL165462,TN,INACT,0.03999999910593033	CHEMBL593685,TN,INACT,0.05999999865889549	CHEMBL144740,TP,ACT,0.5400000214576721	CHEMBL2042401,TN,INACT,0.09000000357627869	CHEMBL274778,TP,ACT,0.8899999856948853	CHEMBL43788,FP,INACT,0.30000001192092896	CHEMBL85678,TN,INACT,0.09000000357627869	CHEMBL351183,TN,INACT,0.07000000029802322	CHEMBL103553,FN,ACT,0.05000000074505806	CHEMBL119385,TN,INACT,0.05000000074505806	CHEMBL118164,TP,ACT,0.9399999976158142	CHEMBL2413238,FN,ACT,0.05000000074505806	CHEMBL106487,TN,INACT,0.03999999910593033	CHEMBL308756,TN,INACT,0.03999999910593033	CHEMBL2062852,FP,INACT,0.6000000238418579	CHEMBL227397,TP,ACT,0.75	CHEMBL334224,TP,ACT,0.7900000214576721	CHEMBL2062858,FP,INACT,0.8799999952316284	CHEMBL3085215,TN,INACT,0.029999999329447746	CHEMBL279870,TP,ACT,0.6800000071525574	CHEMBL113,TN,INACT,0.05000000074505806	CHEMBL241279,TN,INACT,0.07999999821186066	

