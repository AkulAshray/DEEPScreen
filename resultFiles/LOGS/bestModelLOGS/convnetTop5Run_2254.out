ImageNetInceptionV2 CHEMBL4641 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	229
Number of inactive compounds :	229
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4641_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4641_adam_0.0005_15_0.6/
---------------------------------
Training samples: 292
Validation samples: 92
--
Training Step: 1  | time: 36.341s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/292
[A[ATraining Step: 2  | total loss: [1m[32m0.65956[0m[0m | time: 44.367s
[2K
| Adam | epoch: 001 | loss: 0.65956 - acc: 0.4500 -- iter: 064/292
[A[ATraining Step: 3  | total loss: [1m[32m0.68405[0m[0m | time: 52.319s
[2K
| Adam | epoch: 001 | loss: 0.68405 - acc: 0.5932 -- iter: 096/292
[A[ATraining Step: 4  | total loss: [1m[32m0.69083[0m[0m | time: 60.237s
[2K
| Adam | epoch: 001 | loss: 0.69083 - acc: 0.6170 -- iter: 128/292
[A[ATraining Step: 5  | total loss: [1m[32m0.64742[0m[0m | time: 68.342s
[2K
| Adam | epoch: 001 | loss: 0.64742 - acc: 0.6226 -- iter: 160/292
[A[ATraining Step: 6  | total loss: [1m[32m0.58985[0m[0m | time: 76.185s
[2K
| Adam | epoch: 001 | loss: 0.58985 - acc: 0.7447 -- iter: 192/292
[A[ATraining Step: 7  | total loss: [1m[32m0.50405[0m[0m | time: 84.309s
[2K
| Adam | epoch: 001 | loss: 0.50405 - acc: 0.7854 -- iter: 224/292
[A[ATraining Step: 8  | total loss: [1m[32m0.46788[0m[0m | time: 92.114s
[2K
| Adam | epoch: 001 | loss: 0.46788 - acc: 0.7831 -- iter: 256/292
[A[ATraining Step: 9  | total loss: [1m[32m0.42715[0m[0m | time: 100.183s
[2K
| Adam | epoch: 001 | loss: 0.42715 - acc: 0.7986 -- iter: 288/292
[A[ATraining Step: 10  | total loss: [1m[32m0.41865[0m[0m | time: 112.655s
[2K
| Adam | epoch: 001 | loss: 0.41865 - acc: 0.8056 | val_loss: 1.59623 - val_acc: 0.4565 -- iter: 292/292
--
Training Step: 11  | total loss: [1m[32m0.70796[0m[0m | time: 1.990s
[2K
| Adam | epoch: 002 | loss: 0.70796 - acc: 0.6608 -- iter: 032/292
[A[ATraining Step: 12  | total loss: [1m[32m0.53839[0m[0m | time: 9.929s
[2K
| Adam | epoch: 002 | loss: 0.53839 - acc: 0.7010 -- iter: 064/292
[A[ATraining Step: 13  | total loss: [1m[32m0.43989[0m[0m | time: 18.848s
[2K
| Adam | epoch: 002 | loss: 0.43989 - acc: 0.7622 -- iter: 096/292
[A[ATraining Step: 14  | total loss: [1m[32m0.39982[0m[0m | time: 95.392s
[2K
| Adam | epoch: 002 | loss: 0.39982 - acc: 0.7827 -- iter: 128/292
[A[ATraining Step: 15  | total loss: [1m[32m0.40689[0m[0m | time: 202.437s
[2K
| Adam | epoch: 002 | loss: 0.40689 - acc: 0.8188 -- iter: 160/292
[A[ATraining Step: 16  | total loss: [1m[32m0.36597[0m[0m | time: 312.378s
[2K
| Adam | epoch: 002 | loss: 0.36597 - acc: 0.8516 -- iter: 192/292
[A[ATraining Step: 17  | total loss: [1m[32m0.31819[0m[0m | time: 333.148s
[2K
| Adam | epoch: 002 | loss: 0.31819 - acc: 0.8600 -- iter: 224/292
[A[ATraining Step: 18  | total loss: [1m[32m0.30919[0m[0m | time: 346.971s
[2K
| Adam | epoch: 002 | loss: 0.30919 - acc: 0.8544 -- iter: 256/292
[A[ATraining Step: 19  | total loss: [1m[32m0.27019[0m[0m | time: 364.368s
[2K
| Adam | epoch: 002 | loss: 0.27019 - acc: 0.8821 -- iter: 288/292
[A[ATraining Step: 20  | total loss: [1m[32m0.31580[0m[0m | time: 385.098s
[2K
| Adam | epoch: 002 | loss: 0.31580 - acc: 0.8798 | val_loss: 1.20843 - val_acc: 0.4565 -- iter: 292/292
--
Training Step: 21  | total loss: [1m[32m0.36197[0m[0m | time: 3.045s
[2K
| Adam | epoch: 003 | loss: 0.36197 - acc: 0.8589 -- iter: 032/292
[A[ATraining Step: 22  | total loss: [1m[32m0.33362[0m[0m | time: 6.354s
[2K
| Adam | epoch: 003 | loss: 0.33362 - acc: 0.8262 -- iter: 064/292
[A[ATraining Step: 23  | total loss: [1m[32m0.80922[0m[0m | time: 16.199s
[2K
| Adam | epoch: 003 | loss: 0.80922 - acc: 0.8041 -- iter: 096/292
[A[ATraining Step: 24  | total loss: [1m[32m0.64426[0m[0m | time: 25.503s
[2K
| Adam | epoch: 003 | loss: 0.64426 - acc: 0.8240 -- iter: 128/292
[A[ATraining Step: 25  | total loss: [1m[32m0.56113[0m[0m | time: 36.313s
[2K
| Adam | epoch: 003 | loss: 0.56113 - acc: 0.8209 -- iter: 160/292
[A[ATraining Step: 26  | total loss: [1m[32m0.44654[0m[0m | time: 44.488s
[2K
| Adam | epoch: 003 | loss: 0.44654 - acc: 0.8683 -- iter: 192/292
[A[ATraining Step: 27  | total loss: [1m[32m0.36692[0m[0m | time: 52.508s
[2K
| Adam | epoch: 003 | loss: 0.36692 - acc: 0.8861 -- iter: 224/292
[A[ATraining Step: 28  | total loss: [1m[32m0.29606[0m[0m | time: 60.576s
[2K
| Adam | epoch: 003 | loss: 0.29606 - acc: 0.9146 -- iter: 256/292
[A[ATraining Step: 29  | total loss: [1m[32m0.31354[0m[0m | time: 68.693s
[2K
| Adam | epoch: 003 | loss: 0.31354 - acc: 0.8973 -- iter: 288/292
[A[ATraining Step: 30  | total loss: [1m[32m0.27491[0m[0m | time: 85.130s
[2K
| Adam | epoch: 003 | loss: 0.27491 - acc: 0.9069 | val_loss: 1.50904 - val_acc: 0.4565 -- iter: 292/292
--
Training Step: 31  | total loss: [1m[32m0.22200[0m[0m | time: 73.992s
[2K
| Adam | epoch: 004 | loss: 0.22200 - acc: 0.9284 -- iter: 032/292
[A[ATraining Step: 32  | total loss: [1m[32m0.20218[0m[0m | time: 77.263s
[2K
| Adam | epoch: 004 | loss: 0.20218 - acc: 0.9374 -- iter: 064/292
[A[ATraining Step: 33  | total loss: [1m[32m0.37270[0m[0m | time: 80.106s
[2K
| Adam | epoch: 004 | loss: 0.37270 - acc: 0.7865 -- iter: 096/292
[A[ATraining Step: 34  | total loss: [1m[32m0.39729[0m[0m | time: 95.563s
[2K
| Adam | epoch: 004 | loss: 0.39729 - acc: 0.7787 -- iter: 128/292
[A[ATraining Step: 35  | total loss: [1m[32m0.33618[0m[0m | time: 111.167s
[2K
| Adam | epoch: 004 | loss: 0.33618 - acc: 0.8119 -- iter: 160/292
[A[ATraining Step: 36  | total loss: [1m[32m0.28777[0m[0m | time: 125.057s
[2K
| Adam | epoch: 004 | loss: 0.28777 - acc: 0.8440 -- iter: 192/292
[A[ATraining Step: 37  | total loss: [1m[32m0.24024[0m[0m | time: 139.593s
[2K
| Adam | epoch: 004 | loss: 0.24024 - acc: 0.8752 -- iter: 224/292
[A[ATraining Step: 38  | total loss: [1m[32m0.25128[0m[0m | time: 166.339s
[2K
| Adam | epoch: 004 | loss: 0.25128 - acc: 0.8874 -- iter: 256/292
[A[ATraining Step: 39  | total loss: [1m[32m0.21294[0m[0m | time: 182.644s
[2K
| Adam | epoch: 004 | loss: 0.21294 - acc: 0.9090 -- iter: 288/292
[A[ATraining Step: 40  | total loss: [1m[32m0.17568[0m[0m | time: 200.181s
[2K
| Adam | epoch: 004 | loss: 0.17568 - acc: 0.9260 | val_loss: 0.58536 - val_acc: 0.6630 -- iter: 292/292
--
Training Step: 41  | total loss: [1m[32m0.14848[0m[0m | time: 24.922s
[2K
| Adam | epoch: 005 | loss: 0.14848 - acc: 0.9396 -- iter: 032/292
[A[ATraining Step: 42  | total loss: [1m[32m0.12974[0m[0m | time: 42.607s
[2K
| Adam | epoch: 005 | loss: 0.12974 - acc: 0.9505 -- iter: 064/292
[A[ATraining Step: 43  | total loss: [1m[32m0.11574[0m[0m | time: 45.978s
[2K
| Adam | epoch: 005 | loss: 0.11574 - acc: 0.9592 -- iter: 096/292
[A[ATraining Step: 44  | total loss: [1m[32m0.10116[0m[0m | time: 49.490s
[2K
| Adam | epoch: 005 | loss: 0.10116 - acc: 0.9663 -- iter: 128/292
[A[ATraining Step: 45  | total loss: [1m[32m0.48874[0m[0m | time: 155.344s
[2K
| Adam | epoch: 005 | loss: 0.48874 - acc: 0.9296 -- iter: 160/292
[A[ATraining Step: 46  | total loss: [1m[32m0.40847[0m[0m | time: 215.448s
[2K
| Adam | epoch: 005 | loss: 0.40847 - acc: 0.9413 -- iter: 192/292
[A[ATraining Step: 47  | total loss: [1m[32m0.35481[0m[0m | time: 294.614s
[2K
| Adam | epoch: 005 | loss: 0.35481 - acc: 0.9458 -- iter: 224/292
[A[ATraining Step: 48  | total loss: [1m[32m0.31869[0m[0m | time: 375.523s
[2K
| Adam | epoch: 005 | loss: 0.31869 - acc: 0.9445 -- iter: 256/292
[A[ATraining Step: 49  | total loss: [1m[32m0.28555[0m[0m | time: 416.487s
[2K
| Adam | epoch: 005 | loss: 0.28555 - acc: 0.9434 -- iter: 288/292
[A[ATraining Step: 50  | total loss: [1m[32m0.24443[0m[0m | time: 439.147s
[2K
| Adam | epoch: 005 | loss: 0.24443 - acc: 0.9521 | val_loss: 0.51257 - val_acc: 0.7609 -- iter: 292/292
--
Training Step: 51  | total loss: [1m[32m0.21037[0m[0m | time: 14.300s
[2K
| Adam | epoch: 006 | loss: 0.21037 - acc: 0.9594 -- iter: 032/292
[A[ATraining Step: 52  | total loss: [1m[32m0.18938[0m[0m | time: 28.196s
[2K
| Adam | epoch: 006 | loss: 0.18938 - acc: 0.9608 -- iter: 064/292
[A[ATraining Step: 53  | total loss: [1m[32m0.16259[0m[0m | time: 43.006s
[2K
| Adam | epoch: 006 | loss: 0.16259 - acc: 0.9666 -- iter: 096/292
[A[ATraining Step: 54  | total loss: [1m[32m0.17695[0m[0m | time: 46.554s
[2K
| Adam | epoch: 006 | loss: 0.17695 - acc: 0.9669 -- iter: 128/292
[A[ATraining Step: 55  | total loss: [1m[32m0.50467[0m[0m | time: 50.066s
[2K
| Adam | epoch: 006 | loss: 0.50467 - acc: 0.9002 -- iter: 160/292
[A[ATraining Step: 56  | total loss: [1m[32m0.63308[0m[0m | time: 88.511s
[2K
| Adam | epoch: 006 | loss: 0.63308 - acc: 0.8439 -- iter: 192/292
[A[ATraining Step: 57  | total loss: [1m[32m0.56979[0m[0m | time: 123.779s
[2K
| Adam | epoch: 006 | loss: 0.56979 - acc: 0.8526 -- iter: 224/292
[A[ATraining Step: 58  | total loss: [1m[32m0.50425[0m[0m | time: 162.202s
[2K
| Adam | epoch: 006 | loss: 0.50425 - acc: 0.8684 -- iter: 256/292
[A[ATraining Step: 59  | total loss: [1m[32m0.46306[0m[0m | time: 194.380s
[2K
| Adam | epoch: 006 | loss: 0.46306 - acc: 0.8819 -- iter: 288/292
[A[ATraining Step: 60  | total loss: [1m[32m0.42431[0m[0m | time: 250.433s
[2K
| Adam | epoch: 006 | loss: 0.42431 - acc: 0.8851 | val_loss: 1.31449 - val_acc: 0.5870 -- iter: 292/292
--
Training Step: 61  | total loss: [1m[32m0.38697[0m[0m | time: 8.259s
[2K
| Adam | epoch: 007 | loss: 0.38697 - acc: 0.8919 -- iter: 032/292
[A[ATraining Step: 62  | total loss: [1m[32m0.35183[0m[0m | time: 16.582s
[2K
| Adam | epoch: 007 | loss: 0.35183 - acc: 0.9018 -- iter: 064/292
[A[ATraining Step: 63  | total loss: [1m[32m0.36505[0m[0m | time: 26.096s
[2K
| Adam | epoch: 007 | loss: 0.36505 - acc: 0.8945 -- iter: 096/292
[A[ATraining Step: 64  | total loss: [1m[32m0.32745[0m[0m | time: 38.594s
[2K
| Adam | epoch: 007 | loss: 0.32745 - acc: 0.9077 -- iter: 128/292
[A[ATraining Step: 65  | total loss: [1m[32m0.29509[0m[0m | time: 41.151s
[2K
| Adam | epoch: 007 | loss: 0.29509 - acc: 0.9190 -- iter: 160/292
[A[ATraining Step: 66  | total loss: [1m[32m0.26153[0m[0m | time: 44.324s
[2K
| Adam | epoch: 007 | loss: 0.26153 - acc: 0.9289 -- iter: 192/292
[A[ATraining Step: 67  | total loss: [1m[32m0.23254[0m[0m | time: 55.714s
[2K
| Adam | epoch: 007 | loss: 0.23254 - acc: 0.9374 -- iter: 224/292
[A[ATraining Step: 68  | total loss: [1m[32m0.21784[0m[0m | time: 70.850s
[2K
| Adam | epoch: 007 | loss: 0.21784 - acc: 0.9374 -- iter: 256/292
[A[ATraining Step: 69  | total loss: [1m[32m0.19935[0m[0m | time: 83.559s
[2K
| Adam | epoch: 007 | loss: 0.19935 - acc: 0.9447 -- iter: 288/292
[A[ATraining Step: 70  | total loss: [1m[32m0.18784[0m[0m | time: 110.120s
[2K
| Adam | epoch: 007 | loss: 0.18784 - acc: 0.9475 | val_loss: 0.51611 - val_acc: 0.8587 -- iter: 292/292
--
Training Step: 71  | total loss: [1m[32m0.18338[0m[0m | time: 44.143s
[2K
| Adam | epoch: 008 | loss: 0.18338 - acc: 0.9464 -- iter: 032/292
[A[ATraining Step: 72  | total loss: [1m[32m0.16862[0m[0m | time: 59.074s
[2K
| Adam | epoch: 008 | loss: 0.16862 - acc: 0.9524 -- iter: 064/292
[A[ATraining Step: 73  | total loss: [1m[32m0.16067[0m[0m | time: 70.168s
[2K
| Adam | epoch: 008 | loss: 0.16067 - acc: 0.9542 -- iter: 096/292
[A[ATraining Step: 74  | total loss: [1m[32m0.15401[0m[0m | time: 81.489s
[2K
| Adam | epoch: 008 | loss: 0.15401 - acc: 0.9524 -- iter: 128/292
[A[ATraining Step: 75  | total loss: [1m[32m0.14442[0m[0m | time: 92.859s
[2K
| Adam | epoch: 008 | loss: 0.14442 - acc: 0.9542 -- iter: 160/292
[A[ATraining Step: 76  | total loss: [1m[32m0.13274[0m[0m | time: 96.905s
[2K
| Adam | epoch: 008 | loss: 0.13274 - acc: 0.9591 -- iter: 192/292
[A[ATraining Step: 77  | total loss: [1m[32m0.24299[0m[0m | time: 100.227s
[2K
| Adam | epoch: 008 | loss: 0.24299 - acc: 0.9105 -- iter: 224/292
[A[ATraining Step: 78  | total loss: [1m[32m0.35756[0m[0m | time: 121.250s
[2K
| Adam | epoch: 008 | loss: 0.35756 - acc: 0.8937 -- iter: 256/292
[A[ATraining Step: 79  | total loss: [1m[32m0.32982[0m[0m | time: 139.580s
[2K
| Adam | epoch: 008 | loss: 0.32982 - acc: 0.9014 -- iter: 288/292
[A[ATraining Step: 80  | total loss: [1m[32m0.30624[0m[0m | time: 164.136s
[2K
| Adam | epoch: 008 | loss: 0.30624 - acc: 0.9051 | val_loss: 3.95057 - val_acc: 0.4565 -- iter: 292/292
--
Training Step: 81  | total loss: [1m[32m0.28898[0m[0m | time: 20.497s
[2K
| Adam | epoch: 009 | loss: 0.28898 - acc: 0.9052 -- iter: 032/292
[A[ATraining Step: 82  | total loss: [1m[32m0.26194[0m[0m | time: 43.326s
[2K
| Adam | epoch: 009 | loss: 0.26194 - acc: 0.9147 -- iter: 064/292
[A[ATraining Step: 83  | total loss: [1m[32m0.23940[0m[0m | time: 62.530s
[2K
| Adam | epoch: 009 | loss: 0.23940 - acc: 0.9232 -- iter: 096/292
[A[ATraining Step: 84  | total loss: [1m[32m0.21665[0m[0m | time: 80.607s
[2K
| Adam | epoch: 009 | loss: 0.21665 - acc: 0.9309 -- iter: 128/292
[A[ATraining Step: 85  | total loss: [1m[32m0.19717[0m[0m | time: 97.430s
[2K
| Adam | epoch: 009 | loss: 0.19717 - acc: 0.9378 -- iter: 160/292
[A[ATraining Step: 86  | total loss: [1m[32m0.18256[0m[0m | time: 108.879s
[2K
| Adam | epoch: 009 | loss: 0.18256 - acc: 0.9440 -- iter: 192/292
[A[ATraining Step: 87  | total loss: [1m[32m0.16777[0m[0m | time: 111.153s
[2K
| Adam | epoch: 009 | loss: 0.16777 - acc: 0.9465 -- iter: 224/292
[A[ATraining Step: 88  | total loss: [1m[32m0.15123[0m[0m | time: 113.318s
[2K
| Adam | epoch: 009 | loss: 0.15123 - acc: 0.9519 -- iter: 256/292
[A[ATraining Step: 89  | total loss: [1m[32m0.48912[0m[0m | time: 124.415s
[2K
| Adam | epoch: 009 | loss: 0.48912 - acc: 0.9067 -- iter: 288/292
[A[ATraining Step: 90  | total loss: [1m[32m0.44530[0m[0m | time: 148.858s
[2K
| Adam | epoch: 009 | loss: 0.44530 - acc: 0.9129 | val_loss: 0.56963 - val_acc: 0.8370 -- iter: 292/292
--
Training Step: 91  | total loss: [1m[32m0.43914[0m[0m | time: 32.911s
[2K
| Adam | epoch: 010 | loss: 0.43914 - acc: 0.9028 -- iter: 032/292
[A[ATraining Step: 92  | total loss: [1m[32m0.40082[0m[0m | time: 66.332s
[2K
| Adam | epoch: 010 | loss: 0.40082 - acc: 0.9094 -- iter: 064/292
[A[ATraining Step: 93  | total loss: [1m[32m0.37443[0m[0m | time: 90.180s
[2K
| Adam | epoch: 010 | loss: 0.37443 - acc: 0.9122 -- iter: 096/292
[A[ATraining Step: 94  | total loss: [1m[32m0.34400[0m[0m | time: 126.911s
[2K
| Adam | epoch: 010 | loss: 0.34400 - acc: 0.9179 -- iter: 128/292
[A[ATraining Step: 95  | total loss: [1m[32m0.31991[0m[0m | time: 186.969s
[2K
| Adam | epoch: 010 | loss: 0.31991 - acc: 0.9199 -- iter: 160/292
[A[ATraining Step: 96  | total loss: [1m[32m0.33290[0m[0m | time: 206.099s
[2K
| Adam | epoch: 010 | loss: 0.33290 - acc: 0.9185 -- iter: 192/292
[A[ATraining Step: 97  | total loss: [1m[32m0.30363[0m[0m | time: 221.726s
[2K
| Adam | epoch: 010 | loss: 0.30363 - acc: 0.9266 -- iter: 224/292
[A[ATraining Step: 98  | total loss: [1m[32m0.27546[0m[0m | time: 225.498s
[2K
| Adam | epoch: 010 | loss: 0.27546 - acc: 0.9340 -- iter: 256/292
[A[ATraining Step: 99  | total loss: [1m[32m0.24960[0m[0m | time: 229.334s
[2K
| Adam | epoch: 010 | loss: 0.24960 - acc: 0.9406 -- iter: 288/292
[A[ATraining Step: 100  | total loss: [1m[32m0.43362[0m[0m | time: 257.172s
[2K
| Adam | epoch: 010 | loss: 0.43362 - acc: 0.9215 | val_loss: 9.35542 - val_acc: 0.5435 -- iter: 292/292
--
Training Step: 101  | total loss: [1m[32m0.39293[0m[0m | time: 16.559s
[2K
| Adam | epoch: 011 | loss: 0.39293 - acc: 0.9294 -- iter: 032/292
[A[ATraining Step: 102  | total loss: [1m[32m0.36481[0m[0m | time: 32.370s
[2K
| Adam | epoch: 011 | loss: 0.36481 - acc: 0.9333 -- iter: 064/292
[A[ATraining Step: 103  | total loss: [1m[32m0.34736[0m[0m | time: 50.588s
[2K
| Adam | epoch: 011 | loss: 0.34736 - acc: 0.9275 -- iter: 096/292
[A[ATraining Step: 104  | total loss: [1m[32m0.33089[0m[0m | time: 66.470s
[2K
| Adam | epoch: 011 | loss: 0.33089 - acc: 0.9316 -- iter: 128/292
[A[ATraining Step: 105  | total loss: [1m[32m0.29936[0m[0m | time: 81.668s
[2K
| Adam | epoch: 011 | loss: 0.29936 - acc: 0.9384 -- iter: 160/292
[A[ATraining Step: 106  | total loss: [1m[32m0.27286[0m[0m | time: 97.152s
[2K
| Adam | epoch: 011 | loss: 0.27286 - acc: 0.9446 -- iter: 192/292
[A[ATraining Step: 107  | total loss: [1m[32m0.26264[0m[0m | time: 112.838s
[2K
| Adam | epoch: 011 | loss: 0.26264 - acc: 0.9408 -- iter: 224/292
[A[ATraining Step: 108  | total loss: [1m[32m0.24456[0m[0m | time: 129.503s
[2K
| Adam | epoch: 011 | loss: 0.24456 - acc: 0.9436 -- iter: 256/292
[A[ATraining Step: 109  | total loss: [1m[32m0.23170[0m[0m | time: 134.014s
[2K
| Adam | epoch: 011 | loss: 0.23170 - acc: 0.9430 -- iter: 288/292
[A[ATraining Step: 110  | total loss: [1m[32m0.21878[0m[0m | time: 149.066s
[2K
| Adam | epoch: 011 | loss: 0.21878 - acc: 0.9487 | val_loss: 4.44675 - val_acc: 0.4565 -- iter: 292/292
--
Training Step: 111  | total loss: [1m[32m0.49834[0m[0m | time: 15.812s
[2K
| Adam | epoch: 012 | loss: 0.49834 - acc: 0.9038 -- iter: 032/292
[A[ATraining Step: 112  | total loss: [1m[32m0.45467[0m[0m | time: 28.772s
[2K
| Adam | epoch: 012 | loss: 0.45467 - acc: 0.9103 -- iter: 064/292
[A[ATraining Step: 113  | total loss: [1m[32m0.41519[0m[0m | time: 63.887s
[2K
| Adam | epoch: 012 | loss: 0.41519 - acc: 0.9161 -- iter: 096/292
[A[ATraining Step: 114  | total loss: [1m[32m0.37680[0m[0m | time: 91.928s
[2K
| Adam | epoch: 012 | loss: 0.37680 - acc: 0.9245 -- iter: 128/292
[A[ATraining Step: 115  | total loss: [1m[32m0.34487[0m[0m | time: 110.723s
[2K
| Adam | epoch: 012 | loss: 0.34487 - acc: 0.9321 -- iter: 160/292
[A[ATraining Step: 116  | total loss: [1m[32m0.31550[0m[0m | time: 129.550s
[2K
| Adam | epoch: 012 | loss: 0.31550 - acc: 0.9389 -- iter: 192/292
[A[ATraining Step: 117  | total loss: [1m[32m0.28660[0m[0m | time: 148.896s
[2K
| Adam | epoch: 012 | loss: 0.28660 - acc: 0.9450 -- iter: 224/292
[A[ATraining Step: 118  | total loss: [1m[32m0.26173[0m[0m | time: 167.997s
[2K
| Adam | epoch: 012 | loss: 0.26173 - acc: 0.9505 -- iter: 256/292
[A[ATraining Step: 119  | total loss: [1m[32m0.23770[0m[0m | time: 185.527s
[2K
| Adam | epoch: 012 | loss: 0.23770 - acc: 0.9554 -- iter: 288/292
[A[ATraining Step: 120  | total loss: [1m[32m0.21880[0m[0m | time: 199.921s
[2K
| Adam | epoch: 012 | loss: 0.21880 - acc: 0.9599 | val_loss: 1.56541 - val_acc: 0.6087 -- iter: 292/292
--
Training Step: 121  | total loss: [1m[32m0.25415[0m[0m | time: 4.193s
[2K
| Adam | epoch: 013 | loss: 0.25415 - acc: 0.9139 -- iter: 032/292
[A[ATraining Step: 122  | total loss: [1m[32m0.29358[0m[0m | time: 23.789s
[2K
| Adam | epoch: 013 | loss: 0.29358 - acc: 0.8975 -- iter: 064/292
[A[ATraining Step: 123  | total loss: [1m[32m0.26783[0m[0m | time: 41.382s
[2K
| Adam | epoch: 013 | loss: 0.26783 - acc: 0.9078 -- iter: 096/292
[A[ATraining Step: 124  | total loss: [1m[32m0.24341[0m[0m | time: 54.612s
[2K
| Adam | epoch: 013 | loss: 0.24341 - acc: 0.9170 -- iter: 128/292
[A[ATraining Step: 125  | total loss: [1m[32m0.22049[0m[0m | time: 70.393s
[2K
| Adam | epoch: 013 | loss: 0.22049 - acc: 0.9253 -- iter: 160/292
[A[ATraining Step: 126  | total loss: [1m[32m0.20474[0m[0m | time: 88.429s
[2K
| Adam | epoch: 013 | loss: 0.20474 - acc: 0.9296 -- iter: 192/292
[A[ATraining Step: 127  | total loss: [1m[32m0.19571[0m[0m | time: 106.560s
[2K
| Adam | epoch: 013 | loss: 0.19571 - acc: 0.9335 -- iter: 224/292
[A[ATraining Step: 128  | total loss: [1m[32m0.18170[0m[0m | time: 122.869s
[2K
| Adam | epoch: 013 | loss: 0.18170 - acc: 0.9402 -- iter: 256/292
[A[ATraining Step: 129  | total loss: [1m[32m0.16538[0m[0m | time: 139.342s
[2K
| Adam | epoch: 013 | loss: 0.16538 - acc: 0.9462 -- iter: 288/292
[A[ATraining Step: 130  | total loss: [1m[32m0.15980[0m[0m | time: 163.276s
[2K
| Adam | epoch: 013 | loss: 0.15980 - acc: 0.9484 | val_loss: 0.35206 - val_acc: 0.8478 -- iter: 292/292
--
Training Step: 131  | total loss: [1m[32m0.14498[0m[0m | time: 3.385s
[2K
| Adam | epoch: 014 | loss: 0.14498 - acc: 0.9536 -- iter: 032/292
[A[ATraining Step: 132  | total loss: [1m[32m0.13107[0m[0m | time: 7.071s
[2K
| Adam | epoch: 014 | loss: 0.13107 - acc: 0.9582 -- iter: 064/292
[A[ATraining Step: 133  | total loss: [1m[32m0.29667[0m[0m | time: 22.516s
[2K
| Adam | epoch: 014 | loss: 0.29667 - acc: 0.9124 -- iter: 096/292
[A[ATraining Step: 134  | total loss: [1m[32m0.26824[0m[0m | time: 38.793s
[2K
| Adam | epoch: 014 | loss: 0.26824 - acc: 0.9212 -- iter: 128/292
[A[ATraining Step: 135  | total loss: [1m[32m0.24333[0m[0m | time: 53.230s
[2K
| Adam | epoch: 014 | loss: 0.24333 - acc: 0.9290 -- iter: 160/292
[A[ATraining Step: 136  | total loss: [1m[32m0.22796[0m[0m | time: 63.939s
[2K
| Adam | epoch: 014 | loss: 0.22796 - acc: 0.9299 -- iter: 192/292
[A[ATraining Step: 137  | total loss: [1m[32m0.21259[0m[0m | time: 74.410s
[2K
| Adam | epoch: 014 | loss: 0.21259 - acc: 0.9338 -- iter: 224/292
[A[ATraining Step: 138  | total loss: [1m[32m0.19795[0m[0m | time: 92.788s
[2K
| Adam | epoch: 014 | loss: 0.19795 - acc: 0.9373 -- iter: 256/292
[A[ATraining Step: 139  | total loss: [1m[32m0.18027[0m[0m | time: 107.718s
[2K
| Adam | epoch: 014 | loss: 0.18027 - acc: 0.9435 -- iter: 288/292
[A[ATraining Step: 140  | total loss: [1m[32m0.20167[0m[0m | time: 148.044s
[2K
| Adam | epoch: 014 | loss: 0.20167 - acc: 0.9461 | val_loss: 1.12054 - val_acc: 0.6957 -- iter: 292/292
--
Training Step: 141  | total loss: [1m[32m0.18922[0m[0m | time: 15.200s
[2K
| Adam | epoch: 015 | loss: 0.18922 - acc: 0.9483 -- iter: 032/292
[A[ATraining Step: 142  | total loss: [1m[32m0.17196[0m[0m | time: 18.932s
[2K
| Adam | epoch: 015 | loss: 0.17196 - acc: 0.9535 -- iter: 064/292
[A[ATraining Step: 143  | total loss: [1m[32m0.15589[0m[0m | time: 22.222s
[2K
| Adam | epoch: 015 | loss: 0.15589 - acc: 0.9582 -- iter: 096/292
[A[ATraining Step: 144  | total loss: [1m[32m0.14167[0m[0m | time: 36.852s
[2K
| Adam | epoch: 015 | loss: 0.14167 - acc: 0.9623 -- iter: 128/292
[A[ATraining Step: 145  | total loss: [1m[32m0.13033[0m[0m | time: 51.275s
[2K
| Adam | epoch: 015 | loss: 0.13033 - acc: 0.9661 -- iter: 160/292
[A[ATraining Step: 146  | total loss: [1m[32m0.12212[0m[0m | time: 66.912s
[2K
| Adam | epoch: 015 | loss: 0.12212 - acc: 0.9695 -- iter: 192/292
[A[ATraining Step: 147  | total loss: [1m[32m0.11053[0m[0m | time: 83.066s
[2K
| Adam | epoch: 015 | loss: 0.11053 - acc: 0.9725 -- iter: 224/292
[A[ATraining Step: 148  | total loss: [1m[32m0.13036[0m[0m | time: 93.469s
[2K
| Adam | epoch: 015 | loss: 0.13036 - acc: 0.9628 -- iter: 256/292
[A[ATraining Step: 149  | total loss: [1m[32m0.11827[0m[0m | time: 104.128s
[2K
| Adam | epoch: 015 | loss: 0.11827 - acc: 0.9665 -- iter: 288/292
[A[ATraining Step: 150  | total loss: [1m[32m0.11636[0m[0m | time: 127.012s
[2K
| Adam | epoch: 015 | loss: 0.11636 - acc: 0.9667 | val_loss: 1.24192 - val_acc: 0.6848 -- iter: 292/292
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9500000000000001
Validation AUPRC:0.9531642437187593
Test AUC:0.9763257575757577
Test AUPRC:0.9798033270722198
BestTestF1Score	0.87	0.78	0.88	0.97	0.79	38	1	43	10	0.02
BestTestMCCScore	0.87	0.78	0.88	0.97	0.79	38	1	43	10	0.02
BestTestAccuracyScore	0.87	0.78	0.88	0.97	0.79	38	1	43	10	0.02
BestValidationF1Score	0.84	0.74	0.87	0.94	0.76	32	2	48	10	0.02
BestValidationMCC	0.84	0.74	0.87	0.94	0.76	32	2	48	10	0.02
BestValidationAccuracy	0.84	0.74	0.87	0.94	0.76	32	2	48	10	0.02
TestPredictions (Threshold:0.02)
CHEMBL3677853,TN,INACT,0.0	CHEMBL22704,TN,INACT,0.0	CHEMBL1917112,TN,INACT,0.0	CHEMBL114903,TN,INACT,0.0	CHEMBL2380883,TN,INACT,0.0	CHEMBL1170569,TP,ACT,0.550000011920929	CHEMBL590614,FN,ACT,0.0	CHEMBL1215393,TP,ACT,0.8199999928474426	CHEMBL208957,TN,INACT,0.0	CHEMBL3093776,TP,ACT,0.4300000071525574	CHEMBL536308,TP,ACT,0.4000000059604645	CHEMBL558988,TP,ACT,0.2199999988079071	CHEMBL3613811,FN,ACT,0.0	CHEMBL1777855,TN,INACT,0.0	CHEMBL2380915,TN,INACT,0.0	CHEMBL519199,TN,INACT,0.0	CHEMBL182968,FN,ACT,0.009999999776482582	CHEMBL522211,FP,INACT,0.03999999910593033	CHEMBL317713,TN,INACT,0.0	CHEMBL1171599,TP,ACT,0.8399999737739563	CHEMBL225989,TP,ACT,0.3700000047683716	CHEMBL3113257,TN,INACT,0.0	CHEMBL473705,TN,INACT,0.0	CHEMBL226091,TP,ACT,0.9300000071525574	CHEMBL1098851,TP,ACT,0.03999999910593033	CHEMBL1360994,TN,INACT,0.0	CHEMBL224304,FN,ACT,0.0	CHEMBL3734777,TN,INACT,0.0	CHEMBL3085879,TN,INACT,0.0	CHEMBL537891,TP,ACT,0.05999999865889549	CHEMBL1170571,TP,ACT,0.3499999940395355	CHEMBL1645172,FN,ACT,0.019999999552965164	CHEMBL1819522,TP,ACT,0.6299999952316284	CHEMBL425478,TP,ACT,0.05999999865889549	CHEMBL1819521,TP,ACT,0.15000000596046448	CHEMBL2003901,TN,INACT,0.0	CHEMBL224246,TP,ACT,0.07000000029802322	CHEMBL224227,TP,ACT,0.23000000417232513	CHEMBL214951,TP,ACT,0.1599999964237213	CHEMBL1819509,TP,ACT,0.17000000178813934	CHEMBL543152,TN,INACT,0.0	CHEMBL239375,TP,ACT,0.8399999737739563	CHEMBL3233080,TP,ACT,0.5899999737739563	CHEMBL227905,TP,ACT,0.2199999988079071	CHEMBL3613808,FN,ACT,0.0	CHEMBL2334599,TP,ACT,0.05999999865889549	CHEMBL224907,TP,ACT,0.23000000417232513	CHEMBL741,TN,INACT,0.0	CHEMBL3337593,TN,INACT,0.009999999776482582	CHEMBL2334271,FN,ACT,0.009999999776482582	CHEMBL43961,TN,INACT,0.0	CHEMBL536307,TP,ACT,0.09000000357627869	CHEMBL2380882,TN,INACT,0.0	CHEMBL2409410,TN,INACT,0.0	CHEMBL360359,FN,ACT,0.0	CHEMBL558,TN,INACT,0.0	CHEMBL1645161,TP,ACT,0.6600000262260437	CHEMBL2409402,TN,INACT,0.0	CHEMBL26490,TN,INACT,0.0	CHEMBL223908,TP,ACT,0.6399999856948853	CHEMBL3092995,TN,INACT,0.0	CHEMBL537670,TP,ACT,0.05999999865889549	CHEMBL294290,TN,INACT,0.0	CHEMBL225744,TP,ACT,0.5699999928474426	CHEMBL3617064,TN,INACT,0.0	CHEMBL228257,TP,ACT,0.11999999731779099	CHEMBL1917113,TN,INACT,0.0	CHEMBL1422664,TN,INACT,0.0	CHEMBL2380898,TN,INACT,0.0	CHEMBL331179,TN,INACT,0.019999999552965164	CHEMBL590128,TP,ACT,0.12999999523162842	CHEMBL1409121,TN,INACT,0.0	CHEMBL1819499,TP,ACT,0.8700000047683716	CHEMBL3416887,TN,INACT,0.0	CHEMBL226041,TP,ACT,0.17000000178813934	CHEMBL389861,TP,ACT,0.7599999904632568	CHEMBL1645167,FN,ACT,0.009999999776482582	CHEMBL1215249,TP,ACT,0.6700000166893005	CHEMBL1171952,TP,ACT,0.6800000071525574	CHEMBL2334601,TP,ACT,0.03999999910593033	CHEMBL3084981,TN,INACT,0.0	CHEMBL495792,TN,INACT,0.0	CHEMBL3613804,FN,ACT,0.0	CHEMBL3085154,TN,INACT,0.0	CHEMBL534967,TN,INACT,0.0	CHEMBL146855,TN,INACT,0.0	CHEMBL3233076,TP,ACT,0.23999999463558197	CHEMBL2443262,TN,INACT,0.0	CHEMBL512935,TN,INACT,0.0	CHEMBL1413681,TN,INACT,0.0	CHEMBL388287,TP,ACT,0.12999999523162842	CHEMBL2151778,TN,INACT,0.0	

