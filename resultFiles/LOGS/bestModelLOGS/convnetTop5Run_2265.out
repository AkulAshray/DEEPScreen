CNNModel CHEMBL216 adam 0.0001 30 256 0 0.8 False True
Number of active compounds :	1166
Number of inactive compounds :	1166
---------------------------------
Run id: CNNModel_CHEMBL216_adam_0.0001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL216_adam_0.0001_30_256_0.8_True/
---------------------------------
Training samples: 1468
Validation samples: 459
--
Training Step: 1  | time: 1.172s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1468
[A[ATraining Step: 2  | total loss: [1m[32m0.62376[0m[0m | time: 2.047s
[2K
| Adam | epoch: 001 | loss: 0.62376 - acc: 0.4781 -- iter: 0064/1468
[A[ATraining Step: 3  | total loss: [1m[32m0.67988[0m[0m | time: 2.938s
[2K
| Adam | epoch: 001 | loss: 0.67988 - acc: 0.5727 -- iter: 0096/1468
[A[ATraining Step: 4  | total loss: [1m[32m0.69000[0m[0m | time: 3.929s
[2K
| Adam | epoch: 001 | loss: 0.69000 - acc: 0.4947 -- iter: 0128/1468
[A[ATraining Step: 5  | total loss: [1m[32m0.69305[0m[0m | time: 4.842s
[2K
| Adam | epoch: 001 | loss: 0.69305 - acc: 0.4335 -- iter: 0160/1468
[A[ATraining Step: 6  | total loss: [1m[32m0.69315[0m[0m | time: 5.761s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.4562 -- iter: 0192/1468
[A[ATraining Step: 7  | total loss: [1m[32m0.69420[0m[0m | time: 6.637s
[2K
| Adam | epoch: 001 | loss: 0.69420 - acc: 0.4075 -- iter: 0224/1468
[A[ATraining Step: 8  | total loss: [1m[32m0.69272[0m[0m | time: 7.747s
[2K
| Adam | epoch: 001 | loss: 0.69272 - acc: 0.5298 -- iter: 0256/1468
[A[ATraining Step: 9  | total loss: [1m[32m0.69320[0m[0m | time: 8.928s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.4809 -- iter: 0288/1468
[A[ATraining Step: 10  | total loss: [1m[32m0.69375[0m[0m | time: 9.752s
[2K
| Adam | epoch: 001 | loss: 0.69375 - acc: 0.3811 -- iter: 0320/1468
[A[ATraining Step: 11  | total loss: [1m[32m0.69337[0m[0m | time: 10.674s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.4966 -- iter: 0352/1468
[A[ATraining Step: 12  | total loss: [1m[32m0.69316[0m[0m | time: 11.602s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5122 -- iter: 0384/1468
[A[ATraining Step: 13  | total loss: [1m[32m0.69318[0m[0m | time: 12.564s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.4936 -- iter: 0416/1468
[A[ATraining Step: 14  | total loss: [1m[32m0.69311[0m[0m | time: 13.487s
[2K
| Adam | epoch: 001 | loss: 0.69311 - acc: 0.5218 -- iter: 0448/1468
[A[ATraining Step: 15  | total loss: [1m[32m0.69297[0m[0m | time: 14.447s
[2K
| Adam | epoch: 001 | loss: 0.69297 - acc: 0.5377 -- iter: 0480/1468
[A[ATraining Step: 16  | total loss: [1m[32m0.69288[0m[0m | time: 15.429s
[2K
| Adam | epoch: 001 | loss: 0.69288 - acc: 0.5353 -- iter: 0512/1468
[A[ATraining Step: 17  | total loss: [1m[32m0.69316[0m[0m | time: 16.299s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5001 -- iter: 0544/1468
[A[ATraining Step: 18  | total loss: [1m[32m0.69325[0m[0m | time: 17.261s
[2K
| Adam | epoch: 001 | loss: 0.69325 - acc: 0.5001 -- iter: 0576/1468
[A[ATraining Step: 19  | total loss: [1m[32m0.69288[0m[0m | time: 18.228s
[2K
| Adam | epoch: 001 | loss: 0.69288 - acc: 0.5209 -- iter: 0608/1468
[A[ATraining Step: 20  | total loss: [1m[32m0.69233[0m[0m | time: 19.147s
[2K
| Adam | epoch: 001 | loss: 0.69233 - acc: 0.5543 -- iter: 0640/1468
[A[ATraining Step: 21  | total loss: [1m[32m0.69254[0m[0m | time: 20.070s
[2K
| Adam | epoch: 001 | loss: 0.69254 - acc: 0.5375 -- iter: 0672/1468
[A[ATraining Step: 22  | total loss: [1m[32m0.69285[0m[0m | time: 20.987s
[2K
| Adam | epoch: 001 | loss: 0.69285 - acc: 0.5169 -- iter: 0704/1468
[A[ATraining Step: 23  | total loss: [1m[32m0.69334[0m[0m | time: 21.886s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.4938 -- iter: 0736/1468
[A[ATraining Step: 24  | total loss: [1m[32m0.69279[0m[0m | time: 22.808s
[2K
| Adam | epoch: 001 | loss: 0.69279 - acc: 0.5219 -- iter: 0768/1468
[A[ATraining Step: 25  | total loss: [1m[32m0.69246[0m[0m | time: 23.720s
[2K
| Adam | epoch: 001 | loss: 0.69246 - acc: 0.5330 -- iter: 0800/1468
[A[ATraining Step: 26  | total loss: [1m[32m0.69256[0m[0m | time: 24.620s
[2K
| Adam | epoch: 001 | loss: 0.69256 - acc: 0.5243 -- iter: 0832/1468
[A[ATraining Step: 27  | total loss: [1m[32m0.69344[0m[0m | time: 25.593s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.4939 -- iter: 0864/1468
[A[ATraining Step: 28  | total loss: [1m[32m0.69294[0m[0m | time: 26.486s
[2K
| Adam | epoch: 001 | loss: 0.69294 - acc: 0.5111 -- iter: 0896/1468
[A[ATraining Step: 29  | total loss: [1m[32m0.69218[0m[0m | time: 27.644s
[2K
| Adam | epoch: 001 | loss: 0.69218 - acc: 0.5312 -- iter: 0928/1468
[A[ATraining Step: 30  | total loss: [1m[32m0.69245[0m[0m | time: 28.428s
[2K
| Adam | epoch: 001 | loss: 0.69245 - acc: 0.5238 -- iter: 0960/1468
[A[ATraining Step: 31  | total loss: [1m[32m0.69306[0m[0m | time: 29.328s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.5111 -- iter: 0992/1468
[A[ATraining Step: 32  | total loss: [1m[32m0.69290[0m[0m | time: 30.249s
[2K
| Adam | epoch: 001 | loss: 0.69290 - acc: 0.5156 -- iter: 1024/1468
[A[ATraining Step: 33  | total loss: [1m[32m0.69350[0m[0m | time: 31.190s
[2K
| Adam | epoch: 001 | loss: 0.69350 - acc: 0.4916 -- iter: 1056/1468
[A[ATraining Step: 34  | total loss: [1m[32m0.69406[0m[0m | time: 32.156s
[2K
| Adam | epoch: 001 | loss: 0.69406 - acc: 0.4800 -- iter: 1088/1468
[A[ATraining Step: 35  | total loss: [1m[32m0.69348[0m[0m | time: 33.079s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.4973 -- iter: 1120/1468
[A[ATraining Step: 36  | total loss: [1m[32m0.69316[0m[0m | time: 34.056s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5106 -- iter: 1152/1468
[A[ATraining Step: 37  | total loss: [1m[32m0.69215[0m[0m | time: 34.983s
[2K
| Adam | epoch: 001 | loss: 0.69215 - acc: 0.5335 -- iter: 1184/1468
[A[ATraining Step: 38  | total loss: [1m[32m0.69198[0m[0m | time: 35.872s
[2K
| Adam | epoch: 001 | loss: 0.69198 - acc: 0.5392 -- iter: 1216/1468
[A[ATraining Step: 39  | total loss: [1m[32m0.69233[0m[0m | time: 36.790s
[2K
| Adam | epoch: 001 | loss: 0.69233 - acc: 0.5257 -- iter: 1248/1468
[A[ATraining Step: 40  | total loss: [1m[32m0.69147[0m[0m | time: 37.709s
[2K
| Adam | epoch: 001 | loss: 0.69147 - acc: 0.5443 -- iter: 1280/1468
[A[ATraining Step: 41  | total loss: [1m[32m0.69105[0m[0m | time: 38.653s
[2K
| Adam | epoch: 001 | loss: 0.69105 - acc: 0.5534 -- iter: 1312/1468
[A[ATraining Step: 42  | total loss: [1m[32m0.69147[0m[0m | time: 39.554s
[2K
| Adam | epoch: 001 | loss: 0.69147 - acc: 0.5438 -- iter: 1344/1468
[A[ATraining Step: 43  | total loss: [1m[32m0.69089[0m[0m | time: 40.498s
[2K
| Adam | epoch: 001 | loss: 0.69089 - acc: 0.5526 -- iter: 1376/1468
[A[ATraining Step: 44  | total loss: [1m[32m0.69072[0m[0m | time: 41.396s
[2K
| Adam | epoch: 001 | loss: 0.69072 - acc: 0.5543 -- iter: 1408/1468
[A[ATraining Step: 45  | total loss: [1m[32m0.69174[0m[0m | time: 42.356s
[2K
| Adam | epoch: 001 | loss: 0.69174 - acc: 0.5398 -- iter: 1440/1468
[A[ATraining Step: 46  | total loss: [1m[32m0.69340[0m[0m | time: 46.507s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.5175 | val_loss: 0.69550 - val_acc: 0.4771 -- iter: 1468/1468
--
Training Step: 47  | total loss: [1m[32m0.69671[0m[0m | time: 0.778s
[2K
| Adam | epoch: 002 | loss: 0.69671 - acc: 0.4737 -- iter: 0032/1468
[A[ATraining Step: 48  | total loss: [1m[32m0.69905[0m[0m | time: 1.692s
[2K
| Adam | epoch: 002 | loss: 0.69905 - acc: 0.4378 -- iter: 0064/1468
[A[ATraining Step: 49  | total loss: [1m[32m0.69855[0m[0m | time: 2.626s
[2K
| Adam | epoch: 002 | loss: 0.69855 - acc: 0.4427 -- iter: 0096/1468
[A[ATraining Step: 50  | total loss: [1m[32m0.69769[0m[0m | time: 3.542s
[2K
| Adam | epoch: 002 | loss: 0.69769 - acc: 0.4516 -- iter: 0128/1468
[A[ATraining Step: 51  | total loss: [1m[32m0.69782[0m[0m | time: 4.406s
[2K
| Adam | epoch: 002 | loss: 0.69782 - acc: 0.4399 -- iter: 0160/1468
[A[ATraining Step: 52  | total loss: [1m[32m0.69764[0m[0m | time: 5.314s
[2K
| Adam | epoch: 002 | loss: 0.69764 - acc: 0.4348 -- iter: 0192/1468
[A[ATraining Step: 53  | total loss: [1m[32m0.69639[0m[0m | time: 6.213s
[2K
| Adam | epoch: 002 | loss: 0.69639 - acc: 0.4675 -- iter: 0224/1468
[A[ATraining Step: 54  | total loss: [1m[32m0.69657[0m[0m | time: 7.110s
[2K
| Adam | epoch: 002 | loss: 0.69657 - acc: 0.4450 -- iter: 0256/1468
[A[ATraining Step: 55  | total loss: [1m[32m0.69594[0m[0m | time: 8.020s
[2K
| Adam | epoch: 002 | loss: 0.69594 - acc: 0.4573 -- iter: 0288/1468
[A[ATraining Step: 56  | total loss: [1m[32m0.69571[0m[0m | time: 9.015s
[2K
| Adam | epoch: 002 | loss: 0.69571 - acc: 0.4545 -- iter: 0320/1468
[A[ATraining Step: 57  | total loss: [1m[32m0.69560[0m[0m | time: 10.261s
[2K
| Adam | epoch: 002 | loss: 0.69560 - acc: 0.4435 -- iter: 0352/1468
[A[ATraining Step: 58  | total loss: [1m[32m0.69546[0m[0m | time: 11.144s
[2K
| Adam | epoch: 002 | loss: 0.69546 - acc: 0.4342 -- iter: 0384/1468
[A[ATraining Step: 59  | total loss: [1m[32m0.69509[0m[0m | time: 12.068s
[2K
| Adam | epoch: 002 | loss: 0.69509 - acc: 0.4472 -- iter: 0416/1468
[A[ATraining Step: 60  | total loss: [1m[32m0.69485[0m[0m | time: 12.991s
[2K
| Adam | epoch: 002 | loss: 0.69485 - acc: 0.4583 -- iter: 0448/1468
[A[ATraining Step: 61  | total loss: [1m[32m0.69460[0m[0m | time: 13.864s
[2K
| Adam | epoch: 002 | loss: 0.69460 - acc: 0.4679 -- iter: 0480/1468
[A[ATraining Step: 62  | total loss: [1m[32m0.69440[0m[0m | time: 14.800s
[2K
| Adam | epoch: 002 | loss: 0.69440 - acc: 0.4760 -- iter: 0512/1468
[A[ATraining Step: 63  | total loss: [1m[32m0.69427[0m[0m | time: 15.652s
[2K
| Adam | epoch: 002 | loss: 0.69427 - acc: 0.4711 -- iter: 0544/1468
[A[ATraining Step: 64  | total loss: [1m[32m0.69419[0m[0m | time: 16.582s
[2K
| Adam | epoch: 002 | loss: 0.69419 - acc: 0.4591 -- iter: 0576/1468
[A[ATraining Step: 65  | total loss: [1m[32m0.69404[0m[0m | time: 17.511s
[2K
| Adam | epoch: 002 | loss: 0.69404 - acc: 0.4796 -- iter: 0608/1468
[A[ATraining Step: 66  | total loss: [1m[32m0.69388[0m[0m | time: 18.490s
[2K
| Adam | epoch: 002 | loss: 0.69388 - acc: 0.4972 -- iter: 0640/1468
[A[ATraining Step: 67  | total loss: [1m[32m0.69385[0m[0m | time: 19.753s
[2K
| Adam | epoch: 002 | loss: 0.69385 - acc: 0.4863 -- iter: 0672/1468
[A[ATraining Step: 68  | total loss: [1m[32m0.69381[0m[0m | time: 20.551s
[2K
| Adam | epoch: 002 | loss: 0.69381 - acc: 0.4805 -- iter: 0704/1468
[A[ATraining Step: 69  | total loss: [1m[32m0.69386[0m[0m | time: 21.504s
[2K
| Adam | epoch: 002 | loss: 0.69386 - acc: 0.4682 -- iter: 0736/1468
[A[ATraining Step: 70  | total loss: [1m[32m0.69368[0m[0m | time: 22.420s
[2K
| Adam | epoch: 002 | loss: 0.69368 - acc: 0.4827 -- iter: 0768/1468
[A[ATraining Step: 71  | total loss: [1m[32m0.69355[0m[0m | time: 23.347s
[2K
| Adam | epoch: 002 | loss: 0.69355 - acc: 0.4989 -- iter: 0800/1468
[A[ATraining Step: 72  | total loss: [1m[32m0.69356[0m[0m | time: 24.248s
[2K
| Adam | epoch: 002 | loss: 0.69356 - acc: 0.4885 -- iter: 0832/1468
[A[ATraining Step: 73  | total loss: [1m[32m0.69343[0m[0m | time: 25.173s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.5037 -- iter: 0864/1468
[A[ATraining Step: 74  | total loss: [1m[32m0.69336[0m[0m | time: 26.136s
[2K
| Adam | epoch: 002 | loss: 0.69336 - acc: 0.5101 -- iter: 0896/1468
[A[ATraining Step: 75  | total loss: [1m[32m0.69326[0m[0m | time: 27.134s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.5158 -- iter: 0928/1468
[A[ATraining Step: 76  | total loss: [1m[32m0.69322[0m[0m | time: 28.082s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5141 -- iter: 0960/1468
[A[ATraining Step: 77  | total loss: [1m[32m0.69322[0m[0m | time: 29.015s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5126 -- iter: 0992/1468
[A[ATraining Step: 78  | total loss: [1m[32m0.69325[0m[0m | time: 29.972s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5080 -- iter: 1024/1468
[A[ATraining Step: 79  | total loss: [1m[32m0.69324[0m[0m | time: 30.937s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.5072 -- iter: 1056/1468
[A[ATraining Step: 80  | total loss: [1m[32m0.69330[0m[0m | time: 31.873s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.5033 -- iter: 1088/1468
[A[ATraining Step: 81  | total loss: [1m[32m0.69309[0m[0m | time: 32.847s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5156 -- iter: 1120/1468
[A[ATraining Step: 82  | total loss: [1m[32m0.69297[0m[0m | time: 33.822s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5234 -- iter: 1152/1468
[A[ATraining Step: 83  | total loss: [1m[32m0.69308[0m[0m | time: 34.688s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5179 -- iter: 1184/1468
[A[ATraining Step: 84  | total loss: [1m[32m0.69303[0m[0m | time: 35.627s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5193 -- iter: 1216/1468
[A[ATraining Step: 85  | total loss: [1m[32m0.69307[0m[0m | time: 36.486s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5173 -- iter: 1248/1468
[A[ATraining Step: 86  | total loss: [1m[32m0.69316[0m[0m | time: 37.720s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5125 -- iter: 1280/1468
[A[ATraining Step: 87  | total loss: [1m[32m0.69303[0m[0m | time: 38.959s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5143 -- iter: 1312/1468
[A[ATraining Step: 88  | total loss: [1m[32m0.69341[0m[0m | time: 40.479s
[2K
| Adam | epoch: 002 | loss: 0.69341 - acc: 0.4973 -- iter: 1344/1468
[A[ATraining Step: 89  | total loss: [1m[32m0.69332[0m[0m | time: 41.672s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.5007 -- iter: 1376/1468
[A[ATraining Step: 90  | total loss: [1m[32m0.69327[0m[0m | time: 42.419s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.5006 -- iter: 1408/1468
[A[ATraining Step: 91  | total loss: [1m[32m0.69308[0m[0m | time: 43.199s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5099 -- iter: 1440/1468
[A[ATraining Step: 92  | total loss: [1m[32m0.69307[0m[0m | time: 45.655s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5089 | val_loss: 0.69264 - val_acc: 0.5229 -- iter: 1468/1468
--
Training Step: 93  | total loss: [1m[32m0.69302[0m[0m | time: 0.662s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5112 -- iter: 0032/1468
[A[ATraining Step: 94  | total loss: [1m[32m0.69315[0m[0m | time: 1.328s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5065 -- iter: 0064/1468
[A[ATraining Step: 95  | total loss: [1m[32m0.69323[0m[0m | time: 2.116s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.5023 -- iter: 0096/1468
[A[ATraining Step: 96  | total loss: [1m[32m0.69279[0m[0m | time: 2.890s
[2K
| Adam | epoch: 003 | loss: 0.69279 - acc: 0.5208 -- iter: 0128/1468
[A[ATraining Step: 97  | total loss: [1m[32m0.69283[0m[0m | time: 3.631s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5187 -- iter: 0160/1468
[A[ATraining Step: 98  | total loss: [1m[32m0.69317[0m[0m | time: 4.401s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.5075 -- iter: 0192/1468
[A[ATraining Step: 99  | total loss: [1m[32m0.69328[0m[0m | time: 5.148s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.5036 -- iter: 0224/1468
[A[ATraining Step: 100  | total loss: [1m[32m0.69374[0m[0m | time: 5.946s
[2K
| Adam | epoch: 003 | loss: 0.69374 - acc: 0.4845 -- iter: 0256/1468
[A[ATraining Step: 101  | total loss: [1m[32m0.69381[0m[0m | time: 6.658s
[2K
| Adam | epoch: 003 | loss: 0.69381 - acc: 0.4829 -- iter: 0288/1468
[A[ATraining Step: 102  | total loss: [1m[32m0.69398[0m[0m | time: 7.400s
[2K
| Adam | epoch: 003 | loss: 0.69398 - acc: 0.4752 -- iter: 0320/1468
[A[ATraining Step: 103  | total loss: [1m[32m0.69377[0m[0m | time: 8.163s
[2K
| Adam | epoch: 003 | loss: 0.69377 - acc: 0.4840 -- iter: 0352/1468
[A[ATraining Step: 104  | total loss: [1m[32m0.69369[0m[0m | time: 8.902s
[2K
| Adam | epoch: 003 | loss: 0.69369 - acc: 0.4856 -- iter: 0384/1468
[A[ATraining Step: 105  | total loss: [1m[32m0.69376[0m[0m | time: 9.661s
[2K
| Adam | epoch: 003 | loss: 0.69376 - acc: 0.4776 -- iter: 0416/1468
[A[ATraining Step: 106  | total loss: [1m[32m0.69380[0m[0m | time: 10.387s
[2K
| Adam | epoch: 003 | loss: 0.69380 - acc: 0.4705 -- iter: 0448/1468
[A[ATraining Step: 107  | total loss: [1m[32m0.69372[0m[0m | time: 11.175s
[2K
| Adam | epoch: 003 | loss: 0.69372 - acc: 0.4766 -- iter: 0480/1468
[A[ATraining Step: 108  | total loss: [1m[32m0.69366[0m[0m | time: 11.929s
[2K
| Adam | epoch: 003 | loss: 0.69366 - acc: 0.4789 -- iter: 0512/1468
[A[ATraining Step: 109  | total loss: [1m[32m0.69352[0m[0m | time: 12.687s
[2K
| Adam | epoch: 003 | loss: 0.69352 - acc: 0.4904 -- iter: 0544/1468
[A[ATraining Step: 110  | total loss: [1m[32m0.69358[0m[0m | time: 13.482s
[2K
| Adam | epoch: 003 | loss: 0.69358 - acc: 0.4820 -- iter: 0576/1468
[A[ATraining Step: 111  | total loss: [1m[32m0.69350[0m[0m | time: 14.263s
[2K
| Adam | epoch: 003 | loss: 0.69350 - acc: 0.4869 -- iter: 0608/1468
[A[ATraining Step: 112  | total loss: [1m[32m0.69346[0m[0m | time: 15.056s
[2K
| Adam | epoch: 003 | loss: 0.69346 - acc: 0.4882 -- iter: 0640/1468
[A[ATraining Step: 113  | total loss: [1m[32m0.69342[0m[0m | time: 15.818s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.4894 -- iter: 0672/1468
[A[ATraining Step: 114  | total loss: [1m[32m0.69333[0m[0m | time: 16.591s
[2K
| Adam | epoch: 003 | loss: 0.69333 - acc: 0.4998 -- iter: 0704/1468
[A[ATraining Step: 115  | total loss: [1m[32m0.69331[0m[0m | time: 17.335s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.4999 -- iter: 0736/1468
[A[ATraining Step: 116  | total loss: [1m[32m0.69331[0m[0m | time: 18.112s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.4967 -- iter: 0768/1468
[A[ATraining Step: 117  | total loss: [1m[32m0.69327[0m[0m | time: 18.879s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.4971 -- iter: 0800/1468
[A[ATraining Step: 118  | total loss: [1m[32m0.69319[0m[0m | time: 19.630s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5067 -- iter: 0832/1468
[A[ATraining Step: 119  | total loss: [1m[32m0.69316[0m[0m | time: 20.376s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.5092 -- iter: 0864/1468
[A[ATraining Step: 120  | total loss: [1m[32m0.69323[0m[0m | time: 21.145s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.4958 -- iter: 0896/1468
[A[ATraining Step: 121  | total loss: [1m[32m0.69324[0m[0m | time: 21.874s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4931 -- iter: 0928/1468
[A[ATraining Step: 122  | total loss: [1m[32m0.69319[0m[0m | time: 22.638s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5000 -- iter: 0960/1468
[A[ATraining Step: 123  | total loss: [1m[32m0.69320[0m[0m | time: 23.508s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.4969 -- iter: 0992/1468
[A[ATraining Step: 124  | total loss: [1m[32m0.69313[0m[0m | time: 24.686s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5097 -- iter: 1024/1468
[A[ATraining Step: 125  | total loss: [1m[32m0.69308[0m[0m | time: 25.322s
[2K
| Adam | epoch: 003 | loss: 0.69308 - acc: 0.5150 -- iter: 1056/1468
[A[ATraining Step: 126  | total loss: [1m[32m0.69310[0m[0m | time: 26.024s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5104 -- iter: 1088/1468
[A[ATraining Step: 127  | total loss: [1m[32m0.69316[0m[0m | time: 26.807s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4999 -- iter: 1120/1468
[A[ATraining Step: 128  | total loss: [1m[32m0.69324[0m[0m | time: 27.621s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4874 -- iter: 1152/1468
[A[ATraining Step: 129  | total loss: [1m[32m0.69320[0m[0m | time: 28.407s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.4887 -- iter: 1184/1468
[A[ATraining Step: 130  | total loss: [1m[32m0.69314[0m[0m | time: 29.139s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.4992 -- iter: 1216/1468
[A[ATraining Step: 131  | total loss: [1m[32m0.69319[0m[0m | time: 29.898s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.4837 -- iter: 1248/1468
[A[ATraining Step: 132  | total loss: [1m[32m0.69317[0m[0m | time: 30.699s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4853 -- iter: 1280/1468
[A[ATraining Step: 133  | total loss: [1m[32m0.69317[0m[0m | time: 31.579s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4836 -- iter: 1312/1468
[A[ATraining Step: 134  | total loss: [1m[32m0.69316[0m[0m | time: 32.343s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4822 -- iter: 1344/1468
[A[ATraining Step: 135  | total loss: [1m[32m0.69315[0m[0m | time: 33.080s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.4808 -- iter: 1376/1468
[A[ATraining Step: 136  | total loss: [1m[32m0.69316[0m[0m | time: 33.845s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4796 -- iter: 1408/1468
[A[ATraining Step: 137  | total loss: [1m[32m0.69316[0m[0m | time: 34.561s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4785 -- iter: 1440/1468
[A[ATraining Step: 138  | total loss: [1m[32m0.69317[0m[0m | time: 37.229s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4713 | val_loss: 0.69314 - val_acc: 0.4771 -- iter: 1468/1468
--
Training Step: 139  | total loss: [1m[32m0.69318[0m[0m | time: 0.842s
[2K
| Adam | epoch: 004 | loss: 0.69318 - acc: 0.4585 -- iter: 0032/1468
[A[ATraining Step: 140  | total loss: [1m[32m0.69316[0m[0m | time: 1.626s
[2K
| Adam | epoch: 004 | loss: 0.69316 - acc: 0.4596 -- iter: 0064/1468
[A[ATraining Step: 141  | total loss: [1m[32m0.69320[0m[0m | time: 2.349s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.4493 -- iter: 0096/1468
[A[ATraining Step: 142  | total loss: [1m[32m0.69324[0m[0m | time: 3.168s
[2K
| Adam | epoch: 004 | loss: 0.69324 - acc: 0.4330 -- iter: 0128/1468
[A[ATraining Step: 143  | total loss: [1m[32m0.69321[0m[0m | time: 4.000s
[2K
| Adam | epoch: 004 | loss: 0.69321 - acc: 0.4490 -- iter: 0160/1468
[A[ATraining Step: 144  | total loss: [1m[32m0.69319[0m[0m | time: 4.866s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.4635 -- iter: 0192/1468
[A[ATraining Step: 145  | total loss: [1m[32m0.69315[0m[0m | time: 5.665s
[2K
| Adam | epoch: 004 | loss: 0.69315 - acc: 0.4797 -- iter: 0224/1468
[A[ATraining Step: 146  | total loss: [1m[32m0.69316[0m[0m | time: 6.439s
[2K
| Adam | epoch: 004 | loss: 0.69316 - acc: 0.4786 -- iter: 0256/1468
[A[ATraining Step: 147  | total loss: [1m[32m0.69313[0m[0m | time: 7.208s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.4838 -- iter: 0288/1468
[A[ATraining Step: 148  | total loss: [1m[32m0.69313[0m[0m | time: 7.988s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.4823 -- iter: 0320/1468
[A[ATraining Step: 149  | total loss: [1m[32m0.69303[0m[0m | time: 8.842s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.4935 -- iter: 0352/1468
[A[ATraining Step: 150  | total loss: [1m[32m0.69301[0m[0m | time: 9.665s
[2K
| Adam | epoch: 004 | loss: 0.69301 - acc: 0.4941 -- iter: 0384/1468
[A[ATraining Step: 151  | total loss: [1m[32m0.69334[0m[0m | time: 10.509s
[2K
| Adam | epoch: 004 | loss: 0.69334 - acc: 0.4697 -- iter: 0416/1468
[A[ATraining Step: 152  | total loss: [1m[32m0.69317[0m[0m | time: 11.299s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.4852 -- iter: 0448/1468
[A[ATraining Step: 153  | total loss: [1m[32m0.69332[0m[0m | time: 12.110s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.4742 -- iter: 0480/1468
[A[ATraining Step: 154  | total loss: [1m[32m0.69326[0m[0m | time: 12.938s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.4799 -- iter: 0512/1468
[A[ATraining Step: 155  | total loss: [1m[32m0.69328[0m[0m | time: 13.764s
[2K
| Adam | epoch: 004 | loss: 0.69328 - acc: 0.4788 -- iter: 0544/1468
[A[ATraining Step: 156  | total loss: [1m[32m0.69310[0m[0m | time: 14.591s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.4934 -- iter: 0576/1468
[A[ATraining Step: 157  | total loss: [1m[32m0.69319[0m[0m | time: 15.459s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.4878 -- iter: 0608/1468
[A[ATraining Step: 158  | total loss: [1m[32m0.69323[0m[0m | time: 16.295s
[2K
| Adam | epoch: 004 | loss: 0.69323 - acc: 0.4828 -- iter: 0640/1468
[A[ATraining Step: 159  | total loss: [1m[32m0.69339[0m[0m | time: 17.092s
[2K
| Adam | epoch: 004 | loss: 0.69339 - acc: 0.4689 -- iter: 0672/1468
[A[ATraining Step: 160  | total loss: [1m[32m0.69338[0m[0m | time: 17.923s
[2K
| Adam | epoch: 004 | loss: 0.69338 - acc: 0.4689 -- iter: 0704/1468
[A[ATraining Step: 161  | total loss: [1m[32m0.69332[0m[0m | time: 19.050s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.4782 -- iter: 0736/1468
[A[ATraining Step: 162  | total loss: [1m[32m0.69344[0m[0m | time: 20.172s
[2K
| Adam | epoch: 004 | loss: 0.69344 - acc: 0.4648 -- iter: 0768/1468
[A[ATraining Step: 163  | total loss: [1m[32m0.69333[0m[0m | time: 20.850s
[2K
| Adam | epoch: 004 | loss: 0.69333 - acc: 0.4777 -- iter: 0800/1468
[A[ATraining Step: 164  | total loss: [1m[32m0.69331[0m[0m | time: 21.546s
[2K
| Adam | epoch: 004 | loss: 0.69331 - acc: 0.4799 -- iter: 0832/1468
[A[ATraining Step: 165  | total loss: [1m[32m0.69320[0m[0m | time: 22.329s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.4944 -- iter: 0864/1468
[A[ATraining Step: 166  | total loss: [1m[32m0.69325[0m[0m | time: 23.141s
[2K
| Adam | epoch: 004 | loss: 0.69325 - acc: 0.4856 -- iter: 0896/1468
[A[ATraining Step: 167  | total loss: [1m[32m0.69317[0m[0m | time: 24.087s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.4995 -- iter: 0928/1468
[A[ATraining Step: 168  | total loss: [1m[32m0.69314[0m[0m | time: 24.968s
[2K
| Adam | epoch: 004 | loss: 0.69314 - acc: 0.5027 -- iter: 0960/1468
[A[ATraining Step: 169  | total loss: [1m[32m0.69315[0m[0m | time: 25.864s
[2K
| Adam | epoch: 004 | loss: 0.69315 - acc: 0.4993 -- iter: 0992/1468
[A[ATraining Step: 170  | total loss: [1m[32m0.69307[0m[0m | time: 26.674s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5119 -- iter: 1024/1468
[A[ATraining Step: 171  | total loss: [1m[32m0.69307[0m[0m | time: 27.451s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5045 -- iter: 1056/1468
[A[ATraining Step: 172  | total loss: [1m[32m0.69304[0m[0m | time: 28.249s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5071 -- iter: 1088/1468
[A[ATraining Step: 173  | total loss: [1m[32m0.69307[0m[0m | time: 29.037s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5064 -- iter: 1120/1468
[A[ATraining Step: 174  | total loss: [1m[32m0.69296[0m[0m | time: 29.886s
[2K
| Adam | epoch: 004 | loss: 0.69296 - acc: 0.5183 -- iter: 1152/1468
[A[ATraining Step: 175  | total loss: [1m[32m0.69298[0m[0m | time: 30.830s
[2K
| Adam | epoch: 004 | loss: 0.69298 - acc: 0.5164 -- iter: 1184/1468
[A[ATraining Step: 176  | total loss: [1m[32m0.69299[0m[0m | time: 31.683s
[2K
| Adam | epoch: 004 | loss: 0.69299 - acc: 0.5148 -- iter: 1216/1468
[A[ATraining Step: 177  | total loss: [1m[32m0.69306[0m[0m | time: 32.516s
[2K
| Adam | epoch: 004 | loss: 0.69306 - acc: 0.5071 -- iter: 1248/1468
[A[ATraining Step: 178  | total loss: [1m[32m0.69293[0m[0m | time: 33.270s
[2K
| Adam | epoch: 004 | loss: 0.69293 - acc: 0.5189 -- iter: 1280/1468
[A[ATraining Step: 179  | total loss: [1m[32m0.69288[0m[0m | time: 34.029s
[2K
| Adam | epoch: 004 | loss: 0.69288 - acc: 0.5201 -- iter: 1312/1468
[A[ATraining Step: 180  | total loss: [1m[32m0.69297[0m[0m | time: 34.794s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5150 -- iter: 1344/1468
[A[ATraining Step: 181  | total loss: [1m[32m0.69303[0m[0m | time: 35.585s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5103 -- iter: 1376/1468
[A[ATraining Step: 182  | total loss: [1m[32m0.69323[0m[0m | time: 36.322s
[2K
| Adam | epoch: 004 | loss: 0.69323 - acc: 0.4968 -- iter: 1408/1468
[A[ATraining Step: 183  | total loss: [1m[32m0.69335[0m[0m | time: 37.066s
[2K
| Adam | epoch: 004 | loss: 0.69335 - acc: 0.4909 -- iter: 1440/1468
[A[ATraining Step: 184  | total loss: [1m[32m0.69343[0m[0m | time: 39.627s
[2K
| Adam | epoch: 004 | loss: 0.69343 - acc: 0.4824 | val_loss: 0.69277 - val_acc: 0.5229 -- iter: 1468/1468
--
Training Step: 185  | total loss: [1m[32m0.69341[0m[0m | time: 0.805s
[2K
| Adam | epoch: 005 | loss: 0.69341 - acc: 0.4842 -- iter: 0032/1468
[A[ATraining Step: 186  | total loss: [1m[32m0.69335[0m[0m | time: 1.613s
[2K
| Adam | epoch: 005 | loss: 0.69335 - acc: 0.4889 -- iter: 0064/1468
[A[ATraining Step: 187  | total loss: [1m[32m0.69345[0m[0m | time: 2.307s
[2K
| Adam | epoch: 005 | loss: 0.69345 - acc: 0.4806 -- iter: 0096/1468
[A[ATraining Step: 188  | total loss: [1m[32m0.69329[0m[0m | time: 2.942s
[2K
| Adam | epoch: 005 | loss: 0.69329 - acc: 0.4933 -- iter: 0128/1468
[A[ATraining Step: 189  | total loss: [1m[32m0.69319[0m[0m | time: 3.674s
[2K
| Adam | epoch: 005 | loss: 0.69319 - acc: 0.5047 -- iter: 0160/1468
[A[ATraining Step: 190  | total loss: [1m[32m0.69324[0m[0m | time: 4.477s
[2K
| Adam | epoch: 005 | loss: 0.69324 - acc: 0.4979 -- iter: 0192/1468
[A[ATraining Step: 191  | total loss: [1m[32m0.69331[0m[0m | time: 5.239s
[2K
| Adam | epoch: 005 | loss: 0.69331 - acc: 0.4888 -- iter: 0224/1468
[A[ATraining Step: 192  | total loss: [1m[32m0.69327[0m[0m | time: 6.025s
[2K
| Adam | epoch: 005 | loss: 0.69327 - acc: 0.4930 -- iter: 0256/1468
[A[ATraining Step: 193  | total loss: [1m[32m0.69327[0m[0m | time: 6.828s
[2K
| Adam | epoch: 005 | loss: 0.69327 - acc: 0.4937 -- iter: 0288/1468
[A[ATraining Step: 194  | total loss: [1m[32m0.69330[0m[0m | time: 7.610s
[2K
| Adam | epoch: 005 | loss: 0.69330 - acc: 0.4881 -- iter: 0320/1468
[A[ATraining Step: 195  | total loss: [1m[32m0.69321[0m[0m | time: 8.411s
[2K
| Adam | epoch: 005 | loss: 0.69321 - acc: 0.4987 -- iter: 0352/1468
[A[ATraining Step: 196  | total loss: [1m[32m0.69317[0m[0m | time: 9.254s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.5050 -- iter: 0384/1468
[A[ATraining Step: 197  | total loss: [1m[32m0.69312[0m[0m | time: 9.991s
[2K
| Adam | epoch: 005 | loss: 0.69312 - acc: 0.5077 -- iter: 0416/1468
[A[ATraining Step: 198  | total loss: [1m[32m0.69317[0m[0m | time: 10.776s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.5038 -- iter: 0448/1468
[A[ATraining Step: 199  | total loss: [1m[32m0.69310[0m[0m | time: 11.932s
[2K
| Adam | epoch: 005 | loss: 0.69310 - acc: 0.5096 -- iter: 0480/1468
[A[ATraining Step: 200  | total loss: [1m[32m0.69313[0m[0m | time: 14.416s
[2K
| Adam | epoch: 005 | loss: 0.69313 - acc: 0.5056 | val_loss: 0.69284 - val_acc: 0.5229 -- iter: 0512/1468
--
Training Step: 201  | total loss: [1m[32m0.69315[0m[0m | time: 15.203s
[2K
| Adam | epoch: 005 | loss: 0.69315 - acc: 0.5019 -- iter: 0544/1468
[A[ATraining Step: 202  | total loss: [1m[32m0.69308[0m[0m | time: 15.964s
[2K
| Adam | epoch: 005 | loss: 0.69308 - acc: 0.5079 -- iter: 0576/1468
[A[ATraining Step: 203  | total loss: [1m[32m0.69317[0m[0m | time: 16.708s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.4978 -- iter: 0608/1468
[A[ATraining Step: 204  | total loss: [1m[32m0.69316[0m[0m | time: 17.437s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.4949 -- iter: 0640/1468
[A[ATraining Step: 205  | total loss: [1m[32m0.69325[0m[0m | time: 18.232s
[2K
| Adam | epoch: 005 | loss: 0.69325 - acc: 0.4829 -- iter: 0672/1468
[A[ATraining Step: 206  | total loss: [1m[32m0.69316[0m[0m | time: 19.001s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.4940 -- iter: 0704/1468
[A[ATraining Step: 207  | total loss: [1m[32m0.69312[0m[0m | time: 19.723s
[2K
| Adam | epoch: 005 | loss: 0.69312 - acc: 0.4977 -- iter: 0736/1468
[A[ATraining Step: 208  | total loss: [1m[32m0.69298[0m[0m | time: 20.453s
[2K
| Adam | epoch: 005 | loss: 0.69298 - acc: 0.5167 -- iter: 0768/1468
[A[ATraining Step: 209  | total loss: [1m[32m0.69298[0m[0m | time: 21.174s
[2K
| Adam | epoch: 005 | loss: 0.69298 - acc: 0.5150 -- iter: 0800/1468
[A[ATraining Step: 210  | total loss: [1m[32m0.69298[0m[0m | time: 21.939s
[2K
| Adam | epoch: 005 | loss: 0.69298 - acc: 0.5135 -- iter: 0832/1468
[A[ATraining Step: 211  | total loss: [1m[32m0.69302[0m[0m | time: 22.667s
[2K
| Adam | epoch: 005 | loss: 0.69302 - acc: 0.5059 -- iter: 0864/1468
[A[ATraining Step: 212  | total loss: [1m[32m0.69294[0m[0m | time: 23.409s
[2K
| Adam | epoch: 005 | loss: 0.69294 - acc: 0.5147 -- iter: 0896/1468
[A[ATraining Step: 213  | total loss: [1m[32m0.69277[0m[0m | time: 24.228s
[2K
| Adam | epoch: 005 | loss: 0.69277 - acc: 0.5288 -- iter: 0928/1468
[A[ATraining Step: 214  | total loss: [1m[32m0.69256[0m[0m | time: 25.041s
[2K
| Adam | epoch: 005 | loss: 0.69256 - acc: 0.5447 -- iter: 0960/1468
[A[ATraining Step: 215  | total loss: [1m[32m0.69259[0m[0m | time: 25.832s
[2K
| Adam | epoch: 005 | loss: 0.69259 - acc: 0.5402 -- iter: 0992/1468
[A[ATraining Step: 216  | total loss: [1m[32m0.69245[0m[0m | time: 26.617s
[2K
| Adam | epoch: 005 | loss: 0.69245 - acc: 0.5456 -- iter: 1024/1468
[A[ATraining Step: 217  | total loss: [1m[32m0.69283[0m[0m | time: 27.463s
[2K
| Adam | epoch: 005 | loss: 0.69283 - acc: 0.5254 -- iter: 1056/1468
[A[ATraining Step: 218  | total loss: [1m[32m0.69276[0m[0m | time: 28.246s
[2K
| Adam | epoch: 005 | loss: 0.69276 - acc: 0.5260 -- iter: 1088/1468
[A[ATraining Step: 219  | total loss: [1m[32m0.69286[0m[0m | time: 29.028s
[2K
| Adam | epoch: 005 | loss: 0.69286 - acc: 0.5203 -- iter: 1120/1468
[A[ATraining Step: 220  | total loss: [1m[32m0.69351[0m[0m | time: 29.810s
[2K
| Adam | epoch: 005 | loss: 0.69351 - acc: 0.4932 -- iter: 1152/1468
[A[ATraining Step: 221  | total loss: [1m[32m0.69340[0m[0m | time: 30.590s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.4970 -- iter: 1184/1468
[A[ATraining Step: 222  | total loss: [1m[32m0.69320[0m[0m | time: 31.352s
[2K
| Adam | epoch: 005 | loss: 0.69320 - acc: 0.5036 -- iter: 1216/1468
[A[ATraining Step: 223  | total loss: [1m[32m0.69275[0m[0m | time: 32.141s
[2K
| Adam | epoch: 005 | loss: 0.69275 - acc: 0.5220 -- iter: 1248/1468
[A[ATraining Step: 224  | total loss: [1m[32m0.69277[0m[0m | time: 32.900s
[2K
| Adam | epoch: 005 | loss: 0.69277 - acc: 0.5167 -- iter: 1280/1468
[A[ATraining Step: 225  | total loss: [1m[32m0.69238[0m[0m | time: 33.651s
[2K
| Adam | epoch: 005 | loss: 0.69238 - acc: 0.5306 -- iter: 1312/1468
[A[ATraining Step: 226  | total loss: [1m[32m0.69234[0m[0m | time: 34.421s
[2K
| Adam | epoch: 005 | loss: 0.69234 - acc: 0.5307 -- iter: 1344/1468
[A[ATraining Step: 227  | total loss: [1m[32m0.69244[0m[0m | time: 35.134s
[2K
| Adam | epoch: 005 | loss: 0.69244 - acc: 0.5276 -- iter: 1376/1468
[A[ATraining Step: 228  | total loss: [1m[32m0.69260[0m[0m | time: 35.888s
[2K
| Adam | epoch: 005 | loss: 0.69260 - acc: 0.5217 -- iter: 1408/1468
[A[ATraining Step: 229  | total loss: [1m[32m0.69247[0m[0m | time: 36.665s
[2K
| Adam | epoch: 005 | loss: 0.69247 - acc: 0.5258 -- iter: 1440/1468
[A[ATraining Step: 230  | total loss: [1m[32m0.69249[0m[0m | time: 39.201s
[2K
| Adam | epoch: 005 | loss: 0.69249 - acc: 0.5232 | val_loss: 0.69204 - val_acc: 0.5229 -- iter: 1468/1468
--
Training Step: 231  | total loss: [1m[32m0.69287[0m[0m | time: 0.817s
[2K
| Adam | epoch: 006 | loss: 0.69287 - acc: 0.5115 -- iter: 0032/1468
[A[ATraining Step: 232  | total loss: [1m[32m0.69270[0m[0m | time: 1.556s
[2K
| Adam | epoch: 006 | loss: 0.69270 - acc: 0.5166 -- iter: 0064/1468
[A[ATraining Step: 233  | total loss: [1m[32m0.69355[0m[0m | time: 2.330s
[2K
| Adam | epoch: 006 | loss: 0.69355 - acc: 0.4931 -- iter: 0096/1468
[A[ATraining Step: 234  | total loss: [1m[32m0.69375[0m[0m | time: 3.179s
[2K
| Adam | epoch: 006 | loss: 0.69375 - acc: 0.4875 -- iter: 0128/1468
[A[ATraining Step: 235  | total loss: [1m[32m0.69317[0m[0m | time: 4.153s
[2K
| Adam | epoch: 006 | loss: 0.69317 - acc: 0.5031 -- iter: 0160/1468
[A[ATraining Step: 236  | total loss: [1m[32m0.69275[0m[0m | time: 4.833s
[2K
| Adam | epoch: 006 | loss: 0.69275 - acc: 0.5170 -- iter: 0192/1468
[A[ATraining Step: 237  | total loss: [1m[32m0.69277[0m[0m | time: 5.457s
[2K
| Adam | epoch: 006 | loss: 0.69277 - acc: 0.5153 -- iter: 0224/1468
[A[ATraining Step: 238  | total loss: [1m[32m0.69332[0m[0m | time: 6.161s
[2K
| Adam | epoch: 006 | loss: 0.69332 - acc: 0.4982 -- iter: 0256/1468
[A[ATraining Step: 239  | total loss: [1m[32m0.69279[0m[0m | time: 6.885s
[2K
| Adam | epoch: 006 | loss: 0.69279 - acc: 0.5140 -- iter: 0288/1468
[A[ATraining Step: 240  | total loss: [1m[32m0.69254[0m[0m | time: 7.696s
[2K
| Adam | epoch: 006 | loss: 0.69254 - acc: 0.5220 -- iter: 0320/1468
[A[ATraining Step: 241  | total loss: [1m[32m0.69257[0m[0m | time: 8.466s
[2K
| Adam | epoch: 006 | loss: 0.69257 - acc: 0.5198 -- iter: 0352/1468
[A[ATraining Step: 242  | total loss: [1m[32m0.69264[0m[0m | time: 9.278s
[2K
| Adam | epoch: 006 | loss: 0.69264 - acc: 0.5178 -- iter: 0384/1468
[A[ATraining Step: 243  | total loss: [1m[32m0.69273[0m[0m | time: 10.087s
[2K
| Adam | epoch: 006 | loss: 0.69273 - acc: 0.5160 -- iter: 0416/1468
[A[ATraining Step: 244  | total loss: [1m[32m0.69301[0m[0m | time: 10.816s
[2K
| Adam | epoch: 006 | loss: 0.69301 - acc: 0.5082 -- iter: 0448/1468
[A[ATraining Step: 245  | total loss: [1m[32m0.69330[0m[0m | time: 11.584s
[2K
| Adam | epoch: 006 | loss: 0.69330 - acc: 0.4948 -- iter: 0480/1468
[A[ATraining Step: 246  | total loss: [1m[32m0.69354[0m[0m | time: 12.325s
[2K
| Adam | epoch: 006 | loss: 0.69354 - acc: 0.4860 -- iter: 0512/1468
[A[ATraining Step: 247  | total loss: [1m[32m0.69380[0m[0m | time: 13.116s
[2K
| Adam | epoch: 006 | loss: 0.69380 - acc: 0.4749 -- iter: 0544/1468
[A[ATraining Step: 248  | total loss: [1m[32m0.69391[0m[0m | time: 13.878s
[2K
| Adam | epoch: 006 | loss: 0.69391 - acc: 0.4680 -- iter: 0576/1468
[A[ATraining Step: 249  | total loss: [1m[32m0.69377[0m[0m | time: 14.630s
[2K
| Adam | epoch: 006 | loss: 0.69377 - acc: 0.4712 -- iter: 0608/1468
[A[ATraining Step: 250  | total loss: [1m[32m0.69360[0m[0m | time: 15.356s
[2K
| Adam | epoch: 006 | loss: 0.69360 - acc: 0.4772 -- iter: 0640/1468
[A[ATraining Step: 251  | total loss: [1m[32m0.69360[0m[0m | time: 16.158s
[2K
| Adam | epoch: 006 | loss: 0.69360 - acc: 0.4701 -- iter: 0672/1468
[A[ATraining Step: 252  | total loss: [1m[32m0.69342[0m[0m | time: 16.929s
[2K
| Adam | epoch: 006 | loss: 0.69342 - acc: 0.4919 -- iter: 0704/1468
[A[ATraining Step: 253  | total loss: [1m[32m0.69332[0m[0m | time: 17.641s
[2K
| Adam | epoch: 006 | loss: 0.69332 - acc: 0.5021 -- iter: 0736/1468
[A[ATraining Step: 254  | total loss: [1m[32m0.69329[0m[0m | time: 18.407s
[2K
| Adam | epoch: 006 | loss: 0.69329 - acc: 0.4925 -- iter: 0768/1468
[A[ATraining Step: 255  | total loss: [1m[32m0.69323[0m[0m | time: 19.218s
[2K
| Adam | epoch: 006 | loss: 0.69323 - acc: 0.5026 -- iter: 0800/1468
[A[ATraining Step: 256  | total loss: [1m[32m0.69318[0m[0m | time: 19.953s
[2K
| Adam | epoch: 006 | loss: 0.69318 - acc: 0.5023 -- iter: 0832/1468
[A[ATraining Step: 257  | total loss: [1m[32m0.69306[0m[0m | time: 20.756s
[2K
| Adam | epoch: 006 | loss: 0.69306 - acc: 0.5115 -- iter: 0864/1468
[A[ATraining Step: 258  | total loss: [1m[32m0.69308[0m[0m | time: 21.581s
[2K
| Adam | epoch: 006 | loss: 0.69308 - acc: 0.5010 -- iter: 0896/1468
[A[ATraining Step: 259  | total loss: [1m[32m0.69303[0m[0m | time: 22.353s
[2K
| Adam | epoch: 006 | loss: 0.69303 - acc: 0.5102 -- iter: 0928/1468
[A[ATraining Step: 260  | total loss: [1m[32m0.69291[0m[0m | time: 23.156s
[2K
| Adam | epoch: 006 | loss: 0.69291 - acc: 0.5155 -- iter: 0960/1468
[A[ATraining Step: 261  | total loss: [1m[32m0.69287[0m[0m | time: 23.916s
[2K
| Adam | epoch: 006 | loss: 0.69287 - acc: 0.5139 -- iter: 0992/1468
[A[ATraining Step: 262  | total loss: [1m[32m0.69286[0m[0m | time: 24.682s
[2K
| Adam | epoch: 006 | loss: 0.69286 - acc: 0.5188 -- iter: 1024/1468
[A[ATraining Step: 263  | total loss: [1m[32m0.69267[0m[0m | time: 25.406s
[2K
| Adam | epoch: 006 | loss: 0.69267 - acc: 0.5325 -- iter: 1056/1468
[A[ATraining Step: 264  | total loss: [1m[32m0.69275[0m[0m | time: 26.174s
[2K
| Adam | epoch: 006 | loss: 0.69275 - acc: 0.5168 -- iter: 1088/1468
[A[ATraining Step: 265  | total loss: [1m[32m0.69290[0m[0m | time: 26.950s
[2K
| Adam | epoch: 006 | loss: 0.69290 - acc: 0.5057 -- iter: 1120/1468
[A[ATraining Step: 266  | total loss: [1m[32m0.69296[0m[0m | time: 27.689s
[2K
| Adam | epoch: 006 | loss: 0.69296 - acc: 0.4989 -- iter: 1152/1468
[A[ATraining Step: 267  | total loss: [1m[32m0.69281[0m[0m | time: 28.434s
[2K
| Adam | epoch: 006 | loss: 0.69281 - acc: 0.5115 -- iter: 1184/1468
[A[ATraining Step: 268  | total loss: [1m[32m0.69309[0m[0m | time: 29.350s
[2K
| Adam | epoch: 006 | loss: 0.69309 - acc: 0.4947 -- iter: 1216/1468
[A[ATraining Step: 269  | total loss: [1m[32m0.69308[0m[0m | time: 30.350s
[2K
| Adam | epoch: 006 | loss: 0.69308 - acc: 0.4890 -- iter: 1248/1468
[A[ATraining Step: 270  | total loss: [1m[32m0.69296[0m[0m | time: 30.968s
[2K
| Adam | epoch: 006 | loss: 0.69296 - acc: 0.4932 -- iter: 1280/1468
[A[ATraining Step: 271  | total loss: [1m[32m0.69284[0m[0m | time: 31.693s
[2K
| Adam | epoch: 006 | loss: 0.69284 - acc: 0.5033 -- iter: 1312/1468
[A[ATraining Step: 272  | total loss: [1m[32m0.69282[0m[0m | time: 32.448s
[2K
| Adam | epoch: 006 | loss: 0.69282 - acc: 0.5217 -- iter: 1344/1468
[A[ATraining Step: 273  | total loss: [1m[32m0.69266[0m[0m | time: 33.215s
[2K
| Adam | epoch: 006 | loss: 0.69266 - acc: 0.5352 -- iter: 1376/1468
[A[ATraining Step: 274  | total loss: [1m[32m0.69279[0m[0m | time: 33.980s
[2K
| Adam | epoch: 006 | loss: 0.69279 - acc: 0.5191 -- iter: 1408/1468
[A[ATraining Step: 275  | total loss: [1m[32m0.69273[0m[0m | time: 34.723s
[2K
| Adam | epoch: 006 | loss: 0.69273 - acc: 0.5266 -- iter: 1440/1468
[A[ATraining Step: 276  | total loss: [1m[32m0.69272[0m[0m | time: 37.298s
[2K
| Adam | epoch: 006 | loss: 0.69272 - acc: 0.5364 | val_loss: 0.69246 - val_acc: 0.5730 -- iter: 1468/1468
--
Training Step: 277  | total loss: [1m[32m0.69271[0m[0m | time: 0.730s
[2K
| Adam | epoch: 007 | loss: 0.69271 - acc: 0.5297 -- iter: 0032/1468
[A[ATraining Step: 278  | total loss: [1m[32m0.69272[0m[0m | time: 1.503s
[2K
| Adam | epoch: 007 | loss: 0.69272 - acc: 0.5298 -- iter: 0064/1468
[A[ATraining Step: 279  | total loss: [1m[32m0.69275[0m[0m | time: 2.248s
[2K
| Adam | epoch: 007 | loss: 0.69275 - acc: 0.5331 -- iter: 0096/1468
[A[ATraining Step: 280  | total loss: [1m[32m0.69276[0m[0m | time: 3.009s
[2K
| Adam | epoch: 007 | loss: 0.69276 - acc: 0.5267 -- iter: 0128/1468
[A[ATraining Step: 281  | total loss: [1m[32m0.69255[0m[0m | time: 3.695s
[2K
| Adam | epoch: 007 | loss: 0.69255 - acc: 0.5459 -- iter: 0160/1468
[A[ATraining Step: 282  | total loss: [1m[32m0.69227[0m[0m | time: 4.367s
[2K
| Adam | epoch: 007 | loss: 0.69227 - acc: 0.5520 -- iter: 0192/1468
[A[ATraining Step: 283  | total loss: [1m[32m0.69199[0m[0m | time: 5.188s
[2K
| Adam | epoch: 007 | loss: 0.69199 - acc: 0.5575 -- iter: 0224/1468
[A[ATraining Step: 284  | total loss: [1m[32m0.69210[0m[0m | time: 5.954s
[2K
| Adam | epoch: 007 | loss: 0.69210 - acc: 0.5518 -- iter: 0256/1468
[A[ATraining Step: 285  | total loss: [1m[32m0.69221[0m[0m | time: 6.729s
[2K
| Adam | epoch: 007 | loss: 0.69221 - acc: 0.5560 -- iter: 0288/1468
[A[ATraining Step: 286  | total loss: [1m[32m0.69220[0m[0m | time: 7.476s
[2K
| Adam | epoch: 007 | loss: 0.69220 - acc: 0.5441 -- iter: 0320/1468
[A[ATraining Step: 287  | total loss: [1m[32m0.69191[0m[0m | time: 8.237s
[2K
| Adam | epoch: 007 | loss: 0.69191 - acc: 0.5428 -- iter: 0352/1468
[A[ATraining Step: 288  | total loss: [1m[32m0.69193[0m[0m | time: 9.016s
[2K
| Adam | epoch: 007 | loss: 0.69193 - acc: 0.5385 -- iter: 0384/1468
[A[ATraining Step: 289  | total loss: [1m[32m0.69189[0m[0m | time: 9.787s
[2K
| Adam | epoch: 007 | loss: 0.69189 - acc: 0.5316 -- iter: 0416/1468
[A[ATraining Step: 290  | total loss: [1m[32m0.69190[0m[0m | time: 10.544s
[2K
| Adam | epoch: 007 | loss: 0.69190 - acc: 0.5253 -- iter: 0448/1468
[A[ATraining Step: 291  | total loss: [1m[32m0.69165[0m[0m | time: 11.296s
[2K
| Adam | epoch: 007 | loss: 0.69165 - acc: 0.5290 -- iter: 0480/1468
[A[ATraining Step: 292  | total loss: [1m[32m0.69143[0m[0m | time: 12.017s
[2K
| Adam | epoch: 007 | loss: 0.69143 - acc: 0.5292 -- iter: 0512/1468
[A[ATraining Step: 293  | total loss: [1m[32m0.69149[0m[0m | time: 12.773s
[2K
| Adam | epoch: 007 | loss: 0.69149 - acc: 0.5263 -- iter: 0544/1468
[A[ATraining Step: 294  | total loss: [1m[32m0.69138[0m[0m | time: 13.511s
[2K
| Adam | epoch: 007 | loss: 0.69138 - acc: 0.5299 -- iter: 0576/1468
[A[ATraining Step: 295  | total loss: [1m[32m0.69118[0m[0m | time: 14.291s
[2K
| Adam | epoch: 007 | loss: 0.69118 - acc: 0.5394 -- iter: 0608/1468
[A[ATraining Step: 296  | total loss: [1m[32m0.69117[0m[0m | time: 15.054s
[2K
| Adam | epoch: 007 | loss: 0.69117 - acc: 0.5449 -- iter: 0640/1468
[A[ATraining Step: 297  | total loss: [1m[32m0.69075[0m[0m | time: 15.788s
[2K
| Adam | epoch: 007 | loss: 0.69075 - acc: 0.5623 -- iter: 0672/1468
[A[ATraining Step: 298  | total loss: [1m[32m0.69058[0m[0m | time: 16.559s
[2K
| Adam | epoch: 007 | loss: 0.69058 - acc: 0.5717 -- iter: 0704/1468
[A[ATraining Step: 299  | total loss: [1m[32m0.69067[0m[0m | time: 17.361s
[2K
| Adam | epoch: 007 | loss: 0.69067 - acc: 0.5707 -- iter: 0736/1468
[A[ATraining Step: 300  | total loss: [1m[32m0.69046[0m[0m | time: 18.139s
[2K
| Adam | epoch: 007 | loss: 0.69046 - acc: 0.5699 -- iter: 0768/1468
[A[ATraining Step: 301  | total loss: [1m[32m0.69019[0m[0m | time: 18.882s
[2K
| Adam | epoch: 007 | loss: 0.69019 - acc: 0.5754 -- iter: 0800/1468
[A[ATraining Step: 302  | total loss: [1m[32m0.69047[0m[0m | time: 19.614s
[2K
| Adam | epoch: 007 | loss: 0.69047 - acc: 0.5585 -- iter: 0832/1468
[A[ATraining Step: 303  | total loss: [1m[32m0.69023[0m[0m | time: 20.380s
[2K
| Adam | epoch: 007 | loss: 0.69023 - acc: 0.5652 -- iter: 0864/1468
[A[ATraining Step: 304  | total loss: [1m[32m0.69001[0m[0m | time: 21.095s
[2K
| Adam | epoch: 007 | loss: 0.69001 - acc: 0.5711 -- iter: 0896/1468
[A[ATraining Step: 305  | total loss: [1m[32m0.69045[0m[0m | time: 21.831s
[2K
| Adam | epoch: 007 | loss: 0.69045 - acc: 0.5578 -- iter: 0928/1468
[A[ATraining Step: 306  | total loss: [1m[32m0.69044[0m[0m | time: 22.601s
[2K
| Adam | epoch: 007 | loss: 0.69044 - acc: 0.5551 -- iter: 0960/1468
[A[ATraining Step: 307  | total loss: [1m[32m0.68941[0m[0m | time: 23.376s
[2K
| Adam | epoch: 007 | loss: 0.68941 - acc: 0.5652 -- iter: 0992/1468
[A[ATraining Step: 308  | total loss: [1m[32m0.68913[0m[0m | time: 24.176s
[2K
| Adam | epoch: 007 | loss: 0.68913 - acc: 0.5650 -- iter: 1024/1468
[A[ATraining Step: 309  | total loss: [1m[32m0.68814[0m[0m | time: 24.936s
[2K
| Adam | epoch: 007 | loss: 0.68814 - acc: 0.5710 -- iter: 1056/1468
[A[ATraining Step: 310  | total loss: [1m[32m0.68765[0m[0m | time: 25.678s
[2K
| Adam | epoch: 007 | loss: 0.68765 - acc: 0.5701 -- iter: 1088/1468
[A[ATraining Step: 311  | total loss: [1m[32m0.68837[0m[0m | time: 26.416s
[2K
| Adam | epoch: 007 | loss: 0.68837 - acc: 0.5631 -- iter: 1120/1468
[A[ATraining Step: 312  | total loss: [1m[32m0.68896[0m[0m | time: 27.140s
[2K
| Adam | epoch: 007 | loss: 0.68896 - acc: 0.5537 -- iter: 1152/1468
[A[ATraining Step: 313  | total loss: [1m[32m0.68763[0m[0m | time: 27.968s
[2K
| Adam | epoch: 007 | loss: 0.68763 - acc: 0.5514 -- iter: 1184/1468
[A[ATraining Step: 314  | total loss: [1m[32m0.68765[0m[0m | time: 29.067s
[2K
| Adam | epoch: 007 | loss: 0.68765 - acc: 0.5494 -- iter: 1216/1468
[A[ATraining Step: 315  | total loss: [1m[32m0.68784[0m[0m | time: 29.736s
[2K
| Adam | epoch: 007 | loss: 0.68784 - acc: 0.5445 -- iter: 1248/1468
[A[ATraining Step: 316  | total loss: [1m[32m0.68662[0m[0m | time: 30.441s
[2K
| Adam | epoch: 007 | loss: 0.68662 - acc: 0.5556 -- iter: 1280/1468
[A[ATraining Step: 317  | total loss: [1m[32m0.68650[0m[0m | time: 31.270s
[2K
| Adam | epoch: 007 | loss: 0.68650 - acc: 0.5470 -- iter: 1312/1468
[A[ATraining Step: 318  | total loss: [1m[32m0.68572[0m[0m | time: 31.992s
[2K
| Adam | epoch: 007 | loss: 0.68572 - acc: 0.5548 -- iter: 1344/1468
[A[ATraining Step: 319  | total loss: [1m[32m0.68619[0m[0m | time: 32.809s
[2K
| Adam | epoch: 007 | loss: 0.68619 - acc: 0.5524 -- iter: 1376/1468
[A[ATraining Step: 320  | total loss: [1m[32m0.68446[0m[0m | time: 33.541s
[2K
| Adam | epoch: 007 | loss: 0.68446 - acc: 0.5628 -- iter: 1408/1468
[A[ATraining Step: 321  | total loss: [1m[32m0.68451[0m[0m | time: 34.297s
[2K
| Adam | epoch: 007 | loss: 0.68451 - acc: 0.5628 -- iter: 1440/1468
[A[ATraining Step: 322  | total loss: [1m[32m0.68757[0m[0m | time: 36.875s
[2K
| Adam | epoch: 007 | loss: 0.68757 - acc: 0.5502 | val_loss: 0.70233 - val_acc: 0.4771 -- iter: 1468/1468
--
Training Step: 323  | total loss: [1m[32m0.68915[0m[0m | time: 0.764s
[2K
| Adam | epoch: 008 | loss: 0.68915 - acc: 0.5421 -- iter: 0032/1468
[A[ATraining Step: 324  | total loss: [1m[32m0.68908[0m[0m | time: 1.563s
[2K
| Adam | epoch: 008 | loss: 0.68908 - acc: 0.5441 -- iter: 0064/1468
[A[ATraining Step: 325  | total loss: [1m[32m0.68833[0m[0m | time: 2.306s
[2K
| Adam | epoch: 008 | loss: 0.68833 - acc: 0.5460 -- iter: 0096/1468
[A[ATraining Step: 326  | total loss: [1m[32m0.68572[0m[0m | time: 3.116s
[2K
| Adam | epoch: 008 | loss: 0.68572 - acc: 0.5570 -- iter: 0128/1468
[A[ATraining Step: 327  | total loss: [1m[32m0.68466[0m[0m | time: 3.910s
[2K
| Adam | epoch: 008 | loss: 0.68466 - acc: 0.5607 -- iter: 0160/1468
[A[ATraining Step: 328  | total loss: [1m[32m0.68450[0m[0m | time: 4.622s
[2K
| Adam | epoch: 008 | loss: 0.68450 - acc: 0.5577 -- iter: 0192/1468
[A[ATraining Step: 329  | total loss: [1m[32m0.68488[0m[0m | time: 5.333s
[2K
| Adam | epoch: 008 | loss: 0.68488 - acc: 0.5555 -- iter: 0224/1468
[A[ATraining Step: 330  | total loss: [1m[32m0.68446[0m[0m | time: 6.087s
[2K
| Adam | epoch: 008 | loss: 0.68446 - acc: 0.5571 -- iter: 0256/1468
[A[ATraining Step: 331  | total loss: [1m[32m0.68230[0m[0m | time: 6.860s
[2K
| Adam | epoch: 008 | loss: 0.68230 - acc: 0.5670 -- iter: 0288/1468
[A[ATraining Step: 332  | total loss: [1m[32m0.68108[0m[0m | time: 7.606s
[2K
| Adam | epoch: 008 | loss: 0.68108 - acc: 0.5760 -- iter: 0320/1468
[A[ATraining Step: 333  | total loss: [1m[32m0.67921[0m[0m | time: 8.328s
[2K
| Adam | epoch: 008 | loss: 0.67921 - acc: 0.5871 -- iter: 0352/1468
[A[ATraining Step: 334  | total loss: [1m[32m0.67977[0m[0m | time: 9.081s
[2K
| Adam | epoch: 008 | loss: 0.67977 - acc: 0.5846 -- iter: 0384/1468
[A[ATraining Step: 335  | total loss: [1m[32m0.68053[0m[0m | time: 9.842s
[2K
| Adam | epoch: 008 | loss: 0.68053 - acc: 0.5824 -- iter: 0416/1468
[A[ATraining Step: 336  | total loss: [1m[32m0.67680[0m[0m | time: 10.637s
[2K
| Adam | epoch: 008 | loss: 0.67680 - acc: 0.5929 -- iter: 0448/1468
[A[ATraining Step: 337  | total loss: [1m[32m0.67423[0m[0m | time: 11.402s
[2K
| Adam | epoch: 008 | loss: 0.67423 - acc: 0.5930 -- iter: 0480/1468
[A[ATraining Step: 338  | total loss: [1m[32m0.67477[0m[0m | time: 12.266s
[2K
| Adam | epoch: 008 | loss: 0.67477 - acc: 0.5931 -- iter: 0512/1468
[A[ATraining Step: 339  | total loss: [1m[32m0.67571[0m[0m | time: 13.022s
[2K
| Adam | epoch: 008 | loss: 0.67571 - acc: 0.5869 -- iter: 0544/1468
[A[ATraining Step: 340  | total loss: [1m[32m0.67326[0m[0m | time: 13.756s
[2K
| Adam | epoch: 008 | loss: 0.67326 - acc: 0.5907 -- iter: 0576/1468
[A[ATraining Step: 341  | total loss: [1m[32m0.67778[0m[0m | time: 14.525s
[2K
| Adam | epoch: 008 | loss: 0.67778 - acc: 0.5785 -- iter: 0608/1468
[A[ATraining Step: 342  | total loss: [1m[32m0.68115[0m[0m | time: 15.316s
[2K
| Adam | epoch: 008 | loss: 0.68115 - acc: 0.5613 -- iter: 0640/1468
[A[ATraining Step: 343  | total loss: [1m[32m0.67721[0m[0m | time: 16.076s
[2K
| Adam | epoch: 008 | loss: 0.67721 - acc: 0.5708 -- iter: 0672/1468
[A[ATraining Step: 344  | total loss: [1m[32m0.67504[0m[0m | time: 16.849s
[2K
| Adam | epoch: 008 | loss: 0.67504 - acc: 0.5793 -- iter: 0704/1468
[A[ATraining Step: 345  | total loss: [1m[32m0.67692[0m[0m | time: 17.594s
[2K
| Adam | epoch: 008 | loss: 0.67692 - acc: 0.5652 -- iter: 0736/1468
[A[ATraining Step: 346  | total loss: [1m[32m0.67752[0m[0m | time: 18.313s
[2K
| Adam | epoch: 008 | loss: 0.67752 - acc: 0.5680 -- iter: 0768/1468
[A[ATraining Step: 347  | total loss: [1m[32m0.67869[0m[0m | time: 19.097s
[2K
| Adam | epoch: 008 | loss: 0.67869 - acc: 0.5737 -- iter: 0800/1468
[A[ATraining Step: 348  | total loss: [1m[32m0.68067[0m[0m | time: 19.841s
[2K
| Adam | epoch: 008 | loss: 0.68067 - acc: 0.5726 -- iter: 0832/1468
[A[ATraining Step: 349  | total loss: [1m[32m0.68006[0m[0m | time: 20.585s
[2K
| Adam | epoch: 008 | loss: 0.68006 - acc: 0.5810 -- iter: 0864/1468
[A[ATraining Step: 350  | total loss: [1m[32m0.68121[0m[0m | time: 21.361s
[2K
| Adam | epoch: 008 | loss: 0.68121 - acc: 0.5791 -- iter: 0896/1468
[A[ATraining Step: 351  | total loss: [1m[32m0.68167[0m[0m | time: 22.202s
[2K
| Adam | epoch: 008 | loss: 0.68167 - acc: 0.5774 -- iter: 0928/1468
[A[ATraining Step: 352  | total loss: [1m[32m0.67967[0m[0m | time: 23.284s
[2K
| Adam | epoch: 008 | loss: 0.67967 - acc: 0.5760 -- iter: 0960/1468
[A[ATraining Step: 353  | total loss: [1m[32m0.68068[0m[0m | time: 23.911s
[2K
| Adam | epoch: 008 | loss: 0.68068 - acc: 0.5809 -- iter: 0992/1468
[A[ATraining Step: 354  | total loss: [1m[32m0.68208[0m[0m | time: 24.594s
[2K
| Adam | epoch: 008 | loss: 0.68208 - acc: 0.5853 -- iter: 1024/1468
[A[ATraining Step: 355  | total loss: [1m[32m0.67912[0m[0m | time: 25.352s
[2K
| Adam | epoch: 008 | loss: 0.67912 - acc: 0.5892 -- iter: 1056/1468
[A[ATraining Step: 356  | total loss: [1m[32m0.67843[0m[0m | time: 26.089s
[2K
| Adam | epoch: 008 | loss: 0.67843 - acc: 0.5897 -- iter: 1088/1468
[A[ATraining Step: 357  | total loss: [1m[32m0.67697[0m[0m | time: 26.841s
[2K
| Adam | epoch: 008 | loss: 0.67697 - acc: 0.5807 -- iter: 1120/1468
[A[ATraining Step: 358  | total loss: [1m[32m0.67381[0m[0m | time: 27.586s
[2K
| Adam | epoch: 008 | loss: 0.67381 - acc: 0.5914 -- iter: 1152/1468
[A[ATraining Step: 359  | total loss: [1m[32m0.67611[0m[0m | time: 28.309s
[2K
| Adam | epoch: 008 | loss: 0.67611 - acc: 0.5791 -- iter: 1184/1468
[A[ATraining Step: 360  | total loss: [1m[32m0.67514[0m[0m | time: 29.092s
[2K
| Adam | epoch: 008 | loss: 0.67514 - acc: 0.5806 -- iter: 1216/1468
[A[ATraining Step: 361  | total loss: [1m[32m0.67100[0m[0m | time: 29.813s
[2K
| Adam | epoch: 008 | loss: 0.67100 - acc: 0.6007 -- iter: 1248/1468
[A[ATraining Step: 362  | total loss: [1m[32m0.66954[0m[0m | time: 30.543s
[2K
| Adam | epoch: 008 | loss: 0.66954 - acc: 0.6125 -- iter: 1280/1468
[A[ATraining Step: 363  | total loss: [1m[32m0.66823[0m[0m | time: 31.304s
[2K
| Adam | epoch: 008 | loss: 0.66823 - acc: 0.6137 -- iter: 1312/1468
[A[ATraining Step: 364  | total loss: [1m[32m0.67091[0m[0m | time: 32.036s
[2K
| Adam | epoch: 008 | loss: 0.67091 - acc: 0.6086 -- iter: 1344/1468
[A[ATraining Step: 365  | total loss: [1m[32m0.67009[0m[0m | time: 32.765s
[2K
| Adam | epoch: 008 | loss: 0.67009 - acc: 0.6071 -- iter: 1376/1468
[A[ATraining Step: 366  | total loss: [1m[32m0.67249[0m[0m | time: 33.628s
[2K
| Adam | epoch: 008 | loss: 0.67249 - acc: 0.5964 -- iter: 1408/1468
[A[ATraining Step: 367  | total loss: [1m[32m0.67126[0m[0m | time: 34.341s
[2K
| Adam | epoch: 008 | loss: 0.67126 - acc: 0.6024 -- iter: 1440/1468
[A[ATraining Step: 368  | total loss: [1m[32m0.67198[0m[0m | time: 37.008s
[2K
| Adam | epoch: 008 | loss: 0.67198 - acc: 0.6078 | val_loss: 0.66324 - val_acc: 0.5948 -- iter: 1468/1468
--
Training Step: 369  | total loss: [1m[32m0.66503[0m[0m | time: 0.750s
[2K
| Adam | epoch: 009 | loss: 0.66503 - acc: 0.6251 -- iter: 0032/1468
[A[ATraining Step: 370  | total loss: [1m[32m0.66812[0m[0m | time: 1.477s
[2K
| Adam | epoch: 009 | loss: 0.66812 - acc: 0.6157 -- iter: 0064/1468
[A[ATraining Step: 371  | total loss: [1m[32m0.66601[0m[0m | time: 2.229s
[2K
| Adam | epoch: 009 | loss: 0.66601 - acc: 0.6198 -- iter: 0096/1468
[A[ATraining Step: 372  | total loss: [1m[32m0.66436[0m[0m | time: 2.978s
[2K
| Adam | epoch: 009 | loss: 0.66436 - acc: 0.6203 -- iter: 0128/1468
[A[ATraining Step: 373  | total loss: [1m[32m0.66449[0m[0m | time: 3.745s
[2K
| Adam | epoch: 009 | loss: 0.66449 - acc: 0.6114 -- iter: 0160/1468
[A[ATraining Step: 374  | total loss: [1m[32m0.65936[0m[0m | time: 4.480s
[2K
| Adam | epoch: 009 | loss: 0.65936 - acc: 0.6221 -- iter: 0192/1468
[A[ATraining Step: 375  | total loss: [1m[32m0.65915[0m[0m | time: 5.116s
[2K
| Adam | epoch: 009 | loss: 0.65915 - acc: 0.6224 -- iter: 0224/1468
[A[ATraining Step: 376  | total loss: [1m[32m0.66768[0m[0m | time: 5.733s
[2K
| Adam | epoch: 009 | loss: 0.66768 - acc: 0.5995 -- iter: 0256/1468
[A[ATraining Step: 377  | total loss: [1m[32m0.67491[0m[0m | time: 6.526s
[2K
| Adam | epoch: 009 | loss: 0.67491 - acc: 0.5788 -- iter: 0288/1468
[A[ATraining Step: 378  | total loss: [1m[32m0.67288[0m[0m | time: 7.318s
[2K
| Adam | epoch: 009 | loss: 0.67288 - acc: 0.5866 -- iter: 0320/1468
[A[ATraining Step: 379  | total loss: [1m[32m0.66475[0m[0m | time: 8.112s
[2K
| Adam | epoch: 009 | loss: 0.66475 - acc: 0.5998 -- iter: 0352/1468
[A[ATraining Step: 380  | total loss: [1m[32m0.65927[0m[0m | time: 8.950s
[2K
| Adam | epoch: 009 | loss: 0.65927 - acc: 0.6179 -- iter: 0384/1468
[A[ATraining Step: 381  | total loss: [1m[32m0.65936[0m[0m | time: 9.682s
[2K
| Adam | epoch: 009 | loss: 0.65936 - acc: 0.6155 -- iter: 0416/1468
[A[ATraining Step: 382  | total loss: [1m[32m0.65918[0m[0m | time: 10.572s
[2K
| Adam | epoch: 009 | loss: 0.65918 - acc: 0.6165 -- iter: 0448/1468
[A[ATraining Step: 383  | total loss: [1m[32m0.66029[0m[0m | time: 11.309s
[2K
| Adam | epoch: 009 | loss: 0.66029 - acc: 0.6173 -- iter: 0480/1468
[A[ATraining Step: 384  | total loss: [1m[32m0.66150[0m[0m | time: 12.028s
[2K
| Adam | epoch: 009 | loss: 0.66150 - acc: 0.6025 -- iter: 0512/1468
[A[ATraining Step: 385  | total loss: [1m[32m0.66224[0m[0m | time: 12.799s
[2K
| Adam | epoch: 009 | loss: 0.66224 - acc: 0.6016 -- iter: 0544/1468
[A[ATraining Step: 386  | total loss: [1m[32m0.65709[0m[0m | time: 13.627s
[2K
| Adam | epoch: 009 | loss: 0.65709 - acc: 0.6102 -- iter: 0576/1468
[A[ATraining Step: 387  | total loss: [1m[32m0.65412[0m[0m | time: 14.420s
[2K
| Adam | epoch: 009 | loss: 0.65412 - acc: 0.6085 -- iter: 0608/1468
[A[ATraining Step: 388  | total loss: [1m[32m0.65298[0m[0m | time: 15.270s
[2K
| Adam | epoch: 009 | loss: 0.65298 - acc: 0.6164 -- iter: 0640/1468
[A[ATraining Step: 389  | total loss: [1m[32m0.65364[0m[0m | time: 16.343s
[2K
| Adam | epoch: 009 | loss: 0.65364 - acc: 0.6204 -- iter: 0672/1468
[A[ATraining Step: 390  | total loss: [1m[32m0.65480[0m[0m | time: 16.944s
[2K
| Adam | epoch: 009 | loss: 0.65480 - acc: 0.6209 -- iter: 0704/1468
[A[ATraining Step: 391  | total loss: [1m[32m0.66127[0m[0m | time: 17.550s
[2K
| Adam | epoch: 009 | loss: 0.66127 - acc: 0.6057 -- iter: 0736/1468
[A[ATraining Step: 392  | total loss: [1m[32m0.65848[0m[0m | time: 18.213s
[2K
| Adam | epoch: 009 | loss: 0.65848 - acc: 0.6107 -- iter: 0768/1468
[A[ATraining Step: 393  | total loss: [1m[32m0.65401[0m[0m | time: 18.956s
[2K
| Adam | epoch: 009 | loss: 0.65401 - acc: 0.6184 -- iter: 0800/1468
[A[ATraining Step: 394  | total loss: [1m[32m0.64988[0m[0m | time: 19.721s
[2K
| Adam | epoch: 009 | loss: 0.64988 - acc: 0.6222 -- iter: 0832/1468
[A[ATraining Step: 395  | total loss: [1m[32m0.64909[0m[0m | time: 20.564s
[2K
| Adam | epoch: 009 | loss: 0.64909 - acc: 0.6287 -- iter: 0864/1468
[A[ATraining Step: 396  | total loss: [1m[32m0.65074[0m[0m | time: 21.307s
[2K
| Adam | epoch: 009 | loss: 0.65074 - acc: 0.6190 -- iter: 0896/1468
[A[ATraining Step: 397  | total loss: [1m[32m0.64765[0m[0m | time: 22.124s
[2K
| Adam | epoch: 009 | loss: 0.64765 - acc: 0.6258 -- iter: 0928/1468
[A[ATraining Step: 398  | total loss: [1m[32m0.64637[0m[0m | time: 22.945s
[2K
| Adam | epoch: 009 | loss: 0.64637 - acc: 0.6257 -- iter: 0960/1468
[A[ATraining Step: 399  | total loss: [1m[32m0.64460[0m[0m | time: 23.730s
[2K
| Adam | epoch: 009 | loss: 0.64460 - acc: 0.6257 -- iter: 0992/1468
[A[ATraining Step: 400  | total loss: [1m[32m0.64165[0m[0m | time: 26.305s
[2K
| Adam | epoch: 009 | loss: 0.64165 - acc: 0.6318 | val_loss: 0.66812 - val_acc: 0.6013 -- iter: 1024/1468
--
Training Step: 401  | total loss: [1m[32m0.63717[0m[0m | time: 27.112s
[2K
| Adam | epoch: 009 | loss: 0.63717 - acc: 0.6374 -- iter: 1056/1468
[A[ATraining Step: 402  | total loss: [1m[32m0.64160[0m[0m | time: 27.857s
[2K
| Adam | epoch: 009 | loss: 0.64160 - acc: 0.6299 -- iter: 1088/1468
[A[ATraining Step: 403  | total loss: [1m[32m0.63820[0m[0m | time: 28.613s
[2K
| Adam | epoch: 009 | loss: 0.63820 - acc: 0.6326 -- iter: 1120/1468
[A[ATraining Step: 404  | total loss: [1m[32m0.63873[0m[0m | time: 29.393s
[2K
| Adam | epoch: 009 | loss: 0.63873 - acc: 0.6255 -- iter: 1152/1468
[A[ATraining Step: 405  | total loss: [1m[32m0.63930[0m[0m | time: 30.104s
[2K
| Adam | epoch: 009 | loss: 0.63930 - acc: 0.6192 -- iter: 1184/1468
[A[ATraining Step: 406  | total loss: [1m[32m0.63659[0m[0m | time: 30.802s
[2K
| Adam | epoch: 009 | loss: 0.63659 - acc: 0.6292 -- iter: 1216/1468
[A[ATraining Step: 407  | total loss: [1m[32m0.63509[0m[0m | time: 31.527s
[2K
| Adam | epoch: 009 | loss: 0.63509 - acc: 0.6288 -- iter: 1248/1468
[A[ATraining Step: 408  | total loss: [1m[32m0.63528[0m[0m | time: 32.280s
[2K
| Adam | epoch: 009 | loss: 0.63528 - acc: 0.6253 -- iter: 1280/1468
[A[ATraining Step: 409  | total loss: [1m[32m0.62950[0m[0m | time: 33.062s
[2K
| Adam | epoch: 009 | loss: 0.62950 - acc: 0.6346 -- iter: 1312/1468
[A[ATraining Step: 410  | total loss: [1m[32m0.63096[0m[0m | time: 33.814s
[2K
| Adam | epoch: 009 | loss: 0.63096 - acc: 0.6368 -- iter: 1344/1468
[A[ATraining Step: 411  | total loss: [1m[32m0.63036[0m[0m | time: 34.598s
[2K
| Adam | epoch: 009 | loss: 0.63036 - acc: 0.6356 -- iter: 1376/1468
[A[ATraining Step: 412  | total loss: [1m[32m0.62521[0m[0m | time: 35.348s
[2K
| Adam | epoch: 009 | loss: 0.62521 - acc: 0.6533 -- iter: 1408/1468
[A[ATraining Step: 413  | total loss: [1m[32m0.62254[0m[0m | time: 36.093s
[2K
| Adam | epoch: 009 | loss: 0.62254 - acc: 0.6598 -- iter: 1440/1468
[A[ATraining Step: 414  | total loss: [1m[32m0.62276[0m[0m | time: 38.633s
[2K
| Adam | epoch: 009 | loss: 0.62276 - acc: 0.6501 | val_loss: 0.64373 - val_acc: 0.6078 -- iter: 1468/1468
--
Training Step: 415  | total loss: [1m[32m0.62621[0m[0m | time: 0.777s
[2K
| Adam | epoch: 010 | loss: 0.62621 - acc: 0.6570 -- iter: 0032/1468
[A[ATraining Step: 416  | total loss: [1m[32m0.61757[0m[0m | time: 1.559s
[2K
| Adam | epoch: 010 | loss: 0.61757 - acc: 0.6725 -- iter: 0064/1468
[A[ATraining Step: 417  | total loss: [1m[32m0.61647[0m[0m | time: 2.300s
[2K
| Adam | epoch: 010 | loss: 0.61647 - acc: 0.6709 -- iter: 0096/1468
[A[ATraining Step: 418  | total loss: [1m[32m0.62022[0m[0m | time: 3.093s
[2K
| Adam | epoch: 010 | loss: 0.62022 - acc: 0.6569 -- iter: 0128/1468
[A[ATraining Step: 419  | total loss: [1m[32m0.62305[0m[0m | time: 3.876s
[2K
| Adam | epoch: 010 | loss: 0.62305 - acc: 0.6444 -- iter: 0160/1468
[A[ATraining Step: 420  | total loss: [1m[32m0.61887[0m[0m | time: 4.611s
[2K
| Adam | epoch: 010 | loss: 0.61887 - acc: 0.6487 -- iter: 0192/1468
[A[ATraining Step: 421  | total loss: [1m[32m0.62613[0m[0m | time: 5.380s
[2K
| Adam | epoch: 010 | loss: 0.62613 - acc: 0.6338 -- iter: 0224/1468
[A[ATraining Step: 422  | total loss: [1m[32m0.62492[0m[0m | time: 6.035s
[2K
| Adam | epoch: 010 | loss: 0.62492 - acc: 0.6423 -- iter: 0256/1468
[A[ATraining Step: 423  | total loss: [1m[32m0.62723[0m[0m | time: 6.695s
[2K
| Adam | epoch: 010 | loss: 0.62723 - acc: 0.6388 -- iter: 0288/1468
[A[ATraining Step: 424  | total loss: [1m[32m0.62530[0m[0m | time: 7.536s
[2K
| Adam | epoch: 010 | loss: 0.62530 - acc: 0.6392 -- iter: 0320/1468
[A[ATraining Step: 425  | total loss: [1m[32m0.61904[0m[0m | time: 8.670s
[2K
| Adam | epoch: 010 | loss: 0.61904 - acc: 0.6440 -- iter: 0352/1468
[A[ATraining Step: 426  | total loss: [1m[32m0.61047[0m[0m | time: 9.303s
[2K
| Adam | epoch: 010 | loss: 0.61047 - acc: 0.6640 -- iter: 0384/1468
[A[ATraining Step: 427  | total loss: [1m[32m0.60775[0m[0m | time: 9.920s
[2K
| Adam | epoch: 010 | loss: 0.60775 - acc: 0.6663 -- iter: 0416/1468
[A[ATraining Step: 428  | total loss: [1m[32m0.62479[0m[0m | time: 10.547s
[2K
| Adam | epoch: 010 | loss: 0.62479 - acc: 0.6435 -- iter: 0448/1468
[A[ATraining Step: 429  | total loss: [1m[32m0.62020[0m[0m | time: 11.354s
[2K
| Adam | epoch: 010 | loss: 0.62020 - acc: 0.6572 -- iter: 0480/1468
[A[ATraining Step: 430  | total loss: [1m[32m0.61935[0m[0m | time: 12.146s
[2K
| Adam | epoch: 010 | loss: 0.61935 - acc: 0.6603 -- iter: 0512/1468
[A[ATraining Step: 431  | total loss: [1m[32m0.62075[0m[0m | time: 12.890s
[2K
| Adam | epoch: 010 | loss: 0.62075 - acc: 0.6567 -- iter: 0544/1468
[A[ATraining Step: 432  | total loss: [1m[32m0.62431[0m[0m | time: 13.658s
[2K
| Adam | epoch: 010 | loss: 0.62431 - acc: 0.6536 -- iter: 0576/1468
[A[ATraining Step: 433  | total loss: [1m[32m0.62327[0m[0m | time: 14.399s
[2K
| Adam | epoch: 010 | loss: 0.62327 - acc: 0.6507 -- iter: 0608/1468
[A[ATraining Step: 434  | total loss: [1m[32m0.62833[0m[0m | time: 15.117s
[2K
| Adam | epoch: 010 | loss: 0.62833 - acc: 0.6419 -- iter: 0640/1468
[A[ATraining Step: 435  | total loss: [1m[32m0.62435[0m[0m | time: 15.910s
[2K
| Adam | epoch: 010 | loss: 0.62435 - acc: 0.6527 -- iter: 0672/1468
[A[ATraining Step: 436  | total loss: [1m[32m0.62329[0m[0m | time: 16.665s
[2K
| Adam | epoch: 010 | loss: 0.62329 - acc: 0.6531 -- iter: 0704/1468
[A[ATraining Step: 437  | total loss: [1m[32m0.62494[0m[0m | time: 17.445s
[2K
| Adam | epoch: 010 | loss: 0.62494 - acc: 0.6534 -- iter: 0736/1468
[A[ATraining Step: 438  | total loss: [1m[32m0.62518[0m[0m | time: 18.190s
[2K
| Adam | epoch: 010 | loss: 0.62518 - acc: 0.6505 -- iter: 0768/1468
[A[ATraining Step: 439  | total loss: [1m[32m0.61837[0m[0m | time: 18.915s
[2K
| Adam | epoch: 010 | loss: 0.61837 - acc: 0.6605 -- iter: 0800/1468
[A[ATraining Step: 440  | total loss: [1m[32m0.61760[0m[0m | time: 19.669s
[2K
| Adam | epoch: 010 | loss: 0.61760 - acc: 0.6663 -- iter: 0832/1468
[A[ATraining Step: 441  | total loss: [1m[32m0.61565[0m[0m | time: 20.447s
[2K
| Adam | epoch: 010 | loss: 0.61565 - acc: 0.6747 -- iter: 0864/1468
[A[ATraining Step: 442  | total loss: [1m[32m0.61727[0m[0m | time: 21.178s
[2K
| Adam | epoch: 010 | loss: 0.61727 - acc: 0.6697 -- iter: 0896/1468
[A[ATraining Step: 443  | total loss: [1m[32m0.61256[0m[0m | time: 21.957s
[2K
| Adam | epoch: 010 | loss: 0.61256 - acc: 0.6777 -- iter: 0928/1468
[A[ATraining Step: 444  | total loss: [1m[32m0.60205[0m[0m | time: 22.744s
[2K
| Adam | epoch: 010 | loss: 0.60205 - acc: 0.6943 -- iter: 0960/1468
[A[ATraining Step: 445  | total loss: [1m[32m0.60750[0m[0m | time: 23.569s
[2K
| Adam | epoch: 010 | loss: 0.60750 - acc: 0.6874 -- iter: 0992/1468
[A[ATraining Step: 446  | total loss: [1m[32m0.60062[0m[0m | time: 24.313s
[2K
| Adam | epoch: 010 | loss: 0.60062 - acc: 0.6999 -- iter: 1024/1468
[A[ATraining Step: 447  | total loss: [1m[32m0.59884[0m[0m | time: 25.036s
[2K
| Adam | epoch: 010 | loss: 0.59884 - acc: 0.6987 -- iter: 1056/1468
[A[ATraining Step: 448  | total loss: [1m[32m0.59830[0m[0m | time: 25.734s
[2K
| Adam | epoch: 010 | loss: 0.59830 - acc: 0.6913 -- iter: 1088/1468
[A[ATraining Step: 449  | total loss: [1m[32m0.60565[0m[0m | time: 26.600s
[2K
| Adam | epoch: 010 | loss: 0.60565 - acc: 0.6753 -- iter: 1120/1468
[A[ATraining Step: 450  | total loss: [1m[32m0.60330[0m[0m | time: 27.441s
[2K
| Adam | epoch: 010 | loss: 0.60330 - acc: 0.6796 -- iter: 1152/1468
[A[ATraining Step: 451  | total loss: [1m[32m0.61137[0m[0m | time: 28.158s
[2K
| Adam | epoch: 010 | loss: 0.61137 - acc: 0.6711 -- iter: 1184/1468
[A[ATraining Step: 452  | total loss: [1m[32m0.60369[0m[0m | time: 28.949s
[2K
| Adam | epoch: 010 | loss: 0.60369 - acc: 0.6790 -- iter: 1216/1468
[A[ATraining Step: 453  | total loss: [1m[32m0.59336[0m[0m | time: 29.692s
[2K
| Adam | epoch: 010 | loss: 0.59336 - acc: 0.6892 -- iter: 1248/1468
[A[ATraining Step: 454  | total loss: [1m[32m0.58765[0m[0m | time: 30.473s
[2K
| Adam | epoch: 010 | loss: 0.58765 - acc: 0.6984 -- iter: 1280/1468
[A[ATraining Step: 455  | total loss: [1m[32m0.59213[0m[0m | time: 31.284s
[2K
| Adam | epoch: 010 | loss: 0.59213 - acc: 0.6817 -- iter: 1312/1468
[A[ATraining Step: 456  | total loss: [1m[32m0.58055[0m[0m | time: 32.013s
[2K
| Adam | epoch: 010 | loss: 0.58055 - acc: 0.6948 -- iter: 1344/1468
[A[ATraining Step: 457  | total loss: [1m[32m0.57265[0m[0m | time: 32.796s
[2K
| Adam | epoch: 010 | loss: 0.57265 - acc: 0.7159 -- iter: 1376/1468
[A[ATraining Step: 458  | total loss: [1m[32m0.56998[0m[0m | time: 33.537s
[2K
| Adam | epoch: 010 | loss: 0.56998 - acc: 0.7162 -- iter: 1408/1468
[A[ATraining Step: 459  | total loss: [1m[32m0.56777[0m[0m | time: 34.310s
[2K
| Adam | epoch: 010 | loss: 0.56777 - acc: 0.7196 -- iter: 1440/1468
[A[ATraining Step: 460  | total loss: [1m[32m0.56513[0m[0m | time: 36.810s
[2K
| Adam | epoch: 010 | loss: 0.56513 - acc: 0.7226 | val_loss: 0.58140 - val_acc: 0.6906 -- iter: 1468/1468
--
Training Step: 461  | total loss: [1m[32m0.57191[0m[0m | time: 0.754s
[2K
| Adam | epoch: 011 | loss: 0.57191 - acc: 0.7097 -- iter: 0032/1468
[A[ATraining Step: 462  | total loss: [1m[32m0.56325[0m[0m | time: 1.482s
[2K
| Adam | epoch: 011 | loss: 0.56325 - acc: 0.7169 -- iter: 0064/1468
[A[ATraining Step: 463  | total loss: [1m[32m0.57290[0m[0m | time: 2.304s
[2K
| Adam | epoch: 011 | loss: 0.57290 - acc: 0.7014 -- iter: 0096/1468
[A[ATraining Step: 464  | total loss: [1m[32m0.56414[0m[0m | time: 3.359s
[2K
| Adam | epoch: 011 | loss: 0.56414 - acc: 0.7032 -- iter: 0128/1468
[A[ATraining Step: 465  | total loss: [1m[32m0.56499[0m[0m | time: 4.013s
[2K
| Adam | epoch: 011 | loss: 0.56499 - acc: 0.6954 -- iter: 0160/1468
[A[ATraining Step: 466  | total loss: [1m[32m0.57007[0m[0m | time: 4.763s
[2K
| Adam | epoch: 011 | loss: 0.57007 - acc: 0.6914 -- iter: 0192/1468
[A[ATraining Step: 467  | total loss: [1m[32m0.55656[0m[0m | time: 5.535s
[2K
| Adam | epoch: 011 | loss: 0.55656 - acc: 0.7098 -- iter: 0224/1468
[A[ATraining Step: 468  | total loss: [1m[32m0.55622[0m[0m | time: 6.352s
[2K
| Adam | epoch: 011 | loss: 0.55622 - acc: 0.7013 -- iter: 0256/1468
[A[ATraining Step: 469  | total loss: [1m[32m0.55115[0m[0m | time: 7.261s
[2K
| Adam | epoch: 011 | loss: 0.55115 - acc: 0.7093 -- iter: 0288/1468
[A[ATraining Step: 470  | total loss: [1m[32m0.55061[0m[0m | time: 7.969s
[2K
| Adam | epoch: 011 | loss: 0.55061 - acc: 0.7134 -- iter: 0320/1468
[A[ATraining Step: 471  | total loss: [1m[32m0.55095[0m[0m | time: 8.583s
[2K
| Adam | epoch: 011 | loss: 0.55095 - acc: 0.7170 -- iter: 0352/1468
[A[ATraining Step: 472  | total loss: [1m[32m0.55292[0m[0m | time: 9.213s
[2K
| Adam | epoch: 011 | loss: 0.55292 - acc: 0.7141 -- iter: 0384/1468
[A[ATraining Step: 473  | total loss: [1m[32m0.55330[0m[0m | time: 9.967s
[2K
| Adam | epoch: 011 | loss: 0.55330 - acc: 0.7208 -- iter: 0416/1468
[A[ATraining Step: 474  | total loss: [1m[32m0.54266[0m[0m | time: 10.748s
[2K
| Adam | epoch: 011 | loss: 0.54266 - acc: 0.7300 -- iter: 0448/1468
[A[ATraining Step: 475  | total loss: [1m[32m0.54184[0m[0m | time: 11.483s
[2K
| Adam | epoch: 011 | loss: 0.54184 - acc: 0.7320 -- iter: 0480/1468
[A[ATraining Step: 476  | total loss: [1m[32m0.53815[0m[0m | time: 12.225s
[2K
| Adam | epoch: 011 | loss: 0.53815 - acc: 0.7400 -- iter: 0512/1468
[A[ATraining Step: 477  | total loss: [1m[32m0.53799[0m[0m | time: 12.959s
[2K
| Adam | epoch: 011 | loss: 0.53799 - acc: 0.7410 -- iter: 0544/1468
[A[ATraining Step: 478  | total loss: [1m[32m0.54351[0m[0m | time: 13.700s
[2K
| Adam | epoch: 011 | loss: 0.54351 - acc: 0.7294 -- iter: 0576/1468
[A[ATraining Step: 479  | total loss: [1m[32m0.54177[0m[0m | time: 14.451s
[2K
| Adam | epoch: 011 | loss: 0.54177 - acc: 0.7284 -- iter: 0608/1468
[A[ATraining Step: 480  | total loss: [1m[32m0.55727[0m[0m | time: 15.177s
[2K
| Adam | epoch: 011 | loss: 0.55727 - acc: 0.7086 -- iter: 0640/1468
[A[ATraining Step: 481  | total loss: [1m[32m0.56066[0m[0m | time: 15.911s
[2K
| Adam | epoch: 011 | loss: 0.56066 - acc: 0.7065 -- iter: 0672/1468
[A[ATraining Step: 482  | total loss: [1m[32m0.54202[0m[0m | time: 16.664s
[2K
| Adam | epoch: 011 | loss: 0.54202 - acc: 0.7234 -- iter: 0704/1468
[A[ATraining Step: 483  | total loss: [1m[32m0.53935[0m[0m | time: 17.426s
[2K
| Adam | epoch: 011 | loss: 0.53935 - acc: 0.7260 -- iter: 0736/1468
[A[ATraining Step: 484  | total loss: [1m[32m0.53976[0m[0m | time: 18.184s
[2K
| Adam | epoch: 011 | loss: 0.53976 - acc: 0.7222 -- iter: 0768/1468
[A[ATraining Step: 485  | total loss: [1m[32m0.53384[0m[0m | time: 18.962s
[2K
| Adam | epoch: 011 | loss: 0.53384 - acc: 0.7281 -- iter: 0800/1468
[A[ATraining Step: 486  | total loss: [1m[32m0.52982[0m[0m | time: 19.790s
[2K
| Adam | epoch: 011 | loss: 0.52982 - acc: 0.7303 -- iter: 0832/1468
[A[ATraining Step: 487  | total loss: [1m[32m0.53638[0m[0m | time: 20.566s
[2K
| Adam | epoch: 011 | loss: 0.53638 - acc: 0.7198 -- iter: 0864/1468
[A[ATraining Step: 488  | total loss: [1m[32m0.52879[0m[0m | time: 21.336s
[2K
| Adam | epoch: 011 | loss: 0.52879 - acc: 0.7259 -- iter: 0896/1468
[A[ATraining Step: 489  | total loss: [1m[32m0.52663[0m[0m | time: 22.097s
[2K
| Adam | epoch: 011 | loss: 0.52663 - acc: 0.7314 -- iter: 0928/1468
[A[ATraining Step: 490  | total loss: [1m[32m0.51393[0m[0m | time: 22.804s
[2K
| Adam | epoch: 011 | loss: 0.51393 - acc: 0.7427 -- iter: 0960/1468
[A[ATraining Step: 491  | total loss: [1m[32m0.50523[0m[0m | time: 23.514s
[2K
| Adam | epoch: 011 | loss: 0.50523 - acc: 0.7528 -- iter: 0992/1468
[A[ATraining Step: 492  | total loss: [1m[32m0.52457[0m[0m | time: 24.307s
[2K
| Adam | epoch: 011 | loss: 0.52457 - acc: 0.7338 -- iter: 1024/1468
[A[ATraining Step: 493  | total loss: [1m[32m0.52061[0m[0m | time: 25.093s
[2K
| Adam | epoch: 011 | loss: 0.52061 - acc: 0.7291 -- iter: 1056/1468
[A[ATraining Step: 494  | total loss: [1m[32m0.53158[0m[0m | time: 25.832s
[2K
| Adam | epoch: 011 | loss: 0.53158 - acc: 0.7187 -- iter: 1088/1468
[A[ATraining Step: 495  | total loss: [1m[32m0.53176[0m[0m | time: 26.577s
[2K
| Adam | epoch: 011 | loss: 0.53176 - acc: 0.7187 -- iter: 1120/1468
[A[ATraining Step: 496  | total loss: [1m[32m0.52732[0m[0m | time: 27.332s
[2K
| Adam | epoch: 011 | loss: 0.52732 - acc: 0.7281 -- iter: 1152/1468
[A[ATraining Step: 497  | total loss: [1m[32m0.52359[0m[0m | time: 28.091s
[2K
| Adam | epoch: 011 | loss: 0.52359 - acc: 0.7303 -- iter: 1184/1468
[A[ATraining Step: 498  | total loss: [1m[32m0.52362[0m[0m | time: 28.862s
[2K
| Adam | epoch: 011 | loss: 0.52362 - acc: 0.7166 -- iter: 1216/1468
[A[ATraining Step: 499  | total loss: [1m[32m0.52635[0m[0m | time: 29.603s
[2K
| Adam | epoch: 011 | loss: 0.52635 - acc: 0.7200 -- iter: 1248/1468
[A[ATraining Step: 500  | total loss: [1m[32m0.52321[0m[0m | time: 30.362s
[2K
| Adam | epoch: 011 | loss: 0.52321 - acc: 0.7230 -- iter: 1280/1468
[A[ATraining Step: 501  | total loss: [1m[32m0.50739[0m[0m | time: 31.109s
[2K
| Adam | epoch: 011 | loss: 0.50739 - acc: 0.7382 -- iter: 1312/1468
[A[ATraining Step: 502  | total loss: [1m[32m0.50649[0m[0m | time: 31.851s
[2K
| Adam | epoch: 011 | loss: 0.50649 - acc: 0.7394 -- iter: 1344/1468
[A[ATraining Step: 503  | total loss: [1m[32m0.49828[0m[0m | time: 32.591s
[2K
| Adam | epoch: 011 | loss: 0.49828 - acc: 0.7529 -- iter: 1376/1468
[A[ATraining Step: 504  | total loss: [1m[32m0.48881[0m[0m | time: 33.400s
[2K
| Adam | epoch: 011 | loss: 0.48881 - acc: 0.7620 -- iter: 1408/1468
[A[ATraining Step: 505  | total loss: [1m[32m0.49405[0m[0m | time: 34.129s
[2K
| Adam | epoch: 011 | loss: 0.49405 - acc: 0.7608 -- iter: 1440/1468
[A[ATraining Step: 506  | total loss: [1m[32m0.49947[0m[0m | time: 36.589s
[2K
| Adam | epoch: 011 | loss: 0.49947 - acc: 0.7503 | val_loss: 0.56666 - val_acc: 0.7190 -- iter: 1468/1468
--
Training Step: 507  | total loss: [1m[32m0.51332[0m[0m | time: 0.633s
[2K
| Adam | epoch: 012 | loss: 0.51332 - acc: 0.7441 -- iter: 0032/1468
[A[ATraining Step: 508  | total loss: [1m[32m0.51439[0m[0m | time: 1.354s
[2K
| Adam | epoch: 012 | loss: 0.51439 - acc: 0.7478 -- iter: 0064/1468
[A[ATraining Step: 509  | total loss: [1m[32m0.51800[0m[0m | time: 2.133s
[2K
| Adam | epoch: 012 | loss: 0.51800 - acc: 0.7449 -- iter: 0096/1468
[A[ATraining Step: 510  | total loss: [1m[32m0.51220[0m[0m | time: 2.861s
[2K
| Adam | epoch: 012 | loss: 0.51220 - acc: 0.7485 -- iter: 0128/1468
[A[ATraining Step: 511  | total loss: [1m[32m0.51048[0m[0m | time: 3.596s
[2K
| Adam | epoch: 012 | loss: 0.51048 - acc: 0.7455 -- iter: 0160/1468
[A[ATraining Step: 512  | total loss: [1m[32m0.51414[0m[0m | time: 4.429s
[2K
| Adam | epoch: 012 | loss: 0.51414 - acc: 0.7366 -- iter: 0192/1468
[A[ATraining Step: 513  | total loss: [1m[32m0.52535[0m[0m | time: 5.172s
[2K
| Adam | epoch: 012 | loss: 0.52535 - acc: 0.7254 -- iter: 0224/1468
[A[ATraining Step: 514  | total loss: [1m[32m0.51686[0m[0m | time: 5.987s
[2K
| Adam | epoch: 012 | loss: 0.51686 - acc: 0.7404 -- iter: 0256/1468
[A[ATraining Step: 515  | total loss: [1m[32m0.51779[0m[0m | time: 6.817s
[2K
| Adam | epoch: 012 | loss: 0.51779 - acc: 0.7382 -- iter: 0288/1468
[A[ATraining Step: 516  | total loss: [1m[32m0.51435[0m[0m | time: 7.497s
[2K
| Adam | epoch: 012 | loss: 0.51435 - acc: 0.7394 -- iter: 0320/1468
[A[ATraining Step: 517  | total loss: [1m[32m0.51305[0m[0m | time: 8.127s
[2K
| Adam | epoch: 012 | loss: 0.51305 - acc: 0.7405 -- iter: 0352/1468
[A[ATraining Step: 518  | total loss: [1m[32m0.51043[0m[0m | time: 8.859s
[2K
| Adam | epoch: 012 | loss: 0.51043 - acc: 0.7414 -- iter: 0384/1468
[A[ATraining Step: 519  | total loss: [1m[32m0.51369[0m[0m | time: 9.599s
[2K
| Adam | epoch: 012 | loss: 0.51369 - acc: 0.7423 -- iter: 0416/1468
[A[ATraining Step: 520  | total loss: [1m[32m0.51405[0m[0m | time: 10.383s
[2K
| Adam | epoch: 012 | loss: 0.51405 - acc: 0.7431 -- iter: 0448/1468
[A[ATraining Step: 521  | total loss: [1m[32m0.50617[0m[0m | time: 11.174s
[2K
| Adam | epoch: 012 | loss: 0.50617 - acc: 0.7531 -- iter: 0480/1468
[A[ATraining Step: 522  | total loss: [1m[32m0.49578[0m[0m | time: 11.926s
[2K
| Adam | epoch: 012 | loss: 0.49578 - acc: 0.7559 -- iter: 0512/1468
[A[ATraining Step: 523  | total loss: [1m[32m0.49962[0m[0m | time: 12.675s
[2K
| Adam | epoch: 012 | loss: 0.49962 - acc: 0.7522 -- iter: 0544/1468
[A[ATraining Step: 524  | total loss: [1m[32m0.50409[0m[0m | time: 13.431s
[2K
| Adam | epoch: 012 | loss: 0.50409 - acc: 0.7582 -- iter: 0576/1468
[A[ATraining Step: 525  | total loss: [1m[32m0.49908[0m[0m | time: 14.205s
[2K
| Adam | epoch: 012 | loss: 0.49908 - acc: 0.7668 -- iter: 0608/1468
[A[ATraining Step: 526  | total loss: [1m[32m0.49169[0m[0m | time: 15.021s
[2K
| Adam | epoch: 012 | loss: 0.49169 - acc: 0.7714 -- iter: 0640/1468
[A[ATraining Step: 527  | total loss: [1m[32m0.48452[0m[0m | time: 15.787s
[2K
| Adam | epoch: 012 | loss: 0.48452 - acc: 0.7786 -- iter: 0672/1468
[A[ATraining Step: 528  | total loss: [1m[32m0.47647[0m[0m | time: 16.536s
[2K
| Adam | epoch: 012 | loss: 0.47647 - acc: 0.7820 -- iter: 0704/1468
[A[ATraining Step: 529  | total loss: [1m[32m0.48193[0m[0m | time: 17.303s
[2K
| Adam | epoch: 012 | loss: 0.48193 - acc: 0.7819 -- iter: 0736/1468
[A[ATraining Step: 530  | total loss: [1m[32m0.47552[0m[0m | time: 18.104s
[2K
| Adam | epoch: 012 | loss: 0.47552 - acc: 0.7881 -- iter: 0768/1468
[A[ATraining Step: 531  | total loss: [1m[32m0.47008[0m[0m | time: 18.874s
[2K
| Adam | epoch: 012 | loss: 0.47008 - acc: 0.7937 -- iter: 0800/1468
[A[ATraining Step: 532  | total loss: [1m[32m0.46149[0m[0m | time: 19.633s
[2K
| Adam | epoch: 012 | loss: 0.46149 - acc: 0.8018 -- iter: 0832/1468
[A[ATraining Step: 533  | total loss: [1m[32m0.45813[0m[0m | time: 20.393s
[2K
| Adam | epoch: 012 | loss: 0.45813 - acc: 0.8029 -- iter: 0864/1468
[A[ATraining Step: 534  | total loss: [1m[32m0.46912[0m[0m | time: 21.138s
[2K
| Adam | epoch: 012 | loss: 0.46912 - acc: 0.7945 -- iter: 0896/1468
[A[ATraining Step: 535  | total loss: [1m[32m0.46199[0m[0m | time: 21.925s
[2K
| Adam | epoch: 012 | loss: 0.46199 - acc: 0.7994 -- iter: 0928/1468
[A[ATraining Step: 536  | total loss: [1m[32m0.45975[0m[0m | time: 22.658s
[2K
| Adam | epoch: 012 | loss: 0.45975 - acc: 0.8101 -- iter: 0960/1468
[A[ATraining Step: 537  | total loss: [1m[32m0.44840[0m[0m | time: 23.428s
[2K
| Adam | epoch: 012 | loss: 0.44840 - acc: 0.8134 -- iter: 0992/1468
[A[ATraining Step: 538  | total loss: [1m[32m0.43896[0m[0m | time: 24.191s
[2K
| Adam | epoch: 012 | loss: 0.43896 - acc: 0.8165 -- iter: 1024/1468
[A[ATraining Step: 539  | total loss: [1m[32m0.44042[0m[0m | time: 25.022s
[2K
| Adam | epoch: 012 | loss: 0.44042 - acc: 0.8098 -- iter: 1056/1468
[A[ATraining Step: 540  | total loss: [1m[32m0.44628[0m[0m | time: 25.810s
[2K
| Adam | epoch: 012 | loss: 0.44628 - acc: 0.8070 -- iter: 1088/1468
[A[ATraining Step: 541  | total loss: [1m[32m0.43731[0m[0m | time: 26.556s
[2K
| Adam | epoch: 012 | loss: 0.43731 - acc: 0.8200 -- iter: 1120/1468
[A[ATraining Step: 542  | total loss: [1m[32m0.43190[0m[0m | time: 27.283s
[2K
| Adam | epoch: 012 | loss: 0.43190 - acc: 0.8224 -- iter: 1152/1468
[A[ATraining Step: 543  | total loss: [1m[32m0.43859[0m[0m | time: 28.065s
[2K
| Adam | epoch: 012 | loss: 0.43859 - acc: 0.8183 -- iter: 1184/1468
[A[ATraining Step: 544  | total loss: [1m[32m0.43036[0m[0m | time: 28.831s
[2K
| Adam | epoch: 012 | loss: 0.43036 - acc: 0.8271 -- iter: 1216/1468
[A[ATraining Step: 545  | total loss: [1m[32m0.42911[0m[0m | time: 29.559s
[2K
| Adam | epoch: 012 | loss: 0.42911 - acc: 0.8287 -- iter: 1248/1468
[A[ATraining Step: 546  | total loss: [1m[32m0.43095[0m[0m | time: 30.449s
[2K
| Adam | epoch: 012 | loss: 0.43095 - acc: 0.8271 -- iter: 1280/1468
[A[ATraining Step: 547  | total loss: [1m[32m0.42263[0m[0m | time: 31.456s
[2K
| Adam | epoch: 012 | loss: 0.42263 - acc: 0.8382 -- iter: 1312/1468
[A[ATraining Step: 548  | total loss: [1m[32m0.41648[0m[0m | time: 32.087s
[2K
| Adam | epoch: 012 | loss: 0.41648 - acc: 0.8356 -- iter: 1344/1468
[A[ATraining Step: 549  | total loss: [1m[32m0.42008[0m[0m | time: 32.725s
[2K
| Adam | epoch: 012 | loss: 0.42008 - acc: 0.8239 -- iter: 1376/1468
[A[ATraining Step: 550  | total loss: [1m[32m0.42718[0m[0m | time: 33.461s
[2K
| Adam | epoch: 012 | loss: 0.42718 - acc: 0.8103 -- iter: 1408/1468
[A[ATraining Step: 551  | total loss: [1m[32m0.42438[0m[0m | time: 34.240s
[2K
| Adam | epoch: 012 | loss: 0.42438 - acc: 0.8167 -- iter: 1440/1468
[A[ATraining Step: 552  | total loss: [1m[32m0.44829[0m[0m | time: 36.828s
[2K
| Adam | epoch: 012 | loss: 0.44829 - acc: 0.7976 | val_loss: 0.71794 - val_acc: 0.6057 -- iter: 1468/1468
--
Training Step: 553  | total loss: [1m[32m0.46359[0m[0m | time: 0.772s
[2K
| Adam | epoch: 013 | loss: 0.46359 - acc: 0.7866 -- iter: 0032/1468
[A[ATraining Step: 554  | total loss: [1m[32m0.48020[0m[0m | time: 1.559s
[2K
| Adam | epoch: 013 | loss: 0.48020 - acc: 0.7673 -- iter: 0064/1468
[A[ATraining Step: 555  | total loss: [1m[32m0.47911[0m[0m | time: 2.332s
[2K
| Adam | epoch: 013 | loss: 0.47911 - acc: 0.7687 -- iter: 0096/1468
[A[ATraining Step: 556  | total loss: [1m[32m0.47074[0m[0m | time: 3.058s
[2K
| Adam | epoch: 013 | loss: 0.47074 - acc: 0.7793 -- iter: 0128/1468
[A[ATraining Step: 557  | total loss: [1m[32m0.45684[0m[0m | time: 3.817s
[2K
| Adam | epoch: 013 | loss: 0.45684 - acc: 0.7858 -- iter: 0160/1468
[A[ATraining Step: 558  | total loss: [1m[32m0.45491[0m[0m | time: 4.543s
[2K
| Adam | epoch: 013 | loss: 0.45491 - acc: 0.7916 -- iter: 0192/1468
[A[ATraining Step: 559  | total loss: [1m[32m0.47157[0m[0m | time: 5.294s
[2K
| Adam | epoch: 013 | loss: 0.47157 - acc: 0.7874 -- iter: 0224/1468
[A[ATraining Step: 560  | total loss: [1m[32m0.48630[0m[0m | time: 6.051s
[2K
| Adam | epoch: 013 | loss: 0.48630 - acc: 0.7680 -- iter: 0256/1468
[A[ATraining Step: 561  | total loss: [1m[32m0.47935[0m[0m | time: 6.847s
[2K
| Adam | epoch: 013 | loss: 0.47935 - acc: 0.7694 -- iter: 0288/1468
[A[ATraining Step: 562  | total loss: [1m[32m0.47060[0m[0m | time: 7.607s
[2K
| Adam | epoch: 013 | loss: 0.47060 - acc: 0.7768 -- iter: 0320/1468
[A[ATraining Step: 563  | total loss: [1m[32m0.46813[0m[0m | time: 8.269s
[2K
| Adam | epoch: 013 | loss: 0.46813 - acc: 0.7772 -- iter: 0352/1468
[A[ATraining Step: 564  | total loss: [1m[32m0.46735[0m[0m | time: 8.986s
[2K
| Adam | epoch: 013 | loss: 0.46735 - acc: 0.7781 -- iter: 0384/1468
[A[ATraining Step: 565  | total loss: [1m[32m0.47279[0m[0m | time: 9.779s
[2K
| Adam | epoch: 013 | loss: 0.47279 - acc: 0.7574 -- iter: 0416/1468
[A[ATraining Step: 566  | total loss: [1m[32m0.48500[0m[0m | time: 10.606s
[2K
| Adam | epoch: 013 | loss: 0.48500 - acc: 0.7442 -- iter: 0448/1468
[A[ATraining Step: 567  | total loss: [1m[32m0.47926[0m[0m | time: 11.342s
[2K
| Adam | epoch: 013 | loss: 0.47926 - acc: 0.7479 -- iter: 0480/1468
[A[ATraining Step: 568  | total loss: [1m[32m0.47559[0m[0m | time: 12.096s
[2K
| Adam | epoch: 013 | loss: 0.47559 - acc: 0.7512 -- iter: 0512/1468
[A[ATraining Step: 569  | total loss: [1m[32m0.46048[0m[0m | time: 12.907s
[2K
| Adam | epoch: 013 | loss: 0.46048 - acc: 0.7636 -- iter: 0544/1468
[A[ATraining Step: 570  | total loss: [1m[32m0.47950[0m[0m | time: 13.697s
[2K
| Adam | epoch: 013 | loss: 0.47950 - acc: 0.7529 -- iter: 0576/1468
[A[ATraining Step: 571  | total loss: [1m[32m0.49671[0m[0m | time: 14.449s
[2K
| Adam | epoch: 013 | loss: 0.49671 - acc: 0.7370 -- iter: 0608/1468
[A[ATraining Step: 572  | total loss: [1m[32m0.50014[0m[0m | time: 15.219s
[2K
| Adam | epoch: 013 | loss: 0.50014 - acc: 0.7351 -- iter: 0640/1468
[A[ATraining Step: 573  | total loss: [1m[32m0.50428[0m[0m | time: 15.953s
[2K
| Adam | epoch: 013 | loss: 0.50428 - acc: 0.7335 -- iter: 0672/1468
[A[ATraining Step: 574  | total loss: [1m[32m0.49364[0m[0m | time: 16.724s
[2K
| Adam | epoch: 013 | loss: 0.49364 - acc: 0.7508 -- iter: 0704/1468
[A[ATraining Step: 575  | total loss: [1m[32m0.47390[0m[0m | time: 17.487s
[2K
| Adam | epoch: 013 | loss: 0.47390 - acc: 0.7694 -- iter: 0736/1468
[A[ATraining Step: 576  | total loss: [1m[32m0.47761[0m[0m | time: 18.255s
[2K
| Adam | epoch: 013 | loss: 0.47761 - acc: 0.7675 -- iter: 0768/1468
[A[ATraining Step: 577  | total loss: [1m[32m0.47397[0m[0m | time: 19.028s
[2K
| Adam | epoch: 013 | loss: 0.47397 - acc: 0.7657 -- iter: 0800/1468
[A[ATraining Step: 578  | total loss: [1m[32m0.47951[0m[0m | time: 19.803s
[2K
| Adam | epoch: 013 | loss: 0.47951 - acc: 0.7610 -- iter: 0832/1468
[A[ATraining Step: 579  | total loss: [1m[32m0.48686[0m[0m | time: 20.592s
[2K
| Adam | epoch: 013 | loss: 0.48686 - acc: 0.7599 -- iter: 0864/1468
[A[ATraining Step: 580  | total loss: [1m[32m0.47174[0m[0m | time: 21.367s
[2K
| Adam | epoch: 013 | loss: 0.47174 - acc: 0.7714 -- iter: 0896/1468
[A[ATraining Step: 581  | total loss: [1m[32m0.45879[0m[0m | time: 22.118s
[2K
| Adam | epoch: 013 | loss: 0.45879 - acc: 0.7849 -- iter: 0928/1468
[A[ATraining Step: 582  | total loss: [1m[32m0.46136[0m[0m | time: 22.913s
[2K
| Adam | epoch: 013 | loss: 0.46136 - acc: 0.7752 -- iter: 0960/1468
[A[ATraining Step: 583  | total loss: [1m[32m0.46540[0m[0m | time: 23.710s
[2K
| Adam | epoch: 013 | loss: 0.46540 - acc: 0.7664 -- iter: 0992/1468
[A[ATraining Step: 584  | total loss: [1m[32m0.44886[0m[0m | time: 24.645s
[2K
| Adam | epoch: 013 | loss: 0.44886 - acc: 0.7804 -- iter: 1024/1468
[A[ATraining Step: 585  | total loss: [1m[32m0.44082[0m[0m | time: 25.711s
[2K
| Adam | epoch: 013 | loss: 0.44082 - acc: 0.7805 -- iter: 1056/1468
[A[ATraining Step: 586  | total loss: [1m[32m0.43029[0m[0m | time: 26.340s
[2K
| Adam | epoch: 013 | loss: 0.43029 - acc: 0.7962 -- iter: 1088/1468
[A[ATraining Step: 587  | total loss: [1m[32m0.42357[0m[0m | time: 27.087s
[2K
| Adam | epoch: 013 | loss: 0.42357 - acc: 0.8009 -- iter: 1120/1468
[A[ATraining Step: 588  | total loss: [1m[32m0.41370[0m[0m | time: 27.854s
[2K
| Adam | epoch: 013 | loss: 0.41370 - acc: 0.8052 -- iter: 1152/1468
[A[ATraining Step: 589  | total loss: [1m[32m0.40958[0m[0m | time: 28.642s
[2K
| Adam | epoch: 013 | loss: 0.40958 - acc: 0.8091 -- iter: 1184/1468
[A[ATraining Step: 590  | total loss: [1m[32m0.39770[0m[0m | time: 29.444s
[2K
| Adam | epoch: 013 | loss: 0.39770 - acc: 0.8188 -- iter: 1216/1468
[A[ATraining Step: 591  | total loss: [1m[32m0.39542[0m[0m | time: 30.202s
[2K
| Adam | epoch: 013 | loss: 0.39542 - acc: 0.8244 -- iter: 1248/1468
[A[ATraining Step: 592  | total loss: [1m[32m0.39192[0m[0m | time: 30.998s
[2K
| Adam | epoch: 013 | loss: 0.39192 - acc: 0.8326 -- iter: 1280/1468
[A[ATraining Step: 593  | total loss: [1m[32m0.39172[0m[0m | time: 31.751s
[2K
| Adam | epoch: 013 | loss: 0.39172 - acc: 0.8368 -- iter: 1312/1468
[A[ATraining Step: 594  | total loss: [1m[32m0.38108[0m[0m | time: 32.529s
[2K
| Adam | epoch: 013 | loss: 0.38108 - acc: 0.8500 -- iter: 1344/1468
[A[ATraining Step: 595  | total loss: [1m[32m0.38317[0m[0m | time: 33.312s
[2K
| Adam | epoch: 013 | loss: 0.38317 - acc: 0.8432 -- iter: 1376/1468
[A[ATraining Step: 596  | total loss: [1m[32m0.38114[0m[0m | time: 34.082s
[2K
| Adam | epoch: 013 | loss: 0.38114 - acc: 0.8432 -- iter: 1408/1468
[A[ATraining Step: 597  | total loss: [1m[32m0.38748[0m[0m | time: 34.848s
[2K
| Adam | epoch: 013 | loss: 0.38748 - acc: 0.8433 -- iter: 1440/1468
[A[ATraining Step: 598  | total loss: [1m[32m0.39167[0m[0m | time: 37.496s
[2K
| Adam | epoch: 013 | loss: 0.39167 - acc: 0.8339 | val_loss: 0.50746 - val_acc: 0.7712 -- iter: 1468/1468
--
Training Step: 599  | total loss: [1m[32m0.39538[0m[0m | time: 0.776s
[2K
| Adam | epoch: 014 | loss: 0.39538 - acc: 0.8255 -- iter: 0032/1468
[A[ATraining Step: 600  | total loss: [1m[32m0.39621[0m[0m | time: 3.242s
[2K
| Adam | epoch: 014 | loss: 0.39621 - acc: 0.8180 | val_loss: 0.49642 - val_acc: 0.7778 -- iter: 0064/1468
--
Training Step: 601  | total loss: [1m[32m0.38621[0m[0m | time: 3.996s
[2K
| Adam | epoch: 014 | loss: 0.38621 - acc: 0.8237 -- iter: 0096/1468
[A[ATraining Step: 602  | total loss: [1m[32m0.37600[0m[0m | time: 4.790s
[2K
| Adam | epoch: 014 | loss: 0.37600 - acc: 0.8351 -- iter: 0128/1468
[A[ATraining Step: 603  | total loss: [1m[32m0.37112[0m[0m | time: 5.565s
[2K
| Adam | epoch: 014 | loss: 0.37112 - acc: 0.8422 -- iter: 0160/1468
[A[ATraining Step: 604  | total loss: [1m[32m0.36817[0m[0m | time: 6.342s
[2K
| Adam | epoch: 014 | loss: 0.36817 - acc: 0.8423 -- iter: 0192/1468
[A[ATraining Step: 605  | total loss: [1m[32m0.37190[0m[0m | time: 7.149s
[2K
| Adam | epoch: 014 | loss: 0.37190 - acc: 0.8394 -- iter: 0224/1468
[A[ATraining Step: 606  | total loss: [1m[32m0.36407[0m[0m | time: 7.971s
[2K
| Adam | epoch: 014 | loss: 0.36407 - acc: 0.8429 -- iter: 0256/1468
[A[ATraining Step: 607  | total loss: [1m[32m0.36088[0m[0m | time: 8.757s
[2K
| Adam | epoch: 014 | loss: 0.36088 - acc: 0.8430 -- iter: 0288/1468
[A[ATraining Step: 608  | total loss: [1m[32m0.35350[0m[0m | time: 9.523s
[2K
| Adam | epoch: 014 | loss: 0.35350 - acc: 0.8493 -- iter: 0320/1468
[A[ATraining Step: 609  | total loss: [1m[32m0.34980[0m[0m | time: 10.291s
[2K
| Adam | epoch: 014 | loss: 0.34980 - acc: 0.8456 -- iter: 0352/1468
[A[ATraining Step: 610  | total loss: [1m[32m0.36908[0m[0m | time: 10.966s
[2K
| Adam | epoch: 014 | loss: 0.36908 - acc: 0.8423 -- iter: 0384/1468
[A[ATraining Step: 611  | total loss: [1m[32m0.38780[0m[0m | time: 11.673s
[2K
| Adam | epoch: 014 | loss: 0.38780 - acc: 0.8331 -- iter: 0416/1468
[A[ATraining Step: 612  | total loss: [1m[32m0.39686[0m[0m | time: 12.417s
[2K
| Adam | epoch: 014 | loss: 0.39686 - acc: 0.8284 -- iter: 0448/1468
[A[ATraining Step: 613  | total loss: [1m[32m0.39889[0m[0m | time: 13.193s
[2K
| Adam | epoch: 014 | loss: 0.39889 - acc: 0.8299 -- iter: 0480/1468
[A[ATraining Step: 614  | total loss: [1m[32m0.40270[0m[0m | time: 14.032s
[2K
| Adam | epoch: 014 | loss: 0.40270 - acc: 0.8313 -- iter: 0512/1468
[A[ATraining Step: 615  | total loss: [1m[32m0.40987[0m[0m | time: 14.813s
[2K
| Adam | epoch: 014 | loss: 0.40987 - acc: 0.8232 -- iter: 0544/1468
[A[ATraining Step: 616  | total loss: [1m[32m0.40176[0m[0m | time: 15.575s
[2K
| Adam | epoch: 014 | loss: 0.40176 - acc: 0.8252 -- iter: 0576/1468
[A[ATraining Step: 617  | total loss: [1m[32m0.41006[0m[0m | time: 16.445s
[2K
| Adam | epoch: 014 | loss: 0.41006 - acc: 0.8208 -- iter: 0608/1468
[A[ATraining Step: 618  | total loss: [1m[32m0.40244[0m[0m | time: 17.588s
[2K
| Adam | epoch: 014 | loss: 0.40244 - acc: 0.8231 -- iter: 0640/1468
[A[ATraining Step: 619  | total loss: [1m[32m0.39641[0m[0m | time: 18.306s
[2K
| Adam | epoch: 014 | loss: 0.39641 - acc: 0.8283 -- iter: 0672/1468
[A[ATraining Step: 620  | total loss: [1m[32m0.38878[0m[0m | time: 19.102s
[2K
| Adam | epoch: 014 | loss: 0.38878 - acc: 0.8298 -- iter: 0704/1468
[A[ATraining Step: 621  | total loss: [1m[32m0.39627[0m[0m | time: 19.963s
[2K
| Adam | epoch: 014 | loss: 0.39627 - acc: 0.8219 -- iter: 0736/1468
[A[ATraining Step: 622  | total loss: [1m[32m0.39588[0m[0m | time: 20.698s
[2K
| Adam | epoch: 014 | loss: 0.39588 - acc: 0.8178 -- iter: 0768/1468
[A[ATraining Step: 623  | total loss: [1m[32m0.38744[0m[0m | time: 21.490s
[2K
| Adam | epoch: 014 | loss: 0.38744 - acc: 0.8173 -- iter: 0800/1468
[A[ATraining Step: 624  | total loss: [1m[32m0.39804[0m[0m | time: 22.285s
[2K
| Adam | epoch: 014 | loss: 0.39804 - acc: 0.8168 -- iter: 0832/1468
[A[ATraining Step: 625  | total loss: [1m[32m0.39237[0m[0m | time: 23.086s
[2K
| Adam | epoch: 014 | loss: 0.39237 - acc: 0.8226 -- iter: 0864/1468
[A[ATraining Step: 626  | total loss: [1m[32m0.39769[0m[0m | time: 23.841s
[2K
| Adam | epoch: 014 | loss: 0.39769 - acc: 0.8216 -- iter: 0896/1468
[A[ATraining Step: 627  | total loss: [1m[32m0.38306[0m[0m | time: 24.632s
[2K
| Adam | epoch: 014 | loss: 0.38306 - acc: 0.8332 -- iter: 0928/1468
[A[ATraining Step: 628  | total loss: [1m[32m0.37269[0m[0m | time: 25.424s
[2K
| Adam | epoch: 014 | loss: 0.37269 - acc: 0.8436 -- iter: 0960/1468
[A[ATraining Step: 629  | total loss: [1m[32m0.38147[0m[0m | time: 26.191s
[2K
| Adam | epoch: 014 | loss: 0.38147 - acc: 0.8468 -- iter: 0992/1468
[A[ATraining Step: 630  | total loss: [1m[32m0.37701[0m[0m | time: 26.957s
[2K
| Adam | epoch: 014 | loss: 0.37701 - acc: 0.8496 -- iter: 1024/1468
[A[ATraining Step: 631  | total loss: [1m[32m0.37443[0m[0m | time: 27.738s
[2K
| Adam | epoch: 014 | loss: 0.37443 - acc: 0.8490 -- iter: 1056/1468
[A[ATraining Step: 632  | total loss: [1m[32m0.36168[0m[0m | time: 28.514s
[2K
| Adam | epoch: 014 | loss: 0.36168 - acc: 0.8579 -- iter: 1088/1468
[A[ATraining Step: 633  | total loss: [1m[32m0.36457[0m[0m | time: 29.285s
[2K
| Adam | epoch: 014 | loss: 0.36457 - acc: 0.8564 -- iter: 1120/1468
[A[ATraining Step: 634  | total loss: [1m[32m0.35612[0m[0m | time: 30.049s
[2K
| Adam | epoch: 014 | loss: 0.35612 - acc: 0.8583 -- iter: 1152/1468
[A[ATraining Step: 635  | total loss: [1m[32m0.36062[0m[0m | time: 30.861s
[2K
| Adam | epoch: 014 | loss: 0.36062 - acc: 0.8568 -- iter: 1184/1468
[A[ATraining Step: 636  | total loss: [1m[32m0.35782[0m[0m | time: 31.646s
[2K
| Adam | epoch: 014 | loss: 0.35782 - acc: 0.8587 -- iter: 1216/1468
[A[ATraining Step: 637  | total loss: [1m[32m0.34232[0m[0m | time: 32.405s
[2K
| Adam | epoch: 014 | loss: 0.34232 - acc: 0.8697 -- iter: 1248/1468
[A[ATraining Step: 638  | total loss: [1m[32m0.34266[0m[0m | time: 33.198s
[2K
| Adam | epoch: 014 | loss: 0.34266 - acc: 0.8702 -- iter: 1280/1468
[A[ATraining Step: 639  | total loss: [1m[32m0.32678[0m[0m | time: 33.939s
[2K
| Adam | epoch: 014 | loss: 0.32678 - acc: 0.8801 -- iter: 1312/1468
[A[ATraining Step: 640  | total loss: [1m[32m0.32749[0m[0m | time: 34.791s
[2K
| Adam | epoch: 014 | loss: 0.32749 - acc: 0.8827 -- iter: 1344/1468
[A[ATraining Step: 641  | total loss: [1m[32m0.31941[0m[0m | time: 35.561s
[2K
| Adam | epoch: 014 | loss: 0.31941 - acc: 0.8850 -- iter: 1376/1468
[A[ATraining Step: 642  | total loss: [1m[32m0.30557[0m[0m | time: 36.298s
[2K
| Adam | epoch: 014 | loss: 0.30557 - acc: 0.8934 -- iter: 1408/1468
[A[ATraining Step: 643  | total loss: [1m[32m0.30643[0m[0m | time: 37.162s
[2K
| Adam | epoch: 014 | loss: 0.30643 - acc: 0.8884 -- iter: 1440/1468
[A[ATraining Step: 644  | total loss: [1m[32m0.29405[0m[0m | time: 39.779s
[2K
| Adam | epoch: 014 | loss: 0.29405 - acc: 0.8996 | val_loss: 0.47015 - val_acc: 0.7930 -- iter: 1468/1468
--
Training Step: 645  | total loss: [1m[32m0.29854[0m[0m | time: 0.759s
[2K
| Adam | epoch: 015 | loss: 0.29854 - acc: 0.9034 -- iter: 0032/1468
[A[ATraining Step: 646  | total loss: [1m[32m0.28551[0m[0m | time: 1.537s
[2K
| Adam | epoch: 015 | loss: 0.28551 - acc: 0.9099 -- iter: 0064/1468
[A[ATraining Step: 647  | total loss: [1m[32m0.28896[0m[0m | time: 2.289s
[2K
| Adam | epoch: 015 | loss: 0.28896 - acc: 0.9033 -- iter: 0096/1468
[A[ATraining Step: 648  | total loss: [1m[32m0.29376[0m[0m | time: 3.033s
[2K
| Adam | epoch: 015 | loss: 0.29376 - acc: 0.8911 -- iter: 0128/1468
[A[ATraining Step: 649  | total loss: [1m[32m0.30494[0m[0m | time: 3.798s
[2K
| Adam | epoch: 015 | loss: 0.30494 - acc: 0.8832 -- iter: 0160/1468
[A[ATraining Step: 650  | total loss: [1m[32m0.30138[0m[0m | time: 4.579s
[2K
| Adam | epoch: 015 | loss: 0.30138 - acc: 0.8793 -- iter: 0192/1468
[A[ATraining Step: 651  | total loss: [1m[32m0.31145[0m[0m | time: 5.352s
[2K
| Adam | epoch: 015 | loss: 0.31145 - acc: 0.8757 -- iter: 0224/1468
[A[ATraining Step: 652  | total loss: [1m[32m0.31586[0m[0m | time: 6.141s
[2K
| Adam | epoch: 015 | loss: 0.31586 - acc: 0.8725 -- iter: 0256/1468
[A[ATraining Step: 653  | total loss: [1m[32m0.32252[0m[0m | time: 7.001s
[2K
| Adam | epoch: 015 | loss: 0.32252 - acc: 0.8665 -- iter: 0288/1468
[A[ATraining Step: 654  | total loss: [1m[32m0.32434[0m[0m | time: 8.090s
[2K
| Adam | epoch: 015 | loss: 0.32434 - acc: 0.8674 -- iter: 0320/1468
[A[ATraining Step: 655  | total loss: [1m[32m0.31321[0m[0m | time: 8.704s
[2K
| Adam | epoch: 015 | loss: 0.31321 - acc: 0.8775 -- iter: 0352/1468
[A[ATraining Step: 656  | total loss: [1m[32m0.31182[0m[0m | time: 9.327s
[2K
| Adam | epoch: 015 | loss: 0.31182 - acc: 0.8773 -- iter: 0384/1468
[A[ATraining Step: 657  | total loss: [1m[32m0.31994[0m[0m | time: 10.012s
[2K
| Adam | epoch: 015 | loss: 0.31994 - acc: 0.8708 -- iter: 0416/1468
[A[ATraining Step: 658  | total loss: [1m[32m0.34832[0m[0m | time: 10.670s
[2K
| Adam | epoch: 015 | loss: 0.34832 - acc: 0.8480 -- iter: 0448/1468
[A[ATraining Step: 659  | total loss: [1m[32m0.36677[0m[0m | time: 11.406s
[2K
| Adam | epoch: 015 | loss: 0.36677 - acc: 0.8418 -- iter: 0480/1468
[A[ATraining Step: 660  | total loss: [1m[32m0.36369[0m[0m | time: 12.158s
[2K
| Adam | epoch: 015 | loss: 0.36369 - acc: 0.8482 -- iter: 0512/1468
[A[ATraining Step: 661  | total loss: [1m[32m0.36515[0m[0m | time: 12.951s
[2K
| Adam | epoch: 015 | loss: 0.36515 - acc: 0.8509 -- iter: 0544/1468
[A[ATraining Step: 662  | total loss: [1m[32m0.36289[0m[0m | time: 13.701s
[2K
| Adam | epoch: 015 | loss: 0.36289 - acc: 0.8564 -- iter: 0576/1468
[A[ATraining Step: 663  | total loss: [1m[32m0.34919[0m[0m | time: 14.462s
[2K
| Adam | epoch: 015 | loss: 0.34919 - acc: 0.8645 -- iter: 0608/1468
[A[ATraining Step: 664  | total loss: [1m[32m0.33567[0m[0m | time: 15.210s
[2K
| Adam | epoch: 015 | loss: 0.33567 - acc: 0.8750 -- iter: 0640/1468
[A[ATraining Step: 665  | total loss: [1m[32m0.32465[0m[0m | time: 16.006s
[2K
| Adam | epoch: 015 | loss: 0.32465 - acc: 0.8843 -- iter: 0672/1468
[A[ATraining Step: 666  | total loss: [1m[32m0.33249[0m[0m | time: 16.807s
[2K
| Adam | epoch: 015 | loss: 0.33249 - acc: 0.8740 -- iter: 0704/1468
[A[ATraining Step: 667  | total loss: [1m[32m0.31969[0m[0m | time: 17.583s
[2K
| Adam | epoch: 015 | loss: 0.31969 - acc: 0.8773 -- iter: 0736/1468
[A[ATraining Step: 668  | total loss: [1m[32m0.31774[0m[0m | time: 18.337s
[2K
| Adam | epoch: 015 | loss: 0.31774 - acc: 0.8739 -- iter: 0768/1468
[A[ATraining Step: 669  | total loss: [1m[32m0.33596[0m[0m | time: 19.189s
[2K
| Adam | epoch: 015 | loss: 0.33596 - acc: 0.8678 -- iter: 0800/1468
[A[ATraining Step: 670  | total loss: [1m[32m0.32914[0m[0m | time: 20.324s
[2K
| Adam | epoch: 015 | loss: 0.32914 - acc: 0.8685 -- iter: 0832/1468
[A[ATraining Step: 671  | total loss: [1m[32m0.32410[0m[0m | time: 20.938s
[2K
| Adam | epoch: 015 | loss: 0.32410 - acc: 0.8723 -- iter: 0864/1468
[A[ATraining Step: 672  | total loss: [1m[32m0.34871[0m[0m | time: 21.662s
[2K
| Adam | epoch: 015 | loss: 0.34871 - acc: 0.8538 -- iter: 0896/1468
[A[ATraining Step: 673  | total loss: [1m[32m0.35183[0m[0m | time: 22.428s
[2K
| Adam | epoch: 015 | loss: 0.35183 - acc: 0.8497 -- iter: 0928/1468
[A[ATraining Step: 674  | total loss: [1m[32m0.34782[0m[0m | time: 23.173s
[2K
| Adam | epoch: 015 | loss: 0.34782 - acc: 0.8491 -- iter: 0960/1468
[A[ATraining Step: 675  | total loss: [1m[32m0.33164[0m[0m | time: 23.932s
[2K
| Adam | epoch: 015 | loss: 0.33164 - acc: 0.8610 -- iter: 0992/1468
[A[ATraining Step: 676  | total loss: [1m[32m0.32916[0m[0m | time: 24.698s
[2K
| Adam | epoch: 015 | loss: 0.32916 - acc: 0.8624 -- iter: 1024/1468
[A[ATraining Step: 677  | total loss: [1m[32m0.31814[0m[0m | time: 25.434s
[2K
| Adam | epoch: 015 | loss: 0.31814 - acc: 0.8668 -- iter: 1056/1468
[A[ATraining Step: 678  | total loss: [1m[32m0.30791[0m[0m | time: 26.165s
[2K
| Adam | epoch: 015 | loss: 0.30791 - acc: 0.8708 -- iter: 1088/1468
[A[ATraining Step: 679  | total loss: [1m[32m0.29813[0m[0m | time: 26.962s
[2K
| Adam | epoch: 015 | loss: 0.29813 - acc: 0.8743 -- iter: 1120/1468
[A[ATraining Step: 680  | total loss: [1m[32m0.29490[0m[0m | time: 27.701s
[2K
| Adam | epoch: 015 | loss: 0.29490 - acc: 0.8744 -- iter: 1152/1468
[A[ATraining Step: 681  | total loss: [1m[32m0.28175[0m[0m | time: 28.530s
[2K
| Adam | epoch: 015 | loss: 0.28175 - acc: 0.8838 -- iter: 1184/1468
[A[ATraining Step: 682  | total loss: [1m[32m0.27539[0m[0m | time: 29.284s
[2K
| Adam | epoch: 015 | loss: 0.27539 - acc: 0.8954 -- iter: 1216/1468
[A[ATraining Step: 683  | total loss: [1m[32m0.27744[0m[0m | time: 30.036s
[2K
| Adam | epoch: 015 | loss: 0.27744 - acc: 0.8871 -- iter: 1248/1468
[A[ATraining Step: 684  | total loss: [1m[32m0.27850[0m[0m | time: 30.781s
[2K
| Adam | epoch: 015 | loss: 0.27850 - acc: 0.8859 -- iter: 1280/1468
[A[ATraining Step: 685  | total loss: [1m[32m0.27344[0m[0m | time: 31.596s
[2K
| Adam | epoch: 015 | loss: 0.27344 - acc: 0.8911 -- iter: 1312/1468
[A[ATraining Step: 686  | total loss: [1m[32m0.27741[0m[0m | time: 32.420s
[2K
| Adam | epoch: 015 | loss: 0.27741 - acc: 0.8832 -- iter: 1344/1468
[A[ATraining Step: 687  | total loss: [1m[32m0.27309[0m[0m | time: 33.243s
[2K
| Adam | epoch: 015 | loss: 0.27309 - acc: 0.8918 -- iter: 1376/1468
[A[ATraining Step: 688  | total loss: [1m[32m0.27873[0m[0m | time: 34.004s
[2K
| Adam | epoch: 015 | loss: 0.27873 - acc: 0.8870 -- iter: 1408/1468
[A[ATraining Step: 689  | total loss: [1m[32m0.28281[0m[0m | time: 34.741s
[2K
| Adam | epoch: 015 | loss: 0.28281 - acc: 0.8858 -- iter: 1440/1468
[A[ATraining Step: 690  | total loss: [1m[32m0.27660[0m[0m | time: 37.250s
[2K
| Adam | epoch: 015 | loss: 0.27660 - acc: 0.8878 | val_loss: 0.55281 - val_acc: 0.7538 -- iter: 1468/1468
--
Training Step: 691  | total loss: [1m[32m0.26984[0m[0m | time: 0.812s
[2K
| Adam | epoch: 016 | loss: 0.26984 - acc: 0.8928 -- iter: 0032/1468
[A[ATraining Step: 692  | total loss: [1m[32m0.26974[0m[0m | time: 1.560s
[2K
| Adam | epoch: 016 | loss: 0.26974 - acc: 0.8941 -- iter: 0064/1468
[A[ATraining Step: 693  | total loss: [1m[32m0.27053[0m[0m | time: 2.321s
[2K
| Adam | epoch: 016 | loss: 0.27053 - acc: 0.8922 -- iter: 0096/1468
[A[ATraining Step: 694  | total loss: [1m[32m0.27916[0m[0m | time: 3.406s
[2K
| Adam | epoch: 016 | loss: 0.27916 - acc: 0.8905 -- iter: 0128/1468
[A[ATraining Step: 695  | total loss: [1m[32m0.27587[0m[0m | time: 4.166s
[2K
| Adam | epoch: 016 | loss: 0.27587 - acc: 0.8952 -- iter: 0160/1468
[A[ATraining Step: 696  | total loss: [1m[32m0.27408[0m[0m | time: 4.971s
[2K
| Adam | epoch: 016 | loss: 0.27408 - acc: 0.8994 -- iter: 0192/1468
[A[ATraining Step: 697  | total loss: [1m[32m0.27491[0m[0m | time: 5.756s
[2K
| Adam | epoch: 016 | loss: 0.27491 - acc: 0.8970 -- iter: 0224/1468
[A[ATraining Step: 698  | total loss: [1m[32m0.26872[0m[0m | time: 6.567s
[2K
| Adam | epoch: 016 | loss: 0.26872 - acc: 0.9010 -- iter: 0256/1468
[A[ATraining Step: 699  | total loss: [1m[32m0.26601[0m[0m | time: 7.445s
[2K
| Adam | epoch: 016 | loss: 0.26601 - acc: 0.9047 -- iter: 0288/1468
[A[ATraining Step: 700  | total loss: [1m[32m0.26052[0m[0m | time: 8.265s
[2K
| Adam | epoch: 016 | loss: 0.26052 - acc: 0.9111 -- iter: 0320/1468
[A[ATraining Step: 701  | total loss: [1m[32m0.25913[0m[0m | time: 9.064s
[2K
| Adam | epoch: 016 | loss: 0.25913 - acc: 0.9106 -- iter: 0352/1468
[A[ATraining Step: 702  | total loss: [1m[32m0.26173[0m[0m | time: 9.825s
[2K
| Adam | epoch: 016 | loss: 0.26173 - acc: 0.9102 -- iter: 0384/1468
[A[ATraining Step: 703  | total loss: [1m[32m0.25566[0m[0m | time: 10.635s
[2K
| Adam | epoch: 016 | loss: 0.25566 - acc: 0.9098 -- iter: 0416/1468
[A[ATraining Step: 704  | total loss: [1m[32m0.24894[0m[0m | time: 11.354s
[2K
| Adam | epoch: 016 | loss: 0.24894 - acc: 0.9126 -- iter: 0448/1468
[A[ATraining Step: 705  | total loss: [1m[32m0.25784[0m[0m | time: 12.044s
[2K
| Adam | epoch: 016 | loss: 0.25784 - acc: 0.9070 -- iter: 0480/1468
[A[ATraining Step: 706  | total loss: [1m[32m0.26094[0m[0m | time: 12.826s
[2K
| Adam | epoch: 016 | loss: 0.26094 - acc: 0.9020 -- iter: 0512/1468
[A[ATraining Step: 707  | total loss: [1m[32m0.25791[0m[0m | time: 13.570s
[2K
| Adam | epoch: 016 | loss: 0.25791 - acc: 0.8993 -- iter: 0544/1468
[A[ATraining Step: 708  | total loss: [1m[32m0.26629[0m[0m | time: 14.367s
[2K
| Adam | epoch: 016 | loss: 0.26629 - acc: 0.8906 -- iter: 0576/1468
[A[ATraining Step: 709  | total loss: [1m[32m0.27595[0m[0m | time: 15.148s
[2K
| Adam | epoch: 016 | loss: 0.27595 - acc: 0.8828 -- iter: 0608/1468
[A[ATraining Step: 710  | total loss: [1m[32m0.27883[0m[0m | time: 15.901s
[2K
| Adam | epoch: 016 | loss: 0.27883 - acc: 0.8820 -- iter: 0640/1468
[A[ATraining Step: 711  | total loss: [1m[32m0.28254[0m[0m | time: 16.674s
[2K
| Adam | epoch: 016 | loss: 0.28254 - acc: 0.8845 -- iter: 0672/1468
[A[ATraining Step: 712  | total loss: [1m[32m0.29043[0m[0m | time: 17.411s
[2K
| Adam | epoch: 016 | loss: 0.29043 - acc: 0.8866 -- iter: 0704/1468
[A[ATraining Step: 713  | total loss: [1m[32m0.31824[0m[0m | time: 18.212s
[2K
| Adam | epoch: 016 | loss: 0.31824 - acc: 0.8730 -- iter: 0736/1468
[A[ATraining Step: 714  | total loss: [1m[32m0.33101[0m[0m | time: 18.963s
[2K
| Adam | epoch: 016 | loss: 0.33101 - acc: 0.8638 -- iter: 0768/1468
[A[ATraining Step: 715  | total loss: [1m[32m0.34825[0m[0m | time: 19.719s
[2K
| Adam | epoch: 016 | loss: 0.34825 - acc: 0.8493 -- iter: 0800/1468
[A[ATraining Step: 716  | total loss: [1m[32m0.36098[0m[0m | time: 20.467s
[2K
| Adam | epoch: 016 | loss: 0.36098 - acc: 0.8394 -- iter: 0832/1468
[A[ATraining Step: 717  | total loss: [1m[32m0.36701[0m[0m | time: 21.199s
[2K
| Adam | epoch: 016 | loss: 0.36701 - acc: 0.8398 -- iter: 0864/1468
[A[ATraining Step: 718  | total loss: [1m[32m0.35131[0m[0m | time: 21.945s
[2K
| Adam | epoch: 016 | loss: 0.35131 - acc: 0.8465 -- iter: 0896/1468
[A[ATraining Step: 719  | total loss: [1m[32m0.34435[0m[0m | time: 22.701s
[2K
| Adam | epoch: 016 | loss: 0.34435 - acc: 0.8556 -- iter: 0928/1468
[A[ATraining Step: 720  | total loss: [1m[32m0.34234[0m[0m | time: 23.471s
[2K
| Adam | epoch: 016 | loss: 0.34234 - acc: 0.8544 -- iter: 0960/1468
[A[ATraining Step: 721  | total loss: [1m[32m0.32686[0m[0m | time: 24.186s
[2K
| Adam | epoch: 016 | loss: 0.32686 - acc: 0.8596 -- iter: 0992/1468
[A[ATraining Step: 722  | total loss: [1m[32m0.31578[0m[0m | time: 24.915s
[2K
| Adam | epoch: 016 | loss: 0.31578 - acc: 0.8611 -- iter: 1024/1468
[A[ATraining Step: 723  | total loss: [1m[32m0.31413[0m[0m | time: 25.700s
[2K
| Adam | epoch: 016 | loss: 0.31413 - acc: 0.8625 -- iter: 1056/1468
[A[ATraining Step: 724  | total loss: [1m[32m0.30488[0m[0m | time: 26.488s
[2K
| Adam | epoch: 016 | loss: 0.30488 - acc: 0.8669 -- iter: 1088/1468
[A[ATraining Step: 725  | total loss: [1m[32m0.29929[0m[0m | time: 27.323s
[2K
| Adam | epoch: 016 | loss: 0.29929 - acc: 0.8677 -- iter: 1120/1468
[A[ATraining Step: 726  | total loss: [1m[32m0.32808[0m[0m | time: 28.142s
[2K
| Adam | epoch: 016 | loss: 0.32808 - acc: 0.8497 -- iter: 1152/1468
[A[ATraining Step: 727  | total loss: [1m[32m0.34774[0m[0m | time: 28.987s
[2K
| Adam | epoch: 016 | loss: 0.34774 - acc: 0.8366 -- iter: 1184/1468
[A[ATraining Step: 728  | total loss: [1m[32m0.35994[0m[0m | time: 29.753s
[2K
| Adam | epoch: 016 | loss: 0.35994 - acc: 0.8342 -- iter: 1216/1468
[A[ATraining Step: 729  | total loss: [1m[32m0.36901[0m[0m | time: 30.536s
[2K
| Adam | epoch: 016 | loss: 0.36901 - acc: 0.8351 -- iter: 1248/1468
[A[ATraining Step: 730  | total loss: [1m[32m0.37117[0m[0m | time: 31.324s
[2K
| Adam | epoch: 016 | loss: 0.37117 - acc: 0.8360 -- iter: 1280/1468
[A[ATraining Step: 731  | total loss: [1m[32m0.36728[0m[0m | time: 32.142s
[2K
| Adam | epoch: 016 | loss: 0.36728 - acc: 0.8336 -- iter: 1312/1468
[A[ATraining Step: 732  | total loss: [1m[32m0.35975[0m[0m | time: 32.926s
[2K
| Adam | epoch: 016 | loss: 0.35975 - acc: 0.8409 -- iter: 1344/1468
[A[ATraining Step: 733  | total loss: [1m[32m0.33907[0m[0m | time: 33.699s
[2K
| Adam | epoch: 016 | loss: 0.33907 - acc: 0.8537 -- iter: 1376/1468
[A[ATraining Step: 734  | total loss: [1m[32m0.33539[0m[0m | time: 34.645s
[2K
| Adam | epoch: 016 | loss: 0.33539 - acc: 0.8496 -- iter: 1408/1468
[A[ATraining Step: 735  | total loss: [1m[32m0.32871[0m[0m | time: 35.607s
[2K
| Adam | epoch: 016 | loss: 0.32871 - acc: 0.8552 -- iter: 1440/1468
[A[ATraining Step: 736  | total loss: [1m[32m0.32282[0m[0m | time: 38.073s
[2K
| Adam | epoch: 016 | loss: 0.32282 - acc: 0.8541 | val_loss: 0.46632 - val_acc: 0.8061 -- iter: 1468/1468
--
Training Step: 737  | total loss: [1m[32m0.30808[0m[0m | time: 0.781s
[2K
| Adam | epoch: 017 | loss: 0.30808 - acc: 0.8656 -- iter: 0032/1468
[A[ATraining Step: 738  | total loss: [1m[32m0.29122[0m[0m | time: 1.511s
[2K
| Adam | epoch: 017 | loss: 0.29122 - acc: 0.8759 -- iter: 0064/1468
[A[ATraining Step: 739  | total loss: [1m[32m0.27155[0m[0m | time: 2.279s
[2K
| Adam | epoch: 017 | loss: 0.27155 - acc: 0.8883 -- iter: 0096/1468
[A[ATraining Step: 740  | total loss: [1m[32m0.27425[0m[0m | time: 3.015s
[2K
| Adam | epoch: 017 | loss: 0.27425 - acc: 0.8807 -- iter: 0128/1468
[A[ATraining Step: 741  | total loss: [1m[32m0.28342[0m[0m | time: 3.756s
[2K
| Adam | epoch: 017 | loss: 0.28342 - acc: 0.8739 -- iter: 0160/1468
[A[ATraining Step: 742  | total loss: [1m[32m0.27665[0m[0m | time: 4.552s
[2K
| Adam | epoch: 017 | loss: 0.27665 - acc: 0.8834 -- iter: 0192/1468
[A[ATraining Step: 743  | total loss: [1m[32m0.26425[0m[0m | time: 5.348s
[2K
| Adam | epoch: 017 | loss: 0.26425 - acc: 0.8919 -- iter: 0224/1468
[A[ATraining Step: 744  | total loss: [1m[32m0.26868[0m[0m | time: 6.128s
[2K
| Adam | epoch: 017 | loss: 0.26868 - acc: 0.8840 -- iter: 0256/1468
[A[ATraining Step: 745  | total loss: [1m[32m0.26628[0m[0m | time: 6.877s
[2K
| Adam | epoch: 017 | loss: 0.26628 - acc: 0.8862 -- iter: 0288/1468
[A[ATraining Step: 746  | total loss: [1m[32m0.26244[0m[0m | time: 7.661s
[2K
| Adam | epoch: 017 | loss: 0.26244 - acc: 0.8882 -- iter: 0320/1468
[A[ATraining Step: 747  | total loss: [1m[32m0.26093[0m[0m | time: 8.470s
[2K
| Adam | epoch: 017 | loss: 0.26093 - acc: 0.8931 -- iter: 0352/1468
[A[ATraining Step: 748  | total loss: [1m[32m0.25872[0m[0m | time: 9.186s
[2K
| Adam | epoch: 017 | loss: 0.25872 - acc: 0.8976 -- iter: 0384/1468
[A[ATraining Step: 749  | total loss: [1m[32m0.25915[0m[0m | time: 9.946s
[2K
| Adam | epoch: 017 | loss: 0.25915 - acc: 0.9016 -- iter: 0416/1468
[A[ATraining Step: 750  | total loss: [1m[32m0.24346[0m[0m | time: 10.715s
[2K
| Adam | epoch: 017 | loss: 0.24346 - acc: 0.9114 -- iter: 0448/1468
[A[ATraining Step: 751  | total loss: [1m[32m0.25435[0m[0m | time: 11.419s
[2K
| Adam | epoch: 017 | loss: 0.25435 - acc: 0.9078 -- iter: 0480/1468
[A[ATraining Step: 752  | total loss: [1m[32m0.24638[0m[0m | time: 12.104s
[2K
| Adam | epoch: 017 | loss: 0.24638 - acc: 0.9134 -- iter: 0512/1468
[A[ATraining Step: 753  | total loss: [1m[32m0.23757[0m[0m | time: 12.861s
[2K
| Adam | epoch: 017 | loss: 0.23757 - acc: 0.9185 -- iter: 0544/1468
[A[ATraining Step: 754  | total loss: [1m[32m0.23807[0m[0m | time: 13.595s
[2K
| Adam | epoch: 017 | loss: 0.23807 - acc: 0.9142 -- iter: 0576/1468
[A[ATraining Step: 755  | total loss: [1m[32m0.24096[0m[0m | time: 14.433s
[2K
| Adam | epoch: 017 | loss: 0.24096 - acc: 0.9196 -- iter: 0608/1468
[A[ATraining Step: 756  | total loss: [1m[32m0.23150[0m[0m | time: 15.192s
[2K
| Adam | epoch: 017 | loss: 0.23150 - acc: 0.9245 -- iter: 0640/1468
[A[ATraining Step: 757  | total loss: [1m[32m0.21956[0m[0m | time: 15.953s
[2K
| Adam | epoch: 017 | loss: 0.21956 - acc: 0.9321 -- iter: 0672/1468
[A[ATraining Step: 758  | total loss: [1m[32m0.21304[0m[0m | time: 16.701s
[2K
| Adam | epoch: 017 | loss: 0.21304 - acc: 0.9326 -- iter: 0704/1468
[A[ATraining Step: 759  | total loss: [1m[32m0.21927[0m[0m | time: 17.505s
[2K
| Adam | epoch: 017 | loss: 0.21927 - acc: 0.9300 -- iter: 0736/1468
[A[ATraining Step: 760  | total loss: [1m[32m0.22481[0m[0m | time: 18.267s
[2K
| Adam | epoch: 017 | loss: 0.22481 - acc: 0.9245 -- iter: 0768/1468
[A[ATraining Step: 761  | total loss: [1m[32m0.21903[0m[0m | time: 19.002s
[2K
| Adam | epoch: 017 | loss: 0.21903 - acc: 0.9289 -- iter: 0800/1468
[A[ATraining Step: 762  | total loss: [1m[32m0.21860[0m[0m | time: 19.742s
[2K
| Adam | epoch: 017 | loss: 0.21860 - acc: 0.9235 -- iter: 0832/1468
[A[ATraining Step: 763  | total loss: [1m[32m0.21072[0m[0m | time: 20.530s
[2K
| Adam | epoch: 017 | loss: 0.21072 - acc: 0.9280 -- iter: 0864/1468
[A[ATraining Step: 764  | total loss: [1m[32m0.20635[0m[0m | time: 21.308s
[2K
| Adam | epoch: 017 | loss: 0.20635 - acc: 0.9321 -- iter: 0896/1468
[A[ATraining Step: 765  | total loss: [1m[32m0.22059[0m[0m | time: 22.096s
[2K
| Adam | epoch: 017 | loss: 0.22059 - acc: 0.9327 -- iter: 0928/1468
[A[ATraining Step: 766  | total loss: [1m[32m0.22896[0m[0m | time: 22.874s
[2K
| Adam | epoch: 017 | loss: 0.22896 - acc: 0.9144 -- iter: 0960/1468
[A[ATraining Step: 767  | total loss: [1m[32m0.23073[0m[0m | time: 23.632s
[2K
| Adam | epoch: 017 | loss: 0.23073 - acc: 0.9136 -- iter: 0992/1468
[A[ATraining Step: 768  | total loss: [1m[32m0.22097[0m[0m | time: 24.361s
[2K
| Adam | epoch: 017 | loss: 0.22097 - acc: 0.9160 -- iter: 1024/1468
[A[ATraining Step: 769  | total loss: [1m[32m0.21412[0m[0m | time: 25.145s
[2K
| Adam | epoch: 017 | loss: 0.21412 - acc: 0.9150 -- iter: 1056/1468
[A[ATraining Step: 770  | total loss: [1m[32m0.22777[0m[0m | time: 25.909s
[2K
| Adam | epoch: 017 | loss: 0.22777 - acc: 0.9079 -- iter: 1088/1468
[A[ATraining Step: 771  | total loss: [1m[32m0.23222[0m[0m | time: 26.646s
[2K
| Adam | epoch: 017 | loss: 0.23222 - acc: 0.9046 -- iter: 1120/1468
[A[ATraining Step: 772  | total loss: [1m[32m0.24193[0m[0m | time: 27.492s
[2K
| Adam | epoch: 017 | loss: 0.24193 - acc: 0.8985 -- iter: 1152/1468
[A[ATraining Step: 773  | total loss: [1m[32m0.22946[0m[0m | time: 28.624s
[2K
| Adam | epoch: 017 | loss: 0.22946 - acc: 0.9086 -- iter: 1184/1468
[A[ATraining Step: 774  | total loss: [1m[32m0.21823[0m[0m | time: 29.260s
[2K
| Adam | epoch: 017 | loss: 0.21823 - acc: 0.9147 -- iter: 1216/1468
[A[ATraining Step: 775  | total loss: [1m[32m0.20999[0m[0m | time: 29.938s
[2K
| Adam | epoch: 017 | loss: 0.20999 - acc: 0.9201 -- iter: 1248/1468
[A[ATraining Step: 776  | total loss: [1m[32m0.21065[0m[0m | time: 30.731s
[2K
| Adam | epoch: 017 | loss: 0.21065 - acc: 0.9187 -- iter: 1280/1468
[A[ATraining Step: 777  | total loss: [1m[32m0.20861[0m[0m | time: 31.547s
[2K
| Adam | epoch: 017 | loss: 0.20861 - acc: 0.9174 -- iter: 1312/1468
[A[ATraining Step: 778  | total loss: [1m[32m0.20269[0m[0m | time: 32.320s
[2K
| Adam | epoch: 017 | loss: 0.20269 - acc: 0.9257 -- iter: 1344/1468
[A[ATraining Step: 779  | total loss: [1m[32m0.20501[0m[0m | time: 33.147s
[2K
| Adam | epoch: 017 | loss: 0.20501 - acc: 0.9238 -- iter: 1376/1468
[A[ATraining Step: 780  | total loss: [1m[32m0.19833[0m[0m | time: 33.966s
[2K
| Adam | epoch: 017 | loss: 0.19833 - acc: 0.9283 -- iter: 1408/1468
[A[ATraining Step: 781  | total loss: [1m[32m0.20959[0m[0m | time: 34.751s
[2K
| Adam | epoch: 017 | loss: 0.20959 - acc: 0.9261 -- iter: 1440/1468
[A[ATraining Step: 782  | total loss: [1m[32m0.21514[0m[0m | time: 37.442s
[2K
| Adam | epoch: 017 | loss: 0.21514 - acc: 0.9272 | val_loss: 0.49480 - val_acc: 0.7908 -- iter: 1468/1468
--
Training Step: 783  | total loss: [1m[32m0.20576[0m[0m | time: 0.804s
[2K
| Adam | epoch: 018 | loss: 0.20576 - acc: 0.9314 -- iter: 0032/1468
[A[ATraining Step: 784  | total loss: [1m[32m0.20304[0m[0m | time: 1.542s
[2K
| Adam | epoch: 018 | loss: 0.20304 - acc: 0.9320 -- iter: 0064/1468
[A[ATraining Step: 785  | total loss: [1m[32m0.20960[0m[0m | time: 2.311s
[2K
| Adam | epoch: 018 | loss: 0.20960 - acc: 0.9263 -- iter: 0096/1468
[A[ATraining Step: 786  | total loss: [1m[32m0.22050[0m[0m | time: 3.075s
[2K
| Adam | epoch: 018 | loss: 0.22050 - acc: 0.9211 -- iter: 0128/1468
[A[ATraining Step: 787  | total loss: [1m[32m0.21311[0m[0m | time: 3.834s
[2K
| Adam | epoch: 018 | loss: 0.21311 - acc: 0.9259 -- iter: 0160/1468
[A[ATraining Step: 788  | total loss: [1m[32m0.20814[0m[0m | time: 4.579s
[2K
| Adam | epoch: 018 | loss: 0.20814 - acc: 0.9271 -- iter: 0192/1468
[A[ATraining Step: 789  | total loss: [1m[32m0.20211[0m[0m | time: 5.309s
[2K
| Adam | epoch: 018 | loss: 0.20211 - acc: 0.9312 -- iter: 0224/1468
[A[ATraining Step: 790  | total loss: [1m[32m0.19462[0m[0m | time: 6.070s
[2K
| Adam | epoch: 018 | loss: 0.19462 - acc: 0.9319 -- iter: 0256/1468
[A[ATraining Step: 791  | total loss: [1m[32m0.19066[0m[0m | time: 6.844s
[2K
| Adam | epoch: 018 | loss: 0.19066 - acc: 0.9387 -- iter: 0288/1468
[A[ATraining Step: 792  | total loss: [1m[32m0.19002[0m[0m | time: 7.590s
[2K
| Adam | epoch: 018 | loss: 0.19002 - acc: 0.9417 -- iter: 0320/1468
[A[ATraining Step: 793  | total loss: [1m[32m0.18317[0m[0m | time: 8.342s
[2K
| Adam | epoch: 018 | loss: 0.18317 - acc: 0.9475 -- iter: 0352/1468
[A[ATraining Step: 794  | total loss: [1m[32m0.17791[0m[0m | time: 9.106s
[2K
| Adam | epoch: 018 | loss: 0.17791 - acc: 0.9496 -- iter: 0384/1468
[A[ATraining Step: 795  | total loss: [1m[32m0.18341[0m[0m | time: 9.888s
[2K
| Adam | epoch: 018 | loss: 0.18341 - acc: 0.9515 -- iter: 0416/1468
[A[ATraining Step: 796  | total loss: [1m[32m0.17426[0m[0m | time: 10.611s
[2K
| Adam | epoch: 018 | loss: 0.17426 - acc: 0.9564 -- iter: 0448/1468
[A[ATraining Step: 797  | total loss: [1m[32m0.17529[0m[0m | time: 11.379s
[2K
| Adam | epoch: 018 | loss: 0.17529 - acc: 0.9514 -- iter: 0480/1468
[A[ATraining Step: 798  | total loss: [1m[32m0.17680[0m[0m | time: 12.116s
[2K
| Adam | epoch: 018 | loss: 0.17680 - acc: 0.9500 -- iter: 0512/1468
[A[ATraining Step: 799  | total loss: [1m[32m0.16836[0m[0m | time: 12.828s
[2K
| Adam | epoch: 018 | loss: 0.16836 - acc: 0.9550 -- iter: 0544/1468
[A[ATraining Step: 800  | total loss: [1m[32m0.15993[0m[0m | time: 15.447s
[2K
| Adam | epoch: 018 | loss: 0.15993 - acc: 0.9595 | val_loss: 0.46818 - val_acc: 0.7952 -- iter: 0576/1468
--
Training Step: 801  | total loss: [1m[32m0.15130[0m[0m | time: 16.221s
[2K
| Adam | epoch: 018 | loss: 0.15130 - acc: 0.9635 -- iter: 0608/1468
[A[ATraining Step: 802  | total loss: [1m[32m0.14749[0m[0m | time: 16.997s
[2K
| Adam | epoch: 018 | loss: 0.14749 - acc: 0.9641 -- iter: 0640/1468
[A[ATraining Step: 803  | total loss: [1m[32m0.14548[0m[0m | time: 17.756s
[2K
| Adam | epoch: 018 | loss: 0.14548 - acc: 0.9645 -- iter: 0672/1468
[A[ATraining Step: 804  | total loss: [1m[32m0.15394[0m[0m | time: 18.577s
[2K
| Adam | epoch: 018 | loss: 0.15394 - acc: 0.9618 -- iter: 0704/1468
[A[ATraining Step: 805  | total loss: [1m[32m0.15152[0m[0m | time: 19.316s
[2K
| Adam | epoch: 018 | loss: 0.15152 - acc: 0.9625 -- iter: 0736/1468
[A[ATraining Step: 806  | total loss: [1m[32m0.15489[0m[0m | time: 20.089s
[2K
| Adam | epoch: 018 | loss: 0.15489 - acc: 0.9600 -- iter: 0768/1468
[A[ATraining Step: 807  | total loss: [1m[32m0.16095[0m[0m | time: 20.835s
[2K
| Adam | epoch: 018 | loss: 0.16095 - acc: 0.9546 -- iter: 0800/1468
[A[ATraining Step: 808  | total loss: [1m[32m0.16256[0m[0m | time: 21.691s
[2K
| Adam | epoch: 018 | loss: 0.16256 - acc: 0.9529 -- iter: 0832/1468
[A[ATraining Step: 809  | total loss: [1m[32m0.17315[0m[0m | time: 22.838s
[2K
| Adam | epoch: 018 | loss: 0.17315 - acc: 0.9451 -- iter: 0864/1468
[A[ATraining Step: 810  | total loss: [1m[32m0.16390[0m[0m | time: 23.470s
[2K
| Adam | epoch: 018 | loss: 0.16390 - acc: 0.9506 -- iter: 0896/1468
[A[ATraining Step: 811  | total loss: [1m[32m0.16603[0m[0m | time: 24.752s
[2K
| Adam | epoch: 018 | loss: 0.16603 - acc: 0.9493 -- iter: 0928/1468
[A[ATraining Step: 812  | total loss: [1m[32m0.18556[0m[0m | time: 26.216s
[2K
| Adam | epoch: 018 | loss: 0.18556 - acc: 0.9450 -- iter: 0960/1468
[A[ATraining Step: 813  | total loss: [1m[32m0.18396[0m[0m | time: 26.879s
[2K
| Adam | epoch: 018 | loss: 0.18396 - acc: 0.9474 -- iter: 0992/1468
[A[ATraining Step: 814  | total loss: [1m[32m0.18758[0m[0m | time: 27.513s
[2K
| Adam | epoch: 018 | loss: 0.18758 - acc: 0.9495 -- iter: 1024/1468
[A[ATraining Step: 815  | total loss: [1m[32m0.17469[0m[0m | time: 28.155s
[2K
| Adam | epoch: 018 | loss: 0.17469 - acc: 0.9546 -- iter: 1056/1468
[A[ATraining Step: 816  | total loss: [1m[32m0.18115[0m[0m | time: 28.770s
[2K
| Adam | epoch: 018 | loss: 0.18115 - acc: 0.9497 -- iter: 1088/1468
[A[ATraining Step: 817  | total loss: [1m[32m0.17720[0m[0m | time: 29.425s
[2K
| Adam | epoch: 018 | loss: 0.17720 - acc: 0.9485 -- iter: 1120/1468
[A[ATraining Step: 818  | total loss: [1m[32m0.18185[0m[0m | time: 30.073s
[2K
| Adam | epoch: 018 | loss: 0.18185 - acc: 0.9474 -- iter: 1152/1468
[A[ATraining Step: 819  | total loss: [1m[32m0.17329[0m[0m | time: 30.696s
[2K
| Adam | epoch: 018 | loss: 0.17329 - acc: 0.9495 -- iter: 1184/1468
[A[ATraining Step: 820  | total loss: [1m[32m0.16271[0m[0m | time: 31.317s
[2K
| Adam | epoch: 018 | loss: 0.16271 - acc: 0.9546 -- iter: 1216/1468
[A[ATraining Step: 821  | total loss: [1m[32m0.16537[0m[0m | time: 31.942s
[2K
| Adam | epoch: 018 | loss: 0.16537 - acc: 0.9529 -- iter: 1248/1468
[A[ATraining Step: 822  | total loss: [1m[32m0.16138[0m[0m | time: 32.560s
[2K
| Adam | epoch: 018 | loss: 0.16138 - acc: 0.9576 -- iter: 1280/1468
[A[ATraining Step: 823  | total loss: [1m[32m0.16077[0m[0m | time: 33.198s
[2K
| Adam | epoch: 018 | loss: 0.16077 - acc: 0.9587 -- iter: 1312/1468
[A[ATraining Step: 824  | total loss: [1m[32m0.15200[0m[0m | time: 33.838s
[2K
| Adam | epoch: 018 | loss: 0.15200 - acc: 0.9628 -- iter: 1344/1468
[A[ATraining Step: 825  | total loss: [1m[32m0.15577[0m[0m | time: 34.451s
[2K
| Adam | epoch: 018 | loss: 0.15577 - acc: 0.9603 -- iter: 1376/1468
[A[ATraining Step: 826  | total loss: [1m[32m0.16587[0m[0m | time: 35.092s
[2K
| Adam | epoch: 018 | loss: 0.16587 - acc: 0.9549 -- iter: 1408/1468
[A[ATraining Step: 827  | total loss: [1m[32m0.16613[0m[0m | time: 35.712s
[2K
| Adam | epoch: 018 | loss: 0.16613 - acc: 0.9563 -- iter: 1440/1468
[A[ATraining Step: 828  | total loss: [1m[32m0.16173[0m[0m | time: 37.867s
[2K
| Adam | epoch: 018 | loss: 0.16173 - acc: 0.9575 | val_loss: 0.48771 - val_acc: 0.8083 -- iter: 1468/1468
--
Training Step: 829  | total loss: [1m[32m0.15810[0m[0m | time: 0.655s
[2K
| Adam | epoch: 019 | loss: 0.15810 - acc: 0.9555 -- iter: 0032/1468
[A[ATraining Step: 830  | total loss: [1m[32m0.15532[0m[0m | time: 1.301s
[2K
| Adam | epoch: 019 | loss: 0.15532 - acc: 0.9568 -- iter: 0064/1468
[A[ATraining Step: 831  | total loss: [1m[32m0.15232[0m[0m | time: 1.934s
[2K
| Adam | epoch: 019 | loss: 0.15232 - acc: 0.9580 -- iter: 0096/1468
[A[ATraining Step: 832  | total loss: [1m[32m0.15507[0m[0m | time: 2.595s
[2K
| Adam | epoch: 019 | loss: 0.15507 - acc: 0.9529 -- iter: 0128/1468
[A[ATraining Step: 833  | total loss: [1m[32m0.15733[0m[0m | time: 3.234s
[2K
| Adam | epoch: 019 | loss: 0.15733 - acc: 0.9513 -- iter: 0160/1468
[A[ATraining Step: 834  | total loss: [1m[32m0.14642[0m[0m | time: 3.889s
[2K
| Adam | epoch: 019 | loss: 0.14642 - acc: 0.9562 -- iter: 0192/1468
[A[ATraining Step: 835  | total loss: [1m[32m0.13979[0m[0m | time: 4.513s
[2K
| Adam | epoch: 019 | loss: 0.13979 - acc: 0.9606 -- iter: 0224/1468
[A[ATraining Step: 836  | total loss: [1m[32m0.15342[0m[0m | time: 5.141s
[2K
| Adam | epoch: 019 | loss: 0.15342 - acc: 0.9551 -- iter: 0256/1468
[A[ATraining Step: 837  | total loss: [1m[32m0.16702[0m[0m | time: 5.755s
[2K
| Adam | epoch: 019 | loss: 0.16702 - acc: 0.9503 -- iter: 0288/1468
[A[ATraining Step: 838  | total loss: [1m[32m0.15700[0m[0m | time: 6.379s
[2K
| Adam | epoch: 019 | loss: 0.15700 - acc: 0.9552 -- iter: 0320/1468
[A[ATraining Step: 839  | total loss: [1m[32m0.16094[0m[0m | time: 6.992s
[2K
| Adam | epoch: 019 | loss: 0.16094 - acc: 0.9535 -- iter: 0352/1468
[A[ATraining Step: 840  | total loss: [1m[32m0.15352[0m[0m | time: 7.609s
[2K
| Adam | epoch: 019 | loss: 0.15352 - acc: 0.9550 -- iter: 0384/1468
[A[ATraining Step: 841  | total loss: [1m[32m0.15063[0m[0m | time: 8.210s
[2K
| Adam | epoch: 019 | loss: 0.15063 - acc: 0.9532 -- iter: 0416/1468
[A[ATraining Step: 842  | total loss: [1m[32m0.15108[0m[0m | time: 8.839s
[2K
| Adam | epoch: 019 | loss: 0.15108 - acc: 0.9485 -- iter: 0448/1468
[A[ATraining Step: 843  | total loss: [1m[32m0.15079[0m[0m | time: 9.464s
[2K
| Adam | epoch: 019 | loss: 0.15079 - acc: 0.9474 -- iter: 0480/1468
[A[ATraining Step: 844  | total loss: [1m[32m0.14816[0m[0m | time: 10.140s
[2K
| Adam | epoch: 019 | loss: 0.14816 - acc: 0.9496 -- iter: 0512/1468
[A[ATraining Step: 845  | total loss: [1m[32m0.16034[0m[0m | time: 10.697s
[2K
| Adam | epoch: 019 | loss: 0.16034 - acc: 0.9452 -- iter: 0544/1468
[A[ATraining Step: 846  | total loss: [1m[32m0.15255[0m[0m | time: 11.272s
[2K
| Adam | epoch: 019 | loss: 0.15255 - acc: 0.9507 -- iter: 0576/1468
[A[ATraining Step: 847  | total loss: [1m[32m0.14627[0m[0m | time: 11.936s
[2K
| Adam | epoch: 019 | loss: 0.14627 - acc: 0.9556 -- iter: 0608/1468
[A[ATraining Step: 848  | total loss: [1m[32m0.14614[0m[0m | time: 12.557s
[2K
| Adam | epoch: 019 | loss: 0.14614 - acc: 0.9569 -- iter: 0640/1468
[A[ATraining Step: 849  | total loss: [1m[32m0.14030[0m[0m | time: 13.172s
[2K
| Adam | epoch: 019 | loss: 0.14030 - acc: 0.9613 -- iter: 0672/1468
[A[ATraining Step: 850  | total loss: [1m[32m0.15135[0m[0m | time: 13.814s
[2K
| Adam | epoch: 019 | loss: 0.15135 - acc: 0.9526 -- iter: 0704/1468
[A[ATraining Step: 851  | total loss: [1m[32m0.14810[0m[0m | time: 14.463s
[2K
| Adam | epoch: 019 | loss: 0.14810 - acc: 0.9542 -- iter: 0736/1468
[A[ATraining Step: 852  | total loss: [1m[32m0.14226[0m[0m | time: 15.110s
[2K
| Adam | epoch: 019 | loss: 0.14226 - acc: 0.9557 -- iter: 0768/1468
[A[ATraining Step: 853  | total loss: [1m[32m0.14462[0m[0m | time: 15.757s
[2K
| Adam | epoch: 019 | loss: 0.14462 - acc: 0.9539 -- iter: 0800/1468
[A[ATraining Step: 854  | total loss: [1m[32m0.14366[0m[0m | time: 16.389s
[2K
| Adam | epoch: 019 | loss: 0.14366 - acc: 0.9585 -- iter: 0832/1468
[A[ATraining Step: 855  | total loss: [1m[32m0.14976[0m[0m | time: 17.032s
[2K
| Adam | epoch: 019 | loss: 0.14976 - acc: 0.9564 -- iter: 0864/1468
[A[ATraining Step: 856  | total loss: [1m[32m0.14295[0m[0m | time: 17.648s
[2K
| Adam | epoch: 019 | loss: 0.14295 - acc: 0.9576 -- iter: 0896/1468
[A[ATraining Step: 857  | total loss: [1m[32m0.13813[0m[0m | time: 18.379s
[2K
| Adam | epoch: 019 | loss: 0.13813 - acc: 0.9587 -- iter: 0928/1468
[A[ATraining Step: 858  | total loss: [1m[32m0.14019[0m[0m | time: 19.028s
[2K
| Adam | epoch: 019 | loss: 0.14019 - acc: 0.9566 -- iter: 0960/1468
[A[ATraining Step: 859  | total loss: [1m[32m0.13517[0m[0m | time: 19.669s
[2K
| Adam | epoch: 019 | loss: 0.13517 - acc: 0.9610 -- iter: 0992/1468
[A[ATraining Step: 860  | total loss: [1m[32m0.12976[0m[0m | time: 20.303s
[2K
| Adam | epoch: 019 | loss: 0.12976 - acc: 0.9617 -- iter: 1024/1468
[A[ATraining Step: 861  | total loss: [1m[32m0.12097[0m[0m | time: 20.983s
[2K
| Adam | epoch: 019 | loss: 0.12097 - acc: 0.9656 -- iter: 1056/1468
[A[ATraining Step: 862  | total loss: [1m[32m0.11934[0m[0m | time: 21.635s
[2K
| Adam | epoch: 019 | loss: 0.11934 - acc: 0.9628 -- iter: 1088/1468
[A[ATraining Step: 863  | total loss: [1m[32m0.11984[0m[0m | time: 22.296s
[2K
| Adam | epoch: 019 | loss: 0.11984 - acc: 0.9634 -- iter: 1120/1468
[A[ATraining Step: 864  | total loss: [1m[32m0.11422[0m[0m | time: 22.919s
[2K
| Adam | epoch: 019 | loss: 0.11422 - acc: 0.9670 -- iter: 1152/1468
[A[ATraining Step: 865  | total loss: [1m[32m0.10919[0m[0m | time: 23.543s
[2K
| Adam | epoch: 019 | loss: 0.10919 - acc: 0.9703 -- iter: 1184/1468
[A[ATraining Step: 866  | total loss: [1m[32m0.11616[0m[0m | time: 24.173s
[2K
| Adam | epoch: 019 | loss: 0.11616 - acc: 0.9670 -- iter: 1216/1468
[A[ATraining Step: 867  | total loss: [1m[32m0.11190[0m[0m | time: 24.794s
[2K
| Adam | epoch: 019 | loss: 0.11190 - acc: 0.9703 -- iter: 1248/1468
[A[ATraining Step: 868  | total loss: [1m[32m0.12086[0m[0m | time: 25.423s
[2K
| Adam | epoch: 019 | loss: 0.12086 - acc: 0.9702 -- iter: 1280/1468
[A[ATraining Step: 869  | total loss: [1m[32m0.11842[0m[0m | time: 26.084s
[2K
| Adam | epoch: 019 | loss: 0.11842 - acc: 0.9732 -- iter: 1312/1468
[A[ATraining Step: 870  | total loss: [1m[32m0.11234[0m[0m | time: 26.715s
[2K
| Adam | epoch: 019 | loss: 0.11234 - acc: 0.9758 -- iter: 1344/1468
[A[ATraining Step: 871  | total loss: [1m[32m0.11523[0m[0m | time: 27.363s
[2K
| Adam | epoch: 019 | loss: 0.11523 - acc: 0.9720 -- iter: 1376/1468
[A[ATraining Step: 872  | total loss: [1m[32m0.12439[0m[0m | time: 27.985s
[2K
| Adam | epoch: 019 | loss: 0.12439 - acc: 0.9717 -- iter: 1408/1468
[A[ATraining Step: 873  | total loss: [1m[32m0.13574[0m[0m | time: 28.616s
[2K
| Adam | epoch: 019 | loss: 0.13574 - acc: 0.9620 -- iter: 1440/1468
[A[ATraining Step: 874  | total loss: [1m[32m0.13763[0m[0m | time: 30.797s
[2K
| Adam | epoch: 019 | loss: 0.13763 - acc: 0.9627 | val_loss: 0.48258 - val_acc: 0.8105 -- iter: 1468/1468
--
Training Step: 875  | total loss: [1m[32m0.13473[0m[0m | time: 0.645s
[2K
| Adam | epoch: 020 | loss: 0.13473 - acc: 0.9633 -- iter: 0032/1468
[A[ATraining Step: 876  | total loss: [1m[32m0.12598[0m[0m | time: 1.289s
[2K
| Adam | epoch: 020 | loss: 0.12598 - acc: 0.9670 -- iter: 0064/1468
[A[ATraining Step: 877  | total loss: [1m[32m0.12649[0m[0m | time: 1.926s
[2K
| Adam | epoch: 020 | loss: 0.12649 - acc: 0.9703 -- iter: 0096/1468
[A[ATraining Step: 878  | total loss: [1m[32m0.13145[0m[0m | time: 2.543s
[2K
| Adam | epoch: 020 | loss: 0.13145 - acc: 0.9639 -- iter: 0128/1468
[A[ATraining Step: 879  | total loss: [1m[32m0.12675[0m[0m | time: 3.191s
[2K
| Adam | epoch: 020 | loss: 0.12675 - acc: 0.9675 -- iter: 0160/1468
[A[ATraining Step: 880  | total loss: [1m[32m0.13102[0m[0m | time: 3.846s
[2K
| Adam | epoch: 020 | loss: 0.13102 - acc: 0.9645 -- iter: 0192/1468
[A[ATraining Step: 881  | total loss: [1m[32m0.12655[0m[0m | time: 4.451s
[2K
| Adam | epoch: 020 | loss: 0.12655 - acc: 0.9649 -- iter: 0224/1468
[A[ATraining Step: 882  | total loss: [1m[32m0.13141[0m[0m | time: 5.095s
[2K
| Adam | epoch: 020 | loss: 0.13141 - acc: 0.9622 -- iter: 0256/1468
[A[ATraining Step: 883  | total loss: [1m[32m0.12328[0m[0m | time: 5.727s
[2K
| Adam | epoch: 020 | loss: 0.12328 - acc: 0.9660 -- iter: 0288/1468
[A[ATraining Step: 884  | total loss: [1m[32m0.11625[0m[0m | time: 6.364s
[2K
| Adam | epoch: 020 | loss: 0.11625 - acc: 0.9694 -- iter: 0320/1468
[A[ATraining Step: 885  | total loss: [1m[32m0.11212[0m[0m | time: 6.984s
[2K
| Adam | epoch: 020 | loss: 0.11212 - acc: 0.9662 -- iter: 0352/1468
[A[ATraining Step: 886  | total loss: [1m[32m0.11168[0m[0m | time: 7.640s
[2K
| Adam | epoch: 020 | loss: 0.11168 - acc: 0.9633 -- iter: 0384/1468
[A[ATraining Step: 887  | total loss: [1m[32m0.10360[0m[0m | time: 8.272s
[2K
| Adam | epoch: 020 | loss: 0.10360 - acc: 0.9670 -- iter: 0416/1468
[A[ATraining Step: 888  | total loss: [1m[32m0.10033[0m[0m | time: 8.900s
[2K
| Adam | epoch: 020 | loss: 0.10033 - acc: 0.9672 -- iter: 0448/1468
[A[ATraining Step: 889  | total loss: [1m[32m0.11271[0m[0m | time: 9.563s
[2K
| Adam | epoch: 020 | loss: 0.11271 - acc: 0.9611 -- iter: 0480/1468
[A[ATraining Step: 890  | total loss: [1m[32m0.11777[0m[0m | time: 10.193s
[2K
| Adam | epoch: 020 | loss: 0.11777 - acc: 0.9587 -- iter: 0512/1468
[A[ATraining Step: 891  | total loss: [1m[32m0.11228[0m[0m | time: 10.817s
[2K
| Adam | epoch: 020 | loss: 0.11228 - acc: 0.9628 -- iter: 0544/1468
[A[ATraining Step: 892  | total loss: [1m[32m0.11449[0m[0m | time: 11.375s
[2K
| Adam | epoch: 020 | loss: 0.11449 - acc: 0.9634 -- iter: 0576/1468
[A[ATraining Step: 893  | total loss: [1m[32m0.11985[0m[0m | time: 11.941s
[2K
| Adam | epoch: 020 | loss: 0.11985 - acc: 0.9599 -- iter: 0608/1468
[A[ATraining Step: 894  | total loss: [1m[32m0.12238[0m[0m | time: 12.565s
[2K
| Adam | epoch: 020 | loss: 0.12238 - acc: 0.9568 -- iter: 0640/1468
[A[ATraining Step: 895  | total loss: [1m[32m0.12070[0m[0m | time: 13.177s
[2K
| Adam | epoch: 020 | loss: 0.12070 - acc: 0.9611 -- iter: 0672/1468
[A[ATraining Step: 896  | total loss: [1m[32m0.11567[0m[0m | time: 13.820s
[2K
| Adam | epoch: 020 | loss: 0.11567 - acc: 0.9650 -- iter: 0704/1468
[A[ATraining Step: 897  | total loss: [1m[32m0.11923[0m[0m | time: 14.476s
[2K
| Adam | epoch: 020 | loss: 0.11923 - acc: 0.9591 -- iter: 0736/1468
[A[ATraining Step: 898  | total loss: [1m[32m0.11575[0m[0m | time: 15.106s
[2K
| Adam | epoch: 020 | loss: 0.11575 - acc: 0.9601 -- iter: 0768/1468
[A[ATraining Step: 899  | total loss: [1m[32m0.12866[0m[0m | time: 15.727s
[2K
| Adam | epoch: 020 | loss: 0.12866 - acc: 0.9453 -- iter: 0800/1468
[A[ATraining Step: 900  | total loss: [1m[32m0.12703[0m[0m | time: 16.350s
[2K
| Adam | epoch: 020 | loss: 0.12703 - acc: 0.9446 -- iter: 0832/1468
[A[ATraining Step: 901  | total loss: [1m[32m0.12629[0m[0m | time: 16.965s
[2K
| Adam | epoch: 020 | loss: 0.12629 - acc: 0.9470 -- iter: 0864/1468
[A[ATraining Step: 902  | total loss: [1m[32m0.12489[0m[0m | time: 17.653s
[2K
| Adam | epoch: 020 | loss: 0.12489 - acc: 0.9460 -- iter: 0896/1468
[A[ATraining Step: 903  | total loss: [1m[32m0.12194[0m[0m | time: 18.342s
[2K
| Adam | epoch: 020 | loss: 0.12194 - acc: 0.9483 -- iter: 0928/1468
[A[ATraining Step: 904  | total loss: [1m[32m0.12677[0m[0m | time: 19.008s
[2K
| Adam | epoch: 020 | loss: 0.12677 - acc: 0.9441 -- iter: 0960/1468
[A[ATraining Step: 905  | total loss: [1m[32m0.12040[0m[0m | time: 19.669s
[2K
| Adam | epoch: 020 | loss: 0.12040 - acc: 0.9466 -- iter: 0992/1468
[A[ATraining Step: 906  | total loss: [1m[32m0.11359[0m[0m | time: 20.317s
[2K
| Adam | epoch: 020 | loss: 0.11359 - acc: 0.9519 -- iter: 1024/1468
[A[ATraining Step: 907  | total loss: [1m[32m0.10866[0m[0m | time: 20.957s
[2K
| Adam | epoch: 020 | loss: 0.10866 - acc: 0.9567 -- iter: 1056/1468
[A[ATraining Step: 908  | total loss: [1m[32m0.11887[0m[0m | time: 21.617s
[2K
| Adam | epoch: 020 | loss: 0.11887 - acc: 0.9579 -- iter: 1088/1468
[A[ATraining Step: 909  | total loss: [1m[32m0.10951[0m[0m | time: 22.256s
[2K
| Adam | epoch: 020 | loss: 0.10951 - acc: 0.9621 -- iter: 1120/1468
[A[ATraining Step: 910  | total loss: [1m[32m0.10471[0m[0m | time: 22.886s
[2K
| Adam | epoch: 020 | loss: 0.10471 - acc: 0.9659 -- iter: 1152/1468
[A[ATraining Step: 911  | total loss: [1m[32m0.10032[0m[0m | time: 23.535s
[2K
| Adam | epoch: 020 | loss: 0.10032 - acc: 0.9693 -- iter: 1184/1468
[A[ATraining Step: 912  | total loss: [1m[32m0.09559[0m[0m | time: 24.212s
[2K
| Adam | epoch: 020 | loss: 0.09559 - acc: 0.9724 -- iter: 1216/1468
[A[ATraining Step: 913  | total loss: [1m[32m0.09179[0m[0m | time: 24.863s
[2K
| Adam | epoch: 020 | loss: 0.09179 - acc: 0.9720 -- iter: 1248/1468
[A[ATraining Step: 914  | total loss: [1m[32m0.08670[0m[0m | time: 25.517s
[2K
| Adam | epoch: 020 | loss: 0.08670 - acc: 0.9748 -- iter: 1280/1468
[A[ATraining Step: 915  | total loss: [1m[32m0.10075[0m[0m | time: 26.165s
[2K
| Adam | epoch: 020 | loss: 0.10075 - acc: 0.9680 -- iter: 1312/1468
[A[ATraining Step: 916  | total loss: [1m[32m0.09951[0m[0m | time: 26.779s
[2K
| Adam | epoch: 020 | loss: 0.09951 - acc: 0.9680 -- iter: 1344/1468
[A[ATraining Step: 917  | total loss: [1m[32m0.10140[0m[0m | time: 27.400s
[2K
| Adam | epoch: 020 | loss: 0.10140 - acc: 0.9681 -- iter: 1376/1468
[A[ATraining Step: 918  | total loss: [1m[32m0.10028[0m[0m | time: 28.040s
[2K
| Adam | epoch: 020 | loss: 0.10028 - acc: 0.9682 -- iter: 1408/1468
[A[ATraining Step: 919  | total loss: [1m[32m0.09436[0m[0m | time: 28.680s
[2K
| Adam | epoch: 020 | loss: 0.09436 - acc: 0.9714 -- iter: 1440/1468
[A[ATraining Step: 920  | total loss: [1m[32m0.08762[0m[0m | time: 30.858s
[2K
| Adam | epoch: 020 | loss: 0.08762 - acc: 0.9742 | val_loss: 0.56026 - val_acc: 0.8105 -- iter: 1468/1468
--
Training Step: 921  | total loss: [1m[32m0.08963[0m[0m | time: 0.644s
[2K
| Adam | epoch: 021 | loss: 0.08963 - acc: 0.9706 -- iter: 0032/1468
[A[ATraining Step: 922  | total loss: [1m[32m0.09750[0m[0m | time: 1.283s
[2K
| Adam | epoch: 021 | loss: 0.09750 - acc: 0.9672 -- iter: 0064/1468
[A[ATraining Step: 923  | total loss: [1m[32m0.09970[0m[0m | time: 1.917s
[2K
| Adam | epoch: 021 | loss: 0.09970 - acc: 0.9674 -- iter: 0096/1468
[A[ATraining Step: 924  | total loss: [1m[32m0.09762[0m[0m | time: 2.580s
[2K
| Adam | epoch: 021 | loss: 0.09762 - acc: 0.9675 -- iter: 0128/1468
[A[ATraining Step: 925  | total loss: [1m[32m0.10085[0m[0m | time: 3.205s
[2K
| Adam | epoch: 021 | loss: 0.10085 - acc: 0.9645 -- iter: 0160/1468
[A[ATraining Step: 926  | total loss: [1m[32m0.09720[0m[0m | time: 3.818s
[2K
| Adam | epoch: 021 | loss: 0.09720 - acc: 0.9681 -- iter: 0192/1468
[A[ATraining Step: 927  | total loss: [1m[32m0.10611[0m[0m | time: 4.437s
[2K
| Adam | epoch: 021 | loss: 0.10611 - acc: 0.9650 -- iter: 0224/1468
[A[ATraining Step: 928  | total loss: [1m[32m0.10366[0m[0m | time: 5.167s
[2K
| Adam | epoch: 021 | loss: 0.10366 - acc: 0.9685 -- iter: 0256/1468
[A[ATraining Step: 929  | total loss: [1m[32m0.09834[0m[0m | time: 5.783s
[2K
| Adam | epoch: 021 | loss: 0.09834 - acc: 0.9717 -- iter: 0288/1468
[A[ATraining Step: 930  | total loss: [1m[32m0.09367[0m[0m | time: 6.403s
[2K
| Adam | epoch: 021 | loss: 0.09367 - acc: 0.9745 -- iter: 0320/1468
[A[ATraining Step: 931  | total loss: [1m[32m0.09436[0m[0m | time: 7.034s
[2K
| Adam | epoch: 021 | loss: 0.09436 - acc: 0.9739 -- iter: 0352/1468
[A[ATraining Step: 932  | total loss: [1m[32m0.09940[0m[0m | time: 7.659s
[2K
| Adam | epoch: 021 | loss: 0.09940 - acc: 0.9703 -- iter: 0384/1468
[A[ATraining Step: 933  | total loss: [1m[32m0.09592[0m[0m | time: 8.270s
[2K
| Adam | epoch: 021 | loss: 0.09592 - acc: 0.9733 -- iter: 0416/1468
[A[ATraining Step: 934  | total loss: [1m[32m0.09071[0m[0m | time: 8.899s
[2K
| Adam | epoch: 021 | loss: 0.09071 - acc: 0.9759 -- iter: 0448/1468
[A[ATraining Step: 935  | total loss: [1m[32m0.08727[0m[0m | time: 9.524s
[2K
| Adam | epoch: 021 | loss: 0.08727 - acc: 0.9783 -- iter: 0480/1468
[A[ATraining Step: 936  | total loss: [1m[32m0.09843[0m[0m | time: 10.142s
[2K
| Adam | epoch: 021 | loss: 0.09843 - acc: 0.9711 -- iter: 0512/1468
[A[ATraining Step: 937  | total loss: [1m[32m0.09980[0m[0m | time: 10.789s
[2K
| Adam | epoch: 021 | loss: 0.09980 - acc: 0.9678 -- iter: 0544/1468
[A[ATraining Step: 938  | total loss: [1m[32m0.10264[0m[0m | time: 11.422s
[2K
| Adam | epoch: 021 | loss: 0.10264 - acc: 0.9647 -- iter: 0576/1468
[A[ATraining Step: 939  | total loss: [1m[32m0.09786[0m[0m | time: 11.973s
[2K
| Adam | epoch: 021 | loss: 0.09786 - acc: 0.9683 -- iter: 0608/1468
[A[ATraining Step: 940  | total loss: [1m[32m0.10324[0m[0m | time: 12.545s
[2K
| Adam | epoch: 021 | loss: 0.10324 - acc: 0.9679 -- iter: 0640/1468
[A[ATraining Step: 941  | total loss: [1m[32m0.10494[0m[0m | time: 13.184s
[2K
| Adam | epoch: 021 | loss: 0.10494 - acc: 0.9675 -- iter: 0672/1468
[A[ATraining Step: 942  | total loss: [1m[32m0.13589[0m[0m | time: 13.826s
[2K
| Adam | epoch: 021 | loss: 0.13589 - acc: 0.9614 -- iter: 0704/1468
[A[ATraining Step: 943  | total loss: [1m[32m0.13751[0m[0m | time: 14.454s
[2K
| Adam | epoch: 021 | loss: 0.13751 - acc: 0.9559 -- iter: 0736/1468
[A[ATraining Step: 944  | total loss: [1m[32m0.13065[0m[0m | time: 15.106s
[2K
| Adam | epoch: 021 | loss: 0.13065 - acc: 0.9603 -- iter: 0768/1468
[A[ATraining Step: 945  | total loss: [1m[32m0.12896[0m[0m | time: 15.741s
[2K
| Adam | epoch: 021 | loss: 0.12896 - acc: 0.9611 -- iter: 0800/1468
[A[ATraining Step: 946  | total loss: [1m[32m0.12688[0m[0m | time: 16.367s
[2K
| Adam | epoch: 021 | loss: 0.12688 - acc: 0.9588 -- iter: 0832/1468
[A[ATraining Step: 947  | total loss: [1m[32m0.12312[0m[0m | time: 17.020s
[2K
| Adam | epoch: 021 | loss: 0.12312 - acc: 0.9629 -- iter: 0864/1468
[A[ATraining Step: 948  | total loss: [1m[32m0.13514[0m[0m | time: 17.633s
[2K
| Adam | epoch: 021 | loss: 0.13514 - acc: 0.9604 -- iter: 0896/1468
[A[ATraining Step: 949  | total loss: [1m[32m0.13285[0m[0m | time: 18.291s
[2K
| Adam | epoch: 021 | loss: 0.13285 - acc: 0.9612 -- iter: 0928/1468
[A[ATraining Step: 950  | total loss: [1m[32m0.12901[0m[0m | time: 18.945s
[2K
| Adam | epoch: 021 | loss: 0.12901 - acc: 0.9588 -- iter: 0960/1468
[A[ATraining Step: 951  | total loss: [1m[32m0.12840[0m[0m | time: 19.606s
[2K
| Adam | epoch: 021 | loss: 0.12840 - acc: 0.9598 -- iter: 0992/1468
[A[ATraining Step: 952  | total loss: [1m[32m0.11899[0m[0m | time: 20.220s
[2K
| Adam | epoch: 021 | loss: 0.11899 - acc: 0.9638 -- iter: 1024/1468
[A[ATraining Step: 953  | total loss: [1m[32m0.11661[0m[0m | time: 20.836s
[2K
| Adam | epoch: 021 | loss: 0.11661 - acc: 0.9643 -- iter: 1056/1468
[A[ATraining Step: 954  | total loss: [1m[32m0.12847[0m[0m | time: 21.452s
[2K
| Adam | epoch: 021 | loss: 0.12847 - acc: 0.9585 -- iter: 1088/1468
[A[ATraining Step: 955  | total loss: [1m[32m0.12888[0m[0m | time: 22.102s
[2K
| Adam | epoch: 021 | loss: 0.12888 - acc: 0.9564 -- iter: 1120/1468
[A[ATraining Step: 956  | total loss: [1m[32m0.12012[0m[0m | time: 22.710s
[2K
| Adam | epoch: 021 | loss: 0.12012 - acc: 0.9576 -- iter: 1152/1468
[A[ATraining Step: 957  | total loss: [1m[32m0.11757[0m[0m | time: 23.332s
[2K
| Adam | epoch: 021 | loss: 0.11757 - acc: 0.9619 -- iter: 1184/1468
[A[ATraining Step: 958  | total loss: [1m[32m0.11485[0m[0m | time: 23.965s
[2K
| Adam | epoch: 021 | loss: 0.11485 - acc: 0.9626 -- iter: 1216/1468
[A[ATraining Step: 959  | total loss: [1m[32m0.11440[0m[0m | time: 24.595s
[2K
| Adam | epoch: 021 | loss: 0.11440 - acc: 0.9601 -- iter: 1248/1468
[A[ATraining Step: 960  | total loss: [1m[32m0.10949[0m[0m | time: 25.297s
[2K
| Adam | epoch: 021 | loss: 0.10949 - acc: 0.9641 -- iter: 1280/1468
[A[ATraining Step: 961  | total loss: [1m[32m0.10421[0m[0m | time: 25.917s
[2K
| Adam | epoch: 021 | loss: 0.10421 - acc: 0.9645 -- iter: 1312/1468
[A[ATraining Step: 962  | total loss: [1m[32m0.10282[0m[0m | time: 26.545s
[2K
| Adam | epoch: 021 | loss: 0.10282 - acc: 0.9649 -- iter: 1344/1468
[A[ATraining Step: 963  | total loss: [1m[32m0.09637[0m[0m | time: 27.176s
[2K
| Adam | epoch: 021 | loss: 0.09637 - acc: 0.9685 -- iter: 1376/1468
[A[ATraining Step: 964  | total loss: [1m[32m0.10618[0m[0m | time: 27.857s
[2K
| Adam | epoch: 021 | loss: 0.10618 - acc: 0.9685 -- iter: 1408/1468
[A[ATraining Step: 965  | total loss: [1m[32m0.09957[0m[0m | time: 28.495s
[2K
| Adam | epoch: 021 | loss: 0.09957 - acc: 0.9716 -- iter: 1440/1468
[A[ATraining Step: 966  | total loss: [1m[32m0.09453[0m[0m | time: 30.667s
[2K
| Adam | epoch: 021 | loss: 0.09453 - acc: 0.9745 | val_loss: 0.51690 - val_acc: 0.8061 -- iter: 1468/1468
--
Training Step: 967  | total loss: [1m[32m0.08984[0m[0m | time: 0.673s
[2K
| Adam | epoch: 022 | loss: 0.08984 - acc: 0.9770 -- iter: 0032/1468
[A[ATraining Step: 968  | total loss: [1m[32m0.08474[0m[0m | time: 1.328s
[2K
| Adam | epoch: 022 | loss: 0.08474 - acc: 0.9793 -- iter: 0064/1468
[A[ATraining Step: 969  | total loss: [1m[32m0.08371[0m[0m | time: 1.987s
[2K
| Adam | epoch: 022 | loss: 0.08371 - acc: 0.9783 -- iter: 0096/1468
[A[ATraining Step: 970  | total loss: [1m[32m0.08544[0m[0m | time: 2.629s
[2K
| Adam | epoch: 022 | loss: 0.08544 - acc: 0.9773 -- iter: 0128/1468
[A[ATraining Step: 971  | total loss: [1m[32m0.08028[0m[0m | time: 3.274s
[2K
| Adam | epoch: 022 | loss: 0.08028 - acc: 0.9796 -- iter: 0160/1468
[A[ATraining Step: 972  | total loss: [1m[32m0.09015[0m[0m | time: 3.894s
[2K
| Adam | epoch: 022 | loss: 0.09015 - acc: 0.9754 -- iter: 0192/1468
[A[ATraining Step: 973  | total loss: [1m[32m0.08680[0m[0m | time: 4.512s
[2K
| Adam | epoch: 022 | loss: 0.08680 - acc: 0.9778 -- iter: 0224/1468
[A[ATraining Step: 974  | total loss: [1m[32m0.08114[0m[0m | time: 5.135s
[2K
| Adam | epoch: 022 | loss: 0.08114 - acc: 0.9801 -- iter: 0256/1468
[A[ATraining Step: 975  | total loss: [1m[32m0.07925[0m[0m | time: 5.784s
[2K
| Adam | epoch: 022 | loss: 0.07925 - acc: 0.9789 -- iter: 0288/1468
[A[ATraining Step: 976  | total loss: [1m[32m0.08036[0m[0m | time: 6.407s
[2K
| Adam | epoch: 022 | loss: 0.08036 - acc: 0.9748 -- iter: 0320/1468
[A[ATraining Step: 977  | total loss: [1m[32m0.07894[0m[0m | time: 7.035s
[2K
| Adam | epoch: 022 | loss: 0.07894 - acc: 0.9742 -- iter: 0352/1468
[A[ATraining Step: 978  | total loss: [1m[32m0.07579[0m[0m | time: 7.658s
[2K
| Adam | epoch: 022 | loss: 0.07579 - acc: 0.9736 -- iter: 0384/1468
[A[ATraining Step: 979  | total loss: [1m[32m0.08180[0m[0m | time: 8.285s
[2K
| Adam | epoch: 022 | loss: 0.08180 - acc: 0.9731 -- iter: 0416/1468
[A[ATraining Step: 980  | total loss: [1m[32m0.07699[0m[0m | time: 8.972s
[2K
| Adam | epoch: 022 | loss: 0.07699 - acc: 0.9758 -- iter: 0448/1468
[A[ATraining Step: 981  | total loss: [1m[32m0.07530[0m[0m | time: 9.620s
[2K
| Adam | epoch: 022 | loss: 0.07530 - acc: 0.9782 -- iter: 0480/1468
[A[ATraining Step: 982  | total loss: [1m[32m0.07816[0m[0m | time: 10.246s
[2K
| Adam | epoch: 022 | loss: 0.07816 - acc: 0.9773 -- iter: 0512/1468
[A[ATraining Step: 983  | total loss: [1m[32m0.07291[0m[0m | time: 10.871s
[2K
| Adam | epoch: 022 | loss: 0.07291 - acc: 0.9796 -- iter: 0544/1468
[A[ATraining Step: 984  | total loss: [1m[32m0.06998[0m[0m | time: 11.494s
[2K
| Adam | epoch: 022 | loss: 0.06998 - acc: 0.9816 -- iter: 0576/1468
[A[ATraining Step: 985  | total loss: [1m[32m0.06844[0m[0m | time: 12.115s
[2K
| Adam | epoch: 022 | loss: 0.06844 - acc: 0.9803 -- iter: 0608/1468
[A[ATraining Step: 986  | total loss: [1m[32m0.06681[0m[0m | time: 12.670s
[2K
| Adam | epoch: 022 | loss: 0.06681 - acc: 0.9823 -- iter: 0640/1468
[A[ATraining Step: 987  | total loss: [1m[32m0.06720[0m[0m | time: 13.250s
[2K
| Adam | epoch: 022 | loss: 0.06720 - acc: 0.9805 -- iter: 0672/1468
[A[ATraining Step: 988  | total loss: [1m[32m0.06588[0m[0m | time: 13.897s
[2K
| Adam | epoch: 022 | loss: 0.06588 - acc: 0.9824 -- iter: 0704/1468
[A[ATraining Step: 989  | total loss: [1m[32m0.07789[0m[0m | time: 14.512s
[2K
| Adam | epoch: 022 | loss: 0.07789 - acc: 0.9779 -- iter: 0736/1468
[A[ATraining Step: 990  | total loss: [1m[32m0.07989[0m[0m | time: 15.164s
[2K
| Adam | epoch: 022 | loss: 0.07989 - acc: 0.9770 -- iter: 0768/1468
[A[ATraining Step: 991  | total loss: [1m[32m0.07567[0m[0m | time: 15.801s
[2K
| Adam | epoch: 022 | loss: 0.07567 - acc: 0.9793 -- iter: 0800/1468
[A[ATraining Step: 992  | total loss: [1m[32m0.09458[0m[0m | time: 16.418s
[2K
| Adam | epoch: 022 | loss: 0.09458 - acc: 0.9720 -- iter: 0832/1468
[A[ATraining Step: 993  | total loss: [1m[32m0.09641[0m[0m | time: 17.031s
[2K
| Adam | epoch: 022 | loss: 0.09641 - acc: 0.9686 -- iter: 0864/1468
[A[ATraining Step: 994  | total loss: [1m[32m0.09064[0m[0m | time: 17.681s
[2K
| Adam | epoch: 022 | loss: 0.09064 - acc: 0.9717 -- iter: 0896/1468
[A[ATraining Step: 995  | total loss: [1m[32m0.08447[0m[0m | time: 18.294s
[2K
| Adam | epoch: 022 | loss: 0.08447 - acc: 0.9745 -- iter: 0928/1468
[A[ATraining Step: 996  | total loss: [1m[32m0.08030[0m[0m | time: 18.893s
[2K
| Adam | epoch: 022 | loss: 0.08030 - acc: 0.9771 -- iter: 0960/1468
[A[ATraining Step: 997  | total loss: [1m[32m0.07838[0m[0m | time: 19.506s
[2K
| Adam | epoch: 022 | loss: 0.07838 - acc: 0.9763 -- iter: 0992/1468
[A[ATraining Step: 998  | total loss: [1m[32m0.07685[0m[0m | time: 20.128s
[2K
| Adam | epoch: 022 | loss: 0.07685 - acc: 0.9755 -- iter: 1024/1468
[A[ATraining Step: 999  | total loss: [1m[32m0.08037[0m[0m | time: 20.741s
[2K
| Adam | epoch: 022 | loss: 0.08037 - acc: 0.9717 -- iter: 1056/1468
[A[ATraining Step: 1000  | total loss: [1m[32m0.07928[0m[0m | time: 22.874s
[2K
| Adam | epoch: 022 | loss: 0.07928 - acc: 0.9714 | val_loss: 0.73275 - val_acc: 0.7625 -- iter: 1088/1468
--
Training Step: 1001  | total loss: [1m[32m0.07746[0m[0m | time: 23.489s
[2K
| Adam | epoch: 022 | loss: 0.07746 - acc: 0.9743 -- iter: 1120/1468
[A[ATraining Step: 1002  | total loss: [1m[32m0.08684[0m[0m | time: 24.107s
[2K
| Adam | epoch: 022 | loss: 0.08684 - acc: 0.9706 -- iter: 1152/1468
[A[ATraining Step: 1003  | total loss: [1m[32m0.08275[0m[0m | time: 24.752s
[2K
| Adam | epoch: 022 | loss: 0.08275 - acc: 0.9735 -- iter: 1184/1468
[A[ATraining Step: 1004  | total loss: [1m[32m0.08086[0m[0m | time: 25.365s
[2K
| Adam | epoch: 022 | loss: 0.08086 - acc: 0.9762 -- iter: 1216/1468
[A[ATraining Step: 1005  | total loss: [1m[32m0.08349[0m[0m | time: 25.975s
[2K
| Adam | epoch: 022 | loss: 0.08349 - acc: 0.9754 -- iter: 1248/1468
[A[ATraining Step: 1006  | total loss: [1m[32m0.08511[0m[0m | time: 26.599s
[2K
| Adam | epoch: 022 | loss: 0.08511 - acc: 0.9716 -- iter: 1280/1468
[A[ATraining Step: 1007  | total loss: [1m[32m0.08427[0m[0m | time: 27.210s
[2K
| Adam | epoch: 022 | loss: 0.08427 - acc: 0.9714 -- iter: 1312/1468
[A[ATraining Step: 1008  | total loss: [1m[32m0.07916[0m[0m | time: 27.830s
[2K
| Adam | epoch: 022 | loss: 0.07916 - acc: 0.9742 -- iter: 1344/1468
[A[ATraining Step: 1009  | total loss: [1m[32m0.08161[0m[0m | time: 28.448s
[2K
| Adam | epoch: 022 | loss: 0.08161 - acc: 0.9705 -- iter: 1376/1468
[A[ATraining Step: 1010  | total loss: [1m[32m0.09162[0m[0m | time: 29.062s
[2K
| Adam | epoch: 022 | loss: 0.09162 - acc: 0.9672 -- iter: 1408/1468
[A[ATraining Step: 1011  | total loss: [1m[32m0.08553[0m[0m | time: 29.685s
[2K
| Adam | epoch: 022 | loss: 0.08553 - acc: 0.9705 -- iter: 1440/1468
[A[ATraining Step: 1012  | total loss: [1m[32m0.09593[0m[0m | time: 31.759s
[2K
| Adam | epoch: 022 | loss: 0.09593 - acc: 0.9703 | val_loss: 0.67716 - val_acc: 0.7582 -- iter: 1468/1468
--
Training Step: 1013  | total loss: [1m[32m0.09050[0m[0m | time: 0.623s
[2K
| Adam | epoch: 023 | loss: 0.09050 - acc: 0.9733 -- iter: 0032/1468
[A[ATraining Step: 1014  | total loss: [1m[32m0.09645[0m[0m | time: 1.249s
[2K
| Adam | epoch: 023 | loss: 0.09645 - acc: 0.9697 -- iter: 0064/1468
[A[ATraining Step: 1015  | total loss: [1m[32m0.08977[0m[0m | time: 1.860s
[2K
| Adam | epoch: 023 | loss: 0.08977 - acc: 0.9728 -- iter: 0096/1468
[A[ATraining Step: 1016  | total loss: [1m[32m0.08312[0m[0m | time: 2.531s
[2K
| Adam | epoch: 023 | loss: 0.08312 - acc: 0.9755 -- iter: 0128/1468
[A[ATraining Step: 1017  | total loss: [1m[32m0.08081[0m[0m | time: 3.230s
[2K
| Adam | epoch: 023 | loss: 0.08081 - acc: 0.9779 -- iter: 0160/1468
[A[ATraining Step: 1018  | total loss: [1m[32m0.07853[0m[0m | time: 3.842s
[2K
| Adam | epoch: 023 | loss: 0.07853 - acc: 0.9801 -- iter: 0192/1468
[A[ATraining Step: 1019  | total loss: [1m[32m0.07491[0m[0m | time: 4.459s
[2K
| Adam | epoch: 023 | loss: 0.07491 - acc: 0.9821 -- iter: 0224/1468
[A[ATraining Step: 1020  | total loss: [1m[32m0.07095[0m[0m | time: 5.115s
[2K
| Adam | epoch: 023 | loss: 0.07095 - acc: 0.9839 -- iter: 0256/1468
[A[ATraining Step: 1021  | total loss: [1m[32m0.07203[0m[0m | time: 5.722s
[2K
| Adam | epoch: 023 | loss: 0.07203 - acc: 0.9793 -- iter: 0288/1468
[A[ATraining Step: 1022  | total loss: [1m[32m0.08057[0m[0m | time: 6.350s
[2K
| Adam | epoch: 023 | loss: 0.08057 - acc: 0.9751 -- iter: 0320/1468
[A[ATraining Step: 1023  | total loss: [1m[32m0.07789[0m[0m | time: 7.004s
[2K
| Adam | epoch: 023 | loss: 0.07789 - acc: 0.9776 -- iter: 0352/1468
[A[ATraining Step: 1024  | total loss: [1m[32m0.07547[0m[0m | time: 7.622s
[2K
| Adam | epoch: 023 | loss: 0.07547 - acc: 0.9798 -- iter: 0384/1468
[A[ATraining Step: 1025  | total loss: [1m[32m0.07045[0m[0m | time: 8.253s
[2K
| Adam | epoch: 023 | loss: 0.07045 - acc: 0.9818 -- iter: 0416/1468
[A[ATraining Step: 1026  | total loss: [1m[32m0.06588[0m[0m | time: 8.937s
[2K
| Adam | epoch: 023 | loss: 0.06588 - acc: 0.9837 -- iter: 0448/1468
[A[ATraining Step: 1027  | total loss: [1m[32m0.06354[0m[0m | time: 9.569s
[2K
| Adam | epoch: 023 | loss: 0.06354 - acc: 0.9853 -- iter: 0480/1468
[A[ATraining Step: 1028  | total loss: [1m[32m0.05980[0m[0m | time: 10.198s
[2K
| Adam | epoch: 023 | loss: 0.05980 - acc: 0.9868 -- iter: 0512/1468
[A[ATraining Step: 1029  | total loss: [1m[32m0.05783[0m[0m | time: 10.851s
[2K
| Adam | epoch: 023 | loss: 0.05783 - acc: 0.9881 -- iter: 0544/1468
[A[ATraining Step: 1030  | total loss: [1m[32m0.05479[0m[0m | time: 11.526s
[2K
| Adam | epoch: 023 | loss: 0.05479 - acc: 0.9893 -- iter: 0576/1468
[A[ATraining Step: 1031  | total loss: [1m[32m0.05211[0m[0m | time: 12.136s
[2K
| Adam | epoch: 023 | loss: 0.05211 - acc: 0.9904 -- iter: 0608/1468
[A[ATraining Step: 1032  | total loss: [1m[32m0.06705[0m[0m | time: 12.765s
[2K
| Adam | epoch: 023 | loss: 0.06705 - acc: 0.9882 -- iter: 0640/1468
[A[ATraining Step: 1033  | total loss: [1m[32m0.06656[0m[0m | time: 13.346s
[2K
| Adam | epoch: 023 | loss: 0.06656 - acc: 0.9862 -- iter: 0672/1468
[A[ATraining Step: 1034  | total loss: [1m[32m0.06325[0m[0m | time: 13.922s
[2K
| Adam | epoch: 023 | loss: 0.06325 - acc: 0.9876 -- iter: 0704/1468
[A[ATraining Step: 1035  | total loss: [1m[32m0.05979[0m[0m | time: 14.536s
[2K
| Adam | epoch: 023 | loss: 0.05979 - acc: 0.9889 -- iter: 0736/1468
[A[ATraining Step: 1036  | total loss: [1m[32m0.06163[0m[0m | time: 15.192s
[2K
| Adam | epoch: 023 | loss: 0.06163 - acc: 0.9868 -- iter: 0768/1468
[A[ATraining Step: 1037  | total loss: [1m[32m0.05897[0m[0m | time: 15.808s
[2K
| Adam | epoch: 023 | loss: 0.05897 - acc: 0.9882 -- iter: 0800/1468
[A[ATraining Step: 1038  | total loss: [1m[32m0.06266[0m[0m | time: 16.430s
[2K
| Adam | epoch: 023 | loss: 0.06266 - acc: 0.9862 -- iter: 0832/1468
[A[ATraining Step: 1039  | total loss: [1m[32m0.06344[0m[0m | time: 17.053s
[2K
| Adam | epoch: 023 | loss: 0.06344 - acc: 0.9845 -- iter: 0864/1468
[A[ATraining Step: 1040  | total loss: [1m[32m0.06201[0m[0m | time: 17.667s
[2K
| Adam | epoch: 023 | loss: 0.06201 - acc: 0.9829 -- iter: 0896/1468
[A[ATraining Step: 1041  | total loss: [1m[32m0.06507[0m[0m | time: 18.281s
[2K
| Adam | epoch: 023 | loss: 0.06507 - acc: 0.9815 -- iter: 0928/1468
[A[ATraining Step: 1042  | total loss: [1m[32m0.06308[0m[0m | time: 18.902s
[2K
| Adam | epoch: 023 | loss: 0.06308 - acc: 0.9833 -- iter: 0960/1468
[A[ATraining Step: 1043  | total loss: [1m[32m0.06296[0m[0m | time: 19.556s
[2K
| Adam | epoch: 023 | loss: 0.06296 - acc: 0.9819 -- iter: 0992/1468
[A[ATraining Step: 1044  | total loss: [1m[32m0.06355[0m[0m | time: 20.167s
[2K
| Adam | epoch: 023 | loss: 0.06355 - acc: 0.9806 -- iter: 1024/1468
[A[ATraining Step: 1045  | total loss: [1m[32m0.07796[0m[0m | time: 20.836s
[2K
| Adam | epoch: 023 | loss: 0.07796 - acc: 0.9794 -- iter: 1056/1468
[A[ATraining Step: 1046  | total loss: [1m[32m0.07783[0m[0m | time: 21.448s
[2K
| Adam | epoch: 023 | loss: 0.07783 - acc: 0.9814 -- iter: 1088/1468
[A[ATraining Step: 1047  | total loss: [1m[32m0.08542[0m[0m | time: 22.075s
[2K
| Adam | epoch: 023 | loss: 0.08542 - acc: 0.9802 -- iter: 1120/1468
[A[ATraining Step: 1048  | total loss: [1m[32m0.08260[0m[0m | time: 22.701s
[2K
| Adam | epoch: 023 | loss: 0.08260 - acc: 0.9790 -- iter: 1152/1468
[A[ATraining Step: 1049  | total loss: [1m[32m0.08738[0m[0m | time: 23.322s
[2K
| Adam | epoch: 023 | loss: 0.08738 - acc: 0.9780 -- iter: 1184/1468
[A[ATraining Step: 1050  | total loss: [1m[32m0.07984[0m[0m | time: 23.960s
[2K
| Adam | epoch: 023 | loss: 0.07984 - acc: 0.9802 -- iter: 1216/1468
[A[ATraining Step: 1051  | total loss: [1m[32m0.07352[0m[0m | time: 24.574s
[2K
| Adam | epoch: 023 | loss: 0.07352 - acc: 0.9822 -- iter: 1248/1468
[A[ATraining Step: 1052  | total loss: [1m[32m0.08939[0m[0m | time: 25.216s
[2K
| Adam | epoch: 023 | loss: 0.08939 - acc: 0.9777 -- iter: 1280/1468
[A[ATraining Step: 1053  | total loss: [1m[32m0.08781[0m[0m | time: 25.853s
[2K
| Adam | epoch: 023 | loss: 0.08781 - acc: 0.9799 -- iter: 1312/1468
[A[ATraining Step: 1054  | total loss: [1m[32m0.09356[0m[0m | time: 26.462s
[2K
| Adam | epoch: 023 | loss: 0.09356 - acc: 0.9757 -- iter: 1344/1468
[A[ATraining Step: 1055  | total loss: [1m[32m0.08663[0m[0m | time: 27.082s
[2K
| Adam | epoch: 023 | loss: 0.08663 - acc: 0.9781 -- iter: 1376/1468
[A[ATraining Step: 1056  | total loss: [1m[32m0.08194[0m[0m | time: 27.706s
[2K
| Adam | epoch: 023 | loss: 0.08194 - acc: 0.9803 -- iter: 1408/1468
[A[ATraining Step: 1057  | total loss: [1m[32m0.07741[0m[0m | time: 28.335s
[2K
| Adam | epoch: 023 | loss: 0.07741 - acc: 0.9823 -- iter: 1440/1468
[A[ATraining Step: 1058  | total loss: [1m[32m0.07143[0m[0m | time: 30.437s
[2K
| Adam | epoch: 023 | loss: 0.07143 - acc: 0.9841 | val_loss: 0.57357 - val_acc: 0.8039 -- iter: 1468/1468
--
Training Step: 1059  | total loss: [1m[32m0.06625[0m[0m | time: 0.654s
[2K
| Adam | epoch: 024 | loss: 0.06625 - acc: 0.9857 -- iter: 0032/1468
[A[ATraining Step: 1060  | total loss: [1m[32m0.06170[0m[0m | time: 1.328s
[2K
| Adam | epoch: 024 | loss: 0.06170 - acc: 0.9871 -- iter: 0064/1468
[A[ATraining Step: 1061  | total loss: [1m[32m0.05983[0m[0m | time: 1.957s
[2K
| Adam | epoch: 024 | loss: 0.05983 - acc: 0.9884 -- iter: 0096/1468
[A[ATraining Step: 1062  | total loss: [1m[32m0.06477[0m[0m | time: 2.588s
[2K
| Adam | epoch: 024 | loss: 0.06477 - acc: 0.9864 -- iter: 0128/1468
[A[ATraining Step: 1063  | total loss: [1m[32m0.06341[0m[0m | time: 3.213s
[2K
| Adam | epoch: 024 | loss: 0.06341 - acc: 0.9846 -- iter: 0160/1468
[A[ATraining Step: 1064  | total loss: [1m[32m0.06041[0m[0m | time: 3.871s
[2K
| Adam | epoch: 024 | loss: 0.06041 - acc: 0.9862 -- iter: 0192/1468
[A[ATraining Step: 1065  | total loss: [1m[32m0.06019[0m[0m | time: 4.492s
[2K
| Adam | epoch: 024 | loss: 0.06019 - acc: 0.9844 -- iter: 0224/1468
[A[ATraining Step: 1066  | total loss: [1m[32m0.05619[0m[0m | time: 5.107s
[2K
| Adam | epoch: 024 | loss: 0.05619 - acc: 0.9860 -- iter: 0256/1468
[A[ATraining Step: 1067  | total loss: [1m[32m0.05306[0m[0m | time: 5.715s
[2K
| Adam | epoch: 024 | loss: 0.05306 - acc: 0.9874 -- iter: 0288/1468
[A[ATraining Step: 1068  | total loss: [1m[32m0.05264[0m[0m | time: 6.359s
[2K
| Adam | epoch: 024 | loss: 0.05264 - acc: 0.9887 -- iter: 0320/1468
[A[ATraining Step: 1069  | total loss: [1m[32m0.05348[0m[0m | time: 6.974s
[2K
| Adam | epoch: 024 | loss: 0.05348 - acc: 0.9867 -- iter: 0352/1468
[A[ATraining Step: 1070  | total loss: [1m[32m0.05726[0m[0m | time: 7.615s
[2K
| Adam | epoch: 024 | loss: 0.05726 - acc: 0.9849 -- iter: 0384/1468
[A[ATraining Step: 1071  | total loss: [1m[32m0.05575[0m[0m | time: 8.227s
[2K
| Adam | epoch: 024 | loss: 0.05575 - acc: 0.9864 -- iter: 0416/1468
[A[ATraining Step: 1072  | total loss: [1m[32m0.05844[0m[0m | time: 8.875s
[2K
| Adam | epoch: 024 | loss: 0.05844 - acc: 0.9846 -- iter: 0448/1468
[A[ATraining Step: 1073  | total loss: [1m[32m0.05871[0m[0m | time: 9.512s
[2K
| Adam | epoch: 024 | loss: 0.05871 - acc: 0.9830 -- iter: 0480/1468
[A[ATraining Step: 1074  | total loss: [1m[32m0.06021[0m[0m | time: 10.160s
[2K
| Adam | epoch: 024 | loss: 0.06021 - acc: 0.9816 -- iter: 0512/1468
[A[ATraining Step: 1075  | total loss: [1m[32m0.05558[0m[0m | time: 10.803s
[2K
| Adam | epoch: 024 | loss: 0.05558 - acc: 0.9834 -- iter: 0544/1468
[A[ATraining Step: 1076  | total loss: [1m[32m0.05163[0m[0m | time: 11.427s
[2K
| Adam | epoch: 024 | loss: 0.05163 - acc: 0.9851 -- iter: 0576/1468
[A[ATraining Step: 1077  | total loss: [1m[32m0.04857[0m[0m | time: 12.099s
[2K
| Adam | epoch: 024 | loss: 0.04857 - acc: 0.9866 -- iter: 0608/1468
[A[ATraining Step: 1078  | total loss: [1m[32m0.04777[0m[0m | time: 12.753s
[2K
| Adam | epoch: 024 | loss: 0.04777 - acc: 0.9879 -- iter: 0640/1468
[A[ATraining Step: 1079  | total loss: [1m[32m0.04616[0m[0m | time: 13.405s
[2K
| Adam | epoch: 024 | loss: 0.04616 - acc: 0.9891 -- iter: 0672/1468
[A[ATraining Step: 1080  | total loss: [1m[32m0.04955[0m[0m | time: 13.972s
[2K
| Adam | epoch: 024 | loss: 0.04955 - acc: 0.9840 -- iter: 0704/1468
[A[ATraining Step: 1081  | total loss: [1m[32m0.04786[0m[0m | time: 14.528s
[2K
| Adam | epoch: 024 | loss: 0.04786 - acc: 0.9856 -- iter: 0736/1468
[A[ATraining Step: 1082  | total loss: [1m[32m0.04547[0m[0m | time: 15.166s
[2K
| Adam | epoch: 024 | loss: 0.04547 - acc: 0.9870 -- iter: 0768/1468
[A[ATraining Step: 1083  | total loss: [1m[32m0.05013[0m[0m | time: 15.817s
[2K
| Adam | epoch: 024 | loss: 0.05013 - acc: 0.9852 -- iter: 0800/1468
[A[ATraining Step: 1084  | total loss: [1m[32m0.04754[0m[0m | time: 16.433s
[2K
| Adam | epoch: 024 | loss: 0.04754 - acc: 0.9867 -- iter: 0832/1468
[A[ATraining Step: 1085  | total loss: [1m[32m0.04902[0m[0m | time: 17.062s
[2K
| Adam | epoch: 024 | loss: 0.04902 - acc: 0.9849 -- iter: 0864/1468
[A[ATraining Step: 1086  | total loss: [1m[32m0.06625[0m[0m | time: 17.684s
[2K
| Adam | epoch: 024 | loss: 0.06625 - acc: 0.9801 -- iter: 0896/1468
[A[ATraining Step: 1087  | total loss: [1m[32m0.06667[0m[0m | time: 18.302s
[2K
| Adam | epoch: 024 | loss: 0.06667 - acc: 0.9790 -- iter: 0928/1468
[A[ATraining Step: 1088  | total loss: [1m[32m0.06219[0m[0m | time: 18.948s
[2K
| Adam | epoch: 024 | loss: 0.06219 - acc: 0.9811 -- iter: 0960/1468
[A[ATraining Step: 1089  | total loss: [1m[32m0.05792[0m[0m | time: 19.608s
[2K
| Adam | epoch: 024 | loss: 0.05792 - acc: 0.9830 -- iter: 0992/1468
[A[ATraining Step: 1090  | total loss: [1m[32m0.05387[0m[0m | time: 20.231s
[2K
| Adam | epoch: 024 | loss: 0.05387 - acc: 0.9847 -- iter: 1024/1468
[A[ATraining Step: 1091  | total loss: [1m[32m0.05368[0m[0m | time: 20.887s
[2K
| Adam | epoch: 024 | loss: 0.05368 - acc: 0.9862 -- iter: 1056/1468
[A[ATraining Step: 1092  | total loss: [1m[32m0.05460[0m[0m | time: 21.565s
[2K
| Adam | epoch: 024 | loss: 0.05460 - acc: 0.9876 -- iter: 1088/1468
[A[ATraining Step: 1093  | total loss: [1m[32m0.05271[0m[0m | time: 22.206s
[2K
| Adam | epoch: 024 | loss: 0.05271 - acc: 0.9888 -- iter: 1120/1468
[A[ATraining Step: 1094  | total loss: [1m[32m0.05025[0m[0m | time: 22.819s
[2K
| Adam | epoch: 024 | loss: 0.05025 - acc: 0.9900 -- iter: 1152/1468
[A[ATraining Step: 1095  | total loss: [1m[32m0.05098[0m[0m | time: 23.451s
[2K
| Adam | epoch: 024 | loss: 0.05098 - acc: 0.9878 -- iter: 1184/1468
[A[ATraining Step: 1096  | total loss: [1m[32m0.05928[0m[0m | time: 24.074s
[2K
| Adam | epoch: 024 | loss: 0.05928 - acc: 0.9859 -- iter: 1216/1468
[A[ATraining Step: 1097  | total loss: [1m[32m0.07920[0m[0m | time: 24.698s
[2K
| Adam | epoch: 024 | loss: 0.07920 - acc: 0.9780 -- iter: 1248/1468
[A[ATraining Step: 1098  | total loss: [1m[32m0.07329[0m[0m | time: 25.315s
[2K
| Adam | epoch: 024 | loss: 0.07329 - acc: 0.9802 -- iter: 1280/1468
[A[ATraining Step: 1099  | total loss: [1m[32m0.07068[0m[0m | time: 25.951s
[2K
| Adam | epoch: 024 | loss: 0.07068 - acc: 0.9790 -- iter: 1312/1468
[A[ATraining Step: 1100  | total loss: [1m[32m0.06620[0m[0m | time: 26.584s
[2K
| Adam | epoch: 024 | loss: 0.06620 - acc: 0.9811 -- iter: 1344/1468
[A[ATraining Step: 1101  | total loss: [1m[32m0.06484[0m[0m | time: 27.237s
[2K
| Adam | epoch: 024 | loss: 0.06484 - acc: 0.9799 -- iter: 1376/1468
[A[ATraining Step: 1102  | total loss: [1m[32m0.06196[0m[0m | time: 27.860s
[2K
| Adam | epoch: 024 | loss: 0.06196 - acc: 0.9819 -- iter: 1408/1468
[A[ATraining Step: 1103  | total loss: [1m[32m0.06177[0m[0m | time: 28.476s
[2K
| Adam | epoch: 024 | loss: 0.06177 - acc: 0.9806 -- iter: 1440/1468
[A[ATraining Step: 1104  | total loss: [1m[32m0.05646[0m[0m | time: 30.602s
[2K
| Adam | epoch: 024 | loss: 0.05646 - acc: 0.9825 | val_loss: 0.63004 - val_acc: 0.7952 -- iter: 1468/1468
--
Training Step: 1105  | total loss: [1m[32m0.05291[0m[0m | time: 0.658s
[2K
| Adam | epoch: 025 | loss: 0.05291 - acc: 0.9843 -- iter: 0032/1468
[A[ATraining Step: 1106  | total loss: [1m[32m0.04948[0m[0m | time: 1.306s
[2K
| Adam | epoch: 025 | loss: 0.04948 - acc: 0.9858 -- iter: 0064/1468
[A[ATraining Step: 1107  | total loss: [1m[32m0.04675[0m[0m | time: 1.923s
[2K
| Adam | epoch: 025 | loss: 0.04675 - acc: 0.9873 -- iter: 0096/1468
[A[ATraining Step: 1108  | total loss: [1m[32m0.04878[0m[0m | time: 2.536s
[2K
| Adam | epoch: 025 | loss: 0.04878 - acc: 0.9885 -- iter: 0128/1468
[A[ATraining Step: 1109  | total loss: [1m[32m0.04605[0m[0m | time: 3.165s
[2K
| Adam | epoch: 025 | loss: 0.04605 - acc: 0.9897 -- iter: 0160/1468
[A[ATraining Step: 1110  | total loss: [1m[32m0.04255[0m[0m | time: 3.839s
[2K
| Adam | epoch: 025 | loss: 0.04255 - acc: 0.9907 -- iter: 0192/1468
[A[ATraining Step: 1111  | total loss: [1m[32m0.04023[0m[0m | time: 4.498s
[2K
| Adam | epoch: 025 | loss: 0.04023 - acc: 0.9916 -- iter: 0224/1468
[A[ATraining Step: 1112  | total loss: [1m[32m0.03774[0m[0m | time: 5.155s
[2K
| Adam | epoch: 025 | loss: 0.03774 - acc: 0.9925 -- iter: 0256/1468
[A[ATraining Step: 1113  | total loss: [1m[32m0.03847[0m[0m | time: 5.788s
[2K
| Adam | epoch: 025 | loss: 0.03847 - acc: 0.9901 -- iter: 0288/1468
[A[ATraining Step: 1114  | total loss: [1m[32m0.03826[0m[0m | time: 6.409s
[2K
| Adam | epoch: 025 | loss: 0.03826 - acc: 0.9911 -- iter: 0320/1468
[A[ATraining Step: 1115  | total loss: [1m[32m0.03951[0m[0m | time: 7.033s
[2K
| Adam | epoch: 025 | loss: 0.03951 - acc: 0.9889 -- iter: 0352/1468
[A[ATraining Step: 1116  | total loss: [1m[32m0.03699[0m[0m | time: 7.678s
[2K
| Adam | epoch: 025 | loss: 0.03699 - acc: 0.9900 -- iter: 0384/1468
[A[ATraining Step: 1117  | total loss: [1m[32m0.04169[0m[0m | time: 8.333s
[2K
| Adam | epoch: 025 | loss: 0.04169 - acc: 0.9879 -- iter: 0416/1468
[A[ATraining Step: 1118  | total loss: [1m[32m0.03996[0m[0m | time: 8.978s
[2K
| Adam | epoch: 025 | loss: 0.03996 - acc: 0.9891 -- iter: 0448/1468
[A[ATraining Step: 1119  | total loss: [1m[32m0.03722[0m[0m | time: 9.595s
[2K
| Adam | epoch: 025 | loss: 0.03722 - acc: 0.9902 -- iter: 0480/1468
[A[ATraining Step: 1120  | total loss: [1m[32m0.04627[0m[0m | time: 10.230s
[2K
| Adam | epoch: 025 | loss: 0.04627 - acc: 0.9880 -- iter: 0512/1468
[A[ATraining Step: 1121  | total loss: [1m[32m0.04341[0m[0m | time: 10.870s
[2K
| Adam | epoch: 025 | loss: 0.04341 - acc: 0.9892 -- iter: 0544/1468
[A[ATraining Step: 1122  | total loss: [1m[32m0.04228[0m[0m | time: 11.476s
[2K
| Adam | epoch: 025 | loss: 0.04228 - acc: 0.9903 -- iter: 0576/1468
[A[ATraining Step: 1123  | total loss: [1m[32m0.04133[0m[0m | time: 12.116s
[2K
| Adam | epoch: 025 | loss: 0.04133 - acc: 0.9913 -- iter: 0608/1468
[A[ATraining Step: 1124  | total loss: [1m[32m0.03779[0m[0m | time: 12.747s
[2K
| Adam | epoch: 025 | loss: 0.03779 - acc: 0.9921 -- iter: 0640/1468
[A[ATraining Step: 1125  | total loss: [1m[32m0.03757[0m[0m | time: 13.374s
[2K
| Adam | epoch: 025 | loss: 0.03757 - acc: 0.9929 -- iter: 0672/1468
[A[ATraining Step: 1126  | total loss: [1m[32m0.05582[0m[0m | time: 14.009s
[2K
| Adam | epoch: 025 | loss: 0.05582 - acc: 0.9843 -- iter: 0704/1468
[A[ATraining Step: 1127  | total loss: [1m[32m0.05548[0m[0m | time: 14.574s
[2K
| Adam | epoch: 025 | loss: 0.05548 - acc: 0.9827 -- iter: 0736/1468
[A[ATraining Step: 1128  | total loss: [1m[32m0.05283[0m[0m | time: 15.128s
[2K
| Adam | epoch: 025 | loss: 0.05283 - acc: 0.9844 -- iter: 0768/1468
[A[ATraining Step: 1129  | total loss: [1m[32m0.04995[0m[0m | time: 15.771s
[2K
| Adam | epoch: 025 | loss: 0.04995 - acc: 0.9860 -- iter: 0800/1468
[A[ATraining Step: 1130  | total loss: [1m[32m0.04812[0m[0m | time: 16.402s
[2K
| Adam | epoch: 025 | loss: 0.04812 - acc: 0.9874 -- iter: 0832/1468
[A[ATraining Step: 1131  | total loss: [1m[32m0.06080[0m[0m | time: 17.030s
[2K
| Adam | epoch: 025 | loss: 0.06080 - acc: 0.9855 -- iter: 0864/1468
[A[ATraining Step: 1132  | total loss: [1m[32m0.05896[0m[0m | time: 17.690s
[2K
| Adam | epoch: 025 | loss: 0.05896 - acc: 0.9870 -- iter: 0896/1468
[A[ATraining Step: 1133  | total loss: [1m[32m0.05841[0m[0m | time: 18.375s
[2K
| Adam | epoch: 025 | loss: 0.05841 - acc: 0.9883 -- iter: 0928/1468
[A[ATraining Step: 1134  | total loss: [1m[32m0.05436[0m[0m | time: 18.996s
[2K
| Adam | epoch: 025 | loss: 0.05436 - acc: 0.9895 -- iter: 0960/1468
[A[ATraining Step: 1135  | total loss: [1m[32m0.05200[0m[0m | time: 19.639s
[2K
| Adam | epoch: 025 | loss: 0.05200 - acc: 0.9905 -- iter: 0992/1468
[A[ATraining Step: 1136  | total loss: [1m[32m0.04841[0m[0m | time: 20.266s
[2K
| Adam | epoch: 025 | loss: 0.04841 - acc: 0.9915 -- iter: 1024/1468
[A[ATraining Step: 1137  | total loss: [1m[32m0.04940[0m[0m | time: 20.887s
[2K
| Adam | epoch: 025 | loss: 0.04940 - acc: 0.9892 -- iter: 1056/1468
[A[ATraining Step: 1138  | total loss: [1m[32m0.04985[0m[0m | time: 21.518s
[2K
| Adam | epoch: 025 | loss: 0.04985 - acc: 0.9871 -- iter: 1088/1468
[A[ATraining Step: 1139  | total loss: [1m[32m0.05155[0m[0m | time: 22.154s
[2K
| Adam | epoch: 025 | loss: 0.05155 - acc: 0.9884 -- iter: 1120/1468
[A[ATraining Step: 1140  | total loss: [1m[32m0.05067[0m[0m | time: 22.787s
[2K
| Adam | epoch: 025 | loss: 0.05067 - acc: 0.9896 -- iter: 1152/1468
[A[ATraining Step: 1141  | total loss: [1m[32m0.04703[0m[0m | time: 23.403s
[2K
| Adam | epoch: 025 | loss: 0.04703 - acc: 0.9906 -- iter: 1184/1468
[A[ATraining Step: 1142  | total loss: [1m[32m0.04328[0m[0m | time: 24.073s
[2K
| Adam | epoch: 025 | loss: 0.04328 - acc: 0.9916 -- iter: 1216/1468
[A[ATraining Step: 1143  | total loss: [1m[32m0.06863[0m[0m | time: 24.713s
[2K
| Adam | epoch: 025 | loss: 0.06863 - acc: 0.9830 -- iter: 1248/1468
[A[ATraining Step: 1144  | total loss: [1m[32m0.07133[0m[0m | time: 25.356s
[2K
| Adam | epoch: 025 | loss: 0.07133 - acc: 0.9816 -- iter: 1280/1468
[A[ATraining Step: 1145  | total loss: [1m[32m0.06950[0m[0m | time: 25.996s
[2K
| Adam | epoch: 025 | loss: 0.06950 - acc: 0.9803 -- iter: 1312/1468
[A[ATraining Step: 1146  | total loss: [1m[32m0.06779[0m[0m | time: 26.695s
[2K
| Adam | epoch: 025 | loss: 0.06779 - acc: 0.9792 -- iter: 1344/1468
[A[ATraining Step: 1147  | total loss: [1m[32m0.06177[0m[0m | time: 27.318s
[2K
| Adam | epoch: 025 | loss: 0.06177 - acc: 0.9812 -- iter: 1376/1468
[A[ATraining Step: 1148  | total loss: [1m[32m0.05994[0m[0m | time: 27.953s
[2K
| Adam | epoch: 025 | loss: 0.05994 - acc: 0.9831 -- iter: 1408/1468
[A[ATraining Step: 1149  | total loss: [1m[32m0.06178[0m[0m | time: 28.600s
[2K
| Adam | epoch: 025 | loss: 0.06178 - acc: 0.9817 -- iter: 1440/1468
[A[ATraining Step: 1150  | total loss: [1m[32m0.06061[0m[0m | time: 30.738s
[2K
| Adam | epoch: 025 | loss: 0.06061 - acc: 0.9835 | val_loss: 0.57535 - val_acc: 0.8039 -- iter: 1468/1468
--
Training Step: 1151  | total loss: [1m[32m0.05534[0m[0m | time: 0.622s
[2K
| Adam | epoch: 026 | loss: 0.05534 - acc: 0.9852 -- iter: 0032/1468
[A[ATraining Step: 1152  | total loss: [1m[32m0.06370[0m[0m | time: 1.249s
[2K
| Adam | epoch: 026 | loss: 0.06370 - acc: 0.9804 -- iter: 0064/1468
[A[ATraining Step: 1153  | total loss: [1m[32m0.05873[0m[0m | time: 1.890s
[2K
| Adam | epoch: 026 | loss: 0.05873 - acc: 0.9824 -- iter: 0096/1468
[A[ATraining Step: 1154  | total loss: [1m[32m0.05870[0m[0m | time: 2.527s
[2K
| Adam | epoch: 026 | loss: 0.05870 - acc: 0.9810 -- iter: 0128/1468
[A[ATraining Step: 1155  | total loss: [1m[32m0.05865[0m[0m | time: 3.149s
[2K
| Adam | epoch: 026 | loss: 0.05865 - acc: 0.9829 -- iter: 0160/1468
[A[ATraining Step: 1156  | total loss: [1m[32m0.05516[0m[0m | time: 3.765s
[2K
| Adam | epoch: 026 | loss: 0.05516 - acc: 0.9846 -- iter: 0192/1468
[A[ATraining Step: 1157  | total loss: [1m[32m0.05137[0m[0m | time: 4.417s
[2K
| Adam | epoch: 026 | loss: 0.05137 - acc: 0.9861 -- iter: 0224/1468
[A[ATraining Step: 1158  | total loss: [1m[32m0.05359[0m[0m | time: 5.085s
[2K
| Adam | epoch: 026 | loss: 0.05359 - acc: 0.9844 -- iter: 0256/1468
[A[ATraining Step: 1159  | total loss: [1m[32m0.05648[0m[0m | time: 5.714s
[2K
| Adam | epoch: 026 | loss: 0.05648 - acc: 0.9828 -- iter: 0288/1468
[A[ATraining Step: 1160  | total loss: [1m[32m0.05939[0m[0m | time: 6.369s
[2K
| Adam | epoch: 026 | loss: 0.05939 - acc: 0.9814 -- iter: 0320/1468
[A[ATraining Step: 1161  | total loss: [1m[32m0.05572[0m[0m | time: 7.018s
[2K
| Adam | epoch: 026 | loss: 0.05572 - acc: 0.9833 -- iter: 0352/1468
[A[ATraining Step: 1162  | total loss: [1m[32m0.05310[0m[0m | time: 7.677s
[2K
| Adam | epoch: 026 | loss: 0.05310 - acc: 0.9850 -- iter: 0384/1468
[A[ATraining Step: 1163  | total loss: [1m[32m0.04906[0m[0m | time: 8.307s
[2K
| Adam | epoch: 026 | loss: 0.04906 - acc: 0.9865 -- iter: 0416/1468
[A[ATraining Step: 1164  | total loss: [1m[32m0.05971[0m[0m | time: 8.932s
[2K
| Adam | epoch: 026 | loss: 0.05971 - acc: 0.9816 -- iter: 0448/1468
[A[ATraining Step: 1165  | total loss: [1m[32m0.05896[0m[0m | time: 9.562s
[2K
| Adam | epoch: 026 | loss: 0.05896 - acc: 0.9803 -- iter: 0480/1468
[A[ATraining Step: 1166  | total loss: [1m[32m0.05676[0m[0m | time: 10.202s
[2K
| Adam | epoch: 026 | loss: 0.05676 - acc: 0.9823 -- iter: 0512/1468
[A[ATraining Step: 1167  | total loss: [1m[32m0.05207[0m[0m | time: 10.864s
[2K
| Adam | epoch: 026 | loss: 0.05207 - acc: 0.9840 -- iter: 0544/1468
[A[ATraining Step: 1168  | total loss: [1m[32m0.04837[0m[0m | time: 11.528s
[2K
| Adam | epoch: 026 | loss: 0.04837 - acc: 0.9856 -- iter: 0576/1468
[A[ATraining Step: 1169  | total loss: [1m[32m0.04429[0m[0m | time: 12.162s
[2K
| Adam | epoch: 026 | loss: 0.04429 - acc: 0.9871 -- iter: 0608/1468
[A[ATraining Step: 1170  | total loss: [1m[32m0.04066[0m[0m | time: 12.791s
[2K
| Adam | epoch: 026 | loss: 0.04066 - acc: 0.9884 -- iter: 0640/1468
[A[ATraining Step: 1171  | total loss: [1m[32m0.03743[0m[0m | time: 13.449s
[2K
| Adam | epoch: 026 | loss: 0.03743 - acc: 0.9895 -- iter: 0672/1468
[A[ATraining Step: 1172  | total loss: [1m[32m0.03659[0m[0m | time: 14.102s
[2K
| Adam | epoch: 026 | loss: 0.03659 - acc: 0.9906 -- iter: 0704/1468
[A[ATraining Step: 1173  | total loss: [1m[32m0.03412[0m[0m | time: 14.742s
[2K
| Adam | epoch: 026 | loss: 0.03412 - acc: 0.9915 -- iter: 0736/1468
[A[ATraining Step: 1174  | total loss: [1m[32m0.03194[0m[0m | time: 15.312s
[2K
| Adam | epoch: 026 | loss: 0.03194 - acc: 0.9924 -- iter: 0768/1468
[A[ATraining Step: 1175  | total loss: [1m[32m0.02945[0m[0m | time: 15.888s
[2K
| Adam | epoch: 026 | loss: 0.02945 - acc: 0.9931 -- iter: 0800/1468
[A[ATraining Step: 1176  | total loss: [1m[32m0.02719[0m[0m | time: 16.547s
[2K
| Adam | epoch: 026 | loss: 0.02719 - acc: 0.9938 -- iter: 0832/1468
[A[ATraining Step: 1177  | total loss: [1m[32m0.02506[0m[0m | time: 17.166s
[2K
| Adam | epoch: 026 | loss: 0.02506 - acc: 0.9944 -- iter: 0864/1468
[A[ATraining Step: 1178  | total loss: [1m[32m0.02384[0m[0m | time: 17.788s
[2K
| Adam | epoch: 026 | loss: 0.02384 - acc: 0.9950 -- iter: 0896/1468
[A[ATraining Step: 1179  | total loss: [1m[32m0.02384[0m[0m | time: 18.402s
[2K
| Adam | epoch: 026 | loss: 0.02384 - acc: 0.9955 -- iter: 0928/1468
[A[ATraining Step: 1180  | total loss: [1m[32m0.02449[0m[0m | time: 19.051s
[2K
| Adam | epoch: 026 | loss: 0.02449 - acc: 0.9959 -- iter: 0960/1468
[A[ATraining Step: 1181  | total loss: [1m[32m0.02327[0m[0m | time: 19.716s
[2K
| Adam | epoch: 026 | loss: 0.02327 - acc: 0.9963 -- iter: 0992/1468
[A[ATraining Step: 1182  | total loss: [1m[32m0.02312[0m[0m | time: 20.362s
[2K
| Adam | epoch: 026 | loss: 0.02312 - acc: 0.9967 -- iter: 1024/1468
[A[ATraining Step: 1183  | total loss: [1m[32m0.02906[0m[0m | time: 20.986s
[2K
| Adam | epoch: 026 | loss: 0.02906 - acc: 0.9939 -- iter: 1056/1468
[A[ATraining Step: 1184  | total loss: [1m[32m0.02669[0m[0m | time: 21.629s
[2K
| Adam | epoch: 026 | loss: 0.02669 - acc: 0.9945 -- iter: 1088/1468
[A[ATraining Step: 1185  | total loss: [1m[32m0.02503[0m[0m | time: 22.275s
[2K
| Adam | epoch: 026 | loss: 0.02503 - acc: 0.9951 -- iter: 1120/1468
[A[ATraining Step: 1186  | total loss: [1m[32m0.02971[0m[0m | time: 22.883s
[2K
| Adam | epoch: 026 | loss: 0.02971 - acc: 0.9924 -- iter: 1152/1468
[A[ATraining Step: 1187  | total loss: [1m[32m0.03509[0m[0m | time: 23.503s
[2K
| Adam | epoch: 026 | loss: 0.03509 - acc: 0.9901 -- iter: 1184/1468
[A[ATraining Step: 1188  | total loss: [1m[32m0.03402[0m[0m | time: 24.159s
[2K
| Adam | epoch: 026 | loss: 0.03402 - acc: 0.9911 -- iter: 1216/1468
[A[ATraining Step: 1189  | total loss: [1m[32m0.03379[0m[0m | time: 24.834s
[2K
| Adam | epoch: 026 | loss: 0.03379 - acc: 0.9888 -- iter: 1248/1468
[A[ATraining Step: 1190  | total loss: [1m[32m0.04471[0m[0m | time: 25.479s
[2K
| Adam | epoch: 026 | loss: 0.04471 - acc: 0.9868 -- iter: 1280/1468
[A[ATraining Step: 1191  | total loss: [1m[32m0.04112[0m[0m | time: 26.108s
[2K
| Adam | epoch: 026 | loss: 0.04112 - acc: 0.9881 -- iter: 1312/1468
[A[ATraining Step: 1192  | total loss: [1m[32m0.03899[0m[0m | time: 26.732s
[2K
| Adam | epoch: 026 | loss: 0.03899 - acc: 0.9893 -- iter: 1344/1468
[A[ATraining Step: 1193  | total loss: [1m[32m0.04792[0m[0m | time: 27.450s
[2K
| Adam | epoch: 026 | loss: 0.04792 - acc: 0.9873 -- iter: 1376/1468
[A[ATraining Step: 1194  | total loss: [1m[32m0.04414[0m[0m | time: 28.076s
[2K
| Adam | epoch: 026 | loss: 0.04414 - acc: 0.9885 -- iter: 1408/1468
[A[ATraining Step: 1195  | total loss: [1m[32m0.04004[0m[0m | time: 28.703s
[2K
| Adam | epoch: 026 | loss: 0.04004 - acc: 0.9897 -- iter: 1440/1468
[A[ATraining Step: 1196  | total loss: [1m[32m0.03702[0m[0m | time: 30.886s
[2K
| Adam | epoch: 026 | loss: 0.03702 - acc: 0.9907 | val_loss: 0.58584 - val_acc: 0.8126 -- iter: 1468/1468
--
Training Step: 1197  | total loss: [1m[32m0.04758[0m[0m | time: 0.633s
[2K
| Adam | epoch: 027 | loss: 0.04758 - acc: 0.9885 -- iter: 0032/1468
[A[ATraining Step: 1198  | total loss: [1m[32m0.04401[0m[0m | time: 1.285s
[2K
| Adam | epoch: 027 | loss: 0.04401 - acc: 0.9897 -- iter: 0064/1468
[A[ATraining Step: 1199  | total loss: [1m[32m0.04056[0m[0m | time: 1.921s
[2K
| Adam | epoch: 027 | loss: 0.04056 - acc: 0.9907 -- iter: 0096/1468
[A[ATraining Step: 1200  | total loss: [1m[32m0.03786[0m[0m | time: 4.104s
[2K
| Adam | epoch: 027 | loss: 0.03786 - acc: 0.9916 | val_loss: 0.59441 - val_acc: 0.8061 -- iter: 0128/1468
--
Training Step: 1201  | total loss: [1m[32m0.03520[0m[0m | time: 4.750s
[2K
| Adam | epoch: 027 | loss: 0.03520 - acc: 0.9925 -- iter: 0160/1468
[A[ATraining Step: 1202  | total loss: [1m[32m0.03458[0m[0m | time: 5.408s
[2K
| Adam | epoch: 027 | loss: 0.03458 - acc: 0.9932 -- iter: 0192/1468
[A[ATraining Step: 1203  | total loss: [1m[32m0.03220[0m[0m | time: 6.057s
[2K
| Adam | epoch: 027 | loss: 0.03220 - acc: 0.9939 -- iter: 0224/1468
[A[ATraining Step: 1204  | total loss: [1m[32m0.03021[0m[0m | time: 6.711s
[2K
| Adam | epoch: 027 | loss: 0.03021 - acc: 0.9945 -- iter: 0256/1468
[A[ATraining Step: 1205  | total loss: [1m[32m0.02796[0m[0m | time: 7.353s
[2K
| Adam | epoch: 027 | loss: 0.02796 - acc: 0.9951 -- iter: 0288/1468
[A[ATraining Step: 1206  | total loss: [1m[32m0.02741[0m[0m | time: 8.027s
[2K
| Adam | epoch: 027 | loss: 0.02741 - acc: 0.9956 -- iter: 0320/1468
[A[ATraining Step: 1207  | total loss: [1m[32m0.04312[0m[0m | time: 8.661s
[2K
| Adam | epoch: 027 | loss: 0.04312 - acc: 0.9929 -- iter: 0352/1468
[A[ATraining Step: 1208  | total loss: [1m[32m0.04778[0m[0m | time: 9.318s
[2K
| Adam | epoch: 027 | loss: 0.04778 - acc: 0.9905 -- iter: 0384/1468
[A[ATraining Step: 1209  | total loss: [1m[32m0.04571[0m[0m | time: 9.942s
[2K
| Adam | epoch: 027 | loss: 0.04571 - acc: 0.9914 -- iter: 0416/1468
[A[ATraining Step: 1210  | total loss: [1m[32m0.04405[0m[0m | time: 10.599s
[2K
| Adam | epoch: 027 | loss: 0.04405 - acc: 0.9923 -- iter: 0448/1468
[A[ATraining Step: 1211  | total loss: [1m[32m0.04151[0m[0m | time: 11.259s
[2K
| Adam | epoch: 027 | loss: 0.04151 - acc: 0.9930 -- iter: 0480/1468
[A[ATraining Step: 1212  | total loss: [1m[32m0.03862[0m[0m | time: 11.878s
[2K
| Adam | epoch: 027 | loss: 0.03862 - acc: 0.9937 -- iter: 0512/1468
[A[ATraining Step: 1213  | total loss: [1m[32m0.03540[0m[0m | time: 12.522s
[2K
| Adam | epoch: 027 | loss: 0.03540 - acc: 0.9944 -- iter: 0544/1468
[A[ATraining Step: 1214  | total loss: [1m[32m0.03308[0m[0m | time: 13.182s
[2K
| Adam | epoch: 027 | loss: 0.03308 - acc: 0.9949 -- iter: 0576/1468
[A[ATraining Step: 1215  | total loss: [1m[32m0.03608[0m[0m | time: 13.846s
[2K
| Adam | epoch: 027 | loss: 0.03608 - acc: 0.9892 -- iter: 0608/1468
[A[ATraining Step: 1216  | total loss: [1m[32m0.03391[0m[0m | time: 14.467s
[2K
| Adam | epoch: 027 | loss: 0.03391 - acc: 0.9903 -- iter: 0640/1468
[A[ATraining Step: 1217  | total loss: [1m[32m0.03404[0m[0m | time: 15.101s
[2K
| Adam | epoch: 027 | loss: 0.03404 - acc: 0.9912 -- iter: 0672/1468
[A[ATraining Step: 1218  | total loss: [1m[32m0.03402[0m[0m | time: 15.737s
[2K
| Adam | epoch: 027 | loss: 0.03402 - acc: 0.9890 -- iter: 0704/1468
[A[ATraining Step: 1219  | total loss: [1m[32m0.03164[0m[0m | time: 16.375s
[2K
| Adam | epoch: 027 | loss: 0.03164 - acc: 0.9901 -- iter: 0736/1468
[A[ATraining Step: 1220  | total loss: [1m[32m0.03102[0m[0m | time: 17.001s
[2K
| Adam | epoch: 027 | loss: 0.03102 - acc: 0.9911 -- iter: 0768/1468
[A[ATraining Step: 1221  | total loss: [1m[32m0.05149[0m[0m | time: 17.550s
[2K
| Adam | epoch: 027 | loss: 0.05149 - acc: 0.9857 -- iter: 0800/1468
[A[ATraining Step: 1222  | total loss: [1m[32m0.04720[0m[0m | time: 18.100s
[2K
| Adam | epoch: 027 | loss: 0.04720 - acc: 0.9872 -- iter: 0832/1468
[A[ATraining Step: 1223  | total loss: [1m[32m0.04353[0m[0m | time: 18.725s
[2K
| Adam | epoch: 027 | loss: 0.04353 - acc: 0.9884 -- iter: 0864/1468
[A[ATraining Step: 1224  | total loss: [1m[32m0.04132[0m[0m | time: 19.360s
[2K
| Adam | epoch: 027 | loss: 0.04132 - acc: 0.9896 -- iter: 0896/1468
[A[ATraining Step: 1225  | total loss: [1m[32m0.04377[0m[0m | time: 20.031s
[2K
| Adam | epoch: 027 | loss: 0.04377 - acc: 0.9844 -- iter: 0928/1468
[A[ATraining Step: 1226  | total loss: [1m[32m0.04051[0m[0m | time: 20.682s
[2K
| Adam | epoch: 027 | loss: 0.04051 - acc: 0.9859 -- iter: 0960/1468
[A[ATraining Step: 1227  | total loss: [1m[32m0.03914[0m[0m | time: 21.326s
[2K
| Adam | epoch: 027 | loss: 0.03914 - acc: 0.9874 -- iter: 0992/1468
[A[ATraining Step: 1228  | total loss: [1m[32m0.04020[0m[0m | time: 21.960s
[2K
| Adam | epoch: 027 | loss: 0.04020 - acc: 0.9855 -- iter: 1024/1468
[A[ATraining Step: 1229  | total loss: [1m[32m0.03783[0m[0m | time: 22.608s
[2K
| Adam | epoch: 027 | loss: 0.03783 - acc: 0.9869 -- iter: 1056/1468
[A[ATraining Step: 1230  | total loss: [1m[32m0.03886[0m[0m | time: 23.231s
[2K
| Adam | epoch: 027 | loss: 0.03886 - acc: 0.9882 -- iter: 1088/1468
[A[ATraining Step: 1231  | total loss: [1m[32m0.03830[0m[0m | time: 23.892s
[2K
| Adam | epoch: 027 | loss: 0.03830 - acc: 0.9894 -- iter: 1120/1468
[A[ATraining Step: 1232  | total loss: [1m[32m0.03740[0m[0m | time: 24.543s
[2K
| Adam | epoch: 027 | loss: 0.03740 - acc: 0.9905 -- iter: 1152/1468
[A[ATraining Step: 1233  | total loss: [1m[32m0.03708[0m[0m | time: 25.171s
[2K
| Adam | epoch: 027 | loss: 0.03708 - acc: 0.9914 -- iter: 1184/1468
[A[ATraining Step: 1234  | total loss: [1m[32m0.03543[0m[0m | time: 25.804s
[2K
| Adam | epoch: 027 | loss: 0.03543 - acc: 0.9923 -- iter: 1216/1468
[A[ATraining Step: 1235  | total loss: [1m[32m0.03312[0m[0m | time: 26.462s
[2K
| Adam | epoch: 027 | loss: 0.03312 - acc: 0.9931 -- iter: 1248/1468
[A[ATraining Step: 1236  | total loss: [1m[32m0.03181[0m[0m | time: 27.083s
[2K
| Adam | epoch: 027 | loss: 0.03181 - acc: 0.9938 -- iter: 1280/1468
[A[ATraining Step: 1237  | total loss: [1m[32m0.06081[0m[0m | time: 27.711s
[2K
| Adam | epoch: 027 | loss: 0.06081 - acc: 0.9913 -- iter: 1312/1468
[A[ATraining Step: 1238  | total loss: [1m[32m0.05582[0m[0m | time: 28.359s
[2K
| Adam | epoch: 027 | loss: 0.05582 - acc: 0.9921 -- iter: 1344/1468
[A[ATraining Step: 1239  | total loss: [1m[32m0.05217[0m[0m | time: 28.995s
[2K
| Adam | epoch: 027 | loss: 0.05217 - acc: 0.9929 -- iter: 1376/1468
[A[ATraining Step: 1240  | total loss: [1m[32m0.05074[0m[0m | time: 29.678s
[2K
| Adam | epoch: 027 | loss: 0.05074 - acc: 0.9905 -- iter: 1408/1468
[A[ATraining Step: 1241  | total loss: [1m[32m0.04649[0m[0m | time: 30.301s
[2K
| Adam | epoch: 027 | loss: 0.04649 - acc: 0.9914 -- iter: 1440/1468
[A[ATraining Step: 1242  | total loss: [1m[32m0.04356[0m[0m | time: 32.477s
[2K
| Adam | epoch: 027 | loss: 0.04356 - acc: 0.9923 | val_loss: 0.62999 - val_acc: 0.7996 -- iter: 1468/1468
--
Training Step: 1243  | total loss: [1m[32m0.04183[0m[0m | time: 0.637s
[2K
| Adam | epoch: 028 | loss: 0.04183 - acc: 0.9931 -- iter: 0032/1468
[A[ATraining Step: 1244  | total loss: [1m[32m0.03846[0m[0m | time: 1.268s
[2K
| Adam | epoch: 028 | loss: 0.03846 - acc: 0.9938 -- iter: 0064/1468
[A[ATraining Step: 1245  | total loss: [1m[32m0.03539[0m[0m | time: 1.994s
[2K
| Adam | epoch: 028 | loss: 0.03539 - acc: 0.9944 -- iter: 0096/1468
[A[ATraining Step: 1246  | total loss: [1m[32m0.03300[0m[0m | time: 2.659s
[2K
| Adam | epoch: 028 | loss: 0.03300 - acc: 0.9950 -- iter: 0128/1468
[A[ATraining Step: 1247  | total loss: [1m[32m0.03021[0m[0m | time: 3.293s
[2K
| Adam | epoch: 028 | loss: 0.03021 - acc: 0.9955 -- iter: 0160/1468
[A[ATraining Step: 1248  | total loss: [1m[32m0.02915[0m[0m | time: 3.958s
[2K
| Adam | epoch: 028 | loss: 0.02915 - acc: 0.9959 -- iter: 0192/1468
[A[ATraining Step: 1249  | total loss: [1m[32m0.02994[0m[0m | time: 4.596s
[2K
| Adam | epoch: 028 | loss: 0.02994 - acc: 0.9932 -- iter: 0224/1468
[A[ATraining Step: 1250  | total loss: [1m[32m0.02717[0m[0m | time: 5.252s
[2K
| Adam | epoch: 028 | loss: 0.02717 - acc: 0.9939 -- iter: 0256/1468
[A[ATraining Step: 1251  | total loss: [1m[32m0.02507[0m[0m | time: 5.918s
[2K
| Adam | epoch: 028 | loss: 0.02507 - acc: 0.9945 -- iter: 0288/1468
[A[ATraining Step: 1252  | total loss: [1m[32m0.02300[0m[0m | time: 6.535s
[2K
| Adam | epoch: 028 | loss: 0.02300 - acc: 0.9950 -- iter: 0320/1468
[A[ATraining Step: 1253  | total loss: [1m[32m0.02161[0m[0m | time: 7.165s
[2K
| Adam | epoch: 028 | loss: 0.02161 - acc: 0.9955 -- iter: 0352/1468
[A[ATraining Step: 1254  | total loss: [1m[32m0.02061[0m[0m | time: 7.824s
[2K
| Adam | epoch: 028 | loss: 0.02061 - acc: 0.9960 -- iter: 0384/1468
[A[ATraining Step: 1255  | total loss: [1m[32m0.01910[0m[0m | time: 8.442s
[2K
| Adam | epoch: 028 | loss: 0.01910 - acc: 0.9964 -- iter: 0416/1468
[A[ATraining Step: 1256  | total loss: [1m[32m0.01889[0m[0m | time: 9.062s
[2K
| Adam | epoch: 028 | loss: 0.01889 - acc: 0.9967 -- iter: 0448/1468
[A[ATraining Step: 1257  | total loss: [1m[32m0.01748[0m[0m | time: 9.703s
[2K
| Adam | epoch: 028 | loss: 0.01748 - acc: 0.9971 -- iter: 0480/1468
[A[ATraining Step: 1258  | total loss: [1m[32m0.01946[0m[0m | time: 10.323s
[2K
| Adam | epoch: 028 | loss: 0.01946 - acc: 0.9942 -- iter: 0512/1468
[A[ATraining Step: 1259  | total loss: [1m[32m0.02043[0m[0m | time: 11.028s
[2K
| Adam | epoch: 028 | loss: 0.02043 - acc: 0.9917 -- iter: 0544/1468
[A[ATraining Step: 1260  | total loss: [1m[32m0.04188[0m[0m | time: 11.650s
[2K
| Adam | epoch: 028 | loss: 0.04188 - acc: 0.9894 -- iter: 0576/1468
[A[ATraining Step: 1261  | total loss: [1m[32m0.03872[0m[0m | time: 12.279s
[2K
| Adam | epoch: 028 | loss: 0.03872 - acc: 0.9905 -- iter: 0608/1468
[A[ATraining Step: 1262  | total loss: [1m[32m0.03618[0m[0m | time: 12.921s
[2K
| Adam | epoch: 028 | loss: 0.03618 - acc: 0.9914 -- iter: 0640/1468
[A[ATraining Step: 1263  | total loss: [1m[32m0.03461[0m[0m | time: 13.555s
[2K
| Adam | epoch: 028 | loss: 0.03461 - acc: 0.9923 -- iter: 0672/1468
[A[ATraining Step: 1264  | total loss: [1m[32m0.03408[0m[0m | time: 14.210s
[2K
| Adam | epoch: 028 | loss: 0.03408 - acc: 0.9930 -- iter: 0704/1468
[A[ATraining Step: 1265  | total loss: [1m[32m0.03204[0m[0m | time: 14.856s
[2K
| Adam | epoch: 028 | loss: 0.03204 - acc: 0.9937 -- iter: 0736/1468
[A[ATraining Step: 1266  | total loss: [1m[32m0.02904[0m[0m | time: 15.494s
[2K
| Adam | epoch: 028 | loss: 0.02904 - acc: 0.9944 -- iter: 0768/1468
[A[ATraining Step: 1267  | total loss: [1m[32m0.02698[0m[0m | time: 16.134s
[2K
| Adam | epoch: 028 | loss: 0.02698 - acc: 0.9949 -- iter: 0800/1468
[A[ATraining Step: 1268  | total loss: [1m[32m0.02811[0m[0m | time: 16.702s
[2K
| Adam | epoch: 028 | loss: 0.02811 - acc: 0.9954 -- iter: 0832/1468
[A[ATraining Step: 1269  | total loss: [1m[32m0.02921[0m[0m | time: 17.256s
[2K
| Adam | epoch: 028 | loss: 0.02921 - acc: 0.9959 -- iter: 0864/1468
[A[ATraining Step: 1270  | total loss: [1m[32m0.02759[0m[0m | time: 17.890s
[2K
| Adam | epoch: 028 | loss: 0.02759 - acc: 0.9963 -- iter: 0896/1468
[A[ATraining Step: 1271  | total loss: [1m[32m0.02529[0m[0m | time: 18.514s
[2K
| Adam | epoch: 028 | loss: 0.02529 - acc: 0.9967 -- iter: 0928/1468
[A[ATraining Step: 1272  | total loss: [1m[32m0.02347[0m[0m | time: 19.138s
[2K
| Adam | epoch: 028 | loss: 0.02347 - acc: 0.9970 -- iter: 0960/1468
[A[ATraining Step: 1273  | total loss: [1m[32m0.02198[0m[0m | time: 19.775s
[2K
| Adam | epoch: 028 | loss: 0.02198 - acc: 0.9973 -- iter: 0992/1468
[A[ATraining Step: 1274  | total loss: [1m[32m0.02175[0m[0m | time: 20.398s
[2K
| Adam | epoch: 028 | loss: 0.02175 - acc: 0.9976 -- iter: 1024/1468
[A[ATraining Step: 1275  | total loss: [1m[32m0.03827[0m[0m | time: 21.048s
[2K
| Adam | epoch: 028 | loss: 0.03827 - acc: 0.9947 -- iter: 1056/1468
[A[ATraining Step: 1276  | total loss: [1m[32m0.05584[0m[0m | time: 21.676s
[2K
| Adam | epoch: 028 | loss: 0.05584 - acc: 0.9858 -- iter: 1088/1468
[A[ATraining Step: 1277  | total loss: [1m[32m0.05086[0m[0m | time: 22.308s
[2K
| Adam | epoch: 028 | loss: 0.05086 - acc: 0.9873 -- iter: 1120/1468
[A[ATraining Step: 1278  | total loss: [1m[32m0.04621[0m[0m | time: 22.969s
[2K
| Adam | epoch: 028 | loss: 0.04621 - acc: 0.9885 -- iter: 1152/1468
[A[ATraining Step: 1279  | total loss: [1m[32m0.06097[0m[0m | time: 23.614s
[2K
| Adam | epoch: 028 | loss: 0.06097 - acc: 0.9866 -- iter: 1184/1468
[A[ATraining Step: 1280  | total loss: [1m[32m0.06762[0m[0m | time: 24.247s
[2K
| Adam | epoch: 028 | loss: 0.06762 - acc: 0.9817 -- iter: 1216/1468
[A[ATraining Step: 1281  | total loss: [1m[32m0.08045[0m[0m | time: 24.883s
[2K
| Adam | epoch: 028 | loss: 0.08045 - acc: 0.9804 -- iter: 1248/1468
[A[ATraining Step: 1282  | total loss: [1m[32m0.07332[0m[0m | time: 25.510s
[2K
| Adam | epoch: 028 | loss: 0.07332 - acc: 0.9823 -- iter: 1280/1468
[A[ATraining Step: 1283  | total loss: [1m[32m0.07083[0m[0m | time: 26.143s
[2K
| Adam | epoch: 028 | loss: 0.07083 - acc: 0.9810 -- iter: 1312/1468
[A[ATraining Step: 1284  | total loss: [1m[32m0.09316[0m[0m | time: 26.774s
[2K
| Adam | epoch: 028 | loss: 0.09316 - acc: 0.9797 -- iter: 1344/1468
[A[ATraining Step: 1285  | total loss: [1m[32m0.08443[0m[0m | time: 27.424s
[2K
| Adam | epoch: 028 | loss: 0.08443 - acc: 0.9818 -- iter: 1376/1468
[A[ATraining Step: 1286  | total loss: [1m[32m0.08081[0m[0m | time: 28.055s
[2K
| Adam | epoch: 028 | loss: 0.08081 - acc: 0.9836 -- iter: 1408/1468
[A[ATraining Step: 1287  | total loss: [1m[32m0.08265[0m[0m | time: 28.698s
[2K
| Adam | epoch: 028 | loss: 0.08265 - acc: 0.9790 -- iter: 1440/1468
[A[ATraining Step: 1288  | total loss: [1m[32m0.07627[0m[0m | time: 30.889s
[2K
| Adam | epoch: 028 | loss: 0.07627 - acc: 0.9811 | val_loss: 0.63176 - val_acc: 0.8126 -- iter: 1468/1468
--
Training Step: 1289  | total loss: [1m[32m0.06938[0m[0m | time: 0.630s
[2K
| Adam | epoch: 029 | loss: 0.06938 - acc: 0.9830 -- iter: 0032/1468
[A[ATraining Step: 1290  | total loss: [1m[32m0.06280[0m[0m | time: 1.275s
[2K
| Adam | epoch: 029 | loss: 0.06280 - acc: 0.9847 -- iter: 0064/1468
[A[ATraining Step: 1291  | total loss: [1m[32m0.05947[0m[0m | time: 1.906s
[2K
| Adam | epoch: 029 | loss: 0.05947 - acc: 0.9862 -- iter: 0096/1468
[A[ATraining Step: 1292  | total loss: [1m[32m0.05770[0m[0m | time: 2.559s
[2K
| Adam | epoch: 029 | loss: 0.05770 - acc: 0.9876 -- iter: 0128/1468
[A[ATraining Step: 1293  | total loss: [1m[32m0.05292[0m[0m | time: 3.179s
[2K
| Adam | epoch: 029 | loss: 0.05292 - acc: 0.9888 -- iter: 0160/1468
[A[ATraining Step: 1294  | total loss: [1m[32m0.04830[0m[0m | time: 3.818s
[2K
| Adam | epoch: 029 | loss: 0.04830 - acc: 0.9899 -- iter: 0192/1468
[A[ATraining Step: 1295  | total loss: [1m[32m0.04385[0m[0m | time: 4.456s
[2K
| Adam | epoch: 029 | loss: 0.04385 - acc: 0.9910 -- iter: 0224/1468
[A[ATraining Step: 1296  | total loss: [1m[32m0.03986[0m[0m | time: 5.096s
[2K
| Adam | epoch: 029 | loss: 0.03986 - acc: 0.9919 -- iter: 0256/1468
[A[ATraining Step: 1297  | total loss: [1m[32m0.04385[0m[0m | time: 5.731s
[2K
| Adam | epoch: 029 | loss: 0.04385 - acc: 0.9895 -- iter: 0288/1468
[A[ATraining Step: 1298  | total loss: [1m[32m0.04308[0m[0m | time: 6.383s
[2K
| Adam | epoch: 029 | loss: 0.04308 - acc: 0.9875 -- iter: 0320/1468
[A[ATraining Step: 1299  | total loss: [1m[32m0.03943[0m[0m | time: 7.117s
[2K
| Adam | epoch: 029 | loss: 0.03943 - acc: 0.9887 -- iter: 0352/1468
[A[ATraining Step: 1300  | total loss: [1m[32m0.03684[0m[0m | time: 7.756s
[2K
| Adam | epoch: 029 | loss: 0.03684 - acc: 0.9898 -- iter: 0384/1468
[A[ATraining Step: 1301  | total loss: [1m[32m0.03377[0m[0m | time: 8.379s
[2K
| Adam | epoch: 029 | loss: 0.03377 - acc: 0.9909 -- iter: 0416/1468
[A[ATraining Step: 1302  | total loss: [1m[32m0.03198[0m[0m | time: 9.031s
[2K
| Adam | epoch: 029 | loss: 0.03198 - acc: 0.9918 -- iter: 0448/1468
[A[ATraining Step: 1303  | total loss: [1m[32m0.03599[0m[0m | time: 9.711s
[2K
| Adam | epoch: 029 | loss: 0.03599 - acc: 0.9895 -- iter: 0480/1468
[A[ATraining Step: 1304  | total loss: [1m[32m0.03572[0m[0m | time: 10.378s
[2K
| Adam | epoch: 029 | loss: 0.03572 - acc: 0.9905 -- iter: 0512/1468
[A[ATraining Step: 1305  | total loss: [1m[32m0.03795[0m[0m | time: 11.027s
[2K
| Adam | epoch: 029 | loss: 0.03795 - acc: 0.9883 -- iter: 0544/1468
[A[ATraining Step: 1306  | total loss: [1m[32m0.03672[0m[0m | time: 11.662s
[2K
| Adam | epoch: 029 | loss: 0.03672 - acc: 0.9895 -- iter: 0576/1468
[A[ATraining Step: 1307  | total loss: [1m[32m0.03395[0m[0m | time: 12.321s
[2K
| Adam | epoch: 029 | loss: 0.03395 - acc: 0.9906 -- iter: 0608/1468
[A[ATraining Step: 1308  | total loss: [1m[32m0.03453[0m[0m | time: 12.939s
[2K
| Adam | epoch: 029 | loss: 0.03453 - acc: 0.9884 -- iter: 0640/1468
[A[ATraining Step: 1309  | total loss: [1m[32m0.03396[0m[0m | time: 13.593s
[2K
| Adam | epoch: 029 | loss: 0.03396 - acc: 0.9895 -- iter: 0672/1468
[A[ATraining Step: 1310  | total loss: [1m[32m0.03103[0m[0m | time: 14.221s
[2K
| Adam | epoch: 029 | loss: 0.03103 - acc: 0.9906 -- iter: 0704/1468
[A[ATraining Step: 1311  | total loss: [1m[32m0.02849[0m[0m | time: 14.868s
[2K
| Adam | epoch: 029 | loss: 0.02849 - acc: 0.9915 -- iter: 0736/1468
[A[ATraining Step: 1312  | total loss: [1m[32m0.02774[0m[0m | time: 15.502s
[2K
| Adam | epoch: 029 | loss: 0.02774 - acc: 0.9924 -- iter: 0768/1468
[A[ATraining Step: 1313  | total loss: [1m[32m0.02593[0m[0m | time: 16.131s
[2K
| Adam | epoch: 029 | loss: 0.02593 - acc: 0.9931 -- iter: 0800/1468
[A[ATraining Step: 1314  | total loss: [1m[32m0.02990[0m[0m | time: 16.775s
[2K
| Adam | epoch: 029 | loss: 0.02990 - acc: 0.9907 -- iter: 0832/1468
[A[ATraining Step: 1315  | total loss: [1m[32m0.02815[0m[0m | time: 17.323s
[2K
| Adam | epoch: 029 | loss: 0.02815 - acc: 0.9916 -- iter: 0864/1468
[A[ATraining Step: 1316  | total loss: [1m[32m0.02881[0m[0m | time: 17.896s
[2K
| Adam | epoch: 029 | loss: 0.02881 - acc: 0.9925 -- iter: 0896/1468
[A[ATraining Step: 1317  | total loss: [1m[32m0.02861[0m[0m | time: 18.545s
[2K
| Adam | epoch: 029 | loss: 0.02861 - acc: 0.9932 -- iter: 0928/1468
[A[ATraining Step: 1318  | total loss: [1m[32m0.02725[0m[0m | time: 19.170s
[2K
| Adam | epoch: 029 | loss: 0.02725 - acc: 0.9939 -- iter: 0960/1468
[A[ATraining Step: 1319  | total loss: [1m[32m0.02567[0m[0m | time: 19.812s
[2K
| Adam | epoch: 029 | loss: 0.02567 - acc: 0.9945 -- iter: 0992/1468
[A[ATraining Step: 1320  | total loss: [1m[32m0.04749[0m[0m | time: 20.456s
[2K
| Adam | epoch: 029 | loss: 0.04749 - acc: 0.9888 -- iter: 1024/1468
[A[ATraining Step: 1321  | total loss: [1m[32m0.04338[0m[0m | time: 21.100s
[2K
| Adam | epoch: 029 | loss: 0.04338 - acc: 0.9899 -- iter: 1056/1468
[A[ATraining Step: 1322  | total loss: [1m[32m0.03938[0m[0m | time: 21.763s
[2K
| Adam | epoch: 029 | loss: 0.03938 - acc: 0.9909 -- iter: 1088/1468
[A[ATraining Step: 1323  | total loss: [1m[32m0.03593[0m[0m | time: 22.388s
[2K
| Adam | epoch: 029 | loss: 0.03593 - acc: 0.9918 -- iter: 1120/1468
[A[ATraining Step: 1324  | total loss: [1m[32m0.04024[0m[0m | time: 23.020s
[2K
| Adam | epoch: 029 | loss: 0.04024 - acc: 0.9895 -- iter: 1152/1468
[A[ATraining Step: 1325  | total loss: [1m[32m0.03734[0m[0m | time: 23.636s
[2K
| Adam | epoch: 029 | loss: 0.03734 - acc: 0.9906 -- iter: 1184/1468
[A[ATraining Step: 1326  | total loss: [1m[32m0.03675[0m[0m | time: 24.264s
[2K
| Adam | epoch: 029 | loss: 0.03675 - acc: 0.9915 -- iter: 1216/1468
[A[ATraining Step: 1327  | total loss: [1m[32m0.05784[0m[0m | time: 24.899s
[2K
| Adam | epoch: 029 | loss: 0.05784 - acc: 0.9892 -- iter: 1248/1468
[A[ATraining Step: 1328  | total loss: [1m[32m0.05374[0m[0m | time: 25.530s
[2K
| Adam | epoch: 029 | loss: 0.05374 - acc: 0.9903 -- iter: 1280/1468
[A[ATraining Step: 1329  | total loss: [1m[32m0.04885[0m[0m | time: 26.168s
[2K
| Adam | epoch: 029 | loss: 0.04885 - acc: 0.9913 -- iter: 1312/1468
[A[ATraining Step: 1330  | total loss: [1m[32m0.04620[0m[0m | time: 26.794s
[2K
| Adam | epoch: 029 | loss: 0.04620 - acc: 0.9922 -- iter: 1344/1468
[A[ATraining Step: 1331  | total loss: [1m[32m0.05467[0m[0m | time: 27.442s
[2K
| Adam | epoch: 029 | loss: 0.05467 - acc: 0.9898 -- iter: 1376/1468
[A[ATraining Step: 1332  | total loss: [1m[32m0.06317[0m[0m | time: 28.090s
[2K
| Adam | epoch: 029 | loss: 0.06317 - acc: 0.9877 -- iter: 1408/1468
[A[ATraining Step: 1333  | total loss: [1m[32m0.07516[0m[0m | time: 28.738s
[2K
| Adam | epoch: 029 | loss: 0.07516 - acc: 0.9858 -- iter: 1440/1468
[A[ATraining Step: 1334  | total loss: [1m[32m0.06886[0m[0m | time: 30.922s
[2K
| Adam | epoch: 029 | loss: 0.06886 - acc: 0.9872 | val_loss: 0.62296 - val_acc: 0.8214 -- iter: 1468/1468
--
Training Step: 1335  | total loss: [1m[32m0.06321[0m[0m | time: 0.626s
[2K
| Adam | epoch: 030 | loss: 0.06321 - acc: 0.9885 -- iter: 0032/1468
[A[ATraining Step: 1336  | total loss: [1m[32m0.05767[0m[0m | time: 1.312s
[2K
| Adam | epoch: 030 | loss: 0.05767 - acc: 0.9897 -- iter: 0064/1468
[A[ATraining Step: 1337  | total loss: [1m[32m0.05454[0m[0m | time: 1.953s
[2K
| Adam | epoch: 030 | loss: 0.05454 - acc: 0.9907 -- iter: 0096/1468
[A[ATraining Step: 1338  | total loss: [1m[32m0.04995[0m[0m | time: 2.577s
[2K
| Adam | epoch: 030 | loss: 0.04995 - acc: 0.9916 -- iter: 0128/1468
[A[ATraining Step: 1339  | total loss: [1m[32m0.04591[0m[0m | time: 3.277s
[2K
| Adam | epoch: 030 | loss: 0.04591 - acc: 0.9925 -- iter: 0160/1468
[A[ATraining Step: 1340  | total loss: [1m[32m0.04293[0m[0m | time: 3.929s
[2K
| Adam | epoch: 030 | loss: 0.04293 - acc: 0.9932 -- iter: 0192/1468
[A[ATraining Step: 1341  | total loss: [1m[32m0.03991[0m[0m | time: 4.568s
[2K
| Adam | epoch: 030 | loss: 0.03991 - acc: 0.9939 -- iter: 0224/1468
[A[ATraining Step: 1342  | total loss: [1m[32m0.03610[0m[0m | time: 5.193s
[2K
| Adam | epoch: 030 | loss: 0.03610 - acc: 0.9945 -- iter: 0256/1468
[A[ATraining Step: 1343  | total loss: [1m[32m0.03292[0m[0m | time: 5.837s
[2K
| Adam | epoch: 030 | loss: 0.03292 - acc: 0.9951 -- iter: 0288/1468
[A[ATraining Step: 1344  | total loss: [1m[32m0.03361[0m[0m | time: 6.458s
[2K
| Adam | epoch: 030 | loss: 0.03361 - acc: 0.9955 -- iter: 0320/1468
[A[ATraining Step: 1345  | total loss: [1m[32m0.03111[0m[0m | time: 7.128s
[2K
| Adam | epoch: 030 | loss: 0.03111 - acc: 0.9960 -- iter: 0352/1468
[A[ATraining Step: 1346  | total loss: [1m[32m0.02885[0m[0m | time: 7.771s
[2K
| Adam | epoch: 030 | loss: 0.02885 - acc: 0.9964 -- iter: 0384/1468
[A[ATraining Step: 1347  | total loss: [1m[32m0.02657[0m[0m | time: 8.398s
[2K
| Adam | epoch: 030 | loss: 0.02657 - acc: 0.9968 -- iter: 0416/1468
[A[ATraining Step: 1348  | total loss: [1m[32m0.02566[0m[0m | time: 9.031s
[2K
| Adam | epoch: 030 | loss: 0.02566 - acc: 0.9971 -- iter: 0448/1468
[A[ATraining Step: 1349  | total loss: [1m[32m0.02821[0m[0m | time: 9.646s
[2K
| Adam | epoch: 030 | loss: 0.02821 - acc: 0.9942 -- iter: 0480/1468
[A[ATraining Step: 1350  | total loss: [1m[32m0.02638[0m[0m | time: 10.280s
[2K
| Adam | epoch: 030 | loss: 0.02638 - acc: 0.9948 -- iter: 0512/1468
[A[ATraining Step: 1351  | total loss: [1m[32m0.03705[0m[0m | time: 10.909s
[2K
| Adam | epoch: 030 | loss: 0.03705 - acc: 0.9891 -- iter: 0544/1468
[A[ATraining Step: 1352  | total loss: [1m[32m0.03427[0m[0m | time: 11.564s
[2K
| Adam | epoch: 030 | loss: 0.03427 - acc: 0.9902 -- iter: 0576/1468
[A[ATraining Step: 1353  | total loss: [1m[32m0.05323[0m[0m | time: 12.181s
[2K
| Adam | epoch: 030 | loss: 0.05323 - acc: 0.9849 -- iter: 0608/1468
[A[ATraining Step: 1354  | total loss: [1m[32m0.04849[0m[0m | time: 12.831s
[2K
| Adam | epoch: 030 | loss: 0.04849 - acc: 0.9864 -- iter: 0640/1468
[A[ATraining Step: 1355  | total loss: [1m[32m0.04411[0m[0m | time: 13.468s
[2K
| Adam | epoch: 030 | loss: 0.04411 - acc: 0.9878 -- iter: 0672/1468
[A[ATraining Step: 1356  | total loss: [1m[32m0.04005[0m[0m | time: 14.112s
[2K
| Adam | epoch: 030 | loss: 0.04005 - acc: 0.9890 -- iter: 0704/1468
[A[ATraining Step: 1357  | total loss: [1m[32m0.03735[0m[0m | time: 14.724s
[2K
| Adam | epoch: 030 | loss: 0.03735 - acc: 0.9901 -- iter: 0736/1468
[A[ATraining Step: 1358  | total loss: [1m[32m0.04247[0m[0m | time: 15.373s
[2K
| Adam | epoch: 030 | loss: 0.04247 - acc: 0.9880 -- iter: 0768/1468
[A[ATraining Step: 1359  | total loss: [1m[32m0.03845[0m[0m | time: 16.005s
[2K
| Adam | epoch: 030 | loss: 0.03845 - acc: 0.9892 -- iter: 0800/1468
[A[ATraining Step: 1360  | total loss: [1m[32m0.03765[0m[0m | time: 16.633s
[2K
| Adam | epoch: 030 | loss: 0.03765 - acc: 0.9903 -- iter: 0832/1468
[A[ATraining Step: 1361  | total loss: [1m[32m0.03559[0m[0m | time: 17.303s
[2K
| Adam | epoch: 030 | loss: 0.03559 - acc: 0.9912 -- iter: 0864/1468
[A[ATraining Step: 1362  | total loss: [1m[32m0.03244[0m[0m | time: 17.863s
[2K
| Adam | epoch: 030 | loss: 0.03244 - acc: 0.9921 -- iter: 0896/1468
[A[ATraining Step: 1363  | total loss: [1m[32m0.02972[0m[0m | time: 18.451s
[2K
| Adam | epoch: 030 | loss: 0.02972 - acc: 0.9929 -- iter: 0928/1468
[A[ATraining Step: 1364  | total loss: [1m[32m0.02730[0m[0m | time: 19.087s
[2K
| Adam | epoch: 030 | loss: 0.02730 - acc: 0.9936 -- iter: 0960/1468
[A[ATraining Step: 1365  | total loss: [1m[32m0.02815[0m[0m | time: 19.729s
[2K
| Adam | epoch: 030 | loss: 0.02815 - acc: 0.9911 -- iter: 0992/1468
[A[ATraining Step: 1366  | total loss: [1m[32m0.02559[0m[0m | time: 20.363s
[2K
| Adam | epoch: 030 | loss: 0.02559 - acc: 0.9920 -- iter: 1024/1468
[A[ATraining Step: 1367  | total loss: [1m[32m0.03262[0m[0m | time: 20.998s
[2K
| Adam | epoch: 030 | loss: 0.03262 - acc: 0.9897 -- iter: 1056/1468
[A[ATraining Step: 1368  | total loss: [1m[32m0.03135[0m[0m | time: 21.657s
[2K
| Adam | epoch: 030 | loss: 0.03135 - acc: 0.9907 -- iter: 1088/1468
[A[ATraining Step: 1369  | total loss: [1m[32m0.03506[0m[0m | time: 22.281s
[2K
| Adam | epoch: 030 | loss: 0.03506 - acc: 0.9885 -- iter: 1120/1468
[A[ATraining Step: 1370  | total loss: [1m[32m0.03603[0m[0m | time: 22.928s
[2K
| Adam | epoch: 030 | loss: 0.03603 - acc: 0.9897 -- iter: 1152/1468
[A[ATraining Step: 1371  | total loss: [1m[32m0.03315[0m[0m | time: 23.572s
[2K
| Adam | epoch: 030 | loss: 0.03315 - acc: 0.9907 -- iter: 1184/1468
[A[ATraining Step: 1372  | total loss: [1m[32m0.03053[0m[0m | time: 24.212s
[2K
| Adam | epoch: 030 | loss: 0.03053 - acc: 0.9916 -- iter: 1216/1468
[A[ATraining Step: 1373  | total loss: [1m[32m0.02835[0m[0m | time: 24.864s
[2K
| Adam | epoch: 030 | loss: 0.02835 - acc: 0.9925 -- iter: 1248/1468
[A[ATraining Step: 1374  | total loss: [1m[32m0.02601[0m[0m | time: 25.523s
[2K
| Adam | epoch: 030 | loss: 0.02601 - acc: 0.9932 -- iter: 1280/1468
[A[ATraining Step: 1375  | total loss: [1m[32m0.02745[0m[0m | time: 26.167s
[2K
| Adam | epoch: 030 | loss: 0.02745 - acc: 0.9939 -- iter: 1312/1468
[A[ATraining Step: 1376  | total loss: [1m[32m0.03269[0m[0m | time: 26.825s
[2K
| Adam | epoch: 030 | loss: 0.03269 - acc: 0.9914 -- iter: 1344/1468
[A[ATraining Step: 1377  | total loss: [1m[32m0.03091[0m[0m | time: 27.460s
[2K
| Adam | epoch: 030 | loss: 0.03091 - acc: 0.9922 -- iter: 1376/1468
[A[ATraining Step: 1378  | total loss: [1m[32m0.07766[0m[0m | time: 28.117s
[2K
| Adam | epoch: 030 | loss: 0.07766 - acc: 0.9836 -- iter: 1408/1468
[A[ATraining Step: 1379  | total loss: [1m[32m0.07196[0m[0m | time: 28.747s
[2K
| Adam | epoch: 030 | loss: 0.07196 - acc: 0.9853 -- iter: 1440/1468
[A[ATraining Step: 1380  | total loss: [1m[32m0.07920[0m[0m | time: 30.937s
[2K
| Adam | epoch: 030 | loss: 0.07920 - acc: 0.9836 | val_loss: 0.61490 - val_acc: 0.8170 -- iter: 1468/1468
--
Validation AUC:0.894406392694064
Validation AUPRC:0.9078608141725605
Test AUC:0.8714073622901519
Test AUPRC:0.8690683208402256
BestTestF1Score	0.77	0.57	0.79	0.78	0.76	166	46	195	52	0.72
BestTestMCCScore	0.77	0.59	0.79	0.81	0.73	160	37	204	58	0.83
BestTestAccuracyScore	0.77	0.59	0.79	0.81	0.73	160	37	204	58	0.83
BestValidationF1Score	0.83	0.65	0.83	0.85	0.8	193	33	186	47	0.72
BestValidationMCC	0.83	0.66	0.83	0.88	0.78	187	26	193	53	0.83
BestValidationAccuracy	0.83	0.66	0.83	0.88	0.78	187	26	193	53	0.83
TestPredictions (Threshold:0.83)
CHEMBL197159,TN,INACT,0.0	CHEMBL322256,TN,INACT,0.05999999865889549	CHEMBL284311,TN,INACT,0.0	CHEMBL78601,TN,INACT,0.0	CHEMBL77793,FN,ACT,0.09000000357627869	CHEMBL25984,TN,INACT,0.029999999329447746	CHEMBL3290583,TN,INACT,0.009999999776482582	CHEMBL2062861,TN,INACT,0.0	CHEMBL787,TP,ACT,1.0	CHEMBL3608420,TP,ACT,1.0	CHEMBL104803,TP,ACT,0.8500000238418579	CHEMBL3414844,TP,ACT,1.0	CHEMBL295207,TN,INACT,0.0	CHEMBL588119,TP,ACT,0.9399999976158142	CHEMBL440961,TN,INACT,0.0	CHEMBL119409,TN,INACT,0.5299999713897705	CHEMBL59,TN,INACT,0.0	CHEMBL2443006,FP,INACT,0.949999988079071	CHEMBL2079597,TN,INACT,0.7400000095367432	CHEMBL310712,TP,ACT,0.9800000190734863	CHEMBL143469,TP,ACT,1.0	CHEMBL3608413,TP,ACT,1.0	CHEMBL57908,TN,INACT,0.0	CHEMBL312567,TN,INACT,0.0	CHEMBL496915,TP,ACT,1.0	CHEMBL139603,TP,ACT,1.0	CHEMBL3588909,FP,INACT,0.9700000286102295	CHEMBL410531,FP,INACT,0.9900000095367432	CHEMBL56275,TP,ACT,0.9700000286102295	CHEMBL194837,FN,ACT,0.5400000214576721	CHEMBL282426,TN,INACT,0.6499999761581421	CHEMBL420781,FN,ACT,0.029999999329447746	CHEMBL3084658,TP,ACT,1.0	CHEMBL70319,FN,ACT,0.6600000262260437	CHEMBL540310,TN,INACT,0.2199999988079071	CHEMBL295722,TN,INACT,0.09000000357627869	CHEMBL168704,TP,ACT,0.9200000166893005	CHEMBL366819,TP,ACT,1.0	CHEMBL3764306,TN,INACT,0.019999999552965164	CHEMBL1934067,TN,INACT,0.03999999910593033	CHEMBL3745995,FN,ACT,0.5799999833106995	CHEMBL404866,FP,INACT,1.0	CHEMBL3747166,TP,ACT,1.0	CHEMBL516334,TN,INACT,0.05999999865889549	CHEMBL283320,TN,INACT,0.009999999776482582	CHEMBL334194,TP,ACT,1.0	CHEMBL301559,TN,INACT,0.0	CHEMBL100209,TP,ACT,1.0	CHEMBL3335535,TN,INACT,0.0	CHEMBL62804,TN,INACT,0.009999999776482582	CHEMBL1956200,FP,INACT,1.0	CHEMBL324652,TN,INACT,0.019999999552965164	CHEMBL93709,TP,ACT,0.9900000095367432	CHEMBL378859,TP,ACT,0.949999988079071	CHEMBL2030625,TP,ACT,0.8999999761581421	CHEMBL357983,TN,INACT,0.14000000059604645	CHEMBL63937,TN,INACT,0.0	CHEMBL542240,TP,ACT,0.9100000262260437	CHEMBL1160977,TP,ACT,1.0	CHEMBL305264,TP,ACT,1.0	CHEMBL291992,TN,INACT,0.0	CHEMBL3601045,TP,ACT,1.0	CHEMBL257643,FN,ACT,0.019999999552965164	CHEMBL112877,TN,INACT,0.0	CHEMBL158589,FN,ACT,0.5699999928474426	CHEMBL2205812,FN,ACT,0.07000000029802322	CHEMBL169594,TP,ACT,1.0	CHEMBL1091777,TN,INACT,0.7799999713897705	CHEMBL355475,TP,ACT,0.9900000095367432	CHEMBL349505,TN,INACT,0.0	CHEMBL392888,TN,INACT,0.0	CHEMBL61700,FN,ACT,0.05000000074505806	CHEMBL332320,TP,ACT,1.0	CHEMBL130835,FN,ACT,0.009999999776482582	CHEMBL268190,TN,INACT,0.05999999865889549	CHEMBL144385,TP,ACT,0.9399999976158142	CHEMBL74352,TP,ACT,1.0	CHEMBL2312386,TP,ACT,1.0	CHEMBL1743758,TN,INACT,0.6899999976158142	CHEMBL401694,TP,ACT,1.0	CHEMBL306462,FN,ACT,0.029999999329447746	CHEMBL202861,TN,INACT,0.15000000596046448	CHEMBL418411,TN,INACT,0.0	CHEMBL284672,TN,INACT,0.7400000095367432	CHEMBL386983,TP,ACT,0.9900000095367432	CHEMBL62660,TN,INACT,0.009999999776482582	CHEMBL527880,FP,INACT,0.9800000190734863	CHEMBL148129,TP,ACT,0.9800000190734863	CHEMBL54885,TN,INACT,0.0	CHEMBL537994,TN,INACT,0.25999999046325684	CHEMBL429450,TP,ACT,1.0	CHEMBL63290,TN,INACT,0.0	CHEMBL1275791,FP,INACT,1.0	CHEMBL275469,TN,INACT,0.41999998688697815	CHEMBL1923293,TN,INACT,0.25	CHEMBL389902,TN,INACT,0.0	CHEMBL451542,FN,ACT,0.0	CHEMBL3290986,FP,INACT,0.8799999952316284	CHEMBL31533,TN,INACT,0.0	CHEMBL3349055,TN,INACT,0.029999999329447746	CHEMBL365702,TP,ACT,0.8899999856948853	CHEMBL75217,TP,ACT,1.0	CHEMBL69648,TP,ACT,1.0	CHEMBL339069,TN,INACT,0.0	CHEMBL1940809,FP,INACT,0.9100000262260437	CHEMBL83,TP,ACT,1.0	CHEMBL3323005,TN,INACT,0.03999999910593033	CHEMBL3085032,FN,ACT,0.6499999761581421	CHEMBL329861,TN,INACT,0.0	CHEMBL1916635,TN,INACT,0.009999999776482582	CHEMBL135645,TP,ACT,0.9800000190734863	CHEMBL169553,FP,INACT,0.9200000166893005	CHEMBL477542,FN,ACT,0.019999999552965164	CHEMBL3354070,TP,ACT,1.0	CHEMBL449738,TN,INACT,0.0	CHEMBL342256,TN,INACT,0.029999999329447746	CHEMBL3746599,TP,ACT,1.0	CHEMBL234439,TP,ACT,1.0	CHEMBL331394,TN,INACT,0.0	CHEMBL3600972,TP,ACT,1.0	CHEMBL2376800,TN,INACT,0.009999999776482582	CHEMBL27384,FP,INACT,0.9900000095367432	CHEMBL1777826,TP,ACT,1.0	CHEMBL27673,FN,ACT,0.019999999552965164	CHEMBL412642,TN,INACT,0.0	CHEMBL375340,TP,ACT,1.0	CHEMBL2092951,TN,INACT,0.0	CHEMBL3765754,FN,ACT,0.1899999976158142	CHEMBL563666,TN,INACT,0.05999999865889549	CHEMBL330892,TP,ACT,1.0	CHEMBL2314767,TN,INACT,0.03999999910593033	CHEMBL302829,TN,INACT,0.009999999776482582	CHEMBL376057,TP,ACT,1.0	CHEMBL3084413,TP,ACT,1.0	CHEMBL556221,TP,ACT,1.0	CHEMBL146291,FN,ACT,0.800000011920929	CHEMBL106218,TP,ACT,0.9900000095367432	CHEMBL1172,TP,ACT,0.9900000095367432	CHEMBL69305,TP,ACT,1.0	CHEMBL429238,TN,INACT,0.7200000286102295	CHEMBL104693,TP,ACT,0.9900000095367432	CHEMBL3085033,TP,ACT,1.0	CHEMBL229390,TN,INACT,0.0	CHEMBL3745962,TP,ACT,1.0	CHEMBL574412,TN,INACT,0.05000000074505806	CHEMBL1098607,TN,INACT,0.10999999940395355	CHEMBL170922,TP,ACT,1.0	CHEMBL2443002,TN,INACT,0.05999999865889549	CHEMBL1478530,TN,INACT,0.38999998569488525	CHEMBL149763,TN,INACT,0.0	CHEMBL242345,FN,ACT,0.05999999865889549	CHEMBL328925,TN,INACT,0.12999999523162842	CHEMBL416747,FP,INACT,1.0	CHEMBL20168,TN,INACT,0.0	CHEMBL3618449,TP,ACT,1.0	CHEMBL130861,FP,INACT,0.9700000286102295	CHEMBL3115577,TN,INACT,0.12999999523162842	CHEMBL74342,TN,INACT,0.0	CHEMBL128585,TN,INACT,0.27000001072883606	CHEMBL145081,FN,ACT,0.7599999904632568	CHEMBL330885,FP,INACT,1.0	CHEMBL373888,TP,ACT,0.9399999976158142	CHEMBL453,TN,INACT,0.0	CHEMBL537834,FP,INACT,0.9900000095367432	CHEMBL78830,TN,INACT,0.0	CHEMBL490,FN,ACT,0.09000000357627869	CHEMBL164968,FP,INACT,0.8500000238418579	CHEMBL140746,TP,ACT,1.0	CHEMBL143468,TP,ACT,1.0	CHEMBL9967,TP,ACT,1.0	CHEMBL54050,TN,INACT,0.0	CHEMBL290715,TN,INACT,0.009999999776482582	CHEMBL308924,TN,INACT,0.0	CHEMBL58617,TN,INACT,0.0	CHEMBL119555,TN,INACT,0.0	CHEMBL85936,FN,ACT,0.05000000074505806	CHEMBL6966,TN,INACT,0.019999999552965164	CHEMBL281232,TN,INACT,0.0	CHEMBL170335,TN,INACT,0.009999999776482582	CHEMBL151619,TN,INACT,0.2800000011920929	CHEMBL42360,TN,INACT,0.0	CHEMBL303203,TN,INACT,0.0	CHEMBL544721,TN,INACT,0.25999999046325684	CHEMBL306903,FN,ACT,0.019999999552965164	CHEMBL508011,TN,INACT,0.6499999761581421	CHEMBL45160,TN,INACT,0.0	CHEMBL54002,TP,ACT,1.0	CHEMBL43788,FP,INACT,0.9399999976158142	CHEMBL467375,TN,INACT,0.0	CHEMBL23529,TN,INACT,0.05000000074505806	CHEMBL326742,TN,INACT,0.019999999552965164	CHEMBL407818,TN,INACT,0.0	CHEMBL3233666,FP,INACT,0.9700000286102295	CHEMBL7634,FN,ACT,0.5099999904632568	CHEMBL3618445,TP,ACT,1.0	CHEMBL539120,TP,ACT,1.0	CHEMBL172272,TP,ACT,1.0	CHEMBL549598,TP,ACT,1.0	CHEMBL2031737,FN,ACT,0.009999999776482582	CHEMBL2114058,TN,INACT,0.0	CHEMBL42219,TN,INACT,0.0	CHEMBL593861,TN,INACT,0.009999999776482582	CHEMBL2333862,TP,ACT,1.0	CHEMBL246794,FN,ACT,0.0	CHEMBL539334,TN,INACT,0.0	CHEMBL334093,TP,ACT,1.0	CHEMBL298649,TN,INACT,0.2800000011920929	CHEMBL481153,FN,ACT,0.6299999952316284	CHEMBL147653,TP,ACT,0.9900000095367432	CHEMBL314420,FN,ACT,0.05000000074505806	CHEMBL396845,TP,ACT,1.0	CHEMBL410890,TP,ACT,1.0	CHEMBL545506,FP,INACT,0.9200000166893005	CHEMBL86150,FP,INACT,1.0	CHEMBL66241,TN,INACT,0.23999999463558197	CHEMBL430587,TP,ACT,1.0	CHEMBL593448,TN,INACT,0.20000000298023224	CHEMBL92318,TN,INACT,0.0	CHEMBL14580,TP,ACT,1.0	CHEMBL3085028,TP,ACT,0.9900000095367432	CHEMBL96998,TN,INACT,0.0	CHEMBL73341,TP,ACT,1.0	CHEMBL95727,TN,INACT,0.10000000149011612	CHEMBL213709,FN,ACT,0.6700000166893005	CHEMBL150696,TN,INACT,0.5799999833106995	CHEMBL168855,FP,INACT,0.9800000190734863	CHEMBL169695,TP,ACT,0.949999988079071	CHEMBL328089,TN,INACT,0.0	CHEMBL561187,TP,ACT,1.0	CHEMBL444128,TN,INACT,0.019999999552965164	CHEMBL135489,TN,INACT,0.6899999976158142	CHEMBL303922,FN,ACT,0.03999999910593033	CHEMBL104172,TN,INACT,0.07000000029802322	CHEMBL3085215,TN,INACT,0.0	CHEMBL279453,TP,ACT,0.9800000190734863	CHEMBL404505,TN,INACT,0.7699999809265137	CHEMBL205654,FN,ACT,0.019999999552965164	CHEMBL364629,TN,INACT,0.0	CHEMBL2021969,FP,INACT,0.9800000190734863	CHEMBL2312368,FN,ACT,0.550000011920929	CHEMBL73245,TP,ACT,1.0	CHEMBL481415,TN,INACT,0.0	CHEMBL297690,TP,ACT,1.0	CHEMBL1770373,TP,ACT,0.9900000095367432	CHEMBL3084427,FP,INACT,0.949999988079071	CHEMBL356321,TP,ACT,1.0	CHEMBL328422,TN,INACT,0.0	CHEMBL327626,TN,INACT,0.03999999910593033	CHEMBL324685,TN,INACT,0.0	CHEMBL595022,TN,INACT,0.0	CHEMBL141051,TN,INACT,0.7599999904632568	CHEMBL72168,TN,INACT,0.1899999976158142	CHEMBL128360,TN,INACT,0.12999999523162842	CHEMBL3335537,TN,INACT,0.0	CHEMBL353304,TN,INACT,0.029999999329447746	CHEMBL110018,FP,INACT,0.9800000190734863	CHEMBL271774,FN,ACT,0.1599999964237213	CHEMBL72363,TP,ACT,1.0	CHEMBL84825,TN,INACT,0.6200000047683716	CHEMBL3765426,FN,ACT,0.019999999552965164	CHEMBL569089,TP,ACT,1.0	CHEMBL2314496,FP,INACT,1.0	CHEMBL3601043,FN,ACT,0.6299999952316284	CHEMBL538793,TP,ACT,0.9800000190734863	CHEMBL1113,FN,ACT,0.09000000357627869	CHEMBL120599,TP,ACT,1.0	CHEMBL1200604,FN,ACT,0.20000000298023224	CHEMBL68964,TN,INACT,0.009999999776482582	CHEMBL172234,TP,ACT,1.0	CHEMBL83874,TN,INACT,0.009999999776482582	CHEMBL16108,TN,INACT,0.0	CHEMBL240021,TN,INACT,0.0	CHEMBL257431,FN,ACT,0.10000000149011612	CHEMBL1097622,FP,INACT,0.9300000071525574	CHEMBL17045,TP,ACT,1.0	CHEMBL428561,FP,INACT,1.0	CHEMBL15936,TN,INACT,0.019999999552965164	CHEMBL72794,TP,ACT,0.9700000286102295	CHEMBL109778,TN,INACT,0.0	CHEMBL12529,TN,INACT,0.019999999552965164	CHEMBL22829,TP,ACT,1.0	CHEMBL391191,TN,INACT,0.0	CHEMBL121520,TP,ACT,1.0	CHEMBL171216,FN,ACT,0.019999999552965164	CHEMBL73164,TN,INACT,0.0	CHEMBL73234,TP,ACT,1.0	CHEMBL304961,TN,INACT,0.0	CHEMBL3618437,FN,ACT,0.5299999713897705	CHEMBL32688,TN,INACT,0.0	CHEMBL564515,FN,ACT,0.0	CHEMBL143466,TP,ACT,1.0	CHEMBL2443000,TN,INACT,0.25	CHEMBL431688,TP,ACT,1.0	CHEMBL43064,FN,ACT,0.009999999776482582	CHEMBL62247,TP,ACT,0.9599999785423279	CHEMBL726,TP,ACT,0.8999999761581421	CHEMBL219825,TP,ACT,1.0	CHEMBL296291,TN,INACT,0.0	CHEMBL1779037,TP,ACT,1.0	CHEMBL2112959,TP,ACT,0.9399999976158142	CHEMBL255791,FP,INACT,0.9900000095367432	CHEMBL3085031,TP,ACT,0.9700000286102295	CHEMBL294649,FN,ACT,0.009999999776482582	CHEMBL2111775,TN,INACT,0.0	CHEMBL52438,TN,INACT,0.0	CHEMBL168145,TP,ACT,0.9599999785423279	CHEMBL343449,TP,ACT,1.0	CHEMBL37736,TN,INACT,0.0	CHEMBL3084679,TP,ACT,1.0	CHEMBL3618446,TP,ACT,1.0	CHEMBL151668,TN,INACT,0.36000001430511475	CHEMBL563887,TP,ACT,1.0	CHEMBL593864,TN,INACT,0.0	CHEMBL69036,TN,INACT,0.009999999776482582	CHEMBL295651,TN,INACT,0.009999999776482582	CHEMBL53463,FN,ACT,0.05999999865889549	CHEMBL229443,TN,INACT,0.0	CHEMBL1381098,TN,INACT,0.03999999910593033	CHEMBL312551,TN,INACT,0.0	CHEMBL42359,TN,INACT,0.0	CHEMBL343659,TP,ACT,1.0	CHEMBL391307,TP,ACT,0.8600000143051147	CHEMBL119698,TN,INACT,0.12999999523162842	CHEMBL215189,TP,ACT,0.9900000095367432	CHEMBL48120,TN,INACT,0.6800000071525574	CHEMBL1938841,TN,INACT,0.0	CHEMBL1779135,TP,ACT,1.0	CHEMBL562890,FN,ACT,0.10999999940395355	CHEMBL156851,TN,INACT,0.0	CHEMBL106224,TP,ACT,1.0	CHEMBL52785,TN,INACT,0.019999999552965164	CHEMBL1779137,TP,ACT,1.0	CHEMBL402517,TN,INACT,0.05999999865889549	CHEMBL1622248,FP,INACT,0.9599999785423279	CHEMBL359027,FN,ACT,0.8100000023841858	CHEMBL58824,TP,ACT,0.9900000095367432	CHEMBL549986,TP,ACT,1.0	CHEMBL3121473,FN,ACT,0.019999999552965164	CHEMBL22962,TP,ACT,1.0	CHEMBL545363,TN,INACT,0.0	CHEMBL136429,TN,INACT,0.0	CHEMBL2377261,TP,ACT,1.0	CHEMBL2377388,TP,ACT,1.0	CHEMBL346194,TP,ACT,1.0	CHEMBL1258999,TN,INACT,0.0	CHEMBL965,TP,ACT,0.8899999856948853	CHEMBL241099,FP,INACT,1.0	CHEMBL553155,FP,INACT,0.9700000286102295	CHEMBL539621,TN,INACT,0.07999999821186066	CHEMBL2370509,TN,INACT,0.0	CHEMBL39922,FN,ACT,0.10999999940395355	CHEMBL147105,TP,ACT,1.0	CHEMBL2397392,TN,INACT,0.0	CHEMBL40554,FN,ACT,0.2199999988079071	CHEMBL2377269,TP,ACT,1.0	CHEMBL298203,TN,INACT,0.0	CHEMBL408395,TN,INACT,0.0	CHEMBL150365,FP,INACT,0.9800000190734863	CHEMBL355455,TP,ACT,1.0	CHEMBL257804,TN,INACT,0.8199999928474426	CHEMBL66322,TP,ACT,1.0	CHEMBL22278,TP,ACT,1.0	CHEMBL1090432,TP,ACT,0.9599999785423279	CHEMBL107681,TN,INACT,0.0	CHEMBL2335158,FN,ACT,0.0	CHEMBL129198,TN,INACT,0.0	CHEMBL515170,TN,INACT,0.0	CHEMBL356505,TP,ACT,0.9900000095367432	CHEMBL450463,TN,INACT,0.0	CHEMBL589,TN,INACT,0.0	CHEMBL1688981,TN,INACT,0.5400000214576721	CHEMBL1779043,TP,ACT,1.0	CHEMBL140789,TP,ACT,1.0	CHEMBL298286,TN,INACT,0.699999988079071	CHEMBL524097,TP,ACT,1.0	CHEMBL336033,TN,INACT,0.0	CHEMBL343236,TP,ACT,1.0	CHEMBL2333865,FN,ACT,0.10999999940395355	CHEMBL32301,TN,INACT,0.4099999964237213	CHEMBL15689,TN,INACT,0.10000000149011612	CHEMBL576663,TP,ACT,1.0	CHEMBL542877,TN,INACT,0.019999999552965164	CHEMBL76403,TN,INACT,0.0	CHEMBL1087367,TP,ACT,0.8500000238418579	CHEMBL277285,TN,INACT,0.0	CHEMBL37372,FN,ACT,0.3100000023841858	CHEMBL954,TP,ACT,1.0	CHEMBL569712,TP,ACT,1.0	CHEMBL104223,TN,INACT,0.6899999976158142	CHEMBL352618,TP,ACT,1.0	CHEMBL256121,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.0	CHEMBL2112955,TP,ACT,1.0	CHEMBL335971,TN,INACT,0.0	CHEMBL341759,TP,ACT,0.9900000095367432	CHEMBL272853,TN,INACT,0.0	CHEMBL170088,TP,ACT,1.0	CHEMBL323854,TN,INACT,0.05999999865889549	CHEMBL389629,TN,INACT,0.0	CHEMBL304950,TN,INACT,0.25	CHEMBL1078642,TN,INACT,0.0	CHEMBL215180,TP,ACT,1.0	CHEMBL3600830,TP,ACT,0.9700000286102295	CHEMBL85460,TP,ACT,0.9800000190734863	CHEMBL118241,TP,ACT,1.0	CHEMBL78137,TN,INACT,0.47999998927116394	CHEMBL320569,TN,INACT,0.0	CHEMBL1916491,TN,INACT,0.07000000029802322	CHEMBL258907,TP,ACT,0.8799999952316284	CHEMBL3618441,FN,ACT,0.7200000286102295	CHEMBL583027,TP,ACT,1.0	CHEMBL3704833,TN,INACT,0.07999999821186066	CHEMBL59597,TN,INACT,0.0	CHEMBL369359,TN,INACT,0.0	CHEMBL831,TP,ACT,1.0	CHEMBL434,TN,INACT,0.009999999776482582	CHEMBL602474,TN,INACT,0.0	CHEMBL549784,TP,ACT,1.0	CHEMBL1688979,TN,INACT,0.41999998688697815	CHEMBL296927,TN,INACT,0.0	CHEMBL2042553,TP,ACT,1.0	CHEMBL120581,TP,ACT,0.9900000095367432	CHEMBL1620339,TN,INACT,0.8299999833106995	CHEMBL302809,TP,ACT,1.0	CHEMBL2021989,TN,INACT,0.36000001430511475	CHEMBL14,TN,INACT,0.4300000071525574	CHEMBL145488,TP,ACT,1.0	CHEMBL42,TP,ACT,1.0	CHEMBL2311547,FP,INACT,1.0	CHEMBL63390,FP,INACT,0.9100000262260437	CHEMBL3218120,TN,INACT,0.0	CHEMBL3601040,TP,ACT,0.9900000095367432	CHEMBL3354069,TP,ACT,1.0	CHEMBL2377264,FN,ACT,0.7400000095367432	CHEMBL112297,FN,ACT,0.009999999776482582	CHEMBL551729,TP,ACT,0.8600000143051147	CHEMBL2312347,FP,INACT,1.0	CHEMBL40966,TN,INACT,0.28999999165534973	CHEMBL25649,TN,INACT,0.7599999904632568	CHEMBL395110,TP,ACT,0.9700000286102295	CHEMBL6638,FP,INACT,0.9700000286102295	CHEMBL401971,TP,ACT,0.9800000190734863	CHEMBL553361,TN,INACT,0.0	CHEMBL71907,TN,INACT,0.10000000149011612	CHEMBL174632,TN,INACT,0.03999999910593033	CHEMBL332181,FN,ACT,0.7599999904632568	CHEMBL553602,TN,INACT,0.0	CHEMBL91073,TN,INACT,0.029999999329447746	CHEMBL27979,FN,ACT,0.2199999988079071	CHEMBL3629537,TP,ACT,0.9900000095367432	CHEMBL541671,TP,ACT,1.0	CHEMBL441305,FP,INACT,1.0	CHEMBL144434,FN,ACT,0.6700000166893005	CHEMBL323175,TN,INACT,0.0	CHEMBL304888,TN,INACT,0.0	CHEMBL76897,TP,ACT,1.0	CHEMBL168632,TN,INACT,0.09000000357627869	CHEMBL252258,FN,ACT,0.6399999856948853	CHEMBL301670,TP,ACT,1.0	

