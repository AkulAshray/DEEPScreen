ImageNetInceptionV2 CHEMBL3529 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	183
Number of inactive compounds :	183
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3529_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3529_adam_0.0005_30_0.8/
---------------------------------
Training samples: 213
Validation samples: 67
--
Training Step: 1  | time: 35.356s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/213
[A[ATraining Step: 2  | total loss: [1m[32m0.60826[0m[0m | time: 43.289s
[2K
| Adam | epoch: 001 | loss: 0.60826 - acc: 0.5062 -- iter: 064/213
[A[ATraining Step: 3  | total loss: [1m[32m0.53593[0m[0m | time: 51.322s
[2K
| Adam | epoch: 001 | loss: 0.53593 - acc: 0.7057 -- iter: 096/213
[A[ATraining Step: 4  | total loss: [1m[32m1.02902[0m[0m | time: 59.232s
[2K
| Adam | epoch: 001 | loss: 1.02902 - acc: 0.5983 -- iter: 128/213
[A[ATraining Step: 5  | total loss: [1m[32m0.85819[0m[0m | time: 67.048s
[2K
| Adam | epoch: 001 | loss: 0.85819 - acc: 0.6817 -- iter: 160/213
[A[ATraining Step: 6  | total loss: [1m[32m0.74635[0m[0m | time: 74.808s
[2K
| Adam | epoch: 001 | loss: 0.74635 - acc: 0.6653 -- iter: 192/213
[A[ATraining Step: 7  | total loss: [1m[32m0.70046[0m[0m | time: 89.157s
[2K
| Adam | epoch: 001 | loss: 0.70046 - acc: 0.6036 | val_loss: 0.84125 - val_acc: 0.5672 -- iter: 213/213
--
Training Step: 8  | total loss: [1m[32m0.57080[0m[0m | time: 5.721s
[2K
| Adam | epoch: 002 | loss: 0.57080 - acc: 0.7730 -- iter: 032/213
[A[ATraining Step: 9  | total loss: [1m[32m0.40025[0m[0m | time: 13.682s
[2K
| Adam | epoch: 002 | loss: 0.40025 - acc: 0.8932 -- iter: 064/213
[A[ATraining Step: 10  | total loss: [1m[32m0.35117[0m[0m | time: 21.797s
[2K
| Adam | epoch: 002 | loss: 0.35117 - acc: 0.8997 -- iter: 096/213
[A[ATraining Step: 11  | total loss: [1m[32m0.28936[0m[0m | time: 29.631s
[2K
| Adam | epoch: 002 | loss: 0.28936 - acc: 0.9176 -- iter: 128/213
[A[ATraining Step: 12  | total loss: [1m[32m0.30403[0m[0m | time: 37.418s
[2K
| Adam | epoch: 002 | loss: 0.30403 - acc: 0.8703 -- iter: 160/213
[A[ATraining Step: 13  | total loss: [1m[32m0.33427[0m[0m | time: 45.271s
[2K
| Adam | epoch: 002 | loss: 0.33427 - acc: 0.8188 -- iter: 192/213
[A[ATraining Step: 14  | total loss: [1m[32m0.37358[0m[0m | time: 56.099s
[2K
| Adam | epoch: 002 | loss: 0.37358 - acc: 0.8290 | val_loss: 1.55983 - val_acc: 0.4328 -- iter: 213/213
--
Training Step: 15  | total loss: [1m[32m0.34431[0m[0m | time: 5.660s
[2K
| Adam | epoch: 003 | loss: 0.34431 - acc: 0.8714 -- iter: 032/213
[A[ATraining Step: 16  | total loss: [1m[32m0.29866[0m[0m | time: 11.431s
[2K
| Adam | epoch: 003 | loss: 0.29866 - acc: 0.8839 -- iter: 064/213
[A[ATraining Step: 17  | total loss: [1m[32m0.20733[0m[0m | time: 19.391s
[2K
| Adam | epoch: 003 | loss: 0.20733 - acc: 0.9257 -- iter: 096/213
[A[ATraining Step: 18  | total loss: [1m[32m0.20743[0m[0m | time: 27.265s
[2K
| Adam | epoch: 003 | loss: 0.20743 - acc: 0.9298 -- iter: 128/213
[A[ATraining Step: 19  | total loss: [1m[32m0.22924[0m[0m | time: 35.082s
[2K
| Adam | epoch: 003 | loss: 0.22924 - acc: 0.9115 -- iter: 160/213
[A[ATraining Step: 20  | total loss: [1m[32m0.25892[0m[0m | time: 43.095s
[2K
| Adam | epoch: 003 | loss: 0.25892 - acc: 0.9199 -- iter: 192/213
[A[ATraining Step: 21  | total loss: [1m[32m0.23467[0m[0m | time: 54.194s
[2K
| Adam | epoch: 003 | loss: 0.23467 - acc: 0.9156 | val_loss: 3.00918 - val_acc: 0.4328 -- iter: 213/213
--
Training Step: 22  | total loss: [1m[32m0.21155[0m[0m | time: 8.017s
[2K
| Adam | epoch: 004 | loss: 0.21155 - acc: 0.9316 -- iter: 032/213
[A[ATraining Step: 23  | total loss: [1m[32m0.19636[0m[0m | time: 13.637s
[2K
| Adam | epoch: 004 | loss: 0.19636 - acc: 0.9242 -- iter: 064/213
[A[ATraining Step: 24  | total loss: [1m[32m0.23816[0m[0m | time: 19.444s
[2K
| Adam | epoch: 004 | loss: 0.23816 - acc: 0.9188 -- iter: 096/213
[A[ATraining Step: 25  | total loss: [1m[32m0.18036[0m[0m | time: 27.169s
[2K
| Adam | epoch: 004 | loss: 0.18036 - acc: 0.9409 -- iter: 128/213
[A[ATraining Step: 26  | total loss: [1m[32m0.16605[0m[0m | time: 35.041s
[2K
| Adam | epoch: 004 | loss: 0.16605 - acc: 0.9483 -- iter: 160/213
[A[ATraining Step: 27  | total loss: [1m[32m0.14817[0m[0m | time: 42.827s
[2K
| Adam | epoch: 004 | loss: 0.14817 - acc: 0.9535 -- iter: 192/213
[A[ATraining Step: 28  | total loss: [1m[32m0.11550[0m[0m | time: 53.895s
[2K
| Adam | epoch: 004 | loss: 0.11550 - acc: 0.9652 | val_loss: 0.75450 - val_acc: 0.4478 -- iter: 213/213
--
Training Step: 29  | total loss: [1m[32m0.09521[0m[0m | time: 7.877s
[2K
| Adam | epoch: 005 | loss: 0.09521 - acc: 0.9736 -- iter: 032/213
[A[ATraining Step: 30  | total loss: [1m[32m0.07578[0m[0m | time: 15.759s
[2K
| Adam | epoch: 005 | loss: 0.07578 - acc: 0.9799 -- iter: 064/213
[A[ATraining Step: 31  | total loss: [1m[32m0.07861[0m[0m | time: 21.372s
[2K
| Adam | epoch: 005 | loss: 0.07861 - acc: 0.9773 -- iter: 096/213
[A[ATraining Step: 32  | total loss: [1m[32m0.07269[0m[0m | time: 27.255s
[2K
| Adam | epoch: 005 | loss: 0.07269 - acc: 0.9717 -- iter: 128/213
[A[ATraining Step: 33  | total loss: [1m[32m0.05810[0m[0m | time: 35.224s
[2K
| Adam | epoch: 005 | loss: 0.05810 - acc: 0.9779 -- iter: 160/213
[A[ATraining Step: 34  | total loss: [1m[32m0.04741[0m[0m | time: 43.443s
[2K
| Adam | epoch: 005 | loss: 0.04741 - acc: 0.9826 -- iter: 192/213
[A[ATraining Step: 35  | total loss: [1m[32m0.04341[0m[0m | time: 54.645s
[2K
| Adam | epoch: 005 | loss: 0.04341 - acc: 0.9863 | val_loss: 0.79474 - val_acc: 0.5672 -- iter: 213/213
--
Training Step: 36  | total loss: [1m[32m0.04177[0m[0m | time: 8.018s
[2K
| Adam | epoch: 006 | loss: 0.04177 - acc: 0.9891 -- iter: 032/213
[A[ATraining Step: 37  | total loss: [1m[32m0.04082[0m[0m | time: 16.130s
[2K
| Adam | epoch: 006 | loss: 0.04082 - acc: 0.9913 -- iter: 064/213
[A[ATraining Step: 38  | total loss: [1m[32m0.04331[0m[0m | time: 24.013s
[2K
| Adam | epoch: 006 | loss: 0.04331 - acc: 0.9869 -- iter: 096/213
[A[ATraining Step: 39  | total loss: [1m[32m0.03605[0m[0m | time: 29.702s
[2K
| Adam | epoch: 006 | loss: 0.03605 - acc: 0.9894 -- iter: 128/213
[A[ATraining Step: 40  | total loss: [1m[32m0.03340[0m[0m | time: 35.285s
[2K
| Adam | epoch: 006 | loss: 0.03340 - acc: 0.9914 -- iter: 160/213
[A[ATraining Step: 41  | total loss: [1m[32m0.02848[0m[0m | time: 43.310s
[2K
| Adam | epoch: 006 | loss: 0.02848 - acc: 0.9930 -- iter: 192/213
[A[ATraining Step: 42  | total loss: [1m[32m0.04471[0m[0m | time: 54.425s
[2K
| Adam | epoch: 006 | loss: 0.04471 - acc: 0.9830 | val_loss: 2.79922 - val_acc: 0.5672 -- iter: 213/213
--
Training Step: 43  | total loss: [1m[32m0.03983[0m[0m | time: 7.989s
[2K
| Adam | epoch: 007 | loss: 0.03983 - acc: 0.9860 -- iter: 032/213
[A[ATraining Step: 44  | total loss: [1m[32m0.03452[0m[0m | time: 16.090s
[2K
| Adam | epoch: 007 | loss: 0.03452 - acc: 0.9884 -- iter: 064/213
[A[ATraining Step: 45  | total loss: [1m[32m0.03377[0m[0m | time: 24.095s
[2K
| Adam | epoch: 007 | loss: 0.03377 - acc: 0.9851 -- iter: 096/213
[A[ATraining Step: 46  | total loss: [1m[32m0.03330[0m[0m | time: 32.326s
[2K
| Adam | epoch: 007 | loss: 0.03330 - acc: 0.9876 -- iter: 128/213
[A[ATraining Step: 47  | total loss: [1m[32m0.05220[0m[0m | time: 37.990s
[2K
| Adam | epoch: 007 | loss: 0.05220 - acc: 0.9845 -- iter: 160/213
[A[ATraining Step: 48  | total loss: [1m[32m0.04483[0m[0m | time: 43.490s
[2K
| Adam | epoch: 007 | loss: 0.04483 - acc: 0.9870 -- iter: 192/213
[A[ATraining Step: 49  | total loss: [1m[32m0.03915[0m[0m | time: 54.822s
[2K
| Adam | epoch: 007 | loss: 0.03915 - acc: 0.9890 | val_loss: 4.34772 - val_acc: 0.5672 -- iter: 213/213
--
Training Step: 50  | total loss: [1m[32m0.07905[0m[0m | time: 8.076s
[2K
| Adam | epoch: 008 | loss: 0.07905 - acc: 0.9810 -- iter: 032/213
[A[ATraining Step: 51  | total loss: [1m[32m0.07372[0m[0m | time: 16.166s
[2K
| Adam | epoch: 008 | loss: 0.07372 - acc: 0.9839 -- iter: 064/213
[A[ATraining Step: 52  | total loss: [1m[32m0.06428[0m[0m | time: 24.251s
[2K
| Adam | epoch: 008 | loss: 0.06428 - acc: 0.9863 -- iter: 096/213
[A[ATraining Step: 53  | total loss: [1m[32m0.07783[0m[0m | time: 32.262s
[2K
| Adam | epoch: 008 | loss: 0.07783 - acc: 0.9791 -- iter: 128/213
[A[ATraining Step: 54  | total loss: [1m[32m0.06842[0m[0m | time: 40.311s
[2K
| Adam | epoch: 008 | loss: 0.06842 - acc: 0.9822 -- iter: 160/213
[A[ATraining Step: 55  | total loss: [1m[32m0.06129[0m[0m | time: 45.957s
[2K
| Adam | epoch: 008 | loss: 0.06129 - acc: 0.9847 -- iter: 192/213
[A[ATraining Step: 56  | total loss: [1m[32m0.11630[0m[0m | time: 54.809s
[2K
| Adam | epoch: 008 | loss: 0.11630 - acc: 0.9802 | val_loss: 4.17919 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 57  | total loss: [1m[32m0.10547[0m[0m | time: 8.066s
[2K
| Adam | epoch: 009 | loss: 0.10547 - acc: 0.9829 -- iter: 032/213
[A[ATraining Step: 58  | total loss: [1m[32m0.09179[0m[0m | time: 16.270s
[2K
| Adam | epoch: 009 | loss: 0.09179 - acc: 0.9852 -- iter: 064/213
[A[ATraining Step: 59  | total loss: [1m[32m0.08613[0m[0m | time: 24.389s
[2K
| Adam | epoch: 009 | loss: 0.08613 - acc: 0.9830 -- iter: 096/213
[A[ATraining Step: 60  | total loss: [1m[32m0.09964[0m[0m | time: 32.501s
[2K
| Adam | epoch: 009 | loss: 0.09964 - acc: 0.9770 -- iter: 128/213
[A[ATraining Step: 61  | total loss: [1m[32m0.11924[0m[0m | time: 40.679s
[2K
| Adam | epoch: 009 | loss: 0.11924 - acc: 0.9759 -- iter: 160/213
[A[ATraining Step: 62  | total loss: [1m[32m0.10780[0m[0m | time: 48.546s
[2K
| Adam | epoch: 009 | loss: 0.10780 - acc: 0.9790 -- iter: 192/213
[A[ATraining Step: 63  | total loss: [1m[32m0.12349[0m[0m | time: 57.088s
[2K
| Adam | epoch: 009 | loss: 0.12349 - acc: 0.9777 | val_loss: 1.32004 - val_acc: 0.5970 -- iter: 213/213
--
Training Step: 64  | total loss: [1m[32m0.21608[0m[0m | time: 5.686s
[2K
| Adam | epoch: 010 | loss: 0.21608 - acc: 0.9686 -- iter: 032/213
[A[ATraining Step: 65  | total loss: [1m[32m0.20754[0m[0m | time: 13.696s
[2K
| Adam | epoch: 010 | loss: 0.20754 - acc: 0.9666 -- iter: 064/213
[A[ATraining Step: 66  | total loss: [1m[32m0.19271[0m[0m | time: 21.661s
[2K
| Adam | epoch: 010 | loss: 0.19271 - acc: 0.9707 -- iter: 096/213
[A[ATraining Step: 67  | total loss: [1m[32m0.18509[0m[0m | time: 29.668s
[2K
| Adam | epoch: 010 | loss: 0.18509 - acc: 0.9704 -- iter: 128/213
[A[ATraining Step: 68  | total loss: [1m[32m0.17631[0m[0m | time: 37.915s
[2K
| Adam | epoch: 010 | loss: 0.17631 - acc: 0.9665 -- iter: 160/213
[A[ATraining Step: 69  | total loss: [1m[32m0.17095[0m[0m | time: 46.065s
[2K
| Adam | epoch: 010 | loss: 0.17095 - acc: 0.9668 -- iter: 192/213
[A[ATraining Step: 70  | total loss: [1m[32m0.16612[0m[0m | time: 57.309s
[2K
| Adam | epoch: 010 | loss: 0.16612 - acc: 0.9634 | val_loss: 4.14998 - val_acc: 0.4328 -- iter: 213/213
--
Training Step: 71  | total loss: [1m[32m0.15351[0m[0m | time: 5.591s
[2K
| Adam | epoch: 011 | loss: 0.15351 - acc: 0.9676 -- iter: 032/213
[A[ATraining Step: 72  | total loss: [1m[32m0.17047[0m[0m | time: 11.133s
[2K
| Adam | epoch: 011 | loss: 0.17047 - acc: 0.9659 -- iter: 064/213
[A[ATraining Step: 73  | total loss: [1m[32m0.15281[0m[0m | time: 19.356s
[2K
| Adam | epoch: 011 | loss: 0.15281 - acc: 0.9697 -- iter: 096/213
[A[ATraining Step: 74  | total loss: [1m[32m0.14055[0m[0m | time: 27.382s
[2K
| Adam | epoch: 011 | loss: 0.14055 - acc: 0.9696 -- iter: 128/213
[A[ATraining Step: 75  | total loss: [1m[32m0.13822[0m[0m | time: 35.449s
[2K
| Adam | epoch: 011 | loss: 0.13822 - acc: 0.9661 -- iter: 160/213
[A[ATraining Step: 76  | total loss: [1m[32m0.12741[0m[0m | time: 43.577s
[2K
| Adam | epoch: 011 | loss: 0.12741 - acc: 0.9697 -- iter: 192/213
[A[ATraining Step: 77  | total loss: [1m[32m0.12991[0m[0m | time: 54.817s
[2K
| Adam | epoch: 011 | loss: 0.12991 - acc: 0.9630 | val_loss: 0.53019 - val_acc: 0.7910 -- iter: 213/213
--
Training Step: 78  | total loss: [1m[32m0.13582[0m[0m | time: 8.171s
[2K
| Adam | epoch: 012 | loss: 0.13582 - acc: 0.9636 -- iter: 032/213
[A[ATraining Step: 79  | total loss: [1m[32m0.12453[0m[0m | time: 13.729s
[2K
| Adam | epoch: 012 | loss: 0.12453 - acc: 0.9674 -- iter: 064/213
[A[ATraining Step: 80  | total loss: [1m[32m0.18275[0m[0m | time: 19.321s
[2K
| Adam | epoch: 012 | loss: 0.18275 - acc: 0.9610 -- iter: 096/213
[A[ATraining Step: 81  | total loss: [1m[32m0.17052[0m[0m | time: 27.504s
[2K
| Adam | epoch: 012 | loss: 0.17052 - acc: 0.9649 -- iter: 128/213
[A[ATraining Step: 82  | total loss: [1m[32m0.16138[0m[0m | time: 35.557s
[2K
| Adam | epoch: 012 | loss: 0.16138 - acc: 0.9684 -- iter: 160/213
[A[ATraining Step: 83  | total loss: [1m[32m0.14793[0m[0m | time: 43.601s
[2K
| Adam | epoch: 012 | loss: 0.14793 - acc: 0.9716 -- iter: 192/213
[A[ATraining Step: 84  | total loss: [1m[32m0.13730[0m[0m | time: 54.828s
[2K
| Adam | epoch: 012 | loss: 0.13730 - acc: 0.9713 | val_loss: 1.23310 - val_acc: 0.6269 -- iter: 213/213
--
Training Step: 85  | total loss: [1m[32m0.14683[0m[0m | time: 8.322s
[2K
| Adam | epoch: 013 | loss: 0.14683 - acc: 0.9679 -- iter: 032/213
[A[ATraining Step: 86  | total loss: [1m[32m0.13522[0m[0m | time: 16.586s
[2K
| Adam | epoch: 013 | loss: 0.13522 - acc: 0.9711 -- iter: 064/213
[A[ATraining Step: 87  | total loss: [1m[32m0.12295[0m[0m | time: 22.214s
[2K
| Adam | epoch: 013 | loss: 0.12295 - acc: 0.9740 -- iter: 096/213
[A[ATraining Step: 88  | total loss: [1m[32m0.14865[0m[0m | time: 27.778s
[2K
| Adam | epoch: 013 | loss: 0.14865 - acc: 0.9718 -- iter: 128/213
[A[ATraining Step: 89  | total loss: [1m[32m0.13473[0m[0m | time: 35.947s
[2K
| Adam | epoch: 013 | loss: 0.13473 - acc: 0.9747 -- iter: 160/213
[A[ATraining Step: 90  | total loss: [1m[32m0.12320[0m[0m | time: 44.081s
[2K
| Adam | epoch: 013 | loss: 0.12320 - acc: 0.9772 -- iter: 192/213
[A[ATraining Step: 91  | total loss: [1m[32m0.12138[0m[0m | time: 55.246s
[2K
| Adam | epoch: 013 | loss: 0.12138 - acc: 0.9764 | val_loss: 1.42785 - val_acc: 0.6119 -- iter: 213/213
--
Training Step: 92  | total loss: [1m[32m0.11354[0m[0m | time: 8.300s
[2K
| Adam | epoch: 014 | loss: 0.11354 - acc: 0.9756 -- iter: 032/213
[A[ATraining Step: 93  | total loss: [1m[32m0.11270[0m[0m | time: 16.549s
[2K
| Adam | epoch: 014 | loss: 0.11270 - acc: 0.9749 -- iter: 064/213
[A[ATraining Step: 94  | total loss: [1m[32m0.10302[0m[0m | time: 24.858s
[2K
| Adam | epoch: 014 | loss: 0.10302 - acc: 0.9774 -- iter: 096/213
[A[ATraining Step: 95  | total loss: [1m[32m0.12268[0m[0m | time: 30.422s
[2K
| Adam | epoch: 014 | loss: 0.12268 - acc: 0.9703 -- iter: 128/213
[A[ATraining Step: 96  | total loss: [1m[32m0.13596[0m[0m | time: 35.943s
[2K
| Adam | epoch: 014 | loss: 0.13596 - acc: 0.9685 -- iter: 160/213
[A[ATraining Step: 97  | total loss: [1m[32m0.12342[0m[0m | time: 44.172s
[2K
| Adam | epoch: 014 | loss: 0.12342 - acc: 0.9717 -- iter: 192/213
[A[ATraining Step: 98  | total loss: [1m[32m0.11459[0m[0m | time: 55.290s
[2K
| Adam | epoch: 014 | loss: 0.11459 - acc: 0.9745 | val_loss: 2.91504 - val_acc: 0.4328 -- iter: 213/213
--
Training Step: 99  | total loss: [1m[32m0.10635[0m[0m | time: 8.054s
[2K
| Adam | epoch: 015 | loss: 0.10635 - acc: 0.9770 -- iter: 032/213
[A[ATraining Step: 100  | total loss: [1m[32m0.11513[0m[0m | time: 16.441s
[2K
| Adam | epoch: 015 | loss: 0.11513 - acc: 0.9762 -- iter: 064/213
[A[ATraining Step: 101  | total loss: [1m[32m0.10594[0m[0m | time: 24.734s
[2K
| Adam | epoch: 015 | loss: 0.10594 - acc: 0.9786 -- iter: 096/213
[A[ATraining Step: 102  | total loss: [1m[32m0.10209[0m[0m | time: 33.067s
[2K
| Adam | epoch: 015 | loss: 0.10209 - acc: 0.9807 -- iter: 128/213
[A[ATraining Step: 103  | total loss: [1m[32m0.09654[0m[0m | time: 38.656s
[2K
| Adam | epoch: 015 | loss: 0.09654 - acc: 0.9827 -- iter: 160/213
[A[ATraining Step: 104  | total loss: [1m[32m0.09043[0m[0m | time: 44.296s
[2K
| Adam | epoch: 015 | loss: 0.09043 - acc: 0.9844 -- iter: 192/213
[A[ATraining Step: 105  | total loss: [1m[32m0.08361[0m[0m | time: 55.448s
[2K
| Adam | epoch: 015 | loss: 0.08361 - acc: 0.9860 | val_loss: 2.79976 - val_acc: 0.4776 -- iter: 213/213
--
Training Step: 106  | total loss: [1m[32m0.07631[0m[0m | time: 8.425s
[2K
| Adam | epoch: 016 | loss: 0.07631 - acc: 0.9874 -- iter: 032/213
[A[ATraining Step: 107  | total loss: [1m[32m0.07053[0m[0m | time: 16.701s
[2K
| Adam | epoch: 016 | loss: 0.07053 - acc: 0.9886 -- iter: 064/213
[A[ATraining Step: 108  | total loss: [1m[32m0.07310[0m[0m | time: 24.934s
[2K
| Adam | epoch: 016 | loss: 0.07310 - acc: 0.9866 -- iter: 096/213
[A[ATraining Step: 109  | total loss: [1m[32m0.06639[0m[0m | time: 33.089s
[2K
| Adam | epoch: 016 | loss: 0.06639 - acc: 0.9880 -- iter: 128/213
[A[ATraining Step: 110  | total loss: [1m[32m0.06305[0m[0m | time: 41.307s
[2K
| Adam | epoch: 016 | loss: 0.06305 - acc: 0.9892 -- iter: 160/213
[A[ATraining Step: 111  | total loss: [1m[32m0.05818[0m[0m | time: 46.791s
[2K
| Adam | epoch: 016 | loss: 0.05818 - acc: 0.9903 -- iter: 192/213
[A[ATraining Step: 112  | total loss: [1m[32m0.07894[0m[0m | time: 55.425s
[2K
| Adam | epoch: 016 | loss: 0.07894 - acc: 0.9865 | val_loss: 1.91678 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 113  | total loss: [1m[32m0.07321[0m[0m | time: 8.114s
[2K
| Adam | epoch: 017 | loss: 0.07321 - acc: 0.9878 -- iter: 032/213
[A[ATraining Step: 114  | total loss: [1m[32m0.06681[0m[0m | time: 16.165s
[2K
| Adam | epoch: 017 | loss: 0.06681 - acc: 0.9890 -- iter: 064/213
[A[ATraining Step: 115  | total loss: [1m[32m0.06130[0m[0m | time: 24.216s
[2K
| Adam | epoch: 017 | loss: 0.06130 - acc: 0.9901 -- iter: 096/213
[A[ATraining Step: 116  | total loss: [1m[32m0.06165[0m[0m | time: 32.367s
[2K
| Adam | epoch: 017 | loss: 0.06165 - acc: 0.9911 -- iter: 128/213
[A[ATraining Step: 117  | total loss: [1m[32m0.05722[0m[0m | time: 40.399s
[2K
| Adam | epoch: 017 | loss: 0.05722 - acc: 0.9920 -- iter: 160/213
[A[ATraining Step: 118  | total loss: [1m[32m0.07869[0m[0m | time: 48.620s
[2K
| Adam | epoch: 017 | loss: 0.07869 - acc: 0.9897 -- iter: 192/213
[A[ATraining Step: 119  | total loss: [1m[32m0.07126[0m[0m | time: 57.206s
[2K
| Adam | epoch: 017 | loss: 0.07126 - acc: 0.9907 | val_loss: 0.71713 - val_acc: 0.8060 -- iter: 213/213
--
Training Step: 120  | total loss: [1m[32m0.06504[0m[0m | time: 5.763s
[2K
| Adam | epoch: 018 | loss: 0.06504 - acc: 0.9916 -- iter: 032/213
[A[ATraining Step: 121  | total loss: [1m[32m0.05933[0m[0m | time: 14.043s
[2K
| Adam | epoch: 018 | loss: 0.05933 - acc: 0.9925 -- iter: 064/213
[A[ATraining Step: 122  | total loss: [1m[32m0.05409[0m[0m | time: 22.239s
[2K
| Adam | epoch: 018 | loss: 0.05409 - acc: 0.9932 -- iter: 096/213
[A[ATraining Step: 123  | total loss: [1m[32m0.04934[0m[0m | time: 30.238s
[2K
| Adam | epoch: 018 | loss: 0.04934 - acc: 0.9939 -- iter: 128/213
[A[ATraining Step: 124  | total loss: [1m[32m0.04496[0m[0m | time: 38.537s
[2K
| Adam | epoch: 018 | loss: 0.04496 - acc: 0.9945 -- iter: 160/213
[A[ATraining Step: 125  | total loss: [1m[32m0.04467[0m[0m | time: 46.908s
[2K
| Adam | epoch: 018 | loss: 0.04467 - acc: 0.9951 -- iter: 192/213
[A[ATraining Step: 126  | total loss: [1m[32m0.04114[0m[0m | time: 58.139s
[2K
| Adam | epoch: 018 | loss: 0.04114 - acc: 0.9956 | val_loss: 0.54381 - val_acc: 0.7313 -- iter: 213/213
--
Training Step: 127  | total loss: [1m[32m0.05322[0m[0m | time: 5.722s
[2K
| Adam | epoch: 019 | loss: 0.05322 - acc: 0.9929 -- iter: 032/213
[A[ATraining Step: 128  | total loss: [1m[32m0.06973[0m[0m | time: 11.304s
[2K
| Adam | epoch: 019 | loss: 0.06973 - acc: 0.9888 -- iter: 064/213
[A[ATraining Step: 129  | total loss: [1m[32m0.07371[0m[0m | time: 19.479s
[2K
| Adam | epoch: 019 | loss: 0.07371 - acc: 0.9852 -- iter: 096/213
[A[ATraining Step: 130  | total loss: [1m[32m0.06756[0m[0m | time: 27.691s
[2K
| Adam | epoch: 019 | loss: 0.06756 - acc: 0.9867 -- iter: 128/213
[A[ATraining Step: 131  | total loss: [1m[32m0.06303[0m[0m | time: 35.751s
[2K
| Adam | epoch: 019 | loss: 0.06303 - acc: 0.9880 -- iter: 160/213
[A[ATraining Step: 132  | total loss: [1m[32m0.05956[0m[0m | time: 44.018s
[2K
| Adam | epoch: 019 | loss: 0.05956 - acc: 0.9892 -- iter: 192/213
[A[ATraining Step: 133  | total loss: [1m[32m0.05527[0m[0m | time: 55.208s
[2K
| Adam | epoch: 019 | loss: 0.05527 - acc: 0.9903 | val_loss: 1.42911 - val_acc: 0.5821 -- iter: 213/213
--
Training Step: 134  | total loss: [1m[32m0.05832[0m[0m | time: 8.025s
[2K
| Adam | epoch: 020 | loss: 0.05832 - acc: 0.9850 -- iter: 032/213
[A[ATraining Step: 135  | total loss: [1m[32m0.06277[0m[0m | time: 13.644s
[2K
| Adam | epoch: 020 | loss: 0.06277 - acc: 0.9834 -- iter: 064/213
[A[ATraining Step: 136  | total loss: [1m[32m0.10654[0m[0m | time: 19.338s
[2K
| Adam | epoch: 020 | loss: 0.10654 - acc: 0.9803 -- iter: 096/213
[A[ATraining Step: 137  | total loss: [1m[32m0.09788[0m[0m | time: 27.598s
[2K
| Adam | epoch: 020 | loss: 0.09788 - acc: 0.9822 -- iter: 128/213
[A[ATraining Step: 138  | total loss: [1m[32m0.08924[0m[0m | time: 35.619s
[2K
| Adam | epoch: 020 | loss: 0.08924 - acc: 0.9840 -- iter: 160/213
[A[ATraining Step: 139  | total loss: [1m[32m0.09684[0m[0m | time: 43.778s
[2K
| Adam | epoch: 020 | loss: 0.09684 - acc: 0.9825 -- iter: 192/213
[A[ATraining Step: 140  | total loss: [1m[32m0.08807[0m[0m | time: 54.989s
[2K
| Adam | epoch: 020 | loss: 0.08807 - acc: 0.9842 | val_loss: 0.75224 - val_acc: 0.8358 -- iter: 213/213
--
Training Step: 141  | total loss: [1m[32m0.08327[0m[0m | time: 8.255s
[2K
| Adam | epoch: 021 | loss: 0.08327 - acc: 0.9858 -- iter: 032/213
[A[ATraining Step: 142  | total loss: [1m[32m0.07816[0m[0m | time: 16.274s
[2K
| Adam | epoch: 021 | loss: 0.07816 - acc: 0.9872 -- iter: 064/213
[A[ATraining Step: 143  | total loss: [1m[32m0.07574[0m[0m | time: 21.894s
[2K
| Adam | epoch: 021 | loss: 0.07574 - acc: 0.9854 -- iter: 096/213
[A[ATraining Step: 144  | total loss: [1m[32m0.09479[0m[0m | time: 27.470s
[2K
| Adam | epoch: 021 | loss: 0.09479 - acc: 0.9821 -- iter: 128/213
[A[ATraining Step: 145  | total loss: [1m[32m0.08656[0m[0m | time: 35.523s
[2K
| Adam | epoch: 021 | loss: 0.08656 - acc: 0.9839 -- iter: 160/213
[A[ATraining Step: 146  | total loss: [1m[32m0.07885[0m[0m | time: 43.603s
[2K
| Adam | epoch: 021 | loss: 0.07885 - acc: 0.9855 -- iter: 192/213
[A[ATraining Step: 147  | total loss: [1m[32m0.07670[0m[0m | time: 54.817s
[2K
| Adam | epoch: 021 | loss: 0.07670 - acc: 0.9838 | val_loss: 0.45474 - val_acc: 0.8060 -- iter: 213/213
--
Training Step: 148  | total loss: [1m[32m0.07043[0m[0m | time: 8.060s
[2K
| Adam | epoch: 022 | loss: 0.07043 - acc: 0.9854 -- iter: 032/213
[A[ATraining Step: 149  | total loss: [1m[32m0.08339[0m[0m | time: 16.323s
[2K
| Adam | epoch: 022 | loss: 0.08339 - acc: 0.9838 -- iter: 064/213
[A[ATraining Step: 150  | total loss: [1m[32m0.07588[0m[0m | time: 24.403s
[2K
| Adam | epoch: 022 | loss: 0.07588 - acc: 0.9854 -- iter: 096/213
[A[ATraining Step: 151  | total loss: [1m[32m0.06863[0m[0m | time: 30.004s
[2K
| Adam | epoch: 022 | loss: 0.06863 - acc: 0.9869 -- iter: 128/213
[A[ATraining Step: 152  | total loss: [1m[32m0.14145[0m[0m | time: 35.606s
[2K
| Adam | epoch: 022 | loss: 0.14145 - acc: 0.9786 -- iter: 160/213
[A[ATraining Step: 153  | total loss: [1m[32m0.12825[0m[0m | time: 43.595s
[2K
| Adam | epoch: 022 | loss: 0.12825 - acc: 0.9808 -- iter: 192/213
[A[ATraining Step: 154  | total loss: [1m[32m0.11677[0m[0m | time: 54.690s
[2K
| Adam | epoch: 022 | loss: 0.11677 - acc: 0.9827 | val_loss: 1.30485 - val_acc: 0.6567 -- iter: 213/213
--
Training Step: 155  | total loss: [1m[32m0.11334[0m[0m | time: 8.365s
[2K
| Adam | epoch: 023 | loss: 0.11334 - acc: 0.9813 -- iter: 032/213
[A[ATraining Step: 156  | total loss: [1m[32m0.10606[0m[0m | time: 16.414s
[2K
| Adam | epoch: 023 | loss: 0.10606 - acc: 0.9832 -- iter: 064/213
[A[ATraining Step: 157  | total loss: [1m[32m0.09914[0m[0m | time: 24.876s
[2K
| Adam | epoch: 023 | loss: 0.09914 - acc: 0.9849 -- iter: 096/213
[A[ATraining Step: 158  | total loss: [1m[32m0.09152[0m[0m | time: 32.824s
[2K
| Adam | epoch: 023 | loss: 0.09152 - acc: 0.9864 -- iter: 128/213
[A[ATraining Step: 159  | total loss: [1m[32m0.08492[0m[0m | time: 38.408s
[2K
| Adam | epoch: 023 | loss: 0.08492 - acc: 0.9877 -- iter: 160/213
[A[ATraining Step: 160  | total loss: [1m[32m0.11893[0m[0m | time: 43.894s
[2K
| Adam | epoch: 023 | loss: 0.11893 - acc: 0.9794 -- iter: 192/213
[A[ATraining Step: 161  | total loss: [1m[32m0.10873[0m[0m | time: 55.075s
[2K
| Adam | epoch: 023 | loss: 0.10873 - acc: 0.9815 | val_loss: 2.58287 - val_acc: 0.5970 -- iter: 213/213
--
Training Step: 162  | total loss: [1m[32m0.10042[0m[0m | time: 8.020s
[2K
| Adam | epoch: 024 | loss: 0.10042 - acc: 0.9833 -- iter: 032/213
[A[ATraining Step: 163  | total loss: [1m[32m0.09520[0m[0m | time: 16.172s
[2K
| Adam | epoch: 024 | loss: 0.09520 - acc: 0.9819 -- iter: 064/213
[A[ATraining Step: 164  | total loss: [1m[32m0.09387[0m[0m | time: 24.456s
[2K
| Adam | epoch: 024 | loss: 0.09387 - acc: 0.9806 -- iter: 096/213
[A[ATraining Step: 165  | total loss: [1m[32m0.09548[0m[0m | time: 32.766s
[2K
| Adam | epoch: 024 | loss: 0.09548 - acc: 0.9794 -- iter: 128/213
[A[ATraining Step: 166  | total loss: [1m[32m0.10849[0m[0m | time: 40.975s
[2K
| Adam | epoch: 024 | loss: 0.10849 - acc: 0.9783 -- iter: 160/213
[A[ATraining Step: 167  | total loss: [1m[32m0.10498[0m[0m | time: 46.579s
[2K
| Adam | epoch: 024 | loss: 0.10498 - acc: 0.9805 -- iter: 192/213
[A[ATraining Step: 168  | total loss: [1m[32m0.12990[0m[0m | time: 55.212s
[2K
| Adam | epoch: 024 | loss: 0.12990 - acc: 0.9777 | val_loss: 0.47135 - val_acc: 0.7761 -- iter: 213/213
--
Training Step: 169  | total loss: [1m[32m0.11866[0m[0m | time: 8.288s
[2K
| Adam | epoch: 025 | loss: 0.11866 - acc: 0.9799 -- iter: 032/213
[A[ATraining Step: 170  | total loss: [1m[32m0.10838[0m[0m | time: 16.338s
[2K
| Adam | epoch: 025 | loss: 0.10838 - acc: 0.9819 -- iter: 064/213
[A[ATraining Step: 171  | total loss: [1m[32m0.11187[0m[0m | time: 24.637s
[2K
| Adam | epoch: 025 | loss: 0.11187 - acc: 0.9806 -- iter: 096/213
[A[ATraining Step: 172  | total loss: [1m[32m0.10202[0m[0m | time: 33.042s
[2K
| Adam | epoch: 025 | loss: 0.10202 - acc: 0.9825 -- iter: 128/213
[A[ATraining Step: 173  | total loss: [1m[32m0.09459[0m[0m | time: 41.401s
[2K
| Adam | epoch: 025 | loss: 0.09459 - acc: 0.9843 -- iter: 160/213
[A[ATraining Step: 174  | total loss: [1m[32m0.08694[0m[0m | time: 49.584s
[2K
| Adam | epoch: 025 | loss: 0.08694 - acc: 0.9859 -- iter: 192/213
[A[ATraining Step: 175  | total loss: [1m[32m0.08034[0m[0m | time: 58.360s
[2K
| Adam | epoch: 025 | loss: 0.08034 - acc: 0.9873 | val_loss: 0.50316 - val_acc: 0.8358 -- iter: 213/213
--
Training Step: 176  | total loss: [1m[32m0.09436[0m[0m | time: 5.485s
[2K
| Adam | epoch: 026 | loss: 0.09436 - acc: 0.9838 -- iter: 032/213
[A[ATraining Step: 177  | total loss: [1m[32m0.08667[0m[0m | time: 13.605s
[2K
| Adam | epoch: 026 | loss: 0.08667 - acc: 0.9854 -- iter: 064/213
[A[ATraining Step: 178  | total loss: [1m[32m0.07985[0m[0m | time: 21.674s
[2K
| Adam | epoch: 026 | loss: 0.07985 - acc: 0.9869 -- iter: 096/213
[A[ATraining Step: 179  | total loss: [1m[32m0.07331[0m[0m | time: 29.976s
[2K
| Adam | epoch: 026 | loss: 0.07331 - acc: 0.9882 -- iter: 128/213
[A[ATraining Step: 180  | total loss: [1m[32m0.06761[0m[0m | time: 38.259s
[2K
| Adam | epoch: 026 | loss: 0.06761 - acc: 0.9894 -- iter: 160/213
[A[ATraining Step: 181  | total loss: [1m[32m0.06974[0m[0m | time: 46.528s
[2K
| Adam | epoch: 026 | loss: 0.06974 - acc: 0.9873 -- iter: 192/213
[A[ATraining Step: 182  | total loss: [1m[32m0.06421[0m[0m | time: 57.790s
[2K
| Adam | epoch: 026 | loss: 0.06421 - acc: 0.9886 | val_loss: 0.38353 - val_acc: 0.8806 -- iter: 213/213
--
Training Step: 183  | total loss: [1m[32m0.05934[0m[0m | time: 5.544s
[2K
| Adam | epoch: 027 | loss: 0.05934 - acc: 0.9897 -- iter: 032/213
[A[ATraining Step: 184  | total loss: [1m[32m0.11911[0m[0m | time: 11.315s
[2K
| Adam | epoch: 027 | loss: 0.11911 - acc: 0.9812 -- iter: 064/213
[A[ATraining Step: 185  | total loss: [1m[32m0.11028[0m[0m | time: 19.401s
[2K
| Adam | epoch: 027 | loss: 0.11028 - acc: 0.9831 -- iter: 096/213
[A[ATraining Step: 186  | total loss: [1m[32m0.11319[0m[0m | time: 27.646s
[2K
| Adam | epoch: 027 | loss: 0.11319 - acc: 0.9817 -- iter: 128/213
[A[ATraining Step: 187  | total loss: [1m[32m0.10363[0m[0m | time: 35.938s
[2K
| Adam | epoch: 027 | loss: 0.10363 - acc: 0.9835 -- iter: 160/213
[A[ATraining Step: 188  | total loss: [1m[32m0.09610[0m[0m | time: 44.281s
[2K
| Adam | epoch: 027 | loss: 0.09610 - acc: 0.9851 -- iter: 192/213
[A[ATraining Step: 189  | total loss: [1m[32m0.09600[0m[0m | time: 57.247s
[2K
| Adam | epoch: 027 | loss: 0.09600 - acc: 0.9804 | val_loss: 0.86583 - val_acc: 0.7164 -- iter: 213/213
--
Training Step: 190  | total loss: [1m[32m0.09935[0m[0m | time: 10.729s
[2K
| Adam | epoch: 028 | loss: 0.09935 - acc: 0.9792 -- iter: 032/213
[A[ATraining Step: 191  | total loss: [1m[32m0.09362[0m[0m | time: 18.226s
[2K
| Adam | epoch: 028 | loss: 0.09362 - acc: 0.9813 -- iter: 064/213
[A[ATraining Step: 192  | total loss: [1m[32m0.09721[0m[0m | time: 26.522s
[2K
| Adam | epoch: 028 | loss: 0.09721 - acc: 0.9784 -- iter: 096/213
[A[ATraining Step: 193  | total loss: [1m[32m0.09197[0m[0m | time: 37.161s
[2K
| Adam | epoch: 028 | loss: 0.09197 - acc: 0.9806 -- iter: 128/213
[A[ATraining Step: 194  | total loss: [1m[32m0.08465[0m[0m | time: 47.962s
[2K
| Adam | epoch: 028 | loss: 0.08465 - acc: 0.9825 -- iter: 160/213
[A[ATraining Step: 195  | total loss: [1m[32m0.07896[0m[0m | time: 58.375s
[2K
| Adam | epoch: 028 | loss: 0.07896 - acc: 0.9843 -- iter: 192/213
[A[ATraining Step: 196  | total loss: [1m[32m0.07404[0m[0m | time: 72.971s
[2K
| Adam | epoch: 028 | loss: 0.07404 - acc: 0.9858 | val_loss: 1.37995 - val_acc: 0.5970 -- iter: 213/213
--
Training Step: 197  | total loss: [1m[32m0.07662[0m[0m | time: 10.739s
[2K
| Adam | epoch: 029 | loss: 0.07662 - acc: 0.9779 -- iter: 032/213
[A[ATraining Step: 198  | total loss: [1m[32m0.07620[0m[0m | time: 21.480s
[2K
| Adam | epoch: 029 | loss: 0.07620 - acc: 0.9770 -- iter: 064/213
[A[ATraining Step: 199  | total loss: [1m[32m0.08425[0m[0m | time: 28.871s
[2K
| Adam | epoch: 029 | loss: 0.08425 - acc: 0.9668 -- iter: 096/213
[A[ATraining Step: 200  | total loss: [1m[32m0.07665[0m[0m | time: 41.097s
[2K
| Adam | epoch: 029 | loss: 0.07665 - acc: 0.9701 | val_loss: 1.15037 - val_acc: 0.6269 -- iter: 128/213
--
Training Step: 201  | total loss: [1m[32m0.06961[0m[0m | time: 51.948s
[2K
| Adam | epoch: 029 | loss: 0.06961 - acc: 0.9731 -- iter: 160/213
[A[ATraining Step: 202  | total loss: [1m[32m0.06328[0m[0m | time: 63.427s
[2K
| Adam | epoch: 029 | loss: 0.06328 - acc: 0.9758 -- iter: 192/213
[A[ATraining Step: 203  | total loss: [1m[32m0.05768[0m[0m | time: 78.017s
[2K
| Adam | epoch: 029 | loss: 0.05768 - acc: 0.9782 | val_loss: 0.86018 - val_acc: 0.6716 -- iter: 213/213
--
Training Step: 204  | total loss: [1m[32m0.05270[0m[0m | time: 10.606s
[2K
| Adam | epoch: 030 | loss: 0.05270 - acc: 0.9804 -- iter: 032/213
[A[ATraining Step: 205  | total loss: [1m[32m0.04890[0m[0m | time: 21.183s
[2K
| Adam | epoch: 030 | loss: 0.04890 - acc: 0.9823 -- iter: 064/213
[A[ATraining Step: 206  | total loss: [1m[32m0.04453[0m[0m | time: 32.456s
[2K
| Adam | epoch: 030 | loss: 0.04453 - acc: 0.9841 -- iter: 096/213
[A[ATraining Step: 207  | total loss: [1m[32m0.04162[0m[0m | time: 40.150s
[2K
| Adam | epoch: 030 | loss: 0.04162 - acc: 0.9857 -- iter: 128/213
[A[ATraining Step: 208  | total loss: [1m[32m0.03765[0m[0m | time: 47.784s
[2K
| Adam | epoch: 030 | loss: 0.03765 - acc: 0.9871 -- iter: 160/213
[A[ATraining Step: 209  | total loss: [1m[32m0.03409[0m[0m | time: 58.518s
[2K
| Adam | epoch: 030 | loss: 0.03409 - acc: 0.9884 -- iter: 192/213
[A[ATraining Step: 210  | total loss: [1m[32m0.03161[0m[0m | time: 72.930s
[2K
| Adam | epoch: 030 | loss: 0.03161 - acc: 0.9896 | val_loss: 0.36903 - val_acc: 0.8358 -- iter: 213/213
--
Validation AUC:0.9419237749546279
Validation AUPRC:0.9612982189863155
Test AUC:0.9411764705882354
Test AUPRC:0.9385155872340581
BestTestF1Score	0.88	0.74	0.87	0.82	0.94	32	7	26	2	0.17
BestTestMCCScore	0.88	0.74	0.87	0.82	0.94	32	7	26	2	0.17
BestTestAccuracyScore	0.88	0.76	0.88	0.91	0.85	29	3	30	5	0.57
BestValidationF1Score	0.89	0.74	0.87	0.82	0.97	37	8	21	1	0.17
BestValidationMCC	0.89	0.74	0.87	0.82	0.97	37	8	21	1	0.17
BestValidationAccuracy	0.88	0.73	0.87	0.89	0.87	33	4	25	5	0.57
TestPredictions (Threshold:0.17)
CHEMBL563948,TN,INACT,0.0	CHEMBL2011935,TP,ACT,1.0	CHEMBL3687117,TP,ACT,0.9900000095367432	CHEMBL3639859,TP,ACT,0.9900000095367432	CHEMBL456796,TN,INACT,0.0	CHEMBL3682431,TP,ACT,1.0	CHEMBL1910761,FP,INACT,0.5400000214576721	CHEMBL2392241,TN,INACT,0.0	CHEMBL2392236,TN,INACT,0.0	CHEMBL3687112,TP,ACT,1.0	CHEMBL318485,FP,INACT,0.30000001192092896	CHEMBL2392388,TN,INACT,0.0	CHEMBL2011919,FN,ACT,0.029999999329447746	CHEMBL3125726,TP,ACT,0.9800000190734863	CHEMBL1287975,TN,INACT,0.0	CHEMBL3125737,TP,ACT,0.6600000262260437	CHEMBL3687128,TP,ACT,1.0	CHEMBL1910760,TN,INACT,0.019999999552965164	CHEMBL3125721,TP,ACT,1.0	CHEMBL3682432,TP,ACT,0.9900000095367432	CHEMBL3125729,TP,ACT,0.949999988079071	CHEMBL1767292,TN,INACT,0.0	CHEMBL521201,TN,INACT,0.14000000059604645	CHEMBL3687131,TP,ACT,0.9599999785423279	CHEMBL517154,TN,INACT,0.0	CHEMBL3682425,TP,ACT,0.9800000190734863	CHEMBL2042136,FP,INACT,0.4399999976158142	CHEMBL608533,TP,ACT,0.9900000095367432	CHEMBL469776,TN,INACT,0.0	CHEMBL3687149,TP,ACT,0.8100000023841858	CHEMBL3687148,TP,ACT,0.9900000095367432	CHEMBL3682424,TP,ACT,0.550000011920929	CHEMBL219992,FN,ACT,0.03999999910593033	CHEMBL456797,TN,INACT,0.0	CHEMBL515051,TN,INACT,0.0	CHEMBL3687145,TP,ACT,0.7699999809265137	CHEMBL524820,FP,INACT,0.9800000190734863	CHEMBL1287945,TN,INACT,0.0	CHEMBL3125738,TP,ACT,0.9800000190734863	CHEMBL3687172,TP,ACT,1.0	CHEMBL2164716,TN,INACT,0.0	CHEMBL3687165,TP,ACT,1.0	CHEMBL2392237,TN,INACT,0.0	CHEMBL601719,TP,ACT,0.8399999737739563	CHEMBL502835,TP,ACT,0.9900000095367432	CHEMBL488646,TN,INACT,0.0	CHEMBL557525,TN,INACT,0.0	CHEMBL101557,FP,INACT,0.9900000095367432	CHEMBL396487,TN,INACT,0.0	CHEMBL498249,TN,INACT,0.03999999910593033	CHEMBL3421968,TN,INACT,0.15000000596046448	CHEMBL3682426,TP,ACT,0.8500000238418579	CHEMBL2010815,TP,ACT,1.0	CHEMBL469770,TN,INACT,0.0	CHEMBL2011933,TP,ACT,1.0	CHEMBL334248,TN,INACT,0.07999999821186066	CHEMBL3687137,TP,ACT,0.9399999976158142	CHEMBL2392239,TN,INACT,0.0	CHEMBL2312654,FP,INACT,0.8899999856948853	CHEMBL3687134,TP,ACT,0.6100000143051147	CHEMBL230911,TP,ACT,0.3799999952316284	CHEMBL3687157,TP,ACT,0.9800000190734863	CHEMBL120127,TN,INACT,0.0	CHEMBL3125733,TP,ACT,0.49000000953674316	CHEMBL1910602,TN,INACT,0.0	CHEMBL1809197,FP,INACT,0.4300000071525574	CHEMBL2011944,TP,ACT,1.0	

