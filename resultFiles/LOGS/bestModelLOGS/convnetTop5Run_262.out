CNNModel CHEMBL283 RMSprop 0.001 30 32 0 0.6 False True
Number of active compounds :	940
Number of inactive compounds :	627
---------------------------------
Run id: CNNModel_CHEMBL283_RMSprop_0.001_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL283_RMSprop_0.001_30_32_0.6_True/
---------------------------------
Training samples: 1000
Validation samples: 313
--
Training Step: 1  | time: 23.697s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1000
[A[ATraining Step: 2  | total loss: [1m[32m0.62296[0m[0m | time: 37.039s
[2K
| RMSProp | epoch: 001 | loss: 0.62296 - acc: 0.7312 -- iter: 0064/1000
[A[ATraining Step: 3  | total loss: [1m[32m0.68026[0m[0m | time: 47.585s
[2K
| RMSProp | epoch: 001 | loss: 0.68026 - acc: 0.5676 -- iter: 0096/1000
[A[ATraining Step: 4  | total loss: [1m[32m0.68959[0m[0m | time: 57.955s
[2K
| RMSProp | epoch: 001 | loss: 0.68959 - acc: 0.6107 -- iter: 0128/1000
[A[ATraining Step: 5  | total loss: [1m[32m0.69175[0m[0m | time: 71.574s
[2K
| RMSProp | epoch: 001 | loss: 0.69175 - acc: 0.6206 -- iter: 0160/1000
[A[ATraining Step: 6  | total loss: [1m[32m0.69190[0m[0m | time: 83.340s
[2K
| RMSProp | epoch: 001 | loss: 0.69190 - acc: 0.6837 -- iter: 0192/1000
[A[ATraining Step: 7  | total loss: [1m[32m0.69214[0m[0m | time: 94.889s
[2K
| RMSProp | epoch: 001 | loss: 0.69214 - acc: 0.6672 -- iter: 0224/1000
[A[ATraining Step: 8  | total loss: [1m[32m0.69253[0m[0m | time: 102.065s
[2K
| RMSProp | epoch: 001 | loss: 0.69253 - acc: 0.5907 -- iter: 0256/1000
[A[ATraining Step: 9  | total loss: [1m[32m0.69239[0m[0m | time: 109.310s
[2K
| RMSProp | epoch: 001 | loss: 0.69239 - acc: 0.6254 -- iter: 0288/1000
[A[ATraining Step: 10  | total loss: [1m[32m0.69182[0m[0m | time: 110.449s
[2K
| RMSProp | epoch: 001 | loss: 0.69182 - acc: 0.7033 -- iter: 0320/1000
[A[ATraining Step: 11  | total loss: [1m[32m0.69190[0m[0m | time: 111.650s
[2K
| RMSProp | epoch: 001 | loss: 0.69190 - acc: 0.6810 -- iter: 0352/1000
[A[ATraining Step: 12  | total loss: [1m[32m0.69136[0m[0m | time: 112.745s
[2K
| RMSProp | epoch: 001 | loss: 0.69136 - acc: 0.7261 -- iter: 0384/1000
[A[ATraining Step: 13  | total loss: [1m[32m0.69138[0m[0m | time: 113.973s
[2K
| RMSProp | epoch: 001 | loss: 0.69138 - acc: 0.7096 -- iter: 0416/1000
[A[ATraining Step: 14  | total loss: [1m[32m0.69158[0m[0m | time: 128.082s
[2K
| RMSProp | epoch: 001 | loss: 0.69158 - acc: 0.6750 -- iter: 0448/1000
[A[ATraining Step: 15  | total loss: [1m[32m0.69138[0m[0m | time: 134.931s
[2K
| RMSProp | epoch: 001 | loss: 0.69138 - acc: 0.6799 -- iter: 0480/1000
[A[ATraining Step: 16  | total loss: [1m[32m0.69203[0m[0m | time: 138.866s
[2K
| RMSProp | epoch: 001 | loss: 0.69203 - acc: 0.6124 -- iter: 0512/1000
[A[ATraining Step: 17  | total loss: [1m[32m0.69160[0m[0m | time: 157.460s
[2K
| RMSProp | epoch: 001 | loss: 0.69160 - acc: 0.6395 -- iter: 0544/1000
[A[ATraining Step: 18  | total loss: [1m[32m0.69201[0m[0m | time: 165.609s
[2K
| RMSProp | epoch: 001 | loss: 0.69201 - acc: 0.6020 -- iter: 0576/1000
[A[ATraining Step: 19  | total loss: [1m[32m0.69184[0m[0m | time: 173.338s
[2K
| RMSProp | epoch: 001 | loss: 0.69184 - acc: 0.6097 -- iter: 0608/1000
[A[ATraining Step: 20  | total loss: [1m[32m0.69200[0m[0m | time: 184.227s
[2K
| RMSProp | epoch: 001 | loss: 0.69200 - acc: 0.5945 -- iter: 0640/1000
[A[ATraining Step: 21  | total loss: [1m[32m0.69156[0m[0m | time: 196.901s
[2K
| RMSProp | epoch: 001 | loss: 0.69156 - acc: 0.6234 -- iter: 0672/1000
[A[ATraining Step: 22  | total loss: [1m[32m0.69170[0m[0m | time: 211.467s
[2K
| RMSProp | epoch: 001 | loss: 0.69170 - acc: 0.6051 -- iter: 0704/1000
[A[ATraining Step: 23  | total loss: [1m[32m0.69172[0m[0m | time: 223.390s
[2K
| RMSProp | epoch: 001 | loss: 0.69172 - acc: 0.6018 -- iter: 0736/1000
[A[ATraining Step: 24  | total loss: [1m[32m0.69229[0m[0m | time: 231.078s
[2K
| RMSProp | epoch: 001 | loss: 0.69229 - acc: 0.5644 -- iter: 0768/1000
[A[ATraining Step: 25  | total loss: [1m[32m0.69264[0m[0m | time: 237.818s
[2K
| RMSProp | epoch: 001 | loss: 0.69264 - acc: 0.5383 -- iter: 0800/1000
[A[ATraining Step: 26  | total loss: [1m[32m0.69251[0m[0m | time: 246.881s
[2K
| RMSProp | epoch: 001 | loss: 0.69251 - acc: 0.5447 -- iter: 0832/1000
[A[ATraining Step: 27  | total loss: [1m[32m0.69244[0m[0m | time: 252.280s
[2K
| RMSProp | epoch: 001 | loss: 0.69244 - acc: 0.5493 -- iter: 0864/1000
[A[ATraining Step: 28  | total loss: [1m[32m0.69275[0m[0m | time: 258.508s
[2K
| RMSProp | epoch: 001 | loss: 0.69275 - acc: 0.5292 -- iter: 0896/1000
[A[ATraining Step: 29  | total loss: [1m[32m0.69234[0m[0m | time: 263.956s
[2K
| RMSProp | epoch: 001 | loss: 0.69234 - acc: 0.5525 -- iter: 0928/1000
[A[ATraining Step: 30  | total loss: [1m[32m0.69267[0m[0m | time: 274.903s
[2K
| RMSProp | epoch: 001 | loss: 0.69267 - acc: 0.5326 -- iter: 0960/1000
[A[ATraining Step: 31  | total loss: [1m[32m0.69180[0m[0m | time: 277.352s
[2K
| RMSProp | epoch: 001 | loss: 0.69180 - acc: 0.5828 -- iter: 0992/1000
[A[ATraining Step: 32  | total loss: [1m[32m0.69198[0m[0m | time: 289.094s
[2K
| RMSProp | epoch: 001 | loss: 0.69198 - acc: 0.5712 | val_loss: 0.69121 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 33  | total loss: [1m[32m0.69279[0m[0m | time: 0.362s
[2K
| RMSProp | epoch: 002 | loss: 0.69279 - acc: 0.5281 -- iter: 0032/1000
[A[ATraining Step: 34  | total loss: [1m[32m0.69342[0m[0m | time: 1.645s
[2K
| RMSProp | epoch: 002 | loss: 0.69342 - acc: 0.4953 -- iter: 0064/1000
[A[ATraining Step: 35  | total loss: [1m[32m0.69327[0m[0m | time: 3.228s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.5028 -- iter: 0096/1000
[A[ATraining Step: 36  | total loss: [1m[32m0.69258[0m[0m | time: 13.090s
[2K
| RMSProp | epoch: 002 | loss: 0.69258 - acc: 0.5406 -- iter: 0128/1000
[A[ATraining Step: 37  | total loss: [1m[32m0.69247[0m[0m | time: 17.745s
[2K
| RMSProp | epoch: 002 | loss: 0.69247 - acc: 0.5450 -- iter: 0160/1000
[A[ATraining Step: 38  | total loss: [1m[32m0.69236[0m[0m | time: 26.415s
[2K
| RMSProp | epoch: 002 | loss: 0.69236 - acc: 0.5484 -- iter: 0192/1000
[A[ATraining Step: 39  | total loss: [1m[32m0.69149[0m[0m | time: 36.720s
[2K
| RMSProp | epoch: 002 | loss: 0.69149 - acc: 0.5870 -- iter: 0224/1000
[A[ATraining Step: 40  | total loss: [1m[32m0.69093[0m[0m | time: 46.005s
[2K
| RMSProp | epoch: 002 | loss: 0.69093 - acc: 0.6059 -- iter: 0256/1000
[A[ATraining Step: 41  | total loss: [1m[32m0.69135[0m[0m | time: 50.286s
[2K
| RMSProp | epoch: 002 | loss: 0.69135 - acc: 0.5864 -- iter: 0288/1000
[A[ATraining Step: 42  | total loss: [1m[32m0.69094[0m[0m | time: 60.004s
[2K
| RMSProp | epoch: 002 | loss: 0.69094 - acc: 0.5990 -- iter: 0320/1000
[A[ATraining Step: 43  | total loss: [1m[32m0.69100[0m[0m | time: 72.435s
[2K
| RMSProp | epoch: 002 | loss: 0.69100 - acc: 0.5925 -- iter: 0352/1000
[A[ATraining Step: 44  | total loss: [1m[32m0.69107[0m[0m | time: 79.374s
[2K
| RMSProp | epoch: 002 | loss: 0.69107 - acc: 0.5873 -- iter: 0384/1000
[A[ATraining Step: 45  | total loss: [1m[32m0.69129[0m[0m | time: 88.690s
[2K
| RMSProp | epoch: 002 | loss: 0.69129 - acc: 0.5778 -- iter: 0416/1000
[A[ATraining Step: 46  | total loss: [1m[32m0.69060[0m[0m | time: 98.001s
[2K
| RMSProp | epoch: 002 | loss: 0.69060 - acc: 0.5961 -- iter: 0448/1000
[A[ATraining Step: 47  | total loss: [1m[32m0.68981[0m[0m | time: 104.760s
[2K
| RMSProp | epoch: 002 | loss: 0.68981 - acc: 0.6162 -- iter: 0480/1000
[A[ATraining Step: 48  | total loss: [1m[32m0.68979[0m[0m | time: 110.911s
[2K
| RMSProp | epoch: 002 | loss: 0.68979 - acc: 0.6126 -- iter: 0512/1000
[A[ATraining Step: 49  | total loss: [1m[32m0.69035[0m[0m | time: 118.956s
[2K
| RMSProp | epoch: 002 | loss: 0.69035 - acc: 0.5948 -- iter: 0544/1000
[A[ATraining Step: 50  | total loss: [1m[32m0.68911[0m[0m | time: 122.227s
[2K
| RMSProp | epoch: 002 | loss: 0.68911 - acc: 0.6237 -- iter: 0576/1000
[A[ATraining Step: 51  | total loss: [1m[32m0.68748[0m[0m | time: 125.891s
[2K
| RMSProp | epoch: 002 | loss: 0.68748 - acc: 0.6573 -- iter: 0608/1000
[A[ATraining Step: 52  | total loss: [1m[32m0.68792[0m[0m | time: 133.058s
[2K
| RMSProp | epoch: 002 | loss: 0.68792 - acc: 0.6431 -- iter: 0640/1000
[A[ATraining Step: 53  | total loss: [1m[32m0.68875[0m[0m | time: 137.316s
[2K
| RMSProp | epoch: 002 | loss: 0.68875 - acc: 0.6220 -- iter: 0672/1000
[A[ATraining Step: 54  | total loss: [1m[32m0.68874[0m[0m | time: 142.593s
[2K
| RMSProp | epoch: 002 | loss: 0.68874 - acc: 0.6179 -- iter: 0704/1000
[A[ATraining Step: 55  | total loss: [1m[32m0.68872[0m[0m | time: 150.420s
[2K
| RMSProp | epoch: 002 | loss: 0.68872 - acc: 0.6144 -- iter: 0736/1000
[A[ATraining Step: 56  | total loss: [1m[32m0.68801[0m[0m | time: 155.344s
[2K
| RMSProp | epoch: 002 | loss: 0.68801 - acc: 0.6247 -- iter: 0768/1000
[A[ATraining Step: 57  | total loss: [1m[32m0.68733[0m[0m | time: 162.103s
[2K
| RMSProp | epoch: 002 | loss: 0.68733 - acc: 0.6334 -- iter: 0800/1000
[A[ATraining Step: 58  | total loss: [1m[32m0.68717[0m[0m | time: 164.130s
[2K
| RMSProp | epoch: 002 | loss: 0.68717 - acc: 0.6322 -- iter: 0832/1000
[A[ATraining Step: 59  | total loss: [1m[32m0.68698[0m[0m | time: 165.326s
[2K
| RMSProp | epoch: 002 | loss: 0.68698 - acc: 0.6313 -- iter: 0864/1000
[A[ATraining Step: 60  | total loss: [1m[32m0.68708[0m[0m | time: 166.743s
[2K
| RMSProp | epoch: 002 | loss: 0.68708 - acc: 0.6263 -- iter: 0896/1000
[A[ATraining Step: 61  | total loss: [1m[32m0.68740[0m[0m | time: 176.928s
[2K
| RMSProp | epoch: 002 | loss: 0.68740 - acc: 0.6180 -- iter: 0928/1000
[A[ATraining Step: 62  | total loss: [1m[32m0.68742[0m[0m | time: 182.063s
[2K
| RMSProp | epoch: 002 | loss: 0.68742 - acc: 0.6149 -- iter: 0960/1000
[A[ATraining Step: 63  | total loss: [1m[32m0.68767[0m[0m | time: 185.533s
[2K
| RMSProp | epoch: 002 | loss: 0.68767 - acc: 0.6082 -- iter: 0992/1000
[A[ATraining Step: 64  | total loss: [1m[32m0.68761[0m[0m | time: 246.145s
[2K
| RMSProp | epoch: 002 | loss: 0.68761 - acc: 0.6064 | val_loss: 0.68599 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 65  | total loss: [1m[32m0.68810[0m[0m | time: 4.907s
[2K
| RMSProp | epoch: 003 | loss: 0.68810 - acc: 0.5972 -- iter: 0032/1000
[A[ATraining Step: 66  | total loss: [1m[32m0.68989[0m[0m | time: 11.018s
[2K
| RMSProp | epoch: 003 | loss: 0.68989 - acc: 0.5701 -- iter: 0064/1000
[A[ATraining Step: 67  | total loss: [1m[32m0.69143[0m[0m | time: 20.116s
[2K
| RMSProp | epoch: 003 | loss: 0.69143 - acc: 0.5467 -- iter: 0096/1000
[A[ATraining Step: 68  | total loss: [1m[32m0.68977[0m[0m | time: 25.144s
[2K
| RMSProp | epoch: 003 | loss: 0.68977 - acc: 0.5708 -- iter: 0128/1000
[A[ATraining Step: 69  | total loss: [1m[32m0.68710[0m[0m | time: 29.841s
[2K
| RMSProp | epoch: 003 | loss: 0.68710 - acc: 0.6063 -- iter: 0160/1000
[A[ATraining Step: 70  | total loss: [1m[32m0.68790[0m[0m | time: 32.306s
[2K
| RMSProp | epoch: 003 | loss: 0.68790 - acc: 0.5941 -- iter: 0192/1000
[A[ATraining Step: 71  | total loss: [1m[32m0.68914[0m[0m | time: 41.376s
[2K
| RMSProp | epoch: 003 | loss: 0.68914 - acc: 0.5762 -- iter: 0224/1000
[A[ATraining Step: 72  | total loss: [1m[32m0.68775[0m[0m | time: 47.913s
[2K
| RMSProp | epoch: 003 | loss: 0.68775 - acc: 0.5923 -- iter: 0256/1000
[A[ATraining Step: 73  | total loss: [1m[32m0.68700[0m[0m | time: 52.673s
[2K
| RMSProp | epoch: 003 | loss: 0.68700 - acc: 0.5994 -- iter: 0288/1000
[A[ATraining Step: 74  | total loss: [1m[32m0.68596[0m[0m | time: 55.017s
[2K
| RMSProp | epoch: 003 | loss: 0.68596 - acc: 0.6091 -- iter: 0320/1000
[A[ATraining Step: 75  | total loss: [1m[32m0.68621[0m[0m | time: 63.453s
[2K
| RMSProp | epoch: 003 | loss: 0.68621 - acc: 0.6040 -- iter: 0352/1000
[A[ATraining Step: 76  | total loss: [1m[32m0.68772[0m[0m | time: 68.262s
[2K
| RMSProp | epoch: 003 | loss: 0.68772 - acc: 0.5862 -- iter: 0384/1000
[A[ATraining Step: 77  | total loss: [1m[32m0.68751[0m[0m | time: 76.787s
[2K
| RMSProp | epoch: 003 | loss: 0.68751 - acc: 0.5870 -- iter: 0416/1000
[A[ATraining Step: 78  | total loss: [1m[32m0.68701[0m[0m | time: 84.275s
[2K
| RMSProp | epoch: 003 | loss: 0.68701 - acc: 0.5909 -- iter: 0448/1000
[A[ATraining Step: 79  | total loss: [1m[32m0.68747[0m[0m | time: 86.001s
[2K
| RMSProp | epoch: 003 | loss: 0.68747 - acc: 0.5848 -- iter: 0480/1000
[A[ATraining Step: 80  | total loss: [1m[32m0.68693[0m[0m | time: 89.504s
[2K
| RMSProp | epoch: 003 | loss: 0.68693 - acc: 0.5889 -- iter: 0512/1000
[A[ATraining Step: 81  | total loss: [1m[32m0.68833[0m[0m | time: 90.722s
[2K
| RMSProp | epoch: 003 | loss: 0.68833 - acc: 0.5736 -- iter: 0544/1000
[A[ATraining Step: 82  | total loss: [1m[32m0.68954[0m[0m | time: 91.852s
[2K
| RMSProp | epoch: 003 | loss: 0.68954 - acc: 0.5600 -- iter: 0576/1000
[A[ATraining Step: 83  | total loss: [1m[32m0.68826[0m[0m | time: 93.145s
[2K
| RMSProp | epoch: 003 | loss: 0.68826 - acc: 0.5727 -- iter: 0608/1000
[A[ATraining Step: 84  | total loss: [1m[32m0.68793[0m[0m | time: 95.020s
[2K
| RMSProp | epoch: 003 | loss: 0.68793 - acc: 0.5748 -- iter: 0640/1000
[A[ATraining Step: 85  | total loss: [1m[32m0.68693[0m[0m | time: 101.607s
[2K
| RMSProp | epoch: 003 | loss: 0.68693 - acc: 0.5830 -- iter: 0672/1000
[A[ATraining Step: 86  | total loss: [1m[32m0.68702[0m[0m | time: 109.789s
[2K
| RMSProp | epoch: 003 | loss: 0.68702 - acc: 0.5809 -- iter: 0704/1000
[A[ATraining Step: 87  | total loss: [1m[32m0.68674[0m[0m | time: 118.061s
[2K
| RMSProp | epoch: 003 | loss: 0.68674 - acc: 0.5822 -- iter: 0736/1000
[A[ATraining Step: 88  | total loss: [1m[32m0.68755[0m[0m | time: 122.937s
[2K
| RMSProp | epoch: 003 | loss: 0.68755 - acc: 0.5740 -- iter: 0768/1000
[A[ATraining Step: 89  | total loss: [1m[32m0.68574[0m[0m | time: 135.988s
[2K
| RMSProp | epoch: 003 | loss: 0.68574 - acc: 0.5885 -- iter: 0800/1000
[A[ATraining Step: 90  | total loss: [1m[32m0.68310[0m[0m | time: 146.492s
[2K
| RMSProp | epoch: 003 | loss: 0.68310 - acc: 0.6077 -- iter: 0832/1000
[A[ATraining Step: 91  | total loss: [1m[32m0.68115[0m[0m | time: 153.747s
[2K
| RMSProp | epoch: 003 | loss: 0.68115 - acc: 0.6188 -- iter: 0864/1000
[A[ATraining Step: 92  | total loss: [1m[32m0.68117[0m[0m | time: 159.294s
[2K
| RMSProp | epoch: 003 | loss: 0.68117 - acc: 0.6163 -- iter: 0896/1000
[A[ATraining Step: 93  | total loss: [1m[32m0.68271[0m[0m | time: 164.902s
[2K
| RMSProp | epoch: 003 | loss: 0.68271 - acc: 0.6047 -- iter: 0928/1000
[A[ATraining Step: 94  | total loss: [1m[32m0.67849[0m[0m | time: 169.934s
[2K
| RMSProp | epoch: 003 | loss: 0.67849 - acc: 0.6286 -- iter: 0960/1000
[A[ATraining Step: 95  | total loss: [1m[32m0.67931[0m[0m | time: 175.512s
[2K
| RMSProp | epoch: 003 | loss: 0.67931 - acc: 0.6220 -- iter: 0992/1000
[A[ATraining Step: 96  | total loss: [1m[32m0.67995[0m[0m | time: 203.060s
[2K
| RMSProp | epoch: 003 | loss: 0.67995 - acc: 0.6160 | val_loss: 0.67620 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 97  | total loss: [1m[32m0.67933[0m[0m | time: 2.387s
[2K
| RMSProp | epoch: 004 | loss: 0.67933 - acc: 0.6169 -- iter: 0032/1000
[A[ATraining Step: 98  | total loss: [1m[32m0.67867[0m[0m | time: 4.303s
[2K
| RMSProp | epoch: 004 | loss: 0.67867 - acc: 0.6177 -- iter: 0064/1000
[A[ATraining Step: 99  | total loss: [1m[32m0.68077[0m[0m | time: 4.603s
[2K
| RMSProp | epoch: 004 | loss: 0.68077 - acc: 0.6060 -- iter: 0096/1000
[A[ATraining Step: 100  | total loss: [1m[32m0.67202[0m[0m | time: 5.684s
[2K
| RMSProp | epoch: 004 | loss: 0.67202 - acc: 0.6454 -- iter: 0128/1000
[A[ATraining Step: 101  | total loss: [1m[32m0.67630[0m[0m | time: 6.891s
[2K
| RMSProp | epoch: 004 | loss: 0.67630 - acc: 0.6277 -- iter: 0160/1000
[A[ATraining Step: 102  | total loss: [1m[32m0.67557[0m[0m | time: 8.190s
[2K
| RMSProp | epoch: 004 | loss: 0.67557 - acc: 0.6274 -- iter: 0192/1000
[A[ATraining Step: 103  | total loss: [1m[32m0.67568[0m[0m | time: 9.475s
[2K
| RMSProp | epoch: 004 | loss: 0.67568 - acc: 0.6241 -- iter: 0224/1000
[A[ATraining Step: 104  | total loss: [1m[32m0.67767[0m[0m | time: 10.799s
[2K
| RMSProp | epoch: 004 | loss: 0.67767 - acc: 0.6148 -- iter: 0256/1000
[A[ATraining Step: 105  | total loss: [1m[32m0.67580[0m[0m | time: 12.135s
[2K
| RMSProp | epoch: 004 | loss: 0.67580 - acc: 0.6189 -- iter: 0288/1000
[A[ATraining Step: 106  | total loss: [1m[32m0.67495[0m[0m | time: 13.440s
[2K
| RMSProp | epoch: 004 | loss: 0.67495 - acc: 0.6195 -- iter: 0320/1000
[A[ATraining Step: 107  | total loss: [1m[32m0.67182[0m[0m | time: 15.077s
[2K
| RMSProp | epoch: 004 | loss: 0.67182 - acc: 0.6263 -- iter: 0352/1000
[A[ATraining Step: 108  | total loss: [1m[32m0.66821[0m[0m | time: 16.495s
[2K
| RMSProp | epoch: 004 | loss: 0.66821 - acc: 0.6325 -- iter: 0384/1000
[A[ATraining Step: 109  | total loss: [1m[32m0.66401[0m[0m | time: 18.307s
[2K
| RMSProp | epoch: 004 | loss: 0.66401 - acc: 0.6380 -- iter: 0416/1000
[A[ATraining Step: 110  | total loss: [1m[32m0.65975[0m[0m | time: 27.226s
[2K
| RMSProp | epoch: 004 | loss: 0.65975 - acc: 0.6429 -- iter: 0448/1000
[A[ATraining Step: 111  | total loss: [1m[32m0.67248[0m[0m | time: 32.998s
[2K
| RMSProp | epoch: 004 | loss: 0.67248 - acc: 0.6255 -- iter: 0480/1000
[A[ATraining Step: 112  | total loss: [1m[32m0.67456[0m[0m | time: 39.727s
[2K
| RMSProp | epoch: 004 | loss: 0.67456 - acc: 0.6161 -- iter: 0512/1000
[A[ATraining Step: 113  | total loss: [1m[32m0.67568[0m[0m | time: 43.279s
[2K
| RMSProp | epoch: 004 | loss: 0.67568 - acc: 0.6107 -- iter: 0544/1000
[A[ATraining Step: 114  | total loss: [1m[32m0.67824[0m[0m | time: 51.669s
[2K
| RMSProp | epoch: 004 | loss: 0.67824 - acc: 0.5996 -- iter: 0576/1000
[A[ATraining Step: 115  | total loss: [1m[32m0.67680[0m[0m | time: 58.352s
[2K
| RMSProp | epoch: 004 | loss: 0.67680 - acc: 0.6053 -- iter: 0608/1000
[A[ATraining Step: 116  | total loss: [1m[32m0.67586[0m[0m | time: 62.490s
[2K
| RMSProp | epoch: 004 | loss: 0.67586 - acc: 0.6073 -- iter: 0640/1000
[A[ATraining Step: 117  | total loss: [1m[32m0.67786[0m[0m | time: 68.775s
[2K
| RMSProp | epoch: 004 | loss: 0.67786 - acc: 0.5997 -- iter: 0672/1000
[A[ATraining Step: 118  | total loss: [1m[32m0.67356[0m[0m | time: 71.071s
[2K
| RMSProp | epoch: 004 | loss: 0.67356 - acc: 0.6147 -- iter: 0704/1000
[A[ATraining Step: 119  | total loss: [1m[32m0.67498[0m[0m | time: 75.335s
[2K
| RMSProp | epoch: 004 | loss: 0.67498 - acc: 0.6095 -- iter: 0736/1000
[A[ATraining Step: 120  | total loss: [1m[32m0.67184[0m[0m | time: 80.141s
[2K
| RMSProp | epoch: 004 | loss: 0.67184 - acc: 0.6173 -- iter: 0768/1000
[A[ATraining Step: 121  | total loss: [1m[32m0.67355[0m[0m | time: 82.874s
[2K
| RMSProp | epoch: 004 | loss: 0.67355 - acc: 0.6118 -- iter: 0800/1000
[A[ATraining Step: 122  | total loss: [1m[32m0.67239[0m[0m | time: 84.182s
[2K
| RMSProp | epoch: 004 | loss: 0.67239 - acc: 0.6131 -- iter: 0832/1000
[A[ATraining Step: 123  | total loss: [1m[32m0.67809[0m[0m | time: 85.386s
[2K
| RMSProp | epoch: 004 | loss: 0.67809 - acc: 0.5987 -- iter: 0864/1000
[A[ATraining Step: 124  | total loss: [1m[32m0.67709[0m[0m | time: 86.655s
[2K
| RMSProp | epoch: 004 | loss: 0.67709 - acc: 0.6013 -- iter: 0896/1000
[A[ATraining Step: 125  | total loss: [1m[32m0.67883[0m[0m | time: 87.975s
[2K
| RMSProp | epoch: 004 | loss: 0.67883 - acc: 0.5943 -- iter: 0928/1000
[A[ATraining Step: 126  | total loss: [1m[32m0.67782[0m[0m | time: 89.186s
[2K
| RMSProp | epoch: 004 | loss: 0.67782 - acc: 0.5974 -- iter: 0960/1000
[A[ATraining Step: 127  | total loss: [1m[32m0.67394[0m[0m | time: 90.689s
[2K
| RMSProp | epoch: 004 | loss: 0.67394 - acc: 0.6095 -- iter: 0992/1000
[A[ATraining Step: 128  | total loss: [1m[32m0.67406[0m[0m | time: 134.173s
[2K
| RMSProp | epoch: 004 | loss: 0.67406 - acc: 0.6079 | val_loss: 0.67970 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 129  | total loss: [1m[32m0.66887[0m[0m | time: 6.220s
[2K
| RMSProp | epoch: 005 | loss: 0.66887 - acc: 0.6190 -- iter: 0032/1000
[A[ATraining Step: 130  | total loss: [1m[32m0.67077[0m[0m | time: 18.031s
[2K
| RMSProp | epoch: 005 | loss: 0.67077 - acc: 0.6165 -- iter: 0064/1000
[A[ATraining Step: 131  | total loss: [1m[32m0.66749[0m[0m | time: 19.719s
[2K
| RMSProp | epoch: 005 | loss: 0.66749 - acc: 0.6236 -- iter: 0096/1000
[A[ATraining Step: 132  | total loss: [1m[32m0.64666[0m[0m | time: 21.363s
[2K
| RMSProp | epoch: 005 | loss: 0.64666 - acc: 0.6612 -- iter: 0128/1000
[A[ATraining Step: 133  | total loss: [1m[32m0.62322[0m[0m | time: 29.043s
[2K
| RMSProp | epoch: 005 | loss: 0.62322 - acc: 0.6826 -- iter: 0160/1000
[A[ATraining Step: 134  | total loss: [1m[32m0.62740[0m[0m | time: 30.080s
[2K
| RMSProp | epoch: 005 | loss: 0.62740 - acc: 0.6769 -- iter: 0192/1000
[A[ATraining Step: 135  | total loss: [1m[32m0.62917[0m[0m | time: 31.261s
[2K
| RMSProp | epoch: 005 | loss: 0.62917 - acc: 0.6748 -- iter: 0224/1000
[A[ATraining Step: 136  | total loss: [1m[32m0.63842[0m[0m | time: 32.551s
[2K
| RMSProp | epoch: 005 | loss: 0.63842 - acc: 0.6604 -- iter: 0256/1000
[A[ATraining Step: 137  | total loss: [1m[32m0.64209[0m[0m | time: 33.791s
[2K
| RMSProp | epoch: 005 | loss: 0.64209 - acc: 0.6538 -- iter: 0288/1000
[A[ATraining Step: 138  | total loss: [1m[32m0.64301[0m[0m | time: 35.019s
[2K
| RMSProp | epoch: 005 | loss: 0.64301 - acc: 0.6540 -- iter: 0320/1000
[A[ATraining Step: 139  | total loss: [1m[32m0.64635[0m[0m | time: 36.269s
[2K
| RMSProp | epoch: 005 | loss: 0.64635 - acc: 0.6480 -- iter: 0352/1000
[A[ATraining Step: 140  | total loss: [1m[32m0.65066[0m[0m | time: 37.621s
[2K
| RMSProp | epoch: 005 | loss: 0.65066 - acc: 0.6394 -- iter: 0384/1000
[A[ATraining Step: 141  | total loss: [1m[32m0.65772[0m[0m | time: 38.926s
[2K
| RMSProp | epoch: 005 | loss: 0.65772 - acc: 0.6224 -- iter: 0416/1000
[A[ATraining Step: 142  | total loss: [1m[32m0.65466[0m[0m | time: 40.040s
[2K
| RMSProp | epoch: 005 | loss: 0.65466 - acc: 0.6383 -- iter: 0448/1000
[A[ATraining Step: 143  | total loss: [1m[32m0.66168[0m[0m | time: 41.336s
[2K
| RMSProp | epoch: 005 | loss: 0.66168 - acc: 0.6213 -- iter: 0480/1000
[A[ATraining Step: 144  | total loss: [1m[32m0.65956[0m[0m | time: 42.396s
[2K
| RMSProp | epoch: 005 | loss: 0.65956 - acc: 0.6311 -- iter: 0512/1000
[A[ATraining Step: 145  | total loss: [1m[32m0.66341[0m[0m | time: 44.143s
[2K
| RMSProp | epoch: 005 | loss: 0.66341 - acc: 0.6211 -- iter: 0544/1000
[A[ATraining Step: 146  | total loss: [1m[32m0.66759[0m[0m | time: 46.825s
[2K
| RMSProp | epoch: 005 | loss: 0.66759 - acc: 0.6090 -- iter: 0576/1000
[A[ATraining Step: 147  | total loss: [1m[32m0.67019[0m[0m | time: 50.800s
[2K
| RMSProp | epoch: 005 | loss: 0.67019 - acc: 0.6012 -- iter: 0608/1000
[A[ATraining Step: 148  | total loss: [1m[32m0.67170[0m[0m | time: 58.161s
[2K
| RMSProp | epoch: 005 | loss: 0.67170 - acc: 0.5973 -- iter: 0640/1000
[A[ATraining Step: 149  | total loss: [1m[32m0.67226[0m[0m | time: 69.011s
[2K
| RMSProp | epoch: 005 | loss: 0.67226 - acc: 0.5970 -- iter: 0672/1000
[A[ATraining Step: 150  | total loss: [1m[32m0.66915[0m[0m | time: 75.275s
[2K
| RMSProp | epoch: 005 | loss: 0.66915 - acc: 0.6091 -- iter: 0704/1000
[A[ATraining Step: 151  | total loss: [1m[32m0.66851[0m[0m | time: 82.219s
[2K
| RMSProp | epoch: 005 | loss: 0.66851 - acc: 0.6107 -- iter: 0736/1000
[A[ATraining Step: 152  | total loss: [1m[32m0.66953[0m[0m | time: 86.470s
[2K
| RMSProp | epoch: 005 | loss: 0.66953 - acc: 0.6090 -- iter: 0768/1000
[A[ATraining Step: 153  | total loss: [1m[32m0.67246[0m[0m | time: 93.902s
[2K
| RMSProp | epoch: 005 | loss: 0.67246 - acc: 0.6013 -- iter: 0800/1000
[A[ATraining Step: 154  | total loss: [1m[32m0.67380[0m[0m | time: 99.991s
[2K
| RMSProp | epoch: 005 | loss: 0.67380 - acc: 0.5974 -- iter: 0832/1000
[A[ATraining Step: 155  | total loss: [1m[32m0.67597[0m[0m | time: 106.800s
[2K
| RMSProp | epoch: 005 | loss: 0.67597 - acc: 0.5908 -- iter: 0864/1000
[A[ATraining Step: 156  | total loss: [1m[32m0.67602[0m[0m | time: 113.533s
[2K
| RMSProp | epoch: 005 | loss: 0.67602 - acc: 0.5911 -- iter: 0896/1000
[A[ATraining Step: 157  | total loss: [1m[32m0.67410[0m[0m | time: 117.416s
[2K
| RMSProp | epoch: 005 | loss: 0.67410 - acc: 0.5976 -- iter: 0928/1000
[A[ATraining Step: 158  | total loss: [1m[32m0.67092[0m[0m | time: 118.631s
[2K
| RMSProp | epoch: 005 | loss: 0.67092 - acc: 0.6066 -- iter: 0960/1000
[A[ATraining Step: 159  | total loss: [1m[32m0.66338[0m[0m | time: 119.871s
[2K
| RMSProp | epoch: 005 | loss: 0.66338 - acc: 0.6209 -- iter: 0992/1000
[A[ATraining Step: 160  | total loss: [1m[32m0.67361[0m[0m | time: 123.376s
[2K
| RMSProp | epoch: 005 | loss: 0.67361 - acc: 0.6213 | val_loss: 0.67215 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 161  | total loss: [1m[32m0.67217[0m[0m | time: 1.038s
[2K
| RMSProp | epoch: 006 | loss: 0.67217 - acc: 0.6248 -- iter: 0032/1000
[A[ATraining Step: 162  | total loss: [1m[32m0.67070[0m[0m | time: 2.080s
[2K
| RMSProp | epoch: 006 | loss: 0.67070 - acc: 0.6280 -- iter: 0064/1000
[A[ATraining Step: 163  | total loss: [1m[32m0.67025[0m[0m | time: 3.110s
[2K
| RMSProp | epoch: 006 | loss: 0.67025 - acc: 0.6277 -- iter: 0096/1000
[A[ATraining Step: 164  | total loss: [1m[32m0.66667[0m[0m | time: 3.424s
[2K
| RMSProp | epoch: 006 | loss: 0.66667 - acc: 0.6368 -- iter: 0128/1000
[A[ATraining Step: 165  | total loss: [1m[32m0.65658[0m[0m | time: 3.710s
[2K
| RMSProp | epoch: 006 | loss: 0.65658 - acc: 0.6606 -- iter: 0160/1000
[A[ATraining Step: 166  | total loss: [1m[32m0.66401[0m[0m | time: 4.653s
[2K
| RMSProp | epoch: 006 | loss: 0.66401 - acc: 0.6445 -- iter: 0192/1000
[A[ATraining Step: 167  | total loss: [1m[32m0.66132[0m[0m | time: 6.077s
[2K
| RMSProp | epoch: 006 | loss: 0.66132 - acc: 0.6488 -- iter: 0224/1000
[A[ATraining Step: 168  | total loss: [1m[32m0.66826[0m[0m | time: 7.069s
[2K
| RMSProp | epoch: 006 | loss: 0.66826 - acc: 0.6308 -- iter: 0256/1000
[A[ATraining Step: 169  | total loss: [1m[32m0.66538[0m[0m | time: 8.546s
[2K
| RMSProp | epoch: 006 | loss: 0.66538 - acc: 0.6365 -- iter: 0288/1000
[A[ATraining Step: 170  | total loss: [1m[32m0.67012[0m[0m | time: 10.045s
[2K
| RMSProp | epoch: 006 | loss: 0.67012 - acc: 0.6228 -- iter: 0320/1000
[A[ATraining Step: 171  | total loss: [1m[32m0.66932[0m[0m | time: 12.759s
[2K
| RMSProp | epoch: 006 | loss: 0.66932 - acc: 0.6231 -- iter: 0352/1000
[A[ATraining Step: 172  | total loss: [1m[32m0.66497[0m[0m | time: 14.873s
[2K
| RMSProp | epoch: 006 | loss: 0.66497 - acc: 0.6326 -- iter: 0384/1000
[A[ATraining Step: 173  | total loss: [1m[32m0.66590[0m[0m | time: 20.340s
[2K
| RMSProp | epoch: 006 | loss: 0.66590 - acc: 0.6287 -- iter: 0416/1000
[A[ATraining Step: 174  | total loss: [1m[32m0.66971[0m[0m | time: 24.124s
[2K
| RMSProp | epoch: 006 | loss: 0.66971 - acc: 0.6190 -- iter: 0448/1000
[A[ATraining Step: 175  | total loss: [1m[32m0.67144[0m[0m | time: 28.978s
[2K
| RMSProp | epoch: 006 | loss: 0.67144 - acc: 0.6133 -- iter: 0480/1000
[A[ATraining Step: 176  | total loss: [1m[32m0.67177[0m[0m | time: 34.898s
[2K
| RMSProp | epoch: 006 | loss: 0.67177 - acc: 0.6114 -- iter: 0512/1000
[A[ATraining Step: 177  | total loss: [1m[32m0.67094[0m[0m | time: 50.333s
[2K
| RMSProp | epoch: 006 | loss: 0.67094 - acc: 0.6127 -- iter: 0544/1000
[A[ATraining Step: 178  | total loss: [1m[32m0.66873[0m[0m | time: 61.087s
[2K
| RMSProp | epoch: 006 | loss: 0.66873 - acc: 0.6171 -- iter: 0576/1000
[A[ATraining Step: 179  | total loss: [1m[32m0.66685[0m[0m | time: 74.434s
[2K
| RMSProp | epoch: 006 | loss: 0.66685 - acc: 0.6210 -- iter: 0608/1000
[A[ATraining Step: 180  | total loss: [1m[32m0.66937[0m[0m | time: 84.024s
[2K
| RMSProp | epoch: 006 | loss: 0.66937 - acc: 0.6152 -- iter: 0640/1000
[A[ATraining Step: 181  | total loss: [1m[32m0.66478[0m[0m | time: 85.233s
[2K
| RMSProp | epoch: 006 | loss: 0.66478 - acc: 0.6255 -- iter: 0672/1000
[A[ATraining Step: 182  | total loss: [1m[32m0.66110[0m[0m | time: 88.182s
[2K
| RMSProp | epoch: 006 | loss: 0.66110 - acc: 0.6317 -- iter: 0704/1000
[A[ATraining Step: 183  | total loss: [1m[32m0.66543[0m[0m | time: 101.856s
[2K
| RMSProp | epoch: 006 | loss: 0.66543 - acc: 0.6248 -- iter: 0736/1000
[A[ATraining Step: 184  | total loss: [1m[32m0.66767[0m[0m | time: 106.064s
[2K
| RMSProp | epoch: 006 | loss: 0.66767 - acc: 0.6186 -- iter: 0768/1000
[A[ATraining Step: 185  | total loss: [1m[32m0.66718[0m[0m | time: 107.466s
[2K
| RMSProp | epoch: 006 | loss: 0.66718 - acc: 0.6192 -- iter: 0800/1000
[A[ATraining Step: 186  | total loss: [1m[32m0.67192[0m[0m | time: 108.827s
[2K
| RMSProp | epoch: 006 | loss: 0.67192 - acc: 0.6073 -- iter: 0832/1000
[A[ATraining Step: 187  | total loss: [1m[32m0.67003[0m[0m | time: 110.201s
[2K
| RMSProp | epoch: 006 | loss: 0.67003 - acc: 0.6122 -- iter: 0864/1000
[A[ATraining Step: 188  | total loss: [1m[32m0.67300[0m[0m | time: 111.520s
[2K
| RMSProp | epoch: 006 | loss: 0.67300 - acc: 0.6041 -- iter: 0896/1000
[A[ATraining Step: 189  | total loss: [1m[32m0.67434[0m[0m | time: 112.954s
[2K
| RMSProp | epoch: 006 | loss: 0.67434 - acc: 0.5999 -- iter: 0928/1000
[A[ATraining Step: 190  | total loss: [1m[32m0.67339[0m[0m | time: 114.495s
[2K
| RMSProp | epoch: 006 | loss: 0.67339 - acc: 0.6024 -- iter: 0960/1000
[A[ATraining Step: 191  | total loss: [1m[32m0.67490[0m[0m | time: 119.849s
[2K
| RMSProp | epoch: 006 | loss: 0.67490 - acc: 0.5984 -- iter: 0992/1000
[A[ATraining Step: 192  | total loss: [1m[32m0.67376[0m[0m | time: 198.922s
[2K
| RMSProp | epoch: 006 | loss: 0.67376 - acc: 0.6011 | val_loss: 0.66989 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 193  | total loss: [1m[32m0.67166[0m[0m | time: 7.288s
[2K
| RMSProp | epoch: 007 | loss: 0.67166 - acc: 0.6066 -- iter: 0032/1000
[A[ATraining Step: 194  | total loss: [1m[32m0.66556[0m[0m | time: 10.424s
[2K
| RMSProp | epoch: 007 | loss: 0.66556 - acc: 0.6210 -- iter: 0064/1000
[A[ATraining Step: 195  | total loss: [1m[32m0.67063[0m[0m | time: 21.172s
[2K
| RMSProp | epoch: 007 | loss: 0.67063 - acc: 0.6120 -- iter: 0096/1000
[A[ATraining Step: 196  | total loss: [1m[32m0.66736[0m[0m | time: 29.673s
[2K
| RMSProp | epoch: 007 | loss: 0.66736 - acc: 0.6195 -- iter: 0128/1000
[A[ATraining Step: 197  | total loss: [1m[32m0.66411[0m[0m | time: 30.027s
[2K
| RMSProp | epoch: 007 | loss: 0.66411 - acc: 0.6263 -- iter: 0160/1000
[A[ATraining Step: 198  | total loss: [1m[32m0.67045[0m[0m | time: 31.973s
[2K
| RMSProp | epoch: 007 | loss: 0.67045 - acc: 0.6137 -- iter: 0192/1000
[A[ATraining Step: 199  | total loss: [1m[32m0.66977[0m[0m | time: 33.351s
[2K
| RMSProp | epoch: 007 | loss: 0.66977 - acc: 0.6148 -- iter: 0224/1000
[A[ATraining Step: 200  | total loss: [1m[32m0.66898[0m[0m | time: 47.138s
[2K
| RMSProp | epoch: 007 | loss: 0.66898 - acc: 0.6158 | val_loss: 0.66993 - val_acc: 0.6070 -- iter: 0256/1000
--
Training Step: 201  | total loss: [1m[32m0.66709[0m[0m | time: 48.462s
[2K
| RMSProp | epoch: 007 | loss: 0.66709 - acc: 0.6199 -- iter: 0288/1000
[A[ATraining Step: 202  | total loss: [1m[32m0.66953[0m[0m | time: 49.877s
[2K
| RMSProp | epoch: 007 | loss: 0.66953 - acc: 0.6141 -- iter: 0320/1000
[A[ATraining Step: 203  | total loss: [1m[32m0.65849[0m[0m | time: 51.350s
[2K
| RMSProp | epoch: 007 | loss: 0.65849 - acc: 0.6402 -- iter: 0352/1000
[A[ATraining Step: 204  | total loss: [1m[32m0.66614[0m[0m | time: 53.738s
[2K
| RMSProp | epoch: 007 | loss: 0.66614 - acc: 0.6262 -- iter: 0384/1000
[A[ATraining Step: 205  | total loss: [1m[32m0.67102[0m[0m | time: 56.312s
[2K
| RMSProp | epoch: 007 | loss: 0.67102 - acc: 0.6136 -- iter: 0416/1000
[A[ATraining Step: 206  | total loss: [1m[32m0.67256[0m[0m | time: 57.477s
[2K
| RMSProp | epoch: 007 | loss: 0.67256 - acc: 0.6085 -- iter: 0448/1000
[A[ATraining Step: 207  | total loss: [1m[32m0.67497[0m[0m | time: 58.741s
[2K
| RMSProp | epoch: 007 | loss: 0.67497 - acc: 0.6008 -- iter: 0480/1000
[A[ATraining Step: 208  | total loss: [1m[32m0.67291[0m[0m | time: 60.050s
[2K
| RMSProp | epoch: 007 | loss: 0.67291 - acc: 0.6063 -- iter: 0512/1000
[A[ATraining Step: 209  | total loss: [1m[32m0.67586[0m[0m | time: 61.353s
[2K
| RMSProp | epoch: 007 | loss: 0.67586 - acc: 0.5988 -- iter: 0544/1000
[A[ATraining Step: 210  | total loss: [1m[32m0.68131[0m[0m | time: 62.656s
[2K
| RMSProp | epoch: 007 | loss: 0.68131 - acc: 0.5827 -- iter: 0576/1000
[A[ATraining Step: 211  | total loss: [1m[32m0.68066[0m[0m | time: 64.046s
[2K
| RMSProp | epoch: 007 | loss: 0.68066 - acc: 0.5838 -- iter: 0608/1000
[A[ATraining Step: 212  | total loss: [1m[32m0.67403[0m[0m | time: 65.372s
[2K
| RMSProp | epoch: 007 | loss: 0.67403 - acc: 0.6035 -- iter: 0640/1000
[A[ATraining Step: 213  | total loss: [1m[32m0.67044[0m[0m | time: 66.548s
[2K
| RMSProp | epoch: 007 | loss: 0.67044 - acc: 0.6119 -- iter: 0672/1000
[A[ATraining Step: 214  | total loss: [1m[32m0.67108[0m[0m | time: 67.781s
[2K
| RMSProp | epoch: 007 | loss: 0.67108 - acc: 0.6101 -- iter: 0704/1000
[A[ATraining Step: 215  | total loss: [1m[32m0.67410[0m[0m | time: 68.960s
[2K
| RMSProp | epoch: 007 | loss: 0.67410 - acc: 0.6022 -- iter: 0736/1000
[A[ATraining Step: 216  | total loss: [1m[32m0.66962[0m[0m | time: 70.121s
[2K
| RMSProp | epoch: 007 | loss: 0.66962 - acc: 0.6139 -- iter: 0768/1000
[A[ATraining Step: 217  | total loss: [1m[32m0.67159[0m[0m | time: 71.296s
[2K
| RMSProp | epoch: 007 | loss: 0.67159 - acc: 0.6087 -- iter: 0800/1000
[A[ATraining Step: 218  | total loss: [1m[32m0.67090[0m[0m | time: 72.392s
[2K
| RMSProp | epoch: 007 | loss: 0.67090 - acc: 0.6104 -- iter: 0832/1000
[A[ATraining Step: 219  | total loss: [1m[32m0.66752[0m[0m | time: 73.306s
[2K
| RMSProp | epoch: 007 | loss: 0.66752 - acc: 0.6181 -- iter: 0864/1000
[A[ATraining Step: 220  | total loss: [1m[32m0.66536[0m[0m | time: 74.246s
[2K
| RMSProp | epoch: 007 | loss: 0.66536 - acc: 0.6219 -- iter: 0896/1000
[A[ATraining Step: 221  | total loss: [1m[32m0.66495[0m[0m | time: 75.358s
[2K
| RMSProp | epoch: 007 | loss: 0.66495 - acc: 0.6222 -- iter: 0928/1000
[A[ATraining Step: 222  | total loss: [1m[32m0.66934[0m[0m | time: 76.662s
[2K
| RMSProp | epoch: 007 | loss: 0.66934 - acc: 0.6131 -- iter: 0960/1000
[A[ATraining Step: 223  | total loss: [1m[32m0.67007[0m[0m | time: 77.989s
[2K
| RMSProp | epoch: 007 | loss: 0.67007 - acc: 0.6112 -- iter: 0992/1000
[A[ATraining Step: 224  | total loss: [1m[32m0.67067[0m[0m | time: 110.355s
[2K
| RMSProp | epoch: 007 | loss: 0.67067 - acc: 0.6094 | val_loss: 0.67032 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 225  | total loss: [1m[32m0.67111[0m[0m | time: 1.288s
[2K
| RMSProp | epoch: 008 | loss: 0.67111 - acc: 0.6079 -- iter: 0032/1000
[A[ATraining Step: 226  | total loss: [1m[32m0.67266[0m[0m | time: 2.664s
[2K
| RMSProp | epoch: 008 | loss: 0.67266 - acc: 0.6033 -- iter: 0064/1000
[A[ATraining Step: 227  | total loss: [1m[32m0.67409[0m[0m | time: 4.013s
[2K
| RMSProp | epoch: 008 | loss: 0.67409 - acc: 0.5992 -- iter: 0096/1000
[A[ATraining Step: 228  | total loss: [1m[32m0.66864[0m[0m | time: 5.417s
[2K
| RMSProp | epoch: 008 | loss: 0.66864 - acc: 0.6143 -- iter: 0128/1000
[A[ATraining Step: 229  | total loss: [1m[32m0.66692[0m[0m | time: 6.732s
[2K
| RMSProp | epoch: 008 | loss: 0.66692 - acc: 0.6185 -- iter: 0160/1000
[A[ATraining Step: 230  | total loss: [1m[32m0.66626[0m[0m | time: 7.140s
[2K
| RMSProp | epoch: 008 | loss: 0.66626 - acc: 0.6192 -- iter: 0192/1000
[A[ATraining Step: 231  | total loss: [1m[32m0.66641[0m[0m | time: 7.519s
[2K
| RMSProp | epoch: 008 | loss: 0.66641 - acc: 0.6197 -- iter: 0224/1000
[A[ATraining Step: 232  | total loss: [1m[32m0.66097[0m[0m | time: 8.999s
[2K
| RMSProp | epoch: 008 | loss: 0.66097 - acc: 0.6328 -- iter: 0256/1000
[A[ATraining Step: 233  | total loss: [1m[32m0.65914[0m[0m | time: 10.123s
[2K
| RMSProp | epoch: 008 | loss: 0.65914 - acc: 0.6351 -- iter: 0288/1000
[A[ATraining Step: 234  | total loss: [1m[32m0.65555[0m[0m | time: 11.521s
[2K
| RMSProp | epoch: 008 | loss: 0.65555 - acc: 0.6404 -- iter: 0320/1000
[A[ATraining Step: 235  | total loss: [1m[32m0.64598[0m[0m | time: 12.799s
[2K
| RMSProp | epoch: 008 | loss: 0.64598 - acc: 0.6513 -- iter: 0352/1000
[A[ATraining Step: 236  | total loss: [1m[32m0.67170[0m[0m | time: 13.847s
[2K
| RMSProp | epoch: 008 | loss: 0.67170 - acc: 0.6456 -- iter: 0384/1000
[A[ATraining Step: 237  | total loss: [1m[32m0.67354[0m[0m | time: 18.271s
[2K
| RMSProp | epoch: 008 | loss: 0.67354 - acc: 0.6373 -- iter: 0416/1000
[A[ATraining Step: 238  | total loss: [1m[32m0.66987[0m[0m | time: 26.934s
[2K
| RMSProp | epoch: 008 | loss: 0.66987 - acc: 0.6423 -- iter: 0448/1000
[A[ATraining Step: 239  | total loss: [1m[32m0.67172[0m[0m | time: 29.050s
[2K
| RMSProp | epoch: 008 | loss: 0.67172 - acc: 0.6343 -- iter: 0480/1000
[A[ATraining Step: 240  | total loss: [1m[32m0.66792[0m[0m | time: 34.955s
[2K
| RMSProp | epoch: 008 | loss: 0.66792 - acc: 0.6396 -- iter: 0512/1000
[A[ATraining Step: 241  | total loss: [1m[32m0.66167[0m[0m | time: 40.832s
[2K
| RMSProp | epoch: 008 | loss: 0.66167 - acc: 0.6507 -- iter: 0544/1000
[A[ATraining Step: 242  | total loss: [1m[32m0.66528[0m[0m | time: 51.747s
[2K
| RMSProp | epoch: 008 | loss: 0.66528 - acc: 0.6418 -- iter: 0576/1000
[A[ATraining Step: 243  | total loss: [1m[32m0.66327[0m[0m | time: 60.018s
[2K
| RMSProp | epoch: 008 | loss: 0.66327 - acc: 0.6433 -- iter: 0608/1000
[A[ATraining Step: 244  | total loss: [1m[32m0.67293[0m[0m | time: 63.759s
[2K
| RMSProp | epoch: 008 | loss: 0.67293 - acc: 0.6227 -- iter: 0640/1000
[A[ATraining Step: 245  | total loss: [1m[32m0.67187[0m[0m | time: 64.822s
[2K
| RMSProp | epoch: 008 | loss: 0.67187 - acc: 0.6229 -- iter: 0672/1000
[A[ATraining Step: 246  | total loss: [1m[32m0.67620[0m[0m | time: 65.973s
[2K
| RMSProp | epoch: 008 | loss: 0.67620 - acc: 0.6106 -- iter: 0704/1000
[A[ATraining Step: 247  | total loss: [1m[32m0.67128[0m[0m | time: 67.316s
[2K
| RMSProp | epoch: 008 | loss: 0.67128 - acc: 0.6215 -- iter: 0736/1000
[A[ATraining Step: 248  | total loss: [1m[32m0.66761[0m[0m | time: 68.651s
[2K
| RMSProp | epoch: 008 | loss: 0.66761 - acc: 0.6281 -- iter: 0768/1000
[A[ATraining Step: 249  | total loss: [1m[32m0.66574[0m[0m | time: 69.872s
[2K
| RMSProp | epoch: 008 | loss: 0.66574 - acc: 0.6309 -- iter: 0800/1000
[A[ATraining Step: 250  | total loss: [1m[32m0.66075[0m[0m | time: 75.306s
[2K
| RMSProp | epoch: 008 | loss: 0.66075 - acc: 0.6397 -- iter: 0832/1000
[A[ATraining Step: 251  | total loss: [1m[32m0.66075[0m[0m | time: 76.907s
[2K
| RMSProp | epoch: 008 | loss: 0.66075 - acc: 0.6382 -- iter: 0864/1000
[A[ATraining Step: 252  | total loss: [1m[32m0.65733[0m[0m | time: 78.165s
[2K
| RMSProp | epoch: 008 | loss: 0.65733 - acc: 0.6431 -- iter: 0896/1000
[A[ATraining Step: 253  | total loss: [1m[32m0.66138[0m[0m | time: 79.417s
[2K
| RMSProp | epoch: 008 | loss: 0.66138 - acc: 0.6351 -- iter: 0928/1000
[A[ATraining Step: 254  | total loss: [1m[32m0.67107[0m[0m | time: 80.863s
[2K
| RMSProp | epoch: 008 | loss: 0.67107 - acc: 0.6153 -- iter: 0960/1000
[A[ATraining Step: 255  | total loss: [1m[32m0.67413[0m[0m | time: 82.262s
[2K
| RMSProp | epoch: 008 | loss: 0.67413 - acc: 0.6069 -- iter: 0992/1000
[A[ATraining Step: 256  | total loss: [1m[32m0.67293[0m[0m | time: 116.521s
[2K
| RMSProp | epoch: 008 | loss: 0.67293 - acc: 0.6087 | val_loss: 0.67002 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 257  | total loss: [1m[32m0.67068[0m[0m | time: 1.320s
[2K
| RMSProp | epoch: 009 | loss: 0.67068 - acc: 0.6135 -- iter: 0032/1000
[A[ATraining Step: 258  | total loss: [1m[32m0.67100[0m[0m | time: 2.634s
[2K
| RMSProp | epoch: 009 | loss: 0.67100 - acc: 0.6115 -- iter: 0064/1000
[A[ATraining Step: 259  | total loss: [1m[32m0.66744[0m[0m | time: 7.791s
[2K
| RMSProp | epoch: 009 | loss: 0.66744 - acc: 0.6191 -- iter: 0096/1000
[A[ATraining Step: 260  | total loss: [1m[32m0.67737[0m[0m | time: 8.970s
[2K
| RMSProp | epoch: 009 | loss: 0.67737 - acc: 0.5978 -- iter: 0128/1000
[A[ATraining Step: 261  | total loss: [1m[32m0.67955[0m[0m | time: 10.193s
[2K
| RMSProp | epoch: 009 | loss: 0.67955 - acc: 0.5912 -- iter: 0160/1000
[A[ATraining Step: 262  | total loss: [1m[32m0.67809[0m[0m | time: 11.455s
[2K
| RMSProp | epoch: 009 | loss: 0.67809 - acc: 0.5945 -- iter: 0192/1000
[A[ATraining Step: 263  | total loss: [1m[32m0.68247[0m[0m | time: 11.790s
[2K
| RMSProp | epoch: 009 | loss: 0.68247 - acc: 0.5820 -- iter: 0224/1000
[A[ATraining Step: 264  | total loss: [1m[32m0.67654[0m[0m | time: 12.181s
[2K
| RMSProp | epoch: 009 | loss: 0.67654 - acc: 0.5988 -- iter: 0256/1000
[A[ATraining Step: 265  | total loss: [1m[32m0.67073[0m[0m | time: 13.466s
[2K
| RMSProp | epoch: 009 | loss: 0.67073 - acc: 0.6139 -- iter: 0288/1000
[A[ATraining Step: 266  | total loss: [1m[32m0.66861[0m[0m | time: 14.750s
[2K
| RMSProp | epoch: 009 | loss: 0.66861 - acc: 0.6181 -- iter: 0320/1000
[A[ATraining Step: 267  | total loss: [1m[32m0.66658[0m[0m | time: 16.063s
[2K
| RMSProp | epoch: 009 | loss: 0.66658 - acc: 0.6219 -- iter: 0352/1000
[A[ATraining Step: 268  | total loss: [1m[32m0.66477[0m[0m | time: 17.547s
[2K
| RMSProp | epoch: 009 | loss: 0.66477 - acc: 0.6254 -- iter: 0384/1000
[A[ATraining Step: 269  | total loss: [1m[32m0.66945[0m[0m | time: 18.939s
[2K
| RMSProp | epoch: 009 | loss: 0.66945 - acc: 0.6160 -- iter: 0416/1000
[A[ATraining Step: 270  | total loss: [1m[32m0.66874[0m[0m | time: 20.126s
[2K
| RMSProp | epoch: 009 | loss: 0.66874 - acc: 0.6169 -- iter: 0448/1000
[A[ATraining Step: 271  | total loss: [1m[32m0.66382[0m[0m | time: 21.275s
[2K
| RMSProp | epoch: 009 | loss: 0.66382 - acc: 0.6270 -- iter: 0480/1000
[A[ATraining Step: 272  | total loss: [1m[32m0.65877[0m[0m | time: 23.367s
[2K
| RMSProp | epoch: 009 | loss: 0.65877 - acc: 0.6362 -- iter: 0512/1000
[A[ATraining Step: 273  | total loss: [1m[32m0.65936[0m[0m | time: 24.608s
[2K
| RMSProp | epoch: 009 | loss: 0.65936 - acc: 0.6351 -- iter: 0544/1000
[A[ATraining Step: 274  | total loss: [1m[32m0.65631[0m[0m | time: 29.698s
[2K
| RMSProp | epoch: 009 | loss: 0.65631 - acc: 0.6403 -- iter: 0576/1000
[A[ATraining Step: 275  | total loss: [1m[32m0.64776[0m[0m | time: 37.165s
[2K
| RMSProp | epoch: 009 | loss: 0.64776 - acc: 0.6544 -- iter: 0608/1000
[A[ATraining Step: 276  | total loss: [1m[32m0.63727[0m[0m | time: 38.716s
[2K
| RMSProp | epoch: 009 | loss: 0.63727 - acc: 0.6671 -- iter: 0640/1000
[A[ATraining Step: 277  | total loss: [1m[32m0.64529[0m[0m | time: 45.817s
[2K
| RMSProp | epoch: 009 | loss: 0.64529 - acc: 0.6660 -- iter: 0672/1000
[A[ATraining Step: 278  | total loss: [1m[32m0.65246[0m[0m | time: 63.345s
[2K
| RMSProp | epoch: 009 | loss: 0.65246 - acc: 0.6525 -- iter: 0704/1000
[A[ATraining Step: 279  | total loss: [1m[32m0.65836[0m[0m | time: 75.677s
[2K
| RMSProp | epoch: 009 | loss: 0.65836 - acc: 0.6404 -- iter: 0736/1000
[A[ATraining Step: 280  | total loss: [1m[32m0.65728[0m[0m | time: 91.677s
[2K
| RMSProp | epoch: 009 | loss: 0.65728 - acc: 0.6420 -- iter: 0768/1000
[A[ATraining Step: 281  | total loss: [1m[32m0.65946[0m[0m | time: 103.455s
[2K
| RMSProp | epoch: 009 | loss: 0.65946 - acc: 0.6372 -- iter: 0800/1000
[A[ATraining Step: 282  | total loss: [1m[32m0.66267[0m[0m | time: 115.526s
[2K
| RMSProp | epoch: 009 | loss: 0.66267 - acc: 0.6297 -- iter: 0832/1000
[A[ATraining Step: 283  | total loss: [1m[32m0.66969[0m[0m | time: 131.373s
[2K
| RMSProp | epoch: 009 | loss: 0.66969 - acc: 0.6136 -- iter: 0864/1000
[A[ATraining Step: 284  | total loss: [1m[32m0.67141[0m[0m | time: 138.696s
[2K
| RMSProp | epoch: 009 | loss: 0.67141 - acc: 0.6085 -- iter: 0896/1000
[A[ATraining Step: 285  | total loss: [1m[32m0.67184[0m[0m | time: 154.949s
[2K
| RMSProp | epoch: 009 | loss: 0.67184 - acc: 0.6070 -- iter: 0928/1000
[A[ATraining Step: 286  | total loss: [1m[32m0.67999[0m[0m | time: 160.562s
[2K
| RMSProp | epoch: 009 | loss: 0.67999 - acc: 0.5838 -- iter: 0960/1000
[A[ATraining Step: 287  | total loss: [1m[32m0.67970[0m[0m | time: 168.819s
[2K
| RMSProp | epoch: 009 | loss: 0.67970 - acc: 0.5879 -- iter: 0992/1000
[A[ATraining Step: 288  | total loss: [1m[32m0.67746[0m[0m | time: 236.378s
[2K
| RMSProp | epoch: 009 | loss: 0.67746 - acc: 0.5948 | val_loss: 0.67005 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 289  | total loss: [1m[32m0.67369[0m[0m | time: 2.481s
[2K
| RMSProp | epoch: 010 | loss: 0.67369 - acc: 0.6040 -- iter: 0032/1000
[A[ATraining Step: 290  | total loss: [1m[32m0.67517[0m[0m | time: 3.677s
[2K
| RMSProp | epoch: 010 | loss: 0.67517 - acc: 0.5999 -- iter: 0064/1000
[A[ATraining Step: 291  | total loss: [1m[32m0.67391[0m[0m | time: 4.938s
[2K
| RMSProp | epoch: 010 | loss: 0.67391 - acc: 0.6024 -- iter: 0096/1000
[A[ATraining Step: 292  | total loss: [1m[32m0.67263[0m[0m | time: 6.115s
[2K
| RMSProp | epoch: 010 | loss: 0.67263 - acc: 0.6047 -- iter: 0128/1000
[A[ATraining Step: 293  | total loss: [1m[32m0.67435[0m[0m | time: 7.564s
[2K
| RMSProp | epoch: 010 | loss: 0.67435 - acc: 0.6004 -- iter: 0160/1000
[A[ATraining Step: 294  | total loss: [1m[32m0.68079[0m[0m | time: 8.931s
[2K
| RMSProp | epoch: 010 | loss: 0.68079 - acc: 0.5842 -- iter: 0192/1000
[A[ATraining Step: 295  | total loss: [1m[32m0.68053[0m[0m | time: 14.262s
[2K
| RMSProp | epoch: 010 | loss: 0.68053 - acc: 0.5851 -- iter: 0224/1000
[A[ATraining Step: 296  | total loss: [1m[32m0.68016[0m[0m | time: 15.805s
[2K
| RMSProp | epoch: 010 | loss: 0.68016 - acc: 0.5860 -- iter: 0256/1000
[A[ATraining Step: 297  | total loss: [1m[32m0.67407[0m[0m | time: 20.471s
[2K
| RMSProp | epoch: 010 | loss: 0.67407 - acc: 0.6024 -- iter: 0288/1000
[A[ATraining Step: 298  | total loss: [1m[32m0.67318[0m[0m | time: 21.518s
[2K
| RMSProp | epoch: 010 | loss: 0.67318 - acc: 0.6046 -- iter: 0320/1000
[A[ATraining Step: 299  | total loss: [1m[32m0.67210[0m[0m | time: 22.644s
[2K
| RMSProp | epoch: 010 | loss: 0.67210 - acc: 0.6067 -- iter: 0352/1000
[A[ATraining Step: 300  | total loss: [1m[32m0.66972[0m[0m | time: 24.008s
[2K
| RMSProp | epoch: 010 | loss: 0.66972 - acc: 0.6116 -- iter: 0384/1000
[A[ATraining Step: 301  | total loss: [1m[32m0.66454[0m[0m | time: 25.397s
[2K
| RMSProp | epoch: 010 | loss: 0.66454 - acc: 0.6223 -- iter: 0416/1000
[A[ATraining Step: 302  | total loss: [1m[32m0.66054[0m[0m | time: 26.649s
[2K
| RMSProp | epoch: 010 | loss: 0.66054 - acc: 0.6289 -- iter: 0448/1000
[A[ATraining Step: 303  | total loss: [1m[32m0.67145[0m[0m | time: 28.495s
[2K
| RMSProp | epoch: 010 | loss: 0.67145 - acc: 0.6191 -- iter: 0480/1000
[A[ATraining Step: 304  | total loss: [1m[32m0.66488[0m[0m | time: 29.780s
[2K
| RMSProp | epoch: 010 | loss: 0.66488 - acc: 0.6322 -- iter: 0512/1000
[A[ATraining Step: 305  | total loss: [1m[32m0.67083[0m[0m | time: 31.133s
[2K
| RMSProp | epoch: 010 | loss: 0.67083 - acc: 0.6190 -- iter: 0544/1000
[A[ATraining Step: 306  | total loss: [1m[32m0.67557[0m[0m | time: 32.414s
[2K
| RMSProp | epoch: 010 | loss: 0.67557 - acc: 0.6071 -- iter: 0576/1000
[A[ATraining Step: 307  | total loss: [1m[32m0.67559[0m[0m | time: 33.797s
[2K
| RMSProp | epoch: 010 | loss: 0.67559 - acc: 0.6057 -- iter: 0608/1000
[A[ATraining Step: 308  | total loss: [1m[32m0.67565[0m[0m | time: 35.283s
[2K
| RMSProp | epoch: 010 | loss: 0.67565 - acc: 0.6045 -- iter: 0640/1000
[A[ATraining Step: 309  | total loss: [1m[32m0.67809[0m[0m | time: 36.671s
[2K
| RMSProp | epoch: 010 | loss: 0.67809 - acc: 0.5972 -- iter: 0672/1000
[A[ATraining Step: 310  | total loss: [1m[32m0.67330[0m[0m | time: 38.283s
[2K
| RMSProp | epoch: 010 | loss: 0.67330 - acc: 0.6094 -- iter: 0704/1000
[A[ATraining Step: 311  | total loss: [1m[32m0.67218[0m[0m | time: 39.560s
[2K
| RMSProp | epoch: 010 | loss: 0.67218 - acc: 0.6109 -- iter: 0736/1000
[A[ATraining Step: 312  | total loss: [1m[32m0.67264[0m[0m | time: 40.874s
[2K
| RMSProp | epoch: 010 | loss: 0.67264 - acc: 0.6092 -- iter: 0768/1000
[A[ATraining Step: 313  | total loss: [1m[32m0.67689[0m[0m | time: 42.306s
[2K
| RMSProp | epoch: 010 | loss: 0.67689 - acc: 0.5983 -- iter: 0800/1000
[A[ATraining Step: 314  | total loss: [1m[32m0.67683[0m[0m | time: 43.470s
[2K
| RMSProp | epoch: 010 | loss: 0.67683 - acc: 0.5978 -- iter: 0832/1000
[A[ATraining Step: 315  | total loss: [1m[32m0.67794[0m[0m | time: 46.059s
[2K
| RMSProp | epoch: 010 | loss: 0.67794 - acc: 0.5943 -- iter: 0864/1000
[A[ATraining Step: 316  | total loss: [1m[32m0.68131[0m[0m | time: 49.966s
[2K
| RMSProp | epoch: 010 | loss: 0.68131 - acc: 0.5849 -- iter: 0896/1000
[A[ATraining Step: 317  | total loss: [1m[32m0.68081[0m[0m | time: 51.129s
[2K
| RMSProp | epoch: 010 | loss: 0.68081 - acc: 0.5858 -- iter: 0928/1000
[A[ATraining Step: 318  | total loss: [1m[32m0.67927[0m[0m | time: 52.420s
[2K
| RMSProp | epoch: 010 | loss: 0.67927 - acc: 0.5897 -- iter: 0960/1000
[A[ATraining Step: 319  | total loss: [1m[32m0.67340[0m[0m | time: 53.744s
[2K
| RMSProp | epoch: 010 | loss: 0.67340 - acc: 0.6057 -- iter: 0992/1000
[A[ATraining Step: 320  | total loss: [1m[32m0.66973[0m[0m | time: 62.171s
[2K
| RMSProp | epoch: 010 | loss: 0.66973 - acc: 0.6139 | val_loss: 0.67001 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 321  | total loss: [1m[32m0.67015[0m[0m | time: 1.125s
[2K
| RMSProp | epoch: 011 | loss: 0.67015 - acc: 0.6119 -- iter: 0032/1000
[A[ATraining Step: 322  | total loss: [1m[32m0.67207[0m[0m | time: 2.342s
[2K
| RMSProp | epoch: 011 | loss: 0.67207 - acc: 0.6069 -- iter: 0064/1000
[A[ATraining Step: 323  | total loss: [1m[32m0.67368[0m[0m | time: 3.655s
[2K
| RMSProp | epoch: 011 | loss: 0.67368 - acc: 0.6025 -- iter: 0096/1000
[A[ATraining Step: 324  | total loss: [1m[32m0.67269[0m[0m | time: 5.035s
[2K
| RMSProp | epoch: 011 | loss: 0.67269 - acc: 0.6047 -- iter: 0128/1000
[A[ATraining Step: 325  | total loss: [1m[32m0.67037[0m[0m | time: 6.347s
[2K
| RMSProp | epoch: 011 | loss: 0.67037 - acc: 0.6099 -- iter: 0160/1000
[A[ATraining Step: 326  | total loss: [1m[32m0.66681[0m[0m | time: 7.639s
[2K
| RMSProp | epoch: 011 | loss: 0.66681 - acc: 0.6177 -- iter: 0192/1000
[A[ATraining Step: 327  | total loss: [1m[32m0.66479[0m[0m | time: 8.992s
[2K
| RMSProp | epoch: 011 | loss: 0.66479 - acc: 0.6215 -- iter: 0224/1000
[A[ATraining Step: 328  | total loss: [1m[32m0.66090[0m[0m | time: 10.386s
[2K
| RMSProp | epoch: 011 | loss: 0.66090 - acc: 0.6281 -- iter: 0256/1000
[A[ATraining Step: 329  | total loss: [1m[32m0.66969[0m[0m | time: 10.833s
[2K
| RMSProp | epoch: 011 | loss: 0.66969 - acc: 0.6153 -- iter: 0288/1000
[A[ATraining Step: 330  | total loss: [1m[32m0.66928[0m[0m | time: 11.195s
[2K
| RMSProp | epoch: 011 | loss: 0.66928 - acc: 0.6163 -- iter: 0320/1000
[A[ATraining Step: 331  | total loss: [1m[32m0.67438[0m[0m | time: 12.284s
[2K
| RMSProp | epoch: 011 | loss: 0.67438 - acc: 0.6046 -- iter: 0352/1000
[A[ATraining Step: 332  | total loss: [1m[32m0.67829[0m[0m | time: 13.553s
[2K
| RMSProp | epoch: 011 | loss: 0.67829 - acc: 0.5942 -- iter: 0384/1000
[A[ATraining Step: 333  | total loss: [1m[32m0.67469[0m[0m | time: 14.628s
[2K
| RMSProp | epoch: 011 | loss: 0.67469 - acc: 0.6035 -- iter: 0416/1000
[A[ATraining Step: 334  | total loss: [1m[32m0.67977[0m[0m | time: 15.404s
[2K
| RMSProp | epoch: 011 | loss: 0.67977 - acc: 0.5900 -- iter: 0448/1000
[A[ATraining Step: 335  | total loss: [1m[32m0.67708[0m[0m | time: 16.380s
[2K
| RMSProp | epoch: 011 | loss: 0.67708 - acc: 0.5967 -- iter: 0480/1000
[A[ATraining Step: 336  | total loss: [1m[32m0.67687[0m[0m | time: 17.388s
[2K
| RMSProp | epoch: 011 | loss: 0.67687 - acc: 0.5964 -- iter: 0512/1000
[A[ATraining Step: 337  | total loss: [1m[32m0.67534[0m[0m | time: 18.380s
[2K
| RMSProp | epoch: 011 | loss: 0.67534 - acc: 0.5992 -- iter: 0544/1000
[A[ATraining Step: 338  | total loss: [1m[32m0.67419[0m[0m | time: 19.334s
[2K
| RMSProp | epoch: 011 | loss: 0.67419 - acc: 0.6018 -- iter: 0576/1000
[A[ATraining Step: 339  | total loss: [1m[32m0.67549[0m[0m | time: 20.366s
[2K
| RMSProp | epoch: 011 | loss: 0.67549 - acc: 0.5979 -- iter: 0608/1000
[A[ATraining Step: 340  | total loss: [1m[32m0.67439[0m[0m | time: 21.339s
[2K
| RMSProp | epoch: 011 | loss: 0.67439 - acc: 0.6006 -- iter: 0640/1000
[A[ATraining Step: 341  | total loss: [1m[32m0.67946[0m[0m | time: 22.417s
[2K
| RMSProp | epoch: 011 | loss: 0.67946 - acc: 0.5874 -- iter: 0672/1000
[A[ATraining Step: 342  | total loss: [1m[32m0.67696[0m[0m | time: 23.382s
[2K
| RMSProp | epoch: 011 | loss: 0.67696 - acc: 0.5943 -- iter: 0704/1000
[A[ATraining Step: 343  | total loss: [1m[32m0.67317[0m[0m | time: 24.581s
[2K
| RMSProp | epoch: 011 | loss: 0.67317 - acc: 0.6036 -- iter: 0736/1000
[A[ATraining Step: 344  | total loss: [1m[32m0.67350[0m[0m | time: 25.581s
[2K
| RMSProp | epoch: 011 | loss: 0.67350 - acc: 0.6026 -- iter: 0768/1000
[A[ATraining Step: 345  | total loss: [1m[32m0.67376[0m[0m | time: 26.362s
[2K
| RMSProp | epoch: 011 | loss: 0.67376 - acc: 0.6017 -- iter: 0800/1000
[A[ATraining Step: 346  | total loss: [1m[32m0.67146[0m[0m | time: 27.295s
[2K
| RMSProp | epoch: 011 | loss: 0.67146 - acc: 0.6072 -- iter: 0832/1000
[A[ATraining Step: 347  | total loss: [1m[32m0.66391[0m[0m | time: 28.301s
[2K
| RMSProp | epoch: 011 | loss: 0.66391 - acc: 0.6246 -- iter: 0864/1000
[A[ATraining Step: 348  | total loss: [1m[32m0.66699[0m[0m | time: 29.396s
[2K
| RMSProp | epoch: 011 | loss: 0.66699 - acc: 0.6184 -- iter: 0896/1000
[A[ATraining Step: 349  | total loss: [1m[32m0.66817[0m[0m | time: 30.374s
[2K
| RMSProp | epoch: 011 | loss: 0.66817 - acc: 0.6159 -- iter: 0928/1000
[A[ATraining Step: 350  | total loss: [1m[32m0.66190[0m[0m | time: 31.374s
[2K
| RMSProp | epoch: 011 | loss: 0.66190 - acc: 0.6293 -- iter: 0960/1000
[A[ATraining Step: 351  | total loss: [1m[32m0.66353[0m[0m | time: 32.421s
[2K
| RMSProp | epoch: 011 | loss: 0.66353 - acc: 0.6258 -- iter: 0992/1000
[A[ATraining Step: 352  | total loss: [1m[32m0.66959[0m[0m | time: 35.932s
[2K
| RMSProp | epoch: 011 | loss: 0.66959 - acc: 0.6132 | val_loss: 0.67003 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 353  | total loss: [1m[32m0.67148[0m[0m | time: 1.623s
[2K
| RMSProp | epoch: 012 | loss: 0.67148 - acc: 0.6081 -- iter: 0032/1000
[A[ATraining Step: 354  | total loss: [1m[32m0.67057[0m[0m | time: 7.430s
[2K
| RMSProp | epoch: 012 | loss: 0.67057 - acc: 0.6098 -- iter: 0064/1000
[A[ATraining Step: 355  | total loss: [1m[32m0.66716[0m[0m | time: 10.955s
[2K
| RMSProp | epoch: 012 | loss: 0.66716 - acc: 0.6176 -- iter: 0096/1000
[A[ATraining Step: 356  | total loss: [1m[32m0.67091[0m[0m | time: 12.015s
[2K
| RMSProp | epoch: 012 | loss: 0.67091 - acc: 0.6089 -- iter: 0128/1000
[A[ATraining Step: 357  | total loss: [1m[32m0.66999[0m[0m | time: 13.266s
[2K
| RMSProp | epoch: 012 | loss: 0.66999 - acc: 0.6106 -- iter: 0160/1000
[A[ATraining Step: 358  | total loss: [1m[32m0.66937[0m[0m | time: 14.551s
[2K
| RMSProp | epoch: 012 | loss: 0.66937 - acc: 0.6120 -- iter: 0192/1000
[A[ATraining Step: 359  | total loss: [1m[32m0.66727[0m[0m | time: 15.782s
[2K
| RMSProp | epoch: 012 | loss: 0.66727 - acc: 0.6164 -- iter: 0224/1000
[A[ATraining Step: 360  | total loss: [1m[32m0.66508[0m[0m | time: 17.061s
[2K
| RMSProp | epoch: 012 | loss: 0.66508 - acc: 0.6204 -- iter: 0256/1000
[A[ATraining Step: 361  | total loss: [1m[32m0.66471[0m[0m | time: 18.375s
[2K
| RMSProp | epoch: 012 | loss: 0.66471 - acc: 0.6209 -- iter: 0288/1000
[A[ATraining Step: 362  | total loss: [1m[32m0.66429[0m[0m | time: 18.768s
[2K
| RMSProp | epoch: 012 | loss: 0.66429 - acc: 0.6213 -- iter: 0320/1000
[A[ATraining Step: 363  | total loss: [1m[32m0.67025[0m[0m | time: 19.145s
[2K
| RMSProp | epoch: 012 | loss: 0.67025 - acc: 0.6092 -- iter: 0352/1000
[A[ATraining Step: 364  | total loss: [1m[32m0.66382[0m[0m | time: 20.407s
[2K
| RMSProp | epoch: 012 | loss: 0.66382 - acc: 0.6232 -- iter: 0384/1000
[A[ATraining Step: 365  | total loss: [1m[32m0.66060[0m[0m | time: 21.825s
[2K
| RMSProp | epoch: 012 | loss: 0.66060 - acc: 0.6297 -- iter: 0416/1000
[A[ATraining Step: 366  | total loss: [1m[32m0.66546[0m[0m | time: 23.198s
[2K
| RMSProp | epoch: 012 | loss: 0.66546 - acc: 0.6198 -- iter: 0448/1000
[A[ATraining Step: 367  | total loss: [1m[32m0.66517[0m[0m | time: 24.415s
[2K
| RMSProp | epoch: 012 | loss: 0.66517 - acc: 0.6203 -- iter: 0480/1000
[A[ATraining Step: 368  | total loss: [1m[32m0.66476[0m[0m | time: 25.618s
[2K
| RMSProp | epoch: 012 | loss: 0.66476 - acc: 0.6208 -- iter: 0512/1000
[A[ATraining Step: 369  | total loss: [1m[32m0.65993[0m[0m | time: 26.650s
[2K
| RMSProp | epoch: 012 | loss: 0.65993 - acc: 0.6306 -- iter: 0544/1000
[A[ATraining Step: 370  | total loss: [1m[32m0.65817[0m[0m | time: 27.824s
[2K
| RMSProp | epoch: 012 | loss: 0.65817 - acc: 0.6332 -- iter: 0576/1000
[A[ATraining Step: 371  | total loss: [1m[32m0.65815[0m[0m | time: 29.093s
[2K
| RMSProp | epoch: 012 | loss: 0.65815 - acc: 0.6323 -- iter: 0608/1000
[A[ATraining Step: 372  | total loss: [1m[32m0.66026[0m[0m | time: 30.435s
[2K
| RMSProp | epoch: 012 | loss: 0.66026 - acc: 0.6285 -- iter: 0640/1000
[A[ATraining Step: 373  | total loss: [1m[32m0.66213[0m[0m | time: 31.657s
[2K
| RMSProp | epoch: 012 | loss: 0.66213 - acc: 0.6250 -- iter: 0672/1000
[A[ATraining Step: 374  | total loss: [1m[32m0.66682[0m[0m | time: 33.032s
[2K
| RMSProp | epoch: 012 | loss: 0.66682 - acc: 0.6156 -- iter: 0704/1000
[A[ATraining Step: 375  | total loss: [1m[32m0.66631[0m[0m | time: 34.311s
[2K
| RMSProp | epoch: 012 | loss: 0.66631 - acc: 0.6166 -- iter: 0736/1000
[A[ATraining Step: 376  | total loss: [1m[32m0.66282[0m[0m | time: 35.753s
[2K
| RMSProp | epoch: 012 | loss: 0.66282 - acc: 0.6237 -- iter: 0768/1000
[A[ATraining Step: 377  | total loss: [1m[32m0.66729[0m[0m | time: 37.262s
[2K
| RMSProp | epoch: 012 | loss: 0.66729 - acc: 0.6144 -- iter: 0800/1000
[A[ATraining Step: 378  | total loss: [1m[32m0.66262[0m[0m | time: 38.443s
[2K
| RMSProp | epoch: 012 | loss: 0.66262 - acc: 0.6249 -- iter: 0832/1000
[A[ATraining Step: 379  | total loss: [1m[32m0.65761[0m[0m | time: 39.802s
[2K
| RMSProp | epoch: 012 | loss: 0.65761 - acc: 0.6342 -- iter: 0864/1000
[A[ATraining Step: 380  | total loss: [1m[32m0.66156[0m[0m | time: 41.148s
[2K
| RMSProp | epoch: 012 | loss: 0.66156 - acc: 0.6271 -- iter: 0896/1000
[A[ATraining Step: 381  | total loss: [1m[32m0.66288[0m[0m | time: 48.299s
[2K
| RMSProp | epoch: 012 | loss: 0.66288 - acc: 0.6237 -- iter: 0928/1000
[A[ATraining Step: 382  | total loss: [1m[32m0.66879[0m[0m | time: 52.788s
[2K
| RMSProp | epoch: 012 | loss: 0.66879 - acc: 0.6114 -- iter: 0960/1000
[A[ATraining Step: 383  | total loss: [1m[32m0.66660[0m[0m | time: 54.794s
[2K
| RMSProp | epoch: 012 | loss: 0.66660 - acc: 0.6159 -- iter: 0992/1000
[A[ATraining Step: 384  | total loss: [1m[32m0.66757[0m[0m | time: 58.701s
[2K
| RMSProp | epoch: 012 | loss: 0.66757 - acc: 0.6136 | val_loss: 0.66977 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 385  | total loss: [1m[32m0.67276[0m[0m | time: 1.368s
[2K
| RMSProp | epoch: 013 | loss: 0.67276 - acc: 0.6023 -- iter: 0032/1000
[A[ATraining Step: 386  | total loss: [1m[32m0.67301[0m[0m | time: 2.863s
[2K
| RMSProp | epoch: 013 | loss: 0.67301 - acc: 0.6014 -- iter: 0064/1000
[A[ATraining Step: 387  | total loss: [1m[32m0.67710[0m[0m | time: 4.246s
[2K
| RMSProp | epoch: 013 | loss: 0.67710 - acc: 0.5913 -- iter: 0096/1000
[A[ATraining Step: 388  | total loss: [1m[32m0.67810[0m[0m | time: 5.388s
[2K
| RMSProp | epoch: 013 | loss: 0.67810 - acc: 0.5884 -- iter: 0128/1000
[A[ATraining Step: 389  | total loss: [1m[32m0.67557[0m[0m | time: 6.585s
[2K
| RMSProp | epoch: 013 | loss: 0.67557 - acc: 0.5952 -- iter: 0160/1000
[A[ATraining Step: 390  | total loss: [1m[32m0.67551[0m[0m | time: 7.976s
[2K
| RMSProp | epoch: 013 | loss: 0.67551 - acc: 0.5950 -- iter: 0192/1000
[A[ATraining Step: 391  | total loss: [1m[32m0.67409[0m[0m | time: 9.307s
[2K
| RMSProp | epoch: 013 | loss: 0.67409 - acc: 0.5980 -- iter: 0224/1000
[A[ATraining Step: 392  | total loss: [1m[32m0.67405[0m[0m | time: 10.561s
[2K
| RMSProp | epoch: 013 | loss: 0.67405 - acc: 0.5976 -- iter: 0256/1000
[A[ATraining Step: 393  | total loss: [1m[32m0.66889[0m[0m | time: 11.737s
[2K
| RMSProp | epoch: 013 | loss: 0.66889 - acc: 0.6097 -- iter: 0288/1000
[A[ATraining Step: 394  | total loss: [1m[32m0.66224[0m[0m | time: 13.025s
[2K
| RMSProp | epoch: 013 | loss: 0.66224 - acc: 0.6206 -- iter: 0320/1000
[A[ATraining Step: 395  | total loss: [1m[32m0.68346[0m[0m | time: 13.400s
[2K
| RMSProp | epoch: 013 | loss: 0.68346 - acc: 0.6086 -- iter: 0352/1000
[A[ATraining Step: 396  | total loss: [1m[32m0.67519[0m[0m | time: 13.839s
[2K
| RMSProp | epoch: 013 | loss: 0.67519 - acc: 0.6227 -- iter: 0384/1000
[A[ATraining Step: 397  | total loss: [1m[32m0.66635[0m[0m | time: 15.106s
[2K
| RMSProp | epoch: 013 | loss: 0.66635 - acc: 0.6354 -- iter: 0416/1000
[A[ATraining Step: 398  | total loss: [1m[32m0.66925[0m[0m | time: 16.371s
[2K
| RMSProp | epoch: 013 | loss: 0.66925 - acc: 0.6281 -- iter: 0448/1000
[A[ATraining Step: 399  | total loss: [1m[32m0.66487[0m[0m | time: 17.785s
[2K
| RMSProp | epoch: 013 | loss: 0.66487 - acc: 0.6341 -- iter: 0480/1000
[A[ATraining Step: 400  | total loss: [1m[32m0.66980[0m[0m | time: 56.380s
[2K
| RMSProp | epoch: 013 | loss: 0.66980 - acc: 0.6238 | val_loss: 0.66710 - val_acc: 0.6070 -- iter: 0512/1000
--
Training Step: 401  | total loss: [1m[32m0.67190[0m[0m | time: 57.650s
[2K
| RMSProp | epoch: 013 | loss: 0.67190 - acc: 0.6177 -- iter: 0544/1000
[A[ATraining Step: 402  | total loss: [1m[32m0.67684[0m[0m | time: 60.289s
[2K
| RMSProp | epoch: 013 | loss: 0.67684 - acc: 0.6059 -- iter: 0576/1000
[A[ATraining Step: 403  | total loss: [1m[32m0.68162[0m[0m | time: 64.263s
[2K
| RMSProp | epoch: 013 | loss: 0.68162 - acc: 0.5922 -- iter: 0608/1000
[A[ATraining Step: 404  | total loss: [1m[32m0.67633[0m[0m | time: 66.754s
[2K
| RMSProp | epoch: 013 | loss: 0.67633 - acc: 0.6048 -- iter: 0640/1000
[A[ATraining Step: 405  | total loss: [1m[32m0.66909[0m[0m | time: 69.707s
[2K
| RMSProp | epoch: 013 | loss: 0.66909 - acc: 0.6194 -- iter: 0672/1000
[A[ATraining Step: 406  | total loss: [1m[32m0.67104[0m[0m | time: 71.766s
[2K
| RMSProp | epoch: 013 | loss: 0.67104 - acc: 0.6137 -- iter: 0704/1000
[A[ATraining Step: 407  | total loss: [1m[32m0.67569[0m[0m | time: 72.989s
[2K
| RMSProp | epoch: 013 | loss: 0.67569 - acc: 0.6023 -- iter: 0736/1000
[A[ATraining Step: 408  | total loss: [1m[32m0.67375[0m[0m | time: 74.234s
[2K
| RMSProp | epoch: 013 | loss: 0.67375 - acc: 0.6046 -- iter: 0768/1000
[A[ATraining Step: 409  | total loss: [1m[32m0.66807[0m[0m | time: 75.445s
[2K
| RMSProp | epoch: 013 | loss: 0.66807 - acc: 0.6160 -- iter: 0800/1000
[A[ATraining Step: 410  | total loss: [1m[32m0.67226[0m[0m | time: 76.791s
[2K
| RMSProp | epoch: 013 | loss: 0.67226 - acc: 0.6075 -- iter: 0832/1000
[A[ATraining Step: 411  | total loss: [1m[32m0.66549[0m[0m | time: 78.148s
[2K
| RMSProp | epoch: 013 | loss: 0.66549 - acc: 0.6218 -- iter: 0864/1000
[A[ATraining Step: 412  | total loss: [1m[32m0.66586[0m[0m | time: 79.497s
[2K
| RMSProp | epoch: 013 | loss: 0.66586 - acc: 0.6190 -- iter: 0896/1000
[A[ATraining Step: 413  | total loss: [1m[32m0.66506[0m[0m | time: 80.589s
[2K
| RMSProp | epoch: 013 | loss: 0.66506 - acc: 0.6196 -- iter: 0928/1000
[A[ATraining Step: 414  | total loss: [1m[32m0.65354[0m[0m | time: 81.902s
[2K
| RMSProp | epoch: 013 | loss: 0.65354 - acc: 0.6389 -- iter: 0960/1000
[A[ATraining Step: 415  | total loss: [1m[32m0.65962[0m[0m | time: 83.074s
[2K
| RMSProp | epoch: 013 | loss: 0.65962 - acc: 0.6312 -- iter: 0992/1000
[A[ATraining Step: 416  | total loss: [1m[32m0.66052[0m[0m | time: 87.196s
[2K
| RMSProp | epoch: 013 | loss: 0.66052 - acc: 0.6275 | val_loss: 0.66595 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 417  | total loss: [1m[32m0.65634[0m[0m | time: 1.375s
[2K
| RMSProp | epoch: 014 | loss: 0.65634 - acc: 0.6335 -- iter: 0032/1000
[A[ATraining Step: 418  | total loss: [1m[32m0.64805[0m[0m | time: 2.837s
[2K
| RMSProp | epoch: 014 | loss: 0.64805 - acc: 0.6451 -- iter: 0064/1000
[A[ATraining Step: 419  | total loss: [1m[32m0.65087[0m[0m | time: 4.057s
[2K
| RMSProp | epoch: 014 | loss: 0.65087 - acc: 0.6400 -- iter: 0096/1000
[A[ATraining Step: 420  | total loss: [1m[32m0.65975[0m[0m | time: 5.372s
[2K
| RMSProp | epoch: 014 | loss: 0.65975 - acc: 0.6229 -- iter: 0128/1000
[A[ATraining Step: 421  | total loss: [1m[32m0.66334[0m[0m | time: 6.750s
[2K
| RMSProp | epoch: 014 | loss: 0.66334 - acc: 0.6137 -- iter: 0160/1000
[A[ATraining Step: 422  | total loss: [1m[32m0.66323[0m[0m | time: 8.047s
[2K
| RMSProp | epoch: 014 | loss: 0.66323 - acc: 0.6148 -- iter: 0192/1000
[A[ATraining Step: 423  | total loss: [1m[32m0.65937[0m[0m | time: 8.956s
[2K
| RMSProp | epoch: 014 | loss: 0.65937 - acc: 0.6221 -- iter: 0224/1000
[A[ATraining Step: 424  | total loss: [1m[32m0.66380[0m[0m | time: 9.873s
[2K
| RMSProp | epoch: 014 | loss: 0.66380 - acc: 0.6130 -- iter: 0256/1000
[A[ATraining Step: 425  | total loss: [1m[32m0.66575[0m[0m | time: 10.829s
[2K
| RMSProp | epoch: 014 | loss: 0.66575 - acc: 0.6048 -- iter: 0288/1000
[A[ATraining Step: 426  | total loss: [1m[32m0.66261[0m[0m | time: 11.793s
[2K
| RMSProp | epoch: 014 | loss: 0.66261 - acc: 0.6100 -- iter: 0320/1000
[A[ATraining Step: 427  | total loss: [1m[32m0.66343[0m[0m | time: 12.765s
[2K
| RMSProp | epoch: 014 | loss: 0.66343 - acc: 0.6052 -- iter: 0352/1000
[A[ATraining Step: 428  | total loss: [1m[32m0.65855[0m[0m | time: 13.058s
[2K
| RMSProp | epoch: 014 | loss: 0.65855 - acc: 0.6135 -- iter: 0384/1000
[A[ATraining Step: 429  | total loss: [1m[32m0.65677[0m[0m | time: 13.351s
[2K
| RMSProp | epoch: 014 | loss: 0.65677 - acc: 0.6146 -- iter: 0416/1000
[A[ATraining Step: 430  | total loss: [1m[32m0.65215[0m[0m | time: 14.375s
[2K
| RMSProp | epoch: 014 | loss: 0.65215 - acc: 0.6157 -- iter: 0448/1000
[A[ATraining Step: 431  | total loss: [1m[32m0.65403[0m[0m | time: 15.453s
[2K
| RMSProp | epoch: 014 | loss: 0.65403 - acc: 0.6135 -- iter: 0480/1000
[A[ATraining Step: 432  | total loss: [1m[32m0.65770[0m[0m | time: 16.382s
[2K
| RMSProp | epoch: 014 | loss: 0.65770 - acc: 0.6052 -- iter: 0512/1000
[A[ATraining Step: 433  | total loss: [1m[32m0.65874[0m[0m | time: 17.391s
[2K
| RMSProp | epoch: 014 | loss: 0.65874 - acc: 0.6041 -- iter: 0544/1000
[A[ATraining Step: 434  | total loss: [1m[32m0.64531[0m[0m | time: 18.581s
[2K
| RMSProp | epoch: 014 | loss: 0.64531 - acc: 0.6281 -- iter: 0576/1000
[A[ATraining Step: 435  | total loss: [1m[32m0.63508[0m[0m | time: 19.688s
[2K
| RMSProp | epoch: 014 | loss: 0.63508 - acc: 0.6403 -- iter: 0608/1000
[A[ATraining Step: 436  | total loss: [1m[32m0.62312[0m[0m | time: 20.465s
[2K
| RMSProp | epoch: 014 | loss: 0.62312 - acc: 0.6575 -- iter: 0640/1000
[A[ATraining Step: 437  | total loss: [1m[32m0.63103[0m[0m | time: 21.439s
[2K
| RMSProp | epoch: 014 | loss: 0.63103 - acc: 0.6511 -- iter: 0672/1000
[A[ATraining Step: 438  | total loss: [1m[32m0.62921[0m[0m | time: 22.370s
[2K
| RMSProp | epoch: 014 | loss: 0.62921 - acc: 0.6547 -- iter: 0704/1000
[A[ATraining Step: 439  | total loss: [1m[32m0.63444[0m[0m | time: 23.353s
[2K
| RMSProp | epoch: 014 | loss: 0.63444 - acc: 0.6455 -- iter: 0736/1000
[A[ATraining Step: 440  | total loss: [1m[32m0.63997[0m[0m | time: 24.390s
[2K
| RMSProp | epoch: 014 | loss: 0.63997 - acc: 0.6310 -- iter: 0768/1000
[A[ATraining Step: 441  | total loss: [1m[32m0.63995[0m[0m | time: 25.346s
[2K
| RMSProp | epoch: 014 | loss: 0.63995 - acc: 0.6335 -- iter: 0800/1000
[A[ATraining Step: 442  | total loss: [1m[32m0.63209[0m[0m | time: 26.372s
[2K
| RMSProp | epoch: 014 | loss: 0.63209 - acc: 0.6389 -- iter: 0832/1000
[A[ATraining Step: 443  | total loss: [1m[32m0.63647[0m[0m | time: 27.382s
[2K
| RMSProp | epoch: 014 | loss: 0.63647 - acc: 0.6313 -- iter: 0864/1000
[A[ATraining Step: 444  | total loss: [1m[32m0.64172[0m[0m | time: 28.384s
[2K
| RMSProp | epoch: 014 | loss: 0.64172 - acc: 0.6213 -- iter: 0896/1000
[A[ATraining Step: 445  | total loss: [1m[32m0.64430[0m[0m | time: 29.550s
[2K
| RMSProp | epoch: 014 | loss: 0.64430 - acc: 0.6123 -- iter: 0928/1000
[A[ATraining Step: 446  | total loss: [1m[32m0.64201[0m[0m | time: 30.649s
[2K
| RMSProp | epoch: 014 | loss: 0.64201 - acc: 0.6135 -- iter: 0960/1000
[A[ATraining Step: 447  | total loss: [1m[32m0.63932[0m[0m | time: 31.423s
[2K
| RMSProp | epoch: 014 | loss: 0.63932 - acc: 0.6178 -- iter: 0992/1000
[A[ATraining Step: 448  | total loss: [1m[32m0.64198[0m[0m | time: 34.581s
[2K
| RMSProp | epoch: 014 | loss: 0.64198 - acc: 0.6123 | val_loss: 0.63721 - val_acc: 0.6070 -- iter: 1000/1000
--
Training Step: 449  | total loss: [1m[32m0.64389[0m[0m | time: 1.115s
[2K
| RMSProp | epoch: 015 | loss: 0.64389 - acc: 0.6104 -- iter: 0032/1000
[A[ATraining Step: 450  | total loss: [1m[32m0.63484[0m[0m | time: 2.292s
[2K
| RMSProp | epoch: 015 | loss: 0.63484 - acc: 0.6213 -- iter: 0064/1000
[A[ATraining Step: 451  | total loss: [1m[32m0.63047[0m[0m | time: 3.498s
[2K
| RMSProp | epoch: 015 | loss: 0.63047 - acc: 0.6248 -- iter: 0096/1000
[A[ATraining Step: 452  | total loss: [1m[32m0.62860[0m[0m | time: 4.644s
[2K
| RMSProp | epoch: 015 | loss: 0.62860 - acc: 0.6154 -- iter: 0128/1000
[A[ATraining Step: 453  | total loss: [1m[32m0.62342[0m[0m | time: 5.753s
[2K
| RMSProp | epoch: 015 | loss: 0.62342 - acc: 0.6289 -- iter: 0160/1000
[A[ATraining Step: 454  | total loss: [1m[32m0.62061[0m[0m | time: 7.223s
[2K
| RMSProp | epoch: 015 | loss: 0.62061 - acc: 0.6347 -- iter: 0192/1000
[A[ATraining Step: 455  | total loss: [1m[32m0.62964[0m[0m | time: 8.573s
[2K
| RMSProp | epoch: 015 | loss: 0.62964 - acc: 0.6181 -- iter: 0224/1000
[A[ATraining Step: 456  | total loss: [1m[32m0.62970[0m[0m | time: 12.957s
[2K
| RMSProp | epoch: 015 | loss: 0.62970 - acc: 0.6219 -- iter: 0256/1000
[A[ATraining Step: 457  | total loss: [1m[32m0.63628[0m[0m | time: 16.265s
[2K
| RMSProp | epoch: 015 | loss: 0.63628 - acc: 0.6222 -- iter: 0288/1000
[A[ATraining Step: 458  | total loss: [1m[32m0.63590[0m[0m | time: 20.781s
[2K
| RMSProp | epoch: 015 | loss: 0.63590 - acc: 0.6350 -- iter: 0320/1000
[A[ATraining Step: 459  | total loss: [1m[32m0.63878[0m[0m | time: 26.172s
[2K
| RMSProp | epoch: 015 | loss: 0.63878 - acc: 0.6309 -- iter: 0352/1000
[A[ATraining Step: 460  | total loss: [1m[32m0.64015[0m[0m | time: 30.980s
[2K
| RMSProp | epoch: 015 | loss: 0.64015 - acc: 0.6366 -- iter: 0384/1000
[A[ATraining Step: 461  | total loss: [1m[32m0.64190[0m[0m | time: 31.291s
[2K
| RMSProp | epoch: 015 | loss: 0.64190 - acc: 0.6323 -- iter: 0416/1000
[A[ATraining Step: 462  | total loss: [1m[32m0.64121[0m[0m | time: 31.640s
[2K
| RMSProp | epoch: 015 | loss: 0.64121 - acc: 0.6190 -- iter: 0448/1000
[A[ATraining Step: 463  | total loss: [1m[32m0.64094[0m[0m | time: 32.753s
[2K
| RMSProp | epoch: 015 | loss: 0.64094 - acc: 0.6321 -- iter: 0480/1000
[A[ATraining Step: 464  | total loss: [1m[32m0.64001[0m[0m | time: 34.045s
[2K
| RMSProp | epoch: 015 | loss: 0.64001 - acc: 0.6408 -- iter: 0512/1000
[A[ATraining Step: 465  | total loss: [1m[32m0.64034[0m[0m | time: 35.331s
[2K
| RMSProp | epoch: 015 | loss: 0.64034 - acc: 0.6423 -- iter: 0544/1000
[A[ATraining Step: 466  | total loss: [1m[32m0.64302[0m[0m | time: 36.728s
[2K
| RMSProp | epoch: 015 | loss: 0.64302 - acc: 0.6344 -- iter: 0576/1000
[A[ATraining Step: 467  | total loss: [1m[32m0.63845[0m[0m | time: 38.120s
[2K
| RMSProp | epoch: 015 | loss: 0.63845 - acc: 0.6459 -- iter: 0608/1000
[A[ATraining Step: 468  | total loss: [1m[32m0.63246[0m[0m | time: 39.498s
[2K
| RMSProp | epoch: 015 | loss: 0.63246 - acc: 0.6438 -- iter: 0640/1000
[A[ATraining Step: 469  | total loss: [1m[32m0.62635[0m[0m | time: 40.802s
[2K
| RMSProp | epoch: 015 | loss: 0.62635 - acc: 0.6576 -- iter: 0672/1000
[A[ATraining Step: 470  | total loss: [1m[32m0.62613[0m[0m | time: 42.065s
[2K
| RMSProp | epoch: 015 | loss: 0.62613 - acc: 0.6606 -- iter: 0704/1000
[A[ATraining Step: 471  | total loss: [1m[32m0.62090[0m[0m | time: 43.582s
[2K
| RMSProp | epoch: 015 | loss: 0.62090 - acc: 0.6695 -- iter: 0736/1000
[A[ATraining Step: 472  | total loss: [1m[32m0.61018[0m[0m | time: 44.967s
[2K
| RMSProp | epoch: 015 | loss: 0.61018 - acc: 0.6838 -- iter: 0768/1000
[A[ATraining Step: 473  | total loss: [1m[32m0.58814[0m[0m | time: 46.185s
[2K
| RMSProp | epoch: 015 | loss: 0.58814 - acc: 0.6998 -- iter: 0800/1000
[A[ATraining Step: 474  | total loss: [1m[32m0.59631[0m[0m | time: 47.428s
[2K
| RMSProp | epoch: 015 | loss: 0.59631 - acc: 0.6923 -- iter: 0832/1000
[A[ATraining Step: 475  | total loss: [1m[32m0.60045[0m[0m | time: 48.797s
[2K
| RMSProp | epoch: 015 | loss: 0.60045 - acc: 0.6825 -- iter: 0864/1000
[A[ATraining Step: 476  | total loss: [1m[32m0.61753[0m[0m | time: 50.113s
[2K
| RMSProp | epoch: 015 | loss: 0.61753 - acc: 0.6611 -- iter: 0896/1000
[A[ATraining Step: 477  | total loss: [1m[32m0.61667[0m[0m | time: 51.392s
[2K
| RMSProp | epoch: 015 | loss: 0.61667 - acc: 0.6669 -- iter: 0928/1000
[A[ATraining Step: 478  | total loss: [1m[32m0.62947[0m[0m | time: 52.484s
[2K
| RMSProp | epoch: 015 | loss: 0.62947 - acc: 0.6470 -- iter: 0960/1000
[A[ATraining Step: 479  | total loss: [1m[32m0.62390[0m[0m | time: 53.478s
[2K
| RMSProp | epoch: 015 | loss: 0.62390 - acc: 0.6636 -- iter: 0992/1000
[A[ATraining Step: 480  | total loss: [1m[32m0.62993[0m[0m | time: 56.324s
[2K
| RMSProp | epoch: 015 | loss: 0.62993 - acc: 0.6504 | val_loss: 0.60024 - val_acc: 0.7252 -- iter: 1000/1000
--
Training Step: 481  | total loss: [1m[32m0.62511[0m[0m | time: 1.216s
[2K
| RMSProp | epoch: 016 | loss: 0.62511 - acc: 0.6509 -- iter: 0032/1000
[A[ATraining Step: 482  | total loss: [1m[32m0.62376[0m[0m | time: 2.255s
[2K
| RMSProp | epoch: 016 | loss: 0.62376 - acc: 0.6515 -- iter: 0064/1000
[A[ATraining Step: 483  | total loss: [1m[32m0.61391[0m[0m | time: 3.176s
[2K
| RMSProp | epoch: 016 | loss: 0.61391 - acc: 0.6676 -- iter: 0096/1000
[A[ATraining Step: 484  | total loss: [1m[32m0.61452[0m[0m | time: 4.224s
[2K
| RMSProp | epoch: 016 | loss: 0.61452 - acc: 0.6602 -- iter: 0128/1000
[A[ATraining Step: 485  | total loss: [1m[32m0.61425[0m[0m | time: 5.261s
[2K
| RMSProp | epoch: 016 | loss: 0.61425 - acc: 0.6567 -- iter: 0160/1000
[A[ATraining Step: 486  | total loss: [1m[32m0.60078[0m[0m | time: 6.200s
[2K
| RMSProp | epoch: 016 | loss: 0.60078 - acc: 0.6785 -- iter: 0192/1000
[A[ATraining Step: 487  | total loss: [1m[32m0.58746[0m[0m | time: 7.156s
[2K
| RMSProp | epoch: 016 | loss: 0.58746 - acc: 0.6919 -- iter: 0224/1000
[A[ATraining Step: 488  | total loss: [1m[32m0.57486[0m[0m | time: 8.124s
[2K
| RMSProp | epoch: 016 | loss: 0.57486 - acc: 0.7071 -- iter: 0256/1000
[A[ATraining Step: 489  | total loss: [1m[32m0.60415[0m[0m | time: 9.174s
[2K
| RMSProp | epoch: 016 | loss: 0.60415 - acc: 0.6895 -- iter: 0288/1000
[A[ATraining Step: 490  | total loss: [1m[32m0.63222[0m[0m | time: 10.132s
[2K
| RMSProp | epoch: 016 | loss: 0.63222 - acc: 0.6706 -- iter: 0320/1000
[A[ATraining Step: 491  | total loss: [1m[32m0.62196[0m[0m | time: 11.369s
[2K
| RMSProp | epoch: 016 | loss: 0.62196 - acc: 0.6816 -- iter: 0352/1000
[A[ATraining Step: 492  | total loss: [1m[32m0.61142[0m[0m | time: 12.501s
[2K
| RMSProp | epoch: 016 | loss: 0.61142 - acc: 0.6916 -- iter: 0384/1000
[A[ATraining Step: 493  | total loss: [1m[32m0.59829[0m[0m | time: 13.315s
[2K
| RMSProp | epoch: 016 | loss: 0.59829 - acc: 0.6974 -- iter: 0416/1000
[A[ATraining Step: 494  | total loss: [1m[32m0.60790[0m[0m | time: 13.602s
[2K
| RMSProp | epoch: 016 | loss: 0.60790 - acc: 0.6902 -- iter: 0448/1000
[A[ATraining Step: 495  | total loss: [1m[32m0.60540[0m[0m | time: 13.887s
[2K
| RMSProp | epoch: 016 | loss: 0.60540 - acc: 0.6962 -- iter: 0480/1000
[A[ATraining Step: 496  | total loss: [1m[32m0.59817[0m[0m | time: 14.886s
[2K
| RMSProp | epoch: 016 | loss: 0.59817 - acc: 0.7016 -- iter: 0512/1000
[A[ATraining Step: 497  | total loss: [1m[32m0.59556[0m[0m | time: 15.857s
[2K
| RMSProp | epoch: 016 | loss: 0.59556 - acc: 0.7033 -- iter: 0544/1000
[A[ATraining Step: 498  | total loss: [1m[32m0.58522[0m[0m | time: 16.945s
[2K
| RMSProp | epoch: 016 | loss: 0.58522 - acc: 0.7142 -- iter: 0576/1000
[A[ATraining Step: 499  | total loss: [1m[32m0.58877[0m[0m | time: 18.315s
[2K
| RMSProp | epoch: 016 | loss: 0.58877 - acc: 0.7084 -- iter: 0608/1000
[A[ATraining Step: 500  | total loss: [1m[32m0.58508[0m[0m | time: 19.721s
[2K
| RMSProp | epoch: 016 | loss: 0.58508 - acc: 0.7094 -- iter: 0640/1000
[A[ATraining Step: 501  | total loss: [1m[32m0.58472[0m[0m | time: 20.989s
[2K
| RMSProp | epoch: 016 | loss: 0.58472 - acc: 0.7135 -- iter: 0672/1000
[A[ATraining Step: 502  | total loss: [1m[32m0.57883[0m[0m | time: 22.066s
[2K
| RMSProp | epoch: 016 | loss: 0.57883 - acc: 0.7140 -- iter: 0704/1000
[A[ATraining Step: 503  | total loss: [1m[32m0.57439[0m[0m | time: 23.432s
[2K
| RMSProp | epoch: 016 | loss: 0.57439 - acc: 0.7082 -- iter: 0736/1000
[A[ATraining Step: 504  | total loss: [1m[32m0.57249[0m[0m | time: 24.788s
[2K
| RMSProp | epoch: 016 | loss: 0.57249 - acc: 0.7093 -- iter: 0768/1000
[A[ATraining Step: 505  | total loss: [1m[32m0.55087[0m[0m | time: 26.060s
[2K
| RMSProp | epoch: 016 | loss: 0.55087 - acc: 0.7290 -- iter: 0800/1000
[A[ATraining Step: 506  | total loss: [1m[32m0.56344[0m[0m | time: 27.228s
[2K
| RMSProp | epoch: 016 | loss: 0.56344 - acc: 0.7217 -- iter: 0832/1000
[A[ATraining Step: 507  | total loss: [1m[32m0.55819[0m[0m | time: 28.551s
[2K
| RMSProp | epoch: 016 | loss: 0.55819 - acc: 0.7214 -- iter: 0864/1000
[A[ATraining Step: 508  | total loss: [1m[32m0.58627[0m[0m | time: 29.811s
[2K
| RMSProp | epoch: 016 | loss: 0.58627 - acc: 0.6930 -- iter: 0896/1000
[A[ATraining Step: 509  | total loss: [1m[32m0.58270[0m[0m | time: 31.142s
[2K
| RMSProp | epoch: 016 | loss: 0.58270 - acc: 0.7018 -- iter: 0928/1000
[A[ATraining Step: 510  | total loss: [1m[32m0.57837[0m[0m | time: 32.355s
[2K
| RMSProp | epoch: 016 | loss: 0.57837 - acc: 0.7067 -- iter: 0960/1000
[A[ATraining Step: 511  | total loss: [1m[32m0.57784[0m[0m | time: 33.802s
[2K
| RMSProp | epoch: 016 | loss: 0.57784 - acc: 0.7047 -- iter: 0992/1000
[A[ATraining Step: 512  | total loss: [1m[32m0.57262[0m[0m | time: 37.419s
[2K
| RMSProp | epoch: 016 | loss: 0.57262 - acc: 0.7093 | val_loss: 0.56098 - val_acc: 0.7412 -- iter: 1000/1000
--
Training Step: 513  | total loss: [1m[32m0.57226[0m[0m | time: 1.405s
[2K
| RMSProp | epoch: 017 | loss: 0.57226 - acc: 0.7102 -- iter: 0032/1000
[A[ATraining Step: 514  | total loss: [1m[32m0.56547[0m[0m | time: 2.690s
[2K
| RMSProp | epoch: 017 | loss: 0.56547 - acc: 0.7173 -- iter: 0064/1000
[A[ATraining Step: 515  | total loss: [1m[32m0.57427[0m[0m | time: 3.796s
[2K
| RMSProp | epoch: 017 | loss: 0.57427 - acc: 0.7112 -- iter: 0096/1000
[A[ATraining Step: 516  | total loss: [1m[32m0.56107[0m[0m | time: 5.038s
[2K
| RMSProp | epoch: 017 | loss: 0.56107 - acc: 0.7213 -- iter: 0128/1000
[A[ATraining Step: 517  | total loss: [1m[32m0.55084[0m[0m | time: 6.256s
[2K
| RMSProp | epoch: 017 | loss: 0.55084 - acc: 0.7211 -- iter: 0160/1000
[A[ATraining Step: 518  | total loss: [1m[32m0.53926[0m[0m | time: 7.574s
[2K
| RMSProp | epoch: 017 | loss: 0.53926 - acc: 0.7302 -- iter: 0192/1000
[A[ATraining Step: 519  | total loss: [1m[32m0.54479[0m[0m | time: 8.820s
[2K
| RMSProp | epoch: 017 | loss: 0.54479 - acc: 0.7260 -- iter: 0224/1000
[A[ATraining Step: 520  | total loss: [1m[32m0.54660[0m[0m | time: 10.151s
[2K
| RMSProp | epoch: 017 | loss: 0.54660 - acc: 0.7190 -- iter: 0256/1000
[A[ATraining Step: 521  | total loss: [1m[32m0.55329[0m[0m | time: 11.520s
[2K
| RMSProp | epoch: 017 | loss: 0.55329 - acc: 0.7158 -- iter: 0288/1000
[A[ATraining Step: 522  | total loss: [1m[32m0.55392[0m[0m | time: 12.643s
[2K
| RMSProp | epoch: 017 | loss: 0.55392 - acc: 0.7193 -- iter: 0320/1000
[A[ATraining Step: 523  | total loss: [1m[32m0.55897[0m[0m | time: 13.885s
[2K
| RMSProp | epoch: 017 | loss: 0.55897 - acc: 0.7192 -- iter: 0352/1000
[A[ATraining Step: 524  | total loss: [1m[32m0.54630[0m[0m | time: 15.293s
[2K
| RMSProp | epoch: 017 | loss: 0.54630 - acc: 0.7317 -- iter: 0384/1000
[A[ATraining Step: 525  | total loss: [1m[32m0.53892[0m[0m | time: 16.618s
[2K
| RMSProp | epoch: 017 | loss: 0.53892 - acc: 0.7397 -- iter: 0416/1000
[A[ATraining Step: 526  | total loss: [1m[32m0.52292[0m[0m | time: 17.982s
[2K
| RMSProp | epoch: 017 | loss: 0.52292 - acc: 0.7501 -- iter: 0448/1000
[A[ATraining Step: 527  | total loss: [1m[32m0.51836[0m[0m | time: 18.365s
[2K
| RMSProp | epoch: 017 | loss: 0.51836 - acc: 0.7501 -- iter: 0480/1000
[A[ATraining Step: 528  | total loss: [1m[32m0.57012[0m[0m | time: 18.639s
[2K
| RMSProp | epoch: 017 | loss: 0.57012 - acc: 0.7251 -- iter: 0512/1000
[A[ATraining Step: 529  | total loss: [1m[32m0.59442[0m[0m | time: 19.784s
[2K
| RMSProp | epoch: 017 | loss: 0.59442 - acc: 0.7026 -- iter: 0544/1000
[A[ATraining Step: 530  | total loss: [1m[32m0.58875[0m[0m | time: 21.118s
[2K
| RMSProp | epoch: 017 | loss: 0.58875 - acc: 0.7136 -- iter: 0576/1000
[A[ATraining Step: 531  | total loss: [1m[32m0.58442[0m[0m | time: 22.366s
[2K
| RMSProp | epoch: 017 | loss: 0.58442 - acc: 0.7141 -- iter: 0608/1000
[A[ATraining Step: 532  | total loss: [1m[32m0.57035[0m[0m | time: 23.760s
[2K
| RMSProp | epoch: 017 | loss: 0.57035 - acc: 0.7271 -- iter: 0640/1000
[A[ATraining Step: 533  | total loss: [1m[32m0.56055[0m[0m | time: 25.102s
[2K
| RMSProp | epoch: 017 | loss: 0.56055 - acc: 0.7325 -- iter: 0672/1000
[A[ATraining Step: 534  | total loss: [1m[32m0.55585[0m[0m | time: 26.431s
[2K
| RMSProp | epoch: 017 | loss: 0.55585 - acc: 0.7280 -- iter: 0704/1000
[A[ATraining Step: 535  | total loss: [1m[32m0.53946[0m[0m | time: 27.555s
[2K
| RMSProp | epoch: 017 | loss: 0.53946 - acc: 0.7458 -- iter: 0736/1000
[A[ATraining Step: 536  | total loss: [1m[32m0.53890[0m[0m | time: 28.821s
[2K
| RMSProp | epoch: 017 | loss: 0.53890 - acc: 0.7462 -- iter: 0768/1000
[A[ATraining Step: 537  | total loss: [1m[32m0.54682[0m[0m | time: 30.101s
[2K
| RMSProp | epoch: 017 | loss: 0.54682 - acc: 0.7341 -- iter: 0800/1000
[A[ATraining Step: 538  | total loss: [1m[32m0.56155[0m[0m | time: 31.413s
[2K
| RMSProp | epoch: 017 | loss: 0.56155 - acc: 0.7201 -- iter: 0832/1000
[A[ATraining Step: 539  | total loss: [1m[32m0.55741[0m[0m | time: 32.818s
[2K
| RMSProp | epoch: 017 | loss: 0.55741 - acc: 0.7199 -- iter: 0864/1000
[A[ATraining Step: 540  | total loss: [1m[32m0.56207[0m[0m | time: 33.954s
[2K
| RMSProp | epoch: 017 | loss: 0.56207 - acc: 0.7136 -- iter: 0896/1000
[A[ATraining Step: 541  | total loss: [1m[32m0.55431[0m[0m | time: 35.198s
[2K
| RMSProp | epoch: 017 | loss: 0.55431 - acc: 0.7235 -- iter: 0928/1000
[A[ATraining Step: 542  | total loss: [1m[32m0.53719[0m[0m | time: 36.449s
[2K
| RMSProp | epoch: 017 | loss: 0.53719 - acc: 0.7386 -- iter: 0960/1000
[A[ATraining Step: 543  | total loss: [1m[32m0.52240[0m[0m | time: 37.739s
[2K
| RMSProp | epoch: 017 | loss: 0.52240 - acc: 0.7523 -- iter: 0992/1000
[A[ATraining Step: 544  | total loss: [1m[32m0.49631[0m[0m | time: 41.804s
[2K
| RMSProp | epoch: 017 | loss: 0.49631 - acc: 0.7708 | val_loss: 0.55371 - val_acc: 0.7476 -- iter: 1000/1000
--
Training Step: 545  | total loss: [1m[32m0.49952[0m[0m | time: 1.037s
[2K
| RMSProp | epoch: 018 | loss: 0.49952 - acc: 0.7718 -- iter: 0032/1000
[A[ATraining Step: 546  | total loss: [1m[32m0.49029[0m[0m | time: 2.239s
[2K
| RMSProp | epoch: 018 | loss: 0.49029 - acc: 0.7696 -- iter: 0064/1000
[A[ATraining Step: 547  | total loss: [1m[32m0.47786[0m[0m | time: 3.531s
[2K
| RMSProp | epoch: 018 | loss: 0.47786 - acc: 0.7771 -- iter: 0096/1000
[A[ATraining Step: 548  | total loss: [1m[32m0.47803[0m[0m | time: 4.925s
[2K
| RMSProp | epoch: 018 | loss: 0.47803 - acc: 0.7775 -- iter: 0128/1000
[A[ATraining Step: 549  | total loss: [1m[32m0.47179[0m[0m | time: 6.274s
[2K
| RMSProp | epoch: 018 | loss: 0.47179 - acc: 0.7779 -- iter: 0160/1000
[A[ATraining Step: 550  | total loss: [1m[32m0.54268[0m[0m | time: 7.453s
[2K
| RMSProp | epoch: 018 | loss: 0.54268 - acc: 0.7501 -- iter: 0192/1000
[A[ATraining Step: 551  | total loss: [1m[32m0.54918[0m[0m | time: 8.729s
[2K
| RMSProp | epoch: 018 | loss: 0.54918 - acc: 0.7438 -- iter: 0224/1000
[A[ATraining Step: 552  | total loss: [1m[32m0.54651[0m[0m | time: 10.093s
[2K
| RMSProp | epoch: 018 | loss: 0.54651 - acc: 0.7444 -- iter: 0256/1000
[A[ATraining Step: 553  | total loss: [1m[32m0.53916[0m[0m | time: 11.407s
[2K
| RMSProp | epoch: 018 | loss: 0.53916 - acc: 0.7450 -- iter: 0288/1000
[A[ATraining Step: 554  | total loss: [1m[32m0.53369[0m[0m | time: 12.617s
[2K
| RMSProp | epoch: 018 | loss: 0.53369 - acc: 0.7424 -- iter: 0320/1000
[A[ATraining Step: 555  | total loss: [1m[32m0.53215[0m[0m | time: 14.031s
[2K
| RMSProp | epoch: 018 | loss: 0.53215 - acc: 0.7400 -- iter: 0352/1000
[A[ATraining Step: 556  | total loss: [1m[32m0.53229[0m[0m | time: 15.507s
[2K
| RMSProp | epoch: 018 | loss: 0.53229 - acc: 0.7379 -- iter: 0384/1000
[A[ATraining Step: 557  | total loss: [1m[32m0.52667[0m[0m | time: 16.645s
[2K
| RMSProp | epoch: 018 | loss: 0.52667 - acc: 0.7422 -- iter: 0416/1000
[A[ATraining Step: 558  | total loss: [1m[32m0.51115[0m[0m | time: 17.849s
[2K
| RMSProp | epoch: 018 | loss: 0.51115 - acc: 0.7492 -- iter: 0448/1000
[A[ATraining Step: 559  | total loss: [1m[32m0.49371[0m[0m | time: 19.076s
[2K
| RMSProp | epoch: 018 | loss: 0.49371 - acc: 0.7618 -- iter: 0480/1000
[A[ATraining Step: 560  | total loss: [1m[32m0.49106[0m[0m | time: 19.467s
[2K
| RMSProp | epoch: 018 | loss: 0.49106 - acc: 0.7700 -- iter: 0512/1000
[A[ATraining Step: 561  | total loss: [1m[32m0.46126[0m[0m | time: 19.872s
[2K
| RMSProp | epoch: 018 | loss: 0.46126 - acc: 0.7930 -- iter: 0544/1000
[A[ATraining Step: 562  | total loss: [1m[32m0.42662[0m[0m | time: 21.210s
[2K
| RMSProp | epoch: 018 | loss: 0.42662 - acc: 0.8137 -- iter: 0576/1000
[A[ATraining Step: 563  | total loss: [1m[32m0.48095[0m[0m | time: 22.497s
[2K
| RMSProp | epoch: 018 | loss: 0.48095 - acc: 0.7855 -- iter: 0608/1000
[A[ATraining Step: 564  | total loss: [1m[32m0.52042[0m[0m | time: 23.643s
[2K
| RMSProp | epoch: 018 | loss: 0.52042 - acc: 0.7663 -- iter: 0640/1000
[A[ATraining Step: 565  | total loss: [1m[32m0.51645[0m[0m | time: 24.944s
[2K
| RMSProp | epoch: 018 | loss: 0.51645 - acc: 0.7678 -- iter: 0672/1000
[A[ATraining Step: 566  | total loss: [1m[32m0.51668[0m[0m | time: 26.227s
[2K
| RMSProp | epoch: 018 | loss: 0.51668 - acc: 0.7598 -- iter: 0704/1000
[A[ATraining Step: 567  | total loss: [1m[32m0.50819[0m[0m | time: 27.472s
[2K
| RMSProp | epoch: 018 | loss: 0.50819 - acc: 0.7650 -- iter: 0736/1000
[A[ATraining Step: 568  | total loss: [1m[32m0.49808[0m[0m | time: 28.811s
[2K
| RMSProp | epoch: 018 | loss: 0.49808 - acc: 0.7698 -- iter: 0768/1000
[A[ATraining Step: 569  | total loss: [1m[32m0.48960[0m[0m | time: 30.261s
[2K
| RMSProp | epoch: 018 | loss: 0.48960 - acc: 0.7741 -- iter: 0800/1000
[A[ATraining Step: 570  | total loss: [1m[32m0.48202[0m[0m | time: 31.581s
[2K
| RMSProp | epoch: 018 | loss: 0.48202 - acc: 0.7810 -- iter: 0832/1000
[A[ATraining Step: 571  | total loss: [1m[32m0.47745[0m[0m | time: 32.721s
[2K
| RMSProp | epoch: 018 | loss: 0.47745 - acc: 0.7779 -- iter: 0864/1000
[A[ATraining Step: 572  | total loss: [1m[32m0.47187[0m[0m | time: 33.943s
[2K
| RMSProp | epoch: 018 | loss: 0.47187 - acc: 0.7783 -- iter: 0896/1000
[A[ATraining Step: 573  | total loss: [1m[32m0.46786[0m[0m | time: 35.321s
[2K
| RMSProp | epoch: 018 | loss: 0.46786 - acc: 0.7817 -- iter: 0928/1000
[A[ATraining Step: 574  | total loss: [1m[32m0.48003[0m[0m | time: 36.654s
[2K
| RMSProp | epoch: 018 | loss: 0.48003 - acc: 0.7785 -- iter: 0960/1000
[A[ATraining Step: 575  | total loss: [1m[32m0.47247[0m[0m | time: 37.822s
[2K
| RMSProp | epoch: 018 | loss: 0.47247 - acc: 0.7757 -- iter: 0992/1000
[A[ATraining Step: 576  | total loss: [1m[32m0.48075[0m[0m | time: 41.657s
[2K
| RMSProp | epoch: 018 | loss: 0.48075 - acc: 0.7762 | val_loss: 0.51935 - val_acc: 0.7764 -- iter: 1000/1000
--
Training Step: 577  | total loss: [1m[32m0.47858[0m[0m | time: 1.306s
[2K
| RMSProp | epoch: 019 | loss: 0.47858 - acc: 0.7767 -- iter: 0032/1000
[A[ATraining Step: 578  | total loss: [1m[32m0.46615[0m[0m | time: 2.502s
[2K
| RMSProp | epoch: 019 | loss: 0.46615 - acc: 0.7803 -- iter: 0064/1000
[A[ATraining Step: 579  | total loss: [1m[32m0.46026[0m[0m | time: 3.893s
[2K
| RMSProp | epoch: 019 | loss: 0.46026 - acc: 0.7898 -- iter: 0096/1000
[A[ATraining Step: 580  | total loss: [1m[32m0.45591[0m[0m | time: 5.306s
[2K
| RMSProp | epoch: 019 | loss: 0.45591 - acc: 0.7952 -- iter: 0128/1000
[A[ATraining Step: 581  | total loss: [1m[32m0.44114[0m[0m | time: 6.447s
[2K
| RMSProp | epoch: 019 | loss: 0.44114 - acc: 0.8063 -- iter: 0160/1000
[A[ATraining Step: 582  | total loss: [1m[32m0.43316[0m[0m | time: 7.671s
[2K
| RMSProp | epoch: 019 | loss: 0.43316 - acc: 0.8100 -- iter: 0192/1000
[A[ATraining Step: 583  | total loss: [1m[32m0.42645[0m[0m | time: 9.020s
[2K
| RMSProp | epoch: 019 | loss: 0.42645 - acc: 0.8165 -- iter: 0224/1000
[A[ATraining Step: 584  | total loss: [1m[32m0.45414[0m[0m | time: 10.334s
[2K
| RMSProp | epoch: 019 | loss: 0.45414 - acc: 0.8036 -- iter: 0256/1000
[A[ATraining Step: 585  | total loss: [1m[32m0.46638[0m[0m | time: 11.404s
[2K
| RMSProp | epoch: 019 | loss: 0.46638 - acc: 0.7951 -- iter: 0288/1000
[A[ATraining Step: 586  | total loss: [1m[32m0.47023[0m[0m | time: 12.523s
[2K
| RMSProp | epoch: 019 | loss: 0.47023 - acc: 0.7906 -- iter: 0320/1000
[A[ATraining Step: 587  | total loss: [1m[32m0.47314[0m[0m | time: 13.811s
[2K
| RMSProp | epoch: 019 | loss: 0.47314 - acc: 0.7866 -- iter: 0352/1000
[A[ATraining Step: 588  | total loss: [1m[32m0.46124[0m[0m | time: 15.124s
[2K
| RMSProp | epoch: 019 | loss: 0.46124 - acc: 0.7954 -- iter: 0384/1000
[A[ATraining Step: 589  | total loss: [1m[32m0.45724[0m[0m | time: 16.392s
[2K
| RMSProp | epoch: 019 | loss: 0.45724 - acc: 0.7909 -- iter: 0416/1000
[A[ATraining Step: 590  | total loss: [1m[32m0.44912[0m[0m | time: 17.552s
[2K
| RMSProp | epoch: 019 | loss: 0.44912 - acc: 0.7961 -- iter: 0448/1000
[A[ATraining Step: 591  | total loss: [1m[32m0.43435[0m[0m | time: 18.854s
[2K
| RMSProp | epoch: 019 | loss: 0.43435 - acc: 0.8103 -- iter: 0480/1000
[A[ATraining Step: 592  | total loss: [1m[32m0.41472[0m[0m | time: 20.227s
[2K
| RMSProp | epoch: 019 | loss: 0.41472 - acc: 0.8168 -- iter: 0512/1000
[A[ATraining Step: 593  | total loss: [1m[32m0.40627[0m[0m | time: 20.664s
[2K
| RMSProp | epoch: 019 | loss: 0.40627 - acc: 0.8132 -- iter: 0544/1000
[A[ATraining Step: 594  | total loss: [1m[32m0.37551[0m[0m | time: 21.124s
[2K
| RMSProp | epoch: 019 | loss: 0.37551 - acc: 0.8319 -- iter: 0576/1000
[A[ATraining Step: 595  | total loss: [1m[32m0.38406[0m[0m | time: 22.327s
[2K
| RMSProp | epoch: 019 | loss: 0.38406 - acc: 0.8237 -- iter: 0608/1000
[A[ATraining Step: 596  | total loss: [1m[32m0.50591[0m[0m | time: 23.575s
[2K
| RMSProp | epoch: 019 | loss: 0.50591 - acc: 0.7757 -- iter: 0640/1000
[A[ATraining Step: 597  | total loss: [1m[32m0.48877[0m[0m | time: 24.869s
[2K
| RMSProp | epoch: 019 | loss: 0.48877 - acc: 0.7856 -- iter: 0672/1000
[A[ATraining Step: 598  | total loss: [1m[32m0.46653[0m[0m | time: 26.222s
[2K
| RMSProp | epoch: 019 | loss: 0.46653 - acc: 0.8008 -- iter: 0704/1000
[A[ATraining Step: 599  | total loss: [1m[32m0.44645[0m[0m | time: 27.597s
[2K
| RMSProp | epoch: 019 | loss: 0.44645 - acc: 0.8114 -- iter: 0736/1000
[A[ATraining Step: 600  | total loss: [1m[32m0.42911[0m[0m | time: 31.780s
[2K
| RMSProp | epoch: 019 | loss: 0.42911 - acc: 0.8209 | val_loss: 0.79802 - val_acc: 0.7252 -- iter: 0768/1000
--
Training Step: 601  | total loss: [1m[32m0.41999[0m[0m | time: 33.103s
[2K
| RMSProp | epoch: 019 | loss: 0.41999 - acc: 0.8231 -- iter: 0800/1000
[A[ATraining Step: 602  | total loss: [1m[32m0.44255[0m[0m | time: 34.383s
[2K
| RMSProp | epoch: 019 | loss: 0.44255 - acc: 0.8096 -- iter: 0832/1000
[A[ATraining Step: 603  | total loss: [1m[32m0.42402[0m[0m | time: 35.785s
[2K
| RMSProp | epoch: 019 | loss: 0.42402 - acc: 0.8192 -- iter: 0864/1000
[A[ATraining Step: 604  | total loss: [1m[32m0.40716[0m[0m | time: 36.962s
[2K
| RMSProp | epoch: 019 | loss: 0.40716 - acc: 0.8248 -- iter: 0896/1000
[A[ATraining Step: 605  | total loss: [1m[32m0.39927[0m[0m | time: 37.826s
[2K
| RMSProp | epoch: 019 | loss: 0.39927 - acc: 0.8298 -- iter: 0928/1000
[A[ATraining Step: 606  | total loss: [1m[32m0.42189[0m[0m | time: 38.852s
[2K
| RMSProp | epoch: 019 | loss: 0.42189 - acc: 0.8156 -- iter: 0960/1000
[A[ATraining Step: 607  | total loss: [1m[32m0.43774[0m[0m | time: 39.886s
[2K
| RMSProp | epoch: 019 | loss: 0.43774 - acc: 0.8090 -- iter: 0992/1000
[A[ATraining Step: 608  | total loss: [1m[32m0.43279[0m[0m | time: 42.818s
[2K
| RMSProp | epoch: 019 | loss: 0.43279 - acc: 0.8125 | val_loss: 0.49667 - val_acc: 0.7827 -- iter: 1000/1000
--
Training Step: 609  | total loss: [1m[32m0.41288[0m[0m | time: 1.027s
[2K
| RMSProp | epoch: 020 | loss: 0.41288 - acc: 0.8250 -- iter: 0032/1000
[A[ATraining Step: 610  | total loss: [1m[32m0.39129[0m[0m | time: 1.934s
[2K
| RMSProp | epoch: 020 | loss: 0.39129 - acc: 0.8363 -- iter: 0064/1000
[A[ATraining Step: 611  | total loss: [1m[32m0.38134[0m[0m | time: 2.977s
[2K
| RMSProp | epoch: 020 | loss: 0.38134 - acc: 0.8433 -- iter: 0096/1000
[A[ATraining Step: 612  | total loss: [1m[32m0.35573[0m[0m | time: 4.102s
[2K
| RMSProp | epoch: 020 | loss: 0.35573 - acc: 0.8558 -- iter: 0128/1000
[A[ATraining Step: 613  | total loss: [1m[32m0.34878[0m[0m | time: 5.111s
[2K
| RMSProp | epoch: 020 | loss: 0.34878 - acc: 0.8577 -- iter: 0160/1000
[A[ATraining Step: 614  | total loss: [1m[32m0.33334[0m[0m | time: 6.227s
[2K
| RMSProp | epoch: 020 | loss: 0.33334 - acc: 0.8626 -- iter: 0192/1000
[A[ATraining Step: 615  | total loss: [1m[32m0.35304[0m[0m | time: 7.233s
[2K
| RMSProp | epoch: 020 | loss: 0.35304 - acc: 0.8576 -- iter: 0224/1000
[A[ATraining Step: 616  | total loss: [1m[32m0.42178[0m[0m | time: 8.251s
[2K
| RMSProp | epoch: 020 | loss: 0.42178 - acc: 0.8312 -- iter: 0256/1000
[A[ATraining Step: 617  | total loss: [1m[32m0.42474[0m[0m | time: 8.934s
[2K
| RMSProp | epoch: 020 | loss: 0.42474 - acc: 0.8231 -- iter: 0288/1000
[A[ATraining Step: 618  | total loss: [1m[32m0.41965[0m[0m | time: 9.647s
[2K
| RMSProp | epoch: 020 | loss: 0.41965 - acc: 0.8189 -- iter: 0320/1000
[A[ATraining Step: 619  | total loss: [1m[32m0.40245[0m[0m | time: 10.393s
[2K
| RMSProp | epoch: 020 | loss: 0.40245 - acc: 0.8339 -- iter: 0352/1000
[A[ATraining Step: 620  | total loss: [1m[32m0.38660[0m[0m | time: 11.091s
[2K
| RMSProp | epoch: 020 | loss: 0.38660 - acc: 0.8380 -- iter: 0384/1000
[A[ATraining Step: 621  | total loss: [1m[32m0.37035[0m[0m | time: 11.789s
[2K
| RMSProp | epoch: 020 | loss: 0.37035 - acc: 0.8448 -- iter: 0416/1000
[A[ATraining Step: 622  | total loss: [1m[32m0.36335[0m[0m | time: 12.494s
[2K
| RMSProp | epoch: 020 | loss: 0.36335 - acc: 0.8447 -- iter: 0448/1000
[A[ATraining Step: 623  | total loss: [1m[32m0.36176[0m[0m | time: 13.509s
[2K
| RMSProp | epoch: 020 | loss: 0.36176 - acc: 0.8477 -- iter: 0480/1000
[A[ATraining Step: 624  | total loss: [1m[32m0.36839[0m[0m | time: 14.682s
[2K
| RMSProp | epoch: 020 | loss: 0.36839 - acc: 0.8442 -- iter: 0512/1000
[A[ATraining Step: 625  | total loss: [1m[32m0.39158[0m[0m | time: 15.694s
[2K
| RMSProp | epoch: 020 | loss: 0.39158 - acc: 0.8317 -- iter: 0544/1000
[A[ATraining Step: 626  | total loss: [1m[32m0.39694[0m[0m | time: 15.955s
[2K
| RMSProp | epoch: 020 | loss: 0.39694 - acc: 0.8298 -- iter: 0576/1000
[A[ATraining Step: 627  | total loss: [1m[32m0.38763[0m[0m | time: 16.214s
[2K
| RMSProp | epoch: 020 | loss: 0.38763 - acc: 0.8343 -- iter: 0608/1000
[A[ATraining Step: 628  | total loss: [1m[32m0.40786[0m[0m | time: 17.229s
[2K
| RMSProp | epoch: 020 | loss: 0.40786 - acc: 0.8383 -- iter: 0640/1000
[A[ATraining Step: 629  | total loss: [1m[32m0.39165[0m[0m | time: 18.106s
[2K
| RMSProp | epoch: 020 | loss: 0.39165 - acc: 0.8514 -- iter: 0672/1000
[A[ATraining Step: 630  | total loss: [1m[32m0.38196[0m[0m | time: 19.071s
[2K
| RMSProp | epoch: 020 | loss: 0.38196 - acc: 0.8537 -- iter: 0704/1000
[A[ATraining Step: 631  | total loss: [1m[32m0.36120[0m[0m | time: 20.084s
[2K
| RMSProp | epoch: 020 | loss: 0.36120 - acc: 0.8652 -- iter: 0736/1000
[A[ATraining Step: 632  | total loss: [1m[32m0.33935[0m[0m | time: 21.107s
[2K
| RMSProp | epoch: 020 | loss: 0.33935 - acc: 0.8725 -- iter: 0768/1000
[A[ATraining Step: 633  | total loss: [1m[32m0.32545[0m[0m | time: 22.145s
[2K
| RMSProp | epoch: 020 | loss: 0.32545 - acc: 0.8821 -- iter: 0800/1000
[A[ATraining Step: 634  | total loss: [1m[32m0.31967[0m[0m | time: 23.089s
[2K
| RMSProp | epoch: 020 | loss: 0.31967 - acc: 0.8783 -- iter: 0832/1000
[A[ATraining Step: 635  | total loss: [1m[32m0.32537[0m[0m | time: 23.993s
[2K
| RMSProp | epoch: 020 | loss: 0.32537 - acc: 0.8686 -- iter: 0864/1000
[A[ATraining Step: 636  | total loss: [1m[32m0.39309[0m[0m | time: 24.822s
[2K
| RMSProp | epoch: 020 | loss: 0.39309 - acc: 0.8317 -- iter: 0896/1000
[A[ATraining Step: 637  | total loss: [1m[32m0.37709[0m[0m | time: 25.700s
[2K
| RMSProp | epoch: 020 | loss: 0.37709 - acc: 0.8454 -- iter: 0928/1000
[A[ATraining Step: 638  | total loss: [1m[32m0.36668[0m[0m | time: 26.524s
[2K
| RMSProp | epoch: 020 | loss: 0.36668 - acc: 0.8452 -- iter: 0960/1000
[A[ATraining Step: 639  | total loss: [1m[32m0.35154[0m[0m | time: 27.417s
[2K
| RMSProp | epoch: 020 | loss: 0.35154 - acc: 0.8545 -- iter: 0992/1000
[A[ATraining Step: 640  | total loss: [1m[32m0.34555[0m[0m | time: 31.174s
[2K
| RMSProp | epoch: 020 | loss: 0.34555 - acc: 0.8596 | val_loss: 0.57840 - val_acc: 0.7796 -- iter: 1000/1000
--
Training Step: 641  | total loss: [1m[32m0.32340[0m[0m | time: 1.169s
[2K
| RMSProp | epoch: 021 | loss: 0.32340 - acc: 0.8737 -- iter: 0032/1000
[A[ATraining Step: 642  | total loss: [1m[32m0.30761[0m[0m | time: 2.343s
[2K
| RMSProp | epoch: 021 | loss: 0.30761 - acc: 0.8769 -- iter: 0064/1000
[A[ATraining Step: 643  | total loss: [1m[32m0.28817[0m[0m | time: 3.516s
[2K
| RMSProp | epoch: 021 | loss: 0.28817 - acc: 0.8861 -- iter: 0096/1000
[A[ATraining Step: 644  | total loss: [1m[32m0.26917[0m[0m | time: 4.786s
[2K
| RMSProp | epoch: 021 | loss: 0.26917 - acc: 0.8944 -- iter: 0128/1000
[A[ATraining Step: 645  | total loss: [1m[32m0.25492[0m[0m | time: 6.066s
[2K
| RMSProp | epoch: 021 | loss: 0.25492 - acc: 0.9018 -- iter: 0160/1000
[A[ATraining Step: 646  | total loss: [1m[32m0.28388[0m[0m | time: 7.346s
[2K
| RMSProp | epoch: 021 | loss: 0.28388 - acc: 0.8741 -- iter: 0192/1000
[A[ATraining Step: 647  | total loss: [1m[32m0.34596[0m[0m | time: 8.644s
[2K
| RMSProp | epoch: 021 | loss: 0.34596 - acc: 0.8524 -- iter: 0224/1000
[A[ATraining Step: 648  | total loss: [1m[32m0.35481[0m[0m | time: 9.973s
[2K
| RMSProp | epoch: 021 | loss: 0.35481 - acc: 0.8546 -- iter: 0256/1000
[A[ATraining Step: 649  | total loss: [1m[32m0.34920[0m[0m | time: 11.322s
[2K
| RMSProp | epoch: 021 | loss: 0.34920 - acc: 0.8535 -- iter: 0288/1000
[A[ATraining Step: 650  | total loss: [1m[32m0.32743[0m[0m | time: 12.536s
[2K
| RMSProp | epoch: 021 | loss: 0.32743 - acc: 0.8682 -- iter: 0320/1000
[A[ATraining Step: 651  | total loss: [1m[32m0.32025[0m[0m | time: 13.909s
[2K
| RMSProp | epoch: 021 | loss: 0.32025 - acc: 0.8689 -- iter: 0352/1000
[A[ATraining Step: 652  | total loss: [1m[32m0.33007[0m[0m | time: 15.404s
[2K
| RMSProp | epoch: 021 | loss: 0.33007 - acc: 0.8632 -- iter: 0384/1000
[A[ATraining Step: 653  | total loss: [1m[32m0.34791[0m[0m | time: 16.721s
[2K
| RMSProp | epoch: 021 | loss: 0.34791 - acc: 0.8457 -- iter: 0416/1000
[A[ATraining Step: 654  | total loss: [1m[32m0.35645[0m[0m | time: 17.683s
[2K
| RMSProp | epoch: 021 | loss: 0.35645 - acc: 0.8392 -- iter: 0448/1000
[A[ATraining Step: 655  | total loss: [1m[32m0.33895[0m[0m | time: 18.968s
[2K
| RMSProp | epoch: 021 | loss: 0.33895 - acc: 0.8490 -- iter: 0480/1000
[A[ATraining Step: 656  | total loss: [1m[32m0.32573[0m[0m | time: 20.271s
[2K
| RMSProp | epoch: 021 | loss: 0.32573 - acc: 0.8579 -- iter: 0512/1000
[A[ATraining Step: 657  | total loss: [1m[32m0.31109[0m[0m | time: 21.492s
[2K
| RMSProp | epoch: 021 | loss: 0.31109 - acc: 0.8627 -- iter: 0544/1000
[A[ATraining Step: 658  | total loss: [1m[32m0.29353[0m[0m | time: 22.814s
[2K
| RMSProp | epoch: 021 | loss: 0.29353 - acc: 0.8733 -- iter: 0576/1000
[A[ATraining Step: 659  | total loss: [1m[32m0.30383[0m[0m | time: 23.236s
[2K
| RMSProp | epoch: 021 | loss: 0.30383 - acc: 0.8735 -- iter: 0608/1000
[A[ATraining Step: 660  | total loss: [1m[32m0.28203[0m[0m | time: 23.654s
[2K
| RMSProp | epoch: 021 | loss: 0.28203 - acc: 0.8861 -- iter: 0640/1000
[A[ATraining Step: 661  | total loss: [1m[32m0.25621[0m[0m | time: 24.817s
[2K
| RMSProp | epoch: 021 | loss: 0.25621 - acc: 0.8975 -- iter: 0672/1000
[A[ATraining Step: 662  | total loss: [1m[32m0.23566[0m[0m | time: 26.097s
[2K
| RMSProp | epoch: 021 | loss: 0.23566 - acc: 0.9078 -- iter: 0704/1000
[A[ATraining Step: 663  | total loss: [1m[32m0.21634[0m[0m | time: 27.381s
[2K
| RMSProp | epoch: 021 | loss: 0.21634 - acc: 0.9170 -- iter: 0736/1000
[A[ATraining Step: 664  | total loss: [1m[32m0.20738[0m[0m | time: 28.611s
[2K
| RMSProp | epoch: 021 | loss: 0.20738 - acc: 0.9190 -- iter: 0768/1000
[A[ATraining Step: 665  | total loss: [1m[32m0.19272[0m[0m | time: 29.976s
[2K
| RMSProp | epoch: 021 | loss: 0.19272 - acc: 0.9240 -- iter: 0800/1000
[A[ATraining Step: 666  | total loss: [1m[32m0.18380[0m[0m | time: 31.289s
[2K
| RMSProp | epoch: 021 | loss: 0.18380 - acc: 0.9254 -- iter: 0832/1000
[A[ATraining Step: 667  | total loss: [1m[32m0.19804[0m[0m | time: 32.445s
[2K
| RMSProp | epoch: 021 | loss: 0.19804 - acc: 0.9141 -- iter: 0864/1000
[A[ATraining Step: 668  | total loss: [1m[32m0.22516[0m[0m | time: 33.615s
[2K
| RMSProp | epoch: 021 | loss: 0.22516 - acc: 0.9008 -- iter: 0896/1000
[A[ATraining Step: 669  | total loss: [1m[32m0.24561[0m[0m | time: 34.863s
[2K
| RMSProp | epoch: 021 | loss: 0.24561 - acc: 0.8888 -- iter: 0928/1000
[A[ATraining Step: 670  | total loss: [1m[32m0.24004[0m[0m | time: 36.143s
[2K
| RMSProp | epoch: 021 | loss: 0.24004 - acc: 0.8937 -- iter: 0960/1000
[A[ATraining Step: 671  | total loss: [1m[32m0.24243[0m[0m | time: 37.408s
[2K
| RMSProp | epoch: 021 | loss: 0.24243 - acc: 0.8887 -- iter: 0992/1000
[A[ATraining Step: 672  | total loss: [1m[32m0.22973[0m[0m | time: 41.414s
[2K
| RMSProp | epoch: 021 | loss: 0.22973 - acc: 0.8967 | val_loss: 0.51712 - val_acc: 0.7955 -- iter: 1000/1000
--
Training Step: 673  | total loss: [1m[32m0.21638[0m[0m | time: 1.308s
[2K
| RMSProp | epoch: 022 | loss: 0.21638 - acc: 0.9039 -- iter: 0032/1000
[A[ATraining Step: 674  | total loss: [1m[32m0.20971[0m[0m | time: 2.717s
[2K
| RMSProp | epoch: 022 | loss: 0.20971 - acc: 0.9073 -- iter: 0064/1000
[A[ATraining Step: 675  | total loss: [1m[32m0.26007[0m[0m | time: 3.971s
[2K
| RMSProp | epoch: 022 | loss: 0.26007 - acc: 0.8884 -- iter: 0096/1000
[A[ATraining Step: 676  | total loss: [1m[32m0.26540[0m[0m | time: 5.225s
[2K
| RMSProp | epoch: 022 | loss: 0.26540 - acc: 0.8871 -- iter: 0128/1000
[A[ATraining Step: 677  | total loss: [1m[32m0.25880[0m[0m | time: 6.283s
[2K
| RMSProp | epoch: 022 | loss: 0.25880 - acc: 0.8859 -- iter: 0160/1000
[A[ATraining Step: 678  | total loss: [1m[32m0.24970[0m[0m | time: 7.577s
[2K
| RMSProp | epoch: 022 | loss: 0.24970 - acc: 0.8879 -- iter: 0192/1000
[A[ATraining Step: 679  | total loss: [1m[32m0.25008[0m[0m | time: 8.749s
[2K
| RMSProp | epoch: 022 | loss: 0.25008 - acc: 0.8835 -- iter: 0224/1000
[A[ATraining Step: 680  | total loss: [1m[32m0.25096[0m[0m | time: 10.092s
[2K
| RMSProp | epoch: 022 | loss: 0.25096 - acc: 0.8826 -- iter: 0256/1000
[A[ATraining Step: 681  | total loss: [1m[32m0.24932[0m[0m | time: 11.375s
[2K
| RMSProp | epoch: 022 | loss: 0.24932 - acc: 0.8850 -- iter: 0288/1000
[A[ATraining Step: 682  | total loss: [1m[32m0.25449[0m[0m | time: 12.785s
[2K
| RMSProp | epoch: 022 | loss: 0.25449 - acc: 0.8871 -- iter: 0320/1000
[A[ATraining Step: 683  | total loss: [1m[32m0.24811[0m[0m | time: 14.201s
[2K
| RMSProp | epoch: 022 | loss: 0.24811 - acc: 0.8922 -- iter: 0352/1000
[A[ATraining Step: 684  | total loss: [1m[32m0.23540[0m[0m | time: 15.656s
[2K
| RMSProp | epoch: 022 | loss: 0.23540 - acc: 0.8998 -- iter: 0384/1000
[A[ATraining Step: 685  | total loss: [1m[32m0.22510[0m[0m | time: 16.937s
[2K
| RMSProp | epoch: 022 | loss: 0.22510 - acc: 0.9067 -- iter: 0416/1000
[A[ATraining Step: 686  | total loss: [1m[32m0.21541[0m[0m | time: 18.222s
[2K
| RMSProp | epoch: 022 | loss: 0.21541 - acc: 0.9098 -- iter: 0448/1000
[A[ATraining Step: 687  | total loss: [1m[32m0.21290[0m[0m | time: 19.520s
[2K
| RMSProp | epoch: 022 | loss: 0.21290 - acc: 0.9126 -- iter: 0480/1000
[A[ATraining Step: 688  | total loss: [1m[32m0.21179[0m[0m | time: 20.652s
[2K
| RMSProp | epoch: 022 | loss: 0.21179 - acc: 0.9119 -- iter: 0512/1000
[A[ATraining Step: 689  | total loss: [1m[32m0.22137[0m[0m | time: 21.896s
[2K
| RMSProp | epoch: 022 | loss: 0.22137 - acc: 0.9051 -- iter: 0544/1000
[A[ATraining Step: 690  | total loss: [1m[32m0.24215[0m[0m | time: 23.156s
[2K
| RMSProp | epoch: 022 | loss: 0.24215 - acc: 0.8927 -- iter: 0576/1000
[A[ATraining Step: 691  | total loss: [1m[32m0.24830[0m[0m | time: 24.409s
[2K
| RMSProp | epoch: 022 | loss: 0.24830 - acc: 0.8941 -- iter: 0608/1000
[A[ATraining Step: 692  | total loss: [1m[32m0.23294[0m[0m | time: 24.793s
[2K
| RMSProp | epoch: 022 | loss: 0.23294 - acc: 0.9015 -- iter: 0640/1000
[A[ATraining Step: 693  | total loss: [1m[32m0.21194[0m[0m | time: 25.145s
[2K
| RMSProp | epoch: 022 | loss: 0.21194 - acc: 0.9114 -- iter: 0672/1000
[A[ATraining Step: 694  | total loss: [1m[32m0.19559[0m[0m | time: 26.448s
[2K
| RMSProp | epoch: 022 | loss: 0.19559 - acc: 0.9203 -- iter: 0704/1000
[A[ATraining Step: 695  | total loss: [1m[32m0.18239[0m[0m | time: 27.802s
[2K
| RMSProp | epoch: 022 | loss: 0.18239 - acc: 0.9251 -- iter: 0736/1000
[A[ATraining Step: 696  | total loss: [1m[32m0.17521[0m[0m | time: 29.111s
[2K
| RMSProp | epoch: 022 | loss: 0.17521 - acc: 0.9263 -- iter: 0768/1000
[A[ATraining Step: 697  | total loss: [1m[32m0.17439[0m[0m | time: 30.462s
[2K
| RMSProp | epoch: 022 | loss: 0.17439 - acc: 0.9306 -- iter: 0800/1000
[A[ATraining Step: 698  | total loss: [1m[32m0.16011[0m[0m | time: 31.863s
[2K
| RMSProp | epoch: 022 | loss: 0.16011 - acc: 0.9375 -- iter: 0832/1000
[A[ATraining Step: 699  | total loss: [1m[32m0.15236[0m[0m | time: 33.110s
[2K
| RMSProp | epoch: 022 | loss: 0.15236 - acc: 0.9406 -- iter: 0864/1000
[A[ATraining Step: 700  | total loss: [1m[32m0.14136[0m[0m | time: 34.391s
[2K
| RMSProp | epoch: 022 | loss: 0.14136 - acc: 0.9435 -- iter: 0896/1000
[A[ATraining Step: 701  | total loss: [1m[32m0.13758[0m[0m | time: 35.800s
[2K
| RMSProp | epoch: 022 | loss: 0.13758 - acc: 0.9460 -- iter: 0928/1000
[A[ATraining Step: 702  | total loss: [1m[32m0.13016[0m[0m | time: 36.984s
[2K
| RMSProp | epoch: 022 | loss: 0.13016 - acc: 0.9483 -- iter: 0960/1000
[A[ATraining Step: 703  | total loss: [1m[32m0.13054[0m[0m | time: 38.206s
[2K
| RMSProp | epoch: 022 | loss: 0.13054 - acc: 0.9503 -- iter: 0992/1000
[A[ATraining Step: 704  | total loss: [1m[32m0.12534[0m[0m | time: 42.026s
[2K
| RMSProp | epoch: 022 | loss: 0.12534 - acc: 0.9522 | val_loss: 0.68610 - val_acc: 0.8019 -- iter: 1000/1000
--
Training Step: 705  | total loss: [1m[32m0.12134[0m[0m | time: 1.355s
[2K
| RMSProp | epoch: 023 | loss: 0.12134 - acc: 0.9507 -- iter: 0032/1000
[A[ATraining Step: 706  | total loss: [1m[32m0.11841[0m[0m | time: 2.705s
[2K
| RMSProp | epoch: 023 | loss: 0.11841 - acc: 0.9494 -- iter: 0064/1000
[A[ATraining Step: 707  | total loss: [1m[32m0.12952[0m[0m | time: 4.135s
[2K
| RMSProp | epoch: 023 | loss: 0.12952 - acc: 0.9482 -- iter: 0096/1000
[A[ATraining Step: 708  | total loss: [1m[32m0.14547[0m[0m | time: 5.421s
[2K
| RMSProp | epoch: 023 | loss: 0.14547 - acc: 0.9440 -- iter: 0128/1000
[A[ATraining Step: 709  | total loss: [1m[32m0.20818[0m[0m | time: 6.626s
[2K
| RMSProp | epoch: 023 | loss: 0.20818 - acc: 0.9215 -- iter: 0160/1000
[A[ATraining Step: 710  | total loss: [1m[32m0.20039[0m[0m | time: 7.886s
[2K
| RMSProp | epoch: 023 | loss: 0.20039 - acc: 0.9231 -- iter: 0192/1000
[A[ATraining Step: 711  | total loss: [1m[32m0.19273[0m[0m | time: 9.143s
[2K
| RMSProp | epoch: 023 | loss: 0.19273 - acc: 0.9245 -- iter: 0224/1000
[A[ATraining Step: 712  | total loss: [1m[32m0.18365[0m[0m | time: 10.138s
[2K
| RMSProp | epoch: 023 | loss: 0.18365 - acc: 0.9321 -- iter: 0256/1000
[A[ATraining Step: 713  | total loss: [1m[32m0.19307[0m[0m | time: 11.441s
[2K
| RMSProp | epoch: 023 | loss: 0.19307 - acc: 0.9295 -- iter: 0288/1000
[A[ATraining Step: 714  | total loss: [1m[32m0.20815[0m[0m | time: 12.772s
[2K
| RMSProp | epoch: 023 | loss: 0.20815 - acc: 0.9209 -- iter: 0320/1000
[A[ATraining Step: 715  | total loss: [1m[32m0.21803[0m[0m | time: 14.086s
[2K
| RMSProp | epoch: 023 | loss: 0.21803 - acc: 0.9163 -- iter: 0352/1000
[A[ATraining Step: 716  | total loss: [1m[32m0.23355[0m[0m | time: 15.411s
[2K
| RMSProp | epoch: 023 | loss: 0.23355 - acc: 0.9122 -- iter: 0384/1000
[A[ATraining Step: 717  | total loss: [1m[32m0.22897[0m[0m | time: 16.744s
[2K
| RMSProp | epoch: 023 | loss: 0.22897 - acc: 0.9116 -- iter: 0416/1000
[A[ATraining Step: 718  | total loss: [1m[32m0.21393[0m[0m | time: 17.958s
[2K
| RMSProp | epoch: 023 | loss: 0.21393 - acc: 0.9204 -- iter: 0448/1000
[A[ATraining Step: 719  | total loss: [1m[32m0.20023[0m[0m | time: 19.354s
[2K
| RMSProp | epoch: 023 | loss: 0.20023 - acc: 0.9284 -- iter: 0480/1000
[A[ATraining Step: 720  | total loss: [1m[32m0.18538[0m[0m | time: 20.735s
[2K
| RMSProp | epoch: 023 | loss: 0.18538 - acc: 0.9356 -- iter: 0512/1000
[A[ATraining Step: 721  | total loss: [1m[32m0.17982[0m[0m | time: 22.002s
[2K
| RMSProp | epoch: 023 | loss: 0.17982 - acc: 0.9389 -- iter: 0544/1000
[A[ATraining Step: 722  | total loss: [1m[32m0.17207[0m[0m | time: 23.289s
[2K
| RMSProp | epoch: 023 | loss: 0.17207 - acc: 0.9419 -- iter: 0576/1000
[A[ATraining Step: 723  | total loss: [1m[32m0.17527[0m[0m | time: 24.603s
[2K
| RMSProp | epoch: 023 | loss: 0.17527 - acc: 0.9414 -- iter: 0608/1000
[A[ATraining Step: 724  | total loss: [1m[32m0.16324[0m[0m | time: 25.586s
[2K
| RMSProp | epoch: 023 | loss: 0.16324 - acc: 0.9442 -- iter: 0640/1000
[A[ATraining Step: 725  | total loss: [1m[32m0.15393[0m[0m | time: 25.951s
[2K
| RMSProp | epoch: 023 | loss: 0.15393 - acc: 0.9466 -- iter: 0672/1000
[A[ATraining Step: 726  | total loss: [1m[32m0.14009[0m[0m | time: 26.306s
[2K
| RMSProp | epoch: 023 | loss: 0.14009 - acc: 0.9520 -- iter: 0704/1000
[A[ATraining Step: 727  | total loss: [1m[32m0.17589[0m[0m | time: 27.569s
[2K
| RMSProp | epoch: 023 | loss: 0.17589 - acc: 0.9443 -- iter: 0736/1000
[A[ATraining Step: 728  | total loss: [1m[32m0.16312[0m[0m | time: 28.862s
[2K
| RMSProp | epoch: 023 | loss: 0.16312 - acc: 0.9498 -- iter: 0768/1000
[A[ATraining Step: 729  | total loss: [1m[32m0.15525[0m[0m | time: 30.190s
[2K
| RMSProp | epoch: 023 | loss: 0.15525 - acc: 0.9517 -- iter: 0800/1000
[A[ATraining Step: 730  | total loss: [1m[32m0.14308[0m[0m | time: 31.527s
[2K
| RMSProp | epoch: 023 | loss: 0.14308 - acc: 0.9566 -- iter: 0832/1000
[A[ATraining Step: 731  | total loss: [1m[32m0.13071[0m[0m | time: 32.858s
[2K
| RMSProp | epoch: 023 | loss: 0.13071 - acc: 0.9609 -- iter: 0864/1000
[A[ATraining Step: 732  | total loss: [1m[32m0.12075[0m[0m | time: 34.110s
[2K
| RMSProp | epoch: 023 | loss: 0.12075 - acc: 0.9648 -- iter: 0896/1000
[A[ATraining Step: 733  | total loss: [1m[32m0.11053[0m[0m | time: 35.503s
[2K
| RMSProp | epoch: 023 | loss: 0.11053 - acc: 0.9683 -- iter: 0928/1000
[A[ATraining Step: 734  | total loss: [1m[32m0.10068[0m[0m | time: 36.878s
[2K
| RMSProp | epoch: 023 | loss: 0.10068 - acc: 0.9715 -- iter: 0960/1000
[A[ATraining Step: 735  | total loss: [1m[32m0.09193[0m[0m | time: 38.260s
[2K
| RMSProp | epoch: 023 | loss: 0.09193 - acc: 0.9743 -- iter: 0992/1000
[A[ATraining Step: 736  | total loss: [1m[32m0.08348[0m[0m | time: 41.514s
[2K
| RMSProp | epoch: 023 | loss: 0.08348 - acc: 0.9769 | val_loss: 0.66998 - val_acc: 0.8083 -- iter: 1000/1000
--
Training Step: 737  | total loss: [1m[32m0.07635[0m[0m | time: 1.280s
[2K
| RMSProp | epoch: 024 | loss: 0.07635 - acc: 0.9792 -- iter: 0032/1000
[A[ATraining Step: 738  | total loss: [1m[32m0.07927[0m[0m | time: 2.538s
[2K
| RMSProp | epoch: 024 | loss: 0.07927 - acc: 0.9750 -- iter: 0064/1000
[A[ATraining Step: 739  | total loss: [1m[32m0.17040[0m[0m | time: 3.834s
[2K
| RMSProp | epoch: 024 | loss: 0.17040 - acc: 0.9494 -- iter: 0096/1000
[A[ATraining Step: 740  | total loss: [1m[32m0.19680[0m[0m | time: 5.171s
[2K
| RMSProp | epoch: 024 | loss: 0.19680 - acc: 0.9389 -- iter: 0128/1000
[A[ATraining Step: 741  | total loss: [1m[32m0.19256[0m[0m | time: 6.455s
[2K
| RMSProp | epoch: 024 | loss: 0.19256 - acc: 0.9387 -- iter: 0160/1000
[A[ATraining Step: 742  | total loss: [1m[32m0.18223[0m[0m | time: 7.649s
[2K
| RMSProp | epoch: 024 | loss: 0.18223 - acc: 0.9448 -- iter: 0192/1000
[A[ATraining Step: 743  | total loss: [1m[32m0.17099[0m[0m | time: 9.087s
[2K
| RMSProp | epoch: 024 | loss: 0.17099 - acc: 0.9472 -- iter: 0224/1000
[A[ATraining Step: 744  | total loss: [1m[32m0.17258[0m[0m | time: 10.501s
[2K
| RMSProp | epoch: 024 | loss: 0.17258 - acc: 0.9463 -- iter: 0256/1000
[A[ATraining Step: 745  | total loss: [1m[32m0.19483[0m[0m | time: 11.919s
[2K
| RMSProp | epoch: 024 | loss: 0.19483 - acc: 0.9423 -- iter: 0288/1000
[A[ATraining Step: 746  | total loss: [1m[32m0.18796[0m[0m | time: 13.159s
[2K
| RMSProp | epoch: 024 | loss: 0.18796 - acc: 0.9418 -- iter: 0320/1000
[A[ATraining Step: 747  | total loss: [1m[32m0.18753[0m[0m | time: 14.546s
[2K
| RMSProp | epoch: 024 | loss: 0.18753 - acc: 0.9414 -- iter: 0352/1000
[A[ATraining Step: 748  | total loss: [1m[32m0.17526[0m[0m | time: 15.756s
[2K
| RMSProp | epoch: 024 | loss: 0.17526 - acc: 0.9441 -- iter: 0384/1000
[A[ATraining Step: 749  | total loss: [1m[32m0.17405[0m[0m | time: 17.062s
[2K
| RMSProp | epoch: 024 | loss: 0.17405 - acc: 0.9466 -- iter: 0416/1000
[A[ATraining Step: 750  | total loss: [1m[32m0.16125[0m[0m | time: 18.405s
[2K
| RMSProp | epoch: 024 | loss: 0.16125 - acc: 0.9519 -- iter: 0448/1000
[A[ATraining Step: 751  | total loss: [1m[32m0.14748[0m[0m | time: 19.781s
[2K
| RMSProp | epoch: 024 | loss: 0.14748 - acc: 0.9567 -- iter: 0480/1000
[A[ATraining Step: 752  | total loss: [1m[32m0.13778[0m[0m | time: 21.136s
[2K
| RMSProp | epoch: 024 | loss: 0.13778 - acc: 0.9610 -- iter: 0512/1000
[A[ATraining Step: 753  | total loss: [1m[32m0.13954[0m[0m | time: 22.560s
[2K
| RMSProp | epoch: 024 | loss: 0.13954 - acc: 0.9618 -- iter: 0544/1000
[A[ATraining Step: 754  | total loss: [1m[32m0.15413[0m[0m | time: 23.896s
[2K
| RMSProp | epoch: 024 | loss: 0.15413 - acc: 0.9531 -- iter: 0576/1000
[A[ATraining Step: 755  | total loss: [1m[32m0.16417[0m[0m | time: 25.183s
[2K
| RMSProp | epoch: 024 | loss: 0.16417 - acc: 0.9453 -- iter: 0608/1000
[A[ATraining Step: 756  | total loss: [1m[32m0.16663[0m[0m | time: 26.580s
[2K
| RMSProp | epoch: 024 | loss: 0.16663 - acc: 0.9445 -- iter: 0640/1000
[A[ATraining Step: 757  | total loss: [1m[32m0.15246[0m[0m | time: 27.956s
[2K
| RMSProp | epoch: 024 | loss: 0.15246 - acc: 0.9501 -- iter: 0672/1000
[A[ATraining Step: 758  | total loss: [1m[32m0.14236[0m[0m | time: 28.385s
[2K
| RMSProp | epoch: 024 | loss: 0.14236 - acc: 0.9551 -- iter: 0704/1000
[A[ATraining Step: 759  | total loss: [1m[32m0.13965[0m[0m | time: 28.837s
[2K
| RMSProp | epoch: 024 | loss: 0.13965 - acc: 0.9471 -- iter: 0736/1000
[A[ATraining Step: 760  | total loss: [1m[32m0.15358[0m[0m | time: 30.135s
[2K
| RMSProp | epoch: 024 | loss: 0.15358 - acc: 0.9399 -- iter: 0768/1000
[A[ATraining Step: 761  | total loss: [1m[32m0.14908[0m[0m | time: 31.406s
[2K
| RMSProp | epoch: 024 | loss: 0.14908 - acc: 0.9427 -- iter: 0800/1000
[A[ATraining Step: 762  | total loss: [1m[32m0.13645[0m[0m | time: 32.735s
[2K
| RMSProp | epoch: 024 | loss: 0.13645 - acc: 0.9485 -- iter: 0832/1000
[A[ATraining Step: 763  | total loss: [1m[32m0.12499[0m[0m | time: 33.860s
[2K
| RMSProp | epoch: 024 | loss: 0.12499 - acc: 0.9536 -- iter: 0864/1000
[A[ATraining Step: 764  | total loss: [1m[32m0.11384[0m[0m | time: 34.813s
[2K
| RMSProp | epoch: 024 | loss: 0.11384 - acc: 0.9583 -- iter: 0896/1000
[A[ATraining Step: 765  | total loss: [1m[32m0.10393[0m[0m | time: 35.816s
[2K
| RMSProp | epoch: 024 | loss: 0.10393 - acc: 0.9624 -- iter: 0928/1000
[A[ATraining Step: 766  | total loss: [1m[32m0.09466[0m[0m | time: 36.836s
[2K
| RMSProp | epoch: 024 | loss: 0.09466 - acc: 0.9662 -- iter: 0960/1000
[A[ATraining Step: 767  | total loss: [1m[32m0.08654[0m[0m | time: 37.873s
[2K
| RMSProp | epoch: 024 | loss: 0.08654 - acc: 0.9696 -- iter: 0992/1000
[A[ATraining Step: 768  | total loss: [1m[32m0.09100[0m[0m | time: 40.847s
[2K
| RMSProp | epoch: 024 | loss: 0.09100 - acc: 0.9664 | val_loss: 0.76809 - val_acc: 0.7859 -- iter: 1000/1000
--
Training Step: 769  | total loss: [1m[32m0.08583[0m[0m | time: 1.130s
[2K
| RMSProp | epoch: 025 | loss: 0.08583 - acc: 0.9697 -- iter: 0032/1000
[A[ATraining Step: 770  | total loss: [1m[32m0.07825[0m[0m | time: 2.279s
[2K
| RMSProp | epoch: 025 | loss: 0.07825 - acc: 0.9728 -- iter: 0064/1000
[A[ATraining Step: 771  | total loss: [1m[32m0.08186[0m[0m | time: 3.439s
[2K
| RMSProp | epoch: 025 | loss: 0.08186 - acc: 0.9724 -- iter: 0096/1000
[A[ATraining Step: 772  | total loss: [1m[32m0.08881[0m[0m | time: 4.608s
[2K
| RMSProp | epoch: 025 | loss: 0.08881 - acc: 0.9657 -- iter: 0128/1000
[A[ATraining Step: 773  | total loss: [1m[32m0.14892[0m[0m | time: 5.686s
[2K
| RMSProp | epoch: 025 | loss: 0.14892 - acc: 0.9442 -- iter: 0160/1000
[A[ATraining Step: 774  | total loss: [1m[32m0.15637[0m[0m | time: 6.695s
[2K
| RMSProp | epoch: 025 | loss: 0.15637 - acc: 0.9341 -- iter: 0192/1000
[A[ATraining Step: 775  | total loss: [1m[32m0.14926[0m[0m | time: 7.407s
[2K
| RMSProp | epoch: 025 | loss: 0.14926 - acc: 0.9407 -- iter: 0224/1000
[A[ATraining Step: 776  | total loss: [1m[32m0.13688[0m[0m | time: 8.086s
[2K
| RMSProp | epoch: 025 | loss: 0.13688 - acc: 0.9466 -- iter: 0256/1000
[A[ATraining Step: 777  | total loss: [1m[32m0.13554[0m[0m | time: 8.840s
[2K
| RMSProp | epoch: 025 | loss: 0.13554 - acc: 0.9457 -- iter: 0288/1000
[A[ATraining Step: 778  | total loss: [1m[32m0.12743[0m[0m | time: 9.563s
[2K
| RMSProp | epoch: 025 | loss: 0.12743 - acc: 0.9480 -- iter: 0320/1000
[A[ATraining Step: 779  | total loss: [1m[32m0.11643[0m[0m | time: 10.315s
[2K
| RMSProp | epoch: 025 | loss: 0.11643 - acc: 0.9532 -- iter: 0352/1000
[A[ATraining Step: 780  | total loss: [1m[32m0.10614[0m[0m | time: 11.004s
[2K
| RMSProp | epoch: 025 | loss: 0.10614 - acc: 0.9579 -- iter: 0384/1000
[A[ATraining Step: 781  | total loss: [1m[32m0.09654[0m[0m | time: 11.720s
[2K
| RMSProp | epoch: 025 | loss: 0.09654 - acc: 0.9621 -- iter: 0416/1000
[A[ATraining Step: 782  | total loss: [1m[32m0.08807[0m[0m | time: 12.384s
[2K
| RMSProp | epoch: 025 | loss: 0.08807 - acc: 0.9659 -- iter: 0448/1000
[A[ATraining Step: 783  | total loss: [1m[32m0.11715[0m[0m | time: 13.086s
[2K
| RMSProp | epoch: 025 | loss: 0.11715 - acc: 0.9631 -- iter: 0480/1000
[A[ATraining Step: 784  | total loss: [1m[32m0.10928[0m[0m | time: 13.988s
[2K
| RMSProp | epoch: 025 | loss: 0.10928 - acc: 0.9668 -- iter: 0512/1000
[A[ATraining Step: 785  | total loss: [1m[32m0.10286[0m[0m | time: 15.144s
[2K
| RMSProp | epoch: 025 | loss: 0.10286 - acc: 0.9670 -- iter: 0544/1000
[A[ATraining Step: 786  | total loss: [1m[32m0.09358[0m[0m | time: 16.183s
[2K
| RMSProp | epoch: 025 | loss: 0.09358 - acc: 0.9703 -- iter: 0576/1000
[A[ATraining Step: 787  | total loss: [1m[32m0.08750[0m[0m | time: 17.045s
[2K
| RMSProp | epoch: 025 | loss: 0.08750 - acc: 0.9732 -- iter: 0608/1000
[A[ATraining Step: 788  | total loss: [1m[32m0.10396[0m[0m | time: 18.034s
[2K
| RMSProp | epoch: 025 | loss: 0.10396 - acc: 0.9665 -- iter: 0640/1000
[A[ATraining Step: 789  | total loss: [1m[32m0.11203[0m[0m | time: 19.014s
[2K
| RMSProp | epoch: 025 | loss: 0.11203 - acc: 0.9636 -- iter: 0672/1000
[A[ATraining Step: 790  | total loss: [1m[32m0.10316[0m[0m | time: 19.947s
[2K
| RMSProp | epoch: 025 | loss: 0.10316 - acc: 0.9673 -- iter: 0704/1000
[A[ATraining Step: 791  | total loss: [1m[32m0.09531[0m[0m | time: 20.257s
[2K
| RMSProp | epoch: 025 | loss: 0.09531 - acc: 0.9705 -- iter: 0736/1000
[A[ATraining Step: 792  | total loss: [1m[32m0.08743[0m[0m | time: 20.550s
[2K
| RMSProp | epoch: 025 | loss: 0.08743 - acc: 0.9735 -- iter: 0768/1000
[A[ATraining Step: 793  | total loss: [1m[32m0.07903[0m[0m | time: 21.663s
[2K
| RMSProp | epoch: 025 | loss: 0.07903 - acc: 0.9761 -- iter: 0800/1000
[A[ATraining Step: 794  | total loss: [1m[32m0.07513[0m[0m | time: 22.661s
[2K
| RMSProp | epoch: 025 | loss: 0.07513 - acc: 0.9754 -- iter: 0832/1000
[A[ATraining Step: 795  | total loss: [1m[32m0.06921[0m[0m | time: 23.601s
[2K
| RMSProp | epoch: 025 | loss: 0.06921 - acc: 0.9779 -- iter: 0864/1000
[A[ATraining Step: 796  | total loss: [1m[32m0.06256[0m[0m | time: 24.571s
[2K
| RMSProp | epoch: 025 | loss: 0.06256 - acc: 0.9801 -- iter: 0896/1000
[A[ATraining Step: 797  | total loss: [1m[32m0.05666[0m[0m | time: 25.824s
[2K
| RMSProp | epoch: 025 | loss: 0.05666 - acc: 0.9821 -- iter: 0928/1000
[A[ATraining Step: 798  | total loss: [1m[32m0.05644[0m[0m | time: 26.966s
[2K
| RMSProp | epoch: 025 | loss: 0.05644 - acc: 0.9807 -- iter: 0960/1000
[A[ATraining Step: 799  | total loss: [1m[32m0.15508[0m[0m | time: 27.821s
[2K
| RMSProp | epoch: 025 | loss: 0.15508 - acc: 0.9514 -- iter: 0992/1000
[A[ATraining Step: 800  | total loss: [1m[32m0.15098[0m[0m | time: 30.694s
[2K
| RMSProp | epoch: 025 | loss: 0.15098 - acc: 0.9500 | val_loss: 0.58041 - val_acc: 0.8211 -- iter: 1000/1000
--
Training Step: 801  | total loss: [1m[32m0.13895[0m[0m | time: 1.062s
[2K
| RMSProp | epoch: 026 | loss: 0.13895 - acc: 0.9519 -- iter: 0032/1000
[A[ATraining Step: 802  | total loss: [1m[32m0.13373[0m[0m | time: 2.111s
[2K
| RMSProp | epoch: 026 | loss: 0.13373 - acc: 0.9536 -- iter: 0064/1000
[A[ATraining Step: 803  | total loss: [1m[32m0.12137[0m[0m | time: 3.068s
[2K
| RMSProp | epoch: 026 | loss: 0.12137 - acc: 0.9582 -- iter: 0096/1000
[A[ATraining Step: 804  | total loss: [1m[32m0.11046[0m[0m | time: 4.078s
[2K
| RMSProp | epoch: 026 | loss: 0.11046 - acc: 0.9624 -- iter: 0128/1000
[A[ATraining Step: 805  | total loss: [1m[32m0.10076[0m[0m | time: 5.203s
[2K
| RMSProp | epoch: 026 | loss: 0.10076 - acc: 0.9662 -- iter: 0160/1000
[A[ATraining Step: 806  | total loss: [1m[32m0.09592[0m[0m | time: 6.356s
[2K
| RMSProp | epoch: 026 | loss: 0.09592 - acc: 0.9664 -- iter: 0192/1000
[A[ATraining Step: 807  | total loss: [1m[32m0.08696[0m[0m | time: 7.725s
[2K
| RMSProp | epoch: 026 | loss: 0.08696 - acc: 0.9698 -- iter: 0224/1000
[A[ATraining Step: 808  | total loss: [1m[32m0.08076[0m[0m | time: 8.956s
[2K
| RMSProp | epoch: 026 | loss: 0.08076 - acc: 0.9728 -- iter: 0256/1000
[A[ATraining Step: 809  | total loss: [1m[32m0.07764[0m[0m | time: 10.114s
[2K
| RMSProp | epoch: 026 | loss: 0.07764 - acc: 0.9724 -- iter: 0288/1000
[A[ATraining Step: 810  | total loss: [1m[32m0.09249[0m[0m | time: 11.316s
[2K
| RMSProp | epoch: 026 | loss: 0.09249 - acc: 0.9720 -- iter: 0320/1000
[A[ATraining Step: 811  | total loss: [1m[32m0.10863[0m[0m | time: 12.647s
[2K
| RMSProp | epoch: 026 | loss: 0.10863 - acc: 0.9623 -- iter: 0352/1000
[A[ATraining Step: 812  | total loss: [1m[32m0.12715[0m[0m | time: 13.983s
[2K
| RMSProp | epoch: 026 | loss: 0.12715 - acc: 0.9536 -- iter: 0384/1000
[A[ATraining Step: 813  | total loss: [1m[32m0.11666[0m[0m | time: 15.294s
[2K
| RMSProp | epoch: 026 | loss: 0.11666 - acc: 0.9582 -- iter: 0416/1000
[A[ATraining Step: 814  | total loss: [1m[32m0.11414[0m[0m | time: 16.656s
[2K
| RMSProp | epoch: 026 | loss: 0.11414 - acc: 0.9562 -- iter: 0448/1000
[A[ATraining Step: 815  | total loss: [1m[32m0.10420[0m[0m | time: 18.071s
[2K
| RMSProp | epoch: 026 | loss: 0.10420 - acc: 0.9605 -- iter: 0480/1000
[A[ATraining Step: 816  | total loss: [1m[32m0.09545[0m[0m | time: 19.358s
[2K
| RMSProp | epoch: 026 | loss: 0.09545 - acc: 0.9645 -- iter: 0512/1000
[A[ATraining Step: 817  | total loss: [1m[32m0.10317[0m[0m | time: 20.841s
[2K
| RMSProp | epoch: 026 | loss: 0.10317 - acc: 0.9618 -- iter: 0544/1000
[A[ATraining Step: 818  | total loss: [1m[32m0.11434[0m[0m | time: 22.153s
[2K
| RMSProp | epoch: 026 | loss: 0.11434 - acc: 0.9562 -- iter: 0576/1000
[A[ATraining Step: 819  | total loss: [1m[32m0.11669[0m[0m | time: 23.412s
[2K
| RMSProp | epoch: 026 | loss: 0.11669 - acc: 0.9544 -- iter: 0608/1000
[A[ATraining Step: 820  | total loss: [1m[32m0.12381[0m[0m | time: 24.701s
[2K
| RMSProp | epoch: 026 | loss: 0.12381 - acc: 0.9558 -- iter: 0640/1000
[A[ATraining Step: 821  | total loss: [1m[32m0.12678[0m[0m | time: 25.851s
[2K
| RMSProp | epoch: 026 | loss: 0.12678 - acc: 0.9540 -- iter: 0672/1000
[A[ATraining Step: 822  | total loss: [1m[32m0.11894[0m[0m | time: 27.064s
[2K
| RMSProp | epoch: 026 | loss: 0.11894 - acc: 0.9554 -- iter: 0704/1000
[A[ATraining Step: 823  | total loss: [1m[32m0.10849[0m[0m | time: 28.382s
[2K
| RMSProp | epoch: 026 | loss: 0.10849 - acc: 0.9599 -- iter: 0736/1000
[A[ATraining Step: 824  | total loss: [1m[32m0.10040[0m[0m | time: 28.803s
[2K
| RMSProp | epoch: 026 | loss: 0.10040 - acc: 0.9639 -- iter: 0768/1000
[A[ATraining Step: 825  | total loss: [1m[32m0.09085[0m[0m | time: 29.165s
[2K
| RMSProp | epoch: 026 | loss: 0.09085 - acc: 0.9675 -- iter: 0800/1000
[A[ATraining Step: 826  | total loss: [1m[32m0.08237[0m[0m | time: 30.477s
[2K
| RMSProp | epoch: 026 | loss: 0.08237 - acc: 0.9708 -- iter: 0832/1000
[A[ATraining Step: 827  | total loss: [1m[32m0.07711[0m[0m | time: 31.759s
[2K
| RMSProp | epoch: 026 | loss: 0.07711 - acc: 0.9737 -- iter: 0864/1000
[A[ATraining Step: 828  | total loss: [1m[32m0.07247[0m[0m | time: 33.009s
[2K
| RMSProp | epoch: 026 | loss: 0.07247 - acc: 0.9763 -- iter: 0896/1000
[A[ATraining Step: 829  | total loss: [1m[32m0.06927[0m[0m | time: 34.504s
[2K
| RMSProp | epoch: 026 | loss: 0.06927 - acc: 0.9787 -- iter: 0928/1000
[A[ATraining Step: 830  | total loss: [1m[32m0.06314[0m[0m | time: 35.853s
[2K
| RMSProp | epoch: 026 | loss: 0.06314 - acc: 0.9808 -- iter: 0960/1000
[A[ATraining Step: 831  | total loss: [1m[32m0.05797[0m[0m | time: 36.871s
[2K
| RMSProp | epoch: 026 | loss: 0.05797 - acc: 0.9827 -- iter: 0992/1000
[A[ATraining Step: 832  | total loss: [1m[32m0.05336[0m[0m | time: 40.181s
[2K
| RMSProp | epoch: 026 | loss: 0.05336 - acc: 0.9845 | val_loss: 0.78535 - val_acc: 0.8307 -- iter: 1000/1000
--
Training Step: 833  | total loss: [1m[32m0.04866[0m[0m | time: 1.112s
[2K
| RMSProp | epoch: 027 | loss: 0.04866 - acc: 0.9860 -- iter: 0032/1000
[A[ATraining Step: 834  | total loss: [1m[32m0.04391[0m[0m | time: 2.269s
[2K
| RMSProp | epoch: 027 | loss: 0.04391 - acc: 0.9874 -- iter: 0064/1000
[A[ATraining Step: 835  | total loss: [1m[32m0.05591[0m[0m | time: 3.618s
[2K
| RMSProp | epoch: 027 | loss: 0.05591 - acc: 0.9856 -- iter: 0096/1000
[A[ATraining Step: 836  | total loss: [1m[32m0.05112[0m[0m | time: 4.911s
[2K
| RMSProp | epoch: 027 | loss: 0.05112 - acc: 0.9870 -- iter: 0128/1000
[A[ATraining Step: 837  | total loss: [1m[32m0.04728[0m[0m | time: 6.390s
[2K
| RMSProp | epoch: 027 | loss: 0.04728 - acc: 0.9883 -- iter: 0160/1000
[A[ATraining Step: 838  | total loss: [1m[32m0.04425[0m[0m | time: 7.699s
[2K
| RMSProp | epoch: 027 | loss: 0.04425 - acc: 0.9895 -- iter: 0192/1000
[A[ATraining Step: 839  | total loss: [1m[32m0.04011[0m[0m | time: 8.806s
[2K
| RMSProp | epoch: 027 | loss: 0.04011 - acc: 0.9905 -- iter: 0224/1000
[A[ATraining Step: 840  | total loss: [1m[32m0.05216[0m[0m | time: 9.980s
[2K
| RMSProp | epoch: 027 | loss: 0.05216 - acc: 0.9883 -- iter: 0256/1000
[A[ATraining Step: 841  | total loss: [1m[32m0.05133[0m[0m | time: 11.237s
[2K
| RMSProp | epoch: 027 | loss: 0.05133 - acc: 0.9864 -- iter: 0288/1000
[A[ATraining Step: 842  | total loss: [1m[32m0.04712[0m[0m | time: 12.496s
[2K
| RMSProp | epoch: 027 | loss: 0.04712 - acc: 0.9877 -- iter: 0320/1000
[A[ATraining Step: 843  | total loss: [1m[32m0.04400[0m[0m | time: 13.748s
[2K
| RMSProp | epoch: 027 | loss: 0.04400 - acc: 0.9890 -- iter: 0352/1000
[A[ATraining Step: 844  | total loss: [1m[32m0.04317[0m[0m | time: 15.091s
[2K
| RMSProp | epoch: 027 | loss: 0.04317 - acc: 0.9901 -- iter: 0384/1000
[A[ATraining Step: 845  | total loss: [1m[32m0.04751[0m[0m | time: 16.490s
[2K
| RMSProp | epoch: 027 | loss: 0.04751 - acc: 0.9848 -- iter: 0416/1000
[A[ATraining Step: 846  | total loss: [1m[32m0.09946[0m[0m | time: 17.747s
[2K
| RMSProp | epoch: 027 | loss: 0.09946 - acc: 0.9707 -- iter: 0448/1000
[A[ATraining Step: 847  | total loss: [1m[32m0.11864[0m[0m | time: 19.132s
[2K
| RMSProp | epoch: 027 | loss: 0.11864 - acc: 0.9549 -- iter: 0480/1000
[A[ATraining Step: 848  | total loss: [1m[32m0.11359[0m[0m | time: 20.340s
[2K
| RMSProp | epoch: 027 | loss: 0.11359 - acc: 0.9531 -- iter: 0512/1000
[A[ATraining Step: 849  | total loss: [1m[32m0.10349[0m[0m | time: 21.699s
[2K
| RMSProp | epoch: 027 | loss: 0.10349 - acc: 0.9578 -- iter: 0544/1000
[A[ATraining Step: 850  | total loss: [1m[32m0.09443[0m[0m | time: 22.890s
[2K
| RMSProp | epoch: 027 | loss: 0.09443 - acc: 0.9621 -- iter: 0576/1000
[A[ATraining Step: 851  | total loss: [1m[32m0.08536[0m[0m | time: 24.141s
[2K
| RMSProp | epoch: 027 | loss: 0.08536 - acc: 0.9658 -- iter: 0608/1000
[A[ATraining Step: 852  | total loss: [1m[32m0.08628[0m[0m | time: 25.247s
[2K
| RMSProp | epoch: 027 | loss: 0.08628 - acc: 0.9661 -- iter: 0640/1000
[A[ATraining Step: 853  | total loss: [1m[32m0.07846[0m[0m | time: 26.421s
[2K
| RMSProp | epoch: 027 | loss: 0.07846 - acc: 0.9695 -- iter: 0672/1000
[A[ATraining Step: 854  | total loss: [1m[32m0.07805[0m[0m | time: 27.825s
[2K
| RMSProp | epoch: 027 | loss: 0.07805 - acc: 0.9694 -- iter: 0704/1000
[A[ATraining Step: 855  | total loss: [1m[32m0.09595[0m[0m | time: 29.083s
[2K
| RMSProp | epoch: 027 | loss: 0.09595 - acc: 0.9631 -- iter: 0736/1000
[A[ATraining Step: 856  | total loss: [1m[32m0.15387[0m[0m | time: 30.393s
[2K
| RMSProp | epoch: 027 | loss: 0.15387 - acc: 0.9512 -- iter: 0768/1000
[A[ATraining Step: 857  | total loss: [1m[32m0.14541[0m[0m | time: 30.806s
[2K
| RMSProp | epoch: 027 | loss: 0.14541 - acc: 0.9529 -- iter: 0800/1000
[A[ATraining Step: 858  | total loss: [1m[32m0.15770[0m[0m | time: 31.178s
[2K
| RMSProp | epoch: 027 | loss: 0.15770 - acc: 0.9452 -- iter: 0832/1000
[A[ATraining Step: 859  | total loss: [1m[32m0.14273[0m[0m | time: 32.583s
[2K
| RMSProp | epoch: 027 | loss: 0.14273 - acc: 0.9506 -- iter: 0864/1000
[A[ATraining Step: 860  | total loss: [1m[32m0.14523[0m[0m | time: 34.028s
[2K
| RMSProp | epoch: 027 | loss: 0.14523 - acc: 0.9493 -- iter: 0896/1000
[A[ATraining Step: 861  | total loss: [1m[32m0.13259[0m[0m | time: 35.464s
[2K
| RMSProp | epoch: 027 | loss: 0.13259 - acc: 0.9544 -- iter: 0928/1000
[A[ATraining Step: 862  | total loss: [1m[32m0.12177[0m[0m | time: 36.761s
[2K
| RMSProp | epoch: 027 | loss: 0.12177 - acc: 0.9590 -- iter: 0960/1000
[A[ATraining Step: 863  | total loss: [1m[32m0.12068[0m[0m | time: 38.092s
[2K
| RMSProp | epoch: 027 | loss: 0.12068 - acc: 0.9599 -- iter: 0992/1000
[A[ATraining Step: 864  | total loss: [1m[32m0.13930[0m[0m | time: 41.630s
[2K
| RMSProp | epoch: 027 | loss: 0.13930 - acc: 0.9514 | val_loss: 0.87152 - val_acc: 0.7827 -- iter: 1000/1000
--
Training Step: 865  | total loss: [1m[32m0.13003[0m[0m | time: 1.241s
[2K
| RMSProp | epoch: 028 | loss: 0.13003 - acc: 0.9563 -- iter: 0032/1000
[A[ATraining Step: 866  | total loss: [1m[32m0.11950[0m[0m | time: 2.490s
[2K
| RMSProp | epoch: 028 | loss: 0.11950 - acc: 0.9607 -- iter: 0064/1000
[A[ATraining Step: 867  | total loss: [1m[32m0.10899[0m[0m | time: 3.768s
[2K
| RMSProp | epoch: 028 | loss: 0.10899 - acc: 0.9646 -- iter: 0096/1000
[A[ATraining Step: 868  | total loss: [1m[32m0.09890[0m[0m | time: 5.104s
[2K
| RMSProp | epoch: 028 | loss: 0.09890 - acc: 0.9681 -- iter: 0128/1000
[A[ATraining Step: 869  | total loss: [1m[32m0.09000[0m[0m | time: 6.548s
[2K
| RMSProp | epoch: 028 | loss: 0.09000 - acc: 0.9713 -- iter: 0160/1000
[A[ATraining Step: 870  | total loss: [1m[32m0.08172[0m[0m | time: 7.824s
[2K
| RMSProp | epoch: 028 | loss: 0.08172 - acc: 0.9742 -- iter: 0192/1000
[A[ATraining Step: 871  | total loss: [1m[32m0.07462[0m[0m | time: 9.139s
[2K
| RMSProp | epoch: 028 | loss: 0.07462 - acc: 0.9768 -- iter: 0224/1000
[A[ATraining Step: 872  | total loss: [1m[32m0.06749[0m[0m | time: 10.479s
[2K
| RMSProp | epoch: 028 | loss: 0.06749 - acc: 0.9791 -- iter: 0256/1000
[A[ATraining Step: 873  | total loss: [1m[32m0.06109[0m[0m | time: 11.848s
[2K
| RMSProp | epoch: 028 | loss: 0.06109 - acc: 0.9812 -- iter: 0288/1000
[A[ATraining Step: 874  | total loss: [1m[32m0.06159[0m[0m | time: 13.117s
[2K
| RMSProp | epoch: 028 | loss: 0.06159 - acc: 0.9799 -- iter: 0320/1000
[A[ATraining Step: 875  | total loss: [1m[32m0.06700[0m[0m | time: 14.210s
[2K
| RMSProp | epoch: 028 | loss: 0.06700 - acc: 0.9757 -- iter: 0352/1000
[A[ATraining Step: 876  | total loss: [1m[32m0.11002[0m[0m | time: 15.455s
[2K
| RMSProp | epoch: 028 | loss: 0.11002 - acc: 0.9688 -- iter: 0384/1000
[A[ATraining Step: 877  | total loss: [1m[32m0.10773[0m[0m | time: 16.659s
[2K
| RMSProp | epoch: 028 | loss: 0.10773 - acc: 0.9656 -- iter: 0416/1000
[A[ATraining Step: 878  | total loss: [1m[32m0.11200[0m[0m | time: 17.904s
[2K
| RMSProp | epoch: 028 | loss: 0.11200 - acc: 0.9659 -- iter: 0448/1000
[A[ATraining Step: 879  | total loss: [1m[32m0.10215[0m[0m | time: 19.140s
[2K
| RMSProp | epoch: 028 | loss: 0.10215 - acc: 0.9693 -- iter: 0480/1000
[A[ATraining Step: 880  | total loss: [1m[32m0.11050[0m[0m | time: 20.430s
[2K
| RMSProp | epoch: 028 | loss: 0.11050 - acc: 0.9662 -- iter: 0512/1000
[A[ATraining Step: 881  | total loss: [1m[32m0.11142[0m[0m | time: 21.906s
[2K
| RMSProp | epoch: 028 | loss: 0.11142 - acc: 0.9633 -- iter: 0544/1000
[A[ATraining Step: 882  | total loss: [1m[32m0.10349[0m[0m | time: 23.195s
[2K
| RMSProp | epoch: 028 | loss: 0.10349 - acc: 0.9670 -- iter: 0576/1000
[A[ATraining Step: 883  | total loss: [1m[32m0.09459[0m[0m | time: 24.570s
[2K
| RMSProp | epoch: 028 | loss: 0.09459 - acc: 0.9703 -- iter: 0608/1000
[A[ATraining Step: 884  | total loss: [1m[32m0.08959[0m[0m | time: 25.956s
[2K
| RMSProp | epoch: 028 | loss: 0.08959 - acc: 0.9701 -- iter: 0640/1000
[A[ATraining Step: 885  | total loss: [1m[32m0.08407[0m[0m | time: 27.380s
[2K
| RMSProp | epoch: 028 | loss: 0.08407 - acc: 0.9731 -- iter: 0672/1000
[A[ATraining Step: 886  | total loss: [1m[32m0.07900[0m[0m | time: 28.693s
[2K
| RMSProp | epoch: 028 | loss: 0.07900 - acc: 0.9758 -- iter: 0704/1000
[A[ATraining Step: 887  | total loss: [1m[32m0.08471[0m[0m | time: 30.011s
[2K
| RMSProp | epoch: 028 | loss: 0.08471 - acc: 0.9751 -- iter: 0736/1000
[A[ATraining Step: 888  | total loss: [1m[32m0.07758[0m[0m | time: 31.161s
[2K
| RMSProp | epoch: 028 | loss: 0.07758 - acc: 0.9776 -- iter: 0768/1000
[A[ATraining Step: 889  | total loss: [1m[32m0.07385[0m[0m | time: 32.510s
[2K
| RMSProp | epoch: 028 | loss: 0.07385 - acc: 0.9767 -- iter: 0800/1000
[A[ATraining Step: 890  | total loss: [1m[32m0.06965[0m[0m | time: 32.895s
[2K
| RMSProp | epoch: 028 | loss: 0.06965 - acc: 0.9790 -- iter: 0832/1000
[A[ATraining Step: 891  | total loss: [1m[32m0.06347[0m[0m | time: 33.249s
[2K
| RMSProp | epoch: 028 | loss: 0.06347 - acc: 0.9811 -- iter: 0864/1000
[A[ATraining Step: 892  | total loss: [1m[32m0.05736[0m[0m | time: 34.639s
[2K
| RMSProp | epoch: 028 | loss: 0.05736 - acc: 0.9830 -- iter: 0896/1000
[A[ATraining Step: 893  | total loss: [1m[32m0.05215[0m[0m | time: 35.936s
[2K
| RMSProp | epoch: 028 | loss: 0.05215 - acc: 0.9847 -- iter: 0928/1000
[A[ATraining Step: 894  | total loss: [1m[32m0.04751[0m[0m | time: 37.318s
[2K
| RMSProp | epoch: 028 | loss: 0.04751 - acc: 0.9862 -- iter: 0960/1000
[A[ATraining Step: 895  | total loss: [1m[32m0.04297[0m[0m | time: 38.664s
[2K
| RMSProp | epoch: 028 | loss: 0.04297 - acc: 0.9876 -- iter: 0992/1000
[A[ATraining Step: 896  | total loss: [1m[32m0.03995[0m[0m | time: 42.548s
[2K
| RMSProp | epoch: 028 | loss: 0.03995 - acc: 0.9889 | val_loss: 0.96271 - val_acc: 0.7796 -- iter: 1000/1000
--
Training Step: 897  | total loss: [1m[32m0.05486[0m[0m | time: 1.359s
[2K
| RMSProp | epoch: 029 | loss: 0.05486 - acc: 0.9837 -- iter: 0032/1000
[A[ATraining Step: 898  | total loss: [1m[32m0.08704[0m[0m | time: 2.605s
[2K
| RMSProp | epoch: 029 | loss: 0.08704 - acc: 0.9760 -- iter: 0064/1000
[A[ATraining Step: 899  | total loss: [1m[32m0.07982[0m[0m | time: 3.992s
[2K
| RMSProp | epoch: 029 | loss: 0.07982 - acc: 0.9784 -- iter: 0096/1000
[A[ATraining Step: 900  | total loss: [1m[32m0.07260[0m[0m | time: 5.435s
[2K
| RMSProp | epoch: 029 | loss: 0.07260 - acc: 0.9805 -- iter: 0128/1000
[A[ATraining Step: 901  | total loss: [1m[32m0.06641[0m[0m | time: 6.918s
[2K
| RMSProp | epoch: 029 | loss: 0.06641 - acc: 0.9825 -- iter: 0160/1000
[A[ATraining Step: 902  | total loss: [1m[32m0.06019[0m[0m | time: 8.154s
[2K
| RMSProp | epoch: 029 | loss: 0.06019 - acc: 0.9842 -- iter: 0192/1000
[A[ATraining Step: 903  | total loss: [1m[32m0.05498[0m[0m | time: 9.175s
[2K
| RMSProp | epoch: 029 | loss: 0.05498 - acc: 0.9858 -- iter: 0224/1000
[A[ATraining Step: 904  | total loss: [1m[32m0.04981[0m[0m | time: 10.204s
[2K
| RMSProp | epoch: 029 | loss: 0.04981 - acc: 0.9872 -- iter: 0256/1000
[A[ATraining Step: 905  | total loss: [1m[32m0.06739[0m[0m | time: 11.134s
[2K
| RMSProp | epoch: 029 | loss: 0.06739 - acc: 0.9854 -- iter: 0288/1000
[A[ATraining Step: 906  | total loss: [1m[32m0.06535[0m[0m | time: 12.380s
[2K
| RMSProp | epoch: 029 | loss: 0.06535 - acc: 0.9868 -- iter: 0320/1000
[A[ATraining Step: 907  | total loss: [1m[32m0.07302[0m[0m | time: 13.539s
[2K
| RMSProp | epoch: 029 | loss: 0.07302 - acc: 0.9819 -- iter: 0352/1000
[A[ATraining Step: 908  | total loss: [1m[32m0.10300[0m[0m | time: 14.390s
[2K
| RMSProp | epoch: 029 | loss: 0.10300 - acc: 0.9712 -- iter: 0384/1000
[A[ATraining Step: 909  | total loss: [1m[32m0.11905[0m[0m | time: 15.365s
[2K
| RMSProp | epoch: 029 | loss: 0.11905 - acc: 0.9647 -- iter: 0416/1000
[A[ATraining Step: 910  | total loss: [1m[32m0.11241[0m[0m | time: 16.394s
[2K
| RMSProp | epoch: 029 | loss: 0.11241 - acc: 0.9682 -- iter: 0448/1000
[A[ATraining Step: 911  | total loss: [1m[32m0.10250[0m[0m | time: 17.469s
[2K
| RMSProp | epoch: 029 | loss: 0.10250 - acc: 0.9714 -- iter: 0480/1000
[A[ATraining Step: 912  | total loss: [1m[32m0.09331[0m[0m | time: 18.551s
[2K
| RMSProp | epoch: 029 | loss: 0.09331 - acc: 0.9743 -- iter: 0512/1000
[A[ATraining Step: 913  | total loss: [1m[32m0.08460[0m[0m | time: 19.597s
[2K
| RMSProp | epoch: 029 | loss: 0.08460 - acc: 0.9769 -- iter: 0544/1000
[A[ATraining Step: 914  | total loss: [1m[32m0.07739[0m[0m | time: 20.640s
[2K
| RMSProp | epoch: 029 | loss: 0.07739 - acc: 0.9792 -- iter: 0576/1000
[A[ATraining Step: 915  | total loss: [1m[32m0.07016[0m[0m | time: 21.587s
[2K
| RMSProp | epoch: 029 | loss: 0.07016 - acc: 0.9813 -- iter: 0608/1000
[A[ATraining Step: 916  | total loss: [1m[32m0.06371[0m[0m | time: 22.773s
[2K
| RMSProp | epoch: 029 | loss: 0.06371 - acc: 0.9831 -- iter: 0640/1000
[A[ATraining Step: 917  | total loss: [1m[32m0.05759[0m[0m | time: 23.979s
[2K
| RMSProp | epoch: 029 | loss: 0.05759 - acc: 0.9848 -- iter: 0672/1000
[A[ATraining Step: 918  | total loss: [1m[32m0.05218[0m[0m | time: 24.794s
[2K
| RMSProp | epoch: 029 | loss: 0.05218 - acc: 0.9863 -- iter: 0704/1000
[A[ATraining Step: 919  | total loss: [1m[32m0.04736[0m[0m | time: 25.800s
[2K
| RMSProp | epoch: 029 | loss: 0.04736 - acc: 0.9877 -- iter: 0736/1000
[A[ATraining Step: 920  | total loss: [1m[32m0.04280[0m[0m | time: 26.769s
[2K
| RMSProp | epoch: 029 | loss: 0.04280 - acc: 0.9889 -- iter: 0768/1000
[A[ATraining Step: 921  | total loss: [1m[32m0.04233[0m[0m | time: 27.774s
[2K
| RMSProp | epoch: 029 | loss: 0.04233 - acc: 0.9869 -- iter: 0800/1000
[A[ATraining Step: 922  | total loss: [1m[32m0.08982[0m[0m | time: 28.803s
[2K
| RMSProp | epoch: 029 | loss: 0.08982 - acc: 0.9757 -- iter: 0832/1000
[A[ATraining Step: 923  | total loss: [1m[32m0.10028[0m[0m | time: 29.131s
[2K
| RMSProp | epoch: 029 | loss: 0.10028 - acc: 0.9719 -- iter: 0864/1000
[A[ATraining Step: 924  | total loss: [1m[32m0.09057[0m[0m | time: 29.421s
[2K
| RMSProp | epoch: 029 | loss: 0.09057 - acc: 0.9747 -- iter: 0896/1000
[A[ATraining Step: 925  | total loss: [1m[32m0.43419[0m[0m | time: 30.400s
[2K
| RMSProp | epoch: 029 | loss: 0.43419 - acc: 0.9272 -- iter: 0928/1000
[A[ATraining Step: 926  | total loss: [1m[32m0.46894[0m[0m | time: 31.401s
[2K
| RMSProp | epoch: 029 | loss: 0.46894 - acc: 0.9064 -- iter: 0960/1000
[A[ATraining Step: 927  | total loss: [1m[32m0.43503[0m[0m | time: 32.413s
[2K
| RMSProp | epoch: 029 | loss: 0.43503 - acc: 0.9157 -- iter: 0992/1000
[A[ATraining Step: 928  | total loss: [1m[32m0.39473[0m[0m | time: 36.260s
[2K
| RMSProp | epoch: 029 | loss: 0.39473 - acc: 0.9242 | val_loss: 0.82175 - val_acc: 0.7252 -- iter: 1000/1000
--
Training Step: 929  | total loss: [1m[32m0.36518[0m[0m | time: 1.230s
[2K
| RMSProp | epoch: 030 | loss: 0.36518 - acc: 0.9255 -- iter: 0032/1000
[A[ATraining Step: 930  | total loss: [1m[32m0.33801[0m[0m | time: 2.487s
[2K
| RMSProp | epoch: 030 | loss: 0.33801 - acc: 0.9267 -- iter: 0064/1000
[A[ATraining Step: 931  | total loss: [1m[32m0.31232[0m[0m | time: 3.745s
[2K
| RMSProp | epoch: 030 | loss: 0.31232 - acc: 0.9309 -- iter: 0096/1000
[A[ATraining Step: 932  | total loss: [1m[32m0.29979[0m[0m | time: 5.157s
[2K
| RMSProp | epoch: 030 | loss: 0.29979 - acc: 0.9347 -- iter: 0128/1000
[A[ATraining Step: 933  | total loss: [1m[32m0.27112[0m[0m | time: 6.362s
[2K
| RMSProp | epoch: 030 | loss: 0.27112 - acc: 0.9412 -- iter: 0160/1000
[A[ATraining Step: 934  | total loss: [1m[32m0.25419[0m[0m | time: 7.647s
[2K
| RMSProp | epoch: 030 | loss: 0.25419 - acc: 0.9440 -- iter: 0192/1000
[A[ATraining Step: 935  | total loss: [1m[32m0.23007[0m[0m | time: 8.962s
[2K
| RMSProp | epoch: 030 | loss: 0.23007 - acc: 0.9496 -- iter: 0224/1000
[A[ATraining Step: 936  | total loss: [1m[32m0.22040[0m[0m | time: 10.314s
[2K
| RMSProp | epoch: 030 | loss: 0.22040 - acc: 0.9515 -- iter: 0256/1000
[A[ATraining Step: 937  | total loss: [1m[32m0.20140[0m[0m | time: 11.521s
[2K
| RMSProp | epoch: 030 | loss: 0.20140 - acc: 0.9563 -- iter: 0288/1000
[A[ATraining Step: 938  | total loss: [1m[32m0.18248[0m[0m | time: 12.876s
[2K
| RMSProp | epoch: 030 | loss: 0.18248 - acc: 0.9607 -- iter: 0320/1000
[A[ATraining Step: 939  | total loss: [1m[32m0.16491[0m[0m | time: 14.363s
[2K
| RMSProp | epoch: 030 | loss: 0.16491 - acc: 0.9646 -- iter: 0352/1000
[A[ATraining Step: 940  | total loss: [1m[32m0.15397[0m[0m | time: 15.683s
[2K
| RMSProp | epoch: 030 | loss: 0.15397 - acc: 0.9651 -- iter: 0384/1000
[A[ATraining Step: 941  | total loss: [1m[32m0.14100[0m[0m | time: 16.843s
[2K
| RMSProp | epoch: 030 | loss: 0.14100 - acc: 0.9685 -- iter: 0416/1000
[A[ATraining Step: 942  | total loss: [1m[32m0.15471[0m[0m | time: 18.027s
[2K
| RMSProp | epoch: 030 | loss: 0.15471 - acc: 0.9623 -- iter: 0448/1000
[A[ATraining Step: 943  | total loss: [1m[32m0.17584[0m[0m | time: 19.234s
[2K
| RMSProp | epoch: 030 | loss: 0.17584 - acc: 0.9473 -- iter: 0480/1000
[A[ATraining Step: 944  | total loss: [1m[32m0.16786[0m[0m | time: 20.600s
[2K
| RMSProp | epoch: 030 | loss: 0.16786 - acc: 0.9432 -- iter: 0512/1000
[A[ATraining Step: 945  | total loss: [1m[32m0.15866[0m[0m | time: 21.919s
[2K
| RMSProp | epoch: 030 | loss: 0.15866 - acc: 0.9458 -- iter: 0544/1000
[A[ATraining Step: 946  | total loss: [1m[32m0.16552[0m[0m | time: 23.210s
[2K
| RMSProp | epoch: 030 | loss: 0.16552 - acc: 0.9450 -- iter: 0576/1000
[A[ATraining Step: 947  | total loss: [1m[32m0.15237[0m[0m | time: 24.597s
[2K
| RMSProp | epoch: 030 | loss: 0.15237 - acc: 0.9505 -- iter: 0608/1000
[A[ATraining Step: 948  | total loss: [1m[32m0.14756[0m[0m | time: 25.969s
[2K
| RMSProp | epoch: 030 | loss: 0.14756 - acc: 0.9523 -- iter: 0640/1000
[A[ATraining Step: 949  | total loss: [1m[32m0.13430[0m[0m | time: 27.247s
[2K
| RMSProp | epoch: 030 | loss: 0.13430 - acc: 0.9571 -- iter: 0672/1000
[A[ATraining Step: 950  | total loss: [1m[32m0.12185[0m[0m | time: 28.642s
[2K
| RMSProp | epoch: 030 | loss: 0.12185 - acc: 0.9614 -- iter: 0704/1000
[A[ATraining Step: 951  | total loss: [1m[32m0.11041[0m[0m | time: 29.993s
[2K
| RMSProp | epoch: 030 | loss: 0.11041 - acc: 0.9652 -- iter: 0736/1000
[A[ATraining Step: 952  | total loss: [1m[32m0.10258[0m[0m | time: 31.406s
[2K
| RMSProp | epoch: 030 | loss: 0.10258 - acc: 0.9656 -- iter: 0768/1000
[A[ATraining Step: 953  | total loss: [1m[32m0.10920[0m[0m | time: 32.606s
[2K
| RMSProp | epoch: 030 | loss: 0.10920 - acc: 0.9659 -- iter: 0800/1000
[A[ATraining Step: 954  | total loss: [1m[32m0.09869[0m[0m | time: 33.861s
[2K
| RMSProp | epoch: 030 | loss: 0.09869 - acc: 0.9693 -- iter: 0832/1000
[A[ATraining Step: 955  | total loss: [1m[32m0.09235[0m[0m | time: 35.273s
[2K
| RMSProp | epoch: 030 | loss: 0.09235 - acc: 0.9724 -- iter: 0864/1000
[A[ATraining Step: 956  | total loss: [1m[32m0.08610[0m[0m | time: 35.654s
[2K
| RMSProp | epoch: 030 | loss: 0.08610 - acc: 0.9751 -- iter: 0896/1000
[A[ATraining Step: 957  | total loss: [1m[32m0.07798[0m[0m | time: 36.069s
[2K
| RMSProp | epoch: 030 | loss: 0.07798 - acc: 0.9776 -- iter: 0928/1000
[A[ATraining Step: 958  | total loss: [1m[32m0.26844[0m[0m | time: 37.381s
[2K
| RMSProp | epoch: 030 | loss: 0.26844 - acc: 0.9549 -- iter: 0960/1000
[A[ATraining Step: 959  | total loss: [1m[32m0.24469[0m[0m | time: 38.790s
[2K
| RMSProp | epoch: 030 | loss: 0.24469 - acc: 0.9594 -- iter: 0992/1000
[A[ATraining Step: 960  | total loss: [1m[32m0.22768[0m[0m | time: 41.999s
[2K
| RMSProp | epoch: 030 | loss: 0.22768 - acc: 0.9603 | val_loss: 0.56008 - val_acc: 0.8211 -- iter: 1000/1000
--
Validation AUC:0.8743260590500641
Validation AUPRC:0.8925156479148129
Test AUC:0.8927590511860175
Test AUPRC:0.8891285209737447
BestTestF1Score	0.86	0.65	0.83	0.82	0.9	161	36	99	17	0.38
BestTestMCCScore	0.86	0.65	0.83	0.82	0.9	161	36	99	17	0.38
BestTestAccuracyScore	0.86	0.65	0.83	0.82	0.9	161	36	99	17	0.38
BestValidationF1Score	0.87	0.65	0.83	0.82	0.93	176	38	85	14	0.38
BestValidationMCC	0.87	0.65	0.83	0.82	0.93	176	38	85	14	0.38
BestValidationAccuracy	0.87	0.65	0.83	0.82	0.93	176	38	85	14	0.38
TestPredictions (Threshold:0.38)
CHEMBL91636,TP,ACT,0.8100000023841858	CHEMBL326489,TP,ACT,0.9900000095367432	CHEMBL255575,TP,ACT,1.0	CHEMBL321613,TP,ACT,0.4300000071525574	CHEMBL392974,TN,INACT,0.009999999776482582	CHEMBL158521,TN,INACT,0.009999999776482582	CHEMBL121592,TN,INACT,0.03999999910593033	CHEMBL575896,FP,INACT,0.9900000095367432	CHEMBL63415,TN,INACT,0.05999999865889549	CHEMBL254404,TN,INACT,0.009999999776482582	CHEMBL250058,TN,INACT,0.019999999552965164	CHEMBL279176,TN,INACT,0.009999999776482582	CHEMBL356504,TP,ACT,1.0	CHEMBL3098991,FP,INACT,0.6200000047683716	CHEMBL572947,TN,INACT,0.019999999552965164	CHEMBL400449,TN,INACT,0.009999999776482582	CHEMBL473841,TN,INACT,0.07000000029802322	CHEMBL3639695,TP,ACT,0.9900000095367432	CHEMBL349124,TP,ACT,0.9599999785423279	CHEMBL3084966,FN,ACT,0.05999999865889549	CHEMBL70817,TN,INACT,0.019999999552965164	CHEMBL410259,TP,ACT,0.9399999976158142	CHEMBL333122,TN,INACT,0.05000000074505806	CHEMBL1939865,TN,INACT,0.09000000357627869	CHEMBL127168,TP,ACT,0.9900000095367432	CHEMBL42040,TP,ACT,0.75	CHEMBL228230,TN,INACT,0.029999999329447746	CHEMBL1160569,TP,ACT,0.9399999976158142	CHEMBL3675542,TP,ACT,0.9700000286102295	CHEMBL151047,TP,ACT,0.5899999737739563	CHEMBL442161,TP,ACT,1.0	CHEMBL445939,TN,INACT,0.12999999523162842	CHEMBL1834423,TN,INACT,0.019999999552965164	CHEMBL8718,TP,ACT,1.0	CHEMBL440048,TP,ACT,0.9900000095367432	CHEMBL45208,TP,ACT,0.9900000095367432	CHEMBL191106,FP,INACT,0.9900000095367432	CHEMBL3417766,TP,ACT,0.9700000286102295	CHEMBL102415,TP,ACT,0.9900000095367432	CHEMBL3643916,TP,ACT,0.9900000095367432	CHEMBL120934,TN,INACT,0.019999999552965164	CHEMBL3670720,TP,ACT,0.9900000095367432	CHEMBL103200,TN,INACT,0.03999999910593033	CHEMBL83864,TP,ACT,0.9900000095367432	CHEMBL198039,FP,INACT,1.0	CHEMBL43644,TP,ACT,0.9599999785423279	CHEMBL77956,TP,ACT,0.8700000047683716	CHEMBL3142612,FP,INACT,0.9100000262260437	CHEMBL1771219,TP,ACT,0.9900000095367432	CHEMBL3142588,TN,INACT,0.14000000059604645	CHEMBL17082,TP,ACT,0.9900000095367432	CHEMBL1760318,TN,INACT,0.009999999776482582	CHEMBL399684,TN,INACT,0.019999999552965164	CHEMBL307365,FN,ACT,0.05999999865889549	CHEMBL147910,TP,ACT,1.0	CHEMBL2205661,FP,INACT,1.0	CHEMBL3775452,TN,INACT,0.019999999552965164	CHEMBL251423,TN,INACT,0.009999999776482582	CHEMBL296911,TP,ACT,0.9900000095367432	CHEMBL126711,TP,ACT,0.9800000190734863	CHEMBL93742,TN,INACT,0.3400000035762787	CHEMBL271235,TP,ACT,0.9900000095367432	CHEMBL187282,FP,INACT,0.8700000047683716	CHEMBL1433,TN,INACT,0.05999999865889549	CHEMBL1630091,TP,ACT,1.0	CHEMBL325835,TP,ACT,0.9800000190734863	CHEMBL3643914,TP,ACT,0.9900000095367432	CHEMBL360704,FP,INACT,0.949999988079071	CHEMBL3670708,TP,ACT,0.9599999785423279	CHEMBL575400,FP,INACT,0.800000011920929	CHEMBL3358158,TN,INACT,0.23999999463558197	CHEMBL2147933,TN,INACT,0.07000000029802322	CHEMBL123105,TN,INACT,0.019999999552965164	CHEMBL419430,TP,ACT,1.0	CHEMBL2431025,TN,INACT,0.0	CHEMBL553109,TP,ACT,1.0	CHEMBL430524,TP,ACT,1.0	CHEMBL431570,TN,INACT,0.05000000074505806	CHEMBL1819323,TN,INACT,0.10999999940395355	CHEMBL147261,TP,ACT,1.0	CHEMBL404019,TP,ACT,0.9800000190734863	CHEMBL41923,TN,INACT,0.029999999329447746	CHEMBL58834,FN,ACT,0.3100000023841858	CHEMBL1801427,TP,ACT,0.9800000190734863	CHEMBL3142626,TN,INACT,0.009999999776482582	CHEMBL414597,TN,INACT,0.009999999776482582	CHEMBL1796284,TN,INACT,0.029999999329447746	CHEMBL36615,TP,ACT,0.8500000238418579	CHEMBL141359,TP,ACT,0.9900000095367432	CHEMBL365827,TN,INACT,0.019999999552965164	CHEMBL306862,TN,INACT,0.029999999329447746	CHEMBL575895,FP,INACT,0.9800000190734863	CHEMBL448755,TN,INACT,0.03999999910593033	CHEMBL111856,TP,ACT,0.9900000095367432	CHEMBL97408,FP,INACT,0.9100000262260437	CHEMBL96438,TN,INACT,0.14000000059604645	CHEMBL1916210,TP,ACT,0.9599999785423279	CHEMBL103589,FN,ACT,0.2800000011920929	CHEMBL356011,FN,ACT,0.10000000149011612	CHEMBL2369490,FP,INACT,0.9800000190734863	CHEMBL1957599,FP,INACT,0.8899999856948853	CHEMBL1229868,TP,ACT,0.9300000071525574	CHEMBL3774656,TN,INACT,0.009999999776482582	CHEMBL47254,TP,ACT,1.0	CHEMBL433063,TP,ACT,1.0	CHEMBL388671,TN,INACT,0.20999999344348907	CHEMBL252326,TN,INACT,0.019999999552965164	CHEMBL138181,TP,ACT,0.41999998688697815	CHEMBL255051,TN,INACT,0.029999999329447746	CHEMBL1771214,TP,ACT,0.9599999785423279	CHEMBL1939861,TN,INACT,0.03999999910593033	CHEMBL308799,FP,INACT,0.949999988079071	CHEMBL172722,TP,ACT,0.9700000286102295	CHEMBL3775799,TN,INACT,0.03999999910593033	CHEMBL87046,FN,ACT,0.09000000357627869	CHEMBL398640,TP,ACT,0.9900000095367432	CHEMBL8634,TP,ACT,1.0	CHEMBL249859,TN,INACT,0.05000000074505806	CHEMBL398641,TP,ACT,1.0	CHEMBL2440435,TN,INACT,0.03999999910593033	CHEMBL288510,TN,INACT,0.009999999776482582	CHEMBL42537,TP,ACT,0.9599999785423279	CHEMBL141339,TP,ACT,1.0	CHEMBL406131,TP,ACT,0.9900000095367432	CHEMBL3142608,FP,INACT,0.5199999809265137	CHEMBL410649,TN,INACT,0.07000000029802322	CHEMBL1771223,TP,ACT,0.9800000190734863	CHEMBL20256,TP,ACT,0.9800000190734863	CHEMBL322412,TP,ACT,0.9900000095367432	CHEMBL3398611,TN,INACT,0.05000000074505806	CHEMBL337585,TP,ACT,0.8899999856948853	CHEMBL99995,TP,ACT,0.9900000095367432	CHEMBL270083,TN,INACT,0.029999999329447746	CHEMBL10180,FP,INACT,0.9900000095367432	CHEMBL3675569,TP,ACT,1.0	CHEMBL174993,TN,INACT,0.029999999329447746	CHEMBL337793,TP,ACT,0.7200000286102295	CHEMBL357796,TP,ACT,1.0	CHEMBL351968,TP,ACT,1.0	CHEMBL138656,TP,ACT,1.0	CHEMBL140863,TP,ACT,0.9800000190734863	CHEMBL148120,TP,ACT,0.9700000286102295	CHEMBL418442,TP,ACT,1.0	CHEMBL253373,TN,INACT,0.029999999329447746	CHEMBL298167,TP,ACT,1.0	CHEMBL104022,TP,ACT,0.9900000095367432	CHEMBL1651848,TN,INACT,0.05999999865889549	CHEMBL485691,TN,INACT,0.20000000298023224	CHEMBL328477,TN,INACT,0.11999999731779099	CHEMBL307211,TP,ACT,0.9800000190734863	CHEMBL65439,TP,ACT,0.9900000095367432	CHEMBL244883,FP,INACT,0.8399999737739563	CHEMBL3675572,TP,ACT,1.0	CHEMBL334909,TP,ACT,0.9800000190734863	CHEMBL327262,TP,ACT,0.9800000190734863	CHEMBL93695,TP,ACT,0.9900000095367432	CHEMBL307027,TP,ACT,0.9900000095367432	CHEMBL1927183,TN,INACT,0.009999999776482582	CHEMBL291833,TN,INACT,0.05999999865889549	CHEMBL115145,TN,INACT,0.3199999928474426	CHEMBL447787,TP,ACT,0.9900000095367432	CHEMBL263909,TN,INACT,0.03999999910593033	CHEMBL269019,TP,ACT,0.9399999976158142	CHEMBL1795860,TP,ACT,0.9900000095367432	CHEMBL8256,TP,ACT,0.9900000095367432	CHEMBL415872,FP,INACT,1.0	CHEMBL398892,TN,INACT,0.009999999776482582	CHEMBL291898,TP,ACT,0.9900000095367432	CHEMBL1160575,TP,ACT,0.6200000047683716	CHEMBL3670701,FN,ACT,0.18000000715255737	CHEMBL602700,TN,INACT,0.019999999552965164	CHEMBL3617402,TP,ACT,0.9700000286102295	CHEMBL66532,TP,ACT,0.9800000190734863	CHEMBL324842,TN,INACT,0.03999999910593033	CHEMBL328243,FP,INACT,0.46000000834465027	CHEMBL65493,FN,ACT,0.2800000011920929	CHEMBL2440436,TN,INACT,0.029999999329447746	CHEMBL254510,TP,ACT,0.5799999833106995	CHEMBL8761,TP,ACT,1.0	CHEMBL138814,TP,ACT,1.0	CHEMBL1796285,FP,INACT,0.8799999952316284	CHEMBL172886,TP,ACT,0.9800000190734863	CHEMBL207756,TP,ACT,0.6100000143051147	CHEMBL254398,TP,ACT,0.9900000095367432	CHEMBL393793,TN,INACT,0.029999999329447746	CHEMBL2147932,TN,INACT,0.029999999329447746	CHEMBL312218,TP,ACT,0.8700000047683716	CHEMBL184058,TN,INACT,0.03999999910593033	CHEMBL1645387,FN,ACT,0.019999999552965164	CHEMBL2147934,TN,INACT,0.27000001072883606	CHEMBL1796281,FP,INACT,0.5899999737739563	CHEMBL1819450,TN,INACT,0.029999999329447746	CHEMBL42420,TP,ACT,1.0	CHEMBL312100,TP,ACT,0.9900000095367432	CHEMBL575881,FP,INACT,0.9100000262260437	CHEMBL293382,FN,ACT,0.07000000029802322	CHEMBL320402,TP,ACT,0.9900000095367432	CHEMBL95004,TN,INACT,0.009999999776482582	CHEMBL433902,TP,ACT,1.0	CHEMBL10655,FN,ACT,0.03999999910593033	CHEMBL345447,TP,ACT,0.9900000095367432	CHEMBL3758657,FN,ACT,0.03999999910593033	CHEMBL254838,TN,INACT,0.03999999910593033	CHEMBL254191,FN,ACT,0.029999999329447746	CHEMBL399998,TN,INACT,0.019999999552965164	CHEMBL28815,FP,INACT,0.9900000095367432	CHEMBL178509,TP,ACT,0.9599999785423279	CHEMBL24398,TN,INACT,0.03999999910593033	CHEMBL210517,TP,ACT,1.0	CHEMBL1801396,TP,ACT,0.9900000095367432	CHEMBL2380406,TP,ACT,0.8100000023841858	CHEMBL3775617,TN,INACT,0.009999999776482582	CHEMBL351888,TP,ACT,1.0	CHEMBL605144,TN,INACT,0.009999999776482582	CHEMBL3417742,TP,ACT,0.9800000190734863	CHEMBL403185,TP,ACT,0.949999988079071	CHEMBL97389,TN,INACT,0.10999999940395355	CHEMBL94715,FP,INACT,0.949999988079071	CHEMBL44455,TP,ACT,0.9900000095367432	CHEMBL68315,TN,INACT,0.029999999329447746	CHEMBL150027,TP,ACT,0.9599999785423279	CHEMBL10760,TP,ACT,1.0	CHEMBL91055,FP,INACT,0.9800000190734863	CHEMBL289202,FN,ACT,0.3100000023841858	CHEMBL93720,TP,ACT,1.0	CHEMBL296368,TP,ACT,1.0	CHEMBL325924,FP,INACT,0.9700000286102295	CHEMBL267722,TP,ACT,1.0	CHEMBL227553,FP,INACT,0.9200000166893005	CHEMBL3092093,TN,INACT,0.019999999552965164	CHEMBL429319,FP,INACT,0.9100000262260437	CHEMBL3417764,TP,ACT,0.9599999785423279	CHEMBL1957595,TN,INACT,0.009999999776482582	CHEMBL325552,TP,ACT,0.9300000071525574	CHEMBL347209,TP,ACT,0.9900000095367432	CHEMBL1779630,TN,INACT,0.05999999865889549	CHEMBL85026,TP,ACT,1.0	CHEMBL45040,TP,ACT,1.0	CHEMBL152840,TP,ACT,0.9700000286102295	CHEMBL94348,TN,INACT,0.07000000029802322	CHEMBL288599,TN,INACT,0.019999999552965164	CHEMBL266133,TP,ACT,1.0	CHEMBL1771216,TP,ACT,0.9100000262260437	CHEMBL147489,FP,INACT,0.9700000286102295	CHEMBL43206,TP,ACT,0.9900000095367432	CHEMBL314327,FP,INACT,0.9399999976158142	CHEMBL2333288,FN,ACT,0.029999999329447746	CHEMBL1801047,TP,ACT,0.9399999976158142	CHEMBL1607077,FP,INACT,0.44999998807907104	CHEMBL150628,TP,ACT,0.9900000095367432	CHEMBL174373,TN,INACT,0.36000001430511475	CHEMBL97454,FP,INACT,1.0	CHEMBL438519,TN,INACT,0.019999999552965164	CHEMBL135216,TN,INACT,0.2199999988079071	CHEMBL319040,TP,ACT,0.9700000286102295	CHEMBL335118,TP,ACT,0.9900000095367432	CHEMBL295798,TP,ACT,1.0	CHEMBL1795351,TP,ACT,1.0	CHEMBL16650,TP,ACT,0.9900000095367432	CHEMBL329298,TP,ACT,1.0	CHEMBL64571,TP,ACT,0.9399999976158142	CHEMBL268405,TP,ACT,0.9900000095367432	CHEMBL253801,TN,INACT,0.009999999776482582	CHEMBL121501,TN,INACT,0.05999999865889549	CHEMBL3675575,TP,ACT,1.0	CHEMBL43147,TP,ACT,0.9900000095367432	CHEMBL36682,TN,INACT,0.029999999329447746	CHEMBL398662,TN,INACT,0.019999999552965164	CHEMBL236446,FP,INACT,0.9900000095367432	CHEMBL288866,TP,ACT,0.9100000262260437	CHEMBL262758,FP,INACT,0.8100000023841858	CHEMBL1214590,TN,INACT,0.019999999552965164	CHEMBL1801050,TP,ACT,0.9700000286102295	CHEMBL1939846,TP,ACT,0.9700000286102295	CHEMBL2333267,TN,INACT,0.03999999910593033	CHEMBL277010,TP,ACT,1.0	CHEMBL44383,TP,ACT,0.9900000095367432	CHEMBL228268,TP,ACT,0.8600000143051147	CHEMBL476657,TN,INACT,0.009999999776482582	CHEMBL359716,TP,ACT,0.9800000190734863	CHEMBL16114,TP,ACT,0.9900000095367432	CHEMBL288843,TP,ACT,1.0	CHEMBL125755,TP,ACT,1.0	CHEMBL1939869,TN,INACT,0.019999999552965164	CHEMBL145175,TP,ACT,0.9700000286102295	CHEMBL73945,FP,INACT,0.4099999964237213	CHEMBL502282,TN,INACT,0.009999999776482582	CHEMBL234567,FP,INACT,0.6000000238418579	CHEMBL3417763,TP,ACT,0.9700000286102295	CHEMBL407151,TN,INACT,0.029999999329447746	CHEMBL180570,TN,INACT,0.029999999329447746	CHEMBL280946,TP,ACT,0.9800000190734863	CHEMBL348210,TP,ACT,0.5299999713897705	CHEMBL10674,TP,ACT,1.0	CHEMBL171962,TP,ACT,0.9800000190734863	CHEMBL292636,TP,ACT,0.9900000095367432	CHEMBL105279,TP,ACT,1.0	CHEMBL95143,TN,INACT,0.20000000298023224	CHEMBL60196,FN,ACT,0.05000000074505806	CHEMBL127138,TP,ACT,0.9300000071525574	CHEMBL1650630,TN,INACT,0.03999999910593033	CHEMBL157048,TP,ACT,0.9200000166893005	CHEMBL149977,TP,ACT,0.9700000286102295	CHEMBL151399,TP,ACT,0.9300000071525574	CHEMBL158622,TP,ACT,0.9900000095367432	CHEMBL140439,TP,ACT,0.9900000095367432	CHEMBL481712,TN,INACT,0.009999999776482582	CHEMBL60179,TP,ACT,1.0	CHEMBL75403,TP,ACT,0.9700000286102295	CHEMBL125601,FN,ACT,0.3199999928474426	CHEMBL306412,TP,ACT,0.9900000095367432	CHEMBL276373,TP,ACT,1.0	CHEMBL351344,TP,ACT,0.6100000143051147	

