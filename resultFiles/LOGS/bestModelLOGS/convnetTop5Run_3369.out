ImageNetInceptionV2 CHEMBL3385 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	104
Number of inactive compounds :	104
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3385_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3385_adam_0.0001_15_0.6/
---------------------------------
Training samples: 130
Validation samples: 41
--
Training Step: 1  | time: 85.607s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/130
[A[ATraining Step: 2  | total loss: [1m[32m0.65497[0m[0m | time: 96.562s
[2K
| Adam | epoch: 001 | loss: 0.65497 - acc: 0.4500 -- iter: 064/130
[A[ATraining Step: 3  | total loss: [1m[32m0.69836[0m[0m | time: 112.660s
[2K
| Adam | epoch: 001 | loss: 0.69836 - acc: 0.4653 -- iter: 096/130
[A[ATraining Step: 4  | total loss: [1m[32m0.65411[0m[0m | time: 127.059s
[2K
| Adam | epoch: 001 | loss: 0.65411 - acc: 0.6085 -- iter: 128/130
[A[ATraining Step: 5  | total loss: [1m[32m0.58545[0m[0m | time: 144.166s
[2K
| Adam | epoch: 001 | loss: 0.58545 - acc: 0.7065 | val_loss: 0.68661 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 6  | total loss: [1m[32m0.79717[0m[0m | time: 2.317s
[2K
| Adam | epoch: 002 | loss: 0.79717 - acc: 0.2523 -- iter: 032/130
[A[ATraining Step: 7  | total loss: [1m[32m0.71011[0m[0m | time: 16.767s
[2K
| Adam | epoch: 002 | loss: 0.71011 - acc: 0.4009 -- iter: 064/130
[A[ATraining Step: 8  | total loss: [1m[32m0.56506[0m[0m | time: 30.660s
[2K
| Adam | epoch: 002 | loss: 0.56506 - acc: 0.7027 -- iter: 096/130
[A[ATraining Step: 9  | total loss: [1m[32m0.56238[0m[0m | time: 42.314s
[2K
| Adam | epoch: 002 | loss: 0.56238 - acc: 0.7112 -- iter: 128/130
[A[ATraining Step: 10  | total loss: [1m[32m0.51482[0m[0m | time: 68.693s
[2K
| Adam | epoch: 002 | loss: 0.51482 - acc: 0.7619 | val_loss: 0.74493 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 11  | total loss: [1m[32m0.44184[0m[0m | time: 2.504s
[2K
| Adam | epoch: 003 | loss: 0.44184 - acc: 0.8303 -- iter: 032/130
[A[ATraining Step: 12  | total loss: [1m[32m0.57585[0m[0m | time: 4.288s
[2K
| Adam | epoch: 003 | loss: 0.57585 - acc: 0.6816 -- iter: 064/130
[A[ATraining Step: 13  | total loss: [1m[32m0.60297[0m[0m | time: 12.409s
[2K
| Adam | epoch: 003 | loss: 0.60297 - acc: 0.6038 -- iter: 096/130
[A[ATraining Step: 14  | total loss: [1m[32m0.48938[0m[0m | time: 20.590s
[2K
| Adam | epoch: 003 | loss: 0.48938 - acc: 0.7275 -- iter: 128/130
[A[ATraining Step: 15  | total loss: [1m[32m0.41434[0m[0m | time: 30.526s
[2K
| Adam | epoch: 003 | loss: 0.41434 - acc: 0.8097 | val_loss: 1.13414 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 16  | total loss: [1m[32m0.32525[0m[0m | time: 98.584s
[2K
| Adam | epoch: 004 | loss: 0.32525 - acc: 0.8811 -- iter: 032/130
[A[ATraining Step: 17  | total loss: [1m[32m0.28655[0m[0m | time: 100.125s
[2K
| Adam | epoch: 004 | loss: 0.28655 - acc: 0.9126 -- iter: 064/130
[A[ATraining Step: 18  | total loss: [1m[32m0.31321[0m[0m | time: 101.842s
[2K
| Adam | epoch: 004 | loss: 0.31321 - acc: 0.9429 -- iter: 096/130
[A[ATraining Step: 19  | total loss: [1m[32m0.24634[0m[0m | time: 113.625s
[2K
| Adam | epoch: 004 | loss: 0.24634 - acc: 0.9619 -- iter: 128/130
[A[ATraining Step: 20  | total loss: [1m[32m0.23247[0m[0m | time: 129.937s
[2K
| Adam | epoch: 004 | loss: 0.23247 - acc: 0.9742 | val_loss: 1.30805 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 21  | total loss: [1m[32m0.19855[0m[0m | time: 7.998s
[2K
| Adam | epoch: 005 | loss: 0.19855 - acc: 0.9822 -- iter: 032/130
[A[ATraining Step: 22  | total loss: [1m[32m0.18372[0m[0m | time: 16.869s
[2K
| Adam | epoch: 005 | loss: 0.18372 - acc: 0.9781 -- iter: 064/130
[A[ATraining Step: 23  | total loss: [1m[32m0.14542[0m[0m | time: 18.898s
[2K
| Adam | epoch: 005 | loss: 0.14542 - acc: 0.9845 -- iter: 096/130
[A[ATraining Step: 24  | total loss: [1m[32m0.12050[0m[0m | time: 21.061s
[2K
| Adam | epoch: 005 | loss: 0.12050 - acc: 0.9889 -- iter: 128/130
[A[ATraining Step: 25  | total loss: [1m[32m0.09400[0m[0m | time: 36.099s
[2K
| Adam | epoch: 005 | loss: 0.09400 - acc: 0.9919 | val_loss: 1.15627 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 26  | total loss: [1m[32m0.08928[0m[0m | time: 10.962s
[2K
| Adam | epoch: 006 | loss: 0.08928 - acc: 0.9940 -- iter: 032/130
[A[ATraining Step: 27  | total loss: [1m[32m0.07790[0m[0m | time: 97.434s
[2K
| Adam | epoch: 006 | loss: 0.07790 - acc: 0.9956 -- iter: 064/130
[A[ATraining Step: 28  | total loss: [1m[32m0.16522[0m[0m | time: 154.355s
[2K
| Adam | epoch: 006 | loss: 0.16522 - acc: 0.9732 -- iter: 096/130
[A[ATraining Step: 29  | total loss: [1m[32m0.12985[0m[0m | time: 156.789s
[2K
| Adam | epoch: 006 | loss: 0.12985 - acc: 0.9798 -- iter: 128/130
[A[ATraining Step: 30  | total loss: [1m[32m0.10313[0m[0m | time: 160.464s
[2K
| Adam | epoch: 006 | loss: 0.10313 - acc: 0.9845 | val_loss: 1.13738 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 31  | total loss: [1m[32m0.08070[0m[0m | time: 12.431s
[2K
| Adam | epoch: 007 | loss: 0.08070 - acc: 0.9881 -- iter: 032/130
[A[ATraining Step: 32  | total loss: [1m[32m0.08290[0m[0m | time: 26.760s
[2K
| Adam | epoch: 007 | loss: 0.08290 - acc: 0.9767 -- iter: 064/130
[A[ATraining Step: 33  | total loss: [1m[32m0.07239[0m[0m | time: 39.315s
[2K
| Adam | epoch: 007 | loss: 0.07239 - acc: 0.9818 -- iter: 096/130
[A[ATraining Step: 34  | total loss: [1m[32m0.06188[0m[0m | time: 52.049s
[2K
| Adam | epoch: 007 | loss: 0.06188 - acc: 0.9857 -- iter: 128/130
[A[ATraining Step: 35  | total loss: [1m[32m0.05459[0m[0m | time: 57.523s
[2K
| Adam | epoch: 007 | loss: 0.05459 - acc: 0.9887 | val_loss: 1.05781 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 36  | total loss: [1m[32m0.19141[0m[0m | time: 2.319s
[2K
| Adam | epoch: 008 | loss: 0.19141 - acc: 0.7865 -- iter: 032/130
[A[ATraining Step: 37  | total loss: [1m[32m0.30221[0m[0m | time: 11.038s
[2K
| Adam | epoch: 008 | loss: 0.30221 - acc: 0.7292 -- iter: 064/130
[A[ATraining Step: 38  | total loss: [1m[32m0.24522[0m[0m | time: 19.075s
[2K
| Adam | epoch: 008 | loss: 0.24522 - acc: 0.7822 -- iter: 096/130
[A[ATraining Step: 39  | total loss: [1m[32m0.19994[0m[0m | time: 26.963s
[2K
| Adam | epoch: 008 | loss: 0.19994 - acc: 0.8239 -- iter: 128/130
[A[ATraining Step: 40  | total loss: [1m[32m0.18731[0m[0m | time: 36.799s
[2K
| Adam | epoch: 008 | loss: 0.18731 - acc: 0.8510 | val_loss: 0.81847 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 41  | total loss: [1m[32m0.15420[0m[0m | time: 2.431s
[2K
| Adam | epoch: 009 | loss: 0.15420 - acc: 0.8784 -- iter: 032/130
[A[ATraining Step: 42  | total loss: [1m[32m0.34395[0m[0m | time: 4.445s
[2K
| Adam | epoch: 009 | loss: 0.34395 - acc: 0.8103 -- iter: 064/130
[A[ATraining Step: 43  | total loss: [1m[32m0.46698[0m[0m | time: 17.308s
[2K
| Adam | epoch: 009 | loss: 0.46698 - acc: 0.7555 -- iter: 096/130
[A[ATraining Step: 44  | total loss: [1m[32m0.41649[0m[0m | time: 30.268s
[2K
| Adam | epoch: 009 | loss: 0.41649 - acc: 0.7924 -- iter: 128/130
[A[ATraining Step: 45  | total loss: [1m[32m0.35164[0m[0m | time: 46.106s
[2K
| Adam | epoch: 009 | loss: 0.35164 - acc: 0.8277 | val_loss: 0.73119 - val_acc: 0.6098 -- iter: 130/130
--
Training Step: 46  | total loss: [1m[32m0.31901[0m[0m | time: 7.984s
[2K
| Adam | epoch: 010 | loss: 0.31901 - acc: 0.8512 -- iter: 032/130
[A[ATraining Step: 47  | total loss: [1m[32m0.27639[0m[0m | time: 9.175s
[2K
| Adam | epoch: 010 | loss: 0.27639 - acc: 0.8704 -- iter: 064/130
[A[ATraining Step: 48  | total loss: [1m[32m0.51629[0m[0m | time: 10.349s
[2K
| Adam | epoch: 010 | loss: 0.51629 - acc: 0.8109 -- iter: 096/130
[A[ATraining Step: 49  | total loss: [1m[32m0.53674[0m[0m | time: 51.509s
[2K
| Adam | epoch: 010 | loss: 0.53674 - acc: 0.7618 -- iter: 128/130
[A[ATraining Step: 50  | total loss: [1m[32m0.45917[0m[0m | time: 93.738s
[2K
| Adam | epoch: 010 | loss: 0.45917 - acc: 0.7988 | val_loss: 0.58341 - val_acc: 0.6585 -- iter: 130/130
--
Training Step: 51  | total loss: [1m[32m0.39147[0m[0m | time: 12.760s
[2K
| Adam | epoch: 011 | loss: 0.39147 - acc: 0.8295 -- iter: 032/130
[A[ATraining Step: 52  | total loss: [1m[32m0.33682[0m[0m | time: 24.540s
[2K
| Adam | epoch: 011 | loss: 0.33682 - acc: 0.8550 -- iter: 064/130
[A[ATraining Step: 53  | total loss: [1m[32m0.29249[0m[0m | time: 25.776s
[2K
| Adam | epoch: 011 | loss: 0.29249 - acc: 0.8764 -- iter: 096/130
[A[ATraining Step: 54  | total loss: [1m[32m0.34784[0m[0m | time: 26.979s
[2K
| Adam | epoch: 011 | loss: 0.34784 - acc: 0.8218 -- iter: 128/130
[A[ATraining Step: 55  | total loss: [1m[32m0.47616[0m[0m | time: 36.972s
[2K
| Adam | epoch: 011 | loss: 0.47616 - acc: 0.7758 | val_loss: 0.51480 - val_acc: 0.7805 -- iter: 130/130
--
Training Step: 56  | total loss: [1m[32m0.41214[0m[0m | time: 12.110s
[2K
| Adam | epoch: 012 | loss: 0.41214 - acc: 0.8073 -- iter: 032/130
[A[ATraining Step: 57  | total loss: [1m[32m0.37600[0m[0m | time: 25.131s
[2K
| Adam | epoch: 012 | loss: 0.37600 - acc: 0.8297 -- iter: 064/130
[A[ATraining Step: 58  | total loss: [1m[32m0.34904[0m[0m | time: 38.234s
[2K
| Adam | epoch: 012 | loss: 0.34904 - acc: 0.8487 -- iter: 096/130
[A[ATraining Step: 59  | total loss: [1m[32m0.31257[0m[0m | time: 40.585s
[2K
| Adam | epoch: 012 | loss: 0.31257 - acc: 0.8648 -- iter: 128/130
[A[ATraining Step: 60  | total loss: [1m[32m0.39422[0m[0m | time: 45.804s
[2K
| Adam | epoch: 012 | loss: 0.39422 - acc: 0.7503 | val_loss: 0.52432 - val_acc: 0.8049 -- iter: 130/130
--
Training Step: 61  | total loss: [1m[32m0.44403[0m[0m | time: 8.114s
[2K
| Adam | epoch: 013 | loss: 0.44403 - acc: 0.7177 -- iter: 032/130
[A[ATraining Step: 62  | total loss: [1m[32m0.39268[0m[0m | time: 18.860s
[2K
| Adam | epoch: 013 | loss: 0.39268 - acc: 0.7540 -- iter: 064/130
[A[ATraining Step: 63  | total loss: [1m[32m0.34718[0m[0m | time: 38.186s
[2K
| Adam | epoch: 013 | loss: 0.34718 - acc: 0.7852 -- iter: 096/130
[A[ATraining Step: 64  | total loss: [1m[32m0.31083[0m[0m | time: 51.172s
[2K
| Adam | epoch: 013 | loss: 0.31083 - acc: 0.8120 -- iter: 128/130
[A[ATraining Step: 65  | total loss: [1m[32m0.27761[0m[0m | time: 56.062s
[2K
| Adam | epoch: 013 | loss: 0.27761 - acc: 0.8313 | val_loss: 1.16785 - val_acc: 0.5610 -- iter: 130/130
--
Training Step: 66  | total loss: [1m[32m0.24569[0m[0m | time: 2.206s
[2K
| Adam | epoch: 014 | loss: 0.24569 - acc: 0.8519 -- iter: 032/130
[A[ATraining Step: 67  | total loss: [1m[32m0.21683[0m[0m | time: 17.909s
[2K
| Adam | epoch: 014 | loss: 0.21683 - acc: 0.8696 -- iter: 064/130
[A[ATraining Step: 68  | total loss: [1m[32m0.19337[0m[0m | time: 28.107s
[2K
| Adam | epoch: 014 | loss: 0.19337 - acc: 0.8851 -- iter: 096/130
[A[ATraining Step: 69  | total loss: [1m[32m0.17368[0m[0m | time: 36.190s
[2K
| Adam | epoch: 014 | loss: 0.17368 - acc: 0.8985 -- iter: 128/130
[A[ATraining Step: 70  | total loss: [1m[32m0.18802[0m[0m | time: 46.278s
[2K
| Adam | epoch: 014 | loss: 0.18802 - acc: 0.9066 | val_loss: 3.11698 - val_acc: 0.4390 -- iter: 130/130
--
Training Step: 71  | total loss: [1m[32m0.16811[0m[0m | time: 2.095s
[2K
| Adam | epoch: 015 | loss: 0.16811 - acc: 0.9172 -- iter: 032/130
[A[ATraining Step: 72  | total loss: [1m[32m0.14992[0m[0m | time: 3.986s
[2K
| Adam | epoch: 015 | loss: 0.14992 - acc: 0.9266 -- iter: 064/130
[A[ATraining Step: 73  | total loss: [1m[32m0.13413[0m[0m | time: 51.149s
[2K
| Adam | epoch: 015 | loss: 0.13413 - acc: 0.9347 -- iter: 096/130
[A[ATraining Step: 74  | total loss: [1m[32m0.12066[0m[0m | time: 70.287s
[2K
| Adam | epoch: 015 | loss: 0.12066 - acc: 0.9419 -- iter: 128/130
[A[ATraining Step: 75  | total loss: [1m[32m0.11324[0m[0m | time: 86.071s
[2K
| Adam | epoch: 015 | loss: 0.11324 - acc: 0.9482 | val_loss: 1.45231 - val_acc: 0.5854 -- iter: 130/130
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8455882352941178
Validation AUPRC:0.841984154215236
Test AUC:0.8857142857142857
Test AUPRC:0.870364664704061
BestTestF1Score	0.82	0.66	0.83	0.84	0.8	16	3	18	4	0.98
BestTestMCCScore	0.82	0.66	0.83	0.84	0.8	16	3	18	4	0.98
BestTestAccuracyScore	0.82	0.66	0.83	0.84	0.8	16	3	18	4	0.98
BestValidationF1Score	0.76	0.57	0.78	0.7	0.82	14	6	18	3	0.98
BestValidationMCC	0.76	0.57	0.78	0.7	0.82	14	6	18	3	0.98
BestValidationAccuracy	0.76	0.57	0.78	0.7	0.82	14	6	18	3	0.98
TestPredictions (Threshold:0.98)
CHEMBL497454,TN,INACT,0.8799999952316284	CHEMBL456112,TN,INACT,0.6200000047683716	CHEMBL509499,TN,INACT,0.7699999809265137	CHEMBL3590107,FN,ACT,0.9300000071525574	CHEMBL500659,TP,ACT,0.9900000095367432	CHEMBL1734241,TN,INACT,0.12999999523162842	CHEMBL497701,TP,ACT,0.9900000095367432	CHEMBL1087421,TN,INACT,0.9700000286102295	CHEMBL457401,TN,INACT,0.8500000238418579	CHEMBL500406,TP,ACT,0.9900000095367432	CHEMBL527029,TP,ACT,1.0	CHEMBL1668411,TP,ACT,1.0	CHEMBL521201,FP,INACT,1.0	CHEMBL496478,TP,ACT,0.9900000095367432	CHEMBL457191,TN,INACT,0.23999999463558197	CHEMBL3577567,TP,ACT,1.0	CHEMBL1089119,FN,ACT,0.9200000166893005	CHEMBL2420584,TN,INACT,0.9599999785423279	CHEMBL3798631,FN,ACT,0.9599999785423279	CHEMBL452812,FP,INACT,1.0	CHEMBL498705,TN,INACT,0.8799999952316284	CHEMBL3797917,FN,ACT,0.8700000047683716	CHEMBL1767126,TN,INACT,0.6899999976158142	CHEMBL1081198,FP,INACT,1.0	CHEMBL3798624,TP,ACT,1.0	CHEMBL1287914,TN,INACT,0.5899999737739563	CHEMBL3798109,TP,ACT,1.0	CHEMBL259551,TP,ACT,1.0	CHEMBL1234833,TP,ACT,0.9900000095367432	CHEMBL524640,TP,ACT,1.0	CHEMBL77155,TN,INACT,0.8600000143051147	CHEMBL3577631,TP,ACT,1.0	CHEMBL525921,TN,INACT,0.3400000035762787	CHEMBL551936,TN,INACT,0.03999999910593033	CHEMBL3800134,TP,ACT,1.0	CHEMBL1922121,TN,INACT,0.7200000286102295	CHEMBL498487,TP,ACT,0.9800000190734863	CHEMBL524445,TP,ACT,1.0	CHEMBL498130,TN,INACT,0.07999999821186066	CHEMBL1287945,TN,INACT,0.8600000143051147	CHEMBL1784660,TN,INACT,0.949999988079071	

