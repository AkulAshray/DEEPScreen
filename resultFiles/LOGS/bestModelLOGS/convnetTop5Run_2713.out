CNNModel CHEMBL3066 RMSprop 0.0005 15 128 0 0.8 False True
Number of active compounds :	730
Number of inactive compounds :	730
---------------------------------
Run id: CNNModel_CHEMBL3066_RMSprop_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3066_RMSprop_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 909
Validation samples: 285
--
Training Step: 1  | time: 1.308s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/909
[A[ATraining Step: 2  | total loss: [1m[32m0.62388[0m[0m | time: 2.342s
[2K
| RMSProp | epoch: 001 | loss: 0.62388 - acc: 0.4500 -- iter: 064/909
[A[ATraining Step: 3  | total loss: [1m[32m0.68049[0m[0m | time: 3.303s
[2K
| RMSProp | epoch: 001 | loss: 0.68049 - acc: 0.4909 -- iter: 096/909
[A[ATraining Step: 4  | total loss: [1m[32m0.69020[0m[0m | time: 4.284s
[2K
| RMSProp | epoch: 001 | loss: 0.69020 - acc: 0.4274 -- iter: 128/909
[A[ATraining Step: 5  | total loss: [1m[32m0.69225[0m[0m | time: 5.298s
[2K
| RMSProp | epoch: 001 | loss: 0.69225 - acc: 0.5209 -- iter: 160/909
[A[ATraining Step: 6  | total loss: [1m[32m0.69293[0m[0m | time: 6.303s
[2K
| RMSProp | epoch: 001 | loss: 0.69293 - acc: 0.4673 -- iter: 192/909
[A[ATraining Step: 7  | total loss: [1m[32m0.69324[0m[0m | time: 7.175s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4307 -- iter: 224/909
[A[ATraining Step: 8  | total loss: [1m[32m0.69326[0m[0m | time: 8.012s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.4521 -- iter: 256/909
[A[ATraining Step: 9  | total loss: [1m[32m0.69319[0m[0m | time: 8.908s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4609 -- iter: 288/909
[A[ATraining Step: 10  | total loss: [1m[32m0.69329[0m[0m | time: 9.817s
[2K
| RMSProp | epoch: 001 | loss: 0.69329 - acc: 0.4492 -- iter: 320/909
[A[ATraining Step: 11  | total loss: [1m[32m0.69332[0m[0m | time: 10.765s
[2K
| RMSProp | epoch: 001 | loss: 0.69332 - acc: 0.4437 -- iter: 352/909
[A[ATraining Step: 12  | total loss: [1m[32m0.69337[0m[0m | time: 11.770s
[2K
| RMSProp | epoch: 001 | loss: 0.69337 - acc: 0.4409 -- iter: 384/909
[A[ATraining Step: 13  | total loss: [1m[32m0.69316[0m[0m | time: 12.725s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4796 -- iter: 416/909
[A[ATraining Step: 14  | total loss: [1m[32m0.69318[0m[0m | time: 13.564s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5007 -- iter: 448/909
[A[ATraining Step: 15  | total loss: [1m[32m0.69322[0m[0m | time: 14.596s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.5004 -- iter: 480/909
[A[ATraining Step: 16  | total loss: [1m[32m0.69314[0m[0m | time: 15.624s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5354 -- iter: 512/909
[A[ATraining Step: 17  | total loss: [1m[32m0.69315[0m[0m | time: 16.627s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.5452 -- iter: 544/909
[A[ATraining Step: 18  | total loss: [1m[32m0.69319[0m[0m | time: 17.427s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.5187 -- iter: 576/909
[A[ATraining Step: 19  | total loss: [1m[32m0.69317[0m[0m | time: 18.341s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5437 -- iter: 608/909
[A[ATraining Step: 20  | total loss: [1m[32m0.69325[0m[0m | time: 19.274s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4795 -- iter: 640/909
[A[ATraining Step: 21  | total loss: [1m[32m0.69319[0m[0m | time: 20.175s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4664 -- iter: 672/909
[A[ATraining Step: 22  | total loss: [1m[32m0.69328[0m[0m | time: 21.152s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4578 -- iter: 704/909
[A[ATraining Step: 23  | total loss: [1m[32m0.69329[0m[0m | time: 22.193s
[2K
| RMSProp | epoch: 001 | loss: 0.69329 - acc: 0.4609 -- iter: 736/909
[A[ATraining Step: 24  | total loss: [1m[32m0.69327[0m[0m | time: 23.059s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.4719 -- iter: 768/909
[A[ATraining Step: 25  | total loss: [1m[32m0.69326[0m[0m | time: 24.000s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.4796 -- iter: 800/909
[A[ATraining Step: 26  | total loss: [1m[32m0.69326[0m[0m | time: 25.010s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.4519 -- iter: 832/909
[A[ATraining Step: 27  | total loss: [1m[32m0.69314[0m[0m | time: 25.995s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5044 -- iter: 864/909
[A[ATraining Step: 28  | total loss: [1m[32m0.69312[0m[0m | time: 26.739s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5190 -- iter: 896/909
[A[ATraining Step: 29  | total loss: [1m[32m0.69315[0m[0m | time: 28.496s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.4915 | val_loss: 0.69324 - val_acc: 0.4456 -- iter: 909/909
--
Training Step: 30  | total loss: [1m[32m0.69316[0m[0m | time: 0.548s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.4844 -- iter: 032/909
[A[ATraining Step: 31  | total loss: [1m[32m0.69314[0m[0m | time: 1.586s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.5147 -- iter: 064/909
[A[ATraining Step: 32  | total loss: [1m[32m0.69317[0m[0m | time: 2.566s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4903 -- iter: 096/909
[A[ATraining Step: 33  | total loss: [1m[32m0.69314[0m[0m | time: 3.374s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4924 -- iter: 128/909
[A[ATraining Step: 34  | total loss: [1m[32m0.69318[0m[0m | time: 4.263s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4806 -- iter: 160/909
[A[ATraining Step: 35  | total loss: [1m[32m0.69316[0m[0m | time: 5.162s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.4912 -- iter: 192/909
[A[ATraining Step: 36  | total loss: [1m[32m0.69321[0m[0m | time: 6.048s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4547 -- iter: 224/909
[A[ATraining Step: 37  | total loss: [1m[32m0.69318[0m[0m | time: 6.985s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4575 -- iter: 256/909
[A[ATraining Step: 38  | total loss: [1m[32m0.69322[0m[0m | time: 8.027s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4536 -- iter: 288/909
[A[ATraining Step: 39  | total loss: [1m[32m0.69322[0m[0m | time: 9.017s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4565 -- iter: 320/909
[A[ATraining Step: 40  | total loss: [1m[32m0.69322[0m[0m | time: 9.878s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4705 -- iter: 352/909
[A[ATraining Step: 41  | total loss: [1m[32m0.69316[0m[0m | time: 10.946s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.5104 -- iter: 384/909
[A[ATraining Step: 42  | total loss: [1m[32m0.69312[0m[0m | time: 11.938s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5254 -- iter: 416/909
[A[ATraining Step: 43  | total loss: [1m[32m0.69313[0m[0m | time: 12.778s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.4933 -- iter: 448/909
[A[ATraining Step: 44  | total loss: [1m[32m0.69313[0m[0m | time: 13.668s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.4945 -- iter: 480/909
[A[ATraining Step: 45  | total loss: [1m[32m0.69312[0m[0m | time: 14.562s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5007 -- iter: 512/909
[A[ATraining Step: 46  | total loss: [1m[32m0.69315[0m[0m | time: 15.469s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4902 -- iter: 544/909
[A[ATraining Step: 47  | total loss: [1m[32m0.69314[0m[0m | time: 16.400s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4969 -- iter: 576/909
[A[ATraining Step: 48  | total loss: [1m[32m0.69316[0m[0m | time: 17.402s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.4874 -- iter: 608/909
[A[ATraining Step: 49  | total loss: [1m[32m0.69319[0m[0m | time: 18.386s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4745 -- iter: 640/909
[A[ATraining Step: 50  | total loss: [1m[32m0.69318[0m[0m | time: 19.210s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4591 -- iter: 672/909
[A[ATraining Step: 51  | total loss: [1m[32m0.69317[0m[0m | time: 20.207s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4510 -- iter: 704/909
[A[ATraining Step: 52  | total loss: [1m[32m0.69319[0m[0m | time: 21.257s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4443 -- iter: 736/909
[A[ATraining Step: 53  | total loss: [1m[32m0.69318[0m[0m | time: 22.225s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4618 -- iter: 768/909
[A[ATraining Step: 54  | total loss: [1m[32m0.69317[0m[0m | time: 23.084s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4673 -- iter: 800/909
[A[ATraining Step: 55  | total loss: [1m[32m0.69315[0m[0m | time: 23.981s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4764 -- iter: 832/909
[A[ATraining Step: 56  | total loss: [1m[32m0.69315[0m[0m | time: 24.854s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4798 -- iter: 864/909
[A[ATraining Step: 57  | total loss: [1m[32m0.69314[0m[0m | time: 25.753s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4955 -- iter: 896/909
[A[ATraining Step: 58  | total loss: [1m[32m0.69313[0m[0m | time: 28.214s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.4961 | val_loss: 0.69346 - val_acc: 0.4456 -- iter: 909/909
--
Training Step: 59  | total loss: [1m[32m0.69311[0m[0m | time: 0.330s
[2K
| RMSProp | epoch: 003 | loss: 0.69311 - acc: 0.5051 -- iter: 032/909
[A[ATraining Step: 60  | total loss: [1m[32m0.69321[0m[0m | time: 0.691s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4891 -- iter: 064/909
[A[ATraining Step: 61  | total loss: [1m[32m0.69324[0m[0m | time: 1.562s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.4755 -- iter: 096/909
[A[ATraining Step: 62  | total loss: [1m[32m0.69320[0m[0m | time: 2.433s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.4746 -- iter: 128/909
[A[ATraining Step: 63  | total loss: [1m[32m0.69321[0m[0m | time: 3.338s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4660 -- iter: 160/909
[A[ATraining Step: 64  | total loss: [1m[32m0.69319[0m[0m | time: 4.253s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.4819 -- iter: 192/909
[A[ATraining Step: 65  | total loss: [1m[32m0.69320[0m[0m | time: 5.316s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.4765 -- iter: 224/909
[A[ATraining Step: 66  | total loss: [1m[32m0.69318[0m[0m | time: 6.257s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.4869 -- iter: 256/909
[A[ATraining Step: 67  | total loss: [1m[32m0.69316[0m[0m | time: 7.113s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.4960 -- iter: 288/909
[A[ATraining Step: 68  | total loss: [1m[32m0.69313[0m[0m | time: 8.199s
[2K
| RMSProp | epoch: 003 | loss: 0.69313 - acc: 0.5002 -- iter: 320/909
[A[ATraining Step: 69  | total loss: [1m[32m0.69312[0m[0m | time: 9.219s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5074 -- iter: 352/909
[A[ATraining Step: 70  | total loss: [1m[32m0.69305[0m[0m | time: 10.063s
[2K
| RMSProp | epoch: 003 | loss: 0.69305 - acc: 0.5174 -- iter: 384/909
[A[ATraining Step: 71  | total loss: [1m[32m0.69304[0m[0m | time: 10.924s
[2K
| RMSProp | epoch: 003 | loss: 0.69304 - acc: 0.5190 -- iter: 416/909
[A[ATraining Step: 72  | total loss: [1m[32m0.69303[0m[0m | time: 11.802s
[2K
| RMSProp | epoch: 003 | loss: 0.69303 - acc: 0.5204 -- iter: 448/909
[A[ATraining Step: 73  | total loss: [1m[32m0.69283[0m[0m | time: 12.726s
[2K
| RMSProp | epoch: 003 | loss: 0.69283 - acc: 0.5389 -- iter: 480/909
[A[ATraining Step: 74  | total loss: [1m[32m0.69267[0m[0m | time: 13.616s
[2K
| RMSProp | epoch: 003 | loss: 0.69267 - acc: 0.5518 -- iter: 512/909
[A[ATraining Step: 75  | total loss: [1m[32m0.69282[0m[0m | time: 14.695s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5394 -- iter: 544/909
[A[ATraining Step: 76  | total loss: [1m[32m0.69280[0m[0m | time: 15.703s
[2K
| RMSProp | epoch: 003 | loss: 0.69280 - acc: 0.5385 -- iter: 576/909
[A[ATraining Step: 77  | total loss: [1m[32m0.69253[0m[0m | time: 16.515s
[2K
| RMSProp | epoch: 003 | loss: 0.69253 - acc: 0.5543 -- iter: 608/909
[A[ATraining Step: 78  | total loss: [1m[32m0.69285[0m[0m | time: 17.551s
[2K
| RMSProp | epoch: 003 | loss: 0.69285 - acc: 0.5323 -- iter: 640/909
[A[ATraining Step: 79  | total loss: [1m[32m0.69276[0m[0m | time: 18.604s
[2K
| RMSProp | epoch: 003 | loss: 0.69276 - acc: 0.5386 -- iter: 672/909
[A[ATraining Step: 80  | total loss: [1m[32m0.69271[0m[0m | time: 19.560s
[2K
| RMSProp | epoch: 003 | loss: 0.69271 - acc: 0.5411 -- iter: 704/909
[A[ATraining Step: 81  | total loss: [1m[32m0.69306[0m[0m | time: 20.362s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5180 -- iter: 736/909
[A[ATraining Step: 82  | total loss: [1m[32m0.69306[0m[0m | time: 21.249s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5162 -- iter: 768/909
[A[ATraining Step: 83  | total loss: [1m[32m0.69318[0m[0m | time: 22.175s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.5052 -- iter: 800/909
[A[ATraining Step: 84  | total loss: [1m[32m0.69329[0m[0m | time: 23.092s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4953 -- iter: 832/909
[A[ATraining Step: 85  | total loss: [1m[32m0.69326[0m[0m | time: 24.108s
[2K
| RMSProp | epoch: 003 | loss: 0.69326 - acc: 0.4989 -- iter: 864/909
[A[ATraining Step: 86  | total loss: [1m[32m0.69314[0m[0m | time: 25.129s
[2K
| RMSProp | epoch: 003 | loss: 0.69314 - acc: 0.5084 -- iter: 896/909
[A[ATraining Step: 87  | total loss: [1m[32m0.69307[0m[0m | time: 27.323s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5138 | val_loss: 0.69392 - val_acc: 0.4456 -- iter: 909/909
--
Training Step: 88  | total loss: [1m[32m0.69306[0m[0m | time: 0.912s
[2K
| RMSProp | epoch: 004 | loss: 0.69306 - acc: 0.5155 -- iter: 032/909
[A[ATraining Step: 89  | total loss: [1m[32m0.69284[0m[0m | time: 1.381s
[2K
| RMSProp | epoch: 004 | loss: 0.69284 - acc: 0.5296 -- iter: 064/909
[A[ATraining Step: 90  | total loss: [1m[32m0.69269[0m[0m | time: 1.894s
[2K
| RMSProp | epoch: 004 | loss: 0.69269 - acc: 0.5382 -- iter: 096/909
[A[ATraining Step: 91  | total loss: [1m[32m0.69254[0m[0m | time: 2.860s
[2K
| RMSProp | epoch: 004 | loss: 0.69254 - acc: 0.5459 -- iter: 128/909
[A[ATraining Step: 92  | total loss: [1m[32m0.69267[0m[0m | time: 3.661s
[2K
| RMSProp | epoch: 004 | loss: 0.69267 - acc: 0.5382 -- iter: 160/909
[A[ATraining Step: 93  | total loss: [1m[32m0.69252[0m[0m | time: 4.723s
[2K
| RMSProp | epoch: 004 | loss: 0.69252 - acc: 0.5437 -- iter: 192/909
[A[ATraining Step: 94  | total loss: [1m[32m0.69239[0m[0m | time: 5.824s
[2K
| RMSProp | epoch: 004 | loss: 0.69239 - acc: 0.5456 -- iter: 224/909
[A[ATraining Step: 95  | total loss: [1m[32m0.69246[0m[0m | time: 6.737s
[2K
| RMSProp | epoch: 004 | loss: 0.69246 - acc: 0.5411 -- iter: 256/909
[A[ATraining Step: 96  | total loss: [1m[32m0.69193[0m[0m | time: 7.569s
[2K
| RMSProp | epoch: 004 | loss: 0.69193 - acc: 0.5588 -- iter: 288/909
[A[ATraining Step: 97  | total loss: [1m[32m0.69174[0m[0m | time: 8.482s
[2K
| RMSProp | epoch: 004 | loss: 0.69174 - acc: 0.5623 -- iter: 320/909
[A[ATraining Step: 98  | total loss: [1m[32m0.69212[0m[0m | time: 9.377s
[2K
| RMSProp | epoch: 004 | loss: 0.69212 - acc: 0.5498 -- iter: 352/909
[A[ATraining Step: 99  | total loss: [1m[32m0.69223[0m[0m | time: 10.272s
[2K
| RMSProp | epoch: 004 | loss: 0.69223 - acc: 0.5449 -- iter: 384/909
[A[ATraining Step: 100  | total loss: [1m[32m0.69244[0m[0m | time: 11.263s
[2K
| RMSProp | epoch: 004 | loss: 0.69244 - acc: 0.5372 -- iter: 416/909
[A[ATraining Step: 101  | total loss: [1m[32m0.69229[0m[0m | time: 12.215s
[2K
| RMSProp | epoch: 004 | loss: 0.69229 - acc: 0.5398 -- iter: 448/909
[A[ATraining Step: 102  | total loss: [1m[32m0.69218[0m[0m | time: 13.084s
[2K
| RMSProp | epoch: 004 | loss: 0.69218 - acc: 0.5420 -- iter: 480/909
[A[ATraining Step: 103  | total loss: [1m[32m0.69206[0m[0m | time: 14.096s
[2K
| RMSProp | epoch: 004 | loss: 0.69206 - acc: 0.5441 -- iter: 512/909
[A[ATraining Step: 104  | total loss: [1m[32m0.69266[0m[0m | time: 15.153s
[2K
| RMSProp | epoch: 004 | loss: 0.69266 - acc: 0.5272 -- iter: 544/909
[A[ATraining Step: 105  | total loss: [1m[32m0.69332[0m[0m | time: 16.135s
[2K
| RMSProp | epoch: 004 | loss: 0.69332 - acc: 0.5057 -- iter: 576/909
[A[ATraining Step: 106  | total loss: [1m[32m0.69332[0m[0m | time: 16.922s
[2K
| RMSProp | epoch: 004 | loss: 0.69332 - acc: 0.5051 -- iter: 608/909
[A[ATraining Step: 107  | total loss: [1m[32m0.69340[0m[0m | time: 17.800s
[2K
| RMSProp | epoch: 004 | loss: 0.69340 - acc: 0.5015 -- iter: 640/909
[A[ATraining Step: 108  | total loss: [1m[32m0.69362[0m[0m | time: 18.687s
[2K
| RMSProp | epoch: 004 | loss: 0.69362 - acc: 0.4888 -- iter: 672/909
[A[ATraining Step: 109  | total loss: [1m[32m0.69335[0m[0m | time: 19.604s
[2K
| RMSProp | epoch: 004 | loss: 0.69335 - acc: 0.5056 -- iter: 704/909
[A[ATraining Step: 110  | total loss: [1m[32m0.69319[0m[0m | time: 20.666s
[2K
| RMSProp | epoch: 004 | loss: 0.69319 - acc: 0.5113 -- iter: 736/909
[A[ATraining Step: 111  | total loss: [1m[32m0.69309[0m[0m | time: 21.733s
[2K
| RMSProp | epoch: 004 | loss: 0.69309 - acc: 0.5133 -- iter: 768/909
[A[ATraining Step: 112  | total loss: [1m[32m0.69285[0m[0m | time: 22.630s
[2K
| RMSProp | epoch: 004 | loss: 0.69285 - acc: 0.5213 -- iter: 800/909
[A[ATraining Step: 113  | total loss: [1m[32m0.69261[0m[0m | time: 23.630s
[2K
| RMSProp | epoch: 004 | loss: 0.69261 - acc: 0.5286 -- iter: 832/909
[A[ATraining Step: 114  | total loss: [1m[32m0.69258[0m[0m | time: 24.636s
[2K
| RMSProp | epoch: 004 | loss: 0.69258 - acc: 0.5288 -- iter: 864/909
[A[ATraining Step: 115  | total loss: [1m[32m0.69264[0m[0m | time: 25.658s
[2K
| RMSProp | epoch: 004 | loss: 0.69264 - acc: 0.5260 -- iter: 896/909
[A[ATraining Step: 116  | total loss: [1m[32m0.69289[0m[0m | time: 27.643s
[2K
| RMSProp | epoch: 004 | loss: 0.69289 - acc: 0.5171 | val_loss: 0.69459 - val_acc: 0.4456 -- iter: 909/909
--
Training Step: 117  | total loss: [1m[32m0.69301[0m[0m | time: 0.872s
[2K
| RMSProp | epoch: 005 | loss: 0.69301 - acc: 0.5123 -- iter: 032/909
[A[ATraining Step: 118  | total loss: [1m[32m0.69302[0m[0m | time: 1.844s
[2K
| RMSProp | epoch: 005 | loss: 0.69302 - acc: 0.5110 -- iter: 064/909
[A[ATraining Step: 119  | total loss: [1m[32m0.69353[0m[0m | time: 2.315s
[2K
| RMSProp | epoch: 005 | loss: 0.69353 - acc: 0.4912 -- iter: 096/909
[A[ATraining Step: 120  | total loss: [1m[32m0.69335[0m[0m | time: 2.794s
[2K
| RMSProp | epoch: 005 | loss: 0.69335 - acc: 0.5036 -- iter: 128/909
[A[ATraining Step: 121  | total loss: [1m[32m0.69311[0m[0m | time: 3.794s
[2K
| RMSProp | epoch: 005 | loss: 0.69311 - acc: 0.5148 -- iter: 160/909
[A[ATraining Step: 122  | total loss: [1m[32m0.69301[0m[0m | time: 4.574s
[2K
| RMSProp | epoch: 005 | loss: 0.69301 - acc: 0.5164 -- iter: 192/909
[A[ATraining Step: 123  | total loss: [1m[32m0.69293[0m[0m | time: 5.545s
[2K
| RMSProp | epoch: 005 | loss: 0.69293 - acc: 0.5179 -- iter: 224/909
[A[ATraining Step: 124  | total loss: [1m[32m0.69332[0m[0m | time: 6.463s
[2K
| RMSProp | epoch: 005 | loss: 0.69332 - acc: 0.5036 -- iter: 256/909
[A[ATraining Step: 125  | total loss: [1m[32m0.69342[0m[0m | time: 7.420s
[2K
| RMSProp | epoch: 005 | loss: 0.69342 - acc: 0.4970 -- iter: 288/909
[A[ATraining Step: 126  | total loss: [1m[32m0.69350[0m[0m | time: 8.344s
[2K
| RMSProp | epoch: 005 | loss: 0.69350 - acc: 0.4911 -- iter: 320/909
[A[ATraining Step: 127  | total loss: [1m[32m0.69353[0m[0m | time: 9.349s
[2K
| RMSProp | epoch: 005 | loss: 0.69353 - acc: 0.4857 -- iter: 352/909
[A[ATraining Step: 128  | total loss: [1m[32m0.69343[0m[0m | time: 10.319s
[2K
| RMSProp | epoch: 005 | loss: 0.69343 - acc: 0.4996 -- iter: 384/909
[A[ATraining Step: 129  | total loss: [1m[32m0.69333[0m[0m | time: 11.154s
[2K
| RMSProp | epoch: 005 | loss: 0.69333 - acc: 0.5028 -- iter: 416/909
[A[ATraining Step: 130  | total loss: [1m[32m0.69305[0m[0m | time: 12.245s
[2K
| RMSProp | epoch: 005 | loss: 0.69305 - acc: 0.5150 -- iter: 448/909
[A[ATraining Step: 131  | total loss: [1m[32m0.69336[0m[0m | time: 13.283s
[2K
| RMSProp | epoch: 005 | loss: 0.69336 - acc: 0.5041 -- iter: 480/909
[A[ATraining Step: 132  | total loss: [1m[32m0.69328[0m[0m | time: 14.166s
[2K
| RMSProp | epoch: 005 | loss: 0.69328 - acc: 0.5069 -- iter: 512/909
[A[ATraining Step: 133  | total loss: [1m[32m0.69317[0m[0m | time: 15.001s
[2K
| RMSProp | epoch: 005 | loss: 0.69317 - acc: 0.5093 -- iter: 544/909
[A[ATraining Step: 134  | total loss: [1m[32m0.69308[0m[0m | time: 15.949s
[2K
| RMSProp | epoch: 005 | loss: 0.69308 - acc: 0.5115 -- iter: 576/909
[A[ATraining Step: 135  | total loss: [1m[32m0.69261[0m[0m | time: 16.868s
[2K
| RMSProp | epoch: 005 | loss: 0.69261 - acc: 0.5260 -- iter: 608/909
[A[ATraining Step: 136  | total loss: [1m[32m0.69252[0m[0m | time: 17.824s
[2K
| RMSProp | epoch: 005 | loss: 0.69252 - acc: 0.5265 -- iter: 640/909
[A[ATraining Step: 137  | total loss: [1m[32m0.69246[0m[0m | time: 18.945s
[2K
| RMSProp | epoch: 005 | loss: 0.69246 - acc: 0.5270 -- iter: 672/909
[A[ATraining Step: 138  | total loss: [1m[32m0.69255[0m[0m | time: 19.910s
[2K
| RMSProp | epoch: 005 | loss: 0.69255 - acc: 0.5243 -- iter: 704/909
[A[ATraining Step: 139  | total loss: [1m[32m0.69223[0m[0m | time: 20.868s
[2K
| RMSProp | epoch: 005 | loss: 0.69223 - acc: 0.5312 -- iter: 736/909
[A[ATraining Step: 140  | total loss: [1m[32m0.69253[0m[0m | time: 21.938s
[2K
| RMSProp | epoch: 005 | loss: 0.69253 - acc: 0.5250 -- iter: 768/909
[A[ATraining Step: 141  | total loss: [1m[32m0.69157[0m[0m | time: 23.095s
[2K
| RMSProp | epoch: 005 | loss: 0.69157 - acc: 0.5443 -- iter: 800/909
[A[ATraining Step: 142  | total loss: [1m[32m0.69201[0m[0m | time: 23.928s
[2K
| RMSProp | epoch: 005 | loss: 0.69201 - acc: 0.5368 -- iter: 832/909
[A[ATraining Step: 143  | total loss: [1m[32m0.69179[0m[0m | time: 24.791s
[2K
| RMSProp | epoch: 005 | loss: 0.69179 - acc: 0.5394 -- iter: 864/909
[A[ATraining Step: 144  | total loss: [1m[32m0.69132[0m[0m | time: 25.673s
[2K
| RMSProp | epoch: 005 | loss: 0.69132 - acc: 0.5448 -- iter: 896/909
[A[ATraining Step: 145  | total loss: [1m[32m0.69103[0m[0m | time: 27.894s
[2K
| RMSProp | epoch: 005 | loss: 0.69103 - acc: 0.5466 | val_loss: 0.69903 - val_acc: 0.4456 -- iter: 909/909
--
Training Step: 146  | total loss: [1m[32m0.69136[0m[0m | time: 0.866s
[2K
| RMSProp | epoch: 006 | loss: 0.69136 - acc: 0.5419 -- iter: 032/909
[A[ATraining Step: 147  | total loss: [1m[32m0.69084[0m[0m | time: 1.792s
[2K
| RMSProp | epoch: 006 | loss: 0.69084 - acc: 0.5471 -- iter: 064/909
[A[ATraining Step: 148  | total loss: [1m[32m0.69052[0m[0m | time: 2.704s
[2K
| RMSProp | epoch: 006 | loss: 0.69052 - acc: 0.5486 -- iter: 096/909
[A[ATraining Step: 149  | total loss: [1m[32m0.69278[0m[0m | time: 3.108s
[2K
| RMSProp | epoch: 006 | loss: 0.69278 - acc: 0.5313 -- iter: 128/909
[A[ATraining Step: 150  | total loss: [1m[32m0.69358[0m[0m | time: 3.523s
[2K
| RMSProp | epoch: 006 | loss: 0.69358 - acc: 0.5166 -- iter: 160/909
[A[ATraining Step: 151  | total loss: [1m[32m0.69396[0m[0m | time: 4.482s
[2K
| RMSProp | epoch: 006 | loss: 0.69396 - acc: 0.5034 -- iter: 192/909
[A[ATraining Step: 152  | total loss: [1m[32m0.69398[0m[0m | time: 5.456s
[2K
| RMSProp | epoch: 006 | loss: 0.69398 - acc: 0.4968 -- iter: 224/909
[A[ATraining Step: 153  | total loss: [1m[32m0.69383[0m[0m | time: 6.333s
[2K
| RMSProp | epoch: 006 | loss: 0.69383 - acc: 0.5065 -- iter: 256/909
[A[ATraining Step: 154  | total loss: [1m[32m0.69387[0m[0m | time: 7.280s
[2K
| RMSProp | epoch: 006 | loss: 0.69387 - acc: 0.5027 -- iter: 288/909
[A[ATraining Step: 155  | total loss: [1m[32m0.69385[0m[0m | time: 8.286s
[2K
| RMSProp | epoch: 006 | loss: 0.69385 - acc: 0.4993 -- iter: 320/909
[A[ATraining Step: 156  | total loss: [1m[32m0.69379[0m[0m | time: 9.290s
[2K
| RMSProp | epoch: 006 | loss: 0.69379 - acc: 0.4963 -- iter: 352/909
[A[ATraining Step: 157  | total loss: [1m[32m0.69351[0m[0m | time: 10.257s
[2K
| RMSProp | epoch: 006 | loss: 0.69351 - acc: 0.5123 -- iter: 384/909
[A[ATraining Step: 158  | total loss: [1m[32m0.69346[0m[0m | time: 11.266s
[2K
| RMSProp | epoch: 006 | loss: 0.69346 - acc: 0.5110 -- iter: 416/909
[A[ATraining Step: 159  | total loss: [1m[32m0.69315[0m[0m | time: 12.237s
[2K
| RMSProp | epoch: 006 | loss: 0.69315 - acc: 0.5162 -- iter: 448/909
[A[ATraining Step: 160  | total loss: [1m[32m0.69268[0m[0m | time: 13.281s
[2K
| RMSProp | epoch: 006 | loss: 0.69268 - acc: 0.5239 -- iter: 480/909
[A[ATraining Step: 161  | total loss: [1m[32m0.69190[0m[0m | time: 14.294s
[2K
| RMSProp | epoch: 006 | loss: 0.69190 - acc: 0.5341 -- iter: 512/909
[A[ATraining Step: 162  | total loss: [1m[32m0.69251[0m[0m | time: 15.273s
[2K
| RMSProp | epoch: 006 | loss: 0.69251 - acc: 0.5275 -- iter: 544/909
[A[ATraining Step: 163  | total loss: [1m[32m0.69237[0m[0m | time: 16.268s
[2K
| RMSProp | epoch: 006 | loss: 0.69237 - acc: 0.5279 -- iter: 576/909
[A[ATraining Step: 164  | total loss: [1m[32m0.69085[0m[0m | time: 17.297s
[2K
| RMSProp | epoch: 006 | loss: 0.69085 - acc: 0.5470 -- iter: 608/909
[A[ATraining Step: 165  | total loss: [1m[32m0.69447[0m[0m | time: 18.308s
[2K
| RMSProp | epoch: 006 | loss: 0.69447 - acc: 0.5235 -- iter: 640/909
[A[ATraining Step: 166  | total loss: [1m[32m0.69453[0m[0m | time: 19.325s
[2K
| RMSProp | epoch: 006 | loss: 0.69453 - acc: 0.5181 -- iter: 672/909
[A[ATraining Step: 167  | total loss: [1m[32m0.69380[0m[0m | time: 20.312s
[2K
| RMSProp | epoch: 006 | loss: 0.69380 - acc: 0.5287 -- iter: 704/909
[A[ATraining Step: 168  | total loss: [1m[32m0.69398[0m[0m | time: 21.295s
[2K
| RMSProp | epoch: 006 | loss: 0.69398 - acc: 0.5227 -- iter: 736/909
[A[ATraining Step: 169  | total loss: [1m[32m0.69372[0m[0m | time: 22.305s
[2K
| RMSProp | epoch: 006 | loss: 0.69372 - acc: 0.5236 -- iter: 768/909
[A[ATraining Step: 170  | total loss: [1m[32m0.69349[0m[0m | time: 22.948s
[2K
| RMSProp | epoch: 006 | loss: 0.69349 - acc: 0.5244 -- iter: 800/909
[A[ATraining Step: 171  | total loss: [1m[32m0.69309[0m[0m | time: 23.556s
[2K
| RMSProp | epoch: 006 | loss: 0.69309 - acc: 0.5282 -- iter: 832/909
[A[ATraining Step: 172  | total loss: [1m[32m0.69204[0m[0m | time: 24.180s
[2K
| RMSProp | epoch: 006 | loss: 0.69204 - acc: 0.5410 -- iter: 864/909
[A[ATraining Step: 173  | total loss: [1m[32m0.69108[0m[0m | time: 24.817s
[2K
| RMSProp | epoch: 006 | loss: 0.69108 - acc: 0.5494 -- iter: 896/909
[A[ATraining Step: 174  | total loss: [1m[32m0.69076[0m[0m | time: 26.466s
[2K
| RMSProp | epoch: 006 | loss: 0.69076 - acc: 0.5507 | val_loss: 0.69690 - val_acc: 0.4456 -- iter: 909/909
--
Training Step: 175  | total loss: [1m[32m0.69286[0m[0m | time: 0.630s
[2K
| RMSProp | epoch: 007 | loss: 0.69286 - acc: 0.5331 -- iter: 032/909
[A[ATraining Step: 176  | total loss: [1m[32m0.69289[0m[0m | time: 1.250s
[2K
| RMSProp | epoch: 007 | loss: 0.69289 - acc: 0.5298 -- iter: 064/909
[A[ATraining Step: 177  | total loss: [1m[32m0.69315[0m[0m | time: 1.866s
[2K
| RMSProp | epoch: 007 | loss: 0.69315 - acc: 0.5237 -- iter: 096/909
[A[ATraining Step: 178  | total loss: [1m[32m0.69275[0m[0m | time: 2.478s
[2K
| RMSProp | epoch: 007 | loss: 0.69275 - acc: 0.5307 -- iter: 128/909
[A[ATraining Step: 179  | total loss: [1m[32m0.69304[0m[0m | time: 2.760s
[2K
| RMSProp | epoch: 007 | loss: 0.69304 - acc: 0.5245 -- iter: 160/909
[A[ATraining Step: 180  | total loss: [1m[32m0.69331[0m[0m | time: 3.044s
[2K
| RMSProp | epoch: 007 | loss: 0.69331 - acc: 0.5182 -- iter: 192/909
[A[ATraining Step: 181  | total loss: [1m[32m0.69343[0m[0m | time: 3.664s
[2K
| RMSProp | epoch: 007 | loss: 0.69343 - acc: 0.5126 -- iter: 224/909
[A[ATraining Step: 182  | total loss: [1m[32m0.69324[0m[0m | time: 4.302s
[2K
| RMSProp | epoch: 007 | loss: 0.69324 - acc: 0.5144 -- iter: 256/909
[A[ATraining Step: 183  | total loss: [1m[32m0.69263[0m[0m | time: 4.931s
[2K
| RMSProp | epoch: 007 | loss: 0.69263 - acc: 0.5224 -- iter: 288/909
[A[ATraining Step: 184  | total loss: [1m[32m0.69273[0m[0m | time: 5.546s
[2K
| RMSProp | epoch: 007 | loss: 0.69273 - acc: 0.5201 -- iter: 320/909
[A[ATraining Step: 185  | total loss: [1m[32m0.69227[0m[0m | time: 6.152s
[2K
| RMSProp | epoch: 007 | loss: 0.69227 - acc: 0.5244 -- iter: 352/909
[A[ATraining Step: 186  | total loss: [1m[32m0.69154[0m[0m | time: 6.753s
[2K
| RMSProp | epoch: 007 | loss: 0.69154 - acc: 0.5313 -- iter: 384/909
[A[ATraining Step: 187  | total loss: [1m[32m0.68900[0m[0m | time: 7.344s
[2K
| RMSProp | epoch: 007 | loss: 0.68900 - acc: 0.5532 -- iter: 416/909
[A[ATraining Step: 188  | total loss: [1m[32m0.69168[0m[0m | time: 7.948s
[2K
| RMSProp | epoch: 007 | loss: 0.69168 - acc: 0.5447 -- iter: 448/909
[A[ATraining Step: 189  | total loss: [1m[32m0.69164[0m[0m | time: 8.540s
[2K
| RMSProp | epoch: 007 | loss: 0.69164 - acc: 0.5434 -- iter: 480/909
[A[ATraining Step: 190  | total loss: [1m[32m0.69256[0m[0m | time: 9.146s
[2K
| RMSProp | epoch: 007 | loss: 0.69256 - acc: 0.5328 -- iter: 512/909
[A[ATraining Step: 191  | total loss: [1m[32m0.69221[0m[0m | time: 9.766s
[2K
| RMSProp | epoch: 007 | loss: 0.69221 - acc: 0.5358 -- iter: 544/909
[A[ATraining Step: 192  | total loss: [1m[32m0.69075[0m[0m | time: 10.400s
[2K
| RMSProp | epoch: 007 | loss: 0.69075 - acc: 0.5509 -- iter: 576/909
[A[ATraining Step: 193  | total loss: [1m[32m0.69164[0m[0m | time: 11.002s
[2K
| RMSProp | epoch: 007 | loss: 0.69164 - acc: 0.5427 -- iter: 608/909
[A[ATraining Step: 194  | total loss: [1m[32m0.69325[0m[0m | time: 11.630s
[2K
| RMSProp | epoch: 007 | loss: 0.69325 - acc: 0.5259 -- iter: 640/909
[A[ATraining Step: 195  | total loss: [1m[32m0.69230[0m[0m | time: 12.247s
[2K
| RMSProp | epoch: 007 | loss: 0.69230 - acc: 0.5358 -- iter: 672/909
[A[ATraining Step: 196  | total loss: [1m[32m0.69277[0m[0m | time: 12.973s
[2K
| RMSProp | epoch: 007 | loss: 0.69277 - acc: 0.5291 -- iter: 704/909
[A[ATraining Step: 197  | total loss: [1m[32m0.69223[0m[0m | time: 14.076s
[2K
| RMSProp | epoch: 007 | loss: 0.69223 - acc: 0.5325 -- iter: 736/909
[A[ATraining Step: 198  | total loss: [1m[32m0.69269[0m[0m | time: 15.132s
[2K
| RMSProp | epoch: 007 | loss: 0.69269 - acc: 0.5261 -- iter: 768/909
[A[ATraining Step: 199  | total loss: [1m[32m0.69239[0m[0m | time: 15.959s
[2K
| RMSProp | epoch: 007 | loss: 0.69239 - acc: 0.5266 -- iter: 800/909
[A[ATraining Step: 200  | total loss: [1m[32m0.69124[0m[0m | time: 18.168s
[2K
| RMSProp | epoch: 007 | loss: 0.69124 - acc: 0.5365 | val_loss: 0.70733 - val_acc: 0.4456 -- iter: 832/909
--
Training Step: 201  | total loss: [1m[32m0.68989[0m[0m | time: 19.101s
[2K
| RMSProp | epoch: 007 | loss: 0.68989 - acc: 0.5453 -- iter: 864/909
[A[ATraining Step: 202  | total loss: [1m[32m0.69292[0m[0m | time: 19.959s
[2K
| RMSProp | epoch: 007 | loss: 0.69292 - acc: 0.5283 -- iter: 896/909
[A[ATraining Step: 203  | total loss: [1m[32m0.69282[0m[0m | time: 22.405s
[2K
| RMSProp | epoch: 007 | loss: 0.69282 - acc: 0.5255 | val_loss: 0.69351 - val_acc: 0.4456 -- iter: 909/909
--
Training Step: 204  | total loss: [1m[32m0.69355[0m[0m | time: 0.935s
[2K
| RMSProp | epoch: 008 | loss: 0.69355 - acc: 0.5104 -- iter: 032/909
[A[ATraining Step: 205  | total loss: [1m[32m0.69352[0m[0m | time: 1.953s
[2K
| RMSProp | epoch: 008 | loss: 0.69352 - acc: 0.5062 -- iter: 064/909
[A[ATraining Step: 206  | total loss: [1m[32m0.69328[0m[0m | time: 2.895s
[2K
| RMSProp | epoch: 008 | loss: 0.69328 - acc: 0.5087 -- iter: 096/909
[A[ATraining Step: 207  | total loss: [1m[32m0.69296[0m[0m | time: 3.708s
[2K
| RMSProp | epoch: 008 | loss: 0.69296 - acc: 0.5141 -- iter: 128/909
[A[ATraining Step: 208  | total loss: [1m[32m0.69229[0m[0m | time: 4.811s
[2K
| RMSProp | epoch: 008 | loss: 0.69229 - acc: 0.5158 -- iter: 160/909
[A[ATraining Step: 209  | total loss: [1m[32m0.69327[0m[0m | time: 5.304s
[2K
| RMSProp | epoch: 008 | loss: 0.69327 - acc: 0.5080 -- iter: 192/909
[A[ATraining Step: 210  | total loss: [1m[32m0.69315[0m[0m | time: 5.767s
[2K
| RMSProp | epoch: 008 | loss: 0.69315 - acc: 0.5034 -- iter: 224/909
[A[ATraining Step: 211  | total loss: [1m[32m0.69267[0m[0m | time: 6.744s
[2K
| RMSProp | epoch: 008 | loss: 0.69267 - acc: 0.5146 -- iter: 256/909
[A[ATraining Step: 212  | total loss: [1m[32m0.69211[0m[0m | time: 7.545s
[2K
| RMSProp | epoch: 008 | loss: 0.69211 - acc: 0.5225 -- iter: 288/909
[A[ATraining Step: 213  | total loss: [1m[32m0.69153[0m[0m | time: 8.470s
[2K
| RMSProp | epoch: 008 | loss: 0.69153 - acc: 0.5202 -- iter: 320/909
[A[ATraining Step: 214  | total loss: [1m[32m0.69226[0m[0m | time: 9.368s
[2K
| RMSProp | epoch: 008 | loss: 0.69226 - acc: 0.5088 -- iter: 352/909
[A[ATraining Step: 215  | total loss: [1m[32m0.69203[0m[0m | time: 10.311s
[2K
| RMSProp | epoch: 008 | loss: 0.69203 - acc: 0.4954 -- iter: 384/909
[A[ATraining Step: 216  | total loss: [1m[32m0.69188[0m[0m | time: 11.263s
[2K
| RMSProp | epoch: 008 | loss: 0.69188 - acc: 0.4897 -- iter: 416/909
[A[ATraining Step: 217  | total loss: [1m[32m0.69005[0m[0m | time: 12.299s
[2K
| RMSProp | epoch: 008 | loss: 0.69005 - acc: 0.5188 -- iter: 448/909
[A[ATraining Step: 218  | total loss: [1m[32m0.68884[0m[0m | time: 13.190s
[2K
| RMSProp | epoch: 008 | loss: 0.68884 - acc: 0.5201 -- iter: 480/909
[A[ATraining Step: 219  | total loss: [1m[32m0.68774[0m[0m | time: 14.059s
[2K
| RMSProp | epoch: 008 | loss: 0.68774 - acc: 0.5180 -- iter: 512/909
[A[ATraining Step: 220  | total loss: [1m[32m0.68695[0m[0m | time: 15.076s
[2K
| RMSProp | epoch: 008 | loss: 0.68695 - acc: 0.5131 -- iter: 544/909
[A[ATraining Step: 221  | total loss: [1m[32m0.68428[0m[0m | time: 16.240s
[2K
| RMSProp | epoch: 008 | loss: 0.68428 - acc: 0.5274 -- iter: 576/909
[A[ATraining Step: 222  | total loss: [1m[32m0.67763[0m[0m | time: 16.999s
[2K
| RMSProp | epoch: 008 | loss: 0.67763 - acc: 0.5559 -- iter: 608/909
[A[ATraining Step: 223  | total loss: [1m[32m0.67833[0m[0m | time: 17.906s
[2K
| RMSProp | epoch: 008 | loss: 0.67833 - acc: 0.5597 -- iter: 640/909
[A[ATraining Step: 224  | total loss: [1m[32m0.67441[0m[0m | time: 18.861s
[2K
| RMSProp | epoch: 008 | loss: 0.67441 - acc: 0.5787 -- iter: 672/909
[A[ATraining Step: 225  | total loss: [1m[32m0.67315[0m[0m | time: 19.800s
[2K
| RMSProp | epoch: 008 | loss: 0.67315 - acc: 0.5771 -- iter: 704/909
[A[ATraining Step: 226  | total loss: [1m[32m0.67851[0m[0m | time: 20.780s
[2K
| RMSProp | epoch: 008 | loss: 0.67851 - acc: 0.5663 -- iter: 736/909
[A[ATraining Step: 227  | total loss: [1m[32m0.67393[0m[0m | time: 21.860s
[2K
| RMSProp | epoch: 008 | loss: 0.67393 - acc: 0.5878 -- iter: 768/909
[A[ATraining Step: 228  | total loss: [1m[32m0.66963[0m[0m | time: 22.730s
[2K
| RMSProp | epoch: 008 | loss: 0.66963 - acc: 0.5946 -- iter: 800/909
[A[ATraining Step: 229  | total loss: [1m[32m0.66024[0m[0m | time: 23.625s
[2K
| RMSProp | epoch: 008 | loss: 0.66024 - acc: 0.6164 -- iter: 832/909
[A[ATraining Step: 230  | total loss: [1m[32m0.65680[0m[0m | time: 24.708s
[2K
| RMSProp | epoch: 008 | loss: 0.65680 - acc: 0.6173 -- iter: 864/909
[A[ATraining Step: 231  | total loss: [1m[32m0.65218[0m[0m | time: 25.740s
[2K
| RMSProp | epoch: 008 | loss: 0.65218 - acc: 0.6212 -- iter: 896/909
[A[ATraining Step: 232  | total loss: [1m[32m0.65011[0m[0m | time: 27.766s
[2K
| RMSProp | epoch: 008 | loss: 0.65011 - acc: 0.6247 | val_loss: 0.68654 - val_acc: 0.5789 -- iter: 909/909
--
Training Step: 233  | total loss: [1m[32m0.64343[0m[0m | time: 0.976s
[2K
| RMSProp | epoch: 009 | loss: 0.64343 - acc: 0.6372 -- iter: 032/909
[A[ATraining Step: 234  | total loss: [1m[32m0.64601[0m[0m | time: 1.773s
[2K
| RMSProp | epoch: 009 | loss: 0.64601 - acc: 0.6329 -- iter: 064/909
[A[ATraining Step: 235  | total loss: [1m[32m0.65106[0m[0m | time: 2.716s
[2K
| RMSProp | epoch: 009 | loss: 0.65106 - acc: 0.6258 -- iter: 096/909
[A[ATraining Step: 236  | total loss: [1m[32m0.64558[0m[0m | time: 3.634s
[2K
| RMSProp | epoch: 009 | loss: 0.64558 - acc: 0.6382 -- iter: 128/909
[A[ATraining Step: 237  | total loss: [1m[32m0.64067[0m[0m | time: 4.510s
[2K
| RMSProp | epoch: 009 | loss: 0.64067 - acc: 0.6463 -- iter: 160/909
[A[ATraining Step: 238  | total loss: [1m[32m0.63849[0m[0m | time: 5.571s
[2K
| RMSProp | epoch: 009 | loss: 0.63849 - acc: 0.6535 -- iter: 192/909
[A[ATraining Step: 239  | total loss: [1m[32m0.63159[0m[0m | time: 6.041s
[2K
| RMSProp | epoch: 009 | loss: 0.63159 - acc: 0.6632 -- iter: 224/909
[A[ATraining Step: 240  | total loss: [1m[32m0.62038[0m[0m | time: 6.522s
[2K
| RMSProp | epoch: 009 | loss: 0.62038 - acc: 0.6738 -- iter: 256/909
[A[ATraining Step: 241  | total loss: [1m[32m0.60537[0m[0m | time: 7.385s
[2K
| RMSProp | epoch: 009 | loss: 0.60537 - acc: 0.6910 -- iter: 288/909
[A[ATraining Step: 242  | total loss: [1m[32m0.59532[0m[0m | time: 8.305s
[2K
| RMSProp | epoch: 009 | loss: 0.59532 - acc: 0.6969 -- iter: 320/909
[A[ATraining Step: 243  | total loss: [1m[32m0.62659[0m[0m | time: 9.335s
[2K
| RMSProp | epoch: 009 | loss: 0.62659 - acc: 0.6772 -- iter: 352/909
[A[ATraining Step: 244  | total loss: [1m[32m0.62406[0m[0m | time: 10.359s
[2K
| RMSProp | epoch: 009 | loss: 0.62406 - acc: 0.6751 -- iter: 384/909
[A[ATraining Step: 245  | total loss: [1m[32m0.61806[0m[0m | time: 11.124s
[2K
| RMSProp | epoch: 009 | loss: 0.61806 - acc: 0.6826 -- iter: 416/909
[A[ATraining Step: 246  | total loss: [1m[32m0.61468[0m[0m | time: 11.955s
[2K
| RMSProp | epoch: 009 | loss: 0.61468 - acc: 0.6862 -- iter: 448/909
[A[ATraining Step: 247  | total loss: [1m[32m0.61445[0m[0m | time: 12.865s
[2K
| RMSProp | epoch: 009 | loss: 0.61445 - acc: 0.6770 -- iter: 480/909
[A[ATraining Step: 248  | total loss: [1m[32m0.59905[0m[0m | time: 13.751s
[2K
| RMSProp | epoch: 009 | loss: 0.59905 - acc: 0.6999 -- iter: 512/909
[A[ATraining Step: 249  | total loss: [1m[32m0.58701[0m[0m | time: 14.665s
[2K
| RMSProp | epoch: 009 | loss: 0.58701 - acc: 0.7112 -- iter: 544/909
[A[ATraining Step: 250  | total loss: [1m[32m0.57799[0m[0m | time: 15.694s
[2K
| RMSProp | epoch: 009 | loss: 0.57799 - acc: 0.7182 -- iter: 576/909
[A[ATraining Step: 251  | total loss: [1m[32m0.58625[0m[0m | time: 16.652s
[2K
| RMSProp | epoch: 009 | loss: 0.58625 - acc: 0.7151 -- iter: 608/909
[A[ATraining Step: 252  | total loss: [1m[32m0.57745[0m[0m | time: 17.475s
[2K
| RMSProp | epoch: 009 | loss: 0.57745 - acc: 0.7217 -- iter: 640/909
[A[ATraining Step: 253  | total loss: [1m[32m0.55903[0m[0m | time: 18.519s
[2K
| RMSProp | epoch: 009 | loss: 0.55903 - acc: 0.7308 -- iter: 672/909
[A[ATraining Step: 254  | total loss: [1m[32m0.56818[0m[0m | time: 19.546s
[2K
| RMSProp | epoch: 009 | loss: 0.56818 - acc: 0.7233 -- iter: 704/909
[A[ATraining Step: 255  | total loss: [1m[32m0.56554[0m[0m | time: 20.296s
[2K
| RMSProp | epoch: 009 | loss: 0.56554 - acc: 0.7229 -- iter: 736/909
[A[ATraining Step: 256  | total loss: [1m[32m0.56129[0m[0m | time: 21.135s
[2K
| RMSProp | epoch: 009 | loss: 0.56129 - acc: 0.7193 -- iter: 768/909
[A[ATraining Step: 257  | total loss: [1m[32m0.55388[0m[0m | time: 22.008s
[2K
| RMSProp | epoch: 009 | loss: 0.55388 - acc: 0.7255 -- iter: 800/909
[A[ATraining Step: 258  | total loss: [1m[32m0.56605[0m[0m | time: 22.870s
[2K
| RMSProp | epoch: 009 | loss: 0.56605 - acc: 0.7155 -- iter: 832/909
[A[ATraining Step: 259  | total loss: [1m[32m0.55775[0m[0m | time: 23.815s
[2K
| RMSProp | epoch: 009 | loss: 0.55775 - acc: 0.7314 -- iter: 864/909
[A[ATraining Step: 260  | total loss: [1m[32m0.55828[0m[0m | time: 24.742s
[2K
| RMSProp | epoch: 009 | loss: 0.55828 - acc: 0.7239 -- iter: 896/909
[A[ATraining Step: 261  | total loss: [1m[32m0.54081[0m[0m | time: 27.020s
[2K
| RMSProp | epoch: 009 | loss: 0.54081 - acc: 0.7359 | val_loss: 0.61714 - val_acc: 0.6667 -- iter: 909/909
--
Training Step: 262  | total loss: [1m[32m0.53810[0m[0m | time: 0.851s
[2K
| RMSProp | epoch: 010 | loss: 0.53810 - acc: 0.7373 -- iter: 032/909
[A[ATraining Step: 263  | total loss: [1m[32m0.54595[0m[0m | time: 1.934s
[2K
| RMSProp | epoch: 010 | loss: 0.54595 - acc: 0.7292 -- iter: 064/909
[A[ATraining Step: 264  | total loss: [1m[32m0.54098[0m[0m | time: 2.931s
[2K
| RMSProp | epoch: 010 | loss: 0.54098 - acc: 0.7375 -- iter: 096/909
[A[ATraining Step: 265  | total loss: [1m[32m0.53415[0m[0m | time: 3.839s
[2K
| RMSProp | epoch: 010 | loss: 0.53415 - acc: 0.7419 -- iter: 128/909
[A[ATraining Step: 266  | total loss: [1m[32m0.52158[0m[0m | time: 4.675s
[2K
| RMSProp | epoch: 010 | loss: 0.52158 - acc: 0.7521 -- iter: 160/909
[A[ATraining Step: 267  | total loss: [1m[32m0.53044[0m[0m | time: 5.591s
[2K
| RMSProp | epoch: 010 | loss: 0.53044 - acc: 0.7456 -- iter: 192/909
[A[ATraining Step: 268  | total loss: [1m[32m0.54042[0m[0m | time: 6.486s
[2K
| RMSProp | epoch: 010 | loss: 0.54042 - acc: 0.7367 -- iter: 224/909
[A[ATraining Step: 269  | total loss: [1m[32m0.53419[0m[0m | time: 6.893s
[2K
| RMSProp | epoch: 010 | loss: 0.53419 - acc: 0.7474 -- iter: 256/909
[A[ATraining Step: 270  | total loss: [1m[32m0.51505[0m[0m | time: 7.303s
[2K
| RMSProp | epoch: 010 | loss: 0.51505 - acc: 0.7650 -- iter: 288/909
[A[ATraining Step: 271  | total loss: [1m[32m0.48972[0m[0m | time: 8.327s
[2K
| RMSProp | epoch: 010 | loss: 0.48972 - acc: 0.7885 -- iter: 320/909
[A[ATraining Step: 272  | total loss: [1m[32m0.47579[0m[0m | time: 9.363s
[2K
| RMSProp | epoch: 010 | loss: 0.47579 - acc: 0.7940 -- iter: 352/909
[A[ATraining Step: 273  | total loss: [1m[32m0.46530[0m[0m | time: 10.223s
[2K
| RMSProp | epoch: 010 | loss: 0.46530 - acc: 0.8021 -- iter: 384/909
[A[ATraining Step: 274  | total loss: [1m[32m0.47895[0m[0m | time: 11.160s
[2K
| RMSProp | epoch: 010 | loss: 0.47895 - acc: 0.7906 -- iter: 416/909
[A[ATraining Step: 275  | total loss: [1m[32m0.51334[0m[0m | time: 12.200s
[2K
| RMSProp | epoch: 010 | loss: 0.51334 - acc: 0.7616 -- iter: 448/909
[A[ATraining Step: 276  | total loss: [1m[32m0.49893[0m[0m | time: 13.235s
[2K
| RMSProp | epoch: 010 | loss: 0.49893 - acc: 0.7760 -- iter: 480/909
[A[ATraining Step: 277  | total loss: [1m[32m0.51169[0m[0m | time: 14.018s
[2K
| RMSProp | epoch: 010 | loss: 0.51169 - acc: 0.7578 -- iter: 512/909
[A[ATraining Step: 278  | total loss: [1m[32m0.51491[0m[0m | time: 14.956s
[2K
| RMSProp | epoch: 010 | loss: 0.51491 - acc: 0.7570 -- iter: 544/909
[A[ATraining Step: 279  | total loss: [1m[32m0.49890[0m[0m | time: 15.857s
[2K
| RMSProp | epoch: 010 | loss: 0.49890 - acc: 0.7720 -- iter: 576/909
[A[ATraining Step: 280  | total loss: [1m[32m0.48258[0m[0m | time: 16.760s
[2K
| RMSProp | epoch: 010 | loss: 0.48258 - acc: 0.7823 -- iter: 608/909
[A[ATraining Step: 281  | total loss: [1m[32m0.47541[0m[0m | time: 17.732s
[2K
| RMSProp | epoch: 010 | loss: 0.47541 - acc: 0.7822 -- iter: 640/909
[A[ATraining Step: 282  | total loss: [1m[32m0.46051[0m[0m | time: 18.767s
[2K
| RMSProp | epoch: 010 | loss: 0.46051 - acc: 0.7914 -- iter: 672/909
[A[ATraining Step: 283  | total loss: [1m[32m0.46814[0m[0m | time: 19.734s
[2K
| RMSProp | epoch: 010 | loss: 0.46814 - acc: 0.7873 -- iter: 704/909
[A[ATraining Step: 284  | total loss: [1m[32m0.46270[0m[0m | time: 20.657s
[2K
| RMSProp | epoch: 010 | loss: 0.46270 - acc: 0.7867 -- iter: 736/909
[A[ATraining Step: 285  | total loss: [1m[32m0.45097[0m[0m | time: 21.699s
[2K
| RMSProp | epoch: 010 | loss: 0.45097 - acc: 0.7986 -- iter: 768/909
[A[ATraining Step: 286  | total loss: [1m[32m0.44967[0m[0m | time: 22.747s
[2K
| RMSProp | epoch: 010 | loss: 0.44967 - acc: 0.7969 -- iter: 800/909
[A[ATraining Step: 287  | total loss: [1m[32m0.45790[0m[0m | time: 23.583s
[2K
| RMSProp | epoch: 010 | loss: 0.45790 - acc: 0.7985 -- iter: 832/909
[A[ATraining Step: 288  | total loss: [1m[32m0.45181[0m[0m | time: 24.507s
[2K
| RMSProp | epoch: 010 | loss: 0.45181 - acc: 0.8030 -- iter: 864/909
[A[ATraining Step: 289  | total loss: [1m[32m0.43016[0m[0m | time: 25.465s
[2K
| RMSProp | epoch: 010 | loss: 0.43016 - acc: 0.8164 -- iter: 896/909
[A[ATraining Step: 290  | total loss: [1m[32m0.41777[0m[0m | time: 27.814s
[2K
| RMSProp | epoch: 010 | loss: 0.41777 - acc: 0.8254 | val_loss: 0.46186 - val_acc: 0.7825 -- iter: 909/909
--
Training Step: 291  | total loss: [1m[32m0.44616[0m[0m | time: 1.060s
[2K
| RMSProp | epoch: 011 | loss: 0.44616 - acc: 0.8085 -- iter: 032/909
[A[ATraining Step: 292  | total loss: [1m[32m0.45377[0m[0m | time: 2.097s
[2K
| RMSProp | epoch: 011 | loss: 0.45377 - acc: 0.7995 -- iter: 064/909
[A[ATraining Step: 293  | total loss: [1m[32m0.45599[0m[0m | time: 2.888s
[2K
| RMSProp | epoch: 011 | loss: 0.45599 - acc: 0.7977 -- iter: 096/909
[A[ATraining Step: 294  | total loss: [1m[32m0.44859[0m[0m | time: 3.722s
[2K
| RMSProp | epoch: 011 | loss: 0.44859 - acc: 0.7992 -- iter: 128/909
[A[ATraining Step: 295  | total loss: [1m[32m0.47333[0m[0m | time: 4.644s
[2K
| RMSProp | epoch: 011 | loss: 0.47333 - acc: 0.7818 -- iter: 160/909
[A[ATraining Step: 296  | total loss: [1m[32m0.46226[0m[0m | time: 5.570s
[2K
| RMSProp | epoch: 011 | loss: 0.46226 - acc: 0.7911 -- iter: 192/909
[A[ATraining Step: 297  | total loss: [1m[32m0.44988[0m[0m | time: 6.516s
[2K
| RMSProp | epoch: 011 | loss: 0.44988 - acc: 0.7932 -- iter: 224/909
[A[ATraining Step: 298  | total loss: [1m[32m0.43904[0m[0m | time: 7.551s
[2K
| RMSProp | epoch: 011 | loss: 0.43904 - acc: 0.8014 -- iter: 256/909
[A[ATraining Step: 299  | total loss: [1m[32m0.43252[0m[0m | time: 8.001s
[2K
| RMSProp | epoch: 011 | loss: 0.43252 - acc: 0.8150 -- iter: 288/909
[A[ATraining Step: 300  | total loss: [1m[32m0.43227[0m[0m | time: 8.409s
[2K
| RMSProp | epoch: 011 | loss: 0.43227 - acc: 0.8104 -- iter: 320/909
[A[ATraining Step: 301  | total loss: [1m[32m0.41699[0m[0m | time: 9.230s
[2K
| RMSProp | epoch: 011 | loss: 0.41699 - acc: 0.8217 -- iter: 352/909
[A[ATraining Step: 302  | total loss: [1m[32m0.40307[0m[0m | time: 10.284s
[2K
| RMSProp | epoch: 011 | loss: 0.40307 - acc: 0.8333 -- iter: 384/909
[A[ATraining Step: 303  | total loss: [1m[32m0.38861[0m[0m | time: 11.358s
[2K
| RMSProp | epoch: 011 | loss: 0.38861 - acc: 0.8406 -- iter: 416/909
[A[ATraining Step: 304  | total loss: [1m[32m0.41398[0m[0m | time: 12.207s
[2K
| RMSProp | epoch: 011 | loss: 0.41398 - acc: 0.8190 -- iter: 448/909
[A[ATraining Step: 305  | total loss: [1m[32m0.42888[0m[0m | time: 13.118s
[2K
| RMSProp | epoch: 011 | loss: 0.42888 - acc: 0.8121 -- iter: 480/909
[A[ATraining Step: 306  | total loss: [1m[32m0.42212[0m[0m | time: 14.032s
[2K
| RMSProp | epoch: 011 | loss: 0.42212 - acc: 0.8184 -- iter: 512/909
[A[ATraining Step: 307  | total loss: [1m[32m0.41442[0m[0m | time: 14.911s
[2K
| RMSProp | epoch: 011 | loss: 0.41442 - acc: 0.8241 -- iter: 544/909
[A[ATraining Step: 308  | total loss: [1m[32m0.40695[0m[0m | time: 15.817s
[2K
| RMSProp | epoch: 011 | loss: 0.40695 - acc: 0.8323 -- iter: 576/909
[A[ATraining Step: 309  | total loss: [1m[32m0.38916[0m[0m | time: 16.771s
[2K
| RMSProp | epoch: 011 | loss: 0.38916 - acc: 0.8428 -- iter: 608/909
[A[ATraining Step: 310  | total loss: [1m[32m0.37352[0m[0m | time: 17.783s
[2K
| RMSProp | epoch: 011 | loss: 0.37352 - acc: 0.8460 -- iter: 640/909
[A[ATraining Step: 311  | total loss: [1m[32m0.36359[0m[0m | time: 18.695s
[2K
| RMSProp | epoch: 011 | loss: 0.36359 - acc: 0.8458 -- iter: 672/909
[A[ATraining Step: 312  | total loss: [1m[32m0.39591[0m[0m | time: 19.673s
[2K
| RMSProp | epoch: 011 | loss: 0.39591 - acc: 0.8331 -- iter: 704/909
[A[ATraining Step: 313  | total loss: [1m[32m0.38461[0m[0m | time: 20.689s
[2K
| RMSProp | epoch: 011 | loss: 0.38461 - acc: 0.8404 -- iter: 736/909
[A[ATraining Step: 314  | total loss: [1m[32m0.37449[0m[0m | time: 21.696s
[2K
| RMSProp | epoch: 011 | loss: 0.37449 - acc: 0.8439 -- iter: 768/909
[A[ATraining Step: 315  | total loss: [1m[32m0.35692[0m[0m | time: 22.449s
[2K
| RMSProp | epoch: 011 | loss: 0.35692 - acc: 0.8532 -- iter: 800/909
[A[ATraining Step: 316  | total loss: [1m[32m0.37519[0m[0m | time: 23.304s
[2K
| RMSProp | epoch: 011 | loss: 0.37519 - acc: 0.8398 -- iter: 832/909
[A[ATraining Step: 317  | total loss: [1m[32m0.38684[0m[0m | time: 24.225s
[2K
| RMSProp | epoch: 011 | loss: 0.38684 - acc: 0.8339 -- iter: 864/909
[A[ATraining Step: 318  | total loss: [1m[32m0.38527[0m[0m | time: 25.128s
[2K
| RMSProp | epoch: 011 | loss: 0.38527 - acc: 0.8287 -- iter: 896/909
[A[ATraining Step: 319  | total loss: [1m[32m0.37738[0m[0m | time: 27.462s
[2K
| RMSProp | epoch: 011 | loss: 0.37738 - acc: 0.8302 | val_loss: 0.30638 - val_acc: 0.8947 -- iter: 909/909
--
Training Step: 320  | total loss: [1m[32m0.37275[0m[0m | time: 1.059s
[2K
| RMSProp | epoch: 012 | loss: 0.37275 - acc: 0.8347 -- iter: 032/909
[A[ATraining Step: 321  | total loss: [1m[32m0.36185[0m[0m | time: 1.894s
[2K
| RMSProp | epoch: 012 | loss: 0.36185 - acc: 0.8418 -- iter: 064/909
[A[ATraining Step: 322  | total loss: [1m[32m0.35222[0m[0m | time: 2.729s
[2K
| RMSProp | epoch: 012 | loss: 0.35222 - acc: 0.8451 -- iter: 096/909
[A[ATraining Step: 323  | total loss: [1m[32m0.34976[0m[0m | time: 3.665s
[2K
| RMSProp | epoch: 012 | loss: 0.34976 - acc: 0.8481 -- iter: 128/909
[A[ATraining Step: 324  | total loss: [1m[32m0.33388[0m[0m | time: 4.590s
[2K
| RMSProp | epoch: 012 | loss: 0.33388 - acc: 0.8571 -- iter: 160/909
[A[ATraining Step: 325  | total loss: [1m[32m0.33366[0m[0m | time: 5.489s
[2K
| RMSProp | epoch: 012 | loss: 0.33366 - acc: 0.8620 -- iter: 192/909
[A[ATraining Step: 326  | total loss: [1m[32m0.32785[0m[0m | time: 6.474s
[2K
| RMSProp | epoch: 012 | loss: 0.32785 - acc: 0.8633 -- iter: 224/909
[A[ATraining Step: 327  | total loss: [1m[32m0.35027[0m[0m | time: 7.471s
[2K
| RMSProp | epoch: 012 | loss: 0.35027 - acc: 0.8551 -- iter: 256/909
[A[ATraining Step: 328  | total loss: [1m[32m0.36827[0m[0m | time: 8.300s
[2K
| RMSProp | epoch: 012 | loss: 0.36827 - acc: 0.8446 -- iter: 288/909
[A[ATraining Step: 329  | total loss: [1m[32m0.35237[0m[0m | time: 8.734s
[2K
| RMSProp | epoch: 012 | loss: 0.35237 - acc: 0.8570 -- iter: 320/909
[A[ATraining Step: 330  | total loss: [1m[32m0.32541[0m[0m | time: 9.236s
[2K
| RMSProp | epoch: 012 | loss: 0.32541 - acc: 0.8713 -- iter: 352/909
[A[ATraining Step: 331  | total loss: [1m[32m0.29771[0m[0m | time: 10.250s
[2K
| RMSProp | epoch: 012 | loss: 0.29771 - acc: 0.8842 -- iter: 384/909
[A[ATraining Step: 332  | total loss: [1m[32m0.27924[0m[0m | time: 11.250s
[2K
| RMSProp | epoch: 012 | loss: 0.27924 - acc: 0.8926 -- iter: 416/909
[A[ATraining Step: 333  | total loss: [1m[32m0.26775[0m[0m | time: 12.125s
[2K
| RMSProp | epoch: 012 | loss: 0.26775 - acc: 0.9002 -- iter: 448/909
[A[ATraining Step: 334  | total loss: [1m[32m0.27324[0m[0m | time: 13.007s
[2K
| RMSProp | epoch: 012 | loss: 0.27324 - acc: 0.9040 -- iter: 480/909
[A[ATraining Step: 335  | total loss: [1m[32m0.27693[0m[0m | time: 13.883s
[2K
| RMSProp | epoch: 012 | loss: 0.27693 - acc: 0.9011 -- iter: 512/909
[A[ATraining Step: 336  | total loss: [1m[32m0.29993[0m[0m | time: 14.784s
[2K
| RMSProp | epoch: 012 | loss: 0.29993 - acc: 0.8828 -- iter: 544/909
[A[ATraining Step: 337  | total loss: [1m[32m0.31888[0m[0m | time: 15.718s
[2K
| RMSProp | epoch: 012 | loss: 0.31888 - acc: 0.8695 -- iter: 576/909
[A[ATraining Step: 338  | total loss: [1m[32m0.31459[0m[0m | time: 16.682s
[2K
| RMSProp | epoch: 012 | loss: 0.31459 - acc: 0.8732 -- iter: 608/909
[A[ATraining Step: 339  | total loss: [1m[32m0.29918[0m[0m | time: 17.657s
[2K
| RMSProp | epoch: 012 | loss: 0.29918 - acc: 0.8828 -- iter: 640/909
[A[ATraining Step: 340  | total loss: [1m[32m0.29031[0m[0m | time: 18.562s
[2K
| RMSProp | epoch: 012 | loss: 0.29031 - acc: 0.8882 -- iter: 672/909
[A[ATraining Step: 341  | total loss: [1m[32m0.28246[0m[0m | time: 19.771s
[2K
| RMSProp | epoch: 012 | loss: 0.28246 - acc: 0.8932 -- iter: 704/909
[A[ATraining Step: 342  | total loss: [1m[32m0.26405[0m[0m | time: 21.024s
[2K
| RMSProp | epoch: 012 | loss: 0.26405 - acc: 0.9039 -- iter: 736/909
[A[ATraining Step: 343  | total loss: [1m[32m0.25773[0m[0m | time: 22.417s
[2K
| RMSProp | epoch: 012 | loss: 0.25773 - acc: 0.9072 -- iter: 768/909
[A[ATraining Step: 344  | total loss: [1m[32m0.30086[0m[0m | time: 25.123s
[2K
| RMSProp | epoch: 012 | loss: 0.30086 - acc: 0.8821 -- iter: 800/909
[A[ATraining Step: 345  | total loss: [1m[32m0.31098[0m[0m | time: 26.977s
[2K
| RMSProp | epoch: 012 | loss: 0.31098 - acc: 0.8783 -- iter: 832/909
[A[ATraining Step: 346  | total loss: [1m[32m0.33273[0m[0m | time: 28.237s
[2K
| RMSProp | epoch: 012 | loss: 0.33273 - acc: 0.8623 -- iter: 864/909
[A[ATraining Step: 347  | total loss: [1m[32m0.32362[0m[0m | time: 29.315s
[2K
| RMSProp | epoch: 012 | loss: 0.32362 - acc: 0.8667 -- iter: 896/909
[A[ATraining Step: 348  | total loss: [1m[32m0.32163[0m[0m | time: 32.466s
[2K
| RMSProp | epoch: 012 | loss: 0.32163 - acc: 0.8676 | val_loss: 0.36095 - val_acc: 0.8561 -- iter: 909/909
--
Training Step: 349  | total loss: [1m[32m0.33408[0m[0m | time: 1.452s
[2K
| RMSProp | epoch: 013 | loss: 0.33408 - acc: 0.8652 -- iter: 032/909
[A[ATraining Step: 350  | total loss: [1m[32m0.33718[0m[0m | time: 2.678s
[2K
| RMSProp | epoch: 013 | loss: 0.33718 - acc: 0.8568 -- iter: 064/909
[A[ATraining Step: 351  | total loss: [1m[32m0.32983[0m[0m | time: 3.798s
[2K
| RMSProp | epoch: 013 | loss: 0.32983 - acc: 0.8617 -- iter: 096/909
[A[ATraining Step: 352  | total loss: [1m[32m0.32611[0m[0m | time: 4.870s
[2K
| RMSProp | epoch: 013 | loss: 0.32611 - acc: 0.8631 -- iter: 128/909
[A[ATraining Step: 353  | total loss: [1m[32m0.32093[0m[0m | time: 6.143s
[2K
| RMSProp | epoch: 013 | loss: 0.32093 - acc: 0.8674 -- iter: 160/909
[A[ATraining Step: 354  | total loss: [1m[32m0.31285[0m[0m | time: 7.337s
[2K
| RMSProp | epoch: 013 | loss: 0.31285 - acc: 0.8713 -- iter: 192/909
[A[ATraining Step: 355  | total loss: [1m[32m0.28844[0m[0m | time: 8.727s
[2K
| RMSProp | epoch: 013 | loss: 0.28844 - acc: 0.8841 -- iter: 224/909
[A[ATraining Step: 356  | total loss: [1m[32m0.28576[0m[0m | time: 9.962s
[2K
| RMSProp | epoch: 013 | loss: 0.28576 - acc: 0.8832 -- iter: 256/909
[A[ATraining Step: 357  | total loss: [1m[32m0.31055[0m[0m | time: 11.146s
[2K
| RMSProp | epoch: 013 | loss: 0.31055 - acc: 0.8668 -- iter: 288/909
[A[ATraining Step: 358  | total loss: [1m[32m0.31033[0m[0m | time: 12.372s
[2K
| RMSProp | epoch: 013 | loss: 0.31033 - acc: 0.8645 -- iter: 320/909
[A[ATraining Step: 359  | total loss: [1m[32m0.30031[0m[0m | time: 12.943s
[2K
| RMSProp | epoch: 013 | loss: 0.30031 - acc: 0.8749 -- iter: 352/909
[A[ATraining Step: 360  | total loss: [1m[32m0.30554[0m[0m | time: 13.567s
[2K
| RMSProp | epoch: 013 | loss: 0.30554 - acc: 0.8797 -- iter: 384/909
[A[ATraining Step: 361  | total loss: [1m[32m0.29726[0m[0m | time: 14.976s
[2K
| RMSProp | epoch: 013 | loss: 0.29726 - acc: 0.8841 -- iter: 416/909
[A[ATraining Step: 362  | total loss: [1m[32m0.30533[0m[0m | time: 16.390s
[2K
| RMSProp | epoch: 013 | loss: 0.30533 - acc: 0.8769 -- iter: 448/909
[A[ATraining Step: 363  | total loss: [1m[32m0.31504[0m[0m | time: 17.618s
[2K
| RMSProp | epoch: 013 | loss: 0.31504 - acc: 0.8705 -- iter: 480/909
[A[ATraining Step: 364  | total loss: [1m[32m0.31749[0m[0m | time: 18.906s
[2K
| RMSProp | epoch: 013 | loss: 0.31749 - acc: 0.8709 -- iter: 512/909
[A[ATraining Step: 365  | total loss: [1m[32m0.31287[0m[0m | time: 20.183s
[2K
| RMSProp | epoch: 013 | loss: 0.31287 - acc: 0.8713 -- iter: 544/909
[A[ATraining Step: 366  | total loss: [1m[32m0.31568[0m[0m | time: 21.510s
[2K
| RMSProp | epoch: 013 | loss: 0.31568 - acc: 0.8748 -- iter: 576/909
[A[ATraining Step: 367  | total loss: [1m[32m0.29813[0m[0m | time: 22.867s
[2K
| RMSProp | epoch: 013 | loss: 0.29813 - acc: 0.8842 -- iter: 608/909
[A[ATraining Step: 368  | total loss: [1m[32m0.29612[0m[0m | time: 24.078s
[2K
| RMSProp | epoch: 013 | loss: 0.29612 - acc: 0.8864 -- iter: 640/909
[A[ATraining Step: 369  | total loss: [1m[32m0.28376[0m[0m | time: 25.316s
[2K
| RMSProp | epoch: 013 | loss: 0.28376 - acc: 0.8915 -- iter: 672/909
[A[ATraining Step: 370  | total loss: [1m[32m0.26663[0m[0m | time: 26.702s
[2K
| RMSProp | epoch: 013 | loss: 0.26663 - acc: 0.8992 -- iter: 704/909
[A[ATraining Step: 371  | total loss: [1m[32m0.27028[0m[0m | time: 27.903s
[2K
| RMSProp | epoch: 013 | loss: 0.27028 - acc: 0.8968 -- iter: 736/909
[A[ATraining Step: 372  | total loss: [1m[32m0.25877[0m[0m | time: 29.077s
[2K
| RMSProp | epoch: 013 | loss: 0.25877 - acc: 0.9040 -- iter: 768/909
[A[ATraining Step: 373  | total loss: [1m[32m0.25437[0m[0m | time: 30.330s
[2K
| RMSProp | epoch: 013 | loss: 0.25437 - acc: 0.9042 -- iter: 800/909
[A[ATraining Step: 374  | total loss: [1m[32m0.29799[0m[0m | time: 31.654s
[2K
| RMSProp | epoch: 013 | loss: 0.29799 - acc: 0.8857 -- iter: 832/909
[A[ATraining Step: 375  | total loss: [1m[32m0.30116[0m[0m | time: 33.018s
[2K
| RMSProp | epoch: 013 | loss: 0.30116 - acc: 0.8877 -- iter: 864/909
[A[ATraining Step: 376  | total loss: [1m[32m0.30152[0m[0m | time: 34.233s
[2K
| RMSProp | epoch: 013 | loss: 0.30152 - acc: 0.8896 -- iter: 896/909
[A[ATraining Step: 377  | total loss: [1m[32m0.28623[0m[0m | time: 37.480s
[2K
| RMSProp | epoch: 013 | loss: 0.28623 - acc: 0.8975 | val_loss: 0.26818 - val_acc: 0.9053 -- iter: 909/909
--
Training Step: 378  | total loss: [1m[32m0.26522[0m[0m | time: 4.498s
[2K
| RMSProp | epoch: 014 | loss: 0.26522 - acc: 0.9078 -- iter: 032/909
[A[ATraining Step: 379  | total loss: [1m[32m0.24545[0m[0m | time: 5.717s
[2K
| RMSProp | epoch: 014 | loss: 0.24545 - acc: 0.9170 -- iter: 064/909
[A[ATraining Step: 380  | total loss: [1m[32m0.24919[0m[0m | time: 7.015s
[2K
| RMSProp | epoch: 014 | loss: 0.24919 - acc: 0.9128 -- iter: 096/909
[A[ATraining Step: 381  | total loss: [1m[32m0.25294[0m[0m | time: 8.357s
[2K
| RMSProp | epoch: 014 | loss: 0.25294 - acc: 0.9121 -- iter: 128/909
[A[ATraining Step: 382  | total loss: [1m[32m0.27561[0m[0m | time: 9.768s
[2K
| RMSProp | epoch: 014 | loss: 0.27561 - acc: 0.8990 -- iter: 160/909
[A[ATraining Step: 383  | total loss: [1m[32m0.26498[0m[0m | time: 11.295s
[2K
| RMSProp | epoch: 014 | loss: 0.26498 - acc: 0.9029 -- iter: 192/909
[A[ATraining Step: 384  | total loss: [1m[32m0.25680[0m[0m | time: 12.662s
[2K
| RMSProp | epoch: 014 | loss: 0.25680 - acc: 0.9063 -- iter: 224/909
[A[ATraining Step: 385  | total loss: [1m[32m0.24880[0m[0m | time: 13.855s
[2K
| RMSProp | epoch: 014 | loss: 0.24880 - acc: 0.9126 -- iter: 256/909
[A[ATraining Step: 386  | total loss: [1m[32m0.27696[0m[0m | time: 15.154s
[2K
| RMSProp | epoch: 014 | loss: 0.27696 - acc: 0.8995 -- iter: 288/909
[A[ATraining Step: 387  | total loss: [1m[32m0.29985[0m[0m | time: 16.493s
[2K
| RMSProp | epoch: 014 | loss: 0.29985 - acc: 0.8876 -- iter: 320/909
[A[ATraining Step: 388  | total loss: [1m[32m0.31757[0m[0m | time: 17.676s
[2K
| RMSProp | epoch: 014 | loss: 0.31757 - acc: 0.8832 -- iter: 352/909
[A[ATraining Step: 389  | total loss: [1m[32m0.30911[0m[0m | time: 18.219s
[2K
| RMSProp | epoch: 014 | loss: 0.30911 - acc: 0.8918 -- iter: 384/909
[A[ATraining Step: 390  | total loss: [1m[32m0.31708[0m[0m | time: 18.885s
[2K
| RMSProp | epoch: 014 | loss: 0.31708 - acc: 0.8949 -- iter: 416/909
[A[ATraining Step: 391  | total loss: [1m[32m0.31789[0m[0m | time: 20.519s
[2K
| RMSProp | epoch: 014 | loss: 0.31789 - acc: 0.8977 -- iter: 448/909
[A[ATraining Step: 392  | total loss: [1m[32m0.29792[0m[0m | time: 21.641s
[2K
| RMSProp | epoch: 014 | loss: 0.29792 - acc: 0.9048 -- iter: 480/909
[A[ATraining Step: 393  | total loss: [1m[32m0.27856[0m[0m | time: 22.862s
[2K
| RMSProp | epoch: 014 | loss: 0.27856 - acc: 0.9112 -- iter: 512/909
[A[ATraining Step: 394  | total loss: [1m[32m0.26573[0m[0m | time: 24.182s
[2K
| RMSProp | epoch: 014 | loss: 0.26573 - acc: 0.9139 -- iter: 544/909
[A[ATraining Step: 395  | total loss: [1m[32m0.28795[0m[0m | time: 25.559s
[2K
| RMSProp | epoch: 014 | loss: 0.28795 - acc: 0.9100 -- iter: 576/909
[A[ATraining Step: 396  | total loss: [1m[32m0.33531[0m[0m | time: 26.991s
[2K
| RMSProp | epoch: 014 | loss: 0.33531 - acc: 0.8815 -- iter: 608/909
[A[ATraining Step: 397  | total loss: [1m[32m0.32536[0m[0m | time: 28.444s
[2K
| RMSProp | epoch: 014 | loss: 0.32536 - acc: 0.8840 -- iter: 640/909
[A[ATraining Step: 398  | total loss: [1m[32m0.30709[0m[0m | time: 29.763s
[2K
| RMSProp | epoch: 014 | loss: 0.30709 - acc: 0.8893 -- iter: 672/909
[A[ATraining Step: 399  | total loss: [1m[32m0.30802[0m[0m | time: 30.992s
[2K
| RMSProp | epoch: 014 | loss: 0.30802 - acc: 0.8848 -- iter: 704/909
[A[ATraining Step: 400  | total loss: [1m[32m0.31409[0m[0m | time: 35.117s
[2K
| RMSProp | epoch: 014 | loss: 0.31409 - acc: 0.8807 | val_loss: 0.24991 - val_acc: 0.9158 -- iter: 736/909
--
Training Step: 401  | total loss: [1m[32m0.31348[0m[0m | time: 36.243s
[2K
| RMSProp | epoch: 014 | loss: 0.31348 - acc: 0.8770 -- iter: 768/909
[A[ATraining Step: 402  | total loss: [1m[32m0.30601[0m[0m | time: 37.430s
[2K
| RMSProp | epoch: 014 | loss: 0.30601 - acc: 0.8799 -- iter: 800/909
[A[ATraining Step: 403  | total loss: [1m[32m0.30860[0m[0m | time: 38.827s
[2K
| RMSProp | epoch: 014 | loss: 0.30860 - acc: 0.8794 -- iter: 832/909
[A[ATraining Step: 404  | total loss: [1m[32m0.30468[0m[0m | time: 40.144s
[2K
| RMSProp | epoch: 014 | loss: 0.30468 - acc: 0.8821 -- iter: 864/909
[A[ATraining Step: 405  | total loss: [1m[32m0.29587[0m[0m | time: 41.552s
[2K
| RMSProp | epoch: 014 | loss: 0.29587 - acc: 0.8876 -- iter: 896/909
[A[ATraining Step: 406  | total loss: [1m[32m0.29098[0m[0m | time: 44.719s
[2K
| RMSProp | epoch: 014 | loss: 0.29098 - acc: 0.8926 | val_loss: 0.47752 - val_acc: 0.7614 -- iter: 909/909
--
Training Step: 407  | total loss: [1m[32m0.28499[0m[0m | time: 1.260s
[2K
| RMSProp | epoch: 015 | loss: 0.28499 - acc: 0.8940 -- iter: 032/909
[A[ATraining Step: 408  | total loss: [1m[32m0.29753[0m[0m | time: 2.713s
[2K
| RMSProp | epoch: 015 | loss: 0.29753 - acc: 0.8827 -- iter: 064/909
[A[ATraining Step: 409  | total loss: [1m[32m0.30677[0m[0m | time: 3.710s
[2K
| RMSProp | epoch: 015 | loss: 0.30677 - acc: 0.8819 -- iter: 096/909
[A[ATraining Step: 410  | total loss: [1m[32m0.29860[0m[0m | time: 4.990s
[2K
| RMSProp | epoch: 015 | loss: 0.29860 - acc: 0.8844 -- iter: 128/909
[A[ATraining Step: 411  | total loss: [1m[32m0.28796[0m[0m | time: 6.318s
[2K
| RMSProp | epoch: 015 | loss: 0.28796 - acc: 0.8928 -- iter: 160/909
[A[ATraining Step: 412  | total loss: [1m[32m0.28488[0m[0m | time: 7.673s
[2K
| RMSProp | epoch: 015 | loss: 0.28488 - acc: 0.8973 -- iter: 192/909
[A[ATraining Step: 413  | total loss: [1m[32m0.26863[0m[0m | time: 9.088s
[2K
| RMSProp | epoch: 015 | loss: 0.26863 - acc: 0.9075 -- iter: 224/909
[A[ATraining Step: 414  | total loss: [1m[32m0.25525[0m[0m | time: 10.502s
[2K
| RMSProp | epoch: 015 | loss: 0.25525 - acc: 0.9105 -- iter: 256/909
[A[ATraining Step: 415  | total loss: [1m[32m0.31680[0m[0m | time: 11.650s
[2K
| RMSProp | epoch: 015 | loss: 0.31680 - acc: 0.8945 -- iter: 288/909
[A[ATraining Step: 416  | total loss: [1m[32m0.30218[0m[0m | time: 12.923s
[2K
| RMSProp | epoch: 015 | loss: 0.30218 - acc: 0.8988 -- iter: 320/909
[A[ATraining Step: 417  | total loss: [1m[32m0.29561[0m[0m | time: 14.260s
[2K
| RMSProp | epoch: 015 | loss: 0.29561 - acc: 0.9027 -- iter: 352/909
[A[ATraining Step: 418  | total loss: [1m[32m0.42497[0m[0m | time: 15.708s
[2K
| RMSProp | epoch: 015 | loss: 0.42497 - acc: 0.8593 -- iter: 384/909
[A[ATraining Step: 419  | total loss: [1m[32m0.41311[0m[0m | time: 16.325s
[2K
| RMSProp | epoch: 015 | loss: 0.41311 - acc: 0.8608 -- iter: 416/909
[A[ATraining Step: 420  | total loss: [1m[32m0.38859[0m[0m | time: 17.149s
[2K
| RMSProp | epoch: 015 | loss: 0.38859 - acc: 0.8748 -- iter: 448/909
[A[ATraining Step: 421  | total loss: [1m[32m0.35887[0m[0m | time: 19.062s
[2K
| RMSProp | epoch: 015 | loss: 0.35887 - acc: 0.8873 -- iter: 480/909
[A[ATraining Step: 422  | total loss: [1m[32m0.34990[0m[0m | time: 20.287s
[2K
| RMSProp | epoch: 015 | loss: 0.34990 - acc: 0.8923 -- iter: 512/909
[A[ATraining Step: 423  | total loss: [1m[32m0.32491[0m[0m | time: 21.557s
[2K
| RMSProp | epoch: 015 | loss: 0.32491 - acc: 0.8999 -- iter: 544/909
[A[ATraining Step: 424  | total loss: [1m[32m0.30756[0m[0m | time: 22.905s
[2K
| RMSProp | epoch: 015 | loss: 0.30756 - acc: 0.9037 -- iter: 576/909
[A[ATraining Step: 425  | total loss: [1m[32m0.29011[0m[0m | time: 24.144s
[2K
| RMSProp | epoch: 015 | loss: 0.29011 - acc: 0.9071 -- iter: 608/909
[A[ATraining Step: 426  | total loss: [1m[32m0.27714[0m[0m | time: 25.461s
[2K
| RMSProp | epoch: 015 | loss: 0.27714 - acc: 0.9133 -- iter: 640/909
[A[ATraining Step: 427  | total loss: [1m[32m0.26770[0m[0m | time: 27.012s
[2K
| RMSProp | epoch: 015 | loss: 0.26770 - acc: 0.9094 -- iter: 672/909
[A[ATraining Step: 428  | total loss: [1m[32m0.24523[0m[0m | time: 28.449s
[2K
| RMSProp | epoch: 015 | loss: 0.24523 - acc: 0.9185 -- iter: 704/909
[A[ATraining Step: 429  | total loss: [1m[32m0.24368[0m[0m | time: 29.677s
[2K
| RMSProp | epoch: 015 | loss: 0.24368 - acc: 0.9173 -- iter: 736/909
[A[ATraining Step: 430  | total loss: [1m[32m0.36235[0m[0m | time: 30.843s
[2K
| RMSProp | epoch: 015 | loss: 0.36235 - acc: 0.8724 -- iter: 768/909
[A[ATraining Step: 431  | total loss: [1m[32m0.33723[0m[0m | time: 32.219s
[2K
| RMSProp | epoch: 015 | loss: 0.33723 - acc: 0.8852 -- iter: 800/909
[A[ATraining Step: 432  | total loss: [1m[32m0.31656[0m[0m | time: 33.547s
[2K
| RMSProp | epoch: 015 | loss: 0.31656 - acc: 0.8935 -- iter: 832/909
[A[ATraining Step: 433  | total loss: [1m[32m0.30666[0m[0m | time: 34.612s
[2K
| RMSProp | epoch: 015 | loss: 0.30666 - acc: 0.8979 -- iter: 864/909
[A[ATraining Step: 434  | total loss: [1m[32m0.30493[0m[0m | time: 35.841s
[2K
| RMSProp | epoch: 015 | loss: 0.30493 - acc: 0.8956 -- iter: 896/909
[A[ATraining Step: 435  | total loss: [1m[32m0.28881[0m[0m | time: 38.943s
[2K
| RMSProp | epoch: 015 | loss: 0.28881 - acc: 0.8998 | val_loss: 0.46003 - val_acc: 0.7684 -- iter: 909/909
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9592345260639888
Validation AUPRC:0.9397833369500481
Test AUC:0.964324430866266
Test AUPRC:0.913271324568999
BestTestF1Score	0.94	0.88	0.94	0.94	0.94	131	9	137	8	0.09
BestTestMCCScore	0.94	0.88	0.94	0.94	0.94	131	9	137	8	0.09
BestTestAccuracyScore	0.94	0.88	0.94	0.94	0.94	131	9	137	8	0.09
BestValidationF1Score	0.93	0.85	0.93	0.92	0.95	150	13	114	8	0.09
BestValidationMCC	0.93	0.85	0.93	0.92	0.95	150	13	114	8	0.09
BestValidationAccuracy	0.93	0.85	0.93	0.92	0.95	150	13	114	8	0.09
TestPredictions (Threshold:0.09)
CHEMBL302150,TN,INACT,0.019999999552965164	CHEMBL267986,TP,ACT,0.15000000596046448	CHEMBL169459,TN,INACT,0.019999999552965164	CHEMBL1091790,TN,INACT,0.009999999776482582	CHEMBL317064,TP,ACT,0.550000011920929	CHEMBL2371514,TP,ACT,0.9399999976158142	CHEMBL512893,TN,INACT,0.009999999776482582	CHEMBL115425,TP,ACT,0.8199999928474426	CHEMBL558364,TN,INACT,0.019999999552965164	CHEMBL1258999,TN,INACT,0.0	CHEMBL473807,TP,ACT,0.5799999833106995	CHEMBL311455,TN,INACT,0.0	CHEMBL147537,TP,ACT,0.550000011920929	CHEMBL262787,TN,INACT,0.029999999329447746	CHEMBL262160,TP,ACT,0.5600000023841858	CHEMBL217002,TN,INACT,0.0	CHEMBL3394007,TN,INACT,0.009999999776482582	CHEMBL2113072,TN,INACT,0.0	CHEMBL132179,FP,INACT,0.27000001072883606	CHEMBL45597,TP,ACT,0.949999988079071	CHEMBL3393993,TN,INACT,0.009999999776482582	CHEMBL173059,TN,INACT,0.0	CHEMBL3740042,TN,INACT,0.0	CHEMBL593861,TN,INACT,0.009999999776482582	CHEMBL276217,TP,ACT,0.6700000166893005	CHEMBL459659,TP,ACT,0.75	CHEMBL189192,TN,INACT,0.0	CHEMBL232356,TP,ACT,0.10000000149011612	CHEMBL183430,TP,ACT,0.5	CHEMBL284969,TN,INACT,0.0	CHEMBL412681,TP,ACT,0.7900000214576721	CHEMBL135988,TN,INACT,0.009999999776482582	CHEMBL2158005,TN,INACT,0.0	CHEMBL359370,TP,ACT,0.18000000715255737	CHEMBL299538,TN,INACT,0.0	CHEMBL1791272,FP,INACT,0.8700000047683716	CHEMBL326606,TP,ACT,0.10999999940395355	CHEMBL312372,TN,INACT,0.0	CHEMBL233501,TN,INACT,0.009999999776482582	CHEMBL307034,TN,INACT,0.0	CHEMBL109926,TN,INACT,0.009999999776482582	CHEMBL322678,TN,INACT,0.0	CHEMBL269583,TP,ACT,0.9200000166893005	CHEMBL2371508,TP,ACT,0.7699999809265137	CHEMBL11370,TP,ACT,0.5299999713897705	CHEMBL228686,TN,INACT,0.0	CHEMBL42411,TN,INACT,0.009999999776482582	CHEMBL11149,TP,ACT,0.9399999976158142	CHEMBL68738,TN,INACT,0.0	CHEMBL1765671,TN,INACT,0.019999999552965164	CHEMBL392401,TN,INACT,0.0	CHEMBL2371559,TP,ACT,0.9599999785423279	CHEMBL312266,TN,INACT,0.0	CHEMBL272873,TN,INACT,0.0	CHEMBL265240,TP,ACT,0.9200000166893005	CHEMBL407023,FN,ACT,0.03999999910593033	CHEMBL324685,TN,INACT,0.009999999776482582	CHEMBL413062,TP,ACT,0.49000000953674316	CHEMBL633,TN,INACT,0.009999999776482582	CHEMBL2371470,TP,ACT,0.15000000596046448	CHEMBL3665443,TN,INACT,0.009999999776482582	CHEMBL553155,TN,INACT,0.0	CHEMBL62716,TN,INACT,0.0	CHEMBL2163919,TN,INACT,0.05999999865889549	CHEMBL2443002,TN,INACT,0.0	CHEMBL2093084,TN,INACT,0.0	CHEMBL199186,TN,INACT,0.0	CHEMBL80532,TN,INACT,0.0	CHEMBL89501,FN,ACT,0.07999999821186066	CHEMBL10808,TN,INACT,0.019999999552965164	CHEMBL294910,TP,ACT,0.5199999809265137	CHEMBL282426,TN,INACT,0.009999999776482582	CHEMBL527880,TN,INACT,0.0	CHEMBL10941,TP,ACT,0.6899999976158142	CHEMBL148571,TP,ACT,0.8899999856948853	CHEMBL168855,TN,INACT,0.029999999329447746	CHEMBL265010,TP,ACT,0.27000001072883606	CHEMBL431344,TP,ACT,0.23000000417232513	CHEMBL410382,TP,ACT,0.5099999904632568	CHEMBL109478,TN,INACT,0.009999999776482582	CHEMBL183779,TP,ACT,0.47999998927116394	CHEMBL415608,TP,ACT,0.9200000166893005	CHEMBL241514,TN,INACT,0.0	CHEMBL2371577,TP,ACT,0.7099999785423279	CHEMBL50035,TP,ACT,0.10999999940395355	CHEMBL11101,TP,ACT,0.8899999856948853	CHEMBL2371575,TP,ACT,0.9200000166893005	CHEMBL3410301,TN,INACT,0.0	CHEMBL436683,TP,ACT,0.9300000071525574	CHEMBL168372,TN,INACT,0.009999999776482582	CHEMBL594802,TN,INACT,0.009999999776482582	CHEMBL404557,TN,INACT,0.0	CHEMBL395225,TP,ACT,0.8899999856948853	CHEMBL172788,TN,INACT,0.009999999776482582	CHEMBL167335,TN,INACT,0.0	CHEMBL202861,TN,INACT,0.05999999865889549	CHEMBL205768,FP,INACT,0.09000000357627869	CHEMBL151619,TN,INACT,0.009999999776482582	CHEMBL148245,TP,ACT,0.6200000047683716	CHEMBL438915,FP,INACT,0.9800000190734863	CHEMBL116246,TP,ACT,0.10000000149011612	CHEMBL308414,TN,INACT,0.009999999776482582	CHEMBL149196,TP,ACT,0.36000001430511475	CHEMBL141048,TN,INACT,0.0	CHEMBL272853,TN,INACT,0.0	CHEMBL440436,TP,ACT,0.27000001072883606	CHEMBL399779,TP,ACT,0.7699999809265137	CHEMBL416285,TP,ACT,0.9300000071525574	CHEMBL436657,TP,ACT,0.9300000071525574	CHEMBL3143400,TN,INACT,0.05999999865889549	CHEMBL611496,TN,INACT,0.0	CHEMBL120834,TP,ACT,0.550000011920929	CHEMBL329807,TP,ACT,0.7200000286102295	CHEMBL62660,TN,INACT,0.0	CHEMBL2372076,TN,INACT,0.03999999910593033	CHEMBL409990,TP,ACT,0.9399999976158142	CHEMBL405265,TP,ACT,0.9100000262260437	CHEMBL553666,TN,INACT,0.0	CHEMBL44463,TN,INACT,0.0	CHEMBL1765670,TN,INACT,0.019999999552965164	CHEMBL1800159,FN,ACT,0.05000000074505806	CHEMBL412802,TP,ACT,0.4399999976158142	CHEMBL536800,TN,INACT,0.05999999865889549	CHEMBL2371486,TP,ACT,0.9399999976158142	CHEMBL104994,TN,INACT,0.0	CHEMBL408737,TP,ACT,0.5699999928474426	CHEMBL345951,TN,INACT,0.0	CHEMBL313184,TN,INACT,0.0	CHEMBL411806,TP,ACT,0.7200000286102295	CHEMBL160396,TN,INACT,0.0	CHEMBL273725,TP,ACT,0.6100000143051147	CHEMBL146678,TP,ACT,0.17000000178813934	CHEMBL89041,TP,ACT,0.09000000357627869	CHEMBL149592,TN,INACT,0.0	CHEMBL314147,FN,ACT,0.009999999776482582	CHEMBL233552,TN,INACT,0.009999999776482582	CHEMBL209121,TN,INACT,0.009999999776482582	CHEMBL327323,TP,ACT,0.20000000298023224	CHEMBL2371591,TP,ACT,0.7599999904632568	CHEMBL364510,TP,ACT,0.49000000953674316	CHEMBL1346,TN,INACT,0.009999999776482582	CHEMBL2371581,TP,ACT,0.8999999761581421	CHEMBL106359,TN,INACT,0.009999999776482582	CHEMBL307326,TN,INACT,0.009999999776482582	CHEMBL545363,TN,INACT,0.0	CHEMBL89086,TP,ACT,0.3799999952316284	CHEMBL430344,TP,ACT,0.20000000298023224	CHEMBL2371274,TP,ACT,0.4000000059604645	CHEMBL267838,FN,ACT,0.07999999821186066	CHEMBL392843,TP,ACT,0.5799999833106995	CHEMBL296927,TN,INACT,0.009999999776482582	CHEMBL197159,TN,INACT,0.0	CHEMBL2371568,TP,ACT,0.9599999785423279	CHEMBL423918,TN,INACT,0.009999999776482582	CHEMBL7441,TN,INACT,0.0	CHEMBL327528,TP,ACT,0.36000001430511475	CHEMBL60435,TN,INACT,0.0	CHEMBL42592,TP,ACT,0.949999988079071	CHEMBL145840,TP,ACT,0.5899999737739563	CHEMBL62703,TN,INACT,0.0	CHEMBL273642,FP,INACT,0.1899999976158142	CHEMBL1923416,TN,INACT,0.009999999776482582	CHEMBL310425,TN,INACT,0.0	CHEMBL168223,TN,INACT,0.0	CHEMBL368511,FN,ACT,0.05000000074505806	CHEMBL89672,FN,ACT,0.019999999552965164	CHEMBL74515,TN,INACT,0.009999999776482582	CHEMBL541424,TN,INACT,0.009999999776482582	CHEMBL368629,TN,INACT,0.05999999865889549	CHEMBL298074,TP,ACT,0.949999988079071	CHEMBL516334,TN,INACT,0.0	CHEMBL302027,TN,INACT,0.009999999776482582	CHEMBL143341,TN,INACT,0.009999999776482582	CHEMBL438191,TP,ACT,0.8700000047683716	CHEMBL103731,TN,INACT,0.009999999776482582	CHEMBL1092626,TP,ACT,0.5799999833106995	CHEMBL414468,TP,ACT,0.9599999785423279	CHEMBL283941,TN,INACT,0.0	CHEMBL150041,TP,ACT,0.1899999976158142	CHEMBL249982,TP,ACT,0.699999988079071	CHEMBL268479,TP,ACT,0.699999988079071	CHEMBL11623,TP,ACT,0.10999999940395355	CHEMBL88506,TN,INACT,0.009999999776482582	CHEMBL1170027,FP,INACT,0.8700000047683716	CHEMBL319924,TN,INACT,0.0	CHEMBL372316,TP,ACT,0.3400000035762787	CHEMBL493167,TP,ACT,0.38999998569488525	CHEMBL407589,TP,ACT,0.9200000166893005	CHEMBL3633665,TN,INACT,0.019999999552965164	CHEMBL74342,TN,INACT,0.019999999552965164	CHEMBL149062,TP,ACT,0.9200000166893005	CHEMBL411963,TP,ACT,0.9300000071525574	CHEMBL196337,TP,ACT,0.49000000953674316	CHEMBL241082,TN,INACT,0.009999999776482582	CHEMBL49893,TP,ACT,0.9399999976158142	CHEMBL435334,TP,ACT,0.17000000178813934	CHEMBL175228,TN,INACT,0.009999999776482582	CHEMBL340934,TP,ACT,0.18000000715255737	CHEMBL595022,TN,INACT,0.009999999776482582	CHEMBL301802,TP,ACT,0.8899999856948853	CHEMBL11253,TP,ACT,0.8899999856948853	CHEMBL316792,TN,INACT,0.009999999776482582	CHEMBL358126,TP,ACT,0.8600000143051147	CHEMBL86609,TP,ACT,0.5299999713897705	CHEMBL104210,TN,INACT,0.009999999776482582	CHEMBL408395,TN,INACT,0.019999999552965164	CHEMBL183197,TP,ACT,0.6100000143051147	CHEMBL148246,TP,ACT,0.6399999856948853	CHEMBL328089,TN,INACT,0.009999999776482582	CHEMBL1161419,TN,INACT,0.029999999329447746	CHEMBL595265,TN,INACT,0.009999999776482582	CHEMBL42586,TN,INACT,0.03999999910593033	CHEMBL234543,TN,INACT,0.009999999776482582	CHEMBL249772,TP,ACT,0.6399999856948853	CHEMBL357077,TN,INACT,0.0	CHEMBL48448,TN,INACT,0.05000000074505806	CHEMBL461089,TN,INACT,0.0	CHEMBL3577344,TN,INACT,0.0	CHEMBL48380,TP,ACT,0.8600000143051147	CHEMBL292521,TN,INACT,0.009999999776482582	CHEMBL364246,TP,ACT,0.8600000143051147	CHEMBL358260,TP,ACT,0.9200000166893005	CHEMBL301501,TP,ACT,0.49000000953674316	CHEMBL385090,TP,ACT,0.9300000071525574	CHEMBL300268,TP,ACT,0.9200000166893005	CHEMBL167032,TN,INACT,0.0	CHEMBL294649,TN,INACT,0.0	CHEMBL264332,TP,ACT,0.9100000262260437	CHEMBL182178,TP,ACT,0.38999998569488525	CHEMBL89387,TP,ACT,0.11999999731779099	CHEMBL115482,TP,ACT,0.5	CHEMBL298748,TP,ACT,0.9399999976158142	CHEMBL321644,TN,INACT,0.0	CHEMBL119856,TP,ACT,0.8399999737739563	CHEMBL323175,TN,INACT,0.009999999776482582	CHEMBL2371558,TP,ACT,0.8899999856948853	CHEMBL22055,TP,ACT,0.2199999988079071	CHEMBL303204,TN,INACT,0.05000000074505806	CHEMBL429238,FP,INACT,0.9700000286102295	CHEMBL181301,TP,ACT,0.23000000417232513	CHEMBL233957,TN,INACT,0.009999999776482582	CHEMBL95727,TN,INACT,0.0	CHEMBL408372,TP,ACT,0.7799999713897705	CHEMBL552615,TN,INACT,0.0	CHEMBL2369851,TP,ACT,0.8899999856948853	CHEMBL140365,TN,INACT,0.009999999776482582	CHEMBL430683,TN,INACT,0.0	CHEMBL2371532,TP,ACT,0.8399999737739563	CHEMBL2370261,TP,ACT,0.3400000035762787	CHEMBL113472,TN,INACT,0.009999999776482582	CHEMBL100874,TN,INACT,0.019999999552965164	CHEMBL446978,TP,ACT,0.23000000417232513	CHEMBL415179,TP,ACT,0.8199999928474426	CHEMBL2371479,TP,ACT,0.7799999713897705	CHEMBL149441,TP,ACT,0.8999999761581421	CHEMBL121145,TP,ACT,0.9300000071525574	CHEMBL43330,TN,INACT,0.03999999910593033	CHEMBL325747,TP,ACT,0.10999999940395355	CHEMBL331394,TN,INACT,0.05000000074505806	CHEMBL276676,FP,INACT,0.18000000715255737	CHEMBL183325,TP,ACT,0.4699999988079071	CHEMBL303538,TN,INACT,0.009999999776482582	CHEMBL2371585,TP,ACT,0.9599999785423279	CHEMBL2371531,FN,ACT,0.029999999329447746	CHEMBL73096,TN,INACT,0.009999999776482582	CHEMBL265232,TP,ACT,0.27000001072883606	CHEMBL360297,TP,ACT,0.46000000834465027	CHEMBL23830,TP,ACT,0.6000000238418579	CHEMBL441741,TP,ACT,0.9700000286102295	CHEMBL2369493,FP,INACT,0.6100000143051147	CHEMBL6568,TN,INACT,0.0	CHEMBL358901,TP,ACT,0.7900000214576721	CHEMBL27809,TN,INACT,0.0	CHEMBL307659,TN,INACT,0.0	CHEMBL88620,TP,ACT,0.23999999463558197	CHEMBL210514,TP,ACT,0.09000000357627869	CHEMBL393971,TN,INACT,0.0	CHEMBL2371541,TP,ACT,0.9599999785423279	CHEMBL410779,TP,ACT,0.5899999737739563	CHEMBL336033,TN,INACT,0.029999999329447746	CHEMBL2370263,TP,ACT,0.8100000023841858	CHEMBL327529,TP,ACT,0.9100000262260437	CHEMBL22314,TP,ACT,0.14000000059604645	CHEMBL304950,TN,INACT,0.05999999865889549	CHEMBL414556,TP,ACT,0.5899999737739563	

