CNNModel CHEMBL4761 adam 0.001 30 128 0 0.8 False True
Number of active compounds :	111
Number of inactive compounds :	111
---------------------------------
Run id: CNNModel_CHEMBL4761_adam_0.001_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4761_adam_0.001_30_128_0.8_True/
---------------------------------
Training samples: 123
Validation samples: 39
--
Training Step: 1  | time: 0.985s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/123
[A[ATraining Step: 2  | total loss: [1m[32m0.62402[0m[0m | time: 1.711s
[2K
| Adam | epoch: 001 | loss: 0.62402 - acc: 0.4219 -- iter: 064/123
[A[ATraining Step: 3  | total loss: [1m[32m0.67984[0m[0m | time: 2.445s
[2K
| Adam | epoch: 001 | loss: 0.67984 - acc: 0.5625 -- iter: 096/123
[A[ATraining Step: 4  | total loss: [1m[32m0.68622[0m[0m | time: 4.108s
[2K
| Adam | epoch: 001 | loss: 0.68622 - acc: 0.5859 | val_loss: 0.67756 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 5  | total loss: [1m[32m0.68681[0m[0m | time: 0.649s
[2K
| Adam | epoch: 002 | loss: 0.68681 - acc: 0.5649 -- iter: 032/123
[A[ATraining Step: 6  | total loss: [1m[32m0.69090[0m[0m | time: 1.477s
[2K
| Adam | epoch: 002 | loss: 0.69090 - acc: 0.5589 -- iter: 064/123
[A[ATraining Step: 7  | total loss: [1m[32m0.69710[0m[0m | time: 2.283s
[2K
| Adam | epoch: 002 | loss: 0.69710 - acc: 0.5236 -- iter: 096/123
[A[ATraining Step: 8  | total loss: [1m[32m0.70057[0m[0m | time: 4.018s
[2K
| Adam | epoch: 002 | loss: 0.70057 - acc: 0.4752 | val_loss: 0.68928 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 9  | total loss: [1m[32m0.69469[0m[0m | time: 0.642s
[2K
| Adam | epoch: 003 | loss: 0.69469 - acc: 0.5214 -- iter: 032/123
[A[ATraining Step: 10  | total loss: [1m[32m0.68946[0m[0m | time: 1.279s
[2K
| Adam | epoch: 003 | loss: 0.68946 - acc: 0.6125 -- iter: 064/123
[A[ATraining Step: 11  | total loss: [1m[32m0.68711[0m[0m | time: 2.008s
[2K
| Adam | epoch: 003 | loss: 0.68711 - acc: 0.6557 -- iter: 096/123
[A[ATraining Step: 12  | total loss: [1m[32m0.68851[0m[0m | time: 3.760s
[2K
| Adam | epoch: 003 | loss: 0.68851 - acc: 0.6138 | val_loss: 0.68755 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 13  | total loss: [1m[32m0.68834[0m[0m | time: 0.744s
[2K
| Adam | epoch: 004 | loss: 0.68834 - acc: 0.6052 -- iter: 032/123
[A[ATraining Step: 14  | total loss: [1m[32m0.68784[0m[0m | time: 1.398s
[2K
| Adam | epoch: 004 | loss: 0.68784 - acc: 0.6005 -- iter: 064/123
[A[ATraining Step: 15  | total loss: [1m[32m0.68847[0m[0m | time: 2.049s
[2K
| Adam | epoch: 004 | loss: 0.68847 - acc: 0.5829 -- iter: 096/123
[A[ATraining Step: 16  | total loss: [1m[32m0.68850[0m[0m | time: 3.793s
[2K
| Adam | epoch: 004 | loss: 0.68850 - acc: 0.5727 | val_loss: 0.68245 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 17  | total loss: [1m[32m0.69097[0m[0m | time: 0.780s
[2K
| Adam | epoch: 005 | loss: 0.69097 - acc: 0.5465 -- iter: 032/123
[A[ATraining Step: 18  | total loss: [1m[32m0.68311[0m[0m | time: 1.561s
[2K
| Adam | epoch: 005 | loss: 0.68311 - acc: 0.5953 -- iter: 064/123
[A[ATraining Step: 19  | total loss: [1m[32m0.68575[0m[0m | time: 2.248s
[2K
| Adam | epoch: 005 | loss: 0.68575 - acc: 0.5740 -- iter: 096/123
[A[ATraining Step: 20  | total loss: [1m[32m0.68343[0m[0m | time: 3.901s
[2K
| Adam | epoch: 005 | loss: 0.68343 - acc: 0.5799 | val_loss: 0.67699 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 21  | total loss: [1m[32m0.68124[0m[0m | time: 0.693s
[2K
| Adam | epoch: 006 | loss: 0.68124 - acc: 0.5839 -- iter: 032/123
[A[ATraining Step: 22  | total loss: [1m[32m0.70080[0m[0m | time: 1.308s
[2K
| Adam | epoch: 006 | loss: 0.70080 - acc: 0.5400 -- iter: 064/123
[A[ATraining Step: 23  | total loss: [1m[32m0.68702[0m[0m | time: 1.905s
[2K
| Adam | epoch: 006 | loss: 0.68702 - acc: 0.5737 -- iter: 096/123
[A[ATraining Step: 24  | total loss: [1m[32m0.68929[0m[0m | time: 3.437s
[2K
| Adam | epoch: 006 | loss: 0.68929 - acc: 0.5618 | val_loss: 0.67974 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 25  | total loss: [1m[32m0.69884[0m[0m | time: 0.705s
[2K
| Adam | epoch: 007 | loss: 0.69884 - acc: 0.5197 -- iter: 032/123
[A[ATraining Step: 26  | total loss: [1m[32m0.70340[0m[0m | time: 1.423s
[2K
| Adam | epoch: 007 | loss: 0.70340 - acc: 0.4900 -- iter: 064/123
[A[ATraining Step: 27  | total loss: [1m[32m0.69642[0m[0m | time: 2.161s
[2K
| Adam | epoch: 007 | loss: 0.69642 - acc: 0.5247 -- iter: 096/123
[A[ATraining Step: 28  | total loss: [1m[32m0.69484[0m[0m | time: 3.935s
[2K
| Adam | epoch: 007 | loss: 0.69484 - acc: 0.5263 | val_loss: 0.68509 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 29  | total loss: [1m[32m0.69453[0m[0m | time: 0.626s
[2K
| Adam | epoch: 008 | loss: 0.69453 - acc: 0.5199 -- iter: 032/123
[A[ATraining Step: 30  | total loss: [1m[32m0.68964[0m[0m | time: 1.263s
[2K
| Adam | epoch: 008 | loss: 0.68964 - acc: 0.5634 -- iter: 064/123
[A[ATraining Step: 31  | total loss: [1m[32m0.68602[0m[0m | time: 2.009s
[2K
| Adam | epoch: 008 | loss: 0.68602 - acc: 0.5958 -- iter: 096/123
[A[ATraining Step: 32  | total loss: [1m[32m0.68718[0m[0m | time: 3.743s
[2K
| Adam | epoch: 008 | loss: 0.68718 - acc: 0.5813 | val_loss: 0.68511 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 33  | total loss: [1m[32m0.68805[0m[0m | time: 0.718s
[2K
| Adam | epoch: 009 | loss: 0.68805 - acc: 0.5703 -- iter: 032/123
[A[ATraining Step: 34  | total loss: [1m[32m0.68518[0m[0m | time: 1.329s
[2K
| Adam | epoch: 009 | loss: 0.68518 - acc: 0.5954 -- iter: 064/123
[A[ATraining Step: 35  | total loss: [1m[32m0.68659[0m[0m | time: 1.955s
[2K
| Adam | epoch: 009 | loss: 0.68659 - acc: 0.5793 -- iter: 096/123
[A[ATraining Step: 36  | total loss: [1m[32m0.68786[0m[0m | time: 3.743s
[2K
| Adam | epoch: 009 | loss: 0.68786 - acc: 0.5669 | val_loss: 0.68406 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 37  | total loss: [1m[32m0.68841[0m[0m | time: 0.754s
[2K
| Adam | epoch: 010 | loss: 0.68841 - acc: 0.5598 -- iter: 032/123
[A[ATraining Step: 38  | total loss: [1m[32m0.68963[0m[0m | time: 1.503s
[2K
| Adam | epoch: 010 | loss: 0.68963 - acc: 0.5481 -- iter: 064/123
[A[ATraining Step: 39  | total loss: [1m[32m0.68979[0m[0m | time: 2.126s
[2K
| Adam | epoch: 010 | loss: 0.68979 - acc: 0.5448 -- iter: 096/123
[A[ATraining Step: 40  | total loss: [1m[32m0.68932[0m[0m | time: 3.757s
[2K
| Adam | epoch: 010 | loss: 0.68932 - acc: 0.5469 | val_loss: 0.68330 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 41  | total loss: [1m[32m0.68891[0m[0m | time: 0.797s
[2K
| Adam | epoch: 011 | loss: 0.68891 - acc: 0.5485 -- iter: 032/123
[A[ATraining Step: 42  | total loss: [1m[32m0.68622[0m[0m | time: 1.577s
[2K
| Adam | epoch: 011 | loss: 0.68622 - acc: 0.5679 -- iter: 064/123
[A[ATraining Step: 43  | total loss: [1m[32m0.68693[0m[0m | time: 2.373s
[2K
| Adam | epoch: 011 | loss: 0.68693 - acc: 0.5614 -- iter: 096/123
[A[ATraining Step: 44  | total loss: [1m[32m0.68586[0m[0m | time: 4.054s
[2K
| Adam | epoch: 011 | loss: 0.68586 - acc: 0.5670 | val_loss: 0.68075 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 45  | total loss: [1m[32m0.68395[0m[0m | time: 0.690s
[2K
| Adam | epoch: 012 | loss: 0.68395 - acc: 0.5776 -- iter: 032/123
[A[ATraining Step: 46  | total loss: [1m[32m0.68229[0m[0m | time: 1.411s
[2K
| Adam | epoch: 012 | loss: 0.68229 - acc: 0.5863 -- iter: 064/123
[A[ATraining Step: 47  | total loss: [1m[32m0.68477[0m[0m | time: 2.147s
[2K
| Adam | epoch: 012 | loss: 0.68477 - acc: 0.5722 -- iter: 096/123
[A[ATraining Step: 48  | total loss: [1m[32m0.67948[0m[0m | time: 3.864s
[2K
| Adam | epoch: 012 | loss: 0.67948 - acc: 0.5957 | val_loss: 0.67654 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 49  | total loss: [1m[32m0.68240[0m[0m | time: 0.682s
[2K
| Adam | epoch: 013 | loss: 0.68240 - acc: 0.5806 -- iter: 032/123
[A[ATraining Step: 50  | total loss: [1m[32m0.68723[0m[0m | time: 1.332s
[2K
| Adam | epoch: 013 | loss: 0.68723 - acc: 0.5595 -- iter: 064/123
[A[ATraining Step: 51  | total loss: [1m[32m0.69088[0m[0m | time: 2.109s
[2K
| Adam | epoch: 013 | loss: 0.69088 - acc: 0.5419 -- iter: 096/123
[A[ATraining Step: 52  | total loss: [1m[32m0.68902[0m[0m | time: 3.850s
[2K
| Adam | epoch: 013 | loss: 0.68902 - acc: 0.5450 | val_loss: 0.67690 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 53  | total loss: [1m[32m0.68665[0m[0m | time: 0.765s
[2K
| Adam | epoch: 014 | loss: 0.68665 - acc: 0.5522 -- iter: 032/123
[A[ATraining Step: 54  | total loss: [1m[32m0.68455[0m[0m | time: 1.379s
[2K
| Adam | epoch: 014 | loss: 0.68455 - acc: 0.5582 -- iter: 064/123
[A[ATraining Step: 55  | total loss: [1m[32m0.68035[0m[0m | time: 2.024s
[2K
| Adam | epoch: 014 | loss: 0.68035 - acc: 0.5737 -- iter: 096/123
[A[ATraining Step: 56  | total loss: [1m[32m0.67605[0m[0m | time: 3.776s
[2K
| Adam | epoch: 014 | loss: 0.67605 - acc: 0.5868 | val_loss: 0.67221 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 57  | total loss: [1m[32m0.68309[0m[0m | time: 0.790s
[2K
| Adam | epoch: 015 | loss: 0.68309 - acc: 0.5618 -- iter: 032/123
[A[ATraining Step: 58  | total loss: [1m[32m0.67944[0m[0m | time: 1.531s
[2K
| Adam | epoch: 015 | loss: 0.67944 - acc: 0.5704 -- iter: 064/123
[A[ATraining Step: 59  | total loss: [1m[32m0.67663[0m[0m | time: 2.220s
[2K
| Adam | epoch: 015 | loss: 0.67663 - acc: 0.5736 -- iter: 096/123
[A[ATraining Step: 60  | total loss: [1m[32m0.67518[0m[0m | time: 3.895s
[2K
| Adam | epoch: 015 | loss: 0.67518 - acc: 0.5712 | val_loss: 0.66642 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 61  | total loss: [1m[32m0.67307[0m[0m | time: 0.619s
[2K
| Adam | epoch: 016 | loss: 0.67307 - acc: 0.5691 -- iter: 032/123
[A[ATraining Step: 62  | total loss: [1m[32m0.67604[0m[0m | time: 1.230s
[2K
| Adam | epoch: 016 | loss: 0.67604 - acc: 0.5562 -- iter: 064/123
[A[ATraining Step: 63  | total loss: [1m[32m0.67253[0m[0m | time: 1.917s
[2K
| Adam | epoch: 016 | loss: 0.67253 - acc: 0.5610 -- iter: 096/123
[A[ATraining Step: 64  | total loss: [1m[32m0.67076[0m[0m | time: 3.548s
[2K
| Adam | epoch: 016 | loss: 0.67076 - acc: 0.5573 | val_loss: 0.65956 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 65  | total loss: [1m[32m0.66491[0m[0m | time: 0.678s
[2K
| Adam | epoch: 017 | loss: 0.66491 - acc: 0.5616 -- iter: 032/123
[A[ATraining Step: 66  | total loss: [1m[32m0.65757[0m[0m | time: 1.448s
[2K
| Adam | epoch: 017 | loss: 0.65757 - acc: 0.5654 -- iter: 064/123
[A[ATraining Step: 67  | total loss: [1m[32m0.65729[0m[0m | time: 2.216s
[2K
| Adam | epoch: 017 | loss: 0.65729 - acc: 0.5613 -- iter: 096/123
[A[ATraining Step: 68  | total loss: [1m[32m0.64408[0m[0m | time: 4.013s
[2K
| Adam | epoch: 017 | loss: 0.64408 - acc: 0.5688 | val_loss: 0.66582 - val_acc: 0.7692 -- iter: 123/123
--
Training Step: 69  | total loss: [1m[32m0.63288[0m[0m | time: 0.639s
[2K
| Adam | epoch: 018 | loss: 0.63288 - acc: 0.5754 -- iter: 032/123
[A[ATraining Step: 70  | total loss: [1m[32m0.64206[0m[0m | time: 1.277s
[2K
| Adam | epoch: 018 | loss: 0.64206 - acc: 0.5859 -- iter: 064/123
[A[ATraining Step: 71  | total loss: [1m[32m0.64534[0m[0m | time: 2.026s
[2K
| Adam | epoch: 018 | loss: 0.64534 - acc: 0.6120 -- iter: 096/123
[A[ATraining Step: 72  | total loss: [1m[32m0.63331[0m[0m | time: 3.761s
[2K
| Adam | epoch: 018 | loss: 0.63331 - acc: 0.6416 | val_loss: 0.63677 - val_acc: 0.6410 -- iter: 123/123
--
Training Step: 73  | total loss: [1m[32m0.62866[0m[0m | time: 0.741s
[2K
| Adam | epoch: 019 | loss: 0.62866 - acc: 0.6536 -- iter: 032/123
[A[ATraining Step: 74  | total loss: [1m[32m0.61161[0m[0m | time: 1.363s
[2K
| Adam | epoch: 019 | loss: 0.61161 - acc: 0.6779 -- iter: 064/123
[A[ATraining Step: 75  | total loss: [1m[32m0.59165[0m[0m | time: 1.991s
[2K
| Adam | epoch: 019 | loss: 0.59165 - acc: 0.6968 -- iter: 096/123
[A[ATraining Step: 76  | total loss: [1m[32m0.56435[0m[0m | time: 3.730s
[2K
| Adam | epoch: 019 | loss: 0.56435 - acc: 0.7094 | val_loss: 0.86910 - val_acc: 0.5897 -- iter: 123/123
--
Training Step: 77  | total loss: [1m[32m0.63454[0m[0m | time: 0.772s
[2K
| Adam | epoch: 020 | loss: 0.63454 - acc: 0.6906 -- iter: 032/123
[A[ATraining Step: 78  | total loss: [1m[32m0.64715[0m[0m | time: 1.583s
[2K
| Adam | epoch: 020 | loss: 0.64715 - acc: 0.6870 -- iter: 064/123
[A[ATraining Step: 79  | total loss: [1m[32m0.63557[0m[0m | time: 2.253s
[2K
| Adam | epoch: 020 | loss: 0.63557 - acc: 0.6903 -- iter: 096/123
[A[ATraining Step: 80  | total loss: [1m[32m0.62539[0m[0m | time: 3.891s
[2K
| Adam | epoch: 020 | loss: 0.62539 - acc: 0.6916 | val_loss: 0.71070 - val_acc: 0.5385 -- iter: 123/123
--
Training Step: 81  | total loss: [1m[32m0.62927[0m[0m | time: 0.717s
[2K
| Adam | epoch: 021 | loss: 0.62927 - acc: 0.6779 -- iter: 032/123
[A[ATraining Step: 82  | total loss: [1m[32m0.62769[0m[0m | time: 1.460s
[2K
| Adam | epoch: 021 | loss: 0.62769 - acc: 0.6695 -- iter: 064/123
[A[ATraining Step: 83  | total loss: [1m[32m0.62086[0m[0m | time: 2.208s
[2K
| Adam | epoch: 021 | loss: 0.62086 - acc: 0.6775 -- iter: 096/123
[A[ATraining Step: 84  | total loss: [1m[32m0.61392[0m[0m | time: 3.814s
[2K
| Adam | epoch: 021 | loss: 0.61392 - acc: 0.6973 | val_loss: 0.58347 - val_acc: 0.7436 -- iter: 123/123
--
Training Step: 85  | total loss: [1m[32m0.60156[0m[0m | time: 0.629s
[2K
| Adam | epoch: 022 | loss: 0.60156 - acc: 0.7053 -- iter: 032/123
[A[ATraining Step: 86  | total loss: [1m[32m0.59122[0m[0m | time: 1.402s
[2K
| Adam | epoch: 022 | loss: 0.59122 - acc: 0.7126 -- iter: 064/123
[A[ATraining Step: 87  | total loss: [1m[32m0.58273[0m[0m | time: 2.163s
[2K
| Adam | epoch: 022 | loss: 0.58273 - acc: 0.7226 -- iter: 096/123
[A[ATraining Step: 88  | total loss: [1m[32m0.57725[0m[0m | time: 3.878s
[2K
| Adam | epoch: 022 | loss: 0.57725 - acc: 0.7253 | val_loss: 0.56936 - val_acc: 0.7179 -- iter: 123/123
--
Training Step: 89  | total loss: [1m[32m0.57556[0m[0m | time: 0.522s
[2K
| Adam | epoch: 023 | loss: 0.57556 - acc: 0.7184 -- iter: 032/123
[A[ATraining Step: 90  | total loss: [1m[32m0.55823[0m[0m | time: 1.051s
[2K
| Adam | epoch: 023 | loss: 0.55823 - acc: 0.7391 -- iter: 064/123
[A[ATraining Step: 91  | total loss: [1m[32m0.54212[0m[0m | time: 1.662s
[2K
| Adam | epoch: 023 | loss: 0.54212 - acc: 0.7578 -- iter: 096/123
[A[ATraining Step: 92  | total loss: [1m[32m0.52697[0m[0m | time: 3.273s
[2K
| Adam | epoch: 023 | loss: 0.52697 - acc: 0.7695 | val_loss: 0.62007 - val_acc: 0.6923 -- iter: 123/123
--
Training Step: 93  | total loss: [1m[32m0.52784[0m[0m | time: 0.618s
[2K
| Adam | epoch: 024 | loss: 0.52784 - acc: 0.7738 -- iter: 032/123
[A[ATraining Step: 94  | total loss: [1m[32m0.49635[0m[0m | time: 1.152s
[2K
| Adam | epoch: 024 | loss: 0.49635 - acc: 0.7933 -- iter: 064/123
[A[ATraining Step: 95  | total loss: [1m[32m0.48933[0m[0m | time: 1.674s
[2K
| Adam | epoch: 024 | loss: 0.48933 - acc: 0.7992 -- iter: 096/123
[A[ATraining Step: 96  | total loss: [1m[32m0.48055[0m[0m | time: 3.310s
[2K
| Adam | epoch: 024 | loss: 0.48055 - acc: 0.8045 | val_loss: 0.76275 - val_acc: 0.6667 -- iter: 123/123
--
Training Step: 97  | total loss: [1m[32m0.46427[0m[0m | time: 0.609s
[2K
| Adam | epoch: 025 | loss: 0.46427 - acc: 0.8146 -- iter: 032/123
[A[ATraining Step: 98  | total loss: [1m[32m0.45286[0m[0m | time: 1.211s
[2K
| Adam | epoch: 025 | loss: 0.45286 - acc: 0.8175 -- iter: 064/123
[A[ATraining Step: 99  | total loss: [1m[32m0.43991[0m[0m | time: 1.712s
[2K
| Adam | epoch: 025 | loss: 0.43991 - acc: 0.8233 -- iter: 096/123
[A[ATraining Step: 100  | total loss: [1m[32m0.40898[0m[0m | time: 3.255s
[2K
| Adam | epoch: 025 | loss: 0.40898 - acc: 0.8410 | val_loss: 0.62730 - val_acc: 0.7436 -- iter: 123/123
--
Training Step: 101  | total loss: [1m[32m0.37926[0m[0m | time: 0.606s
[2K
| Adam | epoch: 026 | loss: 0.37926 - acc: 0.8569 -- iter: 032/123
[A[ATraining Step: 102  | total loss: [1m[32m0.37421[0m[0m | time: 1.220s
[2K
| Adam | epoch: 026 | loss: 0.37421 - acc: 0.8587 -- iter: 064/123
[A[ATraining Step: 103  | total loss: [1m[32m0.35572[0m[0m | time: 1.821s
[2K
| Adam | epoch: 026 | loss: 0.35572 - acc: 0.8697 -- iter: 096/123
[A[ATraining Step: 104  | total loss: [1m[32m0.33262[0m[0m | time: 3.357s
[2K
| Adam | epoch: 026 | loss: 0.33262 - acc: 0.8796 | val_loss: 0.67265 - val_acc: 0.6154 -- iter: 123/123
--
Training Step: 105  | total loss: [1m[32m0.32537[0m[0m | time: 0.532s
[2K
| Adam | epoch: 027 | loss: 0.32537 - acc: 0.8805 -- iter: 032/123
[A[ATraining Step: 106  | total loss: [1m[32m0.30984[0m[0m | time: 1.138s
[2K
| Adam | epoch: 027 | loss: 0.30984 - acc: 0.8888 -- iter: 064/123
[A[ATraining Step: 107  | total loss: [1m[32m0.32088[0m[0m | time: 1.737s
[2K
| Adam | epoch: 027 | loss: 0.32088 - acc: 0.8874 -- iter: 096/123
[A[ATraining Step: 108  | total loss: [1m[32m0.31491[0m[0m | time: 3.344s
[2K
| Adam | epoch: 027 | loss: 0.31491 - acc: 0.8893 | val_loss: 0.53946 - val_acc: 0.8462 -- iter: 123/123
--
Training Step: 109  | total loss: [1m[32m0.30083[0m[0m | time: 0.530s
[2K
| Adam | epoch: 028 | loss: 0.30083 - acc: 0.8941 -- iter: 032/123
[A[ATraining Step: 110  | total loss: [1m[32m0.29244[0m[0m | time: 1.049s
[2K
| Adam | epoch: 028 | loss: 0.29244 - acc: 0.8936 -- iter: 064/123
[A[ATraining Step: 111  | total loss: [1m[32m0.27700[0m[0m | time: 1.659s
[2K
| Adam | epoch: 028 | loss: 0.27700 - acc: 0.9005 -- iter: 096/123
[A[ATraining Step: 112  | total loss: [1m[32m0.25806[0m[0m | time: 3.267s
[2K
| Adam | epoch: 028 | loss: 0.25806 - acc: 0.9105 | val_loss: 0.70328 - val_acc: 0.6923 -- iter: 123/123
--
Training Step: 113  | total loss: [1m[32m0.25579[0m[0m | time: 0.624s
[2K
| Adam | epoch: 029 | loss: 0.25579 - acc: 0.9132 -- iter: 032/123
[A[ATraining Step: 114  | total loss: [1m[32m0.25292[0m[0m | time: 1.160s
[2K
| Adam | epoch: 029 | loss: 0.25292 - acc: 0.9156 -- iter: 064/123
[A[ATraining Step: 115  | total loss: [1m[32m0.24397[0m[0m | time: 1.723s
[2K
| Adam | epoch: 029 | loss: 0.24397 - acc: 0.9203 -- iter: 096/123
[A[ATraining Step: 116  | total loss: [1m[32m0.23565[0m[0m | time: 3.333s
[2K
| Adam | epoch: 029 | loss: 0.23565 - acc: 0.9246 | val_loss: 0.59471 - val_acc: 0.7949 -- iter: 123/123
--
Training Step: 117  | total loss: [1m[32m0.22203[0m[0m | time: 0.636s
[2K
| Adam | epoch: 030 | loss: 0.22203 - acc: 0.9290 -- iter: 032/123
[A[ATraining Step: 118  | total loss: [1m[32m0.20444[0m[0m | time: 1.280s
[2K
| Adam | epoch: 030 | loss: 0.20444 - acc: 0.9361 -- iter: 064/123
[A[ATraining Step: 119  | total loss: [1m[32m0.19445[0m[0m | time: 1.802s
[2K
| Adam | epoch: 030 | loss: 0.19445 - acc: 0.9394 -- iter: 096/123
[A[ATraining Step: 120  | total loss: [1m[32m0.18823[0m[0m | time: 3.339s
[2K
| Adam | epoch: 030 | loss: 0.18823 - acc: 0.9417 | val_loss: 0.65102 - val_acc: 0.6923 -- iter: 123/123
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8369565217391304
Validation AUPRC:0.785580965968897
Test AUC:0.8527777777777777
Test AUPRC:0.884927823580296
BestTestF1Score	0.88	0.68	0.85	0.88	0.88	21	3	12	3	0.87
BestTestMCCScore	0.88	0.68	0.85	0.88	0.88	21	3	12	3	0.87
BestTestAccuracyScore	0.88	0.68	0.85	0.88	0.88	21	3	12	3	0.87
BestValidationF1Score	0.77	0.63	0.82	0.8	0.75	12	3	20	4	0.87
BestValidationMCC	0.77	0.63	0.82	0.8	0.75	12	3	20	4	0.87
BestValidationAccuracy	0.77	0.63	0.82	0.8	0.75	12	3	20	4	0.87
TestPredictions (Threshold:0.87)
CHEMBL3736447,TP,ACT,0.9399999976158142	CHEMBL427268,FN,ACT,0.18000000715255737	CHEMBL246585,FP,INACT,0.9700000286102295	CHEMBL3735240,TP,ACT,0.949999988079071	CHEMBL414570,FP,INACT,0.9399999976158142	CHEMBL42359,TN,INACT,0.23999999463558197	CHEMBL234305,TP,ACT,0.9700000286102295	CHEMBL234304,FN,ACT,0.6499999761581421	CHEMBL174463,TN,INACT,0.019999999552965164	CHEMBL435810,TN,INACT,0.03999999910593033	CHEMBL169553,TN,INACT,0.23000000417232513	CHEMBL228901,TP,ACT,0.9300000071525574	CHEMBL3342678,TP,ACT,0.9399999976158142	CHEMBL229005,TP,ACT,0.9700000286102295	CHEMBL3342680,TP,ACT,0.9700000286102295	CHEMBL195893,FP,INACT,0.8700000047683716	CHEMBL165012,TN,INACT,0.03999999910593033	CHEMBL3342688,TP,ACT,0.9700000286102295	CHEMBL438915,TN,INACT,0.14000000059604645	CHEMBL228847,TP,ACT,0.8899999856948853	CHEMBL3342682,TP,ACT,0.9599999785423279	CHEMBL3342676,TP,ACT,0.9399999976158142	CHEMBL515170,TN,INACT,0.019999999552965164	CHEMBL1170637,FN,ACT,0.009999999776482582	CHEMBL3342686,TP,ACT,0.9700000286102295	CHEMBL233234,TP,ACT,0.9700000286102295	CHEMBL3736519,TP,ACT,0.949999988079071	CHEMBL389349,TP,ACT,0.9300000071525574	CHEMBL387686,TP,ACT,0.9300000071525574	CHEMBL1170644,TP,ACT,0.9599999785423279	CHEMBL2113072,TN,INACT,0.33000001311302185	CHEMBL3736108,TP,ACT,0.9300000071525574	CHEMBL441305,TN,INACT,0.5199999809265137	CHEMBL191915,TN,INACT,0.8600000143051147	CHEMBL234101,TP,ACT,0.9399999976158142	CHEMBL39879,TN,INACT,0.019999999552965164	CHEMBL3109772,TN,INACT,0.36000001430511475	CHEMBL230034,TP,ACT,0.9700000286102295	CHEMBL3735760,TP,ACT,0.9100000262260437	

