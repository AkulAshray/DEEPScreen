ImageNetInceptionV2 CHEMBL3759 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	1016
Number of inactive compounds :	1016
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3759_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3759_adam_0.0005_15_0.6/
---------------------------------
Training samples: 1275
Validation samples: 399
--
Training Step: 1  | time: 906.349s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1275
[A[ATraining Step: 2  | total loss: [1m[32m0.69850[0m[0m | time: 985.251s
[2K
| Adam | epoch: 001 | loss: 0.69850 - acc: 0.4781 -- iter: 0064/1275
[A[ATraining Step: 3  | total loss: [1m[32m0.60625[0m[0m | time: 1054.565s
[2K
| Adam | epoch: 001 | loss: 0.60625 - acc: 0.7517 -- iter: 0096/1275
[A[ATraining Step: 4  | total loss: [1m[32m0.76400[0m[0m | time: 1092.672s
[2K
| Adam | epoch: 001 | loss: 0.76400 - acc: 0.6098 -- iter: 0128/1275
[A[ATraining Step: 5  | total loss: [1m[32m0.74105[0m[0m | time: 1109.725s
[2K
| Adam | epoch: 001 | loss: 0.74105 - acc: 0.5987 -- iter: 0160/1275
[A[ATraining Step: 6  | total loss: [1m[32m0.77891[0m[0m | time: 1126.950s
[2K
| Adam | epoch: 001 | loss: 0.77891 - acc: 0.4951 -- iter: 0192/1275
[A[ATraining Step: 7  | total loss: [1m[32m0.75630[0m[0m | time: 1142.827s
[2K
| Adam | epoch: 001 | loss: 0.75630 - acc: 0.5355 -- iter: 0224/1275
[A[ATraining Step: 8  | total loss: [1m[32m0.68372[0m[0m | time: 1154.849s
[2K
| Adam | epoch: 001 | loss: 0.68372 - acc: 0.5683 -- iter: 0256/1275
[A[ATraining Step: 9  | total loss: [1m[32m0.69561[0m[0m | time: 1168.176s
[2K
| Adam | epoch: 001 | loss: 0.69561 - acc: 0.5983 -- iter: 0288/1275
[A[ATraining Step: 10  | total loss: [1m[32m0.59424[0m[0m | time: 1186.444s
[2K
| Adam | epoch: 001 | loss: 0.59424 - acc: 0.6898 -- iter: 0320/1275
[A[ATraining Step: 11  | total loss: [1m[32m0.54176[0m[0m | time: 1200.252s
[2K
| Adam | epoch: 001 | loss: 0.54176 - acc: 0.7331 -- iter: 0352/1275
[A[ATraining Step: 12  | total loss: [1m[32m0.52863[0m[0m | time: 1215.958s
[2K
| Adam | epoch: 001 | loss: 0.52863 - acc: 0.6845 -- iter: 0384/1275
[A[ATraining Step: 13  | total loss: [1m[32m0.51285[0m[0m | time: 1231.887s
[2K
| Adam | epoch: 001 | loss: 0.51285 - acc: 0.7259 -- iter: 0416/1275
[A[ATraining Step: 14  | total loss: [1m[32m0.59898[0m[0m | time: 1247.759s
[2K
| Adam | epoch: 001 | loss: 0.59898 - acc: 0.6719 -- iter: 0448/1275
[A[ATraining Step: 15  | total loss: [1m[32m0.56640[0m[0m | time: 1264.152s
[2K
| Adam | epoch: 001 | loss: 0.56640 - acc: 0.7147 -- iter: 0480/1275
[A[ATraining Step: 16  | total loss: [1m[32m0.56437[0m[0m | time: 1281.363s
[2K
| Adam | epoch: 001 | loss: 0.56437 - acc: 0.7045 -- iter: 0512/1275
[A[ATraining Step: 17  | total loss: [1m[32m0.59886[0m[0m | time: 1293.410s
[2K
| Adam | epoch: 001 | loss: 0.59886 - acc: 0.6871 -- iter: 0544/1275
[A[ATraining Step: 18  | total loss: [1m[32m0.61121[0m[0m | time: 1303.326s
[2K
| Adam | epoch: 001 | loss: 0.61121 - acc: 0.6764 -- iter: 0576/1275
[A[ATraining Step: 19  | total loss: [1m[32m0.55537[0m[0m | time: 1313.707s
[2K
| Adam | epoch: 001 | loss: 0.55537 - acc: 0.7114 -- iter: 0608/1275
[A[ATraining Step: 20  | total loss: [1m[32m0.55043[0m[0m | time: 1329.052s
[2K
| Adam | epoch: 001 | loss: 0.55043 - acc: 0.7238 -- iter: 0640/1275
[A[ATraining Step: 21  | total loss: [1m[32m0.50894[0m[0m | time: 1350.378s
[2K
| Adam | epoch: 001 | loss: 0.50894 - acc: 0.7610 -- iter: 0672/1275
[A[ATraining Step: 22  | total loss: [1m[32m0.48546[0m[0m | time: 1363.369s
[2K
| Adam | epoch: 001 | loss: 0.48546 - acc: 0.7858 -- iter: 0704/1275
[A[ATraining Step: 23  | total loss: [1m[32m0.53416[0m[0m | time: 1392.161s
[2K
| Adam | epoch: 001 | loss: 0.53416 - acc: 0.7664 -- iter: 0736/1275
[A[ATraining Step: 24  | total loss: [1m[32m0.52698[0m[0m | time: 1406.844s
[2K
| Adam | epoch: 001 | loss: 0.52698 - acc: 0.7354 -- iter: 0768/1275
[A[ATraining Step: 25  | total loss: [1m[32m0.46956[0m[0m | time: 1421.164s
[2K
| Adam | epoch: 001 | loss: 0.46956 - acc: 0.7905 -- iter: 0800/1275
[A[ATraining Step: 26  | total loss: [1m[32m0.45676[0m[0m | time: 1435.825s
[2K
| Adam | epoch: 001 | loss: 0.45676 - acc: 0.8129 -- iter: 0832/1275
[A[ATraining Step: 27  | total loss: [1m[32m0.45552[0m[0m | time: 1450.405s
[2K
| Adam | epoch: 001 | loss: 0.45552 - acc: 0.8047 -- iter: 0864/1275
[A[ATraining Step: 28  | total loss: [1m[32m0.45186[0m[0m | time: 1460.693s
[2K
| Adam | epoch: 001 | loss: 0.45186 - acc: 0.7911 -- iter: 0896/1275
[A[ATraining Step: 29  | total loss: [1m[32m0.47891[0m[0m | time: 1470.501s
[2K
| Adam | epoch: 001 | loss: 0.47891 - acc: 0.7583 -- iter: 0928/1275
[A[ATraining Step: 30  | total loss: [1m[32m0.48212[0m[0m | time: 1483.178s
[2K
| Adam | epoch: 001 | loss: 0.48212 - acc: 0.7859 -- iter: 0960/1275
[A[ATraining Step: 31  | total loss: [1m[32m0.44718[0m[0m | time: 1497.970s
[2K
| Adam | epoch: 001 | loss: 0.44718 - acc: 0.8065 -- iter: 0992/1275
[A[ATraining Step: 32  | total loss: [1m[32m0.49549[0m[0m | time: 1512.762s
[2K
| Adam | epoch: 001 | loss: 0.49549 - acc: 0.7867 -- iter: 1024/1275
[A[ATraining Step: 33  | total loss: [1m[32m0.46851[0m[0m | time: 1527.143s
[2K
| Adam | epoch: 001 | loss: 0.46851 - acc: 0.7993 -- iter: 1056/1275
[A[ATraining Step: 34  | total loss: [1m[32m0.44752[0m[0m | time: 1540.280s
[2K
| Adam | epoch: 001 | loss: 0.44752 - acc: 0.8021 -- iter: 1088/1275
[A[ATraining Step: 35  | total loss: [1m[32m0.43057[0m[0m | time: 1555.148s
[2K
| Adam | epoch: 001 | loss: 0.43057 - acc: 0.8043 -- iter: 1120/1275
[A[ATraining Step: 36  | total loss: [1m[32m0.48003[0m[0m | time: 1569.596s
[2K
| Adam | epoch: 001 | loss: 0.48003 - acc: 0.7804 -- iter: 1152/1275
[A[ATraining Step: 37  | total loss: [1m[32m0.47131[0m[0m | time: 1583.779s
[2K
| Adam | epoch: 001 | loss: 0.47131 - acc: 0.7868 -- iter: 1184/1275
[A[ATraining Step: 38  | total loss: [1m[32m0.44690[0m[0m | time: 1596.145s
[2K
| Adam | epoch: 001 | loss: 0.44690 - acc: 0.7979 -- iter: 1216/1275
[A[ATraining Step: 39  | total loss: [1m[32m0.43694[0m[0m | time: 1605.742s
[2K
| Adam | epoch: 001 | loss: 0.43694 - acc: 0.8127 -- iter: 1248/1275
[A[ATraining Step: 40  | total loss: [1m[32m0.41108[0m[0m | time: 1658.480s
[2K
| Adam | epoch: 001 | loss: 0.41108 - acc: 0.8244 | val_loss: 2.56075 - val_acc: 0.4812 -- iter: 1275/1275
--
Training Step: 41  | total loss: [1m[32m0.41560[0m[0m | time: 7.146s
[2K
| Adam | epoch: 002 | loss: 0.41560 - acc: 0.8158 -- iter: 0032/1275
[A[ATraining Step: 42  | total loss: [1m[32m0.38688[0m[0m | time: 15.180s
[2K
| Adam | epoch: 002 | loss: 0.38688 - acc: 0.8423 -- iter: 0064/1275
[A[ATraining Step: 43  | total loss: [1m[32m0.45785[0m[0m | time: 24.892s
[2K
| Adam | epoch: 002 | loss: 0.45785 - acc: 0.8095 -- iter: 0096/1275
[A[ATraining Step: 44  | total loss: [1m[32m0.47281[0m[0m | time: 37.083s
[2K
| Adam | epoch: 002 | loss: 0.47281 - acc: 0.8046 -- iter: 0128/1275
[A[ATraining Step: 45  | total loss: [1m[32m0.51998[0m[0m | time: 49.415s
[2K
| Adam | epoch: 002 | loss: 0.51998 - acc: 0.7741 -- iter: 0160/1275
[A[ATraining Step: 46  | total loss: [1m[32m0.51446[0m[0m | time: 61.272s
[2K
| Adam | epoch: 002 | loss: 0.51446 - acc: 0.7701 -- iter: 0192/1275
[A[ATraining Step: 47  | total loss: [1m[32m0.53589[0m[0m | time: 73.060s
[2K
| Adam | epoch: 002 | loss: 0.53589 - acc: 0.7566 -- iter: 0224/1275
[A[ATraining Step: 48  | total loss: [1m[32m0.49820[0m[0m | time: 84.624s
[2K
| Adam | epoch: 002 | loss: 0.49820 - acc: 0.7706 -- iter: 0256/1275
[A[ATraining Step: 49  | total loss: [1m[32m0.50896[0m[0m | time: 95.406s
[2K
| Adam | epoch: 002 | loss: 0.50896 - acc: 0.7723 -- iter: 0288/1275
[A[ATraining Step: 50  | total loss: [1m[32m0.58082[0m[0m | time: 107.713s
[2K
| Adam | epoch: 002 | loss: 0.58082 - acc: 0.7397 -- iter: 0320/1275
[A[ATraining Step: 51  | total loss: [1m[32m0.52905[0m[0m | time: 118.820s
[2K
| Adam | epoch: 002 | loss: 0.52905 - acc: 0.7747 -- iter: 0352/1275
[A[ATraining Step: 52  | total loss: [1m[32m0.53777[0m[0m | time: 126.718s
[2K
| Adam | epoch: 002 | loss: 0.53777 - acc: 0.7710 -- iter: 0384/1275
[A[ATraining Step: 53  | total loss: [1m[32m0.51699[0m[0m | time: 134.670s
[2K
| Adam | epoch: 002 | loss: 0.51699 - acc: 0.7725 -- iter: 0416/1275
[A[ATraining Step: 54  | total loss: [1m[32m0.49163[0m[0m | time: 142.675s
[2K
| Adam | epoch: 002 | loss: 0.49163 - acc: 0.7828 -- iter: 0448/1275
[A[ATraining Step: 55  | total loss: [1m[32m0.47629[0m[0m | time: 152.282s
[2K
| Adam | epoch: 002 | loss: 0.47629 - acc: 0.7871 -- iter: 0480/1275
[A[ATraining Step: 56  | total loss: [1m[32m0.44123[0m[0m | time: 164.744s
[2K
| Adam | epoch: 002 | loss: 0.44123 - acc: 0.8082 -- iter: 0512/1275
[A[ATraining Step: 57  | total loss: [1m[32m0.42709[0m[0m | time: 176.397s
[2K
| Adam | epoch: 002 | loss: 0.42709 - acc: 0.8088 -- iter: 0544/1275
[A[ATraining Step: 58  | total loss: [1m[32m0.40403[0m[0m | time: 188.010s
[2K
| Adam | epoch: 002 | loss: 0.40403 - acc: 0.8264 -- iter: 0576/1275
[A[ATraining Step: 59  | total loss: [1m[32m0.39134[0m[0m | time: 200.171s
[2K
| Adam | epoch: 002 | loss: 0.39134 - acc: 0.8371 -- iter: 0608/1275
[A[ATraining Step: 60  | total loss: [1m[32m0.37251[0m[0m | time: 212.276s
[2K
| Adam | epoch: 002 | loss: 0.37251 - acc: 0.8462 -- iter: 0640/1275
[A[ATraining Step: 61  | total loss: [1m[32m0.36536[0m[0m | time: 224.035s
[2K
| Adam | epoch: 002 | loss: 0.36536 - acc: 0.8459 -- iter: 0672/1275
[A[ATraining Step: 62  | total loss: [1m[32m0.35314[0m[0m | time: 234.630s
[2K
| Adam | epoch: 002 | loss: 0.35314 - acc: 0.8497 -- iter: 0704/1275
[A[ATraining Step: 63  | total loss: [1m[32m0.34238[0m[0m | time: 245.282s
[2K
| Adam | epoch: 002 | loss: 0.34238 - acc: 0.8449 -- iter: 0736/1275
[A[ATraining Step: 64  | total loss: [1m[32m0.32672[0m[0m | time: 253.370s
[2K
| Adam | epoch: 002 | loss: 0.32672 - acc: 0.8526 -- iter: 0768/1275
[A[ATraining Step: 65  | total loss: [1m[32m0.34001[0m[0m | time: 261.482s
[2K
| Adam | epoch: 002 | loss: 0.34001 - acc: 0.8515 -- iter: 0800/1275
[A[ATraining Step: 66  | total loss: [1m[32m0.33991[0m[0m | time: 273.037s
[2K
| Adam | epoch: 002 | loss: 0.33991 - acc: 0.8582 -- iter: 0832/1275
[A[ATraining Step: 67  | total loss: [1m[32m0.31789[0m[0m | time: 285.100s
[2K
| Adam | epoch: 002 | loss: 0.31789 - acc: 0.8714 -- iter: 0864/1275
[A[ATraining Step: 68  | total loss: [1m[32m0.31293[0m[0m | time: 296.705s
[2K
| Adam | epoch: 002 | loss: 0.31293 - acc: 0.8719 -- iter: 0896/1275
[A[ATraining Step: 69  | total loss: [1m[32m0.29350[0m[0m | time: 308.732s
[2K
| Adam | epoch: 002 | loss: 0.29350 - acc: 0.8832 -- iter: 0928/1275
[A[ATraining Step: 70  | total loss: [1m[32m0.28474[0m[0m | time: 320.605s
[2K
| Adam | epoch: 002 | loss: 0.28474 - acc: 0.8822 -- iter: 0960/1275
[A[ATraining Step: 71  | total loss: [1m[32m0.28512[0m[0m | time: 332.910s
[2K
| Adam | epoch: 002 | loss: 0.28512 - acc: 0.8814 -- iter: 0992/1275
[A[ATraining Step: 72  | total loss: [1m[32m0.27521[0m[0m | time: 344.265s
[2K
| Adam | epoch: 002 | loss: 0.27521 - acc: 0.8842 -- iter: 1024/1275
[A[ATraining Step: 73  | total loss: [1m[32m0.32541[0m[0m | time: 356.232s
[2K
| Adam | epoch: 002 | loss: 0.32541 - acc: 0.8693 -- iter: 1056/1275
[A[ATraining Step: 74  | total loss: [1m[32m0.30918[0m[0m | time: 367.354s
[2K
| Adam | epoch: 002 | loss: 0.30918 - acc: 0.8768 -- iter: 1088/1275
[A[ATraining Step: 75  | total loss: [1m[32m0.29376[0m[0m | time: 375.611s
[2K
| Adam | epoch: 002 | loss: 0.29376 - acc: 0.8800 -- iter: 1120/1275
[A[ATraining Step: 76  | total loss: [1m[32m0.27637[0m[0m | time: 383.593s
[2K
| Adam | epoch: 002 | loss: 0.27637 - acc: 0.8928 -- iter: 1152/1275
[A[ATraining Step: 77  | total loss: [1m[32m0.27458[0m[0m | time: 392.384s
[2K
| Adam | epoch: 002 | loss: 0.27458 - acc: 0.8943 -- iter: 1184/1275
[A[ATraining Step: 78  | total loss: [1m[32m0.27156[0m[0m | time: 404.042s
[2K
| Adam | epoch: 002 | loss: 0.27156 - acc: 0.8922 -- iter: 1216/1275
[A[ATraining Step: 79  | total loss: [1m[32m0.25664[0m[0m | time: 415.870s
[2K
| Adam | epoch: 002 | loss: 0.25664 - acc: 0.9002 -- iter: 1248/1275
[A[ATraining Step: 80  | total loss: [1m[32m0.26944[0m[0m | time: 455.425s
[2K
| Adam | epoch: 002 | loss: 0.26944 - acc: 0.8944 | val_loss: 0.66770 - val_acc: 0.7118 -- iter: 1275/1275
--
Training Step: 81  | total loss: [1m[32m0.28187[0m[0m | time: 7.010s
[2K
| Adam | epoch: 003 | loss: 0.28187 - acc: 0.8861 -- iter: 0032/1275
[A[ATraining Step: 82  | total loss: [1m[32m0.28193[0m[0m | time: 13.901s
[2K
| Adam | epoch: 003 | loss: 0.28193 - acc: 0.8864 -- iter: 0064/1275
[A[ATraining Step: 83  | total loss: [1m[32m0.26559[0m[0m | time: 21.971s
[2K
| Adam | epoch: 003 | loss: 0.26559 - acc: 0.8903 -- iter: 0096/1275
[A[ATraining Step: 84  | total loss: [1m[32m0.26165[0m[0m | time: 32.533s
[2K
| Adam | epoch: 003 | loss: 0.26165 - acc: 0.8951 -- iter: 0128/1275
[A[ATraining Step: 85  | total loss: [1m[32m0.25306[0m[0m | time: 44.163s
[2K
| Adam | epoch: 003 | loss: 0.25306 - acc: 0.9024 -- iter: 0160/1275
[A[ATraining Step: 86  | total loss: [1m[32m0.26637[0m[0m | time: 56.336s
[2K
| Adam | epoch: 003 | loss: 0.26637 - acc: 0.8966 -- iter: 0192/1275
[A[ATraining Step: 87  | total loss: [1m[32m0.27029[0m[0m | time: 68.391s
[2K
| Adam | epoch: 003 | loss: 0.27029 - acc: 0.8944 -- iter: 0224/1275
[A[ATraining Step: 88  | total loss: [1m[32m0.27334[0m[0m | time: 80.220s
[2K
| Adam | epoch: 003 | loss: 0.27334 - acc: 0.8987 -- iter: 0256/1275
[A[ATraining Step: 89  | total loss: [1m[32m0.27143[0m[0m | time: 92.063s
[2K
| Adam | epoch: 003 | loss: 0.27143 - acc: 0.8995 -- iter: 0288/1275
[A[ATraining Step: 90  | total loss: [1m[32m0.26880[0m[0m | time: 103.505s
[2K
| Adam | epoch: 003 | loss: 0.26880 - acc: 0.8939 -- iter: 0320/1275
[A[ATraining Step: 91  | total loss: [1m[32m0.29396[0m[0m | time: 115.679s
[2K
| Adam | epoch: 003 | loss: 0.29396 - acc: 0.8826 -- iter: 0352/1275
[A[ATraining Step: 92  | total loss: [1m[32m0.27688[0m[0m | time: 123.812s
[2K
| Adam | epoch: 003 | loss: 0.27688 - acc: 0.8944 -- iter: 0384/1275
[A[ATraining Step: 93  | total loss: [1m[32m0.27348[0m[0m | time: 131.920s
[2K
| Adam | epoch: 003 | loss: 0.27348 - acc: 0.8924 -- iter: 0416/1275
[A[ATraining Step: 94  | total loss: [1m[32m0.25412[0m[0m | time: 141.444s
[2K
| Adam | epoch: 003 | loss: 0.25412 - acc: 0.9032 -- iter: 0448/1275
[A[ATraining Step: 95  | total loss: [1m[32m0.25808[0m[0m | time: 152.776s
[2K
| Adam | epoch: 003 | loss: 0.25808 - acc: 0.9035 -- iter: 0480/1275
[A[ATraining Step: 96  | total loss: [1m[32m0.26315[0m[0m | time: 164.171s
[2K
| Adam | epoch: 003 | loss: 0.26315 - acc: 0.9038 -- iter: 0512/1275
[A[ATraining Step: 97  | total loss: [1m[32m0.24794[0m[0m | time: 176.387s
[2K
| Adam | epoch: 003 | loss: 0.24794 - acc: 0.9103 -- iter: 0544/1275
[A[ATraining Step: 98  | total loss: [1m[32m0.25086[0m[0m | time: 188.412s
[2K
| Adam | epoch: 003 | loss: 0.25086 - acc: 0.9099 -- iter: 0576/1275
[A[ATraining Step: 99  | total loss: [1m[32m0.24731[0m[0m | time: 200.344s
[2K
| Adam | epoch: 003 | loss: 0.24731 - acc: 0.9064 -- iter: 0608/1275
[A[ATraining Step: 100  | total loss: [1m[32m0.23227[0m[0m | time: 212.389s
[2K
| Adam | epoch: 003 | loss: 0.23227 - acc: 0.9095 -- iter: 0640/1275
[A[ATraining Step: 101  | total loss: [1m[32m0.23987[0m[0m | time: 223.828s
[2K
| Adam | epoch: 003 | loss: 0.23987 - acc: 0.9092 -- iter: 0672/1275
[A[ATraining Step: 102  | total loss: [1m[32m0.26021[0m[0m | time: 234.017s
[2K
| Adam | epoch: 003 | loss: 0.26021 - acc: 0.8995 -- iter: 0704/1275
[A[ATraining Step: 103  | total loss: [1m[32m0.24760[0m[0m | time: 242.032s
[2K
| Adam | epoch: 003 | loss: 0.24760 - acc: 0.9033 -- iter: 0736/1275
[A[ATraining Step: 104  | total loss: [1m[32m0.27040[0m[0m | time: 249.944s
[2K
| Adam | epoch: 003 | loss: 0.27040 - acc: 0.8973 -- iter: 0768/1275
[A[ATraining Step: 105  | total loss: [1m[32m0.26318[0m[0m | time: 261.034s
[2K
| Adam | epoch: 003 | loss: 0.26318 - acc: 0.9045 -- iter: 0800/1275
[A[ATraining Step: 106  | total loss: [1m[32m0.24652[0m[0m | time: 272.700s
[2K
| Adam | epoch: 003 | loss: 0.24652 - acc: 0.9078 -- iter: 0832/1275
[A[ATraining Step: 107  | total loss: [1m[32m0.23717[0m[0m | time: 283.780s
[2K
| Adam | epoch: 003 | loss: 0.23717 - acc: 0.9076 -- iter: 0864/1275
[A[ATraining Step: 108  | total loss: [1m[32m0.22067[0m[0m | time: 295.028s
[2K
| Adam | epoch: 003 | loss: 0.22067 - acc: 0.9169 -- iter: 0896/1275
[A[ATraining Step: 109  | total loss: [1m[32m0.25126[0m[0m | time: 306.704s
[2K
| Adam | epoch: 003 | loss: 0.25126 - acc: 0.9064 -- iter: 0928/1275
[A[ATraining Step: 110  | total loss: [1m[32m0.24332[0m[0m | time: 318.536s
[2K
| Adam | epoch: 003 | loss: 0.24332 - acc: 0.9064 -- iter: 0960/1275
[A[ATraining Step: 111  | total loss: [1m[32m0.23909[0m[0m | time: 330.544s
[2K
| Adam | epoch: 003 | loss: 0.23909 - acc: 0.9095 -- iter: 0992/1275
[A[ATraining Step: 112  | total loss: [1m[32m0.22931[0m[0m | time: 342.137s
[2K
| Adam | epoch: 003 | loss: 0.22931 - acc: 0.9123 -- iter: 1024/1275
[A[ATraining Step: 113  | total loss: [1m[32m0.21745[0m[0m | time: 352.051s
[2K
| Adam | epoch: 003 | loss: 0.21745 - acc: 0.9180 -- iter: 1056/1275
[A[ATraining Step: 114  | total loss: [1m[32m0.21342[0m[0m | time: 360.139s
[2K
| Adam | epoch: 003 | loss: 0.21342 - acc: 0.9230 -- iter: 1088/1275
[A[ATraining Step: 115  | total loss: [1m[32m0.20350[0m[0m | time: 368.187s
[2K
| Adam | epoch: 003 | loss: 0.20350 - acc: 0.9245 -- iter: 1120/1275
[A[ATraining Step: 116  | total loss: [1m[32m0.19163[0m[0m | time: 376.140s
[2K
| Adam | epoch: 003 | loss: 0.19163 - acc: 0.9289 -- iter: 1152/1275
[A[ATraining Step: 117  | total loss: [1m[32m0.19222[0m[0m | time: 387.239s
[2K
| Adam | epoch: 003 | loss: 0.19222 - acc: 0.9266 -- iter: 1184/1275
[A[ATraining Step: 118  | total loss: [1m[32m0.17789[0m[0m | time: 398.876s
[2K
| Adam | epoch: 003 | loss: 0.17789 - acc: 0.9309 -- iter: 1216/1275
[A[ATraining Step: 119  | total loss: [1m[32m0.20898[0m[0m | time: 410.851s
[2K
| Adam | epoch: 003 | loss: 0.20898 - acc: 0.9221 -- iter: 1248/1275
[A[ATraining Step: 120  | total loss: [1m[32m0.19763[0m[0m | time: 448.975s
[2K
| Adam | epoch: 003 | loss: 0.19763 - acc: 0.9237 | val_loss: 0.48219 - val_acc: 0.8195 -- iter: 1275/1275
--
Training Step: 121  | total loss: [1m[32m0.18790[0m[0m | time: 10.000s
[2K
| Adam | epoch: 004 | loss: 0.18790 - acc: 0.9282 -- iter: 0032/1275
[A[ATraining Step: 122  | total loss: [1m[32m0.20572[0m[0m | time: 20.741s
[2K
| Adam | epoch: 004 | loss: 0.20572 - acc: 0.9229 -- iter: 0064/1275
[A[ATraining Step: 123  | total loss: [1m[32m0.19575[0m[0m | time: 30.776s
[2K
| Adam | epoch: 004 | loss: 0.19575 - acc: 0.9232 -- iter: 0096/1275
[A[ATraining Step: 124  | total loss: [1m[32m0.17950[0m[0m | time: 42.723s
[2K
| Adam | epoch: 004 | loss: 0.17950 - acc: 0.9309 -- iter: 0128/1275
[A[ATraining Step: 125  | total loss: [1m[32m0.16996[0m[0m | time: 54.303s
[2K
| Adam | epoch: 004 | loss: 0.16996 - acc: 0.9346 -- iter: 0160/1275
[A[ATraining Step: 126  | total loss: [1m[32m0.18620[0m[0m | time: 64.798s
[2K
| Adam | epoch: 004 | loss: 0.18620 - acc: 0.9224 -- iter: 0192/1275
[A[ATraining Step: 127  | total loss: [1m[32m0.20811[0m[0m | time: 76.575s
[2K
| Adam | epoch: 004 | loss: 0.20811 - acc: 0.9177 -- iter: 0224/1275
[A[ATraining Step: 128  | total loss: [1m[32m0.22016[0m[0m | time: 88.317s
[2K
| Adam | epoch: 004 | loss: 0.22016 - acc: 0.9165 -- iter: 0256/1275
[A[ATraining Step: 129  | total loss: [1m[32m0.21993[0m[0m | time: 100.216s
[2K
| Adam | epoch: 004 | loss: 0.21993 - acc: 0.9155 -- iter: 0288/1275
[A[ATraining Step: 130  | total loss: [1m[32m0.22642[0m[0m | time: 108.070s
[2K
| Adam | epoch: 004 | loss: 0.22642 - acc: 0.9146 -- iter: 0320/1275
[A[ATraining Step: 131  | total loss: [1m[32m0.22140[0m[0m | time: 116.091s
[2K
| Adam | epoch: 004 | loss: 0.22140 - acc: 0.9138 -- iter: 0352/1275
[A[ATraining Step: 132  | total loss: [1m[32m0.22741[0m[0m | time: 125.628s
[2K
| Adam | epoch: 004 | loss: 0.22741 - acc: 0.9099 -- iter: 0384/1275
[A[ATraining Step: 133  | total loss: [1m[32m0.23134[0m[0m | time: 137.640s
[2K
| Adam | epoch: 004 | loss: 0.23134 - acc: 0.9064 -- iter: 0416/1275
[A[ATraining Step: 134  | total loss: [1m[32m0.22731[0m[0m | time: 149.215s
[2K
| Adam | epoch: 004 | loss: 0.22731 - acc: 0.9064 -- iter: 0448/1275
[A[ATraining Step: 135  | total loss: [1m[32m0.21365[0m[0m | time: 161.194s
[2K
| Adam | epoch: 004 | loss: 0.21365 - acc: 0.9157 -- iter: 0480/1275
[A[ATraining Step: 136  | total loss: [1m[32m0.20740[0m[0m | time: 172.884s
[2K
| Adam | epoch: 004 | loss: 0.20740 - acc: 0.9210 -- iter: 0512/1275
[A[ATraining Step: 137  | total loss: [1m[32m0.19617[0m[0m | time: 184.331s
[2K
| Adam | epoch: 004 | loss: 0.19617 - acc: 0.9227 -- iter: 0544/1275
[A[ATraining Step: 138  | total loss: [1m[32m0.18841[0m[0m | time: 195.176s
[2K
| Adam | epoch: 004 | loss: 0.18841 - acc: 0.9242 -- iter: 0576/1275
[A[ATraining Step: 139  | total loss: [1m[32m0.18345[0m[0m | time: 206.593s
[2K
| Adam | epoch: 004 | loss: 0.18345 - acc: 0.9255 -- iter: 0608/1275
[A[ATraining Step: 140  | total loss: [1m[32m0.17680[0m[0m | time: 218.260s
[2K
| Adam | epoch: 004 | loss: 0.17680 - acc: 0.9267 -- iter: 0640/1275
[A[ATraining Step: 141  | total loss: [1m[32m0.17049[0m[0m | time: 226.117s
[2K
| Adam | epoch: 004 | loss: 0.17049 - acc: 0.9309 -- iter: 0672/1275
[A[ATraining Step: 142  | total loss: [1m[32m0.16102[0m[0m | time: 234.153s
[2K
| Adam | epoch: 004 | loss: 0.16102 - acc: 0.9347 -- iter: 0704/1275
[A[ATraining Step: 143  | total loss: [1m[32m0.14685[0m[0m | time: 243.436s
[2K
| Adam | epoch: 004 | loss: 0.14685 - acc: 0.9412 -- iter: 0736/1275
[A[ATraining Step: 144  | total loss: [1m[32m0.15850[0m[0m | time: 255.047s
[2K
| Adam | epoch: 004 | loss: 0.15850 - acc: 0.9408 -- iter: 0768/1275
[A[ATraining Step: 145  | total loss: [1m[32m0.14467[0m[0m | time: 266.709s
[2K
| Adam | epoch: 004 | loss: 0.14467 - acc: 0.9468 -- iter: 0800/1275
[A[ATraining Step: 146  | total loss: [1m[32m0.13971[0m[0m | time: 278.537s
[2K
| Adam | epoch: 004 | loss: 0.13971 - acc: 0.9490 -- iter: 0832/1275
[A[ATraining Step: 147  | total loss: [1m[32m0.14001[0m[0m | time: 290.576s
[2K
| Adam | epoch: 004 | loss: 0.14001 - acc: 0.9478 -- iter: 0864/1275
[A[ATraining Step: 148  | total loss: [1m[32m0.14411[0m[0m | time: 302.349s
[2K
| Adam | epoch: 004 | loss: 0.14411 - acc: 0.9468 -- iter: 0896/1275
[A[ATraining Step: 149  | total loss: [1m[32m0.13317[0m[0m | time: 314.427s
[2K
| Adam | epoch: 004 | loss: 0.13317 - acc: 0.9521 -- iter: 0928/1275
[A[ATraining Step: 150  | total loss: [1m[32m0.12578[0m[0m | time: 325.345s
[2K
| Adam | epoch: 004 | loss: 0.12578 - acc: 0.9569 -- iter: 0960/1275
[A[ATraining Step: 151  | total loss: [1m[32m0.11567[0m[0m | time: 336.008s
[2K
| Adam | epoch: 004 | loss: 0.11567 - acc: 0.9612 -- iter: 0992/1275
[A[ATraining Step: 152  | total loss: [1m[32m0.11619[0m[0m | time: 343.822s
[2K
| Adam | epoch: 004 | loss: 0.11619 - acc: 0.9588 -- iter: 1024/1275
[A[ATraining Step: 153  | total loss: [1m[32m0.11090[0m[0m | time: 351.773s
[2K
| Adam | epoch: 004 | loss: 0.11090 - acc: 0.9598 -- iter: 1056/1275
[A[ATraining Step: 154  | total loss: [1m[32m0.10721[0m[0m | time: 360.159s
[2K
| Adam | epoch: 004 | loss: 0.10721 - acc: 0.9607 -- iter: 1088/1275
[A[ATraining Step: 155  | total loss: [1m[32m0.10675[0m[0m | time: 371.937s
[2K
| Adam | epoch: 004 | loss: 0.10675 - acc: 0.9615 -- iter: 1120/1275
[A[ATraining Step: 156  | total loss: [1m[32m0.12234[0m[0m | time: 384.013s
[2K
| Adam | epoch: 004 | loss: 0.12234 - acc: 0.9560 -- iter: 1152/1275
[A[ATraining Step: 157  | total loss: [1m[32m0.11895[0m[0m | time: 396.346s
[2K
| Adam | epoch: 004 | loss: 0.11895 - acc: 0.9573 -- iter: 1184/1275
[A[ATraining Step: 158  | total loss: [1m[32m0.13333[0m[0m | time: 408.189s
[2K
| Adam | epoch: 004 | loss: 0.13333 - acc: 0.9522 -- iter: 1216/1275
[A[ATraining Step: 159  | total loss: [1m[32m0.12366[0m[0m | time: 419.791s
[2K
| Adam | epoch: 004 | loss: 0.12366 - acc: 0.9570 -- iter: 1248/1275
[A[ATraining Step: 160  | total loss: [1m[32m0.12121[0m[0m | time: 458.344s
[2K
| Adam | epoch: 004 | loss: 0.12121 - acc: 0.9550 | val_loss: 1.07014 - val_acc: 0.6842 -- iter: 1275/1275
--
Training Step: 161  | total loss: [1m[32m0.12145[0m[0m | time: 8.333s
[2K
| Adam | epoch: 005 | loss: 0.12145 - acc: 0.9564 -- iter: 0032/1275
[A[ATraining Step: 162  | total loss: [1m[32m0.13770[0m[0m | time: 19.825s
[2K
| Adam | epoch: 005 | loss: 0.13770 - acc: 0.9545 -- iter: 0064/1275
[A[ATraining Step: 163  | total loss: [1m[32m0.15070[0m[0m | time: 30.330s
[2K
| Adam | epoch: 005 | loss: 0.15070 - acc: 0.9465 -- iter: 0096/1275
[A[ATraining Step: 164  | total loss: [1m[32m0.15156[0m[0m | time: 41.033s
[2K
| Adam | epoch: 005 | loss: 0.15156 - acc: 0.9371 -- iter: 0128/1275
[A[ATraining Step: 165  | total loss: [1m[32m0.13908[0m[0m | time: 53.222s
[2K
| Adam | epoch: 005 | loss: 0.13908 - acc: 0.9434 -- iter: 0160/1275
[A[ATraining Step: 166  | total loss: [1m[32m0.18011[0m[0m | time: 64.901s
[2K
| Adam | epoch: 005 | loss: 0.18011 - acc: 0.9334 -- iter: 0192/1275
[A[ATraining Step: 167  | total loss: [1m[32m0.17690[0m[0m | time: 76.849s
[2K
| Adam | epoch: 005 | loss: 0.17690 - acc: 0.9338 -- iter: 0224/1275
[A[ATraining Step: 168  | total loss: [1m[32m0.17080[0m[0m | time: 89.074s
[2K
| Adam | epoch: 005 | loss: 0.17080 - acc: 0.9342 -- iter: 0256/1275
[A[ATraining Step: 169  | total loss: [1m[32m0.16696[0m[0m | time: 101.258s
[2K
| Adam | epoch: 005 | loss: 0.16696 - acc: 0.9314 -- iter: 0288/1275
[A[ATraining Step: 170  | total loss: [1m[32m0.17050[0m[0m | time: 112.441s
[2K
| Adam | epoch: 005 | loss: 0.17050 - acc: 0.9320 -- iter: 0320/1275
[A[ATraining Step: 171  | total loss: [1m[32m0.19779[0m[0m | time: 120.266s
[2K
| Adam | epoch: 005 | loss: 0.19779 - acc: 0.9232 -- iter: 0352/1275
[A[ATraining Step: 172  | total loss: [1m[32m0.20415[0m[0m | time: 128.369s
[2K
| Adam | epoch: 005 | loss: 0.20415 - acc: 0.9277 -- iter: 0384/1275
[A[ATraining Step: 173  | total loss: [1m[32m0.22694[0m[0m | time: 136.317s
[2K
| Adam | epoch: 005 | loss: 0.22694 - acc: 0.9193 -- iter: 0416/1275
[A[ATraining Step: 174  | total loss: [1m[32m0.21469[0m[0m | time: 144.428s
[2K
| Adam | epoch: 005 | loss: 0.21469 - acc: 0.9243 -- iter: 0448/1275
[A[ATraining Step: 175  | total loss: [1m[32m0.21372[0m[0m | time: 152.918s
[2K
| Adam | epoch: 005 | loss: 0.21372 - acc: 0.9256 -- iter: 0480/1275
[A[ATraining Step: 176  | total loss: [1m[32m0.21847[0m[0m | time: 164.045s
[2K
| Adam | epoch: 005 | loss: 0.21847 - acc: 0.9237 -- iter: 0512/1275
[A[ATraining Step: 177  | total loss: [1m[32m0.21545[0m[0m | time: 176.066s
[2K
| Adam | epoch: 005 | loss: 0.21545 - acc: 0.9219 -- iter: 0544/1275
[A[ATraining Step: 178  | total loss: [1m[32m0.20645[0m[0m | time: 188.156s
[2K
| Adam | epoch: 005 | loss: 0.20645 - acc: 0.9266 -- iter: 0576/1275
[A[ATraining Step: 179  | total loss: [1m[32m0.19646[0m[0m | time: 199.974s
[2K
| Adam | epoch: 005 | loss: 0.19646 - acc: 0.9277 -- iter: 0608/1275
[A[ATraining Step: 180  | total loss: [1m[32m0.18120[0m[0m | time: 211.655s
[2K
| Adam | epoch: 005 | loss: 0.18120 - acc: 0.9349 -- iter: 0640/1275
[A[ATraining Step: 181  | total loss: [1m[32m0.17052[0m[0m | time: 223.586s
[2K
| Adam | epoch: 005 | loss: 0.17052 - acc: 0.9414 -- iter: 0672/1275
[A[ATraining Step: 182  | total loss: [1m[32m0.16353[0m[0m | time: 235.200s
[2K
| Adam | epoch: 005 | loss: 0.16353 - acc: 0.9442 -- iter: 0704/1275
[A[ATraining Step: 183  | total loss: [1m[32m0.16813[0m[0m | time: 246.262s
[2K
| Adam | epoch: 005 | loss: 0.16813 - acc: 0.9404 -- iter: 0736/1275
[A[ATraining Step: 184  | total loss: [1m[32m0.16425[0m[0m | time: 254.298s
[2K
| Adam | epoch: 005 | loss: 0.16425 - acc: 0.9370 -- iter: 0768/1275
[A[ATraining Step: 185  | total loss: [1m[32m0.16594[0m[0m | time: 262.357s
[2K
| Adam | epoch: 005 | loss: 0.16594 - acc: 0.9401 -- iter: 0800/1275
[A[ATraining Step: 186  | total loss: [1m[32m0.15785[0m[0m | time: 270.232s
[2K
| Adam | epoch: 005 | loss: 0.15785 - acc: 0.9430 -- iter: 0832/1275
[A[ATraining Step: 187  | total loss: [1m[32m0.16796[0m[0m | time: 281.774s
[2K
| Adam | epoch: 005 | loss: 0.16796 - acc: 0.9393 -- iter: 0864/1275
[A[ATraining Step: 188  | total loss: [1m[32m0.15882[0m[0m | time: 291.872s
[2K
| Adam | epoch: 005 | loss: 0.15882 - acc: 0.9423 -- iter: 0896/1275
[A[ATraining Step: 189  | total loss: [1m[32m0.16146[0m[0m | time: 303.692s
[2K
| Adam | epoch: 005 | loss: 0.16146 - acc: 0.9418 -- iter: 0928/1275
[A[ATraining Step: 190  | total loss: [1m[32m0.16325[0m[0m | time: 315.163s
[2K
| Adam | epoch: 005 | loss: 0.16325 - acc: 0.9414 -- iter: 0960/1275
[A[ATraining Step: 191  | total loss: [1m[32m0.15166[0m[0m | time: 327.139s
[2K
| Adam | epoch: 005 | loss: 0.15166 - acc: 0.9441 -- iter: 0992/1275
[A[ATraining Step: 192  | total loss: [1m[32m0.13842[0m[0m | time: 339.055s
[2K
| Adam | epoch: 005 | loss: 0.13842 - acc: 0.9497 -- iter: 1024/1275
[A[ATraining Step: 193  | total loss: [1m[32m0.14511[0m[0m | time: 350.841s
[2K
| Adam | epoch: 005 | loss: 0.14511 - acc: 0.9453 -- iter: 1056/1275
[A[ATraining Step: 194  | total loss: [1m[32m0.14360[0m[0m | time: 363.450s
[2K
| Adam | epoch: 005 | loss: 0.14360 - acc: 0.9446 -- iter: 1088/1275
[A[ATraining Step: 195  | total loss: [1m[32m0.14085[0m[0m | time: 371.667s
[2K
| Adam | epoch: 005 | loss: 0.14085 - acc: 0.9407 -- iter: 1120/1275
[A[ATraining Step: 196  | total loss: [1m[32m0.17717[0m[0m | time: 379.636s
[2K
| Adam | epoch: 005 | loss: 0.17717 - acc: 0.9310 -- iter: 1152/1275
[A[ATraining Step: 197  | total loss: [1m[32m0.18999[0m[0m | time: 387.671s
[2K
| Adam | epoch: 005 | loss: 0.18999 - acc: 0.9286 -- iter: 1184/1275
[A[ATraining Step: 198  | total loss: [1m[32m0.17876[0m[0m | time: 399.316s
[2K
| Adam | epoch: 005 | loss: 0.17876 - acc: 0.9326 -- iter: 1216/1275
[A[ATraining Step: 199  | total loss: [1m[32m0.17038[0m[0m | time: 411.183s
[2K
| Adam | epoch: 005 | loss: 0.17038 - acc: 0.9362 -- iter: 1248/1275
[A[ATraining Step: 200  | total loss: [1m[32m0.16795[0m[0m | time: 449.428s
[2K
| Adam | epoch: 005 | loss: 0.16795 - acc: 0.9363 | val_loss: 0.34432 - val_acc: 0.8722 -- iter: 1275/1275
--
Training Step: 201  | total loss: [1m[32m0.20642[0m[0m | time: 10.131s
[2K
| Adam | epoch: 006 | loss: 0.20642 - acc: 0.9239 -- iter: 0032/1275
[A[ATraining Step: 202  | total loss: [1m[32m0.19055[0m[0m | time: 21.824s
[2K
| Adam | epoch: 006 | loss: 0.19055 - acc: 0.9315 -- iter: 0064/1275
[A[ATraining Step: 203  | total loss: [1m[32m0.20242[0m[0m | time: 33.824s
[2K
| Adam | epoch: 006 | loss: 0.20242 - acc: 0.9228 -- iter: 0096/1275
[A[ATraining Step: 204  | total loss: [1m[32m0.19249[0m[0m | time: 43.929s
[2K
| Adam | epoch: 006 | loss: 0.19249 - acc: 0.9242 -- iter: 0128/1275
[A[ATraining Step: 205  | total loss: [1m[32m0.19341[0m[0m | time: 53.297s
[2K
| Adam | epoch: 006 | loss: 0.19341 - acc: 0.9244 -- iter: 0160/1275
[A[ATraining Step: 206  | total loss: [1m[32m0.18647[0m[0m | time: 65.027s
[2K
| Adam | epoch: 006 | loss: 0.18647 - acc: 0.9283 -- iter: 0192/1275
[A[ATraining Step: 207  | total loss: [1m[32m0.17609[0m[0m | time: 77.833s
[2K
| Adam | epoch: 006 | loss: 0.17609 - acc: 0.9323 -- iter: 0224/1275
[A[ATraining Step: 208  | total loss: [1m[32m0.17597[0m[0m | time: 89.815s
[2K
| Adam | epoch: 006 | loss: 0.17597 - acc: 0.9328 -- iter: 0256/1275
[A[ATraining Step: 209  | total loss: [1m[32m0.16764[0m[0m | time: 101.188s
[2K
| Adam | epoch: 006 | loss: 0.16764 - acc: 0.9364 -- iter: 0288/1275
[A[ATraining Step: 210  | total loss: [1m[32m0.16382[0m[0m | time: 109.065s
[2K
| Adam | epoch: 006 | loss: 0.16382 - acc: 0.9365 -- iter: 0320/1275
[A[ATraining Step: 211  | total loss: [1m[32m0.15123[0m[0m | time: 117.052s
[2K
| Adam | epoch: 006 | loss: 0.15123 - acc: 0.9429 -- iter: 0352/1275
[A[ATraining Step: 212  | total loss: [1m[32m0.13857[0m[0m | time: 126.465s
[2K
| Adam | epoch: 006 | loss: 0.13857 - acc: 0.9486 -- iter: 0384/1275
[A[ATraining Step: 213  | total loss: [1m[32m0.13137[0m[0m | time: 138.999s
[2K
| Adam | epoch: 006 | loss: 0.13137 - acc: 0.9506 -- iter: 0416/1275
[A[ATraining Step: 214  | total loss: [1m[32m0.26560[0m[0m | time: 150.800s
[2K
| Adam | epoch: 006 | loss: 0.26560 - acc: 0.9274 -- iter: 0448/1275
[A[ATraining Step: 215  | total loss: [1m[32m0.26023[0m[0m | time: 162.600s
[2K
| Adam | epoch: 006 | loss: 0.26023 - acc: 0.9284 -- iter: 0480/1275
[A[ATraining Step: 216  | total loss: [1m[32m0.25368[0m[0m | time: 174.811s
[2K
| Adam | epoch: 006 | loss: 0.25368 - acc: 0.9293 -- iter: 0512/1275
[A[ATraining Step: 217  | total loss: [1m[32m0.24066[0m[0m | time: 184.712s
[2K
| Adam | epoch: 006 | loss: 0.24066 - acc: 0.9302 -- iter: 0544/1275
[A[ATraining Step: 218  | total loss: [1m[32m0.24009[0m[0m | time: 199.208s
[2K
| Adam | epoch: 006 | loss: 0.24009 - acc: 0.9309 -- iter: 0576/1275
[A[ATraining Step: 219  | total loss: [1m[32m0.22286[0m[0m | time: 210.936s
[2K
| Adam | epoch: 006 | loss: 0.22286 - acc: 0.9347 -- iter: 0608/1275
[A[ATraining Step: 220  | total loss: [1m[32m0.22305[0m[0m | time: 222.187s
[2K
| Adam | epoch: 006 | loss: 0.22305 - acc: 0.9287 -- iter: 0640/1275
[A[ATraining Step: 221  | total loss: [1m[32m0.21023[0m[0m | time: 230.014s
[2K
| Adam | epoch: 006 | loss: 0.21023 - acc: 0.9358 -- iter: 0672/1275
[A[ATraining Step: 222  | total loss: [1m[32m0.21083[0m[0m | time: 237.972s
[2K
| Adam | epoch: 006 | loss: 0.21083 - acc: 0.9360 -- iter: 0704/1275
[A[ATraining Step: 223  | total loss: [1m[32m0.19649[0m[0m | time: 247.031s
[2K
| Adam | epoch: 006 | loss: 0.19649 - acc: 0.9393 -- iter: 0736/1275
[A[ATraining Step: 224  | total loss: [1m[32m0.18440[0m[0m | time: 258.522s
[2K
| Adam | epoch: 006 | loss: 0.18440 - acc: 0.9453 -- iter: 0768/1275
[A[ATraining Step: 225  | total loss: [1m[32m0.17836[0m[0m | time: 270.539s
[2K
| Adam | epoch: 006 | loss: 0.17836 - acc: 0.9446 -- iter: 0800/1275
[A[ATraining Step: 226  | total loss: [1m[32m0.18009[0m[0m | time: 286.680s
[2K
| Adam | epoch: 006 | loss: 0.18009 - acc: 0.9407 -- iter: 0832/1275
[A[ATraining Step: 227  | total loss: [1m[32m0.17875[0m[0m | time: 298.360s
[2K
| Adam | epoch: 006 | loss: 0.17875 - acc: 0.9404 -- iter: 0864/1275
[A[ATraining Step: 228  | total loss: [1m[32m0.17275[0m[0m | time: 310.250s
[2K
| Adam | epoch: 006 | loss: 0.17275 - acc: 0.9432 -- iter: 0896/1275
[A[ATraining Step: 229  | total loss: [1m[32m0.16390[0m[0m | time: 321.147s
[2K
| Adam | epoch: 006 | loss: 0.16390 - acc: 0.9489 -- iter: 0928/1275
[A[ATraining Step: 230  | total loss: [1m[32m0.16380[0m[0m | time: 332.511s
[2K
| Adam | epoch: 006 | loss: 0.16380 - acc: 0.9478 -- iter: 0960/1275
[A[ATraining Step: 231  | total loss: [1m[32m0.16532[0m[0m | time: 343.972s
[2K
| Adam | epoch: 006 | loss: 0.16532 - acc: 0.9467 -- iter: 0992/1275
[A[ATraining Step: 232  | total loss: [1m[32m0.18103[0m[0m | time: 351.892s
[2K
| Adam | epoch: 006 | loss: 0.18103 - acc: 0.9364 -- iter: 1024/1275
[A[ATraining Step: 233  | total loss: [1m[32m0.16823[0m[0m | time: 359.900s
[2K
| Adam | epoch: 006 | loss: 0.16823 - acc: 0.9428 -- iter: 1056/1275
[A[ATraining Step: 234  | total loss: [1m[32m0.17430[0m[0m | time: 367.922s
[2K
| Adam | epoch: 006 | loss: 0.17430 - acc: 0.9423 -- iter: 1088/1275
[A[ATraining Step: 235  | total loss: [1m[32m0.16935[0m[0m | time: 375.931s
[2K
| Adam | epoch: 006 | loss: 0.16935 - acc: 0.9418 -- iter: 1120/1275
[A[ATraining Step: 236  | total loss: [1m[32m0.15902[0m[0m | time: 385.203s
[2K
| Adam | epoch: 006 | loss: 0.15902 - acc: 0.9445 -- iter: 1152/1275
[A[ATraining Step: 237  | total loss: [1m[32m0.15092[0m[0m | time: 397.695s
[2K
| Adam | epoch: 006 | loss: 0.15092 - acc: 0.9469 -- iter: 1184/1275
[A[ATraining Step: 238  | total loss: [1m[32m0.16080[0m[0m | time: 409.406s
[2K
| Adam | epoch: 006 | loss: 0.16080 - acc: 0.9460 -- iter: 1216/1275
[A[ATraining Step: 239  | total loss: [1m[32m0.15220[0m[0m | time: 421.317s
[2K
| Adam | epoch: 006 | loss: 0.15220 - acc: 0.9483 -- iter: 1248/1275
[A[ATraining Step: 240  | total loss: [1m[32m0.15399[0m[0m | time: 464.486s
[2K
| Adam | epoch: 006 | loss: 0.15399 - acc: 0.9441 | val_loss: 0.44495 - val_acc: 0.8571 -- iter: 1275/1275
--
Training Step: 241  | total loss: [1m[32m0.15144[0m[0m | time: 8.140s
[2K
| Adam | epoch: 007 | loss: 0.15144 - acc: 0.9465 -- iter: 0032/1275
[A[ATraining Step: 242  | total loss: [1m[32m0.13979[0m[0m | time: 21.040s
[2K
| Adam | epoch: 007 | loss: 0.13979 - acc: 0.9519 -- iter: 0064/1275
[A[ATraining Step: 243  | total loss: [1m[32m0.12762[0m[0m | time: 32.758s
[2K
| Adam | epoch: 007 | loss: 0.12762 - acc: 0.9567 -- iter: 0096/1275
[A[ATraining Step: 244  | total loss: [1m[32m0.13032[0m[0m | time: 44.610s
[2K
| Adam | epoch: 007 | loss: 0.13032 - acc: 0.9548 -- iter: 0128/1275
[A[ATraining Step: 245  | total loss: [1m[32m0.13150[0m[0m | time: 55.350s
[2K
| Adam | epoch: 007 | loss: 0.13150 - acc: 0.9530 -- iter: 0160/1275
[A[ATraining Step: 246  | total loss: [1m[32m0.11992[0m[0m | time: 65.899s
[2K
| Adam | epoch: 007 | loss: 0.11992 - acc: 0.9577 -- iter: 0192/1275
[A[ATraining Step: 247  | total loss: [1m[32m0.10915[0m[0m | time: 77.403s
[2K
| Adam | epoch: 007 | loss: 0.10915 - acc: 0.9620 -- iter: 0224/1275
[A[ATraining Step: 248  | total loss: [1m[32m0.11728[0m[0m | time: 89.614s
[2K
| Adam | epoch: 007 | loss: 0.11728 - acc: 0.9564 -- iter: 0256/1275
[A[ATraining Step: 249  | total loss: [1m[32m0.11386[0m[0m | time: 101.663s
[2K
| Adam | epoch: 007 | loss: 0.11386 - acc: 0.9576 -- iter: 0288/1275
[A[ATraining Step: 250  | total loss: [1m[32m0.11143[0m[0m | time: 112.825s
[2K
| Adam | epoch: 007 | loss: 0.11143 - acc: 0.9587 -- iter: 0320/1275
[A[ATraining Step: 251  | total loss: [1m[32m0.11230[0m[0m | time: 120.733s
[2K
| Adam | epoch: 007 | loss: 0.11230 - acc: 0.9566 -- iter: 0352/1275
[A[ATraining Step: 252  | total loss: [1m[32m0.10825[0m[0m | time: 128.767s
[2K
| Adam | epoch: 007 | loss: 0.10825 - acc: 0.9578 -- iter: 0384/1275
[A[ATraining Step: 253  | total loss: [1m[32m0.09947[0m[0m | time: 137.250s
[2K
| Adam | epoch: 007 | loss: 0.09947 - acc: 0.9620 -- iter: 0416/1275
[A[ATraining Step: 254  | total loss: [1m[32m0.10070[0m[0m | time: 149.022s
[2K
| Adam | epoch: 007 | loss: 0.10070 - acc: 0.9596 -- iter: 0448/1275
[A[ATraining Step: 255  | total loss: [1m[32m0.11777[0m[0m | time: 160.981s
[2K
| Adam | epoch: 007 | loss: 0.11777 - acc: 0.9574 -- iter: 0480/1275
[A[ATraining Step: 256  | total loss: [1m[32m0.10978[0m[0m | time: 172.867s
[2K
| Adam | epoch: 007 | loss: 0.10978 - acc: 0.9616 -- iter: 0512/1275
[A[ATraining Step: 257  | total loss: [1m[32m0.10004[0m[0m | time: 184.612s
[2K
| Adam | epoch: 007 | loss: 0.10004 - acc: 0.9655 -- iter: 0544/1275
[A[ATraining Step: 258  | total loss: [1m[32m0.09406[0m[0m | time: 196.688s
[2K
| Adam | epoch: 007 | loss: 0.09406 - acc: 0.9689 -- iter: 0576/1275
[A[ATraining Step: 259  | total loss: [1m[32m0.08896[0m[0m | time: 208.655s
[2K
| Adam | epoch: 007 | loss: 0.08896 - acc: 0.9720 -- iter: 0608/1275
[A[ATraining Step: 260  | total loss: [1m[32m0.08483[0m[0m | time: 220.832s
[2K
| Adam | epoch: 007 | loss: 0.08483 - acc: 0.9748 -- iter: 0640/1275
[A[ATraining Step: 261  | total loss: [1m[32m0.08074[0m[0m | time: 232.673s
[2K
| Adam | epoch: 007 | loss: 0.08074 - acc: 0.9774 -- iter: 0672/1275
[A[ATraining Step: 262  | total loss: [1m[32m0.07620[0m[0m | time: 242.706s
[2K
| Adam | epoch: 007 | loss: 0.07620 - acc: 0.9796 -- iter: 0704/1275
[A[ATraining Step: 263  | total loss: [1m[32m0.08782[0m[0m | time: 250.590s
[2K
| Adam | epoch: 007 | loss: 0.08782 - acc: 0.9785 -- iter: 0736/1275
[A[ATraining Step: 264  | total loss: [1m[32m0.09774[0m[0m | time: 258.641s
[2K
| Adam | epoch: 007 | loss: 0.09774 - acc: 0.9713 -- iter: 0768/1275
[A[ATraining Step: 265  | total loss: [1m[32m0.09134[0m[0m | time: 267.636s
[2K
| Adam | epoch: 007 | loss: 0.09134 - acc: 0.9742 -- iter: 0800/1275
[A[ATraining Step: 266  | total loss: [1m[32m0.08550[0m[0m | time: 279.054s
[2K
| Adam | epoch: 007 | loss: 0.08550 - acc: 0.9768 -- iter: 0832/1275
[A[ATraining Step: 267  | total loss: [1m[32m0.08535[0m[0m | time: 291.007s
[2K
| Adam | epoch: 007 | loss: 0.08535 - acc: 0.9728 -- iter: 0864/1275
[A[ATraining Step: 268  | total loss: [1m[32m0.08173[0m[0m | time: 303.051s
[2K
| Adam | epoch: 007 | loss: 0.08173 - acc: 0.9755 -- iter: 0896/1275
[A[ATraining Step: 269  | total loss: [1m[32m0.07726[0m[0m | time: 315.150s
[2K
| Adam | epoch: 007 | loss: 0.07726 - acc: 0.9780 -- iter: 0928/1275
[A[ATraining Step: 270  | total loss: [1m[32m0.07935[0m[0m | time: 327.387s
[2K
| Adam | epoch: 007 | loss: 0.07935 - acc: 0.9739 -- iter: 0960/1275
[A[ATraining Step: 271  | total loss: [1m[32m0.07364[0m[0m | time: 339.442s
[2K
| Adam | epoch: 007 | loss: 0.07364 - acc: 0.9765 -- iter: 0992/1275
[A[ATraining Step: 272  | total loss: [1m[32m0.06875[0m[0m | time: 350.986s
[2K
| Adam | epoch: 007 | loss: 0.06875 - acc: 0.9789 -- iter: 1024/1275
[A[ATraining Step: 273  | total loss: [1m[32m0.06283[0m[0m | time: 360.660s
[2K
| Adam | epoch: 007 | loss: 0.06283 - acc: 0.9810 -- iter: 1056/1275
[A[ATraining Step: 274  | total loss: [1m[32m0.06465[0m[0m | time: 368.492s
[2K
| Adam | epoch: 007 | loss: 0.06465 - acc: 0.9829 -- iter: 1088/1275
[A[ATraining Step: 275  | total loss: [1m[32m0.06100[0m[0m | time: 376.584s
[2K
| Adam | epoch: 007 | loss: 0.06100 - acc: 0.9846 -- iter: 1120/1275
[A[ATraining Step: 276  | total loss: [1m[32m0.05623[0m[0m | time: 384.467s
[2K
| Adam | epoch: 007 | loss: 0.05623 - acc: 0.9862 -- iter: 1152/1275
[A[ATraining Step: 277  | total loss: [1m[32m0.05866[0m[0m | time: 395.708s
[2K
| Adam | epoch: 007 | loss: 0.05866 - acc: 0.9844 -- iter: 1184/1275
[A[ATraining Step: 278  | total loss: [1m[32m0.05931[0m[0m | time: 404.718s
[2K
| Adam | epoch: 007 | loss: 0.05931 - acc: 0.9828 -- iter: 1216/1275
[A[ATraining Step: 279  | total loss: [1m[32m0.07000[0m[0m | time: 412.659s
[2K
| Adam | epoch: 007 | loss: 0.07000 - acc: 0.9783 -- iter: 1248/1275
[A[ATraining Step: 280  | total loss: [1m[32m0.06393[0m[0m | time: 438.699s
[2K
| Adam | epoch: 007 | loss: 0.06393 - acc: 0.9805 | val_loss: 0.30695 - val_acc: 0.8997 -- iter: 1275/1275
--
Training Step: 281  | total loss: [1m[32m0.06139[0m[0m | time: 8.151s
[2K
| Adam | epoch: 008 | loss: 0.06139 - acc: 0.9824 -- iter: 0032/1275
[A[ATraining Step: 282  | total loss: [1m[32m0.08496[0m[0m | time: 16.041s
[2K
| Adam | epoch: 008 | loss: 0.08496 - acc: 0.9779 -- iter: 0064/1275
[A[ATraining Step: 283  | total loss: [1m[32m0.08009[0m[0m | time: 24.120s
[2K
| Adam | epoch: 008 | loss: 0.08009 - acc: 0.9801 -- iter: 0096/1275
[A[ATraining Step: 284  | total loss: [1m[32m0.08405[0m[0m | time: 31.905s
[2K
| Adam | epoch: 008 | loss: 0.08405 - acc: 0.9759 -- iter: 0128/1275
[A[ATraining Step: 285  | total loss: [1m[32m0.08182[0m[0m | time: 39.717s
[2K
| Adam | epoch: 008 | loss: 0.08182 - acc: 0.9752 -- iter: 0160/1275
[A[ATraining Step: 286  | total loss: [1m[32m0.08200[0m[0m | time: 46.663s
[2K
| Adam | epoch: 008 | loss: 0.08200 - acc: 0.9745 -- iter: 0192/1275
[A[ATraining Step: 287  | total loss: [1m[32m0.08210[0m[0m | time: 53.698s
[2K
| Adam | epoch: 008 | loss: 0.08210 - acc: 0.9734 -- iter: 0224/1275
[A[ATraining Step: 288  | total loss: [1m[32m0.07541[0m[0m | time: 61.694s
[2K
| Adam | epoch: 008 | loss: 0.07541 - acc: 0.9760 -- iter: 0256/1275
[A[ATraining Step: 289  | total loss: [1m[32m0.07074[0m[0m | time: 69.575s
[2K
| Adam | epoch: 008 | loss: 0.07074 - acc: 0.9784 -- iter: 0288/1275
[A[ATraining Step: 290  | total loss: [1m[32m0.07138[0m[0m | time: 77.664s
[2K
| Adam | epoch: 008 | loss: 0.07138 - acc: 0.9775 -- iter: 0320/1275
[A[ATraining Step: 291  | total loss: [1m[32m0.07078[0m[0m | time: 85.592s
[2K
| Adam | epoch: 008 | loss: 0.07078 - acc: 0.9766 -- iter: 0352/1275
[A[ATraining Step: 292  | total loss: [1m[32m0.08479[0m[0m | time: 93.595s
[2K
| Adam | epoch: 008 | loss: 0.08479 - acc: 0.9664 -- iter: 0384/1275
[A[ATraining Step: 293  | total loss: [1m[32m0.08275[0m[0m | time: 101.501s
[2K
| Adam | epoch: 008 | loss: 0.08275 - acc: 0.9635 -- iter: 0416/1275
[A[ATraining Step: 294  | total loss: [1m[32m0.08305[0m[0m | time: 109.436s
[2K
| Adam | epoch: 008 | loss: 0.08305 - acc: 0.9641 -- iter: 0448/1275
[A[ATraining Step: 295  | total loss: [1m[32m0.08234[0m[0m | time: 117.371s
[2K
| Adam | epoch: 008 | loss: 0.08234 - acc: 0.9614 -- iter: 0480/1275
[A[ATraining Step: 296  | total loss: [1m[32m0.16013[0m[0m | time: 125.689s
[2K
| Adam | epoch: 008 | loss: 0.16013 - acc: 0.9559 -- iter: 0512/1275
[A[ATraining Step: 297  | total loss: [1m[32m0.14670[0m[0m | time: 133.691s
[2K
| Adam | epoch: 008 | loss: 0.14670 - acc: 0.9603 -- iter: 0544/1275
[A[ATraining Step: 298  | total loss: [1m[32m0.14365[0m[0m | time: 141.762s
[2K
| Adam | epoch: 008 | loss: 0.14365 - acc: 0.9580 -- iter: 0576/1275
[A[ATraining Step: 299  | total loss: [1m[32m0.13862[0m[0m | time: 149.848s
[2K
| Adam | epoch: 008 | loss: 0.13862 - acc: 0.9591 -- iter: 0608/1275
[A[ATraining Step: 300  | total loss: [1m[32m0.13556[0m[0m | time: 157.654s
[2K
| Adam | epoch: 008 | loss: 0.13556 - acc: 0.9601 -- iter: 0640/1275
[A[ATraining Step: 301  | total loss: [1m[32m0.14797[0m[0m | time: 165.748s
[2K
| Adam | epoch: 008 | loss: 0.14797 - acc: 0.9484 -- iter: 0672/1275
[A[ATraining Step: 302  | total loss: [1m[32m0.13544[0m[0m | time: 173.719s
[2K
| Adam | epoch: 008 | loss: 0.13544 - acc: 0.9536 -- iter: 0704/1275
[A[ATraining Step: 303  | total loss: [1m[32m0.13264[0m[0m | time: 181.811s
[2K
| Adam | epoch: 008 | loss: 0.13264 - acc: 0.9520 -- iter: 0736/1275
[A[ATraining Step: 304  | total loss: [1m[32m0.12089[0m[0m | time: 190.113s
[2K
| Adam | epoch: 008 | loss: 0.12089 - acc: 0.9568 -- iter: 0768/1275
[A[ATraining Step: 305  | total loss: [1m[32m0.11802[0m[0m | time: 197.960s
[2K
| Adam | epoch: 008 | loss: 0.11802 - acc: 0.9580 -- iter: 0800/1275
[A[ATraining Step: 306  | total loss: [1m[32m0.11455[0m[0m | time: 205.972s
[2K
| Adam | epoch: 008 | loss: 0.11455 - acc: 0.9591 -- iter: 0832/1275
[A[ATraining Step: 307  | total loss: [1m[32m0.11958[0m[0m | time: 213.795s
[2K
| Adam | epoch: 008 | loss: 0.11958 - acc: 0.9600 -- iter: 0864/1275
[A[ATraining Step: 308  | total loss: [1m[32m0.12283[0m[0m | time: 222.031s
[2K
| Adam | epoch: 008 | loss: 0.12283 - acc: 0.9609 -- iter: 0896/1275
[A[ATraining Step: 309  | total loss: [1m[32m0.12455[0m[0m | time: 230.080s
[2K
| Adam | epoch: 008 | loss: 0.12455 - acc: 0.9586 -- iter: 0928/1275
[A[ATraining Step: 310  | total loss: [1m[32m0.11539[0m[0m | time: 238.014s
[2K
| Adam | epoch: 008 | loss: 0.11539 - acc: 0.9627 -- iter: 0960/1275
[A[ATraining Step: 311  | total loss: [1m[32m0.10701[0m[0m | time: 245.952s
[2K
| Adam | epoch: 008 | loss: 0.10701 - acc: 0.9664 -- iter: 0992/1275
[A[ATraining Step: 312  | total loss: [1m[32m0.10444[0m[0m | time: 253.967s
[2K
| Adam | epoch: 008 | loss: 0.10444 - acc: 0.9667 -- iter: 1024/1275
[A[ATraining Step: 313  | total loss: [1m[32m0.10305[0m[0m | time: 261.870s
[2K
| Adam | epoch: 008 | loss: 0.10305 - acc: 0.9669 -- iter: 1056/1275
[A[ATraining Step: 314  | total loss: [1m[32m0.10058[0m[0m | time: 269.731s
[2K
| Adam | epoch: 008 | loss: 0.10058 - acc: 0.9671 -- iter: 1088/1275
[A[ATraining Step: 315  | total loss: [1m[32m0.10346[0m[0m | time: 277.656s
[2K
| Adam | epoch: 008 | loss: 0.10346 - acc: 0.9610 -- iter: 1120/1275
[A[ATraining Step: 316  | total loss: [1m[32m0.10160[0m[0m | time: 285.784s
[2K
| Adam | epoch: 008 | loss: 0.10160 - acc: 0.9586 -- iter: 1152/1275
[A[ATraining Step: 317  | total loss: [1m[32m0.09990[0m[0m | time: 293.608s
[2K
| Adam | epoch: 008 | loss: 0.09990 - acc: 0.9565 -- iter: 1184/1275
[A[ATraining Step: 318  | total loss: [1m[32m0.09992[0m[0m | time: 301.458s
[2K
| Adam | epoch: 008 | loss: 0.09992 - acc: 0.9577 -- iter: 1216/1275
[A[ATraining Step: 319  | total loss: [1m[32m0.09580[0m[0m | time: 309.487s
[2K
| Adam | epoch: 008 | loss: 0.09580 - acc: 0.9620 -- iter: 1248/1275
[A[ATraining Step: 320  | total loss: [1m[32m0.09516[0m[0m | time: 335.908s
[2K
| Adam | epoch: 008 | loss: 0.09516 - acc: 0.9595 | val_loss: 0.35394 - val_acc: 0.8922 -- iter: 1275/1275
--
Training Step: 321  | total loss: [1m[32m0.09065[0m[0m | time: 7.810s
[2K
| Adam | epoch: 009 | loss: 0.09065 - acc: 0.9604 -- iter: 0032/1275
[A[ATraining Step: 322  | total loss: [1m[32m0.08596[0m[0m | time: 15.794s
[2K
| Adam | epoch: 009 | loss: 0.08596 - acc: 0.9644 -- iter: 0064/1275
[A[ATraining Step: 323  | total loss: [1m[32m0.08735[0m[0m | time: 23.852s
[2K
| Adam | epoch: 009 | loss: 0.08735 - acc: 0.9617 -- iter: 0096/1275
[A[ATraining Step: 324  | total loss: [1m[32m0.08641[0m[0m | time: 31.671s
[2K
| Adam | epoch: 009 | loss: 0.08641 - acc: 0.9624 -- iter: 0128/1275
[A[ATraining Step: 325  | total loss: [1m[32m0.08325[0m[0m | time: 39.567s
[2K
| Adam | epoch: 009 | loss: 0.08325 - acc: 0.9662 -- iter: 0160/1275
[A[ATraining Step: 326  | total loss: [1m[32m0.07800[0m[0m | time: 47.541s
[2K
| Adam | epoch: 009 | loss: 0.07800 - acc: 0.9696 -- iter: 0192/1275
[A[ATraining Step: 327  | total loss: [1m[32m0.10421[0m[0m | time: 54.590s
[2K
| Adam | epoch: 009 | loss: 0.10421 - acc: 0.9663 -- iter: 0224/1275
[A[ATraining Step: 328  | total loss: [1m[32m0.09862[0m[0m | time: 61.773s
[2K
| Adam | epoch: 009 | loss: 0.09862 - acc: 0.9660 -- iter: 0256/1275
[A[ATraining Step: 329  | total loss: [1m[32m0.09029[0m[0m | time: 69.761s
[2K
| Adam | epoch: 009 | loss: 0.09029 - acc: 0.9694 -- iter: 0288/1275
[A[ATraining Step: 330  | total loss: [1m[32m0.08523[0m[0m | time: 77.713s
[2K
| Adam | epoch: 009 | loss: 0.08523 - acc: 0.9725 -- iter: 0320/1275
[A[ATraining Step: 331  | total loss: [1m[32m0.08711[0m[0m | time: 85.582s
[2K
| Adam | epoch: 009 | loss: 0.08711 - acc: 0.9721 -- iter: 0352/1275
[A[ATraining Step: 332  | total loss: [1m[32m0.07959[0m[0m | time: 93.439s
[2K
| Adam | epoch: 009 | loss: 0.07959 - acc: 0.9749 -- iter: 0384/1275
[A[ATraining Step: 333  | total loss: [1m[32m0.07570[0m[0m | time: 101.315s
[2K
| Adam | epoch: 009 | loss: 0.07570 - acc: 0.9774 -- iter: 0416/1275
[A[ATraining Step: 334  | total loss: [1m[32m0.07856[0m[0m | time: 109.533s
[2K
| Adam | epoch: 009 | loss: 0.07856 - acc: 0.9765 -- iter: 0448/1275
[A[ATraining Step: 335  | total loss: [1m[32m0.07255[0m[0m | time: 117.393s
[2K
| Adam | epoch: 009 | loss: 0.07255 - acc: 0.9789 -- iter: 0480/1275
[A[ATraining Step: 336  | total loss: [1m[32m0.07150[0m[0m | time: 125.405s
[2K
| Adam | epoch: 009 | loss: 0.07150 - acc: 0.9779 -- iter: 0512/1275
[A[ATraining Step: 337  | total loss: [1m[32m0.08467[0m[0m | time: 133.268s
[2K
| Adam | epoch: 009 | loss: 0.08467 - acc: 0.9770 -- iter: 0544/1275
[A[ATraining Step: 338  | total loss: [1m[32m0.07993[0m[0m | time: 141.273s
[2K
| Adam | epoch: 009 | loss: 0.07993 - acc: 0.9761 -- iter: 0576/1275
[A[ATraining Step: 339  | total loss: [1m[32m0.07420[0m[0m | time: 149.061s
[2K
| Adam | epoch: 009 | loss: 0.07420 - acc: 0.9785 -- iter: 0608/1275
[A[ATraining Step: 340  | total loss: [1m[32m0.09748[0m[0m | time: 157.044s
[2K
| Adam | epoch: 009 | loss: 0.09748 - acc: 0.9744 -- iter: 0640/1275
[A[ATraining Step: 341  | total loss: [1m[32m0.08985[0m[0m | time: 164.994s
[2K
| Adam | epoch: 009 | loss: 0.08985 - acc: 0.9770 -- iter: 0672/1275
[A[ATraining Step: 342  | total loss: [1m[32m0.08655[0m[0m | time: 172.927s
[2K
| Adam | epoch: 009 | loss: 0.08655 - acc: 0.9793 -- iter: 0704/1275
[A[ATraining Step: 343  | total loss: [1m[32m0.09606[0m[0m | time: 180.824s
[2K
| Adam | epoch: 009 | loss: 0.09606 - acc: 0.9782 -- iter: 0736/1275
[A[ATraining Step: 344  | total loss: [1m[32m0.08744[0m[0m | time: 188.680s
[2K
| Adam | epoch: 009 | loss: 0.08744 - acc: 0.9804 -- iter: 0768/1275
[A[ATraining Step: 345  | total loss: [1m[32m0.07913[0m[0m | time: 196.649s
[2K
| Adam | epoch: 009 | loss: 0.07913 - acc: 0.9824 -- iter: 0800/1275
[A[ATraining Step: 346  | total loss: [1m[32m0.08142[0m[0m | time: 204.756s
[2K
| Adam | epoch: 009 | loss: 0.08142 - acc: 0.9779 -- iter: 0832/1275
[A[ATraining Step: 347  | total loss: [1m[32m0.07375[0m[0m | time: 212.781s
[2K
| Adam | epoch: 009 | loss: 0.07375 - acc: 0.9801 -- iter: 0864/1275
[A[ATraining Step: 348  | total loss: [1m[32m0.06749[0m[0m | time: 220.698s
[2K
| Adam | epoch: 009 | loss: 0.06749 - acc: 0.9821 -- iter: 0896/1275
[A[ATraining Step: 349  | total loss: [1m[32m0.06820[0m[0m | time: 228.731s
[2K
| Adam | epoch: 009 | loss: 0.06820 - acc: 0.9807 -- iter: 0928/1275
[A[ATraining Step: 350  | total loss: [1m[32m0.06240[0m[0m | time: 236.720s
[2K
| Adam | epoch: 009 | loss: 0.06240 - acc: 0.9827 -- iter: 0960/1275
[A[ATraining Step: 351  | total loss: [1m[32m0.06112[0m[0m | time: 244.715s
[2K
| Adam | epoch: 009 | loss: 0.06112 - acc: 0.9844 -- iter: 0992/1275
[A[ATraining Step: 352  | total loss: [1m[32m0.05584[0m[0m | time: 252.834s
[2K
| Adam | epoch: 009 | loss: 0.05584 - acc: 0.9860 -- iter: 1024/1275
[A[ATraining Step: 353  | total loss: [1m[32m0.07510[0m[0m | time: 260.868s
[2K
| Adam | epoch: 009 | loss: 0.07510 - acc: 0.9749 -- iter: 1056/1275
[A[ATraining Step: 354  | total loss: [1m[32m0.06966[0m[0m | time: 268.606s
[2K
| Adam | epoch: 009 | loss: 0.06966 - acc: 0.9774 -- iter: 1088/1275
[A[ATraining Step: 355  | total loss: [1m[32m0.06726[0m[0m | time: 276.565s
[2K
| Adam | epoch: 009 | loss: 0.06726 - acc: 0.9765 -- iter: 1120/1275
[A[ATraining Step: 356  | total loss: [1m[32m0.08158[0m[0m | time: 284.453s
[2K
| Adam | epoch: 009 | loss: 0.08158 - acc: 0.9757 -- iter: 1152/1275
[A[ATraining Step: 357  | total loss: [1m[32m0.07569[0m[0m | time: 292.408s
[2K
| Adam | epoch: 009 | loss: 0.07569 - acc: 0.9782 -- iter: 1184/1275
[A[ATraining Step: 358  | total loss: [1m[32m0.06998[0m[0m | time: 300.332s
[2K
| Adam | epoch: 009 | loss: 0.06998 - acc: 0.9804 -- iter: 1216/1275
[A[ATraining Step: 359  | total loss: [1m[32m0.07013[0m[0m | time: 308.306s
[2K
| Adam | epoch: 009 | loss: 0.07013 - acc: 0.9792 -- iter: 1248/1275
[A[ATraining Step: 360  | total loss: [1m[32m0.07051[0m[0m | time: 334.060s
[2K
| Adam | epoch: 009 | loss: 0.07051 - acc: 0.9781 | val_loss: 0.29596 - val_acc: 0.8947 -- iter: 1275/1275
--
Training Step: 361  | total loss: [1m[32m0.10615[0m[0m | time: 8.105s
[2K
| Adam | epoch: 010 | loss: 0.10615 - acc: 0.9710 -- iter: 0032/1275
[A[ATraining Step: 362  | total loss: [1m[32m0.10978[0m[0m | time: 15.936s
[2K
| Adam | epoch: 010 | loss: 0.10978 - acc: 0.9676 -- iter: 0064/1275
[A[ATraining Step: 363  | total loss: [1m[32m0.10613[0m[0m | time: 24.147s
[2K
| Adam | epoch: 010 | loss: 0.10613 - acc: 0.9677 -- iter: 0096/1275
[A[ATraining Step: 364  | total loss: [1m[32m0.10332[0m[0m | time: 32.276s
[2K
| Adam | epoch: 010 | loss: 0.10332 - acc: 0.9647 -- iter: 0128/1275
[A[ATraining Step: 365  | total loss: [1m[32m0.10096[0m[0m | time: 40.187s
[2K
| Adam | epoch: 010 | loss: 0.10096 - acc: 0.9651 -- iter: 0160/1275
[A[ATraining Step: 366  | total loss: [1m[32m0.10079[0m[0m | time: 48.109s
[2K
| Adam | epoch: 010 | loss: 0.10079 - acc: 0.9623 -- iter: 0192/1275
[A[ATraining Step: 367  | total loss: [1m[32m0.09466[0m[0m | time: 56.170s
[2K
| Adam | epoch: 010 | loss: 0.09466 - acc: 0.9630 -- iter: 0224/1275
[A[ATraining Step: 368  | total loss: [1m[32m0.08943[0m[0m | time: 63.125s
[2K
| Adam | epoch: 010 | loss: 0.08943 - acc: 0.9636 -- iter: 0256/1275
[A[ATraining Step: 369  | total loss: [1m[32m0.08835[0m[0m | time: 70.064s
[2K
| Adam | epoch: 010 | loss: 0.08835 - acc: 0.9635 -- iter: 0288/1275
[A[ATraining Step: 370  | total loss: [1m[32m0.08308[0m[0m | time: 77.882s
[2K
| Adam | epoch: 010 | loss: 0.08308 - acc: 0.9634 -- iter: 0320/1275
[A[ATraining Step: 371  | total loss: [1m[32m0.08600[0m[0m | time: 85.847s
[2K
| Adam | epoch: 010 | loss: 0.08600 - acc: 0.9640 -- iter: 0352/1275
[A[ATraining Step: 372  | total loss: [1m[32m0.08460[0m[0m | time: 93.847s
[2K
| Adam | epoch: 010 | loss: 0.08460 - acc: 0.9645 -- iter: 0384/1275
[A[ATraining Step: 373  | total loss: [1m[32m0.07774[0m[0m | time: 101.742s
[2K
| Adam | epoch: 010 | loss: 0.07774 - acc: 0.9680 -- iter: 0416/1275
[A[ATraining Step: 374  | total loss: [1m[32m0.07167[0m[0m | time: 109.837s
[2K
| Adam | epoch: 010 | loss: 0.07167 - acc: 0.9712 -- iter: 0448/1275
[A[ATraining Step: 375  | total loss: [1m[32m0.06506[0m[0m | time: 117.739s
[2K
| Adam | epoch: 010 | loss: 0.06506 - acc: 0.9741 -- iter: 0480/1275
[A[ATraining Step: 376  | total loss: [1m[32m0.07961[0m[0m | time: 125.809s
[2K
| Adam | epoch: 010 | loss: 0.07961 - acc: 0.9704 -- iter: 0512/1275
[A[ATraining Step: 377  | total loss: [1m[32m0.07307[0m[0m | time: 133.784s
[2K
| Adam | epoch: 010 | loss: 0.07307 - acc: 0.9734 -- iter: 0544/1275
[A[ATraining Step: 378  | total loss: [1m[32m0.06797[0m[0m | time: 143.635s
[2K
| Adam | epoch: 010 | loss: 0.06797 - acc: 0.9760 -- iter: 0576/1275
[A[ATraining Step: 379  | total loss: [1m[32m0.06225[0m[0m | time: 155.277s
[2K
| Adam | epoch: 010 | loss: 0.06225 - acc: 0.9784 -- iter: 0608/1275
[A[ATraining Step: 380  | total loss: [1m[32m0.06024[0m[0m | time: 168.244s
[2K
| Adam | epoch: 010 | loss: 0.06024 - acc: 0.9775 -- iter: 0640/1275
[A[ATraining Step: 381  | total loss: [1m[32m0.05586[0m[0m | time: 181.265s
[2K
| Adam | epoch: 010 | loss: 0.05586 - acc: 0.9797 -- iter: 0672/1275
[A[ATraining Step: 382  | total loss: [1m[32m0.05127[0m[0m | time: 194.288s
[2K
| Adam | epoch: 010 | loss: 0.05127 - acc: 0.9818 -- iter: 0704/1275
[A[ATraining Step: 383  | total loss: [1m[32m0.04656[0m[0m | time: 206.906s
[2K
| Adam | epoch: 010 | loss: 0.04656 - acc: 0.9836 -- iter: 0736/1275
[A[ATraining Step: 384  | total loss: [1m[32m0.04493[0m[0m | time: 219.827s
[2K
| Adam | epoch: 010 | loss: 0.04493 - acc: 0.9852 -- iter: 0768/1275
[A[ATraining Step: 385  | total loss: [1m[32m0.04122[0m[0m | time: 233.066s
[2K
| Adam | epoch: 010 | loss: 0.04122 - acc: 0.9867 -- iter: 0800/1275
[A[ATraining Step: 386  | total loss: [1m[32m0.05892[0m[0m | time: 246.239s
[2K
| Adam | epoch: 010 | loss: 0.05892 - acc: 0.9755 -- iter: 0832/1275
[A[ATraining Step: 387  | total loss: [1m[32m0.05452[0m[0m | time: 259.334s
[2K
| Adam | epoch: 010 | loss: 0.05452 - acc: 0.9780 -- iter: 0864/1275
[A[ATraining Step: 388  | total loss: [1m[32m0.05062[0m[0m | time: 271.980s
[2K
| Adam | epoch: 010 | loss: 0.05062 - acc: 0.9802 -- iter: 0896/1275
[A[ATraining Step: 389  | total loss: [1m[32m0.05403[0m[0m | time: 284.390s
[2K
| Adam | epoch: 010 | loss: 0.05403 - acc: 0.9790 -- iter: 0928/1275
[A[ATraining Step: 390  | total loss: [1m[32m0.05427[0m[0m | time: 296.824s
[2K
| Adam | epoch: 010 | loss: 0.05427 - acc: 0.9780 -- iter: 0960/1275
[A[ATraining Step: 391  | total loss: [1m[32m0.04941[0m[0m | time: 309.867s
[2K
| Adam | epoch: 010 | loss: 0.04941 - acc: 0.9802 -- iter: 0992/1275
[A[ATraining Step: 392  | total loss: [1m[32m0.05822[0m[0m | time: 322.632s
[2K
| Adam | epoch: 010 | loss: 0.05822 - acc: 0.9791 -- iter: 1024/1275
[A[ATraining Step: 393  | total loss: [1m[32m0.05505[0m[0m | time: 335.968s
[2K
| Adam | epoch: 010 | loss: 0.05505 - acc: 0.9812 -- iter: 1056/1275
[A[ATraining Step: 394  | total loss: [1m[32m0.06284[0m[0m | time: 348.621s
[2K
| Adam | epoch: 010 | loss: 0.06284 - acc: 0.9768 -- iter: 1088/1275
[A[ATraining Step: 395  | total loss: [1m[32m0.05862[0m[0m | time: 361.546s
[2K
| Adam | epoch: 010 | loss: 0.05862 - acc: 0.9791 -- iter: 1120/1275
[A[ATraining Step: 396  | total loss: [1m[32m0.05902[0m[0m | time: 374.420s
[2K
| Adam | epoch: 010 | loss: 0.05902 - acc: 0.9781 -- iter: 1152/1275
[A[ATraining Step: 397  | total loss: [1m[32m0.05529[0m[0m | time: 387.946s
[2K
| Adam | epoch: 010 | loss: 0.05529 - acc: 0.9803 -- iter: 1184/1275
[A[ATraining Step: 398  | total loss: [1m[32m0.05092[0m[0m | time: 401.286s
[2K
| Adam | epoch: 010 | loss: 0.05092 - acc: 0.9822 -- iter: 1216/1275
[A[ATraining Step: 399  | total loss: [1m[32m0.04936[0m[0m | time: 414.439s
[2K
| Adam | epoch: 010 | loss: 0.04936 - acc: 0.9809 -- iter: 1248/1275
[A[ATraining Step: 400  | total loss: [1m[32m0.05465[0m[0m | time: 457.948s
[2K
| Adam | epoch: 010 | loss: 0.05465 - acc: 0.9766 | val_loss: 0.60766 - val_acc: 0.8596 -- iter: 1275/1275
--
Training Step: 401  | total loss: [1m[32m0.06754[0m[0m | time: 12.906s
[2K
| Adam | epoch: 011 | loss: 0.06754 - acc: 0.9726 -- iter: 0032/1275
[A[ATraining Step: 402  | total loss: [1m[32m0.06307[0m[0m | time: 25.939s
[2K
| Adam | epoch: 011 | loss: 0.06307 - acc: 0.9754 -- iter: 0064/1275
[A[ATraining Step: 403  | total loss: [1m[32m0.06431[0m[0m | time: 38.997s
[2K
| Adam | epoch: 011 | loss: 0.06431 - acc: 0.9716 -- iter: 0096/1275
[A[ATraining Step: 404  | total loss: [1m[32m0.07960[0m[0m | time: 52.110s
[2K
| Adam | epoch: 011 | loss: 0.07960 - acc: 0.9651 -- iter: 0128/1275
[A[ATraining Step: 405  | total loss: [1m[32m0.09040[0m[0m | time: 64.289s
[2K
| Adam | epoch: 011 | loss: 0.09040 - acc: 0.9592 -- iter: 0160/1275
[A[ATraining Step: 406  | total loss: [1m[32m0.08936[0m[0m | time: 76.053s
[2K
| Adam | epoch: 011 | loss: 0.08936 - acc: 0.9601 -- iter: 0192/1275
[A[ATraining Step: 407  | total loss: [1m[32m0.08220[0m[0m | time: 86.253s
[2K
| Adam | epoch: 011 | loss: 0.08220 - acc: 0.9641 -- iter: 0224/1275
[A[ATraining Step: 408  | total loss: [1m[32m0.08480[0m[0m | time: 96.067s
[2K
| Adam | epoch: 011 | loss: 0.08480 - acc: 0.9646 -- iter: 0256/1275
[A[ATraining Step: 409  | total loss: [1m[32m0.08207[0m[0m | time: 105.273s
[2K
| Adam | epoch: 011 | loss: 0.08207 - acc: 0.9650 -- iter: 0288/1275
[A[ATraining Step: 410  | total loss: [1m[32m0.08519[0m[0m | time: 114.096s
[2K
| Adam | epoch: 011 | loss: 0.08519 - acc: 0.9648 -- iter: 0320/1275
[A[ATraining Step: 411  | total loss: [1m[32m0.08091[0m[0m | time: 124.287s
[2K
| Adam | epoch: 011 | loss: 0.08091 - acc: 0.9683 -- iter: 0352/1275
[A[ATraining Step: 412  | total loss: [1m[32m0.07452[0m[0m | time: 134.214s
[2K
| Adam | epoch: 011 | loss: 0.07452 - acc: 0.9715 -- iter: 0384/1275
[A[ATraining Step: 413  | total loss: [1m[32m0.08407[0m[0m | time: 144.064s
[2K
| Adam | epoch: 011 | loss: 0.08407 - acc: 0.9650 -- iter: 0416/1275
[A[ATraining Step: 414  | total loss: [1m[32m0.07757[0m[0m | time: 154.247s
[2K
| Adam | epoch: 011 | loss: 0.07757 - acc: 0.9685 -- iter: 0448/1275
[A[ATraining Step: 415  | total loss: [1m[32m0.08900[0m[0m | time: 164.154s
[2K
| Adam | epoch: 011 | loss: 0.08900 - acc: 0.9560 -- iter: 0480/1275
[A[ATraining Step: 416  | total loss: [1m[32m0.08576[0m[0m | time: 174.122s
[2K
| Adam | epoch: 011 | loss: 0.08576 - acc: 0.9573 -- iter: 0512/1275
[A[ATraining Step: 417  | total loss: [1m[32m0.07806[0m[0m | time: 184.203s
[2K
| Adam | epoch: 011 | loss: 0.07806 - acc: 0.9615 -- iter: 0544/1275
[A[ATraining Step: 418  | total loss: [1m[32m0.08721[0m[0m | time: 194.524s
[2K
| Adam | epoch: 011 | loss: 0.08721 - acc: 0.9623 -- iter: 0576/1275
[A[ATraining Step: 419  | total loss: [1m[32m0.08595[0m[0m | time: 204.351s
[2K
| Adam | epoch: 011 | loss: 0.08595 - acc: 0.9598 -- iter: 0608/1275
[A[ATraining Step: 420  | total loss: [1m[32m0.08380[0m[0m | time: 214.162s
[2K
| Adam | epoch: 011 | loss: 0.08380 - acc: 0.9576 -- iter: 0640/1275
[A[ATraining Step: 421  | total loss: [1m[32m0.07725[0m[0m | time: 224.344s
[2K
| Adam | epoch: 011 | loss: 0.07725 - acc: 0.9618 -- iter: 0672/1275
[A[ATraining Step: 422  | total loss: [1m[32m0.07168[0m[0m | time: 234.489s
[2K
| Adam | epoch: 011 | loss: 0.07168 - acc: 0.9656 -- iter: 0704/1275
[A[ATraining Step: 423  | total loss: [1m[32m0.06851[0m[0m | time: 244.797s
[2K
| Adam | epoch: 011 | loss: 0.06851 - acc: 0.9659 -- iter: 0736/1275
[A[ATraining Step: 424  | total loss: [1m[32m0.07119[0m[0m | time: 255.049s
[2K
| Adam | epoch: 011 | loss: 0.07119 - acc: 0.9662 -- iter: 0768/1275
[A[ATraining Step: 425  | total loss: [1m[32m0.07951[0m[0m | time: 265.155s
[2K
| Adam | epoch: 011 | loss: 0.07951 - acc: 0.9665 -- iter: 0800/1275
[A[ATraining Step: 426  | total loss: [1m[32m0.07480[0m[0m | time: 274.925s
[2K
| Adam | epoch: 011 | loss: 0.07480 - acc: 0.9667 -- iter: 0832/1275
[A[ATraining Step: 427  | total loss: [1m[32m0.06886[0m[0m | time: 285.034s
[2K
| Adam | epoch: 011 | loss: 0.06886 - acc: 0.9700 -- iter: 0864/1275
[A[ATraining Step: 428  | total loss: [1m[32m0.07459[0m[0m | time: 295.249s
[2K
| Adam | epoch: 011 | loss: 0.07459 - acc: 0.9668 -- iter: 0896/1275
[A[ATraining Step: 429  | total loss: [1m[32m0.08093[0m[0m | time: 305.011s
[2K
| Adam | epoch: 011 | loss: 0.08093 - acc: 0.9670 -- iter: 0928/1275
[A[ATraining Step: 430  | total loss: [1m[32m0.12361[0m[0m | time: 315.228s
[2K
| Adam | epoch: 011 | loss: 0.12361 - acc: 0.9578 -- iter: 0960/1275
[A[ATraining Step: 431  | total loss: [1m[32m0.11507[0m[0m | time: 325.416s
[2K
| Adam | epoch: 011 | loss: 0.11507 - acc: 0.9589 -- iter: 0992/1275
[A[ATraining Step: 432  | total loss: [1m[32m0.10664[0m[0m | time: 335.260s
[2K
| Adam | epoch: 011 | loss: 0.10664 - acc: 0.9630 -- iter: 1024/1275
[A[ATraining Step: 433  | total loss: [1m[32m0.09715[0m[0m | time: 345.294s
[2K
| Adam | epoch: 011 | loss: 0.09715 - acc: 0.9667 -- iter: 1056/1275
[A[ATraining Step: 434  | total loss: [1m[32m0.08942[0m[0m | time: 355.488s
[2K
| Adam | epoch: 011 | loss: 0.08942 - acc: 0.9700 -- iter: 1088/1275
[A[ATraining Step: 435  | total loss: [1m[32m0.08337[0m[0m | time: 365.748s
[2K
| Adam | epoch: 011 | loss: 0.08337 - acc: 0.9730 -- iter: 1120/1275
[A[ATraining Step: 436  | total loss: [1m[32m0.07679[0m[0m | time: 375.407s
[2K
| Adam | epoch: 011 | loss: 0.07679 - acc: 0.9757 -- iter: 1152/1275
[A[ATraining Step: 437  | total loss: [1m[32m0.08879[0m[0m | time: 385.672s
[2K
| Adam | epoch: 011 | loss: 0.08879 - acc: 0.9688 -- iter: 1184/1275
[A[ATraining Step: 438  | total loss: [1m[32m0.08728[0m[0m | time: 395.748s
[2K
| Adam | epoch: 011 | loss: 0.08728 - acc: 0.9688 -- iter: 1216/1275
[A[ATraining Step: 439  | total loss: [1m[32m0.09086[0m[0m | time: 405.838s
[2K
| Adam | epoch: 011 | loss: 0.09086 - acc: 0.9688 -- iter: 1248/1275
[A[ATraining Step: 440  | total loss: [1m[32m0.08461[0m[0m | time: 433.053s
[2K
| Adam | epoch: 011 | loss: 0.08461 - acc: 0.9719 | val_loss: 1.99083 - val_acc: 0.6115 -- iter: 1275/1275
--
Training Step: 441  | total loss: [1m[32m0.08178[0m[0m | time: 7.933s
[2K
| Adam | epoch: 012 | loss: 0.08178 - acc: 0.9716 -- iter: 0032/1275
[A[ATraining Step: 442  | total loss: [1m[32m0.07557[0m[0m | time: 15.737s
[2K
| Adam | epoch: 012 | loss: 0.07557 - acc: 0.9744 -- iter: 0064/1275
[A[ATraining Step: 443  | total loss: [1m[32m0.06889[0m[0m | time: 23.571s
[2K
| Adam | epoch: 012 | loss: 0.06889 - acc: 0.9770 -- iter: 0096/1275
[A[ATraining Step: 444  | total loss: [1m[32m0.07270[0m[0m | time: 31.611s
[2K
| Adam | epoch: 012 | loss: 0.07270 - acc: 0.9762 -- iter: 0128/1275
[A[ATraining Step: 445  | total loss: [1m[32m0.07287[0m[0m | time: 39.352s
[2K
| Adam | epoch: 012 | loss: 0.07287 - acc: 0.9754 -- iter: 0160/1275
[A[ATraining Step: 446  | total loss: [1m[32m0.06968[0m[0m | time: 47.448s
[2K
| Adam | epoch: 012 | loss: 0.06968 - acc: 0.9779 -- iter: 0192/1275
[A[ATraining Step: 447  | total loss: [1m[32m0.06523[0m[0m | time: 55.506s
[2K
| Adam | epoch: 012 | loss: 0.06523 - acc: 0.9801 -- iter: 0224/1275
[A[ATraining Step: 448  | total loss: [1m[32m0.06423[0m[0m | time: 63.446s
[2K
| Adam | epoch: 012 | loss: 0.06423 - acc: 0.9790 -- iter: 0256/1275
[A[ATraining Step: 449  | total loss: [1m[32m0.07504[0m[0m | time: 71.324s
[2K
| Adam | epoch: 012 | loss: 0.07504 - acc: 0.9748 -- iter: 0288/1275
[A[ATraining Step: 450  | total loss: [1m[32m0.08301[0m[0m | time: 78.546s
[2K
| Adam | epoch: 012 | loss: 0.08301 - acc: 0.9742 -- iter: 0320/1275
[A[ATraining Step: 451  | total loss: [1m[32m0.08052[0m[0m | time: 85.499s
[2K
| Adam | epoch: 012 | loss: 0.08052 - acc: 0.9731 -- iter: 0352/1275
[A[ATraining Step: 452  | total loss: [1m[32m0.07356[0m[0m | time: 93.440s
[2K
| Adam | epoch: 012 | loss: 0.07356 - acc: 0.9758 -- iter: 0384/1275
[A[ATraining Step: 453  | total loss: [1m[32m0.09831[0m[0m | time: 101.423s
[2K
| Adam | epoch: 012 | loss: 0.09831 - acc: 0.9688 -- iter: 0416/1275
[A[ATraining Step: 454  | total loss: [1m[32m0.10165[0m[0m | time: 109.282s
[2K
| Adam | epoch: 012 | loss: 0.10165 - acc: 0.9657 -- iter: 0448/1275
[A[ATraining Step: 455  | total loss: [1m[32m0.09284[0m[0m | time: 117.118s
[2K
| Adam | epoch: 012 | loss: 0.09284 - acc: 0.9691 -- iter: 0480/1275
[A[ATraining Step: 456  | total loss: [1m[32m0.09793[0m[0m | time: 125.113s
[2K
| Adam | epoch: 012 | loss: 0.09793 - acc: 0.9628 -- iter: 0512/1275
[A[ATraining Step: 457  | total loss: [1m[32m0.08890[0m[0m | time: 133.078s
[2K
| Adam | epoch: 012 | loss: 0.08890 - acc: 0.9665 -- iter: 0544/1275
[A[ATraining Step: 458  | total loss: [1m[32m0.08648[0m[0m | time: 140.931s
[2K
| Adam | epoch: 012 | loss: 0.08648 - acc: 0.9668 -- iter: 0576/1275
[A[ATraining Step: 459  | total loss: [1m[32m0.10468[0m[0m | time: 148.764s
[2K
| Adam | epoch: 012 | loss: 0.10468 - acc: 0.9638 -- iter: 0608/1275
[A[ATraining Step: 460  | total loss: [1m[32m0.09568[0m[0m | time: 156.606s
[2K
| Adam | epoch: 012 | loss: 0.09568 - acc: 0.9675 -- iter: 0640/1275
[A[ATraining Step: 461  | total loss: [1m[32m0.08829[0m[0m | time: 164.360s
[2K
| Adam | epoch: 012 | loss: 0.08829 - acc: 0.9707 -- iter: 0672/1275
[A[ATraining Step: 462  | total loss: [1m[32m0.08247[0m[0m | time: 172.440s
[2K
| Adam | epoch: 012 | loss: 0.08247 - acc: 0.9736 -- iter: 0704/1275
[A[ATraining Step: 463  | total loss: [1m[32m0.07949[0m[0m | time: 180.359s
[2K
| Adam | epoch: 012 | loss: 0.07949 - acc: 0.9763 -- iter: 0736/1275
[A[ATraining Step: 464  | total loss: [1m[32m0.07948[0m[0m | time: 188.298s
[2K
| Adam | epoch: 012 | loss: 0.07948 - acc: 0.9724 -- iter: 0768/1275
[A[ATraining Step: 465  | total loss: [1m[32m0.07405[0m[0m | time: 196.357s
[2K
| Adam | epoch: 012 | loss: 0.07405 - acc: 0.9752 -- iter: 0800/1275
[A[ATraining Step: 466  | total loss: [1m[32m0.07199[0m[0m | time: 204.315s
[2K
| Adam | epoch: 012 | loss: 0.07199 - acc: 0.9776 -- iter: 0832/1275
[A[ATraining Step: 467  | total loss: [1m[32m0.08831[0m[0m | time: 212.236s
[2K
| Adam | epoch: 012 | loss: 0.08831 - acc: 0.9768 -- iter: 0864/1275
[A[ATraining Step: 468  | total loss: [1m[32m0.08033[0m[0m | time: 219.991s
[2K
| Adam | epoch: 012 | loss: 0.08033 - acc: 0.9791 -- iter: 0896/1275
[A[ATraining Step: 469  | total loss: [1m[32m0.08197[0m[0m | time: 227.884s
[2K
| Adam | epoch: 012 | loss: 0.08197 - acc: 0.9749 -- iter: 0928/1275
[A[ATraining Step: 470  | total loss: [1m[32m0.07938[0m[0m | time: 236.040s
[2K
| Adam | epoch: 012 | loss: 0.07938 - acc: 0.9743 -- iter: 0960/1275
[A[ATraining Step: 471  | total loss: [1m[32m0.08185[0m[0m | time: 243.998s
[2K
| Adam | epoch: 012 | loss: 0.08185 - acc: 0.9706 -- iter: 0992/1275
[A[ATraining Step: 472  | total loss: [1m[32m0.07727[0m[0m | time: 251.944s
[2K
| Adam | epoch: 012 | loss: 0.07727 - acc: 0.9704 -- iter: 1024/1275
[A[ATraining Step: 473  | total loss: [1m[32m0.07012[0m[0m | time: 259.865s
[2K
| Adam | epoch: 012 | loss: 0.07012 - acc: 0.9734 -- iter: 1056/1275
[A[ATraining Step: 474  | total loss: [1m[32m0.06714[0m[0m | time: 267.675s
[2K
| Adam | epoch: 012 | loss: 0.06714 - acc: 0.9761 -- iter: 1088/1275
[A[ATraining Step: 475  | total loss: [1m[32m0.06649[0m[0m | time: 275.480s
[2K
| Adam | epoch: 012 | loss: 0.06649 - acc: 0.9753 -- iter: 1120/1275
[A[ATraining Step: 476  | total loss: [1m[32m0.06575[0m[0m | time: 283.482s
[2K
| Adam | epoch: 012 | loss: 0.06575 - acc: 0.9747 -- iter: 1152/1275
[A[ATraining Step: 477  | total loss: [1m[32m0.06927[0m[0m | time: 291.284s
[2K
| Adam | epoch: 012 | loss: 0.06927 - acc: 0.9709 -- iter: 1184/1275
[A[ATraining Step: 478  | total loss: [1m[32m0.06277[0m[0m | time: 299.276s
[2K
| Adam | epoch: 012 | loss: 0.06277 - acc: 0.9739 -- iter: 1216/1275
[A[ATraining Step: 479  | total loss: [1m[32m0.05744[0m[0m | time: 307.057s
[2K
| Adam | epoch: 012 | loss: 0.05744 - acc: 0.9765 -- iter: 1248/1275
[A[ATraining Step: 480  | total loss: [1m[32m0.06295[0m[0m | time: 332.920s
[2K
| Adam | epoch: 012 | loss: 0.06295 - acc: 0.9726 | val_loss: 0.97811 - val_acc: 0.7995 -- iter: 1275/1275
--
Training Step: 481  | total loss: [1m[32m0.05710[0m[0m | time: 8.134s
[2K
| Adam | epoch: 013 | loss: 0.05710 - acc: 0.9753 -- iter: 0032/1275
[A[ATraining Step: 482  | total loss: [1m[32m0.06993[0m[0m | time: 16.189s
[2K
| Adam | epoch: 013 | loss: 0.06993 - acc: 0.9747 -- iter: 0064/1275
[A[ATraining Step: 483  | total loss: [1m[32m0.06587[0m[0m | time: 24.117s
[2K
| Adam | epoch: 013 | loss: 0.06587 - acc: 0.9741 -- iter: 0096/1275
[A[ATraining Step: 484  | total loss: [1m[32m0.06427[0m[0m | time: 31.903s
[2K
| Adam | epoch: 013 | loss: 0.06427 - acc: 0.9735 -- iter: 0128/1275
[A[ATraining Step: 485  | total loss: [1m[32m0.06804[0m[0m | time: 39.711s
[2K
| Adam | epoch: 013 | loss: 0.06804 - acc: 0.9731 -- iter: 0160/1275
[A[ATraining Step: 486  | total loss: [1m[32m0.06841[0m[0m | time: 47.507s
[2K
| Adam | epoch: 013 | loss: 0.06841 - acc: 0.9726 -- iter: 0192/1275
[A[ATraining Step: 487  | total loss: [1m[32m0.06365[0m[0m | time: 55.478s
[2K
| Adam | epoch: 013 | loss: 0.06365 - acc: 0.9754 -- iter: 0224/1275
[A[ATraining Step: 488  | total loss: [1m[32m0.05791[0m[0m | time: 63.387s
[2K
| Adam | epoch: 013 | loss: 0.05791 - acc: 0.9778 -- iter: 0256/1275
[A[ATraining Step: 489  | total loss: [1m[32m0.05534[0m[0m | time: 71.429s
[2K
| Adam | epoch: 013 | loss: 0.05534 - acc: 0.9800 -- iter: 0288/1275
[A[ATraining Step: 490  | total loss: [1m[32m0.06409[0m[0m | time: 79.316s
[2K
| Adam | epoch: 013 | loss: 0.06409 - acc: 0.9727 -- iter: 0320/1275
[A[ATraining Step: 491  | total loss: [1m[32m0.05822[0m[0m | time: 86.422s
[2K
| Adam | epoch: 013 | loss: 0.05822 - acc: 0.9754 -- iter: 0352/1275
[A[ATraining Step: 492  | total loss: [1m[32m0.05500[0m[0m | time: 93.456s
[2K
| Adam | epoch: 013 | loss: 0.05500 - acc: 0.9779 -- iter: 0384/1275
[A[ATraining Step: 493  | total loss: [1m[32m0.05042[0m[0m | time: 101.255s
[2K
| Adam | epoch: 013 | loss: 0.05042 - acc: 0.9801 -- iter: 0416/1275
[A[ATraining Step: 494  | total loss: [1m[32m0.04679[0m[0m | time: 109.126s
[2K
| Adam | epoch: 013 | loss: 0.04679 - acc: 0.9821 -- iter: 0448/1275
[A[ATraining Step: 495  | total loss: [1m[32m0.05467[0m[0m | time: 116.978s
[2K
| Adam | epoch: 013 | loss: 0.05467 - acc: 0.9807 -- iter: 0480/1275
[A[ATraining Step: 496  | total loss: [1m[32m0.04952[0m[0m | time: 125.142s
[2K
| Adam | epoch: 013 | loss: 0.04952 - acc: 0.9827 -- iter: 0512/1275
[A[ATraining Step: 497  | total loss: [1m[32m0.04614[0m[0m | time: 133.098s
[2K
| Adam | epoch: 013 | loss: 0.04614 - acc: 0.9844 -- iter: 0544/1275
[A[ATraining Step: 498  | total loss: [1m[32m0.04181[0m[0m | time: 141.109s
[2K
| Adam | epoch: 013 | loss: 0.04181 - acc: 0.9860 -- iter: 0576/1275
[A[ATraining Step: 499  | total loss: [1m[32m0.04112[0m[0m | time: 149.097s
[2K
| Adam | epoch: 013 | loss: 0.04112 - acc: 0.9874 -- iter: 0608/1275
[A[ATraining Step: 500  | total loss: [1m[32m0.03752[0m[0m | time: 157.079s
[2K
| Adam | epoch: 013 | loss: 0.03752 - acc: 0.9886 -- iter: 0640/1275
[A[ATraining Step: 501  | total loss: [1m[32m0.06810[0m[0m | time: 164.909s
[2K
| Adam | epoch: 013 | loss: 0.06810 - acc: 0.9866 -- iter: 0672/1275
[A[ATraining Step: 502  | total loss: [1m[32m0.06243[0m[0m | time: 172.793s
[2K
| Adam | epoch: 013 | loss: 0.06243 - acc: 0.9880 -- iter: 0704/1275
[A[ATraining Step: 503  | total loss: [1m[32m0.06525[0m[0m | time: 180.623s
[2K
| Adam | epoch: 013 | loss: 0.06525 - acc: 0.9861 -- iter: 0736/1275
[A[ATraining Step: 504  | total loss: [1m[32m0.05903[0m[0m | time: 188.760s
[2K
| Adam | epoch: 013 | loss: 0.05903 - acc: 0.9874 -- iter: 0768/1275
[A[ATraining Step: 505  | total loss: [1m[32m0.05397[0m[0m | time: 196.523s
[2K
| Adam | epoch: 013 | loss: 0.05397 - acc: 0.9887 -- iter: 0800/1275
[A[ATraining Step: 506  | total loss: [1m[32m0.04946[0m[0m | time: 204.415s
[2K
| Adam | epoch: 013 | loss: 0.04946 - acc: 0.9898 -- iter: 0832/1275
[A[ATraining Step: 507  | total loss: [1m[32m0.04797[0m[0m | time: 212.449s
[2K
| Adam | epoch: 013 | loss: 0.04797 - acc: 0.9908 -- iter: 0864/1275
[A[ATraining Step: 508  | total loss: [1m[32m0.04469[0m[0m | time: 220.341s
[2K
| Adam | epoch: 013 | loss: 0.04469 - acc: 0.9918 -- iter: 0896/1275
[A[ATraining Step: 509  | total loss: [1m[32m0.04158[0m[0m | time: 228.496s
[2K
| Adam | epoch: 013 | loss: 0.04158 - acc: 0.9926 -- iter: 0928/1275
[A[ATraining Step: 510  | total loss: [1m[32m0.03791[0m[0m | time: 236.729s
[2K
| Adam | epoch: 013 | loss: 0.03791 - acc: 0.9933 -- iter: 0960/1275
[A[ATraining Step: 511  | total loss: [1m[32m0.04751[0m[0m | time: 244.628s
[2K
| Adam | epoch: 013 | loss: 0.04751 - acc: 0.9846 -- iter: 0992/1275
[A[ATraining Step: 512  | total loss: [1m[32m0.04814[0m[0m | time: 252.738s
[2K
| Adam | epoch: 013 | loss: 0.04814 - acc: 0.9830 -- iter: 1024/1275
[A[ATraining Step: 513  | total loss: [1m[32m0.04373[0m[0m | time: 260.520s
[2K
| Adam | epoch: 013 | loss: 0.04373 - acc: 0.9847 -- iter: 1056/1275
[A[ATraining Step: 514  | total loss: [1m[32m0.04046[0m[0m | time: 268.338s
[2K
| Adam | epoch: 013 | loss: 0.04046 - acc: 0.9863 -- iter: 1088/1275
[A[ATraining Step: 515  | total loss: [1m[32m0.04358[0m[0m | time: 276.083s
[2K
| Adam | epoch: 013 | loss: 0.04358 - acc: 0.9814 -- iter: 1120/1275
[A[ATraining Step: 516  | total loss: [1m[32m0.04067[0m[0m | time: 284.128s
[2K
| Adam | epoch: 013 | loss: 0.04067 - acc: 0.9832 -- iter: 1152/1275
[A[ATraining Step: 517  | total loss: [1m[32m0.03863[0m[0m | time: 292.154s
[2K
| Adam | epoch: 013 | loss: 0.03863 - acc: 0.9849 -- iter: 1184/1275
[A[ATraining Step: 518  | total loss: [1m[32m0.03562[0m[0m | time: 300.082s
[2K
| Adam | epoch: 013 | loss: 0.03562 - acc: 0.9864 -- iter: 1216/1275
[A[ATraining Step: 519  | total loss: [1m[32m0.03357[0m[0m | time: 308.055s
[2K
| Adam | epoch: 013 | loss: 0.03357 - acc: 0.9878 -- iter: 1248/1275
[A[ATraining Step: 520  | total loss: [1m[32m0.03038[0m[0m | time: 334.079s
[2K
| Adam | epoch: 013 | loss: 0.03038 - acc: 0.9890 | val_loss: 0.34009 - val_acc: 0.8972 -- iter: 1275/1275
--
Training Step: 521  | total loss: [1m[32m0.04449[0m[0m | time: 7.830s
[2K
| Adam | epoch: 014 | loss: 0.04449 - acc: 0.9870 -- iter: 0032/1275
[A[ATraining Step: 522  | total loss: [1m[32m0.04211[0m[0m | time: 15.813s
[2K
| Adam | epoch: 014 | loss: 0.04211 - acc: 0.9883 -- iter: 0064/1275
[A[ATraining Step: 523  | total loss: [1m[32m0.04049[0m[0m | time: 23.691s
[2K
| Adam | epoch: 014 | loss: 0.04049 - acc: 0.9863 -- iter: 0096/1275
[A[ATraining Step: 524  | total loss: [1m[32m0.03674[0m[0m | time: 31.646s
[2K
| Adam | epoch: 014 | loss: 0.03674 - acc: 0.9877 -- iter: 0128/1275
[A[ATraining Step: 525  | total loss: [1m[32m0.04512[0m[0m | time: 39.413s
[2K
| Adam | epoch: 014 | loss: 0.04512 - acc: 0.9827 -- iter: 0160/1275
[A[ATraining Step: 526  | total loss: [1m[32m0.04546[0m[0m | time: 47.349s
[2K
| Adam | epoch: 014 | loss: 0.04546 - acc: 0.9813 -- iter: 0192/1275
[A[ATraining Step: 527  | total loss: [1m[32m0.04417[0m[0m | time: 55.347s
[2K
| Adam | epoch: 014 | loss: 0.04417 - acc: 0.9800 -- iter: 0224/1275
[A[ATraining Step: 528  | total loss: [1m[32m0.04095[0m[0m | time: 63.138s
[2K
| Adam | epoch: 014 | loss: 0.04095 - acc: 0.9820 -- iter: 0256/1275
[A[ATraining Step: 529  | total loss: [1m[32m0.03825[0m[0m | time: 71.081s
[2K
| Adam | epoch: 014 | loss: 0.03825 - acc: 0.9838 -- iter: 0288/1275
[A[ATraining Step: 530  | total loss: [1m[32m0.03461[0m[0m | time: 78.919s
[2K
| Adam | epoch: 014 | loss: 0.03461 - acc: 0.9854 -- iter: 0320/1275
[A[ATraining Step: 531  | total loss: [1m[32m0.03324[0m[0m | time: 86.716s
[2K
| Adam | epoch: 014 | loss: 0.03324 - acc: 0.9869 -- iter: 0352/1275
[A[ATraining Step: 532  | total loss: [1m[32m0.03455[0m[0m | time: 93.724s
[2K
| Adam | epoch: 014 | loss: 0.03455 - acc: 0.9851 -- iter: 0384/1275
[A[ATraining Step: 533  | total loss: [1m[32m0.03286[0m[0m | time: 100.814s
[2K
| Adam | epoch: 014 | loss: 0.03286 - acc: 0.9866 -- iter: 0416/1275
[A[ATraining Step: 534  | total loss: [1m[32m0.03034[0m[0m | time: 108.838s
[2K
| Adam | epoch: 014 | loss: 0.03034 - acc: 0.9879 -- iter: 0448/1275
[A[ATraining Step: 535  | total loss: [1m[32m0.02844[0m[0m | time: 117.014s
[2K
| Adam | epoch: 014 | loss: 0.02844 - acc: 0.9891 -- iter: 0480/1275
[A[ATraining Step: 536  | total loss: [1m[32m0.02753[0m[0m | time: 125.117s
[2K
| Adam | epoch: 014 | loss: 0.02753 - acc: 0.9902 -- iter: 0512/1275
[A[ATraining Step: 537  | total loss: [1m[32m0.02822[0m[0m | time: 133.111s
[2K
| Adam | epoch: 014 | loss: 0.02822 - acc: 0.9912 -- iter: 0544/1275
[A[ATraining Step: 538  | total loss: [1m[32m0.02623[0m[0m | time: 140.979s
[2K
| Adam | epoch: 014 | loss: 0.02623 - acc: 0.9921 -- iter: 0576/1275
[A[ATraining Step: 539  | total loss: [1m[32m0.02784[0m[0m | time: 149.007s
[2K
| Adam | epoch: 014 | loss: 0.02784 - acc: 0.9897 -- iter: 0608/1275
[A[ATraining Step: 540  | total loss: [1m[32m0.03248[0m[0m | time: 156.860s
[2K
| Adam | epoch: 014 | loss: 0.03248 - acc: 0.9845 -- iter: 0640/1275
[A[ATraining Step: 541  | total loss: [1m[32m0.03000[0m[0m | time: 164.854s
[2K
| Adam | epoch: 014 | loss: 0.03000 - acc: 0.9861 -- iter: 0672/1275
[A[ATraining Step: 542  | total loss: [1m[32m0.07254[0m[0m | time: 172.617s
[2K
| Adam | epoch: 014 | loss: 0.07254 - acc: 0.9687 -- iter: 0704/1275
[A[ATraining Step: 543  | total loss: [1m[32m0.06595[0m[0m | time: 180.515s
[2K
| Adam | epoch: 014 | loss: 0.06595 - acc: 0.9718 -- iter: 0736/1275
[A[ATraining Step: 544  | total loss: [1m[32m0.06028[0m[0m | time: 188.490s
[2K
| Adam | epoch: 014 | loss: 0.06028 - acc: 0.9747 -- iter: 0768/1275
[A[ATraining Step: 545  | total loss: [1m[32m0.05470[0m[0m | time: 196.402s
[2K
| Adam | epoch: 014 | loss: 0.05470 - acc: 0.9772 -- iter: 0800/1275
[A[ATraining Step: 546  | total loss: [1m[32m0.05335[0m[0m | time: 204.320s
[2K
| Adam | epoch: 014 | loss: 0.05335 - acc: 0.9763 -- iter: 0832/1275
[A[ATraining Step: 547  | total loss: [1m[32m0.04942[0m[0m | time: 212.189s
[2K
| Adam | epoch: 014 | loss: 0.04942 - acc: 0.9787 -- iter: 0864/1275
[A[ATraining Step: 548  | total loss: [1m[32m0.04634[0m[0m | time: 220.256s
[2K
| Adam | epoch: 014 | loss: 0.04634 - acc: 0.9808 -- iter: 0896/1275
[A[ATraining Step: 549  | total loss: [1m[32m0.04431[0m[0m | time: 228.173s
[2K
| Adam | epoch: 014 | loss: 0.04431 - acc: 0.9828 -- iter: 0928/1275
[A[ATraining Step: 550  | total loss: [1m[32m0.04110[0m[0m | time: 236.043s
[2K
| Adam | epoch: 014 | loss: 0.04110 - acc: 0.9845 -- iter: 0960/1275
[A[ATraining Step: 551  | total loss: [1m[32m0.03882[0m[0m | time: 244.067s
[2K
| Adam | epoch: 014 | loss: 0.03882 - acc: 0.9860 -- iter: 0992/1275
[A[ATraining Step: 552  | total loss: [1m[32m0.03569[0m[0m | time: 251.964s
[2K
| Adam | epoch: 014 | loss: 0.03569 - acc: 0.9874 -- iter: 1024/1275
[A[ATraining Step: 553  | total loss: [1m[32m0.03549[0m[0m | time: 259.856s
[2K
| Adam | epoch: 014 | loss: 0.03549 - acc: 0.9887 -- iter: 1056/1275
[A[ATraining Step: 554  | total loss: [1m[32m0.03281[0m[0m | time: 267.811s
[2K
| Adam | epoch: 014 | loss: 0.03281 - acc: 0.9898 -- iter: 1088/1275
[A[ATraining Step: 555  | total loss: [1m[32m0.03327[0m[0m | time: 275.663s
[2K
| Adam | epoch: 014 | loss: 0.03327 - acc: 0.9877 -- iter: 1120/1275
[A[ATraining Step: 556  | total loss: [1m[32m0.03075[0m[0m | time: 283.603s
[2K
| Adam | epoch: 014 | loss: 0.03075 - acc: 0.9889 -- iter: 1152/1275
[A[ATraining Step: 557  | total loss: [1m[32m0.04884[0m[0m | time: 291.591s
[2K
| Adam | epoch: 014 | loss: 0.04884 - acc: 0.9869 -- iter: 1184/1275
[A[ATraining Step: 558  | total loss: [1m[32m0.05010[0m[0m | time: 299.440s
[2K
| Adam | epoch: 014 | loss: 0.05010 - acc: 0.9851 -- iter: 1216/1275
[A[ATraining Step: 559  | total loss: [1m[32m0.04527[0m[0m | time: 307.254s
[2K
| Adam | epoch: 014 | loss: 0.04527 - acc: 0.9866 -- iter: 1248/1275
[A[ATraining Step: 560  | total loss: [1m[32m0.04228[0m[0m | time: 333.008s
[2K
| Adam | epoch: 014 | loss: 0.04228 - acc: 0.9879 | val_loss: 1.13883 - val_acc: 0.7970 -- iter: 1275/1275
--
Training Step: 561  | total loss: [1m[32m0.03814[0m[0m | time: 8.081s
[2K
| Adam | epoch: 015 | loss: 0.03814 - acc: 0.9891 -- iter: 0032/1275
[A[ATraining Step: 562  | total loss: [1m[32m0.03518[0m[0m | time: 16.136s
[2K
| Adam | epoch: 015 | loss: 0.03518 - acc: 0.9902 -- iter: 0064/1275
[A[ATraining Step: 563  | total loss: [1m[32m0.03734[0m[0m | time: 24.157s
[2K
| Adam | epoch: 015 | loss: 0.03734 - acc: 0.9912 -- iter: 0096/1275
[A[ATraining Step: 564  | total loss: [1m[32m0.03534[0m[0m | time: 32.239s
[2K
| Adam | epoch: 015 | loss: 0.03534 - acc: 0.9921 -- iter: 0128/1275
[A[ATraining Step: 565  | total loss: [1m[32m0.03208[0m[0m | time: 40.309s
[2K
| Adam | epoch: 015 | loss: 0.03208 - acc: 0.9929 -- iter: 0160/1275
[A[ATraining Step: 566  | total loss: [1m[32m0.02924[0m[0m | time: 48.193s
[2K
| Adam | epoch: 015 | loss: 0.02924 - acc: 0.9936 -- iter: 0192/1275
[A[ATraining Step: 567  | total loss: [1m[32m0.02933[0m[0m | time: 55.991s
[2K
| Adam | epoch: 015 | loss: 0.02933 - acc: 0.9942 -- iter: 0224/1275
[A[ATraining Step: 568  | total loss: [1m[32m0.02653[0m[0m | time: 63.883s
[2K
| Adam | epoch: 015 | loss: 0.02653 - acc: 0.9948 -- iter: 0256/1275
[A[ATraining Step: 569  | total loss: [1m[32m0.02443[0m[0m | time: 71.710s
[2K
| Adam | epoch: 015 | loss: 0.02443 - acc: 0.9953 -- iter: 0288/1275
[A[ATraining Step: 570  | total loss: [1m[32m0.02220[0m[0m | time: 79.609s
[2K
| Adam | epoch: 015 | loss: 0.02220 - acc: 0.9958 -- iter: 0320/1275
[A[ATraining Step: 571  | total loss: [1m[32m0.02046[0m[0m | time: 87.523s
[2K
| Adam | epoch: 015 | loss: 0.02046 - acc: 0.9962 -- iter: 0352/1275
[A[ATraining Step: 572  | total loss: [1m[32m0.02137[0m[0m | time: 95.527s
[2K
| Adam | epoch: 015 | loss: 0.02137 - acc: 0.9966 -- iter: 0384/1275
[A[ATraining Step: 573  | total loss: [1m[32m0.02015[0m[0m | time: 102.559s
[2K
| Adam | epoch: 015 | loss: 0.02015 - acc: 0.9969 -- iter: 0416/1275
[A[ATraining Step: 574  | total loss: [1m[32m0.02375[0m[0m | time: 109.543s
[2K
| Adam | epoch: 015 | loss: 0.02375 - acc: 0.9935 -- iter: 0448/1275
[A[ATraining Step: 575  | total loss: [1m[32m0.02153[0m[0m | time: 117.542s
[2K
| Adam | epoch: 015 | loss: 0.02153 - acc: 0.9942 -- iter: 0480/1275
[A[ATraining Step: 576  | total loss: [1m[32m0.01970[0m[0m | time: 125.368s
[2K
| Adam | epoch: 015 | loss: 0.01970 - acc: 0.9948 -- iter: 0512/1275
[A[ATraining Step: 577  | total loss: [1m[32m0.02517[0m[0m | time: 133.327s
[2K
| Adam | epoch: 015 | loss: 0.02517 - acc: 0.9922 -- iter: 0544/1275
[A[ATraining Step: 578  | total loss: [1m[32m0.06279[0m[0m | time: 141.340s
[2K
| Adam | epoch: 015 | loss: 0.06279 - acc: 0.9898 -- iter: 0576/1275
[A[ATraining Step: 579  | total loss: [1m[32m0.05968[0m[0m | time: 149.498s
[2K
| Adam | epoch: 015 | loss: 0.05968 - acc: 0.9877 -- iter: 0608/1275
[A[ATraining Step: 580  | total loss: [1m[32m0.05433[0m[0m | time: 157.343s
[2K
| Adam | epoch: 015 | loss: 0.05433 - acc: 0.9889 -- iter: 0640/1275
[A[ATraining Step: 581  | total loss: [1m[32m0.04907[0m[0m | time: 165.329s
[2K
| Adam | epoch: 015 | loss: 0.04907 - acc: 0.9900 -- iter: 0672/1275
[A[ATraining Step: 582  | total loss: [1m[32m0.05803[0m[0m | time: 173.309s
[2K
| Adam | epoch: 015 | loss: 0.05803 - acc: 0.9848 -- iter: 0704/1275
[A[ATraining Step: 583  | total loss: [1m[32m0.05242[0m[0m | time: 181.442s
[2K
| Adam | epoch: 015 | loss: 0.05242 - acc: 0.9863 -- iter: 0736/1275
[A[ATraining Step: 584  | total loss: [1m[32m0.04876[0m[0m | time: 189.200s
[2K
| Adam | epoch: 015 | loss: 0.04876 - acc: 0.9877 -- iter: 0768/1275
[A[ATraining Step: 585  | total loss: [1m[32m0.05511[0m[0m | time: 197.322s
[2K
| Adam | epoch: 015 | loss: 0.05511 - acc: 0.9858 -- iter: 0800/1275
[A[ATraining Step: 586  | total loss: [1m[32m0.05744[0m[0m | time: 205.205s
[2K
| Adam | epoch: 015 | loss: 0.05744 - acc: 0.9841 -- iter: 0832/1275
[A[ATraining Step: 587  | total loss: [1m[32m0.05182[0m[0m | time: 213.180s
[2K
| Adam | epoch: 015 | loss: 0.05182 - acc: 0.9857 -- iter: 0864/1275
[A[ATraining Step: 588  | total loss: [1m[32m0.05289[0m[0m | time: 221.036s
[2K
| Adam | epoch: 015 | loss: 0.05289 - acc: 0.9840 -- iter: 0896/1275
[A[ATraining Step: 589  | total loss: [1m[32m0.04883[0m[0m | time: 228.966s
[2K
| Adam | epoch: 015 | loss: 0.04883 - acc: 0.9856 -- iter: 0928/1275
[A[ATraining Step: 590  | total loss: [1m[32m0.04574[0m[0m | time: 236.908s
[2K
| Adam | epoch: 015 | loss: 0.04574 - acc: 0.9870 -- iter: 0960/1275
[A[ATraining Step: 591  | total loss: [1m[32m0.04519[0m[0m | time: 244.856s
[2K
| Adam | epoch: 015 | loss: 0.04519 - acc: 0.9852 -- iter: 0992/1275
[A[ATraining Step: 592  | total loss: [1m[32m0.04317[0m[0m | time: 252.864s
[2K
| Adam | epoch: 015 | loss: 0.04317 - acc: 0.9867 -- iter: 1024/1275
[A[ATraining Step: 593  | total loss: [1m[32m0.03931[0m[0m | time: 260.659s
[2K
| Adam | epoch: 015 | loss: 0.03931 - acc: 0.9880 -- iter: 1056/1275
[A[ATraining Step: 594  | total loss: [1m[32m0.05345[0m[0m | time: 268.634s
[2K
| Adam | epoch: 015 | loss: 0.05345 - acc: 0.9861 -- iter: 1088/1275
[A[ATraining Step: 595  | total loss: [1m[32m0.05076[0m[0m | time: 276.497s
[2K
| Adam | epoch: 015 | loss: 0.05076 - acc: 0.9844 -- iter: 1120/1275
[A[ATraining Step: 596  | total loss: [1m[32m0.04589[0m[0m | time: 284.386s
[2K
| Adam | epoch: 015 | loss: 0.04589 - acc: 0.9859 -- iter: 1152/1275
[A[ATraining Step: 597  | total loss: [1m[32m0.04278[0m[0m | time: 292.510s
[2K
| Adam | epoch: 015 | loss: 0.04278 - acc: 0.9873 -- iter: 1184/1275
[A[ATraining Step: 598  | total loss: [1m[32m0.04329[0m[0m | time: 300.378s
[2K
| Adam | epoch: 015 | loss: 0.04329 - acc: 0.9855 -- iter: 1216/1275
[A[ATraining Step: 599  | total loss: [1m[32m0.04348[0m[0m | time: 308.071s
[2K
| Adam | epoch: 015 | loss: 0.04348 - acc: 0.9838 -- iter: 1248/1275
[A[ATraining Step: 600  | total loss: [1m[32m0.05067[0m[0m | time: 333.857s
[2K
| Adam | epoch: 015 | loss: 0.05067 - acc: 0.9792 | val_loss: 0.93795 - val_acc: 0.7920 -- iter: 1275/1275
--
Validation AUC:0.9618558776167472
Validation AUPRC:0.9515731872711547
Test AUC:0.9540429167294839
Test AUPRC:0.9379026184908617
BestTestF1Score	0.9	0.81	0.9	0.93	0.87	175	13	185	26	0.01
BestTestMCCScore	0.9	0.81	0.9	0.93	0.87	175	13	185	26	0.01
BestTestAccuracyScore	0.9	0.81	0.9	0.93	0.87	175	13	185	26	0.01
BestValidationF1Score	0.87	0.77	0.88	0.93	0.82	157	12	195	35	0.01
BestValidationMCC	0.87	0.77	0.88	0.93	0.82	157	12	195	35	0.01
BestValidationAccuracy	0.87	0.77	0.88	0.93	0.82	157	12	195	35	0.01
TestPredictions (Threshold:0.01)
CHEMBL99331,TN,INACT,0.0	CHEMBL25373,FP,INACT,0.11999999731779099	CHEMBL312551,TN,INACT,0.0	CHEMBL591027,FN,ACT,0.0	CHEMBL1082771,TP,ACT,0.10999999940395355	CHEMBL1202331,TP,ACT,0.8500000238418579	CHEMBL2376795,TP,ACT,0.029999999329447746	CHEMBL308913,TP,ACT,0.6399999856948853	CHEMBL3804837,TP,ACT,0.9700000286102295	CHEMBL2047461,TP,ACT,0.41999998688697815	CHEMBL73791,TN,INACT,0.0	CHEMBL76949,TN,INACT,0.0	CHEMBL1688942,TP,ACT,0.9200000166893005	CHEMBL2047273,TP,ACT,0.9800000190734863	CHEMBL417096,TP,ACT,0.9800000190734863	CHEMBL473099,TP,ACT,0.5099999904632568	CHEMBL1914778,TP,ACT,0.9700000286102295	CHEMBL378619,TP,ACT,0.8199999928474426	CHEMBL1770987,TP,ACT,0.49000000953674316	CHEMBL1083084,TP,ACT,0.46000000834465027	CHEMBL109778,TN,INACT,0.0	CHEMBL602269,TN,INACT,0.0	CHEMBL27979,FN,ACT,0.0	CHEMBL303369,TN,INACT,0.0	CHEMBL291992,TN,INACT,0.0	CHEMBL123654,TN,INACT,0.0	CHEMBL2047454,FN,ACT,0.0	CHEMBL3805813,TP,ACT,0.7599999904632568	CHEMBL2376805,TP,ACT,0.9900000095367432	CHEMBL325935,TN,INACT,0.0	CHEMBL223490,TP,ACT,0.03999999910593033	CHEMBL516024,TN,INACT,0.0	CHEMBL2047467,FN,ACT,0.009999999776482582	CHEMBL2047447,TP,ACT,0.6700000166893005	CHEMBL450729,TN,INACT,0.0	CHEMBL552694,TP,ACT,0.949999988079071	CHEMBL456675,FP,INACT,0.05999999865889549	CHEMBL1935571,TP,ACT,0.9900000095367432	CHEMBL61120,TN,INACT,0.0	CHEMBL416453,TN,INACT,0.0	CHEMBL1096429,TP,ACT,1.0	CHEMBL320279,TN,INACT,0.0	CHEMBL451335,TN,INACT,0.0	CHEMBL214311,TP,ACT,0.9900000095367432	CHEMBL2398752,TN,INACT,0.0	CHEMBL594490,TP,ACT,1.0	CHEMBL3608763,TN,INACT,0.0	CHEMBL2314499,FP,INACT,0.9599999785423279	CHEMBL1088888,FP,INACT,0.33000001311302185	CHEMBL315096,TN,INACT,0.0	CHEMBL3234454,TN,INACT,0.0	CHEMBL595265,TN,INACT,0.0	CHEMBL90,TP,ACT,0.3199999928474426	CHEMBL3805361,TP,ACT,0.8600000143051147	CHEMBL297599,TN,INACT,0.0	CHEMBL327626,FP,INACT,0.019999999552965164	CHEMBL1923031,TP,ACT,0.25999999046325684	CHEMBL1923032,TP,ACT,0.019999999552965164	CHEMBL3314917,FP,INACT,0.10999999940395355	CHEMBL206303,TP,ACT,0.9900000095367432	CHEMBL213886,TP,ACT,0.9700000286102295	CHEMBL73096,TN,INACT,0.0	CHEMBL3604302,TN,INACT,0.0	CHEMBL1914773,TP,ACT,0.8999999761581421	CHEMBL2443002,TN,INACT,0.0	CHEMBL1770964,TP,ACT,0.8399999737739563	CHEMBL1770980,TP,ACT,0.9900000095367432	CHEMBL434284,TN,INACT,0.0	CHEMBL539343,TP,ACT,0.7200000286102295	CHEMBL150743,TN,INACT,0.0	CHEMBL325327,TP,ACT,1.0	CHEMBL1938843,TP,ACT,1.0	CHEMBL1688971,FN,ACT,0.0	CHEMBL1083098,TP,ACT,0.33000001311302185	CHEMBL377491,TP,ACT,0.800000011920929	CHEMBL377985,TP,ACT,0.09000000357627869	CHEMBL320254,TN,INACT,0.0	CHEMBL89689,TN,INACT,0.0	CHEMBL3354811,TP,ACT,0.9900000095367432	CHEMBL3290572,TP,ACT,0.9900000095367432	CHEMBL147365,TN,INACT,0.0	CHEMBL515428,TP,ACT,0.4099999964237213	CHEMBL1915026,TP,ACT,0.20000000298023224	CHEMBL2047264,TP,ACT,0.9700000286102295	CHEMBL1938841,FP,INACT,0.9900000095367432	CHEMBL2047274,FN,ACT,0.0	CHEMBL3236582,FN,ACT,0.0	CHEMBL1916503,TP,ACT,1.0	CHEMBL353087,TN,INACT,0.0	CHEMBL594022,TP,ACT,0.9599999785423279	CHEMBL1202321,TP,ACT,0.7099999785423279	CHEMBL1824228,TP,ACT,0.05999999865889549	CHEMBL1935450,TP,ACT,0.09000000357627869	CHEMBL233552,TN,INACT,0.0	CHEMBL103404,TN,INACT,0.009999999776482582	CHEMBL1914749,TP,ACT,1.0	CHEMBL429691,TP,ACT,0.7300000190734863	CHEMBL3819260,TP,ACT,0.6800000071525574	CHEMBL1223696,TN,INACT,0.0	CHEMBL47018,TN,INACT,0.0	CHEMBL54885,TN,INACT,0.009999999776482582	CHEMBL19439,TP,ACT,0.9300000071525574	CHEMBL262787,TN,INACT,0.0	CHEMBL1923030,FN,ACT,0.009999999776482582	CHEMBL414570,TN,INACT,0.0	CHEMBL173708,TN,INACT,0.0	CHEMBL382276,TP,ACT,1.0	CHEMBL2323582,FN,ACT,0.0	CHEMBL2375751,TP,ACT,0.029999999329447746	CHEMBL1938972,TP,ACT,0.9200000166893005	CHEMBL2314761,TP,ACT,0.25	CHEMBL3604301,TN,INACT,0.0	CHEMBL2436818,TN,INACT,0.0	CHEMBL18661,TP,ACT,0.05999999865889549	CHEMBL59931,TN,INACT,0.0	CHEMBL169675,TN,INACT,0.0	CHEMBL1914755,TP,ACT,0.7599999904632568	CHEMBL61231,TN,INACT,0.0	CHEMBL206451,TP,ACT,1.0	CHEMBL2373213,TN,INACT,0.0	CHEMBL565799,TN,INACT,0.0	CHEMBL3810142,TN,INACT,0.0	CHEMBL298203,TN,INACT,0.0	CHEMBL259957,TP,ACT,0.9900000095367432	CHEMBL359141,TN,INACT,0.0	CHEMBL340801,TP,ACT,0.9900000095367432	CHEMBL594721,TP,ACT,1.0	CHEMBL3290578,TP,ACT,1.0	CHEMBL2314766,FP,INACT,0.9900000095367432	CHEMBL596562,TP,ACT,1.0	CHEMBL294349,TN,INACT,0.009999999776482582	CHEMBL1770979,TP,ACT,1.0	CHEMBL3393525,TP,ACT,0.800000011920929	CHEMBL12344,TP,ACT,0.949999988079071	CHEMBL2376790,TP,ACT,1.0	CHEMBL330885,TN,INACT,0.0	CHEMBL302150,TN,INACT,0.0	CHEMBL33720,TN,INACT,0.0	CHEMBL2375764,TP,ACT,0.019999999552965164	CHEMBL2163921,TN,INACT,0.0	CHEMBL2163920,TN,INACT,0.0	CHEMBL45160,TN,INACT,0.0	CHEMBL1202328,TP,ACT,0.6899999976158142	CHEMBL63905,TN,INACT,0.0	CHEMBL405044,TP,ACT,0.25999999046325684	CHEMBL1688973,TP,ACT,0.36000001430511475	CHEMBL143341,TN,INACT,0.0	CHEMBL1082296,TP,ACT,0.5299999713897705	CHEMBL39879,TN,INACT,0.0	CHEMBL608813,TN,INACT,0.0	CHEMBL1910384,TN,INACT,0.0	CHEMBL1091559,TP,ACT,0.9900000095367432	CHEMBL1914774,TP,ACT,0.9300000071525574	CHEMBL380054,TN,INACT,0.0	CHEMBL591250,TP,ACT,0.8299999833106995	CHEMBL1192069,TN,INACT,0.0	CHEMBL303203,TN,INACT,0.0	CHEMBL106570,FP,INACT,0.800000011920929	CHEMBL322537,TN,INACT,0.0	CHEMBL2375760,TP,ACT,0.9300000071525574	CHEMBL1914754,FN,ACT,0.009999999776482582	CHEMBL53662,TN,INACT,0.0	CHEMBL592663,FN,ACT,0.0	CHEMBL241279,TN,INACT,0.0	CHEMBL2372075,TN,INACT,0.0	CHEMBL505061,TP,ACT,1.0	CHEMBL76576,TN,INACT,0.0	CHEMBL106602,TN,INACT,0.0	CHEMBL1910380,FP,INACT,0.11999999731779099	CHEMBL1915536,TP,ACT,1.0	CHEMBL474449,TP,ACT,0.11999999731779099	CHEMBL414605,TN,INACT,0.0	CHEMBL378788,TP,ACT,0.05999999865889549	CHEMBL63003,TN,INACT,0.0	CHEMBL1243367,FN,ACT,0.009999999776482582	CHEMBL204843,TP,ACT,1.0	CHEMBL1770984,TP,ACT,0.019999999552965164	CHEMBL1774600,TP,ACT,0.029999999329447746	CHEMBL1172775,FN,ACT,0.0	CHEMBL72060,TN,INACT,0.009999999776482582	CHEMBL298649,TN,INACT,0.0	CHEMBL1770965,TP,ACT,1.0	CHEMBL3740837,TP,ACT,0.2199999988079071	CHEMBL508030,TN,INACT,0.0	CHEMBL323245,TN,INACT,0.0	CHEMBL3393531,TP,ACT,0.5	CHEMBL89688,TN,INACT,0.0	CHEMBL268490,TP,ACT,0.17000000178813934	CHEMBL260850,TP,ACT,0.019999999552965164	CHEMBL2375752,TP,ACT,0.5400000214576721	CHEMBL489061,TP,ACT,0.9599999785423279	CHEMBL1162347,TP,ACT,0.9100000262260437	CHEMBL440864,TN,INACT,0.0	CHEMBL1789800,FN,ACT,0.0	CHEMBL62804,TN,INACT,0.0	CHEMBL1688944,TP,ACT,0.9599999785423279	CHEMBL31524,TN,INACT,0.0	CHEMBL11262,TN,INACT,0.0	CHEMBL70728,TN,INACT,0.0	CHEMBL1915046,TP,ACT,0.9900000095367432	CHEMBL294849,TN,INACT,0.0	CHEMBL300725,TN,INACT,0.0	CHEMBL3236560,TP,ACT,0.9900000095367432	CHEMBL2436713,TN,INACT,0.0	CHEMBL79126,TP,ACT,0.9800000190734863	CHEMBL316648,TN,INACT,0.0	CHEMBL323951,TN,INACT,0.0	CHEMBL2047258,TP,ACT,0.8399999737739563	CHEMBL1914788,TP,ACT,0.7799999713897705	CHEMBL3739430,TP,ACT,0.7200000286102295	CHEMBL1923026,TP,ACT,0.05000000074505806	CHEMBL282426,TN,INACT,0.0	CHEMBL407818,TN,INACT,0.0	CHEMBL111023,TN,INACT,0.0	CHEMBL1688974,FN,ACT,0.0	CHEMBL2113072,TN,INACT,0.0	CHEMBL1915042,TP,ACT,0.9900000095367432	CHEMBL349689,TN,INACT,0.0	CHEMBL2436720,TN,INACT,0.0	CHEMBL370135,TP,ACT,0.9900000095367432	CHEMBL67109,TN,INACT,0.0	CHEMBL2375363,TP,ACT,0.7200000286102295	CHEMBL123137,TP,ACT,0.8999999761581421	CHEMBL3629827,TP,ACT,1.0	CHEMBL717,TN,INACT,0.0	CHEMBL302886,TN,INACT,0.0	CHEMBL3393557,TP,ACT,0.8799999952316284	CHEMBL2062852,TN,INACT,0.0	CHEMBL2047263,TP,ACT,0.9900000095367432	CHEMBL462650,TN,INACT,0.0	CHEMBL95727,TN,INACT,0.0	CHEMBL62703,TN,INACT,0.0	CHEMBL1623307,TN,INACT,0.0	CHEMBL452847,TP,ACT,1.0	CHEMBL12608,TP,ACT,0.3100000023841858	CHEMBL2436825,TN,INACT,0.0	CHEMBL1935566,TP,ACT,0.9900000095367432	CHEMBL522673,TP,ACT,0.8700000047683716	CHEMBL2163568,TN,INACT,0.0	CHEMBL374602,TN,INACT,0.0	CHEMBL112314,TN,INACT,0.0	CHEMBL1915535,TP,ACT,1.0	CHEMBL3393522,TP,ACT,0.03999999910593033	CHEMBL1935574,TP,ACT,0.9900000095367432	CHEMBL259956,TP,ACT,1.0	CHEMBL510130,TN,INACT,0.0	CHEMBL2376797,TP,ACT,0.9900000095367432	CHEMBL1774589,TP,ACT,0.9800000190734863	CHEMBL384248,TN,INACT,0.0	CHEMBL88506,TN,INACT,0.0	CHEMBL512035,TN,INACT,0.0	CHEMBL1923533,FN,ACT,0.0	CHEMBL489070,TP,ACT,0.47999998927116394	CHEMBL610626,TP,ACT,0.9900000095367432	CHEMBL1914796,TP,ACT,0.9800000190734863	CHEMBL414165,TN,INACT,0.0	CHEMBL175698,TN,INACT,0.0	CHEMBL45269,TN,INACT,0.009999999776482582	CHEMBL323175,TN,INACT,0.0	CHEMBL48031,TN,INACT,0.0	CHEMBL377954,TP,ACT,0.9900000095367432	CHEMBL273642,TN,INACT,0.0	CHEMBL3627724,TN,INACT,0.0	CHEMBL255791,TN,INACT,0.0	CHEMBL1916491,TN,INACT,0.0	CHEMBL272853,TN,INACT,0.009999999776482582	CHEMBL196866,TN,INACT,0.0	CHEMBL2436715,TN,INACT,0.0	CHEMBL186108,TP,ACT,0.8500000238418579	CHEMBL2047261,TP,ACT,1.0	CHEMBL1083160,TP,ACT,0.019999999552965164	CHEMBL2314765,TP,ACT,1.0	CHEMBL1086328,TP,ACT,0.17000000178813934	CHEMBL521996,TP,ACT,0.11999999731779099	CHEMBL1076300,TP,ACT,0.4699999988079071	CHEMBL416069,TN,INACT,0.0	CHEMBL58617,TN,INACT,0.0	CHEMBL584,TN,INACT,0.0	CHEMBL1916635,TN,INACT,0.0	CHEMBL129660,TP,ACT,0.9900000095367432	CHEMBL128637,TP,ACT,0.28999999165534973	CHEMBL345357,TN,INACT,0.0	CHEMBL297335,TN,INACT,0.0	CHEMBL334933,TN,INACT,0.0	CHEMBL1202329,TP,ACT,0.7300000190734863	CHEMBL344602,TN,INACT,0.0	CHEMBL461089,TN,INACT,0.0	CHEMBL373579,TP,ACT,0.09000000357627869	CHEMBL589746,TP,ACT,0.05999999865889549	CHEMBL214312,TP,ACT,0.949999988079071	CHEMBL1914794,TP,ACT,0.03999999910593033	CHEMBL300926,TN,INACT,0.0	CHEMBL3393543,TP,ACT,0.47999998927116394	CHEMBL44134,TN,INACT,0.0	CHEMBL1914544,TP,ACT,0.14000000059604645	CHEMBL2436822,TN,INACT,0.0	CHEMBL1923034,FN,ACT,0.0	CHEMBL3290581,TP,ACT,0.949999988079071	CHEMBL1090532,TP,ACT,0.1899999976158142	CHEMBL3633650,TN,INACT,0.0	CHEMBL113,TN,INACT,0.0	CHEMBL337243,TN,INACT,0.0	CHEMBL591249,TP,ACT,0.029999999329447746	CHEMBL454891,TP,ACT,1.0	CHEMBL3088176,TN,INACT,0.0	CHEMBL3403332,TN,INACT,0.0	CHEMBL2047473,TP,ACT,0.7200000286102295	CHEMBL365257,FN,ACT,0.009999999776482582	CHEMBL553666,FP,INACT,0.019999999552965164	CHEMBL205768,TN,INACT,0.0	CHEMBL74515,TN,INACT,0.0	CHEMBL400404,TN,INACT,0.0	CHEMBL60559,TN,INACT,0.0	CHEMBL612059,TP,ACT,0.9700000286102295	CHEMBL2047458,TP,ACT,0.8899999856948853	CHEMBL2376807,TP,ACT,0.49000000953674316	CHEMBL1907839,TN,INACT,0.0	CHEMBL151619,TN,INACT,0.0	CHEMBL1938978,TP,ACT,0.019999999552965164	CHEMBL332471,TN,INACT,0.0	CHEMBL3628046,TP,ACT,1.0	CHEMBL1688988,TP,ACT,0.30000001192092896	CHEMBL2047446,FN,ACT,0.0	CHEMBL545363,TN,INACT,0.0	CHEMBL104947,TN,INACT,0.0	CHEMBL121679,TP,ACT,0.8700000047683716	CHEMBL1914793,FN,ACT,0.009999999776482582	CHEMBL128470,FN,ACT,0.0	CHEMBL609289,TP,ACT,0.3100000023841858	CHEMBL2047463,TP,ACT,0.05000000074505806	CHEMBL1938975,FN,ACT,0.009999999776482582	CHEMBL1791272,TN,INACT,0.0	CHEMBL1770972,TP,ACT,0.019999999552965164	CHEMBL11919,FN,ACT,0.0	CHEMBL153051,FN,ACT,0.0	CHEMBL535602,TN,INACT,0.0	CHEMBL72738,TN,INACT,0.0	CHEMBL1086327,TP,ACT,0.33000001311302185	CHEMBL527880,TN,INACT,0.0	CHEMBL43934,TP,ACT,0.8999999761581421	CHEMBL315974,TN,INACT,0.0	CHEMBL379447,TP,ACT,0.8799999952316284	CHEMBL341087,TP,ACT,0.75	CHEMBL308924,TN,INACT,0.0	CHEMBL609161,TP,ACT,0.9700000286102295	CHEMBL302282,TN,INACT,0.0	CHEMBL354126,TN,INACT,0.0	CHEMBL1091777,TN,INACT,0.0	CHEMBL3629829,FP,INACT,1.0	CHEMBL595880,TP,ACT,0.9100000262260437	CHEMBL330674,TN,INACT,0.0	CHEMBL3290583,FP,INACT,0.9900000095367432	CHEMBL1915532,FN,ACT,0.0	CHEMBL210931,TN,INACT,0.0	CHEMBL551047,TP,ACT,0.5699999928474426	CHEMBL80807,TN,INACT,0.0	CHEMBL400190,TN,INACT,0.0	CHEMBL453822,TN,INACT,0.0	CHEMBL309017,TN,INACT,0.0	CHEMBL62115,TN,INACT,0.0	CHEMBL205868,TP,ACT,0.9900000095367432	CHEMBL1770993,TP,ACT,0.550000011920929	CHEMBL205731,TP,ACT,1.0	CHEMBL375591,TN,INACT,0.0	CHEMBL428606,TP,ACT,0.17000000178813934	CHEMBL1632411,TP,ACT,0.05000000074505806	CHEMBL3393550,TP,ACT,0.5400000214576721	CHEMBL89457,TN,INACT,0.0	CHEMBL3290580,TP,ACT,1.0	CHEMBL59517,TN,INACT,0.0	CHEMBL1915048,TP,ACT,1.0	CHEMBL357077,TN,INACT,0.0	CHEMBL59597,TN,INACT,0.0	CHEMBL212705,TP,ACT,0.30000001192092896	CHEMBL601946,TP,ACT,0.029999999329447746	CHEMBL320124,TN,INACT,0.0	CHEMBL1914462,TP,ACT,1.0	CHEMBL452869,TP,ACT,0.9800000190734863	CHEMBL1914757,TP,ACT,0.9800000190734863	CHEMBL1237146,TP,ACT,0.23999999463558197	CHEMBL320174,TN,INACT,0.0	CHEMBL437,TN,INACT,0.0	CHEMBL289284,TN,INACT,0.0	CHEMBL53842,TN,INACT,0.0	CHEMBL429238,TN,INACT,0.0	CHEMBL1576791,TN,INACT,0.0	CHEMBL241080,TN,INACT,0.0	CHEMBL76403,TN,INACT,0.0	CHEMBL106259,TN,INACT,0.0	CHEMBL433814,TN,INACT,0.0	CHEMBL33224,TN,INACT,0.0	CHEMBL561250,TP,ACT,0.6100000143051147	CHEMBL227378,TN,INACT,0.0	CHEMBL251997,TN,INACT,0.0	CHEMBL1938846,TP,ACT,0.10000000149011612	CHEMBL1923028,FN,ACT,0.0	CHEMBL42359,TN,INACT,0.0	CHEMBL355851,TN,INACT,0.0	CHEMBL62601,TN,INACT,0.0	

