ImageNetInceptionV2 CHEMBL3459 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	306
Number of inactive compounds :	306
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3459_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3459_adam_0.0001_15_0.8/
---------------------------------
Training samples: 383
Validation samples: 120
--
Training Step: 1  | time: 43.193s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/383
[A[ATraining Step: 2  | total loss: [1m[32m0.61292[0m[0m | time: 55.740s
[2K
| Adam | epoch: 001 | loss: 0.61292 - acc: 0.5344 -- iter: 064/383
[A[ATraining Step: 3  | total loss: [1m[32m0.66706[0m[0m | time: 68.556s
[2K
| Adam | epoch: 001 | loss: 0.66706 - acc: 0.5574 -- iter: 096/383
[A[ATraining Step: 4  | total loss: [1m[32m0.70077[0m[0m | time: 81.401s
[2K
| Adam | epoch: 001 | loss: 0.70077 - acc: 0.5378 -- iter: 128/383
[A[ATraining Step: 5  | total loss: [1m[32m0.67386[0m[0m | time: 94.047s
[2K
| Adam | epoch: 001 | loss: 0.67386 - acc: 0.5982 -- iter: 160/383
[A[ATraining Step: 6  | total loss: [1m[32m0.65241[0m[0m | time: 102.749s
[2K
| Adam | epoch: 001 | loss: 0.65241 - acc: 0.6355 -- iter: 192/383
[A[ATraining Step: 7  | total loss: [1m[32m0.64389[0m[0m | time: 110.703s
[2K
| Adam | epoch: 001 | loss: 0.64389 - acc: 0.6480 -- iter: 224/383
[A[ATraining Step: 8  | total loss: [1m[32m0.57312[0m[0m | time: 118.567s
[2K
| Adam | epoch: 001 | loss: 0.57312 - acc: 0.7054 -- iter: 256/383
[A[ATraining Step: 9  | total loss: [1m[32m0.58204[0m[0m | time: 128.331s
[2K
| Adam | epoch: 001 | loss: 0.58204 - acc: 0.6959 -- iter: 288/383
[A[ATraining Step: 10  | total loss: [1m[32m0.53486[0m[0m | time: 140.794s
[2K
| Adam | epoch: 001 | loss: 0.53486 - acc: 0.7386 -- iter: 320/383
[A[ATraining Step: 11  | total loss: [1m[32m0.55127[0m[0m | time: 153.020s
[2K
| Adam | epoch: 001 | loss: 0.55127 - acc: 0.7144 -- iter: 352/383
[A[ATraining Step: 12  | total loss: [1m[32m0.52628[0m[0m | time: 185.298s
[2K
| Adam | epoch: 001 | loss: 0.52628 - acc: 0.7726 | val_loss: 1.41320 - val_acc: 0.5667 -- iter: 383/383
--
Training Step: 13  | total loss: [1m[32m0.50507[0m[0m | time: 9.078s
[2K
| Adam | epoch: 002 | loss: 0.50507 - acc: 0.7733 -- iter: 032/383
[A[ATraining Step: 14  | total loss: [1m[32m0.47309[0m[0m | time: 21.806s
[2K
| Adam | epoch: 002 | loss: 0.47309 - acc: 0.8396 -- iter: 064/383
[A[ATraining Step: 15  | total loss: [1m[32m0.47049[0m[0m | time: 34.444s
[2K
| Adam | epoch: 002 | loss: 0.47049 - acc: 0.8046 -- iter: 096/383
[A[ATraining Step: 16  | total loss: [1m[32m0.45445[0m[0m | time: 47.103s
[2K
| Adam | epoch: 002 | loss: 0.45445 - acc: 0.8310 -- iter: 128/383
[A[ATraining Step: 17  | total loss: [1m[32m0.43715[0m[0m | time: 58.915s
[2K
| Adam | epoch: 002 | loss: 0.43715 - acc: 0.8581 -- iter: 160/383
[A[ATraining Step: 18  | total loss: [1m[32m0.46496[0m[0m | time: 71.057s
[2K
| Adam | epoch: 002 | loss: 0.46496 - acc: 0.8315 -- iter: 192/383
[A[ATraining Step: 19  | total loss: [1m[32m0.47455[0m[0m | time: 82.388s
[2K
| Adam | epoch: 002 | loss: 0.47455 - acc: 0.8043 -- iter: 224/383
[A[ATraining Step: 20  | total loss: [1m[32m0.58575[0m[0m | time: 90.349s
[2K
| Adam | epoch: 002 | loss: 0.58575 - acc: 0.7366 -- iter: 256/383
[A[ATraining Step: 21  | total loss: [1m[32m0.47967[0m[0m | time: 98.198s
[2K
| Adam | epoch: 002 | loss: 0.47967 - acc: 0.8087 -- iter: 288/383
[A[ATraining Step: 22  | total loss: [1m[32m0.43581[0m[0m | time: 106.071s
[2K
| Adam | epoch: 002 | loss: 0.43581 - acc: 0.8192 -- iter: 320/383
[A[ATraining Step: 23  | total loss: [1m[32m0.40333[0m[0m | time: 113.895s
[2K
| Adam | epoch: 002 | loss: 0.40333 - acc: 0.8445 -- iter: 352/383
[A[ATraining Step: 24  | total loss: [1m[32m0.35492[0m[0m | time: 130.297s
[2K
| Adam | epoch: 002 | loss: 0.35492 - acc: 0.8794 | val_loss: 1.11385 - val_acc: 0.5667 -- iter: 383/383
--
Training Step: 25  | total loss: [1m[32m0.31131[0m[0m | time: 12.147s
[2K
| Adam | epoch: 003 | loss: 0.31131 - acc: 0.9038 -- iter: 032/383
[A[ATraining Step: 26  | total loss: [1m[32m0.31779[0m[0m | time: 24.853s
[2K
| Adam | epoch: 003 | loss: 0.31779 - acc: 0.8951 -- iter: 064/383
[A[ATraining Step: 27  | total loss: [1m[32m0.29736[0m[0m | time: 33.489s
[2K
| Adam | epoch: 003 | loss: 0.29736 - acc: 0.9138 -- iter: 096/383
[A[ATraining Step: 28  | total loss: [1m[32m0.28998[0m[0m | time: 41.298s
[2K
| Adam | epoch: 003 | loss: 0.28998 - acc: 0.9119 -- iter: 128/383
[A[ATraining Step: 29  | total loss: [1m[32m0.27508[0m[0m | time: 49.141s
[2K
| Adam | epoch: 003 | loss: 0.27508 - acc: 0.9181 -- iter: 160/383
[A[ATraining Step: 30  | total loss: [1m[32m0.26908[0m[0m | time: 58.792s
[2K
| Adam | epoch: 003 | loss: 0.26908 - acc: 0.9079 -- iter: 192/383
[A[ATraining Step: 31  | total loss: [1m[32m0.23108[0m[0m | time: 71.003s
[2K
| Adam | epoch: 003 | loss: 0.23108 - acc: 0.9292 -- iter: 224/383
[A[ATraining Step: 32  | total loss: [1m[32m0.21568[0m[0m | time: 83.474s
[2K
| Adam | epoch: 003 | loss: 0.21568 - acc: 0.9310 -- iter: 256/383
[A[ATraining Step: 33  | total loss: [1m[32m0.21784[0m[0m | time: 95.868s
[2K
| Adam | epoch: 003 | loss: 0.21784 - acc: 0.9393 -- iter: 288/383
[A[ATraining Step: 34  | total loss: [1m[32m0.18935[0m[0m | time: 108.418s
[2K
| Adam | epoch: 003 | loss: 0.18935 - acc: 0.9523 -- iter: 320/383
[A[ATraining Step: 35  | total loss: [1m[32m0.16087[0m[0m | time: 120.409s
[2K
| Adam | epoch: 003 | loss: 0.16087 - acc: 0.9623 -- iter: 352/383
[A[ATraining Step: 36  | total loss: [1m[32m0.16125[0m[0m | time: 136.986s
[2K
| Adam | epoch: 003 | loss: 0.16125 - acc: 0.9636 | val_loss: 1.59746 - val_acc: 0.4333 -- iter: 383/383
--
Training Step: 37  | total loss: [1m[32m0.14346[0m[0m | time: 10.648s
[2K
| Adam | epoch: 004 | loss: 0.14346 - acc: 0.9646 -- iter: 032/383
[A[ATraining Step: 38  | total loss: [1m[32m0.13690[0m[0m | time: 18.437s
[2K
| Adam | epoch: 004 | loss: 0.13690 - acc: 0.9654 -- iter: 064/383
[A[ATraining Step: 39  | total loss: [1m[32m0.12541[0m[0m | time: 26.071s
[2K
| Adam | epoch: 004 | loss: 0.12541 - acc: 0.9597 -- iter: 096/383
[A[ATraining Step: 40  | total loss: [1m[32m0.10775[0m[0m | time: 33.836s
[2K
| Adam | epoch: 004 | loss: 0.10775 - acc: 0.9673 -- iter: 128/383
[A[ATraining Step: 41  | total loss: [1m[32m0.09955[0m[0m | time: 41.773s
[2K
| Adam | epoch: 004 | loss: 0.09955 - acc: 0.9675 -- iter: 160/383
[A[ATraining Step: 42  | total loss: [1m[32m0.08708[0m[0m | time: 49.591s
[2K
| Adam | epoch: 004 | loss: 0.08708 - acc: 0.9734 -- iter: 192/383
[A[ATraining Step: 43  | total loss: [1m[32m0.11279[0m[0m | time: 57.343s
[2K
| Adam | epoch: 004 | loss: 0.11279 - acc: 0.9726 -- iter: 224/383
[A[ATraining Step: 44  | total loss: [1m[32m0.09973[0m[0m | time: 65.180s
[2K
| Adam | epoch: 004 | loss: 0.09973 - acc: 0.9773 -- iter: 256/383
[A[ATraining Step: 45  | total loss: [1m[32m0.08781[0m[0m | time: 73.002s
[2K
| Adam | epoch: 004 | loss: 0.08781 - acc: 0.9812 -- iter: 288/383
[A[ATraining Step: 46  | total loss: [1m[32m0.09824[0m[0m | time: 80.855s
[2K
| Adam | epoch: 004 | loss: 0.09824 - acc: 0.9791 -- iter: 320/383
[A[ATraining Step: 47  | total loss: [1m[32m0.09005[0m[0m | time: 88.566s
[2K
| Adam | epoch: 004 | loss: 0.09005 - acc: 0.9774 -- iter: 352/383
[A[ATraining Step: 48  | total loss: [1m[32m0.08268[0m[0m | time: 101.790s
[2K
| Adam | epoch: 004 | loss: 0.08268 - acc: 0.9760 | val_loss: 1.35360 - val_acc: 0.4750 -- iter: 383/383
--
Training Step: 49  | total loss: [1m[32m0.07719[0m[0m | time: 7.957s
[2K
| Adam | epoch: 005 | loss: 0.07719 - acc: 0.9749 -- iter: 032/383
[A[ATraining Step: 50  | total loss: [1m[32m0.06837[0m[0m | time: 15.635s
[2K
| Adam | epoch: 005 | loss: 0.06837 - acc: 0.9788 -- iter: 064/383
[A[ATraining Step: 51  | total loss: [1m[32m0.06023[0m[0m | time: 23.326s
[2K
| Adam | epoch: 005 | loss: 0.06023 - acc: 0.9820 -- iter: 096/383
[A[ATraining Step: 52  | total loss: [1m[32m0.05861[0m[0m | time: 30.855s
[2K
| Adam | epoch: 005 | loss: 0.05861 - acc: 0.9799 -- iter: 128/383
[A[ATraining Step: 53  | total loss: [1m[32m0.05237[0m[0m | time: 38.633s
[2K
| Adam | epoch: 005 | loss: 0.05237 - acc: 0.9828 -- iter: 160/383
[A[ATraining Step: 54  | total loss: [1m[32m0.07255[0m[0m | time: 46.311s
[2K
| Adam | epoch: 005 | loss: 0.07255 - acc: 0.9808 -- iter: 192/383
[A[ATraining Step: 55  | total loss: [1m[32m0.06344[0m[0m | time: 53.954s
[2K
| Adam | epoch: 005 | loss: 0.06344 - acc: 0.9835 -- iter: 224/383
[A[ATraining Step: 56  | total loss: [1m[32m0.05581[0m[0m | time: 61.803s
[2K
| Adam | epoch: 005 | loss: 0.05581 - acc: 0.9859 -- iter: 256/383
[A[ATraining Step: 57  | total loss: [1m[32m0.04960[0m[0m | time: 69.511s
[2K
| Adam | epoch: 005 | loss: 0.04960 - acc: 0.9878 -- iter: 288/383
[A[ATraining Step: 58  | total loss: [1m[32m0.09245[0m[0m | time: 77.368s
[2K
| Adam | epoch: 005 | loss: 0.09245 - acc: 0.9852 -- iter: 320/383
[A[ATraining Step: 59  | total loss: [1m[32m0.17506[0m[0m | time: 85.127s
[2K
| Adam | epoch: 005 | loss: 0.17506 - acc: 0.9662 -- iter: 352/383
[A[ATraining Step: 60  | total loss: [1m[32m0.15440[0m[0m | time: 98.141s
[2K
| Adam | epoch: 005 | loss: 0.15440 - acc: 0.9707 | val_loss: 3.44797 - val_acc: 0.4333 -- iter: 383/383
--
Training Step: 61  | total loss: [1m[32m0.13743[0m[0m | time: 7.897s
[2K
| Adam | epoch: 006 | loss: 0.13743 - acc: 0.9745 -- iter: 032/383
[A[ATraining Step: 62  | total loss: [1m[32m0.12584[0m[0m | time: 15.634s
[2K
| Adam | epoch: 006 | loss: 0.12584 - acc: 0.9778 -- iter: 064/383
[A[ATraining Step: 63  | total loss: [1m[32m0.11616[0m[0m | time: 23.497s
[2K
| Adam | epoch: 006 | loss: 0.11616 - acc: 0.9806 -- iter: 096/383
[A[ATraining Step: 64  | total loss: [1m[32m0.10271[0m[0m | time: 31.027s
[2K
| Adam | epoch: 006 | loss: 0.10271 - acc: 0.9830 -- iter: 128/383
[A[ATraining Step: 65  | total loss: [1m[32m0.11543[0m[0m | time: 38.586s
[2K
| Adam | epoch: 006 | loss: 0.11543 - acc: 0.9732 -- iter: 160/383
[A[ATraining Step: 66  | total loss: [1m[32m0.10931[0m[0m | time: 46.417s
[2K
| Adam | epoch: 006 | loss: 0.10931 - acc: 0.9764 -- iter: 192/383
[A[ATraining Step: 67  | total loss: [1m[32m0.09881[0m[0m | time: 54.168s
[2K
| Adam | epoch: 006 | loss: 0.09881 - acc: 0.9793 -- iter: 224/383
[A[ATraining Step: 68  | total loss: [1m[32m0.08831[0m[0m | time: 61.964s
[2K
| Adam | epoch: 006 | loss: 0.08831 - acc: 0.9817 -- iter: 256/383
[A[ATraining Step: 69  | total loss: [1m[32m0.08163[0m[0m | time: 69.806s
[2K
| Adam | epoch: 006 | loss: 0.08163 - acc: 0.9839 -- iter: 288/383
[A[ATraining Step: 70  | total loss: [1m[32m0.11239[0m[0m | time: 77.394s
[2K
| Adam | epoch: 006 | loss: 0.11239 - acc: 0.9749 -- iter: 320/383
[A[ATraining Step: 71  | total loss: [1m[32m0.10635[0m[0m | time: 85.139s
[2K
| Adam | epoch: 006 | loss: 0.10635 - acc: 0.9742 -- iter: 352/383
[A[ATraining Step: 72  | total loss: [1m[32m0.10027[0m[0m | time: 98.190s
[2K
| Adam | epoch: 006 | loss: 0.10027 - acc: 0.9771 | val_loss: 1.56569 - val_acc: 0.6333 -- iter: 383/383
--
Training Step: 73  | total loss: [1m[32m0.09118[0m[0m | time: 7.824s
[2K
| Adam | epoch: 007 | loss: 0.09118 - acc: 0.9797 -- iter: 032/383
[A[ATraining Step: 74  | total loss: [1m[32m0.08311[0m[0m | time: 15.507s
[2K
| Adam | epoch: 007 | loss: 0.08311 - acc: 0.9819 -- iter: 064/383
[A[ATraining Step: 75  | total loss: [1m[32m0.07587[0m[0m | time: 23.412s
[2K
| Adam | epoch: 007 | loss: 0.07587 - acc: 0.9838 -- iter: 096/383
[A[ATraining Step: 76  | total loss: [1m[32m0.07929[0m[0m | time: 31.190s
[2K
| Adam | epoch: 007 | loss: 0.07929 - acc: 0.9822 -- iter: 128/383
[A[ATraining Step: 77  | total loss: [1m[32m0.07611[0m[0m | time: 38.815s
[2K
| Adam | epoch: 007 | loss: 0.07611 - acc: 0.9808 -- iter: 160/383
[A[ATraining Step: 78  | total loss: [1m[32m0.07160[0m[0m | time: 46.330s
[2K
| Adam | epoch: 007 | loss: 0.07160 - acc: 0.9828 -- iter: 192/383
[A[ATraining Step: 79  | total loss: [1m[32m0.06584[0m[0m | time: 54.141s
[2K
| Adam | epoch: 007 | loss: 0.06584 - acc: 0.9846 -- iter: 224/383
[A[ATraining Step: 80  | total loss: [1m[32m0.06018[0m[0m | time: 61.782s
[2K
| Adam | epoch: 007 | loss: 0.06018 - acc: 0.9862 -- iter: 256/383
[A[ATraining Step: 81  | total loss: [1m[32m0.06715[0m[0m | time: 69.655s
[2K
| Adam | epoch: 007 | loss: 0.06715 - acc: 0.9812 -- iter: 288/383
[A[ATraining Step: 82  | total loss: [1m[32m0.06156[0m[0m | time: 77.414s
[2K
| Adam | epoch: 007 | loss: 0.06156 - acc: 0.9831 -- iter: 320/383
[A[ATraining Step: 83  | total loss: [1m[32m0.05796[0m[0m | time: 85.298s
[2K
| Adam | epoch: 007 | loss: 0.05796 - acc: 0.9848 -- iter: 352/383
[A[ATraining Step: 84  | total loss: [1m[32m0.05941[0m[0m | time: 98.375s
[2K
| Adam | epoch: 007 | loss: 0.05941 - acc: 0.9832 | val_loss: 7.31790 - val_acc: 0.4333 -- iter: 383/383
--
Training Step: 85  | total loss: [1m[32m0.09392[0m[0m | time: 7.589s
[2K
| Adam | epoch: 008 | loss: 0.09392 - acc: 0.9818 -- iter: 032/383
[A[ATraining Step: 86  | total loss: [1m[32m0.08529[0m[0m | time: 15.451s
[2K
| Adam | epoch: 008 | loss: 0.08529 - acc: 0.9836 -- iter: 064/383
[A[ATraining Step: 87  | total loss: [1m[32m0.07766[0m[0m | time: 23.242s
[2K
| Adam | epoch: 008 | loss: 0.07766 - acc: 0.9852 -- iter: 096/383
[A[ATraining Step: 88  | total loss: [1m[32m0.07163[0m[0m | time: 31.101s
[2K
| Adam | epoch: 008 | loss: 0.07163 - acc: 0.9867 -- iter: 128/383
[A[ATraining Step: 89  | total loss: [1m[32m0.08037[0m[0m | time: 38.902s
[2K
| Adam | epoch: 008 | loss: 0.08037 - acc: 0.9818 -- iter: 160/383
[A[ATraining Step: 90  | total loss: [1m[32m0.07341[0m[0m | time: 46.435s
[2K
| Adam | epoch: 008 | loss: 0.07341 - acc: 0.9836 -- iter: 192/383
[A[ATraining Step: 91  | total loss: [1m[32m0.07018[0m[0m | time: 53.944s
[2K
| Adam | epoch: 008 | loss: 0.07018 - acc: 0.9852 -- iter: 224/383
[A[ATraining Step: 92  | total loss: [1m[32m0.06459[0m[0m | time: 61.648s
[2K
| Adam | epoch: 008 | loss: 0.06459 - acc: 0.9867 -- iter: 256/383
[A[ATraining Step: 93  | total loss: [1m[32m0.05881[0m[0m | time: 69.422s
[2K
| Adam | epoch: 008 | loss: 0.05881 - acc: 0.9880 -- iter: 288/383
[A[ATraining Step: 94  | total loss: [1m[32m0.05480[0m[0m | time: 77.091s
[2K
| Adam | epoch: 008 | loss: 0.05480 - acc: 0.9892 -- iter: 320/383
[A[ATraining Step: 95  | total loss: [1m[32m0.05117[0m[0m | time: 84.850s
[2K
| Adam | epoch: 008 | loss: 0.05117 - acc: 0.9903 -- iter: 352/383
[A[ATraining Step: 96  | total loss: [1m[32m0.04666[0m[0m | time: 97.958s
[2K
| Adam | epoch: 008 | loss: 0.04666 - acc: 0.9913 | val_loss: 4.52419 - val_acc: 0.5667 -- iter: 383/383
--
Training Step: 97  | total loss: [1m[32m0.04336[0m[0m | time: 7.738s
[2K
| Adam | epoch: 009 | loss: 0.04336 - acc: 0.9922 -- iter: 032/383
[A[ATraining Step: 98  | total loss: [1m[32m0.03934[0m[0m | time: 15.473s
[2K
| Adam | epoch: 009 | loss: 0.03934 - acc: 0.9929 -- iter: 064/383
[A[ATraining Step: 99  | total loss: [1m[32m0.03581[0m[0m | time: 23.158s
[2K
| Adam | epoch: 009 | loss: 0.03581 - acc: 0.9936 -- iter: 096/383
[A[ATraining Step: 100  | total loss: [1m[32m0.03959[0m[0m | time: 31.100s
[2K
| Adam | epoch: 009 | loss: 0.03959 - acc: 0.9943 -- iter: 128/383
[A[ATraining Step: 101  | total loss: [1m[32m0.03607[0m[0m | time: 38.787s
[2K
| Adam | epoch: 009 | loss: 0.03607 - acc: 0.9949 -- iter: 160/383
[A[ATraining Step: 102  | total loss: [1m[32m0.03315[0m[0m | time: 46.452s
[2K
| Adam | epoch: 009 | loss: 0.03315 - acc: 0.9954 -- iter: 192/383
[A[ATraining Step: 103  | total loss: [1m[32m0.03176[0m[0m | time: 54.193s
[2K
| Adam | epoch: 009 | loss: 0.03176 - acc: 0.9958 -- iter: 224/383
[A[ATraining Step: 104  | total loss: [1m[32m0.02923[0m[0m | time: 61.633s
[2K
| Adam | epoch: 009 | loss: 0.02923 - acc: 0.9962 -- iter: 256/383
[A[ATraining Step: 105  | total loss: [1m[32m0.02694[0m[0m | time: 69.392s
[2K
| Adam | epoch: 009 | loss: 0.02694 - acc: 0.9966 -- iter: 288/383
[A[ATraining Step: 106  | total loss: [1m[32m0.03109[0m[0m | time: 77.154s
[2K
| Adam | epoch: 009 | loss: 0.03109 - acc: 0.9938 -- iter: 320/383
[A[ATraining Step: 107  | total loss: [1m[32m0.02903[0m[0m | time: 84.888s
[2K
| Adam | epoch: 009 | loss: 0.02903 - acc: 0.9945 -- iter: 352/383
[A[ATraining Step: 108  | total loss: [1m[32m0.02695[0m[0m | time: 97.868s
[2K
| Adam | epoch: 009 | loss: 0.02695 - acc: 0.9950 | val_loss: 1.64907 - val_acc: 0.5750 -- iter: 383/383
--
Training Step: 109  | total loss: [1m[32m0.02494[0m[0m | time: 7.709s
[2K
| Adam | epoch: 010 | loss: 0.02494 - acc: 0.9955 -- iter: 032/383
[A[ATraining Step: 110  | total loss: [1m[32m0.02607[0m[0m | time: 15.573s
[2K
| Adam | epoch: 010 | loss: 0.02607 - acc: 0.9960 -- iter: 064/383
[A[ATraining Step: 111  | total loss: [1m[32m0.06385[0m[0m | time: 23.302s
[2K
| Adam | epoch: 010 | loss: 0.06385 - acc: 0.9932 -- iter: 096/383
[A[ATraining Step: 112  | total loss: [1m[32m0.05772[0m[0m | time: 31.163s
[2K
| Adam | epoch: 010 | loss: 0.05772 - acc: 0.9939 -- iter: 128/383
[A[ATraining Step: 113  | total loss: [1m[32m0.05227[0m[0m | time: 38.980s
[2K
| Adam | epoch: 010 | loss: 0.05227 - acc: 0.9945 -- iter: 160/383
[A[ATraining Step: 114  | total loss: [1m[32m0.04751[0m[0m | time: 46.688s
[2K
| Adam | epoch: 010 | loss: 0.04751 - acc: 0.9951 -- iter: 192/383
[A[ATraining Step: 115  | total loss: [1m[32m0.04302[0m[0m | time: 54.463s
[2K
| Adam | epoch: 010 | loss: 0.04302 - acc: 0.9956 -- iter: 224/383
[A[ATraining Step: 116  | total loss: [1m[32m0.03936[0m[0m | time: 61.995s
[2K
| Adam | epoch: 010 | loss: 0.03936 - acc: 0.9960 -- iter: 256/383
[A[ATraining Step: 117  | total loss: [1m[32m0.03565[0m[0m | time: 69.587s
[2K
| Adam | epoch: 010 | loss: 0.03565 - acc: 0.9964 -- iter: 288/383
[A[ATraining Step: 118  | total loss: [1m[32m0.03235[0m[0m | time: 77.349s
[2K
| Adam | epoch: 010 | loss: 0.03235 - acc: 0.9968 -- iter: 320/383
[A[ATraining Step: 119  | total loss: [1m[32m0.03007[0m[0m | time: 85.089s
[2K
| Adam | epoch: 010 | loss: 0.03007 - acc: 0.9971 -- iter: 352/383
[A[ATraining Step: 120  | total loss: [1m[32m0.02783[0m[0m | time: 98.070s
[2K
| Adam | epoch: 010 | loss: 0.02783 - acc: 0.9974 | val_loss: 1.98901 - val_acc: 0.5167 -- iter: 383/383
--
Training Step: 121  | total loss: [1m[32m0.02546[0m[0m | time: 7.609s
[2K
| Adam | epoch: 011 | loss: 0.02546 - acc: 0.9976 -- iter: 032/383
[A[ATraining Step: 122  | total loss: [1m[32m0.04472[0m[0m | time: 15.437s
[2K
| Adam | epoch: 011 | loss: 0.04472 - acc: 0.9948 -- iter: 064/383
[A[ATraining Step: 123  | total loss: [1m[32m0.06804[0m[0m | time: 23.081s
[2K
| Adam | epoch: 011 | loss: 0.06804 - acc: 0.9890 -- iter: 096/383
[A[ATraining Step: 124  | total loss: [1m[32m0.08036[0m[0m | time: 30.869s
[2K
| Adam | epoch: 011 | loss: 0.08036 - acc: 0.9870 -- iter: 128/383
[A[ATraining Step: 125  | total loss: [1m[32m0.07281[0m[0m | time: 38.552s
[2K
| Adam | epoch: 011 | loss: 0.07281 - acc: 0.9883 -- iter: 160/383
[A[ATraining Step: 126  | total loss: [1m[32m0.06693[0m[0m | time: 46.350s
[2K
| Adam | epoch: 011 | loss: 0.06693 - acc: 0.9895 -- iter: 192/383
[A[ATraining Step: 127  | total loss: [1m[32m0.06082[0m[0m | time: 54.131s
[2K
| Adam | epoch: 011 | loss: 0.06082 - acc: 0.9905 -- iter: 224/383
[A[ATraining Step: 128  | total loss: [1m[32m0.05550[0m[0m | time: 61.942s
[2K
| Adam | epoch: 011 | loss: 0.05550 - acc: 0.9915 -- iter: 256/383
[A[ATraining Step: 129  | total loss: [1m[32m0.09005[0m[0m | time: 69.499s
[2K
| Adam | epoch: 011 | loss: 0.09005 - acc: 0.9892 -- iter: 288/383
[A[ATraining Step: 130  | total loss: [1m[32m0.08171[0m[0m | time: 77.085s
[2K
| Adam | epoch: 011 | loss: 0.08171 - acc: 0.9903 -- iter: 320/383
[A[ATraining Step: 131  | total loss: [1m[32m0.07404[0m[0m | time: 84.937s
[2K
| Adam | epoch: 011 | loss: 0.07404 - acc: 0.9913 -- iter: 352/383
[A[ATraining Step: 132  | total loss: [1m[32m0.06710[0m[0m | time: 99.884s
[2K
| Adam | epoch: 011 | loss: 0.06710 - acc: 0.9921 | val_loss: 0.97757 - val_acc: 0.7167 -- iter: 383/383
--
Training Step: 133  | total loss: [1m[32m0.06098[0m[0m | time: 12.791s
[2K
| Adam | epoch: 012 | loss: 0.06098 - acc: 0.9929 -- iter: 032/383
[A[ATraining Step: 134  | total loss: [1m[32m0.05605[0m[0m | time: 22.140s
[2K
| Adam | epoch: 012 | loss: 0.05605 - acc: 0.9936 -- iter: 064/383
[A[ATraining Step: 135  | total loss: [1m[32m0.05093[0m[0m | time: 30.429s
[2K
| Adam | epoch: 012 | loss: 0.05093 - acc: 0.9943 -- iter: 096/383
[A[ATraining Step: 136  | total loss: [1m[32m0.05441[0m[0m | time: 39.617s
[2K
| Adam | epoch: 012 | loss: 0.05441 - acc: 0.9917 -- iter: 128/383
[A[ATraining Step: 137  | total loss: [1m[32m0.05153[0m[0m | time: 47.416s
[2K
| Adam | epoch: 012 | loss: 0.05153 - acc: 0.9925 -- iter: 160/383
[A[ATraining Step: 138  | total loss: [1m[32m0.04838[0m[0m | time: 55.338s
[2K
| Adam | epoch: 012 | loss: 0.04838 - acc: 0.9933 -- iter: 192/383
[A[ATraining Step: 139  | total loss: [1m[32m0.04423[0m[0m | time: 62.987s
[2K
| Adam | epoch: 012 | loss: 0.04423 - acc: 0.9940 -- iter: 224/383
[A[ATraining Step: 140  | total loss: [1m[32m0.04024[0m[0m | time: 71.037s
[2K
| Adam | epoch: 012 | loss: 0.04024 - acc: 0.9946 -- iter: 256/383
[A[ATraining Step: 141  | total loss: [1m[32m0.03680[0m[0m | time: 83.058s
[2K
| Adam | epoch: 012 | loss: 0.03680 - acc: 0.9951 -- iter: 288/383
[A[ATraining Step: 142  | total loss: [1m[32m0.03352[0m[0m | time: 95.369s
[2K
| Adam | epoch: 012 | loss: 0.03352 - acc: 0.9956 -- iter: 320/383
[A[ATraining Step: 143  | total loss: [1m[32m0.03058[0m[0m | time: 107.479s
[2K
| Adam | epoch: 012 | loss: 0.03058 - acc: 0.9960 -- iter: 352/383
[A[ATraining Step: 144  | total loss: [1m[32m0.02789[0m[0m | time: 129.557s
[2K
| Adam | epoch: 012 | loss: 0.02789 - acc: 0.9964 | val_loss: 1.83035 - val_acc: 0.4917 -- iter: 383/383
--
Training Step: 145  | total loss: [1m[32m0.02659[0m[0m | time: 7.934s
[2K
| Adam | epoch: 013 | loss: 0.02659 - acc: 0.9968 -- iter: 032/383
[A[ATraining Step: 146  | total loss: [1m[32m0.02454[0m[0m | time: 15.605s
[2K
| Adam | epoch: 013 | loss: 0.02454 - acc: 0.9971 -- iter: 064/383
[A[ATraining Step: 147  | total loss: [1m[32m0.02236[0m[0m | time: 24.262s
[2K
| Adam | epoch: 013 | loss: 0.02236 - acc: 0.9974 -- iter: 096/383
[A[ATraining Step: 148  | total loss: [1m[32m0.02161[0m[0m | time: 35.778s
[2K
| Adam | epoch: 013 | loss: 0.02161 - acc: 0.9977 -- iter: 128/383
[A[ATraining Step: 149  | total loss: [1m[32m0.02064[0m[0m | time: 48.565s
[2K
| Adam | epoch: 013 | loss: 0.02064 - acc: 0.9979 -- iter: 160/383
[A[ATraining Step: 150  | total loss: [1m[32m0.05932[0m[0m | time: 61.210s
[2K
| Adam | epoch: 013 | loss: 0.05932 - acc: 0.9919 -- iter: 192/383
[A[ATraining Step: 151  | total loss: [1m[32m0.05358[0m[0m | time: 73.779s
[2K
| Adam | epoch: 013 | loss: 0.05358 - acc: 0.9927 -- iter: 224/383
[A[ATraining Step: 152  | total loss: [1m[32m0.04853[0m[0m | time: 87.021s
[2K
| Adam | epoch: 013 | loss: 0.04853 - acc: 0.9934 -- iter: 256/383
[A[ATraining Step: 153  | total loss: [1m[32m0.04426[0m[0m | time: 99.723s
[2K
| Adam | epoch: 013 | loss: 0.04426 - acc: 0.9941 -- iter: 288/383
[A[ATraining Step: 154  | total loss: [1m[32m0.04004[0m[0m | time: 107.688s
[2K
| Adam | epoch: 013 | loss: 0.04004 - acc: 0.9947 -- iter: 320/383
[A[ATraining Step: 155  | total loss: [1m[32m0.03623[0m[0m | time: 115.303s
[2K
| Adam | epoch: 013 | loss: 0.03623 - acc: 0.9952 -- iter: 352/383
[A[ATraining Step: 156  | total loss: [1m[32m0.05155[0m[0m | time: 130.223s
[2K
| Adam | epoch: 013 | loss: 0.05155 - acc: 0.9924 | val_loss: 3.89177 - val_acc: 0.5833 -- iter: 383/383
--
Training Step: 157  | total loss: [1m[32m0.05522[0m[0m | time: 12.335s
[2K
| Adam | epoch: 014 | loss: 0.05522 - acc: 0.9900 -- iter: 032/383
[A[ATraining Step: 158  | total loss: [1m[32m0.05006[0m[0m | time: 24.573s
[2K
| Adam | epoch: 014 | loss: 0.05006 - acc: 0.9910 -- iter: 064/383
[A[ATraining Step: 159  | total loss: [1m[32m0.04535[0m[0m | time: 35.954s
[2K
| Adam | epoch: 014 | loss: 0.04535 - acc: 0.9919 -- iter: 096/383
[A[ATraining Step: 160  | total loss: [1m[32m0.04119[0m[0m | time: 43.589s
[2K
| Adam | epoch: 014 | loss: 0.04119 - acc: 0.9927 -- iter: 128/383
[A[ATraining Step: 161  | total loss: [1m[32m0.03862[0m[0m | time: 51.319s
[2K
| Adam | epoch: 014 | loss: 0.03862 - acc: 0.9934 -- iter: 160/383
[A[ATraining Step: 162  | total loss: [1m[32m0.03564[0m[0m | time: 59.111s
[2K
| Adam | epoch: 014 | loss: 0.03564 - acc: 0.9941 -- iter: 192/383
[A[ATraining Step: 163  | total loss: [1m[32m0.03675[0m[0m | time: 70.857s
[2K
| Adam | epoch: 014 | loss: 0.03675 - acc: 0.9947 -- iter: 224/383
[A[ATraining Step: 164  | total loss: [1m[32m0.03607[0m[0m | time: 83.281s
[2K
| Adam | epoch: 014 | loss: 0.03607 - acc: 0.9952 -- iter: 256/383
[A[ATraining Step: 165  | total loss: [1m[32m0.03398[0m[0m | time: 94.069s
[2K
| Adam | epoch: 014 | loss: 0.03398 - acc: 0.9957 -- iter: 288/383
[A[ATraining Step: 166  | total loss: [1m[32m0.03135[0m[0m | time: 106.035s
[2K
| Adam | epoch: 014 | loss: 0.03135 - acc: 0.9961 -- iter: 320/383
[A[ATraining Step: 167  | total loss: [1m[32m0.02893[0m[0m | time: 118.509s
[2K
| Adam | epoch: 014 | loss: 0.02893 - acc: 0.9965 -- iter: 352/383
[A[ATraining Step: 168  | total loss: [1m[32m0.02904[0m[0m | time: 139.917s
[2K
| Adam | epoch: 014 | loss: 0.02904 - acc: 0.9969 | val_loss: 5.45044 - val_acc: 0.4333 -- iter: 383/383
--
Training Step: 169  | total loss: [1m[32m0.02866[0m[0m | time: 7.603s
[2K
| Adam | epoch: 015 | loss: 0.02866 - acc: 0.9972 -- iter: 032/383
[A[ATraining Step: 170  | total loss: [1m[32m0.02701[0m[0m | time: 29.637s
[2K
| Adam | epoch: 015 | loss: 0.02701 - acc: 0.9975 -- iter: 064/383
[A[ATraining Step: 171  | total loss: [1m[32m0.02493[0m[0m | time: 47.476s
[2K
| Adam | epoch: 015 | loss: 0.02493 - acc: 0.9977 -- iter: 096/383
[A[ATraining Step: 172  | total loss: [1m[32m0.02340[0m[0m | time: 59.801s
[2K
| Adam | epoch: 015 | loss: 0.02340 - acc: 0.9979 -- iter: 128/383
[A[ATraining Step: 173  | total loss: [1m[32m0.02131[0m[0m | time: 70.452s
[2K
| Adam | epoch: 015 | loss: 0.02131 - acc: 0.9981 -- iter: 160/383
[A[ATraining Step: 174  | total loss: [1m[32m0.02107[0m[0m | time: 83.596s
[2K
| Adam | epoch: 015 | loss: 0.02107 - acc: 0.9983 -- iter: 192/383
[A[ATraining Step: 175  | total loss: [1m[32m0.01997[0m[0m | time: 96.883s
[2K
| Adam | epoch: 015 | loss: 0.01997 - acc: 0.9985 -- iter: 224/383
[A[ATraining Step: 176  | total loss: [1m[32m0.04413[0m[0m | time: 107.297s
[2K
| Adam | epoch: 015 | loss: 0.04413 - acc: 0.9955 -- iter: 256/383
[A[ATraining Step: 177  | total loss: [1m[32m0.04006[0m[0m | time: 114.962s
[2K
| Adam | epoch: 015 | loss: 0.04006 - acc: 0.9960 -- iter: 288/383
[A[ATraining Step: 178  | total loss: [1m[32m0.03639[0m[0m | time: 122.707s
[2K
| Adam | epoch: 015 | loss: 0.03639 - acc: 0.9964 -- iter: 320/383
[A[ATraining Step: 179  | total loss: [1m[32m0.03313[0m[0m | time: 132.972s
[2K
| Adam | epoch: 015 | loss: 0.03313 - acc: 0.9967 -- iter: 352/383
[A[ATraining Step: 180  | total loss: [1m[32m0.04741[0m[0m | time: 154.414s
[2K
| Adam | epoch: 015 | loss: 0.04741 - acc: 0.9939 | val_loss: 1.82856 - val_acc: 0.6417 -- iter: 383/383
--
Validation AUC:0.8718891402714932
Validation AUPRC:0.8582615629207543
Test AUC:0.9226918798665183
Test AUPRC:0.9060683590215663
BestTestF1Score	0.83	0.7	0.84	0.92	0.76	47	4	54	15	0.01
BestTestMCCScore	0.75	0.61	0.78	0.95	0.61	38	2	56	24	0.07
BestTestAccuracyScore	0.83	0.7	0.84	0.92	0.76	47	4	54	15	0.01
BestValidationF1Score	0.78	0.57	0.78	0.87	0.71	48	7	45	20	0.01
BestValidationMCC	0.75	0.59	0.77	0.93	0.63	43	3	49	25	0.07
BestValidationAccuracy	0.78	0.57	0.78	0.87	0.71	48	7	45	20	0.01
TestPredictions (Threshold:0.07)
CHEMBL450463,TN,INACT,0.0	CHEMBL303204,TN,INACT,0.0	CHEMBL78853,TN,INACT,0.0	CHEMBL330674,TN,INACT,0.0	CHEMBL2042401,TN,INACT,0.009999999776482582	CHEMBL149763,TN,INACT,0.0	CHEMBL1550957,FN,ACT,0.0	CHEMBL594376,TN,INACT,0.0	CHEMBL296245,TN,INACT,0.0	CHEMBL42360,TN,INACT,0.0	CHEMBL80532,TN,INACT,0.0	CHEMBL174448,TN,INACT,0.0	CHEMBL109926,TN,INACT,0.0	CHEMBL177546,TN,INACT,0.0	CHEMBL1416204,TP,ACT,0.10000000149011612	CHEMBL9841,TP,ACT,1.0	CHEMBL1255834,TP,ACT,0.07000000029802322	CHEMBL297335,TN,INACT,0.0	CHEMBL114478,FP,INACT,0.9800000190734863	CHEMBL64878,TP,ACT,0.9399999976158142	CHEMBL10211,TN,INACT,0.0	CHEMBL137478,TN,INACT,0.0	CHEMBL65710,TN,INACT,0.0	CHEMBL137486,TN,INACT,0.0	CHEMBL11760,TP,ACT,0.07999999821186066	CHEMBL2112592,TN,INACT,0.0	CHEMBL43788,TN,INACT,0.0	CHEMBL268800,FN,ACT,0.019999999552965164	CHEMBL445,TP,ACT,0.8700000047683716	CHEMBL2376484,FN,ACT,0.0	CHEMBL274922,FN,ACT,0.019999999552965164	CHEMBL136470,TP,ACT,0.9300000071525574	CHEMBL357077,TN,INACT,0.0	CHEMBL15837,FN,ACT,0.05000000074505806	CHEMBL60447,FN,ACT,0.05000000074505806	CHEMBL50456,TN,INACT,0.0	CHEMBL1626,FN,ACT,0.0	CHEMBL275943,TP,ACT,0.9900000095367432	CHEMBL59347,TN,INACT,0.0	CHEMBL3645476,FN,ACT,0.009999999776482582	CHEMBL50740,TN,INACT,0.0	CHEMBL15933,FN,ACT,0.0	CHEMBL76576,TN,INACT,0.0	CHEMBL352107,FN,ACT,0.009999999776482582	CHEMBL267153,TP,ACT,0.4399999976158142	CHEMBL153451,TP,ACT,0.8799999952316284	CHEMBL59300,TP,ACT,0.3499999940395355	CHEMBL1788282,TP,ACT,0.9200000166893005	CHEMBL2376491,FN,ACT,0.0	CHEMBL8600,FN,ACT,0.019999999552965164	CHEMBL2079598,TP,ACT,0.36000001430511475	CHEMBL112877,TN,INACT,0.0	CHEMBL304210,TP,ACT,0.8600000143051147	CHEMBL7257,FN,ACT,0.019999999552965164	CHEMBL44615,TN,INACT,0.0	CHEMBL18785,FN,ACT,0.05999999865889549	CHEMBL100624,TN,INACT,0.0	CHEMBL27,TP,ACT,0.9200000166893005	CHEMBL633,TN,INACT,0.0	CHEMBL602474,TN,INACT,0.0	CHEMBL59,FP,INACT,0.4300000071525574	CHEMBL43661,TN,INACT,0.0	CHEMBL331304,TP,ACT,0.9700000286102295	CHEMBL131200,FN,ACT,0.0	CHEMBL322537,TN,INACT,0.0	CHEMBL64948,TP,ACT,0.8299999833106995	CHEMBL1201939,FN,ACT,0.019999999552965164	CHEMBL89203,TN,INACT,0.0	CHEMBL18855,TP,ACT,0.7900000214576721	CHEMBL9746,TP,ACT,1.0	CHEMBL15855,TP,ACT,0.8500000238418579	CHEMBL369359,TN,INACT,0.0	CHEMBL1259241,TN,INACT,0.0	CHEMBL2093088,TP,ACT,0.9599999785423279	CHEMBL76779,TN,INACT,0.0	CHEMBL515170,TN,INACT,0.0	CHEMBL3633663,TN,INACT,0.0	CHEMBL6437,FN,ACT,0.009999999776482582	CHEMBL169956,TP,ACT,0.20999999344348907	CHEMBL294368,FN,ACT,0.0	CHEMBL130276,TP,ACT,0.9700000286102295	CHEMBL54720,FN,ACT,0.0	CHEMBL12129,TP,ACT,0.9399999976158142	CHEMBL421523,TN,INACT,0.0	CHEMBL513277,TN,INACT,0.0	CHEMBL287987,TP,ACT,0.1599999964237213	CHEMBL306384,FN,ACT,0.029999999329447746	CHEMBL148967,TN,INACT,0.0	CHEMBL89688,TN,INACT,0.0	CHEMBL131198,TP,ACT,0.1599999964237213	CHEMBL3633665,TN,INACT,0.0	CHEMBL175698,TN,INACT,0.0	CHEMBL6568,TN,INACT,0.05000000074505806	CHEMBL293879,FN,ACT,0.0	CHEMBL12152,TP,ACT,0.8999999761581421	CHEMBL321644,TN,INACT,0.0	CHEMBL129947,TP,ACT,0.5199999809265137	CHEMBL13904,TP,ACT,0.4000000059604645	CHEMBL9452,TP,ACT,0.6800000071525574	CHEMBL151420,TP,ACT,0.1599999964237213	CHEMBL2079596,TP,ACT,0.12999999523162842	CHEMBL430683,TN,INACT,0.0	CHEMBL300735,FN,ACT,0.0	CHEMBL110695,TN,INACT,0.0	CHEMBL59637,TP,ACT,0.3199999928474426	CHEMBL2079597,TN,INACT,0.05000000074505806	CHEMBL63290,TN,INACT,0.0	CHEMBL109206,TN,INACT,0.0	CHEMBL1744074,TP,ACT,0.09000000357627869	CHEMBL337279,FN,ACT,0.0	CHEMBL417358,TN,INACT,0.0	CHEMBL81,FN,ACT,0.009999999776482582	CHEMBL52867,TN,INACT,0.0	CHEMBL334465,TP,ACT,0.38999998569488525	CHEMBL337036,TP,ACT,0.9700000286102295	CHEMBL21508,TN,INACT,0.0	CHEMBL341391,TP,ACT,0.9300000071525574	CHEMBL1258999,TN,INACT,0.0	CHEMBL56,TP,ACT,0.6499999761581421	CHEMBL351183,TN,INACT,0.0	

