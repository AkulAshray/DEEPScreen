ImageNetInceptionV2 CHEMBL1870 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	106
Number of inactive compounds :	106
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1870_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1870_adam_0.0005_30_0.6/
---------------------------------
Training samples: 135
Validation samples: 43
--
Training Step: 1  | time: 59.489s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/135
[A[ATraining Step: 2  | total loss: [1m[32m0.59453[0m[0m | time: 71.428s
[2K
| Adam | epoch: 001 | loss: 0.59453 - acc: 0.6187 -- iter: 064/135
[A[ATraining Step: 3  | total loss: [1m[32m0.68040[0m[0m | time: 83.581s
[2K
| Adam | epoch: 001 | loss: 0.68040 - acc: 0.7261 -- iter: 096/135
[A[ATraining Step: 4  | total loss: [1m[32m1.03849[0m[0m | time: 95.511s
[2K
| Adam | epoch: 001 | loss: 1.03849 - acc: 0.6268 -- iter: 128/135
[A[ATraining Step: 5  | total loss: [1m[32m0.58768[0m[0m | time: 112.842s
[2K
| Adam | epoch: 001 | loss: 0.58768 - acc: 0.7770 | val_loss: 1.68679 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 6  | total loss: [1m[32m0.40387[0m[0m | time: 3.821s
[2K
| Adam | epoch: 002 | loss: 0.40387 - acc: 0.8285 -- iter: 032/135
[A[ATraining Step: 7  | total loss: [1m[32m0.23427[0m[0m | time: 15.563s
[2K
| Adam | epoch: 002 | loss: 0.23427 - acc: 0.9314 -- iter: 064/135
[A[ATraining Step: 8  | total loss: [1m[32m0.23954[0m[0m | time: 27.490s
[2K
| Adam | epoch: 002 | loss: 0.23954 - acc: 0.9348 -- iter: 096/135
[A[ATraining Step: 9  | total loss: [1m[32m0.32600[0m[0m | time: 39.810s
[2K
| Adam | epoch: 002 | loss: 0.32600 - acc: 0.8701 -- iter: 128/135
[A[ATraining Step: 10  | total loss: [1m[32m0.41822[0m[0m | time: 54.603s
[2K
| Adam | epoch: 002 | loss: 0.41822 - acc: 0.8413 | val_loss: 2.95143 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 11  | total loss: [1m[32m0.34439[0m[0m | time: 3.773s
[2K
| Adam | epoch: 003 | loss: 0.34439 - acc: 0.8573 -- iter: 032/135
[A[ATraining Step: 12  | total loss: [1m[32m0.22027[0m[0m | time: 7.773s
[2K
| Adam | epoch: 003 | loss: 0.22027 - acc: 0.9215 -- iter: 064/135
[A[ATraining Step: 13  | total loss: [1m[32m0.14556[0m[0m | time: 19.850s
[2K
| Adam | epoch: 003 | loss: 0.14556 - acc: 0.9551 -- iter: 096/135
[A[ATraining Step: 14  | total loss: [1m[32m0.16246[0m[0m | time: 31.511s
[2K
| Adam | epoch: 003 | loss: 0.16246 - acc: 0.9607 -- iter: 128/135
[A[ATraining Step: 15  | total loss: [1m[32m0.20992[0m[0m | time: 46.458s
[2K
| Adam | epoch: 003 | loss: 0.20992 - acc: 0.9394 | val_loss: 3.14051 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 16  | total loss: [1m[32m0.21249[0m[0m | time: 12.282s
[2K
| Adam | epoch: 004 | loss: 0.21249 - acc: 0.9152 -- iter: 032/135
[A[ATraining Step: 17  | total loss: [1m[32m0.15413[0m[0m | time: 16.015s
[2K
| Adam | epoch: 004 | loss: 0.15413 - acc: 0.9458 -- iter: 064/135
[A[ATraining Step: 18  | total loss: [1m[32m0.11598[0m[0m | time: 20.111s
[2K
| Adam | epoch: 004 | loss: 0.11598 - acc: 0.9645 -- iter: 096/135
[A[ATraining Step: 19  | total loss: [1m[32m0.08390[0m[0m | time: 36.504s
[2K
| Adam | epoch: 004 | loss: 0.08390 - acc: 0.9764 -- iter: 128/135
[A[ATraining Step: 20  | total loss: [1m[32m0.06659[0m[0m | time: 72.769s
[2K
| Adam | epoch: 004 | loss: 0.06659 - acc: 0.9840 | val_loss: 2.78790 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 21  | total loss: [1m[32m0.09232[0m[0m | time: 11.560s
[2K
| Adam | epoch: 005 | loss: 0.09232 - acc: 0.9695 -- iter: 032/135
[A[ATraining Step: 22  | total loss: [1m[32m0.38862[0m[0m | time: 23.022s
[2K
| Adam | epoch: 005 | loss: 0.38862 - acc: 0.9131 -- iter: 064/135
[A[ATraining Step: 23  | total loss: [1m[32m0.29777[0m[0m | time: 27.252s
[2K
| Adam | epoch: 005 | loss: 0.29777 - acc: 0.9292 -- iter: 096/135
[A[ATraining Step: 24  | total loss: [1m[32m0.24551[0m[0m | time: 31.176s
[2K
| Adam | epoch: 005 | loss: 0.24551 - acc: 0.9491 -- iter: 128/135
[A[ATraining Step: 25  | total loss: [1m[32m0.19768[0m[0m | time: 45.951s
[2K
| Adam | epoch: 005 | loss: 0.19768 - acc: 0.9630 | val_loss: 3.17926 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 26  | total loss: [1m[32m0.17179[0m[0m | time: 30.757s
[2K
| Adam | epoch: 006 | loss: 0.17179 - acc: 0.9563 -- iter: 032/135
[A[ATraining Step: 27  | total loss: [1m[32m0.14773[0m[0m | time: 49.038s
[2K
| Adam | epoch: 006 | loss: 0.14773 - acc: 0.9595 -- iter: 064/135
[A[ATraining Step: 28  | total loss: [1m[32m0.18950[0m[0m | time: 60.427s
[2K
| Adam | epoch: 006 | loss: 0.18950 - acc: 0.9462 -- iter: 096/135
[A[ATraining Step: 29  | total loss: [1m[32m0.15053[0m[0m | time: 64.398s
[2K
| Adam | epoch: 006 | loss: 0.15053 - acc: 0.9593 -- iter: 128/135
[A[ATraining Step: 30  | total loss: [1m[32m0.30856[0m[0m | time: 71.388s
[2K
| Adam | epoch: 006 | loss: 0.30856 - acc: 0.9012 | val_loss: 3.79882 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 31  | total loss: [1m[32m0.37682[0m[0m | time: 11.746s
[2K
| Adam | epoch: 007 | loss: 0.37682 - acc: 0.8911 -- iter: 032/135
[A[ATraining Step: 32  | total loss: [1m[32m0.31748[0m[0m | time: 23.567s
[2K
| Adam | epoch: 007 | loss: 0.31748 - acc: 0.9015 -- iter: 064/135
[A[ATraining Step: 33  | total loss: [1m[32m0.25617[0m[0m | time: 35.036s
[2K
| Adam | epoch: 007 | loss: 0.25617 - acc: 0.9231 -- iter: 096/135
[A[ATraining Step: 34  | total loss: [1m[32m0.22236[0m[0m | time: 46.556s
[2K
| Adam | epoch: 007 | loss: 0.22236 - acc: 0.9262 -- iter: 128/135
[A[ATraining Step: 35  | total loss: [1m[32m0.22315[0m[0m | time: 53.524s
[2K
| Adam | epoch: 007 | loss: 0.22315 - acc: 0.9351 | val_loss: 3.97533 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 36  | total loss: [1m[32m0.19294[0m[0m | time: 3.868s
[2K
| Adam | epoch: 008 | loss: 0.19294 - acc: 0.9484 -- iter: 032/135
[A[ATraining Step: 37  | total loss: [1m[32m0.16429[0m[0m | time: 15.720s
[2K
| Adam | epoch: 008 | loss: 0.16429 - acc: 0.9587 -- iter: 064/135
[A[ATraining Step: 38  | total loss: [1m[32m0.14744[0m[0m | time: 27.171s
[2K
| Adam | epoch: 008 | loss: 0.14744 - acc: 0.9668 -- iter: 096/135
[A[ATraining Step: 39  | total loss: [1m[32m0.13195[0m[0m | time: 38.663s
[2K
| Adam | epoch: 008 | loss: 0.13195 - acc: 0.9672 -- iter: 128/135
[A[ATraining Step: 40  | total loss: [1m[32m0.17427[0m[0m | time: 53.405s
[2K
| Adam | epoch: 008 | loss: 0.17427 - acc: 0.9616 | val_loss: 3.46277 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 41  | total loss: [1m[32m0.14895[0m[0m | time: 4.116s
[2K
| Adam | epoch: 009 | loss: 0.14895 - acc: 0.9687 -- iter: 032/135
[A[ATraining Step: 42  | total loss: [1m[32m0.12995[0m[0m | time: 7.719s
[2K
| Adam | epoch: 009 | loss: 0.12995 - acc: 0.9743 -- iter: 064/135
[A[ATraining Step: 43  | total loss: [1m[32m0.11435[0m[0m | time: 19.246s
[2K
| Adam | epoch: 009 | loss: 0.11435 - acc: 0.9788 -- iter: 096/135
[A[ATraining Step: 44  | total loss: [1m[32m0.10159[0m[0m | time: 30.978s
[2K
| Adam | epoch: 009 | loss: 0.10159 - acc: 0.9825 -- iter: 128/135
[A[ATraining Step: 45  | total loss: [1m[32m0.10889[0m[0m | time: 45.406s
[2K
| Adam | epoch: 009 | loss: 0.10889 - acc: 0.9749 | val_loss: 2.83700 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 46  | total loss: [1m[32m0.15692[0m[0m | time: 11.694s
[2K
| Adam | epoch: 010 | loss: 0.15692 - acc: 0.9686 -- iter: 032/135
[A[ATraining Step: 47  | total loss: [1m[32m0.15365[0m[0m | time: 15.543s
[2K
| Adam | epoch: 010 | loss: 0.15365 - acc: 0.9686 -- iter: 064/135
[A[ATraining Step: 48  | total loss: [1m[32m0.19522[0m[0m | time: 19.558s
[2K
| Adam | epoch: 010 | loss: 0.19522 - acc: 0.9507 -- iter: 096/135
[A[ATraining Step: 49  | total loss: [1m[32m0.18159[0m[0m | time: 31.302s
[2K
| Adam | epoch: 010 | loss: 0.18159 - acc: 0.9585 -- iter: 128/135
[A[ATraining Step: 50  | total loss: [1m[32m0.15909[0m[0m | time: 46.407s
[2K
| Adam | epoch: 010 | loss: 0.15909 - acc: 0.9649 | val_loss: 1.95762 - val_acc: 0.5349 -- iter: 135/135
--
Training Step: 51  | total loss: [1m[32m0.15019[0m[0m | time: 11.520s
[2K
| Adam | epoch: 011 | loss: 0.15019 - acc: 0.9703 -- iter: 032/135
[A[ATraining Step: 52  | total loss: [1m[32m0.15498[0m[0m | time: 23.363s
[2K
| Adam | epoch: 011 | loss: 0.15498 - acc: 0.9701 -- iter: 064/135
[A[ATraining Step: 53  | total loss: [1m[32m0.13928[0m[0m | time: 27.232s
[2K
| Adam | epoch: 011 | loss: 0.13928 - acc: 0.9699 -- iter: 096/135
[A[ATraining Step: 54  | total loss: [1m[32m0.18239[0m[0m | time: 31.127s
[2K
| Adam | epoch: 011 | loss: 0.18239 - acc: 0.9535 -- iter: 128/135
[A[ATraining Step: 55  | total loss: [1m[32m0.16841[0m[0m | time: 46.122s
[2K
| Adam | epoch: 011 | loss: 0.16841 - acc: 0.9601 | val_loss: 1.54582 - val_acc: 0.5581 -- iter: 135/135
--
Training Step: 56  | total loss: [1m[32m0.15445[0m[0m | time: 12.839s
[2K
| Adam | epoch: 012 | loss: 0.15445 - acc: 0.9614 -- iter: 032/135
[A[ATraining Step: 57  | total loss: [1m[32m0.13595[0m[0m | time: 25.268s
[2K
| Adam | epoch: 012 | loss: 0.13595 - acc: 0.9667 -- iter: 064/135
[A[ATraining Step: 58  | total loss: [1m[32m0.15279[0m[0m | time: 38.225s
[2K
| Adam | epoch: 012 | loss: 0.15279 - acc: 0.9670 -- iter: 096/135
[A[ATraining Step: 59  | total loss: [1m[32m0.13648[0m[0m | time: 42.524s
[2K
| Adam | epoch: 012 | loss: 0.13648 - acc: 0.9714 -- iter: 128/135
[A[ATraining Step: 60  | total loss: [1m[32m0.14457[0m[0m | time: 50.128s
[2K
| Adam | epoch: 012 | loss: 0.14457 - acc: 0.9563 | val_loss: 1.13559 - val_acc: 0.6512 -- iter: 135/135
--
Training Step: 61  | total loss: [1m[32m0.13006[0m[0m | time: 11.736s
[2K
| Adam | epoch: 013 | loss: 0.13006 - acc: 0.9620 -- iter: 032/135
[A[ATraining Step: 62  | total loss: [1m[32m0.14114[0m[0m | time: 23.375s
[2K
| Adam | epoch: 013 | loss: 0.14114 - acc: 0.9508 -- iter: 064/135
[A[ATraining Step: 63  | total loss: [1m[32m0.13015[0m[0m | time: 34.966s
[2K
| Adam | epoch: 013 | loss: 0.13015 - acc: 0.9570 -- iter: 096/135
[A[ATraining Step: 64  | total loss: [1m[32m0.14167[0m[0m | time: 46.325s
[2K
| Adam | epoch: 013 | loss: 0.14167 - acc: 0.9546 -- iter: 128/135
[A[ATraining Step: 65  | total loss: [1m[32m0.12686[0m[0m | time: 53.404s
[2K
| Adam | epoch: 013 | loss: 0.12686 - acc: 0.9602 | val_loss: 0.28778 - val_acc: 0.8837 -- iter: 135/135
--
Training Step: 66  | total loss: [1m[32m0.11405[0m[0m | time: 4.108s
[2K
| Adam | epoch: 014 | loss: 0.11405 - acc: 0.9650 -- iter: 032/135
[A[ATraining Step: 67  | total loss: [1m[32m0.10398[0m[0m | time: 16.865s
[2K
| Adam | epoch: 014 | loss: 0.10398 - acc: 0.9692 -- iter: 064/135
[A[ATraining Step: 68  | total loss: [1m[32m0.11184[0m[0m | time: 28.188s
[2K
| Adam | epoch: 014 | loss: 0.11184 - acc: 0.9655 -- iter: 096/135
[A[ATraining Step: 69  | total loss: [1m[32m0.12241[0m[0m | time: 39.820s
[2K
| Adam | epoch: 014 | loss: 0.12241 - acc: 0.9586 -- iter: 128/135
[A[ATraining Step: 70  | total loss: [1m[32m0.11050[0m[0m | time: 54.590s
[2K
| Adam | epoch: 014 | loss: 0.11050 - acc: 0.9633 | val_loss: 2.66612 - val_acc: 0.6279 -- iter: 135/135
--
Training Step: 71  | total loss: [1m[32m0.09902[0m[0m | time: 4.184s
[2K
| Adam | epoch: 015 | loss: 0.09902 - acc: 0.9675 -- iter: 032/135
[A[ATraining Step: 72  | total loss: [1m[32m0.10446[0m[0m | time: 8.043s
[2K
| Adam | epoch: 015 | loss: 0.10446 - acc: 0.9551 -- iter: 064/135
[A[ATraining Step: 73  | total loss: [1m[32m0.09658[0m[0m | time: 19.641s
[2K
| Adam | epoch: 015 | loss: 0.09658 - acc: 0.9601 -- iter: 096/135
[A[ATraining Step: 74  | total loss: [1m[32m0.08782[0m[0m | time: 31.078s
[2K
| Adam | epoch: 015 | loss: 0.08782 - acc: 0.9645 -- iter: 128/135
[A[ATraining Step: 75  | total loss: [1m[32m0.09158[0m[0m | time: 46.049s
[2K
| Adam | epoch: 015 | loss: 0.09158 - acc: 0.9582 | val_loss: 5.36842 - val_acc: 0.4651 -- iter: 135/135
--
Training Step: 76  | total loss: [1m[32m0.19248[0m[0m | time: 11.022s
[2K
| Adam | epoch: 016 | loss: 0.19248 - acc: 0.9526 -- iter: 032/135
[A[ATraining Step: 77  | total loss: [1m[32m0.17887[0m[0m | time: 14.945s
[2K
| Adam | epoch: 016 | loss: 0.17887 - acc: 0.9576 -- iter: 064/135
[A[ATraining Step: 78  | total loss: [1m[32m0.16317[0m[0m | time: 18.612s
[2K
| Adam | epoch: 016 | loss: 0.16317 - acc: 0.9620 -- iter: 096/135
[A[ATraining Step: 79  | total loss: [1m[32m0.14715[0m[0m | time: 30.521s
[2K
| Adam | epoch: 016 | loss: 0.14715 - acc: 0.9660 -- iter: 128/135
[A[ATraining Step: 80  | total loss: [1m[32m0.13335[0m[0m | time: 45.607s
[2K
| Adam | epoch: 016 | loss: 0.13335 - acc: 0.9695 | val_loss: 3.73829 - val_acc: 0.4884 -- iter: 135/135
--
Training Step: 81  | total loss: [1m[32m0.12153[0m[0m | time: 12.440s
[2K
| Adam | epoch: 017 | loss: 0.12153 - acc: 0.9725 -- iter: 032/135
[A[ATraining Step: 82  | total loss: [1m[32m0.13263[0m[0m | time: 24.420s
[2K
| Adam | epoch: 017 | loss: 0.13263 - acc: 0.9722 -- iter: 064/135
[A[ATraining Step: 83  | total loss: [1m[32m0.12820[0m[0m | time: 28.073s
[2K
| Adam | epoch: 017 | loss: 0.12820 - acc: 0.9718 -- iter: 096/135
[A[ATraining Step: 84  | total loss: [1m[32m0.15126[0m[0m | time: 32.192s
[2K
| Adam | epoch: 017 | loss: 0.15126 - acc: 0.9604 -- iter: 128/135
[A[ATraining Step: 85  | total loss: [1m[32m0.15531[0m[0m | time: 49.166s
[2K
| Adam | epoch: 017 | loss: 0.15531 - acc: 0.9500 | val_loss: 0.97380 - val_acc: 0.7674 -- iter: 135/135
--
Training Step: 86  | total loss: [1m[32m0.14228[0m[0m | time: 11.997s
[2K
| Adam | epoch: 018 | loss: 0.14228 - acc: 0.9550 -- iter: 032/135
[A[ATraining Step: 87  | total loss: [1m[32m0.13229[0m[0m | time: 23.768s
[2K
| Adam | epoch: 018 | loss: 0.13229 - acc: 0.9564 -- iter: 064/135
[A[ATraining Step: 88  | total loss: [1m[32m0.12170[0m[0m | time: 35.293s
[2K
| Adam | epoch: 018 | loss: 0.12170 - acc: 0.9608 -- iter: 096/135
[A[ATraining Step: 89  | total loss: [1m[32m0.11227[0m[0m | time: 39.065s
[2K
| Adam | epoch: 018 | loss: 0.11227 - acc: 0.9647 -- iter: 128/135
[A[ATraining Step: 90  | total loss: [1m[32m0.10471[0m[0m | time: 46.433s
[2K
| Adam | epoch: 018 | loss: 0.10471 - acc: 0.9682 | val_loss: 0.47250 - val_acc: 0.8605 -- iter: 135/135
--
Training Step: 91  | total loss: [1m[32m0.09568[0m[0m | time: 13.113s
[2K
| Adam | epoch: 019 | loss: 0.09568 - acc: 0.9714 -- iter: 032/135
[A[ATraining Step: 92  | total loss: [1m[32m0.09397[0m[0m | time: 25.393s
[2K
| Adam | epoch: 019 | loss: 0.09397 - acc: 0.9711 -- iter: 064/135
[A[ATraining Step: 93  | total loss: [1m[32m0.08868[0m[0m | time: 37.295s
[2K
| Adam | epoch: 019 | loss: 0.08868 - acc: 0.9740 -- iter: 096/135
[A[ATraining Step: 94  | total loss: [1m[32m0.08232[0m[0m | time: 49.051s
[2K
| Adam | epoch: 019 | loss: 0.08232 - acc: 0.9766 -- iter: 128/135
[A[ATraining Step: 95  | total loss: [1m[32m0.07722[0m[0m | time: 56.390s
[2K
| Adam | epoch: 019 | loss: 0.07722 - acc: 0.9790 | val_loss: 0.38441 - val_acc: 0.9070 -- iter: 135/135
--
Training Step: 96  | total loss: [1m[32m0.07395[0m[0m | time: 4.170s
[2K
| Adam | epoch: 020 | loss: 0.07395 - acc: 0.9811 -- iter: 032/135
[A[ATraining Step: 97  | total loss: [1m[32m0.06813[0m[0m | time: 16.203s
[2K
| Adam | epoch: 020 | loss: 0.06813 - acc: 0.9830 -- iter: 064/135
[A[ATraining Step: 98  | total loss: [1m[32m0.06173[0m[0m | time: 28.189s
[2K
| Adam | epoch: 020 | loss: 0.06173 - acc: 0.9847 -- iter: 096/135
[A[ATraining Step: 99  | total loss: [1m[32m0.05996[0m[0m | time: 39.971s
[2K
| Adam | epoch: 020 | loss: 0.05996 - acc: 0.9831 -- iter: 128/135
[A[ATraining Step: 100  | total loss: [1m[32m0.07360[0m[0m | time: 55.038s
[2K
| Adam | epoch: 020 | loss: 0.07360 - acc: 0.9816 | val_loss: 0.56754 - val_acc: 0.8605 -- iter: 135/135
--
Training Step: 101  | total loss: [1m[32m0.06657[0m[0m | time: 4.565s
[2K
| Adam | epoch: 021 | loss: 0.06657 - acc: 0.9835 -- iter: 032/135
[A[ATraining Step: 102  | total loss: [1m[32m0.06140[0m[0m | time: 9.007s
[2K
| Adam | epoch: 021 | loss: 0.06140 - acc: 0.9851 -- iter: 064/135
[A[ATraining Step: 103  | total loss: [1m[32m0.05674[0m[0m | time: 22.009s
[2K
| Adam | epoch: 021 | loss: 0.05674 - acc: 0.9866 -- iter: 096/135
[A[ATraining Step: 104  | total loss: [1m[32m0.05194[0m[0m | time: 34.558s
[2K
| Adam | epoch: 021 | loss: 0.05194 - acc: 0.9880 -- iter: 128/135
[A[ATraining Step: 105  | total loss: [1m[32m0.05290[0m[0m | time: 51.000s
[2K
| Adam | epoch: 021 | loss: 0.05290 - acc: 0.9860 | val_loss: 0.44307 - val_acc: 0.8837 -- iter: 135/135
--
Training Step: 106  | total loss: [1m[32m0.06535[0m[0m | time: 11.623s
[2K
| Adam | epoch: 022 | loss: 0.06535 - acc: 0.9843 -- iter: 032/135
[A[ATraining Step: 107  | total loss: [1m[32m0.06400[0m[0m | time: 15.347s
[2K
| Adam | epoch: 022 | loss: 0.06400 - acc: 0.9827 -- iter: 064/135
[A[ATraining Step: 108  | total loss: [1m[32m0.05927[0m[0m | time: 19.629s
[2K
| Adam | epoch: 022 | loss: 0.05927 - acc: 0.9845 -- iter: 096/135
[A[ATraining Step: 109  | total loss: [1m[32m0.05369[0m[0m | time: 31.807s
[2K
| Adam | epoch: 022 | loss: 0.05369 - acc: 0.9860 -- iter: 128/135
[A[ATraining Step: 110  | total loss: [1m[32m0.06709[0m[0m | time: 46.810s
[2K
| Adam | epoch: 022 | loss: 0.06709 - acc: 0.9843 | val_loss: 0.50181 - val_acc: 0.8837 -- iter: 135/135
--
Training Step: 111  | total loss: [1m[32m0.06101[0m[0m | time: 11.864s
[2K
| Adam | epoch: 023 | loss: 0.06101 - acc: 0.9859 -- iter: 032/135
[A[ATraining Step: 112  | total loss: [1m[32m0.10017[0m[0m | time: 23.579s
[2K
| Adam | epoch: 023 | loss: 0.10017 - acc: 0.9810 -- iter: 064/135
[A[ATraining Step: 113  | total loss: [1m[32m0.09170[0m[0m | time: 27.729s
[2K
| Adam | epoch: 023 | loss: 0.09170 - acc: 0.9829 -- iter: 096/135
[A[ATraining Step: 114  | total loss: [1m[32m0.22568[0m[0m | time: 31.680s
[2K
| Adam | epoch: 023 | loss: 0.22568 - acc: 0.9418 -- iter: 128/135
[A[ATraining Step: 115  | total loss: [1m[32m0.28283[0m[0m | time: 46.567s
[2K
| Adam | epoch: 023 | loss: 0.28283 - acc: 0.9190 | val_loss: 2.17769 - val_acc: 0.6744 -- iter: 135/135
--
Training Step: 116  | total loss: [1m[32m0.26050[0m[0m | time: 12.013s
[2K
| Adam | epoch: 024 | loss: 0.26050 - acc: 0.9240 -- iter: 032/135
[A[ATraining Step: 117  | total loss: [1m[32m0.23831[0m[0m | time: 24.028s
[2K
| Adam | epoch: 024 | loss: 0.23831 - acc: 0.9316 -- iter: 064/135
[A[ATraining Step: 118  | total loss: [1m[32m0.23467[0m[0m | time: 35.761s
[2K
| Adam | epoch: 024 | loss: 0.23467 - acc: 0.9353 -- iter: 096/135
[A[ATraining Step: 119  | total loss: [1m[32m0.21433[0m[0m | time: 39.565s
[2K
| Adam | epoch: 024 | loss: 0.21433 - acc: 0.9418 -- iter: 128/135
[A[ATraining Step: 120  | total loss: [1m[32m0.24135[0m[0m | time: 46.896s
[2K
| Adam | epoch: 024 | loss: 0.24135 - acc: 0.9190 | val_loss: 2.05821 - val_acc: 0.7209 -- iter: 135/135
--
Training Step: 121  | total loss: [1m[32m0.23925[0m[0m | time: 12.123s
[2K
| Adam | epoch: 025 | loss: 0.23925 - acc: 0.9271 -- iter: 032/135
[A[ATraining Step: 122  | total loss: [1m[32m0.23730[0m[0m | time: 24.111s
[2K
| Adam | epoch: 025 | loss: 0.23730 - acc: 0.9282 -- iter: 064/135
[A[ATraining Step: 123  | total loss: [1m[32m0.22039[0m[0m | time: 35.608s
[2K
| Adam | epoch: 025 | loss: 0.22039 - acc: 0.9322 -- iter: 096/135
[A[ATraining Step: 124  | total loss: [1m[32m0.20017[0m[0m | time: 47.517s
[2K
| Adam | epoch: 025 | loss: 0.20017 - acc: 0.9390 -- iter: 128/135
[A[ATraining Step: 125  | total loss: [1m[32m0.18537[0m[0m | time: 54.962s
[2K
| Adam | epoch: 025 | loss: 0.18537 - acc: 0.9451 | val_loss: 1.71575 - val_acc: 0.7907 -- iter: 135/135
--
Training Step: 126  | total loss: [1m[32m0.16716[0m[0m | time: 4.077s
[2K
| Adam | epoch: 026 | loss: 0.16716 - acc: 0.9506 -- iter: 032/135
[A[ATraining Step: 127  | total loss: [1m[32m0.15068[0m[0m | time: 16.020s
[2K
| Adam | epoch: 026 | loss: 0.15068 - acc: 0.9555 -- iter: 064/135
[A[ATraining Step: 128  | total loss: [1m[32m0.17527[0m[0m | time: 27.804s
[2K
| Adam | epoch: 026 | loss: 0.17527 - acc: 0.9412 -- iter: 096/135
[A[ATraining Step: 129  | total loss: [1m[32m0.15996[0m[0m | time: 40.450s
[2K
| Adam | epoch: 026 | loss: 0.15996 - acc: 0.9471 -- iter: 128/135
[A[ATraining Step: 130  | total loss: [1m[32m0.22617[0m[0m | time: 56.586s
[2K
| Adam | epoch: 026 | loss: 0.22617 - acc: 0.9368 | val_loss: 1.91946 - val_acc: 0.7674 -- iter: 135/135
--
Training Step: 131  | total loss: [1m[32m0.20467[0m[0m | time: 2.489s
[2K
| Adam | epoch: 027 | loss: 0.20467 - acc: 0.9431 -- iter: 032/135
[A[ATraining Step: 132  | total loss: [1m[32m0.21154[0m[0m | time: 5.025s
[2K
| Adam | epoch: 027 | loss: 0.21154 - acc: 0.9345 -- iter: 064/135
[A[ATraining Step: 133  | total loss: [1m[32m0.20865[0m[0m | time: 12.904s
[2K
| Adam | epoch: 027 | loss: 0.20865 - acc: 0.9268 -- iter: 096/135
[A[ATraining Step: 134  | total loss: [1m[32m0.20058[0m[0m | time: 20.837s
[2K
| Adam | epoch: 027 | loss: 0.20058 - acc: 0.9278 -- iter: 128/135
[A[ATraining Step: 135  | total loss: [1m[32m0.18476[0m[0m | time: 35.002s
[2K
| Adam | epoch: 027 | loss: 0.18476 - acc: 0.9351 | val_loss: 3.43635 - val_acc: 0.6744 -- iter: 135/135
--
Training Step: 136  | total loss: [1m[32m0.17142[0m[0m | time: 11.903s
[2K
| Adam | epoch: 028 | loss: 0.17142 - acc: 0.9384 -- iter: 032/135
[A[ATraining Step: 137  | total loss: [1m[32m0.16097[0m[0m | time: 16.076s
[2K
| Adam | epoch: 028 | loss: 0.16097 - acc: 0.9415 -- iter: 064/135
[A[ATraining Step: 138  | total loss: [1m[32m0.18625[0m[0m | time: 19.503s
[2K
| Adam | epoch: 028 | loss: 0.18625 - acc: 0.9330 -- iter: 096/135
[A[ATraining Step: 139  | total loss: [1m[32m0.17384[0m[0m | time: 31.297s
[2K
| Adam | epoch: 028 | loss: 0.17384 - acc: 0.9397 -- iter: 128/135
[A[ATraining Step: 140  | total loss: [1m[32m0.17030[0m[0m | time: 46.955s
[2K
| Adam | epoch: 028 | loss: 0.17030 - acc: 0.9426 | val_loss: 1.41444 - val_acc: 0.7209 -- iter: 135/135
--
Training Step: 141  | total loss: [1m[32m0.15584[0m[0m | time: 11.744s
[2K
| Adam | epoch: 029 | loss: 0.15584 - acc: 0.9484 -- iter: 032/135
[A[ATraining Step: 142  | total loss: [1m[32m0.14716[0m[0m | time: 24.224s
[2K
| Adam | epoch: 029 | loss: 0.14716 - acc: 0.9504 -- iter: 064/135
[A[ATraining Step: 143  | total loss: [1m[32m0.13655[0m[0m | time: 27.956s
[2K
| Adam | epoch: 029 | loss: 0.13655 - acc: 0.9554 -- iter: 096/135
[A[ATraining Step: 144  | total loss: [1m[32m0.12601[0m[0m | time: 31.884s
[2K
| Adam | epoch: 029 | loss: 0.12601 - acc: 0.9598 -- iter: 128/135
[A[ATraining Step: 145  | total loss: [1m[32m0.11552[0m[0m | time: 47.191s
[2K
| Adam | epoch: 029 | loss: 0.11552 - acc: 0.9638 | val_loss: 0.80579 - val_acc: 0.7674 -- iter: 135/135
--
Training Step: 146  | total loss: [1m[32m0.10841[0m[0m | time: 12.097s
[2K
| Adam | epoch: 030 | loss: 0.10841 - acc: 0.9643 -- iter: 032/135
[A[ATraining Step: 147  | total loss: [1m[32m0.10200[0m[0m | time: 24.486s
[2K
| Adam | epoch: 030 | loss: 0.10200 - acc: 0.9679 -- iter: 064/135
[A[ATraining Step: 148  | total loss: [1m[32m0.13358[0m[0m | time: 36.426s
[2K
| Adam | epoch: 030 | loss: 0.13358 - acc: 0.9649 -- iter: 096/135
[A[ATraining Step: 149  | total loss: [1m[32m0.13441[0m[0m | time: 40.368s
[2K
| Adam | epoch: 030 | loss: 0.13441 - acc: 0.9621 -- iter: 128/135
[A[ATraining Step: 150  | total loss: [1m[32m0.15166[0m[0m | time: 47.657s
[2K
| Adam | epoch: 030 | loss: 0.15166 - acc: 0.9373 | val_loss: 1.22786 - val_acc: 0.7442 -- iter: 135/135
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9652173913043478
Validation AUPRC:0.962832156317905
Test AUC:0.9864253393665158
Test AUPRC:0.9912627187627187
BestTestF1Score	0.94	0.85	0.93	0.93	0.96	25	2	15	1	0.99
BestTestMCCScore	0.94	0.85	0.93	0.93	0.96	25	2	15	1	0.99
BestTestAccuracyScore	0.92	0.81	0.91	0.96	0.88	23	1	16	3	1.0
BestValidationF1Score	0.89	0.79	0.88	0.8	1.0	20	5	18	0	0.99
BestValidationMCC	0.89	0.79	0.88	0.8	1.0	20	5	18	0	0.99
BestValidationAccuracy	0.88	0.78	0.88	0.83	0.95	19	4	19	1	1.0
TestPredictions (Threshold:0.99)
CHEMBL1329455,TN,INACT,0.41999998688697815	CHEMBL133915,TP,ACT,1.0	CHEMBL424636,TP,ACT,1.0	CHEMBL111217,TP,ACT,1.0	CHEMBL85322,TN,INACT,0.9100000262260437	CHEMBL206005,TP,ACT,1.0	CHEMBL114390,TP,ACT,1.0	CHEMBL1528123,TN,INACT,0.5699999928474426	CHEMBL308377,TP,ACT,1.0	CHEMBL205634,TP,ACT,1.0	CHEMBL205532,TP,ACT,1.0	CHEMBL208213,TP,ACT,1.0	CHEMBL396873,TN,INACT,0.019999999552965164	CHEMBL347411,TP,ACT,1.0	CHEMBL208529,TP,ACT,1.0	CHEMBL101308,TP,ACT,1.0	CHEMBL115763,TP,ACT,1.0	CHEMBL164902,TP,ACT,1.0	CHEMBL423465,TP,ACT,1.0	CHEMBL2348875,TN,INACT,0.07000000029802322	CHEMBL1434961,TN,INACT,0.019999999552965164	CHEMBL93848,TP,ACT,1.0	CHEMBL378553,FN,ACT,0.9800000190734863	CHEMBL1525366,TN,INACT,0.30000001192092896	CHEMBL1597933,TN,INACT,0.9100000262260437	CHEMBL133896,TP,ACT,0.9900000095367432	CHEMBL1498999,TN,INACT,0.10999999940395355	CHEMBL3189442,TN,INACT,0.05000000074505806	CHEMBL235491,TN,INACT,0.10000000149011612	CHEMBL2441817,FP,INACT,1.0	CHEMBL290246,TP,ACT,0.9900000095367432	CHEMBL551185,TN,INACT,0.09000000357627869	CHEMBL41422,TP,ACT,1.0	CHEMBL1326483,TN,INACT,0.6000000238418579	CHEMBL1023,TP,ACT,1.0	CHEMBL41146,TP,ACT,1.0	CHEMBL324960,TP,ACT,1.0	CHEMBL337393,TP,ACT,1.0	CHEMBL1495194,TN,INACT,0.05999999865889549	CHEMBL205694,TP,ACT,1.0	CHEMBL3827633,TN,INACT,0.029999999329447746	CHEMBL1501269,FP,INACT,0.9900000095367432	CHEMBL38,TP,ACT,1.0	

