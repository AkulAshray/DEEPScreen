CNNModel CHEMBL3785 adam 0.001 15 128 0 0.6 False True
Number of active compounds :	256
Number of inactive compounds :	256
---------------------------------
Run id: CNNModel_CHEMBL3785_adam_0.001_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3785_adam_0.001_15_128_0.6_True/
---------------------------------
Training samples: 313
Validation samples: 98
--
Training Step: 1  | time: 1.238s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/313
[A[ATraining Step: 2  | total loss: [1m[32m0.62368[0m[0m | time: 2.313s
[2K
| Adam | epoch: 001 | loss: 0.62368 - acc: 0.4781 -- iter: 064/313
[A[ATraining Step: 3  | total loss: [1m[32m0.68272[0m[0m | time: 3.336s
[2K
| Adam | epoch: 001 | loss: 0.68272 - acc: 0.4449 -- iter: 096/313
[A[ATraining Step: 4  | total loss: [1m[32m0.69074[0m[0m | time: 4.199s
[2K
| Adam | epoch: 001 | loss: 0.69074 - acc: 0.4862 -- iter: 128/313
[A[ATraining Step: 5  | total loss: [1m[32m0.69133[0m[0m | time: 5.184s
[2K
| Adam | epoch: 001 | loss: 0.69133 - acc: 0.5823 -- iter: 160/313
[A[ATraining Step: 6  | total loss: [1m[32m0.69061[0m[0m | time: 6.172s
[2K
| Adam | epoch: 001 | loss: 0.69061 - acc: 0.5696 -- iter: 192/313
[A[ATraining Step: 7  | total loss: [1m[32m0.68600[0m[0m | time: 7.147s
[2K
| Adam | epoch: 001 | loss: 0.68600 - acc: 0.5841 -- iter: 224/313
[A[ATraining Step: 8  | total loss: [1m[32m0.66631[0m[0m | time: 8.339s
[2K
| Adam | epoch: 001 | loss: 0.66631 - acc: 0.6247 -- iter: 256/313
[A[ATraining Step: 9  | total loss: [1m[32m0.69242[0m[0m | time: 9.377s
[2K
| Adam | epoch: 001 | loss: 0.69242 - acc: 0.5918 -- iter: 288/313
[A[ATraining Step: 10  | total loss: [1m[32m0.73899[0m[0m | time: 11.195s
[2K
| Adam | epoch: 001 | loss: 0.73899 - acc: 0.4990 | val_loss: 0.68881 - val_acc: 0.5408 -- iter: 313/313
--
Training Step: 11  | total loss: [1m[32m0.73078[0m[0m | time: 0.846s
[2K
| Adam | epoch: 002 | loss: 0.73078 - acc: 0.4711 -- iter: 032/313
[A[ATraining Step: 12  | total loss: [1m[32m0.72067[0m[0m | time: 2.000s
[2K
| Adam | epoch: 002 | loss: 0.72067 - acc: 0.4391 -- iter: 064/313
[A[ATraining Step: 13  | total loss: [1m[32m0.70904[0m[0m | time: 3.283s
[2K
| Adam | epoch: 002 | loss: 0.70904 - acc: 0.4652 -- iter: 096/313
[A[ATraining Step: 14  | total loss: [1m[32m0.70318[0m[0m | time: 4.302s
[2K
| Adam | epoch: 002 | loss: 0.70318 - acc: 0.4539 -- iter: 128/313
[A[ATraining Step: 15  | total loss: [1m[32m0.69851[0m[0m | time: 5.442s
[2K
| Adam | epoch: 002 | loss: 0.69851 - acc: 0.5331 -- iter: 160/313
[A[ATraining Step: 16  | total loss: [1m[32m0.69632[0m[0m | time: 6.700s
[2K
| Adam | epoch: 002 | loss: 0.69632 - acc: 0.5441 -- iter: 192/313
[A[ATraining Step: 17  | total loss: [1m[32m0.69511[0m[0m | time: 7.830s
[2K
| Adam | epoch: 002 | loss: 0.69511 - acc: 0.5732 -- iter: 224/313
[A[ATraining Step: 18  | total loss: [1m[32m0.69442[0m[0m | time: 8.794s
[2K
| Adam | epoch: 002 | loss: 0.69442 - acc: 0.5479 -- iter: 256/313
[A[ATraining Step: 19  | total loss: [1m[32m0.69389[0m[0m | time: 9.975s
[2K
| Adam | epoch: 002 | loss: 0.69389 - acc: 0.5840 -- iter: 288/313
[A[ATraining Step: 20  | total loss: [1m[32m0.69362[0m[0m | time: 12.012s
[2K
| Adam | epoch: 002 | loss: 0.69362 - acc: 0.5771 | val_loss: 0.69288 - val_acc: 0.5408 -- iter: 313/313
--
Training Step: 21  | total loss: [1m[32m0.69348[0m[0m | time: 0.928s
[2K
| Adam | epoch: 003 | loss: 0.69348 - acc: 0.5532 -- iter: 032/313
[A[ATraining Step: 22  | total loss: [1m[32m0.69352[0m[0m | time: 1.629s
[2K
| Adam | epoch: 003 | loss: 0.69352 - acc: 0.5072 -- iter: 064/313
[A[ATraining Step: 23  | total loss: [1m[32m0.69359[0m[0m | time: 2.425s
[2K
| Adam | epoch: 003 | loss: 0.69359 - acc: 0.4761 -- iter: 096/313
[A[ATraining Step: 24  | total loss: [1m[32m0.69339[0m[0m | time: 3.219s
[2K
| Adam | epoch: 003 | loss: 0.69339 - acc: 0.5004 -- iter: 128/313
[A[ATraining Step: 25  | total loss: [1m[32m0.69321[0m[0m | time: 3.982s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.5259 -- iter: 160/313
[A[ATraining Step: 26  | total loss: [1m[32m0.69318[0m[0m | time: 4.738s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.5190 -- iter: 192/313
[A[ATraining Step: 27  | total loss: [1m[32m0.69307[0m[0m | time: 5.469s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5302 -- iter: 224/313
[A[ATraining Step: 28  | total loss: [1m[32m0.69325[0m[0m | time: 6.241s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.4992 -- iter: 256/313
[A[ATraining Step: 29  | total loss: [1m[32m0.69330[0m[0m | time: 6.864s
[2K
| Adam | epoch: 003 | loss: 0.69330 - acc: 0.4918 -- iter: 288/313
[A[ATraining Step: 30  | total loss: [1m[32m0.69304[0m[0m | time: 8.565s
[2K
| Adam | epoch: 003 | loss: 0.69304 - acc: 0.5233 | val_loss: 0.69268 - val_acc: 0.5408 -- iter: 313/313
--
Training Step: 31  | total loss: [1m[32m0.69282[0m[0m | time: 1.220s
[2K
| Adam | epoch: 004 | loss: 0.69282 - acc: 0.5468 -- iter: 032/313
[A[ATraining Step: 32  | total loss: [1m[32m0.69304[0m[0m | time: 2.178s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5222 -- iter: 064/313
[A[ATraining Step: 33  | total loss: [1m[32m0.69282[0m[0m | time: 3.237s
[2K
| Adam | epoch: 004 | loss: 0.69282 - acc: 0.5393 -- iter: 096/313
[A[ATraining Step: 34  | total loss: [1m[32m0.69231[0m[0m | time: 4.401s
[2K
| Adam | epoch: 004 | loss: 0.69231 - acc: 0.5694 -- iter: 128/313
[A[ATraining Step: 35  | total loss: [1m[32m0.69211[0m[0m | time: 5.635s
[2K
| Adam | epoch: 004 | loss: 0.69211 - acc: 0.5745 -- iter: 160/313
[A[ATraining Step: 36  | total loss: [1m[32m0.69183[0m[0m | time: 6.391s
[2K
| Adam | epoch: 004 | loss: 0.69183 - acc: 0.5785 -- iter: 192/313
[A[ATraining Step: 37  | total loss: [1m[32m0.69205[0m[0m | time: 7.027s
[2K
| Adam | epoch: 004 | loss: 0.69205 - acc: 0.5628 -- iter: 224/313
[A[ATraining Step: 38  | total loss: [1m[32m0.69204[0m[0m | time: 7.645s
[2K
| Adam | epoch: 004 | loss: 0.69204 - acc: 0.5566 -- iter: 256/313
[A[ATraining Step: 39  | total loss: [1m[32m0.69182[0m[0m | time: 8.377s
[2K
| Adam | epoch: 004 | loss: 0.69182 - acc: 0.5577 -- iter: 288/313
[A[ATraining Step: 40  | total loss: [1m[32m0.69304[0m[0m | time: 10.106s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5293 | val_loss: 0.69020 - val_acc: 0.5408 -- iter: 313/313
--
Training Step: 41  | total loss: [1m[32m0.69205[0m[0m | time: 0.733s
[2K
| Adam | epoch: 005 | loss: 0.69205 - acc: 0.5412 -- iter: 032/313
[A[ATraining Step: 42  | total loss: [1m[32m0.69253[0m[0m | time: 1.475s
[2K
| Adam | epoch: 005 | loss: 0.69253 - acc: 0.5281 -- iter: 064/313
[A[ATraining Step: 43  | total loss: [1m[32m0.69287[0m[0m | time: 2.083s
[2K
| Adam | epoch: 005 | loss: 0.69287 - acc: 0.5176 -- iter: 096/313
[A[ATraining Step: 44  | total loss: [1m[32m0.69103[0m[0m | time: 2.683s
[2K
| Adam | epoch: 005 | loss: 0.69103 - acc: 0.5457 -- iter: 128/313
[A[ATraining Step: 45  | total loss: [1m[32m0.68941[0m[0m | time: 3.470s
[2K
| Adam | epoch: 005 | loss: 0.68941 - acc: 0.5618 -- iter: 160/313
[A[ATraining Step: 46  | total loss: [1m[32m0.68870[0m[0m | time: 4.099s
[2K
| Adam | epoch: 005 | loss: 0.68870 - acc: 0.5619 -- iter: 192/313
[A[ATraining Step: 47  | total loss: [1m[32m0.68723[0m[0m | time: 4.813s
[2K
| Adam | epoch: 005 | loss: 0.68723 - acc: 0.5671 -- iter: 224/313
[A[ATraining Step: 48  | total loss: [1m[32m0.68656[0m[0m | time: 5.559s
[2K
| Adam | epoch: 005 | loss: 0.68656 - acc: 0.5664 -- iter: 256/313
[A[ATraining Step: 49  | total loss: [1m[32m0.68755[0m[0m | time: 6.312s
[2K
| Adam | epoch: 005 | loss: 0.68755 - acc: 0.5608 -- iter: 288/313
[A[ATraining Step: 50  | total loss: [1m[32m0.69219[0m[0m | time: 8.082s
[2K
| Adam | epoch: 005 | loss: 0.69219 - acc: 0.5465 | val_loss: 0.68477 - val_acc: 0.5408 -- iter: 313/313
--
Training Step: 51  | total loss: [1m[32m0.68984[0m[0m | time: 0.779s
[2K
| Adam | epoch: 006 | loss: 0.68984 - acc: 0.5490 -- iter: 032/313
[A[ATraining Step: 52  | total loss: [1m[32m0.69364[0m[0m | time: 1.506s
[2K
| Adam | epoch: 006 | loss: 0.69364 - acc: 0.5322 -- iter: 064/313
[A[ATraining Step: 53  | total loss: [1m[32m0.69129[0m[0m | time: 2.261s
[2K
| Adam | epoch: 006 | loss: 0.69129 - acc: 0.5367 -- iter: 096/313
[A[ATraining Step: 54  | total loss: [1m[32m0.69179[0m[0m | time: 2.751s
[2K
| Adam | epoch: 006 | loss: 0.69179 - acc: 0.5268 -- iter: 128/313
[A[ATraining Step: 55  | total loss: [1m[32m0.68899[0m[0m | time: 3.268s
[2K
| Adam | epoch: 006 | loss: 0.68899 - acc: 0.5430 -- iter: 160/313
[A[ATraining Step: 56  | total loss: [1m[32m0.68911[0m[0m | time: 4.066s
[2K
| Adam | epoch: 006 | loss: 0.68911 - acc: 0.5341 -- iter: 192/313
[A[ATraining Step: 57  | total loss: [1m[32m0.68956[0m[0m | time: 4.813s
[2K
| Adam | epoch: 006 | loss: 0.68956 - acc: 0.5164 -- iter: 224/313
[A[ATraining Step: 58  | total loss: [1m[32m0.68882[0m[0m | time: 5.580s
[2K
| Adam | epoch: 006 | loss: 0.68882 - acc: 0.5185 -- iter: 256/313
[A[ATraining Step: 59  | total loss: [1m[32m0.68797[0m[0m | time: 6.297s
[2K
| Adam | epoch: 006 | loss: 0.68797 - acc: 0.5244 -- iter: 288/313
[A[ATraining Step: 60  | total loss: [1m[32m0.68566[0m[0m | time: 8.038s
[2K
| Adam | epoch: 006 | loss: 0.68566 - acc: 0.5418 | val_loss: 0.67296 - val_acc: 0.5408 -- iter: 313/313
--
Training Step: 61  | total loss: [1m[32m0.68509[0m[0m | time: 0.790s
[2K
| Adam | epoch: 007 | loss: 0.68509 - acc: 0.5323 -- iter: 032/313
[A[ATraining Step: 62  | total loss: [1m[32m0.68519[0m[0m | time: 1.401s
[2K
| Adam | epoch: 007 | loss: 0.68519 - acc: 0.5241 -- iter: 064/313
[A[ATraining Step: 63  | total loss: [1m[32m0.68299[0m[0m | time: 2.131s
[2K
| Adam | epoch: 007 | loss: 0.68299 - acc: 0.5330 -- iter: 096/313
[A[ATraining Step: 64  | total loss: [1m[32m0.68041[0m[0m | time: 2.878s
[2K
| Adam | epoch: 007 | loss: 0.68041 - acc: 0.5288 -- iter: 128/313
[A[ATraining Step: 65  | total loss: [1m[32m0.67407[0m[0m | time: 3.429s
[2K
| Adam | epoch: 007 | loss: 0.67407 - acc: 0.5561 -- iter: 160/313
[A[ATraining Step: 66  | total loss: [1m[32m0.67047[0m[0m | time: 4.041s
[2K
| Adam | epoch: 007 | loss: 0.67047 - acc: 0.5468 -- iter: 192/313
[A[ATraining Step: 67  | total loss: [1m[32m0.66723[0m[0m | time: 4.779s
[2K
| Adam | epoch: 007 | loss: 0.66723 - acc: 0.5436 -- iter: 224/313
[A[ATraining Step: 68  | total loss: [1m[32m0.66107[0m[0m | time: 5.522s
[2K
| Adam | epoch: 007 | loss: 0.66107 - acc: 0.5681 -- iter: 256/313
[A[ATraining Step: 69  | total loss: [1m[32m0.65554[0m[0m | time: 6.281s
[2K
| Adam | epoch: 007 | loss: 0.65554 - acc: 0.5930 -- iter: 288/313
[A[ATraining Step: 70  | total loss: [1m[32m0.63325[0m[0m | time: 8.124s
[2K
| Adam | epoch: 007 | loss: 0.63325 - acc: 0.6327 | val_loss: 0.50798 - val_acc: 0.7755 -- iter: 313/313
--
Training Step: 71  | total loss: [1m[32m0.62481[0m[0m | time: 1.160s
[2K
| Adam | epoch: 008 | loss: 0.62481 - acc: 0.6425 -- iter: 032/313
[A[ATraining Step: 72  | total loss: [1m[32m0.61159[0m[0m | time: 2.276s
[2K
| Adam | epoch: 008 | loss: 0.61159 - acc: 0.6617 -- iter: 064/313
[A[ATraining Step: 73  | total loss: [1m[32m0.60710[0m[0m | time: 3.232s
[2K
| Adam | epoch: 008 | loss: 0.60710 - acc: 0.6715 -- iter: 096/313
[A[ATraining Step: 74  | total loss: [1m[32m0.59852[0m[0m | time: 4.316s
[2K
| Adam | epoch: 008 | loss: 0.59852 - acc: 0.6869 -- iter: 128/313
[A[ATraining Step: 75  | total loss: [1m[32m0.61820[0m[0m | time: 5.428s
[2K
| Adam | epoch: 008 | loss: 0.61820 - acc: 0.6836 -- iter: 160/313
[A[ATraining Step: 76  | total loss: [1m[32m0.59020[0m[0m | time: 6.258s
[2K
| Adam | epoch: 008 | loss: 0.59020 - acc: 0.7075 -- iter: 192/313
[A[ATraining Step: 77  | total loss: [1m[32m0.57938[0m[0m | time: 7.274s
[2K
| Adam | epoch: 008 | loss: 0.57938 - acc: 0.7173 -- iter: 224/313
[A[ATraining Step: 78  | total loss: [1m[32m0.57291[0m[0m | time: 8.538s
[2K
| Adam | epoch: 008 | loss: 0.57291 - acc: 0.7176 -- iter: 256/313
[A[ATraining Step: 79  | total loss: [1m[32m0.55859[0m[0m | time: 9.597s
[2K
| Adam | epoch: 008 | loss: 0.55859 - acc: 0.7274 -- iter: 288/313
[A[ATraining Step: 80  | total loss: [1m[32m0.52474[0m[0m | time: 11.823s
[2K
| Adam | epoch: 008 | loss: 0.52474 - acc: 0.7489 | val_loss: 0.47625 - val_acc: 0.7653 -- iter: 313/313
--
Training Step: 81  | total loss: [1m[32m0.52626[0m[0m | time: 1.043s
[2K
| Adam | epoch: 009 | loss: 0.52626 - acc: 0.7521 -- iter: 032/313
[A[ATraining Step: 82  | total loss: [1m[32m0.50304[0m[0m | time: 2.116s
[2K
| Adam | epoch: 009 | loss: 0.50304 - acc: 0.7644 -- iter: 064/313
[A[ATraining Step: 83  | total loss: [1m[32m0.51119[0m[0m | time: 3.291s
[2K
| Adam | epoch: 009 | loss: 0.51119 - acc: 0.7661 -- iter: 096/313
[A[ATraining Step: 84  | total loss: [1m[32m0.49143[0m[0m | time: 4.463s
[2K
| Adam | epoch: 009 | loss: 0.49143 - acc: 0.7801 -- iter: 128/313
[A[ATraining Step: 85  | total loss: [1m[32m0.52222[0m[0m | time: 5.778s
[2K
| Adam | epoch: 009 | loss: 0.52222 - acc: 0.7584 -- iter: 160/313
[A[ATraining Step: 86  | total loss: [1m[32m0.50674[0m[0m | time: 7.026s
[2K
| Adam | epoch: 009 | loss: 0.50674 - acc: 0.7700 -- iter: 192/313
[A[ATraining Step: 87  | total loss: [1m[32m0.52304[0m[0m | time: 8.025s
[2K
| Adam | epoch: 009 | loss: 0.52304 - acc: 0.7524 -- iter: 224/313
[A[ATraining Step: 88  | total loss: [1m[32m0.51242[0m[0m | time: 8.951s
[2K
| Adam | epoch: 009 | loss: 0.51242 - acc: 0.7612 -- iter: 256/313
[A[ATraining Step: 89  | total loss: [1m[32m0.51255[0m[0m | time: 10.070s
[2K
| Adam | epoch: 009 | loss: 0.51255 - acc: 0.7610 -- iter: 288/313
[A[ATraining Step: 90  | total loss: [1m[32m0.51702[0m[0m | time: 12.330s
[2K
| Adam | epoch: 009 | loss: 0.51702 - acc: 0.7662 | val_loss: 0.40044 - val_acc: 0.8265 -- iter: 313/313
--
Training Step: 91  | total loss: [1m[32m0.50290[0m[0m | time: 1.234s
[2K
| Adam | epoch: 010 | loss: 0.50290 - acc: 0.7771 -- iter: 032/313
[A[ATraining Step: 92  | total loss: [1m[32m0.49880[0m[0m | time: 2.385s
[2K
| Adam | epoch: 010 | loss: 0.49880 - acc: 0.7806 -- iter: 064/313
[A[ATraining Step: 93  | total loss: [1m[32m0.49096[0m[0m | time: 3.658s
[2K
| Adam | epoch: 010 | loss: 0.49096 - acc: 0.7869 -- iter: 096/313
[A[ATraining Step: 94  | total loss: [1m[32m0.48609[0m[0m | time: 5.026s
[2K
| Adam | epoch: 010 | loss: 0.48609 - acc: 0.7895 -- iter: 128/313
[A[ATraining Step: 95  | total loss: [1m[32m0.47938[0m[0m | time: 6.170s
[2K
| Adam | epoch: 010 | loss: 0.47938 - acc: 0.7980 -- iter: 160/313
[A[ATraining Step: 96  | total loss: [1m[32m0.48190[0m[0m | time: 7.407s
[2K
| Adam | epoch: 010 | loss: 0.48190 - acc: 0.7995 -- iter: 192/313
[A[ATraining Step: 97  | total loss: [1m[32m0.47952[0m[0m | time: 8.499s
[2K
| Adam | epoch: 010 | loss: 0.47952 - acc: 0.8008 -- iter: 224/313
[A[ATraining Step: 98  | total loss: [1m[32m0.45987[0m[0m | time: 9.512s
[2K
| Adam | epoch: 010 | loss: 0.45987 - acc: 0.8176 -- iter: 256/313
[A[ATraining Step: 99  | total loss: [1m[32m0.45642[0m[0m | time: 10.407s
[2K
| Adam | epoch: 010 | loss: 0.45642 - acc: 0.8118 -- iter: 288/313
[A[ATraining Step: 100  | total loss: [1m[32m0.44520[0m[0m | time: 12.498s
[2K
| Adam | epoch: 010 | loss: 0.44520 - acc: 0.8226 | val_loss: 0.33109 - val_acc: 0.8673 -- iter: 313/313
--
Training Step: 101  | total loss: [1m[32m0.42822[0m[0m | time: 1.066s
[2K
| Adam | epoch: 011 | loss: 0.42822 - acc: 0.8373 -- iter: 032/313
[A[ATraining Step: 102  | total loss: [1m[32m0.42519[0m[0m | time: 2.114s
[2K
| Adam | epoch: 011 | loss: 0.42519 - acc: 0.8379 -- iter: 064/313
[A[ATraining Step: 103  | total loss: [1m[32m0.41653[0m[0m | time: 3.166s
[2K
| Adam | epoch: 011 | loss: 0.41653 - acc: 0.8447 -- iter: 096/313
[A[ATraining Step: 104  | total loss: [1m[32m0.41122[0m[0m | time: 4.383s
[2K
| Adam | epoch: 011 | loss: 0.41122 - acc: 0.8478 -- iter: 128/313
[A[ATraining Step: 105  | total loss: [1m[32m0.43235[0m[0m | time: 5.427s
[2K
| Adam | epoch: 011 | loss: 0.43235 - acc: 0.8349 -- iter: 160/313
[A[ATraining Step: 106  | total loss: [1m[32m0.41642[0m[0m | time: 6.575s
[2K
| Adam | epoch: 011 | loss: 0.41642 - acc: 0.8451 -- iter: 192/313
[A[ATraining Step: 107  | total loss: [1m[32m0.40687[0m[0m | time: 7.710s
[2K
| Adam | epoch: 011 | loss: 0.40687 - acc: 0.8512 -- iter: 224/313
[A[ATraining Step: 108  | total loss: [1m[32m0.40381[0m[0m | time: 8.824s
[2K
| Adam | epoch: 011 | loss: 0.40381 - acc: 0.8567 -- iter: 256/313
[A[ATraining Step: 109  | total loss: [1m[32m0.40001[0m[0m | time: 9.872s
[2K
| Adam | epoch: 011 | loss: 0.40001 - acc: 0.8554 -- iter: 288/313
[A[ATraining Step: 110  | total loss: [1m[32m0.37452[0m[0m | time: 11.947s
[2K
| Adam | epoch: 011 | loss: 0.37452 - acc: 0.8659 | val_loss: 0.28387 - val_acc: 0.8878 -- iter: 313/313
--
Training Step: 111  | total loss: [1m[32m0.42226[0m[0m | time: 0.993s
[2K
| Adam | epoch: 012 | loss: 0.42226 - acc: 0.8433 -- iter: 032/313
[A[ATraining Step: 112  | total loss: [1m[32m0.41439[0m[0m | time: 2.000s
[2K
| Adam | epoch: 012 | loss: 0.41439 - acc: 0.8496 -- iter: 064/313
[A[ATraining Step: 113  | total loss: [1m[32m0.39616[0m[0m | time: 3.158s
[2K
| Adam | epoch: 012 | loss: 0.39616 - acc: 0.8615 -- iter: 096/313
[A[ATraining Step: 114  | total loss: [1m[32m0.40203[0m[0m | time: 4.272s
[2K
| Adam | epoch: 012 | loss: 0.40203 - acc: 0.8597 -- iter: 128/313
[A[ATraining Step: 115  | total loss: [1m[32m0.37660[0m[0m | time: 5.479s
[2K
| Adam | epoch: 012 | loss: 0.37660 - acc: 0.8738 -- iter: 160/313
[A[ATraining Step: 116  | total loss: [1m[32m0.37474[0m[0m | time: 6.798s
[2K
| Adam | epoch: 012 | loss: 0.37474 - acc: 0.8770 -- iter: 192/313
[A[ATraining Step: 117  | total loss: [1m[32m0.35528[0m[0m | time: 8.051s
[2K
| Adam | epoch: 012 | loss: 0.35528 - acc: 0.8862 -- iter: 224/313
[A[ATraining Step: 118  | total loss: [1m[32m0.36355[0m[0m | time: 9.262s
[2K
| Adam | epoch: 012 | loss: 0.36355 - acc: 0.8819 -- iter: 256/313
[A[ATraining Step: 119  | total loss: [1m[32m0.37581[0m[0m | time: 10.514s
[2K
| Adam | epoch: 012 | loss: 0.37581 - acc: 0.8719 -- iter: 288/313
[A[ATraining Step: 120  | total loss: [1m[32m0.35248[0m[0m | time: 12.533s
[2K
| Adam | epoch: 012 | loss: 0.35248 - acc: 0.8816 | val_loss: 0.26777 - val_acc: 0.8980 -- iter: 313/313
--
Training Step: 121  | total loss: [1m[32m0.35923[0m[0m | time: 1.047s
[2K
| Adam | epoch: 013 | loss: 0.35923 - acc: 0.8774 -- iter: 032/313
[A[ATraining Step: 122  | total loss: [1m[32m0.37128[0m[0m | time: 2.131s
[2K
| Adam | epoch: 013 | loss: 0.37128 - acc: 0.8697 -- iter: 064/313
[A[ATraining Step: 123  | total loss: [1m[32m0.35569[0m[0m | time: 3.120s
[2K
| Adam | epoch: 013 | loss: 0.35569 - acc: 0.8764 -- iter: 096/313
[A[ATraining Step: 124  | total loss: [1m[32m0.34685[0m[0m | time: 4.302s
[2K
| Adam | epoch: 013 | loss: 0.34685 - acc: 0.8794 -- iter: 128/313
[A[ATraining Step: 125  | total loss: [1m[32m0.33111[0m[0m | time: 5.502s
[2K
| Adam | epoch: 013 | loss: 0.33111 - acc: 0.8852 -- iter: 160/313
[A[ATraining Step: 126  | total loss: [1m[32m0.33293[0m[0m | time: 6.578s
[2K
| Adam | epoch: 013 | loss: 0.33293 - acc: 0.8842 -- iter: 192/313
[A[ATraining Step: 127  | total loss: [1m[32m0.31353[0m[0m | time: 7.603s
[2K
| Adam | epoch: 013 | loss: 0.31353 - acc: 0.8958 -- iter: 224/313
[A[ATraining Step: 128  | total loss: [1m[32m0.30420[0m[0m | time: 8.558s
[2K
| Adam | epoch: 013 | loss: 0.30420 - acc: 0.9000 -- iter: 256/313
[A[ATraining Step: 129  | total loss: [1m[32m0.31407[0m[0m | time: 9.568s
[2K
| Adam | epoch: 013 | loss: 0.31407 - acc: 0.8943 -- iter: 288/313
[A[ATraining Step: 130  | total loss: [1m[32m0.30100[0m[0m | time: 11.685s
[2K
| Adam | epoch: 013 | loss: 0.30100 - acc: 0.9018 | val_loss: 0.19821 - val_acc: 0.9388 -- iter: 313/313
--
Training Step: 131  | total loss: [1m[32m0.30549[0m[0m | time: 1.038s
[2K
| Adam | epoch: 014 | loss: 0.30549 - acc: 0.8991 -- iter: 032/313
[A[ATraining Step: 132  | total loss: [1m[32m0.31316[0m[0m | time: 1.984s
[2K
| Adam | epoch: 014 | loss: 0.31316 - acc: 0.8892 -- iter: 064/313
[A[ATraining Step: 133  | total loss: [1m[32m0.31133[0m[0m | time: 3.180s
[2K
| Adam | epoch: 014 | loss: 0.31133 - acc: 0.8883 -- iter: 096/313
[A[ATraining Step: 134  | total loss: [1m[32m0.30065[0m[0m | time: 4.273s
[2K
| Adam | epoch: 014 | loss: 0.30065 - acc: 0.8932 -- iter: 128/313
[A[ATraining Step: 135  | total loss: [1m[32m0.31241[0m[0m | time: 4.975s
[2K
| Adam | epoch: 014 | loss: 0.31241 - acc: 0.8914 -- iter: 160/313
[A[ATraining Step: 136  | total loss: [1m[32m0.29365[0m[0m | time: 5.599s
[2K
| Adam | epoch: 014 | loss: 0.29365 - acc: 0.9022 -- iter: 192/313
[A[ATraining Step: 137  | total loss: [1m[32m0.30461[0m[0m | time: 6.207s
[2K
| Adam | epoch: 014 | loss: 0.30461 - acc: 0.8995 -- iter: 224/313
[A[ATraining Step: 138  | total loss: [1m[32m0.29401[0m[0m | time: 6.815s
[2K
| Adam | epoch: 014 | loss: 0.29401 - acc: 0.9033 -- iter: 256/313
[A[ATraining Step: 139  | total loss: [1m[32m0.28591[0m[0m | time: 7.443s
[2K
| Adam | epoch: 014 | loss: 0.28591 - acc: 0.9067 -- iter: 288/313
[A[ATraining Step: 140  | total loss: [1m[32m0.27702[0m[0m | time: 9.306s
[2K
| Adam | epoch: 014 | loss: 0.27702 - acc: 0.9098 | val_loss: 0.17307 - val_acc: 0.9388 -- iter: 313/313
--
Training Step: 141  | total loss: [1m[32m0.26643[0m[0m | time: 0.622s
[2K
| Adam | epoch: 015 | loss: 0.26643 - acc: 0.9157 -- iter: 032/313
[A[ATraining Step: 142  | total loss: [1m[32m0.26606[0m[0m | time: 1.131s
[2K
| Adam | epoch: 015 | loss: 0.26606 - acc: 0.9116 -- iter: 064/313
[A[ATraining Step: 143  | total loss: [1m[32m0.25525[0m[0m | time: 1.637s
[2K
| Adam | epoch: 015 | loss: 0.25525 - acc: 0.9125 -- iter: 096/313
[A[ATraining Step: 144  | total loss: [1m[32m0.26272[0m[0m | time: 2.248s
[2K
| Adam | epoch: 015 | loss: 0.26272 - acc: 0.9092 -- iter: 128/313
[A[ATraining Step: 145  | total loss: [1m[32m0.25073[0m[0m | time: 2.853s
[2K
| Adam | epoch: 015 | loss: 0.25073 - acc: 0.9152 -- iter: 160/313
[A[ATraining Step: 146  | total loss: [1m[32m0.23376[0m[0m | time: 3.469s
[2K
| Adam | epoch: 015 | loss: 0.23376 - acc: 0.9237 -- iter: 192/313
[A[ATraining Step: 147  | total loss: [1m[32m0.23213[0m[0m | time: 4.072s
[2K
| Adam | epoch: 015 | loss: 0.23213 - acc: 0.9250 -- iter: 224/313
[A[ATraining Step: 148  | total loss: [1m[32m0.21389[0m[0m | time: 4.688s
[2K
| Adam | epoch: 015 | loss: 0.21389 - acc: 0.9325 -- iter: 256/313
[A[ATraining Step: 149  | total loss: [1m[32m0.20236[0m[0m | time: 5.283s
[2K
| Adam | epoch: 015 | loss: 0.20236 - acc: 0.9393 -- iter: 288/313
[A[ATraining Step: 150  | total loss: [1m[32m0.21170[0m[0m | time: 6.897s
[2K
| Adam | epoch: 015 | loss: 0.21170 - acc: 0.9360 | val_loss: 0.14594 - val_acc: 0.9286 -- iter: 313/313
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9937106918238994
Validation AUPRC:0.9932429035544438
Test AUC:0.9937421777221527
Test AUPRC:0.9946866739057872
BestTestF1Score	0.94	0.88	0.94	0.98	0.9	46	1	46	5	0.82
BestTestMCCScore	0.94	0.88	0.94	0.98	0.9	46	1	46	5	0.82
BestTestAccuracyScore	0.94	0.88	0.94	0.98	0.9	46	1	46	5	0.82
BestValidationF1Score	0.97	0.94	0.97	0.98	0.96	43	1	52	2	0.82
BestValidationMCC	0.97	0.94	0.97	0.98	0.96	43	1	52	2	0.82
BestValidationAccuracy	0.97	0.94	0.97	0.98	0.96	43	1	52	2	0.82
TestPredictions (Threshold:0.82)
CHEMBL401470,TP,ACT,0.9700000286102295	CHEMBL398625,TP,ACT,0.9700000286102295	CHEMBL78601,TN,INACT,0.009999999776482582	CHEMBL302038,TN,INACT,0.25	CHEMBL1224147,TP,ACT,0.949999988079071	CHEMBL323175,TN,INACT,0.009999999776482582	CHEMBL482963,TP,ACT,0.9700000286102295	CHEMBL297473,TN,INACT,0.0	CHEMBL441305,TN,INACT,0.03999999910593033	CHEMBL1771745,TP,ACT,0.9599999785423279	CHEMBL1083743,TP,ACT,0.9300000071525574	CHEMBL273410,TN,INACT,0.0	CHEMBL429238,TN,INACT,0.05000000074505806	CHEMBL237036,TP,ACT,0.9399999976158142	CHEMBL483336,TP,ACT,0.8999999761581421	CHEMBL114478,TN,INACT,0.4000000059604645	CHEMBL594801,TN,INACT,0.009999999776482582	CHEMBL1083442,TP,ACT,0.949999988079071	CHEMBL485184,TP,ACT,0.9800000190734863	CHEMBL252306,TP,ACT,0.9700000286102295	CHEMBL1771640,TP,ACT,0.9300000071525574	CHEMBL542000,TP,ACT,0.9800000190734863	CHEMBL164968,TN,INACT,0.0	CHEMBL15936,TN,INACT,0.12999999523162842	CHEMBL492020,TP,ACT,0.9200000166893005	CHEMBL123099,TN,INACT,0.0	CHEMBL483140,TP,ACT,0.8999999761581421	CHEMBL40317,TN,INACT,0.11999999731779099	CHEMBL520299,TP,ACT,0.9700000286102295	CHEMBL602474,FP,INACT,0.8700000047683716	CHEMBL3589835,TP,ACT,0.9700000286102295	CHEMBL521326,TP,ACT,0.9700000286102295	CHEMBL520136,TP,ACT,0.9700000286102295	CHEMBL45456,TN,INACT,0.009999999776482582	CHEMBL3589785,TP,ACT,0.9599999785423279	CHEMBL3633656,TN,INACT,0.009999999776482582	CHEMBL104223,TN,INACT,0.009999999776482582	CHEMBL3589836,TP,ACT,0.9399999976158142	CHEMBL236163,TP,ACT,0.9599999785423279	CHEMBL413040,TN,INACT,0.019999999552965164	CHEMBL1084059,TP,ACT,0.9700000286102295	CHEMBL369359,TN,INACT,0.009999999776482582	CHEMBL2391353,TN,INACT,0.38999998569488525	CHEMBL112877,TN,INACT,0.0	CHEMBL1224070,TP,ACT,0.9700000286102295	CHEMBL407818,TN,INACT,0.41999998688697815	CHEMBL21508,TN,INACT,0.05999999865889549	CHEMBL235256,TP,ACT,0.9700000286102295	CHEMBL1770356,TP,ACT,0.9700000286102295	CHEMBL558334,TP,ACT,0.9700000286102295	CHEMBL391603,TP,ACT,0.9599999785423279	CHEMBL1771641,TP,ACT,0.9399999976158142	CHEMBL484783,TP,ACT,0.9800000190734863	CHEMBL1083174,TP,ACT,0.9200000166893005	CHEMBL1770175,TP,ACT,0.9700000286102295	CHEMBL491003,TP,ACT,0.9700000286102295	CHEMBL1086030,FN,ACT,0.7900000214576721	CHEMBL401469,TP,ACT,0.9700000286102295	CHEMBL1208921,FN,ACT,0.8100000023841858	CHEMBL15689,TN,INACT,0.009999999776482582	CHEMBL1770353,TP,ACT,0.9599999785423279	CHEMBL247921,FN,ACT,0.6899999976158142	CHEMBL233552,TN,INACT,0.009999999776482582	CHEMBL308924,TN,INACT,0.28999999165534973	CHEMBL79030,TN,INACT,0.1599999964237213	CHEMBL149592,TN,INACT,0.0	CHEMBL482943,TP,ACT,0.9700000286102295	CHEMBL502716,TP,ACT,0.9800000190734863	CHEMBL267094,TN,INACT,0.009999999776482582	CHEMBL1086354,FN,ACT,0.5600000023841858	CHEMBL1088074,FN,ACT,0.1899999976158142	CHEMBL329861,TN,INACT,0.0	CHEMBL1085616,TP,ACT,0.9599999785423279	CHEMBL483337,TP,ACT,0.9599999785423279	CHEMBL3589784,TP,ACT,0.9599999785423279	CHEMBL48120,TN,INACT,0.0	CHEMBL2391356,TN,INACT,0.1899999976158142	CHEMBL217002,TN,INACT,0.03999999910593033	CHEMBL2113072,TN,INACT,0.550000011920929	CHEMBL1085653,TP,ACT,0.9399999976158142	CHEMBL133257,TN,INACT,0.0	CHEMBL355851,TN,INACT,0.0	CHEMBL553155,TN,INACT,0.33000001311302185	CHEMBL491002,TP,ACT,0.9599999785423279	CHEMBL320763,TN,INACT,0.009999999776482582	CHEMBL80807,TN,INACT,0.6200000047683716	CHEMBL595022,TN,INACT,0.03999999910593033	CHEMBL283320,TN,INACT,0.0	CHEMBL112770,TN,INACT,0.0	CHEMBL482768,TP,ACT,0.9700000286102295	CHEMBL3350741,TN,INACT,0.0	CHEMBL507182,TP,ACT,0.9700000286102295	CHEMBL421523,TN,INACT,0.009999999776482582	CHEMBL76949,TN,INACT,0.019999999552965164	CHEMBL21509,TN,INACT,0.03999999910593033	CHEMBL483996,TP,ACT,0.9700000286102295	CHEMBL1085842,TP,ACT,0.8600000143051147	CHEMBL78669,TN,INACT,0.009999999776482582	

