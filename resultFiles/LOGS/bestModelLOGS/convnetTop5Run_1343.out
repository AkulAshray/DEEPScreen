ImageNetInceptionV2 CHEMBL5896 adam 0.0001 30 0 0 0.6 False True
Number of active compounds :	107
Number of inactive compounds :	107
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5896_adam_0.0001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5896_adam_0.0001_30_0.6/
---------------------------------
Training samples: 119
Validation samples: 38
--
Training Step: 1  | time: 625.147s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/119
[A[ATraining Step: 2  | total loss: [1m[32m0.59980[0m[0m | time: 1122.931s
[2K
| Adam | epoch: 001 | loss: 0.59980 - acc: 0.6187 -- iter: 064/119
[A[ATraining Step: 3  | total loss: [1m[32m0.60441[0m[0m | time: 1404.161s
[2K
| Adam | epoch: 001 | loss: 0.60441 - acc: 0.7006 -- iter: 096/119
[A[ATraining Step: 4  | total loss: [1m[32m0.64985[0m[0m | time: 1622.924s
[2K
| Adam | epoch: 001 | loss: 0.64985 - acc: 0.6205 | val_loss: 0.70269 - val_acc: 0.4211 -- iter: 119/119
--
Training Step: 5  | total loss: [1m[32m0.58267[0m[0m | time: 143.783s
[2K
| Adam | epoch: 002 | loss: 0.58267 - acc: 0.7026 -- iter: 032/119
[A[ATraining Step: 6  | total loss: [1m[32m0.49246[0m[0m | time: 552.503s
[2K
| Adam | epoch: 002 | loss: 0.49246 - acc: 0.8658 -- iter: 064/119
[A[ATraining Step: 7  | total loss: [1m[32m0.57176[0m[0m | time: 697.291s
[2K
| Adam | epoch: 002 | loss: 0.57176 - acc: 0.7213 -- iter: 096/119
[A[ATraining Step: 8  | total loss: [1m[32m0.50255[0m[0m | time: 800.959s
[2K
| Adam | epoch: 002 | loss: 0.50255 - acc: 0.7902 | val_loss: 0.89735 - val_acc: 0.4211 -- iter: 119/119
--
Training Step: 9  | total loss: [1m[32m0.45767[0m[0m | time: 22.259s
[2K
| Adam | epoch: 003 | loss: 0.45767 - acc: 0.8185 -- iter: 032/119
[A[ATraining Step: 10  | total loss: [1m[32m0.40389[0m[0m | time: 141.222s
[2K
| Adam | epoch: 003 | loss: 0.40389 - acc: 0.8875 -- iter: 064/119
[A[ATraining Step: 11  | total loss: [1m[32m0.33298[0m[0m | time: 285.015s
[2K
| Adam | epoch: 003 | loss: 0.33298 - acc: 0.9408 -- iter: 096/119
[A[ATraining Step: 12  | total loss: [1m[32m0.32306[0m[0m | time: 432.133s
[2K
| Adam | epoch: 003 | loss: 0.32306 - acc: 0.9393 | val_loss: 0.96006 - val_acc: 0.4211 -- iter: 119/119
--
Training Step: 13  | total loss: [1m[32m0.31546[0m[0m | time: 19.286s
[2K
| Adam | epoch: 004 | loss: 0.31546 - acc: 0.9385 -- iter: 032/119
[A[ATraining Step: 14  | total loss: [1m[32m0.29587[0m[0m | time: 28.074s
[2K
| Adam | epoch: 004 | loss: 0.29587 - acc: 0.9637 -- iter: 064/119
[A[ATraining Step: 15  | total loss: [1m[32m0.24810[0m[0m | time: 54.145s
[2K
| Adam | epoch: 004 | loss: 0.24810 - acc: 0.9779 -- iter: 096/119
[A[ATraining Step: 16  | total loss: [1m[32m0.21112[0m[0m | time: 114.171s
[2K
| Adam | epoch: 004 | loss: 0.21112 - acc: 0.9699 | val_loss: 0.92068 - val_acc: 0.4211 -- iter: 119/119
--
Training Step: 17  | total loss: [1m[32m0.19586[0m[0m | time: 74.726s
[2K
| Adam | epoch: 005 | loss: 0.19586 - acc: 0.9807 -- iter: 032/119
[A[ATraining Step: 18  | total loss: [1m[32m0.19462[0m[0m | time: 95.028s
[2K
| Adam | epoch: 005 | loss: 0.19462 - acc: 0.9766 -- iter: 064/119
[A[ATraining Step: 19  | total loss: [1m[32m0.15869[0m[0m | time: 102.357s
[2K
| Adam | epoch: 005 | loss: 0.15869 - acc: 0.9844 -- iter: 096/119
[A[ATraining Step: 20  | total loss: [1m[32m0.13149[0m[0m | time: 111.241s
[2K
| Adam | epoch: 005 | loss: 0.13149 - acc: 0.9894 | val_loss: 0.87538 - val_acc: 0.4211 -- iter: 119/119
--
Training Step: 21  | total loss: [1m[32m0.10576[0m[0m | time: 9.491s
[2K
| Adam | epoch: 006 | loss: 0.10576 - acc: 0.9927 -- iter: 032/119
[A[ATraining Step: 22  | total loss: [1m[32m0.09351[0m[0m | time: 18.565s
[2K
| Adam | epoch: 006 | loss: 0.09351 - acc: 0.9949 -- iter: 064/119
[A[ATraining Step: 23  | total loss: [1m[32m0.07439[0m[0m | time: 37.696s
[2K
| Adam | epoch: 006 | loss: 0.07439 - acc: 0.9964 -- iter: 096/119
[A[ATraining Step: 24  | total loss: [1m[32m0.06078[0m[0m | time: 46.530s
[2K
| Adam | epoch: 006 | loss: 0.06078 - acc: 0.9974 | val_loss: 0.80515 - val_acc: 0.3947 -- iter: 119/119
--
Training Step: 25  | total loss: [1m[32m0.05257[0m[0m | time: 7.134s
[2K
| Adam | epoch: 007 | loss: 0.05257 - acc: 0.9981 -- iter: 032/119
[A[ATraining Step: 26  | total loss: [1m[32m0.04456[0m[0m | time: 16.518s
[2K
| Adam | epoch: 007 | loss: 0.04456 - acc: 0.9986 -- iter: 064/119
[A[ATraining Step: 27  | total loss: [1m[32m0.04080[0m[0m | time: 25.474s
[2K
| Adam | epoch: 007 | loss: 0.04080 - acc: 0.9990 -- iter: 096/119
[A[ATraining Step: 28  | total loss: [1m[32m0.03477[0m[0m | time: 52.354s
[2K
| Adam | epoch: 007 | loss: 0.03477 - acc: 0.9992 | val_loss: 0.77585 - val_acc: 0.5000 -- iter: 119/119
--
Training Step: 29  | total loss: [1m[32m0.03092[0m[0m | time: 7.250s
[2K
| Adam | epoch: 008 | loss: 0.03092 - acc: 0.9994 -- iter: 032/119
[A[ATraining Step: 30  | total loss: [1m[32m0.02578[0m[0m | time: 14.481s
[2K
| Adam | epoch: 008 | loss: 0.02578 - acc: 0.9996 -- iter: 064/119
[A[ATraining Step: 31  | total loss: [1m[32m0.02148[0m[0m | time: 23.613s
[2K
| Adam | epoch: 008 | loss: 0.02148 - acc: 0.9997 -- iter: 096/119
[A[ATraining Step: 32  | total loss: [1m[32m0.01826[0m[0m | time: 34.678s
[2K
| Adam | epoch: 008 | loss: 0.01826 - acc: 0.9997 | val_loss: 1.09597 - val_acc: 0.5789 -- iter: 119/119
--
Training Step: 33  | total loss: [1m[32m0.05583[0m[0m | time: 9.464s
[2K
| Adam | epoch: 009 | loss: 0.05583 - acc: 0.9929 -- iter: 032/119
[A[ATraining Step: 34  | total loss: [1m[32m0.04454[0m[0m | time: 16.189s
[2K
| Adam | epoch: 009 | loss: 0.04454 - acc: 0.9944 -- iter: 064/119
[A[ATraining Step: 35  | total loss: [1m[32m0.03704[0m[0m | time: 23.513s
[2K
| Adam | epoch: 009 | loss: 0.03704 - acc: 0.9956 -- iter: 096/119
[A[ATraining Step: 36  | total loss: [1m[32m0.03168[0m[0m | time: 35.587s
[2K
| Adam | epoch: 009 | loss: 0.03168 - acc: 0.9965 | val_loss: 1.68020 - val_acc: 0.5789 -- iter: 119/119
--
Training Step: 37  | total loss: [1m[32m0.02590[0m[0m | time: 9.600s
[2K
| Adam | epoch: 010 | loss: 0.02590 - acc: 0.9972 -- iter: 032/119
[A[ATraining Step: 38  | total loss: [1m[32m0.39515[0m[0m | time: 18.755s
[2K
| Adam | epoch: 010 | loss: 0.39515 - acc: 0.9427 -- iter: 064/119
[A[ATraining Step: 39  | total loss: [1m[32m0.32051[0m[0m | time: 25.741s
[2K
| Adam | epoch: 010 | loss: 0.32051 - acc: 0.9537 -- iter: 096/119
[A[ATraining Step: 40  | total loss: [1m[32m0.28018[0m[0m | time: 35.229s
[2K
| Adam | epoch: 010 | loss: 0.28018 - acc: 0.9542 | val_loss: 2.13311 - val_acc: 0.5789 -- iter: 119/119
--
Training Step: 41  | total loss: [1m[32m0.23393[0m[0m | time: 9.443s
[2K
| Adam | epoch: 011 | loss: 0.23393 - acc: 0.9626 -- iter: 032/119
[A[ATraining Step: 42  | total loss: [1m[32m0.19323[0m[0m | time: 18.654s
[2K
| Adam | epoch: 011 | loss: 0.19323 - acc: 0.9694 -- iter: 064/119
[A[ATraining Step: 43  | total loss: [1m[32m0.27493[0m[0m | time: 27.698s
[2K
| Adam | epoch: 011 | loss: 0.27493 - acc: 0.9527 -- iter: 096/119
[A[ATraining Step: 44  | total loss: [1m[32m0.22944[0m[0m | time: 36.620s
[2K
| Adam | epoch: 011 | loss: 0.22944 - acc: 0.9609 | val_loss: 1.49711 - val_acc: 0.5789 -- iter: 119/119
--
Training Step: 45  | total loss: [1m[32m0.19298[0m[0m | time: 7.331s
[2K
| Adam | epoch: 012 | loss: 0.19298 - acc: 0.9675 -- iter: 032/119
[A[ATraining Step: 46  | total loss: [1m[32m0.16295[0m[0m | time: 16.471s
[2K
| Adam | epoch: 012 | loss: 0.16295 - acc: 0.9729 -- iter: 064/119
[A[ATraining Step: 47  | total loss: [1m[32m0.14903[0m[0m | time: 25.822s
[2K
| Adam | epoch: 012 | loss: 0.14903 - acc: 0.9671 -- iter: 096/119
[A[ATraining Step: 48  | total loss: [1m[32m0.12719[0m[0m | time: 41.743s
[2K
| Adam | epoch: 012 | loss: 0.12719 - acc: 0.9724 | val_loss: 1.04673 - val_acc: 0.6053 -- iter: 119/119
--
Training Step: 49  | total loss: [1m[32m0.11331[0m[0m | time: 7.179s
[2K
| Adam | epoch: 013 | loss: 0.11331 - acc: 0.9718 -- iter: 032/119
[A[ATraining Step: 50  | total loss: [1m[32m0.09784[0m[0m | time: 14.294s
[2K
| Adam | epoch: 013 | loss: 0.09784 - acc: 0.9762 -- iter: 064/119
[A[ATraining Step: 51  | total loss: [1m[32m0.08509[0m[0m | time: 23.561s
[2K
| Adam | epoch: 013 | loss: 0.08509 - acc: 0.9798 -- iter: 096/119
[A[ATraining Step: 52  | total loss: [1m[32m0.09196[0m[0m | time: 34.894s
[2K
| Adam | epoch: 013 | loss: 0.09196 - acc: 0.9782 | val_loss: 0.97231 - val_acc: 0.6579 -- iter: 119/119
--
Training Step: 53  | total loss: [1m[32m0.11245[0m[0m | time: 9.589s
[2K
| Adam | epoch: 014 | loss: 0.11245 - acc: 0.9768 -- iter: 032/119
[A[ATraining Step: 54  | total loss: [1m[32m0.09839[0m[0m | time: 16.627s
[2K
| Adam | epoch: 014 | loss: 0.09839 - acc: 0.9802 -- iter: 064/119
[A[ATraining Step: 55  | total loss: [1m[32m0.08830[0m[0m | time: 23.531s
[2K
| Adam | epoch: 014 | loss: 0.08830 - acc: 0.9830 -- iter: 096/119
[A[ATraining Step: 56  | total loss: [1m[32m0.08079[0m[0m | time: 34.387s
[2K
| Adam | epoch: 014 | loss: 0.08079 - acc: 0.9854 | val_loss: 0.74485 - val_acc: 0.6842 -- iter: 119/119
--
Training Step: 57  | total loss: [1m[32m0.07242[0m[0m | time: 10.220s
[2K
| Adam | epoch: 015 | loss: 0.07242 - acc: 0.9874 -- iter: 032/119
[A[ATraining Step: 58  | total loss: [1m[32m0.10374[0m[0m | time: 19.282s
[2K
| Adam | epoch: 015 | loss: 0.10374 - acc: 0.9849 -- iter: 064/119
[A[ATraining Step: 59  | total loss: [1m[32m0.09152[0m[0m | time: 26.426s
[2K
| Adam | epoch: 015 | loss: 0.09152 - acc: 0.9869 -- iter: 096/119
[A[ATraining Step: 60  | total loss: [1m[32m0.08073[0m[0m | time: 35.048s
[2K
| Adam | epoch: 015 | loss: 0.08073 - acc: 0.9886 | val_loss: 1.16078 - val_acc: 0.6053 -- iter: 119/119
--
Training Step: 61  | total loss: [1m[32m0.07173[0m[0m | time: 9.307s
[2K
| Adam | epoch: 016 | loss: 0.07173 - acc: 0.9901 -- iter: 032/119
[A[ATraining Step: 62  | total loss: [1m[32m0.06485[0m[0m | time: 18.782s
[2K
| Adam | epoch: 016 | loss: 0.06485 - acc: 0.9914 -- iter: 064/119
[A[ATraining Step: 63  | total loss: [1m[32m0.05864[0m[0m | time: 28.006s
[2K
| Adam | epoch: 016 | loss: 0.05864 - acc: 0.9925 -- iter: 096/119
[A[ATraining Step: 64  | total loss: [1m[32m0.05249[0m[0m | time: 36.869s
[2K
| Adam | epoch: 016 | loss: 0.05249 - acc: 0.9934 | val_loss: 0.81761 - val_acc: 0.6053 -- iter: 119/119
--
Training Step: 65  | total loss: [1m[32m0.04870[0m[0m | time: 7.043s
[2K
| Adam | epoch: 017 | loss: 0.04870 - acc: 0.9942 -- iter: 032/119
[A[ATraining Step: 66  | total loss: [1m[32m0.04434[0m[0m | time: 16.638s
[2K
| Adam | epoch: 017 | loss: 0.04434 - acc: 0.9949 -- iter: 064/119
[A[ATraining Step: 67  | total loss: [1m[32m0.04047[0m[0m | time: 25.868s
[2K
| Adam | epoch: 017 | loss: 0.04047 - acc: 0.9955 -- iter: 096/119
[A[ATraining Step: 68  | total loss: [1m[32m0.03665[0m[0m | time: 37.401s
[2K
| Adam | epoch: 017 | loss: 0.03665 - acc: 0.9961 | val_loss: 0.70245 - val_acc: 0.6842 -- iter: 119/119
--
Training Step: 69  | total loss: [1m[32m0.03366[0m[0m | time: 7.280s
[2K
| Adam | epoch: 018 | loss: 0.03366 - acc: 0.9965 -- iter: 032/119
[A[ATraining Step: 70  | total loss: [1m[32m0.03031[0m[0m | time: 14.764s
[2K
| Adam | epoch: 018 | loss: 0.03031 - acc: 0.9969 -- iter: 064/119
[A[ATraining Step: 71  | total loss: [1m[32m0.02739[0m[0m | time: 24.312s
[2K
| Adam | epoch: 018 | loss: 0.02739 - acc: 0.9973 -- iter: 096/119
[A[ATraining Step: 72  | total loss: [1m[32m0.02477[0m[0m | time: 35.382s
[2K
| Adam | epoch: 018 | loss: 0.02477 - acc: 0.9976 | val_loss: 0.79688 - val_acc: 0.6316 -- iter: 119/119
--
Training Step: 73  | total loss: [1m[32m0.02261[0m[0m | time: 9.037s
[2K
| Adam | epoch: 019 | loss: 0.02261 - acc: 0.9979 -- iter: 032/119
[A[ATraining Step: 74  | total loss: [1m[32m0.02045[0m[0m | time: 15.941s
[2K
| Adam | epoch: 019 | loss: 0.02045 - acc: 0.9981 -- iter: 064/119
[A[ATraining Step: 75  | total loss: [1m[32m0.01857[0m[0m | time: 23.247s
[2K
| Adam | epoch: 019 | loss: 0.01857 - acc: 0.9983 -- iter: 096/119
[A[ATraining Step: 76  | total loss: [1m[32m0.01690[0m[0m | time: 34.638s
[2K
| Adam | epoch: 019 | loss: 0.01690 - acc: 0.9985 | val_loss: 0.79410 - val_acc: 0.6579 -- iter: 119/119
--
Training Step: 77  | total loss: [1m[32m0.01536[0m[0m | time: 9.564s
[2K
| Adam | epoch: 020 | loss: 0.01536 - acc: 0.9986 -- iter: 032/119
[A[ATraining Step: 78  | total loss: [1m[32m0.03651[0m[0m | time: 19.283s
[2K
| Adam | epoch: 020 | loss: 0.03651 - acc: 0.9955 -- iter: 064/119
[A[ATraining Step: 79  | total loss: [1m[32m0.03304[0m[0m | time: 26.363s
[2K
| Adam | epoch: 020 | loss: 0.03304 - acc: 0.9960 -- iter: 096/119
[A[ATraining Step: 80  | total loss: [1m[32m0.04526[0m[0m | time: 37.321s
[2K
| Adam | epoch: 020 | loss: 0.04526 - acc: 0.9919 | val_loss: 1.15240 - val_acc: 0.5789 -- iter: 119/119
--
Training Step: 81  | total loss: [1m[32m0.04640[0m[0m | time: 18.478s
[2K
| Adam | epoch: 021 | loss: 0.04640 - acc: 0.9884 -- iter: 032/119
[A[ATraining Step: 82  | total loss: [1m[32m0.04243[0m[0m | time: 30.796s
[2K
| Adam | epoch: 021 | loss: 0.04243 - acc: 0.9895 -- iter: 064/119
[A[ATraining Step: 83  | total loss: [1m[32m0.04694[0m[0m | time: 41.931s
[2K
| Adam | epoch: 021 | loss: 0.04694 - acc: 0.9874 -- iter: 096/119
[A[ATraining Step: 84  | total loss: [1m[32m0.04342[0m[0m | time: 52.708s
[2K
| Adam | epoch: 021 | loss: 0.04342 - acc: 0.9887 | val_loss: 2.82318 - val_acc: 0.5526 -- iter: 119/119
--
Training Step: 85  | total loss: [1m[32m0.04022[0m[0m | time: 9.210s
[2K
| Adam | epoch: 022 | loss: 0.04022 - acc: 0.9898 -- iter: 032/119
[A[ATraining Step: 86  | total loss: [1m[32m0.03706[0m[0m | time: 18.901s
[2K
| Adam | epoch: 022 | loss: 0.03706 - acc: 0.9908 -- iter: 064/119
[A[ATraining Step: 87  | total loss: [1m[32m0.05993[0m[0m | time: 29.935s
[2K
| Adam | epoch: 022 | loss: 0.05993 - acc: 0.9886 -- iter: 096/119
[A[ATraining Step: 88  | total loss: [1m[32m0.08599[0m[0m | time: 43.717s
[2K
| Adam | epoch: 022 | loss: 0.08599 - acc: 0.9835 | val_loss: 2.23454 - val_acc: 0.5789 -- iter: 119/119
--
Training Step: 89  | total loss: [1m[32m0.09293[0m[0m | time: 7.820s
[2K
| Adam | epoch: 023 | loss: 0.09293 - acc: 0.9820 -- iter: 032/119
[A[ATraining Step: 90  | total loss: [1m[32m0.08510[0m[0m | time: 16.298s
[2K
| Adam | epoch: 023 | loss: 0.08510 - acc: 0.9838 -- iter: 064/119
[A[ATraining Step: 91  | total loss: [1m[32m0.07752[0m[0m | time: 35.828s
[2K
| Adam | epoch: 023 | loss: 0.07752 - acc: 0.9855 -- iter: 096/119
[A[ATraining Step: 92  | total loss: [1m[32m0.07431[0m[0m | time: 47.171s
[2K
| Adam | epoch: 023 | loss: 0.07431 - acc: 0.9838 | val_loss: 0.76491 - val_acc: 0.5789 -- iter: 119/119
--
Training Step: 93  | total loss: [1m[32m0.09489[0m[0m | time: 9.143s
[2K
| Adam | epoch: 024 | loss: 0.09489 - acc: 0.9792 -- iter: 032/119
[A[ATraining Step: 94  | total loss: [1m[32m0.08731[0m[0m | time: 16.446s
[2K
| Adam | epoch: 024 | loss: 0.08731 - acc: 0.9812 -- iter: 064/119
[A[ATraining Step: 95  | total loss: [1m[32m0.08194[0m[0m | time: 23.672s
[2K
| Adam | epoch: 024 | loss: 0.08194 - acc: 0.9831 -- iter: 096/119
[A[ATraining Step: 96  | total loss: [1m[32m0.07639[0m[0m | time: 34.784s
[2K
| Adam | epoch: 024 | loss: 0.07639 - acc: 0.9848 | val_loss: 0.98828 - val_acc: 0.5526 -- iter: 119/119
--
Training Step: 97  | total loss: [1m[32m0.07156[0m[0m | time: 9.105s
[2K
| Adam | epoch: 025 | loss: 0.07156 - acc: 0.9863 -- iter: 032/119
[A[ATraining Step: 98  | total loss: [1m[32m0.08795[0m[0m | time: 18.398s
[2K
| Adam | epoch: 025 | loss: 0.08795 - acc: 0.9846 -- iter: 064/119
[A[ATraining Step: 99  | total loss: [1m[32m0.08931[0m[0m | time: 25.300s
[2K
| Adam | epoch: 025 | loss: 0.08931 - acc: 0.9830 -- iter: 096/119
[A[ATraining Step: 100  | total loss: [1m[32m0.08976[0m[0m | time: 34.036s
[2K
| Adam | epoch: 025 | loss: 0.08976 - acc: 0.9803 | val_loss: 0.76876 - val_acc: 0.6053 -- iter: 119/119
--
Training Step: 101  | total loss: [1m[32m0.08630[0m[0m | time: 9.462s
[2K
| Adam | epoch: 026 | loss: 0.08630 - acc: 0.9780 -- iter: 032/119
[A[ATraining Step: 102  | total loss: [1m[32m0.07986[0m[0m | time: 18.383s
[2K
| Adam | epoch: 026 | loss: 0.07986 - acc: 0.9802 -- iter: 064/119
[A[ATraining Step: 103  | total loss: [1m[32m0.09969[0m[0m | time: 29.343s
[2K
| Adam | epoch: 026 | loss: 0.09969 - acc: 0.9759 -- iter: 096/119
[A[ATraining Step: 104  | total loss: [1m[32m0.09159[0m[0m | time: 38.422s
[2K
| Adam | epoch: 026 | loss: 0.09159 - acc: 0.9783 | val_loss: 0.64932 - val_acc: 0.6316 -- iter: 119/119
--
Training Step: 105  | total loss: [1m[32m0.08490[0m[0m | time: 7.096s
[2K
| Adam | epoch: 027 | loss: 0.08490 - acc: 0.9805 -- iter: 032/119
[A[ATraining Step: 106  | total loss: [1m[32m0.07822[0m[0m | time: 16.357s
[2K
| Adam | epoch: 027 | loss: 0.07822 - acc: 0.9824 -- iter: 064/119
[A[ATraining Step: 107  | total loss: [1m[32m0.07770[0m[0m | time: 25.752s
[2K
| Adam | epoch: 027 | loss: 0.07770 - acc: 0.9811 -- iter: 096/119
[A[ATraining Step: 108  | total loss: [1m[32m0.08261[0m[0m | time: 36.760s
[2K
| Adam | epoch: 027 | loss: 0.08261 - acc: 0.9798 | val_loss: 2.13260 - val_acc: 0.5789 -- iter: 119/119
--
Training Step: 109  | total loss: [1m[32m0.07714[0m[0m | time: 7.137s
[2K
| Adam | epoch: 028 | loss: 0.07714 - acc: 0.9818 -- iter: 032/119
[A[ATraining Step: 110  | total loss: [1m[32m0.07051[0m[0m | time: 13.996s
[2K
| Adam | epoch: 028 | loss: 0.07051 - acc: 0.9837 -- iter: 064/119
[A[ATraining Step: 111  | total loss: [1m[32m0.06458[0m[0m | time: 23.204s
[2K
| Adam | epoch: 028 | loss: 0.06458 - acc: 0.9853 -- iter: 096/119
[A[ATraining Step: 112  | total loss: [1m[32m0.08112[0m[0m | time: 34.666s
[2K
| Adam | epoch: 028 | loss: 0.08112 - acc: 0.9836 | val_loss: 2.26070 - val_acc: 0.5526 -- iter: 119/119
--
Training Step: 113  | total loss: [1m[32m0.09108[0m[0m | time: 10.401s
[2K
| Adam | epoch: 029 | loss: 0.09108 - acc: 0.9790 -- iter: 032/119
[A[ATraining Step: 114  | total loss: [1m[32m0.08289[0m[0m | time: 17.298s
[2K
| Adam | epoch: 029 | loss: 0.08289 - acc: 0.9811 -- iter: 064/119
[A[ATraining Step: 115  | total loss: [1m[32m0.07539[0m[0m | time: 24.520s
[2K
| Adam | epoch: 029 | loss: 0.07539 - acc: 0.9830 -- iter: 096/119
[A[ATraining Step: 116  | total loss: [1m[32m0.06846[0m[0m | time: 35.525s
[2K
| Adam | epoch: 029 | loss: 0.06846 - acc: 0.9847 | val_loss: 1.24046 - val_acc: 0.6053 -- iter: 119/119
--
Training Step: 117  | total loss: [1m[32m0.06309[0m[0m | time: 9.065s
[2K
| Adam | epoch: 030 | loss: 0.06309 - acc: 0.9862 -- iter: 032/119
[A[ATraining Step: 118  | total loss: [1m[32m0.07837[0m[0m | time: 19.753s
[2K
| Adam | epoch: 030 | loss: 0.07837 - acc: 0.9845 -- iter: 064/119
[A[ATraining Step: 119  | total loss: [1m[32m0.07345[0m[0m | time: 26.980s
[2K
| Adam | epoch: 030 | loss: 0.07345 - acc: 0.9860 -- iter: 096/119
[A[ATraining Step: 120  | total loss: [1m[32m0.06744[0m[0m | time: 36.110s
[2K
| Adam | epoch: 030 | loss: 0.06744 - acc: 0.9874 | val_loss: 1.21813 - val_acc: 0.6053 -- iter: 119/119
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7073863636363636
Validation AUPRC:0.6116609749787163
Test AUC:0.8111111111111111
Test AUPRC:0.7952506397875336
BestTestF1Score	0.8	0.6	0.79	0.73	0.89	16	6	14	2	0.75
BestTestMCCScore	0.8	0.6	0.79	0.73	0.89	16	6	14	2	0.75
BestTestAccuracyScore	0.63	0.37	0.68	0.71	0.56	10	4	16	8	0.89
BestValidationF1Score	0.73	0.5	0.71	0.6	0.94	15	10	12	1	0.75
BestValidationMCC	0.73	0.5	0.71	0.6	0.94	15	10	12	1	0.75
BestValidationAccuracy	0.67	0.41	0.71	0.65	0.69	11	6	16	5	0.89
TestPredictions (Threshold:0.75)
CHEMBL3775516,TP,ACT,1.0	CHEMBL1995684,TN,INACT,0.699999988079071	CHEMBL148680,FP,INACT,0.9200000166893005	CHEMBL1598,TN,INACT,0.46000000834465027	CHEMBL103182,TN,INACT,0.3100000023841858	CHEMBL385073,TN,INACT,0.36000001430511475	CHEMBL374829,TN,INACT,0.019999999552965164	CHEMBL3786188,TP,ACT,0.9100000262260437	CHEMBL3775823,TP,ACT,1.0	CHEMBL3775802,TP,ACT,0.7900000214576721	CHEMBL3138159,FP,INACT,0.8799999952316284	CHEMBL3774701,TP,ACT,1.0	CHEMBL1255023,FP,INACT,0.9900000095367432	CHEMBL321586,TN,INACT,0.33000001311302185	CHEMBL3771180,TP,ACT,1.0	CHEMBL1435274,TP,ACT,0.7900000214576721	CHEMBL3137798,TN,INACT,0.5199999809265137	CHEMBL3634948,TP,ACT,0.8600000143051147	CHEMBL6648,TN,INACT,0.2199999988079071	CHEMBL1215519,TP,ACT,0.9900000095367432	CHEMBL3634935,FN,ACT,0.3400000035762787	CHEMBL3634950,FN,ACT,0.5699999928474426	CHEMBL2424809,FP,INACT,0.9900000095367432	CHEMBL1957185,TN,INACT,0.6200000047683716	CHEMBL308819,TN,INACT,0.25	CHEMBL3785421,TP,ACT,0.8500000238418579	CHEMBL1615211,TN,INACT,0.07000000029802322	CHEMBL6852,TN,INACT,0.7400000095367432	CHEMBL1576395,TN,INACT,0.20999999344348907	CHEMBL3621870,TP,ACT,0.9900000095367432	CHEMBL1984581,TP,ACT,0.8100000023841858	CHEMBL3775899,TP,ACT,1.0	CHEMBL1566909,TP,ACT,0.75	CHEMBL1966136,TP,ACT,0.9200000166893005	CHEMBL235501,TN,INACT,0.11999999731779099	CHEMBL2424811,FP,INACT,0.9800000190734863	CHEMBL3775145,TP,ACT,0.9800000190734863	CHEMBL3138176,FP,INACT,0.8399999737739563	

