ImageNetInceptionV2 CHEMBL2439 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	135
Number of inactive compounds :	135
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2439_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2439_adam_0.0005_15_0.6/
---------------------------------
Training samples: 150
Validation samples: 47
--
Training Step: 1  | time: 39.743s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/150
[A[ATraining Step: 2  | total loss: [1m[32m0.60339[0m[0m | time: 48.305s
[2K
| Adam | epoch: 001 | loss: 0.60339 - acc: 0.5344 -- iter: 064/150
[A[ATraining Step: 3  | total loss: [1m[32m0.49533[0m[0m | time: 56.873s
[2K
| Adam | epoch: 001 | loss: 0.49533 - acc: 0.7619 -- iter: 096/150
[A[ATraining Step: 4  | total loss: [1m[32m0.45423[0m[0m | time: 65.363s
[2K
| Adam | epoch: 001 | loss: 0.45423 - acc: 0.8233 -- iter: 128/150
[A[ATraining Step: 5  | total loss: [1m[32m0.61671[0m[0m | time: 79.368s
[2K
| Adam | epoch: 001 | loss: 0.61671 - acc: 0.7509 | val_loss: 1.26362 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 6  | total loss: [1m[32m0.62664[0m[0m | time: 5.905s
[2K
| Adam | epoch: 002 | loss: 0.62664 - acc: 0.7357 -- iter: 032/150
[A[ATraining Step: 7  | total loss: [1m[32m0.41696[0m[0m | time: 14.681s
[2K
| Adam | epoch: 002 | loss: 0.41696 - acc: 0.8397 -- iter: 064/150
[A[ATraining Step: 8  | total loss: [1m[32m0.41676[0m[0m | time: 23.242s
[2K
| Adam | epoch: 002 | loss: 0.41676 - acc: 0.8244 -- iter: 096/150
[A[ATraining Step: 9  | total loss: [1m[32m0.38773[0m[0m | time: 31.712s
[2K
| Adam | epoch: 002 | loss: 0.38773 - acc: 0.8347 -- iter: 128/150
[A[ATraining Step: 10  | total loss: [1m[32m0.28318[0m[0m | time: 42.504s
[2K
| Adam | epoch: 002 | loss: 0.28318 - acc: 0.8705 | val_loss: 2.80778 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 11  | total loss: [1m[32m0.31273[0m[0m | time: 7.472s
[2K
| Adam | epoch: 003 | loss: 0.31273 - acc: 0.8726 -- iter: 032/150
[A[ATraining Step: 12  | total loss: [1m[32m0.29239[0m[0m | time: 14.925s
[2K
| Adam | epoch: 003 | loss: 0.29239 - acc: 0.8890 -- iter: 064/150
[A[ATraining Step: 13  | total loss: [1m[32m0.20493[0m[0m | time: 24.638s
[2K
| Adam | epoch: 003 | loss: 0.20493 - acc: 0.9366 -- iter: 096/150
[A[ATraining Step: 14  | total loss: [1m[32m0.19934[0m[0m | time: 34.704s
[2K
| Adam | epoch: 003 | loss: 0.19934 - acc: 0.9497 -- iter: 128/150
[A[ATraining Step: 15  | total loss: [1m[32m0.30131[0m[0m | time: 47.642s
[2K
| Adam | epoch: 003 | loss: 0.30131 - acc: 0.9205 | val_loss: 1.45128 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 16  | total loss: [1m[32m0.24653[0m[0m | time: 10.835s
[2K
| Adam | epoch: 004 | loss: 0.24653 - acc: 0.9386 -- iter: 032/150
[A[ATraining Step: 17  | total loss: [1m[32m0.21021[0m[0m | time: 18.077s
[2K
| Adam | epoch: 004 | loss: 0.21021 - acc: 0.9494 -- iter: 064/150
[A[ATraining Step: 18  | total loss: [1m[32m0.15457[0m[0m | time: 25.515s
[2K
| Adam | epoch: 004 | loss: 0.15457 - acc: 0.9669 -- iter: 096/150
[A[ATraining Step: 19  | total loss: [1m[32m0.10924[0m[0m | time: 35.900s
[2K
| Adam | epoch: 004 | loss: 0.10924 - acc: 0.9780 -- iter: 128/150
[A[ATraining Step: 20  | total loss: [1m[32m0.13987[0m[0m | time: 48.801s
[2K
| Adam | epoch: 004 | loss: 0.13987 - acc: 0.9549 | val_loss: 0.75967 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 21  | total loss: [1m[32m0.20655[0m[0m | time: 10.696s
[2K
| Adam | epoch: 005 | loss: 0.20655 - acc: 0.9398 -- iter: 032/150
[A[ATraining Step: 22  | total loss: [1m[32m0.16677[0m[0m | time: 20.606s
[2K
| Adam | epoch: 005 | loss: 0.16677 - acc: 0.9485 -- iter: 064/150
[A[ATraining Step: 23  | total loss: [1m[32m0.13537[0m[0m | time: 27.963s
[2K
| Adam | epoch: 005 | loss: 0.13537 - acc: 0.9544 -- iter: 096/150
[A[ATraining Step: 24  | total loss: [1m[32m0.11697[0m[0m | time: 35.695s
[2K
| Adam | epoch: 005 | loss: 0.11697 - acc: 0.9672 -- iter: 128/150
[A[ATraining Step: 25  | total loss: [1m[32m0.09378[0m[0m | time: 48.234s
[2K
| Adam | epoch: 005 | loss: 0.09378 - acc: 0.9761 | val_loss: 0.93522 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 26  | total loss: [1m[32m0.08465[0m[0m | time: 10.675s
[2K
| Adam | epoch: 006 | loss: 0.08465 - acc: 0.9742 -- iter: 032/150
[A[ATraining Step: 27  | total loss: [1m[32m0.12727[0m[0m | time: 20.571s
[2K
| Adam | epoch: 006 | loss: 0.12727 - acc: 0.9567 -- iter: 064/150
[A[ATraining Step: 28  | total loss: [1m[32m0.16298[0m[0m | time: 30.505s
[2K
| Adam | epoch: 006 | loss: 0.16298 - acc: 0.9597 -- iter: 096/150
[A[ATraining Step: 29  | total loss: [1m[32m0.12712[0m[0m | time: 38.612s
[2K
| Adam | epoch: 006 | loss: 0.12712 - acc: 0.9695 -- iter: 128/150
[A[ATraining Step: 30  | total loss: [1m[32m0.10200[0m[0m | time: 48.448s
[2K
| Adam | epoch: 006 | loss: 0.10200 - acc: 0.9767 | val_loss: 1.51020 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 31  | total loss: [1m[32m0.08250[0m[0m | time: 10.773s
[2K
| Adam | epoch: 007 | loss: 0.08250 - acc: 0.9821 -- iter: 032/150
[A[ATraining Step: 32  | total loss: [1m[32m0.07595[0m[0m | time: 21.003s
[2K
| Adam | epoch: 007 | loss: 0.07595 - acc: 0.9791 -- iter: 064/150
[A[ATraining Step: 33  | total loss: [1m[32m0.07353[0m[0m | time: 31.023s
[2K
| Adam | epoch: 007 | loss: 0.07353 - acc: 0.9837 -- iter: 096/150
[A[ATraining Step: 34  | total loss: [1m[32m0.06332[0m[0m | time: 41.498s
[2K
| Adam | epoch: 007 | loss: 0.06332 - acc: 0.9872 -- iter: 128/150
[A[ATraining Step: 35  | total loss: [1m[32m0.05655[0m[0m | time: 51.641s
[2K
| Adam | epoch: 007 | loss: 0.05655 - acc: 0.9899 | val_loss: 1.51799 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 36  | total loss: [1m[32m0.04814[0m[0m | time: 8.225s
[2K
| Adam | epoch: 008 | loss: 0.04814 - acc: 0.9919 -- iter: 032/150
[A[ATraining Step: 37  | total loss: [1m[32m0.04018[0m[0m | time: 18.260s
[2K
| Adam | epoch: 008 | loss: 0.04018 - acc: 0.9936 -- iter: 064/150
[A[ATraining Step: 38  | total loss: [1m[32m0.03454[0m[0m | time: 26.921s
[2K
| Adam | epoch: 008 | loss: 0.03454 - acc: 0.9948 -- iter: 096/150
[A[ATraining Step: 39  | total loss: [1m[32m0.05388[0m[0m | time: 35.526s
[2K
| Adam | epoch: 008 | loss: 0.05388 - acc: 0.9898 -- iter: 128/150
[A[ATraining Step: 40  | total loss: [1m[32m0.07787[0m[0m | time: 46.307s
[2K
| Adam | epoch: 008 | loss: 0.07787 - acc: 0.9800 | val_loss: 1.98678 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 41  | total loss: [1m[32m0.08520[0m[0m | time: 6.335s
[2K
| Adam | epoch: 009 | loss: 0.08520 - acc: 0.9722 -- iter: 032/150
[A[ATraining Step: 42  | total loss: [1m[32m0.08428[0m[0m | time: 12.694s
[2K
| Adam | epoch: 009 | loss: 0.08428 - acc: 0.9690 -- iter: 064/150
[A[ATraining Step: 43  | total loss: [1m[32m0.07082[0m[0m | time: 21.329s
[2K
| Adam | epoch: 009 | loss: 0.07082 - acc: 0.9745 -- iter: 096/150
[A[ATraining Step: 44  | total loss: [1m[32m0.06125[0m[0m | time: 29.877s
[2K
| Adam | epoch: 009 | loss: 0.06125 - acc: 0.9789 -- iter: 128/150
[A[ATraining Step: 45  | total loss: [1m[32m0.06490[0m[0m | time: 40.539s
[2K
| Adam | epoch: 009 | loss: 0.06490 - acc: 0.9719 | val_loss: 4.03578 - val_acc: 0.3830 -- iter: 150/150
--
Training Step: 46  | total loss: [1m[32m0.10825[0m[0m | time: 8.585s
[2K
| Adam | epoch: 010 | loss: 0.10825 - acc: 0.9661 -- iter: 032/150
[A[ATraining Step: 47  | total loss: [1m[32m0.09357[0m[0m | time: 14.943s
[2K
| Adam | epoch: 010 | loss: 0.09357 - acc: 0.9717 -- iter: 064/150
[A[ATraining Step: 48  | total loss: [1m[32m0.08113[0m[0m | time: 21.213s
[2K
| Adam | epoch: 010 | loss: 0.08113 - acc: 0.9762 -- iter: 096/150
[A[ATraining Step: 49  | total loss: [1m[32m0.07069[0m[0m | time: 29.576s
[2K
| Adam | epoch: 010 | loss: 0.07069 - acc: 0.9800 -- iter: 128/150
[A[ATraining Step: 50  | total loss: [1m[32m0.06196[0m[0m | time: 40.273s
[2K
| Adam | epoch: 010 | loss: 0.06196 - acc: 0.9831 | val_loss: 2.89682 - val_acc: 0.4255 -- iter: 150/150
--
Training Step: 51  | total loss: [1m[32m0.06884[0m[0m | time: 8.552s
[2K
| Adam | epoch: 011 | loss: 0.06884 - acc: 0.9809 -- iter: 032/150
[A[ATraining Step: 52  | total loss: [1m[32m0.06293[0m[0m | time: 17.023s
[2K
| Adam | epoch: 011 | loss: 0.06293 - acc: 0.9838 -- iter: 064/150
[A[ATraining Step: 53  | total loss: [1m[32m0.05518[0m[0m | time: 23.353s
[2K
| Adam | epoch: 011 | loss: 0.05518 - acc: 0.9862 -- iter: 096/150
[A[ATraining Step: 54  | total loss: [1m[32m0.05118[0m[0m | time: 29.628s
[2K
| Adam | epoch: 011 | loss: 0.05118 - acc: 0.9882 -- iter: 128/150
[A[ATraining Step: 55  | total loss: [1m[32m0.04523[0m[0m | time: 40.542s
[2K
| Adam | epoch: 011 | loss: 0.04523 - acc: 0.9899 | val_loss: 0.72563 - val_acc: 0.8298 -- iter: 150/150
--
Training Step: 56  | total loss: [1m[32m0.03973[0m[0m | time: 8.679s
[2K
| Adam | epoch: 012 | loss: 0.03973 - acc: 0.9913 -- iter: 032/150
[A[ATraining Step: 57  | total loss: [1m[32m0.05209[0m[0m | time: 17.036s
[2K
| Adam | epoch: 012 | loss: 0.05209 - acc: 0.9882 -- iter: 064/150
[A[ATraining Step: 58  | total loss: [1m[32m0.08937[0m[0m | time: 25.579s
[2K
| Adam | epoch: 012 | loss: 0.08937 - acc: 0.9855 -- iter: 096/150
[A[ATraining Step: 59  | total loss: [1m[32m0.07802[0m[0m | time: 31.753s
[2K
| Adam | epoch: 012 | loss: 0.07802 - acc: 0.9875 -- iter: 128/150
[A[ATraining Step: 60  | total loss: [1m[32m0.11794[0m[0m | time: 40.047s
[2K
| Adam | epoch: 012 | loss: 0.11794 - acc: 0.9711 | val_loss: 0.63906 - val_acc: 0.8936 -- iter: 150/150
--
Training Step: 61  | total loss: [1m[32m0.12526[0m[0m | time: 8.598s
[2K
| Adam | epoch: 013 | loss: 0.12526 - acc: 0.9689 -- iter: 032/150
[A[ATraining Step: 62  | total loss: [1m[32m0.12654[0m[0m | time: 17.047s
[2K
| Adam | epoch: 013 | loss: 0.12654 - acc: 0.9689 -- iter: 064/150
[A[ATraining Step: 63  | total loss: [1m[32m0.12876[0m[0m | time: 25.530s
[2K
| Adam | epoch: 013 | loss: 0.12876 - acc: 0.9649 -- iter: 096/150
[A[ATraining Step: 64  | total loss: [1m[32m0.15402[0m[0m | time: 33.999s
[2K
| Adam | epoch: 013 | loss: 0.15402 - acc: 0.9615 -- iter: 128/150
[A[ATraining Step: 65  | total loss: [1m[32m0.15143[0m[0m | time: 42.254s
[2K
| Adam | epoch: 013 | loss: 0.15143 - acc: 0.9624 | val_loss: 0.57503 - val_acc: 0.8723 -- iter: 150/150
--
Training Step: 66  | total loss: [1m[32m0.13685[0m[0m | time: 6.287s
[2K
| Adam | epoch: 014 | loss: 0.13685 - acc: 0.9670 -- iter: 032/150
[A[ATraining Step: 67  | total loss: [1m[32m0.12189[0m[0m | time: 14.832s
[2K
| Adam | epoch: 014 | loss: 0.12189 - acc: 0.9709 -- iter: 064/150
[A[ATraining Step: 68  | total loss: [1m[32m0.11920[0m[0m | time: 23.590s
[2K
| Adam | epoch: 014 | loss: 0.11920 - acc: 0.9670 -- iter: 096/150
[A[ATraining Step: 69  | total loss: [1m[32m0.13892[0m[0m | time: 32.248s
[2K
| Adam | epoch: 014 | loss: 0.13892 - acc: 0.9672 -- iter: 128/150
[A[ATraining Step: 70  | total loss: [1m[32m0.14588[0m[0m | time: 43.187s
[2K
| Adam | epoch: 014 | loss: 0.14588 - acc: 0.9674 | val_loss: 0.94589 - val_acc: 0.7447 -- iter: 150/150
--
Training Step: 71  | total loss: [1m[32m0.15025[0m[0m | time: 6.409s
[2K
| Adam | epoch: 015 | loss: 0.15025 - acc: 0.9640 -- iter: 032/150
[A[ATraining Step: 72  | total loss: [1m[32m0.15848[0m[0m | time: 12.515s
[2K
| Adam | epoch: 015 | loss: 0.15848 - acc: 0.9578 -- iter: 064/150
[A[ATraining Step: 73  | total loss: [1m[32m0.14840[0m[0m | time: 21.010s
[2K
| Adam | epoch: 015 | loss: 0.14840 - acc: 0.9625 -- iter: 096/150
[A[ATraining Step: 74  | total loss: [1m[32m0.13629[0m[0m | time: 29.561s
[2K
| Adam | epoch: 015 | loss: 0.13629 - acc: 0.9666 -- iter: 128/150
[A[ATraining Step: 75  | total loss: [1m[32m0.12523[0m[0m | time: 40.175s
[2K
| Adam | epoch: 015 | loss: 0.12523 - acc: 0.9702 | val_loss: 0.43291 - val_acc: 0.8511 -- iter: 150/150
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9118773946360154
Validation AUPRC:0.8408767239907591
Test AUC:0.9274509803921569
Test AUPRC:0.879146948783627
BestTestF1Score	0.85	0.77	0.89	0.88	0.82	14	2	28	3	0.37
BestTestMCCScore	0.85	0.77	0.89	0.88	0.82	14	2	28	3	0.37
BestTestAccuracyScore	0.85	0.77	0.89	0.88	0.82	14	2	28	3	0.37
BestValidationF1Score	0.89	0.83	0.91	0.85	0.94	17	3	26	1	0.37
BestValidationMCC	0.89	0.83	0.91	0.85	0.94	17	3	26	1	0.37
BestValidationAccuracy	0.89	0.83	0.91	0.85	0.94	17	3	26	1	0.37
TestPredictions (Threshold:0.37)
CHEMBL1770594,TN,INACT,0.009999999776482582	CHEMBL324730,TN,INACT,0.0	CHEMBL3343349,TP,ACT,0.8600000143051147	CHEMBL2347170,TP,ACT,0.9700000286102295	CHEMBL117763,TN,INACT,0.029999999329447746	CHEMBL203489,TN,INACT,0.009999999776482582	CHEMBL1630729,TP,ACT,0.9900000095367432	CHEMBL3343330,FN,ACT,0.009999999776482582	CHEMBL1089510,TN,INACT,0.05000000074505806	CHEMBL184374,TN,INACT,0.03999999910593033	CHEMBL215872,TN,INACT,0.05000000074505806	CHEMBL3343331,TP,ACT,0.9200000166893005	CHEMBL3633249,TP,ACT,0.9700000286102295	CHEMBL7162,FP,INACT,0.9599999785423279	CHEMBL2021951,TN,INACT,0.0	CHEMBL1780082,TN,INACT,0.009999999776482582	CHEMBL1780074,TN,INACT,0.0	CHEMBL3408778,TN,INACT,0.009999999776482582	CHEMBL3739661,TP,ACT,0.6600000262260437	CHEMBL433813,TN,INACT,0.009999999776482582	CHEMBL117635,TN,INACT,0.05999999865889549	CHEMBL1885837,TP,ACT,0.9200000166893005	CHEMBL179204,TN,INACT,0.009999999776482582	CHEMBL1405583,TP,ACT,0.6499999761581421	CHEMBL1780071,TN,INACT,0.009999999776482582	CHEMBL1780075,TN,INACT,0.0	CHEMBL446332,TN,INACT,0.11999999731779099	CHEMBL2024227,TN,INACT,0.0	CHEMBL3740646,FN,ACT,0.36000001430511475	CHEMBL1780078,TN,INACT,0.009999999776482582	CHEMBL1770578,FP,INACT,0.9700000286102295	CHEMBL3144791,TP,ACT,0.800000011920929	CHEMBL2347025,TP,ACT,0.9800000190734863	CHEMBL2347166,TP,ACT,0.9900000095367432	CHEMBL3740416,FN,ACT,0.3199999928474426	CHEMBL3785696,TN,INACT,0.07000000029802322	CHEMBL3742363,TP,ACT,0.9200000166893005	CHEMBL1950245,TN,INACT,0.009999999776482582	CHEMBL118011,TN,INACT,0.0	CHEMBL26915,TN,INACT,0.009999999776482582	CHEMBL315813,TN,INACT,0.009999999776482582	CHEMBL71329,TN,INACT,0.11999999731779099	CHEMBL259241,TP,ACT,0.3799999952316284	CHEMBL84837,TN,INACT,0.009999999776482582	CHEMBL2377788,TN,INACT,0.03999999910593033	CHEMBL2413425,TN,INACT,0.019999999552965164	CHEMBL3145355,TP,ACT,0.9800000190734863	

