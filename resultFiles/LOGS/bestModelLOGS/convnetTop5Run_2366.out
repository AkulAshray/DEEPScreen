CNNModel CHEMBL1853 adam 0.0005 15 128 0 0.6 False True
Number of active compounds :	444
Number of inactive compounds :	444
---------------------------------
Run id: CNNModel_CHEMBL1853_adam_0.0005_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1853_adam_0.0005_15_128_0.6_True/
---------------------------------
Training samples: 541
Validation samples: 170
--
Training Step: 1  | time: 7.256s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/541
[A[ATraining Step: 2  | total loss: [1m[32m0.62356[0m[0m | time: 13.860s
[2K
| Adam | epoch: 001 | loss: 0.62356 - acc: 0.5906 -- iter: 064/541
[A[ATraining Step: 3  | total loss: [1m[32m0.68180[0m[0m | time: 14.835s
[2K
| Adam | epoch: 001 | loss: 0.68180 - acc: 0.4653 -- iter: 096/541
[A[ATraining Step: 4  | total loss: [1m[32m0.69042[0m[0m | time: 15.915s
[2K
| Adam | epoch: 001 | loss: 0.69042 - acc: 0.5148 -- iter: 128/541
[A[ATraining Step: 5  | total loss: [1m[32m0.69344[0m[0m | time: 16.998s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.3964 -- iter: 160/541
[A[ATraining Step: 6  | total loss: [1m[32m0.69324[0m[0m | time: 18.106s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.4228 -- iter: 192/541
[A[ATraining Step: 7  | total loss: [1m[32m0.69307[0m[0m | time: 19.274s
[2K
| Adam | epoch: 001 | loss: 0.69307 - acc: 0.5066 -- iter: 224/541
[A[ATraining Step: 8  | total loss: [1m[32m0.69301[0m[0m | time: 20.371s
[2K
| Adam | epoch: 001 | loss: 0.69301 - acc: 0.5029 -- iter: 256/541
[A[ATraining Step: 9  | total loss: [1m[32m0.69301[0m[0m | time: 21.507s
[2K
| Adam | epoch: 001 | loss: 0.69301 - acc: 0.5014 -- iter: 288/541
[A[ATraining Step: 10  | total loss: [1m[32m0.69337[0m[0m | time: 22.651s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.4538 -- iter: 320/541
[A[ATraining Step: 11  | total loss: [1m[32m0.69265[0m[0m | time: 23.688s
[2K
| Adam | epoch: 001 | loss: 0.69265 - acc: 0.5645 -- iter: 352/541
[A[ATraining Step: 12  | total loss: [1m[32m0.69262[0m[0m | time: 25.170s
[2K
| Adam | epoch: 001 | loss: 0.69262 - acc: 0.5355 -- iter: 384/541
[A[ATraining Step: 13  | total loss: [1m[32m0.69215[0m[0m | time: 26.667s
[2K
| Adam | epoch: 001 | loss: 0.69215 - acc: 0.5337 -- iter: 416/541
[A[ATraining Step: 14  | total loss: [1m[32m0.69196[0m[0m | time: 33.151s
[2K
| Adam | epoch: 001 | loss: 0.69196 - acc: 0.5327 -- iter: 448/541
[A[ATraining Step: 15  | total loss: [1m[32m0.69198[0m[0m | time: 41.479s
[2K
| Adam | epoch: 001 | loss: 0.69198 - acc: 0.5199 -- iter: 480/541
[A[ATraining Step: 16  | total loss: [1m[32m0.68969[0m[0m | time: 52.429s
[2K
| Adam | epoch: 001 | loss: 0.68969 - acc: 0.5476 -- iter: 512/541
[A[ATraining Step: 17  | total loss: [1m[32m0.69057[0m[0m | time: 69.886s
[2K
| Adam | epoch: 001 | loss: 0.69057 - acc: 0.5192 | val_loss: 0.69220 - val_acc: 0.4294 -- iter: 541/541
--
Training Step: 18  | total loss: [1m[32m0.69415[0m[0m | time: 1.092s
[2K
| Adam | epoch: 002 | loss: 0.69415 - acc: 0.4708 -- iter: 032/541
[A[ATraining Step: 19  | total loss: [1m[32m0.69491[0m[0m | time: 2.175s
[2K
| Adam | epoch: 002 | loss: 0.69491 - acc: 0.4403 -- iter: 064/541
[A[ATraining Step: 20  | total loss: [1m[32m0.69268[0m[0m | time: 3.292s
[2K
| Adam | epoch: 002 | loss: 0.69268 - acc: 0.4494 -- iter: 096/541
[A[ATraining Step: 21  | total loss: [1m[32m0.69209[0m[0m | time: 4.515s
[2K
| Adam | epoch: 002 | loss: 0.69209 - acc: 0.4554 -- iter: 128/541
[A[ATraining Step: 22  | total loss: [1m[32m0.69113[0m[0m | time: 5.898s
[2K
| Adam | epoch: 002 | loss: 0.69113 - acc: 0.5438 -- iter: 160/541
[A[ATraining Step: 23  | total loss: [1m[32m0.68923[0m[0m | time: 6.955s
[2K
| Adam | epoch: 002 | loss: 0.68923 - acc: 0.6490 -- iter: 192/541
[A[ATraining Step: 24  | total loss: [1m[32m0.68730[0m[0m | time: 8.303s
[2K
| Adam | epoch: 002 | loss: 0.68730 - acc: 0.6950 -- iter: 224/541
[A[ATraining Step: 25  | total loss: [1m[32m0.68438[0m[0m | time: 9.704s
[2K
| Adam | epoch: 002 | loss: 0.68438 - acc: 0.7270 -- iter: 256/541
[A[ATraining Step: 26  | total loss: [1m[32m0.68134[0m[0m | time: 20.826s
[2K
| Adam | epoch: 002 | loss: 0.68134 - acc: 0.7497 -- iter: 288/541
[A[ATraining Step: 27  | total loss: [1m[32m0.67718[0m[0m | time: 33.494s
[2K
| Adam | epoch: 002 | loss: 0.67718 - acc: 0.7739 -- iter: 320/541
[A[ATraining Step: 28  | total loss: [1m[32m0.67457[0m[0m | time: 42.999s
[2K
| Adam | epoch: 002 | loss: 0.67457 - acc: 0.7288 -- iter: 352/541
[A[ATraining Step: 29  | total loss: [1m[32m0.66934[0m[0m | time: 51.558s
[2K
| Adam | epoch: 002 | loss: 0.66934 - acc: 0.7416 -- iter: 384/541
[A[ATraining Step: 30  | total loss: [1m[32m0.66642[0m[0m | time: 59.101s
[2K
| Adam | epoch: 002 | loss: 0.66642 - acc: 0.7140 -- iter: 416/541
[A[ATraining Step: 31  | total loss: [1m[32m0.64893[0m[0m | time: 71.073s
[2K
| Adam | epoch: 002 | loss: 0.64893 - acc: 0.7583 -- iter: 448/541
[A[ATraining Step: 32  | total loss: [1m[32m0.62338[0m[0m | time: 80.074s
[2K
| Adam | epoch: 002 | loss: 0.62338 - acc: 0.7916 -- iter: 480/541
[A[ATraining Step: 33  | total loss: [1m[32m0.61422[0m[0m | time: 88.791s
[2K
| Adam | epoch: 002 | loss: 0.61422 - acc: 0.7756 -- iter: 512/541
[A[ATraining Step: 34  | total loss: [1m[32m0.58827[0m[0m | time: 112.208s
[2K
| Adam | epoch: 002 | loss: 0.58827 - acc: 0.7969 | val_loss: 0.59157 - val_acc: 0.6059 -- iter: 541/541
--
Training Step: 35  | total loss: [1m[32m0.57224[0m[0m | time: 1.016s
[2K
| Adam | epoch: 003 | loss: 0.57224 - acc: 0.7936 -- iter: 032/541
[A[ATraining Step: 36  | total loss: [1m[32m0.56284[0m[0m | time: 2.066s
[2K
| Adam | epoch: 003 | loss: 0.56284 - acc: 0.7583 -- iter: 064/541
[A[ATraining Step: 37  | total loss: [1m[32m0.56640[0m[0m | time: 3.161s
[2K
| Adam | epoch: 003 | loss: 0.56640 - acc: 0.7514 -- iter: 096/541
[A[ATraining Step: 38  | total loss: [1m[32m0.54312[0m[0m | time: 4.357s
[2K
| Adam | epoch: 003 | loss: 0.54312 - acc: 0.7389 -- iter: 128/541
[A[ATraining Step: 39  | total loss: [1m[32m0.52358[0m[0m | time: 5.491s
[2K
| Adam | epoch: 003 | loss: 0.52358 - acc: 0.7590 -- iter: 160/541
[A[ATraining Step: 40  | total loss: [1m[32m0.52330[0m[0m | time: 6.637s
[2K
| Adam | epoch: 003 | loss: 0.52330 - acc: 0.7632 -- iter: 192/541
[A[ATraining Step: 41  | total loss: [1m[32m0.49001[0m[0m | time: 7.809s
[2K
| Adam | epoch: 003 | loss: 0.49001 - acc: 0.7722 -- iter: 224/541
[A[ATraining Step: 42  | total loss: [1m[32m0.48558[0m[0m | time: 9.239s
[2K
| Adam | epoch: 003 | loss: 0.48558 - acc: 0.7739 -- iter: 256/541
[A[ATraining Step: 43  | total loss: [1m[32m0.48312[0m[0m | time: 10.502s
[2K
| Adam | epoch: 003 | loss: 0.48312 - acc: 0.7807 -- iter: 288/541
[A[ATraining Step: 44  | total loss: [1m[32m0.46432[0m[0m | time: 11.639s
[2K
| Adam | epoch: 003 | loss: 0.46432 - acc: 0.7862 -- iter: 320/541
[A[ATraining Step: 45  | total loss: [1m[32m0.43620[0m[0m | time: 12.646s
[2K
| Adam | epoch: 003 | loss: 0.43620 - acc: 0.8013 -- iter: 352/541
[A[ATraining Step: 46  | total loss: [1m[32m0.44209[0m[0m | time: 13.721s
[2K
| Adam | epoch: 003 | loss: 0.44209 - acc: 0.7927 -- iter: 384/541
[A[ATraining Step: 47  | total loss: [1m[32m0.43859[0m[0m | time: 14.928s
[2K
| Adam | epoch: 003 | loss: 0.43859 - acc: 0.7857 -- iter: 416/541
[A[ATraining Step: 48  | total loss: [1m[32m0.42752[0m[0m | time: 16.084s
[2K
| Adam | epoch: 003 | loss: 0.42752 - acc: 0.7900 -- iter: 448/541
[A[ATraining Step: 49  | total loss: [1m[32m0.45303[0m[0m | time: 17.179s
[2K
| Adam | epoch: 003 | loss: 0.45303 - acc: 0.7738 -- iter: 480/541
[A[ATraining Step: 50  | total loss: [1m[32m0.46789[0m[0m | time: 18.450s
[2K
| Adam | epoch: 003 | loss: 0.46789 - acc: 0.7701 -- iter: 512/541
[A[ATraining Step: 51  | total loss: [1m[32m0.52829[0m[0m | time: 20.863s
[2K
| Adam | epoch: 003 | loss: 0.52829 - acc: 0.7385 | val_loss: 0.40661 - val_acc: 0.8412 -- iter: 541/541
--
Training Step: 52  | total loss: [1m[32m0.51860[0m[0m | time: 2.050s
[2K
| Adam | epoch: 004 | loss: 0.51860 - acc: 0.7496 -- iter: 032/541
[A[ATraining Step: 53  | total loss: [1m[32m0.49593[0m[0m | time: 3.012s
[2K
| Adam | epoch: 004 | loss: 0.49593 - acc: 0.7681 -- iter: 064/541
[A[ATraining Step: 54  | total loss: [1m[32m0.48444[0m[0m | time: 4.109s
[2K
| Adam | epoch: 004 | loss: 0.48444 - acc: 0.7717 -- iter: 096/541
[A[ATraining Step: 55  | total loss: [1m[32m0.47816[0m[0m | time: 5.307s
[2K
| Adam | epoch: 004 | loss: 0.47816 - acc: 0.7698 -- iter: 128/541
[A[ATraining Step: 56  | total loss: [1m[32m0.48146[0m[0m | time: 6.339s
[2K
| Adam | epoch: 004 | loss: 0.48146 - acc: 0.7802 -- iter: 160/541
[A[ATraining Step: 57  | total loss: [1m[32m0.46487[0m[0m | time: 7.490s
[2K
| Adam | epoch: 004 | loss: 0.46487 - acc: 0.7847 -- iter: 192/541
[A[ATraining Step: 58  | total loss: [1m[32m0.45884[0m[0m | time: 8.570s
[2K
| Adam | epoch: 004 | loss: 0.45884 - acc: 0.7928 -- iter: 224/541
[A[ATraining Step: 59  | total loss: [1m[32m0.45304[0m[0m | time: 9.799s
[2K
| Adam | epoch: 004 | loss: 0.45304 - acc: 0.7996 -- iter: 256/541
[A[ATraining Step: 60  | total loss: [1m[32m0.45908[0m[0m | time: 10.961s
[2K
| Adam | epoch: 004 | loss: 0.45908 - acc: 0.7930 -- iter: 288/541
[A[ATraining Step: 61  | total loss: [1m[32m0.45534[0m[0m | time: 12.098s
[2K
| Adam | epoch: 004 | loss: 0.45534 - acc: 0.7915 -- iter: 320/541
[A[ATraining Step: 62  | total loss: [1m[32m0.45307[0m[0m | time: 13.237s
[2K
| Adam | epoch: 004 | loss: 0.45307 - acc: 0.7902 -- iter: 352/541
[A[ATraining Step: 63  | total loss: [1m[32m0.44994[0m[0m | time: 14.731s
[2K
| Adam | epoch: 004 | loss: 0.44994 - acc: 0.7891 -- iter: 384/541
[A[ATraining Step: 64  | total loss: [1m[32m0.43689[0m[0m | time: 17.006s
[2K
| Adam | epoch: 004 | loss: 0.43689 - acc: 0.7998 -- iter: 416/541
[A[ATraining Step: 65  | total loss: [1m[32m0.43163[0m[0m | time: 22.766s
[2K
| Adam | epoch: 004 | loss: 0.43163 - acc: 0.8052 -- iter: 448/541
[A[ATraining Step: 66  | total loss: [1m[32m0.42217[0m[0m | time: 29.353s
[2K
| Adam | epoch: 004 | loss: 0.42217 - acc: 0.8099 -- iter: 480/541
[A[ATraining Step: 67  | total loss: [1m[32m0.42127[0m[0m | time: 39.506s
[2K
| Adam | epoch: 004 | loss: 0.42127 - acc: 0.8065 -- iter: 512/541
[A[ATraining Step: 68  | total loss: [1m[32m0.42174[0m[0m | time: 77.115s
[2K
| Adam | epoch: 004 | loss: 0.42174 - acc: 0.8072 | val_loss: 0.40506 - val_acc: 0.8529 -- iter: 541/541
--
Training Step: 69  | total loss: [1m[32m0.41780[0m[0m | time: 10.402s
[2K
| Adam | epoch: 005 | loss: 0.41780 - acc: 0.8115 -- iter: 032/541
[A[ATraining Step: 70  | total loss: [1m[32m0.40571[0m[0m | time: 14.225s
[2K
| Adam | epoch: 005 | loss: 0.40571 - acc: 0.8188 -- iter: 064/541
[A[ATraining Step: 71  | total loss: [1m[32m0.41399[0m[0m | time: 17.078s
[2K
| Adam | epoch: 005 | loss: 0.41399 - acc: 0.8145 -- iter: 096/541
[A[ATraining Step: 72  | total loss: [1m[32m0.38840[0m[0m | time: 18.758s
[2K
| Adam | epoch: 005 | loss: 0.38840 - acc: 0.8315 -- iter: 128/541
[A[ATraining Step: 73  | total loss: [1m[32m0.36252[0m[0m | time: 19.681s
[2K
| Adam | epoch: 005 | loss: 0.36252 - acc: 0.8502 -- iter: 160/541
[A[ATraining Step: 74  | total loss: [1m[32m0.36522[0m[0m | time: 20.873s
[2K
| Adam | epoch: 005 | loss: 0.36522 - acc: 0.8461 -- iter: 192/541
[A[ATraining Step: 75  | total loss: [1m[32m0.34754[0m[0m | time: 21.964s
[2K
| Adam | epoch: 005 | loss: 0.34754 - acc: 0.8560 -- iter: 224/541
[A[ATraining Step: 76  | total loss: [1m[32m0.36189[0m[0m | time: 23.160s
[2K
| Adam | epoch: 005 | loss: 0.36189 - acc: 0.8513 -- iter: 256/541
[A[ATraining Step: 77  | total loss: [1m[32m0.34039[0m[0m | time: 24.181s
[2K
| Adam | epoch: 005 | loss: 0.34039 - acc: 0.8638 -- iter: 288/541
[A[ATraining Step: 78  | total loss: [1m[32m0.32180[0m[0m | time: 25.385s
[2K
| Adam | epoch: 005 | loss: 0.32180 - acc: 0.8715 -- iter: 320/541
[A[ATraining Step: 79  | total loss: [1m[32m0.30760[0m[0m | time: 26.605s
[2K
| Adam | epoch: 005 | loss: 0.30760 - acc: 0.8783 -- iter: 352/541
[A[ATraining Step: 80  | total loss: [1m[32m0.34323[0m[0m | time: 27.793s
[2K
| Adam | epoch: 005 | loss: 0.34323 - acc: 0.8652 -- iter: 384/541
[A[ATraining Step: 81  | total loss: [1m[32m0.35101[0m[0m | time: 28.866s
[2K
| Adam | epoch: 005 | loss: 0.35101 - acc: 0.8662 -- iter: 416/541
[A[ATraining Step: 82  | total loss: [1m[32m0.33507[0m[0m | time: 30.151s
[2K
| Adam | epoch: 005 | loss: 0.33507 - acc: 0.8733 -- iter: 448/541
[A[ATraining Step: 83  | total loss: [1m[32m0.35319[0m[0m | time: 31.413s
[2K
| Adam | epoch: 005 | loss: 0.35319 - acc: 0.8704 -- iter: 480/541
[A[ATraining Step: 84  | total loss: [1m[32m0.38098[0m[0m | time: 32.605s
[2K
| Adam | epoch: 005 | loss: 0.38098 - acc: 0.8614 -- iter: 512/541
[A[ATraining Step: 85  | total loss: [1m[32m0.42537[0m[0m | time: 35.040s
[2K
| Adam | epoch: 005 | loss: 0.42537 - acc: 0.8409 | val_loss: 0.32472 - val_acc: 0.8882 -- iter: 541/541
--
Training Step: 86  | total loss: [1m[32m0.39811[0m[0m | time: 1.224s
[2K
| Adam | epoch: 006 | loss: 0.39811 - acc: 0.8537 -- iter: 032/541
[A[ATraining Step: 87  | total loss: [1m[32m0.40018[0m[0m | time: 2.508s
[2K
| Adam | epoch: 006 | loss: 0.40018 - acc: 0.8496 -- iter: 064/541
[A[ATraining Step: 88  | total loss: [1m[32m0.39469[0m[0m | time: 3.636s
[2K
| Adam | epoch: 006 | loss: 0.39469 - acc: 0.8490 -- iter: 096/541
[A[ATraining Step: 89  | total loss: [1m[32m0.39494[0m[0m | time: 4.701s
[2K
| Adam | epoch: 006 | loss: 0.39494 - acc: 0.8516 -- iter: 128/541
[A[ATraining Step: 90  | total loss: [1m[32m0.41576[0m[0m | time: 6.080s
[2K
| Adam | epoch: 006 | loss: 0.41576 - acc: 0.8423 -- iter: 160/541
[A[ATraining Step: 91  | total loss: [1m[32m0.42401[0m[0m | time: 7.375s
[2K
| Adam | epoch: 006 | loss: 0.42401 - acc: 0.8339 -- iter: 192/541
[A[ATraining Step: 92  | total loss: [1m[32m0.42305[0m[0m | time: 8.381s
[2K
| Adam | epoch: 006 | loss: 0.42305 - acc: 0.8349 -- iter: 224/541
[A[ATraining Step: 93  | total loss: [1m[32m0.42145[0m[0m | time: 13.079s
[2K
| Adam | epoch: 006 | loss: 0.42145 - acc: 0.8389 -- iter: 256/541
[A[ATraining Step: 94  | total loss: [1m[32m0.42901[0m[0m | time: 18.580s
[2K
| Adam | epoch: 006 | loss: 0.42901 - acc: 0.8363 -- iter: 288/541
[A[ATraining Step: 95  | total loss: [1m[32m0.43380[0m[0m | time: 20.258s
[2K
| Adam | epoch: 006 | loss: 0.43380 - acc: 0.8308 -- iter: 320/541
[A[ATraining Step: 96  | total loss: [1m[32m0.43637[0m[0m | time: 21.647s
[2K
| Adam | epoch: 006 | loss: 0.43637 - acc: 0.8290 -- iter: 352/541
[A[ATraining Step: 97  | total loss: [1m[32m0.42900[0m[0m | time: 22.696s
[2K
| Adam | epoch: 006 | loss: 0.42900 - acc: 0.8429 -- iter: 384/541
[A[ATraining Step: 98  | total loss: [1m[32m0.42286[0m[0m | time: 23.861s
[2K
| Adam | epoch: 006 | loss: 0.42286 - acc: 0.8493 -- iter: 416/541
[A[ATraining Step: 99  | total loss: [1m[32m0.42057[0m[0m | time: 24.975s
[2K
| Adam | epoch: 006 | loss: 0.42057 - acc: 0.8456 -- iter: 448/541
[A[ATraining Step: 100  | total loss: [1m[32m0.41033[0m[0m | time: 26.021s
[2K
| Adam | epoch: 006 | loss: 0.41033 - acc: 0.8485 -- iter: 480/541
[A[ATraining Step: 101  | total loss: [1m[32m0.39184[0m[0m | time: 27.271s
[2K
| Adam | epoch: 006 | loss: 0.39184 - acc: 0.8606 -- iter: 512/541
[A[ATraining Step: 102  | total loss: [1m[32m0.38054[0m[0m | time: 29.901s
[2K
| Adam | epoch: 006 | loss: 0.38054 - acc: 0.8651 | val_loss: 0.33302 - val_acc: 0.8824 -- iter: 541/541
--
Training Step: 103  | total loss: [1m[32m0.38779[0m[0m | time: 1.380s
[2K
| Adam | epoch: 007 | loss: 0.38779 - acc: 0.8536 -- iter: 032/541
[A[ATraining Step: 104  | total loss: [1m[32m0.39265[0m[0m | time: 2.687s
[2K
| Adam | epoch: 007 | loss: 0.39265 - acc: 0.8526 -- iter: 064/541
[A[ATraining Step: 105  | total loss: [1m[32m0.38287[0m[0m | time: 3.688s
[2K
| Adam | epoch: 007 | loss: 0.38287 - acc: 0.8580 -- iter: 096/541
[A[ATraining Step: 106  | total loss: [1m[32m0.37962[0m[0m | time: 4.927s
[2K
| Adam | epoch: 007 | loss: 0.37962 - acc: 0.8566 -- iter: 128/541
[A[ATraining Step: 107  | total loss: [1m[32m0.40100[0m[0m | time: 6.083s
[2K
| Adam | epoch: 007 | loss: 0.40100 - acc: 0.8397 -- iter: 160/541
[A[ATraining Step: 108  | total loss: [1m[32m0.41716[0m[0m | time: 7.149s
[2K
| Adam | epoch: 007 | loss: 0.41716 - acc: 0.8316 -- iter: 192/541
[A[ATraining Step: 109  | total loss: [1m[32m0.42904[0m[0m | time: 8.367s
[2K
| Adam | epoch: 007 | loss: 0.42904 - acc: 0.8243 -- iter: 224/541
[A[ATraining Step: 110  | total loss: [1m[32m0.41681[0m[0m | time: 9.725s
[2K
| Adam | epoch: 007 | loss: 0.41681 - acc: 0.8293 -- iter: 256/541
[A[ATraining Step: 111  | total loss: [1m[32m0.39919[0m[0m | time: 10.971s
[2K
| Adam | epoch: 007 | loss: 0.39919 - acc: 0.8401 -- iter: 288/541
[A[ATraining Step: 112  | total loss: [1m[32m0.39284[0m[0m | time: 12.298s
[2K
| Adam | epoch: 007 | loss: 0.39284 - acc: 0.8436 -- iter: 320/541
[A[ATraining Step: 113  | total loss: [1m[32m0.38311[0m[0m | time: 13.550s
[2K
| Adam | epoch: 007 | loss: 0.38311 - acc: 0.8468 -- iter: 352/541
[A[ATraining Step: 114  | total loss: [1m[32m0.38600[0m[0m | time: 14.624s
[2K
| Adam | epoch: 007 | loss: 0.38600 - acc: 0.8402 -- iter: 384/541
[A[ATraining Step: 115  | total loss: [1m[32m0.38072[0m[0m | time: 15.885s
[2K
| Adam | epoch: 007 | loss: 0.38072 - acc: 0.8406 -- iter: 416/541
[A[ATraining Step: 116  | total loss: [1m[32m0.35716[0m[0m | time: 17.247s
[2K
| Adam | epoch: 007 | loss: 0.35716 - acc: 0.8534 -- iter: 448/541
[A[ATraining Step: 117  | total loss: [1m[32m0.35123[0m[0m | time: 18.406s
[2K
| Adam | epoch: 007 | loss: 0.35123 - acc: 0.8556 -- iter: 480/541
[A[ATraining Step: 118  | total loss: [1m[32m0.34118[0m[0m | time: 19.658s
[2K
| Adam | epoch: 007 | loss: 0.34118 - acc: 0.8637 -- iter: 512/541
[A[ATraining Step: 119  | total loss: [1m[32m0.34008[0m[0m | time: 22.219s
[2K
| Adam | epoch: 007 | loss: 0.34008 - acc: 0.8649 | val_loss: 0.27993 - val_acc: 0.8824 -- iter: 541/541
--
Training Step: 120  | total loss: [1m[32m0.33051[0m[0m | time: 1.091s
[2K
| Adam | epoch: 008 | loss: 0.33051 - acc: 0.8690 -- iter: 032/541
[A[ATraining Step: 121  | total loss: [1m[32m0.33329[0m[0m | time: 2.553s
[2K
| Adam | epoch: 008 | loss: 0.33329 - acc: 0.8602 -- iter: 064/541
[A[ATraining Step: 122  | total loss: [1m[32m0.33554[0m[0m | time: 3.894s
[2K
| Adam | epoch: 008 | loss: 0.33554 - acc: 0.8586 -- iter: 096/541
[A[ATraining Step: 123  | total loss: [1m[32m0.35966[0m[0m | time: 5.541s
[2K
| Adam | epoch: 008 | loss: 0.35966 - acc: 0.8509 -- iter: 128/541
[A[ATraining Step: 124  | total loss: [1m[32m0.34954[0m[0m | time: 6.546s
[2K
| Adam | epoch: 008 | loss: 0.34954 - acc: 0.8533 -- iter: 160/541
[A[ATraining Step: 125  | total loss: [1m[32m0.33933[0m[0m | time: 12.031s
[2K
| Adam | epoch: 008 | loss: 0.33933 - acc: 0.8554 -- iter: 192/541
[A[ATraining Step: 126  | total loss: [1m[32m0.32747[0m[0m | time: 13.400s
[2K
| Adam | epoch: 008 | loss: 0.32747 - acc: 0.8630 -- iter: 224/541
[A[ATraining Step: 127  | total loss: [1m[32m0.31654[0m[0m | time: 14.562s
[2K
| Adam | epoch: 008 | loss: 0.31654 - acc: 0.8698 -- iter: 256/541
[A[ATraining Step: 128  | total loss: [1m[32m0.30641[0m[0m | time: 15.711s
[2K
| Adam | epoch: 008 | loss: 0.30641 - acc: 0.8734 -- iter: 288/541
[A[ATraining Step: 129  | total loss: [1m[32m0.30984[0m[0m | time: 16.812s
[2K
| Adam | epoch: 008 | loss: 0.30984 - acc: 0.8674 -- iter: 320/541
[A[ATraining Step: 130  | total loss: [1m[32m0.30984[0m[0m | time: 17.926s
[2K
| Adam | epoch: 008 | loss: 0.30984 - acc: 0.8744 -- iter: 352/541
[A[ATraining Step: 131  | total loss: [1m[32m0.31050[0m[0m | time: 19.069s
[2K
| Adam | epoch: 008 | loss: 0.31050 - acc: 0.8713 -- iter: 384/541
[A[ATraining Step: 132  | total loss: [1m[32m0.31385[0m[0m | time: 20.310s
[2K
| Adam | epoch: 008 | loss: 0.31385 - acc: 0.8654 -- iter: 416/541
[A[ATraining Step: 133  | total loss: [1m[32m0.29514[0m[0m | time: 21.640s
[2K
| Adam | epoch: 008 | loss: 0.29514 - acc: 0.8758 -- iter: 448/541
[A[ATraining Step: 134  | total loss: [1m[32m0.28215[0m[0m | time: 22.557s
[2K
| Adam | epoch: 008 | loss: 0.28215 - acc: 0.8819 -- iter: 480/541
[A[ATraining Step: 135  | total loss: [1m[32m0.29770[0m[0m | time: 23.595s
[2K
| Adam | epoch: 008 | loss: 0.29770 - acc: 0.8812 -- iter: 512/541
[A[ATraining Step: 136  | total loss: [1m[32m0.31197[0m[0m | time: 31.690s
[2K
| Adam | epoch: 008 | loss: 0.31197 - acc: 0.8744 | val_loss: 0.30644 - val_acc: 0.8529 -- iter: 541/541
--
Training Step: 137  | total loss: [1m[32m0.29705[0m[0m | time: 0.977s
[2K
| Adam | epoch: 009 | loss: 0.29705 - acc: 0.8807 -- iter: 032/541
[A[ATraining Step: 138  | total loss: [1m[32m0.28783[0m[0m | time: 2.002s
[2K
| Adam | epoch: 009 | loss: 0.28783 - acc: 0.8832 -- iter: 064/541
[A[ATraining Step: 139  | total loss: [1m[32m0.27402[0m[0m | time: 2.928s
[2K
| Adam | epoch: 009 | loss: 0.27402 - acc: 0.8887 -- iter: 096/541
[A[ATraining Step: 140  | total loss: [1m[32m0.27789[0m[0m | time: 3.882s
[2K
| Adam | epoch: 009 | loss: 0.27789 - acc: 0.8810 -- iter: 128/541
[A[ATraining Step: 141  | total loss: [1m[32m0.28516[0m[0m | time: 4.911s
[2K
| Adam | epoch: 009 | loss: 0.28516 - acc: 0.8742 -- iter: 160/541
[A[ATraining Step: 142  | total loss: [1m[32m0.28336[0m[0m | time: 5.867s
[2K
| Adam | epoch: 009 | loss: 0.28336 - acc: 0.8774 -- iter: 192/541
[A[ATraining Step: 143  | total loss: [1m[32m0.28407[0m[0m | time: 6.782s
[2K
| Adam | epoch: 009 | loss: 0.28407 - acc: 0.8834 -- iter: 224/541
[A[ATraining Step: 144  | total loss: [1m[32m0.32488[0m[0m | time: 7.848s
[2K
| Adam | epoch: 009 | loss: 0.32488 - acc: 0.8709 -- iter: 256/541
[A[ATraining Step: 145  | total loss: [1m[32m0.34262[0m[0m | time: 8.967s
[2K
| Adam | epoch: 009 | loss: 0.34262 - acc: 0.8597 -- iter: 288/541
[A[ATraining Step: 146  | total loss: [1m[32m0.32923[0m[0m | time: 9.771s
[2K
| Adam | epoch: 009 | loss: 0.32923 - acc: 0.8644 -- iter: 320/541
[A[ATraining Step: 147  | total loss: [1m[32m0.33113[0m[0m | time: 10.698s
[2K
| Adam | epoch: 009 | loss: 0.33113 - acc: 0.8623 -- iter: 352/541
[A[ATraining Step: 148  | total loss: [1m[32m0.31434[0m[0m | time: 11.644s
[2K
| Adam | epoch: 009 | loss: 0.31434 - acc: 0.8698 -- iter: 384/541
[A[ATraining Step: 149  | total loss: [1m[32m0.30440[0m[0m | time: 12.650s
[2K
| Adam | epoch: 009 | loss: 0.30440 - acc: 0.8703 -- iter: 416/541
[A[ATraining Step: 150  | total loss: [1m[32m0.28405[0m[0m | time: 13.583s
[2K
| Adam | epoch: 009 | loss: 0.28405 - acc: 0.8802 -- iter: 448/541
[A[ATraining Step: 151  | total loss: [1m[32m0.27118[0m[0m | time: 14.610s
[2K
| Adam | epoch: 009 | loss: 0.27118 - acc: 0.8828 -- iter: 480/541
[A[ATraining Step: 152  | total loss: [1m[32m0.27213[0m[0m | time: 15.726s
[2K
| Adam | epoch: 009 | loss: 0.27213 - acc: 0.8789 -- iter: 512/541
[A[ATraining Step: 153  | total loss: [1m[32m0.27182[0m[0m | time: 17.685s
[2K
| Adam | epoch: 009 | loss: 0.27182 - acc: 0.8785 | val_loss: 0.29085 - val_acc: 0.9176 -- iter: 541/541
--
Training Step: 154  | total loss: [1m[32m0.26799[0m[0m | time: 1.028s
[2K
| Adam | epoch: 010 | loss: 0.26799 - acc: 0.8813 -- iter: 032/541
[A[ATraining Step: 155  | total loss: [1m[32m0.26738[0m[0m | time: 2.049s
[2K
| Adam | epoch: 010 | loss: 0.26738 - acc: 0.8838 -- iter: 064/541
[A[ATraining Step: 156  | total loss: [1m[32m0.26106[0m[0m | time: 3.073s
[2K
| Adam | epoch: 010 | loss: 0.26106 - acc: 0.8923 -- iter: 096/541
[A[ATraining Step: 157  | total loss: [1m[32m0.26251[0m[0m | time: 4.092s
[2K
| Adam | epoch: 010 | loss: 0.26251 - acc: 0.8905 -- iter: 128/541
[A[ATraining Step: 158  | total loss: [1m[32m0.25957[0m[0m | time: 5.195s
[2K
| Adam | epoch: 010 | loss: 0.25957 - acc: 0.8890 -- iter: 160/541
[A[ATraining Step: 159  | total loss: [1m[32m0.24824[0m[0m | time: 6.168s
[2K
| Adam | epoch: 010 | loss: 0.24824 - acc: 0.8938 -- iter: 192/541
[A[ATraining Step: 160  | total loss: [1m[32m0.25197[0m[0m | time: 7.167s
[2K
| Adam | epoch: 010 | loss: 0.25197 - acc: 0.8951 -- iter: 224/541
[A[ATraining Step: 161  | total loss: [1m[32m0.23876[0m[0m | time: 8.269s
[2K
| Adam | epoch: 010 | loss: 0.23876 - acc: 0.9056 -- iter: 256/541
[A[ATraining Step: 162  | total loss: [1m[32m0.23507[0m[0m | time: 9.442s
[2K
| Adam | epoch: 010 | loss: 0.23507 - acc: 0.9081 -- iter: 288/541
[A[ATraining Step: 163  | total loss: [1m[32m0.22893[0m[0m | time: 10.381s
[2K
| Adam | epoch: 010 | loss: 0.22893 - acc: 0.9104 -- iter: 320/541
[A[ATraining Step: 164  | total loss: [1m[32m0.24475[0m[0m | time: 11.167s
[2K
| Adam | epoch: 010 | loss: 0.24475 - acc: 0.9006 -- iter: 352/541
[A[ATraining Step: 165  | total loss: [1m[32m0.25195[0m[0m | time: 12.097s
[2K
| Adam | epoch: 010 | loss: 0.25195 - acc: 0.8981 -- iter: 384/541
[A[ATraining Step: 166  | total loss: [1m[32m0.26708[0m[0m | time: 13.123s
[2K
| Adam | epoch: 010 | loss: 0.26708 - acc: 0.8926 -- iter: 416/541
[A[ATraining Step: 167  | total loss: [1m[32m0.26898[0m[0m | time: 14.123s
[2K
| Adam | epoch: 010 | loss: 0.26898 - acc: 0.8940 -- iter: 448/541
[A[ATraining Step: 168  | total loss: [1m[32m0.26155[0m[0m | time: 15.112s
[2K
| Adam | epoch: 010 | loss: 0.26155 - acc: 0.8952 -- iter: 480/541
[A[ATraining Step: 169  | total loss: [1m[32m0.27183[0m[0m | time: 16.131s
[2K
| Adam | epoch: 010 | loss: 0.27183 - acc: 0.8901 -- iter: 512/541
[A[ATraining Step: 170  | total loss: [1m[32m0.25585[0m[0m | time: 18.182s
[2K
| Adam | epoch: 010 | loss: 0.25585 - acc: 0.8979 | val_loss: 0.23614 - val_acc: 0.9118 -- iter: 541/541
--
Training Step: 171  | total loss: [1m[32m0.24552[0m[0m | time: 3.080s
[2K
| Adam | epoch: 011 | loss: 0.24552 - acc: 0.8988 -- iter: 032/541
[A[ATraining Step: 172  | total loss: [1m[32m0.23642[0m[0m | time: 7.108s
[2K
| Adam | epoch: 011 | loss: 0.23642 - acc: 0.9058 -- iter: 064/541
[A[ATraining Step: 173  | total loss: [1m[32m0.22569[0m[0m | time: 9.704s
[2K
| Adam | epoch: 011 | loss: 0.22569 - acc: 0.9121 -- iter: 096/541
[A[ATraining Step: 174  | total loss: [1m[32m0.21511[0m[0m | time: 10.603s
[2K
| Adam | epoch: 011 | loss: 0.21511 - acc: 0.9209 -- iter: 128/541
[A[ATraining Step: 175  | total loss: [1m[32m0.22156[0m[0m | time: 11.609s
[2K
| Adam | epoch: 011 | loss: 0.22156 - acc: 0.9194 -- iter: 160/541
[A[ATraining Step: 176  | total loss: [1m[32m0.21407[0m[0m | time: 12.592s
[2K
| Adam | epoch: 011 | loss: 0.21407 - acc: 0.9212 -- iter: 192/541
[A[ATraining Step: 177  | total loss: [1m[32m0.23070[0m[0m | time: 13.631s
[2K
| Adam | epoch: 011 | loss: 0.23070 - acc: 0.9135 -- iter: 224/541
[A[ATraining Step: 178  | total loss: [1m[32m0.22457[0m[0m | time: 14.715s
[2K
| Adam | epoch: 011 | loss: 0.22457 - acc: 0.9096 -- iter: 256/541
[A[ATraining Step: 179  | total loss: [1m[32m0.21484[0m[0m | time: 15.628s
[2K
| Adam | epoch: 011 | loss: 0.21484 - acc: 0.9124 -- iter: 288/541
[A[ATraining Step: 180  | total loss: [1m[32m0.22029[0m[0m | time: 16.575s
[2K
| Adam | epoch: 011 | loss: 0.22029 - acc: 0.9143 -- iter: 320/541
[A[ATraining Step: 181  | total loss: [1m[32m0.22400[0m[0m | time: 17.461s
[2K
| Adam | epoch: 011 | loss: 0.22400 - acc: 0.9159 -- iter: 352/541
[A[ATraining Step: 182  | total loss: [1m[32m0.22724[0m[0m | time: 18.630s
[2K
| Adam | epoch: 011 | loss: 0.22724 - acc: 0.9212 -- iter: 384/541
[A[ATraining Step: 183  | total loss: [1m[32m0.21801[0m[0m | time: 19.883s
[2K
| Adam | epoch: 011 | loss: 0.21801 - acc: 0.9229 -- iter: 416/541
[A[ATraining Step: 184  | total loss: [1m[32m0.21573[0m[0m | time: 20.980s
[2K
| Adam | epoch: 011 | loss: 0.21573 - acc: 0.9243 -- iter: 448/541
[A[ATraining Step: 185  | total loss: [1m[32m0.23926[0m[0m | time: 22.981s
[2K
| Adam | epoch: 011 | loss: 0.23926 - acc: 0.9131 -- iter: 480/541
[A[ATraining Step: 186  | total loss: [1m[32m0.22739[0m[0m | time: 25.728s
[2K
| Adam | epoch: 011 | loss: 0.22739 - acc: 0.9156 -- iter: 512/541
[A[ATraining Step: 187  | total loss: [1m[32m0.21929[0m[0m | time: 29.664s
[2K
| Adam | epoch: 011 | loss: 0.21929 - acc: 0.9146 | val_loss: 0.26086 - val_acc: 0.9353 -- iter: 541/541
--
Training Step: 188  | total loss: [1m[32m0.21364[0m[0m | time: 1.100s
[2K
| Adam | epoch: 012 | loss: 0.21364 - acc: 0.9169 -- iter: 032/541
[A[ATraining Step: 189  | total loss: [1m[32m0.21310[0m[0m | time: 2.138s
[2K
| Adam | epoch: 012 | loss: 0.21310 - acc: 0.9159 -- iter: 064/541
[A[ATraining Step: 190  | total loss: [1m[32m0.21546[0m[0m | time: 3.081s
[2K
| Adam | epoch: 012 | loss: 0.21546 - acc: 0.9118 -- iter: 096/541
[A[ATraining Step: 191  | total loss: [1m[32m0.20601[0m[0m | time: 4.215s
[2K
| Adam | epoch: 012 | loss: 0.20601 - acc: 0.9143 -- iter: 128/541
[A[ATraining Step: 192  | total loss: [1m[32m0.23312[0m[0m | time: 5.404s
[2K
| Adam | epoch: 012 | loss: 0.23312 - acc: 0.8979 -- iter: 160/541
[A[ATraining Step: 193  | total loss: [1m[32m0.23048[0m[0m | time: 6.528s
[2K
| Adam | epoch: 012 | loss: 0.23048 - acc: 0.9019 -- iter: 192/541
[A[ATraining Step: 194  | total loss: [1m[32m0.23784[0m[0m | time: 11.778s
[2K
| Adam | epoch: 012 | loss: 0.23784 - acc: 0.8992 -- iter: 224/541
[A[ATraining Step: 195  | total loss: [1m[32m0.23939[0m[0m | time: 14.876s
[2K
| Adam | epoch: 012 | loss: 0.23939 - acc: 0.8999 -- iter: 256/541
[A[ATraining Step: 196  | total loss: [1m[32m0.23550[0m[0m | time: 16.966s
[2K
| Adam | epoch: 012 | loss: 0.23550 - acc: 0.9005 -- iter: 288/541
[A[ATraining Step: 197  | total loss: [1m[32m0.23413[0m[0m | time: 17.812s
[2K
| Adam | epoch: 012 | loss: 0.23413 - acc: 0.9011 -- iter: 320/541
[A[ATraining Step: 198  | total loss: [1m[32m0.22044[0m[0m | time: 18.712s
[2K
| Adam | epoch: 012 | loss: 0.22044 - acc: 0.9110 -- iter: 352/541
[A[ATraining Step: 199  | total loss: [1m[32m0.21343[0m[0m | time: 19.738s
[2K
| Adam | epoch: 012 | loss: 0.21343 - acc: 0.9130 -- iter: 384/541
[A[ATraining Step: 200  | total loss: [1m[32m0.22667[0m[0m | time: 21.810s
[2K
| Adam | epoch: 012 | loss: 0.22667 - acc: 0.9123 | val_loss: 0.22707 - val_acc: 0.9471 -- iter: 416/541
--
Training Step: 201  | total loss: [1m[32m0.21834[0m[0m | time: 22.764s
[2K
| Adam | epoch: 012 | loss: 0.21834 - acc: 0.9180 -- iter: 448/541
[A[ATraining Step: 202  | total loss: [1m[32m0.21176[0m[0m | time: 24.091s
[2K
| Adam | epoch: 012 | loss: 0.21176 - acc: 0.9199 -- iter: 480/541
[A[ATraining Step: 203  | total loss: [1m[32m0.20917[0m[0m | time: 25.337s
[2K
| Adam | epoch: 012 | loss: 0.20917 - acc: 0.9217 -- iter: 512/541
[A[ATraining Step: 204  | total loss: [1m[32m0.19879[0m[0m | time: 27.303s
[2K
| Adam | epoch: 012 | loss: 0.19879 - acc: 0.9264 | val_loss: 0.22134 - val_acc: 0.9294 -- iter: 541/541
--
Training Step: 205  | total loss: [1m[32m0.20730[0m[0m | time: 1.079s
[2K
| Adam | epoch: 013 | loss: 0.20730 - acc: 0.9181 -- iter: 032/541
[A[ATraining Step: 206  | total loss: [1m[32m0.20364[0m[0m | time: 2.194s
[2K
| Adam | epoch: 013 | loss: 0.20364 - acc: 0.9169 -- iter: 064/541
[A[ATraining Step: 207  | total loss: [1m[32m0.20198[0m[0m | time: 3.157s
[2K
| Adam | epoch: 013 | loss: 0.20198 - acc: 0.9190 -- iter: 096/541
[A[ATraining Step: 208  | total loss: [1m[32m0.20176[0m[0m | time: 4.063s
[2K
| Adam | epoch: 013 | loss: 0.20176 - acc: 0.9208 -- iter: 128/541
[A[ATraining Step: 209  | total loss: [1m[32m0.20451[0m[0m | time: 5.141s
[2K
| Adam | epoch: 013 | loss: 0.20451 - acc: 0.9225 -- iter: 160/541
[A[ATraining Step: 210  | total loss: [1m[32m0.19941[0m[0m | time: 6.277s
[2K
| Adam | epoch: 013 | loss: 0.19941 - acc: 0.9240 -- iter: 192/541
[A[ATraining Step: 211  | total loss: [1m[32m0.20217[0m[0m | time: 7.380s
[2K
| Adam | epoch: 013 | loss: 0.20217 - acc: 0.9191 -- iter: 224/541
[A[ATraining Step: 212  | total loss: [1m[32m0.19277[0m[0m | time: 8.832s
[2K
| Adam | epoch: 013 | loss: 0.19277 - acc: 0.9209 -- iter: 256/541
[A[ATraining Step: 213  | total loss: [1m[32m0.18538[0m[0m | time: 9.736s
[2K
| Adam | epoch: 013 | loss: 0.18538 - acc: 0.9257 -- iter: 288/541
[A[ATraining Step: 214  | total loss: [1m[32m0.18029[0m[0m | time: 10.725s
[2K
| Adam | epoch: 013 | loss: 0.18029 - acc: 0.9300 -- iter: 320/541
[A[ATraining Step: 215  | total loss: [1m[32m0.17909[0m[0m | time: 11.628s
[2K
| Adam | epoch: 013 | loss: 0.17909 - acc: 0.9276 -- iter: 352/541
[A[ATraining Step: 216  | total loss: [1m[32m0.18245[0m[0m | time: 12.565s
[2K
| Adam | epoch: 013 | loss: 0.18245 - acc: 0.9280 -- iter: 384/541
[A[ATraining Step: 217  | total loss: [1m[32m0.18618[0m[0m | time: 13.655s
[2K
| Adam | epoch: 013 | loss: 0.18618 - acc: 0.9283 -- iter: 416/541
[A[ATraining Step: 218  | total loss: [1m[32m0.17246[0m[0m | time: 14.727s
[2K
| Adam | epoch: 013 | loss: 0.17246 - acc: 0.9355 -- iter: 448/541
[A[ATraining Step: 219  | total loss: [1m[32m0.16212[0m[0m | time: 15.761s
[2K
| Adam | epoch: 013 | loss: 0.16212 - acc: 0.9419 -- iter: 480/541
[A[ATraining Step: 220  | total loss: [1m[32m0.18739[0m[0m | time: 16.754s
[2K
| Adam | epoch: 013 | loss: 0.18739 - acc: 0.9384 -- iter: 512/541
[A[ATraining Step: 221  | total loss: [1m[32m0.17921[0m[0m | time: 19.080s
[2K
| Adam | epoch: 013 | loss: 0.17921 - acc: 0.9414 | val_loss: 0.23062 - val_acc: 0.9412 -- iter: 541/541
--
Training Step: 222  | total loss: [1m[32m0.16709[0m[0m | time: 1.028s
[2K
| Adam | epoch: 014 | loss: 0.16709 - acc: 0.9473 -- iter: 032/541
[A[ATraining Step: 223  | total loss: [1m[32m0.15803[0m[0m | time: 2.020s
[2K
| Adam | epoch: 014 | loss: 0.15803 - acc: 0.9525 -- iter: 064/541
[A[ATraining Step: 224  | total loss: [1m[32m0.16030[0m[0m | time: 3.080s
[2K
| Adam | epoch: 014 | loss: 0.16030 - acc: 0.9510 -- iter: 096/541
[A[ATraining Step: 225  | total loss: [1m[32m0.15118[0m[0m | time: 4.186s
[2K
| Adam | epoch: 014 | loss: 0.15118 - acc: 0.9559 -- iter: 128/541
[A[ATraining Step: 226  | total loss: [1m[32m0.13926[0m[0m | time: 5.316s
[2K
| Adam | epoch: 014 | loss: 0.13926 - acc: 0.9603 -- iter: 160/541
[A[ATraining Step: 227  | total loss: [1m[32m0.14617[0m[0m | time: 6.291s
[2K
| Adam | epoch: 014 | loss: 0.14617 - acc: 0.9580 -- iter: 192/541
[A[ATraining Step: 228  | total loss: [1m[32m0.14847[0m[0m | time: 7.351s
[2K
| Adam | epoch: 014 | loss: 0.14847 - acc: 0.9591 -- iter: 224/541
[A[ATraining Step: 229  | total loss: [1m[32m0.14117[0m[0m | time: 8.533s
[2K
| Adam | epoch: 014 | loss: 0.14117 - acc: 0.9601 -- iter: 256/541
[A[ATraining Step: 230  | total loss: [1m[32m0.13732[0m[0m | time: 9.776s
[2K
| Adam | epoch: 014 | loss: 0.13732 - acc: 0.9609 -- iter: 288/541
[A[ATraining Step: 231  | total loss: [1m[32m0.12823[0m[0m | time: 10.546s
[2K
| Adam | epoch: 014 | loss: 0.12823 - acc: 0.9649 -- iter: 320/541
[A[ATraining Step: 232  | total loss: [1m[32m0.12735[0m[0m | time: 11.533s
[2K
| Adam | epoch: 014 | loss: 0.12735 - acc: 0.9652 -- iter: 352/541
[A[ATraining Step: 233  | total loss: [1m[32m0.12634[0m[0m | time: 12.463s
[2K
| Adam | epoch: 014 | loss: 0.12634 - acc: 0.9656 -- iter: 384/541
[A[ATraining Step: 234  | total loss: [1m[32m0.12759[0m[0m | time: 13.369s
[2K
| Adam | epoch: 014 | loss: 0.12759 - acc: 0.9656 -- iter: 416/541
[A[ATraining Step: 235  | total loss: [1m[32m0.12834[0m[0m | time: 14.298s
[2K
| Adam | epoch: 014 | loss: 0.12834 - acc: 0.9656 -- iter: 448/541
[A[ATraining Step: 236  | total loss: [1m[32m0.12459[0m[0m | time: 15.335s
[2K
| Adam | epoch: 014 | loss: 0.12459 - acc: 0.9659 -- iter: 480/541
[A[ATraining Step: 237  | total loss: [1m[32m0.11950[0m[0m | time: 16.426s
[2K
| Adam | epoch: 014 | loss: 0.11950 - acc: 0.9662 -- iter: 512/541
[A[ATraining Step: 238  | total loss: [1m[32m0.20875[0m[0m | time: 18.461s
[2K
| Adam | epoch: 014 | loss: 0.20875 - acc: 0.9446 | val_loss: 0.33370 - val_acc: 0.9059 -- iter: 541/541
--
Training Step: 239  | total loss: [1m[32m0.19746[0m[0m | time: 1.827s
[2K
| Adam | epoch: 015 | loss: 0.19746 - acc: 0.9501 -- iter: 032/541
[A[ATraining Step: 240  | total loss: [1m[32m0.18744[0m[0m | time: 6.225s
[2K
| Adam | epoch: 015 | loss: 0.18744 - acc: 0.9520 -- iter: 064/541
[A[ATraining Step: 241  | total loss: [1m[32m0.18808[0m[0m | time: 7.096s
[2K
| Adam | epoch: 015 | loss: 0.18808 - acc: 0.9474 -- iter: 096/541
[A[ATraining Step: 242  | total loss: [1m[32m0.18328[0m[0m | time: 7.930s
[2K
| Adam | epoch: 015 | loss: 0.18328 - acc: 0.9464 -- iter: 128/541
[A[ATraining Step: 243  | total loss: [1m[32m0.17037[0m[0m | time: 8.959s
[2K
| Adam | epoch: 015 | loss: 0.17037 - acc: 0.9518 -- iter: 160/541
[A[ATraining Step: 244  | total loss: [1m[32m0.16938[0m[0m | time: 9.915s
[2K
| Adam | epoch: 015 | loss: 0.16938 - acc: 0.9535 -- iter: 192/541
[A[ATraining Step: 245  | total loss: [1m[32m0.16870[0m[0m | time: 10.873s
[2K
| Adam | epoch: 015 | loss: 0.16870 - acc: 0.9487 -- iter: 224/541
[A[ATraining Step: 246  | total loss: [1m[32m0.16125[0m[0m | time: 11.814s
[2K
| Adam | epoch: 015 | loss: 0.16125 - acc: 0.9507 -- iter: 256/541
[A[ATraining Step: 247  | total loss: [1m[32m0.15824[0m[0m | time: 12.850s
[2K
| Adam | epoch: 015 | loss: 0.15824 - acc: 0.9494 -- iter: 288/541
[A[ATraining Step: 248  | total loss: [1m[32m0.16323[0m[0m | time: 13.880s
[2K
| Adam | epoch: 015 | loss: 0.16323 - acc: 0.9514 -- iter: 320/541
[A[ATraining Step: 249  | total loss: [1m[32m0.16776[0m[0m | time: 14.873s
[2K
| Adam | epoch: 015 | loss: 0.16776 - acc: 0.9468 -- iter: 352/541
[A[ATraining Step: 250  | total loss: [1m[32m0.15716[0m[0m | time: 15.802s
[2K
| Adam | epoch: 015 | loss: 0.15716 - acc: 0.9522 -- iter: 384/541
[A[ATraining Step: 251  | total loss: [1m[32m0.14428[0m[0m | time: 16.878s
[2K
| Adam | epoch: 015 | loss: 0.14428 - acc: 0.9569 -- iter: 416/541
[A[ATraining Step: 252  | total loss: [1m[32m0.14028[0m[0m | time: 18.034s
[2K
| Adam | epoch: 015 | loss: 0.14028 - acc: 0.9578 -- iter: 448/541
[A[ATraining Step: 253  | total loss: [1m[32m0.13671[0m[0m | time: 18.834s
[2K
| Adam | epoch: 015 | loss: 0.13671 - acc: 0.9586 -- iter: 480/541
[A[ATraining Step: 254  | total loss: [1m[32m0.13114[0m[0m | time: 19.824s
[2K
| Adam | epoch: 015 | loss: 0.13114 - acc: 0.9596 -- iter: 512/541
[A[ATraining Step: 255  | total loss: [1m[32m0.12066[0m[0m | time: 21.984s
[2K
| Adam | epoch: 015 | loss: 0.12066 - acc: 0.9636 | val_loss: 0.26582 - val_acc: 0.9294 -- iter: 541/541
--
Validation AUC:0.9683660499929387
Validation AUPRC:0.9646168522450473
Test AUC:0.992521811383465
Test AUPRC:0.9930566496328751
BestTestF1Score	0.96	0.91	0.95	0.92	0.99	86	7	76	1	0.46
BestTestMCCScore	0.96	0.91	0.95	0.92	0.99	86	7	76	1	0.46
BestTestAccuracyScore	0.96	0.92	0.96	0.98	0.94	82	2	81	5	0.82
BestValidationF1Score	0.93	0.87	0.94	0.89	0.97	71	9	88	2	0.46
BestValidationMCC	0.93	0.87	0.94	0.89	0.97	71	9	88	2	0.46
BestValidationAccuracy	0.92	0.87	0.94	0.94	0.9	66	4	93	7	0.82
TestPredictions (Threshold:0.46)
CHEMBL460470,TN,INACT,0.029999999329447746	CHEMBL330885,TN,INACT,0.2800000011920929	CHEMBL311455,TN,INACT,0.03999999910593033	CHEMBL109206,TN,INACT,0.029999999329447746	CHEMBL3349611,TP,ACT,1.0	CHEMBL3350354,TP,ACT,1.0	CHEMBL15936,TN,INACT,0.12999999523162842	CHEMBL1765668,TN,INACT,0.019999999552965164	CHEMBL3349680,TP,ACT,1.0	CHEMBL1076624,TP,ACT,0.9599999785423279	CHEMBL2369754,TP,ACT,1.0	CHEMBL413171,TP,ACT,1.0	CHEMBL509192,TP,ACT,1.0	CHEMBL112777,TN,INACT,0.019999999552965164	CHEMBL319910,TN,INACT,0.10000000149011612	CHEMBL109478,TN,INACT,0.019999999552965164	CHEMBL2369753,TP,ACT,1.0	CHEMBL453,TN,INACT,0.029999999329447746	CHEMBL1824050,TP,ACT,1.0	CHEMBL1790896,TP,ACT,1.0	CHEMBL323175,TN,INACT,0.019999999552965164	CHEMBL140495,TN,INACT,0.07999999821186066	CHEMBL3349665,TP,ACT,1.0	CHEMBL264028,TP,ACT,1.0	CHEMBL437220,TP,ACT,1.0	CHEMBL3098601,TP,ACT,1.0	CHEMBL262975,TP,ACT,1.0	CHEMBL446693,TN,INACT,0.10000000149011612	CHEMBL76779,TN,INACT,0.05000000074505806	CHEMBL164968,FP,INACT,0.6200000047683716	CHEMBL511086,TP,ACT,0.9900000095367432	CHEMBL254500,TP,ACT,0.949999988079071	CHEMBL44615,TN,INACT,0.2800000011920929	CHEMBL3647677,TP,ACT,1.0	CHEMBL425090,TP,ACT,1.0	CHEMBL296245,TN,INACT,0.029999999329447746	CHEMBL3238446,TN,INACT,0.029999999329447746	CHEMBL510755,TP,ACT,1.0	CHEMBL391191,TN,INACT,0.05000000074505806	CHEMBL460542,TP,ACT,0.8299999833106995	CHEMBL3349669,TP,ACT,1.0	CHEMBL415582,TP,ACT,1.0	CHEMBL408395,TN,INACT,0.2199999988079071	CHEMBL2391353,TN,INACT,0.05000000074505806	CHEMBL1791305,TP,ACT,1.0	CHEMBL359215,TP,ACT,0.9800000190734863	CHEMBL3349678,TP,ACT,1.0	CHEMBL285333,TP,ACT,1.0	CHEMBL2312376,TN,INACT,0.05999999865889549	CHEMBL2021544,TP,ACT,0.949999988079071	CHEMBL297335,FP,INACT,0.699999988079071	CHEMBL452074,TP,ACT,1.0	CHEMBL435631,FN,ACT,0.12999999523162842	CHEMBL510693,TP,ACT,1.0	CHEMBL3349612,TP,ACT,1.0	CHEMBL308414,TN,INACT,0.019999999552965164	CHEMBL45160,TN,INACT,0.03999999910593033	CHEMBL3122127,TP,ACT,1.0	CHEMBL294087,TN,INACT,0.029999999329447746	CHEMBL263306,TP,ACT,1.0	CHEMBL594802,TN,INACT,0.019999999552965164	CHEMBL174463,TN,INACT,0.36000001430511475	CHEMBL297599,TN,INACT,0.1899999976158142	CHEMBL3349671,TP,ACT,1.0	CHEMBL173708,TN,INACT,0.09000000357627869	CHEMBL1983100,TN,INACT,0.09000000357627869	CHEMBL63937,TN,INACT,0.029999999329447746	CHEMBL510901,TP,ACT,1.0	CHEMBL437448,TP,ACT,1.0	CHEMBL60401,TN,INACT,0.019999999552965164	CHEMBL386784,TP,ACT,1.0	CHEMBL3350885,TP,ACT,1.0	CHEMBL3647702,TP,ACT,1.0	CHEMBL289284,FP,INACT,0.9900000095367432	CHEMBL3350725,TP,ACT,1.0	CHEMBL1824055,TP,ACT,1.0	CHEMBL19808,TN,INACT,0.09000000357627869	CHEMBL407649,TP,ACT,1.0	CHEMBL227378,TN,INACT,0.05000000074505806	CHEMBL447064,TP,ACT,1.0	CHEMBL42359,TN,INACT,0.019999999552965164	CHEMBL265846,TP,ACT,1.0	CHEMBL252355,TP,ACT,1.0	CHEMBL2369493,FP,INACT,0.5899999737739563	CHEMBL3349523,TP,ACT,1.0	CHEMBL3633650,TN,INACT,0.10999999940395355	CHEMBL2021559,TP,ACT,0.9599999785423279	CHEMBL424214,TN,INACT,0.15000000596046448	CHEMBL292906,TP,ACT,1.0	CHEMBL2369757,TP,ACT,1.0	CHEMBL54832,TP,ACT,1.0	CHEMBL406738,TP,ACT,1.0	CHEMBL288967,TN,INACT,0.12999999523162842	CHEMBL11131,TN,INACT,0.03999999910593033	CHEMBL45269,TN,INACT,0.009999999776482582	CHEMBL2112488,TN,INACT,0.05000000074505806	CHEMBL3350881,TP,ACT,1.0	CHEMBL1791304,TP,ACT,1.0	CHEMBL143539,FP,INACT,0.9300000071525574	CHEMBL3350910,TP,ACT,1.0	CHEMBL513277,TN,INACT,0.019999999552965164	CHEMBL461502,TN,INACT,0.029999999329447746	CHEMBL3144285,TP,ACT,0.9599999785423279	CHEMBL165012,TN,INACT,0.019999999552965164	CHEMBL78929,TN,INACT,0.05000000074505806	CHEMBL422411,TN,INACT,0.10000000149011612	CHEMBL446077,TP,ACT,1.0	CHEMBL422701,TN,INACT,0.09000000357627869	CHEMBL510793,TP,ACT,0.5799999833106995	CHEMBL1253871,TP,ACT,0.9800000190734863	CHEMBL241099,TN,INACT,0.019999999552965164	CHEMBL263587,TP,ACT,1.0	CHEMBL166089,TN,INACT,0.1599999964237213	CHEMBL175698,TN,INACT,0.28999999165534973	CHEMBL559150,TP,ACT,1.0	CHEMBL2372964,TP,ACT,1.0	CHEMBL2111200,TP,ACT,1.0	CHEMBL2369750,TP,ACT,1.0	CHEMBL262379,TP,ACT,1.0	CHEMBL387458,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.07000000029802322	CHEMBL455760,TP,ACT,0.9900000095367432	CHEMBL3350892,TP,ACT,1.0	CHEMBL362859,TP,ACT,0.5	CHEMBL142823,TP,ACT,0.9900000095367432	CHEMBL441920,TP,ACT,0.7099999785423279	CHEMBL499681,TP,ACT,1.0	CHEMBL322547,TN,INACT,0.019999999552965164	CHEMBL3350895,TP,ACT,1.0	CHEMBL408493,TN,INACT,0.07999999821186066	CHEMBL114074,TN,INACT,0.05000000074505806	CHEMBL251835,TP,ACT,0.9800000190734863	CHEMBL312551,TN,INACT,0.029999999329447746	CHEMBL282129,TP,ACT,1.0	CHEMBL2371051,TP,ACT,1.0	CHEMBL18797,TN,INACT,0.019999999552965164	CHEMBL154068,TN,INACT,0.019999999552965164	CHEMBL1091790,TN,INACT,0.029999999329447746	CHEMBL95727,TN,INACT,0.029999999329447746	CHEMBL1255049,TP,ACT,0.9599999785423279	CHEMBL593620,TN,INACT,0.03999999910593033	CHEMBL563462,TP,ACT,1.0	CHEMBL303386,FP,INACT,0.5600000023841858	CHEMBL594803,TN,INACT,0.05000000074505806	CHEMBL553656,TP,ACT,1.0	CHEMBL1794035,TP,ACT,1.0	CHEMBL109248,TN,INACT,0.009999999776482582	CHEMBL323951,TN,INACT,0.019999999552965164	CHEMBL141354,TN,INACT,0.09000000357627869	CHEMBL2372603,TP,ACT,1.0	CHEMBL174872,TP,ACT,0.5	CHEMBL414544,TP,ACT,1.0	CHEMBL324586,TN,INACT,0.009999999776482582	CHEMBL336081,FP,INACT,0.6399999856948853	CHEMBL2370509,TN,INACT,0.10999999940395355	CHEMBL322537,TN,INACT,0.029999999329447746	CHEMBL503379,TP,ACT,0.949999988079071	CHEMBL2369751,TP,ACT,1.0	CHEMBL1254967,TP,ACT,0.949999988079071	CHEMBL2376804,TN,INACT,0.05999999865889549	CHEMBL523814,TP,ACT,0.9200000166893005	CHEMBL240021,TN,INACT,0.019999999552965164	CHEMBL2113072,TN,INACT,0.05999999865889549	CHEMBL21328,TN,INACT,0.4000000059604645	CHEMBL308924,TN,INACT,0.009999999776482582	CHEMBL110904,TN,INACT,0.019999999552965164	CHEMBL2111789,TN,INACT,0.05000000074505806	CHEMBL461089,TN,INACT,0.029999999329447746	CHEMBL276676,TN,INACT,0.05000000074505806	CHEMBL59,TN,INACT,0.019999999552965164	

