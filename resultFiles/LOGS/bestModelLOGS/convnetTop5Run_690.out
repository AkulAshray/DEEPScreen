CNNModel CHEMBL5719 adam 0.001 30 256 0 0.8 False True
Number of active compounds :	148
Number of inactive compounds :	148
---------------------------------
Run id: CNNModel_CHEMBL5719_adam_0.001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5719_adam_0.001_30_256_0.8_True/
---------------------------------
Training samples: 169
Validation samples: 53
--
Training Step: 1  | time: 1.597s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/169
[A[ATraining Step: 2  | total loss: [1m[32m0.62385[0m[0m | time: 2.394s
[2K
| Adam | epoch: 001 | loss: 0.62385 - acc: 0.4500 -- iter: 064/169
[A[ATraining Step: 3  | total loss: [1m[32m0.68122[0m[0m | time: 3.209s
[2K
| Adam | epoch: 001 | loss: 0.68122 - acc: 0.4909 -- iter: 096/169
[A[ATraining Step: 4  | total loss: [1m[32m0.68921[0m[0m | time: 4.142s
[2K
| Adam | epoch: 001 | loss: 0.68921 - acc: 0.5212 -- iter: 128/169
[A[ATraining Step: 5  | total loss: [1m[32m0.68937[0m[0m | time: 5.091s
[2K
| Adam | epoch: 001 | loss: 0.68937 - acc: 0.5498 -- iter: 160/169
[A[ATraining Step: 6  | total loss: [1m[32m0.69375[0m[0m | time: 6.478s
[2K
| Adam | epoch: 001 | loss: 0.69375 - acc: 0.5178 | val_loss: 0.68875 - val_acc: 0.5472 -- iter: 169/169
--
Training Step: 7  | total loss: [1m[32m0.68972[0m[0m | time: 0.252s
[2K
| Adam | epoch: 002 | loss: 0.68972 - acc: 0.5404 -- iter: 032/169
[A[ATraining Step: 8  | total loss: [1m[32m0.68785[0m[0m | time: 1.014s
[2K
| Adam | epoch: 002 | loss: 0.68785 - acc: 0.5489 -- iter: 064/169
[A[ATraining Step: 9  | total loss: [1m[32m0.68953[0m[0m | time: 1.800s
[2K
| Adam | epoch: 002 | loss: 0.68953 - acc: 0.5396 -- iter: 096/169
[A[ATraining Step: 10  | total loss: [1m[32m0.70572[0m[0m | time: 2.621s
[2K
| Adam | epoch: 002 | loss: 0.70572 - acc: 0.4729 -- iter: 128/169
[A[ATraining Step: 11  | total loss: [1m[32m0.68993[0m[0m | time: 3.354s
[2K
| Adam | epoch: 002 | loss: 0.68993 - acc: 0.5746 -- iter: 160/169
[A[ATraining Step: 12  | total loss: [1m[32m0.69222[0m[0m | time: 5.126s
[2K
| Adam | epoch: 002 | loss: 0.69222 - acc: 0.5410 | val_loss: 0.68943 - val_acc: 0.5472 -- iter: 169/169
--
Training Step: 13  | total loss: [1m[32m0.68942[0m[0m | time: 0.273s
[2K
| Adam | epoch: 003 | loss: 0.68942 - acc: 0.5636 -- iter: 032/169
[A[ATraining Step: 14  | total loss: [1m[32m0.69822[0m[0m | time: 0.509s
[2K
| Adam | epoch: 003 | loss: 0.69822 - acc: 0.4694 -- iter: 064/169
[A[ATraining Step: 15  | total loss: [1m[32m0.70068[0m[0m | time: 1.335s
[2K
| Adam | epoch: 003 | loss: 0.70068 - acc: 0.4162 -- iter: 096/169
[A[ATraining Step: 16  | total loss: [1m[32m0.69807[0m[0m | time: 2.225s
[2K
| Adam | epoch: 003 | loss: 0.69807 - acc: 0.4476 -- iter: 128/169
[A[ATraining Step: 17  | total loss: [1m[32m0.69626[0m[0m | time: 3.110s
[2K
| Adam | epoch: 003 | loss: 0.69626 - acc: 0.4665 -- iter: 160/169
[A[ATraining Step: 18  | total loss: [1m[32m0.69438[0m[0m | time: 5.020s
[2K
| Adam | epoch: 003 | loss: 0.69438 - acc: 0.5105 | val_loss: 0.69238 - val_acc: 0.5472 -- iter: 169/169
--
Training Step: 19  | total loss: [1m[32m0.69447[0m[0m | time: 1.107s
[2K
| Adam | epoch: 004 | loss: 0.69447 - acc: 0.4862 -- iter: 032/169
[A[ATraining Step: 20  | total loss: [1m[32m0.69366[0m[0m | time: 1.461s
[2K
| Adam | epoch: 004 | loss: 0.69366 - acc: 0.5107 -- iter: 064/169
[A[ATraining Step: 21  | total loss: [1m[32m0.69439[0m[0m | time: 1.826s
[2K
| Adam | epoch: 004 | loss: 0.69439 - acc: 0.4557 -- iter: 096/169
[A[ATraining Step: 22  | total loss: [1m[32m0.69457[0m[0m | time: 2.627s
[2K
| Adam | epoch: 004 | loss: 0.69457 - acc: 0.4190 -- iter: 128/169
[A[ATraining Step: 23  | total loss: [1m[32m0.69407[0m[0m | time: 3.495s
[2K
| Adam | epoch: 004 | loss: 0.69407 - acc: 0.4697 -- iter: 160/169
[A[ATraining Step: 24  | total loss: [1m[32m0.69371[0m[0m | time: 5.411s
[2K
| Adam | epoch: 004 | loss: 0.69371 - acc: 0.5046 | val_loss: 0.69311 - val_acc: 0.5472 -- iter: 169/169
--
Training Step: 25  | total loss: [1m[32m0.69361[0m[0m | time: 0.844s
[2K
| Adam | epoch: 005 | loss: 0.69361 - acc: 0.4778 -- iter: 032/169
[A[ATraining Step: 26  | total loss: [1m[32m0.69348[0m[0m | time: 1.897s
[2K
| Adam | epoch: 005 | loss: 0.69348 - acc: 0.4837 -- iter: 064/169
[A[ATraining Step: 27  | total loss: [1m[32m0.69342[0m[0m | time: 2.277s
[2K
| Adam | epoch: 005 | loss: 0.69342 - acc: 0.4557 -- iter: 096/169
[A[ATraining Step: 28  | total loss: [1m[32m0.69337[0m[0m | time: 2.623s
[2K
| Adam | epoch: 005 | loss: 0.69337 - acc: 0.4251 -- iter: 128/169
[A[ATraining Step: 29  | total loss: [1m[32m0.69336[0m[0m | time: 3.641s
[2K
| Adam | epoch: 005 | loss: 0.69336 - acc: 0.4568 -- iter: 160/169
[A[ATraining Step: 30  | total loss: [1m[32m0.69333[0m[0m | time: 5.461s
[2K
| Adam | epoch: 005 | loss: 0.69333 - acc: 0.4597 | val_loss: 0.69331 - val_acc: 0.4528 -- iter: 169/169
--
Training Step: 31  | total loss: [1m[32m0.69338[0m[0m | time: 0.964s
[2K
| Adam | epoch: 006 | loss: 0.69338 - acc: 0.4473 -- iter: 032/169
[A[ATraining Step: 32  | total loss: [1m[32m0.69334[0m[0m | time: 1.925s
[2K
| Adam | epoch: 006 | loss: 0.69334 - acc: 0.4451 -- iter: 064/169
[A[ATraining Step: 33  | total loss: [1m[32m0.69333[0m[0m | time: 2.785s
[2K
| Adam | epoch: 006 | loss: 0.69333 - acc: 0.4503 -- iter: 096/169
[A[ATraining Step: 34  | total loss: [1m[32m0.69329[0m[0m | time: 3.168s
[2K
| Adam | epoch: 006 | loss: 0.69329 - acc: 0.4610 -- iter: 128/169
[A[ATraining Step: 35  | total loss: [1m[32m0.69323[0m[0m | time: 3.509s
[2K
| Adam | epoch: 006 | loss: 0.69323 - acc: 0.4575 -- iter: 160/169
[A[ATraining Step: 36  | total loss: [1m[32m0.69325[0m[0m | time: 5.574s
[2K
| Adam | epoch: 006 | loss: 0.69325 - acc: 0.4321 | val_loss: 0.69315 - val_acc: 0.4528 -- iter: 169/169
--
Training Step: 37  | total loss: [1m[32m0.69323[0m[0m | time: 0.892s
[2K
| Adam | epoch: 007 | loss: 0.69323 - acc: 0.4457 -- iter: 032/169
[A[ATraining Step: 38  | total loss: [1m[32m0.69323[0m[0m | time: 1.925s
[2K
| Adam | epoch: 007 | loss: 0.69323 - acc: 0.4319 -- iter: 064/169
[A[ATraining Step: 39  | total loss: [1m[32m0.69317[0m[0m | time: 2.925s
[2K
| Adam | epoch: 007 | loss: 0.69317 - acc: 0.4688 -- iter: 096/169
[A[ATraining Step: 40  | total loss: [1m[32m0.69312[0m[0m | time: 3.746s
[2K
| Adam | epoch: 007 | loss: 0.69312 - acc: 0.4981 -- iter: 128/169
[A[ATraining Step: 41  | total loss: [1m[32m0.69307[0m[0m | time: 4.108s
[2K
| Adam | epoch: 007 | loss: 0.69307 - acc: 0.5099 -- iter: 160/169
[A[ATraining Step: 42  | total loss: [1m[32m0.69293[0m[0m | time: 5.454s
[2K
| Adam | epoch: 007 | loss: 0.69293 - acc: 0.5382 | val_loss: 0.69187 - val_acc: 0.5472 -- iter: 169/169
--
Training Step: 43  | total loss: [1m[32m0.69267[0m[0m | time: 0.923s
[2K
| Adam | epoch: 008 | loss: 0.69267 - acc: 0.5608 -- iter: 032/169
[A[ATraining Step: 44  | total loss: [1m[32m0.69264[0m[0m | time: 1.824s
[2K
| Adam | epoch: 008 | loss: 0.69264 - acc: 0.5557 -- iter: 064/169
[A[ATraining Step: 45  | total loss: [1m[32m0.69218[0m[0m | time: 2.724s
[2K
| Adam | epoch: 008 | loss: 0.69218 - acc: 0.5728 -- iter: 096/169
[A[ATraining Step: 46  | total loss: [1m[32m0.69170[0m[0m | time: 3.669s
[2K
| Adam | epoch: 008 | loss: 0.69170 - acc: 0.5763 -- iter: 128/169
[A[ATraining Step: 47  | total loss: [1m[32m0.69167[0m[0m | time: 4.622s
[2K
| Adam | epoch: 008 | loss: 0.69167 - acc: 0.5587 -- iter: 160/169
[A[ATraining Step: 48  | total loss: [1m[32m0.69213[0m[0m | time: 5.952s
[2K
| Adam | epoch: 008 | loss: 0.69213 - acc: 0.5392 | val_loss: 0.69023 - val_acc: 0.6604 -- iter: 169/169
--
Training Step: 49  | total loss: [1m[32m0.69197[0m[0m | time: 0.312s
[2K
| Adam | epoch: 009 | loss: 0.69197 - acc: 0.5593 -- iter: 032/169
[A[ATraining Step: 50  | total loss: [1m[32m0.69146[0m[0m | time: 1.243s
[2K
| Adam | epoch: 009 | loss: 0.69146 - acc: 0.5932 -- iter: 064/169
[A[ATraining Step: 51  | total loss: [1m[32m0.69115[0m[0m | time: 2.309s
[2K
| Adam | epoch: 009 | loss: 0.69115 - acc: 0.5790 -- iter: 096/169
[A[ATraining Step: 52  | total loss: [1m[32m0.69113[0m[0m | time: 3.305s
[2K
| Adam | epoch: 009 | loss: 0.69113 - acc: 0.5625 -- iter: 128/169
[A[ATraining Step: 53  | total loss: [1m[32m0.69040[0m[0m | time: 4.125s
[2K
| Adam | epoch: 009 | loss: 0.69040 - acc: 0.5717 -- iter: 160/169
[A[ATraining Step: 54  | total loss: [1m[32m0.68889[0m[0m | time: 6.205s
[2K
| Adam | epoch: 009 | loss: 0.68889 - acc: 0.6021 | val_loss: 0.66652 - val_acc: 0.5472 -- iter: 169/169
--
Training Step: 55  | total loss: [1m[32m0.68612[0m[0m | time: 0.320s
[2K
| Adam | epoch: 010 | loss: 0.68612 - acc: 0.6098 -- iter: 032/169
[A[ATraining Step: 56  | total loss: [1m[32m0.68350[0m[0m | time: 0.622s
[2K
| Adam | epoch: 010 | loss: 0.68350 - acc: 0.6022 -- iter: 064/169
[A[ATraining Step: 57  | total loss: [1m[32m0.67940[0m[0m | time: 1.518s
[2K
| Adam | epoch: 010 | loss: 0.67940 - acc: 0.5958 -- iter: 096/169
[A[ATraining Step: 58  | total loss: [1m[32m0.67319[0m[0m | time: 2.457s
[2K
| Adam | epoch: 010 | loss: 0.67319 - acc: 0.5997 -- iter: 128/169
[A[ATraining Step: 59  | total loss: [1m[32m0.66987[0m[0m | time: 3.417s
[2K
| Adam | epoch: 010 | loss: 0.66987 - acc: 0.6157 -- iter: 160/169
[A[ATraining Step: 60  | total loss: [1m[32m0.66154[0m[0m | time: 5.306s
[2K
| Adam | epoch: 010 | loss: 0.66154 - acc: 0.6335 | val_loss: 0.56872 - val_acc: 0.7736 -- iter: 169/169
--
Training Step: 61  | total loss: [1m[32m0.64809[0m[0m | time: 0.962s
[2K
| Adam | epoch: 011 | loss: 0.64809 - acc: 0.6650 -- iter: 032/169
[A[ATraining Step: 62  | total loss: [1m[32m0.64730[0m[0m | time: 1.300s
[2K
| Adam | epoch: 011 | loss: 0.64730 - acc: 0.6558 -- iter: 064/169
[A[ATraining Step: 63  | total loss: [1m[32m0.64114[0m[0m | time: 1.639s
[2K
| Adam | epoch: 011 | loss: 0.64114 - acc: 0.6431 -- iter: 096/169
[A[ATraining Step: 64  | total loss: [1m[32m0.62858[0m[0m | time: 2.628s
[2K
| Adam | epoch: 011 | loss: 0.62858 - acc: 0.6600 -- iter: 128/169
[A[ATraining Step: 65  | total loss: [1m[32m0.63695[0m[0m | time: 3.482s
[2K
| Adam | epoch: 011 | loss: 0.63695 - acc: 0.6595 -- iter: 160/169
[A[ATraining Step: 66  | total loss: [1m[32m0.63288[0m[0m | time: 5.495s
[2K
| Adam | epoch: 011 | loss: 0.63288 - acc: 0.6591 | val_loss: 0.49532 - val_acc: 0.7925 -- iter: 169/169
--
Training Step: 67  | total loss: [1m[32m0.63401[0m[0m | time: 0.923s
[2K
| Adam | epoch: 012 | loss: 0.63401 - acc: 0.6513 -- iter: 032/169
[A[ATraining Step: 68  | total loss: [1m[32m0.61762[0m[0m | time: 1.869s
[2K
| Adam | epoch: 012 | loss: 0.61762 - acc: 0.6519 -- iter: 064/169
[A[ATraining Step: 69  | total loss: [1m[32m0.60314[0m[0m | time: 2.210s
[2K
| Adam | epoch: 012 | loss: 0.60314 - acc: 0.6597 -- iter: 096/169
[A[ATraining Step: 70  | total loss: [1m[32m0.58203[0m[0m | time: 2.565s
[2K
| Adam | epoch: 012 | loss: 0.58203 - acc: 0.6733 -- iter: 128/169
[A[ATraining Step: 71  | total loss: [1m[32m0.56047[0m[0m | time: 3.533s
[2K
| Adam | epoch: 012 | loss: 0.56047 - acc: 0.6852 -- iter: 160/169
[A[ATraining Step: 72  | total loss: [1m[32m0.54366[0m[0m | time: 5.404s
[2K
| Adam | epoch: 012 | loss: 0.54366 - acc: 0.6960 | val_loss: 0.45950 - val_acc: 0.8302 -- iter: 169/169
--
Training Step: 73  | total loss: [1m[32m0.56174[0m[0m | time: 0.916s
[2K
| Adam | epoch: 013 | loss: 0.56174 - acc: 0.6881 -- iter: 032/169
[A[ATraining Step: 74  | total loss: [1m[32m0.55444[0m[0m | time: 1.787s
[2K
| Adam | epoch: 013 | loss: 0.55444 - acc: 0.6983 -- iter: 064/169
[A[ATraining Step: 75  | total loss: [1m[32m0.52998[0m[0m | time: 2.713s
[2K
| Adam | epoch: 013 | loss: 0.52998 - acc: 0.7175 -- iter: 096/169
[A[ATraining Step: 76  | total loss: [1m[32m0.52187[0m[0m | time: 3.053s
[2K
| Adam | epoch: 013 | loss: 0.52187 - acc: 0.7277 -- iter: 128/169
[A[ATraining Step: 77  | total loss: [1m[32m0.48303[0m[0m | time: 3.403s
[2K
| Adam | epoch: 013 | loss: 0.48303 - acc: 0.7565 -- iter: 160/169
[A[ATraining Step: 78  | total loss: [1m[32m0.44532[0m[0m | time: 5.342s
[2K
| Adam | epoch: 013 | loss: 0.44532 - acc: 0.7820 | val_loss: 0.44491 - val_acc: 0.8491 -- iter: 169/169
--
Training Step: 79  | total loss: [1m[32m0.45459[0m[0m | time: 0.933s
[2K
| Adam | epoch: 014 | loss: 0.45459 - acc: 0.7787 -- iter: 032/169
[A[ATraining Step: 80  | total loss: [1m[32m0.43709[0m[0m | time: 1.831s
[2K
| Adam | epoch: 014 | loss: 0.43709 - acc: 0.7949 -- iter: 064/169
[A[ATraining Step: 81  | total loss: [1m[32m0.42847[0m[0m | time: 2.702s
[2K
| Adam | epoch: 014 | loss: 0.42847 - acc: 0.7999 -- iter: 096/169
[A[ATraining Step: 82  | total loss: [1m[32m0.43075[0m[0m | time: 3.590s
[2K
| Adam | epoch: 014 | loss: 0.43075 - acc: 0.7980 -- iter: 128/169
[A[ATraining Step: 83  | total loss: [1m[32m0.44418[0m[0m | time: 3.893s
[2K
| Adam | epoch: 014 | loss: 0.44418 - acc: 0.7932 -- iter: 160/169
[A[ATraining Step: 84  | total loss: [1m[32m0.40761[0m[0m | time: 5.219s
[2K
| Adam | epoch: 014 | loss: 0.40761 - acc: 0.8139 | val_loss: 0.55017 - val_acc: 0.7547 -- iter: 169/169
--
Training Step: 85  | total loss: [1m[32m0.37418[0m[0m | time: 0.982s
[2K
| Adam | epoch: 015 | loss: 0.37418 - acc: 0.8325 -- iter: 032/169
[A[ATraining Step: 86  | total loss: [1m[32m0.39488[0m[0m | time: 1.808s
[2K
| Adam | epoch: 015 | loss: 0.39488 - acc: 0.8149 -- iter: 064/169
[A[ATraining Step: 87  | total loss: [1m[32m0.39036[0m[0m | time: 2.696s
[2K
| Adam | epoch: 015 | loss: 0.39036 - acc: 0.8178 -- iter: 096/169
[A[ATraining Step: 88  | total loss: [1m[32m0.41087[0m[0m | time: 3.587s
[2K
| Adam | epoch: 015 | loss: 0.41087 - acc: 0.8110 -- iter: 128/169
[A[ATraining Step: 89  | total loss: [1m[32m0.44057[0m[0m | time: 4.498s
[2K
| Adam | epoch: 015 | loss: 0.44057 - acc: 0.8018 -- iter: 160/169
[A[ATraining Step: 90  | total loss: [1m[32m0.45472[0m[0m | time: 5.811s
[2K
| Adam | epoch: 015 | loss: 0.45472 - acc: 0.7997 | val_loss: 0.47041 - val_acc: 0.8302 -- iter: 169/169
--
Training Step: 91  | total loss: [1m[32m0.41641[0m[0m | time: 0.373s
[2K
| Adam | epoch: 016 | loss: 0.41641 - acc: 0.8197 -- iter: 032/169
[A[ATraining Step: 92  | total loss: [1m[32m0.38863[0m[0m | time: 1.339s
[2K
| Adam | epoch: 016 | loss: 0.38863 - acc: 0.8378 -- iter: 064/169
[A[ATraining Step: 93  | total loss: [1m[32m0.38604[0m[0m | time: 2.140s
[2K
| Adam | epoch: 016 | loss: 0.38604 - acc: 0.8352 -- iter: 096/169
[A[ATraining Step: 94  | total loss: [1m[32m0.38898[0m[0m | time: 2.989s
[2K
| Adam | epoch: 016 | loss: 0.38898 - acc: 0.8267 -- iter: 128/169
[A[ATraining Step: 95  | total loss: [1m[32m0.37954[0m[0m | time: 3.855s
[2K
| Adam | epoch: 016 | loss: 0.37954 - acc: 0.8315 -- iter: 160/169
[A[ATraining Step: 96  | total loss: [1m[32m0.37014[0m[0m | time: 5.719s
[2K
| Adam | epoch: 016 | loss: 0.37014 - acc: 0.8359 | val_loss: 0.41304 - val_acc: 0.8302 -- iter: 169/169
--
Training Step: 97  | total loss: [1m[32m0.35935[0m[0m | time: 0.359s
[2K
| Adam | epoch: 017 | loss: 0.35935 - acc: 0.8398 -- iter: 032/169
[A[ATraining Step: 98  | total loss: [1m[32m0.37192[0m[0m | time: 0.718s
[2K
| Adam | epoch: 017 | loss: 0.37192 - acc: 0.8447 -- iter: 064/169
[A[ATraining Step: 99  | total loss: [1m[32m0.37789[0m[0m | time: 1.743s
[2K
| Adam | epoch: 017 | loss: 0.37789 - acc: 0.8491 -- iter: 096/169
[A[ATraining Step: 100  | total loss: [1m[32m0.36236[0m[0m | time: 2.608s
[2K
| Adam | epoch: 017 | loss: 0.36236 - acc: 0.8548 -- iter: 128/169
[A[ATraining Step: 101  | total loss: [1m[32m0.35593[0m[0m | time: 3.470s
[2K
| Adam | epoch: 017 | loss: 0.35593 - acc: 0.8537 -- iter: 160/169
[A[ATraining Step: 102  | total loss: [1m[32m0.35213[0m[0m | time: 5.395s
[2K
| Adam | epoch: 017 | loss: 0.35213 - acc: 0.8559 | val_loss: 0.39318 - val_acc: 0.8679 -- iter: 169/169
--
Training Step: 103  | total loss: [1m[32m0.33492[0m[0m | time: 1.159s
[2K
| Adam | epoch: 018 | loss: 0.33492 - acc: 0.8640 -- iter: 032/169
[A[ATraining Step: 104  | total loss: [1m[32m0.33036[0m[0m | time: 1.524s
[2K
| Adam | epoch: 018 | loss: 0.33036 - acc: 0.8682 -- iter: 064/169
[A[ATraining Step: 105  | total loss: [1m[32m0.32024[0m[0m | time: 1.836s
[2K
| Adam | epoch: 018 | loss: 0.32024 - acc: 0.8814 -- iter: 096/169
[A[ATraining Step: 106  | total loss: [1m[32m0.30359[0m[0m | time: 2.566s
[2K
| Adam | epoch: 018 | loss: 0.30359 - acc: 0.8933 -- iter: 128/169
[A[ATraining Step: 107  | total loss: [1m[32m0.29287[0m[0m | time: 3.431s
[2K
| Adam | epoch: 018 | loss: 0.29287 - acc: 0.8977 -- iter: 160/169
[A[ATraining Step: 108  | total loss: [1m[32m0.28139[0m[0m | time: 5.369s
[2K
| Adam | epoch: 018 | loss: 0.28139 - acc: 0.9017 | val_loss: 0.45722 - val_acc: 0.8868 -- iter: 169/169
--
Training Step: 109  | total loss: [1m[32m0.27059[0m[0m | time: 1.028s
[2K
| Adam | epoch: 019 | loss: 0.27059 - acc: 0.9053 -- iter: 032/169
[A[ATraining Step: 110  | total loss: [1m[32m0.27683[0m[0m | time: 1.775s
[2K
| Adam | epoch: 019 | loss: 0.27683 - acc: 0.9022 -- iter: 064/169
[A[ATraining Step: 111  | total loss: [1m[32m0.26848[0m[0m | time: 2.082s
[2K
| Adam | epoch: 019 | loss: 0.26848 - acc: 0.9058 -- iter: 096/169
[A[ATraining Step: 112  | total loss: [1m[32m0.26418[0m[0m | time: 2.382s
[2K
| Adam | epoch: 019 | loss: 0.26418 - acc: 0.9041 -- iter: 128/169
[A[ATraining Step: 113  | total loss: [1m[32m0.25869[0m[0m | time: 3.278s
[2K
| Adam | epoch: 019 | loss: 0.25869 - acc: 0.9026 -- iter: 160/169
[A[ATraining Step: 114  | total loss: [1m[32m0.25442[0m[0m | time: 5.167s
[2K
| Adam | epoch: 019 | loss: 0.25442 - acc: 0.8998 | val_loss: 0.42881 - val_acc: 0.8868 -- iter: 169/169
--
Training Step: 115  | total loss: [1m[32m0.26934[0m[0m | time: 1.047s
[2K
| Adam | epoch: 020 | loss: 0.26934 - acc: 0.8942 -- iter: 032/169
[A[ATraining Step: 116  | total loss: [1m[32m0.25041[0m[0m | time: 2.121s
[2K
| Adam | epoch: 020 | loss: 0.25041 - acc: 0.9017 -- iter: 064/169
[A[ATraining Step: 117  | total loss: [1m[32m0.24800[0m[0m | time: 3.158s
[2K
| Adam | epoch: 020 | loss: 0.24800 - acc: 0.8990 -- iter: 096/169
[A[ATraining Step: 118  | total loss: [1m[32m0.23626[0m[0m | time: 3.387s
[2K
| Adam | epoch: 020 | loss: 0.23626 - acc: 0.9060 -- iter: 128/169
[A[ATraining Step: 119  | total loss: [1m[32m0.21536[0m[0m | time: 3.660s
[2K
| Adam | epoch: 020 | loss: 0.21536 - acc: 0.9154 -- iter: 160/169
[A[ATraining Step: 120  | total loss: [1m[32m0.19691[0m[0m | time: 5.565s
[2K
| Adam | epoch: 020 | loss: 0.19691 - acc: 0.9238 | val_loss: 0.34647 - val_acc: 0.9245 -- iter: 169/169
--
Training Step: 121  | total loss: [1m[32m0.19246[0m[0m | time: 1.040s
[2K
| Adam | epoch: 021 | loss: 0.19246 - acc: 0.9221 -- iter: 032/169
[A[ATraining Step: 122  | total loss: [1m[32m0.38066[0m[0m | time: 2.058s
[2K
| Adam | epoch: 021 | loss: 0.38066 - acc: 0.8705 -- iter: 064/169
[A[ATraining Step: 123  | total loss: [1m[32m0.38838[0m[0m | time: 2.808s
[2K
| Adam | epoch: 021 | loss: 0.38838 - acc: 0.8647 -- iter: 096/169
[A[ATraining Step: 124  | total loss: [1m[32m0.38094[0m[0m | time: 3.677s
[2K
| Adam | epoch: 021 | loss: 0.38094 - acc: 0.8688 -- iter: 128/169
[A[ATraining Step: 125  | total loss: [1m[32m0.36860[0m[0m | time: 3.985s
[2K
| Adam | epoch: 021 | loss: 0.36860 - acc: 0.8726 -- iter: 160/169
[A[ATraining Step: 126  | total loss: [1m[32m0.34184[0m[0m | time: 5.275s
[2K
| Adam | epoch: 021 | loss: 0.34184 - acc: 0.8853 | val_loss: 0.62636 - val_acc: 0.7358 -- iter: 169/169
--
Training Step: 127  | total loss: [1m[32m0.31476[0m[0m | time: 0.847s
[2K
| Adam | epoch: 022 | loss: 0.31476 - acc: 0.8968 -- iter: 032/169
[A[ATraining Step: 128  | total loss: [1m[32m0.34187[0m[0m | time: 1.902s
[2K
| Adam | epoch: 022 | loss: 0.34187 - acc: 0.8759 -- iter: 064/169
[A[ATraining Step: 129  | total loss: [1m[32m0.35736[0m[0m | time: 2.972s
[2K
| Adam | epoch: 022 | loss: 0.35736 - acc: 0.8664 -- iter: 096/169
[A[ATraining Step: 130  | total loss: [1m[32m0.37112[0m[0m | time: 3.765s
[2K
| Adam | epoch: 022 | loss: 0.37112 - acc: 0.8548 -- iter: 128/169
[A[ATraining Step: 131  | total loss: [1m[32m0.34707[0m[0m | time: 4.606s
[2K
| Adam | epoch: 022 | loss: 0.34707 - acc: 0.8693 -- iter: 160/169
[A[ATraining Step: 132  | total loss: [1m[32m0.33226[0m[0m | time: 5.922s
[2K
| Adam | epoch: 022 | loss: 0.33226 - acc: 0.8761 | val_loss: 0.43043 - val_acc: 0.8302 -- iter: 169/169
--
Training Step: 133  | total loss: [1m[32m0.31937[0m[0m | time: 0.278s
[2K
| Adam | epoch: 023 | loss: 0.31937 - acc: 0.8774 -- iter: 032/169
[A[ATraining Step: 134  | total loss: [1m[32m0.30530[0m[0m | time: 1.161s
[2K
| Adam | epoch: 023 | loss: 0.30530 - acc: 0.8785 -- iter: 064/169
[A[ATraining Step: 135  | total loss: [1m[32m0.29773[0m[0m | time: 2.182s
[2K
| Adam | epoch: 023 | loss: 0.29773 - acc: 0.8813 -- iter: 096/169
[A[ATraining Step: 136  | total loss: [1m[32m0.35686[0m[0m | time: 3.250s
[2K
| Adam | epoch: 023 | loss: 0.35686 - acc: 0.8682 -- iter: 128/169
[A[ATraining Step: 137  | total loss: [1m[32m0.33154[0m[0m | time: 4.079s
[2K
| Adam | epoch: 023 | loss: 0.33154 - acc: 0.8782 -- iter: 160/169
[A[ATraining Step: 138  | total loss: [1m[32m0.30780[0m[0m | time: 5.956s
[2K
| Adam | epoch: 023 | loss: 0.30780 - acc: 0.8904 | val_loss: 0.30767 - val_acc: 0.8868 -- iter: 169/169
--
Training Step: 139  | total loss: [1m[32m0.28850[0m[0m | time: 0.294s
[2K
| Adam | epoch: 024 | loss: 0.28850 - acc: 0.9014 -- iter: 032/169
[A[ATraining Step: 140  | total loss: [1m[32m0.27492[0m[0m | time: 0.586s
[2K
| Adam | epoch: 024 | loss: 0.27492 - acc: 0.9112 -- iter: 064/169
[A[ATraining Step: 141  | total loss: [1m[32m0.25717[0m[0m | time: 1.546s
[2K
| Adam | epoch: 024 | loss: 0.25717 - acc: 0.9201 -- iter: 096/169
[A[ATraining Step: 142  | total loss: [1m[32m0.25476[0m[0m | time: 2.567s
[2K
| Adam | epoch: 024 | loss: 0.25476 - acc: 0.9187 -- iter: 128/169
[A[ATraining Step: 143  | total loss: [1m[32m0.23740[0m[0m | time: 3.566s
[2K
| Adam | epoch: 024 | loss: 0.23740 - acc: 0.9237 -- iter: 160/169
[A[ATraining Step: 144  | total loss: [1m[32m0.22379[0m[0m | time: 5.386s
[2K
| Adam | epoch: 024 | loss: 0.22379 - acc: 0.9314 | val_loss: 0.35794 - val_acc: 0.8679 -- iter: 169/169
--
Training Step: 145  | total loss: [1m[32m0.21382[0m[0m | time: 0.961s
[2K
| Adam | epoch: 025 | loss: 0.21382 - acc: 0.9351 -- iter: 032/169
[A[ATraining Step: 146  | total loss: [1m[32m0.20208[0m[0m | time: 1.223s
[2K
| Adam | epoch: 025 | loss: 0.20208 - acc: 0.9385 -- iter: 064/169
[A[ATraining Step: 147  | total loss: [1m[32m0.20078[0m[0m | time: 1.479s
[2K
| Adam | epoch: 025 | loss: 0.20078 - acc: 0.9446 -- iter: 096/169
[A[ATraining Step: 148  | total loss: [1m[32m0.18938[0m[0m | time: 2.531s
[2K
| Adam | epoch: 025 | loss: 0.18938 - acc: 0.9502 -- iter: 128/169
[A[ATraining Step: 149  | total loss: [1m[32m0.17710[0m[0m | time: 3.565s
[2K
| Adam | epoch: 025 | loss: 0.17710 - acc: 0.9520 -- iter: 160/169
[A[ATraining Step: 150  | total loss: [1m[32m0.28659[0m[0m | time: 5.540s
[2K
| Adam | epoch: 025 | loss: 0.28659 - acc: 0.9318 | val_loss: 0.34900 - val_acc: 0.8679 -- iter: 169/169
--
Training Step: 151  | total loss: [1m[32m0.26636[0m[0m | time: 0.907s
[2K
| Adam | epoch: 026 | loss: 0.26636 - acc: 0.9386 -- iter: 032/169
[A[ATraining Step: 152  | total loss: [1m[32m0.24797[0m[0m | time: 1.863s
[2K
| Adam | epoch: 026 | loss: 0.24797 - acc: 0.9416 -- iter: 064/169
[A[ATraining Step: 153  | total loss: [1m[32m0.23114[0m[0m | time: 2.147s
[2K
| Adam | epoch: 026 | loss: 0.23114 - acc: 0.9475 -- iter: 096/169
[A[ATraining Step: 154  | total loss: [1m[32m0.21728[0m[0m | time: 2.472s
[2K
| Adam | epoch: 026 | loss: 0.21728 - acc: 0.9527 -- iter: 128/169
[A[ATraining Step: 155  | total loss: [1m[32m0.20356[0m[0m | time: 3.383s
[2K
| Adam | epoch: 026 | loss: 0.20356 - acc: 0.9575 -- iter: 160/169
[A[ATraining Step: 156  | total loss: [1m[32m0.18659[0m[0m | time: 5.439s
[2K
| Adam | epoch: 026 | loss: 0.18659 - acc: 0.9617 | val_loss: 0.27928 - val_acc: 0.9245 -- iter: 169/169
--
Training Step: 157  | total loss: [1m[32m0.17326[0m[0m | time: 0.963s
[2K
| Adam | epoch: 027 | loss: 0.17326 - acc: 0.9655 -- iter: 032/169
[A[ATraining Step: 158  | total loss: [1m[32m0.15942[0m[0m | time: 1.970s
[2K
| Adam | epoch: 027 | loss: 0.15942 - acc: 0.9690 -- iter: 064/169
[A[ATraining Step: 159  | total loss: [1m[32m0.14660[0m[0m | time: 2.954s
[2K
| Adam | epoch: 027 | loss: 0.14660 - acc: 0.9721 -- iter: 096/169
[A[ATraining Step: 160  | total loss: [1m[32m0.13445[0m[0m | time: 3.194s
[2K
| Adam | epoch: 027 | loss: 0.13445 - acc: 0.9749 -- iter: 128/169
[A[ATraining Step: 161  | total loss: [1m[32m0.12189[0m[0m | time: 3.510s
[2K
| Adam | epoch: 027 | loss: 0.12189 - acc: 0.9774 -- iter: 160/169
[A[ATraining Step: 162  | total loss: [1m[32m0.11029[0m[0m | time: 5.545s
[2K
| Adam | epoch: 027 | loss: 0.11029 - acc: 0.9797 | val_loss: 0.34362 - val_acc: 0.9245 -- iter: 169/169
--
Training Step: 163  | total loss: [1m[32m0.10140[0m[0m | time: 0.902s
[2K
| Adam | epoch: 028 | loss: 0.10140 - acc: 0.9817 -- iter: 032/169
[A[ATraining Step: 164  | total loss: [1m[32m0.10423[0m[0m | time: 1.860s
[2K
| Adam | epoch: 028 | loss: 0.10423 - acc: 0.9804 -- iter: 064/169
[A[ATraining Step: 165  | total loss: [1m[32m0.09595[0m[0m | time: 2.830s
[2K
| Adam | epoch: 028 | loss: 0.09595 - acc: 0.9824 -- iter: 096/169
[A[ATraining Step: 166  | total loss: [1m[32m0.09148[0m[0m | time: 3.846s
[2K
| Adam | epoch: 028 | loss: 0.09148 - acc: 0.9810 -- iter: 128/169
[A[ATraining Step: 167  | total loss: [1m[32m0.08355[0m[0m | time: 4.134s
[2K
| Adam | epoch: 028 | loss: 0.08355 - acc: 0.9829 -- iter: 160/169
[A[ATraining Step: 168  | total loss: [1m[32m0.07537[0m[0m | time: 5.412s
[2K
| Adam | epoch: 028 | loss: 0.07537 - acc: 0.9846 | val_loss: 0.58806 - val_acc: 0.9057 -- iter: 169/169
--
Training Step: 169  | total loss: [1m[32m0.06823[0m[0m | time: 0.875s
[2K
| Adam | epoch: 029 | loss: 0.06823 - acc: 0.9861 -- iter: 032/169
[A[ATraining Step: 170  | total loss: [1m[32m0.06539[0m[0m | time: 1.789s
[2K
| Adam | epoch: 029 | loss: 0.06539 - acc: 0.9844 -- iter: 064/169
[A[ATraining Step: 171  | total loss: [1m[32m0.27652[0m[0m | time: 2.687s
[2K
| Adam | epoch: 029 | loss: 0.27652 - acc: 0.9516 -- iter: 096/169
[A[ATraining Step: 172  | total loss: [1m[32m0.25087[0m[0m | time: 3.606s
[2K
| Adam | epoch: 029 | loss: 0.25087 - acc: 0.9564 -- iter: 128/169
[A[ATraining Step: 173  | total loss: [1m[32m0.23061[0m[0m | time: 4.573s
[2K
| Adam | epoch: 029 | loss: 0.23061 - acc: 0.9577 -- iter: 160/169
[A[ATraining Step: 174  | total loss: [1m[32m0.20839[0m[0m | time: 5.910s
[2K
| Adam | epoch: 029 | loss: 0.20839 - acc: 0.9619 | val_loss: 0.31546 - val_acc: 0.9434 -- iter: 169/169
--
Training Step: 175  | total loss: [1m[32m0.19305[0m[0m | time: 0.334s
[2K
| Adam | epoch: 030 | loss: 0.19305 - acc: 0.9657 -- iter: 032/169
[A[ATraining Step: 176  | total loss: [1m[32m0.17746[0m[0m | time: 1.317s
[2K
| Adam | epoch: 030 | loss: 0.17746 - acc: 0.9691 -- iter: 064/169
[A[ATraining Step: 177  | total loss: [1m[32m0.16109[0m[0m | time: 2.338s
[2K
| Adam | epoch: 030 | loss: 0.16109 - acc: 0.9722 -- iter: 096/169
[A[ATraining Step: 178  | total loss: [1m[32m0.18118[0m[0m | time: 3.237s
[2K
| Adam | epoch: 030 | loss: 0.18118 - acc: 0.9656 -- iter: 128/169
[A[ATraining Step: 179  | total loss: [1m[32m0.16546[0m[0m | time: 4.095s
[2K
| Adam | epoch: 030 | loss: 0.16546 - acc: 0.9691 -- iter: 160/169
[A[ATraining Step: 180  | total loss: [1m[32m0.15379[0m[0m | time: 6.142s
[2K
| Adam | epoch: 030 | loss: 0.15379 - acc: 0.9722 | val_loss: 0.27535 - val_acc: 0.9434 -- iter: 169/169
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9439655172413793
Validation AUPRC:0.9583795333795333
Test AUC:0.9910714285714286
Test AUPRC:0.9894179894179895
BestTestF1Score	0.95	0.92	0.96	0.95	0.95	20	1	31	1	0.68
BestTestMCCScore	0.95	0.92	0.96	0.95	0.95	20	1	31	1	0.68
BestTestAccuracyScore	0.95	0.92	0.96	0.95	0.95	20	1	31	1	0.68
BestValidationF1Score	0.93	0.89	0.94	1.0	0.88	21	0	29	3	0.68
BestValidationMCC	0.93	0.89	0.94	1.0	0.88	21	0	29	3	0.68
BestValidationAccuracy	0.93	0.89	0.94	1.0	0.88	21	0	29	3	0.68
TestPredictions (Threshold:0.68)
CHEMBL3827944,TP,ACT,0.9700000286102295	CHEMBL456378,TN,INACT,0.019999999552965164	CHEMBL1734241,TN,INACT,0.019999999552965164	CHEMBL2392237,TN,INACT,0.019999999552965164	CHEMBL487526,TN,INACT,0.20999999344348907	CHEMBL318188,TN,INACT,0.029999999329447746	CHEMBL2392238,TN,INACT,0.019999999552965164	CHEMBL525530,TN,INACT,0.0	CHEMBL3828470,TP,ACT,0.9700000286102295	CHEMBL3799679,TP,ACT,0.9900000095367432	CHEMBL1933806,FP,INACT,0.6800000071525574	CHEMBL2392390,TN,INACT,0.019999999552965164	CHEMBL551936,TN,INACT,0.009999999776482582	CHEMBL3797689,TP,ACT,0.9399999976158142	CHEMBL3828572,TP,ACT,0.949999988079071	CHEMBL3775519,FN,ACT,0.07999999821186066	CHEMBL3828071,TP,ACT,0.9700000286102295	CHEMBL3798778,TP,ACT,0.9900000095367432	CHEMBL552136,TN,INACT,0.009999999776482582	CHEMBL456965,TN,INACT,0.0	CHEMBL3774400,TP,ACT,0.9100000262260437	CHEMBL2392234,TN,INACT,0.019999999552965164	CHEMBL456113,TN,INACT,0.019999999552965164	CHEMBL3798853,TP,ACT,0.9900000095367432	CHEMBL498520,TN,INACT,0.009999999776482582	CHEMBL3827482,TP,ACT,0.9700000286102295	CHEMBL456796,TN,INACT,0.009999999776482582	CHEMBL334248,TN,INACT,0.029999999329447746	CHEMBL521201,TN,INACT,0.49000000953674316	CHEMBL3798726,TP,ACT,0.9700000286102295	CHEMBL3827118,TP,ACT,0.9100000262260437	CHEMBL3828553,TP,ACT,0.949999988079071	CHEMBL1287945,TN,INACT,0.009999999776482582	CHEMBL470851,TN,INACT,0.029999999329447746	CHEMBL488646,TN,INACT,0.1599999964237213	CHEMBL3798611,TP,ACT,0.9599999785423279	CHEMBL559882,TN,INACT,0.009999999776482582	CHEMBL3828430,TP,ACT,0.9700000286102295	CHEMBL469770,TN,INACT,0.03999999910593033	CHEMBL1288069,TN,INACT,0.019999999552965164	CHEMBL388978,TP,ACT,0.9300000071525574	CHEMBL102622,TN,INACT,0.09000000357627869	CHEMBL3798382,TP,ACT,0.9800000190734863	CHEMBL1767275,TN,INACT,0.009999999776482582	CHEMBL3774885,TP,ACT,0.9399999976158142	CHEMBL1082152,TN,INACT,0.10000000149011612	CHEMBL456143,TN,INACT,0.0	CHEMBL482919,TN,INACT,0.019999999552965164	CHEMBL3828689,TP,ACT,0.9599999785423279	CHEMBL2392223,TN,INACT,0.009999999776482582	CHEMBL560278,TN,INACT,0.009999999776482582	CHEMBL457191,TN,INACT,0.0	CHEMBL3775317,TP,ACT,0.9300000071525574	

