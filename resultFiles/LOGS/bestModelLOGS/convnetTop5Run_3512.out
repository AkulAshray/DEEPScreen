ImageNetInceptionV2 CHEMBL4427 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	364
Number of inactive compounds :	364
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4427_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4427_adam_0.0005_15_0.6/
---------------------------------
Training samples: 428
Validation samples: 135
--
Training Step: 1  | time: 46.544s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/428
[A[ATraining Step: 2  | total loss: [1m[32m0.61961[0m[0m | time: 57.657s
[2K
| Adam | epoch: 001 | loss: 0.61961 - acc: 0.4500 -- iter: 064/428
[A[ATraining Step: 3  | total loss: [1m[32m0.58858[0m[0m | time: 68.837s
[2K
| Adam | epoch: 001 | loss: 0.58858 - acc: 0.6955 -- iter: 096/428
[A[ATraining Step: 4  | total loss: [1m[32m0.75356[0m[0m | time: 83.363s
[2K
| Adam | epoch: 001 | loss: 0.75356 - acc: 0.6661 -- iter: 128/428
[A[ATraining Step: 5  | total loss: [1m[32m0.75462[0m[0m | time: 102.548s
[2K
| Adam | epoch: 001 | loss: 0.75462 - acc: 0.6809 -- iter: 160/428
[A[ATraining Step: 6  | total loss: [1m[32m0.72374[0m[0m | time: 122.055s
[2K
| Adam | epoch: 001 | loss: 0.72374 - acc: 0.6048 -- iter: 192/428
[A[ATraining Step: 7  | total loss: [1m[32m0.65810[0m[0m | time: 138.874s
[2K
| Adam | epoch: 001 | loss: 0.65810 - acc: 0.6544 -- iter: 224/428
[A[ATraining Step: 8  | total loss: [1m[32m0.59660[0m[0m | time: 159.045s
[2K
| Adam | epoch: 001 | loss: 0.59660 - acc: 0.7258 -- iter: 256/428
[A[ATraining Step: 9  | total loss: [1m[32m0.56935[0m[0m | time: 175.779s
[2K
| Adam | epoch: 001 | loss: 0.56935 - acc: 0.7220 -- iter: 288/428
[A[ATraining Step: 10  | total loss: [1m[32m0.58220[0m[0m | time: 194.661s
[2K
| Adam | epoch: 001 | loss: 0.58220 - acc: 0.6735 -- iter: 320/428
[A[ATraining Step: 11  | total loss: [1m[32m0.68318[0m[0m | time: 211.478s
[2K
| Adam | epoch: 001 | loss: 0.68318 - acc: 0.6061 -- iter: 352/428
[A[ATraining Step: 12  | total loss: [1m[32m0.80212[0m[0m | time: 228.480s
[2K
| Adam | epoch: 001 | loss: 0.80212 - acc: 0.5865 -- iter: 384/428
[A[ATraining Step: 13  | total loss: [1m[32m0.71196[0m[0m | time: 244.487s
[2K
| Adam | epoch: 001 | loss: 0.71196 - acc: 0.6566 -- iter: 416/428
[A[ATraining Step: 14  | total loss: [1m[32m0.76554[0m[0m | time: 275.054s
[2K
| Adam | epoch: 001 | loss: 0.76554 - acc: 0.6181 | val_loss: 0.98768 - val_acc: 0.5111 -- iter: 428/428
--
Training Step: 15  | total loss: [1m[32m0.55304[0m[0m | time: 6.553s
[2K
| Adam | epoch: 002 | loss: 0.55304 - acc: 0.7349 -- iter: 032/428
[A[ATraining Step: 16  | total loss: [1m[32m0.40262[0m[0m | time: 19.951s
[2K
| Adam | epoch: 002 | loss: 0.40262 - acc: 0.8343 -- iter: 064/428
[A[ATraining Step: 17  | total loss: [1m[32m0.43499[0m[0m | time: 33.500s
[2K
| Adam | epoch: 002 | loss: 0.43499 - acc: 0.8040 -- iter: 096/428
[A[ATraining Step: 18  | total loss: [1m[32m0.49763[0m[0m | time: 46.837s
[2K
| Adam | epoch: 002 | loss: 0.49763 - acc: 0.7528 -- iter: 128/428
[A[ATraining Step: 19  | total loss: [1m[32m0.43814[0m[0m | time: 60.872s
[2K
| Adam | epoch: 002 | loss: 0.43814 - acc: 0.8040 -- iter: 160/428
[A[ATraining Step: 20  | total loss: [1m[32m0.40008[0m[0m | time: 74.705s
[2K
| Adam | epoch: 002 | loss: 0.40008 - acc: 0.8268 -- iter: 192/428
[A[ATraining Step: 21  | total loss: [1m[32m0.45623[0m[0m | time: 88.653s
[2K
| Adam | epoch: 002 | loss: 0.45623 - acc: 0.7836 -- iter: 224/428
[A[ATraining Step: 22  | total loss: [1m[32m0.43236[0m[0m | time: 102.404s
[2K
| Adam | epoch: 002 | loss: 0.43236 - acc: 0.8016 -- iter: 256/428
[A[ATraining Step: 23  | total loss: [1m[32m0.43002[0m[0m | time: 115.878s
[2K
| Adam | epoch: 002 | loss: 0.43002 - acc: 0.8048 -- iter: 288/428
[A[ATraining Step: 24  | total loss: [1m[32m0.39554[0m[0m | time: 129.521s
[2K
| Adam | epoch: 002 | loss: 0.39554 - acc: 0.8245 -- iter: 320/428
[A[ATraining Step: 25  | total loss: [1m[32m0.43885[0m[0m | time: 143.038s
[2K
| Adam | epoch: 002 | loss: 0.43885 - acc: 0.8042 -- iter: 352/428
[A[ATraining Step: 26  | total loss: [1m[32m0.41848[0m[0m | time: 156.842s
[2K
| Adam | epoch: 002 | loss: 0.41848 - acc: 0.8064 -- iter: 384/428
[A[ATraining Step: 27  | total loss: [1m[32m0.42030[0m[0m | time: 170.463s
[2K
| Adam | epoch: 002 | loss: 0.42030 - acc: 0.7839 -- iter: 416/428
[A[ATraining Step: 28  | total loss: [1m[32m0.35154[0m[0m | time: 194.616s
[2K
| Adam | epoch: 002 | loss: 0.35154 - acc: 0.8301 | val_loss: 0.71927 - val_acc: 0.5111 -- iter: 428/428
--
Training Step: 29  | total loss: [1m[32m0.31711[0m[0m | time: 6.701s
[2K
| Adam | epoch: 003 | loss: 0.31711 - acc: 0.8562 -- iter: 032/428
[A[ATraining Step: 30  | total loss: [1m[32m0.33330[0m[0m | time: 12.942s
[2K
| Adam | epoch: 003 | loss: 0.33330 - acc: 0.8508 -- iter: 064/428
[A[ATraining Step: 31  | total loss: [1m[32m0.28856[0m[0m | time: 26.417s
[2K
| Adam | epoch: 003 | loss: 0.28856 - acc: 0.8852 -- iter: 096/428
[A[ATraining Step: 32  | total loss: [1m[32m0.34092[0m[0m | time: 39.792s
[2K
| Adam | epoch: 003 | loss: 0.34092 - acc: 0.8618 -- iter: 128/428
[A[ATraining Step: 33  | total loss: [1m[32m0.29841[0m[0m | time: 53.088s
[2K
| Adam | epoch: 003 | loss: 0.29841 - acc: 0.8853 -- iter: 160/428
[A[ATraining Step: 34  | total loss: [1m[32m0.28500[0m[0m | time: 65.123s
[2K
| Adam | epoch: 003 | loss: 0.28500 - acc: 0.8831 -- iter: 192/428
[A[ATraining Step: 35  | total loss: [1m[32m0.24561[0m[0m | time: 73.644s
[2K
| Adam | epoch: 003 | loss: 0.24561 - acc: 0.9010 -- iter: 224/428
[A[ATraining Step: 36  | total loss: [1m[32m0.22373[0m[0m | time: 86.225s
[2K
| Adam | epoch: 003 | loss: 0.22373 - acc: 0.9085 -- iter: 256/428
[A[ATraining Step: 37  | total loss: [1m[32m0.23540[0m[0m | time: 100.043s
[2K
| Adam | epoch: 003 | loss: 0.23540 - acc: 0.8955 -- iter: 288/428
[A[ATraining Step: 38  | total loss: [1m[32m0.23176[0m[0m | time: 110.702s
[2K
| Adam | epoch: 003 | loss: 0.23176 - acc: 0.8976 -- iter: 320/428
[A[ATraining Step: 39  | total loss: [1m[32m0.23462[0m[0m | time: 119.396s
[2K
| Adam | epoch: 003 | loss: 0.23462 - acc: 0.8993 -- iter: 352/428
[A[ATraining Step: 40  | total loss: [1m[32m0.24226[0m[0m | time: 128.020s
[2K
| Adam | epoch: 003 | loss: 0.24226 - acc: 0.8947 -- iter: 384/428
[A[ATraining Step: 41  | total loss: [1m[32m0.26285[0m[0m | time: 136.598s
[2K
| Adam | epoch: 003 | loss: 0.26285 - acc: 0.8911 -- iter: 416/428
[A[ATraining Step: 42  | total loss: [1m[32m0.26024[0m[0m | time: 156.483s
[2K
| Adam | epoch: 003 | loss: 0.26024 - acc: 0.8995 | val_loss: 0.77692 - val_acc: 0.5037 -- iter: 428/428
--
Training Step: 43  | total loss: [1m[32m0.34772[0m[0m | time: 13.880s
[2K
| Adam | epoch: 004 | loss: 0.34772 - acc: 0.8841 -- iter: 032/428
[A[ATraining Step: 44  | total loss: [1m[32m0.31180[0m[0m | time: 20.012s
[2K
| Adam | epoch: 004 | loss: 0.31180 - acc: 0.8988 -- iter: 064/428
[A[ATraining Step: 45  | total loss: [1m[32m0.29165[0m[0m | time: 26.522s
[2K
| Adam | epoch: 004 | loss: 0.29165 - acc: 0.9018 -- iter: 096/428
[A[ATraining Step: 46  | total loss: [1m[32m0.25134[0m[0m | time: 40.622s
[2K
| Adam | epoch: 004 | loss: 0.25134 - acc: 0.9182 -- iter: 128/428
[A[ATraining Step: 47  | total loss: [1m[32m0.26116[0m[0m | time: 54.108s
[2K
| Adam | epoch: 004 | loss: 0.26116 - acc: 0.9111 -- iter: 160/428
[A[ATraining Step: 48  | total loss: [1m[32m0.25966[0m[0m | time: 67.724s
[2K
| Adam | epoch: 004 | loss: 0.25966 - acc: 0.9053 -- iter: 192/428
[A[ATraining Step: 49  | total loss: [1m[32m0.24857[0m[0m | time: 81.757s
[2K
| Adam | epoch: 004 | loss: 0.24857 - acc: 0.9055 -- iter: 224/428
[A[ATraining Step: 50  | total loss: [1m[32m0.23973[0m[0m | time: 95.181s
[2K
| Adam | epoch: 004 | loss: 0.23973 - acc: 0.9153 -- iter: 256/428
[A[ATraining Step: 51  | total loss: [1m[32m0.22255[0m[0m | time: 109.242s
[2K
| Adam | epoch: 004 | loss: 0.22255 - acc: 0.9234 -- iter: 288/428
[A[ATraining Step: 52  | total loss: [1m[32m0.23121[0m[0m | time: 122.739s
[2K
| Adam | epoch: 004 | loss: 0.23121 - acc: 0.9162 -- iter: 320/428
[A[ATraining Step: 53  | total loss: [1m[32m0.21322[0m[0m | time: 136.918s
[2K
| Adam | epoch: 004 | loss: 0.21322 - acc: 0.9239 -- iter: 352/428
[A[ATraining Step: 54  | total loss: [1m[32m0.20441[0m[0m | time: 150.999s
[2K
| Adam | epoch: 004 | loss: 0.20441 - acc: 0.9304 -- iter: 384/428
[A[ATraining Step: 55  | total loss: [1m[32m0.20388[0m[0m | time: 164.680s
[2K
| Adam | epoch: 004 | loss: 0.20388 - acc: 0.9270 -- iter: 416/428
[A[ATraining Step: 56  | total loss: [1m[32m0.19423[0m[0m | time: 189.484s
[2K
| Adam | epoch: 004 | loss: 0.19423 - acc: 0.9329 | val_loss: 1.00051 - val_acc: 0.5481 -- iter: 428/428
--
Training Step: 57  | total loss: [1m[32m0.21275[0m[0m | time: 13.997s
[2K
| Adam | epoch: 005 | loss: 0.21275 - acc: 0.9292 -- iter: 032/428
[A[ATraining Step: 58  | total loss: [1m[32m0.18620[0m[0m | time: 27.975s
[2K
| Adam | epoch: 005 | loss: 0.18620 - acc: 0.9388 -- iter: 064/428
[A[ATraining Step: 59  | total loss: [1m[32m0.19107[0m[0m | time: 34.235s
[2K
| Adam | epoch: 005 | loss: 0.19107 - acc: 0.9345 -- iter: 096/428
[A[ATraining Step: 60  | total loss: [1m[32m0.17410[0m[0m | time: 40.859s
[2K
| Adam | epoch: 005 | loss: 0.17410 - acc: 0.9431 -- iter: 128/428
[A[ATraining Step: 61  | total loss: [1m[32m0.15258[0m[0m | time: 54.962s
[2K
| Adam | epoch: 005 | loss: 0.15258 - acc: 0.9505 -- iter: 160/428
[A[ATraining Step: 62  | total loss: [1m[32m0.14989[0m[0m | time: 68.838s
[2K
| Adam | epoch: 005 | loss: 0.14989 - acc: 0.9529 -- iter: 192/428
[A[ATraining Step: 63  | total loss: [1m[32m0.13624[0m[0m | time: 82.705s
[2K
| Adam | epoch: 005 | loss: 0.13624 - acc: 0.9589 -- iter: 224/428
[A[ATraining Step: 64  | total loss: [1m[32m0.12250[0m[0m | time: 96.655s
[2K
| Adam | epoch: 005 | loss: 0.12250 - acc: 0.9640 -- iter: 256/428
[A[ATraining Step: 65  | total loss: [1m[32m0.11979[0m[0m | time: 110.729s
[2K
| Adam | epoch: 005 | loss: 0.11979 - acc: 0.9607 -- iter: 288/428
[A[ATraining Step: 66  | total loss: [1m[32m0.12857[0m[0m | time: 124.834s
[2K
| Adam | epoch: 005 | loss: 0.12857 - acc: 0.9579 -- iter: 320/428
[A[ATraining Step: 67  | total loss: [1m[32m0.13189[0m[0m | time: 138.755s
[2K
| Adam | epoch: 005 | loss: 0.13189 - acc: 0.9592 -- iter: 352/428
[A[ATraining Step: 68  | total loss: [1m[32m0.12425[0m[0m | time: 152.702s
[2K
| Adam | epoch: 005 | loss: 0.12425 - acc: 0.9603 -- iter: 384/428
[A[ATraining Step: 69  | total loss: [1m[32m0.11687[0m[0m | time: 166.882s
[2K
| Adam | epoch: 005 | loss: 0.11687 - acc: 0.9613 -- iter: 416/428
[A[ATraining Step: 70  | total loss: [1m[32m0.11817[0m[0m | time: 192.000s
[2K
| Adam | epoch: 005 | loss: 0.11817 - acc: 0.9550 | val_loss: 0.81968 - val_acc: 0.7333 -- iter: 428/428
--
Training Step: 71  | total loss: [1m[32m0.10837[0m[0m | time: 11.086s
[2K
| Adam | epoch: 006 | loss: 0.10837 - acc: 0.9601 -- iter: 032/428
[A[ATraining Step: 72  | total loss: [1m[32m0.10196[0m[0m | time: 19.853s
[2K
| Adam | epoch: 006 | loss: 0.10196 - acc: 0.9646 -- iter: 064/428
[A[ATraining Step: 73  | total loss: [1m[32m0.14947[0m[0m | time: 28.628s
[2K
| Adam | epoch: 006 | loss: 0.14947 - acc: 0.9581 -- iter: 096/428
[A[ATraining Step: 74  | total loss: [1m[32m0.19336[0m[0m | time: 32.297s
[2K
| Adam | epoch: 006 | loss: 0.19336 - acc: 0.9490 -- iter: 128/428
[A[ATraining Step: 75  | total loss: [1m[32m0.18858[0m[0m | time: 35.979s
[2K
| Adam | epoch: 006 | loss: 0.18858 - acc: 0.9455 -- iter: 160/428
[A[ATraining Step: 76  | total loss: [1m[32m0.16993[0m[0m | time: 46.098s
[2K
| Adam | epoch: 006 | loss: 0.16993 - acc: 0.9513 -- iter: 192/428
[A[ATraining Step: 77  | total loss: [1m[32m0.15864[0m[0m | time: 58.744s
[2K
| Adam | epoch: 006 | loss: 0.15864 - acc: 0.9532 -- iter: 224/428
[A[ATraining Step: 78  | total loss: [1m[32m0.14409[0m[0m | time: 74.810s
[2K
| Adam | epoch: 006 | loss: 0.14409 - acc: 0.9581 -- iter: 256/428
[A[ATraining Step: 79  | total loss: [1m[32m0.16114[0m[0m | time: 92.820s
[2K
| Adam | epoch: 006 | loss: 0.16114 - acc: 0.9559 -- iter: 288/428
[A[ATraining Step: 80  | total loss: [1m[32m0.15089[0m[0m | time: 121.025s
[2K
| Adam | epoch: 006 | loss: 0.15089 - acc: 0.9604 -- iter: 320/428
[A[ATraining Step: 81  | total loss: [1m[32m0.14445[0m[0m | time: 142.188s
[2K
| Adam | epoch: 006 | loss: 0.14445 - acc: 0.9581 -- iter: 352/428
[A[ATraining Step: 82  | total loss: [1m[32m0.14482[0m[0m | time: 184.512s
[2K
| Adam | epoch: 006 | loss: 0.14482 - acc: 0.9529 -- iter: 384/428
[A[ATraining Step: 83  | total loss: [1m[32m0.16457[0m[0m | time: 211.725s
[2K
| Adam | epoch: 006 | loss: 0.16457 - acc: 0.9514 -- iter: 416/428
[A[ATraining Step: 84  | total loss: [1m[32m0.16466[0m[0m | time: 244.856s
[2K
| Adam | epoch: 006 | loss: 0.16466 - acc: 0.9531 | val_loss: 4.62031 - val_acc: 0.5259 -- iter: 428/428
--
Training Step: 85  | total loss: [1m[32m0.16877[0m[0m | time: 14.243s
[2K
| Adam | epoch: 007 | loss: 0.16877 - acc: 0.9516 -- iter: 032/428
[A[ATraining Step: 86  | total loss: [1m[32m0.15746[0m[0m | time: 28.130s
[2K
| Adam | epoch: 007 | loss: 0.15746 - acc: 0.9533 -- iter: 064/428
[A[ATraining Step: 87  | total loss: [1m[32m0.16071[0m[0m | time: 42.070s
[2K
| Adam | epoch: 007 | loss: 0.16071 - acc: 0.9517 -- iter: 096/428
[A[ATraining Step: 88  | total loss: [1m[32m0.16057[0m[0m | time: 56.217s
[2K
| Adam | epoch: 007 | loss: 0.16057 - acc: 0.9534 -- iter: 128/428
[A[ATraining Step: 89  | total loss: [1m[32m0.14923[0m[0m | time: 62.809s
[2K
| Adam | epoch: 007 | loss: 0.14923 - acc: 0.9549 -- iter: 160/428
[A[ATraining Step: 90  | total loss: [1m[32m0.14122[0m[0m | time: 68.909s
[2K
| Adam | epoch: 007 | loss: 0.14122 - acc: 0.9595 -- iter: 192/428
[A[ATraining Step: 91  | total loss: [1m[32m0.12961[0m[0m | time: 82.962s
[2K
| Adam | epoch: 007 | loss: 0.12961 - acc: 0.9635 -- iter: 224/428
[A[ATraining Step: 92  | total loss: [1m[32m0.14333[0m[0m | time: 97.036s
[2K
| Adam | epoch: 007 | loss: 0.14333 - acc: 0.9609 -- iter: 256/428
[A[ATraining Step: 93  | total loss: [1m[32m0.13942[0m[0m | time: 110.590s
[2K
| Adam | epoch: 007 | loss: 0.13942 - acc: 0.9617 -- iter: 288/428
[A[ATraining Step: 94  | total loss: [1m[32m0.16029[0m[0m | time: 124.429s
[2K
| Adam | epoch: 007 | loss: 0.16029 - acc: 0.9468 -- iter: 320/428
[A[ATraining Step: 95  | total loss: [1m[32m0.15331[0m[0m | time: 138.466s
[2K
| Adam | epoch: 007 | loss: 0.15331 - acc: 0.9458 -- iter: 352/428
[A[ATraining Step: 96  | total loss: [1m[32m0.14189[0m[0m | time: 152.470s
[2K
| Adam | epoch: 007 | loss: 0.14189 - acc: 0.9513 -- iter: 384/428
[A[ATraining Step: 97  | total loss: [1m[32m0.13320[0m[0m | time: 166.739s
[2K
| Adam | epoch: 007 | loss: 0.13320 - acc: 0.9561 -- iter: 416/428
[A[ATraining Step: 98  | total loss: [1m[32m0.13003[0m[0m | time: 195.190s
[2K
| Adam | epoch: 007 | loss: 0.13003 - acc: 0.9574 | val_loss: 1.67783 - val_acc: 0.5852 -- iter: 428/428
--
Training Step: 99  | total loss: [1m[32m0.12125[0m[0m | time: 18.611s
[2K
| Adam | epoch: 008 | loss: 0.12125 - acc: 0.9617 -- iter: 032/428
[A[ATraining Step: 100  | total loss: [1m[32m0.11435[0m[0m | time: 36.739s
[2K
| Adam | epoch: 008 | loss: 0.11435 - acc: 0.9655 -- iter: 064/428
[A[ATraining Step: 101  | total loss: [1m[32m0.12201[0m[0m | time: 54.767s
[2K
| Adam | epoch: 008 | loss: 0.12201 - acc: 0.9596 -- iter: 096/428
[A[ATraining Step: 102  | total loss: [1m[32m0.11724[0m[0m | time: 72.566s
[2K
| Adam | epoch: 008 | loss: 0.11724 - acc: 0.9605 -- iter: 128/428
[A[ATraining Step: 103  | total loss: [1m[32m0.15553[0m[0m | time: 92.934s
[2K
| Adam | epoch: 008 | loss: 0.15553 - acc: 0.9582 -- iter: 160/428
[A[ATraining Step: 104  | total loss: [1m[32m0.14206[0m[0m | time: 101.370s
[2K
| Adam | epoch: 008 | loss: 0.14206 - acc: 0.9624 -- iter: 192/428
[A[ATraining Step: 105  | total loss: [1m[32m0.13699[0m[0m | time: 111.179s
[2K
| Adam | epoch: 008 | loss: 0.13699 - acc: 0.9661 -- iter: 224/428
[A[ATraining Step: 106  | total loss: [1m[32m0.12479[0m[0m | time: 142.269s
[2K
| Adam | epoch: 008 | loss: 0.12479 - acc: 0.9695 -- iter: 256/428
[A[ATraining Step: 107  | total loss: [1m[32m0.12497[0m[0m | time: 180.918s
[2K
| Adam | epoch: 008 | loss: 0.12497 - acc: 0.9694 -- iter: 288/428
[A[ATraining Step: 108  | total loss: [1m[32m0.11456[0m[0m | time: 213.651s
[2K
| Adam | epoch: 008 | loss: 0.11456 - acc: 0.9725 -- iter: 320/428
[A[ATraining Step: 109  | total loss: [1m[32m0.11206[0m[0m | time: 253.871s
[2K
| Adam | epoch: 008 | loss: 0.11206 - acc: 0.9721 -- iter: 352/428
[A[ATraining Step: 110  | total loss: [1m[32m0.12014[0m[0m | time: 270.721s
[2K
| Adam | epoch: 008 | loss: 0.12014 - acc: 0.9687 -- iter: 384/428
[A[ATraining Step: 111  | total loss: [1m[32m0.10950[0m[0m | time: 287.607s
[2K
| Adam | epoch: 008 | loss: 0.10950 - acc: 0.9718 -- iter: 416/428
[A[ATraining Step: 112  | total loss: [1m[32m0.11316[0m[0m | time: 307.371s
[2K
| Adam | epoch: 008 | loss: 0.11316 - acc: 0.9684 | val_loss: 5.92029 - val_acc: 0.5037 -- iter: 428/428
--
Training Step: 113  | total loss: [1m[32m0.14180[0m[0m | time: 15.802s
[2K
| Adam | epoch: 009 | loss: 0.14180 - acc: 0.9590 -- iter: 032/428
[A[ATraining Step: 114  | total loss: [1m[32m0.13032[0m[0m | time: 32.355s
[2K
| Adam | epoch: 009 | loss: 0.13032 - acc: 0.9631 -- iter: 064/428
[A[ATraining Step: 115  | total loss: [1m[32m0.12395[0m[0m | time: 48.671s
[2K
| Adam | epoch: 009 | loss: 0.12395 - acc: 0.9637 -- iter: 096/428
[A[ATraining Step: 116  | total loss: [1m[32m0.12490[0m[0m | time: 65.212s
[2K
| Adam | epoch: 009 | loss: 0.12490 - acc: 0.9611 -- iter: 128/428
[A[ATraining Step: 117  | total loss: [1m[32m0.12323[0m[0m | time: 82.121s
[2K
| Adam | epoch: 009 | loss: 0.12323 - acc: 0.9618 -- iter: 160/428
[A[ATraining Step: 118  | total loss: [1m[32m0.18910[0m[0m | time: 98.773s
[2K
| Adam | epoch: 009 | loss: 0.18910 - acc: 0.9532 -- iter: 192/428
[A[ATraining Step: 119  | total loss: [1m[32m0.18371[0m[0m | time: 106.255s
[2K
| Adam | epoch: 009 | loss: 0.18371 - acc: 0.9547 -- iter: 224/428
[A[ATraining Step: 120  | total loss: [1m[32m0.19248[0m[0m | time: 114.317s
[2K
| Adam | epoch: 009 | loss: 0.19248 - acc: 0.9426 -- iter: 256/428
[A[ATraining Step: 121  | total loss: [1m[32m0.18463[0m[0m | time: 131.586s
[2K
| Adam | epoch: 009 | loss: 0.18463 - acc: 0.9483 -- iter: 288/428
[A[ATraining Step: 122  | total loss: [1m[32m0.17209[0m[0m | time: 149.923s
[2K
| Adam | epoch: 009 | loss: 0.17209 - acc: 0.9535 -- iter: 320/428
[A[ATraining Step: 123  | total loss: [1m[32m0.17375[0m[0m | time: 166.673s
[2K
| Adam | epoch: 009 | loss: 0.17375 - acc: 0.9488 -- iter: 352/428
[A[ATraining Step: 124  | total loss: [1m[32m0.15935[0m[0m | time: 183.573s
[2K
| Adam | epoch: 009 | loss: 0.15935 - acc: 0.9539 -- iter: 384/428
[A[ATraining Step: 125  | total loss: [1m[32m0.15361[0m[0m | time: 200.744s
[2K
| Adam | epoch: 009 | loss: 0.15361 - acc: 0.9522 -- iter: 416/428
[A[ATraining Step: 126  | total loss: [1m[32m0.16971[0m[0m | time: 231.310s
[2K
| Adam | epoch: 009 | loss: 0.16971 - acc: 0.9476 | val_loss: 0.32144 - val_acc: 0.8444 -- iter: 428/428
--
Training Step: 127  | total loss: [1m[32m0.16334[0m[0m | time: 17.346s
[2K
| Adam | epoch: 010 | loss: 0.16334 - acc: 0.9466 -- iter: 032/428
[A[ATraining Step: 128  | total loss: [1m[32m0.15845[0m[0m | time: 35.239s
[2K
| Adam | epoch: 010 | loss: 0.15845 - acc: 0.9457 -- iter: 064/428
[A[ATraining Step: 129  | total loss: [1m[32m0.15901[0m[0m | time: 53.523s
[2K
| Adam | epoch: 010 | loss: 0.15901 - acc: 0.9449 -- iter: 096/428
[A[ATraining Step: 130  | total loss: [1m[32m0.14806[0m[0m | time: 69.753s
[2K
| Adam | epoch: 010 | loss: 0.14806 - acc: 0.9504 -- iter: 128/428
[A[ATraining Step: 131  | total loss: [1m[32m0.14836[0m[0m | time: 86.494s
[2K
| Adam | epoch: 010 | loss: 0.14836 - acc: 0.9491 -- iter: 160/428
[A[ATraining Step: 132  | total loss: [1m[32m0.13812[0m[0m | time: 104.031s
[2K
| Adam | epoch: 010 | loss: 0.13812 - acc: 0.9542 -- iter: 192/428
[A[ATraining Step: 133  | total loss: [1m[32m0.34143[0m[0m | time: 121.686s
[2K
| Adam | epoch: 010 | loss: 0.34143 - acc: 0.9119 -- iter: 224/428
[A[ATraining Step: 134  | total loss: [1m[32m0.32017[0m[0m | time: 130.203s
[2K
| Adam | epoch: 010 | loss: 0.32017 - acc: 0.9145 -- iter: 256/428
[A[ATraining Step: 135  | total loss: [1m[32m0.30112[0m[0m | time: 137.918s
[2K
| Adam | epoch: 010 | loss: 0.30112 - acc: 0.9147 -- iter: 288/428
[A[ATraining Step: 136  | total loss: [1m[32m0.27602[0m[0m | time: 154.876s
[2K
| Adam | epoch: 010 | loss: 0.27602 - acc: 0.9232 -- iter: 320/428
[A[ATraining Step: 137  | total loss: [1m[32m0.25428[0m[0m | time: 171.919s
[2K
| Adam | epoch: 010 | loss: 0.25428 - acc: 0.9309 -- iter: 352/428
[A[ATraining Step: 138  | total loss: [1m[32m0.23960[0m[0m | time: 189.725s
[2K
| Adam | epoch: 010 | loss: 0.23960 - acc: 0.9316 -- iter: 384/428
[A[ATraining Step: 139  | total loss: [1m[32m0.22216[0m[0m | time: 207.681s
[2K
| Adam | epoch: 010 | loss: 0.22216 - acc: 0.9384 -- iter: 416/428
[A[ATraining Step: 140  | total loss: [1m[32m0.20793[0m[0m | time: 238.114s
[2K
| Adam | epoch: 010 | loss: 0.20793 - acc: 0.9414 | val_loss: 0.60821 - val_acc: 0.8148 -- iter: 428/428
--
Training Step: 141  | total loss: [1m[32m0.19403[0m[0m | time: 16.934s
[2K
| Adam | epoch: 011 | loss: 0.19403 - acc: 0.9473 -- iter: 032/428
[A[ATraining Step: 142  | total loss: [1m[32m0.17939[0m[0m | time: 34.101s
[2K
| Adam | epoch: 011 | loss: 0.17939 - acc: 0.9526 -- iter: 064/428
[A[ATraining Step: 143  | total loss: [1m[32m0.16758[0m[0m | time: 51.156s
[2K
| Adam | epoch: 011 | loss: 0.16758 - acc: 0.9573 -- iter: 096/428
[A[ATraining Step: 144  | total loss: [1m[32m0.15611[0m[0m | time: 68.017s
[2K
| Adam | epoch: 011 | loss: 0.15611 - acc: 0.9616 -- iter: 128/428
[A[ATraining Step: 145  | total loss: [1m[32m0.15675[0m[0m | time: 85.824s
[2K
| Adam | epoch: 011 | loss: 0.15675 - acc: 0.9592 -- iter: 160/428
[A[ATraining Step: 146  | total loss: [1m[32m0.14706[0m[0m | time: 99.765s
[2K
| Adam | epoch: 011 | loss: 0.14706 - acc: 0.9633 -- iter: 192/428
[A[ATraining Step: 147  | total loss: [1m[32m0.14982[0m[0m | time: 110.525s
[2K
| Adam | epoch: 011 | loss: 0.14982 - acc: 0.9607 -- iter: 224/428
[A[ATraining Step: 148  | total loss: [1m[32m0.14623[0m[0m | time: 123.682s
[2K
| Adam | epoch: 011 | loss: 0.14623 - acc: 0.9584 -- iter: 256/428
[A[ATraining Step: 149  | total loss: [1m[32m0.13958[0m[0m | time: 131.063s
[2K
| Adam | epoch: 011 | loss: 0.13958 - acc: 0.9594 -- iter: 288/428
[A[ATraining Step: 150  | total loss: [1m[32m0.21658[0m[0m | time: 138.620s
[2K
| Adam | epoch: 011 | loss: 0.21658 - acc: 0.9301 -- iter: 320/428
[A[ATraining Step: 151  | total loss: [1m[32m0.24551[0m[0m | time: 154.324s
[2K
| Adam | epoch: 011 | loss: 0.24551 - acc: 0.9204 -- iter: 352/428
[A[ATraining Step: 152  | total loss: [1m[32m0.23699[0m[0m | time: 169.562s
[2K
| Adam | epoch: 011 | loss: 0.23699 - acc: 0.9253 -- iter: 384/428
[A[ATraining Step: 153  | total loss: [1m[32m0.21597[0m[0m | time: 185.961s
[2K
| Adam | epoch: 011 | loss: 0.21597 - acc: 0.9327 -- iter: 416/428
[A[ATraining Step: 154  | total loss: [1m[32m0.19591[0m[0m | time: 214.659s
[2K
| Adam | epoch: 011 | loss: 0.19591 - acc: 0.9395 | val_loss: 1.69444 - val_acc: 0.6444 -- iter: 428/428
--
Training Step: 155  | total loss: [1m[32m0.19719[0m[0m | time: 15.774s
[2K
| Adam | epoch: 012 | loss: 0.19719 - acc: 0.9424 -- iter: 032/428
[A[ATraining Step: 156  | total loss: [1m[32m0.18547[0m[0m | time: 33.068s
[2K
| Adam | epoch: 012 | loss: 0.18547 - acc: 0.9450 -- iter: 064/428
[A[ATraining Step: 157  | total loss: [1m[32m0.17080[0m[0m | time: 49.205s
[2K
| Adam | epoch: 012 | loss: 0.17080 - acc: 0.9505 -- iter: 096/428
[A[ATraining Step: 158  | total loss: [1m[32m0.16603[0m[0m | time: 65.665s
[2K
| Adam | epoch: 012 | loss: 0.16603 - acc: 0.9524 -- iter: 128/428
[A[ATraining Step: 159  | total loss: [1m[32m0.15415[0m[0m | time: 82.050s
[2K
| Adam | epoch: 012 | loss: 0.15415 - acc: 0.9571 -- iter: 160/428
[A[ATraining Step: 160  | total loss: [1m[32m0.17025[0m[0m | time: 98.381s
[2K
| Adam | epoch: 012 | loss: 0.17025 - acc: 0.9489 -- iter: 192/428
[A[ATraining Step: 161  | total loss: [1m[32m0.15801[0m[0m | time: 114.931s
[2K
| Adam | epoch: 012 | loss: 0.15801 - acc: 0.9540 -- iter: 224/428
[A[ATraining Step: 162  | total loss: [1m[32m0.15468[0m[0m | time: 131.282s
[2K
| Adam | epoch: 012 | loss: 0.15468 - acc: 0.9555 -- iter: 256/428
[A[ATraining Step: 163  | total loss: [1m[32m0.21539[0m[0m | time: 148.424s
[2K
| Adam | epoch: 012 | loss: 0.21539 - acc: 0.9474 -- iter: 288/428
[A[ATraining Step: 164  | total loss: [1m[32m0.19641[0m[0m | time: 157.338s
[2K
| Adam | epoch: 012 | loss: 0.19641 - acc: 0.9527 -- iter: 320/428
[A[ATraining Step: 165  | total loss: [1m[32m0.17774[0m[0m | time: 164.866s
[2K
| Adam | epoch: 012 | loss: 0.17774 - acc: 0.9574 -- iter: 352/428
[A[ATraining Step: 166  | total loss: [1m[32m0.16154[0m[0m | time: 181.516s
[2K
| Adam | epoch: 012 | loss: 0.16154 - acc: 0.9617 -- iter: 384/428
[A[ATraining Step: 167  | total loss: [1m[32m0.14806[0m[0m | time: 197.870s
[2K
| Adam | epoch: 012 | loss: 0.14806 - acc: 0.9655 -- iter: 416/428
[A[ATraining Step: 168  | total loss: [1m[32m0.14262[0m[0m | time: 227.404s
[2K
| Adam | epoch: 012 | loss: 0.14262 - acc: 0.9658 | val_loss: 5.02643 - val_acc: 0.5185 -- iter: 428/428
--
Training Step: 169  | total loss: [1m[32m0.13077[0m[0m | time: 16.591s
[2K
| Adam | epoch: 013 | loss: 0.13077 - acc: 0.9693 -- iter: 032/428
[A[ATraining Step: 170  | total loss: [1m[32m0.13336[0m[0m | time: 33.293s
[2K
| Adam | epoch: 013 | loss: 0.13336 - acc: 0.9692 -- iter: 064/428
[A[ATraining Step: 171  | total loss: [1m[32m0.15442[0m[0m | time: 51.982s
[2K
| Adam | epoch: 013 | loss: 0.15442 - acc: 0.9629 -- iter: 096/428
[A[ATraining Step: 172  | total loss: [1m[32m0.15421[0m[0m | time: 69.854s
[2K
| Adam | epoch: 013 | loss: 0.15421 - acc: 0.9635 -- iter: 128/428
[A[ATraining Step: 173  | total loss: [1m[32m0.14360[0m[0m | time: 87.009s
[2K
| Adam | epoch: 013 | loss: 0.14360 - acc: 0.9640 -- iter: 160/428
[A[ATraining Step: 174  | total loss: [1m[32m0.13994[0m[0m | time: 104.378s
[2K
| Adam | epoch: 013 | loss: 0.13994 - acc: 0.9582 -- iter: 192/428
[A[ATraining Step: 175  | total loss: [1m[32m0.13287[0m[0m | time: 121.221s
[2K
| Adam | epoch: 013 | loss: 0.13287 - acc: 0.9593 -- iter: 224/428
[A[ATraining Step: 176  | total loss: [1m[32m0.12685[0m[0m | time: 137.764s
[2K
| Adam | epoch: 013 | loss: 0.12685 - acc: 0.9602 -- iter: 256/428
[A[ATraining Step: 177  | total loss: [1m[32m0.12642[0m[0m | time: 154.370s
[2K
| Adam | epoch: 013 | loss: 0.12642 - acc: 0.9548 -- iter: 288/428
[A[ATraining Step: 178  | total loss: [1m[32m0.17125[0m[0m | time: 171.174s
[2K
| Adam | epoch: 013 | loss: 0.17125 - acc: 0.9500 -- iter: 320/428
[A[ATraining Step: 179  | total loss: [1m[32m0.16521[0m[0m | time: 179.080s
[2K
| Adam | epoch: 013 | loss: 0.16521 - acc: 0.9487 -- iter: 352/428
[A[ATraining Step: 180  | total loss: [1m[32m0.17133[0m[0m | time: 186.834s
[2K
| Adam | epoch: 013 | loss: 0.17133 - acc: 0.9455 -- iter: 384/428
[A[ATraining Step: 181  | total loss: [1m[32m0.16171[0m[0m | time: 203.330s
[2K
| Adam | epoch: 013 | loss: 0.16171 - acc: 0.9510 -- iter: 416/428
[A[ATraining Step: 182  | total loss: [1m[32m0.15325[0m[0m | time: 236.523s
[2K
| Adam | epoch: 013 | loss: 0.15325 - acc: 0.9528 | val_loss: 0.95329 - val_acc: 0.6519 -- iter: 428/428
--
Training Step: 183  | total loss: [1m[32m0.14848[0m[0m | time: 11.464s
[2K
| Adam | epoch: 014 | loss: 0.14848 - acc: 0.9544 -- iter: 032/428
[A[ATraining Step: 184  | total loss: [1m[32m0.13806[0m[0m | time: 26.298s
[2K
| Adam | epoch: 014 | loss: 0.13806 - acc: 0.9589 -- iter: 064/428
[A[ATraining Step: 185  | total loss: [1m[32m0.13862[0m[0m | time: 44.060s
[2K
| Adam | epoch: 014 | loss: 0.13862 - acc: 0.9568 -- iter: 096/428
[A[ATraining Step: 186  | total loss: [1m[32m0.15056[0m[0m | time: 60.953s
[2K
| Adam | epoch: 014 | loss: 0.15056 - acc: 0.9548 -- iter: 128/428
[A[ATraining Step: 187  | total loss: [1m[32m0.13875[0m[0m | time: 80.030s
[2K
| Adam | epoch: 014 | loss: 0.13875 - acc: 0.9594 -- iter: 160/428
[A[ATraining Step: 188  | total loss: [1m[32m0.13183[0m[0m | time: 96.866s
[2K
| Adam | epoch: 014 | loss: 0.13183 - acc: 0.9634 -- iter: 192/428
[A[ATraining Step: 189  | total loss: [1m[32m0.12165[0m[0m | time: 116.508s
[2K
| Adam | epoch: 014 | loss: 0.12165 - acc: 0.9671 -- iter: 224/428
[A[ATraining Step: 190  | total loss: [1m[32m0.11244[0m[0m | time: 132.419s
[2K
| Adam | epoch: 014 | loss: 0.11244 - acc: 0.9704 -- iter: 256/428
[A[ATraining Step: 191  | total loss: [1m[32m0.10804[0m[0m | time: 143.936s
[2K
| Adam | epoch: 014 | loss: 0.10804 - acc: 0.9702 -- iter: 288/428
[A[ATraining Step: 192  | total loss: [1m[32m0.09985[0m[0m | time: 155.957s
[2K
| Adam | epoch: 014 | loss: 0.09985 - acc: 0.9732 -- iter: 320/428
[A[ATraining Step: 193  | total loss: [1m[32m0.26767[0m[0m | time: 172.753s
[2K
| Adam | epoch: 014 | loss: 0.26767 - acc: 0.9446 -- iter: 352/428
[A[ATraining Step: 194  | total loss: [1m[32m0.24435[0m[0m | time: 180.861s
[2K
| Adam | epoch: 014 | loss: 0.24435 - acc: 0.9502 -- iter: 384/428
[A[ATraining Step: 195  | total loss: [1m[32m0.22745[0m[0m | time: 189.016s
[2K
| Adam | epoch: 014 | loss: 0.22745 - acc: 0.9468 -- iter: 416/428
[A[ATraining Step: 196  | total loss: [1m[32m0.20741[0m[0m | time: 220.018s
[2K
| Adam | epoch: 014 | loss: 0.20741 - acc: 0.9521 | val_loss: 0.45879 - val_acc: 0.8519 -- iter: 428/428
--
Training Step: 197  | total loss: [1m[32m0.19459[0m[0m | time: 17.146s
[2K
| Adam | epoch: 015 | loss: 0.19459 - acc: 0.9538 -- iter: 032/428
[A[ATraining Step: 198  | total loss: [1m[32m0.19326[0m[0m | time: 35.046s
[2K
| Adam | epoch: 015 | loss: 0.19326 - acc: 0.9522 -- iter: 064/428
[A[ATraining Step: 199  | total loss: [1m[32m0.17745[0m[0m | time: 52.233s
[2K
| Adam | epoch: 015 | loss: 0.17745 - acc: 0.9569 -- iter: 096/428
[A[ATraining Step: 200  | total loss: [1m[32m0.17130[0m[0m | time: 82.909s
[2K
| Adam | epoch: 015 | loss: 0.17130 - acc: 0.9550 | val_loss: 0.53559 - val_acc: 0.8296 -- iter: 128/428
--
Training Step: 201  | total loss: [1m[32m0.15742[0m[0m | time: 100.867s
[2K
| Adam | epoch: 015 | loss: 0.15742 - acc: 0.9595 -- iter: 160/428
[A[ATraining Step: 202  | total loss: [1m[32m0.14919[0m[0m | time: 118.210s
[2K
| Adam | epoch: 015 | loss: 0.14919 - acc: 0.9604 -- iter: 192/428
[A[ATraining Step: 203  | total loss: [1m[32m0.14679[0m[0m | time: 135.794s
[2K
| Adam | epoch: 015 | loss: 0.14679 - acc: 0.9613 -- iter: 224/428
[A[ATraining Step: 204  | total loss: [1m[32m0.13419[0m[0m | time: 154.888s
[2K
| Adam | epoch: 015 | loss: 0.13419 - acc: 0.9651 -- iter: 256/428
[A[ATraining Step: 205  | total loss: [1m[32m0.12349[0m[0m | time: 172.683s
[2K
| Adam | epoch: 015 | loss: 0.12349 - acc: 0.9686 -- iter: 288/428
[A[ATraining Step: 206  | total loss: [1m[32m0.11320[0m[0m | time: 190.005s
[2K
| Adam | epoch: 015 | loss: 0.11320 - acc: 0.9718 -- iter: 320/428
[A[ATraining Step: 207  | total loss: [1m[32m0.10359[0m[0m | time: 207.827s
[2K
| Adam | epoch: 015 | loss: 0.10359 - acc: 0.9746 -- iter: 352/428
[A[ATraining Step: 208  | total loss: [1m[32m0.09489[0m[0m | time: 225.490s
[2K
| Adam | epoch: 015 | loss: 0.09489 - acc: 0.9771 -- iter: 384/428
[A[ATraining Step: 209  | total loss: [1m[32m0.08858[0m[0m | time: 232.878s
[2K
| Adam | epoch: 015 | loss: 0.08858 - acc: 0.9794 -- iter: 416/428
[A[ATraining Step: 210  | total loss: [1m[32m0.08469[0m[0m | time: 255.069s
[2K
| Adam | epoch: 015 | loss: 0.08469 - acc: 0.9815 | val_loss: 1.56269 - val_acc: 0.7111 -- iter: 428/428
--
Validation AUC:0.9236934563021519
Validation AUPRC:0.9057974016751201
Test AUC:0.9563213345039508
Test AUPRC:0.9596405625315675
BestTestF1Score	0.88	0.75	0.87	0.84	0.93	63	12	55	5	1.0
BestTestMCCScore	0.88	0.75	0.87	0.84	0.93	63	12	55	5	1.0
BestTestAccuracyScore	0.88	0.75	0.87	0.84	0.93	63	12	55	5	1.0
BestValidationF1Score	0.84	0.68	0.83	0.77	0.94	62	19	50	4	1.0
BestValidationMCC	0.84	0.68	0.83	0.77	0.94	62	19	50	4	1.0
BestValidationAccuracy	0.84	0.68	0.83	0.77	0.94	62	19	50	4	1.0
TestPredictions (Threshold:1.0)
CHEMBL1643796,FN,ACT,0.9300000071525574	CHEMBL23529,TN,INACT,0.949999988079071	CHEMBL484777,TP,ACT,1.0	CHEMBL483346,TP,ACT,1.0	CHEMBL172788,TN,INACT,0.9900000095367432	CHEMBL1643770,TP,ACT,1.0	CHEMBL310643,TP,ACT,1.0	CHEMBL3398215,TP,ACT,1.0	CHEMBL394394,TN,INACT,0.8899999856948853	CHEMBL140984,TN,INACT,0.9900000095367432	CHEMBL1643797,TP,ACT,1.0	CHEMBL396303,TN,INACT,0.009999999776482582	CHEMBL312182,TP,ACT,1.0	CHEMBL3398228,TP,ACT,1.0	CHEMBL245908,TP,ACT,1.0	CHEMBL102584,TN,INACT,0.47999998927116394	CHEMBL10404,TN,INACT,0.019999999552965164	CHEMBL569762,TP,ACT,1.0	CHEMBL570204,TP,ACT,1.0	CHEMBL308414,TN,INACT,0.8299999833106995	CHEMBL1237297,FP,INACT,1.0	CHEMBL423260,TN,INACT,0.8299999833106995	CHEMBL2164609,FP,INACT,1.0	CHEMBL392316,TN,INACT,0.800000011920929	CHEMBL72841,TN,INACT,0.3700000047683716	CHEMBL126472,FP,INACT,1.0	CHEMBL9274,TN,INACT,0.009999999776482582	CHEMBL420953,TP,ACT,1.0	CHEMBL124675,TN,INACT,0.9599999785423279	CHEMBL1951567,TP,ACT,1.0	CHEMBL537834,TN,INACT,0.28999999165534973	CHEMBL333438,TN,INACT,0.9900000095367432	CHEMBL91,TN,INACT,0.5199999809265137	CHEMBL569772,TP,ACT,1.0	CHEMBL1643784,TP,ACT,1.0	CHEMBL328422,TN,INACT,0.9900000095367432	CHEMBL141048,TN,INACT,0.20999999344348907	CHEMBL3287088,TP,ACT,1.0	CHEMBL269689,TN,INACT,0.029999999329447746	CHEMBL81768,TP,ACT,1.0	CHEMBL311977,TP,ACT,1.0	CHEMBL238342,TN,INACT,0.07999999821186066	CHEMBL402517,TN,INACT,0.05000000074505806	CHEMBL338221,FP,INACT,1.0	CHEMBL141051,TN,INACT,0.5600000023841858	CHEMBL399000,TN,INACT,0.25999999046325684	CHEMBL3398210,TP,ACT,1.0	CHEMBL569537,TP,ACT,1.0	CHEMBL312476,TP,ACT,1.0	CHEMBL235139,TN,INACT,0.9399999976158142	CHEMBL3398206,TP,ACT,1.0	CHEMBL416262,FP,INACT,1.0	CHEMBL1258999,TN,INACT,0.0	CHEMBL310505,TP,ACT,1.0	CHEMBL297578,TN,INACT,0.8700000047683716	CHEMBL289284,TN,INACT,0.3400000035762787	CHEMBL1643794,TP,ACT,1.0	CHEMBL342256,TN,INACT,0.11999999731779099	CHEMBL79943,TP,ACT,1.0	CHEMBL207203,TP,ACT,1.0	CHEMBL1933765,TP,ACT,1.0	CHEMBL518987,TP,ACT,1.0	CHEMBL1950876,TP,ACT,1.0	CHEMBL1950866,TP,ACT,1.0	CHEMBL407818,TN,INACT,0.029999999329447746	CHEMBL173039,TN,INACT,0.6899999976158142	CHEMBL2425370,FP,INACT,1.0	CHEMBL451211,FP,INACT,1.0	CHEMBL207104,TP,ACT,1.0	CHEMBL1951574,TP,ACT,1.0	CHEMBL373118,FN,ACT,0.9900000095367432	CHEMBL397842,TP,ACT,1.0	CHEMBL420588,TP,ACT,1.0	CHEMBL257746,TN,INACT,0.9100000262260437	CHEMBL312092,FN,ACT,0.9700000286102295	CHEMBL125110,TN,INACT,0.7900000214576721	CHEMBL336437,TN,INACT,0.9800000190734863	CHEMBL303386,TN,INACT,0.03999999910593033	CHEMBL393753,TN,INACT,0.8899999856948853	CHEMBL551813,TN,INACT,0.8299999833106995	CHEMBL1907969,TN,INACT,0.3199999928474426	CHEMBL514802,TP,ACT,1.0	CHEMBL309017,TN,INACT,0.9700000286102295	CHEMBL1916700,TP,ACT,1.0	CHEMBL422411,TN,INACT,0.1899999976158142	CHEMBL3586362,TN,INACT,0.8700000047683716	CHEMBL81231,TP,ACT,1.0	CHEMBL394669,FP,INACT,1.0	CHEMBL311769,TP,ACT,1.0	CHEMBL2164612,TN,INACT,0.9599999785423279	CHEMBL489310,FP,INACT,1.0	CHEMBL3398220,TP,ACT,1.0	CHEMBL83788,TP,ACT,1.0	CHEMBL210615,TP,ACT,1.0	CHEMBL520007,TP,ACT,1.0	CHEMBL483152,TP,ACT,1.0	CHEMBL325752,TN,INACT,0.9300000071525574	CHEMBL570005,TP,ACT,1.0	CHEMBL3310166,TN,INACT,0.0	CHEMBL311790,TP,ACT,1.0	CHEMBL332635,TP,ACT,1.0	CHEMBL401798,TN,INACT,0.0	CHEMBL1950872,TP,ACT,1.0	CHEMBL590582,TN,INACT,0.8500000238418579	CHEMBL3398208,TP,ACT,1.0	CHEMBL324652,TN,INACT,0.9700000286102295	CHEMBL118619,TN,INACT,0.5400000214576721	CHEMBL236630,TN,INACT,0.009999999776482582	CHEMBL1951565,TP,ACT,1.0	CHEMBL79370,TP,ACT,1.0	CHEMBL393755,TN,INACT,0.699999988079071	CHEMBL1170027,FP,INACT,1.0	CHEMBL3586317,TN,INACT,0.17000000178813934	CHEMBL514895,TN,INACT,0.2800000011920929	CHEMBL1668898,TN,INACT,0.9900000095367432	CHEMBL435382,TP,ACT,1.0	CHEMBL3143394,TN,INACT,0.7200000286102295	CHEMBL127204,FP,INACT,1.0	CHEMBL310454,TP,ACT,1.0	CHEMBL127551,TN,INACT,0.009999999776482582	CHEMBL419040,TP,ACT,1.0	CHEMBL3398229,TP,ACT,1.0	CHEMBL208082,TP,ACT,1.0	CHEMBL3398237,FN,ACT,0.7099999785423279	CHEMBL1950869,TP,ACT,1.0	CHEMBL307659,FP,INACT,1.0	CHEMBL1917584,TP,ACT,1.0	CHEMBL1951572,TP,ACT,1.0	CHEMBL365908,TP,ACT,1.0	CHEMBL312707,FN,ACT,0.9800000190734863	CHEMBL83893,TP,ACT,1.0	CHEMBL446628,TP,ACT,1.0	CHEMBL280534,TN,INACT,0.5899999737739563	CHEMBL82426,TP,ACT,1.0	CHEMBL1643798,TP,ACT,1.0	

