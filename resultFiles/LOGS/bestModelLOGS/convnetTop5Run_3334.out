ImageNetInceptionV2 CHEMBL4072 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	496
Number of inactive compounds :	331
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4072_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4072_adam_0.0005_15_0.8/
---------------------------------
Training samples: 528
Validation samples: 166
--
Training Step: 1  | time: 46.210s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/528
[A[ATraining Step: 2  | total loss: [1m[32m0.63855[0m[0m | time: 58.083s
[2K
| Adam | epoch: 001 | loss: 0.63855 - acc: 0.4219 -- iter: 064/528
[A[ATraining Step: 3  | total loss: [1m[32m0.82471[0m[0m | time: 68.933s
[2K
| Adam | epoch: 001 | loss: 0.82471 - acc: 0.4347 -- iter: 096/528
[A[ATraining Step: 4  | total loss: [1m[32m0.86738[0m[0m | time: 79.593s
[2K
| Adam | epoch: 001 | loss: 0.86738 - acc: 0.5071 -- iter: 128/528
[A[ATraining Step: 5  | total loss: [1m[32m0.73081[0m[0m | time: 91.459s
[2K
| Adam | epoch: 001 | loss: 0.73081 - acc: 0.5887 -- iter: 160/528
[A[ATraining Step: 6  | total loss: [1m[32m0.73232[0m[0m | time: 103.222s
[2K
| Adam | epoch: 001 | loss: 0.73232 - acc: 0.5116 -- iter: 192/528
[A[ATraining Step: 7  | total loss: [1m[32m0.74106[0m[0m | time: 113.308s
[2K
| Adam | epoch: 001 | loss: 0.74106 - acc: 0.4859 -- iter: 224/528
[A[ATraining Step: 8  | total loss: [1m[32m0.62467[0m[0m | time: 123.755s
[2K
| Adam | epoch: 001 | loss: 0.62467 - acc: 0.6696 -- iter: 256/528
[A[ATraining Step: 9  | total loss: [1m[32m0.63654[0m[0m | time: 134.454s
[2K
| Adam | epoch: 001 | loss: 0.63654 - acc: 0.6460 -- iter: 288/528
[A[ATraining Step: 10  | total loss: [1m[32m0.75422[0m[0m | time: 144.561s
[2K
| Adam | epoch: 001 | loss: 0.75422 - acc: 0.5261 -- iter: 320/528
[A[ATraining Step: 11  | total loss: [1m[32m0.71246[0m[0m | time: 154.974s
[2K
| Adam | epoch: 001 | loss: 0.71246 - acc: 0.5730 -- iter: 352/528
[A[ATraining Step: 12  | total loss: [1m[32m0.72942[0m[0m | time: 166.149s
[2K
| Adam | epoch: 001 | loss: 0.72942 - acc: 0.5261 -- iter: 384/528
[A[ATraining Step: 13  | total loss: [1m[32m0.64350[0m[0m | time: 176.291s
[2K
| Adam | epoch: 001 | loss: 0.64350 - acc: 0.6354 -- iter: 416/528
[A[ATraining Step: 14  | total loss: [1m[32m0.69210[0m[0m | time: 186.662s
[2K
| Adam | epoch: 001 | loss: 0.69210 - acc: 0.5800 -- iter: 448/528
[A[ATraining Step: 15  | total loss: [1m[32m0.73518[0m[0m | time: 197.567s
[2K
| Adam | epoch: 001 | loss: 0.73518 - acc: 0.5854 -- iter: 480/528
[A[ATraining Step: 16  | total loss: [1m[32m0.72450[0m[0m | time: 208.049s
[2K
| Adam | epoch: 001 | loss: 0.72450 - acc: 0.5768 -- iter: 512/528
[A[ATraining Step: 17  | total loss: [1m[32m0.75346[0m[0m | time: 231.031s
[2K
| Adam | epoch: 001 | loss: 0.75346 - acc: 0.5379 | val_loss: 0.69800 - val_acc: 0.6386 -- iter: 528/528
--
Training Step: 18  | total loss: [1m[32m0.73692[0m[0m | time: 6.059s
[2K
| Adam | epoch: 002 | loss: 0.73692 - acc: 0.5248 -- iter: 032/528
[A[ATraining Step: 19  | total loss: [1m[32m0.67076[0m[0m | time: 16.027s
[2K
| Adam | epoch: 002 | loss: 0.67076 - acc: 0.5999 -- iter: 064/528
[A[ATraining Step: 20  | total loss: [1m[32m0.67663[0m[0m | time: 26.755s
[2K
| Adam | epoch: 002 | loss: 0.67663 - acc: 0.5678 -- iter: 096/528
[A[ATraining Step: 21  | total loss: [1m[32m0.67262[0m[0m | time: 39.249s
[2K
| Adam | epoch: 002 | loss: 0.67262 - acc: 0.5758 -- iter: 128/528
[A[ATraining Step: 22  | total loss: [1m[32m0.65591[0m[0m | time: 53.226s
[2K
| Adam | epoch: 002 | loss: 0.65591 - acc: 0.5718 -- iter: 160/528
[A[ATraining Step: 23  | total loss: [1m[32m0.63326[0m[0m | time: 72.345s
[2K
| Adam | epoch: 002 | loss: 0.63326 - acc: 0.6054 -- iter: 192/528
[A[ATraining Step: 24  | total loss: [1m[32m0.60815[0m[0m | time: 82.440s
[2K
| Adam | epoch: 002 | loss: 0.60815 - acc: 0.6285 -- iter: 224/528
[A[ATraining Step: 25  | total loss: [1m[32m0.56690[0m[0m | time: 92.642s
[2K
| Adam | epoch: 002 | loss: 0.56690 - acc: 0.6787 -- iter: 256/528
[A[ATraining Step: 26  | total loss: [1m[32m0.59949[0m[0m | time: 105.831s
[2K
| Adam | epoch: 002 | loss: 0.59949 - acc: 0.6479 -- iter: 288/528
[A[ATraining Step: 27  | total loss: [1m[32m0.60014[0m[0m | time: 116.693s
[2K
| Adam | epoch: 002 | loss: 0.60014 - acc: 0.6581 -- iter: 320/528
[A[ATraining Step: 28  | total loss: [1m[32m0.60279[0m[0m | time: 127.179s
[2K
| Adam | epoch: 002 | loss: 0.60279 - acc: 0.6498 -- iter: 352/528
[A[ATraining Step: 29  | total loss: [1m[32m0.59646[0m[0m | time: 137.216s
[2K
| Adam | epoch: 002 | loss: 0.59646 - acc: 0.6590 -- iter: 384/528
[A[ATraining Step: 30  | total loss: [1m[32m0.61352[0m[0m | time: 148.048s
[2K
| Adam | epoch: 002 | loss: 0.61352 - acc: 0.6287 -- iter: 416/528
[A[ATraining Step: 31  | total loss: [1m[32m0.56790[0m[0m | time: 190.894s
[2K
| Adam | epoch: 002 | loss: 0.56790 - acc: 0.6856 -- iter: 448/528
[A[ATraining Step: 32  | total loss: [1m[32m0.56967[0m[0m | time: 200.861s
[2K
| Adam | epoch: 002 | loss: 0.56967 - acc: 0.6930 -- iter: 480/528
[A[ATraining Step: 33  | total loss: [1m[32m0.55842[0m[0m | time: 210.702s
[2K
| Adam | epoch: 002 | loss: 0.55842 - acc: 0.7055 -- iter: 512/528
[A[ATraining Step: 34  | total loss: [1m[32m0.61963[0m[0m | time: 230.121s
[2K
| Adam | epoch: 002 | loss: 0.61963 - acc: 0.6749 | val_loss: 0.80420 - val_acc: 0.6386 -- iter: 528/528
--
Training Step: 35  | total loss: [1m[32m0.59001[0m[0m | time: 5.365s
[2K
| Adam | epoch: 003 | loss: 0.59001 - acc: 0.7037 -- iter: 032/528
[A[ATraining Step: 36  | total loss: [1m[32m0.55123[0m[0m | time: 11.009s
[2K
| Adam | epoch: 003 | loss: 0.55123 - acc: 0.7387 -- iter: 064/528
[A[ATraining Step: 37  | total loss: [1m[32m0.48569[0m[0m | time: 21.032s
[2K
| Adam | epoch: 003 | loss: 0.48569 - acc: 0.7910 -- iter: 096/528
[A[ATraining Step: 38  | total loss: [1m[32m0.52689[0m[0m | time: 30.844s
[2K
| Adam | epoch: 003 | loss: 0.52689 - acc: 0.7524 -- iter: 128/528
[A[ATraining Step: 39  | total loss: [1m[32m0.52580[0m[0m | time: 40.589s
[2K
| Adam | epoch: 003 | loss: 0.52580 - acc: 0.7579 -- iter: 160/528
[A[ATraining Step: 40  | total loss: [1m[32m0.57937[0m[0m | time: 50.683s
[2K
| Adam | epoch: 003 | loss: 0.57937 - acc: 0.7330 -- iter: 192/528
[A[ATraining Step: 41  | total loss: [1m[32m0.55269[0m[0m | time: 60.775s
[2K
| Adam | epoch: 003 | loss: 0.55269 - acc: 0.7476 -- iter: 224/528
[A[ATraining Step: 42  | total loss: [1m[32m0.52521[0m[0m | time: 70.589s
[2K
| Adam | epoch: 003 | loss: 0.52521 - acc: 0.7705 -- iter: 256/528
[A[ATraining Step: 43  | total loss: [1m[32m0.54030[0m[0m | time: 80.767s
[2K
| Adam | epoch: 003 | loss: 0.54030 - acc: 0.7449 -- iter: 288/528
[A[ATraining Step: 44  | total loss: [1m[32m0.51540[0m[0m | time: 90.547s
[2K
| Adam | epoch: 003 | loss: 0.51540 - acc: 0.7620 -- iter: 320/528
[A[ATraining Step: 45  | total loss: [1m[32m0.48609[0m[0m | time: 100.605s
[2K
| Adam | epoch: 003 | loss: 0.48609 - acc: 0.7971 -- iter: 352/528
[A[ATraining Step: 46  | total loss: [1m[32m0.47053[0m[0m | time: 110.442s
[2K
| Adam | epoch: 003 | loss: 0.47053 - acc: 0.8101 -- iter: 384/528
[A[ATraining Step: 47  | total loss: [1m[32m0.46292[0m[0m | time: 120.105s
[2K
| Adam | epoch: 003 | loss: 0.46292 - acc: 0.8156 -- iter: 416/528
[A[ATraining Step: 48  | total loss: [1m[32m0.48144[0m[0m | time: 130.183s
[2K
| Adam | epoch: 003 | loss: 0.48144 - acc: 0.7900 -- iter: 448/528
[A[ATraining Step: 49  | total loss: [1m[32m0.44964[0m[0m | time: 140.121s
[2K
| Adam | epoch: 003 | loss: 0.44964 - acc: 0.8083 -- iter: 480/528
[A[ATraining Step: 50  | total loss: [1m[32m0.43568[0m[0m | time: 150.083s
[2K
| Adam | epoch: 003 | loss: 0.43568 - acc: 0.8138 -- iter: 512/528
[A[ATraining Step: 51  | total loss: [1m[32m0.42930[0m[0m | time: 169.217s
[2K
| Adam | epoch: 003 | loss: 0.42930 - acc: 0.8232 | val_loss: 0.88337 - val_acc: 0.4217 -- iter: 528/528
--
Training Step: 52  | total loss: [1m[32m0.41933[0m[0m | time: 8.206s
[2K
| Adam | epoch: 004 | loss: 0.41933 - acc: 0.8309 -- iter: 032/528
[A[ATraining Step: 53  | total loss: [1m[32m0.41387[0m[0m | time: 12.819s
[2K
| Adam | epoch: 004 | loss: 0.41387 - acc: 0.8328 -- iter: 064/528
[A[ATraining Step: 54  | total loss: [1m[32m0.43321[0m[0m | time: 17.372s
[2K
| Adam | epoch: 004 | loss: 0.43321 - acc: 0.8299 -- iter: 096/528
[A[ATraining Step: 55  | total loss: [1m[32m0.40471[0m[0m | time: 25.602s
[2K
| Adam | epoch: 004 | loss: 0.40471 - acc: 0.8453 -- iter: 128/528
[A[ATraining Step: 56  | total loss: [1m[32m0.38148[0m[0m | time: 33.893s
[2K
| Adam | epoch: 004 | loss: 0.38148 - acc: 0.8538 -- iter: 160/528
[A[ATraining Step: 57  | total loss: [1m[32m0.40572[0m[0m | time: 42.088s
[2K
| Adam | epoch: 004 | loss: 0.40572 - acc: 0.8438 -- iter: 192/528
[A[ATraining Step: 58  | total loss: [1m[32m0.43220[0m[0m | time: 50.213s
[2K
| Adam | epoch: 004 | loss: 0.43220 - acc: 0.8353 -- iter: 224/528
[A[ATraining Step: 59  | total loss: [1m[32m0.41272[0m[0m | time: 58.493s
[2K
| Adam | epoch: 004 | loss: 0.41272 - acc: 0.8448 -- iter: 256/528
[A[ATraining Step: 60  | total loss: [1m[32m0.41046[0m[0m | time: 66.792s
[2K
| Adam | epoch: 004 | loss: 0.41046 - acc: 0.8488 -- iter: 288/528
[A[ATraining Step: 61  | total loss: [1m[32m0.40119[0m[0m | time: 74.898s
[2K
| Adam | epoch: 004 | loss: 0.40119 - acc: 0.8481 -- iter: 320/528
[A[ATraining Step: 62  | total loss: [1m[32m0.37490[0m[0m | time: 82.989s
[2K
| Adam | epoch: 004 | loss: 0.37490 - acc: 0.8516 -- iter: 352/528
[A[ATraining Step: 63  | total loss: [1m[32m0.35839[0m[0m | time: 91.204s
[2K
| Adam | epoch: 004 | loss: 0.35839 - acc: 0.8664 -- iter: 384/528
[A[ATraining Step: 64  | total loss: [1m[32m0.35871[0m[0m | time: 99.351s
[2K
| Adam | epoch: 004 | loss: 0.35871 - acc: 0.8519 -- iter: 416/528
[A[ATraining Step: 65  | total loss: [1m[32m0.34083[0m[0m | time: 107.627s
[2K
| Adam | epoch: 004 | loss: 0.34083 - acc: 0.8586 -- iter: 448/528
[A[ATraining Step: 66  | total loss: [1m[32m0.32726[0m[0m | time: 115.868s
[2K
| Adam | epoch: 004 | loss: 0.32726 - acc: 0.8606 -- iter: 480/528
[A[ATraining Step: 67  | total loss: [1m[32m0.33221[0m[0m | time: 124.097s
[2K
| Adam | epoch: 004 | loss: 0.33221 - acc: 0.8586 -- iter: 512/528
[A[ATraining Step: 68  | total loss: [1m[32m0.33538[0m[0m | time: 139.569s
[2K
| Adam | epoch: 004 | loss: 0.33538 - acc: 0.8605 | val_loss: 0.97841 - val_acc: 0.6747 -- iter: 528/528
--
Training Step: 69  | total loss: [1m[32m0.32417[0m[0m | time: 8.156s
[2K
| Adam | epoch: 005 | loss: 0.32417 - acc: 0.8659 -- iter: 032/528
[A[ATraining Step: 70  | total loss: [1m[32m0.31004[0m[0m | time: 16.206s
[2K
| Adam | epoch: 005 | loss: 0.31004 - acc: 0.8705 -- iter: 064/528
[A[ATraining Step: 71  | total loss: [1m[32m0.32716[0m[0m | time: 20.865s
[2K
| Adam | epoch: 005 | loss: 0.32716 - acc: 0.8675 -- iter: 096/528
[A[ATraining Step: 72  | total loss: [1m[32m0.34387[0m[0m | time: 25.473s
[2K
| Adam | epoch: 005 | loss: 0.34387 - acc: 0.8543 -- iter: 128/528
[A[ATraining Step: 73  | total loss: [1m[32m0.31688[0m[0m | time: 33.469s
[2K
| Adam | epoch: 005 | loss: 0.31688 - acc: 0.8704 -- iter: 160/528
[A[ATraining Step: 74  | total loss: [1m[32m0.35498[0m[0m | time: 41.785s
[2K
| Adam | epoch: 005 | loss: 0.35498 - acc: 0.8572 -- iter: 192/528
[A[ATraining Step: 75  | total loss: [1m[32m0.36657[0m[0m | time: 49.690s
[2K
| Adam | epoch: 005 | loss: 0.36657 - acc: 0.8456 -- iter: 224/528
[A[ATraining Step: 76  | total loss: [1m[32m0.37052[0m[0m | time: 57.768s
[2K
| Adam | epoch: 005 | loss: 0.37052 - acc: 0.8487 -- iter: 256/528
[A[ATraining Step: 77  | total loss: [1m[32m0.35914[0m[0m | time: 66.004s
[2K
| Adam | epoch: 005 | loss: 0.35914 - acc: 0.8548 -- iter: 288/528
[A[ATraining Step: 78  | total loss: [1m[32m0.33374[0m[0m | time: 74.115s
[2K
| Adam | epoch: 005 | loss: 0.33374 - acc: 0.8700 -- iter: 320/528
[A[ATraining Step: 79  | total loss: [1m[32m0.32736[0m[0m | time: 82.052s
[2K
| Adam | epoch: 005 | loss: 0.32736 - acc: 0.8705 -- iter: 352/528
[A[ATraining Step: 80  | total loss: [1m[32m0.35315[0m[0m | time: 90.359s
[2K
| Adam | epoch: 005 | loss: 0.35315 - acc: 0.8582 -- iter: 384/528
[A[ATraining Step: 81  | total loss: [1m[32m0.34585[0m[0m | time: 98.370s
[2K
| Adam | epoch: 005 | loss: 0.34585 - acc: 0.8568 -- iter: 416/528
[A[ATraining Step: 82  | total loss: [1m[32m0.33703[0m[0m | time: 106.579s
[2K
| Adam | epoch: 005 | loss: 0.33703 - acc: 0.8586 -- iter: 448/528
[A[ATraining Step: 83  | total loss: [1m[32m0.31548[0m[0m | time: 114.635s
[2K
| Adam | epoch: 005 | loss: 0.31548 - acc: 0.8665 -- iter: 480/528
[A[ATraining Step: 84  | total loss: [1m[32m0.32076[0m[0m | time: 122.765s
[2K
| Adam | epoch: 005 | loss: 0.32076 - acc: 0.8673 -- iter: 512/528
[A[ATraining Step: 85  | total loss: [1m[32m0.33467[0m[0m | time: 138.226s
[2K
| Adam | epoch: 005 | loss: 0.33467 - acc: 0.8618 | val_loss: 0.93819 - val_acc: 0.6747 -- iter: 528/528
--
Training Step: 86  | total loss: [1m[32m0.33927[0m[0m | time: 8.062s
[2K
| Adam | epoch: 006 | loss: 0.33927 - acc: 0.8569 -- iter: 032/528
[A[ATraining Step: 87  | total loss: [1m[32m0.33394[0m[0m | time: 16.133s
[2K
| Adam | epoch: 006 | loss: 0.33394 - acc: 0.8587 -- iter: 064/528
[A[ATraining Step: 88  | total loss: [1m[32m0.31891[0m[0m | time: 24.266s
[2K
| Adam | epoch: 006 | loss: 0.31891 - acc: 0.8666 -- iter: 096/528
[A[ATraining Step: 89  | total loss: [1m[32m0.32659[0m[0m | time: 28.742s
[2K
| Adam | epoch: 006 | loss: 0.32659 - acc: 0.8643 -- iter: 128/528
[A[ATraining Step: 90  | total loss: [1m[32m0.31619[0m[0m | time: 33.418s
[2K
| Adam | epoch: 006 | loss: 0.31619 - acc: 0.8654 -- iter: 160/528
[A[ATraining Step: 91  | total loss: [1m[32m0.28862[0m[0m | time: 42.731s
[2K
| Adam | epoch: 006 | loss: 0.28862 - acc: 0.8788 -- iter: 192/528
[A[ATraining Step: 92  | total loss: [1m[32m0.31420[0m[0m | time: 52.677s
[2K
| Adam | epoch: 006 | loss: 0.31420 - acc: 0.8753 -- iter: 224/528
[A[ATraining Step: 93  | total loss: [1m[32m0.32165[0m[0m | time: 63.004s
[2K
| Adam | epoch: 006 | loss: 0.32165 - acc: 0.8784 -- iter: 256/528
[A[ATraining Step: 94  | total loss: [1m[32m0.32673[0m[0m | time: 73.042s
[2K
| Adam | epoch: 006 | loss: 0.32673 - acc: 0.8812 -- iter: 288/528
[A[ATraining Step: 95  | total loss: [1m[32m0.32153[0m[0m | time: 83.033s
[2K
| Adam | epoch: 006 | loss: 0.32153 - acc: 0.8806 -- iter: 320/528
[A[ATraining Step: 96  | total loss: [1m[32m0.31081[0m[0m | time: 93.297s
[2K
| Adam | epoch: 006 | loss: 0.31081 - acc: 0.8832 -- iter: 352/528
[A[ATraining Step: 97  | total loss: [1m[32m0.30575[0m[0m | time: 103.035s
[2K
| Adam | epoch: 006 | loss: 0.30575 - acc: 0.8761 -- iter: 384/528
[A[ATraining Step: 98  | total loss: [1m[32m0.30948[0m[0m | time: 113.031s
[2K
| Adam | epoch: 006 | loss: 0.30948 - acc: 0.8729 -- iter: 416/528
[A[ATraining Step: 99  | total loss: [1m[32m0.29605[0m[0m | time: 123.410s
[2K
| Adam | epoch: 006 | loss: 0.29605 - acc: 0.8824 -- iter: 448/528
[A[ATraining Step: 100  | total loss: [1m[32m0.28597[0m[0m | time: 133.219s
[2K
| Adam | epoch: 006 | loss: 0.28597 - acc: 0.8879 -- iter: 480/528
[A[ATraining Step: 101  | total loss: [1m[32m0.26879[0m[0m | time: 143.512s
[2K
| Adam | epoch: 006 | loss: 0.26879 - acc: 0.8960 -- iter: 512/528
[A[ATraining Step: 102  | total loss: [1m[32m0.25596[0m[0m | time: 162.704s
[2K
| Adam | epoch: 006 | loss: 0.25596 - acc: 0.9033 | val_loss: 1.62114 - val_acc: 0.5060 -- iter: 528/528
--
Training Step: 103  | total loss: [1m[32m0.25897[0m[0m | time: 10.074s
[2K
| Adam | epoch: 007 | loss: 0.25897 - acc: 0.9067 -- iter: 032/528
[A[ATraining Step: 104  | total loss: [1m[32m0.27549[0m[0m | time: 20.155s
[2K
| Adam | epoch: 007 | loss: 0.27549 - acc: 0.9004 -- iter: 064/528
[A[ATraining Step: 105  | total loss: [1m[32m0.26203[0m[0m | time: 30.074s
[2K
| Adam | epoch: 007 | loss: 0.26203 - acc: 0.9073 -- iter: 096/528
[A[ATraining Step: 106  | total loss: [1m[32m0.25275[0m[0m | time: 40.485s
[2K
| Adam | epoch: 007 | loss: 0.25275 - acc: 0.9072 -- iter: 128/528
[A[ATraining Step: 107  | total loss: [1m[32m0.25667[0m[0m | time: 46.142s
[2K
| Adam | epoch: 007 | loss: 0.25667 - acc: 0.9039 -- iter: 160/528
[A[ATraining Step: 108  | total loss: [1m[32m0.25537[0m[0m | time: 51.712s
[2K
| Adam | epoch: 007 | loss: 0.25537 - acc: 0.9073 -- iter: 192/528
[A[ATraining Step: 109  | total loss: [1m[32m0.23415[0m[0m | time: 62.189s
[2K
| Adam | epoch: 007 | loss: 0.23415 - acc: 0.9166 -- iter: 224/528
[A[ATraining Step: 110  | total loss: [1m[32m0.23042[0m[0m | time: 72.111s
[2K
| Adam | epoch: 007 | loss: 0.23042 - acc: 0.9187 -- iter: 256/528
[A[ATraining Step: 111  | total loss: [1m[32m0.23192[0m[0m | time: 81.941s
[2K
| Adam | epoch: 007 | loss: 0.23192 - acc: 0.9174 -- iter: 288/528
[A[ATraining Step: 112  | total loss: [1m[32m0.22884[0m[0m | time: 92.344s
[2K
| Adam | epoch: 007 | loss: 0.22884 - acc: 0.9163 -- iter: 320/528
[A[ATraining Step: 113  | total loss: [1m[32m0.22259[0m[0m | time: 103.465s
[2K
| Adam | epoch: 007 | loss: 0.22259 - acc: 0.9184 -- iter: 352/528
[A[ATraining Step: 114  | total loss: [1m[32m0.20959[0m[0m | time: 113.619s
[2K
| Adam | epoch: 007 | loss: 0.20959 - acc: 0.9203 -- iter: 384/528
[A[ATraining Step: 115  | total loss: [1m[32m0.20275[0m[0m | time: 123.799s
[2K
| Adam | epoch: 007 | loss: 0.20275 - acc: 0.9252 -- iter: 416/528
[A[ATraining Step: 116  | total loss: [1m[32m0.23389[0m[0m | time: 133.590s
[2K
| Adam | epoch: 007 | loss: 0.23389 - acc: 0.9139 -- iter: 448/528
[A[ATraining Step: 117  | total loss: [1m[32m0.21704[0m[0m | time: 143.756s
[2K
| Adam | epoch: 007 | loss: 0.21704 - acc: 0.9194 -- iter: 480/528
[A[ATraining Step: 118  | total loss: [1m[32m0.20358[0m[0m | time: 153.699s
[2K
| Adam | epoch: 007 | loss: 0.20358 - acc: 0.9243 -- iter: 512/528
[A[ATraining Step: 119  | total loss: [1m[32m0.19997[0m[0m | time: 173.313s
[2K
| Adam | epoch: 007 | loss: 0.19997 - acc: 0.9194 | val_loss: 2.73987 - val_acc: 0.6506 -- iter: 528/528
--
Training Step: 120  | total loss: [1m[32m0.24227[0m[0m | time: 9.859s
[2K
| Adam | epoch: 008 | loss: 0.24227 - acc: 0.9087 -- iter: 032/528
[A[ATraining Step: 121  | total loss: [1m[32m0.22190[0m[0m | time: 19.813s
[2K
| Adam | epoch: 008 | loss: 0.22190 - acc: 0.9178 -- iter: 064/528
[A[ATraining Step: 122  | total loss: [1m[32m0.21426[0m[0m | time: 29.813s
[2K
| Adam | epoch: 008 | loss: 0.21426 - acc: 0.9167 -- iter: 096/528
[A[ATraining Step: 123  | total loss: [1m[32m0.19807[0m[0m | time: 39.690s
[2K
| Adam | epoch: 008 | loss: 0.19807 - acc: 0.9219 -- iter: 128/528
[A[ATraining Step: 124  | total loss: [1m[32m0.21980[0m[0m | time: 49.746s
[2K
| Adam | epoch: 008 | loss: 0.21980 - acc: 0.9141 -- iter: 160/528
[A[ATraining Step: 125  | total loss: [1m[32m0.20497[0m[0m | time: 55.179s
[2K
| Adam | epoch: 008 | loss: 0.20497 - acc: 0.9195 -- iter: 192/528
[A[ATraining Step: 126  | total loss: [1m[32m0.22254[0m[0m | time: 61.810s
[2K
| Adam | epoch: 008 | loss: 0.22254 - acc: 0.9151 -- iter: 224/528
[A[ATraining Step: 127  | total loss: [1m[32m0.20965[0m[0m | time: 70.260s
[2K
| Adam | epoch: 008 | loss: 0.20965 - acc: 0.9173 -- iter: 256/528
[A[ATraining Step: 128  | total loss: [1m[32m0.21093[0m[0m | time: 78.478s
[2K
| Adam | epoch: 008 | loss: 0.21093 - acc: 0.9225 -- iter: 288/528
[A[ATraining Step: 129  | total loss: [1m[32m0.20933[0m[0m | time: 86.517s
[2K
| Adam | epoch: 008 | loss: 0.20933 - acc: 0.9177 -- iter: 320/528
[A[ATraining Step: 130  | total loss: [1m[32m0.22117[0m[0m | time: 94.636s
[2K
| Adam | epoch: 008 | loss: 0.22117 - acc: 0.9166 -- iter: 352/528
[A[ATraining Step: 131  | total loss: [1m[32m0.21435[0m[0m | time: 102.634s
[2K
| Adam | epoch: 008 | loss: 0.21435 - acc: 0.9187 -- iter: 384/528
[A[ATraining Step: 132  | total loss: [1m[32m0.20933[0m[0m | time: 110.738s
[2K
| Adam | epoch: 008 | loss: 0.20933 - acc: 0.9205 -- iter: 416/528
[A[ATraining Step: 133  | total loss: [1m[32m0.19525[0m[0m | time: 118.633s
[2K
| Adam | epoch: 008 | loss: 0.19525 - acc: 0.9285 -- iter: 448/528
[A[ATraining Step: 134  | total loss: [1m[32m0.22149[0m[0m | time: 126.743s
[2K
| Adam | epoch: 008 | loss: 0.22149 - acc: 0.9138 -- iter: 480/528
[A[ATraining Step: 135  | total loss: [1m[32m0.22825[0m[0m | time: 134.868s
[2K
| Adam | epoch: 008 | loss: 0.22825 - acc: 0.9130 -- iter: 512/528
[A[ATraining Step: 136  | total loss: [1m[32m0.21981[0m[0m | time: 150.107s
[2K
| Adam | epoch: 008 | loss: 0.21981 - acc: 0.9186 | val_loss: 0.90941 - val_acc: 0.6627 -- iter: 528/528
--
Training Step: 137  | total loss: [1m[32m0.21164[0m[0m | time: 8.200s
[2K
| Adam | epoch: 009 | loss: 0.21164 - acc: 0.9236 -- iter: 032/528
[A[ATraining Step: 138  | total loss: [1m[32m0.19503[0m[0m | time: 16.221s
[2K
| Adam | epoch: 009 | loss: 0.19503 - acc: 0.9312 -- iter: 064/528
[A[ATraining Step: 139  | total loss: [1m[32m0.20216[0m[0m | time: 24.396s
[2K
| Adam | epoch: 009 | loss: 0.20216 - acc: 0.9287 -- iter: 096/528
[A[ATraining Step: 140  | total loss: [1m[32m0.21180[0m[0m | time: 32.459s
[2K
| Adam | epoch: 009 | loss: 0.21180 - acc: 0.9327 -- iter: 128/528
[A[ATraining Step: 141  | total loss: [1m[32m0.19842[0m[0m | time: 40.520s
[2K
| Adam | epoch: 009 | loss: 0.19842 - acc: 0.9363 -- iter: 160/528
[A[ATraining Step: 142  | total loss: [1m[32m0.20717[0m[0m | time: 48.609s
[2K
| Adam | epoch: 009 | loss: 0.20717 - acc: 0.9365 -- iter: 192/528
[A[ATraining Step: 143  | total loss: [1m[32m0.20310[0m[0m | time: 53.178s
[2K
| Adam | epoch: 009 | loss: 0.20310 - acc: 0.9397 -- iter: 224/528
[A[ATraining Step: 144  | total loss: [1m[32m0.20569[0m[0m | time: 57.690s
[2K
| Adam | epoch: 009 | loss: 0.20569 - acc: 0.9395 -- iter: 256/528
[A[ATraining Step: 145  | total loss: [1m[32m0.18795[0m[0m | time: 65.779s
[2K
| Adam | epoch: 009 | loss: 0.18795 - acc: 0.9455 -- iter: 288/528
[A[ATraining Step: 146  | total loss: [1m[32m0.17538[0m[0m | time: 73.878s
[2K
| Adam | epoch: 009 | loss: 0.17538 - acc: 0.9478 -- iter: 320/528
[A[ATraining Step: 147  | total loss: [1m[32m0.18800[0m[0m | time: 81.955s
[2K
| Adam | epoch: 009 | loss: 0.18800 - acc: 0.9437 -- iter: 352/528
[A[ATraining Step: 148  | total loss: [1m[32m0.18600[0m[0m | time: 89.912s
[2K
| Adam | epoch: 009 | loss: 0.18600 - acc: 0.9431 -- iter: 384/528
[A[ATraining Step: 149  | total loss: [1m[32m0.18376[0m[0m | time: 98.093s
[2K
| Adam | epoch: 009 | loss: 0.18376 - acc: 0.9456 -- iter: 416/528
[A[ATraining Step: 150  | total loss: [1m[32m0.17745[0m[0m | time: 106.186s
[2K
| Adam | epoch: 009 | loss: 0.17745 - acc: 0.9479 -- iter: 448/528
[A[ATraining Step: 151  | total loss: [1m[32m0.17040[0m[0m | time: 114.199s
[2K
| Adam | epoch: 009 | loss: 0.17040 - acc: 0.9500 -- iter: 480/528
[A[ATraining Step: 152  | total loss: [1m[32m0.15731[0m[0m | time: 122.102s
[2K
| Adam | epoch: 009 | loss: 0.15731 - acc: 0.9550 -- iter: 512/528
[A[ATraining Step: 153  | total loss: [1m[32m0.18163[0m[0m | time: 137.543s
[2K
| Adam | epoch: 009 | loss: 0.18163 - acc: 0.9533 | val_loss: 2.67942 - val_acc: 0.4337 -- iter: 528/528
--
Training Step: 154  | total loss: [1m[32m0.16644[0m[0m | time: 8.234s
[2K
| Adam | epoch: 010 | loss: 0.16644 - acc: 0.9579 -- iter: 032/528
[A[ATraining Step: 155  | total loss: [1m[32m0.15609[0m[0m | time: 16.125s
[2K
| Adam | epoch: 010 | loss: 0.15609 - acc: 0.9622 -- iter: 064/528
[A[ATraining Step: 156  | total loss: [1m[32m0.16238[0m[0m | time: 24.280s
[2K
| Adam | epoch: 010 | loss: 0.16238 - acc: 0.9566 -- iter: 096/528
[A[ATraining Step: 157  | total loss: [1m[32m0.15813[0m[0m | time: 32.309s
[2K
| Adam | epoch: 010 | loss: 0.15813 - acc: 0.9547 -- iter: 128/528
[A[ATraining Step: 158  | total loss: [1m[32m0.14825[0m[0m | time: 40.391s
[2K
| Adam | epoch: 010 | loss: 0.14825 - acc: 0.9561 -- iter: 160/528
[A[ATraining Step: 159  | total loss: [1m[32m0.13697[0m[0m | time: 48.338s
[2K
| Adam | epoch: 010 | loss: 0.13697 - acc: 0.9605 -- iter: 192/528
[A[ATraining Step: 160  | total loss: [1m[32m0.13716[0m[0m | time: 56.383s
[2K
| Adam | epoch: 010 | loss: 0.13716 - acc: 0.9582 -- iter: 224/528
[A[ATraining Step: 161  | total loss: [1m[32m0.13534[0m[0m | time: 60.876s
[2K
| Adam | epoch: 010 | loss: 0.13534 - acc: 0.9530 -- iter: 256/528
[A[ATraining Step: 162  | total loss: [1m[32m0.17438[0m[0m | time: 65.385s
[2K
| Adam | epoch: 010 | loss: 0.17438 - acc: 0.9452 -- iter: 288/528
[A[ATraining Step: 163  | total loss: [1m[32m0.16274[0m[0m | time: 73.395s
[2K
| Adam | epoch: 010 | loss: 0.16274 - acc: 0.9507 -- iter: 320/528
[A[ATraining Step: 164  | total loss: [1m[32m0.14862[0m[0m | time: 81.487s
[2K
| Adam | epoch: 010 | loss: 0.14862 - acc: 0.9556 -- iter: 352/528
[A[ATraining Step: 165  | total loss: [1m[32m0.15243[0m[0m | time: 89.427s
[2K
| Adam | epoch: 010 | loss: 0.15243 - acc: 0.9538 -- iter: 384/528
[A[ATraining Step: 166  | total loss: [1m[32m0.19937[0m[0m | time: 97.471s
[2K
| Adam | epoch: 010 | loss: 0.19937 - acc: 0.9459 -- iter: 416/528
[A[ATraining Step: 167  | total loss: [1m[32m0.18961[0m[0m | time: 105.648s
[2K
| Adam | epoch: 010 | loss: 0.18961 - acc: 0.9451 -- iter: 448/528
[A[ATraining Step: 168  | total loss: [1m[32m0.18442[0m[0m | time: 113.649s
[2K
| Adam | epoch: 010 | loss: 0.18442 - acc: 0.9443 -- iter: 480/528
[A[ATraining Step: 169  | total loss: [1m[32m0.19101[0m[0m | time: 121.780s
[2K
| Adam | epoch: 010 | loss: 0.19101 - acc: 0.9468 -- iter: 512/528
[A[ATraining Step: 170  | total loss: [1m[32m0.19966[0m[0m | time: 137.187s
[2K
| Adam | epoch: 010 | loss: 0.19966 - acc: 0.9396 | val_loss: 0.95471 - val_acc: 0.6024 -- iter: 528/528
--
Training Step: 171  | total loss: [1m[32m0.18437[0m[0m | time: 8.063s
[2K
| Adam | epoch: 011 | loss: 0.18437 - acc: 0.9456 -- iter: 032/528
[A[ATraining Step: 172  | total loss: [1m[32m0.17201[0m[0m | time: 16.092s
[2K
| Adam | epoch: 011 | loss: 0.17201 - acc: 0.9511 -- iter: 064/528
[A[ATraining Step: 173  | total loss: [1m[32m0.15830[0m[0m | time: 24.177s
[2K
| Adam | epoch: 011 | loss: 0.15830 - acc: 0.9560 -- iter: 096/528
[A[ATraining Step: 174  | total loss: [1m[32m0.15569[0m[0m | time: 32.144s
[2K
| Adam | epoch: 011 | loss: 0.15569 - acc: 0.9541 -- iter: 128/528
[A[ATraining Step: 175  | total loss: [1m[32m0.15512[0m[0m | time: 40.169s
[2K
| Adam | epoch: 011 | loss: 0.15512 - acc: 0.9556 -- iter: 160/528
[A[ATraining Step: 176  | total loss: [1m[32m0.17581[0m[0m | time: 48.197s
[2K
| Adam | epoch: 011 | loss: 0.17581 - acc: 0.9475 -- iter: 192/528
[A[ATraining Step: 177  | total loss: [1m[32m0.16988[0m[0m | time: 56.101s
[2K
| Adam | epoch: 011 | loss: 0.16988 - acc: 0.9465 -- iter: 224/528
[A[ATraining Step: 178  | total loss: [1m[32m0.16453[0m[0m | time: 64.398s
[2K
| Adam | epoch: 011 | loss: 0.16453 - acc: 0.9487 -- iter: 256/528
[A[ATraining Step: 179  | total loss: [1m[32m0.15754[0m[0m | time: 68.815s
[2K
| Adam | epoch: 011 | loss: 0.15754 - acc: 0.9476 -- iter: 288/528
[A[ATraining Step: 180  | total loss: [1m[32m0.15876[0m[0m | time: 73.278s
[2K
| Adam | epoch: 011 | loss: 0.15876 - acc: 0.9466 -- iter: 320/528
[A[ATraining Step: 181  | total loss: [1m[32m0.14734[0m[0m | time: 81.339s
[2K
| Adam | epoch: 011 | loss: 0.14734 - acc: 0.9519 -- iter: 352/528
[A[ATraining Step: 182  | total loss: [1m[32m0.14905[0m[0m | time: 89.234s
[2K
| Adam | epoch: 011 | loss: 0.14905 - acc: 0.9536 -- iter: 384/528
[A[ATraining Step: 183  | total loss: [1m[32m0.13694[0m[0m | time: 97.348s
[2K
| Adam | epoch: 011 | loss: 0.13694 - acc: 0.9583 -- iter: 416/528
[A[ATraining Step: 184  | total loss: [1m[32m0.19525[0m[0m | time: 105.366s
[2K
| Adam | epoch: 011 | loss: 0.19525 - acc: 0.9499 -- iter: 448/528
[A[ATraining Step: 185  | total loss: [1m[32m0.18924[0m[0m | time: 113.369s
[2K
| Adam | epoch: 011 | loss: 0.18924 - acc: 0.9487 -- iter: 480/528
[A[ATraining Step: 186  | total loss: [1m[32m0.18447[0m[0m | time: 121.303s
[2K
| Adam | epoch: 011 | loss: 0.18447 - acc: 0.9476 -- iter: 512/528
[A[ATraining Step: 187  | total loss: [1m[32m0.18687[0m[0m | time: 136.564s
[2K
| Adam | epoch: 011 | loss: 0.18687 - acc: 0.9434 | val_loss: 0.74715 - val_acc: 0.7410 -- iter: 528/528
--
Training Step: 188  | total loss: [1m[32m0.18829[0m[0m | time: 8.026s
[2K
| Adam | epoch: 012 | loss: 0.18829 - acc: 0.9460 -- iter: 032/528
[A[ATraining Step: 189  | total loss: [1m[32m0.17702[0m[0m | time: 16.011s
[2K
| Adam | epoch: 012 | loss: 0.17702 - acc: 0.9482 -- iter: 064/528
[A[ATraining Step: 190  | total loss: [1m[32m0.17862[0m[0m | time: 24.048s
[2K
| Adam | epoch: 012 | loss: 0.17862 - acc: 0.9472 -- iter: 096/528
[A[ATraining Step: 191  | total loss: [1m[32m0.16591[0m[0m | time: 32.134s
[2K
| Adam | epoch: 012 | loss: 0.16591 - acc: 0.9525 -- iter: 128/528
[A[ATraining Step: 192  | total loss: [1m[32m0.17019[0m[0m | time: 40.272s
[2K
| Adam | epoch: 012 | loss: 0.17019 - acc: 0.9510 -- iter: 160/528
[A[ATraining Step: 193  | total loss: [1m[32m0.15964[0m[0m | time: 48.231s
[2K
| Adam | epoch: 012 | loss: 0.15964 - acc: 0.9527 -- iter: 192/528
[A[ATraining Step: 194  | total loss: [1m[32m0.14695[0m[0m | time: 56.109s
[2K
| Adam | epoch: 012 | loss: 0.14695 - acc: 0.9575 -- iter: 224/528
[A[ATraining Step: 195  | total loss: [1m[32m0.14306[0m[0m | time: 64.059s
[2K
| Adam | epoch: 012 | loss: 0.14306 - acc: 0.9586 -- iter: 256/528
[A[ATraining Step: 196  | total loss: [1m[32m0.13366[0m[0m | time: 72.122s
[2K
| Adam | epoch: 012 | loss: 0.13366 - acc: 0.9627 -- iter: 288/528
[A[ATraining Step: 197  | total loss: [1m[32m0.12577[0m[0m | time: 76.605s
[2K
| Adam | epoch: 012 | loss: 0.12577 - acc: 0.9665 -- iter: 320/528
[A[ATraining Step: 198  | total loss: [1m[32m0.13143[0m[0m | time: 81.021s
[2K
| Adam | epoch: 012 | loss: 0.13143 - acc: 0.9573 -- iter: 352/528
[A[ATraining Step: 199  | total loss: [1m[32m0.12159[0m[0m | time: 89.006s
[2K
| Adam | epoch: 012 | loss: 0.12159 - acc: 0.9616 -- iter: 384/528
[A[ATraining Step: 200  | total loss: [1m[32m0.12971[0m[0m | time: 104.307s
[2K
| Adam | epoch: 012 | loss: 0.12971 - acc: 0.9623 | val_loss: 1.18309 - val_acc: 0.6145 -- iter: 416/528
--
Training Step: 201  | total loss: [1m[32m0.11940[0m[0m | time: 112.339s
[2K
| Adam | epoch: 012 | loss: 0.11940 - acc: 0.9661 -- iter: 448/528
[A[ATraining Step: 202  | total loss: [1m[32m0.11334[0m[0m | time: 120.234s
[2K
| Adam | epoch: 012 | loss: 0.11334 - acc: 0.9695 -- iter: 480/528
[A[ATraining Step: 203  | total loss: [1m[32m0.10340[0m[0m | time: 128.094s
[2K
| Adam | epoch: 012 | loss: 0.10340 - acc: 0.9725 -- iter: 512/528
[A[ATraining Step: 204  | total loss: [1m[32m0.09607[0m[0m | time: 143.384s
[2K
| Adam | epoch: 012 | loss: 0.09607 - acc: 0.9753 | val_loss: 2.69199 - val_acc: 0.4759 -- iter: 528/528
--
Training Step: 205  | total loss: [1m[32m0.09347[0m[0m | time: 7.793s
[2K
| Adam | epoch: 013 | loss: 0.09347 - acc: 0.9746 -- iter: 032/528
[A[ATraining Step: 206  | total loss: [1m[32m0.08516[0m[0m | time: 15.707s
[2K
| Adam | epoch: 013 | loss: 0.08516 - acc: 0.9772 -- iter: 064/528
[A[ATraining Step: 207  | total loss: [1m[32m0.07717[0m[0m | time: 23.741s
[2K
| Adam | epoch: 013 | loss: 0.07717 - acc: 0.9794 -- iter: 096/528
[A[ATraining Step: 208  | total loss: [1m[32m0.07098[0m[0m | time: 31.747s
[2K
| Adam | epoch: 013 | loss: 0.07098 - acc: 0.9815 -- iter: 128/528
[A[ATraining Step: 209  | total loss: [1m[32m0.07568[0m[0m | time: 39.738s
[2K
| Adam | epoch: 013 | loss: 0.07568 - acc: 0.9802 -- iter: 160/528
[A[ATraining Step: 210  | total loss: [1m[32m0.07537[0m[0m | time: 47.679s
[2K
| Adam | epoch: 013 | loss: 0.07537 - acc: 0.9759 -- iter: 192/528
[A[ATraining Step: 211  | total loss: [1m[32m0.06983[0m[0m | time: 55.663s
[2K
| Adam | epoch: 013 | loss: 0.06983 - acc: 0.9784 -- iter: 224/528
[A[ATraining Step: 212  | total loss: [1m[32m0.09919[0m[0m | time: 63.599s
[2K
| Adam | epoch: 013 | loss: 0.09919 - acc: 0.9743 -- iter: 256/528
[A[ATraining Step: 213  | total loss: [1m[32m0.09013[0m[0m | time: 71.510s
[2K
| Adam | epoch: 013 | loss: 0.09013 - acc: 0.9768 -- iter: 288/528
[A[ATraining Step: 214  | total loss: [1m[32m0.09357[0m[0m | time: 79.294s
[2K
| Adam | epoch: 013 | loss: 0.09357 - acc: 0.9698 -- iter: 320/528
[A[ATraining Step: 215  | total loss: [1m[32m0.09374[0m[0m | time: 83.938s
[2K
| Adam | epoch: 013 | loss: 0.09374 - acc: 0.9697 -- iter: 352/528
[A[ATraining Step: 216  | total loss: [1m[32m0.09426[0m[0m | time: 88.390s
[2K
| Adam | epoch: 013 | loss: 0.09426 - acc: 0.9665 -- iter: 384/528
[A[ATraining Step: 217  | total loss: [1m[32m0.08628[0m[0m | time: 96.438s
[2K
| Adam | epoch: 013 | loss: 0.08628 - acc: 0.9698 -- iter: 416/528
[A[ATraining Step: 218  | total loss: [1m[32m0.10196[0m[0m | time: 104.306s
[2K
| Adam | epoch: 013 | loss: 0.10196 - acc: 0.9603 -- iter: 448/528
[A[ATraining Step: 219  | total loss: [1m[32m0.09755[0m[0m | time: 112.326s
[2K
| Adam | epoch: 013 | loss: 0.09755 - acc: 0.9612 -- iter: 480/528
[A[ATraining Step: 220  | total loss: [1m[32m0.10934[0m[0m | time: 120.308s
[2K
| Adam | epoch: 013 | loss: 0.10934 - acc: 0.9619 -- iter: 512/528
[A[ATraining Step: 221  | total loss: [1m[32m0.14719[0m[0m | time: 135.489s
[2K
| Adam | epoch: 013 | loss: 0.14719 - acc: 0.9470 | val_loss: 0.73063 - val_acc: 0.7470 -- iter: 528/528
--
Training Step: 222  | total loss: [1m[32m0.14716[0m[0m | time: 8.048s
[2K
| Adam | epoch: 014 | loss: 0.14716 - acc: 0.9492 -- iter: 032/528
[A[ATraining Step: 223  | total loss: [1m[32m0.13319[0m[0m | time: 16.169s
[2K
| Adam | epoch: 014 | loss: 0.13319 - acc: 0.9542 -- iter: 064/528
[A[ATraining Step: 224  | total loss: [1m[32m0.12190[0m[0m | time: 24.109s
[2K
| Adam | epoch: 014 | loss: 0.12190 - acc: 0.9588 -- iter: 096/528
[A[ATraining Step: 225  | total loss: [1m[32m0.11309[0m[0m | time: 32.173s
[2K
| Adam | epoch: 014 | loss: 0.11309 - acc: 0.9629 -- iter: 128/528
[A[ATraining Step: 226  | total loss: [1m[32m0.10792[0m[0m | time: 40.141s
[2K
| Adam | epoch: 014 | loss: 0.10792 - acc: 0.9666 -- iter: 160/528
[A[ATraining Step: 227  | total loss: [1m[32m0.10381[0m[0m | time: 48.085s
[2K
| Adam | epoch: 014 | loss: 0.10381 - acc: 0.9669 -- iter: 192/528
[A[ATraining Step: 228  | total loss: [1m[32m0.11273[0m[0m | time: 55.969s
[2K
| Adam | epoch: 014 | loss: 0.11273 - acc: 0.9639 -- iter: 224/528
[A[ATraining Step: 229  | total loss: [1m[32m0.11080[0m[0m | time: 64.114s
[2K
| Adam | epoch: 014 | loss: 0.11080 - acc: 0.9644 -- iter: 256/528
[A[ATraining Step: 230  | total loss: [1m[32m0.10406[0m[0m | time: 72.128s
[2K
| Adam | epoch: 014 | loss: 0.10406 - acc: 0.9648 -- iter: 288/528
[A[ATraining Step: 231  | total loss: [1m[32m0.10016[0m[0m | time: 80.278s
[2K
| Adam | epoch: 014 | loss: 0.10016 - acc: 0.9684 -- iter: 320/528
[A[ATraining Step: 232  | total loss: [1m[32m0.10946[0m[0m | time: 88.275s
[2K
| Adam | epoch: 014 | loss: 0.10946 - acc: 0.9653 -- iter: 352/528
[A[ATraining Step: 233  | total loss: [1m[32m0.11147[0m[0m | time: 92.817s
[2K
| Adam | epoch: 014 | loss: 0.11147 - acc: 0.9625 -- iter: 384/528
[A[ATraining Step: 234  | total loss: [1m[32m0.10457[0m[0m | time: 97.320s
[2K
| Adam | epoch: 014 | loss: 0.10457 - acc: 0.9662 -- iter: 416/528
[A[ATraining Step: 235  | total loss: [1m[32m0.09528[0m[0m | time: 105.286s
[2K
| Adam | epoch: 014 | loss: 0.09528 - acc: 0.9696 -- iter: 448/528
[A[ATraining Step: 236  | total loss: [1m[32m0.09123[0m[0m | time: 113.195s
[2K
| Adam | epoch: 014 | loss: 0.09123 - acc: 0.9727 -- iter: 480/528
[A[ATraining Step: 237  | total loss: [1m[32m0.08489[0m[0m | time: 121.048s
[2K
| Adam | epoch: 014 | loss: 0.08489 - acc: 0.9754 -- iter: 512/528
[A[ATraining Step: 238  | total loss: [1m[32m0.08362[0m[0m | time: 136.211s
[2K
| Adam | epoch: 014 | loss: 0.08362 - acc: 0.9747 | val_loss: 1.12313 - val_acc: 0.6446 -- iter: 528/528
--
Training Step: 239  | total loss: [1m[32m0.08225[0m[0m | time: 8.180s
[2K
| Adam | epoch: 015 | loss: 0.08225 - acc: 0.9741 -- iter: 032/528
[A[ATraining Step: 240  | total loss: [1m[32m0.07566[0m[0m | time: 16.085s
[2K
| Adam | epoch: 015 | loss: 0.07566 - acc: 0.9767 -- iter: 064/528
[A[ATraining Step: 241  | total loss: [1m[32m0.08745[0m[0m | time: 23.944s
[2K
| Adam | epoch: 015 | loss: 0.08745 - acc: 0.9759 -- iter: 096/528
[A[ATraining Step: 242  | total loss: [1m[32m0.10511[0m[0m | time: 32.041s
[2K
| Adam | epoch: 015 | loss: 0.10511 - acc: 0.9721 -- iter: 128/528
[A[ATraining Step: 243  | total loss: [1m[32m0.09706[0m[0m | time: 40.006s
[2K
| Adam | epoch: 015 | loss: 0.09706 - acc: 0.9749 -- iter: 160/528
[A[ATraining Step: 244  | total loss: [1m[32m0.08883[0m[0m | time: 47.794s
[2K
| Adam | epoch: 015 | loss: 0.08883 - acc: 0.9774 -- iter: 192/528
[A[ATraining Step: 245  | total loss: [1m[32m0.08200[0m[0m | time: 55.818s
[2K
| Adam | epoch: 015 | loss: 0.08200 - acc: 0.9796 -- iter: 224/528
[A[ATraining Step: 246  | total loss: [1m[32m0.09281[0m[0m | time: 63.743s
[2K
| Adam | epoch: 015 | loss: 0.09281 - acc: 0.9786 -- iter: 256/528
[A[ATraining Step: 247  | total loss: [1m[32m0.08610[0m[0m | time: 71.804s
[2K
| Adam | epoch: 015 | loss: 0.08610 - acc: 0.9807 -- iter: 288/528
[A[ATraining Step: 248  | total loss: [1m[32m0.07936[0m[0m | time: 79.913s
[2K
| Adam | epoch: 015 | loss: 0.07936 - acc: 0.9826 -- iter: 320/528
[A[ATraining Step: 249  | total loss: [1m[32m0.07432[0m[0m | time: 87.984s
[2K
| Adam | epoch: 015 | loss: 0.07432 - acc: 0.9844 -- iter: 352/528
[A[ATraining Step: 250  | total loss: [1m[32m0.08187[0m[0m | time: 95.945s
[2K
| Adam | epoch: 015 | loss: 0.08187 - acc: 0.9828 -- iter: 384/528
[A[ATraining Step: 251  | total loss: [1m[32m0.07682[0m[0m | time: 100.359s
[2K
| Adam | epoch: 015 | loss: 0.07682 - acc: 0.9845 -- iter: 416/528
[A[ATraining Step: 252  | total loss: [1m[32m0.06990[0m[0m | time: 104.917s
[2K
| Adam | epoch: 015 | loss: 0.06990 - acc: 0.9861 -- iter: 448/528
[A[ATraining Step: 253  | total loss: [1m[32m0.06356[0m[0m | time: 112.895s
[2K
| Adam | epoch: 015 | loss: 0.06356 - acc: 0.9875 -- iter: 480/528
[A[ATraining Step: 254  | total loss: [1m[32m0.07186[0m[0m | time: 121.032s
[2K
| Adam | epoch: 015 | loss: 0.07186 - acc: 0.9856 -- iter: 512/528
[A[ATraining Step: 255  | total loss: [1m[32m0.07801[0m[0m | time: 136.227s
[2K
| Adam | epoch: 015 | loss: 0.07801 - acc: 0.9839 | val_loss: 0.90416 - val_acc: 0.7530 -- iter: 528/528
--
Validation AUC:0.7819182389937107
Validation AUPRC:0.8380036126805368
Test AUC:0.7336609336609337
Test AUPRC:0.8442752047335244
BestTestF1Score	0.82	0.33	0.73	0.74	0.91	101	35	20	10	0.73
BestTestMCCScore	0.82	0.41	0.75	0.79	0.86	95	26	29	16	0.92
BestTestAccuracyScore	0.82	0.41	0.75	0.79	0.86	95	26	29	16	0.92
BestValidationF1Score	0.84	0.5	0.78	0.77	0.92	98	29	31	8	0.73
BestValidationMCC	0.83	0.5	0.78	0.8	0.87	92	23	37	14	0.92
BestValidationAccuracy	0.83	0.5	0.78	0.8	0.87	92	23	37	14	0.92
TestPredictions (Threshold:0.92)
CHEMBL2153163,TN,INACT,0.8500000238418579	CHEMBL3805662,TP,ACT,1.0	CHEMBL3357672,TN,INACT,0.11999999731779099	CHEMBL83563,TN,INACT,0.009999999776482582	CHEMBL345081,TP,ACT,1.0	CHEMBL2028919,TP,ACT,0.9800000190734863	CHEMBL3359785,TP,ACT,1.0	CHEMBL142118,TP,ACT,1.0	CHEMBL310855,TP,ACT,0.9800000190734863	CHEMBL378691,TP,ACT,0.9700000286102295	CHEMBL1086435,TN,INACT,0.8700000047683716	CHEMBL2370193,TP,ACT,0.949999988079071	CHEMBL608115,TP,ACT,1.0	CHEMBL3342185,TP,ACT,1.0	CHEMBL3237995,TN,INACT,0.009999999776482582	CHEMBL3640721,FN,ACT,0.6200000047683716	CHEMBL341197,TP,ACT,0.9399999976158142	CHEMBL370786,TP,ACT,1.0	CHEMBL387812,TP,ACT,1.0	CHEMBL159905,TN,INACT,0.7300000190734863	CHEMBL3218473,FN,ACT,0.4000000059604645	CHEMBL2071096,TP,ACT,0.9900000095367432	CHEMBL416281,TP,ACT,1.0	CHEMBL249915,TP,ACT,1.0	CHEMBL2382118,FP,INACT,1.0	CHEMBL1603238,TN,INACT,0.6200000047683716	CHEMBL3640712,TP,ACT,1.0	CHEMBL3804975,TP,ACT,0.949999988079071	CHEMBL1836508,FP,INACT,0.9800000190734863	CHEMBL258148,TN,INACT,0.5400000214576721	CHEMBL2070947,TP,ACT,1.0	CHEMBL550246,TP,ACT,0.9599999785423279	CHEMBL383816,TN,INACT,0.8199999928474426	CHEMBL213405,TP,ACT,0.9800000190734863	CHEMBL2387617,FP,INACT,0.9900000095367432	CHEMBL1240874,TP,ACT,0.949999988079071	CHEMBL2042448,TN,INACT,0.8999999761581421	CHEMBL440369,TP,ACT,1.0	CHEMBL205436,FP,INACT,0.9800000190734863	CHEMBL1350793,TN,INACT,0.0	CHEMBL3143406,FN,ACT,0.8899999856948853	CHEMBL3218471,TN,INACT,0.8799999952316284	CHEMBL423995,TP,ACT,1.0	CHEMBL3649378,TP,ACT,1.0	CHEMBL206243,FN,ACT,0.03999999910593033	CHEMBL326093,TP,ACT,1.0	CHEMBL122149,TP,ACT,1.0	CHEMBL2371795,TP,ACT,1.0	CHEMBL3649404,FN,ACT,0.8999999761581421	CHEMBL399733,TP,ACT,1.0	CHEMBL354132,TP,ACT,1.0	CHEMBL191558,FN,ACT,0.2800000011920929	CHEMBL2171986,TP,ACT,1.0	CHEMBL381621,TP,ACT,1.0	CHEMBL3806231,TN,INACT,0.3400000035762787	CHEMBL1086432,FN,ACT,0.0	CHEMBL315636,TP,ACT,0.9399999976158142	CHEMBL1241348,FP,INACT,0.9900000095367432	CHEMBL250119,TP,ACT,0.9700000286102295	CHEMBL1171636,FP,INACT,1.0	CHEMBL172456,TP,ACT,0.9800000190734863	CHEMBL2382002,FP,INACT,1.0	CHEMBL1651242,FN,ACT,0.05000000074505806	CHEMBL1084402,TP,ACT,1.0	CHEMBL497235,TP,ACT,0.9700000286102295	CHEMBL207579,FN,ACT,0.0	CHEMBL2316311,FP,INACT,0.9900000095367432	CHEMBL124159,TP,ACT,1.0	CHEMBL482167,FP,INACT,0.9800000190734863	CHEMBL1209129,TN,INACT,0.18000000715255737	CHEMBL394271,TP,ACT,1.0	CHEMBL436636,TP,ACT,0.9700000286102295	CHEMBL205504,TP,ACT,1.0	CHEMBL3357670,TN,INACT,0.05000000074505806	CHEMBL134083,FN,ACT,0.75	CHEMBL2028913,TP,ACT,0.9599999785423279	CHEMBL271992,TP,ACT,1.0	CHEMBL36969,TP,ACT,1.0	CHEMBL245264,TP,ACT,0.9599999785423279	CHEMBL439590,TP,ACT,1.0	CHEMBL130215,TP,ACT,0.9900000095367432	CHEMBL130114,TP,ACT,1.0	CHEMBL3804980,TP,ACT,0.9399999976158142	CHEMBL411498,TN,INACT,0.009999999776482582	CHEMBL116746,FP,INACT,1.0	CHEMBL132773,TP,ACT,0.9800000190734863	CHEMBL516749,FP,INACT,0.9900000095367432	CHEMBL3359772,TP,ACT,0.9300000071525574	CHEMBL123200,TP,ACT,0.9900000095367432	CHEMBL1086431,TN,INACT,0.0	CHEMBL1790996,TP,ACT,0.9900000095367432	CHEMBL3805868,TP,ACT,0.9800000190734863	CHEMBL2153162,FP,INACT,1.0	CHEMBL3093947,TP,ACT,1.0	CHEMBL3309803,TN,INACT,0.8999999761581421	CHEMBL515494,TN,INACT,0.8700000047683716	CHEMBL251327,TP,ACT,1.0	CHEMBL3142936,TN,INACT,0.5799999833106995	CHEMBL1288526,TP,ACT,0.9900000095367432	CHEMBL212234,TP,ACT,0.9900000095367432	CHEMBL3649374,TP,ACT,1.0	CHEMBL551805,TP,ACT,1.0	CHEMBL342463,TP,ACT,1.0	CHEMBL334717,TP,ACT,1.0	CHEMBL243314,TP,ACT,0.9300000071525574	CHEMBL168471,FN,ACT,0.8100000023841858	CHEMBL3649388,FP,INACT,0.9900000095367432	CHEMBL207162,TN,INACT,0.0	CHEMBL1836466,TP,ACT,0.9800000190734863	CHEMBL3237999,TN,INACT,0.009999999776482582	CHEMBL3649386,TP,ACT,1.0	CHEMBL215449,FP,INACT,1.0	CHEMBL116358,TN,INACT,0.11999999731779099	CHEMBL138586,TP,ACT,0.9700000286102295	CHEMBL2382065,FP,INACT,0.9700000286102295	CHEMBL141530,TN,INACT,0.0	CHEMBL414669,TP,ACT,0.9900000095367432	CHEMBL3354493,TN,INACT,0.33000001311302185	CHEMBL378731,FP,INACT,1.0	CHEMBL419590,TP,ACT,1.0	CHEMBL241898,FP,INACT,0.9599999785423279	CHEMBL3805560,FN,ACT,0.07000000029802322	CHEMBL252156,FP,INACT,0.949999988079071	CHEMBL209216,TP,ACT,1.0	CHEMBL2172005,FN,ACT,0.7699999809265137	CHEMBL1621187,FP,INACT,1.0	CHEMBL518284,TP,ACT,1.0	CHEMBL231862,TP,ACT,1.0	CHEMBL446669,TN,INACT,0.009999999776482582	CHEMBL1836506,TP,ACT,1.0	CHEMBL130338,TP,ACT,1.0	CHEMBL262103,TP,ACT,1.0	CHEMBL1290303,TP,ACT,0.9900000095367432	CHEMBL200569,FP,INACT,0.949999988079071	CHEMBL234762,TP,ACT,1.0	CHEMBL2316612,FP,INACT,0.9900000095367432	CHEMBL1651355,TP,ACT,1.0	CHEMBL2437297,TN,INACT,0.07000000029802322	CHEMBL380560,FN,ACT,0.3400000035762787	CHEMBL116724,TP,ACT,1.0	CHEMBL284939,FN,ACT,0.7300000190734863	CHEMBL200574,TN,INACT,0.8999999761581421	CHEMBL443319,TP,ACT,0.9800000190734863	CHEMBL381758,TP,ACT,1.0	CHEMBL1289305,TP,ACT,1.0	CHEMBL2070950,TP,ACT,0.9599999785423279	CHEMBL3649387,FP,INACT,1.0	CHEMBL409875,TP,ACT,1.0	CHEMBL133016,FP,INACT,0.9700000286102295	CHEMBL443336,TP,ACT,0.9599999785423279	CHEMBL8726,TP,ACT,0.9700000286102295	CHEMBL92114,TP,ACT,0.9599999785423279	CHEMBL3649412,TP,ACT,0.9900000095367432	CHEMBL313182,TP,ACT,0.9399999976158142	CHEMBL3649380,TP,ACT,1.0	CHEMBL189149,FN,ACT,0.6100000143051147	CHEMBL486232,TP,ACT,1.0	CHEMBL567134,TN,INACT,0.699999988079071	CHEMBL440035,TP,ACT,0.9700000286102295	CHEMBL270792,TP,ACT,0.9700000286102295	CHEMBL1171093,FP,INACT,0.9900000095367432	CHEMBL2382117,FP,INACT,0.9900000095367432	CHEMBL594178,TP,ACT,0.9800000190734863	CHEMBL1790998,TP,ACT,1.0	CHEMBL199470,TP,ACT,1.0	CHEMBL525792,FP,INACT,0.9800000190734863	

