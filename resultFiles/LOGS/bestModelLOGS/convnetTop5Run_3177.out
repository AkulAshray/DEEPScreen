ImageNetInceptionV2 CHEMBL4132 RMSprop 0.0005 15 0 0 0.8 False True
Number of active compounds :	135
Number of inactive compounds :	135
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4132_RMSprop_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4132_RMSprop_0.0005_15_0.8/
---------------------------------
Training samples: 171
Validation samples: 54
--
Training Step: 1  | time: 193.655s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/171
[A[ATraining Step: 2  | total loss: [1m[32m0.71765[0m[0m | time: 367.645s
[2K
| RMSProp | epoch: 001 | loss: 0.71765 - acc: 0.3094 -- iter: 064/171
[A[ATraining Step: 3  | total loss: [1m[32m0.69987[0m[0m | time: 557.367s
[2K
| RMSProp | epoch: 001 | loss: 0.69987 - acc: 0.4909 -- iter: 096/171
[A[ATraining Step: 4  | total loss: [1m[32m0.69402[0m[0m | time: 686.882s
[2K
| RMSProp | epoch: 001 | loss: 0.69402 - acc: 0.5212 -- iter: 128/171
[A[ATraining Step: 5  | total loss: [1m[32m0.77266[0m[0m | time: 803.888s
[2K
| RMSProp | epoch: 001 | loss: 0.77266 - acc: 0.3983 -- iter: 160/171
[A[ATraining Step: 6  | total loss: [1m[32m0.75088[0m[0m | time: 825.322s
[2K
| RMSProp | epoch: 001 | loss: 0.75088 - acc: 0.5240 | val_loss: 0.69916 - val_acc: 0.3704 -- iter: 171/171
--
Training Step: 7  | total loss: [1m[32m0.75845[0m[0m | time: 39.216s
[2K
| RMSProp | epoch: 002 | loss: 0.75845 - acc: 0.4278 -- iter: 032/171
[A[ATraining Step: 8  | total loss: [1m[32m0.71396[0m[0m | time: 123.928s
[2K
| RMSProp | epoch: 002 | loss: 0.71396 - acc: 0.4940 -- iter: 064/171
[A[ATraining Step: 9  | total loss: [1m[32m0.70467[0m[0m | time: 208.176s
[2K
| RMSProp | epoch: 002 | loss: 0.70467 - acc: 0.4972 -- iter: 096/171
[A[ATraining Step: 10  | total loss: [1m[32m0.68800[0m[0m | time: 300.924s
[2K
| RMSProp | epoch: 002 | loss: 0.68800 - acc: 0.5455 -- iter: 128/171
[A[ATraining Step: 11  | total loss: [1m[32m0.70591[0m[0m | time: 419.714s
[2K
| RMSProp | epoch: 002 | loss: 0.70591 - acc: 0.5091 -- iter: 160/171
[A[ATraining Step: 12  | total loss: [1m[32m0.73125[0m[0m | time: 440.224s
[2K
| RMSProp | epoch: 002 | loss: 0.73125 - acc: 0.3925 | val_loss: 0.70704 - val_acc: 0.3704 -- iter: 171/171
--
Training Step: 13  | total loss: [1m[32m0.72885[0m[0m | time: 7.728s
[2K
| RMSProp | epoch: 003 | loss: 0.72885 - acc: 0.4386 -- iter: 032/171
[A[ATraining Step: 14  | total loss: [1m[32m0.70091[0m[0m | time: 15.938s
[2K
| RMSProp | epoch: 003 | loss: 0.70091 - acc: 0.4823 -- iter: 064/171
[A[ATraining Step: 15  | total loss: [1m[32m0.69996[0m[0m | time: 102.701s
[2K
| RMSProp | epoch: 003 | loss: 0.69996 - acc: 0.4359 -- iter: 096/171
[A[ATraining Step: 16  | total loss: [1m[32m0.69634[0m[0m | time: 214.340s
[2K
| RMSProp | epoch: 003 | loss: 0.69634 - acc: 0.4716 -- iter: 128/171
[A[ATraining Step: 17  | total loss: [1m[32m0.69320[0m[0m | time: 255.133s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.5043 -- iter: 160/171
[A[ATraining Step: 18  | total loss: [1m[32m0.70096[0m[0m | time: 333.366s
[2K
| RMSProp | epoch: 003 | loss: 0.70096 - acc: 0.4812 | val_loss: 0.71010 - val_acc: 0.3704 -- iter: 171/171
--
Training Step: 19  | total loss: [1m[32m0.69716[0m[0m | time: 46.086s
[2K
| RMSProp | epoch: 004 | loss: 0.69716 - acc: 0.4979 -- iter: 032/171
[A[ATraining Step: 20  | total loss: [1m[32m0.70237[0m[0m | time: 54.190s
[2K
| RMSProp | epoch: 004 | loss: 0.70237 - acc: 0.4885 -- iter: 064/171
[A[ATraining Step: 21  | total loss: [1m[32m0.66764[0m[0m | time: 61.820s
[2K
| RMSProp | epoch: 004 | loss: 0.66764 - acc: 0.5908 -- iter: 096/171
[A[ATraining Step: 22  | total loss: [1m[32m0.65788[0m[0m | time: 82.814s
[2K
| RMSProp | epoch: 004 | loss: 0.65788 - acc: 0.6590 -- iter: 128/171
[A[ATraining Step: 23  | total loss: [1m[32m0.65882[0m[0m | time: 183.949s
[2K
| RMSProp | epoch: 004 | loss: 0.65882 - acc: 0.6492 -- iter: 160/171
[A[ATraining Step: 24  | total loss: [1m[32m0.67606[0m[0m | time: 237.163s
[2K
| RMSProp | epoch: 004 | loss: 0.67606 - acc: 0.5720 | val_loss: 0.72957 - val_acc: 0.3704 -- iter: 171/171
--
Training Step: 25  | total loss: [1m[32m0.68338[0m[0m | time: 75.345s
[2K
| RMSProp | epoch: 005 | loss: 0.68338 - acc: 0.5524 -- iter: 032/171
[A[ATraining Step: 26  | total loss: [1m[32m0.68259[0m[0m | time: 108.524s
[2K
| RMSProp | epoch: 005 | loss: 0.68259 - acc: 0.5551 -- iter: 064/171
[A[ATraining Step: 27  | total loss: [1m[32m0.66809[0m[0m | time: 116.760s
[2K
| RMSProp | epoch: 005 | loss: 0.66809 - acc: 0.6293 -- iter: 096/171
[A[ATraining Step: 28  | total loss: [1m[32m0.68625[0m[0m | time: 124.511s
[2K
| RMSProp | epoch: 005 | loss: 0.68625 - acc: 0.5629 -- iter: 128/171
[A[ATraining Step: 29  | total loss: [1m[32m0.67853[0m[0m | time: 142.375s
[2K
| RMSProp | epoch: 005 | loss: 0.67853 - acc: 0.6029 -- iter: 160/171
[A[ATraining Step: 30  | total loss: [1m[32m0.67511[0m[0m | time: 177.391s
[2K
| RMSProp | epoch: 005 | loss: 0.67511 - acc: 0.5933 | val_loss: 0.75137 - val_acc: 0.3704 -- iter: 171/171
--
Training Step: 31  | total loss: [1m[32m0.67467[0m[0m | time: 12.443s
[2K
| RMSProp | epoch: 006 | loss: 0.67467 - acc: 0.5934 -- iter: 032/171
[A[ATraining Step: 32  | total loss: [1m[32m0.66990[0m[0m | time: 43.815s
[2K
| RMSProp | epoch: 006 | loss: 0.66990 - acc: 0.6216 -- iter: 064/171
[A[ATraining Step: 33  | total loss: [1m[32m0.65066[0m[0m | time: 72.533s
[2K
| RMSProp | epoch: 006 | loss: 0.65066 - acc: 0.6772 -- iter: 096/171
[A[ATraining Step: 34  | total loss: [1m[32m0.66287[0m[0m | time: 80.581s
[2K
| RMSProp | epoch: 006 | loss: 0.66287 - acc: 0.6192 -- iter: 128/171
[A[ATraining Step: 35  | total loss: [1m[32m0.66675[0m[0m | time: 88.418s
[2K
| RMSProp | epoch: 006 | loss: 0.66675 - acc: 0.6418 -- iter: 160/171
[A[ATraining Step: 36  | total loss: [1m[32m0.65869[0m[0m | time: 127.992s
[2K
| RMSProp | epoch: 006 | loss: 0.65869 - acc: 0.6965 | val_loss: 0.82177 - val_acc: 0.3704 -- iter: 171/171
--
Training Step: 37  | total loss: [1m[32m0.65555[0m[0m | time: 29.252s
[2K
| RMSProp | epoch: 007 | loss: 0.65555 - acc: 0.6822 -- iter: 032/171
[A[ATraining Step: 38  | total loss: [1m[32m0.65175[0m[0m | time: 42.017s
[2K
| RMSProp | epoch: 007 | loss: 0.65175 - acc: 0.6771 -- iter: 064/171
[A[ATraining Step: 39  | total loss: [1m[32m0.65786[0m[0m | time: 111.324s
[2K
| RMSProp | epoch: 007 | loss: 0.65786 - acc: 0.6312 -- iter: 096/171
[A[ATraining Step: 40  | total loss: [1m[32m0.65022[0m[0m | time: 148.388s
[2K
| RMSProp | epoch: 007 | loss: 0.65022 - acc: 0.6711 -- iter: 128/171
[A[ATraining Step: 41  | total loss: [1m[32m0.64780[0m[0m | time: 156.337s
[2K
| RMSProp | epoch: 007 | loss: 0.64780 - acc: 0.6683 -- iter: 160/171
[A[ATraining Step: 42  | total loss: [1m[32m0.65779[0m[0m | time: 169.981s
[2K
| RMSProp | epoch: 007 | loss: 0.65779 - acc: 0.6462 | val_loss: 0.84170 - val_acc: 0.3704 -- iter: 171/171
--
Training Step: 43  | total loss: [1m[32m0.63302[0m[0m | time: 43.711s
[2K
| RMSProp | epoch: 008 | loss: 0.63302 - acc: 0.6926 -- iter: 032/171
[A[ATraining Step: 44  | total loss: [1m[32m0.63780[0m[0m | time: 60.007s
[2K
| RMSProp | epoch: 008 | loss: 0.63780 - acc: 0.6701 -- iter: 064/171
[A[ATraining Step: 45  | total loss: [1m[32m0.63696[0m[0m | time: 73.675s
[2K
| RMSProp | epoch: 008 | loss: 0.63696 - acc: 0.6784 -- iter: 096/171
[A[ATraining Step: 46  | total loss: [1m[32m0.63135[0m[0m | time: 103.770s
[2K
| RMSProp | epoch: 008 | loss: 0.63135 - acc: 0.6955 -- iter: 128/171
[A[ATraining Step: 47  | total loss: [1m[32m0.62764[0m[0m | time: 123.656s
[2K
| RMSProp | epoch: 008 | loss: 0.62764 - acc: 0.6942 -- iter: 160/171
[A[ATraining Step: 48  | total loss: [1m[32m0.62841[0m[0m | time: 138.206s
[2K
| RMSProp | epoch: 008 | loss: 0.62841 - acc: 0.6881 | val_loss: 0.69016 - val_acc: 0.5556 -- iter: 171/171
--
Training Step: 49  | total loss: [1m[32m0.62411[0m[0m | time: 8.576s
[2K
| RMSProp | epoch: 009 | loss: 0.62411 - acc: 0.6943 -- iter: 032/171
[A[ATraining Step: 50  | total loss: [1m[32m0.60884[0m[0m | time: 28.169s
[2K
| RMSProp | epoch: 009 | loss: 0.60884 - acc: 0.7417 -- iter: 064/171
[A[ATraining Step: 51  | total loss: [1m[32m0.61611[0m[0m | time: 47.174s
[2K
| RMSProp | epoch: 009 | loss: 0.61611 - acc: 0.6953 -- iter: 096/171
[A[ATraining Step: 52  | total loss: [1m[32m0.61436[0m[0m | time: 60.493s
[2K
| RMSProp | epoch: 009 | loss: 0.61436 - acc: 0.6754 -- iter: 128/171
[A[ATraining Step: 53  | total loss: [1m[32m0.61289[0m[0m | time: 74.227s
[2K
| RMSProp | epoch: 009 | loss: 0.61289 - acc: 0.6910 -- iter: 160/171
[A[ATraining Step: 54  | total loss: [1m[32m0.59570[0m[0m | time: 104.303s
[2K
| RMSProp | epoch: 009 | loss: 0.59570 - acc: 0.7177 | val_loss: 0.65264 - val_acc: 0.6667 -- iter: 171/171
--
Training Step: 55  | total loss: [1m[32m0.59943[0m[0m | time: 6.784s
[2K
| RMSProp | epoch: 010 | loss: 0.59943 - acc: 0.7089 -- iter: 032/171
[A[ATraining Step: 56  | total loss: [1m[32m0.60550[0m[0m | time: 13.484s
[2K
| RMSProp | epoch: 010 | loss: 0.60550 - acc: 0.7243 -- iter: 064/171
[A[ATraining Step: 57  | total loss: [1m[32m0.59566[0m[0m | time: 30.439s
[2K
| RMSProp | epoch: 010 | loss: 0.59566 - acc: 0.7499 -- iter: 096/171
[A[ATraining Step: 58  | total loss: [1m[32m0.59880[0m[0m | time: 47.642s
[2K
| RMSProp | epoch: 010 | loss: 0.59880 - acc: 0.7414 -- iter: 128/171
[A[ATraining Step: 59  | total loss: [1m[32m0.59282[0m[0m | time: 66.824s
[2K
| RMSProp | epoch: 010 | loss: 0.59282 - acc: 0.7383 -- iter: 160/171
[A[ATraining Step: 60  | total loss: [1m[32m0.58708[0m[0m | time: 109.443s
[2K
| RMSProp | epoch: 010 | loss: 0.58708 - acc: 0.7357 | val_loss: 0.67189 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 61  | total loss: [1m[32m0.57474[0m[0m | time: 17.107s
[2K
| RMSProp | epoch: 011 | loss: 0.57474 - acc: 0.7539 -- iter: 032/171
[A[ATraining Step: 62  | total loss: [1m[32m0.58401[0m[0m | time: 24.175s
[2K
| RMSProp | epoch: 011 | loss: 0.58401 - acc: 0.7253 -- iter: 064/171
[A[ATraining Step: 63  | total loss: [1m[32m0.57419[0m[0m | time: 29.286s
[2K
| RMSProp | epoch: 011 | loss: 0.57419 - acc: 0.7371 -- iter: 096/171
[A[ATraining Step: 64  | total loss: [1m[32m0.55438[0m[0m | time: 42.583s
[2K
| RMSProp | epoch: 011 | loss: 0.55438 - acc: 0.7699 -- iter: 128/171
[A[ATraining Step: 65  | total loss: [1m[32m0.55626[0m[0m | time: 88.561s
[2K
| RMSProp | epoch: 011 | loss: 0.55626 - acc: 0.7713 -- iter: 160/171
[A[ATraining Step: 66  | total loss: [1m[32m0.55000[0m[0m | time: 119.981s
[2K
| RMSProp | epoch: 011 | loss: 0.55000 - acc: 0.7839 | val_loss: 0.61284 - val_acc: 0.7037 -- iter: 171/171
--
Training Step: 67  | total loss: [1m[32m0.54519[0m[0m | time: 15.648s
[2K
| RMSProp | epoch: 012 | loss: 0.54519 - acc: 0.7761 -- iter: 032/171
[A[ATraining Step: 68  | total loss: [1m[32m0.53631[0m[0m | time: 60.399s
[2K
| RMSProp | epoch: 012 | loss: 0.53631 - acc: 0.7841 -- iter: 064/171
[A[ATraining Step: 69  | total loss: [1m[32m0.53759[0m[0m | time: 67.791s
[2K
| RMSProp | epoch: 012 | loss: 0.53759 - acc: 0.7838 -- iter: 096/171
[A[ATraining Step: 70  | total loss: [1m[32m0.52561[0m[0m | time: 75.290s
[2K
| RMSProp | epoch: 012 | loss: 0.52561 - acc: 0.7982 -- iter: 128/171
[A[ATraining Step: 71  | total loss: [1m[32m0.50261[0m[0m | time: 95.340s
[2K
| RMSProp | epoch: 012 | loss: 0.50261 - acc: 0.8212 -- iter: 160/171
[A[ATraining Step: 72  | total loss: [1m[32m0.51032[0m[0m | time: 117.963s
[2K
| RMSProp | epoch: 012 | loss: 0.51032 - acc: 0.8027 | val_loss: 0.87467 - val_acc: 0.6296 -- iter: 171/171
--
Training Step: 73  | total loss: [1m[32m0.50600[0m[0m | time: 16.391s
[2K
| RMSProp | epoch: 013 | loss: 0.50600 - acc: 0.8107 -- iter: 032/171
[A[ATraining Step: 74  | total loss: [1m[32m0.52524[0m[0m | time: 32.776s
[2K
| RMSProp | epoch: 013 | loss: 0.52524 - acc: 0.7903 -- iter: 064/171
[A[ATraining Step: 75  | total loss: [1m[32m0.51320[0m[0m | time: 48.262s
[2K
| RMSProp | epoch: 013 | loss: 0.51320 - acc: 0.8029 -- iter: 096/171
[A[ATraining Step: 76  | total loss: [1m[32m0.51323[0m[0m | time: 54.651s
[2K
| RMSProp | epoch: 013 | loss: 0.51323 - acc: 0.7939 -- iter: 128/171
[A[ATraining Step: 77  | total loss: [1m[32m0.52238[0m[0m | time: 61.298s
[2K
| RMSProp | epoch: 013 | loss: 0.52238 - acc: 0.7868 -- iter: 160/171
[A[ATraining Step: 78  | total loss: [1m[32m0.50851[0m[0m | time: 81.950s
[2K
| RMSProp | epoch: 013 | loss: 0.50851 - acc: 0.8091 | val_loss: 0.57879 - val_acc: 0.7407 -- iter: 171/171
--
Training Step: 79  | total loss: [1m[32m0.50698[0m[0m | time: 15.280s
[2K
| RMSProp | epoch: 014 | loss: 0.50698 - acc: 0.8062 -- iter: 032/171
[A[ATraining Step: 80  | total loss: [1m[32m0.51299[0m[0m | time: 32.311s
[2K
| RMSProp | epoch: 014 | loss: 0.51299 - acc: 0.7973 -- iter: 064/171
[A[ATraining Step: 81  | total loss: [1m[32m0.49945[0m[0m | time: 46.772s
[2K
| RMSProp | epoch: 014 | loss: 0.49945 - acc: 0.8020 -- iter: 096/171
[A[ATraining Step: 82  | total loss: [1m[32m0.49256[0m[0m | time: 62.046s
[2K
| RMSProp | epoch: 014 | loss: 0.49256 - acc: 0.8030 -- iter: 128/171
[A[ATraining Step: 83  | total loss: [1m[32m0.48749[0m[0m | time: 68.453s
[2K
| RMSProp | epoch: 014 | loss: 0.48749 - acc: 0.8071 -- iter: 160/171
[A[ATraining Step: 84  | total loss: [1m[32m0.47649[0m[0m | time: 80.746s
[2K
| RMSProp | epoch: 014 | loss: 0.47649 - acc: 0.8082 | val_loss: 1.80240 - val_acc: 0.6296 -- iter: 171/171
--
Training Step: 85  | total loss: [1m[32m0.45001[0m[0m | time: 15.533s
[2K
| RMSProp | epoch: 015 | loss: 0.45001 - acc: 0.8274 -- iter: 032/171
[A[ATraining Step: 86  | total loss: [1m[32m0.44533[0m[0m | time: 31.768s
[2K
| RMSProp | epoch: 015 | loss: 0.44533 - acc: 0.8322 -- iter: 064/171
[A[ATraining Step: 87  | total loss: [1m[32m0.43654[0m[0m | time: 46.856s
[2K
| RMSProp | epoch: 015 | loss: 0.43654 - acc: 0.8333 -- iter: 096/171
[A[ATraining Step: 88  | total loss: [1m[32m0.41983[0m[0m | time: 62.694s
[2K
| RMSProp | epoch: 015 | loss: 0.41983 - acc: 0.8375 -- iter: 128/171
[A[ATraining Step: 89  | total loss: [1m[32m0.40790[0m[0m | time: 77.901s
[2K
| RMSProp | epoch: 015 | loss: 0.40790 - acc: 0.8537 -- iter: 160/171
[A[ATraining Step: 90  | total loss: [1m[32m0.41055[0m[0m | time: 89.835s
[2K
| RMSProp | epoch: 015 | loss: 0.41055 - acc: 0.8402 | val_loss: 0.70309 - val_acc: 0.7037 -- iter: 171/171
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7985294117647059
Validation AUPRC:0.8695078660234866
Test AUC:0.8500000000000001
Test AUPRC:0.7843170994406159
BestTestF1Score	0.73	0.47	0.69	0.59	0.96	23	16	14	1	0.73
BestTestMCCScore	0.77	0.63	0.81	0.85	0.71	17	3	27	7	0.93
BestTestAccuracyScore	0.77	0.63	0.81	0.85	0.71	17	3	27	7	0.93
BestValidationF1Score	0.83	0.47	0.76	0.74	0.94	32	11	9	2	0.73
BestValidationMCC	0.79	0.52	0.76	0.86	0.74	25	4	16	9	0.93
BestValidationAccuracy	0.79	0.52	0.76	0.86	0.74	25	4	16	9	0.93
TestPredictions (Threshold:0.93)
CHEMBL1335846,TN,INACT,0.9100000262260437	CHEMBL2381035,TP,ACT,0.9399999976158142	CHEMBL1464645,TN,INACT,0.8600000143051147	CHEMBL3236343,TN,INACT,0.6899999976158142	CHEMBL433514,TP,ACT,0.9599999785423279	CHEMBL1451569,TN,INACT,0.9200000166893005	CHEMBL1704776,TN,INACT,0.3400000035762787	CHEMBL294326,TN,INACT,0.6299999952316284	CHEMBL24086,TP,ACT,0.9900000095367432	CHEMBL2381028,FN,ACT,0.9100000262260437	CHEMBL522211,TN,INACT,0.5199999809265137	CHEMBL282854,TP,ACT,0.9700000286102295	CHEMBL1542752,FP,INACT,0.9700000286102295	CHEMBL2380923,FN,ACT,0.8500000238418579	CHEMBL1532234,TN,INACT,0.15000000596046448	CHEMBL2147316,TN,INACT,0.4099999964237213	CHEMBL488817,TN,INACT,0.6100000143051147	CHEMBL151447,TP,ACT,0.9700000286102295	CHEMBL3325534,TN,INACT,0.7900000214576721	CHEMBL2381006,FN,ACT,0.8399999737739563	CHEMBL18988,TP,ACT,0.949999988079071	CHEMBL495793,TN,INACT,0.2800000011920929	CHEMBL3634328,TN,INACT,0.7599999904632568	CHEMBL3589904,TN,INACT,0.6499999761581421	CHEMBL2381017,TN,INACT,0.8700000047683716	CHEMBL167975,FP,INACT,0.9800000190734863	CHEMBL2381020,TP,ACT,0.9900000095367432	CHEMBL150319,FN,ACT,0.9200000166893005	CHEMBL2398425,TP,ACT,0.9399999976158142	CHEMBL2380922,FN,ACT,0.800000011920929	CHEMBL3085876,TN,INACT,0.8999999761581421	CHEMBL1432215,TN,INACT,0.800000011920929	CHEMBL24243,TP,ACT,0.9599999785423279	CHEMBL3085875,TN,INACT,0.6000000238418579	CHEMBL3682816,TN,INACT,0.8999999761581421	CHEMBL2398402,FN,ACT,0.8999999761581421	CHEMBL1346897,TN,INACT,0.8700000047683716	CHEMBL2380903,TN,INACT,0.7099999785423279	CHEMBL1532635,TN,INACT,0.8600000143051147	CHEMBL1523678,FP,INACT,0.9900000095367432	CHEMBL26605,TP,ACT,0.9900000095367432	CHEMBL2164367,TN,INACT,0.8799999952316284	CHEMBL284195,TP,ACT,0.9800000190734863	CHEMBL2398397,TP,ACT,0.9900000095367432	CHEMBL275195,TP,ACT,0.9399999976158142	CHEMBL3799379,TN,INACT,0.3400000035762787	CHEMBL24085,FN,ACT,0.6800000071525574	CHEMBL2398396,TP,ACT,0.9900000095367432	CHEMBL2381030,TP,ACT,0.9599999785423279	CHEMBL277293,TP,ACT,0.9800000190734863	CHEMBL64202,TN,INACT,0.8700000047683716	CHEMBL61933,TN,INACT,0.38999998569488525	CHEMBL150921,TP,ACT,0.9399999976158142	CHEMBL1770752,TN,INACT,0.550000011920929	

