ImageNetInceptionV2 CHEMBL2072 adam 0.0001 30 0 0 0.8 False True
Number of active compounds :	173
Number of inactive compounds :	173
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2072_adam_0.0001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2072_adam_0.0001_30_0.8/
---------------------------------
Training samples: 220
Validation samples: 69
--
Training Step: 1  | time: 41.749s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/220
[A[ATraining Step: 2  | total loss: [1m[32m0.69428[0m[0m | time: 50.640s
[2K
| Adam | epoch: 001 | loss: 0.69428 - acc: 0.3656 -- iter: 064/220
[A[ATraining Step: 3  | total loss: [1m[32m0.42820[0m[0m | time: 59.628s
[2K
| Adam | epoch: 001 | loss: 0.42820 - acc: 0.7568 -- iter: 096/220
[A[ATraining Step: 4  | total loss: [1m[32m0.47304[0m[0m | time: 69.217s
[2K
| Adam | epoch: 001 | loss: 0.47304 - acc: 0.8220 -- iter: 128/220
[A[ATraining Step: 5  | total loss: [1m[32m0.45786[0m[0m | time: 78.670s
[2K
| Adam | epoch: 001 | loss: 0.45786 - acc: 0.7938 -- iter: 160/220
[A[ATraining Step: 6  | total loss: [1m[32m0.49397[0m[0m | time: 88.223s
[2K
| Adam | epoch: 001 | loss: 0.49397 - acc: 0.8058 -- iter: 192/220
[A[ATraining Step: 7  | total loss: [1m[32m0.40111[0m[0m | time: 106.516s
[2K
| Adam | epoch: 001 | loss: 0.40111 - acc: 0.8661 | val_loss: 2.04023 - val_acc: 0.3913 -- iter: 220/220
--
Training Step: 8  | total loss: [1m[32m0.38307[0m[0m | time: 8.375s
[2K
| Adam | epoch: 002 | loss: 0.38307 - acc: 0.8611 -- iter: 032/220
[A[ATraining Step: 9  | total loss: [1m[32m0.29289[0m[0m | time: 17.890s
[2K
| Adam | epoch: 002 | loss: 0.29289 - acc: 0.8779 -- iter: 064/220
[A[ATraining Step: 10  | total loss: [1m[32m0.29731[0m[0m | time: 27.435s
[2K
| Adam | epoch: 002 | loss: 0.29731 - acc: 0.8608 -- iter: 096/220
[A[ATraining Step: 11  | total loss: [1m[32m0.24436[0m[0m | time: 36.716s
[2K
| Adam | epoch: 002 | loss: 0.24436 - acc: 0.9119 -- iter: 128/220
[A[ATraining Step: 12  | total loss: [1m[32m0.23630[0m[0m | time: 46.002s
[2K
| Adam | epoch: 002 | loss: 0.23630 - acc: 0.9234 -- iter: 160/220
[A[ATraining Step: 13  | total loss: [1m[32m0.23684[0m[0m | time: 55.515s
[2K
| Adam | epoch: 002 | loss: 0.23684 - acc: 0.9161 -- iter: 192/220
[A[ATraining Step: 14  | total loss: [1m[32m0.21195[0m[0m | time: 68.993s
[2K
| Adam | epoch: 002 | loss: 0.21195 - acc: 0.9376 | val_loss: 1.46340 - val_acc: 0.3913 -- iter: 220/220
--
Training Step: 15  | total loss: [1m[32m0.21192[0m[0m | time: 13.220s
[2K
| Adam | epoch: 003 | loss: 0.21192 - acc: 0.9376 -- iter: 032/220
[A[ATraining Step: 16  | total loss: [1m[32m0.18628[0m[0m | time: 26.382s
[2K
| Adam | epoch: 003 | loss: 0.18628 - acc: 0.9476 -- iter: 064/220
[A[ATraining Step: 17  | total loss: [1m[32m0.13600[0m[0m | time: 38.899s
[2K
| Adam | epoch: 003 | loss: 0.13600 - acc: 0.9665 -- iter: 096/220
[A[ATraining Step: 18  | total loss: [1m[32m0.14431[0m[0m | time: 51.575s
[2K
| Adam | epoch: 003 | loss: 0.14431 - acc: 0.9456 -- iter: 128/220
[A[ATraining Step: 19  | total loss: [1m[32m0.13371[0m[0m | time: 64.186s
[2K
| Adam | epoch: 003 | loss: 0.13371 - acc: 0.9533 -- iter: 160/220
[A[ATraining Step: 20  | total loss: [1m[32m0.10448[0m[0m | time: 76.861s
[2K
| Adam | epoch: 003 | loss: 0.10448 - acc: 0.9683 -- iter: 192/220
[A[ATraining Step: 21  | total loss: [1m[32m0.09220[0m[0m | time: 95.228s
[2K
| Adam | epoch: 003 | loss: 0.09220 - acc: 0.9782 | val_loss: 1.56572 - val_acc: 0.3913 -- iter: 220/220
--
Training Step: 22  | total loss: [1m[32m0.08815[0m[0m | time: 9.180s
[2K
| Adam | epoch: 004 | loss: 0.08815 - acc: 0.9753 -- iter: 032/220
[A[ATraining Step: 23  | total loss: [1m[32m0.10961[0m[0m | time: 16.649s
[2K
| Adam | epoch: 004 | loss: 0.10961 - acc: 0.9462 -- iter: 064/220
[A[ATraining Step: 24  | total loss: [1m[32m0.13094[0m[0m | time: 23.825s
[2K
| Adam | epoch: 004 | loss: 0.13094 - acc: 0.9513 -- iter: 096/220
[A[ATraining Step: 25  | total loss: [1m[32m0.10144[0m[0m | time: 31.806s
[2K
| Adam | epoch: 004 | loss: 0.10144 - acc: 0.9646 -- iter: 128/220
[A[ATraining Step: 26  | total loss: [1m[32m0.08152[0m[0m | time: 39.545s
[2K
| Adam | epoch: 004 | loss: 0.08152 - acc: 0.9740 -- iter: 160/220
[A[ATraining Step: 27  | total loss: [1m[32m0.06561[0m[0m | time: 51.348s
[2K
| Adam | epoch: 004 | loss: 0.06561 - acc: 0.9807 -- iter: 192/220
[A[ATraining Step: 28  | total loss: [1m[32m0.06393[0m[0m | time: 69.072s
[2K
| Adam | epoch: 004 | loss: 0.06393 - acc: 0.9855 | val_loss: 2.10929 - val_acc: 0.3913 -- iter: 220/220
--
Training Step: 29  | total loss: [1m[32m0.08547[0m[0m | time: 12.630s
[2K
| Adam | epoch: 005 | loss: 0.08547 - acc: 0.9814 -- iter: 032/220
[A[ATraining Step: 30  | total loss: [1m[32m0.06954[0m[0m | time: 25.407s
[2K
| Adam | epoch: 005 | loss: 0.06954 - acc: 0.9858 -- iter: 064/220
[A[ATraining Step: 31  | total loss: [1m[32m0.06868[0m[0m | time: 36.830s
[2K
| Adam | epoch: 005 | loss: 0.06868 - acc: 0.9891 -- iter: 096/220
[A[ATraining Step: 32  | total loss: [1m[32m0.09948[0m[0m | time: 48.140s
[2K
| Adam | epoch: 005 | loss: 0.09948 - acc: 0.9835 -- iter: 128/220
[A[ATraining Step: 33  | total loss: [1m[32m0.08212[0m[0m | time: 61.186s
[2K
| Adam | epoch: 005 | loss: 0.08212 - acc: 0.9871 -- iter: 160/220
[A[ATraining Step: 34  | total loss: [1m[32m0.06942[0m[0m | time: 69.231s
[2K
| Adam | epoch: 005 | loss: 0.06942 - acc: 0.9899 -- iter: 192/220
[A[ATraining Step: 35  | total loss: [1m[32m0.05841[0m[0m | time: 80.388s
[2K
| Adam | epoch: 005 | loss: 0.05841 - acc: 0.9920 | val_loss: 0.96295 - val_acc: 0.3913 -- iter: 220/220
--
Training Step: 36  | total loss: [1m[32m0.04758[0m[0m | time: 12.690s
[2K
| Adam | epoch: 006 | loss: 0.04758 - acc: 0.9936 -- iter: 032/220
[A[ATraining Step: 37  | total loss: [1m[32m0.03960[0m[0m | time: 25.249s
[2K
| Adam | epoch: 006 | loss: 0.03960 - acc: 0.9949 -- iter: 064/220
[A[ATraining Step: 38  | total loss: [1m[32m0.03680[0m[0m | time: 37.813s
[2K
| Adam | epoch: 006 | loss: 0.03680 - acc: 0.9959 -- iter: 096/220
[A[ATraining Step: 39  | total loss: [1m[32m0.03825[0m[0m | time: 49.283s
[2K
| Adam | epoch: 006 | loss: 0.03825 - acc: 0.9907 -- iter: 128/220
[A[ATraining Step: 40  | total loss: [1m[32m0.08432[0m[0m | time: 60.986s
[2K
| Adam | epoch: 006 | loss: 0.08432 - acc: 0.9791 -- iter: 160/220
[A[ATraining Step: 41  | total loss: [1m[32m0.06923[0m[0m | time: 73.570s
[2K
| Adam | epoch: 006 | loss: 0.06923 - acc: 0.9829 -- iter: 192/220
[A[ATraining Step: 42  | total loss: [1m[32m0.06206[0m[0m | time: 91.766s
[2K
| Adam | epoch: 006 | loss: 0.06206 - acc: 0.9860 | val_loss: 0.42511 - val_acc: 0.9130 -- iter: 220/220
--
Training Step: 43  | total loss: [1m[32m0.05217[0m[0m | time: 12.544s
[2K
| Adam | epoch: 007 | loss: 0.05217 - acc: 0.9885 -- iter: 032/220
[A[ATraining Step: 44  | total loss: [1m[32m0.04364[0m[0m | time: 24.858s
[2K
| Adam | epoch: 007 | loss: 0.04364 - acc: 0.9905 -- iter: 064/220
[A[ATraining Step: 45  | total loss: [1m[32m0.04069[0m[0m | time: 37.200s
[2K
| Adam | epoch: 007 | loss: 0.04069 - acc: 0.9921 -- iter: 096/220
[A[ATraining Step: 46  | total loss: [1m[32m0.03433[0m[0m | time: 49.697s
[2K
| Adam | epoch: 007 | loss: 0.03433 - acc: 0.9934 -- iter: 128/220
[A[ATraining Step: 47  | total loss: [1m[32m0.04713[0m[0m | time: 61.211s
[2K
| Adam | epoch: 007 | loss: 0.04713 - acc: 0.9894 -- iter: 160/220
[A[ATraining Step: 48  | total loss: [1m[32m0.07020[0m[0m | time: 72.890s
[2K
| Adam | epoch: 007 | loss: 0.07020 - acc: 0.9853 -- iter: 192/220
[A[ATraining Step: 49  | total loss: [1m[32m0.05958[0m[0m | time: 90.738s
[2K
| Adam | epoch: 007 | loss: 0.05958 - acc: 0.9876 | val_loss: 0.35697 - val_acc: 0.9130 -- iter: 220/220
--
Training Step: 50  | total loss: [1m[32m0.05402[0m[0m | time: 7.892s
[2K
| Adam | epoch: 008 | loss: 0.05402 - acc: 0.9896 -- iter: 032/220
[A[ATraining Step: 51  | total loss: [1m[32m0.04722[0m[0m | time: 15.937s
[2K
| Adam | epoch: 008 | loss: 0.04722 - acc: 0.9912 -- iter: 064/220
[A[ATraining Step: 52  | total loss: [1m[32m0.04064[0m[0m | time: 24.217s
[2K
| Adam | epoch: 008 | loss: 0.04064 - acc: 0.9925 -- iter: 096/220
[A[ATraining Step: 53  | total loss: [1m[32m0.04041[0m[0m | time: 36.771s
[2K
| Adam | epoch: 008 | loss: 0.04041 - acc: 0.9890 -- iter: 128/220
[A[ATraining Step: 54  | total loss: [1m[32m0.03543[0m[0m | time: 49.627s
[2K
| Adam | epoch: 008 | loss: 0.03543 - acc: 0.9906 -- iter: 160/220
[A[ATraining Step: 55  | total loss: [1m[32m0.03076[0m[0m | time: 60.462s
[2K
| Adam | epoch: 008 | loss: 0.03076 - acc: 0.9919 -- iter: 192/220
[A[ATraining Step: 56  | total loss: [1m[32m0.09689[0m[0m | time: 76.786s
[2K
| Adam | epoch: 008 | loss: 0.09689 - acc: 0.9830 | val_loss: 0.49250 - val_acc: 0.8406 -- iter: 220/220
--
Training Step: 57  | total loss: [1m[32m0.08467[0m[0m | time: 12.825s
[2K
| Adam | epoch: 009 | loss: 0.08467 - acc: 0.9854 -- iter: 032/220
[A[ATraining Step: 58  | total loss: [1m[32m0.09062[0m[0m | time: 25.095s
[2K
| Adam | epoch: 009 | loss: 0.09062 - acc: 0.9831 -- iter: 064/220
[A[ATraining Step: 59  | total loss: [1m[32m0.07972[0m[0m | time: 36.730s
[2K
| Adam | epoch: 009 | loss: 0.07972 - acc: 0.9854 -- iter: 096/220
[A[ATraining Step: 60  | total loss: [1m[32m0.07045[0m[0m | time: 44.640s
[2K
| Adam | epoch: 009 | loss: 0.07045 - acc: 0.9873 -- iter: 128/220
[A[ATraining Step: 61  | total loss: [1m[32m0.06538[0m[0m | time: 52.391s
[2K
| Adam | epoch: 009 | loss: 0.06538 - acc: 0.9890 -- iter: 160/220
[A[ATraining Step: 62  | total loss: [1m[32m0.05888[0m[0m | time: 60.228s
[2K
| Adam | epoch: 009 | loss: 0.05888 - acc: 0.9904 -- iter: 192/220
[A[ATraining Step: 63  | total loss: [1m[32m0.05224[0m[0m | time: 70.564s
[2K
| Adam | epoch: 009 | loss: 0.05224 - acc: 0.9916 | val_loss: 0.40679 - val_acc: 0.8696 -- iter: 220/220
--
Training Step: 64  | total loss: [1m[32m0.06513[0m[0m | time: 11.274s
[2K
| Adam | epoch: 010 | loss: 0.06513 - acc: 0.9882 -- iter: 032/220
[A[ATraining Step: 65  | total loss: [1m[32m0.05892[0m[0m | time: 23.455s
[2K
| Adam | epoch: 010 | loss: 0.05892 - acc: 0.9896 -- iter: 064/220
[A[ATraining Step: 66  | total loss: [1m[32m0.05269[0m[0m | time: 36.231s
[2K
| Adam | epoch: 010 | loss: 0.05269 - acc: 0.9909 -- iter: 096/220
[A[ATraining Step: 67  | total loss: [1m[32m0.04692[0m[0m | time: 48.809s
[2K
| Adam | epoch: 010 | loss: 0.04692 - acc: 0.9920 -- iter: 128/220
[A[ATraining Step: 68  | total loss: [1m[32m0.04221[0m[0m | time: 61.302s
[2K
| Adam | epoch: 010 | loss: 0.04221 - acc: 0.9929 -- iter: 160/220
[A[ATraining Step: 69  | total loss: [1m[32m0.03852[0m[0m | time: 74.044s
[2K
| Adam | epoch: 010 | loss: 0.03852 - acc: 0.9938 -- iter: 192/220
[A[ATraining Step: 70  | total loss: [1m[32m0.03607[0m[0m | time: 90.545s
[2K
| Adam | epoch: 010 | loss: 0.03607 - acc: 0.9945 | val_loss: 0.30997 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 71  | total loss: [1m[32m0.03246[0m[0m | time: 11.289s
[2K
| Adam | epoch: 011 | loss: 0.03246 - acc: 0.9951 -- iter: 032/220
[A[ATraining Step: 72  | total loss: [1m[32m0.04501[0m[0m | time: 22.549s
[2K
| Adam | epoch: 011 | loss: 0.04501 - acc: 0.9876 -- iter: 064/220
[A[ATraining Step: 73  | total loss: [1m[32m0.04345[0m[0m | time: 35.097s
[2K
| Adam | epoch: 011 | loss: 0.04345 - acc: 0.9850 -- iter: 096/220
[A[ATraining Step: 74  | total loss: [1m[32m0.03916[0m[0m | time: 47.540s
[2K
| Adam | epoch: 011 | loss: 0.03916 - acc: 0.9867 -- iter: 128/220
[A[ATraining Step: 75  | total loss: [1m[32m0.03586[0m[0m | time: 59.648s
[2K
| Adam | epoch: 011 | loss: 0.03586 - acc: 0.9881 -- iter: 160/220
[A[ATraining Step: 76  | total loss: [1m[32m0.03594[0m[0m | time: 72.364s
[2K
| Adam | epoch: 011 | loss: 0.03594 - acc: 0.9860 -- iter: 192/220
[A[ATraining Step: 77  | total loss: [1m[32m0.03275[0m[0m | time: 90.433s
[2K
| Adam | epoch: 011 | loss: 0.03275 - acc: 0.9875 | val_loss: 0.35758 - val_acc: 0.9130 -- iter: 220/220
--
Training Step: 78  | total loss: [1m[32m0.02976[0m[0m | time: 7.922s
[2K
| Adam | epoch: 012 | loss: 0.02976 - acc: 0.9888 -- iter: 032/220
[A[ATraining Step: 79  | total loss: [1m[32m0.04478[0m[0m | time: 15.047s
[2K
| Adam | epoch: 012 | loss: 0.04478 - acc: 0.9868 -- iter: 064/220
[A[ATraining Step: 80  | total loss: [1m[32m0.18881[0m[0m | time: 24.162s
[2K
| Adam | epoch: 012 | loss: 0.18881 - acc: 0.9662 -- iter: 096/220
[A[ATraining Step: 81  | total loss: [1m[32m0.17105[0m[0m | time: 36.515s
[2K
| Adam | epoch: 012 | loss: 0.17105 - acc: 0.9696 -- iter: 128/220
[A[ATraining Step: 82  | total loss: [1m[32m0.15472[0m[0m | time: 49.220s
[2K
| Adam | epoch: 012 | loss: 0.15472 - acc: 0.9726 -- iter: 160/220
[A[ATraining Step: 83  | total loss: [1m[32m0.14186[0m[0m | time: 61.684s
[2K
| Adam | epoch: 012 | loss: 0.14186 - acc: 0.9754 -- iter: 192/220
[A[ATraining Step: 84  | total loss: [1m[32m0.12844[0m[0m | time: 79.540s
[2K
| Adam | epoch: 012 | loss: 0.12844 - acc: 0.9778 | val_loss: 0.33963 - val_acc: 0.9420 -- iter: 220/220
--
Training Step: 85  | total loss: [1m[32m0.11613[0m[0m | time: 12.573s
[2K
| Adam | epoch: 013 | loss: 0.11613 - acc: 0.9801 -- iter: 032/220
[A[ATraining Step: 86  | total loss: [1m[32m0.10605[0m[0m | time: 20.450s
[2K
| Adam | epoch: 013 | loss: 0.10605 - acc: 0.9821 -- iter: 064/220
[A[ATraining Step: 87  | total loss: [1m[32m0.09624[0m[0m | time: 27.720s
[2K
| Adam | epoch: 013 | loss: 0.09624 - acc: 0.9838 -- iter: 096/220
[A[ATraining Step: 88  | total loss: [1m[32m0.10750[0m[0m | time: 35.191s
[2K
| Adam | epoch: 013 | loss: 0.10750 - acc: 0.9783 -- iter: 128/220
[A[ATraining Step: 89  | total loss: [1m[32m0.09916[0m[0m | time: 48.107s
[2K
| Adam | epoch: 013 | loss: 0.09916 - acc: 0.9805 -- iter: 160/220
[A[ATraining Step: 90  | total loss: [1m[32m0.09094[0m[0m | time: 60.701s
[2K
| Adam | epoch: 013 | loss: 0.09094 - acc: 0.9824 -- iter: 192/220
[A[ATraining Step: 91  | total loss: [1m[32m0.08335[0m[0m | time: 78.589s
[2K
| Adam | epoch: 013 | loss: 0.08335 - acc: 0.9842 | val_loss: 0.29711 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 92  | total loss: [1m[32m0.07662[0m[0m | time: 11.928s
[2K
| Adam | epoch: 014 | loss: 0.07662 - acc: 0.9858 -- iter: 032/220
[A[ATraining Step: 93  | total loss: [1m[32m0.07212[0m[0m | time: 25.988s
[2K
| Adam | epoch: 014 | loss: 0.07212 - acc: 0.9872 -- iter: 064/220
[A[ATraining Step: 94  | total loss: [1m[32m0.06680[0m[0m | time: 38.760s
[2K
| Adam | epoch: 014 | loss: 0.06680 - acc: 0.9885 -- iter: 096/220
[A[ATraining Step: 95  | total loss: [1m[32m0.06110[0m[0m | time: 48.890s
[2K
| Adam | epoch: 014 | loss: 0.06110 - acc: 0.9896 -- iter: 128/220
[A[ATraining Step: 96  | total loss: [1m[32m0.05627[0m[0m | time: 56.012s
[2K
| Adam | epoch: 014 | loss: 0.05627 - acc: 0.9907 -- iter: 160/220
[A[ATraining Step: 97  | total loss: [1m[32m0.05166[0m[0m | time: 63.961s
[2K
| Adam | epoch: 014 | loss: 0.05166 - acc: 0.9916 -- iter: 192/220
[A[ATraining Step: 98  | total loss: [1m[32m0.04737[0m[0m | time: 79.797s
[2K
| Adam | epoch: 014 | loss: 0.04737 - acc: 0.9924 | val_loss: 0.40647 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 99  | total loss: [1m[32m0.04314[0m[0m | time: 12.226s
[2K
| Adam | epoch: 015 | loss: 0.04314 - acc: 0.9932 -- iter: 032/220
[A[ATraining Step: 100  | total loss: [1m[32m0.04181[0m[0m | time: 24.858s
[2K
| Adam | epoch: 015 | loss: 0.04181 - acc: 0.9939 -- iter: 064/220
[A[ATraining Step: 101  | total loss: [1m[32m0.03821[0m[0m | time: 37.197s
[2K
| Adam | epoch: 015 | loss: 0.03821 - acc: 0.9945 -- iter: 096/220
[A[ATraining Step: 102  | total loss: [1m[32m0.03596[0m[0m | time: 49.648s
[2K
| Adam | epoch: 015 | loss: 0.03596 - acc: 0.9950 -- iter: 128/220
[A[ATraining Step: 103  | total loss: [1m[32m0.03271[0m[0m | time: 60.589s
[2K
| Adam | epoch: 015 | loss: 0.03271 - acc: 0.9955 -- iter: 160/220
[A[ATraining Step: 104  | total loss: [1m[32m0.05406[0m[0m | time: 72.116s
[2K
| Adam | epoch: 015 | loss: 0.05406 - acc: 0.9924 -- iter: 192/220
[A[ATraining Step: 105  | total loss: [1m[32m0.04890[0m[0m | time: 86.663s
[2K
| Adam | epoch: 015 | loss: 0.04890 - acc: 0.9932 | val_loss: 0.37376 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 106  | total loss: [1m[32m0.04421[0m[0m | time: 12.756s
[2K
| Adam | epoch: 016 | loss: 0.04421 - acc: 0.9939 -- iter: 032/220
[A[ATraining Step: 107  | total loss: [1m[32m0.04044[0m[0m | time: 27.946s
[2K
| Adam | epoch: 016 | loss: 0.04044 - acc: 0.9945 -- iter: 064/220
[A[ATraining Step: 108  | total loss: [1m[32m0.03684[0m[0m | time: 43.279s
[2K
| Adam | epoch: 016 | loss: 0.03684 - acc: 0.9950 -- iter: 096/220
[A[ATraining Step: 109  | total loss: [1m[32m0.03502[0m[0m | time: 57.867s
[2K
| Adam | epoch: 016 | loss: 0.03502 - acc: 0.9955 -- iter: 128/220
[A[ATraining Step: 110  | total loss: [1m[32m0.03390[0m[0m | time: 73.333s
[2K
| Adam | epoch: 016 | loss: 0.03390 - acc: 0.9960 -- iter: 160/220
[A[ATraining Step: 111  | total loss: [1m[32m0.03087[0m[0m | time: 87.071s
[2K
| Adam | epoch: 016 | loss: 0.03087 - acc: 0.9964 -- iter: 192/220
[A[ATraining Step: 112  | total loss: [1m[32m0.04749[0m[0m | time: 107.204s
[2K
| Adam | epoch: 016 | loss: 0.04749 - acc: 0.9932 | val_loss: 0.38801 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 113  | total loss: [1m[32m0.04386[0m[0m | time: 9.560s
[2K
| Adam | epoch: 017 | loss: 0.04386 - acc: 0.9938 -- iter: 032/220
[A[ATraining Step: 114  | total loss: [1m[32m0.04008[0m[0m | time: 19.365s
[2K
| Adam | epoch: 017 | loss: 0.04008 - acc: 0.9945 -- iter: 064/220
[A[ATraining Step: 115  | total loss: [1m[32m0.03675[0m[0m | time: 39.843s
[2K
| Adam | epoch: 017 | loss: 0.03675 - acc: 0.9950 -- iter: 096/220
[A[ATraining Step: 116  | total loss: [1m[32m0.03430[0m[0m | time: 54.934s
[2K
| Adam | epoch: 017 | loss: 0.03430 - acc: 0.9955 -- iter: 128/220
[A[ATraining Step: 117  | total loss: [1m[32m0.03142[0m[0m | time: 70.333s
[2K
| Adam | epoch: 017 | loss: 0.03142 - acc: 0.9960 -- iter: 160/220
[A[ATraining Step: 118  | total loss: [1m[32m0.02859[0m[0m | time: 89.135s
[2K
| Adam | epoch: 017 | loss: 0.02859 - acc: 0.9964 -- iter: 192/220
[A[ATraining Step: 119  | total loss: [1m[32m0.02607[0m[0m | time: 109.783s
[2K
| Adam | epoch: 017 | loss: 0.02607 - acc: 0.9967 | val_loss: 0.43847 - val_acc: 0.9130 -- iter: 220/220
--
Training Step: 120  | total loss: [1m[32m0.06216[0m[0m | time: 14.301s
[2K
| Adam | epoch: 018 | loss: 0.06216 - acc: 0.9899 -- iter: 032/220
[A[ATraining Step: 121  | total loss: [1m[32m0.05612[0m[0m | time: 29.153s
[2K
| Adam | epoch: 018 | loss: 0.05612 - acc: 0.9909 -- iter: 064/220
[A[ATraining Step: 122  | total loss: [1m[32m0.05412[0m[0m | time: 43.175s
[2K
| Adam | epoch: 018 | loss: 0.05412 - acc: 0.9887 -- iter: 096/220
[A[ATraining Step: 123  | total loss: [1m[32m0.04964[0m[0m | time: 53.087s
[2K
| Adam | epoch: 018 | loss: 0.04964 - acc: 0.9898 -- iter: 128/220
[A[ATraining Step: 124  | total loss: [1m[32m0.04530[0m[0m | time: 63.260s
[2K
| Adam | epoch: 018 | loss: 0.04530 - acc: 0.9909 -- iter: 160/220
[A[ATraining Step: 125  | total loss: [1m[32m0.04113[0m[0m | time: 75.607s
[2K
| Adam | epoch: 018 | loss: 0.04113 - acc: 0.9918 -- iter: 192/220
[A[ATraining Step: 126  | total loss: [1m[32m0.03734[0m[0m | time: 97.147s
[2K
| Adam | epoch: 018 | loss: 0.03734 - acc: 0.9926 | val_loss: 0.42691 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 127  | total loss: [1m[32m0.03418[0m[0m | time: 13.811s
[2K
| Adam | epoch: 019 | loss: 0.03418 - acc: 0.9933 -- iter: 032/220
[A[ATraining Step: 128  | total loss: [1m[32m0.05649[0m[0m | time: 27.844s
[2K
| Adam | epoch: 019 | loss: 0.05649 - acc: 0.9904 -- iter: 064/220
[A[ATraining Step: 129  | total loss: [1m[32m0.05109[0m[0m | time: 43.404s
[2K
| Adam | epoch: 019 | loss: 0.05109 - acc: 0.9914 -- iter: 096/220
[A[ATraining Step: 130  | total loss: [1m[32m0.04795[0m[0m | time: 58.547s
[2K
| Adam | epoch: 019 | loss: 0.04795 - acc: 0.9922 -- iter: 128/220
[A[ATraining Step: 131  | total loss: [1m[32m0.04351[0m[0m | time: 73.212s
[2K
| Adam | epoch: 019 | loss: 0.04351 - acc: 0.9930 -- iter: 160/220
[A[ATraining Step: 132  | total loss: [1m[32m0.04137[0m[0m | time: 88.456s
[2K
| Adam | epoch: 019 | loss: 0.04137 - acc: 0.9937 -- iter: 192/220
[A[ATraining Step: 133  | total loss: [1m[32m0.03795[0m[0m | time: 103.817s
[2K
| Adam | epoch: 019 | loss: 0.03795 - acc: 0.9943 | val_loss: 0.61377 - val_acc: 0.8551 -- iter: 220/220
--
Training Step: 134  | total loss: [1m[32m0.03463[0m[0m | time: 14.880s
[2K
| Adam | epoch: 020 | loss: 0.03463 - acc: 0.9949 -- iter: 032/220
[A[ATraining Step: 135  | total loss: [1m[32m0.03171[0m[0m | time: 28.328s
[2K
| Adam | epoch: 020 | loss: 0.03171 - acc: 0.9954 -- iter: 064/220
[A[ATraining Step: 136  | total loss: [1m[32m0.08523[0m[0m | time: 41.810s
[2K
| Adam | epoch: 020 | loss: 0.08523 - acc: 0.9887 -- iter: 096/220
[A[ATraining Step: 137  | total loss: [1m[32m0.07766[0m[0m | time: 57.220s
[2K
| Adam | epoch: 020 | loss: 0.07766 - acc: 0.9899 -- iter: 128/220
[A[ATraining Step: 138  | total loss: [1m[32m0.07065[0m[0m | time: 72.544s
[2K
| Adam | epoch: 020 | loss: 0.07065 - acc: 0.9909 -- iter: 160/220
[A[ATraining Step: 139  | total loss: [1m[32m0.06498[0m[0m | time: 87.434s
[2K
| Adam | epoch: 020 | loss: 0.06498 - acc: 0.9918 -- iter: 192/220
[A[ATraining Step: 140  | total loss: [1m[32m0.06228[0m[0m | time: 113.016s
[2K
| Adam | epoch: 020 | loss: 0.06228 - acc: 0.9926 | val_loss: 0.31988 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 141  | total loss: [1m[32m0.05715[0m[0m | time: 9.727s
[2K
| Adam | epoch: 021 | loss: 0.05715 - acc: 0.9933 -- iter: 032/220
[A[ATraining Step: 142  | total loss: [1m[32m0.05212[0m[0m | time: 20.170s
[2K
| Adam | epoch: 021 | loss: 0.05212 - acc: 0.9940 -- iter: 064/220
[A[ATraining Step: 143  | total loss: [1m[32m0.04814[0m[0m | time: 28.933s
[2K
| Adam | epoch: 021 | loss: 0.04814 - acc: 0.9946 -- iter: 096/220
[A[ATraining Step: 144  | total loss: [1m[32m0.04411[0m[0m | time: 38.790s
[2K
| Adam | epoch: 021 | loss: 0.04411 - acc: 0.9952 -- iter: 128/220
[A[ATraining Step: 145  | total loss: [1m[32m0.04049[0m[0m | time: 53.612s
[2K
| Adam | epoch: 021 | loss: 0.04049 - acc: 0.9956 -- iter: 160/220
[A[ATraining Step: 146  | total loss: [1m[32m0.03723[0m[0m | time: 68.364s
[2K
| Adam | epoch: 021 | loss: 0.03723 - acc: 0.9961 -- iter: 192/220
[A[ATraining Step: 147  | total loss: [1m[32m0.03390[0m[0m | time: 89.754s
[2K
| Adam | epoch: 021 | loss: 0.03390 - acc: 0.9965 | val_loss: 0.38105 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 148  | total loss: [1m[32m0.03426[0m[0m | time: 15.289s
[2K
| Adam | epoch: 022 | loss: 0.03426 - acc: 0.9937 -- iter: 032/220
[A[ATraining Step: 149  | total loss: [1m[32m0.03171[0m[0m | time: 27.756s
[2K
| Adam | epoch: 022 | loss: 0.03171 - acc: 0.9943 -- iter: 064/220
[A[ATraining Step: 150  | total loss: [1m[32m0.02961[0m[0m | time: 40.005s
[2K
| Adam | epoch: 022 | loss: 0.02961 - acc: 0.9949 -- iter: 096/220
[A[ATraining Step: 151  | total loss: [1m[32m0.02698[0m[0m | time: 51.566s
[2K
| Adam | epoch: 022 | loss: 0.02698 - acc: 0.9954 -- iter: 128/220
[A[ATraining Step: 152  | total loss: [1m[32m0.06521[0m[0m | time: 59.652s
[2K
| Adam | epoch: 022 | loss: 0.06521 - acc: 0.9887 -- iter: 160/220
[A[ATraining Step: 153  | total loss: [1m[32m0.05973[0m[0m | time: 67.400s
[2K
| Adam | epoch: 022 | loss: 0.05973 - acc: 0.9898 -- iter: 192/220
[A[ATraining Step: 154  | total loss: [1m[32m0.05563[0m[0m | time: 78.166s
[2K
| Adam | epoch: 022 | loss: 0.05563 - acc: 0.9909 | val_loss: 0.44636 - val_acc: 0.9130 -- iter: 220/220
--
Training Step: 155  | total loss: [1m[32m0.05064[0m[0m | time: 7.827s
[2K
| Adam | epoch: 023 | loss: 0.05064 - acc: 0.9918 -- iter: 032/220
[A[ATraining Step: 156  | total loss: [1m[32m0.05568[0m[0m | time: 15.484s
[2K
| Adam | epoch: 023 | loss: 0.05568 - acc: 0.9895 -- iter: 064/220
[A[ATraining Step: 157  | total loss: [1m[32m0.05970[0m[0m | time: 23.312s
[2K
| Adam | epoch: 023 | loss: 0.05970 - acc: 0.9874 -- iter: 096/220
[A[ATraining Step: 158  | total loss: [1m[32m0.05771[0m[0m | time: 31.101s
[2K
| Adam | epoch: 023 | loss: 0.05771 - acc: 0.9855 -- iter: 128/220
[A[ATraining Step: 159  | total loss: [1m[32m0.05757[0m[0m | time: 38.163s
[2K
| Adam | epoch: 023 | loss: 0.05757 - acc: 0.9839 -- iter: 160/220
[A[ATraining Step: 160  | total loss: [1m[32m0.07824[0m[0m | time: 45.150s
[2K
| Adam | epoch: 023 | loss: 0.07824 - acc: 0.9819 -- iter: 192/220
[A[ATraining Step: 161  | total loss: [1m[32m0.07230[0m[0m | time: 56.005s
[2K
| Adam | epoch: 023 | loss: 0.07230 - acc: 0.9837 | val_loss: 0.44013 - val_acc: 0.8406 -- iter: 220/220
--
Training Step: 162  | total loss: [1m[32m0.06701[0m[0m | time: 7.788s
[2K
| Adam | epoch: 024 | loss: 0.06701 - acc: 0.9853 -- iter: 032/220
[A[ATraining Step: 163  | total loss: [1m[32m0.06101[0m[0m | time: 15.541s
[2K
| Adam | epoch: 024 | loss: 0.06101 - acc: 0.9868 -- iter: 064/220
[A[ATraining Step: 164  | total loss: [1m[32m0.05752[0m[0m | time: 23.311s
[2K
| Adam | epoch: 024 | loss: 0.05752 - acc: 0.9881 -- iter: 096/220
[A[ATraining Step: 165  | total loss: [1m[32m0.05264[0m[0m | time: 31.222s
[2K
| Adam | epoch: 024 | loss: 0.05264 - acc: 0.9893 -- iter: 128/220
[A[ATraining Step: 166  | total loss: [1m[32m0.05508[0m[0m | time: 39.068s
[2K
| Adam | epoch: 024 | loss: 0.05508 - acc: 0.9904 -- iter: 160/220
[A[ATraining Step: 167  | total loss: [1m[32m0.05086[0m[0m | time: 46.230s
[2K
| Adam | epoch: 024 | loss: 0.05086 - acc: 0.9913 -- iter: 192/220
[A[ATraining Step: 168  | total loss: [1m[32m0.07075[0m[0m | time: 56.275s
[2K
| Adam | epoch: 024 | loss: 0.07075 - acc: 0.9886 | val_loss: 0.28491 - val_acc: 0.9565 -- iter: 220/220
--
Training Step: 169  | total loss: [1m[32m0.06492[0m[0m | time: 7.888s
[2K
| Adam | epoch: 025 | loss: 0.06492 - acc: 0.9898 -- iter: 032/220
[A[ATraining Step: 170  | total loss: [1m[32m0.05920[0m[0m | time: 15.724s
[2K
| Adam | epoch: 025 | loss: 0.05920 - acc: 0.9908 -- iter: 064/220
[A[ATraining Step: 171  | total loss: [1m[32m0.05448[0m[0m | time: 23.648s
[2K
| Adam | epoch: 025 | loss: 0.05448 - acc: 0.9917 -- iter: 096/220
[A[ATraining Step: 172  | total loss: [1m[32m0.05069[0m[0m | time: 31.468s
[2K
| Adam | epoch: 025 | loss: 0.05069 - acc: 0.9925 -- iter: 128/220
[A[ATraining Step: 173  | total loss: [1m[32m0.04707[0m[0m | time: 39.382s
[2K
| Adam | epoch: 025 | loss: 0.04707 - acc: 0.9933 -- iter: 160/220
[A[ATraining Step: 174  | total loss: [1m[32m0.04296[0m[0m | time: 47.188s
[2K
| Adam | epoch: 025 | loss: 0.04296 - acc: 0.9940 -- iter: 192/220
[A[ATraining Step: 175  | total loss: [1m[32m0.04125[0m[0m | time: 57.268s
[2K
| Adam | epoch: 025 | loss: 0.04125 - acc: 0.9946 | val_loss: 0.31561 - val_acc: 0.9420 -- iter: 220/220
--
Training Step: 176  | total loss: [1m[32m0.03749[0m[0m | time: 6.975s
[2K
| Adam | epoch: 026 | loss: 0.03749 - acc: 0.9951 -- iter: 032/220
[A[ATraining Step: 177  | total loss: [1m[32m0.03405[0m[0m | time: 14.611s
[2K
| Adam | epoch: 026 | loss: 0.03405 - acc: 0.9956 -- iter: 064/220
[A[ATraining Step: 178  | total loss: [1m[32m0.03151[0m[0m | time: 22.394s
[2K
| Adam | epoch: 026 | loss: 0.03151 - acc: 0.9960 -- iter: 096/220
[A[ATraining Step: 179  | total loss: [1m[32m0.02870[0m[0m | time: 30.025s
[2K
| Adam | epoch: 026 | loss: 0.02870 - acc: 0.9964 -- iter: 128/220
[A[ATraining Step: 180  | total loss: [1m[32m0.02610[0m[0m | time: 37.780s
[2K
| Adam | epoch: 026 | loss: 0.02610 - acc: 0.9968 -- iter: 160/220
[A[ATraining Step: 181  | total loss: [1m[32m0.02387[0m[0m | time: 45.568s
[2K
| Adam | epoch: 026 | loss: 0.02387 - acc: 0.9971 -- iter: 192/220
[A[ATraining Step: 182  | total loss: [1m[32m0.02179[0m[0m | time: 56.405s
[2K
| Adam | epoch: 026 | loss: 0.02179 - acc: 0.9974 | val_loss: 0.39120 - val_acc: 0.9565 -- iter: 220/220
--
Training Step: 183  | total loss: [1m[32m0.01984[0m[0m | time: 7.132s
[2K
| Adam | epoch: 027 | loss: 0.01984 - acc: 0.9977 -- iter: 032/220
[A[ATraining Step: 184  | total loss: [1m[32m0.07064[0m[0m | time: 14.039s
[2K
| Adam | epoch: 027 | loss: 0.07064 - acc: 0.9872 -- iter: 064/220
[A[ATraining Step: 185  | total loss: [1m[32m0.06377[0m[0m | time: 21.773s
[2K
| Adam | epoch: 027 | loss: 0.06377 - acc: 0.9885 -- iter: 096/220
[A[ATraining Step: 186  | total loss: [1m[32m0.05857[0m[0m | time: 29.476s
[2K
| Adam | epoch: 027 | loss: 0.05857 - acc: 0.9896 -- iter: 128/220
[A[ATraining Step: 187  | total loss: [1m[32m0.05317[0m[0m | time: 37.167s
[2K
| Adam | epoch: 027 | loss: 0.05317 - acc: 0.9907 -- iter: 160/220
[A[ATraining Step: 188  | total loss: [1m[32m0.04846[0m[0m | time: 44.842s
[2K
| Adam | epoch: 027 | loss: 0.04846 - acc: 0.9916 -- iter: 192/220
[A[ATraining Step: 189  | total loss: [1m[32m0.04526[0m[0m | time: 55.702s
[2K
| Adam | epoch: 027 | loss: 0.04526 - acc: 0.9924 | val_loss: 0.31594 - val_acc: 0.9130 -- iter: 220/220
--
Training Step: 190  | total loss: [1m[32m0.04125[0m[0m | time: 7.669s
[2K
| Adam | epoch: 028 | loss: 0.04125 - acc: 0.9932 -- iter: 032/220
[A[ATraining Step: 191  | total loss: [1m[32m0.03753[0m[0m | time: 14.821s
[2K
| Adam | epoch: 028 | loss: 0.03753 - acc: 0.9939 -- iter: 064/220
[A[ATraining Step: 192  | total loss: [1m[32m0.07864[0m[0m | time: 21.847s
[2K
| Adam | epoch: 028 | loss: 0.07864 - acc: 0.9909 -- iter: 096/220
[A[ATraining Step: 193  | total loss: [1m[32m0.07103[0m[0m | time: 29.586s
[2K
| Adam | epoch: 028 | loss: 0.07103 - acc: 0.9918 -- iter: 128/220
[A[ATraining Step: 194  | total loss: [1m[32m0.06483[0m[0m | time: 37.202s
[2K
| Adam | epoch: 028 | loss: 0.06483 - acc: 0.9926 -- iter: 160/220
[A[ATraining Step: 195  | total loss: [1m[32m0.07087[0m[0m | time: 44.937s
[2K
| Adam | epoch: 028 | loss: 0.07087 - acc: 0.9902 -- iter: 192/220
[A[ATraining Step: 196  | total loss: [1m[32m0.06657[0m[0m | time: 55.748s
[2K
| Adam | epoch: 028 | loss: 0.06657 - acc: 0.9912 | val_loss: 0.38067 - val_acc: 0.9275 -- iter: 220/220
--
Training Step: 197  | total loss: [1m[32m0.06201[0m[0m | time: 7.662s
[2K
| Adam | epoch: 029 | loss: 0.06201 - acc: 0.9921 -- iter: 032/220
[A[ATraining Step: 198  | total loss: [1m[32m0.05668[0m[0m | time: 15.363s
[2K
| Adam | epoch: 029 | loss: 0.05668 - acc: 0.9929 -- iter: 064/220
[A[ATraining Step: 199  | total loss: [1m[32m0.05442[0m[0m | time: 22.335s
[2K
| Adam | epoch: 029 | loss: 0.05442 - acc: 0.9936 -- iter: 096/220
[A[ATraining Step: 200  | total loss: [1m[32m0.04962[0m[0m | time: 32.550s
[2K
| Adam | epoch: 029 | loss: 0.04962 - acc: 0.9942 | val_loss: 0.45214 - val_acc: 0.8841 -- iter: 128/220
--
Training Step: 201  | total loss: [1m[32m0.04527[0m[0m | time: 40.241s
[2K
| Adam | epoch: 029 | loss: 0.04527 - acc: 0.9948 -- iter: 160/220
[A[ATraining Step: 202  | total loss: [1m[32m0.04229[0m[0m | time: 47.952s
[2K
| Adam | epoch: 029 | loss: 0.04229 - acc: 0.9953 -- iter: 192/220
[A[ATraining Step: 203  | total loss: [1m[32m0.03920[0m[0m | time: 58.732s
[2K
| Adam | epoch: 029 | loss: 0.03920 - acc: 0.9958 | val_loss: 0.41338 - val_acc: 0.8986 -- iter: 220/220
--
Training Step: 204  | total loss: [1m[32m0.03647[0m[0m | time: 7.745s
[2K
| Adam | epoch: 030 | loss: 0.03647 - acc: 0.9962 -- iter: 032/220
[A[ATraining Step: 205  | total loss: [1m[32m0.03504[0m[0m | time: 15.475s
[2K
| Adam | epoch: 030 | loss: 0.03504 - acc: 0.9966 -- iter: 064/220
[A[ATraining Step: 206  | total loss: [1m[32m0.03766[0m[0m | time: 23.097s
[2K
| Adam | epoch: 030 | loss: 0.03766 - acc: 0.9938 -- iter: 096/220
[A[ATraining Step: 207  | total loss: [1m[32m0.03568[0m[0m | time: 30.166s
[2K
| Adam | epoch: 030 | loss: 0.03568 - acc: 0.9944 -- iter: 128/220
[A[ATraining Step: 208  | total loss: [1m[32m0.05511[0m[0m | time: 37.230s
[2K
| Adam | epoch: 030 | loss: 0.05511 - acc: 0.9914 -- iter: 160/220
[A[ATraining Step: 209  | total loss: [1m[32m0.04988[0m[0m | time: 44.976s
[2K
| Adam | epoch: 030 | loss: 0.04988 - acc: 0.9923 -- iter: 192/220
[A[ATraining Step: 210  | total loss: [1m[32m0.04512[0m[0m | time: 55.734s
[2K
| Adam | epoch: 030 | loss: 0.04512 - acc: 0.9930 | val_loss: 0.33823 - val_acc: 0.9275 -- iter: 220/220
--
Validation AUC:0.9435626102292769
Validation AUPRC:0.9105813042397666
Test AUC:1.0
Test AUPRC:1.0
BestTestF1Score	0.96	0.92	0.96	0.92	1.0	34	3	32	0	0.72
BestTestMCCScore	0.96	0.92	0.96	0.92	1.0	34	3	32	0	0.72
BestTestAccuracyScore	0.99	0.97	0.99	0.97	1.0	34	1	34	0	0.94
BestValidationF1Score	0.95	0.88	0.94	0.93	0.98	41	3	24	1	0.72
BestValidationMCC	0.95	0.88	0.94	0.93	0.98	41	3	24	1	0.72
BestValidationAccuracy	0.95	0.88	0.94	0.95	0.95	40	2	25	2	0.94
TestPredictions (Threshold:0.72)
CHEMBL2324988,TN,INACT,0.019999999552965164	CHEMBL3416923,TP,ACT,1.0	CHEMBL2324978,TN,INACT,0.20999999344348907	CHEMBL3113249,TN,INACT,0.009999999776482582	CHEMBL3416920,TP,ACT,1.0	CHEMBL3799377,TP,ACT,1.0	CHEMBL105782,TN,INACT,0.05999999865889549	CHEMBL3799874,TP,ACT,1.0	CHEMBL3800441,TP,ACT,1.0	CHEMBL2325233,TN,INACT,0.009999999776482582	CHEMBL3800075,TP,ACT,1.0	CHEMBL2325264,TN,INACT,0.009999999776482582	CHEMBL289425,TP,ACT,0.9900000095367432	CHEMBL3799719,TP,ACT,1.0	CHEMBL10404,TN,INACT,0.009999999776482582	CHEMBL3800326,TP,ACT,1.0	CHEMBL1917112,TN,INACT,0.17000000178813934	CHEMBL558,TN,INACT,0.009999999776482582	CHEMBL3799252,TP,ACT,1.0	CHEMBL3337593,TN,INACT,0.019999999552965164	CHEMBL3337590,TN,INACT,0.1599999964237213	CHEMBL2409402,FP,INACT,0.8799999952316284	CHEMBL3416938,TP,ACT,1.0	CHEMBL1800374,TN,INACT,0.2800000011920929	CHEMBL3416922,TP,ACT,1.0	CHEMBL2324980,TN,INACT,0.029999999329447746	CHEMBL3416890,TP,ACT,1.0	CHEMBL2298875,TN,INACT,0.4699999988079071	CHEMBL3634321,TN,INACT,0.009999999776482582	CHEMBL2325263,TN,INACT,0.029999999329447746	CHEMBL3799811,TP,ACT,1.0	CHEMBL3798460,TP,ACT,1.0	CHEMBL522211,TN,INACT,0.009999999776482582	CHEMBL3687606,TN,INACT,0.009999999776482582	CHEMBL193449,TN,INACT,0.5600000023841858	CHEMBL741,TN,INACT,0.07000000029802322	CHEMBL3800625,TP,ACT,1.0	CHEMBL1767045,TN,INACT,0.029999999329447746	CHEMBL466587,TN,INACT,0.23000000417232513	CHEMBL3687593,TN,INACT,0.49000000953674316	CHEMBL37379,TN,INACT,0.15000000596046448	CHEMBL3797227,TP,ACT,0.9900000095367432	CHEMBL3416900,TP,ACT,1.0	CHEMBL3799101,TP,ACT,1.0	CHEMBL3416930,TP,ACT,1.0	CHEMBL357719,TP,ACT,0.9800000190734863	CHEMBL3113261,TN,INACT,0.009999999776482582	CHEMBL3798824,TP,ACT,1.0	CHEMBL3799721,TP,ACT,1.0	CHEMBL3085878,TN,INACT,0.009999999776482582	CHEMBL3416894,TP,ACT,1.0	CHEMBL1800241,TN,INACT,0.6899999976158142	CHEMBL519199,FP,INACT,0.9700000286102295	CHEMBL3799535,TP,ACT,1.0	CHEMBL3126834,TN,INACT,0.009999999776482582	CHEMBL3416931,TP,ACT,1.0	CHEMBL3113262,TN,INACT,0.33000001311302185	CHEMBL312097,TN,INACT,0.009999999776482582	CHEMBL108,TN,INACT,0.10999999940395355	CHEMBL3797204,TP,ACT,1.0	CHEMBL3800504,TP,ACT,1.0	CHEMBL3797473,TP,ACT,1.0	CHEMBL2324983,TN,INACT,0.009999999776482582	CHEMBL3416921,TP,ACT,1.0	CHEMBL151508,TP,ACT,0.9800000190734863	CHEMBL3798414,TP,ACT,1.0	CHEMBL3416943,TP,ACT,1.0	CHEMBL2325234,FP,INACT,0.8899999856948853	CHEMBL3799702,TP,ACT,1.0	

