ImageNetInceptionV2 CHEMBL4472 RMSprop 0.001 15 0 0 0.8 False True
Number of active compounds :	118
Number of inactive compounds :	118
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4472_RMSprop_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4472_RMSprop_0.001_15_0.8/
---------------------------------
Training samples: 150
Validation samples: 48
--
Training Step: 1  | time: 77.410s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/150
[A[ATraining Step: 2  | total loss: [1m[32m0.68358[0m[0m | time: 144.078s
[2K
| RMSProp | epoch: 001 | loss: 0.68358 - acc: 0.4219 -- iter: 064/150
[A[ATraining Step: 3  | total loss: [1m[32m0.70070[0m[0m | time: 197.288s
[2K
| RMSProp | epoch: 001 | loss: 0.70070 - acc: 0.5369 -- iter: 096/150
[A[ATraining Step: 4  | total loss: [1m[32m0.67273[0m[0m | time: 206.571s
[2K
| RMSProp | epoch: 001 | loss: 0.67273 - acc: 0.5795 -- iter: 128/150
[A[ATraining Step: 5  | total loss: [1m[32m0.71749[0m[0m | time: 221.137s
[2K
| RMSProp | epoch: 001 | loss: 0.71749 - acc: 0.4812 | val_loss: 0.69712 - val_acc: 0.5417 -- iter: 150/150
--
Training Step: 6  | total loss: [1m[32m0.71648[0m[0m | time: 14.908s
[2K
| RMSProp | epoch: 002 | loss: 0.71648 - acc: 0.4641 -- iter: 032/150
[A[ATraining Step: 7  | total loss: [1m[32m0.68769[0m[0m | time: 62.803s
[2K
| RMSProp | epoch: 002 | loss: 0.68769 - acc: 0.5129 -- iter: 064/150
[A[ATraining Step: 8  | total loss: [1m[32m0.72165[0m[0m | time: 84.324s
[2K
| RMSProp | epoch: 002 | loss: 0.72165 - acc: 0.4002 -- iter: 096/150
[A[ATraining Step: 9  | total loss: [1m[32m0.70238[0m[0m | time: 117.431s
[2K
| RMSProp | epoch: 002 | loss: 0.70238 - acc: 0.4530 -- iter: 128/150
[A[ATraining Step: 10  | total loss: [1m[32m0.67027[0m[0m | time: 153.724s
[2K
| RMSProp | epoch: 002 | loss: 0.67027 - acc: 0.5390 | val_loss: 0.70859 - val_acc: 0.5417 -- iter: 150/150
--
Training Step: 11  | total loss: [1m[32m0.68457[0m[0m | time: 6.598s
[2K
| RMSProp | epoch: 003 | loss: 0.68457 - acc: 0.5057 -- iter: 032/150
[A[ATraining Step: 12  | total loss: [1m[32m0.68839[0m[0m | time: 14.103s
[2K
| RMSProp | epoch: 003 | loss: 0.68839 - acc: 0.5236 -- iter: 064/150
[A[ATraining Step: 13  | total loss: [1m[32m0.67506[0m[0m | time: 30.794s
[2K
| RMSProp | epoch: 003 | loss: 0.67506 - acc: 0.5719 -- iter: 096/150
[A[ATraining Step: 14  | total loss: [1m[32m0.68184[0m[0m | time: 63.129s
[2K
| RMSProp | epoch: 003 | loss: 0.68184 - acc: 0.5553 -- iter: 128/150
[A[ATraining Step: 15  | total loss: [1m[32m0.68255[0m[0m | time: 79.523s
[2K
| RMSProp | epoch: 003 | loss: 0.68255 - acc: 0.5581 | val_loss: 0.70440 - val_acc: 0.5417 -- iter: 150/150
--
Training Step: 16  | total loss: [1m[32m0.67922[0m[0m | time: 35.132s
[2K
| RMSProp | epoch: 004 | loss: 0.67922 - acc: 0.5832 -- iter: 032/150
[A[ATraining Step: 17  | total loss: [1m[32m0.67492[0m[0m | time: 41.634s
[2K
| RMSProp | epoch: 004 | loss: 0.67492 - acc: 0.5645 -- iter: 064/150
[A[ATraining Step: 18  | total loss: [1m[32m0.69059[0m[0m | time: 48.301s
[2K
| RMSProp | epoch: 004 | loss: 0.69059 - acc: 0.5264 -- iter: 096/150
[A[ATraining Step: 19  | total loss: [1m[32m0.69355[0m[0m | time: 70.707s
[2K
| RMSProp | epoch: 004 | loss: 0.69355 - acc: 0.5176 -- iter: 128/150
[A[ATraining Step: 20  | total loss: [1m[32m0.67809[0m[0m | time: 100.639s
[2K
| RMSProp | epoch: 004 | loss: 0.67809 - acc: 0.5923 | val_loss: 0.72779 - val_acc: 0.5417 -- iter: 150/150
--
Training Step: 21  | total loss: [1m[32m0.67016[0m[0m | time: 15.665s
[2K
| RMSProp | epoch: 005 | loss: 0.67016 - acc: 0.6025 -- iter: 032/150
[A[ATraining Step: 22  | total loss: [1m[32m0.67327[0m[0m | time: 29.177s
[2K
| RMSProp | epoch: 005 | loss: 0.67327 - acc: 0.5905 -- iter: 064/150
[A[ATraining Step: 23  | total loss: [1m[32m0.66417[0m[0m | time: 35.630s
[2K
| RMSProp | epoch: 005 | loss: 0.66417 - acc: 0.6186 -- iter: 096/150
[A[ATraining Step: 24  | total loss: [1m[32m0.66368[0m[0m | time: 41.873s
[2K
| RMSProp | epoch: 005 | loss: 0.66368 - acc: 0.5981 -- iter: 128/150
[A[ATraining Step: 25  | total loss: [1m[32m0.65401[0m[0m | time: 64.883s
[2K
| RMSProp | epoch: 005 | loss: 0.65401 - acc: 0.6457 | val_loss: 0.71560 - val_acc: 0.5417 -- iter: 150/150
--
Training Step: 26  | total loss: [1m[32m0.64514[0m[0m | time: 24.762s
[2K
| RMSProp | epoch: 006 | loss: 0.64514 - acc: 0.6898 -- iter: 032/150
[A[ATraining Step: 27  | total loss: [1m[32m0.63922[0m[0m | time: 46.871s
[2K
| RMSProp | epoch: 006 | loss: 0.63922 - acc: 0.7053 -- iter: 064/150
[A[ATraining Step: 28  | total loss: [1m[32m0.64178[0m[0m | time: 55.569s
[2K
| RMSProp | epoch: 006 | loss: 0.64178 - acc: 0.6930 -- iter: 096/150
[A[ATraining Step: 29  | total loss: [1m[32m0.63881[0m[0m | time: 62.036s
[2K
| RMSProp | epoch: 006 | loss: 0.63881 - acc: 0.7069 -- iter: 128/150
[A[ATraining Step: 30  | total loss: [1m[32m0.63248[0m[0m | time: 70.769s
[2K
| RMSProp | epoch: 006 | loss: 0.63248 - acc: 0.7225 | val_loss: 0.69977 - val_acc: 0.5417 -- iter: 150/150
--
Training Step: 31  | total loss: [1m[32m0.61361[0m[0m | time: 12.228s
[2K
| RMSProp | epoch: 007 | loss: 0.61361 - acc: 0.7341 -- iter: 032/150
[A[ATraining Step: 32  | total loss: [1m[32m0.61650[0m[0m | time: 46.358s
[2K
| RMSProp | epoch: 007 | loss: 0.61650 - acc: 0.7236 -- iter: 064/150
[A[ATraining Step: 33  | total loss: [1m[32m0.61692[0m[0m | time: 70.406s
[2K
| RMSProp | epoch: 007 | loss: 0.61692 - acc: 0.7363 -- iter: 096/150
[A[ATraining Step: 34  | total loss: [1m[32m0.61151[0m[0m | time: 92.252s
[2K
| RMSProp | epoch: 007 | loss: 0.61151 - acc: 0.7526 -- iter: 128/150
[A[ATraining Step: 35  | total loss: [1m[32m0.60647[0m[0m | time: 101.012s
[2K
| RMSProp | epoch: 007 | loss: 0.60647 - acc: 0.7324 | val_loss: 0.67118 - val_acc: 0.5417 -- iter: 150/150
--
Training Step: 36  | total loss: [1m[32m0.60470[0m[0m | time: 6.360s
[2K
| RMSProp | epoch: 008 | loss: 0.60470 - acc: 0.7221 -- iter: 032/150
[A[ATraining Step: 37  | total loss: [1m[32m0.58467[0m[0m | time: 16.151s
[2K
| RMSProp | epoch: 008 | loss: 0.58467 - acc: 0.7413 -- iter: 064/150
[A[ATraining Step: 38  | total loss: [1m[32m0.59389[0m[0m | time: 36.086s
[2K
| RMSProp | epoch: 008 | loss: 0.59389 - acc: 0.7185 -- iter: 096/150
[A[ATraining Step: 39  | total loss: [1m[32m0.59611[0m[0m | time: 53.484s
[2K
| RMSProp | epoch: 008 | loss: 0.59611 - acc: 0.7126 -- iter: 128/150
[A[ATraining Step: 40  | total loss: [1m[32m0.59527[0m[0m | time: 67.294s
[2K
| RMSProp | epoch: 008 | loss: 0.59527 - acc: 0.7255 | val_loss: 0.65161 - val_acc: 0.5625 -- iter: 150/150
--
Training Step: 41  | total loss: [1m[32m0.60151[0m[0m | time: 7.121s
[2K
| RMSProp | epoch: 009 | loss: 0.60151 - acc: 0.7242 -- iter: 032/150
[A[ATraining Step: 42  | total loss: [1m[32m0.58957[0m[0m | time: 14.564s
[2K
| RMSProp | epoch: 009 | loss: 0.58957 - acc: 0.7411 -- iter: 064/150
[A[ATraining Step: 43  | total loss: [1m[32m0.57884[0m[0m | time: 47.435s
[2K
| RMSProp | epoch: 009 | loss: 0.57884 - acc: 0.7628 -- iter: 096/150
[A[ATraining Step: 44  | total loss: [1m[32m0.57076[0m[0m | time: 57.727s
[2K
| RMSProp | epoch: 009 | loss: 0.57076 - acc: 0.7768 -- iter: 128/150
[A[ATraining Step: 45  | total loss: [1m[32m0.56893[0m[0m | time: 74.928s
[2K
| RMSProp | epoch: 009 | loss: 0.56893 - acc: 0.7828 | val_loss: 0.62828 - val_acc: 0.6875 -- iter: 150/150
--
Training Step: 46  | total loss: [1m[32m0.56269[0m[0m | time: 13.404s
[2K
| RMSProp | epoch: 010 | loss: 0.56269 - acc: 0.7826 -- iter: 032/150
[A[ATraining Step: 47  | total loss: [1m[32m0.56040[0m[0m | time: 19.861s
[2K
| RMSProp | epoch: 010 | loss: 0.56040 - acc: 0.7772 -- iter: 064/150
[A[ATraining Step: 48  | total loss: [1m[32m0.57207[0m[0m | time: 26.134s
[2K
| RMSProp | epoch: 010 | loss: 0.57207 - acc: 0.7619 -- iter: 096/150
[A[ATraining Step: 49  | total loss: [1m[32m0.56035[0m[0m | time: 34.882s
[2K
| RMSProp | epoch: 010 | loss: 0.56035 - acc: 0.7636 -- iter: 128/150
[A[ATraining Step: 50  | total loss: [1m[32m0.55697[0m[0m | time: 47.333s
[2K
| RMSProp | epoch: 010 | loss: 0.55697 - acc: 0.7615 | val_loss: 0.66389 - val_acc: 0.5417 -- iter: 150/150
--
Training Step: 51  | total loss: [1m[32m0.56771[0m[0m | time: 10.155s
[2K
| RMSProp | epoch: 011 | loss: 0.56771 - acc: 0.7502 -- iter: 032/150
[A[ATraining Step: 52  | total loss: [1m[32m0.57576[0m[0m | time: 20.620s
[2K
| RMSProp | epoch: 011 | loss: 0.57576 - acc: 0.7267 -- iter: 064/150
[A[ATraining Step: 53  | total loss: [1m[32m0.56892[0m[0m | time: 27.171s
[2K
| RMSProp | epoch: 011 | loss: 0.56892 - acc: 0.7302 -- iter: 096/150
[A[ATraining Step: 54  | total loss: [1m[32m0.56327[0m[0m | time: 33.537s
[2K
| RMSProp | epoch: 011 | loss: 0.56327 - acc: 0.7496 -- iter: 128/150
[A[ATraining Step: 55  | total loss: [1m[32m0.55011[0m[0m | time: 48.576s
[2K
| RMSProp | epoch: 011 | loss: 0.55011 - acc: 0.7658 | val_loss: 0.69683 - val_acc: 0.5000 -- iter: 150/150
--
Training Step: 56  | total loss: [1m[32m0.54679[0m[0m | time: 8.881s
[2K
| RMSProp | epoch: 012 | loss: 0.54679 - acc: 0.7812 -- iter: 032/150
[A[ATraining Step: 57  | total loss: [1m[32m0.56031[0m[0m | time: 17.476s
[2K
| RMSProp | epoch: 012 | loss: 0.56031 - acc: 0.7552 -- iter: 064/150
[A[ATraining Step: 58  | total loss: [1m[32m0.56221[0m[0m | time: 25.999s
[2K
| RMSProp | epoch: 012 | loss: 0.56221 - acc: 0.7460 -- iter: 096/150
[A[ATraining Step: 59  | total loss: [1m[32m0.55749[0m[0m | time: 32.224s
[2K
| RMSProp | epoch: 012 | loss: 0.55749 - acc: 0.7507 -- iter: 128/150
[A[ATraining Step: 60  | total loss: [1m[32m0.55064[0m[0m | time: 40.508s
[2K
| RMSProp | epoch: 012 | loss: 0.55064 - acc: 0.7416 | val_loss: 0.60012 - val_acc: 0.7708 -- iter: 150/150
--
Training Step: 61  | total loss: [1m[32m0.53366[0m[0m | time: 8.542s
[2K
| RMSProp | epoch: 013 | loss: 0.53366 - acc: 0.7694 -- iter: 032/150
[A[ATraining Step: 62  | total loss: [1m[32m0.53595[0m[0m | time: 17.030s
[2K
| RMSProp | epoch: 013 | loss: 0.53595 - acc: 0.7589 -- iter: 064/150
[A[ATraining Step: 63  | total loss: [1m[32m0.53002[0m[0m | time: 30.994s
[2K
| RMSProp | epoch: 013 | loss: 0.53002 - acc: 0.7577 -- iter: 096/150
[A[ATraining Step: 64  | total loss: [1m[32m0.53302[0m[0m | time: 46.620s
[2K
| RMSProp | epoch: 013 | loss: 0.53302 - acc: 0.7451 -- iter: 128/150
[A[ATraining Step: 65  | total loss: [1m[32m0.53588[0m[0m | time: 55.391s
[2K
| RMSProp | epoch: 013 | loss: 0.53588 - acc: 0.7341 | val_loss: 0.63874 - val_acc: 0.5625 -- iter: 150/150
--
Training Step: 66  | total loss: [1m[32m0.53987[0m[0m | time: 6.330s
[2K
| RMSProp | epoch: 014 | loss: 0.53987 - acc: 0.7222 -- iter: 032/150
[A[ATraining Step: 67  | total loss: [1m[32m0.50877[0m[0m | time: 15.062s
[2K
| RMSProp | epoch: 014 | loss: 0.50877 - acc: 0.7556 -- iter: 064/150
[A[ATraining Step: 68  | total loss: [1m[32m0.51640[0m[0m | time: 23.915s
[2K
| RMSProp | epoch: 014 | loss: 0.51640 - acc: 0.7586 -- iter: 096/150
[A[ATraining Step: 69  | total loss: [1m[32m0.50371[0m[0m | time: 32.421s
[2K
| RMSProp | epoch: 014 | loss: 0.50371 - acc: 0.7722 -- iter: 128/150
[A[ATraining Step: 70  | total loss: [1m[32m0.50658[0m[0m | time: 43.367s
[2K
| RMSProp | epoch: 014 | loss: 0.50658 - acc: 0.7769 | val_loss: 2.20206 - val_acc: 0.4583 -- iter: 150/150
--
Training Step: 71  | total loss: [1m[32m0.49573[0m[0m | time: 6.398s
[2K
| RMSProp | epoch: 015 | loss: 0.49573 - acc: 0.7809 -- iter: 032/150
[A[ATraining Step: 72  | total loss: [1m[32m0.49612[0m[0m | time: 12.733s
[2K
| RMSProp | epoch: 015 | loss: 0.49612 - acc: 0.7800 -- iter: 064/150
[A[ATraining Step: 73  | total loss: [1m[32m0.47446[0m[0m | time: 23.291s
[2K
| RMSProp | epoch: 015 | loss: 0.47446 - acc: 0.7994 -- iter: 096/150
[A[ATraining Step: 74  | total loss: [1m[32m0.46245[0m[0m | time: 31.891s
[2K
| RMSProp | epoch: 015 | loss: 0.46245 - acc: 0.8111 -- iter: 128/150
[A[ATraining Step: 75  | total loss: [1m[32m0.46726[0m[0m | time: 42.785s
[2K
| RMSProp | epoch: 015 | loss: 0.46726 - acc: 0.8147 | val_loss: 1.90487 - val_acc: 0.4792 -- iter: 150/150
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7744755244755245
Validation AUPRC:0.7329605639410046
Test AUC:0.9195804195804196
Test AUPRC:0.8761637067439758
BestTestF1Score	0.79	0.59	0.75	0.65	1.0	22	12	14	0	0.95
BestTestMCCScore	0.88	0.79	0.9	0.9	0.86	19	2	24	3	0.99
BestTestAccuracyScore	0.88	0.79	0.9	0.9	0.86	19	2	24	3	0.99
BestValidationF1Score	0.7	0.37	0.65	0.57	0.91	20	15	11	2	0.95
BestValidationMCC	0.68	0.41	0.71	0.68	0.68	15	7	19	7	0.99
BestValidationAccuracy	0.68	0.41	0.71	0.68	0.68	15	7	19	7	0.99
TestPredictions (Threshold:0.99)
CHEMBL318773,TP,ACT,0.9900000095367432	CHEMBL1348562,TN,INACT,0.7900000214576721	CHEMBL119964,TP,ACT,1.0	CHEMBL331896,TP,ACT,1.0	CHEMBL294326,TN,INACT,0.8100000023841858	CHEMBL322830,TP,ACT,0.9900000095367432	CHEMBL107140,TP,ACT,1.0	CHEMBL1704776,TN,INACT,0.9200000166893005	CHEMBL104426,TP,ACT,1.0	CHEMBL2159304,TN,INACT,0.9200000166893005	CHEMBL60160,TN,INACT,0.7599999904632568	CHEMBL1523678,TN,INACT,0.9700000286102295	CHEMBL108354,TP,ACT,0.9900000095367432	CHEMBL1392593,TN,INACT,0.8799999952316284	CHEMBL1907778,TN,INACT,0.9800000190734863	CHEMBL1557929,TN,INACT,0.8600000143051147	CHEMBL108058,FN,ACT,0.9800000190734863	CHEMBL106718,TP,ACT,0.9900000095367432	CHEMBL406121,TN,INACT,0.7699999809265137	CHEMBL323452,TP,ACT,0.9900000095367432	CHEMBL38512,TN,INACT,0.9200000166893005	CHEMBL318304,TP,ACT,0.9900000095367432	CHEMBL118906,TP,ACT,0.9900000095367432	CHEMBL1907779,TN,INACT,0.9800000190734863	CHEMBL3247193,TN,INACT,0.8500000238418579	CHEMBL107592,TP,ACT,0.9900000095367432	CHEMBL1537034,FP,INACT,1.0	CHEMBL3408419,TN,INACT,0.9800000190734863	CHEMBL327600,TP,ACT,1.0	CHEMBL1542752,TN,INACT,0.9700000286102295	CHEMBL3099874,TN,INACT,0.9599999785423279	CHEMBL119773,FN,ACT,0.9700000286102295	CHEMBL418839,TN,INACT,0.9800000190734863	CHEMBL320937,TP,ACT,1.0	CHEMBL51173,FN,ACT,0.9800000190734863	CHEMBL133027,TN,INACT,0.9800000190734863	CHEMBL323304,TP,ACT,0.9900000095367432	CHEMBL320393,TP,ACT,1.0	CHEMBL119966,TP,ACT,0.9900000095367432	CHEMBL61933,TN,INACT,0.7900000214576721	CHEMBL310760,TN,INACT,0.49000000953674316	CHEMBL62490,TN,INACT,0.8600000143051147	CHEMBL322165,TP,ACT,1.0	CHEMBL3125572,TN,INACT,0.9700000286102295	CHEMBL1405851,TN,INACT,0.8999999761581421	CHEMBL332650,TP,ACT,0.9900000095367432	CHEMBL320512,FP,INACT,1.0	CHEMBL1532635,TN,INACT,0.9800000190734863	

