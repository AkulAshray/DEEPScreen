ImageNetInceptionV2 CHEMBL2004 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	108
Number of inactive compounds :	108
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2004_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2004_adam_0.0005_30_0.8/
---------------------------------
Training samples: 137
Validation samples: 44
--
Training Step: 1  | time: 76.259s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/137
[A[ATraining Step: 2  | total loss: [1m[32m0.60250[0m[0m | time: 128.186s
[2K
| Adam | epoch: 001 | loss: 0.60250 - acc: 0.5625 -- iter: 064/137
[A[ATraining Step: 3  | total loss: [1m[32m0.44480[0m[0m | time: 172.785s
[2K
| Adam | epoch: 001 | loss: 0.44480 - acc: 0.7415 -- iter: 096/137
[A[ATraining Step: 4  | total loss: [1m[32m0.28514[0m[0m | time: 243.988s
[2K
| Adam | epoch: 001 | loss: 0.28514 - acc: 0.8885 -- iter: 128/137
[A[ATraining Step: 5  | total loss: [1m[32m0.45427[0m[0m | time: 255.538s
[2K
| Adam | epoch: 001 | loss: 0.45427 - acc: 0.8575 | val_loss: 2.73519 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 6  | total loss: [1m[32m0.24597[0m[0m | time: 3.362s
[2K
| Adam | epoch: 002 | loss: 0.24597 - acc: 0.9491 -- iter: 032/137
[A[ATraining Step: 7  | total loss: [1m[32m0.11272[0m[0m | time: 33.972s
[2K
| Adam | epoch: 002 | loss: 0.11272 - acc: 0.9796 -- iter: 064/137
[A[ATraining Step: 8  | total loss: [1m[32m0.18769[0m[0m | time: 64.412s
[2K
| Adam | epoch: 002 | loss: 0.18769 - acc: 0.9032 -- iter: 096/137
[A[ATraining Step: 9  | total loss: [1m[32m0.39813[0m[0m | time: 89.987s
[2K
| Adam | epoch: 002 | loss: 0.39813 - acc: 0.8717 -- iter: 128/137
[A[ATraining Step: 10  | total loss: [1m[32m0.29512[0m[0m | time: 101.016s
[2K
| Adam | epoch: 002 | loss: 0.29512 - acc: 0.9202 | val_loss: 3.23445 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 11  | total loss: [1m[32m0.26059[0m[0m | time: 3.340s
[2K
| Adam | epoch: 003 | loss: 0.26059 - acc: 0.8988 -- iter: 032/137
[A[ATraining Step: 12  | total loss: [1m[32m0.18232[0m[0m | time: 6.860s
[2K
| Adam | epoch: 003 | loss: 0.18232 - acc: 0.9443 -- iter: 064/137
[A[ATraining Step: 13  | total loss: [1m[32m0.11387[0m[0m | time: 85.775s
[2K
| Adam | epoch: 003 | loss: 0.11387 - acc: 0.9682 -- iter: 096/137
[A[ATraining Step: 14  | total loss: [1m[32m0.09904[0m[0m | time: 140.579s
[2K
| Adam | epoch: 003 | loss: 0.09904 - acc: 0.9812 -- iter: 128/137
[A[ATraining Step: 15  | total loss: [1m[32m0.10557[0m[0m | time: 172.077s
[2K
| Adam | epoch: 003 | loss: 0.10557 - acc: 0.9886 | val_loss: 3.19817 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 16  | total loss: [1m[32m0.07888[0m[0m | time: 54.117s
[2K
| Adam | epoch: 004 | loss: 0.07888 - acc: 0.9929 -- iter: 032/137
[A[ATraining Step: 17  | total loss: [1m[32m0.06632[0m[0m | time: 57.431s
[2K
| Adam | epoch: 004 | loss: 0.06632 - acc: 0.9954 -- iter: 064/137
[A[ATraining Step: 18  | total loss: [1m[32m0.05801[0m[0m | time: 60.880s
[2K
| Adam | epoch: 004 | loss: 0.05801 - acc: 0.9970 -- iter: 096/137
[A[ATraining Step: 19  | total loss: [1m[32m0.04021[0m[0m | time: 82.148s
[2K
| Adam | epoch: 004 | loss: 0.04021 - acc: 0.9980 -- iter: 128/137
[A[ATraining Step: 20  | total loss: [1m[32m0.03045[0m[0m | time: 119.015s
[2K
| Adam | epoch: 004 | loss: 0.03045 - acc: 0.9986 | val_loss: 3.33846 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 21  | total loss: [1m[32m0.02613[0m[0m | time: 20.555s
[2K
| Adam | epoch: 005 | loss: 0.02613 - acc: 0.9991 -- iter: 032/137
[A[ATraining Step: 22  | total loss: [1m[32m0.01931[0m[0m | time: 29.969s
[2K
| Adam | epoch: 005 | loss: 0.01931 - acc: 0.9993 -- iter: 064/137
[A[ATraining Step: 23  | total loss: [1m[32m0.02522[0m[0m | time: 33.340s
[2K
| Adam | epoch: 005 | loss: 0.02522 - acc: 0.9905 -- iter: 096/137
[A[ATraining Step: 24  | total loss: [1m[32m0.13010[0m[0m | time: 36.861s
[2K
| Adam | epoch: 005 | loss: 0.13010 - acc: 0.9306 -- iter: 128/137
[A[ATraining Step: 25  | total loss: [1m[32m0.11372[0m[0m | time: 48.995s
[2K
| Adam | epoch: 005 | loss: 0.11372 - acc: 0.9496 | val_loss: 3.05472 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 26  | total loss: [1m[32m0.08695[0m[0m | time: 9.438s
[2K
| Adam | epoch: 006 | loss: 0.08695 - acc: 0.9629 -- iter: 032/137
[A[ATraining Step: 27  | total loss: [1m[32m0.17236[0m[0m | time: 19.146s
[2K
| Adam | epoch: 006 | loss: 0.17236 - acc: 0.9403 -- iter: 064/137
[A[ATraining Step: 28  | total loss: [1m[32m0.18808[0m[0m | time: 28.809s
[2K
| Adam | epoch: 006 | loss: 0.18808 - acc: 0.9474 -- iter: 096/137
[A[ATraining Step: 29  | total loss: [1m[32m0.14291[0m[0m | time: 32.314s
[2K
| Adam | epoch: 006 | loss: 0.14291 - acc: 0.9602 -- iter: 128/137
[A[ATraining Step: 30  | total loss: [1m[32m0.25866[0m[0m | time: 37.832s
[2K
| Adam | epoch: 006 | loss: 0.25866 - acc: 0.9433 | val_loss: 3.38468 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 31  | total loss: [1m[32m0.20548[0m[0m | time: 9.287s
[2K
| Adam | epoch: 007 | loss: 0.20548 - acc: 0.9564 -- iter: 032/137
[A[ATraining Step: 32  | total loss: [1m[32m0.16881[0m[0m | time: 18.654s
[2K
| Adam | epoch: 007 | loss: 0.16881 - acc: 0.9662 -- iter: 064/137
[A[ATraining Step: 33  | total loss: [1m[32m0.21121[0m[0m | time: 28.247s
[2K
| Adam | epoch: 007 | loss: 0.21121 - acc: 0.9462 -- iter: 096/137
[A[ATraining Step: 34  | total loss: [1m[32m0.17585[0m[0m | time: 37.956s
[2K
| Adam | epoch: 007 | loss: 0.17585 - acc: 0.9510 -- iter: 128/137
[A[ATraining Step: 35  | total loss: [1m[32m0.14383[0m[0m | time: 43.545s
[2K
| Adam | epoch: 007 | loss: 0.14383 - acc: 0.9613 | val_loss: 3.50423 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 36  | total loss: [1m[32m0.11981[0m[0m | time: 3.291s
[2K
| Adam | epoch: 008 | loss: 0.11981 - acc: 0.9692 -- iter: 032/137
[A[ATraining Step: 37  | total loss: [1m[32m0.09701[0m[0m | time: 12.902s
[2K
| Adam | epoch: 008 | loss: 0.09701 - acc: 0.9754 -- iter: 064/137
[A[ATraining Step: 38  | total loss: [1m[32m0.08150[0m[0m | time: 23.641s
[2K
| Adam | epoch: 008 | loss: 0.08150 - acc: 0.9802 -- iter: 096/137
[A[ATraining Step: 39  | total loss: [1m[32m0.13911[0m[0m | time: 32.850s
[2K
| Adam | epoch: 008 | loss: 0.13911 - acc: 0.9541 -- iter: 128/137
[A[ATraining Step: 40  | total loss: [1m[32m0.22231[0m[0m | time: 44.785s
[2K
| Adam | epoch: 008 | loss: 0.22231 - acc: 0.9451 | val_loss: 3.18624 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 41  | total loss: [1m[32m0.18536[0m[0m | time: 3.476s
[2K
| Adam | epoch: 009 | loss: 0.18536 - acc: 0.9552 -- iter: 032/137
[A[ATraining Step: 42  | total loss: [1m[32m0.15537[0m[0m | time: 6.781s
[2K
| Adam | epoch: 009 | loss: 0.15537 - acc: 0.9632 -- iter: 064/137
[A[ATraining Step: 43  | total loss: [1m[32m0.13034[0m[0m | time: 16.319s
[2K
| Adam | epoch: 009 | loss: 0.13034 - acc: 0.9697 -- iter: 096/137
[A[ATraining Step: 44  | total loss: [1m[32m0.14247[0m[0m | time: 25.460s
[2K
| Adam | epoch: 009 | loss: 0.14247 - acc: 0.9642 -- iter: 128/137
[A[ATraining Step: 45  | total loss: [1m[32m0.17821[0m[0m | time: 37.010s
[2K
| Adam | epoch: 009 | loss: 0.17821 - acc: 0.9490 | val_loss: 3.11877 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 46  | total loss: [1m[32m0.18088[0m[0m | time: 9.668s
[2K
| Adam | epoch: 010 | loss: 0.18088 - acc: 0.9523 -- iter: 032/137
[A[ATraining Step: 47  | total loss: [1m[32m0.15269[0m[0m | time: 13.027s
[2K
| Adam | epoch: 010 | loss: 0.15269 - acc: 0.9601 -- iter: 064/137
[A[ATraining Step: 48  | total loss: [1m[32m0.14484[0m[0m | time: 16.243s
[2K
| Adam | epoch: 010 | loss: 0.14484 - acc: 0.9665 -- iter: 096/137
[A[ATraining Step: 49  | total loss: [1m[32m0.12542[0m[0m | time: 25.627s
[2K
| Adam | epoch: 010 | loss: 0.12542 - acc: 0.9718 -- iter: 128/137
[A[ATraining Step: 50  | total loss: [1m[32m0.11314[0m[0m | time: 37.069s
[2K
| Adam | epoch: 010 | loss: 0.11314 - acc: 0.9762 | val_loss: 2.12268 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 51  | total loss: [1m[32m0.09777[0m[0m | time: 9.416s
[2K
| Adam | epoch: 011 | loss: 0.09777 - acc: 0.9798 -- iter: 032/137
[A[ATraining Step: 52  | total loss: [1m[32m0.12198[0m[0m | time: 18.613s
[2K
| Adam | epoch: 011 | loss: 0.12198 - acc: 0.9735 -- iter: 064/137
[A[ATraining Step: 53  | total loss: [1m[32m0.12792[0m[0m | time: 21.901s
[2K
| Adam | epoch: 011 | loss: 0.12792 - acc: 0.9682 -- iter: 096/137
[A[ATraining Step: 54  | total loss: [1m[32m0.14231[0m[0m | time: 25.266s
[2K
| Adam | epoch: 011 | loss: 0.14231 - acc: 0.9567 -- iter: 128/137
[A[ATraining Step: 55  | total loss: [1m[32m0.13299[0m[0m | time: 36.963s
[2K
| Adam | epoch: 011 | loss: 0.13299 - acc: 0.9628 | val_loss: 2.16754 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 56  | total loss: [1m[32m0.11650[0m[0m | time: 9.390s
[2K
| Adam | epoch: 012 | loss: 0.11650 - acc: 0.9681 -- iter: 032/137
[A[ATraining Step: 57  | total loss: [1m[32m0.10244[0m[0m | time: 18.708s
[2K
| Adam | epoch: 012 | loss: 0.10244 - acc: 0.9725 -- iter: 064/137
[A[ATraining Step: 58  | total loss: [1m[32m0.11435[0m[0m | time: 28.171s
[2K
| Adam | epoch: 012 | loss: 0.11435 - acc: 0.9677 -- iter: 096/137
[A[ATraining Step: 59  | total loss: [1m[32m0.10127[0m[0m | time: 31.509s
[2K
| Adam | epoch: 012 | loss: 0.10127 - acc: 0.9721 -- iter: 128/137
[A[ATraining Step: 60  | total loss: [1m[32m0.10095[0m[0m | time: 37.050s
[2K
| Adam | epoch: 012 | loss: 0.10095 - acc: 0.9758 | val_loss: 2.30111 - val_acc: 0.5227 -- iter: 137/137
--
Training Step: 61  | total loss: [1m[32m0.09142[0m[0m | time: 9.523s
[2K
| Adam | epoch: 013 | loss: 0.09142 - acc: 0.9789 -- iter: 032/137
[A[ATraining Step: 62  | total loss: [1m[32m0.08127[0m[0m | time: 18.606s
[2K
| Adam | epoch: 013 | loss: 0.08127 - acc: 0.9816 -- iter: 064/137
[A[ATraining Step: 63  | total loss: [1m[32m0.08568[0m[0m | time: 27.907s
[2K
| Adam | epoch: 013 | loss: 0.08568 - acc: 0.9721 -- iter: 096/137
[A[ATraining Step: 64  | total loss: [1m[32m0.07712[0m[0m | time: 37.419s
[2K
| Adam | epoch: 013 | loss: 0.07712 - acc: 0.9756 -- iter: 128/137
[A[ATraining Step: 65  | total loss: [1m[32m0.07478[0m[0m | time: 43.032s
[2K
| Adam | epoch: 013 | loss: 0.07478 - acc: 0.9747 | val_loss: 1.70637 - val_acc: 0.5455 -- iter: 137/137
--
Training Step: 66  | total loss: [1m[32m0.06815[0m[0m | time: 3.330s
[2K
| Adam | epoch: 014 | loss: 0.06815 - acc: 0.9778 -- iter: 032/137
[A[ATraining Step: 67  | total loss: [1m[32m0.06044[0m[0m | time: 12.844s
[2K
| Adam | epoch: 014 | loss: 0.06044 - acc: 0.9805 -- iter: 064/137
[A[ATraining Step: 68  | total loss: [1m[32m0.05791[0m[0m | time: 22.174s
[2K
| Adam | epoch: 014 | loss: 0.05791 - acc: 0.9828 -- iter: 096/137
[A[ATraining Step: 69  | total loss: [1m[32m0.06851[0m[0m | time: 31.390s
[2K
| Adam | epoch: 014 | loss: 0.06851 - acc: 0.9811 -- iter: 128/137
[A[ATraining Step: 70  | total loss: [1m[32m0.07590[0m[0m | time: 49.710s
[2K
| Adam | epoch: 014 | loss: 0.07590 - acc: 0.9761 | val_loss: 0.26040 - val_acc: 0.9318 -- iter: 137/137
--
Training Step: 71  | total loss: [1m[32m0.07158[0m[0m | time: 3.240s
[2K
| Adam | epoch: 015 | loss: 0.07158 - acc: 0.9788 -- iter: 032/137
[A[ATraining Step: 72  | total loss: [1m[32m0.06769[0m[0m | time: 6.471s
[2K
| Adam | epoch: 015 | loss: 0.06769 - acc: 0.9812 -- iter: 064/137
[A[ATraining Step: 73  | total loss: [1m[32m0.06211[0m[0m | time: 15.802s
[2K
| Adam | epoch: 015 | loss: 0.06211 - acc: 0.9833 -- iter: 096/137
[A[ATraining Step: 74  | total loss: [1m[32m0.05793[0m[0m | time: 25.271s
[2K
| Adam | epoch: 015 | loss: 0.05793 - acc: 0.9851 -- iter: 128/137
[A[ATraining Step: 75  | total loss: [1m[32m0.05442[0m[0m | time: 36.578s
[2K
| Adam | epoch: 015 | loss: 0.05442 - acc: 0.9867 | val_loss: 0.55799 - val_acc: 0.7955 -- iter: 137/137
--
Training Step: 76  | total loss: [1m[32m0.04977[0m[0m | time: 9.465s
[2K
| Adam | epoch: 016 | loss: 0.04977 - acc: 0.9882 -- iter: 032/137
[A[ATraining Step: 77  | total loss: [1m[32m0.04827[0m[0m | time: 12.729s
[2K
| Adam | epoch: 016 | loss: 0.04827 - acc: 0.9894 -- iter: 064/137
[A[ATraining Step: 78  | total loss: [1m[32m0.04340[0m[0m | time: 16.120s
[2K
| Adam | epoch: 016 | loss: 0.04340 - acc: 0.9905 -- iter: 096/137
[A[ATraining Step: 79  | total loss: [1m[32m0.03904[0m[0m | time: 25.478s
[2K
| Adam | epoch: 016 | loss: 0.03904 - acc: 0.9915 -- iter: 128/137
[A[ATraining Step: 80  | total loss: [1m[32m0.03568[0m[0m | time: 37.271s
[2K
| Adam | epoch: 016 | loss: 0.03568 - acc: 0.9924 | val_loss: 0.99151 - val_acc: 0.7273 -- iter: 137/137
--
Training Step: 81  | total loss: [1m[32m0.03383[0m[0m | time: 9.066s
[2K
| Adam | epoch: 017 | loss: 0.03383 - acc: 0.9931 -- iter: 032/137
[A[ATraining Step: 82  | total loss: [1m[32m0.05555[0m[0m | time: 18.260s
[2K
| Adam | epoch: 017 | loss: 0.05555 - acc: 0.9907 -- iter: 064/137
[A[ATraining Step: 83  | total loss: [1m[32m0.05054[0m[0m | time: 21.504s
[2K
| Adam | epoch: 017 | loss: 0.05054 - acc: 0.9916 -- iter: 096/137
[A[ATraining Step: 84  | total loss: [1m[32m0.11001[0m[0m | time: 24.802s
[2K
| Adam | epoch: 017 | loss: 0.11001 - acc: 0.9591 -- iter: 128/137
[A[ATraining Step: 85  | total loss: [1m[32m0.11859[0m[0m | time: 36.340s
[2K
| Adam | epoch: 017 | loss: 0.11859 - acc: 0.9632 | val_loss: 0.67695 - val_acc: 0.8636 -- iter: 137/137
--
Training Step: 86  | total loss: [1m[32m0.10732[0m[0m | time: 9.408s
[2K
| Adam | epoch: 018 | loss: 0.10732 - acc: 0.9669 -- iter: 032/137
[A[ATraining Step: 87  | total loss: [1m[32m0.11140[0m[0m | time: 18.632s
[2K
| Adam | epoch: 018 | loss: 0.11140 - acc: 0.9608 -- iter: 064/137
[A[ATraining Step: 88  | total loss: [1m[32m0.11740[0m[0m | time: 28.023s
[2K
| Adam | epoch: 018 | loss: 0.11740 - acc: 0.9616 -- iter: 096/137
[A[ATraining Step: 89  | total loss: [1m[32m0.10701[0m[0m | time: 31.294s
[2K
| Adam | epoch: 018 | loss: 0.10701 - acc: 0.9655 -- iter: 128/137
[A[ATraining Step: 90  | total loss: [1m[32m0.09868[0m[0m | time: 36.714s
[2K
| Adam | epoch: 018 | loss: 0.09868 - acc: 0.9689 | val_loss: 0.46378 - val_acc: 0.8409 -- iter: 137/137
--
Training Step: 91  | total loss: [1m[32m0.08913[0m[0m | time: 9.114s
[2K
| Adam | epoch: 019 | loss: 0.08913 - acc: 0.9720 -- iter: 032/137
[A[ATraining Step: 92  | total loss: [1m[32m0.08074[0m[0m | time: 18.263s
[2K
| Adam | epoch: 019 | loss: 0.08074 - acc: 0.9748 -- iter: 064/137
[A[ATraining Step: 93  | total loss: [1m[32m0.08309[0m[0m | time: 27.556s
[2K
| Adam | epoch: 019 | loss: 0.08309 - acc: 0.9742 -- iter: 096/137
[A[ATraining Step: 94  | total loss: [1m[32m0.07524[0m[0m | time: 36.888s
[2K
| Adam | epoch: 019 | loss: 0.07524 - acc: 0.9768 -- iter: 128/137
[A[ATraining Step: 95  | total loss: [1m[32m0.07017[0m[0m | time: 42.388s
[2K
| Adam | epoch: 019 | loss: 0.07017 - acc: 0.9791 | val_loss: 1.04309 - val_acc: 0.7727 -- iter: 137/137
--
Training Step: 96  | total loss: [1m[32m0.10048[0m[0m | time: 3.247s
[2K
| Adam | epoch: 020 | loss: 0.10048 - acc: 0.9701 -- iter: 032/137
[A[ATraining Step: 97  | total loss: [1m[32m0.09551[0m[0m | time: 12.500s
[2K
| Adam | epoch: 020 | loss: 0.09551 - acc: 0.9731 -- iter: 064/137
[A[ATraining Step: 98  | total loss: [1m[32m0.09059[0m[0m | time: 21.604s
[2K
| Adam | epoch: 020 | loss: 0.09059 - acc: 0.9726 -- iter: 096/137
[A[ATraining Step: 99  | total loss: [1m[32m0.12202[0m[0m | time: 30.794s
[2K
| Adam | epoch: 020 | loss: 0.12202 - acc: 0.9629 -- iter: 128/137
[A[ATraining Step: 100  | total loss: [1m[32m0.11043[0m[0m | time: 42.168s
[2K
| Adam | epoch: 020 | loss: 0.11043 - acc: 0.9666 | val_loss: 1.05228 - val_acc: 0.8864 -- iter: 137/137
--
Training Step: 101  | total loss: [1m[32m0.11176[0m[0m | time: 3.223s
[2K
| Adam | epoch: 021 | loss: 0.11176 - acc: 0.9668 -- iter: 032/137
[A[ATraining Step: 102  | total loss: [1m[32m0.10104[0m[0m | time: 6.403s
[2K
| Adam | epoch: 021 | loss: 0.10104 - acc: 0.9701 -- iter: 064/137
[A[ATraining Step: 103  | total loss: [1m[32m0.09126[0m[0m | time: 15.740s
[2K
| Adam | epoch: 021 | loss: 0.09126 - acc: 0.9731 -- iter: 096/137
[A[ATraining Step: 104  | total loss: [1m[32m0.08744[0m[0m | time: 24.950s
[2K
| Adam | epoch: 021 | loss: 0.08744 - acc: 0.9727 -- iter: 128/137
[A[ATraining Step: 105  | total loss: [1m[32m0.07991[0m[0m | time: 36.279s
[2K
| Adam | epoch: 021 | loss: 0.07991 - acc: 0.9754 | val_loss: 0.99506 - val_acc: 0.8864 -- iter: 137/137
--
Training Step: 106  | total loss: [1m[32m0.10276[0m[0m | time: 9.229s
[2K
| Adam | epoch: 022 | loss: 0.10276 - acc: 0.9716 -- iter: 032/137
[A[ATraining Step: 107  | total loss: [1m[32m0.09332[0m[0m | time: 12.454s
[2K
| Adam | epoch: 022 | loss: 0.09332 - acc: 0.9745 -- iter: 064/137
[A[ATraining Step: 108  | total loss: [1m[32m0.10327[0m[0m | time: 15.799s
[2K
| Adam | epoch: 022 | loss: 0.10327 - acc: 0.9659 -- iter: 096/137
[A[ATraining Step: 109  | total loss: [1m[32m0.09622[0m[0m | time: 24.904s
[2K
| Adam | epoch: 022 | loss: 0.09622 - acc: 0.9693 -- iter: 128/137
[A[ATraining Step: 110  | total loss: [1m[32m0.08764[0m[0m | time: 36.506s
[2K
| Adam | epoch: 022 | loss: 0.08764 - acc: 0.9724 | val_loss: 0.44395 - val_acc: 0.7955 -- iter: 137/137
--
Training Step: 111  | total loss: [1m[32m0.08116[0m[0m | time: 9.634s
[2K
| Adam | epoch: 023 | loss: 0.08116 - acc: 0.9751 -- iter: 032/137
[A[ATraining Step: 112  | total loss: [1m[32m0.10255[0m[0m | time: 18.768s
[2K
| Adam | epoch: 023 | loss: 0.10255 - acc: 0.9714 -- iter: 064/137
[A[ATraining Step: 113  | total loss: [1m[32m0.09472[0m[0m | time: 21.968s
[2K
| Adam | epoch: 023 | loss: 0.09472 - acc: 0.9742 -- iter: 096/137
[A[ATraining Step: 114  | total loss: [1m[32m0.08958[0m[0m | time: 25.130s
[2K
| Adam | epoch: 023 | loss: 0.08958 - acc: 0.9768 -- iter: 128/137
[A[ATraining Step: 115  | total loss: [1m[32m0.08302[0m[0m | time: 36.453s
[2K
| Adam | epoch: 023 | loss: 0.08302 - acc: 0.9791 | val_loss: 0.56841 - val_acc: 0.8409 -- iter: 137/137
--
Training Step: 116  | total loss: [1m[32m0.10928[0m[0m | time: 8.876s
[2K
| Adam | epoch: 024 | loss: 0.10928 - acc: 0.9656 -- iter: 032/137
[A[ATraining Step: 117  | total loss: [1m[32m0.12494[0m[0m | time: 17.941s
[2K
| Adam | epoch: 024 | loss: 0.12494 - acc: 0.9534 -- iter: 064/137
[A[ATraining Step: 118  | total loss: [1m[32m0.13352[0m[0m | time: 26.867s
[2K
| Adam | epoch: 024 | loss: 0.13352 - acc: 0.9518 -- iter: 096/137
[A[ATraining Step: 119  | total loss: [1m[32m0.12568[0m[0m | time: 30.128s
[2K
| Adam | epoch: 024 | loss: 0.12568 - acc: 0.9566 -- iter: 128/137
[A[ATraining Step: 120  | total loss: [1m[32m0.11357[0m[0m | time: 35.440s
[2K
| Adam | epoch: 024 | loss: 0.11357 - acc: 0.9610 | val_loss: 0.24490 - val_acc: 0.9545 -- iter: 137/137
--
Training Step: 121  | total loss: [1m[32m0.10273[0m[0m | time: 9.144s
[2K
| Adam | epoch: 025 | loss: 0.10273 - acc: 0.9649 -- iter: 032/137
[A[ATraining Step: 122  | total loss: [1m[32m0.09435[0m[0m | time: 18.253s
[2K
| Adam | epoch: 025 | loss: 0.09435 - acc: 0.9684 -- iter: 064/137
[A[ATraining Step: 123  | total loss: [1m[32m0.10086[0m[0m | time: 27.329s
[2K
| Adam | epoch: 025 | loss: 0.10086 - acc: 0.9684 -- iter: 096/137
[A[ATraining Step: 124  | total loss: [1m[32m0.14172[0m[0m | time: 36.740s
[2K
| Adam | epoch: 025 | loss: 0.14172 - acc: 0.9653 -- iter: 128/137
[A[ATraining Step: 125  | total loss: [1m[32m0.12880[0m[0m | time: 42.170s
[2K
| Adam | epoch: 025 | loss: 0.12880 - acc: 0.9688 | val_loss: 0.75272 - val_acc: 0.7045 -- iter: 137/137
--
Training Step: 126  | total loss: [1m[32m0.12425[0m[0m | time: 3.203s
[2K
| Adam | epoch: 026 | loss: 0.12425 - acc: 0.9719 -- iter: 032/137
[A[ATraining Step: 127  | total loss: [1m[32m0.11464[0m[0m | time: 12.199s
[2K
| Adam | epoch: 026 | loss: 0.11464 - acc: 0.9747 -- iter: 064/137
[A[ATraining Step: 128  | total loss: [1m[32m0.10752[0m[0m | time: 21.366s
[2K
| Adam | epoch: 026 | loss: 0.10752 - acc: 0.9773 -- iter: 096/137
[A[ATraining Step: 129  | total loss: [1m[32m0.10014[0m[0m | time: 30.797s
[2K
| Adam | epoch: 026 | loss: 0.10014 - acc: 0.9795 -- iter: 128/137
[A[ATraining Step: 130  | total loss: [1m[32m0.10912[0m[0m | time: 41.913s
[2K
| Adam | epoch: 026 | loss: 0.10912 - acc: 0.9785 | val_loss: 0.83519 - val_acc: 0.7500 -- iter: 137/137
--
Training Step: 131  | total loss: [1m[32m0.10083[0m[0m | time: 3.279s
[2K
| Adam | epoch: 027 | loss: 0.10083 - acc: 0.9806 -- iter: 032/137
[A[ATraining Step: 132  | total loss: [1m[32m0.09104[0m[0m | time: 6.517s
[2K
| Adam | epoch: 027 | loss: 0.09104 - acc: 0.9825 -- iter: 064/137
[A[ATraining Step: 133  | total loss: [1m[32m0.08232[0m[0m | time: 15.702s
[2K
| Adam | epoch: 027 | loss: 0.08232 - acc: 0.9843 -- iter: 096/137
[A[ATraining Step: 134  | total loss: [1m[32m0.08806[0m[0m | time: 24.590s
[2K
| Adam | epoch: 027 | loss: 0.08806 - acc: 0.9827 -- iter: 128/137
[A[ATraining Step: 135  | total loss: [1m[32m0.08117[0m[0m | time: 35.619s
[2K
| Adam | epoch: 027 | loss: 0.08117 - acc: 0.9845 | val_loss: 0.58251 - val_acc: 0.7955 -- iter: 137/137
--
Training Step: 136  | total loss: [1m[32m0.08025[0m[0m | time: 9.340s
[2K
| Adam | epoch: 028 | loss: 0.08025 - acc: 0.9829 -- iter: 032/137
[A[ATraining Step: 137  | total loss: [1m[32m0.07277[0m[0m | time: 12.504s
[2K
| Adam | epoch: 028 | loss: 0.07277 - acc: 0.9846 -- iter: 064/137
[A[ATraining Step: 138  | total loss: [1m[32m0.06648[0m[0m | time: 15.759s
[2K
| Adam | epoch: 028 | loss: 0.06648 - acc: 0.9861 -- iter: 096/137
[A[ATraining Step: 139  | total loss: [1m[32m0.06072[0m[0m | time: 24.965s
[2K
| Adam | epoch: 028 | loss: 0.06072 - acc: 0.9875 -- iter: 128/137
[A[ATraining Step: 140  | total loss: [1m[32m0.05665[0m[0m | time: 36.301s
[2K
| Adam | epoch: 028 | loss: 0.05665 - acc: 0.9888 | val_loss: 0.25590 - val_acc: 0.9545 -- iter: 137/137
--
Training Step: 141  | total loss: [1m[32m0.06470[0m[0m | time: 9.114s
[2K
| Adam | epoch: 029 | loss: 0.06470 - acc: 0.9836 -- iter: 032/137
[A[ATraining Step: 142  | total loss: [1m[32m0.07049[0m[0m | time: 18.365s
[2K
| Adam | epoch: 029 | loss: 0.07049 - acc: 0.9790 -- iter: 064/137
[A[ATraining Step: 143  | total loss: [1m[32m0.06515[0m[0m | time: 21.532s
[2K
| Adam | epoch: 029 | loss: 0.06515 - acc: 0.9811 -- iter: 096/137
[A[ATraining Step: 144  | total loss: [1m[32m0.06571[0m[0m | time: 24.733s
[2K
| Adam | epoch: 029 | loss: 0.06571 - acc: 0.9830 -- iter: 128/137
[A[ATraining Step: 145  | total loss: [1m[32m0.05999[0m[0m | time: 35.951s
[2K
| Adam | epoch: 029 | loss: 0.05999 - acc: 0.9847 | val_loss: 0.26125 - val_acc: 0.9318 -- iter: 137/137
--
Training Step: 146  | total loss: [1m[32m0.05674[0m[0m | time: 9.091s
[2K
| Adam | epoch: 030 | loss: 0.05674 - acc: 0.9862 -- iter: 032/137
[A[ATraining Step: 147  | total loss: [1m[32m0.05144[0m[0m | time: 18.048s
[2K
| Adam | epoch: 030 | loss: 0.05144 - acc: 0.9876 -- iter: 064/137
[A[ATraining Step: 148  | total loss: [1m[32m0.04655[0m[0m | time: 26.916s
[2K
| Adam | epoch: 030 | loss: 0.04655 - acc: 0.9889 -- iter: 096/137
[A[ATraining Step: 149  | total loss: [1m[32m0.04265[0m[0m | time: 30.164s
[2K
| Adam | epoch: 030 | loss: 0.04265 - acc: 0.9900 -- iter: 128/137
[A[ATraining Step: 150  | total loss: [1m[32m0.03885[0m[0m | time: 35.568s
[2K
| Adam | epoch: 030 | loss: 0.03885 - acc: 0.9910 | val_loss: 0.21324 - val_acc: 0.9773 -- iter: 137/137
--
Validation AUC:0.9627329192546583
Validation AUPRC:0.9780219780219783
Test AUC:0.9935897435897435
Test AUPRC:0.9957734573119188
BestTestF1Score	0.94	0.87	0.93	1.0	0.88	23	0	18	3	0.56
BestTestMCCScore	0.94	0.87	0.93	1.0	0.88	23	0	18	3	0.56
BestTestAccuracyScore	0.94	0.87	0.93	1.0	0.88	23	0	18	3	0.56
BestValidationF1Score	0.98	0.96	0.98	1.0	0.95	20	0	23	1	0.56
BestValidationMCC	0.98	0.96	0.98	1.0	0.95	20	0	23	1	0.56
BestValidationAccuracy	0.98	0.96	0.98	1.0	0.95	20	0	23	1	0.56
TestPredictions (Threshold:0.56)
CHEMBL486176,TN,INACT,0.019999999552965164	CHEMBL378553,TP,ACT,0.949999988079071	CHEMBL2011541,TN,INACT,0.05999999865889549	CHEMBL424636,TP,ACT,1.0	CHEMBL111983,TP,ACT,1.0	CHEMBL92284,TP,ACT,1.0	CHEMBL111217,TP,ACT,1.0	CHEMBL162827,TP,ACT,1.0	CHEMBL377178,TP,ACT,0.6299999952316284	CHEMBL2403499,TN,INACT,0.009999999776482582	CHEMBL705,FN,ACT,0.25	CHEMBL237611,TN,INACT,0.0	CHEMBL162334,TP,ACT,1.0	CHEMBL2204698,TN,INACT,0.0	CHEMBL235113,TN,INACT,0.0	CHEMBL164557,TP,ACT,1.0	CHEMBL518700,TN,INACT,0.4300000071525574	CHEMBL166244,TP,ACT,0.9900000095367432	CHEMBL111911,TP,ACT,1.0	CHEMBL166201,TP,ACT,1.0	CHEMBL3397548,TN,INACT,0.0	CHEMBL118268,TP,ACT,1.0	CHEMBL89331,TP,ACT,0.949999988079071	CHEMBL371320,TN,INACT,0.0	CHEMBL96184,TP,ACT,1.0	CHEMBL118693,TP,ACT,1.0	CHEMBL308883,TP,ACT,1.0	CHEMBL3397549,TN,INACT,0.0	CHEMBL41260,TP,ACT,1.0	CHEMBL38,FN,ACT,0.4300000071525574	CHEMBL2110180,TP,ACT,1.0	CHEMBL487611,TN,INACT,0.029999999329447746	CHEMBL672,TN,INACT,0.009999999776482582	CHEMBL157333,FN,ACT,0.07000000029802322	CHEMBL111589,TP,ACT,0.9900000095367432	CHEMBL101308,TP,ACT,1.0	CHEMBL32505,TP,ACT,0.9399999976158142	CHEMBL1956358,TN,INACT,0.11999999731779099	CHEMBL2204687,TN,INACT,0.009999999776482582	CHEMBL2348891,TN,INACT,0.0	CHEMBL83953,TN,INACT,0.029999999329447746	CHEMBL484264,TN,INACT,0.009999999776482582	CHEMBL205894,TP,ACT,0.5600000023841858	CHEMBL234659,TN,INACT,0.0	

