ImageNetInceptionV2 CHEMBL1901 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	369
Number of inactive compounds :	369
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1901_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1901_adam_0.001_15_0.8/
---------------------------------
Training samples: 457
Validation samples: 144
--
Training Step: 1  | time: 248.925s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/457
[A[ATraining Step: 2  | total loss: [1m[32m0.72596[0m[0m | time: 345.076s
[2K
| Adam | epoch: 001 | loss: 0.72596 - acc: 0.4219 -- iter: 064/457
[A[ATraining Step: 3  | total loss: [1m[32m0.68925[0m[0m | time: 470.675s
[2K
| Adam | epoch: 001 | loss: 0.68925 - acc: 0.7159 -- iter: 096/457
[A[ATraining Step: 4  | total loss: [1m[32m0.64318[0m[0m | time: 544.830s
[2K
| Adam | epoch: 001 | loss: 0.64318 - acc: 0.7415 -- iter: 128/457
[A[ATraining Step: 5  | total loss: [1m[32m0.32227[0m[0m | time: 571.012s
[2K
| Adam | epoch: 001 | loss: 0.32227 - acc: 0.8772 -- iter: 160/457
[A[ATraining Step: 6  | total loss: [1m[32m0.28968[0m[0m | time: 600.822s
[2K
| Adam | epoch: 001 | loss: 0.28968 - acc: 0.8959 -- iter: 192/457
[A[ATraining Step: 7  | total loss: [1m[32m0.74833[0m[0m | time: 633.173s
[2K
| Adam | epoch: 001 | loss: 0.74833 - acc: 0.7333 -- iter: 224/457
[A[ATraining Step: 8  | total loss: [1m[32m0.52889[0m[0m | time: 664.162s
[2K
| Adam | epoch: 001 | loss: 0.52889 - acc: 0.8130 -- iter: 256/457
[A[ATraining Step: 9  | total loss: [1m[32m0.40252[0m[0m | time: 732.865s
[2K
| Adam | epoch: 001 | loss: 0.40252 - acc: 0.8624 -- iter: 288/457
[A[ATraining Step: 10  | total loss: [1m[32m0.33938[0m[0m | time: 886.902s
[2K
| Adam | epoch: 001 | loss: 0.33938 - acc: 0.8687 -- iter: 320/457
[A[ATraining Step: 11  | total loss: [1m[32m0.28891[0m[0m | time: 930.574s
[2K
| Adam | epoch: 001 | loss: 0.28891 - acc: 0.8717 -- iter: 352/457
[A[ATraining Step: 12  | total loss: [1m[32m0.32070[0m[0m | time: 955.188s
[2K
| Adam | epoch: 001 | loss: 0.32070 - acc: 0.8872 -- iter: 384/457
[A[ATraining Step: 13  | total loss: [1m[32m0.29983[0m[0m | time: 966.997s
[2K
| Adam | epoch: 001 | loss: 0.29983 - acc: 0.8820 -- iter: 416/457
[A[ATraining Step: 14  | total loss: [1m[32m0.23550[0m[0m | time: 976.220s
[2K
| Adam | epoch: 001 | loss: 0.23550 - acc: 0.9175 -- iter: 448/457
[A[ATraining Step: 15  | total loss: [1m[32m0.27985[0m[0m | time: 1001.601s
[2K
| Adam | epoch: 001 | loss: 0.27985 - acc: 0.9009 | val_loss: 1.88544 - val_acc: 0.6042 -- iter: 457/457
--
Training Step: 16  | total loss: [1m[32m0.48184[0m[0m | time: 3.023s
[2K
| Adam | epoch: 002 | loss: 0.48184 - acc: 0.8964 -- iter: 032/457
[A[ATraining Step: 17  | total loss: [1m[32m0.36800[0m[0m | time: 12.096s
[2K
| Adam | epoch: 002 | loss: 0.36800 - acc: 0.9337 -- iter: 064/457
[A[ATraining Step: 18  | total loss: [1m[32m0.31677[0m[0m | time: 20.887s
[2K
| Adam | epoch: 002 | loss: 0.31677 - acc: 0.9350 -- iter: 096/457
[A[ATraining Step: 19  | total loss: [1m[32m0.27974[0m[0m | time: 90.822s
[2K
| Adam | epoch: 002 | loss: 0.27974 - acc: 0.9358 -- iter: 128/457
[A[ATraining Step: 20  | total loss: [1m[32m0.26490[0m[0m | time: 133.499s
[2K
| Adam | epoch: 002 | loss: 0.26490 - acc: 0.9263 -- iter: 160/457
[A[ATraining Step: 21  | total loss: [1m[32m0.28732[0m[0m | time: 203.502s
[2K
| Adam | epoch: 002 | loss: 0.28732 - acc: 0.9201 -- iter: 192/457
[A[ATraining Step: 22  | total loss: [1m[32m0.23641[0m[0m | time: 216.040s
[2K
| Adam | epoch: 002 | loss: 0.23641 - acc: 0.9253 -- iter: 224/457
[A[ATraining Step: 23  | total loss: [1m[32m0.20077[0m[0m | time: 231.440s
[2K
| Adam | epoch: 002 | loss: 0.20077 - acc: 0.9379 -- iter: 256/457
[A[ATraining Step: 24  | total loss: [1m[32m0.23590[0m[0m | time: 244.069s
[2K
| Adam | epoch: 002 | loss: 0.23590 - acc: 0.9290 -- iter: 288/457
[A[ATraining Step: 25  | total loss: [1m[32m0.24044[0m[0m | time: 253.089s
[2K
| Adam | epoch: 002 | loss: 0.24044 - acc: 0.9313 -- iter: 320/457
[A[ATraining Step: 26  | total loss: [1m[32m0.25521[0m[0m | time: 261.907s
[2K
| Adam | epoch: 002 | loss: 0.25521 - acc: 0.9247 -- iter: 352/457
[A[ATraining Step: 27  | total loss: [1m[32m0.21721[0m[0m | time: 272.509s
[2K
| Adam | epoch: 002 | loss: 0.21721 - acc: 0.9360 -- iter: 384/457
[A[ATraining Step: 28  | total loss: [1m[32m0.20710[0m[0m | time: 285.927s
[2K
| Adam | epoch: 002 | loss: 0.20710 - acc: 0.9364 -- iter: 416/457
[A[ATraining Step: 29  | total loss: [1m[32m0.21468[0m[0m | time: 298.998s
[2K
| Adam | epoch: 002 | loss: 0.21468 - acc: 0.9367 -- iter: 448/457
[A[ATraining Step: 30  | total loss: [1m[32m0.22295[0m[0m | time: 322.903s
[2K
| Adam | epoch: 002 | loss: 0.22295 - acc: 0.9369 | val_loss: 3.40506 - val_acc: 0.6042 -- iter: 457/457
--
Training Step: 31  | total loss: [1m[32m0.24938[0m[0m | time: 2.984s
[2K
| Adam | epoch: 003 | loss: 0.24938 - acc: 0.9226 -- iter: 032/457
[A[ATraining Step: 32  | total loss: [1m[32m0.20850[0m[0m | time: 6.004s
[2K
| Adam | epoch: 003 | loss: 0.20850 - acc: 0.9400 -- iter: 064/457
[A[ATraining Step: 33  | total loss: [1m[32m0.17870[0m[0m | time: 14.798s
[2K
| Adam | epoch: 003 | loss: 0.17870 - acc: 0.9532 -- iter: 096/457
[A[ATraining Step: 34  | total loss: [1m[32m0.17979[0m[0m | time: 26.191s
[2K
| Adam | epoch: 003 | loss: 0.17979 - acc: 0.9498 -- iter: 128/457
[A[ATraining Step: 35  | total loss: [1m[32m0.18999[0m[0m | time: 39.154s
[2K
| Adam | epoch: 003 | loss: 0.18999 - acc: 0.9407 -- iter: 160/457
[A[ATraining Step: 36  | total loss: [1m[32m0.18775[0m[0m | time: 52.141s
[2K
| Adam | epoch: 003 | loss: 0.18775 - acc: 0.9400 -- iter: 192/457
[A[ATraining Step: 37  | total loss: [1m[32m0.16403[0m[0m | time: 65.537s
[2K
| Adam | epoch: 003 | loss: 0.16403 - acc: 0.9520 -- iter: 224/457
[A[ATraining Step: 38  | total loss: [1m[32m0.14267[0m[0m | time: 78.311s
[2K
| Adam | epoch: 003 | loss: 0.14267 - acc: 0.9553 -- iter: 256/457
[A[ATraining Step: 39  | total loss: [1m[32m0.13524[0m[0m | time: 90.607s
[2K
| Adam | epoch: 003 | loss: 0.13524 - acc: 0.9579 -- iter: 288/457
[A[ATraining Step: 40  | total loss: [1m[32m0.16684[0m[0m | time: 102.389s
[2K
| Adam | epoch: 003 | loss: 0.16684 - acc: 0.9482 -- iter: 320/457
[A[ATraining Step: 41  | total loss: [1m[32m0.15008[0m[0m | time: 110.931s
[2K
| Adam | epoch: 003 | loss: 0.15008 - acc: 0.9577 -- iter: 352/457
[A[ATraining Step: 42  | total loss: [1m[32m0.15198[0m[0m | time: 119.356s
[2K
| Adam | epoch: 003 | loss: 0.15198 - acc: 0.9484 -- iter: 384/457
[A[ATraining Step: 43  | total loss: [1m[32m0.13411[0m[0m | time: 128.815s
[2K
| Adam | epoch: 003 | loss: 0.13411 - acc: 0.9575 -- iter: 416/457
[A[ATraining Step: 44  | total loss: [1m[32m0.11739[0m[0m | time: 141.290s
[2K
| Adam | epoch: 003 | loss: 0.11739 - acc: 0.9649 -- iter: 448/457
[A[ATraining Step: 45  | total loss: [1m[32m0.12761[0m[0m | time: 164.790s
[2K
| Adam | epoch: 003 | loss: 0.12761 - acc: 0.9496 | val_loss: 2.82368 - val_acc: 0.6042 -- iter: 457/457
--
Training Step: 46  | total loss: [1m[32m0.12513[0m[0m | time: 11.213s
[2K
| Adam | epoch: 004 | loss: 0.12513 - acc: 0.9528 -- iter: 032/457
[A[ATraining Step: 47  | total loss: [1m[32m0.11790[0m[0m | time: 14.181s
[2K
| Adam | epoch: 004 | loss: 0.11790 - acc: 0.9605 -- iter: 064/457
[A[ATraining Step: 48  | total loss: [1m[32m0.22601[0m[0m | time: 17.165s
[2K
| Adam | epoch: 004 | loss: 0.22601 - acc: 0.9312 -- iter: 096/457
[A[ATraining Step: 49  | total loss: [1m[32m0.19808[0m[0m | time: 25.876s
[2K
| Adam | epoch: 004 | loss: 0.19808 - acc: 0.9420 -- iter: 128/457
[A[ATraining Step: 50  | total loss: [1m[32m0.21666[0m[0m | time: 36.001s
[2K
| Adam | epoch: 004 | loss: 0.21666 - acc: 0.9268 -- iter: 160/457
[A[ATraining Step: 51  | total loss: [1m[32m0.20721[0m[0m | time: 47.895s
[2K
| Adam | epoch: 004 | loss: 0.20721 - acc: 0.9284 -- iter: 192/457
[A[ATraining Step: 52  | total loss: [1m[32m0.20476[0m[0m | time: 82.177s
[2K
| Adam | epoch: 004 | loss: 0.20476 - acc: 0.9345 -- iter: 224/457
[A[ATraining Step: 53  | total loss: [1m[32m0.17891[0m[0m | time: 95.110s
[2K
| Adam | epoch: 004 | loss: 0.17891 - acc: 0.9441 -- iter: 256/457
[A[ATraining Step: 54  | total loss: [1m[32m0.16377[0m[0m | time: 108.276s
[2K
| Adam | epoch: 004 | loss: 0.16377 - acc: 0.9522 -- iter: 288/457
[A[ATraining Step: 55  | total loss: [1m[32m0.15123[0m[0m | time: 121.171s
[2K
| Adam | epoch: 004 | loss: 0.15123 - acc: 0.9546 -- iter: 320/457
[A[ATraining Step: 56  | total loss: [1m[32m0.13969[0m[0m | time: 132.604s
[2K
| Adam | epoch: 004 | loss: 0.13969 - acc: 0.9610 -- iter: 352/457
[A[ATraining Step: 57  | total loss: [1m[32m0.13338[0m[0m | time: 140.896s
[2K
| Adam | epoch: 004 | loss: 0.13338 - acc: 0.9621 -- iter: 384/457
[A[ATraining Step: 58  | total loss: [1m[32m0.14605[0m[0m | time: 149.431s
[2K
| Adam | epoch: 004 | loss: 0.14605 - acc: 0.9545 -- iter: 416/457
[A[ATraining Step: 59  | total loss: [1m[32m0.14060[0m[0m | time: 162.923s
[2K
| Adam | epoch: 004 | loss: 0.14060 - acc: 0.9564 -- iter: 448/457
[A[ATraining Step: 60  | total loss: [1m[32m0.12872[0m[0m | time: 185.131s
[2K
| Adam | epoch: 004 | loss: 0.12872 - acc: 0.9621 | val_loss: 0.35029 - val_acc: 0.8611 -- iter: 457/457
--
Training Step: 61  | total loss: [1m[32m0.11476[0m[0m | time: 8.726s
[2K
| Adam | epoch: 005 | loss: 0.11476 - acc: 0.9671 -- iter: 032/457
[A[ATraining Step: 62  | total loss: [1m[32m0.10506[0m[0m | time: 17.721s
[2K
| Adam | epoch: 005 | loss: 0.10506 - acc: 0.9713 -- iter: 064/457
[A[ATraining Step: 63  | total loss: [1m[32m0.09683[0m[0m | time: 22.565s
[2K
| Adam | epoch: 005 | loss: 0.09683 - acc: 0.9750 -- iter: 096/457
[A[ATraining Step: 64  | total loss: [1m[32m0.09125[0m[0m | time: 27.250s
[2K
| Adam | epoch: 005 | loss: 0.09125 - acc: 0.9781 -- iter: 128/457
[A[ATraining Step: 65  | total loss: [1m[32m0.15834[0m[0m | time: 47.500s
[2K
| Adam | epoch: 005 | loss: 0.15834 - acc: 0.9671 -- iter: 160/457
[A[ATraining Step: 66  | total loss: [1m[32m0.16567[0m[0m | time: 59.455s
[2K
| Adam | epoch: 005 | loss: 0.16567 - acc: 0.9597 -- iter: 192/457
[A[ATraining Step: 67  | total loss: [1m[32m0.15458[0m[0m | time: 71.550s
[2K
| Adam | epoch: 005 | loss: 0.15458 - acc: 0.9608 -- iter: 224/457
[A[ATraining Step: 68  | total loss: [1m[32m0.15145[0m[0m | time: 84.193s
[2K
| Adam | epoch: 005 | loss: 0.15145 - acc: 0.9617 -- iter: 256/457
[A[ATraining Step: 69  | total loss: [1m[32m0.14523[0m[0m | time: 96.924s
[2K
| Adam | epoch: 005 | loss: 0.14523 - acc: 0.9625 -- iter: 288/457
[A[ATraining Step: 70  | total loss: [1m[32m0.14030[0m[0m | time: 105.416s
[2K
| Adam | epoch: 005 | loss: 0.14030 - acc: 0.9633 -- iter: 320/457
[A[ATraining Step: 71  | total loss: [1m[32m0.13660[0m[0m | time: 114.201s
[2K
| Adam | epoch: 005 | loss: 0.13660 - acc: 0.9639 -- iter: 352/457
[A[ATraining Step: 72  | total loss: [1m[32m0.12548[0m[0m | time: 122.714s
[2K
| Adam | epoch: 005 | loss: 0.12548 - acc: 0.9679 -- iter: 384/457
[A[ATraining Step: 73  | total loss: [1m[32m0.11773[0m[0m | time: 131.519s
[2K
| Adam | epoch: 005 | loss: 0.11773 - acc: 0.9715 -- iter: 416/457
[A[ATraining Step: 74  | total loss: [1m[32m0.11275[0m[0m | time: 142.674s
[2K
| Adam | epoch: 005 | loss: 0.11275 - acc: 0.9712 -- iter: 448/457
[A[ATraining Step: 75  | total loss: [1m[32m0.10396[0m[0m | time: 166.213s
[2K
| Adam | epoch: 005 | loss: 0.10396 - acc: 0.9743 | val_loss: 1.35889 - val_acc: 0.7083 -- iter: 457/457
--
Training Step: 76  | total loss: [1m[32m0.10178[0m[0m | time: 13.192s
[2K
| Adam | epoch: 006 | loss: 0.10178 - acc: 0.9737 -- iter: 032/457
[A[ATraining Step: 77  | total loss: [1m[32m0.09391[0m[0m | time: 21.800s
[2K
| Adam | epoch: 006 | loss: 0.09391 - acc: 0.9765 -- iter: 064/457
[A[ATraining Step: 78  | total loss: [1m[32m0.10044[0m[0m | time: 29.946s
[2K
| Adam | epoch: 006 | loss: 0.10044 - acc: 0.9692 -- iter: 096/457
[A[ATraining Step: 79  | total loss: [1m[32m0.10142[0m[0m | time: 32.952s
[2K
| Adam | epoch: 006 | loss: 0.10142 - acc: 0.9691 -- iter: 128/457
[A[ATraining Step: 80  | total loss: [1m[32m0.16740[0m[0m | time: 36.647s
[2K
| Adam | epoch: 006 | loss: 0.16740 - acc: 0.9495 -- iter: 160/457
[A[ATraining Step: 81  | total loss: [1m[32m0.16847[0m[0m | time: 48.807s
[2K
| Adam | epoch: 006 | loss: 0.16847 - acc: 0.9434 -- iter: 192/457
[A[ATraining Step: 82  | total loss: [1m[32m0.15719[0m[0m | time: 72.637s
[2K
| Adam | epoch: 006 | loss: 0.15719 - acc: 0.9491 -- iter: 224/457
[A[ATraining Step: 83  | total loss: [1m[32m0.15122[0m[0m | time: 101.010s
[2K
| Adam | epoch: 006 | loss: 0.15122 - acc: 0.9510 -- iter: 256/457
[A[ATraining Step: 84  | total loss: [1m[32m0.14274[0m[0m | time: 113.669s
[2K
| Adam | epoch: 006 | loss: 0.14274 - acc: 0.9528 -- iter: 288/457
[A[ATraining Step: 85  | total loss: [1m[32m0.13287[0m[0m | time: 125.819s
[2K
| Adam | epoch: 006 | loss: 0.13287 - acc: 0.9575 -- iter: 320/457
[A[ATraining Step: 86  | total loss: [1m[32m0.14023[0m[0m | time: 137.887s
[2K
| Adam | epoch: 006 | loss: 0.14023 - acc: 0.9587 -- iter: 352/457
[A[ATraining Step: 87  | total loss: [1m[32m0.15023[0m[0m | time: 146.486s
[2K
| Adam | epoch: 006 | loss: 0.15023 - acc: 0.9565 -- iter: 384/457
[A[ATraining Step: 88  | total loss: [1m[32m0.14430[0m[0m | time: 154.738s
[2K
| Adam | epoch: 006 | loss: 0.14430 - acc: 0.9546 -- iter: 416/457
[A[ATraining Step: 89  | total loss: [1m[32m0.13508[0m[0m | time: 163.659s
[2K
| Adam | epoch: 006 | loss: 0.13508 - acc: 0.9560 -- iter: 448/457
[A[ATraining Step: 90  | total loss: [1m[32m0.15782[0m[0m | time: 186.429s
[2K
| Adam | epoch: 006 | loss: 0.15782 - acc: 0.9448 | val_loss: 0.70242 - val_acc: 0.8264 -- iter: 457/457
--
Training Step: 91  | total loss: [1m[32m0.15789[0m[0m | time: 11.695s
[2K
| Adam | epoch: 007 | loss: 0.15789 - acc: 0.9410 -- iter: 032/457
[A[ATraining Step: 92  | total loss: [1m[32m0.14496[0m[0m | time: 21.798s
[2K
| Adam | epoch: 007 | loss: 0.14496 - acc: 0.9469 -- iter: 064/457
[A[ATraining Step: 93  | total loss: [1m[32m0.13564[0m[0m | time: 29.926s
[2K
| Adam | epoch: 007 | loss: 0.13564 - acc: 0.9491 -- iter: 096/457
[A[ATraining Step: 94  | total loss: [1m[32m0.13384[0m[0m | time: 38.533s
[2K
| Adam | epoch: 007 | loss: 0.13384 - acc: 0.9510 -- iter: 128/457
[A[ATraining Step: 95  | total loss: [1m[32m0.13653[0m[0m | time: 41.547s
[2K
| Adam | epoch: 007 | loss: 0.13653 - acc: 0.9434 -- iter: 160/457
[A[ATraining Step: 96  | total loss: [1m[32m0.29396[0m[0m | time: 45.986s
[2K
| Adam | epoch: 007 | loss: 0.29396 - acc: 0.9269 -- iter: 192/457
[A[ATraining Step: 97  | total loss: [1m[32m0.28838[0m[0m | time: 58.045s
[2K
| Adam | epoch: 007 | loss: 0.28838 - acc: 0.9231 -- iter: 224/457
[A[ATraining Step: 98  | total loss: [1m[32m0.27446[0m[0m | time: 70.185s
[2K
| Adam | epoch: 007 | loss: 0.27446 - acc: 0.9245 -- iter: 256/457
[A[ATraining Step: 99  | total loss: [1m[32m0.27359[0m[0m | time: 82.733s
[2K
| Adam | epoch: 007 | loss: 0.27359 - acc: 0.9227 -- iter: 288/457
[A[ATraining Step: 100  | total loss: [1m[32m0.25091[0m[0m | time: 95.175s
[2K
| Adam | epoch: 007 | loss: 0.25091 - acc: 0.9304 -- iter: 320/457
[A[ATraining Step: 101  | total loss: [1m[32m0.23523[0m[0m | time: 107.648s
[2K
| Adam | epoch: 007 | loss: 0.23523 - acc: 0.9342 -- iter: 352/457
[A[ATraining Step: 102  | total loss: [1m[32m0.21637[0m[0m | time: 119.886s
[2K
| Adam | epoch: 007 | loss: 0.21637 - acc: 0.9408 -- iter: 384/457
[A[ATraining Step: 103  | total loss: [1m[32m0.21523[0m[0m | time: 128.270s
[2K
| Adam | epoch: 007 | loss: 0.21523 - acc: 0.9405 -- iter: 416/457
[A[ATraining Step: 104  | total loss: [1m[32m0.20507[0m[0m | time: 136.402s
[2K
| Adam | epoch: 007 | loss: 0.20507 - acc: 0.9433 -- iter: 448/457
[A[ATraining Step: 105  | total loss: [1m[32m0.19028[0m[0m | time: 151.278s
[2K
| Adam | epoch: 007 | loss: 0.19028 - acc: 0.9490 | val_loss: 2.08704 - val_acc: 0.5833 -- iter: 457/457
--
Training Step: 106  | total loss: [1m[32m0.17899[0m[0m | time: 8.242s
[2K
| Adam | epoch: 008 | loss: 0.17899 - acc: 0.9510 -- iter: 032/457
[A[ATraining Step: 107  | total loss: [1m[32m0.19109[0m[0m | time: 16.253s
[2K
| Adam | epoch: 008 | loss: 0.19109 - acc: 0.9402 -- iter: 064/457
[A[ATraining Step: 108  | total loss: [1m[32m0.17909[0m[0m | time: 24.438s
[2K
| Adam | epoch: 008 | loss: 0.17909 - acc: 0.9462 -- iter: 096/457
[A[ATraining Step: 109  | total loss: [1m[32m0.18525[0m[0m | time: 32.480s
[2K
| Adam | epoch: 008 | loss: 0.18525 - acc: 0.9422 -- iter: 128/457
[A[ATraining Step: 110  | total loss: [1m[32m0.20140[0m[0m | time: 40.726s
[2K
| Adam | epoch: 008 | loss: 0.20140 - acc: 0.9292 -- iter: 160/457
[A[ATraining Step: 111  | total loss: [1m[32m0.18636[0m[0m | time: 43.756s
[2K
| Adam | epoch: 008 | loss: 0.18636 - acc: 0.9363 -- iter: 192/457
[A[ATraining Step: 112  | total loss: [1m[32m0.26746[0m[0m | time: 46.832s
[2K
| Adam | epoch: 008 | loss: 0.26746 - acc: 0.8871 -- iter: 224/457
[A[ATraining Step: 113  | total loss: [1m[32m0.31068[0m[0m | time: 54.844s
[2K
| Adam | epoch: 008 | loss: 0.31068 - acc: 0.8651 -- iter: 256/457
[A[ATraining Step: 114  | total loss: [1m[32m0.28220[0m[0m | time: 62.955s
[2K
| Adam | epoch: 008 | loss: 0.28220 - acc: 0.8786 -- iter: 288/457
[A[ATraining Step: 115  | total loss: [1m[32m0.27194[0m[0m | time: 71.205s
[2K
| Adam | epoch: 008 | loss: 0.27194 - acc: 0.8876 -- iter: 320/457
[A[ATraining Step: 116  | total loss: [1m[32m0.25101[0m[0m | time: 79.372s
[2K
| Adam | epoch: 008 | loss: 0.25101 - acc: 0.8988 -- iter: 352/457
[A[ATraining Step: 117  | total loss: [1m[32m0.24364[0m[0m | time: 87.457s
[2K
| Adam | epoch: 008 | loss: 0.24364 - acc: 0.9027 -- iter: 384/457
[A[ATraining Step: 118  | total loss: [1m[32m0.23761[0m[0m | time: 95.738s
[2K
| Adam | epoch: 008 | loss: 0.23761 - acc: 0.8999 -- iter: 416/457
[A[ATraining Step: 119  | total loss: [1m[32m0.22633[0m[0m | time: 103.994s
[2K
| Adam | epoch: 008 | loss: 0.22633 - acc: 0.9037 -- iter: 448/457
[A[ATraining Step: 120  | total loss: [1m[32m0.20879[0m[0m | time: 118.924s
[2K
| Adam | epoch: 008 | loss: 0.20879 - acc: 0.9133 | val_loss: 0.30773 - val_acc: 0.8681 -- iter: 457/457
--
Training Step: 121  | total loss: [1m[32m0.19116[0m[0m | time: 8.091s
[2K
| Adam | epoch: 009 | loss: 0.19116 - acc: 0.9220 -- iter: 032/457
[A[ATraining Step: 122  | total loss: [1m[32m0.18061[0m[0m | time: 16.162s
[2K
| Adam | epoch: 009 | loss: 0.18061 - acc: 0.9267 -- iter: 064/457
[A[ATraining Step: 123  | total loss: [1m[32m0.19849[0m[0m | time: 24.442s
[2K
| Adam | epoch: 009 | loss: 0.19849 - acc: 0.9277 -- iter: 096/457
[A[ATraining Step: 124  | total loss: [1m[32m0.18044[0m[0m | time: 32.576s
[2K
| Adam | epoch: 009 | loss: 0.18044 - acc: 0.9350 -- iter: 128/457
[A[ATraining Step: 125  | total loss: [1m[32m0.16658[0m[0m | time: 40.692s
[2K
| Adam | epoch: 009 | loss: 0.16658 - acc: 0.9415 -- iter: 160/457
[A[ATraining Step: 126  | total loss: [1m[32m0.16159[0m[0m | time: 48.727s
[2K
| Adam | epoch: 009 | loss: 0.16159 - acc: 0.9442 -- iter: 192/457
[A[ATraining Step: 127  | total loss: [1m[32m0.15098[0m[0m | time: 51.744s
[2K
| Adam | epoch: 009 | loss: 0.15098 - acc: 0.9498 -- iter: 224/457
[A[ATraining Step: 128  | total loss: [1m[32m0.16039[0m[0m | time: 54.754s
[2K
| Adam | epoch: 009 | loss: 0.16039 - acc: 0.9326 -- iter: 256/457
[A[ATraining Step: 129  | total loss: [1m[32m0.14527[0m[0m | time: 62.748s
[2K
| Adam | epoch: 009 | loss: 0.14527 - acc: 0.9393 -- iter: 288/457
[A[ATraining Step: 130  | total loss: [1m[32m0.13165[0m[0m | time: 70.992s
[2K
| Adam | epoch: 009 | loss: 0.13165 - acc: 0.9454 -- iter: 320/457
[A[ATraining Step: 131  | total loss: [1m[32m0.13254[0m[0m | time: 79.069s
[2K
| Adam | epoch: 009 | loss: 0.13254 - acc: 0.9446 -- iter: 352/457
[A[ATraining Step: 132  | total loss: [1m[32m0.13227[0m[0m | time: 87.164s
[2K
| Adam | epoch: 009 | loss: 0.13227 - acc: 0.9439 -- iter: 384/457
[A[ATraining Step: 133  | total loss: [1m[32m0.12012[0m[0m | time: 95.262s
[2K
| Adam | epoch: 009 | loss: 0.12012 - acc: 0.9495 -- iter: 416/457
[A[ATraining Step: 134  | total loss: [1m[32m0.11210[0m[0m | time: 103.199s
[2K
| Adam | epoch: 009 | loss: 0.11210 - acc: 0.9546 -- iter: 448/457
[A[ATraining Step: 135  | total loss: [1m[32m0.14013[0m[0m | time: 117.802s
[2K
| Adam | epoch: 009 | loss: 0.14013 - acc: 0.9560 | val_loss: 7.10292 - val_acc: 0.4514 -- iter: 457/457
--
Training Step: 136  | total loss: [1m[32m0.12886[0m[0m | time: 8.033s
[2K
| Adam | epoch: 010 | loss: 0.12886 - acc: 0.9604 -- iter: 032/457
[A[ATraining Step: 137  | total loss: [1m[32m0.13442[0m[0m | time: 16.145s
[2K
| Adam | epoch: 010 | loss: 0.13442 - acc: 0.9581 -- iter: 064/457
[A[ATraining Step: 138  | total loss: [1m[32m0.15500[0m[0m | time: 24.324s
[2K
| Adam | epoch: 010 | loss: 0.15500 - acc: 0.9529 -- iter: 096/457
[A[ATraining Step: 139  | total loss: [1m[32m0.14652[0m[0m | time: 32.669s
[2K
| Adam | epoch: 010 | loss: 0.14652 - acc: 0.9545 -- iter: 128/457
[A[ATraining Step: 140  | total loss: [1m[32m0.13554[0m[0m | time: 40.860s
[2K
| Adam | epoch: 010 | loss: 0.13554 - acc: 0.9559 -- iter: 160/457
[A[ATraining Step: 141  | total loss: [1m[32m0.13165[0m[0m | time: 49.195s
[2K
| Adam | epoch: 010 | loss: 0.13165 - acc: 0.9572 -- iter: 192/457
[A[ATraining Step: 142  | total loss: [1m[32m0.12349[0m[0m | time: 57.364s
[2K
| Adam | epoch: 010 | loss: 0.12349 - acc: 0.9584 -- iter: 224/457
[A[ATraining Step: 143  | total loss: [1m[32m0.11382[0m[0m | time: 60.355s
[2K
| Adam | epoch: 010 | loss: 0.11382 - acc: 0.9625 -- iter: 256/457
[A[ATraining Step: 144  | total loss: [1m[32m0.21446[0m[0m | time: 63.309s
[2K
| Adam | epoch: 010 | loss: 0.21446 - acc: 0.9552 -- iter: 288/457
[A[ATraining Step: 145  | total loss: [1m[32m0.21569[0m[0m | time: 71.360s
[2K
| Adam | epoch: 010 | loss: 0.21569 - acc: 0.9485 -- iter: 320/457
[A[ATraining Step: 146  | total loss: [1m[32m0.19505[0m[0m | time: 79.360s
[2K
| Adam | epoch: 010 | loss: 0.19505 - acc: 0.9537 -- iter: 352/457
[A[ATraining Step: 147  | total loss: [1m[32m0.17762[0m[0m | time: 87.429s
[2K
| Adam | epoch: 010 | loss: 0.17762 - acc: 0.9583 -- iter: 384/457
[A[ATraining Step: 148  | total loss: [1m[32m0.18930[0m[0m | time: 95.410s
[2K
| Adam | epoch: 010 | loss: 0.18930 - acc: 0.9531 -- iter: 416/457
[A[ATraining Step: 149  | total loss: [1m[32m0.17367[0m[0m | time: 103.564s
[2K
| Adam | epoch: 010 | loss: 0.17367 - acc: 0.9578 -- iter: 448/457
[A[ATraining Step: 150  | total loss: [1m[32m0.16685[0m[0m | time: 118.280s
[2K
| Adam | epoch: 010 | loss: 0.16685 - acc: 0.9558 | val_loss: 1.81240 - val_acc: 0.6806 -- iter: 457/457
--
Training Step: 151  | total loss: [1m[32m0.15563[0m[0m | time: 8.285s
[2K
| Adam | epoch: 011 | loss: 0.15563 - acc: 0.9602 -- iter: 032/457
[A[ATraining Step: 152  | total loss: [1m[32m0.15636[0m[0m | time: 16.327s
[2K
| Adam | epoch: 011 | loss: 0.15636 - acc: 0.9579 -- iter: 064/457
[A[ATraining Step: 153  | total loss: [1m[32m0.14763[0m[0m | time: 24.297s
[2K
| Adam | epoch: 011 | loss: 0.14763 - acc: 0.9621 -- iter: 096/457
[A[ATraining Step: 154  | total loss: [1m[32m0.16718[0m[0m | time: 32.429s
[2K
| Adam | epoch: 011 | loss: 0.16718 - acc: 0.9503 -- iter: 128/457
[A[ATraining Step: 155  | total loss: [1m[32m0.19544[0m[0m | time: 40.473s
[2K
| Adam | epoch: 011 | loss: 0.19544 - acc: 0.9428 -- iter: 160/457
[A[ATraining Step: 156  | total loss: [1m[32m0.18912[0m[0m | time: 48.330s
[2K
| Adam | epoch: 011 | loss: 0.18912 - acc: 0.9422 -- iter: 192/457
[A[ATraining Step: 157  | total loss: [1m[32m0.18687[0m[0m | time: 56.554s
[2K
| Adam | epoch: 011 | loss: 0.18687 - acc: 0.9449 -- iter: 224/457
[A[ATraining Step: 158  | total loss: [1m[32m0.18226[0m[0m | time: 64.604s
[2K
| Adam | epoch: 011 | loss: 0.18226 - acc: 0.9473 -- iter: 256/457
[A[ATraining Step: 159  | total loss: [1m[32m0.16476[0m[0m | time: 67.621s
[2K
| Adam | epoch: 011 | loss: 0.16476 - acc: 0.9525 -- iter: 288/457
[A[ATraining Step: 160  | total loss: [1m[32m0.15241[0m[0m | time: 70.636s
[2K
| Adam | epoch: 011 | loss: 0.15241 - acc: 0.9573 -- iter: 320/457
[A[ATraining Step: 161  | total loss: [1m[32m0.13769[0m[0m | time: 78.753s
[2K
| Adam | epoch: 011 | loss: 0.13769 - acc: 0.9616 -- iter: 352/457
[A[ATraining Step: 162  | total loss: [1m[32m0.13432[0m[0m | time: 87.023s
[2K
| Adam | epoch: 011 | loss: 0.13432 - acc: 0.9592 -- iter: 384/457
[A[ATraining Step: 163  | total loss: [1m[32m0.12377[0m[0m | time: 95.308s
[2K
| Adam | epoch: 011 | loss: 0.12377 - acc: 0.9632 -- iter: 416/457
[A[ATraining Step: 164  | total loss: [1m[32m0.11542[0m[0m | time: 103.353s
[2K
| Adam | epoch: 011 | loss: 0.11542 - acc: 0.9669 -- iter: 448/457
[A[ATraining Step: 165  | total loss: [1m[32m0.10733[0m[0m | time: 118.380s
[2K
| Adam | epoch: 011 | loss: 0.10733 - acc: 0.9702 | val_loss: 1.48042 - val_acc: 0.7361 -- iter: 457/457
--
Training Step: 166  | total loss: [1m[32m0.11731[0m[0m | time: 8.317s
[2K
| Adam | epoch: 012 | loss: 0.11731 - acc: 0.9670 -- iter: 032/457
[A[ATraining Step: 167  | total loss: [1m[32m0.11346[0m[0m | time: 16.406s
[2K
| Adam | epoch: 012 | loss: 0.11346 - acc: 0.9640 -- iter: 064/457
[A[ATraining Step: 168  | total loss: [1m[32m0.10286[0m[0m | time: 24.453s
[2K
| Adam | epoch: 012 | loss: 0.10286 - acc: 0.9676 -- iter: 096/457
[A[ATraining Step: 169  | total loss: [1m[32m0.09528[0m[0m | time: 32.588s
[2K
| Adam | epoch: 012 | loss: 0.09528 - acc: 0.9708 -- iter: 128/457
[A[ATraining Step: 170  | total loss: [1m[32m0.09066[0m[0m | time: 40.720s
[2K
| Adam | epoch: 012 | loss: 0.09066 - acc: 0.9706 -- iter: 160/457
[A[ATraining Step: 171  | total loss: [1m[32m0.08529[0m[0m | time: 48.831s
[2K
| Adam | epoch: 012 | loss: 0.08529 - acc: 0.9704 -- iter: 192/457
[A[ATraining Step: 172  | total loss: [1m[32m0.07803[0m[0m | time: 56.933s
[2K
| Adam | epoch: 012 | loss: 0.07803 - acc: 0.9734 -- iter: 224/457
[A[ATraining Step: 173  | total loss: [1m[32m0.07605[0m[0m | time: 65.088s
[2K
| Adam | epoch: 012 | loss: 0.07605 - acc: 0.9729 -- iter: 256/457
[A[ATraining Step: 174  | total loss: [1m[32m0.07223[0m[0m | time: 73.295s
[2K
| Adam | epoch: 012 | loss: 0.07223 - acc: 0.9756 -- iter: 288/457
[A[ATraining Step: 175  | total loss: [1m[32m0.07367[0m[0m | time: 76.240s
[2K
| Adam | epoch: 012 | loss: 0.07367 - acc: 0.9718 -- iter: 320/457
[A[ATraining Step: 176  | total loss: [1m[32m0.15391[0m[0m | time: 79.243s
[2K
| Adam | epoch: 012 | loss: 0.15391 - acc: 0.9635 -- iter: 352/457
[A[ATraining Step: 177  | total loss: [1m[32m0.13927[0m[0m | time: 87.236s
[2K
| Adam | epoch: 012 | loss: 0.13927 - acc: 0.9672 -- iter: 384/457
[A[ATraining Step: 178  | total loss: [1m[32m0.12573[0m[0m | time: 95.418s
[2K
| Adam | epoch: 012 | loss: 0.12573 - acc: 0.9705 -- iter: 416/457
[A[ATraining Step: 179  | total loss: [1m[32m0.11931[0m[0m | time: 103.484s
[2K
| Adam | epoch: 012 | loss: 0.11931 - acc: 0.9703 -- iter: 448/457
[A[ATraining Step: 180  | total loss: [1m[32m0.11661[0m[0m | time: 118.150s
[2K
| Adam | epoch: 012 | loss: 0.11661 - acc: 0.9639 | val_loss: 1.74537 - val_acc: 0.6597 -- iter: 457/457
--
Training Step: 181  | total loss: [1m[32m0.10606[0m[0m | time: 8.107s
[2K
| Adam | epoch: 013 | loss: 0.10606 - acc: 0.9675 -- iter: 032/457
[A[ATraining Step: 182  | total loss: [1m[32m0.10328[0m[0m | time: 16.148s
[2K
| Adam | epoch: 013 | loss: 0.10328 - acc: 0.9676 -- iter: 064/457
[A[ATraining Step: 183  | total loss: [1m[32m0.11171[0m[0m | time: 24.179s
[2K
| Adam | epoch: 013 | loss: 0.11171 - acc: 0.9646 -- iter: 096/457
[A[ATraining Step: 184  | total loss: [1m[32m0.10942[0m[0m | time: 32.410s
[2K
| Adam | epoch: 013 | loss: 0.10942 - acc: 0.9619 -- iter: 128/457
[A[ATraining Step: 185  | total loss: [1m[32m0.10400[0m[0m | time: 40.565s
[2K
| Adam | epoch: 013 | loss: 0.10400 - acc: 0.9657 -- iter: 160/457
[A[ATraining Step: 186  | total loss: [1m[32m0.12850[0m[0m | time: 48.501s
[2K
| Adam | epoch: 013 | loss: 0.12850 - acc: 0.9598 -- iter: 192/457
[A[ATraining Step: 187  | total loss: [1m[32m0.11887[0m[0m | time: 56.646s
[2K
| Adam | epoch: 013 | loss: 0.11887 - acc: 0.9607 -- iter: 224/457
[A[ATraining Step: 188  | total loss: [1m[32m0.11048[0m[0m | time: 64.746s
[2K
| Adam | epoch: 013 | loss: 0.11048 - acc: 0.9615 -- iter: 256/457
[A[ATraining Step: 189  | total loss: [1m[32m0.10475[0m[0m | time: 73.032s
[2K
| Adam | epoch: 013 | loss: 0.10475 - acc: 0.9622 -- iter: 288/457
[A[ATraining Step: 190  | total loss: [1m[32m0.09918[0m[0m | time: 80.996s
[2K
| Adam | epoch: 013 | loss: 0.09918 - acc: 0.9629 -- iter: 320/457
[A[ATraining Step: 191  | total loss: [1m[32m0.09508[0m[0m | time: 83.999s
[2K
| Adam | epoch: 013 | loss: 0.09508 - acc: 0.9634 -- iter: 352/457
[A[ATraining Step: 192  | total loss: [1m[32m0.15412[0m[0m | time: 86.961s
[2K
| Adam | epoch: 013 | loss: 0.15412 - acc: 0.9449 -- iter: 384/457
[A[ATraining Step: 193  | total loss: [1m[32m0.13965[0m[0m | time: 95.086s
[2K
| Adam | epoch: 013 | loss: 0.13965 - acc: 0.9504 -- iter: 416/457
[A[ATraining Step: 194  | total loss: [1m[32m0.13633[0m[0m | time: 103.121s
[2K
| Adam | epoch: 013 | loss: 0.13633 - acc: 0.9522 -- iter: 448/457
[A[ATraining Step: 195  | total loss: [1m[32m0.14019[0m[0m | time: 117.676s
[2K
| Adam | epoch: 013 | loss: 0.14019 - acc: 0.9476 | val_loss: 2.68307 - val_acc: 0.6528 -- iter: 457/457
--
Training Step: 196  | total loss: [1m[32m0.13184[0m[0m | time: 8.211s
[2K
| Adam | epoch: 014 | loss: 0.13184 - acc: 0.9497 -- iter: 032/457
[A[ATraining Step: 197  | total loss: [1m[32m0.11994[0m[0m | time: 16.247s
[2K
| Adam | epoch: 014 | loss: 0.11994 - acc: 0.9548 -- iter: 064/457
[A[ATraining Step: 198  | total loss: [1m[32m0.10998[0m[0m | time: 24.553s
[2K
| Adam | epoch: 014 | loss: 0.10998 - acc: 0.9593 -- iter: 096/457
[A[ATraining Step: 199  | total loss: [1m[32m0.10590[0m[0m | time: 32.479s
[2K
| Adam | epoch: 014 | loss: 0.10590 - acc: 0.9602 -- iter: 128/457
[A[ATraining Step: 200  | total loss: [1m[32m0.09792[0m[0m | time: 47.363s
[2K
| Adam | epoch: 014 | loss: 0.09792 - acc: 0.9642 | val_loss: 0.95240 - val_acc: 0.7847 -- iter: 160/457
--
Training Step: 201  | total loss: [1m[32m0.08915[0m[0m | time: 55.467s
[2K
| Adam | epoch: 014 | loss: 0.08915 - acc: 0.9678 -- iter: 192/457
[A[ATraining Step: 202  | total loss: [1m[32m0.08073[0m[0m | time: 63.737s
[2K
| Adam | epoch: 014 | loss: 0.08073 - acc: 0.9710 -- iter: 224/457
[A[ATraining Step: 203  | total loss: [1m[32m0.07588[0m[0m | time: 72.050s
[2K
| Adam | epoch: 014 | loss: 0.07588 - acc: 0.9739 -- iter: 256/457
[A[ATraining Step: 204  | total loss: [1m[32m0.06981[0m[0m | time: 80.153s
[2K
| Adam | epoch: 014 | loss: 0.06981 - acc: 0.9765 -- iter: 288/457
[A[ATraining Step: 205  | total loss: [1m[32m0.08278[0m[0m | time: 88.269s
[2K
| Adam | epoch: 014 | loss: 0.08278 - acc: 0.9757 -- iter: 320/457
[A[ATraining Step: 206  | total loss: [1m[32m0.07575[0m[0m | time: 96.423s
[2K
| Adam | epoch: 014 | loss: 0.07575 - acc: 0.9782 -- iter: 352/457
[A[ATraining Step: 207  | total loss: [1m[32m0.06957[0m[0m | time: 99.375s
[2K
| Adam | epoch: 014 | loss: 0.06957 - acc: 0.9804 -- iter: 384/457
[A[ATraining Step: 208  | total loss: [1m[32m0.11681[0m[0m | time: 102.501s
[2K
| Adam | epoch: 014 | loss: 0.11681 - acc: 0.9712 -- iter: 416/457
[A[ATraining Step: 209  | total loss: [1m[32m0.10675[0m[0m | time: 110.501s
[2K
| Adam | epoch: 014 | loss: 0.10675 - acc: 0.9741 -- iter: 448/457
[A[ATraining Step: 210  | total loss: [1m[32m0.09726[0m[0m | time: 125.352s
[2K
| Adam | epoch: 014 | loss: 0.09726 - acc: 0.9767 | val_loss: 1.01953 - val_acc: 0.7569 -- iter: 457/457
--
Training Step: 211  | total loss: [1m[32m0.08886[0m[0m | time: 8.174s
[2K
| Adam | epoch: 015 | loss: 0.08886 - acc: 0.9790 -- iter: 032/457
[A[ATraining Step: 212  | total loss: [1m[32m0.08568[0m[0m | time: 16.094s
[2K
| Adam | epoch: 015 | loss: 0.08568 - acc: 0.9780 -- iter: 064/457
[A[ATraining Step: 213  | total loss: [1m[32m0.09723[0m[0m | time: 24.303s
[2K
| Adam | epoch: 015 | loss: 0.09723 - acc: 0.9771 -- iter: 096/457
[A[ATraining Step: 214  | total loss: [1m[32m0.09030[0m[0m | time: 32.281s
[2K
| Adam | epoch: 015 | loss: 0.09030 - acc: 0.9794 -- iter: 128/457
[A[ATraining Step: 215  | total loss: [1m[32m0.09044[0m[0m | time: 40.384s
[2K
| Adam | epoch: 015 | loss: 0.09044 - acc: 0.9783 -- iter: 160/457
[A[ATraining Step: 216  | total loss: [1m[32m0.08337[0m[0m | time: 48.363s
[2K
| Adam | epoch: 015 | loss: 0.08337 - acc: 0.9805 -- iter: 192/457
[A[ATraining Step: 217  | total loss: [1m[32m0.07683[0m[0m | time: 56.551s
[2K
| Adam | epoch: 015 | loss: 0.07683 - acc: 0.9824 -- iter: 224/457
[A[ATraining Step: 218  | total loss: [1m[32m0.06981[0m[0m | time: 64.652s
[2K
| Adam | epoch: 015 | loss: 0.06981 - acc: 0.9842 -- iter: 256/457
[A[ATraining Step: 219  | total loss: [1m[32m0.06370[0m[0m | time: 72.724s
[2K
| Adam | epoch: 015 | loss: 0.06370 - acc: 0.9858 -- iter: 288/457
[A[ATraining Step: 220  | total loss: [1m[32m0.05810[0m[0m | time: 80.759s
[2K
| Adam | epoch: 015 | loss: 0.05810 - acc: 0.9872 -- iter: 320/457
[A[ATraining Step: 221  | total loss: [1m[32m0.06360[0m[0m | time: 88.940s
[2K
| Adam | epoch: 015 | loss: 0.06360 - acc: 0.9853 -- iter: 352/457
[A[ATraining Step: 222  | total loss: [1m[32m0.05786[0m[0m | time: 96.961s
[2K
| Adam | epoch: 015 | loss: 0.05786 - acc: 0.9868 -- iter: 384/457
[A[ATraining Step: 223  | total loss: [1m[32m0.05342[0m[0m | time: 99.958s
[2K
| Adam | epoch: 015 | loss: 0.05342 - acc: 0.9881 -- iter: 416/457
[A[ATraining Step: 224  | total loss: [1m[32m0.05206[0m[0m | time: 102.954s
[2K
| Adam | epoch: 015 | loss: 0.05206 - acc: 0.9893 -- iter: 448/457
[A[ATraining Step: 225  | total loss: [1m[32m0.04837[0m[0m | time: 117.680s
[2K
| Adam | epoch: 015 | loss: 0.04837 - acc: 0.9904 | val_loss: 0.27164 - val_acc: 0.8681 -- iter: 457/457
--
Validation AUC:0.9659205484976809
Validation AUPRC:0.9463061160602175
Test AUC:0.965040489828165
Test AUPRC:0.9606372716042011
BestTestF1Score	0.91	0.84	0.92	0.95	0.87	53	3	80	8	0.2
BestTestMCCScore	0.91	0.84	0.92	0.95	0.87	53	3	80	8	0.2
BestTestAccuracyScore	0.91	0.84	0.92	0.95	0.87	53	3	80	8	0.2
BestValidationF1Score	0.9	0.83	0.92	0.86	0.95	54	9	78	3	0.2
BestValidationMCC	0.9	0.83	0.92	0.86	0.95	54	9	78	3	0.2
BestValidationAccuracy	0.9	0.83	0.92	0.86	0.95	54	9	78	3	0.2
TestPredictions (Threshold:0.2)
CHEMBL108130,TP,ACT,0.9900000095367432	CHEMBL249153,TP,ACT,0.8899999856948853	CHEMBL322537,TN,INACT,0.0	CHEMBL165012,TN,INACT,0.0	CHEMBL2372072,FN,ACT,0.0	CHEMBL537834,TN,INACT,0.009999999776482582	CHEMBL1933103,TP,ACT,0.9700000286102295	CHEMBL150869,TP,ACT,0.20000000298023224	CHEMBL584525,TP,ACT,0.8199999928474426	CHEMBL76576,TN,INACT,0.0	CHEMBL296245,TN,INACT,0.0	CHEMBL3109772,TN,INACT,0.009999999776482582	CHEMBL400670,TP,ACT,0.8600000143051147	CHEMBL89203,TN,INACT,0.0	CHEMBL1161950,TP,ACT,0.4099999964237213	CHEMBL407340,FN,ACT,0.10000000149011612	CHEMBL3633665,TN,INACT,0.0	CHEMBL417712,TN,INACT,0.0	CHEMBL1259241,TN,INACT,0.0	CHEMBL413644,FP,INACT,0.33000001311302185	CHEMBL89445,TN,INACT,0.0	CHEMBL2310857,TP,ACT,0.4399999976158142	CHEMBL43661,TN,INACT,0.009999999776482582	CHEMBL366344,TP,ACT,0.23999999463558197	CHEMBL583457,TP,ACT,1.0	CHEMBL570520,TP,ACT,1.0	CHEMBL2372077,TN,INACT,0.0	CHEMBL248949,TP,ACT,0.9800000190734863	CHEMBL515170,TN,INACT,0.0	CHEMBL154615,TP,ACT,1.0	CHEMBL319438,FN,ACT,0.019999999552965164	CHEMBL27065,TN,INACT,0.0	CHEMBL536800,TN,INACT,0.0	CHEMBL308924,TN,INACT,0.0	CHEMBL505432,TP,ACT,0.23999999463558197	CHEMBL422411,TN,INACT,0.05999999865889549	CHEMBL2062154,TP,ACT,0.9200000166893005	CHEMBL2112592,TN,INACT,0.0	CHEMBL594376,TN,INACT,0.0	CHEMBL80807,TN,INACT,0.0	CHEMBL146206,FN,ACT,0.03999999910593033	CHEMBL320763,TN,INACT,0.0	CHEMBL516113,TP,ACT,0.6899999976158142	CHEMBL389639,TP,ACT,0.8100000023841858	CHEMBL104172,TN,INACT,0.0	CHEMBL1774042,TP,ACT,0.9599999785423279	CHEMBL431451,TP,ACT,0.9900000095367432	CHEMBL296291,TN,INACT,0.0	CHEMBL429238,TN,INACT,0.019999999552965164	CHEMBL309397,TN,INACT,0.0	CHEMBL48031,TN,INACT,0.0	CHEMBL595022,TN,INACT,0.0	CHEMBL352779,TN,INACT,0.0	CHEMBL111023,TN,INACT,0.0	CHEMBL1773878,TP,ACT,0.9399999976158142	CHEMBL112877,TN,INACT,0.0	CHEMBL206025,FN,ACT,0.0	CHEMBL345869,TP,ACT,0.9900000095367432	CHEMBL9387,TP,ACT,0.4099999964237213	CHEMBL276676,FP,INACT,0.7400000095367432	CHEMBL174448,TN,INACT,0.0	CHEMBL175228,TN,INACT,0.0	CHEMBL476725,TP,ACT,0.9599999785423279	CHEMBL311455,TN,INACT,0.0	CHEMBL3780633,TN,INACT,0.0	CHEMBL294649,TN,INACT,0.0	CHEMBL39263,FN,ACT,0.0	CHEMBL421778,TP,ACT,0.8399999737739563	CHEMBL320124,TN,INACT,0.0	CHEMBL414605,TN,INACT,0.0	CHEMBL2391353,TN,INACT,0.0	CHEMBL369359,TN,INACT,0.0	CHEMBL63937,TN,INACT,0.0	CHEMBL413040,TN,INACT,0.0	CHEMBL502924,TP,ACT,1.0	CHEMBL78669,TN,INACT,0.0	CHEMBL316106,TP,ACT,0.9900000095367432	CHEMBL552615,TN,INACT,0.0	CHEMBL10211,TN,INACT,0.10999999940395355	CHEMBL1765667,TN,INACT,0.0	CHEMBL377157,FN,ACT,0.009999999776482582	CHEMBL227333,TP,ACT,0.9300000071525574	CHEMBL1773884,TP,ACT,1.0	CHEMBL1774040,TP,ACT,0.5600000023841858	CHEMBL80438,TN,INACT,0.0	CHEMBL218651,TP,ACT,0.9900000095367432	CHEMBL374388,TP,ACT,0.9800000190734863	CHEMBL80180,TN,INACT,0.0	CHEMBL73272,TN,INACT,0.0	CHEMBL141365,TN,INACT,0.09000000357627869	CHEMBL345951,TN,INACT,0.0	CHEMBL446693,TN,INACT,0.009999999776482582	CHEMBL330521,TP,ACT,0.800000011920929	CHEMBL319036,TN,INACT,0.0	CHEMBL438915,TN,INACT,0.009999999776482582	CHEMBL1773890,TP,ACT,0.7300000190734863	CHEMBL435810,TN,INACT,0.0	CHEMBL410114,TP,ACT,0.4000000059604645	CHEMBL1933104,TP,ACT,0.9700000286102295	CHEMBL205198,TP,ACT,0.6000000238418579	CHEMBL325935,TN,INACT,0.0	CHEMBL477784,TP,ACT,0.23999999463558197	CHEMBL2369493,TN,INACT,0.0	CHEMBL45305,TN,INACT,0.0	CHEMBL73096,TN,INACT,0.0	CHEMBL112314,TN,INACT,0.0	CHEMBL307034,TN,INACT,0.009999999776482582	CHEMBL1121,TP,ACT,0.5299999713897705	CHEMBL208479,TP,ACT,0.41999998688697815	CHEMBL227276,TP,ACT,0.9900000095367432	CHEMBL514716,TP,ACT,0.9900000095367432	CHEMBL218729,FN,ACT,0.0	CHEMBL21509,TN,INACT,0.0	CHEMBL508772,TP,ACT,1.0	CHEMBL572046,TP,ACT,0.7300000190734863	CHEMBL44615,TN,INACT,0.0	CHEMBL302027,TP,ACT,0.9599999785423279	CHEMBL2370511,TN,INACT,0.0	CHEMBL478604,TP,ACT,0.8799999952316284	CHEMBL191915,TN,INACT,0.0	CHEMBL319910,TN,INACT,0.0	CHEMBL3350741,TN,INACT,0.029999999329447746	CHEMBL110695,TN,INACT,0.0	CHEMBL1774035,TP,ACT,0.38999998569488525	CHEMBL478397,TP,ACT,0.9800000190734863	CHEMBL407198,TP,ACT,0.9900000095367432	CHEMBL515288,TP,ACT,0.4099999964237213	CHEMBL15689,FP,INACT,0.3799999952316284	CHEMBL18797,TN,INACT,0.0	CHEMBL43788,TN,INACT,0.0	CHEMBL324547,TP,ACT,0.9900000095367432	CHEMBL3218121,TN,INACT,0.0	CHEMBL343969,TN,INACT,0.1599999964237213	CHEMBL1258999,TN,INACT,0.0	CHEMBL150260,TN,INACT,0.0	CHEMBL320569,TN,INACT,0.0	CHEMBL399056,TP,ACT,0.9800000190734863	CHEMBL258863,TP,ACT,0.3199999928474426	CHEMBL90697,TP,ACT,1.0	CHEMBL1076625,TN,INACT,0.019999999552965164	CHEMBL76860,TN,INACT,0.0	CHEMBL1916635,TN,INACT,0.029999999329447746	CHEMBL324586,TN,INACT,0.0	CHEMBL109248,TN,INACT,0.0	

