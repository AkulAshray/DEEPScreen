ImageNetInceptionV2 CHEMBL2789 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	183
Number of inactive compounds :	122
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2789_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2789_adam_0.0005_30_0.6/
---------------------------------
Training samples: 190
Validation samples: 60
--
Training Step: 1  | time: 36.819s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/190
[A[ATraining Step: 2  | total loss: [1m[32m0.69697[0m[0m | time: 45.193s
[2K
| Adam | epoch: 001 | loss: 0.69697 - acc: 0.4500 -- iter: 064/190
[A[ATraining Step: 3  | total loss: [1m[32m0.72119[0m[0m | time: 53.589s
[2K
| Adam | epoch: 001 | loss: 0.72119 - acc: 0.4398 -- iter: 096/190
[A[ATraining Step: 4  | total loss: [1m[32m0.63128[0m[0m | time: 61.687s
[2K
| Adam | epoch: 001 | loss: 0.63128 - acc: 0.6724 -- iter: 128/190
[A[ATraining Step: 5  | total loss: [1m[32m0.66339[0m[0m | time: 70.087s
[2K
| Adam | epoch: 001 | loss: 0.66339 - acc: 0.6396 -- iter: 160/190
[A[ATraining Step: 6  | total loss: [1m[32m0.61848[0m[0m | time: 86.014s
[2K
| Adam | epoch: 001 | loss: 0.61848 - acc: 0.6503 | val_loss: 0.71265 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 7  | total loss: [1m[32m0.60132[0m[0m | time: 7.667s
[2K
| Adam | epoch: 002 | loss: 0.60132 - acc: 0.6601 -- iter: 032/190
[A[ATraining Step: 8  | total loss: [1m[32m0.38155[0m[0m | time: 15.979s
[2K
| Adam | epoch: 002 | loss: 0.38155 - acc: 0.8326 -- iter: 064/190
[A[ATraining Step: 9  | total loss: [1m[32m0.41433[0m[0m | time: 24.300s
[2K
| Adam | epoch: 002 | loss: 0.41433 - acc: 0.8385 -- iter: 096/190
[A[ATraining Step: 10  | total loss: [1m[32m0.29337[0m[0m | time: 32.548s
[2K
| Adam | epoch: 002 | loss: 0.29337 - acc: 0.9036 -- iter: 128/190
[A[ATraining Step: 11  | total loss: [1m[32m0.26592[0m[0m | time: 40.869s
[2K
| Adam | epoch: 002 | loss: 0.26592 - acc: 0.9197 -- iter: 160/190
[A[ATraining Step: 12  | total loss: [1m[32m0.20366[0m[0m | time: 51.937s
[2K
| Adam | epoch: 002 | loss: 0.20366 - acc: 0.9277 | val_loss: 3.49533 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 13  | total loss: [1m[32m0.17145[0m[0m | time: 9.380s
[2K
| Adam | epoch: 003 | loss: 0.17145 - acc: 0.9453 -- iter: 032/190
[A[ATraining Step: 14  | total loss: [1m[32m0.17127[0m[0m | time: 21.401s
[2K
| Adam | epoch: 003 | loss: 0.17127 - acc: 0.9404 -- iter: 064/190
[A[ATraining Step: 15  | total loss: [1m[32m0.11813[0m[0m | time: 29.950s
[2K
| Adam | epoch: 003 | loss: 0.11813 - acc: 0.9637 -- iter: 096/190
[A[ATraining Step: 16  | total loss: [1m[32m0.22345[0m[0m | time: 39.676s
[2K
| Adam | epoch: 003 | loss: 0.22345 - acc: 0.9305 -- iter: 128/190
[A[ATraining Step: 17  | total loss: [1m[32m0.21119[0m[0m | time: 48.256s
[2K
| Adam | epoch: 003 | loss: 0.21119 - acc: 0.9442 -- iter: 160/190
[A[ATraining Step: 18  | total loss: [1m[32m0.14492[0m[0m | time: 61.649s
[2K
| Adam | epoch: 003 | loss: 0.14492 - acc: 0.9635 | val_loss: 4.79974 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 19  | total loss: [1m[32m0.14838[0m[0m | time: 15.879s
[2K
| Adam | epoch: 004 | loss: 0.14838 - acc: 0.9549 -- iter: 032/190
[A[ATraining Step: 20  | total loss: [1m[32m0.11197[0m[0m | time: 23.630s
[2K
| Adam | epoch: 004 | loss: 0.11197 - acc: 0.9694 -- iter: 064/190
[A[ATraining Step: 21  | total loss: [1m[32m0.08718[0m[0m | time: 31.509s
[2K
| Adam | epoch: 004 | loss: 0.08718 - acc: 0.9789 -- iter: 096/190
[A[ATraining Step: 22  | total loss: [1m[32m0.06540[0m[0m | time: 40.057s
[2K
| Adam | epoch: 004 | loss: 0.06540 - acc: 0.9852 -- iter: 128/190
[A[ATraining Step: 23  | total loss: [1m[32m0.07168[0m[0m | time: 48.959s
[2K
| Adam | epoch: 004 | loss: 0.07168 - acc: 0.9804 -- iter: 160/190
[A[ATraining Step: 24  | total loss: [1m[32m0.14105[0m[0m | time: 60.829s
[2K
| Adam | epoch: 004 | loss: 0.14105 - acc: 0.9771 | val_loss: 3.93298 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 25  | total loss: [1m[32m0.10815[0m[0m | time: 9.490s
[2K
| Adam | epoch: 005 | loss: 0.10815 - acc: 0.9834 -- iter: 032/190
[A[ATraining Step: 26  | total loss: [1m[32m0.08677[0m[0m | time: 17.685s
[2K
| Adam | epoch: 005 | loss: 0.08677 - acc: 0.9878 -- iter: 064/190
[A[ATraining Step: 27  | total loss: [1m[32m0.08257[0m[0m | time: 25.736s
[2K
| Adam | epoch: 005 | loss: 0.08257 - acc: 0.9829 -- iter: 096/190
[A[ATraining Step: 28  | total loss: [1m[32m0.07517[0m[0m | time: 33.387s
[2K
| Adam | epoch: 005 | loss: 0.07517 - acc: 0.9872 -- iter: 128/190
[A[ATraining Step: 29  | total loss: [1m[32m0.06196[0m[0m | time: 41.565s
[2K
| Adam | epoch: 005 | loss: 0.06196 - acc: 0.9903 -- iter: 160/190
[A[ATraining Step: 30  | total loss: [1m[32m0.10289[0m[0m | time: 52.530s
[2K
| Adam | epoch: 005 | loss: 0.10289 - acc: 0.9852 | val_loss: 6.00643 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 31  | total loss: [1m[32m0.16114[0m[0m | time: 8.520s
[2K
| Adam | epoch: 006 | loss: 0.16114 - acc: 0.9814 -- iter: 032/190
[A[ATraining Step: 32  | total loss: [1m[32m0.12753[0m[0m | time: 16.785s
[2K
| Adam | epoch: 006 | loss: 0.12753 - acc: 0.9856 -- iter: 064/190
[A[ATraining Step: 33  | total loss: [1m[32m0.10538[0m[0m | time: 24.978s
[2K
| Adam | epoch: 006 | loss: 0.10538 - acc: 0.9887 -- iter: 096/190
[A[ATraining Step: 34  | total loss: [1m[32m0.09243[0m[0m | time: 32.722s
[2K
| Adam | epoch: 006 | loss: 0.09243 - acc: 0.9912 -- iter: 128/190
[A[ATraining Step: 35  | total loss: [1m[32m0.07550[0m[0m | time: 40.382s
[2K
| Adam | epoch: 006 | loss: 0.07550 - acc: 0.9930 -- iter: 160/190
[A[ATraining Step: 36  | total loss: [1m[32m0.06255[0m[0m | time: 51.310s
[2K
| Adam | epoch: 006 | loss: 0.06255 - acc: 0.9944 | val_loss: 5.98797 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 37  | total loss: [1m[32m0.08325[0m[0m | time: 10.609s
[2K
| Adam | epoch: 007 | loss: 0.08325 - acc: 0.9831 -- iter: 032/190
[A[ATraining Step: 38  | total loss: [1m[32m0.13891[0m[0m | time: 23.331s
[2K
| Adam | epoch: 007 | loss: 0.13891 - acc: 0.9741 -- iter: 064/190
[A[ATraining Step: 39  | total loss: [1m[32m0.11527[0m[0m | time: 31.610s
[2K
| Adam | epoch: 007 | loss: 0.11527 - acc: 0.9791 -- iter: 096/190
[A[ATraining Step: 40  | total loss: [1m[32m0.09702[0m[0m | time: 39.795s
[2K
| Adam | epoch: 007 | loss: 0.09702 - acc: 0.9830 -- iter: 128/190
[A[ATraining Step: 41  | total loss: [1m[32m0.09252[0m[0m | time: 47.645s
[2K
| Adam | epoch: 007 | loss: 0.09252 - acc: 0.9804 -- iter: 160/190
[A[ATraining Step: 42  | total loss: [1m[32m0.07989[0m[0m | time: 58.115s
[2K
| Adam | epoch: 007 | loss: 0.07989 - acc: 0.9839 | val_loss: 6.94115 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 43  | total loss: [1m[32m0.07086[0m[0m | time: 8.420s
[2K
| Adam | epoch: 008 | loss: 0.07086 - acc: 0.9868 -- iter: 032/190
[A[ATraining Step: 44  | total loss: [1m[32m0.07468[0m[0m | time: 17.194s
[2K
| Adam | epoch: 008 | loss: 0.07468 - acc: 0.9836 -- iter: 064/190
[A[ATraining Step: 45  | total loss: [1m[32m0.11219[0m[0m | time: 25.401s
[2K
| Adam | epoch: 008 | loss: 0.11219 - acc: 0.9758 -- iter: 096/190
[A[ATraining Step: 46  | total loss: [1m[32m0.09604[0m[0m | time: 34.260s
[2K
| Adam | epoch: 008 | loss: 0.09604 - acc: 0.9798 -- iter: 128/190
[A[ATraining Step: 47  | total loss: [1m[32m0.10174[0m[0m | time: 42.548s
[2K
| Adam | epoch: 008 | loss: 0.10174 - acc: 0.9780 -- iter: 160/190
[A[ATraining Step: 48  | total loss: [1m[32m0.10027[0m[0m | time: 53.034s
[2K
| Adam | epoch: 008 | loss: 0.10027 - acc: 0.9765 | val_loss: 1.82001 - val_acc: 0.5333 -- iter: 190/190
--
Training Step: 49  | total loss: [1m[32m0.08953[0m[0m | time: 8.050s
[2K
| Adam | epoch: 009 | loss: 0.08953 - acc: 0.9802 -- iter: 032/190
[A[ATraining Step: 50  | total loss: [1m[32m0.08009[0m[0m | time: 16.292s
[2K
| Adam | epoch: 009 | loss: 0.08009 - acc: 0.9833 -- iter: 064/190
[A[ATraining Step: 51  | total loss: [1m[32m0.06923[0m[0m | time: 24.470s
[2K
| Adam | epoch: 009 | loss: 0.06923 - acc: 0.9859 -- iter: 096/190
[A[ATraining Step: 52  | total loss: [1m[32m0.07933[0m[0m | time: 32.723s
[2K
| Adam | epoch: 009 | loss: 0.07933 - acc: 0.9833 -- iter: 128/190
[A[ATraining Step: 53  | total loss: [1m[32m0.06982[0m[0m | time: 41.125s
[2K
| Adam | epoch: 009 | loss: 0.06982 - acc: 0.9858 -- iter: 160/190
[A[ATraining Step: 54  | total loss: [1m[32m0.06112[0m[0m | time: 52.219s
[2K
| Adam | epoch: 009 | loss: 0.06112 - acc: 0.9878 | val_loss: 0.60244 - val_acc: 0.7333 -- iter: 190/190
--
Training Step: 55  | total loss: [1m[32m0.05483[0m[0m | time: 8.016s
[2K
| Adam | epoch: 010 | loss: 0.05483 - acc: 0.9896 -- iter: 032/190
[A[ATraining Step: 56  | total loss: [1m[32m0.04855[0m[0m | time: 15.914s
[2K
| Adam | epoch: 010 | loss: 0.04855 - acc: 0.9910 -- iter: 064/190
[A[ATraining Step: 57  | total loss: [1m[32m0.04289[0m[0m | time: 24.216s
[2K
| Adam | epoch: 010 | loss: 0.04289 - acc: 0.9923 -- iter: 096/190
[A[ATraining Step: 58  | total loss: [1m[32m0.04396[0m[0m | time: 32.674s
[2K
| Adam | epoch: 010 | loss: 0.04396 - acc: 0.9891 -- iter: 128/190
[A[ATraining Step: 59  | total loss: [1m[32m0.03972[0m[0m | time: 40.817s
[2K
| Adam | epoch: 010 | loss: 0.03972 - acc: 0.9905 -- iter: 160/190
[A[ATraining Step: 60  | total loss: [1m[32m0.03533[0m[0m | time: 51.996s
[2K
| Adam | epoch: 010 | loss: 0.03533 - acc: 0.9918 | val_loss: 0.37848 - val_acc: 0.8000 -- iter: 190/190
--
Training Step: 61  | total loss: [1m[32m0.03152[0m[0m | time: 8.176s
[2K
| Adam | epoch: 011 | loss: 0.03152 - acc: 0.9929 -- iter: 032/190
[A[ATraining Step: 62  | total loss: [1m[32m0.02937[0m[0m | time: 15.952s
[2K
| Adam | epoch: 011 | loss: 0.02937 - acc: 0.9938 -- iter: 064/190
[A[ATraining Step: 63  | total loss: [1m[32m0.02699[0m[0m | time: 23.839s
[2K
| Adam | epoch: 011 | loss: 0.02699 - acc: 0.9946 -- iter: 096/190
[A[ATraining Step: 64  | total loss: [1m[32m0.02449[0m[0m | time: 31.885s
[2K
| Adam | epoch: 011 | loss: 0.02449 - acc: 0.9952 -- iter: 128/190
[A[ATraining Step: 65  | total loss: [1m[32m0.02328[0m[0m | time: 39.881s
[2K
| Adam | epoch: 011 | loss: 0.02328 - acc: 0.9958 -- iter: 160/190
[A[ATraining Step: 66  | total loss: [1m[32m0.08315[0m[0m | time: 50.664s
[2K
| Adam | epoch: 011 | loss: 0.08315 - acc: 0.9887 | val_loss: 0.41694 - val_acc: 0.8500 -- iter: 190/190
--
Training Step: 67  | total loss: [1m[32m0.07400[0m[0m | time: 8.106s
[2K
| Adam | epoch: 012 | loss: 0.07400 - acc: 0.9901 -- iter: 032/190
[A[ATraining Step: 68  | total loss: [1m[32m0.06596[0m[0m | time: 16.323s
[2K
| Adam | epoch: 012 | loss: 0.06596 - acc: 0.9913 -- iter: 064/190
[A[ATraining Step: 69  | total loss: [1m[32m0.05977[0m[0m | time: 24.115s
[2K
| Adam | epoch: 012 | loss: 0.05977 - acc: 0.9923 -- iter: 096/190
[A[ATraining Step: 70  | total loss: [1m[32m0.06634[0m[0m | time: 31.936s
[2K
| Adam | epoch: 012 | loss: 0.06634 - acc: 0.9893 -- iter: 128/190
[A[ATraining Step: 71  | total loss: [1m[32m0.06078[0m[0m | time: 40.050s
[2K
| Adam | epoch: 012 | loss: 0.06078 - acc: 0.9905 -- iter: 160/190
[A[ATraining Step: 72  | total loss: [1m[32m0.05601[0m[0m | time: 51.014s
[2K
| Adam | epoch: 012 | loss: 0.05601 - acc: 0.9916 | val_loss: 1.05218 - val_acc: 0.6000 -- iter: 190/190
--
Training Step: 73  | total loss: [1m[32m0.10206[0m[0m | time: 8.266s
[2K
| Adam | epoch: 013 | loss: 0.10206 - acc: 0.9856 -- iter: 032/190
[A[ATraining Step: 74  | total loss: [1m[32m0.09388[0m[0m | time: 17.987s
[2K
| Adam | epoch: 013 | loss: 0.09388 - acc: 0.9872 -- iter: 064/190
[A[ATraining Step: 75  | total loss: [1m[32m0.08870[0m[0m | time: 26.238s
[2K
| Adam | epoch: 013 | loss: 0.08870 - acc: 0.9886 -- iter: 096/190
[A[ATraining Step: 76  | total loss: [1m[32m0.08257[0m[0m | time: 34.004s
[2K
| Adam | epoch: 013 | loss: 0.08257 - acc: 0.9898 -- iter: 128/190
[A[ATraining Step: 77  | total loss: [1m[32m0.07620[0m[0m | time: 41.929s
[2K
| Adam | epoch: 013 | loss: 0.07620 - acc: 0.9909 -- iter: 160/190
[A[ATraining Step: 78  | total loss: [1m[32m0.06955[0m[0m | time: 52.989s
[2K
| Adam | epoch: 013 | loss: 0.06955 - acc: 0.9918 | val_loss: 0.68893 - val_acc: 0.7167 -- iter: 190/190
--
Training Step: 79  | total loss: [1m[32m0.06652[0m[0m | time: 8.353s
[2K
| Adam | epoch: 014 | loss: 0.06652 - acc: 0.9894 -- iter: 032/190
[A[ATraining Step: 80  | total loss: [1m[32m0.08205[0m[0m | time: 16.629s
[2K
| Adam | epoch: 014 | loss: 0.08205 - acc: 0.9873 -- iter: 064/190
[A[ATraining Step: 81  | total loss: [1m[32m0.07624[0m[0m | time: 24.910s
[2K
| Adam | epoch: 014 | loss: 0.07624 - acc: 0.9886 -- iter: 096/190
[A[ATraining Step: 82  | total loss: [1m[32m0.08271[0m[0m | time: 33.312s
[2K
| Adam | epoch: 014 | loss: 0.08271 - acc: 0.9866 -- iter: 128/190
[A[ATraining Step: 83  | total loss: [1m[32m0.07734[0m[0m | time: 41.272s
[2K
| Adam | epoch: 014 | loss: 0.07734 - acc: 0.9880 -- iter: 160/190
[A[ATraining Step: 84  | total loss: [1m[32m0.07129[0m[0m | time: 51.768s
[2K
| Adam | epoch: 014 | loss: 0.07129 - acc: 0.9892 | val_loss: 2.83594 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 85  | total loss: [1m[32m0.06543[0m[0m | time: 8.153s
[2K
| Adam | epoch: 015 | loss: 0.06543 - acc: 0.9902 -- iter: 032/190
[A[ATraining Step: 86  | total loss: [1m[32m0.06017[0m[0m | time: 16.369s
[2K
| Adam | epoch: 015 | loss: 0.06017 - acc: 0.9912 -- iter: 064/190
[A[ATraining Step: 87  | total loss: [1m[32m0.05550[0m[0m | time: 24.564s
[2K
| Adam | epoch: 015 | loss: 0.05550 - acc: 0.9921 -- iter: 096/190
[A[ATraining Step: 88  | total loss: [1m[32m0.05138[0m[0m | time: 32.821s
[2K
| Adam | epoch: 015 | loss: 0.05138 - acc: 0.9929 -- iter: 128/190
[A[ATraining Step: 89  | total loss: [1m[32m0.04752[0m[0m | time: 41.176s
[2K
| Adam | epoch: 015 | loss: 0.04752 - acc: 0.9936 -- iter: 160/190
[A[ATraining Step: 90  | total loss: [1m[32m0.04303[0m[0m | time: 51.768s
[2K
| Adam | epoch: 015 | loss: 0.04303 - acc: 0.9942 | val_loss: 4.02211 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 91  | total loss: [1m[32m0.03918[0m[0m | time: 8.168s
[2K
| Adam | epoch: 016 | loss: 0.03918 - acc: 0.9948 -- iter: 032/190
[A[ATraining Step: 92  | total loss: [1m[32m0.03573[0m[0m | time: 16.566s
[2K
| Adam | epoch: 016 | loss: 0.03573 - acc: 0.9953 -- iter: 064/190
[A[ATraining Step: 93  | total loss: [1m[32m0.03259[0m[0m | time: 24.928s
[2K
| Adam | epoch: 016 | loss: 0.03259 - acc: 0.9958 -- iter: 096/190
[A[ATraining Step: 94  | total loss: [1m[32m0.02970[0m[0m | time: 33.147s
[2K
| Adam | epoch: 016 | loss: 0.02970 - acc: 0.9962 -- iter: 128/190
[A[ATraining Step: 95  | total loss: [1m[32m0.02791[0m[0m | time: 41.500s
[2K
| Adam | epoch: 016 | loss: 0.02791 - acc: 0.9966 -- iter: 160/190
[A[ATraining Step: 96  | total loss: [1m[32m0.02532[0m[0m | time: 52.389s
[2K
| Adam | epoch: 016 | loss: 0.02532 - acc: 0.9969 | val_loss: 2.02393 - val_acc: 0.5500 -- iter: 190/190
--
Training Step: 97  | total loss: [1m[32m0.02328[0m[0m | time: 8.036s
[2K
| Adam | epoch: 017 | loss: 0.02328 - acc: 0.9972 -- iter: 032/190
[A[ATraining Step: 98  | total loss: [1m[32m0.02133[0m[0m | time: 15.787s
[2K
| Adam | epoch: 017 | loss: 0.02133 - acc: 0.9975 -- iter: 064/190
[A[ATraining Step: 99  | total loss: [1m[32m0.01950[0m[0m | time: 24.008s
[2K
| Adam | epoch: 017 | loss: 0.01950 - acc: 0.9978 -- iter: 096/190
[A[ATraining Step: 100  | total loss: [1m[32m0.01778[0m[0m | time: 32.347s
[2K
| Adam | epoch: 017 | loss: 0.01778 - acc: 0.9980 -- iter: 128/190
[A[ATraining Step: 101  | total loss: [1m[32m0.01618[0m[0m | time: 40.573s
[2K
| Adam | epoch: 017 | loss: 0.01618 - acc: 0.9982 -- iter: 160/190
[A[ATraining Step: 102  | total loss: [1m[32m0.01470[0m[0m | time: 51.339s
[2K
| Adam | epoch: 017 | loss: 0.01470 - acc: 0.9984 | val_loss: 0.44395 - val_acc: 0.8000 -- iter: 190/190
--
Training Step: 103  | total loss: [1m[32m0.01343[0m[0m | time: 8.218s
[2K
| Adam | epoch: 018 | loss: 0.01343 - acc: 0.9985 -- iter: 032/190
[A[ATraining Step: 104  | total loss: [1m[32m0.01224[0m[0m | time: 16.190s
[2K
| Adam | epoch: 018 | loss: 0.01224 - acc: 0.9987 -- iter: 064/190
[A[ATraining Step: 105  | total loss: [1m[32m0.01121[0m[0m | time: 24.041s
[2K
| Adam | epoch: 018 | loss: 0.01121 - acc: 0.9988 -- iter: 096/190
[A[ATraining Step: 106  | total loss: [1m[32m0.01029[0m[0m | time: 32.280s
[2K
| Adam | epoch: 018 | loss: 0.01029 - acc: 0.9989 -- iter: 128/190
[A[ATraining Step: 107  | total loss: [1m[32m0.00933[0m[0m | time: 40.477s
[2K
| Adam | epoch: 018 | loss: 0.00933 - acc: 0.9990 -- iter: 160/190
[A[ATraining Step: 108  | total loss: [1m[32m0.02922[0m[0m | time: 51.345s
[2K
| Adam | epoch: 018 | loss: 0.02922 - acc: 0.9960 | val_loss: 0.54201 - val_acc: 0.8833 -- iter: 190/190
--
Training Step: 109  | total loss: [1m[32m0.02639[0m[0m | time: 8.351s
[2K
| Adam | epoch: 019 | loss: 0.02639 - acc: 0.9964 -- iter: 032/190
[A[ATraining Step: 110  | total loss: [1m[32m0.02394[0m[0m | time: 16.685s
[2K
| Adam | epoch: 019 | loss: 0.02394 - acc: 0.9968 -- iter: 064/190
[A[ATraining Step: 111  | total loss: [1m[32m0.02172[0m[0m | time: 24.457s
[2K
| Adam | epoch: 019 | loss: 0.02172 - acc: 0.9971 -- iter: 096/190
[A[ATraining Step: 112  | total loss: [1m[32m0.01969[0m[0m | time: 32.168s
[2K
| Adam | epoch: 019 | loss: 0.01969 - acc: 0.9974 -- iter: 128/190
[A[ATraining Step: 113  | total loss: [1m[32m0.01795[0m[0m | time: 40.556s
[2K
| Adam | epoch: 019 | loss: 0.01795 - acc: 0.9976 -- iter: 160/190
[A[ATraining Step: 114  | total loss: [1m[32m0.07477[0m[0m | time: 51.452s
[2K
| Adam | epoch: 019 | loss: 0.07477 - acc: 0.9916 | val_loss: 0.57343 - val_acc: 0.8500 -- iter: 190/190
--
Training Step: 115  | total loss: [1m[32m0.09202[0m[0m | time: 8.113s
[2K
| Adam | epoch: 020 | loss: 0.09202 - acc: 0.9862 -- iter: 032/190
[A[ATraining Step: 116  | total loss: [1m[32m0.08313[0m[0m | time: 16.174s
[2K
| Adam | epoch: 020 | loss: 0.08313 - acc: 0.9876 -- iter: 064/190
[A[ATraining Step: 117  | total loss: [1m[32m0.07531[0m[0m | time: 24.371s
[2K
| Adam | epoch: 020 | loss: 0.07531 - acc: 0.9888 -- iter: 096/190
[A[ATraining Step: 118  | total loss: [1m[32m0.06908[0m[0m | time: 32.197s
[2K
| Adam | epoch: 020 | loss: 0.06908 - acc: 0.9900 -- iter: 128/190
[A[ATraining Step: 119  | total loss: [1m[32m0.07250[0m[0m | time: 39.835s
[2K
| Adam | epoch: 020 | loss: 0.07250 - acc: 0.9876 -- iter: 160/190
[A[ATraining Step: 120  | total loss: [1m[32m0.07228[0m[0m | time: 50.691s
[2K
| Adam | epoch: 020 | loss: 0.07228 - acc: 0.9855 | val_loss: 0.68792 - val_acc: 0.7667 -- iter: 190/190
--
Training Step: 121  | total loss: [1m[32m0.06620[0m[0m | time: 8.283s
[2K
| Adam | epoch: 021 | loss: 0.06620 - acc: 0.9870 -- iter: 032/190
[A[ATraining Step: 122  | total loss: [1m[32m0.10489[0m[0m | time: 16.478s
[2K
| Adam | epoch: 021 | loss: 0.10489 - acc: 0.9820 -- iter: 064/190
[A[ATraining Step: 123  | total loss: [1m[32m0.09687[0m[0m | time: 24.540s
[2K
| Adam | epoch: 021 | loss: 0.09687 - acc: 0.9838 -- iter: 096/190
[A[ATraining Step: 124  | total loss: [1m[32m0.08847[0m[0m | time: 32.903s
[2K
| Adam | epoch: 021 | loss: 0.08847 - acc: 0.9854 -- iter: 128/190
[A[ATraining Step: 125  | total loss: [1m[32m0.08222[0m[0m | time: 40.669s
[2K
| Adam | epoch: 021 | loss: 0.08222 - acc: 0.9869 -- iter: 160/190
[A[ATraining Step: 126  | total loss: [1m[32m0.07919[0m[0m | time: 51.132s
[2K
| Adam | epoch: 021 | loss: 0.07919 - acc: 0.9882 | val_loss: 3.76032 - val_acc: 0.5000 -- iter: 190/190
--
Training Step: 127  | total loss: [1m[32m0.07366[0m[0m | time: 8.297s
[2K
| Adam | epoch: 022 | loss: 0.07366 - acc: 0.9894 -- iter: 032/190
[A[ATraining Step: 128  | total loss: [1m[32m0.06754[0m[0m | time: 16.298s
[2K
| Adam | epoch: 022 | loss: 0.06754 - acc: 0.9904 -- iter: 064/190
[A[ATraining Step: 129  | total loss: [1m[32m0.07171[0m[0m | time: 24.364s
[2K
| Adam | epoch: 022 | loss: 0.07171 - acc: 0.9883 -- iter: 096/190
[A[ATraining Step: 130  | total loss: [1m[32m0.07121[0m[0m | time: 32.549s
[2K
| Adam | epoch: 022 | loss: 0.07121 - acc: 0.9863 -- iter: 128/190
[A[ATraining Step: 131  | total loss: [1m[32m0.06622[0m[0m | time: 40.645s
[2K
| Adam | epoch: 022 | loss: 0.06622 - acc: 0.9877 -- iter: 160/190
[A[ATraining Step: 132  | total loss: [1m[32m0.06615[0m[0m | time: 50.920s
[2K
| Adam | epoch: 022 | loss: 0.06615 - acc: 0.9858 | val_loss: 1.92299 - val_acc: 0.5833 -- iter: 190/190
--
Training Step: 133  | total loss: [1m[32m0.06106[0m[0m | time: 7.949s
[2K
| Adam | epoch: 023 | loss: 0.06106 - acc: 0.9872 -- iter: 032/190
[A[ATraining Step: 134  | total loss: [1m[32m0.05578[0m[0m | time: 16.191s
[2K
| Adam | epoch: 023 | loss: 0.05578 - acc: 0.9885 -- iter: 064/190
[A[ATraining Step: 135  | total loss: [1m[32m0.06474[0m[0m | time: 24.330s
[2K
| Adam | epoch: 023 | loss: 0.06474 - acc: 0.9865 -- iter: 096/190
[A[ATraining Step: 136  | total loss: [1m[32m0.06221[0m[0m | time: 32.823s
[2K
| Adam | epoch: 023 | loss: 0.06221 - acc: 0.9879 -- iter: 128/190
[A[ATraining Step: 137  | total loss: [1m[32m0.05942[0m[0m | time: 40.999s
[2K
| Adam | epoch: 023 | loss: 0.05942 - acc: 0.9891 -- iter: 160/190
[A[ATraining Step: 138  | total loss: [1m[32m0.05442[0m[0m | time: 51.972s
[2K
| Adam | epoch: 023 | loss: 0.05442 - acc: 0.9902 | val_loss: 0.32354 - val_acc: 0.9000 -- iter: 190/190
--
Training Step: 139  | total loss: [1m[32m0.04965[0m[0m | time: 10.211s
[2K
| Adam | epoch: 024 | loss: 0.04965 - acc: 0.9912 -- iter: 032/190
[A[ATraining Step: 140  | total loss: [1m[32m0.04715[0m[0m | time: 20.470s
[2K
| Adam | epoch: 024 | loss: 0.04715 - acc: 0.9920 -- iter: 064/190
[A[ATraining Step: 141  | total loss: [1m[32m0.04371[0m[0m | time: 36.022s
[2K
| Adam | epoch: 024 | loss: 0.04371 - acc: 0.9928 -- iter: 096/190
[A[ATraining Step: 142  | total loss: [1m[32m0.05135[0m[0m | time: 46.204s
[2K
| Adam | epoch: 024 | loss: 0.05135 - acc: 0.9873 -- iter: 128/190
[A[ATraining Step: 143  | total loss: [1m[32m0.04666[0m[0m | time: 61.298s
[2K
| Adam | epoch: 024 | loss: 0.04666 - acc: 0.9886 -- iter: 160/190
[A[ATraining Step: 144  | total loss: [1m[32m0.04318[0m[0m | time: 74.411s
[2K
| Adam | epoch: 024 | loss: 0.04318 - acc: 0.9897 | val_loss: 0.62358 - val_acc: 0.8333 -- iter: 190/190
--
Training Step: 145  | total loss: [1m[32m0.04368[0m[0m | time: 10.064s
[2K
| Adam | epoch: 025 | loss: 0.04368 - acc: 0.9876 -- iter: 032/190
[A[ATraining Step: 146  | total loss: [1m[32m0.03966[0m[0m | time: 20.005s
[2K
| Adam | epoch: 025 | loss: 0.03966 - acc: 0.9889 -- iter: 064/190
[A[ATraining Step: 147  | total loss: [1m[32m0.03850[0m[0m | time: 28.855s
[2K
| Adam | epoch: 025 | loss: 0.03850 - acc: 0.9900 -- iter: 096/190
[A[ATraining Step: 148  | total loss: [1m[32m0.03527[0m[0m | time: 39.093s
[2K
| Adam | epoch: 025 | loss: 0.03527 - acc: 0.9910 -- iter: 128/190
[A[ATraining Step: 149  | total loss: [1m[32m0.03190[0m[0m | time: 48.890s
[2K
| Adam | epoch: 025 | loss: 0.03190 - acc: 0.9919 -- iter: 160/190
[A[ATraining Step: 150  | total loss: [1m[32m0.05151[0m[0m | time: 63.780s
[2K
| Adam | epoch: 025 | loss: 0.05151 - acc: 0.9864 | val_loss: 0.52470 - val_acc: 0.8833 -- iter: 190/190
--
Training Step: 151  | total loss: [1m[32m0.04677[0m[0m | time: 9.921s
[2K
| Adam | epoch: 026 | loss: 0.04677 - acc: 0.9878 -- iter: 032/190
[A[ATraining Step: 152  | total loss: [1m[32m0.04510[0m[0m | time: 21.363s
[2K
| Adam | epoch: 026 | loss: 0.04510 - acc: 0.9859 -- iter: 064/190
[A[ATraining Step: 153  | total loss: [1m[32m0.04343[0m[0m | time: 31.111s
[2K
| Adam | epoch: 026 | loss: 0.04343 - acc: 0.9873 -- iter: 096/190
[A[ATraining Step: 154  | total loss: [1m[32m0.04281[0m[0m | time: 40.524s
[2K
| Adam | epoch: 026 | loss: 0.04281 - acc: 0.9886 -- iter: 128/190
[A[ATraining Step: 155  | total loss: [1m[32m0.04024[0m[0m | time: 50.576s
[2K
| Adam | epoch: 026 | loss: 0.04024 - acc: 0.9897 -- iter: 160/190
[A[ATraining Step: 156  | total loss: [1m[32m0.03757[0m[0m | time: 64.759s
[2K
| Adam | epoch: 026 | loss: 0.03757 - acc: 0.9907 | val_loss: 0.88267 - val_acc: 0.7833 -- iter: 190/190
--
Training Step: 157  | total loss: [1m[32m0.03443[0m[0m | time: 10.088s
[2K
| Adam | epoch: 027 | loss: 0.03443 - acc: 0.9917 -- iter: 032/190
[A[ATraining Step: 158  | total loss: [1m[32m0.03199[0m[0m | time: 20.050s
[2K
| Adam | epoch: 027 | loss: 0.03199 - acc: 0.9925 -- iter: 064/190
[A[ATraining Step: 159  | total loss: [1m[32m0.03054[0m[0m | time: 29.858s
[2K
| Adam | epoch: 027 | loss: 0.03054 - acc: 0.9933 -- iter: 096/190
[A[ATraining Step: 160  | total loss: [1m[32m0.03808[0m[0m | time: 39.337s
[2K
| Adam | epoch: 027 | loss: 0.03808 - acc: 0.9908 -- iter: 128/190
[A[ATraining Step: 161  | total loss: [1m[32m0.03449[0m[0m | time: 49.032s
[2K
| Adam | epoch: 027 | loss: 0.03449 - acc: 0.9917 -- iter: 160/190
[A[ATraining Step: 162  | total loss: [1m[32m0.03127[0m[0m | time: 62.636s
[2K
| Adam | epoch: 027 | loss: 0.03127 - acc: 0.9925 | val_loss: 1.05655 - val_acc: 0.7333 -- iter: 190/190
--
Training Step: 163  | total loss: [1m[32m0.02912[0m[0m | time: 10.028s
[2K
| Adam | epoch: 028 | loss: 0.02912 - acc: 0.9933 -- iter: 032/190
[A[ATraining Step: 164  | total loss: [1m[32m0.06172[0m[0m | time: 20.373s
[2K
| Adam | epoch: 028 | loss: 0.06172 - acc: 0.9908 -- iter: 064/190
[A[ATraining Step: 165  | total loss: [1m[32m0.05616[0m[0m | time: 35.011s
[2K
| Adam | epoch: 028 | loss: 0.05616 - acc: 0.9918 -- iter: 096/190
[A[ATraining Step: 166  | total loss: [1m[32m0.05166[0m[0m | time: 45.180s
[2K
| Adam | epoch: 028 | loss: 0.05166 - acc: 0.9926 -- iter: 128/190
[A[ATraining Step: 167  | total loss: [1m[32m0.07394[0m[0m | time: 54.396s
[2K
| Adam | epoch: 028 | loss: 0.07394 - acc: 0.9839 -- iter: 160/190
[A[ATraining Step: 168  | total loss: [1m[32m0.07036[0m[0m | time: 66.675s
[2K
| Adam | epoch: 028 | loss: 0.07036 - acc: 0.9856 | val_loss: 0.48556 - val_acc: 0.8333 -- iter: 190/190
--
Training Step: 169  | total loss: [1m[32m0.06517[0m[0m | time: 9.858s
[2K
| Adam | epoch: 029 | loss: 0.06517 - acc: 0.9870 -- iter: 032/190
[A[ATraining Step: 170  | total loss: [1m[32m0.05923[0m[0m | time: 20.235s
[2K
| Adam | epoch: 029 | loss: 0.05923 - acc: 0.9883 -- iter: 064/190
[A[ATraining Step: 171  | total loss: [1m[32m0.05516[0m[0m | time: 31.347s
[2K
| Adam | epoch: 029 | loss: 0.05516 - acc: 0.9895 -- iter: 096/190
[A[ATraining Step: 172  | total loss: [1m[32m0.05148[0m[0m | time: 40.630s
[2K
| Adam | epoch: 029 | loss: 0.05148 - acc: 0.9905 -- iter: 128/190
[A[ATraining Step: 173  | total loss: [1m[32m0.04713[0m[0m | time: 54.549s
[2K
| Adam | epoch: 029 | loss: 0.04713 - acc: 0.9915 -- iter: 160/190
[A[ATraining Step: 174  | total loss: [1m[32m0.04323[0m[0m | time: 67.282s
[2K
| Adam | epoch: 029 | loss: 0.04323 - acc: 0.9923 | val_loss: 0.31904 - val_acc: 0.8500 -- iter: 190/190
--
Training Step: 175  | total loss: [1m[32m0.04977[0m[0m | time: 7.649s
[2K
| Adam | epoch: 030 | loss: 0.04977 - acc: 0.9898 -- iter: 032/190
[A[ATraining Step: 176  | total loss: [1m[32m0.04732[0m[0m | time: 15.697s
[2K
| Adam | epoch: 030 | loss: 0.04732 - acc: 0.9908 -- iter: 064/190
[A[ATraining Step: 177  | total loss: [1m[32m0.04309[0m[0m | time: 23.708s
[2K
| Adam | epoch: 030 | loss: 0.04309 - acc: 0.9917 -- iter: 096/190
[A[ATraining Step: 178  | total loss: [1m[32m0.04250[0m[0m | time: 31.716s
[2K
| Adam | epoch: 030 | loss: 0.04250 - acc: 0.9894 -- iter: 128/190
[A[ATraining Step: 179  | total loss: [1m[32m0.03940[0m[0m | time: 39.856s
[2K
| Adam | epoch: 030 | loss: 0.03940 - acc: 0.9905 -- iter: 160/190
[A[ATraining Step: 180  | total loss: [1m[32m0.04072[0m[0m | time: 50.769s
[2K
| Adam | epoch: 030 | loss: 0.04072 - acc: 0.9883 | val_loss: 0.90872 - val_acc: 0.7833 -- iter: 190/190
--
Validation AUC:0.9644444444444444
Validation AUPRC:0.9629813220257556
Test AUC:0.9473684210526315
Test AUPRC:0.9124702371213655
BestTestF1Score	0.95	0.86	0.93	0.95	0.95	36	2	20	2	0.98
BestTestMCCScore	0.95	0.86	0.93	0.95	0.95	36	2	20	2	0.98
BestTestAccuracyScore	0.95	0.86	0.93	0.95	0.95	36	2	20	2	0.98
BestValidationF1Score	0.92	0.85	0.92	0.86	1.0	30	5	25	0	0.98
BestValidationMCC	0.92	0.85	0.92	0.86	1.0	30	5	25	0	0.98
BestValidationAccuracy	0.92	0.85	0.92	0.86	1.0	30	5	25	0	0.98
TestPredictions (Threshold:0.98)
CHEMBL2041376,TP,ACT,1.0	CHEMBL188874,TP,ACT,1.0	CHEMBL210465,TN,INACT,0.7699999809265137	CHEMBL219575,TN,INACT,0.27000001072883606	CHEMBL372900,TP,ACT,1.0	CHEMBL459976,TP,ACT,1.0	CHEMBL307621,FP,INACT,1.0	CHEMBL2170758,TP,ACT,1.0	CHEMBL394884,TN,INACT,0.029999999329447746	CHEMBL3342513,TP,ACT,1.0	CHEMBL3741469,TP,ACT,1.0	CHEMBL1915940,TP,ACT,1.0	CHEMBL276915,FP,INACT,1.0	CHEMBL116438,TN,INACT,0.0	CHEMBL215844,TP,ACT,1.0	CHEMBL441370,TN,INACT,0.6899999976158142	CHEMBL1917881,FN,ACT,0.9700000286102295	CHEMBL1928186,TP,ACT,1.0	CHEMBL2170755,TP,ACT,1.0	CHEMBL1163685,TN,INACT,0.10000000149011612	CHEMBL373792,TN,INACT,0.10999999940395355	CHEMBL3741097,FN,ACT,0.9599999785423279	CHEMBL462513,TP,ACT,1.0	CHEMBL2170753,TP,ACT,1.0	CHEMBL219712,TN,INACT,0.8399999737739563	CHEMBL246057,TN,INACT,0.8100000023841858	CHEMBL1917898,TP,ACT,1.0	CHEMBL382614,TN,INACT,0.6899999976158142	CHEMBL2170746,TP,ACT,1.0	CHEMBL1915937,TP,ACT,1.0	CHEMBL191305,TP,ACT,1.0	CHEMBL437522,TN,INACT,0.009999999776482582	CHEMBL467151,TP,ACT,1.0	CHEMBL246677,TN,INACT,0.019999999552965164	CHEMBL2041361,TP,ACT,1.0	CHEMBL1644043,TP,ACT,1.0	CHEMBL1277802,TP,ACT,1.0	CHEMBL380677,TN,INACT,0.009999999776482582	CHEMBL396925,TN,INACT,0.9399999976158142	CHEMBL1096375,TP,ACT,1.0	CHEMBL3629436,TP,ACT,1.0	CHEMBL188446,TP,ACT,1.0	CHEMBL2324367,TP,ACT,1.0	CHEMBL218569,TN,INACT,0.05999999865889549	CHEMBL577338,TP,ACT,1.0	CHEMBL2436738,TP,ACT,1.0	CHEMBL1915949,TP,ACT,1.0	CHEMBL3629435,TP,ACT,1.0	CHEMBL3339193,TN,INACT,0.18000000715255737	CHEMBL214150,TN,INACT,0.7300000190734863	CHEMBL223083,TN,INACT,0.07000000029802322	CHEMBL2041375,TP,ACT,1.0	CHEMBL364812,TP,ACT,1.0	CHEMBL3629444,TP,ACT,1.0	CHEMBL3629454,TP,ACT,1.0	CHEMBL247768,TN,INACT,0.0	CHEMBL189184,TP,ACT,1.0	CHEMBL363257,TP,ACT,1.0	CHEMBL555375,TN,INACT,0.05000000074505806	CHEMBL1928181,TP,ACT,1.0	

