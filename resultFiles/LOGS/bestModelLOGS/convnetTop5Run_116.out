CNNModel CHEMBL3687 adam 0.0005 30 256 0 0.6 False True
Number of active compounds :	113
Number of inactive compounds :	113
---------------------------------
Run id: CNNModel_CHEMBL3687_adam_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3687_adam_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 144
Validation samples: 46
--
Training Step: 1  | time: 0.806s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/144
[A[ATraining Step: 2  | total loss: [1m[32m0.62376[0m[0m | time: 1.414s
[2K
| Adam | epoch: 001 | loss: 0.62376 - acc: 0.5062 -- iter: 064/144
[A[ATraining Step: 3  | total loss: [1m[32m0.68170[0m[0m | time: 2.023s
[2K
| Adam | epoch: 001 | loss: 0.68170 - acc: 0.3733 -- iter: 096/144
[A[ATraining Step: 4  | total loss: [1m[32m0.69020[0m[0m | time: 2.623s
[2K
| Adam | epoch: 001 | loss: 0.69020 - acc: 0.4918 -- iter: 128/144
[A[ATraining Step: 5  | total loss: [1m[32m0.69112[0m[0m | time: 3.986s
[2K
| Adam | epoch: 001 | loss: 0.69112 - acc: 0.5407 | val_loss: 0.69707 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 6  | total loss: [1m[32m0.69784[0m[0m | time: 0.345s
[2K
| Adam | epoch: 002 | loss: 0.69784 - acc: 0.4342 -- iter: 032/144
[A[ATraining Step: 7  | total loss: [1m[32m0.69849[0m[0m | time: 0.982s
[2K
| Adam | epoch: 002 | loss: 0.69849 - acc: 0.3987 -- iter: 064/144
[A[ATraining Step: 8  | total loss: [1m[32m0.69585[0m[0m | time: 1.602s
[2K
| Adam | epoch: 002 | loss: 0.69585 - acc: 0.4381 -- iter: 096/144
[A[ATraining Step: 9  | total loss: [1m[32m0.69392[0m[0m | time: 2.218s
[2K
| Adam | epoch: 002 | loss: 0.69392 - acc: 0.5370 -- iter: 128/144
[A[ATraining Step: 10  | total loss: [1m[32m0.69336[0m[0m | time: 3.839s
[2K
| Adam | epoch: 002 | loss: 0.69336 - acc: 0.5498 | val_loss: 0.69426 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 11  | total loss: [1m[32m0.69278[0m[0m | time: 0.323s
[2K
| Adam | epoch: 003 | loss: 0.69278 - acc: 0.5854 -- iter: 032/144
[A[ATraining Step: 12  | total loss: [1m[32m0.69387[0m[0m | time: 0.664s
[2K
| Adam | epoch: 003 | loss: 0.69387 - acc: 0.4626 -- iter: 064/144
[A[ATraining Step: 13  | total loss: [1m[32m0.69447[0m[0m | time: 1.262s
[2K
| Adam | epoch: 003 | loss: 0.69447 - acc: 0.3983 -- iter: 096/144
[A[ATraining Step: 14  | total loss: [1m[32m0.69417[0m[0m | time: 1.901s
[2K
| Adam | epoch: 003 | loss: 0.69417 - acc: 0.4143 -- iter: 128/144
[A[ATraining Step: 15  | total loss: [1m[32m0.69357[0m[0m | time: 3.501s
[2K
| Adam | epoch: 003 | loss: 0.69357 - acc: 0.4845 | val_loss: 0.69328 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 16  | total loss: [1m[32m0.69347[0m[0m | time: 0.599s
[2K
| Adam | epoch: 004 | loss: 0.69347 - acc: 0.4669 -- iter: 032/144
[A[ATraining Step: 17  | total loss: [1m[32m0.69335[0m[0m | time: 0.917s
[2K
| Adam | epoch: 004 | loss: 0.69335 - acc: 0.4901 -- iter: 064/144
[A[ATraining Step: 18  | total loss: [1m[32m0.69322[0m[0m | time: 1.233s
[2K
| Adam | epoch: 004 | loss: 0.69322 - acc: 0.5368 -- iter: 096/144
[A[ATraining Step: 19  | total loss: [1m[32m0.69321[0m[0m | time: 1.889s
[2K
| Adam | epoch: 004 | loss: 0.69321 - acc: 0.4828 -- iter: 128/144
[A[ATraining Step: 20  | total loss: [1m[32m0.69319[0m[0m | time: 3.622s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.5185 | val_loss: 0.69340 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 21  | total loss: [1m[32m0.69320[0m[0m | time: 0.614s
[2K
| Adam | epoch: 005 | loss: 0.69320 - acc: 0.5031 -- iter: 032/144
[A[ATraining Step: 22  | total loss: [1m[32m0.69307[0m[0m | time: 1.227s
[2K
| Adam | epoch: 005 | loss: 0.69307 - acc: 0.5396 -- iter: 064/144
[A[ATraining Step: 23  | total loss: [1m[32m0.69320[0m[0m | time: 1.537s
[2K
| Adam | epoch: 005 | loss: 0.69320 - acc: 0.5100 -- iter: 096/144
[A[ATraining Step: 24  | total loss: [1m[32m0.69303[0m[0m | time: 1.845s
[2K
| Adam | epoch: 005 | loss: 0.69303 - acc: 0.5248 -- iter: 128/144
[A[ATraining Step: 25  | total loss: [1m[32m0.69301[0m[0m | time: 3.464s
[2K
| Adam | epoch: 005 | loss: 0.69301 - acc: 0.5350 | val_loss: 0.69405 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 26  | total loss: [1m[32m0.69285[0m[0m | time: 0.644s
[2K
| Adam | epoch: 006 | loss: 0.69285 - acc: 0.5506 -- iter: 032/144
[A[ATraining Step: 27  | total loss: [1m[32m0.69311[0m[0m | time: 1.253s
[2K
| Adam | epoch: 006 | loss: 0.69311 - acc: 0.5215 -- iter: 064/144
[A[ATraining Step: 28  | total loss: [1m[32m0.69278[0m[0m | time: 1.895s
[2K
| Adam | epoch: 006 | loss: 0.69278 - acc: 0.5474 -- iter: 096/144
[A[ATraining Step: 29  | total loss: [1m[32m0.69292[0m[0m | time: 2.215s
[2K
| Adam | epoch: 006 | loss: 0.69292 - acc: 0.5283 -- iter: 128/144
[A[ATraining Step: 30  | total loss: [1m[32m0.69326[0m[0m | time: 3.538s
[2K
| Adam | epoch: 006 | loss: 0.69326 - acc: 0.5068 | val_loss: 0.69461 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 31  | total loss: [1m[32m0.69344[0m[0m | time: 0.619s
[2K
| Adam | epoch: 007 | loss: 0.69344 - acc: 0.4908 -- iter: 032/144
[A[ATraining Step: 32  | total loss: [1m[32m0.69305[0m[0m | time: 1.213s
[2K
| Adam | epoch: 007 | loss: 0.69305 - acc: 0.5139 -- iter: 064/144
[A[ATraining Step: 33  | total loss: [1m[32m0.69321[0m[0m | time: 1.851s
[2K
| Adam | epoch: 007 | loss: 0.69321 - acc: 0.5040 -- iter: 096/144
[A[ATraining Step: 34  | total loss: [1m[32m0.69261[0m[0m | time: 2.456s
[2K
| Adam | epoch: 007 | loss: 0.69261 - acc: 0.5366 -- iter: 128/144
[A[ATraining Step: 35  | total loss: [1m[32m0.69207[0m[0m | time: 3.776s
[2K
| Adam | epoch: 007 | loss: 0.69207 - acc: 0.5617 | val_loss: 0.69564 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 36  | total loss: [1m[32m0.69200[0m[0m | time: 0.348s
[2K
| Adam | epoch: 008 | loss: 0.69200 - acc: 0.5618 -- iter: 032/144
[A[ATraining Step: 37  | total loss: [1m[32m0.69194[0m[0m | time: 0.956s
[2K
| Adam | epoch: 008 | loss: 0.69194 - acc: 0.5620 -- iter: 064/144
[A[ATraining Step: 38  | total loss: [1m[32m0.69256[0m[0m | time: 1.592s
[2K
| Adam | epoch: 008 | loss: 0.69256 - acc: 0.5376 -- iter: 096/144
[A[ATraining Step: 39  | total loss: [1m[32m0.69377[0m[0m | time: 2.216s
[2K
| Adam | epoch: 008 | loss: 0.69377 - acc: 0.5005 -- iter: 128/144
[A[ATraining Step: 40  | total loss: [1m[32m0.69305[0m[0m | time: 3.824s
[2K
| Adam | epoch: 008 | loss: 0.69305 - acc: 0.5180 | val_loss: 0.69653 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 41  | total loss: [1m[32m0.69274[0m[0m | time: 0.328s
[2K
| Adam | epoch: 009 | loss: 0.69274 - acc: 0.5262 -- iter: 032/144
[A[ATraining Step: 42  | total loss: [1m[32m0.69283[0m[0m | time: 0.640s
[2K
| Adam | epoch: 009 | loss: 0.69283 - acc: 0.5215 -- iter: 064/144
[A[ATraining Step: 43  | total loss: [1m[32m0.69287[0m[0m | time: 1.241s
[2K
| Adam | epoch: 009 | loss: 0.69287 - acc: 0.5177 -- iter: 096/144
[A[ATraining Step: 44  | total loss: [1m[32m0.69276[0m[0m | time: 1.856s
[2K
| Adam | epoch: 009 | loss: 0.69276 - acc: 0.5200 -- iter: 128/144
[A[ATraining Step: 45  | total loss: [1m[32m0.69322[0m[0m | time: 3.468s
[2K
| Adam | epoch: 009 | loss: 0.69322 - acc: 0.5060 | val_loss: 0.69684 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 46  | total loss: [1m[32m0.69325[0m[0m | time: 0.592s
[2K
| Adam | epoch: 010 | loss: 0.69325 - acc: 0.5050 -- iter: 032/144
[A[ATraining Step: 47  | total loss: [1m[32m0.69328[0m[0m | time: 0.903s
[2K
| Adam | epoch: 010 | loss: 0.69328 - acc: 0.5042 -- iter: 064/144
[A[ATraining Step: 48  | total loss: [1m[32m0.69249[0m[0m | time: 1.238s
[2K
| Adam | epoch: 010 | loss: 0.69249 - acc: 0.5236 -- iter: 096/144
[A[ATraining Step: 49  | total loss: [1m[32m0.69191[0m[0m | time: 1.824s
[2K
| Adam | epoch: 010 | loss: 0.69191 - acc: 0.5396 -- iter: 128/144
[A[ATraining Step: 50  | total loss: [1m[32m0.69166[0m[0m | time: 3.442s
[2K
| Adam | epoch: 010 | loss: 0.69166 - acc: 0.5432 | val_loss: 0.69829 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 51  | total loss: [1m[32m0.69191[0m[0m | time: 0.617s
[2K
| Adam | epoch: 011 | loss: 0.69191 - acc: 0.5366 -- iter: 032/144
[A[ATraining Step: 52  | total loss: [1m[32m0.69237[0m[0m | time: 1.213s
[2K
| Adam | epoch: 011 | loss: 0.69237 - acc: 0.5264 -- iter: 064/144
[A[ATraining Step: 53  | total loss: [1m[32m0.69114[0m[0m | time: 1.526s
[2K
| Adam | epoch: 011 | loss: 0.69114 - acc: 0.5456 -- iter: 096/144
[A[ATraining Step: 54  | total loss: [1m[32m0.69267[0m[0m | time: 1.867s
[2K
| Adam | epoch: 011 | loss: 0.69267 - acc: 0.5208 -- iter: 128/144
[A[ATraining Step: 55  | total loss: [1m[32m0.69398[0m[0m | time: 3.475s
[2K
| Adam | epoch: 011 | loss: 0.69398 - acc: 0.5000 | val_loss: 0.69867 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 56  | total loss: [1m[32m0.69362[0m[0m | time: 0.853s
[2K
| Adam | epoch: 012 | loss: 0.69362 - acc: 0.5044 -- iter: 032/144
[A[ATraining Step: 57  | total loss: [1m[32m0.69331[0m[0m | time: 1.454s
[2K
| Adam | epoch: 012 | loss: 0.69331 - acc: 0.5081 -- iter: 064/144
[A[ATraining Step: 58  | total loss: [1m[32m0.69334[0m[0m | time: 2.085s
[2K
| Adam | epoch: 012 | loss: 0.69334 - acc: 0.5070 -- iter: 096/144
[A[ATraining Step: 59  | total loss: [1m[32m0.69315[0m[0m | time: 2.427s
[2K
| Adam | epoch: 012 | loss: 0.69315 - acc: 0.5102 -- iter: 128/144
[A[ATraining Step: 60  | total loss: [1m[32m0.69317[0m[0m | time: 3.769s
[2K
| Adam | epoch: 012 | loss: 0.69317 - acc: 0.5089 | val_loss: 0.69785 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 61  | total loss: [1m[32m0.69316[0m[0m | time: 0.641s
[2K
| Adam | epoch: 013 | loss: 0.69316 - acc: 0.5077 -- iter: 032/144
[A[ATraining Step: 62  | total loss: [1m[32m0.69272[0m[0m | time: 1.255s
[2K
| Adam | epoch: 013 | loss: 0.69272 - acc: 0.5148 -- iter: 064/144
[A[ATraining Step: 63  | total loss: [1m[32m0.69257[0m[0m | time: 1.862s
[2K
| Adam | epoch: 013 | loss: 0.69257 - acc: 0.5169 -- iter: 096/144
[A[ATraining Step: 64  | total loss: [1m[32m0.69283[0m[0m | time: 2.462s
[2K
| Adam | epoch: 013 | loss: 0.69283 - acc: 0.5108 -- iter: 128/144
[A[ATraining Step: 65  | total loss: [1m[32m0.69310[0m[0m | time: 3.802s
[2K
| Adam | epoch: 013 | loss: 0.69310 - acc: 0.5057 | val_loss: 0.69789 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 66  | total loss: [1m[32m0.69270[0m[0m | time: 0.328s
[2K
| Adam | epoch: 014 | loss: 0.69270 - acc: 0.5126 -- iter: 032/144
[A[ATraining Step: 67  | total loss: [1m[32m0.69236[0m[0m | time: 0.939s
[2K
| Adam | epoch: 014 | loss: 0.69236 - acc: 0.5186 -- iter: 064/144
[A[ATraining Step: 68  | total loss: [1m[32m0.69187[0m[0m | time: 1.559s
[2K
| Adam | epoch: 014 | loss: 0.69187 - acc: 0.5275 -- iter: 096/144
[A[ATraining Step: 69  | total loss: [1m[32m0.69156[0m[0m | time: 2.180s
[2K
| Adam | epoch: 014 | loss: 0.69156 - acc: 0.5316 -- iter: 128/144
[A[ATraining Step: 70  | total loss: [1m[32m0.69226[0m[0m | time: 3.796s
[2K
| Adam | epoch: 014 | loss: 0.69226 - acc: 0.5207 | val_loss: 0.69970 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 71  | total loss: [1m[32m0.69167[0m[0m | time: 0.325s
[2K
| Adam | epoch: 015 | loss: 0.69167 - acc: 0.5290 -- iter: 032/144
[A[ATraining Step: 72  | total loss: [1m[32m0.69183[0m[0m | time: 0.665s
[2K
| Adam | epoch: 015 | loss: 0.69183 - acc: 0.5258 -- iter: 064/144
[A[ATraining Step: 73  | total loss: [1m[32m0.69191[0m[0m | time: 1.273s
[2K
| Adam | epoch: 015 | loss: 0.69191 - acc: 0.5229 -- iter: 096/144
[A[ATraining Step: 74  | total loss: [1m[32m0.69233[0m[0m | time: 1.896s
[2K
| Adam | epoch: 015 | loss: 0.69233 - acc: 0.5170 -- iter: 128/144
[A[ATraining Step: 75  | total loss: [1m[32m0.69131[0m[0m | time: 3.501s
[2K
| Adam | epoch: 015 | loss: 0.69131 - acc: 0.5287 | val_loss: 0.70270 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 76  | total loss: [1m[32m0.69119[0m[0m | time: 0.618s
[2K
| Adam | epoch: 016 | loss: 0.69119 - acc: 0.5289 -- iter: 032/144
[A[ATraining Step: 77  | total loss: [1m[32m0.68994[0m[0m | time: 0.925s
[2K
| Adam | epoch: 016 | loss: 0.68994 - acc: 0.5391 -- iter: 064/144
[A[ATraining Step: 78  | total loss: [1m[32m0.69297[0m[0m | time: 1.264s
[2K
| Adam | epoch: 016 | loss: 0.69297 - acc: 0.5154 -- iter: 096/144
[A[ATraining Step: 79  | total loss: [1m[32m0.69515[0m[0m | time: 1.897s
[2K
| Adam | epoch: 016 | loss: 0.69515 - acc: 0.4944 -- iter: 128/144
[A[ATraining Step: 80  | total loss: [1m[32m0.69530[0m[0m | time: 3.514s
[2K
| Adam | epoch: 016 | loss: 0.69530 - acc: 0.4918 | val_loss: 0.69861 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 81  | total loss: [1m[32m0.69426[0m[0m | time: 0.635s
[2K
| Adam | epoch: 017 | loss: 0.69426 - acc: 0.5021 -- iter: 032/144
[A[ATraining Step: 82  | total loss: [1m[32m0.69472[0m[0m | time: 1.235s
[2K
| Adam | epoch: 017 | loss: 0.69472 - acc: 0.4925 -- iter: 064/144
[A[ATraining Step: 83  | total loss: [1m[32m0.69436[0m[0m | time: 1.554s
[2K
| Adam | epoch: 017 | loss: 0.69436 - acc: 0.4964 -- iter: 096/144
[A[ATraining Step: 84  | total loss: [1m[32m0.69323[0m[0m | time: 1.864s
[2K
| Adam | epoch: 017 | loss: 0.69323 - acc: 0.5155 -- iter: 128/144
[A[ATraining Step: 85  | total loss: [1m[32m0.69228[0m[0m | time: 3.467s
[2K
| Adam | epoch: 017 | loss: 0.69228 - acc: 0.5327 | val_loss: 0.69688 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 86  | total loss: [1m[32m0.69205[0m[0m | time: 0.587s
[2K
| Adam | epoch: 018 | loss: 0.69205 - acc: 0.5326 -- iter: 032/144
[A[ATraining Step: 87  | total loss: [1m[32m0.69178[0m[0m | time: 1.222s
[2K
| Adam | epoch: 018 | loss: 0.69178 - acc: 0.5355 -- iter: 064/144
[A[ATraining Step: 88  | total loss: [1m[32m0.69144[0m[0m | time: 1.849s
[2K
| Adam | epoch: 018 | loss: 0.69144 - acc: 0.5382 -- iter: 096/144
[A[ATraining Step: 89  | total loss: [1m[32m0.69109[0m[0m | time: 2.178s
[2K
| Adam | epoch: 018 | loss: 0.69109 - acc: 0.5407 -- iter: 128/144
[A[ATraining Step: 90  | total loss: [1m[32m0.69075[0m[0m | time: 3.486s
[2K
| Adam | epoch: 018 | loss: 0.69075 - acc: 0.5429 | val_loss: 0.69846 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 91  | total loss: [1m[32m0.69039[0m[0m | time: 0.635s
[2K
| Adam | epoch: 019 | loss: 0.69039 - acc: 0.5448 -- iter: 032/144
[A[ATraining Step: 92  | total loss: [1m[32m0.69036[0m[0m | time: 1.235s
[2K
| Adam | epoch: 019 | loss: 0.69036 - acc: 0.5435 -- iter: 064/144
[A[ATraining Step: 93  | total loss: [1m[32m0.69108[0m[0m | time: 1.842s
[2K
| Adam | epoch: 019 | loss: 0.69108 - acc: 0.5329 -- iter: 096/144
[A[ATraining Step: 94  | total loss: [1m[32m0.69130[0m[0m | time: 2.418s
[2K
| Adam | epoch: 019 | loss: 0.69130 - acc: 0.5265 -- iter: 128/144
[A[ATraining Step: 95  | total loss: [1m[32m0.69096[0m[0m | time: 3.749s
[2K
| Adam | epoch: 019 | loss: 0.69096 - acc: 0.5269 | val_loss: 0.69683 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 96  | total loss: [1m[32m0.69149[0m[0m | time: 0.324s
[2K
| Adam | epoch: 020 | loss: 0.69149 - acc: 0.5180 -- iter: 032/144
[A[ATraining Step: 97  | total loss: [1m[32m0.69189[0m[0m | time: 0.946s
[2K
| Adam | epoch: 020 | loss: 0.69189 - acc: 0.5099 -- iter: 064/144
[A[ATraining Step: 98  | total loss: [1m[32m0.69163[0m[0m | time: 1.544s
[2K
| Adam | epoch: 020 | loss: 0.69163 - acc: 0.5089 -- iter: 096/144
[A[ATraining Step: 99  | total loss: [1m[32m0.69033[0m[0m | time: 2.151s
[2K
| Adam | epoch: 020 | loss: 0.69033 - acc: 0.5237 -- iter: 128/144
[A[ATraining Step: 100  | total loss: [1m[32m0.69002[0m[0m | time: 3.765s
[2K
| Adam | epoch: 020 | loss: 0.69002 - acc: 0.5213 | val_loss: 0.69787 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 101  | total loss: [1m[32m0.68989[0m[0m | time: 0.319s
[2K
| Adam | epoch: 021 | loss: 0.68989 - acc: 0.5192 -- iter: 032/144
[A[ATraining Step: 102  | total loss: [1m[32m0.68759[0m[0m | time: 0.624s
[2K
| Adam | epoch: 021 | loss: 0.68759 - acc: 0.5360 -- iter: 064/144
[A[ATraining Step: 103  | total loss: [1m[32m0.68460[0m[0m | time: 1.252s
[2K
| Adam | epoch: 021 | loss: 0.68460 - acc: 0.5512 -- iter: 096/144
[A[ATraining Step: 104  | total loss: [1m[32m0.68231[0m[0m | time: 1.853s
[2K
| Adam | epoch: 021 | loss: 0.68231 - acc: 0.5554 -- iter: 128/144
[A[ATraining Step: 105  | total loss: [1m[32m0.68493[0m[0m | time: 3.462s
[2K
| Adam | epoch: 021 | loss: 0.68493 - acc: 0.5436 | val_loss: 0.72104 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 106  | total loss: [1m[32m0.68161[0m[0m | time: 0.604s
[2K
| Adam | epoch: 022 | loss: 0.68161 - acc: 0.5486 -- iter: 032/144
[A[ATraining Step: 107  | total loss: [1m[32m0.68171[0m[0m | time: 0.940s
[2K
| Adam | epoch: 022 | loss: 0.68171 - acc: 0.5438 -- iter: 064/144
[A[ATraining Step: 108  | total loss: [1m[32m0.68415[0m[0m | time: 1.250s
[2K
| Adam | epoch: 022 | loss: 0.68415 - acc: 0.5331 -- iter: 096/144
[A[ATraining Step: 109  | total loss: [1m[32m0.68448[0m[0m | time: 1.859s
[2K
| Adam | epoch: 022 | loss: 0.68448 - acc: 0.5236 -- iter: 128/144
[A[ATraining Step: 110  | total loss: [1m[32m0.68186[0m[0m | time: 3.600s
[2K
| Adam | epoch: 022 | loss: 0.68186 - acc: 0.5368 | val_loss: 0.67864 - val_acc: 0.4130 -- iter: 144/144
--
Training Step: 111  | total loss: [1m[32m0.68186[0m[0m | time: 0.636s
[2K
| Adam | epoch: 023 | loss: 0.68186 - acc: 0.5238 -- iter: 032/144
[A[ATraining Step: 112  | total loss: [1m[32m0.67931[0m[0m | time: 1.234s
[2K
| Adam | epoch: 023 | loss: 0.67931 - acc: 0.5308 -- iter: 064/144
[A[ATraining Step: 113  | total loss: [1m[32m0.67376[0m[0m | time: 1.554s
[2K
| Adam | epoch: 023 | loss: 0.67376 - acc: 0.5433 -- iter: 096/144
[A[ATraining Step: 114  | total loss: [1m[32m0.67298[0m[0m | time: 1.873s
[2K
| Adam | epoch: 023 | loss: 0.67298 - acc: 0.5327 -- iter: 128/144
[A[ATraining Step: 115  | total loss: [1m[32m0.67119[0m[0m | time: 3.500s
[2K
| Adam | epoch: 023 | loss: 0.67119 - acc: 0.5232 | val_loss: 0.65728 - val_acc: 0.5435 -- iter: 144/144
--
Training Step: 116  | total loss: [1m[32m0.66844[0m[0m | time: 0.604s
[2K
| Adam | epoch: 024 | loss: 0.66844 - acc: 0.5272 -- iter: 032/144
[A[ATraining Step: 117  | total loss: [1m[32m0.66478[0m[0m | time: 1.217s
[2K
| Adam | epoch: 024 | loss: 0.66478 - acc: 0.5401 -- iter: 064/144
[A[ATraining Step: 118  | total loss: [1m[32m0.66132[0m[0m | time: 1.843s
[2K
| Adam | epoch: 024 | loss: 0.66132 - acc: 0.5548 -- iter: 096/144
[A[ATraining Step: 119  | total loss: [1m[32m0.65528[0m[0m | time: 2.308s
[2K
| Adam | epoch: 024 | loss: 0.65528 - acc: 0.5743 -- iter: 128/144
[A[ATraining Step: 120  | total loss: [1m[32m0.65005[0m[0m | time: 3.632s
[2K
| Adam | epoch: 024 | loss: 0.65005 - acc: 0.5794 | val_loss: 0.61856 - val_acc: 0.6304 -- iter: 144/144
--
Training Step: 121  | total loss: [1m[32m0.64476[0m[0m | time: 0.696s
[2K
| Adam | epoch: 025 | loss: 0.64476 - acc: 0.5902 -- iter: 032/144
[A[ATraining Step: 122  | total loss: [1m[32m0.63202[0m[0m | time: 1.300s
[2K
| Adam | epoch: 025 | loss: 0.63202 - acc: 0.6093 -- iter: 064/144
[A[ATraining Step: 123  | total loss: [1m[32m0.62336[0m[0m | time: 1.908s
[2K
| Adam | epoch: 025 | loss: 0.62336 - acc: 0.6203 -- iter: 096/144
[A[ATraining Step: 124  | total loss: [1m[32m0.62147[0m[0m | time: 2.530s
[2K
| Adam | epoch: 025 | loss: 0.62147 - acc: 0.6176 -- iter: 128/144
[A[ATraining Step: 125  | total loss: [1m[32m0.61057[0m[0m | time: 4.043s
[2K
| Adam | epoch: 025 | loss: 0.61057 - acc: 0.6340 | val_loss: 1.00525 - val_acc: 0.4783 -- iter: 144/144
--
Training Step: 126  | total loss: [1m[32m0.57642[0m[0m | time: 0.321s
[2K
| Adam | epoch: 026 | loss: 0.57642 - acc: 0.6643 -- iter: 032/144
[A[ATraining Step: 127  | total loss: [1m[32m0.54301[0m[0m | time: 0.919s
[2K
| Adam | epoch: 026 | loss: 0.54301 - acc: 0.6854 -- iter: 064/144
[A[ATraining Step: 128  | total loss: [1m[32m0.56490[0m[0m | time: 1.508s
[2K
| Adam | epoch: 026 | loss: 0.56490 - acc: 0.6762 -- iter: 096/144
[A[ATraining Step: 129  | total loss: [1m[32m0.54654[0m[0m | time: 2.124s
[2K
| Adam | epoch: 026 | loss: 0.54654 - acc: 0.6930 -- iter: 128/144
[A[ATraining Step: 130  | total loss: [1m[32m0.55409[0m[0m | time: 3.755s
[2K
| Adam | epoch: 026 | loss: 0.55409 - acc: 0.6893 | val_loss: 0.47841 - val_acc: 0.7826 -- iter: 144/144
--
Training Step: 131  | total loss: [1m[32m0.55702[0m[0m | time: 0.306s
[2K
| Adam | epoch: 027 | loss: 0.55702 - acc: 0.6954 -- iter: 032/144
[A[ATraining Step: 132  | total loss: [1m[32m0.54735[0m[0m | time: 0.614s
[2K
| Adam | epoch: 027 | loss: 0.54735 - acc: 0.7008 -- iter: 064/144
[A[ATraining Step: 133  | total loss: [1m[32m0.53154[0m[0m | time: 1.233s
[2K
| Adam | epoch: 027 | loss: 0.53154 - acc: 0.7058 -- iter: 096/144
[A[ATraining Step: 134  | total loss: [1m[32m0.52486[0m[0m | time: 1.868s
[2K
| Adam | epoch: 027 | loss: 0.52486 - acc: 0.7102 -- iter: 128/144
[A[ATraining Step: 135  | total loss: [1m[32m0.53053[0m[0m | time: 3.506s
[2K
| Adam | epoch: 027 | loss: 0.53053 - acc: 0.7079 | val_loss: 0.50072 - val_acc: 0.6739 -- iter: 144/144
--
Training Step: 136  | total loss: [1m[32m0.51673[0m[0m | time: 0.637s
[2K
| Adam | epoch: 028 | loss: 0.51673 - acc: 0.7121 -- iter: 032/144
[A[ATraining Step: 137  | total loss: [1m[32m0.50367[0m[0m | time: 0.955s
[2K
| Adam | epoch: 028 | loss: 0.50367 - acc: 0.7284 -- iter: 064/144
[A[ATraining Step: 138  | total loss: [1m[32m0.51301[0m[0m | time: 1.380s
[2K
| Adam | epoch: 028 | loss: 0.51301 - acc: 0.7181 -- iter: 096/144
[A[ATraining Step: 139  | total loss: [1m[32m0.51779[0m[0m | time: 1.975s
[2K
| Adam | epoch: 028 | loss: 0.51779 - acc: 0.7150 -- iter: 128/144
[A[ATraining Step: 140  | total loss: [1m[32m0.50790[0m[0m | time: 3.587s
[2K
| Adam | epoch: 028 | loss: 0.50790 - acc: 0.7279 | val_loss: 0.71517 - val_acc: 0.5652 -- iter: 144/144
--
Training Step: 141  | total loss: [1m[32m0.49857[0m[0m | time: 0.590s
[2K
| Adam | epoch: 029 | loss: 0.49857 - acc: 0.7426 -- iter: 032/144
[A[ATraining Step: 142  | total loss: [1m[32m0.50113[0m[0m | time: 1.202s
[2K
| Adam | epoch: 029 | loss: 0.50113 - acc: 0.7433 -- iter: 064/144
[A[ATraining Step: 143  | total loss: [1m[32m0.49016[0m[0m | time: 1.545s
[2K
| Adam | epoch: 029 | loss: 0.49016 - acc: 0.7534 -- iter: 096/144
[A[ATraining Step: 144  | total loss: [1m[32m0.47340[0m[0m | time: 1.870s
[2K
| Adam | epoch: 029 | loss: 0.47340 - acc: 0.7593 -- iter: 128/144
[A[ATraining Step: 145  | total loss: [1m[32m0.45483[0m[0m | time: 3.488s
[2K
| Adam | epoch: 029 | loss: 0.45483 - acc: 0.7771 | val_loss: 0.43731 - val_acc: 0.8043 -- iter: 144/144
--
Training Step: 146  | total loss: [1m[32m0.44034[0m[0m | time: 0.598s
[2K
| Adam | epoch: 030 | loss: 0.44034 - acc: 0.7900 -- iter: 032/144
[A[ATraining Step: 147  | total loss: [1m[32m0.44122[0m[0m | time: 1.205s
[2K
| Adam | epoch: 030 | loss: 0.44122 - acc: 0.7829 -- iter: 064/144
[A[ATraining Step: 148  | total loss: [1m[32m0.42650[0m[0m | time: 1.957s
[2K
| Adam | epoch: 030 | loss: 0.42650 - acc: 0.7984 -- iter: 096/144
[A[ATraining Step: 149  | total loss: [1m[32m0.42041[0m[0m | time: 2.303s
[2K
| Adam | epoch: 030 | loss: 0.42041 - acc: 0.8029 -- iter: 128/144
[A[ATraining Step: 150  | total loss: [1m[32m0.39764[0m[0m | time: 3.625s
[2K
| Adam | epoch: 030 | loss: 0.39764 - acc: 0.8164 | val_loss: 0.56208 - val_acc: 0.6739 -- iter: 144/144
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8479532163742689
Validation AUPRC:0.8878047435073047
Test AUC:0.8865784499054821
Test AUPRC:0.9056726797977301
BestTestF1Score	0.82	0.65	0.83	0.86	0.78	18	3	20	5	0.8
BestTestMCCScore	0.82	0.65	0.83	0.86	0.78	18	3	20	5	0.8
BestTestAccuracyScore	0.82	0.65	0.83	0.86	0.78	18	3	20	5	0.8
BestValidationF1Score	0.89	0.82	0.91	0.94	0.84	16	1	26	3	0.8
BestValidationMCC	0.89	0.82	0.91	0.94	0.84	16	1	26	3	0.8
BestValidationAccuracy	0.89	0.82	0.91	0.94	0.84	16	1	26	3	0.8
TestPredictions (Threshold:0.8)
CHEMBL3113202,TP,ACT,0.9900000095367432	CHEMBL1555743,TN,INACT,0.5299999713897705	CHEMBL3113167,TP,ACT,1.0	CHEMBL26851,FP,INACT,0.8100000023841858	CHEMBL1406616,TP,ACT,0.9800000190734863	CHEMBL2165869,FP,INACT,0.8600000143051147	CHEMBL92212,TP,ACT,0.800000011920929	CHEMBL106899,FP,INACT,0.9700000286102295	CHEMBL3113204,FN,ACT,0.6399999856948853	CHEMBL30202,TN,INACT,0.17000000178813934	CHEMBL1907659,TN,INACT,0.10000000149011612	CHEMBL323991,TN,INACT,0.12999999523162842	CHEMBL3113371,TP,ACT,1.0	CHEMBL348933,TN,INACT,0.36000001430511475	CHEMBL241814,FN,ACT,0.550000011920929	CHEMBL3113366,TP,ACT,0.9900000095367432	CHEMBL3113191,TP,ACT,0.9900000095367432	CHEMBL1392167,TN,INACT,0.11999999731779099	CHEMBL3113200,FN,ACT,0.7099999785423279	CHEMBL1487619,TP,ACT,0.9800000190734863	CHEMBL238843,TP,ACT,0.8100000023841858	CHEMBL2165868,TN,INACT,0.23999999463558197	CHEMBL1163222,TN,INACT,0.7799999713897705	CHEMBL239031,TP,ACT,0.9200000166893005	CHEMBL185893,TP,ACT,0.800000011920929	CHEMBL8260,FN,ACT,0.4699999988079071	CHEMBL110668,TN,INACT,0.14000000059604645	CHEMBL3113198,TP,ACT,1.0	CHEMBL2163382,TN,INACT,0.3100000023841858	CHEMBL1929092,TN,INACT,0.1599999964237213	CHEMBL1521956,TP,ACT,0.9900000095367432	CHEMBL1215117,TN,INACT,0.1599999964237213	CHEMBL1929091,TN,INACT,0.12999999523162842	CHEMBL29874,TN,INACT,0.3100000023841858	CHEMBL148503,TP,ACT,0.8999999761581421	CHEMBL71552,TN,INACT,0.6399999856948853	CHEMBL1215118,TN,INACT,0.2800000011920929	CHEMBL281981,TN,INACT,0.5299999713897705	CHEMBL3113180,TP,ACT,1.0	CHEMBL2165865,TN,INACT,0.7599999904632568	CHEMBL3113192,FN,ACT,0.11999999731779099	CHEMBL52,TP,ACT,0.800000011920929	CHEMBL1394624,TP,ACT,0.9900000095367432	CHEMBL1917087,TN,INACT,0.12999999523162842	CHEMBL423092,TN,INACT,0.2199999988079071	CHEMBL3113369,TP,ACT,0.9200000166893005	

