CNNModel CHEMBL1881 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	290
Number of inactive compounds :	290
---------------------------------
Run id: CNNModel_CHEMBL1881_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1881_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 370
Validation samples: 116
--
Training Step: 1  | time: 3.099s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/370
[A[ATraining Step: 2  | total loss: [1m[32m0.62372[0m[0m | time: 4.472s
[2K
| Adam | epoch: 001 | loss: 0.62372 - acc: 0.4781 -- iter: 064/370
[A[ATraining Step: 3  | total loss: [1m[32m0.68104[0m[0m | time: 5.623s
[2K
| Adam | epoch: 001 | loss: 0.68104 - acc: 0.4705 -- iter: 096/370
[A[ATraining Step: 4  | total loss: [1m[32m0.69030[0m[0m | time: 7.013s
[2K
| Adam | epoch: 001 | loss: 0.69030 - acc: 0.4692 -- iter: 128/370
[A[ATraining Step: 5  | total loss: [1m[32m0.69151[0m[0m | time: 8.356s
[2K
| Adam | epoch: 001 | loss: 0.69151 - acc: 0.5554 -- iter: 160/370
[A[ATraining Step: 6  | total loss: [1m[32m0.69295[0m[0m | time: 9.677s
[2K
| Adam | epoch: 001 | loss: 0.69295 - acc: 0.5198 -- iter: 192/370
[A[ATraining Step: 7  | total loss: [1m[32m0.69310[0m[0m | time: 11.375s
[2K
| Adam | epoch: 001 | loss: 0.69310 - acc: 0.5079 -- iter: 224/370
[A[ATraining Step: 8  | total loss: [1m[32m0.69252[0m[0m | time: 13.042s
[2K
| Adam | epoch: 001 | loss: 0.69252 - acc: 0.5210 -- iter: 256/370
[A[ATraining Step: 9  | total loss: [1m[32m0.69211[0m[0m | time: 14.634s
[2K
| Adam | epoch: 001 | loss: 0.69211 - acc: 0.5264 -- iter: 288/370
[A[ATraining Step: 10  | total loss: [1m[32m0.69636[0m[0m | time: 15.926s
[2K
| Adam | epoch: 001 | loss: 0.69636 - acc: 0.4507 -- iter: 320/370
[A[ATraining Step: 11  | total loss: [1m[32m0.69502[0m[0m | time: 17.139s
[2K
| Adam | epoch: 001 | loss: 0.69502 - acc: 0.4741 -- iter: 352/370
[A[ATraining Step: 12  | total loss: [1m[32m0.69309[0m[0m | time: 19.164s
[2K
| Adam | epoch: 001 | loss: 0.69309 - acc: 0.5420 | val_loss: 0.69261 - val_acc: 0.5259 -- iter: 370/370
--
Training Step: 13  | total loss: [1m[32m0.69388[0m[0m | time: 0.751s
[2K
| Adam | epoch: 002 | loss: 0.69388 - acc: 0.4764 -- iter: 032/370
[A[ATraining Step: 14  | total loss: [1m[32m0.69415[0m[0m | time: 2.175s
[2K
| Adam | epoch: 002 | loss: 0.69415 - acc: 0.4406 -- iter: 064/370
[A[ATraining Step: 15  | total loss: [1m[32m0.69411[0m[0m | time: 3.587s
[2K
| Adam | epoch: 002 | loss: 0.69411 - acc: 0.4027 -- iter: 096/370
[A[ATraining Step: 16  | total loss: [1m[32m0.69361[0m[0m | time: 4.795s
[2K
| Adam | epoch: 002 | loss: 0.69361 - acc: 0.4626 -- iter: 128/370
[A[ATraining Step: 17  | total loss: [1m[32m0.69358[0m[0m | time: 6.283s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.4761 -- iter: 160/370
[A[ATraining Step: 18  | total loss: [1m[32m0.69314[0m[0m | time: 7.929s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5060 -- iter: 192/370
[A[ATraining Step: 19  | total loss: [1m[32m0.69298[0m[0m | time: 9.572s
[2K
| Adam | epoch: 002 | loss: 0.69298 - acc: 0.5144 -- iter: 224/370
[A[ATraining Step: 20  | total loss: [1m[32m0.69374[0m[0m | time: 10.642s
[2K
| Adam | epoch: 002 | loss: 0.69374 - acc: 0.4897 -- iter: 256/370
[A[ATraining Step: 21  | total loss: [1m[32m0.69389[0m[0m | time: 12.137s
[2K
| Adam | epoch: 002 | loss: 0.69389 - acc: 0.4832 -- iter: 288/370
[A[ATraining Step: 22  | total loss: [1m[32m0.69253[0m[0m | time: 13.607s
[2K
| Adam | epoch: 002 | loss: 0.69253 - acc: 0.5257 -- iter: 320/370
[A[ATraining Step: 23  | total loss: [1m[32m0.69325[0m[0m | time: 15.090s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5092 -- iter: 352/370
[A[ATraining Step: 24  | total loss: [1m[32m0.69353[0m[0m | time: 17.453s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.4978 | val_loss: 0.69417 - val_acc: 0.4741 -- iter: 370/370
--
Training Step: 25  | total loss: [1m[32m0.69319[0m[0m | time: 0.891s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5069 -- iter: 032/370
[A[ATraining Step: 26  | total loss: [1m[32m0.69371[0m[0m | time: 1.788s
[2K
| Adam | epoch: 003 | loss: 0.69371 - acc: 0.4904 -- iter: 064/370
[A[ATraining Step: 27  | total loss: [1m[32m0.69392[0m[0m | time: 3.407s
[2K
| Adam | epoch: 003 | loss: 0.69392 - acc: 0.4786 -- iter: 096/370
[A[ATraining Step: 28  | total loss: [1m[32m0.69371[0m[0m | time: 4.695s
[2K
| Adam | epoch: 003 | loss: 0.69371 - acc: 0.4839 -- iter: 128/370
[A[ATraining Step: 29  | total loss: [1m[32m0.69378[0m[0m | time: 5.869s
[2K
| Adam | epoch: 003 | loss: 0.69378 - acc: 0.4802 -- iter: 160/370
[A[ATraining Step: 30  | total loss: [1m[32m0.69343[0m[0m | time: 7.305s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.4923 -- iter: 192/370
[A[ATraining Step: 31  | total loss: [1m[32m0.69247[0m[0m | time: 8.662s
[2K
| Adam | epoch: 003 | loss: 0.69247 - acc: 0.5374 -- iter: 224/370
[A[ATraining Step: 32  | total loss: [1m[32m0.69224[0m[0m | time: 10.058s
[2K
| Adam | epoch: 003 | loss: 0.69224 - acc: 0.5430 -- iter: 256/370
[A[ATraining Step: 33  | total loss: [1m[32m0.69243[0m[0m | time: 11.305s
[2K
| Adam | epoch: 003 | loss: 0.69243 - acc: 0.5336 -- iter: 288/370
[A[ATraining Step: 34  | total loss: [1m[32m0.69284[0m[0m | time: 12.455s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5197 -- iter: 320/370
[A[ATraining Step: 35  | total loss: [1m[32m0.69159[0m[0m | time: 13.844s
[2K
| Adam | epoch: 003 | loss: 0.69159 - acc: 0.5483 -- iter: 352/370
[A[ATraining Step: 36  | total loss: [1m[32m0.69127[0m[0m | time: 16.312s
[2K
| Adam | epoch: 003 | loss: 0.69127 - acc: 0.5512 | val_loss: 0.69477 - val_acc: 0.4741 -- iter: 370/370
--
Training Step: 37  | total loss: [1m[32m0.69354[0m[0m | time: 1.332s
[2K
| Adam | epoch: 004 | loss: 0.69354 - acc: 0.5097 -- iter: 032/370
[A[ATraining Step: 38  | total loss: [1m[32m0.69200[0m[0m | time: 1.977s
[2K
| Adam | epoch: 004 | loss: 0.69200 - acc: 0.5323 -- iter: 064/370
[A[ATraining Step: 39  | total loss: [1m[32m0.69154[0m[0m | time: 2.788s
[2K
| Adam | epoch: 004 | loss: 0.69154 - acc: 0.5367 -- iter: 096/370
[A[ATraining Step: 40  | total loss: [1m[32m0.69116[0m[0m | time: 4.220s
[2K
| Adam | epoch: 004 | loss: 0.69116 - acc: 0.5402 -- iter: 128/370
[A[ATraining Step: 41  | total loss: [1m[32m0.69161[0m[0m | time: 5.603s
[2K
| Adam | epoch: 004 | loss: 0.69161 - acc: 0.5329 -- iter: 160/370
[A[ATraining Step: 42  | total loss: [1m[32m0.69355[0m[0m | time: 7.025s
[2K
| Adam | epoch: 004 | loss: 0.69355 - acc: 0.5101 -- iter: 192/370
[A[ATraining Step: 43  | total loss: [1m[32m0.69444[0m[0m | time: 11.368s
[2K
| Adam | epoch: 004 | loss: 0.69444 - acc: 0.4973 -- iter: 224/370
[A[ATraining Step: 44  | total loss: [1m[32m0.69366[0m[0m | time: 12.607s
[2K
| Adam | epoch: 004 | loss: 0.69366 - acc: 0.5031 -- iter: 256/370
[A[ATraining Step: 45  | total loss: [1m[32m0.69194[0m[0m | time: 13.929s
[2K
| Adam | epoch: 004 | loss: 0.69194 - acc: 0.5291 -- iter: 288/370
[A[ATraining Step: 46  | total loss: [1m[32m0.69103[0m[0m | time: 15.238s
[2K
| Adam | epoch: 004 | loss: 0.69103 - acc: 0.5399 -- iter: 320/370
[A[ATraining Step: 47  | total loss: [1m[32m0.69007[0m[0m | time: 16.505s
[2K
| Adam | epoch: 004 | loss: 0.69007 - acc: 0.5487 -- iter: 352/370
[A[ATraining Step: 48  | total loss: [1m[32m0.69222[0m[0m | time: 19.076s
[2K
| Adam | epoch: 004 | loss: 0.69222 - acc: 0.5208 | val_loss: 0.69444 - val_acc: 0.4741 -- iter: 370/370
--
Training Step: 49  | total loss: [1m[32m0.69138[0m[0m | time: 1.407s
[2K
| Adam | epoch: 005 | loss: 0.69138 - acc: 0.5274 -- iter: 032/370
[A[ATraining Step: 50  | total loss: [1m[32m0.69215[0m[0m | time: 2.821s
[2K
| Adam | epoch: 005 | loss: 0.69215 - acc: 0.5134 -- iter: 064/370
[A[ATraining Step: 51  | total loss: [1m[32m0.69147[0m[0m | time: 3.547s
[2K
| Adam | epoch: 005 | loss: 0.69147 - acc: 0.5209 -- iter: 096/370
[A[ATraining Step: 52  | total loss: [1m[32m0.69045[0m[0m | time: 5.364s
[2K
| Adam | epoch: 005 | loss: 0.69045 - acc: 0.5261 -- iter: 128/370
[A[ATraining Step: 53  | total loss: [1m[32m0.68918[0m[0m | time: 6.488s
[2K
| Adam | epoch: 005 | loss: 0.68918 - acc: 0.5305 -- iter: 160/370
[A[ATraining Step: 54  | total loss: [1m[32m0.68796[0m[0m | time: 7.807s
[2K
| Adam | epoch: 005 | loss: 0.68796 - acc: 0.5396 -- iter: 192/370
[A[ATraining Step: 55  | total loss: [1m[32m0.69207[0m[0m | time: 9.237s
[2K
| Adam | epoch: 005 | loss: 0.69207 - acc: 0.5072 -- iter: 224/370
[A[ATraining Step: 56  | total loss: [1m[32m0.68996[0m[0m | time: 10.567s
[2K
| Adam | epoch: 005 | loss: 0.68996 - acc: 0.5194 -- iter: 256/370
[A[ATraining Step: 57  | total loss: [1m[32m0.68900[0m[0m | time: 11.869s
[2K
| Adam | epoch: 005 | loss: 0.68900 - acc: 0.5297 -- iter: 288/370
[A[ATraining Step: 58  | total loss: [1m[32m0.68933[0m[0m | time: 13.556s
[2K
| Adam | epoch: 005 | loss: 0.68933 - acc: 0.5214 -- iter: 320/370
[A[ATraining Step: 59  | total loss: [1m[32m0.69006[0m[0m | time: 15.217s
[2K
| Adam | epoch: 005 | loss: 0.69006 - acc: 0.5143 -- iter: 352/370
[A[ATraining Step: 60  | total loss: [1m[32m0.68952[0m[0m | time: 17.778s
[2K
| Adam | epoch: 005 | loss: 0.68952 - acc: 0.5124 | val_loss: 0.68400 - val_acc: 0.6293 -- iter: 370/370
--
Training Step: 61  | total loss: [1m[32m0.68870[0m[0m | time: 1.280s
[2K
| Adam | epoch: 006 | loss: 0.68870 - acc: 0.5108 -- iter: 032/370
[A[ATraining Step: 62  | total loss: [1m[32m0.68643[0m[0m | time: 2.694s
[2K
| Adam | epoch: 006 | loss: 0.68643 - acc: 0.5456 -- iter: 064/370
[A[ATraining Step: 63  | total loss: [1m[32m0.68300[0m[0m | time: 4.023s
[2K
| Adam | epoch: 006 | loss: 0.68300 - acc: 0.5636 -- iter: 096/370
[A[ATraining Step: 64  | total loss: [1m[32m0.68632[0m[0m | time: 4.791s
[2K
| Adam | epoch: 006 | loss: 0.68632 - acc: 0.5400 -- iter: 128/370
[A[ATraining Step: 65  | total loss: [1m[32m0.68093[0m[0m | time: 5.484s
[2K
| Adam | epoch: 006 | loss: 0.68093 - acc: 0.5625 -- iter: 160/370
[A[ATraining Step: 66  | total loss: [1m[32m0.67549[0m[0m | time: 7.035s
[2K
| Adam | epoch: 006 | loss: 0.67549 - acc: 0.5886 -- iter: 192/370
[A[ATraining Step: 67  | total loss: [1m[32m0.67100[0m[0m | time: 8.554s
[2K
| Adam | epoch: 006 | loss: 0.67100 - acc: 0.6005 -- iter: 224/370
[A[ATraining Step: 68  | total loss: [1m[32m0.67052[0m[0m | time: 10.044s
[2K
| Adam | epoch: 006 | loss: 0.67052 - acc: 0.5997 -- iter: 256/370
[A[ATraining Step: 69  | total loss: [1m[32m0.67051[0m[0m | time: 11.492s
[2K
| Adam | epoch: 006 | loss: 0.67051 - acc: 0.5954 -- iter: 288/370
[A[ATraining Step: 70  | total loss: [1m[32m0.67999[0m[0m | time: 12.564s
[2K
| Adam | epoch: 006 | loss: 0.67999 - acc: 0.5807 -- iter: 320/370
[A[ATraining Step: 71  | total loss: [1m[32m0.67553[0m[0m | time: 14.088s
[2K
| Adam | epoch: 006 | loss: 0.67553 - acc: 0.5929 -- iter: 352/370
[A[ATraining Step: 72  | total loss: [1m[32m0.67376[0m[0m | time: 16.509s
[2K
| Adam | epoch: 006 | loss: 0.67376 - acc: 0.6000 | val_loss: 0.64077 - val_acc: 0.6552 -- iter: 370/370
--
Training Step: 73  | total loss: [1m[32m0.67701[0m[0m | time: 1.208s
[2K
| Adam | epoch: 007 | loss: 0.67701 - acc: 0.5820 -- iter: 032/370
[A[ATraining Step: 74  | total loss: [1m[32m0.66897[0m[0m | time: 2.778s
[2K
| Adam | epoch: 007 | loss: 0.66897 - acc: 0.5936 -- iter: 064/370
[A[ATraining Step: 75  | total loss: [1m[32m0.66246[0m[0m | time: 4.374s
[2K
| Adam | epoch: 007 | loss: 0.66246 - acc: 0.5970 -- iter: 096/370
[A[ATraining Step: 76  | total loss: [1m[32m0.66828[0m[0m | time: 5.972s
[2K
| Adam | epoch: 007 | loss: 0.66828 - acc: 0.5832 -- iter: 128/370
[A[ATraining Step: 77  | total loss: [1m[32m0.67088[0m[0m | time: 6.859s
[2K
| Adam | epoch: 007 | loss: 0.67088 - acc: 0.5711 -- iter: 160/370
[A[ATraining Step: 78  | total loss: [1m[32m0.66965[0m[0m | time: 7.563s
[2K
| Adam | epoch: 007 | loss: 0.66965 - acc: 0.5811 -- iter: 192/370
[A[ATraining Step: 79  | total loss: [1m[32m0.66561[0m[0m | time: 8.824s
[2K
| Adam | epoch: 007 | loss: 0.66561 - acc: 0.5900 -- iter: 224/370
[A[ATraining Step: 80  | total loss: [1m[32m0.66432[0m[0m | time: 10.225s
[2K
| Adam | epoch: 007 | loss: 0.66432 - acc: 0.5935 -- iter: 256/370
[A[ATraining Step: 81  | total loss: [1m[32m0.66564[0m[0m | time: 11.531s
[2K
| Adam | epoch: 007 | loss: 0.66564 - acc: 0.5841 -- iter: 288/370
[A[ATraining Step: 82  | total loss: [1m[32m0.66801[0m[0m | time: 12.806s
[2K
| Adam | epoch: 007 | loss: 0.66801 - acc: 0.5725 -- iter: 320/370
[A[ATraining Step: 83  | total loss: [1m[32m0.66694[0m[0m | time: 14.291s
[2K
| Adam | epoch: 007 | loss: 0.66694 - acc: 0.5778 -- iter: 352/370
[A[ATraining Step: 84  | total loss: [1m[32m0.65962[0m[0m | time: 16.510s
[2K
| Adam | epoch: 007 | loss: 0.65962 - acc: 0.5981 | val_loss: 0.61240 - val_acc: 0.6897 -- iter: 370/370
--
Training Step: 85  | total loss: [1m[32m0.65458[0m[0m | time: 1.571s
[2K
| Adam | epoch: 008 | loss: 0.65458 - acc: 0.6133 -- iter: 032/370
[A[ATraining Step: 86  | total loss: [1m[32m0.64960[0m[0m | time: 2.640s
[2K
| Adam | epoch: 008 | loss: 0.64960 - acc: 0.6270 -- iter: 064/370
[A[ATraining Step: 87  | total loss: [1m[32m0.64711[0m[0m | time: 3.989s
[2K
| Adam | epoch: 008 | loss: 0.64711 - acc: 0.6362 -- iter: 096/370
[A[ATraining Step: 88  | total loss: [1m[32m0.63000[0m[0m | time: 5.454s
[2K
| Adam | epoch: 008 | loss: 0.63000 - acc: 0.6601 -- iter: 128/370
[A[ATraining Step: 89  | total loss: [1m[32m0.63461[0m[0m | time: 6.802s
[2K
| Adam | epoch: 008 | loss: 0.63461 - acc: 0.6472 -- iter: 160/370
[A[ATraining Step: 90  | total loss: [1m[32m0.61938[0m[0m | time: 7.602s
[2K
| Adam | epoch: 008 | loss: 0.61938 - acc: 0.6637 -- iter: 192/370
[A[ATraining Step: 91  | total loss: [1m[32m0.60795[0m[0m | time: 8.248s
[2K
| Adam | epoch: 008 | loss: 0.60795 - acc: 0.6751 -- iter: 224/370
[A[ATraining Step: 92  | total loss: [1m[32m0.59645[0m[0m | time: 9.583s
[2K
| Adam | epoch: 008 | loss: 0.59645 - acc: 0.6798 -- iter: 256/370
[A[ATraining Step: 93  | total loss: [1m[32m0.59447[0m[0m | time: 11.033s
[2K
| Adam | epoch: 008 | loss: 0.59447 - acc: 0.6837 -- iter: 288/370
[A[ATraining Step: 94  | total loss: [1m[32m0.59044[0m[0m | time: 12.576s
[2K
| Adam | epoch: 008 | loss: 0.59044 - acc: 0.6810 -- iter: 320/370
[A[ATraining Step: 95  | total loss: [1m[32m0.58148[0m[0m | time: 13.912s
[2K
| Adam | epoch: 008 | loss: 0.58148 - acc: 0.6879 -- iter: 352/370
[A[ATraining Step: 96  | total loss: [1m[32m0.58317[0m[0m | time: 16.470s
[2K
| Adam | epoch: 008 | loss: 0.58317 - acc: 0.6847 | val_loss: 0.65828 - val_acc: 0.6638 -- iter: 370/370
--
Training Step: 97  | total loss: [1m[32m0.60354[0m[0m | time: 1.676s
[2K
| Adam | epoch: 009 | loss: 0.60354 - acc: 0.6694 -- iter: 032/370
[A[ATraining Step: 98  | total loss: [1m[32m0.62164[0m[0m | time: 3.158s
[2K
| Adam | epoch: 009 | loss: 0.62164 - acc: 0.6556 -- iter: 064/370
[A[ATraining Step: 99  | total loss: [1m[32m0.60528[0m[0m | time: 4.631s
[2K
| Adam | epoch: 009 | loss: 0.60528 - acc: 0.6712 -- iter: 096/370
[A[ATraining Step: 100  | total loss: [1m[32m0.59436[0m[0m | time: 5.725s
[2K
| Adam | epoch: 009 | loss: 0.59436 - acc: 0.6791 -- iter: 128/370
[A[ATraining Step: 101  | total loss: [1m[32m0.60528[0m[0m | time: 7.104s
[2K
| Adam | epoch: 009 | loss: 0.60528 - acc: 0.6643 -- iter: 160/370
[A[ATraining Step: 102  | total loss: [1m[32m0.60319[0m[0m | time: 8.457s
[2K
| Adam | epoch: 009 | loss: 0.60319 - acc: 0.6635 -- iter: 192/370
[A[ATraining Step: 103  | total loss: [1m[32m0.59473[0m[0m | time: 9.323s
[2K
| Adam | epoch: 009 | loss: 0.59473 - acc: 0.6784 -- iter: 224/370
[A[ATraining Step: 104  | total loss: [1m[32m0.58307[0m[0m | time: 10.079s
[2K
| Adam | epoch: 009 | loss: 0.58307 - acc: 0.6995 -- iter: 256/370
[A[ATraining Step: 105  | total loss: [1m[32m0.57229[0m[0m | time: 11.472s
[2K
| Adam | epoch: 009 | loss: 0.57229 - acc: 0.7129 -- iter: 288/370
[A[ATraining Step: 106  | total loss: [1m[32m0.56869[0m[0m | time: 12.938s
[2K
| Adam | epoch: 009 | loss: 0.56869 - acc: 0.7103 -- iter: 320/370
[A[ATraining Step: 107  | total loss: [1m[32m0.55488[0m[0m | time: 14.361s
[2K
| Adam | epoch: 009 | loss: 0.55488 - acc: 0.7174 -- iter: 352/370
[A[ATraining Step: 108  | total loss: [1m[32m0.54719[0m[0m | time: 16.389s
[2K
| Adam | epoch: 009 | loss: 0.54719 - acc: 0.7300 | val_loss: 0.53703 - val_acc: 0.7155 -- iter: 370/370
--
Training Step: 109  | total loss: [1m[32m0.54353[0m[0m | time: 1.076s
[2K
| Adam | epoch: 010 | loss: 0.54353 - acc: 0.7320 -- iter: 032/370
[A[ATraining Step: 110  | total loss: [1m[32m0.53439[0m[0m | time: 2.288s
[2K
| Adam | epoch: 010 | loss: 0.53439 - acc: 0.7370 -- iter: 064/370
[A[ATraining Step: 111  | total loss: [1m[32m0.52612[0m[0m | time: 3.652s
[2K
| Adam | epoch: 010 | loss: 0.52612 - acc: 0.7445 -- iter: 096/370
[A[ATraining Step: 112  | total loss: [1m[32m0.50840[0m[0m | time: 4.978s
[2K
| Adam | epoch: 010 | loss: 0.50840 - acc: 0.7544 -- iter: 128/370
[A[ATraining Step: 113  | total loss: [1m[32m0.49668[0m[0m | time: 5.881s
[2K
| Adam | epoch: 010 | loss: 0.49668 - acc: 0.7634 -- iter: 160/370
[A[ATraining Step: 114  | total loss: [1m[32m0.52898[0m[0m | time: 6.928s
[2K
| Adam | epoch: 010 | loss: 0.52898 - acc: 0.7495 -- iter: 192/370
[A[ATraining Step: 115  | total loss: [1m[32m0.52886[0m[0m | time: 8.007s
[2K
| Adam | epoch: 010 | loss: 0.52886 - acc: 0.7465 -- iter: 224/370
[A[ATraining Step: 116  | total loss: [1m[32m0.53001[0m[0m | time: 8.687s
[2K
| Adam | epoch: 010 | loss: 0.53001 - acc: 0.7343 -- iter: 256/370
[A[ATraining Step: 117  | total loss: [1m[32m0.50229[0m[0m | time: 9.439s
[2K
| Adam | epoch: 010 | loss: 0.50229 - acc: 0.7553 -- iter: 288/370
[A[ATraining Step: 118  | total loss: [1m[32m0.48213[0m[0m | time: 10.741s
[2K
| Adam | epoch: 010 | loss: 0.48213 - acc: 0.7631 -- iter: 320/370
[A[ATraining Step: 119  | total loss: [1m[32m0.47805[0m[0m | time: 11.722s
[2K
| Adam | epoch: 010 | loss: 0.47805 - acc: 0.7649 -- iter: 352/370
[A[ATraining Step: 120  | total loss: [1m[32m0.45715[0m[0m | time: 13.406s
[2K
| Adam | epoch: 010 | loss: 0.45715 - acc: 0.7759 | val_loss: 0.48069 - val_acc: 0.7672 -- iter: 370/370
--
Training Step: 121  | total loss: [1m[32m0.44357[0m[0m | time: 1.367s
[2K
| Adam | epoch: 011 | loss: 0.44357 - acc: 0.7890 -- iter: 032/370
[A[ATraining Step: 122  | total loss: [1m[32m0.42893[0m[0m | time: 2.562s
[2K
| Adam | epoch: 011 | loss: 0.42893 - acc: 0.7976 -- iter: 064/370
[A[ATraining Step: 123  | total loss: [1m[32m0.43312[0m[0m | time: 3.836s
[2K
| Adam | epoch: 011 | loss: 0.43312 - acc: 0.7928 -- iter: 096/370
[A[ATraining Step: 124  | total loss: [1m[32m0.47393[0m[0m | time: 4.747s
[2K
| Adam | epoch: 011 | loss: 0.47393 - acc: 0.7885 -- iter: 128/370
[A[ATraining Step: 125  | total loss: [1m[32m0.46454[0m[0m | time: 6.004s
[2K
| Adam | epoch: 011 | loss: 0.46454 - acc: 0.7941 -- iter: 160/370
[A[ATraining Step: 126  | total loss: [1m[32m0.43949[0m[0m | time: 7.349s
[2K
| Adam | epoch: 011 | loss: 0.43949 - acc: 0.8115 -- iter: 192/370
[A[ATraining Step: 127  | total loss: [1m[32m0.44838[0m[0m | time: 8.770s
[2K
| Adam | epoch: 011 | loss: 0.44838 - acc: 0.7991 -- iter: 224/370
[A[ATraining Step: 128  | total loss: [1m[32m0.44808[0m[0m | time: 10.098s
[2K
| Adam | epoch: 011 | loss: 0.44808 - acc: 0.7973 -- iter: 256/370
[A[ATraining Step: 129  | total loss: [1m[32m0.43707[0m[0m | time: 10.894s
[2K
| Adam | epoch: 011 | loss: 0.43707 - acc: 0.7957 -- iter: 288/370
[A[ATraining Step: 130  | total loss: [1m[32m0.42710[0m[0m | time: 11.712s
[2K
| Adam | epoch: 011 | loss: 0.42710 - acc: 0.8050 -- iter: 320/370
[A[ATraining Step: 131  | total loss: [1m[32m0.41597[0m[0m | time: 13.084s
[2K
| Adam | epoch: 011 | loss: 0.41597 - acc: 0.8134 -- iter: 352/370
[A[ATraining Step: 132  | total loss: [1m[32m0.40773[0m[0m | time: 15.528s
[2K
| Adam | epoch: 011 | loss: 0.40773 - acc: 0.8227 | val_loss: 0.41267 - val_acc: 0.8276 -- iter: 370/370
--
Training Step: 133  | total loss: [1m[32m0.39756[0m[0m | time: 1.332s
[2K
| Adam | epoch: 012 | loss: 0.39756 - acc: 0.8342 -- iter: 032/370
[A[ATraining Step: 134  | total loss: [1m[32m0.38509[0m[0m | time: 2.643s
[2K
| Adam | epoch: 012 | loss: 0.38509 - acc: 0.8445 -- iter: 064/370
[A[ATraining Step: 135  | total loss: [1m[32m0.37878[0m[0m | time: 4.019s
[2K
| Adam | epoch: 012 | loss: 0.37878 - acc: 0.8476 -- iter: 096/370
[A[ATraining Step: 136  | total loss: [1m[32m0.36793[0m[0m | time: 5.359s
[2K
| Adam | epoch: 012 | loss: 0.36793 - acc: 0.8503 -- iter: 128/370
[A[ATraining Step: 137  | total loss: [1m[32m0.34866[0m[0m | time: 6.771s
[2K
| Adam | epoch: 012 | loss: 0.34866 - acc: 0.8622 -- iter: 160/370
[A[ATraining Step: 138  | total loss: [1m[32m0.33367[0m[0m | time: 8.049s
[2K
| Adam | epoch: 012 | loss: 0.33367 - acc: 0.8697 -- iter: 192/370
[A[ATraining Step: 139  | total loss: [1m[32m0.32684[0m[0m | time: 9.399s
[2K
| Adam | epoch: 012 | loss: 0.32684 - acc: 0.8733 -- iter: 224/370
[A[ATraining Step: 140  | total loss: [1m[32m0.32916[0m[0m | time: 10.878s
[2K
| Adam | epoch: 012 | loss: 0.32916 - acc: 0.8704 -- iter: 256/370
[A[ATraining Step: 141  | total loss: [1m[32m0.33645[0m[0m | time: 12.327s
[2K
| Adam | epoch: 012 | loss: 0.33645 - acc: 0.8740 -- iter: 288/370
[A[ATraining Step: 142  | total loss: [1m[32m0.32143[0m[0m | time: 13.166s
[2K
| Adam | epoch: 012 | loss: 0.32143 - acc: 0.8803 -- iter: 320/370
[A[ATraining Step: 143  | total loss: [1m[32m0.31446[0m[0m | time: 13.957s
[2K
| Adam | epoch: 012 | loss: 0.31446 - acc: 0.8812 -- iter: 352/370
[A[ATraining Step: 144  | total loss: [1m[32m0.30520[0m[0m | time: 16.447s
[2K
| Adam | epoch: 012 | loss: 0.30520 - acc: 0.8875 | val_loss: 0.47375 - val_acc: 0.8103 -- iter: 370/370
--
Training Step: 145  | total loss: [1m[32m0.30101[0m[0m | time: 0.982s
[2K
| Adam | epoch: 013 | loss: 0.30101 - acc: 0.8894 -- iter: 032/370
[A[ATraining Step: 146  | total loss: [1m[32m0.28157[0m[0m | time: 1.910s
[2K
| Adam | epoch: 013 | loss: 0.28157 - acc: 0.9004 -- iter: 064/370
[A[ATraining Step: 147  | total loss: [1m[32m0.31736[0m[0m | time: 2.940s
[2K
| Adam | epoch: 013 | loss: 0.31736 - acc: 0.8885 -- iter: 096/370
[A[ATraining Step: 148  | total loss: [1m[32m0.31262[0m[0m | time: 4.107s
[2K
| Adam | epoch: 013 | loss: 0.31262 - acc: 0.8872 -- iter: 128/370
[A[ATraining Step: 149  | total loss: [1m[32m0.29864[0m[0m | time: 5.236s
[2K
| Adam | epoch: 013 | loss: 0.29864 - acc: 0.8922 -- iter: 160/370
[A[ATraining Step: 150  | total loss: [1m[32m0.29855[0m[0m | time: 6.204s
[2K
| Adam | epoch: 013 | loss: 0.29855 - acc: 0.8874 -- iter: 192/370
[A[ATraining Step: 151  | total loss: [1m[32m0.29421[0m[0m | time: 7.703s
[2K
| Adam | epoch: 013 | loss: 0.29421 - acc: 0.8861 -- iter: 224/370
[A[ATraining Step: 152  | total loss: [1m[32m0.28856[0m[0m | time: 9.036s
[2K
| Adam | epoch: 013 | loss: 0.28856 - acc: 0.8881 -- iter: 256/370
[A[ATraining Step: 153  | total loss: [1m[32m0.28200[0m[0m | time: 10.248s
[2K
| Adam | epoch: 013 | loss: 0.28200 - acc: 0.8899 -- iter: 288/370
[A[ATraining Step: 154  | total loss: [1m[32m0.28809[0m[0m | time: 11.067s
[2K
| Adam | epoch: 013 | loss: 0.28809 - acc: 0.8822 -- iter: 320/370
[A[ATraining Step: 155  | total loss: [1m[32m0.28812[0m[0m | time: 11.640s
[2K
| Adam | epoch: 013 | loss: 0.28812 - acc: 0.8815 -- iter: 352/370
[A[ATraining Step: 156  | total loss: [1m[32m0.30277[0m[0m | time: 13.200s
[2K
| Adam | epoch: 013 | loss: 0.30277 - acc: 0.8767 | val_loss: 0.41024 - val_acc: 0.8190 -- iter: 370/370
--
Training Step: 157  | total loss: [1m[32m0.31062[0m[0m | time: 1.278s
[2K
| Adam | epoch: 014 | loss: 0.31062 - acc: 0.8723 -- iter: 032/370
[A[ATraining Step: 158  | total loss: [1m[32m0.29962[0m[0m | time: 2.543s
[2K
| Adam | epoch: 014 | loss: 0.29962 - acc: 0.8757 -- iter: 064/370
[A[ATraining Step: 159  | total loss: [1m[32m0.29225[0m[0m | time: 3.865s
[2K
| Adam | epoch: 014 | loss: 0.29225 - acc: 0.8819 -- iter: 096/370
[A[ATraining Step: 160  | total loss: [1m[32m0.27374[0m[0m | time: 4.801s
[2K
| Adam | epoch: 014 | loss: 0.27374 - acc: 0.8937 -- iter: 128/370
[A[ATraining Step: 161  | total loss: [1m[32m0.26070[0m[0m | time: 5.751s
[2K
| Adam | epoch: 014 | loss: 0.26070 - acc: 0.9012 -- iter: 160/370
[A[ATraining Step: 162  | total loss: [1m[32m0.24410[0m[0m | time: 6.776s
[2K
| Adam | epoch: 014 | loss: 0.24410 - acc: 0.9080 -- iter: 192/370
[A[ATraining Step: 163  | total loss: [1m[32m0.31491[0m[0m | time: 7.761s
[2K
| Adam | epoch: 014 | loss: 0.31491 - acc: 0.8890 -- iter: 224/370
[A[ATraining Step: 164  | total loss: [1m[32m0.31154[0m[0m | time: 8.768s
[2K
| Adam | epoch: 014 | loss: 0.31154 - acc: 0.8876 -- iter: 256/370
[A[ATraining Step: 165  | total loss: [1m[32m0.30046[0m[0m | time: 9.978s
[2K
| Adam | epoch: 014 | loss: 0.30046 - acc: 0.8895 -- iter: 288/370
[A[ATraining Step: 166  | total loss: [1m[32m0.28328[0m[0m | time: 11.125s
[2K
| Adam | epoch: 014 | loss: 0.28328 - acc: 0.9006 -- iter: 320/370
[A[ATraining Step: 167  | total loss: [1m[32m0.27529[0m[0m | time: 12.032s
[2K
| Adam | epoch: 014 | loss: 0.27529 - acc: 0.9042 -- iter: 352/370
[A[ATraining Step: 168  | total loss: [1m[32m0.26677[0m[0m | time: 13.862s
[2K
| Adam | epoch: 014 | loss: 0.26677 - acc: 0.9013 | val_loss: 0.41573 - val_acc: 0.8276 -- iter: 370/370
--
Training Step: 169  | total loss: [1m[32m0.24923[0m[0m | time: 0.603s
[2K
| Adam | epoch: 015 | loss: 0.24923 - acc: 0.9112 -- iter: 032/370
[A[ATraining Step: 170  | total loss: [1m[32m0.23225[0m[0m | time: 1.544s
[2K
| Adam | epoch: 015 | loss: 0.23225 - acc: 0.9201 -- iter: 064/370
[A[ATraining Step: 171  | total loss: [1m[32m0.21953[0m[0m | time: 2.535s
[2K
| Adam | epoch: 015 | loss: 0.21953 - acc: 0.9249 -- iter: 096/370
[A[ATraining Step: 172  | total loss: [1m[32m0.20631[0m[0m | time: 3.494s
[2K
| Adam | epoch: 015 | loss: 0.20631 - acc: 0.9324 -- iter: 128/370
[A[ATraining Step: 173  | total loss: [1m[32m0.19193[0m[0m | time: 4.597s
[2K
| Adam | epoch: 015 | loss: 0.19193 - acc: 0.9392 -- iter: 160/370
[A[ATraining Step: 174  | total loss: [1m[32m0.18561[0m[0m | time: 6.231s
[2K
| Adam | epoch: 015 | loss: 0.18561 - acc: 0.9422 -- iter: 192/370
[A[ATraining Step: 175  | total loss: [1m[32m0.18481[0m[0m | time: 7.675s
[2K
| Adam | epoch: 015 | loss: 0.18481 - acc: 0.9448 -- iter: 224/370
[A[ATraining Step: 176  | total loss: [1m[32m0.17398[0m[0m | time: 9.063s
[2K
| Adam | epoch: 015 | loss: 0.17398 - acc: 0.9503 -- iter: 256/370
[A[ATraining Step: 177  | total loss: [1m[32m0.18243[0m[0m | time: 10.592s
[2K
| Adam | epoch: 015 | loss: 0.18243 - acc: 0.9459 -- iter: 288/370
[A[ATraining Step: 178  | total loss: [1m[32m0.17565[0m[0m | time: 12.009s
[2K
| Adam | epoch: 015 | loss: 0.17565 - acc: 0.9482 -- iter: 320/370
[A[ATraining Step: 179  | total loss: [1m[32m0.17251[0m[0m | time: 13.415s
[2K
| Adam | epoch: 015 | loss: 0.17251 - acc: 0.9503 -- iter: 352/370
[A[ATraining Step: 180  | total loss: [1m[32m0.15916[0m[0m | time: 16.055s
[2K
| Adam | epoch: 015 | loss: 0.15916 - acc: 0.9552 | val_loss: 0.45094 - val_acc: 0.8190 -- iter: 370/370
--
Validation AUC:0.8959761549925483
Validation AUPRC:0.9205251033546633
Test AUC:0.9236778846153846
Test AUPRC:0.9411967859897767
BestTestF1Score	0.89	0.74	0.87	0.87	0.91	58	9	43	6	0.58
BestTestMCCScore	0.89	0.74	0.87	0.87	0.91	58	9	43	6	0.58
BestTestAccuracyScore	0.89	0.74	0.87	0.87	0.91	58	9	43	6	0.58
BestValidationF1Score	0.85	0.67	0.84	0.84	0.85	52	10	45	9	0.58
BestValidationMCC	0.85	0.67	0.84	0.84	0.85	52	10	45	9	0.58
BestValidationAccuracy	0.85	0.67	0.84	0.84	0.85	52	10	45	9	0.58
TestPredictions (Threshold:0.58)
CHEMBL3099661,FP,INACT,0.800000011920929	CHEMBL1940809,TN,INACT,0.029999999329447746	CHEMBL1237298,TP,ACT,1.0	CHEMBL3793209,TP,ACT,0.9800000190734863	CHEMBL313266,TP,ACT,0.9300000071525574	CHEMBL86933,FN,ACT,0.019999999552965164	CHEMBL2096894,TP,ACT,0.949999988079071	CHEMBL313700,TP,ACT,0.9300000071525574	CHEMBL398948,TP,ACT,0.9800000190734863	CHEMBL418386,TN,INACT,0.009999999776482582	CHEMBL11629,TN,INACT,0.12999999523162842	CHEMBL3586362,TP,ACT,0.9800000190734863	CHEMBL3805767,TP,ACT,0.9599999785423279	CHEMBL298612,TN,INACT,0.0	CHEMBL165175,TN,INACT,0.009999999776482582	CHEMBL73164,TN,INACT,0.029999999329447746	CHEMBL3586319,TP,ACT,0.699999988079071	CHEMBL3670659,TP,ACT,0.9599999785423279	CHEMBL3586314,TP,ACT,0.6800000071525574	CHEMBL340501,TP,ACT,0.9900000095367432	CHEMBL52438,TN,INACT,0.05999999865889549	CHEMBL565799,FP,INACT,0.9800000190734863	CHEMBL564845,FP,INACT,0.6600000262260437	CHEMBL3586360,TP,ACT,0.9800000190734863	CHEMBL3586339,TP,ACT,0.9800000190734863	CHEMBL3754197,TP,ACT,0.9800000190734863	CHEMBL124738,TP,ACT,0.9900000095367432	CHEMBL34328,TN,INACT,0.009999999776482582	CHEMBL3670660,TP,ACT,0.9200000166893005	CHEMBL210232,TN,INACT,0.009999999776482582	CHEMBL222782,TP,ACT,1.0	CHEMBL120278,TN,INACT,0.14000000059604645	CHEMBL605330,TP,ACT,0.9800000190734863	CHEMBL521777,TP,ACT,0.9800000190734863	CHEMBL3806284,TP,ACT,0.8100000023841858	CHEMBL42129,TN,INACT,0.33000001311302185	CHEMBL61479,TN,INACT,0.10000000149011612	CHEMBL248678,TP,ACT,0.949999988079071	CHEMBL57908,TN,INACT,0.009999999776482582	CHEMBL3586334,TP,ACT,0.949999988079071	CHEMBL2397392,TN,INACT,0.029999999329447746	CHEMBL413509,TP,ACT,0.9900000095367432	CHEMBL475349,TP,ACT,0.6200000047683716	CHEMBL3805408,TP,ACT,1.0	CHEMBL42219,TN,INACT,0.0	CHEMBL434247,TP,ACT,0.9900000095367432	CHEMBL100624,TN,INACT,0.009999999776482582	CHEMBL217991,FN,ACT,0.5699999928474426	CHEMBL3586337,TP,ACT,1.0	CHEMBL104377,TN,INACT,0.009999999776482582	CHEMBL3670658,TP,ACT,0.8999999761581421	CHEMBL3670656,TP,ACT,0.8399999737739563	CHEMBL181035,TP,ACT,0.9900000095367432	CHEMBL412070,TP,ACT,0.6399999856948853	CHEMBL9746,TN,INACT,0.009999999776482582	CHEMBL428794,FP,INACT,0.9800000190734863	CHEMBL249540,FN,ACT,0.2199999988079071	CHEMBL2164609,TN,INACT,0.15000000596046448	CHEMBL2385904,FN,ACT,0.009999999776482582	CHEMBL3586356,TP,ACT,0.9900000095367432	CHEMBL40796,TN,INACT,0.009999999776482582	CHEMBL218280,TP,ACT,0.9599999785423279	CHEMBL11427,TN,INACT,0.0	CHEMBL11671,TN,INACT,0.009999999776482582	CHEMBL92539,FP,INACT,0.8700000047683716	CHEMBL83450,FP,INACT,0.6000000238418579	CHEMBL42027,TP,ACT,0.9900000095367432	CHEMBL400446,TP,ACT,1.0	CHEMBL10813,TN,INACT,0.009999999776482582	CHEMBL1620339,TN,INACT,0.009999999776482582	CHEMBL124675,TP,ACT,0.9900000095367432	CHEMBL479633,TN,INACT,0.3100000023841858	CHEMBL90269,FP,INACT,0.9399999976158142	CHEMBL229390,TN,INACT,0.0	CHEMBL3793786,TP,ACT,1.0	CHEMBL552615,TN,INACT,0.019999999552965164	CHEMBL565992,FN,ACT,0.44999998807907104	CHEMBL3806076,TP,ACT,1.0	CHEMBL2052006,TN,INACT,0.009999999776482582	CHEMBL398827,TP,ACT,1.0	CHEMBL46395,TN,INACT,0.3700000047683716	CHEMBL143304,TN,INACT,0.10000000149011612	CHEMBL360290,TP,ACT,0.9900000095367432	CHEMBL26782,TN,INACT,0.03999999910593033	CHEMBL64102,FP,INACT,0.8999999761581421	CHEMBL426387,TP,ACT,0.7099999785423279	CHEMBL2386081,TP,ACT,0.7099999785423279	CHEMBL3805554,TP,ACT,1.0	CHEMBL1668898,TN,INACT,0.4300000071525574	CHEMBL86886,TP,ACT,0.9200000166893005	CHEMBL10404,TN,INACT,0.05999999865889549	CHEMBL45418,FP,INACT,0.9700000286102295	CHEMBL479664,FN,ACT,0.15000000596046448	CHEMBL3586338,TP,ACT,1.0	CHEMBL560993,TN,INACT,0.5600000023841858	CHEMBL404414,TP,ACT,1.0	CHEMBL119291,TN,INACT,0.4000000059604645	CHEMBL332446,TP,ACT,0.9700000286102295	CHEMBL314616,TN,INACT,0.5799999833106995	CHEMBL3805316,TP,ACT,1.0	CHEMBL389734,TN,INACT,0.009999999776482582	CHEMBL3670655,TP,ACT,0.8500000238418579	CHEMBL3084424,TN,INACT,0.20999999344348907	CHEMBL257217,TP,ACT,0.9700000286102295	CHEMBL39334,TN,INACT,0.47999998927116394	CHEMBL1765667,TN,INACT,0.05999999865889549	CHEMBL3586320,TP,ACT,0.6600000262260437	CHEMBL3586312,TP,ACT,0.9900000095367432	CHEMBL432380,TN,INACT,0.07999999821186066	CHEMBL87816,TP,ACT,0.9900000095367432	CHEMBL3586316,TP,ACT,1.0	CHEMBL3751951,TP,ACT,1.0	CHEMBL1237295,TP,ACT,1.0	CHEMBL229400,TN,INACT,0.0	CHEMBL224970,TP,ACT,0.9900000095367432	CHEMBL2443010,TN,INACT,0.029999999329447746	

