CNNModel CHEMBL5285 adam 0.0005 30 256 0 0.6 False True
Number of active compounds :	120
Number of inactive compounds :	120
---------------------------------
Run id: CNNModel_CHEMBL5285_adam_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5285_adam_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 153
Validation samples: 48
--
Training Step: 1  | time: 0.752s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/153
[A[ATraining Step: 2  | total loss: [1m[32m0.62348[0m[0m | time: 1.357s
[2K
| Adam | epoch: 001 | loss: 0.62348 - acc: 0.5344 -- iter: 064/153
[A[ATraining Step: 3  | total loss: [1m[32m0.67898[0m[0m | time: 1.952s
[2K
| Adam | epoch: 001 | loss: 0.67898 - acc: 0.5574 -- iter: 096/153
[A[ATraining Step: 4  | total loss: [1m[32m0.69219[0m[0m | time: 2.544s
[2K
| Adam | epoch: 001 | loss: 0.69219 - acc: 0.4909 -- iter: 128/153
[A[ATraining Step: 5  | total loss: [1m[32m0.69134[0m[0m | time: 4.051s
[2K
| Adam | epoch: 001 | loss: 0.69134 - acc: 0.5188 | val_loss: 0.70097 - val_acc: 0.3958 -- iter: 153/153
--
Training Step: 6  | total loss: [1m[32m0.69316[0m[0m | time: 0.505s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.4939 -- iter: 032/153
[A[ATraining Step: 7  | total loss: [1m[32m0.69451[0m[0m | time: 1.115s
[2K
| Adam | epoch: 002 | loss: 0.69451 - acc: 0.4855 -- iter: 064/153
[A[ATraining Step: 8  | total loss: [1m[32m0.69382[0m[0m | time: 1.728s
[2K
| Adam | epoch: 002 | loss: 0.69382 - acc: 0.4937 -- iter: 096/153
[A[ATraining Step: 9  | total loss: [1m[32m0.69356[0m[0m | time: 2.336s
[2K
| Adam | epoch: 002 | loss: 0.69356 - acc: 0.4970 -- iter: 128/153
[A[ATraining Step: 10  | total loss: [1m[32m0.69376[0m[0m | time: 3.953s
[2K
| Adam | epoch: 002 | loss: 0.69376 - acc: 0.4829 | val_loss: 0.69463 - val_acc: 0.3958 -- iter: 153/153
--
Training Step: 11  | total loss: [1m[32m0.69299[0m[0m | time: 0.484s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5206 -- iter: 032/153
[A[ATraining Step: 12  | total loss: [1m[32m0.69414[0m[0m | time: 0.965s
[2K
| Adam | epoch: 003 | loss: 0.69414 - acc: 0.4483 -- iter: 064/153
[A[ATraining Step: 13  | total loss: [1m[32m0.69415[0m[0m | time: 1.566s
[2K
| Adam | epoch: 003 | loss: 0.69415 - acc: 0.4105 -- iter: 096/153
[A[ATraining Step: 14  | total loss: [1m[32m0.69343[0m[0m | time: 2.191s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.5238 -- iter: 128/153
[A[ATraining Step: 15  | total loss: [1m[32m0.69428[0m[0m | time: 3.811s
[2K
| Adam | epoch: 003 | loss: 0.69428 - acc: 0.4289 | val_loss: 0.69212 - val_acc: 0.6042 -- iter: 153/153
--
Training Step: 16  | total loss: [1m[32m0.69387[0m[0m | time: 0.603s
[2K
| Adam | epoch: 004 | loss: 0.69387 - acc: 0.4556 -- iter: 032/153
[A[ATraining Step: 17  | total loss: [1m[32m0.69326[0m[0m | time: 1.122s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.5053 -- iter: 064/153
[A[ATraining Step: 18  | total loss: [1m[32m0.69362[0m[0m | time: 1.620s
[2K
| Adam | epoch: 004 | loss: 0.69362 - acc: 0.4689 -- iter: 096/153
[A[ATraining Step: 19  | total loss: [1m[32m0.69378[0m[0m | time: 2.221s
[2K
| Adam | epoch: 004 | loss: 0.69378 - acc: 0.4459 -- iter: 128/153
[A[ATraining Step: 20  | total loss: [1m[32m0.69350[0m[0m | time: 3.839s
[2K
| Adam | epoch: 004 | loss: 0.69350 - acc: 0.4733 | val_loss: 0.69266 - val_acc: 0.6042 -- iter: 153/153
--
Training Step: 21  | total loss: [1m[32m0.69350[0m[0m | time: 0.615s
[2K
| Adam | epoch: 005 | loss: 0.69350 - acc: 0.4719 -- iter: 032/153
[A[ATraining Step: 22  | total loss: [1m[32m0.69334[0m[0m | time: 1.233s
[2K
| Adam | epoch: 005 | loss: 0.69334 - acc: 0.4991 -- iter: 064/153
[A[ATraining Step: 23  | total loss: [1m[32m0.69332[0m[0m | time: 1.725s
[2K
| Adam | epoch: 005 | loss: 0.69332 - acc: 0.4903 -- iter: 096/153
[A[ATraining Step: 24  | total loss: [1m[32m0.69330[0m[0m | time: 2.228s
[2K
| Adam | epoch: 005 | loss: 0.69330 - acc: 0.4874 -- iter: 128/153
[A[ATraining Step: 25  | total loss: [1m[32m0.69324[0m[0m | time: 3.834s
[2K
| Adam | epoch: 005 | loss: 0.69324 - acc: 0.4854 | val_loss: 0.69342 - val_acc: 0.3958 -- iter: 153/153
--
Training Step: 26  | total loss: [1m[32m0.69321[0m[0m | time: 0.614s
[2K
| Adam | epoch: 006 | loss: 0.69321 - acc: 0.4892 -- iter: 032/153
[A[ATraining Step: 27  | total loss: [1m[32m0.69320[0m[0m | time: 1.225s
[2K
| Adam | epoch: 006 | loss: 0.69320 - acc: 0.4840 -- iter: 064/153
[A[ATraining Step: 28  | total loss: [1m[32m0.69322[0m[0m | time: 1.825s
[2K
| Adam | epoch: 006 | loss: 0.69322 - acc: 0.4802 -- iter: 096/153
[A[ATraining Step: 29  | total loss: [1m[32m0.69314[0m[0m | time: 2.323s
[2K
| Adam | epoch: 006 | loss: 0.69314 - acc: 0.5002 -- iter: 128/153
[A[ATraining Step: 30  | total loss: [1m[32m0.69311[0m[0m | time: 3.810s
[2K
| Adam | epoch: 006 | loss: 0.69311 - acc: 0.4954 | val_loss: 0.69362 - val_acc: 0.3958 -- iter: 153/153
--
Training Step: 31  | total loss: [1m[32m0.69310[0m[0m | time: 0.608s
[2K
| Adam | epoch: 007 | loss: 0.69310 - acc: 0.4919 -- iter: 032/153
[A[ATraining Step: 32  | total loss: [1m[32m0.69312[0m[0m | time: 1.222s
[2K
| Adam | epoch: 007 | loss: 0.69312 - acc: 0.4867 -- iter: 064/153
[A[ATraining Step: 33  | total loss: [1m[32m0.69308[0m[0m | time: 1.821s
[2K
| Adam | epoch: 007 | loss: 0.69308 - acc: 0.4896 -- iter: 096/153
[A[ATraining Step: 34  | total loss: [1m[32m0.69305[0m[0m | time: 2.417s
[2K
| Adam | epoch: 007 | loss: 0.69305 - acc: 0.4985 -- iter: 128/153
[A[ATraining Step: 35  | total loss: [1m[32m0.69313[0m[0m | time: 3.908s
[2K
| Adam | epoch: 007 | loss: 0.69313 - acc: 0.4792 | val_loss: 0.69327 - val_acc: 0.3958 -- iter: 153/153
--
Training Step: 36  | total loss: [1m[32m0.69311[0m[0m | time: 0.489s
[2K
| Adam | epoch: 008 | loss: 0.69311 - acc: 0.4794 -- iter: 032/153
[A[ATraining Step: 37  | total loss: [1m[32m0.69310[0m[0m | time: 1.101s
[2K
| Adam | epoch: 008 | loss: 0.69310 - acc: 0.4795 -- iter: 064/153
[A[ATraining Step: 38  | total loss: [1m[32m0.69307[0m[0m | time: 1.714s
[2K
| Adam | epoch: 008 | loss: 0.69307 - acc: 0.5141 -- iter: 096/153
[A[ATraining Step: 39  | total loss: [1m[32m0.69296[0m[0m | time: 2.310s
[2K
| Adam | epoch: 008 | loss: 0.69296 - acc: 0.5293 -- iter: 128/153
[A[ATraining Step: 40  | total loss: [1m[32m0.69285[0m[0m | time: 3.926s
[2K
| Adam | epoch: 008 | loss: 0.69285 - acc: 0.5238 | val_loss: 0.69491 - val_acc: 0.3958 -- iter: 153/153
--
Training Step: 41  | total loss: [1m[32m0.69260[0m[0m | time: 0.489s
[2K
| Adam | epoch: 009 | loss: 0.69260 - acc: 0.5424 -- iter: 032/153
[A[ATraining Step: 42  | total loss: [1m[32m0.69254[0m[0m | time: 0.970s
[2K
| Adam | epoch: 009 | loss: 0.69254 - acc: 0.5384 -- iter: 064/153
[A[ATraining Step: 43  | total loss: [1m[32m0.69242[0m[0m | time: 1.572s
[2K
| Adam | epoch: 009 | loss: 0.69242 - acc: 0.5351 -- iter: 096/153
[A[ATraining Step: 44  | total loss: [1m[32m0.69235[0m[0m | time: 2.208s
[2K
| Adam | epoch: 009 | loss: 0.69235 - acc: 0.5291 -- iter: 128/153
[A[ATraining Step: 45  | total loss: [1m[32m0.69365[0m[0m | time: 3.811s
[2K
| Adam | epoch: 009 | loss: 0.69365 - acc: 0.4976 | val_loss: 0.69394 - val_acc: 0.3958 -- iter: 153/153
--
Training Step: 46  | total loss: [1m[32m0.69290[0m[0m | time: 0.600s
[2K
| Adam | epoch: 010 | loss: 0.69290 - acc: 0.5084 -- iter: 032/153
[A[ATraining Step: 47  | total loss: [1m[32m0.69284[0m[0m | time: 1.092s
[2K
| Adam | epoch: 010 | loss: 0.69284 - acc: 0.5070 -- iter: 064/153
[A[ATraining Step: 48  | total loss: [1m[32m0.69271[0m[0m | time: 1.579s
[2K
| Adam | epoch: 010 | loss: 0.69271 - acc: 0.5284 -- iter: 096/153
[A[ATraining Step: 49  | total loss: [1m[32m0.69255[0m[0m | time: 2.176s
[2K
| Adam | epoch: 010 | loss: 0.69255 - acc: 0.5587 -- iter: 128/153
[A[ATraining Step: 50  | total loss: [1m[32m0.69200[0m[0m | time: 3.793s
[2K
| Adam | epoch: 010 | loss: 0.69200 - acc: 0.5883 | val_loss: 0.69363 - val_acc: 0.3958 -- iter: 153/153
--
Training Step: 51  | total loss: [1m[32m0.69195[0m[0m | time: 0.594s
[2K
| Adam | epoch: 011 | loss: 0.69195 - acc: 0.5606 -- iter: 032/153
[A[ATraining Step: 52  | total loss: [1m[32m0.69107[0m[0m | time: 1.204s
[2K
| Adam | epoch: 011 | loss: 0.69107 - acc: 0.5655 -- iter: 064/153
[A[ATraining Step: 53  | total loss: [1m[32m0.69049[0m[0m | time: 1.723s
[2K
| Adam | epoch: 011 | loss: 0.69049 - acc: 0.5605 -- iter: 096/153
[A[ATraining Step: 54  | total loss: [1m[32m0.69044[0m[0m | time: 2.204s
[2K
| Adam | epoch: 011 | loss: 0.69044 - acc: 0.5430 -- iter: 128/153
[A[ATraining Step: 55  | total loss: [1m[32m0.69014[0m[0m | time: 3.808s
[2K
| Adam | epoch: 011 | loss: 0.69014 - acc: 0.5283 | val_loss: 0.68946 - val_acc: 0.6250 -- iter: 153/153
--
Training Step: 56  | total loss: [1m[32m0.68947[0m[0m | time: 0.651s
[2K
| Adam | epoch: 012 | loss: 0.68947 - acc: 0.5551 -- iter: 032/153
[A[ATraining Step: 57  | total loss: [1m[32m0.68880[0m[0m | time: 1.256s
[2K
| Adam | epoch: 012 | loss: 0.68880 - acc: 0.5777 -- iter: 064/153
[A[ATraining Step: 58  | total loss: [1m[32m0.68748[0m[0m | time: 1.877s
[2K
| Adam | epoch: 012 | loss: 0.68748 - acc: 0.6012 -- iter: 096/153
[A[ATraining Step: 59  | total loss: [1m[32m0.68541[0m[0m | time: 2.370s
[2K
| Adam | epoch: 012 | loss: 0.68541 - acc: 0.6044 -- iter: 128/153
[A[ATraining Step: 60  | total loss: [1m[32m0.68659[0m[0m | time: 3.891s
[2K
| Adam | epoch: 012 | loss: 0.68659 - acc: 0.5879 | val_loss: 0.68468 - val_acc: 0.6875 -- iter: 153/153
--
Training Step: 61  | total loss: [1m[32m0.68678[0m[0m | time: 0.617s
[2K
| Adam | epoch: 013 | loss: 0.68678 - acc: 0.5843 -- iter: 032/153
[A[ATraining Step: 62  | total loss: [1m[32m0.68340[0m[0m | time: 1.216s
[2K
| Adam | epoch: 013 | loss: 0.68340 - acc: 0.6257 -- iter: 064/153
[A[ATraining Step: 63  | total loss: [1m[32m0.68321[0m[0m | time: 1.815s
[2K
| Adam | epoch: 013 | loss: 0.68321 - acc: 0.6296 -- iter: 096/153
[A[ATraining Step: 64  | total loss: [1m[32m0.67853[0m[0m | time: 2.455s
[2K
| Adam | epoch: 013 | loss: 0.67853 - acc: 0.6563 -- iter: 128/153
[A[ATraining Step: 65  | total loss: [1m[32m0.67393[0m[0m | time: 3.936s
[2K
| Adam | epoch: 013 | loss: 0.67393 - acc: 0.6602 | val_loss: 0.70152 - val_acc: 0.4792 -- iter: 153/153
--
Training Step: 66  | total loss: [1m[32m0.66683[0m[0m | time: 0.485s
[2K
| Adam | epoch: 014 | loss: 0.66683 - acc: 0.6723 -- iter: 032/153
[A[ATraining Step: 67  | total loss: [1m[32m0.65945[0m[0m | time: 1.067s
[2K
| Adam | epoch: 014 | loss: 0.65945 - acc: 0.6828 -- iter: 064/153
[A[ATraining Step: 68  | total loss: [1m[32m0.65547[0m[0m | time: 1.678s
[2K
| Adam | epoch: 014 | loss: 0.65547 - acc: 0.6834 -- iter: 096/153
[A[ATraining Step: 69  | total loss: [1m[32m0.65783[0m[0m | time: 2.301s
[2K
| Adam | epoch: 014 | loss: 0.65783 - acc: 0.6656 -- iter: 128/153
[A[ATraining Step: 70  | total loss: [1m[32m0.65403[0m[0m | time: 3.928s
[2K
| Adam | epoch: 014 | loss: 0.65403 - acc: 0.6681 | val_loss: 0.64967 - val_acc: 0.6667 -- iter: 153/153
--
Training Step: 71  | total loss: [1m[32m0.65492[0m[0m | time: 0.509s
[2K
| Adam | epoch: 015 | loss: 0.65492 - acc: 0.6632 -- iter: 032/153
[A[ATraining Step: 72  | total loss: [1m[32m0.64272[0m[0m | time: 1.009s
[2K
| Adam | epoch: 015 | loss: 0.64272 - acc: 0.6831 -- iter: 064/153
[A[ATraining Step: 73  | total loss: [1m[32m0.63149[0m[0m | time: 1.612s
[2K
| Adam | epoch: 015 | loss: 0.63149 - acc: 0.6961 -- iter: 096/153
[A[ATraining Step: 74  | total loss: [1m[32m0.61132[0m[0m | time: 2.212s
[2K
| Adam | epoch: 015 | loss: 0.61132 - acc: 0.7192 -- iter: 128/153
[A[ATraining Step: 75  | total loss: [1m[32m0.61353[0m[0m | time: 3.805s
[2K
| Adam | epoch: 015 | loss: 0.61353 - acc: 0.7191 | val_loss: 0.62443 - val_acc: 0.6042 -- iter: 153/153
--
Training Step: 76  | total loss: [1m[32m0.60024[0m[0m | time: 0.600s
[2K
| Adam | epoch: 016 | loss: 0.60024 - acc: 0.7258 -- iter: 032/153
[A[ATraining Step: 77  | total loss: [1m[32m0.58622[0m[0m | time: 1.120s
[2K
| Adam | epoch: 016 | loss: 0.58622 - acc: 0.7383 -- iter: 064/153
[A[ATraining Step: 78  | total loss: [1m[32m0.57887[0m[0m | time: 1.613s
[2K
| Adam | epoch: 016 | loss: 0.57887 - acc: 0.7364 -- iter: 096/153
[A[ATraining Step: 79  | total loss: [1m[32m0.57154[0m[0m | time: 2.222s
[2K
| Adam | epoch: 016 | loss: 0.57154 - acc: 0.7429 -- iter: 128/153
[A[ATraining Step: 80  | total loss: [1m[32m0.55002[0m[0m | time: 3.831s
[2K
| Adam | epoch: 016 | loss: 0.55002 - acc: 0.7564 | val_loss: 0.62796 - val_acc: 0.7292 -- iter: 153/153
--
Training Step: 81  | total loss: [1m[32m0.55200[0m[0m | time: 0.601s
[2K
| Adam | epoch: 017 | loss: 0.55200 - acc: 0.7526 -- iter: 032/153
[A[ATraining Step: 82  | total loss: [1m[32m0.52571[0m[0m | time: 1.195s
[2K
| Adam | epoch: 017 | loss: 0.52571 - acc: 0.7680 -- iter: 064/153
[A[ATraining Step: 83  | total loss: [1m[32m0.52071[0m[0m | time: 1.680s
[2K
| Adam | epoch: 017 | loss: 0.52071 - acc: 0.7693 -- iter: 096/153
[A[ATraining Step: 84  | total loss: [1m[32m0.51370[0m[0m | time: 2.167s
[2K
| Adam | epoch: 017 | loss: 0.51370 - acc: 0.7684 -- iter: 128/153
[A[ATraining Step: 85  | total loss: [1m[32m0.49833[0m[0m | time: 3.766s
[2K
| Adam | epoch: 017 | loss: 0.49833 - acc: 0.7755 | val_loss: 0.80295 - val_acc: 0.7083 -- iter: 153/153
--
Training Step: 86  | total loss: [1m[32m0.47703[0m[0m | time: 0.598s
[2K
| Adam | epoch: 018 | loss: 0.47703 - acc: 0.7824 -- iter: 032/153
[A[ATraining Step: 87  | total loss: [1m[32m0.47904[0m[0m | time: 1.218s
[2K
| Adam | epoch: 018 | loss: 0.47904 - acc: 0.7854 -- iter: 064/153
[A[ATraining Step: 88  | total loss: [1m[32m0.45794[0m[0m | time: 1.823s
[2K
| Adam | epoch: 018 | loss: 0.45794 - acc: 0.8037 -- iter: 096/153
[A[ATraining Step: 89  | total loss: [1m[32m0.43629[0m[0m | time: 2.308s
[2K
| Adam | epoch: 018 | loss: 0.43629 - acc: 0.8171 -- iter: 128/153
[A[ATraining Step: 90  | total loss: [1m[32m0.42200[0m[0m | time: 3.812s
[2K
| Adam | epoch: 018 | loss: 0.42200 - acc: 0.8234 | val_loss: 0.72148 - val_acc: 0.7292 -- iter: 153/153
--
Training Step: 91  | total loss: [1m[32m0.40100[0m[0m | time: 0.606s
[2K
| Adam | epoch: 019 | loss: 0.40100 - acc: 0.8330 -- iter: 032/153
[A[ATraining Step: 92  | total loss: [1m[32m0.40312[0m[0m | time: 1.210s
[2K
| Adam | epoch: 019 | loss: 0.40312 - acc: 0.8310 -- iter: 064/153
[A[ATraining Step: 93  | total loss: [1m[32m0.40039[0m[0m | time: 1.814s
[2K
| Adam | epoch: 019 | loss: 0.40039 - acc: 0.8323 -- iter: 096/153
[A[ATraining Step: 94  | total loss: [1m[32m0.39167[0m[0m | time: 2.412s
[2K
| Adam | epoch: 019 | loss: 0.39167 - acc: 0.8397 -- iter: 128/153
[A[ATraining Step: 95  | total loss: [1m[32m0.38404[0m[0m | time: 3.897s
[2K
| Adam | epoch: 019 | loss: 0.38404 - acc: 0.8338 | val_loss: 0.44390 - val_acc: 0.7917 -- iter: 153/153
--
Training Step: 96  | total loss: [1m[32m0.35537[0m[0m | time: 0.495s
[2K
| Adam | epoch: 020 | loss: 0.35537 - acc: 0.8504 -- iter: 032/153
[A[ATraining Step: 97  | total loss: [1m[32m0.32867[0m[0m | time: 1.125s
[2K
| Adam | epoch: 020 | loss: 0.32867 - acc: 0.8654 -- iter: 064/153
[A[ATraining Step: 98  | total loss: [1m[32m0.31025[0m[0m | time: 1.727s
[2K
| Adam | epoch: 020 | loss: 0.31025 - acc: 0.8757 -- iter: 096/153
[A[ATraining Step: 99  | total loss: [1m[32m0.32311[0m[0m | time: 2.333s
[2K
| Adam | epoch: 020 | loss: 0.32311 - acc: 0.8663 -- iter: 128/153
[A[ATraining Step: 100  | total loss: [1m[32m0.33213[0m[0m | time: 3.975s
[2K
| Adam | epoch: 020 | loss: 0.33213 - acc: 0.8515 | val_loss: 0.44836 - val_acc: 0.8125 -- iter: 153/153
--
Training Step: 101  | total loss: [1m[32m0.31466[0m[0m | time: 0.501s
[2K
| Adam | epoch: 021 | loss: 0.31466 - acc: 0.8601 -- iter: 032/153
[A[ATraining Step: 102  | total loss: [1m[32m0.29443[0m[0m | time: 0.982s
[2K
| Adam | epoch: 021 | loss: 0.29443 - acc: 0.8741 -- iter: 064/153
[A[ATraining Step: 103  | total loss: [1m[32m0.27900[0m[0m | time: 1.610s
[2K
| Adam | epoch: 021 | loss: 0.27900 - acc: 0.8867 -- iter: 096/153
[A[ATraining Step: 104  | total loss: [1m[32m0.25871[0m[0m | time: 2.258s
[2K
| Adam | epoch: 021 | loss: 0.25871 - acc: 0.8949 -- iter: 128/153
[A[ATraining Step: 105  | total loss: [1m[32m0.24327[0m[0m | time: 3.866s
[2K
| Adam | epoch: 021 | loss: 0.24327 - acc: 0.9023 | val_loss: 0.38756 - val_acc: 0.8333 -- iter: 153/153
--
Training Step: 106  | total loss: [1m[32m0.24835[0m[0m | time: 0.624s
[2K
| Adam | epoch: 022 | loss: 0.24835 - acc: 0.9089 -- iter: 032/153
[A[ATraining Step: 107  | total loss: [1m[32m0.24232[0m[0m | time: 1.135s
[2K
| Adam | epoch: 022 | loss: 0.24232 - acc: 0.9087 -- iter: 064/153
[A[ATraining Step: 108  | total loss: [1m[32m0.22704[0m[0m | time: 1.616s
[2K
| Adam | epoch: 022 | loss: 0.22704 - acc: 0.9178 -- iter: 096/153
[A[ATraining Step: 109  | total loss: [1m[32m0.21213[0m[0m | time: 2.242s
[2K
| Adam | epoch: 022 | loss: 0.21213 - acc: 0.9260 -- iter: 128/153
[A[ATraining Step: 110  | total loss: [1m[32m0.19825[0m[0m | time: 3.843s
[2K
| Adam | epoch: 022 | loss: 0.19825 - acc: 0.9303 | val_loss: 0.40990 - val_acc: 0.8125 -- iter: 153/153
--
Training Step: 111  | total loss: [1m[32m0.18887[0m[0m | time: 0.612s
[2K
| Adam | epoch: 023 | loss: 0.18887 - acc: 0.9310 -- iter: 032/153
[A[ATraining Step: 112  | total loss: [1m[32m0.19191[0m[0m | time: 1.220s
[2K
| Adam | epoch: 023 | loss: 0.19191 - acc: 0.9348 -- iter: 064/153
[A[ATraining Step: 113  | total loss: [1m[32m0.18358[0m[0m | time: 1.704s
[2K
| Adam | epoch: 023 | loss: 0.18358 - acc: 0.9382 -- iter: 096/153
[A[ATraining Step: 114  | total loss: [1m[32m0.18112[0m[0m | time: 2.187s
[2K
| Adam | epoch: 023 | loss: 0.18112 - acc: 0.9364 -- iter: 128/153
[A[ATraining Step: 115  | total loss: [1m[32m0.16892[0m[0m | time: 3.794s
[2K
| Adam | epoch: 023 | loss: 0.16892 - acc: 0.9387 | val_loss: 0.72456 - val_acc: 0.8125 -- iter: 153/153
--
Training Step: 116  | total loss: [1m[32m0.17385[0m[0m | time: 0.618s
[2K
| Adam | epoch: 024 | loss: 0.17385 - acc: 0.9355 -- iter: 032/153
[A[ATraining Step: 117  | total loss: [1m[32m0.17368[0m[0m | time: 1.233s
[2K
| Adam | epoch: 024 | loss: 0.17368 - acc: 0.9326 -- iter: 064/153
[A[ATraining Step: 118  | total loss: [1m[32m0.19945[0m[0m | time: 1.837s
[2K
| Adam | epoch: 024 | loss: 0.19945 - acc: 0.9299 -- iter: 096/153
[A[ATraining Step: 119  | total loss: [1m[32m0.18741[0m[0m | time: 2.333s
[2K
| Adam | epoch: 024 | loss: 0.18741 - acc: 0.9338 -- iter: 128/153
[A[ATraining Step: 120  | total loss: [1m[32m0.19529[0m[0m | time: 3.835s
[2K
| Adam | epoch: 024 | loss: 0.19529 - acc: 0.9244 | val_loss: 0.74081 - val_acc: 0.7292 -- iter: 153/153
--
Training Step: 121  | total loss: [1m[32m0.21363[0m[0m | time: 0.655s
[2K
| Adam | epoch: 025 | loss: 0.21363 - acc: 0.9160 -- iter: 032/153
[A[ATraining Step: 122  | total loss: [1m[32m0.24315[0m[0m | time: 1.276s
[2K
| Adam | epoch: 025 | loss: 0.24315 - acc: 0.8963 -- iter: 064/153
[A[ATraining Step: 123  | total loss: [1m[32m0.22835[0m[0m | time: 1.892s
[2K
| Adam | epoch: 025 | loss: 0.22835 - acc: 0.9035 -- iter: 096/153
[A[ATraining Step: 124  | total loss: [1m[32m0.20800[0m[0m | time: 2.516s
[2K
| Adam | epoch: 025 | loss: 0.20800 - acc: 0.9132 -- iter: 128/153
[A[ATraining Step: 125  | total loss: [1m[32m0.24704[0m[0m | time: 3.996s
[2K
| Adam | epoch: 025 | loss: 0.24704 - acc: 0.8937 | val_loss: 0.89776 - val_acc: 0.7708 -- iter: 153/153
--
Training Step: 126  | total loss: [1m[32m0.24446[0m[0m | time: 0.515s
[2K
| Adam | epoch: 026 | loss: 0.24446 - acc: 0.8883 -- iter: 032/153
[A[ATraining Step: 127  | total loss: [1m[32m0.23454[0m[0m | time: 1.117s
[2K
| Adam | epoch: 026 | loss: 0.23454 - acc: 0.8955 -- iter: 064/153
[A[ATraining Step: 128  | total loss: [1m[32m0.22152[0m[0m | time: 1.723s
[2K
| Adam | epoch: 026 | loss: 0.22152 - acc: 0.8997 -- iter: 096/153
[A[ATraining Step: 129  | total loss: [1m[32m0.20409[0m[0m | time: 2.313s
[2K
| Adam | epoch: 026 | loss: 0.20409 - acc: 0.9097 -- iter: 128/153
[A[ATraining Step: 130  | total loss: [1m[32m0.22574[0m[0m | time: 3.910s
[2K
| Adam | epoch: 026 | loss: 0.22574 - acc: 0.9125 | val_loss: 0.46477 - val_acc: 0.8125 -- iter: 153/153
--
Training Step: 131  | total loss: [1m[32m0.23038[0m[0m | time: 0.484s
[2K
| Adam | epoch: 027 | loss: 0.23038 - acc: 0.9119 -- iter: 032/153
[A[ATraining Step: 132  | total loss: [1m[32m0.21784[0m[0m | time: 0.987s
[2K
| Adam | epoch: 027 | loss: 0.21784 - acc: 0.9127 -- iter: 064/153
[A[ATraining Step: 133  | total loss: [1m[32m0.19961[0m[0m | time: 1.600s
[2K
| Adam | epoch: 027 | loss: 0.19961 - acc: 0.9214 -- iter: 096/153
[A[ATraining Step: 134  | total loss: [1m[32m0.18284[0m[0m | time: 2.260s
[2K
| Adam | epoch: 027 | loss: 0.18284 - acc: 0.9293 -- iter: 128/153
[A[ATraining Step: 135  | total loss: [1m[32m0.17650[0m[0m | time: 3.870s
[2K
| Adam | epoch: 027 | loss: 0.17650 - acc: 0.9332 | val_loss: 0.46994 - val_acc: 0.8333 -- iter: 153/153
--
Training Step: 136  | total loss: [1m[32m0.20686[0m[0m | time: 0.599s
[2K
| Adam | epoch: 028 | loss: 0.20686 - acc: 0.9274 -- iter: 032/153
[A[ATraining Step: 137  | total loss: [1m[32m0.19027[0m[0m | time: 1.103s
[2K
| Adam | epoch: 028 | loss: 0.19027 - acc: 0.9315 -- iter: 064/153
[A[ATraining Step: 138  | total loss: [1m[32m0.17337[0m[0m | time: 1.607s
[2K
| Adam | epoch: 028 | loss: 0.17337 - acc: 0.9384 -- iter: 096/153
[A[ATraining Step: 139  | total loss: [1m[32m0.15859[0m[0m | time: 2.211s
[2K
| Adam | epoch: 028 | loss: 0.15859 - acc: 0.9446 -- iter: 128/153
[A[ATraining Step: 140  | total loss: [1m[32m0.14882[0m[0m | time: 3.838s
[2K
| Adam | epoch: 028 | loss: 0.14882 - acc: 0.9501 | val_loss: 0.37773 - val_acc: 0.7917 -- iter: 153/153
--
Training Step: 141  | total loss: [1m[32m0.13887[0m[0m | time: 0.627s
[2K
| Adam | epoch: 029 | loss: 0.13887 - acc: 0.9551 -- iter: 032/153
[A[ATraining Step: 142  | total loss: [1m[32m0.12870[0m[0m | time: 1.235s
[2K
| Adam | epoch: 029 | loss: 0.12870 - acc: 0.9596 -- iter: 064/153
[A[ATraining Step: 143  | total loss: [1m[32m0.11869[0m[0m | time: 1.723s
[2K
| Adam | epoch: 029 | loss: 0.11869 - acc: 0.9636 -- iter: 096/153
[A[ATraining Step: 144  | total loss: [1m[32m0.10903[0m[0m | time: 2.214s
[2K
| Adam | epoch: 029 | loss: 0.10903 - acc: 0.9673 -- iter: 128/153
[A[ATraining Step: 145  | total loss: [1m[32m0.10042[0m[0m | time: 3.836s
[2K
| Adam | epoch: 029 | loss: 0.10042 - acc: 0.9705 | val_loss: 0.48612 - val_acc: 0.8333 -- iter: 153/153
--
Training Step: 146  | total loss: [1m[32m0.09336[0m[0m | time: 0.595s
[2K
| Adam | epoch: 030 | loss: 0.09336 - acc: 0.9735 -- iter: 032/153
[A[ATraining Step: 147  | total loss: [1m[32m0.09665[0m[0m | time: 1.197s
[2K
| Adam | epoch: 030 | loss: 0.09665 - acc: 0.9730 -- iter: 064/153
[A[ATraining Step: 148  | total loss: [1m[32m0.10639[0m[0m | time: 1.796s
[2K
| Adam | epoch: 030 | loss: 0.10639 - acc: 0.9726 -- iter: 096/153
[A[ATraining Step: 149  | total loss: [1m[32m0.09691[0m[0m | time: 2.287s
[2K
| Adam | epoch: 030 | loss: 0.09691 - acc: 0.9753 -- iter: 128/153
[A[ATraining Step: 150  | total loss: [1m[32m0.09208[0m[0m | time: 3.783s
[2K
| Adam | epoch: 030 | loss: 0.09208 - acc: 0.9778 | val_loss: 0.46806 - val_acc: 0.8125 -- iter: 153/153
--
Validation AUC:0.9292196007259528
Validation AUPRC:0.9611759748908906
Test AUC:0.9927404718693285
Test AUPRC:0.9892934089609988
BestTestF1Score	0.93	0.88	0.94	0.86	1.0	19	3	26	0	0.87
BestTestMCCScore	0.93	0.88	0.94	0.86	1.0	19	3	26	0	0.87
BestTestAccuracyScore	0.93	0.88	0.94	0.86	1.0	19	3	26	0	0.87
BestValidationF1Score	0.89	0.75	0.88	0.93	0.86	25	2	17	4	0.87
BestValidationMCC	0.89	0.75	0.88	0.93	0.86	25	2	17	4	0.87
BestValidationAccuracy	0.89	0.75	0.88	0.93	0.86	25	2	17	4	0.87
TestPredictions (Threshold:0.87)
CHEMBL102622,TN,INACT,0.20000000298023224	CHEMBL3402498,TP,ACT,0.9900000095367432	CHEMBL2392355,TN,INACT,0.46000000834465027	CHEMBL3644044,TP,ACT,1.0	CHEMBL2349208,TP,ACT,1.0	CHEMBL3400829,TN,INACT,0.6000000238418579	CHEMBL1087421,TN,INACT,0.03999999910593033	CHEMBL3402503,TP,ACT,1.0	CHEMBL3683261,TP,ACT,1.0	CHEMBL486487,TN,INACT,0.3199999928474426	CHEMBL2349207,TP,ACT,0.9900000095367432	CHEMBL557050,TN,INACT,0.0	CHEMBL1287914,TN,INACT,0.23999999463558197	CHEMBL1081198,TN,INACT,0.05000000074505806	CHEMBL1734241,TN,INACT,0.28999999165534973	CHEMBL3644041,TP,ACT,1.0	CHEMBL3402505,TP,ACT,1.0	CHEMBL3330172,TP,ACT,0.9800000190734863	CHEMBL67655,TN,INACT,0.1599999964237213	CHEMBL490241,TN,INACT,0.6800000071525574	CHEMBL1922210,TN,INACT,0.009999999776482582	CHEMBL3644045,TP,ACT,0.9700000286102295	CHEMBL1287975,TN,INACT,0.03999999910593033	CHEMBL1933802,TN,INACT,0.699999988079071	CHEMBL269881,FP,INACT,0.9900000095367432	CHEMBL557456,TN,INACT,0.019999999552965164	CHEMBL498249,FP,INACT,0.9599999785423279	CHEMBL2349218,TP,ACT,1.0	CHEMBL102136,TN,INACT,0.009999999776482582	CHEMBL2205634,TP,ACT,1.0	CHEMBL101868,TN,INACT,0.019999999552965164	CHEMBL3683265,TP,ACT,1.0	CHEMBL318188,TN,INACT,0.019999999552965164	CHEMBL3402500,TP,ACT,1.0	CHEMBL456113,TN,INACT,0.8500000238418579	CHEMBL318485,TN,INACT,0.07999999821186066	CHEMBL48614,TN,INACT,0.019999999552965164	CHEMBL1784660,TN,INACT,0.009999999776482582	CHEMBL456964,TN,INACT,0.0	CHEMBL3644042,TP,ACT,1.0	CHEMBL517154,TN,INACT,0.5799999833106995	CHEMBL488646,TN,INACT,0.10999999940395355	CHEMBL3644056,TP,ACT,1.0	CHEMBL498705,FP,INACT,0.9800000190734863	CHEMBL562198,TN,INACT,0.009999999776482582	CHEMBL1688850,TP,ACT,1.0	CHEMBL3683269,TP,ACT,1.0	CHEMBL3402502,TP,ACT,0.9900000095367432	

