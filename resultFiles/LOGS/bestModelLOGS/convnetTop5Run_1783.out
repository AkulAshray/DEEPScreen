CNNModel CHEMBL1255126 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	141
Number of inactive compounds :	141
---------------------------------
Run id: CNNModel_CHEMBL1255126_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1255126_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 176
Validation samples: 55
--
Training Step: 1  | time: 0.829s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/176
[A[ATraining Step: 2  | total loss: [1m[32m0.62364[0m[0m | time: 1.453s
[2K
| Adam | epoch: 001 | loss: 0.62364 - acc: 0.5062 -- iter: 064/176
[A[ATraining Step: 3  | total loss: [1m[32m0.68246[0m[0m | time: 2.075s
[2K
| Adam | epoch: 001 | loss: 0.68246 - acc: 0.4500 -- iter: 096/176
[A[ATraining Step: 4  | total loss: [1m[32m0.68979[0m[0m | time: 2.714s
[2K
| Adam | epoch: 001 | loss: 0.68979 - acc: 0.5109 -- iter: 128/176
[A[ATraining Step: 5  | total loss: [1m[32m0.69276[0m[0m | time: 3.335s
[2K
| Adam | epoch: 001 | loss: 0.69276 - acc: 0.4601 -- iter: 160/176
[A[ATraining Step: 6  | total loss: [1m[32m0.69319[0m[0m | time: 4.682s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5058 | val_loss: 0.69340 - val_acc: 0.4727 -- iter: 176/176
--
Training Step: 7  | total loss: [1m[32m0.69270[0m[0m | time: 0.332s
[2K
| Adam | epoch: 002 | loss: 0.69270 - acc: 0.5773 -- iter: 032/176
[A[ATraining Step: 8  | total loss: [1m[32m0.69166[0m[0m | time: 0.978s
[2K
| Adam | epoch: 002 | loss: 0.69166 - acc: 0.6041 -- iter: 064/176
[A[ATraining Step: 9  | total loss: [1m[32m0.69430[0m[0m | time: 1.604s
[2K
| Adam | epoch: 002 | loss: 0.69430 - acc: 0.4994 -- iter: 096/176
[A[ATraining Step: 10  | total loss: [1m[32m0.69390[0m[0m | time: 2.239s
[2K
| Adam | epoch: 002 | loss: 0.69390 - acc: 0.4684 -- iter: 128/176
[A[ATraining Step: 11  | total loss: [1m[32m0.69301[0m[0m | time: 2.882s
[2K
| Adam | epoch: 002 | loss: 0.69301 - acc: 0.5130 -- iter: 160/176
[A[ATraining Step: 12  | total loss: [1m[32m0.69224[0m[0m | time: 4.509s
[2K
| Adam | epoch: 002 | loss: 0.69224 - acc: 0.5353 | val_loss: 0.69409 - val_acc: 0.4727 -- iter: 176/176
--
Training Step: 13  | total loss: [1m[32m0.69298[0m[0m | time: 0.326s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5068 -- iter: 032/176
[A[ATraining Step: 14  | total loss: [1m[32m0.69473[0m[0m | time: 0.649s
[2K
| Adam | epoch: 003 | loss: 0.69473 - acc: 0.4529 -- iter: 064/176
[A[ATraining Step: 15  | total loss: [1m[32m0.69538[0m[0m | time: 1.271s
[2K
| Adam | epoch: 003 | loss: 0.69538 - acc: 0.4224 -- iter: 096/176
[A[ATraining Step: 16  | total loss: [1m[32m0.69419[0m[0m | time: 1.916s
[2K
| Adam | epoch: 003 | loss: 0.69419 - acc: 0.4867 -- iter: 128/176
[A[ATraining Step: 17  | total loss: [1m[32m0.69348[0m[0m | time: 2.535s
[2K
| Adam | epoch: 003 | loss: 0.69348 - acc: 0.5140 -- iter: 160/176
[A[ATraining Step: 18  | total loss: [1m[32m0.69378[0m[0m | time: 4.144s
[2K
| Adam | epoch: 003 | loss: 0.69378 - acc: 0.4983 | val_loss: 0.69244 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 19  | total loss: [1m[32m0.69332[0m[0m | time: 0.620s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.5093 -- iter: 032/176
[A[ATraining Step: 20  | total loss: [1m[32m0.69393[0m[0m | time: 0.963s
[2K
| Adam | epoch: 004 | loss: 0.69393 - acc: 0.4963 -- iter: 064/176
[A[ATraining Step: 21  | total loss: [1m[32m0.69352[0m[0m | time: 1.300s
[2K
| Adam | epoch: 004 | loss: 0.69352 - acc: 0.4974 -- iter: 096/176
[A[ATraining Step: 22  | total loss: [1m[32m0.69333[0m[0m | time: 1.932s
[2K
| Adam | epoch: 004 | loss: 0.69333 - acc: 0.4982 -- iter: 128/176
[A[ATraining Step: 23  | total loss: [1m[32m0.69397[0m[0m | time: 2.548s
[2K
| Adam | epoch: 004 | loss: 0.69397 - acc: 0.4806 -- iter: 160/176
[A[ATraining Step: 24  | total loss: [1m[32m0.69273[0m[0m | time: 4.182s
[2K
| Adam | epoch: 004 | loss: 0.69273 - acc: 0.5212 | val_loss: 0.69229 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 25  | total loss: [1m[32m0.69259[0m[0m | time: 0.618s
[2K
| Adam | epoch: 005 | loss: 0.69259 - acc: 0.5325 -- iter: 032/176
[A[ATraining Step: 26  | total loss: [1m[32m0.69390[0m[0m | time: 1.239s
[2K
| Adam | epoch: 005 | loss: 0.69390 - acc: 0.4991 -- iter: 064/176
[A[ATraining Step: 27  | total loss: [1m[32m0.69311[0m[0m | time: 1.569s
[2K
| Adam | epoch: 005 | loss: 0.69311 - acc: 0.5154 -- iter: 096/176
[A[ATraining Step: 28  | total loss: [1m[32m0.69315[0m[0m | time: 1.896s
[2K
| Adam | epoch: 005 | loss: 0.69315 - acc: 0.5115 -- iter: 128/176
[A[ATraining Step: 29  | total loss: [1m[32m0.69321[0m[0m | time: 2.515s
[2K
| Adam | epoch: 005 | loss: 0.69321 - acc: 0.5087 -- iter: 160/176
[A[ATraining Step: 30  | total loss: [1m[32m0.69457[0m[0m | time: 4.143s
[2K
| Adam | epoch: 005 | loss: 0.69457 - acc: 0.4696 | val_loss: 0.69252 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 31  | total loss: [1m[32m0.69428[0m[0m | time: 0.615s
[2K
| Adam | epoch: 006 | loss: 0.69428 - acc: 0.4767 -- iter: 032/176
[A[ATraining Step: 32  | total loss: [1m[32m0.69367[0m[0m | time: 1.242s
[2K
| Adam | epoch: 006 | loss: 0.69367 - acc: 0.4960 -- iter: 064/176
[A[ATraining Step: 33  | total loss: [1m[32m0.69376[0m[0m | time: 1.855s
[2K
| Adam | epoch: 006 | loss: 0.69376 - acc: 0.4900 -- iter: 096/176
[A[ATraining Step: 34  | total loss: [1m[32m0.69334[0m[0m | time: 2.176s
[2K
| Adam | epoch: 006 | loss: 0.69334 - acc: 0.5122 -- iter: 128/176
[A[ATraining Step: 35  | total loss: [1m[32m0.69354[0m[0m | time: 2.498s
[2K
| Adam | epoch: 006 | loss: 0.69354 - acc: 0.4966 -- iter: 160/176
[A[ATraining Step: 36  | total loss: [1m[32m0.69368[0m[0m | time: 4.115s
[2K
| Adam | epoch: 006 | loss: 0.69368 - acc: 0.4845 | val_loss: 0.69284 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 37  | total loss: [1m[32m0.69383[0m[0m | time: 0.640s
[2K
| Adam | epoch: 007 | loss: 0.69383 - acc: 0.4689 -- iter: 032/176
[A[ATraining Step: 38  | total loss: [1m[32m0.69380[0m[0m | time: 1.248s
[2K
| Adam | epoch: 007 | loss: 0.69380 - acc: 0.4627 -- iter: 064/176
[A[ATraining Step: 39  | total loss: [1m[32m0.69351[0m[0m | time: 1.893s
[2K
| Adam | epoch: 007 | loss: 0.69351 - acc: 0.4938 -- iter: 096/176
[A[ATraining Step: 40  | total loss: [1m[32m0.69351[0m[0m | time: 2.513s
[2K
| Adam | epoch: 007 | loss: 0.69351 - acc: 0.4832 -- iter: 128/176
[A[ATraining Step: 41  | total loss: [1m[32m0.69338[0m[0m | time: 2.828s
[2K
| Adam | epoch: 007 | loss: 0.69338 - acc: 0.4978 -- iter: 160/176
[A[ATraining Step: 42  | total loss: [1m[32m0.69332[0m[0m | time: 4.166s
[2K
| Adam | epoch: 007 | loss: 0.69332 - acc: 0.4982 | val_loss: 0.69305 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 43  | total loss: [1m[32m0.69325[0m[0m | time: 0.621s
[2K
| Adam | epoch: 008 | loss: 0.69325 - acc: 0.4985 -- iter: 032/176
[A[ATraining Step: 44  | total loss: [1m[32m0.69325[0m[0m | time: 1.249s
[2K
| Adam | epoch: 008 | loss: 0.69325 - acc: 0.4880 -- iter: 064/176
[A[ATraining Step: 45  | total loss: [1m[32m0.69322[0m[0m | time: 1.899s
[2K
| Adam | epoch: 008 | loss: 0.69322 - acc: 0.5059 -- iter: 096/176
[A[ATraining Step: 46  | total loss: [1m[32m0.69325[0m[0m | time: 2.521s
[2K
| Adam | epoch: 008 | loss: 0.69325 - acc: 0.4893 -- iter: 128/176
[A[ATraining Step: 47  | total loss: [1m[32m0.69321[0m[0m | time: 3.168s
[2K
| Adam | epoch: 008 | loss: 0.69321 - acc: 0.4962 -- iter: 160/176
[A[ATraining Step: 48  | total loss: [1m[32m0.69318[0m[0m | time: 4.491s
[2K
| Adam | epoch: 008 | loss: 0.69318 - acc: 0.5119 | val_loss: 0.69312 - val_acc: 0.4727 -- iter: 176/176
--
Training Step: 49  | total loss: [1m[32m0.69325[0m[0m | time: 0.336s
[2K
| Adam | epoch: 009 | loss: 0.69325 - acc: 0.4804 -- iter: 032/176
[A[ATraining Step: 50  | total loss: [1m[32m0.69325[0m[0m | time: 0.959s
[2K
| Adam | epoch: 009 | loss: 0.69325 - acc: 0.4931 -- iter: 064/176
[A[ATraining Step: 51  | total loss: [1m[32m0.69324[0m[0m | time: 1.576s
[2K
| Adam | epoch: 009 | loss: 0.69324 - acc: 0.4894 -- iter: 096/176
[A[ATraining Step: 52  | total loss: [1m[32m0.69313[0m[0m | time: 2.217s
[2K
| Adam | epoch: 009 | loss: 0.69313 - acc: 0.5051 -- iter: 128/176
[A[ATraining Step: 53  | total loss: [1m[32m0.69316[0m[0m | time: 2.837s
[2K
| Adam | epoch: 009 | loss: 0.69316 - acc: 0.4997 -- iter: 160/176
[A[ATraining Step: 54  | total loss: [1m[32m0.69314[0m[0m | time: 4.445s
[2K
| Adam | epoch: 009 | loss: 0.69314 - acc: 0.4997 | val_loss: 0.69282 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 55  | total loss: [1m[32m0.69326[0m[0m | time: 0.325s
[2K
| Adam | epoch: 010 | loss: 0.69326 - acc: 0.4864 -- iter: 032/176
[A[ATraining Step: 56  | total loss: [1m[32m0.69352[0m[0m | time: 0.649s
[2K
| Adam | epoch: 010 | loss: 0.69352 - acc: 0.4619 -- iter: 064/176
[A[ATraining Step: 57  | total loss: [1m[32m0.69368[0m[0m | time: 1.291s
[2K
| Adam | epoch: 010 | loss: 0.69368 - acc: 0.4412 -- iter: 096/176
[A[ATraining Step: 58  | total loss: [1m[32m0.69349[0m[0m | time: 1.904s
[2K
| Adam | epoch: 010 | loss: 0.69349 - acc: 0.4663 -- iter: 128/176
[A[ATraining Step: 59  | total loss: [1m[32m0.69346[0m[0m | time: 2.507s
[2K
| Adam | epoch: 010 | loss: 0.69346 - acc: 0.4624 -- iter: 160/176
[A[ATraining Step: 60  | total loss: [1m[32m0.69341[0m[0m | time: 4.142s
[2K
| Adam | epoch: 010 | loss: 0.69341 - acc: 0.4757 | val_loss: 0.69306 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 61  | total loss: [1m[32m0.69338[0m[0m | time: 0.614s
[2K
| Adam | epoch: 011 | loss: 0.69338 - acc: 0.4788 -- iter: 032/176
[A[ATraining Step: 62  | total loss: [1m[32m0.69333[0m[0m | time: 0.934s
[2K
| Adam | epoch: 011 | loss: 0.69333 - acc: 0.4936 -- iter: 064/176
[A[ATraining Step: 63  | total loss: [1m[32m0.69330[0m[0m | time: 1.253s
[2K
| Adam | epoch: 011 | loss: 0.69330 - acc: 0.4786 -- iter: 096/176
[A[ATraining Step: 64  | total loss: [1m[32m0.69326[0m[0m | time: 1.867s
[2K
| Adam | epoch: 011 | loss: 0.69326 - acc: 0.4891 -- iter: 128/176
[A[ATraining Step: 65  | total loss: [1m[32m0.69325[0m[0m | time: 2.478s
[2K
| Adam | epoch: 011 | loss: 0.69325 - acc: 0.4827 -- iter: 160/176
[A[ATraining Step: 66  | total loss: [1m[32m0.69324[0m[0m | time: 4.093s
[2K
| Adam | epoch: 011 | loss: 0.69324 - acc: 0.4848 | val_loss: 0.69301 - val_acc: 0.7273 -- iter: 176/176
--
Training Step: 67  | total loss: [1m[32m0.69321[0m[0m | time: 0.628s
[2K
| Adam | epoch: 012 | loss: 0.69321 - acc: 0.4941 -- iter: 032/176
[A[ATraining Step: 68  | total loss: [1m[32m0.69317[0m[0m | time: 1.240s
[2K
| Adam | epoch: 012 | loss: 0.69317 - acc: 0.5244 -- iter: 064/176
[A[ATraining Step: 69  | total loss: [1m[32m0.69315[0m[0m | time: 1.557s
[2K
| Adam | epoch: 012 | loss: 0.69315 - acc: 0.5362 -- iter: 096/176
[A[ATraining Step: 70  | total loss: [1m[32m0.69312[0m[0m | time: 1.879s
[2K
| Adam | epoch: 012 | loss: 0.69312 - acc: 0.5464 -- iter: 128/176
[A[ATraining Step: 71  | total loss: [1m[32m0.69313[0m[0m | time: 2.500s
[2K
| Adam | epoch: 012 | loss: 0.69313 - acc: 0.5411 -- iter: 160/176
[A[ATraining Step: 72  | total loss: [1m[32m0.69310[0m[0m | time: 4.152s
[2K
| Adam | epoch: 012 | loss: 0.69310 - acc: 0.5506 | val_loss: 0.69274 - val_acc: 0.7455 -- iter: 176/176
--
Training Step: 73  | total loss: [1m[32m0.69306[0m[0m | time: 0.629s
[2K
| Adam | epoch: 013 | loss: 0.69306 - acc: 0.5589 -- iter: 032/176
[A[ATraining Step: 74  | total loss: [1m[32m0.69301[0m[0m | time: 1.230s
[2K
| Adam | epoch: 013 | loss: 0.69301 - acc: 0.5833 -- iter: 064/176
[A[ATraining Step: 75  | total loss: [1m[32m0.69297[0m[0m | time: 1.874s
[2K
| Adam | epoch: 013 | loss: 0.69297 - acc: 0.5912 -- iter: 096/176
[A[ATraining Step: 76  | total loss: [1m[32m0.69290[0m[0m | time: 2.205s
[2K
| Adam | epoch: 013 | loss: 0.69290 - acc: 0.6082 -- iter: 128/176
[A[ATraining Step: 77  | total loss: [1m[32m0.69284[0m[0m | time: 2.527s
[2K
| Adam | epoch: 013 | loss: 0.69284 - acc: 0.6232 -- iter: 160/176
[A[ATraining Step: 78  | total loss: [1m[32m0.69258[0m[0m | time: 4.175s
[2K
| Adam | epoch: 013 | loss: 0.69258 - acc: 0.6365 | val_loss: 0.69198 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 79  | total loss: [1m[32m0.69280[0m[0m | time: 0.635s
[2K
| Adam | epoch: 014 | loss: 0.69280 - acc: 0.6127 -- iter: 032/176
[A[ATraining Step: 80  | total loss: [1m[32m0.69280[0m[0m | time: 1.261s
[2K
| Adam | epoch: 014 | loss: 0.69280 - acc: 0.6011 -- iter: 064/176
[A[ATraining Step: 81  | total loss: [1m[32m0.69325[0m[0m | time: 1.920s
[2K
| Adam | epoch: 014 | loss: 0.69325 - acc: 0.5783 -- iter: 096/176
[A[ATraining Step: 82  | total loss: [1m[32m0.69296[0m[0m | time: 2.574s
[2K
| Adam | epoch: 014 | loss: 0.69296 - acc: 0.5767 -- iter: 128/176
[A[ATraining Step: 83  | total loss: [1m[32m0.69244[0m[0m | time: 2.906s
[2K
| Adam | epoch: 014 | loss: 0.69244 - acc: 0.5815 -- iter: 160/176
[A[ATraining Step: 84  | total loss: [1m[32m0.69304[0m[0m | time: 4.245s
[2K
| Adam | epoch: 014 | loss: 0.69304 - acc: 0.5609 | val_loss: 0.69130 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 85  | total loss: [1m[32m0.69363[0m[0m | time: 0.641s
[2K
| Adam | epoch: 015 | loss: 0.69363 - acc: 0.5423 -- iter: 032/176
[A[ATraining Step: 86  | total loss: [1m[32m0.69343[0m[0m | time: 1.284s
[2K
| Adam | epoch: 015 | loss: 0.69343 - acc: 0.5381 -- iter: 064/176
[A[ATraining Step: 87  | total loss: [1m[32m0.69333[0m[0m | time: 1.900s
[2K
| Adam | epoch: 015 | loss: 0.69333 - acc: 0.5343 -- iter: 096/176
[A[ATraining Step: 88  | total loss: [1m[32m0.69298[0m[0m | time: 2.532s
[2K
| Adam | epoch: 015 | loss: 0.69298 - acc: 0.5371 -- iter: 128/176
[A[ATraining Step: 89  | total loss: [1m[32m0.69278[0m[0m | time: 3.144s
[2K
| Adam | epoch: 015 | loss: 0.69278 - acc: 0.5365 -- iter: 160/176
[A[ATraining Step: 90  | total loss: [1m[32m0.69254[0m[0m | time: 4.471s
[2K
| Adam | epoch: 015 | loss: 0.69254 - acc: 0.5360 | val_loss: 0.69018 - val_acc: 0.5273 -- iter: 176/176
--
Training Step: 91  | total loss: [1m[32m0.69238[0m[0m | time: 0.326s
[2K
| Adam | epoch: 016 | loss: 0.69238 - acc: 0.5324 -- iter: 032/176
[A[ATraining Step: 92  | total loss: [1m[32m0.69211[0m[0m | time: 0.937s
[2K
| Adam | epoch: 016 | loss: 0.69211 - acc: 0.5291 -- iter: 064/176
[A[ATraining Step: 93  | total loss: [1m[32m0.69212[0m[0m | time: 1.548s
[2K
| Adam | epoch: 016 | loss: 0.69212 - acc: 0.5137 -- iter: 096/176
[A[ATraining Step: 94  | total loss: [1m[32m0.69203[0m[0m | time: 2.164s
[2K
| Adam | epoch: 016 | loss: 0.69203 - acc: 0.5342 -- iter: 128/176
[A[ATraining Step: 95  | total loss: [1m[32m0.69168[0m[0m | time: 2.780s
[2K
| Adam | epoch: 016 | loss: 0.69168 - acc: 0.5652 -- iter: 160/176
[A[ATraining Step: 96  | total loss: [1m[32m0.69129[0m[0m | time: 4.387s
[2K
| Adam | epoch: 016 | loss: 0.69129 - acc: 0.5743 | val_loss: 0.68389 - val_acc: 0.6364 -- iter: 176/176
--
Training Step: 97  | total loss: [1m[32m0.69037[0m[0m | time: 0.316s
[2K
| Adam | epoch: 017 | loss: 0.69037 - acc: 0.5981 -- iter: 032/176
[A[ATraining Step: 98  | total loss: [1m[32m0.68962[0m[0m | time: 0.656s
[2K
| Adam | epoch: 017 | loss: 0.68962 - acc: 0.5883 -- iter: 064/176
[A[ATraining Step: 99  | total loss: [1m[32m0.68858[0m[0m | time: 1.283s
[2K
| Adam | epoch: 017 | loss: 0.68858 - acc: 0.5857 -- iter: 096/176
[A[ATraining Step: 100  | total loss: [1m[32m0.68701[0m[0m | time: 1.897s
[2K
| Adam | epoch: 017 | loss: 0.68701 - acc: 0.5959 -- iter: 128/176
[A[ATraining Step: 101  | total loss: [1m[32m0.68547[0m[0m | time: 2.520s
[2K
| Adam | epoch: 017 | loss: 0.68547 - acc: 0.6019 -- iter: 160/176
[A[ATraining Step: 102  | total loss: [1m[32m0.68266[0m[0m | time: 4.137s
[2K
| Adam | epoch: 017 | loss: 0.68266 - acc: 0.6199 | val_loss: 0.65036 - val_acc: 0.8000 -- iter: 176/176
--
Training Step: 103  | total loss: [1m[32m0.67984[0m[0m | time: 0.606s
[2K
| Adam | epoch: 018 | loss: 0.67984 - acc: 0.6360 -- iter: 032/176
[A[ATraining Step: 104  | total loss: [1m[32m0.67674[0m[0m | time: 0.923s
[2K
| Adam | epoch: 018 | loss: 0.67674 - acc: 0.6537 -- iter: 064/176
[A[ATraining Step: 105  | total loss: [1m[32m0.67334[0m[0m | time: 1.237s
[2K
| Adam | epoch: 018 | loss: 0.67334 - acc: 0.6570 -- iter: 096/176
[A[ATraining Step: 106  | total loss: [1m[32m0.66746[0m[0m | time: 1.843s
[2K
| Adam | epoch: 018 | loss: 0.66746 - acc: 0.6538 -- iter: 128/176
[A[ATraining Step: 107  | total loss: [1m[32m0.66818[0m[0m | time: 2.450s
[2K
| Adam | epoch: 018 | loss: 0.66818 - acc: 0.6384 -- iter: 160/176
[A[ATraining Step: 108  | total loss: [1m[32m0.65722[0m[0m | time: 4.068s
[2K
| Adam | epoch: 018 | loss: 0.65722 - acc: 0.6652 | val_loss: 0.58443 - val_acc: 0.8182 -- iter: 176/176
--
Training Step: 109  | total loss: [1m[32m0.65676[0m[0m | time: 0.653s
[2K
| Adam | epoch: 019 | loss: 0.65676 - acc: 0.6456 -- iter: 032/176
[A[ATraining Step: 110  | total loss: [1m[32m0.65136[0m[0m | time: 1.275s
[2K
| Adam | epoch: 019 | loss: 0.65136 - acc: 0.6654 -- iter: 064/176
[A[ATraining Step: 111  | total loss: [1m[32m0.64080[0m[0m | time: 1.593s
[2K
| Adam | epoch: 019 | loss: 0.64080 - acc: 0.6739 -- iter: 096/176
[A[ATraining Step: 112  | total loss: [1m[32m0.64718[0m[0m | time: 1.929s
[2K
| Adam | epoch: 019 | loss: 0.64718 - acc: 0.6627 -- iter: 128/176
[A[ATraining Step: 113  | total loss: [1m[32m0.64407[0m[0m | time: 2.542s
[2K
| Adam | epoch: 019 | loss: 0.64407 - acc: 0.6589 -- iter: 160/176
[A[ATraining Step: 114  | total loss: [1m[32m0.62362[0m[0m | time: 4.155s
[2K
| Adam | epoch: 019 | loss: 0.62362 - acc: 0.6837 | val_loss: 0.73560 - val_acc: 0.4727 -- iter: 176/176
--
Training Step: 115  | total loss: [1m[32m0.62687[0m[0m | time: 0.613s
[2K
| Adam | epoch: 020 | loss: 0.62687 - acc: 0.6716 -- iter: 032/176
[A[ATraining Step: 116  | total loss: [1m[32m0.61702[0m[0m | time: 1.214s
[2K
| Adam | epoch: 020 | loss: 0.61702 - acc: 0.6763 -- iter: 064/176
[A[ATraining Step: 117  | total loss: [1m[32m0.61435[0m[0m | time: 1.843s
[2K
| Adam | epoch: 020 | loss: 0.61435 - acc: 0.6712 -- iter: 096/176
[A[ATraining Step: 118  | total loss: [1m[32m0.60271[0m[0m | time: 2.173s
[2K
| Adam | epoch: 020 | loss: 0.60271 - acc: 0.6884 -- iter: 128/176
[A[ATraining Step: 119  | total loss: [1m[32m0.58423[0m[0m | time: 2.492s
[2K
| Adam | epoch: 020 | loss: 0.58423 - acc: 0.7008 -- iter: 160/176
[A[ATraining Step: 120  | total loss: [1m[32m0.56877[0m[0m | time: 4.088s
[2K
| Adam | epoch: 020 | loss: 0.56877 - acc: 0.7120 | val_loss: 0.52358 - val_acc: 0.7273 -- iter: 176/176
--
Training Step: 121  | total loss: [1m[32m0.56871[0m[0m | time: 0.624s
[2K
| Adam | epoch: 021 | loss: 0.56871 - acc: 0.7064 -- iter: 032/176
[A[ATraining Step: 122  | total loss: [1m[32m0.57385[0m[0m | time: 1.235s
[2K
| Adam | epoch: 021 | loss: 0.57385 - acc: 0.6983 -- iter: 064/176
[A[ATraining Step: 123  | total loss: [1m[32m0.55974[0m[0m | time: 1.844s
[2K
| Adam | epoch: 021 | loss: 0.55974 - acc: 0.7191 -- iter: 096/176
[A[ATraining Step: 124  | total loss: [1m[32m0.54314[0m[0m | time: 2.461s
[2K
| Adam | epoch: 021 | loss: 0.54314 - acc: 0.7315 -- iter: 128/176
[A[ATraining Step: 125  | total loss: [1m[32m0.54285[0m[0m | time: 2.778s
[2K
| Adam | epoch: 021 | loss: 0.54285 - acc: 0.7240 -- iter: 160/176
[A[ATraining Step: 126  | total loss: [1m[32m0.53988[0m[0m | time: 4.111s
[2K
| Adam | epoch: 021 | loss: 0.53988 - acc: 0.7266 | val_loss: 0.46605 - val_acc: 0.8364 -- iter: 176/176
--
Training Step: 127  | total loss: [1m[32m0.52779[0m[0m | time: 0.619s
[2K
| Adam | epoch: 022 | loss: 0.52779 - acc: 0.7414 -- iter: 032/176
[A[ATraining Step: 128  | total loss: [1m[32m0.51750[0m[0m | time: 1.241s
[2K
| Adam | epoch: 022 | loss: 0.51750 - acc: 0.7486 -- iter: 064/176
[A[ATraining Step: 129  | total loss: [1m[32m0.50483[0m[0m | time: 1.859s
[2K
| Adam | epoch: 022 | loss: 0.50483 - acc: 0.7487 -- iter: 096/176
[A[ATraining Step: 130  | total loss: [1m[32m0.49875[0m[0m | time: 2.526s
[2K
| Adam | epoch: 022 | loss: 0.49875 - acc: 0.7520 -- iter: 128/176
[A[ATraining Step: 131  | total loss: [1m[32m0.49249[0m[0m | time: 3.141s
[2K
| Adam | epoch: 022 | loss: 0.49249 - acc: 0.7580 -- iter: 160/176
[A[ATraining Step: 132  | total loss: [1m[32m0.49201[0m[0m | time: 4.460s
[2K
| Adam | epoch: 022 | loss: 0.49201 - acc: 0.7666 | val_loss: 0.62797 - val_acc: 0.6182 -- iter: 176/176
--
Training Step: 133  | total loss: [1m[32m0.48624[0m[0m | time: 0.372s
[2K
| Adam | epoch: 023 | loss: 0.48624 - acc: 0.7774 -- iter: 032/176
[A[ATraining Step: 134  | total loss: [1m[32m0.47822[0m[0m | time: 0.990s
[2K
| Adam | epoch: 023 | loss: 0.47822 - acc: 0.7872 -- iter: 064/176
[A[ATraining Step: 135  | total loss: [1m[32m0.47909[0m[0m | time: 1.608s
[2K
| Adam | epoch: 023 | loss: 0.47909 - acc: 0.7866 -- iter: 096/176
[A[ATraining Step: 136  | total loss: [1m[32m0.45382[0m[0m | time: 2.224s
[2K
| Adam | epoch: 023 | loss: 0.45382 - acc: 0.8048 -- iter: 128/176
[A[ATraining Step: 137  | total loss: [1m[32m0.43868[0m[0m | time: 2.824s
[2K
| Adam | epoch: 023 | loss: 0.43868 - acc: 0.8149 -- iter: 160/176
[A[ATraining Step: 138  | total loss: [1m[32m0.44039[0m[0m | time: 4.443s
[2K
| Adam | epoch: 023 | loss: 0.44039 - acc: 0.8085 | val_loss: 0.47595 - val_acc: 0.8182 -- iter: 176/176
--
Training Step: 139  | total loss: [1m[32m0.44550[0m[0m | time: 0.322s
[2K
| Adam | epoch: 024 | loss: 0.44550 - acc: 0.7995 -- iter: 032/176
[A[ATraining Step: 140  | total loss: [1m[32m0.42271[0m[0m | time: 0.651s
[2K
| Adam | epoch: 024 | loss: 0.42271 - acc: 0.8133 -- iter: 064/176
[A[ATraining Step: 141  | total loss: [1m[32m0.40319[0m[0m | time: 1.262s
[2K
| Adam | epoch: 024 | loss: 0.40319 - acc: 0.8195 -- iter: 096/176
[A[ATraining Step: 142  | total loss: [1m[32m0.38708[0m[0m | time: 1.897s
[2K
| Adam | epoch: 024 | loss: 0.38708 - acc: 0.8281 -- iter: 128/176
[A[ATraining Step: 143  | total loss: [1m[32m0.38185[0m[0m | time: 2.503s
[2K
| Adam | epoch: 024 | loss: 0.38185 - acc: 0.8328 -- iter: 160/176
[A[ATraining Step: 144  | total loss: [1m[32m0.36872[0m[0m | time: 4.126s
[2K
| Adam | epoch: 024 | loss: 0.36872 - acc: 0.8402 | val_loss: 0.49668 - val_acc: 0.7636 -- iter: 176/176
--
Training Step: 145  | total loss: [1m[32m0.36660[0m[0m | time: 0.663s
[2K
| Adam | epoch: 025 | loss: 0.36660 - acc: 0.8436 -- iter: 032/176
[A[ATraining Step: 146  | total loss: [1m[32m0.35358[0m[0m | time: 0.978s
[2K
| Adam | epoch: 025 | loss: 0.35358 - acc: 0.8499 -- iter: 064/176
[A[ATraining Step: 147  | total loss: [1m[32m0.34348[0m[0m | time: 1.296s
[2K
| Adam | epoch: 025 | loss: 0.34348 - acc: 0.8524 -- iter: 096/176
[A[ATraining Step: 148  | total loss: [1m[32m0.33081[0m[0m | time: 1.914s
[2K
| Adam | epoch: 025 | loss: 0.33081 - acc: 0.8547 -- iter: 128/176
[A[ATraining Step: 149  | total loss: [1m[32m0.31390[0m[0m | time: 2.520s
[2K
| Adam | epoch: 025 | loss: 0.31390 - acc: 0.8661 -- iter: 160/176
[A[ATraining Step: 150  | total loss: [1m[32m0.29876[0m[0m | time: 4.137s
[2K
| Adam | epoch: 025 | loss: 0.29876 - acc: 0.8764 | val_loss: 0.50361 - val_acc: 0.8182 -- iter: 176/176
--
Training Step: 151  | total loss: [1m[32m0.28326[0m[0m | time: 0.625s
[2K
| Adam | epoch: 026 | loss: 0.28326 - acc: 0.8856 -- iter: 032/176
[A[ATraining Step: 152  | total loss: [1m[32m0.27747[0m[0m | time: 1.226s
[2K
| Adam | epoch: 026 | loss: 0.27747 - acc: 0.8877 -- iter: 064/176
[A[ATraining Step: 153  | total loss: [1m[32m0.27173[0m[0m | time: 1.554s
[2K
| Adam | epoch: 026 | loss: 0.27173 - acc: 0.8895 -- iter: 096/176
[A[ATraining Step: 154  | total loss: [1m[32m0.25683[0m[0m | time: 1.873s
[2K
| Adam | epoch: 026 | loss: 0.25683 - acc: 0.9006 -- iter: 128/176
[A[ATraining Step: 155  | total loss: [1m[32m0.24032[0m[0m | time: 2.487s
[2K
| Adam | epoch: 026 | loss: 0.24032 - acc: 0.9105 -- iter: 160/176
[A[ATraining Step: 156  | total loss: [1m[32m0.25822[0m[0m | time: 4.107s
[2K
| Adam | epoch: 026 | loss: 0.25822 - acc: 0.9038 | val_loss: 0.72403 - val_acc: 0.7273 -- iter: 176/176
--
Training Step: 157  | total loss: [1m[32m0.26272[0m[0m | time: 0.608s
[2K
| Adam | epoch: 027 | loss: 0.26272 - acc: 0.9072 -- iter: 032/176
[A[ATraining Step: 158  | total loss: [1m[32m0.27283[0m[0m | time: 1.227s
[2K
| Adam | epoch: 027 | loss: 0.27283 - acc: 0.8977 -- iter: 064/176
[A[ATraining Step: 159  | total loss: [1m[32m0.26922[0m[0m | time: 1.848s
[2K
| Adam | epoch: 027 | loss: 0.26922 - acc: 0.8986 -- iter: 096/176
[A[ATraining Step: 160  | total loss: [1m[32m0.26119[0m[0m | time: 2.170s
[2K
| Adam | epoch: 027 | loss: 0.26119 - acc: 0.9025 -- iter: 128/176
[A[ATraining Step: 161  | total loss: [1m[32m0.28204[0m[0m | time: 2.479s
[2K
| Adam | epoch: 027 | loss: 0.28204 - acc: 0.8935 -- iter: 160/176
[A[ATraining Step: 162  | total loss: [1m[32m0.31259[0m[0m | time: 4.088s
[2K
| Adam | epoch: 027 | loss: 0.31259 - acc: 0.8791 | val_loss: 0.58510 - val_acc: 0.7273 -- iter: 176/176
--
Training Step: 163  | total loss: [1m[32m0.31232[0m[0m | time: 0.605s
[2K
| Adam | epoch: 028 | loss: 0.31232 - acc: 0.8787 -- iter: 032/176
[A[ATraining Step: 164  | total loss: [1m[32m0.30714[0m[0m | time: 1.221s
[2K
| Adam | epoch: 028 | loss: 0.30714 - acc: 0.8783 -- iter: 064/176
[A[ATraining Step: 165  | total loss: [1m[32m0.28547[0m[0m | time: 1.839s
[2K
| Adam | epoch: 028 | loss: 0.28547 - acc: 0.8905 -- iter: 096/176
[A[ATraining Step: 166  | total loss: [1m[32m0.29311[0m[0m | time: 2.454s
[2K
| Adam | epoch: 028 | loss: 0.29311 - acc: 0.8890 -- iter: 128/176
[A[ATraining Step: 167  | total loss: [1m[32m0.28734[0m[0m | time: 2.771s
[2K
| Adam | epoch: 028 | loss: 0.28734 - acc: 0.8907 -- iter: 160/176
[A[ATraining Step: 168  | total loss: [1m[32m0.30516[0m[0m | time: 4.089s
[2K
| Adam | epoch: 028 | loss: 0.30516 - acc: 0.8829 | val_loss: 0.58774 - val_acc: 0.7091 -- iter: 176/176
--
Training Step: 169  | total loss: [1m[32m0.30274[0m[0m | time: 0.607s
[2K
| Adam | epoch: 029 | loss: 0.30274 - acc: 0.8821 -- iter: 032/176
[A[ATraining Step: 170  | total loss: [1m[32m0.28502[0m[0m | time: 1.209s
[2K
| Adam | epoch: 029 | loss: 0.28502 - acc: 0.8907 -- iter: 064/176
[A[ATraining Step: 171  | total loss: [1m[32m0.31675[0m[0m | time: 1.842s
[2K
| Adam | epoch: 029 | loss: 0.31675 - acc: 0.8829 -- iter: 096/176
[A[ATraining Step: 172  | total loss: [1m[32m0.30482[0m[0m | time: 2.459s
[2K
| Adam | epoch: 029 | loss: 0.30482 - acc: 0.8884 -- iter: 128/176
[A[ATraining Step: 173  | total loss: [1m[32m0.29032[0m[0m | time: 3.146s
[2K
| Adam | epoch: 029 | loss: 0.29032 - acc: 0.8964 -- iter: 160/176
[A[ATraining Step: 174  | total loss: [1m[32m0.28242[0m[0m | time: 4.472s
[2K
| Adam | epoch: 029 | loss: 0.28242 - acc: 0.9005 | val_loss: 0.49278 - val_acc: 0.7818 -- iter: 176/176
--
Training Step: 175  | total loss: [1m[32m0.26312[0m[0m | time: 0.330s
[2K
| Adam | epoch: 030 | loss: 0.26312 - acc: 0.9105 -- iter: 032/176
[A[ATraining Step: 176  | total loss: [1m[32m0.24547[0m[0m | time: 0.990s
[2K
| Adam | epoch: 030 | loss: 0.24547 - acc: 0.9194 -- iter: 064/176
[A[ATraining Step: 177  | total loss: [1m[32m0.24122[0m[0m | time: 1.595s
[2K
| Adam | epoch: 030 | loss: 0.24122 - acc: 0.9212 -- iter: 096/176
[A[ATraining Step: 178  | total loss: [1m[32m0.24678[0m[0m | time: 2.198s
[2K
| Adam | epoch: 030 | loss: 0.24678 - acc: 0.9197 -- iter: 128/176
[A[ATraining Step: 179  | total loss: [1m[32m0.24509[0m[0m | time: 2.811s
[2K
| Adam | epoch: 030 | loss: 0.24509 - acc: 0.9215 -- iter: 160/176
[A[ATraining Step: 180  | total loss: [1m[32m0.23453[0m[0m | time: 4.426s
[2K
| Adam | epoch: 030 | loss: 0.23453 - acc: 0.9294 | val_loss: 0.60520 - val_acc: 0.7455 -- iter: 176/176
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8726790450928382
Validation AUPRC:0.8399157434583244
Test AUC:0.8709239130434783
Test AUPRC:0.8018599456099456
BestTestF1Score	0.77	0.59	0.75	0.62	1.0	23	14	18	0	0.05
BestTestMCCScore	0.77	0.59	0.75	0.62	1.0	23	14	18	0	0.05
BestTestAccuracyScore	0.67	0.47	0.75	0.74	0.61	14	5	27	9	0.3
BestValidationF1Score	0.82	0.64	0.8	0.71	0.96	25	10	19	1	0.05
BestValidationMCC	0.82	0.64	0.8	0.71	0.96	25	10	19	1	0.05
BestValidationAccuracy	0.8	0.64	0.82	0.83	0.77	20	4	25	6	0.3
TestPredictions (Threshold:0.05)
CHEMBL3683184,FP,INACT,0.1599999964237213	CHEMBL3691694,FP,INACT,0.23000000417232513	CHEMBL469951,FP,INACT,0.18000000715255737	CHEMBL3653164,TP,ACT,0.15000000596046448	CHEMBL3687275,TP,ACT,0.05999999865889549	CHEMBL3347605,TP,ACT,0.5199999809265137	CHEMBL3650063,TN,INACT,0.009999999776482582	CHEMBL3687264,FP,INACT,0.17000000178813934	CHEMBL3650064,TN,INACT,0.009999999776482582	CHEMBL3691719,TN,INACT,0.029999999329447746	CHEMBL3683172,TP,ACT,0.9800000190734863	CHEMBL3683158,FP,INACT,0.9700000286102295	CHEMBL3687229,FP,INACT,0.3700000047683716	CHEMBL3601322,FP,INACT,0.8799999952316284	CHEMBL3687305,TN,INACT,0.009999999776482582	CHEMBL2024322,FP,INACT,0.7699999809265137	CHEMBL3735566,TP,ACT,0.17000000178813934	CHEMBL1411448,FP,INACT,0.05999999865889549	CHEMBL1618026,TN,INACT,0.009999999776482582	CHEMBL2397155,FP,INACT,0.41999998688697815	CHEMBL3687226,TP,ACT,0.23999999463558197	CHEMBL3683121,TN,INACT,0.029999999329447746	CHEMBL3653161,TP,ACT,0.7699999809265137	CHEMBL1567081,TN,INACT,0.009999999776482582	CHEMBL3650059,TN,INACT,0.0	CHEMBL1689409,TP,ACT,0.949999988079071	CHEMBL3683164,FP,INACT,0.05000000074505806	CHEMBL1626340,TN,INACT,0.009999999776482582	CHEMBL1689393,TP,ACT,0.9800000190734863	CHEMBL3687300,TN,INACT,0.009999999776482582	CHEMBL1490324,TN,INACT,0.009999999776482582	CHEMBL1689400,TP,ACT,0.9700000286102295	CHEMBL1531252,TN,INACT,0.019999999552965164	CHEMBL566458,TN,INACT,0.029999999329447746	CHEMBL3653163,TP,ACT,0.2199999988079071	CHEMBL3691703,TP,ACT,0.41999998688697815	CHEMBL3653174,TP,ACT,0.6499999761581421	CHEMBL3683182,TP,ACT,0.9700000286102295	CHEMBL3653166,TP,ACT,0.9300000071525574	CHEMBL3601398,TP,ACT,0.9800000190734863	CHEMBL3691711,TP,ACT,0.27000001072883606	CHEMBL1689397,TP,ACT,0.7599999904632568	CHEMBL3683171,TP,ACT,0.9700000286102295	CHEMBL3653172,TP,ACT,0.23999999463558197	CHEMBL1533044,TN,INACT,0.009999999776482582	CHEMBL3683148,FP,INACT,0.05999999865889549	CHEMBL3220313,FP,INACT,0.18000000715255737	CHEMBL3687282,TN,INACT,0.009999999776482582	CHEMBL3699996,TN,INACT,0.019999999552965164	CHEMBL3687302,TN,INACT,0.009999999776482582	CHEMBL3687262,TP,ACT,0.07000000029802322	CHEMBL3683119,TN,INACT,0.019999999552965164	CHEMBL3691700,TP,ACT,0.5099999904632568	CHEMBL3691715,TP,ACT,0.05999999865889549	CHEMBL3687240,FP,INACT,0.15000000596046448	

