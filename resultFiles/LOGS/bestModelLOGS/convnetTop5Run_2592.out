ImageNetInceptionV2 CHEMBL1945 adam 0.0005 5 0 0 0.8 False True
Number of active compounds :	867
Number of inactive compounds :	867
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1945_adam_0.0005_5_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1945_adam_0.0005_5_0.8/
---------------------------------
Training samples: 1104
Validation samples: 346
--
Training Step: 1  | time: 36.265s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1104
[A[ATraining Step: 2  | total loss: [1m[32m0.82039[0m[0m | time: 44.322s
[2K
| Adam | epoch: 001 | loss: 0.82039 - acc: 0.2812 -- iter: 0064/1104
[A[ATraining Step: 3  | total loss: [1m[32m0.94010[0m[0m | time: 52.361s
[2K
| Adam | epoch: 001 | loss: 0.94010 - acc: 0.5369 -- iter: 0096/1104
[A[ATraining Step: 4  | total loss: [1m[32m0.70566[0m[0m | time: 60.195s
[2K
| Adam | epoch: 001 | loss: 0.70566 - acc: 0.6264 -- iter: 0128/1104
[A[ATraining Step: 5  | total loss: [1m[32m0.68255[0m[0m | time: 68.015s
[2K
| Adam | epoch: 001 | loss: 0.68255 - acc: 0.6038 -- iter: 0160/1104
[A[ATraining Step: 6  | total loss: [1m[32m0.61613[0m[0m | time: 76.076s
[2K
| Adam | epoch: 001 | loss: 0.61613 - acc: 0.6576 -- iter: 0192/1104
[A[ATraining Step: 7  | total loss: [1m[32m0.61593[0m[0m | time: 83.973s
[2K
| Adam | epoch: 001 | loss: 0.61593 - acc: 0.6380 -- iter: 0224/1104
[A[ATraining Step: 8  | total loss: [1m[32m0.63777[0m[0m | time: 92.047s
[2K
| Adam | epoch: 001 | loss: 0.63777 - acc: 0.6307 -- iter: 0256/1104
[A[ATraining Step: 9  | total loss: [1m[32m0.63249[0m[0m | time: 99.957s
[2K
| Adam | epoch: 001 | loss: 0.63249 - acc: 0.6111 -- iter: 0288/1104
[A[ATraining Step: 10  | total loss: [1m[32m0.59364[0m[0m | time: 107.885s
[2K
| Adam | epoch: 001 | loss: 0.59364 - acc: 0.6493 -- iter: 0320/1104
[A[ATraining Step: 11  | total loss: [1m[32m0.54174[0m[0m | time: 115.928s
[2K
| Adam | epoch: 001 | loss: 0.54174 - acc: 0.7414 -- iter: 0352/1104
[A[ATraining Step: 12  | total loss: [1m[32m0.53542[0m[0m | time: 123.882s
[2K
| Adam | epoch: 001 | loss: 0.53542 - acc: 0.7312 -- iter: 0384/1104
[A[ATraining Step: 13  | total loss: [1m[32m0.59279[0m[0m | time: 131.778s
[2K
| Adam | epoch: 001 | loss: 0.59279 - acc: 0.6991 -- iter: 0416/1104
[A[ATraining Step: 14  | total loss: [1m[32m0.51842[0m[0m | time: 139.722s
[2K
| Adam | epoch: 001 | loss: 0.51842 - acc: 0.7583 -- iter: 0448/1104
[A[ATraining Step: 15  | total loss: [1m[32m0.46587[0m[0m | time: 149.236s
[2K
| Adam | epoch: 001 | loss: 0.46587 - acc: 0.8039 -- iter: 0480/1104
[A[ATraining Step: 16  | total loss: [1m[32m0.46606[0m[0m | time: 160.488s
[2K
| Adam | epoch: 001 | loss: 0.46606 - acc: 0.7837 -- iter: 0512/1104
[A[ATraining Step: 17  | total loss: [1m[32m0.47202[0m[0m | time: 173.448s
[2K
| Adam | epoch: 001 | loss: 0.47202 - acc: 0.8053 -- iter: 0544/1104
[A[ATraining Step: 18  | total loss: [1m[32m0.58887[0m[0m | time: 186.842s
[2K
| Adam | epoch: 001 | loss: 0.58887 - acc: 0.7645 -- iter: 0576/1104
[A[ATraining Step: 19  | total loss: [1m[32m0.52755[0m[0m | time: 199.997s
[2K
| Adam | epoch: 001 | loss: 0.52755 - acc: 0.7909 -- iter: 0608/1104
[A[ATraining Step: 20  | total loss: [1m[32m0.45912[0m[0m | time: 212.865s
[2K
| Adam | epoch: 001 | loss: 0.45912 - acc: 0.8180 -- iter: 0640/1104
[A[ATraining Step: 21  | total loss: [1m[32m0.45943[0m[0m | time: 225.416s
[2K
| Adam | epoch: 001 | loss: 0.45943 - acc: 0.7872 -- iter: 0672/1104
[A[ATraining Step: 22  | total loss: [1m[32m0.54857[0m[0m | time: 238.604s
[2K
| Adam | epoch: 001 | loss: 0.54857 - acc: 0.7573 -- iter: 0704/1104
[A[ATraining Step: 23  | total loss: [1m[32m0.49496[0m[0m | time: 251.020s
[2K
| Adam | epoch: 001 | loss: 0.49496 - acc: 0.7733 -- iter: 0736/1104
[A[ATraining Step: 24  | total loss: [1m[32m0.46311[0m[0m | time: 263.631s
[2K
| Adam | epoch: 001 | loss: 0.46311 - acc: 0.7843 -- iter: 0768/1104
[A[ATraining Step: 25  | total loss: [1m[32m0.46833[0m[0m | time: 276.138s
[2K
| Adam | epoch: 001 | loss: 0.46833 - acc: 0.7920 -- iter: 0800/1104
[A[ATraining Step: 26  | total loss: [1m[32m0.43717[0m[0m | time: 288.964s
[2K
| Adam | epoch: 001 | loss: 0.43717 - acc: 0.8057 -- iter: 0832/1104
[A[ATraining Step: 27  | total loss: [1m[32m0.44697[0m[0m | time: 301.758s
[2K
| Adam | epoch: 001 | loss: 0.44697 - acc: 0.8075 -- iter: 0864/1104
[A[ATraining Step: 28  | total loss: [1m[32m0.41106[0m[0m | time: 314.730s
[2K
| Adam | epoch: 001 | loss: 0.41106 - acc: 0.8322 -- iter: 0896/1104
[A[ATraining Step: 29  | total loss: [1m[32m0.42947[0m[0m | time: 327.219s
[2K
| Adam | epoch: 001 | loss: 0.42947 - acc: 0.7970 -- iter: 0928/1104
[A[ATraining Step: 30  | total loss: [1m[32m0.40689[0m[0m | time: 339.722s
[2K
| Adam | epoch: 001 | loss: 0.40689 - acc: 0.8080 -- iter: 0960/1104
[A[ATraining Step: 31  | total loss: [1m[32m0.38017[0m[0m | time: 352.298s
[2K
| Adam | epoch: 001 | loss: 0.38017 - acc: 0.8235 -- iter: 0992/1104
[A[ATraining Step: 32  | total loss: [1m[32m0.38057[0m[0m | time: 364.840s
[2K
| Adam | epoch: 001 | loss: 0.38057 - acc: 0.8351 -- iter: 1024/1104
[A[ATraining Step: 33  | total loss: [1m[32m0.37459[0m[0m | time: 376.663s
[2K
| Adam | epoch: 001 | loss: 0.37459 - acc: 0.8370 -- iter: 1056/1104
[A[ATraining Step: 34  | total loss: [1m[32m0.43226[0m[0m | time: 384.442s
[2K
| Adam | epoch: 001 | loss: 0.43226 - acc: 0.8317 -- iter: 1088/1104
[A[ATraining Step: 35  | total loss: [1m[32m0.40149[0m[0m | time: 415.038s
[2K
| Adam | epoch: 001 | loss: 0.40149 - acc: 0.8408 | val_loss: 0.88140 - val_acc: 0.4191 -- iter: 1104/1104
--
Training Step: 36  | total loss: [1m[32m0.37819[0m[0m | time: 7.421s
[2K
| Adam | epoch: 002 | loss: 0.37819 - acc: 0.8350 -- iter: 0032/1104
[A[ATraining Step: 37  | total loss: [1m[32m0.32693[0m[0m | time: 19.756s
[2K
| Adam | epoch: 002 | loss: 0.32693 - acc: 0.8680 -- iter: 0064/1104
[A[ATraining Step: 38  | total loss: [1m[32m0.32408[0m[0m | time: 32.078s
[2K
| Adam | epoch: 002 | loss: 0.32408 - acc: 0.8633 -- iter: 0096/1104
[A[ATraining Step: 39  | total loss: [1m[32m0.38980[0m[0m | time: 44.339s
[2K
| Adam | epoch: 002 | loss: 0.38980 - acc: 0.8296 -- iter: 0128/1104
[A[ATraining Step: 40  | total loss: [1m[32m0.43687[0m[0m | time: 56.699s
[2K
| Adam | epoch: 002 | loss: 0.43687 - acc: 0.8381 -- iter: 0160/1104
[A[ATraining Step: 41  | total loss: [1m[32m0.40376[0m[0m | time: 69.316s
[2K
| Adam | epoch: 002 | loss: 0.40376 - acc: 0.8449 -- iter: 0192/1104
[A[ATraining Step: 42  | total loss: [1m[32m0.41376[0m[0m | time: 81.765s
[2K
| Adam | epoch: 002 | loss: 0.41376 - acc: 0.8391 -- iter: 0224/1104
[A[ATraining Step: 43  | total loss: [1m[32m0.37099[0m[0m | time: 94.326s
[2K
| Adam | epoch: 002 | loss: 0.37099 - acc: 0.8564 -- iter: 0256/1104
[A[ATraining Step: 44  | total loss: [1m[32m0.37994[0m[0m | time: 106.786s
[2K
| Adam | epoch: 002 | loss: 0.37994 - acc: 0.8488 -- iter: 0288/1104
[A[ATraining Step: 45  | total loss: [1m[32m0.36548[0m[0m | time: 119.340s
[2K
| Adam | epoch: 002 | loss: 0.36548 - acc: 0.8480 -- iter: 0320/1104
[A[ATraining Step: 46  | total loss: [1m[32m0.35417[0m[0m | time: 131.832s
[2K
| Adam | epoch: 002 | loss: 0.35417 - acc: 0.8577 -- iter: 0352/1104
[A[ATraining Step: 47  | total loss: [1m[32m0.34446[0m[0m | time: 144.145s
[2K
| Adam | epoch: 002 | loss: 0.34446 - acc: 0.8605 -- iter: 0384/1104
[A[ATraining Step: 48  | total loss: [1m[32m0.33134[0m[0m | time: 156.276s
[2K
| Adam | epoch: 002 | loss: 0.33134 - acc: 0.8679 -- iter: 0416/1104
[A[ATraining Step: 49  | total loss: [1m[32m0.34959[0m[0m | time: 168.477s
[2K
| Adam | epoch: 002 | loss: 0.34959 - acc: 0.8641 -- iter: 0448/1104
[A[ATraining Step: 50  | total loss: [1m[32m0.32219[0m[0m | time: 180.586s
[2K
| Adam | epoch: 002 | loss: 0.32219 - acc: 0.8755 -- iter: 0480/1104
[A[ATraining Step: 51  | total loss: [1m[32m0.30186[0m[0m | time: 192.981s
[2K
| Adam | epoch: 002 | loss: 0.30186 - acc: 0.8849 -- iter: 0512/1104
[A[ATraining Step: 52  | total loss: [1m[32m0.27641[0m[0m | time: 205.258s
[2K
| Adam | epoch: 002 | loss: 0.27641 - acc: 0.8975 -- iter: 0544/1104
[A[ATraining Step: 53  | total loss: [1m[32m0.25888[0m[0m | time: 213.070s
[2K
| Adam | epoch: 002 | loss: 0.25888 - acc: 0.8988 -- iter: 0576/1104
[A[ATraining Step: 54  | total loss: [1m[32m0.27610[0m[0m | time: 220.935s
[2K
| Adam | epoch: 002 | loss: 0.27610 - acc: 0.8772 -- iter: 0608/1104
[A[ATraining Step: 55  | total loss: [1m[32m0.24905[0m[0m | time: 228.801s
[2K
| Adam | epoch: 002 | loss: 0.24905 - acc: 0.8947 -- iter: 0640/1104
[A[ATraining Step: 56  | total loss: [1m[32m0.23634[0m[0m | time: 238.926s
[2K
| Adam | epoch: 002 | loss: 0.23634 - acc: 0.9007 -- iter: 0672/1104
[A[ATraining Step: 57  | total loss: [1m[32m0.25083[0m[0m | time: 251.068s
[2K
| Adam | epoch: 002 | loss: 0.25083 - acc: 0.8972 -- iter: 0704/1104
[A[ATraining Step: 58  | total loss: [1m[32m0.24571[0m[0m | time: 263.559s
[2K
| Adam | epoch: 002 | loss: 0.24571 - acc: 0.8984 -- iter: 0736/1104
[A[ATraining Step: 59  | total loss: [1m[32m0.25081[0m[0m | time: 275.989s
[2K
| Adam | epoch: 002 | loss: 0.25081 - acc: 0.8995 -- iter: 0768/1104
[A[ATraining Step: 60  | total loss: [1m[32m0.27161[0m[0m | time: 288.235s
[2K
| Adam | epoch: 002 | loss: 0.27161 - acc: 0.8880 -- iter: 0800/1104
[A[ATraining Step: 61  | total loss: [1m[32m0.26811[0m[0m | time: 300.836s
[2K
| Adam | epoch: 002 | loss: 0.26811 - acc: 0.8822 -- iter: 0832/1104
[A[ATraining Step: 62  | total loss: [1m[32m0.26281[0m[0m | time: 313.150s
[2K
| Adam | epoch: 002 | loss: 0.26281 - acc: 0.8813 -- iter: 0864/1104
[A[ATraining Step: 63  | total loss: [1m[32m0.25837[0m[0m | time: 325.882s
[2K
| Adam | epoch: 002 | loss: 0.25837 - acc: 0.8884 -- iter: 0896/1104
[A[ATraining Step: 64  | total loss: [1m[32m0.24243[0m[0m | time: 338.279s
[2K
| Adam | epoch: 002 | loss: 0.24243 - acc: 0.8984 -- iter: 0928/1104
[A[ATraining Step: 65  | total loss: [1m[32m0.24524[0m[0m | time: 350.966s
[2K
| Adam | epoch: 002 | loss: 0.24524 - acc: 0.8994 -- iter: 0960/1104
[A[ATraining Step: 66  | total loss: [1m[32m0.23093[0m[0m | time: 363.499s
[2K
| Adam | epoch: 002 | loss: 0.23093 - acc: 0.9040 -- iter: 0992/1104
[A[ATraining Step: 67  | total loss: [1m[32m0.25641[0m[0m | time: 376.224s
[2K
| Adam | epoch: 002 | loss: 0.25641 - acc: 0.8968 -- iter: 1024/1104
[A[ATraining Step: 68  | total loss: [1m[32m0.26573[0m[0m | time: 388.581s
[2K
| Adam | epoch: 002 | loss: 0.26573 - acc: 0.8942 -- iter: 1056/1104
[A[ATraining Step: 69  | total loss: [1m[32m0.25644[0m[0m | time: 401.077s
[2K
| Adam | epoch: 002 | loss: 0.25644 - acc: 0.8993 -- iter: 1088/1104
[A[ATraining Step: 70  | total loss: [1m[32m0.24087[0m[0m | time: 439.068s
[2K
| Adam | epoch: 002 | loss: 0.24087 - acc: 0.9073 | val_loss: 0.98601 - val_acc: 0.6792 -- iter: 1104/1104
--
Training Step: 71  | total loss: [1m[32m0.24333[0m[0m | time: 4.557s
[2K
| Adam | epoch: 003 | loss: 0.24333 - acc: 0.9036 -- iter: 0032/1104
[A[ATraining Step: 72  | total loss: [1m[32m0.23617[0m[0m | time: 9.080s
[2K
| Adam | epoch: 003 | loss: 0.23617 - acc: 0.9074 -- iter: 0064/1104
[A[ATraining Step: 73  | total loss: [1m[32m0.21942[0m[0m | time: 16.804s
[2K
| Adam | epoch: 003 | loss: 0.21942 - acc: 0.9177 -- iter: 0096/1104
[A[ATraining Step: 74  | total loss: [1m[32m0.24210[0m[0m | time: 27.021s
[2K
| Adam | epoch: 003 | loss: 0.24210 - acc: 0.9062 -- iter: 0128/1104
[A[ATraining Step: 75  | total loss: [1m[32m0.24476[0m[0m | time: 39.030s
[2K
| Adam | epoch: 003 | loss: 0.24476 - acc: 0.8994 -- iter: 0160/1104
[A[ATraining Step: 76  | total loss: [1m[32m0.24017[0m[0m | time: 51.187s
[2K
| Adam | epoch: 003 | loss: 0.24017 - acc: 0.9035 -- iter: 0192/1104
[A[ATraining Step: 77  | total loss: [1m[32m0.23770[0m[0m | time: 63.279s
[2K
| Adam | epoch: 003 | loss: 0.23770 - acc: 0.9038 -- iter: 0224/1104
[A[ATraining Step: 78  | total loss: [1m[32m0.25530[0m[0m | time: 75.641s
[2K
| Adam | epoch: 003 | loss: 0.25530 - acc: 0.9008 -- iter: 0256/1104
[A[ATraining Step: 79  | total loss: [1m[32m0.25439[0m[0m | time: 87.490s
[2K
| Adam | epoch: 003 | loss: 0.25439 - acc: 0.8981 -- iter: 0288/1104
[A[ATraining Step: 80  | total loss: [1m[32m0.26425[0m[0m | time: 99.763s
[2K
| Adam | epoch: 003 | loss: 0.26425 - acc: 0.8957 -- iter: 0320/1104
[A[ATraining Step: 81  | total loss: [1m[32m0.25438[0m[0m | time: 111.755s
[2K
| Adam | epoch: 003 | loss: 0.25438 - acc: 0.8968 -- iter: 0352/1104
[A[ATraining Step: 82  | total loss: [1m[32m0.26718[0m[0m | time: 124.303s
[2K
| Adam | epoch: 003 | loss: 0.26718 - acc: 0.8884 -- iter: 0384/1104
[A[ATraining Step: 83  | total loss: [1m[32m0.26647[0m[0m | time: 136.765s
[2K
| Adam | epoch: 003 | loss: 0.26647 - acc: 0.8870 -- iter: 0416/1104
[A[ATraining Step: 84  | total loss: [1m[32m0.28955[0m[0m | time: 149.136s
[2K
| Adam | epoch: 003 | loss: 0.28955 - acc: 0.8796 -- iter: 0448/1104
[A[ATraining Step: 85  | total loss: [1m[32m0.29092[0m[0m | time: 161.116s
[2K
| Adam | epoch: 003 | loss: 0.29092 - acc: 0.8822 -- iter: 0480/1104
[A[ATraining Step: 86  | total loss: [1m[32m0.31222[0m[0m | time: 173.652s
[2K
| Adam | epoch: 003 | loss: 0.31222 - acc: 0.8753 -- iter: 0512/1104
[A[ATraining Step: 87  | total loss: [1m[32m0.30825[0m[0m | time: 186.027s
[2K
| Adam | epoch: 003 | loss: 0.30825 - acc: 0.8784 -- iter: 0544/1104
[A[ATraining Step: 88  | total loss: [1m[32m0.29058[0m[0m | time: 198.342s
[2K
| Adam | epoch: 003 | loss: 0.29058 - acc: 0.8905 -- iter: 0576/1104
[A[ATraining Step: 89  | total loss: [1m[32m0.27966[0m[0m | time: 210.376s
[2K
| Adam | epoch: 003 | loss: 0.27966 - acc: 0.8921 -- iter: 0608/1104
[A[ATraining Step: 90  | total loss: [1m[32m0.26297[0m[0m | time: 223.021s
[2K
| Adam | epoch: 003 | loss: 0.26297 - acc: 0.8998 -- iter: 0640/1104
[A[ATraining Step: 91  | total loss: [1m[32m0.25601[0m[0m | time: 235.112s
[2K
| Adam | epoch: 003 | loss: 0.25601 - acc: 0.8973 -- iter: 0672/1104
[A[ATraining Step: 92  | total loss: [1m[32m0.26652[0m[0m | time: 247.806s
[2K
| Adam | epoch: 003 | loss: 0.26652 - acc: 0.8857 -- iter: 0704/1104
[A[ATraining Step: 93  | total loss: [1m[32m0.26278[0m[0m | time: 257.801s
[2K
| Adam | epoch: 003 | loss: 0.26278 - acc: 0.8877 -- iter: 0736/1104
[A[ATraining Step: 94  | total loss: [1m[32m0.26400[0m[0m | time: 265.637s
[2K
| Adam | epoch: 003 | loss: 0.26400 - acc: 0.8927 -- iter: 0768/1104
[A[ATraining Step: 95  | total loss: [1m[32m0.27288[0m[0m | time: 273.542s
[2K
| Adam | epoch: 003 | loss: 0.27288 - acc: 0.8909 -- iter: 0800/1104
[A[ATraining Step: 96  | total loss: [1m[32m0.26569[0m[0m | time: 282.854s
[2K
| Adam | epoch: 003 | loss: 0.26569 - acc: 0.8987 -- iter: 0832/1104
[A[ATraining Step: 97  | total loss: [1m[32m0.26414[0m[0m | time: 295.331s
[2K
| Adam | epoch: 003 | loss: 0.26414 - acc: 0.8964 -- iter: 0864/1104
[A[ATraining Step: 98  | total loss: [1m[32m0.24957[0m[0m | time: 307.232s
[2K
| Adam | epoch: 003 | loss: 0.24957 - acc: 0.9005 -- iter: 0896/1104
[A[ATraining Step: 99  | total loss: [1m[32m0.23837[0m[0m | time: 319.441s
[2K
| Adam | epoch: 003 | loss: 0.23837 - acc: 0.9073 -- iter: 0928/1104
[A[ATraining Step: 100  | total loss: [1m[32m0.24334[0m[0m | time: 331.551s
[2K
| Adam | epoch: 003 | loss: 0.24334 - acc: 0.9072 -- iter: 0960/1104
[A[ATraining Step: 101  | total loss: [1m[32m0.24197[0m[0m | time: 343.945s
[2K
| Adam | epoch: 003 | loss: 0.24197 - acc: 0.9071 -- iter: 0992/1104
[A[ATraining Step: 102  | total loss: [1m[32m0.23305[0m[0m | time: 356.496s
[2K
| Adam | epoch: 003 | loss: 0.23305 - acc: 0.9133 -- iter: 1024/1104
[A[ATraining Step: 103  | total loss: [1m[32m0.21581[0m[0m | time: 368.765s
[2K
| Adam | epoch: 003 | loss: 0.21581 - acc: 0.9219 -- iter: 1056/1104
[A[ATraining Step: 104  | total loss: [1m[32m0.22108[0m[0m | time: 381.062s
[2K
| Adam | epoch: 003 | loss: 0.22108 - acc: 0.9172 -- iter: 1088/1104
[A[ATraining Step: 105  | total loss: [1m[32m0.21444[0m[0m | time: 418.825s
[2K
| Adam | epoch: 003 | loss: 0.21444 - acc: 0.9224 | val_loss: 0.42949 - val_acc: 0.8324 -- iter: 1104/1104
--
Training Step: 106  | total loss: [1m[32m0.20576[0m[0m | time: 12.206s
[2K
| Adam | epoch: 004 | loss: 0.20576 - acc: 0.9302 -- iter: 0032/1104
[A[ATraining Step: 107  | total loss: [1m[32m0.20710[0m[0m | time: 19.717s
[2K
| Adam | epoch: 004 | loss: 0.20710 - acc: 0.9309 -- iter: 0064/1104
[A[ATraining Step: 108  | total loss: [1m[32m0.21180[0m[0m | time: 27.420s
[2K
| Adam | epoch: 004 | loss: 0.21180 - acc: 0.9253 -- iter: 0096/1104
[A[ATraining Step: 109  | total loss: [1m[32m0.19606[0m[0m | time: 35.502s
[2K
| Adam | epoch: 004 | loss: 0.19606 - acc: 0.9328 -- iter: 0128/1104
[A[ATraining Step: 110  | total loss: [1m[32m0.18432[0m[0m | time: 43.337s
[2K
| Adam | epoch: 004 | loss: 0.18432 - acc: 0.9364 -- iter: 0160/1104
[A[ATraining Step: 111  | total loss: [1m[32m0.20659[0m[0m | time: 51.137s
[2K
| Adam | epoch: 004 | loss: 0.20659 - acc: 0.9271 -- iter: 0192/1104
[A[ATraining Step: 112  | total loss: [1m[32m0.22067[0m[0m | time: 58.964s
[2K
| Adam | epoch: 004 | loss: 0.22067 - acc: 0.9281 -- iter: 0224/1104
[A[ATraining Step: 113  | total loss: [1m[32m0.22430[0m[0m | time: 67.898s
[2K
| Adam | epoch: 004 | loss: 0.22430 - acc: 0.9228 -- iter: 0256/1104
[A[ATraining Step: 114  | total loss: [1m[32m0.22615[0m[0m | time: 80.377s
[2K
| Adam | epoch: 004 | loss: 0.22615 - acc: 0.9274 -- iter: 0288/1104
[A[ATraining Step: 115  | total loss: [1m[32m0.23216[0m[0m | time: 92.721s
[2K
| Adam | epoch: 004 | loss: 0.23216 - acc: 0.9284 -- iter: 0320/1104
[A[ATraining Step: 116  | total loss: [1m[32m0.24136[0m[0m | time: 104.960s
[2K
| Adam | epoch: 004 | loss: 0.24136 - acc: 0.9200 -- iter: 0352/1104
[A[ATraining Step: 117  | total loss: [1m[32m0.22515[0m[0m | time: 116.884s
[2K
| Adam | epoch: 004 | loss: 0.22515 - acc: 0.9280 -- iter: 0384/1104
[A[ATraining Step: 118  | total loss: [1m[32m0.22017[0m[0m | time: 128.787s
[2K
| Adam | epoch: 004 | loss: 0.22017 - acc: 0.9258 -- iter: 0416/1104
[A[ATraining Step: 119  | total loss: [1m[32m0.21308[0m[0m | time: 141.165s
[2K
| Adam | epoch: 004 | loss: 0.21308 - acc: 0.9238 -- iter: 0448/1104
[A[ATraining Step: 120  | total loss: [1m[32m0.21781[0m[0m | time: 153.394s
[2K
| Adam | epoch: 004 | loss: 0.21781 - acc: 0.9158 -- iter: 0480/1104
[A[ATraining Step: 121  | total loss: [1m[32m0.20389[0m[0m | time: 165.688s
[2K
| Adam | epoch: 004 | loss: 0.20389 - acc: 0.9242 -- iter: 0512/1104
[A[ATraining Step: 122  | total loss: [1m[32m0.20048[0m[0m | time: 178.064s
[2K
| Adam | epoch: 004 | loss: 0.20048 - acc: 0.9224 -- iter: 0544/1104
[A[ATraining Step: 123  | total loss: [1m[32m0.20867[0m[0m | time: 190.568s
[2K
| Adam | epoch: 004 | loss: 0.20867 - acc: 0.9271 -- iter: 0576/1104
[A[ATraining Step: 124  | total loss: [1m[32m0.20459[0m[0m | time: 202.899s
[2K
| Adam | epoch: 004 | loss: 0.20459 - acc: 0.9250 -- iter: 0608/1104
[A[ATraining Step: 125  | total loss: [1m[32m0.19593[0m[0m | time: 214.791s
[2K
| Adam | epoch: 004 | loss: 0.19593 - acc: 0.9262 -- iter: 0640/1104
[A[ATraining Step: 126  | total loss: [1m[32m0.19081[0m[0m | time: 227.132s
[2K
| Adam | epoch: 004 | loss: 0.19081 - acc: 0.9242 -- iter: 0672/1104
[A[ATraining Step: 127  | total loss: [1m[32m0.18374[0m[0m | time: 239.375s
[2K
| Adam | epoch: 004 | loss: 0.18374 - acc: 0.9287 -- iter: 0704/1104
[A[ATraining Step: 128  | total loss: [1m[32m0.17179[0m[0m | time: 251.873s
[2K
| Adam | epoch: 004 | loss: 0.17179 - acc: 0.9358 -- iter: 0736/1104
[A[ATraining Step: 129  | total loss: [1m[32m0.17197[0m[0m | time: 264.173s
[2K
| Adam | epoch: 004 | loss: 0.17197 - acc: 0.9360 -- iter: 0768/1104
[A[ATraining Step: 130  | total loss: [1m[32m0.15951[0m[0m | time: 276.581s
[2K
| Adam | epoch: 004 | loss: 0.15951 - acc: 0.9424 -- iter: 0800/1104
[A[ATraining Step: 131  | total loss: [1m[32m0.15117[0m[0m | time: 289.181s
[2K
| Adam | epoch: 004 | loss: 0.15117 - acc: 0.9450 -- iter: 0832/1104
[A[ATraining Step: 132  | total loss: [1m[32m0.14606[0m[0m | time: 301.070s
[2K
| Adam | epoch: 004 | loss: 0.14606 - acc: 0.9474 -- iter: 0864/1104
[A[ATraining Step: 133  | total loss: [1m[32m0.15731[0m[0m | time: 308.822s
[2K
| Adam | epoch: 004 | loss: 0.15731 - acc: 0.9402 -- iter: 0896/1104
[A[ATraining Step: 134  | total loss: [1m[32m0.14433[0m[0m | time: 316.755s
[2K
| Adam | epoch: 004 | loss: 0.14433 - acc: 0.9461 -- iter: 0928/1104
[A[ATraining Step: 135  | total loss: [1m[32m0.14171[0m[0m | time: 326.131s
[2K
| Adam | epoch: 004 | loss: 0.14171 - acc: 0.9484 -- iter: 0960/1104
[A[ATraining Step: 136  | total loss: [1m[32m0.15628[0m[0m | time: 338.538s
[2K
| Adam | epoch: 004 | loss: 0.15628 - acc: 0.9379 -- iter: 0992/1104
[A[ATraining Step: 137  | total loss: [1m[32m0.14670[0m[0m | time: 350.937s
[2K
| Adam | epoch: 004 | loss: 0.14670 - acc: 0.9410 -- iter: 1024/1104
[A[ATraining Step: 138  | total loss: [1m[32m0.14676[0m[0m | time: 363.053s
[2K
| Adam | epoch: 004 | loss: 0.14676 - acc: 0.9438 -- iter: 1056/1104
[A[ATraining Step: 139  | total loss: [1m[32m0.13531[0m[0m | time: 375.141s
[2K
| Adam | epoch: 004 | loss: 0.13531 - acc: 0.9494 -- iter: 1088/1104
[A[ATraining Step: 140  | total loss: [1m[32m0.14268[0m[0m | time: 412.141s
[2K
| Adam | epoch: 004 | loss: 0.14268 - acc: 0.9451 | val_loss: 5.55668 - val_acc: 0.5173 -- iter: 1104/1104
--
Training Step: 141  | total loss: [1m[32m0.14591[0m[0m | time: 12.072s
[2K
| Adam | epoch: 005 | loss: 0.14591 - acc: 0.9412 -- iter: 0032/1104
[A[ATraining Step: 142  | total loss: [1m[32m0.14400[0m[0m | time: 24.595s
[2K
| Adam | epoch: 005 | loss: 0.14400 - acc: 0.9440 -- iter: 0064/1104
[A[ATraining Step: 143  | total loss: [1m[32m0.13836[0m[0m | time: 31.633s
[2K
| Adam | epoch: 005 | loss: 0.13836 - acc: 0.9464 -- iter: 0096/1104
[A[ATraining Step: 144  | total loss: [1m[32m0.14292[0m[0m | time: 38.896s
[2K
| Adam | epoch: 005 | loss: 0.14292 - acc: 0.9456 -- iter: 0128/1104
[A[ATraining Step: 145  | total loss: [1m[32m0.13270[0m[0m | time: 51.240s
[2K
| Adam | epoch: 005 | loss: 0.13270 - acc: 0.9510 -- iter: 0160/1104
[A[ATraining Step: 146  | total loss: [1m[32m0.14195[0m[0m | time: 63.139s
[2K
| Adam | epoch: 005 | loss: 0.14195 - acc: 0.9434 -- iter: 0192/1104
[A[ATraining Step: 147  | total loss: [1m[32m0.16649[0m[0m | time: 75.430s
[2K
| Adam | epoch: 005 | loss: 0.16649 - acc: 0.9303 -- iter: 0224/1104
[A[ATraining Step: 148  | total loss: [1m[32m0.17541[0m[0m | time: 87.619s
[2K
| Adam | epoch: 005 | loss: 0.17541 - acc: 0.9342 -- iter: 0256/1104
[A[ATraining Step: 149  | total loss: [1m[32m0.16797[0m[0m | time: 100.095s
[2K
| Adam | epoch: 005 | loss: 0.16797 - acc: 0.9376 -- iter: 0288/1104
[A[ATraining Step: 150  | total loss: [1m[32m0.15356[0m[0m | time: 111.458s
[2K
| Adam | epoch: 005 | loss: 0.15356 - acc: 0.9438 -- iter: 0320/1104
[A[ATraining Step: 151  | total loss: [1m[32m0.14192[0m[0m | time: 119.309s
[2K
| Adam | epoch: 005 | loss: 0.14192 - acc: 0.9495 -- iter: 0352/1104
[A[ATraining Step: 152  | total loss: [1m[32m0.13038[0m[0m | time: 127.124s
[2K
| Adam | epoch: 005 | loss: 0.13038 - acc: 0.9545 -- iter: 0384/1104
[A[ATraining Step: 153  | total loss: [1m[32m0.13523[0m[0m | time: 134.891s
[2K
| Adam | epoch: 005 | loss: 0.13523 - acc: 0.9528 -- iter: 0416/1104
[A[ATraining Step: 154  | total loss: [1m[32m0.13600[0m[0m | time: 147.677s
[2K
| Adam | epoch: 005 | loss: 0.13600 - acc: 0.9482 -- iter: 0448/1104
[A[ATraining Step: 155  | total loss: [1m[32m0.13315[0m[0m | time: 163.381s
[2K
| Adam | epoch: 005 | loss: 0.13315 - acc: 0.9502 -- iter: 0480/1104
[A[ATraining Step: 156  | total loss: [1m[32m0.12343[0m[0m | time: 175.933s
[2K
| Adam | epoch: 005 | loss: 0.12343 - acc: 0.9552 -- iter: 0512/1104
[A[ATraining Step: 157  | total loss: [1m[32m0.11502[0m[0m | time: 187.897s
[2K
| Adam | epoch: 005 | loss: 0.11502 - acc: 0.9597 -- iter: 0544/1104
[A[ATraining Step: 158  | total loss: [1m[32m0.12411[0m[0m | time: 200.204s
[2K
| Adam | epoch: 005 | loss: 0.12411 - acc: 0.9575 -- iter: 0576/1104
[A[ATraining Step: 159  | total loss: [1m[32m0.11474[0m[0m | time: 212.135s
[2K
| Adam | epoch: 005 | loss: 0.11474 - acc: 0.9617 -- iter: 0608/1104
[A[ATraining Step: 160  | total loss: [1m[32m0.12416[0m[0m | time: 224.248s
[2K
| Adam | epoch: 005 | loss: 0.12416 - acc: 0.9562 -- iter: 0640/1104
[A[ATraining Step: 161  | total loss: [1m[32m0.11611[0m[0m | time: 242.377s
[2K
| Adam | epoch: 005 | loss: 0.11611 - acc: 0.9606 -- iter: 0672/1104
[A[ATraining Step: 162  | total loss: [1m[32m0.12271[0m[0m | time: 259.001s
[2K
| Adam | epoch: 005 | loss: 0.12271 - acc: 0.9551 -- iter: 0704/1104
[A[ATraining Step: 163  | total loss: [1m[32m0.12055[0m[0m | time: 272.239s
[2K
| Adam | epoch: 005 | loss: 0.12055 - acc: 0.9565 -- iter: 0736/1104
[A[ATraining Step: 164  | total loss: [1m[32m0.11612[0m[0m | time: 290.056s
[2K
| Adam | epoch: 005 | loss: 0.11612 - acc: 0.9577 -- iter: 0768/1104
[A[ATraining Step: 165  | total loss: [1m[32m0.11160[0m[0m | time: 303.801s
[2K
| Adam | epoch: 005 | loss: 0.11160 - acc: 0.9588 -- iter: 0800/1104
[A[ATraining Step: 166  | total loss: [1m[32m0.11032[0m[0m | time: 316.202s
[2K
| Adam | epoch: 005 | loss: 0.11032 - acc: 0.9567 -- iter: 0832/1104
[A[ATraining Step: 167  | total loss: [1m[32m0.12497[0m[0m | time: 330.164s
[2K
| Adam | epoch: 005 | loss: 0.12497 - acc: 0.9548 -- iter: 0864/1104
[A[ATraining Step: 168  | total loss: [1m[32m0.11803[0m[0m | time: 342.443s
[2K
| Adam | epoch: 005 | loss: 0.11803 - acc: 0.9593 -- iter: 0896/1104
[A[ATraining Step: 169  | total loss: [1m[32m0.11039[0m[0m | time: 355.044s
[2K
| Adam | epoch: 005 | loss: 0.11039 - acc: 0.9602 -- iter: 0928/1104
[A[ATraining Step: 170  | total loss: [1m[32m0.10080[0m[0m | time: 367.355s
[2K
| Adam | epoch: 005 | loss: 0.10080 - acc: 0.9642 -- iter: 0960/1104
[A[ATraining Step: 171  | total loss: [1m[32m0.09287[0m[0m | time: 380.364s
[2K
| Adam | epoch: 005 | loss: 0.09287 - acc: 0.9678 -- iter: 0992/1104
[A[ATraining Step: 172  | total loss: [1m[32m0.08901[0m[0m | time: 393.463s
[2K
| Adam | epoch: 005 | loss: 0.08901 - acc: 0.9679 -- iter: 1024/1104
[A[ATraining Step: 173  | total loss: [1m[32m0.08835[0m[0m | time: 401.304s
[2K
| Adam | epoch: 005 | loss: 0.08835 - acc: 0.9680 -- iter: 1056/1104
[A[ATraining Step: 174  | total loss: [1m[32m0.08827[0m[0m | time: 409.125s
[2K
| Adam | epoch: 005 | loss: 0.08827 - acc: 0.9681 -- iter: 1088/1104
[A[ATraining Step: 175  | total loss: [1m[32m0.09508[0m[0m | time: 439.794s
[2K
| Adam | epoch: 005 | loss: 0.09508 - acc: 0.9650 | val_loss: 0.55768 - val_acc: 0.8757 -- iter: 1104/1104
--
Validation AUC:0.9333032370251471
Validation AUPRC:0.8990073414325913
Test AUC:0.9521852445870088
Test AUPRC:0.935559804354427
BestTestF1Score	0.91	0.82	0.91	0.89	0.94	163	20	152	11	0.76
BestTestMCCScore	0.91	0.82	0.91	0.89	0.94	163	20	152	11	0.76
BestTestAccuracyScore	0.92	0.83	0.91	0.9	0.93	162	18	154	12	0.85
BestValidationF1Score	0.9	0.78	0.89	0.87	0.93	165	25	143	13	0.76
BestValidationMCC	0.9	0.78	0.89	0.87	0.93	165	25	143	13	0.76
BestValidationAccuracy	0.9	0.78	0.89	0.88	0.92	163	23	145	15	0.85
TestPredictions (Threshold:0.76)
CHEMBL288978,FP,INACT,1.0	CHEMBL104551,TN,INACT,0.03999999910593033	CHEMBL2042551,TN,INACT,0.0	CHEMBL104848,TN,INACT,0.3100000023841858	CHEMBL394406,TP,ACT,0.9900000095367432	CHEMBL404557,TN,INACT,0.07000000029802322	CHEMBL2370511,TN,INACT,0.0	CHEMBL324652,TN,INACT,0.10999999940395355	CHEMBL207745,TP,ACT,0.9900000095367432	CHEMBL167335,TN,INACT,0.49000000953674316	CHEMBL1097315,TP,ACT,1.0	CHEMBL3648356,TP,ACT,1.0	CHEMBL535602,FP,INACT,0.9100000262260437	CHEMBL3109560,FN,ACT,0.05000000074505806	CHEMBL361206,TP,ACT,1.0	CHEMBL362133,TP,ACT,1.0	CHEMBL207625,TP,ACT,1.0	CHEMBL287310,TP,ACT,1.0	CHEMBL137969,TP,ACT,1.0	CHEMBL363321,TP,ACT,1.0	CHEMBL344488,TP,ACT,1.0	CHEMBL1223128,TP,ACT,1.0	CHEMBL124488,TP,ACT,1.0	CHEMBL365852,TP,ACT,1.0	CHEMBL11404,TP,ACT,1.0	CHEMBL1222985,TP,ACT,1.0	CHEMBL390842,TN,INACT,0.03999999910593033	CHEMBL26522,TN,INACT,0.0	CHEMBL422636,TP,ACT,1.0	CHEMBL173059,TN,INACT,0.05000000074505806	CHEMBL89953,TN,INACT,0.0	CHEMBL3109772,TN,INACT,0.09000000357627869	CHEMBL96562,TP,ACT,0.9900000095367432	CHEMBL274317,TP,ACT,1.0	CHEMBL130861,TN,INACT,0.03999999910593033	CHEMBL7215,TP,ACT,0.9700000286102295	CHEMBL255791,FP,INACT,0.7900000214576721	CHEMBL14701,TP,ACT,1.0	CHEMBL1091894,TP,ACT,1.0	CHEMBL98484,TP,ACT,1.0	CHEMBL19050,TP,ACT,1.0	CHEMBL394430,TP,ACT,1.0	CHEMBL441664,TP,ACT,1.0	CHEMBL241279,TN,INACT,0.75	CHEMBL330137,TP,ACT,1.0	CHEMBL94919,TP,ACT,0.9900000095367432	CHEMBL169631,TN,INACT,0.3700000047683716	CHEMBL148967,TN,INACT,0.0	CHEMBL220091,TP,ACT,0.9900000095367432	CHEMBL109086,TP,ACT,1.0	CHEMBL7441,TN,INACT,0.009999999776482582	CHEMBL10328,TP,ACT,1.0	CHEMBL104,TN,INACT,0.25999999046325684	CHEMBL3260987,TP,ACT,1.0	CHEMBL423405,TN,INACT,0.0	CHEMBL68738,TN,INACT,0.0	CHEMBL233308,TP,ACT,1.0	CHEMBL342655,TP,ACT,1.0	CHEMBL139228,TP,ACT,0.9800000190734863	CHEMBL337024,TP,ACT,0.9900000095367432	CHEMBL279520,TN,INACT,0.05000000074505806	CHEMBL38861,FP,INACT,0.8199999928474426	CHEMBL240021,TN,INACT,0.009999999776482582	CHEMBL440961,TN,INACT,0.0	CHEMBL306645,TN,INACT,0.0	CHEMBL3580910,TP,ACT,1.0	CHEMBL387655,FN,ACT,0.5699999928474426	CHEMBL436006,TP,ACT,1.0	CHEMBL417358,TN,INACT,0.03999999910593033	CHEMBL33869,TP,ACT,1.0	CHEMBL3765249,TP,ACT,1.0	CHEMBL1381098,FP,INACT,1.0	CHEMBL63760,TN,INACT,0.1899999976158142	CHEMBL7713,TP,ACT,1.0	CHEMBL584,TN,INACT,0.0	CHEMBL138766,TP,ACT,1.0	CHEMBL344268,TP,ACT,1.0	CHEMBL124577,TP,ACT,1.0	CHEMBL431172,TN,INACT,0.009999999776482582	CHEMBL1813321,TP,ACT,0.8700000047683716	CHEMBL37703,TP,ACT,1.0	CHEMBL377809,TP,ACT,0.9800000190734863	CHEMBL186736,TP,ACT,1.0	CHEMBL34728,TP,ACT,1.0	CHEMBL102390,TN,INACT,0.009999999776482582	CHEMBL325935,TN,INACT,0.0	CHEMBL1223126,TP,ACT,0.9800000190734863	CHEMBL494566,TP,ACT,0.9900000095367432	CHEMBL396132,TP,ACT,1.0	CHEMBL593861,TN,INACT,0.03999999910593033	CHEMBL543251,TN,INACT,0.009999999776482582	CHEMBL114074,TN,INACT,0.009999999776482582	CHEMBL262787,TN,INACT,0.10999999940395355	CHEMBL136815,TP,ACT,1.0	CHEMBL490595,TP,ACT,1.0	CHEMBL186452,TP,ACT,0.8799999952316284	CHEMBL1223631,TN,INACT,0.05999999865889549	CHEMBL168372,TN,INACT,0.5099999904632568	CHEMBL241100,TN,INACT,0.6600000262260437	CHEMBL3088176,TN,INACT,0.27000001072883606	CHEMBL1779810,TP,ACT,1.0	CHEMBL336225,TP,ACT,1.0	CHEMBL2112592,TN,INACT,0.009999999776482582	CHEMBL377871,TP,ACT,1.0	CHEMBL227378,TN,INACT,0.05999999865889549	CHEMBL230249,TN,INACT,0.0	CHEMBL322339,TP,ACT,1.0	CHEMBL220820,FP,INACT,1.0	CHEMBL384248,TN,INACT,0.0	CHEMBL168223,TN,INACT,0.029999999329447746	CHEMBL478218,FN,ACT,0.4399999976158142	CHEMBL3612606,FN,ACT,0.5400000214576721	CHEMBL1823016,TP,ACT,0.9900000095367432	CHEMBL80504,TN,INACT,0.0	CHEMBL394642,TN,INACT,0.0	CHEMBL307659,TN,INACT,0.3400000035762787	CHEMBL1237299,TN,INACT,0.5199999809265137	CHEMBL1083787,TN,INACT,0.1599999964237213	CHEMBL299538,TN,INACT,0.14000000059604645	CHEMBL1092911,FN,ACT,0.5799999833106995	CHEMBL515856,FN,ACT,0.6000000238418579	CHEMBL334079,TP,ACT,1.0	CHEMBL140006,TN,INACT,0.14000000059604645	CHEMBL327864,TP,ACT,0.949999988079071	CHEMBL138581,TP,ACT,1.0	CHEMBL104377,TN,INACT,0.009999999776482582	CHEMBL1774531,TP,ACT,0.9399999976158142	CHEMBL431103,TP,ACT,1.0	CHEMBL239153,FP,INACT,1.0	CHEMBL112877,TN,INACT,0.0	CHEMBL64461,TN,INACT,0.009999999776482582	CHEMBL2436825,TN,INACT,0.05000000074505806	CHEMBL37512,TN,INACT,0.019999999552965164	CHEMBL446693,TN,INACT,0.0	CHEMBL1774524,TP,ACT,1.0	CHEMBL274438,TP,ACT,1.0	CHEMBL434674,TN,INACT,0.0	CHEMBL1813322,TP,ACT,1.0	CHEMBL123119,TP,ACT,0.949999988079071	CHEMBL330674,TN,INACT,0.009999999776482582	CHEMBL302829,TN,INACT,0.0	CHEMBL300195,TP,ACT,0.9700000286102295	CHEMBL169459,TN,INACT,0.07999999821186066	CHEMBL1091561,TP,ACT,1.0	CHEMBL98028,TP,ACT,0.9700000286102295	CHEMBL134416,TP,ACT,1.0	CHEMBL2376800,TN,INACT,0.6700000166893005	CHEMBL329861,TN,INACT,0.05999999865889549	CHEMBL342432,TP,ACT,1.0	CHEMBL288967,TN,INACT,0.0	CHEMBL322547,TN,INACT,0.0	CHEMBL138817,TP,ACT,1.0	CHEMBL3665433,TN,INACT,0.0	CHEMBL259131,TN,INACT,0.17000000178813934	CHEMBL3759054,TP,ACT,1.0	CHEMBL33185,TP,ACT,1.0	CHEMBL109778,TN,INACT,0.0	CHEMBL273410,TN,INACT,0.15000000596046448	CHEMBL2391352,TN,INACT,0.019999999552965164	CHEMBL1223275,FP,INACT,1.0	CHEMBL2112722,TP,ACT,1.0	CHEMBL2314253,TP,ACT,1.0	CHEMBL3740377,TP,ACT,1.0	CHEMBL368886,TP,ACT,1.0	CHEMBL207676,TP,ACT,0.9700000286102295	CHEMBL140896,TP,ACT,1.0	CHEMBL1258999,TN,INACT,0.05000000074505806	CHEMBL297335,TN,INACT,0.019999999552965164	CHEMBL3219326,TP,ACT,0.9800000190734863	CHEMBL10808,TN,INACT,0.6700000166893005	CHEMBL336509,TP,ACT,1.0	CHEMBL2314263,TP,ACT,1.0	CHEMBL3604310,TN,INACT,0.0	CHEMBL75358,TN,INACT,0.019999999552965164	CHEMBL3758679,TP,ACT,1.0	CHEMBL435023,FN,ACT,0.009999999776482582	CHEMBL354126,TN,INACT,0.0	CHEMBL10043,TP,ACT,1.0	CHEMBL3648369,TP,ACT,0.9900000095367432	CHEMBL267094,FP,INACT,0.949999988079071	CHEMBL280223,TN,INACT,0.6800000071525574	CHEMBL298612,TN,INACT,0.6600000262260437	CHEMBL595022,TN,INACT,0.0	CHEMBL426168,TP,ACT,1.0	CHEMBL160626,TN,INACT,0.009999999776482582	CHEMBL42359,FP,INACT,0.9200000166893005	CHEMBL2311547,TN,INACT,0.6200000047683716	CHEMBL608816,TN,INACT,0.019999999552965164	CHEMBL444128,FP,INACT,0.9300000071525574	CHEMBL328925,TN,INACT,0.0	CHEMBL469855,TN,INACT,0.2800000011920929	CHEMBL474091,TN,INACT,0.0	CHEMBL309397,TN,INACT,0.0	CHEMBL15675,TN,INACT,0.019999999552965164	CHEMBL337802,TP,ACT,1.0	CHEMBL3612463,TP,ACT,0.9900000095367432	CHEMBL171108,FP,INACT,1.0	CHEMBL233517,TP,ACT,1.0	CHEMBL319036,TN,INACT,0.019999999552965164	CHEMBL310427,TN,INACT,0.029999999329447746	CHEMBL502593,TN,INACT,0.0	CHEMBL3759816,TP,ACT,1.0	CHEMBL337764,TP,ACT,1.0	CHEMBL1237302,TN,INACT,0.0	CHEMBL316952,TP,ACT,1.0	CHEMBL226171,FN,ACT,0.23999999463558197	CHEMBL97186,TP,ACT,1.0	CHEMBL130813,TP,ACT,1.0	CHEMBL344866,FP,INACT,1.0	CHEMBL1092646,TP,ACT,1.0	CHEMBL1774514,TP,ACT,1.0	CHEMBL3329390,FN,ACT,0.44999998807907104	CHEMBL2436718,TN,INACT,0.019999999552965164	CHEMBL96173,TP,ACT,1.0	CHEMBL241080,TN,INACT,0.6100000143051147	CHEMBL344242,TP,ACT,1.0	CHEMBL394273,TP,ACT,1.0	CHEMBL45,TP,ACT,1.0	CHEMBL3612605,TP,ACT,1.0	CHEMBL149763,TN,INACT,0.019999999552965164	CHEMBL233310,TP,ACT,1.0	CHEMBL3238444,TN,INACT,0.5099999904632568	CHEMBL351183,TN,INACT,0.0	CHEMBL2048230,TN,INACT,0.05000000074505806	CHEMBL7673,TP,ACT,1.0	CHEMBL589,FP,INACT,0.9800000190734863	CHEMBL186977,TP,ACT,0.9900000095367432	CHEMBL3648366,TP,ACT,1.0	CHEMBL312670,TN,INACT,0.0	CHEMBL323854,TN,INACT,0.41999998688697815	CHEMBL476131,TP,ACT,1.0	CHEMBL3604309,TN,INACT,0.0	CHEMBL3628489,TP,ACT,1.0	CHEMBL136214,TP,ACT,1.0	CHEMBL181687,TP,ACT,1.0	CHEMBL352925,TN,INACT,0.029999999329447746	CHEMBL320254,TN,INACT,0.009999999776482582	CHEMBL181035,FP,INACT,1.0	CHEMBL2312347,TN,INACT,0.029999999329447746	CHEMBL143341,TN,INACT,0.09000000357627869	CHEMBL219127,TP,ACT,1.0	CHEMBL1907839,TN,INACT,0.0	CHEMBL1223346,FP,INACT,1.0	CHEMBL136273,TP,ACT,0.9900000095367432	CHEMBL672,TN,INACT,0.33000001311302185	CHEMBL296291,TN,INACT,0.07000000029802322	CHEMBL308414,TN,INACT,0.03999999910593033	CHEMBL132179,TN,INACT,0.33000001311302185	CHEMBL69521,TP,ACT,1.0	CHEMBL455909,TP,ACT,0.9800000190734863	CHEMBL79030,TN,INACT,0.009999999776482582	CHEMBL141208,TP,ACT,1.0	CHEMBL404866,TN,INACT,0.0	CHEMBL339265,TP,ACT,1.0	CHEMBL297473,TN,INACT,0.0	CHEMBL207420,TP,ACT,0.9900000095367432	CHEMBL45269,TN,INACT,0.0	CHEMBL1774526,TP,ACT,1.0	CHEMBL143304,TN,INACT,0.09000000357627869	CHEMBL327626,TN,INACT,0.05999999865889549	CHEMBL328422,TN,INACT,0.0	CHEMBL40986,TN,INACT,0.41999998688697815	CHEMBL3739674,TP,ACT,0.9900000095367432	CHEMBL218065,TP,ACT,1.0	CHEMBL398017,TP,ACT,1.0	CHEMBL3648361,TP,ACT,0.9800000190734863	CHEMBL297215,TN,INACT,0.0	CHEMBL3109563,TP,ACT,0.9800000190734863	CHEMBL233721,TN,INACT,0.5099999904632568	CHEMBL124422,TP,ACT,1.0	CHEMBL162095,TN,INACT,0.0	CHEMBL7599,TP,ACT,0.9900000095367432	CHEMBL1094546,TP,ACT,0.9200000166893005	CHEMBL19653,TP,ACT,0.9900000095367432	CHEMBL1223131,TP,ACT,1.0	CHEMBL308756,TN,INACT,0.07999999821186066	CHEMBL19260,TP,ACT,1.0	CHEMBL498493,TP,ACT,0.949999988079071	CHEMBL342256,TN,INACT,0.0	CHEMBL553666,TN,INACT,0.019999999552965164	CHEMBL314616,FP,INACT,0.9900000095367432	CHEMBL149592,TN,INACT,0.03999999910593033	CHEMBL208311,FP,INACT,1.0	CHEMBL282426,TN,INACT,0.009999999776482582	CHEMBL139439,FN,ACT,0.4300000071525574	CHEMBL1093457,FN,ACT,0.36000001430511475	CHEMBL95727,TN,INACT,0.009999999776482582	CHEMBL3109562,TP,ACT,0.9100000262260437	CHEMBL138012,TP,ACT,0.9900000095367432	CHEMBL440144,TP,ACT,1.0	CHEMBL394676,TP,ACT,1.0	CHEMBL305558,TN,INACT,0.3799999952316284	CHEMBL3580915,TP,ACT,1.0	CHEMBL293874,TN,INACT,0.0	CHEMBL83450,FP,INACT,0.9800000190734863	CHEMBL3604300,TN,INACT,0.009999999776482582	CHEMBL374075,TP,ACT,1.0	CHEMBL474708,TN,INACT,0.019999999552965164	CHEMBL3260985,TP,ACT,1.0	CHEMBL311781,TN,INACT,0.05000000074505806	CHEMBL424693,TP,ACT,1.0	CHEMBL233552,TN,INACT,0.5799999833106995	CHEMBL2369493,TN,INACT,0.0	CHEMBL330003,TN,INACT,0.0	CHEMBL3612610,TP,ACT,1.0	CHEMBL1224608,TN,INACT,0.05000000074505806	CHEMBL341989,TP,ACT,1.0	CHEMBL1946221,TP,ACT,1.0	CHEMBL1097497,TP,ACT,1.0	CHEMBL329960,TP,ACT,1.0	CHEMBL3759606,TP,ACT,1.0	CHEMBL195893,TN,INACT,0.05999999865889549	CHEMBL1223196,TP,ACT,1.0	CHEMBL1223130,TP,ACT,1.0	CHEMBL3612603,TP,ACT,0.8500000238418579	CHEMBL106259,TN,INACT,0.0	CHEMBL2011441,TN,INACT,0.07999999821186066	CHEMBL3648360,TP,ACT,0.9800000190734863	CHEMBL89203,TN,INACT,0.07999999821186066	CHEMBL1760950,TP,ACT,0.949999988079071	CHEMBL2112734,TP,ACT,1.0	CHEMBL351531,TN,INACT,0.0	CHEMBL2372075,TN,INACT,0.0	CHEMBL96916,TP,ACT,1.0	CHEMBL310425,TN,INACT,0.18000000715255737	CHEMBL218774,TP,ACT,1.0	CHEMBL11416,TP,ACT,1.0	CHEMBL2203713,TN,INACT,0.07999999821186066	CHEMBL2436719,TN,INACT,0.009999999776482582	CHEMBL392888,TN,INACT,0.5299999713897705	CHEMBL1765671,FP,INACT,0.9700000286102295	CHEMBL3590085,TN,INACT,0.019999999552965164	CHEMBL10211,TN,INACT,0.49000000953674316	CHEMBL99001,TP,ACT,0.7699999809265137	CHEMBL42411,TN,INACT,0.0	CHEMBL140244,TP,ACT,1.0	CHEMBL3760044,TP,ACT,1.0	CHEMBL3648359,TP,ACT,0.9399999976158142	CHEMBL45160,TN,INACT,0.029999999329447746	CHEMBL425064,TN,INACT,0.009999999776482582	CHEMBL142295,TN,INACT,0.6100000143051147	CHEMBL1259241,TN,INACT,0.03999999910593033	CHEMBL3612467,TP,ACT,1.0	CHEMBL7505,TN,INACT,0.0	CHEMBL109361,TP,ACT,1.0	CHEMBL1802024,TP,ACT,1.0	

