ImageNetInceptionV2 CHEMBL4979 adam 0.001 30 0 0 0.6 False True
Number of active compounds :	327
Number of inactive compounds :	218
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4979_adam_0.001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4979_adam_0.001_30_0.6/
---------------------------------
Training samples: 348
Validation samples: 109
--
Training Step: 1  | time: 105.320s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/348
[A[ATraining Step: 2  | total loss: [1m[32m0.59998[0m[0m | time: 172.444s
[2K
| Adam | epoch: 001 | loss: 0.59998 - acc: 0.6187 -- iter: 064/348
[A[ATraining Step: 3  | total loss: [1m[32m0.96261[0m[0m | time: 230.643s
[2K
| Adam | epoch: 001 | loss: 0.96261 - acc: 0.3682 -- iter: 096/348
[A[ATraining Step: 4  | total loss: [1m[32m0.78730[0m[0m | time: 286.038s
[2K
| Adam | epoch: 001 | loss: 0.78730 - acc: 0.5374 -- iter: 128/348
[A[ATraining Step: 5  | total loss: [1m[32m0.66690[0m[0m | time: 347.778s
[2K
| Adam | epoch: 001 | loss: 0.66690 - acc: 0.7062 -- iter: 160/348
[A[ATraining Step: 6  | total loss: [1m[32m0.61703[0m[0m | time: 380.973s
[2K
| Adam | epoch: 001 | loss: 0.61703 - acc: 0.7143 -- iter: 192/348
[A[ATraining Step: 7  | total loss: [1m[32m0.54335[0m[0m | time: 407.519s
[2K
| Adam | epoch: 001 | loss: 0.54335 - acc: 0.7732 -- iter: 224/348
[A[ATraining Step: 8  | total loss: [1m[32m0.61459[0m[0m | time: 481.146s
[2K
| Adam | epoch: 001 | loss: 0.61459 - acc: 0.6195 -- iter: 256/348
[A[ATraining Step: 9  | total loss: [1m[32m0.52585[0m[0m | time: 502.837s
[2K
| Adam | epoch: 001 | loss: 0.52585 - acc: 0.7217 -- iter: 288/348
[A[ATraining Step: 10  | total loss: [1m[32m0.52282[0m[0m | time: 530.598s
[2K
| Adam | epoch: 001 | loss: 0.52282 - acc: 0.7358 -- iter: 320/348
[A[ATraining Step: 11  | total loss: [1m[32m0.47392[0m[0m | time: 558.402s
[2K
| Adam | epoch: 001 | loss: 0.47392 - acc: 0.8166 | val_loss: 1.70681 - val_acc: 0.6239 -- iter: 348/348
--
Training Step: 12  | total loss: [1m[32m0.43749[0m[0m | time: 31.311s
[2K
| Adam | epoch: 002 | loss: 0.43749 - acc: 0.8027 -- iter: 032/348
[A[ATraining Step: 13  | total loss: [1m[32m0.36594[0m[0m | time: 75.208s
[2K
| Adam | epoch: 002 | loss: 0.36594 - acc: 0.8719 -- iter: 064/348
[A[ATraining Step: 14  | total loss: [1m[32m0.35514[0m[0m | time: 112.557s
[2K
| Adam | epoch: 002 | loss: 0.35514 - acc: 0.8732 -- iter: 096/348
[A[ATraining Step: 15  | total loss: [1m[32m0.32863[0m[0m | time: 142.129s
[2K
| Adam | epoch: 002 | loss: 0.32863 - acc: 0.8984 -- iter: 128/348
[A[ATraining Step: 16  | total loss: [1m[32m0.25319[0m[0m | time: 186.089s
[2K
| Adam | epoch: 002 | loss: 0.25319 - acc: 0.9365 -- iter: 160/348
[A[ATraining Step: 17  | total loss: [1m[32m0.24079[0m[0m | time: 204.448s
[2K
| Adam | epoch: 002 | loss: 0.24079 - acc: 0.9143 -- iter: 192/348
[A[ATraining Step: 18  | total loss: [1m[32m0.24431[0m[0m | time: 217.600s
[2K
| Adam | epoch: 002 | loss: 0.24431 - acc: 0.9115 -- iter: 224/348
[A[ATraining Step: 19  | total loss: [1m[32m0.18887[0m[0m | time: 232.881s
[2K
| Adam | epoch: 002 | loss: 0.18887 - acc: 0.9410 -- iter: 256/348
[A[ATraining Step: 20  | total loss: [1m[32m0.19456[0m[0m | time: 246.115s
[2K
| Adam | epoch: 002 | loss: 0.19456 - acc: 0.9399 -- iter: 288/348
[A[ATraining Step: 21  | total loss: [1m[32m0.41277[0m[0m | time: 257.787s
[2K
| Adam | epoch: 002 | loss: 0.41277 - acc: 0.8810 -- iter: 320/348
[A[ATraining Step: 22  | total loss: [1m[32m0.49279[0m[0m | time: 307.338s
[2K
| Adam | epoch: 002 | loss: 0.49279 - acc: 0.8323 | val_loss: 2.92833 - val_acc: 0.6239 -- iter: 348/348
--
Training Step: 23  | total loss: [1m[32m0.44981[0m[0m | time: 49.719s
[2K
| Adam | epoch: 003 | loss: 0.44981 - acc: 0.8266 -- iter: 032/348
[A[ATraining Step: 24  | total loss: [1m[32m0.41317[0m[0m | time: 77.684s
[2K
| Adam | epoch: 003 | loss: 0.41317 - acc: 0.8352 -- iter: 064/348
[A[ATraining Step: 25  | total loss: [1m[32m0.34596[0m[0m | time: 92.847s
[2K
| Adam | epoch: 003 | loss: 0.34596 - acc: 0.8704 -- iter: 096/348
[A[ATraining Step: 26  | total loss: [1m[32m0.29126[0m[0m | time: 121.034s
[2K
| Adam | epoch: 003 | loss: 0.29126 - acc: 0.8799 -- iter: 128/348
[A[ATraining Step: 27  | total loss: [1m[32m0.28743[0m[0m | time: 163.490s
[2K
| Adam | epoch: 003 | loss: 0.28743 - acc: 0.8867 -- iter: 160/348
[A[ATraining Step: 28  | total loss: [1m[32m0.26931[0m[0m | time: 201.388s
[2K
| Adam | epoch: 003 | loss: 0.26931 - acc: 0.8916 -- iter: 192/348
[A[ATraining Step: 29  | total loss: [1m[32m0.25744[0m[0m | time: 225.187s
[2K
| Adam | epoch: 003 | loss: 0.25744 - acc: 0.8951 -- iter: 224/348
[A[ATraining Step: 30  | total loss: [1m[32m0.28758[0m[0m | time: 244.647s
[2K
| Adam | epoch: 003 | loss: 0.28758 - acc: 0.8756 -- iter: 256/348
[A[ATraining Step: 31  | total loss: [1m[32m0.25092[0m[0m | time: 253.614s
[2K
| Adam | epoch: 003 | loss: 0.25092 - acc: 0.8971 -- iter: 288/348
[A[ATraining Step: 32  | total loss: [1m[32m0.22446[0m[0m | time: 262.246s
[2K
| Adam | epoch: 003 | loss: 0.22446 - acc: 0.9132 -- iter: 320/348
[A[ATraining Step: 33  | total loss: [1m[32m0.25461[0m[0m | time: 290.932s
[2K
| Adam | epoch: 003 | loss: 0.25461 - acc: 0.9117 | val_loss: 0.74260 - val_acc: 0.6330 -- iter: 348/348
--
Training Step: 34  | total loss: [1m[32m0.21504[0m[0m | time: 12.251s
[2K
| Adam | epoch: 004 | loss: 0.21504 - acc: 0.9306 -- iter: 032/348
[A[ATraining Step: 35  | total loss: [1m[32m0.26880[0m[0m | time: 19.769s
[2K
| Adam | epoch: 004 | loss: 0.26880 - acc: 0.9059 -- iter: 064/348
[A[ATraining Step: 36  | total loss: [1m[32m0.29831[0m[0m | time: 27.331s
[2K
| Adam | epoch: 004 | loss: 0.29831 - acc: 0.8886 -- iter: 096/348
[A[ATraining Step: 37  | total loss: [1m[32m0.26856[0m[0m | time: 57.197s
[2K
| Adam | epoch: 004 | loss: 0.26856 - acc: 0.8966 -- iter: 128/348
[A[ATraining Step: 38  | total loss: [1m[32m0.24833[0m[0m | time: 69.514s
[2K
| Adam | epoch: 004 | loss: 0.24833 - acc: 0.9107 -- iter: 160/348
[A[ATraining Step: 39  | total loss: [1m[32m0.26329[0m[0m | time: 81.986s
[2K
| Adam | epoch: 004 | loss: 0.26329 - acc: 0.9039 -- iter: 192/348
[A[ATraining Step: 40  | total loss: [1m[32m0.27639[0m[0m | time: 97.332s
[2K
| Adam | epoch: 004 | loss: 0.27639 - acc: 0.8926 -- iter: 224/348
[A[ATraining Step: 41  | total loss: [1m[32m0.26033[0m[0m | time: 110.692s
[2K
| Adam | epoch: 004 | loss: 0.26033 - acc: 0.8951 -- iter: 256/348
[A[ATraining Step: 42  | total loss: [1m[32m0.26009[0m[0m | time: 124.424s
[2K
| Adam | epoch: 004 | loss: 0.26009 - acc: 0.8971 -- iter: 288/348
[A[ATraining Step: 43  | total loss: [1m[32m0.22383[0m[0m | time: 137.029s
[2K
| Adam | epoch: 004 | loss: 0.22383 - acc: 0.9153 -- iter: 320/348
[A[ATraining Step: 44  | total loss: [1m[32m0.23081[0m[0m | time: 151.112s
[2K
| Adam | epoch: 004 | loss: 0.23081 - acc: 0.9137 | val_loss: 2.08548 - val_acc: 0.3761 -- iter: 348/348
--
Training Step: 45  | total loss: [1m[32m0.22761[0m[0m | time: 8.847s
[2K
| Adam | epoch: 005 | loss: 0.22761 - acc: 0.9124 -- iter: 032/348
[A[ATraining Step: 46  | total loss: [1m[32m0.20933[0m[0m | time: 17.167s
[2K
| Adam | epoch: 005 | loss: 0.20933 - acc: 0.9218 -- iter: 064/348
[A[ATraining Step: 47  | total loss: [1m[32m0.19800[0m[0m | time: 24.849s
[2K
| Adam | epoch: 005 | loss: 0.19800 - acc: 0.9244 -- iter: 096/348
[A[ATraining Step: 48  | total loss: [1m[32m0.19845[0m[0m | time: 32.354s
[2K
| Adam | epoch: 005 | loss: 0.19845 - acc: 0.9193 -- iter: 128/348
[A[ATraining Step: 49  | total loss: [1m[32m0.17514[0m[0m | time: 40.674s
[2K
| Adam | epoch: 005 | loss: 0.17514 - acc: 0.9321 -- iter: 160/348
[A[ATraining Step: 50  | total loss: [1m[32m0.18478[0m[0m | time: 49.076s
[2K
| Adam | epoch: 005 | loss: 0.18478 - acc: 0.9281 -- iter: 192/348
[A[ATraining Step: 51  | total loss: [1m[32m0.24129[0m[0m | time: 57.549s
[2K
| Adam | epoch: 005 | loss: 0.24129 - acc: 0.9057 -- iter: 224/348
[A[ATraining Step: 52  | total loss: [1m[32m0.24279[0m[0m | time: 66.212s
[2K
| Adam | epoch: 005 | loss: 0.24279 - acc: 0.9058 -- iter: 256/348
[A[ATraining Step: 53  | total loss: [1m[32m0.23562[0m[0m | time: 74.679s
[2K
| Adam | epoch: 005 | loss: 0.23562 - acc: 0.9104 -- iter: 288/348
[A[ATraining Step: 54  | total loss: [1m[32m0.21679[0m[0m | time: 83.084s
[2K
| Adam | epoch: 005 | loss: 0.21679 - acc: 0.9234 -- iter: 320/348
[A[ATraining Step: 55  | total loss: [1m[32m0.22165[0m[0m | time: 96.516s
[2K
| Adam | epoch: 005 | loss: 0.22165 - acc: 0.9210 | val_loss: 2.28796 - val_acc: 0.7248 -- iter: 348/348
--
Training Step: 56  | total loss: [1m[32m0.23268[0m[0m | time: 8.266s
[2K
| Adam | epoch: 006 | loss: 0.23268 - acc: 0.9101 -- iter: 032/348
[A[ATraining Step: 57  | total loss: [1m[32m0.22444[0m[0m | time: 16.675s
[2K
| Adam | epoch: 006 | loss: 0.22444 - acc: 0.9139 -- iter: 064/348
[A[ATraining Step: 58  | total loss: [1m[32m0.26800[0m[0m | time: 25.345s
[2K
| Adam | epoch: 006 | loss: 0.26800 - acc: 0.9001 -- iter: 096/348
[A[ATraining Step: 59  | total loss: [1m[32m0.25304[0m[0m | time: 32.777s
[2K
| Adam | epoch: 006 | loss: 0.25304 - acc: 0.9009 -- iter: 128/348
[A[ATraining Step: 60  | total loss: [1m[32m0.23291[0m[0m | time: 40.238s
[2K
| Adam | epoch: 006 | loss: 0.23291 - acc: 0.9093 -- iter: 160/348
[A[ATraining Step: 61  | total loss: [1m[32m0.20917[0m[0m | time: 48.821s
[2K
| Adam | epoch: 006 | loss: 0.20917 - acc: 0.9211 -- iter: 192/348
[A[ATraining Step: 62  | total loss: [1m[32m0.19173[0m[0m | time: 57.421s
[2K
| Adam | epoch: 006 | loss: 0.19173 - acc: 0.9232 -- iter: 224/348
[A[ATraining Step: 63  | total loss: [1m[32m0.18742[0m[0m | time: 65.795s
[2K
| Adam | epoch: 006 | loss: 0.18742 - acc: 0.9250 -- iter: 256/348
[A[ATraining Step: 64  | total loss: [1m[32m0.18672[0m[0m | time: 74.018s
[2K
| Adam | epoch: 006 | loss: 0.18672 - acc: 0.9305 -- iter: 288/348
[A[ATraining Step: 65  | total loss: [1m[32m0.16671[0m[0m | time: 82.391s
[2K
| Adam | epoch: 006 | loss: 0.16671 - acc: 0.9391 -- iter: 320/348
[A[ATraining Step: 66  | total loss: [1m[32m0.15987[0m[0m | time: 95.879s
[2K
| Adam | epoch: 006 | loss: 0.15987 - acc: 0.9427 | val_loss: 2.35434 - val_acc: 0.3853 -- iter: 348/348
--
Training Step: 67  | total loss: [1m[32m0.15363[0m[0m | time: 8.243s
[2K
| Adam | epoch: 007 | loss: 0.15363 - acc: 0.9496 -- iter: 032/348
[A[ATraining Step: 68  | total loss: [1m[32m0.15804[0m[0m | time: 16.472s
[2K
| Adam | epoch: 007 | loss: 0.15804 - acc: 0.9481 -- iter: 064/348
[A[ATraining Step: 69  | total loss: [1m[32m0.14847[0m[0m | time: 24.549s
[2K
| Adam | epoch: 007 | loss: 0.14847 - acc: 0.9505 -- iter: 096/348
[A[ATraining Step: 70  | total loss: [1m[32m0.13631[0m[0m | time: 32.942s
[2K
| Adam | epoch: 007 | loss: 0.13631 - acc: 0.9562 -- iter: 128/348
[A[ATraining Step: 71  | total loss: [1m[32m0.16483[0m[0m | time: 40.524s
[2K
| Adam | epoch: 007 | loss: 0.16483 - acc: 0.9470 -- iter: 160/348
[A[ATraining Step: 72  | total loss: [1m[32m0.14985[0m[0m | time: 48.262s
[2K
| Adam | epoch: 007 | loss: 0.14985 - acc: 0.9530 -- iter: 192/348
[A[ATraining Step: 73  | total loss: [1m[32m0.13695[0m[0m | time: 56.811s
[2K
| Adam | epoch: 007 | loss: 0.13695 - acc: 0.9582 -- iter: 224/348
[A[ATraining Step: 74  | total loss: [1m[32m0.12833[0m[0m | time: 65.359s
[2K
| Adam | epoch: 007 | loss: 0.12833 - acc: 0.9593 -- iter: 256/348
[A[ATraining Step: 75  | total loss: [1m[32m0.12301[0m[0m | time: 73.779s
[2K
| Adam | epoch: 007 | loss: 0.12301 - acc: 0.9604 -- iter: 288/348
[A[ATraining Step: 76  | total loss: [1m[32m0.18741[0m[0m | time: 82.125s
[2K
| Adam | epoch: 007 | loss: 0.18741 - acc: 0.9512 -- iter: 320/348
[A[ATraining Step: 77  | total loss: [1m[32m0.18232[0m[0m | time: 95.747s
[2K
| Adam | epoch: 007 | loss: 0.18232 - acc: 0.9498 | val_loss: 3.08869 - val_acc: 0.4128 -- iter: 348/348
--
Training Step: 78  | total loss: [1m[32m0.17688[0m[0m | time: 8.335s
[2K
| Adam | epoch: 008 | loss: 0.17688 - acc: 0.9485 -- iter: 032/348
[A[ATraining Step: 79  | total loss: [1m[32m0.16609[0m[0m | time: 16.492s
[2K
| Adam | epoch: 008 | loss: 0.16609 - acc: 0.9506 -- iter: 064/348
[A[ATraining Step: 80  | total loss: [1m[32m0.19096[0m[0m | time: 25.083s
[2K
| Adam | epoch: 008 | loss: 0.19096 - acc: 0.9428 -- iter: 096/348
[A[ATraining Step: 81  | total loss: [1m[32m0.18524[0m[0m | time: 33.570s
[2K
| Adam | epoch: 008 | loss: 0.18524 - acc: 0.9391 -- iter: 128/348
[A[ATraining Step: 82  | total loss: [1m[32m0.17999[0m[0m | time: 42.290s
[2K
| Adam | epoch: 008 | loss: 0.17999 - acc: 0.9390 -- iter: 160/348
[A[ATraining Step: 83  | total loss: [1m[32m0.17246[0m[0m | time: 49.952s
[2K
| Adam | epoch: 008 | loss: 0.17246 - acc: 0.9388 -- iter: 192/348
[A[ATraining Step: 84  | total loss: [1m[32m0.18598[0m[0m | time: 57.417s
[2K
| Adam | epoch: 008 | loss: 0.18598 - acc: 0.9307 -- iter: 224/348
[A[ATraining Step: 85  | total loss: [1m[32m0.18307[0m[0m | time: 65.721s
[2K
| Adam | epoch: 008 | loss: 0.18307 - acc: 0.9340 -- iter: 256/348
[A[ATraining Step: 86  | total loss: [1m[32m0.17702[0m[0m | time: 74.205s
[2K
| Adam | epoch: 008 | loss: 0.17702 - acc: 0.9344 -- iter: 288/348
[A[ATraining Step: 87  | total loss: [1m[32m0.18606[0m[0m | time: 82.364s
[2K
| Adam | epoch: 008 | loss: 0.18606 - acc: 0.9284 -- iter: 320/348
[A[ATraining Step: 88  | total loss: [1m[32m0.19655[0m[0m | time: 95.831s
[2K
| Adam | epoch: 008 | loss: 0.19655 - acc: 0.9325 | val_loss: 1.23133 - val_acc: 0.7615 -- iter: 348/348
--
Training Step: 89  | total loss: [1m[32m0.19066[0m[0m | time: 8.471s
[2K
| Adam | epoch: 009 | loss: 0.19066 - acc: 0.9298 -- iter: 032/348
[A[ATraining Step: 90  | total loss: [1m[32m0.18338[0m[0m | time: 16.881s
[2K
| Adam | epoch: 009 | loss: 0.18338 - acc: 0.9306 -- iter: 064/348
[A[ATraining Step: 91  | total loss: [1m[32m0.17315[0m[0m | time: 25.215s
[2K
| Adam | epoch: 009 | loss: 0.17315 - acc: 0.9313 -- iter: 096/348
[A[ATraining Step: 92  | total loss: [1m[32m0.16438[0m[0m | time: 33.526s
[2K
| Adam | epoch: 009 | loss: 0.16438 - acc: 0.9382 -- iter: 128/348
[A[ATraining Step: 93  | total loss: [1m[32m0.15395[0m[0m | time: 41.926s
[2K
| Adam | epoch: 009 | loss: 0.15395 - acc: 0.9412 -- iter: 160/348
[A[ATraining Step: 94  | total loss: [1m[32m0.15003[0m[0m | time: 50.358s
[2K
| Adam | epoch: 009 | loss: 0.15003 - acc: 0.9409 -- iter: 192/348
[A[ATraining Step: 95  | total loss: [1m[32m0.14212[0m[0m | time: 57.818s
[2K
| Adam | epoch: 009 | loss: 0.14212 - acc: 0.9436 -- iter: 224/348
[A[ATraining Step: 96  | total loss: [1m[32m0.13269[0m[0m | time: 65.224s
[2K
| Adam | epoch: 009 | loss: 0.13269 - acc: 0.9493 -- iter: 256/348
[A[ATraining Step: 97  | total loss: [1m[32m0.12157[0m[0m | time: 73.646s
[2K
| Adam | epoch: 009 | loss: 0.12157 - acc: 0.9544 -- iter: 288/348
[A[ATraining Step: 98  | total loss: [1m[32m0.13908[0m[0m | time: 82.056s
[2K
| Adam | epoch: 009 | loss: 0.13908 - acc: 0.9495 -- iter: 320/348
[A[ATraining Step: 99  | total loss: [1m[32m0.15771[0m[0m | time: 95.647s
[2K
| Adam | epoch: 009 | loss: 0.15771 - acc: 0.9452 | val_loss: 0.64151 - val_acc: 0.8257 -- iter: 348/348
--
Training Step: 100  | total loss: [1m[32m0.15436[0m[0m | time: 8.549s
[2K
| Adam | epoch: 010 | loss: 0.15436 - acc: 0.9476 -- iter: 032/348
[A[ATraining Step: 101  | total loss: [1m[32m0.14532[0m[0m | time: 16.841s
[2K
| Adam | epoch: 010 | loss: 0.14532 - acc: 0.9497 -- iter: 064/348
[A[ATraining Step: 102  | total loss: [1m[32m0.13405[0m[0m | time: 25.337s
[2K
| Adam | epoch: 010 | loss: 0.13405 - acc: 0.9547 -- iter: 096/348
[A[ATraining Step: 103  | total loss: [1m[32m0.16189[0m[0m | time: 33.839s
[2K
| Adam | epoch: 010 | loss: 0.16189 - acc: 0.9467 -- iter: 128/348
[A[ATraining Step: 104  | total loss: [1m[32m0.14936[0m[0m | time: 42.753s
[2K
| Adam | epoch: 010 | loss: 0.14936 - acc: 0.9521 -- iter: 160/348
[A[ATraining Step: 105  | total loss: [1m[32m0.14650[0m[0m | time: 51.473s
[2K
| Adam | epoch: 010 | loss: 0.14650 - acc: 0.9537 -- iter: 192/348
[A[ATraining Step: 106  | total loss: [1m[32m0.13893[0m[0m | time: 59.766s
[2K
| Adam | epoch: 010 | loss: 0.13893 - acc: 0.9552 -- iter: 224/348
[A[ATraining Step: 107  | total loss: [1m[32m0.13453[0m[0m | time: 67.437s
[2K
| Adam | epoch: 010 | loss: 0.13453 - acc: 0.9535 -- iter: 256/348
[A[ATraining Step: 108  | total loss: [1m[32m0.12629[0m[0m | time: 74.939s
[2K
| Adam | epoch: 010 | loss: 0.12629 - acc: 0.9545 -- iter: 288/348
[A[ATraining Step: 109  | total loss: [1m[32m0.11719[0m[0m | time: 83.282s
[2K
| Adam | epoch: 010 | loss: 0.11719 - acc: 0.9591 -- iter: 320/348
[A[ATraining Step: 110  | total loss: [1m[32m0.11390[0m[0m | time: 96.871s
[2K
| Adam | epoch: 010 | loss: 0.11390 - acc: 0.9601 | val_loss: 0.32087 - val_acc: 0.9174 -- iter: 348/348
--
Training Step: 111  | total loss: [1m[32m0.10656[0m[0m | time: 8.673s
[2K
| Adam | epoch: 011 | loss: 0.10656 - acc: 0.9641 -- iter: 032/348
[A[ATraining Step: 112  | total loss: [1m[32m0.11095[0m[0m | time: 17.524s
[2K
| Adam | epoch: 011 | loss: 0.11095 - acc: 0.9645 -- iter: 064/348
[A[ATraining Step: 113  | total loss: [1m[32m0.10522[0m[0m | time: 25.991s
[2K
| Adam | epoch: 011 | loss: 0.10522 - acc: 0.9649 -- iter: 096/348
[A[ATraining Step: 114  | total loss: [1m[32m0.10221[0m[0m | time: 34.395s
[2K
| Adam | epoch: 011 | loss: 0.10221 - acc: 0.9653 -- iter: 128/348
[A[ATraining Step: 115  | total loss: [1m[32m0.09441[0m[0m | time: 42.725s
[2K
| Adam | epoch: 011 | loss: 0.09441 - acc: 0.9688 -- iter: 160/348
[A[ATraining Step: 116  | total loss: [1m[32m0.08752[0m[0m | time: 51.243s
[2K
| Adam | epoch: 011 | loss: 0.08752 - acc: 0.9719 -- iter: 192/348
[A[ATraining Step: 117  | total loss: [1m[32m0.09107[0m[0m | time: 59.667s
[2K
| Adam | epoch: 011 | loss: 0.09107 - acc: 0.9685 -- iter: 224/348
[A[ATraining Step: 118  | total loss: [1m[32m0.08492[0m[0m | time: 68.254s
[2K
| Adam | epoch: 011 | loss: 0.08492 - acc: 0.9716 -- iter: 256/348
[A[ATraining Step: 119  | total loss: [1m[32m0.08013[0m[0m | time: 75.675s
[2K
| Adam | epoch: 011 | loss: 0.08013 - acc: 0.9745 -- iter: 288/348
[A[ATraining Step: 120  | total loss: [1m[32m0.07705[0m[0m | time: 83.223s
[2K
| Adam | epoch: 011 | loss: 0.07705 - acc: 0.9734 -- iter: 320/348
[A[ATraining Step: 121  | total loss: [1m[32m0.07116[0m[0m | time: 97.338s
[2K
| Adam | epoch: 011 | loss: 0.07116 - acc: 0.9761 | val_loss: 0.50784 - val_acc: 0.8532 -- iter: 348/348
--
Training Step: 122  | total loss: [1m[32m0.06554[0m[0m | time: 8.476s
[2K
| Adam | epoch: 012 | loss: 0.06554 - acc: 0.9785 -- iter: 032/348
[A[ATraining Step: 123  | total loss: [1m[32m0.07755[0m[0m | time: 17.183s
[2K
| Adam | epoch: 012 | loss: 0.07755 - acc: 0.9744 -- iter: 064/348
[A[ATraining Step: 124  | total loss: [1m[32m0.11443[0m[0m | time: 25.828s
[2K
| Adam | epoch: 012 | loss: 0.11443 - acc: 0.9707 -- iter: 096/348
[A[ATraining Step: 125  | total loss: [1m[32m0.10386[0m[0m | time: 34.373s
[2K
| Adam | epoch: 012 | loss: 0.10386 - acc: 0.9736 -- iter: 128/348
[A[ATraining Step: 126  | total loss: [1m[32m0.09400[0m[0m | time: 42.508s
[2K
| Adam | epoch: 012 | loss: 0.09400 - acc: 0.9763 -- iter: 160/348
[A[ATraining Step: 127  | total loss: [1m[32m0.09021[0m[0m | time: 51.234s
[2K
| Adam | epoch: 012 | loss: 0.09021 - acc: 0.9724 -- iter: 192/348
[A[ATraining Step: 128  | total loss: [1m[32m0.09412[0m[0m | time: 59.429s
[2K
| Adam | epoch: 012 | loss: 0.09412 - acc: 0.9689 -- iter: 224/348
[A[ATraining Step: 129  | total loss: [1m[32m0.09120[0m[0m | time: 68.070s
[2K
| Adam | epoch: 012 | loss: 0.09120 - acc: 0.9689 -- iter: 256/348
[A[ATraining Step: 130  | total loss: [1m[32m0.09401[0m[0m | time: 76.318s
[2K
| Adam | epoch: 012 | loss: 0.09401 - acc: 0.9689 -- iter: 288/348
[A[ATraining Step: 131  | total loss: [1m[32m0.09116[0m[0m | time: 83.806s
[2K
| Adam | epoch: 012 | loss: 0.09116 - acc: 0.9689 -- iter: 320/348
[A[ATraining Step: 132  | total loss: [1m[32m0.08758[0m[0m | time: 96.423s
[2K
| Adam | epoch: 012 | loss: 0.08758 - acc: 0.9684 | val_loss: 0.58996 - val_acc: 0.8349 -- iter: 348/348
--
Training Step: 133  | total loss: [1m[32m0.08207[0m[0m | time: 8.494s
[2K
| Adam | epoch: 013 | loss: 0.08207 - acc: 0.9716 -- iter: 032/348
[A[ATraining Step: 134  | total loss: [1m[32m0.07878[0m[0m | time: 17.167s
[2K
| Adam | epoch: 013 | loss: 0.07878 - acc: 0.9713 -- iter: 064/348
[A[ATraining Step: 135  | total loss: [1m[32m0.07567[0m[0m | time: 25.582s
[2K
| Adam | epoch: 013 | loss: 0.07567 - acc: 0.9710 -- iter: 096/348
[A[ATraining Step: 136  | total loss: [1m[32m0.10526[0m[0m | time: 34.045s
[2K
| Adam | epoch: 013 | loss: 0.10526 - acc: 0.9677 -- iter: 128/348
[A[ATraining Step: 137  | total loss: [1m[32m0.09603[0m[0m | time: 42.676s
[2K
| Adam | epoch: 013 | loss: 0.09603 - acc: 0.9709 -- iter: 160/348
[A[ATraining Step: 138  | total loss: [1m[32m0.09293[0m[0m | time: 50.960s
[2K
| Adam | epoch: 013 | loss: 0.09293 - acc: 0.9707 -- iter: 192/348
[A[ATraining Step: 139  | total loss: [1m[32m0.08444[0m[0m | time: 59.436s
[2K
| Adam | epoch: 013 | loss: 0.08444 - acc: 0.9736 -- iter: 224/348
[A[ATraining Step: 140  | total loss: [1m[32m0.08520[0m[0m | time: 68.455s
[2K
| Adam | epoch: 013 | loss: 0.08520 - acc: 0.9731 -- iter: 256/348
[A[ATraining Step: 141  | total loss: [1m[32m0.12442[0m[0m | time: 77.046s
[2K
| Adam | epoch: 013 | loss: 0.12442 - acc: 0.9633 -- iter: 288/348
[A[ATraining Step: 142  | total loss: [1m[32m0.11558[0m[0m | time: 85.691s
[2K
| Adam | epoch: 013 | loss: 0.11558 - acc: 0.9670 -- iter: 320/348
[A[ATraining Step: 143  | total loss: [1m[32m0.10489[0m[0m | time: 98.536s
[2K
| Adam | epoch: 013 | loss: 0.10489 - acc: 0.9703 | val_loss: 0.54703 - val_acc: 0.8716 -- iter: 348/348
--
Training Step: 144  | total loss: [1m[32m0.10024[0m[0m | time: 7.715s
[2K
| Adam | epoch: 014 | loss: 0.10024 - acc: 0.9697 -- iter: 032/348
[A[ATraining Step: 145  | total loss: [1m[32m0.09378[0m[0m | time: 15.998s
[2K
| Adam | epoch: 014 | loss: 0.09378 - acc: 0.9727 -- iter: 064/348
[A[ATraining Step: 146  | total loss: [1m[32m0.08930[0m[0m | time: 24.849s
[2K
| Adam | epoch: 014 | loss: 0.08930 - acc: 0.9754 -- iter: 096/348
[A[ATraining Step: 147  | total loss: [1m[32m0.08749[0m[0m | time: 33.507s
[2K
| Adam | epoch: 014 | loss: 0.08749 - acc: 0.9748 -- iter: 128/348
[A[ATraining Step: 148  | total loss: [1m[32m0.10186[0m[0m | time: 42.726s
[2K
| Adam | epoch: 014 | loss: 0.10186 - acc: 0.9742 -- iter: 160/348
[A[ATraining Step: 149  | total loss: [1m[32m0.09235[0m[0m | time: 51.214s
[2K
| Adam | epoch: 014 | loss: 0.09235 - acc: 0.9768 -- iter: 192/348
[A[ATraining Step: 150  | total loss: [1m[32m0.08422[0m[0m | time: 59.628s
[2K
| Adam | epoch: 014 | loss: 0.08422 - acc: 0.9791 -- iter: 224/348
[A[ATraining Step: 151  | total loss: [1m[32m0.07713[0m[0m | time: 68.321s
[2K
| Adam | epoch: 014 | loss: 0.07713 - acc: 0.9812 -- iter: 256/348
[A[ATraining Step: 152  | total loss: [1m[32m0.07052[0m[0m | time: 76.722s
[2K
| Adam | epoch: 014 | loss: 0.07052 - acc: 0.9831 -- iter: 288/348
[A[ATraining Step: 153  | total loss: [1m[32m0.07463[0m[0m | time: 86.179s
[2K
| Adam | epoch: 014 | loss: 0.07463 - acc: 0.9785 -- iter: 320/348
[A[ATraining Step: 154  | total loss: [1m[32m0.07051[0m[0m | time: 103.909s
[2K
| Adam | epoch: 014 | loss: 0.07051 - acc: 0.9807 | val_loss: 0.98109 - val_acc: 0.6881 -- iter: 348/348
--
Training Step: 155  | total loss: [1m[32m0.07380[0m[0m | time: 10.667s
[2K
| Adam | epoch: 015 | loss: 0.07380 - acc: 0.9763 -- iter: 032/348
[A[ATraining Step: 156  | total loss: [1m[32m0.06883[0m[0m | time: 27.453s
[2K
| Adam | epoch: 015 | loss: 0.06883 - acc: 0.9787 -- iter: 064/348
[A[ATraining Step: 157  | total loss: [1m[32m0.06378[0m[0m | time: 42.014s
[2K
| Adam | epoch: 015 | loss: 0.06378 - acc: 0.9808 -- iter: 096/348
[A[ATraining Step: 158  | total loss: [1m[32m0.06010[0m[0m | time: 58.091s
[2K
| Adam | epoch: 015 | loss: 0.06010 - acc: 0.9827 -- iter: 128/348
[A[ATraining Step: 159  | total loss: [1m[32m0.05571[0m[0m | time: 68.624s
[2K
| Adam | epoch: 015 | loss: 0.05571 - acc: 0.9845 -- iter: 160/348
[A[ATraining Step: 160  | total loss: [1m[32m0.06721[0m[0m | time: 84.425s
[2K
| Adam | epoch: 015 | loss: 0.06721 - acc: 0.9829 -- iter: 192/348
[A[ATraining Step: 161  | total loss: [1m[32m0.06327[0m[0m | time: 101.768s
[2K
| Adam | epoch: 015 | loss: 0.06327 - acc: 0.9846 -- iter: 224/348
[A[ATraining Step: 162  | total loss: [1m[32m0.06266[0m[0m | time: 111.971s
[2K
| Adam | epoch: 015 | loss: 0.06266 - acc: 0.9862 -- iter: 256/348
[A[ATraining Step: 163  | total loss: [1m[32m0.05937[0m[0m | time: 134.322s
[2K
| Adam | epoch: 015 | loss: 0.05937 - acc: 0.9875 -- iter: 288/348
[A[ATraining Step: 164  | total loss: [1m[32m0.06215[0m[0m | time: 154.004s
[2K
| Adam | epoch: 015 | loss: 0.06215 - acc: 0.9825 -- iter: 320/348
[A[ATraining Step: 165  | total loss: [1m[32m0.06157[0m[0m | time: 170.174s
[2K
| Adam | epoch: 015 | loss: 0.06157 - acc: 0.9812 | val_loss: 0.49635 - val_acc: 0.8899 -- iter: 348/348
--
Training Step: 166  | total loss: [1m[32m0.06080[0m[0m | time: 10.794s
[2K
| Adam | epoch: 016 | loss: 0.06080 - acc: 0.9799 -- iter: 032/348
[A[ATraining Step: 167  | total loss: [1m[32m0.06171[0m[0m | time: 20.726s
[2K
| Adam | epoch: 016 | loss: 0.06171 - acc: 0.9788 -- iter: 064/348
[A[ATraining Step: 168  | total loss: [1m[32m0.05868[0m[0m | time: 29.887s
[2K
| Adam | epoch: 016 | loss: 0.05868 - acc: 0.9809 -- iter: 096/348
[A[ATraining Step: 169  | total loss: [1m[32m0.05387[0m[0m | time: 39.639s
[2K
| Adam | epoch: 016 | loss: 0.05387 - acc: 0.9828 -- iter: 128/348
[A[ATraining Step: 170  | total loss: [1m[32m0.04988[0m[0m | time: 52.115s
[2K
| Adam | epoch: 016 | loss: 0.04988 - acc: 0.9845 -- iter: 160/348
[A[ATraining Step: 171  | total loss: [1m[32m0.04578[0m[0m | time: 74.871s
[2K
| Adam | epoch: 016 | loss: 0.04578 - acc: 0.9861 -- iter: 192/348
[A[ATraining Step: 172  | total loss: [1m[32m0.08952[0m[0m | time: 102.480s
[2K
| Adam | epoch: 016 | loss: 0.08952 - acc: 0.9812 -- iter: 224/348
[A[ATraining Step: 173  | total loss: [1m[32m0.09132[0m[0m | time: 126.811s
[2K
| Adam | epoch: 016 | loss: 0.09132 - acc: 0.9800 -- iter: 256/348
[A[ATraining Step: 174  | total loss: [1m[32m0.09258[0m[0m | time: 137.145s
[2K
| Adam | epoch: 016 | loss: 0.09258 - acc: 0.9789 -- iter: 288/348
[A[ATraining Step: 175  | total loss: [1m[32m0.08377[0m[0m | time: 148.252s
[2K
| Adam | epoch: 016 | loss: 0.08377 - acc: 0.9810 -- iter: 320/348
[A[ATraining Step: 176  | total loss: [1m[32m0.07656[0m[0m | time: 170.668s
[2K
| Adam | epoch: 016 | loss: 0.07656 - acc: 0.9829 | val_loss: 0.64463 - val_acc: 0.7982 -- iter: 348/348
--
Training Step: 177  | total loss: [1m[32m0.07040[0m[0m | time: 16.122s
[2K
| Adam | epoch: 017 | loss: 0.07040 - acc: 0.9846 -- iter: 032/348
[A[ATraining Step: 178  | total loss: [1m[32m0.06514[0m[0m | time: 27.749s
[2K
| Adam | epoch: 017 | loss: 0.06514 - acc: 0.9861 -- iter: 064/348
[A[ATraining Step: 179  | total loss: [1m[32m0.08373[0m[0m | time: 37.706s
[2K
| Adam | epoch: 017 | loss: 0.08373 - acc: 0.9813 -- iter: 096/348
[A[ATraining Step: 180  | total loss: [1m[32m0.08897[0m[0m | time: 47.603s
[2K
| Adam | epoch: 017 | loss: 0.08897 - acc: 0.9760 -- iter: 128/348
[A[ATraining Step: 181  | total loss: [1m[32m0.08213[0m[0m | time: 64.174s
[2K
| Adam | epoch: 017 | loss: 0.08213 - acc: 0.9784 -- iter: 160/348
[A[ATraining Step: 182  | total loss: [1m[32m0.07486[0m[0m | time: 74.803s
[2K
| Adam | epoch: 017 | loss: 0.07486 - acc: 0.9806 -- iter: 192/348
[A[ATraining Step: 183  | total loss: [1m[32m0.07007[0m[0m | time: 88.576s
[2K
| Adam | epoch: 017 | loss: 0.07007 - acc: 0.9825 -- iter: 224/348
[A[ATraining Step: 184  | total loss: [1m[32m0.09092[0m[0m | time: 111.077s
[2K
| Adam | epoch: 017 | loss: 0.09092 - acc: 0.9811 -- iter: 256/348
[A[ATraining Step: 185  | total loss: [1m[32m0.08376[0m[0m | time: 122.012s
[2K
| Adam | epoch: 017 | loss: 0.08376 - acc: 0.9830 -- iter: 288/348
[A[ATraining Step: 186  | total loss: [1m[32m0.08308[0m[0m | time: 134.097s
[2K
| Adam | epoch: 017 | loss: 0.08308 - acc: 0.9816 -- iter: 320/348
[A[ATraining Step: 187  | total loss: [1m[32m0.07615[0m[0m | time: 151.927s
[2K
| Adam | epoch: 017 | loss: 0.07615 - acc: 0.9834 | val_loss: 0.34363 - val_acc: 0.8440 -- iter: 348/348
--
Training Step: 188  | total loss: [1m[32m0.06922[0m[0m | time: 9.141s
[2K
| Adam | epoch: 018 | loss: 0.06922 - acc: 0.9851 -- iter: 032/348
[A[ATraining Step: 189  | total loss: [1m[32m0.06351[0m[0m | time: 17.473s
[2K
| Adam | epoch: 018 | loss: 0.06351 - acc: 0.9866 -- iter: 064/348
[A[ATraining Step: 190  | total loss: [1m[32m0.05891[0m[0m | time: 26.044s
[2K
| Adam | epoch: 018 | loss: 0.05891 - acc: 0.9879 -- iter: 096/348
[A[ATraining Step: 191  | total loss: [1m[32m0.06251[0m[0m | time: 33.626s
[2K
| Adam | epoch: 018 | loss: 0.06251 - acc: 0.9860 -- iter: 128/348
[A[ATraining Step: 192  | total loss: [1m[32m0.06372[0m[0m | time: 41.335s
[2K
| Adam | epoch: 018 | loss: 0.06372 - acc: 0.9838 -- iter: 160/348
[A[ATraining Step: 193  | total loss: [1m[32m0.06106[0m[0m | time: 49.829s
[2K
| Adam | epoch: 018 | loss: 0.06106 - acc: 0.9819 -- iter: 192/348
[A[ATraining Step: 194  | total loss: [1m[32m0.06320[0m[0m | time: 58.341s
[2K
| Adam | epoch: 018 | loss: 0.06320 - acc: 0.9806 -- iter: 224/348
[A[ATraining Step: 195  | total loss: [1m[32m0.06101[0m[0m | time: 66.765s
[2K
| Adam | epoch: 018 | loss: 0.06101 - acc: 0.9825 -- iter: 256/348
[A[ATraining Step: 196  | total loss: [1m[32m0.08295[0m[0m | time: 74.943s
[2K
| Adam | epoch: 018 | loss: 0.08295 - acc: 0.9749 -- iter: 288/348
[A[ATraining Step: 197  | total loss: [1m[32m0.07988[0m[0m | time: 83.374s
[2K
| Adam | epoch: 018 | loss: 0.07988 - acc: 0.9743 -- iter: 320/348
[A[ATraining Step: 198  | total loss: [1m[32m0.07400[0m[0m | time: 96.770s
[2K
| Adam | epoch: 018 | loss: 0.07400 - acc: 0.9768 | val_loss: 0.51264 - val_acc: 0.8440 -- iter: 348/348
--
Training Step: 199  | total loss: [1m[32m0.07343[0m[0m | time: 8.385s
[2K
| Adam | epoch: 019 | loss: 0.07343 - acc: 0.9760 -- iter: 032/348
[A[ATraining Step: 200  | total loss: [1m[32m0.07960[0m[0m | time: 21.960s
[2K
| Adam | epoch: 019 | loss: 0.07960 - acc: 0.9722 | val_loss: 0.33740 - val_acc: 0.8807 -- iter: 064/348
--
Training Step: 201  | total loss: [1m[32m0.07838[0m[0m | time: 30.410s
[2K
| Adam | epoch: 019 | loss: 0.07838 - acc: 0.9718 -- iter: 096/348
[A[ATraining Step: 202  | total loss: [1m[32m0.07446[0m[0m | time: 39.076s
[2K
| Adam | epoch: 019 | loss: 0.07446 - acc: 0.9747 -- iter: 128/348
[A[ATraining Step: 203  | total loss: [1m[32m0.08096[0m[0m | time: 46.945s
[2K
| Adam | epoch: 019 | loss: 0.08096 - acc: 0.9678 -- iter: 160/348
[A[ATraining Step: 204  | total loss: [1m[32m0.07391[0m[0m | time: 54.596s
[2K
| Adam | epoch: 019 | loss: 0.07391 - acc: 0.9710 -- iter: 192/348
[A[ATraining Step: 205  | total loss: [1m[32m0.06763[0m[0m | time: 63.397s
[2K
| Adam | epoch: 019 | loss: 0.06763 - acc: 0.9739 -- iter: 224/348
[A[ATraining Step: 206  | total loss: [1m[32m0.06174[0m[0m | time: 71.816s
[2K
| Adam | epoch: 019 | loss: 0.06174 - acc: 0.9765 -- iter: 256/348
[A[ATraining Step: 207  | total loss: [1m[32m0.05666[0m[0m | time: 80.229s
[2K
| Adam | epoch: 019 | loss: 0.05666 - acc: 0.9789 -- iter: 288/348
[A[ATraining Step: 208  | total loss: [1m[32m0.06581[0m[0m | time: 88.615s
[2K
| Adam | epoch: 019 | loss: 0.06581 - acc: 0.9779 -- iter: 320/348
[A[ATraining Step: 209  | total loss: [1m[32m0.06056[0m[0m | time: 101.808s
[2K
| Adam | epoch: 019 | loss: 0.06056 - acc: 0.9801 | val_loss: 0.86748 - val_acc: 0.7339 -- iter: 348/348
--
Training Step: 210  | total loss: [1m[32m0.05826[0m[0m | time: 8.513s
[2K
| Adam | epoch: 020 | loss: 0.05826 - acc: 0.9821 -- iter: 032/348
[A[ATraining Step: 211  | total loss: [1m[32m0.05598[0m[0m | time: 16.865s
[2K
| Adam | epoch: 020 | loss: 0.05598 - acc: 0.9839 -- iter: 064/348
[A[ATraining Step: 212  | total loss: [1m[32m0.05118[0m[0m | time: 25.168s
[2K
| Adam | epoch: 020 | loss: 0.05118 - acc: 0.9855 -- iter: 096/348
[A[ATraining Step: 213  | total loss: [1m[32m0.04964[0m[0m | time: 33.663s
[2K
| Adam | epoch: 020 | loss: 0.04964 - acc: 0.9838 -- iter: 128/348
[A[ATraining Step: 214  | total loss: [1m[32m0.04513[0m[0m | time: 41.900s
[2K
| Adam | epoch: 020 | loss: 0.04513 - acc: 0.9854 -- iter: 160/348
[A[ATraining Step: 215  | total loss: [1m[32m0.04356[0m[0m | time: 49.434s
[2K
| Adam | epoch: 020 | loss: 0.04356 - acc: 0.9869 -- iter: 192/348
[A[ATraining Step: 216  | total loss: [1m[32m0.03954[0m[0m | time: 57.093s
[2K
| Adam | epoch: 020 | loss: 0.03954 - acc: 0.9882 -- iter: 224/348
[A[ATraining Step: 217  | total loss: [1m[32m0.03592[0m[0m | time: 65.465s
[2K
| Adam | epoch: 020 | loss: 0.03592 - acc: 0.9894 -- iter: 256/348
[A[ATraining Step: 218  | total loss: [1m[32m0.03377[0m[0m | time: 73.957s
[2K
| Adam | epoch: 020 | loss: 0.03377 - acc: 0.9904 -- iter: 288/348
[A[ATraining Step: 219  | total loss: [1m[32m0.03080[0m[0m | time: 82.482s
[2K
| Adam | epoch: 020 | loss: 0.03080 - acc: 0.9914 -- iter: 320/348
[A[ATraining Step: 220  | total loss: [1m[32m0.06799[0m[0m | time: 96.137s
[2K
| Adam | epoch: 020 | loss: 0.06799 - acc: 0.9860 | val_loss: 0.93091 - val_acc: 0.7523 -- iter: 348/348
--
Training Step: 221  | total loss: [1m[32m0.06258[0m[0m | time: 8.563s
[2K
| Adam | epoch: 021 | loss: 0.06258 - acc: 0.9874 -- iter: 032/348
[A[ATraining Step: 222  | total loss: [1m[32m0.05792[0m[0m | time: 17.063s
[2K
| Adam | epoch: 021 | loss: 0.05792 - acc: 0.9887 -- iter: 064/348
[A[ATraining Step: 223  | total loss: [1m[32m0.05417[0m[0m | time: 25.538s
[2K
| Adam | epoch: 021 | loss: 0.05417 - acc: 0.9898 -- iter: 096/348
[A[ATraining Step: 224  | total loss: [1m[32m0.05300[0m[0m | time: 33.973s
[2K
| Adam | epoch: 021 | loss: 0.05300 - acc: 0.9877 -- iter: 128/348
[A[ATraining Step: 225  | total loss: [1m[32m0.04842[0m[0m | time: 42.601s
[2K
| Adam | epoch: 021 | loss: 0.04842 - acc: 0.9889 -- iter: 160/348
[A[ATraining Step: 226  | total loss: [1m[32m0.05281[0m[0m | time: 50.783s
[2K
| Adam | epoch: 021 | loss: 0.05281 - acc: 0.9869 -- iter: 192/348
[A[ATraining Step: 227  | total loss: [1m[32m0.07010[0m[0m | time: 58.216s
[2K
| Adam | epoch: 021 | loss: 0.07010 - acc: 0.9851 -- iter: 224/348
[A[ATraining Step: 228  | total loss: [1m[32m0.08029[0m[0m | time: 65.863s
[2K
| Adam | epoch: 021 | loss: 0.08029 - acc: 0.9830 -- iter: 256/348
[A[ATraining Step: 229  | total loss: [1m[32m0.08649[0m[0m | time: 74.288s
[2K
| Adam | epoch: 021 | loss: 0.08649 - acc: 0.9811 -- iter: 288/348
[A[ATraining Step: 230  | total loss: [1m[32m0.07926[0m[0m | time: 82.808s
[2K
| Adam | epoch: 021 | loss: 0.07926 - acc: 0.9830 -- iter: 320/348
[A[ATraining Step: 231  | total loss: [1m[32m0.10190[0m[0m | time: 96.647s
[2K
| Adam | epoch: 021 | loss: 0.10190 - acc: 0.9753 | val_loss: 6.41307 - val_acc: 0.3761 -- iter: 348/348
--
Training Step: 232  | total loss: [1m[32m0.13553[0m[0m | time: 12.722s
[2K
| Adam | epoch: 022 | loss: 0.13553 - acc: 0.9716 -- iter: 032/348
[A[ATraining Step: 233  | total loss: [1m[32m0.12386[0m[0m | time: 23.451s
[2K
| Adam | epoch: 022 | loss: 0.12386 - acc: 0.9744 -- iter: 064/348
[A[ATraining Step: 234  | total loss: [1m[32m0.12448[0m[0m | time: 34.638s
[2K
| Adam | epoch: 022 | loss: 0.12448 - acc: 0.9738 -- iter: 096/348
[A[ATraining Step: 235  | total loss: [1m[32m0.11338[0m[0m | time: 45.410s
[2K
| Adam | epoch: 022 | loss: 0.11338 - acc: 0.9765 -- iter: 128/348
[A[ATraining Step: 236  | total loss: [1m[32m0.11391[0m[0m | time: 56.818s
[2K
| Adam | epoch: 022 | loss: 0.11391 - acc: 0.9757 -- iter: 160/348
[A[ATraining Step: 237  | total loss: [1m[32m0.12915[0m[0m | time: 67.295s
[2K
| Adam | epoch: 022 | loss: 0.12915 - acc: 0.9656 -- iter: 192/348
[A[ATraining Step: 238  | total loss: [1m[32m0.13385[0m[0m | time: 78.631s
[2K
| Adam | epoch: 022 | loss: 0.13385 - acc: 0.9628 -- iter: 224/348
[A[ATraining Step: 239  | total loss: [1m[32m0.13622[0m[0m | time: 88.409s
[2K
| Adam | epoch: 022 | loss: 0.13622 - acc: 0.9603 -- iter: 256/348
[A[ATraining Step: 240  | total loss: [1m[32m0.12698[0m[0m | time: 97.884s
[2K
| Adam | epoch: 022 | loss: 0.12698 - acc: 0.9642 -- iter: 288/348
[A[ATraining Step: 241  | total loss: [1m[32m0.11731[0m[0m | time: 109.031s
[2K
| Adam | epoch: 022 | loss: 0.11731 - acc: 0.9678 -- iter: 320/348
[A[ATraining Step: 242  | total loss: [1m[32m0.10778[0m[0m | time: 127.617s
[2K
| Adam | epoch: 022 | loss: 0.10778 - acc: 0.9710 | val_loss: 1.36498 - val_acc: 0.7706 -- iter: 348/348
--
Training Step: 243  | total loss: [1m[32m0.10390[0m[0m | time: 10.018s
[2K
| Adam | epoch: 023 | loss: 0.10390 - acc: 0.9708 -- iter: 032/348
[A[ATraining Step: 244  | total loss: [1m[32m0.10598[0m[0m | time: 20.934s
[2K
| Adam | epoch: 023 | loss: 0.10598 - acc: 0.9706 -- iter: 064/348
[A[ATraining Step: 245  | total loss: [1m[32m0.09939[0m[0m | time: 35.607s
[2K
| Adam | epoch: 023 | loss: 0.09939 - acc: 0.9735 -- iter: 096/348
[A[ATraining Step: 246  | total loss: [1m[32m0.09319[0m[0m | time: 45.854s
[2K
| Adam | epoch: 023 | loss: 0.09319 - acc: 0.9762 -- iter: 128/348
[A[ATraining Step: 247  | total loss: [1m[32m0.08684[0m[0m | time: 55.803s
[2K
| Adam | epoch: 023 | loss: 0.08684 - acc: 0.9786 -- iter: 160/348
[A[ATraining Step: 248  | total loss: [1m[32m0.08087[0m[0m | time: 65.934s
[2K
| Adam | epoch: 023 | loss: 0.08087 - acc: 0.9807 -- iter: 192/348
[A[ATraining Step: 249  | total loss: [1m[32m0.08802[0m[0m | time: 77.054s
[2K
| Adam | epoch: 023 | loss: 0.08802 - acc: 0.9795 -- iter: 224/348
[A[ATraining Step: 250  | total loss: [1m[32m0.08033[0m[0m | time: 87.219s
[2K
| Adam | epoch: 023 | loss: 0.08033 - acc: 0.9816 -- iter: 256/348
[A[ATraining Step: 251  | total loss: [1m[32m0.07296[0m[0m | time: 97.491s
[2K
| Adam | epoch: 023 | loss: 0.07296 - acc: 0.9834 -- iter: 288/348
[A[ATraining Step: 252  | total loss: [1m[32m0.06797[0m[0m | time: 106.999s
[2K
| Adam | epoch: 023 | loss: 0.06797 - acc: 0.9851 -- iter: 320/348
[A[ATraining Step: 253  | total loss: [1m[32m0.06325[0m[0m | time: 123.030s
[2K
| Adam | epoch: 023 | loss: 0.06325 - acc: 0.9866 | val_loss: 0.43974 - val_acc: 0.8257 -- iter: 348/348
--
Training Step: 254  | total loss: [1m[32m0.06577[0m[0m | time: 9.892s
[2K
| Adam | epoch: 024 | loss: 0.06577 - acc: 0.9848 -- iter: 032/348
[A[ATraining Step: 255  | total loss: [1m[32m0.05997[0m[0m | time: 20.557s
[2K
| Adam | epoch: 024 | loss: 0.05997 - acc: 0.9863 -- iter: 064/348
[A[ATraining Step: 256  | total loss: [1m[32m0.08922[0m[0m | time: 31.417s
[2K
| Adam | epoch: 024 | loss: 0.08922 - acc: 0.9814 -- iter: 096/348
[A[ATraining Step: 257  | total loss: [1m[32m0.08202[0m[0m | time: 41.262s
[2K
| Adam | epoch: 024 | loss: 0.08202 - acc: 0.9833 -- iter: 128/348
[A[ATraining Step: 258  | total loss: [1m[32m0.07431[0m[0m | time: 54.348s
[2K
| Adam | epoch: 024 | loss: 0.07431 - acc: 0.9850 -- iter: 160/348
[A[ATraining Step: 259  | total loss: [1m[32m0.06948[0m[0m | time: 65.367s
[2K
| Adam | epoch: 024 | loss: 0.06948 - acc: 0.9865 -- iter: 192/348
[A[ATraining Step: 260  | total loss: [1m[32m0.06517[0m[0m | time: 75.344s
[2K
| Adam | epoch: 024 | loss: 0.06517 - acc: 0.9878 -- iter: 224/348
[A[ATraining Step: 261  | total loss: [1m[32m0.06853[0m[0m | time: 85.740s
[2K
| Adam | epoch: 024 | loss: 0.06853 - acc: 0.9859 -- iter: 256/348
[A[ATraining Step: 262  | total loss: [1m[32m0.06710[0m[0m | time: 104.581s
[2K
| Adam | epoch: 024 | loss: 0.06710 - acc: 0.9842 -- iter: 288/348
[A[ATraining Step: 263  | total loss: [1m[32m0.06262[0m[0m | time: 114.233s
[2K
| Adam | epoch: 024 | loss: 0.06262 - acc: 0.9858 -- iter: 320/348
[A[ATraining Step: 264  | total loss: [1m[32m0.05953[0m[0m | time: 129.793s
[2K
| Adam | epoch: 024 | loss: 0.05953 - acc: 0.9872 | val_loss: 0.68211 - val_acc: 0.7706 -- iter: 348/348
--
Training Step: 265  | total loss: [1m[32m0.05495[0m[0m | time: 11.453s
[2K
| Adam | epoch: 025 | loss: 0.05495 - acc: 0.9885 -- iter: 032/348
[A[ATraining Step: 266  | total loss: [1m[32m0.05008[0m[0m | time: 26.217s
[2K
| Adam | epoch: 025 | loss: 0.05008 - acc: 0.9896 -- iter: 064/348
[A[ATraining Step: 267  | total loss: [1m[32m0.05123[0m[0m | time: 35.812s
[2K
| Adam | epoch: 025 | loss: 0.05123 - acc: 0.9875 -- iter: 096/348
[A[ATraining Step: 268  | total loss: [1m[32m0.04701[0m[0m | time: 51.922s
[2K
| Adam | epoch: 025 | loss: 0.04701 - acc: 0.9888 -- iter: 128/348
[A[ATraining Step: 269  | total loss: [1m[32m0.04447[0m[0m | time: 62.460s
[2K
| Adam | epoch: 025 | loss: 0.04447 - acc: 0.9899 -- iter: 160/348
[A[ATraining Step: 270  | total loss: [1m[32m0.04090[0m[0m | time: 72.972s
[2K
| Adam | epoch: 025 | loss: 0.04090 - acc: 0.9909 -- iter: 192/348
[A[ATraining Step: 271  | total loss: [1m[32m0.03728[0m[0m | time: 84.388s
[2K
| Adam | epoch: 025 | loss: 0.03728 - acc: 0.9918 -- iter: 224/348
[A[ATraining Step: 272  | total loss: [1m[32m0.03487[0m[0m | time: 97.660s
[2K
| Adam | epoch: 025 | loss: 0.03487 - acc: 0.9926 -- iter: 256/348
[A[ATraining Step: 273  | total loss: [1m[32m0.03182[0m[0m | time: 116.164s
[2K
| Adam | epoch: 025 | loss: 0.03182 - acc: 0.9934 -- iter: 288/348
[A[ATraining Step: 274  | total loss: [1m[32m0.03263[0m[0m | time: 126.913s
[2K
| Adam | epoch: 025 | loss: 0.03263 - acc: 0.9909 -- iter: 320/348
[A[ATraining Step: 275  | total loss: [1m[32m0.03039[0m[0m | time: 142.915s
[2K
| Adam | epoch: 025 | loss: 0.03039 - acc: 0.9918 | val_loss: 0.63132 - val_acc: 0.7890 -- iter: 348/348
--
Training Step: 276  | total loss: [1m[32m0.02760[0m[0m | time: 10.278s
[2K
| Adam | epoch: 026 | loss: 0.02760 - acc: 0.9926 -- iter: 032/348
[A[ATraining Step: 277  | total loss: [1m[32m0.02512[0m[0m | time: 19.635s
[2K
| Adam | epoch: 026 | loss: 0.02512 - acc: 0.9934 -- iter: 064/348
[A[ATraining Step: 278  | total loss: [1m[32m0.02305[0m[0m | time: 32.451s
[2K
| Adam | epoch: 026 | loss: 0.02305 - acc: 0.9940 -- iter: 096/348
[A[ATraining Step: 279  | total loss: [1m[32m0.02108[0m[0m | time: 43.109s
[2K
| Adam | epoch: 026 | loss: 0.02108 - acc: 0.9946 -- iter: 128/348
[A[ATraining Step: 280  | total loss: [1m[32m0.03881[0m[0m | time: 53.033s
[2K
| Adam | epoch: 026 | loss: 0.03881 - acc: 0.9920 -- iter: 160/348
[A[ATraining Step: 281  | total loss: [1m[32m0.03507[0m[0m | time: 65.285s
[2K
| Adam | epoch: 026 | loss: 0.03507 - acc: 0.9928 -- iter: 192/348
[A[ATraining Step: 282  | total loss: [1m[32m0.03187[0m[0m | time: 75.073s
[2K
| Adam | epoch: 026 | loss: 0.03187 - acc: 0.9936 -- iter: 224/348
[A[ATraining Step: 283  | total loss: [1m[32m0.02906[0m[0m | time: 85.640s
[2K
| Adam | epoch: 026 | loss: 0.02906 - acc: 0.9942 -- iter: 256/348
[A[ATraining Step: 284  | total loss: [1m[32m0.02668[0m[0m | time: 95.498s
[2K
| Adam | epoch: 026 | loss: 0.02668 - acc: 0.9948 -- iter: 288/348
[A[ATraining Step: 285  | total loss: [1m[32m0.02516[0m[0m | time: 106.025s
[2K
| Adam | epoch: 026 | loss: 0.02516 - acc: 0.9953 -- iter: 320/348
[A[ATraining Step: 286  | total loss: [1m[32m0.02290[0m[0m | time: 127.290s
[2K
| Adam | epoch: 026 | loss: 0.02290 - acc: 0.9958 | val_loss: 0.57639 - val_acc: 0.8073 -- iter: 348/348
--
Training Step: 287  | total loss: [1m[32m0.02091[0m[0m | time: 9.461s
[2K
| Adam | epoch: 027 | loss: 0.02091 - acc: 0.9962 -- iter: 032/348
[A[ATraining Step: 288  | total loss: [1m[32m0.01926[0m[0m | time: 19.142s
[2K
| Adam | epoch: 027 | loss: 0.01926 - acc: 0.9966 -- iter: 064/348
[A[ATraining Step: 289  | total loss: [1m[32m0.01774[0m[0m | time: 30.138s
[2K
| Adam | epoch: 027 | loss: 0.01774 - acc: 0.9969 -- iter: 096/348
[A[ATraining Step: 290  | total loss: [1m[32m0.01902[0m[0m | time: 40.729s
[2K
| Adam | epoch: 027 | loss: 0.01902 - acc: 0.9941 -- iter: 128/348
[A[ATraining Step: 291  | total loss: [1m[32m0.02211[0m[0m | time: 50.449s
[2K
| Adam | epoch: 027 | loss: 0.02211 - acc: 0.9916 -- iter: 160/348
[A[ATraining Step: 292  | total loss: [1m[32m0.02781[0m[0m | time: 62.232s
[2K
| Adam | epoch: 027 | loss: 0.02781 - acc: 0.9893 -- iter: 192/348
[A[ATraining Step: 293  | total loss: [1m[32m0.02820[0m[0m | time: 72.649s
[2K
| Adam | epoch: 027 | loss: 0.02820 - acc: 0.9904 -- iter: 224/348
[A[ATraining Step: 294  | total loss: [1m[32m0.02557[0m[0m | time: 82.485s
[2K
| Adam | epoch: 027 | loss: 0.02557 - acc: 0.9913 -- iter: 256/348
[A[ATraining Step: 295  | total loss: [1m[32m0.02633[0m[0m | time: 93.047s
[2K
| Adam | epoch: 027 | loss: 0.02633 - acc: 0.9922 -- iter: 288/348
[A[ATraining Step: 296  | total loss: [1m[32m0.02526[0m[0m | time: 103.558s
[2K
| Adam | epoch: 027 | loss: 0.02526 - acc: 0.9930 -- iter: 320/348
[A[ATraining Step: 297  | total loss: [1m[32m0.02285[0m[0m | time: 122.667s
[2K
| Adam | epoch: 027 | loss: 0.02285 - acc: 0.9937 | val_loss: 0.95568 - val_acc: 0.7248 -- iter: 348/348
--
Training Step: 298  | total loss: [1m[32m0.02373[0m[0m | time: 9.756s
[2K
| Adam | epoch: 028 | loss: 0.02373 - acc: 0.9912 -- iter: 032/348
[A[ATraining Step: 299  | total loss: [1m[32m0.02172[0m[0m | time: 20.040s
[2K
| Adam | epoch: 028 | loss: 0.02172 - acc: 0.9921 -- iter: 064/348
[A[ATraining Step: 300  | total loss: [1m[32m0.04040[0m[0m | time: 30.308s
[2K
| Adam | epoch: 028 | loss: 0.04040 - acc: 0.9821 -- iter: 096/348
[A[ATraining Step: 301  | total loss: [1m[32m0.03866[0m[0m | time: 40.939s
[2K
| Adam | epoch: 028 | loss: 0.03866 - acc: 0.9839 -- iter: 128/348
[A[ATraining Step: 302  | total loss: [1m[32m0.03580[0m[0m | time: 52.139s
[2K
| Adam | epoch: 028 | loss: 0.03580 - acc: 0.9855 -- iter: 160/348
[A[ATraining Step: 303  | total loss: [1m[32m0.03313[0m[0m | time: 62.948s
[2K
| Adam | epoch: 028 | loss: 0.03313 - acc: 0.9870 -- iter: 192/348
[A[ATraining Step: 304  | total loss: [1m[32m0.08991[0m[0m | time: 72.783s
[2K
| Adam | epoch: 028 | loss: 0.08991 - acc: 0.9820 -- iter: 224/348
[A[ATraining Step: 305  | total loss: [1m[32m0.08600[0m[0m | time: 84.426s
[2K
| Adam | epoch: 028 | loss: 0.08600 - acc: 0.9807 -- iter: 256/348
[A[ATraining Step: 306  | total loss: [1m[32m0.08975[0m[0m | time: 94.997s
[2K
| Adam | epoch: 028 | loss: 0.08975 - acc: 0.9795 -- iter: 288/348
[A[ATraining Step: 307  | total loss: [1m[32m0.08149[0m[0m | time: 105.824s
[2K
| Adam | epoch: 028 | loss: 0.08149 - acc: 0.9816 -- iter: 320/348
[A[ATraining Step: 308  | total loss: [1m[32m0.07448[0m[0m | time: 123.067s
[2K
| Adam | epoch: 028 | loss: 0.07448 - acc: 0.9834 | val_loss: 0.86778 - val_acc: 0.8532 -- iter: 348/348
--
Training Step: 309  | total loss: [1m[32m0.07278[0m[0m | time: 13.641s
[2K
| Adam | epoch: 029 | loss: 0.07278 - acc: 0.9819 -- iter: 032/348
[A[ATraining Step: 310  | total loss: [1m[32m0.07094[0m[0m | time: 22.224s
[2K
| Adam | epoch: 029 | loss: 0.07094 - acc: 0.9806 -- iter: 064/348
[A[ATraining Step: 311  | total loss: [1m[32m0.06454[0m[0m | time: 29.784s
[2K
| Adam | epoch: 029 | loss: 0.06454 - acc: 0.9826 -- iter: 096/348
[A[ATraining Step: 312  | total loss: [1m[32m0.05860[0m[0m | time: 37.440s
[2K
| Adam | epoch: 029 | loss: 0.05860 - acc: 0.9843 -- iter: 128/348
[A[ATraining Step: 313  | total loss: [1m[32m0.05312[0m[0m | time: 45.947s
[2K
| Adam | epoch: 029 | loss: 0.05312 - acc: 0.9859 -- iter: 160/348
[A[ATraining Step: 314  | total loss: [1m[32m0.05346[0m[0m | time: 54.484s
[2K
| Adam | epoch: 029 | loss: 0.05346 - acc: 0.9842 -- iter: 192/348
[A[ATraining Step: 315  | total loss: [1m[32m0.05424[0m[0m | time: 63.176s
[2K
| Adam | epoch: 029 | loss: 0.05424 - acc: 0.9826 -- iter: 224/348
[A[ATraining Step: 316  | total loss: [1m[32m0.18185[0m[0m | time: 71.534s
[2K
| Adam | epoch: 029 | loss: 0.18185 - acc: 0.9656 -- iter: 256/348
[A[ATraining Step: 317  | total loss: [1m[32m0.16418[0m[0m | time: 80.045s
[2K
| Adam | epoch: 029 | loss: 0.16418 - acc: 0.9690 -- iter: 288/348
[A[ATraining Step: 318  | total loss: [1m[32m0.14865[0m[0m | time: 88.696s
[2K
| Adam | epoch: 029 | loss: 0.14865 - acc: 0.9721 -- iter: 320/348
[A[ATraining Step: 319  | total loss: [1m[32m0.13432[0m[0m | time: 101.977s
[2K
| Adam | epoch: 029 | loss: 0.13432 - acc: 0.9749 | val_loss: 0.90841 - val_acc: 0.8257 -- iter: 348/348
--
Training Step: 320  | total loss: [1m[32m0.12869[0m[0m | time: 8.522s
[2K
| Adam | epoch: 030 | loss: 0.12869 - acc: 0.9743 -- iter: 032/348
[A[ATraining Step: 321  | total loss: [1m[32m0.11753[0m[0m | time: 16.842s
[2K
| Adam | epoch: 030 | loss: 0.11753 - acc: 0.9769 -- iter: 064/348
[A[ATraining Step: 322  | total loss: [1m[32m0.10715[0m[0m | time: 25.183s
[2K
| Adam | epoch: 030 | loss: 0.10715 - acc: 0.9792 -- iter: 096/348
[A[ATraining Step: 323  | total loss: [1m[32m0.09987[0m[0m | time: 32.598s
[2K
| Adam | epoch: 030 | loss: 0.09987 - acc: 0.9813 -- iter: 128/348
[A[ATraining Step: 324  | total loss: [1m[32m0.09897[0m[0m | time: 40.414s
[2K
| Adam | epoch: 030 | loss: 0.09897 - acc: 0.9796 -- iter: 160/348
[A[ATraining Step: 325  | total loss: [1m[32m0.09484[0m[0m | time: 48.782s
[2K
| Adam | epoch: 030 | loss: 0.09484 - acc: 0.9780 -- iter: 192/348
[A[ATraining Step: 326  | total loss: [1m[32m0.09064[0m[0m | time: 57.367s
[2K
| Adam | epoch: 030 | loss: 0.09064 - acc: 0.9771 -- iter: 224/348
[A[ATraining Step: 327  | total loss: [1m[32m0.09104[0m[0m | time: 65.623s
[2K
| Adam | epoch: 030 | loss: 0.09104 - acc: 0.9763 -- iter: 256/348
[A[ATraining Step: 328  | total loss: [1m[32m0.13742[0m[0m | time: 73.785s
[2K
| Adam | epoch: 030 | loss: 0.13742 - acc: 0.9693 -- iter: 288/348
[A[ATraining Step: 329  | total loss: [1m[32m0.13443[0m[0m | time: 82.086s
[2K
| Adam | epoch: 030 | loss: 0.13443 - acc: 0.9692 -- iter: 320/348
[A[ATraining Step: 330  | total loss: [1m[32m0.13388[0m[0m | time: 95.641s
[2K
| Adam | epoch: 030 | loss: 0.13388 - acc: 0.9629 | val_loss: 0.44473 - val_acc: 0.8073 -- iter: 348/348
--
Validation AUC:0.9307747489239598
Validation AUPRC:0.9560622949246431
Test AUC:0.9361702127659575
Test AUPRC:0.9390760495462597
BestTestF1Score	0.9	0.75	0.87	0.82	0.98	61	13	34	1	0.1
BestTestMCCScore	0.9	0.75	0.87	0.82	0.98	61	13	34	1	0.1
BestTestAccuracyScore	0.9	0.75	0.87	0.82	0.98	61	13	34	1	0.1
BestValidationF1Score	0.91	0.76	0.89	0.89	0.94	64	8	33	4	0.1
BestValidationMCC	0.91	0.76	0.89	0.89	0.94	64	8	33	4	0.1
BestValidationAccuracy	0.91	0.76	0.89	0.89	0.94	64	8	33	4	0.1
TestPredictions (Threshold:0.1)
CHEMBL3686388,TP,ACT,1.0	CHEMBL2323693,TP,ACT,0.9700000286102295	CHEMBL1097907,FP,INACT,0.9900000095367432	CHEMBL2403781,TN,INACT,0.07999999821186066	CHEMBL3695162,TP,ACT,0.9700000286102295	CHEMBL3125459,TP,ACT,0.949999988079071	CHEMBL3695169,TP,ACT,0.8399999737739563	CHEMBL3690891,TP,ACT,1.0	CHEMBL1782370,TP,ACT,0.9200000166893005	CHEMBL3398507,TN,INACT,0.009999999776482582	CHEMBL3686455,TP,ACT,1.0	CHEMBL2323691,TP,ACT,0.9900000095367432	CHEMBL3686374,TP,ACT,1.0	CHEMBL2159102,TP,ACT,0.9700000286102295	CHEMBL308528,TN,INACT,0.0	CHEMBL1819491,TP,ACT,0.949999988079071	CHEMBL592589,TN,INACT,0.019999999552965164	CHEMBL3690925,TP,ACT,0.9900000095367432	CHEMBL2048490,TN,INACT,0.05999999865889549	CHEMBL1917044,FP,INACT,0.4699999988079071	CHEMBL3695108,TP,ACT,1.0	CHEMBL2172379,TP,ACT,0.6399999856948853	CHEMBL1091948,FP,INACT,0.12999999523162842	CHEMBL470499,FP,INACT,0.10999999940395355	CHEMBL3690908,TP,ACT,1.0	CHEMBL3695168,TP,ACT,0.9900000095367432	CHEMBL3690930,TP,ACT,0.9900000095367432	CHEMBL2414169,TN,INACT,0.009999999776482582	CHEMBL2414186,TN,INACT,0.009999999776482582	CHEMBL3691006,TP,ACT,1.0	CHEMBL2064102,FN,ACT,0.05999999865889549	CHEMBL3686469,TP,ACT,1.0	CHEMBL3686471,TP,ACT,1.0	CHEMBL1779345,FP,INACT,0.6800000071525574	CHEMBL3289586,TN,INACT,0.0	CHEMBL3695161,TP,ACT,0.49000000953674316	CHEMBL206724,TP,ACT,0.8199999928474426	CHEMBL3125149,TP,ACT,0.7699999809265137	CHEMBL1093013,FP,INACT,0.8299999833106995	CHEMBL3654332,TP,ACT,0.8999999761581421	CHEMBL3690986,TP,ACT,1.0	CHEMBL2064094,TN,INACT,0.009999999776482582	CHEMBL2440381,TN,INACT,0.029999999329447746	CHEMBL3690845,TP,ACT,1.0	CHEMBL450681,TN,INACT,0.09000000357627869	CHEMBL3695164,TP,ACT,1.0	CHEMBL3289569,TN,INACT,0.0	CHEMBL1817688,FP,INACT,0.47999998927116394	CHEMBL3775725,TN,INACT,0.0	CHEMBL518689,FP,INACT,1.0	CHEMBL3785254,TP,ACT,0.15000000596046448	CHEMBL3695088,TP,ACT,0.9800000190734863	CHEMBL3686370,TP,ACT,0.9700000286102295	CHEMBL3695177,TP,ACT,0.9599999785423279	CHEMBL3289293,TN,INACT,0.0	CHEMBL3686474,TP,ACT,0.9900000095367432	CHEMBL2387673,FP,INACT,0.11999999731779099	CHEMBL473113,TN,INACT,0.019999999552965164	CHEMBL1209421,TN,INACT,0.0	CHEMBL472577,TN,INACT,0.05000000074505806	CHEMBL585021,TP,ACT,0.800000011920929	CHEMBL1093777,TP,ACT,0.7900000214576721	CHEMBL2064099,TP,ACT,0.5799999833106995	CHEMBL3695081,TP,ACT,1.0	CHEMBL2172491,TP,ACT,0.11999999731779099	CHEMBL3289587,TN,INACT,0.0	CHEMBL3690938,TP,ACT,0.949999988079071	CHEMBL3686480,TP,ACT,0.9100000262260437	CHEMBL3690870,TP,ACT,0.9399999976158142	CHEMBL3288737,TN,INACT,0.009999999776482582	CHEMBL3690854,TP,ACT,0.9300000071525574	CHEMBL567058,FP,INACT,0.9700000286102295	CHEMBL3695077,TP,ACT,0.9900000095367432	CHEMBL3774505,TN,INACT,0.019999999552965164	CHEMBL1917032,TN,INACT,0.0	CHEMBL382293,TP,ACT,0.27000001072883606	CHEMBL2303982,TN,INACT,0.019999999552965164	CHEMBL3690894,TP,ACT,0.9900000095367432	CHEMBL3775938,TN,INACT,0.019999999552965164	CHEMBL3695079,TP,ACT,0.8399999737739563	CHEMBL3686489,TP,ACT,1.0	CHEMBL2303990,FP,INACT,0.20999999344348907	CHEMBL3690832,TP,ACT,1.0	CHEMBL3686442,TP,ACT,0.9900000095367432	CHEMBL1808389,TP,ACT,0.3799999952316284	CHEMBL3691021,TP,ACT,0.9900000095367432	CHEMBL3289567,TN,INACT,0.009999999776482582	CHEMBL2172382,TN,INACT,0.09000000357627869	CHEMBL538322,FP,INACT,0.4300000071525574	CHEMBL2387679,TN,INACT,0.019999999552965164	CHEMBL2414178,TN,INACT,0.0	CHEMBL473117,TN,INACT,0.009999999776482582	CHEMBL3695090,TP,ACT,0.4000000059604645	CHEMBL2414173,TN,INACT,0.0	CHEMBL1807547,TP,ACT,1.0	CHEMBL2414182,TN,INACT,0.0	CHEMBL3695196,TP,ACT,0.8199999928474426	CHEMBL3691018,TP,ACT,0.9900000095367432	CHEMBL3775673,TN,INACT,0.019999999552965164	CHEMBL2440365,TN,INACT,0.029999999329447746	CHEMBL1135,TN,INACT,0.009999999776482582	CHEMBL3695129,TP,ACT,0.4000000059604645	CHEMBL3695184,TP,ACT,1.0	CHEMBL45068,TN,INACT,0.07999999821186066	CHEMBL2303994,FP,INACT,0.33000001311302185	CHEMBL3654331,TP,ACT,0.10000000149011612	CHEMBL3686457,TP,ACT,0.9800000190734863	CHEMBL2159432,TP,ACT,0.949999988079071	CHEMBL3690926,TP,ACT,0.9900000095367432	

