CNNModel CHEMBL258 RMSprop 0.001 30 32 0 0.6 False True
Number of active compounds :	1394
Number of inactive compounds :	1394
---------------------------------
Run id: CNNModel_CHEMBL258_RMSprop_0.001_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL258_RMSprop_0.001_30_32_0.6_True/
---------------------------------
Training samples: 1707
Validation samples: 534
--
Training Step: 1  | time: 1.196s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1707
[A[ATraining Step: 2  | total loss: [1m[32m0.62383[0m[0m | time: 2.163s
[2K
| RMSProp | epoch: 001 | loss: 0.62383 - acc: 0.5062 -- iter: 0064/1707
[A[ATraining Step: 3  | total loss: [1m[32m0.68031[0m[0m | time: 3.132s
[2K
| RMSProp | epoch: 001 | loss: 0.68031 - acc: 0.6801 -- iter: 0096/1707
[A[ATraining Step: 4  | total loss: [1m[32m0.68994[0m[0m | time: 4.121s
[2K
| RMSProp | epoch: 001 | loss: 0.68994 - acc: 0.5685 -- iter: 0128/1707
[A[ATraining Step: 5  | total loss: [1m[32m0.69211[0m[0m | time: 5.117s
[2K
| RMSProp | epoch: 001 | loss: 0.69211 - acc: 0.5643 -- iter: 0160/1707
[A[ATraining Step: 6  | total loss: [1m[32m0.69283[0m[0m | time: 5.996s
[2K
| RMSProp | epoch: 001 | loss: 0.69283 - acc: 0.5230 -- iter: 0192/1707
[A[ATraining Step: 7  | total loss: [1m[32m0.69300[0m[0m | time: 7.006s
[2K
| RMSProp | epoch: 001 | loss: 0.69300 - acc: 0.5092 -- iter: 0224/1707
[A[ATraining Step: 8  | total loss: [1m[32m0.69308[0m[0m | time: 8.045s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.4689 -- iter: 0256/1707
[A[ATraining Step: 9  | total loss: [1m[32m0.69305[0m[0m | time: 9.182s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5681 -- iter: 0288/1707
[A[ATraining Step: 10  | total loss: [1m[32m0.69307[0m[0m | time: 10.012s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5340 -- iter: 0320/1707
[A[ATraining Step: 11  | total loss: [1m[32m0.69305[0m[0m | time: 10.977s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5623 -- iter: 0352/1707
[A[ATraining Step: 12  | total loss: [1m[32m0.69311[0m[0m | time: 11.959s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.4921 -- iter: 0384/1707
[A[ATraining Step: 13  | total loss: [1m[32m0.69314[0m[0m | time: 12.880s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5089 -- iter: 0416/1707
[A[ATraining Step: 14  | total loss: [1m[32m0.69305[0m[0m | time: 13.865s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5436 -- iter: 0448/1707
[A[ATraining Step: 15  | total loss: [1m[32m0.69305[0m[0m | time: 14.928s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5388 -- iter: 0480/1707
[A[ATraining Step: 16  | total loss: [1m[32m0.69313[0m[0m | time: 15.891s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4656 -- iter: 0512/1707
[A[ATraining Step: 17  | total loss: [1m[32m0.69314[0m[0m | time: 16.818s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.4780 -- iter: 0544/1707
[A[ATraining Step: 18  | total loss: [1m[32m0.69317[0m[0m | time: 17.899s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4532 -- iter: 0576/1707
[A[ATraining Step: 19  | total loss: [1m[32m0.69326[0m[0m | time: 18.965s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.4479 -- iter: 0608/1707
[A[ATraining Step: 20  | total loss: [1m[32m0.69321[0m[0m | time: 19.857s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4948 -- iter: 0640/1707
[A[ATraining Step: 21  | total loss: [1m[32m0.69319[0m[0m | time: 20.747s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4867 -- iter: 0672/1707
[A[ATraining Step: 22  | total loss: [1m[32m0.69325[0m[0m | time: 21.732s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4438 -- iter: 0704/1707
[A[ATraining Step: 23  | total loss: [1m[32m0.69323[0m[0m | time: 22.738s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4511 -- iter: 0736/1707
[A[ATraining Step: 24  | total loss: [1m[32m0.69313[0m[0m | time: 23.706s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5088 -- iter: 0768/1707
[A[ATraining Step: 25  | total loss: [1m[32m0.69314[0m[0m | time: 24.699s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5064 -- iter: 0800/1707
[A[ATraining Step: 26  | total loss: [1m[32m0.69318[0m[0m | time: 25.722s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5295 -- iter: 0832/1707
[A[ATraining Step: 27  | total loss: [1m[32m0.69317[0m[0m | time: 26.647s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5219 -- iter: 0864/1707
[A[ATraining Step: 28  | total loss: [1m[32m0.69315[0m[0m | time: 27.692s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.5321 -- iter: 0896/1707
[A[ATraining Step: 29  | total loss: [1m[32m0.69319[0m[0m | time: 28.796s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4939 -- iter: 0928/1707
[A[ATraining Step: 30  | total loss: [1m[32m0.69323[0m[0m | time: 29.711s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4731 -- iter: 0960/1707
[A[ATraining Step: 31  | total loss: [1m[32m0.69324[0m[0m | time: 30.551s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4505 -- iter: 0992/1707
[A[ATraining Step: 32  | total loss: [1m[32m0.69325[0m[0m | time: 31.580s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4616 -- iter: 1024/1707
[A[ATraining Step: 33  | total loss: [1m[32m0.69319[0m[0m | time: 32.469s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.5043 -- iter: 1056/1707
[A[ATraining Step: 34  | total loss: [1m[32m0.69321[0m[0m | time: 33.424s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4967 -- iter: 1088/1707
[A[ATraining Step: 35  | total loss: [1m[32m0.69323[0m[0m | time: 34.455s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4843 -- iter: 1120/1707
[A[ATraining Step: 36  | total loss: [1m[32m0.69324[0m[0m | time: 35.440s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4684 -- iter: 1152/1707
[A[ATraining Step: 37  | total loss: [1m[32m0.69320[0m[0m | time: 36.300s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4809 -- iter: 1184/1707
[A[ATraining Step: 38  | total loss: [1m[32m0.69316[0m[0m | time: 37.379s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4969 -- iter: 1216/1707
[A[ATraining Step: 39  | total loss: [1m[32m0.69317[0m[0m | time: 38.475s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4975 -- iter: 1248/1707
[A[ATraining Step: 40  | total loss: [1m[32m0.69324[0m[0m | time: 39.485s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4862 -- iter: 1280/1707
[A[ATraining Step: 41  | total loss: [1m[32m0.69322[0m[0m | time: 40.312s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4888 -- iter: 1312/1707
[A[ATraining Step: 42  | total loss: [1m[32m0.69325[0m[0m | time: 41.260s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4458 -- iter: 1344/1707
[A[ATraining Step: 43  | total loss: [1m[32m0.69321[0m[0m | time: 42.248s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4664 -- iter: 1376/1707
[A[ATraining Step: 44  | total loss: [1m[32m0.69319[0m[0m | time: 43.323s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4722 -- iter: 1408/1707
[A[ATraining Step: 45  | total loss: [1m[32m0.69321[0m[0m | time: 44.345s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4504 -- iter: 1440/1707
[A[ATraining Step: 46  | total loss: [1m[32m0.69320[0m[0m | time: 45.393s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4639 -- iter: 1472/1707
[A[ATraining Step: 47  | total loss: [1m[32m0.69317[0m[0m | time: 46.271s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4800 -- iter: 1504/1707
[A[ATraining Step: 48  | total loss: [1m[32m0.69324[0m[0m | time: 47.232s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4631 -- iter: 1536/1707
[A[ATraining Step: 49  | total loss: [1m[32m0.69319[0m[0m | time: 48.341s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4788 -- iter: 1568/1707
[A[ATraining Step: 50  | total loss: [1m[32m0.69323[0m[0m | time: 49.377s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4724 -- iter: 1600/1707
[A[ATraining Step: 51  | total loss: [1m[32m0.69323[0m[0m | time: 50.177s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4719 -- iter: 1632/1707
[A[ATraining Step: 52  | total loss: [1m[32m0.69319[0m[0m | time: 51.068s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4854 -- iter: 1664/1707
[A[ATraining Step: 53  | total loss: [1m[32m0.69326[0m[0m | time: 52.017s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.4645 -- iter: 1696/1707
[A[ATraining Step: 54  | total loss: [1m[32m0.69322[0m[0m | time: 55.150s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4833 | val_loss: 0.69341 - val_acc: 0.4476 -- iter: 1707/1707
--
Training Step: 55  | total loss: [1m[32m0.69318[0m[0m | time: 0.326s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4792 -- iter: 0032/1707
[A[ATraining Step: 56  | total loss: [1m[32m0.69311[0m[0m | time: 1.410s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5013 -- iter: 0064/1707
[A[ATraining Step: 57  | total loss: [1m[32m0.69337[0m[0m | time: 2.518s
[2K
| RMSProp | epoch: 002 | loss: 0.69337 - acc: 0.4708 -- iter: 0096/1707
[A[ATraining Step: 58  | total loss: [1m[32m0.69334[0m[0m | time: 3.503s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4833 -- iter: 0128/1707
[A[ATraining Step: 59  | total loss: [1m[32m0.69331[0m[0m | time: 4.381s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4772 -- iter: 0160/1707
[A[ATraining Step: 60  | total loss: [1m[32m0.69331[0m[0m | time: 5.288s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4719 -- iter: 0192/1707
[A[ATraining Step: 61  | total loss: [1m[32m0.69331[0m[0m | time: 6.259s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4593 -- iter: 0224/1707
[A[ATraining Step: 62  | total loss: [1m[32m0.69332[0m[0m | time: 7.207s
[2K
| RMSProp | epoch: 002 | loss: 0.69332 - acc: 0.4484 -- iter: 0256/1707
[A[ATraining Step: 63  | total loss: [1m[32m0.69328[0m[0m | time: 8.281s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4550 -- iter: 0288/1707
[A[ATraining Step: 64  | total loss: [1m[32m0.69322[0m[0m | time: 9.282s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4723 -- iter: 0320/1707
[A[ATraining Step: 65  | total loss: [1m[32m0.69314[0m[0m | time: 10.140s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4873 -- iter: 0352/1707
[A[ATraining Step: 66  | total loss: [1m[32m0.69305[0m[0m | time: 11.021s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5002 -- iter: 0384/1707
[A[ATraining Step: 67  | total loss: [1m[32m0.69320[0m[0m | time: 12.079s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4890 -- iter: 0416/1707
[A[ATraining Step: 68  | total loss: [1m[32m0.69310[0m[0m | time: 13.170s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.4977 -- iter: 0448/1707
[A[ATraining Step: 69  | total loss: [1m[32m0.69319[0m[0m | time: 13.995s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4906 -- iter: 0480/1707
[A[ATraining Step: 70  | total loss: [1m[32m0.69325[0m[0m | time: 14.912s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4845 -- iter: 0512/1707
[A[ATraining Step: 71  | total loss: [1m[32m0.69328[0m[0m | time: 15.865s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4792 -- iter: 0544/1707
[A[ATraining Step: 72  | total loss: [1m[32m0.69328[0m[0m | time: 16.716s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4780 -- iter: 0576/1707
[A[ATraining Step: 73  | total loss: [1m[32m0.69327[0m[0m | time: 17.709s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4735 -- iter: 0608/1707
[A[ATraining Step: 74  | total loss: [1m[32m0.69324[0m[0m | time: 18.786s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4798 -- iter: 0640/1707
[A[ATraining Step: 75  | total loss: [1m[32m0.69326[0m[0m | time: 19.794s
[2K
| RMSProp | epoch: 002 | loss: 0.69326 - acc: 0.4752 -- iter: 0672/1707
[A[ATraining Step: 76  | total loss: [1m[32m0.69325[0m[0m | time: 20.673s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4812 -- iter: 0704/1707
[A[ATraining Step: 77  | total loss: [1m[32m0.69326[0m[0m | time: 21.810s
[2K
| RMSProp | epoch: 002 | loss: 0.69326 - acc: 0.4700 -- iter: 0736/1707
[A[ATraining Step: 78  | total loss: [1m[32m0.69319[0m[0m | time: 22.908s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4895 -- iter: 0768/1707
[A[ATraining Step: 79  | total loss: [1m[32m0.69299[0m[0m | time: 23.750s
[2K
| RMSProp | epoch: 002 | loss: 0.69299 - acc: 0.5100 -- iter: 0800/1707
[A[ATraining Step: 80  | total loss: [1m[32m0.69296[0m[0m | time: 24.636s
[2K
| RMSProp | epoch: 002 | loss: 0.69296 - acc: 0.5121 -- iter: 0832/1707
[A[ATraining Step: 81  | total loss: [1m[32m0.69294[0m[0m | time: 25.542s
[2K
| RMSProp | epoch: 002 | loss: 0.69294 - acc: 0.5141 -- iter: 0864/1707
[A[ATraining Step: 82  | total loss: [1m[32m0.69266[0m[0m | time: 26.439s
[2K
| RMSProp | epoch: 002 | loss: 0.69266 - acc: 0.5283 -- iter: 0896/1707
[A[ATraining Step: 83  | total loss: [1m[32m0.69246[0m[0m | time: 27.371s
[2K
| RMSProp | epoch: 002 | loss: 0.69246 - acc: 0.5348 -- iter: 0928/1707
[A[ATraining Step: 84  | total loss: [1m[32m0.69207[0m[0m | time: 28.365s
[2K
| RMSProp | epoch: 002 | loss: 0.69207 - acc: 0.5470 -- iter: 0960/1707
[A[ATraining Step: 85  | total loss: [1m[32m0.69238[0m[0m | time: 29.354s
[2K
| RMSProp | epoch: 002 | loss: 0.69238 - acc: 0.5360 -- iter: 0992/1707
[A[ATraining Step: 86  | total loss: [1m[32m0.69269[0m[0m | time: 30.245s
[2K
| RMSProp | epoch: 002 | loss: 0.69269 - acc: 0.5262 -- iter: 1024/1707
[A[ATraining Step: 87  | total loss: [1m[32m0.69276[0m[0m | time: 31.176s
[2K
| RMSProp | epoch: 002 | loss: 0.69276 - acc: 0.5236 -- iter: 1056/1707
[A[ATraining Step: 88  | total loss: [1m[32m0.69283[0m[0m | time: 31.960s
[2K
| RMSProp | epoch: 002 | loss: 0.69283 - acc: 0.5212 -- iter: 1088/1707
[A[ATraining Step: 89  | total loss: [1m[32m0.69288[0m[0m | time: 32.752s
[2K
| RMSProp | epoch: 002 | loss: 0.69288 - acc: 0.5191 -- iter: 1120/1707
[A[ATraining Step: 90  | total loss: [1m[32m0.69283[0m[0m | time: 33.577s
[2K
| RMSProp | epoch: 002 | loss: 0.69283 - acc: 0.5203 -- iter: 1152/1707
[A[ATraining Step: 91  | total loss: [1m[32m0.69251[0m[0m | time: 34.608s
[2K
| RMSProp | epoch: 002 | loss: 0.69251 - acc: 0.5308 -- iter: 1184/1707
[A[ATraining Step: 92  | total loss: [1m[32m0.69296[0m[0m | time: 35.638s
[2K
| RMSProp | epoch: 002 | loss: 0.69296 - acc: 0.5183 -- iter: 1216/1707
[A[ATraining Step: 93  | total loss: [1m[32m0.69292[0m[0m | time: 36.703s
[2K
| RMSProp | epoch: 002 | loss: 0.69292 - acc: 0.5196 -- iter: 1248/1707
[A[ATraining Step: 94  | total loss: [1m[32m0.69324[0m[0m | time: 37.770s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.5083 -- iter: 1280/1707
[A[ATraining Step: 95  | total loss: [1m[32m0.69346[0m[0m | time: 38.789s
[2K
| RMSProp | epoch: 002 | loss: 0.69346 - acc: 0.4981 -- iter: 1312/1707
[A[ATraining Step: 96  | total loss: [1m[32m0.69344[0m[0m | time: 39.632s
[2K
| RMSProp | epoch: 002 | loss: 0.69344 - acc: 0.4983 -- iter: 1344/1707
[A[ATraining Step: 97  | total loss: [1m[32m0.69335[0m[0m | time: 40.277s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.5016 -- iter: 1376/1707
[A[ATraining Step: 98  | total loss: [1m[32m0.69308[0m[0m | time: 40.896s
[2K
| RMSProp | epoch: 002 | loss: 0.69308 - acc: 0.5139 -- iter: 1408/1707
[A[ATraining Step: 99  | total loss: [1m[32m0.69246[0m[0m | time: 41.507s
[2K
| RMSProp | epoch: 002 | loss: 0.69246 - acc: 0.5344 -- iter: 1440/1707
[A[ATraining Step: 100  | total loss: [1m[32m0.69229[0m[0m | time: 42.154s
[2K
| RMSProp | epoch: 002 | loss: 0.69229 - acc: 0.5372 -- iter: 1472/1707
[A[ATraining Step: 101  | total loss: [1m[32m0.69242[0m[0m | time: 42.767s
[2K
| RMSProp | epoch: 002 | loss: 0.69242 - acc: 0.5335 -- iter: 1504/1707
[A[ATraining Step: 102  | total loss: [1m[32m0.69193[0m[0m | time: 43.385s
[2K
| RMSProp | epoch: 002 | loss: 0.69193 - acc: 0.5426 -- iter: 1536/1707
[A[ATraining Step: 103  | total loss: [1m[32m0.69312[0m[0m | time: 44.008s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5196 -- iter: 1568/1707
[A[ATraining Step: 104  | total loss: [1m[32m0.69302[0m[0m | time: 44.648s
[2K
| RMSProp | epoch: 002 | loss: 0.69302 - acc: 0.5208 -- iter: 1600/1707
[A[ATraining Step: 105  | total loss: [1m[32m0.69333[0m[0m | time: 45.252s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.5125 -- iter: 1632/1707
[A[ATraining Step: 106  | total loss: [1m[32m0.69345[0m[0m | time: 45.880s
[2K
| RMSProp | epoch: 002 | loss: 0.69345 - acc: 0.5081 -- iter: 1664/1707
[A[ATraining Step: 107  | total loss: [1m[32m0.69372[0m[0m | time: 46.502s
[2K
| RMSProp | epoch: 002 | loss: 0.69372 - acc: 0.4979 -- iter: 1696/1707
[A[ATraining Step: 108  | total loss: [1m[32m0.69351[0m[0m | time: 48.843s
[2K
| RMSProp | epoch: 002 | loss: 0.69351 - acc: 0.5044 | val_loss: 0.69417 - val_acc: 0.4476 -- iter: 1707/1707
--
Training Step: 109  | total loss: [1m[32m0.69374[0m[0m | time: 0.243s
[2K
| RMSProp | epoch: 003 | loss: 0.69374 - acc: 0.4945 -- iter: 0032/1707
[A[ATraining Step: 110  | total loss: [1m[32m0.69377[0m[0m | time: 0.497s
[2K
| RMSProp | epoch: 003 | loss: 0.69377 - acc: 0.4905 -- iter: 0064/1707
[A[ATraining Step: 111  | total loss: [1m[32m0.69375[0m[0m | time: 1.165s
[2K
| RMSProp | epoch: 003 | loss: 0.69375 - acc: 0.4869 -- iter: 0096/1707
[A[ATraining Step: 112  | total loss: [1m[32m0.69357[0m[0m | time: 1.799s
[2K
| RMSProp | epoch: 003 | loss: 0.69357 - acc: 0.5008 -- iter: 0128/1707
[A[ATraining Step: 113  | total loss: [1m[32m0.69368[0m[0m | time: 2.418s
[2K
| RMSProp | epoch: 003 | loss: 0.69368 - acc: 0.4944 -- iter: 0160/1707
[A[ATraining Step: 114  | total loss: [1m[32m0.69378[0m[0m | time: 3.085s
[2K
| RMSProp | epoch: 003 | loss: 0.69378 - acc: 0.4856 -- iter: 0192/1707
[A[ATraining Step: 115  | total loss: [1m[32m0.69374[0m[0m | time: 3.714s
[2K
| RMSProp | epoch: 003 | loss: 0.69374 - acc: 0.4808 -- iter: 0224/1707
[A[ATraining Step: 116  | total loss: [1m[32m0.69366[0m[0m | time: 4.322s
[2K
| RMSProp | epoch: 003 | loss: 0.69366 - acc: 0.4858 -- iter: 0256/1707
[A[ATraining Step: 117  | total loss: [1m[32m0.69357[0m[0m | time: 4.966s
[2K
| RMSProp | epoch: 003 | loss: 0.69357 - acc: 0.4966 -- iter: 0288/1707
[A[ATraining Step: 118  | total loss: [1m[32m0.69345[0m[0m | time: 5.602s
[2K
| RMSProp | epoch: 003 | loss: 0.69345 - acc: 0.5001 -- iter: 0320/1707
[A[ATraining Step: 119  | total loss: [1m[32m0.69357[0m[0m | time: 6.214s
[2K
| RMSProp | epoch: 003 | loss: 0.69357 - acc: 0.4938 -- iter: 0352/1707
[A[ATraining Step: 120  | total loss: [1m[32m0.69337[0m[0m | time: 6.841s
[2K
| RMSProp | epoch: 003 | loss: 0.69337 - acc: 0.5101 -- iter: 0384/1707
[A[ATraining Step: 121  | total loss: [1m[32m0.69282[0m[0m | time: 7.537s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5278 -- iter: 0416/1707
[A[ATraining Step: 122  | total loss: [1m[32m0.69319[0m[0m | time: 8.348s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5188 -- iter: 0448/1707
[A[ATraining Step: 123  | total loss: [1m[32m0.69280[0m[0m | time: 9.115s
[2K
| RMSProp | epoch: 003 | loss: 0.69280 - acc: 0.5263 -- iter: 0480/1707
[A[ATraining Step: 124  | total loss: [1m[32m0.69175[0m[0m | time: 9.932s
[2K
| RMSProp | epoch: 003 | loss: 0.69175 - acc: 0.5424 -- iter: 0512/1707
[A[ATraining Step: 125  | total loss: [1m[32m0.69068[0m[0m | time: 10.922s
[2K
| RMSProp | epoch: 003 | loss: 0.69068 - acc: 0.5507 -- iter: 0544/1707
[A[ATraining Step: 126  | total loss: [1m[32m0.69114[0m[0m | time: 12.053s
[2K
| RMSProp | epoch: 003 | loss: 0.69114 - acc: 0.5456 -- iter: 0576/1707
[A[ATraining Step: 127  | total loss: [1m[32m0.69195[0m[0m | time: 13.117s
[2K
| RMSProp | epoch: 003 | loss: 0.69195 - acc: 0.5379 -- iter: 0608/1707
[A[ATraining Step: 128  | total loss: [1m[32m0.69224[0m[0m | time: 13.918s
[2K
| RMSProp | epoch: 003 | loss: 0.69224 - acc: 0.5341 -- iter: 0640/1707
[A[ATraining Step: 129  | total loss: [1m[32m0.69290[0m[0m | time: 14.893s
[2K
| RMSProp | epoch: 003 | loss: 0.69290 - acc: 0.5245 -- iter: 0672/1707
[A[ATraining Step: 130  | total loss: [1m[32m0.69265[0m[0m | time: 15.873s
[2K
| RMSProp | epoch: 003 | loss: 0.69265 - acc: 0.5283 -- iter: 0704/1707
[A[ATraining Step: 131  | total loss: [1m[32m0.69234[0m[0m | time: 16.825s
[2K
| RMSProp | epoch: 003 | loss: 0.69234 - acc: 0.5317 -- iter: 0736/1707
[A[ATraining Step: 132  | total loss: [1m[32m0.69197[0m[0m | time: 17.814s
[2K
| RMSProp | epoch: 003 | loss: 0.69197 - acc: 0.5348 -- iter: 0768/1707
[A[ATraining Step: 133  | total loss: [1m[32m0.69245[0m[0m | time: 18.842s
[2K
| RMSProp | epoch: 003 | loss: 0.69245 - acc: 0.5282 -- iter: 0800/1707
[A[ATraining Step: 134  | total loss: [1m[32m0.69185[0m[0m | time: 19.785s
[2K
| RMSProp | epoch: 003 | loss: 0.69185 - acc: 0.5347 -- iter: 0832/1707
[A[ATraining Step: 135  | total loss: [1m[32m0.69209[0m[0m | time: 20.714s
[2K
| RMSProp | epoch: 003 | loss: 0.69209 - acc: 0.5313 -- iter: 0864/1707
[A[ATraining Step: 136  | total loss: [1m[32m0.69266[0m[0m | time: 21.799s
[2K
| RMSProp | epoch: 003 | loss: 0.69266 - acc: 0.5250 -- iter: 0896/1707
[A[ATraining Step: 137  | total loss: [1m[32m0.69349[0m[0m | time: 22.863s
[2K
| RMSProp | epoch: 003 | loss: 0.69349 - acc: 0.5100 -- iter: 0928/1707
[A[ATraining Step: 138  | total loss: [1m[32m0.69357[0m[0m | time: 23.692s
[2K
| RMSProp | epoch: 003 | loss: 0.69357 - acc: 0.5059 -- iter: 0960/1707
[A[ATraining Step: 139  | total loss: [1m[32m0.69337[0m[0m | time: 24.602s
[2K
| RMSProp | epoch: 003 | loss: 0.69337 - acc: 0.5115 -- iter: 0992/1707
[A[ATraining Step: 140  | total loss: [1m[32m0.69346[0m[0m | time: 25.588s
[2K
| RMSProp | epoch: 003 | loss: 0.69346 - acc: 0.5073 -- iter: 1024/1707
[A[ATraining Step: 141  | total loss: [1m[32m0.69316[0m[0m | time: 26.569s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.5159 -- iter: 1056/1707
[A[ATraining Step: 142  | total loss: [1m[32m0.69245[0m[0m | time: 27.550s
[2K
| RMSProp | epoch: 003 | loss: 0.69245 - acc: 0.5299 -- iter: 1088/1707
[A[ATraining Step: 143  | total loss: [1m[32m0.69209[0m[0m | time: 28.556s
[2K
| RMSProp | epoch: 003 | loss: 0.69209 - acc: 0.5332 -- iter: 1120/1707
[A[ATraining Step: 144  | total loss: [1m[32m0.69332[0m[0m | time: 29.485s
[2K
| RMSProp | epoch: 003 | loss: 0.69332 - acc: 0.5205 -- iter: 1152/1707
[A[ATraining Step: 145  | total loss: [1m[32m0.69269[0m[0m | time: 30.341s
[2K
| RMSProp | epoch: 003 | loss: 0.69269 - acc: 0.5310 -- iter: 1184/1707
[A[ATraining Step: 146  | total loss: [1m[32m0.69352[0m[0m | time: 31.452s
[2K
| RMSProp | epoch: 003 | loss: 0.69352 - acc: 0.5185 -- iter: 1216/1707
[A[ATraining Step: 147  | total loss: [1m[32m0.69295[0m[0m | time: 32.458s
[2K
| RMSProp | epoch: 003 | loss: 0.69295 - acc: 0.5291 -- iter: 1248/1707
[A[ATraining Step: 148  | total loss: [1m[32m0.69275[0m[0m | time: 33.347s
[2K
| RMSProp | epoch: 003 | loss: 0.69275 - acc: 0.5293 -- iter: 1280/1707
[A[ATraining Step: 149  | total loss: [1m[32m0.69307[0m[0m | time: 34.253s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5233 -- iter: 1312/1707
[A[ATraining Step: 150  | total loss: [1m[32m0.69334[0m[0m | time: 35.220s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.5178 -- iter: 1344/1707
[A[ATraining Step: 151  | total loss: [1m[32m0.69316[0m[0m | time: 36.128s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.5192 -- iter: 1376/1707
[A[ATraining Step: 152  | total loss: [1m[32m0.69285[0m[0m | time: 37.107s
[2K
| RMSProp | epoch: 003 | loss: 0.69285 - acc: 0.5235 -- iter: 1408/1707
[A[ATraining Step: 153  | total loss: [1m[32m0.69334[0m[0m | time: 38.142s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.5149 -- iter: 1440/1707
[A[ATraining Step: 154  | total loss: [1m[32m0.69306[0m[0m | time: 39.095s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5197 -- iter: 1472/1707
[A[ATraining Step: 155  | total loss: [1m[32m0.69311[0m[0m | time: 39.994s
[2K
| RMSProp | epoch: 003 | loss: 0.69311 - acc: 0.5177 -- iter: 1504/1707
[A[ATraining Step: 156  | total loss: [1m[32m0.69328[0m[0m | time: 41.055s
[2K
| RMSProp | epoch: 003 | loss: 0.69328 - acc: 0.5128 -- iter: 1536/1707
[A[ATraining Step: 157  | total loss: [1m[32m0.69329[0m[0m | time: 42.119s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.5115 -- iter: 1568/1707
[A[ATraining Step: 158  | total loss: [1m[32m0.69314[0m[0m | time: 43.021s
[2K
| RMSProp | epoch: 003 | loss: 0.69314 - acc: 0.5135 -- iter: 1600/1707
[A[ATraining Step: 159  | total loss: [1m[32m0.69273[0m[0m | time: 43.878s
[2K
| RMSProp | epoch: 003 | loss: 0.69273 - acc: 0.5215 -- iter: 1632/1707
[A[ATraining Step: 160  | total loss: [1m[32m0.69354[0m[0m | time: 44.863s
[2K
| RMSProp | epoch: 003 | loss: 0.69354 - acc: 0.5100 -- iter: 1664/1707
[A[ATraining Step: 161  | total loss: [1m[32m0.69284[0m[0m | time: 45.803s
[2K
| RMSProp | epoch: 003 | loss: 0.69284 - acc: 0.5277 -- iter: 1696/1707
[A[ATraining Step: 162  | total loss: [1m[32m0.69313[0m[0m | time: 49.649s
[2K
| RMSProp | epoch: 003 | loss: 0.69313 - acc: 0.5218 | val_loss: 0.69123 - val_acc: 0.5524 -- iter: 1707/1707
--
Training Step: 163  | total loss: [1m[32m0.69349[0m[0m | time: 1.074s
[2K
| RMSProp | epoch: 004 | loss: 0.69349 - acc: 0.5134 -- iter: 0032/1707
[A[ATraining Step: 164  | total loss: [1m[32m0.69333[0m[0m | time: 1.400s
[2K
| RMSProp | epoch: 004 | loss: 0.69333 - acc: 0.5152 -- iter: 0064/1707
[A[ATraining Step: 165  | total loss: [1m[32m0.69358[0m[0m | time: 1.749s
[2K
| RMSProp | epoch: 004 | loss: 0.69358 - acc: 0.5091 -- iter: 0096/1707
[A[ATraining Step: 166  | total loss: [1m[32m0.69372[0m[0m | time: 2.685s
[2K
| RMSProp | epoch: 004 | loss: 0.69372 - acc: 0.5037 -- iter: 0128/1707
[A[ATraining Step: 167  | total loss: [1m[32m0.69366[0m[0m | time: 3.631s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.5033 -- iter: 0160/1707
[A[ATraining Step: 168  | total loss: [1m[32m0.69340[0m[0m | time: 4.644s
[2K
| RMSProp | epoch: 004 | loss: 0.69340 - acc: 0.5123 -- iter: 0192/1707
[A[ATraining Step: 169  | total loss: [1m[32m0.69377[0m[0m | time: 5.637s
[2K
| RMSProp | epoch: 004 | loss: 0.69377 - acc: 0.5017 -- iter: 0224/1707
[A[ATraining Step: 170  | total loss: [1m[32m0.69400[0m[0m | time: 6.698s
[2K
| RMSProp | epoch: 004 | loss: 0.69400 - acc: 0.4891 -- iter: 0256/1707
[A[ATraining Step: 171  | total loss: [1m[32m0.69390[0m[0m | time: 7.629s
[2K
| RMSProp | epoch: 004 | loss: 0.69390 - acc: 0.4964 -- iter: 0288/1707
[A[ATraining Step: 172  | total loss: [1m[32m0.69393[0m[0m | time: 8.478s
[2K
| RMSProp | epoch: 004 | loss: 0.69393 - acc: 0.4905 -- iter: 0320/1707
[A[ATraining Step: 173  | total loss: [1m[32m0.69383[0m[0m | time: 9.617s
[2K
| RMSProp | epoch: 004 | loss: 0.69383 - acc: 0.4977 -- iter: 0352/1707
[A[ATraining Step: 174  | total loss: [1m[32m0.69387[0m[0m | time: 10.699s
[2K
| RMSProp | epoch: 004 | loss: 0.69387 - acc: 0.4886 -- iter: 0384/1707
[A[ATraining Step: 175  | total loss: [1m[32m0.69380[0m[0m | time: 11.642s
[2K
| RMSProp | epoch: 004 | loss: 0.69380 - acc: 0.4897 -- iter: 0416/1707
[A[ATraining Step: 176  | total loss: [1m[32m0.69368[0m[0m | time: 12.487s
[2K
| RMSProp | epoch: 004 | loss: 0.69368 - acc: 0.4970 -- iter: 0448/1707
[A[ATraining Step: 177  | total loss: [1m[32m0.69377[0m[0m | time: 13.401s
[2K
| RMSProp | epoch: 004 | loss: 0.69377 - acc: 0.4879 -- iter: 0480/1707
[A[ATraining Step: 178  | total loss: [1m[32m0.69369[0m[0m | time: 14.343s
[2K
| RMSProp | epoch: 004 | loss: 0.69369 - acc: 0.4923 -- iter: 0512/1707
[A[ATraining Step: 179  | total loss: [1m[32m0.69366[0m[0m | time: 15.312s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.4930 -- iter: 0544/1707
[A[ATraining Step: 180  | total loss: [1m[32m0.69353[0m[0m | time: 16.348s
[2K
| RMSProp | epoch: 004 | loss: 0.69353 - acc: 0.5093 -- iter: 0576/1707
[A[ATraining Step: 181  | total loss: [1m[32m0.69344[0m[0m | time: 17.373s
[2K
| RMSProp | epoch: 004 | loss: 0.69344 - acc: 0.5115 -- iter: 0608/1707
[A[ATraining Step: 182  | total loss: [1m[32m0.69381[0m[0m | time: 18.236s
[2K
| RMSProp | epoch: 004 | loss: 0.69381 - acc: 0.4948 -- iter: 0640/1707
[A[ATraining Step: 183  | total loss: [1m[32m0.69380[0m[0m | time: 19.239s
[2K
| RMSProp | epoch: 004 | loss: 0.69380 - acc: 0.4859 -- iter: 0672/1707
[A[ATraining Step: 184  | total loss: [1m[32m0.69377[0m[0m | time: 20.260s
[2K
| RMSProp | epoch: 004 | loss: 0.69377 - acc: 0.4842 -- iter: 0704/1707
[A[ATraining Step: 185  | total loss: [1m[32m0.69372[0m[0m | time: 21.307s
[2K
| RMSProp | epoch: 004 | loss: 0.69372 - acc: 0.4826 -- iter: 0736/1707
[A[ATraining Step: 186  | total loss: [1m[32m0.69367[0m[0m | time: 22.098s
[2K
| RMSProp | epoch: 004 | loss: 0.69367 - acc: 0.4906 -- iter: 0768/1707
[A[ATraining Step: 187  | total loss: [1m[32m0.69362[0m[0m | time: 22.988s
[2K
| RMSProp | epoch: 004 | loss: 0.69362 - acc: 0.4916 -- iter: 0800/1707
[A[ATraining Step: 188  | total loss: [1m[32m0.69357[0m[0m | time: 23.965s
[2K
| RMSProp | epoch: 004 | loss: 0.69357 - acc: 0.4924 -- iter: 0832/1707
[A[ATraining Step: 189  | total loss: [1m[32m0.69354[0m[0m | time: 24.885s
[2K
| RMSProp | epoch: 004 | loss: 0.69354 - acc: 0.4900 -- iter: 0864/1707
[A[ATraining Step: 190  | total loss: [1m[32m0.69347[0m[0m | time: 25.905s
[2K
| RMSProp | epoch: 004 | loss: 0.69347 - acc: 0.4973 -- iter: 0896/1707
[A[ATraining Step: 191  | total loss: [1m[32m0.69364[0m[0m | time: 26.920s
[2K
| RMSProp | epoch: 004 | loss: 0.69364 - acc: 0.4882 -- iter: 0928/1707
[A[ATraining Step: 192  | total loss: [1m[32m0.69351[0m[0m | time: 27.960s
[2K
| RMSProp | epoch: 004 | loss: 0.69351 - acc: 0.4987 -- iter: 0960/1707
[A[ATraining Step: 193  | total loss: [1m[32m0.69317[0m[0m | time: 28.815s
[2K
| RMSProp | epoch: 004 | loss: 0.69317 - acc: 0.5145 -- iter: 0992/1707
[A[ATraining Step: 194  | total loss: [1m[32m0.69358[0m[0m | time: 29.837s
[2K
| RMSProp | epoch: 004 | loss: 0.69358 - acc: 0.5037 -- iter: 1024/1707
[A[ATraining Step: 195  | total loss: [1m[32m0.69346[0m[0m | time: 30.912s
[2K
| RMSProp | epoch: 004 | loss: 0.69346 - acc: 0.5064 -- iter: 1056/1707
[A[ATraining Step: 196  | total loss: [1m[32m0.69345[0m[0m | time: 31.852s
[2K
| RMSProp | epoch: 004 | loss: 0.69345 - acc: 0.5058 -- iter: 1088/1707
[A[ATraining Step: 197  | total loss: [1m[32m0.69336[0m[0m | time: 32.784s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.5083 -- iter: 1120/1707
[A[ATraining Step: 198  | total loss: [1m[32m0.69337[0m[0m | time: 33.738s
[2K
| RMSProp | epoch: 004 | loss: 0.69337 - acc: 0.5075 -- iter: 1152/1707
[A[ATraining Step: 199  | total loss: [1m[32m0.69319[0m[0m | time: 34.704s
[2K
| RMSProp | epoch: 004 | loss: 0.69319 - acc: 0.5130 -- iter: 1184/1707
[A[ATraining Step: 200  | total loss: [1m[32m0.69321[0m[0m | time: 38.525s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.5117 | val_loss: 0.69382 - val_acc: 0.4476 -- iter: 1216/1707
--
Training Step: 201  | total loss: [1m[32m0.69369[0m[0m | time: 39.415s
[2K
| RMSProp | epoch: 004 | loss: 0.69369 - acc: 0.4949 -- iter: 1248/1707
[A[ATraining Step: 202  | total loss: [1m[32m0.69364[0m[0m | time: 40.463s
[2K
| RMSProp | epoch: 004 | loss: 0.69364 - acc: 0.4954 -- iter: 1280/1707
[A[ATraining Step: 203  | total loss: [1m[32m0.69349[0m[0m | time: 41.639s
[2K
| RMSProp | epoch: 004 | loss: 0.69349 - acc: 0.5052 -- iter: 1312/1707
[A[ATraining Step: 204  | total loss: [1m[32m0.69316[0m[0m | time: 42.492s
[2K
| RMSProp | epoch: 004 | loss: 0.69316 - acc: 0.5172 -- iter: 1344/1707
[A[ATraining Step: 205  | total loss: [1m[32m0.69310[0m[0m | time: 43.414s
[2K
| RMSProp | epoch: 004 | loss: 0.69310 - acc: 0.5186 -- iter: 1376/1707
[A[ATraining Step: 206  | total loss: [1m[32m0.69350[0m[0m | time: 44.304s
[2K
| RMSProp | epoch: 004 | loss: 0.69350 - acc: 0.5074 -- iter: 1408/1707
[A[ATraining Step: 207  | total loss: [1m[32m0.69371[0m[0m | time: 45.271s
[2K
| RMSProp | epoch: 004 | loss: 0.69371 - acc: 0.4973 -- iter: 1440/1707
[A[ATraining Step: 208  | total loss: [1m[32m0.69359[0m[0m | time: 46.203s
[2K
| RMSProp | epoch: 004 | loss: 0.69359 - acc: 0.5007 -- iter: 1472/1707
[A[ATraining Step: 209  | total loss: [1m[32m0.69373[0m[0m | time: 47.180s
[2K
| RMSProp | epoch: 004 | loss: 0.69373 - acc: 0.4912 -- iter: 1504/1707
[A[ATraining Step: 210  | total loss: [1m[32m0.69369[0m[0m | time: 48.239s
[2K
| RMSProp | epoch: 004 | loss: 0.69369 - acc: 0.4859 -- iter: 1536/1707
[A[ATraining Step: 211  | total loss: [1m[32m0.69372[0m[0m | time: 49.070s
[2K
| RMSProp | epoch: 004 | loss: 0.69372 - acc: 0.4810 -- iter: 1568/1707
[A[ATraining Step: 212  | total loss: [1m[32m0.69363[0m[0m | time: 50.082s
[2K
| RMSProp | epoch: 004 | loss: 0.69363 - acc: 0.4892 -- iter: 1600/1707
[A[ATraining Step: 213  | total loss: [1m[32m0.69350[0m[0m | time: 51.183s
[2K
| RMSProp | epoch: 004 | loss: 0.69350 - acc: 0.4965 -- iter: 1632/1707
[A[ATraining Step: 214  | total loss: [1m[32m0.69353[0m[0m | time: 52.213s
[2K
| RMSProp | epoch: 004 | loss: 0.69353 - acc: 0.4937 -- iter: 1664/1707
[A[ATraining Step: 215  | total loss: [1m[32m0.69352[0m[0m | time: 53.018s
[2K
| RMSProp | epoch: 004 | loss: 0.69352 - acc: 0.4912 -- iter: 1696/1707
[A[ATraining Step: 216  | total loss: [1m[32m0.69339[0m[0m | time: 56.546s
[2K
| RMSProp | epoch: 004 | loss: 0.69339 - acc: 0.4984 | val_loss: 0.69497 - val_acc: 0.4476 -- iter: 1707/1707
--
Training Step: 217  | total loss: [1m[32m0.69315[0m[0m | time: 1.028s
[2K
| RMSProp | epoch: 005 | loss: 0.69315 - acc: 0.5079 -- iter: 0032/1707
[A[ATraining Step: 218  | total loss: [1m[32m0.69317[0m[0m | time: 1.922s
[2K
| RMSProp | epoch: 005 | loss: 0.69317 - acc: 0.5071 -- iter: 0064/1707
[A[ATraining Step: 219  | total loss: [1m[32m0.69287[0m[0m | time: 2.285s
[2K
| RMSProp | epoch: 005 | loss: 0.69287 - acc: 0.5158 -- iter: 0096/1707
[A[ATraining Step: 220  | total loss: [1m[32m0.69347[0m[0m | time: 2.710s
[2K
| RMSProp | epoch: 005 | loss: 0.69347 - acc: 0.5006 -- iter: 0128/1707
[A[ATraining Step: 221  | total loss: [1m[32m0.69374[0m[0m | time: 3.735s
[2K
| RMSProp | epoch: 005 | loss: 0.69374 - acc: 0.4869 -- iter: 0160/1707
[A[ATraining Step: 222  | total loss: [1m[32m0.69364[0m[0m | time: 4.818s
[2K
| RMSProp | epoch: 005 | loss: 0.69364 - acc: 0.4944 -- iter: 0192/1707
[A[ATraining Step: 223  | total loss: [1m[32m0.69404[0m[0m | time: 5.784s
[2K
| RMSProp | epoch: 005 | loss: 0.69404 - acc: 0.4731 -- iter: 0224/1707
[A[ATraining Step: 224  | total loss: [1m[32m0.69393[0m[0m | time: 6.809s
[2K
| RMSProp | epoch: 005 | loss: 0.69393 - acc: 0.4789 -- iter: 0256/1707
[A[ATraining Step: 225  | total loss: [1m[32m0.69371[0m[0m | time: 7.819s
[2K
| RMSProp | epoch: 005 | loss: 0.69371 - acc: 0.4873 -- iter: 0288/1707
[A[ATraining Step: 226  | total loss: [1m[32m0.69341[0m[0m | time: 8.532s
[2K
| RMSProp | epoch: 005 | loss: 0.69341 - acc: 0.4917 -- iter: 0320/1707
[A[ATraining Step: 227  | total loss: [1m[32m0.69274[0m[0m | time: 9.169s
[2K
| RMSProp | epoch: 005 | loss: 0.69274 - acc: 0.4988 -- iter: 0352/1707
[A[ATraining Step: 228  | total loss: [1m[32m0.69202[0m[0m | time: 9.784s
[2K
| RMSProp | epoch: 005 | loss: 0.69202 - acc: 0.5051 -- iter: 0384/1707
[A[ATraining Step: 229  | total loss: [1m[32m0.69290[0m[0m | time: 10.410s
[2K
| RMSProp | epoch: 005 | loss: 0.69290 - acc: 0.4921 -- iter: 0416/1707
[A[ATraining Step: 230  | total loss: [1m[32m0.69288[0m[0m | time: 11.057s
[2K
| RMSProp | epoch: 005 | loss: 0.69288 - acc: 0.4960 -- iter: 0448/1707
[A[ATraining Step: 231  | total loss: [1m[32m0.69287[0m[0m | time: 11.687s
[2K
| RMSProp | epoch: 005 | loss: 0.69287 - acc: 0.4996 -- iter: 0480/1707
[A[ATraining Step: 232  | total loss: [1m[32m0.69321[0m[0m | time: 12.302s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.4840 -- iter: 0512/1707
[A[ATraining Step: 233  | total loss: [1m[32m0.69322[0m[0m | time: 12.946s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.4793 -- iter: 0544/1707
[A[ATraining Step: 234  | total loss: [1m[32m0.69320[0m[0m | time: 13.595s
[2K
| RMSProp | epoch: 005 | loss: 0.69320 - acc: 0.4845 -- iter: 0576/1707
[A[ATraining Step: 235  | total loss: [1m[32m0.69323[0m[0m | time: 14.230s
[2K
| RMSProp | epoch: 005 | loss: 0.69323 - acc: 0.4736 -- iter: 0608/1707
[A[ATraining Step: 236  | total loss: [1m[32m0.69339[0m[0m | time: 14.857s
[2K
| RMSProp | epoch: 005 | loss: 0.69339 - acc: 0.4637 -- iter: 0640/1707
[A[ATraining Step: 237  | total loss: [1m[32m0.69339[0m[0m | time: 15.493s
[2K
| RMSProp | epoch: 005 | loss: 0.69339 - acc: 0.4611 -- iter: 0672/1707
[A[ATraining Step: 238  | total loss: [1m[32m0.69333[0m[0m | time: 16.128s
[2K
| RMSProp | epoch: 005 | loss: 0.69333 - acc: 0.4775 -- iter: 0704/1707
[A[ATraining Step: 239  | total loss: [1m[32m0.69329[0m[0m | time: 16.760s
[2K
| RMSProp | epoch: 005 | loss: 0.69329 - acc: 0.4829 -- iter: 0736/1707
[A[ATraining Step: 240  | total loss: [1m[32m0.69303[0m[0m | time: 17.409s
[2K
| RMSProp | epoch: 005 | loss: 0.69303 - acc: 0.5002 -- iter: 0768/1707
[A[ATraining Step: 241  | total loss: [1m[32m0.69310[0m[0m | time: 18.048s
[2K
| RMSProp | epoch: 005 | loss: 0.69310 - acc: 0.4971 -- iter: 0800/1707
[A[ATraining Step: 242  | total loss: [1m[32m0.69311[0m[0m | time: 18.678s
[2K
| RMSProp | epoch: 005 | loss: 0.69311 - acc: 0.4973 -- iter: 0832/1707
[A[ATraining Step: 243  | total loss: [1m[32m0.69313[0m[0m | time: 19.339s
[2K
| RMSProp | epoch: 005 | loss: 0.69313 - acc: 0.4976 -- iter: 0864/1707
[A[ATraining Step: 244  | total loss: [1m[32m0.69346[0m[0m | time: 19.968s
[2K
| RMSProp | epoch: 005 | loss: 0.69346 - acc: 0.4854 -- iter: 0896/1707
[A[ATraining Step: 245  | total loss: [1m[32m0.69355[0m[0m | time: 20.616s
[2K
| RMSProp | epoch: 005 | loss: 0.69355 - acc: 0.4743 -- iter: 0928/1707
[A[ATraining Step: 246  | total loss: [1m[32m0.69347[0m[0m | time: 21.235s
[2K
| RMSProp | epoch: 005 | loss: 0.69347 - acc: 0.4800 -- iter: 0960/1707
[A[ATraining Step: 247  | total loss: [1m[32m0.69325[0m[0m | time: 21.859s
[2K
| RMSProp | epoch: 005 | loss: 0.69325 - acc: 0.4976 -- iter: 0992/1707
[A[ATraining Step: 248  | total loss: [1m[32m0.69443[0m[0m | time: 22.481s
[2K
| RMSProp | epoch: 005 | loss: 0.69443 - acc: 0.4666 -- iter: 1024/1707
[A[ATraining Step: 249  | total loss: [1m[32m0.69431[0m[0m | time: 23.240s
[2K
| RMSProp | epoch: 005 | loss: 0.69431 - acc: 0.4637 -- iter: 1056/1707
[A[ATraining Step: 250  | total loss: [1m[32m0.69418[0m[0m | time: 23.871s
[2K
| RMSProp | epoch: 005 | loss: 0.69418 - acc: 0.4705 -- iter: 1088/1707
[A[ATraining Step: 251  | total loss: [1m[32m0.69412[0m[0m | time: 24.685s
[2K
| RMSProp | epoch: 005 | loss: 0.69412 - acc: 0.4640 -- iter: 1120/1707
[A[ATraining Step: 252  | total loss: [1m[32m0.69403[0m[0m | time: 25.412s
[2K
| RMSProp | epoch: 005 | loss: 0.69403 - acc: 0.4676 -- iter: 1152/1707
[A[ATraining Step: 253  | total loss: [1m[32m0.69400[0m[0m | time: 26.239s
[2K
| RMSProp | epoch: 005 | loss: 0.69400 - acc: 0.4615 -- iter: 1184/1707
[A[ATraining Step: 254  | total loss: [1m[32m0.69387[0m[0m | time: 27.071s
[2K
| RMSProp | epoch: 005 | loss: 0.69387 - acc: 0.4685 -- iter: 1216/1707
[A[ATraining Step: 255  | total loss: [1m[32m0.69372[0m[0m | time: 27.860s
[2K
| RMSProp | epoch: 005 | loss: 0.69372 - acc: 0.4748 -- iter: 1248/1707
[A[ATraining Step: 256  | total loss: [1m[32m0.69378[0m[0m | time: 28.665s
[2K
| RMSProp | epoch: 005 | loss: 0.69378 - acc: 0.4710 -- iter: 1280/1707
[A[ATraining Step: 257  | total loss: [1m[32m0.69380[0m[0m | time: 29.553s
[2K
| RMSProp | epoch: 005 | loss: 0.69380 - acc: 0.4708 -- iter: 1312/1707
[A[ATraining Step: 258  | total loss: [1m[32m0.69365[0m[0m | time: 30.540s
[2K
| RMSProp | epoch: 005 | loss: 0.69365 - acc: 0.4800 -- iter: 1344/1707
[A[ATraining Step: 259  | total loss: [1m[32m0.69355[0m[0m | time: 31.607s
[2K
| RMSProp | epoch: 005 | loss: 0.69355 - acc: 0.4882 -- iter: 1376/1707
[A[ATraining Step: 260  | total loss: [1m[32m0.69359[0m[0m | time: 32.718s
[2K
| RMSProp | epoch: 005 | loss: 0.69359 - acc: 0.4863 -- iter: 1408/1707
[A[ATraining Step: 261  | total loss: [1m[32m0.69344[0m[0m | time: 33.531s
[2K
| RMSProp | epoch: 005 | loss: 0.69344 - acc: 0.4939 -- iter: 1440/1707
[A[ATraining Step: 262  | total loss: [1m[32m0.69375[0m[0m | time: 34.457s
[2K
| RMSProp | epoch: 005 | loss: 0.69375 - acc: 0.4820 -- iter: 1472/1707
[A[ATraining Step: 263  | total loss: [1m[32m0.69367[0m[0m | time: 35.406s
[2K
| RMSProp | epoch: 005 | loss: 0.69367 - acc: 0.4838 -- iter: 1504/1707
[A[ATraining Step: 264  | total loss: [1m[32m0.69359[0m[0m | time: 36.354s
[2K
| RMSProp | epoch: 005 | loss: 0.69359 - acc: 0.4886 -- iter: 1536/1707
[A[ATraining Step: 265  | total loss: [1m[32m0.69355[0m[0m | time: 37.359s
[2K
| RMSProp | epoch: 005 | loss: 0.69355 - acc: 0.4866 -- iter: 1568/1707
[A[ATraining Step: 266  | total loss: [1m[32m0.69351[0m[0m | time: 38.385s
[2K
| RMSProp | epoch: 005 | loss: 0.69351 - acc: 0.4910 -- iter: 1600/1707
[A[ATraining Step: 267  | total loss: [1m[32m0.69350[0m[0m | time: 39.374s
[2K
| RMSProp | epoch: 005 | loss: 0.69350 - acc: 0.4888 -- iter: 1632/1707
[A[ATraining Step: 268  | total loss: [1m[32m0.69351[0m[0m | time: 40.360s
[2K
| RMSProp | epoch: 005 | loss: 0.69351 - acc: 0.4837 -- iter: 1664/1707
[A[ATraining Step: 269  | total loss: [1m[32m0.69349[0m[0m | time: 41.683s
[2K
| RMSProp | epoch: 005 | loss: 0.69349 - acc: 0.4697 -- iter: 1696/1707
[A[ATraining Step: 270  | total loss: [1m[32m0.69342[0m[0m | time: 46.382s
[2K
| RMSProp | epoch: 005 | loss: 0.69342 - acc: 0.4758 | val_loss: 0.69376 - val_acc: 0.4476 -- iter: 1707/1707
--
Training Step: 271  | total loss: [1m[32m0.69347[0m[0m | time: 1.011s
[2K
| RMSProp | epoch: 006 | loss: 0.69347 - acc: 0.4751 -- iter: 0032/1707
[A[ATraining Step: 272  | total loss: [1m[32m0.69358[0m[0m | time: 2.085s
[2K
| RMSProp | epoch: 006 | loss: 0.69358 - acc: 0.4651 -- iter: 0064/1707
[A[ATraining Step: 273  | total loss: [1m[32m0.69351[0m[0m | time: 3.268s
[2K
| RMSProp | epoch: 006 | loss: 0.69351 - acc: 0.4749 -- iter: 0096/1707
[A[ATraining Step: 274  | total loss: [1m[32m0.69354[0m[0m | time: 3.764s
[2K
| RMSProp | epoch: 006 | loss: 0.69354 - acc: 0.4680 -- iter: 0128/1707
[A[ATraining Step: 275  | total loss: [1m[32m0.69349[0m[0m | time: 4.254s
[2K
| RMSProp | epoch: 006 | loss: 0.69349 - acc: 0.4939 -- iter: 0160/1707
[A[ATraining Step: 276  | total loss: [1m[32m0.69341[0m[0m | time: 5.442s
[2K
| RMSProp | epoch: 006 | loss: 0.69341 - acc: 0.4991 -- iter: 0192/1707
[A[ATraining Step: 277  | total loss: [1m[32m0.69350[0m[0m | time: 6.495s
[2K
| RMSProp | epoch: 006 | loss: 0.69350 - acc: 0.4898 -- iter: 0224/1707
[A[ATraining Step: 278  | total loss: [1m[32m0.69345[0m[0m | time: 7.534s
[2K
| RMSProp | epoch: 006 | loss: 0.69345 - acc: 0.4971 -- iter: 0256/1707
[A[ATraining Step: 279  | total loss: [1m[32m0.69344[0m[0m | time: 8.819s
[2K
| RMSProp | epoch: 006 | loss: 0.69344 - acc: 0.4974 -- iter: 0288/1707
[A[ATraining Step: 280  | total loss: [1m[32m0.69335[0m[0m | time: 10.250s
[2K
| RMSProp | epoch: 006 | loss: 0.69335 - acc: 0.5039 -- iter: 0320/1707
[A[ATraining Step: 281  | total loss: [1m[32m0.69339[0m[0m | time: 11.451s
[2K
| RMSProp | epoch: 006 | loss: 0.69339 - acc: 0.4972 -- iter: 0352/1707
[A[ATraining Step: 282  | total loss: [1m[32m0.69344[0m[0m | time: 12.462s
[2K
| RMSProp | epoch: 006 | loss: 0.69344 - acc: 0.4819 -- iter: 0384/1707
[A[ATraining Step: 283  | total loss: [1m[32m0.69321[0m[0m | time: 13.587s
[2K
| RMSProp | epoch: 006 | loss: 0.69321 - acc: 0.5024 -- iter: 0416/1707
[A[ATraining Step: 284  | total loss: [1m[32m0.69336[0m[0m | time: 14.720s
[2K
| RMSProp | epoch: 006 | loss: 0.69336 - acc: 0.4991 -- iter: 0448/1707
[A[ATraining Step: 285  | total loss: [1m[32m0.69369[0m[0m | time: 15.776s
[2K
| RMSProp | epoch: 006 | loss: 0.69369 - acc: 0.4867 -- iter: 0480/1707
[A[ATraining Step: 286  | total loss: [1m[32m0.69356[0m[0m | time: 16.887s
[2K
| RMSProp | epoch: 006 | loss: 0.69356 - acc: 0.4974 -- iter: 0512/1707
[A[ATraining Step: 287  | total loss: [1m[32m0.69359[0m[0m | time: 18.047s
[2K
| RMSProp | epoch: 006 | loss: 0.69359 - acc: 0.4945 -- iter: 0544/1707
[A[ATraining Step: 288  | total loss: [1m[32m0.69365[0m[0m | time: 19.331s
[2K
| RMSProp | epoch: 006 | loss: 0.69365 - acc: 0.4888 -- iter: 0576/1707
[A[ATraining Step: 289  | total loss: [1m[32m0.69354[0m[0m | time: 20.297s
[2K
| RMSProp | epoch: 006 | loss: 0.69354 - acc: 0.4931 -- iter: 0608/1707
[A[ATraining Step: 290  | total loss: [1m[32m0.69340[0m[0m | time: 21.341s
[2K
| RMSProp | epoch: 006 | loss: 0.69340 - acc: 0.5031 -- iter: 0640/1707
[A[ATraining Step: 291  | total loss: [1m[32m0.69333[0m[0m | time: 22.727s
[2K
| RMSProp | epoch: 006 | loss: 0.69333 - acc: 0.5059 -- iter: 0672/1707
[A[ATraining Step: 292  | total loss: [1m[32m0.69370[0m[0m | time: 24.264s
[2K
| RMSProp | epoch: 006 | loss: 0.69370 - acc: 0.4897 -- iter: 0704/1707
[A[ATraining Step: 293  | total loss: [1m[32m0.69363[0m[0m | time: 25.526s
[2K
| RMSProp | epoch: 006 | loss: 0.69363 - acc: 0.4876 -- iter: 0736/1707
[A[ATraining Step: 294  | total loss: [1m[32m0.69358[0m[0m | time: 26.500s
[2K
| RMSProp | epoch: 006 | loss: 0.69358 - acc: 0.4857 -- iter: 0768/1707
[A[ATraining Step: 295  | total loss: [1m[32m0.69350[0m[0m | time: 27.693s
[2K
| RMSProp | epoch: 006 | loss: 0.69350 - acc: 0.4840 -- iter: 0800/1707
[A[ATraining Step: 296  | total loss: [1m[32m0.69353[0m[0m | time: 28.789s
[2K
| RMSProp | epoch: 006 | loss: 0.69353 - acc: 0.4731 -- iter: 0832/1707
[A[ATraining Step: 297  | total loss: [1m[32m0.69356[0m[0m | time: 29.965s
[2K
| RMSProp | epoch: 006 | loss: 0.69356 - acc: 0.4696 -- iter: 0864/1707
[A[ATraining Step: 298  | total loss: [1m[32m0.69353[0m[0m | time: 31.281s
[2K
| RMSProp | epoch: 006 | loss: 0.69353 - acc: 0.4664 -- iter: 0896/1707
[A[ATraining Step: 299  | total loss: [1m[32m0.69331[0m[0m | time: 32.524s
[2K
| RMSProp | epoch: 006 | loss: 0.69331 - acc: 0.4791 -- iter: 0928/1707
[A[ATraining Step: 300  | total loss: [1m[32m0.69306[0m[0m | time: 33.568s
[2K
| RMSProp | epoch: 006 | loss: 0.69306 - acc: 0.4906 -- iter: 0960/1707
[A[ATraining Step: 301  | total loss: [1m[32m0.69333[0m[0m | time: 34.846s
[2K
| RMSProp | epoch: 006 | loss: 0.69333 - acc: 0.4853 -- iter: 0992/1707
[A[ATraining Step: 302  | total loss: [1m[32m0.69324[0m[0m | time: 36.382s
[2K
| RMSProp | epoch: 006 | loss: 0.69324 - acc: 0.4899 -- iter: 1024/1707
[A[ATraining Step: 303  | total loss: [1m[32m0.69324[0m[0m | time: 37.798s
[2K
| RMSProp | epoch: 006 | loss: 0.69324 - acc: 0.4909 -- iter: 1056/1707
[A[ATraining Step: 304  | total loss: [1m[32m0.69354[0m[0m | time: 39.083s
[2K
| RMSProp | epoch: 006 | loss: 0.69354 - acc: 0.4824 -- iter: 1088/1707
[A[ATraining Step: 305  | total loss: [1m[32m0.69327[0m[0m | time: 40.217s
[2K
| RMSProp | epoch: 006 | loss: 0.69327 - acc: 0.4967 -- iter: 1120/1707
[A[ATraining Step: 306  | total loss: [1m[32m0.69293[0m[0m | time: 41.300s
[2K
| RMSProp | epoch: 006 | loss: 0.69293 - acc: 0.5064 -- iter: 1152/1707
[A[ATraining Step: 307  | total loss: [1m[32m0.69275[0m[0m | time: 42.414s
[2K
| RMSProp | epoch: 006 | loss: 0.69275 - acc: 0.5120 -- iter: 1184/1707
[A[ATraining Step: 308  | total loss: [1m[32m0.69260[0m[0m | time: 43.530s
[2K
| RMSProp | epoch: 006 | loss: 0.69260 - acc: 0.5139 -- iter: 1216/1707
[A[ATraining Step: 309  | total loss: [1m[32m0.69226[0m[0m | time: 44.718s
[2K
| RMSProp | epoch: 006 | loss: 0.69226 - acc: 0.5188 -- iter: 1248/1707
[A[ATraining Step: 310  | total loss: [1m[32m0.69378[0m[0m | time: 45.930s
[2K
| RMSProp | epoch: 006 | loss: 0.69378 - acc: 0.5075 -- iter: 1280/1707
[A[ATraining Step: 311  | total loss: [1m[32m0.69404[0m[0m | time: 47.058s
[2K
| RMSProp | epoch: 006 | loss: 0.69404 - acc: 0.4974 -- iter: 1312/1707
[A[ATraining Step: 312  | total loss: [1m[32m0.69393[0m[0m | time: 48.215s
[2K
| RMSProp | epoch: 006 | loss: 0.69393 - acc: 0.4977 -- iter: 1344/1707
[A[ATraining Step: 313  | total loss: [1m[32m0.69367[0m[0m | time: 49.655s
[2K
| RMSProp | epoch: 006 | loss: 0.69367 - acc: 0.5041 -- iter: 1376/1707
[A[ATraining Step: 314  | total loss: [1m[32m0.69363[0m[0m | time: 51.232s
[2K
| RMSProp | epoch: 006 | loss: 0.69363 - acc: 0.5037 -- iter: 1408/1707
[A[ATraining Step: 315  | total loss: [1m[32m0.69301[0m[0m | time: 52.435s
[2K
| RMSProp | epoch: 006 | loss: 0.69301 - acc: 0.5190 -- iter: 1440/1707
[A[ATraining Step: 316  | total loss: [1m[32m0.69327[0m[0m | time: 53.459s
[2K
| RMSProp | epoch: 006 | loss: 0.69327 - acc: 0.5140 -- iter: 1472/1707
[A[ATraining Step: 317  | total loss: [1m[32m0.69282[0m[0m | time: 54.652s
[2K
| RMSProp | epoch: 006 | loss: 0.69282 - acc: 0.5219 -- iter: 1504/1707
[A[ATraining Step: 318  | total loss: [1m[32m0.69312[0m[0m | time: 55.761s
[2K
| RMSProp | epoch: 006 | loss: 0.69312 - acc: 0.5166 -- iter: 1536/1707
[A[ATraining Step: 319  | total loss: [1m[32m0.69286[0m[0m | time: 56.904s
[2K
| RMSProp | epoch: 006 | loss: 0.69286 - acc: 0.5212 -- iter: 1568/1707
[A[ATraining Step: 320  | total loss: [1m[32m0.69315[0m[0m | time: 58.087s
[2K
| RMSProp | epoch: 006 | loss: 0.69315 - acc: 0.5160 -- iter: 1600/1707
[A[ATraining Step: 321  | total loss: [1m[32m0.69320[0m[0m | time: 59.254s
[2K
| RMSProp | epoch: 006 | loss: 0.69320 - acc: 0.5144 -- iter: 1632/1707
[A[ATraining Step: 322  | total loss: [1m[32m0.69275[0m[0m | time: 60.357s
[2K
| RMSProp | epoch: 006 | loss: 0.69275 - acc: 0.5223 -- iter: 1664/1707
[A[ATraining Step: 323  | total loss: [1m[32m0.69301[0m[0m | time: 61.320s
[2K
| RMSProp | epoch: 006 | loss: 0.69301 - acc: 0.5169 -- iter: 1696/1707
[A[ATraining Step: 324  | total loss: [1m[32m0.69273[0m[0m | time: 66.538s
[2K
| RMSProp | epoch: 006 | loss: 0.69273 - acc: 0.5215 | val_loss: 0.69025 - val_acc: 0.5524 -- iter: 1707/1707
--
Training Step: 325  | total loss: [1m[32m0.69300[0m[0m | time: 1.121s
[2K
| RMSProp | epoch: 007 | loss: 0.69300 - acc: 0.5162 -- iter: 0032/1707
[A[ATraining Step: 326  | total loss: [1m[32m0.69353[0m[0m | time: 2.181s
[2K
| RMSProp | epoch: 007 | loss: 0.69353 - acc: 0.5052 -- iter: 0064/1707
[A[ATraining Step: 327  | total loss: [1m[32m0.69420[0m[0m | time: 3.308s
[2K
| RMSProp | epoch: 007 | loss: 0.69420 - acc: 0.4860 -- iter: 0096/1707
[A[ATraining Step: 328  | total loss: [1m[32m0.69398[0m[0m | time: 4.471s
[2K
| RMSProp | epoch: 007 | loss: 0.69398 - acc: 0.4967 -- iter: 0128/1707
[A[ATraining Step: 329  | total loss: [1m[32m0.69412[0m[0m | time: 4.949s
[2K
| RMSProp | epoch: 007 | loss: 0.69412 - acc: 0.4877 -- iter: 0160/1707
[A[ATraining Step: 330  | total loss: [1m[32m0.69416[0m[0m | time: 5.354s
[2K
| RMSProp | epoch: 007 | loss: 0.69416 - acc: 0.4844 -- iter: 0192/1707
[A[ATraining Step: 331  | total loss: [1m[32m0.69417[0m[0m | time: 6.506s
[2K
| RMSProp | epoch: 007 | loss: 0.69417 - acc: 0.4814 -- iter: 0224/1707
[A[ATraining Step: 332  | total loss: [1m[32m0.69413[0m[0m | time: 7.655s
[2K
| RMSProp | epoch: 007 | loss: 0.69413 - acc: 0.4708 -- iter: 0256/1707
[A[ATraining Step: 333  | total loss: [1m[32m0.69405[0m[0m | time: 9.023s
[2K
| RMSProp | epoch: 007 | loss: 0.69405 - acc: 0.4706 -- iter: 0288/1707
[A[ATraining Step: 334  | total loss: [1m[32m0.69397[0m[0m | time: 10.594s
[2K
| RMSProp | epoch: 007 | loss: 0.69397 - acc: 0.4641 -- iter: 0320/1707
[A[ATraining Step: 335  | total loss: [1m[32m0.69400[0m[0m | time: 12.032s
[2K
| RMSProp | epoch: 007 | loss: 0.69400 - acc: 0.4521 -- iter: 0352/1707
[A[ATraining Step: 336  | total loss: [1m[32m0.69391[0m[0m | time: 13.010s
[2K
| RMSProp | epoch: 007 | loss: 0.69391 - acc: 0.4600 -- iter: 0384/1707
[A[ATraining Step: 337  | total loss: [1m[32m0.69393[0m[0m | time: 14.068s
[2K
| RMSProp | epoch: 007 | loss: 0.69393 - acc: 0.4515 -- iter: 0416/1707
[A[ATraining Step: 338  | total loss: [1m[32m0.69391[0m[0m | time: 15.165s
[2K
| RMSProp | epoch: 007 | loss: 0.69391 - acc: 0.4439 -- iter: 0448/1707
[A[ATraining Step: 339  | total loss: [1m[32m0.69374[0m[0m | time: 16.360s
[2K
| RMSProp | epoch: 007 | loss: 0.69374 - acc: 0.4588 -- iter: 0480/1707
[A[ATraining Step: 340  | total loss: [1m[32m0.69406[0m[0m | time: 17.535s
[2K
| RMSProp | epoch: 007 | loss: 0.69406 - acc: 0.4411 -- iter: 0512/1707
[A[ATraining Step: 341  | total loss: [1m[32m0.69401[0m[0m | time: 18.691s
[2K
| RMSProp | epoch: 007 | loss: 0.69401 - acc: 0.4376 -- iter: 0544/1707
[A[ATraining Step: 342  | total loss: [1m[32m0.69389[0m[0m | time: 19.867s
[2K
| RMSProp | epoch: 007 | loss: 0.69389 - acc: 0.4563 -- iter: 0576/1707
[A[ATraining Step: 343  | total loss: [1m[32m0.69378[0m[0m | time: 20.890s
[2K
| RMSProp | epoch: 007 | loss: 0.69378 - acc: 0.4670 -- iter: 0608/1707
[A[ATraining Step: 344  | total loss: [1m[32m0.69388[0m[0m | time: 22.176s
[2K
| RMSProp | epoch: 007 | loss: 0.69388 - acc: 0.4640 -- iter: 0640/1707
[A[ATraining Step: 345  | total loss: [1m[32m0.69376[0m[0m | time: 23.516s
[2K
| RMSProp | epoch: 007 | loss: 0.69376 - acc: 0.4770 -- iter: 0672/1707
[A[ATraining Step: 346  | total loss: [1m[32m0.69376[0m[0m | time: 25.276s
[2K
| RMSProp | epoch: 007 | loss: 0.69376 - acc: 0.4762 -- iter: 0704/1707
[A[ATraining Step: 347  | total loss: [1m[32m0.69368[0m[0m | time: 26.766s
[2K
| RMSProp | epoch: 007 | loss: 0.69368 - acc: 0.4817 -- iter: 0736/1707
[A[ATraining Step: 348  | total loss: [1m[32m0.69396[0m[0m | time: 27.820s
[2K
| RMSProp | epoch: 007 | loss: 0.69396 - acc: 0.4648 -- iter: 0768/1707
[A[ATraining Step: 349  | total loss: [1m[32m0.69376[0m[0m | time: 29.013s
[2K
| RMSProp | epoch: 007 | loss: 0.69376 - acc: 0.4839 -- iter: 0800/1707
[A[ATraining Step: 350  | total loss: [1m[32m0.69360[0m[0m | time: 30.104s
[2K
| RMSProp | epoch: 007 | loss: 0.69360 - acc: 0.4886 -- iter: 0832/1707
[A[ATraining Step: 351  | total loss: [1m[32m0.69368[0m[0m | time: 31.198s
[2K
| RMSProp | epoch: 007 | loss: 0.69368 - acc: 0.4804 -- iter: 0864/1707
[A[ATraining Step: 352  | total loss: [1m[32m0.69352[0m[0m | time: 32.382s
[2K
| RMSProp | epoch: 007 | loss: 0.69352 - acc: 0.4917 -- iter: 0896/1707
[A[ATraining Step: 353  | total loss: [1m[32m0.69358[0m[0m | time: 33.477s
[2K
| RMSProp | epoch: 007 | loss: 0.69358 - acc: 0.4863 -- iter: 0928/1707
[A[ATraining Step: 354  | total loss: [1m[32m0.69348[0m[0m | time: 34.642s
[2K
| RMSProp | epoch: 007 | loss: 0.69348 - acc: 0.4908 -- iter: 0960/1707
[A[ATraining Step: 355  | total loss: [1m[32m0.69362[0m[0m | time: 35.657s
[2K
| RMSProp | epoch: 007 | loss: 0.69362 - acc: 0.4761 -- iter: 0992/1707
[A[ATraining Step: 356  | total loss: [1m[32m0.69332[0m[0m | time: 36.934s
[2K
| RMSProp | epoch: 007 | loss: 0.69332 - acc: 0.4879 -- iter: 1024/1707
[A[ATraining Step: 357  | total loss: [1m[32m0.69335[0m[0m | time: 38.215s
[2K
| RMSProp | epoch: 007 | loss: 0.69335 - acc: 0.4891 -- iter: 1056/1707
[A[ATraining Step: 358  | total loss: [1m[32m0.69278[0m[0m | time: 39.423s
[2K
| RMSProp | epoch: 007 | loss: 0.69278 - acc: 0.4995 -- iter: 1088/1707
[A[ATraining Step: 359  | total loss: [1m[32m0.69360[0m[0m | time: 40.648s
[2K
| RMSProp | epoch: 007 | loss: 0.69360 - acc: 0.4933 -- iter: 1120/1707
[A[ATraining Step: 360  | total loss: [1m[32m0.69296[0m[0m | time: 41.834s
[2K
| RMSProp | epoch: 007 | loss: 0.69296 - acc: 0.5065 -- iter: 1152/1707
[A[ATraining Step: 361  | total loss: [1m[32m0.69207[0m[0m | time: 43.075s
[2K
| RMSProp | epoch: 007 | loss: 0.69207 - acc: 0.5184 -- iter: 1184/1707
[A[ATraining Step: 362  | total loss: [1m[32m0.68993[0m[0m | time: 43.874s
[2K
| RMSProp | epoch: 007 | loss: 0.68993 - acc: 0.5259 -- iter: 1216/1707
[A[ATraining Step: 363  | total loss: [1m[32m0.70275[0m[0m | time: 44.627s
[2K
| RMSProp | epoch: 007 | loss: 0.70275 - acc: 0.5139 -- iter: 1248/1707
[A[ATraining Step: 364  | total loss: [1m[32m0.70130[0m[0m | time: 45.385s
[2K
| RMSProp | epoch: 007 | loss: 0.70130 - acc: 0.5157 -- iter: 1280/1707
[A[ATraining Step: 365  | total loss: [1m[32m0.70091[0m[0m | time: 46.175s
[2K
| RMSProp | epoch: 007 | loss: 0.70091 - acc: 0.5078 -- iter: 1312/1707
[A[ATraining Step: 366  | total loss: [1m[32m0.70057[0m[0m | time: 46.981s
[2K
| RMSProp | epoch: 007 | loss: 0.70057 - acc: 0.5008 -- iter: 1344/1707
[A[ATraining Step: 367  | total loss: [1m[32m0.69968[0m[0m | time: 47.747s
[2K
| RMSProp | epoch: 007 | loss: 0.69968 - acc: 0.5007 -- iter: 1376/1707
[A[ATraining Step: 368  | total loss: [1m[32m0.69895[0m[0m | time: 48.497s
[2K
| RMSProp | epoch: 007 | loss: 0.69895 - acc: 0.5038 -- iter: 1408/1707
[A[ATraining Step: 369  | total loss: [1m[32m0.69795[0m[0m | time: 49.275s
[2K
| RMSProp | epoch: 007 | loss: 0.69795 - acc: 0.5190 -- iter: 1440/1707
[A[ATraining Step: 370  | total loss: [1m[32m0.69713[0m[0m | time: 50.084s
[2K
| RMSProp | epoch: 007 | loss: 0.69713 - acc: 0.5171 -- iter: 1472/1707
[A[ATraining Step: 371  | total loss: [1m[32m0.69592[0m[0m | time: 50.834s
[2K
| RMSProp | epoch: 007 | loss: 0.69592 - acc: 0.5217 -- iter: 1504/1707
[A[ATraining Step: 372  | total loss: [1m[32m0.69496[0m[0m | time: 51.611s
[2K
| RMSProp | epoch: 007 | loss: 0.69496 - acc: 0.5257 -- iter: 1536/1707
[A[ATraining Step: 373  | total loss: [1m[32m0.69345[0m[0m | time: 52.393s
[2K
| RMSProp | epoch: 007 | loss: 0.69345 - acc: 0.5294 -- iter: 1568/1707
[A[ATraining Step: 374  | total loss: [1m[32m0.69327[0m[0m | time: 53.196s
[2K
| RMSProp | epoch: 007 | loss: 0.69327 - acc: 0.5265 -- iter: 1600/1707
[A[ATraining Step: 375  | total loss: [1m[32m0.69287[0m[0m | time: 53.971s
[2K
| RMSProp | epoch: 007 | loss: 0.69287 - acc: 0.5238 -- iter: 1632/1707
[A[ATraining Step: 376  | total loss: [1m[32m0.69317[0m[0m | time: 54.751s
[2K
| RMSProp | epoch: 007 | loss: 0.69317 - acc: 0.5089 -- iter: 1664/1707
[A[ATraining Step: 377  | total loss: [1m[32m0.69281[0m[0m | time: 55.579s
[2K
| RMSProp | epoch: 007 | loss: 0.69281 - acc: 0.5143 -- iter: 1696/1707
[A[ATraining Step: 378  | total loss: [1m[32m0.69335[0m[0m | time: 58.488s
[2K
| RMSProp | epoch: 007 | loss: 0.69335 - acc: 0.5035 | val_loss: 0.68353 - val_acc: 0.6386 -- iter: 1707/1707
--
Training Step: 379  | total loss: [1m[32m0.69309[0m[0m | time: 0.735s
[2K
| RMSProp | epoch: 008 | loss: 0.69309 - acc: 0.5188 -- iter: 0032/1707
[A[ATraining Step: 380  | total loss: [1m[32m0.69368[0m[0m | time: 1.482s
[2K
| RMSProp | epoch: 008 | loss: 0.69368 - acc: 0.5075 -- iter: 0064/1707
[A[ATraining Step: 381  | total loss: [1m[32m0.69361[0m[0m | time: 2.236s
[2K
| RMSProp | epoch: 008 | loss: 0.69361 - acc: 0.5099 -- iter: 0096/1707
[A[ATraining Step: 382  | total loss: [1m[32m0.69387[0m[0m | time: 2.980s
[2K
| RMSProp | epoch: 008 | loss: 0.69387 - acc: 0.4995 -- iter: 0128/1707
[A[ATraining Step: 383  | total loss: [1m[32m0.69353[0m[0m | time: 3.739s
[2K
| RMSProp | epoch: 008 | loss: 0.69353 - acc: 0.5183 -- iter: 0160/1707
[A[ATraining Step: 384  | total loss: [1m[32m0.69284[0m[0m | time: 4.001s
[2K
| RMSProp | epoch: 008 | loss: 0.69284 - acc: 0.5352 -- iter: 0192/1707
[A[ATraining Step: 385  | total loss: [1m[32m0.69332[0m[0m | time: 4.347s
[2K
| RMSProp | epoch: 008 | loss: 0.69332 - acc: 0.5090 -- iter: 0224/1707
[A[ATraining Step: 386  | total loss: [1m[32m0.68933[0m[0m | time: 5.166s
[2K
| RMSProp | epoch: 008 | loss: 0.68933 - acc: 0.5308 -- iter: 0256/1707
[A[ATraining Step: 387  | total loss: [1m[32m0.68353[0m[0m | time: 5.924s
[2K
| RMSProp | epoch: 008 | loss: 0.68353 - acc: 0.5434 -- iter: 0288/1707
[A[ATraining Step: 388  | total loss: [1m[32m0.67919[0m[0m | time: 6.687s
[2K
| RMSProp | epoch: 008 | loss: 0.67919 - acc: 0.5547 -- iter: 0320/1707
[A[ATraining Step: 389  | total loss: [1m[32m0.68102[0m[0m | time: 7.440s
[2K
| RMSProp | epoch: 008 | loss: 0.68102 - acc: 0.5461 -- iter: 0352/1707
[A[ATraining Step: 390  | total loss: [1m[32m0.68259[0m[0m | time: 8.211s
[2K
| RMSProp | epoch: 008 | loss: 0.68259 - acc: 0.5321 -- iter: 0384/1707
[A[ATraining Step: 391  | total loss: [1m[32m0.68340[0m[0m | time: 9.024s
[2K
| RMSProp | epoch: 008 | loss: 0.68340 - acc: 0.5320 -- iter: 0416/1707
[A[ATraining Step: 392  | total loss: [1m[32m0.68424[0m[0m | time: 10.349s
[2K
| RMSProp | epoch: 008 | loss: 0.68424 - acc: 0.5350 -- iter: 0448/1707
[A[ATraining Step: 393  | total loss: [1m[32m0.68420[0m[0m | time: 11.649s
[2K
| RMSProp | epoch: 008 | loss: 0.68420 - acc: 0.5503 -- iter: 0480/1707
[A[ATraining Step: 394  | total loss: [1m[32m0.68416[0m[0m | time: 12.877s
[2K
| RMSProp | epoch: 008 | loss: 0.68416 - acc: 0.5578 -- iter: 0512/1707
[A[ATraining Step: 395  | total loss: [1m[32m0.68410[0m[0m | time: 14.106s
[2K
| RMSProp | epoch: 008 | loss: 0.68410 - acc: 0.5582 -- iter: 0544/1707
[A[ATraining Step: 396  | total loss: [1m[32m0.68478[0m[0m | time: 15.352s
[2K
| RMSProp | epoch: 008 | loss: 0.68478 - acc: 0.5555 -- iter: 0576/1707
[A[ATraining Step: 397  | total loss: [1m[32m0.68466[0m[0m | time: 16.658s
[2K
| RMSProp | epoch: 008 | loss: 0.68466 - acc: 0.5594 -- iter: 0608/1707
[A[ATraining Step: 398  | total loss: [1m[32m0.68595[0m[0m | time: 18.008s
[2K
| RMSProp | epoch: 008 | loss: 0.68595 - acc: 0.5503 -- iter: 0640/1707
[A[ATraining Step: 399  | total loss: [1m[32m0.68408[0m[0m | time: 19.436s
[2K
| RMSProp | epoch: 008 | loss: 0.68408 - acc: 0.5765 -- iter: 0672/1707
[A[ATraining Step: 400  | total loss: [1m[32m0.68202[0m[0m | time: 23.936s
[2K
| RMSProp | epoch: 008 | loss: 0.68202 - acc: 0.5907 | val_loss: 0.67101 - val_acc: 0.5524 -- iter: 0704/1707
--
Training Step: 401  | total loss: [1m[32m0.68305[0m[0m | time: 24.694s
[2K
| RMSProp | epoch: 008 | loss: 0.68305 - acc: 0.5910 -- iter: 0736/1707
[A[ATraining Step: 402  | total loss: [1m[32m0.67839[0m[0m | time: 25.511s
[2K
| RMSProp | epoch: 008 | loss: 0.67839 - acc: 0.5944 -- iter: 0768/1707
[A[ATraining Step: 403  | total loss: [1m[32m0.67661[0m[0m | time: 26.309s
[2K
| RMSProp | epoch: 008 | loss: 0.67661 - acc: 0.5975 -- iter: 0800/1707
[A[ATraining Step: 404  | total loss: [1m[32m0.67924[0m[0m | time: 27.030s
[2K
| RMSProp | epoch: 008 | loss: 0.67924 - acc: 0.5784 -- iter: 0832/1707
[A[ATraining Step: 405  | total loss: [1m[32m0.67808[0m[0m | time: 27.762s
[2K
| RMSProp | epoch: 008 | loss: 0.67808 - acc: 0.5893 -- iter: 0864/1707
[A[ATraining Step: 406  | total loss: [1m[32m0.67764[0m[0m | time: 28.512s
[2K
| RMSProp | epoch: 008 | loss: 0.67764 - acc: 0.5960 -- iter: 0896/1707
[A[ATraining Step: 407  | total loss: [1m[32m0.68268[0m[0m | time: 29.286s
[2K
| RMSProp | epoch: 008 | loss: 0.68268 - acc: 0.5801 -- iter: 0928/1707
[A[ATraining Step: 408  | total loss: [1m[32m0.67857[0m[0m | time: 30.038s
[2K
| RMSProp | epoch: 008 | loss: 0.67857 - acc: 0.5971 -- iter: 0960/1707
[A[ATraining Step: 409  | total loss: [1m[32m0.68844[0m[0m | time: 30.755s
[2K
| RMSProp | epoch: 008 | loss: 0.68844 - acc: 0.5780 -- iter: 0992/1707
[A[ATraining Step: 410  | total loss: [1m[32m0.68973[0m[0m | time: 31.503s
[2K
| RMSProp | epoch: 008 | loss: 0.68973 - acc: 0.5609 -- iter: 1024/1707
[A[ATraining Step: 411  | total loss: [1m[32m0.68849[0m[0m | time: 32.240s
[2K
| RMSProp | epoch: 008 | loss: 0.68849 - acc: 0.5641 -- iter: 1056/1707
[A[ATraining Step: 412  | total loss: [1m[32m0.68773[0m[0m | time: 33.017s
[2K
| RMSProp | epoch: 008 | loss: 0.68773 - acc: 0.5546 -- iter: 1088/1707
[A[ATraining Step: 413  | total loss: [1m[32m0.68865[0m[0m | time: 33.728s
[2K
| RMSProp | epoch: 008 | loss: 0.68865 - acc: 0.5523 -- iter: 1120/1707
[A[ATraining Step: 414  | total loss: [1m[32m0.68809[0m[0m | time: 34.494s
[2K
| RMSProp | epoch: 008 | loss: 0.68809 - acc: 0.5533 -- iter: 1152/1707
[A[ATraining Step: 415  | total loss: [1m[32m0.68503[0m[0m | time: 35.244s
[2K
| RMSProp | epoch: 008 | loss: 0.68503 - acc: 0.5730 -- iter: 1184/1707
[A[ATraining Step: 416  | total loss: [1m[32m0.68541[0m[0m | time: 35.990s
[2K
| RMSProp | epoch: 008 | loss: 0.68541 - acc: 0.5625 -- iter: 1216/1707
[A[ATraining Step: 417  | total loss: [1m[32m0.68439[0m[0m | time: 36.742s
[2K
| RMSProp | epoch: 008 | loss: 0.68439 - acc: 0.5657 -- iter: 1248/1707
[A[ATraining Step: 418  | total loss: [1m[32m0.68032[0m[0m | time: 37.479s
[2K
| RMSProp | epoch: 008 | loss: 0.68032 - acc: 0.5810 -- iter: 1280/1707
[A[ATraining Step: 419  | total loss: [1m[32m0.67643[0m[0m | time: 38.233s
[2K
| RMSProp | epoch: 008 | loss: 0.67643 - acc: 0.5916 -- iter: 1312/1707
[A[ATraining Step: 420  | total loss: [1m[32m0.67434[0m[0m | time: 39.003s
[2K
| RMSProp | epoch: 008 | loss: 0.67434 - acc: 0.5918 -- iter: 1344/1707
[A[ATraining Step: 421  | total loss: [1m[32m0.67321[0m[0m | time: 39.807s
[2K
| RMSProp | epoch: 008 | loss: 0.67321 - acc: 0.5983 -- iter: 1376/1707
[A[ATraining Step: 422  | total loss: [1m[32m0.67932[0m[0m | time: 40.896s
[2K
| RMSProp | epoch: 008 | loss: 0.67932 - acc: 0.5853 -- iter: 1408/1707
[A[ATraining Step: 423  | total loss: [1m[32m0.68194[0m[0m | time: 41.956s
[2K
| RMSProp | epoch: 008 | loss: 0.68194 - acc: 0.5705 -- iter: 1440/1707
[A[ATraining Step: 424  | total loss: [1m[32m0.67896[0m[0m | time: 42.886s
[2K
| RMSProp | epoch: 008 | loss: 0.67896 - acc: 0.5791 -- iter: 1472/1707
[A[ATraining Step: 425  | total loss: [1m[32m0.67225[0m[0m | time: 43.576s
[2K
| RMSProp | epoch: 008 | loss: 0.67225 - acc: 0.5931 -- iter: 1504/1707
[A[ATraining Step: 426  | total loss: [1m[32m0.66417[0m[0m | time: 44.363s
[2K
| RMSProp | epoch: 008 | loss: 0.66417 - acc: 0.6056 -- iter: 1536/1707
[A[ATraining Step: 427  | total loss: [1m[32m0.66405[0m[0m | time: 45.132s
[2K
| RMSProp | epoch: 008 | loss: 0.66405 - acc: 0.6045 -- iter: 1568/1707
[A[ATraining Step: 428  | total loss: [1m[32m0.66841[0m[0m | time: 45.858s
[2K
| RMSProp | epoch: 008 | loss: 0.66841 - acc: 0.5971 -- iter: 1600/1707
[A[ATraining Step: 429  | total loss: [1m[32m0.66653[0m[0m | time: 46.584s
[2K
| RMSProp | epoch: 008 | loss: 0.66653 - acc: 0.5968 -- iter: 1632/1707
[A[ATraining Step: 430  | total loss: [1m[32m0.66809[0m[0m | time: 47.329s
[2K
| RMSProp | epoch: 008 | loss: 0.66809 - acc: 0.5996 -- iter: 1664/1707
[A[ATraining Step: 431  | total loss: [1m[32m0.66228[0m[0m | time: 48.069s
[2K
| RMSProp | epoch: 008 | loss: 0.66228 - acc: 0.6115 -- iter: 1696/1707
[A[ATraining Step: 432  | total loss: [1m[32m0.65875[0m[0m | time: 50.966s
[2K
| RMSProp | epoch: 008 | loss: 0.65875 - acc: 0.6129 | val_loss: 0.64688 - val_acc: 0.6311 -- iter: 1707/1707
--
Training Step: 433  | total loss: [1m[32m0.66279[0m[0m | time: 0.748s
[2K
| RMSProp | epoch: 009 | loss: 0.66279 - acc: 0.6078 -- iter: 0032/1707
[A[ATraining Step: 434  | total loss: [1m[32m0.66227[0m[0m | time: 1.486s
[2K
| RMSProp | epoch: 009 | loss: 0.66227 - acc: 0.6127 -- iter: 0064/1707
[A[ATraining Step: 435  | total loss: [1m[32m0.65814[0m[0m | time: 2.244s
[2K
| RMSProp | epoch: 009 | loss: 0.65814 - acc: 0.6202 -- iter: 0096/1707
[A[ATraining Step: 436  | total loss: [1m[32m0.65490[0m[0m | time: 3.013s
[2K
| RMSProp | epoch: 009 | loss: 0.65490 - acc: 0.6175 -- iter: 0128/1707
[A[ATraining Step: 437  | total loss: [1m[32m0.66036[0m[0m | time: 3.777s
[2K
| RMSProp | epoch: 009 | loss: 0.66036 - acc: 0.6120 -- iter: 0160/1707
[A[ATraining Step: 438  | total loss: [1m[32m0.66116[0m[0m | time: 4.493s
[2K
| RMSProp | epoch: 009 | loss: 0.66116 - acc: 0.6102 -- iter: 0192/1707
[A[ATraining Step: 439  | total loss: [1m[32m0.65654[0m[0m | time: 4.773s
[2K
| RMSProp | epoch: 009 | loss: 0.65654 - acc: 0.6210 -- iter: 0224/1707
[A[ATraining Step: 440  | total loss: [1m[32m0.66043[0m[0m | time: 5.136s
[2K
| RMSProp | epoch: 009 | loss: 0.66043 - acc: 0.6044 -- iter: 0256/1707
[A[ATraining Step: 441  | total loss: [1m[32m0.65780[0m[0m | time: 5.889s
[2K
| RMSProp | epoch: 009 | loss: 0.65780 - acc: 0.6167 -- iter: 0288/1707
[A[ATraining Step: 442  | total loss: [1m[32m0.65407[0m[0m | time: 6.659s
[2K
| RMSProp | epoch: 009 | loss: 0.65407 - acc: 0.6175 -- iter: 0320/1707
[A[ATraining Step: 443  | total loss: [1m[32m0.65481[0m[0m | time: 7.421s
[2K
| RMSProp | epoch: 009 | loss: 0.65481 - acc: 0.6151 -- iter: 0352/1707
[A[ATraining Step: 444  | total loss: [1m[32m0.65055[0m[0m | time: 8.162s
[2K
| RMSProp | epoch: 009 | loss: 0.65055 - acc: 0.6255 -- iter: 0384/1707
[A[ATraining Step: 445  | total loss: [1m[32m0.64334[0m[0m | time: 8.923s
[2K
| RMSProp | epoch: 009 | loss: 0.64334 - acc: 0.6380 -- iter: 0416/1707
[A[ATraining Step: 446  | total loss: [1m[32m0.65662[0m[0m | time: 9.655s
[2K
| RMSProp | epoch: 009 | loss: 0.65662 - acc: 0.6210 -- iter: 0448/1707
[A[ATraining Step: 447  | total loss: [1m[32m0.65347[0m[0m | time: 10.383s
[2K
| RMSProp | epoch: 009 | loss: 0.65347 - acc: 0.6246 -- iter: 0480/1707
[A[ATraining Step: 448  | total loss: [1m[32m0.64896[0m[0m | time: 11.104s
[2K
| RMSProp | epoch: 009 | loss: 0.64896 - acc: 0.6340 -- iter: 0512/1707
[A[ATraining Step: 449  | total loss: [1m[32m0.65242[0m[0m | time: 11.834s
[2K
| RMSProp | epoch: 009 | loss: 0.65242 - acc: 0.6237 -- iter: 0544/1707
[A[ATraining Step: 450  | total loss: [1m[32m0.65427[0m[0m | time: 12.579s
[2K
| RMSProp | epoch: 009 | loss: 0.65427 - acc: 0.6207 -- iter: 0576/1707
[A[ATraining Step: 451  | total loss: [1m[32m0.65588[0m[0m | time: 13.328s
[2K
| RMSProp | epoch: 009 | loss: 0.65588 - acc: 0.6211 -- iter: 0608/1707
[A[ATraining Step: 452  | total loss: [1m[32m0.65763[0m[0m | time: 14.057s
[2K
| RMSProp | epoch: 009 | loss: 0.65763 - acc: 0.6121 -- iter: 0640/1707
[A[ATraining Step: 453  | total loss: [1m[32m0.65705[0m[0m | time: 14.784s
[2K
| RMSProp | epoch: 009 | loss: 0.65705 - acc: 0.6197 -- iter: 0672/1707
[A[ATraining Step: 454  | total loss: [1m[32m0.64807[0m[0m | time: 15.521s
[2K
| RMSProp | epoch: 009 | loss: 0.64807 - acc: 0.6390 -- iter: 0704/1707
[A[ATraining Step: 455  | total loss: [1m[32m0.65371[0m[0m | time: 16.250s
[2K
| RMSProp | epoch: 009 | loss: 0.65371 - acc: 0.6344 -- iter: 0736/1707
[A[ATraining Step: 456  | total loss: [1m[32m0.66721[0m[0m | time: 17.023s
[2K
| RMSProp | epoch: 009 | loss: 0.66721 - acc: 0.6116 -- iter: 0768/1707
[A[ATraining Step: 457  | total loss: [1m[32m0.66510[0m[0m | time: 17.776s
[2K
| RMSProp | epoch: 009 | loss: 0.66510 - acc: 0.6130 -- iter: 0800/1707
[A[ATraining Step: 458  | total loss: [1m[32m0.66537[0m[0m | time: 18.582s
[2K
| RMSProp | epoch: 009 | loss: 0.66537 - acc: 0.6017 -- iter: 0832/1707
[A[ATraining Step: 459  | total loss: [1m[32m0.66657[0m[0m | time: 19.381s
[2K
| RMSProp | epoch: 009 | loss: 0.66657 - acc: 0.5977 -- iter: 0864/1707
[A[ATraining Step: 460  | total loss: [1m[32m0.65978[0m[0m | time: 20.107s
[2K
| RMSProp | epoch: 009 | loss: 0.65978 - acc: 0.6130 -- iter: 0896/1707
[A[ATraining Step: 461  | total loss: [1m[32m0.66334[0m[0m | time: 20.841s
[2K
| RMSProp | epoch: 009 | loss: 0.66334 - acc: 0.6048 -- iter: 0928/1707
[A[ATraining Step: 462  | total loss: [1m[32m0.67049[0m[0m | time: 21.699s
[2K
| RMSProp | epoch: 009 | loss: 0.67049 - acc: 0.5912 -- iter: 0960/1707
[A[ATraining Step: 463  | total loss: [1m[32m0.66868[0m[0m | time: 22.830s
[2K
| RMSProp | epoch: 009 | loss: 0.66868 - acc: 0.5915 -- iter: 0992/1707
[A[ATraining Step: 464  | total loss: [1m[32m0.66143[0m[0m | time: 23.913s
[2K
| RMSProp | epoch: 009 | loss: 0.66143 - acc: 0.6042 -- iter: 1024/1707
[A[ATraining Step: 465  | total loss: [1m[32m0.65244[0m[0m | time: 24.740s
[2K
| RMSProp | epoch: 009 | loss: 0.65244 - acc: 0.6219 -- iter: 1056/1707
[A[ATraining Step: 466  | total loss: [1m[32m0.65055[0m[0m | time: 25.360s
[2K
| RMSProp | epoch: 009 | loss: 0.65055 - acc: 0.6253 -- iter: 1088/1707
[A[ATraining Step: 467  | total loss: [1m[32m0.63795[0m[0m | time: 26.185s
[2K
| RMSProp | epoch: 009 | loss: 0.63795 - acc: 0.6472 -- iter: 1120/1707
[A[ATraining Step: 468  | total loss: [1m[32m0.63752[0m[0m | time: 26.981s
[2K
| RMSProp | epoch: 009 | loss: 0.63752 - acc: 0.6418 -- iter: 1152/1707
[A[ATraining Step: 469  | total loss: [1m[32m0.63796[0m[0m | time: 27.759s
[2K
| RMSProp | epoch: 009 | loss: 0.63796 - acc: 0.6339 -- iter: 1184/1707
[A[ATraining Step: 470  | total loss: [1m[32m0.64367[0m[0m | time: 28.561s
[2K
| RMSProp | epoch: 009 | loss: 0.64367 - acc: 0.6205 -- iter: 1216/1707
[A[ATraining Step: 471  | total loss: [1m[32m0.64856[0m[0m | time: 29.401s
[2K
| RMSProp | epoch: 009 | loss: 0.64856 - acc: 0.6147 -- iter: 1248/1707
[A[ATraining Step: 472  | total loss: [1m[32m0.64045[0m[0m | time: 30.231s
[2K
| RMSProp | epoch: 009 | loss: 0.64045 - acc: 0.6282 -- iter: 1280/1707
[A[ATraining Step: 473  | total loss: [1m[32m0.63914[0m[0m | time: 30.985s
[2K
| RMSProp | epoch: 009 | loss: 0.63914 - acc: 0.6342 -- iter: 1312/1707
[A[ATraining Step: 474  | total loss: [1m[32m0.64474[0m[0m | time: 31.777s
[2K
| RMSProp | epoch: 009 | loss: 0.64474 - acc: 0.6239 -- iter: 1344/1707
[A[ATraining Step: 475  | total loss: [1m[32m0.63015[0m[0m | time: 32.608s
[2K
| RMSProp | epoch: 009 | loss: 0.63015 - acc: 0.6427 -- iter: 1376/1707
[A[ATraining Step: 476  | total loss: [1m[32m0.62526[0m[0m | time: 33.333s
[2K
| RMSProp | epoch: 009 | loss: 0.62526 - acc: 0.6472 -- iter: 1408/1707
[A[ATraining Step: 477  | total loss: [1m[32m0.61838[0m[0m | time: 34.084s
[2K
| RMSProp | epoch: 009 | loss: 0.61838 - acc: 0.6606 -- iter: 1440/1707
[A[ATraining Step: 478  | total loss: [1m[32m0.60843[0m[0m | time: 34.829s
[2K
| RMSProp | epoch: 009 | loss: 0.60843 - acc: 0.6727 -- iter: 1472/1707
[A[ATraining Step: 479  | total loss: [1m[32m0.63429[0m[0m | time: 35.575s
[2K
| RMSProp | epoch: 009 | loss: 0.63429 - acc: 0.6554 -- iter: 1504/1707
[A[ATraining Step: 480  | total loss: [1m[32m0.63878[0m[0m | time: 36.340s
[2K
| RMSProp | epoch: 009 | loss: 0.63878 - acc: 0.6492 -- iter: 1536/1707
[A[ATraining Step: 481  | total loss: [1m[32m0.64297[0m[0m | time: 37.101s
[2K
| RMSProp | epoch: 009 | loss: 0.64297 - acc: 0.6374 -- iter: 1568/1707
[A[ATraining Step: 482  | total loss: [1m[32m0.63711[0m[0m | time: 37.855s
[2K
| RMSProp | epoch: 009 | loss: 0.63711 - acc: 0.6518 -- iter: 1600/1707
[A[ATraining Step: 483  | total loss: [1m[32m0.62883[0m[0m | time: 38.603s
[2K
| RMSProp | epoch: 009 | loss: 0.62883 - acc: 0.6554 -- iter: 1632/1707
[A[ATraining Step: 484  | total loss: [1m[32m0.61901[0m[0m | time: 39.369s
[2K
| RMSProp | epoch: 009 | loss: 0.61901 - acc: 0.6742 -- iter: 1664/1707
[A[ATraining Step: 485  | total loss: [1m[32m0.60747[0m[0m | time: 40.109s
[2K
| RMSProp | epoch: 009 | loss: 0.60747 - acc: 0.6881 -- iter: 1696/1707
[A[ATraining Step: 486  | total loss: [1m[32m0.60231[0m[0m | time: 43.015s
[2K
| RMSProp | epoch: 009 | loss: 0.60231 - acc: 0.6911 | val_loss: 0.54302 - val_acc: 0.7491 -- iter: 1707/1707
--
Training Step: 487  | total loss: [1m[32m0.60359[0m[0m | time: 0.781s
[2K
| RMSProp | epoch: 010 | loss: 0.60359 - acc: 0.6814 -- iter: 0032/1707
[A[ATraining Step: 488  | total loss: [1m[32m0.59056[0m[0m | time: 1.545s
[2K
| RMSProp | epoch: 010 | loss: 0.59056 - acc: 0.6945 -- iter: 0064/1707
[A[ATraining Step: 489  | total loss: [1m[32m0.58922[0m[0m | time: 2.292s
[2K
| RMSProp | epoch: 010 | loss: 0.58922 - acc: 0.6907 -- iter: 0096/1707
[A[ATraining Step: 490  | total loss: [1m[32m0.59616[0m[0m | time: 3.070s
[2K
| RMSProp | epoch: 010 | loss: 0.59616 - acc: 0.6810 -- iter: 0128/1707
[A[ATraining Step: 491  | total loss: [1m[32m0.60167[0m[0m | time: 3.824s
[2K
| RMSProp | epoch: 010 | loss: 0.60167 - acc: 0.6785 -- iter: 0160/1707
[A[ATraining Step: 492  | total loss: [1m[32m0.60200[0m[0m | time: 4.566s
[2K
| RMSProp | epoch: 010 | loss: 0.60200 - acc: 0.6794 -- iter: 0192/1707
[A[ATraining Step: 493  | total loss: [1m[32m0.58922[0m[0m | time: 5.330s
[2K
| RMSProp | epoch: 010 | loss: 0.58922 - acc: 0.6990 -- iter: 0224/1707
[A[ATraining Step: 494  | total loss: [1m[32m0.57971[0m[0m | time: 5.590s
[2K
| RMSProp | epoch: 010 | loss: 0.57971 - acc: 0.7041 -- iter: 0256/1707
[A[ATraining Step: 495  | total loss: [1m[32m0.58158[0m[0m | time: 5.959s
[2K
| RMSProp | epoch: 010 | loss: 0.58158 - acc: 0.6973 -- iter: 0288/1707
[A[ATraining Step: 496  | total loss: [1m[32m0.56927[0m[0m | time: 6.715s
[2K
| RMSProp | epoch: 010 | loss: 0.56927 - acc: 0.7094 -- iter: 0320/1707
[A[ATraining Step: 497  | total loss: [1m[32m0.56440[0m[0m | time: 7.414s
[2K
| RMSProp | epoch: 010 | loss: 0.56440 - acc: 0.7103 -- iter: 0352/1707
[A[ATraining Step: 498  | total loss: [1m[32m0.56820[0m[0m | time: 8.221s
[2K
| RMSProp | epoch: 010 | loss: 0.56820 - acc: 0.7080 -- iter: 0384/1707
[A[ATraining Step: 499  | total loss: [1m[32m0.56935[0m[0m | time: 8.946s
[2K
| RMSProp | epoch: 010 | loss: 0.56935 - acc: 0.6966 -- iter: 0416/1707
[A[ATraining Step: 500  | total loss: [1m[32m0.56557[0m[0m | time: 9.709s
[2K
| RMSProp | epoch: 010 | loss: 0.56557 - acc: 0.7020 -- iter: 0448/1707
[A[ATraining Step: 501  | total loss: [1m[32m0.56878[0m[0m | time: 10.453s
[2K
| RMSProp | epoch: 010 | loss: 0.56878 - acc: 0.6974 -- iter: 0480/1707
[A[ATraining Step: 502  | total loss: [1m[32m0.58653[0m[0m | time: 11.269s
[2K
| RMSProp | epoch: 010 | loss: 0.58653 - acc: 0.6870 -- iter: 0512/1707
[A[ATraining Step: 503  | total loss: [1m[32m0.58623[0m[0m | time: 12.397s
[2K
| RMSProp | epoch: 010 | loss: 0.58623 - acc: 0.6902 -- iter: 0544/1707
[A[ATraining Step: 504  | total loss: [1m[32m0.58118[0m[0m | time: 13.542s
[2K
| RMSProp | epoch: 010 | loss: 0.58118 - acc: 0.6868 -- iter: 0576/1707
[A[ATraining Step: 505  | total loss: [1m[32m0.57920[0m[0m | time: 14.375s
[2K
| RMSProp | epoch: 010 | loss: 0.57920 - acc: 0.6869 -- iter: 0608/1707
[A[ATraining Step: 506  | total loss: [1m[32m0.57402[0m[0m | time: 15.048s
[2K
| RMSProp | epoch: 010 | loss: 0.57402 - acc: 0.6901 -- iter: 0640/1707
[A[ATraining Step: 507  | total loss: [1m[32m0.56832[0m[0m | time: 15.813s
[2K
| RMSProp | epoch: 010 | loss: 0.56832 - acc: 0.6960 -- iter: 0672/1707
[A[ATraining Step: 508  | total loss: [1m[32m0.56841[0m[0m | time: 16.543s
[2K
| RMSProp | epoch: 010 | loss: 0.56841 - acc: 0.6952 -- iter: 0704/1707
[A[ATraining Step: 509  | total loss: [1m[32m0.55764[0m[0m | time: 17.326s
[2K
| RMSProp | epoch: 010 | loss: 0.55764 - acc: 0.7038 -- iter: 0736/1707
[A[ATraining Step: 510  | total loss: [1m[32m0.57514[0m[0m | time: 18.087s
[2K
| RMSProp | epoch: 010 | loss: 0.57514 - acc: 0.6897 -- iter: 0768/1707
[A[ATraining Step: 511  | total loss: [1m[32m0.57317[0m[0m | time: 18.811s
[2K
| RMSProp | epoch: 010 | loss: 0.57317 - acc: 0.6895 -- iter: 0800/1707
[A[ATraining Step: 512  | total loss: [1m[32m0.58737[0m[0m | time: 19.538s
[2K
| RMSProp | epoch: 010 | loss: 0.58737 - acc: 0.6736 -- iter: 0832/1707
[A[ATraining Step: 513  | total loss: [1m[32m0.59656[0m[0m | time: 20.273s
[2K
| RMSProp | epoch: 010 | loss: 0.59656 - acc: 0.6688 -- iter: 0864/1707
[A[ATraining Step: 514  | total loss: [1m[32m0.58777[0m[0m | time: 21.015s
[2K
| RMSProp | epoch: 010 | loss: 0.58777 - acc: 0.6831 -- iter: 0896/1707
[A[ATraining Step: 515  | total loss: [1m[32m0.57169[0m[0m | time: 21.820s
[2K
| RMSProp | epoch: 010 | loss: 0.57169 - acc: 0.6961 -- iter: 0928/1707
[A[ATraining Step: 516  | total loss: [1m[32m0.58212[0m[0m | time: 22.592s
[2K
| RMSProp | epoch: 010 | loss: 0.58212 - acc: 0.6921 -- iter: 0960/1707
[A[ATraining Step: 517  | total loss: [1m[32m0.57967[0m[0m | time: 23.387s
[2K
| RMSProp | epoch: 010 | loss: 0.57967 - acc: 0.6916 -- iter: 0992/1707
[A[ATraining Step: 518  | total loss: [1m[32m0.58701[0m[0m | time: 24.143s
[2K
| RMSProp | epoch: 010 | loss: 0.58701 - acc: 0.6850 -- iter: 1024/1707
[A[ATraining Step: 519  | total loss: [1m[32m0.57847[0m[0m | time: 24.922s
[2K
| RMSProp | epoch: 010 | loss: 0.57847 - acc: 0.6977 -- iter: 1056/1707
[A[ATraining Step: 520  | total loss: [1m[32m0.55899[0m[0m | time: 25.663s
[2K
| RMSProp | epoch: 010 | loss: 0.55899 - acc: 0.7186 -- iter: 1088/1707
[A[ATraining Step: 521  | total loss: [1m[32m0.56676[0m[0m | time: 26.414s
[2K
| RMSProp | epoch: 010 | loss: 0.56676 - acc: 0.7155 -- iter: 1120/1707
[A[ATraining Step: 522  | total loss: [1m[32m0.58630[0m[0m | time: 27.203s
[2K
| RMSProp | epoch: 010 | loss: 0.58630 - acc: 0.6970 -- iter: 1152/1707
[A[ATraining Step: 523  | total loss: [1m[32m0.57719[0m[0m | time: 27.960s
[2K
| RMSProp | epoch: 010 | loss: 0.57719 - acc: 0.7055 -- iter: 1184/1707
[A[ATraining Step: 524  | total loss: [1m[32m0.56951[0m[0m | time: 28.689s
[2K
| RMSProp | epoch: 010 | loss: 0.56951 - acc: 0.7130 -- iter: 1216/1707
[A[ATraining Step: 525  | total loss: [1m[32m0.55923[0m[0m | time: 29.445s
[2K
| RMSProp | epoch: 010 | loss: 0.55923 - acc: 0.7167 -- iter: 1248/1707
[A[ATraining Step: 526  | total loss: [1m[32m0.55939[0m[0m | time: 30.212s
[2K
| RMSProp | epoch: 010 | loss: 0.55939 - acc: 0.7138 -- iter: 1280/1707
[A[ATraining Step: 527  | total loss: [1m[32m0.55939[0m[0m | time: 31.005s
[2K
| RMSProp | epoch: 010 | loss: 0.55939 - acc: 0.7143 -- iter: 1312/1707
[A[ATraining Step: 528  | total loss: [1m[32m0.55234[0m[0m | time: 31.806s
[2K
| RMSProp | epoch: 010 | loss: 0.55234 - acc: 0.7210 -- iter: 1344/1707
[A[ATraining Step: 529  | total loss: [1m[32m0.53848[0m[0m | time: 32.596s
[2K
| RMSProp | epoch: 010 | loss: 0.53848 - acc: 0.7239 -- iter: 1376/1707
[A[ATraining Step: 530  | total loss: [1m[32m0.54746[0m[0m | time: 33.332s
[2K
| RMSProp | epoch: 010 | loss: 0.54746 - acc: 0.7171 -- iter: 1408/1707
[A[ATraining Step: 531  | total loss: [1m[32m0.54208[0m[0m | time: 34.130s
[2K
| RMSProp | epoch: 010 | loss: 0.54208 - acc: 0.7204 -- iter: 1440/1707
[A[ATraining Step: 532  | total loss: [1m[32m0.54600[0m[0m | time: 34.869s
[2K
| RMSProp | epoch: 010 | loss: 0.54600 - acc: 0.7171 -- iter: 1472/1707
[A[ATraining Step: 533  | total loss: [1m[32m0.54017[0m[0m | time: 35.606s
[2K
| RMSProp | epoch: 010 | loss: 0.54017 - acc: 0.7298 -- iter: 1504/1707
[A[ATraining Step: 534  | total loss: [1m[32m0.53349[0m[0m | time: 36.341s
[2K
| RMSProp | epoch: 010 | loss: 0.53349 - acc: 0.7318 -- iter: 1536/1707
[A[ATraining Step: 535  | total loss: [1m[32m0.53354[0m[0m | time: 37.077s
[2K
| RMSProp | epoch: 010 | loss: 0.53354 - acc: 0.7274 -- iter: 1568/1707
[A[ATraining Step: 536  | total loss: [1m[32m0.54615[0m[0m | time: 37.809s
[2K
| RMSProp | epoch: 010 | loss: 0.54615 - acc: 0.7234 -- iter: 1600/1707
[A[ATraining Step: 537  | total loss: [1m[32m0.55537[0m[0m | time: 38.517s
[2K
| RMSProp | epoch: 010 | loss: 0.55537 - acc: 0.7104 -- iter: 1632/1707
[A[ATraining Step: 538  | total loss: [1m[32m0.54631[0m[0m | time: 39.266s
[2K
| RMSProp | epoch: 010 | loss: 0.54631 - acc: 0.7175 -- iter: 1664/1707
[A[ATraining Step: 539  | total loss: [1m[32m0.54280[0m[0m | time: 39.977s
[2K
| RMSProp | epoch: 010 | loss: 0.54280 - acc: 0.7176 -- iter: 1696/1707
[A[ATraining Step: 540  | total loss: [1m[32m0.56828[0m[0m | time: 42.857s
[2K
| RMSProp | epoch: 010 | loss: 0.56828 - acc: 0.6927 | val_loss: 0.54055 - val_acc: 0.7303 -- iter: 1707/1707
--
Training Step: 541  | total loss: [1m[32m0.57777[0m[0m | time: 0.813s
[2K
| RMSProp | epoch: 011 | loss: 0.57777 - acc: 0.6766 -- iter: 0032/1707
[A[ATraining Step: 542  | total loss: [1m[32m0.57921[0m[0m | time: 1.567s
[2K
| RMSProp | epoch: 011 | loss: 0.57921 - acc: 0.6714 -- iter: 0064/1707
[A[ATraining Step: 543  | total loss: [1m[32m0.58078[0m[0m | time: 2.316s
[2K
| RMSProp | epoch: 011 | loss: 0.58078 - acc: 0.6699 -- iter: 0096/1707
[A[ATraining Step: 544  | total loss: [1m[32m0.57107[0m[0m | time: 3.034s
[2K
| RMSProp | epoch: 011 | loss: 0.57107 - acc: 0.6904 -- iter: 0128/1707
[A[ATraining Step: 545  | total loss: [1m[32m0.55451[0m[0m | time: 3.854s
[2K
| RMSProp | epoch: 011 | loss: 0.55451 - acc: 0.7058 -- iter: 0160/1707
[A[ATraining Step: 546  | total loss: [1m[32m0.53683[0m[0m | time: 4.605s
[2K
| RMSProp | epoch: 011 | loss: 0.53683 - acc: 0.7258 -- iter: 0192/1707
[A[ATraining Step: 547  | total loss: [1m[32m0.53320[0m[0m | time: 5.445s
[2K
| RMSProp | epoch: 011 | loss: 0.53320 - acc: 0.7345 -- iter: 0224/1707
[A[ATraining Step: 548  | total loss: [1m[32m0.52411[0m[0m | time: 6.206s
[2K
| RMSProp | epoch: 011 | loss: 0.52411 - acc: 0.7423 -- iter: 0256/1707
[A[ATraining Step: 549  | total loss: [1m[32m0.51936[0m[0m | time: 6.481s
[2K
| RMSProp | epoch: 011 | loss: 0.51936 - acc: 0.7462 -- iter: 0288/1707
[A[ATraining Step: 550  | total loss: [1m[32m0.49690[0m[0m | time: 6.799s
[2K
| RMSProp | epoch: 011 | loss: 0.49690 - acc: 0.7625 -- iter: 0320/1707
[A[ATraining Step: 551  | total loss: [1m[32m0.46324[0m[0m | time: 7.569s
[2K
| RMSProp | epoch: 011 | loss: 0.46324 - acc: 0.7862 -- iter: 0352/1707
[A[ATraining Step: 552  | total loss: [1m[32m0.46298[0m[0m | time: 8.330s
[2K
| RMSProp | epoch: 011 | loss: 0.46298 - acc: 0.7857 -- iter: 0384/1707
[A[ATraining Step: 553  | total loss: [1m[32m0.49965[0m[0m | time: 9.040s
[2K
| RMSProp | epoch: 011 | loss: 0.49965 - acc: 0.7603 -- iter: 0416/1707
[A[ATraining Step: 554  | total loss: [1m[32m0.52569[0m[0m | time: 9.862s
[2K
| RMSProp | epoch: 011 | loss: 0.52569 - acc: 0.7499 -- iter: 0448/1707
[A[ATraining Step: 555  | total loss: [1m[32m0.52000[0m[0m | time: 10.638s
[2K
| RMSProp | epoch: 011 | loss: 0.52000 - acc: 0.7593 -- iter: 0480/1707
[A[ATraining Step: 556  | total loss: [1m[32m0.52658[0m[0m | time: 11.383s
[2K
| RMSProp | epoch: 011 | loss: 0.52658 - acc: 0.7490 -- iter: 0512/1707
[A[ATraining Step: 557  | total loss: [1m[32m0.51720[0m[0m | time: 12.142s
[2K
| RMSProp | epoch: 011 | loss: 0.51720 - acc: 0.7522 -- iter: 0544/1707
[A[ATraining Step: 558  | total loss: [1m[32m0.51168[0m[0m | time: 12.964s
[2K
| RMSProp | epoch: 011 | loss: 0.51168 - acc: 0.7457 -- iter: 0576/1707
[A[ATraining Step: 559  | total loss: [1m[32m0.50486[0m[0m | time: 13.710s
[2K
| RMSProp | epoch: 011 | loss: 0.50486 - acc: 0.7461 -- iter: 0608/1707
[A[ATraining Step: 560  | total loss: [1m[32m0.50464[0m[0m | time: 14.467s
[2K
| RMSProp | epoch: 011 | loss: 0.50464 - acc: 0.7497 -- iter: 0640/1707
[A[ATraining Step: 561  | total loss: [1m[32m0.51659[0m[0m | time: 15.192s
[2K
| RMSProp | epoch: 011 | loss: 0.51659 - acc: 0.7403 -- iter: 0672/1707
[A[ATraining Step: 562  | total loss: [1m[32m0.49826[0m[0m | time: 16.085s
[2K
| RMSProp | epoch: 011 | loss: 0.49826 - acc: 0.7507 -- iter: 0704/1707
[A[ATraining Step: 563  | total loss: [1m[32m0.48998[0m[0m | time: 16.839s
[2K
| RMSProp | epoch: 011 | loss: 0.48998 - acc: 0.7475 -- iter: 0736/1707
[A[ATraining Step: 564  | total loss: [1m[32m0.48575[0m[0m | time: 17.578s
[2K
| RMSProp | epoch: 011 | loss: 0.48575 - acc: 0.7508 -- iter: 0768/1707
[A[ATraining Step: 565  | total loss: [1m[32m0.49684[0m[0m | time: 18.323s
[2K
| RMSProp | epoch: 011 | loss: 0.49684 - acc: 0.7476 -- iter: 0800/1707
[A[ATraining Step: 566  | total loss: [1m[32m0.51472[0m[0m | time: 19.070s
[2K
| RMSProp | epoch: 011 | loss: 0.51472 - acc: 0.7479 -- iter: 0832/1707
[A[ATraining Step: 567  | total loss: [1m[32m0.52335[0m[0m | time: 19.809s
[2K
| RMSProp | epoch: 011 | loss: 0.52335 - acc: 0.7418 -- iter: 0864/1707
[A[ATraining Step: 568  | total loss: [1m[32m0.51849[0m[0m | time: 20.564s
[2K
| RMSProp | epoch: 011 | loss: 0.51849 - acc: 0.7427 -- iter: 0896/1707
[A[ATraining Step: 569  | total loss: [1m[32m0.50780[0m[0m | time: 21.314s
[2K
| RMSProp | epoch: 011 | loss: 0.50780 - acc: 0.7528 -- iter: 0928/1707
[A[ATraining Step: 570  | total loss: [1m[32m0.50194[0m[0m | time: 22.031s
[2K
| RMSProp | epoch: 011 | loss: 0.50194 - acc: 0.7556 -- iter: 0960/1707
[A[ATraining Step: 571  | total loss: [1m[32m0.50736[0m[0m | time: 22.783s
[2K
| RMSProp | epoch: 011 | loss: 0.50736 - acc: 0.7551 -- iter: 0992/1707
[A[ATraining Step: 572  | total loss: [1m[32m0.49631[0m[0m | time: 23.534s
[2K
| RMSProp | epoch: 011 | loss: 0.49631 - acc: 0.7639 -- iter: 1024/1707
[A[ATraining Step: 573  | total loss: [1m[32m0.50456[0m[0m | time: 24.245s
[2K
| RMSProp | epoch: 011 | loss: 0.50456 - acc: 0.7594 -- iter: 1056/1707
[A[ATraining Step: 574  | total loss: [1m[32m0.49663[0m[0m | time: 24.978s
[2K
| RMSProp | epoch: 011 | loss: 0.49663 - acc: 0.7678 -- iter: 1088/1707
[A[ATraining Step: 575  | total loss: [1m[32m0.47995[0m[0m | time: 25.722s
[2K
| RMSProp | epoch: 011 | loss: 0.47995 - acc: 0.7817 -- iter: 1120/1707
[A[ATraining Step: 576  | total loss: [1m[32m0.46525[0m[0m | time: 26.464s
[2K
| RMSProp | epoch: 011 | loss: 0.46525 - acc: 0.7879 -- iter: 1152/1707
[A[ATraining Step: 577  | total loss: [1m[32m0.49593[0m[0m | time: 27.191s
[2K
| RMSProp | epoch: 011 | loss: 0.49593 - acc: 0.7653 -- iter: 1184/1707
[A[ATraining Step: 578  | total loss: [1m[32m0.51302[0m[0m | time: 27.931s
[2K
| RMSProp | epoch: 011 | loss: 0.51302 - acc: 0.7482 -- iter: 1216/1707
[A[ATraining Step: 579  | total loss: [1m[32m0.51946[0m[0m | time: 28.701s
[2K
| RMSProp | epoch: 011 | loss: 0.51946 - acc: 0.7452 -- iter: 1248/1707
[A[ATraining Step: 580  | total loss: [1m[32m0.50793[0m[0m | time: 29.506s
[2K
| RMSProp | epoch: 011 | loss: 0.50793 - acc: 0.7582 -- iter: 1280/1707
[A[ATraining Step: 581  | total loss: [1m[32m0.52179[0m[0m | time: 30.244s
[2K
| RMSProp | epoch: 011 | loss: 0.52179 - acc: 0.7480 -- iter: 1312/1707
[A[ATraining Step: 582  | total loss: [1m[32m0.50552[0m[0m | time: 31.004s
[2K
| RMSProp | epoch: 011 | loss: 0.50552 - acc: 0.7607 -- iter: 1344/1707
[A[ATraining Step: 583  | total loss: [1m[32m0.48720[0m[0m | time: 31.851s
[2K
| RMSProp | epoch: 011 | loss: 0.48720 - acc: 0.7784 -- iter: 1376/1707
[A[ATraining Step: 584  | total loss: [1m[32m0.46688[0m[0m | time: 32.960s
[2K
| RMSProp | epoch: 011 | loss: 0.46688 - acc: 0.7881 -- iter: 1408/1707
[A[ATraining Step: 585  | total loss: [1m[32m0.44852[0m[0m | time: 34.036s
[2K
| RMSProp | epoch: 011 | loss: 0.44852 - acc: 0.7968 -- iter: 1440/1707
[A[ATraining Step: 586  | total loss: [1m[32m0.45876[0m[0m | time: 34.886s
[2K
| RMSProp | epoch: 011 | loss: 0.45876 - acc: 0.7890 -- iter: 1472/1707
[A[ATraining Step: 587  | total loss: [1m[32m0.45369[0m[0m | time: 35.638s
[2K
| RMSProp | epoch: 011 | loss: 0.45369 - acc: 0.7944 -- iter: 1504/1707
[A[ATraining Step: 588  | total loss: [1m[32m0.43581[0m[0m | time: 36.367s
[2K
| RMSProp | epoch: 011 | loss: 0.43581 - acc: 0.8056 -- iter: 1536/1707
[A[ATraining Step: 589  | total loss: [1m[32m0.43049[0m[0m | time: 37.119s
[2K
| RMSProp | epoch: 011 | loss: 0.43049 - acc: 0.8126 -- iter: 1568/1707
[A[ATraining Step: 590  | total loss: [1m[32m0.43881[0m[0m | time: 37.849s
[2K
| RMSProp | epoch: 011 | loss: 0.43881 - acc: 0.8032 -- iter: 1600/1707
[A[ATraining Step: 591  | total loss: [1m[32m0.44077[0m[0m | time: 38.608s
[2K
| RMSProp | epoch: 011 | loss: 0.44077 - acc: 0.7979 -- iter: 1632/1707
[A[ATraining Step: 592  | total loss: [1m[32m0.42206[0m[0m | time: 39.368s
[2K
| RMSProp | epoch: 011 | loss: 0.42206 - acc: 0.8024 -- iter: 1664/1707
[A[ATraining Step: 593  | total loss: [1m[32m0.42081[0m[0m | time: 40.100s
[2K
| RMSProp | epoch: 011 | loss: 0.42081 - acc: 0.8035 -- iter: 1696/1707
[A[ATraining Step: 594  | total loss: [1m[32m0.40885[0m[0m | time: 42.889s
[2K
| RMSProp | epoch: 011 | loss: 0.40885 - acc: 0.8137 | val_loss: 0.46937 - val_acc: 0.7715 -- iter: 1707/1707
--
Training Step: 595  | total loss: [1m[32m0.41815[0m[0m | time: 0.775s
[2K
| RMSProp | epoch: 012 | loss: 0.41815 - acc: 0.8105 -- iter: 0032/1707
[A[ATraining Step: 596  | total loss: [1m[32m0.40866[0m[0m | time: 1.523s
[2K
| RMSProp | epoch: 012 | loss: 0.40866 - acc: 0.8169 -- iter: 0064/1707
[A[ATraining Step: 597  | total loss: [1m[32m0.39268[0m[0m | time: 2.319s
[2K
| RMSProp | epoch: 012 | loss: 0.39268 - acc: 0.8227 -- iter: 0096/1707
[A[ATraining Step: 598  | total loss: [1m[32m0.40168[0m[0m | time: 3.096s
[2K
| RMSProp | epoch: 012 | loss: 0.40168 - acc: 0.8186 -- iter: 0128/1707
[A[ATraining Step: 599  | total loss: [1m[32m0.43200[0m[0m | time: 3.849s
[2K
| RMSProp | epoch: 012 | loss: 0.43200 - acc: 0.8086 -- iter: 0160/1707
[A[ATraining Step: 600  | total loss: [1m[32m0.44855[0m[0m | time: 6.756s
[2K
| RMSProp | epoch: 012 | loss: 0.44855 - acc: 0.7996 | val_loss: 0.46001 - val_acc: 0.7921 -- iter: 0192/1707
--
Training Step: 601  | total loss: [1m[32m0.43225[0m[0m | time: 7.531s
[2K
| RMSProp | epoch: 012 | loss: 0.43225 - acc: 0.8134 -- iter: 0224/1707
[A[ATraining Step: 602  | total loss: [1m[32m0.43106[0m[0m | time: 8.296s
[2K
| RMSProp | epoch: 012 | loss: 0.43106 - acc: 0.8102 -- iter: 0256/1707
[A[ATraining Step: 603  | total loss: [1m[32m0.41985[0m[0m | time: 9.034s
[2K
| RMSProp | epoch: 012 | loss: 0.41985 - acc: 0.8167 -- iter: 0288/1707
[A[ATraining Step: 604  | total loss: [1m[32m0.41576[0m[0m | time: 9.352s
[2K
| RMSProp | epoch: 012 | loss: 0.41576 - acc: 0.8194 -- iter: 0320/1707
[A[ATraining Step: 605  | total loss: [1m[32m0.42319[0m[0m | time: 9.655s
[2K
| RMSProp | epoch: 012 | loss: 0.42319 - acc: 0.8193 -- iter: 0352/1707
[A[ATraining Step: 606  | total loss: [1m[32m0.40056[0m[0m | time: 10.413s
[2K
| RMSProp | epoch: 012 | loss: 0.40056 - acc: 0.8282 -- iter: 0384/1707
[A[ATraining Step: 607  | total loss: [1m[32m0.40216[0m[0m | time: 11.133s
[2K
| RMSProp | epoch: 012 | loss: 0.40216 - acc: 0.8267 -- iter: 0416/1707
[A[ATraining Step: 608  | total loss: [1m[32m0.39181[0m[0m | time: 11.856s
[2K
| RMSProp | epoch: 012 | loss: 0.39181 - acc: 0.8284 -- iter: 0448/1707
[A[ATraining Step: 609  | total loss: [1m[32m0.38430[0m[0m | time: 12.597s
[2K
| RMSProp | epoch: 012 | loss: 0.38430 - acc: 0.8330 -- iter: 0480/1707
[A[ATraining Step: 610  | total loss: [1m[32m0.40102[0m[0m | time: 13.314s
[2K
| RMSProp | epoch: 012 | loss: 0.40102 - acc: 0.8216 -- iter: 0512/1707
[A[ATraining Step: 611  | total loss: [1m[32m0.41140[0m[0m | time: 14.055s
[2K
| RMSProp | epoch: 012 | loss: 0.41140 - acc: 0.8082 -- iter: 0544/1707
[A[ATraining Step: 612  | total loss: [1m[32m0.43124[0m[0m | time: 14.821s
[2K
| RMSProp | epoch: 012 | loss: 0.43124 - acc: 0.7961 -- iter: 0576/1707
[A[ATraining Step: 613  | total loss: [1m[32m0.42627[0m[0m | time: 15.549s
[2K
| RMSProp | epoch: 012 | loss: 0.42627 - acc: 0.8009 -- iter: 0608/1707
[A[ATraining Step: 614  | total loss: [1m[32m0.43392[0m[0m | time: 16.307s
[2K
| RMSProp | epoch: 012 | loss: 0.43392 - acc: 0.7927 -- iter: 0640/1707
[A[ATraining Step: 615  | total loss: [1m[32m0.42948[0m[0m | time: 17.025s
[2K
| RMSProp | epoch: 012 | loss: 0.42948 - acc: 0.7915 -- iter: 0672/1707
[A[ATraining Step: 616  | total loss: [1m[32m0.42909[0m[0m | time: 17.745s
[2K
| RMSProp | epoch: 012 | loss: 0.42909 - acc: 0.7999 -- iter: 0704/1707
[A[ATraining Step: 617  | total loss: [1m[32m0.41391[0m[0m | time: 18.471s
[2K
| RMSProp | epoch: 012 | loss: 0.41391 - acc: 0.8074 -- iter: 0736/1707
[A[ATraining Step: 618  | total loss: [1m[32m0.40636[0m[0m | time: 19.254s
[2K
| RMSProp | epoch: 012 | loss: 0.40636 - acc: 0.8110 -- iter: 0768/1707
[A[ATraining Step: 619  | total loss: [1m[32m0.41439[0m[0m | time: 20.014s
[2K
| RMSProp | epoch: 012 | loss: 0.41439 - acc: 0.8081 -- iter: 0800/1707
[A[ATraining Step: 620  | total loss: [1m[32m0.40942[0m[0m | time: 20.766s
[2K
| RMSProp | epoch: 012 | loss: 0.40942 - acc: 0.8085 -- iter: 0832/1707
[A[ATraining Step: 621  | total loss: [1m[32m0.40579[0m[0m | time: 21.506s
[2K
| RMSProp | epoch: 012 | loss: 0.40579 - acc: 0.8120 -- iter: 0864/1707
[A[ATraining Step: 622  | total loss: [1m[32m0.40928[0m[0m | time: 22.246s
[2K
| RMSProp | epoch: 012 | loss: 0.40928 - acc: 0.8121 -- iter: 0896/1707
[A[ATraining Step: 623  | total loss: [1m[32m0.39369[0m[0m | time: 23.012s
[2K
| RMSProp | epoch: 012 | loss: 0.39369 - acc: 0.8184 -- iter: 0928/1707
[A[ATraining Step: 624  | total loss: [1m[32m0.39786[0m[0m | time: 23.752s
[2K
| RMSProp | epoch: 012 | loss: 0.39786 - acc: 0.8115 -- iter: 0960/1707
[A[ATraining Step: 625  | total loss: [1m[32m0.42342[0m[0m | time: 24.456s
[2K
| RMSProp | epoch: 012 | loss: 0.42342 - acc: 0.8022 -- iter: 0992/1707
[A[ATraining Step: 626  | total loss: [1m[32m0.44125[0m[0m | time: 25.225s
[2K
| RMSProp | epoch: 012 | loss: 0.44125 - acc: 0.8001 -- iter: 1024/1707
[A[ATraining Step: 627  | total loss: [1m[32m0.43155[0m[0m | time: 25.942s
[2K
| RMSProp | epoch: 012 | loss: 0.43155 - acc: 0.8076 -- iter: 1056/1707
[A[ATraining Step: 628  | total loss: [1m[32m0.42536[0m[0m | time: 26.722s
[2K
| RMSProp | epoch: 012 | loss: 0.42536 - acc: 0.8144 -- iter: 1088/1707
[A[ATraining Step: 629  | total loss: [1m[32m0.41778[0m[0m | time: 27.460s
[2K
| RMSProp | epoch: 012 | loss: 0.41778 - acc: 0.8204 -- iter: 1120/1707
[A[ATraining Step: 630  | total loss: [1m[32m0.40793[0m[0m | time: 28.233s
[2K
| RMSProp | epoch: 012 | loss: 0.40793 - acc: 0.8259 -- iter: 1152/1707
[A[ATraining Step: 631  | total loss: [1m[32m0.40291[0m[0m | time: 28.969s
[2K
| RMSProp | epoch: 012 | loss: 0.40291 - acc: 0.8277 -- iter: 1184/1707
[A[ATraining Step: 632  | total loss: [1m[32m0.39606[0m[0m | time: 29.721s
[2K
| RMSProp | epoch: 012 | loss: 0.39606 - acc: 0.8324 -- iter: 1216/1707
[A[ATraining Step: 633  | total loss: [1m[32m0.37286[0m[0m | time: 30.457s
[2K
| RMSProp | epoch: 012 | loss: 0.37286 - acc: 0.8460 -- iter: 1248/1707
[A[ATraining Step: 634  | total loss: [1m[32m0.37443[0m[0m | time: 31.217s
[2K
| RMSProp | epoch: 012 | loss: 0.37443 - acc: 0.8458 -- iter: 1280/1707
[A[ATraining Step: 635  | total loss: [1m[32m0.41764[0m[0m | time: 31.983s
[2K
| RMSProp | epoch: 012 | loss: 0.41764 - acc: 0.8269 -- iter: 1312/1707
[A[ATraining Step: 636  | total loss: [1m[32m0.41448[0m[0m | time: 32.743s
[2K
| RMSProp | epoch: 012 | loss: 0.41448 - acc: 0.8285 -- iter: 1344/1707
[A[ATraining Step: 637  | total loss: [1m[32m0.40421[0m[0m | time: 33.467s
[2K
| RMSProp | epoch: 012 | loss: 0.40421 - acc: 0.8332 -- iter: 1376/1707
[A[ATraining Step: 638  | total loss: [1m[32m0.40213[0m[0m | time: 34.189s
[2K
| RMSProp | epoch: 012 | loss: 0.40213 - acc: 0.8311 -- iter: 1408/1707
[A[ATraining Step: 639  | total loss: [1m[32m0.39878[0m[0m | time: 34.907s
[2K
| RMSProp | epoch: 012 | loss: 0.39878 - acc: 0.8293 -- iter: 1440/1707
[A[ATraining Step: 640  | total loss: [1m[32m0.41136[0m[0m | time: 35.645s
[2K
| RMSProp | epoch: 012 | loss: 0.41136 - acc: 0.8245 -- iter: 1472/1707
[A[ATraining Step: 641  | total loss: [1m[32m0.44740[0m[0m | time: 36.402s
[2K
| RMSProp | epoch: 012 | loss: 0.44740 - acc: 0.8045 -- iter: 1504/1707
[A[ATraining Step: 642  | total loss: [1m[32m0.42952[0m[0m | time: 37.135s
[2K
| RMSProp | epoch: 012 | loss: 0.42952 - acc: 0.8178 -- iter: 1536/1707
[A[ATraining Step: 643  | total loss: [1m[32m0.42019[0m[0m | time: 37.911s
[2K
| RMSProp | epoch: 012 | loss: 0.42019 - acc: 0.8235 -- iter: 1568/1707
[A[ATraining Step: 644  | total loss: [1m[32m0.39657[0m[0m | time: 38.652s
[2K
| RMSProp | epoch: 012 | loss: 0.39657 - acc: 0.8381 -- iter: 1600/1707
[A[ATraining Step: 645  | total loss: [1m[32m0.37946[0m[0m | time: 39.405s
[2K
| RMSProp | epoch: 012 | loss: 0.37946 - acc: 0.8449 -- iter: 1632/1707
[A[ATraining Step: 646  | total loss: [1m[32m0.37312[0m[0m | time: 40.128s
[2K
| RMSProp | epoch: 012 | loss: 0.37312 - acc: 0.8416 -- iter: 1664/1707
[A[ATraining Step: 647  | total loss: [1m[32m0.37427[0m[0m | time: 40.875s
[2K
| RMSProp | epoch: 012 | loss: 0.37427 - acc: 0.8387 -- iter: 1696/1707
[A[ATraining Step: 648  | total loss: [1m[32m0.44299[0m[0m | time: 43.762s
[2K
| RMSProp | epoch: 012 | loss: 0.44299 - acc: 0.8111 | val_loss: 0.45142 - val_acc: 0.7903 -- iter: 1707/1707
--
Training Step: 649  | total loss: [1m[32m0.43251[0m[0m | time: 0.779s
[2K
| RMSProp | epoch: 013 | loss: 0.43251 - acc: 0.8144 -- iter: 0032/1707
[A[ATraining Step: 650  | total loss: [1m[32m0.42443[0m[0m | time: 1.560s
[2K
| RMSProp | epoch: 013 | loss: 0.42443 - acc: 0.8204 -- iter: 0064/1707
[A[ATraining Step: 651  | total loss: [1m[32m0.41636[0m[0m | time: 2.323s
[2K
| RMSProp | epoch: 013 | loss: 0.41636 - acc: 0.8259 -- iter: 0096/1707
[A[ATraining Step: 652  | total loss: [1m[32m0.40542[0m[0m | time: 3.090s
[2K
| RMSProp | epoch: 013 | loss: 0.40542 - acc: 0.8277 -- iter: 0128/1707
[A[ATraining Step: 653  | total loss: [1m[32m0.44063[0m[0m | time: 3.826s
[2K
| RMSProp | epoch: 013 | loss: 0.44063 - acc: 0.8105 -- iter: 0160/1707
[A[ATraining Step: 654  | total loss: [1m[32m0.42685[0m[0m | time: 4.550s
[2K
| RMSProp | epoch: 013 | loss: 0.42685 - acc: 0.8232 -- iter: 0192/1707
[A[ATraining Step: 655  | total loss: [1m[32m0.42393[0m[0m | time: 5.354s
[2K
| RMSProp | epoch: 013 | loss: 0.42393 - acc: 0.8253 -- iter: 0224/1707
[A[ATraining Step: 656  | total loss: [1m[32m0.41955[0m[0m | time: 6.138s
[2K
| RMSProp | epoch: 013 | loss: 0.41955 - acc: 0.8240 -- iter: 0256/1707
[A[ATraining Step: 657  | total loss: [1m[32m0.41050[0m[0m | time: 7.306s
[2K
| RMSProp | epoch: 013 | loss: 0.41050 - acc: 0.8291 -- iter: 0288/1707
[A[ATraining Step: 658  | total loss: [1m[32m0.39238[0m[0m | time: 8.571s
[2K
| RMSProp | epoch: 013 | loss: 0.39238 - acc: 0.8399 -- iter: 0320/1707
[A[ATraining Step: 659  | total loss: [1m[32m0.38056[0m[0m | time: 8.977s
[2K
| RMSProp | epoch: 013 | loss: 0.38056 - acc: 0.8372 -- iter: 0352/1707
[A[ATraining Step: 660  | total loss: [1m[32m0.39212[0m[0m | time: 9.229s
[2K
| RMSProp | epoch: 013 | loss: 0.39212 - acc: 0.8353 -- iter: 0384/1707
[A[ATraining Step: 661  | total loss: [1m[32m0.36949[0m[0m | time: 9.924s
[2K
| RMSProp | epoch: 013 | loss: 0.36949 - acc: 0.8518 -- iter: 0416/1707
[A[ATraining Step: 662  | total loss: [1m[32m0.36890[0m[0m | time: 10.706s
[2K
| RMSProp | epoch: 013 | loss: 0.36890 - acc: 0.8478 -- iter: 0448/1707
[A[ATraining Step: 663  | total loss: [1m[32m0.37899[0m[0m | time: 11.414s
[2K
| RMSProp | epoch: 013 | loss: 0.37899 - acc: 0.8412 -- iter: 0480/1707
[A[ATraining Step: 664  | total loss: [1m[32m0.37497[0m[0m | time: 12.133s
[2K
| RMSProp | epoch: 013 | loss: 0.37497 - acc: 0.8414 -- iter: 0512/1707
[A[ATraining Step: 665  | total loss: [1m[32m0.37925[0m[0m | time: 12.892s
[2K
| RMSProp | epoch: 013 | loss: 0.37925 - acc: 0.8417 -- iter: 0544/1707
[A[ATraining Step: 666  | total loss: [1m[32m0.37937[0m[0m | time: 13.655s
[2K
| RMSProp | epoch: 013 | loss: 0.37937 - acc: 0.8419 -- iter: 0576/1707
[A[ATraining Step: 667  | total loss: [1m[32m0.35754[0m[0m | time: 14.442s
[2K
| RMSProp | epoch: 013 | loss: 0.35754 - acc: 0.8577 -- iter: 0608/1707
[A[ATraining Step: 668  | total loss: [1m[32m0.36404[0m[0m | time: 15.221s
[2K
| RMSProp | epoch: 013 | loss: 0.36404 - acc: 0.8500 -- iter: 0640/1707
[A[ATraining Step: 669  | total loss: [1m[32m0.35613[0m[0m | time: 16.015s
[2K
| RMSProp | epoch: 013 | loss: 0.35613 - acc: 0.8557 -- iter: 0672/1707
[A[ATraining Step: 670  | total loss: [1m[32m0.35620[0m[0m | time: 16.746s
[2K
| RMSProp | epoch: 013 | loss: 0.35620 - acc: 0.8513 -- iter: 0704/1707
[A[ATraining Step: 671  | total loss: [1m[32m0.38020[0m[0m | time: 17.525s
[2K
| RMSProp | epoch: 013 | loss: 0.38020 - acc: 0.8412 -- iter: 0736/1707
[A[ATraining Step: 672  | total loss: [1m[32m0.37192[0m[0m | time: 18.291s
[2K
| RMSProp | epoch: 013 | loss: 0.37192 - acc: 0.8446 -- iter: 0768/1707
[A[ATraining Step: 673  | total loss: [1m[32m0.37361[0m[0m | time: 19.053s
[2K
| RMSProp | epoch: 013 | loss: 0.37361 - acc: 0.8414 -- iter: 0800/1707
[A[ATraining Step: 674  | total loss: [1m[32m0.36667[0m[0m | time: 19.824s
[2K
| RMSProp | epoch: 013 | loss: 0.36667 - acc: 0.8447 -- iter: 0832/1707
[A[ATraining Step: 675  | total loss: [1m[32m0.36094[0m[0m | time: 20.570s
[2K
| RMSProp | epoch: 013 | loss: 0.36094 - acc: 0.8478 -- iter: 0864/1707
[A[ATraining Step: 676  | total loss: [1m[32m0.35373[0m[0m | time: 21.319s
[2K
| RMSProp | epoch: 013 | loss: 0.35373 - acc: 0.8505 -- iter: 0896/1707
[A[ATraining Step: 677  | total loss: [1m[32m0.34998[0m[0m | time: 22.045s
[2K
| RMSProp | epoch: 013 | loss: 0.34998 - acc: 0.8529 -- iter: 0928/1707
[A[ATraining Step: 678  | total loss: [1m[32m0.34965[0m[0m | time: 22.790s
[2K
| RMSProp | epoch: 013 | loss: 0.34965 - acc: 0.8520 -- iter: 0960/1707
[A[ATraining Step: 679  | total loss: [1m[32m0.35720[0m[0m | time: 23.539s
[2K
| RMSProp | epoch: 013 | loss: 0.35720 - acc: 0.8449 -- iter: 0992/1707
[A[ATraining Step: 680  | total loss: [1m[32m0.37106[0m[0m | time: 24.246s
[2K
| RMSProp | epoch: 013 | loss: 0.37106 - acc: 0.8355 -- iter: 1024/1707
[A[ATraining Step: 681  | total loss: [1m[32m0.37522[0m[0m | time: 25.058s
[2K
| RMSProp | epoch: 013 | loss: 0.37522 - acc: 0.8332 -- iter: 1056/1707
[A[ATraining Step: 682  | total loss: [1m[32m0.36603[0m[0m | time: 25.796s
[2K
| RMSProp | epoch: 013 | loss: 0.36603 - acc: 0.8405 -- iter: 1088/1707
[A[ATraining Step: 683  | total loss: [1m[32m0.35430[0m[0m | time: 26.540s
[2K
| RMSProp | epoch: 013 | loss: 0.35430 - acc: 0.8502 -- iter: 1120/1707
[A[ATraining Step: 684  | total loss: [1m[32m0.33999[0m[0m | time: 27.283s
[2K
| RMSProp | epoch: 013 | loss: 0.33999 - acc: 0.8589 -- iter: 1152/1707
[A[ATraining Step: 685  | total loss: [1m[32m0.32631[0m[0m | time: 28.022s
[2K
| RMSProp | epoch: 013 | loss: 0.32631 - acc: 0.8668 -- iter: 1184/1707
[A[ATraining Step: 686  | total loss: [1m[32m0.31563[0m[0m | time: 28.756s
[2K
| RMSProp | epoch: 013 | loss: 0.31563 - acc: 0.8738 -- iter: 1216/1707
[A[ATraining Step: 687  | total loss: [1m[32m0.30463[0m[0m | time: 29.569s
[2K
| RMSProp | epoch: 013 | loss: 0.30463 - acc: 0.8771 -- iter: 1248/1707
[A[ATraining Step: 688  | total loss: [1m[32m0.30704[0m[0m | time: 30.339s
[2K
| RMSProp | epoch: 013 | loss: 0.30704 - acc: 0.8737 -- iter: 1280/1707
[A[ATraining Step: 689  | total loss: [1m[32m0.29575[0m[0m | time: 31.065s
[2K
| RMSProp | epoch: 013 | loss: 0.29575 - acc: 0.8770 -- iter: 1312/1707
[A[ATraining Step: 690  | total loss: [1m[32m0.29518[0m[0m | time: 31.784s
[2K
| RMSProp | epoch: 013 | loss: 0.29518 - acc: 0.8799 -- iter: 1344/1707
[A[ATraining Step: 691  | total loss: [1m[32m0.29259[0m[0m | time: 32.537s
[2K
| RMSProp | epoch: 013 | loss: 0.29259 - acc: 0.8826 -- iter: 1376/1707
[A[ATraining Step: 692  | total loss: [1m[32m0.28804[0m[0m | time: 33.272s
[2K
| RMSProp | epoch: 013 | loss: 0.28804 - acc: 0.8849 -- iter: 1408/1707
[A[ATraining Step: 693  | total loss: [1m[32m0.28621[0m[0m | time: 34.016s
[2K
| RMSProp | epoch: 013 | loss: 0.28621 - acc: 0.8839 -- iter: 1440/1707
[A[ATraining Step: 694  | total loss: [1m[32m0.27222[0m[0m | time: 34.792s
[2K
| RMSProp | epoch: 013 | loss: 0.27222 - acc: 0.8893 -- iter: 1472/1707
[A[ATraining Step: 695  | total loss: [1m[32m0.25969[0m[0m | time: 35.551s
[2K
| RMSProp | epoch: 013 | loss: 0.25969 - acc: 0.8941 -- iter: 1504/1707
[A[ATraining Step: 696  | total loss: [1m[32m0.28221[0m[0m | time: 36.340s
[2K
| RMSProp | epoch: 013 | loss: 0.28221 - acc: 0.8828 -- iter: 1536/1707
[A[ATraining Step: 697  | total loss: [1m[32m0.28412[0m[0m | time: 37.082s
[2K
| RMSProp | epoch: 013 | loss: 0.28412 - acc: 0.8820 -- iter: 1568/1707
[A[ATraining Step: 698  | total loss: [1m[32m0.31340[0m[0m | time: 37.880s
[2K
| RMSProp | epoch: 013 | loss: 0.31340 - acc: 0.8657 -- iter: 1600/1707
[A[ATraining Step: 699  | total loss: [1m[32m0.30180[0m[0m | time: 38.608s
[2K
| RMSProp | epoch: 013 | loss: 0.30180 - acc: 0.8729 -- iter: 1632/1707
[A[ATraining Step: 700  | total loss: [1m[32m0.28548[0m[0m | time: 39.322s
[2K
| RMSProp | epoch: 013 | loss: 0.28548 - acc: 0.8825 -- iter: 1664/1707
[A[ATraining Step: 701  | total loss: [1m[32m0.29419[0m[0m | time: 40.078s
[2K
| RMSProp | epoch: 013 | loss: 0.29419 - acc: 0.8786 -- iter: 1696/1707
[A[ATraining Step: 702  | total loss: [1m[32m0.28002[0m[0m | time: 42.908s
[2K
| RMSProp | epoch: 013 | loss: 0.28002 - acc: 0.8814 | val_loss: 0.53191 - val_acc: 0.7753 -- iter: 1707/1707
--
Training Step: 703  | total loss: [1m[32m0.26708[0m[0m | time: 0.799s
[2K
| RMSProp | epoch: 014 | loss: 0.26708 - acc: 0.8901 -- iter: 0032/1707
[A[ATraining Step: 704  | total loss: [1m[32m0.28546[0m[0m | time: 1.587s
[2K
| RMSProp | epoch: 014 | loss: 0.28546 - acc: 0.8855 -- iter: 0064/1707
[A[ATraining Step: 705  | total loss: [1m[32m0.29018[0m[0m | time: 2.374s
[2K
| RMSProp | epoch: 014 | loss: 0.29018 - acc: 0.8813 -- iter: 0096/1707
[A[ATraining Step: 706  | total loss: [1m[32m0.29106[0m[0m | time: 3.119s
[2K
| RMSProp | epoch: 014 | loss: 0.29106 - acc: 0.8775 -- iter: 0128/1707
[A[ATraining Step: 707  | total loss: [1m[32m0.28407[0m[0m | time: 3.902s
[2K
| RMSProp | epoch: 014 | loss: 0.28407 - acc: 0.8835 -- iter: 0160/1707
[A[ATraining Step: 708  | total loss: [1m[32m0.27907[0m[0m | time: 4.662s
[2K
| RMSProp | epoch: 014 | loss: 0.27907 - acc: 0.8889 -- iter: 0192/1707
[A[ATraining Step: 709  | total loss: [1m[32m0.26637[0m[0m | time: 5.426s
[2K
| RMSProp | epoch: 014 | loss: 0.26637 - acc: 0.8969 -- iter: 0224/1707
[A[ATraining Step: 710  | total loss: [1m[32m0.25669[0m[0m | time: 6.175s
[2K
| RMSProp | epoch: 014 | loss: 0.25669 - acc: 0.9010 -- iter: 0256/1707
[A[ATraining Step: 711  | total loss: [1m[32m0.26193[0m[0m | time: 6.926s
[2K
| RMSProp | epoch: 014 | loss: 0.26193 - acc: 0.8984 -- iter: 0288/1707
[A[ATraining Step: 712  | total loss: [1m[32m0.26513[0m[0m | time: 7.685s
[2K
| RMSProp | epoch: 014 | loss: 0.26513 - acc: 0.8960 -- iter: 0320/1707
[A[ATraining Step: 713  | total loss: [1m[32m0.26414[0m[0m | time: 8.452s
[2K
| RMSProp | epoch: 014 | loss: 0.26414 - acc: 0.8939 -- iter: 0352/1707
[A[ATraining Step: 714  | total loss: [1m[32m0.25467[0m[0m | time: 8.792s
[2K
| RMSProp | epoch: 014 | loss: 0.25467 - acc: 0.8952 -- iter: 0384/1707
[A[ATraining Step: 715  | total loss: [1m[32m0.24547[0m[0m | time: 9.092s
[2K
| RMSProp | epoch: 014 | loss: 0.24547 - acc: 0.8966 -- iter: 0416/1707
[A[ATraining Step: 716  | total loss: [1m[32m0.22536[0m[0m | time: 9.864s
[2K
| RMSProp | epoch: 014 | loss: 0.22536 - acc: 0.9069 -- iter: 0448/1707
[A[ATraining Step: 717  | total loss: [1m[32m0.21235[0m[0m | time: 10.619s
[2K
| RMSProp | epoch: 014 | loss: 0.21235 - acc: 0.9131 -- iter: 0480/1707
[A[ATraining Step: 718  | total loss: [1m[32m0.19678[0m[0m | time: 11.335s
[2K
| RMSProp | epoch: 014 | loss: 0.19678 - acc: 0.9187 -- iter: 0512/1707
[A[ATraining Step: 719  | total loss: [1m[32m0.20574[0m[0m | time: 12.041s
[2K
| RMSProp | epoch: 014 | loss: 0.20574 - acc: 0.9174 -- iter: 0544/1707
[A[ATraining Step: 720  | total loss: [1m[32m0.31291[0m[0m | time: 12.771s
[2K
| RMSProp | epoch: 014 | loss: 0.31291 - acc: 0.8819 -- iter: 0576/1707
[A[ATraining Step: 721  | total loss: [1m[32m0.30588[0m[0m | time: 13.504s
[2K
| RMSProp | epoch: 014 | loss: 0.30588 - acc: 0.8844 -- iter: 0608/1707
[A[ATraining Step: 722  | total loss: [1m[32m0.30338[0m[0m | time: 14.241s
[2K
| RMSProp | epoch: 014 | loss: 0.30338 - acc: 0.8865 -- iter: 0640/1707
[A[ATraining Step: 723  | total loss: [1m[32m0.30597[0m[0m | time: 14.970s
[2K
| RMSProp | epoch: 014 | loss: 0.30597 - acc: 0.8854 -- iter: 0672/1707
[A[ATraining Step: 724  | total loss: [1m[32m0.32394[0m[0m | time: 15.720s
[2K
| RMSProp | epoch: 014 | loss: 0.32394 - acc: 0.8750 -- iter: 0704/1707
[A[ATraining Step: 725  | total loss: [1m[32m0.31918[0m[0m | time: 16.442s
[2K
| RMSProp | epoch: 014 | loss: 0.31918 - acc: 0.8781 -- iter: 0736/1707
[A[ATraining Step: 726  | total loss: [1m[32m0.31833[0m[0m | time: 17.212s
[2K
| RMSProp | epoch: 014 | loss: 0.31833 - acc: 0.8809 -- iter: 0768/1707
[A[ATraining Step: 727  | total loss: [1m[32m0.31553[0m[0m | time: 17.950s
[2K
| RMSProp | epoch: 014 | loss: 0.31553 - acc: 0.8772 -- iter: 0800/1707
[A[ATraining Step: 728  | total loss: [1m[32m0.32488[0m[0m | time: 18.706s
[2K
| RMSProp | epoch: 014 | loss: 0.32488 - acc: 0.8739 -- iter: 0832/1707
[A[ATraining Step: 729  | total loss: [1m[32m0.32452[0m[0m | time: 19.454s
[2K
| RMSProp | epoch: 014 | loss: 0.32452 - acc: 0.8708 -- iter: 0864/1707
[A[ATraining Step: 730  | total loss: [1m[32m0.30221[0m[0m | time: 20.191s
[2K
| RMSProp | epoch: 014 | loss: 0.30221 - acc: 0.8838 -- iter: 0896/1707
[A[ATraining Step: 731  | total loss: [1m[32m0.28911[0m[0m | time: 20.914s
[2K
| RMSProp | epoch: 014 | loss: 0.28911 - acc: 0.8891 -- iter: 0928/1707
[A[ATraining Step: 732  | total loss: [1m[32m0.29029[0m[0m | time: 21.627s
[2K
| RMSProp | epoch: 014 | loss: 0.29029 - acc: 0.8846 -- iter: 0960/1707
[A[ATraining Step: 733  | total loss: [1m[32m0.28258[0m[0m | time: 22.360s
[2K
| RMSProp | epoch: 014 | loss: 0.28258 - acc: 0.8899 -- iter: 0992/1707
[A[ATraining Step: 734  | total loss: [1m[32m0.30049[0m[0m | time: 23.112s
[2K
| RMSProp | epoch: 014 | loss: 0.30049 - acc: 0.8853 -- iter: 1024/1707
[A[ATraining Step: 735  | total loss: [1m[32m0.30459[0m[0m | time: 23.883s
[2K
| RMSProp | epoch: 014 | loss: 0.30459 - acc: 0.8842 -- iter: 1056/1707
[A[ATraining Step: 736  | total loss: [1m[32m0.30088[0m[0m | time: 24.635s
[2K
| RMSProp | epoch: 014 | loss: 0.30088 - acc: 0.8833 -- iter: 1088/1707
[A[ATraining Step: 737  | total loss: [1m[32m0.29876[0m[0m | time: 25.354s
[2K
| RMSProp | epoch: 014 | loss: 0.29876 - acc: 0.8856 -- iter: 1120/1707
[A[ATraining Step: 738  | total loss: [1m[32m0.30126[0m[0m | time: 26.075s
[2K
| RMSProp | epoch: 014 | loss: 0.30126 - acc: 0.8877 -- iter: 1152/1707
[A[ATraining Step: 739  | total loss: [1m[32m0.28090[0m[0m | time: 26.918s
[2K
| RMSProp | epoch: 014 | loss: 0.28090 - acc: 0.8958 -- iter: 1184/1707
[A[ATraining Step: 740  | total loss: [1m[32m0.26448[0m[0m | time: 28.126s
[2K
| RMSProp | epoch: 014 | loss: 0.26448 - acc: 0.9031 -- iter: 1216/1707
[A[ATraining Step: 741  | total loss: [1m[32m0.24373[0m[0m | time: 29.204s
[2K
| RMSProp | epoch: 014 | loss: 0.24373 - acc: 0.9128 -- iter: 1248/1707
[A[ATraining Step: 742  | total loss: [1m[32m0.22393[0m[0m | time: 30.026s
[2K
| RMSProp | epoch: 014 | loss: 0.22393 - acc: 0.9215 -- iter: 1280/1707
[A[ATraining Step: 743  | total loss: [1m[32m0.20463[0m[0m | time: 30.720s
[2K
| RMSProp | epoch: 014 | loss: 0.20463 - acc: 0.9293 -- iter: 1312/1707
[A[ATraining Step: 744  | total loss: [1m[32m0.18679[0m[0m | time: 31.452s
[2K
| RMSProp | epoch: 014 | loss: 0.18679 - acc: 0.9364 -- iter: 1344/1707
[A[ATraining Step: 745  | total loss: [1m[32m0.17299[0m[0m | time: 32.178s
[2K
| RMSProp | epoch: 014 | loss: 0.17299 - acc: 0.9396 -- iter: 1376/1707
[A[ATraining Step: 746  | total loss: [1m[32m0.19678[0m[0m | time: 32.977s
[2K
| RMSProp | epoch: 014 | loss: 0.19678 - acc: 0.9363 -- iter: 1408/1707
[A[ATraining Step: 747  | total loss: [1m[32m0.19044[0m[0m | time: 33.671s
[2K
| RMSProp | epoch: 014 | loss: 0.19044 - acc: 0.9364 -- iter: 1440/1707
[A[ATraining Step: 748  | total loss: [1m[32m0.19426[0m[0m | time: 34.470s
[2K
| RMSProp | epoch: 014 | loss: 0.19426 - acc: 0.9334 -- iter: 1472/1707
[A[ATraining Step: 749  | total loss: [1m[32m0.19034[0m[0m | time: 35.232s
[2K
| RMSProp | epoch: 014 | loss: 0.19034 - acc: 0.9369 -- iter: 1504/1707
[A[ATraining Step: 750  | total loss: [1m[32m0.17764[0m[0m | time: 35.976s
[2K
| RMSProp | epoch: 014 | loss: 0.17764 - acc: 0.9432 -- iter: 1536/1707
[A[ATraining Step: 751  | total loss: [1m[32m0.17204[0m[0m | time: 36.746s
[2K
| RMSProp | epoch: 014 | loss: 0.17204 - acc: 0.9427 -- iter: 1568/1707
[A[ATraining Step: 752  | total loss: [1m[32m0.16217[0m[0m | time: 37.468s
[2K
| RMSProp | epoch: 014 | loss: 0.16217 - acc: 0.9453 -- iter: 1600/1707
[A[ATraining Step: 753  | total loss: [1m[32m0.19001[0m[0m | time: 38.214s
[2K
| RMSProp | epoch: 014 | loss: 0.19001 - acc: 0.9320 -- iter: 1632/1707
[A[ATraining Step: 754  | total loss: [1m[32m0.19814[0m[0m | time: 38.958s
[2K
| RMSProp | epoch: 014 | loss: 0.19814 - acc: 0.9326 -- iter: 1664/1707
[A[ATraining Step: 755  | total loss: [1m[32m0.18891[0m[0m | time: 39.699s
[2K
| RMSProp | epoch: 014 | loss: 0.18891 - acc: 0.9362 -- iter: 1696/1707
[A[ATraining Step: 756  | total loss: [1m[32m0.18712[0m[0m | time: 42.549s
[2K
| RMSProp | epoch: 014 | loss: 0.18712 - acc: 0.9394 | val_loss: 0.55682 - val_acc: 0.7846 -- iter: 1707/1707
--
Training Step: 757  | total loss: [1m[32m0.17310[0m[0m | time: 0.746s
[2K
| RMSProp | epoch: 015 | loss: 0.17310 - acc: 0.9455 -- iter: 0032/1707
[A[ATraining Step: 758  | total loss: [1m[32m0.16908[0m[0m | time: 1.507s
[2K
| RMSProp | epoch: 015 | loss: 0.16908 - acc: 0.9447 -- iter: 0064/1707
[A[ATraining Step: 759  | total loss: [1m[32m0.18077[0m[0m | time: 2.246s
[2K
| RMSProp | epoch: 015 | loss: 0.18077 - acc: 0.9377 -- iter: 0096/1707
[A[ATraining Step: 760  | total loss: [1m[32m0.24015[0m[0m | time: 2.986s
[2K
| RMSProp | epoch: 015 | loss: 0.24015 - acc: 0.9096 -- iter: 0128/1707
[A[ATraining Step: 761  | total loss: [1m[32m0.24475[0m[0m | time: 3.743s
[2K
| RMSProp | epoch: 015 | loss: 0.24475 - acc: 0.9061 -- iter: 0160/1707
[A[ATraining Step: 762  | total loss: [1m[32m0.25509[0m[0m | time: 4.488s
[2K
| RMSProp | epoch: 015 | loss: 0.25509 - acc: 0.8968 -- iter: 0192/1707
[A[ATraining Step: 763  | total loss: [1m[32m0.24050[0m[0m | time: 5.262s
[2K
| RMSProp | epoch: 015 | loss: 0.24050 - acc: 0.9040 -- iter: 0224/1707
[A[ATraining Step: 764  | total loss: [1m[32m0.23675[0m[0m | time: 5.997s
[2K
| RMSProp | epoch: 015 | loss: 0.23675 - acc: 0.9073 -- iter: 0256/1707
[A[ATraining Step: 765  | total loss: [1m[32m0.23823[0m[0m | time: 6.728s
[2K
| RMSProp | epoch: 015 | loss: 0.23823 - acc: 0.9072 -- iter: 0288/1707
[A[ATraining Step: 766  | total loss: [1m[32m0.26275[0m[0m | time: 7.462s
[2K
| RMSProp | epoch: 015 | loss: 0.26275 - acc: 0.8946 -- iter: 0320/1707
[A[ATraining Step: 767  | total loss: [1m[32m0.26238[0m[0m | time: 8.238s
[2K
| RMSProp | epoch: 015 | loss: 0.26238 - acc: 0.8926 -- iter: 0352/1707
[A[ATraining Step: 768  | total loss: [1m[32m0.27636[0m[0m | time: 8.992s
[2K
| RMSProp | epoch: 015 | loss: 0.27636 - acc: 0.8878 -- iter: 0384/1707
[A[ATraining Step: 769  | total loss: [1m[32m0.29767[0m[0m | time: 9.243s
[2K
| RMSProp | epoch: 015 | loss: 0.29767 - acc: 0.8740 -- iter: 0416/1707
[A[ATraining Step: 770  | total loss: [1m[32m0.29431[0m[0m | time: 9.577s
[2K
| RMSProp | epoch: 015 | loss: 0.29431 - acc: 0.8775 -- iter: 0448/1707
[A[ATraining Step: 771  | total loss: [1m[32m0.27287[0m[0m | time: 10.359s
[2K
| RMSProp | epoch: 015 | loss: 0.27287 - acc: 0.8897 -- iter: 0480/1707
[A[ATraining Step: 772  | total loss: [1m[32m0.26463[0m[0m | time: 11.177s
[2K
| RMSProp | epoch: 015 | loss: 0.26463 - acc: 0.8945 -- iter: 0512/1707
[A[ATraining Step: 773  | total loss: [1m[32m0.27840[0m[0m | time: 11.908s
[2K
| RMSProp | epoch: 015 | loss: 0.27840 - acc: 0.8832 -- iter: 0544/1707
[A[ATraining Step: 774  | total loss: [1m[32m0.29556[0m[0m | time: 12.683s
[2K
| RMSProp | epoch: 015 | loss: 0.29556 - acc: 0.8699 -- iter: 0576/1707
[A[ATraining Step: 775  | total loss: [1m[32m0.29806[0m[0m | time: 13.413s
[2K
| RMSProp | epoch: 015 | loss: 0.29806 - acc: 0.8673 -- iter: 0608/1707
[A[ATraining Step: 776  | total loss: [1m[32m0.28837[0m[0m | time: 14.129s
[2K
| RMSProp | epoch: 015 | loss: 0.28837 - acc: 0.8743 -- iter: 0640/1707
[A[ATraining Step: 777  | total loss: [1m[32m0.28051[0m[0m | time: 14.864s
[2K
| RMSProp | epoch: 015 | loss: 0.28051 - acc: 0.8775 -- iter: 0672/1707
[A[ATraining Step: 778  | total loss: [1m[32m0.26608[0m[0m | time: 15.623s
[2K
| RMSProp | epoch: 015 | loss: 0.26608 - acc: 0.8866 -- iter: 0704/1707
[A[ATraining Step: 779  | total loss: [1m[32m0.24888[0m[0m | time: 16.406s
[2K
| RMSProp | epoch: 015 | loss: 0.24888 - acc: 0.8948 -- iter: 0736/1707
[A[ATraining Step: 780  | total loss: [1m[32m0.25066[0m[0m | time: 17.138s
[2K
| RMSProp | epoch: 015 | loss: 0.25066 - acc: 0.8960 -- iter: 0768/1707
[A[ATraining Step: 781  | total loss: [1m[32m0.25335[0m[0m | time: 17.884s
[2K
| RMSProp | epoch: 015 | loss: 0.25335 - acc: 0.9001 -- iter: 0800/1707
[A[ATraining Step: 782  | total loss: [1m[32m0.26423[0m[0m | time: 18.621s
[2K
| RMSProp | epoch: 015 | loss: 0.26423 - acc: 0.8976 -- iter: 0832/1707
[A[ATraining Step: 783  | total loss: [1m[32m0.26346[0m[0m | time: 19.369s
[2K
| RMSProp | epoch: 015 | loss: 0.26346 - acc: 0.8953 -- iter: 0864/1707
[A[ATraining Step: 784  | total loss: [1m[32m0.26275[0m[0m | time: 20.113s
[2K
| RMSProp | epoch: 015 | loss: 0.26275 - acc: 0.8964 -- iter: 0896/1707
[A[ATraining Step: 785  | total loss: [1m[32m0.27140[0m[0m | time: 20.840s
[2K
| RMSProp | epoch: 015 | loss: 0.27140 - acc: 0.8943 -- iter: 0928/1707
[A[ATraining Step: 786  | total loss: [1m[32m0.26346[0m[0m | time: 21.616s
[2K
| RMSProp | epoch: 015 | loss: 0.26346 - acc: 0.8986 -- iter: 0960/1707
[A[ATraining Step: 787  | total loss: [1m[32m0.25185[0m[0m | time: 22.365s
[2K
| RMSProp | epoch: 015 | loss: 0.25185 - acc: 0.9025 -- iter: 0992/1707
[A[ATraining Step: 788  | total loss: [1m[32m0.23753[0m[0m | time: 23.099s
[2K
| RMSProp | epoch: 015 | loss: 0.23753 - acc: 0.9091 -- iter: 1024/1707
[A[ATraining Step: 789  | total loss: [1m[32m0.24447[0m[0m | time: 23.842s
[2K
| RMSProp | epoch: 015 | loss: 0.24447 - acc: 0.9120 -- iter: 1056/1707
[A[ATraining Step: 790  | total loss: [1m[32m0.24039[0m[0m | time: 24.557s
[2K
| RMSProp | epoch: 015 | loss: 0.24039 - acc: 0.9176 -- iter: 1088/1707
[A[ATraining Step: 791  | total loss: [1m[32m0.28593[0m[0m | time: 25.275s
[2K
| RMSProp | epoch: 015 | loss: 0.28593 - acc: 0.8978 -- iter: 1120/1707
[A[ATraining Step: 792  | total loss: [1m[32m0.28864[0m[0m | time: 26.024s
[2K
| RMSProp | epoch: 015 | loss: 0.28864 - acc: 0.8861 -- iter: 1152/1707
[A[ATraining Step: 793  | total loss: [1m[32m0.27444[0m[0m | time: 26.749s
[2K
| RMSProp | epoch: 015 | loss: 0.27444 - acc: 0.8944 -- iter: 1184/1707
[A[ATraining Step: 794  | total loss: [1m[32m0.25229[0m[0m | time: 27.464s
[2K
| RMSProp | epoch: 015 | loss: 0.25229 - acc: 0.9049 -- iter: 1216/1707
[A[ATraining Step: 795  | total loss: [1m[32m0.23591[0m[0m | time: 28.213s
[2K
| RMSProp | epoch: 015 | loss: 0.23591 - acc: 0.9113 -- iter: 1248/1707
[A[ATraining Step: 796  | total loss: [1m[32m0.21423[0m[0m | time: 28.983s
[2K
| RMSProp | epoch: 015 | loss: 0.21423 - acc: 0.9202 -- iter: 1280/1707
[A[ATraining Step: 797  | total loss: [1m[32m0.19780[0m[0m | time: 29.746s
[2K
| RMSProp | epoch: 015 | loss: 0.19780 - acc: 0.9282 -- iter: 1312/1707
[A[ATraining Step: 798  | total loss: [1m[32m0.19573[0m[0m | time: 30.490s
[2K
| RMSProp | epoch: 015 | loss: 0.19573 - acc: 0.9291 -- iter: 1344/1707
[A[ATraining Step: 799  | total loss: [1m[32m0.20883[0m[0m | time: 31.244s
[2K
| RMSProp | epoch: 015 | loss: 0.20883 - acc: 0.9237 -- iter: 1376/1707
[A[ATraining Step: 800  | total loss: [1m[32m0.23129[0m[0m | time: 34.123s
[2K
| RMSProp | epoch: 015 | loss: 0.23129 - acc: 0.9094 | val_loss: 0.53875 - val_acc: 0.7828 -- iter: 1408/1707
--
Training Step: 801  | total loss: [1m[32m0.23610[0m[0m | time: 34.893s
[2K
| RMSProp | epoch: 015 | loss: 0.23610 - acc: 0.9122 -- iter: 1440/1707
[A[ATraining Step: 802  | total loss: [1m[32m0.23437[0m[0m | time: 35.657s
[2K
| RMSProp | epoch: 015 | loss: 0.23437 - acc: 0.9148 -- iter: 1472/1707
[A[ATraining Step: 803  | total loss: [1m[32m0.23489[0m[0m | time: 36.383s
[2K
| RMSProp | epoch: 015 | loss: 0.23489 - acc: 0.9170 -- iter: 1504/1707
[A[ATraining Step: 804  | total loss: [1m[32m0.23492[0m[0m | time: 37.110s
[2K
| RMSProp | epoch: 015 | loss: 0.23492 - acc: 0.9160 -- iter: 1536/1707
[A[ATraining Step: 805  | total loss: [1m[32m0.23677[0m[0m | time: 37.929s
[2K
| RMSProp | epoch: 015 | loss: 0.23677 - acc: 0.9087 -- iter: 1568/1707
[A[ATraining Step: 806  | total loss: [1m[32m0.22796[0m[0m | time: 38.690s
[2K
| RMSProp | epoch: 015 | loss: 0.22796 - acc: 0.9147 -- iter: 1600/1707
[A[ATraining Step: 807  | total loss: [1m[32m0.22976[0m[0m | time: 39.462s
[2K
| RMSProp | epoch: 015 | loss: 0.22976 - acc: 0.9139 -- iter: 1632/1707
[A[ATraining Step: 808  | total loss: [1m[32m0.22471[0m[0m | time: 40.240s
[2K
| RMSProp | epoch: 015 | loss: 0.22471 - acc: 0.9163 -- iter: 1664/1707
[A[ATraining Step: 809  | total loss: [1m[32m0.22203[0m[0m | time: 40.962s
[2K
| RMSProp | epoch: 015 | loss: 0.22203 - acc: 0.9184 -- iter: 1696/1707
[A[ATraining Step: 810  | total loss: [1m[32m0.20815[0m[0m | time: 43.857s
[2K
| RMSProp | epoch: 015 | loss: 0.20815 - acc: 0.9234 | val_loss: 0.54621 - val_acc: 0.7921 -- iter: 1707/1707
--
Training Step: 811  | total loss: [1m[32m0.19571[0m[0m | time: 0.735s
[2K
| RMSProp | epoch: 016 | loss: 0.19571 - acc: 0.9280 -- iter: 0032/1707
[A[ATraining Step: 812  | total loss: [1m[32m0.20284[0m[0m | time: 1.469s
[2K
| RMSProp | epoch: 016 | loss: 0.20284 - acc: 0.9227 -- iter: 0064/1707
[A[ATraining Step: 813  | total loss: [1m[32m0.19242[0m[0m | time: 2.206s
[2K
| RMSProp | epoch: 016 | loss: 0.19242 - acc: 0.9273 -- iter: 0096/1707
[A[ATraining Step: 814  | total loss: [1m[32m0.18073[0m[0m | time: 3.155s
[2K
| RMSProp | epoch: 016 | loss: 0.18073 - acc: 0.9314 -- iter: 0128/1707
[A[ATraining Step: 815  | total loss: [1m[32m0.16780[0m[0m | time: 4.294s
[2K
| RMSProp | epoch: 016 | loss: 0.16780 - acc: 0.9383 -- iter: 0160/1707
[A[ATraining Step: 816  | total loss: [1m[32m0.15992[0m[0m | time: 5.477s
[2K
| RMSProp | epoch: 016 | loss: 0.15992 - acc: 0.9413 -- iter: 0192/1707
[A[ATraining Step: 817  | total loss: [1m[32m0.15546[0m[0m | time: 6.167s
[2K
| RMSProp | epoch: 016 | loss: 0.15546 - acc: 0.9441 -- iter: 0224/1707
[A[ATraining Step: 818  | total loss: [1m[32m0.15067[0m[0m | time: 6.967s
[2K
| RMSProp | epoch: 016 | loss: 0.15067 - acc: 0.9465 -- iter: 0256/1707
[A[ATraining Step: 819  | total loss: [1m[32m0.14848[0m[0m | time: 7.722s
[2K
| RMSProp | epoch: 016 | loss: 0.14848 - acc: 0.9456 -- iter: 0288/1707
[A[ATraining Step: 820  | total loss: [1m[32m0.16319[0m[0m | time: 8.437s
[2K
| RMSProp | epoch: 016 | loss: 0.16319 - acc: 0.9386 -- iter: 0320/1707
[A[ATraining Step: 821  | total loss: [1m[32m0.18828[0m[0m | time: 9.268s
[2K
| RMSProp | epoch: 016 | loss: 0.18828 - acc: 0.9322 -- iter: 0352/1707
[A[ATraining Step: 822  | total loss: [1m[32m0.19529[0m[0m | time: 9.994s
[2K
| RMSProp | epoch: 016 | loss: 0.19529 - acc: 0.9296 -- iter: 0384/1707
[A[ATraining Step: 823  | total loss: [1m[32m0.18759[0m[0m | time: 10.799s
[2K
| RMSProp | epoch: 016 | loss: 0.18759 - acc: 0.9335 -- iter: 0416/1707
[A[ATraining Step: 824  | total loss: [1m[32m0.19877[0m[0m | time: 11.133s
[2K
| RMSProp | epoch: 016 | loss: 0.19877 - acc: 0.9339 -- iter: 0448/1707
[A[ATraining Step: 825  | total loss: [1m[32m0.18784[0m[0m | time: 11.390s
[2K
| RMSProp | epoch: 016 | loss: 0.18784 - acc: 0.9405 -- iter: 0480/1707
[A[ATraining Step: 826  | total loss: [1m[32m0.17340[0m[0m | time: 12.176s
[2K
| RMSProp | epoch: 016 | loss: 0.17340 - acc: 0.9465 -- iter: 0512/1707
[A[ATraining Step: 827  | total loss: [1m[32m0.17193[0m[0m | time: 12.928s
[2K
| RMSProp | epoch: 016 | loss: 0.17193 - acc: 0.9456 -- iter: 0544/1707
[A[ATraining Step: 828  | total loss: [1m[32m0.18739[0m[0m | time: 13.694s
[2K
| RMSProp | epoch: 016 | loss: 0.18739 - acc: 0.9385 -- iter: 0576/1707
[A[ATraining Step: 829  | total loss: [1m[32m0.18818[0m[0m | time: 14.453s
[2K
| RMSProp | epoch: 016 | loss: 0.18818 - acc: 0.9353 -- iter: 0608/1707
[A[ATraining Step: 830  | total loss: [1m[32m0.21593[0m[0m | time: 15.192s
[2K
| RMSProp | epoch: 016 | loss: 0.21593 - acc: 0.9261 -- iter: 0640/1707
[A[ATraining Step: 831  | total loss: [1m[32m0.23726[0m[0m | time: 15.924s
[2K
| RMSProp | epoch: 016 | loss: 0.23726 - acc: 0.9242 -- iter: 0672/1707
[A[ATraining Step: 832  | total loss: [1m[32m0.22710[0m[0m | time: 16.642s
[2K
| RMSProp | epoch: 016 | loss: 0.22710 - acc: 0.9286 -- iter: 0704/1707
[A[ATraining Step: 833  | total loss: [1m[32m0.21496[0m[0m | time: 17.364s
[2K
| RMSProp | epoch: 016 | loss: 0.21496 - acc: 0.9326 -- iter: 0736/1707
[A[ATraining Step: 834  | total loss: [1m[32m0.20566[0m[0m | time: 18.131s
[2K
| RMSProp | epoch: 016 | loss: 0.20566 - acc: 0.9362 -- iter: 0768/1707
[A[ATraining Step: 835  | total loss: [1m[32m0.19823[0m[0m | time: 18.893s
[2K
| RMSProp | epoch: 016 | loss: 0.19823 - acc: 0.9364 -- iter: 0800/1707
[A[ATraining Step: 836  | total loss: [1m[32m0.19545[0m[0m | time: 19.654s
[2K
| RMSProp | epoch: 016 | loss: 0.19545 - acc: 0.9365 -- iter: 0832/1707
[A[ATraining Step: 837  | total loss: [1m[32m0.18747[0m[0m | time: 20.379s
[2K
| RMSProp | epoch: 016 | loss: 0.18747 - acc: 0.9366 -- iter: 0864/1707
[A[ATraining Step: 838  | total loss: [1m[32m0.17780[0m[0m | time: 21.108s
[2K
| RMSProp | epoch: 016 | loss: 0.17780 - acc: 0.9367 -- iter: 0896/1707
[A[ATraining Step: 839  | total loss: [1m[32m0.18131[0m[0m | time: 21.858s
[2K
| RMSProp | epoch: 016 | loss: 0.18131 - acc: 0.9399 -- iter: 0928/1707
[A[ATraining Step: 840  | total loss: [1m[32m0.16708[0m[0m | time: 22.620s
[2K
| RMSProp | epoch: 016 | loss: 0.16708 - acc: 0.9459 -- iter: 0960/1707
[A[ATraining Step: 841  | total loss: [1m[32m0.15728[0m[0m | time: 23.391s
[2K
| RMSProp | epoch: 016 | loss: 0.15728 - acc: 0.9482 -- iter: 0992/1707
[A[ATraining Step: 842  | total loss: [1m[32m0.17026[0m[0m | time: 24.120s
[2K
| RMSProp | epoch: 016 | loss: 0.17026 - acc: 0.9471 -- iter: 1024/1707
[A[ATraining Step: 843  | total loss: [1m[32m0.16918[0m[0m | time: 24.887s
[2K
| RMSProp | epoch: 016 | loss: 0.16918 - acc: 0.9461 -- iter: 1056/1707
[A[ATraining Step: 844  | total loss: [1m[32m0.18761[0m[0m | time: 25.634s
[2K
| RMSProp | epoch: 016 | loss: 0.18761 - acc: 0.9390 -- iter: 1088/1707
[A[ATraining Step: 845  | total loss: [1m[32m0.19848[0m[0m | time: 26.398s
[2K
| RMSProp | epoch: 016 | loss: 0.19848 - acc: 0.9326 -- iter: 1120/1707
[A[ATraining Step: 846  | total loss: [1m[32m0.19460[0m[0m | time: 27.154s
[2K
| RMSProp | epoch: 016 | loss: 0.19460 - acc: 0.9331 -- iter: 1152/1707
[A[ATraining Step: 847  | total loss: [1m[32m0.19343[0m[0m | time: 27.905s
[2K
| RMSProp | epoch: 016 | loss: 0.19343 - acc: 0.9336 -- iter: 1184/1707
[A[ATraining Step: 848  | total loss: [1m[32m0.17721[0m[0m | time: 28.656s
[2K
| RMSProp | epoch: 016 | loss: 0.17721 - acc: 0.9402 -- iter: 1216/1707
[A[ATraining Step: 849  | total loss: [1m[32m0.16268[0m[0m | time: 29.386s
[2K
| RMSProp | epoch: 016 | loss: 0.16268 - acc: 0.9462 -- iter: 1248/1707
[A[ATraining Step: 850  | total loss: [1m[32m0.15038[0m[0m | time: 30.111s
[2K
| RMSProp | epoch: 016 | loss: 0.15038 - acc: 0.9516 -- iter: 1280/1707
[A[ATraining Step: 851  | total loss: [1m[32m0.13751[0m[0m | time: 30.857s
[2K
| RMSProp | epoch: 016 | loss: 0.13751 - acc: 0.9564 -- iter: 1312/1707
[A[ATraining Step: 852  | total loss: [1m[32m0.13237[0m[0m | time: 31.687s
[2K
| RMSProp | epoch: 016 | loss: 0.13237 - acc: 0.9576 -- iter: 1344/1707
[A[ATraining Step: 853  | total loss: [1m[32m0.13521[0m[0m | time: 32.443s
[2K
| RMSProp | epoch: 016 | loss: 0.13521 - acc: 0.9525 -- iter: 1376/1707
[A[ATraining Step: 854  | total loss: [1m[32m0.14832[0m[0m | time: 33.168s
[2K
| RMSProp | epoch: 016 | loss: 0.14832 - acc: 0.9479 -- iter: 1408/1707
[A[ATraining Step: 855  | total loss: [1m[32m0.14130[0m[0m | time: 33.915s
[2K
| RMSProp | epoch: 016 | loss: 0.14130 - acc: 0.9500 -- iter: 1440/1707
[A[ATraining Step: 856  | total loss: [1m[32m0.12948[0m[0m | time: 34.627s
[2K
| RMSProp | epoch: 016 | loss: 0.12948 - acc: 0.9550 -- iter: 1472/1707
[A[ATraining Step: 857  | total loss: [1m[32m0.12425[0m[0m | time: 35.397s
[2K
| RMSProp | epoch: 016 | loss: 0.12425 - acc: 0.9563 -- iter: 1504/1707
[A[ATraining Step: 858  | total loss: [1m[32m0.11578[0m[0m | time: 36.308s
[2K
| RMSProp | epoch: 016 | loss: 0.11578 - acc: 0.9607 -- iter: 1536/1707
[A[ATraining Step: 859  | total loss: [1m[32m0.10720[0m[0m | time: 37.393s
[2K
| RMSProp | epoch: 016 | loss: 0.10720 - acc: 0.9646 -- iter: 1568/1707
[A[ATraining Step: 860  | total loss: [1m[32m0.10173[0m[0m | time: 38.530s
[2K
| RMSProp | epoch: 016 | loss: 0.10173 - acc: 0.9651 -- iter: 1600/1707
[A[ATraining Step: 861  | total loss: [1m[32m0.09526[0m[0m | time: 39.367s
[2K
| RMSProp | epoch: 016 | loss: 0.09526 - acc: 0.9685 -- iter: 1632/1707
[A[ATraining Step: 862  | total loss: [1m[32m0.09369[0m[0m | time: 40.197s
[2K
| RMSProp | epoch: 016 | loss: 0.09369 - acc: 0.9686 -- iter: 1664/1707
[A[ATraining Step: 863  | total loss: [1m[32m0.14198[0m[0m | time: 40.998s
[2K
| RMSProp | epoch: 016 | loss: 0.14198 - acc: 0.9592 -- iter: 1696/1707
[A[ATraining Step: 864  | total loss: [1m[32m0.14044[0m[0m | time: 43.903s
[2K
| RMSProp | epoch: 016 | loss: 0.14044 - acc: 0.9602 | val_loss: 0.91980 - val_acc: 0.7172 -- iter: 1707/1707
--
Training Step: 865  | total loss: [1m[32m0.14439[0m[0m | time: 0.791s
[2K
| RMSProp | epoch: 017 | loss: 0.14439 - acc: 0.9579 -- iter: 0032/1707
[A[ATraining Step: 866  | total loss: [1m[32m0.14621[0m[0m | time: 1.643s
[2K
| RMSProp | epoch: 017 | loss: 0.14621 - acc: 0.9527 -- iter: 0064/1707
[A[ATraining Step: 867  | total loss: [1m[32m0.15528[0m[0m | time: 2.435s
[2K
| RMSProp | epoch: 017 | loss: 0.15528 - acc: 0.9481 -- iter: 0096/1707
[A[ATraining Step: 868  | total loss: [1m[32m0.14422[0m[0m | time: 3.217s
[2K
| RMSProp | epoch: 017 | loss: 0.14422 - acc: 0.9533 -- iter: 0128/1707
[A[ATraining Step: 869  | total loss: [1m[32m0.13365[0m[0m | time: 4.013s
[2K
| RMSProp | epoch: 017 | loss: 0.13365 - acc: 0.9579 -- iter: 0160/1707
[A[ATraining Step: 870  | total loss: [1m[32m0.12381[0m[0m | time: 4.856s
[2K
| RMSProp | epoch: 017 | loss: 0.12381 - acc: 0.9622 -- iter: 0192/1707
[A[ATraining Step: 871  | total loss: [1m[32m0.12452[0m[0m | time: 5.656s
[2K
| RMSProp | epoch: 017 | loss: 0.12452 - acc: 0.9628 -- iter: 0224/1707
[A[ATraining Step: 872  | total loss: [1m[32m0.11625[0m[0m | time: 6.481s
[2K
| RMSProp | epoch: 017 | loss: 0.11625 - acc: 0.9665 -- iter: 0256/1707
[A[ATraining Step: 873  | total loss: [1m[32m0.10717[0m[0m | time: 7.187s
[2K
| RMSProp | epoch: 017 | loss: 0.10717 - acc: 0.9699 -- iter: 0288/1707
[A[ATraining Step: 874  | total loss: [1m[32m0.10074[0m[0m | time: 7.941s
[2K
| RMSProp | epoch: 017 | loss: 0.10074 - acc: 0.9729 -- iter: 0320/1707
[A[ATraining Step: 875  | total loss: [1m[32m0.11526[0m[0m | time: 8.735s
[2K
| RMSProp | epoch: 017 | loss: 0.11526 - acc: 0.9662 -- iter: 0352/1707
[A[ATraining Step: 876  | total loss: [1m[32m0.14492[0m[0m | time: 9.527s
[2K
| RMSProp | epoch: 017 | loss: 0.14492 - acc: 0.9571 -- iter: 0384/1707
[A[ATraining Step: 877  | total loss: [1m[32m0.13345[0m[0m | time: 10.296s
[2K
| RMSProp | epoch: 017 | loss: 0.13345 - acc: 0.9614 -- iter: 0416/1707
[A[ATraining Step: 878  | total loss: [1m[32m0.12201[0m[0m | time: 11.069s
[2K
| RMSProp | epoch: 017 | loss: 0.12201 - acc: 0.9653 -- iter: 0448/1707
[A[ATraining Step: 879  | total loss: [1m[32m0.11941[0m[0m | time: 11.390s
[2K
| RMSProp | epoch: 017 | loss: 0.11941 - acc: 0.9625 -- iter: 0480/1707
[A[ATraining Step: 880  | total loss: [1m[32m0.19409[0m[0m | time: 11.675s
[2K
| RMSProp | epoch: 017 | loss: 0.19409 - acc: 0.9480 -- iter: 0512/1707
[A[ATraining Step: 881  | total loss: [1m[32m0.17833[0m[0m | time: 12.408s
[2K
| RMSProp | epoch: 017 | loss: 0.17833 - acc: 0.9532 -- iter: 0544/1707
[A[ATraining Step: 882  | total loss: [1m[32m0.17954[0m[0m | time: 13.144s
[2K
| RMSProp | epoch: 017 | loss: 0.17954 - acc: 0.9548 -- iter: 0576/1707
[A[ATraining Step: 883  | total loss: [1m[32m0.17419[0m[0m | time: 13.864s
[2K
| RMSProp | epoch: 017 | loss: 0.17419 - acc: 0.9562 -- iter: 0608/1707
[A[ATraining Step: 884  | total loss: [1m[32m0.16067[0m[0m | time: 14.611s
[2K
| RMSProp | epoch: 017 | loss: 0.16067 - acc: 0.9606 -- iter: 0640/1707
[A[ATraining Step: 885  | total loss: [1m[32m0.15079[0m[0m | time: 15.363s
[2K
| RMSProp | epoch: 017 | loss: 0.15079 - acc: 0.9645 -- iter: 0672/1707
[A[ATraining Step: 886  | total loss: [1m[32m0.15208[0m[0m | time: 16.125s
[2K
| RMSProp | epoch: 017 | loss: 0.15208 - acc: 0.9618 -- iter: 0704/1707
[A[ATraining Step: 887  | total loss: [1m[32m0.16158[0m[0m | time: 16.868s
[2K
| RMSProp | epoch: 017 | loss: 0.16158 - acc: 0.9563 -- iter: 0736/1707
[A[ATraining Step: 888  | total loss: [1m[32m0.20313[0m[0m | time: 17.635s
[2K
| RMSProp | epoch: 017 | loss: 0.20313 - acc: 0.9419 -- iter: 0768/1707
[A[ATraining Step: 889  | total loss: [1m[32m0.21960[0m[0m | time: 18.357s
[2K
| RMSProp | epoch: 017 | loss: 0.21960 - acc: 0.9383 -- iter: 0800/1707
[A[ATraining Step: 890  | total loss: [1m[32m0.20249[0m[0m | time: 19.081s
[2K
| RMSProp | epoch: 017 | loss: 0.20249 - acc: 0.9445 -- iter: 0832/1707
[A[ATraining Step: 891  | total loss: [1m[32m0.20492[0m[0m | time: 19.855s
[2K
| RMSProp | epoch: 017 | loss: 0.20492 - acc: 0.9407 -- iter: 0864/1707
[A[ATraining Step: 892  | total loss: [1m[32m0.20416[0m[0m | time: 20.570s
[2K
| RMSProp | epoch: 017 | loss: 0.20416 - acc: 0.9372 -- iter: 0896/1707
[A[ATraining Step: 893  | total loss: [1m[32m0.20142[0m[0m | time: 21.305s
[2K
| RMSProp | epoch: 017 | loss: 0.20142 - acc: 0.9372 -- iter: 0928/1707
[A[ATraining Step: 894  | total loss: [1m[32m0.21311[0m[0m | time: 22.040s
[2K
| RMSProp | epoch: 017 | loss: 0.21311 - acc: 0.9310 -- iter: 0960/1707
[A[ATraining Step: 895  | total loss: [1m[32m0.21051[0m[0m | time: 22.774s
[2K
| RMSProp | epoch: 017 | loss: 0.21051 - acc: 0.9285 -- iter: 0992/1707
[A[ATraining Step: 896  | total loss: [1m[32m0.20377[0m[0m | time: 23.536s
[2K
| RMSProp | epoch: 017 | loss: 0.20377 - acc: 0.9326 -- iter: 1024/1707
[A[ATraining Step: 897  | total loss: [1m[32m0.18960[0m[0m | time: 24.269s
[2K
| RMSProp | epoch: 017 | loss: 0.18960 - acc: 0.9393 -- iter: 1056/1707
[A[ATraining Step: 898  | total loss: [1m[32m0.18423[0m[0m | time: 25.020s
[2K
| RMSProp | epoch: 017 | loss: 0.18423 - acc: 0.9391 -- iter: 1088/1707
[A[ATraining Step: 899  | total loss: [1m[32m0.17334[0m[0m | time: 25.821s
[2K
| RMSProp | epoch: 017 | loss: 0.17334 - acc: 0.9452 -- iter: 1120/1707
[A[ATraining Step: 900  | total loss: [1m[32m0.17351[0m[0m | time: 26.611s
[2K
| RMSProp | epoch: 017 | loss: 0.17351 - acc: 0.9444 -- iter: 1152/1707
[A[ATraining Step: 901  | total loss: [1m[32m0.16893[0m[0m | time: 27.730s
[2K
| RMSProp | epoch: 017 | loss: 0.16893 - acc: 0.9469 -- iter: 1184/1707
[A[ATraining Step: 902  | total loss: [1m[32m0.15445[0m[0m | time: 28.854s
[2K
| RMSProp | epoch: 017 | loss: 0.15445 - acc: 0.9522 -- iter: 1216/1707
[A[ATraining Step: 903  | total loss: [1m[32m0.15498[0m[0m | time: 29.751s
[2K
| RMSProp | epoch: 017 | loss: 0.15498 - acc: 0.9538 -- iter: 1248/1707
[A[ATraining Step: 904  | total loss: [1m[32m0.15020[0m[0m | time: 30.479s
[2K
| RMSProp | epoch: 017 | loss: 0.15020 - acc: 0.9522 -- iter: 1280/1707
[A[ATraining Step: 905  | total loss: [1m[32m0.13950[0m[0m | time: 31.229s
[2K
| RMSProp | epoch: 017 | loss: 0.13950 - acc: 0.9570 -- iter: 1312/1707
[A[ATraining Step: 906  | total loss: [1m[32m0.12725[0m[0m | time: 31.960s
[2K
| RMSProp | epoch: 017 | loss: 0.12725 - acc: 0.9613 -- iter: 1344/1707
[A[ATraining Step: 907  | total loss: [1m[32m0.12133[0m[0m | time: 32.705s
[2K
| RMSProp | epoch: 017 | loss: 0.12133 - acc: 0.9620 -- iter: 1376/1707
[A[ATraining Step: 908  | total loss: [1m[32m0.12204[0m[0m | time: 33.436s
[2K
| RMSProp | epoch: 017 | loss: 0.12204 - acc: 0.9596 -- iter: 1408/1707
[A[ATraining Step: 909  | total loss: [1m[32m0.13570[0m[0m | time: 34.148s
[2K
| RMSProp | epoch: 017 | loss: 0.13570 - acc: 0.9511 -- iter: 1440/1707
[A[ATraining Step: 910  | total loss: [1m[32m0.14122[0m[0m | time: 34.819s
[2K
| RMSProp | epoch: 017 | loss: 0.14122 - acc: 0.9498 -- iter: 1472/1707
[A[ATraining Step: 911  | total loss: [1m[32m0.13700[0m[0m | time: 35.610s
[2K
| RMSProp | epoch: 017 | loss: 0.13700 - acc: 0.9485 -- iter: 1504/1707
[A[ATraining Step: 912  | total loss: [1m[32m0.12394[0m[0m | time: 36.355s
[2K
| RMSProp | epoch: 017 | loss: 0.12394 - acc: 0.9537 -- iter: 1536/1707
[A[ATraining Step: 913  | total loss: [1m[32m0.12760[0m[0m | time: 37.107s
[2K
| RMSProp | epoch: 017 | loss: 0.12760 - acc: 0.9552 -- iter: 1568/1707
[A[ATraining Step: 914  | total loss: [1m[32m0.11865[0m[0m | time: 37.855s
[2K
| RMSProp | epoch: 017 | loss: 0.11865 - acc: 0.9597 -- iter: 1600/1707
[A[ATraining Step: 915  | total loss: [1m[32m0.12044[0m[0m | time: 38.607s
[2K
| RMSProp | epoch: 017 | loss: 0.12044 - acc: 0.9606 -- iter: 1632/1707
[A[ATraining Step: 916  | total loss: [1m[32m0.11260[0m[0m | time: 39.378s
[2K
| RMSProp | epoch: 017 | loss: 0.11260 - acc: 0.9645 -- iter: 1664/1707
[A[ATraining Step: 917  | total loss: [1m[32m0.11368[0m[0m | time: 40.141s
[2K
| RMSProp | epoch: 017 | loss: 0.11368 - acc: 0.9649 -- iter: 1696/1707
[A[ATraining Step: 918  | total loss: [1m[32m0.12333[0m[0m | time: 43.033s
[2K
| RMSProp | epoch: 017 | loss: 0.12333 - acc: 0.9622 | val_loss: 0.67651 - val_acc: 0.7921 -- iter: 1707/1707
--
Training Step: 919  | total loss: [1m[32m0.11269[0m[0m | time: 0.759s
[2K
| RMSProp | epoch: 018 | loss: 0.11269 - acc: 0.9660 -- iter: 0032/1707
[A[ATraining Step: 920  | total loss: [1m[32m0.10479[0m[0m | time: 1.514s
[2K
| RMSProp | epoch: 018 | loss: 0.10479 - acc: 0.9694 -- iter: 0064/1707
[A[ATraining Step: 921  | total loss: [1m[32m0.09999[0m[0m | time: 2.289s
[2K
| RMSProp | epoch: 018 | loss: 0.09999 - acc: 0.9693 -- iter: 0096/1707
[A[ATraining Step: 922  | total loss: [1m[32m0.11864[0m[0m | time: 3.053s
[2K
| RMSProp | epoch: 018 | loss: 0.11864 - acc: 0.9599 -- iter: 0128/1707
[A[ATraining Step: 923  | total loss: [1m[32m0.11250[0m[0m | time: 3.817s
[2K
| RMSProp | epoch: 018 | loss: 0.11250 - acc: 0.9639 -- iter: 0160/1707
[A[ATraining Step: 924  | total loss: [1m[32m0.10201[0m[0m | time: 4.552s
[2K
| RMSProp | epoch: 018 | loss: 0.10201 - acc: 0.9675 -- iter: 0192/1707
[A[ATraining Step: 925  | total loss: [1m[32m0.10277[0m[0m | time: 5.290s
[2K
| RMSProp | epoch: 018 | loss: 0.10277 - acc: 0.9676 -- iter: 0224/1707
[A[ATraining Step: 926  | total loss: [1m[32m0.10158[0m[0m | time: 6.054s
[2K
| RMSProp | epoch: 018 | loss: 0.10158 - acc: 0.9677 -- iter: 0256/1707
[A[ATraining Step: 927  | total loss: [1m[32m0.10771[0m[0m | time: 6.758s
[2K
| RMSProp | epoch: 018 | loss: 0.10771 - acc: 0.9647 -- iter: 0288/1707
[A[ATraining Step: 928  | total loss: [1m[32m0.10723[0m[0m | time: 7.516s
[2K
| RMSProp | epoch: 018 | loss: 0.10723 - acc: 0.9620 -- iter: 0320/1707
[A[ATraining Step: 929  | total loss: [1m[32m0.16603[0m[0m | time: 8.251s
[2K
| RMSProp | epoch: 018 | loss: 0.16603 - acc: 0.9470 -- iter: 0352/1707
[A[ATraining Step: 930  | total loss: [1m[32m0.15732[0m[0m | time: 8.997s
[2K
| RMSProp | epoch: 018 | loss: 0.15732 - acc: 0.9492 -- iter: 0384/1707
[A[ATraining Step: 931  | total loss: [1m[32m0.14687[0m[0m | time: 9.725s
[2K
| RMSProp | epoch: 018 | loss: 0.14687 - acc: 0.9543 -- iter: 0416/1707
[A[ATraining Step: 932  | total loss: [1m[32m0.13595[0m[0m | time: 10.463s
[2K
| RMSProp | epoch: 018 | loss: 0.13595 - acc: 0.9589 -- iter: 0448/1707
[A[ATraining Step: 933  | total loss: [1m[32m0.12639[0m[0m | time: 11.231s
[2K
| RMSProp | epoch: 018 | loss: 0.12639 - acc: 0.9630 -- iter: 0480/1707
[A[ATraining Step: 934  | total loss: [1m[32m0.11691[0m[0m | time: 11.486s
[2K
| RMSProp | epoch: 018 | loss: 0.11691 - acc: 0.9667 -- iter: 0512/1707
[A[ATraining Step: 935  | total loss: [1m[32m0.12778[0m[0m | time: 11.819s
[2K
| RMSProp | epoch: 018 | loss: 0.12778 - acc: 0.9609 -- iter: 0544/1707
[A[ATraining Step: 936  | total loss: [1m[32m0.11720[0m[0m | time: 12.595s
[2K
| RMSProp | epoch: 018 | loss: 0.11720 - acc: 0.9648 -- iter: 0576/1707
[A[ATraining Step: 937  | total loss: [1m[32m0.11974[0m[0m | time: 13.373s
[2K
| RMSProp | epoch: 018 | loss: 0.11974 - acc: 0.9621 -- iter: 0608/1707
[A[ATraining Step: 938  | total loss: [1m[32m0.13915[0m[0m | time: 14.111s
[2K
| RMSProp | epoch: 018 | loss: 0.13915 - acc: 0.9596 -- iter: 0640/1707
[A[ATraining Step: 939  | total loss: [1m[32m0.14247[0m[0m | time: 14.854s
[2K
| RMSProp | epoch: 018 | loss: 0.14247 - acc: 0.9574 -- iter: 0672/1707
[A[ATraining Step: 940  | total loss: [1m[32m0.14705[0m[0m | time: 15.613s
[2K
| RMSProp | epoch: 018 | loss: 0.14705 - acc: 0.9554 -- iter: 0704/1707
[A[ATraining Step: 941  | total loss: [1m[32m0.14385[0m[0m | time: 16.348s
[2K
| RMSProp | epoch: 018 | loss: 0.14385 - acc: 0.9568 -- iter: 0736/1707
[A[ATraining Step: 942  | total loss: [1m[32m0.13252[0m[0m | time: 17.114s
[2K
| RMSProp | epoch: 018 | loss: 0.13252 - acc: 0.9611 -- iter: 0768/1707
[A[ATraining Step: 943  | total loss: [1m[32m0.12937[0m[0m | time: 17.864s
[2K
| RMSProp | epoch: 018 | loss: 0.12937 - acc: 0.9619 -- iter: 0800/1707
[A[ATraining Step: 944  | total loss: [1m[32m0.11789[0m[0m | time: 18.632s
[2K
| RMSProp | epoch: 018 | loss: 0.11789 - acc: 0.9657 -- iter: 0832/1707
[A[ATraining Step: 945  | total loss: [1m[32m0.14115[0m[0m | time: 19.374s
[2K
| RMSProp | epoch: 018 | loss: 0.14115 - acc: 0.9597 -- iter: 0864/1707
[A[ATraining Step: 946  | total loss: [1m[32m0.14166[0m[0m | time: 20.114s
[2K
| RMSProp | epoch: 018 | loss: 0.14166 - acc: 0.9606 -- iter: 0896/1707
[A[ATraining Step: 947  | total loss: [1m[32m0.13999[0m[0m | time: 20.844s
[2K
| RMSProp | epoch: 018 | loss: 0.13999 - acc: 0.9614 -- iter: 0928/1707
[A[ATraining Step: 948  | total loss: [1m[32m0.14189[0m[0m | time: 21.608s
[2K
| RMSProp | epoch: 018 | loss: 0.14189 - acc: 0.9559 -- iter: 0960/1707
[A[ATraining Step: 949  | total loss: [1m[32m0.14445[0m[0m | time: 22.330s
[2K
| RMSProp | epoch: 018 | loss: 0.14445 - acc: 0.9541 -- iter: 0992/1707
[A[ATraining Step: 950  | total loss: [1m[32m0.14435[0m[0m | time: 23.038s
[2K
| RMSProp | epoch: 018 | loss: 0.14435 - acc: 0.9555 -- iter: 1024/1707
[A[ATraining Step: 951  | total loss: [1m[32m0.14542[0m[0m | time: 23.796s
[2K
| RMSProp | epoch: 018 | loss: 0.14542 - acc: 0.9537 -- iter: 1056/1707
[A[ATraining Step: 952  | total loss: [1m[32m0.13608[0m[0m | time: 24.547s
[2K
| RMSProp | epoch: 018 | loss: 0.13608 - acc: 0.9584 -- iter: 1088/1707
[A[ATraining Step: 953  | total loss: [1m[32m0.14402[0m[0m | time: 25.286s
[2K
| RMSProp | epoch: 018 | loss: 0.14402 - acc: 0.9532 -- iter: 1120/1707
[A[ATraining Step: 954  | total loss: [1m[32m0.15247[0m[0m | time: 26.053s
[2K
| RMSProp | epoch: 018 | loss: 0.15247 - acc: 0.9485 -- iter: 1152/1707
[A[ATraining Step: 955  | total loss: [1m[32m0.14638[0m[0m | time: 26.801s
[2K
| RMSProp | epoch: 018 | loss: 0.14638 - acc: 0.9505 -- iter: 1184/1707
[A[ATraining Step: 956  | total loss: [1m[32m0.13575[0m[0m | time: 27.527s
[2K
| RMSProp | epoch: 018 | loss: 0.13575 - acc: 0.9554 -- iter: 1216/1707
[A[ATraining Step: 957  | total loss: [1m[32m0.14099[0m[0m | time: 28.249s
[2K
| RMSProp | epoch: 018 | loss: 0.14099 - acc: 0.9536 -- iter: 1248/1707
[A[ATraining Step: 958  | total loss: [1m[32m0.13664[0m[0m | time: 28.954s
[2K
| RMSProp | epoch: 018 | loss: 0.13664 - acc: 0.9552 -- iter: 1280/1707
[A[ATraining Step: 959  | total loss: [1m[32m0.12733[0m[0m | time: 29.717s
[2K
| RMSProp | epoch: 018 | loss: 0.12733 - acc: 0.9596 -- iter: 1312/1707
[A[ATraining Step: 960  | total loss: [1m[32m0.12421[0m[0m | time: 30.532s
[2K
| RMSProp | epoch: 018 | loss: 0.12421 - acc: 0.9574 -- iter: 1344/1707
[A[ATraining Step: 961  | total loss: [1m[32m0.11723[0m[0m | time: 31.277s
[2K
| RMSProp | epoch: 018 | loss: 0.11723 - acc: 0.9617 -- iter: 1376/1707
[A[ATraining Step: 962  | total loss: [1m[32m0.11400[0m[0m | time: 31.996s
[2K
| RMSProp | epoch: 018 | loss: 0.11400 - acc: 0.9593 -- iter: 1408/1707
[A[ATraining Step: 963  | total loss: [1m[32m0.11453[0m[0m | time: 32.724s
[2K
| RMSProp | epoch: 018 | loss: 0.11453 - acc: 0.9602 -- iter: 1440/1707
[A[ATraining Step: 964  | total loss: [1m[32m0.10494[0m[0m | time: 33.469s
[2K
| RMSProp | epoch: 018 | loss: 0.10494 - acc: 0.9642 -- iter: 1472/1707
[A[ATraining Step: 965  | total loss: [1m[32m0.09573[0m[0m | time: 34.229s
[2K
| RMSProp | epoch: 018 | loss: 0.09573 - acc: 0.9678 -- iter: 1504/1707
[A[ATraining Step: 966  | total loss: [1m[32m0.08670[0m[0m | time: 34.985s
[2K
| RMSProp | epoch: 018 | loss: 0.08670 - acc: 0.9710 -- iter: 1536/1707
[A[ATraining Step: 967  | total loss: [1m[32m0.08017[0m[0m | time: 35.723s
[2K
| RMSProp | epoch: 018 | loss: 0.08017 - acc: 0.9739 -- iter: 1568/1707
[A[ATraining Step: 968  | total loss: [1m[32m0.08717[0m[0m | time: 36.497s
[2K
| RMSProp | epoch: 018 | loss: 0.08717 - acc: 0.9703 -- iter: 1600/1707
[A[ATraining Step: 969  | total loss: [1m[32m0.08426[0m[0m | time: 37.278s
[2K
| RMSProp | epoch: 018 | loss: 0.08426 - acc: 0.9701 -- iter: 1632/1707
[A[ATraining Step: 970  | total loss: [1m[32m0.07713[0m[0m | time: 38.023s
[2K
| RMSProp | epoch: 018 | loss: 0.07713 - acc: 0.9731 -- iter: 1664/1707
[A[ATraining Step: 971  | total loss: [1m[32m0.07526[0m[0m | time: 38.786s
[2K
| RMSProp | epoch: 018 | loss: 0.07526 - acc: 0.9727 -- iter: 1696/1707
[A[ATraining Step: 972  | total loss: [1m[32m0.08539[0m[0m | time: 41.614s
[2K
| RMSProp | epoch: 018 | loss: 0.08539 - acc: 0.9723 | val_loss: 0.98545 - val_acc: 0.7921 -- iter: 1707/1707
--
Training Step: 973  | total loss: [1m[32m0.08447[0m[0m | time: 0.803s
[2K
| RMSProp | epoch: 019 | loss: 0.08447 - acc: 0.9719 -- iter: 0032/1707
[A[ATraining Step: 974  | total loss: [1m[32m0.12368[0m[0m | time: 1.556s
[2K
| RMSProp | epoch: 019 | loss: 0.12368 - acc: 0.9622 -- iter: 0064/1707
[A[ATraining Step: 975  | total loss: [1m[32m0.12423[0m[0m | time: 2.313s
[2K
| RMSProp | epoch: 019 | loss: 0.12423 - acc: 0.9598 -- iter: 0096/1707
[A[ATraining Step: 976  | total loss: [1m[32m0.12782[0m[0m | time: 3.082s
[2K
| RMSProp | epoch: 019 | loss: 0.12782 - acc: 0.9575 -- iter: 0128/1707
[A[ATraining Step: 977  | total loss: [1m[32m0.14307[0m[0m | time: 3.818s
[2K
| RMSProp | epoch: 019 | loss: 0.14307 - acc: 0.9462 -- iter: 0160/1707
[A[ATraining Step: 978  | total loss: [1m[32m0.15645[0m[0m | time: 4.637s
[2K
| RMSProp | epoch: 019 | loss: 0.15645 - acc: 0.9390 -- iter: 0192/1707
[A[ATraining Step: 979  | total loss: [1m[32m0.16629[0m[0m | time: 5.681s
[2K
| RMSProp | epoch: 019 | loss: 0.16629 - acc: 0.9295 -- iter: 0224/1707
[A[ATraining Step: 980  | total loss: [1m[32m0.15990[0m[0m | time: 6.805s
[2K
| RMSProp | epoch: 019 | loss: 0.15990 - acc: 0.9334 -- iter: 0256/1707
[A[ATraining Step: 981  | total loss: [1m[32m0.15913[0m[0m | time: 7.773s
[2K
| RMSProp | epoch: 019 | loss: 0.15913 - acc: 0.9370 -- iter: 0288/1707
[A[ATraining Step: 982  | total loss: [1m[32m0.14955[0m[0m | time: 8.391s
[2K
| RMSProp | epoch: 019 | loss: 0.14955 - acc: 0.9433 -- iter: 0320/1707
[A[ATraining Step: 983  | total loss: [1m[32m0.13633[0m[0m | time: 9.214s
[2K
| RMSProp | epoch: 019 | loss: 0.13633 - acc: 0.9489 -- iter: 0352/1707
[A[ATraining Step: 984  | total loss: [1m[32m0.12460[0m[0m | time: 9.979s
[2K
| RMSProp | epoch: 019 | loss: 0.12460 - acc: 0.9540 -- iter: 0384/1707
[A[ATraining Step: 985  | total loss: [1m[32m0.11906[0m[0m | time: 10.749s
[2K
| RMSProp | epoch: 019 | loss: 0.11906 - acc: 0.9555 -- iter: 0416/1707
[A[ATraining Step: 986  | total loss: [1m[32m0.10897[0m[0m | time: 11.577s
[2K
| RMSProp | epoch: 019 | loss: 0.10897 - acc: 0.9600 -- iter: 0448/1707
[A[ATraining Step: 987  | total loss: [1m[32m0.10089[0m[0m | time: 12.381s
[2K
| RMSProp | epoch: 019 | loss: 0.10089 - acc: 0.9640 -- iter: 0480/1707
[A[ATraining Step: 988  | total loss: [1m[32m0.09466[0m[0m | time: 13.164s
[2K
| RMSProp | epoch: 019 | loss: 0.09466 - acc: 0.9676 -- iter: 0512/1707
[A[ATraining Step: 989  | total loss: [1m[32m0.09742[0m[0m | time: 13.549s
[2K
| RMSProp | epoch: 019 | loss: 0.09742 - acc: 0.9646 -- iter: 0544/1707
[A[ATraining Step: 990  | total loss: [1m[32m0.10563[0m[0m | time: 13.826s
[2K
| RMSProp | epoch: 019 | loss: 0.10563 - acc: 0.9590 -- iter: 0576/1707
[A[ATraining Step: 991  | total loss: [1m[32m0.09512[0m[0m | time: 14.592s
[2K
| RMSProp | epoch: 019 | loss: 0.09512 - acc: 0.9631 -- iter: 0608/1707
[A[ATraining Step: 992  | total loss: [1m[32m0.09505[0m[0m | time: 15.379s
[2K
| RMSProp | epoch: 019 | loss: 0.09505 - acc: 0.9637 -- iter: 0640/1707
[A[ATraining Step: 993  | total loss: [1m[32m0.09827[0m[0m | time: 16.147s
[2K
| RMSProp | epoch: 019 | loss: 0.09827 - acc: 0.9611 -- iter: 0672/1707
[A[ATraining Step: 994  | total loss: [1m[32m0.09801[0m[0m | time: 16.930s
[2K
| RMSProp | epoch: 019 | loss: 0.09801 - acc: 0.9618 -- iter: 0704/1707
[A[ATraining Step: 995  | total loss: [1m[32m0.09497[0m[0m | time: 17.679s
[2K
| RMSProp | epoch: 019 | loss: 0.09497 - acc: 0.9625 -- iter: 0736/1707
[A[ATraining Step: 996  | total loss: [1m[32m0.09458[0m[0m | time: 18.416s
[2K
| RMSProp | epoch: 019 | loss: 0.09458 - acc: 0.9631 -- iter: 0768/1707
[A[ATraining Step: 997  | total loss: [1m[32m0.10038[0m[0m | time: 19.200s
[2K
| RMSProp | epoch: 019 | loss: 0.10038 - acc: 0.9606 -- iter: 0800/1707
[A[ATraining Step: 998  | total loss: [1m[32m0.09975[0m[0m | time: 20.005s
[2K
| RMSProp | epoch: 019 | loss: 0.09975 - acc: 0.9614 -- iter: 0832/1707
[A[ATraining Step: 999  | total loss: [1m[32m0.12945[0m[0m | time: 20.802s
[2K
| RMSProp | epoch: 019 | loss: 0.12945 - acc: 0.9528 -- iter: 0864/1707
[A[ATraining Step: 1000  | total loss: [1m[32m0.14602[0m[0m | time: 23.707s
[2K
| RMSProp | epoch: 019 | loss: 0.14602 - acc: 0.9481 | val_loss: 0.59570 - val_acc: 0.8090 -- iter: 0896/1707
--
Training Step: 1001  | total loss: [1m[32m0.13875[0m[0m | time: 24.541s
[2K
| RMSProp | epoch: 019 | loss: 0.13875 - acc: 0.9502 -- iter: 0928/1707
[A[ATraining Step: 1002  | total loss: [1m[32m0.13181[0m[0m | time: 25.342s
[2K
| RMSProp | epoch: 019 | loss: 0.13181 - acc: 0.9520 -- iter: 0960/1707
[A[ATraining Step: 1003  | total loss: [1m[32m0.13069[0m[0m | time: 26.095s
[2K
| RMSProp | epoch: 019 | loss: 0.13069 - acc: 0.9537 -- iter: 0992/1707
[A[ATraining Step: 1004  | total loss: [1m[32m0.12246[0m[0m | time: 26.894s
[2K
| RMSProp | epoch: 019 | loss: 0.12246 - acc: 0.9583 -- iter: 1024/1707
[A[ATraining Step: 1005  | total loss: [1m[32m0.12242[0m[0m | time: 27.645s
[2K
| RMSProp | epoch: 019 | loss: 0.12242 - acc: 0.9594 -- iter: 1056/1707
[A[ATraining Step: 1006  | total loss: [1m[32m0.11177[0m[0m | time: 28.410s
[2K
| RMSProp | epoch: 019 | loss: 0.11177 - acc: 0.9634 -- iter: 1088/1707
[A[ATraining Step: 1007  | total loss: [1m[32m0.10920[0m[0m | time: 29.145s
[2K
| RMSProp | epoch: 019 | loss: 0.10920 - acc: 0.9640 -- iter: 1120/1707
[A[ATraining Step: 1008  | total loss: [1m[32m0.11399[0m[0m | time: 29.869s
[2K
| RMSProp | epoch: 019 | loss: 0.11399 - acc: 0.9644 -- iter: 1152/1707
[A[ATraining Step: 1009  | total loss: [1m[32m0.12066[0m[0m | time: 30.604s
[2K
| RMSProp | epoch: 019 | loss: 0.12066 - acc: 0.9618 -- iter: 1184/1707
[A[ATraining Step: 1010  | total loss: [1m[32m0.11362[0m[0m | time: 31.351s
[2K
| RMSProp | epoch: 019 | loss: 0.11362 - acc: 0.9656 -- iter: 1216/1707
[A[ATraining Step: 1011  | total loss: [1m[32m0.11881[0m[0m | time: 32.100s
[2K
| RMSProp | epoch: 019 | loss: 0.11881 - acc: 0.9659 -- iter: 1248/1707
[A[ATraining Step: 1012  | total loss: [1m[32m0.11172[0m[0m | time: 32.811s
[2K
| RMSProp | epoch: 019 | loss: 0.11172 - acc: 0.9662 -- iter: 1280/1707
[A[ATraining Step: 1013  | total loss: [1m[32m0.14391[0m[0m | time: 33.557s
[2K
| RMSProp | epoch: 019 | loss: 0.14391 - acc: 0.9633 -- iter: 1312/1707
[A[ATraining Step: 1014  | total loss: [1m[32m0.14761[0m[0m | time: 34.372s
[2K
| RMSProp | epoch: 019 | loss: 0.14761 - acc: 0.9607 -- iter: 1344/1707
[A[ATraining Step: 1015  | total loss: [1m[32m0.13771[0m[0m | time: 35.106s
[2K
| RMSProp | epoch: 019 | loss: 0.13771 - acc: 0.9647 -- iter: 1376/1707
[A[ATraining Step: 1016  | total loss: [1m[32m0.12610[0m[0m | time: 35.847s
[2K
| RMSProp | epoch: 019 | loss: 0.12610 - acc: 0.9682 -- iter: 1408/1707
[A[ATraining Step: 1017  | total loss: [1m[32m0.11868[0m[0m | time: 36.571s
[2K
| RMSProp | epoch: 019 | loss: 0.11868 - acc: 0.9682 -- iter: 1440/1707
[A[ATraining Step: 1018  | total loss: [1m[32m0.12604[0m[0m | time: 37.351s
[2K
| RMSProp | epoch: 019 | loss: 0.12604 - acc: 0.9652 -- iter: 1472/1707
[A[ATraining Step: 1019  | total loss: [1m[32m0.11686[0m[0m | time: 38.115s
[2K
| RMSProp | epoch: 019 | loss: 0.11686 - acc: 0.9687 -- iter: 1504/1707
[A[ATraining Step: 1020  | total loss: [1m[32m0.10916[0m[0m | time: 38.861s
[2K
| RMSProp | epoch: 019 | loss: 0.10916 - acc: 0.9718 -- iter: 1536/1707
[A[ATraining Step: 1021  | total loss: [1m[32m0.10698[0m[0m | time: 39.596s
[2K
| RMSProp | epoch: 019 | loss: 0.10698 - acc: 0.9715 -- iter: 1568/1707
[A[ATraining Step: 1022  | total loss: [1m[32m0.10401[0m[0m | time: 40.368s
[2K
| RMSProp | epoch: 019 | loss: 0.10401 - acc: 0.9712 -- iter: 1600/1707
[A[ATraining Step: 1023  | total loss: [1m[32m0.12130[0m[0m | time: 41.105s
[2K
| RMSProp | epoch: 019 | loss: 0.12130 - acc: 0.9585 -- iter: 1632/1707
[A[ATraining Step: 1024  | total loss: [1m[32m0.12529[0m[0m | time: 41.886s
[2K
| RMSProp | epoch: 019 | loss: 0.12529 - acc: 0.9564 -- iter: 1664/1707
[A[ATraining Step: 1025  | total loss: [1m[32m0.11487[0m[0m | time: 42.620s
[2K
| RMSProp | epoch: 019 | loss: 0.11487 - acc: 0.9607 -- iter: 1696/1707
[A[ATraining Step: 1026  | total loss: [1m[32m0.10431[0m[0m | time: 45.611s
[2K
| RMSProp | epoch: 019 | loss: 0.10431 - acc: 0.9647 | val_loss: 0.88190 - val_acc: 0.7790 -- iter: 1707/1707
--
Training Step: 1027  | total loss: [1m[32m0.09642[0m[0m | time: 0.749s
[2K
| RMSProp | epoch: 020 | loss: 0.09642 - acc: 0.9682 -- iter: 0032/1707
[A[ATraining Step: 1028  | total loss: [1m[32m0.11717[0m[0m | time: 1.460s
[2K
| RMSProp | epoch: 020 | loss: 0.11717 - acc: 0.9651 -- iter: 0064/1707
[A[ATraining Step: 1029  | total loss: [1m[32m0.11105[0m[0m | time: 2.207s
[2K
| RMSProp | epoch: 020 | loss: 0.11105 - acc: 0.9655 -- iter: 0096/1707
[A[ATraining Step: 1030  | total loss: [1m[32m0.10084[0m[0m | time: 2.948s
[2K
| RMSProp | epoch: 020 | loss: 0.10084 - acc: 0.9689 -- iter: 0128/1707
[A[ATraining Step: 1031  | total loss: [1m[32m0.09221[0m[0m | time: 3.690s
[2K
| RMSProp | epoch: 020 | loss: 0.09221 - acc: 0.9720 -- iter: 0160/1707
[A[ATraining Step: 1032  | total loss: [1m[32m0.08438[0m[0m | time: 4.454s
[2K
| RMSProp | epoch: 020 | loss: 0.08438 - acc: 0.9748 -- iter: 0192/1707
[A[ATraining Step: 1033  | total loss: [1m[32m0.08806[0m[0m | time: 5.209s
[2K
| RMSProp | epoch: 020 | loss: 0.08806 - acc: 0.9742 -- iter: 0224/1707
[A[ATraining Step: 1034  | total loss: [1m[32m0.12673[0m[0m | time: 5.959s
[2K
| RMSProp | epoch: 020 | loss: 0.12673 - acc: 0.9643 -- iter: 0256/1707
[A[ATraining Step: 1035  | total loss: [1m[32m0.12678[0m[0m | time: 6.700s
[2K
| RMSProp | epoch: 020 | loss: 0.12678 - acc: 0.9616 -- iter: 0288/1707
[A[ATraining Step: 1036  | total loss: [1m[32m0.13998[0m[0m | time: 7.429s
[2K
| RMSProp | epoch: 020 | loss: 0.13998 - acc: 0.9592 -- iter: 0320/1707
[A[ATraining Step: 1037  | total loss: [1m[32m0.13763[0m[0m | time: 8.145s
[2K
| RMSProp | epoch: 020 | loss: 0.13763 - acc: 0.9602 -- iter: 0352/1707
[A[ATraining Step: 1038  | total loss: [1m[32m0.12750[0m[0m | time: 8.884s
[2K
| RMSProp | epoch: 020 | loss: 0.12750 - acc: 0.9642 -- iter: 0384/1707
[A[ATraining Step: 1039  | total loss: [1m[32m0.11715[0m[0m | time: 9.610s
[2K
| RMSProp | epoch: 020 | loss: 0.11715 - acc: 0.9677 -- iter: 0416/1707
[A[ATraining Step: 1040  | total loss: [1m[32m0.11424[0m[0m | time: 10.402s
[2K
| RMSProp | epoch: 020 | loss: 0.11424 - acc: 0.9678 -- iter: 0448/1707
[A[ATraining Step: 1041  | total loss: [1m[32m0.11104[0m[0m | time: 11.161s
[2K
| RMSProp | epoch: 020 | loss: 0.11104 - acc: 0.9648 -- iter: 0480/1707
[A[ATraining Step: 1042  | total loss: [1m[32m0.11400[0m[0m | time: 11.916s
[2K
| RMSProp | epoch: 020 | loss: 0.11400 - acc: 0.9621 -- iter: 0512/1707
[A[ATraining Step: 1043  | total loss: [1m[32m0.11029[0m[0m | time: 12.680s
[2K
| RMSProp | epoch: 020 | loss: 0.11029 - acc: 0.9627 -- iter: 0544/1707
[A[ATraining Step: 1044  | total loss: [1m[32m0.10384[0m[0m | time: 12.954s
[2K
| RMSProp | epoch: 020 | loss: 0.10384 - acc: 0.9633 -- iter: 0576/1707
[A[ATraining Step: 1045  | total loss: [1m[32m0.09407[0m[0m | time: 13.274s
[2K
| RMSProp | epoch: 020 | loss: 0.09407 - acc: 0.9670 -- iter: 0608/1707
[A[ATraining Step: 1046  | total loss: [1m[32m0.08495[0m[0m | time: 14.052s
[2K
| RMSProp | epoch: 020 | loss: 0.08495 - acc: 0.9703 -- iter: 0640/1707
[A[ATraining Step: 1047  | total loss: [1m[32m0.08165[0m[0m | time: 14.814s
[2K
| RMSProp | epoch: 020 | loss: 0.08165 - acc: 0.9702 -- iter: 0672/1707
[A[ATraining Step: 1048  | total loss: [1m[32m0.07408[0m[0m | time: 15.587s
[2K
| RMSProp | epoch: 020 | loss: 0.07408 - acc: 0.9731 -- iter: 0704/1707
[A[ATraining Step: 1049  | total loss: [1m[32m0.06775[0m[0m | time: 16.346s
[2K
| RMSProp | epoch: 020 | loss: 0.06775 - acc: 0.9758 -- iter: 0736/1707
[A[ATraining Step: 1050  | total loss: [1m[32m0.06185[0m[0m | time: 17.106s
[2K
| RMSProp | epoch: 020 | loss: 0.06185 - acc: 0.9782 -- iter: 0768/1707
[A[ATraining Step: 1051  | total loss: [1m[32m0.10235[0m[0m | time: 17.858s
[2K
| RMSProp | epoch: 020 | loss: 0.10235 - acc: 0.9710 -- iter: 0800/1707
[A[ATraining Step: 1052  | total loss: [1m[32m0.11033[0m[0m | time: 18.588s
[2K
| RMSProp | epoch: 020 | loss: 0.11033 - acc: 0.9646 -- iter: 0832/1707
[A[ATraining Step: 1053  | total loss: [1m[32m0.11044[0m[0m | time: 19.319s
[2K
| RMSProp | epoch: 020 | loss: 0.11044 - acc: 0.9619 -- iter: 0864/1707
[A[ATraining Step: 1054  | total loss: [1m[32m0.11045[0m[0m | time: 20.059s
[2K
| RMSProp | epoch: 020 | loss: 0.11045 - acc: 0.9625 -- iter: 0896/1707
[A[ATraining Step: 1055  | total loss: [1m[32m0.10107[0m[0m | time: 20.802s
[2K
| RMSProp | epoch: 020 | loss: 0.10107 - acc: 0.9663 -- iter: 0928/1707
[A[ATraining Step: 1056  | total loss: [1m[32m0.09875[0m[0m | time: 21.561s
[2K
| RMSProp | epoch: 020 | loss: 0.09875 - acc: 0.9634 -- iter: 0960/1707
[A[ATraining Step: 1057  | total loss: [1m[32m0.09039[0m[0m | time: 22.355s
[2K
| RMSProp | epoch: 020 | loss: 0.09039 - acc: 0.9671 -- iter: 0992/1707
[A[ATraining Step: 1058  | total loss: [1m[32m0.08473[0m[0m | time: 23.455s
[2K
| RMSProp | epoch: 020 | loss: 0.08473 - acc: 0.9704 -- iter: 1024/1707
[A[ATraining Step: 1059  | total loss: [1m[32m0.09964[0m[0m | time: 24.565s
[2K
| RMSProp | epoch: 020 | loss: 0.09964 - acc: 0.9671 -- iter: 1056/1707
[A[ATraining Step: 1060  | total loss: [1m[32m0.09094[0m[0m | time: 25.435s
[2K
| RMSProp | epoch: 020 | loss: 0.09094 - acc: 0.9704 -- iter: 1088/1707
[A[ATraining Step: 1061  | total loss: [1m[32m0.08388[0m[0m | time: 26.131s
[2K
| RMSProp | epoch: 020 | loss: 0.08388 - acc: 0.9733 -- iter: 1120/1707
[A[ATraining Step: 1062  | total loss: [1m[32m0.07969[0m[0m | time: 26.856s
[2K
| RMSProp | epoch: 020 | loss: 0.07969 - acc: 0.9760 -- iter: 1152/1707
[A[ATraining Step: 1063  | total loss: [1m[32m0.09750[0m[0m | time: 27.650s
[2K
| RMSProp | epoch: 020 | loss: 0.09750 - acc: 0.9721 -- iter: 1184/1707
[A[ATraining Step: 1064  | total loss: [1m[32m0.12908[0m[0m | time: 28.420s
[2K
| RMSProp | epoch: 020 | loss: 0.12908 - acc: 0.9656 -- iter: 1216/1707
[A[ATraining Step: 1065  | total loss: [1m[32m0.13335[0m[0m | time: 29.165s
[2K
| RMSProp | epoch: 020 | loss: 0.13335 - acc: 0.9628 -- iter: 1248/1707
[A[ATraining Step: 1066  | total loss: [1m[32m0.13305[0m[0m | time: 29.909s
[2K
| RMSProp | epoch: 020 | loss: 0.13305 - acc: 0.9602 -- iter: 1280/1707
[A[ATraining Step: 1067  | total loss: [1m[32m0.13388[0m[0m | time: 30.699s
[2K
| RMSProp | epoch: 020 | loss: 0.13388 - acc: 0.9548 -- iter: 1312/1707
[A[ATraining Step: 1068  | total loss: [1m[32m0.14905[0m[0m | time: 31.430s
[2K
| RMSProp | epoch: 020 | loss: 0.14905 - acc: 0.9531 -- iter: 1344/1707
[A[ATraining Step: 1069  | total loss: [1m[32m0.13865[0m[0m | time: 32.128s
[2K
| RMSProp | epoch: 020 | loss: 0.13865 - acc: 0.9578 -- iter: 1376/1707
[A[ATraining Step: 1070  | total loss: [1m[32m0.13082[0m[0m | time: 32.941s
[2K
| RMSProp | epoch: 020 | loss: 0.13082 - acc: 0.9589 -- iter: 1408/1707
[A[ATraining Step: 1071  | total loss: [1m[32m0.12856[0m[0m | time: 33.686s
[2K
| RMSProp | epoch: 020 | loss: 0.12856 - acc: 0.9599 -- iter: 1440/1707
[A[ATraining Step: 1072  | total loss: [1m[32m0.12241[0m[0m | time: 34.432s
[2K
| RMSProp | epoch: 020 | loss: 0.12241 - acc: 0.9608 -- iter: 1472/1707
[A[ATraining Step: 1073  | total loss: [1m[32m0.13329[0m[0m | time: 35.189s
[2K
| RMSProp | epoch: 020 | loss: 0.13329 - acc: 0.9553 -- iter: 1504/1707
[A[ATraining Step: 1074  | total loss: [1m[32m0.12239[0m[0m | time: 35.933s
[2K
| RMSProp | epoch: 020 | loss: 0.12239 - acc: 0.9598 -- iter: 1536/1707
[A[ATraining Step: 1075  | total loss: [1m[32m0.12197[0m[0m | time: 36.663s
[2K
| RMSProp | epoch: 020 | loss: 0.12197 - acc: 0.9607 -- iter: 1568/1707
[A[ATraining Step: 1076  | total loss: [1m[32m0.12491[0m[0m | time: 37.390s
[2K
| RMSProp | epoch: 020 | loss: 0.12491 - acc: 0.9615 -- iter: 1600/1707
[A[ATraining Step: 1077  | total loss: [1m[32m0.11741[0m[0m | time: 38.111s
[2K
| RMSProp | epoch: 020 | loss: 0.11741 - acc: 0.9622 -- iter: 1632/1707
[A[ATraining Step: 1078  | total loss: [1m[32m0.10770[0m[0m | time: 38.859s
[2K
| RMSProp | epoch: 020 | loss: 0.10770 - acc: 0.9660 -- iter: 1664/1707
[A[ATraining Step: 1079  | total loss: [1m[32m0.09873[0m[0m | time: 39.587s
[2K
| RMSProp | epoch: 020 | loss: 0.09873 - acc: 0.9694 -- iter: 1696/1707
[A[ATraining Step: 1080  | total loss: [1m[32m0.08986[0m[0m | time: 42.460s
[2K
| RMSProp | epoch: 020 | loss: 0.08986 - acc: 0.9725 | val_loss: 0.79048 - val_acc: 0.7884 -- iter: 1707/1707
--
Training Step: 1081  | total loss: [1m[32m0.08268[0m[0m | time: 0.741s
[2K
| RMSProp | epoch: 021 | loss: 0.08268 - acc: 0.9752 -- iter: 0032/1707
[A[ATraining Step: 1082  | total loss: [1m[32m0.08925[0m[0m | time: 1.491s
[2K
| RMSProp | epoch: 021 | loss: 0.08925 - acc: 0.9746 -- iter: 0064/1707
[A[ATraining Step: 1083  | total loss: [1m[32m0.08145[0m[0m | time: 2.236s
[2K
| RMSProp | epoch: 021 | loss: 0.08145 - acc: 0.9771 -- iter: 0096/1707
[A[ATraining Step: 1084  | total loss: [1m[32m0.07408[0m[0m | time: 2.974s
[2K
| RMSProp | epoch: 021 | loss: 0.07408 - acc: 0.9794 -- iter: 0128/1707
[A[ATraining Step: 1085  | total loss: [1m[32m0.06771[0m[0m | time: 3.758s
[2K
| RMSProp | epoch: 021 | loss: 0.06771 - acc: 0.9815 -- iter: 0160/1707
[A[ATraining Step: 1086  | total loss: [1m[32m0.07631[0m[0m | time: 4.508s
[2K
| RMSProp | epoch: 021 | loss: 0.07631 - acc: 0.9802 -- iter: 0192/1707
[A[ATraining Step: 1087  | total loss: [1m[32m0.11334[0m[0m | time: 5.242s
[2K
| RMSProp | epoch: 021 | loss: 0.11334 - acc: 0.9634 -- iter: 0224/1707
[A[ATraining Step: 1088  | total loss: [1m[32m0.13942[0m[0m | time: 5.993s
[2K
| RMSProp | epoch: 021 | loss: 0.13942 - acc: 0.9546 -- iter: 0256/1707
[A[ATraining Step: 1089  | total loss: [1m[32m0.13858[0m[0m | time: 6.731s
[2K
| RMSProp | epoch: 021 | loss: 0.13858 - acc: 0.9560 -- iter: 0288/1707
[A[ATraining Step: 1090  | total loss: [1m[32m0.13179[0m[0m | time: 7.441s
[2K
| RMSProp | epoch: 021 | loss: 0.13179 - acc: 0.9573 -- iter: 0320/1707
[A[ATraining Step: 1091  | total loss: [1m[32m0.12275[0m[0m | time: 8.185s
[2K
| RMSProp | epoch: 021 | loss: 0.12275 - acc: 0.9615 -- iter: 0352/1707
[A[ATraining Step: 1092  | total loss: [1m[32m0.12256[0m[0m | time: 8.921s
[2K
| RMSProp | epoch: 021 | loss: 0.12256 - acc: 0.9591 -- iter: 0384/1707
[A[ATraining Step: 1093  | total loss: [1m[32m0.11153[0m[0m | time: 9.688s
[2K
| RMSProp | epoch: 021 | loss: 0.11153 - acc: 0.9632 -- iter: 0416/1707
[A[ATraining Step: 1094  | total loss: [1m[32m0.10391[0m[0m | time: 10.428s
[2K
| RMSProp | epoch: 021 | loss: 0.10391 - acc: 0.9638 -- iter: 0448/1707
[A[ATraining Step: 1095  | total loss: [1m[32m0.10617[0m[0m | time: 11.178s
[2K
| RMSProp | epoch: 021 | loss: 0.10617 - acc: 0.9643 -- iter: 0480/1707
[A[ATraining Step: 1096  | total loss: [1m[32m0.09829[0m[0m | time: 11.923s
[2K
| RMSProp | epoch: 021 | loss: 0.09829 - acc: 0.9678 -- iter: 0512/1707
[A[ATraining Step: 1097  | total loss: [1m[32m0.09077[0m[0m | time: 12.729s
[2K
| RMSProp | epoch: 021 | loss: 0.09077 - acc: 0.9711 -- iter: 0544/1707
[A[ATraining Step: 1098  | total loss: [1m[32m0.08444[0m[0m | time: 13.469s
[2K
| RMSProp | epoch: 021 | loss: 0.08444 - acc: 0.9708 -- iter: 0576/1707
[A[ATraining Step: 1099  | total loss: [1m[32m0.07733[0m[0m | time: 13.712s
[2K
| RMSProp | epoch: 021 | loss: 0.07733 - acc: 0.9737 -- iter: 0608/1707
[A[ATraining Step: 1100  | total loss: [1m[32m0.07000[0m[0m | time: 14.121s
[2K
| RMSProp | epoch: 021 | loss: 0.07000 - acc: 0.9764 -- iter: 0640/1707
[A[ATraining Step: 1101  | total loss: [1m[32m0.06316[0m[0m | time: 14.841s
[2K
| RMSProp | epoch: 021 | loss: 0.06316 - acc: 0.9787 -- iter: 0672/1707
[A[ATraining Step: 1102  | total loss: [1m[32m0.05922[0m[0m | time: 15.611s
[2K
| RMSProp | epoch: 021 | loss: 0.05922 - acc: 0.9809 -- iter: 0704/1707
[A[ATraining Step: 1103  | total loss: [1m[32m0.06324[0m[0m | time: 16.400s
[2K
| RMSProp | epoch: 021 | loss: 0.06324 - acc: 0.9765 -- iter: 0736/1707
[A[ATraining Step: 1104  | total loss: [1m[32m0.07166[0m[0m | time: 17.121s
[2K
| RMSProp | epoch: 021 | loss: 0.07166 - acc: 0.9726 -- iter: 0768/1707
[A[ATraining Step: 1105  | total loss: [1m[32m0.08189[0m[0m | time: 17.861s
[2K
| RMSProp | epoch: 021 | loss: 0.08189 - acc: 0.9691 -- iter: 0800/1707
[A[ATraining Step: 1106  | total loss: [1m[32m0.11356[0m[0m | time: 18.644s
[2K
| RMSProp | epoch: 021 | loss: 0.11356 - acc: 0.9597 -- iter: 0832/1707
[A[ATraining Step: 1107  | total loss: [1m[32m0.11072[0m[0m | time: 19.382s
[2K
| RMSProp | epoch: 021 | loss: 0.11072 - acc: 0.9606 -- iter: 0864/1707
[A[ATraining Step: 1108  | total loss: [1m[32m0.10534[0m[0m | time: 20.155s
[2K
| RMSProp | epoch: 021 | loss: 0.10534 - acc: 0.9614 -- iter: 0896/1707
[A[ATraining Step: 1109  | total loss: [1m[32m0.10361[0m[0m | time: 20.891s
[2K
| RMSProp | epoch: 021 | loss: 0.10361 - acc: 0.9590 -- iter: 0928/1707
[A[ATraining Step: 1110  | total loss: [1m[32m0.12129[0m[0m | time: 21.647s
[2K
| RMSProp | epoch: 021 | loss: 0.12129 - acc: 0.9537 -- iter: 0960/1707
[A[ATraining Step: 1111  | total loss: [1m[32m0.12665[0m[0m | time: 22.431s
[2K
| RMSProp | epoch: 021 | loss: 0.12665 - acc: 0.9521 -- iter: 0992/1707
[A[ATraining Step: 1112  | total loss: [1m[32m0.11951[0m[0m | time: 23.189s
[2K
| RMSProp | epoch: 021 | loss: 0.11951 - acc: 0.9538 -- iter: 1024/1707
[A[ATraining Step: 1113  | total loss: [1m[32m0.11234[0m[0m | time: 23.910s
[2K
| RMSProp | epoch: 021 | loss: 0.11234 - acc: 0.9584 -- iter: 1056/1707
[A[ATraining Step: 1114  | total loss: [1m[32m0.10678[0m[0m | time: 24.655s
[2K
| RMSProp | epoch: 021 | loss: 0.10678 - acc: 0.9594 -- iter: 1088/1707
[A[ATraining Step: 1115  | total loss: [1m[32m0.11880[0m[0m | time: 25.371s
[2K
| RMSProp | epoch: 021 | loss: 0.11880 - acc: 0.9541 -- iter: 1120/1707
[A[ATraining Step: 1116  | total loss: [1m[32m0.10941[0m[0m | time: 26.128s
[2K
| RMSProp | epoch: 021 | loss: 0.10941 - acc: 0.9587 -- iter: 1152/1707
[A[ATraining Step: 1117  | total loss: [1m[32m0.10054[0m[0m | time: 26.889s
[2K
| RMSProp | epoch: 021 | loss: 0.10054 - acc: 0.9628 -- iter: 1184/1707
[A[ATraining Step: 1118  | total loss: [1m[32m0.10999[0m[0m | time: 27.633s
[2K
| RMSProp | epoch: 021 | loss: 0.10999 - acc: 0.9603 -- iter: 1216/1707
[A[ATraining Step: 1119  | total loss: [1m[32m0.10373[0m[0m | time: 28.380s
[2K
| RMSProp | epoch: 021 | loss: 0.10373 - acc: 0.9643 -- iter: 1248/1707
[A[ATraining Step: 1120  | total loss: [1m[32m0.09442[0m[0m | time: 29.131s
[2K
| RMSProp | epoch: 021 | loss: 0.09442 - acc: 0.9678 -- iter: 1280/1707
[A[ATraining Step: 1121  | total loss: [1m[32m0.08590[0m[0m | time: 29.899s
[2K
| RMSProp | epoch: 021 | loss: 0.08590 - acc: 0.9711 -- iter: 1312/1707
[A[ATraining Step: 1122  | total loss: [1m[32m0.08051[0m[0m | time: 30.672s
[2K
| RMSProp | epoch: 021 | loss: 0.08051 - acc: 0.9708 -- iter: 1344/1707
[A[ATraining Step: 1123  | total loss: [1m[32m0.08690[0m[0m | time: 31.404s
[2K
| RMSProp | epoch: 021 | loss: 0.08690 - acc: 0.9675 -- iter: 1376/1707
[A[ATraining Step: 1124  | total loss: [1m[32m0.08023[0m[0m | time: 32.144s
[2K
| RMSProp | epoch: 021 | loss: 0.08023 - acc: 0.9707 -- iter: 1408/1707
[A[ATraining Step: 1125  | total loss: [1m[32m0.07299[0m[0m | time: 32.901s
[2K
| RMSProp | epoch: 021 | loss: 0.07299 - acc: 0.9737 -- iter: 1440/1707
[A[ATraining Step: 1126  | total loss: [1m[32m0.06968[0m[0m | time: 33.667s
[2K
| RMSProp | epoch: 021 | loss: 0.06968 - acc: 0.9732 -- iter: 1472/1707
[A[ATraining Step: 1127  | total loss: [1m[32m0.08337[0m[0m | time: 34.418s
[2K
| RMSProp | epoch: 021 | loss: 0.08337 - acc: 0.9727 -- iter: 1504/1707
[A[ATraining Step: 1128  | total loss: [1m[32m0.07548[0m[0m | time: 35.164s
[2K
| RMSProp | epoch: 021 | loss: 0.07548 - acc: 0.9755 -- iter: 1536/1707
[A[ATraining Step: 1129  | total loss: [1m[32m0.07220[0m[0m | time: 35.902s
[2K
| RMSProp | epoch: 021 | loss: 0.07220 - acc: 0.9779 -- iter: 1568/1707
[A[ATraining Step: 1130  | total loss: [1m[32m0.08859[0m[0m | time: 36.634s
[2K
| RMSProp | epoch: 021 | loss: 0.08859 - acc: 0.9739 -- iter: 1600/1707
[A[ATraining Step: 1131  | total loss: [1m[32m0.08233[0m[0m | time: 37.333s
[2K
| RMSProp | epoch: 021 | loss: 0.08233 - acc: 0.9765 -- iter: 1632/1707
[A[ATraining Step: 1132  | total loss: [1m[32m0.07501[0m[0m | time: 38.104s
[2K
| RMSProp | epoch: 021 | loss: 0.07501 - acc: 0.9788 -- iter: 1664/1707
[A[ATraining Step: 1133  | total loss: [1m[32m0.06781[0m[0m | time: 38.838s
[2K
| RMSProp | epoch: 021 | loss: 0.06781 - acc: 0.9810 -- iter: 1696/1707
[A[ATraining Step: 1134  | total loss: [1m[32m0.06177[0m[0m | time: 41.653s
[2K
| RMSProp | epoch: 021 | loss: 0.06177 - acc: 0.9829 | val_loss: 0.68409 - val_acc: 0.7959 -- iter: 1707/1707
--
Training Step: 1135  | total loss: [1m[32m0.07037[0m[0m | time: 0.762s
[2K
| RMSProp | epoch: 022 | loss: 0.07037 - acc: 0.9814 -- iter: 0032/1707
[A[ATraining Step: 1136  | total loss: [1m[32m0.06596[0m[0m | time: 1.549s
[2K
| RMSProp | epoch: 022 | loss: 0.06596 - acc: 0.9833 -- iter: 0064/1707
[A[ATraining Step: 1137  | total loss: [1m[32m0.07351[0m[0m | time: 2.608s
[2K
| RMSProp | epoch: 022 | loss: 0.07351 - acc: 0.9818 -- iter: 0096/1707
[A[ATraining Step: 1138  | total loss: [1m[32m0.06807[0m[0m | time: 3.662s
[2K
| RMSProp | epoch: 022 | loss: 0.06807 - acc: 0.9837 -- iter: 0128/1707
[A[ATraining Step: 1139  | total loss: [1m[32m0.06674[0m[0m | time: 4.748s
[2K
| RMSProp | epoch: 022 | loss: 0.06674 - acc: 0.9822 -- iter: 0160/1707
[A[ATraining Step: 1140  | total loss: [1m[32m0.06481[0m[0m | time: 5.378s
[2K
| RMSProp | epoch: 022 | loss: 0.06481 - acc: 0.9808 -- iter: 0192/1707
[A[ATraining Step: 1141  | total loss: [1m[32m0.06040[0m[0m | time: 6.115s
[2K
| RMSProp | epoch: 022 | loss: 0.06040 - acc: 0.9827 -- iter: 0224/1707
[A[ATraining Step: 1142  | total loss: [1m[32m0.05477[0m[0m | time: 6.861s
[2K
| RMSProp | epoch: 022 | loss: 0.05477 - acc: 0.9845 -- iter: 0256/1707
[A[ATraining Step: 1143  | total loss: [1m[32m0.04998[0m[0m | time: 7.606s
[2K
| RMSProp | epoch: 022 | loss: 0.04998 - acc: 0.9860 -- iter: 0288/1707
[A[ATraining Step: 1144  | total loss: [1m[32m0.04527[0m[0m | time: 8.341s
[2K
| RMSProp | epoch: 022 | loss: 0.04527 - acc: 0.9874 -- iter: 0320/1707
[A[ATraining Step: 1145  | total loss: [1m[32m0.04116[0m[0m | time: 9.127s
[2K
| RMSProp | epoch: 022 | loss: 0.04116 - acc: 0.9887 -- iter: 0352/1707
[A[ATraining Step: 1146  | total loss: [1m[32m0.03883[0m[0m | time: 9.865s
[2K
| RMSProp | epoch: 022 | loss: 0.03883 - acc: 0.9898 -- iter: 0384/1707
[A[ATraining Step: 1147  | total loss: [1m[32m0.03834[0m[0m | time: 10.607s
[2K
| RMSProp | epoch: 022 | loss: 0.03834 - acc: 0.9877 -- iter: 0416/1707
[A[ATraining Step: 1148  | total loss: [1m[32m0.03498[0m[0m | time: 11.351s
[2K
| RMSProp | epoch: 022 | loss: 0.03498 - acc: 0.9889 -- iter: 0448/1707
[A[ATraining Step: 1149  | total loss: [1m[32m0.03592[0m[0m | time: 12.150s
[2K
| RMSProp | epoch: 022 | loss: 0.03592 - acc: 0.9869 -- iter: 0480/1707
[A[ATraining Step: 1150  | total loss: [1m[32m0.07097[0m[0m | time: 12.874s
[2K
| RMSProp | epoch: 022 | loss: 0.07097 - acc: 0.9726 -- iter: 0512/1707
[A[ATraining Step: 1151  | total loss: [1m[32m0.08301[0m[0m | time: 13.650s
[2K
| RMSProp | epoch: 022 | loss: 0.08301 - acc: 0.9660 -- iter: 0544/1707
[A[ATraining Step: 1152  | total loss: [1m[32m0.08545[0m[0m | time: 14.420s
[2K
| RMSProp | epoch: 022 | loss: 0.08545 - acc: 0.9631 -- iter: 0576/1707
[A[ATraining Step: 1153  | total loss: [1m[32m0.08961[0m[0m | time: 15.155s
[2K
| RMSProp | epoch: 022 | loss: 0.08961 - acc: 0.9606 -- iter: 0608/1707
[A[ATraining Step: 1154  | total loss: [1m[32m0.08129[0m[0m | time: 15.434s
[2K
| RMSProp | epoch: 022 | loss: 0.08129 - acc: 0.9645 -- iter: 0640/1707
[A[ATraining Step: 1155  | total loss: [1m[32m0.07350[0m[0m | time: 15.755s
[2K
| RMSProp | epoch: 022 | loss: 0.07350 - acc: 0.9681 -- iter: 0672/1707
[A[ATraining Step: 1156  | total loss: [1m[32m0.06641[0m[0m | time: 16.550s
[2K
| RMSProp | epoch: 022 | loss: 0.06641 - acc: 0.9712 -- iter: 0704/1707
[A[ATraining Step: 1157  | total loss: [1m[32m0.06054[0m[0m | time: 17.282s
[2K
| RMSProp | epoch: 022 | loss: 0.06054 - acc: 0.9741 -- iter: 0736/1707
[A[ATraining Step: 1158  | total loss: [1m[32m0.05696[0m[0m | time: 18.039s
[2K
| RMSProp | epoch: 022 | loss: 0.05696 - acc: 0.9736 -- iter: 0768/1707
[A[ATraining Step: 1159  | total loss: [1m[32m0.06884[0m[0m | time: 18.837s
[2K
| RMSProp | epoch: 022 | loss: 0.06884 - acc: 0.9700 -- iter: 0800/1707
[A[ATraining Step: 1160  | total loss: [1m[32m0.08009[0m[0m | time: 19.562s
[2K
| RMSProp | epoch: 022 | loss: 0.08009 - acc: 0.9699 -- iter: 0832/1707
[A[ATraining Step: 1161  | total loss: [1m[32m0.11180[0m[0m | time: 20.278s
[2K
| RMSProp | epoch: 022 | loss: 0.11180 - acc: 0.9635 -- iter: 0864/1707
[A[ATraining Step: 1162  | total loss: [1m[32m0.10906[0m[0m | time: 21.033s
[2K
| RMSProp | epoch: 022 | loss: 0.10906 - acc: 0.9640 -- iter: 0896/1707
[A[ATraining Step: 1163  | total loss: [1m[32m0.10431[0m[0m | time: 21.763s
[2K
| RMSProp | epoch: 022 | loss: 0.10431 - acc: 0.9645 -- iter: 0928/1707
[A[ATraining Step: 1164  | total loss: [1m[32m0.10388[0m[0m | time: 22.505s
[2K
| RMSProp | epoch: 022 | loss: 0.10388 - acc: 0.9649 -- iter: 0960/1707
[A[ATraining Step: 1165  | total loss: [1m[32m0.10582[0m[0m | time: 23.239s
[2K
| RMSProp | epoch: 022 | loss: 0.10582 - acc: 0.9653 -- iter: 0992/1707
[A[ATraining Step: 1166  | total loss: [1m[32m0.10226[0m[0m | time: 23.977s
[2K
| RMSProp | epoch: 022 | loss: 0.10226 - acc: 0.9688 -- iter: 1024/1707
[A[ATraining Step: 1167  | total loss: [1m[32m0.10522[0m[0m | time: 24.757s
[2K
| RMSProp | epoch: 022 | loss: 0.10522 - acc: 0.9688 -- iter: 1056/1707
[A[ATraining Step: 1168  | total loss: [1m[32m0.10325[0m[0m | time: 25.479s
[2K
| RMSProp | epoch: 022 | loss: 0.10325 - acc: 0.9688 -- iter: 1088/1707
[A[ATraining Step: 1169  | total loss: [1m[32m0.10200[0m[0m | time: 26.211s
[2K
| RMSProp | epoch: 022 | loss: 0.10200 - acc: 0.9688 -- iter: 1120/1707
[A[ATraining Step: 1170  | total loss: [1m[32m0.10517[0m[0m | time: 26.999s
[2K
| RMSProp | epoch: 022 | loss: 0.10517 - acc: 0.9688 -- iter: 1152/1707
[A[ATraining Step: 1171  | total loss: [1m[32m0.09966[0m[0m | time: 27.714s
[2K
| RMSProp | epoch: 022 | loss: 0.09966 - acc: 0.9719 -- iter: 1184/1707
[A[ATraining Step: 1172  | total loss: [1m[32m0.10793[0m[0m | time: 28.455s
[2K
| RMSProp | epoch: 022 | loss: 0.10793 - acc: 0.9716 -- iter: 1216/1707
[A[ATraining Step: 1173  | total loss: [1m[32m0.10526[0m[0m | time: 29.181s
[2K
| RMSProp | epoch: 022 | loss: 0.10526 - acc: 0.9713 -- iter: 1248/1707
[A[ATraining Step: 1174  | total loss: [1m[32m0.09871[0m[0m | time: 29.918s
[2K
| RMSProp | epoch: 022 | loss: 0.09871 - acc: 0.9742 -- iter: 1280/1707
[A[ATraining Step: 1175  | total loss: [1m[32m0.10192[0m[0m | time: 30.642s
[2K
| RMSProp | epoch: 022 | loss: 0.10192 - acc: 0.9705 -- iter: 1312/1707
[A[ATraining Step: 1176  | total loss: [1m[32m0.10050[0m[0m | time: 31.362s
[2K
| RMSProp | epoch: 022 | loss: 0.10050 - acc: 0.9703 -- iter: 1344/1707
[A[ATraining Step: 1177  | total loss: [1m[32m0.10776[0m[0m | time: 32.107s
[2K
| RMSProp | epoch: 022 | loss: 0.10776 - acc: 0.9702 -- iter: 1376/1707
[A[ATraining Step: 1178  | total loss: [1m[32m0.13097[0m[0m | time: 32.847s
[2K
| RMSProp | epoch: 022 | loss: 0.13097 - acc: 0.9669 -- iter: 1408/1707
[A[ATraining Step: 1179  | total loss: [1m[32m0.12440[0m[0m | time: 33.662s
[2K
| RMSProp | epoch: 022 | loss: 0.12440 - acc: 0.9671 -- iter: 1440/1707
[A[ATraining Step: 1180  | total loss: [1m[32m0.11493[0m[0m | time: 34.384s
[2K
| RMSProp | epoch: 022 | loss: 0.11493 - acc: 0.9704 -- iter: 1472/1707
[A[ATraining Step: 1181  | total loss: [1m[32m0.10718[0m[0m | time: 35.128s
[2K
| RMSProp | epoch: 022 | loss: 0.10718 - acc: 0.9733 -- iter: 1504/1707
[A[ATraining Step: 1182  | total loss: [1m[32m0.09806[0m[0m | time: 35.863s
[2K
| RMSProp | epoch: 022 | loss: 0.09806 - acc: 0.9760 -- iter: 1536/1707
[A[ATraining Step: 1183  | total loss: [1m[32m0.08858[0m[0m | time: 36.589s
[2K
| RMSProp | epoch: 022 | loss: 0.08858 - acc: 0.9784 -- iter: 1568/1707
[A[ATraining Step: 1184  | total loss: [1m[32m0.08014[0m[0m | time: 37.294s
[2K
| RMSProp | epoch: 022 | loss: 0.08014 - acc: 0.9806 -- iter: 1600/1707
[A[ATraining Step: 1185  | total loss: [1m[32m0.08326[0m[0m | time: 38.072s
[2K
| RMSProp | epoch: 022 | loss: 0.08326 - acc: 0.9794 -- iter: 1632/1707
[A[ATraining Step: 1186  | total loss: [1m[32m0.07564[0m[0m | time: 38.827s
[2K
| RMSProp | epoch: 022 | loss: 0.07564 - acc: 0.9814 -- iter: 1664/1707
[A[ATraining Step: 1187  | total loss: [1m[32m0.06842[0m[0m | time: 39.636s
[2K
| RMSProp | epoch: 022 | loss: 0.06842 - acc: 0.9833 -- iter: 1696/1707
[A[ATraining Step: 1188  | total loss: [1m[32m0.06203[0m[0m | time: 42.462s
[2K
| RMSProp | epoch: 022 | loss: 0.06203 - acc: 0.9850 | val_loss: 0.96066 - val_acc: 0.7566 -- iter: 1707/1707
--
Training Step: 1189  | total loss: [1m[32m0.06139[0m[0m | time: 0.770s
[2K
| RMSProp | epoch: 023 | loss: 0.06139 - acc: 0.9833 -- iter: 0032/1707
[A[ATraining Step: 1190  | total loss: [1m[32m0.06650[0m[0m | time: 1.495s
[2K
| RMSProp | epoch: 023 | loss: 0.06650 - acc: 0.9788 -- iter: 0064/1707
[A[ATraining Step: 1191  | total loss: [1m[32m0.08094[0m[0m | time: 2.279s
[2K
| RMSProp | epoch: 023 | loss: 0.08094 - acc: 0.9715 -- iter: 0096/1707
[A[ATraining Step: 1192  | total loss: [1m[32m0.07885[0m[0m | time: 3.039s
[2K
| RMSProp | epoch: 023 | loss: 0.07885 - acc: 0.9712 -- iter: 0128/1707
[A[ATraining Step: 1193  | total loss: [1m[32m0.07176[0m[0m | time: 3.839s
[2K
| RMSProp | epoch: 023 | loss: 0.07176 - acc: 0.9741 -- iter: 0160/1707
[A[ATraining Step: 1194  | total loss: [1m[32m0.06555[0m[0m | time: 4.573s
[2K
| RMSProp | epoch: 023 | loss: 0.06555 - acc: 0.9767 -- iter: 0192/1707
[A[ATraining Step: 1195  | total loss: [1m[32m0.05952[0m[0m | time: 5.317s
[2K
| RMSProp | epoch: 023 | loss: 0.05952 - acc: 0.9790 -- iter: 0224/1707
[A[ATraining Step: 1196  | total loss: [1m[32m0.06407[0m[0m | time: 6.066s
[2K
| RMSProp | epoch: 023 | loss: 0.06407 - acc: 0.9780 -- iter: 0256/1707
[A[ATraining Step: 1197  | total loss: [1m[32m0.06040[0m[0m | time: 6.795s
[2K
| RMSProp | epoch: 023 | loss: 0.06040 - acc: 0.9771 -- iter: 0288/1707
[A[ATraining Step: 1198  | total loss: [1m[32m0.05697[0m[0m | time: 7.566s
[2K
| RMSProp | epoch: 023 | loss: 0.05697 - acc: 0.9794 -- iter: 0320/1707
[A[ATraining Step: 1199  | total loss: [1m[32m0.05146[0m[0m | time: 8.400s
[2K
| RMSProp | epoch: 023 | loss: 0.05146 - acc: 0.9814 -- iter: 0352/1707
[A[ATraining Step: 1200  | total loss: [1m[32m0.04673[0m[0m | time: 11.287s
[2K
| RMSProp | epoch: 023 | loss: 0.04673 - acc: 0.9833 | val_loss: 0.88446 - val_acc: 0.7865 -- iter: 0384/1707
--
Training Step: 1201  | total loss: [1m[32m0.04224[0m[0m | time: 12.064s
[2K
| RMSProp | epoch: 023 | loss: 0.04224 - acc: 0.9850 -- iter: 0416/1707
[A[ATraining Step: 1202  | total loss: [1m[32m0.04422[0m[0m | time: 12.794s
[2K
| RMSProp | epoch: 023 | loss: 0.04422 - acc: 0.9833 -- iter: 0448/1707
[A[ATraining Step: 1203  | total loss: [1m[32m0.06984[0m[0m | time: 13.578s
[2K
| RMSProp | epoch: 023 | loss: 0.06984 - acc: 0.9788 -- iter: 0480/1707
[A[ATraining Step: 1204  | total loss: [1m[32m0.10242[0m[0m | time: 14.300s
[2K
| RMSProp | epoch: 023 | loss: 0.10242 - acc: 0.9715 -- iter: 0512/1707
[A[ATraining Step: 1205  | total loss: [1m[32m0.09878[0m[0m | time: 15.055s
[2K
| RMSProp | epoch: 023 | loss: 0.09878 - acc: 0.9744 -- iter: 0544/1707
[A[ATraining Step: 1206  | total loss: [1m[32m0.08961[0m[0m | time: 15.790s
[2K
| RMSProp | epoch: 023 | loss: 0.08961 - acc: 0.9769 -- iter: 0576/1707
[A[ATraining Step: 1207  | total loss: [1m[32m0.08351[0m[0m | time: 16.527s
[2K
| RMSProp | epoch: 023 | loss: 0.08351 - acc: 0.9792 -- iter: 0608/1707
[A[ATraining Step: 1208  | total loss: [1m[32m0.08916[0m[0m | time: 17.252s
[2K
| RMSProp | epoch: 023 | loss: 0.08916 - acc: 0.9751 -- iter: 0640/1707
[A[ATraining Step: 1209  | total loss: [1m[32m0.16968[0m[0m | time: 17.509s
[2K
| RMSProp | epoch: 023 | loss: 0.16968 - acc: 0.9463 -- iter: 0672/1707
[A[ATraining Step: 1210  | total loss: [1m[32m0.17569[0m[0m | time: 17.819s
[2K
| RMSProp | epoch: 023 | loss: 0.17569 - acc: 0.9426 -- iter: 0704/1707
[A[ATraining Step: 1211  | total loss: [1m[32m0.16147[0m[0m | time: 18.648s
[2K
| RMSProp | epoch: 023 | loss: 0.16147 - acc: 0.9483 -- iter: 0736/1707
[A[ATraining Step: 1212  | total loss: [1m[32m0.15641[0m[0m | time: 19.425s
[2K
| RMSProp | epoch: 023 | loss: 0.15641 - acc: 0.9472 -- iter: 0768/1707
[A[ATraining Step: 1213  | total loss: [1m[32m0.17581[0m[0m | time: 20.154s
[2K
| RMSProp | epoch: 023 | loss: 0.17581 - acc: 0.9369 -- iter: 0800/1707
[A[ATraining Step: 1214  | total loss: [1m[32m0.18321[0m[0m | time: 20.930s
[2K
| RMSProp | epoch: 023 | loss: 0.18321 - acc: 0.9401 -- iter: 0832/1707
[A[ATraining Step: 1215  | total loss: [1m[32m0.16971[0m[0m | time: 21.679s
[2K
| RMSProp | epoch: 023 | loss: 0.16971 - acc: 0.9461 -- iter: 0864/1707
[A[ATraining Step: 1216  | total loss: [1m[32m0.15754[0m[0m | time: 22.526s
[2K
| RMSProp | epoch: 023 | loss: 0.15754 - acc: 0.9483 -- iter: 0896/1707
[A[ATraining Step: 1217  | total loss: [1m[32m0.14643[0m[0m | time: 23.603s
[2K
| RMSProp | epoch: 023 | loss: 0.14643 - acc: 0.9504 -- iter: 0928/1707
[A[ATraining Step: 1218  | total loss: [1m[32m0.13197[0m[0m | time: 24.700s
[2K
| RMSProp | epoch: 023 | loss: 0.13197 - acc: 0.9553 -- iter: 0960/1707
[A[ATraining Step: 1219  | total loss: [1m[32m0.11894[0m[0m | time: 25.585s
[2K
| RMSProp | epoch: 023 | loss: 0.11894 - acc: 0.9598 -- iter: 0992/1707
[A[ATraining Step: 1220  | total loss: [1m[32m0.10781[0m[0m | time: 26.335s
[2K
| RMSProp | epoch: 023 | loss: 0.10781 - acc: 0.9638 -- iter: 1024/1707
[A[ATraining Step: 1221  | total loss: [1m[32m0.09768[0m[0m | time: 27.057s
[2K
| RMSProp | epoch: 023 | loss: 0.09768 - acc: 0.9674 -- iter: 1056/1707
[A[ATraining Step: 1222  | total loss: [1m[32m0.10062[0m[0m | time: 27.804s
[2K
| RMSProp | epoch: 023 | loss: 0.10062 - acc: 0.9676 -- iter: 1088/1707
[A[ATraining Step: 1223  | total loss: [1m[32m0.09116[0m[0m | time: 28.538s
[2K
| RMSProp | epoch: 023 | loss: 0.09116 - acc: 0.9708 -- iter: 1120/1707
[A[ATraining Step: 1224  | total loss: [1m[32m0.08617[0m[0m | time: 29.260s
[2K
| RMSProp | epoch: 023 | loss: 0.08617 - acc: 0.9706 -- iter: 1152/1707
[A[ATraining Step: 1225  | total loss: [1m[32m0.08866[0m[0m | time: 30.008s
[2K
| RMSProp | epoch: 023 | loss: 0.08866 - acc: 0.9704 -- iter: 1184/1707
[A[ATraining Step: 1226  | total loss: [1m[32m0.08055[0m[0m | time: 30.855s
[2K
| RMSProp | epoch: 023 | loss: 0.08055 - acc: 0.9734 -- iter: 1216/1707
[A[ATraining Step: 1227  | total loss: [1m[32m0.08513[0m[0m | time: 31.578s
[2K
| RMSProp | epoch: 023 | loss: 0.08513 - acc: 0.9698 -- iter: 1248/1707
[A[ATraining Step: 1228  | total loss: [1m[32m0.08067[0m[0m | time: 32.295s
[2K
| RMSProp | epoch: 023 | loss: 0.08067 - acc: 0.9728 -- iter: 1280/1707
[A[ATraining Step: 1229  | total loss: [1m[32m0.07943[0m[0m | time: 33.032s
[2K
| RMSProp | epoch: 023 | loss: 0.07943 - acc: 0.9724 -- iter: 1312/1707
[A[ATraining Step: 1230  | total loss: [1m[32m0.11687[0m[0m | time: 33.732s
[2K
| RMSProp | epoch: 023 | loss: 0.11687 - acc: 0.9627 -- iter: 1344/1707
[A[ATraining Step: 1231  | total loss: [1m[32m0.11543[0m[0m | time: 34.519s
[2K
| RMSProp | epoch: 023 | loss: 0.11543 - acc: 0.9601 -- iter: 1376/1707
[A[ATraining Step: 1232  | total loss: [1m[32m0.12398[0m[0m | time: 35.256s
[2K
| RMSProp | epoch: 023 | loss: 0.12398 - acc: 0.9579 -- iter: 1408/1707
[A[ATraining Step: 1233  | total loss: [1m[32m0.13493[0m[0m | time: 36.026s
[2K
| RMSProp | epoch: 023 | loss: 0.13493 - acc: 0.9558 -- iter: 1440/1707
[A[ATraining Step: 1234  | total loss: [1m[32m0.12737[0m[0m | time: 36.766s
[2K
| RMSProp | epoch: 023 | loss: 0.12737 - acc: 0.9571 -- iter: 1472/1707
[A[ATraining Step: 1235  | total loss: [1m[32m0.11910[0m[0m | time: 37.514s
[2K
| RMSProp | epoch: 023 | loss: 0.11910 - acc: 0.9614 -- iter: 1504/1707
[A[ATraining Step: 1236  | total loss: [1m[32m0.10909[0m[0m | time: 38.264s
[2K
| RMSProp | epoch: 023 | loss: 0.10909 - acc: 0.9653 -- iter: 1536/1707
[A[ATraining Step: 1237  | total loss: [1m[32m0.11332[0m[0m | time: 39.011s
[2K
| RMSProp | epoch: 023 | loss: 0.11332 - acc: 0.9656 -- iter: 1568/1707
[A[ATraining Step: 1238  | total loss: [1m[32m0.10364[0m[0m | time: 39.749s
[2K
| RMSProp | epoch: 023 | loss: 0.10364 - acc: 0.9691 -- iter: 1600/1707
[A[ATraining Step: 1239  | total loss: [1m[32m0.09407[0m[0m | time: 40.481s
[2K
| RMSProp | epoch: 023 | loss: 0.09407 - acc: 0.9722 -- iter: 1632/1707
[A[ATraining Step: 1240  | total loss: [1m[32m0.08552[0m[0m | time: 41.222s
[2K
| RMSProp | epoch: 023 | loss: 0.08552 - acc: 0.9749 -- iter: 1664/1707
[A[ATraining Step: 1241  | total loss: [1m[32m0.08015[0m[0m | time: 41.952s
[2K
| RMSProp | epoch: 023 | loss: 0.08015 - acc: 0.9743 -- iter: 1696/1707
[A[ATraining Step: 1242  | total loss: [1m[32m0.08256[0m[0m | time: 44.874s
[2K
| RMSProp | epoch: 023 | loss: 0.08256 - acc: 0.9706 | val_loss: 0.73793 - val_acc: 0.8052 -- iter: 1707/1707
--
Training Step: 1243  | total loss: [1m[32m0.07578[0m[0m | time: 0.792s
[2K
| RMSProp | epoch: 024 | loss: 0.07578 - acc: 0.9736 -- iter: 0032/1707
[A[ATraining Step: 1244  | total loss: [1m[32m0.06872[0m[0m | time: 1.568s
[2K
| RMSProp | epoch: 024 | loss: 0.06872 - acc: 0.9762 -- iter: 0064/1707
[A[ATraining Step: 1245  | total loss: [1m[32m0.06263[0m[0m | time: 2.313s
[2K
| RMSProp | epoch: 024 | loss: 0.06263 - acc: 0.9786 -- iter: 0096/1707
[A[ATraining Step: 1246  | total loss: [1m[32m0.07114[0m[0m | time: 3.029s
[2K
| RMSProp | epoch: 024 | loss: 0.07114 - acc: 0.9776 -- iter: 0128/1707
[A[ATraining Step: 1247  | total loss: [1m[32m0.07490[0m[0m | time: 3.829s
[2K
| RMSProp | epoch: 024 | loss: 0.07490 - acc: 0.9767 -- iter: 0160/1707
[A[ATraining Step: 1248  | total loss: [1m[32m0.07256[0m[0m | time: 4.579s
[2K
| RMSProp | epoch: 024 | loss: 0.07256 - acc: 0.9791 -- iter: 0192/1707
[A[ATraining Step: 1249  | total loss: [1m[32m0.07640[0m[0m | time: 5.310s
[2K
| RMSProp | epoch: 024 | loss: 0.07640 - acc: 0.9780 -- iter: 0224/1707
[A[ATraining Step: 1250  | total loss: [1m[32m0.08428[0m[0m | time: 6.047s
[2K
| RMSProp | epoch: 024 | loss: 0.08428 - acc: 0.9740 -- iter: 0256/1707
[A[ATraining Step: 1251  | total loss: [1m[32m0.07906[0m[0m | time: 6.828s
[2K
| RMSProp | epoch: 024 | loss: 0.07906 - acc: 0.9766 -- iter: 0288/1707
[A[ATraining Step: 1252  | total loss: [1m[32m0.07337[0m[0m | time: 7.554s
[2K
| RMSProp | epoch: 024 | loss: 0.07337 - acc: 0.9789 -- iter: 0320/1707
[A[ATraining Step: 1253  | total loss: [1m[32m0.07856[0m[0m | time: 8.308s
[2K
| RMSProp | epoch: 024 | loss: 0.07856 - acc: 0.9779 -- iter: 0352/1707
[A[ATraining Step: 1254  | total loss: [1m[32m0.07141[0m[0m | time: 9.029s
[2K
| RMSProp | epoch: 024 | loss: 0.07141 - acc: 0.9801 -- iter: 0384/1707
[A[ATraining Step: 1255  | total loss: [1m[32m0.06662[0m[0m | time: 9.786s
[2K
| RMSProp | epoch: 024 | loss: 0.06662 - acc: 0.9821 -- iter: 0416/1707
[A[ATraining Step: 1256  | total loss: [1m[32m0.07927[0m[0m | time: 10.604s
[2K
| RMSProp | epoch: 024 | loss: 0.07927 - acc: 0.9808 -- iter: 0448/1707
[A[ATraining Step: 1257  | total loss: [1m[32m0.07455[0m[0m | time: 11.688s
[2K
| RMSProp | epoch: 024 | loss: 0.07455 - acc: 0.9827 -- iter: 0480/1707
[A[ATraining Step: 1258  | total loss: [1m[32m0.06918[0m[0m | time: 12.730s
[2K
| RMSProp | epoch: 024 | loss: 0.06918 - acc: 0.9844 -- iter: 0512/1707
[A[ATraining Step: 1259  | total loss: [1m[32m0.06284[0m[0m | time: 13.703s
[2K
| RMSProp | epoch: 024 | loss: 0.06284 - acc: 0.9860 -- iter: 0544/1707
[A[ATraining Step: 1260  | total loss: [1m[32m0.08395[0m[0m | time: 14.470s
[2K
| RMSProp | epoch: 024 | loss: 0.08395 - acc: 0.9780 -- iter: 0576/1707
[A[ATraining Step: 1261  | total loss: [1m[32m0.10678[0m[0m | time: 15.200s
[2K
| RMSProp | epoch: 024 | loss: 0.10678 - acc: 0.9708 -- iter: 0608/1707
[A[ATraining Step: 1262  | total loss: [1m[32m0.09797[0m[0m | time: 15.956s
[2K
| RMSProp | epoch: 024 | loss: 0.09797 - acc: 0.9737 -- iter: 0640/1707
[A[ATraining Step: 1263  | total loss: [1m[32m0.10392[0m[0m | time: 16.690s
[2K
| RMSProp | epoch: 024 | loss: 0.10392 - acc: 0.9732 -- iter: 0672/1707
[A[ATraining Step: 1264  | total loss: [1m[32m0.11255[0m[0m | time: 16.949s
[2K
| RMSProp | epoch: 024 | loss: 0.11255 - acc: 0.9697 -- iter: 0704/1707
[A[ATraining Step: 1265  | total loss: [1m[32m0.10321[0m[0m | time: 17.310s
[2K
| RMSProp | epoch: 024 | loss: 0.10321 - acc: 0.9727 -- iter: 0736/1707
[A[ATraining Step: 1266  | total loss: [1m[32m0.09328[0m[0m | time: 18.057s
[2K
| RMSProp | epoch: 024 | loss: 0.09328 - acc: 0.9754 -- iter: 0768/1707
[A[ATraining Step: 1267  | total loss: [1m[32m0.09072[0m[0m | time: 18.835s
[2K
| RMSProp | epoch: 024 | loss: 0.09072 - acc: 0.9748 -- iter: 0800/1707
[A[ATraining Step: 1268  | total loss: [1m[32m0.08434[0m[0m | time: 19.598s
[2K
| RMSProp | epoch: 024 | loss: 0.08434 - acc: 0.9773 -- iter: 0832/1707
[A[ATraining Step: 1269  | total loss: [1m[32m0.07683[0m[0m | time: 20.336s
[2K
| RMSProp | epoch: 024 | loss: 0.07683 - acc: 0.9796 -- iter: 0864/1707
[A[ATraining Step: 1270  | total loss: [1m[32m0.07004[0m[0m | time: 21.076s
[2K
| RMSProp | epoch: 024 | loss: 0.07004 - acc: 0.9816 -- iter: 0896/1707
[A[ATraining Step: 1271  | total loss: [1m[32m0.06362[0m[0m | time: 21.815s
[2K
| RMSProp | epoch: 024 | loss: 0.06362 - acc: 0.9834 -- iter: 0928/1707
[A[ATraining Step: 1272  | total loss: [1m[32m0.05755[0m[0m | time: 22.592s
[2K
| RMSProp | epoch: 024 | loss: 0.05755 - acc: 0.9851 -- iter: 0960/1707
[A[ATraining Step: 1273  | total loss: [1m[32m0.05226[0m[0m | time: 23.339s
[2K
| RMSProp | epoch: 024 | loss: 0.05226 - acc: 0.9866 -- iter: 0992/1707
[A[ATraining Step: 1274  | total loss: [1m[32m0.04722[0m[0m | time: 24.084s
[2K
| RMSProp | epoch: 024 | loss: 0.04722 - acc: 0.9879 -- iter: 1024/1707
[A[ATraining Step: 1275  | total loss: [1m[32m0.05619[0m[0m | time: 24.829s
[2K
| RMSProp | epoch: 024 | loss: 0.05619 - acc: 0.9829 -- iter: 1056/1707
[A[ATraining Step: 1276  | total loss: [1m[32m0.06752[0m[0m | time: 25.579s
[2K
| RMSProp | epoch: 024 | loss: 0.06752 - acc: 0.9815 -- iter: 1088/1707
[A[ATraining Step: 1277  | total loss: [1m[32m0.06360[0m[0m | time: 26.307s
[2K
| RMSProp | epoch: 024 | loss: 0.06360 - acc: 0.9833 -- iter: 1120/1707
[A[ATraining Step: 1278  | total loss: [1m[32m0.05799[0m[0m | time: 27.050s
[2K
| RMSProp | epoch: 024 | loss: 0.05799 - acc: 0.9850 -- iter: 1152/1707
[A[ATraining Step: 1279  | total loss: [1m[32m0.06442[0m[0m | time: 27.789s
[2K
| RMSProp | epoch: 024 | loss: 0.06442 - acc: 0.9834 -- iter: 1184/1707
[A[ATraining Step: 1280  | total loss: [1m[32m0.06010[0m[0m | time: 28.534s
[2K
| RMSProp | epoch: 024 | loss: 0.06010 - acc: 0.9850 -- iter: 1216/1707
[A[ATraining Step: 1281  | total loss: [1m[32m0.06875[0m[0m | time: 29.269s
[2K
| RMSProp | epoch: 024 | loss: 0.06875 - acc: 0.9834 -- iter: 1248/1707
[A[ATraining Step: 1282  | total loss: [1m[32m0.07154[0m[0m | time: 30.023s
[2K
| RMSProp | epoch: 024 | loss: 0.07154 - acc: 0.9788 -- iter: 1280/1707
[A[ATraining Step: 1283  | total loss: [1m[32m0.09198[0m[0m | time: 30.820s
[2K
| RMSProp | epoch: 024 | loss: 0.09198 - acc: 0.9653 -- iter: 1312/1707
[A[ATraining Step: 1284  | total loss: [1m[32m0.11390[0m[0m | time: 31.539s
[2K
| RMSProp | epoch: 024 | loss: 0.11390 - acc: 0.9532 -- iter: 1344/1707
[A[ATraining Step: 1285  | total loss: [1m[32m0.10497[0m[0m | time: 32.267s
[2K
| RMSProp | epoch: 024 | loss: 0.10497 - acc: 0.9578 -- iter: 1376/1707
[A[ATraining Step: 1286  | total loss: [1m[32m0.09866[0m[0m | time: 33.008s
[2K
| RMSProp | epoch: 024 | loss: 0.09866 - acc: 0.9589 -- iter: 1408/1707
[A[ATraining Step: 1287  | total loss: [1m[32m0.09732[0m[0m | time: 33.710s
[2K
| RMSProp | epoch: 024 | loss: 0.09732 - acc: 0.9599 -- iter: 1440/1707
[A[ATraining Step: 1288  | total loss: [1m[32m0.10214[0m[0m | time: 34.483s
[2K
| RMSProp | epoch: 024 | loss: 0.10214 - acc: 0.9608 -- iter: 1472/1707
[A[ATraining Step: 1289  | total loss: [1m[32m0.09492[0m[0m | time: 35.252s
[2K
| RMSProp | epoch: 024 | loss: 0.09492 - acc: 0.9647 -- iter: 1504/1707
[A[ATraining Step: 1290  | total loss: [1m[32m0.08797[0m[0m | time: 35.955s
[2K
| RMSProp | epoch: 024 | loss: 0.08797 - acc: 0.9682 -- iter: 1536/1707
[A[ATraining Step: 1291  | total loss: [1m[32m0.07992[0m[0m | time: 36.696s
[2K
| RMSProp | epoch: 024 | loss: 0.07992 - acc: 0.9714 -- iter: 1568/1707
[A[ATraining Step: 1292  | total loss: [1m[32m0.09654[0m[0m | time: 37.485s
[2K
| RMSProp | epoch: 024 | loss: 0.09654 - acc: 0.9712 -- iter: 1600/1707
[A[ATraining Step: 1293  | total loss: [1m[32m0.08931[0m[0m | time: 38.214s
[2K
| RMSProp | epoch: 024 | loss: 0.08931 - acc: 0.9740 -- iter: 1632/1707
[A[ATraining Step: 1294  | total loss: [1m[32m0.08127[0m[0m | time: 38.949s
[2K
| RMSProp | epoch: 024 | loss: 0.08127 - acc: 0.9766 -- iter: 1664/1707
[A[ATraining Step: 1295  | total loss: [1m[32m0.07349[0m[0m | time: 39.684s
[2K
| RMSProp | epoch: 024 | loss: 0.07349 - acc: 0.9790 -- iter: 1696/1707
[A[ATraining Step: 1296  | total loss: [1m[32m0.07660[0m[0m | time: 42.464s
[2K
| RMSProp | epoch: 024 | loss: 0.07660 - acc: 0.9779 | val_loss: 0.74798 - val_acc: 0.7865 -- iter: 1707/1707
--
Training Step: 1297  | total loss: [1m[32m0.07205[0m[0m | time: 0.768s
[2K
| RMSProp | epoch: 025 | loss: 0.07205 - acc: 0.9802 -- iter: 0032/1707
[A[ATraining Step: 1298  | total loss: [1m[32m0.06700[0m[0m | time: 1.518s
[2K
| RMSProp | epoch: 025 | loss: 0.06700 - acc: 0.9821 -- iter: 0064/1707
[A[ATraining Step: 1299  | total loss: [1m[32m0.07756[0m[0m | time: 2.440s
[2K
| RMSProp | epoch: 025 | loss: 0.07756 - acc: 0.9808 -- iter: 0096/1707
[A[ATraining Step: 1300  | total loss: [1m[32m0.07248[0m[0m | time: 3.517s
[2K
| RMSProp | epoch: 025 | loss: 0.07248 - acc: 0.9827 -- iter: 0128/1707
[A[ATraining Step: 1301  | total loss: [1m[32m0.06637[0m[0m | time: 4.592s
[2K
| RMSProp | epoch: 025 | loss: 0.06637 - acc: 0.9844 -- iter: 0160/1707
[A[ATraining Step: 1302  | total loss: [1m[32m0.06035[0m[0m | time: 5.367s
[2K
| RMSProp | epoch: 025 | loss: 0.06035 - acc: 0.9860 -- iter: 0192/1707
[A[ATraining Step: 1303  | total loss: [1m[32m0.05461[0m[0m | time: 6.140s
[2K
| RMSProp | epoch: 025 | loss: 0.05461 - acc: 0.9874 -- iter: 0224/1707
[A[ATraining Step: 1304  | total loss: [1m[32m0.05932[0m[0m | time: 6.890s
[2K
| RMSProp | epoch: 025 | loss: 0.05932 - acc: 0.9855 -- iter: 0256/1707
[A[ATraining Step: 1305  | total loss: [1m[32m0.05450[0m[0m | time: 7.640s
[2K
| RMSProp | epoch: 025 | loss: 0.05450 - acc: 0.9870 -- iter: 0288/1707
[A[ATraining Step: 1306  | total loss: [1m[32m0.04948[0m[0m | time: 8.403s
[2K
| RMSProp | epoch: 025 | loss: 0.04948 - acc: 0.9883 -- iter: 0320/1707
[A[ATraining Step: 1307  | total loss: [1m[32m0.04782[0m[0m | time: 9.205s
[2K
| RMSProp | epoch: 025 | loss: 0.04782 - acc: 0.9863 -- iter: 0352/1707
[A[ATraining Step: 1308  | total loss: [1m[32m0.10197[0m[0m | time: 9.948s
[2K
| RMSProp | epoch: 025 | loss: 0.10197 - acc: 0.9721 -- iter: 0384/1707
[A[ATraining Step: 1309  | total loss: [1m[32m0.12988[0m[0m | time: 10.703s
[2K
| RMSProp | epoch: 025 | loss: 0.12988 - acc: 0.9561 -- iter: 0416/1707
[A[ATraining Step: 1310  | total loss: [1m[32m0.12335[0m[0m | time: 11.450s
[2K
| RMSProp | epoch: 025 | loss: 0.12335 - acc: 0.9605 -- iter: 0448/1707
[A[ATraining Step: 1311  | total loss: [1m[32m0.11358[0m[0m | time: 12.200s
[2K
| RMSProp | epoch: 025 | loss: 0.11358 - acc: 0.9645 -- iter: 0480/1707
[A[ATraining Step: 1312  | total loss: [1m[32m0.10274[0m[0m | time: 12.950s
[2K
| RMSProp | epoch: 025 | loss: 0.10274 - acc: 0.9680 -- iter: 0512/1707
[A[ATraining Step: 1313  | total loss: [1m[32m0.09297[0m[0m | time: 13.675s
[2K
| RMSProp | epoch: 025 | loss: 0.09297 - acc: 0.9712 -- iter: 0544/1707
[A[ATraining Step: 1314  | total loss: [1m[32m0.08537[0m[0m | time: 14.380s
[2K
| RMSProp | epoch: 025 | loss: 0.08537 - acc: 0.9741 -- iter: 0576/1707
[A[ATraining Step: 1315  | total loss: [1m[32m0.07727[0m[0m | time: 15.147s
[2K
| RMSProp | epoch: 025 | loss: 0.07727 - acc: 0.9767 -- iter: 0608/1707
[A[ATraining Step: 1316  | total loss: [1m[32m0.08929[0m[0m | time: 15.908s
[2K
| RMSProp | epoch: 025 | loss: 0.08929 - acc: 0.9728 -- iter: 0640/1707
[A[ATraining Step: 1317  | total loss: [1m[32m0.10709[0m[0m | time: 16.625s
[2K
| RMSProp | epoch: 025 | loss: 0.10709 - acc: 0.9661 -- iter: 0672/1707
[A[ATraining Step: 1318  | total loss: [1m[32m0.10160[0m[0m | time: 17.370s
[2K
| RMSProp | epoch: 025 | loss: 0.10160 - acc: 0.9664 -- iter: 0704/1707
[A[ATraining Step: 1319  | total loss: [1m[32m0.09326[0m[0m | time: 17.660s
[2K
| RMSProp | epoch: 025 | loss: 0.09326 - acc: 0.9697 -- iter: 0736/1707
[A[ATraining Step: 1320  | total loss: [1m[32m0.08686[0m[0m | time: 17.998s
[2K
| RMSProp | epoch: 025 | loss: 0.08686 - acc: 0.9728 -- iter: 0768/1707
[A[ATraining Step: 1321  | total loss: [1m[32m0.07842[0m[0m | time: 18.742s
[2K
| RMSProp | epoch: 025 | loss: 0.07842 - acc: 0.9755 -- iter: 0800/1707
[A[ATraining Step: 1322  | total loss: [1m[32m0.07945[0m[0m | time: 19.482s
[2K
| RMSProp | epoch: 025 | loss: 0.07945 - acc: 0.9748 -- iter: 0832/1707
[A[ATraining Step: 1323  | total loss: [1m[32m0.07227[0m[0m | time: 20.240s
[2K
| RMSProp | epoch: 025 | loss: 0.07227 - acc: 0.9773 -- iter: 0864/1707
[A[ATraining Step: 1324  | total loss: [1m[32m0.07689[0m[0m | time: 21.001s
[2K
| RMSProp | epoch: 025 | loss: 0.07689 - acc: 0.9765 -- iter: 0896/1707
[A[ATraining Step: 1325  | total loss: [1m[32m0.07342[0m[0m | time: 21.732s
[2K
| RMSProp | epoch: 025 | loss: 0.07342 - acc: 0.9757 -- iter: 0928/1707
[A[ATraining Step: 1326  | total loss: [1m[32m0.07435[0m[0m | time: 22.478s
[2K
| RMSProp | epoch: 025 | loss: 0.07435 - acc: 0.9750 -- iter: 0960/1707
[A[ATraining Step: 1327  | total loss: [1m[32m0.09473[0m[0m | time: 23.241s
[2K
| RMSProp | epoch: 025 | loss: 0.09473 - acc: 0.9650 -- iter: 0992/1707
[A[ATraining Step: 1328  | total loss: [1m[32m0.09075[0m[0m | time: 23.960s
[2K
| RMSProp | epoch: 025 | loss: 0.09075 - acc: 0.9685 -- iter: 1024/1707
[A[ATraining Step: 1329  | total loss: [1m[32m0.08259[0m[0m | time: 24.698s
[2K
| RMSProp | epoch: 025 | loss: 0.08259 - acc: 0.9717 -- iter: 1056/1707
[A[ATraining Step: 1330  | total loss: [1m[32m0.07483[0m[0m | time: 25.445s
[2K
| RMSProp | epoch: 025 | loss: 0.07483 - acc: 0.9745 -- iter: 1088/1707
[A[ATraining Step: 1331  | total loss: [1m[32m0.08489[0m[0m | time: 26.182s
[2K
| RMSProp | epoch: 025 | loss: 0.08489 - acc: 0.9739 -- iter: 1120/1707
[A[ATraining Step: 1332  | total loss: [1m[32m0.07885[0m[0m | time: 26.951s
[2K
| RMSProp | epoch: 025 | loss: 0.07885 - acc: 0.9765 -- iter: 1152/1707
[A[ATraining Step: 1333  | total loss: [1m[32m0.07901[0m[0m | time: 27.743s
[2K
| RMSProp | epoch: 025 | loss: 0.07901 - acc: 0.9726 -- iter: 1184/1707
[A[ATraining Step: 1334  | total loss: [1m[32m0.07406[0m[0m | time: 28.484s
[2K
| RMSProp | epoch: 025 | loss: 0.07406 - acc: 0.9754 -- iter: 1216/1707
[A[ATraining Step: 1335  | total loss: [1m[32m0.08518[0m[0m | time: 29.251s
[2K
| RMSProp | epoch: 025 | loss: 0.08518 - acc: 0.9747 -- iter: 1248/1707
[A[ATraining Step: 1336  | total loss: [1m[32m0.07887[0m[0m | time: 29.998s
[2K
| RMSProp | epoch: 025 | loss: 0.07887 - acc: 0.9772 -- iter: 1280/1707
[A[ATraining Step: 1337  | total loss: [1m[32m0.07189[0m[0m | time: 30.740s
[2K
| RMSProp | epoch: 025 | loss: 0.07189 - acc: 0.9795 -- iter: 1312/1707
[A[ATraining Step: 1338  | total loss: [1m[32m0.06506[0m[0m | time: 31.493s
[2K
| RMSProp | epoch: 025 | loss: 0.06506 - acc: 0.9816 -- iter: 1344/1707
[A[ATraining Step: 1339  | total loss: [1m[32m0.06147[0m[0m | time: 32.230s
[2K
| RMSProp | epoch: 025 | loss: 0.06147 - acc: 0.9803 -- iter: 1376/1707
[A[ATraining Step: 1340  | total loss: [1m[32m0.05784[0m[0m | time: 32.980s
[2K
| RMSProp | epoch: 025 | loss: 0.05784 - acc: 0.9791 -- iter: 1408/1707
[A[ATraining Step: 1341  | total loss: [1m[32m0.05250[0m[0m | time: 33.731s
[2K
| RMSProp | epoch: 025 | loss: 0.05250 - acc: 0.9812 -- iter: 1440/1707
[A[ATraining Step: 1342  | total loss: [1m[32m0.04859[0m[0m | time: 34.467s
[2K
| RMSProp | epoch: 025 | loss: 0.04859 - acc: 0.9831 -- iter: 1472/1707
[A[ATraining Step: 1343  | total loss: [1m[32m0.07036[0m[0m | time: 35.207s
[2K
| RMSProp | epoch: 025 | loss: 0.07036 - acc: 0.9817 -- iter: 1504/1707
[A[ATraining Step: 1344  | total loss: [1m[32m0.07317[0m[0m | time: 35.960s
[2K
| RMSProp | epoch: 025 | loss: 0.07317 - acc: 0.9772 -- iter: 1536/1707
[A[ATraining Step: 1345  | total loss: [1m[32m0.07307[0m[0m | time: 36.695s
[2K
| RMSProp | epoch: 025 | loss: 0.07307 - acc: 0.9795 -- iter: 1568/1707
[A[ATraining Step: 1346  | total loss: [1m[32m0.06731[0m[0m | time: 37.465s
[2K
| RMSProp | epoch: 025 | loss: 0.06731 - acc: 0.9816 -- iter: 1600/1707
[A[ATraining Step: 1347  | total loss: [1m[32m0.06315[0m[0m | time: 38.224s
[2K
| RMSProp | epoch: 025 | loss: 0.06315 - acc: 0.9803 -- iter: 1632/1707
[A[ATraining Step: 1348  | total loss: [1m[32m0.05776[0m[0m | time: 38.984s
[2K
| RMSProp | epoch: 025 | loss: 0.05776 - acc: 0.9823 -- iter: 1664/1707
[A[ATraining Step: 1349  | total loss: [1m[32m0.05304[0m[0m | time: 39.753s
[2K
| RMSProp | epoch: 025 | loss: 0.05304 - acc: 0.9840 -- iter: 1696/1707
[A[ATraining Step: 1350  | total loss: [1m[32m0.04795[0m[0m | time: 42.584s
[2K
| RMSProp | epoch: 025 | loss: 0.04795 - acc: 0.9856 | val_loss: 0.86823 - val_acc: 0.7921 -- iter: 1707/1707
--
Training Step: 1351  | total loss: [1m[32m0.04351[0m[0m | time: 0.796s
[2K
| RMSProp | epoch: 026 | loss: 0.04351 - acc: 0.9871 -- iter: 0032/1707
[A[ATraining Step: 1352  | total loss: [1m[32m0.04010[0m[0m | time: 1.559s
[2K
| RMSProp | epoch: 026 | loss: 0.04010 - acc: 0.9884 -- iter: 0064/1707
[A[ATraining Step: 1353  | total loss: [1m[32m0.03626[0m[0m | time: 2.280s
[2K
| RMSProp | epoch: 026 | loss: 0.03626 - acc: 0.9895 -- iter: 0096/1707
[A[ATraining Step: 1354  | total loss: [1m[32m0.03422[0m[0m | time: 2.991s
[2K
| RMSProp | epoch: 026 | loss: 0.03422 - acc: 0.9906 -- iter: 0128/1707
[A[ATraining Step: 1355  | total loss: [1m[32m0.03200[0m[0m | time: 3.746s
[2K
| RMSProp | epoch: 026 | loss: 0.03200 - acc: 0.9915 -- iter: 0160/1707
[A[ATraining Step: 1356  | total loss: [1m[32m0.02952[0m[0m | time: 4.497s
[2K
| RMSProp | epoch: 026 | loss: 0.02952 - acc: 0.9924 -- iter: 0192/1707
[A[ATraining Step: 1357  | total loss: [1m[32m0.02676[0m[0m | time: 5.271s
[2K
| RMSProp | epoch: 026 | loss: 0.02676 - acc: 0.9931 -- iter: 0224/1707
[A[ATraining Step: 1358  | total loss: [1m[32m0.03310[0m[0m | time: 6.049s
[2K
| RMSProp | epoch: 026 | loss: 0.03310 - acc: 0.9907 -- iter: 0256/1707
[A[ATraining Step: 1359  | total loss: [1m[32m0.04998[0m[0m | time: 6.842s
[2K
| RMSProp | epoch: 026 | loss: 0.04998 - acc: 0.9885 -- iter: 0288/1707
[A[ATraining Step: 1360  | total loss: [1m[32m0.05712[0m[0m | time: 7.583s
[2K
| RMSProp | epoch: 026 | loss: 0.05712 - acc: 0.9865 -- iter: 0320/1707
[A[ATraining Step: 1361  | total loss: [1m[32m0.05519[0m[0m | time: 8.316s
[2K
| RMSProp | epoch: 026 | loss: 0.05519 - acc: 0.9847 -- iter: 0352/1707
[A[ATraining Step: 1362  | total loss: [1m[32m0.07433[0m[0m | time: 9.032s
[2K
| RMSProp | epoch: 026 | loss: 0.07433 - acc: 0.9769 -- iter: 0384/1707
[A[ATraining Step: 1363  | total loss: [1m[32m0.07509[0m[0m | time: 9.779s
[2K
| RMSProp | epoch: 026 | loss: 0.07509 - acc: 0.9730 -- iter: 0416/1707
[A[ATraining Step: 1364  | total loss: [1m[32m0.06997[0m[0m | time: 10.583s
[2K
| RMSProp | epoch: 026 | loss: 0.06997 - acc: 0.9757 -- iter: 0448/1707
[A[ATraining Step: 1365  | total loss: [1m[32m0.06372[0m[0m | time: 11.359s
[2K
| RMSProp | epoch: 026 | loss: 0.06372 - acc: 0.9781 -- iter: 0480/1707
[A[ATraining Step: 1366  | total loss: [1m[32m0.05793[0m[0m | time: 12.113s
[2K
| RMSProp | epoch: 026 | loss: 0.05793 - acc: 0.9803 -- iter: 0512/1707
[A[ATraining Step: 1367  | total loss: [1m[32m0.06256[0m[0m | time: 12.856s
[2K
| RMSProp | epoch: 026 | loss: 0.06256 - acc: 0.9791 -- iter: 0544/1707
[A[ATraining Step: 1368  | total loss: [1m[32m0.05912[0m[0m | time: 13.607s
[2K
| RMSProp | epoch: 026 | loss: 0.05912 - acc: 0.9812 -- iter: 0576/1707
[A[ATraining Step: 1369  | total loss: [1m[32m0.05398[0m[0m | time: 14.312s
[2K
| RMSProp | epoch: 026 | loss: 0.05398 - acc: 0.9831 -- iter: 0608/1707
[A[ATraining Step: 1370  | total loss: [1m[32m0.04892[0m[0m | time: 15.059s
[2K
| RMSProp | epoch: 026 | loss: 0.04892 - acc: 0.9848 -- iter: 0640/1707
[A[ATraining Step: 1371  | total loss: [1m[32m0.04473[0m[0m | time: 15.763s
[2K
| RMSProp | epoch: 026 | loss: 0.04473 - acc: 0.9863 -- iter: 0672/1707
[A[ATraining Step: 1372  | total loss: [1m[32m0.06319[0m[0m | time: 16.543s
[2K
| RMSProp | epoch: 026 | loss: 0.06319 - acc: 0.9814 -- iter: 0704/1707
[A[ATraining Step: 1373  | total loss: [1m[32m0.07909[0m[0m | time: 17.279s
[2K
| RMSProp | epoch: 026 | loss: 0.07909 - acc: 0.9739 -- iter: 0736/1707
[A[ATraining Step: 1374  | total loss: [1m[32m0.07463[0m[0m | time: 17.539s
[2K
| RMSProp | epoch: 026 | loss: 0.07463 - acc: 0.9765 -- iter: 0768/1707
[A[ATraining Step: 1375  | total loss: [1m[32m0.06827[0m[0m | time: 17.863s
[2K
| RMSProp | epoch: 026 | loss: 0.06827 - acc: 0.9789 -- iter: 0800/1707
[A[ATraining Step: 1376  | total loss: [1m[32m0.06174[0m[0m | time: 18.639s
[2K
| RMSProp | epoch: 026 | loss: 0.06174 - acc: 0.9810 -- iter: 0832/1707
[A[ATraining Step: 1377  | total loss: [1m[32m0.05587[0m[0m | time: 19.412s
[2K
| RMSProp | epoch: 026 | loss: 0.05587 - acc: 0.9829 -- iter: 0864/1707
[A[ATraining Step: 1378  | total loss: [1m[32m0.06762[0m[0m | time: 20.139s
[2K
| RMSProp | epoch: 026 | loss: 0.06762 - acc: 0.9815 -- iter: 0896/1707
[A[ATraining Step: 1379  | total loss: [1m[32m0.06259[0m[0m | time: 20.885s
[2K
| RMSProp | epoch: 026 | loss: 0.06259 - acc: 0.9833 -- iter: 0928/1707
[A[ATraining Step: 1380  | total loss: [1m[32m0.05871[0m[0m | time: 21.614s
[2K
| RMSProp | epoch: 026 | loss: 0.05871 - acc: 0.9850 -- iter: 0960/1707
[A[ATraining Step: 1381  | total loss: [1m[32m0.06638[0m[0m | time: 22.471s
[2K
| RMSProp | epoch: 026 | loss: 0.06638 - acc: 0.9834 -- iter: 0992/1707
[A[ATraining Step: 1382  | total loss: [1m[32m0.06900[0m[0m | time: 23.632s
[2K
| RMSProp | epoch: 026 | loss: 0.06900 - acc: 0.9788 -- iter: 1024/1707
[A[ATraining Step: 1383  | total loss: [1m[32m0.06344[0m[0m | time: 24.713s
[2K
| RMSProp | epoch: 026 | loss: 0.06344 - acc: 0.9809 -- iter: 1056/1707
[A[ATraining Step: 1384  | total loss: [1m[32m0.06140[0m[0m | time: 25.567s
[2K
| RMSProp | epoch: 026 | loss: 0.06140 - acc: 0.9797 -- iter: 1088/1707
[A[ATraining Step: 1385  | total loss: [1m[32m0.06746[0m[0m | time: 26.299s
[2K
| RMSProp | epoch: 026 | loss: 0.06746 - acc: 0.9755 -- iter: 1120/1707
[A[ATraining Step: 1386  | total loss: [1m[32m0.09515[0m[0m | time: 27.049s
[2K
| RMSProp | epoch: 026 | loss: 0.09515 - acc: 0.9654 -- iter: 1152/1707
[A[ATraining Step: 1387  | total loss: [1m[32m0.08964[0m[0m | time: 27.763s
[2K
| RMSProp | epoch: 026 | loss: 0.08964 - acc: 0.9658 -- iter: 1184/1707
[A[ATraining Step: 1388  | total loss: [1m[32m0.08269[0m[0m | time: 28.496s
[2K
| RMSProp | epoch: 026 | loss: 0.08269 - acc: 0.9692 -- iter: 1216/1707
[A[ATraining Step: 1389  | total loss: [1m[32m0.07479[0m[0m | time: 29.192s
[2K
| RMSProp | epoch: 026 | loss: 0.07479 - acc: 0.9723 -- iter: 1248/1707
[A[ATraining Step: 1390  | total loss: [1m[32m0.06765[0m[0m | time: 29.939s
[2K
| RMSProp | epoch: 026 | loss: 0.06765 - acc: 0.9750 -- iter: 1280/1707
[A[ATraining Step: 1391  | total loss: [1m[32m0.06164[0m[0m | time: 30.670s
[2K
| RMSProp | epoch: 026 | loss: 0.06164 - acc: 0.9775 -- iter: 1312/1707
[A[ATraining Step: 1392  | total loss: [1m[32m0.05664[0m[0m | time: 31.413s
[2K
| RMSProp | epoch: 026 | loss: 0.05664 - acc: 0.9798 -- iter: 1344/1707
[A[ATraining Step: 1393  | total loss: [1m[32m0.05104[0m[0m | time: 32.191s
[2K
| RMSProp | epoch: 026 | loss: 0.05104 - acc: 0.9818 -- iter: 1376/1707
[A[ATraining Step: 1394  | total loss: [1m[32m0.04606[0m[0m | time: 32.924s
[2K
| RMSProp | epoch: 026 | loss: 0.04606 - acc: 0.9836 -- iter: 1408/1707
[A[ATraining Step: 1395  | total loss: [1m[32m0.04162[0m[0m | time: 33.682s
[2K
| RMSProp | epoch: 026 | loss: 0.04162 - acc: 0.9853 -- iter: 1440/1707
[A[ATraining Step: 1396  | total loss: [1m[32m0.03762[0m[0m | time: 34.439s
[2K
| RMSProp | epoch: 026 | loss: 0.03762 - acc: 0.9867 -- iter: 1472/1707
[A[ATraining Step: 1397  | total loss: [1m[32m0.04696[0m[0m | time: 35.134s
[2K
| RMSProp | epoch: 026 | loss: 0.04696 - acc: 0.9849 -- iter: 1504/1707
[A[ATraining Step: 1398  | total loss: [1m[32m0.07067[0m[0m | time: 35.944s
[2K
| RMSProp | epoch: 026 | loss: 0.07067 - acc: 0.9833 -- iter: 1536/1707
[A[ATraining Step: 1399  | total loss: [1m[32m0.06607[0m[0m | time: 36.715s
[2K
| RMSProp | epoch: 026 | loss: 0.06607 - acc: 0.9850 -- iter: 1568/1707
[A[ATraining Step: 1400  | total loss: [1m[32m0.06608[0m[0m | time: 39.582s
[2K
| RMSProp | epoch: 026 | loss: 0.06608 - acc: 0.9834 | val_loss: 0.78368 - val_acc: 0.8034 -- iter: 1600/1707
--
Training Step: 1401  | total loss: [1m[32m0.06145[0m[0m | time: 40.323s
[2K
| RMSProp | epoch: 026 | loss: 0.06145 - acc: 0.9850 -- iter: 1632/1707
[A[ATraining Step: 1402  | total loss: [1m[32m0.05627[0m[0m | time: 41.066s
[2K
| RMSProp | epoch: 026 | loss: 0.05627 - acc: 0.9865 -- iter: 1664/1707
[A[ATraining Step: 1403  | total loss: [1m[32m0.05240[0m[0m | time: 41.841s
[2K
| RMSProp | epoch: 026 | loss: 0.05240 - acc: 0.9879 -- iter: 1696/1707
[A[ATraining Step: 1404  | total loss: [1m[32m0.04737[0m[0m | time: 44.795s
[2K
| RMSProp | epoch: 026 | loss: 0.04737 - acc: 0.9891 | val_loss: 1.02871 - val_acc: 0.7884 -- iter: 1707/1707
--
Training Step: 1405  | total loss: [1m[32m0.04281[0m[0m | time: 0.726s
[2K
| RMSProp | epoch: 027 | loss: 0.04281 - acc: 0.9902 -- iter: 0032/1707
[A[ATraining Step: 1406  | total loss: [1m[32m0.03864[0m[0m | time: 1.440s
[2K
| RMSProp | epoch: 027 | loss: 0.03864 - acc: 0.9912 -- iter: 0064/1707
[A[ATraining Step: 1407  | total loss: [1m[32m0.03492[0m[0m | time: 2.196s
[2K
| RMSProp | epoch: 027 | loss: 0.03492 - acc: 0.9920 -- iter: 0096/1707
[A[ATraining Step: 1408  | total loss: [1m[32m0.03154[0m[0m | time: 2.947s
[2K
| RMSProp | epoch: 027 | loss: 0.03154 - acc: 0.9928 -- iter: 0128/1707
[A[ATraining Step: 1409  | total loss: [1m[32m0.03228[0m[0m | time: 3.695s
[2K
| RMSProp | epoch: 027 | loss: 0.03228 - acc: 0.9904 -- iter: 0160/1707
[A[ATraining Step: 1410  | total loss: [1m[32m0.03866[0m[0m | time: 4.413s
[2K
| RMSProp | epoch: 027 | loss: 0.03866 - acc: 0.9883 -- iter: 0192/1707
[A[ATraining Step: 1411  | total loss: [1m[32m0.05294[0m[0m | time: 5.146s
[2K
| RMSProp | epoch: 027 | loss: 0.05294 - acc: 0.9863 -- iter: 0224/1707
[A[ATraining Step: 1412  | total loss: [1m[32m0.06641[0m[0m | time: 5.910s
[2K
| RMSProp | epoch: 027 | loss: 0.06641 - acc: 0.9814 -- iter: 0256/1707
[A[ATraining Step: 1413  | total loss: [1m[32m0.06808[0m[0m | time: 6.621s
[2K
| RMSProp | epoch: 027 | loss: 0.06808 - acc: 0.9802 -- iter: 0288/1707
[A[ATraining Step: 1414  | total loss: [1m[32m0.06737[0m[0m | time: 7.351s
[2K
| RMSProp | epoch: 027 | loss: 0.06737 - acc: 0.9790 -- iter: 0320/1707
[A[ATraining Step: 1415  | total loss: [1m[32m0.06268[0m[0m | time: 8.093s
[2K
| RMSProp | epoch: 027 | loss: 0.06268 - acc: 0.9811 -- iter: 0352/1707
[A[ATraining Step: 1416  | total loss: [1m[32m0.05847[0m[0m | time: 8.846s
[2K
| RMSProp | epoch: 027 | loss: 0.05847 - acc: 0.9830 -- iter: 0384/1707
[A[ATraining Step: 1417  | total loss: [1m[32m0.05307[0m[0m | time: 9.575s
[2K
| RMSProp | epoch: 027 | loss: 0.05307 - acc: 0.9847 -- iter: 0416/1707
[A[ATraining Step: 1418  | total loss: [1m[32m0.04815[0m[0m | time: 10.322s
[2K
| RMSProp | epoch: 027 | loss: 0.04815 - acc: 0.9862 -- iter: 0448/1707
[A[ATraining Step: 1419  | total loss: [1m[32m0.04374[0m[0m | time: 11.040s
[2K
| RMSProp | epoch: 027 | loss: 0.04374 - acc: 0.9876 -- iter: 0480/1707
[A[ATraining Step: 1420  | total loss: [1m[32m0.03951[0m[0m | time: 11.811s
[2K
| RMSProp | epoch: 027 | loss: 0.03951 - acc: 0.9889 -- iter: 0512/1707
[A[ATraining Step: 1421  | total loss: [1m[32m0.03624[0m[0m | time: 12.534s
[2K
| RMSProp | epoch: 027 | loss: 0.03624 - acc: 0.9900 -- iter: 0544/1707
[A[ATraining Step: 1422  | total loss: [1m[32m0.03291[0m[0m | time: 13.276s
[2K
| RMSProp | epoch: 027 | loss: 0.03291 - acc: 0.9910 -- iter: 0576/1707
[A[ATraining Step: 1423  | total loss: [1m[32m0.05444[0m[0m | time: 14.009s
[2K
| RMSProp | epoch: 027 | loss: 0.05444 - acc: 0.9856 -- iter: 0608/1707
[A[ATraining Step: 1424  | total loss: [1m[32m0.08018[0m[0m | time: 14.770s
[2K
| RMSProp | epoch: 027 | loss: 0.08018 - acc: 0.9777 -- iter: 0640/1707
[A[ATraining Step: 1425  | total loss: [1m[32m0.07409[0m[0m | time: 15.511s
[2K
| RMSProp | epoch: 027 | loss: 0.07409 - acc: 0.9799 -- iter: 0672/1707
[A[ATraining Step: 1426  | total loss: [1m[32m0.08222[0m[0m | time: 16.244s
[2K
| RMSProp | epoch: 027 | loss: 0.08222 - acc: 0.9757 -- iter: 0704/1707
[A[ATraining Step: 1427  | total loss: [1m[32m0.09476[0m[0m | time: 16.989s
[2K
| RMSProp | epoch: 027 | loss: 0.09476 - acc: 0.9687 -- iter: 0736/1707
[A[ATraining Step: 1428  | total loss: [1m[32m0.08895[0m[0m | time: 17.763s
[2K
| RMSProp | epoch: 027 | loss: 0.08895 - acc: 0.9719 -- iter: 0768/1707
[A[ATraining Step: 1429  | total loss: [1m[32m0.08102[0m[0m | time: 18.037s
[2K
| RMSProp | epoch: 027 | loss: 0.08102 - acc: 0.9747 -- iter: 0800/1707
[A[ATraining Step: 1430  | total loss: [1m[32m0.07349[0m[0m | time: 18.426s
[2K
| RMSProp | epoch: 027 | loss: 0.07349 - acc: 0.9772 -- iter: 0832/1707
[A[ATraining Step: 1431  | total loss: [1m[32m0.06646[0m[0m | time: 19.193s
[2K
| RMSProp | epoch: 027 | loss: 0.06646 - acc: 0.9795 -- iter: 0864/1707
[A[ATraining Step: 1432  | total loss: [1m[32m0.06028[0m[0m | time: 19.937s
[2K
| RMSProp | epoch: 027 | loss: 0.06028 - acc: 0.9815 -- iter: 0896/1707
[A[ATraining Step: 1433  | total loss: [1m[32m0.05442[0m[0m | time: 20.665s
[2K
| RMSProp | epoch: 027 | loss: 0.05442 - acc: 0.9834 -- iter: 0928/1707
[A[ATraining Step: 1434  | total loss: [1m[32m0.05396[0m[0m | time: 21.394s
[2K
| RMSProp | epoch: 027 | loss: 0.05396 - acc: 0.9819 -- iter: 0960/1707
[A[ATraining Step: 1435  | total loss: [1m[32m0.05211[0m[0m | time: 22.145s
[2K
| RMSProp | epoch: 027 | loss: 0.05211 - acc: 0.9806 -- iter: 0992/1707
[A[ATraining Step: 1436  | total loss: [1m[32m0.04719[0m[0m | time: 22.882s
[2K
| RMSProp | epoch: 027 | loss: 0.04719 - acc: 0.9825 -- iter: 1024/1707
[A[ATraining Step: 1437  | total loss: [1m[32m0.04298[0m[0m | time: 23.649s
[2K
| RMSProp | epoch: 027 | loss: 0.04298 - acc: 0.9843 -- iter: 1056/1707
[A[ATraining Step: 1438  | total loss: [1m[32m0.03884[0m[0m | time: 24.370s
[2K
| RMSProp | epoch: 027 | loss: 0.03884 - acc: 0.9859 -- iter: 1088/1707
[A[ATraining Step: 1439  | total loss: [1m[32m0.03526[0m[0m | time: 25.133s
[2K
| RMSProp | epoch: 027 | loss: 0.03526 - acc: 0.9873 -- iter: 1120/1707
[A[ATraining Step: 1440  | total loss: [1m[32m0.03187[0m[0m | time: 25.883s
[2K
| RMSProp | epoch: 027 | loss: 0.03187 - acc: 0.9885 -- iter: 1152/1707
[A[ATraining Step: 1441  | total loss: [1m[32m0.02873[0m[0m | time: 26.614s
[2K
| RMSProp | epoch: 027 | loss: 0.02873 - acc: 0.9897 -- iter: 1184/1707
[A[ATraining Step: 1442  | total loss: [1m[32m0.03611[0m[0m | time: 27.360s
[2K
| RMSProp | epoch: 027 | loss: 0.03611 - acc: 0.9876 -- iter: 1216/1707
[A[ATraining Step: 1443  | total loss: [1m[32m0.04580[0m[0m | time: 28.114s
[2K
| RMSProp | epoch: 027 | loss: 0.04580 - acc: 0.9826 -- iter: 1248/1707
[A[ATraining Step: 1444  | total loss: [1m[32m0.05535[0m[0m | time: 28.860s
[2K
| RMSProp | epoch: 027 | loss: 0.05535 - acc: 0.9781 -- iter: 1280/1707
[A[ATraining Step: 1445  | total loss: [1m[32m0.06296[0m[0m | time: 29.609s
[2K
| RMSProp | epoch: 027 | loss: 0.06296 - acc: 0.9740 -- iter: 1312/1707
[A[ATraining Step: 1446  | total loss: [1m[32m0.06545[0m[0m | time: 30.340s
[2K
| RMSProp | epoch: 027 | loss: 0.06545 - acc: 0.9735 -- iter: 1344/1707
[A[ATraining Step: 1447  | total loss: [1m[32m0.08148[0m[0m | time: 31.075s
[2K
| RMSProp | epoch: 027 | loss: 0.08148 - acc: 0.9699 -- iter: 1376/1707
[A[ATraining Step: 1448  | total loss: [1m[32m0.07752[0m[0m | time: 31.867s
[2K
| RMSProp | epoch: 027 | loss: 0.07752 - acc: 0.9698 -- iter: 1408/1707
[A[ATraining Step: 1449  | total loss: [1m[32m0.07115[0m[0m | time: 32.620s
[2K
| RMSProp | epoch: 027 | loss: 0.07115 - acc: 0.9728 -- iter: 1440/1707
[A[ATraining Step: 1450  | total loss: [1m[32m0.06517[0m[0m | time: 33.369s
[2K
| RMSProp | epoch: 027 | loss: 0.06517 - acc: 0.9755 -- iter: 1472/1707
[A[ATraining Step: 1451  | total loss: [1m[32m0.06147[0m[0m | time: 34.126s
[2K
| RMSProp | epoch: 027 | loss: 0.06147 - acc: 0.9780 -- iter: 1504/1707
[A[ATraining Step: 1452  | total loss: [1m[32m0.06005[0m[0m | time: 34.885s
[2K
| RMSProp | epoch: 027 | loss: 0.06005 - acc: 0.9802 -- iter: 1536/1707
[A[ATraining Step: 1453  | total loss: [1m[32m0.17153[0m[0m | time: 35.614s
[2K
| RMSProp | epoch: 027 | loss: 0.17153 - acc: 0.9697 -- iter: 1568/1707
[A[ATraining Step: 1454  | total loss: [1m[32m0.17458[0m[0m | time: 36.373s
[2K
| RMSProp | epoch: 027 | loss: 0.17458 - acc: 0.9602 -- iter: 1600/1707
[A[ATraining Step: 1455  | total loss: [1m[32m0.16436[0m[0m | time: 37.144s
[2K
| RMSProp | epoch: 027 | loss: 0.16436 - acc: 0.9610 -- iter: 1632/1707
[A[ATraining Step: 1456  | total loss: [1m[32m0.14894[0m[0m | time: 37.889s
[2K
| RMSProp | epoch: 027 | loss: 0.14894 - acc: 0.9649 -- iter: 1664/1707
[A[ATraining Step: 1457  | total loss: [1m[32m0.13632[0m[0m | time: 38.633s
[2K
| RMSProp | epoch: 027 | loss: 0.13632 - acc: 0.9684 -- iter: 1696/1707
[A[ATraining Step: 1458  | total loss: [1m[32m0.12317[0m[0m | time: 41.661s
[2K
| RMSProp | epoch: 027 | loss: 0.12317 - acc: 0.9716 | val_loss: 0.85702 - val_acc: 0.7978 -- iter: 1707/1707
--
Training Step: 1459  | total loss: [1m[32m0.11144[0m[0m | time: 1.184s
[2K
| RMSProp | epoch: 028 | loss: 0.11144 - acc: 0.9744 -- iter: 0032/1707
[A[ATraining Step: 1460  | total loss: [1m[32m0.11369[0m[0m | time: 1.977s
[2K
| RMSProp | epoch: 028 | loss: 0.11369 - acc: 0.9739 -- iter: 0064/1707
[A[ATraining Step: 1461  | total loss: [1m[32m0.10426[0m[0m | time: 2.711s
[2K
| RMSProp | epoch: 028 | loss: 0.10426 - acc: 0.9765 -- iter: 0096/1707
[A[ATraining Step: 1462  | total loss: [1m[32m0.10217[0m[0m | time: 3.433s
[2K
| RMSProp | epoch: 028 | loss: 0.10217 - acc: 0.9757 -- iter: 0128/1707
[A[ATraining Step: 1463  | total loss: [1m[32m0.10984[0m[0m | time: 4.184s
[2K
| RMSProp | epoch: 028 | loss: 0.10984 - acc: 0.9750 -- iter: 0160/1707
[A[ATraining Step: 1464  | total loss: [1m[32m0.11233[0m[0m | time: 4.957s
[2K
| RMSProp | epoch: 028 | loss: 0.11233 - acc: 0.9744 -- iter: 0192/1707
[A[ATraining Step: 1465  | total loss: [1m[32m0.10224[0m[0m | time: 5.693s
[2K
| RMSProp | epoch: 028 | loss: 0.10224 - acc: 0.9770 -- iter: 0224/1707
[A[ATraining Step: 1466  | total loss: [1m[32m0.09288[0m[0m | time: 6.436s
[2K
| RMSProp | epoch: 028 | loss: 0.09288 - acc: 0.9793 -- iter: 0256/1707
[A[ATraining Step: 1467  | total loss: [1m[32m0.08408[0m[0m | time: 7.167s
[2K
| RMSProp | epoch: 028 | loss: 0.08408 - acc: 0.9813 -- iter: 0288/1707
[A[ATraining Step: 1468  | total loss: [1m[32m0.07658[0m[0m | time: 7.905s
[2K
| RMSProp | epoch: 028 | loss: 0.07658 - acc: 0.9832 -- iter: 0320/1707
[A[ATraining Step: 1469  | total loss: [1m[32m0.06917[0m[0m | time: 8.660s
[2K
| RMSProp | epoch: 028 | loss: 0.06917 - acc: 0.9849 -- iter: 0352/1707
[A[ATraining Step: 1470  | total loss: [1m[32m0.06238[0m[0m | time: 9.425s
[2K
| RMSProp | epoch: 028 | loss: 0.06238 - acc: 0.9864 -- iter: 0384/1707
[A[ATraining Step: 1471  | total loss: [1m[32m0.05642[0m[0m | time: 10.169s
[2K
| RMSProp | epoch: 028 | loss: 0.05642 - acc: 0.9878 -- iter: 0416/1707
[A[ATraining Step: 1472  | total loss: [1m[32m0.05091[0m[0m | time: 10.929s
[2K
| RMSProp | epoch: 028 | loss: 0.05091 - acc: 0.9890 -- iter: 0448/1707
[A[ATraining Step: 1473  | total loss: [1m[32m0.04602[0m[0m | time: 11.649s
[2K
| RMSProp | epoch: 028 | loss: 0.04602 - acc: 0.9901 -- iter: 0480/1707
[A[ATraining Step: 1474  | total loss: [1m[32m0.05867[0m[0m | time: 12.361s
[2K
| RMSProp | epoch: 028 | loss: 0.05867 - acc: 0.9879 -- iter: 0512/1707
[A[ATraining Step: 1475  | total loss: [1m[32m0.09273[0m[0m | time: 13.183s
[2K
| RMSProp | epoch: 028 | loss: 0.09273 - acc: 0.9704 -- iter: 0544/1707
[A[ATraining Step: 1476  | total loss: [1m[32m0.09038[0m[0m | time: 13.920s
[2K
| RMSProp | epoch: 028 | loss: 0.09038 - acc: 0.9702 -- iter: 0576/1707
[A[ATraining Step: 1477  | total loss: [1m[32m0.08211[0m[0m | time: 14.657s
[2K
| RMSProp | epoch: 028 | loss: 0.08211 - acc: 0.9732 -- iter: 0608/1707
[A[ATraining Step: 1478  | total loss: [1m[32m0.07717[0m[0m | time: 15.417s
[2K
| RMSProp | epoch: 028 | loss: 0.07717 - acc: 0.9728 -- iter: 0640/1707
[A[ATraining Step: 1479  | total loss: [1m[32m0.07234[0m[0m | time: 16.120s
[2K
| RMSProp | epoch: 028 | loss: 0.07234 - acc: 0.9724 -- iter: 0672/1707
[A[ATraining Step: 1480  | total loss: [1m[32m0.09889[0m[0m | time: 16.843s
[2K
| RMSProp | epoch: 028 | loss: 0.09889 - acc: 0.9658 -- iter: 0704/1707
[A[ATraining Step: 1481  | total loss: [1m[32m0.09624[0m[0m | time: 17.585s
[2K
| RMSProp | epoch: 028 | loss: 0.09624 - acc: 0.9661 -- iter: 0736/1707
[A[ATraining Step: 1482  | total loss: [1m[32m0.08889[0m[0m | time: 18.327s
[2K
| RMSProp | epoch: 028 | loss: 0.08889 - acc: 0.9694 -- iter: 0768/1707
[A[ATraining Step: 1483  | total loss: [1m[32m0.08080[0m[0m | time: 19.079s
[2K
| RMSProp | epoch: 028 | loss: 0.08080 - acc: 0.9725 -- iter: 0800/1707
[A[ATraining Step: 1484  | total loss: [1m[32m0.07294[0m[0m | time: 19.347s
[2K
| RMSProp | epoch: 028 | loss: 0.07294 - acc: 0.9753 -- iter: 0832/1707
[A[ATraining Step: 1485  | total loss: [1m[32m0.07991[0m[0m | time: 19.732s
[2K
| RMSProp | epoch: 028 | loss: 0.07991 - acc: 0.9686 -- iter: 0864/1707
[A[ATraining Step: 1486  | total loss: [1m[32m0.07228[0m[0m | time: 20.493s
[2K
| RMSProp | epoch: 028 | loss: 0.07228 - acc: 0.9718 -- iter: 0896/1707
[A[ATraining Step: 1487  | total loss: [1m[32m0.06587[0m[0m | time: 21.259s
[2K
| RMSProp | epoch: 028 | loss: 0.06587 - acc: 0.9746 -- iter: 0928/1707
[A[ATraining Step: 1488  | total loss: [1m[32m0.05995[0m[0m | time: 22.027s
[2K
| RMSProp | epoch: 028 | loss: 0.05995 - acc: 0.9771 -- iter: 0960/1707
[A[ATraining Step: 1489  | total loss: [1m[32m0.05517[0m[0m | time: 22.819s
[2K
| RMSProp | epoch: 028 | loss: 0.05517 - acc: 0.9794 -- iter: 0992/1707
[A[ATraining Step: 1490  | total loss: [1m[32m0.05512[0m[0m | time: 23.577s
[2K
| RMSProp | epoch: 028 | loss: 0.05512 - acc: 0.9784 -- iter: 1024/1707
[A[ATraining Step: 1491  | total loss: [1m[32m0.06826[0m[0m | time: 24.322s
[2K
| RMSProp | epoch: 028 | loss: 0.06826 - acc: 0.9774 -- iter: 1056/1707
[A[ATraining Step: 1492  | total loss: [1m[32m0.06987[0m[0m | time: 25.057s
[2K
| RMSProp | epoch: 028 | loss: 0.06987 - acc: 0.9765 -- iter: 1088/1707
[A[ATraining Step: 1493  | total loss: [1m[32m0.07322[0m[0m | time: 25.781s
[2K
| RMSProp | epoch: 028 | loss: 0.07322 - acc: 0.9726 -- iter: 1120/1707
[A[ATraining Step: 1494  | total loss: [1m[32m0.06653[0m[0m | time: 26.535s
[2K
| RMSProp | epoch: 028 | loss: 0.06653 - acc: 0.9754 -- iter: 1152/1707
[A[ATraining Step: 1495  | total loss: [1m[32m0.06014[0m[0m | time: 27.278s
[2K
| RMSProp | epoch: 028 | loss: 0.06014 - acc: 0.9778 -- iter: 1184/1707
[A[ATraining Step: 1496  | total loss: [1m[32m0.05458[0m[0m | time: 28.035s
[2K
| RMSProp | epoch: 028 | loss: 0.05458 - acc: 0.9800 -- iter: 1216/1707
[A[ATraining Step: 1497  | total loss: [1m[32m0.05022[0m[0m | time: 28.780s
[2K
| RMSProp | epoch: 028 | loss: 0.05022 - acc: 0.9820 -- iter: 1248/1707
[A[ATraining Step: 1498  | total loss: [1m[32m0.04865[0m[0m | time: 29.522s
[2K
| RMSProp | epoch: 028 | loss: 0.04865 - acc: 0.9807 -- iter: 1280/1707
[A[ATraining Step: 1499  | total loss: [1m[32m0.07859[0m[0m | time: 30.276s
[2K
| RMSProp | epoch: 028 | loss: 0.07859 - acc: 0.9764 -- iter: 1312/1707
[A[ATraining Step: 1500  | total loss: [1m[32m0.07160[0m[0m | time: 31.009s
[2K
| RMSProp | epoch: 028 | loss: 0.07160 - acc: 0.9788 -- iter: 1344/1707
[A[ATraining Step: 1501  | total loss: [1m[32m0.06495[0m[0m | time: 31.750s
[2K
| RMSProp | epoch: 028 | loss: 0.06495 - acc: 0.9809 -- iter: 1376/1707
[A[ATraining Step: 1502  | total loss: [1m[32m0.05889[0m[0m | time: 32.484s
[2K
| RMSProp | epoch: 028 | loss: 0.05889 - acc: 0.9828 -- iter: 1408/1707
[A[ATraining Step: 1503  | total loss: [1m[32m0.05341[0m[0m | time: 33.205s
[2K
| RMSProp | epoch: 028 | loss: 0.05341 - acc: 0.9845 -- iter: 1440/1707
[A[ATraining Step: 1504  | total loss: [1m[32m0.04853[0m[0m | time: 33.955s
[2K
| RMSProp | epoch: 028 | loss: 0.04853 - acc: 0.9861 -- iter: 1472/1707
[A[ATraining Step: 1505  | total loss: [1m[32m0.05203[0m[0m | time: 34.693s
[2K
| RMSProp | epoch: 028 | loss: 0.05203 - acc: 0.9843 -- iter: 1504/1707
[A[ATraining Step: 1506  | total loss: [1m[32m0.04712[0m[0m | time: 35.455s
[2K
| RMSProp | epoch: 028 | loss: 0.04712 - acc: 0.9859 -- iter: 1536/1707
[A[ATraining Step: 1507  | total loss: [1m[32m0.04244[0m[0m | time: 36.180s
[2K
| RMSProp | epoch: 028 | loss: 0.04244 - acc: 0.9873 -- iter: 1568/1707
[A[ATraining Step: 1508  | total loss: [1m[32m0.03845[0m[0m | time: 36.900s
[2K
| RMSProp | epoch: 028 | loss: 0.03845 - acc: 0.9886 -- iter: 1600/1707
[A[ATraining Step: 1509  | total loss: [1m[32m0.03517[0m[0m | time: 37.648s
[2K
| RMSProp | epoch: 028 | loss: 0.03517 - acc: 0.9897 -- iter: 1632/1707
[A[ATraining Step: 1510  | total loss: [1m[32m0.03262[0m[0m | time: 38.397s
[2K
| RMSProp | epoch: 028 | loss: 0.03262 - acc: 0.9907 -- iter: 1664/1707
[A[ATraining Step: 1511  | total loss: [1m[32m0.03017[0m[0m | time: 39.210s
[2K
| RMSProp | epoch: 028 | loss: 0.03017 - acc: 0.9917 -- iter: 1696/1707
[A[ATraining Step: 1512  | total loss: [1m[32m0.02737[0m[0m | time: 42.107s
[2K
| RMSProp | epoch: 028 | loss: 0.02737 - acc: 0.9925 | val_loss: 1.67798 - val_acc: 0.7041 -- iter: 1707/1707
--
Training Step: 1513  | total loss: [1m[32m0.03656[0m[0m | time: 0.780s
[2K
| RMSProp | epoch: 029 | loss: 0.03656 - acc: 0.9901 -- iter: 0032/1707
[A[ATraining Step: 1514  | total loss: [1m[32m0.06638[0m[0m | time: 1.555s
[2K
| RMSProp | epoch: 029 | loss: 0.06638 - acc: 0.9817 -- iter: 0064/1707
[A[ATraining Step: 1515  | total loss: [1m[32m0.07117[0m[0m | time: 2.282s
[2K
| RMSProp | epoch: 029 | loss: 0.07117 - acc: 0.9773 -- iter: 0096/1707
[A[ATraining Step: 1516  | total loss: [1m[32m0.06808[0m[0m | time: 3.021s
[2K
| RMSProp | epoch: 029 | loss: 0.06808 - acc: 0.9765 -- iter: 0128/1707
[A[ATraining Step: 1517  | total loss: [1m[32m0.06315[0m[0m | time: 3.758s
[2K
| RMSProp | epoch: 029 | loss: 0.06315 - acc: 0.9788 -- iter: 0160/1707
[A[ATraining Step: 1518  | total loss: [1m[32m0.05714[0m[0m | time: 4.487s
[2K
| RMSProp | epoch: 029 | loss: 0.05714 - acc: 0.9809 -- iter: 0192/1707
[A[ATraining Step: 1519  | total loss: [1m[32m0.05184[0m[0m | time: 5.224s
[2K
| RMSProp | epoch: 029 | loss: 0.05184 - acc: 0.9828 -- iter: 0224/1707
[A[ATraining Step: 1520  | total loss: [1m[32m0.04736[0m[0m | time: 6.001s
[2K
| RMSProp | epoch: 029 | loss: 0.04736 - acc: 0.9846 -- iter: 0256/1707
[A[ATraining Step: 1521  | total loss: [1m[32m0.04281[0m[0m | time: 6.812s
[2K
| RMSProp | epoch: 029 | loss: 0.04281 - acc: 0.9861 -- iter: 0288/1707
[A[ATraining Step: 1522  | total loss: [1m[32m0.03861[0m[0m | time: 7.557s
[2K
| RMSProp | epoch: 029 | loss: 0.03861 - acc: 0.9875 -- iter: 0320/1707
[A[ATraining Step: 1523  | total loss: [1m[32m0.03483[0m[0m | time: 8.331s
[2K
| RMSProp | epoch: 029 | loss: 0.03483 - acc: 0.9887 -- iter: 0352/1707
[A[ATraining Step: 1524  | total loss: [1m[32m0.03145[0m[0m | time: 9.073s
[2K
| RMSProp | epoch: 029 | loss: 0.03145 - acc: 0.9899 -- iter: 0384/1707
[A[ATraining Step: 1525  | total loss: [1m[32m0.03348[0m[0m | time: 9.805s
[2K
| RMSProp | epoch: 029 | loss: 0.03348 - acc: 0.9878 -- iter: 0416/1707
[A[ATraining Step: 1526  | total loss: [1m[32m0.04845[0m[0m | time: 10.622s
[2K
| RMSProp | epoch: 029 | loss: 0.04845 - acc: 0.9859 -- iter: 0448/1707
[A[ATraining Step: 1527  | total loss: [1m[32m0.04551[0m[0m | time: 11.360s
[2K
| RMSProp | epoch: 029 | loss: 0.04551 - acc: 0.9873 -- iter: 0480/1707
[A[ATraining Step: 1528  | total loss: [1m[32m0.04152[0m[0m | time: 12.081s
[2K
| RMSProp | epoch: 029 | loss: 0.04152 - acc: 0.9885 -- iter: 0512/1707
[A[ATraining Step: 1529  | total loss: [1m[32m0.03759[0m[0m | time: 12.837s
[2K
| RMSProp | epoch: 029 | loss: 0.03759 - acc: 0.9897 -- iter: 0544/1707
[A[ATraining Step: 1530  | total loss: [1m[32m0.03673[0m[0m | time: 13.571s
[2K
| RMSProp | epoch: 029 | loss: 0.03673 - acc: 0.9876 -- iter: 0576/1707
[A[ATraining Step: 1531  | total loss: [1m[32m0.03347[0m[0m | time: 14.482s
[2K
| RMSProp | epoch: 029 | loss: 0.03347 - acc: 0.9888 -- iter: 0608/1707
[A[ATraining Step: 1532  | total loss: [1m[32m0.03836[0m[0m | time: 15.408s
[2K
| RMSProp | epoch: 029 | loss: 0.03836 - acc: 0.9868 -- iter: 0640/1707
[A[ATraining Step: 1533  | total loss: [1m[32m0.03512[0m[0m | time: 16.340s
[2K
| RMSProp | epoch: 029 | loss: 0.03512 - acc: 0.9881 -- iter: 0672/1707
[A[ATraining Step: 1534  | total loss: [1m[32m0.03568[0m[0m | time: 17.281s
[2K
| RMSProp | epoch: 029 | loss: 0.03568 - acc: 0.9862 -- iter: 0704/1707
[A[ATraining Step: 1535  | total loss: [1m[32m0.05680[0m[0m | time: 18.162s
[2K
| RMSProp | epoch: 029 | loss: 0.05680 - acc: 0.9782 -- iter: 0736/1707
[A[ATraining Step: 1536  | total loss: [1m[32m0.06163[0m[0m | time: 19.095s
[2K
| RMSProp | epoch: 029 | loss: 0.06163 - acc: 0.9773 -- iter: 0768/1707
[A[ATraining Step: 1537  | total loss: [1m[32m0.05983[0m[0m | time: 20.365s
[2K
| RMSProp | epoch: 029 | loss: 0.05983 - acc: 0.9764 -- iter: 0800/1707
[A[ATraining Step: 1538  | total loss: [1m[32m0.05451[0m[0m | time: 21.660s
[2K
| RMSProp | epoch: 029 | loss: 0.05451 - acc: 0.9788 -- iter: 0832/1707
[A[ATraining Step: 1539  | total loss: [1m[32m0.05422[0m[0m | time: 22.177s
[2K
| RMSProp | epoch: 029 | loss: 0.05422 - acc: 0.9778 -- iter: 0864/1707
[A[ATraining Step: 1540  | total loss: [1m[32m0.04898[0m[0m | time: 22.686s
[2K
| RMSProp | epoch: 029 | loss: 0.04898 - acc: 0.9800 -- iter: 0896/1707
[A[ATraining Step: 1541  | total loss: [1m[32m0.04419[0m[0m | time: 23.448s
[2K
| RMSProp | epoch: 029 | loss: 0.04419 - acc: 0.9820 -- iter: 0928/1707
[A[ATraining Step: 1542  | total loss: [1m[32m0.05960[0m[0m | time: 24.314s
[2K
| RMSProp | epoch: 029 | loss: 0.05960 - acc: 0.9775 -- iter: 0960/1707
[A[ATraining Step: 1543  | total loss: [1m[32m0.06354[0m[0m | time: 25.192s
[2K
| RMSProp | epoch: 029 | loss: 0.06354 - acc: 0.9767 -- iter: 0992/1707
[A[ATraining Step: 1544  | total loss: [1m[32m0.06014[0m[0m | time: 26.085s
[2K
| RMSProp | epoch: 029 | loss: 0.06014 - acc: 0.9790 -- iter: 1024/1707
[A[ATraining Step: 1545  | total loss: [1m[32m0.06268[0m[0m | time: 27.027s
[2K
| RMSProp | epoch: 029 | loss: 0.06268 - acc: 0.9780 -- iter: 1056/1707
[A[ATraining Step: 1546  | total loss: [1m[32m0.05670[0m[0m | time: 27.943s
[2K
| RMSProp | epoch: 029 | loss: 0.05670 - acc: 0.9802 -- iter: 1088/1707
[A[ATraining Step: 1547  | total loss: [1m[32m0.05390[0m[0m | time: 28.793s
[2K
| RMSProp | epoch: 029 | loss: 0.05390 - acc: 0.9822 -- iter: 1120/1707
[A[ATraining Step: 1548  | total loss: [1m[32m0.06212[0m[0m | time: 29.671s
[2K
| RMSProp | epoch: 029 | loss: 0.06212 - acc: 0.9808 -- iter: 1152/1707
[A[ATraining Step: 1549  | total loss: [1m[32m0.05903[0m[0m | time: 30.580s
[2K
| RMSProp | epoch: 029 | loss: 0.05903 - acc: 0.9827 -- iter: 1184/1707
[A[ATraining Step: 1550  | total loss: [1m[32m0.05501[0m[0m | time: 31.522s
[2K
| RMSProp | epoch: 029 | loss: 0.05501 - acc: 0.9845 -- iter: 1216/1707
[A[ATraining Step: 1551  | total loss: [1m[32m0.04959[0m[0m | time: 32.466s
[2K
| RMSProp | epoch: 029 | loss: 0.04959 - acc: 0.9860 -- iter: 1248/1707
[A[ATraining Step: 1552  | total loss: [1m[32m0.04598[0m[0m | time: 33.395s
[2K
| RMSProp | epoch: 029 | loss: 0.04598 - acc: 0.9874 -- iter: 1280/1707
[A[ATraining Step: 1553  | total loss: [1m[32m0.05732[0m[0m | time: 34.257s
[2K
| RMSProp | epoch: 029 | loss: 0.05732 - acc: 0.9824 -- iter: 1312/1707
[A[ATraining Step: 1554  | total loss: [1m[32m0.05327[0m[0m | time: 35.157s
[2K
| RMSProp | epoch: 029 | loss: 0.05327 - acc: 0.9842 -- iter: 1344/1707
[A[ATraining Step: 1555  | total loss: [1m[32m0.05687[0m[0m | time: 36.064s
[2K
| RMSProp | epoch: 029 | loss: 0.05687 - acc: 0.9826 -- iter: 1376/1707
[A[ATraining Step: 1556  | total loss: [1m[32m0.06831[0m[0m | time: 36.918s
[2K
| RMSProp | epoch: 029 | loss: 0.06831 - acc: 0.9812 -- iter: 1408/1707
[A[ATraining Step: 1557  | total loss: [1m[32m0.06459[0m[0m | time: 37.862s
[2K
| RMSProp | epoch: 029 | loss: 0.06459 - acc: 0.9831 -- iter: 1440/1707
[A[ATraining Step: 1558  | total loss: [1m[32m0.05863[0m[0m | time: 38.739s
[2K
| RMSProp | epoch: 029 | loss: 0.05863 - acc: 0.9848 -- iter: 1472/1707
[A[ATraining Step: 1559  | total loss: [1m[32m0.05326[0m[0m | time: 39.600s
[2K
| RMSProp | epoch: 029 | loss: 0.05326 - acc: 0.9863 -- iter: 1504/1707
[A[ATraining Step: 1560  | total loss: [1m[32m0.04809[0m[0m | time: 40.425s
[2K
| RMSProp | epoch: 029 | loss: 0.04809 - acc: 0.9877 -- iter: 1536/1707
[A[ATraining Step: 1561  | total loss: [1m[32m0.04355[0m[0m | time: 41.329s
[2K
| RMSProp | epoch: 029 | loss: 0.04355 - acc: 0.9889 -- iter: 1568/1707
[A[ATraining Step: 1562  | total loss: [1m[32m0.03945[0m[0m | time: 42.286s
[2K
| RMSProp | epoch: 029 | loss: 0.03945 - acc: 0.9900 -- iter: 1600/1707
[A[ATraining Step: 1563  | total loss: [1m[32m0.05708[0m[0m | time: 43.178s
[2K
| RMSProp | epoch: 029 | loss: 0.05708 - acc: 0.9879 -- iter: 1632/1707
[A[ATraining Step: 1564  | total loss: [1m[32m0.05691[0m[0m | time: 44.053s
[2K
| RMSProp | epoch: 029 | loss: 0.05691 - acc: 0.9860 -- iter: 1664/1707
[A[ATraining Step: 1565  | total loss: [1m[32m0.05158[0m[0m | time: 44.997s
[2K
| RMSProp | epoch: 029 | loss: 0.05158 - acc: 0.9874 -- iter: 1696/1707
[A[ATraining Step: 1566  | total loss: [1m[32m0.04656[0m[0m | time: 48.580s
[2K
| RMSProp | epoch: 029 | loss: 0.04656 - acc: 0.9887 | val_loss: 0.91808 - val_acc: 0.7921 -- iter: 1707/1707
--
Training Step: 1567  | total loss: [1m[32m0.04248[0m[0m | time: 0.921s
[2K
| RMSProp | epoch: 030 | loss: 0.04248 - acc: 0.9898 -- iter: 0032/1707
[A[ATraining Step: 1568  | total loss: [1m[32m0.03849[0m[0m | time: 1.873s
[2K
| RMSProp | epoch: 030 | loss: 0.03849 - acc: 0.9908 -- iter: 0064/1707
[A[ATraining Step: 1569  | total loss: [1m[32m0.03487[0m[0m | time: 2.751s
[2K
| RMSProp | epoch: 030 | loss: 0.03487 - acc: 0.9917 -- iter: 0096/1707
[A[ATraining Step: 1570  | total loss: [1m[32m0.03314[0m[0m | time: 3.648s
[2K
| RMSProp | epoch: 030 | loss: 0.03314 - acc: 0.9926 -- iter: 0128/1707
[A[ATraining Step: 1571  | total loss: [1m[32m0.04095[0m[0m | time: 4.543s
[2K
| RMSProp | epoch: 030 | loss: 0.04095 - acc: 0.9902 -- iter: 0160/1707
[A[ATraining Step: 1572  | total loss: [1m[32m0.06527[0m[0m | time: 5.462s
[2K
| RMSProp | epoch: 030 | loss: 0.06527 - acc: 0.9818 -- iter: 0192/1707
[A[ATraining Step: 1573  | total loss: [1m[32m0.06686[0m[0m | time: 6.402s
[2K
| RMSProp | epoch: 030 | loss: 0.06686 - acc: 0.9805 -- iter: 0224/1707
[A[ATraining Step: 1574  | total loss: [1m[32m0.06204[0m[0m | time: 7.254s
[2K
| RMSProp | epoch: 030 | loss: 0.06204 - acc: 0.9824 -- iter: 0256/1707
[A[ATraining Step: 1575  | total loss: [1m[32m0.05596[0m[0m | time: 8.134s
[2K
| RMSProp | epoch: 030 | loss: 0.05596 - acc: 0.9842 -- iter: 0288/1707
[A[ATraining Step: 1576  | total loss: [1m[32m0.05193[0m[0m | time: 9.020s
[2K
| RMSProp | epoch: 030 | loss: 0.05193 - acc: 0.9858 -- iter: 0320/1707
[A[ATraining Step: 1577  | total loss: [1m[32m0.04746[0m[0m | time: 9.897s
[2K
| RMSProp | epoch: 030 | loss: 0.04746 - acc: 0.9872 -- iter: 0352/1707
[A[ATraining Step: 1578  | total loss: [1m[32m0.04399[0m[0m | time: 10.795s
[2K
| RMSProp | epoch: 030 | loss: 0.04399 - acc: 0.9885 -- iter: 0384/1707
[A[ATraining Step: 1579  | total loss: [1m[32m0.03991[0m[0m | time: 11.660s
[2K
| RMSProp | epoch: 030 | loss: 0.03991 - acc: 0.9896 -- iter: 0416/1707
[A[ATraining Step: 1580  | total loss: [1m[32m0.03602[0m[0m | time: 12.544s
[2K
| RMSProp | epoch: 030 | loss: 0.03602 - acc: 0.9907 -- iter: 0448/1707
[A[ATraining Step: 1581  | total loss: [1m[32m0.03253[0m[0m | time: 13.450s
[2K
| RMSProp | epoch: 030 | loss: 0.03253 - acc: 0.9916 -- iter: 0480/1707
[A[ATraining Step: 1582  | total loss: [1m[32m0.02959[0m[0m | time: 14.343s
[2K
| RMSProp | epoch: 030 | loss: 0.02959 - acc: 0.9924 -- iter: 0512/1707
[A[ATraining Step: 1583  | total loss: [1m[32m0.02676[0m[0m | time: 15.229s
[2K
| RMSProp | epoch: 030 | loss: 0.02676 - acc: 0.9932 -- iter: 0544/1707
[A[ATraining Step: 1584  | total loss: [1m[32m0.02412[0m[0m | time: 16.082s
[2K
| RMSProp | epoch: 030 | loss: 0.02412 - acc: 0.9939 -- iter: 0576/1707
[A[ATraining Step: 1585  | total loss: [1m[32m0.02841[0m[0m | time: 16.975s
[2K
| RMSProp | epoch: 030 | loss: 0.02841 - acc: 0.9914 -- iter: 0608/1707
[A[ATraining Step: 1586  | total loss: [1m[32m0.03107[0m[0m | time: 17.875s
[2K
| RMSProp | epoch: 030 | loss: 0.03107 - acc: 0.9891 -- iter: 0640/1707
[A[ATraining Step: 1587  | total loss: [1m[32m0.02832[0m[0m | time: 18.768s
[2K
| RMSProp | epoch: 030 | loss: 0.02832 - acc: 0.9902 -- iter: 0672/1707
[A[ATraining Step: 1588  | total loss: [1m[32m0.03726[0m[0m | time: 19.691s
[2K
| RMSProp | epoch: 030 | loss: 0.03726 - acc: 0.9880 -- iter: 0704/1707
[A[ATraining Step: 1589  | total loss: [1m[32m0.03565[0m[0m | time: 20.599s
[2K
| RMSProp | epoch: 030 | loss: 0.03565 - acc: 0.9892 -- iter: 0736/1707
[A[ATraining Step: 1590  | total loss: [1m[32m0.03311[0m[0m | time: 21.468s
[2K
| RMSProp | epoch: 030 | loss: 0.03311 - acc: 0.9903 -- iter: 0768/1707
[A[ATraining Step: 1591  | total loss: [1m[32m0.03355[0m[0m | time: 22.365s
[2K
| RMSProp | epoch: 030 | loss: 0.03355 - acc: 0.9913 -- iter: 0800/1707
[A[ATraining Step: 1592  | total loss: [1m[32m0.03076[0m[0m | time: 23.241s
[2K
| RMSProp | epoch: 030 | loss: 0.03076 - acc: 0.9922 -- iter: 0832/1707
[A[ATraining Step: 1593  | total loss: [1m[32m0.02782[0m[0m | time: 24.118s
[2K
| RMSProp | epoch: 030 | loss: 0.02782 - acc: 0.9929 -- iter: 0864/1707
[A[ATraining Step: 1594  | total loss: [1m[32m0.02661[0m[0m | time: 24.467s
[2K
| RMSProp | epoch: 030 | loss: 0.02661 - acc: 0.9936 -- iter: 0896/1707
[A[ATraining Step: 1595  | total loss: [1m[32m0.02396[0m[0m | time: 24.875s
[2K
| RMSProp | epoch: 030 | loss: 0.02396 - acc: 0.9943 -- iter: 0928/1707
[A[ATraining Step: 1596  | total loss: [1m[32m0.02157[0m[0m | time: 25.767s
[2K
| RMSProp | epoch: 030 | loss: 0.02157 - acc: 0.9949 -- iter: 0960/1707
[A[ATraining Step: 1597  | total loss: [1m[32m0.04014[0m[0m | time: 26.639s
[2K
| RMSProp | epoch: 030 | loss: 0.04014 - acc: 0.9891 -- iter: 0992/1707
[A[ATraining Step: 1598  | total loss: [1m[32m0.06369[0m[0m | time: 27.525s
[2K
| RMSProp | epoch: 030 | loss: 0.06369 - acc: 0.9840 -- iter: 1024/1707
[A[ATraining Step: 1599  | total loss: [1m[32m0.05832[0m[0m | time: 28.423s
[2K
| RMSProp | epoch: 030 | loss: 0.05832 - acc: 0.9856 -- iter: 1056/1707
[A[ATraining Step: 1600  | total loss: [1m[32m0.05323[0m[0m | time: 32.030s
[2K
| RMSProp | epoch: 030 | loss: 0.05323 - acc: 0.9870 | val_loss: 1.07094 - val_acc: 0.7959 -- iter: 1088/1707
--
Training Step: 1601  | total loss: [1m[32m0.05889[0m[0m | time: 32.927s
[2K
| RMSProp | epoch: 030 | loss: 0.05889 - acc: 0.9852 -- iter: 1120/1707
[A[ATraining Step: 1602  | total loss: [1m[32m0.08984[0m[0m | time: 33.876s
[2K
| RMSProp | epoch: 030 | loss: 0.08984 - acc: 0.9773 -- iter: 1152/1707
[A[ATraining Step: 1603  | total loss: [1m[32m0.08516[0m[0m | time: 34.760s
[2K
| RMSProp | epoch: 030 | loss: 0.08516 - acc: 0.9796 -- iter: 1184/1707
[A[ATraining Step: 1604  | total loss: [1m[32m0.07790[0m[0m | time: 35.673s
[2K
| RMSProp | epoch: 030 | loss: 0.07790 - acc: 0.9816 -- iter: 1216/1707
[A[ATraining Step: 1605  | total loss: [1m[32m0.07072[0m[0m | time: 36.505s
[2K
| RMSProp | epoch: 030 | loss: 0.07072 - acc: 0.9834 -- iter: 1248/1707
[A[ATraining Step: 1606  | total loss: [1m[32m0.06438[0m[0m | time: 37.395s
[2K
| RMSProp | epoch: 030 | loss: 0.06438 - acc: 0.9851 -- iter: 1280/1707
[A[ATraining Step: 1607  | total loss: [1m[32m0.06819[0m[0m | time: 38.378s
[2K
| RMSProp | epoch: 030 | loss: 0.06819 - acc: 0.9835 -- iter: 1312/1707
[A[ATraining Step: 1608  | total loss: [1m[32m0.06771[0m[0m | time: 39.261s
[2K
| RMSProp | epoch: 030 | loss: 0.06771 - acc: 0.9820 -- iter: 1344/1707
[A[ATraining Step: 1609  | total loss: [1m[32m0.07556[0m[0m | time: 40.155s
[2K
| RMSProp | epoch: 030 | loss: 0.07556 - acc: 0.9775 -- iter: 1376/1707
[A[ATraining Step: 1610  | total loss: [1m[32m0.07248[0m[0m | time: 41.009s
[2K
| RMSProp | epoch: 030 | loss: 0.07248 - acc: 0.9798 -- iter: 1408/1707
[A[ATraining Step: 1611  | total loss: [1m[32m0.06913[0m[0m | time: 41.888s
[2K
| RMSProp | epoch: 030 | loss: 0.06913 - acc: 0.9787 -- iter: 1440/1707
[A[ATraining Step: 1612  | total loss: [1m[32m0.07734[0m[0m | time: 42.761s
[2K
| RMSProp | epoch: 030 | loss: 0.07734 - acc: 0.9777 -- iter: 1472/1707
[A[ATraining Step: 1613  | total loss: [1m[32m0.08167[0m[0m | time: 43.725s
[2K
| RMSProp | epoch: 030 | loss: 0.08167 - acc: 0.9768 -- iter: 1504/1707
[A[ATraining Step: 1614  | total loss: [1m[32m0.08345[0m[0m | time: 44.575s
[2K
| RMSProp | epoch: 030 | loss: 0.08345 - acc: 0.9729 -- iter: 1536/1707
[A[ATraining Step: 1615  | total loss: [1m[32m0.07615[0m[0m | time: 45.500s
[2K
| RMSProp | epoch: 030 | loss: 0.07615 - acc: 0.9756 -- iter: 1568/1707
[A[ATraining Step: 1616  | total loss: [1m[32m0.08312[0m[0m | time: 46.531s
[2K
| RMSProp | epoch: 030 | loss: 0.08312 - acc: 0.9718 -- iter: 1600/1707
[A[ATraining Step: 1617  | total loss: [1m[32m0.10039[0m[0m | time: 47.798s
[2K
| RMSProp | epoch: 030 | loss: 0.10039 - acc: 0.9621 -- iter: 1632/1707
[A[ATraining Step: 1618  | total loss: [1m[32m0.15003[0m[0m | time: 49.111s
[2K
| RMSProp | epoch: 030 | loss: 0.15003 - acc: 0.9596 -- iter: 1664/1707
[A[ATraining Step: 1619  | total loss: [1m[32m0.15324[0m[0m | time: 50.046s
[2K
| RMSProp | epoch: 030 | loss: 0.15324 - acc: 0.9574 -- iter: 1696/1707
[A[ATraining Step: 1620  | total loss: [1m[32m0.14170[0m[0m | time: 53.538s
[2K
| RMSProp | epoch: 030 | loss: 0.14170 - acc: 0.9617 | val_loss: 0.71550 - val_acc: 0.7753 -- iter: 1707/1707
--
Validation AUC:0.8692291326856252
Validation AUPRC:0.8471078622258692
Test AUC:0.8784928739759847
Test AUPRC:0.8614004353799867
BestTestF1Score	0.81	0.59	0.79	0.76	0.87	233	75	191	35	0.25
BestTestMCCScore	0.81	0.59	0.79	0.76	0.87	233	75	191	35	0.25
BestTestAccuracyScore	0.79	0.59	0.79	0.81	0.76	205	47	219	63	0.8
BestValidationF1Score	0.78	0.58	0.78	0.71	0.88	210	87	208	29	0.25
BestValidationMCC	0.78	0.58	0.78	0.71	0.88	210	87	208	29	0.25
BestValidationAccuracy	0.77	0.58	0.79	0.78	0.75	180	51	244	59	0.8
TestPredictions (Threshold:0.25)
CHEMBL374517,TP,ACT,1.0	CHEMBL160566,TN,INACT,0.019999999552965164	CHEMBL522905,TP,ACT,1.0	CHEMBL28787,FN,ACT,0.20000000298023224	CHEMBL1945646,TN,INACT,0.0	CHEMBL409447,TP,ACT,0.9900000095367432	CHEMBL213356,TP,ACT,0.9900000095367432	CHEMBL1684372,TN,INACT,0.10999999940395355	CHEMBL542887,TN,INACT,0.03999999910593033	CHEMBL484274,TN,INACT,0.0	CHEMBL90002,TP,ACT,1.0	CHEMBL406845,TP,ACT,0.5199999809265137	CHEMBL2337371,TN,INACT,0.0	CHEMBL248286,TP,ACT,0.9900000095367432	CHEMBL52513,FN,ACT,0.03999999910593033	CHEMBL160105,FN,ACT,0.15000000596046448	CHEMBL408292,TP,ACT,0.9900000095367432	CHEMBL511451,TN,INACT,0.009999999776482582	CHEMBL313798,TP,ACT,0.9599999785423279	CHEMBL1093100,TN,INACT,0.10000000149011612	CHEMBL398243,TN,INACT,0.0	CHEMBL212040,TP,ACT,1.0	CHEMBL1241482,TN,INACT,0.07999999821186066	CHEMBL1171638,TN,INACT,0.009999999776482582	CHEMBL30157,FN,ACT,0.20999999344348907	CHEMBL56964,TN,INACT,0.18000000715255737	CHEMBL1085995,TP,ACT,1.0	CHEMBL230011,TP,ACT,1.0	CHEMBL335628,FP,INACT,0.9599999785423279	CHEMBL2029697,FP,INACT,0.3700000047683716	CHEMBL1916949,TN,INACT,0.0	CHEMBL1767126,TN,INACT,0.0	CHEMBL10,FN,ACT,0.0	CHEMBL527026,FP,INACT,0.49000000953674316	CHEMBL441643,FP,INACT,0.699999988079071	CHEMBL68871,TP,ACT,1.0	CHEMBL266540,TN,INACT,0.0	CHEMBL3086538,TP,ACT,0.44999998807907104	CHEMBL3787112,TP,ACT,0.9900000095367432	CHEMBL311135,TN,INACT,0.0	CHEMBL538528,FP,INACT,0.9900000095367432	CHEMBL423321,TP,ACT,1.0	CHEMBL109157,TP,ACT,1.0	CHEMBL85976,TP,ACT,1.0	CHEMBL1080299,TP,ACT,1.0	CHEMBL272609,TP,ACT,0.9900000095367432	CHEMBL71884,TN,INACT,0.11999999731779099	CHEMBL1081090,TP,ACT,1.0	CHEMBL1836844,TP,ACT,1.0	CHEMBL376298,TP,ACT,0.9399999976158142	CHEMBL280546,TP,ACT,1.0	CHEMBL566362,TP,ACT,1.0	CHEMBL1916897,TP,ACT,0.9900000095367432	CHEMBL560278,TN,INACT,0.0	CHEMBL591252,TN,INACT,0.20999999344348907	CHEMBL86230,TP,ACT,1.0	CHEMBL414013,TN,INACT,0.05999999865889549	CHEMBL2029519,TN,INACT,0.0	CHEMBL525893,TP,ACT,0.9700000286102295	CHEMBL569882,TP,ACT,0.9900000095367432	CHEMBL102765,FP,INACT,0.30000001192092896	CHEMBL1087127,TP,ACT,1.0	CHEMBL87102,TP,ACT,0.9900000095367432	CHEMBL1271533,TP,ACT,0.9399999976158142	CHEMBL279193,TN,INACT,0.009999999776482582	CHEMBL104264,FP,INACT,0.5699999928474426	CHEMBL1821888,TN,INACT,0.12999999523162842	CHEMBL501368,TN,INACT,0.0	CHEMBL68888,TP,ACT,1.0	CHEMBL1083092,FN,ACT,0.05999999865889549	CHEMBL295528,TP,ACT,1.0	CHEMBL563674,TN,INACT,0.009999999776482582	CHEMBL110394,TP,ACT,0.7300000190734863	CHEMBL103838,TN,INACT,0.0	CHEMBL413761,TP,ACT,0.9800000190734863	CHEMBL1641996,FP,INACT,0.9800000190734863	CHEMBL551663,TN,INACT,0.019999999552965164	CHEMBL409867,TP,ACT,1.0	CHEMBL270777,TP,ACT,0.9800000190734863	CHEMBL584044,FN,ACT,0.20999999344348907	CHEMBL334539,TN,INACT,0.019999999552965164	CHEMBL563948,TN,INACT,0.0	CHEMBL3360318,TP,ACT,0.8899999856948853	CHEMBL523559,TP,ACT,0.9900000095367432	CHEMBL330781,FN,ACT,0.009999999776482582	CHEMBL3421963,FP,INACT,0.5099999904632568	CHEMBL84624,TP,ACT,1.0	CHEMBL2392223,TN,INACT,0.009999999776482582	CHEMBL293712,TP,ACT,1.0	CHEMBL470851,TN,INACT,0.019999999552965164	CHEMBL26147,TP,ACT,0.9900000095367432	CHEMBL2029693,FP,INACT,0.9800000190734863	CHEMBL149603,TN,INACT,0.0	CHEMBL212668,TP,ACT,1.0	CHEMBL267213,FP,INACT,0.9900000095367432	CHEMBL2441282,TP,ACT,0.9900000095367432	CHEMBL606459,TP,ACT,1.0	CHEMBL452812,TN,INACT,0.23000000417232513	CHEMBL463323,TP,ACT,1.0	CHEMBL1767294,TN,INACT,0.10999999940395355	CHEMBL55360,TN,INACT,0.10000000149011612	CHEMBL381203,TP,ACT,1.0	CHEMBL506247,TP,ACT,0.30000001192092896	CHEMBL1688214,TN,INACT,0.0	CHEMBL283275,TP,ACT,1.0	CHEMBL2333603,TP,ACT,0.7900000214576721	CHEMBL56081,TN,INACT,0.0	CHEMBL2088106,TN,INACT,0.07000000029802322	CHEMBL269936,TP,ACT,1.0	CHEMBL292930,TP,ACT,1.0	CHEMBL1090356,TP,ACT,0.9300000071525574	CHEMBL51314,TP,ACT,0.3199999928474426	CHEMBL1790805,TN,INACT,0.019999999552965164	CHEMBL271375,TP,ACT,1.0	CHEMBL556746,FP,INACT,0.9900000095367432	CHEMBL2047243,TN,INACT,0.0	CHEMBL212865,TP,ACT,0.9900000095367432	CHEMBL1171273,TN,INACT,0.03999999910593033	CHEMBL1161236,TN,INACT,0.05000000074505806	CHEMBL1235213,TN,INACT,0.23999999463558197	CHEMBL403522,TP,ACT,1.0	CHEMBL2437300,TN,INACT,0.029999999329447746	CHEMBL568100,TP,ACT,1.0	CHEMBL1762119,TN,INACT,0.15000000596046448	CHEMBL374985,FN,ACT,0.15000000596046448	CHEMBL300853,TP,ACT,1.0	CHEMBL1958317,TN,INACT,0.0	CHEMBL1821886,TN,INACT,0.17000000178813934	CHEMBL401038,TN,INACT,0.1899999976158142	CHEMBL474807,TN,INACT,0.20999999344348907	CHEMBL386167,TP,ACT,1.0	CHEMBL282741,TP,ACT,1.0	CHEMBL3797839,TN,INACT,0.0	CHEMBL407005,TP,ACT,1.0	CHEMBL314146,TN,INACT,0.009999999776482582	CHEMBL112263,FN,ACT,0.07000000029802322	CHEMBL1830259,TN,INACT,0.0	CHEMBL450383,TN,INACT,0.0	CHEMBL1082693,TP,ACT,0.9200000166893005	CHEMBL2322141,TN,INACT,0.009999999776482582	CHEMBL200424,TP,ACT,0.9399999976158142	CHEMBL2163624,FP,INACT,0.9800000190734863	CHEMBL3797559,FP,INACT,0.6700000166893005	CHEMBL328034,FP,INACT,0.9200000166893005	CHEMBL212964,TP,ACT,1.0	CHEMBL3143230,FP,INACT,0.8700000047683716	CHEMBL141247,FN,ACT,0.019999999552965164	CHEMBL26016,TP,ACT,1.0	CHEMBL110732,TP,ACT,1.0	CHEMBL315272,TP,ACT,1.0	CHEMBL379849,FP,INACT,0.25999999046325684	CHEMBL3659984,FP,INACT,0.47999998927116394	CHEMBL2029511,FP,INACT,0.9700000286102295	CHEMBL291313,TN,INACT,0.019999999552965164	CHEMBL1287914,TN,INACT,0.0	CHEMBL324842,TN,INACT,0.029999999329447746	CHEMBL1095130,TN,INACT,0.0	CHEMBL309103,TP,ACT,1.0	CHEMBL314627,TP,ACT,1.0	CHEMBL554,FP,INACT,1.0	CHEMBL2312652,TP,ACT,0.9599999785423279	CHEMBL193966,FP,INACT,0.6100000143051147	CHEMBL236384,TN,INACT,0.1899999976158142	CHEMBL131661,TP,ACT,1.0	CHEMBL2283258,TN,INACT,0.029999999329447746	CHEMBL211804,TP,ACT,0.9599999785423279	CHEMBL259850,TN,INACT,0.019999999552965164	CHEMBL216448,TP,ACT,0.9900000095367432	CHEMBL84808,TP,ACT,1.0	CHEMBL2029513,TN,INACT,0.07000000029802322	CHEMBL1683304,FP,INACT,0.9599999785423279	CHEMBL127500,TP,ACT,1.0	CHEMBL261174,TP,ACT,0.9700000286102295	CHEMBL312451,TN,INACT,0.07999999821186066	CHEMBL122721,TN,INACT,0.009999999776482582	CHEMBL1688208,TN,INACT,0.05999999865889549	CHEMBL2017557,TP,ACT,1.0	CHEMBL1241859,TN,INACT,0.0	CHEMBL271101,TP,ACT,1.0	CHEMBL367442,TN,INACT,0.0	CHEMBL370266,TP,ACT,1.0	CHEMBL2087874,TP,ACT,0.9900000095367432	CHEMBL106654,TP,ACT,0.3100000023841858	CHEMBL568101,TP,ACT,0.7699999809265137	CHEMBL311740,FP,INACT,0.7200000286102295	CHEMBL212143,TP,ACT,1.0	CHEMBL59042,FN,ACT,0.07999999821186066	CHEMBL1642269,TN,INACT,0.029999999329447746	CHEMBL3623844,TN,INACT,0.03999999910593033	CHEMBL3182647,TP,ACT,0.9700000286102295	CHEMBL592026,TP,ACT,0.6899999976158142	CHEMBL1829273,TN,INACT,0.0	CHEMBL348146,FP,INACT,0.3799999952316284	CHEMBL160207,TN,INACT,0.019999999552965164	CHEMBL56319,TN,INACT,0.0	CHEMBL217090,FN,ACT,0.029999999329447746	CHEMBL154260,TN,INACT,0.029999999329447746	CHEMBL115166,TP,ACT,1.0	CHEMBL2392355,TN,INACT,0.0	CHEMBL3426304,TP,ACT,1.0	CHEMBL592224,TN,INACT,0.019999999552965164	CHEMBL2441285,TP,ACT,1.0	CHEMBL457180,TN,INACT,0.029999999329447746	CHEMBL437754,TP,ACT,1.0	CHEMBL186568,TP,ACT,1.0	CHEMBL271760,TP,ACT,0.9800000190734863	CHEMBL409914,TP,ACT,1.0	CHEMBL1242207,TN,INACT,0.0	CHEMBL550623,TN,INACT,0.05000000074505806	CHEMBL592267,TP,ACT,1.0	CHEMBL354496,TN,INACT,0.009999999776482582	CHEMBL85295,TP,ACT,1.0	CHEMBL69638,TP,ACT,0.25	CHEMBL8223,TN,INACT,0.11999999731779099	CHEMBL45651,TP,ACT,1.0	CHEMBL1270522,TN,INACT,0.1599999964237213	CHEMBL3086537,TP,ACT,1.0	CHEMBL513336,TN,INACT,0.0	CHEMBL1944923,TN,INACT,0.10999999940395355	CHEMBL558925,TN,INACT,0.0	CHEMBL589503,TN,INACT,0.11999999731779099	CHEMBL3426309,FN,ACT,0.029999999329447746	CHEMBL99687,FP,INACT,1.0	CHEMBL576982,TP,ACT,1.0	CHEMBL115421,TN,INACT,0.029999999329447746	CHEMBL270692,TP,ACT,0.9900000095367432	CHEMBL272850,TP,ACT,1.0	CHEMBL66102,TP,ACT,1.0	CHEMBL214617,FN,ACT,0.009999999776482582	CHEMBL220874,TP,ACT,1.0	CHEMBL110783,TP,ACT,1.0	CHEMBL257858,TP,ACT,1.0	CHEMBL457390,TN,INACT,0.03999999910593033	CHEMBL483298,FP,INACT,0.9900000095367432	CHEMBL565884,FN,ACT,0.1599999964237213	CHEMBL82404,TP,ACT,0.3400000035762787	CHEMBL497350,FN,ACT,0.1899999976158142	CHEMBL303195,TP,ACT,1.0	CHEMBL81793,TP,ACT,1.0	CHEMBL381932,TN,INACT,0.0	CHEMBL2042135,TP,ACT,0.9800000190734863	CHEMBL1790311,FP,INACT,1.0	CHEMBL31965,FN,ACT,0.23999999463558197	CHEMBL87325,TN,INACT,0.009999999776482582	CHEMBL567880,TP,ACT,1.0	CHEMBL321869,TP,ACT,1.0	CHEMBL2426288,TN,INACT,0.009999999776482582	CHEMBL2437475,FP,INACT,0.8100000023841858	CHEMBL169757,TN,INACT,0.03999999910593033	CHEMBL2381601,FN,ACT,0.0	CHEMBL3661093,TN,INACT,0.0	CHEMBL2333595,TP,ACT,1.0	CHEMBL385172,TP,ACT,1.0	CHEMBL1242753,FP,INACT,0.7900000214576721	CHEMBL323015,FP,INACT,0.9599999785423279	CHEMBL492828,TN,INACT,0.009999999776482582	CHEMBL1933751,FP,INACT,1.0	CHEMBL208994,TP,ACT,1.0	CHEMBL592507,TP,ACT,1.0	CHEMBL1087524,TP,ACT,1.0	CHEMBL497454,TN,INACT,0.0	CHEMBL590521,FP,INACT,0.8100000023841858	CHEMBL499067,TN,INACT,0.05999999865889549	CHEMBL3780985,TN,INACT,0.019999999552965164	CHEMBL302281,TP,ACT,1.0	CHEMBL2088258,FP,INACT,0.8500000238418579	CHEMBL214556,TP,ACT,1.0	CHEMBL280998,TN,INACT,0.0	CHEMBL405008,FP,INACT,0.9300000071525574	CHEMBL374079,TP,ACT,0.9900000095367432	CHEMBL2403367,TP,ACT,0.949999988079071	CHEMBL589529,TN,INACT,0.12999999523162842	CHEMBL558859,TN,INACT,0.07000000029802322	CHEMBL406685,TP,ACT,1.0	CHEMBL97162,FN,ACT,0.029999999329447746	CHEMBL591325,TP,ACT,1.0	CHEMBL429430,TP,ACT,1.0	CHEMBL567886,TP,ACT,1.0	CHEMBL191632,TN,INACT,0.03999999910593033	CHEMBL3799345,TN,INACT,0.019999999552965164	CHEMBL1289926,FN,ACT,0.009999999776482582	CHEMBL1240703,TP,ACT,0.9800000190734863	CHEMBL601096,TP,ACT,0.9900000095367432	CHEMBL559683,TN,INACT,0.0	CHEMBL459044,TP,ACT,0.8500000238418579	CHEMBL2163623,FP,INACT,0.9800000190734863	CHEMBL3680492,FP,INACT,1.0	CHEMBL256101,TP,ACT,1.0	CHEMBL2029520,TN,INACT,0.0	CHEMBL1642270,TN,INACT,0.05000000074505806	CHEMBL2403376,TP,ACT,1.0	CHEMBL269871,TP,ACT,0.949999988079071	CHEMBL1242033,FP,INACT,0.9100000262260437	CHEMBL76642,TN,INACT,0.019999999552965164	CHEMBL223873,TP,ACT,0.9200000166893005	CHEMBL247667,TP,ACT,1.0	CHEMBL1241862,TN,INACT,0.05000000074505806	CHEMBL2172315,TP,ACT,0.41999998688697815	CHEMBL27199,TP,ACT,0.9200000166893005	CHEMBL211283,TP,ACT,0.9900000095367432	CHEMBL107183,TP,ACT,0.9900000095367432	CHEMBL3421980,FP,INACT,1.0	CHEMBL3218000,FP,INACT,0.3100000023841858	CHEMBL1241390,TN,INACT,0.009999999776482582	CHEMBL226813,TN,INACT,0.0	CHEMBL433437,TP,ACT,1.0	CHEMBL418580,TP,ACT,1.0	CHEMBL1767275,TN,INACT,0.0	CHEMBL490570,TN,INACT,0.019999999552965164	CHEMBL474015,TN,INACT,0.03999999910593033	CHEMBL466496,TN,INACT,0.009999999776482582	CHEMBL64459,TN,INACT,0.009999999776482582	CHEMBL1084451,TP,ACT,1.0	CHEMBL67052,TP,ACT,0.9900000095367432	CHEMBL432089,TP,ACT,1.0	CHEMBL504416,TN,INACT,0.009999999776482582	CHEMBL77262,FP,INACT,0.8299999833106995	CHEMBL67655,FP,INACT,0.9800000190734863	CHEMBL114263,TP,ACT,0.3700000047683716	CHEMBL1765781,TP,ACT,1.0	CHEMBL212632,TP,ACT,0.9900000095367432	CHEMBL346901,TN,INACT,0.20000000298023224	CHEMBL385055,TP,ACT,0.9900000095367432	CHEMBL248079,TP,ACT,0.27000001072883606	CHEMBL162038,TP,ACT,0.9399999976158142	CHEMBL1836837,TP,ACT,1.0	CHEMBL926,FN,ACT,0.17000000178813934	CHEMBL1922210,TN,INACT,0.0	CHEMBL488899,FP,INACT,0.9900000095367432	CHEMBL214402,TP,ACT,0.9599999785423279	CHEMBL247480,TP,ACT,0.9900000095367432	CHEMBL86694,TP,ACT,1.0	CHEMBL215969,TP,ACT,1.0	CHEMBL324153,TP,ACT,0.9800000190734863	CHEMBL568543,FN,ACT,0.009999999776482582	CHEMBL1254286,TN,INACT,0.0	CHEMBL219103,TP,ACT,0.9900000095367432	CHEMBL485878,FP,INACT,0.9900000095367432	CHEMBL456760,TN,INACT,0.0	CHEMBL1933736,FP,INACT,0.25	CHEMBL1642280,FP,INACT,0.9200000166893005	CHEMBL351638,FP,INACT,0.8799999952316284	CHEMBL1088028,TP,ACT,1.0	CHEMBL523059,TN,INACT,0.009999999776482582	CHEMBL2348180,TN,INACT,0.15000000596046448	CHEMBL1085511,TP,ACT,0.6499999761581421	CHEMBL1276179,FN,ACT,0.07999999821186066	CHEMBL286989,TP,ACT,0.9900000095367432	CHEMBL84846,TP,ACT,0.9900000095367432	CHEMBL281685,TP,ACT,0.9599999785423279	CHEMBL318248,TN,INACT,0.009999999776482582	CHEMBL374009,TP,ACT,0.44999998807907104	CHEMBL29462,FN,ACT,0.23999999463558197	CHEMBL216646,TN,INACT,0.12999999523162842	CHEMBL321312,TN,INACT,0.0	CHEMBL428182,TP,ACT,0.25	CHEMBL287175,TP,ACT,1.0	CHEMBL379729,TP,ACT,1.0	CHEMBL1173789,TN,INACT,0.009999999776482582	CHEMBL485502,TN,INACT,0.0	CHEMBL1650551,TP,ACT,0.9900000095367432	CHEMBL325949,FP,INACT,0.7699999809265137	CHEMBL386661,TP,ACT,0.9300000071525574	CHEMBL458333,TP,ACT,1.0	CHEMBL1076478,TP,ACT,0.9900000095367432	CHEMBL1241583,TN,INACT,0.0	CHEMBL300974,TN,INACT,0.15000000596046448	CHEMBL383899,TP,ACT,0.8199999928474426	CHEMBL88326,TN,INACT,0.03999999910593033	CHEMBL19598,TN,INACT,0.1599999964237213	CHEMBL466154,TN,INACT,0.009999999776482582	CHEMBL603418,FN,ACT,0.17000000178813934	CHEMBL449216,FP,INACT,0.5299999713897705	CHEMBL271372,TP,ACT,1.0	CHEMBL376475,TP,ACT,0.9900000095367432	CHEMBL28864,FN,ACT,0.07000000029802322	CHEMBL53898,TN,INACT,0.019999999552965164	CHEMBL509435,FP,INACT,0.6000000238418579	CHEMBL29723,TP,ACT,0.9800000190734863	CHEMBL279003,TN,INACT,0.12999999523162842	CHEMBL410840,FP,INACT,1.0	CHEMBL324399,FP,INACT,0.9900000095367432	CHEMBL263769,TP,ACT,0.5899999737739563	CHEMBL2029691,FP,INACT,0.9700000286102295	CHEMBL456113,TN,INACT,0.0	CHEMBL68104,TP,ACT,1.0	CHEMBL85920,TP,ACT,1.0	CHEMBL384822,TP,ACT,0.28999999165534973	CHEMBL272673,TP,ACT,1.0	CHEMBL1642266,TN,INACT,0.07999999821186066	CHEMBL100670,TN,INACT,0.0	CHEMBL3628817,FP,INACT,1.0	CHEMBL3621496,TP,ACT,0.9800000190734863	CHEMBL271154,TP,ACT,0.9900000095367432	CHEMBL1271480,TP,ACT,0.9800000190734863	CHEMBL494821,TP,ACT,0.9800000190734863	CHEMBL80030,TN,INACT,0.0	CHEMBL1779746,TN,INACT,0.0	CHEMBL1160317,TN,INACT,0.0	CHEMBL1910753,FP,INACT,0.9100000262260437	CHEMBL313500,TN,INACT,0.14000000059604645	CHEMBL347537,TN,INACT,0.009999999776482582	CHEMBL1830266,TN,INACT,0.0	CHEMBL302140,TP,ACT,1.0	CHEMBL328623,TN,INACT,0.0	CHEMBL1784649,TN,INACT,0.23999999463558197	CHEMBL114816,TP,ACT,1.0	CHEMBL27532,TP,ACT,1.0	CHEMBL77070,TN,INACT,0.23999999463558197	CHEMBL2163608,FP,INACT,0.4699999988079071	CHEMBL297278,TP,ACT,1.0	CHEMBL437502,TP,ACT,1.0	CHEMBL111443,TN,INACT,0.009999999776482582	CHEMBL2382014,TN,INACT,0.0	CHEMBL337454,TN,INACT,0.0	CHEMBL308134,TN,INACT,0.07999999821186066	CHEMBL7699,TN,INACT,0.029999999329447746	CHEMBL461139,FN,ACT,0.05000000074505806	CHEMBL91829,TP,ACT,0.4399999976158142	CHEMBL1076473,TP,ACT,0.9900000095367432	CHEMBL3421978,FP,INACT,0.8399999737739563	CHEMBL3237857,TN,INACT,0.029999999329447746	CHEMBL1221415,TN,INACT,0.07000000029802322	CHEMBL207333,TP,ACT,0.3199999928474426	CHEMBL2348181,TN,INACT,0.019999999552965164	CHEMBL557456,TN,INACT,0.0	CHEMBL77676,TP,ACT,0.9800000190734863	CHEMBL3426891,TP,ACT,0.9599999785423279	CHEMBL457191,TN,INACT,0.0	CHEMBL1270996,TP,ACT,1.0	CHEMBL29858,TP,ACT,1.0	CHEMBL233965,FN,ACT,0.23000000417232513	CHEMBL487526,TN,INACT,0.20999999344348907	CHEMBL2381116,TN,INACT,0.14000000059604645	CHEMBL386051,FN,ACT,0.1899999976158142	CHEMBL1916891,TP,ACT,0.9900000095367432	CHEMBL233540,TP,ACT,0.8199999928474426	CHEMBL156797,TN,INACT,0.029999999329447746	CHEMBL77869,TN,INACT,0.009999999776482582	CHEMBL69129,TP,ACT,0.8700000047683716	CHEMBL110220,TP,ACT,1.0	CHEMBL232148,TN,INACT,0.009999999776482582	CHEMBL1270795,TP,ACT,0.7900000214576721	CHEMBL3086534,TP,ACT,0.9900000095367432	CHEMBL261143,TN,INACT,0.019999999552965164	CHEMBL240431,TP,ACT,1.0	CHEMBL56697,FP,INACT,0.9200000166893005	CHEMBL395666,TP,ACT,0.9800000190734863	CHEMBL2042136,FP,INACT,0.9800000190734863	CHEMBL1242845,TN,INACT,0.23999999463558197	CHEMBL1172602,TN,INACT,0.0	CHEMBL84877,TP,ACT,0.9700000286102295	CHEMBL1242032,TN,INACT,0.019999999552965164	CHEMBL408849,TP,ACT,1.0	CHEMBL2022711,TP,ACT,0.49000000953674316	CHEMBL438610,TN,INACT,0.009999999776482582	CHEMBL407063,TP,ACT,1.0	CHEMBL939,TP,ACT,1.0	CHEMBL27004,TP,ACT,0.9900000095367432	CHEMBL2087875,TP,ACT,0.7300000190734863	CHEMBL69863,TN,INACT,0.0	CHEMBL469776,TN,INACT,0.0	CHEMBL313384,TP,ACT,1.0	CHEMBL45149,FP,INACT,0.6700000166893005	CHEMBL3237858,TN,INACT,0.03999999910593033	CHEMBL144785,TN,INACT,0.0	CHEMBL726,FP,INACT,0.9900000095367432	CHEMBL95477,TN,INACT,0.23999999463558197	CHEMBL1076200,TP,ACT,1.0	CHEMBL303244,TP,ACT,1.0	CHEMBL375581,TP,ACT,0.9900000095367432	CHEMBL1642294,TN,INACT,0.0	CHEMBL94581,TN,INACT,0.0	CHEMBL318485,TN,INACT,0.009999999776482582	CHEMBL83,FN,ACT,0.03999999910593033	CHEMBL239591,TP,ACT,1.0	CHEMBL165751,FP,INACT,0.3799999952316284	CHEMBL409103,TP,ACT,1.0	CHEMBL1630578,TN,INACT,0.17000000178813934	CHEMBL462228,TP,ACT,0.8299999833106995	CHEMBL1830258,TN,INACT,0.0	CHEMBL3632717,TP,ACT,1.0	CHEMBL102362,TP,ACT,1.0	CHEMBL293913,TN,INACT,0.0	CHEMBL2337367,TN,INACT,0.0	CHEMBL130871,FP,INACT,0.7300000190734863	CHEMBL478629,TP,ACT,0.9900000095367432	CHEMBL108907,TP,ACT,1.0	CHEMBL306012,TP,ACT,0.25	CHEMBL479835,FP,INACT,0.7799999713897705	CHEMBL74645,TN,INACT,0.009999999776482582	CHEMBL50913,TP,ACT,0.9900000095367432	CHEMBL104,TN,INACT,0.10000000149011612	CHEMBL3596524,TN,INACT,0.009999999776482582	CHEMBL342280,FP,INACT,0.9800000190734863	CHEMBL1076195,TP,ACT,1.0	CHEMBL411163,FP,INACT,0.7200000286102295	CHEMBL442,FN,ACT,0.1899999976158142	CHEMBL115519,TN,INACT,0.009999999776482582	CHEMBL15887,TN,INACT,0.019999999552965164	CHEMBL3659983,FP,INACT,1.0	CHEMBL1836808,TP,ACT,1.0	CHEMBL318461,FP,INACT,0.6200000047683716	CHEMBL395080,TN,INACT,0.23999999463558197	CHEMBL337253,TN,INACT,0.0	CHEMBL316009,TN,INACT,0.009999999776482582	CHEMBL258202,FP,INACT,0.9800000190734863	CHEMBL2064388,FP,INACT,0.9800000190734863	CHEMBL3633929,TP,ACT,0.9800000190734863	CHEMBL305249,TP,ACT,0.9700000286102295	CHEMBL1084453,TP,ACT,1.0	CHEMBL3680464,FP,INACT,1.0	CHEMBL212948,FN,ACT,0.17000000178813934	CHEMBL409734,TP,ACT,1.0	CHEMBL310726,FP,INACT,0.7099999785423279	CHEMBL1083091,FN,ACT,0.12999999523162842	CHEMBL50,TN,INACT,0.009999999776482582	CHEMBL83721,TP,ACT,0.8999999761581421	CHEMBL154822,TN,INACT,0.05000000074505806	CHEMBL103464,TN,INACT,0.0	CHEMBL164429,TP,ACT,0.3199999928474426	CHEMBL109625,TN,INACT,0.05999999865889549	CHEMBL195437,TN,INACT,0.0	CHEMBL1242031,TN,INACT,0.009999999776482582	CHEMBL2147366,FP,INACT,0.5400000214576721	CHEMBL29564,TP,ACT,0.36000001430511475	CHEMBL340977,TN,INACT,0.0	CHEMBL221959,FN,ACT,0.009999999776482582	CHEMBL310193,FP,INACT,0.7799999713897705	CHEMBL3786567,TP,ACT,0.38999998569488525	CHEMBL49707,TP,ACT,1.0	CHEMBL2088099,FP,INACT,0.9900000095367432	CHEMBL102047,FP,INACT,0.8399999737739563	CHEMBL2031893,TP,ACT,1.0	

