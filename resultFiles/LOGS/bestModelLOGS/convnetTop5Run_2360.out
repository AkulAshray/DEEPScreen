CNNModel CHEMBL4054 adam 0.001 30 256 0 0.6 False True
Number of active compounds :	104
Number of inactive compounds :	104
---------------------------------
Run id: CNNModel_CHEMBL4054_adam_0.001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4054_adam_0.001_30_256_0.6_True/
---------------------------------
Training samples: 127
Validation samples: 40
--
Training Step: 1  | time: 1.686s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/127
[A[ATraining Step: 2  | total loss: [1m[32m0.62427[0m[0m | time: 2.856s
[2K
| Adam | epoch: 001 | loss: 0.62427 - acc: 0.3094 -- iter: 064/127
[A[ATraining Step: 3  | total loss: [1m[32m0.68020[0m[0m | time: 4.001s
[2K
| Adam | epoch: 001 | loss: 0.68020 - acc: 0.4909 -- iter: 096/127
[A[ATraining Step: 4  | total loss: [1m[32m0.69103[0m[0m | time: 6.261s
[2K
| Adam | epoch: 001 | loss: 0.69103 - acc: 0.4977 | val_loss: 0.69039 - val_acc: 0.5750 -- iter: 127/127
--
Training Step: 5  | total loss: [1m[32m0.69391[0m[0m | time: 1.160s
[2K
| Adam | epoch: 002 | loss: 0.69391 - acc: 0.4881 -- iter: 032/127
[A[ATraining Step: 6  | total loss: [1m[32m0.69387[0m[0m | time: 2.289s
[2K
| Adam | epoch: 002 | loss: 0.69387 - acc: 0.4854 -- iter: 064/127
[A[ATraining Step: 7  | total loss: [1m[32m0.69248[0m[0m | time: 3.215s
[2K
| Adam | epoch: 002 | loss: 0.69248 - acc: 0.5317 -- iter: 096/127
[A[ATraining Step: 8  | total loss: [1m[32m0.69277[0m[0m | time: 5.272s
[2K
| Adam | epoch: 002 | loss: 0.69277 - acc: 0.5139 | val_loss: 0.69052 - val_acc: 0.5750 -- iter: 127/127
--
Training Step: 9  | total loss: [1m[32m0.69347[0m[0m | time: 1.113s
[2K
| Adam | epoch: 003 | loss: 0.69347 - acc: 0.4900 -- iter: 032/127
[A[ATraining Step: 10  | total loss: [1m[32m0.69398[0m[0m | time: 2.146s
[2K
| Adam | epoch: 003 | loss: 0.69398 - acc: 0.4708 -- iter: 064/127
[A[ATraining Step: 11  | total loss: [1m[32m0.69415[0m[0m | time: 3.334s
[2K
| Adam | epoch: 003 | loss: 0.69415 - acc: 0.4617 -- iter: 096/127
[A[ATraining Step: 12  | total loss: [1m[32m0.69208[0m[0m | time: 5.587s
[2K
| Adam | epoch: 003 | loss: 0.69208 - acc: 0.5493 | val_loss: 0.68973 - val_acc: 0.5750 -- iter: 127/127
--
Training Step: 13  | total loss: [1m[32m0.69120[0m[0m | time: 1.314s
[2K
| Adam | epoch: 004 | loss: 0.69120 - acc: 0.5683 -- iter: 032/127
[A[ATraining Step: 14  | total loss: [1m[32m0.69132[0m[0m | time: 2.560s
[2K
| Adam | epoch: 004 | loss: 0.69132 - acc: 0.5532 -- iter: 064/127
[A[ATraining Step: 15  | total loss: [1m[32m0.69233[0m[0m | time: 3.519s
[2K
| Adam | epoch: 004 | loss: 0.69233 - acc: 0.5260 -- iter: 096/127
[A[ATraining Step: 16  | total loss: [1m[32m0.69298[0m[0m | time: 5.517s
[2K
| Adam | epoch: 004 | loss: 0.69298 - acc: 0.5102 | val_loss: 0.68698 - val_acc: 0.5750 -- iter: 127/127
--
Training Step: 17  | total loss: [1m[32m0.69340[0m[0m | time: 0.877s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.4953 -- iter: 032/127
[A[ATraining Step: 18  | total loss: [1m[32m0.69280[0m[0m | time: 1.722s
[2K
| Adam | epoch: 005 | loss: 0.69280 - acc: 0.4969 -- iter: 064/127
[A[ATraining Step: 19  | total loss: [1m[32m0.69217[0m[0m | time: 2.486s
[2K
| Adam | epoch: 005 | loss: 0.69217 - acc: 0.4979 -- iter: 096/127
[A[ATraining Step: 20  | total loss: [1m[32m0.68810[0m[0m | time: 4.384s
[2K
| Adam | epoch: 005 | loss: 0.68810 - acc: 0.5556 | val_loss: 0.67618 - val_acc: 0.5750 -- iter: 127/127
--
Training Step: 21  | total loss: [1m[32m0.68276[0m[0m | time: 0.865s
[2K
| Adam | epoch: 006 | loss: 0.68276 - acc: 0.5934 -- iter: 032/127
[A[ATraining Step: 22  | total loss: [1m[32m0.69003[0m[0m | time: 1.695s
[2K
| Adam | epoch: 006 | loss: 0.69003 - acc: 0.5373 -- iter: 064/127
[A[ATraining Step: 23  | total loss: [1m[32m0.68492[0m[0m | time: 2.526s
[2K
| Adam | epoch: 006 | loss: 0.68492 - acc: 0.5446 -- iter: 096/127
[A[ATraining Step: 24  | total loss: [1m[32m0.68073[0m[0m | time: 4.367s
[2K
| Adam | epoch: 006 | loss: 0.68073 - acc: 0.5496 | val_loss: 0.65783 - val_acc: 0.5750 -- iter: 127/127
--
Training Step: 25  | total loss: [1m[32m0.68111[0m[0m | time: 0.999s
[2K
| Adam | epoch: 007 | loss: 0.68111 - acc: 0.5317 -- iter: 032/127
[A[ATraining Step: 26  | total loss: [1m[32m0.67861[0m[0m | time: 1.960s
[2K
| Adam | epoch: 007 | loss: 0.67861 - acc: 0.5190 -- iter: 064/127
[A[ATraining Step: 27  | total loss: [1m[32m0.67513[0m[0m | time: 2.674s
[2K
| Adam | epoch: 007 | loss: 0.67513 - acc: 0.5061 -- iter: 096/127
[A[ATraining Step: 28  | total loss: [1m[32m0.66928[0m[0m | time: 4.505s
[2K
| Adam | epoch: 007 | loss: 0.66928 - acc: 0.5358 | val_loss: 0.58870 - val_acc: 0.6000 -- iter: 127/127
--
Training Step: 29  | total loss: [1m[32m0.65753[0m[0m | time: 1.374s
[2K
| Adam | epoch: 008 | loss: 0.65753 - acc: 0.5423 -- iter: 032/127
[A[ATraining Step: 30  | total loss: [1m[32m0.63607[0m[0m | time: 2.407s
[2K
| Adam | epoch: 008 | loss: 0.63607 - acc: 0.5514 -- iter: 064/127
[A[ATraining Step: 31  | total loss: [1m[32m0.60894[0m[0m | time: 3.398s
[2K
| Adam | epoch: 008 | loss: 0.60894 - acc: 0.6177 -- iter: 096/127
[A[ATraining Step: 32  | total loss: [1m[32m0.58140[0m[0m | time: 5.570s
[2K
| Adam | epoch: 008 | loss: 0.58140 - acc: 0.6756 | val_loss: 0.44457 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 33  | total loss: [1m[32m0.53803[0m[0m | time: 1.263s
[2K
| Adam | epoch: 009 | loss: 0.53803 - acc: 0.6988 -- iter: 032/127
[A[ATraining Step: 34  | total loss: [1m[32m0.51357[0m[0m | time: 2.433s
[2K
| Adam | epoch: 009 | loss: 0.51357 - acc: 0.7365 -- iter: 064/127
[A[ATraining Step: 35  | total loss: [1m[32m0.47329[0m[0m | time: 3.564s
[2K
| Adam | epoch: 009 | loss: 0.47329 - acc: 0.7782 -- iter: 096/127
[A[ATraining Step: 36  | total loss: [1m[32m0.42332[0m[0m | time: 5.755s
[2K
| Adam | epoch: 009 | loss: 0.42332 - acc: 0.8170 | val_loss: 0.58905 - val_acc: 0.8000 -- iter: 127/127
--
Training Step: 37  | total loss: [1m[32m0.39332[0m[0m | time: 0.996s
[2K
| Adam | epoch: 010 | loss: 0.39332 - acc: 0.8348 -- iter: 032/127
[A[ATraining Step: 38  | total loss: [1m[32m0.65410[0m[0m | time: 2.153s
[2K
| Adam | epoch: 010 | loss: 0.65410 - acc: 0.7938 -- iter: 064/127
[A[ATraining Step: 39  | total loss: [1m[32m0.57044[0m[0m | time: 3.308s
[2K
| Adam | epoch: 010 | loss: 0.57044 - acc: 0.8213 -- iter: 096/127
[A[ATraining Step: 40  | total loss: [1m[32m0.49488[0m[0m | time: 5.434s
[2K
| Adam | epoch: 010 | loss: 0.49488 - acc: 0.8427 | val_loss: 0.44816 - val_acc: 0.8750 -- iter: 127/127
--
Training Step: 41  | total loss: [1m[32m0.43063[0m[0m | time: 1.169s
[2K
| Adam | epoch: 011 | loss: 0.43063 - acc: 0.8597 -- iter: 032/127
[A[ATraining Step: 42  | total loss: [1m[32m0.39709[0m[0m | time: 2.305s
[2K
| Adam | epoch: 011 | loss: 0.39709 - acc: 0.8794 -- iter: 064/127
[A[ATraining Step: 43  | total loss: [1m[32m0.40460[0m[0m | time: 3.431s
[2K
| Adam | epoch: 011 | loss: 0.40460 - acc: 0.8786 -- iter: 096/127
[A[ATraining Step: 44  | total loss: [1m[32m0.34950[0m[0m | time: 5.697s
[2K
| Adam | epoch: 011 | loss: 0.34950 - acc: 0.8996 | val_loss: 0.30239 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 45  | total loss: [1m[32m0.30594[0m[0m | time: 1.165s
[2K
| Adam | epoch: 012 | loss: 0.30594 - acc: 0.9167 -- iter: 032/127
[A[ATraining Step: 46  | total loss: [1m[32m0.26793[0m[0m | time: 2.336s
[2K
| Adam | epoch: 012 | loss: 0.26793 - acc: 0.9305 -- iter: 064/127
[A[ATraining Step: 47  | total loss: [1m[32m0.26128[0m[0m | time: 3.515s
[2K
| Adam | epoch: 012 | loss: 0.26128 - acc: 0.9317 -- iter: 096/127
[A[ATraining Step: 48  | total loss: [1m[32m0.24188[0m[0m | time: 5.682s
[2K
| Adam | epoch: 012 | loss: 0.24188 - acc: 0.9276 | val_loss: 0.30436 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 49  | total loss: [1m[32m0.21003[0m[0m | time: 1.161s
[2K
| Adam | epoch: 013 | loss: 0.21003 - acc: 0.9390 -- iter: 032/127
[A[ATraining Step: 50  | total loss: [1m[32m0.19516[0m[0m | time: 2.310s
[2K
| Adam | epoch: 013 | loss: 0.19516 - acc: 0.9385 -- iter: 064/127
[A[ATraining Step: 51  | total loss: [1m[32m0.17406[0m[0m | time: 3.509s
[2K
| Adam | epoch: 013 | loss: 0.17406 - acc: 0.9429 -- iter: 096/127
[A[ATraining Step: 52  | total loss: [1m[32m0.19447[0m[0m | time: 5.764s
[2K
| Adam | epoch: 013 | loss: 0.19447 - acc: 0.9374 | val_loss: 0.31686 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 53  | total loss: [1m[32m0.22481[0m[0m | time: 1.134s
[2K
| Adam | epoch: 014 | loss: 0.22481 - acc: 0.9282 -- iter: 032/127
[A[ATraining Step: 54  | total loss: [1m[32m0.19908[0m[0m | time: 2.287s
[2K
| Adam | epoch: 014 | loss: 0.19908 - acc: 0.9341 -- iter: 064/127
[A[ATraining Step: 55  | total loss: [1m[32m0.17717[0m[0m | time: 3.484s
[2K
| Adam | epoch: 014 | loss: 0.17717 - acc: 0.9435 -- iter: 096/127
[A[ATraining Step: 56  | total loss: [1m[32m0.15714[0m[0m | time: 5.813s
[2K
| Adam | epoch: 014 | loss: 0.15714 - acc: 0.9515 | val_loss: 0.28098 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 57  | total loss: [1m[32m0.16194[0m[0m | time: 1.113s
[2K
| Adam | epoch: 015 | loss: 0.16194 - acc: 0.9495 -- iter: 032/127
[A[ATraining Step: 58  | total loss: [1m[32m0.14295[0m[0m | time: 2.427s
[2K
| Adam | epoch: 015 | loss: 0.14295 - acc: 0.9564 -- iter: 064/127
[A[ATraining Step: 59  | total loss: [1m[32m0.13802[0m[0m | time: 3.703s
[2K
| Adam | epoch: 015 | loss: 0.13802 - acc: 0.9581 -- iter: 096/127
[A[ATraining Step: 60  | total loss: [1m[32m0.12931[0m[0m | time: 6.136s
[2K
| Adam | epoch: 015 | loss: 0.12931 - acc: 0.9636 | val_loss: 0.31949 - val_acc: 0.9000 -- iter: 127/127
--
Training Step: 61  | total loss: [1m[32m0.11748[0m[0m | time: 1.099s
[2K
| Adam | epoch: 016 | loss: 0.11748 - acc: 0.9684 -- iter: 032/127
[A[ATraining Step: 62  | total loss: [1m[32m0.10924[0m[0m | time: 2.351s
[2K
| Adam | epoch: 016 | loss: 0.10924 - acc: 0.9684 -- iter: 064/127
[A[ATraining Step: 63  | total loss: [1m[32m0.09754[0m[0m | time: 3.520s
[2K
| Adam | epoch: 016 | loss: 0.09754 - acc: 0.9724 -- iter: 096/127
[A[ATraining Step: 64  | total loss: [1m[32m0.09865[0m[0m | time: 5.748s
[2K
| Adam | epoch: 016 | loss: 0.09865 - acc: 0.9720 | val_loss: 0.25614 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 65  | total loss: [1m[32m0.09462[0m[0m | time: 1.625s
[2K
| Adam | epoch: 017 | loss: 0.09462 - acc: 0.9714 -- iter: 032/127
[A[ATraining Step: 66  | total loss: [1m[32m0.08656[0m[0m | time: 2.961s
[2K
| Adam | epoch: 017 | loss: 0.08656 - acc: 0.9749 -- iter: 064/127
[A[ATraining Step: 67  | total loss: [1m[32m0.12224[0m[0m | time: 4.274s
[2K
| Adam | epoch: 017 | loss: 0.12224 - acc: 0.9554 -- iter: 096/127
[A[ATraining Step: 68  | total loss: [1m[32m0.17796[0m[0m | time: 6.806s
[2K
| Adam | epoch: 017 | loss: 0.17796 - acc: 0.9311 | val_loss: 0.32892 - val_acc: 0.9000 -- iter: 127/127
--
Training Step: 69  | total loss: [1m[32m0.16448[0m[0m | time: 1.202s
[2K
| Adam | epoch: 018 | loss: 0.16448 - acc: 0.9355 -- iter: 032/127
[A[ATraining Step: 70  | total loss: [1m[32m0.15029[0m[0m | time: 2.314s
[2K
| Adam | epoch: 018 | loss: 0.15029 - acc: 0.9392 -- iter: 064/127
[A[ATraining Step: 71  | total loss: [1m[32m0.14932[0m[0m | time: 3.533s
[2K
| Adam | epoch: 018 | loss: 0.14932 - acc: 0.9388 -- iter: 096/127
[A[ATraining Step: 72  | total loss: [1m[32m0.13904[0m[0m | time: 5.742s
[2K
| Adam | epoch: 018 | loss: 0.13904 - acc: 0.9422 | val_loss: 0.30934 - val_acc: 0.9000 -- iter: 127/127
--
Training Step: 73  | total loss: [1m[32m0.22129[0m[0m | time: 1.261s
[2K
| Adam | epoch: 019 | loss: 0.22129 - acc: 0.9278 -- iter: 032/127
[A[ATraining Step: 74  | total loss: [1m[32m0.19999[0m[0m | time: 2.608s
[2K
| Adam | epoch: 019 | loss: 0.19999 - acc: 0.9357 -- iter: 064/127
[A[ATraining Step: 75  | total loss: [1m[32m0.18316[0m[0m | time: 3.674s
[2K
| Adam | epoch: 019 | loss: 0.18316 - acc: 0.9427 -- iter: 096/127
[A[ATraining Step: 76  | total loss: [1m[32m0.16939[0m[0m | time: 5.815s
[2K
| Adam | epoch: 019 | loss: 0.16939 - acc: 0.9488 | val_loss: 0.21364 - val_acc: 0.9500 -- iter: 127/127
--
Training Step: 77  | total loss: [1m[32m0.15905[0m[0m | time: 1.272s
[2K
| Adam | epoch: 020 | loss: 0.15905 - acc: 0.9542 -- iter: 032/127
[A[ATraining Step: 78  | total loss: [1m[32m0.16167[0m[0m | time: 2.465s
[2K
| Adam | epoch: 020 | loss: 0.16167 - acc: 0.9557 -- iter: 064/127
[A[ATraining Step: 79  | total loss: [1m[32m0.15345[0m[0m | time: 3.576s
[2K
| Adam | epoch: 020 | loss: 0.15345 - acc: 0.9603 -- iter: 096/127
[A[ATraining Step: 80  | total loss: [1m[32m0.14224[0m[0m | time: 5.799s
[2K
| Adam | epoch: 020 | loss: 0.14224 - acc: 0.9644 | val_loss: 0.27600 - val_acc: 0.9000 -- iter: 127/127
--
Training Step: 81  | total loss: [1m[32m0.13158[0m[0m | time: 1.283s
[2K
| Adam | epoch: 021 | loss: 0.13158 - acc: 0.9680 -- iter: 032/127
[A[ATraining Step: 82  | total loss: [1m[32m0.12438[0m[0m | time: 2.294s
[2K
| Adam | epoch: 021 | loss: 0.12438 - acc: 0.9712 -- iter: 064/127
[A[ATraining Step: 83  | total loss: [1m[32m0.12777[0m[0m | time: 3.375s
[2K
| Adam | epoch: 021 | loss: 0.12777 - acc: 0.9709 -- iter: 096/127
[A[ATraining Step: 84  | total loss: [1m[32m0.11684[0m[0m | time: 5.552s
[2K
| Adam | epoch: 021 | loss: 0.11684 - acc: 0.9738 | val_loss: 0.20543 - val_acc: 0.9500 -- iter: 127/127
--
Training Step: 85  | total loss: [1m[32m0.10742[0m[0m | time: 1.189s
[2K
| Adam | epoch: 022 | loss: 0.10742 - acc: 0.9765 -- iter: 032/127
[A[ATraining Step: 86  | total loss: [1m[32m0.09840[0m[0m | time: 2.388s
[2K
| Adam | epoch: 022 | loss: 0.09840 - acc: 0.9788 -- iter: 064/127
[A[ATraining Step: 87  | total loss: [1m[32m0.08964[0m[0m | time: 3.595s
[2K
| Adam | epoch: 022 | loss: 0.08964 - acc: 0.9809 -- iter: 096/127
[A[ATraining Step: 88  | total loss: [1m[32m0.08136[0m[0m | time: 5.788s
[2K
| Adam | epoch: 022 | loss: 0.08136 - acc: 0.9828 | val_loss: 0.32765 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 89  | total loss: [1m[32m0.07371[0m[0m | time: 0.808s
[2K
| Adam | epoch: 023 | loss: 0.07371 - acc: 0.9846 -- iter: 032/127
[A[ATraining Step: 90  | total loss: [1m[32m0.06661[0m[0m | time: 1.669s
[2K
| Adam | epoch: 023 | loss: 0.06661 - acc: 0.9861 -- iter: 064/127
[A[ATraining Step: 91  | total loss: [1m[32m0.06022[0m[0m | time: 2.533s
[2K
| Adam | epoch: 023 | loss: 0.06022 - acc: 0.9875 -- iter: 096/127
[A[ATraining Step: 92  | total loss: [1m[32m0.05449[0m[0m | time: 4.510s
[2K
| Adam | epoch: 023 | loss: 0.05449 - acc: 0.9887 | val_loss: 0.41931 - val_acc: 0.9000 -- iter: 127/127
--
Training Step: 93  | total loss: [1m[32m0.37589[0m[0m | time: 1.167s
[2K
| Adam | epoch: 024 | loss: 0.37589 - acc: 0.9430 -- iter: 032/127
[A[ATraining Step: 94  | total loss: [1m[32m0.33888[0m[0m | time: 1.878s
[2K
| Adam | epoch: 024 | loss: 0.33888 - acc: 0.9487 -- iter: 064/127
[A[ATraining Step: 95  | total loss: [1m[32m0.30728[0m[0m | time: 2.719s
[2K
| Adam | epoch: 024 | loss: 0.30728 - acc: 0.9538 -- iter: 096/127
[A[ATraining Step: 96  | total loss: [1m[32m0.27801[0m[0m | time: 4.577s
[2K
| Adam | epoch: 024 | loss: 0.27801 - acc: 0.9584 | val_loss: 0.20069 - val_acc: 0.9500 -- iter: 127/127
--
Training Step: 97  | total loss: [1m[32m0.25201[0m[0m | time: 1.087s
[2K
| Adam | epoch: 025 | loss: 0.25201 - acc: 0.9626 -- iter: 032/127
[A[ATraining Step: 98  | total loss: [1m[32m0.24428[0m[0m | time: 2.219s
[2K
| Adam | epoch: 025 | loss: 0.24428 - acc: 0.9632 -- iter: 064/127
[A[ATraining Step: 99  | total loss: [1m[32m0.22585[0m[0m | time: 3.228s
[2K
| Adam | epoch: 025 | loss: 0.22585 - acc: 0.9669 -- iter: 096/127
[A[ATraining Step: 100  | total loss: [1m[32m0.20704[0m[0m | time: 4.974s
[2K
| Adam | epoch: 025 | loss: 0.20704 - acc: 0.9702 | val_loss: 0.24819 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 101  | total loss: [1m[32m0.18923[0m[0m | time: 0.973s
[2K
| Adam | epoch: 026 | loss: 0.18923 - acc: 0.9732 -- iter: 032/127
[A[ATraining Step: 102  | total loss: [1m[32m0.17395[0m[0m | time: 2.243s
[2K
| Adam | epoch: 026 | loss: 0.17395 - acc: 0.9759 -- iter: 064/127
[A[ATraining Step: 103  | total loss: [1m[32m0.22715[0m[0m | time: 3.810s
[2K
| Adam | epoch: 026 | loss: 0.22715 - acc: 0.9627 -- iter: 096/127
[A[ATraining Step: 104  | total loss: [1m[32m0.20847[0m[0m | time: 6.204s
[2K
| Adam | epoch: 026 | loss: 0.20847 - acc: 0.9664 | val_loss: 0.20201 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 105  | total loss: [1m[32m0.19199[0m[0m | time: 1.452s
[2K
| Adam | epoch: 027 | loss: 0.19199 - acc: 0.9697 -- iter: 032/127
[A[ATraining Step: 106  | total loss: [1m[32m0.17724[0m[0m | time: 2.942s
[2K
| Adam | epoch: 027 | loss: 0.17724 - acc: 0.9728 -- iter: 064/127
[A[ATraining Step: 107  | total loss: [1m[32m0.16583[0m[0m | time: 6.141s
[2K
| Adam | epoch: 027 | loss: 0.16583 - acc: 0.9755 -- iter: 096/127
[A[ATraining Step: 108  | total loss: [1m[32m0.15444[0m[0m | time: 8.467s
[2K
| Adam | epoch: 027 | loss: 0.15444 - acc: 0.9779 | val_loss: 0.20347 - val_acc: 0.9250 -- iter: 127/127
--
Training Step: 109  | total loss: [1m[32m0.14372[0m[0m | time: 1.223s
[2K
| Adam | epoch: 028 | loss: 0.14372 - acc: 0.9802 -- iter: 032/127
[A[ATraining Step: 110  | total loss: [1m[32m0.13201[0m[0m | time: 2.633s
[2K
| Adam | epoch: 028 | loss: 0.13201 - acc: 0.9821 -- iter: 064/127
[A[ATraining Step: 111  | total loss: [1m[32m0.12094[0m[0m | time: 4.031s
[2K
| Adam | epoch: 028 | loss: 0.12094 - acc: 0.9839 -- iter: 096/127
[A[ATraining Step: 112  | total loss: [1m[32m0.11170[0m[0m | time: 6.571s
[2K
| Adam | epoch: 028 | loss: 0.11170 - acc: 0.9855 | val_loss: 0.46365 - val_acc: 0.8750 -- iter: 127/127
--
Training Step: 113  | total loss: [1m[32m0.17136[0m[0m | time: 1.513s
[2K
| Adam | epoch: 029 | loss: 0.17136 - acc: 0.9682 -- iter: 032/127
[A[ATraining Step: 114  | total loss: [1m[32m0.17294[0m[0m | time: 2.917s
[2K
| Adam | epoch: 029 | loss: 0.17294 - acc: 0.9589 -- iter: 064/127
[A[ATraining Step: 115  | total loss: [1m[32m0.16238[0m[0m | time: 4.440s
[2K
| Adam | epoch: 029 | loss: 0.16238 - acc: 0.9598 -- iter: 096/127
[A[ATraining Step: 116  | total loss: [1m[32m0.14810[0m[0m | time: 6.831s
[2K
| Adam | epoch: 029 | loss: 0.14810 - acc: 0.9638 | val_loss: 0.18745 - val_acc: 0.9500 -- iter: 127/127
--
Training Step: 117  | total loss: [1m[32m0.13483[0m[0m | time: 1.208s
[2K
| Adam | epoch: 030 | loss: 0.13483 - acc: 0.9674 -- iter: 032/127
[A[ATraining Step: 118  | total loss: [1m[32m0.16633[0m[0m | time: 2.592s
[2K
| Adam | epoch: 030 | loss: 0.16633 - acc: 0.9582 -- iter: 064/127
[A[ATraining Step: 119  | total loss: [1m[32m0.16034[0m[0m | time: 3.962s
[2K
| Adam | epoch: 030 | loss: 0.16034 - acc: 0.9592 -- iter: 096/127
[A[ATraining Step: 120  | total loss: [1m[32m0.15621[0m[0m | time: 6.309s
[2K
| Adam | epoch: 030 | loss: 0.15621 - acc: 0.9601 | val_loss: 0.21235 - val_acc: 0.9500 -- iter: 127/127
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9514066496163682
Validation AUPRC:0.9621915751946712
Test AUC:0.9609375
Test AUPRC:0.9829130116959062
BestTestF1Score	0.96	0.9	0.95	1.0	0.92	22	0	16	2	0.55
BestTestMCCScore	0.96	0.9	0.95	1.0	0.92	22	0	16	2	0.55
BestTestAccuracyScore	0.96	0.9	0.95	1.0	0.92	22	0	16	2	0.55
BestValidationF1Score	0.94	0.9	0.95	1.0	0.88	15	0	23	2	0.55
BestValidationMCC	0.94	0.9	0.95	1.0	0.88	15	0	23	2	0.55
BestValidationAccuracy	0.94	0.9	0.95	1.0	0.88	15	0	23	2	0.55
TestPredictions (Threshold:0.55)
CHEMBL545050,TP,ACT,0.9900000095367432	CHEMBL60614,TN,INACT,0.019999999552965164	CHEMBL543400,TP,ACT,0.9800000190734863	CHEMBL536101,TP,ACT,0.9900000095367432	CHEMBL544120,TP,ACT,0.9800000190734863	CHEMBL542960,TP,ACT,0.9399999976158142	CHEMBL387758,TN,INACT,0.0	CHEMBL542934,TP,ACT,0.9800000190734863	CHEMBL555656,TP,ACT,0.949999988079071	CHEMBL542703,FN,ACT,0.25	CHEMBL2431797,TN,INACT,0.14000000059604645	CHEMBL545517,TP,ACT,0.9900000095367432	CHEMBL1191532,TP,ACT,0.9900000095367432	CHEMBL366270,FN,ACT,0.0	CHEMBL539028,TP,ACT,0.9900000095367432	CHEMBL3115209,TN,INACT,0.23999999463558197	CHEMBL77484,TP,ACT,0.5699999928474426	CHEMBL894,TN,INACT,0.019999999552965164	CHEMBL181745,TN,INACT,0.0	CHEMBL401877,TN,INACT,0.05999999865889549	CHEMBL327963,TN,INACT,0.009999999776482582	CHEMBL3115210,TN,INACT,0.25999999046325684	CHEMBL545514,TP,ACT,0.9900000095367432	CHEMBL543642,TP,ACT,0.9900000095367432	CHEMBL1078351,TN,INACT,0.009999999776482582	CHEMBL542642,TP,ACT,0.9900000095367432	CHEMBL553280,TP,ACT,0.9900000095367432	CHEMBL76768,TP,ACT,0.5799999833106995	CHEMBL64102,TN,INACT,0.019999999552965164	CHEMBL555770,TP,ACT,0.9900000095367432	CHEMBL540309,TP,ACT,0.9800000190734863	CHEMBL544850,TP,ACT,0.8700000047683716	CHEMBL213394,TN,INACT,0.019999999552965164	CHEMBL1762478,TN,INACT,0.03999999910593033	CHEMBL543557,TP,ACT,0.9800000190734863	CHEMBL539284,TP,ACT,0.9700000286102295	CHEMBL231684,TN,INACT,0.10999999940395355	CHEMBL555540,TP,ACT,0.9800000190734863	CHEMBL101986,TN,INACT,0.019999999552965164	CHEMBL249214,TN,INACT,0.019999999552965164	

