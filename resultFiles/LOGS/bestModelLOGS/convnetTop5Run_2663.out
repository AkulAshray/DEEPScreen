ImageNetInceptionV2 CHEMBL3308 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	118
Number of inactive compounds :	118
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3308_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3308_adam_0.001_15_0.6/
---------------------------------
Training samples: 150
Validation samples: 48
--
Training Step: 1  | time: 180.176s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/150
[A[ATraining Step: 2  | total loss: [1m[32m0.88829[0m[0m | time: 271.164s
[2K
| Adam | epoch: 001 | loss: 0.88829 - acc: 0.3094 -- iter: 064/150
[A[ATraining Step: 3  | total loss: [1m[32m0.87765[0m[0m | time: 374.687s
[2K
| Adam | epoch: 001 | loss: 0.87765 - acc: 0.4142 -- iter: 096/150
[A[ATraining Step: 4  | total loss: [1m[32m0.72424[0m[0m | time: 591.858s
[2K
| Adam | epoch: 001 | loss: 0.72424 - acc: 0.6426 -- iter: 128/150
[A[ATraining Step: 5  | total loss: [1m[32m0.65544[0m[0m | time: 723.473s
[2K
| Adam | epoch: 001 | loss: 0.65544 - acc: 0.6737 | val_loss: 1.55313 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 6  | total loss: [1m[32m0.71552[0m[0m | time: 6.251s
[2K
| Adam | epoch: 002 | loss: 0.71552 - acc: 0.6497 -- iter: 032/150
[A[ATraining Step: 7  | total loss: [1m[32m0.51650[0m[0m | time: 115.830s
[2K
| Adam | epoch: 002 | loss: 0.51650 - acc: 0.8053 -- iter: 064/150
[A[ATraining Step: 8  | total loss: [1m[32m0.66032[0m[0m | time: 124.701s
[2K
| Adam | epoch: 002 | loss: 0.66032 - acc: 0.7039 -- iter: 096/150
[A[ATraining Step: 9  | total loss: [1m[32m0.68912[0m[0m | time: 133.619s
[2K
| Adam | epoch: 002 | loss: 0.68912 - acc: 0.6456 -- iter: 128/150
[A[ATraining Step: 10  | total loss: [1m[32m0.54859[0m[0m | time: 148.763s
[2K
| Adam | epoch: 002 | loss: 0.54859 - acc: 0.7603 | val_loss: 1.00192 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 11  | total loss: [1m[32m0.48321[0m[0m | time: 6.498s
[2K
| Adam | epoch: 003 | loss: 0.48321 - acc: 0.8146 -- iter: 032/150
[A[ATraining Step: 12  | total loss: [1m[32m0.45201[0m[0m | time: 12.998s
[2K
| Adam | epoch: 003 | loss: 0.45201 - acc: 0.8162 -- iter: 064/150
[A[ATraining Step: 13  | total loss: [1m[32m0.37956[0m[0m | time: 21.711s
[2K
| Adam | epoch: 003 | loss: 0.37956 - acc: 0.8755 -- iter: 096/150
[A[ATraining Step: 14  | total loss: [1m[32m0.48380[0m[0m | time: 77.462s
[2K
| Adam | epoch: 003 | loss: 0.48380 - acc: 0.8369 -- iter: 128/150
[A[ATraining Step: 15  | total loss: [1m[32m0.50979[0m[0m | time: 88.727s
[2K
| Adam | epoch: 003 | loss: 0.50979 - acc: 0.7907 | val_loss: 0.69282 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 16  | total loss: [1m[32m0.44659[0m[0m | time: 8.681s
[2K
| Adam | epoch: 004 | loss: 0.44659 - acc: 0.8106 -- iter: 032/150
[A[ATraining Step: 17  | total loss: [1m[32m0.39805[0m[0m | time: 15.025s
[2K
| Adam | epoch: 004 | loss: 0.39805 - acc: 0.8450 -- iter: 064/150
[A[ATraining Step: 18  | total loss: [1m[32m0.32206[0m[0m | time: 21.598s
[2K
| Adam | epoch: 004 | loss: 0.32206 - acc: 0.8829 -- iter: 096/150
[A[ATraining Step: 19  | total loss: [1m[32m0.26540[0m[0m | time: 45.143s
[2K
| Adam | epoch: 004 | loss: 0.26540 - acc: 0.9068 -- iter: 128/150
[A[ATraining Step: 20  | total loss: [1m[32m0.25988[0m[0m | time: 57.942s
[2K
| Adam | epoch: 004 | loss: 0.25988 - acc: 0.8966 | val_loss: 0.95356 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 21  | total loss: [1m[32m0.47140[0m[0m | time: 8.793s
[2K
| Adam | epoch: 005 | loss: 0.47140 - acc: 0.8317 -- iter: 032/150
[A[ATraining Step: 22  | total loss: [1m[32m0.38951[0m[0m | time: 28.013s
[2K
| Adam | epoch: 005 | loss: 0.38951 - acc: 0.8728 -- iter: 064/150
[A[ATraining Step: 23  | total loss: [1m[32m0.32193[0m[0m | time: 34.448s
[2K
| Adam | epoch: 005 | loss: 0.32193 - acc: 0.9097 -- iter: 096/150
[A[ATraining Step: 24  | total loss: [1m[32m0.34018[0m[0m | time: 41.015s
[2K
| Adam | epoch: 005 | loss: 0.34018 - acc: 0.8840 -- iter: 128/150
[A[ATraining Step: 25  | total loss: [1m[32m0.28034[0m[0m | time: 78.471s
[2K
| Adam | epoch: 005 | loss: 0.28034 - acc: 0.8908 | val_loss: 0.90237 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 26  | total loss: [1m[32m0.34157[0m[0m | time: 8.679s
[2K
| Adam | epoch: 006 | loss: 0.34157 - acc: 0.8536 -- iter: 032/150
[A[ATraining Step: 27  | total loss: [1m[32m0.38803[0m[0m | time: 27.942s
[2K
| Adam | epoch: 006 | loss: 0.38803 - acc: 0.8350 -- iter: 064/150
[A[ATraining Step: 28  | total loss: [1m[32m0.37451[0m[0m | time: 36.732s
[2K
| Adam | epoch: 006 | loss: 0.37451 - acc: 0.8450 -- iter: 096/150
[A[ATraining Step: 29  | total loss: [1m[32m0.33799[0m[0m | time: 42.996s
[2K
| Adam | epoch: 006 | loss: 0.33799 - acc: 0.8599 -- iter: 128/150
[A[ATraining Step: 30  | total loss: [1m[32m0.31475[0m[0m | time: 51.807s
[2K
| Adam | epoch: 006 | loss: 0.31475 - acc: 0.8608 | val_loss: 0.70901 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 31  | total loss: [1m[32m0.26372[0m[0m | time: 15.144s
[2K
| Adam | epoch: 007 | loss: 0.26372 - acc: 0.8929 -- iter: 032/150
[A[ATraining Step: 32  | total loss: [1m[32m0.25889[0m[0m | time: 48.646s
[2K
| Adam | epoch: 007 | loss: 0.25889 - acc: 0.8889 -- iter: 064/150
[A[ATraining Step: 33  | total loss: [1m[32m0.30313[0m[0m | time: 57.621s
[2K
| Adam | epoch: 007 | loss: 0.30313 - acc: 0.8721 -- iter: 096/150
[A[ATraining Step: 34  | total loss: [1m[32m0.35956[0m[0m | time: 98.556s
[2K
| Adam | epoch: 007 | loss: 0.35956 - acc: 0.8660 -- iter: 128/150
[A[ATraining Step: 35  | total loss: [1m[32m0.34909[0m[0m | time: 107.293s
[2K
| Adam | epoch: 007 | loss: 0.34909 - acc: 0.8875 | val_loss: 3.39004 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 36  | total loss: [1m[32m0.29915[0m[0m | time: 6.527s
[2K
| Adam | epoch: 008 | loss: 0.29915 - acc: 0.9105 -- iter: 032/150
[A[ATraining Step: 37  | total loss: [1m[32m0.24909[0m[0m | time: 15.028s
[2K
| Adam | epoch: 008 | loss: 0.24909 - acc: 0.9284 -- iter: 064/150
[A[ATraining Step: 38  | total loss: [1m[32m0.25252[0m[0m | time: 36.026s
[2K
| Adam | epoch: 008 | loss: 0.25252 - acc: 0.9241 -- iter: 096/150
[A[ATraining Step: 39  | total loss: [1m[32m0.22962[0m[0m | time: 46.334s
[2K
| Adam | epoch: 008 | loss: 0.22962 - acc: 0.9326 -- iter: 128/150
[A[ATraining Step: 40  | total loss: [1m[32m0.24796[0m[0m | time: 57.095s
[2K
| Adam | epoch: 008 | loss: 0.24796 - acc: 0.9394 | val_loss: 4.24857 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 41  | total loss: [1m[32m0.21513[0m[0m | time: 6.220s
[2K
| Adam | epoch: 009 | loss: 0.21513 - acc: 0.9448 -- iter: 032/150
[A[ATraining Step: 42  | total loss: [1m[32m0.18775[0m[0m | time: 12.755s
[2K
| Adam | epoch: 009 | loss: 0.18775 - acc: 0.9547 -- iter: 064/150
[A[ATraining Step: 43  | total loss: [1m[32m0.16257[0m[0m | time: 21.468s
[2K
| Adam | epoch: 009 | loss: 0.16257 - acc: 0.9627 -- iter: 096/150
[A[ATraining Step: 44  | total loss: [1m[32m0.15759[0m[0m | time: 30.186s
[2K
| Adam | epoch: 009 | loss: 0.15759 - acc: 0.9529 -- iter: 128/150
[A[ATraining Step: 45  | total loss: [1m[32m0.18042[0m[0m | time: 41.222s
[2K
| Adam | epoch: 009 | loss: 0.18042 - acc: 0.9397 | val_loss: 3.84816 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 46  | total loss: [1m[32m0.16893[0m[0m | time: 8.462s
[2K
| Adam | epoch: 010 | loss: 0.16893 - acc: 0.9341 -- iter: 032/150
[A[ATraining Step: 47  | total loss: [1m[32m0.15515[0m[0m | time: 14.925s
[2K
| Adam | epoch: 010 | loss: 0.15515 - acc: 0.9398 -- iter: 064/150
[A[ATraining Step: 48  | total loss: [1m[32m0.14717[0m[0m | time: 21.427s
[2K
| Adam | epoch: 010 | loss: 0.14717 - acc: 0.9422 -- iter: 096/150
[A[ATraining Step: 49  | total loss: [1m[32m0.13554[0m[0m | time: 30.183s
[2K
| Adam | epoch: 010 | loss: 0.13554 - acc: 0.9513 -- iter: 128/150
[A[ATraining Step: 50  | total loss: [1m[32m0.13385[0m[0m | time: 55.571s
[2K
| Adam | epoch: 010 | loss: 0.13385 - acc: 0.9540 | val_loss: 4.62106 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 51  | total loss: [1m[32m0.14221[0m[0m | time: 9.052s
[2K
| Adam | epoch: 011 | loss: 0.14221 - acc: 0.9515 -- iter: 032/150
[A[ATraining Step: 52  | total loss: [1m[32m0.14655[0m[0m | time: 17.935s
[2K
| Adam | epoch: 011 | loss: 0.14655 - acc: 0.9447 -- iter: 064/150
[A[ATraining Step: 53  | total loss: [1m[32m0.12935[0m[0m | time: 24.622s
[2K
| Adam | epoch: 011 | loss: 0.12935 - acc: 0.9529 -- iter: 096/150
[A[ATraining Step: 54  | total loss: [1m[32m0.15322[0m[0m | time: 31.168s
[2K
| Adam | epoch: 011 | loss: 0.15322 - acc: 0.9465 -- iter: 128/150
[A[ATraining Step: 55  | total loss: [1m[32m0.15314[0m[0m | time: 42.407s
[2K
| Adam | epoch: 011 | loss: 0.15314 - acc: 0.9412 | val_loss: 4.03194 - val_acc: 0.5208 -- iter: 150/150
--
Training Step: 56  | total loss: [1m[32m0.13726[0m[0m | time: 11.630s
[2K
| Adam | epoch: 012 | loss: 0.13726 - acc: 0.9494 -- iter: 032/150
[A[ATraining Step: 57  | total loss: [1m[32m0.14682[0m[0m | time: 22.661s
[2K
| Adam | epoch: 012 | loss: 0.14682 - acc: 0.9478 -- iter: 064/150
[A[ATraining Step: 58  | total loss: [1m[32m0.18973[0m[0m | time: 31.218s
[2K
| Adam | epoch: 012 | loss: 0.18973 - acc: 0.9464 -- iter: 096/150
[A[ATraining Step: 59  | total loss: [1m[32m0.19847[0m[0m | time: 37.786s
[2K
| Adam | epoch: 012 | loss: 0.19847 - acc: 0.9410 -- iter: 128/150
[A[ATraining Step: 60  | total loss: [1m[32m0.18416[0m[0m | time: 46.659s
[2K
| Adam | epoch: 012 | loss: 0.18416 - acc: 0.9428 | val_loss: 6.91977 - val_acc: 0.5000 -- iter: 150/150
--
Training Step: 61  | total loss: [1m[32m0.16769[0m[0m | time: 8.895s
[2K
| Adam | epoch: 013 | loss: 0.16769 - acc: 0.9502 -- iter: 032/150
[A[ATraining Step: 62  | total loss: [1m[32m0.16110[0m[0m | time: 17.674s
[2K
| Adam | epoch: 013 | loss: 0.16110 - acc: 0.9486 -- iter: 064/150
[A[ATraining Step: 63  | total loss: [1m[32m0.17791[0m[0m | time: 36.605s
[2K
| Adam | epoch: 013 | loss: 0.17791 - acc: 0.9353 -- iter: 096/150
[A[ATraining Step: 64  | total loss: [1m[32m0.17636[0m[0m | time: 45.376s
[2K
| Adam | epoch: 013 | loss: 0.17636 - acc: 0.9395 -- iter: 128/150
[A[ATraining Step: 65  | total loss: [1m[32m0.17210[0m[0m | time: 54.371s
[2K
| Adam | epoch: 013 | loss: 0.17210 - acc: 0.9392 | val_loss: 1.21380 - val_acc: 0.6458 -- iter: 150/150
--
Training Step: 66  | total loss: [1m[32m0.15746[0m[0m | time: 6.521s
[2K
| Adam | epoch: 014 | loss: 0.15746 - acc: 0.9466 -- iter: 032/150
[A[ATraining Step: 67  | total loss: [1m[32m0.14453[0m[0m | time: 48.656s
[2K
| Adam | epoch: 014 | loss: 0.14453 - acc: 0.9530 -- iter: 064/150
[A[ATraining Step: 68  | total loss: [1m[32m0.13487[0m[0m | time: 65.987s
[2K
| Adam | epoch: 014 | loss: 0.13487 - acc: 0.9549 -- iter: 096/150
[A[ATraining Step: 69  | total loss: [1m[32m0.12745[0m[0m | time: 89.458s
[2K
| Adam | epoch: 014 | loss: 0.12745 - acc: 0.9565 -- iter: 128/150
[A[ATraining Step: 70  | total loss: [1m[32m0.13749[0m[0m | time: 100.756s
[2K
| Adam | epoch: 014 | loss: 0.13749 - acc: 0.9579 | val_loss: 1.00265 - val_acc: 0.7083 -- iter: 150/150
--
Training Step: 71  | total loss: [1m[32m0.12611[0m[0m | time: 6.171s
[2K
| Adam | epoch: 015 | loss: 0.12611 - acc: 0.9627 -- iter: 032/150
[A[ATraining Step: 72  | total loss: [1m[32m0.11733[0m[0m | time: 12.606s
[2K
| Adam | epoch: 015 | loss: 0.11733 - acc: 0.9669 -- iter: 064/150
[A[ATraining Step: 73  | total loss: [1m[32m0.10830[0m[0m | time: 21.200s
[2K
| Adam | epoch: 015 | loss: 0.10830 - acc: 0.9706 -- iter: 096/150
[A[ATraining Step: 74  | total loss: [1m[32m0.11199[0m[0m | time: 29.887s
[2K
| Adam | epoch: 015 | loss: 0.11199 - acc: 0.9704 -- iter: 128/150
[A[ATraining Step: 75  | total loss: [1m[32m0.12239[0m[0m | time: 42.216s
[2K
| Adam | epoch: 015 | loss: 0.12239 - acc: 0.9634 | val_loss: 1.21653 - val_acc: 0.6667 -- iter: 150/150
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7843478260869565
Validation AUPRC:0.7100896758417263
Test AUC:0.7182608695652174
Test AUPRC:0.7733303496870134
BestTestF1Score	0.68	0.46	0.73	0.78	0.61	14	4	21	9	0.1
BestTestMCCScore	0.72	0.56	0.77	0.88	0.61	14	2	23	9	0.2
BestTestAccuracyScore	0.72	0.56	0.77	0.88	0.61	14	2	23	9	0.2
BestValidationF1Score	0.68	0.46	0.73	0.78	0.61	14	4	21	9	0.1
BestValidationMCC	0.67	0.47	0.73	0.81	0.57	13	3	22	10	0.2
BestValidationAccuracy	0.67	0.47	0.73	0.81	0.57	13	3	22	10	0.2
TestPredictions (Threshold:0.2)
CHEMBL1835318,TN,INACT,0.0	CHEMBL1762355,TP,ACT,0.3400000035762787	CHEMBL227035,TP,ACT,0.5299999713897705	CHEMBL1242700,TN,INACT,0.029999999329447746	CHEMBL567893,TP,ACT,0.3100000023841858	CHEMBL101448,TP,ACT,0.5799999833106995	CHEMBL1222970,TN,INACT,0.0	CHEMBL567785,FN,ACT,0.0	CHEMBL521801,TP,ACT,0.9700000286102295	CHEMBL2348698,FN,ACT,0.0	CHEMBL102901,TP,ACT,0.3700000047683716	CHEMBL1242422,TN,INACT,0.03999999910593033	CHEMBL146453,TP,ACT,0.9700000286102295	CHEMBL166476,TN,INACT,0.09000000357627869	CHEMBL297304,FP,INACT,0.6399999856948853	CHEMBL2348693,FN,ACT,0.0	CHEMBL3133146,FN,ACT,0.0	CHEMBL318386,TP,ACT,0.5699999928474426	CHEMBL101442,TN,INACT,0.009999999776482582	CHEMBL479009,TN,INACT,0.03999999910593033	CHEMBL166472,TN,INACT,0.03999999910593033	CHEMBL1762358,TP,ACT,0.33000001311302185	CHEMBL101145,FN,ACT,0.009999999776482582	CHEMBL400366,TN,INACT,0.0	CHEMBL265439,TN,INACT,0.0	CHEMBL438969,FN,ACT,0.0	CHEMBL1223039,TN,INACT,0.0	CHEMBL3805942,TN,INACT,0.0	CHEMBL3806289,TN,INACT,0.009999999776482582	CHEMBL194183,TN,INACT,0.019999999552965164	CHEMBL2041042,TN,INACT,0.0	CHEMBL317782,TN,INACT,0.11999999731779099	CHEMBL367587,TN,INACT,0.1599999964237213	CHEMBL1762348,FN,ACT,0.019999999552965164	CHEMBL31053,FP,INACT,0.3499999940395355	CHEMBL2324339,FN,ACT,0.0	CHEMBL430648,FN,ACT,0.019999999552965164	CHEMBL521972,TP,ACT,0.6499999761581421	CHEMBL62187,TN,INACT,0.009999999776482582	CHEMBL492059,TP,ACT,0.6499999761581421	CHEMBL1835404,TN,INACT,0.0	CHEMBL411858,TN,INACT,0.03999999910593033	CHEMBL492735,TN,INACT,0.0	CHEMBL2041016,TN,INACT,0.0	CHEMBL492061,TP,ACT,0.9700000286102295	CHEMBL1996492,TN,INACT,0.009999999776482582	CHEMBL321074,TP,ACT,0.36000001430511475	CHEMBL1762346,TP,ACT,0.6100000143051147	

