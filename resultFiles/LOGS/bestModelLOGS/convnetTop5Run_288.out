ImageNetInceptionV2 CHEMBL3571 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	1388
Number of inactive compounds :	1388
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3571_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3571_adam_0.001_15_0.8/
---------------------------------
Training samples: 1702
Validation samples: 533
--
Training Step: 1  | time: 45.718s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1702
[A[ATraining Step: 2  | total loss: [1m[32m0.64246[0m[0m | time: 56.170s
[2K
| Adam | epoch: 001 | loss: 0.64246 - acc: 0.5062 -- iter: 0064/1702
[A[ATraining Step: 3  | total loss: [1m[32m0.66386[0m[0m | time: 67.621s
[2K
| Adam | epoch: 001 | loss: 0.66386 - acc: 0.5267 -- iter: 0096/1702
[A[ATraining Step: 4  | total loss: [1m[32m0.69286[0m[0m | time: 78.630s
[2K
| Adam | epoch: 001 | loss: 0.69286 - acc: 0.6239 -- iter: 0128/1702
[A[ATraining Step: 5  | total loss: [1m[32m0.60533[0m[0m | time: 88.877s
[2K
| Adam | epoch: 001 | loss: 0.60533 - acc: 0.6679 -- iter: 0160/1702
[A[ATraining Step: 6  | total loss: [1m[32m0.73348[0m[0m | time: 99.344s
[2K
| Adam | epoch: 001 | loss: 0.73348 - acc: 0.6403 -- iter: 0192/1702
[A[ATraining Step: 7  | total loss: [1m[32m0.63064[0m[0m | time: 110.491s
[2K
| Adam | epoch: 001 | loss: 0.63064 - acc: 0.6874 -- iter: 0224/1702
[A[ATraining Step: 8  | total loss: [1m[32m0.54059[0m[0m | time: 120.482s
[2K
| Adam | epoch: 001 | loss: 0.54059 - acc: 0.7578 -- iter: 0256/1702
[A[ATraining Step: 9  | total loss: [1m[32m0.49696[0m[0m | time: 130.467s
[2K
| Adam | epoch: 001 | loss: 0.49696 - acc: 0.7537 -- iter: 0288/1702
[A[ATraining Step: 10  | total loss: [1m[32m0.65441[0m[0m | time: 140.677s
[2K
| Adam | epoch: 001 | loss: 0.65441 - acc: 0.7050 -- iter: 0320/1702
[A[ATraining Step: 11  | total loss: [1m[32m0.61246[0m[0m | time: 151.250s
[2K
| Adam | epoch: 001 | loss: 0.61246 - acc: 0.6671 -- iter: 0352/1702
[A[ATraining Step: 12  | total loss: [1m[32m0.63079[0m[0m | time: 161.553s
[2K
| Adam | epoch: 001 | loss: 0.63079 - acc: 0.6903 -- iter: 0384/1702
[A[ATraining Step: 13  | total loss: [1m[32m0.57269[0m[0m | time: 171.847s
[2K
| Adam | epoch: 001 | loss: 0.57269 - acc: 0.7159 -- iter: 0416/1702
[A[ATraining Step: 14  | total loss: [1m[32m0.54008[0m[0m | time: 182.115s
[2K
| Adam | epoch: 001 | loss: 0.54008 - acc: 0.7426 -- iter: 0448/1702
[A[ATraining Step: 15  | total loss: [1m[32m0.52987[0m[0m | time: 192.234s
[2K
| Adam | epoch: 001 | loss: 0.52987 - acc: 0.7577 -- iter: 0480/1702
[A[ATraining Step: 16  | total loss: [1m[32m0.54827[0m[0m | time: 202.504s
[2K
| Adam | epoch: 001 | loss: 0.54827 - acc: 0.7080 -- iter: 0512/1702
[A[ATraining Step: 17  | total loss: [1m[32m0.60958[0m[0m | time: 212.266s
[2K
| Adam | epoch: 001 | loss: 0.60958 - acc: 0.6668 -- iter: 0544/1702
[A[ATraining Step: 18  | total loss: [1m[32m0.57596[0m[0m | time: 223.504s
[2K
| Adam | epoch: 001 | loss: 0.57596 - acc: 0.6956 -- iter: 0576/1702
[A[ATraining Step: 19  | total loss: [1m[32m0.50692[0m[0m | time: 231.841s
[2K
| Adam | epoch: 001 | loss: 0.50692 - acc: 0.7554 -- iter: 0608/1702
[A[ATraining Step: 20  | total loss: [1m[32m0.52699[0m[0m | time: 239.709s
[2K
| Adam | epoch: 001 | loss: 0.52699 - acc: 0.7436 -- iter: 0640/1702
[A[ATraining Step: 21  | total loss: [1m[32m0.45878[0m[0m | time: 247.500s
[2K
| Adam | epoch: 001 | loss: 0.45878 - acc: 0.7941 -- iter: 0672/1702
[A[ATraining Step: 22  | total loss: [1m[32m0.52436[0m[0m | time: 255.224s
[2K
| Adam | epoch: 001 | loss: 0.52436 - acc: 0.7621 -- iter: 0704/1702
[A[ATraining Step: 23  | total loss: [1m[32m0.51280[0m[0m | time: 263.218s
[2K
| Adam | epoch: 001 | loss: 0.51280 - acc: 0.7586 -- iter: 0736/1702
[A[ATraining Step: 24  | total loss: [1m[32m0.49140[0m[0m | time: 271.182s
[2K
| Adam | epoch: 001 | loss: 0.49140 - acc: 0.7738 -- iter: 0768/1702
[A[ATraining Step: 25  | total loss: [1m[32m0.45953[0m[0m | time: 279.123s
[2K
| Adam | epoch: 001 | loss: 0.45953 - acc: 0.7843 -- iter: 0800/1702
[A[ATraining Step: 26  | total loss: [1m[32m0.40194[0m[0m | time: 286.841s
[2K
| Adam | epoch: 001 | loss: 0.40194 - acc: 0.8249 -- iter: 0832/1702
[A[ATraining Step: 27  | total loss: [1m[32m0.35189[0m[0m | time: 294.714s
[2K
| Adam | epoch: 001 | loss: 0.35189 - acc: 0.8619 -- iter: 0864/1702
[A[ATraining Step: 28  | total loss: [1m[32m0.39043[0m[0m | time: 302.484s
[2K
| Adam | epoch: 001 | loss: 0.39043 - acc: 0.8417 -- iter: 0896/1702
[A[ATraining Step: 29  | total loss: [1m[32m0.37265[0m[0m | time: 310.305s
[2K
| Adam | epoch: 001 | loss: 0.37265 - acc: 0.8650 -- iter: 0928/1702
[A[ATraining Step: 30  | total loss: [1m[32m0.41011[0m[0m | time: 318.109s
[2K
| Adam | epoch: 001 | loss: 0.41011 - acc: 0.8378 -- iter: 0960/1702
[A[ATraining Step: 31  | total loss: [1m[32m0.41899[0m[0m | time: 325.998s
[2K
| Adam | epoch: 001 | loss: 0.41899 - acc: 0.8247 -- iter: 0992/1702
[A[ATraining Step: 32  | total loss: [1m[32m0.39277[0m[0m | time: 333.792s
[2K
| Adam | epoch: 001 | loss: 0.39277 - acc: 0.8360 -- iter: 1024/1702
[A[ATraining Step: 33  | total loss: [1m[32m0.37485[0m[0m | time: 341.681s
[2K
| Adam | epoch: 001 | loss: 0.37485 - acc: 0.8309 -- iter: 1056/1702
[A[ATraining Step: 34  | total loss: [1m[32m0.37006[0m[0m | time: 349.579s
[2K
| Adam | epoch: 001 | loss: 0.37006 - acc: 0.8336 -- iter: 1088/1702
[A[ATraining Step: 35  | total loss: [1m[32m0.34592[0m[0m | time: 357.374s
[2K
| Adam | epoch: 001 | loss: 0.34592 - acc: 0.8358 -- iter: 1120/1702
[A[ATraining Step: 36  | total loss: [1m[32m0.31668[0m[0m | time: 365.307s
[2K
| Adam | epoch: 001 | loss: 0.31668 - acc: 0.8566 -- iter: 1152/1702
[A[ATraining Step: 37  | total loss: [1m[32m0.29855[0m[0m | time: 373.174s
[2K
| Adam | epoch: 001 | loss: 0.29855 - acc: 0.8665 -- iter: 1184/1702
[A[ATraining Step: 38  | total loss: [1m[32m0.40801[0m[0m | time: 380.950s
[2K
| Adam | epoch: 001 | loss: 0.40801 - acc: 0.8559 -- iter: 1216/1702
[A[ATraining Step: 39  | total loss: [1m[32m0.36809[0m[0m | time: 388.955s
[2K
| Adam | epoch: 001 | loss: 0.36809 - acc: 0.8775 -- iter: 1248/1702
[A[ATraining Step: 40  | total loss: [1m[32m0.39131[0m[0m | time: 396.837s
[2K
| Adam | epoch: 001 | loss: 0.39131 - acc: 0.8595 -- iter: 1280/1702
[A[ATraining Step: 41  | total loss: [1m[32m0.40767[0m[0m | time: 404.710s
[2K
| Adam | epoch: 001 | loss: 0.40767 - acc: 0.8623 -- iter: 1312/1702
[A[ATraining Step: 42  | total loss: [1m[32m0.40452[0m[0m | time: 412.567s
[2K
| Adam | epoch: 001 | loss: 0.40452 - acc: 0.8534 -- iter: 1344/1702
[A[ATraining Step: 43  | total loss: [1m[32m0.40470[0m[0m | time: 420.456s
[2K
| Adam | epoch: 001 | loss: 0.40470 - acc: 0.8517 -- iter: 1376/1702
[A[ATraining Step: 44  | total loss: [1m[32m0.39259[0m[0m | time: 428.205s
[2K
| Adam | epoch: 001 | loss: 0.39259 - acc: 0.8503 -- iter: 1408/1702
[A[ATraining Step: 45  | total loss: [1m[32m0.37603[0m[0m | time: 436.131s
[2K
| Adam | epoch: 001 | loss: 0.37603 - acc: 0.8545 -- iter: 1440/1702
[A[ATraining Step: 46  | total loss: [1m[32m0.36878[0m[0m | time: 443.956s
[2K
| Adam | epoch: 001 | loss: 0.36878 - acc: 0.8579 -- iter: 1472/1702
[A[ATraining Step: 47  | total loss: [1m[32m0.34736[0m[0m | time: 451.825s
[2K
| Adam | epoch: 001 | loss: 0.34736 - acc: 0.8607 -- iter: 1504/1702
[A[ATraining Step: 48  | total loss: [1m[32m0.36930[0m[0m | time: 459.581s
[2K
| Adam | epoch: 001 | loss: 0.36930 - acc: 0.8530 -- iter: 1536/1702
[A[ATraining Step: 49  | total loss: [1m[32m0.37731[0m[0m | time: 467.363s
[2K
| Adam | epoch: 001 | loss: 0.37731 - acc: 0.8515 -- iter: 1568/1702
[A[ATraining Step: 50  | total loss: [1m[32m0.37589[0m[0m | time: 475.183s
[2K
| Adam | epoch: 001 | loss: 0.37589 - acc: 0.8455 -- iter: 1600/1702
[A[ATraining Step: 51  | total loss: [1m[32m0.41742[0m[0m | time: 483.005s
[2K
| Adam | epoch: 001 | loss: 0.41742 - acc: 0.8261 -- iter: 1632/1702
[A[ATraining Step: 52  | total loss: [1m[32m0.42263[0m[0m | time: 490.728s
[2K
| Adam | epoch: 001 | loss: 0.42263 - acc: 0.8147 -- iter: 1664/1702
[A[ATraining Step: 53  | total loss: [1m[32m0.42615[0m[0m | time: 498.512s
[2K
| Adam | epoch: 001 | loss: 0.42615 - acc: 0.8144 -- iter: 1696/1702
[A[ATraining Step: 54  | total loss: [1m[32m0.41789[0m[0m | time: 529.657s
[2K
| Adam | epoch: 001 | loss: 0.41789 - acc: 0.8186 | val_loss: 0.76743 - val_acc: 0.6792 -- iter: 1702/1702
--
Training Step: 55  | total loss: [1m[32m0.49715[0m[0m | time: 2.308s
[2K
| Adam | epoch: 002 | loss: 0.49715 - acc: 0.7969 -- iter: 0032/1702
[A[ATraining Step: 56  | total loss: [1m[32m0.49561[0m[0m | time: 10.070s
[2K
| Adam | epoch: 002 | loss: 0.49561 - acc: 0.8021 -- iter: 0064/1702
[A[ATraining Step: 57  | total loss: [1m[32m0.49692[0m[0m | time: 18.002s
[2K
| Adam | epoch: 002 | loss: 0.49692 - acc: 0.7905 -- iter: 0096/1702
[A[ATraining Step: 58  | total loss: [1m[32m0.52789[0m[0m | time: 25.757s
[2K
| Adam | epoch: 002 | loss: 0.52789 - acc: 0.7679 -- iter: 0128/1702
[A[ATraining Step: 59  | total loss: [1m[32m0.52649[0m[0m | time: 33.524s
[2K
| Adam | epoch: 002 | loss: 0.52649 - acc: 0.7739 -- iter: 0160/1702
[A[ATraining Step: 60  | total loss: [1m[32m0.53537[0m[0m | time: 41.413s
[2K
| Adam | epoch: 002 | loss: 0.53537 - acc: 0.7584 -- iter: 0192/1702
[A[ATraining Step: 61  | total loss: [1m[32m0.53955[0m[0m | time: 49.236s
[2K
| Adam | epoch: 002 | loss: 0.53955 - acc: 0.7450 -- iter: 0224/1702
[A[ATraining Step: 62  | total loss: [1m[32m0.52557[0m[0m | time: 56.978s
[2K
| Adam | epoch: 002 | loss: 0.52557 - acc: 0.7577 -- iter: 0256/1702
[A[ATraining Step: 63  | total loss: [1m[32m0.52500[0m[0m | time: 64.694s
[2K
| Adam | epoch: 002 | loss: 0.52500 - acc: 0.7647 -- iter: 0288/1702
[A[ATraining Step: 64  | total loss: [1m[32m0.53057[0m[0m | time: 72.637s
[2K
| Adam | epoch: 002 | loss: 0.53057 - acc: 0.7589 -- iter: 0320/1702
[A[ATraining Step: 65  | total loss: [1m[32m0.53934[0m[0m | time: 80.492s
[2K
| Adam | epoch: 002 | loss: 0.53934 - acc: 0.7463 -- iter: 0352/1702
[A[ATraining Step: 66  | total loss: [1m[32m0.52480[0m[0m | time: 88.287s
[2K
| Adam | epoch: 002 | loss: 0.52480 - acc: 0.7467 -- iter: 0384/1702
[A[ATraining Step: 67  | total loss: [1m[32m0.50115[0m[0m | time: 95.947s
[2K
| Adam | epoch: 002 | loss: 0.50115 - acc: 0.7659 -- iter: 0416/1702
[A[ATraining Step: 68  | total loss: [1m[32m0.48762[0m[0m | time: 103.684s
[2K
| Adam | epoch: 002 | loss: 0.48762 - acc: 0.7788 -- iter: 0448/1702
[A[ATraining Step: 69  | total loss: [1m[32m0.49264[0m[0m | time: 111.539s
[2K
| Adam | epoch: 002 | loss: 0.49264 - acc: 0.7754 -- iter: 0480/1702
[A[ATraining Step: 70  | total loss: [1m[32m0.47837[0m[0m | time: 119.283s
[2K
| Adam | epoch: 002 | loss: 0.47837 - acc: 0.7833 -- iter: 0512/1702
[A[ATraining Step: 71  | total loss: [1m[32m0.46122[0m[0m | time: 127.101s
[2K
| Adam | epoch: 002 | loss: 0.46122 - acc: 0.7831 -- iter: 0544/1702
[A[ATraining Step: 72  | total loss: [1m[32m0.44117[0m[0m | time: 134.912s
[2K
| Adam | epoch: 002 | loss: 0.44117 - acc: 0.7934 -- iter: 0576/1702
[A[ATraining Step: 73  | total loss: [1m[32m0.42484[0m[0m | time: 142.739s
[2K
| Adam | epoch: 002 | loss: 0.42484 - acc: 0.8060 -- iter: 0608/1702
[A[ATraining Step: 74  | total loss: [1m[32m0.41928[0m[0m | time: 150.585s
[2K
| Adam | epoch: 002 | loss: 0.41928 - acc: 0.8067 -- iter: 0640/1702
[A[ATraining Step: 75  | total loss: [1m[32m0.39524[0m[0m | time: 158.316s
[2K
| Adam | epoch: 002 | loss: 0.39524 - acc: 0.8209 -- iter: 0672/1702
[A[ATraining Step: 76  | total loss: [1m[32m0.38033[0m[0m | time: 166.277s
[2K
| Adam | epoch: 002 | loss: 0.38033 - acc: 0.8300 -- iter: 0704/1702
[A[ATraining Step: 77  | total loss: [1m[32m0.40088[0m[0m | time: 173.966s
[2K
| Adam | epoch: 002 | loss: 0.40088 - acc: 0.8215 -- iter: 0736/1702
[A[ATraining Step: 78  | total loss: [1m[32m0.40693[0m[0m | time: 181.946s
[2K
| Adam | epoch: 002 | loss: 0.40693 - acc: 0.8271 -- iter: 0768/1702
[A[ATraining Step: 79  | total loss: [1m[32m0.41912[0m[0m | time: 189.787s
[2K
| Adam | epoch: 002 | loss: 0.41912 - acc: 0.8289 -- iter: 0800/1702
[A[ATraining Step: 80  | total loss: [1m[32m0.41223[0m[0m | time: 197.602s
[2K
| Adam | epoch: 002 | loss: 0.41223 - acc: 0.8304 -- iter: 0832/1702
[A[ATraining Step: 81  | total loss: [1m[32m0.40791[0m[0m | time: 205.288s
[2K
| Adam | epoch: 002 | loss: 0.40791 - acc: 0.8349 -- iter: 0864/1702
[A[ATraining Step: 82  | total loss: [1m[32m0.41659[0m[0m | time: 212.987s
[2K
| Adam | epoch: 002 | loss: 0.41659 - acc: 0.8264 -- iter: 0896/1702
[A[ATraining Step: 83  | total loss: [1m[32m0.41566[0m[0m | time: 220.629s
[2K
| Adam | epoch: 002 | loss: 0.41566 - acc: 0.8219 -- iter: 0928/1702
[A[ATraining Step: 84  | total loss: [1m[32m0.41980[0m[0m | time: 228.431s
[2K
| Adam | epoch: 002 | loss: 0.41980 - acc: 0.8241 -- iter: 0960/1702
[A[ATraining Step: 85  | total loss: [1m[32m0.41889[0m[0m | time: 236.212s
[2K
| Adam | epoch: 002 | loss: 0.41889 - acc: 0.8323 -- iter: 0992/1702
[A[ATraining Step: 86  | total loss: [1m[32m0.40132[0m[0m | time: 243.978s
[2K
| Adam | epoch: 002 | loss: 0.40132 - acc: 0.8428 -- iter: 1024/1702
[A[ATraining Step: 87  | total loss: [1m[32m0.38752[0m[0m | time: 251.859s
[2K
| Adam | epoch: 002 | loss: 0.38752 - acc: 0.8460 -- iter: 1056/1702
[A[ATraining Step: 88  | total loss: [1m[32m0.38217[0m[0m | time: 259.707s
[2K
| Adam | epoch: 002 | loss: 0.38217 - acc: 0.8489 -- iter: 1088/1702
[A[ATraining Step: 89  | total loss: [1m[32m0.36797[0m[0m | time: 267.583s
[2K
| Adam | epoch: 002 | loss: 0.36797 - acc: 0.8547 -- iter: 1120/1702
[A[ATraining Step: 90  | total loss: [1m[32m0.35252[0m[0m | time: 275.353s
[2K
| Adam | epoch: 002 | loss: 0.35252 - acc: 0.8598 -- iter: 1152/1702
[A[ATraining Step: 91  | total loss: [1m[32m0.33759[0m[0m | time: 283.421s
[2K
| Adam | epoch: 002 | loss: 0.33759 - acc: 0.8676 -- iter: 1184/1702
[A[ATraining Step: 92  | total loss: [1m[32m0.33401[0m[0m | time: 291.283s
[2K
| Adam | epoch: 002 | loss: 0.33401 - acc: 0.8683 -- iter: 1216/1702
[A[ATraining Step: 93  | total loss: [1m[32m0.34765[0m[0m | time: 298.990s
[2K
| Adam | epoch: 002 | loss: 0.34765 - acc: 0.8690 -- iter: 1248/1702
[A[ATraining Step: 94  | total loss: [1m[32m0.37526[0m[0m | time: 306.719s
[2K
| Adam | epoch: 002 | loss: 0.37526 - acc: 0.8602 -- iter: 1280/1702
[A[ATraining Step: 95  | total loss: [1m[32m0.34873[0m[0m | time: 314.691s
[2K
| Adam | epoch: 002 | loss: 0.34873 - acc: 0.8711 -- iter: 1312/1702
[A[ATraining Step: 96  | total loss: [1m[32m0.34889[0m[0m | time: 322.450s
[2K
| Adam | epoch: 002 | loss: 0.34889 - acc: 0.8683 -- iter: 1344/1702
[A[ATraining Step: 97  | total loss: [1m[32m0.35119[0m[0m | time: 330.290s
[2K
| Adam | epoch: 002 | loss: 0.35119 - acc: 0.8628 -- iter: 1376/1702
[A[ATraining Step: 98  | total loss: [1m[32m0.33147[0m[0m | time: 338.204s
[2K
| Adam | epoch: 002 | loss: 0.33147 - acc: 0.8734 -- iter: 1408/1702
[A[ATraining Step: 99  | total loss: [1m[32m0.32236[0m[0m | time: 346.012s
[2K
| Adam | epoch: 002 | loss: 0.32236 - acc: 0.8735 -- iter: 1440/1702
[A[ATraining Step: 100  | total loss: [1m[32m0.32011[0m[0m | time: 353.789s
[2K
| Adam | epoch: 002 | loss: 0.32011 - acc: 0.8737 -- iter: 1472/1702
[A[ATraining Step: 101  | total loss: [1m[32m0.30243[0m[0m | time: 361.599s
[2K
| Adam | epoch: 002 | loss: 0.30243 - acc: 0.8863 -- iter: 1504/1702
[A[ATraining Step: 102  | total loss: [1m[32m0.29227[0m[0m | time: 369.275s
[2K
| Adam | epoch: 002 | loss: 0.29227 - acc: 0.8914 -- iter: 1536/1702
[A[ATraining Step: 103  | total loss: [1m[32m0.29691[0m[0m | time: 377.246s
[2K
| Adam | epoch: 002 | loss: 0.29691 - acc: 0.8929 -- iter: 1568/1702
[A[ATraining Step: 104  | total loss: [1m[32m0.28867[0m[0m | time: 385.087s
[2K
| Adam | epoch: 002 | loss: 0.28867 - acc: 0.9005 -- iter: 1600/1702
[A[ATraining Step: 105  | total loss: [1m[32m0.28689[0m[0m | time: 393.013s
[2K
| Adam | epoch: 002 | loss: 0.28689 - acc: 0.9042 -- iter: 1632/1702
[A[ATraining Step: 106  | total loss: [1m[32m0.28584[0m[0m | time: 400.851s
[2K
| Adam | epoch: 002 | loss: 0.28584 - acc: 0.9013 -- iter: 1664/1702
[A[ATraining Step: 107  | total loss: [1m[32m0.31062[0m[0m | time: 408.610s
[2K
| Adam | epoch: 002 | loss: 0.31062 - acc: 0.8893 -- iter: 1696/1702
[A[ATraining Step: 108  | total loss: [1m[32m0.31343[0m[0m | time: 439.963s
[2K
| Adam | epoch: 002 | loss: 0.31343 - acc: 0.8941 | val_loss: 0.97955 - val_acc: 0.5685 -- iter: 1702/1702
--
Training Step: 109  | total loss: [1m[32m0.30592[0m[0m | time: 2.221s
[2K
| Adam | epoch: 003 | loss: 0.30592 - acc: 0.9016 -- iter: 0032/1702
[A[ATraining Step: 110  | total loss: [1m[32m0.31245[0m[0m | time: 4.453s
[2K
| Adam | epoch: 003 | loss: 0.31245 - acc: 0.8947 -- iter: 0064/1702
[A[ATraining Step: 111  | total loss: [1m[32m0.29403[0m[0m | time: 12.215s
[2K
| Adam | epoch: 003 | loss: 0.29403 - acc: 0.9053 -- iter: 0096/1702
[A[ATraining Step: 112  | total loss: [1m[32m0.31089[0m[0m | time: 19.923s
[2K
| Adam | epoch: 003 | loss: 0.31089 - acc: 0.8897 -- iter: 0128/1702
[A[ATraining Step: 113  | total loss: [1m[32m0.33121[0m[0m | time: 27.730s
[2K
| Adam | epoch: 003 | loss: 0.33121 - acc: 0.8758 -- iter: 0160/1702
[A[ATraining Step: 114  | total loss: [1m[32m0.34105[0m[0m | time: 35.363s
[2K
| Adam | epoch: 003 | loss: 0.34105 - acc: 0.8726 -- iter: 0192/1702
[A[ATraining Step: 115  | total loss: [1m[32m0.38543[0m[0m | time: 43.047s
[2K
| Adam | epoch: 003 | loss: 0.38543 - acc: 0.8541 -- iter: 0224/1702
[A[ATraining Step: 116  | total loss: [1m[32m0.42192[0m[0m | time: 50.834s
[2K
| Adam | epoch: 003 | loss: 0.42192 - acc: 0.8499 -- iter: 0256/1702
[A[ATraining Step: 117  | total loss: [1m[32m0.41103[0m[0m | time: 58.539s
[2K
| Adam | epoch: 003 | loss: 0.41103 - acc: 0.8524 -- iter: 0288/1702
[A[ATraining Step: 118  | total loss: [1m[32m0.40455[0m[0m | time: 66.326s
[2K
| Adam | epoch: 003 | loss: 0.40455 - acc: 0.8547 -- iter: 0320/1702
[A[ATraining Step: 119  | total loss: [1m[32m0.39181[0m[0m | time: 74.188s
[2K
| Adam | epoch: 003 | loss: 0.39181 - acc: 0.8598 -- iter: 0352/1702
[A[ATraining Step: 120  | total loss: [1m[32m0.37141[0m[0m | time: 81.887s
[2K
| Adam | epoch: 003 | loss: 0.37141 - acc: 0.8582 -- iter: 0384/1702
[A[ATraining Step: 121  | total loss: [1m[32m0.35480[0m[0m | time: 89.618s
[2K
| Adam | epoch: 003 | loss: 0.35480 - acc: 0.8661 -- iter: 0416/1702
[A[ATraining Step: 122  | total loss: [1m[32m0.34211[0m[0m | time: 97.446s
[2K
| Adam | epoch: 003 | loss: 0.34211 - acc: 0.8670 -- iter: 0448/1702
[A[ATraining Step: 123  | total loss: [1m[32m0.34818[0m[0m | time: 105.247s
[2K
| Adam | epoch: 003 | loss: 0.34818 - acc: 0.8710 -- iter: 0480/1702
[A[ATraining Step: 124  | total loss: [1m[32m0.35508[0m[0m | time: 113.250s
[2K
| Adam | epoch: 003 | loss: 0.35508 - acc: 0.8682 -- iter: 0512/1702
[A[ATraining Step: 125  | total loss: [1m[32m0.34204[0m[0m | time: 120.873s
[2K
| Adam | epoch: 003 | loss: 0.34204 - acc: 0.8689 -- iter: 0544/1702
[A[ATraining Step: 126  | total loss: [1m[32m0.33573[0m[0m | time: 128.649s
[2K
| Adam | epoch: 003 | loss: 0.33573 - acc: 0.8726 -- iter: 0576/1702
[A[ATraining Step: 127  | total loss: [1m[32m0.37015[0m[0m | time: 136.382s
[2K
| Adam | epoch: 003 | loss: 0.37015 - acc: 0.8698 -- iter: 0608/1702
[A[ATraining Step: 128  | total loss: [1m[32m0.34443[0m[0m | time: 144.243s
[2K
| Adam | epoch: 003 | loss: 0.34443 - acc: 0.8797 -- iter: 0640/1702
[A[ATraining Step: 129  | total loss: [1m[32m0.32096[0m[0m | time: 151.979s
[2K
| Adam | epoch: 003 | loss: 0.32096 - acc: 0.8917 -- iter: 0672/1702
[A[ATraining Step: 130  | total loss: [1m[32m0.30549[0m[0m | time: 159.794s
[2K
| Adam | epoch: 003 | loss: 0.30549 - acc: 0.8931 -- iter: 0704/1702
[A[ATraining Step: 131  | total loss: [1m[32m0.29437[0m[0m | time: 167.590s
[2K
| Adam | epoch: 003 | loss: 0.29437 - acc: 0.8945 -- iter: 0736/1702
[A[ATraining Step: 132  | total loss: [1m[32m0.28570[0m[0m | time: 175.544s
[2K
| Adam | epoch: 003 | loss: 0.28570 - acc: 0.8988 -- iter: 0768/1702
[A[ATraining Step: 133  | total loss: [1m[32m0.27548[0m[0m | time: 183.284s
[2K
| Adam | epoch: 003 | loss: 0.27548 - acc: 0.9058 -- iter: 0800/1702
[A[ATraining Step: 134  | total loss: [1m[32m0.28185[0m[0m | time: 191.093s
[2K
| Adam | epoch: 003 | loss: 0.28185 - acc: 0.9058 -- iter: 0832/1702
[A[ATraining Step: 135  | total loss: [1m[32m0.27564[0m[0m | time: 198.849s
[2K
| Adam | epoch: 003 | loss: 0.27564 - acc: 0.9027 -- iter: 0864/1702
[A[ATraining Step: 136  | total loss: [1m[32m0.28671[0m[0m | time: 206.725s
[2K
| Adam | epoch: 003 | loss: 0.28671 - acc: 0.9031 -- iter: 0896/1702
[A[ATraining Step: 137  | total loss: [1m[32m0.29325[0m[0m | time: 214.397s
[2K
| Adam | epoch: 003 | loss: 0.29325 - acc: 0.9003 -- iter: 0928/1702
[A[ATraining Step: 138  | total loss: [1m[32m0.28098[0m[0m | time: 222.151s
[2K
| Adam | epoch: 003 | loss: 0.28098 - acc: 0.9009 -- iter: 0960/1702
[A[ATraining Step: 139  | total loss: [1m[32m0.27215[0m[0m | time: 229.780s
[2K
| Adam | epoch: 003 | loss: 0.27215 - acc: 0.9045 -- iter: 0992/1702
[A[ATraining Step: 140  | total loss: [1m[32m0.27932[0m[0m | time: 237.560s
[2K
| Adam | epoch: 003 | loss: 0.27932 - acc: 0.9078 -- iter: 1024/1702
[A[ATraining Step: 141  | total loss: [1m[32m0.26737[0m[0m | time: 245.407s
[2K
| Adam | epoch: 003 | loss: 0.26737 - acc: 0.9108 -- iter: 1056/1702
[A[ATraining Step: 142  | total loss: [1m[32m0.26171[0m[0m | time: 253.292s
[2K
| Adam | epoch: 003 | loss: 0.26171 - acc: 0.9103 -- iter: 1088/1702
[A[ATraining Step: 143  | total loss: [1m[32m0.25132[0m[0m | time: 260.937s
[2K
| Adam | epoch: 003 | loss: 0.25132 - acc: 0.9162 -- iter: 1120/1702
[A[ATraining Step: 144  | total loss: [1m[32m0.24100[0m[0m | time: 268.714s
[2K
| Adam | epoch: 003 | loss: 0.24100 - acc: 0.9183 -- iter: 1152/1702
[A[ATraining Step: 145  | total loss: [1m[32m0.24105[0m[0m | time: 276.483s
[2K
| Adam | epoch: 003 | loss: 0.24105 - acc: 0.9171 -- iter: 1184/1702
[A[ATraining Step: 146  | total loss: [1m[32m0.23021[0m[0m | time: 284.187s
[2K
| Adam | epoch: 003 | loss: 0.23021 - acc: 0.9223 -- iter: 1216/1702
[A[ATraining Step: 147  | total loss: [1m[32m0.21354[0m[0m | time: 291.841s
[2K
| Adam | epoch: 003 | loss: 0.21354 - acc: 0.9300 -- iter: 1248/1702
[A[ATraining Step: 148  | total loss: [1m[32m0.20290[0m[0m | time: 299.797s
[2K
| Adam | epoch: 003 | loss: 0.20290 - acc: 0.9339 -- iter: 1280/1702
[A[ATraining Step: 149  | total loss: [1m[32m0.19721[0m[0m | time: 307.542s
[2K
| Adam | epoch: 003 | loss: 0.19721 - acc: 0.9343 -- iter: 1312/1702
[A[ATraining Step: 150  | total loss: [1m[32m0.18618[0m[0m | time: 315.324s
[2K
| Adam | epoch: 003 | loss: 0.18618 - acc: 0.9377 -- iter: 1344/1702
[A[ATraining Step: 151  | total loss: [1m[32m0.19709[0m[0m | time: 323.077s
[2K
| Adam | epoch: 003 | loss: 0.19709 - acc: 0.9252 -- iter: 1376/1702
[A[ATraining Step: 152  | total loss: [1m[32m0.21500[0m[0m | time: 330.927s
[2K
| Adam | epoch: 003 | loss: 0.21500 - acc: 0.9202 -- iter: 1408/1702
[A[ATraining Step: 153  | total loss: [1m[32m0.25699[0m[0m | time: 338.751s
[2K
| Adam | epoch: 003 | loss: 0.25699 - acc: 0.9188 -- iter: 1440/1702
[A[ATraining Step: 154  | total loss: [1m[32m0.23619[0m[0m | time: 346.577s
[2K
| Adam | epoch: 003 | loss: 0.23619 - acc: 0.9269 -- iter: 1472/1702
[A[ATraining Step: 155  | total loss: [1m[32m0.24301[0m[0m | time: 354.413s
[2K
| Adam | epoch: 003 | loss: 0.24301 - acc: 0.9248 -- iter: 1504/1702
[A[ATraining Step: 156  | total loss: [1m[32m0.23777[0m[0m | time: 362.272s
[2K
| Adam | epoch: 003 | loss: 0.23777 - acc: 0.9230 -- iter: 1536/1702
[A[ATraining Step: 157  | total loss: [1m[32m0.24497[0m[0m | time: 369.986s
[2K
| Adam | epoch: 003 | loss: 0.24497 - acc: 0.9151 -- iter: 1568/1702
[A[ATraining Step: 158  | total loss: [1m[32m0.23747[0m[0m | time: 377.749s
[2K
| Adam | epoch: 003 | loss: 0.23747 - acc: 0.9204 -- iter: 1600/1702
[A[ATraining Step: 159  | total loss: [1m[32m0.24019[0m[0m | time: 385.447s
[2K
| Adam | epoch: 003 | loss: 0.24019 - acc: 0.9190 -- iter: 1632/1702
[A[ATraining Step: 160  | total loss: [1m[32m0.24913[0m[0m | time: 393.236s
[2K
| Adam | epoch: 003 | loss: 0.24913 - acc: 0.9146 -- iter: 1664/1702
[A[ATraining Step: 161  | total loss: [1m[32m0.25880[0m[0m | time: 400.985s
[2K
| Adam | epoch: 003 | loss: 0.25880 - acc: 0.9106 -- iter: 1696/1702
[A[ATraining Step: 162  | total loss: [1m[32m0.27260[0m[0m | time: 432.271s
[2K
| Adam | epoch: 003 | loss: 0.27260 - acc: 0.9008 | val_loss: 0.95692 - val_acc: 0.7280 -- iter: 1702/1702
--
Training Step: 163  | total loss: [1m[32m0.28842[0m[0m | time: 7.733s
[2K
| Adam | epoch: 004 | loss: 0.28842 - acc: 0.8951 -- iter: 0032/1702
[A[ATraining Step: 164  | total loss: [1m[32m0.29694[0m[0m | time: 9.886s
[2K
| Adam | epoch: 004 | loss: 0.29694 - acc: 0.8869 -- iter: 0064/1702
[A[ATraining Step: 165  | total loss: [1m[32m0.30592[0m[0m | time: 12.111s
[2K
| Adam | epoch: 004 | loss: 0.30592 - acc: 0.8815 -- iter: 0096/1702
[A[ATraining Step: 166  | total loss: [1m[32m0.28351[0m[0m | time: 19.778s
[2K
| Adam | epoch: 004 | loss: 0.28351 - acc: 0.8934 -- iter: 0128/1702
[A[ATraining Step: 167  | total loss: [1m[32m0.29523[0m[0m | time: 27.424s
[2K
| Adam | epoch: 004 | loss: 0.29523 - acc: 0.8915 -- iter: 0160/1702
[A[ATraining Step: 168  | total loss: [1m[32m0.28623[0m[0m | time: 35.223s
[2K
| Adam | epoch: 004 | loss: 0.28623 - acc: 0.8930 -- iter: 0192/1702
[A[ATraining Step: 169  | total loss: [1m[32m0.34392[0m[0m | time: 42.952s
[2K
| Adam | epoch: 004 | loss: 0.34392 - acc: 0.8693 -- iter: 0224/1702
[A[ATraining Step: 170  | total loss: [1m[32m0.32434[0m[0m | time: 50.782s
[2K
| Adam | epoch: 004 | loss: 0.32434 - acc: 0.8793 -- iter: 0256/1702
[A[ATraining Step: 171  | total loss: [1m[32m0.32346[0m[0m | time: 58.474s
[2K
| Adam | epoch: 004 | loss: 0.32346 - acc: 0.8820 -- iter: 0288/1702
[A[ATraining Step: 172  | total loss: [1m[32m0.31865[0m[0m | time: 66.260s
[2K
| Adam | epoch: 004 | loss: 0.31865 - acc: 0.8844 -- iter: 0320/1702
[A[ATraining Step: 173  | total loss: [1m[32m0.31668[0m[0m | time: 73.927s
[2K
| Adam | epoch: 004 | loss: 0.31668 - acc: 0.8835 -- iter: 0352/1702
[A[ATraining Step: 174  | total loss: [1m[32m0.29623[0m[0m | time: 81.719s
[2K
| Adam | epoch: 004 | loss: 0.29623 - acc: 0.8920 -- iter: 0384/1702
[A[ATraining Step: 175  | total loss: [1m[32m0.28647[0m[0m | time: 89.340s
[2K
| Adam | epoch: 004 | loss: 0.28647 - acc: 0.8965 -- iter: 0416/1702
[A[ATraining Step: 176  | total loss: [1m[32m0.28535[0m[0m | time: 97.005s
[2K
| Adam | epoch: 004 | loss: 0.28535 - acc: 0.8975 -- iter: 0448/1702
[A[ATraining Step: 177  | total loss: [1m[32m0.27955[0m[0m | time: 104.712s
[2K
| Adam | epoch: 004 | loss: 0.27955 - acc: 0.8953 -- iter: 0480/1702
[A[ATraining Step: 178  | total loss: [1m[32m0.30035[0m[0m | time: 112.497s
[2K
| Adam | epoch: 004 | loss: 0.30035 - acc: 0.8839 -- iter: 0512/1702
[A[ATraining Step: 179  | total loss: [1m[32m0.30142[0m[0m | time: 120.244s
[2K
| Adam | epoch: 004 | loss: 0.30142 - acc: 0.8798 -- iter: 0544/1702
[A[ATraining Step: 180  | total loss: [1m[32m0.32491[0m[0m | time: 128.154s
[2K
| Adam | epoch: 004 | loss: 0.32491 - acc: 0.8731 -- iter: 0576/1702
[A[ATraining Step: 181  | total loss: [1m[32m0.31626[0m[0m | time: 135.840s
[2K
| Adam | epoch: 004 | loss: 0.31626 - acc: 0.8764 -- iter: 0608/1702
[A[ATraining Step: 182  | total loss: [1m[32m0.31291[0m[0m | time: 143.746s
[2K
| Adam | epoch: 004 | loss: 0.31291 - acc: 0.8794 -- iter: 0640/1702
[A[ATraining Step: 183  | total loss: [1m[32m0.30042[0m[0m | time: 151.454s
[2K
| Adam | epoch: 004 | loss: 0.30042 - acc: 0.8821 -- iter: 0672/1702
[A[ATraining Step: 184  | total loss: [1m[32m0.29215[0m[0m | time: 159.199s
[2K
| Adam | epoch: 004 | loss: 0.29215 - acc: 0.8845 -- iter: 0704/1702
[A[ATraining Step: 185  | total loss: [1m[32m0.29820[0m[0m | time: 166.983s
[2K
| Adam | epoch: 004 | loss: 0.29820 - acc: 0.8836 -- iter: 0736/1702
[A[ATraining Step: 186  | total loss: [1m[32m0.29478[0m[0m | time: 174.694s
[2K
| Adam | epoch: 004 | loss: 0.29478 - acc: 0.8827 -- iter: 0768/1702
[A[ATraining Step: 187  | total loss: [1m[32m0.29261[0m[0m | time: 182.317s
[2K
| Adam | epoch: 004 | loss: 0.29261 - acc: 0.8819 -- iter: 0800/1702
[A[ATraining Step: 188  | total loss: [1m[32m0.29893[0m[0m | time: 190.209s
[2K
| Adam | epoch: 004 | loss: 0.29893 - acc: 0.8844 -- iter: 0832/1702
[A[ATraining Step: 189  | total loss: [1m[32m0.29931[0m[0m | time: 197.936s
[2K
| Adam | epoch: 004 | loss: 0.29931 - acc: 0.8772 -- iter: 0864/1702
[A[ATraining Step: 190  | total loss: [1m[32m0.29136[0m[0m | time: 205.847s
[2K
| Adam | epoch: 004 | loss: 0.29136 - acc: 0.8832 -- iter: 0896/1702
[A[ATraining Step: 191  | total loss: [1m[32m0.28432[0m[0m | time: 213.627s
[2K
| Adam | epoch: 004 | loss: 0.28432 - acc: 0.8855 -- iter: 0928/1702
[A[ATraining Step: 192  | total loss: [1m[32m0.28006[0m[0m | time: 221.350s
[2K
| Adam | epoch: 004 | loss: 0.28006 - acc: 0.8813 -- iter: 0960/1702
[A[ATraining Step: 193  | total loss: [1m[32m0.26150[0m[0m | time: 229.209s
[2K
| Adam | epoch: 004 | loss: 0.26150 - acc: 0.8901 -- iter: 0992/1702
[A[ATraining Step: 194  | total loss: [1m[32m0.24834[0m[0m | time: 236.930s
[2K
| Adam | epoch: 004 | loss: 0.24834 - acc: 0.8979 -- iter: 1024/1702
[A[ATraining Step: 195  | total loss: [1m[32m0.24338[0m[0m | time: 244.714s
[2K
| Adam | epoch: 004 | loss: 0.24338 - acc: 0.8957 -- iter: 1056/1702
[A[ATraining Step: 196  | total loss: [1m[32m0.23605[0m[0m | time: 252.538s
[2K
| Adam | epoch: 004 | loss: 0.23605 - acc: 0.8998 -- iter: 1088/1702
[A[ATraining Step: 197  | total loss: [1m[32m0.23371[0m[0m | time: 260.354s
[2K
| Adam | epoch: 004 | loss: 0.23371 - acc: 0.8942 -- iter: 1120/1702
[A[ATraining Step: 198  | total loss: [1m[32m0.23947[0m[0m | time: 268.035s
[2K
| Adam | epoch: 004 | loss: 0.23947 - acc: 0.8986 -- iter: 1152/1702
[A[ATraining Step: 199  | total loss: [1m[32m0.24047[0m[0m | time: 275.606s
[2K
| Adam | epoch: 004 | loss: 0.24047 - acc: 0.9024 -- iter: 1184/1702
[A[ATraining Step: 200  | total loss: [1m[32m0.24620[0m[0m | time: 306.723s
[2K
| Adam | epoch: 004 | loss: 0.24620 - acc: 0.8997 | val_loss: 0.69794 - val_acc: 0.7092 -- iter: 1216/1702
--
Training Step: 201  | total loss: [1m[32m0.23356[0m[0m | time: 314.382s
[2K
| Adam | epoch: 004 | loss: 0.23356 - acc: 0.9066 -- iter: 1248/1702
[A[ATraining Step: 202  | total loss: [1m[32m0.22053[0m[0m | time: 322.266s
[2K
| Adam | epoch: 004 | loss: 0.22053 - acc: 0.9128 -- iter: 1280/1702
[A[ATraining Step: 203  | total loss: [1m[32m0.20762[0m[0m | time: 329.944s
[2K
| Adam | epoch: 004 | loss: 0.20762 - acc: 0.9184 -- iter: 1312/1702
[A[ATraining Step: 204  | total loss: [1m[32m0.19687[0m[0m | time: 337.699s
[2K
| Adam | epoch: 004 | loss: 0.19687 - acc: 0.9234 -- iter: 1344/1702
[A[ATraining Step: 205  | total loss: [1m[32m0.19122[0m[0m | time: 345.418s
[2K
| Adam | epoch: 004 | loss: 0.19122 - acc: 0.9249 -- iter: 1376/1702
[A[ATraining Step: 206  | total loss: [1m[32m0.20453[0m[0m | time: 353.351s
[2K
| Adam | epoch: 004 | loss: 0.20453 - acc: 0.9167 -- iter: 1408/1702
[A[ATraining Step: 207  | total loss: [1m[32m0.20529[0m[0m | time: 361.224s
[2K
| Adam | epoch: 004 | loss: 0.20529 - acc: 0.9157 -- iter: 1440/1702
[A[ATraining Step: 208  | total loss: [1m[32m0.19025[0m[0m | time: 368.904s
[2K
| Adam | epoch: 004 | loss: 0.19025 - acc: 0.9241 -- iter: 1472/1702
[A[ATraining Step: 209  | total loss: [1m[32m0.21363[0m[0m | time: 376.736s
[2K
| Adam | epoch: 004 | loss: 0.21363 - acc: 0.9130 -- iter: 1504/1702
[A[ATraining Step: 210  | total loss: [1m[32m0.21150[0m[0m | time: 384.474s
[2K
| Adam | epoch: 004 | loss: 0.21150 - acc: 0.9123 -- iter: 1536/1702
[A[ATraining Step: 211  | total loss: [1m[32m0.21471[0m[0m | time: 392.261s
[2K
| Adam | epoch: 004 | loss: 0.21471 - acc: 0.9054 -- iter: 1568/1702
[A[ATraining Step: 212  | total loss: [1m[32m0.21070[0m[0m | time: 400.014s
[2K
| Adam | epoch: 004 | loss: 0.21070 - acc: 0.9086 -- iter: 1600/1702
[A[ATraining Step: 213  | total loss: [1m[32m0.19748[0m[0m | time: 407.782s
[2K
| Adam | epoch: 004 | loss: 0.19748 - acc: 0.9147 -- iter: 1632/1702
[A[ATraining Step: 214  | total loss: [1m[32m0.20432[0m[0m | time: 415.562s
[2K
| Adam | epoch: 004 | loss: 0.20432 - acc: 0.9169 -- iter: 1664/1702
[A[ATraining Step: 215  | total loss: [1m[32m0.21874[0m[0m | time: 423.426s
[2K
| Adam | epoch: 004 | loss: 0.21874 - acc: 0.9127 -- iter: 1696/1702
[A[ATraining Step: 216  | total loss: [1m[32m0.21245[0m[0m | time: 454.693s
[2K
| Adam | epoch: 004 | loss: 0.21245 - acc: 0.9183 | val_loss: 1.00303 - val_acc: 0.6041 -- iter: 1702/1702
--
Training Step: 217  | total loss: [1m[32m0.21235[0m[0m | time: 7.774s
[2K
| Adam | epoch: 005 | loss: 0.21235 - acc: 0.9203 -- iter: 0032/1702
[A[ATraining Step: 218  | total loss: [1m[32m0.21728[0m[0m | time: 15.561s
[2K
| Adam | epoch: 005 | loss: 0.21728 - acc: 0.9157 -- iter: 0064/1702
[A[ATraining Step: 219  | total loss: [1m[32m0.22688[0m[0m | time: 17.758s
[2K
| Adam | epoch: 005 | loss: 0.22688 - acc: 0.9085 -- iter: 0096/1702
[A[ATraining Step: 220  | total loss: [1m[32m0.25253[0m[0m | time: 19.879s
[2K
| Adam | epoch: 005 | loss: 0.25253 - acc: 0.8843 -- iter: 0128/1702
[A[ATraining Step: 221  | total loss: [1m[32m0.24500[0m[0m | time: 27.653s
[2K
| Adam | epoch: 005 | loss: 0.24500 - acc: 0.8959 -- iter: 0160/1702
[A[ATraining Step: 222  | total loss: [1m[32m0.23839[0m[0m | time: 35.371s
[2K
| Adam | epoch: 005 | loss: 0.23839 - acc: 0.9001 -- iter: 0192/1702
[A[ATraining Step: 223  | total loss: [1m[32m0.23070[0m[0m | time: 43.111s
[2K
| Adam | epoch: 005 | loss: 0.23070 - acc: 0.9038 -- iter: 0224/1702
[A[ATraining Step: 224  | total loss: [1m[32m0.22229[0m[0m | time: 50.785s
[2K
| Adam | epoch: 005 | loss: 0.22229 - acc: 0.9072 -- iter: 0256/1702
[A[ATraining Step: 225  | total loss: [1m[32m0.25762[0m[0m | time: 58.483s
[2K
| Adam | epoch: 005 | loss: 0.25762 - acc: 0.8977 -- iter: 0288/1702
[A[ATraining Step: 226  | total loss: [1m[32m0.27219[0m[0m | time: 66.157s
[2K
| Adam | epoch: 005 | loss: 0.27219 - acc: 0.8892 -- iter: 0320/1702
[A[ATraining Step: 227  | total loss: [1m[32m0.33243[0m[0m | time: 73.912s
[2K
| Adam | epoch: 005 | loss: 0.33243 - acc: 0.8721 -- iter: 0352/1702
[A[ATraining Step: 228  | total loss: [1m[32m0.32335[0m[0m | time: 81.648s
[2K
| Adam | epoch: 005 | loss: 0.32335 - acc: 0.8724 -- iter: 0384/1702
[A[ATraining Step: 229  | total loss: [1m[32m0.31229[0m[0m | time: 89.400s
[2K
| Adam | epoch: 005 | loss: 0.31229 - acc: 0.8789 -- iter: 0416/1702
[A[ATraining Step: 230  | total loss: [1m[32m0.29653[0m[0m | time: 97.174s
[2K
| Adam | epoch: 005 | loss: 0.29653 - acc: 0.8879 -- iter: 0448/1702
[A[ATraining Step: 231  | total loss: [1m[32m0.29232[0m[0m | time: 104.866s
[2K
| Adam | epoch: 005 | loss: 0.29232 - acc: 0.8866 -- iter: 0480/1702
[A[ATraining Step: 232  | total loss: [1m[32m0.29920[0m[0m | time: 112.602s
[2K
| Adam | epoch: 005 | loss: 0.29920 - acc: 0.8855 -- iter: 0512/1702
[A[ATraining Step: 233  | total loss: [1m[32m0.30947[0m[0m | time: 120.365s
[2K
| Adam | epoch: 005 | loss: 0.30947 - acc: 0.8844 -- iter: 0544/1702
[A[ATraining Step: 234  | total loss: [1m[32m0.30956[0m[0m | time: 128.238s
[2K
| Adam | epoch: 005 | loss: 0.30956 - acc: 0.8866 -- iter: 0576/1702
[A[ATraining Step: 235  | total loss: [1m[32m0.32743[0m[0m | time: 135.944s
[2K
| Adam | epoch: 005 | loss: 0.32743 - acc: 0.8761 -- iter: 0608/1702
[A[ATraining Step: 236  | total loss: [1m[32m0.31932[0m[0m | time: 143.673s
[2K
| Adam | epoch: 005 | loss: 0.31932 - acc: 0.8760 -- iter: 0640/1702
[A[ATraining Step: 237  | total loss: [1m[32m0.30839[0m[0m | time: 151.411s
[2K
| Adam | epoch: 005 | loss: 0.30839 - acc: 0.8790 -- iter: 0672/1702
[A[ATraining Step: 238  | total loss: [1m[32m0.29145[0m[0m | time: 159.138s
[2K
| Adam | epoch: 005 | loss: 0.29145 - acc: 0.8880 -- iter: 0704/1702
[A[ATraining Step: 239  | total loss: [1m[32m0.27924[0m[0m | time: 167.098s
[2K
| Adam | epoch: 005 | loss: 0.27924 - acc: 0.8929 -- iter: 0736/1702
[A[ATraining Step: 240  | total loss: [1m[32m0.27280[0m[0m | time: 174.757s
[2K
| Adam | epoch: 005 | loss: 0.27280 - acc: 0.8943 -- iter: 0768/1702
[A[ATraining Step: 241  | total loss: [1m[32m0.27918[0m[0m | time: 182.680s
[2K
| Adam | epoch: 005 | loss: 0.27918 - acc: 0.8923 -- iter: 0800/1702
[A[ATraining Step: 242  | total loss: [1m[32m0.28234[0m[0m | time: 190.433s
[2K
| Adam | epoch: 005 | loss: 0.28234 - acc: 0.8906 -- iter: 0832/1702
[A[ATraining Step: 243  | total loss: [1m[32m0.26952[0m[0m | time: 198.171s
[2K
| Adam | epoch: 005 | loss: 0.26952 - acc: 0.8953 -- iter: 0864/1702
[A[ATraining Step: 244  | total loss: [1m[32m0.25544[0m[0m | time: 205.988s
[2K
| Adam | epoch: 005 | loss: 0.25544 - acc: 0.8995 -- iter: 0896/1702
[A[ATraining Step: 245  | total loss: [1m[32m0.24147[0m[0m | time: 213.807s
[2K
| Adam | epoch: 005 | loss: 0.24147 - acc: 0.9064 -- iter: 0928/1702
[A[ATraining Step: 246  | total loss: [1m[32m0.24905[0m[0m | time: 221.504s
[2K
| Adam | epoch: 005 | loss: 0.24905 - acc: 0.9033 -- iter: 0960/1702
[A[ATraining Step: 247  | total loss: [1m[32m0.25618[0m[0m | time: 229.249s
[2K
| Adam | epoch: 005 | loss: 0.25618 - acc: 0.8973 -- iter: 0992/1702
[A[ATraining Step: 248  | total loss: [1m[32m0.27792[0m[0m | time: 236.923s
[2K
| Adam | epoch: 005 | loss: 0.27792 - acc: 0.8857 -- iter: 1024/1702
[A[ATraining Step: 249  | total loss: [1m[32m0.26004[0m[0m | time: 244.716s
[2K
| Adam | epoch: 005 | loss: 0.26004 - acc: 0.8940 -- iter: 1056/1702
[A[ATraining Step: 250  | total loss: [1m[32m0.28241[0m[0m | time: 252.614s
[2K
| Adam | epoch: 005 | loss: 0.28241 - acc: 0.8796 -- iter: 1088/1702
[A[ATraining Step: 251  | total loss: [1m[32m0.28499[0m[0m | time: 260.220s
[2K
| Adam | epoch: 005 | loss: 0.28499 - acc: 0.8854 -- iter: 1120/1702
[A[ATraining Step: 252  | total loss: [1m[32m0.28186[0m[0m | time: 268.023s
[2K
| Adam | epoch: 005 | loss: 0.28186 - acc: 0.8906 -- iter: 1152/1702
[A[ATraining Step: 253  | total loss: [1m[32m0.27731[0m[0m | time: 275.673s
[2K
| Adam | epoch: 005 | loss: 0.27731 - acc: 0.8984 -- iter: 1184/1702
[A[ATraining Step: 254  | total loss: [1m[32m0.26084[0m[0m | time: 283.538s
[2K
| Adam | epoch: 005 | loss: 0.26084 - acc: 0.9086 -- iter: 1216/1702
[A[ATraining Step: 255  | total loss: [1m[32m0.24469[0m[0m | time: 291.235s
[2K
| Adam | epoch: 005 | loss: 0.24469 - acc: 0.9146 -- iter: 1248/1702
[A[ATraining Step: 256  | total loss: [1m[32m0.23862[0m[0m | time: 299.041s
[2K
| Adam | epoch: 005 | loss: 0.23862 - acc: 0.9138 -- iter: 1280/1702
[A[ATraining Step: 257  | total loss: [1m[32m0.23083[0m[0m | time: 306.746s
[2K
| Adam | epoch: 005 | loss: 0.23083 - acc: 0.9161 -- iter: 1312/1702
[A[ATraining Step: 258  | total loss: [1m[32m0.21883[0m[0m | time: 314.510s
[2K
| Adam | epoch: 005 | loss: 0.21883 - acc: 0.9214 -- iter: 1344/1702
[A[ATraining Step: 259  | total loss: [1m[32m0.21152[0m[0m | time: 322.217s
[2K
| Adam | epoch: 005 | loss: 0.21152 - acc: 0.9261 -- iter: 1376/1702
[A[ATraining Step: 260  | total loss: [1m[32m0.22090[0m[0m | time: 329.943s
[2K
| Adam | epoch: 005 | loss: 0.22090 - acc: 0.9210 -- iter: 1408/1702
[A[ATraining Step: 261  | total loss: [1m[32m0.20751[0m[0m | time: 337.825s
[2K
| Adam | epoch: 005 | loss: 0.20751 - acc: 0.9227 -- iter: 1440/1702
[A[ATraining Step: 262  | total loss: [1m[32m0.19835[0m[0m | time: 345.579s
[2K
| Adam | epoch: 005 | loss: 0.19835 - acc: 0.9242 -- iter: 1472/1702
[A[ATraining Step: 263  | total loss: [1m[32m0.18747[0m[0m | time: 353.201s
[2K
| Adam | epoch: 005 | loss: 0.18747 - acc: 0.9317 -- iter: 1504/1702
[A[ATraining Step: 264  | total loss: [1m[32m0.18306[0m[0m | time: 361.168s
[2K
| Adam | epoch: 005 | loss: 0.18306 - acc: 0.9323 -- iter: 1536/1702
[A[ATraining Step: 265  | total loss: [1m[32m0.17873[0m[0m | time: 369.065s
[2K
| Adam | epoch: 005 | loss: 0.17873 - acc: 0.9328 -- iter: 1568/1702
[A[ATraining Step: 266  | total loss: [1m[32m0.17450[0m[0m | time: 376.715s
[2K
| Adam | epoch: 005 | loss: 0.17450 - acc: 0.9302 -- iter: 1600/1702
[A[ATraining Step: 267  | total loss: [1m[32m0.16306[0m[0m | time: 384.570s
[2K
| Adam | epoch: 005 | loss: 0.16306 - acc: 0.9340 -- iter: 1632/1702
[A[ATraining Step: 268  | total loss: [1m[32m0.16960[0m[0m | time: 392.244s
[2K
| Adam | epoch: 005 | loss: 0.16960 - acc: 0.9281 -- iter: 1664/1702
[A[ATraining Step: 269  | total loss: [1m[32m0.16497[0m[0m | time: 400.062s
[2K
| Adam | epoch: 005 | loss: 0.16497 - acc: 0.9322 -- iter: 1696/1702
[A[ATraining Step: 270  | total loss: [1m[32m0.17286[0m[0m | time: 431.063s
[2K
| Adam | epoch: 005 | loss: 0.17286 - acc: 0.9327 | val_loss: 0.98991 - val_acc: 0.6585 -- iter: 1702/1702
--
Training Step: 271  | total loss: [1m[32m0.16187[0m[0m | time: 7.703s
[2K
| Adam | epoch: 006 | loss: 0.16187 - acc: 0.9395 -- iter: 0032/1702
[A[ATraining Step: 272  | total loss: [1m[32m0.16040[0m[0m | time: 15.402s
[2K
| Adam | epoch: 006 | loss: 0.16040 - acc: 0.9330 -- iter: 0064/1702
[A[ATraining Step: 273  | total loss: [1m[32m0.14892[0m[0m | time: 23.087s
[2K
| Adam | epoch: 006 | loss: 0.14892 - acc: 0.9397 -- iter: 0096/1702
[A[ATraining Step: 274  | total loss: [1m[32m0.15233[0m[0m | time: 25.296s
[2K
| Adam | epoch: 006 | loss: 0.15233 - acc: 0.9364 -- iter: 0128/1702
[A[ATraining Step: 275  | total loss: [1m[32m0.14404[0m[0m | time: 27.496s
[2K
| Adam | epoch: 006 | loss: 0.14404 - acc: 0.9427 -- iter: 0160/1702
[A[ATraining Step: 276  | total loss: [1m[32m0.13133[0m[0m | time: 35.162s
[2K
| Adam | epoch: 006 | loss: 0.13133 - acc: 0.9485 -- iter: 0192/1702
[A[ATraining Step: 277  | total loss: [1m[32m0.14734[0m[0m | time: 42.978s
[2K
| Adam | epoch: 006 | loss: 0.14734 - acc: 0.9380 -- iter: 0224/1702
[A[ATraining Step: 278  | total loss: [1m[32m0.17531[0m[0m | time: 50.850s
[2K
| Adam | epoch: 006 | loss: 0.17531 - acc: 0.9286 -- iter: 0256/1702
[A[ATraining Step: 279  | total loss: [1m[32m0.17629[0m[0m | time: 58.560s
[2K
| Adam | epoch: 006 | loss: 0.17629 - acc: 0.9263 -- iter: 0288/1702
[A[ATraining Step: 280  | total loss: [1m[32m0.19362[0m[0m | time: 66.500s
[2K
| Adam | epoch: 006 | loss: 0.19362 - acc: 0.9212 -- iter: 0320/1702
[A[ATraining Step: 281  | total loss: [1m[32m0.19023[0m[0m | time: 74.413s
[2K
| Adam | epoch: 006 | loss: 0.19023 - acc: 0.9259 -- iter: 0352/1702
[A[ATraining Step: 282  | total loss: [1m[32m0.19241[0m[0m | time: 82.044s
[2K
| Adam | epoch: 006 | loss: 0.19241 - acc: 0.9209 -- iter: 0384/1702
[A[ATraining Step: 283  | total loss: [1m[32m0.19538[0m[0m | time: 89.778s
[2K
| Adam | epoch: 006 | loss: 0.19538 - acc: 0.9194 -- iter: 0416/1702
[A[ATraining Step: 284  | total loss: [1m[32m0.19687[0m[0m | time: 97.628s
[2K
| Adam | epoch: 006 | loss: 0.19687 - acc: 0.9181 -- iter: 0448/1702
[A[ATraining Step: 285  | total loss: [1m[32m0.21056[0m[0m | time: 105.360s
[2K
| Adam | epoch: 006 | loss: 0.21056 - acc: 0.9200 -- iter: 0480/1702
[A[ATraining Step: 286  | total loss: [1m[32m0.20084[0m[0m | time: 113.190s
[2K
| Adam | epoch: 006 | loss: 0.20084 - acc: 0.9218 -- iter: 0512/1702
[A[ATraining Step: 287  | total loss: [1m[32m0.21069[0m[0m | time: 121.093s
[2K
| Adam | epoch: 006 | loss: 0.21069 - acc: 0.9171 -- iter: 0544/1702
[A[ATraining Step: 288  | total loss: [1m[32m0.21043[0m[0m | time: 128.868s
[2K
| Adam | epoch: 006 | loss: 0.21043 - acc: 0.9191 -- iter: 0576/1702
[A[ATraining Step: 289  | total loss: [1m[32m0.21928[0m[0m | time: 136.482s
[2K
| Adam | epoch: 006 | loss: 0.21928 - acc: 0.9116 -- iter: 0608/1702
[A[ATraining Step: 290  | total loss: [1m[32m0.21855[0m[0m | time: 144.206s
[2K
| Adam | epoch: 006 | loss: 0.21855 - acc: 0.9111 -- iter: 0640/1702
[A[ATraining Step: 291  | total loss: [1m[32m0.21953[0m[0m | time: 151.864s
[2K
| Adam | epoch: 006 | loss: 0.21953 - acc: 0.9106 -- iter: 0672/1702
[A[ATraining Step: 292  | total loss: [1m[32m0.23109[0m[0m | time: 159.517s
[2K
| Adam | epoch: 006 | loss: 0.23109 - acc: 0.9039 -- iter: 0704/1702
[A[ATraining Step: 293  | total loss: [1m[32m0.21485[0m[0m | time: 167.292s
[2K
| Adam | epoch: 006 | loss: 0.21485 - acc: 0.9135 -- iter: 0736/1702
[A[ATraining Step: 294  | total loss: [1m[32m0.20839[0m[0m | time: 175.183s
[2K
| Adam | epoch: 006 | loss: 0.20839 - acc: 0.9159 -- iter: 0768/1702
[A[ATraining Step: 295  | total loss: [1m[32m0.22060[0m[0m | time: 182.718s
[2K
| Adam | epoch: 006 | loss: 0.22060 - acc: 0.9087 -- iter: 0800/1702
[A[ATraining Step: 296  | total loss: [1m[32m0.21511[0m[0m | time: 190.443s
[2K
| Adam | epoch: 006 | loss: 0.21511 - acc: 0.9116 -- iter: 0832/1702
[A[ATraining Step: 297  | total loss: [1m[32m0.21553[0m[0m | time: 198.360s
[2K
| Adam | epoch: 006 | loss: 0.21553 - acc: 0.9110 -- iter: 0864/1702
[A[ATraining Step: 298  | total loss: [1m[32m0.21312[0m[0m | time: 206.137s
[2K
| Adam | epoch: 006 | loss: 0.21312 - acc: 0.9168 -- iter: 0896/1702
[A[ATraining Step: 299  | total loss: [1m[32m0.20281[0m[0m | time: 213.889s
[2K
| Adam | epoch: 006 | loss: 0.20281 - acc: 0.9220 -- iter: 0928/1702
[A[ATraining Step: 300  | total loss: [1m[32m0.19905[0m[0m | time: 221.495s
[2K
| Adam | epoch: 006 | loss: 0.19905 - acc: 0.9267 -- iter: 0960/1702
[A[ATraining Step: 301  | total loss: [1m[32m0.20232[0m[0m | time: 229.340s
[2K
| Adam | epoch: 006 | loss: 0.20232 - acc: 0.9246 -- iter: 0992/1702
[A[ATraining Step: 302  | total loss: [1m[32m0.20568[0m[0m | time: 237.009s
[2K
| Adam | epoch: 006 | loss: 0.20568 - acc: 0.9228 -- iter: 1024/1702
[A[ATraining Step: 303  | total loss: [1m[32m0.20779[0m[0m | time: 244.724s
[2K
| Adam | epoch: 006 | loss: 0.20779 - acc: 0.9211 -- iter: 1056/1702
[A[ATraining Step: 304  | total loss: [1m[32m0.21686[0m[0m | time: 252.503s
[2K
| Adam | epoch: 006 | loss: 0.21686 - acc: 0.9197 -- iter: 1088/1702
[A[ATraining Step: 305  | total loss: [1m[32m0.20750[0m[0m | time: 260.179s
[2K
| Adam | epoch: 006 | loss: 0.20750 - acc: 0.9214 -- iter: 1120/1702
[A[ATraining Step: 306  | total loss: [1m[32m0.22519[0m[0m | time: 267.960s
[2K
| Adam | epoch: 006 | loss: 0.22519 - acc: 0.9105 -- iter: 1152/1702
[A[ATraining Step: 307  | total loss: [1m[32m0.23055[0m[0m | time: 275.791s
[2K
| Adam | epoch: 006 | loss: 0.23055 - acc: 0.9101 -- iter: 1184/1702
[A[ATraining Step: 308  | total loss: [1m[32m0.21298[0m[0m | time: 283.515s
[2K
| Adam | epoch: 006 | loss: 0.21298 - acc: 0.9191 -- iter: 1216/1702
[A[ATraining Step: 309  | total loss: [1m[32m0.20887[0m[0m | time: 291.345s
[2K
| Adam | epoch: 006 | loss: 0.20887 - acc: 0.9241 -- iter: 1248/1702
[A[ATraining Step: 310  | total loss: [1m[32m0.21502[0m[0m | time: 299.131s
[2K
| Adam | epoch: 006 | loss: 0.21502 - acc: 0.9223 -- iter: 1280/1702
[A[ATraining Step: 311  | total loss: [1m[32m0.19956[0m[0m | time: 306.822s
[2K
| Adam | epoch: 006 | loss: 0.19956 - acc: 0.9301 -- iter: 1312/1702
[A[ATraining Step: 312  | total loss: [1m[32m0.21265[0m[0m | time: 314.561s
[2K
| Adam | epoch: 006 | loss: 0.21265 - acc: 0.9277 -- iter: 1344/1702
[A[ATraining Step: 313  | total loss: [1m[32m0.21306[0m[0m | time: 322.361s
[2K
| Adam | epoch: 006 | loss: 0.21306 - acc: 0.9255 -- iter: 1376/1702
[A[ATraining Step: 314  | total loss: [1m[32m0.20486[0m[0m | time: 330.183s
[2K
| Adam | epoch: 006 | loss: 0.20486 - acc: 0.9299 -- iter: 1408/1702
[A[ATraining Step: 315  | total loss: [1m[32m0.21263[0m[0m | time: 337.818s
[2K
| Adam | epoch: 006 | loss: 0.21263 - acc: 0.9275 -- iter: 1440/1702
[A[ATraining Step: 316  | total loss: [1m[32m0.21652[0m[0m | time: 345.669s
[2K
| Adam | epoch: 006 | loss: 0.21652 - acc: 0.9254 -- iter: 1472/1702
[A[ATraining Step: 317  | total loss: [1m[32m0.21468[0m[0m | time: 353.300s
[2K
| Adam | epoch: 006 | loss: 0.21468 - acc: 0.9266 -- iter: 1504/1702
[A[ATraining Step: 318  | total loss: [1m[32m0.21026[0m[0m | time: 361.164s
[2K
| Adam | epoch: 006 | loss: 0.21026 - acc: 0.9277 -- iter: 1536/1702
[A[ATraining Step: 319  | total loss: [1m[32m0.19926[0m[0m | time: 368.909s
[2K
| Adam | epoch: 006 | loss: 0.19926 - acc: 0.9318 -- iter: 1568/1702
[A[ATraining Step: 320  | total loss: [1m[32m0.19366[0m[0m | time: 376.472s
[2K
| Adam | epoch: 006 | loss: 0.19366 - acc: 0.9292 -- iter: 1600/1702
[A[ATraining Step: 321  | total loss: [1m[32m0.19346[0m[0m | time: 384.281s
[2K
| Adam | epoch: 006 | loss: 0.19346 - acc: 0.9269 -- iter: 1632/1702
[A[ATraining Step: 322  | total loss: [1m[32m0.20655[0m[0m | time: 392.200s
[2K
| Adam | epoch: 006 | loss: 0.20655 - acc: 0.9155 -- iter: 1664/1702
[A[ATraining Step: 323  | total loss: [1m[32m0.20845[0m[0m | time: 400.044s
[2K
| Adam | epoch: 006 | loss: 0.20845 - acc: 0.9146 -- iter: 1696/1702
[A[ATraining Step: 324  | total loss: [1m[32m0.20217[0m[0m | time: 431.022s
[2K
| Adam | epoch: 006 | loss: 0.20217 - acc: 0.9169 | val_loss: 0.50347 - val_acc: 0.8518 -- iter: 1702/1702
--
Training Step: 325  | total loss: [1m[32m0.18865[0m[0m | time: 7.732s
[2K
| Adam | epoch: 007 | loss: 0.18865 - acc: 0.9220 -- iter: 0032/1702
[A[ATraining Step: 326  | total loss: [1m[32m0.19693[0m[0m | time: 15.608s
[2K
| Adam | epoch: 007 | loss: 0.19693 - acc: 0.9236 -- iter: 0064/1702
[A[ATraining Step: 327  | total loss: [1m[32m0.18413[0m[0m | time: 23.410s
[2K
| Adam | epoch: 007 | loss: 0.18413 - acc: 0.9312 -- iter: 0096/1702
[A[ATraining Step: 328  | total loss: [1m[32m0.18684[0m[0m | time: 31.184s
[2K
| Adam | epoch: 007 | loss: 0.18684 - acc: 0.9319 -- iter: 0128/1702
[A[ATraining Step: 329  | total loss: [1m[32m0.17760[0m[0m | time: 33.492s
[2K
| Adam | epoch: 007 | loss: 0.17760 - acc: 0.9355 -- iter: 0160/1702
[A[ATraining Step: 330  | total loss: [1m[32m0.17513[0m[0m | time: 35.715s
[2K
| Adam | epoch: 007 | loss: 0.17513 - acc: 0.9420 -- iter: 0192/1702
[A[ATraining Step: 331  | total loss: [1m[32m0.16235[0m[0m | time: 43.563s
[2K
| Adam | epoch: 007 | loss: 0.16235 - acc: 0.9478 -- iter: 0224/1702
[A[ATraining Step: 332  | total loss: [1m[32m0.17490[0m[0m | time: 51.442s
[2K
| Adam | epoch: 007 | loss: 0.17490 - acc: 0.9405 -- iter: 0256/1702
[A[ATraining Step: 333  | total loss: [1m[32m0.16648[0m[0m | time: 59.209s
[2K
| Adam | epoch: 007 | loss: 0.16648 - acc: 0.9402 -- iter: 0288/1702
[A[ATraining Step: 334  | total loss: [1m[32m0.16177[0m[0m | time: 67.039s
[2K
| Adam | epoch: 007 | loss: 0.16177 - acc: 0.9431 -- iter: 0320/1702
[A[ATraining Step: 335  | total loss: [1m[32m0.16523[0m[0m | time: 74.807s
[2K
| Adam | epoch: 007 | loss: 0.16523 - acc: 0.9394 -- iter: 0352/1702
[A[ATraining Step: 336  | total loss: [1m[32m0.15684[0m[0m | time: 82.597s
[2K
| Adam | epoch: 007 | loss: 0.15684 - acc: 0.9423 -- iter: 0384/1702
[A[ATraining Step: 337  | total loss: [1m[32m0.14709[0m[0m | time: 90.476s
[2K
| Adam | epoch: 007 | loss: 0.14709 - acc: 0.9481 -- iter: 0416/1702
[A[ATraining Step: 338  | total loss: [1m[32m0.13999[0m[0m | time: 98.273s
[2K
| Adam | epoch: 007 | loss: 0.13999 - acc: 0.9502 -- iter: 0448/1702
[A[ATraining Step: 339  | total loss: [1m[32m0.13813[0m[0m | time: 105.950s
[2K
| Adam | epoch: 007 | loss: 0.13813 - acc: 0.9520 -- iter: 0480/1702
[A[ATraining Step: 340  | total loss: [1m[32m0.12986[0m[0m | time: 113.761s
[2K
| Adam | epoch: 007 | loss: 0.12986 - acc: 0.9537 -- iter: 0512/1702
[A[ATraining Step: 341  | total loss: [1m[32m0.12478[0m[0m | time: 121.488s
[2K
| Adam | epoch: 007 | loss: 0.12478 - acc: 0.9552 -- iter: 0544/1702
[A[ATraining Step: 342  | total loss: [1m[32m0.14130[0m[0m | time: 129.328s
[2K
| Adam | epoch: 007 | loss: 0.14130 - acc: 0.9503 -- iter: 0576/1702
[A[ATraining Step: 343  | total loss: [1m[32m0.13203[0m[0m | time: 137.169s
[2K
| Adam | epoch: 007 | loss: 0.13203 - acc: 0.9521 -- iter: 0608/1702
[A[ATraining Step: 344  | total loss: [1m[32m0.13087[0m[0m | time: 144.990s
[2K
| Adam | epoch: 007 | loss: 0.13087 - acc: 0.9538 -- iter: 0640/1702
[A[ATraining Step: 345  | total loss: [1m[32m0.12179[0m[0m | time: 152.882s
[2K
| Adam | epoch: 007 | loss: 0.12179 - acc: 0.9584 -- iter: 0672/1702
[A[ATraining Step: 346  | total loss: [1m[32m0.13422[0m[0m | time: 160.547s
[2K
| Adam | epoch: 007 | loss: 0.13422 - acc: 0.9563 -- iter: 0704/1702
[A[ATraining Step: 347  | total loss: [1m[32m0.12203[0m[0m | time: 168.319s
[2K
| Adam | epoch: 007 | loss: 0.12203 - acc: 0.9607 -- iter: 0736/1702
[A[ATraining Step: 348  | total loss: [1m[32m0.12439[0m[0m | time: 176.011s
[2K
| Adam | epoch: 007 | loss: 0.12439 - acc: 0.9553 -- iter: 0768/1702
[A[ATraining Step: 349  | total loss: [1m[32m0.13862[0m[0m | time: 183.813s
[2K
| Adam | epoch: 007 | loss: 0.13862 - acc: 0.9472 -- iter: 0800/1702
[A[ATraining Step: 350  | total loss: [1m[32m0.13089[0m[0m | time: 191.516s
[2K
| Adam | epoch: 007 | loss: 0.13089 - acc: 0.9525 -- iter: 0832/1702
[A[ATraining Step: 351  | total loss: [1m[32m0.19292[0m[0m | time: 199.299s
[2K
| Adam | epoch: 007 | loss: 0.19292 - acc: 0.9354 -- iter: 0864/1702
[A[ATraining Step: 352  | total loss: [1m[32m0.18910[0m[0m | time: 207.055s
[2K
| Adam | epoch: 007 | loss: 0.18910 - acc: 0.9356 -- iter: 0896/1702
[A[ATraining Step: 353  | total loss: [1m[32m0.18488[0m[0m | time: 214.858s
[2K
| Adam | epoch: 007 | loss: 0.18488 - acc: 0.9327 -- iter: 0928/1702
[A[ATraining Step: 354  | total loss: [1m[32m0.17320[0m[0m | time: 222.582s
[2K
| Adam | epoch: 007 | loss: 0.17320 - acc: 0.9394 -- iter: 0960/1702
[A[ATraining Step: 355  | total loss: [1m[32m0.18236[0m[0m | time: 230.252s
[2K
| Adam | epoch: 007 | loss: 0.18236 - acc: 0.9361 -- iter: 0992/1702
[A[ATraining Step: 356  | total loss: [1m[32m0.18876[0m[0m | time: 238.133s
[2K
| Adam | epoch: 007 | loss: 0.18876 - acc: 0.9300 -- iter: 1024/1702
[A[ATraining Step: 357  | total loss: [1m[32m0.18324[0m[0m | time: 245.846s
[2K
| Adam | epoch: 007 | loss: 0.18324 - acc: 0.9307 -- iter: 1056/1702
[A[ATraining Step: 358  | total loss: [1m[32m0.18342[0m[0m | time: 253.491s
[2K
| Adam | epoch: 007 | loss: 0.18342 - acc: 0.9283 -- iter: 1088/1702
[A[ATraining Step: 359  | total loss: [1m[32m0.17995[0m[0m | time: 261.367s
[2K
| Adam | epoch: 007 | loss: 0.17995 - acc: 0.9261 -- iter: 1120/1702
[A[ATraining Step: 360  | total loss: [1m[32m0.17301[0m[0m | time: 269.071s
[2K
| Adam | epoch: 007 | loss: 0.17301 - acc: 0.9303 -- iter: 1152/1702
[A[ATraining Step: 361  | total loss: [1m[32m0.18576[0m[0m | time: 276.849s
[2K
| Adam | epoch: 007 | loss: 0.18576 - acc: 0.9248 -- iter: 1184/1702
[A[ATraining Step: 362  | total loss: [1m[32m0.18548[0m[0m | time: 284.523s
[2K
| Adam | epoch: 007 | loss: 0.18548 - acc: 0.9261 -- iter: 1216/1702
[A[ATraining Step: 363  | total loss: [1m[32m0.17162[0m[0m | time: 292.230s
[2K
| Adam | epoch: 007 | loss: 0.17162 - acc: 0.9303 -- iter: 1248/1702
[A[ATraining Step: 364  | total loss: [1m[32m0.18925[0m[0m | time: 300.009s
[2K
| Adam | epoch: 007 | loss: 0.18925 - acc: 0.9217 -- iter: 1280/1702
[A[ATraining Step: 365  | total loss: [1m[32m0.18177[0m[0m | time: 307.970s
[2K
| Adam | epoch: 007 | loss: 0.18177 - acc: 0.9264 -- iter: 1312/1702
[A[ATraining Step: 366  | total loss: [1m[32m0.17201[0m[0m | time: 315.773s
[2K
| Adam | epoch: 007 | loss: 0.17201 - acc: 0.9306 -- iter: 1344/1702
[A[ATraining Step: 367  | total loss: [1m[32m0.18743[0m[0m | time: 323.580s
[2K
| Adam | epoch: 007 | loss: 0.18743 - acc: 0.9219 -- iter: 1376/1702
[A[ATraining Step: 368  | total loss: [1m[32m0.18880[0m[0m | time: 331.474s
[2K
| Adam | epoch: 007 | loss: 0.18880 - acc: 0.9235 -- iter: 1408/1702
[A[ATraining Step: 369  | total loss: [1m[32m0.18273[0m[0m | time: 339.178s
[2K
| Adam | epoch: 007 | loss: 0.18273 - acc: 0.9280 -- iter: 1440/1702
[A[ATraining Step: 370  | total loss: [1m[32m0.17499[0m[0m | time: 347.110s
[2K
| Adam | epoch: 007 | loss: 0.17499 - acc: 0.9321 -- iter: 1472/1702
[A[ATraining Step: 371  | total loss: [1m[32m0.17636[0m[0m | time: 354.830s
[2K
| Adam | epoch: 007 | loss: 0.17636 - acc: 0.9326 -- iter: 1504/1702
[A[ATraining Step: 372  | total loss: [1m[32m0.17149[0m[0m | time: 362.463s
[2K
| Adam | epoch: 007 | loss: 0.17149 - acc: 0.9331 -- iter: 1536/1702
[A[ATraining Step: 373  | total loss: [1m[32m0.16107[0m[0m | time: 370.173s
[2K
| Adam | epoch: 007 | loss: 0.16107 - acc: 0.9398 -- iter: 1568/1702
[A[ATraining Step: 374  | total loss: [1m[32m0.15084[0m[0m | time: 377.968s
[2K
| Adam | epoch: 007 | loss: 0.15084 - acc: 0.9458 -- iter: 1600/1702
[A[ATraining Step: 375  | total loss: [1m[32m0.14199[0m[0m | time: 385.681s
[2K
| Adam | epoch: 007 | loss: 0.14199 - acc: 0.9481 -- iter: 1632/1702
[A[ATraining Step: 376  | total loss: [1m[32m0.16545[0m[0m | time: 393.495s
[2K
| Adam | epoch: 007 | loss: 0.16545 - acc: 0.9439 -- iter: 1664/1702
[A[ATraining Step: 377  | total loss: [1m[32m0.15019[0m[0m | time: 401.254s
[2K
| Adam | epoch: 007 | loss: 0.15019 - acc: 0.9495 -- iter: 1696/1702
[A[ATraining Step: 378  | total loss: [1m[32m0.13862[0m[0m | time: 432.467s
[2K
| Adam | epoch: 007 | loss: 0.13862 - acc: 0.9546 | val_loss: 0.40193 - val_acc: 0.8856 -- iter: 1702/1702
--
Training Step: 379  | total loss: [1m[32m0.12897[0m[0m | time: 7.662s
[2K
| Adam | epoch: 008 | loss: 0.12897 - acc: 0.9591 -- iter: 0032/1702
[A[ATraining Step: 380  | total loss: [1m[32m0.16579[0m[0m | time: 15.217s
[2K
| Adam | epoch: 008 | loss: 0.16579 - acc: 0.9507 -- iter: 0064/1702
[A[ATraining Step: 381  | total loss: [1m[32m0.16679[0m[0m | time: 22.811s
[2K
| Adam | epoch: 008 | loss: 0.16679 - acc: 0.9431 -- iter: 0096/1702
[A[ATraining Step: 382  | total loss: [1m[32m0.15764[0m[0m | time: 30.581s
[2K
| Adam | epoch: 008 | loss: 0.15764 - acc: 0.9488 -- iter: 0128/1702
[A[ATraining Step: 383  | total loss: [1m[32m0.14886[0m[0m | time: 38.351s
[2K
| Adam | epoch: 008 | loss: 0.14886 - acc: 0.9508 -- iter: 0160/1702
[A[ATraining Step: 384  | total loss: [1m[32m0.15631[0m[0m | time: 40.604s
[2K
| Adam | epoch: 008 | loss: 0.15631 - acc: 0.9464 -- iter: 0192/1702
[A[ATraining Step: 385  | total loss: [1m[32m0.14526[0m[0m | time: 42.855s
[2K
| Adam | epoch: 008 | loss: 0.14526 - acc: 0.9517 -- iter: 0224/1702
[A[ATraining Step: 386  | total loss: [1m[32m0.13380[0m[0m | time: 50.548s
[2K
| Adam | epoch: 008 | loss: 0.13380 - acc: 0.9566 -- iter: 0256/1702
[A[ATraining Step: 387  | total loss: [1m[32m0.14051[0m[0m | time: 58.344s
[2K
| Adam | epoch: 008 | loss: 0.14051 - acc: 0.9546 -- iter: 0288/1702
[A[ATraining Step: 388  | total loss: [1m[32m0.13032[0m[0m | time: 66.066s
[2K
| Adam | epoch: 008 | loss: 0.13032 - acc: 0.9561 -- iter: 0320/1702
[A[ATraining Step: 389  | total loss: [1m[32m0.14341[0m[0m | time: 73.982s
[2K
| Adam | epoch: 008 | loss: 0.14341 - acc: 0.9542 -- iter: 0352/1702
[A[ATraining Step: 390  | total loss: [1m[32m0.15220[0m[0m | time: 81.859s
[2K
| Adam | epoch: 008 | loss: 0.15220 - acc: 0.9557 -- iter: 0384/1702
[A[ATraining Step: 391  | total loss: [1m[32m0.15062[0m[0m | time: 89.718s
[2K
| Adam | epoch: 008 | loss: 0.15062 - acc: 0.9570 -- iter: 0416/1702
[A[ATraining Step: 392  | total loss: [1m[32m0.14164[0m[0m | time: 97.268s
[2K
| Adam | epoch: 008 | loss: 0.14164 - acc: 0.9613 -- iter: 0448/1702
[A[ATraining Step: 393  | total loss: [1m[32m0.13318[0m[0m | time: 105.228s
[2K
| Adam | epoch: 008 | loss: 0.13318 - acc: 0.9620 -- iter: 0480/1702
[A[ATraining Step: 394  | total loss: [1m[32m0.12429[0m[0m | time: 112.892s
[2K
| Adam | epoch: 008 | loss: 0.12429 - acc: 0.9658 -- iter: 0512/1702
[A[ATraining Step: 395  | total loss: [1m[32m0.13478[0m[0m | time: 120.750s
[2K
| Adam | epoch: 008 | loss: 0.13478 - acc: 0.9599 -- iter: 0544/1702
[A[ATraining Step: 396  | total loss: [1m[32m0.12696[0m[0m | time: 128.420s
[2K
| Adam | epoch: 008 | loss: 0.12696 - acc: 0.9639 -- iter: 0576/1702
[A[ATraining Step: 397  | total loss: [1m[32m0.11721[0m[0m | time: 136.352s
[2K
| Adam | epoch: 008 | loss: 0.11721 - acc: 0.9675 -- iter: 0608/1702
[A[ATraining Step: 398  | total loss: [1m[32m0.16013[0m[0m | time: 144.127s
[2K
| Adam | epoch: 008 | loss: 0.16013 - acc: 0.9520 -- iter: 0640/1702
[A[ATraining Step: 399  | total loss: [1m[32m0.15786[0m[0m | time: 151.909s
[2K
| Adam | epoch: 008 | loss: 0.15786 - acc: 0.9505 -- iter: 0672/1702
[A[ATraining Step: 400  | total loss: [1m[32m0.14789[0m[0m | time: 183.335s
[2K
| Adam | epoch: 008 | loss: 0.14789 - acc: 0.9524 | val_loss: 0.84420 - val_acc: 0.6510 -- iter: 0704/1702
--
Training Step: 401  | total loss: [1m[32m0.14753[0m[0m | time: 191.150s
[2K
| Adam | epoch: 008 | loss: 0.14753 - acc: 0.9477 -- iter: 0736/1702
[A[ATraining Step: 402  | total loss: [1m[32m0.18251[0m[0m | time: 198.982s
[2K
| Adam | epoch: 008 | loss: 0.18251 - acc: 0.9436 -- iter: 0768/1702
[A[ATraining Step: 403  | total loss: [1m[32m0.16676[0m[0m | time: 206.774s
[2K
| Adam | epoch: 008 | loss: 0.16676 - acc: 0.9492 -- iter: 0800/1702
[A[ATraining Step: 404  | total loss: [1m[32m0.15880[0m[0m | time: 214.503s
[2K
| Adam | epoch: 008 | loss: 0.15880 - acc: 0.9512 -- iter: 0832/1702
[A[ATraining Step: 405  | total loss: [1m[32m0.14698[0m[0m | time: 222.180s
[2K
| Adam | epoch: 008 | loss: 0.14698 - acc: 0.9561 -- iter: 0864/1702
[A[ATraining Step: 406  | total loss: [1m[32m0.14726[0m[0m | time: 229.982s
[2K
| Adam | epoch: 008 | loss: 0.14726 - acc: 0.9542 -- iter: 0896/1702
[A[ATraining Step: 407  | total loss: [1m[32m0.15103[0m[0m | time: 237.695s
[2K
| Adam | epoch: 008 | loss: 0.15103 - acc: 0.9525 -- iter: 0928/1702
[A[ATraining Step: 408  | total loss: [1m[32m0.14842[0m[0m | time: 245.648s
[2K
| Adam | epoch: 008 | loss: 0.14842 - acc: 0.9542 -- iter: 0960/1702
[A[ATraining Step: 409  | total loss: [1m[32m0.15312[0m[0m | time: 253.384s
[2K
| Adam | epoch: 008 | loss: 0.15312 - acc: 0.9525 -- iter: 0992/1702
[A[ATraining Step: 410  | total loss: [1m[32m0.14746[0m[0m | time: 261.352s
[2K
| Adam | epoch: 008 | loss: 0.14746 - acc: 0.9541 -- iter: 1024/1702
[A[ATraining Step: 411  | total loss: [1m[32m0.14044[0m[0m | time: 269.042s
[2K
| Adam | epoch: 008 | loss: 0.14044 - acc: 0.9587 -- iter: 1056/1702
[A[ATraining Step: 412  | total loss: [1m[32m0.14315[0m[0m | time: 276.800s
[2K
| Adam | epoch: 008 | loss: 0.14315 - acc: 0.9535 -- iter: 1088/1702
[A[ATraining Step: 413  | total loss: [1m[32m0.14640[0m[0m | time: 284.830s
[2K
| Adam | epoch: 008 | loss: 0.14640 - acc: 0.9487 -- iter: 1120/1702
[A[ATraining Step: 414  | total loss: [1m[32m0.13972[0m[0m | time: 292.487s
[2K
| Adam | epoch: 008 | loss: 0.13972 - acc: 0.9507 -- iter: 1152/1702
[A[ATraining Step: 415  | total loss: [1m[32m0.13273[0m[0m | time: 300.372s
[2K
| Adam | epoch: 008 | loss: 0.13273 - acc: 0.9525 -- iter: 1184/1702
[A[ATraining Step: 416  | total loss: [1m[32m0.12995[0m[0m | time: 308.178s
[2K
| Adam | epoch: 008 | loss: 0.12995 - acc: 0.9542 -- iter: 1216/1702
[A[ATraining Step: 417  | total loss: [1m[32m0.12881[0m[0m | time: 315.885s
[2K
| Adam | epoch: 008 | loss: 0.12881 - acc: 0.9525 -- iter: 1248/1702
[A[ATraining Step: 418  | total loss: [1m[32m0.12046[0m[0m | time: 323.554s
[2K
| Adam | epoch: 008 | loss: 0.12046 - acc: 0.9572 -- iter: 1280/1702
[A[ATraining Step: 419  | total loss: [1m[32m0.11567[0m[0m | time: 331.381s
[2K
| Adam | epoch: 008 | loss: 0.11567 - acc: 0.9615 -- iter: 1312/1702
[A[ATraining Step: 420  | total loss: [1m[32m0.11129[0m[0m | time: 339.255s
[2K
| Adam | epoch: 008 | loss: 0.11129 - acc: 0.9622 -- iter: 1344/1702
[A[ATraining Step: 421  | total loss: [1m[32m0.11060[0m[0m | time: 347.221s
[2K
| Adam | epoch: 008 | loss: 0.11060 - acc: 0.9598 -- iter: 1376/1702
[A[ATraining Step: 422  | total loss: [1m[32m0.11444[0m[0m | time: 354.805s
[2K
| Adam | epoch: 008 | loss: 0.11444 - acc: 0.9575 -- iter: 1408/1702
[A[ATraining Step: 423  | total loss: [1m[32m0.11264[0m[0m | time: 362.606s
[2K
| Adam | epoch: 008 | loss: 0.11264 - acc: 0.9555 -- iter: 1440/1702
[A[ATraining Step: 424  | total loss: [1m[32m0.11703[0m[0m | time: 370.300s
[2K
| Adam | epoch: 008 | loss: 0.11703 - acc: 0.9537 -- iter: 1472/1702
[A[ATraining Step: 425  | total loss: [1m[32m0.10630[0m[0m | time: 378.052s
[2K
| Adam | epoch: 008 | loss: 0.10630 - acc: 0.9584 -- iter: 1504/1702
[A[ATraining Step: 426  | total loss: [1m[32m0.10095[0m[0m | time: 385.923s
[2K
| Adam | epoch: 008 | loss: 0.10095 - acc: 0.9594 -- iter: 1536/1702
[A[ATraining Step: 427  | total loss: [1m[32m0.09589[0m[0m | time: 393.562s
[2K
| Adam | epoch: 008 | loss: 0.09589 - acc: 0.9603 -- iter: 1568/1702
[A[ATraining Step: 428  | total loss: [1m[32m0.10039[0m[0m | time: 401.450s
[2K
| Adam | epoch: 008 | loss: 0.10039 - acc: 0.9612 -- iter: 1600/1702
[A[ATraining Step: 429  | total loss: [1m[32m0.09411[0m[0m | time: 409.177s
[2K
| Adam | epoch: 008 | loss: 0.09411 - acc: 0.9619 -- iter: 1632/1702
[A[ATraining Step: 430  | total loss: [1m[32m0.09110[0m[0m | time: 416.978s
[2K
| Adam | epoch: 008 | loss: 0.09110 - acc: 0.9626 -- iter: 1664/1702
[A[ATraining Step: 431  | total loss: [1m[32m0.08806[0m[0m | time: 424.705s
[2K
| Adam | epoch: 008 | loss: 0.08806 - acc: 0.9664 -- iter: 1696/1702
[A[ATraining Step: 432  | total loss: [1m[32m0.08574[0m[0m | time: 455.882s
[2K
| Adam | epoch: 008 | loss: 0.08574 - acc: 0.9666 | val_loss: 0.41413 - val_acc: 0.8724 -- iter: 1702/1702
--
Training Step: 433  | total loss: [1m[32m0.09528[0m[0m | time: 7.768s
[2K
| Adam | epoch: 009 | loss: 0.09528 - acc: 0.9637 -- iter: 0032/1702
[A[ATraining Step: 434  | total loss: [1m[32m0.08654[0m[0m | time: 15.551s
[2K
| Adam | epoch: 009 | loss: 0.08654 - acc: 0.9673 -- iter: 0064/1702
[A[ATraining Step: 435  | total loss: [1m[32m0.08084[0m[0m | time: 23.374s
[2K
| Adam | epoch: 009 | loss: 0.08084 - acc: 0.9706 -- iter: 0096/1702
[A[ATraining Step: 436  | total loss: [1m[32m0.07675[0m[0m | time: 31.059s
[2K
| Adam | epoch: 009 | loss: 0.07675 - acc: 0.9704 -- iter: 0128/1702
[A[ATraining Step: 437  | total loss: [1m[32m0.07658[0m[0m | time: 38.798s
[2K
| Adam | epoch: 009 | loss: 0.07658 - acc: 0.9702 -- iter: 0160/1702
[A[ATraining Step: 438  | total loss: [1m[32m0.07256[0m[0m | time: 46.449s
[2K
| Adam | epoch: 009 | loss: 0.07256 - acc: 0.9732 -- iter: 0192/1702
[A[ATraining Step: 439  | total loss: [1m[32m0.07222[0m[0m | time: 48.679s
[2K
| Adam | epoch: 009 | loss: 0.07222 - acc: 0.9728 -- iter: 0224/1702
[A[ATraining Step: 440  | total loss: [1m[32m0.10825[0m[0m | time: 50.937s
[2K
| Adam | epoch: 009 | loss: 0.10825 - acc: 0.9588 -- iter: 0256/1702
[A[ATraining Step: 441  | total loss: [1m[32m0.10401[0m[0m | time: 58.851s
[2K
| Adam | epoch: 009 | loss: 0.10401 - acc: 0.9629 -- iter: 0288/1702
[A[ATraining Step: 442  | total loss: [1m[32m0.10359[0m[0m | time: 66.652s
[2K
| Adam | epoch: 009 | loss: 0.10359 - acc: 0.9604 -- iter: 0320/1702
[A[ATraining Step: 443  | total loss: [1m[32m0.10507[0m[0m | time: 74.395s
[2K
| Adam | epoch: 009 | loss: 0.10507 - acc: 0.9550 -- iter: 0352/1702
[A[ATraining Step: 444  | total loss: [1m[32m0.10116[0m[0m | time: 82.335s
[2K
| Adam | epoch: 009 | loss: 0.10116 - acc: 0.9564 -- iter: 0384/1702
[A[ATraining Step: 445  | total loss: [1m[32m0.10220[0m[0m | time: 90.267s
[2K
| Adam | epoch: 009 | loss: 0.10220 - acc: 0.9576 -- iter: 0416/1702
[A[ATraining Step: 446  | total loss: [1m[32m0.10077[0m[0m | time: 98.037s
[2K
| Adam | epoch: 009 | loss: 0.10077 - acc: 0.9587 -- iter: 0448/1702
[A[ATraining Step: 447  | total loss: [1m[32m0.12074[0m[0m | time: 105.858s
[2K
| Adam | epoch: 009 | loss: 0.12074 - acc: 0.9503 -- iter: 0480/1702
[A[ATraining Step: 448  | total loss: [1m[32m0.11477[0m[0m | time: 113.664s
[2K
| Adam | epoch: 009 | loss: 0.11477 - acc: 0.9491 -- iter: 0512/1702
[A[ATraining Step: 449  | total loss: [1m[32m0.12895[0m[0m | time: 121.603s
[2K
| Adam | epoch: 009 | loss: 0.12895 - acc: 0.9479 -- iter: 0544/1702
[A[ATraining Step: 450  | total loss: [1m[32m0.12444[0m[0m | time: 129.433s
[2K
| Adam | epoch: 009 | loss: 0.12444 - acc: 0.9500 -- iter: 0576/1702
[A[ATraining Step: 451  | total loss: [1m[32m0.11780[0m[0m | time: 137.260s
[2K
| Adam | epoch: 009 | loss: 0.11780 - acc: 0.9550 -- iter: 0608/1702
[A[ATraining Step: 452  | total loss: [1m[32m0.11945[0m[0m | time: 145.080s
[2K
| Adam | epoch: 009 | loss: 0.11945 - acc: 0.9501 -- iter: 0640/1702
[A[ATraining Step: 453  | total loss: [1m[32m0.11556[0m[0m | time: 152.846s
[2K
| Adam | epoch: 009 | loss: 0.11556 - acc: 0.9520 -- iter: 0672/1702
[A[ATraining Step: 454  | total loss: [1m[32m0.11469[0m[0m | time: 160.533s
[2K
| Adam | epoch: 009 | loss: 0.11469 - acc: 0.9537 -- iter: 0704/1702
[A[ATraining Step: 455  | total loss: [1m[32m0.12479[0m[0m | time: 168.469s
[2K
| Adam | epoch: 009 | loss: 0.12479 - acc: 0.9520 -- iter: 0736/1702
[A[ATraining Step: 456  | total loss: [1m[32m0.13728[0m[0m | time: 176.198s
[2K
| Adam | epoch: 009 | loss: 0.13728 - acc: 0.9412 -- iter: 0768/1702
[A[ATraining Step: 457  | total loss: [1m[32m0.13737[0m[0m | time: 183.904s
[2K
| Adam | epoch: 009 | loss: 0.13737 - acc: 0.9408 -- iter: 0800/1702
[A[ATraining Step: 458  | total loss: [1m[32m0.15209[0m[0m | time: 191.608s
[2K
| Adam | epoch: 009 | loss: 0.15209 - acc: 0.9405 -- iter: 0832/1702
[A[ATraining Step: 459  | total loss: [1m[32m0.15353[0m[0m | time: 199.501s
[2K
| Adam | epoch: 009 | loss: 0.15353 - acc: 0.9371 -- iter: 0864/1702
[A[ATraining Step: 460  | total loss: [1m[32m0.16942[0m[0m | time: 207.322s
[2K
| Adam | epoch: 009 | loss: 0.16942 - acc: 0.9340 -- iter: 0896/1702
[A[ATraining Step: 461  | total loss: [1m[32m0.15506[0m[0m | time: 215.241s
[2K
| Adam | epoch: 009 | loss: 0.15506 - acc: 0.9406 -- iter: 0928/1702
[A[ATraining Step: 462  | total loss: [1m[32m0.16617[0m[0m | time: 222.949s
[2K
| Adam | epoch: 009 | loss: 0.16617 - acc: 0.9340 -- iter: 0960/1702
[A[ATraining Step: 463  | total loss: [1m[32m0.15533[0m[0m | time: 230.811s
[2K
| Adam | epoch: 009 | loss: 0.15533 - acc: 0.9406 -- iter: 0992/1702
[A[ATraining Step: 464  | total loss: [1m[32m0.16280[0m[0m | time: 238.606s
[2K
| Adam | epoch: 009 | loss: 0.16280 - acc: 0.9278 -- iter: 1024/1702
[A[ATraining Step: 465  | total loss: [1m[32m0.17279[0m[0m | time: 246.527s
[2K
| Adam | epoch: 009 | loss: 0.17279 - acc: 0.9288 -- iter: 1056/1702
[A[ATraining Step: 466  | total loss: [1m[32m0.16608[0m[0m | time: 254.424s
[2K
| Adam | epoch: 009 | loss: 0.16608 - acc: 0.9297 -- iter: 1088/1702
[A[ATraining Step: 467  | total loss: [1m[32m0.15998[0m[0m | time: 262.452s
[2K
| Adam | epoch: 009 | loss: 0.15998 - acc: 0.9273 -- iter: 1120/1702
[A[ATraining Step: 468  | total loss: [1m[32m0.15307[0m[0m | time: 270.485s
[2K
| Adam | epoch: 009 | loss: 0.15307 - acc: 0.9283 -- iter: 1152/1702
[A[ATraining Step: 469  | total loss: [1m[32m0.15628[0m[0m | time: 278.566s
[2K
| Adam | epoch: 009 | loss: 0.15628 - acc: 0.9261 -- iter: 1184/1702
[A[ATraining Step: 470  | total loss: [1m[32m0.16764[0m[0m | time: 286.418s
[2K
| Adam | epoch: 009 | loss: 0.16764 - acc: 0.9210 -- iter: 1216/1702
[A[ATraining Step: 471  | total loss: [1m[32m0.18516[0m[0m | time: 294.266s
[2K
| Adam | epoch: 009 | loss: 0.18516 - acc: 0.9164 -- iter: 1248/1702
[A[ATraining Step: 472  | total loss: [1m[32m0.18037[0m[0m | time: 302.055s
[2K
| Adam | epoch: 009 | loss: 0.18037 - acc: 0.9185 -- iter: 1280/1702
[A[ATraining Step: 473  | total loss: [1m[32m0.18066[0m[0m | time: 309.984s
[2K
| Adam | epoch: 009 | loss: 0.18066 - acc: 0.9204 -- iter: 1312/1702
[A[ATraining Step: 474  | total loss: [1m[32m0.18238[0m[0m | time: 317.843s
[2K
| Adam | epoch: 009 | loss: 0.18238 - acc: 0.9253 -- iter: 1344/1702
[A[ATraining Step: 475  | total loss: [1m[32m0.17656[0m[0m | time: 325.598s
[2K
| Adam | epoch: 009 | loss: 0.17656 - acc: 0.9296 -- iter: 1376/1702
[A[ATraining Step: 476  | total loss: [1m[32m0.18143[0m[0m | time: 333.297s
[2K
| Adam | epoch: 009 | loss: 0.18143 - acc: 0.9273 -- iter: 1408/1702
[A[ATraining Step: 477  | total loss: [1m[32m0.19591[0m[0m | time: 341.163s
[2K
| Adam | epoch: 009 | loss: 0.19591 - acc: 0.9189 -- iter: 1440/1702
[A[ATraining Step: 478  | total loss: [1m[32m0.19423[0m[0m | time: 348.990s
[2K
| Adam | epoch: 009 | loss: 0.19423 - acc: 0.9176 -- iter: 1472/1702
[A[ATraining Step: 479  | total loss: [1m[32m0.19050[0m[0m | time: 356.834s
[2K
| Adam | epoch: 009 | loss: 0.19050 - acc: 0.9196 -- iter: 1504/1702
[A[ATraining Step: 480  | total loss: [1m[32m0.19659[0m[0m | time: 364.560s
[2K
| Adam | epoch: 009 | loss: 0.19659 - acc: 0.9183 -- iter: 1536/1702
[A[ATraining Step: 481  | total loss: [1m[32m0.18177[0m[0m | time: 372.268s
[2K
| Adam | epoch: 009 | loss: 0.18177 - acc: 0.9265 -- iter: 1568/1702
[A[ATraining Step: 482  | total loss: [1m[32m0.17084[0m[0m | time: 380.095s
[2K
| Adam | epoch: 009 | loss: 0.17084 - acc: 0.9338 -- iter: 1600/1702
[A[ATraining Step: 483  | total loss: [1m[32m0.19498[0m[0m | time: 387.931s
[2K
| Adam | epoch: 009 | loss: 0.19498 - acc: 0.9217 -- iter: 1632/1702
[A[ATraining Step: 484  | total loss: [1m[32m0.18725[0m[0m | time: 395.718s
[2K
| Adam | epoch: 009 | loss: 0.18725 - acc: 0.9233 -- iter: 1664/1702
[A[ATraining Step: 485  | total loss: [1m[32m0.17562[0m[0m | time: 403.392s
[2K
| Adam | epoch: 009 | loss: 0.17562 - acc: 0.9278 -- iter: 1696/1702
[A[ATraining Step: 486  | total loss: [1m[32m0.16340[0m[0m | time: 434.712s
[2K
| Adam | epoch: 009 | loss: 0.16340 - acc: 0.9350 | val_loss: 0.77826 - val_acc: 0.7167 -- iter: 1702/1702
--
Training Step: 487  | total loss: [1m[32m0.15215[0m[0m | time: 7.819s
[2K
| Adam | epoch: 010 | loss: 0.15215 - acc: 0.9415 -- iter: 0032/1702
[A[ATraining Step: 488  | total loss: [1m[32m0.16021[0m[0m | time: 15.480s
[2K
| Adam | epoch: 010 | loss: 0.16021 - acc: 0.9411 -- iter: 0064/1702
[A[ATraining Step: 489  | total loss: [1m[32m0.15884[0m[0m | time: 23.414s
[2K
| Adam | epoch: 010 | loss: 0.15884 - acc: 0.9408 -- iter: 0096/1702
[A[ATraining Step: 490  | total loss: [1m[32m0.16869[0m[0m | time: 31.151s
[2K
| Adam | epoch: 010 | loss: 0.16869 - acc: 0.9342 -- iter: 0128/1702
[A[ATraining Step: 491  | total loss: [1m[32m0.16289[0m[0m | time: 38.859s
[2K
| Adam | epoch: 010 | loss: 0.16289 - acc: 0.9345 -- iter: 0160/1702
[A[ATraining Step: 492  | total loss: [1m[32m0.17333[0m[0m | time: 46.560s
[2K
| Adam | epoch: 010 | loss: 0.17333 - acc: 0.9379 -- iter: 0192/1702
[A[ATraining Step: 493  | total loss: [1m[32m0.18265[0m[0m | time: 55.472s
[2K
| Adam | epoch: 010 | loss: 0.18265 - acc: 0.9379 -- iter: 0224/1702
[A[ATraining Step: 494  | total loss: [1m[32m0.17438[0m[0m | time: 58.177s
[2K
| Adam | epoch: 010 | loss: 0.17438 - acc: 0.9410 -- iter: 0256/1702
[A[ATraining Step: 495  | total loss: [1m[32m0.20165[0m[0m | time: 60.922s
[2K
| Adam | epoch: 010 | loss: 0.20165 - acc: 0.9302 -- iter: 0288/1702
[A[ATraining Step: 496  | total loss: [1m[32m0.18625[0m[0m | time: 69.736s
[2K
| Adam | epoch: 010 | loss: 0.18625 - acc: 0.9372 -- iter: 0320/1702
[A[ATraining Step: 497  | total loss: [1m[32m0.19115[0m[0m | time: 78.666s
[2K
| Adam | epoch: 010 | loss: 0.19115 - acc: 0.9372 -- iter: 0352/1702
[A[ATraining Step: 498  | total loss: [1m[32m0.17787[0m[0m | time: 87.933s
[2K
| Adam | epoch: 010 | loss: 0.17787 - acc: 0.9435 -- iter: 0384/1702
[A[ATraining Step: 499  | total loss: [1m[32m0.18085[0m[0m | time: 96.755s
[2K
| Adam | epoch: 010 | loss: 0.18085 - acc: 0.9429 -- iter: 0416/1702
[A[ATraining Step: 500  | total loss: [1m[32m0.18134[0m[0m | time: 105.817s
[2K
| Adam | epoch: 010 | loss: 0.18134 - acc: 0.9455 -- iter: 0448/1702
[A[ATraining Step: 501  | total loss: [1m[32m0.17905[0m[0m | time: 114.462s
[2K
| Adam | epoch: 010 | loss: 0.17905 - acc: 0.9447 -- iter: 0480/1702
[A[ATraining Step: 502  | total loss: [1m[32m0.18407[0m[0m | time: 123.620s
[2K
| Adam | epoch: 010 | loss: 0.18407 - acc: 0.9440 -- iter: 0512/1702
[A[ATraining Step: 503  | total loss: [1m[32m0.18196[0m[0m | time: 132.088s
[2K
| Adam | epoch: 010 | loss: 0.18196 - acc: 0.9433 -- iter: 0544/1702
[A[ATraining Step: 504  | total loss: [1m[32m0.20151[0m[0m | time: 140.747s
[2K
| Adam | epoch: 010 | loss: 0.20151 - acc: 0.9302 -- iter: 0576/1702
[A[ATraining Step: 505  | total loss: [1m[32m0.18617[0m[0m | time: 149.604s
[2K
| Adam | epoch: 010 | loss: 0.18617 - acc: 0.9372 -- iter: 0608/1702
[A[ATraining Step: 506  | total loss: [1m[32m0.19710[0m[0m | time: 158.390s
[2K
| Adam | epoch: 010 | loss: 0.19710 - acc: 0.9310 -- iter: 0640/1702
[A[ATraining Step: 507  | total loss: [1m[32m0.18258[0m[0m | time: 167.333s
[2K
| Adam | epoch: 010 | loss: 0.18258 - acc: 0.9379 -- iter: 0672/1702
[A[ATraining Step: 508  | total loss: [1m[32m0.17287[0m[0m | time: 176.412s
[2K
| Adam | epoch: 010 | loss: 0.17287 - acc: 0.9410 -- iter: 0704/1702
[A[ATraining Step: 509  | total loss: [1m[32m0.16858[0m[0m | time: 185.123s
[2K
| Adam | epoch: 010 | loss: 0.16858 - acc: 0.9438 -- iter: 0736/1702
[A[ATraining Step: 510  | total loss: [1m[32m0.15494[0m[0m | time: 193.876s
[2K
| Adam | epoch: 010 | loss: 0.15494 - acc: 0.9494 -- iter: 0768/1702
[A[ATraining Step: 511  | total loss: [1m[32m0.17568[0m[0m | time: 202.908s
[2K
| Adam | epoch: 010 | loss: 0.17568 - acc: 0.9388 -- iter: 0800/1702
[A[ATraining Step: 512  | total loss: [1m[32m0.16255[0m[0m | time: 211.343s
[2K
| Adam | epoch: 010 | loss: 0.16255 - acc: 0.9449 -- iter: 0832/1702
[A[ATraining Step: 513  | total loss: [1m[32m0.16180[0m[0m | time: 220.481s
[2K
| Adam | epoch: 010 | loss: 0.16180 - acc: 0.9442 -- iter: 0864/1702
[A[ATraining Step: 514  | total loss: [1m[32m0.16543[0m[0m | time: 229.331s
[2K
| Adam | epoch: 010 | loss: 0.16543 - acc: 0.9435 -- iter: 0896/1702
[A[ATraining Step: 515  | total loss: [1m[32m0.15256[0m[0m | time: 238.284s
[2K
| Adam | epoch: 010 | loss: 0.15256 - acc: 0.9492 -- iter: 0928/1702
[A[ATraining Step: 516  | total loss: [1m[32m0.16284[0m[0m | time: 247.079s
[2K
| Adam | epoch: 010 | loss: 0.16284 - acc: 0.9449 -- iter: 0960/1702
[A[ATraining Step: 517  | total loss: [1m[32m0.15575[0m[0m | time: 256.495s
[2K
| Adam | epoch: 010 | loss: 0.15575 - acc: 0.9473 -- iter: 0992/1702
[A[ATraining Step: 518  | total loss: [1m[32m0.14478[0m[0m | time: 265.182s
[2K
| Adam | epoch: 010 | loss: 0.14478 - acc: 0.9525 -- iter: 1024/1702
[A[ATraining Step: 519  | total loss: [1m[32m0.13895[0m[0m | time: 274.219s
[2K
| Adam | epoch: 010 | loss: 0.13895 - acc: 0.9542 -- iter: 1056/1702
[A[ATraining Step: 520  | total loss: [1m[32m0.13138[0m[0m | time: 283.219s
[2K
| Adam | epoch: 010 | loss: 0.13138 - acc: 0.9556 -- iter: 1088/1702
[A[ATraining Step: 521  | total loss: [1m[32m0.12551[0m[0m | time: 291.623s
[2K
| Adam | epoch: 010 | loss: 0.12551 - acc: 0.9601 -- iter: 1120/1702
[A[ATraining Step: 522  | total loss: [1m[32m0.11583[0m[0m | time: 300.451s
[2K
| Adam | epoch: 010 | loss: 0.11583 - acc: 0.9641 -- iter: 1152/1702
[A[ATraining Step: 523  | total loss: [1m[32m0.10738[0m[0m | time: 309.867s
[2K
| Adam | epoch: 010 | loss: 0.10738 - acc: 0.9676 -- iter: 1184/1702
[A[ATraining Step: 524  | total loss: [1m[32m0.11266[0m[0m | time: 319.479s
[2K
| Adam | epoch: 010 | loss: 0.11266 - acc: 0.9646 -- iter: 1216/1702
[A[ATraining Step: 525  | total loss: [1m[32m0.10897[0m[0m | time: 328.619s
[2K
| Adam | epoch: 010 | loss: 0.10897 - acc: 0.9619 -- iter: 1248/1702
[A[ATraining Step: 526  | total loss: [1m[32m0.10730[0m[0m | time: 337.740s
[2K
| Adam | epoch: 010 | loss: 0.10730 - acc: 0.9626 -- iter: 1280/1702
[A[ATraining Step: 527  | total loss: [1m[32m0.10008[0m[0m | time: 347.140s
[2K
| Adam | epoch: 010 | loss: 0.10008 - acc: 0.9663 -- iter: 1312/1702
[A[ATraining Step: 528  | total loss: [1m[32m0.09703[0m[0m | time: 356.703s
[2K
| Adam | epoch: 010 | loss: 0.09703 - acc: 0.9635 -- iter: 1344/1702
[A[ATraining Step: 529  | total loss: [1m[32m0.09358[0m[0m | time: 366.023s
[2K
| Adam | epoch: 010 | loss: 0.09358 - acc: 0.9640 -- iter: 1376/1702
[A[ATraining Step: 530  | total loss: [1m[32m0.10249[0m[0m | time: 375.345s
[2K
| Adam | epoch: 010 | loss: 0.10249 - acc: 0.9645 -- iter: 1408/1702
[A[ATraining Step: 531  | total loss: [1m[32m0.09676[0m[0m | time: 384.457s
[2K
| Adam | epoch: 010 | loss: 0.09676 - acc: 0.9649 -- iter: 1440/1702
[A[ATraining Step: 532  | total loss: [1m[32m0.08799[0m[0m | time: 393.445s
[2K
| Adam | epoch: 010 | loss: 0.08799 - acc: 0.9684 -- iter: 1472/1702
[A[ATraining Step: 533  | total loss: [1m[32m0.10047[0m[0m | time: 402.520s
[2K
| Adam | epoch: 010 | loss: 0.10047 - acc: 0.9653 -- iter: 1504/1702
[A[ATraining Step: 534  | total loss: [1m[32m0.09871[0m[0m | time: 411.961s
[2K
| Adam | epoch: 010 | loss: 0.09871 - acc: 0.9625 -- iter: 1536/1702
[A[ATraining Step: 535  | total loss: [1m[32m0.13596[0m[0m | time: 420.916s
[2K
| Adam | epoch: 010 | loss: 0.13596 - acc: 0.9538 -- iter: 1568/1702
[A[ATraining Step: 536  | total loss: [1m[32m0.12371[0m[0m | time: 429.994s
[2K
| Adam | epoch: 010 | loss: 0.12371 - acc: 0.9584 -- iter: 1600/1702
[A[ATraining Step: 537  | total loss: [1m[32m0.11724[0m[0m | time: 439.292s
[2K
| Adam | epoch: 010 | loss: 0.11724 - acc: 0.9594 -- iter: 1632/1702
[A[ATraining Step: 538  | total loss: [1m[32m0.11846[0m[0m | time: 448.489s
[2K
| Adam | epoch: 010 | loss: 0.11846 - acc: 0.9604 -- iter: 1664/1702
[A[ATraining Step: 539  | total loss: [1m[32m0.11372[0m[0m | time: 457.659s
[2K
| Adam | epoch: 010 | loss: 0.11372 - acc: 0.9612 -- iter: 1696/1702
[A[ATraining Step: 540  | total loss: [1m[32m0.10666[0m[0m | time: 495.465s
[2K
| Adam | epoch: 010 | loss: 0.10666 - acc: 0.9651 | val_loss: 0.65989 - val_acc: 0.7355 -- iter: 1702/1702
--
Training Step: 541  | total loss: [1m[32m0.09976[0m[0m | time: 8.868s
[2K
| Adam | epoch: 011 | loss: 0.09976 - acc: 0.9686 -- iter: 0032/1702
[A[ATraining Step: 542  | total loss: [1m[32m0.09342[0m[0m | time: 17.881s
[2K
| Adam | epoch: 011 | loss: 0.09342 - acc: 0.9717 -- iter: 0064/1702
[A[ATraining Step: 543  | total loss: [1m[32m0.08911[0m[0m | time: 25.953s
[2K
| Adam | epoch: 011 | loss: 0.08911 - acc: 0.9745 -- iter: 0096/1702
[A[ATraining Step: 544  | total loss: [1m[32m0.08224[0m[0m | time: 33.670s
[2K
| Adam | epoch: 011 | loss: 0.08224 - acc: 0.9771 -- iter: 0128/1702
[A[ATraining Step: 545  | total loss: [1m[32m0.10112[0m[0m | time: 41.529s
[2K
| Adam | epoch: 011 | loss: 0.10112 - acc: 0.9731 -- iter: 0160/1702
[A[ATraining Step: 546  | total loss: [1m[32m0.12161[0m[0m | time: 49.291s
[2K
| Adam | epoch: 011 | loss: 0.12161 - acc: 0.9664 -- iter: 0192/1702
[A[ATraining Step: 547  | total loss: [1m[32m0.11417[0m[0m | time: 57.274s
[2K
| Adam | epoch: 011 | loss: 0.11417 - acc: 0.9667 -- iter: 0224/1702
[A[ATraining Step: 548  | total loss: [1m[32m0.10719[0m[0m | time: 65.135s
[2K
| Adam | epoch: 011 | loss: 0.10719 - acc: 0.9700 -- iter: 0256/1702
[A[ATraining Step: 549  | total loss: [1m[32m0.10593[0m[0m | time: 67.367s
[2K
| Adam | epoch: 011 | loss: 0.10593 - acc: 0.9699 -- iter: 0288/1702
[A[ATraining Step: 550  | total loss: [1m[32m0.09731[0m[0m | time: 69.594s
[2K
| Adam | epoch: 011 | loss: 0.09731 - acc: 0.9729 -- iter: 0320/1702
[A[ATraining Step: 551  | total loss: [1m[32m0.08845[0m[0m | time: 77.495s
[2K
| Adam | epoch: 011 | loss: 0.08845 - acc: 0.9756 -- iter: 0352/1702
[A[ATraining Step: 552  | total loss: [1m[32m0.08484[0m[0m | time: 85.203s
[2K
| Adam | epoch: 011 | loss: 0.08484 - acc: 0.9780 -- iter: 0384/1702
[A[ATraining Step: 553  | total loss: [1m[32m0.08551[0m[0m | time: 93.004s
[2K
| Adam | epoch: 011 | loss: 0.08551 - acc: 0.9740 -- iter: 0416/1702
[A[ATraining Step: 554  | total loss: [1m[32m0.08093[0m[0m | time: 100.619s
[2K
| Adam | epoch: 011 | loss: 0.08093 - acc: 0.9766 -- iter: 0448/1702
[A[ATraining Step: 555  | total loss: [1m[32m0.07730[0m[0m | time: 108.515s
[2K
| Adam | epoch: 011 | loss: 0.07730 - acc: 0.9758 -- iter: 0480/1702
[A[ATraining Step: 556  | total loss: [1m[32m0.07124[0m[0m | time: 116.264s
[2K
| Adam | epoch: 011 | loss: 0.07124 - acc: 0.9782 -- iter: 0512/1702
[A[ATraining Step: 557  | total loss: [1m[32m0.07224[0m[0m | time: 124.059s
[2K
| Adam | epoch: 011 | loss: 0.07224 - acc: 0.9773 -- iter: 0544/1702
[A[ATraining Step: 558  | total loss: [1m[32m0.08426[0m[0m | time: 131.877s
[2K
| Adam | epoch: 011 | loss: 0.08426 - acc: 0.9702 -- iter: 0576/1702
[A[ATraining Step: 559  | total loss: [1m[32m0.08391[0m[0m | time: 139.650s
[2K
| Adam | epoch: 011 | loss: 0.08391 - acc: 0.9700 -- iter: 0608/1702
[A[ATraining Step: 560  | total loss: [1m[32m0.07799[0m[0m | time: 147.432s
[2K
| Adam | epoch: 011 | loss: 0.07799 - acc: 0.9730 -- iter: 0640/1702
[A[ATraining Step: 561  | total loss: [1m[32m0.08314[0m[0m | time: 155.211s
[2K
| Adam | epoch: 011 | loss: 0.08314 - acc: 0.9695 -- iter: 0672/1702
[A[ATraining Step: 562  | total loss: [1m[32m0.11593[0m[0m | time: 163.107s
[2K
| Adam | epoch: 011 | loss: 0.11593 - acc: 0.9600 -- iter: 0704/1702
[A[ATraining Step: 563  | total loss: [1m[32m0.10895[0m[0m | time: 170.840s
[2K
| Adam | epoch: 011 | loss: 0.10895 - acc: 0.9609 -- iter: 0736/1702
[A[ATraining Step: 564  | total loss: [1m[32m0.11416[0m[0m | time: 178.558s
[2K
| Adam | epoch: 011 | loss: 0.11416 - acc: 0.9554 -- iter: 0768/1702
[A[ATraining Step: 565  | total loss: [1m[32m0.10489[0m[0m | time: 186.364s
[2K
| Adam | epoch: 011 | loss: 0.10489 - acc: 0.9599 -- iter: 0800/1702
[A[ATraining Step: 566  | total loss: [1m[32m0.09821[0m[0m | time: 194.174s
[2K
| Adam | epoch: 011 | loss: 0.09821 - acc: 0.9639 -- iter: 0832/1702
[A[ATraining Step: 567  | total loss: [1m[32m0.09415[0m[0m | time: 202.007s
[2K
| Adam | epoch: 011 | loss: 0.09415 - acc: 0.9644 -- iter: 0864/1702
[A[ATraining Step: 568  | total loss: [1m[32m0.12292[0m[0m | time: 209.781s
[2K
| Adam | epoch: 011 | loss: 0.12292 - acc: 0.9586 -- iter: 0896/1702
[A[ATraining Step: 569  | total loss: [1m[32m0.12925[0m[0m | time: 217.569s
[2K
| Adam | epoch: 011 | loss: 0.12925 - acc: 0.9565 -- iter: 0928/1702
[A[ATraining Step: 570  | total loss: [1m[32m0.12898[0m[0m | time: 225.407s
[2K
| Adam | epoch: 011 | loss: 0.12898 - acc: 0.9514 -- iter: 0960/1702
[A[ATraining Step: 571  | total loss: [1m[32m0.12255[0m[0m | time: 233.232s
[2K
| Adam | epoch: 011 | loss: 0.12255 - acc: 0.9532 -- iter: 0992/1702
[A[ATraining Step: 572  | total loss: [1m[32m0.11440[0m[0m | time: 241.296s
[2K
| Adam | epoch: 011 | loss: 0.11440 - acc: 0.9547 -- iter: 1024/1702
[A[ATraining Step: 573  | total loss: [1m[32m0.14481[0m[0m | time: 249.080s
[2K
| Adam | epoch: 011 | loss: 0.14481 - acc: 0.9499 -- iter: 1056/1702
[A[ATraining Step: 574  | total loss: [1m[32m0.13596[0m[0m | time: 256.864s
[2K
| Adam | epoch: 011 | loss: 0.13596 - acc: 0.9549 -- iter: 1088/1702
[A[ATraining Step: 575  | total loss: [1m[32m0.13749[0m[0m | time: 264.939s
[2K
| Adam | epoch: 011 | loss: 0.13749 - acc: 0.9563 -- iter: 1120/1702
[A[ATraining Step: 576  | total loss: [1m[32m0.14231[0m[0m | time: 272.897s
[2K
| Adam | epoch: 011 | loss: 0.14231 - acc: 0.9575 -- iter: 1152/1702
[A[ATraining Step: 577  | total loss: [1m[32m0.13587[0m[0m | time: 280.762s
[2K
| Adam | epoch: 011 | loss: 0.13587 - acc: 0.9587 -- iter: 1184/1702
[A[ATraining Step: 578  | total loss: [1m[32m0.13536[0m[0m | time: 290.461s
[2K
| Adam | epoch: 011 | loss: 0.13536 - acc: 0.9597 -- iter: 1216/1702
[A[ATraining Step: 579  | total loss: [1m[32m0.13878[0m[0m | time: 302.908s
[2K
| Adam | epoch: 011 | loss: 0.13878 - acc: 0.9574 -- iter: 1248/1702
[A[ATraining Step: 580  | total loss: [1m[32m0.13224[0m[0m | time: 315.857s
[2K
| Adam | epoch: 011 | loss: 0.13224 - acc: 0.9586 -- iter: 1280/1702
[A[ATraining Step: 581  | total loss: [1m[32m0.12325[0m[0m | time: 328.642s
[2K
| Adam | epoch: 011 | loss: 0.12325 - acc: 0.9627 -- iter: 1312/1702
[A[ATraining Step: 582  | total loss: [1m[32m0.11296[0m[0m | time: 341.707s
[2K
| Adam | epoch: 011 | loss: 0.11296 - acc: 0.9664 -- iter: 1344/1702
[A[ATraining Step: 583  | total loss: [1m[32m0.10352[0m[0m | time: 354.473s
[2K
| Adam | epoch: 011 | loss: 0.10352 - acc: 0.9698 -- iter: 1376/1702
[A[ATraining Step: 584  | total loss: [1m[32m0.10013[0m[0m | time: 367.500s
[2K
| Adam | epoch: 011 | loss: 0.10013 - acc: 0.9728 -- iter: 1408/1702
[A[ATraining Step: 585  | total loss: [1m[32m0.10829[0m[0m | time: 380.700s
[2K
| Adam | epoch: 011 | loss: 0.10829 - acc: 0.9724 -- iter: 1440/1702
[A[ATraining Step: 586  | total loss: [1m[32m0.10795[0m[0m | time: 388.489s
[2K
| Adam | epoch: 011 | loss: 0.10795 - acc: 0.9720 -- iter: 1472/1702
[A[ATraining Step: 587  | total loss: [1m[32m0.10573[0m[0m | time: 398.875s
[2K
| Adam | epoch: 011 | loss: 0.10573 - acc: 0.9717 -- iter: 1504/1702
[A[ATraining Step: 588  | total loss: [1m[32m0.10627[0m[0m | time: 406.609s
[2K
| Adam | epoch: 011 | loss: 0.10627 - acc: 0.9652 -- iter: 1536/1702
[A[ATraining Step: 589  | total loss: [1m[32m0.10268[0m[0m | time: 414.387s
[2K
| Adam | epoch: 011 | loss: 0.10268 - acc: 0.9624 -- iter: 1568/1702
[A[ATraining Step: 590  | total loss: [1m[32m0.09512[0m[0m | time: 422.259s
[2K
| Adam | epoch: 011 | loss: 0.09512 - acc: 0.9662 -- iter: 1600/1702
[A[ATraining Step: 591  | total loss: [1m[32m0.10142[0m[0m | time: 430.863s
[2K
| Adam | epoch: 011 | loss: 0.10142 - acc: 0.9633 -- iter: 1632/1702
[A[ATraining Step: 592  | total loss: [1m[32m0.10189[0m[0m | time: 443.649s
[2K
| Adam | epoch: 011 | loss: 0.10189 - acc: 0.9607 -- iter: 1664/1702
[A[ATraining Step: 593  | total loss: [1m[32m0.10690[0m[0m | time: 456.282s
[2K
| Adam | epoch: 011 | loss: 0.10690 - acc: 0.9553 -- iter: 1696/1702
[A[ATraining Step: 594  | total loss: [1m[32m0.10382[0m[0m | time: 510.858s
[2K
| Adam | epoch: 011 | loss: 0.10382 - acc: 0.9566 | val_loss: 0.32115 - val_acc: 0.8780 -- iter: 1702/1702
--
Training Step: 595  | total loss: [1m[32m0.09749[0m[0m | time: 7.721s
[2K
| Adam | epoch: 012 | loss: 0.09749 - acc: 0.9610 -- iter: 0032/1702
[A[ATraining Step: 596  | total loss: [1m[32m0.09292[0m[0m | time: 15.923s
[2K
| Adam | epoch: 012 | loss: 0.09292 - acc: 0.9617 -- iter: 0064/1702
[A[ATraining Step: 597  | total loss: [1m[32m0.09409[0m[0m | time: 29.033s
[2K
| Adam | epoch: 012 | loss: 0.09409 - acc: 0.9624 -- iter: 0096/1702
[A[ATraining Step: 598  | total loss: [1m[32m0.08588[0m[0m | time: 41.651s
[2K
| Adam | epoch: 012 | loss: 0.08588 - acc: 0.9662 -- iter: 0128/1702
[A[ATraining Step: 599  | total loss: [1m[32m0.07827[0m[0m | time: 54.424s
[2K
| Adam | epoch: 012 | loss: 0.07827 - acc: 0.9696 -- iter: 0160/1702
[A[ATraining Step: 600  | total loss: [1m[32m0.07877[0m[0m | time: 108.561s
[2K
| Adam | epoch: 012 | loss: 0.07877 - acc: 0.9695 | val_loss: 0.23892 - val_acc: 0.9174 -- iter: 0192/1702
--
Training Step: 601  | total loss: [1m[32m0.08021[0m[0m | time: 118.982s
[2K
| Adam | epoch: 012 | loss: 0.08021 - acc: 0.9663 -- iter: 0224/1702
[A[ATraining Step: 602  | total loss: [1m[32m0.07947[0m[0m | time: 132.059s
[2K
| Adam | epoch: 012 | loss: 0.07947 - acc: 0.9665 -- iter: 0256/1702
[A[ATraining Step: 603  | total loss: [1m[32m0.07955[0m[0m | time: 144.791s
[2K
| Adam | epoch: 012 | loss: 0.07955 - acc: 0.9668 -- iter: 0288/1702
[A[ATraining Step: 604  | total loss: [1m[32m0.07310[0m[0m | time: 148.762s
[2K
| Adam | epoch: 012 | loss: 0.07310 - acc: 0.9701 -- iter: 0320/1702
[A[ATraining Step: 605  | total loss: [1m[32m0.09784[0m[0m | time: 153.175s
[2K
| Adam | epoch: 012 | loss: 0.09784 - acc: 0.9564 -- iter: 0352/1702
[A[ATraining Step: 606  | total loss: [1m[32m0.08947[0m[0m | time: 166.280s
[2K
| Adam | epoch: 012 | loss: 0.08947 - acc: 0.9608 -- iter: 0384/1702
[A[ATraining Step: 607  | total loss: [1m[32m0.08724[0m[0m | time: 180.445s
[2K
| Adam | epoch: 012 | loss: 0.08724 - acc: 0.9616 -- iter: 0416/1702
[A[ATraining Step: 608  | total loss: [1m[32m0.08786[0m[0m | time: 193.979s
[2K
| Adam | epoch: 012 | loss: 0.08786 - acc: 0.9623 -- iter: 0448/1702
[A[ATraining Step: 609  | total loss: [1m[32m0.09046[0m[0m | time: 206.975s
[2K
| Adam | epoch: 012 | loss: 0.09046 - acc: 0.9629 -- iter: 0480/1702
[A[ATraining Step: 610  | total loss: [1m[32m0.09047[0m[0m | time: 215.355s
[2K
| Adam | epoch: 012 | loss: 0.09047 - acc: 0.9635 -- iter: 0512/1702
[A[ATraining Step: 611  | total loss: [1m[32m0.10688[0m[0m | time: 223.055s
[2K
| Adam | epoch: 012 | loss: 0.10688 - acc: 0.9609 -- iter: 0544/1702
[A[ATraining Step: 612  | total loss: [1m[32m0.11079[0m[0m | time: 230.868s
[2K
| Adam | epoch: 012 | loss: 0.11079 - acc: 0.9617 -- iter: 0576/1702
[A[ATraining Step: 613  | total loss: [1m[32m0.11258[0m[0m | time: 243.375s
[2K
| Adam | epoch: 012 | loss: 0.11258 - acc: 0.9562 -- iter: 0608/1702
[A[ATraining Step: 614  | total loss: [1m[32m0.11099[0m[0m | time: 257.965s
[2K
| Adam | epoch: 012 | loss: 0.11099 - acc: 0.9543 -- iter: 0640/1702
[A[ATraining Step: 615  | total loss: [1m[32m0.10753[0m[0m | time: 270.400s
[2K
| Adam | epoch: 012 | loss: 0.10753 - acc: 0.9557 -- iter: 0672/1702
[A[ATraining Step: 616  | total loss: [1m[32m0.10728[0m[0m | time: 283.148s
[2K
| Adam | epoch: 012 | loss: 0.10728 - acc: 0.9570 -- iter: 0704/1702
[A[ATraining Step: 617  | total loss: [1m[32m0.12953[0m[0m | time: 296.281s
[2K
| Adam | epoch: 012 | loss: 0.12953 - acc: 0.9488 -- iter: 0736/1702
[A[ATraining Step: 618  | total loss: [1m[32m0.12141[0m[0m | time: 309.147s
[2K
| Adam | epoch: 012 | loss: 0.12141 - acc: 0.9508 -- iter: 0768/1702
[A[ATraining Step: 619  | total loss: [1m[32m0.16212[0m[0m | time: 322.537s
[2K
| Adam | epoch: 012 | loss: 0.16212 - acc: 0.9339 -- iter: 0800/1702
[A[ATraining Step: 620  | total loss: [1m[32m0.15076[0m[0m | time: 333.279s
[2K
| Adam | epoch: 012 | loss: 0.15076 - acc: 0.9405 -- iter: 0832/1702
[A[ATraining Step: 621  | total loss: [1m[32m0.14265[0m[0m | time: 341.158s
[2K
| Adam | epoch: 012 | loss: 0.14265 - acc: 0.9433 -- iter: 0864/1702
[A[ATraining Step: 622  | total loss: [1m[32m0.16646[0m[0m | time: 349.178s
[2K
| Adam | epoch: 012 | loss: 0.16646 - acc: 0.9365 -- iter: 0896/1702
[A[ATraining Step: 623  | total loss: [1m[32m0.16394[0m[0m | time: 362.680s
[2K
| Adam | epoch: 012 | loss: 0.16394 - acc: 0.9366 -- iter: 0928/1702
[A[ATraining Step: 624  | total loss: [1m[32m0.15680[0m[0m | time: 378.334s
[2K
| Adam | epoch: 012 | loss: 0.15680 - acc: 0.9398 -- iter: 0960/1702
[A[ATraining Step: 625  | total loss: [1m[32m0.15861[0m[0m | time: 391.089s
[2K
| Adam | epoch: 012 | loss: 0.15861 - acc: 0.9396 -- iter: 0992/1702
[A[ATraining Step: 626  | total loss: [1m[32m0.16256[0m[0m | time: 403.082s
[2K
| Adam | epoch: 012 | loss: 0.16256 - acc: 0.9394 -- iter: 1024/1702
[A[ATraining Step: 627  | total loss: [1m[32m0.15607[0m[0m | time: 415.465s
[2K
| Adam | epoch: 012 | loss: 0.15607 - acc: 0.9423 -- iter: 1056/1702
[A[ATraining Step: 628  | total loss: [1m[32m0.16136[0m[0m | time: 428.333s
[2K
| Adam | epoch: 012 | loss: 0.16136 - acc: 0.9449 -- iter: 1088/1702
[A[ATraining Step: 629  | total loss: [1m[32m0.15172[0m[0m | time: 441.766s
[2K
| Adam | epoch: 012 | loss: 0.15172 - acc: 0.9473 -- iter: 1120/1702
[A[ATraining Step: 630  | total loss: [1m[32m0.15400[0m[0m | time: 452.368s
[2K
| Adam | epoch: 012 | loss: 0.15400 - acc: 0.9463 -- iter: 1152/1702
[A[ATraining Step: 631  | total loss: [1m[32m0.14693[0m[0m | time: 460.171s
[2K
| Adam | epoch: 012 | loss: 0.14693 - acc: 0.9517 -- iter: 1184/1702
[A[ATraining Step: 632  | total loss: [1m[32m0.14054[0m[0m | time: 468.024s
[2K
| Adam | epoch: 012 | loss: 0.14054 - acc: 0.9534 -- iter: 1216/1702
[A[ATraining Step: 633  | total loss: [1m[32m0.13972[0m[0m | time: 478.516s
[2K
| Adam | epoch: 012 | loss: 0.13972 - acc: 0.9549 -- iter: 1248/1702
[A[ATraining Step: 634  | total loss: [1m[32m0.14309[0m[0m | time: 491.252s
[2K
| Adam | epoch: 012 | loss: 0.14309 - acc: 0.9563 -- iter: 1280/1702
[A[ATraining Step: 635  | total loss: [1m[32m0.13760[0m[0m | time: 504.477s
[2K
| Adam | epoch: 012 | loss: 0.13760 - acc: 0.9576 -- iter: 1312/1702
[A[ATraining Step: 636  | total loss: [1m[32m0.13216[0m[0m | time: 517.412s
[2K
| Adam | epoch: 012 | loss: 0.13216 - acc: 0.9618 -- iter: 1344/1702
[A[ATraining Step: 637  | total loss: [1m[32m0.12408[0m[0m | time: 530.393s
[2K
| Adam | epoch: 012 | loss: 0.12408 - acc: 0.9656 -- iter: 1376/1702
[A[ATraining Step: 638  | total loss: [1m[32m0.13101[0m[0m | time: 542.666s
[2K
| Adam | epoch: 012 | loss: 0.13101 - acc: 0.9597 -- iter: 1408/1702
[A[ATraining Step: 639  | total loss: [1m[32m0.13036[0m[0m | time: 555.613s
[2K
| Adam | epoch: 012 | loss: 0.13036 - acc: 0.9575 -- iter: 1440/1702
[A[ATraining Step: 640  | total loss: [1m[32m0.12026[0m[0m | time: 567.894s
[2K
| Adam | epoch: 012 | loss: 0.12026 - acc: 0.9617 -- iter: 1472/1702
[A[ATraining Step: 641  | total loss: [1m[32m0.11455[0m[0m | time: 575.678s
[2K
| Adam | epoch: 012 | loss: 0.11455 - acc: 0.9624 -- iter: 1504/1702
[A[ATraining Step: 642  | total loss: [1m[32m0.12214[0m[0m | time: 583.623s
[2K
| Adam | epoch: 012 | loss: 0.12214 - acc: 0.9631 -- iter: 1536/1702
[A[ATraining Step: 643  | total loss: [1m[32m0.11858[0m[0m | time: 593.165s
[2K
| Adam | epoch: 012 | loss: 0.11858 - acc: 0.9636 -- iter: 1568/1702
[A[ATraining Step: 644  | total loss: [1m[32m0.11437[0m[0m | time: 605.824s
[2K
| Adam | epoch: 012 | loss: 0.11437 - acc: 0.9641 -- iter: 1600/1702
[A[ATraining Step: 645  | total loss: [1m[32m0.10799[0m[0m | time: 618.853s
[2K
| Adam | epoch: 012 | loss: 0.10799 - acc: 0.9646 -- iter: 1632/1702
[A[ATraining Step: 646  | total loss: [1m[32m0.10202[0m[0m | time: 631.448s
[2K
| Adam | epoch: 012 | loss: 0.10202 - acc: 0.9681 -- iter: 1664/1702
[A[ATraining Step: 647  | total loss: [1m[32m0.11946[0m[0m | time: 644.246s
[2K
| Adam | epoch: 012 | loss: 0.11946 - acc: 0.9588 -- iter: 1696/1702
[A[ATraining Step: 648  | total loss: [1m[32m0.10877[0m[0m | time: 693.106s
[2K
| Adam | epoch: 012 | loss: 0.10877 - acc: 0.9629 | val_loss: 0.31564 - val_acc: 0.9043 -- iter: 1702/1702
--
Training Step: 649  | total loss: [1m[32m0.10098[0m[0m | time: 12.901s
[2K
| Adam | epoch: 013 | loss: 0.10098 - acc: 0.9667 -- iter: 0032/1702
[A[ATraining Step: 650  | total loss: [1m[32m0.11399[0m[0m | time: 25.471s
[2K
| Adam | epoch: 013 | loss: 0.11399 - acc: 0.9637 -- iter: 0064/1702
[A[ATraining Step: 651  | total loss: [1m[32m0.10457[0m[0m | time: 38.082s
[2K
| Adam | epoch: 013 | loss: 0.10457 - acc: 0.9674 -- iter: 0096/1702
[A[ATraining Step: 652  | total loss: [1m[32m0.09737[0m[0m | time: 50.780s
[2K
| Adam | epoch: 013 | loss: 0.09737 - acc: 0.9706 -- iter: 0128/1702
[A[ATraining Step: 653  | total loss: [1m[32m0.09407[0m[0m | time: 63.914s
[2K
| Adam | epoch: 013 | loss: 0.09407 - acc: 0.9704 -- iter: 0160/1702
[A[ATraining Step: 654  | total loss: [1m[32m0.08704[0m[0m | time: 76.488s
[2K
| Adam | epoch: 013 | loss: 0.08704 - acc: 0.9734 -- iter: 0192/1702
[A[ATraining Step: 655  | total loss: [1m[32m0.08257[0m[0m | time: 88.602s
[2K
| Adam | epoch: 013 | loss: 0.08257 - acc: 0.9729 -- iter: 0224/1702
[A[ATraining Step: 656  | total loss: [1m[32m0.07802[0m[0m | time: 96.447s
[2K
| Adam | epoch: 013 | loss: 0.07802 - acc: 0.9756 -- iter: 0256/1702
[A[ATraining Step: 657  | total loss: [1m[32m0.08006[0m[0m | time: 104.166s
[2K
| Adam | epoch: 013 | loss: 0.08006 - acc: 0.9749 -- iter: 0288/1702
[A[ATraining Step: 658  | total loss: [1m[32m0.07755[0m[0m | time: 111.896s
[2K
| Adam | epoch: 013 | loss: 0.07755 - acc: 0.9743 -- iter: 0320/1702
[A[ATraining Step: 659  | total loss: [1m[32m0.07422[0m[0m | time: 114.065s
[2K
| Adam | epoch: 013 | loss: 0.07422 - acc: 0.9738 -- iter: 0352/1702
[A[ATraining Step: 660  | total loss: [1m[32m0.14010[0m[0m | time: 116.264s
[2K
| Adam | epoch: 013 | loss: 0.14010 - acc: 0.9597 -- iter: 0384/1702
[A[ATraining Step: 661  | total loss: [1m[32m0.13126[0m[0m | time: 129.778s
[2K
| Adam | epoch: 013 | loss: 0.13126 - acc: 0.9638 -- iter: 0416/1702
[A[ATraining Step: 662  | total loss: [1m[32m0.12803[0m[0m | time: 142.693s
[2K
| Adam | epoch: 013 | loss: 0.12803 - acc: 0.9643 -- iter: 0448/1702
[A[ATraining Step: 663  | total loss: [1m[32m0.12431[0m[0m | time: 155.261s
[2K
| Adam | epoch: 013 | loss: 0.12431 - acc: 0.9678 -- iter: 0480/1702
[A[ATraining Step: 664  | total loss: [1m[32m0.12167[0m[0m | time: 168.228s
[2K
| Adam | epoch: 013 | loss: 0.12167 - acc: 0.9648 -- iter: 0512/1702
[A[ATraining Step: 665  | total loss: [1m[32m0.12670[0m[0m | time: 180.935s
[2K
| Adam | epoch: 013 | loss: 0.12670 - acc: 0.9589 -- iter: 0544/1702
[A[ATraining Step: 666  | total loss: [1m[32m0.13612[0m[0m | time: 193.702s
[2K
| Adam | epoch: 013 | loss: 0.13612 - acc: 0.9537 -- iter: 0576/1702
[A[ATraining Step: 667  | total loss: [1m[32m0.17649[0m[0m | time: 206.829s
[2K
| Adam | epoch: 013 | loss: 0.17649 - acc: 0.9427 -- iter: 0608/1702
[A[ATraining Step: 668  | total loss: [1m[32m0.16472[0m[0m | time: 217.434s
[2K
| Adam | epoch: 013 | loss: 0.16472 - acc: 0.9453 -- iter: 0640/1702
[A[ATraining Step: 669  | total loss: [1m[32m0.15934[0m[0m | time: 225.315s
[2K
| Adam | epoch: 013 | loss: 0.15934 - acc: 0.9445 -- iter: 0672/1702
[A[ATraining Step: 670  | total loss: [1m[32m0.15561[0m[0m | time: 233.241s
[2K
| Adam | epoch: 013 | loss: 0.15561 - acc: 0.9438 -- iter: 0704/1702
[A[ATraining Step: 671  | total loss: [1m[32m0.15837[0m[0m | time: 245.289s
[2K
| Adam | epoch: 013 | loss: 0.15837 - acc: 0.9463 -- iter: 0736/1702
[A[ATraining Step: 672  | total loss: [1m[32m0.14675[0m[0m | time: 258.611s
[2K
| Adam | epoch: 013 | loss: 0.14675 - acc: 0.9517 -- iter: 0768/1702
[A[ATraining Step: 673  | total loss: [1m[32m0.14622[0m[0m | time: 271.475s
[2K
| Adam | epoch: 013 | loss: 0.14622 - acc: 0.9503 -- iter: 0800/1702
[A[ATraining Step: 674  | total loss: [1m[32m0.15945[0m[0m | time: 284.299s
[2K
| Adam | epoch: 013 | loss: 0.15945 - acc: 0.9490 -- iter: 0832/1702
[A[ATraining Step: 675  | total loss: [1m[32m0.14769[0m[0m | time: 297.275s
[2K
| Adam | epoch: 013 | loss: 0.14769 - acc: 0.9541 -- iter: 0864/1702
[A[ATraining Step: 676  | total loss: [1m[32m0.14863[0m[0m | time: 309.555s
[2K
| Adam | epoch: 013 | loss: 0.14863 - acc: 0.9555 -- iter: 0896/1702
[A[ATraining Step: 677  | total loss: [1m[32m0.14256[0m[0m | time: 322.099s
[2K
| Adam | epoch: 013 | loss: 0.14256 - acc: 0.9569 -- iter: 0928/1702
[A[ATraining Step: 678  | total loss: [1m[32m0.13158[0m[0m | time: 333.649s
[2K
| Adam | epoch: 013 | loss: 0.13158 - acc: 0.9612 -- iter: 0960/1702
[A[ATraining Step: 679  | total loss: [1m[32m0.15440[0m[0m | time: 341.772s
[2K
| Adam | epoch: 013 | loss: 0.15440 - acc: 0.9557 -- iter: 0992/1702
[A[ATraining Step: 680  | total loss: [1m[32m0.15473[0m[0m | time: 349.684s
[2K
| Adam | epoch: 013 | loss: 0.15473 - acc: 0.9539 -- iter: 1024/1702
[A[ATraining Step: 681  | total loss: [1m[32m0.15049[0m[0m | time: 357.525s
[2K
| Adam | epoch: 013 | loss: 0.15049 - acc: 0.9522 -- iter: 1056/1702
[A[ATraining Step: 682  | total loss: [1m[32m0.14584[0m[0m | time: 366.906s
[2K
| Adam | epoch: 013 | loss: 0.14584 - acc: 0.9539 -- iter: 1088/1702
[A[ATraining Step: 683  | total loss: [1m[32m0.14845[0m[0m | time: 379.113s
[2K
| Adam | epoch: 013 | loss: 0.14845 - acc: 0.9554 -- iter: 1120/1702
[A[ATraining Step: 684  | total loss: [1m[32m0.14843[0m[0m | time: 391.682s
[2K
| Adam | epoch: 013 | loss: 0.14843 - acc: 0.9536 -- iter: 1152/1702
[A[ATraining Step: 685  | total loss: [1m[32m0.14317[0m[0m | time: 404.951s
[2K
| Adam | epoch: 013 | loss: 0.14317 - acc: 0.9551 -- iter: 1184/1702
[A[ATraining Step: 686  | total loss: [1m[32m0.13157[0m[0m | time: 418.226s
[2K
| Adam | epoch: 013 | loss: 0.13157 - acc: 0.9596 -- iter: 1216/1702
[A[ATraining Step: 687  | total loss: [1m[32m0.12305[0m[0m | time: 431.873s
[2K
| Adam | epoch: 013 | loss: 0.12305 - acc: 0.9636 -- iter: 1248/1702
[A[ATraining Step: 688  | total loss: [1m[32m0.12344[0m[0m | time: 444.982s
[2K
| Adam | epoch: 013 | loss: 0.12344 - acc: 0.9610 -- iter: 1280/1702
[A[ATraining Step: 689  | total loss: [1m[32m0.11958[0m[0m | time: 458.035s
[2K
| Adam | epoch: 013 | loss: 0.11958 - acc: 0.9618 -- iter: 1312/1702
[A[ATraining Step: 690  | total loss: [1m[32m0.12135[0m[0m | time: 465.929s
[2K
| Adam | epoch: 013 | loss: 0.12135 - acc: 0.9625 -- iter: 1344/1702
[A[ATraining Step: 691  | total loss: [1m[32m0.11339[0m[0m | time: 473.800s
[2K
| Adam | epoch: 013 | loss: 0.11339 - acc: 0.9662 -- iter: 1376/1702
[A[ATraining Step: 692  | total loss: [1m[32m0.10956[0m[0m | time: 481.957s
[2K
| Adam | epoch: 013 | loss: 0.10956 - acc: 0.9665 -- iter: 1408/1702
[A[ATraining Step: 693  | total loss: [1m[32m0.10156[0m[0m | time: 494.998s
[2K
| Adam | epoch: 013 | loss: 0.10156 - acc: 0.9698 -- iter: 1440/1702
[A[ATraining Step: 694  | total loss: [1m[32m0.11221[0m[0m | time: 507.319s
[2K
| Adam | epoch: 013 | loss: 0.11221 - acc: 0.9572 -- iter: 1472/1702
[A[ATraining Step: 695  | total loss: [1m[32m0.10352[0m[0m | time: 520.303s
[2K
| Adam | epoch: 013 | loss: 0.10352 - acc: 0.9615 -- iter: 1504/1702
[A[ATraining Step: 696  | total loss: [1m[32m0.09676[0m[0m | time: 532.836s
[2K
| Adam | epoch: 013 | loss: 0.09676 - acc: 0.9654 -- iter: 1536/1702
[A[ATraining Step: 697  | total loss: [1m[32m0.09080[0m[0m | time: 545.421s
[2K
| Adam | epoch: 013 | loss: 0.09080 - acc: 0.9688 -- iter: 1568/1702
[A[ATraining Step: 698  | total loss: [1m[32m0.08762[0m[0m | time: 558.337s
[2K
| Adam | epoch: 013 | loss: 0.08762 - acc: 0.9688 -- iter: 1600/1702
[A[ATraining Step: 699  | total loss: [1m[32m0.09801[0m[0m | time: 571.078s
[2K
| Adam | epoch: 013 | loss: 0.09801 - acc: 0.9657 -- iter: 1632/1702
[A[ATraining Step: 700  | total loss: [1m[32m0.09312[0m[0m | time: 581.288s
[2K
| Adam | epoch: 013 | loss: 0.09312 - acc: 0.9660 -- iter: 1664/1702
[A[ATraining Step: 701  | total loss: [1m[32m0.10599[0m[0m | time: 589.318s
[2K
| Adam | epoch: 013 | loss: 0.10599 - acc: 0.9631 -- iter: 1696/1702
[A[ATraining Step: 702  | total loss: [1m[32m0.10155[0m[0m | time: 635.505s
[2K
| Adam | epoch: 013 | loss: 0.10155 - acc: 0.9637 | val_loss: 0.34788 - val_acc: 0.9118 -- iter: 1702/1702
--
Training Step: 703  | total loss: [1m[32m0.10101[0m[0m | time: 12.480s
[2K
| Adam | epoch: 014 | loss: 0.10101 - acc: 0.9611 -- iter: 0032/1702
[A[ATraining Step: 704  | total loss: [1m[32m0.09433[0m[0m | time: 25.640s
[2K
| Adam | epoch: 014 | loss: 0.09433 - acc: 0.9650 -- iter: 0064/1702
[A[ATraining Step: 705  | total loss: [1m[32m0.08848[0m[0m | time: 33.839s
[2K
| Adam | epoch: 014 | loss: 0.08848 - acc: 0.9654 -- iter: 0096/1702
[A[ATraining Step: 706  | total loss: [1m[32m0.08585[0m[0m | time: 41.619s
[2K
| Adam | epoch: 014 | loss: 0.08585 - acc: 0.9657 -- iter: 0128/1702
[A[ATraining Step: 707  | total loss: [1m[32m0.07929[0m[0m | time: 49.451s
[2K
| Adam | epoch: 014 | loss: 0.07929 - acc: 0.9691 -- iter: 0160/1702
[A[ATraining Step: 708  | total loss: [1m[32m0.10092[0m[0m | time: 62.563s
[2K
| Adam | epoch: 014 | loss: 0.10092 - acc: 0.9628 -- iter: 0192/1702
[A[ATraining Step: 709  | total loss: [1m[32m0.09387[0m[0m | time: 75.601s
[2K
| Adam | epoch: 014 | loss: 0.09387 - acc: 0.9666 -- iter: 0224/1702
[A[ATraining Step: 710  | total loss: [1m[32m0.09727[0m[0m | time: 88.097s
[2K
| Adam | epoch: 014 | loss: 0.09727 - acc: 0.9668 -- iter: 0256/1702
[A[ATraining Step: 711  | total loss: [1m[32m0.09350[0m[0m | time: 100.827s
[2K
| Adam | epoch: 014 | loss: 0.09350 - acc: 0.9670 -- iter: 0288/1702
[A[ATraining Step: 712  | total loss: [1m[32m0.08636[0m[0m | time: 113.338s
[2K
| Adam | epoch: 014 | loss: 0.08636 - acc: 0.9703 -- iter: 0320/1702
[A[ATraining Step: 713  | total loss: [1m[32m0.08815[0m[0m | time: 126.439s
[2K
| Adam | epoch: 014 | loss: 0.08815 - acc: 0.9701 -- iter: 0352/1702
[A[ATraining Step: 714  | total loss: [1m[32m0.10545[0m[0m | time: 130.084s
[2K
| Adam | epoch: 014 | loss: 0.10545 - acc: 0.9669 -- iter: 0384/1702
[A[ATraining Step: 715  | total loss: [1m[32m0.21614[0m[0m | time: 134.173s
[2K
| Adam | epoch: 014 | loss: 0.21614 - acc: 0.9368 -- iter: 0416/1702
[A[ATraining Step: 716  | total loss: [1m[32m0.20366[0m[0m | time: 145.609s
[2K
| Adam | epoch: 014 | loss: 0.20366 - acc: 0.9432 -- iter: 0448/1702
[A[ATraining Step: 717  | total loss: [1m[32m0.18555[0m[0m | time: 153.425s
[2K
| Adam | epoch: 014 | loss: 0.18555 - acc: 0.9488 -- iter: 0480/1702
[A[ATraining Step: 718  | total loss: [1m[32m0.18112[0m[0m | time: 161.221s
[2K
| Adam | epoch: 014 | loss: 0.18112 - acc: 0.9446 -- iter: 0512/1702
[A[ATraining Step: 719  | total loss: [1m[32m0.16962[0m[0m | time: 168.905s
[2K
| Adam | epoch: 014 | loss: 0.16962 - acc: 0.9470 -- iter: 0544/1702
[A[ATraining Step: 720  | total loss: [1m[32m0.17161[0m[0m | time: 179.761s
[2K
| Adam | epoch: 014 | loss: 0.17161 - acc: 0.9460 -- iter: 0576/1702
[A[ATraining Step: 721  | total loss: [1m[32m0.17721[0m[0m | time: 189.369s
[2K
| Adam | epoch: 014 | loss: 0.17721 - acc: 0.9421 -- iter: 0608/1702
[A[ATraining Step: 722  | total loss: [1m[32m0.19232[0m[0m | time: 197.256s
[2K
| Adam | epoch: 014 | loss: 0.19232 - acc: 0.9354 -- iter: 0640/1702
[A[ATraining Step: 723  | total loss: [1m[32m0.18517[0m[0m | time: 205.024s
[2K
| Adam | epoch: 014 | loss: 0.18517 - acc: 0.9387 -- iter: 0672/1702
[A[ATraining Step: 724  | total loss: [1m[32m0.17191[0m[0m | time: 212.905s
[2K
| Adam | epoch: 014 | loss: 0.17191 - acc: 0.9448 -- iter: 0704/1702
[A[ATraining Step: 725  | total loss: [1m[32m0.16029[0m[0m | time: 220.751s
[2K
| Adam | epoch: 014 | loss: 0.16029 - acc: 0.9503 -- iter: 0736/1702
[A[ATraining Step: 726  | total loss: [1m[32m0.15391[0m[0m | time: 228.606s
[2K
| Adam | epoch: 014 | loss: 0.15391 - acc: 0.9522 -- iter: 0768/1702
[A[ATraining Step: 727  | total loss: [1m[32m0.14523[0m[0m | time: 236.470s
[2K
| Adam | epoch: 014 | loss: 0.14523 - acc: 0.9570 -- iter: 0800/1702
[A[ATraining Step: 728  | total loss: [1m[32m0.14507[0m[0m | time: 244.240s
[2K
| Adam | epoch: 014 | loss: 0.14507 - acc: 0.9550 -- iter: 0832/1702
[A[ATraining Step: 729  | total loss: [1m[32m0.13848[0m[0m | time: 252.044s
[2K
| Adam | epoch: 014 | loss: 0.13848 - acc: 0.9595 -- iter: 0864/1702
[A[ATraining Step: 730  | total loss: [1m[32m0.14141[0m[0m | time: 259.876s
[2K
| Adam | epoch: 014 | loss: 0.14141 - acc: 0.9511 -- iter: 0896/1702
[A[ATraining Step: 731  | total loss: [1m[32m0.14539[0m[0m | time: 267.719s
[2K
| Adam | epoch: 014 | loss: 0.14539 - acc: 0.9466 -- iter: 0928/1702
[A[ATraining Step: 732  | total loss: [1m[32m0.14041[0m[0m | time: 275.666s
[2K
| Adam | epoch: 014 | loss: 0.14041 - acc: 0.9457 -- iter: 0960/1702
[A[ATraining Step: 733  | total loss: [1m[32m0.13999[0m[0m | time: 283.608s
[2K
| Adam | epoch: 014 | loss: 0.13999 - acc: 0.9449 -- iter: 0992/1702
[A[ATraining Step: 734  | total loss: [1m[32m0.13590[0m[0m | time: 291.433s
[2K
| Adam | epoch: 014 | loss: 0.13590 - acc: 0.9472 -- iter: 1024/1702
[A[ATraining Step: 735  | total loss: [1m[32m0.16163[0m[0m | time: 299.247s
[2K
| Adam | epoch: 014 | loss: 0.16163 - acc: 0.9400 -- iter: 1056/1702
[A[ATraining Step: 736  | total loss: [1m[32m0.15187[0m[0m | time: 307.231s
[2K
| Adam | epoch: 014 | loss: 0.15187 - acc: 0.9429 -- iter: 1088/1702
[A[ATraining Step: 737  | total loss: [1m[32m0.14293[0m[0m | time: 314.878s
[2K
| Adam | epoch: 014 | loss: 0.14293 - acc: 0.9486 -- iter: 1120/1702
[A[ATraining Step: 738  | total loss: [1m[32m0.18707[0m[0m | time: 322.758s
[2K
| Adam | epoch: 014 | loss: 0.18707 - acc: 0.9475 -- iter: 1152/1702
[A[ATraining Step: 739  | total loss: [1m[32m0.16884[0m[0m | time: 330.413s
[2K
| Adam | epoch: 014 | loss: 0.16884 - acc: 0.9527 -- iter: 1184/1702
[A[ATraining Step: 740  | total loss: [1m[32m0.15653[0m[0m | time: 338.309s
[2K
| Adam | epoch: 014 | loss: 0.15653 - acc: 0.9543 -- iter: 1216/1702
[A[ATraining Step: 741  | total loss: [1m[32m0.14227[0m[0m | time: 346.274s
[2K
| Adam | epoch: 014 | loss: 0.14227 - acc: 0.9589 -- iter: 1248/1702
[A[ATraining Step: 742  | total loss: [1m[32m0.13988[0m[0m | time: 353.888s
[2K
| Adam | epoch: 014 | loss: 0.13988 - acc: 0.9568 -- iter: 1280/1702
[A[ATraining Step: 743  | total loss: [1m[32m0.13080[0m[0m | time: 361.646s
[2K
| Adam | epoch: 014 | loss: 0.13080 - acc: 0.9580 -- iter: 1312/1702
[A[ATraining Step: 744  | total loss: [1m[32m0.12537[0m[0m | time: 369.432s
[2K
| Adam | epoch: 014 | loss: 0.12537 - acc: 0.9559 -- iter: 1344/1702
[A[ATraining Step: 745  | total loss: [1m[32m0.11814[0m[0m | time: 377.304s
[2K
| Adam | epoch: 014 | loss: 0.11814 - acc: 0.9603 -- iter: 1376/1702
[A[ATraining Step: 746  | total loss: [1m[32m0.12586[0m[0m | time: 385.353s
[2K
| Adam | epoch: 014 | loss: 0.12586 - acc: 0.9549 -- iter: 1408/1702
[A[ATraining Step: 747  | total loss: [1m[32m0.11455[0m[0m | time: 392.966s
[2K
| Adam | epoch: 014 | loss: 0.11455 - acc: 0.9594 -- iter: 1440/1702
[A[ATraining Step: 748  | total loss: [1m[32m0.11137[0m[0m | time: 400.607s
[2K
| Adam | epoch: 014 | loss: 0.11137 - acc: 0.9604 -- iter: 1472/1702
[A[ATraining Step: 749  | total loss: [1m[32m0.10574[0m[0m | time: 408.377s
[2K
| Adam | epoch: 014 | loss: 0.10574 - acc: 0.9612 -- iter: 1504/1702
[A[ATraining Step: 750  | total loss: [1m[32m0.10341[0m[0m | time: 416.254s
[2K
| Adam | epoch: 014 | loss: 0.10341 - acc: 0.9620 -- iter: 1536/1702
[A[ATraining Step: 751  | total loss: [1m[32m0.09854[0m[0m | time: 424.100s
[2K
| Adam | epoch: 014 | loss: 0.09854 - acc: 0.9658 -- iter: 1568/1702
[A[ATraining Step: 752  | total loss: [1m[32m0.09798[0m[0m | time: 431.946s
[2K
| Adam | epoch: 014 | loss: 0.09798 - acc: 0.9629 -- iter: 1600/1702
[A[ATraining Step: 753  | total loss: [1m[32m0.09396[0m[0m | time: 439.931s
[2K
| Adam | epoch: 014 | loss: 0.09396 - acc: 0.9666 -- iter: 1632/1702
[A[ATraining Step: 754  | total loss: [1m[32m0.09558[0m[0m | time: 447.741s
[2K
| Adam | epoch: 014 | loss: 0.09558 - acc: 0.9637 -- iter: 1664/1702
[A[ATraining Step: 755  | total loss: [1m[32m0.09846[0m[0m | time: 455.678s
[2K
| Adam | epoch: 014 | loss: 0.09846 - acc: 0.9642 -- iter: 1696/1702
[A[ATraining Step: 756  | total loss: [1m[32m0.09336[0m[0m | time: 487.210s
[2K
| Adam | epoch: 014 | loss: 0.09336 - acc: 0.9647 | val_loss: 0.96845 - val_acc: 0.6398 -- iter: 1702/1702
--
Training Step: 757  | total loss: [1m[32m0.10085[0m[0m | time: 7.953s
[2K
| Adam | epoch: 015 | loss: 0.10085 - acc: 0.9588 -- iter: 0032/1702
[A[ATraining Step: 758  | total loss: [1m[32m0.09763[0m[0m | time: 15.662s
[2K
| Adam | epoch: 015 | loss: 0.09763 - acc: 0.9598 -- iter: 0064/1702
[A[ATraining Step: 759  | total loss: [1m[32m0.09966[0m[0m | time: 23.593s
[2K
| Adam | epoch: 015 | loss: 0.09966 - acc: 0.9607 -- iter: 0096/1702
[A[ATraining Step: 760  | total loss: [1m[32m0.10070[0m[0m | time: 31.393s
[2K
| Adam | epoch: 015 | loss: 0.10070 - acc: 0.9615 -- iter: 0128/1702
[A[ATraining Step: 761  | total loss: [1m[32m0.09586[0m[0m | time: 39.363s
[2K
| Adam | epoch: 015 | loss: 0.09586 - acc: 0.9654 -- iter: 0160/1702
[A[ATraining Step: 762  | total loss: [1m[32m0.09120[0m[0m | time: 47.291s
[2K
| Adam | epoch: 015 | loss: 0.09120 - acc: 0.9688 -- iter: 0192/1702
[A[ATraining Step: 763  | total loss: [1m[32m0.08477[0m[0m | time: 55.134s
[2K
| Adam | epoch: 015 | loss: 0.08477 - acc: 0.9720 -- iter: 0224/1702
[A[ATraining Step: 764  | total loss: [1m[32m0.07770[0m[0m | time: 63.008s
[2K
| Adam | epoch: 015 | loss: 0.07770 - acc: 0.9748 -- iter: 0256/1702
[A[ATraining Step: 765  | total loss: [1m[32m0.07658[0m[0m | time: 70.975s
[2K
| Adam | epoch: 015 | loss: 0.07658 - acc: 0.9742 -- iter: 0288/1702
[A[ATraining Step: 766  | total loss: [1m[32m0.07185[0m[0m | time: 78.838s
[2K
| Adam | epoch: 015 | loss: 0.07185 - acc: 0.9767 -- iter: 0320/1702
[A[ATraining Step: 767  | total loss: [1m[32m0.07426[0m[0m | time: 86.677s
[2K
| Adam | epoch: 015 | loss: 0.07426 - acc: 0.9728 -- iter: 0352/1702
[A[ATraining Step: 768  | total loss: [1m[32m0.07311[0m[0m | time: 94.464s
[2K
| Adam | epoch: 015 | loss: 0.07311 - acc: 0.9724 -- iter: 0384/1702
[A[ATraining Step: 769  | total loss: [1m[32m0.07267[0m[0m | time: 96.675s
[2K
| Adam | epoch: 015 | loss: 0.07267 - acc: 0.9720 -- iter: 0416/1702
[A[ATraining Step: 770  | total loss: [1m[32m0.07713[0m[0m | time: 98.909s
[2K
| Adam | epoch: 015 | loss: 0.07713 - acc: 0.9748 -- iter: 0448/1702
[A[ATraining Step: 771  | total loss: [1m[32m0.07012[0m[0m | time: 106.639s
[2K
| Adam | epoch: 015 | loss: 0.07012 - acc: 0.9774 -- iter: 0480/1702
[A[ATraining Step: 772  | total loss: [1m[32m0.06664[0m[0m | time: 114.459s
[2K
| Adam | epoch: 015 | loss: 0.06664 - acc: 0.9796 -- iter: 0512/1702
[A[ATraining Step: 773  | total loss: [1m[32m0.06541[0m[0m | time: 122.271s
[2K
| Adam | epoch: 015 | loss: 0.06541 - acc: 0.9785 -- iter: 0544/1702
[A[ATraining Step: 774  | total loss: [1m[32m0.05986[0m[0m | time: 130.076s
[2K
| Adam | epoch: 015 | loss: 0.05986 - acc: 0.9807 -- iter: 0576/1702
[A[ATraining Step: 775  | total loss: [1m[32m0.05594[0m[0m | time: 137.820s
[2K
| Adam | epoch: 015 | loss: 0.05594 - acc: 0.9826 -- iter: 0608/1702
[A[ATraining Step: 776  | total loss: [1m[32m0.06198[0m[0m | time: 145.645s
[2K
| Adam | epoch: 015 | loss: 0.06198 - acc: 0.9781 -- iter: 0640/1702
[A[ATraining Step: 777  | total loss: [1m[32m0.05788[0m[0m | time: 153.377s
[2K
| Adam | epoch: 015 | loss: 0.05788 - acc: 0.9803 -- iter: 0672/1702
[A[ATraining Step: 778  | total loss: [1m[32m0.05623[0m[0m | time: 161.095s
[2K
| Adam | epoch: 015 | loss: 0.05623 - acc: 0.9823 -- iter: 0704/1702
[A[ATraining Step: 779  | total loss: [1m[32m0.06163[0m[0m | time: 169.053s
[2K
| Adam | epoch: 015 | loss: 0.06163 - acc: 0.9778 -- iter: 0736/1702
[A[ATraining Step: 780  | total loss: [1m[32m0.05653[0m[0m | time: 176.957s
[2K
| Adam | epoch: 015 | loss: 0.05653 - acc: 0.9800 -- iter: 0768/1702
[A[ATraining Step: 781  | total loss: [1m[32m0.05958[0m[0m | time: 184.677s
[2K
| Adam | epoch: 015 | loss: 0.05958 - acc: 0.9758 -- iter: 0800/1702
[A[ATraining Step: 782  | total loss: [1m[32m0.05482[0m[0m | time: 192.535s
[2K
| Adam | epoch: 015 | loss: 0.05482 - acc: 0.9782 -- iter: 0832/1702
[A[ATraining Step: 783  | total loss: [1m[32m0.05011[0m[0m | time: 200.545s
[2K
| Adam | epoch: 015 | loss: 0.05011 - acc: 0.9804 -- iter: 0864/1702
[A[ATraining Step: 784  | total loss: [1m[32m0.04668[0m[0m | time: 208.482s
[2K
| Adam | epoch: 015 | loss: 0.04668 - acc: 0.9823 -- iter: 0896/1702
[A[ATraining Step: 785  | total loss: [1m[32m0.04569[0m[0m | time: 216.340s
[2K
| Adam | epoch: 015 | loss: 0.04569 - acc: 0.9841 -- iter: 0928/1702
[A[ATraining Step: 786  | total loss: [1m[32m0.04366[0m[0m | time: 224.294s
[2K
| Adam | epoch: 015 | loss: 0.04366 - acc: 0.9857 -- iter: 0960/1702
[A[ATraining Step: 787  | total loss: [1m[32m0.08046[0m[0m | time: 232.141s
[2K
| Adam | epoch: 015 | loss: 0.08046 - acc: 0.9746 -- iter: 0992/1702
[A[ATraining Step: 788  | total loss: [1m[32m0.07350[0m[0m | time: 240.002s
[2K
| Adam | epoch: 015 | loss: 0.07350 - acc: 0.9772 -- iter: 1024/1702
[A[ATraining Step: 789  | total loss: [1m[32m0.08162[0m[0m | time: 247.850s
[2K
| Adam | epoch: 015 | loss: 0.08162 - acc: 0.9732 -- iter: 1056/1702
[A[ATraining Step: 790  | total loss: [1m[32m0.07989[0m[0m | time: 255.786s
[2K
| Adam | epoch: 015 | loss: 0.07989 - acc: 0.9727 -- iter: 1088/1702
[A[ATraining Step: 791  | total loss: [1m[32m0.08697[0m[0m | time: 263.505s
[2K
| Adam | epoch: 015 | loss: 0.08697 - acc: 0.9692 -- iter: 1120/1702
[A[ATraining Step: 792  | total loss: [1m[32m0.08127[0m[0m | time: 271.614s
[2K
| Adam | epoch: 015 | loss: 0.08127 - acc: 0.9723 -- iter: 1152/1702
[A[ATraining Step: 793  | total loss: [1m[32m0.13919[0m[0m | time: 279.432s
[2K
| Adam | epoch: 015 | loss: 0.13919 - acc: 0.9594 -- iter: 1184/1702
[A[ATraining Step: 794  | total loss: [1m[32m0.12607[0m[0m | time: 287.424s
[2K
| Adam | epoch: 015 | loss: 0.12607 - acc: 0.9635 -- iter: 1216/1702
[A[ATraining Step: 795  | total loss: [1m[32m0.11671[0m[0m | time: 295.150s
[2K
| Adam | epoch: 015 | loss: 0.11671 - acc: 0.9671 -- iter: 1248/1702
[A[ATraining Step: 796  | total loss: [1m[32m0.11695[0m[0m | time: 303.237s
[2K
| Adam | epoch: 015 | loss: 0.11695 - acc: 0.9642 -- iter: 1280/1702
[A[ATraining Step: 797  | total loss: [1m[32m0.11038[0m[0m | time: 311.080s
[2K
| Adam | epoch: 015 | loss: 0.11038 - acc: 0.9678 -- iter: 1312/1702
[A[ATraining Step: 798  | total loss: [1m[32m0.11421[0m[0m | time: 318.888s
[2K
| Adam | epoch: 015 | loss: 0.11421 - acc: 0.9647 -- iter: 1344/1702
[A[ATraining Step: 799  | total loss: [1m[32m0.11008[0m[0m | time: 326.602s
[2K
| Adam | epoch: 015 | loss: 0.11008 - acc: 0.9651 -- iter: 1376/1702
[A[ATraining Step: 800  | total loss: [1m[32m0.10604[0m[0m | time: 358.052s
[2K
| Adam | epoch: 015 | loss: 0.10604 - acc: 0.9655 | val_loss: 1.64387 - val_acc: 0.6529 -- iter: 1408/1702
--
Training Step: 801  | total loss: [1m[32m0.09888[0m[0m | time: 365.704s
[2K
| Adam | epoch: 015 | loss: 0.09888 - acc: 0.9658 -- iter: 1440/1702
[A[ATraining Step: 802  | total loss: [1m[32m0.09145[0m[0m | time: 373.481s
[2K
| Adam | epoch: 015 | loss: 0.09145 - acc: 0.9692 -- iter: 1472/1702
[A[ATraining Step: 803  | total loss: [1m[32m0.09137[0m[0m | time: 381.178s
[2K
| Adam | epoch: 015 | loss: 0.09137 - acc: 0.9692 -- iter: 1504/1702
[A[ATraining Step: 804  | total loss: [1m[32m0.09413[0m[0m | time: 388.944s
[2K
| Adam | epoch: 015 | loss: 0.09413 - acc: 0.9691 -- iter: 1536/1702
[A[ATraining Step: 805  | total loss: [1m[32m0.08803[0m[0m | time: 396.836s
[2K
| Adam | epoch: 015 | loss: 0.08803 - acc: 0.9722 -- iter: 1568/1702
[A[ATraining Step: 806  | total loss: [1m[32m0.09109[0m[0m | time: 404.666s
[2K
| Adam | epoch: 015 | loss: 0.09109 - acc: 0.9688 -- iter: 1600/1702
[A[ATraining Step: 807  | total loss: [1m[32m0.08774[0m[0m | time: 412.402s
[2K
| Adam | epoch: 015 | loss: 0.08774 - acc: 0.9688 -- iter: 1632/1702
[A[ATraining Step: 808  | total loss: [1m[32m0.08134[0m[0m | time: 420.231s
[2K
| Adam | epoch: 015 | loss: 0.08134 - acc: 0.9719 -- iter: 1664/1702
[A[ATraining Step: 809  | total loss: [1m[32m0.10008[0m[0m | time: 428.084s
[2K
| Adam | epoch: 015 | loss: 0.10008 - acc: 0.9653 -- iter: 1696/1702
[A[ATraining Step: 810  | total loss: [1m[32m0.09105[0m[0m | time: 460.001s
[2K
| Adam | epoch: 015 | loss: 0.09105 - acc: 0.9688 | val_loss: 0.41092 - val_acc: 0.8424 -- iter: 1702/1702
--
Validation AUC:0.9724447202166066
Validation AUPRC:0.9737729656500697
Test AUC:0.962692036645525
Test AUPRC:0.9500137993309352
BestTestF1Score	0.92	0.85	0.92	0.91	0.94	243	25	250	15	0.05
BestTestMCCScore	0.92	0.85	0.92	0.91	0.94	243	25	250	15	0.05
BestTestAccuracyScore	0.92	0.85	0.92	0.91	0.94	243	25	250	15	0.05
BestValidationF1Score	0.93	0.85	0.93	0.93	0.93	258	20	236	19	0.05
BestValidationMCC	0.93	0.85	0.93	0.93	0.93	258	20	236	19	0.05
BestValidationAccuracy	0.93	0.85	0.93	0.93	0.93	258	20	236	19	0.05
TestPredictions (Threshold:0.05)
CHEMBL391707,TN,INACT,0.0	CHEMBL32409,TN,INACT,0.009999999776482582	CHEMBL25984,TN,INACT,0.0	CHEMBL520884,TP,ACT,0.9800000190734863	CHEMBL344752,TN,INACT,0.0	CHEMBL2113133,FP,INACT,0.20999999344348907	CHEMBL486555,TP,ACT,0.8799999952316284	CHEMBL50,TN,INACT,0.0	CHEMBL541164,TN,INACT,0.0	CHEMBL334813,TN,INACT,0.0	CHEMBL3410305,TN,INACT,0.0	CHEMBL266712,TP,ACT,0.7400000095367432	CHEMBL2441257,TP,ACT,0.9900000095367432	CHEMBL557327,TP,ACT,0.9800000190734863	CHEMBL1223258,TP,ACT,1.0	CHEMBL326877,TN,INACT,0.0	CHEMBL327822,TP,ACT,0.6000000238418579	CHEMBL3633665,FP,INACT,0.4399999976158142	CHEMBL567811,TP,ACT,0.9300000071525574	CHEMBL307034,FP,INACT,0.4699999988079071	CHEMBL480564,FN,ACT,0.0	CHEMBL2163950,TP,ACT,1.0	CHEMBL11262,TN,INACT,0.0	CHEMBL144302,FP,INACT,0.07000000029802322	CHEMBL603605,TN,INACT,0.0	CHEMBL323501,TP,ACT,0.6700000166893005	CHEMBL2441265,TP,ACT,0.6800000071525574	CHEMBL1158,TN,INACT,0.0	CHEMBL351146,TP,ACT,0.9900000095367432	CHEMBL1259092,TP,ACT,0.1899999976158142	CHEMBL603228,TP,ACT,0.7599999904632568	CHEMBL469771,TP,ACT,0.9900000095367432	CHEMBL469609,TP,ACT,0.9800000190734863	CHEMBL238134,TN,INACT,0.0	CHEMBL550419,TP,ACT,0.10000000149011612	CHEMBL418426,TN,INACT,0.0	CHEMBL481785,TP,ACT,0.7599999904632568	CHEMBL2316274,TP,ACT,0.1599999964237213	CHEMBL485735,TP,ACT,0.949999988079071	CHEMBL218202,TP,ACT,0.6800000071525574	CHEMBL121778,TP,ACT,0.949999988079071	CHEMBL603240,TP,ACT,1.0	CHEMBL103643,TN,INACT,0.0	CHEMBL138746,TN,INACT,0.0	CHEMBL68738,TN,INACT,0.0	CHEMBL480993,TP,ACT,1.0	CHEMBL560450,TP,ACT,0.9800000190734863	CHEMBL465928,FN,ACT,0.029999999329447746	CHEMBL314197,TP,ACT,1.0	CHEMBL132222,TN,INACT,0.0	CHEMBL177524,TN,INACT,0.009999999776482582	CHEMBL2381810,TP,ACT,0.9200000166893005	CHEMBL564623,TP,ACT,0.9900000095367432	CHEMBL93879,TP,ACT,0.9900000095367432	CHEMBL293478,TN,INACT,0.019999999552965164	CHEMBL120947,FP,INACT,0.07999999821186066	CHEMBL1916700,TN,INACT,0.0	CHEMBL300725,TN,INACT,0.009999999776482582	CHEMBL422034,TP,ACT,0.9900000095367432	CHEMBL605759,FN,ACT,0.0	CHEMBL520729,TP,ACT,1.0	CHEMBL562704,TP,ACT,0.12999999523162842	CHEMBL16592,TN,INACT,0.0	CHEMBL564622,TP,ACT,1.0	CHEMBL609240,TN,INACT,0.0	CHEMBL497006,TP,ACT,0.6700000166893005	CHEMBL390298,TN,INACT,0.0	CHEMBL2110295,TP,ACT,0.9399999976158142	CHEMBL570688,TP,ACT,0.9300000071525574	CHEMBL479823,TP,ACT,0.9900000095367432	CHEMBL605961,TP,ACT,0.9399999976158142	CHEMBL99331,TN,INACT,0.0	CHEMBL2316283,TP,ACT,1.0	CHEMBL487854,TP,ACT,0.8999999761581421	CHEMBL19847,TP,ACT,0.949999988079071	CHEMBL569658,TP,ACT,0.38999998569488525	CHEMBL1237297,TN,INACT,0.019999999552965164	CHEMBL603451,TP,ACT,0.6200000047683716	CHEMBL1259091,TP,ACT,0.2199999988079071	CHEMBL294087,TN,INACT,0.0	CHEMBL156981,TP,ACT,0.9800000190734863	CHEMBL260005,TP,ACT,0.3700000047683716	CHEMBL121316,TP,ACT,0.44999998807907104	CHEMBL2163952,TP,ACT,0.9100000262260437	CHEMBL3736248,TN,INACT,0.0	CHEMBL603455,TP,ACT,0.9800000190734863	CHEMBL511334,TN,INACT,0.0	CHEMBL274262,TN,INACT,0.029999999329447746	CHEMBL168223,TN,INACT,0.009999999776482582	CHEMBL516197,TN,INACT,0.0	CHEMBL27384,TN,INACT,0.0	CHEMBL314104,TN,INACT,0.0	CHEMBL286139,TN,INACT,0.009999999776482582	CHEMBL477,TN,INACT,0.0	CHEMBL87496,TN,INACT,0.0	CHEMBL54246,TN,INACT,0.009999999776482582	CHEMBL3114151,TN,INACT,0.029999999329447746	CHEMBL323557,TN,INACT,0.009999999776482582	CHEMBL2262478,TN,INACT,0.0	CHEMBL118646,TP,ACT,0.07000000029802322	CHEMBL314959,TN,INACT,0.0	CHEMBL27995,TN,INACT,0.0	CHEMBL33108,TN,INACT,0.0	CHEMBL560286,TP,ACT,0.9900000095367432	CHEMBL78308,TP,ACT,0.9800000190734863	CHEMBL1223177,TP,ACT,1.0	CHEMBL2414609,TP,ACT,0.05000000074505806	CHEMBL2348463,TP,ACT,0.3499999940395355	CHEMBL15056,TN,INACT,0.019999999552965164	CHEMBL2113397,TN,INACT,0.0	CHEMBL482777,TP,ACT,0.8600000143051147	CHEMBL518295,TP,ACT,0.8799999952316284	CHEMBL374254,TP,ACT,0.36000001430511475	CHEMBL238136,TN,INACT,0.009999999776482582	CHEMBL485734,TP,ACT,0.9300000071525574	CHEMBL563670,TP,ACT,0.9900000095367432	CHEMBL46195,TN,INACT,0.0	CHEMBL307175,TN,INACT,0.0	CHEMBL472070,TP,ACT,0.8399999737739563	CHEMBL1791272,TN,INACT,0.0	CHEMBL51280,FP,INACT,0.47999998927116394	CHEMBL1814151,TP,ACT,0.9200000166893005	CHEMBL2180831,FN,ACT,0.029999999329447746	CHEMBL104377,TN,INACT,0.009999999776482582	CHEMBL419912,TN,INACT,0.0	CHEMBL1214503,FP,INACT,0.550000011920929	CHEMBL385940,TP,ACT,0.5899999737739563	CHEMBL463879,TP,ACT,0.8899999856948853	CHEMBL2441453,TP,ACT,0.30000001192092896	CHEMBL565799,FP,INACT,0.9800000190734863	CHEMBL2064067,TP,ACT,0.9800000190734863	CHEMBL473515,TP,ACT,0.9300000071525574	CHEMBL141048,TN,INACT,0.03999999910593033	CHEMBL519460,TP,ACT,0.8500000238418579	CHEMBL470212,TP,ACT,0.3199999928474426	CHEMBL123852,FP,INACT,0.05999999865889549	CHEMBL168541,TN,INACT,0.009999999776482582	CHEMBL3114163,TN,INACT,0.0	CHEMBL2064068,TP,ACT,0.44999998807907104	CHEMBL203131,TP,ACT,0.47999998927116394	CHEMBL598091,TP,ACT,0.8700000047683716	CHEMBL1259000,TP,ACT,0.8799999952316284	CHEMBL2113688,TN,INACT,0.0	CHEMBL123099,TN,INACT,0.0	CHEMBL486154,TP,ACT,0.9800000190734863	CHEMBL2163945,TP,ACT,0.6600000262260437	CHEMBL515878,TP,ACT,0.9900000095367432	CHEMBL199413,TN,INACT,0.009999999776482582	CHEMBL1223180,TP,ACT,1.0	CHEMBL485340,TP,ACT,0.9800000190734863	CHEMBL27763,TN,INACT,0.009999999776482582	CHEMBL275987,TN,INACT,0.0	CHEMBL101239,FP,INACT,0.9599999785423279	CHEMBL610956,TN,INACT,0.0	CHEMBL3290994,TN,INACT,0.0	CHEMBL302447,TN,INACT,0.0	CHEMBL3423404,TN,INACT,0.0	CHEMBL691,TN,INACT,0.0	CHEMBL291992,FP,INACT,0.10000000149011612	CHEMBL597828,TP,ACT,0.9900000095367432	CHEMBL517157,TP,ACT,0.8100000023841858	CHEMBL1814333,TP,ACT,0.17000000178813934	CHEMBL519334,TP,ACT,0.2199999988079071	CHEMBL60837,TN,INACT,0.009999999776482582	CHEMBL101525,TN,INACT,0.0	CHEMBL388528,TN,INACT,0.0	CHEMBL287609,TP,ACT,1.0	CHEMBL1306,TN,INACT,0.0	CHEMBL525936,TP,ACT,0.7699999809265137	CHEMBL485931,TP,ACT,0.9100000262260437	CHEMBL432272,TP,ACT,0.9900000095367432	CHEMBL285380,FP,INACT,0.20999999344348907	CHEMBL3403340,TN,INACT,0.0	CHEMBL563929,TP,ACT,0.7300000190734863	CHEMBL522235,TP,ACT,0.8700000047683716	CHEMBL257690,TP,ACT,0.8399999737739563	CHEMBL74330,TN,INACT,0.0	CHEMBL390842,TN,INACT,0.009999999776482582	CHEMBL392149,TN,INACT,0.0	CHEMBL2163942,TP,ACT,0.8899999856948853	CHEMBL8208,TN,INACT,0.019999999552965164	CHEMBL2112597,TN,INACT,0.0	CHEMBL336881,TN,INACT,0.0	CHEMBL2441469,TP,ACT,0.8700000047683716	CHEMBL2237745,TP,ACT,0.2800000011920929	CHEMBL344284,TN,INACT,0.0	CHEMBL717,TN,INACT,0.0	CHEMBL610675,TN,INACT,0.0	CHEMBL279105,TN,INACT,0.0	CHEMBL61494,TN,INACT,0.0	CHEMBL597317,TP,ACT,0.9700000286102295	CHEMBL21937,TN,INACT,0.0	CHEMBL1437,TN,INACT,0.0	CHEMBL408430,FN,ACT,0.0	CHEMBL524822,FN,ACT,0.009999999776482582	CHEMBL1782798,TN,INACT,0.0	CHEMBL598092,TP,ACT,0.7900000214576721	CHEMBL1222968,TP,ACT,1.0	CHEMBL487170,TP,ACT,0.9399999976158142	CHEMBL20844,TN,INACT,0.0	CHEMBL36553,TP,ACT,0.9900000095367432	CHEMBL64321,TN,INACT,0.0	CHEMBL1916635,TN,INACT,0.0	CHEMBL599800,TP,ACT,0.09000000357627869	CHEMBL426537,TN,INACT,0.0	CHEMBL269689,TN,INACT,0.0	CHEMBL245468,TP,ACT,0.6299999952316284	CHEMBL348404,TP,ACT,0.5199999809265137	CHEMBL91786,TN,INACT,0.0	CHEMBL1945683,TN,INACT,0.009999999776482582	CHEMBL140984,FP,INACT,0.17000000178813934	CHEMBL562585,TP,ACT,0.1599999964237213	CHEMBL400190,TN,INACT,0.0	CHEMBL28057,TN,INACT,0.0	CHEMBL2112364,TP,ACT,0.9700000286102295	CHEMBL2062861,TN,INACT,0.0	CHEMBL516986,TP,ACT,0.8299999833106995	CHEMBL168632,TN,INACT,0.0	CHEMBL2397389,TN,INACT,0.0	CHEMBL3403337,TN,INACT,0.0	CHEMBL37132,TN,INACT,0.019999999552965164	CHEMBL129198,TN,INACT,0.009999999776482582	CHEMBL59085,TN,INACT,0.0	CHEMBL284912,TN,INACT,0.0	CHEMBL1259038,TP,ACT,0.9100000262260437	CHEMBL476325,TP,ACT,0.8899999856948853	CHEMBL189192,TN,INACT,0.0	CHEMBL150942,TP,ACT,1.0	CHEMBL1808421,TN,INACT,0.009999999776482582	CHEMBL440961,FP,INACT,0.18000000715255737	CHEMBL3416129,TP,ACT,0.09000000357627869	CHEMBL2369710,TN,INACT,0.0	CHEMBL521505,TP,ACT,0.1599999964237213	CHEMBL212855,TN,INACT,0.0	CHEMBL2062854,TN,INACT,0.009999999776482582	CHEMBL564705,TP,ACT,1.0	CHEMBL292725,TN,INACT,0.009999999776482582	CHEMBL557668,TP,ACT,0.25	CHEMBL122972,TP,ACT,0.9900000095367432	CHEMBL215040,TN,INACT,0.009999999776482582	CHEMBL558535,TP,ACT,0.1599999964237213	CHEMBL486343,TP,ACT,0.9399999976158142	CHEMBL3423400,TN,INACT,0.0	CHEMBL389118,TP,ACT,0.8899999856948853	CHEMBL564570,TP,ACT,1.0	CHEMBL504920,TP,ACT,0.07000000029802322	CHEMBL257842,TP,ACT,0.9399999976158142	CHEMBL13272,TP,ACT,0.47999998927116394	CHEMBL75773,TN,INACT,0.009999999776482582	CHEMBL52396,TN,INACT,0.0	CHEMBL661,TN,INACT,0.009999999776482582	CHEMBL520456,TP,ACT,0.6600000262260437	CHEMBL574597,TN,INACT,0.0	CHEMBL1814337,TP,ACT,0.8500000238418579	CHEMBL114478,TN,INACT,0.0	CHEMBL169631,TN,INACT,0.0	CHEMBL411,TN,INACT,0.0	CHEMBL231464,TP,ACT,0.9900000095367432	CHEMBL2237746,TP,ACT,0.7699999809265137	CHEMBL417550,TN,INACT,0.0	CHEMBL1088284,TN,INACT,0.0	CHEMBL60509,TN,INACT,0.009999999776482582	CHEMBL452924,TN,INACT,0.0	CHEMBL107680,TN,INACT,0.0	CHEMBL393755,TN,INACT,0.0	CHEMBL216857,TP,ACT,0.8500000238418579	CHEMBL446698,TN,INACT,0.009999999776482582	CHEMBL480803,TP,ACT,0.5	CHEMBL42359,TN,INACT,0.0	CHEMBL218253,TP,ACT,0.15000000596046448	CHEMBL1814331,TP,ACT,0.8799999952316284	CHEMBL476833,TP,ACT,0.9900000095367432	CHEMBL72172,TN,INACT,0.0	CHEMBL157201,TP,ACT,0.9900000095367432	CHEMBL2113697,TN,INACT,0.0	CHEMBL319534,TN,INACT,0.0	CHEMBL384897,TP,ACT,0.7099999785423279	CHEMBL3403336,FP,INACT,0.6200000047683716	CHEMBL302886,TN,INACT,0.0	CHEMBL149938,TN,INACT,0.0	CHEMBL494394,TP,ACT,0.20999999344348907	CHEMBL1814316,TP,ACT,0.8999999761581421	CHEMBL75514,TN,INACT,0.0	CHEMBL562489,TP,ACT,1.0	CHEMBL562545,TP,ACT,0.20000000298023224	CHEMBL273606,TP,ACT,0.9300000071525574	CHEMBL10404,TN,INACT,0.019999999552965164	CHEMBL2316272,TP,ACT,0.6000000238418579	CHEMBL146983,TN,INACT,0.0	CHEMBL1223103,TP,ACT,0.9700000286102295	CHEMBL564407,TP,ACT,0.9900000095367432	CHEMBL598539,TP,ACT,0.9700000286102295	CHEMBL47138,TN,INACT,0.0	CHEMBL38861,TN,INACT,0.019999999552965164	CHEMBL29541,TN,INACT,0.0	CHEMBL2112411,TN,INACT,0.0	CHEMBL598862,TP,ACT,0.6399999856948853	CHEMBL2163580,TP,ACT,0.949999988079071	CHEMBL210931,TN,INACT,0.0	CHEMBL422283,TN,INACT,0.0	CHEMBL188494,TP,ACT,1.0	CHEMBL561349,TP,ACT,0.10999999940395355	CHEMBL260483,TP,ACT,0.9900000095367432	CHEMBL465869,TP,ACT,0.9599999785423279	CHEMBL2316285,TP,ACT,0.8199999928474426	CHEMBL115608,TN,INACT,0.0	CHEMBL419403,TN,INACT,0.019999999552965164	CHEMBL285819,TN,INACT,0.0	CHEMBL263385,TP,ACT,0.9900000095367432	CHEMBL500944,TP,ACT,0.699999988079071	CHEMBL3416128,TP,ACT,0.11999999731779099	CHEMBL72060,TN,INACT,0.019999999552965164	CHEMBL264027,TN,INACT,0.0	CHEMBL194578,TN,INACT,0.0	CHEMBL561013,TP,ACT,0.8899999856948853	CHEMBL3221190,TP,ACT,0.18000000715255737	CHEMBL62911,TN,INACT,0.0	CHEMBL63114,TN,INACT,0.0	CHEMBL488794,TP,ACT,0.9200000166893005	CHEMBL562350,TP,ACT,0.23999999463558197	CHEMBL520392,TP,ACT,0.9200000166893005	CHEMBL166736,TN,INACT,0.009999999776482582	CHEMBL262559,TP,ACT,0.9399999976158142	CHEMBL322112,TP,ACT,0.9200000166893005	CHEMBL293879,TN,INACT,0.009999999776482582	CHEMBL2348470,TP,ACT,0.5799999833106995	CHEMBL286302,TP,ACT,0.8799999952316284	CHEMBL13178,TP,ACT,0.9599999785423279	CHEMBL564543,TP,ACT,0.5299999713897705	CHEMBL593443,TN,INACT,0.0	CHEMBL36032,TP,ACT,0.6299999952316284	CHEMBL338134,TN,INACT,0.0	CHEMBL311341,TN,INACT,0.0	CHEMBL291821,TN,INACT,0.0	CHEMBL519720,TP,ACT,0.9900000095367432	CHEMBL508030,TN,INACT,0.0	CHEMBL169562,TN,INACT,0.0	CHEMBL317398,TN,INACT,0.009999999776482582	CHEMBL298649,FP,INACT,0.12999999523162842	CHEMBL16687,TN,INACT,0.0	CHEMBL260563,TN,INACT,0.0	CHEMBL402473,TN,INACT,0.0	CHEMBL565832,TP,ACT,0.949999988079071	CHEMBL1956200,TN,INACT,0.0	CHEMBL482563,TP,ACT,0.9900000095367432	CHEMBL2093089,TN,INACT,0.0	CHEMBL319910,TN,INACT,0.0	CHEMBL1259019,TP,ACT,0.9900000095367432	CHEMBL482758,TP,ACT,0.75	CHEMBL593861,TN,INACT,0.0	CHEMBL1814329,TP,ACT,0.9900000095367432	CHEMBL101162,FP,INACT,0.23999999463558197	CHEMBL269776,TN,INACT,0.0	CHEMBL520756,TP,ACT,0.75	CHEMBL62948,TN,INACT,0.0	CHEMBL59733,TN,INACT,0.0	CHEMBL294349,TN,INACT,0.009999999776482582	CHEMBL481388,TP,ACT,0.6000000238418579	CHEMBL561894,TP,ACT,0.9900000095367432	CHEMBL264412,TP,ACT,0.9900000095367432	CHEMBL316792,FP,INACT,0.36000001430511475	CHEMBL1782812,TN,INACT,0.0	CHEMBL3410301,TN,INACT,0.0	CHEMBL61407,TP,ACT,0.9800000190734863	CHEMBL2381785,TP,ACT,0.4399999976158142	CHEMBL83,FP,INACT,1.0	CHEMBL365026,TN,INACT,0.009999999776482582	CHEMBL1814158,TP,ACT,0.4399999976158142	CHEMBL51985,TN,INACT,0.0	CHEMBL2372077,TN,INACT,0.0	CHEMBL21053,TN,INACT,0.0	CHEMBL557058,TP,ACT,0.9900000095367432	CHEMBL125874,TN,INACT,0.0	CHEMBL1222969,TP,ACT,0.9900000095367432	CHEMBL1210700,TP,ACT,0.49000000953674316	CHEMBL501851,TP,ACT,0.9900000095367432	CHEMBL292911,TN,INACT,0.0	CHEMBL441284,TP,ACT,0.07999999821186066	CHEMBL3109772,TN,INACT,0.009999999776482582	CHEMBL486356,TP,ACT,0.9399999976158142	CHEMBL29534,TN,INACT,0.0	CHEMBL281811,TN,INACT,0.0	CHEMBL3403731,TN,INACT,0.0	CHEMBL482941,TP,ACT,1.0	CHEMBL267014,TN,INACT,0.0	CHEMBL2164612,TN,INACT,0.0	CHEMBL62527,TN,INACT,0.009999999776482582	CHEMBL120526,TP,ACT,0.9900000095367432	CHEMBL59347,TN,INACT,0.0	CHEMBL237478,TN,INACT,0.0	CHEMBL314320,TN,INACT,0.029999999329447746	CHEMBL2112451,TN,INACT,0.0	CHEMBL438672,TN,INACT,0.0	CHEMBL151504,TP,ACT,0.9900000095367432	CHEMBL62115,TN,INACT,0.009999999776482582	CHEMBL481979,TP,ACT,0.1599999964237213	CHEMBL2348465,FN,ACT,0.019999999552965164	CHEMBL319005,TN,INACT,0.0	CHEMBL1814157,TP,ACT,0.4399999976158142	CHEMBL33224,TN,INACT,0.0	CHEMBL187349,TP,ACT,0.9900000095367432	CHEMBL77445,TP,ACT,0.9100000262260437	CHEMBL525229,TP,ACT,0.8299999833106995	CHEMBL542544,TN,INACT,0.0	CHEMBL63760,TN,INACT,0.019999999552965164	CHEMBL1223100,TP,ACT,1.0	CHEMBL551546,FN,ACT,0.0	CHEMBL2205616,TN,INACT,0.0	CHEMBL603054,TP,ACT,0.05000000074505806	CHEMBL600610,TN,INACT,0.0	CHEMBL59934,TP,ACT,0.9800000190734863	CHEMBL311560,TP,ACT,0.8799999952316284	CHEMBL275433,TN,INACT,0.019999999552965164	CHEMBL2348472,TP,ACT,0.3199999928474426	CHEMBL138040,FN,ACT,0.03999999910593033	CHEMBL604786,TP,ACT,0.9900000095367432	CHEMBL62840,TN,INACT,0.0	CHEMBL1834524,TP,ACT,0.07000000029802322	CHEMBL416505,TN,INACT,0.009999999776482582	CHEMBL514909,TP,ACT,0.17000000178813934	CHEMBL1201353,TN,INACT,0.0	CHEMBL2110296,TP,ACT,0.9900000095367432	CHEMBL458947,TN,INACT,0.0	CHEMBL283320,TN,INACT,0.0	CHEMBL111724,TP,ACT,0.7799999713897705	CHEMBL15948,TP,ACT,0.9700000286102295	CHEMBL18797,FP,INACT,0.7099999785423279	CHEMBL151668,TN,INACT,0.0	CHEMBL62601,TN,INACT,0.009999999776482582	CHEMBL249492,TN,INACT,0.019999999552965164	CHEMBL540310,TN,INACT,0.0	CHEMBL2237756,TP,ACT,0.14000000059604645	CHEMBL160975,TP,ACT,0.8500000238418579	CHEMBL488031,TP,ACT,0.9599999785423279	CHEMBL485744,TP,ACT,0.9700000286102295	CHEMBL609547,TN,INACT,0.0	CHEMBL116874,TN,INACT,0.009999999776482582	CHEMBL217969,TP,ACT,0.7200000286102295	CHEMBL495836,TP,ACT,0.9200000166893005	CHEMBL171447,TP,ACT,0.1899999976158142	CHEMBL76874,TN,INACT,0.0	CHEMBL90040,TP,ACT,0.9800000190734863	CHEMBL2370768,TN,INACT,0.0	CHEMBL80845,TN,INACT,0.0	CHEMBL320786,TN,INACT,0.0	CHEMBL385653,TP,ACT,0.49000000953674316	CHEMBL63012,TN,INACT,0.009999999776482582	CHEMBL468633,TN,INACT,0.0	CHEMBL337309,TN,INACT,0.0	CHEMBL2441449,FN,ACT,0.029999999329447746	CHEMBL480217,TP,ACT,1.0	CHEMBL432857,TP,ACT,0.3499999940395355	CHEMBL2312376,TN,INACT,0.029999999329447746	CHEMBL25649,TN,INACT,0.0	CHEMBL285259,TP,ACT,0.8600000143051147	CHEMBL74342,TN,INACT,0.0	CHEMBL2441451,TP,ACT,0.8899999856948853	CHEMBL188940,TP,ACT,0.8600000143051147	CHEMBL440864,TN,INACT,0.0	CHEMBL301060,TN,INACT,0.0	CHEMBL263070,TN,INACT,0.0	CHEMBL3670286,TN,INACT,0.0	CHEMBL121779,TP,ACT,0.8399999737739563	CHEMBL3220951,TN,INACT,0.0	CHEMBL1223330,TP,ACT,1.0	CHEMBL3142980,TN,INACT,0.0	CHEMBL604925,TP,ACT,1.0	CHEMBL79204,TP,ACT,0.949999988079071	CHEMBL165462,TN,INACT,0.0	CHEMBL102584,FP,INACT,0.11999999731779099	CHEMBL1222967,TP,ACT,1.0	CHEMBL2113101,TP,ACT,0.8999999761581421	CHEMBL241100,TN,INACT,0.009999999776482582	CHEMBL2376804,TN,INACT,0.009999999776482582	CHEMBL220360,FN,ACT,0.0	CHEMBL3104360,TP,ACT,0.949999988079071	CHEMBL88688,TN,INACT,0.009999999776482582	CHEMBL558142,TP,ACT,0.5199999809265137	CHEMBL561089,TP,ACT,0.1899999976158142	CHEMBL59467,TP,ACT,0.4399999976158142	CHEMBL115853,TN,INACT,0.0	CHEMBL565194,FN,ACT,0.0	CHEMBL2348474,TP,ACT,0.6600000262260437	CHEMBL3577343,TN,INACT,0.03999999910593033	CHEMBL1814152,TP,ACT,0.9399999976158142	CHEMBL1223104,TP,ACT,0.9700000286102295	CHEMBL436553,TP,ACT,0.18000000715255737	CHEMBL196364,TP,ACT,0.23999999463558197	CHEMBL487805,FP,INACT,0.6700000166893005	CHEMBL264761,TN,INACT,0.0	CHEMBL2237157,TN,INACT,0.0	CHEMBL100810,TN,INACT,0.0	CHEMBL3810140,TP,ACT,0.12999999523162842	CHEMBL557004,TP,ACT,0.9800000190734863	CHEMBL563764,FN,ACT,0.009999999776482582	CHEMBL2113689,TN,INACT,0.0	CHEMBL33652,TP,ACT,0.9900000095367432	CHEMBL64000,TN,INACT,0.0	CHEMBL94239,TP,ACT,0.11999999731779099	CHEMBL106483,TN,INACT,0.009999999776482582	CHEMBL81473,FN,ACT,0.019999999552965164	CHEMBL461087,TN,INACT,0.009999999776482582	CHEMBL2112647,TP,ACT,0.07000000029802322	CHEMBL323074,TN,INACT,0.0	CHEMBL278932,TN,INACT,0.0	CHEMBL564384,TP,ACT,0.7200000286102295	CHEMBL17875,TN,INACT,0.0	CHEMBL328476,TN,INACT,0.0	CHEMBL112034,TN,INACT,0.019999999552965164	CHEMBL269653,TN,INACT,0.0	CHEMBL190,TN,INACT,0.0	CHEMBL539479,FN,ACT,0.009999999776482582	CHEMBL1237299,FP,INACT,0.6299999952316284	CHEMBL3403333,TN,INACT,0.029999999329447746	CHEMBL74415,TP,ACT,0.07000000029802322	CHEMBL1907856,FP,INACT,0.05000000074505806	CHEMBL32996,TN,INACT,0.0	CHEMBL32855,TP,ACT,1.0	CHEMBL488595,TP,ACT,0.9900000095367432	CHEMBL1259076,TP,ACT,0.1899999976158142	CHEMBL80945,TN,INACT,0.0	CHEMBL2064070,TP,ACT,0.9399999976158142	CHEMBL429797,TP,ACT,0.05999999865889549	CHEMBL327597,TN,INACT,0.0	CHEMBL349689,TN,INACT,0.0	CHEMBL519449,TP,ACT,0.949999988079071	CHEMBL97436,TN,INACT,0.0	CHEMBL321644,FP,INACT,0.25	CHEMBL488613,TP,ACT,0.9100000262260437	CHEMBL86968,TN,INACT,0.0	CHEMBL64559,TN,INACT,0.0	CHEMBL364223,TP,ACT,0.5299999713897705	CHEMBL1223260,TP,ACT,0.49000000953674316	

