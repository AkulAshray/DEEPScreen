ImageNetInceptionV2 CHEMBL4336 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	230
Number of inactive compounds :	230
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4336_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4336_adam_0.0005_30_0.8/
---------------------------------
Training samples: 293
Validation samples: 92
--
Training Step: 1  | time: 53.732s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/293
[A[ATraining Step: 2  | total loss: [1m[32m0.63558[0m[0m | time: 64.893s
[2K
| Adam | epoch: 001 | loss: 0.63558 - acc: 0.4219 -- iter: 064/293
[A[ATraining Step: 3  | total loss: [1m[32m0.55245[0m[0m | time: 75.699s
[2K
| Adam | epoch: 001 | loss: 0.55245 - acc: 0.5881 -- iter: 096/293
[A[ATraining Step: 4  | total loss: [1m[32m0.73371[0m[0m | time: 87.031s
[2K
| Adam | epoch: 001 | loss: 0.73371 - acc: 0.5923 -- iter: 128/293
[A[ATraining Step: 5  | total loss: [1m[32m0.94252[0m[0m | time: 97.959s
[2K
| Adam | epoch: 001 | loss: 0.94252 - acc: 0.5717 -- iter: 160/293
[A[ATraining Step: 6  | total loss: [1m[32m0.63944[0m[0m | time: 109.005s
[2K
| Adam | epoch: 001 | loss: 0.63944 - acc: 0.7064 -- iter: 192/293
[A[ATraining Step: 7  | total loss: [1m[32m0.57138[0m[0m | time: 119.637s
[2K
| Adam | epoch: 001 | loss: 0.57138 - acc: 0.7326 -- iter: 224/293
[A[ATraining Step: 8  | total loss: [1m[32m0.52480[0m[0m | time: 130.810s
[2K
| Adam | epoch: 001 | loss: 0.52480 - acc: 0.7599 -- iter: 256/293
[A[ATraining Step: 9  | total loss: [1m[32m0.46395[0m[0m | time: 141.426s
[2K
| Adam | epoch: 001 | loss: 0.46395 - acc: 0.7712 -- iter: 288/293
[A[ATraining Step: 10  | total loss: [1m[32m0.41766[0m[0m | time: 160.349s
[2K
| Adam | epoch: 001 | loss: 0.41766 - acc: 0.7919 | val_loss: 1.15744 - val_acc: 0.4783 -- iter: 293/293
--
Training Step: 11  | total loss: [1m[32m0.26453[0m[0m | time: 3.379s
[2K
| Adam | epoch: 002 | loss: 0.26453 - acc: 0.8905 -- iter: 032/293
[A[ATraining Step: 12  | total loss: [1m[32m0.66236[0m[0m | time: 14.588s
[2K
| Adam | epoch: 002 | loss: 0.66236 - acc: 0.8497 -- iter: 064/293
[A[ATraining Step: 13  | total loss: [1m[32m0.48651[0m[0m | time: 25.639s
[2K
| Adam | epoch: 002 | loss: 0.48651 - acc: 0.8874 -- iter: 096/293
[A[ATraining Step: 14  | total loss: [1m[32m0.41987[0m[0m | time: 36.413s
[2K
| Adam | epoch: 002 | loss: 0.41987 - acc: 0.8567 -- iter: 128/293
[A[ATraining Step: 15  | total loss: [1m[32m0.30526[0m[0m | time: 47.765s
[2K
| Adam | epoch: 002 | loss: 0.30526 - acc: 0.9006 -- iter: 160/293
[A[ATraining Step: 16  | total loss: [1m[32m0.31183[0m[0m | time: 58.568s
[2K
| Adam | epoch: 002 | loss: 0.31183 - acc: 0.8910 -- iter: 192/293
[A[ATraining Step: 17  | total loss: [1m[32m0.24150[0m[0m | time: 69.622s
[2K
| Adam | epoch: 002 | loss: 0.24150 - acc: 0.9190 -- iter: 224/293
[A[ATraining Step: 18  | total loss: [1m[32m0.24285[0m[0m | time: 80.424s
[2K
| Adam | epoch: 002 | loss: 0.24285 - acc: 0.8929 -- iter: 256/293
[A[ATraining Step: 19  | total loss: [1m[32m0.21906[0m[0m | time: 91.493s
[2K
| Adam | epoch: 002 | loss: 0.21906 - acc: 0.9078 -- iter: 288/293
[A[ATraining Step: 20  | total loss: [1m[32m0.22425[0m[0m | time: 108.454s
[2K
| Adam | epoch: 002 | loss: 0.22425 - acc: 0.9274 | val_loss: 1.50298 - val_acc: 0.4783 -- iter: 293/293
--
Training Step: 21  | total loss: [1m[32m0.20217[0m[0m | time: 2.980s
[2K
| Adam | epoch: 003 | loss: 0.20217 - acc: 0.9208 -- iter: 032/293
[A[ATraining Step: 22  | total loss: [1m[32m0.16465[0m[0m | time: 6.184s
[2K
| Adam | epoch: 003 | loss: 0.16465 - acc: 0.9446 -- iter: 064/293
[A[ATraining Step: 23  | total loss: [1m[32m0.20200[0m[0m | time: 16.809s
[2K
| Adam | epoch: 003 | loss: 0.20200 - acc: 0.9026 -- iter: 096/293
[A[ATraining Step: 24  | total loss: [1m[32m0.17264[0m[0m | time: 28.087s
[2K
| Adam | epoch: 003 | loss: 0.17264 - acc: 0.9212 -- iter: 128/293
[A[ATraining Step: 25  | total loss: [1m[32m0.18555[0m[0m | time: 38.855s
[2K
| Adam | epoch: 003 | loss: 0.18555 - acc: 0.9171 -- iter: 160/293
[A[ATraining Step: 26  | total loss: [1m[32m0.18073[0m[0m | time: 49.582s
[2K
| Adam | epoch: 003 | loss: 0.18073 - acc: 0.9308 -- iter: 192/293
[A[ATraining Step: 27  | total loss: [1m[32m0.14778[0m[0m | time: 60.062s
[2K
| Adam | epoch: 003 | loss: 0.14778 - acc: 0.9406 -- iter: 224/293
[A[ATraining Step: 28  | total loss: [1m[32m0.12578[0m[0m | time: 70.908s
[2K
| Adam | epoch: 003 | loss: 0.12578 - acc: 0.9554 -- iter: 256/293
[A[ATraining Step: 29  | total loss: [1m[32m0.11284[0m[0m | time: 81.831s
[2K
| Adam | epoch: 003 | loss: 0.11284 - acc: 0.9663 -- iter: 288/293
[A[ATraining Step: 30  | total loss: [1m[32m0.09460[0m[0m | time: 98.417s
[2K
| Adam | epoch: 003 | loss: 0.09460 - acc: 0.9743 | val_loss: 4.72409 - val_acc: 0.4783 -- iter: 293/293
--
Training Step: 31  | total loss: [1m[32m0.09546[0m[0m | time: 10.718s
[2K
| Adam | epoch: 004 | loss: 0.09546 - acc: 0.9730 -- iter: 032/293
[A[ATraining Step: 32  | total loss: [1m[32m0.10434[0m[0m | time: 14.017s
[2K
| Adam | epoch: 004 | loss: 0.10434 - acc: 0.9650 -- iter: 064/293
[A[ATraining Step: 33  | total loss: [1m[32m0.27338[0m[0m | time: 16.655s
[2K
| Adam | epoch: 004 | loss: 0.27338 - acc: 0.9288 -- iter: 096/293
[A[ATraining Step: 34  | total loss: [1m[32m0.21570[0m[0m | time: 27.884s
[2K
| Adam | epoch: 004 | loss: 0.21570 - acc: 0.9440 -- iter: 128/293
[A[ATraining Step: 35  | total loss: [1m[32m0.25894[0m[0m | time: 38.448s
[2K
| Adam | epoch: 004 | loss: 0.25894 - acc: 0.9296 -- iter: 160/293
[A[ATraining Step: 36  | total loss: [1m[32m0.26288[0m[0m | time: 49.761s
[2K
| Adam | epoch: 004 | loss: 0.26288 - acc: 0.9248 -- iter: 192/293
[A[ATraining Step: 37  | total loss: [1m[32m0.32131[0m[0m | time: 60.342s
[2K
| Adam | epoch: 004 | loss: 0.32131 - acc: 0.9086 -- iter: 224/293
[A[ATraining Step: 38  | total loss: [1m[32m0.28621[0m[0m | time: 71.057s
[2K
| Adam | epoch: 004 | loss: 0.28621 - acc: 0.9204 -- iter: 256/293
[A[ATraining Step: 39  | total loss: [1m[32m0.25789[0m[0m | time: 83.221s
[2K
| Adam | epoch: 004 | loss: 0.25789 - acc: 0.9177 -- iter: 288/293
[A[ATraining Step: 40  | total loss: [1m[32m0.24664[0m[0m | time: 104.267s
[2K
| Adam | epoch: 004 | loss: 0.24664 - acc: 0.9155 | val_loss: 4.25178 - val_acc: 0.4783 -- iter: 293/293
--
Training Step: 41  | total loss: [1m[32m0.25823[0m[0m | time: 14.244s
[2K
| Adam | epoch: 005 | loss: 0.25823 - acc: 0.9081 -- iter: 032/293
[A[ATraining Step: 42  | total loss: [1m[32m0.26360[0m[0m | time: 29.295s
[2K
| Adam | epoch: 005 | loss: 0.26360 - acc: 0.9078 -- iter: 064/293
[A[ATraining Step: 43  | total loss: [1m[32m0.27471[0m[0m | time: 33.090s
[2K
| Adam | epoch: 005 | loss: 0.27471 - acc: 0.9075 -- iter: 096/293
[A[ATraining Step: 44  | total loss: [1m[32m0.23226[0m[0m | time: 36.924s
[2K
| Adam | epoch: 005 | loss: 0.23226 - acc: 0.9235 -- iter: 128/293
[A[ATraining Step: 45  | total loss: [1m[32m0.58244[0m[0m | time: 50.351s
[2K
| Adam | epoch: 005 | loss: 0.58244 - acc: 0.8346 -- iter: 160/293
[A[ATraining Step: 46  | total loss: [1m[32m0.50554[0m[0m | time: 64.615s
[2K
| Adam | epoch: 005 | loss: 0.50554 - acc: 0.8570 -- iter: 192/293
[A[ATraining Step: 47  | total loss: [1m[32m0.44010[0m[0m | time: 78.804s
[2K
| Adam | epoch: 005 | loss: 0.44010 - acc: 0.8804 -- iter: 224/293
[A[ATraining Step: 48  | total loss: [1m[32m0.38789[0m[0m | time: 94.469s
[2K
| Adam | epoch: 005 | loss: 0.38789 - acc: 0.8996 -- iter: 256/293
[A[ATraining Step: 49  | total loss: [1m[32m0.35886[0m[0m | time: 107.635s
[2K
| Adam | epoch: 005 | loss: 0.35886 - acc: 0.9056 -- iter: 288/293
[A[ATraining Step: 50  | total loss: [1m[32m0.32012[0m[0m | time: 128.628s
[2K
| Adam | epoch: 005 | loss: 0.32012 - acc: 0.9202 | val_loss: 1.09082 - val_acc: 0.5326 -- iter: 293/293
--
Training Step: 51  | total loss: [1m[32m0.29427[0m[0m | time: 11.384s
[2K
| Adam | epoch: 006 | loss: 0.29427 - acc: 0.9276 -- iter: 032/293
[A[ATraining Step: 52  | total loss: [1m[32m0.26424[0m[0m | time: 21.984s
[2K
| Adam | epoch: 006 | loss: 0.26424 - acc: 0.9385 -- iter: 064/293
[A[ATraining Step: 53  | total loss: [1m[32m0.24439[0m[0m | time: 32.628s
[2K
| Adam | epoch: 006 | loss: 0.24439 - acc: 0.9430 -- iter: 096/293
[A[ATraining Step: 54  | total loss: [1m[32m0.21971[0m[0m | time: 35.607s
[2K
| Adam | epoch: 006 | loss: 0.21971 - acc: 0.9512 -- iter: 128/293
[A[ATraining Step: 55  | total loss: [1m[32m0.32717[0m[0m | time: 38.773s
[2K
| Adam | epoch: 006 | loss: 0.32717 - acc: 0.9011 -- iter: 160/293
[A[ATraining Step: 56  | total loss: [1m[32m0.38086[0m[0m | time: 49.502s
[2K
| Adam | epoch: 006 | loss: 0.38086 - acc: 0.8868 -- iter: 192/293
[A[ATraining Step: 57  | total loss: [1m[32m0.33657[0m[0m | time: 60.348s
[2K
| Adam | epoch: 006 | loss: 0.33657 - acc: 0.8982 -- iter: 224/293
[A[ATraining Step: 58  | total loss: [1m[32m0.29422[0m[0m | time: 71.003s
[2K
| Adam | epoch: 006 | loss: 0.29422 - acc: 0.9121 -- iter: 256/293
[A[ATraining Step: 59  | total loss: [1m[32m0.26472[0m[0m | time: 82.074s
[2K
| Adam | epoch: 006 | loss: 0.26472 - acc: 0.9239 -- iter: 288/293
[A[ATraining Step: 60  | total loss: [1m[32m0.25093[0m[0m | time: 98.545s
[2K
| Adam | epoch: 006 | loss: 0.25093 - acc: 0.9298 | val_loss: 0.40563 - val_acc: 0.8261 -- iter: 293/293
--
Training Step: 61  | total loss: [1m[32m0.22405[0m[0m | time: 10.267s
[2K
| Adam | epoch: 007 | loss: 0.22405 - acc: 0.9390 -- iter: 032/293
[A[ATraining Step: 62  | total loss: [1m[32m0.20051[0m[0m | time: 20.772s
[2K
| Adam | epoch: 007 | loss: 0.20051 - acc: 0.9468 -- iter: 064/293
[A[ATraining Step: 63  | total loss: [1m[32m0.18572[0m[0m | time: 31.779s
[2K
| Adam | epoch: 007 | loss: 0.18572 - acc: 0.9456 -- iter: 096/293
[A[ATraining Step: 64  | total loss: [1m[32m0.19961[0m[0m | time: 42.340s
[2K
| Adam | epoch: 007 | loss: 0.19961 - acc: 0.9446 -- iter: 128/293
[A[ATraining Step: 65  | total loss: [1m[32m0.18228[0m[0m | time: 45.437s
[2K
| Adam | epoch: 007 | loss: 0.18228 - acc: 0.9514 -- iter: 160/293
[A[ATraining Step: 66  | total loss: [1m[32m0.16566[0m[0m | time: 48.366s
[2K
| Adam | epoch: 007 | loss: 0.16566 - acc: 0.9574 -- iter: 192/293
[A[ATraining Step: 67  | total loss: [1m[32m0.38543[0m[0m | time: 59.150s
[2K
| Adam | epoch: 007 | loss: 0.38543 - acc: 0.9145 -- iter: 224/293
[A[ATraining Step: 68  | total loss: [1m[32m0.34704[0m[0m | time: 69.766s
[2K
| Adam | epoch: 007 | loss: 0.34704 - acc: 0.9246 -- iter: 256/293
[A[ATraining Step: 69  | total loss: [1m[32m0.31492[0m[0m | time: 80.227s
[2K
| Adam | epoch: 007 | loss: 0.31492 - acc: 0.9298 -- iter: 288/293
[A[ATraining Step: 70  | total loss: [1m[32m0.28222[0m[0m | time: 96.548s
[2K
| Adam | epoch: 007 | loss: 0.28222 - acc: 0.9379 | val_loss: 0.37299 - val_acc: 0.8370 -- iter: 293/293
--
Training Step: 71  | total loss: [1m[32m0.25931[0m[0m | time: 11.205s
[2K
| Adam | epoch: 008 | loss: 0.25931 - acc: 0.9414 -- iter: 032/293
[A[ATraining Step: 72  | total loss: [1m[32m0.27327[0m[0m | time: 21.725s
[2K
| Adam | epoch: 008 | loss: 0.27327 - acc: 0.9445 -- iter: 064/293
[A[ATraining Step: 73  | total loss: [1m[32m0.24621[0m[0m | time: 32.414s
[2K
| Adam | epoch: 008 | loss: 0.24621 - acc: 0.9506 -- iter: 096/293
[A[ATraining Step: 74  | total loss: [1m[32m0.22341[0m[0m | time: 43.223s
[2K
| Adam | epoch: 008 | loss: 0.22341 - acc: 0.9561 -- iter: 128/293
[A[ATraining Step: 75  | total loss: [1m[32m0.20200[0m[0m | time: 54.521s
[2K
| Adam | epoch: 008 | loss: 0.20200 - acc: 0.9608 -- iter: 160/293
[A[ATraining Step: 76  | total loss: [1m[32m0.19906[0m[0m | time: 57.162s
[2K
| Adam | epoch: 008 | loss: 0.19906 - acc: 0.9583 -- iter: 192/293
[A[ATraining Step: 77  | total loss: [1m[32m0.17880[0m[0m | time: 60.071s
[2K
| Adam | epoch: 008 | loss: 0.17880 - acc: 0.9627 -- iter: 224/293
[A[ATraining Step: 78  | total loss: [1m[32m0.53349[0m[0m | time: 71.003s
[2K
| Adam | epoch: 008 | loss: 0.53349 - acc: 0.9038 -- iter: 256/293
[A[ATraining Step: 79  | total loss: [1m[32m0.48932[0m[0m | time: 81.934s
[2K
| Adam | epoch: 008 | loss: 0.48932 - acc: 0.9106 -- iter: 288/293
[A[ATraining Step: 80  | total loss: [1m[32m0.44602[0m[0m | time: 98.580s
[2K
| Adam | epoch: 008 | loss: 0.44602 - acc: 0.9197 | val_loss: 0.56858 - val_acc: 0.8152 -- iter: 293/293
--
Training Step: 81  | total loss: [1m[32m0.41158[0m[0m | time: 12.389s
[2K
| Adam | epoch: 009 | loss: 0.41158 - acc: 0.9215 -- iter: 032/293
[A[ATraining Step: 82  | total loss: [1m[32m0.37786[0m[0m | time: 24.399s
[2K
| Adam | epoch: 009 | loss: 0.37786 - acc: 0.9262 -- iter: 064/293
[A[ATraining Step: 83  | total loss: [1m[32m0.35275[0m[0m | time: 36.583s
[2K
| Adam | epoch: 009 | loss: 0.35275 - acc: 0.9305 -- iter: 096/293
[A[ATraining Step: 84  | total loss: [1m[32m0.32240[0m[0m | time: 48.438s
[2K
| Adam | epoch: 009 | loss: 0.32240 - acc: 0.9374 -- iter: 128/293
[A[ATraining Step: 85  | total loss: [1m[32m0.30157[0m[0m | time: 60.283s
[2K
| Adam | epoch: 009 | loss: 0.30157 - acc: 0.9437 -- iter: 160/293
[A[ATraining Step: 86  | total loss: [1m[32m0.27917[0m[0m | time: 69.735s
[2K
| Adam | epoch: 009 | loss: 0.27917 - acc: 0.9493 -- iter: 192/293
[A[ATraining Step: 87  | total loss: [1m[32m0.25618[0m[0m | time: 71.763s
[2K
| Adam | epoch: 009 | loss: 0.25618 - acc: 0.9544 -- iter: 224/293
[A[ATraining Step: 88  | total loss: [1m[32m0.23539[0m[0m | time: 73.798s
[2K
| Adam | epoch: 009 | loss: 0.23539 - acc: 0.9589 -- iter: 256/293
[A[ATraining Step: 89  | total loss: [1m[32m0.29170[0m[0m | time: 83.739s
[2K
| Adam | epoch: 009 | loss: 0.29170 - acc: 0.9431 -- iter: 288/293
[A[ATraining Step: 90  | total loss: [1m[32m0.26825[0m[0m | time: 100.925s
[2K
| Adam | epoch: 009 | loss: 0.26825 - acc: 0.9456 | val_loss: 0.43747 - val_acc: 0.8478 -- iter: 293/293
--
Training Step: 91  | total loss: [1m[32m0.24830[0m[0m | time: 11.356s
[2K
| Adam | epoch: 010 | loss: 0.24830 - acc: 0.9479 -- iter: 032/293
[A[ATraining Step: 92  | total loss: [1m[32m0.23207[0m[0m | time: 21.919s
[2K
| Adam | epoch: 010 | loss: 0.23207 - acc: 0.9531 -- iter: 064/293
[A[ATraining Step: 93  | total loss: [1m[32m0.22023[0m[0m | time: 33.096s
[2K
| Adam | epoch: 010 | loss: 0.22023 - acc: 0.9547 -- iter: 096/293
[A[ATraining Step: 94  | total loss: [1m[32m0.19983[0m[0m | time: 43.883s
[2K
| Adam | epoch: 010 | loss: 0.19983 - acc: 0.9592 -- iter: 128/293
[A[ATraining Step: 95  | total loss: [1m[32m0.18283[0m[0m | time: 54.840s
[2K
| Adam | epoch: 010 | loss: 0.18283 - acc: 0.9633 -- iter: 160/293
[A[ATraining Step: 96  | total loss: [1m[32m0.16817[0m[0m | time: 65.844s
[2K
| Adam | epoch: 010 | loss: 0.16817 - acc: 0.9670 -- iter: 192/293
[A[ATraining Step: 97  | total loss: [1m[32m0.15358[0m[0m | time: 76.630s
[2K
| Adam | epoch: 010 | loss: 0.15358 - acc: 0.9703 -- iter: 224/293
[A[ATraining Step: 98  | total loss: [1m[32m0.16104[0m[0m | time: 79.831s
[2K
| Adam | epoch: 010 | loss: 0.16104 - acc: 0.9639 -- iter: 256/293
[A[ATraining Step: 99  | total loss: [1m[32m0.14916[0m[0m | time: 82.460s
[2K
| Adam | epoch: 010 | loss: 0.14916 - acc: 0.9675 -- iter: 288/293
[A[ATraining Step: 100  | total loss: [1m[32m0.24488[0m[0m | time: 99.139s
[2K
| Adam | epoch: 010 | loss: 0.24488 - acc: 0.9507 | val_loss: 0.51649 - val_acc: 0.8370 -- iter: 293/293
--
Training Step: 101  | total loss: [1m[32m0.22588[0m[0m | time: 11.023s
[2K
| Adam | epoch: 011 | loss: 0.22588 - acc: 0.9525 -- iter: 032/293
[A[ATraining Step: 102  | total loss: [1m[32m0.21291[0m[0m | time: 22.866s
[2K
| Adam | epoch: 011 | loss: 0.21291 - acc: 0.9542 -- iter: 064/293
[A[ATraining Step: 103  | total loss: [1m[32m0.19347[0m[0m | time: 34.608s
[2K
| Adam | epoch: 011 | loss: 0.19347 - acc: 0.9587 -- iter: 096/293
[A[ATraining Step: 104  | total loss: [1m[32m0.17570[0m[0m | time: 46.592s
[2K
| Adam | epoch: 011 | loss: 0.17570 - acc: 0.9629 -- iter: 128/293
[A[ATraining Step: 105  | total loss: [1m[32m0.16874[0m[0m | time: 58.371s
[2K
| Adam | epoch: 011 | loss: 0.16874 - acc: 0.9603 -- iter: 160/293
[A[ATraining Step: 106  | total loss: [1m[32m0.16035[0m[0m | time: 70.178s
[2K
| Adam | epoch: 011 | loss: 0.16035 - acc: 0.9612 -- iter: 192/293
[A[ATraining Step: 107  | total loss: [1m[32m0.14696[0m[0m | time: 82.091s
[2K
| Adam | epoch: 011 | loss: 0.14696 - acc: 0.9651 -- iter: 224/293
[A[ATraining Step: 108  | total loss: [1m[32m0.13567[0m[0m | time: 93.880s
[2K
| Adam | epoch: 011 | loss: 0.13567 - acc: 0.9686 -- iter: 256/293
[A[ATraining Step: 109  | total loss: [1m[32m0.12436[0m[0m | time: 97.385s
[2K
| Adam | epoch: 011 | loss: 0.12436 - acc: 0.9717 -- iter: 288/293
[A[ATraining Step: 110  | total loss: [1m[32m0.11704[0m[0m | time: 105.224s
[2K
| Adam | epoch: 011 | loss: 0.11704 - acc: 0.9745 | val_loss: 0.30242 - val_acc: 0.8913 -- iter: 293/293
--
Training Step: 111  | total loss: [1m[32m0.10914[0m[0m | time: 10.991s
[2K
| Adam | epoch: 012 | loss: 0.10914 - acc: 0.9771 -- iter: 032/293
[A[ATraining Step: 112  | total loss: [1m[32m0.10097[0m[0m | time: 21.950s
[2K
| Adam | epoch: 012 | loss: 0.10097 - acc: 0.9794 -- iter: 064/293
[A[ATraining Step: 113  | total loss: [1m[32m0.09375[0m[0m | time: 33.391s
[2K
| Adam | epoch: 012 | loss: 0.09375 - acc: 0.9814 -- iter: 096/293
[A[ATraining Step: 114  | total loss: [1m[32m0.09687[0m[0m | time: 44.248s
[2K
| Adam | epoch: 012 | loss: 0.09687 - acc: 0.9802 -- iter: 128/293
[A[ATraining Step: 115  | total loss: [1m[32m0.08950[0m[0m | time: 54.935s
[2K
| Adam | epoch: 012 | loss: 0.08950 - acc: 0.9821 -- iter: 160/293
[A[ATraining Step: 116  | total loss: [1m[32m0.08247[0m[0m | time: 65.850s
[2K
| Adam | epoch: 012 | loss: 0.08247 - acc: 0.9839 -- iter: 192/293
[A[ATraining Step: 117  | total loss: [1m[32m0.08000[0m[0m | time: 76.759s
[2K
| Adam | epoch: 012 | loss: 0.08000 - acc: 0.9824 -- iter: 224/293
[A[ATraining Step: 118  | total loss: [1m[32m0.07566[0m[0m | time: 87.546s
[2K
| Adam | epoch: 012 | loss: 0.07566 - acc: 0.9810 -- iter: 256/293
[A[ATraining Step: 119  | total loss: [1m[32m0.08448[0m[0m | time: 98.414s
[2K
| Adam | epoch: 012 | loss: 0.08448 - acc: 0.9767 -- iter: 288/293
[A[ATraining Step: 120  | total loss: [1m[32m0.08673[0m[0m | time: 107.024s
[2K
| Adam | epoch: 012 | loss: 0.08673 - acc: 0.9759 | val_loss: 0.44260 - val_acc: 0.8478 -- iter: 293/293
--
Training Step: 121  | total loss: [1m[32m0.10034[0m[0m | time: 2.839s
[2K
| Adam | epoch: 013 | loss: 0.10034 - acc: 0.9583 -- iter: 032/293
[A[ATraining Step: 122  | total loss: [1m[32m0.09058[0m[0m | time: 13.842s
[2K
| Adam | epoch: 013 | loss: 0.09058 - acc: 0.9625 -- iter: 064/293
[A[ATraining Step: 123  | total loss: [1m[32m0.08362[0m[0m | time: 24.700s
[2K
| Adam | epoch: 013 | loss: 0.08362 - acc: 0.9662 -- iter: 096/293
[A[ATraining Step: 124  | total loss: [1m[32m0.07961[0m[0m | time: 36.768s
[2K
| Adam | epoch: 013 | loss: 0.07961 - acc: 0.9696 -- iter: 128/293
[A[ATraining Step: 125  | total loss: [1m[32m0.07278[0m[0m | time: 47.923s
[2K
| Adam | epoch: 013 | loss: 0.07278 - acc: 0.9726 -- iter: 160/293
[A[ATraining Step: 126  | total loss: [1m[32m0.06786[0m[0m | time: 58.660s
[2K
| Adam | epoch: 013 | loss: 0.06786 - acc: 0.9754 -- iter: 192/293
[A[ATraining Step: 127  | total loss: [1m[32m0.06536[0m[0m | time: 69.960s
[2K
| Adam | epoch: 013 | loss: 0.06536 - acc: 0.9747 -- iter: 224/293
[A[ATraining Step: 128  | total loss: [1m[32m0.06279[0m[0m | time: 80.643s
[2K
| Adam | epoch: 013 | loss: 0.06279 - acc: 0.9772 -- iter: 256/293
[A[ATraining Step: 129  | total loss: [1m[32m0.06164[0m[0m | time: 91.517s
[2K
| Adam | epoch: 013 | loss: 0.06164 - acc: 0.9795 -- iter: 288/293
[A[ATraining Step: 130  | total loss: [1m[32m0.05717[0m[0m | time: 108.504s
[2K
| Adam | epoch: 013 | loss: 0.05717 - acc: 0.9816 | val_loss: 0.46477 - val_acc: 0.8696 -- iter: 293/293
--
Training Step: 131  | total loss: [1m[32m0.06177[0m[0m | time: 3.022s
[2K
| Adam | epoch: 014 | loss: 0.06177 - acc: 0.9803 -- iter: 032/293
[A[ATraining Step: 132  | total loss: [1m[32m0.05722[0m[0m | time: 5.934s
[2K
| Adam | epoch: 014 | loss: 0.05722 - acc: 0.9823 -- iter: 064/293
[A[ATraining Step: 133  | total loss: [1m[32m0.05195[0m[0m | time: 17.277s
[2K
| Adam | epoch: 014 | loss: 0.05195 - acc: 0.9840 -- iter: 096/293
[A[ATraining Step: 134  | total loss: [1m[32m0.04746[0m[0m | time: 27.900s
[2K
| Adam | epoch: 014 | loss: 0.04746 - acc: 0.9856 -- iter: 128/293
[A[ATraining Step: 135  | total loss: [1m[32m0.04334[0m[0m | time: 38.535s
[2K
| Adam | epoch: 014 | loss: 0.04334 - acc: 0.9871 -- iter: 160/293
[A[ATraining Step: 136  | total loss: [1m[32m0.04029[0m[0m | time: 49.555s
[2K
| Adam | epoch: 014 | loss: 0.04029 - acc: 0.9884 -- iter: 192/293
[A[ATraining Step: 137  | total loss: [1m[32m0.03822[0m[0m | time: 60.656s
[2K
| Adam | epoch: 014 | loss: 0.03822 - acc: 0.9895 -- iter: 224/293
[A[ATraining Step: 138  | total loss: [1m[32m0.05452[0m[0m | time: 71.717s
[2K
| Adam | epoch: 014 | loss: 0.05452 - acc: 0.9843 -- iter: 256/293
[A[ATraining Step: 139  | total loss: [1m[32m0.05033[0m[0m | time: 82.647s
[2K
| Adam | epoch: 014 | loss: 0.05033 - acc: 0.9859 -- iter: 288/293
[A[ATraining Step: 140  | total loss: [1m[32m0.04638[0m[0m | time: 99.766s
[2K
| Adam | epoch: 014 | loss: 0.04638 - acc: 0.9873 | val_loss: 0.66501 - val_acc: 0.8478 -- iter: 293/293
--
Training Step: 141  | total loss: [1m[32m0.04250[0m[0m | time: 10.910s
[2K
| Adam | epoch: 015 | loss: 0.04250 - acc: 0.9886 -- iter: 032/293
[A[ATraining Step: 142  | total loss: [1m[32m0.04715[0m[0m | time: 13.946s
[2K
| Adam | epoch: 015 | loss: 0.04715 - acc: 0.9866 -- iter: 064/293
[A[ATraining Step: 143  | total loss: [1m[32m0.04763[0m[0m | time: 17.324s
[2K
| Adam | epoch: 015 | loss: 0.04763 - acc: 0.9879 -- iter: 096/293
[A[ATraining Step: 144  | total loss: [1m[32m0.15393[0m[0m | time: 27.965s
[2K
| Adam | epoch: 015 | loss: 0.15393 - acc: 0.9691 -- iter: 128/293
[A[ATraining Step: 145  | total loss: [1m[32m0.14045[0m[0m | time: 39.384s
[2K
| Adam | epoch: 015 | loss: 0.14045 - acc: 0.9722 -- iter: 160/293
[A[ATraining Step: 146  | total loss: [1m[32m0.12771[0m[0m | time: 50.166s
[2K
| Adam | epoch: 015 | loss: 0.12771 - acc: 0.9750 -- iter: 192/293
[A[ATraining Step: 147  | total loss: [1m[32m0.11928[0m[0m | time: 61.064s
[2K
| Adam | epoch: 015 | loss: 0.11928 - acc: 0.9744 -- iter: 224/293
[A[ATraining Step: 148  | total loss: [1m[32m0.11448[0m[0m | time: 72.109s
[2K
| Adam | epoch: 015 | loss: 0.11448 - acc: 0.9738 -- iter: 256/293
[A[ATraining Step: 149  | total loss: [1m[32m0.10501[0m[0m | time: 82.791s
[2K
| Adam | epoch: 015 | loss: 0.10501 - acc: 0.9764 -- iter: 288/293
[A[ATraining Step: 150  | total loss: [1m[32m0.09573[0m[0m | time: 99.484s
[2K
| Adam | epoch: 015 | loss: 0.09573 - acc: 0.9788 | val_loss: 0.83791 - val_acc: 0.8043 -- iter: 293/293
--
Training Step: 151  | total loss: [1m[32m0.08892[0m[0m | time: 11.035s
[2K
| Adam | epoch: 016 | loss: 0.08892 - acc: 0.9809 -- iter: 032/293
[A[ATraining Step: 152  | total loss: [1m[32m0.10371[0m[0m | time: 22.173s
[2K
| Adam | epoch: 016 | loss: 0.10371 - acc: 0.9766 -- iter: 064/293
[A[ATraining Step: 153  | total loss: [1m[32m0.10193[0m[0m | time: 25.264s
[2K
| Adam | epoch: 016 | loss: 0.10193 - acc: 0.9758 -- iter: 096/293
[A[ATraining Step: 154  | total loss: [1m[32m0.09284[0m[0m | time: 28.419s
[2K
| Adam | epoch: 016 | loss: 0.09284 - acc: 0.9782 -- iter: 128/293
[A[ATraining Step: 155  | total loss: [1m[32m0.08394[0m[0m | time: 40.238s
[2K
| Adam | epoch: 016 | loss: 0.08394 - acc: 0.9804 -- iter: 160/293
[A[ATraining Step: 156  | total loss: [1m[32m0.07613[0m[0m | time: 51.280s
[2K
| Adam | epoch: 016 | loss: 0.07613 - acc: 0.9823 -- iter: 192/293
[A[ATraining Step: 157  | total loss: [1m[32m0.07237[0m[0m | time: 62.343s
[2K
| Adam | epoch: 016 | loss: 0.07237 - acc: 0.9810 -- iter: 224/293
[A[ATraining Step: 158  | total loss: [1m[32m0.06647[0m[0m | time: 73.703s
[2K
| Adam | epoch: 016 | loss: 0.06647 - acc: 0.9829 -- iter: 256/293
[A[ATraining Step: 159  | total loss: [1m[32m0.06203[0m[0m | time: 105.260s
[2K
| Adam | epoch: 016 | loss: 0.06203 - acc: 0.9846 -- iter: 288/293
[A[ATraining Step: 160  | total loss: [1m[32m0.07616[0m[0m | time: 137.367s
[2K
| Adam | epoch: 016 | loss: 0.07616 - acc: 0.9830 | val_loss: 0.79681 - val_acc: 0.8478 -- iter: 293/293
--
Training Step: 161  | total loss: [1m[32m0.08521[0m[0m | time: 59.096s
[2K
| Adam | epoch: 017 | loss: 0.08521 - acc: 0.9816 -- iter: 032/293
[A[ATraining Step: 162  | total loss: [1m[32m0.08772[0m[0m | time: 102.569s
[2K
| Adam | epoch: 017 | loss: 0.08772 - acc: 0.9741 -- iter: 064/293
[A[ATraining Step: 163  | total loss: [1m[32m0.08758[0m[0m | time: 136.671s
[2K
| Adam | epoch: 017 | loss: 0.08758 - acc: 0.9735 -- iter: 096/293
[A[ATraining Step: 164  | total loss: [1m[32m0.08113[0m[0m | time: 167.361s
[2K
| Adam | epoch: 017 | loss: 0.08113 - acc: 0.9762 -- iter: 128/293
[A[ATraining Step: 165  | total loss: [1m[32m0.09080[0m[0m | time: 172.322s
[2K
| Adam | epoch: 017 | loss: 0.09080 - acc: 0.9786 -- iter: 160/293
[A[ATraining Step: 166  | total loss: [1m[32m0.30558[0m[0m | time: 224.032s
[2K
| Adam | epoch: 017 | loss: 0.30558 - acc: 0.9407 -- iter: 192/293
[A[ATraining Step: 167  | total loss: [1m[32m0.27682[0m[0m | time: 235.495s
[2K
| Adam | epoch: 017 | loss: 0.27682 - acc: 0.9466 -- iter: 224/293
[A[ATraining Step: 168  | total loss: [1m[32m0.25563[0m[0m | time: 249.104s
[2K
| Adam | epoch: 017 | loss: 0.25563 - acc: 0.9488 -- iter: 256/293
[A[ATraining Step: 169  | total loss: [1m[32m0.23512[0m[0m | time: 260.756s
[2K
| Adam | epoch: 017 | loss: 0.23512 - acc: 0.9508 -- iter: 288/293
[A[ATraining Step: 170  | total loss: [1m[32m0.21495[0m[0m | time: 278.291s
[2K
| Adam | epoch: 017 | loss: 0.21495 - acc: 0.9526 | val_loss: 1.01353 - val_acc: 0.8152 -- iter: 293/293
--
Training Step: 171  | total loss: [1m[32m0.19727[0m[0m | time: 29.794s
[2K
| Adam | epoch: 018 | loss: 0.19727 - acc: 0.9574 -- iter: 032/293
[A[ATraining Step: 172  | total loss: [1m[32m0.18851[0m[0m | time: 69.610s
[2K
| Adam | epoch: 018 | loss: 0.18851 - acc: 0.9585 -- iter: 064/293
[A[ATraining Step: 173  | total loss: [1m[32m0.21052[0m[0m | time: 94.633s
[2K
| Adam | epoch: 018 | loss: 0.21052 - acc: 0.9502 -- iter: 096/293
[A[ATraining Step: 174  | total loss: [1m[32m0.19220[0m[0m | time: 132.681s
[2K
| Adam | epoch: 018 | loss: 0.19220 - acc: 0.9551 -- iter: 128/293
[A[ATraining Step: 175  | total loss: [1m[32m0.18955[0m[0m | time: 137.261s
[2K
| Adam | epoch: 018 | loss: 0.18955 - acc: 0.9502 -- iter: 160/293
[A[ATraining Step: 176  | total loss: [1m[32m0.17092[0m[0m | time: 142.359s
[2K
| Adam | epoch: 018 | loss: 0.17092 - acc: 0.9552 -- iter: 192/293
[A[ATraining Step: 177  | total loss: [1m[32m0.36187[0m[0m | time: 193.133s
[2K
| Adam | epoch: 018 | loss: 0.36187 - acc: 0.8997 -- iter: 224/293
[A[ATraining Step: 178  | total loss: [1m[32m0.33877[0m[0m | time: 206.810s
[2K
| Adam | epoch: 018 | loss: 0.33877 - acc: 0.9066 -- iter: 256/293
[A[ATraining Step: 179  | total loss: [1m[32m0.32172[0m[0m | time: 218.711s
[2K
| Adam | epoch: 018 | loss: 0.32172 - acc: 0.9097 -- iter: 288/293
[A[ATraining Step: 180  | total loss: [1m[32m0.35485[0m[0m | time: 237.400s
[2K
| Adam | epoch: 018 | loss: 0.35485 - acc: 0.9031 | val_loss: 2.25312 - val_acc: 0.6848 -- iter: 293/293
--
Training Step: 181  | total loss: [1m[32m0.32951[0m[0m | time: 18.253s
[2K
| Adam | epoch: 019 | loss: 0.32951 - acc: 0.9065 -- iter: 032/293
[A[ATraining Step: 182  | total loss: [1m[32m0.30654[0m[0m | time: 37.450s
[2K
| Adam | epoch: 019 | loss: 0.30654 - acc: 0.9128 -- iter: 064/293
[A[ATraining Step: 183  | total loss: [1m[32m0.28223[0m[0m | time: 56.101s
[2K
| Adam | epoch: 019 | loss: 0.28223 - acc: 0.9184 -- iter: 096/293
[A[ATraining Step: 184  | total loss: [1m[32m0.26767[0m[0m | time: 74.455s
[2K
| Adam | epoch: 019 | loss: 0.26767 - acc: 0.9171 -- iter: 128/293
[A[ATraining Step: 185  | total loss: [1m[32m0.25582[0m[0m | time: 92.395s
[2K
| Adam | epoch: 019 | loss: 0.25582 - acc: 0.9223 -- iter: 160/293
[A[ATraining Step: 186  | total loss: [1m[32m0.23713[0m[0m | time: 97.212s
[2K
| Adam | epoch: 019 | loss: 0.23713 - acc: 0.9301 -- iter: 192/293
[A[ATraining Step: 187  | total loss: [1m[32m0.21960[0m[0m | time: 102.155s
[2K
| Adam | epoch: 019 | loss: 0.21960 - acc: 0.9371 -- iter: 224/293
[A[ATraining Step: 188  | total loss: [1m[32m0.28313[0m[0m | time: 116.744s
[2K
| Adam | epoch: 019 | loss: 0.28313 - acc: 0.9234 -- iter: 256/293
[A[ATraining Step: 189  | total loss: [1m[32m0.26441[0m[0m | time: 128.638s
[2K
| Adam | epoch: 019 | loss: 0.26441 - acc: 0.9279 -- iter: 288/293
[A[ATraining Step: 190  | total loss: [1m[32m0.25031[0m[0m | time: 148.689s
[2K
| Adam | epoch: 019 | loss: 0.25031 - acc: 0.9289 | val_loss: 2.90316 - val_acc: 0.5109 -- iter: 293/293
--
Training Step: 191  | total loss: [1m[32m0.23232[0m[0m | time: 20.998s
[2K
| Adam | epoch: 020 | loss: 0.23232 - acc: 0.9329 -- iter: 032/293
[A[ATraining Step: 192  | total loss: [1m[32m0.22872[0m[0m | time: 40.550s
[2K
| Adam | epoch: 020 | loss: 0.22872 - acc: 0.9302 -- iter: 064/293
[A[ATraining Step: 193  | total loss: [1m[32m0.21259[0m[0m | time: 59.469s
[2K
| Adam | epoch: 020 | loss: 0.21259 - acc: 0.9340 -- iter: 096/293
[A[ATraining Step: 194  | total loss: [1m[32m0.20174[0m[0m | time: 77.161s
[2K
| Adam | epoch: 020 | loss: 0.20174 - acc: 0.9375 -- iter: 128/293
[A[ATraining Step: 195  | total loss: [1m[32m0.18738[0m[0m | time: 95.288s
[2K
| Adam | epoch: 020 | loss: 0.18738 - acc: 0.9406 -- iter: 160/293
[A[ATraining Step: 196  | total loss: [1m[32m0.17456[0m[0m | time: 107.087s
[2K
| Adam | epoch: 020 | loss: 0.17456 - acc: 0.9466 -- iter: 192/293
[A[ATraining Step: 197  | total loss: [1m[32m0.16834[0m[0m | time: 110.161s
[2K
| Adam | epoch: 020 | loss: 0.16834 - acc: 0.9488 -- iter: 224/293
[A[ATraining Step: 198  | total loss: [1m[32m0.17624[0m[0m | time: 113.273s
[2K
| Adam | epoch: 020 | loss: 0.17624 - acc: 0.9339 -- iter: 256/293
[A[ATraining Step: 199  | total loss: [1m[32m0.23546[0m[0m | time: 130.327s
[2K
| Adam | epoch: 020 | loss: 0.23546 - acc: 0.9205 -- iter: 288/293
[A[ATraining Step: 200  | total loss: [1m[32m0.21566[0m[0m | time: 157.468s
[2K
| Adam | epoch: 020 | loss: 0.21566 - acc: 0.9285 | val_loss: 0.40075 - val_acc: 0.8152 -- iter: 293/293
--
Training Step: 201  | total loss: [1m[32m0.19714[0m[0m | time: 30.714s
[2K
| Adam | epoch: 021 | loss: 0.19714 - acc: 0.9356 -- iter: 032/293
[A[ATraining Step: 202  | total loss: [1m[32m0.18418[0m[0m | time: 47.943s
[2K
| Adam | epoch: 021 | loss: 0.18418 - acc: 0.9389 -- iter: 064/293
[A[ATraining Step: 203  | total loss: [1m[32m0.17262[0m[0m | time: 70.584s
[2K
| Adam | epoch: 021 | loss: 0.17262 - acc: 0.9419 -- iter: 096/293
[A[ATraining Step: 204  | total loss: [1m[32m0.15837[0m[0m | time: 86.383s
[2K
| Adam | epoch: 021 | loss: 0.15837 - acc: 0.9477 -- iter: 128/293
[A[ATraining Step: 205  | total loss: [1m[32m0.14505[0m[0m | time: 98.151s
[2K
| Adam | epoch: 021 | loss: 0.14505 - acc: 0.9530 -- iter: 160/293
[A[ATraining Step: 206  | total loss: [1m[32m0.13195[0m[0m | time: 110.475s
[2K
| Adam | epoch: 021 | loss: 0.13195 - acc: 0.9577 -- iter: 192/293
[A[ATraining Step: 207  | total loss: [1m[32m0.13086[0m[0m | time: 123.041s
[2K
| Adam | epoch: 021 | loss: 0.13086 - acc: 0.9588 -- iter: 224/293
[A[ATraining Step: 208  | total loss: [1m[32m0.12633[0m[0m | time: 127.171s
[2K
| Adam | epoch: 021 | loss: 0.12633 - acc: 0.9598 -- iter: 256/293
[A[ATraining Step: 209  | total loss: [1m[32m0.11460[0m[0m | time: 132.143s
[2K
| Adam | epoch: 021 | loss: 0.11460 - acc: 0.9638 -- iter: 288/293
[A[ATraining Step: 210  | total loss: [1m[32m0.10509[0m[0m | time: 159.745s
[2K
| Adam | epoch: 021 | loss: 0.10509 - acc: 0.9674 | val_loss: 0.36647 - val_acc: 0.8913 -- iter: 293/293
--
Training Step: 211  | total loss: [1m[32m0.09880[0m[0m | time: 37.419s
[2K
| Adam | epoch: 022 | loss: 0.09880 - acc: 0.9675 -- iter: 032/293
[A[ATraining Step: 212  | total loss: [1m[32m0.10495[0m[0m | time: 66.502s
[2K
| Adam | epoch: 022 | loss: 0.10495 - acc: 0.9645 -- iter: 064/293
[A[ATraining Step: 213  | total loss: [1m[32m0.09820[0m[0m | time: 82.875s
[2K
| Adam | epoch: 022 | loss: 0.09820 - acc: 0.9650 -- iter: 096/293
[A[ATraining Step: 214  | total loss: [1m[32m0.09059[0m[0m | time: 95.077s
[2K
| Adam | epoch: 022 | loss: 0.09059 - acc: 0.9685 -- iter: 128/293
[A[ATraining Step: 215  | total loss: [1m[32m0.08719[0m[0m | time: 108.687s
[2K
| Adam | epoch: 022 | loss: 0.08719 - acc: 0.9716 -- iter: 160/293
[A[ATraining Step: 216  | total loss: [1m[32m0.08272[0m[0m | time: 125.299s
[2K
| Adam | epoch: 022 | loss: 0.08272 - acc: 0.9713 -- iter: 192/293
[A[ATraining Step: 217  | total loss: [1m[32m0.07665[0m[0m | time: 144.212s
[2K
| Adam | epoch: 022 | loss: 0.07665 - acc: 0.9742 -- iter: 224/293
[A[ATraining Step: 218  | total loss: [1m[32m0.06948[0m[0m | time: 160.955s
[2K
| Adam | epoch: 022 | loss: 0.06948 - acc: 0.9768 -- iter: 256/293
[A[ATraining Step: 219  | total loss: [1m[32m0.06383[0m[0m | time: 166.116s
[2K
| Adam | epoch: 022 | loss: 0.06383 - acc: 0.9791 -- iter: 288/293
[A[ATraining Step: 220  | total loss: [1m[32m0.07275[0m[0m | time: 179.833s
[2K
| Adam | epoch: 022 | loss: 0.07275 - acc: 0.9612 | val_loss: 0.43155 - val_acc: 0.8478 -- iter: 293/293
--
Training Step: 221  | total loss: [1m[32m0.06560[0m[0m | time: 18.852s
[2K
| Adam | epoch: 023 | loss: 0.06560 - acc: 0.9651 -- iter: 032/293
[A[ATraining Step: 222  | total loss: [1m[32m0.06012[0m[0m | time: 32.555s
[2K
| Adam | epoch: 023 | loss: 0.06012 - acc: 0.9686 -- iter: 064/293
[A[ATraining Step: 223  | total loss: [1m[32m0.05896[0m[0m | time: 46.141s
[2K
| Adam | epoch: 023 | loss: 0.05896 - acc: 0.9686 -- iter: 096/293
[A[ATraining Step: 224  | total loss: [1m[32m0.05651[0m[0m | time: 107.214s
[2K
| Adam | epoch: 023 | loss: 0.05651 - acc: 0.9717 -- iter: 128/293
[A[ATraining Step: 225  | total loss: [1m[32m0.05116[0m[0m | time: 168.677s
[2K
| Adam | epoch: 023 | loss: 0.05116 - acc: 0.9746 -- iter: 160/293
[A[ATraining Step: 226  | total loss: [1m[32m0.05995[0m[0m | time: 234.207s
[2K
| Adam | epoch: 023 | loss: 0.05995 - acc: 0.9708 -- iter: 192/293
[A[ATraining Step: 227  | total loss: [1m[32m0.05477[0m[0m | time: 272.309s
[2K
| Adam | epoch: 023 | loss: 0.05477 - acc: 0.9738 -- iter: 224/293
[A[ATraining Step: 228  | total loss: [1m[32m0.06036[0m[0m | time: 284.811s
[2K
| Adam | epoch: 023 | loss: 0.06036 - acc: 0.9733 -- iter: 256/293
[A[ATraining Step: 229  | total loss: [1m[32m0.06475[0m[0m | time: 296.810s
[2K
| Adam | epoch: 023 | loss: 0.06475 - acc: 0.9728 -- iter: 288/293
[A[ATraining Step: 230  | total loss: [1m[32m0.05881[0m[0m | time: 308.048s
[2K
| Adam | epoch: 023 | loss: 0.05881 - acc: 0.9755 | val_loss: 0.46037 - val_acc: 0.8261 -- iter: 293/293
--
Training Step: 231  | total loss: [1m[32m0.05577[0m[0m | time: 3.303s
[2K
| Adam | epoch: 024 | loss: 0.05577 - acc: 0.9780 -- iter: 032/293
[A[ATraining Step: 232  | total loss: [1m[32m0.46562[0m[0m | time: 15.688s
[2K
| Adam | epoch: 024 | loss: 0.46562 - acc: 0.9402 -- iter: 064/293
[A[ATraining Step: 233  | total loss: [1m[32m0.41970[0m[0m | time: 31.254s
[2K
| Adam | epoch: 024 | loss: 0.41970 - acc: 0.9462 -- iter: 096/293
[A[ATraining Step: 234  | total loss: [1m[32m0.37993[0m[0m | time: 48.661s
[2K
| Adam | epoch: 024 | loss: 0.37993 - acc: 0.9515 -- iter: 128/293
[A[ATraining Step: 235  | total loss: [1m[32m0.34538[0m[0m | time: 65.283s
[2K
| Adam | epoch: 024 | loss: 0.34538 - acc: 0.9564 -- iter: 160/293
[A[ATraining Step: 236  | total loss: [1m[32m0.34183[0m[0m | time: 82.437s
[2K
| Adam | epoch: 024 | loss: 0.34183 - acc: 0.9483 -- iter: 192/293
[A[ATraining Step: 237  | total loss: [1m[32m0.31041[0m[0m | time: 101.694s
[2K
| Adam | epoch: 024 | loss: 0.31041 - acc: 0.9534 -- iter: 224/293
[A[ATraining Step: 238  | total loss: [1m[32m0.28525[0m[0m | time: 118.923s
[2K
| Adam | epoch: 024 | loss: 0.28525 - acc: 0.9581 -- iter: 256/293
[A[ATraining Step: 239  | total loss: [1m[32m0.26579[0m[0m | time: 135.551s
[2K
| Adam | epoch: 024 | loss: 0.26579 - acc: 0.9592 -- iter: 288/293
[A[ATraining Step: 240  | total loss: [1m[32m0.24810[0m[0m | time: 158.491s
[2K
| Adam | epoch: 024 | loss: 0.24810 - acc: 0.9601 | val_loss: 0.36724 - val_acc: 0.8587 -- iter: 293/293
--
Training Step: 241  | total loss: [1m[32m0.22816[0m[0m | time: 5.034s
[2K
| Adam | epoch: 025 | loss: 0.22816 - acc: 0.9610 -- iter: 032/293
[A[ATraining Step: 242  | total loss: [1m[32m0.20602[0m[0m | time: 9.710s
[2K
| Adam | epoch: 025 | loss: 0.20602 - acc: 0.9649 -- iter: 064/293
[A[ATraining Step: 243  | total loss: [1m[32m0.18618[0m[0m | time: 26.501s
[2K
| Adam | epoch: 025 | loss: 0.18618 - acc: 0.9684 -- iter: 096/293
[A[ATraining Step: 244  | total loss: [1m[32m0.17168[0m[0m | time: 43.280s
[2K
| Adam | epoch: 025 | loss: 0.17168 - acc: 0.9684 -- iter: 128/293
[A[ATraining Step: 245  | total loss: [1m[32m0.15770[0m[0m | time: 60.165s
[2K
| Adam | epoch: 025 | loss: 0.15770 - acc: 0.9716 -- iter: 160/293
[A[ATraining Step: 246  | total loss: [1m[32m0.14342[0m[0m | time: 77.731s
[2K
| Adam | epoch: 025 | loss: 0.14342 - acc: 0.9744 -- iter: 192/293
[A[ATraining Step: 247  | total loss: [1m[32m0.12993[0m[0m | time: 94.765s
[2K
| Adam | epoch: 025 | loss: 0.12993 - acc: 0.9770 -- iter: 224/293
[A[ATraining Step: 248  | total loss: [1m[32m0.12620[0m[0m | time: 111.330s
[2K
| Adam | epoch: 025 | loss: 0.12620 - acc: 0.9730 -- iter: 256/293
[A[ATraining Step: 249  | total loss: [1m[32m0.11506[0m[0m | time: 125.933s
[2K
| Adam | epoch: 025 | loss: 0.11506 - acc: 0.9757 -- iter: 288/293
[A[ATraining Step: 250  | total loss: [1m[32m0.11470[0m[0m | time: 145.602s
[2K
| Adam | epoch: 025 | loss: 0.11470 - acc: 0.9750 | val_loss: 0.37614 - val_acc: 0.8804 -- iter: 293/293
--
Training Step: 251  | total loss: [1m[32m0.11917[0m[0m | time: 17.303s
[2K
| Adam | epoch: 026 | loss: 0.11917 - acc: 0.9713 -- iter: 032/293
[A[ATraining Step: 252  | total loss: [1m[32m0.11113[0m[0m | time: 22.392s
[2K
| Adam | epoch: 026 | loss: 0.11113 - acc: 0.9710 -- iter: 064/293
[A[ATraining Step: 253  | total loss: [1m[32m0.10413[0m[0m | time: 27.232s
[2K
| Adam | epoch: 026 | loss: 0.10413 - acc: 0.9739 -- iter: 096/293
[A[ATraining Step: 254  | total loss: [1m[32m0.09620[0m[0m | time: 43.907s
[2K
| Adam | epoch: 026 | loss: 0.09620 - acc: 0.9765 -- iter: 128/293
[A[ATraining Step: 255  | total loss: [1m[32m0.08967[0m[0m | time: 61.984s
[2K
| Adam | epoch: 026 | loss: 0.08967 - acc: 0.9758 -- iter: 160/293
[A[ATraining Step: 256  | total loss: [1m[32m0.08298[0m[0m | time: 80.780s
[2K
| Adam | epoch: 026 | loss: 0.08298 - acc: 0.9782 -- iter: 192/293
[A[ATraining Step: 257  | total loss: [1m[32m0.07744[0m[0m | time: 97.898s
[2K
| Adam | epoch: 026 | loss: 0.07744 - acc: 0.9804 -- iter: 224/293
[A[ATraining Step: 258  | total loss: [1m[32m0.07361[0m[0m | time: 111.212s
[2K
| Adam | epoch: 026 | loss: 0.07361 - acc: 0.9792 -- iter: 256/293
[A[ATraining Step: 259  | total loss: [1m[32m0.06711[0m[0m | time: 123.162s
[2K
| Adam | epoch: 026 | loss: 0.06711 - acc: 0.9813 -- iter: 288/293
[A[ATraining Step: 260  | total loss: [1m[32m0.06057[0m[0m | time: 147.263s
[2K
| Adam | epoch: 026 | loss: 0.06057 - acc: 0.9832 | val_loss: 1.22108 - val_acc: 0.7826 -- iter: 293/293
--
Training Step: 261  | total loss: [1m[32m0.05485[0m[0m | time: 19.656s
[2K
| Adam | epoch: 027 | loss: 0.05485 - acc: 0.9848 -- iter: 032/293
[A[ATraining Step: 262  | total loss: [1m[32m0.05052[0m[0m | time: 41.206s
[2K
| Adam | epoch: 027 | loss: 0.05052 - acc: 0.9864 -- iter: 064/293
[A[ATraining Step: 263  | total loss: [1m[32m0.04680[0m[0m | time: 45.977s
[2K
| Adam | epoch: 027 | loss: 0.04680 - acc: 0.9877 -- iter: 096/293
[A[ATraining Step: 264  | total loss: [1m[32m0.05180[0m[0m | time: 50.574s
[2K
| Adam | epoch: 027 | loss: 0.05180 - acc: 0.9889 -- iter: 128/293
[A[ATraining Step: 265  | total loss: [1m[32m0.17480[0m[0m | time: 67.505s
[2K
| Adam | epoch: 027 | loss: 0.17480 - acc: 0.9701 -- iter: 160/293
[A[ATraining Step: 266  | total loss: [1m[32m0.15966[0m[0m | time: 83.993s
[2K
| Adam | epoch: 027 | loss: 0.15966 - acc: 0.9730 -- iter: 192/293
[A[ATraining Step: 267  | total loss: [1m[32m0.14432[0m[0m | time: 96.167s
[2K
| Adam | epoch: 027 | loss: 0.14432 - acc: 0.9757 -- iter: 224/293
[A[ATraining Step: 268  | total loss: [1m[32m0.13033[0m[0m | time: 109.298s
[2K
| Adam | epoch: 027 | loss: 0.13033 - acc: 0.9782 -- iter: 256/293
[A[ATraining Step: 269  | total loss: [1m[32m0.11932[0m[0m | time: 125.268s
[2K
| Adam | epoch: 027 | loss: 0.11932 - acc: 0.9804 -- iter: 288/293
[A[ATraining Step: 270  | total loss: [1m[32m0.10961[0m[0m | time: 151.304s
[2K
| Adam | epoch: 027 | loss: 0.10961 - acc: 0.9823 | val_loss: 0.98155 - val_acc: 0.7174 -- iter: 293/293
--
Training Step: 271  | total loss: [1m[32m0.10630[0m[0m | time: 17.090s
[2K
| Adam | epoch: 028 | loss: 0.10630 - acc: 0.9778 -- iter: 032/293
[A[ATraining Step: 272  | total loss: [1m[32m0.09757[0m[0m | time: 34.203s
[2K
| Adam | epoch: 028 | loss: 0.09757 - acc: 0.9801 -- iter: 064/293
[A[ATraining Step: 273  | total loss: [1m[32m0.09706[0m[0m | time: 51.092s
[2K
| Adam | epoch: 028 | loss: 0.09706 - acc: 0.9789 -- iter: 096/293
[A[ATraining Step: 274  | total loss: [1m[32m0.09112[0m[0m | time: 54.219s
[2K
| Adam | epoch: 028 | loss: 0.09112 - acc: 0.9810 -- iter: 128/293
[A[ATraining Step: 275  | total loss: [1m[32m0.08260[0m[0m | time: 57.412s
[2K
| Adam | epoch: 028 | loss: 0.08260 - acc: 0.9829 -- iter: 160/293
[A[ATraining Step: 276  | total loss: [1m[32m0.34653[0m[0m | time: 69.919s
[2K
| Adam | epoch: 028 | loss: 0.34653 - acc: 0.9446 -- iter: 192/293
[A[ATraining Step: 277  | total loss: [1m[32m0.31601[0m[0m | time: 82.411s
[2K
| Adam | epoch: 028 | loss: 0.31601 - acc: 0.9470 -- iter: 224/293
[A[ATraining Step: 278  | total loss: [1m[32m0.30405[0m[0m | time: 113.165s
[2K
| Adam | epoch: 028 | loss: 0.30405 - acc: 0.9430 -- iter: 256/293
[A[ATraining Step: 279  | total loss: [1m[32m0.28006[0m[0m | time: 135.894s
[2K
| Adam | epoch: 028 | loss: 0.28006 - acc: 0.9455 -- iter: 288/293
[A[ATraining Step: 280  | total loss: [1m[32m0.25884[0m[0m | time: 161.711s
[2K
| Adam | epoch: 028 | loss: 0.25884 - acc: 0.9479 | val_loss: 1.96575 - val_acc: 0.7609 -- iter: 293/293
--
Training Step: 281  | total loss: [1m[32m0.23387[0m[0m | time: 17.196s
[2K
| Adam | epoch: 029 | loss: 0.23387 - acc: 0.9531 -- iter: 032/293
[A[ATraining Step: 282  | total loss: [1m[32m0.21217[0m[0m | time: 35.064s
[2K
| Adam | epoch: 029 | loss: 0.21217 - acc: 0.9578 -- iter: 064/293
[A[ATraining Step: 283  | total loss: [1m[32m0.19517[0m[0m | time: 47.488s
[2K
| Adam | epoch: 029 | loss: 0.19517 - acc: 0.9620 -- iter: 096/293
[A[ATraining Step: 284  | total loss: [1m[32m0.18883[0m[0m | time: 60.324s
[2K
| Adam | epoch: 029 | loss: 0.18883 - acc: 0.9595 -- iter: 128/293
[A[ATraining Step: 285  | total loss: [1m[32m0.17533[0m[0m | time: 64.919s
[2K
| Adam | epoch: 029 | loss: 0.17533 - acc: 0.9605 -- iter: 160/293
[A[ATraining Step: 286  | total loss: [1m[32m0.16009[0m[0m | time: 69.327s
[2K
| Adam | epoch: 029 | loss: 0.16009 - acc: 0.9644 -- iter: 192/293
[A[ATraining Step: 287  | total loss: [1m[32m0.50376[0m[0m | time: 85.910s
[2K
| Adam | epoch: 029 | loss: 0.50376 - acc: 0.9280 -- iter: 224/293
[A[ATraining Step: 288  | total loss: [1m[32m0.46012[0m[0m | time: 102.552s
[2K
| Adam | epoch: 029 | loss: 0.46012 - acc: 0.9321 -- iter: 256/293
[A[ATraining Step: 289  | total loss: [1m[32m0.41864[0m[0m | time: 119.802s
[2K
| Adam | epoch: 029 | loss: 0.41864 - acc: 0.9357 -- iter: 288/293
[A[ATraining Step: 290  | total loss: [1m[32m0.37948[0m[0m | time: 146.101s
[2K
| Adam | epoch: 029 | loss: 0.37948 - acc: 0.9422 | val_loss: 0.49068 - val_acc: 0.8696 -- iter: 293/293
--
Training Step: 291  | total loss: [1m[32m0.35851[0m[0m | time: 16.368s
[2K
| Adam | epoch: 030 | loss: 0.35851 - acc: 0.9417 -- iter: 032/293
[A[ATraining Step: 292  | total loss: [1m[32m0.33021[0m[0m | time: 29.861s
[2K
| Adam | epoch: 030 | loss: 0.33021 - acc: 0.9444 -- iter: 064/293
[A[ATraining Step: 293  | total loss: [1m[32m0.30689[0m[0m | time: 43.268s
[2K
| Adam | epoch: 030 | loss: 0.30689 - acc: 0.9468 -- iter: 096/293
[A[ATraining Step: 294  | total loss: [1m[32m0.27911[0m[0m | time: 57.297s
[2K
| Adam | epoch: 030 | loss: 0.27911 - acc: 0.9521 -- iter: 128/293
[A[ATraining Step: 295  | total loss: [1m[32m0.25475[0m[0m | time: 75.138s
[2K
| Adam | epoch: 030 | loss: 0.25475 - acc: 0.9569 -- iter: 160/293
[A[ATraining Step: 296  | total loss: [1m[32m0.23499[0m[0m | time: 77.210s
[2K
| Adam | epoch: 030 | loss: 0.23499 - acc: 0.9612 -- iter: 192/293
[A[ATraining Step: 297  | total loss: [1m[32m0.22901[0m[0m | time: 79.232s
[2K
| Adam | epoch: 030 | loss: 0.22901 - acc: 0.9651 -- iter: 224/293
[A[ATraining Step: 298  | total loss: [1m[32m0.51192[0m[0m | time: 88.465s
[2K
| Adam | epoch: 030 | loss: 0.51192 - acc: 0.8886 -- iter: 256/293
[A[ATraining Step: 299  | total loss: [1m[32m0.46869[0m[0m | time: 100.676s
[2K
| Adam | epoch: 030 | loss: 0.46869 - acc: 0.8997 -- iter: 288/293
[A[ATraining Step: 300  | total loss: [1m[32m0.42887[0m[0m | time: 118.579s
[2K
| Adam | epoch: 030 | loss: 0.42887 - acc: 0.9098 | val_loss: 0.43891 - val_acc: 0.8587 -- iter: 293/293
--
Validation AUC:0.9327651515151516
Validation AUPRC:0.927933647712837
Test AUC:0.9719047619047619
Test AUPRC:0.9695065418970046
BestTestF1Score	0.9	0.81	0.9	0.85	0.95	40	7	43	2	0.69
BestTestMCCScore	0.9	0.81	0.9	0.85	0.95	40	7	43	2	0.69
BestTestAccuracyScore	0.9	0.81	0.9	0.85	0.95	40	7	43	2	0.69
BestValidationF1Score	0.89	0.76	0.88	0.86	0.92	44	7	37	4	0.69
BestValidationMCC	0.89	0.76	0.88	0.86	0.92	44	7	37	4	0.69
BestValidationAccuracy	0.89	0.76	0.88	0.86	0.92	44	7	37	4	0.69
TestPredictions (Threshold:0.69)
CHEMBL1092431,TP,ACT,0.9900000095367432	CHEMBL74902,TN,INACT,0.5600000023841858	CHEMBL60555,TP,ACT,1.0	CHEMBL595830,TP,ACT,1.0	CHEMBL75514,TN,INACT,0.0	CHEMBL64217,TP,ACT,1.0	CHEMBL184684,TP,ACT,1.0	CHEMBL3410297,TN,INACT,0.0	CHEMBL3586317,TN,INACT,0.10999999940395355	CHEMBL291630,TP,ACT,1.0	CHEMBL2112095,TN,INACT,0.5600000023841858	CHEMBL340501,TN,INACT,0.46000000834465027	CHEMBL221161,TN,INACT,0.009999999776482582	CHEMBL124675,TN,INACT,0.1899999976158142	CHEMBL252198,TN,INACT,0.009999999776482582	CHEMBL606195,TP,ACT,1.0	CHEMBL75141,TN,INACT,0.03999999910593033	CHEMBL220820,TN,INACT,0.07000000029802322	CHEMBL598174,TP,ACT,1.0	CHEMBL603227,FN,ACT,0.3199999928474426	CHEMBL599204,TP,ACT,1.0	CHEMBL2111731,TN,INACT,0.4000000059604645	CHEMBL606197,TP,ACT,1.0	CHEMBL606181,TP,ACT,1.0	CHEMBL279158,TN,INACT,0.6000000238418579	CHEMBL603625,TP,ACT,1.0	CHEMBL1094161,TP,ACT,0.9900000095367432	CHEMBL18797,TN,INACT,0.30000001192092896	CHEMBL592213,TP,ACT,1.0	CHEMBL64557,TP,ACT,1.0	CHEMBL600219,TP,ACT,1.0	CHEMBL439790,TN,INACT,0.019999999552965164	CHEMBL50,TN,INACT,0.0	CHEMBL691,TN,INACT,0.009999999776482582	CHEMBL210931,TN,INACT,0.019999999552965164	CHEMBL3793541,TN,INACT,0.029999999329447746	CHEMBL173039,TN,INACT,0.0	CHEMBL596956,TP,ACT,1.0	CHEMBL1933727,TP,ACT,0.9900000095367432	CHEMBL27041,TN,INACT,0.009999999776482582	CHEMBL598409,TP,ACT,1.0	CHEMBL2111766,TN,INACT,0.0	CHEMBL74330,TN,INACT,0.07000000029802322	CHEMBL828,TN,INACT,0.3100000023841858	CHEMBL308087,TN,INACT,0.009999999776482582	CHEMBL326085,TN,INACT,0.0	CHEMBL479633,TN,INACT,0.3400000035762787	CHEMBL92539,FP,INACT,0.9300000071525574	CHEMBL293697,TP,ACT,0.9399999976158142	CHEMBL1916686,FP,INACT,0.9399999976158142	CHEMBL426378,FP,INACT,0.9599999785423279	CHEMBL1095066,TP,ACT,1.0	CHEMBL1813287,TP,ACT,0.9900000095367432	CHEMBL566014,FP,INACT,0.9399999976158142	CHEMBL1813119,TP,ACT,1.0	CHEMBL3314886,TN,INACT,0.019999999552965164	CHEMBL1916700,TN,INACT,0.18000000715255737	CHEMBL249492,TN,INACT,0.0	CHEMBL603969,TP,ACT,0.8999999761581421	CHEMBL3220951,TN,INACT,0.019999999552965164	CHEMBL194578,FP,INACT,0.8899999856948853	CHEMBL1084009,FP,INACT,1.0	CHEMBL3114143,TN,INACT,0.0	CHEMBL599419,TP,ACT,1.0	CHEMBL292717,TP,ACT,1.0	CHEMBL62779,TP,ACT,1.0	CHEMBL1929533,TP,ACT,0.75	CHEMBL1929549,TP,ACT,0.9900000095367432	CHEMBL592212,TP,ACT,1.0	CHEMBL591034,TP,ACT,0.7699999809265137	CHEMBL46395,TN,INACT,0.6800000071525574	CHEMBL565992,FN,ACT,0.6000000238418579	CHEMBL1098507,TN,INACT,0.0	CHEMBL595159,TP,ACT,1.0	CHEMBL376347,TN,INACT,0.49000000953674316	CHEMBL47138,TN,INACT,0.009999999776482582	CHEMBL1088284,TN,INACT,0.009999999776482582	CHEMBL1929551,TP,ACT,1.0	CHEMBL16687,TN,INACT,0.0	CHEMBL280223,FP,INACT,0.9700000286102295	CHEMBL1092097,TP,ACT,1.0	CHEMBL598795,TP,ACT,1.0	CHEMBL126472,TN,INACT,0.05000000074505806	CHEMBL2315055,TP,ACT,0.949999988079071	CHEMBL599812,TP,ACT,1.0	CHEMBL315391,TN,INACT,0.6299999952316284	CHEMBL305568,TP,ACT,0.9900000095367432	CHEMBL341021,TN,INACT,0.0	CHEMBL1813118,TP,ACT,1.0	CHEMBL591298,TP,ACT,1.0	CHEMBL541164,TN,INACT,0.0	CHEMBL297578,TN,INACT,0.0	

