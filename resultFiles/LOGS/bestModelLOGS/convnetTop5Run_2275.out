CNNModel CHEMBL2916 RMSprop 0.0005 30 256 0 0.8 False True
Number of active compounds :	303
Number of inactive compounds :	202
---------------------------------
Run id: CNNModel_CHEMBL2916_RMSprop_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2916_RMSprop_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 313
Validation samples: 99
--
Training Step: 1  | time: 1.598s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/313
[A[ATraining Step: 2  | total loss: [1m[32m0.62362[0m[0m | time: 2.876s
[2K
| RMSProp | epoch: 001 | loss: 0.62362 - acc: 0.5344 -- iter: 064/313
[A[ATraining Step: 3  | total loss: [1m[32m0.68047[0m[0m | time: 4.068s
[2K
| RMSProp | epoch: 001 | loss: 0.68047 - acc: 0.5574 -- iter: 096/313
[A[ATraining Step: 4  | total loss: [1m[32m0.68985[0m[0m | time: 4.952s
[2K
| RMSProp | epoch: 001 | loss: 0.68985 - acc: 0.6315 -- iter: 128/313
[A[ATraining Step: 5  | total loss: [1m[32m0.69235[0m[0m | time: 5.941s
[2K
| RMSProp | epoch: 001 | loss: 0.69235 - acc: 0.4323 -- iter: 160/313
[A[ATraining Step: 6  | total loss: [1m[32m0.69264[0m[0m | time: 6.926s
[2K
| RMSProp | epoch: 001 | loss: 0.69264 - acc: 0.5964 -- iter: 192/313
[A[ATraining Step: 7  | total loss: [1m[32m0.69292[0m[0m | time: 7.998s
[2K
| RMSProp | epoch: 001 | loss: 0.69292 - acc: 0.5198 -- iter: 224/313
[A[ATraining Step: 8  | total loss: [1m[32m0.69284[0m[0m | time: 9.120s
[2K
| RMSProp | epoch: 001 | loss: 0.69284 - acc: 0.5790 -- iter: 256/313
[A[ATraining Step: 9  | total loss: [1m[32m0.69313[0m[0m | time: 9.995s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5206 -- iter: 288/313
[A[ATraining Step: 10  | total loss: [1m[32m0.69297[0m[0m | time: 11.823s
[2K
| RMSProp | epoch: 001 | loss: 0.69297 - acc: 0.5572 | val_loss: 0.69311 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 11  | total loss: [1m[32m0.69289[0m[0m | time: 0.480s
[2K
| RMSProp | epoch: 002 | loss: 0.69289 - acc: 0.5775 -- iter: 032/313
[A[ATraining Step: 12  | total loss: [1m[32m0.69283[0m[0m | time: 1.106s
[2K
| RMSProp | epoch: 002 | loss: 0.69283 - acc: 0.6236 -- iter: 064/313
[A[ATraining Step: 13  | total loss: [1m[32m0.69258[0m[0m | time: 1.710s
[2K
| RMSProp | epoch: 002 | loss: 0.69258 - acc: 0.6778 -- iter: 096/313
[A[ATraining Step: 14  | total loss: [1m[32m0.69274[0m[0m | time: 2.299s
[2K
| RMSProp | epoch: 002 | loss: 0.69274 - acc: 0.6050 -- iter: 128/313
[A[ATraining Step: 15  | total loss: [1m[32m0.69265[0m[0m | time: 2.893s
[2K
| RMSProp | epoch: 002 | loss: 0.69265 - acc: 0.6373 -- iter: 160/313
[A[ATraining Step: 16  | total loss: [1m[32m0.69291[0m[0m | time: 3.509s
[2K
| RMSProp | epoch: 002 | loss: 0.69291 - acc: 0.5858 -- iter: 192/313
[A[ATraining Step: 17  | total loss: [1m[32m0.69275[0m[0m | time: 4.135s
[2K
| RMSProp | epoch: 002 | loss: 0.69275 - acc: 0.5887 -- iter: 224/313
[A[ATraining Step: 18  | total loss: [1m[32m0.69254[0m[0m | time: 4.738s
[2K
| RMSProp | epoch: 002 | loss: 0.69254 - acc: 0.6445 -- iter: 256/313
[A[ATraining Step: 19  | total loss: [1m[32m0.69267[0m[0m | time: 5.412s
[2K
| RMSProp | epoch: 002 | loss: 0.69267 - acc: 0.6172 -- iter: 288/313
[A[ATraining Step: 20  | total loss: [1m[32m0.69271[0m[0m | time: 7.067s
[2K
| RMSProp | epoch: 002 | loss: 0.69271 - acc: 0.5795 | val_loss: 0.69310 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 21  | total loss: [1m[32m0.69262[0m[0m | time: 0.514s
[2K
| RMSProp | epoch: 003 | loss: 0.69262 - acc: 0.5936 -- iter: 032/313
[A[ATraining Step: 22  | total loss: [1m[32m0.69251[0m[0m | time: 1.015s
[2K
| RMSProp | epoch: 003 | loss: 0.69251 - acc: 0.6075 -- iter: 064/313
[A[ATraining Step: 23  | total loss: [1m[32m0.69266[0m[0m | time: 1.618s
[2K
| RMSProp | epoch: 003 | loss: 0.69266 - acc: 0.5705 -- iter: 096/313
[A[ATraining Step: 24  | total loss: [1m[32m0.69241[0m[0m | time: 2.232s
[2K
| RMSProp | epoch: 003 | loss: 0.69241 - acc: 0.6122 -- iter: 128/313
[A[ATraining Step: 25  | total loss: [1m[32m0.69230[0m[0m | time: 2.847s
[2K
| RMSProp | epoch: 003 | loss: 0.69230 - acc: 0.6242 -- iter: 160/313
[A[ATraining Step: 26  | total loss: [1m[32m0.69212[0m[0m | time: 3.481s
[2K
| RMSProp | epoch: 003 | loss: 0.69212 - acc: 0.6492 -- iter: 192/313
[A[ATraining Step: 27  | total loss: [1m[32m0.69233[0m[0m | time: 4.098s
[2K
| RMSProp | epoch: 003 | loss: 0.69233 - acc: 0.6189 -- iter: 224/313
[A[ATraining Step: 28  | total loss: [1m[32m0.69241[0m[0m | time: 4.696s
[2K
| RMSProp | epoch: 003 | loss: 0.69241 - acc: 0.6048 -- iter: 256/313
[A[ATraining Step: 29  | total loss: [1m[32m0.69218[0m[0m | time: 5.298s
[2K
| RMSProp | epoch: 003 | loss: 0.69218 - acc: 0.6173 -- iter: 288/313
[A[ATraining Step: 30  | total loss: [1m[32m0.69194[0m[0m | time: 6.933s
[2K
| RMSProp | epoch: 003 | loss: 0.69194 - acc: 0.6339 | val_loss: 0.69308 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 31  | total loss: [1m[32m0.69208[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 004 | loss: 0.69208 - acc: 0.6102 -- iter: 032/313
[A[ATraining Step: 32  | total loss: [1m[32m0.69227[0m[0m | time: 1.121s
[2K
| RMSProp | epoch: 004 | loss: 0.69227 - acc: 0.5925 -- iter: 064/313
[A[ATraining Step: 33  | total loss: [1m[32m0.69234[0m[0m | time: 1.608s
[2K
| RMSProp | epoch: 004 | loss: 0.69234 - acc: 0.5766 -- iter: 096/313
[A[ATraining Step: 34  | total loss: [1m[32m0.69211[0m[0m | time: 2.207s
[2K
| RMSProp | epoch: 004 | loss: 0.69211 - acc: 0.5902 -- iter: 128/313
[A[ATraining Step: 35  | total loss: [1m[32m0.69215[0m[0m | time: 2.821s
[2K
| RMSProp | epoch: 004 | loss: 0.69215 - acc: 0.5844 -- iter: 160/313
[A[ATraining Step: 36  | total loss: [1m[32m0.69213[0m[0m | time: 3.424s
[2K
| RMSProp | epoch: 004 | loss: 0.69213 - acc: 0.5863 -- iter: 192/313
[A[ATraining Step: 37  | total loss: [1m[32m0.69219[0m[0m | time: 4.043s
[2K
| RMSProp | epoch: 004 | loss: 0.69219 - acc: 0.5815 -- iter: 224/313
[A[ATraining Step: 38  | total loss: [1m[32m0.69220[0m[0m | time: 4.641s
[2K
| RMSProp | epoch: 004 | loss: 0.69220 - acc: 0.5778 -- iter: 256/313
[A[ATraining Step: 39  | total loss: [1m[32m0.69209[0m[0m | time: 5.233s
[2K
| RMSProp | epoch: 004 | loss: 0.69209 - acc: 0.5809 -- iter: 288/313
[A[ATraining Step: 40  | total loss: [1m[32m0.69195[0m[0m | time: 6.837s
[2K
| RMSProp | epoch: 004 | loss: 0.69195 - acc: 0.5891 | val_loss: 0.69307 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 41  | total loss: [1m[32m0.69167[0m[0m | time: 0.606s
[2K
| RMSProp | epoch: 005 | loss: 0.69167 - acc: 0.6072 -- iter: 032/313
[A[ATraining Step: 42  | total loss: [1m[32m0.69167[0m[0m | time: 1.238s
[2K
| RMSProp | epoch: 005 | loss: 0.69167 - acc: 0.6048 -- iter: 064/313
[A[ATraining Step: 43  | total loss: [1m[32m0.69125[0m[0m | time: 1.746s
[2K
| RMSProp | epoch: 005 | loss: 0.69125 - acc: 0.6249 -- iter: 096/313
[A[ATraining Step: 44  | total loss: [1m[32m0.69112[0m[0m | time: 2.274s
[2K
| RMSProp | epoch: 005 | loss: 0.69112 - acc: 0.6275 -- iter: 128/313
[A[ATraining Step: 45  | total loss: [1m[32m0.69098[0m[0m | time: 2.890s
[2K
| RMSProp | epoch: 005 | loss: 0.69098 - acc: 0.6296 -- iter: 160/313
[A[ATraining Step: 46  | total loss: [1m[32m0.69076[0m[0m | time: 3.508s
[2K
| RMSProp | epoch: 005 | loss: 0.69076 - acc: 0.6341 -- iter: 192/313
[A[ATraining Step: 47  | total loss: [1m[32m0.69150[0m[0m | time: 4.137s
[2K
| RMSProp | epoch: 005 | loss: 0.69150 - acc: 0.5968 -- iter: 224/313
[A[ATraining Step: 48  | total loss: [1m[32m0.69170[0m[0m | time: 4.751s
[2K
| RMSProp | epoch: 005 | loss: 0.69170 - acc: 0.5863 -- iter: 256/313
[A[ATraining Step: 49  | total loss: [1m[32m0.69106[0m[0m | time: 5.367s
[2K
| RMSProp | epoch: 005 | loss: 0.69106 - acc: 0.6121 -- iter: 288/313
[A[ATraining Step: 50  | total loss: [1m[32m0.69109[0m[0m | time: 6.990s
[2K
| RMSProp | epoch: 005 | loss: 0.69109 - acc: 0.6093 | val_loss: 0.69308 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 51  | total loss: [1m[32m0.69092[0m[0m | time: 0.618s
[2K
| RMSProp | epoch: 006 | loss: 0.69092 - acc: 0.6117 -- iter: 032/313
[A[ATraining Step: 52  | total loss: [1m[32m0.69033[0m[0m | time: 1.220s
[2K
| RMSProp | epoch: 006 | loss: 0.69033 - acc: 0.6324 -- iter: 064/313
[A[ATraining Step: 53  | total loss: [1m[32m0.68998[0m[0m | time: 1.829s
[2K
| RMSProp | epoch: 006 | loss: 0.68998 - acc: 0.6405 -- iter: 096/313
[A[ATraining Step: 54  | total loss: [1m[32m0.69045[0m[0m | time: 2.321s
[2K
| RMSProp | epoch: 006 | loss: 0.69045 - acc: 0.6201 -- iter: 128/313
[A[ATraining Step: 55  | total loss: [1m[32m0.69024[0m[0m | time: 2.833s
[2K
| RMSProp | epoch: 006 | loss: 0.69024 - acc: 0.6230 -- iter: 160/313
[A[ATraining Step: 56  | total loss: [1m[32m0.68957[0m[0m | time: 3.439s
[2K
| RMSProp | epoch: 006 | loss: 0.68957 - acc: 0.6366 -- iter: 192/313
[A[ATraining Step: 57  | total loss: [1m[32m0.68903[0m[0m | time: 4.056s
[2K
| RMSProp | epoch: 006 | loss: 0.68903 - acc: 0.6480 -- iter: 224/313
[A[ATraining Step: 58  | total loss: [1m[32m0.68882[0m[0m | time: 4.692s
[2K
| RMSProp | epoch: 006 | loss: 0.68882 - acc: 0.6491 -- iter: 256/313
[A[ATraining Step: 59  | total loss: [1m[32m0.68896[0m[0m | time: 5.304s
[2K
| RMSProp | epoch: 006 | loss: 0.68896 - acc: 0.6417 -- iter: 288/313
[A[ATraining Step: 60  | total loss: [1m[32m0.68900[0m[0m | time: 7.297s
[2K
| RMSProp | epoch: 006 | loss: 0.68900 - acc: 0.6353 | val_loss: 0.69312 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 61  | total loss: [1m[32m0.68953[0m[0m | time: 1.976s
[2K
| RMSProp | epoch: 007 | loss: 0.68953 - acc: 0.6177 -- iter: 032/313
[A[ATraining Step: 62  | total loss: [1m[32m0.68905[0m[0m | time: 2.954s
[2K
| RMSProp | epoch: 007 | loss: 0.68905 - acc: 0.6267 -- iter: 064/313
[A[ATraining Step: 63  | total loss: [1m[32m0.68877[0m[0m | time: 3.952s
[2K
| RMSProp | epoch: 007 | loss: 0.68877 - acc: 0.6304 -- iter: 096/313
[A[ATraining Step: 64  | total loss: [1m[32m0.68952[0m[0m | time: 4.885s
[2K
| RMSProp | epoch: 007 | loss: 0.68952 - acc: 0.6102 -- iter: 128/313
[A[ATraining Step: 65  | total loss: [1m[32m0.68967[0m[0m | time: 5.748s
[2K
| RMSProp | epoch: 007 | loss: 0.68967 - acc: 0.6043 -- iter: 160/313
[A[ATraining Step: 66  | total loss: [1m[32m0.68896[0m[0m | time: 6.691s
[2K
| RMSProp | epoch: 007 | loss: 0.68896 - acc: 0.6184 -- iter: 192/313
[A[ATraining Step: 67  | total loss: [1m[32m0.68866[0m[0m | time: 7.571s
[2K
| RMSProp | epoch: 007 | loss: 0.68866 - acc: 0.6210 -- iter: 224/313
[A[ATraining Step: 68  | total loss: [1m[32m0.68905[0m[0m | time: 8.504s
[2K
| RMSProp | epoch: 007 | loss: 0.68905 - acc: 0.6104 -- iter: 256/313
[A[ATraining Step: 69  | total loss: [1m[32m0.68896[0m[0m | time: 9.650s
[2K
| RMSProp | epoch: 007 | loss: 0.68896 - acc: 0.6084 -- iter: 288/313
[A[ATraining Step: 70  | total loss: [1m[32m0.68912[0m[0m | time: 12.010s
[2K
| RMSProp | epoch: 007 | loss: 0.68912 - acc: 0.6031 | val_loss: 0.69321 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 71  | total loss: [1m[32m0.68892[0m[0m | time: 0.904s
[2K
| RMSProp | epoch: 008 | loss: 0.68892 - acc: 0.6056 -- iter: 032/313
[A[ATraining Step: 72  | total loss: [1m[32m0.68835[0m[0m | time: 1.998s
[2K
| RMSProp | epoch: 008 | loss: 0.68835 - acc: 0.6148 -- iter: 064/313
[A[ATraining Step: 73  | total loss: [1m[32m0.68834[0m[0m | time: 3.042s
[2K
| RMSProp | epoch: 008 | loss: 0.68834 - acc: 0.6125 -- iter: 096/313
[A[ATraining Step: 74  | total loss: [1m[32m0.68793[0m[0m | time: 3.914s
[2K
| RMSProp | epoch: 008 | loss: 0.68793 - acc: 0.6173 -- iter: 128/313
[A[ATraining Step: 75  | total loss: [1m[32m0.68733[0m[0m | time: 5.034s
[2K
| RMSProp | epoch: 008 | loss: 0.68733 - acc: 0.6249 -- iter: 160/313
[A[ATraining Step: 76  | total loss: [1m[32m0.68756[0m[0m | time: 6.091s
[2K
| RMSProp | epoch: 008 | loss: 0.68756 - acc: 0.6182 -- iter: 192/313
[A[ATraining Step: 77  | total loss: [1m[32m0.68729[0m[0m | time: 7.111s
[2K
| RMSProp | epoch: 008 | loss: 0.68729 - acc: 0.6205 -- iter: 224/313
[A[ATraining Step: 78  | total loss: [1m[32m0.68700[0m[0m | time: 7.974s
[2K
| RMSProp | epoch: 008 | loss: 0.68700 - acc: 0.6226 -- iter: 256/313
[A[ATraining Step: 79  | total loss: [1m[32m0.68590[0m[0m | time: 8.919s
[2K
| RMSProp | epoch: 008 | loss: 0.68590 - acc: 0.6357 -- iter: 288/313
[A[ATraining Step: 80  | total loss: [1m[32m0.68668[0m[0m | time: 10.910s
[2K
| RMSProp | epoch: 008 | loss: 0.68668 - acc: 0.6219 | val_loss: 0.69346 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 81  | total loss: [1m[32m0.68668[0m[0m | time: 1.054s
[2K
| RMSProp | epoch: 009 | loss: 0.68668 - acc: 0.6190 -- iter: 032/313
[A[ATraining Step: 82  | total loss: [1m[32m0.68695[0m[0m | time: 1.949s
[2K
| RMSProp | epoch: 009 | loss: 0.68695 - acc: 0.6134 -- iter: 064/313
[A[ATraining Step: 83  | total loss: [1m[32m0.68691[0m[0m | time: 3.079s
[2K
| RMSProp | epoch: 009 | loss: 0.68691 - acc: 0.6114 -- iter: 096/313
[A[ATraining Step: 84  | total loss: [1m[32m0.68712[0m[0m | time: 4.225s
[2K
| RMSProp | epoch: 009 | loss: 0.68712 - acc: 0.6065 -- iter: 128/313
[A[ATraining Step: 85  | total loss: [1m[32m0.68658[0m[0m | time: 5.564s
[2K
| RMSProp | epoch: 009 | loss: 0.68658 - acc: 0.6115 -- iter: 160/313
[A[ATraining Step: 86  | total loss: [1m[32m0.68685[0m[0m | time: 7.316s
[2K
| RMSProp | epoch: 009 | loss: 0.68685 - acc: 0.6066 -- iter: 192/313
[A[ATraining Step: 87  | total loss: [1m[32m0.68572[0m[0m | time: 8.047s
[2K
| RMSProp | epoch: 009 | loss: 0.68572 - acc: 0.6178 -- iter: 224/313
[A[ATraining Step: 88  | total loss: [1m[32m0.68528[0m[0m | time: 8.794s
[2K
| RMSProp | epoch: 009 | loss: 0.68528 - acc: 0.6200 -- iter: 256/313
[A[ATraining Step: 89  | total loss: [1m[32m0.68518[0m[0m | time: 9.784s
[2K
| RMSProp | epoch: 009 | loss: 0.68518 - acc: 0.6180 -- iter: 288/313
[A[ATraining Step: 90  | total loss: [1m[32m0.68458[0m[0m | time: 11.778s
[2K
| RMSProp | epoch: 009 | loss: 0.68458 - acc: 0.6218 | val_loss: 0.69398 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 91  | total loss: [1m[32m0.68432[0m[0m | time: 1.035s
[2K
| RMSProp | epoch: 010 | loss: 0.68432 - acc: 0.6222 -- iter: 032/313
[A[ATraining Step: 92  | total loss: [1m[32m0.68465[0m[0m | time: 2.125s
[2K
| RMSProp | epoch: 010 | loss: 0.68465 - acc: 0.6162 -- iter: 064/313
[A[ATraining Step: 93  | total loss: [1m[32m0.68597[0m[0m | time: 3.021s
[2K
| RMSProp | epoch: 010 | loss: 0.68597 - acc: 0.6014 -- iter: 096/313
[A[ATraining Step: 94  | total loss: [1m[32m0.68618[0m[0m | time: 3.925s
[2K
| RMSProp | epoch: 010 | loss: 0.68618 - acc: 0.5976 -- iter: 128/313
[A[ATraining Step: 95  | total loss: [1m[32m0.68435[0m[0m | time: 4.780s
[2K
| RMSProp | epoch: 010 | loss: 0.68435 - acc: 0.6128 -- iter: 160/313
[A[ATraining Step: 96  | total loss: [1m[32m0.68505[0m[0m | time: 5.752s
[2K
| RMSProp | epoch: 010 | loss: 0.68505 - acc: 0.6046 -- iter: 192/313
[A[ATraining Step: 97  | total loss: [1m[32m0.68345[0m[0m | time: 6.729s
[2K
| RMSProp | epoch: 010 | loss: 0.68345 - acc: 0.6161 -- iter: 224/313
[A[ATraining Step: 98  | total loss: [1m[32m0.68262[0m[0m | time: 7.526s
[2K
| RMSProp | epoch: 010 | loss: 0.68262 - acc: 0.6201 -- iter: 256/313
[A[ATraining Step: 99  | total loss: [1m[32m0.68251[0m[0m | time: 8.348s
[2K
| RMSProp | epoch: 010 | loss: 0.68251 - acc: 0.6181 -- iter: 288/313
[A[ATraining Step: 100  | total loss: [1m[32m0.68187[0m[0m | time: 10.509s
[2K
| RMSProp | epoch: 010 | loss: 0.68187 - acc: 0.6203 | val_loss: 0.69544 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 101  | total loss: [1m[32m0.68048[0m[0m | time: 1.049s
[2K
| RMSProp | epoch: 011 | loss: 0.68048 - acc: 0.6270 -- iter: 032/313
[A[ATraining Step: 102  | total loss: [1m[32m0.68004[0m[0m | time: 1.935s
[2K
| RMSProp | epoch: 011 | loss: 0.68004 - acc: 0.6268 -- iter: 064/313
[A[ATraining Step: 103  | total loss: [1m[32m0.67850[0m[0m | time: 2.932s
[2K
| RMSProp | epoch: 011 | loss: 0.67850 - acc: 0.6329 -- iter: 096/313
[A[ATraining Step: 104  | total loss: [1m[32m0.67980[0m[0m | time: 4.001s
[2K
| RMSProp | epoch: 011 | loss: 0.67980 - acc: 0.6227 -- iter: 128/313
[A[ATraining Step: 105  | total loss: [1m[32m0.68034[0m[0m | time: 4.942s
[2K
| RMSProp | epoch: 011 | loss: 0.68034 - acc: 0.6167 -- iter: 160/313
[A[ATraining Step: 106  | total loss: [1m[32m0.67917[0m[0m | time: 5.556s
[2K
| RMSProp | epoch: 011 | loss: 0.67917 - acc: 0.6206 -- iter: 192/313
[A[ATraining Step: 107  | total loss: [1m[32m0.67783[0m[0m | time: 6.212s
[2K
| RMSProp | epoch: 011 | loss: 0.67783 - acc: 0.6242 -- iter: 224/313
[A[ATraining Step: 108  | total loss: [1m[32m0.67931[0m[0m | time: 6.805s
[2K
| RMSProp | epoch: 011 | loss: 0.67931 - acc: 0.6149 -- iter: 256/313
[A[ATraining Step: 109  | total loss: [1m[32m0.67987[0m[0m | time: 7.296s
[2K
| RMSProp | epoch: 011 | loss: 0.67987 - acc: 0.6097 -- iter: 288/313
[A[ATraining Step: 110  | total loss: [1m[32m0.67863[0m[0m | time: 8.801s
[2K
| RMSProp | epoch: 011 | loss: 0.67863 - acc: 0.6127 | val_loss: 0.69985 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 111  | total loss: [1m[32m0.67849[0m[0m | time: 0.626s
[2K
| RMSProp | epoch: 012 | loss: 0.67849 - acc: 0.6114 -- iter: 032/313
[A[ATraining Step: 112  | total loss: [1m[32m0.67670[0m[0m | time: 1.243s
[2K
| RMSProp | epoch: 012 | loss: 0.67670 - acc: 0.6159 -- iter: 064/313
[A[ATraining Step: 113  | total loss: [1m[32m0.67862[0m[0m | time: 1.851s
[2K
| RMSProp | epoch: 012 | loss: 0.67862 - acc: 0.6074 -- iter: 096/313
[A[ATraining Step: 114  | total loss: [1m[32m0.67766[0m[0m | time: 2.470s
[2K
| RMSProp | epoch: 012 | loss: 0.67766 - acc: 0.6092 -- iter: 128/313
[A[ATraining Step: 115  | total loss: [1m[32m0.67635[0m[0m | time: 3.092s
[2K
| RMSProp | epoch: 012 | loss: 0.67635 - acc: 0.6108 -- iter: 160/313
[A[ATraining Step: 116  | total loss: [1m[32m0.67948[0m[0m | time: 3.743s
[2K
| RMSProp | epoch: 012 | loss: 0.67948 - acc: 0.5997 -- iter: 192/313
[A[ATraining Step: 117  | total loss: [1m[32m0.67583[0m[0m | time: 4.401s
[2K
| RMSProp | epoch: 012 | loss: 0.67583 - acc: 0.6116 -- iter: 224/313
[A[ATraining Step: 118  | total loss: [1m[32m0.66889[0m[0m | time: 5.027s
[2K
| RMSProp | epoch: 012 | loss: 0.66889 - acc: 0.6286 -- iter: 256/313
[A[ATraining Step: 119  | total loss: [1m[32m0.67533[0m[0m | time: 5.662s
[2K
| RMSProp | epoch: 012 | loss: 0.67533 - acc: 0.6157 -- iter: 288/313
[A[ATraining Step: 120  | total loss: [1m[32m0.67546[0m[0m | time: 7.190s
[2K
| RMSProp | epoch: 012 | loss: 0.67546 - acc: 0.6135 | val_loss: 0.70699 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 121  | total loss: [1m[32m0.67531[0m[0m | time: 0.520s
[2K
| RMSProp | epoch: 013 | loss: 0.67531 - acc: 0.6122 -- iter: 032/313
[A[ATraining Step: 122  | total loss: [1m[32m0.67931[0m[0m | time: 1.126s
[2K
| RMSProp | epoch: 013 | loss: 0.67931 - acc: 0.5989 -- iter: 064/313
[A[ATraining Step: 123  | total loss: [1m[32m0.67881[0m[0m | time: 1.724s
[2K
| RMSProp | epoch: 013 | loss: 0.67881 - acc: 0.5984 -- iter: 096/313
[A[ATraining Step: 124  | total loss: [1m[32m0.67383[0m[0m | time: 2.320s
[2K
| RMSProp | epoch: 013 | loss: 0.67383 - acc: 0.6136 -- iter: 128/313
[A[ATraining Step: 125  | total loss: [1m[32m0.67117[0m[0m | time: 3.002s
[2K
| RMSProp | epoch: 013 | loss: 0.67117 - acc: 0.6179 -- iter: 160/313
[A[ATraining Step: 126  | total loss: [1m[32m0.67527[0m[0m | time: 4.086s
[2K
| RMSProp | epoch: 013 | loss: 0.67527 - acc: 0.6092 -- iter: 192/313
[A[ATraining Step: 127  | total loss: [1m[32m0.67511[0m[0m | time: 5.229s
[2K
| RMSProp | epoch: 013 | loss: 0.67511 - acc: 0.6076 -- iter: 224/313
[A[ATraining Step: 128  | total loss: [1m[32m0.67510[0m[0m | time: 6.606s
[2K
| RMSProp | epoch: 013 | loss: 0.67510 - acc: 0.6063 -- iter: 256/313
[A[ATraining Step: 129  | total loss: [1m[32m0.67161[0m[0m | time: 7.783s
[2K
| RMSProp | epoch: 013 | loss: 0.67161 - acc: 0.6144 -- iter: 288/313
[A[ATraining Step: 130  | total loss: [1m[32m0.66440[0m[0m | time: 9.698s
[2K
| RMSProp | epoch: 013 | loss: 0.66440 - acc: 0.6279 | val_loss: 0.70145 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 131  | total loss: [1m[32m0.67804[0m[0m | time: 0.923s
[2K
| RMSProp | epoch: 014 | loss: 0.67804 - acc: 0.6120 -- iter: 032/313
[A[ATraining Step: 132  | total loss: [1m[32m0.68095[0m[0m | time: 1.586s
[2K
| RMSProp | epoch: 014 | loss: 0.68095 - acc: 0.5988 -- iter: 064/313
[A[ATraining Step: 133  | total loss: [1m[32m0.67734[0m[0m | time: 2.528s
[2K
| RMSProp | epoch: 014 | loss: 0.67734 - acc: 0.6109 -- iter: 096/313
[A[ATraining Step: 134  | total loss: [1m[32m0.67720[0m[0m | time: 3.797s
[2K
| RMSProp | epoch: 014 | loss: 0.67720 - acc: 0.6092 -- iter: 128/313
[A[ATraining Step: 135  | total loss: [1m[32m0.67601[0m[0m | time: 5.129s
[2K
| RMSProp | epoch: 014 | loss: 0.67601 - acc: 0.6108 -- iter: 160/313
[A[ATraining Step: 136  | total loss: [1m[32m0.67279[0m[0m | time: 6.371s
[2K
| RMSProp | epoch: 014 | loss: 0.67279 - acc: 0.6185 -- iter: 192/313
[A[ATraining Step: 137  | total loss: [1m[32m0.67017[0m[0m | time: 7.247s
[2K
| RMSProp | epoch: 014 | loss: 0.67017 - acc: 0.6222 -- iter: 224/313
[A[ATraining Step: 138  | total loss: [1m[32m0.67054[0m[0m | time: 8.160s
[2K
| RMSProp | epoch: 014 | loss: 0.67054 - acc: 0.6194 -- iter: 256/313
[A[ATraining Step: 139  | total loss: [1m[32m0.67132[0m[0m | time: 9.170s
[2K
| RMSProp | epoch: 014 | loss: 0.67132 - acc: 0.6168 -- iter: 288/313
[A[ATraining Step: 140  | total loss: [1m[32m0.67032[0m[0m | time: 11.133s
[2K
| RMSProp | epoch: 014 | loss: 0.67032 - acc: 0.6176 | val_loss: 0.70950 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 141  | total loss: [1m[32m0.67202[0m[0m | time: 0.964s
[2K
| RMSProp | epoch: 015 | loss: 0.67202 - acc: 0.6121 -- iter: 032/313
[A[ATraining Step: 142  | total loss: [1m[32m0.67576[0m[0m | time: 1.724s
[2K
| RMSProp | epoch: 015 | loss: 0.67576 - acc: 0.6009 -- iter: 064/313
[A[ATraining Step: 143  | total loss: [1m[32m0.67205[0m[0m | time: 2.519s
[2K
| RMSProp | epoch: 015 | loss: 0.67205 - acc: 0.6128 -- iter: 096/313
[A[ATraining Step: 144  | total loss: [1m[32m0.68230[0m[0m | time: 3.451s
[2K
| RMSProp | epoch: 015 | loss: 0.68230 - acc: 0.5875 -- iter: 128/313
[A[ATraining Step: 145  | total loss: [1m[32m0.68328[0m[0m | time: 4.648s
[2K
| RMSProp | epoch: 015 | loss: 0.68328 - acc: 0.5819 -- iter: 160/313
[A[ATraining Step: 146  | total loss: [1m[32m0.68159[0m[0m | time: 5.623s
[2K
| RMSProp | epoch: 015 | loss: 0.68159 - acc: 0.5893 -- iter: 192/313
[A[ATraining Step: 147  | total loss: [1m[32m0.67983[0m[0m | time: 6.549s
[2K
| RMSProp | epoch: 015 | loss: 0.67983 - acc: 0.5960 -- iter: 224/313
[A[ATraining Step: 148  | total loss: [1m[32m0.67542[0m[0m | time: 7.727s
[2K
| RMSProp | epoch: 015 | loss: 0.67542 - acc: 0.6114 -- iter: 256/313
[A[ATraining Step: 149  | total loss: [1m[32m0.68229[0m[0m | time: 9.045s
[2K
| RMSProp | epoch: 015 | loss: 0.68229 - acc: 0.5909 -- iter: 288/313
[A[ATraining Step: 150  | total loss: [1m[32m0.68254[0m[0m | time: 11.338s
[2K
| RMSProp | epoch: 015 | loss: 0.68254 - acc: 0.5881 | val_loss: 0.70437 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 151  | total loss: [1m[32m0.67717[0m[0m | time: 1.015s
[2K
| RMSProp | epoch: 016 | loss: 0.67717 - acc: 0.6105 -- iter: 032/313
[A[ATraining Step: 152  | total loss: [1m[32m0.67380[0m[0m | time: 1.982s
[2K
| RMSProp | epoch: 016 | loss: 0.67380 - acc: 0.6182 -- iter: 064/313
[A[ATraining Step: 153  | total loss: [1m[32m0.67133[0m[0m | time: 2.934s
[2K
| RMSProp | epoch: 016 | loss: 0.67133 - acc: 0.6220 -- iter: 096/313
[A[ATraining Step: 154  | total loss: [1m[32m0.68375[0m[0m | time: 3.781s
[2K
| RMSProp | epoch: 016 | loss: 0.68375 - acc: 0.5958 -- iter: 128/313
[A[ATraining Step: 155  | total loss: [1m[32m0.68126[0m[0m | time: 4.598s
[2K
| RMSProp | epoch: 016 | loss: 0.68126 - acc: 0.6042 -- iter: 160/313
[A[ATraining Step: 156  | total loss: [1m[32m0.67924[0m[0m | time: 5.812s
[2K
| RMSProp | epoch: 016 | loss: 0.67924 - acc: 0.6094 -- iter: 192/313
[A[ATraining Step: 157  | total loss: [1m[32m0.67886[0m[0m | time: 7.092s
[2K
| RMSProp | epoch: 016 | loss: 0.67886 - acc: 0.6079 -- iter: 224/313
[A[ATraining Step: 158  | total loss: [1m[32m0.67575[0m[0m | time: 8.357s
[2K
| RMSProp | epoch: 016 | loss: 0.67575 - acc: 0.6158 -- iter: 256/313
[A[ATraining Step: 159  | total loss: [1m[32m0.67360[0m[0m | time: 9.443s
[2K
| RMSProp | epoch: 016 | loss: 0.67360 - acc: 0.6199 -- iter: 288/313
[A[ATraining Step: 160  | total loss: [1m[32m0.67253[0m[0m | time: 11.417s
[2K
| RMSProp | epoch: 016 | loss: 0.67253 - acc: 0.6204 | val_loss: 0.70771 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 161  | total loss: [1m[32m0.67435[0m[0m | time: 1.116s
[2K
| RMSProp | epoch: 017 | loss: 0.67435 - acc: 0.6146 -- iter: 032/313
[A[ATraining Step: 162  | total loss: [1m[32m0.67782[0m[0m | time: 2.161s
[2K
| RMSProp | epoch: 017 | loss: 0.67782 - acc: 0.6031 -- iter: 064/313
[A[ATraining Step: 163  | total loss: [1m[32m0.67860[0m[0m | time: 3.061s
[2K
| RMSProp | epoch: 017 | loss: 0.67860 - acc: 0.5991 -- iter: 096/313
[A[ATraining Step: 164  | total loss: [1m[32m0.67749[0m[0m | time: 3.968s
[2K
| RMSProp | epoch: 017 | loss: 0.67749 - acc: 0.6017 -- iter: 128/313
[A[ATraining Step: 165  | total loss: [1m[32m0.67457[0m[0m | time: 5.025s
[2K
| RMSProp | epoch: 017 | loss: 0.67457 - acc: 0.6095 -- iter: 160/313
[A[ATraining Step: 166  | total loss: [1m[32m0.67772[0m[0m | time: 5.857s
[2K
| RMSProp | epoch: 017 | loss: 0.67772 - acc: 0.6005 -- iter: 192/313
[A[ATraining Step: 167  | total loss: [1m[32m0.67743[0m[0m | time: 6.844s
[2K
| RMSProp | epoch: 017 | loss: 0.67743 - acc: 0.5999 -- iter: 224/313
[A[ATraining Step: 168  | total loss: [1m[32m0.67909[0m[0m | time: 7.741s
[2K
| RMSProp | epoch: 017 | loss: 0.67909 - acc: 0.5930 -- iter: 256/313
[A[ATraining Step: 169  | total loss: [1m[32m0.67591[0m[0m | time: 8.765s
[2K
| RMSProp | epoch: 017 | loss: 0.67591 - acc: 0.6025 -- iter: 288/313
[A[ATraining Step: 170  | total loss: [1m[32m0.67929[0m[0m | time: 10.673s
[2K
| RMSProp | epoch: 017 | loss: 0.67929 - acc: 0.5922 | val_loss: 0.69972 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 171  | total loss: [1m[32m0.68079[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 018 | loss: 0.68079 - acc: 0.5861 -- iter: 032/313
[A[ATraining Step: 172  | total loss: [1m[32m0.67721[0m[0m | time: 1.241s
[2K
| RMSProp | epoch: 018 | loss: 0.67721 - acc: 0.5994 -- iter: 064/313
[A[ATraining Step: 173  | total loss: [1m[32m0.67155[0m[0m | time: 1.849s
[2K
| RMSProp | epoch: 018 | loss: 0.67155 - acc: 0.6144 -- iter: 096/313
[A[ATraining Step: 174  | total loss: [1m[32m0.67008[0m[0m | time: 2.472s
[2K
| RMSProp | epoch: 018 | loss: 0.67008 - acc: 0.6155 -- iter: 128/313
[A[ATraining Step: 175  | total loss: [1m[32m0.66764[0m[0m | time: 2.963s
[2K
| RMSProp | epoch: 018 | loss: 0.66764 - acc: 0.6196 -- iter: 160/313
[A[ATraining Step: 176  | total loss: [1m[32m0.67361[0m[0m | time: 3.465s
[2K
| RMSProp | epoch: 018 | loss: 0.67361 - acc: 0.6096 -- iter: 192/313
[A[ATraining Step: 177  | total loss: [1m[32m0.67470[0m[0m | time: 4.098s
[2K
| RMSProp | epoch: 018 | loss: 0.67470 - acc: 0.6047 -- iter: 224/313
[A[ATraining Step: 178  | total loss: [1m[32m0.67207[0m[0m | time: 4.703s
[2K
| RMSProp | epoch: 018 | loss: 0.67207 - acc: 0.6129 -- iter: 256/313
[A[ATraining Step: 179  | total loss: [1m[32m0.67562[0m[0m | time: 5.302s
[2K
| RMSProp | epoch: 018 | loss: 0.67562 - acc: 0.6016 -- iter: 288/313
[A[ATraining Step: 180  | total loss: [1m[32m0.67731[0m[0m | time: 6.909s
[2K
| RMSProp | epoch: 018 | loss: 0.67731 - acc: 0.5946 | val_loss: 0.70715 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 181  | total loss: [1m[32m0.67382[0m[0m | time: 0.620s
[2K
| RMSProp | epoch: 019 | loss: 0.67382 - acc: 0.6070 -- iter: 032/313
[A[ATraining Step: 182  | total loss: [1m[32m0.67618[0m[0m | time: 1.229s
[2K
| RMSProp | epoch: 019 | loss: 0.67618 - acc: 0.5994 -- iter: 064/313
[A[ATraining Step: 183  | total loss: [1m[32m0.67610[0m[0m | time: 1.842s
[2K
| RMSProp | epoch: 019 | loss: 0.67610 - acc: 0.5989 -- iter: 096/313
[A[ATraining Step: 184  | total loss: [1m[32m0.66866[0m[0m | time: 2.488s
[2K
| RMSProp | epoch: 019 | loss: 0.66866 - acc: 0.6202 -- iter: 128/313
[A[ATraining Step: 185  | total loss: [1m[32m0.66937[0m[0m | time: 3.143s
[2K
| RMSProp | epoch: 019 | loss: 0.66937 - acc: 0.6176 -- iter: 160/313
[A[ATraining Step: 186  | total loss: [1m[32m0.66998[0m[0m | time: 3.629s
[2K
| RMSProp | epoch: 019 | loss: 0.66998 - acc: 0.6152 -- iter: 192/313
[A[ATraining Step: 187  | total loss: [1m[32m0.67164[0m[0m | time: 4.123s
[2K
| RMSProp | epoch: 019 | loss: 0.67164 - acc: 0.6097 -- iter: 224/313
[A[ATraining Step: 188  | total loss: [1m[32m0.67457[0m[0m | time: 4.732s
[2K
| RMSProp | epoch: 019 | loss: 0.67457 - acc: 0.6007 -- iter: 256/313
[A[ATraining Step: 189  | total loss: [1m[32m0.67638[0m[0m | time: 5.356s
[2K
| RMSProp | epoch: 019 | loss: 0.67638 - acc: 0.5938 -- iter: 288/313
[A[ATraining Step: 190  | total loss: [1m[32m0.67304[0m[0m | time: 6.963s
[2K
| RMSProp | epoch: 019 | loss: 0.67304 - acc: 0.6063 | val_loss: 0.76556 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 191  | total loss: [1m[32m0.66686[0m[0m | time: 0.664s
[2K
| RMSProp | epoch: 020 | loss: 0.66686 - acc: 0.6206 -- iter: 032/313
[A[ATraining Step: 192  | total loss: [1m[32m0.67654[0m[0m | time: 1.481s
[2K
| RMSProp | epoch: 020 | loss: 0.67654 - acc: 0.6086 -- iter: 064/313
[A[ATraining Step: 193  | total loss: [1m[32m0.67571[0m[0m | time: 2.560s
[2K
| RMSProp | epoch: 020 | loss: 0.67571 - acc: 0.6102 -- iter: 096/313
[A[ATraining Step: 194  | total loss: [1m[32m0.67368[0m[0m | time: 3.767s
[2K
| RMSProp | epoch: 020 | loss: 0.67368 - acc: 0.6148 -- iter: 128/313
[A[ATraining Step: 195  | total loss: [1m[32m0.67561[0m[0m | time: 4.629s
[2K
| RMSProp | epoch: 020 | loss: 0.67561 - acc: 0.6065 -- iter: 160/313
[A[ATraining Step: 196  | total loss: [1m[32m0.67643[0m[0m | time: 5.588s
[2K
| RMSProp | epoch: 020 | loss: 0.67643 - acc: 0.6021 -- iter: 192/313
[A[ATraining Step: 197  | total loss: [1m[32m0.67227[0m[0m | time: 6.332s
[2K
| RMSProp | epoch: 020 | loss: 0.67227 - acc: 0.6137 -- iter: 224/313
[A[ATraining Step: 198  | total loss: [1m[32m0.67563[0m[0m | time: 7.149s
[2K
| RMSProp | epoch: 020 | loss: 0.67563 - acc: 0.6044 -- iter: 256/313
[A[ATraining Step: 199  | total loss: [1m[32m0.67145[0m[0m | time: 8.033s
[2K
| RMSProp | epoch: 020 | loss: 0.67145 - acc: 0.6159 -- iter: 288/313
[A[ATraining Step: 200  | total loss: [1m[32m0.67170[0m[0m | time: 10.245s
[2K
| RMSProp | epoch: 020 | loss: 0.67170 - acc: 0.6137 | val_loss: 0.70338 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 201  | total loss: [1m[32m0.67535[0m[0m | time: 0.859s
[2K
| RMSProp | epoch: 021 | loss: 0.67535 - acc: 0.6023 -- iter: 032/313
[A[ATraining Step: 202  | total loss: [1m[32m0.67312[0m[0m | time: 1.823s
[2K
| RMSProp | epoch: 021 | loss: 0.67312 - acc: 0.6077 -- iter: 064/313
[A[ATraining Step: 203  | total loss: [1m[32m0.67671[0m[0m | time: 2.754s
[2K
| RMSProp | epoch: 021 | loss: 0.67671 - acc: 0.5970 -- iter: 096/313
[A[ATraining Step: 204  | total loss: [1m[32m0.67546[0m[0m | time: 3.700s
[2K
| RMSProp | epoch: 021 | loss: 0.67546 - acc: 0.5998 -- iter: 128/313
[A[ATraining Step: 205  | total loss: [1m[32m0.67308[0m[0m | time: 4.792s
[2K
| RMSProp | epoch: 021 | loss: 0.67308 - acc: 0.6054 -- iter: 160/313
[A[ATraining Step: 206  | total loss: [1m[32m0.67282[0m[0m | time: 5.855s
[2K
| RMSProp | epoch: 021 | loss: 0.67282 - acc: 0.6042 -- iter: 192/313
[A[ATraining Step: 207  | total loss: [1m[32m0.66749[0m[0m | time: 6.720s
[2K
| RMSProp | epoch: 021 | loss: 0.66749 - acc: 0.6157 -- iter: 224/313
[A[ATraining Step: 208  | total loss: [1m[32m0.66855[0m[0m | time: 7.590s
[2K
| RMSProp | epoch: 021 | loss: 0.66855 - acc: 0.6135 -- iter: 256/313
[A[ATraining Step: 209  | total loss: [1m[32m0.66357[0m[0m | time: 8.574s
[2K
| RMSProp | epoch: 021 | loss: 0.66357 - acc: 0.6241 -- iter: 288/313
[A[ATraining Step: 210  | total loss: [1m[32m0.66710[0m[0m | time: 10.888s
[2K
| RMSProp | epoch: 021 | loss: 0.66710 - acc: 0.6177 | val_loss: 0.70674 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 211  | total loss: [1m[32m0.66780[0m[0m | time: 0.990s
[2K
| RMSProp | epoch: 022 | loss: 0.66780 - acc: 0.6153 -- iter: 032/313
[A[ATraining Step: 212  | total loss: [1m[32m0.66704[0m[0m | time: 1.959s
[2K
| RMSProp | epoch: 022 | loss: 0.66704 - acc: 0.6163 -- iter: 064/313
[A[ATraining Step: 213  | total loss: [1m[32m0.66703[0m[0m | time: 3.161s
[2K
| RMSProp | epoch: 022 | loss: 0.66703 - acc: 0.6140 -- iter: 096/313
[A[ATraining Step: 214  | total loss: [1m[32m0.66574[0m[0m | time: 4.157s
[2K
| RMSProp | epoch: 022 | loss: 0.66574 - acc: 0.6151 -- iter: 128/313
[A[ATraining Step: 215  | total loss: [1m[32m0.66559[0m[0m | time: 5.055s
[2K
| RMSProp | epoch: 022 | loss: 0.66559 - acc: 0.6130 -- iter: 160/313
[A[ATraining Step: 216  | total loss: [1m[32m0.66452[0m[0m | time: 6.198s
[2K
| RMSProp | epoch: 022 | loss: 0.66452 - acc: 0.6142 -- iter: 192/313
[A[ATraining Step: 217  | total loss: [1m[32m0.66536[0m[0m | time: 7.519s
[2K
| RMSProp | epoch: 022 | loss: 0.66536 - acc: 0.6090 -- iter: 224/313
[A[ATraining Step: 218  | total loss: [1m[32m0.66308[0m[0m | time: 8.722s
[2K
| RMSProp | epoch: 022 | loss: 0.66308 - acc: 0.6138 -- iter: 256/313
[A[ATraining Step: 219  | total loss: [1m[32m0.65718[0m[0m | time: 9.445s
[2K
| RMSProp | epoch: 022 | loss: 0.65718 - acc: 0.6211 -- iter: 288/313
[A[ATraining Step: 220  | total loss: [1m[32m0.66473[0m[0m | time: 11.246s
[2K
| RMSProp | epoch: 022 | loss: 0.66473 - acc: 0.6150 | val_loss: 0.69557 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 221  | total loss: [1m[32m0.66727[0m[0m | time: 1.037s
[2K
| RMSProp | epoch: 023 | loss: 0.66727 - acc: 0.6055 -- iter: 032/313
[A[ATraining Step: 222  | total loss: [1m[32m0.66366[0m[0m | time: 1.875s
[2K
| RMSProp | epoch: 023 | loss: 0.66366 - acc: 0.6168 -- iter: 064/313
[A[ATraining Step: 223  | total loss: [1m[32m0.66262[0m[0m | time: 3.056s
[2K
| RMSProp | epoch: 023 | loss: 0.66262 - acc: 0.6145 -- iter: 096/313
[A[ATraining Step: 224  | total loss: [1m[32m0.66143[0m[0m | time: 4.450s
[2K
| RMSProp | epoch: 023 | loss: 0.66143 - acc: 0.6125 -- iter: 128/313
[A[ATraining Step: 225  | total loss: [1m[32m0.65801[0m[0m | time: 5.668s
[2K
| RMSProp | epoch: 023 | loss: 0.65801 - acc: 0.6168 -- iter: 160/313
[A[ATraining Step: 226  | total loss: [1m[32m0.65875[0m[0m | time: 6.529s
[2K
| RMSProp | epoch: 023 | loss: 0.65875 - acc: 0.6083 -- iter: 192/313
[A[ATraining Step: 227  | total loss: [1m[32m0.65788[0m[0m | time: 7.495s
[2K
| RMSProp | epoch: 023 | loss: 0.65788 - acc: 0.6162 -- iter: 224/313
[A[ATraining Step: 228  | total loss: [1m[32m0.65640[0m[0m | time: 8.485s
[2K
| RMSProp | epoch: 023 | loss: 0.65640 - acc: 0.6140 -- iter: 256/313
[A[ATraining Step: 229  | total loss: [1m[32m0.65222[0m[0m | time: 9.485s
[2K
| RMSProp | epoch: 023 | loss: 0.65222 - acc: 0.6119 -- iter: 288/313
[A[ATraining Step: 230  | total loss: [1m[32m0.65421[0m[0m | time: 11.385s
[2K
| RMSProp | epoch: 023 | loss: 0.65421 - acc: 0.6132 | val_loss: 0.68626 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 231  | total loss: [1m[32m0.65691[0m[0m | time: 1.089s
[2K
| RMSProp | epoch: 024 | loss: 0.65691 - acc: 0.6039 -- iter: 032/313
[A[ATraining Step: 232  | total loss: [1m[32m0.65466[0m[0m | time: 2.308s
[2K
| RMSProp | epoch: 024 | loss: 0.65466 - acc: 0.6155 -- iter: 064/313
[A[ATraining Step: 233  | total loss: [1m[32m0.64939[0m[0m | time: 3.567s
[2K
| RMSProp | epoch: 024 | loss: 0.64939 - acc: 0.6196 -- iter: 096/313
[A[ATraining Step: 234  | total loss: [1m[32m0.65089[0m[0m | time: 4.461s
[2K
| RMSProp | epoch: 024 | loss: 0.65089 - acc: 0.6108 -- iter: 128/313
[A[ATraining Step: 235  | total loss: [1m[32m0.65313[0m[0m | time: 5.446s
[2K
| RMSProp | epoch: 024 | loss: 0.65313 - acc: 0.6091 -- iter: 160/313
[A[ATraining Step: 236  | total loss: [1m[32m0.65377[0m[0m | time: 6.446s
[2K
| RMSProp | epoch: 024 | loss: 0.65377 - acc: 0.6107 -- iter: 192/313
[A[ATraining Step: 237  | total loss: [1m[32m0.64750[0m[0m | time: 7.484s
[2K
| RMSProp | epoch: 024 | loss: 0.64750 - acc: 0.6121 -- iter: 224/313
[A[ATraining Step: 238  | total loss: [1m[32m0.64506[0m[0m | time: 8.559s
[2K
| RMSProp | epoch: 024 | loss: 0.64506 - acc: 0.6196 -- iter: 256/313
[A[ATraining Step: 239  | total loss: [1m[32m0.64077[0m[0m | time: 9.435s
[2K
| RMSProp | epoch: 024 | loss: 0.64077 - acc: 0.6202 -- iter: 288/313
[A[ATraining Step: 240  | total loss: [1m[32m0.64283[0m[0m | time: 11.463s
[2K
| RMSProp | epoch: 024 | loss: 0.64283 - acc: 0.6050 | val_loss: 0.70450 - val_acc: 0.5051 -- iter: 313/313
--
Training Step: 241  | total loss: [1m[32m0.64217[0m[0m | time: 0.506s
[2K
| RMSProp | epoch: 025 | loss: 0.64217 - acc: 0.6070 -- iter: 032/313
[A[ATraining Step: 242  | total loss: [1m[32m0.63979[0m[0m | time: 1.019s
[2K
| RMSProp | epoch: 025 | loss: 0.63979 - acc: 0.6183 -- iter: 064/313
[A[ATraining Step: 243  | total loss: [1m[32m0.64121[0m[0m | time: 1.635s
[2K
| RMSProp | epoch: 025 | loss: 0.64121 - acc: 0.6085 -- iter: 096/313
[A[ATraining Step: 244  | total loss: [1m[32m0.63730[0m[0m | time: 2.275s
[2K
| RMSProp | epoch: 025 | loss: 0.63730 - acc: 0.6133 -- iter: 128/313
[A[ATraining Step: 245  | total loss: [1m[32m0.62784[0m[0m | time: 2.896s
[2K
| RMSProp | epoch: 025 | loss: 0.62784 - acc: 0.6207 -- iter: 160/313
[A[ATraining Step: 246  | total loss: [1m[32m0.62364[0m[0m | time: 3.524s
[2K
| RMSProp | epoch: 025 | loss: 0.62364 - acc: 0.6211 -- iter: 192/313
[A[ATraining Step: 247  | total loss: [1m[32m0.61632[0m[0m | time: 4.140s
[2K
| RMSProp | epoch: 025 | loss: 0.61632 - acc: 0.6340 -- iter: 224/313
[A[ATraining Step: 248  | total loss: [1m[32m0.62370[0m[0m | time: 4.736s
[2K
| RMSProp | epoch: 025 | loss: 0.62370 - acc: 0.6300 -- iter: 256/313
[A[ATraining Step: 249  | total loss: [1m[32m0.62821[0m[0m | time: 5.339s
[2K
| RMSProp | epoch: 025 | loss: 0.62821 - acc: 0.6139 -- iter: 288/313
[A[ATraining Step: 250  | total loss: [1m[32m0.63119[0m[0m | time: 6.954s
[2K
| RMSProp | epoch: 025 | loss: 0.63119 - acc: 0.6150 | val_loss: 0.67427 - val_acc: 0.5253 -- iter: 313/313
--
Training Step: 251  | total loss: [1m[32m0.63270[0m[0m | time: 0.652s
[2K
| RMSProp | epoch: 026 | loss: 0.63270 - acc: 0.6004 -- iter: 032/313
[A[ATraining Step: 252  | total loss: [1m[32m0.61910[0m[0m | time: 1.150s
[2K
| RMSProp | epoch: 026 | loss: 0.61910 - acc: 0.6122 -- iter: 064/313
[A[ATraining Step: 253  | total loss: [1m[32m0.61622[0m[0m | time: 1.626s
[2K
| RMSProp | epoch: 026 | loss: 0.61622 - acc: 0.6190 -- iter: 096/313
[A[ATraining Step: 254  | total loss: [1m[32m0.62083[0m[0m | time: 2.241s
[2K
| RMSProp | epoch: 026 | loss: 0.62083 - acc: 0.6091 -- iter: 128/313
[A[ATraining Step: 255  | total loss: [1m[32m0.61886[0m[0m | time: 2.866s
[2K
| RMSProp | epoch: 026 | loss: 0.61886 - acc: 0.6294 -- iter: 160/313
[A[ATraining Step: 256  | total loss: [1m[32m0.62142[0m[0m | time: 3.480s
[2K
| RMSProp | epoch: 026 | loss: 0.62142 - acc: 0.6290 -- iter: 192/313
[A[ATraining Step: 257  | total loss: [1m[32m0.60983[0m[0m | time: 4.108s
[2K
| RMSProp | epoch: 026 | loss: 0.60983 - acc: 0.6536 -- iter: 224/313
[A[ATraining Step: 258  | total loss: [1m[32m0.61456[0m[0m | time: 4.720s
[2K
| RMSProp | epoch: 026 | loss: 0.61456 - acc: 0.6445 -- iter: 256/313
[A[ATraining Step: 259  | total loss: [1m[32m0.61849[0m[0m | time: 5.344s
[2K
| RMSProp | epoch: 026 | loss: 0.61849 - acc: 0.6456 -- iter: 288/313
[A[ATraining Step: 260  | total loss: [1m[32m0.60399[0m[0m | time: 6.950s
[2K
| RMSProp | epoch: 026 | loss: 0.60399 - acc: 0.6655 | val_loss: 0.65690 - val_acc: 0.6667 -- iter: 313/313
--
Training Step: 261  | total loss: [1m[32m0.60404[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 027 | loss: 0.60404 - acc: 0.6552 -- iter: 032/313
[A[ATraining Step: 262  | total loss: [1m[32m0.59800[0m[0m | time: 1.237s
[2K
| RMSProp | epoch: 027 | loss: 0.59800 - acc: 0.6678 -- iter: 064/313
[A[ATraining Step: 263  | total loss: [1m[32m0.59713[0m[0m | time: 1.732s
[2K
| RMSProp | epoch: 027 | loss: 0.59713 - acc: 0.6697 -- iter: 096/313
[A[ATraining Step: 264  | total loss: [1m[32m0.59425[0m[0m | time: 2.201s
[2K
| RMSProp | epoch: 027 | loss: 0.59425 - acc: 0.6668 -- iter: 128/313
[A[ATraining Step: 265  | total loss: [1m[32m0.58673[0m[0m | time: 2.829s
[2K
| RMSProp | epoch: 027 | loss: 0.58673 - acc: 0.6721 -- iter: 160/313
[A[ATraining Step: 266  | total loss: [1m[32m0.57551[0m[0m | time: 3.460s
[2K
| RMSProp | epoch: 027 | loss: 0.57551 - acc: 0.6861 -- iter: 192/313
[A[ATraining Step: 267  | total loss: [1m[32m0.57322[0m[0m | time: 4.070s
[2K
| RMSProp | epoch: 027 | loss: 0.57322 - acc: 0.6894 -- iter: 224/313
[A[ATraining Step: 268  | total loss: [1m[32m0.56986[0m[0m | time: 4.680s
[2K
| RMSProp | epoch: 027 | loss: 0.56986 - acc: 0.6955 -- iter: 256/313
[A[ATraining Step: 269  | total loss: [1m[32m0.55963[0m[0m | time: 5.303s
[2K
| RMSProp | epoch: 027 | loss: 0.55963 - acc: 0.7072 -- iter: 288/313
[A[ATraining Step: 270  | total loss: [1m[32m0.54957[0m[0m | time: 6.915s
[2K
| RMSProp | epoch: 027 | loss: 0.54957 - acc: 0.7146 | val_loss: 0.72763 - val_acc: 0.5960 -- iter: 313/313
--
Training Step: 271  | total loss: [1m[32m0.56256[0m[0m | time: 1.104s
[2K
| RMSProp | epoch: 028 | loss: 0.56256 - acc: 0.6962 -- iter: 032/313
[A[ATraining Step: 272  | total loss: [1m[32m0.56386[0m[0m | time: 2.160s
[2K
| RMSProp | epoch: 028 | loss: 0.56386 - acc: 0.6985 -- iter: 064/313
[A[ATraining Step: 273  | total loss: [1m[32m0.56461[0m[0m | time: 3.126s
[2K
| RMSProp | epoch: 028 | loss: 0.56461 - acc: 0.7036 -- iter: 096/313
[A[ATraining Step: 274  | total loss: [1m[32m0.56703[0m[0m | time: 3.887s
[2K
| RMSProp | epoch: 028 | loss: 0.56703 - acc: 0.7020 -- iter: 128/313
[A[ATraining Step: 275  | total loss: [1m[32m0.56310[0m[0m | time: 4.615s
[2K
| RMSProp | epoch: 028 | loss: 0.56310 - acc: 0.7198 -- iter: 160/313
[A[ATraining Step: 276  | total loss: [1m[32m0.55746[0m[0m | time: 5.670s
[2K
| RMSProp | epoch: 028 | loss: 0.55746 - acc: 0.7318 -- iter: 192/313
[A[ATraining Step: 277  | total loss: [1m[32m0.55220[0m[0m | time: 6.570s
[2K
| RMSProp | epoch: 028 | loss: 0.55220 - acc: 0.7274 -- iter: 224/313
[A[ATraining Step: 278  | total loss: [1m[32m0.56957[0m[0m | time: 7.664s
[2K
| RMSProp | epoch: 028 | loss: 0.56957 - acc: 0.7015 -- iter: 256/313
[A[ATraining Step: 279  | total loss: [1m[32m0.55977[0m[0m | time: 8.946s
[2K
| RMSProp | epoch: 028 | loss: 0.55977 - acc: 0.7064 -- iter: 288/313
[A[ATraining Step: 280  | total loss: [1m[32m0.54639[0m[0m | time: 10.806s
[2K
| RMSProp | epoch: 028 | loss: 0.54639 - acc: 0.7201 | val_loss: 0.72782 - val_acc: 0.6061 -- iter: 313/313
--
Training Step: 281  | total loss: [1m[32m0.53242[0m[0m | time: 0.931s
[2K
| RMSProp | epoch: 029 | loss: 0.53242 - acc: 0.7262 -- iter: 032/313
[A[ATraining Step: 282  | total loss: [1m[32m0.53656[0m[0m | time: 2.095s
[2K
| RMSProp | epoch: 029 | loss: 0.53656 - acc: 0.7317 -- iter: 064/313
[A[ATraining Step: 283  | total loss: [1m[32m0.52585[0m[0m | time: 3.385s
[2K
| RMSProp | epoch: 029 | loss: 0.52585 - acc: 0.7429 -- iter: 096/313
[A[ATraining Step: 284  | total loss: [1m[32m0.52409[0m[0m | time: 4.501s
[2K
| RMSProp | epoch: 029 | loss: 0.52409 - acc: 0.7468 -- iter: 128/313
[A[ATraining Step: 285  | total loss: [1m[32m0.52829[0m[0m | time: 5.213s
[2K
| RMSProp | epoch: 029 | loss: 0.52829 - acc: 0.7408 -- iter: 160/313
[A[ATraining Step: 286  | total loss: [1m[32m0.53418[0m[0m | time: 5.983s
[2K
| RMSProp | epoch: 029 | loss: 0.53418 - acc: 0.7308 -- iter: 192/313
[A[ATraining Step: 287  | total loss: [1m[32m0.52057[0m[0m | time: 6.948s
[2K
| RMSProp | epoch: 029 | loss: 0.52057 - acc: 0.7377 -- iter: 224/313
[A[ATraining Step: 288  | total loss: [1m[32m0.52029[0m[0m | time: 7.942s
[2K
| RMSProp | epoch: 029 | loss: 0.52029 - acc: 0.7420 -- iter: 256/313
[A[ATraining Step: 289  | total loss: [1m[32m0.51057[0m[0m | time: 8.918s
[2K
| RMSProp | epoch: 029 | loss: 0.51057 - acc: 0.7428 -- iter: 288/313
[A[ATraining Step: 290  | total loss: [1m[32m0.49727[0m[0m | time: 11.049s
[2K
| RMSProp | epoch: 029 | loss: 0.49727 - acc: 0.7561 | val_loss: 0.73436 - val_acc: 0.6768 -- iter: 313/313
--
Training Step: 291  | total loss: [1m[32m0.48572[0m[0m | time: 0.872s
[2K
| RMSProp | epoch: 030 | loss: 0.48572 - acc: 0.7586 -- iter: 032/313
[A[ATraining Step: 292  | total loss: [1m[32m0.49676[0m[0m | time: 1.831s
[2K
| RMSProp | epoch: 030 | loss: 0.49676 - acc: 0.7546 -- iter: 064/313
[A[ATraining Step: 293  | total loss: [1m[32m0.51937[0m[0m | time: 2.782s
[2K
| RMSProp | epoch: 030 | loss: 0.51937 - acc: 0.7354 -- iter: 096/313
[A[ATraining Step: 294  | total loss: [1m[32m0.51157[0m[0m | time: 3.818s
[2K
| RMSProp | epoch: 030 | loss: 0.51157 - acc: 0.7493 -- iter: 128/313
[A[ATraining Step: 295  | total loss: [1m[32m0.50358[0m[0m | time: 4.936s
[2K
| RMSProp | epoch: 030 | loss: 0.50358 - acc: 0.7494 -- iter: 160/313
[A[ATraining Step: 296  | total loss: [1m[32m0.50237[0m[0m | time: 5.722s
[2K
| RMSProp | epoch: 030 | loss: 0.50237 - acc: 0.7495 -- iter: 192/313
[A[ATraining Step: 297  | total loss: [1m[32m0.48792[0m[0m | time: 6.426s
[2K
| RMSProp | epoch: 030 | loss: 0.48792 - acc: 0.7665 -- iter: 224/313
[A[ATraining Step: 298  | total loss: [1m[32m0.47733[0m[0m | time: 7.644s
[2K
| RMSProp | epoch: 030 | loss: 0.47733 - acc: 0.7739 -- iter: 256/313
[A[ATraining Step: 299  | total loss: [1m[32m0.47092[0m[0m | time: 8.981s
[2K
| RMSProp | epoch: 030 | loss: 0.47092 - acc: 0.7746 -- iter: 288/313
[A[ATraining Step: 300  | total loss: [1m[32m0.47198[0m[0m | time: 11.269s
[2K
| RMSProp | epoch: 030 | loss: 0.47198 - acc: 0.7690 | val_loss: 0.64222 - val_acc: 0.6364 -- iter: 313/313
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7122448979591838
Validation AUPRC:0.7263815066301044
Test AUC:0.7572033898305085
Test AUPRC:0.800898430510115
BestTestF1Score	0.78	0.34	0.68	0.65	0.98	58	31	9	1	0.27
BestTestMCCScore	0.78	0.37	0.71	0.7	0.88	52	22	18	7	0.31
BestTestAccuracyScore	0.78	0.37	0.71	0.7	0.88	52	22	18	7	0.31
BestValidationF1Score	0.72	0.34	0.61	0.56	1.0	50	39	10	0	0.27
BestValidationMCC	0.71	0.35	0.67	0.63	0.82	41	24	25	9	0.31
BestValidationAccuracy	0.71	0.35	0.67	0.63	0.82	41	24	25	9	0.31
TestPredictions (Threshold:0.31)
CHEMBL422120,TP,ACT,0.7699999809265137	CHEMBL2011648,FP,INACT,0.3799999952316284	CHEMBL335132,TP,ACT,0.949999988079071	CHEMBL3361128,TN,INACT,0.30000001192092896	CHEMBL413033,TN,INACT,0.25999999046325684	CHEMBL140084,TP,ACT,0.75	CHEMBL222547,FN,ACT,0.2800000011920929	CHEMBL91935,TP,ACT,0.550000011920929	CHEMBL119096,TP,ACT,0.3100000023841858	CHEMBL3785970,TP,ACT,0.8100000023841858	CHEMBL141740,TP,ACT,0.8999999761581421	CHEMBL2088106,FP,INACT,0.3499999940395355	CHEMBL345606,FP,INACT,0.3400000035762787	CHEMBL3786296,TP,ACT,0.49000000953674316	CHEMBL187955,TP,ACT,0.8999999761581421	CHEMBL2260108,TP,ACT,0.8799999952316284	CHEMBL1171697,FP,INACT,0.4300000071525574	CHEMBL225205,TP,ACT,0.8799999952316284	CHEMBL347537,TN,INACT,0.2199999988079071	CHEMBL591504,FP,INACT,0.3400000035762787	CHEMBL3109739,FN,ACT,0.2800000011920929	CHEMBL2297956,TP,ACT,0.3100000023841858	CHEMBL144984,TP,ACT,0.6700000166893005	CHEMBL2376047,FP,INACT,0.8299999833106995	CHEMBL517587,TP,ACT,0.6600000262260437	CHEMBL462256,TP,ACT,0.7099999785423279	CHEMBL1917272,TP,ACT,0.8100000023841858	CHEMBL461653,FP,INACT,0.44999998807907104	CHEMBL409072,FP,INACT,0.46000000834465027	CHEMBL313009,TN,INACT,0.25	CHEMBL466154,FP,INACT,0.8999999761581421	CHEMBL87116,FP,INACT,0.41999998688697815	CHEMBL140354,TP,ACT,0.8399999737739563	CHEMBL460979,TP,ACT,0.5199999809265137	CHEMBL156403,TN,INACT,0.27000001072883606	CHEMBL89040,FP,INACT,0.3100000023841858	CHEMBL186346,TP,ACT,0.6299999952316284	CHEMBL3359606,TP,ACT,0.8299999833106995	CHEMBL3218001,TN,INACT,0.20000000298023224	CHEMBL2088110,FP,INACT,0.5199999809265137	CHEMBL490013,TP,ACT,0.3100000023841858	CHEMBL3707104,TP,ACT,0.8199999928474426	CHEMBL259739,TP,ACT,0.5299999713897705	CHEMBL1258868,TP,ACT,0.5099999904632568	CHEMBL144386,TP,ACT,0.6200000047683716	CHEMBL186994,TP,ACT,0.6700000166893005	CHEMBL3785281,FN,ACT,0.28999999165534973	CHEMBL85748,FP,INACT,0.6100000143051147	CHEMBL1917275,TP,ACT,0.7599999904632568	CHEMBL2011647,FP,INACT,0.6299999952316284	CHEMBL3785664,FN,ACT,0.25999999046325684	CHEMBL575809,TP,ACT,0.7599999904632568	CHEMBL3323507,TP,ACT,0.8999999761581421	CHEMBL3347490,TP,ACT,0.36000001430511475	CHEMBL330483,FP,INACT,0.4399999976158142	CHEMBL1684641,TP,ACT,0.4699999988079071	CHEMBL454192,TN,INACT,0.23000000417232513	CHEMBL3423386,TP,ACT,0.3700000047683716	CHEMBL3785794,FN,ACT,0.2800000011920929	CHEMBL3423397,FN,ACT,0.28999999165534973	CHEMBL451645,TP,ACT,0.6399999856948853	CHEMBL342480,TP,ACT,0.8500000238418579	CHEMBL313818,TN,INACT,0.27000001072883606	CHEMBL507478,TP,ACT,0.6800000071525574	CHEMBL2323143,TP,ACT,0.4000000059604645	CHEMBL1081908,TN,INACT,0.28999999165534973	CHEMBL2312626,TP,ACT,0.7400000095367432	CHEMBL345370,TN,INACT,0.25999999046325684	CHEMBL1796175,TN,INACT,0.30000001192092896	CHEMBL1258748,FP,INACT,0.6800000071525574	CHEMBL84794,FP,INACT,0.3400000035762787	CHEMBL160642,TN,INACT,0.2800000011920929	CHEMBL3218002,TN,INACT,0.25	CHEMBL2012469,TP,ACT,0.36000001430511475	CHEMBL2011646,FP,INACT,0.3100000023841858	CHEMBL2298066,FN,ACT,0.27000001072883606	CHEMBL3330787,TP,ACT,0.7099999785423279	CHEMBL598000,TN,INACT,0.27000001072883606	CHEMBL1917260,TP,ACT,0.3499999940395355	CHEMBL337762,TP,ACT,0.7599999904632568	CHEMBL2333209,TP,ACT,0.5899999737739563	CHEMBL2158673,TP,ACT,0.41999998688697815	CHEMBL516961,TP,ACT,0.5699999928474426	CHEMBL322704,FP,INACT,0.8700000047683716	CHEMBL3785699,TP,ACT,0.5	CHEMBL316359,FP,INACT,0.4099999964237213	CHEMBL3143740,TP,ACT,0.3100000023841858	CHEMBL2333201,TN,INACT,0.25	CHEMBL1258747,FP,INACT,0.6299999952316284	CHEMBL111417,TP,ACT,0.8999999761581421	CHEMBL157051,TN,INACT,0.2800000011920929	CHEMBL311055,TP,ACT,0.6399999856948853	CHEMBL1689442,TP,ACT,0.3700000047683716	CHEMBL509435,FP,INACT,0.44999998807907104	CHEMBL482414,TP,ACT,0.75	CHEMBL157766,TP,ACT,0.3199999928474426	CHEMBL1796187,TN,INACT,0.2800000011920929	CHEMBL3417322,TP,ACT,0.36000001430511475	CHEMBL296682,TN,INACT,0.25	

