ImageNetInceptionV2 CHEMBL3959 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	174
Number of inactive compounds :	116
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3959_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3959_adam_0.001_15_0.6/
---------------------------------
Training samples: 185
Validation samples: 58
--
Training Step: 1  | time: 36.689s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/185
[A[ATraining Step: 2  | total loss: [1m[32m0.65018[0m[0m | time: 44.543s
[2K
| Adam | epoch: 001 | loss: 0.65018 - acc: 0.3375 -- iter: 064/185
[A[ATraining Step: 3  | total loss: [1m[32m0.78262[0m[0m | time: 52.408s
[2K
| Adam | epoch: 001 | loss: 0.78262 - acc: 0.4449 -- iter: 096/185
[A[ATraining Step: 4  | total loss: [1m[32m0.67269[0m[0m | time: 60.524s
[2K
| Adam | epoch: 001 | loss: 0.67269 - acc: 0.5800 -- iter: 128/185
[A[ATraining Step: 5  | total loss: [1m[32m0.59931[0m[0m | time: 68.394s
[2K
| Adam | epoch: 001 | loss: 0.59931 - acc: 0.6544 -- iter: 160/185
[A[ATraining Step: 6  | total loss: [1m[32m0.69283[0m[0m | time: 82.651s
[2K
| Adam | epoch: 001 | loss: 0.69283 - acc: 0.5953 | val_loss: 2.19559 - val_acc: 0.6034 -- iter: 185/185
--
Training Step: 7  | total loss: [1m[32m0.78044[0m[0m | time: 6.511s
[2K
| Adam | epoch: 002 | loss: 0.78044 - acc: 0.5021 -- iter: 032/185
[A[ATraining Step: 8  | total loss: [1m[32m0.62090[0m[0m | time: 14.311s
[2K
| Adam | epoch: 002 | loss: 0.62090 - acc: 0.6247 -- iter: 064/185
[A[ATraining Step: 9  | total loss: [1m[32m0.55469[0m[0m | time: 22.084s
[2K
| Adam | epoch: 002 | loss: 0.55469 - acc: 0.6745 -- iter: 096/185
[A[ATraining Step: 10  | total loss: [1m[32m0.51849[0m[0m | time: 29.971s
[2K
| Adam | epoch: 002 | loss: 0.51849 - acc: 0.7435 -- iter: 128/185
[A[ATraining Step: 11  | total loss: [1m[32m0.50050[0m[0m | time: 37.756s
[2K
| Adam | epoch: 002 | loss: 0.50050 - acc: 0.7170 -- iter: 160/185
[A[ATraining Step: 12  | total loss: [1m[32m0.58506[0m[0m | time: 48.215s
[2K
| Adam | epoch: 002 | loss: 0.58506 - acc: 0.7178 | val_loss: 3.44246 - val_acc: 0.6034 -- iter: 185/185
--
Training Step: 13  | total loss: [1m[32m0.52864[0m[0m | time: 6.479s
[2K
| Adam | epoch: 003 | loss: 0.52864 - acc: 0.7316 -- iter: 032/185
[A[ATraining Step: 14  | total loss: [1m[32m0.50551[0m[0m | time: 12.920s
[2K
| Adam | epoch: 003 | loss: 0.50551 - acc: 0.7432 -- iter: 064/185
[A[ATraining Step: 15  | total loss: [1m[32m0.40287[0m[0m | time: 20.638s
[2K
| Adam | epoch: 003 | loss: 0.40287 - acc: 0.8437 -- iter: 096/185
[A[ATraining Step: 16  | total loss: [1m[32m0.48403[0m[0m | time: 28.515s
[2K
| Adam | epoch: 003 | loss: 0.48403 - acc: 0.8086 -- iter: 128/185
[A[ATraining Step: 17  | total loss: [1m[32m0.47156[0m[0m | time: 36.250s
[2K
| Adam | epoch: 003 | loss: 0.47156 - acc: 0.7875 -- iter: 160/185
[A[ATraining Step: 18  | total loss: [1m[32m0.44361[0m[0m | time: 46.614s
[2K
| Adam | epoch: 003 | loss: 0.44361 - acc: 0.8070 | val_loss: 6.05168 - val_acc: 0.6034 -- iter: 185/185
--
Training Step: 19  | total loss: [1m[32m0.39790[0m[0m | time: 7.958s
[2K
| Adam | epoch: 004 | loss: 0.39790 - acc: 0.8192 -- iter: 032/185
[A[ATraining Step: 20  | total loss: [1m[32m0.47780[0m[0m | time: 14.401s
[2K
| Adam | epoch: 004 | loss: 0.47780 - acc: 0.7869 -- iter: 064/185
[A[ATraining Step: 21  | total loss: [1m[32m0.51292[0m[0m | time: 20.803s
[2K
| Adam | epoch: 004 | loss: 0.51292 - acc: 0.7662 -- iter: 096/185
[A[ATraining Step: 22  | total loss: [1m[32m0.46477[0m[0m | time: 28.688s
[2K
| Adam | epoch: 004 | loss: 0.46477 - acc: 0.8123 -- iter: 128/185
[A[ATraining Step: 23  | total loss: [1m[32m0.41907[0m[0m | time: 36.438s
[2K
| Adam | epoch: 004 | loss: 0.41907 - acc: 0.8487 -- iter: 160/185
[A[ATraining Step: 24  | total loss: [1m[32m0.35821[0m[0m | time: 46.970s
[2K
| Adam | epoch: 004 | loss: 0.35821 - acc: 0.8649 | val_loss: 6.56998 - val_acc: 0.6034 -- iter: 185/185
--
Training Step: 25  | total loss: [1m[32m0.38920[0m[0m | time: 7.790s
[2K
| Adam | epoch: 005 | loss: 0.38920 - acc: 0.8335 -- iter: 032/185
[A[ATraining Step: 26  | total loss: [1m[32m0.37957[0m[0m | time: 15.557s
[2K
| Adam | epoch: 005 | loss: 0.37957 - acc: 0.8362 -- iter: 064/185
[A[ATraining Step: 27  | total loss: [1m[32m0.35501[0m[0m | time: 22.059s
[2K
| Adam | epoch: 005 | loss: 0.35501 - acc: 0.8382 -- iter: 096/185
[A[ATraining Step: 28  | total loss: [1m[32m0.33269[0m[0m | time: 28.442s
[2K
| Adam | epoch: 005 | loss: 0.33269 - acc: 0.8386 -- iter: 128/185
[A[ATraining Step: 29  | total loss: [1m[32m0.26722[0m[0m | time: 36.358s
[2K
| Adam | epoch: 005 | loss: 0.26722 - acc: 0.8779 -- iter: 160/185
[A[ATraining Step: 30  | total loss: [1m[32m0.25493[0m[0m | time: 46.544s
[2K
| Adam | epoch: 005 | loss: 0.25493 - acc: 0.8772 | val_loss: 7.69305 - val_acc: 0.6034 -- iter: 185/185
--
Training Step: 31  | total loss: [1m[32m0.31094[0m[0m | time: 7.924s
[2K
| Adam | epoch: 006 | loss: 0.31094 - acc: 0.8551 -- iter: 032/185
[A[ATraining Step: 32  | total loss: [1m[32m0.26686[0m[0m | time: 15.572s
[2K
| Adam | epoch: 006 | loss: 0.26686 - acc: 0.8736 -- iter: 064/185
[A[ATraining Step: 33  | total loss: [1m[32m0.23822[0m[0m | time: 23.360s
[2K
| Adam | epoch: 006 | loss: 0.23822 - acc: 0.8945 -- iter: 096/185
[A[ATraining Step: 34  | total loss: [1m[32m0.20547[0m[0m | time: 29.770s
[2K
| Adam | epoch: 006 | loss: 0.20547 - acc: 0.9104 -- iter: 128/185
[A[ATraining Step: 35  | total loss: [1m[32m0.17373[0m[0m | time: 36.113s
[2K
| Adam | epoch: 006 | loss: 0.17373 - acc: 0.9292 -- iter: 160/185
[A[ATraining Step: 36  | total loss: [1m[32m0.14841[0m[0m | time: 46.507s
[2K
| Adam | epoch: 006 | loss: 0.14841 - acc: 0.9436 | val_loss: 7.91188 - val_acc: 0.6034 -- iter: 185/185
--
Training Step: 37  | total loss: [1m[32m0.16922[0m[0m | time: 7.729s
[2K
| Adam | epoch: 007 | loss: 0.16922 - acc: 0.9237 -- iter: 032/185
[A[ATraining Step: 38  | total loss: [1m[32m0.16927[0m[0m | time: 15.455s
[2K
| Adam | epoch: 007 | loss: 0.16927 - acc: 0.9264 -- iter: 064/185
[A[ATraining Step: 39  | total loss: [1m[32m0.14467[0m[0m | time: 23.205s
[2K
| Adam | epoch: 007 | loss: 0.14467 - acc: 0.9405 -- iter: 096/185
[A[ATraining Step: 40  | total loss: [1m[32m0.12800[0m[0m | time: 30.968s
[2K
| Adam | epoch: 007 | loss: 0.12800 - acc: 0.9516 -- iter: 128/185
[A[ATraining Step: 41  | total loss: [1m[32m0.11814[0m[0m | time: 37.305s
[2K
| Adam | epoch: 007 | loss: 0.11814 - acc: 0.9605 -- iter: 160/185
[A[ATraining Step: 42  | total loss: [1m[32m0.11258[0m[0m | time: 46.274s
[2K
| Adam | epoch: 007 | loss: 0.11258 - acc: 0.9604 | val_loss: 7.07302 - val_acc: 0.6034 -- iter: 185/185
--
Training Step: 43  | total loss: [1m[32m0.09580[0m[0m | time: 7.835s
[2K
| Adam | epoch: 008 | loss: 0.09580 - acc: 0.9674 -- iter: 032/185
[A[ATraining Step: 44  | total loss: [1m[32m0.10066[0m[0m | time: 15.586s
[2K
| Adam | epoch: 008 | loss: 0.10066 - acc: 0.9622 -- iter: 064/185
[A[ATraining Step: 45  | total loss: [1m[32m0.11815[0m[0m | time: 23.381s
[2K
| Adam | epoch: 008 | loss: 0.11815 - acc: 0.9580 -- iter: 096/185
[A[ATraining Step: 46  | total loss: [1m[32m0.10776[0m[0m | time: 31.051s
[2K
| Adam | epoch: 008 | loss: 0.10776 - acc: 0.9598 -- iter: 128/185
[A[ATraining Step: 47  | total loss: [1m[32m0.13256[0m[0m | time: 38.761s
[2K
| Adam | epoch: 008 | loss: 0.13256 - acc: 0.9562 -- iter: 160/185
[A[ATraining Step: 48  | total loss: [1m[32m0.11581[0m[0m | time: 47.668s
[2K
| Adam | epoch: 008 | loss: 0.11581 - acc: 0.9632 | val_loss: 5.14109 - val_acc: 0.6034 -- iter: 185/185
--
Training Step: 49  | total loss: [1m[32m0.16016[0m[0m | time: 6.419s
[2K
| Adam | epoch: 009 | loss: 0.16016 - acc: 0.9627 -- iter: 032/185
[A[ATraining Step: 50  | total loss: [1m[32m0.15356[0m[0m | time: 14.214s
[2K
| Adam | epoch: 009 | loss: 0.15356 - acc: 0.9623 -- iter: 064/185
[A[ATraining Step: 51  | total loss: [1m[32m0.13413[0m[0m | time: 22.048s
[2K
| Adam | epoch: 009 | loss: 0.13413 - acc: 0.9680 -- iter: 096/185
[A[ATraining Step: 52  | total loss: [1m[32m0.19665[0m[0m | time: 29.666s
[2K
| Adam | epoch: 009 | loss: 0.19665 - acc: 0.9588 -- iter: 128/185
[A[ATraining Step: 53  | total loss: [1m[32m0.17502[0m[0m | time: 37.402s
[2K
| Adam | epoch: 009 | loss: 0.17502 - acc: 0.9649 -- iter: 160/185
[A[ATraining Step: 54  | total loss: [1m[32m0.16952[0m[0m | time: 47.681s
[2K
| Adam | epoch: 009 | loss: 0.16952 - acc: 0.9609 | val_loss: 1.51061 - val_acc: 0.5862 -- iter: 185/185
--
Training Step: 55  | total loss: [1m[32m0.18344[0m[0m | time: 6.418s
[2K
| Adam | epoch: 010 | loss: 0.18344 - acc: 0.9531 -- iter: 032/185
[A[ATraining Step: 56  | total loss: [1m[32m0.19033[0m[0m | time: 12.764s
[2K
| Adam | epoch: 010 | loss: 0.19033 - acc: 0.9428 -- iter: 064/185
[A[ATraining Step: 57  | total loss: [1m[32m0.17549[0m[0m | time: 20.521s
[2K
| Adam | epoch: 010 | loss: 0.17549 - acc: 0.9507 -- iter: 096/185
[A[ATraining Step: 58  | total loss: [1m[32m0.15642[0m[0m | time: 28.241s
[2K
| Adam | epoch: 010 | loss: 0.15642 - acc: 0.9574 -- iter: 128/185
[A[ATraining Step: 59  | total loss: [1m[32m0.17455[0m[0m | time: 35.959s
[2K
| Adam | epoch: 010 | loss: 0.17455 - acc: 0.9590 -- iter: 160/185
[A[ATraining Step: 60  | total loss: [1m[32m0.17073[0m[0m | time: 46.183s
[2K
| Adam | epoch: 010 | loss: 0.17073 - acc: 0.9561 | val_loss: 5.19897 - val_acc: 0.5690 -- iter: 185/185
--
Training Step: 61  | total loss: [1m[32m0.16749[0m[0m | time: 7.790s
[2K
| Adam | epoch: 011 | loss: 0.16749 - acc: 0.9578 -- iter: 032/185
[A[ATraining Step: 62  | total loss: [1m[32m0.16412[0m[0m | time: 14.197s
[2K
| Adam | epoch: 011 | loss: 0.16412 - acc: 0.9511 -- iter: 064/185
[A[ATraining Step: 63  | total loss: [1m[32m0.18388[0m[0m | time: 20.702s
[2K
| Adam | epoch: 011 | loss: 0.18388 - acc: 0.9421 -- iter: 096/185
[A[ATraining Step: 64  | total loss: [1m[32m0.17139[0m[0m | time: 28.405s
[2K
| Adam | epoch: 011 | loss: 0.17139 - acc: 0.9494 -- iter: 128/185
[A[ATraining Step: 65  | total loss: [1m[32m0.17508[0m[0m | time: 36.085s
[2K
| Adam | epoch: 011 | loss: 0.17508 - acc: 0.9479 -- iter: 160/185
[A[ATraining Step: 66  | total loss: [1m[32m0.18850[0m[0m | time: 46.268s
[2K
| Adam | epoch: 011 | loss: 0.18850 - acc: 0.9428 | val_loss: 3.19903 - val_acc: 0.4138 -- iter: 185/185
--
Training Step: 67  | total loss: [1m[32m0.17922[0m[0m | time: 7.716s
[2K
| Adam | epoch: 012 | loss: 0.17922 - acc: 0.9422 -- iter: 032/185
[A[ATraining Step: 68  | total loss: [1m[32m0.17360[0m[0m | time: 15.406s
[2K
| Adam | epoch: 012 | loss: 0.17360 - acc: 0.9453 -- iter: 064/185
[A[ATraining Step: 69  | total loss: [1m[32m0.15588[0m[0m | time: 21.751s
[2K
| Adam | epoch: 012 | loss: 0.15588 - acc: 0.9517 -- iter: 096/185
[A[ATraining Step: 70  | total loss: [1m[32m0.14608[0m[0m | time: 28.319s
[2K
| Adam | epoch: 012 | loss: 0.14608 - acc: 0.9573 -- iter: 128/185
[A[ATraining Step: 71  | total loss: [1m[32m0.13463[0m[0m | time: 36.075s
[2K
| Adam | epoch: 012 | loss: 0.13463 - acc: 0.9622 -- iter: 160/185
[A[ATraining Step: 72  | total loss: [1m[32m0.12219[0m[0m | time: 46.331s
[2K
| Adam | epoch: 012 | loss: 0.12219 - acc: 0.9664 | val_loss: 1.53960 - val_acc: 0.6207 -- iter: 185/185
--
Training Step: 73  | total loss: [1m[32m0.13579[0m[0m | time: 7.725s
[2K
| Adam | epoch: 013 | loss: 0.13579 - acc: 0.9667 -- iter: 032/185
[A[ATraining Step: 74  | total loss: [1m[32m0.12441[0m[0m | time: 15.545s
[2K
| Adam | epoch: 013 | loss: 0.12441 - acc: 0.9703 -- iter: 064/185
[A[ATraining Step: 75  | total loss: [1m[32m0.13356[0m[0m | time: 23.092s
[2K
| Adam | epoch: 013 | loss: 0.13356 - acc: 0.9634 -- iter: 096/185
[A[ATraining Step: 76  | total loss: [1m[32m0.12344[0m[0m | time: 29.421s
[2K
| Adam | epoch: 013 | loss: 0.12344 - acc: 0.9673 -- iter: 128/185
[A[ATraining Step: 77  | total loss: [1m[32m0.11204[0m[0m | time: 35.945s
[2K
| Adam | epoch: 013 | loss: 0.11204 - acc: 0.9708 -- iter: 160/185
[A[ATraining Step: 78  | total loss: [1m[32m0.10222[0m[0m | time: 46.361s
[2K
| Adam | epoch: 013 | loss: 0.10222 - acc: 0.9738 | val_loss: 1.32562 - val_acc: 0.6552 -- iter: 185/185
--
Training Step: 79  | total loss: [1m[32m0.09514[0m[0m | time: 7.753s
[2K
| Adam | epoch: 014 | loss: 0.09514 - acc: 0.9733 -- iter: 032/185
[A[ATraining Step: 80  | total loss: [1m[32m0.12124[0m[0m | time: 15.452s
[2K
| Adam | epoch: 014 | loss: 0.12124 - acc: 0.9728 -- iter: 064/185
[A[ATraining Step: 81  | total loss: [1m[32m0.11201[0m[0m | time: 23.121s
[2K
| Adam | epoch: 014 | loss: 0.11201 - acc: 0.9756 -- iter: 096/185
[A[ATraining Step: 82  | total loss: [1m[32m0.10896[0m[0m | time: 30.764s
[2K
| Adam | epoch: 014 | loss: 0.10896 - acc: 0.9749 -- iter: 128/185
[A[ATraining Step: 83  | total loss: [1m[32m0.09956[0m[0m | time: 37.230s
[2K
| Adam | epoch: 014 | loss: 0.09956 - acc: 0.9774 -- iter: 160/185
[A[ATraining Step: 84  | total loss: [1m[32m0.10068[0m[0m | time: 46.135s
[2K
| Adam | epoch: 014 | loss: 0.10068 - acc: 0.9717 | val_loss: 1.74882 - val_acc: 0.6379 -- iter: 185/185
--
Training Step: 85  | total loss: [1m[32m0.09329[0m[0m | time: 7.716s
[2K
| Adam | epoch: 015 | loss: 0.09329 - acc: 0.9745 -- iter: 032/185
[A[ATraining Step: 86  | total loss: [1m[32m0.09214[0m[0m | time: 15.407s
[2K
| Adam | epoch: 015 | loss: 0.09214 - acc: 0.9739 -- iter: 064/185
[A[ATraining Step: 87  | total loss: [1m[32m0.11801[0m[0m | time: 23.208s
[2K
| Adam | epoch: 015 | loss: 0.11801 - acc: 0.9703 -- iter: 096/185
[A[ATraining Step: 88  | total loss: [1m[32m0.11339[0m[0m | time: 30.783s
[2K
| Adam | epoch: 015 | loss: 0.11339 - acc: 0.9701 -- iter: 128/185
[A[ATraining Step: 89  | total loss: [1m[32m0.12631[0m[0m | time: 38.536s
[2K
| Adam | epoch: 015 | loss: 0.12631 - acc: 0.9606 -- iter: 160/185
[A[ATraining Step: 90  | total loss: [1m[32m0.12368[0m[0m | time: 47.444s
[2K
| Adam | epoch: 015 | loss: 0.12368 - acc: 0.9614 | val_loss: 2.50399 - val_acc: 0.5690 -- iter: 185/185
--
Validation AUC:0.6658385093167701
Validation AUPRC:0.7689739653104837
Test AUC:0.7928921568627451
Test AUPRC:0.8539005598565872
BestTestF1Score	0.76	0.43	0.72	0.76	0.76	26	8	16	8	0.01
BestTestMCCScore	0.71	0.45	0.71	0.84	0.62	21	4	20	13	0.23
BestTestAccuracyScore	0.76	0.43	0.72	0.76	0.76	26	8	16	8	0.01
BestValidationF1Score	0.62	0.23	0.6	0.73	0.54	19	7	16	16	0.01
BestValidationMCC	0.52	0.32	0.59	0.87	0.37	13	2	21	22	0.23
BestValidationAccuracy	0.62	0.23	0.6	0.73	0.54	19	7	16	16	0.01
TestPredictions (Threshold:0.23)
CHEMBL8805,TN,INACT,0.0	CHEMBL1836823,FN,ACT,0.0	CHEMBL1836795,TP,ACT,0.23999999463558197	CHEMBL2426748,TN,INACT,0.0	CHEMBL37703,TP,ACT,0.3799999952316284	CHEMBL25336,TN,INACT,0.0	CHEMBL292293,TN,INACT,0.009999999776482582	CHEMBL338604,TP,ACT,0.28999999165534973	CHEMBL3770674,FN,ACT,0.009999999776482582	CHEMBL599687,TP,ACT,0.30000001192092896	CHEMBL1684128,TN,INACT,0.019999999552965164	CHEMBL457763,FN,ACT,0.029999999329447746	CHEMBL146752,TP,ACT,1.0	CHEMBL147350,TP,ACT,0.9800000190734863	CHEMBL418678,TN,INACT,0.0	CHEMBL9416,TN,INACT,0.0	CHEMBL599688,FN,ACT,0.009999999776482582	CHEMBL54246,TN,INACT,0.0	CHEMBL134874,TP,ACT,0.949999988079071	CHEMBL1802197,TN,INACT,0.0	CHEMBL1288196,FN,ACT,0.0	CHEMBL1802262,FP,INACT,0.7699999809265137	CHEMBL1945622,TP,ACT,0.9399999976158142	CHEMBL464755,TN,INACT,0.029999999329447746	CHEMBL334404,TP,ACT,0.9599999785423279	CHEMBL33700,TP,ACT,0.9800000190734863	CHEMBL1161926,FP,INACT,0.9100000262260437	CHEMBL1836824,TP,ACT,0.949999988079071	CHEMBL1275791,TN,INACT,0.18000000715255737	CHEMBL80104,TN,INACT,0.0	CHEMBL1945628,TN,INACT,0.0	CHEMBL95604,FN,ACT,0.009999999776482582	CHEMBL1288045,FN,ACT,0.0	CHEMBL44509,TN,INACT,0.0	CHEMBL45305,FP,INACT,0.25999999046325684	CHEMBL32711,TN,INACT,0.0	CHEMBL134544,FN,ACT,0.07000000029802322	CHEMBL453417,TN,INACT,0.0	CHEMBL1944648,TP,ACT,0.5099999904632568	CHEMBL446329,TP,ACT,0.7900000214576721	CHEMBL609028,TP,ACT,0.8999999761581421	CHEMBL490867,TP,ACT,0.5699999928474426	CHEMBL132753,TP,ACT,0.7400000095367432	CHEMBL493181,FN,ACT,0.14000000059604645	CHEMBL134832,TP,ACT,0.9300000071525574	CHEMBL134295,TP,ACT,0.9700000286102295	CHEMBL1836821,TP,ACT,0.6700000166893005	CHEMBL8602,FN,ACT,0.009999999776482582	CHEMBL292725,TN,INACT,0.0	CHEMBL511675,FN,ACT,0.05000000074505806	CHEMBL1802265,TN,INACT,0.0	CHEMBL1945625,FN,ACT,0.0	CHEMBL135136,TP,ACT,1.0	CHEMBL135366,TP,ACT,1.0	CHEMBL2426750,TN,INACT,0.1899999976158142	CHEMBL221049,FP,INACT,0.9399999976158142	CHEMBL592636,FN,ACT,0.029999999329447746	CHEMBL52772,TN,INACT,0.0	

