ImageNetInceptionV2 CHEMBL274 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	1618
Number of inactive compounds :	1618
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL274_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL274_adam_0.0005_15_0.8/
---------------------------------
Training samples: 2068
Validation samples: 647
--
Training Step: 1  | time: 38.318s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2068
[A[ATraining Step: 2  | total loss: [1m[32m0.60661[0m[0m | time: 47.540s
[2K
| Adam | epoch: 001 | loss: 0.60661 - acc: 0.4219 -- iter: 0064/2068
[A[ATraining Step: 3  | total loss: [1m[32m0.91990[0m[0m | time: 56.699s
[2K
| Adam | epoch: 001 | loss: 0.91990 - acc: 0.4091 -- iter: 0096/2068
[A[ATraining Step: 4  | total loss: [1m[32m0.73800[0m[0m | time: 65.669s
[2K
| Adam | epoch: 001 | loss: 0.73800 - acc: 0.5241 -- iter: 0128/2068
[A[ATraining Step: 5  | total loss: [1m[32m0.60575[0m[0m | time: 74.493s
[2K
| Adam | epoch: 001 | loss: 0.60575 - acc: 0.7021 -- iter: 0160/2068
[A[ATraining Step: 6  | total loss: [1m[32m0.59189[0m[0m | time: 83.506s
[2K
| Adam | epoch: 001 | loss: 0.59189 - acc: 0.6726 -- iter: 0192/2068
[A[ATraining Step: 7  | total loss: [1m[32m0.55984[0m[0m | time: 92.492s
[2K
| Adam | epoch: 001 | loss: 0.55984 - acc: 0.6816 -- iter: 0224/2068
[A[ATraining Step: 8  | total loss: [1m[32m0.65986[0m[0m | time: 101.264s
[2K
| Adam | epoch: 001 | loss: 0.65986 - acc: 0.6497 -- iter: 0256/2068
[A[ATraining Step: 9  | total loss: [1m[32m0.76231[0m[0m | time: 110.099s
[2K
| Adam | epoch: 001 | loss: 0.76231 - acc: 0.6036 -- iter: 0288/2068
[A[ATraining Step: 10  | total loss: [1m[32m0.70601[0m[0m | time: 118.879s
[2K
| Adam | epoch: 001 | loss: 0.70601 - acc: 0.5830 -- iter: 0320/2068
[A[ATraining Step: 11  | total loss: [1m[32m0.54525[0m[0m | time: 127.592s
[2K
| Adam | epoch: 001 | loss: 0.54525 - acc: 0.6917 -- iter: 0352/2068
[A[ATraining Step: 12  | total loss: [1m[32m0.52208[0m[0m | time: 136.328s
[2K
| Adam | epoch: 001 | loss: 0.52208 - acc: 0.7039 -- iter: 0384/2068
[A[ATraining Step: 13  | total loss: [1m[32m0.51558[0m[0m | time: 145.072s
[2K
| Adam | epoch: 001 | loss: 0.51558 - acc: 0.7236 -- iter: 0416/2068
[A[ATraining Step: 14  | total loss: [1m[32m0.53309[0m[0m | time: 153.761s
[2K
| Adam | epoch: 001 | loss: 0.53309 - acc: 0.7216 -- iter: 0448/2068
[A[ATraining Step: 15  | total loss: [1m[32m0.47529[0m[0m | time: 162.730s
[2K
| Adam | epoch: 001 | loss: 0.47529 - acc: 0.8061 -- iter: 0480/2068
[A[ATraining Step: 16  | total loss: [1m[32m0.48686[0m[0m | time: 171.505s
[2K
| Adam | epoch: 001 | loss: 0.48686 - acc: 0.7734 -- iter: 0512/2068
[A[ATraining Step: 17  | total loss: [1m[32m0.46179[0m[0m | time: 180.572s
[2K
| Adam | epoch: 001 | loss: 0.46179 - acc: 0.7874 -- iter: 0544/2068
[A[ATraining Step: 18  | total loss: [1m[32m0.55917[0m[0m | time: 189.384s
[2K
| Adam | epoch: 001 | loss: 0.55917 - acc: 0.7637 -- iter: 0576/2068
[A[ATraining Step: 19  | total loss: [1m[32m0.50804[0m[0m | time: 198.262s
[2K
| Adam | epoch: 001 | loss: 0.50804 - acc: 0.8008 -- iter: 0608/2068
[A[ATraining Step: 20  | total loss: [1m[32m0.45869[0m[0m | time: 207.105s
[2K
| Adam | epoch: 001 | loss: 0.45869 - acc: 0.8146 -- iter: 0640/2068
[A[ATraining Step: 21  | total loss: [1m[32m0.48064[0m[0m | time: 215.800s
[2K
| Adam | epoch: 001 | loss: 0.48064 - acc: 0.7654 -- iter: 0672/2068
[A[ATraining Step: 22  | total loss: [1m[32m0.46287[0m[0m | time: 224.536s
[2K
| Adam | epoch: 001 | loss: 0.46287 - acc: 0.7983 -- iter: 0704/2068
[A[ATraining Step: 23  | total loss: [1m[32m0.43380[0m[0m | time: 233.547s
[2K
| Adam | epoch: 001 | loss: 0.43380 - acc: 0.8206 -- iter: 0736/2068
[A[ATraining Step: 24  | total loss: [1m[32m0.40915[0m[0m | time: 242.414s
[2K
| Adam | epoch: 001 | loss: 0.40915 - acc: 0.8359 -- iter: 0768/2068
[A[ATraining Step: 25  | total loss: [1m[32m0.39397[0m[0m | time: 251.215s
[2K
| Adam | epoch: 001 | loss: 0.39397 - acc: 0.8380 -- iter: 0800/2068
[A[ATraining Step: 26  | total loss: [1m[32m0.37810[0m[0m | time: 259.900s
[2K
| Adam | epoch: 001 | loss: 0.37810 - acc: 0.8395 -- iter: 0832/2068
[A[ATraining Step: 27  | total loss: [1m[32m0.31867[0m[0m | time: 268.868s
[2K
| Adam | epoch: 001 | loss: 0.31867 - acc: 0.8808 -- iter: 0864/2068
[A[ATraining Step: 28  | total loss: [1m[32m0.33667[0m[0m | time: 277.739s
[2K
| Adam | epoch: 001 | loss: 0.33667 - acc: 0.8794 -- iter: 0896/2068
[A[ATraining Step: 29  | total loss: [1m[32m0.37244[0m[0m | time: 286.700s
[2K
| Adam | epoch: 001 | loss: 0.37244 - acc: 0.8631 -- iter: 0928/2068
[A[ATraining Step: 30  | total loss: [1m[32m0.43259[0m[0m | time: 295.624s
[2K
| Adam | epoch: 001 | loss: 0.43259 - acc: 0.8289 -- iter: 0960/2068
[A[ATraining Step: 31  | total loss: [1m[32m0.37990[0m[0m | time: 304.402s
[2K
| Adam | epoch: 001 | loss: 0.37990 - acc: 0.8395 -- iter: 0992/2068
[A[ATraining Step: 32  | total loss: [1m[32m0.39874[0m[0m | time: 313.400s
[2K
| Adam | epoch: 001 | loss: 0.39874 - acc: 0.8405 -- iter: 1024/2068
[A[ATraining Step: 33  | total loss: [1m[32m0.43340[0m[0m | time: 323.138s
[2K
| Adam | epoch: 001 | loss: 0.43340 - acc: 0.8275 -- iter: 1056/2068
[A[ATraining Step: 34  | total loss: [1m[32m0.42746[0m[0m | time: 333.865s
[2K
| Adam | epoch: 001 | loss: 0.42746 - acc: 0.8444 -- iter: 1088/2068
[A[ATraining Step: 35  | total loss: [1m[32m0.38779[0m[0m | time: 433.606s
[2K
| Adam | epoch: 001 | loss: 0.38779 - acc: 0.8573 -- iter: 1120/2068
[A[ATraining Step: 36  | total loss: [1m[32m0.35424[0m[0m | time: 655.614s
[2K
| Adam | epoch: 001 | loss: 0.35424 - acc: 0.8673 -- iter: 1152/2068
[A[ATraining Step: 37  | total loss: [1m[32m0.34370[0m[0m | time: 741.880s
[2K
| Adam | epoch: 001 | loss: 0.34370 - acc: 0.8689 -- iter: 1184/2068
[A[ATraining Step: 38  | total loss: [1m[32m0.31436[0m[0m | time: 873.585s
[2K
| Adam | epoch: 001 | loss: 0.31436 - acc: 0.8884 -- iter: 1216/2068
[A[ATraining Step: 39  | total loss: [1m[32m0.33919[0m[0m | time: 1072.245s
[2K
| Adam | epoch: 001 | loss: 0.33919 - acc: 0.8799 -- iter: 1248/2068
[A[ATraining Step: 40  | total loss: [1m[32m0.33366[0m[0m | time: 1137.730s
[2K
| Adam | epoch: 001 | loss: 0.33366 - acc: 0.8731 -- iter: 1280/2068
[A[ATraining Step: 41  | total loss: [1m[32m0.32619[0m[0m | time: 1203.160s
[2K
| Adam | epoch: 001 | loss: 0.32619 - acc: 0.8792 -- iter: 1312/2068
[A[ATraining Step: 42  | total loss: [1m[32m0.35556[0m[0m | time: 1269.332s
[2K
| Adam | epoch: 001 | loss: 0.35556 - acc: 0.8672 -- iter: 1344/2068
[A[ATraining Step: 43  | total loss: [1m[32m0.35996[0m[0m | time: 1339.839s
[2K
| Adam | epoch: 001 | loss: 0.35996 - acc: 0.8575 -- iter: 1376/2068
[A[ATraining Step: 44  | total loss: [1m[32m0.39853[0m[0m | time: 1433.546s
[2K
| Adam | epoch: 001 | loss: 0.39853 - acc: 0.8389 -- iter: 1408/2068
[A[ATraining Step: 45  | total loss: [1m[32m0.40280[0m[0m | time: 1513.690s
[2K
| Adam | epoch: 001 | loss: 0.40280 - acc: 0.8397 -- iter: 1440/2068
[A[ATraining Step: 46  | total loss: [1m[32m0.40799[0m[0m | time: 1593.158s
[2K
| Adam | epoch: 001 | loss: 0.40799 - acc: 0.8300 -- iter: 1472/2068
[A[ATraining Step: 47  | total loss: [1m[32m0.39487[0m[0m | time: 1712.374s
[2K
| Adam | epoch: 001 | loss: 0.39487 - acc: 0.8322 -- iter: 1504/2068
[A[ATraining Step: 48  | total loss: [1m[32m0.36510[0m[0m | time: 1759.405s
[2K
| Adam | epoch: 001 | loss: 0.36510 - acc: 0.8441 -- iter: 1536/2068
[A[ATraining Step: 49  | total loss: [1m[32m0.32860[0m[0m | time: 1767.930s
[2K
| Adam | epoch: 001 | loss: 0.32860 - acc: 0.8638 -- iter: 1568/2068
[A[ATraining Step: 50  | total loss: [1m[32m0.30929[0m[0m | time: 1855.881s
[2K
| Adam | epoch: 001 | loss: 0.30929 - acc: 0.8752 -- iter: 1600/2068
[A[ATraining Step: 51  | total loss: [1m[32m0.36707[0m[0m | time: 1864.306s
[2K
| Adam | epoch: 001 | loss: 0.36707 - acc: 0.8466 -- iter: 1632/2068
[A[ATraining Step: 52  | total loss: [1m[32m0.37362[0m[0m | time: 1929.985s
[2K
| Adam | epoch: 001 | loss: 0.37362 - acc: 0.8415 -- iter: 1664/2068
[A[ATraining Step: 53  | total loss: [1m[32m0.35391[0m[0m | time: 1961.306s
[2K
| Adam | epoch: 001 | loss: 0.35391 - acc: 0.8418 -- iter: 1696/2068
[A[ATraining Step: 54  | total loss: [1m[32m0.33553[0m[0m | time: 1998.494s
[2K
| Adam | epoch: 001 | loss: 0.33553 - acc: 0.8512 -- iter: 1728/2068
[A[ATraining Step: 55  | total loss: [1m[32m0.34352[0m[0m | time: 2006.762s
[2K
| Adam | epoch: 001 | loss: 0.34352 - acc: 0.8457 -- iter: 1760/2068
[A[ATraining Step: 56  | total loss: [1m[32m0.34972[0m[0m | time: 2052.283s
[2K
| Adam | epoch: 001 | loss: 0.34972 - acc: 0.8410 -- iter: 1792/2068
[A[ATraining Step: 57  | total loss: [1m[32m0.35284[0m[0m | time: 2079.675s
[2K
| Adam | epoch: 001 | loss: 0.35284 - acc: 0.8414 -- iter: 1824/2068
[A[ATraining Step: 58  | total loss: [1m[32m0.34233[0m[0m | time: 2129.497s
[2K
| Adam | epoch: 001 | loss: 0.34233 - acc: 0.8502 -- iter: 1856/2068
[A[ATraining Step: 59  | total loss: [1m[32m0.31739[0m[0m | time: 2137.781s
[2K
| Adam | epoch: 001 | loss: 0.31739 - acc: 0.8661 -- iter: 1888/2068
[A[ATraining Step: 60  | total loss: [1m[32m0.29337[0m[0m | time: 2146.019s
[2K
| Adam | epoch: 001 | loss: 0.29337 - acc: 0.8756 -- iter: 1920/2068
[A[ATraining Step: 61  | total loss: [1m[32m0.28299[0m[0m | time: 2154.259s
[2K
| Adam | epoch: 001 | loss: 0.28299 - acc: 0.8796 -- iter: 1952/2068
[A[ATraining Step: 62  | total loss: [1m[32m0.27937[0m[0m | time: 2162.380s
[2K
| Adam | epoch: 001 | loss: 0.27937 - acc: 0.8750 -- iter: 1984/2068
[A[ATraining Step: 63  | total loss: [1m[32m0.30058[0m[0m | time: 2170.296s
[2K
| Adam | epoch: 001 | loss: 0.30058 - acc: 0.8750 -- iter: 2016/2068
[A[ATraining Step: 64  | total loss: [1m[32m0.30096[0m[0m | time: 2178.390s
[2K
| Adam | epoch: 001 | loss: 0.30096 - acc: 0.8750 -- iter: 2048/2068
[A[ATraining Step: 65  | total loss: [1m[32m0.31487[0m[0m | time: 2219.812s
[2K
| Adam | epoch: 001 | loss: 0.31487 - acc: 0.8750 | val_loss: 2.42780 - val_acc: 0.5286 -- iter: 2068/2068
--
Training Step: 66  | total loss: [1m[32m0.29586[0m[0m | time: 5.585s
[2K
| Adam | epoch: 002 | loss: 0.29586 - acc: 0.8902 -- iter: 0032/2068
[A[ATraining Step: 67  | total loss: [1m[32m0.26819[0m[0m | time: 13.720s
[2K
| Adam | epoch: 002 | loss: 0.26819 - acc: 0.9034 -- iter: 0064/2068
[A[ATraining Step: 68  | total loss: [1m[32m0.29835[0m[0m | time: 22.084s
[2K
| Adam | epoch: 002 | loss: 0.29835 - acc: 0.8963 -- iter: 0096/2068
[A[ATraining Step: 69  | total loss: [1m[32m0.31766[0m[0m | time: 57.066s
[2K
| Adam | epoch: 002 | loss: 0.31766 - acc: 0.8902 -- iter: 0128/2068
[A[ATraining Step: 70  | total loss: [1m[32m0.29575[0m[0m | time: 64.927s
[2K
| Adam | epoch: 002 | loss: 0.29575 - acc: 0.8992 -- iter: 0160/2068
[A[ATraining Step: 71  | total loss: [1m[32m0.29683[0m[0m | time: 73.063s
[2K
| Adam | epoch: 002 | loss: 0.29683 - acc: 0.8929 -- iter: 0192/2068
[A[ATraining Step: 72  | total loss: [1m[32m0.31626[0m[0m | time: 81.577s
[2K
| Adam | epoch: 002 | loss: 0.31626 - acc: 0.8803 -- iter: 0224/2068
[A[ATraining Step: 73  | total loss: [1m[32m0.32099[0m[0m | time: 89.715s
[2K
| Adam | epoch: 002 | loss: 0.32099 - acc: 0.8798 -- iter: 0256/2068
[A[ATraining Step: 74  | total loss: [1m[32m0.31927[0m[0m | time: 97.933s
[2K
| Adam | epoch: 002 | loss: 0.31927 - acc: 0.8724 -- iter: 0288/2068
[A[ATraining Step: 75  | total loss: [1m[32m0.31794[0m[0m | time: 106.195s
[2K
| Adam | epoch: 002 | loss: 0.31794 - acc: 0.8693 -- iter: 0320/2068
[A[ATraining Step: 76  | total loss: [1m[32m0.30805[0m[0m | time: 137.461s
[2K
| Adam | epoch: 002 | loss: 0.30805 - acc: 0.8766 -- iter: 0352/2068
[A[ATraining Step: 77  | total loss: [1m[32m0.32700[0m[0m | time: 147.202s
[2K
| Adam | epoch: 002 | loss: 0.32700 - acc: 0.8731 -- iter: 0384/2068
[A[ATraining Step: 78  | total loss: [1m[32m0.31617[0m[0m | time: 157.025s
[2K
| Adam | epoch: 002 | loss: 0.31617 - acc: 0.8766 -- iter: 0416/2068
[A[ATraining Step: 79  | total loss: [1m[32m0.31664[0m[0m | time: 167.219s
[2K
| Adam | epoch: 002 | loss: 0.31664 - acc: 0.8764 -- iter: 0448/2068
[A[ATraining Step: 80  | total loss: [1m[32m0.32880[0m[0m | time: 177.051s
[2K
| Adam | epoch: 002 | loss: 0.32880 - acc: 0.8699 -- iter: 0480/2068
[A[ATraining Step: 81  | total loss: [1m[32m0.31512[0m[0m | time: 186.588s
[2K
| Adam | epoch: 002 | loss: 0.31512 - acc: 0.8767 -- iter: 0512/2068
[A[ATraining Step: 82  | total loss: [1m[32m0.31161[0m[0m | time: 196.293s
[2K
| Adam | epoch: 002 | loss: 0.31161 - acc: 0.8828 -- iter: 0544/2068
[A[ATraining Step: 83  | total loss: [1m[32m0.30458[0m[0m | time: 206.208s
[2K
| Adam | epoch: 002 | loss: 0.30458 - acc: 0.8820 -- iter: 0576/2068
[A[ATraining Step: 84  | total loss: [1m[32m0.28964[0m[0m | time: 216.222s
[2K
| Adam | epoch: 002 | loss: 0.28964 - acc: 0.8907 -- iter: 0608/2068
[A[ATraining Step: 85  | total loss: [1m[32m0.28830[0m[0m | time: 225.835s
[2K
| Adam | epoch: 002 | loss: 0.28830 - acc: 0.8891 -- iter: 0640/2068
[A[ATraining Step: 86  | total loss: [1m[32m0.31042[0m[0m | time: 236.026s
[2K
| Adam | epoch: 002 | loss: 0.31042 - acc: 0.8815 -- iter: 0672/2068
[A[ATraining Step: 87  | total loss: [1m[32m0.31227[0m[0m | time: 246.462s
[2K
| Adam | epoch: 002 | loss: 0.31227 - acc: 0.8777 -- iter: 0704/2068
[A[ATraining Step: 88  | total loss: [1m[32m0.32042[0m[0m | time: 256.392s
[2K
| Adam | epoch: 002 | loss: 0.32042 - acc: 0.8774 -- iter: 0736/2068
[A[ATraining Step: 89  | total loss: [1m[32m0.31211[0m[0m | time: 265.220s
[2K
| Adam | epoch: 002 | loss: 0.31211 - acc: 0.8772 -- iter: 0768/2068
[A[ATraining Step: 90  | total loss: [1m[32m0.31122[0m[0m | time: 273.358s
[2K
| Adam | epoch: 002 | loss: 0.31122 - acc: 0.8801 -- iter: 0800/2068
[A[ATraining Step: 91  | total loss: [1m[32m0.31987[0m[0m | time: 281.375s
[2K
| Adam | epoch: 002 | loss: 0.31987 - acc: 0.8733 -- iter: 0832/2068
[A[ATraining Step: 92  | total loss: [1m[32m0.30930[0m[0m | time: 289.510s
[2K
| Adam | epoch: 002 | loss: 0.30930 - acc: 0.8797 -- iter: 0864/2068
[A[ATraining Step: 93  | total loss: [1m[32m0.32067[0m[0m | time: 297.738s
[2K
| Adam | epoch: 002 | loss: 0.32067 - acc: 0.8730 -- iter: 0896/2068
[A[ATraining Step: 94  | total loss: [1m[32m0.32395[0m[0m | time: 305.731s
[2K
| Adam | epoch: 002 | loss: 0.32395 - acc: 0.8732 -- iter: 0928/2068
[A[ATraining Step: 95  | total loss: [1m[32m0.32160[0m[0m | time: 313.842s
[2K
| Adam | epoch: 002 | loss: 0.32160 - acc: 0.8703 -- iter: 0960/2068
[A[ATraining Step: 96  | total loss: [1m[32m0.30822[0m[0m | time: 322.356s
[2K
| Adam | epoch: 002 | loss: 0.30822 - acc: 0.8770 -- iter: 0992/2068
[A[ATraining Step: 97  | total loss: [1m[32m0.28877[0m[0m | time: 330.767s
[2K
| Adam | epoch: 002 | loss: 0.28877 - acc: 0.8862 -- iter: 1024/2068
[A[ATraining Step: 98  | total loss: [1m[32m0.29141[0m[0m | time: 338.954s
[2K
| Adam | epoch: 002 | loss: 0.29141 - acc: 0.8819 -- iter: 1056/2068
[A[ATraining Step: 99  | total loss: [1m[32m0.27448[0m[0m | time: 346.934s
[2K
| Adam | epoch: 002 | loss: 0.27448 - acc: 0.8906 -- iter: 1088/2068
[A[ATraining Step: 100  | total loss: [1m[32m0.26781[0m[0m | time: 355.145s
[2K
| Adam | epoch: 002 | loss: 0.26781 - acc: 0.8922 -- iter: 1120/2068
[A[ATraining Step: 101  | total loss: [1m[32m0.26171[0m[0m | time: 363.267s
[2K
| Adam | epoch: 002 | loss: 0.26171 - acc: 0.8936 -- iter: 1152/2068
[A[ATraining Step: 102  | total loss: [1m[32m0.25508[0m[0m | time: 371.258s
[2K
| Adam | epoch: 002 | loss: 0.25508 - acc: 0.9011 -- iter: 1184/2068
[A[ATraining Step: 103  | total loss: [1m[32m0.24704[0m[0m | time: 379.443s
[2K
| Adam | epoch: 002 | loss: 0.24704 - acc: 0.9016 -- iter: 1216/2068
[A[ATraining Step: 104  | total loss: [1m[32m0.24279[0m[0m | time: 387.413s
[2K
| Adam | epoch: 002 | loss: 0.24279 - acc: 0.9052 -- iter: 1248/2068
[A[ATraining Step: 105  | total loss: [1m[32m0.22415[0m[0m | time: 395.929s
[2K
| Adam | epoch: 002 | loss: 0.22415 - acc: 0.9147 -- iter: 1280/2068
[A[ATraining Step: 106  | total loss: [1m[32m0.21466[0m[0m | time: 404.095s
[2K
| Adam | epoch: 002 | loss: 0.21466 - acc: 0.9201 -- iter: 1312/2068
[A[ATraining Step: 107  | total loss: [1m[32m0.19963[0m[0m | time: 412.297s
[2K
| Adam | epoch: 002 | loss: 0.19963 - acc: 0.9281 -- iter: 1344/2068
[A[ATraining Step: 108  | total loss: [1m[32m0.19812[0m[0m | time: 420.367s
[2K
| Adam | epoch: 002 | loss: 0.19812 - acc: 0.9290 -- iter: 1376/2068
[A[ATraining Step: 109  | total loss: [1m[32m0.22339[0m[0m | time: 428.715s
[2K
| Adam | epoch: 002 | loss: 0.22339 - acc: 0.9236 -- iter: 1408/2068
[A[ATraining Step: 110  | total loss: [1m[32m0.26255[0m[0m | time: 436.992s
[2K
| Adam | epoch: 002 | loss: 0.26255 - acc: 0.9156 -- iter: 1440/2068
[A[ATraining Step: 111  | total loss: [1m[32m0.25626[0m[0m | time: 445.281s
[2K
| Adam | epoch: 002 | loss: 0.25626 - acc: 0.9178 -- iter: 1472/2068
[A[ATraining Step: 112  | total loss: [1m[32m0.24160[0m[0m | time: 453.420s
[2K
| Adam | epoch: 002 | loss: 0.24160 - acc: 0.9198 -- iter: 1504/2068
[A[ATraining Step: 113  | total loss: [1m[32m0.22392[0m[0m | time: 461.434s
[2K
| Adam | epoch: 002 | loss: 0.22392 - acc: 0.9278 -- iter: 1536/2068
[A[ATraining Step: 114  | total loss: [1m[32m0.21459[0m[0m | time: 469.562s
[2K
| Adam | epoch: 002 | loss: 0.21459 - acc: 0.9319 -- iter: 1568/2068
[A[ATraining Step: 115  | total loss: [1m[32m0.20387[0m[0m | time: 477.520s
[2K
| Adam | epoch: 002 | loss: 0.20387 - acc: 0.9325 -- iter: 1600/2068
[A[ATraining Step: 116  | total loss: [1m[32m0.19799[0m[0m | time: 485.737s
[2K
| Adam | epoch: 002 | loss: 0.19799 - acc: 0.9330 -- iter: 1632/2068
[A[ATraining Step: 117  | total loss: [1m[32m0.19085[0m[0m | time: 493.990s
[2K
| Adam | epoch: 002 | loss: 0.19085 - acc: 0.9365 -- iter: 1664/2068
[A[ATraining Step: 118  | total loss: [1m[32m0.20413[0m[0m | time: 502.076s
[2K
| Adam | epoch: 002 | loss: 0.20413 - acc: 0.9304 -- iter: 1696/2068
[A[ATraining Step: 119  | total loss: [1m[32m0.19119[0m[0m | time: 510.106s
[2K
| Adam | epoch: 002 | loss: 0.19119 - acc: 0.9342 -- iter: 1728/2068
[A[ATraining Step: 120  | total loss: [1m[32m0.19147[0m[0m | time: 518.211s
[2K
| Adam | epoch: 002 | loss: 0.19147 - acc: 0.9314 -- iter: 1760/2068
[A[ATraining Step: 121  | total loss: [1m[32m0.20604[0m[0m | time: 526.273s
[2K
| Adam | epoch: 002 | loss: 0.20604 - acc: 0.9289 -- iter: 1792/2068
[A[ATraining Step: 122  | total loss: [1m[32m0.21716[0m[0m | time: 534.264s
[2K
| Adam | epoch: 002 | loss: 0.21716 - acc: 0.9173 -- iter: 1824/2068
[A[ATraining Step: 123  | total loss: [1m[32m0.21180[0m[0m | time: 542.181s
[2K
| Adam | epoch: 002 | loss: 0.21180 - acc: 0.9193 -- iter: 1856/2068
[A[ATraining Step: 124  | total loss: [1m[32m0.22408[0m[0m | time: 550.492s
[2K
| Adam | epoch: 002 | loss: 0.22408 - acc: 0.9055 -- iter: 1888/2068
[A[ATraining Step: 125  | total loss: [1m[32m0.22027[0m[0m | time: 558.653s
[2K
| Adam | epoch: 002 | loss: 0.22027 - acc: 0.9118 -- iter: 1920/2068
[A[ATraining Step: 126  | total loss: [1m[32m0.21104[0m[0m | time: 566.667s
[2K
| Adam | epoch: 002 | loss: 0.21104 - acc: 0.9144 -- iter: 1952/2068
[A[ATraining Step: 127  | total loss: [1m[32m0.21064[0m[0m | time: 575.046s
[2K
| Adam | epoch: 002 | loss: 0.21064 - acc: 0.9104 -- iter: 1984/2068
[A[ATraining Step: 128  | total loss: [1m[32m0.20594[0m[0m | time: 583.321s
[2K
| Adam | epoch: 002 | loss: 0.20594 - acc: 0.9163 -- iter: 2016/2068
[A[ATraining Step: 129  | total loss: [1m[32m0.19715[0m[0m | time: 591.507s
[2K
| Adam | epoch: 002 | loss: 0.19715 - acc: 0.9184 -- iter: 2048/2068
[A[ATraining Step: 130  | total loss: [1m[32m0.18791[0m[0m | time: 629.027s
[2K
| Adam | epoch: 002 | loss: 0.18791 - acc: 0.9266 | val_loss: 0.45504 - val_acc: 0.8315 -- iter: 2068/2068
--
Training Step: 131  | total loss: [1m[32m0.19715[0m[0m | time: 5.682s
[2K
| Adam | epoch: 003 | loss: 0.19715 - acc: 0.9183 -- iter: 0032/2068
[A[ATraining Step: 132  | total loss: [1m[32m0.17897[0m[0m | time: 11.070s
[2K
| Adam | epoch: 003 | loss: 0.17897 - acc: 0.9264 -- iter: 0064/2068
[A[ATraining Step: 133  | total loss: [1m[32m0.16198[0m[0m | time: 19.312s
[2K
| Adam | epoch: 003 | loss: 0.16198 - acc: 0.9338 -- iter: 0096/2068
[A[ATraining Step: 134  | total loss: [1m[32m0.18134[0m[0m | time: 27.705s
[2K
| Adam | epoch: 003 | loss: 0.18134 - acc: 0.9248 -- iter: 0128/2068
[A[ATraining Step: 135  | total loss: [1m[32m0.19381[0m[0m | time: 35.763s
[2K
| Adam | epoch: 003 | loss: 0.19381 - acc: 0.9229 -- iter: 0160/2068
[A[ATraining Step: 136  | total loss: [1m[32m0.20208[0m[0m | time: 43.962s
[2K
| Adam | epoch: 003 | loss: 0.20208 - acc: 0.9150 -- iter: 0192/2068
[A[ATraining Step: 137  | total loss: [1m[32m0.19999[0m[0m | time: 52.315s
[2K
| Adam | epoch: 003 | loss: 0.19999 - acc: 0.9141 -- iter: 0224/2068
[A[ATraining Step: 138  | total loss: [1m[32m0.20924[0m[0m | time: 60.301s
[2K
| Adam | epoch: 003 | loss: 0.20924 - acc: 0.9102 -- iter: 0256/2068
[A[ATraining Step: 139  | total loss: [1m[32m0.21741[0m[0m | time: 68.645s
[2K
| Adam | epoch: 003 | loss: 0.21741 - acc: 0.9130 -- iter: 0288/2068
[A[ATraining Step: 140  | total loss: [1m[32m0.23478[0m[0m | time: 76.748s
[2K
| Adam | epoch: 003 | loss: 0.23478 - acc: 0.9029 -- iter: 0320/2068
[A[ATraining Step: 141  | total loss: [1m[32m0.25727[0m[0m | time: 84.853s
[2K
| Adam | epoch: 003 | loss: 0.25727 - acc: 0.9001 -- iter: 0352/2068
[A[ATraining Step: 142  | total loss: [1m[32m0.26310[0m[0m | time: 92.984s
[2K
| Adam | epoch: 003 | loss: 0.26310 - acc: 0.8976 -- iter: 0384/2068
[A[ATraining Step: 143  | total loss: [1m[32m0.25051[0m[0m | time: 101.280s
[2K
| Adam | epoch: 003 | loss: 0.25051 - acc: 0.9016 -- iter: 0416/2068
[A[ATraining Step: 144  | total loss: [1m[32m0.23515[0m[0m | time: 109.365s
[2K
| Adam | epoch: 003 | loss: 0.23515 - acc: 0.9083 -- iter: 0448/2068
[A[ATraining Step: 145  | total loss: [1m[32m0.25576[0m[0m | time: 117.625s
[2K
| Adam | epoch: 003 | loss: 0.25576 - acc: 0.9019 -- iter: 0480/2068
[A[ATraining Step: 146  | total loss: [1m[32m0.24472[0m[0m | time: 125.830s
[2K
| Adam | epoch: 003 | loss: 0.24472 - acc: 0.9054 -- iter: 0512/2068
[A[ATraining Step: 147  | total loss: [1m[32m0.23557[0m[0m | time: 134.014s
[2K
| Adam | epoch: 003 | loss: 0.23557 - acc: 0.9055 -- iter: 0544/2068
[A[ATraining Step: 148  | total loss: [1m[32m0.24025[0m[0m | time: 142.026s
[2K
| Adam | epoch: 003 | loss: 0.24025 - acc: 0.9087 -- iter: 0576/2068
[A[ATraining Step: 149  | total loss: [1m[32m0.23670[0m[0m | time: 150.317s
[2K
| Adam | epoch: 003 | loss: 0.23670 - acc: 0.9147 -- iter: 0608/2068
[A[ATraining Step: 150  | total loss: [1m[32m0.22279[0m[0m | time: 158.561s
[2K
| Adam | epoch: 003 | loss: 0.22279 - acc: 0.9232 -- iter: 0640/2068
[A[ATraining Step: 151  | total loss: [1m[32m0.21716[0m[0m | time: 166.817s
[2K
| Adam | epoch: 003 | loss: 0.21716 - acc: 0.9247 -- iter: 0672/2068
[A[ATraining Step: 152  | total loss: [1m[32m0.22611[0m[0m | time: 175.207s
[2K
| Adam | epoch: 003 | loss: 0.22611 - acc: 0.9228 -- iter: 0704/2068
[A[ATraining Step: 153  | total loss: [1m[32m0.21666[0m[0m | time: 183.409s
[2K
| Adam | epoch: 003 | loss: 0.21666 - acc: 0.9243 -- iter: 0736/2068
[A[ATraining Step: 154  | total loss: [1m[32m0.21456[0m[0m | time: 191.489s
[2K
| Adam | epoch: 003 | loss: 0.21456 - acc: 0.9225 -- iter: 0768/2068
[A[ATraining Step: 155  | total loss: [1m[32m0.21020[0m[0m | time: 199.452s
[2K
| Adam | epoch: 003 | loss: 0.21020 - acc: 0.9240 -- iter: 0800/2068
[A[ATraining Step: 156  | total loss: [1m[32m0.22678[0m[0m | time: 207.843s
[2K
| Adam | epoch: 003 | loss: 0.22678 - acc: 0.9191 -- iter: 0832/2068
[A[ATraining Step: 157  | total loss: [1m[32m0.23356[0m[0m | time: 216.451s
[2K
| Adam | epoch: 003 | loss: 0.23356 - acc: 0.9116 -- iter: 0864/2068
[A[ATraining Step: 158  | total loss: [1m[32m0.24002[0m[0m | time: 224.768s
[2K
| Adam | epoch: 003 | loss: 0.24002 - acc: 0.9079 -- iter: 0896/2068
[A[ATraining Step: 159  | total loss: [1m[32m0.23988[0m[0m | time: 232.866s
[2K
| Adam | epoch: 003 | loss: 0.23988 - acc: 0.9077 -- iter: 0928/2068
[A[ATraining Step: 160  | total loss: [1m[32m0.25200[0m[0m | time: 240.948s
[2K
| Adam | epoch: 003 | loss: 0.25200 - acc: 0.9045 -- iter: 0960/2068
[A[ATraining Step: 161  | total loss: [1m[32m0.23083[0m[0m | time: 249.087s
[2K
| Adam | epoch: 003 | loss: 0.23083 - acc: 0.9140 -- iter: 0992/2068
[A[ATraining Step: 162  | total loss: [1m[32m0.24262[0m[0m | time: 257.239s
[2K
| Adam | epoch: 003 | loss: 0.24262 - acc: 0.9039 -- iter: 1024/2068
[A[ATraining Step: 163  | total loss: [1m[32m0.24160[0m[0m | time: 265.536s
[2K
| Adam | epoch: 003 | loss: 0.24160 - acc: 0.9010 -- iter: 1056/2068
[A[ATraining Step: 164  | total loss: [1m[32m0.23021[0m[0m | time: 273.691s
[2K
| Adam | epoch: 003 | loss: 0.23021 - acc: 0.9078 -- iter: 1088/2068
[A[ATraining Step: 165  | total loss: [1m[32m0.25826[0m[0m | time: 281.909s
[2K
| Adam | epoch: 003 | loss: 0.25826 - acc: 0.9045 -- iter: 1120/2068
[A[ATraining Step: 166  | total loss: [1m[32m0.24197[0m[0m | time: 289.980s
[2K
| Adam | epoch: 003 | loss: 0.24197 - acc: 0.9140 -- iter: 1152/2068
[A[ATraining Step: 167  | total loss: [1m[32m0.22458[0m[0m | time: 297.920s
[2K
| Adam | epoch: 003 | loss: 0.22458 - acc: 0.9226 -- iter: 1184/2068
[A[ATraining Step: 168  | total loss: [1m[32m0.20903[0m[0m | time: 306.301s
[2K
| Adam | epoch: 003 | loss: 0.20903 - acc: 0.9272 -- iter: 1216/2068
[A[ATraining Step: 169  | total loss: [1m[32m0.20695[0m[0m | time: 314.782s
[2K
| Adam | epoch: 003 | loss: 0.20695 - acc: 0.9251 -- iter: 1248/2068
[A[ATraining Step: 170  | total loss: [1m[32m0.20742[0m[0m | time: 323.093s
[2K
| Adam | epoch: 003 | loss: 0.20742 - acc: 0.9264 -- iter: 1280/2068
[A[ATraining Step: 171  | total loss: [1m[32m0.19330[0m[0m | time: 331.136s
[2K
| Adam | epoch: 003 | loss: 0.19330 - acc: 0.9337 -- iter: 1312/2068
[A[ATraining Step: 172  | total loss: [1m[32m0.19421[0m[0m | time: 339.412s
[2K
| Adam | epoch: 003 | loss: 0.19421 - acc: 0.9341 -- iter: 1344/2068
[A[ATraining Step: 173  | total loss: [1m[32m0.19442[0m[0m | time: 347.734s
[2K
| Adam | epoch: 003 | loss: 0.19442 - acc: 0.9345 -- iter: 1376/2068
[A[ATraining Step: 174  | total loss: [1m[32m0.18177[0m[0m | time: 355.755s
[2K
| Adam | epoch: 003 | loss: 0.18177 - acc: 0.9379 -- iter: 1408/2068
[A[ATraining Step: 175  | total loss: [1m[32m0.17646[0m[0m | time: 363.909s
[2K
| Adam | epoch: 003 | loss: 0.17646 - acc: 0.9410 -- iter: 1440/2068
[A[ATraining Step: 176  | total loss: [1m[32m0.17583[0m[0m | time: 371.921s
[2K
| Adam | epoch: 003 | loss: 0.17583 - acc: 0.9344 -- iter: 1472/2068
[A[ATraining Step: 177  | total loss: [1m[32m0.17037[0m[0m | time: 380.200s
[2K
| Adam | epoch: 003 | loss: 0.17037 - acc: 0.9316 -- iter: 1504/2068
[A[ATraining Step: 178  | total loss: [1m[32m0.17159[0m[0m | time: 388.231s
[2K
| Adam | epoch: 003 | loss: 0.17159 - acc: 0.9290 -- iter: 1536/2068
[A[ATraining Step: 179  | total loss: [1m[32m0.15944[0m[0m | time: 396.748s
[2K
| Adam | epoch: 003 | loss: 0.15944 - acc: 0.9361 -- iter: 1568/2068
[A[ATraining Step: 180  | total loss: [1m[32m0.14842[0m[0m | time: 405.324s
[2K
| Adam | epoch: 003 | loss: 0.14842 - acc: 0.9425 -- iter: 1600/2068
[A[ATraining Step: 181  | total loss: [1m[32m0.14450[0m[0m | time: 413.369s
[2K
| Adam | epoch: 003 | loss: 0.14450 - acc: 0.9451 -- iter: 1632/2068
[A[ATraining Step: 182  | total loss: [1m[32m0.13440[0m[0m | time: 421.627s
[2K
| Adam | epoch: 003 | loss: 0.13440 - acc: 0.9506 -- iter: 1664/2068
[A[ATraining Step: 183  | total loss: [1m[32m0.12913[0m[0m | time: 429.668s
[2K
| Adam | epoch: 003 | loss: 0.12913 - acc: 0.9524 -- iter: 1696/2068
[A[ATraining Step: 184  | total loss: [1m[32m0.12175[0m[0m | time: 438.068s
[2K
| Adam | epoch: 003 | loss: 0.12175 - acc: 0.9541 -- iter: 1728/2068
[A[ATraining Step: 185  | total loss: [1m[32m0.13242[0m[0m | time: 446.484s
[2K
| Adam | epoch: 003 | loss: 0.13242 - acc: 0.9462 -- iter: 1760/2068
[A[ATraining Step: 186  | total loss: [1m[32m0.12696[0m[0m | time: 454.786s
[2K
| Adam | epoch: 003 | loss: 0.12696 - acc: 0.9515 -- iter: 1792/2068
[A[ATraining Step: 187  | total loss: [1m[32m0.13349[0m[0m | time: 462.890s
[2K
| Adam | epoch: 003 | loss: 0.13349 - acc: 0.9533 -- iter: 1824/2068
[A[ATraining Step: 188  | total loss: [1m[32m0.12972[0m[0m | time: 471.280s
[2K
| Adam | epoch: 003 | loss: 0.12972 - acc: 0.9548 -- iter: 1856/2068
[A[ATraining Step: 189  | total loss: [1m[32m0.13455[0m[0m | time: 479.851s
[2K
| Adam | epoch: 003 | loss: 0.13455 - acc: 0.9531 -- iter: 1888/2068
[A[ATraining Step: 190  | total loss: [1m[32m0.13121[0m[0m | time: 488.209s
[2K
| Adam | epoch: 003 | loss: 0.13121 - acc: 0.9515 -- iter: 1920/2068
[A[ATraining Step: 191  | total loss: [1m[32m0.12785[0m[0m | time: 496.336s
[2K
| Adam | epoch: 003 | loss: 0.12785 - acc: 0.9532 -- iter: 1952/2068
[A[ATraining Step: 192  | total loss: [1m[32m0.15031[0m[0m | time: 504.419s
[2K
| Adam | epoch: 003 | loss: 0.15031 - acc: 0.9454 -- iter: 1984/2068
[A[ATraining Step: 193  | total loss: [1m[32m0.14530[0m[0m | time: 512.629s
[2K
| Adam | epoch: 003 | loss: 0.14530 - acc: 0.9478 -- iter: 2016/2068
[A[ATraining Step: 194  | total loss: [1m[32m0.13347[0m[0m | time: 521.035s
[2K
| Adam | epoch: 003 | loss: 0.13347 - acc: 0.9530 -- iter: 2048/2068
[A[ATraining Step: 195  | total loss: [1m[32m0.14035[0m[0m | time: 558.359s
[2K
| Adam | epoch: 003 | loss: 0.14035 - acc: 0.9483 | val_loss: 2.90916 - val_acc: 0.5008 -- iter: 2068/2068
--
Training Step: 196  | total loss: [1m[32m0.15481[0m[0m | time: 8.531s
[2K
| Adam | epoch: 004 | loss: 0.15481 - acc: 0.9441 -- iter: 0032/2068
[A[ATraining Step: 197  | total loss: [1m[32m0.14864[0m[0m | time: 14.158s
[2K
| Adam | epoch: 004 | loss: 0.14864 - acc: 0.9466 -- iter: 0064/2068
[A[ATraining Step: 198  | total loss: [1m[32m0.17099[0m[0m | time: 19.728s
[2K
| Adam | epoch: 004 | loss: 0.17099 - acc: 0.9419 -- iter: 0096/2068
[A[ATraining Step: 199  | total loss: [1m[32m0.16069[0m[0m | time: 28.082s
[2K
| Adam | epoch: 004 | loss: 0.16069 - acc: 0.9477 -- iter: 0128/2068
[A[ATraining Step: 200  | total loss: [1m[32m0.16870[0m[0m | time: 65.210s
[2K
| Adam | epoch: 004 | loss: 0.16870 - acc: 0.9436 | val_loss: 0.70173 - val_acc: 0.7403 -- iter: 0160/2068
--
Training Step: 201  | total loss: [1m[32m0.15672[0m[0m | time: 73.831s
[2K
| Adam | epoch: 004 | loss: 0.15672 - acc: 0.9492 -- iter: 0192/2068
[A[ATraining Step: 202  | total loss: [1m[32m0.16410[0m[0m | time: 81.924s
[2K
| Adam | epoch: 004 | loss: 0.16410 - acc: 0.9480 -- iter: 0224/2068
[A[ATraining Step: 203  | total loss: [1m[32m0.16443[0m[0m | time: 90.104s
[2K
| Adam | epoch: 004 | loss: 0.16443 - acc: 0.9470 -- iter: 0256/2068
[A[ATraining Step: 204  | total loss: [1m[32m0.16995[0m[0m | time: 98.249s
[2K
| Adam | epoch: 004 | loss: 0.16995 - acc: 0.9429 -- iter: 0288/2068
[A[ATraining Step: 205  | total loss: [1m[32m0.19893[0m[0m | time: 106.646s
[2K
| Adam | epoch: 004 | loss: 0.19893 - acc: 0.9424 -- iter: 0320/2068
[A[ATraining Step: 206  | total loss: [1m[32m0.18451[0m[0m | time: 114.775s
[2K
| Adam | epoch: 004 | loss: 0.18451 - acc: 0.9481 -- iter: 0352/2068
[A[ATraining Step: 207  | total loss: [1m[32m0.18511[0m[0m | time: 123.232s
[2K
| Adam | epoch: 004 | loss: 0.18511 - acc: 0.9377 -- iter: 0384/2068
[A[ATraining Step: 208  | total loss: [1m[32m0.17981[0m[0m | time: 131.409s
[2K
| Adam | epoch: 004 | loss: 0.17981 - acc: 0.9408 -- iter: 0416/2068
[A[ATraining Step: 209  | total loss: [1m[32m0.17325[0m[0m | time: 140.008s
[2K
| Adam | epoch: 004 | loss: 0.17325 - acc: 0.9436 -- iter: 0448/2068
[A[ATraining Step: 210  | total loss: [1m[32m0.16632[0m[0m | time: 148.185s
[2K
| Adam | epoch: 004 | loss: 0.16632 - acc: 0.9461 -- iter: 0480/2068
[A[ATraining Step: 211  | total loss: [1m[32m0.18237[0m[0m | time: 156.490s
[2K
| Adam | epoch: 004 | loss: 0.18237 - acc: 0.9390 -- iter: 0512/2068
[A[ATraining Step: 212  | total loss: [1m[32m0.19272[0m[0m | time: 164.625s
[2K
| Adam | epoch: 004 | loss: 0.19272 - acc: 0.9326 -- iter: 0544/2068
[A[ATraining Step: 213  | total loss: [1m[32m0.18467[0m[0m | time: 172.868s
[2K
| Adam | epoch: 004 | loss: 0.18467 - acc: 0.9362 -- iter: 0576/2068
[A[ATraining Step: 214  | total loss: [1m[32m0.19451[0m[0m | time: 180.954s
[2K
| Adam | epoch: 004 | loss: 0.19451 - acc: 0.9270 -- iter: 0608/2068
[A[ATraining Step: 215  | total loss: [1m[32m0.18238[0m[0m | time: 189.246s
[2K
| Adam | epoch: 004 | loss: 0.18238 - acc: 0.9343 -- iter: 0640/2068
[A[ATraining Step: 216  | total loss: [1m[32m0.17745[0m[0m | time: 197.269s
[2K
| Adam | epoch: 004 | loss: 0.17745 - acc: 0.9377 -- iter: 0672/2068
[A[ATraining Step: 217  | total loss: [1m[32m0.17692[0m[0m | time: 205.621s
[2K
| Adam | epoch: 004 | loss: 0.17692 - acc: 0.9377 -- iter: 0704/2068
[A[ATraining Step: 218  | total loss: [1m[32m0.17292[0m[0m | time: 214.029s
[2K
| Adam | epoch: 004 | loss: 0.17292 - acc: 0.9377 -- iter: 0736/2068
[A[ATraining Step: 219  | total loss: [1m[32m0.17624[0m[0m | time: 222.282s
[2K
| Adam | epoch: 004 | loss: 0.17624 - acc: 0.9345 -- iter: 0768/2068
[A[ATraining Step: 220  | total loss: [1m[32m0.17295[0m[0m | time: 230.447s
[2K
| Adam | epoch: 004 | loss: 0.17295 - acc: 0.9380 -- iter: 0800/2068
[A[ATraining Step: 221  | total loss: [1m[32m0.17657[0m[0m | time: 238.651s
[2K
| Adam | epoch: 004 | loss: 0.17657 - acc: 0.9379 -- iter: 0832/2068
[A[ATraining Step: 222  | total loss: [1m[32m0.16397[0m[0m | time: 247.274s
[2K
| Adam | epoch: 004 | loss: 0.16397 - acc: 0.9441 -- iter: 0864/2068
[A[ATraining Step: 223  | total loss: [1m[32m0.15844[0m[0m | time: 255.417s
[2K
| Adam | epoch: 004 | loss: 0.15844 - acc: 0.9435 -- iter: 0896/2068
[A[ATraining Step: 224  | total loss: [1m[32m0.16336[0m[0m | time: 263.566s
[2K
| Adam | epoch: 004 | loss: 0.16336 - acc: 0.9429 -- iter: 0928/2068
[A[ATraining Step: 225  | total loss: [1m[32m0.17167[0m[0m | time: 271.753s
[2K
| Adam | epoch: 004 | loss: 0.17167 - acc: 0.9392 -- iter: 0960/2068
[A[ATraining Step: 226  | total loss: [1m[32m0.16751[0m[0m | time: 280.009s
[2K
| Adam | epoch: 004 | loss: 0.16751 - acc: 0.9422 -- iter: 0992/2068
[A[ATraining Step: 227  | total loss: [1m[32m0.17920[0m[0m | time: 288.464s
[2K
| Adam | epoch: 004 | loss: 0.17920 - acc: 0.9354 -- iter: 1024/2068
[A[ATraining Step: 228  | total loss: [1m[32m0.19922[0m[0m | time: 296.695s
[2K
| Adam | epoch: 004 | loss: 0.19922 - acc: 0.9294 -- iter: 1056/2068
[A[ATraining Step: 229  | total loss: [1m[32m0.18643[0m[0m | time: 304.920s
[2K
| Adam | epoch: 004 | loss: 0.18643 - acc: 0.9365 -- iter: 1088/2068
[A[ATraining Step: 230  | total loss: [1m[32m0.17758[0m[0m | time: 313.163s
[2K
| Adam | epoch: 004 | loss: 0.17758 - acc: 0.9366 -- iter: 1120/2068
[A[ATraining Step: 231  | total loss: [1m[32m0.19066[0m[0m | time: 321.630s
[2K
| Adam | epoch: 004 | loss: 0.19066 - acc: 0.9304 -- iter: 1152/2068
[A[ATraining Step: 232  | total loss: [1m[32m0.18924[0m[0m | time: 330.206s
[2K
| Adam | epoch: 004 | loss: 0.18924 - acc: 0.9342 -- iter: 1184/2068
[A[ATraining Step: 233  | total loss: [1m[32m0.17820[0m[0m | time: 338.499s
[2K
| Adam | epoch: 004 | loss: 0.17820 - acc: 0.9408 -- iter: 1216/2068
[A[ATraining Step: 234  | total loss: [1m[32m0.17533[0m[0m | time: 346.973s
[2K
| Adam | epoch: 004 | loss: 0.17533 - acc: 0.9405 -- iter: 1248/2068
[A[ATraining Step: 235  | total loss: [1m[32m0.17479[0m[0m | time: 355.354s
[2K
| Adam | epoch: 004 | loss: 0.17479 - acc: 0.9402 -- iter: 1280/2068
[A[ATraining Step: 236  | total loss: [1m[32m0.16580[0m[0m | time: 363.721s
[2K
| Adam | epoch: 004 | loss: 0.16580 - acc: 0.9399 -- iter: 1312/2068
[A[ATraining Step: 237  | total loss: [1m[32m0.15971[0m[0m | time: 371.967s
[2K
| Adam | epoch: 004 | loss: 0.15971 - acc: 0.9428 -- iter: 1344/2068
[A[ATraining Step: 238  | total loss: [1m[32m0.16110[0m[0m | time: 380.266s
[2K
| Adam | epoch: 004 | loss: 0.16110 - acc: 0.9423 -- iter: 1376/2068
[A[ATraining Step: 239  | total loss: [1m[32m0.15053[0m[0m | time: 388.815s
[2K
| Adam | epoch: 004 | loss: 0.15053 - acc: 0.9480 -- iter: 1408/2068
[A[ATraining Step: 240  | total loss: [1m[32m0.15316[0m[0m | time: 397.226s
[2K
| Adam | epoch: 004 | loss: 0.15316 - acc: 0.9439 -- iter: 1440/2068
[A[ATraining Step: 241  | total loss: [1m[32m0.14440[0m[0m | time: 405.507s
[2K
| Adam | epoch: 004 | loss: 0.14440 - acc: 0.9464 -- iter: 1472/2068
[A[ATraining Step: 242  | total loss: [1m[32m0.13367[0m[0m | time: 413.763s
[2K
| Adam | epoch: 004 | loss: 0.13367 - acc: 0.9517 -- iter: 1504/2068
[A[ATraining Step: 243  | total loss: [1m[32m0.12372[0m[0m | time: 422.330s
[2K
| Adam | epoch: 004 | loss: 0.12372 - acc: 0.9565 -- iter: 1536/2068
[A[ATraining Step: 244  | total loss: [1m[32m0.11729[0m[0m | time: 430.815s
[2K
| Adam | epoch: 004 | loss: 0.11729 - acc: 0.9609 -- iter: 1568/2068
[A[ATraining Step: 245  | total loss: [1m[32m0.13264[0m[0m | time: 439.114s
[2K
| Adam | epoch: 004 | loss: 0.13264 - acc: 0.9586 -- iter: 1600/2068
[A[ATraining Step: 246  | total loss: [1m[32m0.14006[0m[0m | time: 447.810s
[2K
| Adam | epoch: 004 | loss: 0.14006 - acc: 0.9533 -- iter: 1632/2068
[A[ATraining Step: 247  | total loss: [1m[32m0.12924[0m[0m | time: 456.172s
[2K
| Adam | epoch: 004 | loss: 0.12924 - acc: 0.9580 -- iter: 1664/2068
[A[ATraining Step: 248  | total loss: [1m[32m0.12189[0m[0m | time: 464.620s
[2K
| Adam | epoch: 004 | loss: 0.12189 - acc: 0.9591 -- iter: 1696/2068
[A[ATraining Step: 249  | total loss: [1m[32m0.11298[0m[0m | time: 472.911s
[2K
| Adam | epoch: 004 | loss: 0.11298 - acc: 0.9632 -- iter: 1728/2068
[A[ATraining Step: 250  | total loss: [1m[32m0.10372[0m[0m | time: 481.520s
[2K
| Adam | epoch: 004 | loss: 0.10372 - acc: 0.9668 -- iter: 1760/2068
[A[ATraining Step: 251  | total loss: [1m[32m0.12528[0m[0m | time: 489.841s
[2K
| Adam | epoch: 004 | loss: 0.12528 - acc: 0.9545 -- iter: 1792/2068
[A[ATraining Step: 252  | total loss: [1m[32m0.12966[0m[0m | time: 498.533s
[2K
| Adam | epoch: 004 | loss: 0.12966 - acc: 0.9497 -- iter: 1824/2068
[A[ATraining Step: 253  | total loss: [1m[32m0.12029[0m[0m | time: 506.905s
[2K
| Adam | epoch: 004 | loss: 0.12029 - acc: 0.9547 -- iter: 1856/2068
[A[ATraining Step: 254  | total loss: [1m[32m0.11997[0m[0m | time: 515.093s
[2K
| Adam | epoch: 004 | loss: 0.11997 - acc: 0.9499 -- iter: 1888/2068
[A[ATraining Step: 255  | total loss: [1m[32m0.12268[0m[0m | time: 523.102s
[2K
| Adam | epoch: 004 | loss: 0.12268 - acc: 0.9455 -- iter: 1920/2068
[A[ATraining Step: 256  | total loss: [1m[32m0.11347[0m[0m | time: 531.535s
[2K
| Adam | epoch: 004 | loss: 0.11347 - acc: 0.9510 -- iter: 1952/2068
[A[ATraining Step: 257  | total loss: [1m[32m0.10602[0m[0m | time: 539.950s
[2K
| Adam | epoch: 004 | loss: 0.10602 - acc: 0.9559 -- iter: 1984/2068
[A[ATraining Step: 258  | total loss: [1m[32m0.11574[0m[0m | time: 548.498s
[2K
| Adam | epoch: 004 | loss: 0.11574 - acc: 0.9540 -- iter: 2016/2068
[A[ATraining Step: 259  | total loss: [1m[32m0.10899[0m[0m | time: 556.698s
[2K
| Adam | epoch: 004 | loss: 0.10899 - acc: 0.9586 -- iter: 2048/2068
[A[ATraining Step: 260  | total loss: [1m[32m0.11306[0m[0m | time: 596.063s
[2K
| Adam | epoch: 004 | loss: 0.11306 - acc: 0.9565 | val_loss: 0.50436 - val_acc: 0.8238 -- iter: 2068/2068
--
Training Step: 261  | total loss: [1m[32m0.12006[0m[0m | time: 10.683s
[2K
| Adam | epoch: 005 | loss: 0.12006 - acc: 0.9546 -- iter: 0032/2068
[A[ATraining Step: 262  | total loss: [1m[32m0.12546[0m[0m | time: 21.087s
[2K
| Adam | epoch: 005 | loss: 0.12546 - acc: 0.9529 -- iter: 0064/2068
[A[ATraining Step: 263  | total loss: [1m[32m0.12484[0m[0m | time: 28.018s
[2K
| Adam | epoch: 005 | loss: 0.12484 - acc: 0.9514 -- iter: 0096/2068
[A[ATraining Step: 264  | total loss: [1m[32m0.12281[0m[0m | time: 35.338s
[2K
| Adam | epoch: 005 | loss: 0.12281 - acc: 0.9462 -- iter: 0128/2068
[A[ATraining Step: 265  | total loss: [1m[32m0.11388[0m[0m | time: 55.669s
[2K
| Adam | epoch: 005 | loss: 0.11388 - acc: 0.9516 -- iter: 0160/2068
[A[ATraining Step: 266  | total loss: [1m[32m0.11382[0m[0m | time: 66.105s
[2K
| Adam | epoch: 005 | loss: 0.11382 - acc: 0.9502 -- iter: 0192/2068
[A[ATraining Step: 267  | total loss: [1m[32m0.11254[0m[0m | time: 76.444s
[2K
| Adam | epoch: 005 | loss: 0.11254 - acc: 0.9521 -- iter: 0224/2068
[A[ATraining Step: 268  | total loss: [1m[32m0.13650[0m[0m | time: 87.820s
[2K
| Adam | epoch: 005 | loss: 0.13650 - acc: 0.9443 -- iter: 0256/2068
[A[ATraining Step: 269  | total loss: [1m[32m0.13692[0m[0m | time: 98.260s
[2K
| Adam | epoch: 005 | loss: 0.13692 - acc: 0.9437 -- iter: 0288/2068
[A[ATraining Step: 270  | total loss: [1m[32m0.13243[0m[0m | time: 108.405s
[2K
| Adam | epoch: 005 | loss: 0.13243 - acc: 0.9462 -- iter: 0320/2068
[A[ATraining Step: 271  | total loss: [1m[32m0.13790[0m[0m | time: 119.454s
[2K
| Adam | epoch: 005 | loss: 0.13790 - acc: 0.9422 -- iter: 0352/2068
[A[ATraining Step: 272  | total loss: [1m[32m0.13998[0m[0m | time: 136.653s
[2K
| Adam | epoch: 005 | loss: 0.13998 - acc: 0.9417 -- iter: 0384/2068
[A[ATraining Step: 273  | total loss: [1m[32m0.14999[0m[0m | time: 147.181s
[2K
| Adam | epoch: 005 | loss: 0.14999 - acc: 0.9382 -- iter: 0416/2068
[A[ATraining Step: 274  | total loss: [1m[32m0.19005[0m[0m | time: 157.954s
[2K
| Adam | epoch: 005 | loss: 0.19005 - acc: 0.9318 -- iter: 0448/2068
[A[ATraining Step: 275  | total loss: [1m[32m0.18371[0m[0m | time: 168.297s
[2K
| Adam | epoch: 005 | loss: 0.18371 - acc: 0.9324 -- iter: 0480/2068
[A[ATraining Step: 276  | total loss: [1m[32m0.17831[0m[0m | time: 178.911s
[2K
| Adam | epoch: 005 | loss: 0.17831 - acc: 0.9329 -- iter: 0512/2068
[A[ATraining Step: 277  | total loss: [1m[32m0.16537[0m[0m | time: 189.821s
[2K
| Adam | epoch: 005 | loss: 0.16537 - acc: 0.9365 -- iter: 0544/2068
[A[ATraining Step: 278  | total loss: [1m[32m0.16021[0m[0m | time: 200.705s
[2K
| Adam | epoch: 005 | loss: 0.16021 - acc: 0.9397 -- iter: 0576/2068
[A[ATraining Step: 279  | total loss: [1m[32m0.15195[0m[0m | time: 210.980s
[2K
| Adam | epoch: 005 | loss: 0.15195 - acc: 0.9426 -- iter: 0608/2068
[A[ATraining Step: 280  | total loss: [1m[32m0.15744[0m[0m | time: 221.373s
[2K
| Adam | epoch: 005 | loss: 0.15744 - acc: 0.9390 -- iter: 0640/2068
[A[ATraining Step: 281  | total loss: [1m[32m0.14780[0m[0m | time: 232.644s
[2K
| Adam | epoch: 005 | loss: 0.14780 - acc: 0.9451 -- iter: 0672/2068
[A[ATraining Step: 282  | total loss: [1m[32m0.15490[0m[0m | time: 243.456s
[2K
| Adam | epoch: 005 | loss: 0.15490 - acc: 0.9443 -- iter: 0704/2068
[A[ATraining Step: 283  | total loss: [1m[32m0.14261[0m[0m | time: 254.370s
[2K
| Adam | epoch: 005 | loss: 0.14261 - acc: 0.9499 -- iter: 0736/2068
[A[ATraining Step: 284  | total loss: [1m[32m0.15764[0m[0m | time: 265.127s
[2K
| Adam | epoch: 005 | loss: 0.15764 - acc: 0.9393 -- iter: 0768/2068
[A[ATraining Step: 285  | total loss: [1m[32m0.15791[0m[0m | time: 275.794s
[2K
| Adam | epoch: 005 | loss: 0.15791 - acc: 0.9391 -- iter: 0800/2068
[A[ATraining Step: 286  | total loss: [1m[32m0.14651[0m[0m | time: 286.133s
[2K
| Adam | epoch: 005 | loss: 0.14651 - acc: 0.9452 -- iter: 0832/2068
[A[ATraining Step: 287  | total loss: [1m[32m0.16058[0m[0m | time: 297.339s
[2K
| Adam | epoch: 005 | loss: 0.16058 - acc: 0.9413 -- iter: 0864/2068
[A[ATraining Step: 288  | total loss: [1m[32m0.17439[0m[0m | time: 307.636s
[2K
| Adam | epoch: 005 | loss: 0.17439 - acc: 0.9347 -- iter: 0896/2068
[A[ATraining Step: 289  | total loss: [1m[32m0.16392[0m[0m | time: 318.130s
[2K
| Adam | epoch: 005 | loss: 0.16392 - acc: 0.9381 -- iter: 0928/2068
[A[ATraining Step: 290  | total loss: [1m[32m0.17235[0m[0m | time: 328.748s
[2K
| Adam | epoch: 005 | loss: 0.17235 - acc: 0.9318 -- iter: 0960/2068
[A[ATraining Step: 291  | total loss: [1m[32m0.19946[0m[0m | time: 339.289s
[2K
| Adam | epoch: 005 | loss: 0.19946 - acc: 0.9261 -- iter: 0992/2068
[A[ATraining Step: 292  | total loss: [1m[32m0.20051[0m[0m | time: 349.809s
[2K
| Adam | epoch: 005 | loss: 0.20051 - acc: 0.9241 -- iter: 1024/2068
[A[ATraining Step: 293  | total loss: [1m[32m0.19122[0m[0m | time: 360.277s
[2K
| Adam | epoch: 005 | loss: 0.19122 - acc: 0.9254 -- iter: 1056/2068
[A[ATraining Step: 294  | total loss: [1m[32m0.24195[0m[0m | time: 371.287s
[2K
| Adam | epoch: 005 | loss: 0.24195 - acc: 0.9173 -- iter: 1088/2068
[A[ATraining Step: 295  | total loss: [1m[32m0.22701[0m[0m | time: 382.479s
[2K
| Adam | epoch: 005 | loss: 0.22701 - acc: 0.9224 -- iter: 1120/2068
[A[ATraining Step: 296  | total loss: [1m[32m0.21038[0m[0m | time: 393.227s
[2K
| Adam | epoch: 005 | loss: 0.21038 - acc: 0.9302 -- iter: 1152/2068
[A[ATraining Step: 297  | total loss: [1m[32m0.20845[0m[0m | time: 404.298s
[2K
| Adam | epoch: 005 | loss: 0.20845 - acc: 0.9309 -- iter: 1184/2068
[A[ATraining Step: 298  | total loss: [1m[32m0.22539[0m[0m | time: 414.495s
[2K
| Adam | epoch: 005 | loss: 0.22539 - acc: 0.9284 -- iter: 1216/2068
[A[ATraining Step: 299  | total loss: [1m[32m0.20757[0m[0m | time: 424.849s
[2K
| Adam | epoch: 005 | loss: 0.20757 - acc: 0.9356 -- iter: 1248/2068
[A[ATraining Step: 300  | total loss: [1m[32m0.19882[0m[0m | time: 435.597s
[2K
| Adam | epoch: 005 | loss: 0.19882 - acc: 0.9358 -- iter: 1280/2068
[A[ATraining Step: 301  | total loss: [1m[32m0.18889[0m[0m | time: 446.025s
[2K
| Adam | epoch: 005 | loss: 0.18889 - acc: 0.9391 -- iter: 1312/2068
[A[ATraining Step: 302  | total loss: [1m[32m0.17396[0m[0m | time: 456.980s
[2K
| Adam | epoch: 005 | loss: 0.17396 - acc: 0.9452 -- iter: 1344/2068
[A[ATraining Step: 303  | total loss: [1m[32m0.16824[0m[0m | time: 467.764s
[2K
| Adam | epoch: 005 | loss: 0.16824 - acc: 0.9475 -- iter: 1376/2068
[A[ATraining Step: 304  | total loss: [1m[32m0.17681[0m[0m | time: 478.589s
[2K
| Adam | epoch: 005 | loss: 0.17681 - acc: 0.9465 -- iter: 1408/2068
[A[ATraining Step: 305  | total loss: [1m[32m0.16577[0m[0m | time: 489.095s
[2K
| Adam | epoch: 005 | loss: 0.16577 - acc: 0.9519 -- iter: 1440/2068
[A[ATraining Step: 306  | total loss: [1m[32m0.15556[0m[0m | time: 499.962s
[2K
| Adam | epoch: 005 | loss: 0.15556 - acc: 0.9536 -- iter: 1472/2068
[A[ATraining Step: 307  | total loss: [1m[32m0.14771[0m[0m | time: 510.956s
[2K
| Adam | epoch: 005 | loss: 0.14771 - acc: 0.9551 -- iter: 1504/2068
[A[ATraining Step: 308  | total loss: [1m[32m0.13886[0m[0m | time: 521.470s
[2K
| Adam | epoch: 005 | loss: 0.13886 - acc: 0.9596 -- iter: 1536/2068
[A[ATraining Step: 309  | total loss: [1m[32m0.13449[0m[0m | time: 531.568s
[2K
| Adam | epoch: 005 | loss: 0.13449 - acc: 0.9574 -- iter: 1568/2068
[A[ATraining Step: 310  | total loss: [1m[32m0.12309[0m[0m | time: 542.019s
[2K
| Adam | epoch: 005 | loss: 0.12309 - acc: 0.9616 -- iter: 1600/2068
[A[ATraining Step: 311  | total loss: [1m[32m0.12815[0m[0m | time: 552.487s
[2K
| Adam | epoch: 005 | loss: 0.12815 - acc: 0.9592 -- iter: 1632/2068
[A[ATraining Step: 312  | total loss: [1m[32m0.12019[0m[0m | time: 562.700s
[2K
| Adam | epoch: 005 | loss: 0.12019 - acc: 0.9633 -- iter: 1664/2068
[A[ATraining Step: 313  | total loss: [1m[32m0.12049[0m[0m | time: 573.426s
[2K
| Adam | epoch: 005 | loss: 0.12049 - acc: 0.9638 -- iter: 1696/2068
[A[ATraining Step: 314  | total loss: [1m[32m0.11189[0m[0m | time: 584.535s
[2K
| Adam | epoch: 005 | loss: 0.11189 - acc: 0.9675 -- iter: 1728/2068
[A[ATraining Step: 315  | total loss: [1m[32m0.10398[0m[0m | time: 595.095s
[2K
| Adam | epoch: 005 | loss: 0.10398 - acc: 0.9707 -- iter: 1760/2068
[A[ATraining Step: 316  | total loss: [1m[32m0.09543[0m[0m | time: 605.268s
[2K
| Adam | epoch: 005 | loss: 0.09543 - acc: 0.9736 -- iter: 1792/2068
[A[ATraining Step: 317  | total loss: [1m[32m0.08708[0m[0m | time: 616.401s
[2K
| Adam | epoch: 005 | loss: 0.08708 - acc: 0.9763 -- iter: 1824/2068
[A[ATraining Step: 318  | total loss: [1m[32m0.08053[0m[0m | time: 626.554s
[2K
| Adam | epoch: 005 | loss: 0.08053 - acc: 0.9786 -- iter: 1856/2068
[A[ATraining Step: 319  | total loss: [1m[32m0.08209[0m[0m | time: 636.672s
[2K
| Adam | epoch: 005 | loss: 0.08209 - acc: 0.9777 -- iter: 1888/2068
[A[ATraining Step: 320  | total loss: [1m[32m0.07790[0m[0m | time: 647.275s
[2K
| Adam | epoch: 005 | loss: 0.07790 - acc: 0.9799 -- iter: 1920/2068
[A[ATraining Step: 321  | total loss: [1m[32m0.07354[0m[0m | time: 657.665s
[2K
| Adam | epoch: 005 | loss: 0.07354 - acc: 0.9819 -- iter: 1952/2068
[A[ATraining Step: 322  | total loss: [1m[32m0.07942[0m[0m | time: 667.984s
[2K
| Adam | epoch: 005 | loss: 0.07942 - acc: 0.9806 -- iter: 1984/2068
[A[ATraining Step: 323  | total loss: [1m[32m0.07411[0m[0m | time: 678.791s
[2K
| Adam | epoch: 005 | loss: 0.07411 - acc: 0.9825 -- iter: 2016/2068
[A[ATraining Step: 324  | total loss: [1m[32m0.06874[0m[0m | time: 689.104s
[2K
| Adam | epoch: 005 | loss: 0.06874 - acc: 0.9843 -- iter: 2048/2068
[A[ATraining Step: 325  | total loss: [1m[32m0.06688[0m[0m | time: 736.738s
[2K
| Adam | epoch: 005 | loss: 0.06688 - acc: 0.9858 | val_loss: 2.05992 - val_acc: 0.6399 -- iter: 2068/2068
--
Training Step: 326  | total loss: [1m[32m0.06094[0m[0m | time: 10.547s
[2K
| Adam | epoch: 006 | loss: 0.06094 - acc: 0.9873 -- iter: 0032/2068
[A[ATraining Step: 327  | total loss: [1m[32m0.06014[0m[0m | time: 21.022s
[2K
| Adam | epoch: 006 | loss: 0.06014 - acc: 0.9854 -- iter: 0064/2068
[A[ATraining Step: 328  | total loss: [1m[32m0.05590[0m[0m | time: 31.157s
[2K
| Adam | epoch: 006 | loss: 0.05590 - acc: 0.9869 -- iter: 0096/2068
[A[ATraining Step: 329  | total loss: [1m[32m0.05287[0m[0m | time: 38.011s
[2K
| Adam | epoch: 006 | loss: 0.05287 - acc: 0.9882 -- iter: 0128/2068
[A[ATraining Step: 330  | total loss: [1m[32m0.05941[0m[0m | time: 45.086s
[2K
| Adam | epoch: 006 | loss: 0.05941 - acc: 0.9844 -- iter: 0160/2068
[A[ATraining Step: 331  | total loss: [1m[32m0.05501[0m[0m | time: 56.110s
[2K
| Adam | epoch: 006 | loss: 0.05501 - acc: 0.9859 -- iter: 0192/2068
[A[ATraining Step: 332  | total loss: [1m[32m0.05611[0m[0m | time: 66.162s
[2K
| Adam | epoch: 006 | loss: 0.05611 - acc: 0.9842 -- iter: 0224/2068
[A[ATraining Step: 333  | total loss: [1m[32m0.05265[0m[0m | time: 76.106s
[2K
| Adam | epoch: 006 | loss: 0.05265 - acc: 0.9858 -- iter: 0256/2068
[A[ATraining Step: 334  | total loss: [1m[32m0.07240[0m[0m | time: 86.964s
[2K
| Adam | epoch: 006 | loss: 0.07240 - acc: 0.9841 -- iter: 0288/2068
[A[ATraining Step: 335  | total loss: [1m[32m0.09128[0m[0m | time: 97.173s
[2K
| Adam | epoch: 006 | loss: 0.09128 - acc: 0.9794 -- iter: 0320/2068
[A[ATraining Step: 336  | total loss: [1m[32m0.10270[0m[0m | time: 107.030s
[2K
| Adam | epoch: 006 | loss: 0.10270 - acc: 0.9752 -- iter: 0352/2068
[A[ATraining Step: 337  | total loss: [1m[32m0.09393[0m[0m | time: 117.813s
[2K
| Adam | epoch: 006 | loss: 0.09393 - acc: 0.9777 -- iter: 0384/2068
[A[ATraining Step: 338  | total loss: [1m[32m0.09183[0m[0m | time: 127.829s
[2K
| Adam | epoch: 006 | loss: 0.09183 - acc: 0.9768 -- iter: 0416/2068
[A[ATraining Step: 339  | total loss: [1m[32m0.09542[0m[0m | time: 137.894s
[2K
| Adam | epoch: 006 | loss: 0.09542 - acc: 0.9729 -- iter: 0448/2068
[A[ATraining Step: 340  | total loss: [1m[32m0.10027[0m[0m | time: 148.248s
[2K
| Adam | epoch: 006 | loss: 0.10027 - acc: 0.9693 -- iter: 0480/2068
[A[ATraining Step: 341  | total loss: [1m[32m0.10270[0m[0m | time: 158.241s
[2K
| Adam | epoch: 006 | loss: 0.10270 - acc: 0.9693 -- iter: 0512/2068
[A[ATraining Step: 342  | total loss: [1m[32m0.09592[0m[0m | time: 168.424s
[2K
| Adam | epoch: 006 | loss: 0.09592 - acc: 0.9724 -- iter: 0544/2068
[A[ATraining Step: 343  | total loss: [1m[32m0.09119[0m[0m | time: 178.516s
[2K
| Adam | epoch: 006 | loss: 0.09119 - acc: 0.9720 -- iter: 0576/2068
[A[ATraining Step: 344  | total loss: [1m[32m0.08749[0m[0m | time: 189.037s
[2K
| Adam | epoch: 006 | loss: 0.08749 - acc: 0.9717 -- iter: 0608/2068
[A[ATraining Step: 345  | total loss: [1m[32m0.10077[0m[0m | time: 199.221s
[2K
| Adam | epoch: 006 | loss: 0.10077 - acc: 0.9683 -- iter: 0640/2068
[A[ATraining Step: 346  | total loss: [1m[32m0.09277[0m[0m | time: 209.849s
[2K
| Adam | epoch: 006 | loss: 0.09277 - acc: 0.9714 -- iter: 0672/2068
[A[ATraining Step: 347  | total loss: [1m[32m0.08683[0m[0m | time: 220.358s
[2K
| Adam | epoch: 006 | loss: 0.08683 - acc: 0.9743 -- iter: 0704/2068
[A[ATraining Step: 348  | total loss: [1m[32m0.07923[0m[0m | time: 230.565s
[2K
| Adam | epoch: 006 | loss: 0.07923 - acc: 0.9769 -- iter: 0736/2068
[A[ATraining Step: 349  | total loss: [1m[32m0.12625[0m[0m | time: 240.290s
[2K
| Adam | epoch: 006 | loss: 0.12625 - acc: 0.9667 -- iter: 0768/2068
[A[ATraining Step: 350  | total loss: [1m[32m0.11713[0m[0m | time: 250.756s
[2K
| Adam | epoch: 006 | loss: 0.11713 - acc: 0.9700 -- iter: 0800/2068
[A[ATraining Step: 351  | total loss: [1m[32m0.10746[0m[0m | time: 280.002s
[2K
| Adam | epoch: 006 | loss: 0.10746 - acc: 0.9730 -- iter: 0832/2068
[A[ATraining Step: 352  | total loss: [1m[32m0.10517[0m[0m | time: 287.974s
[2K
| Adam | epoch: 006 | loss: 0.10517 - acc: 0.9695 -- iter: 0864/2068
[A[ATraining Step: 353  | total loss: [1m[32m0.09622[0m[0m | time: 296.078s
[2K
| Adam | epoch: 006 | loss: 0.09622 - acc: 0.9725 -- iter: 0896/2068
[A[ATraining Step: 354  | total loss: [1m[32m0.09034[0m[0m | time: 304.170s
[2K
| Adam | epoch: 006 | loss: 0.09034 - acc: 0.9721 -- iter: 0928/2068
[A[ATraining Step: 355  | total loss: [1m[32m0.08421[0m[0m | time: 312.273s
[2K
| Adam | epoch: 006 | loss: 0.08421 - acc: 0.9749 -- iter: 0960/2068
[A[ATraining Step: 356  | total loss: [1m[32m0.09425[0m[0m | time: 320.194s
[2K
| Adam | epoch: 006 | loss: 0.09425 - acc: 0.9681 -- iter: 0992/2068
[A[ATraining Step: 357  | total loss: [1m[32m0.09218[0m[0m | time: 328.141s
[2K
| Adam | epoch: 006 | loss: 0.09218 - acc: 0.9712 -- iter: 1024/2068
[A[ATraining Step: 358  | total loss: [1m[32m0.09949[0m[0m | time: 336.088s
[2K
| Adam | epoch: 006 | loss: 0.09949 - acc: 0.9710 -- iter: 1056/2068
[A[ATraining Step: 359  | total loss: [1m[32m0.11323[0m[0m | time: 344.106s
[2K
| Adam | epoch: 006 | loss: 0.11323 - acc: 0.9645 -- iter: 1088/2068
[A[ATraining Step: 360  | total loss: [1m[32m0.12240[0m[0m | time: 352.038s
[2K
| Adam | epoch: 006 | loss: 0.12240 - acc: 0.9649 -- iter: 1120/2068
[A[ATraining Step: 361  | total loss: [1m[32m0.11837[0m[0m | time: 360.147s
[2K
| Adam | epoch: 006 | loss: 0.11837 - acc: 0.9685 -- iter: 1152/2068
[A[ATraining Step: 362  | total loss: [1m[32m0.12956[0m[0m | time: 368.247s
[2K
| Adam | epoch: 006 | loss: 0.12956 - acc: 0.9654 -- iter: 1184/2068
[A[ATraining Step: 363  | total loss: [1m[32m0.12677[0m[0m | time: 376.296s
[2K
| Adam | epoch: 006 | loss: 0.12677 - acc: 0.9626 -- iter: 1216/2068
[A[ATraining Step: 364  | total loss: [1m[32m0.12268[0m[0m | time: 384.080s
[2K
| Adam | epoch: 006 | loss: 0.12268 - acc: 0.9632 -- iter: 1248/2068
[A[ATraining Step: 365  | total loss: [1m[32m0.12130[0m[0m | time: 392.112s
[2K
| Adam | epoch: 006 | loss: 0.12130 - acc: 0.9637 -- iter: 1280/2068
[A[ATraining Step: 366  | total loss: [1m[32m0.11092[0m[0m | time: 400.047s
[2K
| Adam | epoch: 006 | loss: 0.11092 - acc: 0.9674 -- iter: 1312/2068
[A[ATraining Step: 367  | total loss: [1m[32m0.11865[0m[0m | time: 408.133s
[2K
| Adam | epoch: 006 | loss: 0.11865 - acc: 0.9613 -- iter: 1344/2068
[A[ATraining Step: 368  | total loss: [1m[32m0.10775[0m[0m | time: 416.234s
[2K
| Adam | epoch: 006 | loss: 0.10775 - acc: 0.9651 -- iter: 1376/2068
[A[ATraining Step: 369  | total loss: [1m[32m0.09972[0m[0m | time: 424.309s
[2K
| Adam | epoch: 006 | loss: 0.09972 - acc: 0.9686 -- iter: 1408/2068
[A[ATraining Step: 370  | total loss: [1m[32m0.09704[0m[0m | time: 432.334s
[2K
| Adam | epoch: 006 | loss: 0.09704 - acc: 0.9686 -- iter: 1440/2068
[A[ATraining Step: 371  | total loss: [1m[32m0.09794[0m[0m | time: 440.336s
[2K
| Adam | epoch: 006 | loss: 0.09794 - acc: 0.9686 -- iter: 1472/2068
[A[ATraining Step: 372  | total loss: [1m[32m0.09648[0m[0m | time: 448.357s
[2K
| Adam | epoch: 006 | loss: 0.09648 - acc: 0.9687 -- iter: 1504/2068
[A[ATraining Step: 373  | total loss: [1m[32m0.10802[0m[0m | time: 456.215s
[2K
| Adam | epoch: 006 | loss: 0.10802 - acc: 0.9624 -- iter: 1536/2068
[A[ATraining Step: 374  | total loss: [1m[32m0.10436[0m[0m | time: 464.298s
[2K
| Adam | epoch: 006 | loss: 0.10436 - acc: 0.9662 -- iter: 1568/2068
[A[ATraining Step: 375  | total loss: [1m[32m0.10437[0m[0m | time: 472.292s
[2K
| Adam | epoch: 006 | loss: 0.10437 - acc: 0.9664 -- iter: 1600/2068
[A[ATraining Step: 376  | total loss: [1m[32m0.10476[0m[0m | time: 480.581s
[2K
| Adam | epoch: 006 | loss: 0.10476 - acc: 0.9667 -- iter: 1632/2068
[A[ATraining Step: 377  | total loss: [1m[32m0.10374[0m[0m | time: 488.798s
[2K
| Adam | epoch: 006 | loss: 0.10374 - acc: 0.9669 -- iter: 1664/2068
[A[ATraining Step: 378  | total loss: [1m[32m0.09993[0m[0m | time: 496.827s
[2K
| Adam | epoch: 006 | loss: 0.09993 - acc: 0.9671 -- iter: 1696/2068
[A[ATraining Step: 379  | total loss: [1m[32m0.09334[0m[0m | time: 504.676s
[2K
| Adam | epoch: 006 | loss: 0.09334 - acc: 0.9704 -- iter: 1728/2068
[A[ATraining Step: 380  | total loss: [1m[32m0.08849[0m[0m | time: 512.744s
[2K
| Adam | epoch: 006 | loss: 0.08849 - acc: 0.9733 -- iter: 1760/2068
[A[ATraining Step: 381  | total loss: [1m[32m0.08812[0m[0m | time: 520.988s
[2K
| Adam | epoch: 006 | loss: 0.08812 - acc: 0.9697 -- iter: 1792/2068
[A[ATraining Step: 382  | total loss: [1m[32m0.08272[0m[0m | time: 529.109s
[2K
| Adam | epoch: 006 | loss: 0.08272 - acc: 0.9728 -- iter: 1824/2068
[A[ATraining Step: 383  | total loss: [1m[32m0.09456[0m[0m | time: 537.028s
[2K
| Adam | epoch: 006 | loss: 0.09456 - acc: 0.9630 -- iter: 1856/2068
[A[ATraining Step: 384  | total loss: [1m[32m0.08906[0m[0m | time: 545.055s
[2K
| Adam | epoch: 006 | loss: 0.08906 - acc: 0.9667 -- iter: 1888/2068
[A[ATraining Step: 385  | total loss: [1m[32m0.08226[0m[0m | time: 553.094s
[2K
| Adam | epoch: 006 | loss: 0.08226 - acc: 0.9700 -- iter: 1920/2068
[A[ATraining Step: 386  | total loss: [1m[32m0.07568[0m[0m | time: 561.200s
[2K
| Adam | epoch: 006 | loss: 0.07568 - acc: 0.9730 -- iter: 1952/2068
[A[ATraining Step: 387  | total loss: [1m[32m0.06961[0m[0m | time: 569.135s
[2K
| Adam | epoch: 006 | loss: 0.06961 - acc: 0.9757 -- iter: 1984/2068
[A[ATraining Step: 388  | total loss: [1m[32m0.06686[0m[0m | time: 576.909s
[2K
| Adam | epoch: 006 | loss: 0.06686 - acc: 0.9750 -- iter: 2016/2068
[A[ATraining Step: 389  | total loss: [1m[32m0.09022[0m[0m | time: 584.986s
[2K
| Adam | epoch: 006 | loss: 0.09022 - acc: 0.9650 -- iter: 2048/2068
[A[ATraining Step: 390  | total loss: [1m[32m0.08571[0m[0m | time: 621.909s
[2K
| Adam | epoch: 006 | loss: 0.08571 - acc: 0.9654 | val_loss: 0.79623 - val_acc: 0.7821 -- iter: 2068/2068
--
Training Step: 391  | total loss: [1m[32m0.07905[0m[0m | time: 8.007s
[2K
| Adam | epoch: 007 | loss: 0.07905 - acc: 0.9689 -- iter: 0032/2068
[A[ATraining Step: 392  | total loss: [1m[32m0.07788[0m[0m | time: 16.000s
[2K
| Adam | epoch: 007 | loss: 0.07788 - acc: 0.9688 -- iter: 0064/2068
[A[ATraining Step: 393  | total loss: [1m[32m0.07750[0m[0m | time: 24.168s
[2K
| Adam | epoch: 007 | loss: 0.07750 - acc: 0.9688 -- iter: 0096/2068
[A[ATraining Step: 394  | total loss: [1m[32m0.10449[0m[0m | time: 32.093s
[2K
| Adam | epoch: 007 | loss: 0.10449 - acc: 0.9563 -- iter: 0128/2068
[A[ATraining Step: 395  | total loss: [1m[32m0.09807[0m[0m | time: 37.605s
[2K
| Adam | epoch: 007 | loss: 0.09807 - acc: 0.9607 -- iter: 0160/2068
[A[ATraining Step: 396  | total loss: [1m[32m0.11303[0m[0m | time: 43.160s
[2K
| Adam | epoch: 007 | loss: 0.11303 - acc: 0.9596 -- iter: 0192/2068
[A[ATraining Step: 397  | total loss: [1m[32m0.10624[0m[0m | time: 51.004s
[2K
| Adam | epoch: 007 | loss: 0.10624 - acc: 0.9637 -- iter: 0224/2068
[A[ATraining Step: 398  | total loss: [1m[32m0.11356[0m[0m | time: 58.997s
[2K
| Adam | epoch: 007 | loss: 0.11356 - acc: 0.9579 -- iter: 0256/2068
[A[ATraining Step: 399  | total loss: [1m[32m0.11439[0m[0m | time: 67.128s
[2K
| Adam | epoch: 007 | loss: 0.11439 - acc: 0.9528 -- iter: 0288/2068
[A[ATraining Step: 400  | total loss: [1m[32m0.10838[0m[0m | time: 103.834s
[2K
| Adam | epoch: 007 | loss: 0.10838 - acc: 0.9575 | val_loss: 0.45553 - val_acc: 0.8887 -- iter: 0320/2068
--
Training Step: 401  | total loss: [1m[32m0.12371[0m[0m | time: 111.862s
[2K
| Adam | epoch: 007 | loss: 0.12371 - acc: 0.9555 -- iter: 0352/2068
[A[ATraining Step: 402  | total loss: [1m[32m0.16784[0m[0m | time: 119.841s
[2K
| Adam | epoch: 007 | loss: 0.16784 - acc: 0.9506 -- iter: 0384/2068
[A[ATraining Step: 403  | total loss: [1m[32m0.16513[0m[0m | time: 127.697s
[2K
| Adam | epoch: 007 | loss: 0.16513 - acc: 0.9493 -- iter: 0416/2068
[A[ATraining Step: 404  | total loss: [1m[32m0.16722[0m[0m | time: 135.791s
[2K
| Adam | epoch: 007 | loss: 0.16722 - acc: 0.9450 -- iter: 0448/2068
[A[ATraining Step: 405  | total loss: [1m[32m0.15693[0m[0m | time: 143.690s
[2K
| Adam | epoch: 007 | loss: 0.15693 - acc: 0.9473 -- iter: 0480/2068
[A[ATraining Step: 406  | total loss: [1m[32m0.15070[0m[0m | time: 151.698s
[2K
| Adam | epoch: 007 | loss: 0.15070 - acc: 0.9463 -- iter: 0512/2068
[A[ATraining Step: 407  | total loss: [1m[32m0.14260[0m[0m | time: 159.740s
[2K
| Adam | epoch: 007 | loss: 0.14260 - acc: 0.9486 -- iter: 0544/2068
[A[ATraining Step: 408  | total loss: [1m[32m0.13638[0m[0m | time: 167.710s
[2K
| Adam | epoch: 007 | loss: 0.13638 - acc: 0.9475 -- iter: 0576/2068
[A[ATraining Step: 409  | total loss: [1m[32m0.13418[0m[0m | time: 175.731s
[2K
| Adam | epoch: 007 | loss: 0.13418 - acc: 0.9465 -- iter: 0608/2068
[A[ATraining Step: 410  | total loss: [1m[32m0.14477[0m[0m | time: 183.749s
[2K
| Adam | epoch: 007 | loss: 0.14477 - acc: 0.9456 -- iter: 0640/2068
[A[ATraining Step: 411  | total loss: [1m[32m0.13303[0m[0m | time: 191.620s
[2K
| Adam | epoch: 007 | loss: 0.13303 - acc: 0.9510 -- iter: 0672/2068
[A[ATraining Step: 412  | total loss: [1m[32m0.12770[0m[0m | time: 199.433s
[2K
| Adam | epoch: 007 | loss: 0.12770 - acc: 0.9528 -- iter: 0704/2068
[A[ATraining Step: 413  | total loss: [1m[32m0.12772[0m[0m | time: 207.411s
[2K
| Adam | epoch: 007 | loss: 0.12772 - acc: 0.9513 -- iter: 0736/2068
[A[ATraining Step: 414  | total loss: [1m[32m0.14864[0m[0m | time: 215.404s
[2K
| Adam | epoch: 007 | loss: 0.14864 - acc: 0.9499 -- iter: 0768/2068
[A[ATraining Step: 415  | total loss: [1m[32m0.13812[0m[0m | time: 223.284s
[2K
| Adam | epoch: 007 | loss: 0.13812 - acc: 0.9518 -- iter: 0800/2068
[A[ATraining Step: 416  | total loss: [1m[32m0.13135[0m[0m | time: 231.182s
[2K
| Adam | epoch: 007 | loss: 0.13135 - acc: 0.9535 -- iter: 0832/2068
[A[ATraining Step: 417  | total loss: [1m[32m0.12460[0m[0m | time: 238.998s
[2K
| Adam | epoch: 007 | loss: 0.12460 - acc: 0.9550 -- iter: 0864/2068
[A[ATraining Step: 418  | total loss: [1m[32m0.12753[0m[0m | time: 246.925s
[2K
| Adam | epoch: 007 | loss: 0.12753 - acc: 0.9533 -- iter: 0896/2068
[A[ATraining Step: 419  | total loss: [1m[32m0.11913[0m[0m | time: 254.887s
[2K
| Adam | epoch: 007 | loss: 0.11913 - acc: 0.9579 -- iter: 0928/2068
[A[ATraining Step: 420  | total loss: [1m[32m0.15844[0m[0m | time: 262.867s
[2K
| Adam | epoch: 007 | loss: 0.15844 - acc: 0.9465 -- iter: 0960/2068
[A[ATraining Step: 421  | total loss: [1m[32m0.17635[0m[0m | time: 270.998s
[2K
| Adam | epoch: 007 | loss: 0.17635 - acc: 0.9425 -- iter: 0992/2068
[A[ATraining Step: 422  | total loss: [1m[32m0.17005[0m[0m | time: 278.902s
[2K
| Adam | epoch: 007 | loss: 0.17005 - acc: 0.9420 -- iter: 1024/2068
[A[ATraining Step: 423  | total loss: [1m[32m0.15646[0m[0m | time: 286.949s
[2K
| Adam | epoch: 007 | loss: 0.15646 - acc: 0.9478 -- iter: 1056/2068
[A[ATraining Step: 424  | total loss: [1m[32m0.14254[0m[0m | time: 294.909s
[2K
| Adam | epoch: 007 | loss: 0.14254 - acc: 0.9530 -- iter: 1088/2068
[A[ATraining Step: 425  | total loss: [1m[32m0.13297[0m[0m | time: 302.925s
[2K
| Adam | epoch: 007 | loss: 0.13297 - acc: 0.9577 -- iter: 1120/2068
[A[ATraining Step: 426  | total loss: [1m[32m0.12622[0m[0m | time: 310.938s
[2K
| Adam | epoch: 007 | loss: 0.12622 - acc: 0.9619 -- iter: 1152/2068
[A[ATraining Step: 427  | total loss: [1m[32m0.11586[0m[0m | time: 318.825s
[2K
| Adam | epoch: 007 | loss: 0.11586 - acc: 0.9657 -- iter: 1184/2068
[A[ATraining Step: 428  | total loss: [1m[32m0.11560[0m[0m | time: 326.756s
[2K
| Adam | epoch: 007 | loss: 0.11560 - acc: 0.9660 -- iter: 1216/2068
[A[ATraining Step: 429  | total loss: [1m[32m0.11148[0m[0m | time: 334.705s
[2K
| Adam | epoch: 007 | loss: 0.11148 - acc: 0.9663 -- iter: 1248/2068
[A[ATraining Step: 430  | total loss: [1m[32m0.11090[0m[0m | time: 342.516s
[2K
| Adam | epoch: 007 | loss: 0.11090 - acc: 0.9666 -- iter: 1280/2068
[A[ATraining Step: 431  | total loss: [1m[32m0.10284[0m[0m | time: 350.456s
[2K
| Adam | epoch: 007 | loss: 0.10284 - acc: 0.9699 -- iter: 1312/2068
[A[ATraining Step: 432  | total loss: [1m[32m0.10258[0m[0m | time: 358.408s
[2K
| Adam | epoch: 007 | loss: 0.10258 - acc: 0.9698 -- iter: 1344/2068
[A[ATraining Step: 433  | total loss: [1m[32m0.10753[0m[0m | time: 366.276s
[2K
| Adam | epoch: 007 | loss: 0.10753 - acc: 0.9666 -- iter: 1376/2068
[A[ATraining Step: 434  | total loss: [1m[32m0.10101[0m[0m | time: 374.420s
[2K
| Adam | epoch: 007 | loss: 0.10101 - acc: 0.9699 -- iter: 1408/2068
[A[ATraining Step: 435  | total loss: [1m[32m0.09823[0m[0m | time: 382.455s
[2K
| Adam | epoch: 007 | loss: 0.09823 - acc: 0.9729 -- iter: 1440/2068
[A[ATraining Step: 436  | total loss: [1m[32m0.09252[0m[0m | time: 390.439s
[2K
| Adam | epoch: 007 | loss: 0.09252 - acc: 0.9756 -- iter: 1472/2068
[A[ATraining Step: 437  | total loss: [1m[32m0.08571[0m[0m | time: 398.433s
[2K
| Adam | epoch: 007 | loss: 0.08571 - acc: 0.9781 -- iter: 1504/2068
[A[ATraining Step: 438  | total loss: [1m[32m0.12271[0m[0m | time: 406.572s
[2K
| Adam | epoch: 007 | loss: 0.12271 - acc: 0.9615 -- iter: 1536/2068
[A[ATraining Step: 439  | total loss: [1m[32m0.12366[0m[0m | time: 414.641s
[2K
| Adam | epoch: 007 | loss: 0.12366 - acc: 0.9622 -- iter: 1568/2068
[A[ATraining Step: 440  | total loss: [1m[32m0.11323[0m[0m | time: 422.561s
[2K
| Adam | epoch: 007 | loss: 0.11323 - acc: 0.9660 -- iter: 1600/2068
[A[ATraining Step: 441  | total loss: [1m[32m0.10495[0m[0m | time: 430.513s
[2K
| Adam | epoch: 007 | loss: 0.10495 - acc: 0.9694 -- iter: 1632/2068
[A[ATraining Step: 442  | total loss: [1m[32m0.09590[0m[0m | time: 438.424s
[2K
| Adam | epoch: 007 | loss: 0.09590 - acc: 0.9725 -- iter: 1664/2068
[A[ATraining Step: 443  | total loss: [1m[32m0.08906[0m[0m | time: 446.432s
[2K
| Adam | epoch: 007 | loss: 0.08906 - acc: 0.9752 -- iter: 1696/2068
[A[ATraining Step: 444  | total loss: [1m[32m0.08407[0m[0m | time: 454.406s
[2K
| Adam | epoch: 007 | loss: 0.08407 - acc: 0.9777 -- iter: 1728/2068
[A[ATraining Step: 445  | total loss: [1m[32m0.07861[0m[0m | time: 462.272s
[2K
| Adam | epoch: 007 | loss: 0.07861 - acc: 0.9799 -- iter: 1760/2068
[A[ATraining Step: 446  | total loss: [1m[32m0.07278[0m[0m | time: 470.439s
[2K
| Adam | epoch: 007 | loss: 0.07278 - acc: 0.9819 -- iter: 1792/2068
[A[ATraining Step: 447  | total loss: [1m[32m0.06660[0m[0m | time: 478.469s
[2K
| Adam | epoch: 007 | loss: 0.06660 - acc: 0.9837 -- iter: 1824/2068
[A[ATraining Step: 448  | total loss: [1m[32m0.06098[0m[0m | time: 486.401s
[2K
| Adam | epoch: 007 | loss: 0.06098 - acc: 0.9854 -- iter: 1856/2068
[A[ATraining Step: 449  | total loss: [1m[32m0.06150[0m[0m | time: 494.513s
[2K
| Adam | epoch: 007 | loss: 0.06150 - acc: 0.9837 -- iter: 1888/2068
[A[ATraining Step: 450  | total loss: [1m[32m0.05987[0m[0m | time: 502.542s
[2K
| Adam | epoch: 007 | loss: 0.05987 - acc: 0.9853 -- iter: 1920/2068
[A[ATraining Step: 451  | total loss: [1m[32m0.05608[0m[0m | time: 510.591s
[2K
| Adam | epoch: 007 | loss: 0.05608 - acc: 0.9868 -- iter: 1952/2068
[A[ATraining Step: 452  | total loss: [1m[32m0.05241[0m[0m | time: 518.440s
[2K
| Adam | epoch: 007 | loss: 0.05241 - acc: 0.9881 -- iter: 1984/2068
[A[ATraining Step: 453  | total loss: [1m[32m0.04957[0m[0m | time: 526.304s
[2K
| Adam | epoch: 007 | loss: 0.04957 - acc: 0.9893 -- iter: 2016/2068
[A[ATraining Step: 454  | total loss: [1m[32m0.06276[0m[0m | time: 534.197s
[2K
| Adam | epoch: 007 | loss: 0.06276 - acc: 0.9841 -- iter: 2048/2068
[A[ATraining Step: 455  | total loss: [1m[32m0.06226[0m[0m | time: 570.951s
[2K
| Adam | epoch: 007 | loss: 0.06226 - acc: 0.9826 | val_loss: 1.21548 - val_acc: 0.7187 -- iter: 2068/2068
--
Training Step: 456  | total loss: [1m[32m0.06086[0m[0m | time: 8.241s
[2K
| Adam | epoch: 008 | loss: 0.06086 - acc: 0.9812 -- iter: 0032/2068
[A[ATraining Step: 457  | total loss: [1m[32m0.05573[0m[0m | time: 16.329s
[2K
| Adam | epoch: 008 | loss: 0.05573 - acc: 0.9831 -- iter: 0064/2068
[A[ATraining Step: 458  | total loss: [1m[32m0.05171[0m[0m | time: 24.046s
[2K
| Adam | epoch: 008 | loss: 0.05171 - acc: 0.9848 -- iter: 0096/2068
[A[ATraining Step: 459  | total loss: [1m[32m0.04785[0m[0m | time: 32.038s
[2K
| Adam | epoch: 008 | loss: 0.04785 - acc: 0.9863 -- iter: 0128/2068
[A[ATraining Step: 460  | total loss: [1m[32m0.04896[0m[0m | time: 39.805s
[2K
| Adam | epoch: 008 | loss: 0.04896 - acc: 0.9845 -- iter: 0160/2068
[A[ATraining Step: 461  | total loss: [1m[32m0.04626[0m[0m | time: 45.259s
[2K
| Adam | epoch: 008 | loss: 0.04626 - acc: 0.9861 -- iter: 0192/2068
[A[ATraining Step: 462  | total loss: [1m[32m0.04239[0m[0m | time: 50.688s
[2K
| Adam | epoch: 008 | loss: 0.04239 - acc: 0.9875 -- iter: 0224/2068
[A[ATraining Step: 463  | total loss: [1m[32m0.03913[0m[0m | time: 58.750s
[2K
| Adam | epoch: 008 | loss: 0.03913 - acc: 0.9887 -- iter: 0256/2068
[A[ATraining Step: 464  | total loss: [1m[32m0.04317[0m[0m | time: 66.536s
[2K
| Adam | epoch: 008 | loss: 0.04317 - acc: 0.9867 -- iter: 0288/2068
[A[ATraining Step: 465  | total loss: [1m[32m0.04133[0m[0m | time: 74.577s
[2K
| Adam | epoch: 008 | loss: 0.04133 - acc: 0.9881 -- iter: 0320/2068
[A[ATraining Step: 466  | total loss: [1m[32m0.04693[0m[0m | time: 82.645s
[2K
| Adam | epoch: 008 | loss: 0.04693 - acc: 0.9861 -- iter: 0352/2068
[A[ATraining Step: 467  | total loss: [1m[32m0.06666[0m[0m | time: 90.739s
[2K
| Adam | epoch: 008 | loss: 0.06666 - acc: 0.9813 -- iter: 0384/2068
[A[ATraining Step: 468  | total loss: [1m[32m0.06346[0m[0m | time: 98.490s
[2K
| Adam | epoch: 008 | loss: 0.06346 - acc: 0.9800 -- iter: 0416/2068
[A[ATraining Step: 469  | total loss: [1m[32m0.06014[0m[0m | time: 106.266s
[2K
| Adam | epoch: 008 | loss: 0.06014 - acc: 0.9789 -- iter: 0448/2068
[A[ATraining Step: 470  | total loss: [1m[32m0.05468[0m[0m | time: 114.248s
[2K
| Adam | epoch: 008 | loss: 0.05468 - acc: 0.9810 -- iter: 0480/2068
[A[ATraining Step: 471  | total loss: [1m[32m0.05188[0m[0m | time: 122.154s
[2K
| Adam | epoch: 008 | loss: 0.05188 - acc: 0.9829 -- iter: 0512/2068
[A[ATraining Step: 472  | total loss: [1m[32m0.04878[0m[0m | time: 130.155s
[2K
| Adam | epoch: 008 | loss: 0.04878 - acc: 0.9846 -- iter: 0544/2068
[A[ATraining Step: 473  | total loss: [1m[32m0.04440[0m[0m | time: 138.016s
[2K
| Adam | epoch: 008 | loss: 0.04440 - acc: 0.9861 -- iter: 0576/2068
[A[ATraining Step: 474  | total loss: [1m[32m0.04206[0m[0m | time: 145.937s
[2K
| Adam | epoch: 008 | loss: 0.04206 - acc: 0.9875 -- iter: 0608/2068
[A[ATraining Step: 475  | total loss: [1m[32m0.04332[0m[0m | time: 153.854s
[2K
| Adam | epoch: 008 | loss: 0.04332 - acc: 0.9857 -- iter: 0640/2068
[A[ATraining Step: 476  | total loss: [1m[32m0.04763[0m[0m | time: 161.938s
[2K
| Adam | epoch: 008 | loss: 0.04763 - acc: 0.9840 -- iter: 0672/2068
[A[ATraining Step: 477  | total loss: [1m[32m0.05330[0m[0m | time: 169.956s
[2K
| Adam | epoch: 008 | loss: 0.05330 - acc: 0.9824 -- iter: 0704/2068
[A[ATraining Step: 478  | total loss: [1m[32m0.05279[0m[0m | time: 178.039s
[2K
| Adam | epoch: 008 | loss: 0.05279 - acc: 0.9842 -- iter: 0736/2068
[A[ATraining Step: 479  | total loss: [1m[32m0.05282[0m[0m | time: 186.241s
[2K
| Adam | epoch: 008 | loss: 0.05282 - acc: 0.9827 -- iter: 0768/2068
[A[ATraining Step: 480  | total loss: [1m[32m0.05062[0m[0m | time: 194.121s
[2K
| Adam | epoch: 008 | loss: 0.05062 - acc: 0.9844 -- iter: 0800/2068
[A[ATraining Step: 481  | total loss: [1m[32m0.05297[0m[0m | time: 201.982s
[2K
| Adam | epoch: 008 | loss: 0.05297 - acc: 0.9828 -- iter: 0832/2068
[A[ATraining Step: 482  | total loss: [1m[32m0.04858[0m[0m | time: 209.817s
[2K
| Adam | epoch: 008 | loss: 0.04858 - acc: 0.9845 -- iter: 0864/2068
[A[ATraining Step: 483  | total loss: [1m[32m0.05066[0m[0m | time: 217.778s
[2K
| Adam | epoch: 008 | loss: 0.05066 - acc: 0.9830 -- iter: 0896/2068
[A[ATraining Step: 484  | total loss: [1m[32m0.04931[0m[0m | time: 225.879s
[2K
| Adam | epoch: 008 | loss: 0.04931 - acc: 0.9815 -- iter: 0928/2068
[A[ATraining Step: 485  | total loss: [1m[32m0.04564[0m[0m | time: 233.704s
[2K
| Adam | epoch: 008 | loss: 0.04564 - acc: 0.9834 -- iter: 0960/2068
[A[ATraining Step: 486  | total loss: [1m[32m0.04353[0m[0m | time: 241.598s
[2K
| Adam | epoch: 008 | loss: 0.04353 - acc: 0.9850 -- iter: 0992/2068
[A[ATraining Step: 487  | total loss: [1m[32m0.04412[0m[0m | time: 249.429s
[2K
| Adam | epoch: 008 | loss: 0.04412 - acc: 0.9834 -- iter: 1024/2068
[A[ATraining Step: 488  | total loss: [1m[32m0.04169[0m[0m | time: 257.659s
[2K
| Adam | epoch: 008 | loss: 0.04169 - acc: 0.9851 -- iter: 1056/2068
[A[ATraining Step: 489  | total loss: [1m[32m0.04038[0m[0m | time: 265.652s
[2K
| Adam | epoch: 008 | loss: 0.04038 - acc: 0.9866 -- iter: 1088/2068
[A[ATraining Step: 490  | total loss: [1m[32m0.04230[0m[0m | time: 273.642s
[2K
| Adam | epoch: 008 | loss: 0.04230 - acc: 0.9848 -- iter: 1120/2068
[A[ATraining Step: 491  | total loss: [1m[32m0.04030[0m[0m | time: 281.722s
[2K
| Adam | epoch: 008 | loss: 0.04030 - acc: 0.9863 -- iter: 1152/2068
[A[ATraining Step: 492  | total loss: [1m[32m0.04027[0m[0m | time: 289.476s
[2K
| Adam | epoch: 008 | loss: 0.04027 - acc: 0.9877 -- iter: 1184/2068
[A[ATraining Step: 493  | total loss: [1m[32m0.04022[0m[0m | time: 297.542s
[2K
| Adam | epoch: 008 | loss: 0.04022 - acc: 0.9858 -- iter: 1216/2068
[A[ATraining Step: 494  | total loss: [1m[32m0.04905[0m[0m | time: 305.563s
[2K
| Adam | epoch: 008 | loss: 0.04905 - acc: 0.9841 -- iter: 1248/2068
[A[ATraining Step: 495  | total loss: [1m[32m0.04659[0m[0m | time: 313.442s
[2K
| Adam | epoch: 008 | loss: 0.04659 - acc: 0.9857 -- iter: 1280/2068
[A[ATraining Step: 496  | total loss: [1m[32m0.07597[0m[0m | time: 321.486s
[2K
| Adam | epoch: 008 | loss: 0.07597 - acc: 0.9809 -- iter: 1312/2068
[A[ATraining Step: 497  | total loss: [1m[32m0.06874[0m[0m | time: 329.499s
[2K
| Adam | epoch: 008 | loss: 0.06874 - acc: 0.9828 -- iter: 1344/2068
[A[ATraining Step: 498  | total loss: [1m[32m0.08759[0m[0m | time: 337.483s
[2K
| Adam | epoch: 008 | loss: 0.08759 - acc: 0.9782 -- iter: 1376/2068
[A[ATraining Step: 499  | total loss: [1m[32m0.09416[0m[0m | time: 345.409s
[2K
| Adam | epoch: 008 | loss: 0.09416 - acc: 0.9742 -- iter: 1408/2068
[A[ATraining Step: 500  | total loss: [1m[32m0.08751[0m[0m | time: 353.167s
[2K
| Adam | epoch: 008 | loss: 0.08751 - acc: 0.9736 -- iter: 1440/2068
[A[ATraining Step: 501  | total loss: [1m[32m0.08958[0m[0m | time: 361.067s
[2K
| Adam | epoch: 008 | loss: 0.08958 - acc: 0.9731 -- iter: 1472/2068
[A[ATraining Step: 502  | total loss: [1m[32m0.08825[0m[0m | time: 369.207s
[2K
| Adam | epoch: 008 | loss: 0.08825 - acc: 0.9727 -- iter: 1504/2068
[A[ATraining Step: 503  | total loss: [1m[32m0.07997[0m[0m | time: 377.136s
[2K
| Adam | epoch: 008 | loss: 0.07997 - acc: 0.9754 -- iter: 1536/2068
[A[ATraining Step: 504  | total loss: [1m[32m0.07947[0m[0m | time: 384.897s
[2K
| Adam | epoch: 008 | loss: 0.07947 - acc: 0.9748 -- iter: 1568/2068
[A[ATraining Step: 505  | total loss: [1m[32m0.07809[0m[0m | time: 392.854s
[2K
| Adam | epoch: 008 | loss: 0.07809 - acc: 0.9742 -- iter: 1600/2068
[A[ATraining Step: 506  | total loss: [1m[32m0.07362[0m[0m | time: 400.607s
[2K
| Adam | epoch: 008 | loss: 0.07362 - acc: 0.9736 -- iter: 1632/2068
[A[ATraining Step: 507  | total loss: [1m[32m0.09733[0m[0m | time: 408.751s
[2K
| Adam | epoch: 008 | loss: 0.09733 - acc: 0.9669 -- iter: 1664/2068
[A[ATraining Step: 508  | total loss: [1m[32m0.08911[0m[0m | time: 416.669s
[2K
| Adam | epoch: 008 | loss: 0.08911 - acc: 0.9702 -- iter: 1696/2068
[A[ATraining Step: 509  | total loss: [1m[32m0.08116[0m[0m | time: 424.542s
[2K
| Adam | epoch: 008 | loss: 0.08116 - acc: 0.9732 -- iter: 1728/2068
[A[ATraining Step: 510  | total loss: [1m[32m0.07477[0m[0m | time: 432.527s
[2K
| Adam | epoch: 008 | loss: 0.07477 - acc: 0.9759 -- iter: 1760/2068
[A[ATraining Step: 511  | total loss: [1m[32m0.07790[0m[0m | time: 440.752s
[2K
| Adam | epoch: 008 | loss: 0.07790 - acc: 0.9720 -- iter: 1792/2068
[A[ATraining Step: 512  | total loss: [1m[32m0.07399[0m[0m | time: 448.909s
[2K
| Adam | epoch: 008 | loss: 0.07399 - acc: 0.9717 -- iter: 1824/2068
[A[ATraining Step: 513  | total loss: [1m[32m0.07683[0m[0m | time: 456.746s
[2K
| Adam | epoch: 008 | loss: 0.07683 - acc: 0.9714 -- iter: 1856/2068
[A[ATraining Step: 514  | total loss: [1m[32m0.08782[0m[0m | time: 464.780s
[2K
| Adam | epoch: 008 | loss: 0.08782 - acc: 0.9711 -- iter: 1888/2068
[A[ATraining Step: 515  | total loss: [1m[32m0.09246[0m[0m | time: 472.910s
[2K
| Adam | epoch: 008 | loss: 0.09246 - acc: 0.9709 -- iter: 1920/2068
[A[ATraining Step: 516  | total loss: [1m[32m0.08462[0m[0m | time: 481.006s
[2K
| Adam | epoch: 008 | loss: 0.08462 - acc: 0.9738 -- iter: 1952/2068
[A[ATraining Step: 517  | total loss: [1m[32m0.08091[0m[0m | time: 488.831s
[2K
| Adam | epoch: 008 | loss: 0.08091 - acc: 0.9733 -- iter: 1984/2068
[A[ATraining Step: 518  | total loss: [1m[32m0.07589[0m[0m | time: 496.853s
[2K
| Adam | epoch: 008 | loss: 0.07589 - acc: 0.9728 -- iter: 2016/2068
[A[ATraining Step: 519  | total loss: [1m[32m0.07003[0m[0m | time: 505.020s
[2K
| Adam | epoch: 008 | loss: 0.07003 - acc: 0.9756 -- iter: 2048/2068
[A[ATraining Step: 520  | total loss: [1m[32m0.07025[0m[0m | time: 541.747s
[2K
| Adam | epoch: 008 | loss: 0.07025 - acc: 0.9749 | val_loss: 1.43620 - val_acc: 0.6770 -- iter: 2068/2068
--
Training Step: 521  | total loss: [1m[32m0.06382[0m[0m | time: 8.114s
[2K
| Adam | epoch: 009 | loss: 0.06382 - acc: 0.9774 -- iter: 0032/2068
[A[ATraining Step: 522  | total loss: [1m[32m0.06013[0m[0m | time: 15.961s
[2K
| Adam | epoch: 009 | loss: 0.06013 - acc: 0.9797 -- iter: 0064/2068
[A[ATraining Step: 523  | total loss: [1m[32m0.05870[0m[0m | time: 24.184s
[2K
| Adam | epoch: 009 | loss: 0.05870 - acc: 0.9786 -- iter: 0096/2068
[A[ATraining Step: 524  | total loss: [1m[32m0.06654[0m[0m | time: 32.216s
[2K
| Adam | epoch: 009 | loss: 0.06654 - acc: 0.9745 -- iter: 0128/2068
[A[ATraining Step: 525  | total loss: [1m[32m0.07895[0m[0m | time: 40.102s
[2K
| Adam | epoch: 009 | loss: 0.07895 - acc: 0.9708 -- iter: 0160/2068
[A[ATraining Step: 526  | total loss: [1m[32m0.07702[0m[0m | time: 48.228s
[2K
| Adam | epoch: 009 | loss: 0.07702 - acc: 0.9706 -- iter: 0192/2068
[A[ATraining Step: 527  | total loss: [1m[32m0.08607[0m[0m | time: 53.594s
[2K
| Adam | epoch: 009 | loss: 0.08607 - acc: 0.9641 -- iter: 0224/2068
[A[ATraining Step: 528  | total loss: [1m[32m0.07867[0m[0m | time: 59.152s
[2K
| Adam | epoch: 009 | loss: 0.07867 - acc: 0.9677 -- iter: 0256/2068
[A[ATraining Step: 529  | total loss: [1m[32m0.07194[0m[0m | time: 67.183s
[2K
| Adam | epoch: 009 | loss: 0.07194 - acc: 0.9709 -- iter: 0288/2068
[A[ATraining Step: 530  | total loss: [1m[32m0.07557[0m[0m | time: 75.067s
[2K
| Adam | epoch: 009 | loss: 0.07557 - acc: 0.9707 -- iter: 0320/2068
[A[ATraining Step: 531  | total loss: [1m[32m0.08760[0m[0m | time: 83.074s
[2K
| Adam | epoch: 009 | loss: 0.08760 - acc: 0.9674 -- iter: 0352/2068
[A[ATraining Step: 532  | total loss: [1m[32m0.08328[0m[0m | time: 90.938s
[2K
| Adam | epoch: 009 | loss: 0.08328 - acc: 0.9707 -- iter: 0384/2068
[A[ATraining Step: 533  | total loss: [1m[32m0.07692[0m[0m | time: 98.973s
[2K
| Adam | epoch: 009 | loss: 0.07692 - acc: 0.9736 -- iter: 0416/2068
[A[ATraining Step: 534  | total loss: [1m[32m0.07038[0m[0m | time: 106.927s
[2K
| Adam | epoch: 009 | loss: 0.07038 - acc: 0.9762 -- iter: 0448/2068
[A[ATraining Step: 535  | total loss: [1m[32m0.06810[0m[0m | time: 114.920s
[2K
| Adam | epoch: 009 | loss: 0.06810 - acc: 0.9755 -- iter: 0480/2068
[A[ATraining Step: 536  | total loss: [1m[32m0.07281[0m[0m | time: 123.068s
[2K
| Adam | epoch: 009 | loss: 0.07281 - acc: 0.9748 -- iter: 0512/2068
[A[ATraining Step: 537  | total loss: [1m[32m0.06597[0m[0m | time: 131.044s
[2K
| Adam | epoch: 009 | loss: 0.06597 - acc: 0.9773 -- iter: 0544/2068
[A[ATraining Step: 538  | total loss: [1m[32m0.06736[0m[0m | time: 138.976s
[2K
| Adam | epoch: 009 | loss: 0.06736 - acc: 0.9765 -- iter: 0576/2068
[A[ATraining Step: 539  | total loss: [1m[32m0.06607[0m[0m | time: 146.721s
[2K
| Adam | epoch: 009 | loss: 0.06607 - acc: 0.9757 -- iter: 0608/2068
[A[ATraining Step: 540  | total loss: [1m[32m0.06210[0m[0m | time: 154.768s
[2K
| Adam | epoch: 009 | loss: 0.06210 - acc: 0.9781 -- iter: 0640/2068
[A[ATraining Step: 541  | total loss: [1m[32m0.05707[0m[0m | time: 162.830s
[2K
| Adam | epoch: 009 | loss: 0.05707 - acc: 0.9803 -- iter: 0672/2068
[A[ATraining Step: 542  | total loss: [1m[32m0.05286[0m[0m | time: 170.953s
[2K
| Adam | epoch: 009 | loss: 0.05286 - acc: 0.9823 -- iter: 0704/2068
[A[ATraining Step: 543  | total loss: [1m[32m0.04900[0m[0m | time: 178.924s
[2K
| Adam | epoch: 009 | loss: 0.04900 - acc: 0.9841 -- iter: 0736/2068
[A[ATraining Step: 544  | total loss: [1m[32m0.05202[0m[0m | time: 186.848s
[2K
| Adam | epoch: 009 | loss: 0.05202 - acc: 0.9825 -- iter: 0768/2068
[A[ATraining Step: 545  | total loss: [1m[32m0.05608[0m[0m | time: 194.952s
[2K
| Adam | epoch: 009 | loss: 0.05608 - acc: 0.9780 -- iter: 0800/2068
[A[ATraining Step: 546  | total loss: [1m[32m0.05165[0m[0m | time: 203.042s
[2K
| Adam | epoch: 009 | loss: 0.05165 - acc: 0.9802 -- iter: 0832/2068
[A[ATraining Step: 547  | total loss: [1m[32m0.04783[0m[0m | time: 210.987s
[2K
| Adam | epoch: 009 | loss: 0.04783 - acc: 0.9822 -- iter: 0864/2068
[A[ATraining Step: 548  | total loss: [1m[32m0.04607[0m[0m | time: 219.107s
[2K
| Adam | epoch: 009 | loss: 0.04607 - acc: 0.9840 -- iter: 0896/2068
[A[ATraining Step: 549  | total loss: [1m[32m0.04467[0m[0m | time: 227.227s
[2K
| Adam | epoch: 009 | loss: 0.04467 - acc: 0.9856 -- iter: 0928/2068
[A[ATraining Step: 550  | total loss: [1m[32m0.04183[0m[0m | time: 235.274s
[2K
| Adam | epoch: 009 | loss: 0.04183 - acc: 0.9870 -- iter: 0960/2068
[A[ATraining Step: 551  | total loss: [1m[32m0.03927[0m[0m | time: 243.334s
[2K
| Adam | epoch: 009 | loss: 0.03927 - acc: 0.9883 -- iter: 0992/2068
[A[ATraining Step: 552  | total loss: [1m[32m0.03992[0m[0m | time: 251.415s
[2K
| Adam | epoch: 009 | loss: 0.03992 - acc: 0.9864 -- iter: 1024/2068
[A[ATraining Step: 553  | total loss: [1m[32m0.03684[0m[0m | time: 259.430s
[2K
| Adam | epoch: 009 | loss: 0.03684 - acc: 0.9877 -- iter: 1056/2068
[A[ATraining Step: 554  | total loss: [1m[32m0.04351[0m[0m | time: 267.557s
[2K
| Adam | epoch: 009 | loss: 0.04351 - acc: 0.9858 -- iter: 1088/2068
[A[ATraining Step: 555  | total loss: [1m[32m0.04213[0m[0m | time: 275.420s
[2K
| Adam | epoch: 009 | loss: 0.04213 - acc: 0.9872 -- iter: 1120/2068
[A[ATraining Step: 556  | total loss: [1m[32m0.05213[0m[0m | time: 283.513s
[2K
| Adam | epoch: 009 | loss: 0.05213 - acc: 0.9791 -- iter: 1152/2068
[A[ATraining Step: 557  | total loss: [1m[32m0.05096[0m[0m | time: 291.640s
[2K
| Adam | epoch: 009 | loss: 0.05096 - acc: 0.9812 -- iter: 1184/2068
[A[ATraining Step: 558  | total loss: [1m[32m0.05517[0m[0m | time: 299.661s
[2K
| Adam | epoch: 009 | loss: 0.05517 - acc: 0.9831 -- iter: 1216/2068
[A[ATraining Step: 559  | total loss: [1m[32m0.05066[0m[0m | time: 307.413s
[2K
| Adam | epoch: 009 | loss: 0.05066 - acc: 0.9848 -- iter: 1248/2068
[A[ATraining Step: 560  | total loss: [1m[32m0.05620[0m[0m | time: 315.384s
[2K
| Adam | epoch: 009 | loss: 0.05620 - acc: 0.9832 -- iter: 1280/2068
[A[ATraining Step: 561  | total loss: [1m[32m0.05143[0m[0m | time: 323.382s
[2K
| Adam | epoch: 009 | loss: 0.05143 - acc: 0.9849 -- iter: 1312/2068
[A[ATraining Step: 562  | total loss: [1m[32m0.06863[0m[0m | time: 331.347s
[2K
| Adam | epoch: 009 | loss: 0.06863 - acc: 0.9833 -- iter: 1344/2068
[A[ATraining Step: 563  | total loss: [1m[32m0.06384[0m[0m | time: 339.437s
[2K
| Adam | epoch: 009 | loss: 0.06384 - acc: 0.9849 -- iter: 1376/2068
[A[ATraining Step: 564  | total loss: [1m[32m0.05821[0m[0m | time: 347.370s
[2K
| Adam | epoch: 009 | loss: 0.05821 - acc: 0.9864 -- iter: 1408/2068
[A[ATraining Step: 565  | total loss: [1m[32m0.05381[0m[0m | time: 355.270s
[2K
| Adam | epoch: 009 | loss: 0.05381 - acc: 0.9878 -- iter: 1440/2068
[A[ATraining Step: 566  | total loss: [1m[32m0.05637[0m[0m | time: 363.125s
[2K
| Adam | epoch: 009 | loss: 0.05637 - acc: 0.9859 -- iter: 1472/2068
[A[ATraining Step: 567  | total loss: [1m[32m0.05618[0m[0m | time: 371.142s
[2K
| Adam | epoch: 009 | loss: 0.05618 - acc: 0.9842 -- iter: 1504/2068
[A[ATraining Step: 568  | total loss: [1m[32m0.05253[0m[0m | time: 379.260s
[2K
| Adam | epoch: 009 | loss: 0.05253 - acc: 0.9858 -- iter: 1536/2068
[A[ATraining Step: 569  | total loss: [1m[32m0.04832[0m[0m | time: 387.229s
[2K
| Adam | epoch: 009 | loss: 0.04832 - acc: 0.9872 -- iter: 1568/2068
[A[ATraining Step: 570  | total loss: [1m[32m0.04656[0m[0m | time: 395.376s
[2K
| Adam | epoch: 009 | loss: 0.04656 - acc: 0.9885 -- iter: 1600/2068
[A[ATraining Step: 571  | total loss: [1m[32m0.04857[0m[0m | time: 403.190s
[2K
| Adam | epoch: 009 | loss: 0.04857 - acc: 0.9865 -- iter: 1632/2068
[A[ATraining Step: 572  | total loss: [1m[32m0.04386[0m[0m | time: 411.156s
[2K
| Adam | epoch: 009 | loss: 0.04386 - acc: 0.9878 -- iter: 1664/2068
[A[ATraining Step: 573  | total loss: [1m[32m0.04064[0m[0m | time: 419.184s
[2K
| Adam | epoch: 009 | loss: 0.04064 - acc: 0.9891 -- iter: 1696/2068
[A[ATraining Step: 574  | total loss: [1m[32m0.03835[0m[0m | time: 426.935s
[2K
| Adam | epoch: 009 | loss: 0.03835 - acc: 0.9902 -- iter: 1728/2068
[A[ATraining Step: 575  | total loss: [1m[32m0.03483[0m[0m | time: 434.897s
[2K
| Adam | epoch: 009 | loss: 0.03483 - acc: 0.9911 -- iter: 1760/2068
[A[ATraining Step: 576  | total loss: [1m[32m0.03172[0m[0m | time: 442.865s
[2K
| Adam | epoch: 009 | loss: 0.03172 - acc: 0.9920 -- iter: 1792/2068
[A[ATraining Step: 577  | total loss: [1m[32m0.02964[0m[0m | time: 450.820s
[2K
| Adam | epoch: 009 | loss: 0.02964 - acc: 0.9928 -- iter: 1824/2068
[A[ATraining Step: 578  | total loss: [1m[32m0.02839[0m[0m | time: 458.662s
[2K
| Adam | epoch: 009 | loss: 0.02839 - acc: 0.9935 -- iter: 1856/2068
[A[ATraining Step: 579  | total loss: [1m[32m0.02613[0m[0m | time: 466.522s
[2K
| Adam | epoch: 009 | loss: 0.02613 - acc: 0.9942 -- iter: 1888/2068
[A[ATraining Step: 580  | total loss: [1m[32m0.03002[0m[0m | time: 474.509s
[2K
| Adam | epoch: 009 | loss: 0.03002 - acc: 0.9916 -- iter: 1920/2068
[A[ATraining Step: 581  | total loss: [1m[32m0.02815[0m[0m | time: 482.538s
[2K
| Adam | epoch: 009 | loss: 0.02815 - acc: 0.9925 -- iter: 1952/2068
[A[ATraining Step: 582  | total loss: [1m[32m0.02604[0m[0m | time: 490.682s
[2K
| Adam | epoch: 009 | loss: 0.02604 - acc: 0.9932 -- iter: 1984/2068
[A[ATraining Step: 583  | total loss: [1m[32m0.02411[0m[0m | time: 498.558s
[2K
| Adam | epoch: 009 | loss: 0.02411 - acc: 0.9939 -- iter: 2016/2068
[A[ATraining Step: 584  | total loss: [1m[32m0.02294[0m[0m | time: 506.401s
[2K
| Adam | epoch: 009 | loss: 0.02294 - acc: 0.9945 -- iter: 2048/2068
[A[ATraining Step: 585  | total loss: [1m[32m0.02548[0m[0m | time: 543.220s
[2K
| Adam | epoch: 009 | loss: 0.02548 - acc: 0.9919 | val_loss: 0.78767 - val_acc: 0.8300 -- iter: 2068/2068
--
Training Step: 586  | total loss: [1m[32m0.03916[0m[0m | time: 7.957s
[2K
| Adam | epoch: 010 | loss: 0.03916 - acc: 0.9834 -- iter: 0032/2068
[A[ATraining Step: 587  | total loss: [1m[32m0.07029[0m[0m | time: 15.866s
[2K
| Adam | epoch: 010 | loss: 0.07029 - acc: 0.9757 -- iter: 0064/2068
[A[ATraining Step: 588  | total loss: [1m[32m0.06381[0m[0m | time: 23.576s
[2K
| Adam | epoch: 010 | loss: 0.06381 - acc: 0.9781 -- iter: 0096/2068
[A[ATraining Step: 589  | total loss: [1m[32m0.05938[0m[0m | time: 31.661s
[2K
| Adam | epoch: 010 | loss: 0.05938 - acc: 0.9803 -- iter: 0128/2068
[A[ATraining Step: 590  | total loss: [1m[32m0.05455[0m[0m | time: 39.694s
[2K
| Adam | epoch: 010 | loss: 0.05455 - acc: 0.9823 -- iter: 0160/2068
[A[ATraining Step: 591  | total loss: [1m[32m0.05092[0m[0m | time: 47.563s
[2K
| Adam | epoch: 010 | loss: 0.05092 - acc: 0.9840 -- iter: 0192/2068
[A[ATraining Step: 592  | total loss: [1m[32m0.04666[0m[0m | time: 55.439s
[2K
| Adam | epoch: 010 | loss: 0.04666 - acc: 0.9856 -- iter: 0224/2068
[A[ATraining Step: 593  | total loss: [1m[32m0.05635[0m[0m | time: 60.901s
[2K
| Adam | epoch: 010 | loss: 0.05635 - acc: 0.9808 -- iter: 0256/2068
[A[ATraining Step: 594  | total loss: [1m[32m0.05236[0m[0m | time: 66.227s
[2K
| Adam | epoch: 010 | loss: 0.05236 - acc: 0.9827 -- iter: 0288/2068
[A[ATraining Step: 595  | total loss: [1m[32m0.04801[0m[0m | time: 74.139s
[2K
| Adam | epoch: 010 | loss: 0.04801 - acc: 0.9845 -- iter: 0320/2068
[A[ATraining Step: 596  | total loss: [1m[32m0.04413[0m[0m | time: 82.079s
[2K
| Adam | epoch: 010 | loss: 0.04413 - acc: 0.9860 -- iter: 0352/2068
[A[ATraining Step: 597  | total loss: [1m[32m0.04265[0m[0m | time: 90.025s
[2K
| Adam | epoch: 010 | loss: 0.04265 - acc: 0.9843 -- iter: 0384/2068
[A[ATraining Step: 598  | total loss: [1m[32m0.04895[0m[0m | time: 98.086s
[2K
| Adam | epoch: 010 | loss: 0.04895 - acc: 0.9827 -- iter: 0416/2068
[A[ATraining Step: 599  | total loss: [1m[32m0.04566[0m[0m | time: 106.112s
[2K
| Adam | epoch: 010 | loss: 0.04566 - acc: 0.9845 -- iter: 0448/2068
[A[ATraining Step: 600  | total loss: [1m[32m0.04162[0m[0m | time: 142.939s
[2K
| Adam | epoch: 010 | loss: 0.04162 - acc: 0.9860 | val_loss: 0.45740 - val_acc: 0.9088 -- iter: 0480/2068
--
Training Step: 601  | total loss: [1m[32m0.03822[0m[0m | time: 150.963s
[2K
| Adam | epoch: 010 | loss: 0.03822 - acc: 0.9874 -- iter: 0512/2068
[A[ATraining Step: 602  | total loss: [1m[32m0.03936[0m[0m | time: 158.905s
[2K
| Adam | epoch: 010 | loss: 0.03936 - acc: 0.9855 -- iter: 0544/2068
[A[ATraining Step: 603  | total loss: [1m[32m0.03865[0m[0m | time: 166.703s
[2K
| Adam | epoch: 010 | loss: 0.03865 - acc: 0.9839 -- iter: 0576/2068
[A[ATraining Step: 604  | total loss: [1m[32m0.03536[0m[0m | time: 174.490s
[2K
| Adam | epoch: 010 | loss: 0.03536 - acc: 0.9855 -- iter: 0608/2068
[A[ATraining Step: 605  | total loss: [1m[32m0.03916[0m[0m | time: 182.292s
[2K
| Adam | epoch: 010 | loss: 0.03916 - acc: 0.9838 -- iter: 0640/2068
[A[ATraining Step: 606  | total loss: [1m[32m0.04676[0m[0m | time: 190.267s
[2K
| Adam | epoch: 010 | loss: 0.04676 - acc: 0.9792 -- iter: 0672/2068
[A[ATraining Step: 607  | total loss: [1m[32m0.04554[0m[0m | time: 198.337s
[2K
| Adam | epoch: 010 | loss: 0.04554 - acc: 0.9781 -- iter: 0704/2068
[A[ATraining Step: 608  | total loss: [1m[32m0.04435[0m[0m | time: 206.272s
[2K
| Adam | epoch: 010 | loss: 0.04435 - acc: 0.9772 -- iter: 0736/2068
[A[ATraining Step: 609  | total loss: [1m[32m0.04495[0m[0m | time: 214.269s
[2K
| Adam | epoch: 010 | loss: 0.04495 - acc: 0.9732 -- iter: 0768/2068
[A[ATraining Step: 610  | total loss: [1m[32m0.04194[0m[0m | time: 222.115s
[2K
| Adam | epoch: 010 | loss: 0.04194 - acc: 0.9759 -- iter: 0800/2068
[A[ATraining Step: 611  | total loss: [1m[32m0.04931[0m[0m | time: 230.072s
[2K
| Adam | epoch: 010 | loss: 0.04931 - acc: 0.9752 -- iter: 0832/2068
[A[ATraining Step: 612  | total loss: [1m[32m0.04542[0m[0m | time: 237.975s
[2K
| Adam | epoch: 010 | loss: 0.04542 - acc: 0.9777 -- iter: 0864/2068
[A[ATraining Step: 613  | total loss: [1m[32m0.05432[0m[0m | time: 245.963s
[2K
| Adam | epoch: 010 | loss: 0.05432 - acc: 0.9737 -- iter: 0896/2068
[A[ATraining Step: 614  | total loss: [1m[32m0.04933[0m[0m | time: 253.972s
[2K
| Adam | epoch: 010 | loss: 0.04933 - acc: 0.9763 -- iter: 0928/2068
[A[ATraining Step: 615  | total loss: [1m[32m0.04483[0m[0m | time: 262.023s
[2K
| Adam | epoch: 010 | loss: 0.04483 - acc: 0.9787 -- iter: 0960/2068
[A[ATraining Step: 616  | total loss: [1m[32m0.04108[0m[0m | time: 269.870s
[2K
| Adam | epoch: 010 | loss: 0.04108 - acc: 0.9808 -- iter: 0992/2068
[A[ATraining Step: 617  | total loss: [1m[32m0.03713[0m[0m | time: 277.735s
[2K
| Adam | epoch: 010 | loss: 0.03713 - acc: 0.9827 -- iter: 1024/2068
[A[ATraining Step: 618  | total loss: [1m[32m0.04048[0m[0m | time: 285.711s
[2K
| Adam | epoch: 010 | loss: 0.04048 - acc: 0.9813 -- iter: 1056/2068
[A[ATraining Step: 619  | total loss: [1m[32m0.03712[0m[0m | time: 293.799s
[2K
| Adam | epoch: 010 | loss: 0.03712 - acc: 0.9832 -- iter: 1088/2068
[A[ATraining Step: 620  | total loss: [1m[32m0.04216[0m[0m | time: 301.786s
[2K
| Adam | epoch: 010 | loss: 0.04216 - acc: 0.9817 -- iter: 1120/2068
[A[ATraining Step: 621  | total loss: [1m[32m0.03871[0m[0m | time: 309.820s
[2K
| Adam | epoch: 010 | loss: 0.03871 - acc: 0.9836 -- iter: 1152/2068
[A[ATraining Step: 622  | total loss: [1m[32m0.03643[0m[0m | time: 317.711s
[2K
| Adam | epoch: 010 | loss: 0.03643 - acc: 0.9852 -- iter: 1184/2068
[A[ATraining Step: 623  | total loss: [1m[32m0.03637[0m[0m | time: 325.694s
[2K
| Adam | epoch: 010 | loss: 0.03637 - acc: 0.9867 -- iter: 1216/2068
[A[ATraining Step: 624  | total loss: [1m[32m0.03798[0m[0m | time: 333.815s
[2K
| Adam | epoch: 010 | loss: 0.03798 - acc: 0.9849 -- iter: 1248/2068
[A[ATraining Step: 625  | total loss: [1m[32m0.03543[0m[0m | time: 341.736s
[2K
| Adam | epoch: 010 | loss: 0.03543 - acc: 0.9864 -- iter: 1280/2068
[A[ATraining Step: 626  | total loss: [1m[32m0.03275[0m[0m | time: 349.744s
[2K
| Adam | epoch: 010 | loss: 0.03275 - acc: 0.9878 -- iter: 1312/2068
[A[ATraining Step: 627  | total loss: [1m[32m0.03700[0m[0m | time: 357.693s
[2K
| Adam | epoch: 010 | loss: 0.03700 - acc: 0.9827 -- iter: 1344/2068
[A[ATraining Step: 628  | total loss: [1m[32m0.03587[0m[0m | time: 365.667s
[2K
| Adam | epoch: 010 | loss: 0.03587 - acc: 0.9845 -- iter: 1376/2068
[A[ATraining Step: 629  | total loss: [1m[32m0.03978[0m[0m | time: 373.452s
[2K
| Adam | epoch: 010 | loss: 0.03978 - acc: 0.9829 -- iter: 1408/2068
[A[ATraining Step: 630  | total loss: [1m[32m0.03690[0m[0m | time: 381.416s
[2K
| Adam | epoch: 010 | loss: 0.03690 - acc: 0.9846 -- iter: 1440/2068
[A[ATraining Step: 631  | total loss: [1m[32m0.03354[0m[0m | time: 389.405s
[2K
| Adam | epoch: 010 | loss: 0.03354 - acc: 0.9861 -- iter: 1472/2068
[A[ATraining Step: 632  | total loss: [1m[32m0.03105[0m[0m | time: 397.378s
[2K
| Adam | epoch: 010 | loss: 0.03105 - acc: 0.9875 -- iter: 1504/2068
[A[ATraining Step: 633  | total loss: [1m[32m0.03168[0m[0m | time: 405.162s
[2K
| Adam | epoch: 010 | loss: 0.03168 - acc: 0.9857 -- iter: 1536/2068
[A[ATraining Step: 634  | total loss: [1m[32m0.03165[0m[0m | time: 413.310s
[2K
| Adam | epoch: 010 | loss: 0.03165 - acc: 0.9871 -- iter: 1568/2068
[A[ATraining Step: 635  | total loss: [1m[32m0.04104[0m[0m | time: 421.054s
[2K
| Adam | epoch: 010 | loss: 0.04104 - acc: 0.9853 -- iter: 1600/2068
[A[ATraining Step: 636  | total loss: [1m[32m0.03905[0m[0m | time: 428.994s
[2K
| Adam | epoch: 010 | loss: 0.03905 - acc: 0.9867 -- iter: 1632/2068
[A[ATraining Step: 637  | total loss: [1m[32m0.03602[0m[0m | time: 437.012s
[2K
| Adam | epoch: 010 | loss: 0.03602 - acc: 0.9881 -- iter: 1664/2068
[A[ATraining Step: 638  | total loss: [1m[32m0.03316[0m[0m | time: 444.956s
[2K
| Adam | epoch: 010 | loss: 0.03316 - acc: 0.9892 -- iter: 1696/2068
[A[ATraining Step: 639  | total loss: [1m[32m0.03018[0m[0m | time: 452.933s
[2K
| Adam | epoch: 010 | loss: 0.03018 - acc: 0.9903 -- iter: 1728/2068
[A[ATraining Step: 640  | total loss: [1m[32m0.02777[0m[0m | time: 460.854s
[2K
| Adam | epoch: 010 | loss: 0.02777 - acc: 0.9913 -- iter: 1760/2068
[A[ATraining Step: 641  | total loss: [1m[32m0.02540[0m[0m | time: 468.709s
[2K
| Adam | epoch: 010 | loss: 0.02540 - acc: 0.9922 -- iter: 1792/2068
[A[ATraining Step: 642  | total loss: [1m[32m0.02334[0m[0m | time: 476.670s
[2K
| Adam | epoch: 010 | loss: 0.02334 - acc: 0.9929 -- iter: 1824/2068
[A[ATraining Step: 643  | total loss: [1m[32m0.02392[0m[0m | time: 484.612s
[2K
| Adam | epoch: 010 | loss: 0.02392 - acc: 0.9937 -- iter: 1856/2068
[A[ATraining Step: 644  | total loss: [1m[32m0.02321[0m[0m | time: 492.368s
[2K
| Adam | epoch: 010 | loss: 0.02321 - acc: 0.9943 -- iter: 1888/2068
[A[ATraining Step: 645  | total loss: [1m[32m0.02375[0m[0m | time: 500.413s
[2K
| Adam | epoch: 010 | loss: 0.02375 - acc: 0.9949 -- iter: 1920/2068
[A[ATraining Step: 646  | total loss: [1m[32m0.02347[0m[0m | time: 508.346s
[2K
| Adam | epoch: 010 | loss: 0.02347 - acc: 0.9954 -- iter: 1952/2068
[A[ATraining Step: 647  | total loss: [1m[32m0.02198[0m[0m | time: 516.304s
[2K
| Adam | epoch: 010 | loss: 0.02198 - acc: 0.9958 -- iter: 1984/2068
[A[ATraining Step: 648  | total loss: [1m[32m0.02020[0m[0m | time: 524.303s
[2K
| Adam | epoch: 010 | loss: 0.02020 - acc: 0.9963 -- iter: 2016/2068
[A[ATraining Step: 649  | total loss: [1m[32m0.01994[0m[0m | time: 532.359s
[2K
| Adam | epoch: 010 | loss: 0.01994 - acc: 0.9966 -- iter: 2048/2068
[A[ATraining Step: 650  | total loss: [1m[32m0.01838[0m[0m | time: 569.034s
[2K
| Adam | epoch: 010 | loss: 0.01838 - acc: 0.9970 | val_loss: 0.34241 - val_acc: 0.9274 -- iter: 2068/2068
--
Training Step: 651  | total loss: [1m[32m0.01821[0m[0m | time: 7.931s
[2K
| Adam | epoch: 011 | loss: 0.01821 - acc: 0.9973 -- iter: 0032/2068
[A[ATraining Step: 652  | total loss: [1m[32m0.01828[0m[0m | time: 15.811s
[2K
| Adam | epoch: 011 | loss: 0.01828 - acc: 0.9975 -- iter: 0064/2068
[A[ATraining Step: 653  | total loss: [1m[32m0.01718[0m[0m | time: 23.728s
[2K
| Adam | epoch: 011 | loss: 0.01718 - acc: 0.9978 -- iter: 0096/2068
[A[ATraining Step: 654  | total loss: [1m[32m0.01604[0m[0m | time: 31.480s
[2K
| Adam | epoch: 011 | loss: 0.01604 - acc: 0.9980 -- iter: 0128/2068
[A[ATraining Step: 655  | total loss: [1m[32m0.01458[0m[0m | time: 39.355s
[2K
| Adam | epoch: 011 | loss: 0.01458 - acc: 0.9982 -- iter: 0160/2068
[A[ATraining Step: 656  | total loss: [1m[32m0.01324[0m[0m | time: 47.212s
[2K
| Adam | epoch: 011 | loss: 0.01324 - acc: 0.9984 -- iter: 0192/2068
[A[ATraining Step: 657  | total loss: [1m[32m0.01316[0m[0m | time: 55.096s
[2K
| Adam | epoch: 011 | loss: 0.01316 - acc: 0.9985 -- iter: 0224/2068
[A[ATraining Step: 658  | total loss: [1m[32m0.01359[0m[0m | time: 63.033s
[2K
| Adam | epoch: 011 | loss: 0.01359 - acc: 0.9987 -- iter: 0256/2068
[A[ATraining Step: 659  | total loss: [1m[32m0.01237[0m[0m | time: 68.411s
[2K
| Adam | epoch: 011 | loss: 0.01237 - acc: 0.9988 -- iter: 0288/2068
[A[ATraining Step: 660  | total loss: [1m[32m0.02219[0m[0m | time: 73.729s
[2K
| Adam | epoch: 011 | loss: 0.02219 - acc: 0.9939 -- iter: 0320/2068
[A[ATraining Step: 661  | total loss: [1m[32m0.02000[0m[0m | time: 81.643s
[2K
| Adam | epoch: 011 | loss: 0.02000 - acc: 0.9945 -- iter: 0352/2068
[A[ATraining Step: 662  | total loss: [1m[32m0.01818[0m[0m | time: 89.667s
[2K
| Adam | epoch: 011 | loss: 0.01818 - acc: 0.9951 -- iter: 0384/2068
[A[ATraining Step: 663  | total loss: [1m[32m0.01770[0m[0m | time: 97.636s
[2K
| Adam | epoch: 011 | loss: 0.01770 - acc: 0.9956 -- iter: 0416/2068
[A[ATraining Step: 664  | total loss: [1m[32m0.01726[0m[0m | time: 105.437s
[2K
| Adam | epoch: 011 | loss: 0.01726 - acc: 0.9960 -- iter: 0448/2068
[A[ATraining Step: 665  | total loss: [1m[32m0.03168[0m[0m | time: 113.422s
[2K
| Adam | epoch: 011 | loss: 0.03168 - acc: 0.9933 -- iter: 0480/2068
[A[ATraining Step: 666  | total loss: [1m[32m0.02862[0m[0m | time: 121.352s
[2K
| Adam | epoch: 011 | loss: 0.02862 - acc: 0.9940 -- iter: 0512/2068
[A[ATraining Step: 667  | total loss: [1m[32m0.03494[0m[0m | time: 129.173s
[2K
| Adam | epoch: 011 | loss: 0.03494 - acc: 0.9914 -- iter: 0544/2068
[A[ATraining Step: 668  | total loss: [1m[32m0.03811[0m[0m | time: 137.063s
[2K
| Adam | epoch: 011 | loss: 0.03811 - acc: 0.9861 -- iter: 0576/2068
[A[ATraining Step: 669  | total loss: [1m[32m0.03561[0m[0m | time: 145.137s
[2K
| Adam | epoch: 011 | loss: 0.03561 - acc: 0.9874 -- iter: 0608/2068
[A[ATraining Step: 670  | total loss: [1m[32m0.03923[0m[0m | time: 153.071s
[2K
| Adam | epoch: 011 | loss: 0.03923 - acc: 0.9825 -- iter: 0640/2068
[A[ATraining Step: 671  | total loss: [1m[32m0.03613[0m[0m | time: 161.016s
[2K
| Adam | epoch: 011 | loss: 0.03613 - acc: 0.9842 -- iter: 0672/2068
[A[ATraining Step: 672  | total loss: [1m[32m0.04240[0m[0m | time: 169.134s
[2K
| Adam | epoch: 011 | loss: 0.04240 - acc: 0.9827 -- iter: 0704/2068
[A[ATraining Step: 673  | total loss: [1m[32m0.05940[0m[0m | time: 177.091s
[2K
| Adam | epoch: 011 | loss: 0.05940 - acc: 0.9781 -- iter: 0736/2068
[A[ATraining Step: 674  | total loss: [1m[32m0.05652[0m[0m | time: 185.047s
[2K
| Adam | epoch: 011 | loss: 0.05652 - acc: 0.9803 -- iter: 0768/2068
[A[ATraining Step: 675  | total loss: [1m[32m0.05201[0m[0m | time: 192.860s
[2K
| Adam | epoch: 011 | loss: 0.05201 - acc: 0.9823 -- iter: 0800/2068
[A[ATraining Step: 676  | total loss: [1m[32m0.04837[0m[0m | time: 200.593s
[2K
| Adam | epoch: 011 | loss: 0.04837 - acc: 0.9841 -- iter: 0832/2068
[A[ATraining Step: 677  | total loss: [1m[32m0.04372[0m[0m | time: 208.665s
[2K
| Adam | epoch: 011 | loss: 0.04372 - acc: 0.9857 -- iter: 0864/2068
[A[ATraining Step: 678  | total loss: [1m[32m0.05749[0m[0m | time: 216.691s
[2K
| Adam | epoch: 011 | loss: 0.05749 - acc: 0.9808 -- iter: 0896/2068
[A[ATraining Step: 679  | total loss: [1m[32m0.05317[0m[0m | time: 224.795s
[2K
| Adam | epoch: 011 | loss: 0.05317 - acc: 0.9828 -- iter: 0928/2068
[A[ATraining Step: 680  | total loss: [1m[32m0.05196[0m[0m | time: 232.713s
[2K
| Adam | epoch: 011 | loss: 0.05196 - acc: 0.9814 -- iter: 0960/2068
[A[ATraining Step: 681  | total loss: [1m[32m0.04712[0m[0m | time: 240.711s
[2K
| Adam | epoch: 011 | loss: 0.04712 - acc: 0.9832 -- iter: 0992/2068
[A[ATraining Step: 682  | total loss: [1m[32m0.04757[0m[0m | time: 248.686s
[2K
| Adam | epoch: 011 | loss: 0.04757 - acc: 0.9818 -- iter: 1024/2068
[A[ATraining Step: 683  | total loss: [1m[32m0.05145[0m[0m | time: 256.834s
[2K
| Adam | epoch: 011 | loss: 0.05145 - acc: 0.9805 -- iter: 1056/2068
[A[ATraining Step: 684  | total loss: [1m[32m0.04747[0m[0m | time: 264.653s
[2K
| Adam | epoch: 011 | loss: 0.04747 - acc: 0.9824 -- iter: 1088/2068
[A[ATraining Step: 685  | total loss: [1m[32m0.05176[0m[0m | time: 272.615s
[2K
| Adam | epoch: 011 | loss: 0.05176 - acc: 0.9779 -- iter: 1120/2068
[A[ATraining Step: 686  | total loss: [1m[32m0.04691[0m[0m | time: 280.602s
[2K
| Adam | epoch: 011 | loss: 0.04691 - acc: 0.9801 -- iter: 1152/2068
[A[ATraining Step: 687  | total loss: [1m[32m0.05233[0m[0m | time: 288.540s
[2K
| Adam | epoch: 011 | loss: 0.05233 - acc: 0.9790 -- iter: 1184/2068
[A[ATraining Step: 688  | total loss: [1m[32m0.04762[0m[0m | time: 296.300s
[2K
| Adam | epoch: 011 | loss: 0.04762 - acc: 0.9811 -- iter: 1216/2068
[A[ATraining Step: 689  | total loss: [1m[32m0.05542[0m[0m | time: 304.362s
[2K
| Adam | epoch: 011 | loss: 0.05542 - acc: 0.9799 -- iter: 1248/2068
[A[ATraining Step: 690  | total loss: [1m[32m0.06749[0m[0m | time: 312.227s
[2K
| Adam | epoch: 011 | loss: 0.06749 - acc: 0.9725 -- iter: 1280/2068
[A[ATraining Step: 691  | total loss: [1m[32m0.06593[0m[0m | time: 320.350s
[2K
| Adam | epoch: 011 | loss: 0.06593 - acc: 0.9721 -- iter: 1312/2068
[A[ATraining Step: 692  | total loss: [1m[32m0.06021[0m[0m | time: 328.058s
[2K
| Adam | epoch: 011 | loss: 0.06021 - acc: 0.9749 -- iter: 1344/2068
[A[ATraining Step: 693  | total loss: [1m[32m0.05535[0m[0m | time: 336.010s
[2K
| Adam | epoch: 011 | loss: 0.05535 - acc: 0.9774 -- iter: 1376/2068
[A[ATraining Step: 694  | total loss: [1m[32m0.08224[0m[0m | time: 343.894s
[2K
| Adam | epoch: 011 | loss: 0.08224 - acc: 0.9734 -- iter: 1408/2068
[A[ATraining Step: 695  | total loss: [1m[32m0.07433[0m[0m | time: 351.825s
[2K
| Adam | epoch: 011 | loss: 0.07433 - acc: 0.9761 -- iter: 1440/2068
[A[ATraining Step: 696  | total loss: [1m[32m0.07130[0m[0m | time: 359.872s
[2K
| Adam | epoch: 011 | loss: 0.07130 - acc: 0.9754 -- iter: 1472/2068
[A[ATraining Step: 697  | total loss: [1m[32m0.07022[0m[0m | time: 367.879s
[2K
| Adam | epoch: 011 | loss: 0.07022 - acc: 0.9747 -- iter: 1504/2068
[A[ATraining Step: 698  | total loss: [1m[32m0.06408[0m[0m | time: 375.941s
[2K
| Adam | epoch: 011 | loss: 0.06408 - acc: 0.9772 -- iter: 1536/2068
[A[ATraining Step: 699  | total loss: [1m[32m0.08372[0m[0m | time: 384.058s
[2K
| Adam | epoch: 011 | loss: 0.08372 - acc: 0.9764 -- iter: 1568/2068
[A[ATraining Step: 700  | total loss: [1m[32m0.08064[0m[0m | time: 391.962s
[2K
| Adam | epoch: 011 | loss: 0.08064 - acc: 0.9787 -- iter: 1600/2068
[A[ATraining Step: 701  | total loss: [1m[32m0.07492[0m[0m | time: 399.842s
[2K
| Adam | epoch: 011 | loss: 0.07492 - acc: 0.9809 -- iter: 1632/2068
[A[ATraining Step: 702  | total loss: [1m[32m0.08727[0m[0m | time: 407.858s
[2K
| Adam | epoch: 011 | loss: 0.08727 - acc: 0.9765 -- iter: 1664/2068
[A[ATraining Step: 703  | total loss: [1m[32m0.07896[0m[0m | time: 415.641s
[2K
| Adam | epoch: 011 | loss: 0.07896 - acc: 0.9789 -- iter: 1696/2068
[A[ATraining Step: 704  | total loss: [1m[32m0.07344[0m[0m | time: 423.670s
[2K
| Adam | epoch: 011 | loss: 0.07344 - acc: 0.9810 -- iter: 1728/2068
[A[ATraining Step: 705  | total loss: [1m[32m0.06994[0m[0m | time: 431.644s
[2K
| Adam | epoch: 011 | loss: 0.06994 - acc: 0.9829 -- iter: 1760/2068
[A[ATraining Step: 706  | total loss: [1m[32m0.06312[0m[0m | time: 439.570s
[2K
| Adam | epoch: 011 | loss: 0.06312 - acc: 0.9846 -- iter: 1792/2068
[A[ATraining Step: 707  | total loss: [1m[32m0.07280[0m[0m | time: 447.491s
[2K
| Adam | epoch: 011 | loss: 0.07280 - acc: 0.9799 -- iter: 1824/2068
[A[ATraining Step: 708  | total loss: [1m[32m0.06774[0m[0m | time: 455.270s
[2K
| Adam | epoch: 011 | loss: 0.06774 - acc: 0.9819 -- iter: 1856/2068
[A[ATraining Step: 709  | total loss: [1m[32m0.06139[0m[0m | time: 463.168s
[2K
| Adam | epoch: 011 | loss: 0.06139 - acc: 0.9837 -- iter: 1888/2068
[A[ATraining Step: 710  | total loss: [1m[32m0.08984[0m[0m | time: 470.977s
[2K
| Adam | epoch: 011 | loss: 0.08984 - acc: 0.9728 -- iter: 1920/2068
[A[ATraining Step: 711  | total loss: [1m[32m0.08690[0m[0m | time: 479.032s
[2K
| Adam | epoch: 011 | loss: 0.08690 - acc: 0.9724 -- iter: 1952/2068
[A[ATraining Step: 712  | total loss: [1m[32m0.07971[0m[0m | time: 487.068s
[2K
| Adam | epoch: 011 | loss: 0.07971 - acc: 0.9752 -- iter: 1984/2068
[A[ATraining Step: 713  | total loss: [1m[32m0.07417[0m[0m | time: 495.068s
[2K
| Adam | epoch: 011 | loss: 0.07417 - acc: 0.9777 -- iter: 2016/2068
[A[ATraining Step: 714  | total loss: [1m[32m0.06741[0m[0m | time: 503.001s
[2K
| Adam | epoch: 011 | loss: 0.06741 - acc: 0.9799 -- iter: 2048/2068
[A[ATraining Step: 715  | total loss: [1m[32m0.06226[0m[0m | time: 540.097s
[2K
| Adam | epoch: 011 | loss: 0.06226 - acc: 0.9819 | val_loss: 1.77646 - val_acc: 0.7249 -- iter: 2068/2068
--
Training Step: 716  | total loss: [1m[32m0.05809[0m[0m | time: 7.956s
[2K
| Adam | epoch: 012 | loss: 0.05809 - acc: 0.9837 -- iter: 0032/2068
[A[ATraining Step: 717  | total loss: [1m[32m0.05629[0m[0m | time: 15.785s
[2K
| Adam | epoch: 012 | loss: 0.05629 - acc: 0.9853 -- iter: 0064/2068
[A[ATraining Step: 718  | total loss: [1m[32m0.05975[0m[0m | time: 23.588s
[2K
| Adam | epoch: 012 | loss: 0.05975 - acc: 0.9837 -- iter: 0096/2068
[A[ATraining Step: 719  | total loss: [1m[32m0.05458[0m[0m | time: 31.423s
[2K
| Adam | epoch: 012 | loss: 0.05458 - acc: 0.9853 -- iter: 0128/2068
[A[ATraining Step: 720  | total loss: [1m[32m0.06500[0m[0m | time: 39.508s
[2K
| Adam | epoch: 012 | loss: 0.06500 - acc: 0.9837 -- iter: 0160/2068
[A[ATraining Step: 721  | total loss: [1m[32m0.06254[0m[0m | time: 47.554s
[2K
| Adam | epoch: 012 | loss: 0.06254 - acc: 0.9822 -- iter: 0192/2068
[A[ATraining Step: 722  | total loss: [1m[32m0.05689[0m[0m | time: 55.393s
[2K
| Adam | epoch: 012 | loss: 0.05689 - acc: 0.9840 -- iter: 0224/2068
[A[ATraining Step: 723  | total loss: [1m[32m0.05423[0m[0m | time: 63.346s
[2K
| Adam | epoch: 012 | loss: 0.05423 - acc: 0.9856 -- iter: 0256/2068
[A[ATraining Step: 724  | total loss: [1m[32m0.05150[0m[0m | time: 71.357s
[2K
| Adam | epoch: 012 | loss: 0.05150 - acc: 0.9870 -- iter: 0288/2068
[A[ATraining Step: 725  | total loss: [1m[32m0.05449[0m[0m | time: 76.748s
[2K
| Adam | epoch: 012 | loss: 0.05449 - acc: 0.9852 -- iter: 0320/2068
[A[ATraining Step: 726  | total loss: [1m[32m0.05088[0m[0m | time: 82.144s
[2K
| Adam | epoch: 012 | loss: 0.05088 - acc: 0.9867 -- iter: 0352/2068
[A[ATraining Step: 727  | total loss: [1m[32m0.04619[0m[0m | time: 90.319s
[2K
| Adam | epoch: 012 | loss: 0.04619 - acc: 0.9880 -- iter: 0384/2068
[A[ATraining Step: 728  | total loss: [1m[32m0.04583[0m[0m | time: 98.348s
[2K
| Adam | epoch: 012 | loss: 0.04583 - acc: 0.9861 -- iter: 0416/2068
[A[ATraining Step: 729  | total loss: [1m[32m0.05718[0m[0m | time: 106.233s
[2K
| Adam | epoch: 012 | loss: 0.05718 - acc: 0.9812 -- iter: 0448/2068
[A[ATraining Step: 730  | total loss: [1m[32m0.05244[0m[0m | time: 114.076s
[2K
| Adam | epoch: 012 | loss: 0.05244 - acc: 0.9831 -- iter: 0480/2068
[A[ATraining Step: 731  | total loss: [1m[32m0.05088[0m[0m | time: 122.034s
[2K
| Adam | epoch: 012 | loss: 0.05088 - acc: 0.9817 -- iter: 0512/2068
[A[ATraining Step: 732  | total loss: [1m[32m0.05215[0m[0m | time: 129.928s
[2K
| Adam | epoch: 012 | loss: 0.05215 - acc: 0.9772 -- iter: 0544/2068
[A[ATraining Step: 733  | total loss: [1m[32m0.05577[0m[0m | time: 137.720s
[2K
| Adam | epoch: 012 | loss: 0.05577 - acc: 0.9764 -- iter: 0576/2068
[A[ATraining Step: 734  | total loss: [1m[32m0.05704[0m[0m | time: 145.504s
[2K
| Adam | epoch: 012 | loss: 0.05704 - acc: 0.9725 -- iter: 0608/2068
[A[ATraining Step: 735  | total loss: [1m[32m0.05249[0m[0m | time: 153.445s
[2K
| Adam | epoch: 012 | loss: 0.05249 - acc: 0.9753 -- iter: 0640/2068
[A[ATraining Step: 736  | total loss: [1m[32m0.05172[0m[0m | time: 161.514s
[2K
| Adam | epoch: 012 | loss: 0.05172 - acc: 0.9746 -- iter: 0672/2068
[A[ATraining Step: 737  | total loss: [1m[32m0.05482[0m[0m | time: 169.432s
[2K
| Adam | epoch: 012 | loss: 0.05482 - acc: 0.9740 -- iter: 0704/2068
[A[ATraining Step: 738  | total loss: [1m[32m0.05023[0m[0m | time: 177.240s
[2K
| Adam | epoch: 012 | loss: 0.05023 - acc: 0.9766 -- iter: 0736/2068
[A[ATraining Step: 739  | total loss: [1m[32m0.05683[0m[0m | time: 185.140s
[2K
| Adam | epoch: 012 | loss: 0.05683 - acc: 0.9758 -- iter: 0768/2068
[A[ATraining Step: 740  | total loss: [1m[32m0.05764[0m[0m | time: 193.039s
[2K
| Adam | epoch: 012 | loss: 0.05764 - acc: 0.9751 -- iter: 0800/2068
[A[ATraining Step: 741  | total loss: [1m[32m0.05419[0m[0m | time: 201.015s
[2K
| Adam | epoch: 012 | loss: 0.05419 - acc: 0.9776 -- iter: 0832/2068
[A[ATraining Step: 742  | total loss: [1m[32m0.05000[0m[0m | time: 208.976s
[2K
| Adam | epoch: 012 | loss: 0.05000 - acc: 0.9798 -- iter: 0864/2068
[A[ATraining Step: 743  | total loss: [1m[32m0.05098[0m[0m | time: 217.123s
[2K
| Adam | epoch: 012 | loss: 0.05098 - acc: 0.9787 -- iter: 0896/2068
[A[ATraining Step: 744  | total loss: [1m[32m0.06134[0m[0m | time: 224.873s
[2K
| Adam | epoch: 012 | loss: 0.06134 - acc: 0.9746 -- iter: 0928/2068
[A[ATraining Step: 745  | total loss: [1m[32m0.05732[0m[0m | time: 232.951s
[2K
| Adam | epoch: 012 | loss: 0.05732 - acc: 0.9772 -- iter: 0960/2068
[A[ATraining Step: 746  | total loss: [1m[32m0.05294[0m[0m | time: 240.926s
[2K
| Adam | epoch: 012 | loss: 0.05294 - acc: 0.9794 -- iter: 0992/2068
[A[ATraining Step: 747  | total loss: [1m[32m0.04784[0m[0m | time: 248.833s
[2K
| Adam | epoch: 012 | loss: 0.04784 - acc: 0.9815 -- iter: 1024/2068
[A[ATraining Step: 748  | total loss: [1m[32m0.05484[0m[0m | time: 256.796s
[2K
| Adam | epoch: 012 | loss: 0.05484 - acc: 0.9771 -- iter: 1056/2068
[A[ATraining Step: 749  | total loss: [1m[32m0.05919[0m[0m | time: 264.512s
[2K
| Adam | epoch: 012 | loss: 0.05919 - acc: 0.9763 -- iter: 1088/2068
[A[ATraining Step: 750  | total loss: [1m[32m0.05426[0m[0m | time: 272.448s
[2K
| Adam | epoch: 012 | loss: 0.05426 - acc: 0.9786 -- iter: 1120/2068
[A[ATraining Step: 751  | total loss: [1m[32m0.05697[0m[0m | time: 280.397s
[2K
| Adam | epoch: 012 | loss: 0.05697 - acc: 0.9776 -- iter: 1152/2068
[A[ATraining Step: 752  | total loss: [1m[32m0.05653[0m[0m | time: 288.277s
[2K
| Adam | epoch: 012 | loss: 0.05653 - acc: 0.9768 -- iter: 1184/2068
[A[ATraining Step: 753  | total loss: [1m[32m0.05849[0m[0m | time: 296.385s
[2K
| Adam | epoch: 012 | loss: 0.05849 - acc: 0.9760 -- iter: 1216/2068
[A[ATraining Step: 754  | total loss: [1m[32m0.06729[0m[0m | time: 304.316s
[2K
| Adam | epoch: 012 | loss: 0.06729 - acc: 0.9752 -- iter: 1248/2068
[A[ATraining Step: 755  | total loss: [1m[32m0.06160[0m[0m | time: 312.166s
[2K
| Adam | epoch: 012 | loss: 0.06160 - acc: 0.9777 -- iter: 1280/2068
[A[ATraining Step: 756  | total loss: [1m[32m0.06331[0m[0m | time: 320.122s
[2K
| Adam | epoch: 012 | loss: 0.06331 - acc: 0.9768 -- iter: 1312/2068
[A[ATraining Step: 757  | total loss: [1m[32m0.05890[0m[0m | time: 328.303s
[2K
| Adam | epoch: 012 | loss: 0.05890 - acc: 0.9791 -- iter: 1344/2068
[A[ATraining Step: 758  | total loss: [1m[32m0.05686[0m[0m | time: 336.012s
[2K
| Adam | epoch: 012 | loss: 0.05686 - acc: 0.9812 -- iter: 1376/2068
[A[ATraining Step: 759  | total loss: [1m[32m0.06545[0m[0m | time: 343.982s
[2K
| Adam | epoch: 012 | loss: 0.06545 - acc: 0.9768 -- iter: 1408/2068
[A[ATraining Step: 760  | total loss: [1m[32m0.07537[0m[0m | time: 351.925s
[2K
| Adam | epoch: 012 | loss: 0.07537 - acc: 0.9729 -- iter: 1440/2068
[A[ATraining Step: 761  | total loss: [1m[32m0.07019[0m[0m | time: 359.886s
[2K
| Adam | epoch: 012 | loss: 0.07019 - acc: 0.9756 -- iter: 1472/2068
[A[ATraining Step: 762  | total loss: [1m[32m0.08316[0m[0m | time: 367.944s
[2K
| Adam | epoch: 012 | loss: 0.08316 - acc: 0.9718 -- iter: 1504/2068
[A[ATraining Step: 763  | total loss: [1m[32m0.07745[0m[0m | time: 376.103s
[2K
| Adam | epoch: 012 | loss: 0.07745 - acc: 0.9746 -- iter: 1536/2068
[A[ATraining Step: 764  | total loss: [1m[32m0.07053[0m[0m | time: 384.073s
[2K
| Adam | epoch: 012 | loss: 0.07053 - acc: 0.9772 -- iter: 1568/2068
[A[ATraining Step: 765  | total loss: [1m[32m0.06497[0m[0m | time: 392.051s
[2K
| Adam | epoch: 012 | loss: 0.06497 - acc: 0.9794 -- iter: 1600/2068
[A[ATraining Step: 766  | total loss: [1m[32m0.05925[0m[0m | time: 400.034s
[2K
| Adam | epoch: 012 | loss: 0.05925 - acc: 0.9815 -- iter: 1632/2068
[A[ATraining Step: 767  | total loss: [1m[32m0.05818[0m[0m | time: 408.346s
[2K
| Adam | epoch: 012 | loss: 0.05818 - acc: 0.9802 -- iter: 1664/2068
[A[ATraining Step: 768  | total loss: [1m[32m0.06225[0m[0m | time: 416.486s
[2K
| Adam | epoch: 012 | loss: 0.06225 - acc: 0.9791 -- iter: 1696/2068
[A[ATraining Step: 769  | total loss: [1m[32m0.06027[0m[0m | time: 424.531s
[2K
| Adam | epoch: 012 | loss: 0.06027 - acc: 0.9780 -- iter: 1728/2068
[A[ATraining Step: 770  | total loss: [1m[32m0.06480[0m[0m | time: 432.533s
[2K
| Adam | epoch: 012 | loss: 0.06480 - acc: 0.9771 -- iter: 1760/2068
[A[ATraining Step: 771  | total loss: [1m[32m0.05986[0m[0m | time: 440.497s
[2K
| Adam | epoch: 012 | loss: 0.05986 - acc: 0.9794 -- iter: 1792/2068
[A[ATraining Step: 772  | total loss: [1m[32m0.06810[0m[0m | time: 448.468s
[2K
| Adam | epoch: 012 | loss: 0.06810 - acc: 0.9752 -- iter: 1824/2068
[A[ATraining Step: 773  | total loss: [1m[32m0.06173[0m[0m | time: 456.381s
[2K
| Adam | epoch: 012 | loss: 0.06173 - acc: 0.9777 -- iter: 1856/2068
[A[ATraining Step: 774  | total loss: [1m[32m0.05634[0m[0m | time: 464.272s
[2K
| Adam | epoch: 012 | loss: 0.05634 - acc: 0.9799 -- iter: 1888/2068
[A[ATraining Step: 775  | total loss: [1m[32m0.05396[0m[0m | time: 472.111s
[2K
| Adam | epoch: 012 | loss: 0.05396 - acc: 0.9819 -- iter: 1920/2068
[A[ATraining Step: 776  | total loss: [1m[32m0.04897[0m[0m | time: 479.956s
[2K
| Adam | epoch: 012 | loss: 0.04897 - acc: 0.9837 -- iter: 1952/2068
[A[ATraining Step: 777  | total loss: [1m[32m0.06025[0m[0m | time: 487.858s
[2K
| Adam | epoch: 012 | loss: 0.06025 - acc: 0.9822 -- iter: 1984/2068
[A[ATraining Step: 778  | total loss: [1m[32m0.06447[0m[0m | time: 495.684s
[2K
| Adam | epoch: 012 | loss: 0.06447 - acc: 0.9778 -- iter: 2016/2068
[A[ATraining Step: 779  | total loss: [1m[32m0.05968[0m[0m | time: 503.649s
[2K
| Adam | epoch: 012 | loss: 0.05968 - acc: 0.9800 -- iter: 2048/2068
[A[ATraining Step: 780  | total loss: [1m[32m0.06019[0m[0m | time: 540.493s
[2K
| Adam | epoch: 012 | loss: 0.06019 - acc: 0.9789 | val_loss: 1.19304 - val_acc: 0.7357 -- iter: 2068/2068
--
Training Step: 781  | total loss: [1m[32m0.05475[0m[0m | time: 7.775s
[2K
| Adam | epoch: 013 | loss: 0.05475 - acc: 0.9810 -- iter: 0032/2068
[A[ATraining Step: 782  | total loss: [1m[32m0.05011[0m[0m | time: 15.702s
[2K
| Adam | epoch: 013 | loss: 0.05011 - acc: 0.9829 -- iter: 0064/2068
[A[ATraining Step: 783  | total loss: [1m[32m0.05068[0m[0m | time: 23.555s
[2K
| Adam | epoch: 013 | loss: 0.05068 - acc: 0.9846 -- iter: 0096/2068
[A[ATraining Step: 784  | total loss: [1m[32m0.04726[0m[0m | time: 31.369s
[2K
| Adam | epoch: 013 | loss: 0.04726 - acc: 0.9861 -- iter: 0128/2068
[A[ATraining Step: 785  | total loss: [1m[32m0.04756[0m[0m | time: 39.076s
[2K
| Adam | epoch: 013 | loss: 0.04756 - acc: 0.9844 -- iter: 0160/2068
[A[ATraining Step: 786  | total loss: [1m[32m0.05116[0m[0m | time: 46.938s
[2K
| Adam | epoch: 013 | loss: 0.05116 - acc: 0.9828 -- iter: 0192/2068
[A[ATraining Step: 787  | total loss: [1m[32m0.04730[0m[0m | time: 54.859s
[2K
| Adam | epoch: 013 | loss: 0.04730 - acc: 0.9845 -- iter: 0224/2068
[A[ATraining Step: 788  | total loss: [1m[32m0.04596[0m[0m | time: 62.698s
[2K
| Adam | epoch: 013 | loss: 0.04596 - acc: 0.9861 -- iter: 0256/2068
[A[ATraining Step: 789  | total loss: [1m[32m0.05062[0m[0m | time: 70.757s
[2K
| Adam | epoch: 013 | loss: 0.05062 - acc: 0.9844 -- iter: 0288/2068
[A[ATraining Step: 790  | total loss: [1m[32m0.05468[0m[0m | time: 78.632s
[2K
| Adam | epoch: 013 | loss: 0.05468 - acc: 0.9828 -- iter: 0320/2068
[A[ATraining Step: 791  | total loss: [1m[32m0.04987[0m[0m | time: 83.926s
[2K
| Adam | epoch: 013 | loss: 0.04987 - acc: 0.9845 -- iter: 0352/2068
[A[ATraining Step: 792  | total loss: [1m[32m0.05306[0m[0m | time: 89.321s
[2K
| Adam | epoch: 013 | loss: 0.05306 - acc: 0.9861 -- iter: 0384/2068
[A[ATraining Step: 793  | total loss: [1m[32m0.04993[0m[0m | time: 97.180s
[2K
| Adam | epoch: 013 | loss: 0.04993 - acc: 0.9875 -- iter: 0416/2068
[A[ATraining Step: 794  | total loss: [1m[32m0.04700[0m[0m | time: 105.221s
[2K
| Adam | epoch: 013 | loss: 0.04700 - acc: 0.9887 -- iter: 0448/2068
[A[ATraining Step: 795  | total loss: [1m[32m0.04434[0m[0m | time: 113.092s
[2K
| Adam | epoch: 013 | loss: 0.04434 - acc: 0.9898 -- iter: 0480/2068
[A[ATraining Step: 796  | total loss: [1m[32m0.04129[0m[0m | time: 120.931s
[2K
| Adam | epoch: 013 | loss: 0.04129 - acc: 0.9909 -- iter: 0512/2068
[A[ATraining Step: 797  | total loss: [1m[32m0.04013[0m[0m | time: 128.809s
[2K
| Adam | epoch: 013 | loss: 0.04013 - acc: 0.9918 -- iter: 0544/2068
[A[ATraining Step: 798  | total loss: [1m[32m0.06093[0m[0m | time: 136.768s
[2K
| Adam | epoch: 013 | loss: 0.06093 - acc: 0.9863 -- iter: 0576/2068
[A[ATraining Step: 799  | total loss: [1m[32m0.07136[0m[0m | time: 144.857s
[2K
| Adam | epoch: 013 | loss: 0.07136 - acc: 0.9783 -- iter: 0608/2068
[A[ATraining Step: 800  | total loss: [1m[32m0.06997[0m[0m | time: 181.781s
[2K
| Adam | epoch: 013 | loss: 0.06997 - acc: 0.9774 | val_loss: 6.80900 - val_acc: 0.5054 -- iter: 0640/2068
--
Training Step: 801  | total loss: [1m[32m0.06327[0m[0m | time: 189.626s
[2K
| Adam | epoch: 013 | loss: 0.06327 - acc: 0.9796 -- iter: 0672/2068
[A[ATraining Step: 802  | total loss: [1m[32m0.05794[0m[0m | time: 197.545s
[2K
| Adam | epoch: 013 | loss: 0.05794 - acc: 0.9817 -- iter: 0704/2068
[A[ATraining Step: 803  | total loss: [1m[32m0.05606[0m[0m | time: 205.549s
[2K
| Adam | epoch: 013 | loss: 0.05606 - acc: 0.9835 -- iter: 0736/2068
[A[ATraining Step: 804  | total loss: [1m[32m0.06332[0m[0m | time: 213.306s
[2K
| Adam | epoch: 013 | loss: 0.06332 - acc: 0.9789 -- iter: 0768/2068
[A[ATraining Step: 805  | total loss: [1m[32m0.05822[0m[0m | time: 221.302s
[2K
| Adam | epoch: 013 | loss: 0.05822 - acc: 0.9810 -- iter: 0800/2068
[A[ATraining Step: 806  | total loss: [1m[32m0.05440[0m[0m | time: 229.134s
[2K
| Adam | epoch: 013 | loss: 0.05440 - acc: 0.9829 -- iter: 0832/2068
[A[ATraining Step: 807  | total loss: [1m[32m0.04958[0m[0m | time: 237.144s
[2K
| Adam | epoch: 013 | loss: 0.04958 - acc: 0.9846 -- iter: 0864/2068
[A[ATraining Step: 808  | total loss: [1m[32m0.04547[0m[0m | time: 244.888s
[2K
| Adam | epoch: 013 | loss: 0.04547 - acc: 0.9862 -- iter: 0896/2068
[A[ATraining Step: 809  | total loss: [1m[32m0.04194[0m[0m | time: 252.885s
[2K
| Adam | epoch: 013 | loss: 0.04194 - acc: 0.9875 -- iter: 0928/2068
[A[ATraining Step: 810  | total loss: [1m[32m0.03813[0m[0m | time: 260.798s
[2K
| Adam | epoch: 013 | loss: 0.03813 - acc: 0.9888 -- iter: 0960/2068
[A[ATraining Step: 811  | total loss: [1m[32m0.03569[0m[0m | time: 268.855s
[2K
| Adam | epoch: 013 | loss: 0.03569 - acc: 0.9899 -- iter: 0992/2068
[A[ATraining Step: 812  | total loss: [1m[32m0.03430[0m[0m | time: 276.760s
[2K
| Adam | epoch: 013 | loss: 0.03430 - acc: 0.9909 -- iter: 1024/2068
[A[ATraining Step: 813  | total loss: [1m[32m0.03208[0m[0m | time: 284.603s
[2K
| Adam | epoch: 013 | loss: 0.03208 - acc: 0.9918 -- iter: 1056/2068
[A[ATraining Step: 814  | total loss: [1m[32m0.03589[0m[0m | time: 292.491s
[2K
| Adam | epoch: 013 | loss: 0.03589 - acc: 0.9926 -- iter: 1088/2068
[A[ATraining Step: 815  | total loss: [1m[32m0.04557[0m[0m | time: 300.358s
[2K
| Adam | epoch: 013 | loss: 0.04557 - acc: 0.9903 -- iter: 1120/2068
[A[ATraining Step: 816  | total loss: [1m[32m0.04185[0m[0m | time: 308.440s
[2K
| Adam | epoch: 013 | loss: 0.04185 - acc: 0.9912 -- iter: 1152/2068
[A[ATraining Step: 817  | total loss: [1m[32m0.05791[0m[0m | time: 316.265s
[2K
| Adam | epoch: 013 | loss: 0.05791 - acc: 0.9890 -- iter: 1184/2068
[A[ATraining Step: 818  | total loss: [1m[32m0.05305[0m[0m | time: 324.176s
[2K
| Adam | epoch: 013 | loss: 0.05305 - acc: 0.9901 -- iter: 1216/2068
[A[ATraining Step: 819  | total loss: [1m[32m0.04877[0m[0m | time: 331.995s
[2K
| Adam | epoch: 013 | loss: 0.04877 - acc: 0.9911 -- iter: 1248/2068
[A[ATraining Step: 820  | total loss: [1m[32m0.04531[0m[0m | time: 339.831s
[2K
| Adam | epoch: 013 | loss: 0.04531 - acc: 0.9920 -- iter: 1280/2068
[A[ATraining Step: 821  | total loss: [1m[32m0.05208[0m[0m | time: 347.934s
[2K
| Adam | epoch: 013 | loss: 0.05208 - acc: 0.9865 -- iter: 1312/2068
[A[ATraining Step: 822  | total loss: [1m[32m0.07033[0m[0m | time: 355.830s
[2K
| Adam | epoch: 013 | loss: 0.07033 - acc: 0.9785 -- iter: 1344/2068
[A[ATraining Step: 823  | total loss: [1m[32m0.07147[0m[0m | time: 363.817s
[2K
| Adam | epoch: 013 | loss: 0.07147 - acc: 0.9744 -- iter: 1376/2068
[A[ATraining Step: 824  | total loss: [1m[32m0.09229[0m[0m | time: 371.684s
[2K
| Adam | epoch: 013 | loss: 0.09229 - acc: 0.9707 -- iter: 1408/2068
[A[ATraining Step: 825  | total loss: [1m[32m0.09086[0m[0m | time: 379.704s
[2K
| Adam | epoch: 013 | loss: 0.09086 - acc: 0.9674 -- iter: 1440/2068
[A[ATraining Step: 826  | total loss: [1m[32m0.09548[0m[0m | time: 387.753s
[2K
| Adam | epoch: 013 | loss: 0.09548 - acc: 0.9644 -- iter: 1472/2068
[A[ATraining Step: 827  | total loss: [1m[32m0.08680[0m[0m | time: 395.690s
[2K
| Adam | epoch: 013 | loss: 0.08680 - acc: 0.9680 -- iter: 1504/2068
[A[ATraining Step: 828  | total loss: [1m[32m0.07852[0m[0m | time: 403.756s
[2K
| Adam | epoch: 013 | loss: 0.07852 - acc: 0.9712 -- iter: 1536/2068
[A[ATraining Step: 829  | total loss: [1m[32m0.07669[0m[0m | time: 411.670s
[2K
| Adam | epoch: 013 | loss: 0.07669 - acc: 0.9709 -- iter: 1568/2068
[A[ATraining Step: 830  | total loss: [1m[32m0.11606[0m[0m | time: 419.294s
[2K
| Adam | epoch: 013 | loss: 0.11606 - acc: 0.9613 -- iter: 1600/2068
[A[ATraining Step: 831  | total loss: [1m[32m0.10884[0m[0m | time: 427.256s
[2K
| Adam | epoch: 013 | loss: 0.10884 - acc: 0.9621 -- iter: 1632/2068
[A[ATraining Step: 832  | total loss: [1m[32m0.11046[0m[0m | time: 435.018s
[2K
| Adam | epoch: 013 | loss: 0.11046 - acc: 0.9627 -- iter: 1664/2068
[A[ATraining Step: 833  | total loss: [1m[32m0.10790[0m[0m | time: 443.027s
[2K
| Adam | epoch: 013 | loss: 0.10790 - acc: 0.9633 -- iter: 1696/2068
[A[ATraining Step: 834  | total loss: [1m[32m0.10140[0m[0m | time: 450.910s
[2K
| Adam | epoch: 013 | loss: 0.10140 - acc: 0.9639 -- iter: 1728/2068
[A[ATraining Step: 835  | total loss: [1m[32m0.09623[0m[0m | time: 458.785s
[2K
| Adam | epoch: 013 | loss: 0.09623 - acc: 0.9675 -- iter: 1760/2068
[A[ATraining Step: 836  | total loss: [1m[32m0.08713[0m[0m | time: 466.649s
[2K
| Adam | epoch: 013 | loss: 0.08713 - acc: 0.9707 -- iter: 1792/2068
[A[ATraining Step: 837  | total loss: [1m[32m0.08236[0m[0m | time: 474.855s
[2K
| Adam | epoch: 013 | loss: 0.08236 - acc: 0.9737 -- iter: 1824/2068
[A[ATraining Step: 838  | total loss: [1m[32m0.07498[0m[0m | time: 482.703s
[2K
| Adam | epoch: 013 | loss: 0.07498 - acc: 0.9763 -- iter: 1856/2068
[A[ATraining Step: 839  | total loss: [1m[32m0.08907[0m[0m | time: 490.556s
[2K
| Adam | epoch: 013 | loss: 0.08907 - acc: 0.9724 -- iter: 1888/2068
[A[ATraining Step: 840  | total loss: [1m[32m0.08425[0m[0m | time: 498.333s
[2K
| Adam | epoch: 013 | loss: 0.08425 - acc: 0.9752 -- iter: 1920/2068
[A[ATraining Step: 841  | total loss: [1m[32m0.08143[0m[0m | time: 506.097s
[2K
| Adam | epoch: 013 | loss: 0.08143 - acc: 0.9745 -- iter: 1952/2068
[A[ATraining Step: 842  | total loss: [1m[32m0.07822[0m[0m | time: 514.038s
[2K
| Adam | epoch: 013 | loss: 0.07822 - acc: 0.9740 -- iter: 1984/2068
[A[ATraining Step: 843  | total loss: [1m[32m0.08224[0m[0m | time: 522.023s
[2K
| Adam | epoch: 013 | loss: 0.08224 - acc: 0.9734 -- iter: 2016/2068
[A[ATraining Step: 844  | total loss: [1m[32m0.08967[0m[0m | time: 529.917s
[2K
| Adam | epoch: 013 | loss: 0.08967 - acc: 0.9730 -- iter: 2048/2068
[A[ATraining Step: 845  | total loss: [1m[32m0.08162[0m[0m | time: 566.589s
[2K
| Adam | epoch: 013 | loss: 0.08162 - acc: 0.9757 | val_loss: 0.49475 - val_acc: 0.8377 -- iter: 2068/2068
--
Training Step: 846  | total loss: [1m[32m0.07672[0m[0m | time: 7.904s
[2K
| Adam | epoch: 014 | loss: 0.07672 - acc: 0.9781 -- iter: 0032/2068
[A[ATraining Step: 847  | total loss: [1m[32m0.07377[0m[0m | time: 15.715s
[2K
| Adam | epoch: 014 | loss: 0.07377 - acc: 0.9803 -- iter: 0064/2068
[A[ATraining Step: 848  | total loss: [1m[32m0.07881[0m[0m | time: 23.639s
[2K
| Adam | epoch: 014 | loss: 0.07881 - acc: 0.9760 -- iter: 0096/2068
[A[ATraining Step: 849  | total loss: [1m[32m0.07281[0m[0m | time: 31.468s
[2K
| Adam | epoch: 014 | loss: 0.07281 - acc: 0.9784 -- iter: 0128/2068
[A[ATraining Step: 850  | total loss: [1m[32m0.06612[0m[0m | time: 39.464s
[2K
| Adam | epoch: 014 | loss: 0.06612 - acc: 0.9806 -- iter: 0160/2068
[A[ATraining Step: 851  | total loss: [1m[32m0.06039[0m[0m | time: 47.638s
[2K
| Adam | epoch: 014 | loss: 0.06039 - acc: 0.9825 -- iter: 0192/2068
[A[ATraining Step: 852  | total loss: [1m[32m0.06277[0m[0m | time: 55.510s
[2K
| Adam | epoch: 014 | loss: 0.06277 - acc: 0.9811 -- iter: 0224/2068
[A[ATraining Step: 853  | total loss: [1m[32m0.06324[0m[0m | time: 63.163s
[2K
| Adam | epoch: 014 | loss: 0.06324 - acc: 0.9799 -- iter: 0256/2068
[A[ATraining Step: 854  | total loss: [1m[32m0.05759[0m[0m | time: 70.982s
[2K
| Adam | epoch: 014 | loss: 0.05759 - acc: 0.9819 -- iter: 0288/2068
[A[ATraining Step: 855  | total loss: [1m[32m0.05275[0m[0m | time: 78.998s
[2K
| Adam | epoch: 014 | loss: 0.05275 - acc: 0.9837 -- iter: 0320/2068
[A[ATraining Step: 856  | total loss: [1m[32m0.04921[0m[0m | time: 87.066s
[2K
| Adam | epoch: 014 | loss: 0.04921 - acc: 0.9853 -- iter: 0352/2068
[A[ATraining Step: 857  | total loss: [1m[32m0.04711[0m[0m | time: 92.402s
[2K
| Adam | epoch: 014 | loss: 0.04711 - acc: 0.9868 -- iter: 0384/2068
[A[ATraining Step: 858  | total loss: [1m[32m0.04547[0m[0m | time: 97.985s
[2K
| Adam | epoch: 014 | loss: 0.04547 - acc: 0.9881 -- iter: 0416/2068
[A[ATraining Step: 859  | total loss: [1m[32m0.04222[0m[0m | time: 105.943s
[2K
| Adam | epoch: 014 | loss: 0.04222 - acc: 0.9893 -- iter: 0448/2068
[A[ATraining Step: 860  | total loss: [1m[32m0.03935[0m[0m | time: 113.892s
[2K
| Adam | epoch: 014 | loss: 0.03935 - acc: 0.9904 -- iter: 0480/2068
[A[ATraining Step: 861  | total loss: [1m[32m0.03723[0m[0m | time: 121.755s
[2K
| Adam | epoch: 014 | loss: 0.03723 - acc: 0.9913 -- iter: 0512/2068
[A[ATraining Step: 862  | total loss: [1m[32m0.03497[0m[0m | time: 129.881s
[2K
| Adam | epoch: 014 | loss: 0.03497 - acc: 0.9922 -- iter: 0544/2068
[A[ATraining Step: 863  | total loss: [1m[32m0.04054[0m[0m | time: 137.774s
[2K
| Adam | epoch: 014 | loss: 0.04054 - acc: 0.9899 -- iter: 0576/2068
[A[ATraining Step: 864  | total loss: [1m[32m0.03743[0m[0m | time: 145.744s
[2K
| Adam | epoch: 014 | loss: 0.03743 - acc: 0.9909 -- iter: 0608/2068
[A[ATraining Step: 865  | total loss: [1m[32m0.03915[0m[0m | time: 153.562s
[2K
| Adam | epoch: 014 | loss: 0.03915 - acc: 0.9887 -- iter: 0640/2068
[A[ATraining Step: 866  | total loss: [1m[32m0.05199[0m[0m | time: 161.478s
[2K
| Adam | epoch: 014 | loss: 0.05199 - acc: 0.9836 -- iter: 0672/2068
[A[ATraining Step: 867  | total loss: [1m[32m0.04797[0m[0m | time: 169.336s
[2K
| Adam | epoch: 014 | loss: 0.04797 - acc: 0.9852 -- iter: 0704/2068
[A[ATraining Step: 868  | total loss: [1m[32m0.04953[0m[0m | time: 177.043s
[2K
| Adam | epoch: 014 | loss: 0.04953 - acc: 0.9836 -- iter: 0736/2068
[A[ATraining Step: 869  | total loss: [1m[32m0.04802[0m[0m | time: 184.967s
[2K
| Adam | epoch: 014 | loss: 0.04802 - acc: 0.9821 -- iter: 0768/2068
[A[ATraining Step: 870  | total loss: [1m[32m0.05126[0m[0m | time: 193.054s
[2K
| Adam | epoch: 014 | loss: 0.05126 - acc: 0.9807 -- iter: 0800/2068
[A[ATraining Step: 871  | total loss: [1m[32m0.04935[0m[0m | time: 201.042s
[2K
| Adam | epoch: 014 | loss: 0.04935 - acc: 0.9795 -- iter: 0832/2068
[A[ATraining Step: 872  | total loss: [1m[32m0.04565[0m[0m | time: 208.804s
[2K
| Adam | epoch: 014 | loss: 0.04565 - acc: 0.9816 -- iter: 0864/2068
[A[ATraining Step: 873  | total loss: [1m[32m0.04462[0m[0m | time: 216.601s
[2K
| Adam | epoch: 014 | loss: 0.04462 - acc: 0.9803 -- iter: 0896/2068
[A[ATraining Step: 874  | total loss: [1m[32m0.04101[0m[0m | time: 224.424s
[2K
| Adam | epoch: 014 | loss: 0.04101 - acc: 0.9823 -- iter: 0928/2068
[A[ATraining Step: 875  | total loss: [1m[32m0.04365[0m[0m | time: 232.160s
[2K
| Adam | epoch: 014 | loss: 0.04365 - acc: 0.9809 -- iter: 0960/2068
[A[ATraining Step: 876  | total loss: [1m[32m0.05040[0m[0m | time: 240.203s
[2K
| Adam | epoch: 014 | loss: 0.05040 - acc: 0.9766 -- iter: 0992/2068
[A[ATraining Step: 877  | total loss: [1m[32m0.05622[0m[0m | time: 248.132s
[2K
| Adam | epoch: 014 | loss: 0.05622 - acc: 0.9758 -- iter: 1024/2068
[A[ATraining Step: 878  | total loss: [1m[32m0.05116[0m[0m | time: 256.069s
[2K
| Adam | epoch: 014 | loss: 0.05116 - acc: 0.9782 -- iter: 1056/2068
[A[ATraining Step: 879  | total loss: [1m[32m0.04659[0m[0m | time: 263.948s
[2K
| Adam | epoch: 014 | loss: 0.04659 - acc: 0.9804 -- iter: 1088/2068
[A[ATraining Step: 880  | total loss: [1m[32m0.04270[0m[0m | time: 271.727s
[2K
| Adam | epoch: 014 | loss: 0.04270 - acc: 0.9824 -- iter: 1120/2068
[A[ATraining Step: 881  | total loss: [1m[32m0.03933[0m[0m | time: 279.485s
[2K
| Adam | epoch: 014 | loss: 0.03933 - acc: 0.9841 -- iter: 1152/2068
[A[ATraining Step: 882  | total loss: [1m[32m0.03667[0m[0m | time: 287.394s
[2K
| Adam | epoch: 014 | loss: 0.03667 - acc: 0.9857 -- iter: 1184/2068
[A[ATraining Step: 883  | total loss: [1m[32m0.03486[0m[0m | time: 295.336s
[2K
| Adam | epoch: 014 | loss: 0.03486 - acc: 0.9871 -- iter: 1216/2068
[A[ATraining Step: 884  | total loss: [1m[32m0.03257[0m[0m | time: 303.337s
[2K
| Adam | epoch: 014 | loss: 0.03257 - acc: 0.9884 -- iter: 1248/2068
[A[ATraining Step: 885  | total loss: [1m[32m0.03610[0m[0m | time: 311.173s
[2K
| Adam | epoch: 014 | loss: 0.03610 - acc: 0.9865 -- iter: 1280/2068
[A[ATraining Step: 886  | total loss: [1m[32m0.03367[0m[0m | time: 319.055s
[2K
| Adam | epoch: 014 | loss: 0.03367 - acc: 0.9878 -- iter: 1312/2068
[A[ATraining Step: 887  | total loss: [1m[32m0.03246[0m[0m | time: 327.098s
[2K
| Adam | epoch: 014 | loss: 0.03246 - acc: 0.9890 -- iter: 1344/2068
[A[ATraining Step: 888  | total loss: [1m[32m0.03059[0m[0m | time: 334.991s
[2K
| Adam | epoch: 014 | loss: 0.03059 - acc: 0.9901 -- iter: 1376/2068
[A[ATraining Step: 889  | total loss: [1m[32m0.02813[0m[0m | time: 342.805s
[2K
| Adam | epoch: 014 | loss: 0.02813 - acc: 0.9911 -- iter: 1408/2068
[A[ATraining Step: 890  | total loss: [1m[32m0.02872[0m[0m | time: 350.749s
[2K
| Adam | epoch: 014 | loss: 0.02872 - acc: 0.9920 -- iter: 1440/2068
[A[ATraining Step: 891  | total loss: [1m[32m0.03483[0m[0m | time: 358.727s
[2K
| Adam | epoch: 014 | loss: 0.03483 - acc: 0.9897 -- iter: 1472/2068
[A[ATraining Step: 892  | total loss: [1m[32m0.06361[0m[0m | time: 366.623s
[2K
| Adam | epoch: 014 | loss: 0.06361 - acc: 0.9876 -- iter: 1504/2068
[A[ATraining Step: 893  | total loss: [1m[32m0.05756[0m[0m | time: 374.622s
[2K
| Adam | epoch: 014 | loss: 0.05756 - acc: 0.9888 -- iter: 1536/2068
[A[ATraining Step: 894  | total loss: [1m[32m0.05196[0m[0m | time: 382.581s
[2K
| Adam | epoch: 014 | loss: 0.05196 - acc: 0.9899 -- iter: 1568/2068
[A[ATraining Step: 895  | total loss: [1m[32m0.05113[0m[0m | time: 390.532s
[2K
| Adam | epoch: 014 | loss: 0.05113 - acc: 0.9878 -- iter: 1600/2068
[A[ATraining Step: 896  | total loss: [1m[32m0.04687[0m[0m | time: 398.576s
[2K
| Adam | epoch: 014 | loss: 0.04687 - acc: 0.9890 -- iter: 1632/2068
[A[ATraining Step: 897  | total loss: [1m[32m0.04253[0m[0m | time: 406.469s
[2K
| Adam | epoch: 014 | loss: 0.04253 - acc: 0.9901 -- iter: 1664/2068
[A[ATraining Step: 898  | total loss: [1m[32m0.04027[0m[0m | time: 414.360s
[2K
| Adam | epoch: 014 | loss: 0.04027 - acc: 0.9911 -- iter: 1696/2068
[A[ATraining Step: 899  | total loss: [1m[32m0.03854[0m[0m | time: 422.254s
[2K
| Adam | epoch: 014 | loss: 0.03854 - acc: 0.9920 -- iter: 1728/2068
[A[ATraining Step: 900  | total loss: [1m[32m0.03554[0m[0m | time: 430.144s
[2K
| Adam | epoch: 014 | loss: 0.03554 - acc: 0.9928 -- iter: 1760/2068
[A[ATraining Step: 901  | total loss: [1m[32m0.03288[0m[0m | time: 438.045s
[2K
| Adam | epoch: 014 | loss: 0.03288 - acc: 0.9935 -- iter: 1792/2068
[A[ATraining Step: 902  | total loss: [1m[32m0.03208[0m[0m | time: 446.180s
[2K
| Adam | epoch: 014 | loss: 0.03208 - acc: 0.9942 -- iter: 1824/2068
[A[ATraining Step: 903  | total loss: [1m[32m0.03146[0m[0m | time: 454.302s
[2K
| Adam | epoch: 014 | loss: 0.03146 - acc: 0.9948 -- iter: 1856/2068
[A[ATraining Step: 904  | total loss: [1m[32m0.02927[0m[0m | time: 462.432s
[2K
| Adam | epoch: 014 | loss: 0.02927 - acc: 0.9953 -- iter: 1888/2068
[A[ATraining Step: 905  | total loss: [1m[32m0.02815[0m[0m | time: 470.334s
[2K
| Adam | epoch: 014 | loss: 0.02815 - acc: 0.9958 -- iter: 1920/2068
[A[ATraining Step: 906  | total loss: [1m[32m0.02652[0m[0m | time: 478.258s
[2K
| Adam | epoch: 014 | loss: 0.02652 - acc: 0.9962 -- iter: 1952/2068
[A[ATraining Step: 907  | total loss: [1m[32m0.02898[0m[0m | time: 486.253s
[2K
| Adam | epoch: 014 | loss: 0.02898 - acc: 0.9934 -- iter: 1984/2068
[A[ATraining Step: 908  | total loss: [1m[32m0.02615[0m[0m | time: 494.209s
[2K
| Adam | epoch: 014 | loss: 0.02615 - acc: 0.9941 -- iter: 2016/2068
[A[ATraining Step: 909  | total loss: [1m[32m0.02490[0m[0m | time: 502.004s
[2K
| Adam | epoch: 014 | loss: 0.02490 - acc: 0.9947 -- iter: 2048/2068
[A[ATraining Step: 910  | total loss: [1m[32m0.02615[0m[0m | time: 538.873s
[2K
| Adam | epoch: 014 | loss: 0.02615 - acc: 0.9921 | val_loss: 0.41333 - val_acc: 0.8748 -- iter: 2068/2068
--
Training Step: 911  | total loss: [1m[32m0.02361[0m[0m | time: 7.970s
[2K
| Adam | epoch: 015 | loss: 0.02361 - acc: 0.9929 -- iter: 0032/2068
[A[ATraining Step: 912  | total loss: [1m[32m0.02622[0m[0m | time: 15.780s
[2K
| Adam | epoch: 015 | loss: 0.02622 - acc: 0.9905 -- iter: 0064/2068
[A[ATraining Step: 913  | total loss: [1m[32m0.02719[0m[0m | time: 23.394s
[2K
| Adam | epoch: 015 | loss: 0.02719 - acc: 0.9883 -- iter: 0096/2068
[A[ATraining Step: 914  | total loss: [1m[32m0.02735[0m[0m | time: 31.310s
[2K
| Adam | epoch: 015 | loss: 0.02735 - acc: 0.9863 -- iter: 0128/2068
[A[ATraining Step: 915  | total loss: [1m[32m0.03488[0m[0m | time: 39.306s
[2K
| Adam | epoch: 015 | loss: 0.03488 - acc: 0.9846 -- iter: 0160/2068
[A[ATraining Step: 916  | total loss: [1m[32m0.03859[0m[0m | time: 47.242s
[2K
| Adam | epoch: 015 | loss: 0.03859 - acc: 0.9799 -- iter: 0192/2068
[A[ATraining Step: 917  | total loss: [1m[32m0.05495[0m[0m | time: 55.151s
[2K
| Adam | epoch: 015 | loss: 0.05495 - acc: 0.9788 -- iter: 0224/2068
[A[ATraining Step: 918  | total loss: [1m[32m0.05397[0m[0m | time: 63.066s
[2K
| Adam | epoch: 015 | loss: 0.05397 - acc: 0.9778 -- iter: 0256/2068
[A[ATraining Step: 919  | total loss: [1m[32m0.04921[0m[0m | time: 70.875s
[2K
| Adam | epoch: 015 | loss: 0.04921 - acc: 0.9800 -- iter: 0288/2068
[A[ATraining Step: 920  | total loss: [1m[32m0.04852[0m[0m | time: 78.866s
[2K
| Adam | epoch: 015 | loss: 0.04852 - acc: 0.9789 -- iter: 0320/2068
[A[ATraining Step: 921  | total loss: [1m[32m0.04449[0m[0m | time: 86.743s
[2K
| Adam | epoch: 015 | loss: 0.04449 - acc: 0.9810 -- iter: 0352/2068
[A[ATraining Step: 922  | total loss: [1m[32m0.04203[0m[0m | time: 94.851s
[2K
| Adam | epoch: 015 | loss: 0.04203 - acc: 0.9829 -- iter: 0384/2068
[A[ATraining Step: 923  | total loss: [1m[32m0.04340[0m[0m | time: 100.434s
[2K
| Adam | epoch: 015 | loss: 0.04340 - acc: 0.9815 -- iter: 0416/2068
[A[ATraining Step: 924  | total loss: [1m[32m0.03969[0m[0m | time: 105.861s
[2K
| Adam | epoch: 015 | loss: 0.03969 - acc: 0.9833 -- iter: 0448/2068
[A[ATraining Step: 925  | total loss: [1m[32m0.03622[0m[0m | time: 113.591s
[2K
| Adam | epoch: 015 | loss: 0.03622 - acc: 0.9850 -- iter: 0480/2068
[A[ATraining Step: 926  | total loss: [1m[32m0.03370[0m[0m | time: 121.503s
[2K
| Adam | epoch: 015 | loss: 0.03370 - acc: 0.9865 -- iter: 0512/2068
[A[ATraining Step: 927  | total loss: [1m[32m0.03330[0m[0m | time: 129.524s
[2K
| Adam | epoch: 015 | loss: 0.03330 - acc: 0.9878 -- iter: 0544/2068
[A[ATraining Step: 928  | total loss: [1m[32m0.03157[0m[0m | time: 137.584s
[2K
| Adam | epoch: 015 | loss: 0.03157 - acc: 0.9891 -- iter: 0576/2068
[A[ATraining Step: 929  | total loss: [1m[32m0.02965[0m[0m | time: 145.274s
[2K
| Adam | epoch: 015 | loss: 0.02965 - acc: 0.9901 -- iter: 0608/2068
[A[ATraining Step: 930  | total loss: [1m[32m0.02715[0m[0m | time: 153.180s
[2K
| Adam | epoch: 015 | loss: 0.02715 - acc: 0.9911 -- iter: 0640/2068
[A[ATraining Step: 931  | total loss: [1m[32m0.03158[0m[0m | time: 161.145s
[2K
| Adam | epoch: 015 | loss: 0.03158 - acc: 0.9889 -- iter: 0672/2068
[A[ATraining Step: 932  | total loss: [1m[32m0.03419[0m[0m | time: 168.980s
[2K
| Adam | epoch: 015 | loss: 0.03419 - acc: 0.9900 -- iter: 0704/2068
[A[ATraining Step: 933  | total loss: [1m[32m0.03096[0m[0m | time: 176.975s
[2K
| Adam | epoch: 015 | loss: 0.03096 - acc: 0.9910 -- iter: 0736/2068
[A[ATraining Step: 934  | total loss: [1m[32m0.04653[0m[0m | time: 185.012s
[2K
| Adam | epoch: 015 | loss: 0.04653 - acc: 0.9825 -- iter: 0768/2068
[A[ATraining Step: 935  | total loss: [1m[32m0.04254[0m[0m | time: 192.859s
[2K
| Adam | epoch: 015 | loss: 0.04254 - acc: 0.9843 -- iter: 0800/2068
[A[ATraining Step: 936  | total loss: [1m[32m0.04032[0m[0m | time: 200.847s
[2K
| Adam | epoch: 015 | loss: 0.04032 - acc: 0.9858 -- iter: 0832/2068
[A[ATraining Step: 937  | total loss: [1m[32m0.03826[0m[0m | time: 208.583s
[2K
| Adam | epoch: 015 | loss: 0.03826 - acc: 0.9873 -- iter: 0864/2068
[A[ATraining Step: 938  | total loss: [1m[32m0.04033[0m[0m | time: 216.532s
[2K
| Adam | epoch: 015 | loss: 0.04033 - acc: 0.9854 -- iter: 0896/2068
[A[ATraining Step: 939  | total loss: [1m[32m0.03764[0m[0m | time: 224.448s
[2K
| Adam | epoch: 015 | loss: 0.03764 - acc: 0.9869 -- iter: 0928/2068
[A[ATraining Step: 940  | total loss: [1m[32m0.03463[0m[0m | time: 232.593s
[2K
| Adam | epoch: 015 | loss: 0.03463 - acc: 0.9882 -- iter: 0960/2068
[A[ATraining Step: 941  | total loss: [1m[32m0.03202[0m[0m | time: 240.494s
[2K
| Adam | epoch: 015 | loss: 0.03202 - acc: 0.9894 -- iter: 0992/2068
[A[ATraining Step: 942  | total loss: [1m[32m0.03035[0m[0m | time: 248.514s
[2K
| Adam | epoch: 015 | loss: 0.03035 - acc: 0.9904 -- iter: 1024/2068
[A[ATraining Step: 943  | total loss: [1m[32m0.04838[0m[0m | time: 256.598s
[2K
| Adam | epoch: 015 | loss: 0.04838 - acc: 0.9883 -- iter: 1056/2068
[A[ATraining Step: 944  | total loss: [1m[32m0.04384[0m[0m | time: 264.524s
[2K
| Adam | epoch: 015 | loss: 0.04384 - acc: 0.9894 -- iter: 1088/2068
[A[ATraining Step: 945  | total loss: [1m[32m0.03992[0m[0m | time: 272.501s
[2K
| Adam | epoch: 015 | loss: 0.03992 - acc: 0.9905 -- iter: 1120/2068
[A[ATraining Step: 946  | total loss: [1m[32m0.06028[0m[0m | time: 280.408s
[2K
| Adam | epoch: 015 | loss: 0.06028 - acc: 0.9883 -- iter: 1152/2068
[A[ATraining Step: 947  | total loss: [1m[32m0.06098[0m[0m | time: 288.546s
[2K
| Adam | epoch: 015 | loss: 0.06098 - acc: 0.9864 -- iter: 1184/2068
[A[ATraining Step: 948  | total loss: [1m[32m0.06181[0m[0m | time: 296.480s
[2K
| Adam | epoch: 015 | loss: 0.06181 - acc: 0.9846 -- iter: 1216/2068
[A[ATraining Step: 949  | total loss: [1m[32m0.05585[0m[0m | time: 304.353s
[2K
| Adam | epoch: 015 | loss: 0.05585 - acc: 0.9861 -- iter: 1248/2068
[A[ATraining Step: 950  | total loss: [1m[32m0.05222[0m[0m | time: 312.497s
[2K
| Adam | epoch: 015 | loss: 0.05222 - acc: 0.9875 -- iter: 1280/2068
[A[ATraining Step: 951  | total loss: [1m[32m0.04734[0m[0m | time: 320.266s
[2K
| Adam | epoch: 015 | loss: 0.04734 - acc: 0.9888 -- iter: 1312/2068
[A[ATraining Step: 952  | total loss: [1m[32m0.04686[0m[0m | time: 328.179s
[2K
| Adam | epoch: 015 | loss: 0.04686 - acc: 0.9868 -- iter: 1344/2068
[A[ATraining Step: 953  | total loss: [1m[32m0.04504[0m[0m | time: 336.056s
[2K
| Adam | epoch: 015 | loss: 0.04504 - acc: 0.9881 -- iter: 1376/2068
[A[ATraining Step: 954  | total loss: [1m[32m0.04341[0m[0m | time: 344.001s
[2K
| Adam | epoch: 015 | loss: 0.04341 - acc: 0.9893 -- iter: 1408/2068
[A[ATraining Step: 955  | total loss: [1m[32m0.04266[0m[0m | time: 351.840s
[2K
| Adam | epoch: 015 | loss: 0.04266 - acc: 0.9904 -- iter: 1440/2068
[A[ATraining Step: 956  | total loss: [1m[32m0.04011[0m[0m | time: 359.970s
[2K
| Adam | epoch: 015 | loss: 0.04011 - acc: 0.9913 -- iter: 1472/2068
[A[ATraining Step: 957  | total loss: [1m[32m0.03845[0m[0m | time: 368.091s
[2K
| Adam | epoch: 015 | loss: 0.03845 - acc: 0.9922 -- iter: 1504/2068
[A[ATraining Step: 958  | total loss: [1m[32m0.06313[0m[0m | time: 375.997s
[2K
| Adam | epoch: 015 | loss: 0.06313 - acc: 0.9867 -- iter: 1536/2068
[A[ATraining Step: 959  | total loss: [1m[32m0.05753[0m[0m | time: 383.989s
[2K
| Adam | epoch: 015 | loss: 0.05753 - acc: 0.9880 -- iter: 1568/2068
[A[ATraining Step: 960  | total loss: [1m[32m0.05234[0m[0m | time: 391.880s
[2K
| Adam | epoch: 015 | loss: 0.05234 - acc: 0.9892 -- iter: 1600/2068
[A[ATraining Step: 961  | total loss: [1m[32m0.05026[0m[0m | time: 399.778s
[2K
| Adam | epoch: 015 | loss: 0.05026 - acc: 0.9872 -- iter: 1632/2068
[A[ATraining Step: 962  | total loss: [1m[32m0.04613[0m[0m | time: 407.965s
[2K
| Adam | epoch: 015 | loss: 0.04613 - acc: 0.9885 -- iter: 1664/2068
[A[ATraining Step: 963  | total loss: [1m[32m0.04238[0m[0m | time: 416.004s
[2K
| Adam | epoch: 015 | loss: 0.04238 - acc: 0.9896 -- iter: 1696/2068
[A[ATraining Step: 964  | total loss: [1m[32m0.04035[0m[0m | time: 424.118s
[2K
| Adam | epoch: 015 | loss: 0.04035 - acc: 0.9907 -- iter: 1728/2068
[A[ATraining Step: 965  | total loss: [1m[32m0.03910[0m[0m | time: 432.126s
[2K
| Adam | epoch: 015 | loss: 0.03910 - acc: 0.9885 -- iter: 1760/2068
[A[ATraining Step: 966  | total loss: [1m[32m0.03586[0m[0m | time: 440.278s
[2K
| Adam | epoch: 015 | loss: 0.03586 - acc: 0.9896 -- iter: 1792/2068
[A[ATraining Step: 967  | total loss: [1m[32m0.03262[0m[0m | time: 448.168s
[2K
| Adam | epoch: 015 | loss: 0.03262 - acc: 0.9907 -- iter: 1824/2068
[A[ATraining Step: 968  | total loss: [1m[32m0.03090[0m[0m | time: 456.204s
[2K
| Adam | epoch: 015 | loss: 0.03090 - acc: 0.9916 -- iter: 1856/2068
[A[ATraining Step: 969  | total loss: [1m[32m0.02973[0m[0m | time: 469.744s
[2K
| Adam | epoch: 015 | loss: 0.02973 - acc: 0.9924 -- iter: 1888/2068
[A[ATraining Step: 970  | total loss: [1m[32m0.02746[0m[0m | time: 483.355s
[2K
| Adam | epoch: 015 | loss: 0.02746 - acc: 0.9932 -- iter: 1920/2068
[A[ATraining Step: 971  | total loss: [1m[32m0.02924[0m[0m | time: 497.863s
[2K
| Adam | epoch: 015 | loss: 0.02924 - acc: 0.9939 -- iter: 1952/2068
[A[ATraining Step: 972  | total loss: [1m[32m0.02821[0m[0m | time: 515.237s
[2K
| Adam | epoch: 015 | loss: 0.02821 - acc: 0.9945 -- iter: 1984/2068
[A[ATraining Step: 973  | total loss: [1m[32m0.03016[0m[0m | time: 529.589s
[2K
| Adam | epoch: 015 | loss: 0.03016 - acc: 0.9950 -- iter: 2016/2068
[A[ATraining Step: 974  | total loss: [1m[32m0.02740[0m[0m | time: 544.530s
[2K
| Adam | epoch: 015 | loss: 0.02740 - acc: 0.9955 -- iter: 2048/2068
[A[ATraining Step: 975  | total loss: [1m[32m0.02694[0m[0m | time: 643.605s
[2K
| Adam | epoch: 015 | loss: 0.02694 - acc: 0.9960 | val_loss: 0.33186 - val_acc: 0.9335 -- iter: 2068/2068
--
Validation AUC:0.9677693689561594
Validation AUPRC:0.9705045998556648
Test AUC:0.9730128893662728
Test AUPRC:0.9713238955221334
BestTestF1Score	0.94	0.87	0.94	0.94	0.94	322	21	283	21	0.33
BestTestMCCScore	0.94	0.87	0.94	0.94	0.94	322	21	283	21	0.33
BestTestAccuracyScore	0.94	0.87	0.94	0.94	0.94	322	21	283	21	0.33
BestValidationF1Score	0.94	0.88	0.94	0.95	0.92	297	14	310	26	0.33
BestValidationMCC	0.94	0.88	0.94	0.95	0.92	297	14	310	26	0.33
BestValidationAccuracy	0.94	0.88	0.94	0.95	0.92	297	14	310	26	0.33
TestPredictions (Threshold:0.33)
CHEMBL473759,TP,ACT,1.0	CHEMBL104867,TP,ACT,0.9900000095367432	CHEMBL337340,TP,ACT,1.0	CHEMBL207630,TP,ACT,1.0	CHEMBL377026,TP,ACT,1.0	CHEMBL177204,TP,ACT,1.0	CHEMBL312268,TN,INACT,0.0	CHEMBL207190,TP,ACT,1.0	CHEMBL3144603,TN,INACT,0.0	CHEMBL1078015,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.0	CHEMBL2338392,FN,ACT,0.0	CHEMBL310369,TP,ACT,1.0	CHEMBL137327,TP,ACT,1.0	CHEMBL165175,TN,INACT,0.0	CHEMBL78669,TN,INACT,0.0	CHEMBL142822,TN,INACT,0.0	CHEMBL385245,TN,INACT,0.0	CHEMBL2436824,TN,INACT,0.0	CHEMBL3144600,TN,INACT,0.0	CHEMBL516027,TP,ACT,1.0	CHEMBL205706,TP,ACT,0.9900000095367432	CHEMBL310427,TN,INACT,0.0	CHEMBL42065,TN,INACT,0.029999999329447746	CHEMBL184390,TN,INACT,0.2800000011920929	CHEMBL105572,TP,ACT,1.0	CHEMBL83113,TP,ACT,1.0	CHEMBL176624,TP,ACT,1.0	CHEMBL2392142,TN,INACT,0.0	CHEMBL3665440,TN,INACT,0.0	CHEMBL499483,TP,ACT,1.0	CHEMBL279493,TN,INACT,0.0	CHEMBL315854,TN,INACT,0.0	CHEMBL358444,TN,INACT,0.0	CHEMBL207487,TP,ACT,1.0	CHEMBL350027,TP,ACT,1.0	CHEMBL3238444,TN,INACT,0.0	CHEMBL67563,TP,ACT,0.949999988079071	CHEMBL269140,TN,INACT,0.0	CHEMBL2431725,TN,INACT,0.0	CHEMBL1916491,TN,INACT,0.0	CHEMBL243048,TN,INACT,0.17000000178813934	CHEMBL278795,TN,INACT,0.009999999776482582	CHEMBL2093084,TN,INACT,0.0	CHEMBL540360,TN,INACT,0.0	CHEMBL3288121,TN,INACT,0.0	CHEMBL391379,TP,ACT,0.4699999988079071	CHEMBL273549,TN,INACT,0.009999999776482582	CHEMBL241497,TP,ACT,0.8799999952316284	CHEMBL3109173,FN,ACT,0.0	CHEMBL367383,TP,ACT,0.9900000095367432	CHEMBL367894,TP,ACT,1.0	CHEMBL1762464,TP,ACT,1.0	CHEMBL2259881,TP,ACT,1.0	CHEMBL234896,TP,ACT,1.0	CHEMBL108845,TP,ACT,1.0	CHEMBL241097,TP,ACT,1.0	CHEMBL459378,TP,ACT,0.9800000190734863	CHEMBL172760,TN,INACT,0.009999999776482582	CHEMBL472412,TP,ACT,1.0	CHEMBL328908,TP,ACT,1.0	CHEMBL557840,TN,INACT,0.0	CHEMBL1095815,TP,ACT,1.0	CHEMBL1762317,TP,ACT,0.6499999761581421	CHEMBL368360,TN,INACT,0.0	CHEMBL1223055,TN,INACT,0.009999999776482582	CHEMBL299155,TN,INACT,0.0	CHEMBL360524,TP,ACT,1.0	CHEMBL2436815,FP,INACT,0.5899999737739563	CHEMBL452150,TN,INACT,0.009999999776482582	CHEMBL367489,TP,ACT,1.0	CHEMBL234771,TN,INACT,0.10999999940395355	CHEMBL1762313,TP,ACT,0.7699999809265137	CHEMBL1085229,TP,ACT,1.0	CHEMBL107513,TN,INACT,0.0	CHEMBL2178569,TP,ACT,0.8799999952316284	CHEMBL317710,TP,ACT,0.9800000190734863	CHEMBL315176,TN,INACT,0.0	CHEMBL15153,TN,INACT,0.0	CHEMBL193440,TP,ACT,1.0	CHEMBL172322,TP,ACT,0.9900000095367432	CHEMBL1688979,FP,INACT,0.3700000047683716	CHEMBL310645,TP,ACT,1.0	CHEMBL177157,TP,ACT,1.0	CHEMBL309017,TN,INACT,0.009999999776482582	CHEMBL278117,TP,ACT,1.0	CHEMBL335971,TN,INACT,0.0	CHEMBL151803,TN,INACT,0.0	CHEMBL184240,TN,INACT,0.03999999910593033	CHEMBL287374,FP,INACT,1.0	CHEMBL100624,TN,INACT,0.0	CHEMBL2435877,TP,ACT,0.949999988079071	CHEMBL460630,TP,ACT,0.9900000095367432	CHEMBL1098150,TP,ACT,1.0	CHEMBL322693,TP,ACT,0.4699999988079071	CHEMBL106381,TP,ACT,0.9900000095367432	CHEMBL3290986,TN,INACT,0.029999999329447746	CHEMBL1951915,TP,ACT,0.9200000166893005	CHEMBL470578,TP,ACT,1.0	CHEMBL302038,TN,INACT,0.0	CHEMBL335794,TP,ACT,1.0	CHEMBL557015,TP,ACT,0.33000001311302185	CHEMBL505086,TN,INACT,0.009999999776482582	CHEMBL26607,TN,INACT,0.0	CHEMBL60435,TN,INACT,0.0	CHEMBL1269102,TN,INACT,0.0	CHEMBL2314764,TN,INACT,0.0	CHEMBL88976,TP,ACT,1.0	CHEMBL332471,TN,INACT,0.0	CHEMBL62808,TN,INACT,0.0	CHEMBL2112556,TP,ACT,1.0	CHEMBL431172,TN,INACT,0.0	CHEMBL233957,TN,INACT,0.0	CHEMBL24912,TN,INACT,0.0	CHEMBL474838,TP,ACT,1.0	CHEMBL475606,TP,ACT,1.0	CHEMBL92803,TP,ACT,1.0	CHEMBL3290984,TN,INACT,0.07000000029802322	CHEMBL3109175,TP,ACT,1.0	CHEMBL296245,TN,INACT,0.019999999552965164	CHEMBL1161419,TN,INACT,0.0	CHEMBL393971,TN,INACT,0.0	CHEMBL176426,TP,ACT,1.0	CHEMBL272490,TP,ACT,1.0	CHEMBL3393999,TN,INACT,0.0	CHEMBL1916689,TN,INACT,0.0	CHEMBL113,TN,INACT,0.0	CHEMBL1618631,TP,ACT,1.0	CHEMBL510201,TN,INACT,0.0	CHEMBL322439,TP,ACT,1.0	CHEMBL93229,TP,ACT,1.0	CHEMBL3084496,TP,ACT,1.0	CHEMBL2115465,TN,INACT,0.0	CHEMBL183769,TP,ACT,1.0	CHEMBL94179,TP,ACT,1.0	CHEMBL1080794,TP,ACT,1.0	CHEMBL492292,TP,ACT,1.0	CHEMBL2413877,TN,INACT,0.0	CHEMBL1270693,TP,ACT,1.0	CHEMBL171911,TP,ACT,1.0	CHEMBL284969,TN,INACT,0.0	CHEMBL180274,TP,ACT,0.5	CHEMBL523267,TP,ACT,1.0	CHEMBL394642,FP,INACT,0.44999998807907104	CHEMBL543251,TN,INACT,0.0	CHEMBL3746620,TN,INACT,0.009999999776482582	CHEMBL79667,TP,ACT,1.0	CHEMBL491319,TP,ACT,0.9700000286102295	CHEMBL101333,TP,ACT,1.0	CHEMBL1683190,FN,ACT,0.0	CHEMBL408492,TN,INACT,0.0	CHEMBL3604305,TN,INACT,0.0	CHEMBL67109,TN,INACT,0.0	CHEMBL322499,TN,INACT,0.0	CHEMBL2114183,FN,ACT,0.0	CHEMBL431111,TP,ACT,1.0	CHEMBL81719,TP,ACT,1.0	CHEMBL212243,TP,ACT,1.0	CHEMBL12344,TN,INACT,0.10999999940395355	CHEMBL394684,TP,ACT,1.0	CHEMBL2435880,TP,ACT,1.0	CHEMBL107092,TP,ACT,1.0	CHEMBL558620,TN,INACT,0.0	CHEMBL25977,TN,INACT,0.0	CHEMBL179858,TP,ACT,1.0	CHEMBL79697,TP,ACT,1.0	CHEMBL83963,TP,ACT,1.0	CHEMBL99331,TN,INACT,0.0	CHEMBL382079,TP,ACT,1.0	CHEMBL2282508,TP,ACT,0.5	CHEMBL366871,TP,ACT,1.0	CHEMBL241100,TN,INACT,0.23000000417232513	CHEMBL367169,TP,ACT,1.0	CHEMBL357628,FP,INACT,0.6800000071525574	CHEMBL540366,FN,ACT,0.019999999552965164	CHEMBL1951902,TP,ACT,1.0	CHEMBL1080152,TN,INACT,0.0	CHEMBL303737,TN,INACT,0.0	CHEMBL101054,TN,INACT,0.009999999776482582	CHEMBL2435843,TP,ACT,1.0	CHEMBL263529,TP,ACT,1.0	CHEMBL391378,TP,ACT,0.8600000143051147	CHEMBL328476,TN,INACT,0.0	CHEMBL3326770,TN,INACT,0.029999999329447746	CHEMBL475534,TN,INACT,0.0	CHEMBL448610,TP,ACT,0.9599999785423279	CHEMBL42411,TN,INACT,0.0	CHEMBL89715,TP,ACT,0.9599999785423279	CHEMBL239153,FP,INACT,1.0	CHEMBL72295,TN,INACT,0.0	CHEMBL2436719,TN,INACT,0.0	CHEMBL3775378,TN,INACT,0.0	CHEMBL1087153,FN,ACT,0.009999999776482582	CHEMBL327898,TP,ACT,1.0	CHEMBL3218121,TN,INACT,0.0	CHEMBL432974,TN,INACT,0.0	CHEMBL2435873,TP,ACT,1.0	CHEMBL2113072,TN,INACT,0.0	CHEMBL172090,TP,ACT,1.0	CHEMBL330570,TP,ACT,1.0	CHEMBL1097816,TP,ACT,1.0	CHEMBL251121,TN,INACT,0.0	CHEMBL83773,FN,ACT,0.0	CHEMBL367987,TP,ACT,1.0	CHEMBL302668,TN,INACT,0.0	CHEMBL88629,TN,INACT,0.009999999776482582	CHEMBL316073,TP,ACT,1.0	CHEMBL79716,TP,ACT,1.0	CHEMBL91045,FN,ACT,0.029999999329447746	CHEMBL2312346,FP,INACT,0.4699999988079071	CHEMBL233029,FP,INACT,0.9900000095367432	CHEMBL2398752,TN,INACT,0.05999999865889549	CHEMBL64406,TN,INACT,0.07999999821186066	CHEMBL2338391,FN,ACT,0.019999999552965164	CHEMBL148967,TN,INACT,0.0	CHEMBL425618,TP,ACT,0.550000011920929	CHEMBL323172,TP,ACT,1.0	CHEMBL460008,TP,ACT,0.9900000095367432	CHEMBL291293,TN,INACT,0.14000000059604645	CHEMBL2435892,TP,ACT,0.9399999976158142	CHEMBL285814,TN,INACT,0.0	CHEMBL3604300,TN,INACT,0.0	CHEMBL352925,TN,INACT,0.019999999552965164	CHEMBL3219781,TP,ACT,0.8700000047683716	CHEMBL536044,TN,INACT,0.0	CHEMBL2370511,TN,INACT,0.0	CHEMBL470510,TP,ACT,1.0	CHEMBL174304,TP,ACT,1.0	CHEMBL2435899,TP,ACT,0.8899999856948853	CHEMBL181967,TP,ACT,0.9800000190734863	CHEMBL212408,TP,ACT,1.0	CHEMBL341928,TP,ACT,1.0	CHEMBL459985,TP,ACT,1.0	CHEMBL556798,TP,ACT,0.36000001430511475	CHEMBL98350,TN,INACT,0.0	CHEMBL1762330,TP,ACT,1.0	CHEMBL3085309,TP,ACT,0.8399999737739563	CHEMBL133257,TN,INACT,0.0	CHEMBL308924,TN,INACT,0.0	CHEMBL140201,TP,ACT,1.0	CHEMBL1762463,TP,ACT,1.0	CHEMBL283941,TN,INACT,0.0	CHEMBL369659,TP,ACT,1.0	CHEMBL176391,TP,ACT,1.0	CHEMBL89279,TP,ACT,1.0	CHEMBL142021,TP,ACT,1.0	CHEMBL450463,TN,INACT,0.0	CHEMBL1082036,FP,INACT,0.9300000071525574	CHEMBL177033,TP,ACT,0.9599999785423279	CHEMBL369202,TN,INACT,0.0	CHEMBL111023,TN,INACT,0.0	CHEMBL139559,TP,ACT,1.0	CHEMBL217002,TN,INACT,0.0	CHEMBL172806,TP,ACT,1.0	CHEMBL182188,TP,ACT,1.0	CHEMBL1077353,TP,ACT,1.0	CHEMBL316189,TP,ACT,1.0	CHEMBL608814,TN,INACT,0.0	CHEMBL2281968,TP,ACT,1.0	CHEMBL78601,TN,INACT,0.0	CHEMBL175066,TN,INACT,0.0	CHEMBL311795,TP,ACT,0.9700000286102295	CHEMBL2436722,FP,INACT,0.6499999761581421	CHEMBL377542,TN,INACT,0.0	CHEMBL542877,TN,INACT,0.0	CHEMBL2435913,TP,ACT,0.8799999952316284	CHEMBL205964,TP,ACT,0.9800000190734863	CHEMBL254500,TN,INACT,0.0	CHEMBL441188,TN,INACT,0.0	CHEMBL329131,TP,ACT,1.0	CHEMBL57908,TN,INACT,0.0	CHEMBL141683,TP,ACT,1.0	CHEMBL83818,TP,ACT,1.0	CHEMBL86419,TP,ACT,1.0	CHEMBL113436,TP,ACT,0.9900000095367432	CHEMBL412569,TN,INACT,0.0	CHEMBL140827,TP,ACT,0.9700000286102295	CHEMBL309194,TN,INACT,0.0	CHEMBL302150,TN,INACT,0.0	CHEMBL240640,TP,ACT,1.0	CHEMBL322232,TP,ACT,1.0	CHEMBL2112560,TP,ACT,1.0	CHEMBL1760024,TP,ACT,1.0	CHEMBL1085218,TP,ACT,1.0	CHEMBL367586,TP,ACT,1.0	CHEMBL432596,TP,ACT,1.0	CHEMBL402242,TP,ACT,0.8700000047683716	CHEMBL3085313,TP,ACT,1.0	CHEMBL1762339,TP,ACT,1.0	CHEMBL461690,TP,ACT,1.0	CHEMBL27262,TN,INACT,0.0	CHEMBL1078335,TP,ACT,1.0	CHEMBL1762319,TP,ACT,1.0	CHEMBL388528,TN,INACT,0.0	CHEMBL492544,TP,ACT,1.0	CHEMBL412591,TN,INACT,0.0	CHEMBL434284,TN,INACT,0.0	CHEMBL173482,TP,ACT,1.0	CHEMBL119291,TN,INACT,0.05000000074505806	CHEMBL324652,TN,INACT,0.0	CHEMBL2392179,TN,INACT,0.009999999776482582	CHEMBL185948,TN,INACT,0.019999999552965164	CHEMBL503631,TP,ACT,0.6499999761581421	CHEMBL3577948,TP,ACT,0.4699999988079071	CHEMBL506788,TP,ACT,1.0	CHEMBL471909,TP,ACT,1.0	CHEMBL168855,TN,INACT,0.0	CHEMBL175228,TN,INACT,0.0	CHEMBL1201353,TN,INACT,0.009999999776482582	CHEMBL328888,TP,ACT,0.9700000286102295	CHEMBL468150,TP,ACT,1.0	CHEMBL3104693,TP,ACT,0.9700000286102295	CHEMBL286797,TN,INACT,0.0	CHEMBL138198,TP,ACT,1.0	CHEMBL473353,TP,ACT,0.6100000143051147	CHEMBL142515,TN,INACT,0.0	CHEMBL265723,TP,ACT,1.0	CHEMBL319233,TP,ACT,1.0	CHEMBL118553,TN,INACT,0.0	CHEMBL10801,TN,INACT,0.0	CHEMBL174463,TN,INACT,0.029999999329447746	CHEMBL2048230,TN,INACT,0.0	CHEMBL491679,TP,ACT,0.949999988079071	CHEMBL1258999,TN,INACT,0.0	CHEMBL317860,TP,ACT,1.0	CHEMBL62660,TN,INACT,0.0	CHEMBL97420,TN,INACT,0.05999999865889549	CHEMBL377914,TP,ACT,0.9800000190734863	CHEMBL1762143,TP,ACT,0.5199999809265137	CHEMBL103731,TN,INACT,0.1899999976158142	CHEMBL76403,TN,INACT,0.10999999940395355	CHEMBL89929,TP,ACT,0.9900000095367432	CHEMBL78080,TN,INACT,0.0	CHEMBL138502,TP,ACT,1.0	CHEMBL1951907,TP,ACT,1.0	CHEMBL104698,TP,ACT,1.0	CHEMBL2436720,FP,INACT,0.8600000143051147	CHEMBL1269884,TP,ACT,1.0	CHEMBL279289,FP,INACT,0.9200000166893005	CHEMBL7185,TN,INACT,0.0	CHEMBL1762466,TP,ACT,1.0	CHEMBL281232,TN,INACT,0.009999999776482582	CHEMBL297599,TN,INACT,0.0	CHEMBL113072,TP,ACT,1.0	CHEMBL406552,TP,ACT,1.0	CHEMBL89221,TP,ACT,1.0	CHEMBL107681,TN,INACT,0.0	CHEMBL351508,TN,INACT,0.0	CHEMBL500523,TP,ACT,0.9700000286102295	CHEMBL63109,TN,INACT,0.0	CHEMBL2203614,TP,ACT,1.0	CHEMBL102028,TN,INACT,0.0	CHEMBL390842,TN,INACT,0.0	CHEMBL1762333,TP,ACT,0.9900000095367432	CHEMBL520755,TP,ACT,1.0	CHEMBL180334,TP,ACT,0.9599999785423279	CHEMBL21058,TP,ACT,1.0	CHEMBL594802,TN,INACT,0.0	CHEMBL1077355,TP,ACT,1.0	CHEMBL1085221,TP,ACT,1.0	CHEMBL458157,TP,ACT,1.0	CHEMBL3650349,TN,INACT,0.10999999940395355	CHEMBL404888,TN,INACT,0.0	CHEMBL393274,TP,ACT,1.0	CHEMBL46195,TN,INACT,0.0	CHEMBL3335536,TN,INACT,0.0	CHEMBL2435896,TP,ACT,0.7400000095367432	CHEMBL142811,TN,INACT,0.0	CHEMBL2372525,TN,INACT,0.0	CHEMBL1085723,TP,ACT,1.0	CHEMBL3104695,TP,ACT,1.0	CHEMBL310780,TP,ACT,1.0	CHEMBL420359,TN,INACT,0.0	CHEMBL140706,TP,ACT,0.8199999928474426	CHEMBL278383,TP,ACT,1.0	CHEMBL334470,FN,ACT,0.3100000023841858	CHEMBL137934,TP,ACT,1.0	CHEMBL185190,TN,INACT,0.0	CHEMBL3780248,TN,INACT,0.0	CHEMBL323175,TN,INACT,0.0	CHEMBL98038,TN,INACT,0.009999999776482582	CHEMBL85086,TP,ACT,1.0	CHEMBL1095816,TP,ACT,1.0	CHEMBL331007,FP,INACT,1.0	CHEMBL301826,TN,INACT,0.0	CHEMBL234673,TP,ACT,1.0	CHEMBL109051,TP,ACT,0.949999988079071	CHEMBL2164434,TN,INACT,0.0	CHEMBL2435897,TP,ACT,0.5	CHEMBL94902,TN,INACT,0.0	CHEMBL127387,TN,INACT,0.0	CHEMBL446187,TP,ACT,1.0	CHEMBL1910166,FN,ACT,0.03999999910593033	CHEMBL310361,TN,INACT,0.0	CHEMBL485576,TN,INACT,0.0	CHEMBL366450,TP,ACT,1.0	CHEMBL364629,TN,INACT,0.019999999552965164	CHEMBL370998,TP,ACT,1.0	CHEMBL717,TN,INACT,0.0	CHEMBL353331,TP,ACT,1.0	CHEMBL3104680,TP,ACT,0.8100000023841858	CHEMBL1077364,TP,ACT,1.0	CHEMBL3326660,FP,INACT,0.5799999833106995	CHEMBL234894,TP,ACT,0.949999988079071	CHEMBL441635,TP,ACT,0.9900000095367432	CHEMBL162095,TN,INACT,0.0	CHEMBL25688,TN,INACT,0.0	CHEMBL3764306,TN,INACT,0.009999999776482582	CHEMBL45875,TN,INACT,0.0	CHEMBL179950,TP,ACT,1.0	CHEMBL101706,TN,INACT,0.0	CHEMBL42799,TN,INACT,0.0	CHEMBL426048,TP,ACT,1.0	CHEMBL319689,TP,ACT,0.9900000095367432	CHEMBL180656,TP,ACT,0.8700000047683716	CHEMBL558766,TN,INACT,0.0	CHEMBL6995,TN,INACT,0.0	CHEMBL2435911,TP,ACT,0.7900000214576721	CHEMBL58241,TN,INACT,0.0	CHEMBL179138,TN,INACT,0.0	CHEMBL322547,TN,INACT,0.0	CHEMBL93949,TP,ACT,1.0	CHEMBL2435875,TP,ACT,1.0	CHEMBL91362,TN,INACT,0.009999999776482582	CHEMBL26206,TN,INACT,0.0	CHEMBL254499,TN,INACT,0.0	CHEMBL64043,TN,INACT,0.0	CHEMBL1077359,TP,ACT,1.0	CHEMBL309447,TP,ACT,0.5	CHEMBL2367887,FN,ACT,0.0	CHEMBL593620,TN,INACT,0.0	CHEMBL2435894,TP,ACT,0.949999988079071	CHEMBL369278,TP,ACT,0.9800000190734863	CHEMBL2435908,FN,ACT,0.2800000011920929	CHEMBL1078712,TP,ACT,1.0	CHEMBL65649,TP,ACT,0.9900000095367432	CHEMBL475497,FP,INACT,0.7300000190734863	CHEMBL442150,TN,INACT,0.0	CHEMBL314320,TN,INACT,0.009999999776482582	CHEMBL262932,TN,INACT,0.0	CHEMBL107680,TN,INACT,0.0	CHEMBL367560,TP,ACT,1.0	CHEMBL191,TN,INACT,0.0	CHEMBL2435857,TP,ACT,1.0	CHEMBL2372212,TN,INACT,0.0	CHEMBL181858,TP,ACT,1.0	CHEMBL368459,TP,ACT,1.0	CHEMBL2435904,TP,ACT,0.9800000190734863	CHEMBL1765671,TN,INACT,0.0	CHEMBL182780,TP,ACT,1.0	CHEMBL361414,TP,ACT,1.0	CHEMBL489512,TP,ACT,1.0	CHEMBL3577946,FN,ACT,0.27000001072883606	CHEMBL432144,TN,INACT,0.0	CHEMBL404373,TN,INACT,0.0	CHEMBL91522,TP,ACT,0.9900000095367432	CHEMBL402776,FN,ACT,0.0	CHEMBL32301,TN,INACT,0.0	CHEMBL9228,TN,INACT,0.0	CHEMBL491154,TP,ACT,0.9599999785423279	CHEMBL2435847,TP,ACT,1.0	CHEMBL93139,TP,ACT,1.0	CHEMBL3218122,TN,INACT,0.0	CHEMBL964,TN,INACT,0.0	CHEMBL290927,TN,INACT,0.0	CHEMBL240888,TN,INACT,0.0	CHEMBL1223054,TN,INACT,0.0	CHEMBL523512,TP,ACT,1.0	CHEMBL1683063,TP,ACT,1.0	CHEMBL177502,TN,INACT,0.0	CHEMBL3577942,TP,ACT,0.6600000262260437	CHEMBL112770,TN,INACT,0.0	CHEMBL105975,TP,ACT,1.0	CHEMBL3327375,TN,INACT,0.0	CHEMBL1324,TN,INACT,0.0	CHEMBL367024,TN,INACT,0.0	CHEMBL140484,TP,ACT,1.0	CHEMBL417825,TP,ACT,1.0	CHEMBL111218,TN,INACT,0.0	CHEMBL367102,TP,ACT,0.8999999761581421	CHEMBL518326,TP,ACT,0.949999988079071	CHEMBL423427,TP,ACT,1.0	CHEMBL409832,TN,INACT,0.2199999988079071	CHEMBL309397,TN,INACT,0.0	CHEMBL140183,TP,ACT,0.7699999809265137	CHEMBL95489,TN,INACT,0.009999999776482582	CHEMBL220199,FN,ACT,0.0	CHEMBL41686,TN,INACT,0.0	CHEMBL33473,TN,INACT,0.0	CHEMBL3105395,TN,INACT,0.0	CHEMBL172506,TN,INACT,0.009999999776482582	CHEMBL59511,TP,ACT,1.0	CHEMBL3633663,FP,INACT,0.9700000286102295	CHEMBL3665436,TN,INACT,0.0	CHEMBL352779,TN,INACT,0.0	CHEMBL106570,TN,INACT,0.029999999329447746	CHEMBL228900,TN,INACT,0.1899999976158142	CHEMBL176337,TP,ACT,1.0	CHEMBL3218123,FP,INACT,0.8700000047683716	CHEMBL28751,TN,INACT,0.0	CHEMBL312670,TN,INACT,0.0	CHEMBL142243,FP,INACT,0.4699999988079071	CHEMBL424214,TN,INACT,0.07999999821186066	CHEMBL1078013,TP,ACT,1.0	CHEMBL106406,TP,ACT,1.0	CHEMBL366868,TP,ACT,1.0	CHEMBL239783,FN,ACT,0.029999999329447746	CHEMBL463874,TP,ACT,1.0	CHEMBL106098,TP,ACT,1.0	CHEMBL170543,TP,ACT,1.0	CHEMBL1271310,TP,ACT,0.5199999809265137	CHEMBL199186,TN,INACT,0.0	CHEMBL84309,TP,ACT,1.0	CHEMBL369235,TP,ACT,1.0	CHEMBL92133,TP,ACT,0.3400000035762787	CHEMBL2435879,TP,ACT,0.8199999928474426	CHEMBL198497,TP,ACT,1.0	CHEMBL459599,FN,ACT,0.23999999463558197	CHEMBL510130,TN,INACT,0.0	CHEMBL221691,TN,INACT,0.019999999552965164	CHEMBL184474,TN,INACT,0.0	CHEMBL3577932,TP,ACT,0.33000001311302185	CHEMBL475777,TP,ACT,1.0	CHEMBL413644,TN,INACT,0.0	CHEMBL344641,TP,ACT,1.0	CHEMBL3808968,TN,INACT,0.009999999776482582	CHEMBL147365,TN,INACT,0.0	CHEMBL2435884,TP,ACT,0.7799999713897705	CHEMBL3343023,TN,INACT,0.0	CHEMBL366536,TP,ACT,1.0	CHEMBL99909,TP,ACT,1.0	CHEMBL423000,TP,ACT,1.0	CHEMBL2369710,TN,INACT,0.0	CHEMBL275481,TN,INACT,0.0	CHEMBL265131,TP,ACT,1.0	CHEMBL234634,TP,ACT,1.0	CHEMBL393068,TP,ACT,1.0	CHEMBL273642,FP,INACT,0.7099999785423279	CHEMBL18797,TN,INACT,0.0	CHEMBL3088176,TN,INACT,0.0	CHEMBL2442638,TN,INACT,0.0	CHEMBL456675,FP,INACT,0.8199999928474426	CHEMBL88197,TP,ACT,0.949999988079071	CHEMBL173308,TP,ACT,0.9900000095367432	CHEMBL239998,TP,ACT,1.0	CHEMBL284311,TN,INACT,0.0	CHEMBL417712,TN,INACT,0.0	CHEMBL471765,TP,ACT,1.0	CHEMBL83957,TP,ACT,1.0	CHEMBL309619,TP,ACT,1.0	CHEMBL104981,TN,INACT,0.0	CHEMBL213418,TN,INACT,0.0	CHEMBL416069,TN,INACT,0.03999999910593033	CHEMBL183885,TP,ACT,0.949999988079071	CHEMBL2163921,TN,INACT,0.0	CHEMBL430683,TN,INACT,0.0	CHEMBL444061,TN,INACT,0.0	CHEMBL1683065,TP,ACT,0.9900000095367432	CHEMBL174996,TP,ACT,1.0	CHEMBL79030,TN,INACT,0.0	CHEMBL461502,TN,INACT,0.0	CHEMBL481274,TP,ACT,1.0	CHEMBL87167,TP,ACT,1.0	CHEMBL105821,TP,ACT,1.0	CHEMBL1910384,TN,INACT,0.009999999776482582	CHEMBL283788,TP,ACT,1.0	CHEMBL198277,TP,ACT,1.0	CHEMBL158754,TP,ACT,0.9900000095367432	CHEMBL80504,TN,INACT,0.0	CHEMBL107749,TP,ACT,0.7900000214576721	CHEMBL390667,TN,INACT,0.0	CHEMBL314551,TP,ACT,1.0	CHEMBL1478530,TN,INACT,0.0	CHEMBL349689,TN,INACT,0.0	CHEMBL233721,TN,INACT,0.029999999329447746	CHEMBL420465,TP,ACT,1.0	CHEMBL325556,TP,ACT,0.9900000095367432	CHEMBL79907,TP,ACT,1.0	CHEMBL2282500,TP,ACT,1.0	CHEMBL292625,TP,ACT,0.9900000095367432	CHEMBL2436825,TN,INACT,0.07000000029802322	CHEMBL3735151,TN,INACT,0.009999999776482582	CHEMBL50192,TN,INACT,0.0	CHEMBL387152,TN,INACT,0.029999999329447746	CHEMBL19018,TN,INACT,0.0	CHEMBL161587,TP,ACT,1.0	CHEMBL171108,TN,INACT,0.0	CHEMBL176653,TN,INACT,0.0	CHEMBL179209,TP,ACT,1.0	CHEMBL320228,TN,INACT,0.0	CHEMBL301805,TN,INACT,0.0	CHEMBL509665,TP,ACT,1.0	CHEMBL182682,TP,ACT,1.0	CHEMBL58617,TN,INACT,0.0	CHEMBL232409,TP,ACT,1.0	CHEMBL2281956,TP,ACT,1.0	CHEMBL3105391,TN,INACT,0.0	CHEMBL179877,TP,ACT,1.0	CHEMBL368333,TP,ACT,1.0	CHEMBL105784,TP,ACT,0.9900000095367432	CHEMBL96836,TN,INACT,0.009999999776482582	CHEMBL364405,TN,INACT,0.0	CHEMBL33108,TN,INACT,0.0	CHEMBL2435909,TP,ACT,0.9900000095367432	CHEMBL172178,TN,INACT,0.0	CHEMBL41457,TN,INACT,0.0	CHEMBL320386,TP,ACT,1.0	CHEMBL499729,TP,ACT,1.0	CHEMBL516024,TN,INACT,0.009999999776482582	CHEMBL2042551,TN,INACT,0.0	CHEMBL89457,TN,INACT,0.0	CHEMBL332908,TP,ACT,1.0	CHEMBL2036782,FN,ACT,0.0	CHEMBL3665441,TN,INACT,0.009999999776482582	CHEMBL109158,TP,ACT,1.0	CHEMBL105570,TP,ACT,1.0	CHEMBL1270798,TP,ACT,1.0	CHEMBL411640,FN,ACT,0.0	CHEMBL2163918,TN,INACT,0.0	CHEMBL536751,TP,ACT,0.9399999976158142	CHEMBL3577345,TN,INACT,0.0	CHEMBL434674,TN,INACT,0.0	CHEMBL240001,TN,INACT,0.0	CHEMBL157491,TP,ACT,1.0	CHEMBL342842,TP,ACT,1.0	CHEMBL1683064,TP,ACT,0.9900000095367432	CHEMBL84029,TP,ACT,1.0	CHEMBL164968,FP,INACT,0.4699999988079071	CHEMBL233552,TN,INACT,0.0	CHEMBL65696,FN,ACT,0.10999999940395355	CHEMBL101961,TP,ACT,1.0	CHEMBL373654,TN,INACT,0.0	CHEMBL368979,TP,ACT,1.0	CHEMBL83338,TP,ACT,1.0	CHEMBL514606,TN,INACT,0.11999999731779099	CHEMBL277285,TN,INACT,0.0	CHEMBL473352,TP,ACT,1.0	CHEMBL323951,TN,INACT,0.0	CHEMBL49935,TN,INACT,0.0	CHEMBL209278,TP,ACT,1.0	CHEMBL481980,TP,ACT,1.0	CHEMBL357077,TN,INACT,0.0	CHEMBL471149,TP,ACT,0.9800000190734863	CHEMBL2111747,TP,ACT,1.0	CHEMBL172845,TP,ACT,1.0	CHEMBL460009,TP,ACT,1.0	CHEMBL1097169,TP,ACT,1.0	

