ImageNetInceptionV2 CHEMBL315 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	166
Number of inactive compounds :	166
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL315_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL315_adam_0.0005_15_0.8/
---------------------------------
Training samples: 211
Validation samples: 67
--
Training Step: 1  | time: 36.562s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/211
[A[ATraining Step: 2  | total loss: [1m[32m0.62827[0m[0m | time: 46.486s
[2K
| Adam | epoch: 001 | loss: 0.62827 - acc: 0.4781 -- iter: 064/211
[A[ATraining Step: 3  | total loss: [1m[32m0.78132[0m[0m | time: 57.060s
[2K
| Adam | epoch: 001 | loss: 0.78132 - acc: 0.4193 -- iter: 096/211
[A[ATraining Step: 4  | total loss: [1m[32m0.71140[0m[0m | time: 68.606s
[2K
| Adam | epoch: 001 | loss: 0.71140 - acc: 0.5033 -- iter: 128/211
[A[ATraining Step: 5  | total loss: [1m[32m0.70084[0m[0m | time: 79.837s
[2K
| Adam | epoch: 001 | loss: 0.70084 - acc: 0.5010 -- iter: 160/211
[A[ATraining Step: 6  | total loss: [1m[32m0.66427[0m[0m | time: 88.782s
[2K
| Adam | epoch: 001 | loss: 0.66427 - acc: 0.6410 -- iter: 192/211
[A[ATraining Step: 7  | total loss: [1m[32m0.69382[0m[0m | time: 103.250s
[2K
| Adam | epoch: 001 | loss: 0.69382 - acc: 0.6126 | val_loss: 2.20470 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 8  | total loss: [1m[32m0.60438[0m[0m | time: 5.914s
[2K
| Adam | epoch: 002 | loss: 0.60438 - acc: 0.6233 -- iter: 032/211
[A[ATraining Step: 9  | total loss: [1m[32m0.44940[0m[0m | time: 14.759s
[2K
| Adam | epoch: 002 | loss: 0.44940 - acc: 0.7949 -- iter: 064/211
[A[ATraining Step: 10  | total loss: [1m[32m0.45050[0m[0m | time: 23.572s
[2K
| Adam | epoch: 002 | loss: 0.45050 - acc: 0.7724 -- iter: 096/211
[A[ATraining Step: 11  | total loss: [1m[32m0.50386[0m[0m | time: 32.486s
[2K
| Adam | epoch: 002 | loss: 0.50386 - acc: 0.7322 -- iter: 128/211
[A[ATraining Step: 12  | total loss: [1m[32m0.63792[0m[0m | time: 41.370s
[2K
| Adam | epoch: 002 | loss: 0.63792 - acc: 0.6558 -- iter: 160/211
[A[ATraining Step: 13  | total loss: [1m[32m0.59360[0m[0m | time: 50.142s
[2K
| Adam | epoch: 002 | loss: 0.59360 - acc: 0.6962 -- iter: 192/211
[A[ATraining Step: 14  | total loss: [1m[32m0.51233[0m[0m | time: 62.142s
[2K
| Adam | epoch: 002 | loss: 0.51233 - acc: 0.7693 | val_loss: 1.34501 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 15  | total loss: [1m[32m0.56158[0m[0m | time: 5.882s
[2K
| Adam | epoch: 003 | loss: 0.56158 - acc: 0.7373 -- iter: 032/211
[A[ATraining Step: 16  | total loss: [1m[32m0.49736[0m[0m | time: 11.709s
[2K
| Adam | epoch: 003 | loss: 0.49736 - acc: 0.8161 -- iter: 064/211
[A[ATraining Step: 17  | total loss: [1m[32m0.37496[0m[0m | time: 20.451s
[2K
| Adam | epoch: 003 | loss: 0.37496 - acc: 0.8823 -- iter: 096/211
[A[ATraining Step: 18  | total loss: [1m[32m0.37611[0m[0m | time: 29.122s
[2K
| Adam | epoch: 003 | loss: 0.37611 - acc: 0.8473 -- iter: 128/211
[A[ATraining Step: 19  | total loss: [1m[32m0.32381[0m[0m | time: 37.952s
[2K
| Adam | epoch: 003 | loss: 0.32381 - acc: 0.8670 -- iter: 160/211
[A[ATraining Step: 20  | total loss: [1m[32m0.32841[0m[0m | time: 46.808s
[2K
| Adam | epoch: 003 | loss: 0.32841 - acc: 0.8796 -- iter: 192/211
[A[ATraining Step: 21  | total loss: [1m[32m0.28324[0m[0m | time: 58.832s
[2K
| Adam | epoch: 003 | loss: 0.28324 - acc: 0.8879 | val_loss: 1.08571 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 22  | total loss: [1m[32m0.28731[0m[0m | time: 8.879s
[2K
| Adam | epoch: 004 | loss: 0.28731 - acc: 0.8746 -- iter: 032/211
[A[ATraining Step: 23  | total loss: [1m[32m0.25592[0m[0m | time: 14.624s
[2K
| Adam | epoch: 004 | loss: 0.25592 - acc: 0.8838 -- iter: 064/211
[A[ATraining Step: 24  | total loss: [1m[32m0.27577[0m[0m | time: 20.444s
[2K
| Adam | epoch: 004 | loss: 0.27577 - acc: 0.8869 -- iter: 096/211
[A[ATraining Step: 25  | total loss: [1m[32m0.23167[0m[0m | time: 29.288s
[2K
| Adam | epoch: 004 | loss: 0.23167 - acc: 0.9177 -- iter: 128/211
[A[ATraining Step: 26  | total loss: [1m[32m0.19261[0m[0m | time: 37.964s
[2K
| Adam | epoch: 004 | loss: 0.19261 - acc: 0.9312 -- iter: 160/211
[A[ATraining Step: 27  | total loss: [1m[32m0.15080[0m[0m | time: 46.860s
[2K
| Adam | epoch: 004 | loss: 0.15080 - acc: 0.9489 -- iter: 192/211
[A[ATraining Step: 28  | total loss: [1m[32m0.15648[0m[0m | time: 58.926s
[2K
| Adam | epoch: 004 | loss: 0.15648 - acc: 0.9383 | val_loss: 0.94217 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 29  | total loss: [1m[32m0.13347[0m[0m | time: 8.767s
[2K
| Adam | epoch: 005 | loss: 0.13347 - acc: 0.9457 -- iter: 032/211
[A[ATraining Step: 30  | total loss: [1m[32m0.11905[0m[0m | time: 17.516s
[2K
| Adam | epoch: 005 | loss: 0.11905 - acc: 0.9585 -- iter: 064/211
[A[ATraining Step: 31  | total loss: [1m[32m0.09957[0m[0m | time: 23.295s
[2K
| Adam | epoch: 005 | loss: 0.09957 - acc: 0.9681 -- iter: 096/211
[A[ATraining Step: 32  | total loss: [1m[32m0.08965[0m[0m | time: 29.135s
[2K
| Adam | epoch: 005 | loss: 0.08965 - acc: 0.9753 -- iter: 128/211
[A[ATraining Step: 33  | total loss: [1m[32m0.07131[0m[0m | time: 38.010s
[2K
| Adam | epoch: 005 | loss: 0.07131 - acc: 0.9807 -- iter: 160/211
[A[ATraining Step: 34  | total loss: [1m[32m0.07467[0m[0m | time: 46.679s
[2K
| Adam | epoch: 005 | loss: 0.07467 - acc: 0.9714 -- iter: 192/211
[A[ATraining Step: 35  | total loss: [1m[32m0.07563[0m[0m | time: 58.620s
[2K
| Adam | epoch: 005 | loss: 0.07563 - acc: 0.9709 | val_loss: 0.79622 - val_acc: 0.5373 -- iter: 211/211
--
Training Step: 36  | total loss: [1m[32m0.06547[0m[0m | time: 8.823s
[2K
| Adam | epoch: 006 | loss: 0.06547 - acc: 0.9768 -- iter: 032/211
[A[ATraining Step: 37  | total loss: [1m[32m0.05387[0m[0m | time: 17.691s
[2K
| Adam | epoch: 006 | loss: 0.05387 - acc: 0.9815 -- iter: 064/211
[A[ATraining Step: 38  | total loss: [1m[32m0.09619[0m[0m | time: 26.543s
[2K
| Adam | epoch: 006 | loss: 0.09619 - acc: 0.9729 -- iter: 096/211
[A[ATraining Step: 39  | total loss: [1m[32m0.11473[0m[0m | time: 32.441s
[2K
| Adam | epoch: 006 | loss: 0.11473 - acc: 0.9601 -- iter: 128/211
[A[ATraining Step: 40  | total loss: [1m[32m0.17697[0m[0m | time: 38.321s
[2K
| Adam | epoch: 006 | loss: 0.17697 - acc: 0.9479 -- iter: 160/211
[A[ATraining Step: 41  | total loss: [1m[32m0.14512[0m[0m | time: 46.996s
[2K
| Adam | epoch: 006 | loss: 0.14512 - acc: 0.9574 -- iter: 192/211
[A[ATraining Step: 42  | total loss: [1m[32m0.17438[0m[0m | time: 58.836s
[2K
| Adam | epoch: 006 | loss: 0.17438 - acc: 0.9482 | val_loss: 1.38591 - val_acc: 0.5373 -- iter: 211/211
--
Training Step: 43  | total loss: [1m[32m0.23878[0m[0m | time: 8.794s
[2K
| Adam | epoch: 007 | loss: 0.23878 - acc: 0.9298 -- iter: 032/211
[A[ATraining Step: 44  | total loss: [1m[32m0.22419[0m[0m | time: 17.587s
[2K
| Adam | epoch: 007 | loss: 0.22419 - acc: 0.9203 -- iter: 064/211
[A[ATraining Step: 45  | total loss: [1m[32m0.19009[0m[0m | time: 26.339s
[2K
| Adam | epoch: 007 | loss: 0.19009 - acc: 0.9338 -- iter: 096/211
[A[ATraining Step: 46  | total loss: [1m[32m0.20973[0m[0m | time: 35.207s
[2K
| Adam | epoch: 007 | loss: 0.20973 - acc: 0.9344 -- iter: 128/211
[A[ATraining Step: 47  | total loss: [1m[32m0.22967[0m[0m | time: 41.120s
[2K
| Adam | epoch: 007 | loss: 0.22967 - acc: 0.9298 -- iter: 160/211
[A[ATraining Step: 48  | total loss: [1m[32m0.20059[0m[0m | time: 46.806s
[2K
| Adam | epoch: 007 | loss: 0.20059 - acc: 0.9411 -- iter: 192/211
[A[ATraining Step: 49  | total loss: [1m[32m0.17053[0m[0m | time: 58.658s
[2K
| Adam | epoch: 007 | loss: 0.17053 - acc: 0.9504 | val_loss: 0.71864 - val_acc: 0.5821 -- iter: 211/211
--
Training Step: 50  | total loss: [1m[32m0.14677[0m[0m | time: 8.745s
[2K
| Adam | epoch: 008 | loss: 0.14677 - acc: 0.9581 -- iter: 032/211
[A[ATraining Step: 51  | total loss: [1m[32m0.13830[0m[0m | time: 17.473s
[2K
| Adam | epoch: 008 | loss: 0.13830 - acc: 0.9597 -- iter: 064/211
[A[ATraining Step: 52  | total loss: [1m[32m0.13832[0m[0m | time: 26.266s
[2K
| Adam | epoch: 008 | loss: 0.13832 - acc: 0.9611 -- iter: 096/211
[A[ATraining Step: 53  | total loss: [1m[32m0.12372[0m[0m | time: 35.088s
[2K
| Adam | epoch: 008 | loss: 0.12372 - acc: 0.9668 -- iter: 128/211
[A[ATraining Step: 54  | total loss: [1m[32m0.10828[0m[0m | time: 44.557s
[2K
| Adam | epoch: 008 | loss: 0.10828 - acc: 0.9716 -- iter: 160/211
[A[ATraining Step: 55  | total loss: [1m[32m0.09986[0m[0m | time: 50.223s
[2K
| Adam | epoch: 008 | loss: 0.09986 - acc: 0.9757 -- iter: 192/211
[A[ATraining Step: 56  | total loss: [1m[32m0.15299[0m[0m | time: 59.146s
[2K
| Adam | epoch: 008 | loss: 0.15299 - acc: 0.9717 | val_loss: 0.92290 - val_acc: 0.5970 -- iter: 211/211
--
Training Step: 57  | total loss: [1m[32m0.13296[0m[0m | time: 8.857s
[2K
| Adam | epoch: 009 | loss: 0.13296 - acc: 0.9756 -- iter: 032/211
[A[ATraining Step: 58  | total loss: [1m[32m0.12131[0m[0m | time: 17.420s
[2K
| Adam | epoch: 009 | loss: 0.12131 - acc: 0.9789 -- iter: 064/211
[A[ATraining Step: 59  | total loss: [1m[32m0.14419[0m[0m | time: 26.147s
[2K
| Adam | epoch: 009 | loss: 0.14419 - acc: 0.9650 -- iter: 096/211
[A[ATraining Step: 60  | total loss: [1m[32m0.12736[0m[0m | time: 34.869s
[2K
| Adam | epoch: 009 | loss: 0.12736 - acc: 0.9696 -- iter: 128/211
[A[ATraining Step: 61  | total loss: [1m[32m0.15182[0m[0m | time: 43.372s
[2K
| Adam | epoch: 009 | loss: 0.15182 - acc: 0.9695 -- iter: 160/211
[A[ATraining Step: 62  | total loss: [1m[32m0.13479[0m[0m | time: 52.080s
[2K
| Adam | epoch: 009 | loss: 0.13479 - acc: 0.9734 -- iter: 192/211
[A[ATraining Step: 63  | total loss: [1m[32m0.12293[0m[0m | time: 61.004s
[2K
| Adam | epoch: 009 | loss: 0.12293 - acc: 0.9728 | val_loss: 4.49886 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 64  | total loss: [1m[32m0.11835[0m[0m | time: 5.658s
[2K
| Adam | epoch: 010 | loss: 0.11835 - acc: 0.9762 -- iter: 032/211
[A[ATraining Step: 65  | total loss: [1m[32m0.10643[0m[0m | time: 14.384s
[2K
| Adam | epoch: 010 | loss: 0.10643 - acc: 0.9792 -- iter: 064/211
[A[ATraining Step: 66  | total loss: [1m[32m0.14939[0m[0m | time: 22.970s
[2K
| Adam | epoch: 010 | loss: 0.14939 - acc: 0.9627 -- iter: 096/211
[A[ATraining Step: 67  | total loss: [1m[32m0.14248[0m[0m | time: 31.714s
[2K
| Adam | epoch: 010 | loss: 0.14248 - acc: 0.9634 -- iter: 128/211
[A[ATraining Step: 68  | total loss: [1m[32m0.13262[0m[0m | time: 40.618s
[2K
| Adam | epoch: 010 | loss: 0.13262 - acc: 0.9640 -- iter: 160/211
[A[ATraining Step: 69  | total loss: [1m[32m0.12788[0m[0m | time: 49.322s
[2K
| Adam | epoch: 010 | loss: 0.12788 - acc: 0.9646 -- iter: 192/211
[A[ATraining Step: 70  | total loss: [1m[32m0.11699[0m[0m | time: 61.142s
[2K
| Adam | epoch: 010 | loss: 0.11699 - acc: 0.9687 | val_loss: 6.14019 - val_acc: 0.5373 -- iter: 211/211
--
Training Step: 71  | total loss: [1m[32m0.10524[0m[0m | time: 5.808s
[2K
| Adam | epoch: 011 | loss: 0.10524 - acc: 0.9723 -- iter: 032/211
[A[ATraining Step: 72  | total loss: [1m[32m0.18220[0m[0m | time: 11.365s
[2K
| Adam | epoch: 011 | loss: 0.18220 - acc: 0.9576 -- iter: 064/211
[A[ATraining Step: 73  | total loss: [1m[32m0.16695[0m[0m | time: 19.954s
[2K
| Adam | epoch: 011 | loss: 0.16695 - acc: 0.9623 -- iter: 096/211
[A[ATraining Step: 74  | total loss: [1m[32m0.15949[0m[0m | time: 28.662s
[2K
| Adam | epoch: 011 | loss: 0.15949 - acc: 0.9630 -- iter: 128/211
[A[ATraining Step: 75  | total loss: [1m[32m0.14666[0m[0m | time: 37.496s
[2K
| Adam | epoch: 011 | loss: 0.14666 - acc: 0.9636 -- iter: 160/211
[A[ATraining Step: 76  | total loss: [1m[32m0.13607[0m[0m | time: 46.263s
[2K
| Adam | epoch: 011 | loss: 0.13607 - acc: 0.9675 -- iter: 192/211
[A[ATraining Step: 77  | total loss: [1m[32m0.13267[0m[0m | time: 58.011s
[2K
| Adam | epoch: 011 | loss: 0.13267 - acc: 0.9644 | val_loss: 3.64110 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 78  | total loss: [1m[32m0.13318[0m[0m | time: 8.747s
[2K
| Adam | epoch: 012 | loss: 0.13318 - acc: 0.9615 -- iter: 032/211
[A[ATraining Step: 79  | total loss: [1m[32m0.13091[0m[0m | time: 14.520s
[2K
| Adam | epoch: 012 | loss: 0.13091 - acc: 0.9623 -- iter: 064/211
[A[ATraining Step: 80  | total loss: [1m[32m0.16524[0m[0m | time: 20.069s
[2K
| Adam | epoch: 012 | loss: 0.16524 - acc: 0.9608 -- iter: 096/211
[A[ATraining Step: 81  | total loss: [1m[32m0.15015[0m[0m | time: 28.609s
[2K
| Adam | epoch: 012 | loss: 0.15015 - acc: 0.9647 -- iter: 128/211
[A[ATraining Step: 82  | total loss: [1m[32m0.14122[0m[0m | time: 37.196s
[2K
| Adam | epoch: 012 | loss: 0.14122 - acc: 0.9651 -- iter: 160/211
[A[ATraining Step: 83  | total loss: [1m[32m0.13177[0m[0m | time: 45.916s
[2K
| Adam | epoch: 012 | loss: 0.13177 - acc: 0.9655 -- iter: 192/211
[A[ATraining Step: 84  | total loss: [1m[32m0.12512[0m[0m | time: 57.688s
[2K
| Adam | epoch: 012 | loss: 0.12512 - acc: 0.9658 | val_loss: 5.76280 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 85  | total loss: [1m[32m0.11744[0m[0m | time: 8.785s
[2K
| Adam | epoch: 013 | loss: 0.11744 - acc: 0.9692 -- iter: 032/211
[A[ATraining Step: 86  | total loss: [1m[32m0.11561[0m[0m | time: 17.530s
[2K
| Adam | epoch: 013 | loss: 0.11561 - acc: 0.9692 -- iter: 064/211
[A[ATraining Step: 87  | total loss: [1m[32m0.10502[0m[0m | time: 23.136s
[2K
| Adam | epoch: 013 | loss: 0.10502 - acc: 0.9723 -- iter: 096/211
[A[ATraining Step: 88  | total loss: [1m[32m0.16858[0m[0m | time: 28.867s
[2K
| Adam | epoch: 013 | loss: 0.16858 - acc: 0.9645 -- iter: 128/211
[A[ATraining Step: 89  | total loss: [1m[32m0.15258[0m[0m | time: 37.538s
[2K
| Adam | epoch: 013 | loss: 0.15258 - acc: 0.9681 -- iter: 160/211
[A[ATraining Step: 90  | total loss: [1m[32m0.14654[0m[0m | time: 46.276s
[2K
| Adam | epoch: 013 | loss: 0.14654 - acc: 0.9681 -- iter: 192/211
[A[ATraining Step: 91  | total loss: [1m[32m0.13586[0m[0m | time: 57.978s
[2K
| Adam | epoch: 013 | loss: 0.13586 - acc: 0.9713 | val_loss: 2.41652 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 92  | total loss: [1m[32m0.13563[0m[0m | time: 8.766s
[2K
| Adam | epoch: 014 | loss: 0.13563 - acc: 0.9711 -- iter: 032/211
[A[ATraining Step: 93  | total loss: [1m[32m0.14521[0m[0m | time: 17.343s
[2K
| Adam | epoch: 014 | loss: 0.14521 - acc: 0.9677 -- iter: 064/211
[A[ATraining Step: 94  | total loss: [1m[32m0.13450[0m[0m | time: 25.962s
[2K
| Adam | epoch: 014 | loss: 0.13450 - acc: 0.9709 -- iter: 096/211
[A[ATraining Step: 95  | total loss: [1m[32m0.12251[0m[0m | time: 31.667s
[2K
| Adam | epoch: 014 | loss: 0.12251 - acc: 0.9738 -- iter: 128/211
[A[ATraining Step: 96  | total loss: [1m[32m0.11142[0m[0m | time: 37.431s
[2K
| Adam | epoch: 014 | loss: 0.11142 - acc: 0.9765 -- iter: 160/211
[A[ATraining Step: 97  | total loss: [1m[32m0.10181[0m[0m | time: 46.021s
[2K
| Adam | epoch: 014 | loss: 0.10181 - acc: 0.9788 -- iter: 192/211
[A[ATraining Step: 98  | total loss: [1m[32m0.10067[0m[0m | time: 58.030s
[2K
| Adam | epoch: 014 | loss: 0.10067 - acc: 0.9747 | val_loss: 1.61333 - val_acc: 0.4925 -- iter: 211/211
--
Training Step: 99  | total loss: [1m[32m0.09521[0m[0m | time: 8.826s
[2K
| Adam | epoch: 015 | loss: 0.09521 - acc: 0.9772 -- iter: 032/211
[A[ATraining Step: 100  | total loss: [1m[32m0.08809[0m[0m | time: 17.580s
[2K
| Adam | epoch: 015 | loss: 0.08809 - acc: 0.9795 -- iter: 064/211
[A[ATraining Step: 101  | total loss: [1m[32m0.08457[0m[0m | time: 26.164s
[2K
| Adam | epoch: 015 | loss: 0.08457 - acc: 0.9815 -- iter: 096/211
[A[ATraining Step: 102  | total loss: [1m[32m0.08361[0m[0m | time: 34.806s
[2K
| Adam | epoch: 015 | loss: 0.08361 - acc: 0.9834 -- iter: 128/211
[A[ATraining Step: 103  | total loss: [1m[32m0.07723[0m[0m | time: 40.497s
[2K
| Adam | epoch: 015 | loss: 0.07723 - acc: 0.9851 -- iter: 160/211
[A[ATraining Step: 104  | total loss: [1m[32m0.12202[0m[0m | time: 46.169s
[2K
| Adam | epoch: 015 | loss: 0.12202 - acc: 0.9760 -- iter: 192/211
[A[ATraining Step: 105  | total loss: [1m[32m0.11197[0m[0m | time: 58.061s
[2K
| Adam | epoch: 015 | loss: 0.11197 - acc: 0.9784 | val_loss: 1.14007 - val_acc: 0.6418 -- iter: 211/211
--
Validation AUC:0.7078853046594982
Validation AUPRC:0.6693053255528012
Test AUC:0.8414414414414415
Test AUPRC:0.8042239491822514
BestTestF1Score	0.77	0.56	0.76	0.68	0.9	27	13	24	3	0.09
BestTestMCCScore	0.77	0.56	0.76	0.68	0.9	27	13	24	3	0.09
BestTestAccuracyScore	0.78	0.57	0.78	0.7	0.87	26	11	26	4	0.18
BestValidationF1Score	0.75	0.43	0.72	0.71	0.81	29	12	19	7	0.09
BestValidationMCC	0.75	0.43	0.72	0.71	0.81	29	12	19	7	0.09
BestValidationAccuracy	0.75	0.43	0.72	0.72	0.78	28	11	20	8	0.18
TestPredictions (Threshold:0.09)
CHEMBL1732,TP,ACT,0.9599999785423279	CHEMBL432495,FP,INACT,0.28999999165534973	CHEMBL557584,TP,ACT,0.8700000047683716	CHEMBL1626,TP,ACT,0.25	CHEMBL552615,TN,INACT,0.0	CHEMBL168632,FP,INACT,0.949999988079071	CHEMBL146983,FP,INACT,0.4699999988079071	CHEMBL1437,TN,INACT,0.0	CHEMBL98038,FP,INACT,0.9399999976158142	CHEMBL3403334,FP,INACT,0.7400000095367432	CHEMBL27099,TN,INACT,0.0	CHEMBL387825,TN,INACT,0.009999999776482582	CHEMBL11401,TN,INACT,0.0	CHEMBL151668,FP,INACT,0.9700000286102295	CHEMBL51433,TP,ACT,1.0	CHEMBL2419771,TP,ACT,1.0	CHEMBL74122,TN,INACT,0.029999999329447746	CHEMBL338310,TN,INACT,0.009999999776482582	CHEMBL2414357,TP,ACT,1.0	CHEMBL275469,FP,INACT,1.0	CHEMBL3609359,TP,ACT,0.9900000095367432	CHEMBL762,TP,ACT,0.4300000071525574	CHEMBL1259128,TP,ACT,0.3100000023841858	CHEMBL351183,FP,INACT,0.20000000298023224	CHEMBL3609352,TP,ACT,0.9900000095367432	CHEMBL728,TP,ACT,0.9700000286102295	CHEMBL2092927,TP,ACT,0.9599999785423279	CHEMBL27341,TP,ACT,1.0	CHEMBL52800,TN,INACT,0.05999999865889549	CHEMBL137483,TN,INACT,0.019999999552965164	CHEMBL56,TN,INACT,0.009999999776482582	CHEMBL40796,TN,INACT,0.0	CHEMBL1628227,TP,ACT,1.0	CHEMBL3216590,TP,ACT,1.0	CHEMBL541129,TP,ACT,0.9200000166893005	CHEMBL114478,TN,INACT,0.0	CHEMBL536800,TN,INACT,0.0	CHEMBL418386,TN,INACT,0.0	CHEMBL534944,TP,ACT,0.9200000166893005	CHEMBL707,FN,ACT,0.07999999821186066	CHEMBL55,FN,ACT,0.009999999776482582	CHEMBL1576791,FP,INACT,0.12999999523162842	CHEMBL1644484,TN,INACT,0.019999999552965164	CHEMBL3415019,TP,ACT,0.12999999523162842	CHEMBL73164,TN,INACT,0.009999999776482582	CHEMBL157138,FN,ACT,0.0	CHEMBL11629,TN,INACT,0.009999999776482582	CHEMBL321644,FP,INACT,0.14000000059604645	CHEMBL621,TP,ACT,0.9900000095367432	CHEMBL2096751,TN,INACT,0.0	CHEMBL95986,TN,INACT,0.029999999329447746	CHEMBL3415014,TP,ACT,0.38999998569488525	CHEMBL27752,FP,INACT,0.33000001311302185	CHEMBL1201216,TP,ACT,0.9599999785423279	CHEMBL282255,TN,INACT,0.0	CHEMBL296419,TP,ACT,0.7599999904632568	CHEMBL53662,FP,INACT,0.46000000834465027	CHEMBL1729,TP,ACT,0.41999998688697815	CHEMBL3403332,FP,INACT,0.8500000238418579	CHEMBL715,TP,ACT,0.2199999988079071	CHEMBL300725,TN,INACT,0.07000000029802322	CHEMBL133868,TN,INACT,0.0	CHEMBL3609353,TP,ACT,0.20000000298023224	CHEMBL954,TP,ACT,0.9900000095367432	CHEMBL429,TP,ACT,0.699999988079071	CHEMBL276029,TN,INACT,0.009999999776482582	CHEMBL11414,TN,INACT,0.009999999776482582	

