ImageNetInceptionV2 CHEMBL2069 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	557
Number of inactive compounds :	557
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2069_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2069_adam_0.0005_15_0.8/
---------------------------------
Training samples: 696
Validation samples: 218
--
Training Step: 1  | time: 57.395s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/696
[A[ATraining Step: 2  | total loss: [1m[32m0.75697[0m[0m | time: 68.694s
[2K
| Adam | epoch: 001 | loss: 0.75697 - acc: 0.4219 -- iter: 064/696
[A[ATraining Step: 3  | total loss: [1m[32m0.67187[0m[0m | time: 79.795s
[2K
| Adam | epoch: 001 | loss: 0.67187 - acc: 0.6136 -- iter: 096/696
[A[ATraining Step: 4  | total loss: [1m[32m0.67004[0m[0m | time: 91.955s
[2K
| Adam | epoch: 001 | loss: 0.67004 - acc: 0.6222 -- iter: 128/696
[A[ATraining Step: 5  | total loss: [1m[32m0.63104[0m[0m | time: 104.202s
[2K
| Adam | epoch: 001 | loss: 0.63104 - acc: 0.6458 -- iter: 160/696
[A[ATraining Step: 6  | total loss: [1m[32m0.64586[0m[0m | time: 116.617s
[2K
| Adam | epoch: 001 | loss: 0.64586 - acc: 0.6123 -- iter: 192/696
[A[ATraining Step: 7  | total loss: [1m[32m0.65396[0m[0m | time: 128.469s
[2K
| Adam | epoch: 001 | loss: 0.65396 - acc: 0.6949 -- iter: 224/696
[A[ATraining Step: 8  | total loss: [1m[32m0.58364[0m[0m | time: 140.282s
[2K
| Adam | epoch: 001 | loss: 0.58364 - acc: 0.7083 -- iter: 256/696
[A[ATraining Step: 9  | total loss: [1m[32m0.69946[0m[0m | time: 152.184s
[2K
| Adam | epoch: 001 | loss: 0.69946 - acc: 0.6808 -- iter: 288/696
[A[ATraining Step: 10  | total loss: [1m[32m0.66650[0m[0m | time: 164.423s
[2K
| Adam | epoch: 001 | loss: 0.66650 - acc: 0.6998 -- iter: 320/696
[A[ATraining Step: 11  | total loss: [1m[32m0.66304[0m[0m | time: 176.445s
[2K
| Adam | epoch: 001 | loss: 0.66304 - acc: 0.6791 -- iter: 352/696
[A[ATraining Step: 12  | total loss: [1m[32m0.66110[0m[0m | time: 188.075s
[2K
| Adam | epoch: 001 | loss: 0.66110 - acc: 0.6407 -- iter: 384/696
[A[ATraining Step: 13  | total loss: [1m[32m0.66233[0m[0m | time: 196.065s
[2K
| Adam | epoch: 001 | loss: 0.66233 - acc: 0.6742 -- iter: 416/696
[A[ATraining Step: 14  | total loss: [1m[32m0.69954[0m[0m | time: 203.964s
[2K
| Adam | epoch: 001 | loss: 0.69954 - acc: 0.6285 -- iter: 448/696
[A[ATraining Step: 15  | total loss: [1m[32m0.58154[0m[0m | time: 211.843s
[2K
| Adam | epoch: 001 | loss: 0.58154 - acc: 0.7249 -- iter: 480/696
[A[ATraining Step: 16  | total loss: [1m[32m0.52575[0m[0m | time: 221.535s
[2K
| Adam | epoch: 001 | loss: 0.52575 - acc: 0.7578 -- iter: 512/696
[A[ATraining Step: 17  | total loss: [1m[32m0.48315[0m[0m | time: 232.908s
[2K
| Adam | epoch: 001 | loss: 0.48315 - acc: 0.8000 -- iter: 544/696
[A[ATraining Step: 18  | total loss: [1m[32m0.46062[0m[0m | time: 243.869s
[2K
| Adam | epoch: 001 | loss: 0.46062 - acc: 0.7935 -- iter: 576/696
[A[ATraining Step: 19  | total loss: [1m[32m0.50558[0m[0m | time: 254.940s
[2K
| Adam | epoch: 001 | loss: 0.50558 - acc: 0.7373 -- iter: 608/696
[A[ATraining Step: 20  | total loss: [1m[32m0.45053[0m[0m | time: 265.872s
[2K
| Adam | epoch: 001 | loss: 0.45053 - acc: 0.7816 -- iter: 640/696
[A[ATraining Step: 21  | total loss: [1m[32m0.44800[0m[0m | time: 277.015s
[2K
| Adam | epoch: 001 | loss: 0.44800 - acc: 0.7912 -- iter: 672/696
[A[ATraining Step: 22  | total loss: [1m[32m0.43112[0m[0m | time: 311.437s
[2K
| Adam | epoch: 001 | loss: 0.43112 - acc: 0.7882 | val_loss: 2.71255 - val_acc: 0.5092 -- iter: 696/696
--
Training Step: 23  | total loss: [1m[32m0.46870[0m[0m | time: 8.743s
[2K
| Adam | epoch: 002 | loss: 0.46870 - acc: 0.7650 -- iter: 032/696
[A[ATraining Step: 24  | total loss: [1m[32m0.40405[0m[0m | time: 19.801s
[2K
| Adam | epoch: 002 | loss: 0.40405 - acc: 0.8077 -- iter: 064/696
[A[ATraining Step: 25  | total loss: [1m[32m0.37045[0m[0m | time: 30.809s
[2K
| Adam | epoch: 002 | loss: 0.37045 - acc: 0.8260 -- iter: 096/696
[A[ATraining Step: 26  | total loss: [1m[32m0.46331[0m[0m | time: 42.107s
[2K
| Adam | epoch: 002 | loss: 0.46331 - acc: 0.7976 -- iter: 128/696
[A[ATraining Step: 27  | total loss: [1m[32m0.53568[0m[0m | time: 53.144s
[2K
| Adam | epoch: 002 | loss: 0.53568 - acc: 0.7934 -- iter: 160/696
[A[ATraining Step: 28  | total loss: [1m[32m0.56842[0m[0m | time: 64.489s
[2K
| Adam | epoch: 002 | loss: 0.56842 - acc: 0.7748 -- iter: 192/696
[A[ATraining Step: 29  | total loss: [1m[32m0.54610[0m[0m | time: 75.450s
[2K
| Adam | epoch: 002 | loss: 0.54610 - acc: 0.7687 -- iter: 224/696
[A[ATraining Step: 30  | total loss: [1m[32m0.52940[0m[0m | time: 86.454s
[2K
| Adam | epoch: 002 | loss: 0.52940 - acc: 0.7791 -- iter: 256/696
[A[ATraining Step: 31  | total loss: [1m[32m0.53254[0m[0m | time: 97.830s
[2K
| Adam | epoch: 002 | loss: 0.53254 - acc: 0.7652 -- iter: 288/696
[A[ATraining Step: 32  | total loss: [1m[32m0.54481[0m[0m | time: 108.559s
[2K
| Adam | epoch: 002 | loss: 0.54481 - acc: 0.7547 -- iter: 320/696
[A[ATraining Step: 33  | total loss: [1m[32m0.57634[0m[0m | time: 119.781s
[2K
| Adam | epoch: 002 | loss: 0.57634 - acc: 0.7537 -- iter: 352/696
[A[ATraining Step: 34  | total loss: [1m[32m0.53161[0m[0m | time: 130.627s
[2K
| Adam | epoch: 002 | loss: 0.53161 - acc: 0.7663 -- iter: 384/696
[A[ATraining Step: 35  | total loss: [1m[32m0.53666[0m[0m | time: 141.615s
[2K
| Adam | epoch: 002 | loss: 0.53666 - acc: 0.7563 -- iter: 416/696
[A[ATraining Step: 36  | total loss: [1m[32m0.49973[0m[0m | time: 152.988s
[2K
| Adam | epoch: 002 | loss: 0.49973 - acc: 0.7806 -- iter: 448/696
[A[ATraining Step: 37  | total loss: [1m[32m0.50655[0m[0m | time: 164.070s
[2K
| Adam | epoch: 002 | loss: 0.50655 - acc: 0.7682 -- iter: 480/696
[A[ATraining Step: 38  | total loss: [1m[32m0.48317[0m[0m | time: 174.897s
[2K
| Adam | epoch: 002 | loss: 0.48317 - acc: 0.8014 -- iter: 512/696
[A[ATraining Step: 39  | total loss: [1m[32m0.46290[0m[0m | time: 185.512s
[2K
| Adam | epoch: 002 | loss: 0.46290 - acc: 0.8274 -- iter: 544/696
[A[ATraining Step: 40  | total loss: [1m[32m0.44898[0m[0m | time: 196.820s
[2K
| Adam | epoch: 002 | loss: 0.44898 - acc: 0.8246 -- iter: 576/696
[A[ATraining Step: 41  | total loss: [1m[32m0.45373[0m[0m | time: 207.757s
[2K
| Adam | epoch: 002 | loss: 0.45373 - acc: 0.8109 -- iter: 608/696
[A[ATraining Step: 42  | total loss: [1m[32m0.45276[0m[0m | time: 218.848s
[2K
| Adam | epoch: 002 | loss: 0.45276 - acc: 0.8112 -- iter: 640/696
[A[ATraining Step: 43  | total loss: [1m[32m0.42679[0m[0m | time: 229.780s
[2K
| Adam | epoch: 002 | loss: 0.42679 - acc: 0.8225 -- iter: 672/696
[A[ATraining Step: 44  | total loss: [1m[32m0.38817[0m[0m | time: 255.124s
[2K
| Adam | epoch: 002 | loss: 0.38817 - acc: 0.8478 | val_loss: 1.71414 - val_acc: 0.5092 -- iter: 696/696
--
Training Step: 45  | total loss: [1m[32m0.35938[0m[0m | time: 9.386s
[2K
| Adam | epoch: 003 | loss: 0.35938 - acc: 0.8630 -- iter: 032/696
[A[ATraining Step: 46  | total loss: [1m[32m0.34153[0m[0m | time: 17.927s
[2K
| Adam | epoch: 003 | loss: 0.34153 - acc: 0.8720 -- iter: 064/696
[A[ATraining Step: 47  | total loss: [1m[32m0.30306[0m[0m | time: 28.955s
[2K
| Adam | epoch: 003 | loss: 0.30306 - acc: 0.8929 -- iter: 096/696
[A[ATraining Step: 48  | total loss: [1m[32m0.32998[0m[0m | time: 39.974s
[2K
| Adam | epoch: 003 | loss: 0.32998 - acc: 0.8649 -- iter: 128/696
[A[ATraining Step: 49  | total loss: [1m[32m0.37276[0m[0m | time: 51.314s
[2K
| Adam | epoch: 003 | loss: 0.37276 - acc: 0.8468 -- iter: 160/696
[A[ATraining Step: 50  | total loss: [1m[32m0.37435[0m[0m | time: 62.080s
[2K
| Adam | epoch: 003 | loss: 0.37435 - acc: 0.8463 -- iter: 192/696
[A[ATraining Step: 51  | total loss: [1m[32m0.37551[0m[0m | time: 73.200s
[2K
| Adam | epoch: 003 | loss: 0.37551 - acc: 0.8459 -- iter: 224/696
[A[ATraining Step: 52  | total loss: [1m[32m0.38091[0m[0m | time: 84.128s
[2K
| Adam | epoch: 003 | loss: 0.38091 - acc: 0.8409 -- iter: 256/696
[A[ATraining Step: 53  | total loss: [1m[32m0.36071[0m[0m | time: 95.342s
[2K
| Adam | epoch: 003 | loss: 0.36071 - acc: 0.8413 -- iter: 288/696
[A[ATraining Step: 54  | total loss: [1m[32m0.38831[0m[0m | time: 106.259s
[2K
| Adam | epoch: 003 | loss: 0.38831 - acc: 0.8190 -- iter: 320/696
[A[ATraining Step: 55  | total loss: [1m[32m0.37273[0m[0m | time: 117.000s
[2K
| Adam | epoch: 003 | loss: 0.37273 - acc: 0.8270 -- iter: 352/696
[A[ATraining Step: 56  | total loss: [1m[32m0.36995[0m[0m | time: 127.821s
[2K
| Adam | epoch: 003 | loss: 0.36995 - acc: 0.8337 -- iter: 384/696
[A[ATraining Step: 57  | total loss: [1m[32m0.33801[0m[0m | time: 139.013s
[2K
| Adam | epoch: 003 | loss: 0.33801 - acc: 0.8481 -- iter: 416/696
[A[ATraining Step: 58  | total loss: [1m[32m0.32235[0m[0m | time: 150.114s
[2K
| Adam | epoch: 003 | loss: 0.32235 - acc: 0.8560 -- iter: 448/696
[A[ATraining Step: 59  | total loss: [1m[32m0.34074[0m[0m | time: 161.414s
[2K
| Adam | epoch: 003 | loss: 0.34074 - acc: 0.8544 -- iter: 480/696
[A[ATraining Step: 60  | total loss: [1m[32m0.34409[0m[0m | time: 172.563s
[2K
| Adam | epoch: 003 | loss: 0.34409 - acc: 0.8654 -- iter: 512/696
[A[ATraining Step: 61  | total loss: [1m[32m0.31112[0m[0m | time: 183.493s
[2K
| Adam | epoch: 003 | loss: 0.31112 - acc: 0.8829 -- iter: 544/696
[A[ATraining Step: 62  | total loss: [1m[32m0.33431[0m[0m | time: 194.866s
[2K
| Adam | epoch: 003 | loss: 0.33431 - acc: 0.8699 -- iter: 576/696
[A[ATraining Step: 63  | total loss: [1m[32m0.33383[0m[0m | time: 205.625s
[2K
| Adam | epoch: 003 | loss: 0.33383 - acc: 0.8586 -- iter: 608/696
[A[ATraining Step: 64  | total loss: [1m[32m0.29757[0m[0m | time: 216.522s
[2K
| Adam | epoch: 003 | loss: 0.29757 - acc: 0.8763 -- iter: 640/696
[A[ATraining Step: 65  | total loss: [1m[32m0.29698[0m[0m | time: 227.436s
[2K
| Adam | epoch: 003 | loss: 0.29698 - acc: 0.8761 -- iter: 672/696
[A[ATraining Step: 66  | total loss: [1m[32m0.28301[0m[0m | time: 252.947s
[2K
| Adam | epoch: 003 | loss: 0.28301 - acc: 0.8836 | val_loss: 0.83499 - val_acc: 0.6147 -- iter: 696/696
--
Training Step: 67  | total loss: [1m[32m0.28445[0m[0m | time: 11.957s
[2K
| Adam | epoch: 004 | loss: 0.28445 - acc: 0.8788 -- iter: 032/696
[A[ATraining Step: 68  | total loss: [1m[32m0.27484[0m[0m | time: 21.614s
[2K
| Adam | epoch: 004 | loss: 0.27484 - acc: 0.8858 -- iter: 064/696
[A[ATraining Step: 69  | total loss: [1m[32m0.25344[0m[0m | time: 31.036s
[2K
| Adam | epoch: 004 | loss: 0.25344 - acc: 0.8991 -- iter: 096/696
[A[ATraining Step: 70  | total loss: [1m[32m0.22987[0m[0m | time: 43.062s
[2K
| Adam | epoch: 004 | loss: 0.22987 - acc: 0.9108 -- iter: 128/696
[A[ATraining Step: 71  | total loss: [1m[32m0.22736[0m[0m | time: 55.215s
[2K
| Adam | epoch: 004 | loss: 0.22736 - acc: 0.9138 -- iter: 160/696
[A[ATraining Step: 72  | total loss: [1m[32m0.23771[0m[0m | time: 67.081s
[2K
| Adam | epoch: 004 | loss: 0.23771 - acc: 0.9094 -- iter: 192/696
[A[ATraining Step: 73  | total loss: [1m[32m0.24675[0m[0m | time: 77.191s
[2K
| Adam | epoch: 004 | loss: 0.24675 - acc: 0.9021 -- iter: 224/696
[A[ATraining Step: 74  | total loss: [1m[32m0.25030[0m[0m | time: 84.992s
[2K
| Adam | epoch: 004 | loss: 0.25030 - acc: 0.8992 -- iter: 256/696
[A[ATraining Step: 75  | total loss: [1m[32m0.22995[0m[0m | time: 92.735s
[2K
| Adam | epoch: 004 | loss: 0.22995 - acc: 0.9101 -- iter: 288/696
[A[ATraining Step: 76  | total loss: [1m[32m0.23506[0m[0m | time: 100.595s
[2K
| Adam | epoch: 004 | loss: 0.23506 - acc: 0.9097 -- iter: 320/696
[A[ATraining Step: 77  | total loss: [1m[32m0.22110[0m[0m | time: 111.123s
[2K
| Adam | epoch: 004 | loss: 0.22110 - acc: 0.9159 -- iter: 352/696
[A[ATraining Step: 78  | total loss: [1m[32m0.21683[0m[0m | time: 122.194s
[2K
| Adam | epoch: 004 | loss: 0.21683 - acc: 0.9182 -- iter: 384/696
[A[ATraining Step: 79  | total loss: [1m[32m0.20557[0m[0m | time: 133.538s
[2K
| Adam | epoch: 004 | loss: 0.20557 - acc: 0.9234 -- iter: 416/696
[A[ATraining Step: 80  | total loss: [1m[32m0.22196[0m[0m | time: 144.395s
[2K
| Adam | epoch: 004 | loss: 0.22196 - acc: 0.9185 -- iter: 448/696
[A[ATraining Step: 81  | total loss: [1m[32m0.20852[0m[0m | time: 155.574s
[2K
| Adam | epoch: 004 | loss: 0.20852 - acc: 0.9236 -- iter: 480/696
[A[ATraining Step: 82  | total loss: [1m[32m0.20435[0m[0m | time: 166.839s
[2K
| Adam | epoch: 004 | loss: 0.20435 - acc: 0.9281 -- iter: 512/696
[A[ATraining Step: 83  | total loss: [1m[32m0.20760[0m[0m | time: 177.739s
[2K
| Adam | epoch: 004 | loss: 0.20760 - acc: 0.9290 -- iter: 544/696
[A[ATraining Step: 84  | total loss: [1m[32m0.20051[0m[0m | time: 189.189s
[2K
| Adam | epoch: 004 | loss: 0.20051 - acc: 0.9299 -- iter: 576/696
[A[ATraining Step: 85  | total loss: [1m[32m0.19901[0m[0m | time: 200.319s
[2K
| Adam | epoch: 004 | loss: 0.19901 - acc: 0.9306 -- iter: 608/696
[A[ATraining Step: 86  | total loss: [1m[32m0.18949[0m[0m | time: 211.424s
[2K
| Adam | epoch: 004 | loss: 0.18949 - acc: 0.9344 -- iter: 640/696
[A[ATraining Step: 87  | total loss: [1m[32m0.17268[0m[0m | time: 222.555s
[2K
| Adam | epoch: 004 | loss: 0.17268 - acc: 0.9410 -- iter: 672/696
[A[ATraining Step: 88  | total loss: [1m[32m0.18969[0m[0m | time: 247.348s
[2K
| Adam | epoch: 004 | loss: 0.18969 - acc: 0.9406 | val_loss: 1.79084 - val_acc: 0.6560 -- iter: 696/696
--
Training Step: 89  | total loss: [1m[32m0.17862[0m[0m | time: 11.232s
[2K
| Adam | epoch: 005 | loss: 0.17862 - acc: 0.9435 -- iter: 032/696
[A[ATraining Step: 90  | total loss: [1m[32m0.16918[0m[0m | time: 22.337s
[2K
| Adam | epoch: 005 | loss: 0.16918 - acc: 0.9460 -- iter: 064/696
[A[ATraining Step: 91  | total loss: [1m[32m0.15999[0m[0m | time: 31.350s
[2K
| Adam | epoch: 005 | loss: 0.15999 - acc: 0.9514 -- iter: 096/696
[A[ATraining Step: 92  | total loss: [1m[32m0.14821[0m[0m | time: 39.863s
[2K
| Adam | epoch: 005 | loss: 0.14821 - acc: 0.9563 -- iter: 128/696
[A[ATraining Step: 93  | total loss: [1m[32m0.13600[0m[0m | time: 50.720s
[2K
| Adam | epoch: 005 | loss: 0.13600 - acc: 0.9606 -- iter: 160/696
[A[ATraining Step: 94  | total loss: [1m[32m0.15292[0m[0m | time: 61.854s
[2K
| Adam | epoch: 005 | loss: 0.15292 - acc: 0.9521 -- iter: 192/696
[A[ATraining Step: 95  | total loss: [1m[32m0.17339[0m[0m | time: 73.097s
[2K
| Adam | epoch: 005 | loss: 0.17339 - acc: 0.9381 -- iter: 224/696
[A[ATraining Step: 96  | total loss: [1m[32m0.16626[0m[0m | time: 84.147s
[2K
| Adam | epoch: 005 | loss: 0.16626 - acc: 0.9380 -- iter: 256/696
[A[ATraining Step: 97  | total loss: [1m[32m0.15569[0m[0m | time: 95.191s
[2K
| Adam | epoch: 005 | loss: 0.15569 - acc: 0.9442 -- iter: 288/696
[A[ATraining Step: 98  | total loss: [1m[32m0.16225[0m[0m | time: 106.377s
[2K
| Adam | epoch: 005 | loss: 0.16225 - acc: 0.9467 -- iter: 320/696
[A[ATraining Step: 99  | total loss: [1m[32m0.15716[0m[0m | time: 117.457s
[2K
| Adam | epoch: 005 | loss: 0.15716 - acc: 0.9458 -- iter: 352/696
[A[ATraining Step: 100  | total loss: [1m[32m0.17809[0m[0m | time: 128.735s
[2K
| Adam | epoch: 005 | loss: 0.17809 - acc: 0.9387 -- iter: 384/696
[A[ATraining Step: 101  | total loss: [1m[32m0.17272[0m[0m | time: 139.591s
[2K
| Adam | epoch: 005 | loss: 0.17272 - acc: 0.9417 -- iter: 416/696
[A[ATraining Step: 102  | total loss: [1m[32m0.16314[0m[0m | time: 151.227s
[2K
| Adam | epoch: 005 | loss: 0.16314 - acc: 0.9475 -- iter: 448/696
[A[ATraining Step: 103  | total loss: [1m[32m0.16067[0m[0m | time: 162.106s
[2K
| Adam | epoch: 005 | loss: 0.16067 - acc: 0.9434 -- iter: 480/696
[A[ATraining Step: 104  | total loss: [1m[32m0.16195[0m[0m | time: 173.370s
[2K
| Adam | epoch: 005 | loss: 0.16195 - acc: 0.9366 -- iter: 512/696
[A[ATraining Step: 105  | total loss: [1m[32m0.15138[0m[0m | time: 184.328s
[2K
| Adam | epoch: 005 | loss: 0.15138 - acc: 0.9429 -- iter: 544/696
[A[ATraining Step: 106  | total loss: [1m[32m0.14720[0m[0m | time: 195.887s
[2K
| Adam | epoch: 005 | loss: 0.14720 - acc: 0.9455 -- iter: 576/696
[A[ATraining Step: 107  | total loss: [1m[32m0.14561[0m[0m | time: 207.338s
[2K
| Adam | epoch: 005 | loss: 0.14561 - acc: 0.9416 -- iter: 608/696
[A[ATraining Step: 108  | total loss: [1m[32m0.14384[0m[0m | time: 218.496s
[2K
| Adam | epoch: 005 | loss: 0.14384 - acc: 0.9380 -- iter: 640/696
[A[ATraining Step: 109  | total loss: [1m[32m0.13305[0m[0m | time: 229.450s
[2K
| Adam | epoch: 005 | loss: 0.13305 - acc: 0.9442 -- iter: 672/696
[A[ATraining Step: 110  | total loss: [1m[32m0.12321[0m[0m | time: 254.839s
[2K
| Adam | epoch: 005 | loss: 0.12321 - acc: 0.9498 | val_loss: 0.70900 - val_acc: 0.7706 -- iter: 696/696
--
Training Step: 111  | total loss: [1m[32m0.11227[0m[0m | time: 11.114s
[2K
| Adam | epoch: 006 | loss: 0.11227 - acc: 0.9548 -- iter: 032/696
[A[ATraining Step: 112  | total loss: [1m[32m0.10678[0m[0m | time: 22.169s
[2K
| Adam | epoch: 006 | loss: 0.10678 - acc: 0.9593 -- iter: 064/696
[A[ATraining Step: 113  | total loss: [1m[32m0.10468[0m[0m | time: 33.039s
[2K
| Adam | epoch: 006 | loss: 0.10468 - acc: 0.9603 -- iter: 096/696
[A[ATraining Step: 114  | total loss: [1m[32m0.09896[0m[0m | time: 41.931s
[2K
| Adam | epoch: 006 | loss: 0.09896 - acc: 0.9643 -- iter: 128/696
[A[ATraining Step: 115  | total loss: [1m[32m0.10211[0m[0m | time: 50.371s
[2K
| Adam | epoch: 006 | loss: 0.10211 - acc: 0.9637 -- iter: 160/696
[A[ATraining Step: 116  | total loss: [1m[32m0.09458[0m[0m | time: 61.268s
[2K
| Adam | epoch: 006 | loss: 0.09458 - acc: 0.9673 -- iter: 192/696
[A[ATraining Step: 117  | total loss: [1m[32m0.08992[0m[0m | time: 72.594s
[2K
| Adam | epoch: 006 | loss: 0.08992 - acc: 0.9674 -- iter: 224/696
[A[ATraining Step: 118  | total loss: [1m[32m0.08600[0m[0m | time: 83.529s
[2K
| Adam | epoch: 006 | loss: 0.08600 - acc: 0.9707 -- iter: 256/696
[A[ATraining Step: 119  | total loss: [1m[32m0.11953[0m[0m | time: 94.901s
[2K
| Adam | epoch: 006 | loss: 0.11953 - acc: 0.9611 -- iter: 288/696
[A[ATraining Step: 120  | total loss: [1m[32m0.11113[0m[0m | time: 105.931s
[2K
| Adam | epoch: 006 | loss: 0.11113 - acc: 0.9650 -- iter: 320/696
[A[ATraining Step: 121  | total loss: [1m[32m0.10216[0m[0m | time: 116.884s
[2K
| Adam | epoch: 006 | loss: 0.10216 - acc: 0.9685 -- iter: 352/696
[A[ATraining Step: 122  | total loss: [1m[32m0.09817[0m[0m | time: 128.046s
[2K
| Adam | epoch: 006 | loss: 0.09817 - acc: 0.9685 -- iter: 384/696
[A[ATraining Step: 123  | total loss: [1m[32m0.12950[0m[0m | time: 138.912s
[2K
| Adam | epoch: 006 | loss: 0.12950 - acc: 0.9592 -- iter: 416/696
[A[ATraining Step: 124  | total loss: [1m[32m0.12344[0m[0m | time: 150.120s
[2K
| Adam | epoch: 006 | loss: 0.12344 - acc: 0.9601 -- iter: 448/696
[A[ATraining Step: 125  | total loss: [1m[32m0.11567[0m[0m | time: 161.131s
[2K
| Adam | epoch: 006 | loss: 0.11567 - acc: 0.9610 -- iter: 480/696
[A[ATraining Step: 126  | total loss: [1m[32m0.12259[0m[0m | time: 172.041s
[2K
| Adam | epoch: 006 | loss: 0.12259 - acc: 0.9555 -- iter: 512/696
[A[ATraining Step: 127  | total loss: [1m[32m0.12102[0m[0m | time: 183.256s
[2K
| Adam | epoch: 006 | loss: 0.12102 - acc: 0.9568 -- iter: 544/696
[A[ATraining Step: 128  | total loss: [1m[32m0.11303[0m[0m | time: 194.225s
[2K
| Adam | epoch: 006 | loss: 0.11303 - acc: 0.9612 -- iter: 576/696
[A[ATraining Step: 129  | total loss: [1m[32m0.13108[0m[0m | time: 205.180s
[2K
| Adam | epoch: 006 | loss: 0.13108 - acc: 0.9588 -- iter: 608/696
[A[ATraining Step: 130  | total loss: [1m[32m0.11947[0m[0m | time: 216.279s
[2K
| Adam | epoch: 006 | loss: 0.11947 - acc: 0.9629 -- iter: 640/696
[A[ATraining Step: 131  | total loss: [1m[32m0.11219[0m[0m | time: 227.329s
[2K
| Adam | epoch: 006 | loss: 0.11219 - acc: 0.9666 -- iter: 672/696
[A[ATraining Step: 132  | total loss: [1m[32m0.10581[0m[0m | time: 252.302s
[2K
| Adam | epoch: 006 | loss: 0.10581 - acc: 0.9700 | val_loss: 2.62992 - val_acc: 0.5367 -- iter: 696/696
--
Training Step: 133  | total loss: [1m[32m0.13058[0m[0m | time: 11.066s
[2K
| Adam | epoch: 007 | loss: 0.13058 - acc: 0.9636 -- iter: 032/696
[A[ATraining Step: 134  | total loss: [1m[32m0.12352[0m[0m | time: 22.233s
[2K
| Adam | epoch: 007 | loss: 0.12352 - acc: 0.9641 -- iter: 064/696
[A[ATraining Step: 135  | total loss: [1m[32m0.11609[0m[0m | time: 33.041s
[2K
| Adam | epoch: 007 | loss: 0.11609 - acc: 0.9677 -- iter: 096/696
[A[ATraining Step: 136  | total loss: [1m[32m0.10820[0m[0m | time: 44.062s
[2K
| Adam | epoch: 007 | loss: 0.10820 - acc: 0.9709 -- iter: 128/696
[A[ATraining Step: 137  | total loss: [1m[32m0.11767[0m[0m | time: 52.844s
[2K
| Adam | epoch: 007 | loss: 0.11767 - acc: 0.9645 -- iter: 160/696
[A[ATraining Step: 138  | total loss: [1m[32m0.12048[0m[0m | time: 61.895s
[2K
| Adam | epoch: 007 | loss: 0.12048 - acc: 0.9638 -- iter: 192/696
[A[ATraining Step: 139  | total loss: [1m[32m0.10984[0m[0m | time: 72.776s
[2K
| Adam | epoch: 007 | loss: 0.10984 - acc: 0.9675 -- iter: 224/696
[A[ATraining Step: 140  | total loss: [1m[32m0.10761[0m[0m | time: 83.952s
[2K
| Adam | epoch: 007 | loss: 0.10761 - acc: 0.9676 -- iter: 256/696
[A[ATraining Step: 141  | total loss: [1m[32m0.10520[0m[0m | time: 94.827s
[2K
| Adam | epoch: 007 | loss: 0.10520 - acc: 0.9646 -- iter: 288/696
[A[ATraining Step: 142  | total loss: [1m[32m0.10145[0m[0m | time: 105.941s
[2K
| Adam | epoch: 007 | loss: 0.10145 - acc: 0.9650 -- iter: 320/696
[A[ATraining Step: 143  | total loss: [1m[32m0.10199[0m[0m | time: 117.141s
[2K
| Adam | epoch: 007 | loss: 0.10199 - acc: 0.9622 -- iter: 352/696
[A[ATraining Step: 144  | total loss: [1m[32m0.09537[0m[0m | time: 128.218s
[2K
| Adam | epoch: 007 | loss: 0.09537 - acc: 0.9660 -- iter: 384/696
[A[ATraining Step: 145  | total loss: [1m[32m0.12006[0m[0m | time: 139.107s
[2K
| Adam | epoch: 007 | loss: 0.12006 - acc: 0.9569 -- iter: 416/696
[A[ATraining Step: 146  | total loss: [1m[32m0.12989[0m[0m | time: 150.373s
[2K
| Adam | epoch: 007 | loss: 0.12989 - acc: 0.9581 -- iter: 448/696
[A[ATraining Step: 147  | total loss: [1m[32m0.14161[0m[0m | time: 161.471s
[2K
| Adam | epoch: 007 | loss: 0.14161 - acc: 0.9560 -- iter: 480/696
[A[ATraining Step: 148  | total loss: [1m[32m0.13001[0m[0m | time: 172.784s
[2K
| Adam | epoch: 007 | loss: 0.13001 - acc: 0.9604 -- iter: 512/696
[A[ATraining Step: 149  | total loss: [1m[32m0.12462[0m[0m | time: 184.186s
[2K
| Adam | epoch: 007 | loss: 0.12462 - acc: 0.9613 -- iter: 544/696
[A[ATraining Step: 150  | total loss: [1m[32m0.11804[0m[0m | time: 195.219s
[2K
| Adam | epoch: 007 | loss: 0.11804 - acc: 0.9620 -- iter: 576/696
[A[ATraining Step: 151  | total loss: [1m[32m0.11949[0m[0m | time: 205.905s
[2K
| Adam | epoch: 007 | loss: 0.11949 - acc: 0.9596 -- iter: 608/696
[A[ATraining Step: 152  | total loss: [1m[32m0.13641[0m[0m | time: 217.262s
[2K
| Adam | epoch: 007 | loss: 0.13641 - acc: 0.9574 -- iter: 640/696
[A[ATraining Step: 153  | total loss: [1m[32m0.12415[0m[0m | time: 228.057s
[2K
| Adam | epoch: 007 | loss: 0.12415 - acc: 0.9616 -- iter: 672/696
[A[ATraining Step: 154  | total loss: [1m[32m0.12099[0m[0m | time: 252.771s
[2K
| Adam | epoch: 007 | loss: 0.12099 - acc: 0.9592 | val_loss: 2.30639 - val_acc: 0.5688 -- iter: 696/696
--
Training Step: 155  | total loss: [1m[32m0.12534[0m[0m | time: 11.300s
[2K
| Adam | epoch: 008 | loss: 0.12534 - acc: 0.9602 -- iter: 032/696
[A[ATraining Step: 156  | total loss: [1m[32m0.12317[0m[0m | time: 22.567s
[2K
| Adam | epoch: 008 | loss: 0.12317 - acc: 0.9610 -- iter: 064/696
[A[ATraining Step: 157  | total loss: [1m[32m0.11565[0m[0m | time: 33.573s
[2K
| Adam | epoch: 008 | loss: 0.11565 - acc: 0.9649 -- iter: 096/696
[A[ATraining Step: 158  | total loss: [1m[32m0.11387[0m[0m | time: 44.610s
[2K
| Adam | epoch: 008 | loss: 0.11387 - acc: 0.9622 -- iter: 128/696
[A[ATraining Step: 159  | total loss: [1m[32m0.14101[0m[0m | time: 55.945s
[2K
| Adam | epoch: 008 | loss: 0.14101 - acc: 0.9535 -- iter: 160/696
[A[ATraining Step: 160  | total loss: [1m[32m0.16543[0m[0m | time: 64.734s
[2K
| Adam | epoch: 008 | loss: 0.16543 - acc: 0.9425 -- iter: 192/696
[A[ATraining Step: 161  | total loss: [1m[32m0.17763[0m[0m | time: 73.020s
[2K
| Adam | epoch: 008 | loss: 0.17763 - acc: 0.9357 -- iter: 224/696
[A[ATraining Step: 162  | total loss: [1m[32m0.16501[0m[0m | time: 84.423s
[2K
| Adam | epoch: 008 | loss: 0.16501 - acc: 0.9422 -- iter: 256/696
[A[ATraining Step: 163  | total loss: [1m[32m0.15774[0m[0m | time: 95.291s
[2K
| Adam | epoch: 008 | loss: 0.15774 - acc: 0.9448 -- iter: 288/696
[A[ATraining Step: 164  | total loss: [1m[32m0.15031[0m[0m | time: 106.500s
[2K
| Adam | epoch: 008 | loss: 0.15031 - acc: 0.9503 -- iter: 320/696
[A[ATraining Step: 165  | total loss: [1m[32m0.14018[0m[0m | time: 117.975s
[2K
| Adam | epoch: 008 | loss: 0.14018 - acc: 0.9553 -- iter: 352/696
[A[ATraining Step: 166  | total loss: [1m[32m0.12966[0m[0m | time: 128.931s
[2K
| Adam | epoch: 008 | loss: 0.12966 - acc: 0.9598 -- iter: 384/696
[A[ATraining Step: 167  | total loss: [1m[32m0.12288[0m[0m | time: 140.363s
[2K
| Adam | epoch: 008 | loss: 0.12288 - acc: 0.9607 -- iter: 416/696
[A[ATraining Step: 168  | total loss: [1m[32m0.12136[0m[0m | time: 151.398s
[2K
| Adam | epoch: 008 | loss: 0.12136 - acc: 0.9584 -- iter: 448/696
[A[ATraining Step: 169  | total loss: [1m[32m0.11284[0m[0m | time: 162.787s
[2K
| Adam | epoch: 008 | loss: 0.11284 - acc: 0.9625 -- iter: 480/696
[A[ATraining Step: 170  | total loss: [1m[32m0.10424[0m[0m | time: 173.831s
[2K
| Adam | epoch: 008 | loss: 0.10424 - acc: 0.9663 -- iter: 512/696
[A[ATraining Step: 171  | total loss: [1m[32m0.09867[0m[0m | time: 184.820s
[2K
| Adam | epoch: 008 | loss: 0.09867 - acc: 0.9665 -- iter: 544/696
[A[ATraining Step: 172  | total loss: [1m[32m0.09421[0m[0m | time: 195.973s
[2K
| Adam | epoch: 008 | loss: 0.09421 - acc: 0.9699 -- iter: 576/696
[A[ATraining Step: 173  | total loss: [1m[32m0.09166[0m[0m | time: 207.205s
[2K
| Adam | epoch: 008 | loss: 0.09166 - acc: 0.9698 -- iter: 608/696
[A[ATraining Step: 174  | total loss: [1m[32m0.11157[0m[0m | time: 218.305s
[2K
| Adam | epoch: 008 | loss: 0.11157 - acc: 0.9634 -- iter: 640/696
[A[ATraining Step: 175  | total loss: [1m[32m0.12193[0m[0m | time: 229.195s
[2K
| Adam | epoch: 008 | loss: 0.12193 - acc: 0.9577 -- iter: 672/696
[A[ATraining Step: 176  | total loss: [1m[32m0.11165[0m[0m | time: 254.198s
[2K
| Adam | epoch: 008 | loss: 0.11165 - acc: 0.9619 | val_loss: 2.15776 - val_acc: 0.5596 -- iter: 696/696
--
Training Step: 177  | total loss: [1m[32m0.10319[0m[0m | time: 11.741s
[2K
| Adam | epoch: 009 | loss: 0.10319 - acc: 0.9657 -- iter: 032/696
[A[ATraining Step: 178  | total loss: [1m[32m0.09935[0m[0m | time: 22.606s
[2K
| Adam | epoch: 009 | loss: 0.09935 - acc: 0.9660 -- iter: 064/696
[A[ATraining Step: 179  | total loss: [1m[32m0.10405[0m[0m | time: 33.649s
[2K
| Adam | epoch: 009 | loss: 0.10405 - acc: 0.9632 -- iter: 096/696
[A[ATraining Step: 180  | total loss: [1m[32m0.09466[0m[0m | time: 45.331s
[2K
| Adam | epoch: 009 | loss: 0.09466 - acc: 0.9669 -- iter: 128/696
[A[ATraining Step: 181  | total loss: [1m[32m0.09012[0m[0m | time: 56.144s
[2K
| Adam | epoch: 009 | loss: 0.09012 - acc: 0.9670 -- iter: 160/696
[A[ATraining Step: 182  | total loss: [1m[32m0.08169[0m[0m | time: 67.369s
[2K
| Adam | epoch: 009 | loss: 0.08169 - acc: 0.9703 -- iter: 192/696
[A[ATraining Step: 183  | total loss: [1m[32m0.08178[0m[0m | time: 75.884s
[2K
| Adam | epoch: 009 | loss: 0.08178 - acc: 0.9671 -- iter: 224/696
[A[ATraining Step: 184  | total loss: [1m[32m0.07550[0m[0m | time: 84.584s
[2K
| Adam | epoch: 009 | loss: 0.07550 - acc: 0.9704 -- iter: 256/696
[A[ATraining Step: 185  | total loss: [1m[32m0.06886[0m[0m | time: 95.827s
[2K
| Adam | epoch: 009 | loss: 0.06886 - acc: 0.9733 -- iter: 288/696
[A[ATraining Step: 186  | total loss: [1m[32m0.08371[0m[0m | time: 106.926s
[2K
| Adam | epoch: 009 | loss: 0.08371 - acc: 0.9697 -- iter: 320/696
[A[ATraining Step: 187  | total loss: [1m[32m0.07959[0m[0m | time: 117.934s
[2K
| Adam | epoch: 009 | loss: 0.07959 - acc: 0.9696 -- iter: 352/696
[A[ATraining Step: 188  | total loss: [1m[32m0.07368[0m[0m | time: 129.255s
[2K
| Adam | epoch: 009 | loss: 0.07368 - acc: 0.9727 -- iter: 384/696
[A[ATraining Step: 189  | total loss: [1m[32m0.06951[0m[0m | time: 140.328s
[2K
| Adam | epoch: 009 | loss: 0.06951 - acc: 0.9723 -- iter: 416/696
[A[ATraining Step: 190  | total loss: [1m[32m0.08464[0m[0m | time: 151.247s
[2K
| Adam | epoch: 009 | loss: 0.08464 - acc: 0.9657 -- iter: 448/696
[A[ATraining Step: 191  | total loss: [1m[32m0.08077[0m[0m | time: 162.498s
[2K
| Adam | epoch: 009 | loss: 0.08077 - acc: 0.9660 -- iter: 480/696
[A[ATraining Step: 192  | total loss: [1m[32m0.07551[0m[0m | time: 173.552s
[2K
| Adam | epoch: 009 | loss: 0.07551 - acc: 0.9694 -- iter: 512/696
[A[ATraining Step: 193  | total loss: [1m[32m0.07220[0m[0m | time: 184.891s
[2K
| Adam | epoch: 009 | loss: 0.07220 - acc: 0.9724 -- iter: 544/696
[A[ATraining Step: 194  | total loss: [1m[32m0.06611[0m[0m | time: 196.027s
[2K
| Adam | epoch: 009 | loss: 0.06611 - acc: 0.9752 -- iter: 576/696
[A[ATraining Step: 195  | total loss: [1m[32m0.08237[0m[0m | time: 207.264s
[2K
| Adam | epoch: 009 | loss: 0.08237 - acc: 0.9714 -- iter: 608/696
[A[ATraining Step: 196  | total loss: [1m[32m0.07895[0m[0m | time: 218.482s
[2K
| Adam | epoch: 009 | loss: 0.07895 - acc: 0.9712 -- iter: 640/696
[A[ATraining Step: 197  | total loss: [1m[32m0.07208[0m[0m | time: 229.245s
[2K
| Adam | epoch: 009 | loss: 0.07208 - acc: 0.9740 -- iter: 672/696
[A[ATraining Step: 198  | total loss: [1m[32m0.09713[0m[0m | time: 254.931s
[2K
| Adam | epoch: 009 | loss: 0.09713 - acc: 0.9735 | val_loss: 1.08875 - val_acc: 0.7385 -- iter: 696/696
--
Training Step: 199  | total loss: [1m[32m0.08811[0m[0m | time: 11.329s
[2K
| Adam | epoch: 010 | loss: 0.08811 - acc: 0.9762 -- iter: 032/696
[A[ATraining Step: 200  | total loss: [1m[32m0.07987[0m[0m | time: 36.906s
[2K
| Adam | epoch: 010 | loss: 0.07987 - acc: 0.9786 | val_loss: 0.89491 - val_acc: 0.7752 -- iter: 064/696
--
Training Step: 201  | total loss: [1m[32m0.08071[0m[0m | time: 48.169s
[2K
| Adam | epoch: 010 | loss: 0.08071 - acc: 0.9776 -- iter: 096/696
[A[ATraining Step: 202  | total loss: [1m[32m0.10044[0m[0m | time: 59.428s
[2K
| Adam | epoch: 010 | loss: 0.10044 - acc: 0.9704 -- iter: 128/696
[A[ATraining Step: 203  | total loss: [1m[32m0.09174[0m[0m | time: 71.098s
[2K
| Adam | epoch: 010 | loss: 0.09174 - acc: 0.9734 -- iter: 160/696
[A[ATraining Step: 204  | total loss: [1m[32m0.10042[0m[0m | time: 82.312s
[2K
| Adam | epoch: 010 | loss: 0.10042 - acc: 0.9698 -- iter: 192/696
[A[ATraining Step: 205  | total loss: [1m[32m0.09809[0m[0m | time: 93.386s
[2K
| Adam | epoch: 010 | loss: 0.09809 - acc: 0.9697 -- iter: 224/696
[A[ATraining Step: 206  | total loss: [1m[32m0.10855[0m[0m | time: 102.020s
[2K
| Adam | epoch: 010 | loss: 0.10855 - acc: 0.9696 -- iter: 256/696
[A[ATraining Step: 207  | total loss: [1m[32m0.10872[0m[0m | time: 111.133s
[2K
| Adam | epoch: 010 | loss: 0.10872 - acc: 0.9685 -- iter: 288/696
[A[ATraining Step: 208  | total loss: [1m[32m0.09895[0m[0m | time: 122.295s
[2K
| Adam | epoch: 010 | loss: 0.09895 - acc: 0.9716 -- iter: 320/696
[A[ATraining Step: 209  | total loss: [1m[32m0.09132[0m[0m | time: 133.659s
[2K
| Adam | epoch: 010 | loss: 0.09132 - acc: 0.9745 -- iter: 352/696
[A[ATraining Step: 210  | total loss: [1m[32m0.08620[0m[0m | time: 145.375s
[2K
| Adam | epoch: 010 | loss: 0.08620 - acc: 0.9770 -- iter: 384/696
[A[ATraining Step: 211  | total loss: [1m[32m0.10818[0m[0m | time: 157.648s
[2K
| Adam | epoch: 010 | loss: 0.10818 - acc: 0.9668 -- iter: 416/696
[A[ATraining Step: 212  | total loss: [1m[32m0.09807[0m[0m | time: 170.085s
[2K
| Adam | epoch: 010 | loss: 0.09807 - acc: 0.9701 -- iter: 448/696
[A[ATraining Step: 213  | total loss: [1m[32m0.09031[0m[0m | time: 182.144s
[2K
| Adam | epoch: 010 | loss: 0.09031 - acc: 0.9731 -- iter: 480/696
[A[ATraining Step: 214  | total loss: [1m[32m0.08797[0m[0m | time: 194.233s
[2K
| Adam | epoch: 010 | loss: 0.08797 - acc: 0.9727 -- iter: 512/696
[A[ATraining Step: 215  | total loss: [1m[32m0.08159[0m[0m | time: 206.259s
[2K
| Adam | epoch: 010 | loss: 0.08159 - acc: 0.9754 -- iter: 544/696
[A[ATraining Step: 216  | total loss: [1m[32m0.08169[0m[0m | time: 218.370s
[2K
| Adam | epoch: 010 | loss: 0.08169 - acc: 0.9716 -- iter: 576/696
[A[ATraining Step: 217  | total loss: [1m[32m0.08179[0m[0m | time: 230.477s
[2K
| Adam | epoch: 010 | loss: 0.08179 - acc: 0.9713 -- iter: 608/696
[A[ATraining Step: 218  | total loss: [1m[32m0.07567[0m[0m | time: 242.448s
[2K
| Adam | epoch: 010 | loss: 0.07567 - acc: 0.9742 -- iter: 640/696
[A[ATraining Step: 219  | total loss: [1m[32m0.08431[0m[0m | time: 251.068s
[2K
| Adam | epoch: 010 | loss: 0.08431 - acc: 0.9674 -- iter: 672/696
[A[ATraining Step: 220  | total loss: [1m[32m0.08317[0m[0m | time: 268.651s
[2K
| Adam | epoch: 010 | loss: 0.08317 - acc: 0.9675 | val_loss: 1.01841 - val_acc: 0.7248 -- iter: 696/696
--
Training Step: 221  | total loss: [1m[32m0.15944[0m[0m | time: 11.851s
[2K
| Adam | epoch: 011 | loss: 0.15944 - acc: 0.9583 -- iter: 032/696
[A[ATraining Step: 222  | total loss: [1m[32m0.15108[0m[0m | time: 23.098s
[2K
| Adam | epoch: 011 | loss: 0.15108 - acc: 0.9625 -- iter: 064/696
[A[ATraining Step: 223  | total loss: [1m[32m0.15201[0m[0m | time: 34.324s
[2K
| Adam | epoch: 011 | loss: 0.15201 - acc: 0.9600 -- iter: 096/696
[A[ATraining Step: 224  | total loss: [1m[32m0.14224[0m[0m | time: 45.958s
[2K
| Adam | epoch: 011 | loss: 0.14224 - acc: 0.9640 -- iter: 128/696
[A[ATraining Step: 225  | total loss: [1m[32m0.13393[0m[0m | time: 57.232s
[2K
| Adam | epoch: 011 | loss: 0.13393 - acc: 0.9644 -- iter: 160/696
[A[ATraining Step: 226  | total loss: [1m[32m0.15158[0m[0m | time: 68.945s
[2K
| Adam | epoch: 011 | loss: 0.15158 - acc: 0.9555 -- iter: 192/696
[A[ATraining Step: 227  | total loss: [1m[32m0.14042[0m[0m | time: 80.720s
[2K
| Adam | epoch: 011 | loss: 0.14042 - acc: 0.9600 -- iter: 224/696
[A[ATraining Step: 228  | total loss: [1m[32m0.14494[0m[0m | time: 92.092s
[2K
| Adam | epoch: 011 | loss: 0.14494 - acc: 0.9608 -- iter: 256/696
[A[ATraining Step: 229  | total loss: [1m[32m0.13727[0m[0m | time: 101.074s
[2K
| Adam | epoch: 011 | loss: 0.13727 - acc: 0.9616 -- iter: 288/696
[A[ATraining Step: 230  | total loss: [1m[32m0.14714[0m[0m | time: 110.069s
[2K
| Adam | epoch: 011 | loss: 0.14714 - acc: 0.9530 -- iter: 320/696
[A[ATraining Step: 231  | total loss: [1m[32m0.13886[0m[0m | time: 121.430s
[2K
| Adam | epoch: 011 | loss: 0.13886 - acc: 0.9577 -- iter: 352/696
[A[ATraining Step: 232  | total loss: [1m[32m0.13295[0m[0m | time: 132.790s
[2K
| Adam | epoch: 011 | loss: 0.13295 - acc: 0.9588 -- iter: 384/696
[A[ATraining Step: 233  | total loss: [1m[32m0.12382[0m[0m | time: 144.217s
[2K
| Adam | epoch: 011 | loss: 0.12382 - acc: 0.9629 -- iter: 416/696
[A[ATraining Step: 234  | total loss: [1m[32m0.11374[0m[0m | time: 156.012s
[2K
| Adam | epoch: 011 | loss: 0.11374 - acc: 0.9666 -- iter: 448/696
[A[ATraining Step: 235  | total loss: [1m[32m0.10687[0m[0m | time: 167.331s
[2K
| Adam | epoch: 011 | loss: 0.10687 - acc: 0.9668 -- iter: 480/696
[A[ATraining Step: 236  | total loss: [1m[32m0.09704[0m[0m | time: 178.569s
[2K
| Adam | epoch: 011 | loss: 0.09704 - acc: 0.9701 -- iter: 512/696
[A[ATraining Step: 237  | total loss: [1m[32m0.09428[0m[0m | time: 190.414s
[2K
| Adam | epoch: 011 | loss: 0.09428 - acc: 0.9700 -- iter: 544/696
[A[ATraining Step: 238  | total loss: [1m[32m0.08757[0m[0m | time: 201.721s
[2K
| Adam | epoch: 011 | loss: 0.08757 - acc: 0.9730 -- iter: 576/696
[A[ATraining Step: 239  | total loss: [1m[32m0.08899[0m[0m | time: 214.135s
[2K
| Adam | epoch: 011 | loss: 0.08899 - acc: 0.9726 -- iter: 608/696
[A[ATraining Step: 240  | total loss: [1m[32m0.08387[0m[0m | time: 226.147s
[2K
| Adam | epoch: 011 | loss: 0.08387 - acc: 0.9753 -- iter: 640/696
[A[ATraining Step: 241  | total loss: [1m[32m0.08846[0m[0m | time: 238.433s
[2K
| Adam | epoch: 011 | loss: 0.08846 - acc: 0.9715 -- iter: 672/696
[A[ATraining Step: 242  | total loss: [1m[32m0.10544[0m[0m | time: 266.307s
[2K
| Adam | epoch: 011 | loss: 0.10544 - acc: 0.9619 | val_loss: 1.25242 - val_acc: 0.6606 -- iter: 696/696
--
Training Step: 243  | total loss: [1m[32m0.09824[0m[0m | time: 8.828s
[2K
| Adam | epoch: 012 | loss: 0.09824 - acc: 0.9626 -- iter: 032/696
[A[ATraining Step: 244  | total loss: [1m[32m0.10303[0m[0m | time: 17.006s
[2K
| Adam | epoch: 012 | loss: 0.10303 - acc: 0.9632 -- iter: 064/696
[A[ATraining Step: 245  | total loss: [1m[32m0.09686[0m[0m | time: 28.378s
[2K
| Adam | epoch: 012 | loss: 0.09686 - acc: 0.9637 -- iter: 096/696
[A[ATraining Step: 246  | total loss: [1m[32m0.10912[0m[0m | time: 39.980s
[2K
| Adam | epoch: 012 | loss: 0.10912 - acc: 0.9549 -- iter: 128/696
[A[ATraining Step: 247  | total loss: [1m[32m0.10699[0m[0m | time: 51.416s
[2K
| Adam | epoch: 012 | loss: 0.10699 - acc: 0.9531 -- iter: 160/696
[A[ATraining Step: 248  | total loss: [1m[32m0.09951[0m[0m | time: 63.010s
[2K
| Adam | epoch: 012 | loss: 0.09951 - acc: 0.9578 -- iter: 192/696
[A[ATraining Step: 249  | total loss: [1m[32m0.10029[0m[0m | time: 74.571s
[2K
| Adam | epoch: 012 | loss: 0.10029 - acc: 0.9558 -- iter: 224/696
[A[ATraining Step: 250  | total loss: [1m[32m0.09833[0m[0m | time: 85.720s
[2K
| Adam | epoch: 012 | loss: 0.09833 - acc: 0.9571 -- iter: 256/696
[A[ATraining Step: 251  | total loss: [1m[32m0.10093[0m[0m | time: 97.202s
[2K
| Adam | epoch: 012 | loss: 0.10093 - acc: 0.9551 -- iter: 288/696
[A[ATraining Step: 252  | total loss: [1m[32m0.10714[0m[0m | time: 106.044s
[2K
| Adam | epoch: 012 | loss: 0.10714 - acc: 0.9565 -- iter: 320/696
[A[ATraining Step: 253  | total loss: [1m[32m0.13753[0m[0m | time: 115.303s
[2K
| Adam | epoch: 012 | loss: 0.13753 - acc: 0.9567 -- iter: 352/696
[A[ATraining Step: 254  | total loss: [1m[32m0.14813[0m[0m | time: 126.343s
[2K
| Adam | epoch: 012 | loss: 0.14813 - acc: 0.9568 -- iter: 384/696
[A[ATraining Step: 255  | total loss: [1m[32m0.13921[0m[0m | time: 137.586s
[2K
| Adam | epoch: 012 | loss: 0.13921 - acc: 0.9580 -- iter: 416/696
[A[ATraining Step: 256  | total loss: [1m[32m0.13071[0m[0m | time: 149.049s
[2K
| Adam | epoch: 012 | loss: 0.13071 - acc: 0.9591 -- iter: 448/696
[A[ATraining Step: 257  | total loss: [1m[32m0.12058[0m[0m | time: 160.343s
[2K
| Adam | epoch: 012 | loss: 0.12058 - acc: 0.9632 -- iter: 480/696
[A[ATraining Step: 258  | total loss: [1m[32m0.11396[0m[0m | time: 172.079s
[2K
| Adam | epoch: 012 | loss: 0.11396 - acc: 0.9637 -- iter: 512/696
[A[ATraining Step: 259  | total loss: [1m[32m0.10869[0m[0m | time: 183.383s
[2K
| Adam | epoch: 012 | loss: 0.10869 - acc: 0.9674 -- iter: 544/696
[A[ATraining Step: 260  | total loss: [1m[32m0.10607[0m[0m | time: 195.087s
[2K
| Adam | epoch: 012 | loss: 0.10607 - acc: 0.9706 -- iter: 576/696
[A[ATraining Step: 261  | total loss: [1m[32m0.10448[0m[0m | time: 206.438s
[2K
| Adam | epoch: 012 | loss: 0.10448 - acc: 0.9673 -- iter: 608/696
[A[ATraining Step: 262  | total loss: [1m[32m0.10173[0m[0m | time: 218.147s
[2K
| Adam | epoch: 012 | loss: 0.10173 - acc: 0.9675 -- iter: 640/696
[A[ATraining Step: 263  | total loss: [1m[32m0.11006[0m[0m | time: 229.476s
[2K
| Adam | epoch: 012 | loss: 0.11006 - acc: 0.9645 -- iter: 672/696
[A[ATraining Step: 264  | total loss: [1m[32m0.10644[0m[0m | time: 255.189s
[2K
| Adam | epoch: 012 | loss: 0.10644 - acc: 0.9649 | val_loss: 2.20924 - val_acc: 0.5321 -- iter: 696/696
--
Training Step: 265  | total loss: [1m[32m0.10714[0m[0m | time: 11.226s
[2K
| Adam | epoch: 013 | loss: 0.10714 - acc: 0.9622 -- iter: 032/696
[A[ATraining Step: 266  | total loss: [1m[32m0.10393[0m[0m | time: 22.815s
[2K
| Adam | epoch: 013 | loss: 0.10393 - acc: 0.9628 -- iter: 064/696
[A[ATraining Step: 267  | total loss: [1m[32m0.13022[0m[0m | time: 34.482s
[2K
| Adam | epoch: 013 | loss: 0.13022 - acc: 0.9603 -- iter: 096/696
[A[ATraining Step: 268  | total loss: [1m[32m0.12116[0m[0m | time: 45.839s
[2K
| Adam | epoch: 013 | loss: 0.12116 - acc: 0.9643 -- iter: 128/696
[A[ATraining Step: 269  | total loss: [1m[32m0.11075[0m[0m | time: 57.479s
[2K
| Adam | epoch: 013 | loss: 0.11075 - acc: 0.9678 -- iter: 160/696
[A[ATraining Step: 270  | total loss: [1m[32m0.11446[0m[0m | time: 69.186s
[2K
| Adam | epoch: 013 | loss: 0.11446 - acc: 0.9679 -- iter: 192/696
[A[ATraining Step: 271  | total loss: [1m[32m0.11027[0m[0m | time: 80.603s
[2K
| Adam | epoch: 013 | loss: 0.11027 - acc: 0.9680 -- iter: 224/696
[A[ATraining Step: 272  | total loss: [1m[32m0.10767[0m[0m | time: 92.239s
[2K
| Adam | epoch: 013 | loss: 0.10767 - acc: 0.9681 -- iter: 256/696
[A[ATraining Step: 273  | total loss: [1m[32m0.11513[0m[0m | time: 103.638s
[2K
| Adam | epoch: 013 | loss: 0.11513 - acc: 0.9619 -- iter: 288/696
[A[ATraining Step: 274  | total loss: [1m[32m0.10897[0m[0m | time: 115.331s
[2K
| Adam | epoch: 013 | loss: 0.10897 - acc: 0.9626 -- iter: 320/696
[A[ATraining Step: 275  | total loss: [1m[32m0.10384[0m[0m | time: 124.458s
[2K
| Adam | epoch: 013 | loss: 0.10384 - acc: 0.9663 -- iter: 352/696
[A[ATraining Step: 276  | total loss: [1m[32m0.10667[0m[0m | time: 133.679s
[2K
| Adam | epoch: 013 | loss: 0.10667 - acc: 0.9655 -- iter: 384/696
[A[ATraining Step: 277  | total loss: [1m[32m0.09854[0m[0m | time: 145.196s
[2K
| Adam | epoch: 013 | loss: 0.09854 - acc: 0.9690 -- iter: 416/696
[A[ATraining Step: 278  | total loss: [1m[32m0.08976[0m[0m | time: 156.811s
[2K
| Adam | epoch: 013 | loss: 0.08976 - acc: 0.9721 -- iter: 448/696
[A[ATraining Step: 279  | total loss: [1m[32m0.08567[0m[0m | time: 168.304s
[2K
| Adam | epoch: 013 | loss: 0.08567 - acc: 0.9749 -- iter: 480/696
[A[ATraining Step: 280  | total loss: [1m[32m0.08806[0m[0m | time: 179.557s
[2K
| Adam | epoch: 013 | loss: 0.08806 - acc: 0.9711 -- iter: 512/696
[A[ATraining Step: 281  | total loss: [1m[32m0.08438[0m[0m | time: 191.070s
[2K
| Adam | epoch: 013 | loss: 0.08438 - acc: 0.9740 -- iter: 544/696
[A[ATraining Step: 282  | total loss: [1m[32m0.08304[0m[0m | time: 202.578s
[2K
| Adam | epoch: 013 | loss: 0.08304 - acc: 0.9735 -- iter: 576/696
[A[ATraining Step: 283  | total loss: [1m[32m0.07781[0m[0m | time: 214.071s
[2K
| Adam | epoch: 013 | loss: 0.07781 - acc: 0.9761 -- iter: 608/696
[A[ATraining Step: 284  | total loss: [1m[32m0.08949[0m[0m | time: 225.403s
[2K
| Adam | epoch: 013 | loss: 0.08949 - acc: 0.9660 -- iter: 640/696
[A[ATraining Step: 285  | total loss: [1m[32m0.08276[0m[0m | time: 236.576s
[2K
| Adam | epoch: 013 | loss: 0.08276 - acc: 0.9694 -- iter: 672/696
[A[ATraining Step: 286  | total loss: [1m[32m0.07770[0m[0m | time: 262.841s
[2K
| Adam | epoch: 013 | loss: 0.07770 - acc: 0.9725 | val_loss: 0.42874 - val_acc: 0.8532 -- iter: 696/696
--
Training Step: 287  | total loss: [1m[32m0.07608[0m[0m | time: 12.146s
[2K
| Adam | epoch: 014 | loss: 0.07608 - acc: 0.9721 -- iter: 032/696
[A[ATraining Step: 288  | total loss: [1m[32m0.07054[0m[0m | time: 30.427s
[2K
| Adam | epoch: 014 | loss: 0.07054 - acc: 0.9749 -- iter: 064/696
[A[ATraining Step: 289  | total loss: [1m[32m0.06675[0m[0m | time: 46.946s
[2K
| Adam | epoch: 014 | loss: 0.06675 - acc: 0.9774 -- iter: 096/696
[A[ATraining Step: 290  | total loss: [1m[32m0.09259[0m[0m | time: 77.254s
[2K
| Adam | epoch: 014 | loss: 0.09259 - acc: 0.9734 -- iter: 128/696
[A[ATraining Step: 291  | total loss: [1m[32m0.12631[0m[0m | time: 100.184s
[2K
| Adam | epoch: 014 | loss: 0.12631 - acc: 0.9605 -- iter: 160/696
[A[ATraining Step: 292  | total loss: [1m[32m0.11484[0m[0m | time: 118.554s
[2K
| Adam | epoch: 014 | loss: 0.11484 - acc: 0.9644 -- iter: 192/696
[A[ATraining Step: 293  | total loss: [1m[32m0.10686[0m[0m | time: 134.184s
[2K
| Adam | epoch: 014 | loss: 0.10686 - acc: 0.9680 -- iter: 224/696
[A[ATraining Step: 294  | total loss: [1m[32m0.09686[0m[0m | time: 147.229s
[2K
| Adam | epoch: 014 | loss: 0.09686 - acc: 0.9712 -- iter: 256/696
[A[ATraining Step: 295  | total loss: [1m[32m0.08863[0m[0m | time: 160.266s
[2K
| Adam | epoch: 014 | loss: 0.08863 - acc: 0.9741 -- iter: 288/696
[A[ATraining Step: 296  | total loss: [1m[32m0.08062[0m[0m | time: 172.768s
[2K
| Adam | epoch: 014 | loss: 0.08062 - acc: 0.9766 -- iter: 320/696
[A[ATraining Step: 297  | total loss: [1m[32m0.07616[0m[0m | time: 185.252s
[2K
| Adam | epoch: 014 | loss: 0.07616 - acc: 0.9790 -- iter: 352/696
[A[ATraining Step: 298  | total loss: [1m[32m0.07370[0m[0m | time: 195.361s
[2K
| Adam | epoch: 014 | loss: 0.07370 - acc: 0.9811 -- iter: 384/696
[A[ATraining Step: 299  | total loss: [1m[32m0.06904[0m[0m | time: 233.906s
[2K
| Adam | epoch: 014 | loss: 0.06904 - acc: 0.9830 -- iter: 416/696
[A[ATraining Step: 300  | total loss: [1m[32m0.06358[0m[0m | time: 261.295s
[2K
| Adam | epoch: 014 | loss: 0.06358 - acc: 0.9847 -- iter: 448/696
[A[ATraining Step: 301  | total loss: [1m[32m0.09243[0m[0m | time: 280.282s
[2K
| Adam | epoch: 014 | loss: 0.09243 - acc: 0.9831 -- iter: 480/696
[A[ATraining Step: 302  | total loss: [1m[32m0.08606[0m[0m | time: 297.941s
[2K
| Adam | epoch: 014 | loss: 0.08606 - acc: 0.9848 -- iter: 512/696
[A[ATraining Step: 303  | total loss: [1m[32m0.07983[0m[0m | time: 316.673s
[2K
| Adam | epoch: 014 | loss: 0.07983 - acc: 0.9863 -- iter: 544/696
[A[ATraining Step: 304  | total loss: [1m[32m0.08909[0m[0m | time: 339.405s
[2K
| Adam | epoch: 014 | loss: 0.08909 - acc: 0.9814 -- iter: 576/696
[A[ATraining Step: 305  | total loss: [1m[32m0.08970[0m[0m | time: 351.391s
[2K
| Adam | epoch: 014 | loss: 0.08970 - acc: 0.9802 -- iter: 608/696
[A[ATraining Step: 306  | total loss: [1m[32m0.08898[0m[0m | time: 363.574s
[2K
| Adam | epoch: 014 | loss: 0.08898 - acc: 0.9790 -- iter: 640/696
[A[ATraining Step: 307  | total loss: [1m[32m0.08445[0m[0m | time: 375.618s
[2K
| Adam | epoch: 014 | loss: 0.08445 - acc: 0.9780 -- iter: 672/696
[A[ATraining Step: 308  | total loss: [1m[32m0.07655[0m[0m | time: 425.655s
[2K
| Adam | epoch: 014 | loss: 0.07655 - acc: 0.9802 | val_loss: 1.29866 - val_acc: 0.7569 -- iter: 696/696
--
Training Step: 309  | total loss: [1m[32m0.07003[0m[0m | time: 15.076s
[2K
| Adam | epoch: 015 | loss: 0.07003 - acc: 0.9822 -- iter: 032/696
[A[ATraining Step: 310  | total loss: [1m[32m0.07526[0m[0m | time: 27.179s
[2K
| Adam | epoch: 015 | loss: 0.07526 - acc: 0.9808 -- iter: 064/696
[A[ATraining Step: 311  | total loss: [1m[32m0.07201[0m[0m | time: 42.210s
[2K
| Adam | epoch: 015 | loss: 0.07201 - acc: 0.9796 -- iter: 096/696
[A[ATraining Step: 312  | total loss: [1m[32m0.08562[0m[0m | time: 68.290s
[2K
| Adam | epoch: 015 | loss: 0.08562 - acc: 0.9754 -- iter: 128/696
[A[ATraining Step: 313  | total loss: [1m[32m0.08570[0m[0m | time: 152.382s
[2K
| Adam | epoch: 015 | loss: 0.08570 - acc: 0.9747 -- iter: 160/696
[A[ATraining Step: 314  | total loss: [1m[32m0.08348[0m[0m | time: 217.389s
[2K
| Adam | epoch: 015 | loss: 0.08348 - acc: 0.9741 -- iter: 192/696
[A[ATraining Step: 315  | total loss: [1m[32m0.07648[0m[0m | time: 238.975s
[2K
| Adam | epoch: 015 | loss: 0.07648 - acc: 0.9767 -- iter: 224/696
[A[ATraining Step: 316  | total loss: [1m[32m0.06992[0m[0m | time: 255.520s
[2K
| Adam | epoch: 015 | loss: 0.06992 - acc: 0.9791 -- iter: 256/696
[A[ATraining Step: 317  | total loss: [1m[32m0.06810[0m[0m | time: 268.034s
[2K
| Adam | epoch: 015 | loss: 0.06810 - acc: 0.9780 -- iter: 288/696
[A[ATraining Step: 318  | total loss: [1m[32m0.06245[0m[0m | time: 280.105s
[2K
| Adam | epoch: 015 | loss: 0.06245 - acc: 0.9802 -- iter: 320/696
[A[ATraining Step: 319  | total loss: [1m[32m0.06588[0m[0m | time: 309.733s
[2K
| Adam | epoch: 015 | loss: 0.06588 - acc: 0.9760 -- iter: 352/696
[A[ATraining Step: 320  | total loss: [1m[32m0.06893[0m[0m | time: 348.765s
[2K
| Adam | epoch: 015 | loss: 0.06893 - acc: 0.9752 -- iter: 384/696
[A[ATraining Step: 321  | total loss: [1m[32m0.06274[0m[0m | time: 361.359s
[2K
| Adam | epoch: 015 | loss: 0.06274 - acc: 0.9777 -- iter: 416/696
[A[ATraining Step: 322  | total loss: [1m[32m0.05831[0m[0m | time: 396.616s
[2K
| Adam | epoch: 015 | loss: 0.05831 - acc: 0.9799 -- iter: 448/696
[A[ATraining Step: 323  | total loss: [1m[32m0.05332[0m[0m | time: 452.109s
[2K
| Adam | epoch: 015 | loss: 0.05332 - acc: 0.9819 -- iter: 480/696
[A[ATraining Step: 324  | total loss: [1m[32m0.06017[0m[0m | time: 465.654s
[2K
| Adam | epoch: 015 | loss: 0.06017 - acc: 0.9775 -- iter: 512/696
[A[ATraining Step: 325  | total loss: [1m[32m0.05762[0m[0m | time: 478.346s
[2K
| Adam | epoch: 015 | loss: 0.05762 - acc: 0.9797 -- iter: 544/696
[A[ATraining Step: 326  | total loss: [1m[32m0.05605[0m[0m | time: 501.978s
[2K
| Adam | epoch: 015 | loss: 0.05605 - acc: 0.9786 -- iter: 576/696
[A[ATraining Step: 327  | total loss: [1m[32m0.05382[0m[0m | time: 519.144s
[2K
| Adam | epoch: 015 | loss: 0.05382 - acc: 0.9777 -- iter: 608/696
[A[ATraining Step: 328  | total loss: [1m[32m0.04947[0m[0m | time: 536.839s
[2K
| Adam | epoch: 015 | loss: 0.04947 - acc: 0.9799 -- iter: 640/696
[A[ATraining Step: 329  | total loss: [1m[32m0.04568[0m[0m | time: 553.367s
[2K
| Adam | epoch: 015 | loss: 0.04568 - acc: 0.9819 -- iter: 672/696
[A[ATraining Step: 330  | total loss: [1m[32m0.04183[0m[0m | time: 598.152s
[2K
| Adam | epoch: 015 | loss: 0.04183 - acc: 0.9837 | val_loss: 0.77743 - val_acc: 0.7706 -- iter: 696/696
--
Validation AUC:0.9152984760461396
Validation AUPRC:0.9023719999979029
Test AUC:0.927020202020202
Test AUPRC:0.9148082577698986
BestTestF1Score	0.87	0.73	0.86	0.81	0.94	101	23	87	7	0.94
BestTestMCCScore	0.87	0.73	0.86	0.81	0.94	101	23	87	7	0.94
BestTestAccuracyScore	0.85	0.69	0.84	0.81	0.89	96	22	88	12	0.97
BestValidationF1Score	0.86	0.71	0.85	0.83	0.89	99	20	87	12	0.94
BestValidationMCC	0.86	0.71	0.85	0.83	0.89	99	20	87	12	0.94
BestValidationAccuracy	0.86	0.71	0.85	0.85	0.86	96	17	90	15	0.97
TestPredictions (Threshold:0.94)
CHEMBL320786,FP,INACT,0.9900000095367432	CHEMBL296720,TP,ACT,1.0	CHEMBL114975,TN,INACT,0.7300000190734863	CHEMBL127357,TP,ACT,1.0	CHEMBL152986,TN,INACT,0.05000000074505806	CHEMBL361939,TP,ACT,1.0	CHEMBL295698,TN,INACT,0.4300000071525574	CHEMBL483939,TP,ACT,1.0	CHEMBL1643796,FN,ACT,0.4099999964237213	CHEMBL287421,TP,ACT,1.0	CHEMBL2381764,TN,INACT,0.9300000071525574	CHEMBL47688,TN,INACT,0.0	CHEMBL328812,TN,INACT,0.07000000029802322	CHEMBL394073,TN,INACT,0.20000000298023224	CHEMBL3322476,TN,INACT,0.9200000166893005	CHEMBL9219,TN,INACT,0.019999999552965164	CHEMBL262690,FP,INACT,0.9700000286102295	CHEMBL520481,TP,ACT,1.0	CHEMBL82146,FN,ACT,0.8700000047683716	CHEMBL541164,TN,INACT,0.7200000286102295	CHEMBL120165,TP,ACT,1.0	CHEMBL3335473,TP,ACT,1.0	CHEMBL95872,TP,ACT,1.0	CHEMBL3314885,TN,INACT,0.41999998688697815	CHEMBL2113700,FP,INACT,1.0	CHEMBL192662,TP,ACT,0.9900000095367432	CHEMBL99041,TP,ACT,0.9800000190734863	CHEMBL142641,TN,INACT,0.7699999809265137	CHEMBL2063252,FP,INACT,0.9900000095367432	CHEMBL236002,TN,INACT,0.0	CHEMBL261008,TP,ACT,1.0	CHEMBL3354619,TP,ACT,1.0	CHEMBL95867,TP,ACT,0.9900000095367432	CHEMBL175303,FN,ACT,0.20000000298023224	CHEMBL235797,TN,INACT,0.8899999856948853	CHEMBL408336,TN,INACT,0.0	CHEMBL326856,TP,ACT,1.0	CHEMBL393919,TN,INACT,0.0	CHEMBL2381771,TN,INACT,0.47999998927116394	CHEMBL114826,TP,ACT,1.0	CHEMBL235382,TN,INACT,0.0	CHEMBL83366,FN,ACT,0.6299999952316284	CHEMBL208083,TP,ACT,1.0	CHEMBL427844,TP,ACT,1.0	CHEMBL207203,TP,ACT,1.0	CHEMBL2113346,TP,ACT,0.949999988079071	CHEMBL3142980,TN,INACT,0.019999999552965164	CHEMBL1643778,TP,ACT,0.9700000286102295	CHEMBL261501,TP,ACT,1.0	CHEMBL325523,TP,ACT,1.0	CHEMBL17640,TP,ACT,1.0	CHEMBL393557,TN,INACT,0.0	CHEMBL261811,TP,ACT,1.0	CHEMBL236861,TN,INACT,0.05000000074505806	CHEMBL378929,TP,ACT,1.0	CHEMBL415239,TP,ACT,1.0	CHEMBL116837,TP,ACT,1.0	CHEMBL237719,FP,INACT,0.9900000095367432	CHEMBL3218122,TN,INACT,0.0	CHEMBL418000,TP,ACT,0.9800000190734863	CHEMBL120278,FP,INACT,1.0	CHEMBL333236,TP,ACT,1.0	CHEMBL406649,TP,ACT,0.9900000095367432	CHEMBL339269,TP,ACT,1.0	CHEMBL293478,TN,INACT,0.8700000047683716	CHEMBL120250,TP,ACT,1.0	CHEMBL108979,TP,ACT,0.9900000095367432	CHEMBL2113702,FP,INACT,1.0	CHEMBL3586361,TN,INACT,0.9200000166893005	CHEMBL3410297,TN,INACT,0.12999999523162842	CHEMBL274415,TP,ACT,1.0	CHEMBL1644003,TP,ACT,1.0	CHEMBL210457,FP,INACT,0.9900000095367432	CHEMBL308087,TN,INACT,0.10000000149011612	CHEMBL291789,TP,ACT,1.0	CHEMBL25657,TP,ACT,1.0	CHEMBL575027,TN,INACT,0.07999999821186066	CHEMBL486688,TN,INACT,0.5699999928474426	CHEMBL2113689,FP,INACT,0.9900000095367432	CHEMBL1643789,TP,ACT,0.9900000095367432	CHEMBL1090461,TN,INACT,0.6000000238418579	CHEMBL416395,TP,ACT,1.0	CHEMBL331833,TP,ACT,0.9900000095367432	CHEMBL252505,TN,INACT,0.009999999776482582	CHEMBL59547,FN,ACT,0.9200000166893005	CHEMBL113944,TP,ACT,1.0	CHEMBL484130,TP,ACT,1.0	CHEMBL120370,TN,INACT,0.6299999952316284	CHEMBL42129,TN,INACT,0.019999999552965164	CHEMBL27995,TN,INACT,0.009999999776482582	CHEMBL82896,TP,ACT,1.0	CHEMBL1643787,TP,ACT,0.9599999785423279	CHEMBL428480,TN,INACT,0.019999999552965164	CHEMBL126472,FP,INACT,0.9900000095367432	CHEMBL68512,TP,ACT,1.0	CHEMBL115241,TP,ACT,1.0	CHEMBL208260,TP,ACT,1.0	CHEMBL372588,TP,ACT,0.9900000095367432	CHEMBL117036,FP,INACT,1.0	CHEMBL3354614,TP,ACT,1.0	CHEMBL338334,TP,ACT,1.0	CHEMBL374336,TN,INACT,0.18000000715255737	CHEMBL3335482,TP,ACT,1.0	CHEMBL235616,TN,INACT,0.07999999821186066	CHEMBL117399,TP,ACT,0.9599999785423279	CHEMBL237693,TN,INACT,0.019999999552965164	CHEMBL2179773,FP,INACT,0.9700000286102295	CHEMBL1159698,TN,INACT,0.44999998807907104	CHEMBL3423408,TN,INACT,0.05999999865889549	CHEMBL423239,TN,INACT,0.49000000953674316	CHEMBL287068,TP,ACT,1.0	CHEMBL2107786,TP,ACT,1.0	CHEMBL31334,TP,ACT,0.9900000095367432	CHEMBL434063,TN,INACT,0.2199999988079071	CHEMBL103404,TN,INACT,0.20000000298023224	CHEMBL396341,TN,INACT,0.019999999552965164	CHEMBL338546,TP,ACT,1.0	CHEMBL419040,TP,ACT,0.9599999785423279	CHEMBL283923,TP,ACT,1.0	CHEMBL126373,TP,ACT,1.0	CHEMBL237290,TN,INACT,0.019999999552965164	CHEMBL3403728,FP,INACT,1.0	CHEMBL2063250,FP,INACT,0.9800000190734863	CHEMBL122123,TP,ACT,0.9900000095367432	CHEMBL252231,FP,INACT,0.9900000095367432	CHEMBL103950,FP,INACT,0.9900000095367432	CHEMBL3354617,TP,ACT,1.0	CHEMBL392094,TN,INACT,0.8799999952316284	CHEMBL808,TN,INACT,0.9200000166893005	CHEMBL184947,TP,ACT,1.0	CHEMBL235162,TN,INACT,0.05000000074505806	CHEMBL262869,TP,ACT,1.0	CHEMBL280065,TN,INACT,0.05999999865889549	CHEMBL3403741,TN,INACT,0.9100000262260437	CHEMBL236626,TN,INACT,0.8100000023841858	CHEMBL3314942,TN,INACT,0.8100000023841858	CHEMBL299886,TP,ACT,1.0	CHEMBL362543,TP,ACT,1.0	CHEMBL438297,TN,INACT,0.17000000178813934	CHEMBL237069,TN,INACT,0.5699999928474426	CHEMBL3410309,TN,INACT,0.10999999940395355	CHEMBL72172,TN,INACT,0.10999999940395355	CHEMBL83450,TN,INACT,0.6600000262260437	CHEMBL127212,TP,ACT,1.0	CHEMBL426559,TP,ACT,1.0	CHEMBL121304,TP,ACT,1.0	CHEMBL237291,TN,INACT,0.03999999910593033	CHEMBL222677,TN,INACT,0.05999999865889549	CHEMBL3403732,TN,INACT,0.03999999910593033	CHEMBL30377,TP,ACT,1.0	CHEMBL331218,TP,ACT,1.0	CHEMBL379659,TP,ACT,1.0	CHEMBL517108,FP,INACT,1.0	CHEMBL309835,TP,ACT,0.9900000095367432	CHEMBL182367,TP,ACT,1.0	CHEMBL365026,TN,INACT,0.009999999776482582	CHEMBL33621,TP,ACT,1.0	CHEMBL412070,TP,ACT,1.0	CHEMBL117242,TP,ACT,0.9900000095367432	CHEMBL209245,TP,ACT,0.9599999785423279	CHEMBL8561,TN,INACT,0.029999999329447746	CHEMBL332964,TP,ACT,1.0	CHEMBL324965,TP,ACT,0.9800000190734863	CHEMBL278932,TN,INACT,0.7900000214576721	CHEMBL208319,TP,ACT,0.9700000286102295	CHEMBL379491,TP,ACT,1.0	CHEMBL3326602,TP,ACT,1.0	CHEMBL3326905,TN,INACT,0.5600000023841858	CHEMBL236447,TN,INACT,0.029999999329447746	CHEMBL181035,TN,INACT,0.8600000143051147	CHEMBL432602,TP,ACT,1.0	CHEMBL399000,TN,INACT,0.41999998688697815	CHEMBL566014,FP,INACT,1.0	CHEMBL446698,FP,INACT,1.0	CHEMBL393568,TN,INACT,0.6299999952316284	CHEMBL123596,FN,ACT,0.8899999856948853	CHEMBL3114143,TN,INACT,0.3700000047683716	CHEMBL236020,TN,INACT,0.3400000035762787	CHEMBL3087713,TN,INACT,0.41999998688697815	CHEMBL3350496,TN,INACT,0.0	CHEMBL409737,TP,ACT,1.0	CHEMBL235138,TN,INACT,0.009999999776482582	CHEMBL130470,TP,ACT,1.0	CHEMBL378125,TP,ACT,0.9800000190734863	CHEMBL177524,TN,INACT,0.07000000029802322	CHEMBL300681,TP,ACT,1.0	CHEMBL312697,FN,ACT,0.9200000166893005	CHEMBL9274,TN,INACT,0.9399999976158142	CHEMBL1643771,TP,ACT,1.0	CHEMBL73740,FP,INACT,0.9800000190734863	CHEMBL1916686,FP,INACT,1.0	CHEMBL313379,TN,INACT,0.009999999776482582	CHEMBL418585,TP,ACT,1.0	CHEMBL251121,FP,INACT,0.9599999785423279	CHEMBL120041,TP,ACT,1.0	CHEMBL339812,TP,ACT,0.9900000095367432	CHEMBL691,TN,INACT,0.3700000047683716	CHEMBL115536,TP,ACT,1.0	CHEMBL30832,TP,ACT,1.0	CHEMBL72166,TN,INACT,0.0	CHEMBL410179,TN,INACT,0.05999999865889549	CHEMBL444856,TP,ACT,0.9900000095367432	CHEMBL1159699,TN,INACT,0.12999999523162842	CHEMBL3114165,FP,INACT,0.9900000095367432	CHEMBL237910,TN,INACT,0.6399999856948853	CHEMBL2180219,TN,INACT,0.009999999776482582	CHEMBL396655,TN,INACT,0.009999999776482582	CHEMBL361812,TP,ACT,0.9900000095367432	CHEMBL237911,TN,INACT,0.4000000059604645	CHEMBL8825,TN,INACT,0.019999999552965164	CHEMBL238367,TN,INACT,0.009999999776482582	CHEMBL126333,TP,ACT,1.0	CHEMBL114363,TP,ACT,1.0	CHEMBL424031,TP,ACT,1.0	CHEMBL78326,TN,INACT,0.9200000166893005	CHEMBL521784,TP,ACT,1.0	CHEMBL140928,TN,INACT,0.4699999988079071	CHEMBL377072,TP,ACT,1.0	

