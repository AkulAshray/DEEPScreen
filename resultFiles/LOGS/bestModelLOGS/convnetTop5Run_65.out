CNNModel CHEMBL2973 RMSprop 0.0005 30 256 0 0.8 False True
Number of active compounds :	1245
Number of inactive compounds :	1245
---------------------------------
Run id: CNNModel_CHEMBL2973_RMSprop_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2973_RMSprop_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 1593
Validation samples: 498
--
Training Step: 1  | time: 0.788s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1593
[A[ATraining Step: 2  | total loss: [1m[32m0.62402[0m[0m | time: 1.405s
[2K
| RMSProp | epoch: 001 | loss: 0.62402 - acc: 0.3094 -- iter: 0064/1593
[A[ATraining Step: 3  | total loss: [1m[32m0.68045[0m[0m | time: 2.007s
[2K
| RMSProp | epoch: 001 | loss: 0.68045 - acc: 0.4398 -- iter: 0096/1593
[A[ATraining Step: 4  | total loss: [1m[32m0.68989[0m[0m | time: 2.630s
[2K
| RMSProp | epoch: 001 | loss: 0.68989 - acc: 0.5084 -- iter: 0128/1593
[A[ATraining Step: 5  | total loss: [1m[32m0.69209[0m[0m | time: 3.231s
[2K
| RMSProp | epoch: 001 | loss: 0.69209 - acc: 0.5242 -- iter: 0160/1593
[A[ATraining Step: 6  | total loss: [1m[32m0.69278[0m[0m | time: 3.832s
[2K
| RMSProp | epoch: 001 | loss: 0.69278 - acc: 0.5086 -- iter: 0192/1593
[A[ATraining Step: 7  | total loss: [1m[32m0.69307[0m[0m | time: 4.441s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.4660 -- iter: 0224/1593
[A[ATraining Step: 8  | total loss: [1m[32m0.69320[0m[0m | time: 5.064s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4851 -- iter: 0256/1593
[A[ATraining Step: 9  | total loss: [1m[32m0.69328[0m[0m | time: 5.703s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4434 -- iter: 0288/1593
[A[ATraining Step: 10  | total loss: [1m[32m0.69326[0m[0m | time: 6.336s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.5029 -- iter: 0320/1593
[A[ATraining Step: 11  | total loss: [1m[32m0.69313[0m[0m | time: 6.949s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5459 -- iter: 0352/1593
[A[ATraining Step: 12  | total loss: [1m[32m0.69329[0m[0m | time: 7.569s
[2K
| RMSProp | epoch: 001 | loss: 0.69329 - acc: 0.4831 -- iter: 0384/1593
[A[ATraining Step: 13  | total loss: [1m[32m0.69324[0m[0m | time: 8.182s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4635 -- iter: 0416/1593
[A[ATraining Step: 14  | total loss: [1m[32m0.69341[0m[0m | time: 8.796s
[2K
| RMSProp | epoch: 001 | loss: 0.69341 - acc: 0.4273 -- iter: 0448/1593
[A[ATraining Step: 15  | total loss: [1m[32m0.69330[0m[0m | time: 9.423s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4068 -- iter: 0480/1593
[A[ATraining Step: 16  | total loss: [1m[32m0.69331[0m[0m | time: 10.033s
[2K
| RMSProp | epoch: 001 | loss: 0.69331 - acc: 0.4183 -- iter: 0512/1593
[A[ATraining Step: 17  | total loss: [1m[32m0.69323[0m[0m | time: 10.639s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4590 -- iter: 0544/1593
[A[ATraining Step: 18  | total loss: [1m[32m0.69317[0m[0m | time: 11.257s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4732 -- iter: 0576/1593
[A[ATraining Step: 19  | total loss: [1m[32m0.69310[0m[0m | time: 11.887s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5030 -- iter: 0608/1593
[A[ATraining Step: 20  | total loss: [1m[32m0.69313[0m[0m | time: 12.505s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5020 -- iter: 0640/1593
[A[ATraining Step: 21  | total loss: [1m[32m0.69317[0m[0m | time: 13.117s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4723 -- iter: 0672/1593
[A[ATraining Step: 22  | total loss: [1m[32m0.69322[0m[0m | time: 13.716s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4712 -- iter: 0704/1593
[A[ATraining Step: 23  | total loss: [1m[32m0.69321[0m[0m | time: 14.315s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4614 -- iter: 0736/1593
[A[ATraining Step: 24  | total loss: [1m[32m0.69320[0m[0m | time: 14.945s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4635 -- iter: 0768/1593
[A[ATraining Step: 25  | total loss: [1m[32m0.69321[0m[0m | time: 15.555s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4564 -- iter: 0800/1593
[A[ATraining Step: 26  | total loss: [1m[32m0.69313[0m[0m | time: 16.193s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4762 -- iter: 0832/1593
[A[ATraining Step: 27  | total loss: [1m[32m0.69307[0m[0m | time: 16.789s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5064 -- iter: 0864/1593
[A[ATraining Step: 28  | total loss: [1m[32m0.69311[0m[0m | time: 17.417s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5048 -- iter: 0896/1593
[A[ATraining Step: 29  | total loss: [1m[32m0.69311[0m[0m | time: 18.033s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5189 -- iter: 0928/1593
[A[ATraining Step: 30  | total loss: [1m[32m0.69316[0m[0m | time: 18.637s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4996 -- iter: 0960/1593
[A[ATraining Step: 31  | total loss: [1m[32m0.69318[0m[0m | time: 19.252s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5141 -- iter: 0992/1593
[A[ATraining Step: 32  | total loss: [1m[32m0.69321[0m[0m | time: 19.856s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4969 -- iter: 1024/1593
[A[ATraining Step: 33  | total loss: [1m[32m0.69318[0m[0m | time: 20.461s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5044 -- iter: 1056/1593
[A[ATraining Step: 34  | total loss: [1m[32m0.69313[0m[0m | time: 21.073s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5236 -- iter: 1088/1593
[A[ATraining Step: 35  | total loss: [1m[32m0.69313[0m[0m | time: 21.682s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5383 -- iter: 1120/1593
[A[ATraining Step: 36  | total loss: [1m[32m0.69312[0m[0m | time: 22.311s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5240 -- iter: 1152/1593
[A[ATraining Step: 37  | total loss: [1m[32m0.69313[0m[0m | time: 22.924s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5192 -- iter: 1184/1593
[A[ATraining Step: 38  | total loss: [1m[32m0.69311[0m[0m | time: 23.523s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5277 -- iter: 1216/1593
[A[ATraining Step: 39  | total loss: [1m[32m0.69312[0m[0m | time: 24.146s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5224 -- iter: 1248/1593
[A[ATraining Step: 40  | total loss: [1m[32m0.69305[0m[0m | time: 24.745s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5533 -- iter: 1280/1593
[A[ATraining Step: 41  | total loss: [1m[32m0.69306[0m[0m | time: 25.354s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5550 -- iter: 1312/1593
[A[ATraining Step: 42  | total loss: [1m[32m0.69302[0m[0m | time: 25.968s
[2K
| RMSProp | epoch: 001 | loss: 0.69302 - acc: 0.5564 -- iter: 1344/1593
[A[ATraining Step: 43  | total loss: [1m[32m0.69309[0m[0m | time: 26.569s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5354 -- iter: 1376/1593
[A[ATraining Step: 44  | total loss: [1m[32m0.69314[0m[0m | time: 27.192s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5185 -- iter: 1408/1593
[A[ATraining Step: 45  | total loss: [1m[32m0.69306[0m[0m | time: 27.798s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5365 -- iter: 1440/1593
[A[ATraining Step: 46  | total loss: [1m[32m0.69295[0m[0m | time: 28.389s
[2K
| RMSProp | epoch: 001 | loss: 0.69295 - acc: 0.5565 -- iter: 1472/1593
[A[ATraining Step: 47  | total loss: [1m[32m0.69290[0m[0m | time: 29.017s
[2K
| RMSProp | epoch: 001 | loss: 0.69290 - acc: 0.5575 -- iter: 1504/1593
[A[ATraining Step: 48  | total loss: [1m[32m0.69297[0m[0m | time: 29.617s
[2K
| RMSProp | epoch: 001 | loss: 0.69297 - acc: 0.5432 -- iter: 1536/1593
[A[ATraining Step: 49  | total loss: [1m[32m0.69293[0m[0m | time: 30.214s
[2K
| RMSProp | epoch: 001 | loss: 0.69293 - acc: 0.5561 -- iter: 1568/1593
[A[ATraining Step: 50  | total loss: [1m[32m0.69314[0m[0m | time: 32.306s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5232 | val_loss: 0.69318 - val_acc: 0.4940 -- iter: 1593/1593
--
Training Step: 51  | total loss: [1m[32m0.69305[0m[0m | time: 0.496s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5227 -- iter: 0032/1593
[A[ATraining Step: 52  | total loss: [1m[32m0.69301[0m[0m | time: 1.094s
[2K
| RMSProp | epoch: 002 | loss: 0.69301 - acc: 0.5223 -- iter: 0064/1593
[A[ATraining Step: 53  | total loss: [1m[32m0.69306[0m[0m | time: 1.712s
[2K
| RMSProp | epoch: 002 | loss: 0.69306 - acc: 0.5098 -- iter: 0096/1593
[A[ATraining Step: 54  | total loss: [1m[32m0.69317[0m[0m | time: 2.339s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4947 -- iter: 0128/1593
[A[ATraining Step: 55  | total loss: [1m[32m0.69313[0m[0m | time: 2.957s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5044 -- iter: 0160/1593
[A[ATraining Step: 56  | total loss: [1m[32m0.69313[0m[0m | time: 3.591s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5038 -- iter: 0192/1593
[A[ATraining Step: 57  | total loss: [1m[32m0.69312[0m[0m | time: 4.222s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5033 -- iter: 0224/1593
[A[ATraining Step: 58  | total loss: [1m[32m0.69294[0m[0m | time: 4.828s
[2K
| RMSProp | epoch: 002 | loss: 0.69294 - acc: 0.5369 -- iter: 0256/1593
[A[ATraining Step: 59  | total loss: [1m[32m0.69309[0m[0m | time: 5.438s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5152 -- iter: 0288/1593
[A[ATraining Step: 60  | total loss: [1m[32m0.69310[0m[0m | time: 6.025s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5090 -- iter: 0320/1593
[A[ATraining Step: 61  | total loss: [1m[32m0.69318[0m[0m | time: 6.631s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4956 -- iter: 0352/1593
[A[ATraining Step: 62  | total loss: [1m[32m0.69318[0m[0m | time: 7.244s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4962 -- iter: 0384/1593
[A[ATraining Step: 63  | total loss: [1m[32m0.69326[0m[0m | time: 7.855s
[2K
| RMSProp | epoch: 002 | loss: 0.69326 - acc: 0.4808 -- iter: 0416/1593
[A[ATraining Step: 64  | total loss: [1m[32m0.69323[0m[0m | time: 8.457s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4793 -- iter: 0448/1593
[A[ATraining Step: 65  | total loss: [1m[32m0.69321[0m[0m | time: 9.068s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4742 -- iter: 0480/1593
[A[ATraining Step: 66  | total loss: [1m[32m0.69318[0m[0m | time: 9.677s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4773 -- iter: 0512/1593
[A[ATraining Step: 67  | total loss: [1m[32m0.69320[0m[0m | time: 10.294s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4763 -- iter: 0544/1593
[A[ATraining Step: 68  | total loss: [1m[32m0.69322[0m[0m | time: 10.896s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4680 -- iter: 0576/1593
[A[ATraining Step: 69  | total loss: [1m[32m0.69321[0m[0m | time: 11.502s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4681 -- iter: 0608/1593
[A[ATraining Step: 70  | total loss: [1m[32m0.69321[0m[0m | time: 12.098s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4682 -- iter: 0640/1593
[A[ATraining Step: 71  | total loss: [1m[32m0.69322[0m[0m | time: 12.686s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4647 -- iter: 0672/1593
[A[ATraining Step: 72  | total loss: [1m[32m0.69321[0m[0m | time: 13.292s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4651 -- iter: 0704/1593
[A[ATraining Step: 73  | total loss: [1m[32m0.69317[0m[0m | time: 13.931s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4898 -- iter: 0736/1593
[A[ATraining Step: 74  | total loss: [1m[32m0.69313[0m[0m | time: 14.540s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5047 -- iter: 0768/1593
[A[ATraining Step: 75  | total loss: [1m[32m0.69312[0m[0m | time: 15.139s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5008 -- iter: 0800/1593
[A[ATraining Step: 76  | total loss: [1m[32m0.69309[0m[0m | time: 15.743s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5107 -- iter: 0832/1593
[A[ATraining Step: 77  | total loss: [1m[32m0.69316[0m[0m | time: 16.337s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.4964 -- iter: 0864/1593
[A[ATraining Step: 78  | total loss: [1m[32m0.69315[0m[0m | time: 16.959s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5000 -- iter: 0896/1593
[A[ATraining Step: 79  | total loss: [1m[32m0.69312[0m[0m | time: 17.560s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5065 -- iter: 0928/1593
[A[ATraining Step: 80  | total loss: [1m[32m0.69311[0m[0m | time: 18.180s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5090 -- iter: 0960/1593
[A[ATraining Step: 81  | total loss: [1m[32m0.69309[0m[0m | time: 18.781s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5113 -- iter: 0992/1593
[A[ATraining Step: 82  | total loss: [1m[32m0.69310[0m[0m | time: 19.407s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5101 -- iter: 1024/1593
[A[ATraining Step: 83  | total loss: [1m[32m0.69306[0m[0m | time: 20.017s
[2K
| RMSProp | epoch: 002 | loss: 0.69306 - acc: 0.5154 -- iter: 1056/1593
[A[ATraining Step: 84  | total loss: [1m[32m0.69290[0m[0m | time: 20.624s
[2K
| RMSProp | epoch: 002 | loss: 0.69290 - acc: 0.5326 -- iter: 1088/1593
[A[ATraining Step: 85  | total loss: [1m[32m0.69285[0m[0m | time: 21.220s
[2K
| RMSProp | epoch: 002 | loss: 0.69285 - acc: 0.5356 -- iter: 1120/1593
[A[ATraining Step: 86  | total loss: [1m[32m0.69293[0m[0m | time: 21.825s
[2K
| RMSProp | epoch: 002 | loss: 0.69293 - acc: 0.5289 -- iter: 1152/1593
[A[ATraining Step: 87  | total loss: [1m[32m0.69308[0m[0m | time: 22.417s
[2K
| RMSProp | epoch: 002 | loss: 0.69308 - acc: 0.5166 -- iter: 1184/1593
[A[ATraining Step: 88  | total loss: [1m[32m0.69311[0m[0m | time: 23.045s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5118 -- iter: 1216/1593
[A[ATraining Step: 89  | total loss: [1m[32m0.69312[0m[0m | time: 23.658s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5107 -- iter: 1248/1593
[A[ATraining Step: 90  | total loss: [1m[32m0.69314[0m[0m | time: 24.255s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.5065 -- iter: 1280/1593
[A[ATraining Step: 91  | total loss: [1m[32m0.69315[0m[0m | time: 24.870s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5058 -- iter: 1312/1593
[A[ATraining Step: 92  | total loss: [1m[32m0.69320[0m[0m | time: 25.465s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4959 -- iter: 1344/1593
[A[ATraining Step: 93  | total loss: [1m[32m0.69318[0m[0m | time: 26.069s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4963 -- iter: 1376/1593
[A[ATraining Step: 94  | total loss: [1m[32m0.69319[0m[0m | time: 26.659s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4904 -- iter: 1408/1593
[A[ATraining Step: 95  | total loss: [1m[32m0.69312[0m[0m | time: 27.259s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5007 -- iter: 1440/1593
[A[ATraining Step: 96  | total loss: [1m[32m0.69320[0m[0m | time: 27.861s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4944 -- iter: 1472/1593
[A[ATraining Step: 97  | total loss: [1m[32m0.69322[0m[0m | time: 28.462s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4887 -- iter: 1504/1593
[A[ATraining Step: 98  | total loss: [1m[32m0.69320[0m[0m | time: 29.080s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4961 -- iter: 1536/1593
[A[ATraining Step: 99  | total loss: [1m[32m0.69313[0m[0m | time: 29.671s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5090 -- iter: 1568/1593
[A[ATraining Step: 100  | total loss: [1m[32m0.69317[0m[0m | time: 31.813s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.5018 | val_loss: 0.69320 - val_acc: 0.4940 -- iter: 1593/1593
--
Training Step: 101  | total loss: [1m[32m0.69312[0m[0m | time: 0.482s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5079 -- iter: 0032/1593
[A[ATraining Step: 102  | total loss: [1m[32m0.69306[0m[0m | time: 0.966s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5131 -- iter: 0064/1593
[A[ATraining Step: 103  | total loss: [1m[32m0.69300[0m[0m | time: 1.571s
[2K
| RMSProp | epoch: 003 | loss: 0.69300 - acc: 0.5178 -- iter: 0096/1593
[A[ATraining Step: 104  | total loss: [1m[32m0.69301[0m[0m | time: 2.169s
[2K
| RMSProp | epoch: 003 | loss: 0.69301 - acc: 0.5160 -- iter: 0128/1593
[A[ATraining Step: 105  | total loss: [1m[32m0.69300[0m[0m | time: 2.767s
[2K
| RMSProp | epoch: 003 | loss: 0.69300 - acc: 0.5144 -- iter: 0160/1593
[A[ATraining Step: 106  | total loss: [1m[32m0.69302[0m[0m | time: 3.364s
[2K
| RMSProp | epoch: 003 | loss: 0.69302 - acc: 0.5130 -- iter: 0192/1593
[A[ATraining Step: 107  | total loss: [1m[32m0.69304[0m[0m | time: 3.961s
[2K
| RMSProp | epoch: 003 | loss: 0.69304 - acc: 0.5117 -- iter: 0224/1593
[A[ATraining Step: 108  | total loss: [1m[32m0.69319[0m[0m | time: 4.568s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5011 -- iter: 0256/1593
[A[ATraining Step: 109  | total loss: [1m[32m0.69307[0m[0m | time: 5.173s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5135 -- iter: 0288/1593
[A[ATraining Step: 110  | total loss: [1m[32m0.69312[0m[0m | time: 5.773s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5090 -- iter: 0320/1593
[A[ATraining Step: 111  | total loss: [1m[32m0.69334[0m[0m | time: 6.380s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.4925 -- iter: 0352/1593
[A[ATraining Step: 112  | total loss: [1m[32m0.69330[0m[0m | time: 6.988s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.4964 -- iter: 0384/1593
[A[ATraining Step: 113  | total loss: [1m[32m0.69320[0m[0m | time: 7.588s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.5030 -- iter: 0416/1593
[A[ATraining Step: 114  | total loss: [1m[32m0.69318[0m[0m | time: 8.185s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.5027 -- iter: 0448/1593
[A[ATraining Step: 115  | total loss: [1m[32m0.69319[0m[0m | time: 8.798s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.4993 -- iter: 0480/1593
[A[ATraining Step: 116  | total loss: [1m[32m0.69325[0m[0m | time: 9.409s
[2K
| RMSProp | epoch: 003 | loss: 0.69325 - acc: 0.4900 -- iter: 0512/1593
[A[ATraining Step: 117  | total loss: [1m[32m0.69323[0m[0m | time: 10.011s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4848 -- iter: 0544/1593
[A[ATraining Step: 118  | total loss: [1m[32m0.69329[0m[0m | time: 10.634s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4800 -- iter: 0576/1593
[A[ATraining Step: 119  | total loss: [1m[32m0.69328[0m[0m | time: 11.244s
[2K
| RMSProp | epoch: 003 | loss: 0.69328 - acc: 0.4789 -- iter: 0608/1593
[A[ATraining Step: 120  | total loss: [1m[32m0.69325[0m[0m | time: 11.854s
[2K
| RMSProp | epoch: 003 | loss: 0.69325 - acc: 0.4873 -- iter: 0640/1593
[A[ATraining Step: 121  | total loss: [1m[32m0.69320[0m[0m | time: 12.454s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.4979 -- iter: 0672/1593
[A[ATraining Step: 122  | total loss: [1m[32m0.69321[0m[0m | time: 13.059s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4950 -- iter: 0704/1593
[A[ATraining Step: 123  | total loss: [1m[32m0.69323[0m[0m | time: 13.669s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4955 -- iter: 0736/1593
[A[ATraining Step: 124  | total loss: [1m[32m0.69330[0m[0m | time: 14.278s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.4897 -- iter: 0768/1593
[A[ATraining Step: 125  | total loss: [1m[32m0.69318[0m[0m | time: 14.921s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.5063 -- iter: 0800/1593
[A[ATraining Step: 126  | total loss: [1m[32m0.69302[0m[0m | time: 15.513s
[2K
| RMSProp | epoch: 003 | loss: 0.69302 - acc: 0.5151 -- iter: 0832/1593
[A[ATraining Step: 127  | total loss: [1m[32m0.69303[0m[0m | time: 16.117s
[2K
| RMSProp | epoch: 003 | loss: 0.69303 - acc: 0.5136 -- iter: 0864/1593
[A[ATraining Step: 128  | total loss: [1m[32m0.69296[0m[0m | time: 16.706s
[2K
| RMSProp | epoch: 003 | loss: 0.69296 - acc: 0.5153 -- iter: 0896/1593
[A[ATraining Step: 129  | total loss: [1m[32m0.69307[0m[0m | time: 17.306s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5107 -- iter: 0928/1593
[A[ATraining Step: 130  | total loss: [1m[32m0.69272[0m[0m | time: 17.921s
[2K
| RMSProp | epoch: 003 | loss: 0.69272 - acc: 0.5252 -- iter: 0960/1593
[A[ATraining Step: 131  | total loss: [1m[32m0.69330[0m[0m | time: 18.523s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.5102 -- iter: 0992/1593
[A[ATraining Step: 132  | total loss: [1m[32m0.69315[0m[0m | time: 19.123s
[2K
| RMSProp | epoch: 003 | loss: 0.69315 - acc: 0.5154 -- iter: 1024/1593
[A[ATraining Step: 133  | total loss: [1m[32m0.69343[0m[0m | time: 19.717s
[2K
| RMSProp | epoch: 003 | loss: 0.69343 - acc: 0.5045 -- iter: 1056/1593
[A[ATraining Step: 134  | total loss: [1m[32m0.69346[0m[0m | time: 20.318s
[2K
| RMSProp | epoch: 003 | loss: 0.69346 - acc: 0.5009 -- iter: 1088/1593
[A[ATraining Step: 135  | total loss: [1m[32m0.69351[0m[0m | time: 20.917s
[2K
| RMSProp | epoch: 003 | loss: 0.69351 - acc: 0.4946 -- iter: 1120/1593
[A[ATraining Step: 136  | total loss: [1m[32m0.69345[0m[0m | time: 21.489s
[2K
| RMSProp | epoch: 003 | loss: 0.69345 - acc: 0.4983 -- iter: 1152/1593
[A[ATraining Step: 137  | total loss: [1m[32m0.69330[0m[0m | time: 22.083s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.5078 -- iter: 1184/1593
[A[ATraining Step: 138  | total loss: [1m[32m0.69341[0m[0m | time: 22.683s
[2K
| RMSProp | epoch: 003 | loss: 0.69341 - acc: 0.5008 -- iter: 1216/1593
[A[ATraining Step: 139  | total loss: [1m[32m0.69332[0m[0m | time: 23.277s
[2K
| RMSProp | epoch: 003 | loss: 0.69332 - acc: 0.5038 -- iter: 1248/1593
[A[ATraining Step: 140  | total loss: [1m[32m0.69345[0m[0m | time: 23.880s
[2K
| RMSProp | epoch: 003 | loss: 0.69345 - acc: 0.4941 -- iter: 1280/1593
[A[ATraining Step: 141  | total loss: [1m[32m0.69350[0m[0m | time: 24.479s
[2K
| RMSProp | epoch: 003 | loss: 0.69350 - acc: 0.4853 -- iter: 1312/1593
[A[ATraining Step: 142  | total loss: [1m[32m0.69345[0m[0m | time: 25.083s
[2K
| RMSProp | epoch: 003 | loss: 0.69345 - acc: 0.4868 -- iter: 1344/1593
[A[ATraining Step: 143  | total loss: [1m[32m0.69341[0m[0m | time: 25.680s
[2K
| RMSProp | epoch: 003 | loss: 0.69341 - acc: 0.4975 -- iter: 1376/1593
[A[ATraining Step: 144  | total loss: [1m[32m0.69331[0m[0m | time: 26.277s
[2K
| RMSProp | epoch: 003 | loss: 0.69331 - acc: 0.5040 -- iter: 1408/1593
[A[ATraining Step: 145  | total loss: [1m[32m0.69336[0m[0m | time: 26.873s
[2K
| RMSProp | epoch: 003 | loss: 0.69336 - acc: 0.4973 -- iter: 1440/1593
[A[ATraining Step: 146  | total loss: [1m[32m0.69335[0m[0m | time: 27.468s
[2K
| RMSProp | epoch: 003 | loss: 0.69335 - acc: 0.4882 -- iter: 1472/1593
[A[ATraining Step: 147  | total loss: [1m[32m0.69333[0m[0m | time: 28.070s
[2K
| RMSProp | epoch: 003 | loss: 0.69333 - acc: 0.4894 -- iter: 1504/1593
[A[ATraining Step: 148  | total loss: [1m[32m0.69330[0m[0m | time: 28.675s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.4905 -- iter: 1536/1593
[A[ATraining Step: 149  | total loss: [1m[32m0.69334[0m[0m | time: 29.281s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.4820 -- iter: 1568/1593
[A[ATraining Step: 150  | total loss: [1m[32m0.69327[0m[0m | time: 31.444s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.5026 | val_loss: 0.69301 - val_acc: 0.4940 -- iter: 1593/1593
--
Training Step: 151  | total loss: [1m[32m0.69338[0m[0m | time: 0.589s
[2K
| RMSProp | epoch: 004 | loss: 0.69338 - acc: 0.4929 -- iter: 0032/1593
[A[ATraining Step: 152  | total loss: [1m[32m0.69336[0m[0m | time: 1.083s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.4874 -- iter: 0064/1593
[A[ATraining Step: 153  | total loss: [1m[32m0.69327[0m[0m | time: 1.582s
[2K
| RMSProp | epoch: 004 | loss: 0.69327 - acc: 0.5027 -- iter: 0096/1593
[A[ATraining Step: 154  | total loss: [1m[32m0.69286[0m[0m | time: 2.198s
[2K
| RMSProp | epoch: 004 | loss: 0.69286 - acc: 0.5164 -- iter: 0128/1593
[A[ATraining Step: 155  | total loss: [1m[32m0.69276[0m[0m | time: 2.799s
[2K
| RMSProp | epoch: 004 | loss: 0.69276 - acc: 0.5179 -- iter: 0160/1593
[A[ATraining Step: 156  | total loss: [1m[32m0.69340[0m[0m | time: 3.408s
[2K
| RMSProp | epoch: 004 | loss: 0.69340 - acc: 0.5067 -- iter: 0192/1593
[A[ATraining Step: 157  | total loss: [1m[32m0.69329[0m[0m | time: 4.017s
[2K
| RMSProp | epoch: 004 | loss: 0.69329 - acc: 0.5092 -- iter: 0224/1593
[A[ATraining Step: 158  | total loss: [1m[32m0.69390[0m[0m | time: 4.637s
[2K
| RMSProp | epoch: 004 | loss: 0.69390 - acc: 0.4864 -- iter: 0256/1593
[A[ATraining Step: 159  | total loss: [1m[32m0.69366[0m[0m | time: 5.232s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.5034 -- iter: 0288/1593
[A[ATraining Step: 160  | total loss: [1m[32m0.69328[0m[0m | time: 5.823s
[2K
| RMSProp | epoch: 004 | loss: 0.69328 - acc: 0.5124 -- iter: 0320/1593
[A[ATraining Step: 161  | total loss: [1m[32m0.69381[0m[0m | time: 6.424s
[2K
| RMSProp | epoch: 004 | loss: 0.69381 - acc: 0.5018 -- iter: 0352/1593
[A[ATraining Step: 162  | total loss: [1m[32m0.69387[0m[0m | time: 7.018s
[2K
| RMSProp | epoch: 004 | loss: 0.69387 - acc: 0.4954 -- iter: 0384/1593
[A[ATraining Step: 163  | total loss: [1m[32m0.69382[0m[0m | time: 7.615s
[2K
| RMSProp | epoch: 004 | loss: 0.69382 - acc: 0.4896 -- iter: 0416/1593
[A[ATraining Step: 164  | total loss: [1m[32m0.69377[0m[0m | time: 8.211s
[2K
| RMSProp | epoch: 004 | loss: 0.69377 - acc: 0.4781 -- iter: 0448/1593
[A[ATraining Step: 165  | total loss: [1m[32m0.69366[0m[0m | time: 8.806s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.4834 -- iter: 0480/1593
[A[ATraining Step: 166  | total loss: [1m[32m0.69339[0m[0m | time: 9.401s
[2K
| RMSProp | epoch: 004 | loss: 0.69339 - acc: 0.4945 -- iter: 0512/1593
[A[ATraining Step: 167  | total loss: [1m[32m0.69350[0m[0m | time: 10.007s
[2K
| RMSProp | epoch: 004 | loss: 0.69350 - acc: 0.4919 -- iter: 0544/1593
[A[ATraining Step: 168  | total loss: [1m[32m0.69371[0m[0m | time: 10.612s
[2K
| RMSProp | epoch: 004 | loss: 0.69371 - acc: 0.4833 -- iter: 0576/1593
[A[ATraining Step: 169  | total loss: [1m[32m0.69361[0m[0m | time: 11.216s
[2K
| RMSProp | epoch: 004 | loss: 0.69361 - acc: 0.4881 -- iter: 0608/1593
[A[ATraining Step: 170  | total loss: [1m[32m0.69356[0m[0m | time: 11.810s
[2K
| RMSProp | epoch: 004 | loss: 0.69356 - acc: 0.4893 -- iter: 0640/1593
[A[ATraining Step: 171  | total loss: [1m[32m0.69343[0m[0m | time: 12.412s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.4966 -- iter: 0672/1593
[A[ATraining Step: 172  | total loss: [1m[32m0.69354[0m[0m | time: 13.022s
[2K
| RMSProp | epoch: 004 | loss: 0.69354 - acc: 0.4907 -- iter: 0704/1593
[A[ATraining Step: 173  | total loss: [1m[32m0.69341[0m[0m | time: 13.621s
[2K
| RMSProp | epoch: 004 | loss: 0.69341 - acc: 0.4979 -- iter: 0736/1593
[A[ATraining Step: 174  | total loss: [1m[32m0.69334[0m[0m | time: 14.229s
[2K
| RMSProp | epoch: 004 | loss: 0.69334 - acc: 0.4981 -- iter: 0768/1593
[A[ATraining Step: 175  | total loss: [1m[32m0.69366[0m[0m | time: 14.840s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.4827 -- iter: 0800/1593
[A[ATraining Step: 176  | total loss: [1m[32m0.69366[0m[0m | time: 15.437s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.4782 -- iter: 0832/1593
[A[ATraining Step: 177  | total loss: [1m[32m0.69361[0m[0m | time: 16.043s
[2K
| RMSProp | epoch: 004 | loss: 0.69361 - acc: 0.4803 -- iter: 0864/1593
[A[ATraining Step: 178  | total loss: [1m[32m0.69357[0m[0m | time: 16.652s
[2K
| RMSProp | epoch: 004 | loss: 0.69357 - acc: 0.4823 -- iter: 0896/1593
[A[ATraining Step: 179  | total loss: [1m[32m0.69350[0m[0m | time: 17.271s
[2K
| RMSProp | epoch: 004 | loss: 0.69350 - acc: 0.4934 -- iter: 0928/1593
[A[ATraining Step: 180  | total loss: [1m[32m0.69343[0m[0m | time: 17.887s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.4972 -- iter: 0960/1593
[A[ATraining Step: 181  | total loss: [1m[32m0.69341[0m[0m | time: 18.495s
[2K
| RMSProp | epoch: 004 | loss: 0.69341 - acc: 0.4975 -- iter: 0992/1593
[A[ATraining Step: 182  | total loss: [1m[32m0.69347[0m[0m | time: 19.100s
[2K
| RMSProp | epoch: 004 | loss: 0.69347 - acc: 0.4915 -- iter: 1024/1593
[A[ATraining Step: 183  | total loss: [1m[32m0.69342[0m[0m | time: 19.716s
[2K
| RMSProp | epoch: 004 | loss: 0.69342 - acc: 0.4955 -- iter: 1056/1593
[A[ATraining Step: 184  | total loss: [1m[32m0.69325[0m[0m | time: 20.349s
[2K
| RMSProp | epoch: 004 | loss: 0.69325 - acc: 0.5116 -- iter: 1088/1593
[A[ATraining Step: 185  | total loss: [1m[32m0.69340[0m[0m | time: 20.994s
[2K
| RMSProp | epoch: 004 | loss: 0.69340 - acc: 0.5042 -- iter: 1120/1593
[A[ATraining Step: 186  | total loss: [1m[32m0.69339[0m[0m | time: 21.601s
[2K
| RMSProp | epoch: 004 | loss: 0.69339 - acc: 0.5037 -- iter: 1152/1593
[A[ATraining Step: 187  | total loss: [1m[32m0.69344[0m[0m | time: 22.196s
[2K
| RMSProp | epoch: 004 | loss: 0.69344 - acc: 0.4971 -- iter: 1184/1593
[A[ATraining Step: 188  | total loss: [1m[32m0.69338[0m[0m | time: 22.807s
[2K
| RMSProp | epoch: 004 | loss: 0.69338 - acc: 0.5005 -- iter: 1216/1593
[A[ATraining Step: 189  | total loss: [1m[32m0.69334[0m[0m | time: 23.419s
[2K
| RMSProp | epoch: 004 | loss: 0.69334 - acc: 0.5005 -- iter: 1248/1593
[A[ATraining Step: 190  | total loss: [1m[32m0.69327[0m[0m | time: 24.058s
[2K
| RMSProp | epoch: 004 | loss: 0.69327 - acc: 0.5036 -- iter: 1280/1593
[A[ATraining Step: 191  | total loss: [1m[32m0.69347[0m[0m | time: 24.659s
[2K
| RMSProp | epoch: 004 | loss: 0.69347 - acc: 0.4907 -- iter: 1312/1593
[A[ATraining Step: 192  | total loss: [1m[32m0.69346[0m[0m | time: 25.279s
[2K
| RMSProp | epoch: 004 | loss: 0.69346 - acc: 0.4885 -- iter: 1344/1593
[A[ATraining Step: 193  | total loss: [1m[32m0.69343[0m[0m | time: 25.890s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.4959 -- iter: 1376/1593
[A[ATraining Step: 194  | total loss: [1m[32m0.69343[0m[0m | time: 26.508s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.4932 -- iter: 1408/1593
[A[ATraining Step: 195  | total loss: [1m[32m0.69334[0m[0m | time: 27.098s
[2K
| RMSProp | epoch: 004 | loss: 0.69334 - acc: 0.5001 -- iter: 1440/1593
[A[ATraining Step: 196  | total loss: [1m[32m0.69337[0m[0m | time: 27.677s
[2K
| RMSProp | epoch: 004 | loss: 0.69337 - acc: 0.4970 -- iter: 1472/1593
[A[ATraining Step: 197  | total loss: [1m[32m0.69329[0m[0m | time: 28.273s
[2K
| RMSProp | epoch: 004 | loss: 0.69329 - acc: 0.5004 -- iter: 1504/1593
[A[ATraining Step: 198  | total loss: [1m[32m0.69313[0m[0m | time: 28.867s
[2K
| RMSProp | epoch: 004 | loss: 0.69313 - acc: 0.5066 -- iter: 1536/1593
[A[ATraining Step: 199  | total loss: [1m[32m0.69323[0m[0m | time: 29.461s
[2K
| RMSProp | epoch: 004 | loss: 0.69323 - acc: 0.5028 -- iter: 1568/1593
[A[ATraining Step: 200  | total loss: [1m[32m0.69320[0m[0m | time: 31.634s
[2K
| RMSProp | epoch: 004 | loss: 0.69320 - acc: 0.5025 | val_loss: 0.69352 - val_acc: 0.4940 -- iter: 1593/1593
--
Training Step: 201  | total loss: [1m[32m0.69296[0m[0m | time: 0.608s
[2K
| RMSProp | epoch: 005 | loss: 0.69296 - acc: 0.5117 -- iter: 0032/1593
[A[ATraining Step: 202  | total loss: [1m[32m0.69250[0m[0m | time: 1.200s
[2K
| RMSProp | epoch: 005 | loss: 0.69250 - acc: 0.5199 -- iter: 0064/1593
[A[ATraining Step: 203  | total loss: [1m[32m0.69262[0m[0m | time: 1.697s
[2K
| RMSProp | epoch: 005 | loss: 0.69262 - acc: 0.5179 -- iter: 0096/1593
[A[ATraining Step: 204  | total loss: [1m[32m0.69266[0m[0m | time: 2.179s
[2K
| RMSProp | epoch: 005 | loss: 0.69266 - acc: 0.5141 -- iter: 0128/1593
[A[ATraining Step: 205  | total loss: [1m[32m0.69265[0m[0m | time: 2.778s
[2K
| RMSProp | epoch: 005 | loss: 0.69265 - acc: 0.5107 -- iter: 0160/1593
[A[ATraining Step: 206  | total loss: [1m[32m0.69288[0m[0m | time: 3.381s
[2K
| RMSProp | epoch: 005 | loss: 0.69288 - acc: 0.5034 -- iter: 0192/1593
[A[ATraining Step: 207  | total loss: [1m[32m0.69295[0m[0m | time: 3.979s
[2K
| RMSProp | epoch: 005 | loss: 0.69295 - acc: 0.4968 -- iter: 0224/1593
[A[ATraining Step: 208  | total loss: [1m[32m0.69277[0m[0m | time: 4.579s
[2K
| RMSProp | epoch: 005 | loss: 0.69277 - acc: 0.4971 -- iter: 0256/1593
[A[ATraining Step: 209  | total loss: [1m[32m0.69316[0m[0m | time: 5.173s
[2K
| RMSProp | epoch: 005 | loss: 0.69316 - acc: 0.4911 -- iter: 0288/1593
[A[ATraining Step: 210  | total loss: [1m[32m0.69307[0m[0m | time: 5.769s
[2K
| RMSProp | epoch: 005 | loss: 0.69307 - acc: 0.5014 -- iter: 0320/1593
[A[ATraining Step: 211  | total loss: [1m[32m0.69270[0m[0m | time: 6.363s
[2K
| RMSProp | epoch: 005 | loss: 0.69270 - acc: 0.5044 -- iter: 0352/1593
[A[ATraining Step: 212  | total loss: [1m[32m0.69303[0m[0m | time: 6.975s
[2K
| RMSProp | epoch: 005 | loss: 0.69303 - acc: 0.5040 -- iter: 0384/1593
[A[ATraining Step: 213  | total loss: [1m[32m0.69310[0m[0m | time: 7.581s
[2K
| RMSProp | epoch: 005 | loss: 0.69310 - acc: 0.5004 -- iter: 0416/1593
[A[ATraining Step: 214  | total loss: [1m[32m0.69247[0m[0m | time: 8.172s
[2K
| RMSProp | epoch: 005 | loss: 0.69247 - acc: 0.5066 -- iter: 0448/1593
[A[ATraining Step: 215  | total loss: [1m[32m0.69062[0m[0m | time: 8.769s
[2K
| RMSProp | epoch: 005 | loss: 0.69062 - acc: 0.5185 -- iter: 0480/1593
[A[ATraining Step: 216  | total loss: [1m[32m0.68700[0m[0m | time: 9.393s
[2K
| RMSProp | epoch: 005 | loss: 0.68700 - acc: 0.5291 -- iter: 0512/1593
[A[ATraining Step: 217  | total loss: [1m[32m0.69138[0m[0m | time: 10.007s
[2K
| RMSProp | epoch: 005 | loss: 0.69138 - acc: 0.5231 -- iter: 0544/1593
[A[ATraining Step: 218  | total loss: [1m[32m0.69123[0m[0m | time: 10.604s
[2K
| RMSProp | epoch: 005 | loss: 0.69123 - acc: 0.5364 -- iter: 0576/1593
[A[ATraining Step: 219  | total loss: [1m[32m0.68998[0m[0m | time: 11.210s
[2K
| RMSProp | epoch: 005 | loss: 0.68998 - acc: 0.5453 -- iter: 0608/1593
[A[ATraining Step: 220  | total loss: [1m[32m0.69098[0m[0m | time: 11.819s
[2K
| RMSProp | epoch: 005 | loss: 0.69098 - acc: 0.5407 -- iter: 0640/1593
[A[ATraining Step: 221  | total loss: [1m[32m0.69053[0m[0m | time: 12.424s
[2K
| RMSProp | epoch: 005 | loss: 0.69053 - acc: 0.5429 -- iter: 0672/1593
[A[ATraining Step: 222  | total loss: [1m[32m0.69052[0m[0m | time: 13.015s
[2K
| RMSProp | epoch: 005 | loss: 0.69052 - acc: 0.5417 -- iter: 0704/1593
[A[ATraining Step: 223  | total loss: [1m[32m0.69104[0m[0m | time: 13.623s
[2K
| RMSProp | epoch: 005 | loss: 0.69104 - acc: 0.5313 -- iter: 0736/1593
[A[ATraining Step: 224  | total loss: [1m[32m0.69066[0m[0m | time: 14.219s
[2K
| RMSProp | epoch: 005 | loss: 0.69066 - acc: 0.5376 -- iter: 0768/1593
[A[ATraining Step: 225  | total loss: [1m[32m0.69152[0m[0m | time: 14.821s
[2K
| RMSProp | epoch: 005 | loss: 0.69152 - acc: 0.5307 -- iter: 0800/1593
[A[ATraining Step: 226  | total loss: [1m[32m0.69026[0m[0m | time: 15.431s
[2K
| RMSProp | epoch: 005 | loss: 0.69026 - acc: 0.5401 -- iter: 0832/1593
[A[ATraining Step: 227  | total loss: [1m[32m0.69114[0m[0m | time: 16.028s
[2K
| RMSProp | epoch: 005 | loss: 0.69114 - acc: 0.5299 -- iter: 0864/1593
[A[ATraining Step: 228  | total loss: [1m[32m0.69014[0m[0m | time: 16.633s
[2K
| RMSProp | epoch: 005 | loss: 0.69014 - acc: 0.5394 -- iter: 0896/1593
[A[ATraining Step: 229  | total loss: [1m[32m0.68921[0m[0m | time: 17.262s
[2K
| RMSProp | epoch: 005 | loss: 0.68921 - acc: 0.5386 -- iter: 0928/1593
[A[ATraining Step: 230  | total loss: [1m[32m0.68631[0m[0m | time: 17.875s
[2K
| RMSProp | epoch: 005 | loss: 0.68631 - acc: 0.5566 -- iter: 0960/1593
[A[ATraining Step: 231  | total loss: [1m[32m0.68039[0m[0m | time: 18.481s
[2K
| RMSProp | epoch: 005 | loss: 0.68039 - acc: 0.5697 -- iter: 0992/1593
[A[ATraining Step: 232  | total loss: [1m[32m0.68228[0m[0m | time: 19.076s
[2K
| RMSProp | epoch: 005 | loss: 0.68228 - acc: 0.5596 -- iter: 1024/1593
[A[ATraining Step: 233  | total loss: [1m[32m0.68239[0m[0m | time: 19.674s
[2K
| RMSProp | epoch: 005 | loss: 0.68239 - acc: 0.5630 -- iter: 1056/1593
[A[ATraining Step: 234  | total loss: [1m[32m0.67889[0m[0m | time: 20.298s
[2K
| RMSProp | epoch: 005 | loss: 0.67889 - acc: 0.5661 -- iter: 1088/1593
[A[ATraining Step: 235  | total loss: [1m[32m0.67147[0m[0m | time: 20.893s
[2K
| RMSProp | epoch: 005 | loss: 0.67147 - acc: 0.5813 -- iter: 1120/1593
[A[ATraining Step: 236  | total loss: [1m[32m0.69363[0m[0m | time: 21.518s
[2K
| RMSProp | epoch: 005 | loss: 0.69363 - acc: 0.5545 -- iter: 1152/1593
[A[ATraining Step: 237  | total loss: [1m[32m0.69357[0m[0m | time: 22.127s
[2K
| RMSProp | epoch: 005 | loss: 0.69357 - acc: 0.5428 -- iter: 1184/1593
[A[ATraining Step: 238  | total loss: [1m[32m0.68927[0m[0m | time: 22.727s
[2K
| RMSProp | epoch: 005 | loss: 0.68927 - acc: 0.5604 -- iter: 1216/1593
[A[ATraining Step: 239  | total loss: [1m[32m0.68780[0m[0m | time: 23.333s
[2K
| RMSProp | epoch: 005 | loss: 0.68780 - acc: 0.5606 -- iter: 1248/1593
[A[ATraining Step: 240  | total loss: [1m[32m0.68669[0m[0m | time: 23.927s
[2K
| RMSProp | epoch: 005 | loss: 0.68669 - acc: 0.5670 -- iter: 1280/1593
[A[ATraining Step: 241  | total loss: [1m[32m0.68524[0m[0m | time: 24.519s
[2K
| RMSProp | epoch: 005 | loss: 0.68524 - acc: 0.5728 -- iter: 1312/1593
[A[ATraining Step: 242  | total loss: [1m[32m0.68550[0m[0m | time: 25.117s
[2K
| RMSProp | epoch: 005 | loss: 0.68550 - acc: 0.5718 -- iter: 1344/1593
[A[ATraining Step: 243  | total loss: [1m[32m0.68489[0m[0m | time: 25.734s
[2K
| RMSProp | epoch: 005 | loss: 0.68489 - acc: 0.5709 -- iter: 1376/1593
[A[ATraining Step: 244  | total loss: [1m[32m0.68225[0m[0m | time: 26.353s
[2K
| RMSProp | epoch: 005 | loss: 0.68225 - acc: 0.5700 -- iter: 1408/1593
[A[ATraining Step: 245  | total loss: [1m[32m0.68232[0m[0m | time: 26.965s
[2K
| RMSProp | epoch: 005 | loss: 0.68232 - acc: 0.5693 -- iter: 1440/1593
[A[ATraining Step: 246  | total loss: [1m[32m0.67959[0m[0m | time: 27.568s
[2K
| RMSProp | epoch: 005 | loss: 0.67959 - acc: 0.5780 -- iter: 1472/1593
[A[ATraining Step: 247  | total loss: [1m[32m0.68227[0m[0m | time: 28.177s
[2K
| RMSProp | epoch: 005 | loss: 0.68227 - acc: 0.5764 -- iter: 1504/1593
[A[ATraining Step: 248  | total loss: [1m[32m0.67949[0m[0m | time: 28.788s
[2K
| RMSProp | epoch: 005 | loss: 0.67949 - acc: 0.5813 -- iter: 1536/1593
[A[ATraining Step: 249  | total loss: [1m[32m0.67774[0m[0m | time: 29.398s
[2K
| RMSProp | epoch: 005 | loss: 0.67774 - acc: 0.5888 -- iter: 1568/1593
[A[ATraining Step: 250  | total loss: [1m[32m0.66880[0m[0m | time: 31.561s
[2K
| RMSProp | epoch: 005 | loss: 0.66880 - acc: 0.6111 | val_loss: 0.65719 - val_acc: 0.6305 -- iter: 1593/1593
--
Training Step: 251  | total loss: [1m[32m0.67540[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 006 | loss: 0.67540 - acc: 0.6032 -- iter: 0032/1593
[A[ATraining Step: 252  | total loss: [1m[32m0.67932[0m[0m | time: 1.218s
[2K
| RMSProp | epoch: 006 | loss: 0.67932 - acc: 0.5897 -- iter: 0064/1593
[A[ATraining Step: 253  | total loss: [1m[32m0.67391[0m[0m | time: 1.845s
[2K
| RMSProp | epoch: 006 | loss: 0.67391 - acc: 0.6026 -- iter: 0096/1593
[A[ATraining Step: 254  | total loss: [1m[32m0.67540[0m[0m | time: 2.337s
[2K
| RMSProp | epoch: 006 | loss: 0.67540 - acc: 0.5986 -- iter: 0128/1593
[A[ATraining Step: 255  | total loss: [1m[32m0.67055[0m[0m | time: 2.825s
[2K
| RMSProp | epoch: 006 | loss: 0.67055 - acc: 0.6027 -- iter: 0160/1593
[A[ATraining Step: 256  | total loss: [1m[32m0.66010[0m[0m | time: 3.436s
[2K
| RMSProp | epoch: 006 | loss: 0.66010 - acc: 0.6225 -- iter: 0192/1593
[A[ATraining Step: 257  | total loss: [1m[32m0.66002[0m[0m | time: 4.038s
[2K
| RMSProp | epoch: 006 | loss: 0.66002 - acc: 0.6290 -- iter: 0224/1593
[A[ATraining Step: 258  | total loss: [1m[32m0.66438[0m[0m | time: 4.617s
[2K
| RMSProp | epoch: 006 | loss: 0.66438 - acc: 0.6223 -- iter: 0256/1593
[A[ATraining Step: 259  | total loss: [1m[32m0.66530[0m[0m | time: 5.214s
[2K
| RMSProp | epoch: 006 | loss: 0.66530 - acc: 0.6163 -- iter: 0288/1593
[A[ATraining Step: 260  | total loss: [1m[32m0.66193[0m[0m | time: 5.824s
[2K
| RMSProp | epoch: 006 | loss: 0.66193 - acc: 0.6172 -- iter: 0320/1593
[A[ATraining Step: 261  | total loss: [1m[32m0.67451[0m[0m | time: 6.426s
[2K
| RMSProp | epoch: 006 | loss: 0.67451 - acc: 0.5992 -- iter: 0352/1593
[A[ATraining Step: 262  | total loss: [1m[32m0.67080[0m[0m | time: 7.022s
[2K
| RMSProp | epoch: 006 | loss: 0.67080 - acc: 0.6112 -- iter: 0384/1593
[A[ATraining Step: 263  | total loss: [1m[32m0.66449[0m[0m | time: 7.611s
[2K
| RMSProp | epoch: 006 | loss: 0.66449 - acc: 0.6219 -- iter: 0416/1593
[A[ATraining Step: 264  | total loss: [1m[32m0.65963[0m[0m | time: 8.191s
[2K
| RMSProp | epoch: 006 | loss: 0.65963 - acc: 0.6254 -- iter: 0448/1593
[A[ATraining Step: 265  | total loss: [1m[32m0.65160[0m[0m | time: 8.798s
[2K
| RMSProp | epoch: 006 | loss: 0.65160 - acc: 0.6285 -- iter: 0480/1593
[A[ATraining Step: 266  | total loss: [1m[32m0.65818[0m[0m | time: 9.393s
[2K
| RMSProp | epoch: 006 | loss: 0.65818 - acc: 0.6219 -- iter: 0512/1593
[A[ATraining Step: 267  | total loss: [1m[32m0.65737[0m[0m | time: 9.990s
[2K
| RMSProp | epoch: 006 | loss: 0.65737 - acc: 0.6159 -- iter: 0544/1593
[A[ATraining Step: 268  | total loss: [1m[32m0.64893[0m[0m | time: 10.595s
[2K
| RMSProp | epoch: 006 | loss: 0.64893 - acc: 0.6200 -- iter: 0576/1593
[A[ATraining Step: 269  | total loss: [1m[32m0.64989[0m[0m | time: 11.209s
[2K
| RMSProp | epoch: 006 | loss: 0.64989 - acc: 0.6298 -- iter: 0608/1593
[A[ATraining Step: 270  | total loss: [1m[32m0.65518[0m[0m | time: 11.811s
[2K
| RMSProp | epoch: 006 | loss: 0.65518 - acc: 0.6294 -- iter: 0640/1593
[A[ATraining Step: 271  | total loss: [1m[32m0.65381[0m[0m | time: 12.399s
[2K
| RMSProp | epoch: 006 | loss: 0.65381 - acc: 0.6320 -- iter: 0672/1593
[A[ATraining Step: 272  | total loss: [1m[32m0.65877[0m[0m | time: 13.000s
[2K
| RMSProp | epoch: 006 | loss: 0.65877 - acc: 0.6251 -- iter: 0704/1593
[A[ATraining Step: 273  | total loss: [1m[32m0.65794[0m[0m | time: 13.591s
[2K
| RMSProp | epoch: 006 | loss: 0.65794 - acc: 0.6282 -- iter: 0736/1593
[A[ATraining Step: 274  | total loss: [1m[32m0.66031[0m[0m | time: 14.192s
[2K
| RMSProp | epoch: 006 | loss: 0.66031 - acc: 0.6248 -- iter: 0768/1593
[A[ATraining Step: 275  | total loss: [1m[32m0.66153[0m[0m | time: 14.788s
[2K
| RMSProp | epoch: 006 | loss: 0.66153 - acc: 0.6154 -- iter: 0800/1593
[A[ATraining Step: 276  | total loss: [1m[32m0.66118[0m[0m | time: 15.382s
[2K
| RMSProp | epoch: 006 | loss: 0.66118 - acc: 0.6132 -- iter: 0832/1593
[A[ATraining Step: 277  | total loss: [1m[32m0.65556[0m[0m | time: 15.987s
[2K
| RMSProp | epoch: 006 | loss: 0.65556 - acc: 0.6207 -- iter: 0864/1593
[A[ATraining Step: 278  | total loss: [1m[32m0.64718[0m[0m | time: 16.590s
[2K
| RMSProp | epoch: 006 | loss: 0.64718 - acc: 0.6399 -- iter: 0896/1593
[A[ATraining Step: 279  | total loss: [1m[32m0.63678[0m[0m | time: 17.188s
[2K
| RMSProp | epoch: 006 | loss: 0.63678 - acc: 0.6477 -- iter: 0928/1593
[A[ATraining Step: 280  | total loss: [1m[32m0.62873[0m[0m | time: 17.784s
[2K
| RMSProp | epoch: 006 | loss: 0.62873 - acc: 0.6517 -- iter: 0960/1593
[A[ATraining Step: 281  | total loss: [1m[32m0.63141[0m[0m | time: 18.372s
[2K
| RMSProp | epoch: 006 | loss: 0.63141 - acc: 0.6522 -- iter: 0992/1593
[A[ATraining Step: 282  | total loss: [1m[32m0.63798[0m[0m | time: 18.968s
[2K
| RMSProp | epoch: 006 | loss: 0.63798 - acc: 0.6463 -- iter: 1024/1593
[A[ATraining Step: 283  | total loss: [1m[32m0.63825[0m[0m | time: 19.568s
[2K
| RMSProp | epoch: 006 | loss: 0.63825 - acc: 0.6473 -- iter: 1056/1593
[A[ATraining Step: 284  | total loss: [1m[32m0.64021[0m[0m | time: 20.169s
[2K
| RMSProp | epoch: 006 | loss: 0.64021 - acc: 0.6451 -- iter: 1088/1593
[A[ATraining Step: 285  | total loss: [1m[32m0.65782[0m[0m | time: 20.768s
[2K
| RMSProp | epoch: 006 | loss: 0.65782 - acc: 0.6243 -- iter: 1120/1593
[A[ATraining Step: 286  | total loss: [1m[32m0.65871[0m[0m | time: 21.366s
[2K
| RMSProp | epoch: 006 | loss: 0.65871 - acc: 0.6244 -- iter: 1152/1593
[A[ATraining Step: 287  | total loss: [1m[32m0.65557[0m[0m | time: 21.983s
[2K
| RMSProp | epoch: 006 | loss: 0.65557 - acc: 0.6338 -- iter: 1184/1593
[A[ATraining Step: 288  | total loss: [1m[32m0.65280[0m[0m | time: 22.589s
[2K
| RMSProp | epoch: 006 | loss: 0.65280 - acc: 0.6392 -- iter: 1216/1593
[A[ATraining Step: 289  | total loss: [1m[32m0.65019[0m[0m | time: 23.196s
[2K
| RMSProp | epoch: 006 | loss: 0.65019 - acc: 0.6409 -- iter: 1248/1593
[A[ATraining Step: 290  | total loss: [1m[32m0.64972[0m[0m | time: 23.793s
[2K
| RMSProp | epoch: 006 | loss: 0.64972 - acc: 0.6424 -- iter: 1280/1593
[A[ATraining Step: 291  | total loss: [1m[32m0.64275[0m[0m | time: 24.388s
[2K
| RMSProp | epoch: 006 | loss: 0.64275 - acc: 0.6501 -- iter: 1312/1593
[A[ATraining Step: 292  | total loss: [1m[32m0.64752[0m[0m | time: 24.995s
[2K
| RMSProp | epoch: 006 | loss: 0.64752 - acc: 0.6382 -- iter: 1344/1593
[A[ATraining Step: 293  | total loss: [1m[32m0.64900[0m[0m | time: 25.588s
[2K
| RMSProp | epoch: 006 | loss: 0.64900 - acc: 0.6369 -- iter: 1376/1593
[A[ATraining Step: 294  | total loss: [1m[32m0.64362[0m[0m | time: 26.191s
[2K
| RMSProp | epoch: 006 | loss: 0.64362 - acc: 0.6326 -- iter: 1408/1593
[A[ATraining Step: 295  | total loss: [1m[32m0.64228[0m[0m | time: 26.801s
[2K
| RMSProp | epoch: 006 | loss: 0.64228 - acc: 0.6412 -- iter: 1440/1593
[A[ATraining Step: 296  | total loss: [1m[32m0.63873[0m[0m | time: 27.415s
[2K
| RMSProp | epoch: 006 | loss: 0.63873 - acc: 0.6458 -- iter: 1472/1593
[A[ATraining Step: 297  | total loss: [1m[32m0.64792[0m[0m | time: 28.004s
[2K
| RMSProp | epoch: 006 | loss: 0.64792 - acc: 0.6344 -- iter: 1504/1593
[A[ATraining Step: 298  | total loss: [1m[32m0.64675[0m[0m | time: 28.601s
[2K
| RMSProp | epoch: 006 | loss: 0.64675 - acc: 0.6365 -- iter: 1536/1593
[A[ATraining Step: 299  | total loss: [1m[32m0.64778[0m[0m | time: 29.207s
[2K
| RMSProp | epoch: 006 | loss: 0.64778 - acc: 0.6354 -- iter: 1568/1593
[A[ATraining Step: 300  | total loss: [1m[32m0.64665[0m[0m | time: 31.363s
[2K
| RMSProp | epoch: 006 | loss: 0.64665 - acc: 0.6406 | val_loss: 0.63624 - val_acc: 0.6506 -- iter: 1593/1593
--
Training Step: 301  | total loss: [1m[32m0.64329[0m[0m | time: 0.623s
[2K
| RMSProp | epoch: 007 | loss: 0.64329 - acc: 0.6422 -- iter: 0032/1593
[A[ATraining Step: 302  | total loss: [1m[32m0.65428[0m[0m | time: 1.209s
[2K
| RMSProp | epoch: 007 | loss: 0.65428 - acc: 0.6342 -- iter: 0064/1593
[A[ATraining Step: 303  | total loss: [1m[32m0.64986[0m[0m | time: 1.809s
[2K
| RMSProp | epoch: 007 | loss: 0.64986 - acc: 0.6427 -- iter: 0096/1593
[A[ATraining Step: 304  | total loss: [1m[32m0.64803[0m[0m | time: 2.405s
[2K
| RMSProp | epoch: 007 | loss: 0.64803 - acc: 0.6440 -- iter: 0128/1593
[A[ATraining Step: 305  | total loss: [1m[32m0.63808[0m[0m | time: 2.899s
[2K
| RMSProp | epoch: 007 | loss: 0.63808 - acc: 0.6577 -- iter: 0160/1593
[A[ATraining Step: 306  | total loss: [1m[32m0.62939[0m[0m | time: 3.398s
[2K
| RMSProp | epoch: 007 | loss: 0.62939 - acc: 0.6640 -- iter: 0192/1593
[A[ATraining Step: 307  | total loss: [1m[32m0.61366[0m[0m | time: 4.009s
[2K
| RMSProp | epoch: 007 | loss: 0.61366 - acc: 0.6696 -- iter: 0224/1593
[A[ATraining Step: 308  | total loss: [1m[32m0.61090[0m[0m | time: 4.606s
[2K
| RMSProp | epoch: 007 | loss: 0.61090 - acc: 0.6745 -- iter: 0256/1593
[A[ATraining Step: 309  | total loss: [1m[32m0.60018[0m[0m | time: 5.204s
[2K
| RMSProp | epoch: 007 | loss: 0.60018 - acc: 0.6852 -- iter: 0288/1593
[A[ATraining Step: 310  | total loss: [1m[32m0.59806[0m[0m | time: 5.810s
[2K
| RMSProp | epoch: 007 | loss: 0.59806 - acc: 0.6823 -- iter: 0320/1593
[A[ATraining Step: 311  | total loss: [1m[32m0.59957[0m[0m | time: 6.422s
[2K
| RMSProp | epoch: 007 | loss: 0.59957 - acc: 0.6797 -- iter: 0352/1593
[A[ATraining Step: 312  | total loss: [1m[32m0.60592[0m[0m | time: 7.028s
[2K
| RMSProp | epoch: 007 | loss: 0.60592 - acc: 0.6773 -- iter: 0384/1593
[A[ATraining Step: 313  | total loss: [1m[32m0.59622[0m[0m | time: 7.602s
[2K
| RMSProp | epoch: 007 | loss: 0.59622 - acc: 0.6877 -- iter: 0416/1593
[A[ATraining Step: 314  | total loss: [1m[32m0.60272[0m[0m | time: 8.201s
[2K
| RMSProp | epoch: 007 | loss: 0.60272 - acc: 0.6752 -- iter: 0448/1593
[A[ATraining Step: 315  | total loss: [1m[32m0.61073[0m[0m | time: 8.806s
[2K
| RMSProp | epoch: 007 | loss: 0.61073 - acc: 0.6546 -- iter: 0480/1593
[A[ATraining Step: 316  | total loss: [1m[32m0.61723[0m[0m | time: 9.442s
[2K
| RMSProp | epoch: 007 | loss: 0.61723 - acc: 0.6547 -- iter: 0512/1593
[A[ATraining Step: 317  | total loss: [1m[32m0.62046[0m[0m | time: 10.078s
[2K
| RMSProp | epoch: 007 | loss: 0.62046 - acc: 0.6486 -- iter: 0544/1593
[A[ATraining Step: 318  | total loss: [1m[32m0.61681[0m[0m | time: 10.711s
[2K
| RMSProp | epoch: 007 | loss: 0.61681 - acc: 0.6525 -- iter: 0576/1593
[A[ATraining Step: 319  | total loss: [1m[32m0.62509[0m[0m | time: 11.318s
[2K
| RMSProp | epoch: 007 | loss: 0.62509 - acc: 0.6560 -- iter: 0608/1593
[A[ATraining Step: 320  | total loss: [1m[32m0.61974[0m[0m | time: 11.944s
[2K
| RMSProp | epoch: 007 | loss: 0.61974 - acc: 0.6654 -- iter: 0640/1593
[A[ATraining Step: 321  | total loss: [1m[32m0.61322[0m[0m | time: 12.538s
[2K
| RMSProp | epoch: 007 | loss: 0.61322 - acc: 0.6739 -- iter: 0672/1593
[A[ATraining Step: 322  | total loss: [1m[32m0.61478[0m[0m | time: 13.145s
[2K
| RMSProp | epoch: 007 | loss: 0.61478 - acc: 0.6690 -- iter: 0704/1593
[A[ATraining Step: 323  | total loss: [1m[32m0.61163[0m[0m | time: 13.758s
[2K
| RMSProp | epoch: 007 | loss: 0.61163 - acc: 0.6740 -- iter: 0736/1593
[A[ATraining Step: 324  | total loss: [1m[32m0.60224[0m[0m | time: 14.351s
[2K
| RMSProp | epoch: 007 | loss: 0.60224 - acc: 0.6784 -- iter: 0768/1593
[A[ATraining Step: 325  | total loss: [1m[32m0.60478[0m[0m | time: 14.954s
[2K
| RMSProp | epoch: 007 | loss: 0.60478 - acc: 0.6793 -- iter: 0800/1593
[A[ATraining Step: 326  | total loss: [1m[32m0.61610[0m[0m | time: 15.547s
[2K
| RMSProp | epoch: 007 | loss: 0.61610 - acc: 0.6614 -- iter: 0832/1593
[A[ATraining Step: 327  | total loss: [1m[32m0.61878[0m[0m | time: 16.142s
[2K
| RMSProp | epoch: 007 | loss: 0.61878 - acc: 0.6609 -- iter: 0864/1593
[A[ATraining Step: 328  | total loss: [1m[32m0.61510[0m[0m | time: 16.733s
[2K
| RMSProp | epoch: 007 | loss: 0.61510 - acc: 0.6573 -- iter: 0896/1593
[A[ATraining Step: 329  | total loss: [1m[32m0.61849[0m[0m | time: 17.363s
[2K
| RMSProp | epoch: 007 | loss: 0.61849 - acc: 0.6478 -- iter: 0928/1593
[A[ATraining Step: 330  | total loss: [1m[32m0.62443[0m[0m | time: 18.007s
[2K
| RMSProp | epoch: 007 | loss: 0.62443 - acc: 0.6455 -- iter: 0960/1593
[A[ATraining Step: 331  | total loss: [1m[32m0.61747[0m[0m | time: 18.605s
[2K
| RMSProp | epoch: 007 | loss: 0.61747 - acc: 0.6591 -- iter: 0992/1593
[A[ATraining Step: 332  | total loss: [1m[32m0.61289[0m[0m | time: 19.207s
[2K
| RMSProp | epoch: 007 | loss: 0.61289 - acc: 0.6557 -- iter: 1024/1593
[A[ATraining Step: 333  | total loss: [1m[32m0.61234[0m[0m | time: 19.813s
[2K
| RMSProp | epoch: 007 | loss: 0.61234 - acc: 0.6589 -- iter: 1056/1593
[A[ATraining Step: 334  | total loss: [1m[32m0.62034[0m[0m | time: 20.419s
[2K
| RMSProp | epoch: 007 | loss: 0.62034 - acc: 0.6461 -- iter: 1088/1593
[A[ATraining Step: 335  | total loss: [1m[32m0.61756[0m[0m | time: 21.035s
[2K
| RMSProp | epoch: 007 | loss: 0.61756 - acc: 0.6534 -- iter: 1120/1593
[A[ATraining Step: 336  | total loss: [1m[32m0.60981[0m[0m | time: 21.622s
[2K
| RMSProp | epoch: 007 | loss: 0.60981 - acc: 0.6630 -- iter: 1152/1593
[A[ATraining Step: 337  | total loss: [1m[32m0.60933[0m[0m | time: 22.216s
[2K
| RMSProp | epoch: 007 | loss: 0.60933 - acc: 0.6592 -- iter: 1184/1593
[A[ATraining Step: 338  | total loss: [1m[32m0.59846[0m[0m | time: 22.804s
[2K
| RMSProp | epoch: 007 | loss: 0.59846 - acc: 0.6714 -- iter: 1216/1593
[A[ATraining Step: 339  | total loss: [1m[32m0.58408[0m[0m | time: 23.402s
[2K
| RMSProp | epoch: 007 | loss: 0.58408 - acc: 0.6855 -- iter: 1248/1593
[A[ATraining Step: 340  | total loss: [1m[32m0.58503[0m[0m | time: 23.998s
[2K
| RMSProp | epoch: 007 | loss: 0.58503 - acc: 0.6826 -- iter: 1280/1593
[A[ATraining Step: 341  | total loss: [1m[32m0.57703[0m[0m | time: 24.601s
[2K
| RMSProp | epoch: 007 | loss: 0.57703 - acc: 0.6956 -- iter: 1312/1593
[A[ATraining Step: 342  | total loss: [1m[32m0.58568[0m[0m | time: 25.194s
[2K
| RMSProp | epoch: 007 | loss: 0.58568 - acc: 0.6917 -- iter: 1344/1593
[A[ATraining Step: 343  | total loss: [1m[32m0.59587[0m[0m | time: 25.789s
[2K
| RMSProp | epoch: 007 | loss: 0.59587 - acc: 0.6850 -- iter: 1376/1593
[A[ATraining Step: 344  | total loss: [1m[32m0.59915[0m[0m | time: 26.393s
[2K
| RMSProp | epoch: 007 | loss: 0.59915 - acc: 0.6915 -- iter: 1408/1593
[A[ATraining Step: 345  | total loss: [1m[32m0.58823[0m[0m | time: 26.993s
[2K
| RMSProp | epoch: 007 | loss: 0.58823 - acc: 0.7036 -- iter: 1440/1593
[A[ATraining Step: 346  | total loss: [1m[32m0.59888[0m[0m | time: 27.603s
[2K
| RMSProp | epoch: 007 | loss: 0.59888 - acc: 0.6895 -- iter: 1472/1593
[A[ATraining Step: 347  | total loss: [1m[32m0.60387[0m[0m | time: 28.200s
[2K
| RMSProp | epoch: 007 | loss: 0.60387 - acc: 0.6799 -- iter: 1504/1593
[A[ATraining Step: 348  | total loss: [1m[32m0.60085[0m[0m | time: 28.809s
[2K
| RMSProp | epoch: 007 | loss: 0.60085 - acc: 0.6838 -- iter: 1536/1593
[A[ATraining Step: 349  | total loss: [1m[32m0.60630[0m[0m | time: 29.434s
[2K
| RMSProp | epoch: 007 | loss: 0.60630 - acc: 0.6810 -- iter: 1568/1593
[A[ATraining Step: 350  | total loss: [1m[32m0.59777[0m[0m | time: 31.631s
[2K
| RMSProp | epoch: 007 | loss: 0.59777 - acc: 0.7004 | val_loss: 0.66679 - val_acc: 0.5924 -- iter: 1593/1593
--
Training Step: 351  | total loss: [1m[32m0.59646[0m[0m | time: 0.601s
[2K
| RMSProp | epoch: 008 | loss: 0.59646 - acc: 0.6960 -- iter: 0032/1593
[A[ATraining Step: 352  | total loss: [1m[32m0.59193[0m[0m | time: 1.189s
[2K
| RMSProp | epoch: 008 | loss: 0.59193 - acc: 0.7014 -- iter: 0064/1593
[A[ATraining Step: 353  | total loss: [1m[32m0.58953[0m[0m | time: 1.786s
[2K
| RMSProp | epoch: 008 | loss: 0.58953 - acc: 0.7063 -- iter: 0096/1593
[A[ATraining Step: 354  | total loss: [1m[32m0.58872[0m[0m | time: 2.408s
[2K
| RMSProp | epoch: 008 | loss: 0.58872 - acc: 0.6981 -- iter: 0128/1593
[A[ATraining Step: 355  | total loss: [1m[32m0.59395[0m[0m | time: 3.009s
[2K
| RMSProp | epoch: 008 | loss: 0.59395 - acc: 0.6940 -- iter: 0160/1593
[A[ATraining Step: 356  | total loss: [1m[32m0.58836[0m[0m | time: 3.498s
[2K
| RMSProp | epoch: 008 | loss: 0.58836 - acc: 0.7058 -- iter: 0192/1593
[A[ATraining Step: 357  | total loss: [1m[32m0.59292[0m[0m | time: 3.972s
[2K
| RMSProp | epoch: 008 | loss: 0.59292 - acc: 0.6952 -- iter: 0224/1593
[A[ATraining Step: 358  | total loss: [1m[32m0.58885[0m[0m | time: 4.567s
[2K
| RMSProp | epoch: 008 | loss: 0.58885 - acc: 0.7017 -- iter: 0256/1593
[A[ATraining Step: 359  | total loss: [1m[32m0.59058[0m[0m | time: 5.163s
[2K
| RMSProp | epoch: 008 | loss: 0.59058 - acc: 0.6972 -- iter: 0288/1593
[A[ATraining Step: 360  | total loss: [1m[32m0.58254[0m[0m | time: 5.762s
[2K
| RMSProp | epoch: 008 | loss: 0.58254 - acc: 0.7118 -- iter: 0320/1593
[A[ATraining Step: 361  | total loss: [1m[32m0.58601[0m[0m | time: 6.362s
[2K
| RMSProp | epoch: 008 | loss: 0.58601 - acc: 0.7000 -- iter: 0352/1593
[A[ATraining Step: 362  | total loss: [1m[32m0.58350[0m[0m | time: 6.957s
[2K
| RMSProp | epoch: 008 | loss: 0.58350 - acc: 0.7081 -- iter: 0384/1593
[A[ATraining Step: 363  | total loss: [1m[32m0.57170[0m[0m | time: 7.551s
[2K
| RMSProp | epoch: 008 | loss: 0.57170 - acc: 0.7217 -- iter: 0416/1593
[A[ATraining Step: 364  | total loss: [1m[32m0.55704[0m[0m | time: 8.143s
[2K
| RMSProp | epoch: 008 | loss: 0.55704 - acc: 0.7277 -- iter: 0448/1593
[A[ATraining Step: 365  | total loss: [1m[32m0.56567[0m[0m | time: 8.719s
[2K
| RMSProp | epoch: 008 | loss: 0.56567 - acc: 0.7236 -- iter: 0480/1593
[A[ATraining Step: 366  | total loss: [1m[32m0.60818[0m[0m | time: 9.320s
[2K
| RMSProp | epoch: 008 | loss: 0.60818 - acc: 0.6950 -- iter: 0512/1593
[A[ATraining Step: 367  | total loss: [1m[32m0.59845[0m[0m | time: 9.917s
[2K
| RMSProp | epoch: 008 | loss: 0.59845 - acc: 0.7130 -- iter: 0544/1593
[A[ATraining Step: 368  | total loss: [1m[32m0.59443[0m[0m | time: 10.528s
[2K
| RMSProp | epoch: 008 | loss: 0.59443 - acc: 0.7105 -- iter: 0576/1593
[A[ATraining Step: 369  | total loss: [1m[32m0.59499[0m[0m | time: 11.128s
[2K
| RMSProp | epoch: 008 | loss: 0.59499 - acc: 0.7082 -- iter: 0608/1593
[A[ATraining Step: 370  | total loss: [1m[32m0.58248[0m[0m | time: 11.733s
[2K
| RMSProp | epoch: 008 | loss: 0.58248 - acc: 0.7186 -- iter: 0640/1593
[A[ATraining Step: 371  | total loss: [1m[32m0.59169[0m[0m | time: 12.339s
[2K
| RMSProp | epoch: 008 | loss: 0.59169 - acc: 0.7061 -- iter: 0672/1593
[A[ATraining Step: 372  | total loss: [1m[32m0.58862[0m[0m | time: 12.941s
[2K
| RMSProp | epoch: 008 | loss: 0.58862 - acc: 0.7074 -- iter: 0704/1593
[A[ATraining Step: 373  | total loss: [1m[32m0.58677[0m[0m | time: 13.571s
[2K
| RMSProp | epoch: 008 | loss: 0.58677 - acc: 0.7054 -- iter: 0736/1593
[A[ATraining Step: 374  | total loss: [1m[32m0.58020[0m[0m | time: 14.178s
[2K
| RMSProp | epoch: 008 | loss: 0.58020 - acc: 0.7130 -- iter: 0768/1593
[A[ATraining Step: 375  | total loss: [1m[32m0.56743[0m[0m | time: 14.799s
[2K
| RMSProp | epoch: 008 | loss: 0.56743 - acc: 0.7292 -- iter: 0800/1593
[A[ATraining Step: 376  | total loss: [1m[32m0.56447[0m[0m | time: 15.410s
[2K
| RMSProp | epoch: 008 | loss: 0.56447 - acc: 0.7250 -- iter: 0832/1593
[A[ATraining Step: 377  | total loss: [1m[32m0.55005[0m[0m | time: 16.002s
[2K
| RMSProp | epoch: 008 | loss: 0.55005 - acc: 0.7369 -- iter: 0864/1593
[A[ATraining Step: 378  | total loss: [1m[32m0.53334[0m[0m | time: 16.595s
[2K
| RMSProp | epoch: 008 | loss: 0.53334 - acc: 0.7444 -- iter: 0896/1593
[A[ATraining Step: 379  | total loss: [1m[32m0.54654[0m[0m | time: 17.200s
[2K
| RMSProp | epoch: 008 | loss: 0.54654 - acc: 0.7325 -- iter: 0928/1593
[A[ATraining Step: 380  | total loss: [1m[32m0.54407[0m[0m | time: 17.834s
[2K
| RMSProp | epoch: 008 | loss: 0.54407 - acc: 0.7343 -- iter: 0960/1593
[A[ATraining Step: 381  | total loss: [1m[32m0.55246[0m[0m | time: 18.443s
[2K
| RMSProp | epoch: 008 | loss: 0.55246 - acc: 0.7327 -- iter: 0992/1593
[A[ATraining Step: 382  | total loss: [1m[32m0.55374[0m[0m | time: 19.055s
[2K
| RMSProp | epoch: 008 | loss: 0.55374 - acc: 0.7251 -- iter: 1024/1593
[A[ATraining Step: 383  | total loss: [1m[32m0.55730[0m[0m | time: 19.652s
[2K
| RMSProp | epoch: 008 | loss: 0.55730 - acc: 0.7182 -- iter: 1056/1593
[A[ATraining Step: 384  | total loss: [1m[32m0.55254[0m[0m | time: 20.255s
[2K
| RMSProp | epoch: 008 | loss: 0.55254 - acc: 0.7276 -- iter: 1088/1593
[A[ATraining Step: 385  | total loss: [1m[32m0.54720[0m[0m | time: 20.856s
[2K
| RMSProp | epoch: 008 | loss: 0.54720 - acc: 0.7267 -- iter: 1120/1593
[A[ATraining Step: 386  | total loss: [1m[32m0.55260[0m[0m | time: 21.455s
[2K
| RMSProp | epoch: 008 | loss: 0.55260 - acc: 0.7166 -- iter: 1152/1593
[A[ATraining Step: 387  | total loss: [1m[32m0.55450[0m[0m | time: 22.067s
[2K
| RMSProp | epoch: 008 | loss: 0.55450 - acc: 0.7168 -- iter: 1184/1593
[A[ATraining Step: 388  | total loss: [1m[32m0.55423[0m[0m | time: 22.676s
[2K
| RMSProp | epoch: 008 | loss: 0.55423 - acc: 0.7138 -- iter: 1216/1593
[A[ATraining Step: 389  | total loss: [1m[32m0.55132[0m[0m | time: 23.278s
[2K
| RMSProp | epoch: 008 | loss: 0.55132 - acc: 0.7268 -- iter: 1248/1593
[A[ATraining Step: 390  | total loss: [1m[32m0.55060[0m[0m | time: 23.884s
[2K
| RMSProp | epoch: 008 | loss: 0.55060 - acc: 0.7323 -- iter: 1280/1593
[A[ATraining Step: 391  | total loss: [1m[32m0.55658[0m[0m | time: 24.489s
[2K
| RMSProp | epoch: 008 | loss: 0.55658 - acc: 0.7278 -- iter: 1312/1593
[A[ATraining Step: 392  | total loss: [1m[32m0.54844[0m[0m | time: 25.086s
[2K
| RMSProp | epoch: 008 | loss: 0.54844 - acc: 0.7300 -- iter: 1344/1593
[A[ATraining Step: 393  | total loss: [1m[32m0.53954[0m[0m | time: 25.683s
[2K
| RMSProp | epoch: 008 | loss: 0.53954 - acc: 0.7351 -- iter: 1376/1593
[A[ATraining Step: 394  | total loss: [1m[32m0.53202[0m[0m | time: 26.278s
[2K
| RMSProp | epoch: 008 | loss: 0.53202 - acc: 0.7429 -- iter: 1408/1593
[A[ATraining Step: 395  | total loss: [1m[32m0.52478[0m[0m | time: 26.887s
[2K
| RMSProp | epoch: 008 | loss: 0.52478 - acc: 0.7467 -- iter: 1440/1593
[A[ATraining Step: 396  | total loss: [1m[32m0.51864[0m[0m | time: 27.484s
[2K
| RMSProp | epoch: 008 | loss: 0.51864 - acc: 0.7564 -- iter: 1472/1593
[A[ATraining Step: 397  | total loss: [1m[32m0.50342[0m[0m | time: 28.086s
[2K
| RMSProp | epoch: 008 | loss: 0.50342 - acc: 0.7652 -- iter: 1504/1593
[A[ATraining Step: 398  | total loss: [1m[32m0.51241[0m[0m | time: 28.687s
[2K
| RMSProp | epoch: 008 | loss: 0.51241 - acc: 0.7636 -- iter: 1536/1593
[A[ATraining Step: 399  | total loss: [1m[32m0.54308[0m[0m | time: 29.283s
[2K
| RMSProp | epoch: 008 | loss: 0.54308 - acc: 0.7435 -- iter: 1568/1593
[A[ATraining Step: 400  | total loss: [1m[32m0.54436[0m[0m | time: 31.446s
[2K
| RMSProp | epoch: 008 | loss: 0.54436 - acc: 0.7442 | val_loss: 0.51416 - val_acc: 0.7570 -- iter: 1593/1593
--
Training Step: 401  | total loss: [1m[32m0.53298[0m[0m | time: 0.601s
[2K
| RMSProp | epoch: 009 | loss: 0.53298 - acc: 0.7573 -- iter: 0032/1593
[A[ATraining Step: 402  | total loss: [1m[32m0.51615[0m[0m | time: 1.204s
[2K
| RMSProp | epoch: 009 | loss: 0.51615 - acc: 0.7722 -- iter: 0064/1593
[A[ATraining Step: 403  | total loss: [1m[32m0.52166[0m[0m | time: 1.786s
[2K
| RMSProp | epoch: 009 | loss: 0.52166 - acc: 0.7668 -- iter: 0096/1593
[A[ATraining Step: 404  | total loss: [1m[32m0.51249[0m[0m | time: 2.398s
[2K
| RMSProp | epoch: 009 | loss: 0.51249 - acc: 0.7683 -- iter: 0128/1593
[A[ATraining Step: 405  | total loss: [1m[32m0.48667[0m[0m | time: 2.996s
[2K
| RMSProp | epoch: 009 | loss: 0.48667 - acc: 0.7821 -- iter: 0160/1593
[A[ATraining Step: 406  | total loss: [1m[32m0.48423[0m[0m | time: 3.596s
[2K
| RMSProp | epoch: 009 | loss: 0.48423 - acc: 0.7820 -- iter: 0192/1593
[A[ATraining Step: 407  | total loss: [1m[32m0.49732[0m[0m | time: 4.060s
[2K
| RMSProp | epoch: 009 | loss: 0.49732 - acc: 0.7725 -- iter: 0224/1593
[A[ATraining Step: 408  | total loss: [1m[32m0.51619[0m[0m | time: 4.536s
[2K
| RMSProp | epoch: 009 | loss: 0.51619 - acc: 0.7633 -- iter: 0256/1593
[A[ATraining Step: 409  | total loss: [1m[32m0.51388[0m[0m | time: 5.135s
[2K
| RMSProp | epoch: 009 | loss: 0.51388 - acc: 0.7629 -- iter: 0288/1593
[A[ATraining Step: 410  | total loss: [1m[32m0.50088[0m[0m | time: 5.733s
[2K
| RMSProp | epoch: 009 | loss: 0.50088 - acc: 0.7648 -- iter: 0320/1593
[A[ATraining Step: 411  | total loss: [1m[32m0.48870[0m[0m | time: 6.343s
[2K
| RMSProp | epoch: 009 | loss: 0.48870 - acc: 0.7758 -- iter: 0352/1593
[A[ATraining Step: 412  | total loss: [1m[32m0.48347[0m[0m | time: 6.956s
[2K
| RMSProp | epoch: 009 | loss: 0.48347 - acc: 0.7826 -- iter: 0384/1593
[A[ATraining Step: 413  | total loss: [1m[32m0.49118[0m[0m | time: 7.591s
[2K
| RMSProp | epoch: 009 | loss: 0.49118 - acc: 0.7731 -- iter: 0416/1593
[A[ATraining Step: 414  | total loss: [1m[32m0.49467[0m[0m | time: 8.222s
[2K
| RMSProp | epoch: 009 | loss: 0.49467 - acc: 0.7770 -- iter: 0448/1593
[A[ATraining Step: 415  | total loss: [1m[32m0.48030[0m[0m | time: 8.819s
[2K
| RMSProp | epoch: 009 | loss: 0.48030 - acc: 0.7806 -- iter: 0480/1593
[A[ATraining Step: 416  | total loss: [1m[32m0.46481[0m[0m | time: 9.419s
[2K
| RMSProp | epoch: 009 | loss: 0.46481 - acc: 0.7900 -- iter: 0512/1593
[A[ATraining Step: 417  | total loss: [1m[32m0.46367[0m[0m | time: 10.015s
[2K
| RMSProp | epoch: 009 | loss: 0.46367 - acc: 0.7860 -- iter: 0544/1593
[A[ATraining Step: 418  | total loss: [1m[32m0.46474[0m[0m | time: 10.621s
[2K
| RMSProp | epoch: 009 | loss: 0.46474 - acc: 0.7824 -- iter: 0576/1593
[A[ATraining Step: 419  | total loss: [1m[32m0.46120[0m[0m | time: 11.193s
[2K
| RMSProp | epoch: 009 | loss: 0.46120 - acc: 0.7885 -- iter: 0608/1593
[A[ATraining Step: 420  | total loss: [1m[32m0.44845[0m[0m | time: 11.800s
[2K
| RMSProp | epoch: 009 | loss: 0.44845 - acc: 0.7972 -- iter: 0640/1593
[A[ATraining Step: 421  | total loss: [1m[32m0.47771[0m[0m | time: 12.407s
[2K
| RMSProp | epoch: 009 | loss: 0.47771 - acc: 0.7831 -- iter: 0672/1593
[A[ATraining Step: 422  | total loss: [1m[32m0.47110[0m[0m | time: 13.031s
[2K
| RMSProp | epoch: 009 | loss: 0.47110 - acc: 0.7829 -- iter: 0704/1593
[A[ATraining Step: 423  | total loss: [1m[32m0.46982[0m[0m | time: 13.642s
[2K
| RMSProp | epoch: 009 | loss: 0.46982 - acc: 0.7796 -- iter: 0736/1593
[A[ATraining Step: 424  | total loss: [1m[32m0.48175[0m[0m | time: 14.234s
[2K
| RMSProp | epoch: 009 | loss: 0.48175 - acc: 0.7642 -- iter: 0768/1593
[A[ATraining Step: 425  | total loss: [1m[32m0.48828[0m[0m | time: 14.829s
[2K
| RMSProp | epoch: 009 | loss: 0.48828 - acc: 0.7596 -- iter: 0800/1593
[A[ATraining Step: 426  | total loss: [1m[32m0.49689[0m[0m | time: 15.427s
[2K
| RMSProp | epoch: 009 | loss: 0.49689 - acc: 0.7555 -- iter: 0832/1593
[A[ATraining Step: 427  | total loss: [1m[32m0.51236[0m[0m | time: 16.012s
[2K
| RMSProp | epoch: 009 | loss: 0.51236 - acc: 0.7425 -- iter: 0864/1593
[A[ATraining Step: 428  | total loss: [1m[32m0.50522[0m[0m | time: 16.610s
[2K
| RMSProp | epoch: 009 | loss: 0.50522 - acc: 0.7589 -- iter: 0896/1593
[A[ATraining Step: 429  | total loss: [1m[32m0.49948[0m[0m | time: 17.217s
[2K
| RMSProp | epoch: 009 | loss: 0.49948 - acc: 0.7673 -- iter: 0928/1593
[A[ATraining Step: 430  | total loss: [1m[32m0.49726[0m[0m | time: 17.813s
[2K
| RMSProp | epoch: 009 | loss: 0.49726 - acc: 0.7656 -- iter: 0960/1593
[A[ATraining Step: 431  | total loss: [1m[32m0.48736[0m[0m | time: 18.433s
[2K
| RMSProp | epoch: 009 | loss: 0.48736 - acc: 0.7734 -- iter: 0992/1593
[A[ATraining Step: 432  | total loss: [1m[32m0.47996[0m[0m | time: 19.063s
[2K
| RMSProp | epoch: 009 | loss: 0.47996 - acc: 0.7711 -- iter: 1024/1593
[A[ATraining Step: 433  | total loss: [1m[32m0.48186[0m[0m | time: 19.670s
[2K
| RMSProp | epoch: 009 | loss: 0.48186 - acc: 0.7690 -- iter: 1056/1593
[A[ATraining Step: 434  | total loss: [1m[32m0.48841[0m[0m | time: 20.268s
[2K
| RMSProp | epoch: 009 | loss: 0.48841 - acc: 0.7546 -- iter: 1088/1593
[A[ATraining Step: 435  | total loss: [1m[32m0.48726[0m[0m | time: 20.899s
[2K
| RMSProp | epoch: 009 | loss: 0.48726 - acc: 0.7572 -- iter: 1120/1593
[A[ATraining Step: 436  | total loss: [1m[32m0.48049[0m[0m | time: 21.506s
[2K
| RMSProp | epoch: 009 | loss: 0.48049 - acc: 0.7628 -- iter: 1152/1593
[A[ATraining Step: 437  | total loss: [1m[32m0.47183[0m[0m | time: 22.147s
[2K
| RMSProp | epoch: 009 | loss: 0.47183 - acc: 0.7709 -- iter: 1184/1593
[A[ATraining Step: 438  | total loss: [1m[32m0.46264[0m[0m | time: 22.768s
[2K
| RMSProp | epoch: 009 | loss: 0.46264 - acc: 0.7813 -- iter: 1216/1593
[A[ATraining Step: 439  | total loss: [1m[32m0.45415[0m[0m | time: 23.373s
[2K
| RMSProp | epoch: 009 | loss: 0.45415 - acc: 0.7875 -- iter: 1248/1593
[A[ATraining Step: 440  | total loss: [1m[32m0.43738[0m[0m | time: 23.975s
[2K
| RMSProp | epoch: 009 | loss: 0.43738 - acc: 0.7963 -- iter: 1280/1593
[A[ATraining Step: 441  | total loss: [1m[32m0.42078[0m[0m | time: 24.593s
[2K
| RMSProp | epoch: 009 | loss: 0.42078 - acc: 0.8041 -- iter: 1312/1593
[A[ATraining Step: 442  | total loss: [1m[32m0.42334[0m[0m | time: 25.207s
[2K
| RMSProp | epoch: 009 | loss: 0.42334 - acc: 0.8050 -- iter: 1344/1593
[A[ATraining Step: 443  | total loss: [1m[32m0.42057[0m[0m | time: 25.808s
[2K
| RMSProp | epoch: 009 | loss: 0.42057 - acc: 0.8120 -- iter: 1376/1593
[A[ATraining Step: 444  | total loss: [1m[32m0.41446[0m[0m | time: 26.400s
[2K
| RMSProp | epoch: 009 | loss: 0.41446 - acc: 0.8120 -- iter: 1408/1593
[A[ATraining Step: 445  | total loss: [1m[32m0.40663[0m[0m | time: 27.015s
[2K
| RMSProp | epoch: 009 | loss: 0.40663 - acc: 0.8152 -- iter: 1440/1593
[A[ATraining Step: 446  | total loss: [1m[32m0.40337[0m[0m | time: 27.668s
[2K
| RMSProp | epoch: 009 | loss: 0.40337 - acc: 0.8149 -- iter: 1472/1593
[A[ATraining Step: 447  | total loss: [1m[32m0.39653[0m[0m | time: 28.269s
[2K
| RMSProp | epoch: 009 | loss: 0.39653 - acc: 0.8209 -- iter: 1504/1593
[A[ATraining Step: 448  | total loss: [1m[32m0.41402[0m[0m | time: 28.862s
[2K
| RMSProp | epoch: 009 | loss: 0.41402 - acc: 0.8107 -- iter: 1536/1593
[A[ATraining Step: 449  | total loss: [1m[32m0.40906[0m[0m | time: 29.466s
[2K
| RMSProp | epoch: 009 | loss: 0.40906 - acc: 0.8172 -- iter: 1568/1593
[A[ATraining Step: 450  | total loss: [1m[32m0.40832[0m[0m | time: 31.605s
[2K
| RMSProp | epoch: 009 | loss: 0.40832 - acc: 0.8167 | val_loss: 0.50470 - val_acc: 0.7570 -- iter: 1593/1593
--
Training Step: 451  | total loss: [1m[32m0.41631[0m[0m | time: 0.593s
[2K
| RMSProp | epoch: 010 | loss: 0.41631 - acc: 0.8100 -- iter: 0032/1593
[A[ATraining Step: 452  | total loss: [1m[32m0.42429[0m[0m | time: 1.196s
[2K
| RMSProp | epoch: 010 | loss: 0.42429 - acc: 0.8009 -- iter: 0064/1593
[A[ATraining Step: 453  | total loss: [1m[32m0.41504[0m[0m | time: 1.784s
[2K
| RMSProp | epoch: 010 | loss: 0.41504 - acc: 0.8083 -- iter: 0096/1593
[A[ATraining Step: 454  | total loss: [1m[32m0.40564[0m[0m | time: 2.395s
[2K
| RMSProp | epoch: 010 | loss: 0.40564 - acc: 0.8181 -- iter: 0128/1593
[A[ATraining Step: 455  | total loss: [1m[32m0.38944[0m[0m | time: 2.989s
[2K
| RMSProp | epoch: 010 | loss: 0.38944 - acc: 0.8238 -- iter: 0160/1593
[A[ATraining Step: 456  | total loss: [1m[32m0.39721[0m[0m | time: 3.585s
[2K
| RMSProp | epoch: 010 | loss: 0.39721 - acc: 0.8195 -- iter: 0192/1593
[A[ATraining Step: 457  | total loss: [1m[32m0.39936[0m[0m | time: 4.189s
[2K
| RMSProp | epoch: 010 | loss: 0.39936 - acc: 0.8157 -- iter: 0224/1593
[A[ATraining Step: 458  | total loss: [1m[32m0.40158[0m[0m | time: 4.672s
[2K
| RMSProp | epoch: 010 | loss: 0.40158 - acc: 0.8091 -- iter: 0256/1593
[A[ATraining Step: 459  | total loss: [1m[32m0.42371[0m[0m | time: 5.180s
[2K
| RMSProp | epoch: 010 | loss: 0.42371 - acc: 0.7922 -- iter: 0288/1593
[A[ATraining Step: 460  | total loss: [1m[32m0.42518[0m[0m | time: 5.781s
[2K
| RMSProp | epoch: 010 | loss: 0.42518 - acc: 0.7890 -- iter: 0320/1593
[A[ATraining Step: 461  | total loss: [1m[32m0.45215[0m[0m | time: 6.378s
[2K
| RMSProp | epoch: 010 | loss: 0.45215 - acc: 0.7726 -- iter: 0352/1593
[A[ATraining Step: 462  | total loss: [1m[32m0.45041[0m[0m | time: 6.974s
[2K
| RMSProp | epoch: 010 | loss: 0.45041 - acc: 0.7766 -- iter: 0384/1593
[A[ATraining Step: 463  | total loss: [1m[32m0.44359[0m[0m | time: 7.578s
[2K
| RMSProp | epoch: 010 | loss: 0.44359 - acc: 0.7833 -- iter: 0416/1593
[A[ATraining Step: 464  | total loss: [1m[32m0.44059[0m[0m | time: 8.172s
[2K
| RMSProp | epoch: 010 | loss: 0.44059 - acc: 0.7893 -- iter: 0448/1593
[A[ATraining Step: 465  | total loss: [1m[32m0.44021[0m[0m | time: 8.765s
[2K
| RMSProp | epoch: 010 | loss: 0.44021 - acc: 0.7948 -- iter: 0480/1593
[A[ATraining Step: 466  | total loss: [1m[32m0.43480[0m[0m | time: 9.368s
[2K
| RMSProp | epoch: 010 | loss: 0.43480 - acc: 0.7997 -- iter: 0512/1593
[A[ATraining Step: 467  | total loss: [1m[32m0.41782[0m[0m | time: 10.000s
[2K
| RMSProp | epoch: 010 | loss: 0.41782 - acc: 0.8103 -- iter: 0544/1593
[A[ATraining Step: 468  | total loss: [1m[32m0.41815[0m[0m | time: 10.619s
[2K
| RMSProp | epoch: 010 | loss: 0.41815 - acc: 0.8168 -- iter: 0576/1593
[A[ATraining Step: 469  | total loss: [1m[32m0.41443[0m[0m | time: 11.224s
[2K
| RMSProp | epoch: 010 | loss: 0.41443 - acc: 0.8195 -- iter: 0608/1593
[A[ATraining Step: 470  | total loss: [1m[32m0.43891[0m[0m | time: 11.833s
[2K
| RMSProp | epoch: 010 | loss: 0.43891 - acc: 0.8032 -- iter: 0640/1593
[A[ATraining Step: 471  | total loss: [1m[32m0.43544[0m[0m | time: 12.441s
[2K
| RMSProp | epoch: 010 | loss: 0.43544 - acc: 0.8104 -- iter: 0672/1593
[A[ATraining Step: 472  | total loss: [1m[32m0.42985[0m[0m | time: 13.045s
[2K
| RMSProp | epoch: 010 | loss: 0.42985 - acc: 0.8137 -- iter: 0704/1593
[A[ATraining Step: 473  | total loss: [1m[32m0.41615[0m[0m | time: 13.659s
[2K
| RMSProp | epoch: 010 | loss: 0.41615 - acc: 0.8230 -- iter: 0736/1593
[A[ATraining Step: 474  | total loss: [1m[32m0.41701[0m[0m | time: 14.246s
[2K
| RMSProp | epoch: 010 | loss: 0.41701 - acc: 0.8282 -- iter: 0768/1593
[A[ATraining Step: 475  | total loss: [1m[32m0.41082[0m[0m | time: 14.850s
[2K
| RMSProp | epoch: 010 | loss: 0.41082 - acc: 0.8297 -- iter: 0800/1593
[A[ATraining Step: 476  | total loss: [1m[32m0.40310[0m[0m | time: 15.466s
[2K
| RMSProp | epoch: 010 | loss: 0.40310 - acc: 0.8311 -- iter: 0832/1593
[A[ATraining Step: 477  | total loss: [1m[32m0.40015[0m[0m | time: 16.056s
[2K
| RMSProp | epoch: 010 | loss: 0.40015 - acc: 0.8293 -- iter: 0864/1593
[A[ATraining Step: 478  | total loss: [1m[32m0.41132[0m[0m | time: 16.636s
[2K
| RMSProp | epoch: 010 | loss: 0.41132 - acc: 0.8182 -- iter: 0896/1593
[A[ATraining Step: 479  | total loss: [1m[32m0.40896[0m[0m | time: 17.232s
[2K
| RMSProp | epoch: 010 | loss: 0.40896 - acc: 0.8208 -- iter: 0928/1593
[A[ATraining Step: 480  | total loss: [1m[32m0.39357[0m[0m | time: 17.829s
[2K
| RMSProp | epoch: 010 | loss: 0.39357 - acc: 0.8324 -- iter: 0960/1593
[A[ATraining Step: 481  | total loss: [1m[32m0.39080[0m[0m | time: 18.421s
[2K
| RMSProp | epoch: 010 | loss: 0.39080 - acc: 0.8336 -- iter: 0992/1593
[A[ATraining Step: 482  | total loss: [1m[32m0.38227[0m[0m | time: 19.021s
[2K
| RMSProp | epoch: 010 | loss: 0.38227 - acc: 0.8440 -- iter: 1024/1593
[A[ATraining Step: 483  | total loss: [1m[32m0.36184[0m[0m | time: 19.623s
[2K
| RMSProp | epoch: 010 | loss: 0.36184 - acc: 0.8564 -- iter: 1056/1593
[A[ATraining Step: 484  | total loss: [1m[32m0.35013[0m[0m | time: 20.262s
[2K
| RMSProp | epoch: 010 | loss: 0.35013 - acc: 0.8614 -- iter: 1088/1593
[A[ATraining Step: 485  | total loss: [1m[32m0.35400[0m[0m | time: 20.864s
[2K
| RMSProp | epoch: 010 | loss: 0.35400 - acc: 0.8534 -- iter: 1120/1593
[A[ATraining Step: 486  | total loss: [1m[32m0.34604[0m[0m | time: 21.474s
[2K
| RMSProp | epoch: 010 | loss: 0.34604 - acc: 0.8524 -- iter: 1152/1593
[A[ATraining Step: 487  | total loss: [1m[32m0.34895[0m[0m | time: 22.061s
[2K
| RMSProp | epoch: 010 | loss: 0.34895 - acc: 0.8484 -- iter: 1184/1593
[A[ATraining Step: 488  | total loss: [1m[32m0.40064[0m[0m | time: 22.656s
[2K
| RMSProp | epoch: 010 | loss: 0.40064 - acc: 0.8230 -- iter: 1216/1593
[A[ATraining Step: 489  | total loss: [1m[32m0.40151[0m[0m | time: 23.268s
[2K
| RMSProp | epoch: 010 | loss: 0.40151 - acc: 0.8282 -- iter: 1248/1593
[A[ATraining Step: 490  | total loss: [1m[32m0.38582[0m[0m | time: 23.864s
[2K
| RMSProp | epoch: 010 | loss: 0.38582 - acc: 0.8391 -- iter: 1280/1593
[A[ATraining Step: 491  | total loss: [1m[32m0.36659[0m[0m | time: 24.469s
[2K
| RMSProp | epoch: 010 | loss: 0.36659 - acc: 0.8458 -- iter: 1312/1593
[A[ATraining Step: 492  | total loss: [1m[32m0.38312[0m[0m | time: 25.087s
[2K
| RMSProp | epoch: 010 | loss: 0.38312 - acc: 0.8331 -- iter: 1344/1593
[A[ATraining Step: 493  | total loss: [1m[32m0.38622[0m[0m | time: 25.698s
[2K
| RMSProp | epoch: 010 | loss: 0.38622 - acc: 0.8279 -- iter: 1376/1593
[A[ATraining Step: 494  | total loss: [1m[32m0.38973[0m[0m | time: 26.302s
[2K
| RMSProp | epoch: 010 | loss: 0.38973 - acc: 0.8233 -- iter: 1408/1593
[A[ATraining Step: 495  | total loss: [1m[32m0.37583[0m[0m | time: 26.918s
[2K
| RMSProp | epoch: 010 | loss: 0.37583 - acc: 0.8316 -- iter: 1440/1593
[A[ATraining Step: 496  | total loss: [1m[32m0.36063[0m[0m | time: 27.519s
[2K
| RMSProp | epoch: 010 | loss: 0.36063 - acc: 0.8484 -- iter: 1472/1593
[A[ATraining Step: 497  | total loss: [1m[32m0.34444[0m[0m | time: 28.116s
[2K
| RMSProp | epoch: 010 | loss: 0.34444 - acc: 0.8573 -- iter: 1504/1593
[A[ATraining Step: 498  | total loss: [1m[32m0.32522[0m[0m | time: 28.730s
[2K
| RMSProp | epoch: 010 | loss: 0.32522 - acc: 0.8653 -- iter: 1536/1593
[A[ATraining Step: 499  | total loss: [1m[32m0.31152[0m[0m | time: 29.355s
[2K
| RMSProp | epoch: 010 | loss: 0.31152 - acc: 0.8725 -- iter: 1568/1593
[A[ATraining Step: 500  | total loss: [1m[32m0.30438[0m[0m | time: 31.539s
[2K
| RMSProp | epoch: 010 | loss: 0.30438 - acc: 0.8759 | val_loss: 0.51157 - val_acc: 0.7992 -- iter: 1593/1593
--
Training Step: 501  | total loss: [1m[32m0.29250[0m[0m | time: 0.598s
[2K
| RMSProp | epoch: 011 | loss: 0.29250 - acc: 0.8821 -- iter: 0032/1593
[A[ATraining Step: 502  | total loss: [1m[32m0.29309[0m[0m | time: 1.207s
[2K
| RMSProp | epoch: 011 | loss: 0.29309 - acc: 0.8751 -- iter: 0064/1593
[A[ATraining Step: 503  | total loss: [1m[32m0.33626[0m[0m | time: 1.805s
[2K
| RMSProp | epoch: 011 | loss: 0.33626 - acc: 0.8564 -- iter: 0096/1593
[A[ATraining Step: 504  | total loss: [1m[32m0.33871[0m[0m | time: 2.404s
[2K
| RMSProp | epoch: 011 | loss: 0.33871 - acc: 0.8551 -- iter: 0128/1593
[A[ATraining Step: 505  | total loss: [1m[32m0.35949[0m[0m | time: 2.998s
[2K
| RMSProp | epoch: 011 | loss: 0.35949 - acc: 0.8446 -- iter: 0160/1593
[A[ATraining Step: 506  | total loss: [1m[32m0.36959[0m[0m | time: 3.596s
[2K
| RMSProp | epoch: 011 | loss: 0.36959 - acc: 0.8351 -- iter: 0192/1593
[A[ATraining Step: 507  | total loss: [1m[32m0.35905[0m[0m | time: 4.209s
[2K
| RMSProp | epoch: 011 | loss: 0.35905 - acc: 0.8454 -- iter: 0224/1593
[A[ATraining Step: 508  | total loss: [1m[32m0.34631[0m[0m | time: 4.807s
[2K
| RMSProp | epoch: 011 | loss: 0.34631 - acc: 0.8546 -- iter: 0256/1593
[A[ATraining Step: 509  | total loss: [1m[32m0.33247[0m[0m | time: 5.287s
[2K
| RMSProp | epoch: 011 | loss: 0.33247 - acc: 0.8629 -- iter: 0288/1593
[A[ATraining Step: 510  | total loss: [1m[32m0.33492[0m[0m | time: 5.764s
[2K
| RMSProp | epoch: 011 | loss: 0.33492 - acc: 0.8646 -- iter: 0320/1593
[A[ATraining Step: 511  | total loss: [1m[32m0.31684[0m[0m | time: 6.364s
[2K
| RMSProp | epoch: 011 | loss: 0.31684 - acc: 0.8781 -- iter: 0352/1593
[A[ATraining Step: 512  | total loss: [1m[32m0.29977[0m[0m | time: 6.972s
[2K
| RMSProp | epoch: 011 | loss: 0.29977 - acc: 0.8872 -- iter: 0384/1593
[A[ATraining Step: 513  | total loss: [1m[32m0.29956[0m[0m | time: 7.563s
[2K
| RMSProp | epoch: 011 | loss: 0.29956 - acc: 0.8828 -- iter: 0416/1593
[A[ATraining Step: 514  | total loss: [1m[32m0.28492[0m[0m | time: 8.157s
[2K
| RMSProp | epoch: 011 | loss: 0.28492 - acc: 0.8914 -- iter: 0448/1593
[A[ATraining Step: 515  | total loss: [1m[32m0.29931[0m[0m | time: 8.750s
[2K
| RMSProp | epoch: 011 | loss: 0.29931 - acc: 0.8898 -- iter: 0480/1593
[A[ATraining Step: 516  | total loss: [1m[32m0.32754[0m[0m | time: 9.346s
[2K
| RMSProp | epoch: 011 | loss: 0.32754 - acc: 0.8727 -- iter: 0512/1593
[A[ATraining Step: 517  | total loss: [1m[32m0.33154[0m[0m | time: 9.941s
[2K
| RMSProp | epoch: 011 | loss: 0.33154 - acc: 0.8667 -- iter: 0544/1593
[A[ATraining Step: 518  | total loss: [1m[32m0.31502[0m[0m | time: 10.537s
[2K
| RMSProp | epoch: 011 | loss: 0.31502 - acc: 0.8738 -- iter: 0576/1593
[A[ATraining Step: 519  | total loss: [1m[32m0.32478[0m[0m | time: 11.147s
[2K
| RMSProp | epoch: 011 | loss: 0.32478 - acc: 0.8676 -- iter: 0608/1593
[A[ATraining Step: 520  | total loss: [1m[32m0.32609[0m[0m | time: 11.776s
[2K
| RMSProp | epoch: 011 | loss: 0.32609 - acc: 0.8621 -- iter: 0640/1593
[A[ATraining Step: 521  | total loss: [1m[32m0.33350[0m[0m | time: 12.394s
[2K
| RMSProp | epoch: 011 | loss: 0.33350 - acc: 0.8603 -- iter: 0672/1593
[A[ATraining Step: 522  | total loss: [1m[32m0.34374[0m[0m | time: 12.985s
[2K
| RMSProp | epoch: 011 | loss: 0.34374 - acc: 0.8555 -- iter: 0704/1593
[A[ATraining Step: 523  | total loss: [1m[32m0.35414[0m[0m | time: 13.595s
[2K
| RMSProp | epoch: 011 | loss: 0.35414 - acc: 0.8449 -- iter: 0736/1593
[A[ATraining Step: 524  | total loss: [1m[32m0.35538[0m[0m | time: 14.205s
[2K
| RMSProp | epoch: 011 | loss: 0.35538 - acc: 0.8417 -- iter: 0768/1593
[A[ATraining Step: 525  | total loss: [1m[32m0.37560[0m[0m | time: 14.818s
[2K
| RMSProp | epoch: 011 | loss: 0.37560 - acc: 0.8294 -- iter: 0800/1593
[A[ATraining Step: 526  | total loss: [1m[32m0.37260[0m[0m | time: 15.411s
[2K
| RMSProp | epoch: 011 | loss: 0.37260 - acc: 0.8308 -- iter: 0832/1593
[A[ATraining Step: 527  | total loss: [1m[32m0.35178[0m[0m | time: 16.014s
[2K
| RMSProp | epoch: 011 | loss: 0.35178 - acc: 0.8478 -- iter: 0864/1593
[A[ATraining Step: 528  | total loss: [1m[32m0.33526[0m[0m | time: 16.600s
[2K
| RMSProp | epoch: 011 | loss: 0.33526 - acc: 0.8599 -- iter: 0896/1593
[A[ATraining Step: 529  | total loss: [1m[32m0.33499[0m[0m | time: 17.209s
[2K
| RMSProp | epoch: 011 | loss: 0.33499 - acc: 0.8676 -- iter: 0928/1593
[A[ATraining Step: 530  | total loss: [1m[32m0.33224[0m[0m | time: 17.813s
[2K
| RMSProp | epoch: 011 | loss: 0.33224 - acc: 0.8684 -- iter: 0960/1593
[A[ATraining Step: 531  | total loss: [1m[32m0.31931[0m[0m | time: 18.418s
[2K
| RMSProp | epoch: 011 | loss: 0.31931 - acc: 0.8753 -- iter: 0992/1593
[A[ATraining Step: 532  | total loss: [1m[32m0.30809[0m[0m | time: 19.007s
[2K
| RMSProp | epoch: 011 | loss: 0.30809 - acc: 0.8815 -- iter: 1024/1593
[A[ATraining Step: 533  | total loss: [1m[32m0.29570[0m[0m | time: 19.607s
[2K
| RMSProp | epoch: 011 | loss: 0.29570 - acc: 0.8871 -- iter: 1056/1593
[A[ATraining Step: 534  | total loss: [1m[32m0.29762[0m[0m | time: 20.201s
[2K
| RMSProp | epoch: 011 | loss: 0.29762 - acc: 0.8859 -- iter: 1088/1593
[A[ATraining Step: 535  | total loss: [1m[32m0.30182[0m[0m | time: 20.820s
[2K
| RMSProp | epoch: 011 | loss: 0.30182 - acc: 0.8817 -- iter: 1120/1593
[A[ATraining Step: 536  | total loss: [1m[32m0.29801[0m[0m | time: 21.422s
[2K
| RMSProp | epoch: 011 | loss: 0.29801 - acc: 0.8841 -- iter: 1152/1593
[A[ATraining Step: 537  | total loss: [1m[32m0.29210[0m[0m | time: 22.039s
[2K
| RMSProp | epoch: 011 | loss: 0.29210 - acc: 0.8895 -- iter: 1184/1593
[A[ATraining Step: 538  | total loss: [1m[32m0.27952[0m[0m | time: 22.634s
[2K
| RMSProp | epoch: 011 | loss: 0.27952 - acc: 0.8974 -- iter: 1216/1593
[A[ATraining Step: 539  | total loss: [1m[32m0.26643[0m[0m | time: 23.223s
[2K
| RMSProp | epoch: 011 | loss: 0.26643 - acc: 0.9014 -- iter: 1248/1593
[A[ATraining Step: 540  | total loss: [1m[32m0.25538[0m[0m | time: 23.829s
[2K
| RMSProp | epoch: 011 | loss: 0.25538 - acc: 0.9050 -- iter: 1280/1593
[A[ATraining Step: 541  | total loss: [1m[32m0.26513[0m[0m | time: 24.446s
[2K
| RMSProp | epoch: 011 | loss: 0.26513 - acc: 0.9051 -- iter: 1312/1593
[A[ATraining Step: 542  | total loss: [1m[32m0.31368[0m[0m | time: 25.045s
[2K
| RMSProp | epoch: 011 | loss: 0.31368 - acc: 0.8834 -- iter: 1344/1593
[A[ATraining Step: 543  | total loss: [1m[32m0.30375[0m[0m | time: 25.630s
[2K
| RMSProp | epoch: 011 | loss: 0.30375 - acc: 0.8857 -- iter: 1376/1593
[A[ATraining Step: 544  | total loss: [1m[32m0.28947[0m[0m | time: 26.227s
[2K
| RMSProp | epoch: 011 | loss: 0.28947 - acc: 0.8908 -- iter: 1408/1593
[A[ATraining Step: 545  | total loss: [1m[32m0.28609[0m[0m | time: 26.818s
[2K
| RMSProp | epoch: 011 | loss: 0.28609 - acc: 0.8924 -- iter: 1440/1593
[A[ATraining Step: 546  | total loss: [1m[32m0.28856[0m[0m | time: 27.417s
[2K
| RMSProp | epoch: 011 | loss: 0.28856 - acc: 0.8875 -- iter: 1472/1593
[A[ATraining Step: 547  | total loss: [1m[32m0.29874[0m[0m | time: 28.013s
[2K
| RMSProp | epoch: 011 | loss: 0.29874 - acc: 0.8800 -- iter: 1504/1593
[A[ATraining Step: 548  | total loss: [1m[32m0.31642[0m[0m | time: 28.618s
[2K
| RMSProp | epoch: 011 | loss: 0.31642 - acc: 0.8701 -- iter: 1536/1593
[A[ATraining Step: 549  | total loss: [1m[32m0.30815[0m[0m | time: 29.204s
[2K
| RMSProp | epoch: 011 | loss: 0.30815 - acc: 0.8706 -- iter: 1568/1593
[A[ATraining Step: 550  | total loss: [1m[32m0.29649[0m[0m | time: 31.354s
[2K
| RMSProp | epoch: 011 | loss: 0.29649 - acc: 0.8804 | val_loss: 0.43450 - val_acc: 0.8112 -- iter: 1593/1593
--
Training Step: 551  | total loss: [1m[32m0.28087[0m[0m | time: 0.602s
[2K
| RMSProp | epoch: 012 | loss: 0.28087 - acc: 0.8893 -- iter: 0032/1593
[A[ATraining Step: 552  | total loss: [1m[32m0.26702[0m[0m | time: 1.203s
[2K
| RMSProp | epoch: 012 | loss: 0.26702 - acc: 0.8941 -- iter: 0064/1593
[A[ATraining Step: 553  | total loss: [1m[32m0.29229[0m[0m | time: 1.808s
[2K
| RMSProp | epoch: 012 | loss: 0.29229 - acc: 0.8891 -- iter: 0096/1593
[A[ATraining Step: 554  | total loss: [1m[32m0.29886[0m[0m | time: 2.412s
[2K
| RMSProp | epoch: 012 | loss: 0.29886 - acc: 0.8845 -- iter: 0128/1593
[A[ATraining Step: 555  | total loss: [1m[32m0.28436[0m[0m | time: 3.011s
[2K
| RMSProp | epoch: 012 | loss: 0.28436 - acc: 0.8930 -- iter: 0160/1593
[A[ATraining Step: 556  | total loss: [1m[32m0.26336[0m[0m | time: 3.617s
[2K
| RMSProp | epoch: 012 | loss: 0.26336 - acc: 0.9037 -- iter: 0192/1593
[A[ATraining Step: 557  | total loss: [1m[32m0.26720[0m[0m | time: 4.233s
[2K
| RMSProp | epoch: 012 | loss: 0.26720 - acc: 0.9008 -- iter: 0224/1593
[A[ATraining Step: 558  | total loss: [1m[32m0.26327[0m[0m | time: 4.840s
[2K
| RMSProp | epoch: 012 | loss: 0.26327 - acc: 0.9013 -- iter: 0256/1593
[A[ATraining Step: 559  | total loss: [1m[32m0.27554[0m[0m | time: 5.442s
[2K
| RMSProp | epoch: 012 | loss: 0.27554 - acc: 0.8956 -- iter: 0288/1593
[A[ATraining Step: 560  | total loss: [1m[32m0.31102[0m[0m | time: 5.925s
[2K
| RMSProp | epoch: 012 | loss: 0.31102 - acc: 0.8716 -- iter: 0320/1593
[A[ATraining Step: 561  | total loss: [1m[32m0.29942[0m[0m | time: 6.409s
[2K
| RMSProp | epoch: 012 | loss: 0.29942 - acc: 0.8765 -- iter: 0352/1593
[A[ATraining Step: 562  | total loss: [1m[32m0.27499[0m[0m | time: 7.012s
[2K
| RMSProp | epoch: 012 | loss: 0.27499 - acc: 0.8888 -- iter: 0384/1593
[A[ATraining Step: 563  | total loss: [1m[32m0.25943[0m[0m | time: 7.606s
[2K
| RMSProp | epoch: 012 | loss: 0.25943 - acc: 0.8937 -- iter: 0416/1593
[A[ATraining Step: 564  | total loss: [1m[32m0.24083[0m[0m | time: 8.212s
[2K
| RMSProp | epoch: 012 | loss: 0.24083 - acc: 0.9043 -- iter: 0448/1593
[A[ATraining Step: 565  | total loss: [1m[32m0.24347[0m[0m | time: 8.811s
[2K
| RMSProp | epoch: 012 | loss: 0.24347 - acc: 0.9076 -- iter: 0480/1593
[A[ATraining Step: 566  | total loss: [1m[32m0.23915[0m[0m | time: 9.430s
[2K
| RMSProp | epoch: 012 | loss: 0.23915 - acc: 0.9106 -- iter: 0512/1593
[A[ATraining Step: 567  | total loss: [1m[32m0.24045[0m[0m | time: 10.050s
[2K
| RMSProp | epoch: 012 | loss: 0.24045 - acc: 0.9071 -- iter: 0544/1593
[A[ATraining Step: 568  | total loss: [1m[32m0.23379[0m[0m | time: 10.660s
[2K
| RMSProp | epoch: 012 | loss: 0.23379 - acc: 0.9132 -- iter: 0576/1593
[A[ATraining Step: 569  | total loss: [1m[32m0.21551[0m[0m | time: 11.262s
[2K
| RMSProp | epoch: 012 | loss: 0.21551 - acc: 0.9219 -- iter: 0608/1593
[A[ATraining Step: 570  | total loss: [1m[32m0.22512[0m[0m | time: 11.870s
[2K
| RMSProp | epoch: 012 | loss: 0.22512 - acc: 0.9172 -- iter: 0640/1593
[A[ATraining Step: 571  | total loss: [1m[32m0.22492[0m[0m | time: 12.478s
[2K
| RMSProp | epoch: 012 | loss: 0.22492 - acc: 0.9130 -- iter: 0672/1593
[A[ATraining Step: 572  | total loss: [1m[32m0.26629[0m[0m | time: 13.079s
[2K
| RMSProp | epoch: 012 | loss: 0.26629 - acc: 0.8873 -- iter: 0704/1593
[A[ATraining Step: 573  | total loss: [1m[32m0.26493[0m[0m | time: 13.670s
[2K
| RMSProp | epoch: 012 | loss: 0.26493 - acc: 0.8892 -- iter: 0736/1593
[A[ATraining Step: 574  | total loss: [1m[32m0.25634[0m[0m | time: 14.273s
[2K
| RMSProp | epoch: 012 | loss: 0.25634 - acc: 0.8972 -- iter: 0768/1593
[A[ATraining Step: 575  | total loss: [1m[32m0.25340[0m[0m | time: 14.881s
[2K
| RMSProp | epoch: 012 | loss: 0.25340 - acc: 0.8981 -- iter: 0800/1593
[A[ATraining Step: 576  | total loss: [1m[32m0.25705[0m[0m | time: 15.487s
[2K
| RMSProp | epoch: 012 | loss: 0.25705 - acc: 0.8895 -- iter: 0832/1593
[A[ATraining Step: 577  | total loss: [1m[32m0.26381[0m[0m | time: 16.086s
[2K
| RMSProp | epoch: 012 | loss: 0.26381 - acc: 0.8912 -- iter: 0864/1593
[A[ATraining Step: 578  | total loss: [1m[32m0.27364[0m[0m | time: 16.672s
[2K
| RMSProp | epoch: 012 | loss: 0.27364 - acc: 0.8864 -- iter: 0896/1593
[A[ATraining Step: 579  | total loss: [1m[32m0.27761[0m[0m | time: 17.275s
[2K
| RMSProp | epoch: 012 | loss: 0.27761 - acc: 0.8822 -- iter: 0928/1593
[A[ATraining Step: 580  | total loss: [1m[32m0.29003[0m[0m | time: 17.876s
[2K
| RMSProp | epoch: 012 | loss: 0.29003 - acc: 0.8783 -- iter: 0960/1593
[A[ATraining Step: 581  | total loss: [1m[32m0.28815[0m[0m | time: 18.467s
[2K
| RMSProp | epoch: 012 | loss: 0.28815 - acc: 0.8811 -- iter: 0992/1593
[A[ATraining Step: 582  | total loss: [1m[32m0.27349[0m[0m | time: 19.078s
[2K
| RMSProp | epoch: 012 | loss: 0.27349 - acc: 0.8868 -- iter: 1024/1593
[A[ATraining Step: 583  | total loss: [1m[32m0.25813[0m[0m | time: 19.669s
[2K
| RMSProp | epoch: 012 | loss: 0.25813 - acc: 0.8950 -- iter: 1056/1593
[A[ATraining Step: 584  | total loss: [1m[32m0.25318[0m[0m | time: 20.264s
[2K
| RMSProp | epoch: 012 | loss: 0.25318 - acc: 0.8961 -- iter: 1088/1593
[A[ATraining Step: 585  | total loss: [1m[32m0.23864[0m[0m | time: 20.879s
[2K
| RMSProp | epoch: 012 | loss: 0.23864 - acc: 0.9034 -- iter: 1120/1593
[A[ATraining Step: 586  | total loss: [1m[32m0.22607[0m[0m | time: 21.477s
[2K
| RMSProp | epoch: 012 | loss: 0.22607 - acc: 0.9099 -- iter: 1152/1593
[A[ATraining Step: 587  | total loss: [1m[32m0.23797[0m[0m | time: 22.089s
[2K
| RMSProp | epoch: 012 | loss: 0.23797 - acc: 0.9095 -- iter: 1184/1593
[A[ATraining Step: 588  | total loss: [1m[32m0.25128[0m[0m | time: 22.694s
[2K
| RMSProp | epoch: 012 | loss: 0.25128 - acc: 0.9030 -- iter: 1216/1593
[A[ATraining Step: 589  | total loss: [1m[32m0.24572[0m[0m | time: 23.304s
[2K
| RMSProp | epoch: 012 | loss: 0.24572 - acc: 0.9095 -- iter: 1248/1593
[A[ATraining Step: 590  | total loss: [1m[32m0.23447[0m[0m | time: 23.892s
[2K
| RMSProp | epoch: 012 | loss: 0.23447 - acc: 0.9155 -- iter: 1280/1593
[A[ATraining Step: 591  | total loss: [1m[32m0.22051[0m[0m | time: 24.490s
[2K
| RMSProp | epoch: 012 | loss: 0.22051 - acc: 0.9239 -- iter: 1312/1593
[A[ATraining Step: 592  | total loss: [1m[32m0.21492[0m[0m | time: 25.088s
[2K
| RMSProp | epoch: 012 | loss: 0.21492 - acc: 0.9284 -- iter: 1344/1593
[A[ATraining Step: 593  | total loss: [1m[32m0.21617[0m[0m | time: 25.718s
[2K
| RMSProp | epoch: 012 | loss: 0.21617 - acc: 0.9262 -- iter: 1376/1593
[A[ATraining Step: 594  | total loss: [1m[32m0.21421[0m[0m | time: 26.323s
[2K
| RMSProp | epoch: 012 | loss: 0.21421 - acc: 0.9242 -- iter: 1408/1593
[A[ATraining Step: 595  | total loss: [1m[32m0.20591[0m[0m | time: 26.932s
[2K
| RMSProp | epoch: 012 | loss: 0.20591 - acc: 0.9286 -- iter: 1440/1593
[A[ATraining Step: 596  | total loss: [1m[32m0.19986[0m[0m | time: 27.526s
[2K
| RMSProp | epoch: 012 | loss: 0.19986 - acc: 0.9264 -- iter: 1472/1593
[A[ATraining Step: 597  | total loss: [1m[32m0.18674[0m[0m | time: 28.131s
[2K
| RMSProp | epoch: 012 | loss: 0.18674 - acc: 0.9338 -- iter: 1504/1593
[A[ATraining Step: 598  | total loss: [1m[32m0.17255[0m[0m | time: 28.759s
[2K
| RMSProp | epoch: 012 | loss: 0.17255 - acc: 0.9404 -- iter: 1536/1593
[A[ATraining Step: 599  | total loss: [1m[32m0.16464[0m[0m | time: 29.365s
[2K
| RMSProp | epoch: 012 | loss: 0.16464 - acc: 0.9432 -- iter: 1568/1593
[A[ATraining Step: 600  | total loss: [1m[32m0.15514[0m[0m | time: 31.504s
[2K
| RMSProp | epoch: 012 | loss: 0.15514 - acc: 0.9489 | val_loss: 0.70103 - val_acc: 0.7470 -- iter: 1593/1593
--
Training Step: 601  | total loss: [1m[32m0.14931[0m[0m | time: 0.598s
[2K
| RMSProp | epoch: 013 | loss: 0.14931 - acc: 0.9478 -- iter: 0032/1593
[A[ATraining Step: 602  | total loss: [1m[32m0.14872[0m[0m | time: 1.201s
[2K
| RMSProp | epoch: 013 | loss: 0.14872 - acc: 0.9436 -- iter: 0064/1593
[A[ATraining Step: 603  | total loss: [1m[32m0.17698[0m[0m | time: 1.801s
[2K
| RMSProp | epoch: 013 | loss: 0.17698 - acc: 0.9242 -- iter: 0096/1593
[A[ATraining Step: 604  | total loss: [1m[32m0.16992[0m[0m | time: 2.401s
[2K
| RMSProp | epoch: 013 | loss: 0.16992 - acc: 0.9287 -- iter: 0128/1593
[A[ATraining Step: 605  | total loss: [1m[32m0.15682[0m[0m | time: 3.002s
[2K
| RMSProp | epoch: 013 | loss: 0.15682 - acc: 0.9358 -- iter: 0160/1593
[A[ATraining Step: 606  | total loss: [1m[32m0.15892[0m[0m | time: 3.613s
[2K
| RMSProp | epoch: 013 | loss: 0.15892 - acc: 0.9360 -- iter: 0192/1593
[A[ATraining Step: 607  | total loss: [1m[32m0.19290[0m[0m | time: 4.232s
[2K
| RMSProp | epoch: 013 | loss: 0.19290 - acc: 0.9236 -- iter: 0224/1593
[A[ATraining Step: 608  | total loss: [1m[32m0.19242[0m[0m | time: 4.840s
[2K
| RMSProp | epoch: 013 | loss: 0.19242 - acc: 0.9250 -- iter: 0256/1593
[A[ATraining Step: 609  | total loss: [1m[32m0.19952[0m[0m | time: 5.433s
[2K
| RMSProp | epoch: 013 | loss: 0.19952 - acc: 0.9169 -- iter: 0288/1593
[A[ATraining Step: 610  | total loss: [1m[32m0.19779[0m[0m | time: 6.059s
[2K
| RMSProp | epoch: 013 | loss: 0.19779 - acc: 0.9158 -- iter: 0320/1593
[A[ATraining Step: 611  | total loss: [1m[32m0.19822[0m[0m | time: 6.546s
[2K
| RMSProp | epoch: 013 | loss: 0.19822 - acc: 0.9180 -- iter: 0352/1593
[A[ATraining Step: 612  | total loss: [1m[32m0.20339[0m[0m | time: 7.030s
[2K
| RMSProp | epoch: 013 | loss: 0.20339 - acc: 0.9142 -- iter: 0384/1593
[A[ATraining Step: 613  | total loss: [1m[32m0.19751[0m[0m | time: 7.632s
[2K
| RMSProp | epoch: 013 | loss: 0.19751 - acc: 0.9148 -- iter: 0416/1593
[A[ATraining Step: 614  | total loss: [1m[32m0.19670[0m[0m | time: 8.219s
[2K
| RMSProp | epoch: 013 | loss: 0.19670 - acc: 0.9171 -- iter: 0448/1593
[A[ATraining Step: 615  | total loss: [1m[32m0.18476[0m[0m | time: 8.827s
[2K
| RMSProp | epoch: 013 | loss: 0.18476 - acc: 0.9253 -- iter: 0480/1593
[A[ATraining Step: 616  | total loss: [1m[32m0.17476[0m[0m | time: 9.430s
[2K
| RMSProp | epoch: 013 | loss: 0.17476 - acc: 0.9297 -- iter: 0512/1593
[A[ATraining Step: 617  | total loss: [1m[32m0.16778[0m[0m | time: 10.026s
[2K
| RMSProp | epoch: 013 | loss: 0.16778 - acc: 0.9336 -- iter: 0544/1593
[A[ATraining Step: 618  | total loss: [1m[32m0.15482[0m[0m | time: 10.629s
[2K
| RMSProp | epoch: 013 | loss: 0.15482 - acc: 0.9402 -- iter: 0576/1593
[A[ATraining Step: 619  | total loss: [1m[32m0.15449[0m[0m | time: 11.236s
[2K
| RMSProp | epoch: 013 | loss: 0.15449 - acc: 0.9368 -- iter: 0608/1593
[A[ATraining Step: 620  | total loss: [1m[32m0.17033[0m[0m | time: 11.833s
[2K
| RMSProp | epoch: 013 | loss: 0.17033 - acc: 0.9307 -- iter: 0640/1593
[A[ATraining Step: 621  | total loss: [1m[32m0.19452[0m[0m | time: 12.429s
[2K
| RMSProp | epoch: 013 | loss: 0.19452 - acc: 0.9251 -- iter: 0672/1593
[A[ATraining Step: 622  | total loss: [1m[32m0.19179[0m[0m | time: 13.042s
[2K
| RMSProp | epoch: 013 | loss: 0.19179 - acc: 0.9232 -- iter: 0704/1593
[A[ATraining Step: 623  | total loss: [1m[32m0.18903[0m[0m | time: 13.647s
[2K
| RMSProp | epoch: 013 | loss: 0.18903 - acc: 0.9278 -- iter: 0736/1593
[A[ATraining Step: 624  | total loss: [1m[32m0.18654[0m[0m | time: 14.240s
[2K
| RMSProp | epoch: 013 | loss: 0.18654 - acc: 0.9287 -- iter: 0768/1593
[A[ATraining Step: 625  | total loss: [1m[32m0.18236[0m[0m | time: 14.844s
[2K
| RMSProp | epoch: 013 | loss: 0.18236 - acc: 0.9327 -- iter: 0800/1593
[A[ATraining Step: 626  | total loss: [1m[32m0.19290[0m[0m | time: 15.435s
[2K
| RMSProp | epoch: 013 | loss: 0.19290 - acc: 0.9332 -- iter: 0832/1593
[A[ATraining Step: 627  | total loss: [1m[32m0.17818[0m[0m | time: 16.042s
[2K
| RMSProp | epoch: 013 | loss: 0.17818 - acc: 0.9399 -- iter: 0864/1593
[A[ATraining Step: 628  | total loss: [1m[32m0.18336[0m[0m | time: 16.646s
[2K
| RMSProp | epoch: 013 | loss: 0.18336 - acc: 0.9397 -- iter: 0896/1593
[A[ATraining Step: 629  | total loss: [1m[32m0.20711[0m[0m | time: 17.249s
[2K
| RMSProp | epoch: 013 | loss: 0.20711 - acc: 0.9269 -- iter: 0928/1593
[A[ATraining Step: 630  | total loss: [1m[32m0.20645[0m[0m | time: 17.853s
[2K
| RMSProp | epoch: 013 | loss: 0.20645 - acc: 0.9280 -- iter: 0960/1593
[A[ATraining Step: 631  | total loss: [1m[32m0.20697[0m[0m | time: 18.447s
[2K
| RMSProp | epoch: 013 | loss: 0.20697 - acc: 0.9289 -- iter: 0992/1593
[A[ATraining Step: 632  | total loss: [1m[32m0.19565[0m[0m | time: 19.048s
[2K
| RMSProp | epoch: 013 | loss: 0.19565 - acc: 0.9329 -- iter: 1024/1593
[A[ATraining Step: 633  | total loss: [1m[32m0.18356[0m[0m | time: 19.647s
[2K
| RMSProp | epoch: 013 | loss: 0.18356 - acc: 0.9365 -- iter: 1056/1593
[A[ATraining Step: 634  | total loss: [1m[32m0.18465[0m[0m | time: 20.263s
[2K
| RMSProp | epoch: 013 | loss: 0.18465 - acc: 0.9366 -- iter: 1088/1593
[A[ATraining Step: 635  | total loss: [1m[32m0.17581[0m[0m | time: 20.861s
[2K
| RMSProp | epoch: 013 | loss: 0.17581 - acc: 0.9398 -- iter: 1120/1593
[A[ATraining Step: 636  | total loss: [1m[32m0.16290[0m[0m | time: 21.463s
[2K
| RMSProp | epoch: 013 | loss: 0.16290 - acc: 0.9458 -- iter: 1152/1593
[A[ATraining Step: 637  | total loss: [1m[32m0.15281[0m[0m | time: 22.063s
[2K
| RMSProp | epoch: 013 | loss: 0.15281 - acc: 0.9481 -- iter: 1184/1593
[A[ATraining Step: 638  | total loss: [1m[32m0.18947[0m[0m | time: 22.662s
[2K
| RMSProp | epoch: 013 | loss: 0.18947 - acc: 0.9439 -- iter: 1216/1593
[A[ATraining Step: 639  | total loss: [1m[32m0.18590[0m[0m | time: 23.261s
[2K
| RMSProp | epoch: 013 | loss: 0.18590 - acc: 0.9464 -- iter: 1248/1593
[A[ATraining Step: 640  | total loss: [1m[32m0.17186[0m[0m | time: 23.874s
[2K
| RMSProp | epoch: 013 | loss: 0.17186 - acc: 0.9518 -- iter: 1280/1593
[A[ATraining Step: 641  | total loss: [1m[32m0.15837[0m[0m | time: 24.470s
[2K
| RMSProp | epoch: 013 | loss: 0.15837 - acc: 0.9566 -- iter: 1312/1593
[A[ATraining Step: 642  | total loss: [1m[32m0.14705[0m[0m | time: 25.064s
[2K
| RMSProp | epoch: 013 | loss: 0.14705 - acc: 0.9609 -- iter: 1344/1593
[A[ATraining Step: 643  | total loss: [1m[32m0.13863[0m[0m | time: 25.670s
[2K
| RMSProp | epoch: 013 | loss: 0.13863 - acc: 0.9617 -- iter: 1376/1593
[A[ATraining Step: 644  | total loss: [1m[32m0.14351[0m[0m | time: 26.270s
[2K
| RMSProp | epoch: 013 | loss: 0.14351 - acc: 0.9593 -- iter: 1408/1593
[A[ATraining Step: 645  | total loss: [1m[32m0.14185[0m[0m | time: 26.861s
[2K
| RMSProp | epoch: 013 | loss: 0.14185 - acc: 0.9571 -- iter: 1440/1593
[A[ATraining Step: 646  | total loss: [1m[32m0.15220[0m[0m | time: 27.457s
[2K
| RMSProp | epoch: 013 | loss: 0.15220 - acc: 0.9489 -- iter: 1472/1593
[A[ATraining Step: 647  | total loss: [1m[32m0.15291[0m[0m | time: 28.054s
[2K
| RMSProp | epoch: 013 | loss: 0.15291 - acc: 0.9446 -- iter: 1504/1593
[A[ATraining Step: 648  | total loss: [1m[32m0.15153[0m[0m | time: 28.657s
[2K
| RMSProp | epoch: 013 | loss: 0.15153 - acc: 0.9439 -- iter: 1536/1593
[A[ATraining Step: 649  | total loss: [1m[32m0.13952[0m[0m | time: 29.256s
[2K
| RMSProp | epoch: 013 | loss: 0.13952 - acc: 0.9495 -- iter: 1568/1593
[A[ATraining Step: 650  | total loss: [1m[32m0.12983[0m[0m | time: 31.416s
[2K
| RMSProp | epoch: 013 | loss: 0.12983 - acc: 0.9546 | val_loss: 0.43174 - val_acc: 0.8394 -- iter: 1593/1593
--
Training Step: 651  | total loss: [1m[32m0.12216[0m[0m | time: 0.595s
[2K
| RMSProp | epoch: 014 | loss: 0.12216 - acc: 0.9591 -- iter: 0032/1593
[A[ATraining Step: 652  | total loss: [1m[32m0.11221[0m[0m | time: 1.191s
[2K
| RMSProp | epoch: 014 | loss: 0.11221 - acc: 0.9632 -- iter: 0064/1593
[A[ATraining Step: 653  | total loss: [1m[32m0.11249[0m[0m | time: 1.791s
[2K
| RMSProp | epoch: 014 | loss: 0.11249 - acc: 0.9638 -- iter: 0096/1593
[A[ATraining Step: 654  | total loss: [1m[32m0.12777[0m[0m | time: 2.380s
[2K
| RMSProp | epoch: 014 | loss: 0.12777 - acc: 0.9611 -- iter: 0128/1593
[A[ATraining Step: 655  | total loss: [1m[32m0.12363[0m[0m | time: 2.996s
[2K
| RMSProp | epoch: 014 | loss: 0.12363 - acc: 0.9588 -- iter: 0160/1593
[A[ATraining Step: 656  | total loss: [1m[32m0.12161[0m[0m | time: 3.589s
[2K
| RMSProp | epoch: 014 | loss: 0.12161 - acc: 0.9566 -- iter: 0192/1593
[A[ATraining Step: 657  | total loss: [1m[32m0.11507[0m[0m | time: 4.202s
[2K
| RMSProp | epoch: 014 | loss: 0.11507 - acc: 0.9610 -- iter: 0224/1593
[A[ATraining Step: 658  | total loss: [1m[32m0.13020[0m[0m | time: 4.842s
[2K
| RMSProp | epoch: 014 | loss: 0.13020 - acc: 0.9524 -- iter: 0256/1593
[A[ATraining Step: 659  | total loss: [1m[32m0.15600[0m[0m | time: 5.451s
[2K
| RMSProp | epoch: 014 | loss: 0.15600 - acc: 0.9415 -- iter: 0288/1593
[A[ATraining Step: 660  | total loss: [1m[32m0.15059[0m[0m | time: 6.091s
[2K
| RMSProp | epoch: 014 | loss: 0.15059 - acc: 0.9442 -- iter: 0320/1593
[A[ATraining Step: 661  | total loss: [1m[32m0.16011[0m[0m | time: 6.696s
[2K
| RMSProp | epoch: 014 | loss: 0.16011 - acc: 0.9404 -- iter: 0352/1593
[A[ATraining Step: 662  | total loss: [1m[32m0.18618[0m[0m | time: 7.172s
[2K
| RMSProp | epoch: 014 | loss: 0.18618 - acc: 0.9245 -- iter: 0384/1593
[A[ATraining Step: 663  | total loss: [1m[32m0.18158[0m[0m | time: 7.653s
[2K
| RMSProp | epoch: 014 | loss: 0.18158 - acc: 0.9281 -- iter: 0416/1593
[A[ATraining Step: 664  | total loss: [1m[32m0.16753[0m[0m | time: 8.249s
[2K
| RMSProp | epoch: 014 | loss: 0.16753 - acc: 0.9353 -- iter: 0448/1593
[A[ATraining Step: 665  | total loss: [1m[32m0.15665[0m[0m | time: 8.846s
[2K
| RMSProp | epoch: 014 | loss: 0.15665 - acc: 0.9386 -- iter: 0480/1593
[A[ATraining Step: 666  | total loss: [1m[32m0.16335[0m[0m | time: 9.465s
[2K
| RMSProp | epoch: 014 | loss: 0.16335 - acc: 0.9385 -- iter: 0512/1593
[A[ATraining Step: 667  | total loss: [1m[32m0.16825[0m[0m | time: 10.065s
[2K
| RMSProp | epoch: 014 | loss: 0.16825 - acc: 0.9290 -- iter: 0544/1593
[A[ATraining Step: 668  | total loss: [1m[32m0.17913[0m[0m | time: 10.670s
[2K
| RMSProp | epoch: 014 | loss: 0.17913 - acc: 0.9267 -- iter: 0576/1593
[A[ATraining Step: 669  | total loss: [1m[32m0.18750[0m[0m | time: 11.269s
[2K
| RMSProp | epoch: 014 | loss: 0.18750 - acc: 0.9247 -- iter: 0608/1593
[A[ATraining Step: 670  | total loss: [1m[32m0.17633[0m[0m | time: 11.864s
[2K
| RMSProp | epoch: 014 | loss: 0.17633 - acc: 0.9322 -- iter: 0640/1593
[A[ATraining Step: 671  | total loss: [1m[32m0.16627[0m[0m | time: 12.472s
[2K
| RMSProp | epoch: 014 | loss: 0.16627 - acc: 0.9390 -- iter: 0672/1593
[A[ATraining Step: 672  | total loss: [1m[32m0.15342[0m[0m | time: 13.076s
[2K
| RMSProp | epoch: 014 | loss: 0.15342 - acc: 0.9451 -- iter: 0704/1593
[A[ATraining Step: 673  | total loss: [1m[32m0.14197[0m[0m | time: 13.673s
[2K
| RMSProp | epoch: 014 | loss: 0.14197 - acc: 0.9506 -- iter: 0736/1593
[A[ATraining Step: 674  | total loss: [1m[32m0.14895[0m[0m | time: 14.268s
[2K
| RMSProp | epoch: 014 | loss: 0.14895 - acc: 0.9493 -- iter: 0768/1593
[A[ATraining Step: 675  | total loss: [1m[32m0.13854[0m[0m | time: 14.842s
[2K
| RMSProp | epoch: 014 | loss: 0.13854 - acc: 0.9544 -- iter: 0800/1593
[A[ATraining Step: 676  | total loss: [1m[32m0.13038[0m[0m | time: 15.440s
[2K
| RMSProp | epoch: 014 | loss: 0.13038 - acc: 0.9589 -- iter: 0832/1593
[A[ATraining Step: 677  | total loss: [1m[32m0.12567[0m[0m | time: 16.044s
[2K
| RMSProp | epoch: 014 | loss: 0.12567 - acc: 0.9599 -- iter: 0864/1593
[A[ATraining Step: 678  | total loss: [1m[32m0.12967[0m[0m | time: 16.667s
[2K
| RMSProp | epoch: 014 | loss: 0.12967 - acc: 0.9608 -- iter: 0896/1593
[A[ATraining Step: 679  | total loss: [1m[32m0.12171[0m[0m | time: 17.264s
[2K
| RMSProp | epoch: 014 | loss: 0.12171 - acc: 0.9647 -- iter: 0928/1593
[A[ATraining Step: 680  | total loss: [1m[32m0.11078[0m[0m | time: 17.862s
[2K
| RMSProp | epoch: 014 | loss: 0.11078 - acc: 0.9682 -- iter: 0960/1593
[A[ATraining Step: 681  | total loss: [1m[32m0.10221[0m[0m | time: 18.456s
[2K
| RMSProp | epoch: 014 | loss: 0.10221 - acc: 0.9714 -- iter: 0992/1593
[A[ATraining Step: 682  | total loss: [1m[32m0.11797[0m[0m | time: 19.060s
[2K
| RMSProp | epoch: 014 | loss: 0.11797 - acc: 0.9618 -- iter: 1024/1593
[A[ATraining Step: 683  | total loss: [1m[32m0.14927[0m[0m | time: 19.694s
[2K
| RMSProp | epoch: 014 | loss: 0.14927 - acc: 0.9531 -- iter: 1056/1593
[A[ATraining Step: 684  | total loss: [1m[32m0.14066[0m[0m | time: 20.299s
[2K
| RMSProp | epoch: 014 | loss: 0.14066 - acc: 0.9547 -- iter: 1088/1593
[A[ATraining Step: 685  | total loss: [1m[32m0.14219[0m[0m | time: 20.902s
[2K
| RMSProp | epoch: 014 | loss: 0.14219 - acc: 0.9529 -- iter: 1120/1593
[A[ATraining Step: 686  | total loss: [1m[32m0.13425[0m[0m | time: 21.495s
[2K
| RMSProp | epoch: 014 | loss: 0.13425 - acc: 0.9577 -- iter: 1152/1593
[A[ATraining Step: 687  | total loss: [1m[32m0.12474[0m[0m | time: 22.110s
[2K
| RMSProp | epoch: 014 | loss: 0.12474 - acc: 0.9619 -- iter: 1184/1593
[A[ATraining Step: 688  | total loss: [1m[32m0.11916[0m[0m | time: 22.723s
[2K
| RMSProp | epoch: 014 | loss: 0.11916 - acc: 0.9626 -- iter: 1216/1593
[A[ATraining Step: 689  | total loss: [1m[32m0.10981[0m[0m | time: 23.323s
[2K
| RMSProp | epoch: 014 | loss: 0.10981 - acc: 0.9663 -- iter: 1248/1593
[A[ATraining Step: 690  | total loss: [1m[32m0.10000[0m[0m | time: 23.922s
[2K
| RMSProp | epoch: 014 | loss: 0.10000 - acc: 0.9697 -- iter: 1280/1593
[A[ATraining Step: 691  | total loss: [1m[32m0.09289[0m[0m | time: 24.530s
[2K
| RMSProp | epoch: 014 | loss: 0.09289 - acc: 0.9727 -- iter: 1312/1593
[A[ATraining Step: 692  | total loss: [1m[32m0.08963[0m[0m | time: 25.148s
[2K
| RMSProp | epoch: 014 | loss: 0.08963 - acc: 0.9754 -- iter: 1344/1593
[A[ATraining Step: 693  | total loss: [1m[32m0.08672[0m[0m | time: 25.765s
[2K
| RMSProp | epoch: 014 | loss: 0.08672 - acc: 0.9748 -- iter: 1376/1593
[A[ATraining Step: 694  | total loss: [1m[32m0.08259[0m[0m | time: 26.393s
[2K
| RMSProp | epoch: 014 | loss: 0.08259 - acc: 0.9773 -- iter: 1408/1593
[A[ATraining Step: 695  | total loss: [1m[32m0.08732[0m[0m | time: 26.983s
[2K
| RMSProp | epoch: 014 | loss: 0.08732 - acc: 0.9733 -- iter: 1440/1593
[A[ATraining Step: 696  | total loss: [1m[32m0.09120[0m[0m | time: 27.584s
[2K
| RMSProp | epoch: 014 | loss: 0.09120 - acc: 0.9697 -- iter: 1472/1593
[A[ATraining Step: 697  | total loss: [1m[32m0.08870[0m[0m | time: 28.187s
[2K
| RMSProp | epoch: 014 | loss: 0.08870 - acc: 0.9696 -- iter: 1504/1593
[A[ATraining Step: 698  | total loss: [1m[32m0.09034[0m[0m | time: 28.800s
[2K
| RMSProp | epoch: 014 | loss: 0.09034 - acc: 0.9664 -- iter: 1536/1593
[A[ATraining Step: 699  | total loss: [1m[32m0.09441[0m[0m | time: 29.417s
[2K
| RMSProp | epoch: 014 | loss: 0.09441 - acc: 0.9667 -- iter: 1568/1593
[A[ATraining Step: 700  | total loss: [1m[32m0.09135[0m[0m | time: 31.578s
[2K
| RMSProp | epoch: 014 | loss: 0.09135 - acc: 0.9669 | val_loss: 0.69089 - val_acc: 0.8193 -- iter: 1593/1593
--
Training Step: 701  | total loss: [1m[32m0.09434[0m[0m | time: 0.602s
[2K
| RMSProp | epoch: 015 | loss: 0.09434 - acc: 0.9671 -- iter: 0032/1593
[A[ATraining Step: 702  | total loss: [1m[32m0.11880[0m[0m | time: 1.206s
[2K
| RMSProp | epoch: 015 | loss: 0.11880 - acc: 0.9547 -- iter: 0064/1593
[A[ATraining Step: 703  | total loss: [1m[32m0.11800[0m[0m | time: 1.812s
[2K
| RMSProp | epoch: 015 | loss: 0.11800 - acc: 0.9530 -- iter: 0096/1593
[A[ATraining Step: 704  | total loss: [1m[32m0.10718[0m[0m | time: 2.433s
[2K
| RMSProp | epoch: 015 | loss: 0.10718 - acc: 0.9577 -- iter: 0128/1593
[A[ATraining Step: 705  | total loss: [1m[32m0.10319[0m[0m | time: 3.051s
[2K
| RMSProp | epoch: 015 | loss: 0.10319 - acc: 0.9588 -- iter: 0160/1593
[A[ATraining Step: 706  | total loss: [1m[32m0.10081[0m[0m | time: 3.659s
[2K
| RMSProp | epoch: 015 | loss: 0.10081 - acc: 0.9567 -- iter: 0192/1593
[A[ATraining Step: 707  | total loss: [1m[32m0.10348[0m[0m | time: 4.277s
[2K
| RMSProp | epoch: 015 | loss: 0.10348 - acc: 0.9579 -- iter: 0224/1593
[A[ATraining Step: 708  | total loss: [1m[32m0.11145[0m[0m | time: 4.881s
[2K
| RMSProp | epoch: 015 | loss: 0.11145 - acc: 0.9527 -- iter: 0256/1593
[A[ATraining Step: 709  | total loss: [1m[32m0.14081[0m[0m | time: 5.472s
[2K
| RMSProp | epoch: 015 | loss: 0.14081 - acc: 0.9418 -- iter: 0288/1593
[A[ATraining Step: 710  | total loss: [1m[32m0.13417[0m[0m | time: 6.091s
[2K
| RMSProp | epoch: 015 | loss: 0.13417 - acc: 0.9476 -- iter: 0320/1593
[A[ATraining Step: 711  | total loss: [1m[32m0.12553[0m[0m | time: 6.691s
[2K
| RMSProp | epoch: 015 | loss: 0.12553 - acc: 0.9498 -- iter: 0352/1593
[A[ATraining Step: 712  | total loss: [1m[32m0.11595[0m[0m | time: 7.298s
[2K
| RMSProp | epoch: 015 | loss: 0.11595 - acc: 0.9548 -- iter: 0384/1593
[A[ATraining Step: 713  | total loss: [1m[32m0.10646[0m[0m | time: 7.786s
[2K
| RMSProp | epoch: 015 | loss: 0.10646 - acc: 0.9593 -- iter: 0416/1593
[A[ATraining Step: 714  | total loss: [1m[32m0.09664[0m[0m | time: 8.271s
[2K
| RMSProp | epoch: 015 | loss: 0.09664 - acc: 0.9634 -- iter: 0448/1593
[A[ATraining Step: 715  | total loss: [1m[32m0.08737[0m[0m | time: 8.876s
[2K
| RMSProp | epoch: 015 | loss: 0.08737 - acc: 0.9670 -- iter: 0480/1593
[A[ATraining Step: 716  | total loss: [1m[32m0.07969[0m[0m | time: 9.506s
[2K
| RMSProp | epoch: 015 | loss: 0.07969 - acc: 0.9703 -- iter: 0512/1593
[A[ATraining Step: 717  | total loss: [1m[32m0.07634[0m[0m | time: 10.102s
[2K
| RMSProp | epoch: 015 | loss: 0.07634 - acc: 0.9702 -- iter: 0544/1593
[A[ATraining Step: 718  | total loss: [1m[32m0.09330[0m[0m | time: 10.709s
[2K
| RMSProp | epoch: 015 | loss: 0.09330 - acc: 0.9638 -- iter: 0576/1593
[A[ATraining Step: 719  | total loss: [1m[32m0.11721[0m[0m | time: 11.310s
[2K
| RMSProp | epoch: 015 | loss: 0.11721 - acc: 0.9518 -- iter: 0608/1593
[A[ATraining Step: 720  | total loss: [1m[32m0.10954[0m[0m | time: 11.912s
[2K
| RMSProp | epoch: 015 | loss: 0.10954 - acc: 0.9566 -- iter: 0640/1593
[A[ATraining Step: 721  | total loss: [1m[32m0.10014[0m[0m | time: 12.511s
[2K
| RMSProp | epoch: 015 | loss: 0.10014 - acc: 0.9609 -- iter: 0672/1593
[A[ATraining Step: 722  | total loss: [1m[32m0.09178[0m[0m | time: 13.115s
[2K
| RMSProp | epoch: 015 | loss: 0.09178 - acc: 0.9648 -- iter: 0704/1593
[A[ATraining Step: 723  | total loss: [1m[32m0.09063[0m[0m | time: 13.730s
[2K
| RMSProp | epoch: 015 | loss: 0.09063 - acc: 0.9621 -- iter: 0736/1593
[A[ATraining Step: 724  | total loss: [1m[32m0.08382[0m[0m | time: 14.335s
[2K
| RMSProp | epoch: 015 | loss: 0.08382 - acc: 0.9659 -- iter: 0768/1593
[A[ATraining Step: 725  | total loss: [1m[32m0.08244[0m[0m | time: 14.938s
[2K
| RMSProp | epoch: 015 | loss: 0.08244 - acc: 0.9662 -- iter: 0800/1593
[A[ATraining Step: 726  | total loss: [1m[32m0.09016[0m[0m | time: 15.540s
[2K
| RMSProp | epoch: 015 | loss: 0.09016 - acc: 0.9664 -- iter: 0832/1593
[A[ATraining Step: 727  | total loss: [1m[32m0.11659[0m[0m | time: 16.143s
[2K
| RMSProp | epoch: 015 | loss: 0.11659 - acc: 0.9573 -- iter: 0864/1593
[A[ATraining Step: 728  | total loss: [1m[32m0.11295[0m[0m | time: 16.745s
[2K
| RMSProp | epoch: 015 | loss: 0.11295 - acc: 0.9584 -- iter: 0896/1593
[A[ATraining Step: 729  | total loss: [1m[32m0.10647[0m[0m | time: 17.345s
[2K
| RMSProp | epoch: 015 | loss: 0.10647 - acc: 0.9626 -- iter: 0928/1593
[A[ATraining Step: 730  | total loss: [1m[32m0.10731[0m[0m | time: 17.947s
[2K
| RMSProp | epoch: 015 | loss: 0.10731 - acc: 0.9632 -- iter: 0960/1593
[A[ATraining Step: 731  | total loss: [1m[32m0.10381[0m[0m | time: 18.550s
[2K
| RMSProp | epoch: 015 | loss: 0.10381 - acc: 0.9669 -- iter: 0992/1593
[A[ATraining Step: 732  | total loss: [1m[32m0.10989[0m[0m | time: 19.174s
[2K
| RMSProp | epoch: 015 | loss: 0.10989 - acc: 0.9671 -- iter: 1024/1593
[A[ATraining Step: 733  | total loss: [1m[32m0.13391[0m[0m | time: 19.769s
[2K
| RMSProp | epoch: 015 | loss: 0.13391 - acc: 0.9641 -- iter: 1056/1593
[A[ATraining Step: 734  | total loss: [1m[32m0.12752[0m[0m | time: 20.370s
[2K
| RMSProp | epoch: 015 | loss: 0.12752 - acc: 0.9646 -- iter: 1088/1593
[A[ATraining Step: 735  | total loss: [1m[32m0.11607[0m[0m | time: 20.985s
[2K
| RMSProp | epoch: 015 | loss: 0.11607 - acc: 0.9681 -- iter: 1120/1593
[A[ATraining Step: 736  | total loss: [1m[32m0.11405[0m[0m | time: 21.616s
[2K
| RMSProp | epoch: 015 | loss: 0.11405 - acc: 0.9682 -- iter: 1152/1593
[A[ATraining Step: 737  | total loss: [1m[32m0.10921[0m[0m | time: 22.222s
[2K
| RMSProp | epoch: 015 | loss: 0.10921 - acc: 0.9714 -- iter: 1184/1593
[A[ATraining Step: 738  | total loss: [1m[32m0.09973[0m[0m | time: 22.824s
[2K
| RMSProp | epoch: 015 | loss: 0.09973 - acc: 0.9742 -- iter: 1216/1593
[A[ATraining Step: 739  | total loss: [1m[32m0.09071[0m[0m | time: 23.414s
[2K
| RMSProp | epoch: 015 | loss: 0.09071 - acc: 0.9768 -- iter: 1248/1593
[A[ATraining Step: 740  | total loss: [1m[32m0.08326[0m[0m | time: 24.018s
[2K
| RMSProp | epoch: 015 | loss: 0.08326 - acc: 0.9791 -- iter: 1280/1593
[A[ATraining Step: 741  | total loss: [1m[32m0.07718[0m[0m | time: 24.607s
[2K
| RMSProp | epoch: 015 | loss: 0.07718 - acc: 0.9812 -- iter: 1312/1593
[A[ATraining Step: 742  | total loss: [1m[32m0.07132[0m[0m | time: 25.201s
[2K
| RMSProp | epoch: 015 | loss: 0.07132 - acc: 0.9831 -- iter: 1344/1593
[A[ATraining Step: 743  | total loss: [1m[32m0.06525[0m[0m | time: 25.807s
[2K
| RMSProp | epoch: 015 | loss: 0.06525 - acc: 0.9848 -- iter: 1376/1593
[A[ATraining Step: 744  | total loss: [1m[32m0.05956[0m[0m | time: 26.406s
[2K
| RMSProp | epoch: 015 | loss: 0.05956 - acc: 0.9863 -- iter: 1408/1593
[A[ATraining Step: 745  | total loss: [1m[32m0.05401[0m[0m | time: 26.999s
[2K
| RMSProp | epoch: 015 | loss: 0.05401 - acc: 0.9877 -- iter: 1440/1593
[A[ATraining Step: 746  | total loss: [1m[32m0.05523[0m[0m | time: 27.596s
[2K
| RMSProp | epoch: 015 | loss: 0.05523 - acc: 0.9858 -- iter: 1472/1593
[A[ATraining Step: 747  | total loss: [1m[32m0.06477[0m[0m | time: 28.229s
[2K
| RMSProp | epoch: 015 | loss: 0.06477 - acc: 0.9841 -- iter: 1504/1593
[A[ATraining Step: 748  | total loss: [1m[32m0.09517[0m[0m | time: 28.855s
[2K
| RMSProp | epoch: 015 | loss: 0.09517 - acc: 0.9732 -- iter: 1536/1593
[A[ATraining Step: 749  | total loss: [1m[32m0.09249[0m[0m | time: 29.462s
[2K
| RMSProp | epoch: 015 | loss: 0.09249 - acc: 0.9696 -- iter: 1568/1593
[A[ATraining Step: 750  | total loss: [1m[32m0.08553[0m[0m | time: 31.639s
[2K
| RMSProp | epoch: 015 | loss: 0.08553 - acc: 0.9726 | val_loss: 0.54347 - val_acc: 0.8394 -- iter: 1593/1593
--
Training Step: 751  | total loss: [1m[32m0.07864[0m[0m | time: 0.595s
[2K
| RMSProp | epoch: 016 | loss: 0.07864 - acc: 0.9754 -- iter: 0032/1593
[A[ATraining Step: 752  | total loss: [1m[32m0.07167[0m[0m | time: 1.197s
[2K
| RMSProp | epoch: 016 | loss: 0.07167 - acc: 0.9778 -- iter: 0064/1593
[A[ATraining Step: 753  | total loss: [1m[32m0.06494[0m[0m | time: 1.805s
[2K
| RMSProp | epoch: 016 | loss: 0.06494 - acc: 0.9801 -- iter: 0096/1593
[A[ATraining Step: 754  | total loss: [1m[32m0.05967[0m[0m | time: 2.437s
[2K
| RMSProp | epoch: 016 | loss: 0.05967 - acc: 0.9821 -- iter: 0128/1593
[A[ATraining Step: 755  | total loss: [1m[32m0.05399[0m[0m | time: 3.052s
[2K
| RMSProp | epoch: 016 | loss: 0.05399 - acc: 0.9838 -- iter: 0160/1593
[A[ATraining Step: 756  | total loss: [1m[32m0.04963[0m[0m | time: 3.671s
[2K
| RMSProp | epoch: 016 | loss: 0.04963 - acc: 0.9855 -- iter: 0192/1593
[A[ATraining Step: 757  | total loss: [1m[32m0.04513[0m[0m | time: 4.276s
[2K
| RMSProp | epoch: 016 | loss: 0.04513 - acc: 0.9869 -- iter: 0224/1593
[A[ATraining Step: 758  | total loss: [1m[32m0.04115[0m[0m | time: 4.876s
[2K
| RMSProp | epoch: 016 | loss: 0.04115 - acc: 0.9882 -- iter: 0256/1593
[A[ATraining Step: 759  | total loss: [1m[32m0.03795[0m[0m | time: 5.485s
[2K
| RMSProp | epoch: 016 | loss: 0.03795 - acc: 0.9894 -- iter: 0288/1593
[A[ATraining Step: 760  | total loss: [1m[32m0.03518[0m[0m | time: 6.084s
[2K
| RMSProp | epoch: 016 | loss: 0.03518 - acc: 0.9905 -- iter: 0320/1593
[A[ATraining Step: 761  | total loss: [1m[32m0.03196[0m[0m | time: 6.687s
[2K
| RMSProp | epoch: 016 | loss: 0.03196 - acc: 0.9914 -- iter: 0352/1593
[A[ATraining Step: 762  | total loss: [1m[32m0.03681[0m[0m | time: 7.297s
[2K
| RMSProp | epoch: 016 | loss: 0.03681 - acc: 0.9891 -- iter: 0384/1593
[A[ATraining Step: 763  | total loss: [1m[32m0.06440[0m[0m | time: 7.904s
[2K
| RMSProp | epoch: 016 | loss: 0.06440 - acc: 0.9777 -- iter: 0416/1593
[A[ATraining Step: 764  | total loss: [1m[32m0.07736[0m[0m | time: 8.376s
[2K
| RMSProp | epoch: 016 | loss: 0.07736 - acc: 0.9706 -- iter: 0448/1593
[A[ATraining Step: 765  | total loss: [1m[32m0.07959[0m[0m | time: 8.858s
[2K
| RMSProp | epoch: 016 | loss: 0.07959 - acc: 0.9695 -- iter: 0480/1593
[A[ATraining Step: 766  | total loss: [1m[32m0.07471[0m[0m | time: 9.453s
[2K
| RMSProp | epoch: 016 | loss: 0.07471 - acc: 0.9726 -- iter: 0512/1593
[A[ATraining Step: 767  | total loss: [1m[32m0.08128[0m[0m | time: 10.050s
[2K
| RMSProp | epoch: 016 | loss: 0.08128 - acc: 0.9722 -- iter: 0544/1593
[A[ATraining Step: 768  | total loss: [1m[32m0.08063[0m[0m | time: 10.662s
[2K
| RMSProp | epoch: 016 | loss: 0.08063 - acc: 0.9718 -- iter: 0576/1593
[A[ATraining Step: 769  | total loss: [1m[32m0.09640[0m[0m | time: 11.264s
[2K
| RMSProp | epoch: 016 | loss: 0.09640 - acc: 0.9622 -- iter: 0608/1593
[A[ATraining Step: 770  | total loss: [1m[32m0.09247[0m[0m | time: 11.874s
[2K
| RMSProp | epoch: 016 | loss: 0.09247 - acc: 0.9628 -- iter: 0640/1593
[A[ATraining Step: 771  | total loss: [1m[32m0.08558[0m[0m | time: 12.465s
[2K
| RMSProp | epoch: 016 | loss: 0.08558 - acc: 0.9665 -- iter: 0672/1593
[A[ATraining Step: 772  | total loss: [1m[32m0.08945[0m[0m | time: 13.074s
[2K
| RMSProp | epoch: 016 | loss: 0.08945 - acc: 0.9668 -- iter: 0704/1593
[A[ATraining Step: 773  | total loss: [1m[32m0.08846[0m[0m | time: 13.674s
[2K
| RMSProp | epoch: 016 | loss: 0.08846 - acc: 0.9638 -- iter: 0736/1593
[A[ATraining Step: 774  | total loss: [1m[32m0.09752[0m[0m | time: 14.264s
[2K
| RMSProp | epoch: 016 | loss: 0.09752 - acc: 0.9612 -- iter: 0768/1593
[A[ATraining Step: 775  | total loss: [1m[32m0.09899[0m[0m | time: 14.869s
[2K
| RMSProp | epoch: 016 | loss: 0.09899 - acc: 0.9588 -- iter: 0800/1593
[A[ATraining Step: 776  | total loss: [1m[32m0.09116[0m[0m | time: 15.468s
[2K
| RMSProp | epoch: 016 | loss: 0.09116 - acc: 0.9629 -- iter: 0832/1593
[A[ATraining Step: 777  | total loss: [1m[32m0.08756[0m[0m | time: 16.080s
[2K
| RMSProp | epoch: 016 | loss: 0.08756 - acc: 0.9635 -- iter: 0864/1593
[A[ATraining Step: 778  | total loss: [1m[32m0.07962[0m[0m | time: 16.679s
[2K
| RMSProp | epoch: 016 | loss: 0.07962 - acc: 0.9672 -- iter: 0896/1593
[A[ATraining Step: 779  | total loss: [1m[32m0.07235[0m[0m | time: 17.297s
[2K
| RMSProp | epoch: 016 | loss: 0.07235 - acc: 0.9705 -- iter: 0928/1593
[A[ATraining Step: 780  | total loss: [1m[32m0.06667[0m[0m | time: 17.900s
[2K
| RMSProp | epoch: 016 | loss: 0.06667 - acc: 0.9734 -- iter: 0960/1593
[A[ATraining Step: 781  | total loss: [1m[32m0.06269[0m[0m | time: 18.504s
[2K
| RMSProp | epoch: 016 | loss: 0.06269 - acc: 0.9761 -- iter: 0992/1593
[A[ATraining Step: 782  | total loss: [1m[32m0.05695[0m[0m | time: 19.116s
[2K
| RMSProp | epoch: 016 | loss: 0.05695 - acc: 0.9785 -- iter: 1024/1593
[A[ATraining Step: 783  | total loss: [1m[32m0.06040[0m[0m | time: 19.707s
[2K
| RMSProp | epoch: 016 | loss: 0.06040 - acc: 0.9775 -- iter: 1056/1593
[A[ATraining Step: 784  | total loss: [1m[32m0.10580[0m[0m | time: 20.317s
[2K
| RMSProp | epoch: 016 | loss: 0.10580 - acc: 0.9735 -- iter: 1088/1593
[A[ATraining Step: 785  | total loss: [1m[32m0.10145[0m[0m | time: 20.922s
[2K
| RMSProp | epoch: 016 | loss: 0.10145 - acc: 0.9761 -- iter: 1120/1593
[A[ATraining Step: 786  | total loss: [1m[32m0.09429[0m[0m | time: 21.526s
[2K
| RMSProp | epoch: 016 | loss: 0.09429 - acc: 0.9785 -- iter: 1152/1593
[A[ATraining Step: 787  | total loss: [1m[32m0.08632[0m[0m | time: 22.141s
[2K
| RMSProp | epoch: 016 | loss: 0.08632 - acc: 0.9807 -- iter: 1184/1593
[A[ATraining Step: 788  | total loss: [1m[32m0.08152[0m[0m | time: 22.747s
[2K
| RMSProp | epoch: 016 | loss: 0.08152 - acc: 0.9795 -- iter: 1216/1593
[A[ATraining Step: 789  | total loss: [1m[32m0.08300[0m[0m | time: 23.336s
[2K
| RMSProp | epoch: 016 | loss: 0.08300 - acc: 0.9784 -- iter: 1248/1593
[A[ATraining Step: 790  | total loss: [1m[32m0.09252[0m[0m | time: 23.929s
[2K
| RMSProp | epoch: 016 | loss: 0.09252 - acc: 0.9743 -- iter: 1280/1593
[A[ATraining Step: 791  | total loss: [1m[32m0.09410[0m[0m | time: 24.537s
[2K
| RMSProp | epoch: 016 | loss: 0.09410 - acc: 0.9706 -- iter: 1312/1593
[A[ATraining Step: 792  | total loss: [1m[32m0.09047[0m[0m | time: 25.130s
[2K
| RMSProp | epoch: 016 | loss: 0.09047 - acc: 0.9704 -- iter: 1344/1593
[A[ATraining Step: 793  | total loss: [1m[32m0.08787[0m[0m | time: 25.739s
[2K
| RMSProp | epoch: 016 | loss: 0.08787 - acc: 0.9703 -- iter: 1376/1593
[A[ATraining Step: 794  | total loss: [1m[32m0.07997[0m[0m | time: 26.340s
[2K
| RMSProp | epoch: 016 | loss: 0.07997 - acc: 0.9733 -- iter: 1408/1593
[A[ATraining Step: 795  | total loss: [1m[32m0.07532[0m[0m | time: 26.939s
[2K
| RMSProp | epoch: 016 | loss: 0.07532 - acc: 0.9759 -- iter: 1440/1593
[A[ATraining Step: 796  | total loss: [1m[32m0.07157[0m[0m | time: 27.525s
[2K
| RMSProp | epoch: 016 | loss: 0.07157 - acc: 0.9752 -- iter: 1472/1593
[A[ATraining Step: 797  | total loss: [1m[32m0.06533[0m[0m | time: 28.117s
[2K
| RMSProp | epoch: 016 | loss: 0.06533 - acc: 0.9777 -- iter: 1504/1593
[A[ATraining Step: 798  | total loss: [1m[32m0.06092[0m[0m | time: 28.714s
[2K
| RMSProp | epoch: 016 | loss: 0.06092 - acc: 0.9799 -- iter: 1536/1593
[A[ATraining Step: 799  | total loss: [1m[32m0.05623[0m[0m | time: 29.313s
[2K
| RMSProp | epoch: 016 | loss: 0.05623 - acc: 0.9819 -- iter: 1568/1593
[A[ATraining Step: 800  | total loss: [1m[32m0.06513[0m[0m | time: 31.470s
[2K
| RMSProp | epoch: 016 | loss: 0.06513 - acc: 0.9806 | val_loss: 0.49283 - val_acc: 0.8273 -- iter: 1593/1593
--
Training Step: 801  | total loss: [1m[32m0.06773[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 017 | loss: 0.06773 - acc: 0.9794 -- iter: 0032/1593
[A[ATraining Step: 802  | total loss: [1m[32m0.06653[0m[0m | time: 1.209s
[2K
| RMSProp | epoch: 017 | loss: 0.06653 - acc: 0.9784 -- iter: 0064/1593
[A[ATraining Step: 803  | total loss: [1m[32m0.07449[0m[0m | time: 1.806s
[2K
| RMSProp | epoch: 017 | loss: 0.07449 - acc: 0.9774 -- iter: 0096/1593
[A[ATraining Step: 804  | total loss: [1m[32m0.09003[0m[0m | time: 2.410s
[2K
| RMSProp | epoch: 017 | loss: 0.09003 - acc: 0.9672 -- iter: 0128/1593
[A[ATraining Step: 805  | total loss: [1m[32m0.08174[0m[0m | time: 3.009s
[2K
| RMSProp | epoch: 017 | loss: 0.08174 - acc: 0.9704 -- iter: 0160/1593
[A[ATraining Step: 806  | total loss: [1m[32m0.07458[0m[0m | time: 3.601s
[2K
| RMSProp | epoch: 017 | loss: 0.07458 - acc: 0.9734 -- iter: 0192/1593
[A[ATraining Step: 807  | total loss: [1m[32m0.06752[0m[0m | time: 4.202s
[2K
| RMSProp | epoch: 017 | loss: 0.06752 - acc: 0.9761 -- iter: 0224/1593
[A[ATraining Step: 808  | total loss: [1m[32m0.06199[0m[0m | time: 4.835s
[2K
| RMSProp | epoch: 017 | loss: 0.06199 - acc: 0.9785 -- iter: 0256/1593
[A[ATraining Step: 809  | total loss: [1m[32m0.05703[0m[0m | time: 5.448s
[2K
| RMSProp | epoch: 017 | loss: 0.05703 - acc: 0.9806 -- iter: 0288/1593
[A[ATraining Step: 810  | total loss: [1m[32m0.05175[0m[0m | time: 6.062s
[2K
| RMSProp | epoch: 017 | loss: 0.05175 - acc: 0.9825 -- iter: 0320/1593
[A[ATraining Step: 811  | total loss: [1m[32m0.04766[0m[0m | time: 6.664s
[2K
| RMSProp | epoch: 017 | loss: 0.04766 - acc: 0.9843 -- iter: 0352/1593
[A[ATraining Step: 812  | total loss: [1m[32m0.04416[0m[0m | time: 7.272s
[2K
| RMSProp | epoch: 017 | loss: 0.04416 - acc: 0.9859 -- iter: 0384/1593
[A[ATraining Step: 813  | total loss: [1m[32m0.03995[0m[0m | time: 7.871s
[2K
| RMSProp | epoch: 017 | loss: 0.03995 - acc: 0.9873 -- iter: 0416/1593
[A[ATraining Step: 814  | total loss: [1m[32m0.03802[0m[0m | time: 8.470s
[2K
| RMSProp | epoch: 017 | loss: 0.03802 - acc: 0.9885 -- iter: 0448/1593
[A[ATraining Step: 815  | total loss: [1m[32m0.04199[0m[0m | time: 8.950s
[2K
| RMSProp | epoch: 017 | loss: 0.04199 - acc: 0.9866 -- iter: 0480/1593
[A[ATraining Step: 816  | total loss: [1m[32m0.05092[0m[0m | time: 9.429s
[2K
| RMSProp | epoch: 017 | loss: 0.05092 - acc: 0.9799 -- iter: 0512/1593
[A[ATraining Step: 817  | total loss: [1m[32m0.04952[0m[0m | time: 10.038s
[2K
| RMSProp | epoch: 017 | loss: 0.04952 - acc: 0.9779 -- iter: 0544/1593
[A[ATraining Step: 818  | total loss: [1m[32m0.05971[0m[0m | time: 10.633s
[2K
| RMSProp | epoch: 017 | loss: 0.05971 - acc: 0.9708 -- iter: 0576/1593
[A[ATraining Step: 819  | total loss: [1m[32m0.07637[0m[0m | time: 11.248s
[2K
| RMSProp | epoch: 017 | loss: 0.07637 - acc: 0.9643 -- iter: 0608/1593
[A[ATraining Step: 820  | total loss: [1m[32m0.08313[0m[0m | time: 11.851s
[2K
| RMSProp | epoch: 017 | loss: 0.08313 - acc: 0.9616 -- iter: 0640/1593
[A[ATraining Step: 821  | total loss: [1m[32m0.07793[0m[0m | time: 12.466s
[2K
| RMSProp | epoch: 017 | loss: 0.07793 - acc: 0.9655 -- iter: 0672/1593
[A[ATraining Step: 822  | total loss: [1m[32m0.07273[0m[0m | time: 13.079s
[2K
| RMSProp | epoch: 017 | loss: 0.07273 - acc: 0.9689 -- iter: 0704/1593
[A[ATraining Step: 823  | total loss: [1m[32m0.06749[0m[0m | time: 13.703s
[2K
| RMSProp | epoch: 017 | loss: 0.06749 - acc: 0.9720 -- iter: 0736/1593
[A[ATraining Step: 824  | total loss: [1m[32m0.06402[0m[0m | time: 14.303s
[2K
| RMSProp | epoch: 017 | loss: 0.06402 - acc: 0.9748 -- iter: 0768/1593
[A[ATraining Step: 825  | total loss: [1m[32m0.06096[0m[0m | time: 14.916s
[2K
| RMSProp | epoch: 017 | loss: 0.06096 - acc: 0.9773 -- iter: 0800/1593
[A[ATraining Step: 826  | total loss: [1m[32m0.06443[0m[0m | time: 15.515s
[2K
| RMSProp | epoch: 017 | loss: 0.06443 - acc: 0.9765 -- iter: 0832/1593
[A[ATraining Step: 827  | total loss: [1m[32m0.07557[0m[0m | time: 16.113s
[2K
| RMSProp | epoch: 017 | loss: 0.07557 - acc: 0.9726 -- iter: 0864/1593
[A[ATraining Step: 828  | total loss: [1m[32m0.07003[0m[0m | time: 16.715s
[2K
| RMSProp | epoch: 017 | loss: 0.07003 - acc: 0.9753 -- iter: 0896/1593
[A[ATraining Step: 829  | total loss: [1m[32m0.06550[0m[0m | time: 17.311s
[2K
| RMSProp | epoch: 017 | loss: 0.06550 - acc: 0.9778 -- iter: 0928/1593
[A[ATraining Step: 830  | total loss: [1m[32m0.05939[0m[0m | time: 17.909s
[2K
| RMSProp | epoch: 017 | loss: 0.05939 - acc: 0.9800 -- iter: 0960/1593
[A[ATraining Step: 831  | total loss: [1m[32m0.05591[0m[0m | time: 18.531s
[2K
| RMSProp | epoch: 017 | loss: 0.05591 - acc: 0.9820 -- iter: 0992/1593
[A[ATraining Step: 832  | total loss: [1m[32m0.05198[0m[0m | time: 19.155s
[2K
| RMSProp | epoch: 017 | loss: 0.05198 - acc: 0.9838 -- iter: 1024/1593
[A[ATraining Step: 833  | total loss: [1m[32m0.04715[0m[0m | time: 19.749s
[2K
| RMSProp | epoch: 017 | loss: 0.04715 - acc: 0.9854 -- iter: 1056/1593
[A[ATraining Step: 834  | total loss: [1m[32m0.05326[0m[0m | time: 20.380s
[2K
| RMSProp | epoch: 017 | loss: 0.05326 - acc: 0.9806 -- iter: 1088/1593
[A[ATraining Step: 835  | total loss: [1m[32m0.05148[0m[0m | time: 20.976s
[2K
| RMSProp | epoch: 017 | loss: 0.05148 - acc: 0.9794 -- iter: 1120/1593
[A[ATraining Step: 836  | total loss: [1m[32m0.04658[0m[0m | time: 21.580s
[2K
| RMSProp | epoch: 017 | loss: 0.04658 - acc: 0.9815 -- iter: 1152/1593
[A[ATraining Step: 837  | total loss: [1m[32m0.04207[0m[0m | time: 22.200s
[2K
| RMSProp | epoch: 017 | loss: 0.04207 - acc: 0.9834 -- iter: 1184/1593
[A[ATraining Step: 838  | total loss: [1m[32m0.04172[0m[0m | time: 22.810s
[2K
| RMSProp | epoch: 017 | loss: 0.04172 - acc: 0.9819 -- iter: 1216/1593
[A[ATraining Step: 839  | total loss: [1m[32m0.06626[0m[0m | time: 23.403s
[2K
| RMSProp | epoch: 017 | loss: 0.06626 - acc: 0.9743 -- iter: 1248/1593
[A[ATraining Step: 840  | total loss: [1m[32m0.06193[0m[0m | time: 23.996s
[2K
| RMSProp | epoch: 017 | loss: 0.06193 - acc: 0.9769 -- iter: 1280/1593
[A[ATraining Step: 841  | total loss: [1m[32m0.05903[0m[0m | time: 24.603s
[2K
| RMSProp | epoch: 017 | loss: 0.05903 - acc: 0.9761 -- iter: 1312/1593
[A[ATraining Step: 842  | total loss: [1m[32m0.07009[0m[0m | time: 25.204s
[2K
| RMSProp | epoch: 017 | loss: 0.07009 - acc: 0.9660 -- iter: 1344/1593
[A[ATraining Step: 843  | total loss: [1m[32m0.07807[0m[0m | time: 25.824s
[2K
| RMSProp | epoch: 017 | loss: 0.07807 - acc: 0.9663 -- iter: 1376/1593
[A[ATraining Step: 844  | total loss: [1m[32m0.07090[0m[0m | time: 26.417s
[2K
| RMSProp | epoch: 017 | loss: 0.07090 - acc: 0.9696 -- iter: 1408/1593
[A[ATraining Step: 845  | total loss: [1m[32m0.06548[0m[0m | time: 27.022s
[2K
| RMSProp | epoch: 017 | loss: 0.06548 - acc: 0.9727 -- iter: 1440/1593
[A[ATraining Step: 846  | total loss: [1m[32m0.05944[0m[0m | time: 27.627s
[2K
| RMSProp | epoch: 017 | loss: 0.05944 - acc: 0.9754 -- iter: 1472/1593
[A[ATraining Step: 847  | total loss: [1m[32m0.05427[0m[0m | time: 28.229s
[2K
| RMSProp | epoch: 017 | loss: 0.05427 - acc: 0.9779 -- iter: 1504/1593
[A[ATraining Step: 848  | total loss: [1m[32m0.05176[0m[0m | time: 28.835s
[2K
| RMSProp | epoch: 017 | loss: 0.05176 - acc: 0.9801 -- iter: 1536/1593
[A[ATraining Step: 849  | total loss: [1m[32m0.04698[0m[0m | time: 29.449s
[2K
| RMSProp | epoch: 017 | loss: 0.04698 - acc: 0.9821 -- iter: 1568/1593
[A[ATraining Step: 850  | total loss: [1m[32m0.04346[0m[0m | time: 31.615s
[2K
| RMSProp | epoch: 017 | loss: 0.04346 - acc: 0.9839 | val_loss: 0.58730 - val_acc: 0.8454 -- iter: 1593/1593
--
Training Step: 851  | total loss: [1m[32m0.03936[0m[0m | time: 0.592s
[2K
| RMSProp | epoch: 018 | loss: 0.03936 - acc: 0.9855 -- iter: 0032/1593
[A[ATraining Step: 852  | total loss: [1m[32m0.03609[0m[0m | time: 1.193s
[2K
| RMSProp | epoch: 018 | loss: 0.03609 - acc: 0.9869 -- iter: 0064/1593
[A[ATraining Step: 853  | total loss: [1m[32m0.03323[0m[0m | time: 1.802s
[2K
| RMSProp | epoch: 018 | loss: 0.03323 - acc: 0.9882 -- iter: 0096/1593
[A[ATraining Step: 854  | total loss: [1m[32m0.03009[0m[0m | time: 2.392s
[2K
| RMSProp | epoch: 018 | loss: 0.03009 - acc: 0.9894 -- iter: 0128/1593
[A[ATraining Step: 855  | total loss: [1m[32m0.02773[0m[0m | time: 2.998s
[2K
| RMSProp | epoch: 018 | loss: 0.02773 - acc: 0.9905 -- iter: 0160/1593
[A[ATraining Step: 856  | total loss: [1m[32m0.02507[0m[0m | time: 3.597s
[2K
| RMSProp | epoch: 018 | loss: 0.02507 - acc: 0.9914 -- iter: 0192/1593
[A[ATraining Step: 857  | total loss: [1m[32m0.02278[0m[0m | time: 4.189s
[2K
| RMSProp | epoch: 018 | loss: 0.02278 - acc: 0.9923 -- iter: 0224/1593
[A[ATraining Step: 858  | total loss: [1m[32m0.02115[0m[0m | time: 4.778s
[2K
| RMSProp | epoch: 018 | loss: 0.02115 - acc: 0.9931 -- iter: 0256/1593
[A[ATraining Step: 859  | total loss: [1m[32m0.01933[0m[0m | time: 5.368s
[2K
| RMSProp | epoch: 018 | loss: 0.01933 - acc: 0.9937 -- iter: 0288/1593
[A[ATraining Step: 860  | total loss: [1m[32m0.01742[0m[0m | time: 5.966s
[2K
| RMSProp | epoch: 018 | loss: 0.01742 - acc: 0.9944 -- iter: 0320/1593
[A[ATraining Step: 861  | total loss: [1m[32m0.01577[0m[0m | time: 6.564s
[2K
| RMSProp | epoch: 018 | loss: 0.01577 - acc: 0.9949 -- iter: 0352/1593
[A[ATraining Step: 862  | total loss: [1m[32m0.01537[0m[0m | time: 7.161s
[2K
| RMSProp | epoch: 018 | loss: 0.01537 - acc: 0.9954 -- iter: 0384/1593
[A[ATraining Step: 863  | total loss: [1m[32m0.01423[0m[0m | time: 7.750s
[2K
| RMSProp | epoch: 018 | loss: 0.01423 - acc: 0.9959 -- iter: 0416/1593
[A[ATraining Step: 864  | total loss: [1m[32m0.01464[0m[0m | time: 8.355s
[2K
| RMSProp | epoch: 018 | loss: 0.01464 - acc: 0.9963 -- iter: 0448/1593
[A[ATraining Step: 865  | total loss: [1m[32m0.01692[0m[0m | time: 8.937s
[2K
| RMSProp | epoch: 018 | loss: 0.01692 - acc: 0.9936 -- iter: 0480/1593
[A[ATraining Step: 866  | total loss: [1m[32m0.05235[0m[0m | time: 9.434s
[2K
| RMSProp | epoch: 018 | loss: 0.05235 - acc: 0.9879 -- iter: 0512/1593
[A[ATraining Step: 867  | total loss: [1m[32m0.06193[0m[0m | time: 9.937s
[2K
| RMSProp | epoch: 018 | loss: 0.06193 - acc: 0.9852 -- iter: 0544/1593
[A[ATraining Step: 868  | total loss: [1m[32m0.06046[0m[0m | time: 10.541s
[2K
| RMSProp | epoch: 018 | loss: 0.06046 - acc: 0.9866 -- iter: 0576/1593
[A[ATraining Step: 869  | total loss: [1m[32m0.05713[0m[0m | time: 11.168s
[2K
| RMSProp | epoch: 018 | loss: 0.05713 - acc: 0.9880 -- iter: 0608/1593
[A[ATraining Step: 870  | total loss: [1m[32m0.06154[0m[0m | time: 11.777s
[2K
| RMSProp | epoch: 018 | loss: 0.06154 - acc: 0.9861 -- iter: 0640/1593
[A[ATraining Step: 871  | total loss: [1m[32m0.06750[0m[0m | time: 12.381s
[2K
| RMSProp | epoch: 018 | loss: 0.06750 - acc: 0.9812 -- iter: 0672/1593
[A[ATraining Step: 872  | total loss: [1m[32m0.06286[0m[0m | time: 12.971s
[2K
| RMSProp | epoch: 018 | loss: 0.06286 - acc: 0.9831 -- iter: 0704/1593
[A[ATraining Step: 873  | total loss: [1m[32m0.05727[0m[0m | time: 13.572s
[2K
| RMSProp | epoch: 018 | loss: 0.05727 - acc: 0.9848 -- iter: 0736/1593
[A[ATraining Step: 874  | total loss: [1m[32m0.05217[0m[0m | time: 14.197s
[2K
| RMSProp | epoch: 018 | loss: 0.05217 - acc: 0.9863 -- iter: 0768/1593
[A[ATraining Step: 875  | total loss: [1m[32m0.04713[0m[0m | time: 14.791s
[2K
| RMSProp | epoch: 018 | loss: 0.04713 - acc: 0.9877 -- iter: 0800/1593
[A[ATraining Step: 876  | total loss: [1m[32m0.04474[0m[0m | time: 15.404s
[2K
| RMSProp | epoch: 018 | loss: 0.04474 - acc: 0.9889 -- iter: 0832/1593
[A[ATraining Step: 877  | total loss: [1m[32m0.04528[0m[0m | time: 16.010s
[2K
| RMSProp | epoch: 018 | loss: 0.04528 - acc: 0.9869 -- iter: 0864/1593
[A[ATraining Step: 878  | total loss: [1m[32m0.04268[0m[0m | time: 16.621s
[2K
| RMSProp | epoch: 018 | loss: 0.04268 - acc: 0.9882 -- iter: 0896/1593
[A[ATraining Step: 879  | total loss: [1m[32m0.03924[0m[0m | time: 17.242s
[2K
| RMSProp | epoch: 018 | loss: 0.03924 - acc: 0.9894 -- iter: 0928/1593
[A[ATraining Step: 880  | total loss: [1m[32m0.05099[0m[0m | time: 17.856s
[2K
| RMSProp | epoch: 018 | loss: 0.05099 - acc: 0.9873 -- iter: 0960/1593
[A[ATraining Step: 881  | total loss: [1m[32m0.05284[0m[0m | time: 18.447s
[2K
| RMSProp | epoch: 018 | loss: 0.05284 - acc: 0.9855 -- iter: 0992/1593
[A[ATraining Step: 882  | total loss: [1m[32m0.05113[0m[0m | time: 19.076s
[2K
| RMSProp | epoch: 018 | loss: 0.05113 - acc: 0.9869 -- iter: 1024/1593
[A[ATraining Step: 883  | total loss: [1m[32m0.04951[0m[0m | time: 19.671s
[2K
| RMSProp | epoch: 018 | loss: 0.04951 - acc: 0.9851 -- iter: 1056/1593
[A[ATraining Step: 884  | total loss: [1m[32m0.04640[0m[0m | time: 20.280s
[2K
| RMSProp | epoch: 018 | loss: 0.04640 - acc: 0.9866 -- iter: 1088/1593
[A[ATraining Step: 885  | total loss: [1m[32m0.04192[0m[0m | time: 20.906s
[2K
| RMSProp | epoch: 018 | loss: 0.04192 - acc: 0.9879 -- iter: 1120/1593
[A[ATraining Step: 886  | total loss: [1m[32m0.06396[0m[0m | time: 21.521s
[2K
| RMSProp | epoch: 018 | loss: 0.06396 - acc: 0.9860 -- iter: 1152/1593
[A[ATraining Step: 887  | total loss: [1m[32m0.06208[0m[0m | time: 22.130s
[2K
| RMSProp | epoch: 018 | loss: 0.06208 - acc: 0.9843 -- iter: 1184/1593
[A[ATraining Step: 888  | total loss: [1m[32m0.05806[0m[0m | time: 22.735s
[2K
| RMSProp | epoch: 018 | loss: 0.05806 - acc: 0.9859 -- iter: 1216/1593
[A[ATraining Step: 889  | total loss: [1m[32m0.05294[0m[0m | time: 23.338s
[2K
| RMSProp | epoch: 018 | loss: 0.05294 - acc: 0.9873 -- iter: 1248/1593
[A[ATraining Step: 890  | total loss: [1m[32m0.04809[0m[0m | time: 23.951s
[2K
| RMSProp | epoch: 018 | loss: 0.04809 - acc: 0.9885 -- iter: 1280/1593
[A[ATraining Step: 891  | total loss: [1m[32m0.04387[0m[0m | time: 24.569s
[2K
| RMSProp | epoch: 018 | loss: 0.04387 - acc: 0.9897 -- iter: 1312/1593
[A[ATraining Step: 892  | total loss: [1m[32m0.03978[0m[0m | time: 25.165s
[2K
| RMSProp | epoch: 018 | loss: 0.03978 - acc: 0.9907 -- iter: 1344/1593
[A[ATraining Step: 893  | total loss: [1m[32m0.03628[0m[0m | time: 25.789s
[2K
| RMSProp | epoch: 018 | loss: 0.03628 - acc: 0.9916 -- iter: 1376/1593
[A[ATraining Step: 894  | total loss: [1m[32m0.03376[0m[0m | time: 26.395s
[2K
| RMSProp | epoch: 018 | loss: 0.03376 - acc: 0.9925 -- iter: 1408/1593
[A[ATraining Step: 895  | total loss: [1m[32m0.03055[0m[0m | time: 26.997s
[2K
| RMSProp | epoch: 018 | loss: 0.03055 - acc: 0.9932 -- iter: 1440/1593
[A[ATraining Step: 896  | total loss: [1m[32m0.02773[0m[0m | time: 27.595s
[2K
| RMSProp | epoch: 018 | loss: 0.02773 - acc: 0.9939 -- iter: 1472/1593
[A[ATraining Step: 897  | total loss: [1m[32m0.02520[0m[0m | time: 28.214s
[2K
| RMSProp | epoch: 018 | loss: 0.02520 - acc: 0.9945 -- iter: 1504/1593
[A[ATraining Step: 898  | total loss: [1m[32m0.02286[0m[0m | time: 28.815s
[2K
| RMSProp | epoch: 018 | loss: 0.02286 - acc: 0.9951 -- iter: 1536/1593
[A[ATraining Step: 899  | total loss: [1m[32m0.02065[0m[0m | time: 29.418s
[2K
| RMSProp | epoch: 018 | loss: 0.02065 - acc: 0.9956 -- iter: 1568/1593
[A[ATraining Step: 900  | total loss: [1m[32m0.01875[0m[0m | time: 31.575s
[2K
| RMSProp | epoch: 018 | loss: 0.01875 - acc: 0.9960 | val_loss: 0.67184 - val_acc: 0.8755 -- iter: 1593/1593
--
Training Step: 901  | total loss: [1m[32m0.01706[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 019 | loss: 0.01706 - acc: 0.9964 -- iter: 0032/1593
[A[ATraining Step: 902  | total loss: [1m[32m0.01541[0m[0m | time: 1.204s
[2K
| RMSProp | epoch: 019 | loss: 0.01541 - acc: 0.9968 -- iter: 0064/1593
[A[ATraining Step: 903  | total loss: [1m[32m0.01412[0m[0m | time: 1.798s
[2K
| RMSProp | epoch: 019 | loss: 0.01412 - acc: 0.9971 -- iter: 0096/1593
[A[ATraining Step: 904  | total loss: [1m[32m0.01368[0m[0m | time: 2.418s
[2K
| RMSProp | epoch: 019 | loss: 0.01368 - acc: 0.9974 -- iter: 0128/1593
[A[ATraining Step: 905  | total loss: [1m[32m0.01359[0m[0m | time: 3.031s
[2K
| RMSProp | epoch: 019 | loss: 0.01359 - acc: 0.9976 -- iter: 0160/1593
[A[ATraining Step: 906  | total loss: [1m[32m0.01342[0m[0m | time: 3.641s
[2K
| RMSProp | epoch: 019 | loss: 0.01342 - acc: 0.9979 -- iter: 0192/1593
[A[ATraining Step: 907  | total loss: [1m[32m0.01231[0m[0m | time: 4.241s
[2K
| RMSProp | epoch: 019 | loss: 0.01231 - acc: 0.9981 -- iter: 0224/1593
[A[ATraining Step: 908  | total loss: [1m[32m0.01237[0m[0m | time: 4.842s
[2K
| RMSProp | epoch: 019 | loss: 0.01237 - acc: 0.9983 -- iter: 0256/1593
[A[ATraining Step: 909  | total loss: [1m[32m0.01547[0m[0m | time: 5.475s
[2K
| RMSProp | epoch: 019 | loss: 0.01547 - acc: 0.9953 -- iter: 0288/1593
[A[ATraining Step: 910  | total loss: [1m[32m0.01628[0m[0m | time: 6.083s
[2K
| RMSProp | epoch: 019 | loss: 0.01628 - acc: 0.9958 -- iter: 0320/1593
[A[ATraining Step: 911  | total loss: [1m[32m0.03548[0m[0m | time: 6.672s
[2K
| RMSProp | epoch: 019 | loss: 0.03548 - acc: 0.9900 -- iter: 0352/1593
[A[ATraining Step: 912  | total loss: [1m[32m0.06994[0m[0m | time: 7.277s
[2K
| RMSProp | epoch: 019 | loss: 0.06994 - acc: 0.9816 -- iter: 0384/1593
[A[ATraining Step: 913  | total loss: [1m[32m0.06974[0m[0m | time: 7.898s
[2K
| RMSProp | epoch: 019 | loss: 0.06974 - acc: 0.9803 -- iter: 0416/1593
[A[ATraining Step: 914  | total loss: [1m[32m0.06362[0m[0m | time: 8.503s
[2K
| RMSProp | epoch: 019 | loss: 0.06362 - acc: 0.9823 -- iter: 0448/1593
[A[ATraining Step: 915  | total loss: [1m[32m0.05735[0m[0m | time: 9.097s
[2K
| RMSProp | epoch: 019 | loss: 0.05735 - acc: 0.9841 -- iter: 0480/1593
[A[ATraining Step: 916  | total loss: [1m[32m0.05184[0m[0m | time: 9.675s
[2K
| RMSProp | epoch: 019 | loss: 0.05184 - acc: 0.9856 -- iter: 0512/1593
[A[ATraining Step: 917  | total loss: [1m[32m0.05172[0m[0m | time: 10.165s
[2K
| RMSProp | epoch: 019 | loss: 0.05172 - acc: 0.9840 -- iter: 0544/1593
[A[ATraining Step: 918  | total loss: [1m[32m0.04802[0m[0m | time: 10.664s
[2K
| RMSProp | epoch: 019 | loss: 0.04802 - acc: 0.9856 -- iter: 0576/1593
[A[ATraining Step: 919  | total loss: [1m[32m0.04334[0m[0m | time: 11.271s
[2K
| RMSProp | epoch: 019 | loss: 0.04334 - acc: 0.9870 -- iter: 0608/1593
[A[ATraining Step: 920  | total loss: [1m[32m0.04957[0m[0m | time: 11.871s
[2K
| RMSProp | epoch: 019 | loss: 0.04957 - acc: 0.9852 -- iter: 0640/1593
[A[ATraining Step: 921  | total loss: [1m[32m0.05452[0m[0m | time: 12.488s
[2K
| RMSProp | epoch: 019 | loss: 0.05452 - acc: 0.9835 -- iter: 0672/1593
[A[ATraining Step: 922  | total loss: [1m[32m0.04940[0m[0m | time: 13.091s
[2K
| RMSProp | epoch: 019 | loss: 0.04940 - acc: 0.9852 -- iter: 0704/1593
[A[ATraining Step: 923  | total loss: [1m[32m0.05687[0m[0m | time: 13.686s
[2K
| RMSProp | epoch: 019 | loss: 0.05687 - acc: 0.9804 -- iter: 0736/1593
[A[ATraining Step: 924  | total loss: [1m[32m0.07517[0m[0m | time: 14.293s
[2K
| RMSProp | epoch: 019 | loss: 0.07517 - acc: 0.9792 -- iter: 0768/1593
[A[ATraining Step: 925  | total loss: [1m[32m0.06988[0m[0m | time: 14.895s
[2K
| RMSProp | epoch: 019 | loss: 0.06988 - acc: 0.9813 -- iter: 0800/1593
[A[ATraining Step: 926  | total loss: [1m[32m0.06640[0m[0m | time: 15.480s
[2K
| RMSProp | epoch: 019 | loss: 0.06640 - acc: 0.9832 -- iter: 0832/1593
[A[ATraining Step: 927  | total loss: [1m[32m0.06234[0m[0m | time: 16.071s
[2K
| RMSProp | epoch: 019 | loss: 0.06234 - acc: 0.9849 -- iter: 0864/1593
[A[ATraining Step: 928  | total loss: [1m[32m0.05901[0m[0m | time: 16.666s
[2K
| RMSProp | epoch: 019 | loss: 0.05901 - acc: 0.9833 -- iter: 0896/1593
[A[ATraining Step: 929  | total loss: [1m[32m0.05974[0m[0m | time: 17.272s
[2K
| RMSProp | epoch: 019 | loss: 0.05974 - acc: 0.9787 -- iter: 0928/1593
[A[ATraining Step: 930  | total loss: [1m[32m0.07189[0m[0m | time: 17.871s
[2K
| RMSProp | epoch: 019 | loss: 0.07189 - acc: 0.9746 -- iter: 0960/1593
[A[ATraining Step: 931  | total loss: [1m[32m0.07402[0m[0m | time: 18.472s
[2K
| RMSProp | epoch: 019 | loss: 0.07402 - acc: 0.9740 -- iter: 0992/1593
[A[ATraining Step: 932  | total loss: [1m[32m0.07149[0m[0m | time: 19.083s
[2K
| RMSProp | epoch: 019 | loss: 0.07149 - acc: 0.9735 -- iter: 1024/1593
[A[ATraining Step: 933  | total loss: [1m[32m0.06624[0m[0m | time: 19.697s
[2K
| RMSProp | epoch: 019 | loss: 0.06624 - acc: 0.9761 -- iter: 1056/1593
[A[ATraining Step: 934  | total loss: [1m[32m0.06036[0m[0m | time: 20.286s
[2K
| RMSProp | epoch: 019 | loss: 0.06036 - acc: 0.9785 -- iter: 1088/1593
[A[ATraining Step: 935  | total loss: [1m[32m0.06848[0m[0m | time: 20.869s
[2K
| RMSProp | epoch: 019 | loss: 0.06848 - acc: 0.9775 -- iter: 1120/1593
[A[ATraining Step: 936  | total loss: [1m[32m0.06449[0m[0m | time: 21.461s
[2K
| RMSProp | epoch: 019 | loss: 0.06449 - acc: 0.9798 -- iter: 1152/1593
[A[ATraining Step: 937  | total loss: [1m[32m0.09660[0m[0m | time: 22.066s
[2K
| RMSProp | epoch: 019 | loss: 0.09660 - acc: 0.9755 -- iter: 1184/1593
[A[ATraining Step: 938  | total loss: [1m[32m0.08901[0m[0m | time: 22.667s
[2K
| RMSProp | epoch: 019 | loss: 0.08901 - acc: 0.9780 -- iter: 1216/1593
[A[ATraining Step: 939  | total loss: [1m[32m0.08165[0m[0m | time: 23.276s
[2K
| RMSProp | epoch: 019 | loss: 0.08165 - acc: 0.9802 -- iter: 1248/1593
[A[ATraining Step: 940  | total loss: [1m[32m0.07979[0m[0m | time: 23.873s
[2K
| RMSProp | epoch: 019 | loss: 0.07979 - acc: 0.9790 -- iter: 1280/1593
[A[ATraining Step: 941  | total loss: [1m[32m0.07314[0m[0m | time: 24.474s
[2K
| RMSProp | epoch: 019 | loss: 0.07314 - acc: 0.9811 -- iter: 1312/1593
[A[ATraining Step: 942  | total loss: [1m[32m0.06632[0m[0m | time: 25.071s
[2K
| RMSProp | epoch: 019 | loss: 0.06632 - acc: 0.9830 -- iter: 1344/1593
[A[ATraining Step: 943  | total loss: [1m[32m0.06018[0m[0m | time: 25.683s
[2K
| RMSProp | epoch: 019 | loss: 0.06018 - acc: 0.9847 -- iter: 1376/1593
[A[ATraining Step: 944  | total loss: [1m[32m0.05697[0m[0m | time: 26.275s
[2K
| RMSProp | epoch: 019 | loss: 0.05697 - acc: 0.9831 -- iter: 1408/1593
[A[ATraining Step: 945  | total loss: [1m[32m0.05209[0m[0m | time: 26.876s
[2K
| RMSProp | epoch: 019 | loss: 0.05209 - acc: 0.9848 -- iter: 1440/1593
[A[ATraining Step: 946  | total loss: [1m[32m0.04820[0m[0m | time: 27.481s
[2K
| RMSProp | epoch: 019 | loss: 0.04820 - acc: 0.9863 -- iter: 1472/1593
[A[ATraining Step: 947  | total loss: [1m[32m0.04682[0m[0m | time: 28.103s
[2K
| RMSProp | epoch: 019 | loss: 0.04682 - acc: 0.9846 -- iter: 1504/1593
[A[ATraining Step: 948  | total loss: [1m[32m0.04250[0m[0m | time: 28.749s
[2K
| RMSProp | epoch: 019 | loss: 0.04250 - acc: 0.9861 -- iter: 1536/1593
[A[ATraining Step: 949  | total loss: [1m[32m0.03862[0m[0m | time: 29.355s
[2K
| RMSProp | epoch: 019 | loss: 0.03862 - acc: 0.9875 -- iter: 1568/1593
[A[ATraining Step: 950  | total loss: [1m[32m0.03490[0m[0m | time: 31.562s
[2K
| RMSProp | epoch: 019 | loss: 0.03490 - acc: 0.9888 | val_loss: 0.59124 - val_acc: 0.8474 -- iter: 1593/1593
--
Training Step: 951  | total loss: [1m[32m0.03156[0m[0m | time: 0.596s
[2K
| RMSProp | epoch: 020 | loss: 0.03156 - acc: 0.9899 -- iter: 0032/1593
[A[ATraining Step: 952  | total loss: [1m[32m0.02891[0m[0m | time: 1.202s
[2K
| RMSProp | epoch: 020 | loss: 0.02891 - acc: 0.9909 -- iter: 0064/1593
[A[ATraining Step: 953  | total loss: [1m[32m0.02621[0m[0m | time: 1.799s
[2K
| RMSProp | epoch: 020 | loss: 0.02621 - acc: 0.9918 -- iter: 0096/1593
[A[ATraining Step: 954  | total loss: [1m[32m0.02364[0m[0m | time: 2.401s
[2K
| RMSProp | epoch: 020 | loss: 0.02364 - acc: 0.9926 -- iter: 0128/1593
[A[ATraining Step: 955  | total loss: [1m[32m0.02244[0m[0m | time: 3.001s
[2K
| RMSProp | epoch: 020 | loss: 0.02244 - acc: 0.9934 -- iter: 0160/1593
[A[ATraining Step: 956  | total loss: [1m[32m0.02058[0m[0m | time: 3.599s
[2K
| RMSProp | epoch: 020 | loss: 0.02058 - acc: 0.9940 -- iter: 0192/1593
[A[ATraining Step: 957  | total loss: [1m[32m0.02129[0m[0m | time: 4.203s
[2K
| RMSProp | epoch: 020 | loss: 0.02129 - acc: 0.9915 -- iter: 0224/1593
[A[ATraining Step: 958  | total loss: [1m[32m0.02871[0m[0m | time: 4.798s
[2K
| RMSProp | epoch: 020 | loss: 0.02871 - acc: 0.9861 -- iter: 0256/1593
[A[ATraining Step: 959  | total loss: [1m[32m0.04342[0m[0m | time: 5.385s
[2K
| RMSProp | epoch: 020 | loss: 0.04342 - acc: 0.9812 -- iter: 0288/1593
[A[ATraining Step: 960  | total loss: [1m[32m0.04019[0m[0m | time: 5.968s
[2K
| RMSProp | epoch: 020 | loss: 0.04019 - acc: 0.9831 -- iter: 0320/1593
[A[ATraining Step: 961  | total loss: [1m[32m0.03635[0m[0m | time: 6.592s
[2K
| RMSProp | epoch: 020 | loss: 0.03635 - acc: 0.9848 -- iter: 0352/1593
[A[ATraining Step: 962  | total loss: [1m[32m0.03314[0m[0m | time: 7.192s
[2K
| RMSProp | epoch: 020 | loss: 0.03314 - acc: 0.9863 -- iter: 0384/1593
[A[ATraining Step: 963  | total loss: [1m[32m0.03658[0m[0m | time: 7.788s
[2K
| RMSProp | epoch: 020 | loss: 0.03658 - acc: 0.9814 -- iter: 0416/1593
[A[ATraining Step: 964  | total loss: [1m[32m0.03946[0m[0m | time: 8.381s
[2K
| RMSProp | epoch: 020 | loss: 0.03946 - acc: 0.9802 -- iter: 0448/1593
[A[ATraining Step: 965  | total loss: [1m[32m0.07077[0m[0m | time: 8.973s
[2K
| RMSProp | epoch: 020 | loss: 0.07077 - acc: 0.9728 -- iter: 0480/1593
[A[ATraining Step: 966  | total loss: [1m[32m0.07273[0m[0m | time: 9.593s
[2K
| RMSProp | epoch: 020 | loss: 0.07273 - acc: 0.9693 -- iter: 0512/1593
[A[ATraining Step: 967  | total loss: [1m[32m0.07262[0m[0m | time: 10.166s
[2K
| RMSProp | epoch: 020 | loss: 0.07262 - acc: 0.9661 -- iter: 0544/1593
[A[ATraining Step: 968  | total loss: [1m[32m0.06999[0m[0m | time: 10.646s
[2K
| RMSProp | epoch: 020 | loss: 0.06999 - acc: 0.9663 -- iter: 0576/1593
[A[ATraining Step: 969  | total loss: [1m[32m0.06336[0m[0m | time: 11.144s
[2K
| RMSProp | epoch: 020 | loss: 0.06336 - acc: 0.9697 -- iter: 0608/1593
[A[ATraining Step: 970  | total loss: [1m[32m0.05728[0m[0m | time: 11.738s
[2K
| RMSProp | epoch: 020 | loss: 0.05728 - acc: 0.9727 -- iter: 0640/1593
[A[ATraining Step: 971  | total loss: [1m[32m0.05767[0m[0m | time: 12.340s
[2K
| RMSProp | epoch: 020 | loss: 0.05767 - acc: 0.9723 -- iter: 0672/1593
[A[ATraining Step: 972  | total loss: [1m[32m0.05705[0m[0m | time: 12.934s
[2K
| RMSProp | epoch: 020 | loss: 0.05705 - acc: 0.9720 -- iter: 0704/1593
[A[ATraining Step: 973  | total loss: [1m[32m0.05602[0m[0m | time: 13.549s
[2K
| RMSProp | epoch: 020 | loss: 0.05602 - acc: 0.9717 -- iter: 0736/1593
[A[ATraining Step: 974  | total loss: [1m[32m0.06635[0m[0m | time: 14.156s
[2K
| RMSProp | epoch: 020 | loss: 0.06635 - acc: 0.9682 -- iter: 0768/1593
[A[ATraining Step: 975  | total loss: [1m[32m0.06190[0m[0m | time: 14.761s
[2K
| RMSProp | epoch: 020 | loss: 0.06190 - acc: 0.9714 -- iter: 0800/1593
[A[ATraining Step: 976  | total loss: [1m[32m0.05628[0m[0m | time: 15.364s
[2K
| RMSProp | epoch: 020 | loss: 0.05628 - acc: 0.9743 -- iter: 0832/1593
[A[ATraining Step: 977  | total loss: [1m[32m0.05123[0m[0m | time: 15.960s
[2K
| RMSProp | epoch: 020 | loss: 0.05123 - acc: 0.9768 -- iter: 0864/1593
[A[ATraining Step: 978  | total loss: [1m[32m0.04654[0m[0m | time: 16.556s
[2K
| RMSProp | epoch: 020 | loss: 0.04654 - acc: 0.9792 -- iter: 0896/1593
[A[ATraining Step: 979  | total loss: [1m[32m0.04228[0m[0m | time: 17.162s
[2K
| RMSProp | epoch: 020 | loss: 0.04228 - acc: 0.9812 -- iter: 0928/1593
[A[ATraining Step: 980  | total loss: [1m[32m0.03828[0m[0m | time: 17.756s
[2K
| RMSProp | epoch: 020 | loss: 0.03828 - acc: 0.9831 -- iter: 0960/1593
[A[ATraining Step: 981  | total loss: [1m[32m0.03664[0m[0m | time: 18.357s
[2K
| RMSProp | epoch: 020 | loss: 0.03664 - acc: 0.9848 -- iter: 0992/1593
[A[ATraining Step: 982  | total loss: [1m[32m0.03434[0m[0m | time: 18.962s
[2K
| RMSProp | epoch: 020 | loss: 0.03434 - acc: 0.9863 -- iter: 1024/1593
[A[ATraining Step: 983  | total loss: [1m[32m0.03313[0m[0m | time: 19.557s
[2K
| RMSProp | epoch: 020 | loss: 0.03313 - acc: 0.9877 -- iter: 1056/1593
[A[ATraining Step: 984  | total loss: [1m[32m0.07527[0m[0m | time: 20.165s
[2K
| RMSProp | epoch: 020 | loss: 0.07527 - acc: 0.9702 -- iter: 1088/1593
[A[ATraining Step: 985  | total loss: [1m[32m0.07057[0m[0m | time: 20.797s
[2K
| RMSProp | epoch: 020 | loss: 0.07057 - acc: 0.9732 -- iter: 1120/1593
[A[ATraining Step: 986  | total loss: [1m[32m0.06418[0m[0m | time: 21.402s
[2K
| RMSProp | epoch: 020 | loss: 0.06418 - acc: 0.9758 -- iter: 1152/1593
[A[ATraining Step: 987  | total loss: [1m[32m0.05888[0m[0m | time: 22.000s
[2K
| RMSProp | epoch: 020 | loss: 0.05888 - acc: 0.9783 -- iter: 1184/1593
[A[ATraining Step: 988  | total loss: [1m[32m0.07248[0m[0m | time: 22.584s
[2K
| RMSProp | epoch: 020 | loss: 0.07248 - acc: 0.9773 -- iter: 1216/1593
[A[ATraining Step: 989  | total loss: [1m[32m0.06691[0m[0m | time: 23.196s
[2K
| RMSProp | epoch: 020 | loss: 0.06691 - acc: 0.9796 -- iter: 1248/1593
[A[ATraining Step: 990  | total loss: [1m[32m0.06046[0m[0m | time: 23.788s
[2K
| RMSProp | epoch: 020 | loss: 0.06046 - acc: 0.9816 -- iter: 1280/1593
[A[ATraining Step: 991  | total loss: [1m[32m0.05456[0m[0m | time: 24.385s
[2K
| RMSProp | epoch: 020 | loss: 0.05456 - acc: 0.9835 -- iter: 1312/1593
[A[ATraining Step: 992  | total loss: [1m[32m0.04938[0m[0m | time: 24.990s
[2K
| RMSProp | epoch: 020 | loss: 0.04938 - acc: 0.9851 -- iter: 1344/1593
[A[ATraining Step: 993  | total loss: [1m[32m0.04694[0m[0m | time: 25.592s
[2K
| RMSProp | epoch: 020 | loss: 0.04694 - acc: 0.9835 -- iter: 1376/1593
[A[ATraining Step: 994  | total loss: [1m[32m0.04264[0m[0m | time: 26.187s
[2K
| RMSProp | epoch: 020 | loss: 0.04264 - acc: 0.9851 -- iter: 1408/1593
[A[ATraining Step: 995  | total loss: [1m[32m0.03875[0m[0m | time: 26.801s
[2K
| RMSProp | epoch: 020 | loss: 0.03875 - acc: 0.9866 -- iter: 1440/1593
[A[ATraining Step: 996  | total loss: [1m[32m0.03499[0m[0m | time: 27.422s
[2K
| RMSProp | epoch: 020 | loss: 0.03499 - acc: 0.9880 -- iter: 1472/1593
[A[ATraining Step: 997  | total loss: [1m[32m0.03169[0m[0m | time: 28.024s
[2K
| RMSProp | epoch: 020 | loss: 0.03169 - acc: 0.9892 -- iter: 1504/1593
[A[ATraining Step: 998  | total loss: [1m[32m0.02869[0m[0m | time: 28.620s
[2K
| RMSProp | epoch: 020 | loss: 0.02869 - acc: 0.9902 -- iter: 1536/1593
[A[ATraining Step: 999  | total loss: [1m[32m0.02591[0m[0m | time: 29.222s
[2K
| RMSProp | epoch: 020 | loss: 0.02591 - acc: 0.9912 -- iter: 1568/1593
[A[ATraining Step: 1000  | total loss: [1m[32m0.02401[0m[0m | time: 31.406s
[2K
| RMSProp | epoch: 020 | loss: 0.02401 - acc: 0.9921 | val_loss: 0.97079 - val_acc: 0.8112 -- iter: 1593/1593
--
Training Step: 1001  | total loss: [1m[32m0.02368[0m[0m | time: 0.607s
[2K
| RMSProp | epoch: 021 | loss: 0.02368 - acc: 0.9929 -- iter: 0032/1593
[A[ATraining Step: 1002  | total loss: [1m[32m0.02801[0m[0m | time: 1.207s
[2K
| RMSProp | epoch: 021 | loss: 0.02801 - acc: 0.9905 -- iter: 0064/1593
[A[ATraining Step: 1003  | total loss: [1m[32m0.05072[0m[0m | time: 1.818s
[2K
| RMSProp | epoch: 021 | loss: 0.05072 - acc: 0.9883 -- iter: 0096/1593
[A[ATraining Step: 1004  | total loss: [1m[32m0.06598[0m[0m | time: 2.428s
[2K
| RMSProp | epoch: 021 | loss: 0.06598 - acc: 0.9863 -- iter: 0128/1593
[A[ATraining Step: 1005  | total loss: [1m[32m0.06025[0m[0m | time: 3.033s
[2K
| RMSProp | epoch: 021 | loss: 0.06025 - acc: 0.9877 -- iter: 0160/1593
[A[ATraining Step: 1006  | total loss: [1m[32m0.05841[0m[0m | time: 3.632s
[2K
| RMSProp | epoch: 021 | loss: 0.05841 - acc: 0.9858 -- iter: 0192/1593
[A[ATraining Step: 1007  | total loss: [1m[32m0.05310[0m[0m | time: 4.239s
[2K
| RMSProp | epoch: 021 | loss: 0.05310 - acc: 0.9872 -- iter: 0224/1593
[A[ATraining Step: 1008  | total loss: [1m[32m0.04869[0m[0m | time: 4.848s
[2K
| RMSProp | epoch: 021 | loss: 0.04869 - acc: 0.9885 -- iter: 0256/1593
[A[ATraining Step: 1009  | total loss: [1m[32m0.04411[0m[0m | time: 5.464s
[2K
| RMSProp | epoch: 021 | loss: 0.04411 - acc: 0.9897 -- iter: 0288/1593
[A[ATraining Step: 1010  | total loss: [1m[32m0.03987[0m[0m | time: 6.080s
[2K
| RMSProp | epoch: 021 | loss: 0.03987 - acc: 0.9907 -- iter: 0320/1593
[A[ATraining Step: 1011  | total loss: [1m[32m0.03658[0m[0m | time: 6.704s
[2K
| RMSProp | epoch: 021 | loss: 0.03658 - acc: 0.9916 -- iter: 0352/1593
[A[ATraining Step: 1012  | total loss: [1m[32m0.03385[0m[0m | time: 7.313s
[2K
| RMSProp | epoch: 021 | loss: 0.03385 - acc: 0.9925 -- iter: 0384/1593
[A[ATraining Step: 1013  | total loss: [1m[32m0.03062[0m[0m | time: 7.910s
[2K
| RMSProp | epoch: 021 | loss: 0.03062 - acc: 0.9932 -- iter: 0416/1593
[A[ATraining Step: 1014  | total loss: [1m[32m0.03055[0m[0m | time: 8.511s
[2K
| RMSProp | epoch: 021 | loss: 0.03055 - acc: 0.9908 -- iter: 0448/1593
[A[ATraining Step: 1015  | total loss: [1m[32m0.03567[0m[0m | time: 9.119s
[2K
| RMSProp | epoch: 021 | loss: 0.03567 - acc: 0.9854 -- iter: 0480/1593
[A[ATraining Step: 1016  | total loss: [1m[32m0.08890[0m[0m | time: 9.722s
[2K
| RMSProp | epoch: 021 | loss: 0.08890 - acc: 0.9713 -- iter: 0512/1593
[A[ATraining Step: 1017  | total loss: [1m[32m0.08053[0m[0m | time: 10.340s
[2K
| RMSProp | epoch: 021 | loss: 0.08053 - acc: 0.9741 -- iter: 0544/1593
[A[ATraining Step: 1018  | total loss: [1m[32m0.07316[0m[0m | time: 10.941s
[2K
| RMSProp | epoch: 021 | loss: 0.07316 - acc: 0.9767 -- iter: 0576/1593
[A[ATraining Step: 1019  | total loss: [1m[32m0.06621[0m[0m | time: 11.419s
[2K
| RMSProp | epoch: 021 | loss: 0.06621 - acc: 0.9791 -- iter: 0608/1593
[A[ATraining Step: 1020  | total loss: [1m[32m0.06583[0m[0m | time: 11.914s
[2K
| RMSProp | epoch: 021 | loss: 0.06583 - acc: 0.9772 -- iter: 0640/1593
[A[ATraining Step: 1021  | total loss: [1m[32m0.06889[0m[0m | time: 12.506s
[2K
| RMSProp | epoch: 021 | loss: 0.06889 - acc: 0.9714 -- iter: 0672/1593
[A[ATraining Step: 1022  | total loss: [1m[32m0.07506[0m[0m | time: 13.103s
[2K
| RMSProp | epoch: 021 | loss: 0.07506 - acc: 0.9680 -- iter: 0704/1593
[A[ATraining Step: 1023  | total loss: [1m[32m0.07436[0m[0m | time: 13.712s
[2K
| RMSProp | epoch: 021 | loss: 0.07436 - acc: 0.9681 -- iter: 0736/1593
[A[ATraining Step: 1024  | total loss: [1m[32m0.07049[0m[0m | time: 14.320s
[2K
| RMSProp | epoch: 021 | loss: 0.07049 - acc: 0.9713 -- iter: 0768/1593
[A[ATraining Step: 1025  | total loss: [1m[32m0.06442[0m[0m | time: 14.919s
[2K
| RMSProp | epoch: 021 | loss: 0.06442 - acc: 0.9742 -- iter: 0800/1593
[A[ATraining Step: 1026  | total loss: [1m[32m0.05901[0m[0m | time: 15.514s
[2K
| RMSProp | epoch: 021 | loss: 0.05901 - acc: 0.9768 -- iter: 0832/1593
[A[ATraining Step: 1027  | total loss: [1m[32m0.05373[0m[0m | time: 16.119s
[2K
| RMSProp | epoch: 021 | loss: 0.05373 - acc: 0.9791 -- iter: 0864/1593
[A[ATraining Step: 1028  | total loss: [1m[32m0.05161[0m[0m | time: 16.717s
[2K
| RMSProp | epoch: 021 | loss: 0.05161 - acc: 0.9780 -- iter: 0896/1593
[A[ATraining Step: 1029  | total loss: [1m[32m0.05118[0m[0m | time: 17.335s
[2K
| RMSProp | epoch: 021 | loss: 0.05118 - acc: 0.9771 -- iter: 0928/1593
[A[ATraining Step: 1030  | total loss: [1m[32m0.04619[0m[0m | time: 17.938s
[2K
| RMSProp | epoch: 021 | loss: 0.04619 - acc: 0.9794 -- iter: 0960/1593
[A[ATraining Step: 1031  | total loss: [1m[32m0.04173[0m[0m | time: 18.554s
[2K
| RMSProp | epoch: 021 | loss: 0.04173 - acc: 0.9815 -- iter: 0992/1593
[A[ATraining Step: 1032  | total loss: [1m[32m0.03770[0m[0m | time: 19.179s
[2K
| RMSProp | epoch: 021 | loss: 0.03770 - acc: 0.9833 -- iter: 1024/1593
[A[ATraining Step: 1033  | total loss: [1m[32m0.03418[0m[0m | time: 19.781s
[2K
| RMSProp | epoch: 021 | loss: 0.03418 - acc: 0.9850 -- iter: 1056/1593
[A[ATraining Step: 1034  | total loss: [1m[32m0.03626[0m[0m | time: 20.369s
[2K
| RMSProp | epoch: 021 | loss: 0.03626 - acc: 0.9834 -- iter: 1088/1593
[A[ATraining Step: 1035  | total loss: [1m[32m0.04984[0m[0m | time: 20.975s
[2K
| RMSProp | epoch: 021 | loss: 0.04984 - acc: 0.9788 -- iter: 1120/1593
[A[ATraining Step: 1036  | total loss: [1m[32m0.05318[0m[0m | time: 21.588s
[2K
| RMSProp | epoch: 021 | loss: 0.05318 - acc: 0.9778 -- iter: 1152/1593
[A[ATraining Step: 1037  | total loss: [1m[32m0.05057[0m[0m | time: 22.180s
[2K
| RMSProp | epoch: 021 | loss: 0.05057 - acc: 0.9800 -- iter: 1184/1593
[A[ATraining Step: 1038  | total loss: [1m[32m0.04578[0m[0m | time: 22.788s
[2K
| RMSProp | epoch: 021 | loss: 0.04578 - acc: 0.9820 -- iter: 1216/1593
[A[ATraining Step: 1039  | total loss: [1m[32m0.04211[0m[0m | time: 23.402s
[2K
| RMSProp | epoch: 021 | loss: 0.04211 - acc: 0.9838 -- iter: 1248/1593
[A[ATraining Step: 1040  | total loss: [1m[32m0.03815[0m[0m | time: 24.017s
[2K
| RMSProp | epoch: 021 | loss: 0.03815 - acc: 0.9854 -- iter: 1280/1593
[A[ATraining Step: 1041  | total loss: [1m[32m0.03457[0m[0m | time: 24.619s
[2K
| RMSProp | epoch: 021 | loss: 0.03457 - acc: 0.9869 -- iter: 1312/1593
[A[ATraining Step: 1042  | total loss: [1m[32m0.03154[0m[0m | time: 25.209s
[2K
| RMSProp | epoch: 021 | loss: 0.03154 - acc: 0.9882 -- iter: 1344/1593
[A[ATraining Step: 1043  | total loss: [1m[32m0.02848[0m[0m | time: 25.805s
[2K
| RMSProp | epoch: 021 | loss: 0.02848 - acc: 0.9894 -- iter: 1376/1593
[A[ATraining Step: 1044  | total loss: [1m[32m0.02603[0m[0m | time: 26.410s
[2K
| RMSProp | epoch: 021 | loss: 0.02603 - acc: 0.9904 -- iter: 1408/1593
[A[ATraining Step: 1045  | total loss: [1m[32m0.02347[0m[0m | time: 27.022s
[2K
| RMSProp | epoch: 021 | loss: 0.02347 - acc: 0.9914 -- iter: 1440/1593
[A[ATraining Step: 1046  | total loss: [1m[32m0.02127[0m[0m | time: 27.625s
[2K
| RMSProp | epoch: 021 | loss: 0.02127 - acc: 0.9923 -- iter: 1472/1593
[A[ATraining Step: 1047  | total loss: [1m[32m0.01931[0m[0m | time: 28.220s
[2K
| RMSProp | epoch: 021 | loss: 0.01931 - acc: 0.9930 -- iter: 1504/1593
[A[ATraining Step: 1048  | total loss: [1m[32m0.02057[0m[0m | time: 28.813s
[2K
| RMSProp | epoch: 021 | loss: 0.02057 - acc: 0.9906 -- iter: 1536/1593
[A[ATraining Step: 1049  | total loss: [1m[32m0.04849[0m[0m | time: 29.416s
[2K
| RMSProp | epoch: 021 | loss: 0.04849 - acc: 0.9822 -- iter: 1568/1593
[A[ATraining Step: 1050  | total loss: [1m[32m0.04978[0m[0m | time: 31.586s
[2K
| RMSProp | epoch: 021 | loss: 0.04978 - acc: 0.9808 | val_loss: 0.56560 - val_acc: 0.8353 -- iter: 1593/1593
--
Training Step: 1051  | total loss: [1m[32m0.04511[0m[0m | time: 0.605s
[2K
| RMSProp | epoch: 022 | loss: 0.04511 - acc: 0.9827 -- iter: 0032/1593
[A[ATraining Step: 1052  | total loss: [1m[32m0.04225[0m[0m | time: 1.201s
[2K
| RMSProp | epoch: 022 | loss: 0.04225 - acc: 0.9845 -- iter: 0064/1593
[A[ATraining Step: 1053  | total loss: [1m[32m0.03835[0m[0m | time: 1.817s
[2K
| RMSProp | epoch: 022 | loss: 0.03835 - acc: 0.9860 -- iter: 0096/1593
[A[ATraining Step: 1054  | total loss: [1m[32m0.03492[0m[0m | time: 2.408s
[2K
| RMSProp | epoch: 022 | loss: 0.03492 - acc: 0.9874 -- iter: 0128/1593
[A[ATraining Step: 1055  | total loss: [1m[32m0.03217[0m[0m | time: 3.012s
[2K
| RMSProp | epoch: 022 | loss: 0.03217 - acc: 0.9887 -- iter: 0160/1593
[A[ATraining Step: 1056  | total loss: [1m[32m0.02950[0m[0m | time: 3.603s
[2K
| RMSProp | epoch: 022 | loss: 0.02950 - acc: 0.9898 -- iter: 0192/1593
[A[ATraining Step: 1057  | total loss: [1m[32m0.02661[0m[0m | time: 4.214s
[2K
| RMSProp | epoch: 022 | loss: 0.02661 - acc: 0.9908 -- iter: 0224/1593
[A[ATraining Step: 1058  | total loss: [1m[32m0.02634[0m[0m | time: 4.831s
[2K
| RMSProp | epoch: 022 | loss: 0.02634 - acc: 0.9886 -- iter: 0256/1593
[A[ATraining Step: 1059  | total loss: [1m[32m0.02701[0m[0m | time: 5.428s
[2K
| RMSProp | epoch: 022 | loss: 0.02701 - acc: 0.9866 -- iter: 0288/1593
[A[ATraining Step: 1060  | total loss: [1m[32m0.02435[0m[0m | time: 6.040s
[2K
| RMSProp | epoch: 022 | loss: 0.02435 - acc: 0.9880 -- iter: 0320/1593
[A[ATraining Step: 1061  | total loss: [1m[32m0.02204[0m[0m | time: 6.632s
[2K
| RMSProp | epoch: 022 | loss: 0.02204 - acc: 0.9892 -- iter: 0352/1593
[A[ATraining Step: 1062  | total loss: [1m[32m0.02106[0m[0m | time: 7.226s
[2K
| RMSProp | epoch: 022 | loss: 0.02106 - acc: 0.9903 -- iter: 0384/1593
[A[ATraining Step: 1063  | total loss: [1m[32m0.01901[0m[0m | time: 7.847s
[2K
| RMSProp | epoch: 022 | loss: 0.01901 - acc: 0.9912 -- iter: 0416/1593
[A[ATraining Step: 1064  | total loss: [1m[32m0.01718[0m[0m | time: 8.448s
[2K
| RMSProp | epoch: 022 | loss: 0.01718 - acc: 0.9921 -- iter: 0448/1593
[A[ATraining Step: 1065  | total loss: [1m[32m0.01549[0m[0m | time: 9.101s
[2K
| RMSProp | epoch: 022 | loss: 0.01549 - acc: 0.9929 -- iter: 0480/1593
[A[ATraining Step: 1066  | total loss: [1m[32m0.01399[0m[0m | time: 9.698s
[2K
| RMSProp | epoch: 022 | loss: 0.01399 - acc: 0.9936 -- iter: 0512/1593
[A[ATraining Step: 1067  | total loss: [1m[32m0.01342[0m[0m | time: 10.304s
[2K
| RMSProp | epoch: 022 | loss: 0.01342 - acc: 0.9942 -- iter: 0544/1593
[A[ATraining Step: 1068  | total loss: [1m[32m0.01449[0m[0m | time: 10.912s
[2K
| RMSProp | epoch: 022 | loss: 0.01449 - acc: 0.9948 -- iter: 0576/1593
[A[ATraining Step: 1069  | total loss: [1m[32m0.01332[0m[0m | time: 11.548s
[2K
| RMSProp | epoch: 022 | loss: 0.01332 - acc: 0.9953 -- iter: 0608/1593
[A[ATraining Step: 1070  | total loss: [1m[32m0.01218[0m[0m | time: 12.036s
[2K
| RMSProp | epoch: 022 | loss: 0.01218 - acc: 0.9958 -- iter: 0640/1593
[A[ATraining Step: 1071  | total loss: [1m[32m0.01767[0m[0m | time: 12.556s
[2K
| RMSProp | epoch: 022 | loss: 0.01767 - acc: 0.9922 -- iter: 0672/1593
[A[ATraining Step: 1072  | total loss: [1m[32m0.01900[0m[0m | time: 13.155s
[2K
| RMSProp | epoch: 022 | loss: 0.01900 - acc: 0.9930 -- iter: 0704/1593
[A[ATraining Step: 1073  | total loss: [1m[32m0.01925[0m[0m | time: 13.751s
[2K
| RMSProp | epoch: 022 | loss: 0.01925 - acc: 0.9937 -- iter: 0736/1593
[A[ATraining Step: 1074  | total loss: [1m[32m0.01779[0m[0m | time: 14.349s
[2K
| RMSProp | epoch: 022 | loss: 0.01779 - acc: 0.9943 -- iter: 0768/1593
[A[ATraining Step: 1075  | total loss: [1m[32m0.01882[0m[0m | time: 14.961s
[2K
| RMSProp | epoch: 022 | loss: 0.01882 - acc: 0.9918 -- iter: 0800/1593
[A[ATraining Step: 1076  | total loss: [1m[32m0.01860[0m[0m | time: 15.591s
[2K
| RMSProp | epoch: 022 | loss: 0.01860 - acc: 0.9926 -- iter: 0832/1593
[A[ATraining Step: 1077  | total loss: [1m[32m0.01694[0m[0m | time: 16.185s
[2K
| RMSProp | epoch: 022 | loss: 0.01694 - acc: 0.9933 -- iter: 0864/1593
[A[ATraining Step: 1078  | total loss: [1m[32m0.01528[0m[0m | time: 16.776s
[2K
| RMSProp | epoch: 022 | loss: 0.01528 - acc: 0.9940 -- iter: 0896/1593
[A[ATraining Step: 1079  | total loss: [1m[32m0.03209[0m[0m | time: 17.372s
[2K
| RMSProp | epoch: 022 | loss: 0.03209 - acc: 0.9915 -- iter: 0928/1593
[A[ATraining Step: 1080  | total loss: [1m[32m0.05955[0m[0m | time: 18.004s
[2K
| RMSProp | epoch: 022 | loss: 0.05955 - acc: 0.9861 -- iter: 0960/1593
[A[ATraining Step: 1081  | total loss: [1m[32m0.06338[0m[0m | time: 18.601s
[2K
| RMSProp | epoch: 022 | loss: 0.06338 - acc: 0.9843 -- iter: 0992/1593
[A[ATraining Step: 1082  | total loss: [1m[32m0.05788[0m[0m | time: 19.205s
[2K
| RMSProp | epoch: 022 | loss: 0.05788 - acc: 0.9859 -- iter: 1024/1593
[A[ATraining Step: 1083  | total loss: [1m[32m0.05234[0m[0m | time: 19.794s
[2K
| RMSProp | epoch: 022 | loss: 0.05234 - acc: 0.9873 -- iter: 1056/1593
[A[ATraining Step: 1084  | total loss: [1m[32m0.04909[0m[0m | time: 20.389s
[2K
| RMSProp | epoch: 022 | loss: 0.04909 - acc: 0.9886 -- iter: 1088/1593
[A[ATraining Step: 1085  | total loss: [1m[32m0.04539[0m[0m | time: 20.984s
[2K
| RMSProp | epoch: 022 | loss: 0.04539 - acc: 0.9897 -- iter: 1120/1593
[A[ATraining Step: 1086  | total loss: [1m[32m0.04094[0m[0m | time: 21.589s
[2K
| RMSProp | epoch: 022 | loss: 0.04094 - acc: 0.9908 -- iter: 1152/1593
[A[ATraining Step: 1087  | total loss: [1m[32m0.03690[0m[0m | time: 22.202s
[2K
| RMSProp | epoch: 022 | loss: 0.03690 - acc: 0.9917 -- iter: 1184/1593
[A[ATraining Step: 1088  | total loss: [1m[32m0.03390[0m[0m | time: 22.804s
[2K
| RMSProp | epoch: 022 | loss: 0.03390 - acc: 0.9925 -- iter: 1216/1593
[A[ATraining Step: 1089  | total loss: [1m[32m0.03061[0m[0m | time: 23.410s
[2K
| RMSProp | epoch: 022 | loss: 0.03061 - acc: 0.9933 -- iter: 1248/1593
[A[ATraining Step: 1090  | total loss: [1m[32m0.05332[0m[0m | time: 24.006s
[2K
| RMSProp | epoch: 022 | loss: 0.05332 - acc: 0.9877 -- iter: 1280/1593
[A[ATraining Step: 1091  | total loss: [1m[32m0.04965[0m[0m | time: 24.613s
[2K
| RMSProp | epoch: 022 | loss: 0.04965 - acc: 0.9889 -- iter: 1312/1593
[A[ATraining Step: 1092  | total loss: [1m[32m0.04493[0m[0m | time: 25.207s
[2K
| RMSProp | epoch: 022 | loss: 0.04493 - acc: 0.9900 -- iter: 1344/1593
[A[ATraining Step: 1093  | total loss: [1m[32m0.04274[0m[0m | time: 25.822s
[2K
| RMSProp | epoch: 022 | loss: 0.04274 - acc: 0.9910 -- iter: 1376/1593
[A[ATraining Step: 1094  | total loss: [1m[32m0.04885[0m[0m | time: 26.424s
[2K
| RMSProp | epoch: 022 | loss: 0.04885 - acc: 0.9888 -- iter: 1408/1593
[A[ATraining Step: 1095  | total loss: [1m[32m0.05003[0m[0m | time: 27.019s
[2K
| RMSProp | epoch: 022 | loss: 0.05003 - acc: 0.9868 -- iter: 1440/1593
[A[ATraining Step: 1096  | total loss: [1m[32m0.04546[0m[0m | time: 27.614s
[2K
| RMSProp | epoch: 022 | loss: 0.04546 - acc: 0.9881 -- iter: 1472/1593
[A[ATraining Step: 1097  | total loss: [1m[32m0.04119[0m[0m | time: 28.210s
[2K
| RMSProp | epoch: 022 | loss: 0.04119 - acc: 0.9893 -- iter: 1504/1593
[A[ATraining Step: 1098  | total loss: [1m[32m0.03774[0m[0m | time: 28.826s
[2K
| RMSProp | epoch: 022 | loss: 0.03774 - acc: 0.9904 -- iter: 1536/1593
[A[ATraining Step: 1099  | total loss: [1m[32m0.03422[0m[0m | time: 29.447s
[2K
| RMSProp | epoch: 022 | loss: 0.03422 - acc: 0.9913 -- iter: 1568/1593
[A[ATraining Step: 1100  | total loss: [1m[32m0.03400[0m[0m | time: 31.642s
[2K
| RMSProp | epoch: 022 | loss: 0.03400 - acc: 0.9891 | val_loss: 0.53808 - val_acc: 0.8534 -- iter: 1593/1593
--
Training Step: 1101  | total loss: [1m[32m0.03189[0m[0m | time: 0.601s
[2K
| RMSProp | epoch: 023 | loss: 0.03189 - acc: 0.9902 -- iter: 0032/1593
[A[ATraining Step: 1102  | total loss: [1m[32m0.02926[0m[0m | time: 1.202s
[2K
| RMSProp | epoch: 023 | loss: 0.02926 - acc: 0.9912 -- iter: 0064/1593
[A[ATraining Step: 1103  | total loss: [1m[32m0.02677[0m[0m | time: 1.826s
[2K
| RMSProp | epoch: 023 | loss: 0.02677 - acc: 0.9920 -- iter: 0096/1593
[A[ATraining Step: 1104  | total loss: [1m[32m0.02501[0m[0m | time: 2.443s
[2K
| RMSProp | epoch: 023 | loss: 0.02501 - acc: 0.9928 -- iter: 0128/1593
[A[ATraining Step: 1105  | total loss: [1m[32m0.02476[0m[0m | time: 3.032s
[2K
| RMSProp | epoch: 023 | loss: 0.02476 - acc: 0.9935 -- iter: 0160/1593
[A[ATraining Step: 1106  | total loss: [1m[32m0.02269[0m[0m | time: 3.622s
[2K
| RMSProp | epoch: 023 | loss: 0.02269 - acc: 0.9942 -- iter: 0192/1593
[A[ATraining Step: 1107  | total loss: [1m[32m0.02051[0m[0m | time: 4.240s
[2K
| RMSProp | epoch: 023 | loss: 0.02051 - acc: 0.9948 -- iter: 0224/1593
[A[ATraining Step: 1108  | total loss: [1m[32m0.01858[0m[0m | time: 4.842s
[2K
| RMSProp | epoch: 023 | loss: 0.01858 - acc: 0.9953 -- iter: 0256/1593
[A[ATraining Step: 1109  | total loss: [1m[32m0.01685[0m[0m | time: 5.447s
[2K
| RMSProp | epoch: 023 | loss: 0.01685 - acc: 0.9958 -- iter: 0288/1593
[A[ATraining Step: 1110  | total loss: [1m[32m0.01525[0m[0m | time: 6.056s
[2K
| RMSProp | epoch: 023 | loss: 0.01525 - acc: 0.9962 -- iter: 0320/1593
[A[ATraining Step: 1111  | total loss: [1m[32m0.01382[0m[0m | time: 6.655s
[2K
| RMSProp | epoch: 023 | loss: 0.01382 - acc: 0.9966 -- iter: 0352/1593
[A[ATraining Step: 1112  | total loss: [1m[32m0.01253[0m[0m | time: 7.253s
[2K
| RMSProp | epoch: 023 | loss: 0.01253 - acc: 0.9969 -- iter: 0384/1593
[A[ATraining Step: 1113  | total loss: [1m[32m0.01135[0m[0m | time: 7.858s
[2K
| RMSProp | epoch: 023 | loss: 0.01135 - acc: 0.9972 -- iter: 0416/1593
[A[ATraining Step: 1114  | total loss: [1m[32m0.01028[0m[0m | time: 8.464s
[2K
| RMSProp | epoch: 023 | loss: 0.01028 - acc: 0.9975 -- iter: 0448/1593
[A[ATraining Step: 1115  | total loss: [1m[32m0.01332[0m[0m | time: 9.053s
[2K
| RMSProp | epoch: 023 | loss: 0.01332 - acc: 0.9946 -- iter: 0480/1593
[A[ATraining Step: 1116  | total loss: [1m[32m0.08506[0m[0m | time: 9.658s
[2K
| RMSProp | epoch: 023 | loss: 0.08506 - acc: 0.9795 -- iter: 0512/1593
[A[ATraining Step: 1117  | total loss: [1m[32m0.09792[0m[0m | time: 10.262s
[2K
| RMSProp | epoch: 023 | loss: 0.09792 - acc: 0.9753 -- iter: 0544/1593
[A[ATraining Step: 1118  | total loss: [1m[32m0.09003[0m[0m | time: 10.863s
[2K
| RMSProp | epoch: 023 | loss: 0.09003 - acc: 0.9778 -- iter: 0576/1593
[A[ATraining Step: 1119  | total loss: [1m[32m0.08189[0m[0m | time: 11.479s
[2K
| RMSProp | epoch: 023 | loss: 0.08189 - acc: 0.9800 -- iter: 0608/1593
[A[ATraining Step: 1120  | total loss: [1m[32m0.07375[0m[0m | time: 12.073s
[2K
| RMSProp | epoch: 023 | loss: 0.07375 - acc: 0.9820 -- iter: 0640/1593
[A[ATraining Step: 1121  | total loss: [1m[32m0.06824[0m[0m | time: 12.559s
[2K
| RMSProp | epoch: 023 | loss: 0.06824 - acc: 0.9838 -- iter: 0672/1593
[A[ATraining Step: 1122  | total loss: [1m[32m0.06149[0m[0m | time: 13.046s
[2K
| RMSProp | epoch: 023 | loss: 0.06149 - acc: 0.9854 -- iter: 0704/1593
[A[ATraining Step: 1123  | total loss: [1m[32m0.05541[0m[0m | time: 13.640s
[2K
| RMSProp | epoch: 023 | loss: 0.05541 - acc: 0.9869 -- iter: 0736/1593
[A[ATraining Step: 1124  | total loss: [1m[32m0.05559[0m[0m | time: 14.239s
[2K
| RMSProp | epoch: 023 | loss: 0.05559 - acc: 0.9851 -- iter: 0768/1593
[A[ATraining Step: 1125  | total loss: [1m[32m0.05008[0m[0m | time: 14.841s
[2K
| RMSProp | epoch: 023 | loss: 0.05008 - acc: 0.9866 -- iter: 0800/1593
[A[ATraining Step: 1126  | total loss: [1m[32m0.04563[0m[0m | time: 15.446s
[2K
| RMSProp | epoch: 023 | loss: 0.04563 - acc: 0.9879 -- iter: 0832/1593
[A[ATraining Step: 1127  | total loss: [1m[32m0.04135[0m[0m | time: 16.036s
[2K
| RMSProp | epoch: 023 | loss: 0.04135 - acc: 0.9891 -- iter: 0864/1593
[A[ATraining Step: 1128  | total loss: [1m[32m0.03749[0m[0m | time: 16.644s
[2K
| RMSProp | epoch: 023 | loss: 0.03749 - acc: 0.9902 -- iter: 0896/1593
[A[ATraining Step: 1129  | total loss: [1m[32m0.03375[0m[0m | time: 17.257s
[2K
| RMSProp | epoch: 023 | loss: 0.03375 - acc: 0.9912 -- iter: 0928/1593
[A[ATraining Step: 1130  | total loss: [1m[32m0.03045[0m[0m | time: 17.853s
[2K
| RMSProp | epoch: 023 | loss: 0.03045 - acc: 0.9921 -- iter: 0960/1593
[A[ATraining Step: 1131  | total loss: [1m[32m0.02751[0m[0m | time: 18.452s
[2K
| RMSProp | epoch: 023 | loss: 0.02751 - acc: 0.9929 -- iter: 0992/1593
[A[ATraining Step: 1132  | total loss: [1m[32m0.02478[0m[0m | time: 19.077s
[2K
| RMSProp | epoch: 023 | loss: 0.02478 - acc: 0.9936 -- iter: 1024/1593
[A[ATraining Step: 1133  | total loss: [1m[32m0.02233[0m[0m | time: 19.697s
[2K
| RMSProp | epoch: 023 | loss: 0.02233 - acc: 0.9942 -- iter: 1056/1593
[A[ATraining Step: 1134  | total loss: [1m[32m0.02024[0m[0m | time: 20.299s
[2K
| RMSProp | epoch: 023 | loss: 0.02024 - acc: 0.9948 -- iter: 1088/1593
[A[ATraining Step: 1135  | total loss: [1m[32m0.01826[0m[0m | time: 20.904s
[2K
| RMSProp | epoch: 023 | loss: 0.01826 - acc: 0.9953 -- iter: 1120/1593
[A[ATraining Step: 1136  | total loss: [1m[32m0.01842[0m[0m | time: 21.514s
[2K
| RMSProp | epoch: 023 | loss: 0.01842 - acc: 0.9958 -- iter: 1152/1593
[A[ATraining Step: 1137  | total loss: [1m[32m0.04599[0m[0m | time: 22.146s
[2K
| RMSProp | epoch: 023 | loss: 0.04599 - acc: 0.9868 -- iter: 1184/1593
[A[ATraining Step: 1138  | total loss: [1m[32m0.11002[0m[0m | time: 22.777s
[2K
| RMSProp | epoch: 023 | loss: 0.11002 - acc: 0.9756 -- iter: 1216/1593
[A[ATraining Step: 1139  | total loss: [1m[32m0.09930[0m[0m | time: 23.373s
[2K
| RMSProp | epoch: 023 | loss: 0.09930 - acc: 0.9781 -- iter: 1248/1593
[A[ATraining Step: 1140  | total loss: [1m[32m0.08984[0m[0m | time: 23.987s
[2K
| RMSProp | epoch: 023 | loss: 0.08984 - acc: 0.9803 -- iter: 1280/1593
[A[ATraining Step: 1141  | total loss: [1m[32m0.13735[0m[0m | time: 24.583s
[2K
| RMSProp | epoch: 023 | loss: 0.13735 - acc: 0.9760 -- iter: 1312/1593
[A[ATraining Step: 1142  | total loss: [1m[32m0.12656[0m[0m | time: 25.180s
[2K
| RMSProp | epoch: 023 | loss: 0.12656 - acc: 0.9784 -- iter: 1344/1593
[A[ATraining Step: 1143  | total loss: [1m[32m0.11455[0m[0m | time: 25.772s
[2K
| RMSProp | epoch: 023 | loss: 0.11455 - acc: 0.9806 -- iter: 1376/1593
[A[ATraining Step: 1144  | total loss: [1m[32m0.10380[0m[0m | time: 26.368s
[2K
| RMSProp | epoch: 023 | loss: 0.10380 - acc: 0.9825 -- iter: 1408/1593
[A[ATraining Step: 1145  | total loss: [1m[32m0.09398[0m[0m | time: 26.969s
[2K
| RMSProp | epoch: 023 | loss: 0.09398 - acc: 0.9843 -- iter: 1440/1593
[A[ATraining Step: 1146  | total loss: [1m[32m0.08513[0m[0m | time: 27.568s
[2K
| RMSProp | epoch: 023 | loss: 0.08513 - acc: 0.9858 -- iter: 1472/1593
[A[ATraining Step: 1147  | total loss: [1m[32m0.07670[0m[0m | time: 28.166s
[2K
| RMSProp | epoch: 023 | loss: 0.07670 - acc: 0.9872 -- iter: 1504/1593
[A[ATraining Step: 1148  | total loss: [1m[32m0.06954[0m[0m | time: 28.766s
[2K
| RMSProp | epoch: 023 | loss: 0.06954 - acc: 0.9885 -- iter: 1536/1593
[A[ATraining Step: 1149  | total loss: [1m[32m0.06272[0m[0m | time: 29.382s
[2K
| RMSProp | epoch: 023 | loss: 0.06272 - acc: 0.9897 -- iter: 1568/1593
[A[ATraining Step: 1150  | total loss: [1m[32m0.05655[0m[0m | time: 31.545s
[2K
| RMSProp | epoch: 023 | loss: 0.05655 - acc: 0.9907 | val_loss: 0.61681 - val_acc: 0.8695 -- iter: 1593/1593
--
Training Step: 1151  | total loss: [1m[32m0.05144[0m[0m | time: 0.617s
[2K
| RMSProp | epoch: 024 | loss: 0.05144 - acc: 0.9916 -- iter: 0032/1593
[A[ATraining Step: 1152  | total loss: [1m[32m0.04640[0m[0m | time: 1.221s
[2K
| RMSProp | epoch: 024 | loss: 0.04640 - acc: 0.9925 -- iter: 0064/1593
[A[ATraining Step: 1153  | total loss: [1m[32m0.04184[0m[0m | time: 1.830s
[2K
| RMSProp | epoch: 024 | loss: 0.04184 - acc: 0.9932 -- iter: 0096/1593
[A[ATraining Step: 1154  | total loss: [1m[32m0.03786[0m[0m | time: 2.446s
[2K
| RMSProp | epoch: 024 | loss: 0.03786 - acc: 0.9939 -- iter: 0128/1593
[A[ATraining Step: 1155  | total loss: [1m[32m0.03417[0m[0m | time: 3.043s
[2K
| RMSProp | epoch: 024 | loss: 0.03417 - acc: 0.9945 -- iter: 0160/1593
[A[ATraining Step: 1156  | total loss: [1m[32m0.03079[0m[0m | time: 3.633s
[2K
| RMSProp | epoch: 024 | loss: 0.03079 - acc: 0.9951 -- iter: 0192/1593
[A[ATraining Step: 1157  | total loss: [1m[32m0.02778[0m[0m | time: 4.235s
[2K
| RMSProp | epoch: 024 | loss: 0.02778 - acc: 0.9956 -- iter: 0224/1593
[A[ATraining Step: 1158  | total loss: [1m[32m0.02505[0m[0m | time: 4.825s
[2K
| RMSProp | epoch: 024 | loss: 0.02505 - acc: 0.9960 -- iter: 0256/1593
[A[ATraining Step: 1159  | total loss: [1m[32m0.02429[0m[0m | time: 5.423s
[2K
| RMSProp | epoch: 024 | loss: 0.02429 - acc: 0.9964 -- iter: 0288/1593
[A[ATraining Step: 1160  | total loss: [1m[32m0.07195[0m[0m | time: 6.026s
[2K
| RMSProp | epoch: 024 | loss: 0.07195 - acc: 0.9874 -- iter: 0320/1593
[A[ATraining Step: 1161  | total loss: [1m[32m0.06964[0m[0m | time: 6.629s
[2K
| RMSProp | epoch: 024 | loss: 0.06964 - acc: 0.9855 -- iter: 0352/1593
[A[ATraining Step: 1162  | total loss: [1m[32m0.06288[0m[0m | time: 7.222s
[2K
| RMSProp | epoch: 024 | loss: 0.06288 - acc: 0.9870 -- iter: 0384/1593
[A[ATraining Step: 1163  | total loss: [1m[32m0.05676[0m[0m | time: 7.819s
[2K
| RMSProp | epoch: 024 | loss: 0.05676 - acc: 0.9883 -- iter: 0416/1593
[A[ATraining Step: 1164  | total loss: [1m[32m0.05128[0m[0m | time: 8.401s
[2K
| RMSProp | epoch: 024 | loss: 0.05128 - acc: 0.9894 -- iter: 0448/1593
[A[ATraining Step: 1165  | total loss: [1m[32m0.04636[0m[0m | time: 9.037s
[2K
| RMSProp | epoch: 024 | loss: 0.04636 - acc: 0.9905 -- iter: 0480/1593
[A[ATraining Step: 1166  | total loss: [1m[32m0.05039[0m[0m | time: 9.637s
[2K
| RMSProp | epoch: 024 | loss: 0.05039 - acc: 0.9883 -- iter: 0512/1593
[A[ATraining Step: 1167  | total loss: [1m[32m0.07767[0m[0m | time: 10.235s
[2K
| RMSProp | epoch: 024 | loss: 0.07767 - acc: 0.9801 -- iter: 0544/1593
[A[ATraining Step: 1168  | total loss: [1m[32m0.08264[0m[0m | time: 10.845s
[2K
| RMSProp | epoch: 024 | loss: 0.08264 - acc: 0.9790 -- iter: 0576/1593
[A[ATraining Step: 1169  | total loss: [1m[32m0.07839[0m[0m | time: 11.475s
[2K
| RMSProp | epoch: 024 | loss: 0.07839 - acc: 0.9780 -- iter: 0608/1593
[A[ATraining Step: 1170  | total loss: [1m[32m0.07116[0m[0m | time: 12.085s
[2K
| RMSProp | epoch: 024 | loss: 0.07116 - acc: 0.9802 -- iter: 0640/1593
[A[ATraining Step: 1171  | total loss: [1m[32m0.06624[0m[0m | time: 12.662s
[2K
| RMSProp | epoch: 024 | loss: 0.06624 - acc: 0.9821 -- iter: 0672/1593
[A[ATraining Step: 1172  | total loss: [1m[32m0.06005[0m[0m | time: 13.154s
[2K
| RMSProp | epoch: 024 | loss: 0.06005 - acc: 0.9839 -- iter: 0704/1593
[A[ATraining Step: 1173  | total loss: [1m[32m0.06385[0m[0m | time: 13.626s
[2K
| RMSProp | epoch: 024 | loss: 0.06385 - acc: 0.9815 -- iter: 0736/1593
[A[ATraining Step: 1174  | total loss: [1m[32m0.05809[0m[0m | time: 14.219s
[2K
| RMSProp | epoch: 024 | loss: 0.05809 - acc: 0.9834 -- iter: 0768/1593
[A[ATraining Step: 1175  | total loss: [1m[32m0.06348[0m[0m | time: 14.815s
[2K
| RMSProp | epoch: 024 | loss: 0.06348 - acc: 0.9819 -- iter: 0800/1593
[A[ATraining Step: 1176  | total loss: [1m[32m0.05860[0m[0m | time: 15.429s
[2K
| RMSProp | epoch: 024 | loss: 0.05860 - acc: 0.9837 -- iter: 0832/1593
[A[ATraining Step: 1177  | total loss: [1m[32m0.05332[0m[0m | time: 16.048s
[2K
| RMSProp | epoch: 024 | loss: 0.05332 - acc: 0.9854 -- iter: 0864/1593
[A[ATraining Step: 1178  | total loss: [1m[32m0.05130[0m[0m | time: 16.650s
[2K
| RMSProp | epoch: 024 | loss: 0.05130 - acc: 0.9837 -- iter: 0896/1593
[A[ATraining Step: 1179  | total loss: [1m[32m0.04660[0m[0m | time: 17.260s
[2K
| RMSProp | epoch: 024 | loss: 0.04660 - acc: 0.9853 -- iter: 0928/1593
[A[ATraining Step: 1180  | total loss: [1m[32m0.04249[0m[0m | time: 17.862s
[2K
| RMSProp | epoch: 024 | loss: 0.04249 - acc: 0.9868 -- iter: 0960/1593
[A[ATraining Step: 1181  | total loss: [1m[32m0.03841[0m[0m | time: 18.458s
[2K
| RMSProp | epoch: 024 | loss: 0.03841 - acc: 0.9881 -- iter: 0992/1593
[A[ATraining Step: 1182  | total loss: [1m[32m0.03482[0m[0m | time: 19.059s
[2K
| RMSProp | epoch: 024 | loss: 0.03482 - acc: 0.9893 -- iter: 1024/1593
[A[ATraining Step: 1183  | total loss: [1m[32m0.03157[0m[0m | time: 19.677s
[2K
| RMSProp | epoch: 024 | loss: 0.03157 - acc: 0.9904 -- iter: 1056/1593
[A[ATraining Step: 1184  | total loss: [1m[32m0.02917[0m[0m | time: 20.274s
[2K
| RMSProp | epoch: 024 | loss: 0.02917 - acc: 0.9913 -- iter: 1088/1593
[A[ATraining Step: 1185  | total loss: [1m[32m0.02649[0m[0m | time: 20.871s
[2K
| RMSProp | epoch: 024 | loss: 0.02649 - acc: 0.9922 -- iter: 1120/1593
[A[ATraining Step: 1186  | total loss: [1m[32m0.02412[0m[0m | time: 21.472s
[2K
| RMSProp | epoch: 024 | loss: 0.02412 - acc: 0.9930 -- iter: 1152/1593
[A[ATraining Step: 1187  | total loss: [1m[32m0.02222[0m[0m | time: 22.076s
[2K
| RMSProp | epoch: 024 | loss: 0.02222 - acc: 0.9937 -- iter: 1184/1593
[A[ATraining Step: 1188  | total loss: [1m[32m0.02006[0m[0m | time: 22.715s
[2K
| RMSProp | epoch: 024 | loss: 0.02006 - acc: 0.9943 -- iter: 1216/1593
[A[ATraining Step: 1189  | total loss: [1m[32m0.01813[0m[0m | time: 23.320s
[2K
| RMSProp | epoch: 024 | loss: 0.01813 - acc: 0.9949 -- iter: 1248/1593
[A[ATraining Step: 1190  | total loss: [1m[32m0.01643[0m[0m | time: 23.951s
[2K
| RMSProp | epoch: 024 | loss: 0.01643 - acc: 0.9954 -- iter: 1280/1593
[A[ATraining Step: 1191  | total loss: [1m[32m0.01495[0m[0m | time: 24.548s
[2K
| RMSProp | epoch: 024 | loss: 0.01495 - acc: 0.9959 -- iter: 1312/1593
[A[ATraining Step: 1192  | total loss: [1m[32m0.04307[0m[0m | time: 25.158s
[2K
| RMSProp | epoch: 024 | loss: 0.04307 - acc: 0.9931 -- iter: 1344/1593
[A[ATraining Step: 1193  | total loss: [1m[32m0.03962[0m[0m | time: 25.770s
[2K
| RMSProp | epoch: 024 | loss: 0.03962 - acc: 0.9938 -- iter: 1376/1593
[A[ATraining Step: 1194  | total loss: [1m[32m0.03607[0m[0m | time: 26.395s
[2K
| RMSProp | epoch: 024 | loss: 0.03607 - acc: 0.9944 -- iter: 1408/1593
[A[ATraining Step: 1195  | total loss: [1m[32m0.03283[0m[0m | time: 27.018s
[2K
| RMSProp | epoch: 024 | loss: 0.03283 - acc: 0.9950 -- iter: 1440/1593
[A[ATraining Step: 1196  | total loss: [1m[32m0.03158[0m[0m | time: 27.638s
[2K
| RMSProp | epoch: 024 | loss: 0.03158 - acc: 0.9955 -- iter: 1472/1593
[A[ATraining Step: 1197  | total loss: [1m[32m0.02974[0m[0m | time: 28.227s
[2K
| RMSProp | epoch: 024 | loss: 0.02974 - acc: 0.9960 -- iter: 1504/1593
[A[ATraining Step: 1198  | total loss: [1m[32m0.02681[0m[0m | time: 28.853s
[2K
| RMSProp | epoch: 024 | loss: 0.02681 - acc: 0.9964 -- iter: 1536/1593
[A[ATraining Step: 1199  | total loss: [1m[32m0.03092[0m[0m | time: 29.448s
[2K
| RMSProp | epoch: 024 | loss: 0.03092 - acc: 0.9936 -- iter: 1568/1593
[A[ATraining Step: 1200  | total loss: [1m[32m0.04763[0m[0m | time: 31.637s
[2K
| RMSProp | epoch: 024 | loss: 0.04763 - acc: 0.9911 | val_loss: 0.61447 - val_acc: 0.8494 -- iter: 1593/1593
--
Training Step: 1201  | total loss: [1m[32m0.04344[0m[0m | time: 0.631s
[2K
| RMSProp | epoch: 025 | loss: 0.04344 - acc: 0.9920 -- iter: 0032/1593
[A[ATraining Step: 1202  | total loss: [1m[32m0.03947[0m[0m | time: 1.231s
[2K
| RMSProp | epoch: 025 | loss: 0.03947 - acc: 0.9928 -- iter: 0064/1593
[A[ATraining Step: 1203  | total loss: [1m[32m0.03700[0m[0m | time: 1.837s
[2K
| RMSProp | epoch: 025 | loss: 0.03700 - acc: 0.9935 -- iter: 0096/1593
[A[ATraining Step: 1204  | total loss: [1m[32m0.03483[0m[0m | time: 2.445s
[2K
| RMSProp | epoch: 025 | loss: 0.03483 - acc: 0.9942 -- iter: 0128/1593
[A[ATraining Step: 1205  | total loss: [1m[32m0.03141[0m[0m | time: 3.055s
[2K
| RMSProp | epoch: 025 | loss: 0.03141 - acc: 0.9948 -- iter: 0160/1593
[A[ATraining Step: 1206  | total loss: [1m[32m0.02910[0m[0m | time: 3.666s
[2K
| RMSProp | epoch: 025 | loss: 0.02910 - acc: 0.9953 -- iter: 0192/1593
[A[ATraining Step: 1207  | total loss: [1m[32m0.02641[0m[0m | time: 4.299s
[2K
| RMSProp | epoch: 025 | loss: 0.02641 - acc: 0.9957 -- iter: 0224/1593
[A[ATraining Step: 1208  | total loss: [1m[32m0.02384[0m[0m | time: 4.906s
[2K
| RMSProp | epoch: 025 | loss: 0.02384 - acc: 0.9962 -- iter: 0256/1593
[A[ATraining Step: 1209  | total loss: [1m[32m0.02182[0m[0m | time: 5.497s
[2K
| RMSProp | epoch: 025 | loss: 0.02182 - acc: 0.9966 -- iter: 0288/1593
[A[ATraining Step: 1210  | total loss: [1m[32m0.01970[0m[0m | time: 6.110s
[2K
| RMSProp | epoch: 025 | loss: 0.01970 - acc: 0.9969 -- iter: 0320/1593
[A[ATraining Step: 1211  | total loss: [1m[32m0.02108[0m[0m | time: 6.709s
[2K
| RMSProp | epoch: 025 | loss: 0.02108 - acc: 0.9941 -- iter: 0352/1593
[A[ATraining Step: 1212  | total loss: [1m[32m0.05173[0m[0m | time: 7.318s
[2K
| RMSProp | epoch: 025 | loss: 0.05173 - acc: 0.9822 -- iter: 0384/1593
[A[ATraining Step: 1213  | total loss: [1m[32m0.06853[0m[0m | time: 7.909s
[2K
| RMSProp | epoch: 025 | loss: 0.06853 - acc: 0.9746 -- iter: 0416/1593
[A[ATraining Step: 1214  | total loss: [1m[32m0.06606[0m[0m | time: 8.524s
[2K
| RMSProp | epoch: 025 | loss: 0.06606 - acc: 0.9740 -- iter: 0448/1593
[A[ATraining Step: 1215  | total loss: [1m[32m0.05959[0m[0m | time: 9.129s
[2K
| RMSProp | epoch: 025 | loss: 0.05959 - acc: 0.9766 -- iter: 0480/1593
[A[ATraining Step: 1216  | total loss: [1m[32m0.05434[0m[0m | time: 9.748s
[2K
| RMSProp | epoch: 025 | loss: 0.05434 - acc: 0.9789 -- iter: 0512/1593
[A[ATraining Step: 1217  | total loss: [1m[32m0.04898[0m[0m | time: 10.346s
[2K
| RMSProp | epoch: 025 | loss: 0.04898 - acc: 0.9810 -- iter: 0544/1593
[A[ATraining Step: 1218  | total loss: [1m[32m0.04426[0m[0m | time: 10.945s
[2K
| RMSProp | epoch: 025 | loss: 0.04426 - acc: 0.9829 -- iter: 0576/1593
[A[ATraining Step: 1219  | total loss: [1m[32m0.03989[0m[0m | time: 11.543s
[2K
| RMSProp | epoch: 025 | loss: 0.03989 - acc: 0.9846 -- iter: 0608/1593
[A[ATraining Step: 1220  | total loss: [1m[32m0.03596[0m[0m | time: 12.133s
[2K
| RMSProp | epoch: 025 | loss: 0.03596 - acc: 0.9862 -- iter: 0640/1593
[A[ATraining Step: 1221  | total loss: [1m[32m0.03248[0m[0m | time: 12.753s
[2K
| RMSProp | epoch: 025 | loss: 0.03248 - acc: 0.9876 -- iter: 0672/1593
[A[ATraining Step: 1222  | total loss: [1m[32m0.02927[0m[0m | time: 13.387s
[2K
| RMSProp | epoch: 025 | loss: 0.02927 - acc: 0.9888 -- iter: 0704/1593
[A[ATraining Step: 1223  | total loss: [1m[32m0.02644[0m[0m | time: 13.874s
[2K
| RMSProp | epoch: 025 | loss: 0.02644 - acc: 0.9899 -- iter: 0736/1593
[A[ATraining Step: 1224  | total loss: [1m[32m0.02464[0m[0m | time: 14.361s
[2K
| RMSProp | epoch: 025 | loss: 0.02464 - acc: 0.9909 -- iter: 0768/1593
[A[ATraining Step: 1225  | total loss: [1m[32m0.02254[0m[0m | time: 14.955s
[2K
| RMSProp | epoch: 025 | loss: 0.02254 - acc: 0.9918 -- iter: 0800/1593
[A[ATraining Step: 1226  | total loss: [1m[32m0.02106[0m[0m | time: 15.586s
[2K
| RMSProp | epoch: 025 | loss: 0.02106 - acc: 0.9927 -- iter: 0832/1593
[A[ATraining Step: 1227  | total loss: [1m[32m0.01910[0m[0m | time: 16.182s
[2K
| RMSProp | epoch: 025 | loss: 0.01910 - acc: 0.9934 -- iter: 0864/1593
[A[ATraining Step: 1228  | total loss: [1m[32m0.02993[0m[0m | time: 16.777s
[2K
| RMSProp | epoch: 025 | loss: 0.02993 - acc: 0.9909 -- iter: 0896/1593
[A[ATraining Step: 1229  | total loss: [1m[32m0.04264[0m[0m | time: 17.377s
[2K
| RMSProp | epoch: 025 | loss: 0.04264 - acc: 0.9887 -- iter: 0928/1593
[A[ATraining Step: 1230  | total loss: [1m[32m0.03955[0m[0m | time: 17.991s
[2K
| RMSProp | epoch: 025 | loss: 0.03955 - acc: 0.9898 -- iter: 0960/1593
[A[ATraining Step: 1231  | total loss: [1m[32m0.03585[0m[0m | time: 18.584s
[2K
| RMSProp | epoch: 025 | loss: 0.03585 - acc: 0.9909 -- iter: 0992/1593
[A[ATraining Step: 1232  | total loss: [1m[32m0.03274[0m[0m | time: 19.184s
[2K
| RMSProp | epoch: 025 | loss: 0.03274 - acc: 0.9918 -- iter: 1024/1593
[A[ATraining Step: 1233  | total loss: [1m[32m0.02974[0m[0m | time: 19.807s
[2K
| RMSProp | epoch: 025 | loss: 0.02974 - acc: 0.9926 -- iter: 1056/1593
[A[ATraining Step: 1234  | total loss: [1m[32m0.02690[0m[0m | time: 20.410s
[2K
| RMSProp | epoch: 025 | loss: 0.02690 - acc: 0.9933 -- iter: 1088/1593
[A[ATraining Step: 1235  | total loss: [1m[32m0.02427[0m[0m | time: 21.020s
[2K
| RMSProp | epoch: 025 | loss: 0.02427 - acc: 0.9940 -- iter: 1120/1593
[A[ATraining Step: 1236  | total loss: [1m[32m0.02190[0m[0m | time: 21.617s
[2K
| RMSProp | epoch: 025 | loss: 0.02190 - acc: 0.9946 -- iter: 1152/1593
[A[ATraining Step: 1237  | total loss: [1m[32m0.01978[0m[0m | time: 22.219s
[2K
| RMSProp | epoch: 025 | loss: 0.01978 - acc: 0.9951 -- iter: 1184/1593
[A[ATraining Step: 1238  | total loss: [1m[32m0.01787[0m[0m | time: 22.819s
[2K
| RMSProp | epoch: 025 | loss: 0.01787 - acc: 0.9956 -- iter: 1216/1593
[A[ATraining Step: 1239  | total loss: [1m[32m0.01623[0m[0m | time: 23.430s
[2K
| RMSProp | epoch: 025 | loss: 0.01623 - acc: 0.9961 -- iter: 1248/1593
[A[ATraining Step: 1240  | total loss: [1m[32m0.01464[0m[0m | time: 24.035s
[2K
| RMSProp | epoch: 025 | loss: 0.01464 - acc: 0.9965 -- iter: 1280/1593
[A[ATraining Step: 1241  | total loss: [1m[32m0.01431[0m[0m | time: 24.649s
[2K
| RMSProp | epoch: 025 | loss: 0.01431 - acc: 0.9968 -- iter: 1312/1593
[A[ATraining Step: 1242  | total loss: [1m[32m0.01356[0m[0m | time: 25.253s
[2K
| RMSProp | epoch: 025 | loss: 0.01356 - acc: 0.9971 -- iter: 1344/1593
[A[ATraining Step: 1243  | total loss: [1m[32m0.01241[0m[0m | time: 25.857s
[2K
| RMSProp | epoch: 025 | loss: 0.01241 - acc: 0.9974 -- iter: 1376/1593
[A[ATraining Step: 1244  | total loss: [1m[32m0.01146[0m[0m | time: 26.456s
[2K
| RMSProp | epoch: 025 | loss: 0.01146 - acc: 0.9977 -- iter: 1408/1593
[A[ATraining Step: 1245  | total loss: [1m[32m0.02596[0m[0m | time: 27.061s
[2K
| RMSProp | epoch: 025 | loss: 0.02596 - acc: 0.9948 -- iter: 1440/1593
[A[ATraining Step: 1246  | total loss: [1m[32m0.04500[0m[0m | time: 27.661s
[2K
| RMSProp | epoch: 025 | loss: 0.04500 - acc: 0.9891 -- iter: 1472/1593
[A[ATraining Step: 1247  | total loss: [1m[32m0.04145[0m[0m | time: 28.270s
[2K
| RMSProp | epoch: 025 | loss: 0.04145 - acc: 0.9901 -- iter: 1504/1593
[A[ATraining Step: 1248  | total loss: [1m[32m0.04128[0m[0m | time: 28.900s
[2K
| RMSProp | epoch: 025 | loss: 0.04128 - acc: 0.9880 -- iter: 1536/1593
[A[ATraining Step: 1249  | total loss: [1m[32m0.05401[0m[0m | time: 29.508s
[2K
| RMSProp | epoch: 025 | loss: 0.05401 - acc: 0.9830 -- iter: 1568/1593
[A[ATraining Step: 1250  | total loss: [1m[32m0.04935[0m[0m | time: 31.699s
[2K
| RMSProp | epoch: 025 | loss: 0.04935 - acc: 0.9847 | val_loss: 0.67129 - val_acc: 0.8414 -- iter: 1593/1593
--
Training Step: 1251  | total loss: [1m[32m0.04461[0m[0m | time: 0.595s
[2K
| RMSProp | epoch: 026 | loss: 0.04461 - acc: 0.9862 -- iter: 0032/1593
[A[ATraining Step: 1252  | total loss: [1m[32m0.04055[0m[0m | time: 1.192s
[2K
| RMSProp | epoch: 026 | loss: 0.04055 - acc: 0.9876 -- iter: 0064/1593
[A[ATraining Step: 1253  | total loss: [1m[32m0.03661[0m[0m | time: 1.793s
[2K
| RMSProp | epoch: 026 | loss: 0.03661 - acc: 0.9888 -- iter: 0096/1593
[A[ATraining Step: 1254  | total loss: [1m[32m0.03299[0m[0m | time: 2.403s
[2K
| RMSProp | epoch: 026 | loss: 0.03299 - acc: 0.9899 -- iter: 0128/1593
[A[ATraining Step: 1255  | total loss: [1m[32m0.02982[0m[0m | time: 3.023s
[2K
| RMSProp | epoch: 026 | loss: 0.02982 - acc: 0.9909 -- iter: 0160/1593
[A[ATraining Step: 1256  | total loss: [1m[32m0.02738[0m[0m | time: 3.628s
[2K
| RMSProp | epoch: 026 | loss: 0.02738 - acc: 0.9918 -- iter: 0192/1593
[A[ATraining Step: 1257  | total loss: [1m[32m0.02475[0m[0m | time: 4.221s
[2K
| RMSProp | epoch: 026 | loss: 0.02475 - acc: 0.9927 -- iter: 0224/1593
[A[ATraining Step: 1258  | total loss: [1m[32m0.02237[0m[0m | time: 4.813s
[2K
| RMSProp | epoch: 026 | loss: 0.02237 - acc: 0.9934 -- iter: 0256/1593
[A[ATraining Step: 1259  | total loss: [1m[32m0.02037[0m[0m | time: 5.417s
[2K
| RMSProp | epoch: 026 | loss: 0.02037 - acc: 0.9941 -- iter: 0288/1593
[A[ATraining Step: 1260  | total loss: [1m[32m0.01841[0m[0m | time: 6.023s
[2K
| RMSProp | epoch: 026 | loss: 0.01841 - acc: 0.9947 -- iter: 0320/1593
[A[ATraining Step: 1261  | total loss: [1m[32m0.01699[0m[0m | time: 6.635s
[2K
| RMSProp | epoch: 026 | loss: 0.01699 - acc: 0.9952 -- iter: 0352/1593
[A[ATraining Step: 1262  | total loss: [1m[32m0.01532[0m[0m | time: 7.240s
[2K
| RMSProp | epoch: 026 | loss: 0.01532 - acc: 0.9957 -- iter: 0384/1593
[A[ATraining Step: 1263  | total loss: [1m[32m0.01382[0m[0m | time: 7.846s
[2K
| RMSProp | epoch: 026 | loss: 0.01382 - acc: 0.9961 -- iter: 0416/1593
[A[ATraining Step: 1264  | total loss: [1m[32m0.01788[0m[0m | time: 8.459s
[2K
| RMSProp | epoch: 026 | loss: 0.01788 - acc: 0.9934 -- iter: 0448/1593
[A[ATraining Step: 1265  | total loss: [1m[32m0.01643[0m[0m | time: 9.066s
[2K
| RMSProp | epoch: 026 | loss: 0.01643 - acc: 0.9940 -- iter: 0480/1593
[A[ATraining Step: 1266  | total loss: [1m[32m0.01520[0m[0m | time: 9.670s
[2K
| RMSProp | epoch: 026 | loss: 0.01520 - acc: 0.9946 -- iter: 0512/1593
[A[ATraining Step: 1267  | total loss: [1m[32m0.01372[0m[0m | time: 10.275s
[2K
| RMSProp | epoch: 026 | loss: 0.01372 - acc: 0.9952 -- iter: 0544/1593
[A[ATraining Step: 1268  | total loss: [1m[32m0.01275[0m[0m | time: 10.910s
[2K
| RMSProp | epoch: 026 | loss: 0.01275 - acc: 0.9956 -- iter: 0576/1593
[A[ATraining Step: 1269  | total loss: [1m[32m0.01153[0m[0m | time: 11.528s
[2K
| RMSProp | epoch: 026 | loss: 0.01153 - acc: 0.9961 -- iter: 0608/1593
[A[ATraining Step: 1270  | total loss: [1m[32m0.01042[0m[0m | time: 12.135s
[2K
| RMSProp | epoch: 026 | loss: 0.01042 - acc: 0.9965 -- iter: 0640/1593
[A[ATraining Step: 1271  | total loss: [1m[32m0.00967[0m[0m | time: 12.766s
[2K
| RMSProp | epoch: 026 | loss: 0.00967 - acc: 0.9968 -- iter: 0672/1593
[A[ATraining Step: 1272  | total loss: [1m[32m0.01354[0m[0m | time: 13.378s
[2K
| RMSProp | epoch: 026 | loss: 0.01354 - acc: 0.9940 -- iter: 0704/1593
[A[ATraining Step: 1273  | total loss: [1m[32m0.01242[0m[0m | time: 13.987s
[2K
| RMSProp | epoch: 026 | loss: 0.01242 - acc: 0.9946 -- iter: 0736/1593
[A[ATraining Step: 1274  | total loss: [1m[32m0.01134[0m[0m | time: 14.472s
[2K
| RMSProp | epoch: 026 | loss: 0.01134 - acc: 0.9952 -- iter: 0768/1593
[A[ATraining Step: 1275  | total loss: [1m[32m0.01031[0m[0m | time: 14.958s
[2K
| RMSProp | epoch: 026 | loss: 0.01031 - acc: 0.9956 -- iter: 0800/1593
[A[ATraining Step: 1276  | total loss: [1m[32m0.00931[0m[0m | time: 15.552s
[2K
| RMSProp | epoch: 026 | loss: 0.00931 - acc: 0.9961 -- iter: 0832/1593
[A[ATraining Step: 1277  | total loss: [1m[32m0.00840[0m[0m | time: 16.152s
[2K
| RMSProp | epoch: 026 | loss: 0.00840 - acc: 0.9965 -- iter: 0864/1593
[A[ATraining Step: 1278  | total loss: [1m[32m0.00764[0m[0m | time: 16.750s
[2K
| RMSProp | epoch: 026 | loss: 0.00764 - acc: 0.9968 -- iter: 0896/1593
[A[ATraining Step: 1279  | total loss: [1m[32m0.00695[0m[0m | time: 17.337s
[2K
| RMSProp | epoch: 026 | loss: 0.00695 - acc: 0.9971 -- iter: 0928/1593
[A[ATraining Step: 1280  | total loss: [1m[32m0.00630[0m[0m | time: 17.944s
[2K
| RMSProp | epoch: 026 | loss: 0.00630 - acc: 0.9974 -- iter: 0960/1593
[A[ATraining Step: 1281  | total loss: [1m[32m0.00571[0m[0m | time: 18.518s
[2K
| RMSProp | epoch: 026 | loss: 0.00571 - acc: 0.9977 -- iter: 0992/1593
[A[ATraining Step: 1282  | total loss: [1m[32m0.00515[0m[0m | time: 19.120s
[2K
| RMSProp | epoch: 026 | loss: 0.00515 - acc: 0.9979 -- iter: 1024/1593
[A[ATraining Step: 1283  | total loss: [1m[32m0.00468[0m[0m | time: 19.720s
[2K
| RMSProp | epoch: 026 | loss: 0.00468 - acc: 0.9981 -- iter: 1056/1593
[A[ATraining Step: 1284  | total loss: [1m[32m0.00427[0m[0m | time: 20.335s
[2K
| RMSProp | epoch: 026 | loss: 0.00427 - acc: 0.9983 -- iter: 1088/1593
[A[ATraining Step: 1285  | total loss: [1m[32m0.00388[0m[0m | time: 20.931s
[2K
| RMSProp | epoch: 026 | loss: 0.00388 - acc: 0.9985 -- iter: 1120/1593
[A[ATraining Step: 1286  | total loss: [1m[32m0.00355[0m[0m | time: 21.538s
[2K
| RMSProp | epoch: 026 | loss: 0.00355 - acc: 0.9986 -- iter: 1152/1593
[A[ATraining Step: 1287  | total loss: [1m[32m0.00321[0m[0m | time: 22.134s
[2K
| RMSProp | epoch: 026 | loss: 0.00321 - acc: 0.9988 -- iter: 1184/1593
[A[ATraining Step: 1288  | total loss: [1m[32m0.00293[0m[0m | time: 22.729s
[2K
| RMSProp | epoch: 026 | loss: 0.00293 - acc: 0.9989 -- iter: 1216/1593
[A[ATraining Step: 1289  | total loss: [1m[32m0.00265[0m[0m | time: 23.351s
[2K
| RMSProp | epoch: 026 | loss: 0.00265 - acc: 0.9990 -- iter: 1248/1593
[A[ATraining Step: 1290  | total loss: [1m[32m0.00240[0m[0m | time: 23.968s
[2K
| RMSProp | epoch: 026 | loss: 0.00240 - acc: 0.9991 -- iter: 1280/1593
[A[ATraining Step: 1291  | total loss: [1m[32m0.00221[0m[0m | time: 24.567s
[2K
| RMSProp | epoch: 026 | loss: 0.00221 - acc: 0.9992 -- iter: 1312/1593
[A[ATraining Step: 1292  | total loss: [1m[32m0.00199[0m[0m | time: 25.159s
[2K
| RMSProp | epoch: 026 | loss: 0.00199 - acc: 0.9993 -- iter: 1344/1593
[A[ATraining Step: 1293  | total loss: [1m[32m0.00242[0m[0m | time: 25.756s
[2K
| RMSProp | epoch: 026 | loss: 0.00242 - acc: 0.9993 -- iter: 1376/1593
[A[ATraining Step: 1294  | total loss: [1m[32m0.03939[0m[0m | time: 26.357s
[2K
| RMSProp | epoch: 026 | loss: 0.03939 - acc: 0.9900 -- iter: 1408/1593
[A[ATraining Step: 1295  | total loss: [1m[32m0.05836[0m[0m | time: 26.958s
[2K
| RMSProp | epoch: 026 | loss: 0.05836 - acc: 0.9848 -- iter: 1440/1593
[A[ATraining Step: 1296  | total loss: [1m[32m0.05263[0m[0m | time: 27.544s
[2K
| RMSProp | epoch: 026 | loss: 0.05263 - acc: 0.9863 -- iter: 1472/1593
[A[ATraining Step: 1297  | total loss: [1m[32m0.06198[0m[0m | time: 28.148s
[2K
| RMSProp | epoch: 026 | loss: 0.06198 - acc: 0.9845 -- iter: 1504/1593
[A[ATraining Step: 1298  | total loss: [1m[32m0.06676[0m[0m | time: 28.750s
[2K
| RMSProp | epoch: 026 | loss: 0.06676 - acc: 0.9830 -- iter: 1536/1593
[A[ATraining Step: 1299  | total loss: [1m[32m0.06104[0m[0m | time: 29.357s
[2K
| RMSProp | epoch: 026 | loss: 0.06104 - acc: 0.9847 -- iter: 1568/1593
[A[ATraining Step: 1300  | total loss: [1m[32m0.05566[0m[0m | time: 31.542s
[2K
| RMSProp | epoch: 026 | loss: 0.05566 - acc: 0.9862 | val_loss: 0.67490 - val_acc: 0.8614 -- iter: 1593/1593
--
Training Step: 1301  | total loss: [1m[32m0.05057[0m[0m | time: 0.605s
[2K
| RMSProp | epoch: 027 | loss: 0.05057 - acc: 0.9876 -- iter: 0032/1593
[A[ATraining Step: 1302  | total loss: [1m[32m0.04558[0m[0m | time: 1.220s
[2K
| RMSProp | epoch: 027 | loss: 0.04558 - acc: 0.9888 -- iter: 0064/1593
[A[ATraining Step: 1303  | total loss: [1m[32m0.04112[0m[0m | time: 1.827s
[2K
| RMSProp | epoch: 027 | loss: 0.04112 - acc: 0.9899 -- iter: 0096/1593
[A[ATraining Step: 1304  | total loss: [1m[32m0.03706[0m[0m | time: 2.425s
[2K
| RMSProp | epoch: 027 | loss: 0.03706 - acc: 0.9909 -- iter: 0128/1593
[A[ATraining Step: 1305  | total loss: [1m[32m0.03347[0m[0m | time: 3.018s
[2K
| RMSProp | epoch: 027 | loss: 0.03347 - acc: 0.9919 -- iter: 0160/1593
[A[ATraining Step: 1306  | total loss: [1m[32m0.03018[0m[0m | time: 3.624s
[2K
| RMSProp | epoch: 027 | loss: 0.03018 - acc: 0.9927 -- iter: 0192/1593
[A[ATraining Step: 1307  | total loss: [1m[32m0.02728[0m[0m | time: 4.224s
[2K
| RMSProp | epoch: 027 | loss: 0.02728 - acc: 0.9934 -- iter: 0224/1593
[A[ATraining Step: 1308  | total loss: [1m[32m0.02470[0m[0m | time: 4.830s
[2K
| RMSProp | epoch: 027 | loss: 0.02470 - acc: 0.9941 -- iter: 0256/1593
[A[ATraining Step: 1309  | total loss: [1m[32m0.02333[0m[0m | time: 5.438s
[2K
| RMSProp | epoch: 027 | loss: 0.02333 - acc: 0.9947 -- iter: 0288/1593
[A[ATraining Step: 1310  | total loss: [1m[32m0.03157[0m[0m | time: 6.036s
[2K
| RMSProp | epoch: 027 | loss: 0.03157 - acc: 0.9921 -- iter: 0320/1593
[A[ATraining Step: 1311  | total loss: [1m[32m0.03719[0m[0m | time: 6.654s
[2K
| RMSProp | epoch: 027 | loss: 0.03719 - acc: 0.9897 -- iter: 0352/1593
[A[ATraining Step: 1312  | total loss: [1m[32m0.03411[0m[0m | time: 7.256s
[2K
| RMSProp | epoch: 027 | loss: 0.03411 - acc: 0.9908 -- iter: 0384/1593
[A[ATraining Step: 1313  | total loss: [1m[32m0.03072[0m[0m | time: 7.862s
[2K
| RMSProp | epoch: 027 | loss: 0.03072 - acc: 0.9917 -- iter: 0416/1593
[A[ATraining Step: 1314  | total loss: [1m[32m0.03010[0m[0m | time: 8.489s
[2K
| RMSProp | epoch: 027 | loss: 0.03010 - acc: 0.9925 -- iter: 0448/1593
[A[ATraining Step: 1315  | total loss: [1m[32m0.04027[0m[0m | time: 9.102s
[2K
| RMSProp | epoch: 027 | loss: 0.04027 - acc: 0.9901 -- iter: 0480/1593
[A[ATraining Step: 1316  | total loss: [1m[32m0.03719[0m[0m | time: 9.713s
[2K
| RMSProp | epoch: 027 | loss: 0.03719 - acc: 0.9911 -- iter: 0512/1593
[A[ATraining Step: 1317  | total loss: [1m[32m0.03355[0m[0m | time: 10.326s
[2K
| RMSProp | epoch: 027 | loss: 0.03355 - acc: 0.9920 -- iter: 0544/1593
[A[ATraining Step: 1318  | total loss: [1m[32m0.03020[0m[0m | time: 10.936s
[2K
| RMSProp | epoch: 027 | loss: 0.03020 - acc: 0.9928 -- iter: 0576/1593
[A[ATraining Step: 1319  | total loss: [1m[32m0.02721[0m[0m | time: 11.537s
[2K
| RMSProp | epoch: 027 | loss: 0.02721 - acc: 0.9935 -- iter: 0608/1593
[A[ATraining Step: 1320  | total loss: [1m[32m0.02451[0m[0m | time: 12.146s
[2K
| RMSProp | epoch: 027 | loss: 0.02451 - acc: 0.9942 -- iter: 0640/1593
[A[ATraining Step: 1321  | total loss: [1m[32m0.02206[0m[0m | time: 12.765s
[2K
| RMSProp | epoch: 027 | loss: 0.02206 - acc: 0.9948 -- iter: 0672/1593
[A[ATraining Step: 1322  | total loss: [1m[32m0.01986[0m[0m | time: 13.383s
[2K
| RMSProp | epoch: 027 | loss: 0.01986 - acc: 0.9953 -- iter: 0704/1593
[A[ATraining Step: 1323  | total loss: [1m[32m0.01810[0m[0m | time: 14.007s
[2K
| RMSProp | epoch: 027 | loss: 0.01810 - acc: 0.9958 -- iter: 0736/1593
[A[ATraining Step: 1324  | total loss: [1m[32m0.01630[0m[0m | time: 14.614s
[2K
| RMSProp | epoch: 027 | loss: 0.01630 - acc: 0.9962 -- iter: 0768/1593
[A[ATraining Step: 1325  | total loss: [1m[32m0.01467[0m[0m | time: 15.116s
[2K
| RMSProp | epoch: 027 | loss: 0.01467 - acc: 0.9966 -- iter: 0800/1593
[A[ATraining Step: 1326  | total loss: [1m[32m0.01322[0m[0m | time: 15.601s
[2K
| RMSProp | epoch: 027 | loss: 0.01322 - acc: 0.9969 -- iter: 0832/1593
[A[ATraining Step: 1327  | total loss: [1m[32m0.01190[0m[0m | time: 16.194s
[2K
| RMSProp | epoch: 027 | loss: 0.01190 - acc: 0.9972 -- iter: 0864/1593
[A[ATraining Step: 1328  | total loss: [1m[32m0.01108[0m[0m | time: 16.785s
[2K
| RMSProp | epoch: 027 | loss: 0.01108 - acc: 0.9975 -- iter: 0896/1593
[A[ATraining Step: 1329  | total loss: [1m[32m0.00999[0m[0m | time: 17.392s
[2K
| RMSProp | epoch: 027 | loss: 0.00999 - acc: 0.9977 -- iter: 0928/1593
[A[ATraining Step: 1330  | total loss: [1m[32m0.00900[0m[0m | time: 17.992s
[2K
| RMSProp | epoch: 027 | loss: 0.00900 - acc: 0.9980 -- iter: 0960/1593
[A[ATraining Step: 1331  | total loss: [1m[32m0.00818[0m[0m | time: 18.590s
[2K
| RMSProp | epoch: 027 | loss: 0.00818 - acc: 0.9982 -- iter: 0992/1593
[A[ATraining Step: 1332  | total loss: [1m[32m0.00738[0m[0m | time: 19.176s
[2K
| RMSProp | epoch: 027 | loss: 0.00738 - acc: 0.9984 -- iter: 1024/1593
[A[ATraining Step: 1333  | total loss: [1m[32m0.00670[0m[0m | time: 19.800s
[2K
| RMSProp | epoch: 027 | loss: 0.00670 - acc: 0.9985 -- iter: 1056/1593
[A[ATraining Step: 1334  | total loss: [1m[32m0.00606[0m[0m | time: 20.413s
[2K
| RMSProp | epoch: 027 | loss: 0.00606 - acc: 0.9987 -- iter: 1088/1593
[A[ATraining Step: 1335  | total loss: [1m[32m0.00546[0m[0m | time: 21.036s
[2K
| RMSProp | epoch: 027 | loss: 0.00546 - acc: 0.9988 -- iter: 1120/1593
[A[ATraining Step: 1336  | total loss: [1m[32m0.00493[0m[0m | time: 21.642s
[2K
| RMSProp | epoch: 027 | loss: 0.00493 - acc: 0.9989 -- iter: 1152/1593
[A[ATraining Step: 1337  | total loss: [1m[32m0.00444[0m[0m | time: 22.244s
[2K
| RMSProp | epoch: 027 | loss: 0.00444 - acc: 0.9990 -- iter: 1184/1593
[A[ATraining Step: 1338  | total loss: [1m[32m0.00401[0m[0m | time: 22.841s
[2K
| RMSProp | epoch: 027 | loss: 0.00401 - acc: 0.9991 -- iter: 1216/1593
[A[ATraining Step: 1339  | total loss: [1m[32m0.00362[0m[0m | time: 23.436s
[2K
| RMSProp | epoch: 027 | loss: 0.00362 - acc: 0.9992 -- iter: 1248/1593
[A[ATraining Step: 1340  | total loss: [1m[32m0.00327[0m[0m | time: 24.061s
[2K
| RMSProp | epoch: 027 | loss: 0.00327 - acc: 0.9993 -- iter: 1280/1593
[A[ATraining Step: 1341  | total loss: [1m[32m0.00295[0m[0m | time: 24.649s
[2K
| RMSProp | epoch: 027 | loss: 0.00295 - acc: 0.9994 -- iter: 1312/1593
[A[ATraining Step: 1342  | total loss: [1m[32m0.00266[0m[0m | time: 25.273s
[2K
| RMSProp | epoch: 027 | loss: 0.00266 - acc: 0.9994 -- iter: 1344/1593
[A[ATraining Step: 1343  | total loss: [1m[32m0.00240[0m[0m | time: 25.880s
[2K
| RMSProp | epoch: 027 | loss: 0.00240 - acc: 0.9995 -- iter: 1376/1593
[A[ATraining Step: 1344  | total loss: [1m[32m0.00218[0m[0m | time: 26.478s
[2K
| RMSProp | epoch: 027 | loss: 0.00218 - acc: 0.9995 -- iter: 1408/1593
[A[ATraining Step: 1345  | total loss: [1m[32m0.06963[0m[0m | time: 27.094s
[2K
| RMSProp | epoch: 027 | loss: 0.06963 - acc: 0.9933 -- iter: 1440/1593
[A[ATraining Step: 1346  | total loss: [1m[32m0.13819[0m[0m | time: 27.704s
[2K
| RMSProp | epoch: 027 | loss: 0.13819 - acc: 0.9659 -- iter: 1472/1593
[A[ATraining Step: 1347  | total loss: [1m[32m0.14104[0m[0m | time: 28.315s
[2K
| RMSProp | epoch: 027 | loss: 0.14104 - acc: 0.9630 -- iter: 1504/1593
[A[ATraining Step: 1348  | total loss: [1m[32m0.12920[0m[0m | time: 28.911s
[2K
| RMSProp | epoch: 027 | loss: 0.12920 - acc: 0.9667 -- iter: 1536/1593
[A[ATraining Step: 1349  | total loss: [1m[32m0.14498[0m[0m | time: 29.506s
[2K
| RMSProp | epoch: 027 | loss: 0.14498 - acc: 0.9638 -- iter: 1568/1593
[A[ATraining Step: 1350  | total loss: [1m[32m0.13474[0m[0m | time: 31.675s
[2K
| RMSProp | epoch: 027 | loss: 0.13474 - acc: 0.9674 | val_loss: 0.53867 - val_acc: 0.8635 -- iter: 1593/1593
--
Training Step: 1351  | total loss: [1m[32m0.12222[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 028 | loss: 0.12222 - acc: 0.9707 -- iter: 0032/1593
[A[ATraining Step: 1352  | total loss: [1m[32m0.11070[0m[0m | time: 1.206s
[2K
| RMSProp | epoch: 028 | loss: 0.11070 - acc: 0.9736 -- iter: 0064/1593
[A[ATraining Step: 1353  | total loss: [1m[32m0.10001[0m[0m | time: 1.807s
[2K
| RMSProp | epoch: 028 | loss: 0.10001 - acc: 0.9763 -- iter: 0096/1593
[A[ATraining Step: 1354  | total loss: [1m[32m0.09039[0m[0m | time: 2.409s
[2K
| RMSProp | epoch: 028 | loss: 0.09039 - acc: 0.9786 -- iter: 0128/1593
[A[ATraining Step: 1355  | total loss: [1m[32m0.08267[0m[0m | time: 3.012s
[2K
| RMSProp | epoch: 028 | loss: 0.08267 - acc: 0.9808 -- iter: 0160/1593
[A[ATraining Step: 1356  | total loss: [1m[32m0.07801[0m[0m | time: 3.613s
[2K
| RMSProp | epoch: 028 | loss: 0.07801 - acc: 0.9796 -- iter: 0192/1593
[A[ATraining Step: 1357  | total loss: [1m[32m0.07038[0m[0m | time: 4.260s
[2K
| RMSProp | epoch: 028 | loss: 0.07038 - acc: 0.9816 -- iter: 0224/1593
[A[ATraining Step: 1358  | total loss: [1m[32m0.06355[0m[0m | time: 4.857s
[2K
| RMSProp | epoch: 028 | loss: 0.06355 - acc: 0.9834 -- iter: 0256/1593
[A[ATraining Step: 1359  | total loss: [1m[32m0.05803[0m[0m | time: 5.454s
[2K
| RMSProp | epoch: 028 | loss: 0.05803 - acc: 0.9851 -- iter: 0288/1593
[A[ATraining Step: 1360  | total loss: [1m[32m0.05233[0m[0m | time: 6.047s
[2K
| RMSProp | epoch: 028 | loss: 0.05233 - acc: 0.9866 -- iter: 0320/1593
[A[ATraining Step: 1361  | total loss: [1m[32m0.04722[0m[0m | time: 6.637s
[2K
| RMSProp | epoch: 028 | loss: 0.04722 - acc: 0.9879 -- iter: 0352/1593
[A[ATraining Step: 1362  | total loss: [1m[32m0.04261[0m[0m | time: 7.245s
[2K
| RMSProp | epoch: 028 | loss: 0.04261 - acc: 0.9891 -- iter: 0384/1593
[A[ATraining Step: 1363  | total loss: [1m[32m0.03844[0m[0m | time: 7.867s
[2K
| RMSProp | epoch: 028 | loss: 0.03844 - acc: 0.9902 -- iter: 0416/1593
[A[ATraining Step: 1364  | total loss: [1m[32m0.03467[0m[0m | time: 8.464s
[2K
| RMSProp | epoch: 028 | loss: 0.03467 - acc: 0.9912 -- iter: 0448/1593
[A[ATraining Step: 1365  | total loss: [1m[32m0.03166[0m[0m | time: 9.074s
[2K
| RMSProp | epoch: 028 | loss: 0.03166 - acc: 0.9921 -- iter: 0480/1593
[A[ATraining Step: 1366  | total loss: [1m[32m0.02852[0m[0m | time: 9.665s
[2K
| RMSProp | epoch: 028 | loss: 0.02852 - acc: 0.9929 -- iter: 0512/1593
[A[ATraining Step: 1367  | total loss: [1m[32m0.02571[0m[0m | time: 10.233s
[2K
| RMSProp | epoch: 028 | loss: 0.02571 - acc: 0.9936 -- iter: 0544/1593
[A[ATraining Step: 1368  | total loss: [1m[32m0.02323[0m[0m | time: 10.830s
[2K
| RMSProp | epoch: 028 | loss: 0.02323 - acc: 0.9942 -- iter: 0576/1593
[A[ATraining Step: 1369  | total loss: [1m[32m0.02096[0m[0m | time: 11.440s
[2K
| RMSProp | epoch: 028 | loss: 0.02096 - acc: 0.9948 -- iter: 0608/1593
[A[ATraining Step: 1370  | total loss: [1m[32m0.01896[0m[0m | time: 12.030s
[2K
| RMSProp | epoch: 028 | loss: 0.01896 - acc: 0.9953 -- iter: 0640/1593
[A[ATraining Step: 1371  | total loss: [1m[32m0.01800[0m[0m | time: 12.645s
[2K
| RMSProp | epoch: 028 | loss: 0.01800 - acc: 0.9958 -- iter: 0672/1593
[A[ATraining Step: 1372  | total loss: [1m[32m0.01831[0m[0m | time: 13.241s
[2K
| RMSProp | epoch: 028 | loss: 0.01831 - acc: 0.9962 -- iter: 0704/1593
[A[ATraining Step: 1373  | total loss: [1m[32m0.01981[0m[0m | time: 13.841s
[2K
| RMSProp | epoch: 028 | loss: 0.01981 - acc: 0.9935 -- iter: 0736/1593
[A[ATraining Step: 1374  | total loss: [1m[32m0.01811[0m[0m | time: 14.444s
[2K
| RMSProp | epoch: 028 | loss: 0.01811 - acc: 0.9941 -- iter: 0768/1593
[A[ATraining Step: 1375  | total loss: [1m[32m0.01639[0m[0m | time: 15.060s
[2K
| RMSProp | epoch: 028 | loss: 0.01639 - acc: 0.9947 -- iter: 0800/1593
[A[ATraining Step: 1376  | total loss: [1m[32m0.02130[0m[0m | time: 15.554s
[2K
| RMSProp | epoch: 028 | loss: 0.02130 - acc: 0.9921 -- iter: 0832/1593
[A[ATraining Step: 1377  | total loss: [1m[32m0.04585[0m[0m | time: 16.064s
[2K
| RMSProp | epoch: 028 | loss: 0.04585 - acc: 0.9889 -- iter: 0864/1593
[A[ATraining Step: 1378  | total loss: [1m[32m0.04323[0m[0m | time: 16.688s
[2K
| RMSProp | epoch: 028 | loss: 0.04323 - acc: 0.9900 -- iter: 0896/1593
[A[ATraining Step: 1379  | total loss: [1m[32m0.03894[0m[0m | time: 17.290s
[2K
| RMSProp | epoch: 028 | loss: 0.03894 - acc: 0.9910 -- iter: 0928/1593
[A[ATraining Step: 1380  | total loss: [1m[32m0.05317[0m[0m | time: 17.905s
[2K
| RMSProp | epoch: 028 | loss: 0.05317 - acc: 0.9888 -- iter: 0960/1593
[A[ATraining Step: 1381  | total loss: [1m[32m0.06563[0m[0m | time: 18.506s
[2K
| RMSProp | epoch: 028 | loss: 0.06563 - acc: 0.9805 -- iter: 0992/1593
[A[ATraining Step: 1382  | total loss: [1m[32m0.05949[0m[0m | time: 19.114s
[2K
| RMSProp | epoch: 028 | loss: 0.05949 - acc: 0.9825 -- iter: 1024/1593
[A[ATraining Step: 1383  | total loss: [1m[32m0.07087[0m[0m | time: 19.721s
[2K
| RMSProp | epoch: 028 | loss: 0.07087 - acc: 0.9811 -- iter: 1056/1593
[A[ATraining Step: 1384  | total loss: [1m[32m0.11909[0m[0m | time: 20.348s
[2K
| RMSProp | epoch: 028 | loss: 0.11909 - acc: 0.9674 -- iter: 1088/1593
[A[ATraining Step: 1385  | total loss: [1m[32m0.11257[0m[0m | time: 20.950s
[2K
| RMSProp | epoch: 028 | loss: 0.11257 - acc: 0.9675 -- iter: 1120/1593
[A[ATraining Step: 1386  | total loss: [1m[32m0.10262[0m[0m | time: 21.564s
[2K
| RMSProp | epoch: 028 | loss: 0.10262 - acc: 0.9708 -- iter: 1152/1593
[A[ATraining Step: 1387  | total loss: [1m[32m0.09281[0m[0m | time: 22.170s
[2K
| RMSProp | epoch: 028 | loss: 0.09281 - acc: 0.9737 -- iter: 1184/1593
[A[ATraining Step: 1388  | total loss: [1m[32m0.08398[0m[0m | time: 22.798s
[2K
| RMSProp | epoch: 028 | loss: 0.08398 - acc: 0.9763 -- iter: 1216/1593
[A[ATraining Step: 1389  | total loss: [1m[32m0.07590[0m[0m | time: 23.404s
[2K
| RMSProp | epoch: 028 | loss: 0.07590 - acc: 0.9787 -- iter: 1248/1593
[A[ATraining Step: 1390  | total loss: [1m[32m0.06849[0m[0m | time: 24.013s
[2K
| RMSProp | epoch: 028 | loss: 0.06849 - acc: 0.9808 -- iter: 1280/1593
[A[ATraining Step: 1391  | total loss: [1m[32m0.06177[0m[0m | time: 24.631s
[2K
| RMSProp | epoch: 028 | loss: 0.06177 - acc: 0.9827 -- iter: 1312/1593
[A[ATraining Step: 1392  | total loss: [1m[32m0.05578[0m[0m | time: 25.229s
[2K
| RMSProp | epoch: 028 | loss: 0.05578 - acc: 0.9845 -- iter: 1344/1593
[A[ATraining Step: 1393  | total loss: [1m[32m0.05049[0m[0m | time: 25.850s
[2K
| RMSProp | epoch: 028 | loss: 0.05049 - acc: 0.9860 -- iter: 1376/1593
[A[ATraining Step: 1394  | total loss: [1m[32m0.04561[0m[0m | time: 26.451s
[2K
| RMSProp | epoch: 028 | loss: 0.04561 - acc: 0.9874 -- iter: 1408/1593
[A[ATraining Step: 1395  | total loss: [1m[32m0.04116[0m[0m | time: 27.050s
[2K
| RMSProp | epoch: 028 | loss: 0.04116 - acc: 0.9887 -- iter: 1440/1593
[A[ATraining Step: 1396  | total loss: [1m[32m0.06131[0m[0m | time: 27.646s
[2K
| RMSProp | epoch: 028 | loss: 0.06131 - acc: 0.9867 -- iter: 1472/1593
[A[ATraining Step: 1397  | total loss: [1m[32m0.06299[0m[0m | time: 28.258s
[2K
| RMSProp | epoch: 028 | loss: 0.06299 - acc: 0.9849 -- iter: 1504/1593
[A[ATraining Step: 1398  | total loss: [1m[32m0.05773[0m[0m | time: 28.851s
[2K
| RMSProp | epoch: 028 | loss: 0.05773 - acc: 0.9864 -- iter: 1536/1593
[A[ATraining Step: 1399  | total loss: [1m[32m0.05234[0m[0m | time: 29.418s
[2K
| RMSProp | epoch: 028 | loss: 0.05234 - acc: 0.9878 -- iter: 1568/1593
[A[ATraining Step: 1400  | total loss: [1m[32m0.04726[0m[0m | time: 31.571s
[2K
| RMSProp | epoch: 028 | loss: 0.04726 - acc: 0.9890 | val_loss: 0.60809 - val_acc: 0.8635 -- iter: 1593/1593
--
Training Step: 1401  | total loss: [1m[32m0.04319[0m[0m | time: 0.598s
[2K
| RMSProp | epoch: 029 | loss: 0.04319 - acc: 0.9901 -- iter: 0032/1593
[A[ATraining Step: 1402  | total loss: [1m[32m0.03896[0m[0m | time: 1.205s
[2K
| RMSProp | epoch: 029 | loss: 0.03896 - acc: 0.9911 -- iter: 0064/1593
[A[ATraining Step: 1403  | total loss: [1m[32m0.03519[0m[0m | time: 1.804s
[2K
| RMSProp | epoch: 029 | loss: 0.03519 - acc: 0.9920 -- iter: 0096/1593
[A[ATraining Step: 1404  | total loss: [1m[32m0.03201[0m[0m | time: 2.443s
[2K
| RMSProp | epoch: 029 | loss: 0.03201 - acc: 0.9928 -- iter: 0128/1593
[A[ATraining Step: 1405  | total loss: [1m[32m0.02889[0m[0m | time: 3.035s
[2K
| RMSProp | epoch: 029 | loss: 0.02889 - acc: 0.9935 -- iter: 0160/1593
[A[ATraining Step: 1406  | total loss: [1m[32m0.02604[0m[0m | time: 3.644s
[2K
| RMSProp | epoch: 029 | loss: 0.02604 - acc: 0.9941 -- iter: 0192/1593
[A[ATraining Step: 1407  | total loss: [1m[32m0.02348[0m[0m | time: 4.257s
[2K
| RMSProp | epoch: 029 | loss: 0.02348 - acc: 0.9947 -- iter: 0224/1593
[A[ATraining Step: 1408  | total loss: [1m[32m0.02122[0m[0m | time: 4.862s
[2K
| RMSProp | epoch: 029 | loss: 0.02122 - acc: 0.9953 -- iter: 0256/1593
[A[ATraining Step: 1409  | total loss: [1m[32m0.01916[0m[0m | time: 5.471s
[2K
| RMSProp | epoch: 029 | loss: 0.01916 - acc: 0.9957 -- iter: 0288/1593
[A[ATraining Step: 1410  | total loss: [1m[32m0.01728[0m[0m | time: 6.051s
[2K
| RMSProp | epoch: 029 | loss: 0.01728 - acc: 0.9962 -- iter: 0320/1593
[A[ATraining Step: 1411  | total loss: [1m[32m0.01559[0m[0m | time: 6.667s
[2K
| RMSProp | epoch: 029 | loss: 0.01559 - acc: 0.9965 -- iter: 0352/1593
[A[ATraining Step: 1412  | total loss: [1m[32m0.01404[0m[0m | time: 7.271s
[2K
| RMSProp | epoch: 029 | loss: 0.01404 - acc: 0.9969 -- iter: 0384/1593
[A[ATraining Step: 1413  | total loss: [1m[32m0.01269[0m[0m | time: 7.871s
[2K
| RMSProp | epoch: 029 | loss: 0.01269 - acc: 0.9972 -- iter: 0416/1593
[A[ATraining Step: 1414  | total loss: [1m[32m0.01145[0m[0m | time: 8.488s
[2K
| RMSProp | epoch: 029 | loss: 0.01145 - acc: 0.9975 -- iter: 0448/1593
[A[ATraining Step: 1415  | total loss: [1m[32m0.01033[0m[0m | time: 9.095s
[2K
| RMSProp | epoch: 029 | loss: 0.01033 - acc: 0.9977 -- iter: 0480/1593
[A[ATraining Step: 1416  | total loss: [1m[32m0.00933[0m[0m | time: 9.698s
[2K
| RMSProp | epoch: 029 | loss: 0.00933 - acc: 0.9980 -- iter: 0512/1593
[A[ATraining Step: 1417  | total loss: [1m[32m0.00844[0m[0m | time: 10.288s
[2K
| RMSProp | epoch: 029 | loss: 0.00844 - acc: 0.9982 -- iter: 0544/1593
[A[ATraining Step: 1418  | total loss: [1m[32m0.00762[0m[0m | time: 10.888s
[2K
| RMSProp | epoch: 029 | loss: 0.00762 - acc: 0.9983 -- iter: 0576/1593
[A[ATraining Step: 1419  | total loss: [1m[32m0.00687[0m[0m | time: 11.496s
[2K
| RMSProp | epoch: 029 | loss: 0.00687 - acc: 0.9985 -- iter: 0608/1593
[A[ATraining Step: 1420  | total loss: [1m[32m0.00619[0m[0m | time: 12.091s
[2K
| RMSProp | epoch: 029 | loss: 0.00619 - acc: 0.9987 -- iter: 0640/1593
[A[ATraining Step: 1421  | total loss: [1m[32m0.00559[0m[0m | time: 12.694s
[2K
| RMSProp | epoch: 029 | loss: 0.00559 - acc: 0.9988 -- iter: 0672/1593
[A[ATraining Step: 1422  | total loss: [1m[32m0.00505[0m[0m | time: 13.319s
[2K
| RMSProp | epoch: 029 | loss: 0.00505 - acc: 0.9989 -- iter: 0704/1593
[A[ATraining Step: 1423  | total loss: [1m[32m0.00518[0m[0m | time: 13.914s
[2K
| RMSProp | epoch: 029 | loss: 0.00518 - acc: 0.9990 -- iter: 0736/1593
[A[ATraining Step: 1424  | total loss: [1m[32m0.02014[0m[0m | time: 14.513s
[2K
| RMSProp | epoch: 029 | loss: 0.02014 - acc: 0.9960 -- iter: 0768/1593
[A[ATraining Step: 1425  | total loss: [1m[32m0.04036[0m[0m | time: 15.119s
[2K
| RMSProp | epoch: 029 | loss: 0.04036 - acc: 0.9870 -- iter: 0800/1593
[A[ATraining Step: 1426  | total loss: [1m[32m0.04531[0m[0m | time: 15.711s
[2K
| RMSProp | epoch: 029 | loss: 0.04531 - acc: 0.9852 -- iter: 0832/1593
[A[ATraining Step: 1427  | total loss: [1m[32m0.04225[0m[0m | time: 16.194s
[2K
| RMSProp | epoch: 029 | loss: 0.04225 - acc: 0.9867 -- iter: 0864/1593
[A[ATraining Step: 1428  | total loss: [1m[32m0.03877[0m[0m | time: 16.686s
[2K
| RMSProp | epoch: 029 | loss: 0.03877 - acc: 0.9880 -- iter: 0896/1593
[A[ATraining Step: 1429  | total loss: [1m[32m0.03516[0m[0m | time: 17.285s
[2K
| RMSProp | epoch: 029 | loss: 0.03516 - acc: 0.9892 -- iter: 0928/1593
[A[ATraining Step: 1430  | total loss: [1m[32m0.03392[0m[0m | time: 17.885s
[2K
| RMSProp | epoch: 029 | loss: 0.03392 - acc: 0.9903 -- iter: 0960/1593
[A[ATraining Step: 1431  | total loss: [1m[32m0.03176[0m[0m | time: 18.491s
[2K
| RMSProp | epoch: 029 | loss: 0.03176 - acc: 0.9913 -- iter: 0992/1593
[A[ATraining Step: 1432  | total loss: [1m[32m0.02861[0m[0m | time: 19.093s
[2K
| RMSProp | epoch: 029 | loss: 0.02861 - acc: 0.9921 -- iter: 1024/1593
[A[ATraining Step: 1433  | total loss: [1m[32m0.02594[0m[0m | time: 19.697s
[2K
| RMSProp | epoch: 029 | loss: 0.02594 - acc: 0.9929 -- iter: 1056/1593
[A[ATraining Step: 1434  | total loss: [1m[32m0.02337[0m[0m | time: 20.318s
[2K
| RMSProp | epoch: 029 | loss: 0.02337 - acc: 0.9936 -- iter: 1088/1593
[A[ATraining Step: 1435  | total loss: [1m[32m0.02114[0m[0m | time: 20.918s
[2K
| RMSProp | epoch: 029 | loss: 0.02114 - acc: 0.9943 -- iter: 1120/1593
[A[ATraining Step: 1436  | total loss: [1m[32m0.01906[0m[0m | time: 21.535s
[2K
| RMSProp | epoch: 029 | loss: 0.01906 - acc: 0.9948 -- iter: 1152/1593
[A[ATraining Step: 1437  | total loss: [1m[32m0.01726[0m[0m | time: 22.141s
[2K
| RMSProp | epoch: 029 | loss: 0.01726 - acc: 0.9954 -- iter: 1184/1593
[A[ATraining Step: 1438  | total loss: [1m[32m0.01555[0m[0m | time: 22.740s
[2K
| RMSProp | epoch: 029 | loss: 0.01555 - acc: 0.9958 -- iter: 1216/1593
[A[ATraining Step: 1439  | total loss: [1m[32m0.01402[0m[0m | time: 23.337s
[2K
| RMSProp | epoch: 029 | loss: 0.01402 - acc: 0.9962 -- iter: 1248/1593
[A[ATraining Step: 1440  | total loss: [1m[32m0.01268[0m[0m | time: 23.963s
[2K
| RMSProp | epoch: 029 | loss: 0.01268 - acc: 0.9966 -- iter: 1280/1593
[A[ATraining Step: 1441  | total loss: [1m[32m0.01143[0m[0m | time: 24.569s
[2K
| RMSProp | epoch: 029 | loss: 0.01143 - acc: 0.9970 -- iter: 1312/1593
[A[ATraining Step: 1442  | total loss: [1m[32m0.01031[0m[0m | time: 25.174s
[2K
| RMSProp | epoch: 029 | loss: 0.01031 - acc: 0.9973 -- iter: 1344/1593
[A[ATraining Step: 1443  | total loss: [1m[32m0.00930[0m[0m | time: 25.756s
[2K
| RMSProp | epoch: 029 | loss: 0.00930 - acc: 0.9975 -- iter: 1376/1593
[A[ATraining Step: 1444  | total loss: [1m[32m0.00845[0m[0m | time: 26.379s
[2K
| RMSProp | epoch: 029 | loss: 0.00845 - acc: 0.9978 -- iter: 1408/1593
[A[ATraining Step: 1445  | total loss: [1m[32m0.00764[0m[0m | time: 27.009s
[2K
| RMSProp | epoch: 029 | loss: 0.00764 - acc: 0.9980 -- iter: 1440/1593
[A[ATraining Step: 1446  | total loss: [1m[32m0.00691[0m[0m | time: 27.641s
[2K
| RMSProp | epoch: 029 | loss: 0.00691 - acc: 0.9982 -- iter: 1472/1593
[A[ATraining Step: 1447  | total loss: [1m[32m0.12112[0m[0m | time: 28.287s
[2K
| RMSProp | epoch: 029 | loss: 0.12112 - acc: 0.9890 -- iter: 1504/1593
[A[ATraining Step: 1448  | total loss: [1m[32m0.11539[0m[0m | time: 28.915s
[2K
| RMSProp | epoch: 029 | loss: 0.11539 - acc: 0.9870 -- iter: 1536/1593
[A[ATraining Step: 1449  | total loss: [1m[32m0.10686[0m[0m | time: 29.527s
[2K
| RMSProp | epoch: 029 | loss: 0.10686 - acc: 0.9883 -- iter: 1568/1593
[A[ATraining Step: 1450  | total loss: [1m[32m0.10132[0m[0m | time: 31.694s
[2K
| RMSProp | epoch: 029 | loss: 0.10132 - acc: 0.9863 | val_loss: 0.54871 - val_acc: 0.8574 -- iter: 1593/1593
--
Training Step: 1451  | total loss: [1m[32m0.09176[0m[0m | time: 0.599s
[2K
| RMSProp | epoch: 030 | loss: 0.09176 - acc: 0.9877 -- iter: 0032/1593
[A[ATraining Step: 1452  | total loss: [1m[32m0.08284[0m[0m | time: 1.211s
[2K
| RMSProp | epoch: 030 | loss: 0.08284 - acc: 0.9889 -- iter: 0064/1593
[A[ATraining Step: 1453  | total loss: [1m[32m0.07490[0m[0m | time: 1.824s
[2K
| RMSProp | epoch: 030 | loss: 0.07490 - acc: 0.9900 -- iter: 0096/1593
[A[ATraining Step: 1454  | total loss: [1m[32m0.06815[0m[0m | time: 2.427s
[2K
| RMSProp | epoch: 030 | loss: 0.06815 - acc: 0.9910 -- iter: 0128/1593
[A[ATraining Step: 1455  | total loss: [1m[32m0.06140[0m[0m | time: 3.034s
[2K
| RMSProp | epoch: 030 | loss: 0.06140 - acc: 0.9919 -- iter: 0160/1593
[A[ATraining Step: 1456  | total loss: [1m[32m0.05532[0m[0m | time: 3.632s
[2K
| RMSProp | epoch: 030 | loss: 0.05532 - acc: 0.9927 -- iter: 0192/1593
[A[ATraining Step: 1457  | total loss: [1m[32m0.04988[0m[0m | time: 4.238s
[2K
| RMSProp | epoch: 030 | loss: 0.04988 - acc: 0.9935 -- iter: 0224/1593
[A[ATraining Step: 1458  | total loss: [1m[32m0.04511[0m[0m | time: 4.828s
[2K
| RMSProp | epoch: 030 | loss: 0.04511 - acc: 0.9941 -- iter: 0256/1593
[A[ATraining Step: 1459  | total loss: [1m[32m0.04063[0m[0m | time: 5.464s
[2K
| RMSProp | epoch: 030 | loss: 0.04063 - acc: 0.9947 -- iter: 0288/1593
[A[ATraining Step: 1460  | total loss: [1m[32m0.03664[0m[0m | time: 6.063s
[2K
| RMSProp | epoch: 030 | loss: 0.03664 - acc: 0.9952 -- iter: 0320/1593
[A[ATraining Step: 1461  | total loss: [1m[32m0.03301[0m[0m | time: 6.683s
[2K
| RMSProp | epoch: 030 | loss: 0.03301 - acc: 0.9957 -- iter: 0352/1593
[A[ATraining Step: 1462  | total loss: [1m[32m0.02975[0m[0m | time: 7.284s
[2K
| RMSProp | epoch: 030 | loss: 0.02975 - acc: 0.9961 -- iter: 0384/1593
[A[ATraining Step: 1463  | total loss: [1m[32m0.02693[0m[0m | time: 7.893s
[2K
| RMSProp | epoch: 030 | loss: 0.02693 - acc: 0.9965 -- iter: 0416/1593
[A[ATraining Step: 1464  | total loss: [1m[32m0.02582[0m[0m | time: 8.468s
[2K
| RMSProp | epoch: 030 | loss: 0.02582 - acc: 0.9969 -- iter: 0448/1593
[A[ATraining Step: 1465  | total loss: [1m[32m0.04260[0m[0m | time: 9.071s
[2K
| RMSProp | epoch: 030 | loss: 0.04260 - acc: 0.9909 -- iter: 0480/1593
[A[ATraining Step: 1466  | total loss: [1m[32m0.04726[0m[0m | time: 9.668s
[2K
| RMSProp | epoch: 030 | loss: 0.04726 - acc: 0.9887 -- iter: 0512/1593
[A[ATraining Step: 1467  | total loss: [1m[32m0.04601[0m[0m | time: 10.271s
[2K
| RMSProp | epoch: 030 | loss: 0.04601 - acc: 0.9867 -- iter: 0544/1593
[A[ATraining Step: 1468  | total loss: [1m[32m0.04563[0m[0m | time: 10.874s
[2K
| RMSProp | epoch: 030 | loss: 0.04563 - acc: 0.9849 -- iter: 0576/1593
[A[ATraining Step: 1469  | total loss: [1m[32m0.04667[0m[0m | time: 11.469s
[2K
| RMSProp | epoch: 030 | loss: 0.04667 - acc: 0.9833 -- iter: 0608/1593
[A[ATraining Step: 1470  | total loss: [1m[32m0.04218[0m[0m | time: 12.087s
[2K
| RMSProp | epoch: 030 | loss: 0.04218 - acc: 0.9850 -- iter: 0640/1593
[A[ATraining Step: 1471  | total loss: [1m[32m0.03900[0m[0m | time: 12.698s
[2K
| RMSProp | epoch: 030 | loss: 0.03900 - acc: 0.9865 -- iter: 0672/1593
[A[ATraining Step: 1472  | total loss: [1m[32m0.03514[0m[0m | time: 13.316s
[2K
| RMSProp | epoch: 030 | loss: 0.03514 - acc: 0.9878 -- iter: 0704/1593
[A[ATraining Step: 1473  | total loss: [1m[32m0.03165[0m[0m | time: 13.919s
[2K
| RMSProp | epoch: 030 | loss: 0.03165 - acc: 0.9890 -- iter: 0736/1593
[A[ATraining Step: 1474  | total loss: [1m[32m0.02853[0m[0m | time: 14.513s
[2K
| RMSProp | epoch: 030 | loss: 0.02853 - acc: 0.9901 -- iter: 0768/1593
[A[ATraining Step: 1475  | total loss: [1m[32m0.02575[0m[0m | time: 15.108s
[2K
| RMSProp | epoch: 030 | loss: 0.02575 - acc: 0.9911 -- iter: 0800/1593
[A[ATraining Step: 1476  | total loss: [1m[32m0.02325[0m[0m | time: 15.719s
[2K
| RMSProp | epoch: 030 | loss: 0.02325 - acc: 0.9920 -- iter: 0832/1593
[A[ATraining Step: 1477  | total loss: [1m[32m0.02902[0m[0m | time: 16.317s
[2K
| RMSProp | epoch: 030 | loss: 0.02902 - acc: 0.9897 -- iter: 0864/1593
[A[ATraining Step: 1478  | total loss: [1m[32m0.03131[0m[0m | time: 16.801s
[2K
| RMSProp | epoch: 030 | loss: 0.03131 - acc: 0.9876 -- iter: 0896/1593
[A[ATraining Step: 1479  | total loss: [1m[32m0.02844[0m[0m | time: 17.288s
[2K
| RMSProp | epoch: 030 | loss: 0.02844 - acc: 0.9888 -- iter: 0928/1593
[A[ATraining Step: 1480  | total loss: [1m[32m0.02565[0m[0m | time: 17.900s
[2K
| RMSProp | epoch: 030 | loss: 0.02565 - acc: 0.9900 -- iter: 0960/1593
[A[ATraining Step: 1481  | total loss: [1m[32m0.02315[0m[0m | time: 18.477s
[2K
| RMSProp | epoch: 030 | loss: 0.02315 - acc: 0.9910 -- iter: 0992/1593
[A[ATraining Step: 1482  | total loss: [1m[32m0.04314[0m[0m | time: 19.107s
[2K
| RMSProp | epoch: 030 | loss: 0.04314 - acc: 0.9887 -- iter: 1024/1593
[A[ATraining Step: 1483  | total loss: [1m[32m0.05599[0m[0m | time: 19.709s
[2K
| RMSProp | epoch: 030 | loss: 0.05599 - acc: 0.9805 -- iter: 1056/1593
[A[ATraining Step: 1484  | total loss: [1m[32m0.05118[0m[0m | time: 20.312s
[2K
| RMSProp | epoch: 030 | loss: 0.05118 - acc: 0.9824 -- iter: 1088/1593
[A[ATraining Step: 1485  | total loss: [1m[32m0.04678[0m[0m | time: 20.911s
[2K
| RMSProp | epoch: 030 | loss: 0.04678 - acc: 0.9842 -- iter: 1120/1593
[A[ATraining Step: 1486  | total loss: [1m[32m0.04223[0m[0m | time: 21.509s
[2K
| RMSProp | epoch: 030 | loss: 0.04223 - acc: 0.9858 -- iter: 1152/1593
[A[ATraining Step: 1487  | total loss: [1m[32m0.03806[0m[0m | time: 22.087s
[2K
| RMSProp | epoch: 030 | loss: 0.03806 - acc: 0.9872 -- iter: 1184/1593
[A[ATraining Step: 1488  | total loss: [1m[32m0.03432[0m[0m | time: 22.682s
[2K
| RMSProp | epoch: 030 | loss: 0.03432 - acc: 0.9885 -- iter: 1216/1593
[A[ATraining Step: 1489  | total loss: [1m[32m0.03101[0m[0m | time: 23.302s
[2K
| RMSProp | epoch: 030 | loss: 0.03101 - acc: 0.9896 -- iter: 1248/1593
[A[ATraining Step: 1490  | total loss: [1m[32m0.02898[0m[0m | time: 23.903s
[2K
| RMSProp | epoch: 030 | loss: 0.02898 - acc: 0.9907 -- iter: 1280/1593
[A[ATraining Step: 1491  | total loss: [1m[32m0.02617[0m[0m | time: 24.536s
[2K
| RMSProp | epoch: 030 | loss: 0.02617 - acc: 0.9916 -- iter: 1312/1593
[A[ATraining Step: 1492  | total loss: [1m[32m0.02557[0m[0m | time: 25.123s
[2K
| RMSProp | epoch: 030 | loss: 0.02557 - acc: 0.9924 -- iter: 1344/1593
[A[ATraining Step: 1493  | total loss: [1m[32m0.02585[0m[0m | time: 25.717s
[2K
| RMSProp | epoch: 030 | loss: 0.02585 - acc: 0.9901 -- iter: 1376/1593
[A[ATraining Step: 1494  | total loss: [1m[32m0.02332[0m[0m | time: 26.309s
[2K
| RMSProp | epoch: 030 | loss: 0.02332 - acc: 0.9911 -- iter: 1408/1593
[A[ATraining Step: 1495  | total loss: [1m[32m0.02119[0m[0m | time: 26.900s
[2K
| RMSProp | epoch: 030 | loss: 0.02119 - acc: 0.9920 -- iter: 1440/1593
[A[ATraining Step: 1496  | total loss: [1m[32m0.01921[0m[0m | time: 27.494s
[2K
| RMSProp | epoch: 030 | loss: 0.01921 - acc: 0.9928 -- iter: 1472/1593
[A[ATraining Step: 1497  | total loss: [1m[32m0.01735[0m[0m | time: 28.094s
[2K
| RMSProp | epoch: 030 | loss: 0.01735 - acc: 0.9935 -- iter: 1504/1593
[A[ATraining Step: 1498  | total loss: [1m[32m0.08420[0m[0m | time: 28.703s
[2K
| RMSProp | epoch: 030 | loss: 0.08420 - acc: 0.9848 -- iter: 1536/1593
[A[ATraining Step: 1499  | total loss: [1m[32m0.07857[0m[0m | time: 29.306s
[2K
| RMSProp | epoch: 030 | loss: 0.07857 - acc: 0.9863 -- iter: 1568/1593
[A[ATraining Step: 1500  | total loss: [1m[32m0.07239[0m[0m | time: 31.446s
[2K
| RMSProp | epoch: 030 | loss: 0.07239 - acc: 0.9877 | val_loss: 0.58524 - val_acc: 0.8474 -- iter: 1593/1593
--
Validation AUC:0.9163763066202091
Validation AUPRC:0.9250704356205458
Test AUC:0.966212393100215
Test AUPRC:0.9676830267393578
BestTestF1Score	0.9	0.81	0.91	0.89	0.92	218	28	233	19	0.15
BestTestMCCScore	0.9	0.81	0.91	0.89	0.92	218	28	233	19	0.15
BestTestAccuracyScore	0.9	0.81	0.91	0.89	0.92	218	28	233	19	0.15
BestValidationF1Score	0.86	0.71	0.86	0.86	0.85	210	35	217	36	0.15
BestValidationMCC	0.86	0.71	0.86	0.86	0.85	210	35	217	36	0.15
BestValidationAccuracy	0.86	0.71	0.86	0.86	0.85	210	35	217	36	0.15
TestPredictions (Threshold:0.15)
CHEMBL1923179,TP,ACT,1.0	CHEMBL50,TN,INACT,0.0	CHEMBL1684198,TP,ACT,1.0	CHEMBL489430,TN,INACT,0.0	CHEMBL1682335,TP,ACT,0.9800000190734863	CHEMBL381932,TN,INACT,0.0	CHEMBL3700939,TP,ACT,1.0	CHEMBL3426637,TP,ACT,1.0	CHEMBL395664,TN,INACT,0.0	CHEMBL1668418,FP,INACT,0.23999999463558197	CHEMBL3613603,TP,ACT,1.0	CHEMBL497791,TN,INACT,0.0	CHEMBL1524448,TN,INACT,0.009999999776482582	CHEMBL3689416,TP,ACT,1.0	CHEMBL3689489,TP,ACT,1.0	CHEMBL3700902,TP,ACT,1.0	CHEMBL1589110,TN,INACT,0.029999999329447746	CHEMBL485213,TP,ACT,1.0	CHEMBL1643361,FN,ACT,0.0	CHEMBL2407917,FP,INACT,0.3100000023841858	CHEMBL133214,TN,INACT,0.0	CHEMBL3214457,TN,INACT,0.0	CHEMBL3649658,TP,ACT,1.0	CHEMBL559818,TN,INACT,0.009999999776482582	CHEMBL549385,TN,INACT,0.009999999776482582	CHEMBL178397,FP,INACT,0.9800000190734863	CHEMBL3680798,TP,ACT,1.0	CHEMBL3689421,TP,ACT,1.0	CHEMBL490053,TN,INACT,0.0	CHEMBL2325735,TP,ACT,1.0	CHEMBL1086517,TP,ACT,1.0	CHEMBL3596524,TN,INACT,0.0	CHEMBL3085242,TN,INACT,0.0	CHEMBL26372,TN,INACT,0.0	CHEMBL2023157,TP,ACT,1.0	CHEMBL356169,TN,INACT,0.0	CHEMBL1223500,TP,ACT,1.0	CHEMBL1910758,TN,INACT,0.0	CHEMBL1684205,TP,ACT,1.0	CHEMBL1222413,TP,ACT,0.9900000095367432	CHEMBL3689435,TP,ACT,1.0	CHEMBL2325984,TP,ACT,1.0	CHEMBL1682337,TP,ACT,0.9900000095367432	CHEMBL3689422,TP,ACT,1.0	CHEMBL509011,TP,ACT,1.0	CHEMBL1215093,TP,ACT,1.0	CHEMBL2023150,TP,ACT,0.949999988079071	CHEMBL312078,TN,INACT,0.0	CHEMBL88962,TN,INACT,0.0	CHEMBL574738,FN,ACT,0.009999999776482582	CHEMBL3700921,TP,ACT,1.0	CHEMBL1922143,TP,ACT,1.0	CHEMBL2332099,TP,ACT,1.0	CHEMBL3689361,TP,ACT,0.9800000190734863	CHEMBL3792888,TP,ACT,0.9900000095367432	CHEMBL1439904,TN,INACT,0.0	CHEMBL1084863,TN,INACT,0.0	CHEMBL3218012,TP,ACT,1.0	CHEMBL452734,TP,ACT,0.9800000190734863	CHEMBL1922137,TP,ACT,1.0	CHEMBL591047,TP,ACT,0.9900000095367432	CHEMBL101868,TN,INACT,0.0	CHEMBL3689348,TP,ACT,0.9900000095367432	CHEMBL327994,TN,INACT,0.0	CHEMBL2333879,TP,ACT,0.9900000095367432	CHEMBL2325741,TP,ACT,1.0	CHEMBL1413946,TN,INACT,0.009999999776482582	CHEMBL3426636,TP,ACT,1.0	CHEMBL3218009,TP,ACT,1.0	CHEMBL100079,TN,INACT,0.009999999776482582	CHEMBL1582724,TN,INACT,0.0	CHEMBL1688211,TN,INACT,0.009999999776482582	CHEMBL2332065,TP,ACT,1.0	CHEMBL497606,TN,INACT,0.0	CHEMBL3426731,FN,ACT,0.12999999523162842	CHEMBL3613607,TP,ACT,1.0	CHEMBL2392232,TN,INACT,0.0	CHEMBL1222418,FN,ACT,0.009999999776482582	CHEMBL3628248,TN,INACT,0.009999999776482582	CHEMBL3665657,TN,INACT,0.0	CHEMBL3700934,TP,ACT,0.9900000095367432	CHEMBL2023714,FN,ACT,0.11999999731779099	CHEMBL3402474,TP,ACT,1.0	CHEMBL1077370,TP,ACT,0.9900000095367432	CHEMBL1923165,TP,ACT,1.0	CHEMBL1643368,TP,ACT,0.949999988079071	CHEMBL1569232,TN,INACT,0.0	CHEMBL483081,TN,INACT,0.0	CHEMBL2325986,TP,ACT,0.9800000190734863	CHEMBL3700977,TP,ACT,1.0	CHEMBL234944,FP,INACT,0.8399999737739563	CHEMBL1556197,TN,INACT,0.0	CHEMBL554147,TN,INACT,0.0	CHEMBL3689364,TP,ACT,0.949999988079071	CHEMBL246356,TN,INACT,0.10999999940395355	CHEMBL173459,TN,INACT,0.019999999552965164	CHEMBL2205426,TP,ACT,0.9100000262260437	CHEMBL482351,TP,ACT,1.0	CHEMBL518665,TP,ACT,1.0	CHEMBL3680789,TP,ACT,1.0	CHEMBL2024655,TP,ACT,0.23999999463558197	CHEMBL1172459,TN,INACT,0.029999999329447746	CHEMBL1784649,TN,INACT,0.0	CHEMBL391830,TN,INACT,0.0	CHEMBL498203,TN,INACT,0.0	CHEMBL390156,TN,INACT,0.019999999552965164	CHEMBL496588,TN,INACT,0.0	CHEMBL3700932,TP,ACT,1.0	CHEMBL1462031,TN,INACT,0.0	CHEMBL3426640,TP,ACT,1.0	CHEMBL558859,TN,INACT,0.05999999865889549	CHEMBL238744,TP,ACT,1.0	CHEMBL247684,TN,INACT,0.0	CHEMBL1559959,TN,INACT,0.0	CHEMBL1171416,TN,INACT,0.0	CHEMBL2163608,TN,INACT,0.0	CHEMBL3700983,TP,ACT,0.9800000190734863	CHEMBL3680501,TN,INACT,0.009999999776482582	CHEMBL268368,TN,INACT,0.0	CHEMBL3823802,TN,INACT,0.0	CHEMBL550608,TN,INACT,0.009999999776482582	CHEMBL478798,TN,INACT,0.0	CHEMBL3792412,TP,ACT,1.0	CHEMBL1823653,FP,INACT,0.9800000190734863	CHEMBL1525418,FP,INACT,0.23000000417232513	CHEMBL377654,TN,INACT,0.009999999776482582	CHEMBL3623847,TN,INACT,0.0	CHEMBL1082819,TP,ACT,0.9900000095367432	CHEMBL3402444,TP,ACT,1.0	CHEMBL3659984,FP,INACT,0.4300000071525574	CHEMBL213525,TN,INACT,0.0	CHEMBL207544,FP,INACT,0.8600000143051147	CHEMBL3680788,TP,ACT,1.0	CHEMBL3426627,FN,ACT,0.019999999552965164	CHEMBL1641990,TN,INACT,0.0	CHEMBL2087026,TN,INACT,0.0	CHEMBL599791,TP,ACT,0.25999999046325684	CHEMBL3700919,TP,ACT,1.0	CHEMBL1079920,TP,ACT,1.0	CHEMBL3704376,TP,ACT,1.0	CHEMBL1600077,TN,INACT,0.009999999776482582	CHEMBL346721,TN,INACT,0.0	CHEMBL428647,TN,INACT,0.0	CHEMBL3680709,TP,ACT,1.0	CHEMBL102047,TN,INACT,0.0	CHEMBL335938,TN,INACT,0.0	CHEMBL469776,TN,INACT,0.0	CHEMBL3661091,TN,INACT,0.019999999552965164	CHEMBL2113332,TN,INACT,0.0	CHEMBL3668195,FP,INACT,0.20999999344348907	CHEMBL482163,TP,ACT,1.0	CHEMBL2440756,TP,ACT,0.9399999976158142	CHEMBL3629279,TP,ACT,1.0	CHEMBL3680747,TP,ACT,1.0	CHEMBL3680732,TP,ACT,1.0	CHEMBL3704379,TP,ACT,1.0	CHEMBL1432163,TN,INACT,0.0	CHEMBL1682350,TP,ACT,1.0	CHEMBL475601,TP,ACT,1.0	CHEMBL1527476,TN,INACT,0.029999999329447746	CHEMBL17551,TN,INACT,0.0	CHEMBL3647976,FN,ACT,0.0	CHEMBL2391621,TN,INACT,0.009999999776482582	CHEMBL551722,TN,INACT,0.0	CHEMBL344779,TN,INACT,0.009999999776482582	CHEMBL611127,FP,INACT,0.4099999964237213	CHEMBL3666717,FN,ACT,0.009999999776482582	CHEMBL3402464,TP,ACT,1.0	CHEMBL246101,TN,INACT,0.0	CHEMBL3613610,TP,ACT,0.9900000095367432	CHEMBL551545,TN,INACT,0.0	CHEMBL3689360,TP,ACT,0.7599999904632568	CHEMBL1540020,TN,INACT,0.0	CHEMBL507666,FP,INACT,0.949999988079071	CHEMBL2392388,TN,INACT,0.0	CHEMBL3666716,TP,ACT,0.8899999856948853	CHEMBL1379970,TN,INACT,0.0	CHEMBL149604,TN,INACT,0.0	CHEMBL2332083,TP,ACT,1.0	CHEMBL1682348,TP,ACT,1.0	CHEMBL203006,TN,INACT,0.03999999910593033	CHEMBL3680756,TP,ACT,0.9900000095367432	CHEMBL3794254,TP,ACT,0.9900000095367432	CHEMBL1083132,TP,ACT,1.0	CHEMBL3700968,TP,ACT,1.0	CHEMBL1682336,TP,ACT,0.9800000190734863	CHEMBL3680704,TP,ACT,1.0	CHEMBL3218016,TP,ACT,1.0	CHEMBL1667963,TP,ACT,0.9900000095367432	CHEMBL2332070,TP,ACT,0.9300000071525574	CHEMBL1483570,FP,INACT,0.8700000047683716	CHEMBL249089,FP,INACT,0.9300000071525574	CHEMBL411284,TN,INACT,0.0	CHEMBL3680706,TP,ACT,1.0	CHEMBL558460,FP,INACT,0.20000000298023224	CHEMBL481509,TP,ACT,0.9300000071525574	CHEMBL3426625,FN,ACT,0.0	CHEMBL1779067,TN,INACT,0.0	CHEMBL3689480,TP,ACT,1.0	CHEMBL226471,TN,INACT,0.0	CHEMBL1644619,TN,INACT,0.0	CHEMBL3792435,TP,ACT,1.0	CHEMBL1923167,TP,ACT,1.0	CHEMBL512658,TN,INACT,0.0	CHEMBL1910756,TN,INACT,0.009999999776482582	CHEMBL454624,TP,ACT,1.0	CHEMBL478488,FP,INACT,0.5899999737739563	CHEMBL3689353,FN,ACT,0.03999999910593033	CHEMBL467069,TN,INACT,0.009999999776482582	CHEMBL1490940,TN,INACT,0.009999999776482582	CHEMBL3629608,TN,INACT,0.009999999776482582	CHEMBL2029525,TN,INACT,0.019999999552965164	CHEMBL3680728,TP,ACT,1.0	CHEMBL3689381,TP,ACT,1.0	CHEMBL3680737,TP,ACT,1.0	CHEMBL3314278,TN,INACT,0.0	CHEMBL2335070,TN,INACT,0.0	CHEMBL1215303,TP,ACT,1.0	CHEMBL1813625,TN,INACT,0.0	CHEMBL511172,TN,INACT,0.0	CHEMBL505949,TP,ACT,0.9800000190734863	CHEMBL3700912,TP,ACT,0.9900000095367432	CHEMBL2407915,FP,INACT,0.6200000047683716	CHEMBL1922114,TN,INACT,0.0	CHEMBL3680754,TP,ACT,1.0	CHEMBL1481517,TN,INACT,0.0	CHEMBL1077600,TP,ACT,0.7699999809265137	CHEMBL3700959,TP,ACT,1.0	CHEMBL335373,TN,INACT,0.0	CHEMBL598336,TP,ACT,1.0	CHEMBL3402469,TP,ACT,0.8199999928474426	CHEMBL2332097,TP,ACT,1.0	CHEMBL2407910,TN,INACT,0.029999999329447746	CHEMBL1288582,TN,INACT,0.0	CHEMBL1372854,TN,INACT,0.0	CHEMBL1288895,TN,INACT,0.07999999821186066	CHEMBL1315166,TP,ACT,0.9200000166893005	CHEMBL3689368,TP,ACT,0.949999988079071	CHEMBL488646,TN,INACT,0.0	CHEMBL89191,TN,INACT,0.0	CHEMBL1644617,TN,INACT,0.0	CHEMBL453336,TN,INACT,0.0	CHEMBL2334294,TP,ACT,1.0	CHEMBL392064,TP,ACT,1.0	CHEMBL3689362,TP,ACT,0.9300000071525574	CHEMBL3665661,TN,INACT,0.009999999776482582	CHEMBL2163980,TN,INACT,0.009999999776482582	CHEMBL3426638,TP,ACT,1.0	CHEMBL563281,TN,INACT,0.0	CHEMBL88533,TN,INACT,0.0	CHEMBL3700949,TP,ACT,1.0	CHEMBL3426732,TP,ACT,0.9200000166893005	CHEMBL316088,TN,INACT,0.0	CHEMBL392609,TP,ACT,1.0	CHEMBL105350,TN,INACT,0.029999999329447746	CHEMBL575945,TN,INACT,0.009999999776482582	CHEMBL3116062,TN,INACT,0.009999999776482582	CHEMBL1681995,TN,INACT,0.0	CHEMBL3680707,TP,ACT,1.0	CHEMBL1208888,TN,INACT,0.009999999776482582	CHEMBL2420584,TN,INACT,0.009999999776482582	CHEMBL2311808,TN,INACT,0.0	CHEMBL99779,TN,INACT,0.03999999910593033	CHEMBL245769,TN,INACT,0.009999999776482582	CHEMBL78679,TN,INACT,0.10000000149011612	CHEMBL1566655,TN,INACT,0.019999999552965164	CHEMBL401633,TN,INACT,0.0	CHEMBL1567258,TN,INACT,0.0	CHEMBL360278,TN,INACT,0.0	CHEMBL511138,TN,INACT,0.0	CHEMBL1570276,TN,INACT,0.0	CHEMBL3398595,TN,INACT,0.009999999776482582	CHEMBL3261337,TN,INACT,0.0	CHEMBL3680776,TP,ACT,1.0	CHEMBL3700917,TP,ACT,1.0	CHEMBL1222417,TP,ACT,0.9900000095367432	CHEMBL317281,TN,INACT,0.0	CHEMBL278526,TN,INACT,0.0	CHEMBL3680497,TN,INACT,0.0	CHEMBL450786,FN,ACT,0.009999999776482582	CHEMBL3426624,TP,ACT,0.3499999940395355	CHEMBL246309,TN,INACT,0.019999999552965164	CHEMBL2023154,TP,ACT,0.9800000190734863	CHEMBL3689441,TP,ACT,0.9900000095367432	CHEMBL1734241,FP,INACT,0.44999998807907104	CHEMBL1877245,TN,INACT,0.029999999329447746	CHEMBL127277,TN,INACT,0.0	CHEMBL1331525,FP,INACT,0.9900000095367432	CHEMBL1209836,TN,INACT,0.0	CHEMBL1923053,TP,ACT,1.0	CHEMBL1682543,TP,ACT,0.17000000178813934	CHEMBL2333881,TP,ACT,0.9900000095367432	CHEMBL1682347,TP,ACT,1.0	CHEMBL2163999,FP,INACT,0.9399999976158142	CHEMBL1083748,TP,ACT,0.9900000095367432	CHEMBL2332058,TP,ACT,1.0	CHEMBL3689444,TP,ACT,1.0	CHEMBL1922204,TN,INACT,0.0	CHEMBL1258663,FP,INACT,0.9900000095367432	CHEMBL1370652,TN,INACT,0.009999999776482582	CHEMBL3704373,TP,ACT,1.0	CHEMBL3675452,TN,INACT,0.009999999776482582	CHEMBL2163609,TN,INACT,0.029999999329447746	CHEMBL3628246,TN,INACT,0.019999999552965164	CHEMBL2440745,TP,ACT,0.9599999785423279	CHEMBL3338843,TP,ACT,0.9700000286102295	CHEMBL600828,TN,INACT,0.0	CHEMBL1092754,FP,INACT,0.18000000715255737	CHEMBL379849,TN,INACT,0.0	CHEMBL1923181,TP,ACT,1.0	CHEMBL1922039,TP,ACT,1.0	CHEMBL559881,TN,INACT,0.0	CHEMBL1384896,TN,INACT,0.0	CHEMBL309078,TN,INACT,0.0	CHEMBL31184,TN,INACT,0.0	CHEMBL519113,TN,INACT,0.0	CHEMBL1545025,TN,INACT,0.0	CHEMBL600852,TP,ACT,0.9399999976158142	CHEMBL3410030,TP,ACT,1.0	CHEMBL3628993,TN,INACT,0.009999999776482582	CHEMBL3666759,FN,ACT,0.0	CHEMBL2392366,TN,INACT,0.03999999910593033	CHEMBL3700964,TP,ACT,1.0	CHEMBL345800,TN,INACT,0.0	CHEMBL1421889,TN,INACT,0.03999999910593033	CHEMBL2112065,TN,INACT,0.019999999552965164	CHEMBL1684202,TP,ACT,1.0	CHEMBL3680777,TP,ACT,1.0	CHEMBL3195180,TN,INACT,0.009999999776482582	CHEMBL2000337,TN,INACT,0.009999999776482582	CHEMBL2163623,TN,INACT,0.0	CHEMBL390066,FP,INACT,0.23000000417232513	CHEMBL3704377,TP,ACT,1.0	CHEMBL2392233,TN,INACT,0.0	CHEMBL2333900,TP,ACT,0.9399999976158142	CHEMBL1922212,TN,INACT,0.0	CHEMBL557237,TN,INACT,0.0	CHEMBL1083114,TP,ACT,0.5699999928474426	CHEMBL1923161,TP,ACT,1.0	CHEMBL2392236,TN,INACT,0.0	CHEMBL1951346,TP,ACT,1.0	CHEMBL3109401,TN,INACT,0.0	CHEMBL3426632,TP,ACT,0.9900000095367432	CHEMBL3680782,TP,ACT,1.0	CHEMBL3628253,TN,INACT,0.009999999776482582	CHEMBL277432,TN,INACT,0.0	CHEMBL3680791,TP,ACT,1.0	CHEMBL3628365,FP,INACT,0.9599999785423279	CHEMBL3704390,TP,ACT,1.0	CHEMBL3793788,TP,ACT,1.0	CHEMBL3689454,TP,ACT,1.0	CHEMBL3426633,TP,ACT,1.0	CHEMBL2392375,TN,INACT,0.0	CHEMBL3792549,TP,ACT,1.0	CHEMBL2332060,FN,ACT,0.11999999731779099	CHEMBL3704394,TP,ACT,0.9700000286102295	CHEMBL482883,TN,INACT,0.0	CHEMBL367442,TN,INACT,0.019999999552965164	CHEMBL1682341,TP,ACT,1.0	CHEMBL1922128,TP,ACT,1.0	CHEMBL174634,TN,INACT,0.0	CHEMBL1215022,TP,ACT,1.0	CHEMBL3700411,TN,INACT,0.0	CHEMBL2392385,TN,INACT,0.0	CHEMBL436817,TN,INACT,0.029999999329447746	CHEMBL1796178,TN,INACT,0.0	CHEMBL3792663,TP,ACT,1.0	CHEMBL2310935,TN,INACT,0.009999999776482582	CHEMBL1784655,TN,INACT,0.0	CHEMBL3700976,TP,ACT,0.9900000095367432	CHEMBL3689394,TP,ACT,0.9900000095367432	CHEMBL3628257,TN,INACT,0.0	CHEMBL99647,TN,INACT,0.0	CHEMBL128568,TN,INACT,0.009999999776482582	CHEMBL1208826,TN,INACT,0.0	CHEMBL35482,TN,INACT,0.0	CHEMBL600236,TP,ACT,0.949999988079071	CHEMBL118,TN,INACT,0.019999999552965164	CHEMBL1495244,TN,INACT,0.029999999329447746	CHEMBL517891,TP,ACT,1.0	CHEMBL2333896,TP,ACT,0.8700000047683716	CHEMBL3700969,TP,ACT,1.0	CHEMBL3426643,TP,ACT,0.9200000166893005	CHEMBL3314286,TN,INACT,0.0	CHEMBL2325737,TP,ACT,1.0	CHEMBL3700952,TP,ACT,1.0	CHEMBL3356449,TN,INACT,0.029999999329447746	CHEMBL2334723,TN,INACT,0.009999999776482582	CHEMBL1524458,TN,INACT,0.019999999552965164	CHEMBL328627,TN,INACT,0.0	CHEMBL1783550,TN,INACT,0.0	CHEMBL238762,TP,ACT,0.9900000095367432	CHEMBL592709,TP,ACT,1.0	CHEMBL2325989,TP,ACT,0.9800000190734863	CHEMBL519959,TP,ACT,1.0	CHEMBL303205,TN,INACT,0.0	CHEMBL589359,FN,ACT,0.009999999776482582	CHEMBL1684199,TP,ACT,1.0	CHEMBL2333903,TP,ACT,1.0	CHEMBL3700948,TP,ACT,1.0	CHEMBL1796179,TN,INACT,0.0	CHEMBL1922210,TN,INACT,0.0	CHEMBL232542,TN,INACT,0.009999999776482582	CHEMBL496971,TN,INACT,0.0	CHEMBL1922121,TN,INACT,0.0	CHEMBL502585,TN,INACT,0.0	CHEMBL3680731,TP,ACT,1.0	CHEMBL396487,TN,INACT,0.0	CHEMBL1288966,TN,INACT,0.0	CHEMBL2333906,TP,ACT,1.0	CHEMBL1084800,TP,ACT,1.0	CHEMBL120127,FP,INACT,0.9300000071525574	CHEMBL2392237,TN,INACT,0.0	CHEMBL3410039,TP,ACT,0.9900000095367432	CHEMBL1084105,TP,ACT,0.9800000190734863	CHEMBL1682021,TN,INACT,0.0	CHEMBL2151193,TN,INACT,0.009999999776482582	CHEMBL3689448,TP,ACT,0.9900000095367432	CHEMBL2334289,FN,ACT,0.0	CHEMBL345639,TN,INACT,0.0	CHEMBL504550,TN,INACT,0.009999999776482582	CHEMBL403233,TN,INACT,0.009999999776482582	CHEMBL160333,TN,INACT,0.019999999552965164	CHEMBL551318,TN,INACT,0.019999999552965164	CHEMBL1667965,TP,ACT,0.8899999856948853	CHEMBL208561,TN,INACT,0.0	CHEMBL1414543,TN,INACT,0.0	CHEMBL475613,TP,ACT,1.0	CHEMBL3666720,FN,ACT,0.019999999552965164	CHEMBL455446,FN,ACT,0.05000000074505806	CHEMBL100811,TN,INACT,0.0	CHEMBL173647,FP,INACT,0.3400000035762787	CHEMBL207226,TN,INACT,0.009999999776482582	CHEMBL3700923,TP,ACT,1.0	CHEMBL270342,TN,INACT,0.0	CHEMBL2348167,TN,INACT,0.0	CHEMBL2332064,TP,ACT,1.0	CHEMBL151823,FP,INACT,1.0	CHEMBL1806525,TN,INACT,0.0	CHEMBL3809141,TN,INACT,0.009999999776482582	CHEMBL3680532,FP,INACT,0.4399999976158142	CHEMBL3689473,TP,ACT,0.9900000095367432	CHEMBL1923178,TP,ACT,0.9900000095367432	CHEMBL2325997,TP,ACT,0.9900000095367432	CHEMBL3104854,TN,INACT,0.009999999776482582	CHEMBL3680702,TP,ACT,1.0	CHEMBL3689470,TP,ACT,1.0	CHEMBL3661096,TN,INACT,0.0	CHEMBL3700905,TP,ACT,1.0	CHEMBL1922130,TP,ACT,1.0	CHEMBL1555581,TN,INACT,0.0	CHEMBL2163611,FP,INACT,0.949999988079071	CHEMBL2177686,TN,INACT,0.0	CHEMBL68418,TN,INACT,0.0	CHEMBL3629604,TN,INACT,0.0	CHEMBL450383,TN,INACT,0.0	CHEMBL44,TN,INACT,0.019999999552965164	CHEMBL1682340,TP,ACT,1.0	CHEMBL1080286,TP,ACT,1.0	CHEMBL2332096,FN,ACT,0.019999999552965164	CHEMBL86795,TN,INACT,0.11999999731779099	CHEMBL3689390,TP,ACT,0.9900000095367432	CHEMBL2158866,TN,INACT,0.0	CHEMBL522579,TN,INACT,0.0	CHEMBL3689505,TP,ACT,1.0	CHEMBL3410038,TP,ACT,0.9900000095367432	CHEMBL1077598,TP,ACT,0.6000000238418579	CHEMBL247911,TN,INACT,0.009999999776482582	CHEMBL296586,TN,INACT,0.0	CHEMBL1081182,TP,ACT,0.9700000286102295	CHEMBL3700970,TP,ACT,1.0	CHEMBL3689436,TP,ACT,1.0	CHEMBL3691660,TN,INACT,0.0	CHEMBL2440737,TP,ACT,0.9300000071525574	CHEMBL3689492,TP,ACT,1.0	CHEMBL3680700,TP,ACT,1.0	CHEMBL395665,TN,INACT,0.0	CHEMBL3680720,TP,ACT,1.0	CHEMBL3629607,TN,INACT,0.0	CHEMBL3689446,TP,ACT,1.0	CHEMBL1370293,TN,INACT,0.0	CHEMBL3793245,TP,ACT,0.9900000095367432	CHEMBL3680746,TP,ACT,1.0	CHEMBL1084892,TP,ACT,0.8999999761581421	CHEMBL590313,TP,ACT,0.9200000166893005	CHEMBL3609656,TN,INACT,0.0	CHEMBL3809901,TN,INACT,0.009999999776482582	CHEMBL2333895,FN,ACT,0.019999999552965164	CHEMBL3629280,TP,ACT,0.9900000095367432	CHEMBL3639795,TP,ACT,1.0	CHEMBL3689379,TP,ACT,1.0	CHEMBL316887,TN,INACT,0.009999999776482582	CHEMBL183024,TN,INACT,0.0	CHEMBL1379677,TN,INACT,0.0	CHEMBL3238167,TP,ACT,1.0	CHEMBL1923171,TP,ACT,1.0	CHEMBL1923164,TP,ACT,1.0	CHEMBL3402462,TP,ACT,1.0	

