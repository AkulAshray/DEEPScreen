ImageNetInceptionV2 CHEMBL4124 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	1474
Number of inactive compounds :	1474
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4124_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4124_adam_0.0005_15_0.6/
---------------------------------
Training samples: 1856
Validation samples: 580
--
Training Step: 1  | time: 67.263s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1856
[A[ATraining Step: 2  | total loss: [1m[32m0.65933[0m[0m | time: 86.405s
[2K
| Adam | epoch: 001 | loss: 0.65933 - acc: 0.3937 -- iter: 0064/1856
[A[ATraining Step: 3  | total loss: [1m[32m0.62812[0m[0m | time: 105.206s
[2K
| Adam | epoch: 001 | loss: 0.62812 - acc: 0.6341 -- iter: 0096/1856
[A[ATraining Step: 4  | total loss: [1m[32m0.49686[0m[0m | time: 123.820s
[2K
| Adam | epoch: 001 | loss: 0.49686 - acc: 0.7913 -- iter: 0128/1856
[A[ATraining Step: 5  | total loss: [1m[32m0.52910[0m[0m | time: 141.653s
[2K
| Adam | epoch: 001 | loss: 0.52910 - acc: 0.7627 -- iter: 0160/1856
[A[ATraining Step: 6  | total loss: [1m[32m0.45553[0m[0m | time: 161.801s
[2K
| Adam | epoch: 001 | loss: 0.45553 - acc: 0.7947 -- iter: 0192/1856
[A[ATraining Step: 7  | total loss: [1m[32m0.57337[0m[0m | time: 176.514s
[2K
| Adam | epoch: 001 | loss: 0.57337 - acc: 0.7679 -- iter: 0224/1856
[A[ATraining Step: 8  | total loss: [1m[32m0.47655[0m[0m | time: 189.800s
[2K
| Adam | epoch: 001 | loss: 0.47655 - acc: 0.7930 -- iter: 0256/1856
[A[ATraining Step: 9  | total loss: [1m[32m0.42132[0m[0m | time: 208.320s
[2K
| Adam | epoch: 001 | loss: 0.42132 - acc: 0.8364 -- iter: 0288/1856
[A[ATraining Step: 10  | total loss: [1m[32m0.54165[0m[0m | time: 224.144s
[2K
| Adam | epoch: 001 | loss: 0.54165 - acc: 0.7620 -- iter: 0320/1856
[A[ATraining Step: 11  | total loss: [1m[32m0.55898[0m[0m | time: 242.080s
[2K
| Adam | epoch: 001 | loss: 0.55898 - acc: 0.7563 -- iter: 0352/1856
[A[ATraining Step: 12  | total loss: [1m[32m0.54393[0m[0m | time: 258.863s
[2K
| Adam | epoch: 001 | loss: 0.54393 - acc: 0.7394 -- iter: 0384/1856
[A[ATraining Step: 13  | total loss: [1m[32m0.49538[0m[0m | time: 276.409s
[2K
| Adam | epoch: 001 | loss: 0.49538 - acc: 0.7975 -- iter: 0416/1856
[A[ATraining Step: 14  | total loss: [1m[32m0.51859[0m[0m | time: 293.526s
[2K
| Adam | epoch: 001 | loss: 0.51859 - acc: 0.7653 -- iter: 0448/1856
[A[ATraining Step: 15  | total loss: [1m[32m0.60884[0m[0m | time: 311.147s
[2K
| Adam | epoch: 001 | loss: 0.60884 - acc: 0.7226 -- iter: 0480/1856
[A[ATraining Step: 16  | total loss: [1m[32m0.55896[0m[0m | time: 329.474s
[2K
| Adam | epoch: 001 | loss: 0.55896 - acc: 0.7446 -- iter: 0512/1856
[A[ATraining Step: 17  | total loss: [1m[32m0.47431[0m[0m | time: 349.850s
[2K
| Adam | epoch: 001 | loss: 0.47431 - acc: 0.8028 -- iter: 0544/1856
[A[ATraining Step: 18  | total loss: [1m[32m0.48272[0m[0m | time: 374.723s
[2K
| Adam | epoch: 001 | loss: 0.48272 - acc: 0.8062 -- iter: 0576/1856
[A[ATraining Step: 19  | total loss: [1m[32m0.46936[0m[0m | time: 390.100s
[2K
| Adam | epoch: 001 | loss: 0.46936 - acc: 0.7979 -- iter: 0608/1856
[A[ATraining Step: 20  | total loss: [1m[32m0.45079[0m[0m | time: 407.118s
[2K
| Adam | epoch: 001 | loss: 0.45079 - acc: 0.8126 -- iter: 0640/1856
[A[ATraining Step: 21  | total loss: [1m[32m0.45943[0m[0m | time: 423.566s
[2K
| Adam | epoch: 001 | loss: 0.45943 - acc: 0.7932 -- iter: 0672/1856
[A[ATraining Step: 22  | total loss: [1m[32m0.42991[0m[0m | time: 440.020s
[2K
| Adam | epoch: 001 | loss: 0.42991 - acc: 0.8177 -- iter: 0704/1856
[A[ATraining Step: 23  | total loss: [1m[32m0.40448[0m[0m | time: 457.714s
[2K
| Adam | epoch: 001 | loss: 0.40448 - acc: 0.8344 -- iter: 0736/1856
[A[ATraining Step: 24  | total loss: [1m[32m0.36432[0m[0m | time: 475.278s
[2K
| Adam | epoch: 001 | loss: 0.36432 - acc: 0.8546 -- iter: 0768/1856
[A[ATraining Step: 25  | total loss: [1m[32m0.37162[0m[0m | time: 492.203s
[2K
| Adam | epoch: 001 | loss: 0.37162 - acc: 0.8431 -- iter: 0800/1856
[A[ATraining Step: 26  | total loss: [1m[32m0.41273[0m[0m | time: 512.643s
[2K
| Adam | epoch: 001 | loss: 0.41273 - acc: 0.8350 -- iter: 0832/1856
[A[ATraining Step: 27  | total loss: [1m[32m0.51246[0m[0m | time: 531.739s
[2K
| Adam | epoch: 001 | loss: 0.51246 - acc: 0.8212 -- iter: 0864/1856
[A[ATraining Step: 28  | total loss: [1m[32m0.48056[0m[0m | time: 545.610s
[2K
| Adam | epoch: 001 | loss: 0.48056 - acc: 0.8190 -- iter: 0896/1856
[A[ATraining Step: 29  | total loss: [1m[32m0.40066[0m[0m | time: 557.769s
[2K
| Adam | epoch: 001 | loss: 0.40066 - acc: 0.8630 -- iter: 0928/1856
[A[ATraining Step: 30  | total loss: [1m[32m0.37374[0m[0m | time: 571.664s
[2K
| Adam | epoch: 001 | loss: 0.37374 - acc: 0.8659 -- iter: 0960/1856
[A[ATraining Step: 31  | total loss: [1m[32m0.34868[0m[0m | time: 589.281s
[2K
| Adam | epoch: 001 | loss: 0.34868 - acc: 0.8680 -- iter: 0992/1856
[A[ATraining Step: 32  | total loss: [1m[32m0.32704[0m[0m | time: 605.790s
[2K
| Adam | epoch: 001 | loss: 0.32704 - acc: 0.8766 -- iter: 1024/1856
[A[ATraining Step: 33  | total loss: [1m[32m0.32154[0m[0m | time: 622.882s
[2K
| Adam | epoch: 001 | loss: 0.32154 - acc: 0.8694 -- iter: 1056/1856
[A[ATraining Step: 34  | total loss: [1m[32m0.26698[0m[0m | time: 638.816s
[2K
| Adam | epoch: 001 | loss: 0.26698 - acc: 0.8974 -- iter: 1088/1856
[A[ATraining Step: 35  | total loss: [1m[32m0.22866[0m[0m | time: 657.092s
[2K
| Adam | epoch: 001 | loss: 0.22866 - acc: 0.9188 -- iter: 1120/1856
[A[ATraining Step: 36  | total loss: [1m[32m0.28364[0m[0m | time: 674.007s
[2K
| Adam | epoch: 001 | loss: 0.28364 - acc: 0.8843 -- iter: 1152/1856
[A[ATraining Step: 37  | total loss: [1m[32m0.30707[0m[0m | time: 690.964s
[2K
| Adam | epoch: 001 | loss: 0.30707 - acc: 0.8824 -- iter: 1184/1856
[A[ATraining Step: 38  | total loss: [1m[32m0.30786[0m[0m | time: 707.774s
[2K
| Adam | epoch: 001 | loss: 0.30786 - acc: 0.8749 -- iter: 1216/1856
[A[ATraining Step: 39  | total loss: [1m[32m0.28174[0m[0m | time: 724.849s
[2K
| Adam | epoch: 001 | loss: 0.28174 - acc: 0.8749 -- iter: 1248/1856
[A[ATraining Step: 40  | total loss: [1m[32m0.31636[0m[0m | time: 737.032s
[2K
| Adam | epoch: 001 | loss: 0.31636 - acc: 0.8573 -- iter: 1280/1856
[A[ATraining Step: 41  | total loss: [1m[32m0.31850[0m[0m | time: 750.139s
[2K
| Adam | epoch: 001 | loss: 0.31850 - acc: 0.8548 -- iter: 1312/1856
[A[ATraining Step: 42  | total loss: [1m[32m0.31200[0m[0m | time: 772.449s
[2K
| Adam | epoch: 001 | loss: 0.31200 - acc: 0.8641 -- iter: 1344/1856
[A[ATraining Step: 43  | total loss: [1m[32m0.36849[0m[0m | time: 789.543s
[2K
| Adam | epoch: 001 | loss: 0.36849 - acc: 0.8495 -- iter: 1376/1856
[A[ATraining Step: 44  | total loss: [1m[32m0.38204[0m[0m | time: 806.263s
[2K
| Adam | epoch: 001 | loss: 0.38204 - acc: 0.8323 -- iter: 1408/1856
[A[ATraining Step: 45  | total loss: [1m[32m0.36156[0m[0m | time: 823.965s
[2K
| Adam | epoch: 001 | loss: 0.36156 - acc: 0.8448 -- iter: 1440/1856
[A[ATraining Step: 46  | total loss: [1m[32m0.37950[0m[0m | time: 839.149s
[2K
| Adam | epoch: 001 | loss: 0.37950 - acc: 0.8290 -- iter: 1472/1856
[A[ATraining Step: 47  | total loss: [1m[32m0.39405[0m[0m | time: 855.767s
[2K
| Adam | epoch: 001 | loss: 0.39405 - acc: 0.8212 -- iter: 1504/1856
[A[ATraining Step: 48  | total loss: [1m[32m0.37613[0m[0m | time: 873.296s
[2K
| Adam | epoch: 001 | loss: 0.37613 - acc: 0.8298 -- iter: 1536/1856
[A[ATraining Step: 49  | total loss: [1m[32m0.36842[0m[0m | time: 889.994s
[2K
| Adam | epoch: 001 | loss: 0.36842 - acc: 0.8320 -- iter: 1568/1856
[A[ATraining Step: 50  | total loss: [1m[32m0.32958[0m[0m | time: 906.521s
[2K
| Adam | epoch: 001 | loss: 0.32958 - acc: 0.8581 -- iter: 1600/1856
[A[ATraining Step: 51  | total loss: [1m[32m0.32149[0m[0m | time: 918.878s
[2K
| Adam | epoch: 001 | loss: 0.32149 - acc: 0.8702 -- iter: 1632/1856
[A[ATraining Step: 52  | total loss: [1m[32m0.28979[0m[0m | time: 931.073s
[2K
| Adam | epoch: 001 | loss: 0.28979 - acc: 0.8850 -- iter: 1664/1856
[A[ATraining Step: 53  | total loss: [1m[32m0.28804[0m[0m | time: 949.570s
[2K
| Adam | epoch: 001 | loss: 0.28804 - acc: 0.8789 -- iter: 1696/1856
[A[ATraining Step: 54  | total loss: [1m[32m0.30730[0m[0m | time: 966.729s
[2K
| Adam | epoch: 001 | loss: 0.30730 - acc: 0.8738 -- iter: 1728/1856
[A[ATraining Step: 55  | total loss: [1m[32m0.31334[0m[0m | time: 983.592s
[2K
| Adam | epoch: 001 | loss: 0.31334 - acc: 0.8695 -- iter: 1760/1856
[A[ATraining Step: 56  | total loss: [1m[32m0.33151[0m[0m | time: 1001.135s
[2K
| Adam | epoch: 001 | loss: 0.33151 - acc: 0.8615 -- iter: 1792/1856
[A[ATraining Step: 57  | total loss: [1m[32m0.33157[0m[0m | time: 1017.909s
[2K
| Adam | epoch: 001 | loss: 0.33157 - acc: 0.8634 -- iter: 1824/1856
[A[ATraining Step: 58  | total loss: [1m[32m0.32741[0m[0m | time: 1099.124s
[2K
| Adam | epoch: 001 | loss: 0.32741 - acc: 0.8650 | val_loss: 2.64477 - val_acc: 0.5017 -- iter: 1856/1856
--
Training Step: 59  | total loss: [1m[32m0.30408[0m[0m | time: 13.884s
[2K
| Adam | epoch: 002 | loss: 0.30408 - acc: 0.8747 -- iter: 0032/1856
[A[ATraining Step: 60  | total loss: [1m[32m0.27594[0m[0m | time: 26.228s
[2K
| Adam | epoch: 002 | loss: 0.27594 - acc: 0.8913 -- iter: 0064/1856
[A[ATraining Step: 61  | total loss: [1m[32m0.28717[0m[0m | time: 39.847s
[2K
| Adam | epoch: 002 | loss: 0.28717 - acc: 0.8851 -- iter: 0096/1856
[A[ATraining Step: 62  | total loss: [1m[32m0.28799[0m[0m | time: 56.765s
[2K
| Adam | epoch: 002 | loss: 0.28799 - acc: 0.8798 -- iter: 0128/1856
[A[ATraining Step: 63  | total loss: [1m[32m0.32275[0m[0m | time: 72.046s
[2K
| Adam | epoch: 002 | loss: 0.32275 - acc: 0.8594 -- iter: 0160/1856
[A[ATraining Step: 64  | total loss: [1m[32m0.32324[0m[0m | time: 109.295s
[2K
| Adam | epoch: 002 | loss: 0.32324 - acc: 0.8574 -- iter: 0192/1856
[A[ATraining Step: 65  | total loss: [1m[32m0.31302[0m[0m | time: 125.308s
[2K
| Adam | epoch: 002 | loss: 0.31302 - acc: 0.8596 -- iter: 0224/1856
[A[ATraining Step: 66  | total loss: [1m[32m0.30648[0m[0m | time: 137.144s
[2K
| Adam | epoch: 002 | loss: 0.30648 - acc: 0.8577 -- iter: 0256/1856
[A[ATraining Step: 67  | total loss: [1m[32m0.30806[0m[0m | time: 149.876s
[2K
| Adam | epoch: 002 | loss: 0.30806 - acc: 0.8597 -- iter: 0288/1856
[A[ATraining Step: 68  | total loss: [1m[32m0.30365[0m[0m | time: 166.147s
[2K
| Adam | epoch: 002 | loss: 0.30365 - acc: 0.8615 -- iter: 0320/1856
[A[ATraining Step: 69  | total loss: [1m[32m0.32140[0m[0m | time: 183.899s
[2K
| Adam | epoch: 002 | loss: 0.32140 - acc: 0.8485 -- iter: 0352/1856
[A[ATraining Step: 70  | total loss: [1m[32m0.32753[0m[0m | time: 202.424s
[2K
| Adam | epoch: 002 | loss: 0.32753 - acc: 0.8516 -- iter: 0384/1856
[A[ATraining Step: 71  | total loss: [1m[32m0.33590[0m[0m | time: 219.527s
[2K
| Adam | epoch: 002 | loss: 0.33590 - acc: 0.8364 -- iter: 0416/1856
[A[ATraining Step: 72  | total loss: [1m[32m0.38813[0m[0m | time: 236.317s
[2K
| Adam | epoch: 002 | loss: 0.38813 - acc: 0.8162 -- iter: 0448/1856
[A[ATraining Step: 73  | total loss: [1m[32m0.39612[0m[0m | time: 253.404s
[2K
| Adam | epoch: 002 | loss: 0.39612 - acc: 0.8088 -- iter: 0480/1856
[A[ATraining Step: 74  | total loss: [1m[32m0.38799[0m[0m | time: 270.527s
[2K
| Adam | epoch: 002 | loss: 0.38799 - acc: 0.8195 -- iter: 0512/1856
[A[ATraining Step: 75  | total loss: [1m[32m0.36779[0m[0m | time: 286.537s
[2K
| Adam | epoch: 002 | loss: 0.36779 - acc: 0.8289 -- iter: 0544/1856
[A[ATraining Step: 76  | total loss: [1m[32m0.36721[0m[0m | time: 302.756s
[2K
| Adam | epoch: 002 | loss: 0.36721 - acc: 0.8338 -- iter: 0576/1856
[A[ATraining Step: 77  | total loss: [1m[32m0.35316[0m[0m | time: 315.080s
[2K
| Adam | epoch: 002 | loss: 0.35316 - acc: 0.8382 -- iter: 0608/1856
[A[ATraining Step: 78  | total loss: [1m[32m0.35255[0m[0m | time: 327.439s
[2K
| Adam | epoch: 002 | loss: 0.35255 - acc: 0.8355 -- iter: 0640/1856
[A[ATraining Step: 79  | total loss: [1m[32m0.35893[0m[0m | time: 341.086s
[2K
| Adam | epoch: 002 | loss: 0.35893 - acc: 0.8364 -- iter: 0672/1856
[A[ATraining Step: 80  | total loss: [1m[32m0.34592[0m[0m | time: 357.785s
[2K
| Adam | epoch: 002 | loss: 0.34592 - acc: 0.8467 -- iter: 0704/1856
[A[ATraining Step: 81  | total loss: [1m[32m0.34040[0m[0m | time: 369.698s
[2K
| Adam | epoch: 002 | loss: 0.34040 - acc: 0.8496 -- iter: 0736/1856
[A[ATraining Step: 82  | total loss: [1m[32m0.33674[0m[0m | time: 381.488s
[2K
| Adam | epoch: 002 | loss: 0.33674 - acc: 0.8552 -- iter: 0768/1856
[A[ATraining Step: 83  | total loss: [1m[32m0.32149[0m[0m | time: 393.308s
[2K
| Adam | epoch: 002 | loss: 0.32149 - acc: 0.8603 -- iter: 0800/1856
[A[ATraining Step: 84  | total loss: [1m[32m0.31766[0m[0m | time: 404.720s
[2K
| Adam | epoch: 002 | loss: 0.31766 - acc: 0.8587 -- iter: 0832/1856
[A[ATraining Step: 85  | total loss: [1m[32m0.31270[0m[0m | time: 416.753s
[2K
| Adam | epoch: 002 | loss: 0.31270 - acc: 0.8603 -- iter: 0864/1856
[A[ATraining Step: 86  | total loss: [1m[32m0.31439[0m[0m | time: 428.497s
[2K
| Adam | epoch: 002 | loss: 0.31439 - acc: 0.8587 -- iter: 0896/1856
[A[ATraining Step: 87  | total loss: [1m[32m0.29267[0m[0m | time: 440.613s
[2K
| Adam | epoch: 002 | loss: 0.29267 - acc: 0.8697 -- iter: 0928/1856
[A[ATraining Step: 88  | total loss: [1m[32m0.28468[0m[0m | time: 452.220s
[2K
| Adam | epoch: 002 | loss: 0.28468 - acc: 0.8764 -- iter: 0960/1856
[A[ATraining Step: 89  | total loss: [1m[32m0.26545[0m[0m | time: 464.101s
[2K
| Adam | epoch: 002 | loss: 0.26545 - acc: 0.8888 -- iter: 0992/1856
[A[ATraining Step: 90  | total loss: [1m[32m0.24687[0m[0m | time: 475.530s
[2K
| Adam | epoch: 002 | loss: 0.24687 - acc: 0.8968 -- iter: 1024/1856
[A[ATraining Step: 91  | total loss: [1m[32m0.25339[0m[0m | time: 487.098s
[2K
| Adam | epoch: 002 | loss: 0.25339 - acc: 0.8977 -- iter: 1056/1856
[A[ATraining Step: 92  | total loss: [1m[32m0.25761[0m[0m | time: 498.557s
[2K
| Adam | epoch: 002 | loss: 0.25761 - acc: 0.9017 -- iter: 1088/1856
[A[ATraining Step: 93  | total loss: [1m[32m0.28012[0m[0m | time: 509.910s
[2K
| Adam | epoch: 002 | loss: 0.28012 - acc: 0.8928 -- iter: 1120/1856
[A[ATraining Step: 94  | total loss: [1m[32m0.27852[0m[0m | time: 521.868s
[2K
| Adam | epoch: 002 | loss: 0.27852 - acc: 0.8941 -- iter: 1152/1856
[A[ATraining Step: 95  | total loss: [1m[32m0.26710[0m[0m | time: 533.996s
[2K
| Adam | epoch: 002 | loss: 0.26710 - acc: 0.8922 -- iter: 1184/1856
[A[ATraining Step: 96  | total loss: [1m[32m0.25075[0m[0m | time: 545.868s
[2K
| Adam | epoch: 002 | loss: 0.25075 - acc: 0.8999 -- iter: 1216/1856
[A[ATraining Step: 97  | total loss: [1m[32m0.24033[0m[0m | time: 557.755s
[2K
| Adam | epoch: 002 | loss: 0.24033 - acc: 0.9068 -- iter: 1248/1856
[A[ATraining Step: 98  | total loss: [1m[32m0.23766[0m[0m | time: 569.493s
[2K
| Adam | epoch: 002 | loss: 0.23766 - acc: 0.9067 -- iter: 1280/1856
[A[ATraining Step: 99  | total loss: [1m[32m0.22195[0m[0m | time: 581.373s
[2K
| Adam | epoch: 002 | loss: 0.22195 - acc: 0.9160 -- iter: 1312/1856
[A[ATraining Step: 100  | total loss: [1m[32m0.20678[0m[0m | time: 593.285s
[2K
| Adam | epoch: 002 | loss: 0.20678 - acc: 0.9244 -- iter: 1344/1856
[A[ATraining Step: 101  | total loss: [1m[32m0.20135[0m[0m | time: 604.970s
[2K
| Adam | epoch: 002 | loss: 0.20135 - acc: 0.9289 -- iter: 1376/1856
[A[ATraining Step: 102  | total loss: [1m[32m0.21239[0m[0m | time: 616.796s
[2K
| Adam | epoch: 002 | loss: 0.21239 - acc: 0.9235 -- iter: 1408/1856
[A[ATraining Step: 103  | total loss: [1m[32m0.22501[0m[0m | time: 628.767s
[2K
| Adam | epoch: 002 | loss: 0.22501 - acc: 0.9218 -- iter: 1440/1856
[A[ATraining Step: 104  | total loss: [1m[32m0.22408[0m[0m | time: 640.934s
[2K
| Adam | epoch: 002 | loss: 0.22408 - acc: 0.9202 -- iter: 1472/1856
[A[ATraining Step: 105  | total loss: [1m[32m0.22269[0m[0m | time: 652.834s
[2K
| Adam | epoch: 002 | loss: 0.22269 - acc: 0.9219 -- iter: 1504/1856
[A[ATraining Step: 106  | total loss: [1m[32m0.24454[0m[0m | time: 665.154s
[2K
| Adam | epoch: 002 | loss: 0.24454 - acc: 0.9204 -- iter: 1536/1856
[A[ATraining Step: 107  | total loss: [1m[32m0.25181[0m[0m | time: 676.886s
[2K
| Adam | epoch: 002 | loss: 0.25181 - acc: 0.9190 -- iter: 1568/1856
[A[ATraining Step: 108  | total loss: [1m[32m0.24053[0m[0m | time: 688.769s
[2K
| Adam | epoch: 002 | loss: 0.24053 - acc: 0.9239 -- iter: 1600/1856
[A[ATraining Step: 109  | total loss: [1m[32m0.23616[0m[0m | time: 700.846s
[2K
| Adam | epoch: 002 | loss: 0.23616 - acc: 0.9253 -- iter: 1632/1856
[A[ATraining Step: 110  | total loss: [1m[32m0.23577[0m[0m | time: 712.338s
[2K
| Adam | epoch: 002 | loss: 0.23577 - acc: 0.9203 -- iter: 1664/1856
[A[ATraining Step: 111  | total loss: [1m[32m0.22911[0m[0m | time: 723.867s
[2K
| Adam | epoch: 002 | loss: 0.22911 - acc: 0.9220 -- iter: 1696/1856
[A[ATraining Step: 112  | total loss: [1m[32m0.22690[0m[0m | time: 735.762s
[2K
| Adam | epoch: 002 | loss: 0.22690 - acc: 0.9204 -- iter: 1728/1856
[A[ATraining Step: 113  | total loss: [1m[32m0.23536[0m[0m | time: 747.847s
[2K
| Adam | epoch: 002 | loss: 0.23536 - acc: 0.9190 -- iter: 1760/1856
[A[ATraining Step: 114  | total loss: [1m[32m0.22627[0m[0m | time: 759.618s
[2K
| Adam | epoch: 002 | loss: 0.22627 - acc: 0.9177 -- iter: 1792/1856
[A[ATraining Step: 115  | total loss: [1m[32m0.22789[0m[0m | time: 771.703s
[2K
| Adam | epoch: 002 | loss: 0.22789 - acc: 0.9166 -- iter: 1824/1856
[A[ATraining Step: 116  | total loss: [1m[32m0.24038[0m[0m | time: 824.382s
[2K
| Adam | epoch: 002 | loss: 0.24038 - acc: 0.9093 | val_loss: 1.07355 - val_acc: 0.6328 -- iter: 1856/1856
--
Training Step: 117  | total loss: [1m[32m0.23873[0m[0m | time: 11.929s
[2K
| Adam | epoch: 003 | loss: 0.23873 - acc: 0.9059 -- iter: 0032/1856
[A[ATraining Step: 118  | total loss: [1m[32m0.22974[0m[0m | time: 24.161s
[2K
| Adam | epoch: 003 | loss: 0.22974 - acc: 0.9122 -- iter: 0064/1856
[A[ATraining Step: 119  | total loss: [1m[32m0.21845[0m[0m | time: 36.526s
[2K
| Adam | epoch: 003 | loss: 0.21845 - acc: 0.9178 -- iter: 0096/1856
[A[ATraining Step: 120  | total loss: [1m[32m0.23152[0m[0m | time: 49.607s
[2K
| Adam | epoch: 003 | loss: 0.23152 - acc: 0.9167 -- iter: 0128/1856
[A[ATraining Step: 121  | total loss: [1m[32m0.23638[0m[0m | time: 62.108s
[2K
| Adam | epoch: 003 | loss: 0.23638 - acc: 0.9125 -- iter: 0160/1856
[A[ATraining Step: 122  | total loss: [1m[32m0.23429[0m[0m | time: 75.033s
[2K
| Adam | epoch: 003 | loss: 0.23429 - acc: 0.9150 -- iter: 0192/1856
[A[ATraining Step: 123  | total loss: [1m[32m0.22507[0m[0m | time: 83.483s
[2K
| Adam | epoch: 003 | loss: 0.22507 - acc: 0.9204 -- iter: 0224/1856
[A[ATraining Step: 124  | total loss: [1m[32m0.23275[0m[0m | time: 91.501s
[2K
| Adam | epoch: 003 | loss: 0.23275 - acc: 0.9158 -- iter: 0256/1856
[A[ATraining Step: 125  | total loss: [1m[32m0.24243[0m[0m | time: 100.174s
[2K
| Adam | epoch: 003 | loss: 0.24243 - acc: 0.9086 -- iter: 0288/1856
[A[ATraining Step: 126  | total loss: [1m[32m0.24954[0m[0m | time: 112.149s
[2K
| Adam | epoch: 003 | loss: 0.24954 - acc: 0.9021 -- iter: 0320/1856
[A[ATraining Step: 127  | total loss: [1m[32m0.25592[0m[0m | time: 124.296s
[2K
| Adam | epoch: 003 | loss: 0.25592 - acc: 0.9025 -- iter: 0352/1856
[A[ATraining Step: 128  | total loss: [1m[32m0.24528[0m[0m | time: 136.313s
[2K
| Adam | epoch: 003 | loss: 0.24528 - acc: 0.9029 -- iter: 0384/1856
[A[ATraining Step: 129  | total loss: [1m[32m0.24418[0m[0m | time: 148.392s
[2K
| Adam | epoch: 003 | loss: 0.24418 - acc: 0.9064 -- iter: 0416/1856
[A[ATraining Step: 130  | total loss: [1m[32m0.23824[0m[0m | time: 160.417s
[2K
| Adam | epoch: 003 | loss: 0.23824 - acc: 0.9126 -- iter: 0448/1856
[A[ATraining Step: 131  | total loss: [1m[32m0.23813[0m[0m | time: 172.819s
[2K
| Adam | epoch: 003 | loss: 0.23813 - acc: 0.9089 -- iter: 0480/1856
[A[ATraining Step: 132  | total loss: [1m[32m0.23358[0m[0m | time: 184.934s
[2K
| Adam | epoch: 003 | loss: 0.23358 - acc: 0.9148 -- iter: 0512/1856
[A[ATraining Step: 133  | total loss: [1m[32m0.22368[0m[0m | time: 196.720s
[2K
| Adam | epoch: 003 | loss: 0.22368 - acc: 0.9202 -- iter: 0544/1856
[A[ATraining Step: 134  | total loss: [1m[32m0.22161[0m[0m | time: 207.994s
[2K
| Adam | epoch: 003 | loss: 0.22161 - acc: 0.9188 -- iter: 0576/1856
[A[ATraining Step: 135  | total loss: [1m[32m0.20754[0m[0m | time: 219.755s
[2K
| Adam | epoch: 003 | loss: 0.20754 - acc: 0.9270 -- iter: 0608/1856
[A[ATraining Step: 136  | total loss: [1m[32m0.20732[0m[0m | time: 231.745s
[2K
| Adam | epoch: 003 | loss: 0.20732 - acc: 0.9249 -- iter: 0640/1856
[A[ATraining Step: 137  | total loss: [1m[32m0.20573[0m[0m | time: 243.881s
[2K
| Adam | epoch: 003 | loss: 0.20573 - acc: 0.9261 -- iter: 0672/1856
[A[ATraining Step: 138  | total loss: [1m[32m0.19711[0m[0m | time: 255.777s
[2K
| Adam | epoch: 003 | loss: 0.19711 - acc: 0.9304 -- iter: 0704/1856
[A[ATraining Step: 139  | total loss: [1m[32m0.19548[0m[0m | time: 268.016s
[2K
| Adam | epoch: 003 | loss: 0.19548 - acc: 0.9311 -- iter: 0736/1856
[A[ATraining Step: 140  | total loss: [1m[32m0.19152[0m[0m | time: 280.322s
[2K
| Adam | epoch: 003 | loss: 0.19152 - acc: 0.9349 -- iter: 0768/1856
[A[ATraining Step: 141  | total loss: [1m[32m0.19652[0m[0m | time: 292.647s
[2K
| Adam | epoch: 003 | loss: 0.19652 - acc: 0.9289 -- iter: 0800/1856
[A[ATraining Step: 142  | total loss: [1m[32m0.20996[0m[0m | time: 304.905s
[2K
| Adam | epoch: 003 | loss: 0.20996 - acc: 0.9173 -- iter: 0832/1856
[A[ATraining Step: 143  | total loss: [1m[32m0.19512[0m[0m | time: 316.695s
[2K
| Adam | epoch: 003 | loss: 0.19512 - acc: 0.9255 -- iter: 0864/1856
[A[ATraining Step: 144  | total loss: [1m[32m0.20730[0m[0m | time: 328.889s
[2K
| Adam | epoch: 003 | loss: 0.20730 - acc: 0.9267 -- iter: 0896/1856
[A[ATraining Step: 145  | total loss: [1m[32m0.21144[0m[0m | time: 341.033s
[2K
| Adam | epoch: 003 | loss: 0.21144 - acc: 0.9247 -- iter: 0928/1856
[A[ATraining Step: 146  | total loss: [1m[32m0.20274[0m[0m | time: 353.004s
[2K
| Adam | epoch: 003 | loss: 0.20274 - acc: 0.9291 -- iter: 0960/1856
[A[ATraining Step: 147  | total loss: [1m[32m0.18799[0m[0m | time: 364.882s
[2K
| Adam | epoch: 003 | loss: 0.18799 - acc: 0.9362 -- iter: 0992/1856
[A[ATraining Step: 148  | total loss: [1m[32m0.20890[0m[0m | time: 376.698s
[2K
| Adam | epoch: 003 | loss: 0.20890 - acc: 0.9269 -- iter: 1024/1856
[A[ATraining Step: 149  | total loss: [1m[32m0.20228[0m[0m | time: 389.043s
[2K
| Adam | epoch: 003 | loss: 0.20228 - acc: 0.9311 -- iter: 1056/1856
[A[ATraining Step: 150  | total loss: [1m[32m0.19735[0m[0m | time: 400.882s
[2K
| Adam | epoch: 003 | loss: 0.19735 - acc: 0.9349 -- iter: 1088/1856
[A[ATraining Step: 151  | total loss: [1m[32m0.19000[0m[0m | time: 412.765s
[2K
| Adam | epoch: 003 | loss: 0.19000 - acc: 0.9383 -- iter: 1120/1856
[A[ATraining Step: 152  | total loss: [1m[32m0.17958[0m[0m | time: 424.924s
[2K
| Adam | epoch: 003 | loss: 0.17958 - acc: 0.9413 -- iter: 1152/1856
[A[ATraining Step: 153  | total loss: [1m[32m0.17363[0m[0m | time: 436.611s
[2K
| Adam | epoch: 003 | loss: 0.17363 - acc: 0.9409 -- iter: 1184/1856
[A[ATraining Step: 154  | total loss: [1m[32m0.16628[0m[0m | time: 448.499s
[2K
| Adam | epoch: 003 | loss: 0.16628 - acc: 0.9437 -- iter: 1216/1856
[A[ATraining Step: 155  | total loss: [1m[32m0.16879[0m[0m | time: 460.417s
[2K
| Adam | epoch: 003 | loss: 0.16879 - acc: 0.9368 -- iter: 1248/1856
[A[ATraining Step: 156  | total loss: [1m[32m0.17760[0m[0m | time: 472.022s
[2K
| Adam | epoch: 003 | loss: 0.17760 - acc: 0.9307 -- iter: 1280/1856
[A[ATraining Step: 157  | total loss: [1m[32m0.16943[0m[0m | time: 483.782s
[2K
| Adam | epoch: 003 | loss: 0.16943 - acc: 0.9313 -- iter: 1312/1856
[A[ATraining Step: 158  | total loss: [1m[32m0.16074[0m[0m | time: 496.122s
[2K
| Adam | epoch: 003 | loss: 0.16074 - acc: 0.9351 -- iter: 1344/1856
[A[ATraining Step: 159  | total loss: [1m[32m0.17708[0m[0m | time: 508.311s
[2K
| Adam | epoch: 003 | loss: 0.17708 - acc: 0.9259 -- iter: 1376/1856
[A[ATraining Step: 160  | total loss: [1m[32m0.16178[0m[0m | time: 520.098s
[2K
| Adam | epoch: 003 | loss: 0.16178 - acc: 0.9334 -- iter: 1408/1856
[A[ATraining Step: 161  | total loss: [1m[32m0.16628[0m[0m | time: 532.356s
[2K
| Adam | epoch: 003 | loss: 0.16628 - acc: 0.9369 -- iter: 1440/1856
[A[ATraining Step: 162  | total loss: [1m[32m0.15352[0m[0m | time: 544.682s
[2K
| Adam | epoch: 003 | loss: 0.15352 - acc: 0.9432 -- iter: 1472/1856
[A[ATraining Step: 163  | total loss: [1m[32m0.14434[0m[0m | time: 556.386s
[2K
| Adam | epoch: 003 | loss: 0.14434 - acc: 0.9489 -- iter: 1504/1856
[A[ATraining Step: 164  | total loss: [1m[32m0.13315[0m[0m | time: 568.487s
[2K
| Adam | epoch: 003 | loss: 0.13315 - acc: 0.9540 -- iter: 1536/1856
[A[ATraining Step: 165  | total loss: [1m[32m0.13256[0m[0m | time: 580.325s
[2K
| Adam | epoch: 003 | loss: 0.13256 - acc: 0.9555 -- iter: 1568/1856
[A[ATraining Step: 166  | total loss: [1m[32m0.12317[0m[0m | time: 592.531s
[2K
| Adam | epoch: 003 | loss: 0.12317 - acc: 0.9599 -- iter: 1600/1856
[A[ATraining Step: 167  | total loss: [1m[32m0.12607[0m[0m | time: 604.606s
[2K
| Adam | epoch: 003 | loss: 0.12607 - acc: 0.9577 -- iter: 1632/1856
[A[ATraining Step: 168  | total loss: [1m[32m0.12508[0m[0m | time: 616.970s
[2K
| Adam | epoch: 003 | loss: 0.12508 - acc: 0.9588 -- iter: 1664/1856
[A[ATraining Step: 169  | total loss: [1m[32m0.13114[0m[0m | time: 629.274s
[2K
| Adam | epoch: 003 | loss: 0.13114 - acc: 0.9567 -- iter: 1696/1856
[A[ATraining Step: 170  | total loss: [1m[32m0.14139[0m[0m | time: 641.139s
[2K
| Adam | epoch: 003 | loss: 0.14139 - acc: 0.9454 -- iter: 1728/1856
[A[ATraining Step: 171  | total loss: [1m[32m0.13910[0m[0m | time: 653.120s
[2K
| Adam | epoch: 003 | loss: 0.13910 - acc: 0.9477 -- iter: 1760/1856
[A[ATraining Step: 172  | total loss: [1m[32m0.13328[0m[0m | time: 665.063s
[2K
| Adam | epoch: 003 | loss: 0.13328 - acc: 0.9498 -- iter: 1792/1856
[A[ATraining Step: 173  | total loss: [1m[32m0.14824[0m[0m | time: 677.446s
[2K
| Adam | epoch: 003 | loss: 0.14824 - acc: 0.9517 -- iter: 1824/1856
[A[ATraining Step: 174  | total loss: [1m[32m0.14088[0m[0m | time: 729.684s
[2K
| Adam | epoch: 003 | loss: 0.14088 - acc: 0.9534 | val_loss: 0.78510 - val_acc: 0.7655 -- iter: 1856/1856
--
Training Step: 175  | total loss: [1m[32m0.14718[0m[0m | time: 12.551s
[2K
| Adam | epoch: 004 | loss: 0.14718 - acc: 0.9456 -- iter: 0032/1856
[A[ATraining Step: 176  | total loss: [1m[32m0.18655[0m[0m | time: 24.587s
[2K
| Adam | epoch: 004 | loss: 0.18655 - acc: 0.9291 -- iter: 0064/1856
[A[ATraining Step: 177  | total loss: [1m[32m0.17024[0m[0m | time: 36.372s
[2K
| Adam | epoch: 004 | loss: 0.17024 - acc: 0.9362 -- iter: 0096/1856
[A[ATraining Step: 178  | total loss: [1m[32m0.15505[0m[0m | time: 48.575s
[2K
| Adam | epoch: 004 | loss: 0.15505 - acc: 0.9426 -- iter: 0128/1856
[A[ATraining Step: 179  | total loss: [1m[32m0.15269[0m[0m | time: 60.714s
[2K
| Adam | epoch: 004 | loss: 0.15269 - acc: 0.9390 -- iter: 0160/1856
[A[ATraining Step: 180  | total loss: [1m[32m0.15125[0m[0m | time: 73.035s
[2K
| Adam | epoch: 004 | loss: 0.15125 - acc: 0.9388 -- iter: 0192/1856
[A[ATraining Step: 181  | total loss: [1m[32m0.14188[0m[0m | time: 84.814s
[2K
| Adam | epoch: 004 | loss: 0.14188 - acc: 0.9418 -- iter: 0224/1856
[A[ATraining Step: 182  | total loss: [1m[32m0.13870[0m[0m | time: 96.727s
[2K
| Adam | epoch: 004 | loss: 0.13870 - acc: 0.9445 -- iter: 0256/1856
[A[ATraining Step: 183  | total loss: [1m[32m0.15520[0m[0m | time: 109.233s
[2K
| Adam | epoch: 004 | loss: 0.15520 - acc: 0.9407 -- iter: 0288/1856
[A[ATraining Step: 184  | total loss: [1m[32m0.14466[0m[0m | time: 122.129s
[2K
| Adam | epoch: 004 | loss: 0.14466 - acc: 0.9466 -- iter: 0320/1856
[A[ATraining Step: 185  | total loss: [1m[32m0.14957[0m[0m | time: 135.242s
[2K
| Adam | epoch: 004 | loss: 0.14957 - acc: 0.9426 -- iter: 0352/1856
[A[ATraining Step: 186  | total loss: [1m[32m0.14163[0m[0m | time: 147.091s
[2K
| Adam | epoch: 004 | loss: 0.14163 - acc: 0.9483 -- iter: 0384/1856
[A[ATraining Step: 187  | total loss: [1m[32m0.13146[0m[0m | time: 155.345s
[2K
| Adam | epoch: 004 | loss: 0.13146 - acc: 0.9535 -- iter: 0416/1856
[A[ATraining Step: 188  | total loss: [1m[32m0.14149[0m[0m | time: 163.301s
[2K
| Adam | epoch: 004 | loss: 0.14149 - acc: 0.9488 -- iter: 0448/1856
[A[ATraining Step: 189  | total loss: [1m[32m0.14559[0m[0m | time: 172.644s
[2K
| Adam | epoch: 004 | loss: 0.14559 - acc: 0.9445 -- iter: 0480/1856
[A[ATraining Step: 190  | total loss: [1m[32m0.13986[0m[0m | time: 184.516s
[2K
| Adam | epoch: 004 | loss: 0.13986 - acc: 0.9438 -- iter: 0512/1856
[A[ATraining Step: 191  | total loss: [1m[32m0.13400[0m[0m | time: 195.927s
[2K
| Adam | epoch: 004 | loss: 0.13400 - acc: 0.9463 -- iter: 0544/1856
[A[ATraining Step: 192  | total loss: [1m[32m0.12628[0m[0m | time: 207.729s
[2K
| Adam | epoch: 004 | loss: 0.12628 - acc: 0.9485 -- iter: 0576/1856
[A[ATraining Step: 193  | total loss: [1m[32m0.11668[0m[0m | time: 219.382s
[2K
| Adam | epoch: 004 | loss: 0.11668 - acc: 0.9537 -- iter: 0608/1856
[A[ATraining Step: 194  | total loss: [1m[32m0.12470[0m[0m | time: 231.388s
[2K
| Adam | epoch: 004 | loss: 0.12470 - acc: 0.9489 -- iter: 0640/1856
[A[ATraining Step: 195  | total loss: [1m[32m0.11894[0m[0m | time: 243.428s
[2K
| Adam | epoch: 004 | loss: 0.11894 - acc: 0.9541 -- iter: 0672/1856
[A[ATraining Step: 196  | total loss: [1m[32m0.13218[0m[0m | time: 255.187s
[2K
| Adam | epoch: 004 | loss: 0.13218 - acc: 0.9524 -- iter: 0704/1856
[A[ATraining Step: 197  | total loss: [1m[32m0.13338[0m[0m | time: 266.919s
[2K
| Adam | epoch: 004 | loss: 0.13338 - acc: 0.9509 -- iter: 0736/1856
[A[ATraining Step: 198  | total loss: [1m[32m0.12789[0m[0m | time: 278.876s
[2K
| Adam | epoch: 004 | loss: 0.12789 - acc: 0.9527 -- iter: 0768/1856
[A[ATraining Step: 199  | total loss: [1m[32m0.12198[0m[0m | time: 290.059s
[2K
| Adam | epoch: 004 | loss: 0.12198 - acc: 0.9574 -- iter: 0800/1856
[A[ATraining Step: 200  | total loss: [1m[32m0.11801[0m[0m | time: 342.551s
[2K
| Adam | epoch: 004 | loss: 0.11801 - acc: 0.9586 | val_loss: 0.35060 - val_acc: 0.8828 -- iter: 0832/1856
--
Training Step: 201  | total loss: [1m[32m0.12100[0m[0m | time: 354.774s
[2K
| Adam | epoch: 004 | loss: 0.12100 - acc: 0.9565 -- iter: 0864/1856
[A[ATraining Step: 202  | total loss: [1m[32m0.13204[0m[0m | time: 366.555s
[2K
| Adam | epoch: 004 | loss: 0.13204 - acc: 0.9546 -- iter: 0896/1856
[A[ATraining Step: 203  | total loss: [1m[32m0.14192[0m[0m | time: 377.960s
[2K
| Adam | epoch: 004 | loss: 0.14192 - acc: 0.9497 -- iter: 0928/1856
[A[ATraining Step: 204  | total loss: [1m[32m0.17338[0m[0m | time: 389.989s
[2K
| Adam | epoch: 004 | loss: 0.17338 - acc: 0.9454 -- iter: 0960/1856
[A[ATraining Step: 205  | total loss: [1m[32m0.16279[0m[0m | time: 401.739s
[2K
| Adam | epoch: 004 | loss: 0.16279 - acc: 0.9508 -- iter: 0992/1856
[A[ATraining Step: 206  | total loss: [1m[32m0.15377[0m[0m | time: 413.552s
[2K
| Adam | epoch: 004 | loss: 0.15377 - acc: 0.9526 -- iter: 1024/1856
[A[ATraining Step: 207  | total loss: [1m[32m0.14846[0m[0m | time: 425.390s
[2K
| Adam | epoch: 004 | loss: 0.14846 - acc: 0.9542 -- iter: 1056/1856
[A[ATraining Step: 208  | total loss: [1m[32m0.14584[0m[0m | time: 437.850s
[2K
| Adam | epoch: 004 | loss: 0.14584 - acc: 0.9526 -- iter: 1088/1856
[A[ATraining Step: 209  | total loss: [1m[32m0.13765[0m[0m | time: 449.716s
[2K
| Adam | epoch: 004 | loss: 0.13765 - acc: 0.9573 -- iter: 1120/1856
[A[ATraining Step: 210  | total loss: [1m[32m0.13985[0m[0m | time: 461.391s
[2K
| Adam | epoch: 004 | loss: 0.13985 - acc: 0.9553 -- iter: 1152/1856
[A[ATraining Step: 211  | total loss: [1m[32m0.14369[0m[0m | time: 473.390s
[2K
| Adam | epoch: 004 | loss: 0.14369 - acc: 0.9535 -- iter: 1184/1856
[A[ATraining Step: 212  | total loss: [1m[32m0.13878[0m[0m | time: 485.262s
[2K
| Adam | epoch: 004 | loss: 0.13878 - acc: 0.9551 -- iter: 1216/1856
[A[ATraining Step: 213  | total loss: [1m[32m0.13377[0m[0m | time: 497.123s
[2K
| Adam | epoch: 004 | loss: 0.13377 - acc: 0.9564 -- iter: 1248/1856
[A[ATraining Step: 214  | total loss: [1m[32m0.13536[0m[0m | time: 509.210s
[2K
| Adam | epoch: 004 | loss: 0.13536 - acc: 0.9545 -- iter: 1280/1856
[A[ATraining Step: 215  | total loss: [1m[32m0.12443[0m[0m | time: 521.340s
[2K
| Adam | epoch: 004 | loss: 0.12443 - acc: 0.9591 -- iter: 1312/1856
[A[ATraining Step: 216  | total loss: [1m[32m0.11979[0m[0m | time: 532.635s
[2K
| Adam | epoch: 004 | loss: 0.11979 - acc: 0.9601 -- iter: 1344/1856
[A[ATraining Step: 217  | total loss: [1m[32m0.11208[0m[0m | time: 545.559s
[2K
| Adam | epoch: 004 | loss: 0.11208 - acc: 0.9640 -- iter: 1376/1856
[A[ATraining Step: 218  | total loss: [1m[32m0.11974[0m[0m | time: 558.698s
[2K
| Adam | epoch: 004 | loss: 0.11974 - acc: 0.9645 -- iter: 1408/1856
[A[ATraining Step: 219  | total loss: [1m[32m0.12315[0m[0m | time: 571.560s
[2K
| Adam | epoch: 004 | loss: 0.12315 - acc: 0.9618 -- iter: 1440/1856
[A[ATraining Step: 220  | total loss: [1m[32m0.12716[0m[0m | time: 582.178s
[2K
| Adam | epoch: 004 | loss: 0.12716 - acc: 0.9563 -- iter: 1472/1856
[A[ATraining Step: 221  | total loss: [1m[32m0.11802[0m[0m | time: 590.233s
[2K
| Adam | epoch: 004 | loss: 0.11802 - acc: 0.9606 -- iter: 1504/1856
[A[ATraining Step: 222  | total loss: [1m[32m0.11251[0m[0m | time: 602.028s
[2K
| Adam | epoch: 004 | loss: 0.11251 - acc: 0.9646 -- iter: 1536/1856
[A[ATraining Step: 223  | total loss: [1m[32m0.11823[0m[0m | time: 614.037s
[2K
| Adam | epoch: 004 | loss: 0.11823 - acc: 0.9619 -- iter: 1568/1856
[A[ATraining Step: 224  | total loss: [1m[32m0.11014[0m[0m | time: 626.033s
[2K
| Adam | epoch: 004 | loss: 0.11014 - acc: 0.9657 -- iter: 1600/1856
[A[ATraining Step: 225  | total loss: [1m[32m0.10280[0m[0m | time: 637.925s
[2K
| Adam | epoch: 004 | loss: 0.10280 - acc: 0.9691 -- iter: 1632/1856
[A[ATraining Step: 226  | total loss: [1m[32m0.11292[0m[0m | time: 650.144s
[2K
| Adam | epoch: 004 | loss: 0.11292 - acc: 0.9659 -- iter: 1664/1856
[A[ATraining Step: 227  | total loss: [1m[32m0.11039[0m[0m | time: 662.478s
[2K
| Adam | epoch: 004 | loss: 0.11039 - acc: 0.9631 -- iter: 1696/1856
[A[ATraining Step: 228  | total loss: [1m[32m0.11013[0m[0m | time: 674.265s
[2K
| Adam | epoch: 004 | loss: 0.11013 - acc: 0.9637 -- iter: 1728/1856
[A[ATraining Step: 229  | total loss: [1m[32m0.10845[0m[0m | time: 685.876s
[2K
| Adam | epoch: 004 | loss: 0.10845 - acc: 0.9673 -- iter: 1760/1856
[A[ATraining Step: 230  | total loss: [1m[32m0.14368[0m[0m | time: 697.911s
[2K
| Adam | epoch: 004 | loss: 0.14368 - acc: 0.9612 -- iter: 1792/1856
[A[ATraining Step: 231  | total loss: [1m[32m0.13025[0m[0m | time: 709.965s
[2K
| Adam | epoch: 004 | loss: 0.13025 - acc: 0.9651 -- iter: 1824/1856
[A[ATraining Step: 232  | total loss: [1m[32m0.12854[0m[0m | time: 763.137s
[2K
| Adam | epoch: 004 | loss: 0.12854 - acc: 0.9623 | val_loss: 0.39613 - val_acc: 0.8621 -- iter: 1856/1856
--
Training Step: 233  | total loss: [1m[32m0.12672[0m[0m | time: 12.213s
[2K
| Adam | epoch: 005 | loss: 0.12672 - acc: 0.9630 -- iter: 0032/1856
[A[ATraining Step: 234  | total loss: [1m[32m0.12600[0m[0m | time: 23.994s
[2K
| Adam | epoch: 005 | loss: 0.12600 - acc: 0.9635 -- iter: 0064/1856
[A[ATraining Step: 235  | total loss: [1m[32m0.12280[0m[0m | time: 36.191s
[2K
| Adam | epoch: 005 | loss: 0.12280 - acc: 0.9641 -- iter: 0096/1856
[A[ATraining Step: 236  | total loss: [1m[32m0.11714[0m[0m | time: 47.848s
[2K
| Adam | epoch: 005 | loss: 0.11714 - acc: 0.9645 -- iter: 0128/1856
[A[ATraining Step: 237  | total loss: [1m[32m0.10912[0m[0m | time: 59.513s
[2K
| Adam | epoch: 005 | loss: 0.10912 - acc: 0.9681 -- iter: 0160/1856
[A[ATraining Step: 238  | total loss: [1m[32m0.12118[0m[0m | time: 71.531s
[2K
| Adam | epoch: 005 | loss: 0.12118 - acc: 0.9650 -- iter: 0192/1856
[A[ATraining Step: 239  | total loss: [1m[32m0.11312[0m[0m | time: 83.307s
[2K
| Adam | epoch: 005 | loss: 0.11312 - acc: 0.9685 -- iter: 0224/1856
[A[ATraining Step: 240  | total loss: [1m[32m0.11925[0m[0m | time: 94.782s
[2K
| Adam | epoch: 005 | loss: 0.11925 - acc: 0.9654 -- iter: 0256/1856
[A[ATraining Step: 241  | total loss: [1m[32m0.11857[0m[0m | time: 106.609s
[2K
| Adam | epoch: 005 | loss: 0.11857 - acc: 0.9657 -- iter: 0288/1856
[A[ATraining Step: 242  | total loss: [1m[32m0.12739[0m[0m | time: 118.848s
[2K
| Adam | epoch: 005 | loss: 0.12739 - acc: 0.9598 -- iter: 0320/1856
[A[ATraining Step: 243  | total loss: [1m[32m0.13940[0m[0m | time: 130.556s
[2K
| Adam | epoch: 005 | loss: 0.13940 - acc: 0.9544 -- iter: 0352/1856
[A[ATraining Step: 244  | total loss: [1m[32m0.13088[0m[0m | time: 142.238s
[2K
| Adam | epoch: 005 | loss: 0.13088 - acc: 0.9559 -- iter: 0384/1856
[A[ATraining Step: 245  | total loss: [1m[32m0.13356[0m[0m | time: 154.114s
[2K
| Adam | epoch: 005 | loss: 0.13356 - acc: 0.9572 -- iter: 0416/1856
[A[ATraining Step: 246  | total loss: [1m[32m0.13643[0m[0m | time: 165.926s
[2K
| Adam | epoch: 005 | loss: 0.13643 - acc: 0.9583 -- iter: 0448/1856
[A[ATraining Step: 247  | total loss: [1m[32m0.14552[0m[0m | time: 178.289s
[2K
| Adam | epoch: 005 | loss: 0.14552 - acc: 0.9562 -- iter: 0480/1856
[A[ATraining Step: 248  | total loss: [1m[32m0.19287[0m[0m | time: 191.127s
[2K
| Adam | epoch: 005 | loss: 0.19287 - acc: 0.9356 -- iter: 0512/1856
[A[ATraining Step: 249  | total loss: [1m[32m0.17761[0m[0m | time: 203.902s
[2K
| Adam | epoch: 005 | loss: 0.17761 - acc: 0.9421 -- iter: 0544/1856
[A[ATraining Step: 250  | total loss: [1m[32m0.16936[0m[0m | time: 214.566s
[2K
| Adam | epoch: 005 | loss: 0.16936 - acc: 0.9447 -- iter: 0576/1856
[A[ATraining Step: 251  | total loss: [1m[32m0.15666[0m[0m | time: 222.734s
[2K
| Adam | epoch: 005 | loss: 0.15666 - acc: 0.9503 -- iter: 0608/1856
[A[ATraining Step: 252  | total loss: [1m[32m0.15513[0m[0m | time: 230.797s
[2K
| Adam | epoch: 005 | loss: 0.15513 - acc: 0.9459 -- iter: 0640/1856
[A[ATraining Step: 253  | total loss: [1m[32m0.14883[0m[0m | time: 241.016s
[2K
| Adam | epoch: 005 | loss: 0.14883 - acc: 0.9481 -- iter: 0672/1856
[A[ATraining Step: 254  | total loss: [1m[32m0.13601[0m[0m | time: 252.890s
[2K
| Adam | epoch: 005 | loss: 0.13601 - acc: 0.9533 -- iter: 0704/1856
[A[ATraining Step: 255  | total loss: [1m[32m0.13628[0m[0m | time: 264.891s
[2K
| Adam | epoch: 005 | loss: 0.13628 - acc: 0.9549 -- iter: 0736/1856
[A[ATraining Step: 256  | total loss: [1m[32m0.13472[0m[0m | time: 276.000s
[2K
| Adam | epoch: 005 | loss: 0.13472 - acc: 0.9563 -- iter: 0768/1856
[A[ATraining Step: 257  | total loss: [1m[32m0.12291[0m[0m | time: 287.770s
[2K
| Adam | epoch: 005 | loss: 0.12291 - acc: 0.9606 -- iter: 0800/1856
[A[ATraining Step: 258  | total loss: [1m[32m0.11602[0m[0m | time: 299.849s
[2K
| Adam | epoch: 005 | loss: 0.11602 - acc: 0.9614 -- iter: 0832/1856
[A[ATraining Step: 259  | total loss: [1m[32m0.11636[0m[0m | time: 311.599s
[2K
| Adam | epoch: 005 | loss: 0.11636 - acc: 0.9590 -- iter: 0864/1856
[A[ATraining Step: 260  | total loss: [1m[32m0.12760[0m[0m | time: 323.635s
[2K
| Adam | epoch: 005 | loss: 0.12760 - acc: 0.9569 -- iter: 0896/1856
[A[ATraining Step: 261  | total loss: [1m[32m0.11823[0m[0m | time: 335.576s
[2K
| Adam | epoch: 005 | loss: 0.11823 - acc: 0.9612 -- iter: 0928/1856
[A[ATraining Step: 262  | total loss: [1m[32m0.11104[0m[0m | time: 347.808s
[2K
| Adam | epoch: 005 | loss: 0.11104 - acc: 0.9620 -- iter: 0960/1856
[A[ATraining Step: 263  | total loss: [1m[32m0.13076[0m[0m | time: 359.642s
[2K
| Adam | epoch: 005 | loss: 0.13076 - acc: 0.9595 -- iter: 0992/1856
[A[ATraining Step: 264  | total loss: [1m[32m0.12090[0m[0m | time: 370.626s
[2K
| Adam | epoch: 005 | loss: 0.12090 - acc: 0.9636 -- iter: 1024/1856
[A[ATraining Step: 265  | total loss: [1m[32m0.12657[0m[0m | time: 382.886s
[2K
| Adam | epoch: 005 | loss: 0.12657 - acc: 0.9610 -- iter: 1056/1856
[A[ATraining Step: 266  | total loss: [1m[32m0.12384[0m[0m | time: 394.517s
[2K
| Adam | epoch: 005 | loss: 0.12384 - acc: 0.9617 -- iter: 1088/1856
[A[ATraining Step: 267  | total loss: [1m[32m0.11468[0m[0m | time: 406.425s
[2K
| Adam | epoch: 005 | loss: 0.11468 - acc: 0.9656 -- iter: 1120/1856
[A[ATraining Step: 268  | total loss: [1m[32m0.10608[0m[0m | time: 418.676s
[2K
| Adam | epoch: 005 | loss: 0.10608 - acc: 0.9690 -- iter: 1152/1856
[A[ATraining Step: 269  | total loss: [1m[32m0.10617[0m[0m | time: 430.772s
[2K
| Adam | epoch: 005 | loss: 0.10617 - acc: 0.9690 -- iter: 1184/1856
[A[ATraining Step: 270  | total loss: [1m[32m0.10629[0m[0m | time: 442.140s
[2K
| Adam | epoch: 005 | loss: 0.10629 - acc: 0.9658 -- iter: 1216/1856
[A[ATraining Step: 271  | total loss: [1m[32m0.10278[0m[0m | time: 454.297s
[2K
| Adam | epoch: 005 | loss: 0.10278 - acc: 0.9661 -- iter: 1248/1856
[A[ATraining Step: 272  | total loss: [1m[32m0.09565[0m[0m | time: 465.946s
[2K
| Adam | epoch: 005 | loss: 0.09565 - acc: 0.9695 -- iter: 1280/1856
[A[ATraining Step: 273  | total loss: [1m[32m0.08838[0m[0m | time: 477.666s
[2K
| Adam | epoch: 005 | loss: 0.08838 - acc: 0.9726 -- iter: 1312/1856
[A[ATraining Step: 274  | total loss: [1m[32m0.08535[0m[0m | time: 489.774s
[2K
| Adam | epoch: 005 | loss: 0.08535 - acc: 0.9722 -- iter: 1344/1856
[A[ATraining Step: 275  | total loss: [1m[32m0.08082[0m[0m | time: 501.528s
[2K
| Adam | epoch: 005 | loss: 0.08082 - acc: 0.9750 -- iter: 1376/1856
[A[ATraining Step: 276  | total loss: [1m[32m0.07999[0m[0m | time: 513.693s
[2K
| Adam | epoch: 005 | loss: 0.07999 - acc: 0.9743 -- iter: 1408/1856
[A[ATraining Step: 277  | total loss: [1m[32m0.07761[0m[0m | time: 525.481s
[2K
| Adam | epoch: 005 | loss: 0.07761 - acc: 0.9738 -- iter: 1440/1856
[A[ATraining Step: 278  | total loss: [1m[32m0.07457[0m[0m | time: 537.321s
[2K
| Adam | epoch: 005 | loss: 0.07457 - acc: 0.9764 -- iter: 1472/1856
[A[ATraining Step: 279  | total loss: [1m[32m0.06918[0m[0m | time: 548.968s
[2K
| Adam | epoch: 005 | loss: 0.06918 - acc: 0.9788 -- iter: 1504/1856
[A[ATraining Step: 280  | total loss: [1m[32m0.07404[0m[0m | time: 561.086s
[2K
| Adam | epoch: 005 | loss: 0.07404 - acc: 0.9746 -- iter: 1536/1856
[A[ATraining Step: 281  | total loss: [1m[32m0.07619[0m[0m | time: 572.899s
[2K
| Adam | epoch: 005 | loss: 0.07619 - acc: 0.9709 -- iter: 1568/1856
[A[ATraining Step: 282  | total loss: [1m[32m0.07184[0m[0m | time: 584.724s
[2K
| Adam | epoch: 005 | loss: 0.07184 - acc: 0.9738 -- iter: 1600/1856
[A[ATraining Step: 283  | total loss: [1m[32m0.06783[0m[0m | time: 596.669s
[2K
| Adam | epoch: 005 | loss: 0.06783 - acc: 0.9764 -- iter: 1632/1856
[A[ATraining Step: 284  | total loss: [1m[32m0.06634[0m[0m | time: 608.959s
[2K
| Adam | epoch: 005 | loss: 0.06634 - acc: 0.9757 -- iter: 1664/1856
[A[ATraining Step: 285  | total loss: [1m[32m0.06114[0m[0m | time: 620.839s
[2K
| Adam | epoch: 005 | loss: 0.06114 - acc: 0.9781 -- iter: 1696/1856
[A[ATraining Step: 286  | total loss: [1m[32m0.08635[0m[0m | time: 632.807s
[2K
| Adam | epoch: 005 | loss: 0.08635 - acc: 0.9709 -- iter: 1728/1856
[A[ATraining Step: 287  | total loss: [1m[32m0.07883[0m[0m | time: 645.033s
[2K
| Adam | epoch: 005 | loss: 0.07883 - acc: 0.9738 -- iter: 1760/1856
[A[ATraining Step: 288  | total loss: [1m[32m0.08223[0m[0m | time: 656.937s
[2K
| Adam | epoch: 005 | loss: 0.08223 - acc: 0.9733 -- iter: 1792/1856
[A[ATraining Step: 289  | total loss: [1m[32m0.09141[0m[0m | time: 668.965s
[2K
| Adam | epoch: 005 | loss: 0.09141 - acc: 0.9635 -- iter: 1824/1856
[A[ATraining Step: 290  | total loss: [1m[32m0.11067[0m[0m | time: 721.779s
[2K
| Adam | epoch: 005 | loss: 0.11067 - acc: 0.9609 | val_loss: 1.49820 - val_acc: 0.6586 -- iter: 1856/1856
--
Training Step: 291  | total loss: [1m[32m0.10578[0m[0m | time: 12.262s
[2K
| Adam | epoch: 006 | loss: 0.10578 - acc: 0.9617 -- iter: 0032/1856
[A[ATraining Step: 292  | total loss: [1m[32m0.10017[0m[0m | time: 24.218s
[2K
| Adam | epoch: 006 | loss: 0.10017 - acc: 0.9624 -- iter: 0064/1856
[A[ATraining Step: 293  | total loss: [1m[32m0.09218[0m[0m | time: 36.138s
[2K
| Adam | epoch: 006 | loss: 0.09218 - acc: 0.9661 -- iter: 0096/1856
[A[ATraining Step: 294  | total loss: [1m[32m0.09341[0m[0m | time: 48.006s
[2K
| Adam | epoch: 006 | loss: 0.09341 - acc: 0.9633 -- iter: 0128/1856
[A[ATraining Step: 295  | total loss: [1m[32m0.09225[0m[0m | time: 60.664s
[2K
| Adam | epoch: 006 | loss: 0.09225 - acc: 0.9638 -- iter: 0160/1856
[A[ATraining Step: 296  | total loss: [1m[32m0.08594[0m[0m | time: 72.996s
[2K
| Adam | epoch: 006 | loss: 0.08594 - acc: 0.9674 -- iter: 0192/1856
[A[ATraining Step: 297  | total loss: [1m[32m0.10357[0m[0m | time: 84.629s
[2K
| Adam | epoch: 006 | loss: 0.10357 - acc: 0.9613 -- iter: 0224/1856
[A[ATraining Step: 298  | total loss: [1m[32m0.10362[0m[0m | time: 96.363s
[2K
| Adam | epoch: 006 | loss: 0.10362 - acc: 0.9589 -- iter: 0256/1856
[A[ATraining Step: 299  | total loss: [1m[32m0.10032[0m[0m | time: 108.348s
[2K
| Adam | epoch: 006 | loss: 0.10032 - acc: 0.9599 -- iter: 0288/1856
[A[ATraining Step: 300  | total loss: [1m[32m0.09257[0m[0m | time: 120.148s
[2K
| Adam | epoch: 006 | loss: 0.09257 - acc: 0.9639 -- iter: 0320/1856
[A[ATraining Step: 301  | total loss: [1m[32m0.12359[0m[0m | time: 132.103s
[2K
| Adam | epoch: 006 | loss: 0.12359 - acc: 0.9582 -- iter: 0352/1856
[A[ATraining Step: 302  | total loss: [1m[32m0.13204[0m[0m | time: 144.238s
[2K
| Adam | epoch: 006 | loss: 0.13204 - acc: 0.9530 -- iter: 0384/1856
[A[ATraining Step: 303  | total loss: [1m[32m0.12830[0m[0m | time: 156.341s
[2K
| Adam | epoch: 006 | loss: 0.12830 - acc: 0.9546 -- iter: 0416/1856
[A[ATraining Step: 304  | total loss: [1m[32m0.11833[0m[0m | time: 168.481s
[2K
| Adam | epoch: 006 | loss: 0.11833 - acc: 0.9591 -- iter: 0448/1856
[A[ATraining Step: 305  | total loss: [1m[32m0.11967[0m[0m | time: 180.108s
[2K
| Adam | epoch: 006 | loss: 0.11967 - acc: 0.9569 -- iter: 0480/1856
[A[ATraining Step: 306  | total loss: [1m[32m0.11629[0m[0m | time: 192.239s
[2K
| Adam | epoch: 006 | loss: 0.11629 - acc: 0.9581 -- iter: 0512/1856
[A[ATraining Step: 307  | total loss: [1m[32m0.14252[0m[0m | time: 204.314s
[2K
| Adam | epoch: 006 | loss: 0.14252 - acc: 0.9592 -- iter: 0544/1856
[A[ATraining Step: 308  | total loss: [1m[32m0.13197[0m[0m | time: 216.229s
[2K
| Adam | epoch: 006 | loss: 0.13197 - acc: 0.9633 -- iter: 0576/1856
[A[ATraining Step: 309  | total loss: [1m[32m0.12369[0m[0m | time: 228.086s
[2K
| Adam | epoch: 006 | loss: 0.12369 - acc: 0.9638 -- iter: 0608/1856
[A[ATraining Step: 310  | total loss: [1m[32m0.12159[0m[0m | time: 239.725s
[2K
| Adam | epoch: 006 | loss: 0.12159 - acc: 0.9643 -- iter: 0640/1856
[A[ATraining Step: 311  | total loss: [1m[32m0.15085[0m[0m | time: 251.999s
[2K
| Adam | epoch: 006 | loss: 0.15085 - acc: 0.9554 -- iter: 0672/1856
[A[ATraining Step: 312  | total loss: [1m[32m0.14309[0m[0m | time: 264.813s
[2K
| Adam | epoch: 006 | loss: 0.14309 - acc: 0.9567 -- iter: 0704/1856
[A[ATraining Step: 313  | total loss: [1m[32m0.14547[0m[0m | time: 277.626s
[2K
| Adam | epoch: 006 | loss: 0.14547 - acc: 0.9517 -- iter: 0736/1856
[A[ATraining Step: 314  | total loss: [1m[32m0.13708[0m[0m | time: 290.477s
[2K
| Adam | epoch: 006 | loss: 0.13708 - acc: 0.9534 -- iter: 0768/1856
[A[ATraining Step: 315  | total loss: [1m[32m0.13676[0m[0m | time: 299.681s
[2K
| Adam | epoch: 006 | loss: 0.13676 - acc: 0.9518 -- iter: 0800/1856
[A[ATraining Step: 316  | total loss: [1m[32m0.12550[0m[0m | time: 307.560s
[2K
| Adam | epoch: 006 | loss: 0.12550 - acc: 0.9566 -- iter: 0832/1856
[A[ATraining Step: 317  | total loss: [1m[32m0.11825[0m[0m | time: 315.741s
[2K
| Adam | epoch: 006 | loss: 0.11825 - acc: 0.9609 -- iter: 0864/1856
[A[ATraining Step: 318  | total loss: [1m[32m0.11385[0m[0m | time: 327.392s
[2K
| Adam | epoch: 006 | loss: 0.11385 - acc: 0.9649 -- iter: 0896/1856
[A[ATraining Step: 319  | total loss: [1m[32m0.10835[0m[0m | time: 339.215s
[2K
| Adam | epoch: 006 | loss: 0.10835 - acc: 0.9652 -- iter: 0928/1856
[A[ATraining Step: 320  | total loss: [1m[32m0.11651[0m[0m | time: 351.060s
[2K
| Adam | epoch: 006 | loss: 0.11651 - acc: 0.9625 -- iter: 0960/1856
[A[ATraining Step: 321  | total loss: [1m[32m0.11714[0m[0m | time: 363.037s
[2K
| Adam | epoch: 006 | loss: 0.11714 - acc: 0.9631 -- iter: 0992/1856
[A[ATraining Step: 322  | total loss: [1m[32m0.14208[0m[0m | time: 375.233s
[2K
| Adam | epoch: 006 | loss: 0.14208 - acc: 0.9637 -- iter: 1024/1856
[A[ATraining Step: 323  | total loss: [1m[32m0.13817[0m[0m | time: 387.366s
[2K
| Adam | epoch: 006 | loss: 0.13817 - acc: 0.9642 -- iter: 1056/1856
[A[ATraining Step: 324  | total loss: [1m[32m0.13347[0m[0m | time: 398.967s
[2K
| Adam | epoch: 006 | loss: 0.13347 - acc: 0.9678 -- iter: 1088/1856
[A[ATraining Step: 325  | total loss: [1m[32m0.13624[0m[0m | time: 411.180s
[2K
| Adam | epoch: 006 | loss: 0.13624 - acc: 0.9647 -- iter: 1120/1856
[A[ATraining Step: 326  | total loss: [1m[32m0.12566[0m[0m | time: 423.137s
[2K
| Adam | epoch: 006 | loss: 0.12566 - acc: 0.9683 -- iter: 1152/1856
[A[ATraining Step: 327  | total loss: [1m[32m0.12455[0m[0m | time: 435.005s
[2K
| Adam | epoch: 006 | loss: 0.12455 - acc: 0.9652 -- iter: 1184/1856
[A[ATraining Step: 328  | total loss: [1m[32m0.11551[0m[0m | time: 446.925s
[2K
| Adam | epoch: 006 | loss: 0.11551 - acc: 0.9687 -- iter: 1216/1856
[A[ATraining Step: 329  | total loss: [1m[32m0.10673[0m[0m | time: 458.529s
[2K
| Adam | epoch: 006 | loss: 0.10673 - acc: 0.9718 -- iter: 1248/1856
[A[ATraining Step: 330  | total loss: [1m[32m0.11492[0m[0m | time: 470.252s
[2K
| Adam | epoch: 006 | loss: 0.11492 - acc: 0.9652 -- iter: 1280/1856
[A[ATraining Step: 331  | total loss: [1m[32m0.10751[0m[0m | time: 482.021s
[2K
| Adam | epoch: 006 | loss: 0.10751 - acc: 0.9687 -- iter: 1312/1856
[A[ATraining Step: 332  | total loss: [1m[32m0.10079[0m[0m | time: 493.706s
[2K
| Adam | epoch: 006 | loss: 0.10079 - acc: 0.9687 -- iter: 1344/1856
[A[ATraining Step: 333  | total loss: [1m[32m0.09376[0m[0m | time: 505.450s
[2K
| Adam | epoch: 006 | loss: 0.09376 - acc: 0.9718 -- iter: 1376/1856
[A[ATraining Step: 334  | total loss: [1m[32m0.08812[0m[0m | time: 517.360s
[2K
| Adam | epoch: 006 | loss: 0.08812 - acc: 0.9747 -- iter: 1408/1856
[A[ATraining Step: 335  | total loss: [1m[32m0.08187[0m[0m | time: 529.498s
[2K
| Adam | epoch: 006 | loss: 0.08187 - acc: 0.9772 -- iter: 1440/1856
[A[ATraining Step: 336  | total loss: [1m[32m0.08113[0m[0m | time: 541.674s
[2K
| Adam | epoch: 006 | loss: 0.08113 - acc: 0.9764 -- iter: 1472/1856
[A[ATraining Step: 337  | total loss: [1m[32m0.08062[0m[0m | time: 553.506s
[2K
| Adam | epoch: 006 | loss: 0.08062 - acc: 0.9756 -- iter: 1504/1856
[A[ATraining Step: 338  | total loss: [1m[32m0.07398[0m[0m | time: 565.167s
[2K
| Adam | epoch: 006 | loss: 0.07398 - acc: 0.9780 -- iter: 1536/1856
[A[ATraining Step: 339  | total loss: [1m[32m0.08455[0m[0m | time: 577.096s
[2K
| Adam | epoch: 006 | loss: 0.08455 - acc: 0.9740 -- iter: 1568/1856
[A[ATraining Step: 340  | total loss: [1m[32m0.08384[0m[0m | time: 588.983s
[2K
| Adam | epoch: 006 | loss: 0.08384 - acc: 0.9735 -- iter: 1600/1856
[A[ATraining Step: 341  | total loss: [1m[32m0.07652[0m[0m | time: 600.724s
[2K
| Adam | epoch: 006 | loss: 0.07652 - acc: 0.9761 -- iter: 1632/1856
[A[ATraining Step: 342  | total loss: [1m[32m0.07477[0m[0m | time: 612.540s
[2K
| Adam | epoch: 006 | loss: 0.07477 - acc: 0.9754 -- iter: 1664/1856
[A[ATraining Step: 343  | total loss: [1m[32m0.08089[0m[0m | time: 624.676s
[2K
| Adam | epoch: 006 | loss: 0.08089 - acc: 0.9747 -- iter: 1696/1856
[A[ATraining Step: 344  | total loss: [1m[32m0.07579[0m[0m | time: 636.529s
[2K
| Adam | epoch: 006 | loss: 0.07579 - acc: 0.9772 -- iter: 1728/1856
[A[ATraining Step: 345  | total loss: [1m[32m0.07172[0m[0m | time: 648.592s
[2K
| Adam | epoch: 006 | loss: 0.07172 - acc: 0.9795 -- iter: 1760/1856
[A[ATraining Step: 346  | total loss: [1m[32m0.06678[0m[0m | time: 660.589s
[2K
| Adam | epoch: 006 | loss: 0.06678 - acc: 0.9816 -- iter: 1792/1856
[A[ATraining Step: 347  | total loss: [1m[32m0.06113[0m[0m | time: 672.570s
[2K
| Adam | epoch: 006 | loss: 0.06113 - acc: 0.9834 -- iter: 1824/1856
[A[ATraining Step: 348  | total loss: [1m[32m0.05605[0m[0m | time: 726.611s
[2K
| Adam | epoch: 006 | loss: 0.05605 - acc: 0.9851 | val_loss: 0.39222 - val_acc: 0.9017 -- iter: 1856/1856
--
Training Step: 349  | total loss: [1m[32m0.05349[0m[0m | time: 11.709s
[2K
| Adam | epoch: 007 | loss: 0.05349 - acc: 0.9866 -- iter: 0032/1856
[A[ATraining Step: 350  | total loss: [1m[32m0.05139[0m[0m | time: 23.562s
[2K
| Adam | epoch: 007 | loss: 0.05139 - acc: 0.9848 -- iter: 0064/1856
[A[ATraining Step: 351  | total loss: [1m[32m0.04715[0m[0m | time: 35.573s
[2K
| Adam | epoch: 007 | loss: 0.04715 - acc: 0.9863 -- iter: 0096/1856
[A[ATraining Step: 352  | total loss: [1m[32m0.04354[0m[0m | time: 47.435s
[2K
| Adam | epoch: 007 | loss: 0.04354 - acc: 0.9877 -- iter: 0128/1856
[A[ATraining Step: 353  | total loss: [1m[32m0.04409[0m[0m | time: 59.642s
[2K
| Adam | epoch: 007 | loss: 0.04409 - acc: 0.9858 -- iter: 0160/1856
[A[ATraining Step: 354  | total loss: [1m[32m0.04081[0m[0m | time: 71.645s
[2K
| Adam | epoch: 007 | loss: 0.04081 - acc: 0.9872 -- iter: 0192/1856
[A[ATraining Step: 355  | total loss: [1m[32m0.03720[0m[0m | time: 83.425s
[2K
| Adam | epoch: 007 | loss: 0.03720 - acc: 0.9885 -- iter: 0224/1856
[A[ATraining Step: 356  | total loss: [1m[32m0.04277[0m[0m | time: 95.222s
[2K
| Adam | epoch: 007 | loss: 0.04277 - acc: 0.9865 -- iter: 0256/1856
[A[ATraining Step: 357  | total loss: [1m[32m0.03984[0m[0m | time: 107.074s
[2K
| Adam | epoch: 007 | loss: 0.03984 - acc: 0.9879 -- iter: 0288/1856
[A[ATraining Step: 358  | total loss: [1m[32m0.05542[0m[0m | time: 118.692s
[2K
| Adam | epoch: 007 | loss: 0.05542 - acc: 0.9828 -- iter: 0320/1856
[A[ATraining Step: 359  | total loss: [1m[32m0.06719[0m[0m | time: 130.420s
[2K
| Adam | epoch: 007 | loss: 0.06719 - acc: 0.9783 -- iter: 0352/1856
[A[ATraining Step: 360  | total loss: [1m[32m0.06149[0m[0m | time: 143.093s
[2K
| Adam | epoch: 007 | loss: 0.06149 - acc: 0.9805 -- iter: 0384/1856
[A[ATraining Step: 361  | total loss: [1m[32m0.06380[0m[0m | time: 155.437s
[2K
| Adam | epoch: 007 | loss: 0.06380 - acc: 0.9762 -- iter: 0416/1856
[A[ATraining Step: 362  | total loss: [1m[32m0.05891[0m[0m | time: 167.183s
[2K
| Adam | epoch: 007 | loss: 0.05891 - acc: 0.9785 -- iter: 0448/1856
[A[ATraining Step: 363  | total loss: [1m[32m0.06935[0m[0m | time: 178.963s
[2K
| Adam | epoch: 007 | loss: 0.06935 - acc: 0.9744 -- iter: 0480/1856
[A[ATraining Step: 364  | total loss: [1m[32m0.06496[0m[0m | time: 190.752s
[2K
| Adam | epoch: 007 | loss: 0.06496 - acc: 0.9770 -- iter: 0512/1856
[A[ATraining Step: 365  | total loss: [1m[32m0.07063[0m[0m | time: 202.767s
[2K
| Adam | epoch: 007 | loss: 0.07063 - acc: 0.9762 -- iter: 0544/1856
[A[ATraining Step: 366  | total loss: [1m[32m0.06735[0m[0m | time: 214.446s
[2K
| Adam | epoch: 007 | loss: 0.06735 - acc: 0.9786 -- iter: 0576/1856
[A[ATraining Step: 367  | total loss: [1m[32m0.06338[0m[0m | time: 226.393s
[2K
| Adam | epoch: 007 | loss: 0.06338 - acc: 0.9807 -- iter: 0608/1856
[A[ATraining Step: 368  | total loss: [1m[32m0.06012[0m[0m | time: 238.216s
[2K
| Adam | epoch: 007 | loss: 0.06012 - acc: 0.9826 -- iter: 0640/1856
[A[ATraining Step: 369  | total loss: [1m[32m0.06739[0m[0m | time: 250.073s
[2K
| Adam | epoch: 007 | loss: 0.06739 - acc: 0.9781 -- iter: 0672/1856
[A[ATraining Step: 370  | total loss: [1m[32m0.06577[0m[0m | time: 261.625s
[2K
| Adam | epoch: 007 | loss: 0.06577 - acc: 0.9803 -- iter: 0704/1856
[A[ATraining Step: 371  | total loss: [1m[32m0.07107[0m[0m | time: 273.525s
[2K
| Adam | epoch: 007 | loss: 0.07107 - acc: 0.9760 -- iter: 0736/1856
[A[ATraining Step: 372  | total loss: [1m[32m0.06611[0m[0m | time: 285.602s
[2K
| Adam | epoch: 007 | loss: 0.06611 - acc: 0.9784 -- iter: 0768/1856
[A[ATraining Step: 373  | total loss: [1m[32m0.06248[0m[0m | time: 297.206s
[2K
| Adam | epoch: 007 | loss: 0.06248 - acc: 0.9806 -- iter: 0800/1856
[A[ATraining Step: 374  | total loss: [1m[32m0.05748[0m[0m | time: 309.482s
[2K
| Adam | epoch: 007 | loss: 0.05748 - acc: 0.9825 -- iter: 0832/1856
[A[ATraining Step: 375  | total loss: [1m[32m0.05285[0m[0m | time: 321.872s
[2K
| Adam | epoch: 007 | loss: 0.05285 - acc: 0.9843 -- iter: 0864/1856
[A[ATraining Step: 376  | total loss: [1m[32m0.06267[0m[0m | time: 334.690s
[2K
| Adam | epoch: 007 | loss: 0.06267 - acc: 0.9796 -- iter: 0896/1856
[A[ATraining Step: 377  | total loss: [1m[32m0.05814[0m[0m | time: 347.565s
[2K
| Adam | epoch: 007 | loss: 0.05814 - acc: 0.9816 -- iter: 0928/1856
[A[ATraining Step: 378  | total loss: [1m[32m0.06815[0m[0m | time: 355.866s
[2K
| Adam | epoch: 007 | loss: 0.06815 - acc: 0.9803 -- iter: 0960/1856
[A[ATraining Step: 379  | total loss: [1m[32m0.07388[0m[0m | time: 363.921s
[2K
| Adam | epoch: 007 | loss: 0.07388 - acc: 0.9792 -- iter: 0992/1856
[A[ATraining Step: 380  | total loss: [1m[32m0.07034[0m[0m | time: 371.895s
[2K
| Adam | epoch: 007 | loss: 0.07034 - acc: 0.9781 -- iter: 1024/1856
[A[ATraining Step: 381  | total loss: [1m[32m0.07871[0m[0m | time: 379.935s
[2K
| Adam | epoch: 007 | loss: 0.07871 - acc: 0.9741 -- iter: 1056/1856
[A[ATraining Step: 382  | total loss: [1m[32m0.07325[0m[0m | time: 389.314s
[2K
| Adam | epoch: 007 | loss: 0.07325 - acc: 0.9767 -- iter: 1088/1856
[A[ATraining Step: 383  | total loss: [1m[32m0.07732[0m[0m | time: 401.448s
[2K
| Adam | epoch: 007 | loss: 0.07732 - acc: 0.9759 -- iter: 1120/1856
[A[ATraining Step: 384  | total loss: [1m[32m0.08079[0m[0m | time: 413.097s
[2K
| Adam | epoch: 007 | loss: 0.08079 - acc: 0.9720 -- iter: 1152/1856
[A[ATraining Step: 385  | total loss: [1m[32m0.08049[0m[0m | time: 424.952s
[2K
| Adam | epoch: 007 | loss: 0.08049 - acc: 0.9717 -- iter: 1184/1856
[A[ATraining Step: 386  | total loss: [1m[32m0.11247[0m[0m | time: 436.576s
[2K
| Adam | epoch: 007 | loss: 0.11247 - acc: 0.9558 -- iter: 1216/1856
[A[ATraining Step: 387  | total loss: [1m[32m0.13587[0m[0m | time: 448.342s
[2K
| Adam | epoch: 007 | loss: 0.13587 - acc: 0.9446 -- iter: 1248/1856
[A[ATraining Step: 388  | total loss: [1m[32m0.13761[0m[0m | time: 460.291s
[2K
| Adam | epoch: 007 | loss: 0.13761 - acc: 0.9439 -- iter: 1280/1856
[A[ATraining Step: 389  | total loss: [1m[32m0.14220[0m[0m | time: 471.905s
[2K
| Adam | epoch: 007 | loss: 0.14220 - acc: 0.9464 -- iter: 1312/1856
[A[ATraining Step: 390  | total loss: [1m[32m0.13016[0m[0m | time: 483.964s
[2K
| Adam | epoch: 007 | loss: 0.13016 - acc: 0.9517 -- iter: 1344/1856
[A[ATraining Step: 391  | total loss: [1m[32m0.11962[0m[0m | time: 495.609s
[2K
| Adam | epoch: 007 | loss: 0.11962 - acc: 0.9566 -- iter: 1376/1856
[A[ATraining Step: 392  | total loss: [1m[32m0.10959[0m[0m | time: 507.173s
[2K
| Adam | epoch: 007 | loss: 0.10959 - acc: 0.9609 -- iter: 1408/1856
[A[ATraining Step: 393  | total loss: [1m[32m0.10347[0m[0m | time: 518.990s
[2K
| Adam | epoch: 007 | loss: 0.10347 - acc: 0.9648 -- iter: 1440/1856
[A[ATraining Step: 394  | total loss: [1m[32m0.10242[0m[0m | time: 530.818s
[2K
| Adam | epoch: 007 | loss: 0.10242 - acc: 0.9652 -- iter: 1472/1856
[A[ATraining Step: 395  | total loss: [1m[32m0.11886[0m[0m | time: 542.029s
[2K
| Adam | epoch: 007 | loss: 0.11886 - acc: 0.9562 -- iter: 1504/1856
[A[ATraining Step: 396  | total loss: [1m[32m0.11261[0m[0m | time: 553.551s
[2K
| Adam | epoch: 007 | loss: 0.11261 - acc: 0.9574 -- iter: 1536/1856
[A[ATraining Step: 397  | total loss: [1m[32m0.10761[0m[0m | time: 565.688s
[2K
| Adam | epoch: 007 | loss: 0.10761 - acc: 0.9586 -- iter: 1568/1856
[A[ATraining Step: 398  | total loss: [1m[32m0.10255[0m[0m | time: 577.379s
[2K
| Adam | epoch: 007 | loss: 0.10255 - acc: 0.9565 -- iter: 1600/1856
[A[ATraining Step: 399  | total loss: [1m[32m0.10203[0m[0m | time: 589.223s
[2K
| Adam | epoch: 007 | loss: 0.10203 - acc: 0.9546 -- iter: 1632/1856
[A[ATraining Step: 400  | total loss: [1m[32m0.10368[0m[0m | time: 641.794s
[2K
| Adam | epoch: 007 | loss: 0.10368 - acc: 0.9560 | val_loss: 0.27810 - val_acc: 0.9086 -- iter: 1664/1856
--
Training Step: 401  | total loss: [1m[32m0.11142[0m[0m | time: 654.063s
[2K
| Adam | epoch: 007 | loss: 0.11142 - acc: 0.9510 -- iter: 1696/1856
[A[ATraining Step: 402  | total loss: [1m[32m0.10636[0m[0m | time: 665.744s
[2K
| Adam | epoch: 007 | loss: 0.10636 - acc: 0.9528 -- iter: 1728/1856
[A[ATraining Step: 403  | total loss: [1m[32m0.09934[0m[0m | time: 677.199s
[2K
| Adam | epoch: 007 | loss: 0.09934 - acc: 0.9575 -- iter: 1760/1856
[A[ATraining Step: 404  | total loss: [1m[32m0.09193[0m[0m | time: 688.692s
[2K
| Adam | epoch: 007 | loss: 0.09193 - acc: 0.9618 -- iter: 1792/1856
[A[ATraining Step: 405  | total loss: [1m[32m0.08937[0m[0m | time: 700.651s
[2K
| Adam | epoch: 007 | loss: 0.08937 - acc: 0.9625 -- iter: 1824/1856
[A[ATraining Step: 406  | total loss: [1m[32m0.09724[0m[0m | time: 752.888s
[2K
| Adam | epoch: 007 | loss: 0.09724 - acc: 0.9600 | val_loss: 0.49350 - val_acc: 0.8241 -- iter: 1856/1856
--
Training Step: 407  | total loss: [1m[32m0.09170[0m[0m | time: 12.150s
[2K
| Adam | epoch: 008 | loss: 0.09170 - acc: 0.9640 -- iter: 0032/1856
[A[ATraining Step: 408  | total loss: [1m[32m0.09613[0m[0m | time: 23.710s
[2K
| Adam | epoch: 008 | loss: 0.09613 - acc: 0.9613 -- iter: 0064/1856
[A[ATraining Step: 409  | total loss: [1m[32m0.09762[0m[0m | time: 35.294s
[2K
| Adam | epoch: 008 | loss: 0.09762 - acc: 0.9621 -- iter: 0096/1856
[A[ATraining Step: 410  | total loss: [1m[32m0.09069[0m[0m | time: 47.164s
[2K
| Adam | epoch: 008 | loss: 0.09069 - acc: 0.9659 -- iter: 0128/1856
[A[ATraining Step: 411  | total loss: [1m[32m0.08850[0m[0m | time: 58.815s
[2K
| Adam | epoch: 008 | loss: 0.08850 - acc: 0.9661 -- iter: 0160/1856
[A[ATraining Step: 412  | total loss: [1m[32m0.08316[0m[0m | time: 70.174s
[2K
| Adam | epoch: 008 | loss: 0.08316 - acc: 0.9695 -- iter: 0192/1856
[A[ATraining Step: 413  | total loss: [1m[32m0.09650[0m[0m | time: 82.089s
[2K
| Adam | epoch: 008 | loss: 0.09650 - acc: 0.9695 -- iter: 0224/1856
[A[ATraining Step: 414  | total loss: [1m[32m0.10377[0m[0m | time: 93.753s
[2K
| Adam | epoch: 008 | loss: 0.10377 - acc: 0.9694 -- iter: 0256/1856
[A[ATraining Step: 415  | total loss: [1m[32m0.10536[0m[0m | time: 105.403s
[2K
| Adam | epoch: 008 | loss: 0.10536 - acc: 0.9662 -- iter: 0288/1856
[A[ATraining Step: 416  | total loss: [1m[32m0.10143[0m[0m | time: 117.270s
[2K
| Adam | epoch: 008 | loss: 0.10143 - acc: 0.9664 -- iter: 0320/1856
[A[ATraining Step: 417  | total loss: [1m[32m0.09557[0m[0m | time: 129.244s
[2K
| Adam | epoch: 008 | loss: 0.09557 - acc: 0.9667 -- iter: 0352/1856
[A[ATraining Step: 418  | total loss: [1m[32m0.09068[0m[0m | time: 140.543s
[2K
| Adam | epoch: 008 | loss: 0.09068 - acc: 0.9669 -- iter: 0384/1856
[A[ATraining Step: 419  | total loss: [1m[32m0.08337[0m[0m | time: 152.322s
[2K
| Adam | epoch: 008 | loss: 0.08337 - acc: 0.9702 -- iter: 0416/1856
[A[ATraining Step: 420  | total loss: [1m[32m0.08445[0m[0m | time: 163.994s
[2K
| Adam | epoch: 008 | loss: 0.08445 - acc: 0.9701 -- iter: 0448/1856
[A[ATraining Step: 421  | total loss: [1m[32m0.07811[0m[0m | time: 175.969s
[2K
| Adam | epoch: 008 | loss: 0.07811 - acc: 0.9730 -- iter: 0480/1856
[A[ATraining Step: 422  | total loss: [1m[32m0.07109[0m[0m | time: 187.749s
[2K
| Adam | epoch: 008 | loss: 0.07109 - acc: 0.9757 -- iter: 0512/1856
[A[ATraining Step: 423  | total loss: [1m[32m0.06594[0m[0m | time: 199.365s
[2K
| Adam | epoch: 008 | loss: 0.06594 - acc: 0.9782 -- iter: 0544/1856
[A[ATraining Step: 424  | total loss: [1m[32m0.07013[0m[0m | time: 211.271s
[2K
| Adam | epoch: 008 | loss: 0.07013 - acc: 0.9772 -- iter: 0576/1856
[A[ATraining Step: 425  | total loss: [1m[32m0.06647[0m[0m | time: 223.080s
[2K
| Adam | epoch: 008 | loss: 0.06647 - acc: 0.9764 -- iter: 0608/1856
[A[ATraining Step: 426  | total loss: [1m[32m0.06312[0m[0m | time: 234.951s
[2K
| Adam | epoch: 008 | loss: 0.06312 - acc: 0.9787 -- iter: 0640/1856
[A[ATraining Step: 427  | total loss: [1m[32m0.05933[0m[0m | time: 246.268s
[2K
| Adam | epoch: 008 | loss: 0.05933 - acc: 0.9809 -- iter: 0672/1856
[A[ATraining Step: 428  | total loss: [1m[32m0.06880[0m[0m | time: 257.856s
[2K
| Adam | epoch: 008 | loss: 0.06880 - acc: 0.9797 -- iter: 0704/1856
[A[ATraining Step: 429  | total loss: [1m[32m0.06509[0m[0m | time: 269.298s
[2K
| Adam | epoch: 008 | loss: 0.06509 - acc: 0.9817 -- iter: 0736/1856
[A[ATraining Step: 430  | total loss: [1m[32m0.05989[0m[0m | time: 281.322s
[2K
| Adam | epoch: 008 | loss: 0.05989 - acc: 0.9835 -- iter: 0768/1856
[A[ATraining Step: 431  | total loss: [1m[32m0.06061[0m[0m | time: 293.354s
[2K
| Adam | epoch: 008 | loss: 0.06061 - acc: 0.9820 -- iter: 0800/1856
[A[ATraining Step: 432  | total loss: [1m[32m0.05580[0m[0m | time: 304.583s
[2K
| Adam | epoch: 008 | loss: 0.05580 - acc: 0.9838 -- iter: 0832/1856
[A[ATraining Step: 433  | total loss: [1m[32m0.06177[0m[0m | time: 316.431s
[2K
| Adam | epoch: 008 | loss: 0.06177 - acc: 0.9823 -- iter: 0864/1856
[A[ATraining Step: 434  | total loss: [1m[32m0.05673[0m[0m | time: 328.476s
[2K
| Adam | epoch: 008 | loss: 0.05673 - acc: 0.9841 -- iter: 0896/1856
[A[ATraining Step: 435  | total loss: [1m[32m0.07549[0m[0m | time: 341.037s
[2K
| Adam | epoch: 008 | loss: 0.07549 - acc: 0.9763 -- iter: 0928/1856
[A[ATraining Step: 436  | total loss: [1m[32m0.06954[0m[0m | time: 353.900s
[2K
| Adam | epoch: 008 | loss: 0.06954 - acc: 0.9787 -- iter: 0960/1856
[A[ATraining Step: 437  | total loss: [1m[32m0.08099[0m[0m | time: 366.657s
[2K
| Adam | epoch: 008 | loss: 0.08099 - acc: 0.9746 -- iter: 0992/1856
[A[ATraining Step: 438  | total loss: [1m[32m0.08816[0m[0m | time: 378.215s
[2K
| Adam | epoch: 008 | loss: 0.08816 - acc: 0.9709 -- iter: 1024/1856
[A[ATraining Step: 439  | total loss: [1m[32m0.08651[0m[0m | time: 386.348s
[2K
| Adam | epoch: 008 | loss: 0.08651 - acc: 0.9675 -- iter: 1056/1856
[A[ATraining Step: 440  | total loss: [1m[32m0.12350[0m[0m | time: 394.325s
[2K
| Adam | epoch: 008 | loss: 0.12350 - acc: 0.9645 -- iter: 1088/1856
[A[ATraining Step: 441  | total loss: [1m[32m0.11357[0m[0m | time: 405.752s
[2K
| Adam | epoch: 008 | loss: 0.11357 - acc: 0.9681 -- iter: 1120/1856
[A[ATraining Step: 442  | total loss: [1m[32m0.10549[0m[0m | time: 417.300s
[2K
| Adam | epoch: 008 | loss: 0.10549 - acc: 0.9713 -- iter: 1152/1856
[A[ATraining Step: 443  | total loss: [1m[32m0.10373[0m[0m | time: 429.532s
[2K
| Adam | epoch: 008 | loss: 0.10373 - acc: 0.9710 -- iter: 1184/1856
[A[ATraining Step: 444  | total loss: [1m[32m0.09671[0m[0m | time: 442.631s
[2K
| Adam | epoch: 008 | loss: 0.09671 - acc: 0.9739 -- iter: 1216/1856
[A[ATraining Step: 445  | total loss: [1m[32m0.08803[0m[0m | time: 455.202s
[2K
| Adam | epoch: 008 | loss: 0.08803 - acc: 0.9765 -- iter: 1248/1856
[A[ATraining Step: 446  | total loss: [1m[32m0.08050[0m[0m | time: 467.766s
[2K
| Adam | epoch: 008 | loss: 0.08050 - acc: 0.9789 -- iter: 1280/1856
[A[ATraining Step: 447  | total loss: [1m[32m0.07602[0m[0m | time: 475.944s
[2K
| Adam | epoch: 008 | loss: 0.07602 - acc: 0.9779 -- iter: 1312/1856
[A[ATraining Step: 448  | total loss: [1m[32m0.07517[0m[0m | time: 485.254s
[2K
| Adam | epoch: 008 | loss: 0.07517 - acc: 0.9769 -- iter: 1344/1856
[A[ATraining Step: 449  | total loss: [1m[32m0.07733[0m[0m | time: 496.882s
[2K
| Adam | epoch: 008 | loss: 0.07733 - acc: 0.9730 -- iter: 1376/1856
[A[ATraining Step: 450  | total loss: [1m[32m0.07518[0m[0m | time: 508.444s
[2K
| Adam | epoch: 008 | loss: 0.07518 - acc: 0.9757 -- iter: 1408/1856
[A[ATraining Step: 451  | total loss: [1m[32m0.07461[0m[0m | time: 521.054s
[2K
| Adam | epoch: 008 | loss: 0.07461 - acc: 0.9750 -- iter: 1440/1856
[A[ATraining Step: 452  | total loss: [1m[32m0.06904[0m[0m | time: 532.297s
[2K
| Adam | epoch: 008 | loss: 0.06904 - acc: 0.9775 -- iter: 1472/1856
[A[ATraining Step: 453  | total loss: [1m[32m0.06284[0m[0m | time: 544.309s
[2K
| Adam | epoch: 008 | loss: 0.06284 - acc: 0.9798 -- iter: 1504/1856
[A[ATraining Step: 454  | total loss: [1m[32m0.06013[0m[0m | time: 555.977s
[2K
| Adam | epoch: 008 | loss: 0.06013 - acc: 0.9787 -- iter: 1536/1856
[A[ATraining Step: 455  | total loss: [1m[32m0.05728[0m[0m | time: 567.775s
[2K
| Adam | epoch: 008 | loss: 0.05728 - acc: 0.9808 -- iter: 1568/1856
[A[ATraining Step: 456  | total loss: [1m[32m0.05664[0m[0m | time: 579.855s
[2K
| Adam | epoch: 008 | loss: 0.05664 - acc: 0.9796 -- iter: 1600/1856
[A[ATraining Step: 457  | total loss: [1m[32m0.07021[0m[0m | time: 591.941s
[2K
| Adam | epoch: 008 | loss: 0.07021 - acc: 0.9754 -- iter: 1632/1856
[A[ATraining Step: 458  | total loss: [1m[32m0.06572[0m[0m | time: 603.353s
[2K
| Adam | epoch: 008 | loss: 0.06572 - acc: 0.9778 -- iter: 1664/1856
[A[ATraining Step: 459  | total loss: [1m[32m0.06052[0m[0m | time: 615.024s
[2K
| Adam | epoch: 008 | loss: 0.06052 - acc: 0.9801 -- iter: 1696/1856
[A[ATraining Step: 460  | total loss: [1m[32m0.05829[0m[0m | time: 626.264s
[2K
| Adam | epoch: 008 | loss: 0.05829 - acc: 0.9820 -- iter: 1728/1856
[A[ATraining Step: 461  | total loss: [1m[32m0.05952[0m[0m | time: 637.549s
[2K
| Adam | epoch: 008 | loss: 0.05952 - acc: 0.9807 -- iter: 1760/1856
[A[ATraining Step: 462  | total loss: [1m[32m0.05703[0m[0m | time: 649.699s
[2K
| Adam | epoch: 008 | loss: 0.05703 - acc: 0.9826 -- iter: 1792/1856
[A[ATraining Step: 463  | total loss: [1m[32m0.07932[0m[0m | time: 661.816s
[2K
| Adam | epoch: 008 | loss: 0.07932 - acc: 0.9719 -- iter: 1824/1856
[A[ATraining Step: 464  | total loss: [1m[32m0.07623[0m[0m | time: 714.377s
[2K
| Adam | epoch: 008 | loss: 0.07623 - acc: 0.9747 | val_loss: 0.33341 - val_acc: 0.8966 -- iter: 1856/1856
--
Training Step: 465  | total loss: [1m[32m0.07715[0m[0m | time: 11.511s
[2K
| Adam | epoch: 009 | loss: 0.07715 - acc: 0.9710 -- iter: 0032/1856
[A[ATraining Step: 466  | total loss: [1m[32m0.08144[0m[0m | time: 23.594s
[2K
| Adam | epoch: 009 | loss: 0.08144 - acc: 0.9676 -- iter: 0064/1856
[A[ATraining Step: 467  | total loss: [1m[32m0.08143[0m[0m | time: 35.517s
[2K
| Adam | epoch: 009 | loss: 0.08143 - acc: 0.9677 -- iter: 0096/1856
[A[ATraining Step: 468  | total loss: [1m[32m0.07434[0m[0m | time: 47.445s
[2K
| Adam | epoch: 009 | loss: 0.07434 - acc: 0.9710 -- iter: 0128/1856
[A[ATraining Step: 469  | total loss: [1m[32m0.07068[0m[0m | time: 58.832s
[2K
| Adam | epoch: 009 | loss: 0.07068 - acc: 0.9707 -- iter: 0160/1856
[A[ATraining Step: 470  | total loss: [1m[32m0.06772[0m[0m | time: 70.786s
[2K
| Adam | epoch: 009 | loss: 0.06772 - acc: 0.9737 -- iter: 0192/1856
[A[ATraining Step: 471  | total loss: [1m[32m0.07357[0m[0m | time: 82.946s
[2K
| Adam | epoch: 009 | loss: 0.07357 - acc: 0.9701 -- iter: 0224/1856
[A[ATraining Step: 472  | total loss: [1m[32m0.08492[0m[0m | time: 95.366s
[2K
| Adam | epoch: 009 | loss: 0.08492 - acc: 0.9668 -- iter: 0256/1856
[A[ATraining Step: 473  | total loss: [1m[32m0.08287[0m[0m | time: 107.168s
[2K
| Adam | epoch: 009 | loss: 0.08287 - acc: 0.9701 -- iter: 0288/1856
[A[ATraining Step: 474  | total loss: [1m[32m0.08146[0m[0m | time: 118.827s
[2K
| Adam | epoch: 009 | loss: 0.08146 - acc: 0.9700 -- iter: 0320/1856
[A[ATraining Step: 475  | total loss: [1m[32m0.07420[0m[0m | time: 130.883s
[2K
| Adam | epoch: 009 | loss: 0.07420 - acc: 0.9730 -- iter: 0352/1856
[A[ATraining Step: 476  | total loss: [1m[32m0.07337[0m[0m | time: 142.639s
[2K
| Adam | epoch: 009 | loss: 0.07337 - acc: 0.9726 -- iter: 0384/1856
[A[ATraining Step: 477  | total loss: [1m[32m0.07116[0m[0m | time: 154.541s
[2K
| Adam | epoch: 009 | loss: 0.07116 - acc: 0.9722 -- iter: 0416/1856
[A[ATraining Step: 478  | total loss: [1m[32m0.06576[0m[0m | time: 166.886s
[2K
| Adam | epoch: 009 | loss: 0.06576 - acc: 0.9750 -- iter: 0448/1856
[A[ATraining Step: 479  | total loss: [1m[32m0.06092[0m[0m | time: 178.772s
[2K
| Adam | epoch: 009 | loss: 0.06092 - acc: 0.9775 -- iter: 0480/1856
[A[ATraining Step: 480  | total loss: [1m[32m0.05540[0m[0m | time: 190.715s
[2K
| Adam | epoch: 009 | loss: 0.05540 - acc: 0.9797 -- iter: 0512/1856
[A[ATraining Step: 481  | total loss: [1m[32m0.06170[0m[0m | time: 202.260s
[2K
| Adam | epoch: 009 | loss: 0.06170 - acc: 0.9786 -- iter: 0544/1856
[A[ATraining Step: 482  | total loss: [1m[32m0.05682[0m[0m | time: 213.854s
[2K
| Adam | epoch: 009 | loss: 0.05682 - acc: 0.9808 -- iter: 0576/1856
[A[ATraining Step: 483  | total loss: [1m[32m0.05281[0m[0m | time: 226.075s
[2K
| Adam | epoch: 009 | loss: 0.05281 - acc: 0.9827 -- iter: 0608/1856
[A[ATraining Step: 484  | total loss: [1m[32m0.05522[0m[0m | time: 237.505s
[2K
| Adam | epoch: 009 | loss: 0.05522 - acc: 0.9813 -- iter: 0640/1856
[A[ATraining Step: 485  | total loss: [1m[32m0.05454[0m[0m | time: 249.340s
[2K
| Adam | epoch: 009 | loss: 0.05454 - acc: 0.9800 -- iter: 0672/1856
[A[ATraining Step: 486  | total loss: [1m[32m0.05141[0m[0m | time: 261.293s
[2K
| Adam | epoch: 009 | loss: 0.05141 - acc: 0.9820 -- iter: 0704/1856
[A[ATraining Step: 487  | total loss: [1m[32m0.05701[0m[0m | time: 273.154s
[2K
| Adam | epoch: 009 | loss: 0.05701 - acc: 0.9807 -- iter: 0736/1856
[A[ATraining Step: 488  | total loss: [1m[32m0.05184[0m[0m | time: 284.939s
[2K
| Adam | epoch: 009 | loss: 0.05184 - acc: 0.9826 -- iter: 0768/1856
[A[ATraining Step: 489  | total loss: [1m[32m0.04784[0m[0m | time: 297.199s
[2K
| Adam | epoch: 009 | loss: 0.04784 - acc: 0.9844 -- iter: 0800/1856
[A[ATraining Step: 490  | total loss: [1m[32m0.05474[0m[0m | time: 309.261s
[2K
| Adam | epoch: 009 | loss: 0.05474 - acc: 0.9797 -- iter: 0832/1856
[A[ATraining Step: 491  | total loss: [1m[32m0.06947[0m[0m | time: 321.468s
[2K
| Adam | epoch: 009 | loss: 0.06947 - acc: 0.9755 -- iter: 0864/1856
[A[ATraining Step: 492  | total loss: [1m[32m0.06911[0m[0m | time: 333.250s
[2K
| Adam | epoch: 009 | loss: 0.06911 - acc: 0.9748 -- iter: 0896/1856
[A[ATraining Step: 493  | total loss: [1m[32m0.06303[0m[0m | time: 344.845s
[2K
| Adam | epoch: 009 | loss: 0.06303 - acc: 0.9773 -- iter: 0928/1856
[A[ATraining Step: 494  | total loss: [1m[32m0.06004[0m[0m | time: 356.757s
[2K
| Adam | epoch: 009 | loss: 0.06004 - acc: 0.9765 -- iter: 0960/1856
[A[ATraining Step: 495  | total loss: [1m[32m0.05577[0m[0m | time: 368.620s
[2K
| Adam | epoch: 009 | loss: 0.05577 - acc: 0.9788 -- iter: 0992/1856
[A[ATraining Step: 496  | total loss: [1m[32m0.05882[0m[0m | time: 380.639s
[2K
| Adam | epoch: 009 | loss: 0.05882 - acc: 0.9778 -- iter: 1024/1856
[A[ATraining Step: 497  | total loss: [1m[32m0.05916[0m[0m | time: 392.712s
[2K
| Adam | epoch: 009 | loss: 0.05916 - acc: 0.9769 -- iter: 1056/1856
[A[ATraining Step: 498  | total loss: [1m[32m0.05489[0m[0m | time: 404.502s
[2K
| Adam | epoch: 009 | loss: 0.05489 - acc: 0.9792 -- iter: 1088/1856
[A[ATraining Step: 499  | total loss: [1m[32m0.10709[0m[0m | time: 416.998s
[2K
| Adam | epoch: 009 | loss: 0.10709 - acc: 0.9719 -- iter: 1120/1856
[A[ATraining Step: 500  | total loss: [1m[32m0.10268[0m[0m | time: 428.454s
[2K
| Adam | epoch: 009 | loss: 0.10268 - acc: 0.9716 -- iter: 1152/1856
[A[ATraining Step: 501  | total loss: [1m[32m0.09836[0m[0m | time: 440.513s
[2K
| Adam | epoch: 009 | loss: 0.09836 - acc: 0.9744 -- iter: 1184/1856
[A[ATraining Step: 502  | total loss: [1m[32m0.09697[0m[0m | time: 452.550s
[2K
| Adam | epoch: 009 | loss: 0.09697 - acc: 0.9739 -- iter: 1216/1856
[A[ATraining Step: 503  | total loss: [1m[32m0.08786[0m[0m | time: 464.527s
[2K
| Adam | epoch: 009 | loss: 0.08786 - acc: 0.9765 -- iter: 1248/1856
[A[ATraining Step: 504  | total loss: [1m[32m0.08009[0m[0m | time: 477.223s
[2K
| Adam | epoch: 009 | loss: 0.08009 - acc: 0.9788 -- iter: 1280/1856
[A[ATraining Step: 505  | total loss: [1m[32m0.07634[0m[0m | time: 490.035s
[2K
| Adam | epoch: 009 | loss: 0.07634 - acc: 0.9810 -- iter: 1312/1856
[A[ATraining Step: 506  | total loss: [1m[32m0.07464[0m[0m | time: 502.877s
[2K
| Adam | epoch: 009 | loss: 0.07464 - acc: 0.9797 -- iter: 1344/1856
[A[ATraining Step: 507  | total loss: [1m[32m0.08020[0m[0m | time: 514.987s
[2K
| Adam | epoch: 009 | loss: 0.08020 - acc: 0.9786 -- iter: 1376/1856
[A[ATraining Step: 508  | total loss: [1m[32m0.07318[0m[0m | time: 523.053s
[2K
| Adam | epoch: 009 | loss: 0.07318 - acc: 0.9808 -- iter: 1408/1856
[A[ATraining Step: 509  | total loss: [1m[32m0.07052[0m[0m | time: 531.119s
[2K
| Adam | epoch: 009 | loss: 0.07052 - acc: 0.9796 -- iter: 1440/1856
[A[ATraining Step: 510  | total loss: [1m[32m0.08590[0m[0m | time: 539.173s
[2K
| Adam | epoch: 009 | loss: 0.08590 - acc: 0.9785 -- iter: 1472/1856
[A[ATraining Step: 511  | total loss: [1m[32m0.09053[0m[0m | time: 550.979s
[2K
| Adam | epoch: 009 | loss: 0.09053 - acc: 0.9713 -- iter: 1504/1856
[A[ATraining Step: 512  | total loss: [1m[32m0.08350[0m[0m | time: 569.459s
[2K
| Adam | epoch: 009 | loss: 0.08350 - acc: 0.9741 -- iter: 1536/1856
[A[ATraining Step: 513  | total loss: [1m[32m0.07719[0m[0m | time: 588.013s
[2K
| Adam | epoch: 009 | loss: 0.07719 - acc: 0.9767 -- iter: 1568/1856
[A[ATraining Step: 514  | total loss: [1m[32m0.07218[0m[0m | time: 606.751s
[2K
| Adam | epoch: 009 | loss: 0.07218 - acc: 0.9791 -- iter: 1600/1856
[A[ATraining Step: 515  | total loss: [1m[32m0.06662[0m[0m | time: 615.904s
[2K
| Adam | epoch: 009 | loss: 0.06662 - acc: 0.9811 -- iter: 1632/1856
[A[ATraining Step: 516  | total loss: [1m[32m0.07423[0m[0m | time: 623.870s
[2K
| Adam | epoch: 009 | loss: 0.07423 - acc: 0.9768 -- iter: 1664/1856
[A[ATraining Step: 517  | total loss: [1m[32m0.06986[0m[0m | time: 631.783s
[2K
| Adam | epoch: 009 | loss: 0.06986 - acc: 0.9760 -- iter: 1696/1856
[A[ATraining Step: 518  | total loss: [1m[32m0.06698[0m[0m | time: 639.738s
[2K
| Adam | epoch: 009 | loss: 0.06698 - acc: 0.9753 -- iter: 1728/1856
[A[ATraining Step: 519  | total loss: [1m[32m0.06622[0m[0m | time: 647.616s
[2K
| Adam | epoch: 009 | loss: 0.06622 - acc: 0.9746 -- iter: 1760/1856
[A[ATraining Step: 520  | total loss: [1m[32m0.06221[0m[0m | time: 655.538s
[2K
| Adam | epoch: 009 | loss: 0.06221 - acc: 0.9771 -- iter: 1792/1856
[A[ATraining Step: 521  | total loss: [1m[32m0.06100[0m[0m | time: 663.418s
[2K
| Adam | epoch: 009 | loss: 0.06100 - acc: 0.9763 -- iter: 1824/1856
[A[ATraining Step: 522  | total loss: [1m[32m0.06504[0m[0m | time: 697.424s
[2K
| Adam | epoch: 009 | loss: 0.06504 - acc: 0.9755 | val_loss: 0.93970 - val_acc: 0.7379 -- iter: 1856/1856
--
Training Step: 523  | total loss: [1m[32m0.06072[0m[0m | time: 8.068s
[2K
| Adam | epoch: 010 | loss: 0.06072 - acc: 0.9780 -- iter: 0032/1856
[A[ATraining Step: 524  | total loss: [1m[32m0.05563[0m[0m | time: 16.100s
[2K
| Adam | epoch: 010 | loss: 0.05563 - acc: 0.9802 -- iter: 0064/1856
[A[ATraining Step: 525  | total loss: [1m[32m0.07032[0m[0m | time: 23.922s
[2K
| Adam | epoch: 010 | loss: 0.07032 - acc: 0.9759 -- iter: 0096/1856
[A[ATraining Step: 526  | total loss: [1m[32m0.08474[0m[0m | time: 31.940s
[2K
| Adam | epoch: 010 | loss: 0.08474 - acc: 0.9658 -- iter: 0128/1856
[A[ATraining Step: 527  | total loss: [1m[32m0.08047[0m[0m | time: 39.743s
[2K
| Adam | epoch: 010 | loss: 0.08047 - acc: 0.9661 -- iter: 0160/1856
[A[ATraining Step: 528  | total loss: [1m[32m0.09554[0m[0m | time: 47.697s
[2K
| Adam | epoch: 010 | loss: 0.09554 - acc: 0.9633 -- iter: 0192/1856
[A[ATraining Step: 529  | total loss: [1m[32m0.09568[0m[0m | time: 55.404s
[2K
| Adam | epoch: 010 | loss: 0.09568 - acc: 0.9607 -- iter: 0224/1856
[A[ATraining Step: 530  | total loss: [1m[32m0.09276[0m[0m | time: 63.314s
[2K
| Adam | epoch: 010 | loss: 0.09276 - acc: 0.9615 -- iter: 0256/1856
[A[ATraining Step: 531  | total loss: [1m[32m0.08801[0m[0m | time: 71.273s
[2K
| Adam | epoch: 010 | loss: 0.08801 - acc: 0.9622 -- iter: 0288/1856
[A[ATraining Step: 532  | total loss: [1m[32m0.08074[0m[0m | time: 79.127s
[2K
| Adam | epoch: 010 | loss: 0.08074 - acc: 0.9660 -- iter: 0320/1856
[A[ATraining Step: 533  | total loss: [1m[32m0.09939[0m[0m | time: 86.914s
[2K
| Adam | epoch: 010 | loss: 0.09939 - acc: 0.9600 -- iter: 0352/1856
[A[ATraining Step: 534  | total loss: [1m[32m0.09433[0m[0m | time: 94.772s
[2K
| Adam | epoch: 010 | loss: 0.09433 - acc: 0.9640 -- iter: 0384/1856
[A[ATraining Step: 535  | total loss: [1m[32m0.08662[0m[0m | time: 102.722s
[2K
| Adam | epoch: 010 | loss: 0.08662 - acc: 0.9676 -- iter: 0416/1856
[A[ATraining Step: 536  | total loss: [1m[32m0.08543[0m[0m | time: 110.619s
[2K
| Adam | epoch: 010 | loss: 0.08543 - acc: 0.9677 -- iter: 0448/1856
[A[ATraining Step: 537  | total loss: [1m[32m0.09855[0m[0m | time: 118.568s
[2K
| Adam | epoch: 010 | loss: 0.09855 - acc: 0.9647 -- iter: 0480/1856
[A[ATraining Step: 538  | total loss: [1m[32m0.09872[0m[0m | time: 126.582s
[2K
| Adam | epoch: 010 | loss: 0.09872 - acc: 0.9651 -- iter: 0512/1856
[A[ATraining Step: 539  | total loss: [1m[32m0.09160[0m[0m | time: 134.579s
[2K
| Adam | epoch: 010 | loss: 0.09160 - acc: 0.9686 -- iter: 0544/1856
[A[ATraining Step: 540  | total loss: [1m[32m0.08826[0m[0m | time: 142.494s
[2K
| Adam | epoch: 010 | loss: 0.08826 - acc: 0.9686 -- iter: 0576/1856
[A[ATraining Step: 541  | total loss: [1m[32m0.08832[0m[0m | time: 150.381s
[2K
| Adam | epoch: 010 | loss: 0.08832 - acc: 0.9655 -- iter: 0608/1856
[A[ATraining Step: 542  | total loss: [1m[32m0.09155[0m[0m | time: 158.238s
[2K
| Adam | epoch: 010 | loss: 0.09155 - acc: 0.9627 -- iter: 0640/1856
[A[ATraining Step: 543  | total loss: [1m[32m0.09731[0m[0m | time: 166.251s
[2K
| Adam | epoch: 010 | loss: 0.09731 - acc: 0.9602 -- iter: 0672/1856
[A[ATraining Step: 544  | total loss: [1m[32m0.11421[0m[0m | time: 174.012s
[2K
| Adam | epoch: 010 | loss: 0.11421 - acc: 0.9579 -- iter: 0704/1856
[A[ATraining Step: 545  | total loss: [1m[32m0.12157[0m[0m | time: 181.734s
[2K
| Adam | epoch: 010 | loss: 0.12157 - acc: 0.9527 -- iter: 0736/1856
[A[ATraining Step: 546  | total loss: [1m[32m0.11041[0m[0m | time: 189.557s
[2K
| Adam | epoch: 010 | loss: 0.11041 - acc: 0.9575 -- iter: 0768/1856
[A[ATraining Step: 547  | total loss: [1m[32m0.10461[0m[0m | time: 197.461s
[2K
| Adam | epoch: 010 | loss: 0.10461 - acc: 0.9586 -- iter: 0800/1856
[A[ATraining Step: 548  | total loss: [1m[32m0.10301[0m[0m | time: 205.289s
[2K
| Adam | epoch: 010 | loss: 0.10301 - acc: 0.9596 -- iter: 0832/1856
[A[ATraining Step: 549  | total loss: [1m[32m0.10133[0m[0m | time: 213.196s
[2K
| Adam | epoch: 010 | loss: 0.10133 - acc: 0.9605 -- iter: 0864/1856
[A[ATraining Step: 550  | total loss: [1m[32m0.09487[0m[0m | time: 221.155s
[2K
| Adam | epoch: 010 | loss: 0.09487 - acc: 0.9645 -- iter: 0896/1856
[A[ATraining Step: 551  | total loss: [1m[32m0.09532[0m[0m | time: 229.214s
[2K
| Adam | epoch: 010 | loss: 0.09532 - acc: 0.9649 -- iter: 0928/1856
[A[ATraining Step: 552  | total loss: [1m[32m0.09441[0m[0m | time: 237.073s
[2K
| Adam | epoch: 010 | loss: 0.09441 - acc: 0.9653 -- iter: 0960/1856
[A[ATraining Step: 553  | total loss: [1m[32m0.09511[0m[0m | time: 245.117s
[2K
| Adam | epoch: 010 | loss: 0.09511 - acc: 0.9625 -- iter: 0992/1856
[A[ATraining Step: 554  | total loss: [1m[32m0.09846[0m[0m | time: 253.147s
[2K
| Adam | epoch: 010 | loss: 0.09846 - acc: 0.9600 -- iter: 1024/1856
[A[ATraining Step: 555  | total loss: [1m[32m0.09289[0m[0m | time: 261.055s
[2K
| Adam | epoch: 010 | loss: 0.09289 - acc: 0.9640 -- iter: 1056/1856
[A[ATraining Step: 556  | total loss: [1m[32m0.08698[0m[0m | time: 273.415s
[2K
| Adam | epoch: 010 | loss: 0.08698 - acc: 0.9676 -- iter: 1088/1856
[A[ATraining Step: 557  | total loss: [1m[32m0.08116[0m[0m | time: 285.066s
[2K
| Adam | epoch: 010 | loss: 0.08116 - acc: 0.9708 -- iter: 1120/1856
[A[ATraining Step: 558  | total loss: [1m[32m0.14286[0m[0m | time: 298.212s
[2K
| Adam | epoch: 010 | loss: 0.14286 - acc: 0.9644 -- iter: 1152/1856
[A[ATraining Step: 559  | total loss: [1m[32m0.13336[0m[0m | time: 311.383s
[2K
| Adam | epoch: 010 | loss: 0.13336 - acc: 0.9648 -- iter: 1184/1856
[A[ATraining Step: 560  | total loss: [1m[32m0.13075[0m[0m | time: 325.390s
[2K
| Adam | epoch: 010 | loss: 0.13075 - acc: 0.9621 -- iter: 1216/1856
[A[ATraining Step: 561  | total loss: [1m[32m0.12781[0m[0m | time: 339.084s
[2K
| Adam | epoch: 010 | loss: 0.12781 - acc: 0.9596 -- iter: 1248/1856
[A[ATraining Step: 562  | total loss: [1m[32m0.11565[0m[0m | time: 352.318s
[2K
| Adam | epoch: 010 | loss: 0.11565 - acc: 0.9637 -- iter: 1280/1856
[A[ATraining Step: 563  | total loss: [1m[32m0.10608[0m[0m | time: 365.559s
[2K
| Adam | epoch: 010 | loss: 0.10608 - acc: 0.9673 -- iter: 1312/1856
[A[ATraining Step: 564  | total loss: [1m[32m0.09728[0m[0m | time: 379.374s
[2K
| Adam | epoch: 010 | loss: 0.09728 - acc: 0.9706 -- iter: 1344/1856
[A[ATraining Step: 565  | total loss: [1m[32m0.09253[0m[0m | time: 392.732s
[2K
| Adam | epoch: 010 | loss: 0.09253 - acc: 0.9735 -- iter: 1376/1856
[A[ATraining Step: 566  | total loss: [1m[32m0.08481[0m[0m | time: 406.580s
[2K
| Adam | epoch: 010 | loss: 0.08481 - acc: 0.9762 -- iter: 1408/1856
[A[ATraining Step: 567  | total loss: [1m[32m0.08102[0m[0m | time: 420.254s
[2K
| Adam | epoch: 010 | loss: 0.08102 - acc: 0.9785 -- iter: 1440/1856
[A[ATraining Step: 568  | total loss: [1m[32m0.08039[0m[0m | time: 434.193s
[2K
| Adam | epoch: 010 | loss: 0.08039 - acc: 0.9776 -- iter: 1472/1856
[A[ATraining Step: 569  | total loss: [1m[32m0.08679[0m[0m | time: 447.453s
[2K
| Adam | epoch: 010 | loss: 0.08679 - acc: 0.9704 -- iter: 1504/1856
[A[ATraining Step: 570  | total loss: [1m[32m0.09097[0m[0m | time: 460.563s
[2K
| Adam | epoch: 010 | loss: 0.09097 - acc: 0.9703 -- iter: 1536/1856
[A[ATraining Step: 571  | total loss: [1m[32m0.08673[0m[0m | time: 473.796s
[2K
| Adam | epoch: 010 | loss: 0.08673 - acc: 0.9701 -- iter: 1568/1856
[A[ATraining Step: 572  | total loss: [1m[32m0.07987[0m[0m | time: 487.013s
[2K
| Adam | epoch: 010 | loss: 0.07987 - acc: 0.9731 -- iter: 1600/1856
[A[ATraining Step: 573  | total loss: [1m[32m0.07244[0m[0m | time: 500.636s
[2K
| Adam | epoch: 010 | loss: 0.07244 - acc: 0.9758 -- iter: 1632/1856
[A[ATraining Step: 574  | total loss: [1m[32m0.07203[0m[0m | time: 513.807s
[2K
| Adam | epoch: 010 | loss: 0.07203 - acc: 0.9751 -- iter: 1664/1856
[A[ATraining Step: 575  | total loss: [1m[32m0.07067[0m[0m | time: 527.620s
[2K
| Adam | epoch: 010 | loss: 0.07067 - acc: 0.9745 -- iter: 1696/1856
[A[ATraining Step: 576  | total loss: [1m[32m0.06514[0m[0m | time: 540.897s
[2K
| Adam | epoch: 010 | loss: 0.06514 - acc: 0.9770 -- iter: 1728/1856
[A[ATraining Step: 577  | total loss: [1m[32m0.06492[0m[0m | time: 554.419s
[2K
| Adam | epoch: 010 | loss: 0.06492 - acc: 0.9793 -- iter: 1760/1856
[A[ATraining Step: 578  | total loss: [1m[32m0.06948[0m[0m | time: 568.202s
[2K
| Adam | epoch: 010 | loss: 0.06948 - acc: 0.9751 -- iter: 1792/1856
[A[ATraining Step: 579  | total loss: [1m[32m0.06678[0m[0m | time: 582.156s
[2K
| Adam | epoch: 010 | loss: 0.06678 - acc: 0.9745 -- iter: 1824/1856
[A[ATraining Step: 580  | total loss: [1m[32m0.06060[0m[0m | time: 643.187s
[2K
| Adam | epoch: 010 | loss: 0.06060 - acc: 0.9770 | val_loss: 1.56058 - val_acc: 0.6983 -- iter: 1856/1856
--
Training Step: 581  | total loss: [1m[32m0.05509[0m[0m | time: 13.370s
[2K
| Adam | epoch: 011 | loss: 0.05509 - acc: 0.9793 -- iter: 0032/1856
[A[ATraining Step: 582  | total loss: [1m[32m0.05710[0m[0m | time: 27.193s
[2K
| Adam | epoch: 011 | loss: 0.05710 - acc: 0.9783 -- iter: 0064/1856
[A[ATraining Step: 583  | total loss: [1m[32m0.07060[0m[0m | time: 40.840s
[2K
| Adam | epoch: 011 | loss: 0.07060 - acc: 0.9773 -- iter: 0096/1856
[A[ATraining Step: 584  | total loss: [1m[32m0.07439[0m[0m | time: 54.172s
[2K
| Adam | epoch: 011 | loss: 0.07439 - acc: 0.9733 -- iter: 0128/1856
[A[ATraining Step: 585  | total loss: [1m[32m0.07913[0m[0m | time: 67.699s
[2K
| Adam | epoch: 011 | loss: 0.07913 - acc: 0.9666 -- iter: 0160/1856
[A[ATraining Step: 586  | total loss: [1m[32m0.07502[0m[0m | time: 81.097s
[2K
| Adam | epoch: 011 | loss: 0.07502 - acc: 0.9668 -- iter: 0192/1856
[A[ATraining Step: 587  | total loss: [1m[32m0.07400[0m[0m | time: 94.945s
[2K
| Adam | epoch: 011 | loss: 0.07400 - acc: 0.9670 -- iter: 0224/1856
[A[ATraining Step: 588  | total loss: [1m[32m0.07374[0m[0m | time: 108.517s
[2K
| Adam | epoch: 011 | loss: 0.07374 - acc: 0.9672 -- iter: 0256/1856
[A[ATraining Step: 589  | total loss: [1m[32m0.07081[0m[0m | time: 122.185s
[2K
| Adam | epoch: 011 | loss: 0.07081 - acc: 0.9705 -- iter: 0288/1856
[A[ATraining Step: 590  | total loss: [1m[32m0.07464[0m[0m | time: 135.807s
[2K
| Adam | epoch: 011 | loss: 0.07464 - acc: 0.9703 -- iter: 0320/1856
[A[ATraining Step: 591  | total loss: [1m[32m0.07164[0m[0m | time: 149.796s
[2K
| Adam | epoch: 011 | loss: 0.07164 - acc: 0.9733 -- iter: 0352/1856
[A[ATraining Step: 592  | total loss: [1m[32m0.06932[0m[0m | time: 162.059s
[2K
| Adam | epoch: 011 | loss: 0.06932 - acc: 0.9728 -- iter: 0384/1856
[A[ATraining Step: 593  | total loss: [1m[32m0.06436[0m[0m | time: 170.023s
[2K
| Adam | epoch: 011 | loss: 0.06436 - acc: 0.9755 -- iter: 0416/1856
[A[ATraining Step: 594  | total loss: [1m[32m0.05899[0m[0m | time: 183.346s
[2K
| Adam | epoch: 011 | loss: 0.05899 - acc: 0.9780 -- iter: 0448/1856
[A[ATraining Step: 595  | total loss: [1m[32m0.05362[0m[0m | time: 196.919s
[2K
| Adam | epoch: 011 | loss: 0.05362 - acc: 0.9802 -- iter: 0480/1856
[A[ATraining Step: 596  | total loss: [1m[32m0.04890[0m[0m | time: 208.059s
[2K
| Adam | epoch: 011 | loss: 0.04890 - acc: 0.9822 -- iter: 0512/1856
[A[ATraining Step: 597  | total loss: [1m[32m0.06493[0m[0m | time: 216.241s
[2K
| Adam | epoch: 011 | loss: 0.06493 - acc: 0.9777 -- iter: 0544/1856
[A[ATraining Step: 598  | total loss: [1m[32m0.06121[0m[0m | time: 224.145s
[2K
| Adam | epoch: 011 | loss: 0.06121 - acc: 0.9799 -- iter: 0576/1856
[A[ATraining Step: 599  | total loss: [1m[32m0.06280[0m[0m | time: 232.104s
[2K
| Adam | epoch: 011 | loss: 0.06280 - acc: 0.9788 -- iter: 0608/1856
[A[ATraining Step: 600  | total loss: [1m[32m0.05707[0m[0m | time: 283.639s
[2K
| Adam | epoch: 011 | loss: 0.05707 - acc: 0.9809 | val_loss: 0.17086 - val_acc: 0.9431 -- iter: 0640/1856
--
Training Step: 601  | total loss: [1m[32m0.05632[0m[0m | time: 296.849s
[2K
| Adam | epoch: 011 | loss: 0.05632 - acc: 0.9797 -- iter: 0672/1856
[A[ATraining Step: 602  | total loss: [1m[32m0.05459[0m[0m | time: 310.702s
[2K
| Adam | epoch: 011 | loss: 0.05459 - acc: 0.9786 -- iter: 0704/1856
[A[ATraining Step: 603  | total loss: [1m[32m0.05057[0m[0m | time: 325.699s
[2K
| Adam | epoch: 011 | loss: 0.05057 - acc: 0.9808 -- iter: 0736/1856
[A[ATraining Step: 604  | total loss: [1m[32m0.05066[0m[0m | time: 340.819s
[2K
| Adam | epoch: 011 | loss: 0.05066 - acc: 0.9796 -- iter: 0768/1856
[A[ATraining Step: 605  | total loss: [1m[32m0.04595[0m[0m | time: 356.160s
[2K
| Adam | epoch: 011 | loss: 0.04595 - acc: 0.9816 -- iter: 0800/1856
[A[ATraining Step: 606  | total loss: [1m[32m0.04253[0m[0m | time: 371.667s
[2K
| Adam | epoch: 011 | loss: 0.04253 - acc: 0.9834 -- iter: 0832/1856
[A[ATraining Step: 607  | total loss: [1m[32m0.03950[0m[0m | time: 387.081s
[2K
| Adam | epoch: 011 | loss: 0.03950 - acc: 0.9851 -- iter: 0864/1856
[A[ATraining Step: 608  | total loss: [1m[32m0.03867[0m[0m | time: 402.179s
[2K
| Adam | epoch: 011 | loss: 0.03867 - acc: 0.9866 -- iter: 0896/1856
[A[ATraining Step: 609  | total loss: [1m[32m0.03748[0m[0m | time: 417.868s
[2K
| Adam | epoch: 011 | loss: 0.03748 - acc: 0.9879 -- iter: 0928/1856
[A[ATraining Step: 610  | total loss: [1m[32m0.03470[0m[0m | time: 433.760s
[2K
| Adam | epoch: 011 | loss: 0.03470 - acc: 0.9891 -- iter: 0960/1856
[A[ATraining Step: 611  | total loss: [1m[32m0.03453[0m[0m | time: 450.742s
[2K
| Adam | epoch: 011 | loss: 0.03453 - acc: 0.9871 -- iter: 0992/1856
[A[ATraining Step: 612  | total loss: [1m[32m0.03460[0m[0m | time: 466.880s
[2K
| Adam | epoch: 011 | loss: 0.03460 - acc: 0.9853 -- iter: 1024/1856
[A[ATraining Step: 613  | total loss: [1m[32m0.03165[0m[0m | time: 482.381s
[2K
| Adam | epoch: 011 | loss: 0.03165 - acc: 0.9867 -- iter: 1056/1856
[A[ATraining Step: 614  | total loss: [1m[32m0.03269[0m[0m | time: 497.281s
[2K
| Adam | epoch: 011 | loss: 0.03269 - acc: 0.9881 -- iter: 1088/1856
[A[ATraining Step: 615  | total loss: [1m[32m0.03576[0m[0m | time: 513.088s
[2K
| Adam | epoch: 011 | loss: 0.03576 - acc: 0.9861 -- iter: 1120/1856
[A[ATraining Step: 616  | total loss: [1m[32m0.04582[0m[0m | time: 528.386s
[2K
| Adam | epoch: 011 | loss: 0.04582 - acc: 0.9844 -- iter: 1152/1856
[A[ATraining Step: 617  | total loss: [1m[32m0.05983[0m[0m | time: 543.624s
[2K
| Adam | epoch: 011 | loss: 0.05983 - acc: 0.9828 -- iter: 1184/1856
[A[ATraining Step: 618  | total loss: [1m[32m0.05455[0m[0m | time: 558.942s
[2K
| Adam | epoch: 011 | loss: 0.05455 - acc: 0.9845 -- iter: 1216/1856
[A[ATraining Step: 619  | total loss: [1m[32m0.05084[0m[0m | time: 574.003s
[2K
| Adam | epoch: 011 | loss: 0.05084 - acc: 0.9861 -- iter: 1248/1856
[A[ATraining Step: 620  | total loss: [1m[32m0.04593[0m[0m | time: 588.839s
[2K
| Adam | epoch: 011 | loss: 0.04593 - acc: 0.9875 -- iter: 1280/1856
[A[ATraining Step: 621  | total loss: [1m[32m0.04166[0m[0m | time: 604.394s
[2K
| Adam | epoch: 011 | loss: 0.04166 - acc: 0.9887 -- iter: 1312/1856
[A[ATraining Step: 622  | total loss: [1m[32m0.03902[0m[0m | time: 618.826s
[2K
| Adam | epoch: 011 | loss: 0.03902 - acc: 0.9899 -- iter: 1344/1856
[A[ATraining Step: 623  | total loss: [1m[32m0.04357[0m[0m | time: 634.284s
[2K
| Adam | epoch: 011 | loss: 0.04357 - acc: 0.9877 -- iter: 1376/1856
[A[ATraining Step: 624  | total loss: [1m[32m0.04316[0m[0m | time: 649.128s
[2K
| Adam | epoch: 011 | loss: 0.04316 - acc: 0.9858 -- iter: 1408/1856
[A[ATraining Step: 625  | total loss: [1m[32m0.04041[0m[0m | time: 664.647s
[2K
| Adam | epoch: 011 | loss: 0.04041 - acc: 0.9873 -- iter: 1440/1856
[A[ATraining Step: 626  | total loss: [1m[32m0.03766[0m[0m | time: 680.219s
[2K
| Adam | epoch: 011 | loss: 0.03766 - acc: 0.9885 -- iter: 1472/1856
[A[ATraining Step: 627  | total loss: [1m[32m0.05184[0m[0m | time: 695.590s
[2K
| Adam | epoch: 011 | loss: 0.05184 - acc: 0.9866 -- iter: 1504/1856
[A[ATraining Step: 628  | total loss: [1m[32m0.05648[0m[0m | time: 713.103s
[2K
| Adam | epoch: 011 | loss: 0.05648 - acc: 0.9848 -- iter: 1536/1856
[A[ATraining Step: 629  | total loss: [1m[32m0.05131[0m[0m | time: 727.753s
[2K
| Adam | epoch: 011 | loss: 0.05131 - acc: 0.9863 -- iter: 1568/1856
[A[ATraining Step: 630  | total loss: [1m[32m0.04726[0m[0m | time: 741.167s
[2K
| Adam | epoch: 011 | loss: 0.04726 - acc: 0.9877 -- iter: 1600/1856
[A[ATraining Step: 631  | total loss: [1m[32m0.04476[0m[0m | time: 754.045s
[2K
| Adam | epoch: 011 | loss: 0.04476 - acc: 0.9889 -- iter: 1632/1856
[A[ATraining Step: 632  | total loss: [1m[32m0.04431[0m[0m | time: 766.798s
[2K
| Adam | epoch: 011 | loss: 0.04431 - acc: 0.9869 -- iter: 1664/1856
[A[ATraining Step: 633  | total loss: [1m[32m0.04172[0m[0m | time: 779.829s
[2K
| Adam | epoch: 011 | loss: 0.04172 - acc: 0.9882 -- iter: 1696/1856
[A[ATraining Step: 634  | total loss: [1m[32m0.03792[0m[0m | time: 792.861s
[2K
| Adam | epoch: 011 | loss: 0.03792 - acc: 0.9894 -- iter: 1728/1856
[A[ATraining Step: 635  | total loss: [1m[32m0.03477[0m[0m | time: 805.684s
[2K
| Adam | epoch: 011 | loss: 0.03477 - acc: 0.9904 -- iter: 1760/1856
[A[ATraining Step: 636  | total loss: [1m[32m0.04281[0m[0m | time: 818.779s
[2K
| Adam | epoch: 011 | loss: 0.04281 - acc: 0.9883 -- iter: 1792/1856
[A[ATraining Step: 637  | total loss: [1m[32m0.03957[0m[0m | time: 831.434s
[2K
| Adam | epoch: 011 | loss: 0.03957 - acc: 0.9894 -- iter: 1824/1856
[A[ATraining Step: 638  | total loss: [1m[32m0.03606[0m[0m | time: 882.894s
[2K
| Adam | epoch: 011 | loss: 0.03606 - acc: 0.9905 | val_loss: 0.20606 - val_acc: 0.9328 -- iter: 1856/1856
--
Training Step: 639  | total loss: [1m[32m0.03260[0m[0m | time: 13.510s
[2K
| Adam | epoch: 012 | loss: 0.03260 - acc: 0.9915 -- iter: 0032/1856
[A[ATraining Step: 640  | total loss: [1m[32m0.03019[0m[0m | time: 26.661s
[2K
| Adam | epoch: 012 | loss: 0.03019 - acc: 0.9923 -- iter: 0064/1856
[A[ATraining Step: 641  | total loss: [1m[32m0.03342[0m[0m | time: 39.794s
[2K
| Adam | epoch: 012 | loss: 0.03342 - acc: 0.9899 -- iter: 0096/1856
[A[ATraining Step: 642  | total loss: [1m[32m0.03078[0m[0m | time: 52.547s
[2K
| Adam | epoch: 012 | loss: 0.03078 - acc: 0.9910 -- iter: 0128/1856
[A[ATraining Step: 643  | total loss: [1m[32m0.03230[0m[0m | time: 65.313s
[2K
| Adam | epoch: 012 | loss: 0.03230 - acc: 0.9887 -- iter: 0160/1856
[A[ATraining Step: 644  | total loss: [1m[32m0.02950[0m[0m | time: 78.582s
[2K
| Adam | epoch: 012 | loss: 0.02950 - acc: 0.9899 -- iter: 0192/1856
[A[ATraining Step: 645  | total loss: [1m[32m0.03351[0m[0m | time: 92.121s
[2K
| Adam | epoch: 012 | loss: 0.03351 - acc: 0.9877 -- iter: 0224/1856
[A[ATraining Step: 646  | total loss: [1m[32m0.03162[0m[0m | time: 105.042s
[2K
| Adam | epoch: 012 | loss: 0.03162 - acc: 0.9890 -- iter: 0256/1856
[A[ATraining Step: 647  | total loss: [1m[32m0.02951[0m[0m | time: 118.296s
[2K
| Adam | epoch: 012 | loss: 0.02951 - acc: 0.9901 -- iter: 0288/1856
[A[ATraining Step: 648  | total loss: [1m[32m0.03135[0m[0m | time: 131.826s
[2K
| Adam | epoch: 012 | loss: 0.03135 - acc: 0.9879 -- iter: 0320/1856
[A[ATraining Step: 649  | total loss: [1m[32m0.03210[0m[0m | time: 145.128s
[2K
| Adam | epoch: 012 | loss: 0.03210 - acc: 0.9860 -- iter: 0352/1856
[A[ATraining Step: 650  | total loss: [1m[32m0.02958[0m[0m | time: 157.763s
[2K
| Adam | epoch: 012 | loss: 0.02958 - acc: 0.9874 -- iter: 0384/1856
[A[ATraining Step: 651  | total loss: [1m[32m0.02677[0m[0m | time: 174.091s
[2K
| Adam | epoch: 012 | loss: 0.02677 - acc: 0.9887 -- iter: 0416/1856
[A[ATraining Step: 652  | total loss: [1m[32m0.02713[0m[0m | time: 188.763s
[2K
| Adam | epoch: 012 | loss: 0.02713 - acc: 0.9867 -- iter: 0448/1856
[A[ATraining Step: 653  | total loss: [1m[32m0.03438[0m[0m | time: 202.120s
[2K
| Adam | epoch: 012 | loss: 0.03438 - acc: 0.9818 -- iter: 0480/1856
[A[ATraining Step: 654  | total loss: [1m[32m0.03184[0m[0m | time: 215.454s
[2K
| Adam | epoch: 012 | loss: 0.03184 - acc: 0.9836 -- iter: 0512/1856
[A[ATraining Step: 655  | total loss: [1m[32m0.03744[0m[0m | time: 228.564s
[2K
| Adam | epoch: 012 | loss: 0.03744 - acc: 0.9821 -- iter: 0544/1856
[A[ATraining Step: 656  | total loss: [1m[32m0.03427[0m[0m | time: 241.954s
[2K
| Adam | epoch: 012 | loss: 0.03427 - acc: 0.9839 -- iter: 0576/1856
[A[ATraining Step: 657  | total loss: [1m[32m0.03117[0m[0m | time: 255.204s
[2K
| Adam | epoch: 012 | loss: 0.03117 - acc: 0.9855 -- iter: 0608/1856
[A[ATraining Step: 658  | total loss: [1m[32m0.03101[0m[0m | time: 267.904s
[2K
| Adam | epoch: 012 | loss: 0.03101 - acc: 0.9870 -- iter: 0640/1856
[A[ATraining Step: 659  | total loss: [1m[32m0.03319[0m[0m | time: 280.815s
[2K
| Adam | epoch: 012 | loss: 0.03319 - acc: 0.9851 -- iter: 0672/1856
[A[ATraining Step: 660  | total loss: [1m[32m0.03267[0m[0m | time: 293.584s
[2K
| Adam | epoch: 012 | loss: 0.03267 - acc: 0.9866 -- iter: 0704/1856
[A[ATraining Step: 661  | total loss: [1m[32m0.02960[0m[0m | time: 306.661s
[2K
| Adam | epoch: 012 | loss: 0.02960 - acc: 0.9880 -- iter: 0736/1856
[A[ATraining Step: 662  | total loss: [1m[32m0.03025[0m[0m | time: 319.934s
[2K
| Adam | epoch: 012 | loss: 0.03025 - acc: 0.9860 -- iter: 0768/1856
[A[ATraining Step: 663  | total loss: [1m[32m0.03190[0m[0m | time: 333.126s
[2K
| Adam | epoch: 012 | loss: 0.03190 - acc: 0.9843 -- iter: 0800/1856
[A[ATraining Step: 664  | total loss: [1m[32m0.02887[0m[0m | time: 346.299s
[2K
| Adam | epoch: 012 | loss: 0.02887 - acc: 0.9859 -- iter: 0832/1856
[A[ATraining Step: 665  | total loss: [1m[32m0.02859[0m[0m | time: 359.471s
[2K
| Adam | epoch: 012 | loss: 0.02859 - acc: 0.9873 -- iter: 0864/1856
[A[ATraining Step: 666  | total loss: [1m[32m0.02630[0m[0m | time: 372.518s
[2K
| Adam | epoch: 012 | loss: 0.02630 - acc: 0.9886 -- iter: 0896/1856
[A[ATraining Step: 667  | total loss: [1m[32m0.02476[0m[0m | time: 386.344s
[2K
| Adam | epoch: 012 | loss: 0.02476 - acc: 0.9897 -- iter: 0928/1856
[A[ATraining Step: 668  | total loss: [1m[32m0.02343[0m[0m | time: 400.426s
[2K
| Adam | epoch: 012 | loss: 0.02343 - acc: 0.9907 -- iter: 0960/1856
[A[ATraining Step: 669  | total loss: [1m[32m0.02424[0m[0m | time: 413.829s
[2K
| Adam | epoch: 012 | loss: 0.02424 - acc: 0.9917 -- iter: 0992/1856
[A[ATraining Step: 670  | total loss: [1m[32m0.02302[0m[0m | time: 427.135s
[2K
| Adam | epoch: 012 | loss: 0.02302 - acc: 0.9925 -- iter: 1024/1856
[A[ATraining Step: 671  | total loss: [1m[32m0.02507[0m[0m | time: 439.905s
[2K
| Adam | epoch: 012 | loss: 0.02507 - acc: 0.9901 -- iter: 1056/1856
[A[ATraining Step: 672  | total loss: [1m[32m0.02354[0m[0m | time: 452.726s
[2K
| Adam | epoch: 012 | loss: 0.02354 - acc: 0.9911 -- iter: 1088/1856
[A[ATraining Step: 673  | total loss: [1m[32m0.02174[0m[0m | time: 465.905s
[2K
| Adam | epoch: 012 | loss: 0.02174 - acc: 0.9920 -- iter: 1120/1856
[A[ATraining Step: 674  | total loss: [1m[32m0.02008[0m[0m | time: 479.151s
[2K
| Adam | epoch: 012 | loss: 0.02008 - acc: 0.9928 -- iter: 1152/1856
[A[ATraining Step: 675  | total loss: [1m[32m0.01813[0m[0m | time: 492.295s
[2K
| Adam | epoch: 012 | loss: 0.01813 - acc: 0.9935 -- iter: 1184/1856
[A[ATraining Step: 676  | total loss: [1m[32m0.06153[0m[0m | time: 505.094s
[2K
| Adam | epoch: 012 | loss: 0.06153 - acc: 0.9754 -- iter: 1216/1856
[A[ATraining Step: 677  | total loss: [1m[32m0.05982[0m[0m | time: 518.059s
[2K
| Adam | epoch: 012 | loss: 0.05982 - acc: 0.9779 -- iter: 1248/1856
[A[ATraining Step: 678  | total loss: [1m[32m0.05770[0m[0m | time: 531.781s
[2K
| Adam | epoch: 012 | loss: 0.05770 - acc: 0.9770 -- iter: 1280/1856
[A[ATraining Step: 679  | total loss: [1m[32m0.05397[0m[0m | time: 545.206s
[2K
| Adam | epoch: 012 | loss: 0.05397 - acc: 0.9793 -- iter: 1312/1856
[A[ATraining Step: 680  | total loss: [1m[32m0.04987[0m[0m | time: 559.061s
[2K
| Adam | epoch: 012 | loss: 0.04987 - acc: 0.9813 -- iter: 1344/1856
[A[ATraining Step: 681  | total loss: [1m[32m0.04554[0m[0m | time: 572.465s
[2K
| Adam | epoch: 012 | loss: 0.04554 - acc: 0.9832 -- iter: 1376/1856
[A[ATraining Step: 682  | total loss: [1m[32m0.04234[0m[0m | time: 583.364s
[2K
| Adam | epoch: 012 | loss: 0.04234 - acc: 0.9849 -- iter: 1408/1856
[A[ATraining Step: 683  | total loss: [1m[32m0.03856[0m[0m | time: 591.420s
[2K
| Adam | epoch: 012 | loss: 0.03856 - acc: 0.9864 -- iter: 1440/1856
[A[ATraining Step: 684  | total loss: [1m[32m0.03630[0m[0m | time: 599.341s
[2K
| Adam | epoch: 012 | loss: 0.03630 - acc: 0.9878 -- iter: 1472/1856
[A[ATraining Step: 685  | total loss: [1m[32m0.03288[0m[0m | time: 609.768s
[2K
| Adam | epoch: 012 | loss: 0.03288 - acc: 0.9890 -- iter: 1504/1856
[A[ATraining Step: 686  | total loss: [1m[32m0.04444[0m[0m | time: 621.362s
[2K
| Adam | epoch: 012 | loss: 0.04444 - acc: 0.9870 -- iter: 1536/1856
[A[ATraining Step: 687  | total loss: [1m[32m0.04258[0m[0m | time: 636.250s
[2K
| Adam | epoch: 012 | loss: 0.04258 - acc: 0.9883 -- iter: 1568/1856
[A[ATraining Step: 688  | total loss: [1m[32m0.04017[0m[0m | time: 649.210s
[2K
| Adam | epoch: 012 | loss: 0.04017 - acc: 0.9894 -- iter: 1600/1856
[A[ATraining Step: 689  | total loss: [1m[32m0.03718[0m[0m | time: 662.116s
[2K
| Adam | epoch: 012 | loss: 0.03718 - acc: 0.9905 -- iter: 1632/1856
[A[ATraining Step: 690  | total loss: [1m[32m0.03563[0m[0m | time: 675.161s
[2K
| Adam | epoch: 012 | loss: 0.03563 - acc: 0.9914 -- iter: 1664/1856
[A[ATraining Step: 691  | total loss: [1m[32m0.03643[0m[0m | time: 687.975s
[2K
| Adam | epoch: 012 | loss: 0.03643 - acc: 0.9892 -- iter: 1696/1856
[A[ATraining Step: 692  | total loss: [1m[32m0.03815[0m[0m | time: 701.233s
[2K
| Adam | epoch: 012 | loss: 0.03815 - acc: 0.9903 -- iter: 1728/1856
[A[ATraining Step: 693  | total loss: [1m[32m0.03452[0m[0m | time: 714.192s
[2K
| Adam | epoch: 012 | loss: 0.03452 - acc: 0.9912 -- iter: 1760/1856
[A[ATraining Step: 694  | total loss: [1m[32m0.03138[0m[0m | time: 726.869s
[2K
| Adam | epoch: 012 | loss: 0.03138 - acc: 0.9921 -- iter: 1792/1856
[A[ATraining Step: 695  | total loss: [1m[32m0.02892[0m[0m | time: 739.533s
[2K
| Adam | epoch: 012 | loss: 0.02892 - acc: 0.9929 -- iter: 1824/1856
[A[ATraining Step: 696  | total loss: [1m[32m0.02865[0m[0m | time: 797.718s
[2K
| Adam | epoch: 012 | loss: 0.02865 - acc: 0.9905 | val_loss: 0.47872 - val_acc: 0.8655 -- iter: 1856/1856
--
Training Step: 697  | total loss: [1m[32m0.03094[0m[0m | time: 13.064s
[2K
| Adam | epoch: 013 | loss: 0.03094 - acc: 0.9883 -- iter: 0032/1856
[A[ATraining Step: 698  | total loss: [1m[32m0.02829[0m[0m | time: 25.806s
[2K
| Adam | epoch: 013 | loss: 0.02829 - acc: 0.9895 -- iter: 0064/1856
[A[ATraining Step: 699  | total loss: [1m[32m0.02600[0m[0m | time: 38.585s
[2K
| Adam | epoch: 013 | loss: 0.02600 - acc: 0.9905 -- iter: 0096/1856
[A[ATraining Step: 700  | total loss: [1m[32m0.02795[0m[0m | time: 51.636s
[2K
| Adam | epoch: 013 | loss: 0.02795 - acc: 0.9884 -- iter: 0128/1856
[A[ATraining Step: 701  | total loss: [1m[32m0.03216[0m[0m | time: 64.456s
[2K
| Adam | epoch: 013 | loss: 0.03216 - acc: 0.9864 -- iter: 0160/1856
[A[ATraining Step: 702  | total loss: [1m[32m0.02983[0m[0m | time: 77.466s
[2K
| Adam | epoch: 013 | loss: 0.02983 - acc: 0.9878 -- iter: 0192/1856
[A[ATraining Step: 703  | total loss: [1m[32m0.02726[0m[0m | time: 90.797s
[2K
| Adam | epoch: 013 | loss: 0.02726 - acc: 0.9890 -- iter: 0224/1856
[A[ATraining Step: 704  | total loss: [1m[32m0.03265[0m[0m | time: 103.766s
[2K
| Adam | epoch: 013 | loss: 0.03265 - acc: 0.9838 -- iter: 0256/1856
[A[ATraining Step: 705  | total loss: [1m[32m0.02980[0m[0m | time: 116.886s
[2K
| Adam | epoch: 013 | loss: 0.02980 - acc: 0.9854 -- iter: 0288/1856
[A[ATraining Step: 706  | total loss: [1m[32m0.03712[0m[0m | time: 130.171s
[2K
| Adam | epoch: 013 | loss: 0.03712 - acc: 0.9838 -- iter: 0320/1856
[A[ATraining Step: 707  | total loss: [1m[32m0.04277[0m[0m | time: 146.128s
[2K
| Adam | epoch: 013 | loss: 0.04277 - acc: 0.9823 -- iter: 0352/1856
[A[ATraining Step: 708  | total loss: [1m[32m0.05640[0m[0m | time: 158.988s
[2K
| Adam | epoch: 013 | loss: 0.05640 - acc: 0.9715 -- iter: 0384/1856
[A[ATraining Step: 709  | total loss: [1m[32m0.05304[0m[0m | time: 171.881s
[2K
| Adam | epoch: 013 | loss: 0.05304 - acc: 0.9744 -- iter: 0416/1856
[A[ATraining Step: 710  | total loss: [1m[32m0.05414[0m[0m | time: 185.165s
[2K
| Adam | epoch: 013 | loss: 0.05414 - acc: 0.9738 -- iter: 0448/1856
[A[ATraining Step: 711  | total loss: [1m[32m0.05046[0m[0m | time: 198.551s
[2K
| Adam | epoch: 013 | loss: 0.05046 - acc: 0.9764 -- iter: 0480/1856
[A[ATraining Step: 712  | total loss: [1m[32m0.04594[0m[0m | time: 211.511s
[2K
| Adam | epoch: 013 | loss: 0.04594 - acc: 0.9788 -- iter: 0512/1856
[A[ATraining Step: 713  | total loss: [1m[32m0.06265[0m[0m | time: 224.731s
[2K
| Adam | epoch: 013 | loss: 0.06265 - acc: 0.9778 -- iter: 0544/1856
[A[ATraining Step: 714  | total loss: [1m[32m0.06297[0m[0m | time: 237.604s
[2K
| Adam | epoch: 013 | loss: 0.06297 - acc: 0.9769 -- iter: 0576/1856
[A[ATraining Step: 715  | total loss: [1m[32m0.06317[0m[0m | time: 250.842s
[2K
| Adam | epoch: 013 | loss: 0.06317 - acc: 0.9730 -- iter: 0608/1856
[A[ATraining Step: 716  | total loss: [1m[32m0.05737[0m[0m | time: 263.787s
[2K
| Adam | epoch: 013 | loss: 0.05737 - acc: 0.9757 -- iter: 0640/1856
[A[ATraining Step: 717  | total loss: [1m[32m0.05466[0m[0m | time: 276.635s
[2K
| Adam | epoch: 013 | loss: 0.05466 - acc: 0.9750 -- iter: 0672/1856
[A[ATraining Step: 718  | total loss: [1m[32m0.05551[0m[0m | time: 289.639s
[2K
| Adam | epoch: 013 | loss: 0.05551 - acc: 0.9743 -- iter: 0704/1856
[A[ATraining Step: 719  | total loss: [1m[32m0.05369[0m[0m | time: 302.811s
[2K
| Adam | epoch: 013 | loss: 0.05369 - acc: 0.9769 -- iter: 0736/1856
[A[ATraining Step: 720  | total loss: [1m[32m0.04909[0m[0m | time: 316.434s
[2K
| Adam | epoch: 013 | loss: 0.04909 - acc: 0.9792 -- iter: 0768/1856
[A[ATraining Step: 721  | total loss: [1m[32m0.04668[0m[0m | time: 329.438s
[2K
| Adam | epoch: 013 | loss: 0.04668 - acc: 0.9813 -- iter: 0800/1856
[A[ATraining Step: 722  | total loss: [1m[32m0.05351[0m[0m | time: 343.170s
[2K
| Adam | epoch: 013 | loss: 0.05351 - acc: 0.9769 -- iter: 0832/1856
[A[ATraining Step: 723  | total loss: [1m[32m0.06057[0m[0m | time: 356.906s
[2K
| Adam | epoch: 013 | loss: 0.06057 - acc: 0.9761 -- iter: 0864/1856
[A[ATraining Step: 724  | total loss: [1m[32m0.06925[0m[0m | time: 367.523s
[2K
| Adam | epoch: 013 | loss: 0.06925 - acc: 0.9722 -- iter: 0896/1856
[A[ATraining Step: 725  | total loss: [1m[32m0.06566[0m[0m | time: 375.686s
[2K
| Adam | epoch: 013 | loss: 0.06566 - acc: 0.9719 -- iter: 0928/1856
[A[ATraining Step: 726  | total loss: [1m[32m0.05969[0m[0m | time: 383.719s
[2K
| Adam | epoch: 013 | loss: 0.05969 - acc: 0.9747 -- iter: 0960/1856
[A[ATraining Step: 727  | total loss: [1m[32m0.06446[0m[0m | time: 391.786s
[2K
| Adam | epoch: 013 | loss: 0.06446 - acc: 0.9741 -- iter: 0992/1856
[A[ATraining Step: 728  | total loss: [1m[32m0.06120[0m[0m | time: 399.996s
[2K
| Adam | epoch: 013 | loss: 0.06120 - acc: 0.9767 -- iter: 1024/1856
[A[ATraining Step: 729  | total loss: [1m[32m0.05632[0m[0m | time: 413.410s
[2K
| Adam | epoch: 013 | loss: 0.05632 - acc: 0.9790 -- iter: 1056/1856
[A[ATraining Step: 730  | total loss: [1m[32m0.12519[0m[0m | time: 426.365s
[2K
| Adam | epoch: 013 | loss: 0.12519 - acc: 0.9624 -- iter: 1088/1856
[A[ATraining Step: 731  | total loss: [1m[32m0.12048[0m[0m | time: 438.513s
[2K
| Adam | epoch: 013 | loss: 0.12048 - acc: 0.9630 -- iter: 1120/1856
[A[ATraining Step: 732  | total loss: [1m[32m0.11906[0m[0m | time: 451.256s
[2K
| Adam | epoch: 013 | loss: 0.11906 - acc: 0.9636 -- iter: 1152/1856
[A[ATraining Step: 733  | total loss: [1m[32m0.10772[0m[0m | time: 464.935s
[2K
| Adam | epoch: 013 | loss: 0.10772 - acc: 0.9672 -- iter: 1184/1856
[A[ATraining Step: 734  | total loss: [1m[32m0.09856[0m[0m | time: 478.209s
[2K
| Adam | epoch: 013 | loss: 0.09856 - acc: 0.9705 -- iter: 1216/1856
[A[ATraining Step: 735  | total loss: [1m[32m0.11705[0m[0m | time: 491.247s
[2K
| Adam | epoch: 013 | loss: 0.11705 - acc: 0.9672 -- iter: 1248/1856
[A[ATraining Step: 736  | total loss: [1m[32m0.11063[0m[0m | time: 504.519s
[2K
| Adam | epoch: 013 | loss: 0.11063 - acc: 0.9674 -- iter: 1280/1856
[A[ATraining Step: 737  | total loss: [1m[32m0.10303[0m[0m | time: 518.815s
[2K
| Adam | epoch: 013 | loss: 0.10303 - acc: 0.9706 -- iter: 1312/1856
[A[ATraining Step: 738  | total loss: [1m[32m0.09762[0m[0m | time: 531.708s
[2K
| Adam | epoch: 013 | loss: 0.09762 - acc: 0.9736 -- iter: 1344/1856
[A[ATraining Step: 739  | total loss: [1m[32m0.10030[0m[0m | time: 545.133s
[2K
| Adam | epoch: 013 | loss: 0.10030 - acc: 0.9700 -- iter: 1376/1856
[A[ATraining Step: 740  | total loss: [1m[32m0.11298[0m[0m | time: 558.687s
[2K
| Adam | epoch: 013 | loss: 0.11298 - acc: 0.9667 -- iter: 1408/1856
[A[ATraining Step: 741  | total loss: [1m[32m0.10242[0m[0m | time: 568.996s
[2K
| Adam | epoch: 013 | loss: 0.10242 - acc: 0.9700 -- iter: 1440/1856
[A[ATraining Step: 742  | total loss: [1m[32m0.09447[0m[0m | time: 577.106s
[2K
| Adam | epoch: 013 | loss: 0.09447 - acc: 0.9730 -- iter: 1472/1856
[A[ATraining Step: 743  | total loss: [1m[32m0.08772[0m[0m | time: 589.147s
[2K
| Adam | epoch: 013 | loss: 0.08772 - acc: 0.9757 -- iter: 1504/1856
[A[ATraining Step: 744  | total loss: [1m[32m0.08065[0m[0m | time: 602.507s
[2K
| Adam | epoch: 013 | loss: 0.08065 - acc: 0.9782 -- iter: 1536/1856
[A[ATraining Step: 745  | total loss: [1m[32m0.07476[0m[0m | time: 615.503s
[2K
| Adam | epoch: 013 | loss: 0.07476 - acc: 0.9803 -- iter: 1568/1856
[A[ATraining Step: 746  | total loss: [1m[32m0.07004[0m[0m | time: 628.386s
[2K
| Adam | epoch: 013 | loss: 0.07004 - acc: 0.9823 -- iter: 1600/1856
[A[ATraining Step: 747  | total loss: [1m[32m0.06485[0m[0m | time: 641.765s
[2K
| Adam | epoch: 013 | loss: 0.06485 - acc: 0.9841 -- iter: 1632/1856
[A[ATraining Step: 748  | total loss: [1m[32m0.06026[0m[0m | time: 655.125s
[2K
| Adam | epoch: 013 | loss: 0.06026 - acc: 0.9857 -- iter: 1664/1856
[A[ATraining Step: 749  | total loss: [1m[32m0.05505[0m[0m | time: 668.204s
[2K
| Adam | epoch: 013 | loss: 0.05505 - acc: 0.9871 -- iter: 1696/1856
[A[ATraining Step: 750  | total loss: [1m[32m0.05469[0m[0m | time: 681.546s
[2K
| Adam | epoch: 013 | loss: 0.05469 - acc: 0.9853 -- iter: 1728/1856
[A[ATraining Step: 751  | total loss: [1m[32m0.05214[0m[0m | time: 694.723s
[2K
| Adam | epoch: 013 | loss: 0.05214 - acc: 0.9836 -- iter: 1760/1856
[A[ATraining Step: 752  | total loss: [1m[32m0.05048[0m[0m | time: 707.762s
[2K
| Adam | epoch: 013 | loss: 0.05048 - acc: 0.9821 -- iter: 1792/1856
[A[ATraining Step: 753  | total loss: [1m[32m0.04732[0m[0m | time: 720.521s
[2K
| Adam | epoch: 013 | loss: 0.04732 - acc: 0.9839 -- iter: 1824/1856
[A[ATraining Step: 754  | total loss: [1m[32m0.04362[0m[0m | time: 777.615s
[2K
| Adam | epoch: 013 | loss: 0.04362 - acc: 0.9855 | val_loss: 0.23413 - val_acc: 0.9224 -- iter: 1856/1856
--
Training Step: 755  | total loss: [1m[32m0.04519[0m[0m | time: 13.124s
[2K
| Adam | epoch: 014 | loss: 0.04519 - acc: 0.9838 -- iter: 0032/1856
[A[ATraining Step: 756  | total loss: [1m[32m0.04116[0m[0m | time: 26.410s
[2K
| Adam | epoch: 014 | loss: 0.04116 - acc: 0.9855 -- iter: 0064/1856
[A[ATraining Step: 757  | total loss: [1m[32m0.04851[0m[0m | time: 39.574s
[2K
| Adam | epoch: 014 | loss: 0.04851 - acc: 0.9838 -- iter: 0096/1856
[A[ATraining Step: 758  | total loss: [1m[32m0.04405[0m[0m | time: 52.604s
[2K
| Adam | epoch: 014 | loss: 0.04405 - acc: 0.9854 -- iter: 0128/1856
[A[ATraining Step: 759  | total loss: [1m[32m0.05080[0m[0m | time: 65.293s
[2K
| Adam | epoch: 014 | loss: 0.05080 - acc: 0.9806 -- iter: 0160/1856
[A[ATraining Step: 760  | total loss: [1m[32m0.05485[0m[0m | time: 78.204s
[2K
| Adam | epoch: 014 | loss: 0.05485 - acc: 0.9794 -- iter: 0192/1856
[A[ATraining Step: 761  | total loss: [1m[32m0.07126[0m[0m | time: 90.883s
[2K
| Adam | epoch: 014 | loss: 0.07126 - acc: 0.9784 -- iter: 0224/1856
[A[ATraining Step: 762  | total loss: [1m[32m0.06533[0m[0m | time: 104.123s
[2K
| Adam | epoch: 014 | loss: 0.06533 - acc: 0.9805 -- iter: 0256/1856
[A[ATraining Step: 763  | total loss: [1m[32m0.07140[0m[0m | time: 116.427s
[2K
| Adam | epoch: 014 | loss: 0.07140 - acc: 0.9794 -- iter: 0288/1856
[A[ATraining Step: 764  | total loss: [1m[32m0.06809[0m[0m | time: 129.200s
[2K
| Adam | epoch: 014 | loss: 0.06809 - acc: 0.9814 -- iter: 0320/1856
[A[ATraining Step: 765  | total loss: [1m[32m0.07226[0m[0m | time: 141.928s
[2K
| Adam | epoch: 014 | loss: 0.07226 - acc: 0.9801 -- iter: 0352/1856
[A[ATraining Step: 766  | total loss: [1m[32m0.06514[0m[0m | time: 154.977s
[2K
| Adam | epoch: 014 | loss: 0.06514 - acc: 0.9821 -- iter: 0384/1856
[A[ATraining Step: 767  | total loss: [1m[32m0.06137[0m[0m | time: 167.856s
[2K
| Adam | epoch: 014 | loss: 0.06137 - acc: 0.9839 -- iter: 0416/1856
[A[ATraining Step: 768  | total loss: [1m[32m0.05732[0m[0m | time: 180.839s
[2K
| Adam | epoch: 014 | loss: 0.05732 - acc: 0.9855 -- iter: 0448/1856
[A[ATraining Step: 769  | total loss: [1m[32m0.05812[0m[0m | time: 193.402s
[2K
| Adam | epoch: 014 | loss: 0.05812 - acc: 0.9839 -- iter: 0480/1856
[A[ATraining Step: 770  | total loss: [1m[32m0.05551[0m[0m | time: 206.634s
[2K
| Adam | epoch: 014 | loss: 0.05551 - acc: 0.9823 -- iter: 0512/1856
[A[ATraining Step: 771  | total loss: [1m[32m0.05111[0m[0m | time: 220.268s
[2K
| Adam | epoch: 014 | loss: 0.05111 - acc: 0.9841 -- iter: 0544/1856
[A[ATraining Step: 772  | total loss: [1m[32m0.05091[0m[0m | time: 233.158s
[2K
| Adam | epoch: 014 | loss: 0.05091 - acc: 0.9857 -- iter: 0576/1856
[A[ATraining Step: 773  | total loss: [1m[32m0.04660[0m[0m | time: 241.301s
[2K
| Adam | epoch: 014 | loss: 0.04660 - acc: 0.9871 -- iter: 0608/1856
[A[ATraining Step: 774  | total loss: [1m[32m0.04381[0m[0m | time: 249.377s
[2K
| Adam | epoch: 014 | loss: 0.04381 - acc: 0.9884 -- iter: 0640/1856
[A[ATraining Step: 775  | total loss: [1m[32m0.05647[0m[0m | time: 257.363s
[2K
| Adam | epoch: 014 | loss: 0.05647 - acc: 0.9864 -- iter: 0672/1856
[A[ATraining Step: 776  | total loss: [1m[32m0.05287[0m[0m | time: 265.365s
[2K
| Adam | epoch: 014 | loss: 0.05287 - acc: 0.9878 -- iter: 0704/1856
[A[ATraining Step: 777  | total loss: [1m[32m0.05562[0m[0m | time: 274.980s
[2K
| Adam | epoch: 014 | loss: 0.05562 - acc: 0.9859 -- iter: 0736/1856
[A[ATraining Step: 778  | total loss: [1m[32m0.05284[0m[0m | time: 287.691s
[2K
| Adam | epoch: 014 | loss: 0.05284 - acc: 0.9873 -- iter: 0768/1856
[A[ATraining Step: 779  | total loss: [1m[32m0.04961[0m[0m | time: 300.548s
[2K
| Adam | epoch: 014 | loss: 0.04961 - acc: 0.9886 -- iter: 0800/1856
[A[ATraining Step: 780  | total loss: [1m[32m0.04716[0m[0m | time: 312.106s
[2K
| Adam | epoch: 014 | loss: 0.04716 - acc: 0.9897 -- iter: 0832/1856
[A[ATraining Step: 781  | total loss: [1m[32m0.04294[0m[0m | time: 324.862s
[2K
| Adam | epoch: 014 | loss: 0.04294 - acc: 0.9907 -- iter: 0864/1856
[A[ATraining Step: 782  | total loss: [1m[32m0.03876[0m[0m | time: 337.580s
[2K
| Adam | epoch: 014 | loss: 0.03876 - acc: 0.9917 -- iter: 0896/1856
[A[ATraining Step: 783  | total loss: [1m[32m0.04412[0m[0m | time: 350.538s
[2K
| Adam | epoch: 014 | loss: 0.04412 - acc: 0.9863 -- iter: 0928/1856
[A[ATraining Step: 784  | total loss: [1m[32m0.04107[0m[0m | time: 363.632s
[2K
| Adam | epoch: 014 | loss: 0.04107 - acc: 0.9876 -- iter: 0960/1856
[A[ATraining Step: 785  | total loss: [1m[32m0.04189[0m[0m | time: 376.953s
[2K
| Adam | epoch: 014 | loss: 0.04189 - acc: 0.9857 -- iter: 0992/1856
[A[ATraining Step: 786  | total loss: [1m[32m0.04768[0m[0m | time: 390.160s
[2K
| Adam | epoch: 014 | loss: 0.04768 - acc: 0.9809 -- iter: 1024/1856
[A[ATraining Step: 787  | total loss: [1m[32m0.04862[0m[0m | time: 403.755s
[2K
| Adam | epoch: 014 | loss: 0.04862 - acc: 0.9797 -- iter: 1056/1856
[A[ATraining Step: 788  | total loss: [1m[32m0.04833[0m[0m | time: 416.849s
[2K
| Adam | epoch: 014 | loss: 0.04833 - acc: 0.9786 -- iter: 1088/1856
[A[ATraining Step: 789  | total loss: [1m[32m0.04453[0m[0m | time: 429.945s
[2K
| Adam | epoch: 014 | loss: 0.04453 - acc: 0.9807 -- iter: 1120/1856
[A[ATraining Step: 790  | total loss: [1m[32m0.05697[0m[0m | time: 442.732s
[2K
| Adam | epoch: 014 | loss: 0.05697 - acc: 0.9795 -- iter: 1152/1856
[A[ATraining Step: 791  | total loss: [1m[32m0.05343[0m[0m | time: 455.772s
[2K
| Adam | epoch: 014 | loss: 0.05343 - acc: 0.9816 -- iter: 1184/1856
[A[ATraining Step: 792  | total loss: [1m[32m0.04925[0m[0m | time: 468.778s
[2K
| Adam | epoch: 014 | loss: 0.04925 - acc: 0.9834 -- iter: 1216/1856
[A[ATraining Step: 793  | total loss: [1m[32m0.04600[0m[0m | time: 482.008s
[2K
| Adam | epoch: 014 | loss: 0.04600 - acc: 0.9851 -- iter: 1248/1856
[A[ATraining Step: 794  | total loss: [1m[32m0.07126[0m[0m | time: 494.848s
[2K
| Adam | epoch: 014 | loss: 0.07126 - acc: 0.9835 -- iter: 1280/1856
[A[ATraining Step: 795  | total loss: [1m[32m0.08458[0m[0m | time: 508.228s
[2K
| Adam | epoch: 014 | loss: 0.08458 - acc: 0.9789 -- iter: 1312/1856
[A[ATraining Step: 796  | total loss: [1m[32m0.08631[0m[0m | time: 521.411s
[2K
| Adam | epoch: 014 | loss: 0.08631 - acc: 0.9747 -- iter: 1344/1856
[A[ATraining Step: 797  | total loss: [1m[32m0.08599[0m[0m | time: 534.626s
[2K
| Adam | epoch: 014 | loss: 0.08599 - acc: 0.9741 -- iter: 1376/1856
[A[ATraining Step: 798  | total loss: [1m[32m0.08005[0m[0m | time: 547.628s
[2K
| Adam | epoch: 014 | loss: 0.08005 - acc: 0.9767 -- iter: 1408/1856
[A[ATraining Step: 799  | total loss: [1m[32m0.07280[0m[0m | time: 560.298s
[2K
| Adam | epoch: 014 | loss: 0.07280 - acc: 0.9790 -- iter: 1440/1856
[A[ATraining Step: 800  | total loss: [1m[32m0.08267[0m[0m | time: 618.567s
[2K
| Adam | epoch: 014 | loss: 0.08267 - acc: 0.9749 | val_loss: 0.26054 - val_acc: 0.9345 -- iter: 1472/1856
--
Training Step: 801  | total loss: [1m[32m0.07690[0m[0m | time: 631.077s
[2K
| Adam | epoch: 014 | loss: 0.07690 - acc: 0.9774 -- iter: 1504/1856
[A[ATraining Step: 802  | total loss: [1m[32m0.07035[0m[0m | time: 644.528s
[2K
| Adam | epoch: 014 | loss: 0.07035 - acc: 0.9797 -- iter: 1536/1856
[A[ATraining Step: 803  | total loss: [1m[32m0.06468[0m[0m | time: 657.740s
[2K
| Adam | epoch: 014 | loss: 0.06468 - acc: 0.9817 -- iter: 1568/1856
[A[ATraining Step: 804  | total loss: [1m[32m0.05838[0m[0m | time: 670.738s
[2K
| Adam | epoch: 014 | loss: 0.05838 - acc: 0.9835 -- iter: 1600/1856
[A[ATraining Step: 805  | total loss: [1m[32m0.06343[0m[0m | time: 683.942s
[2K
| Adam | epoch: 014 | loss: 0.06343 - acc: 0.9820 -- iter: 1632/1856
[A[ATraining Step: 806  | total loss: [1m[32m0.06165[0m[0m | time: 697.068s
[2K
| Adam | epoch: 014 | loss: 0.06165 - acc: 0.9807 -- iter: 1664/1856
[A[ATraining Step: 807  | total loss: [1m[32m0.05710[0m[0m | time: 709.945s
[2K
| Adam | epoch: 014 | loss: 0.05710 - acc: 0.9826 -- iter: 1696/1856
[A[ATraining Step: 808  | total loss: [1m[32m0.05479[0m[0m | time: 722.969s
[2K
| Adam | epoch: 014 | loss: 0.05479 - acc: 0.9844 -- iter: 1728/1856
[A[ATraining Step: 809  | total loss: [1m[32m0.05243[0m[0m | time: 736.229s
[2K
| Adam | epoch: 014 | loss: 0.05243 - acc: 0.9859 -- iter: 1760/1856
[A[ATraining Step: 810  | total loss: [1m[32m0.04831[0m[0m | time: 749.134s
[2K
| Adam | epoch: 014 | loss: 0.04831 - acc: 0.9873 -- iter: 1792/1856
[A[ATraining Step: 811  | total loss: [1m[32m0.04377[0m[0m | time: 762.014s
[2K
| Adam | epoch: 014 | loss: 0.04377 - acc: 0.9886 -- iter: 1824/1856
[A[ATraining Step: 812  | total loss: [1m[32m0.04100[0m[0m | time: 819.023s
[2K
| Adam | epoch: 014 | loss: 0.04100 - acc: 0.9898 | val_loss: 1.89608 - val_acc: 0.6793 -- iter: 1856/1856
--
Training Step: 813  | total loss: [1m[32m0.03748[0m[0m | time: 8.255s
[2K
| Adam | epoch: 015 | loss: 0.03748 - acc: 0.9908 -- iter: 0032/1856
[A[ATraining Step: 814  | total loss: [1m[32m0.04550[0m[0m | time: 16.354s
[2K
| Adam | epoch: 015 | loss: 0.04550 - acc: 0.9886 -- iter: 0064/1856
[A[ATraining Step: 815  | total loss: [1m[32m0.04209[0m[0m | time: 24.402s
[2K
| Adam | epoch: 015 | loss: 0.04209 - acc: 0.9897 -- iter: 0096/1856
[A[ATraining Step: 816  | total loss: [1m[32m0.04184[0m[0m | time: 33.524s
[2K
| Adam | epoch: 015 | loss: 0.04184 - acc: 0.9907 -- iter: 0128/1856
[A[ATraining Step: 817  | total loss: [1m[32m0.04100[0m[0m | time: 46.561s
[2K
| Adam | epoch: 015 | loss: 0.04100 - acc: 0.9885 -- iter: 0160/1856
[A[ATraining Step: 818  | total loss: [1m[32m0.05212[0m[0m | time: 59.484s
[2K
| Adam | epoch: 015 | loss: 0.05212 - acc: 0.9834 -- iter: 0192/1856
[A[ATraining Step: 819  | total loss: [1m[32m0.04894[0m[0m | time: 72.653s
[2K
| Adam | epoch: 015 | loss: 0.04894 - acc: 0.9851 -- iter: 0224/1856
[A[ATraining Step: 820  | total loss: [1m[32m0.04990[0m[0m | time: 84.412s
[2K
| Adam | epoch: 015 | loss: 0.04990 - acc: 0.9835 -- iter: 0256/1856
[A[ATraining Step: 821  | total loss: [1m[32m0.04525[0m[0m | time: 97.237s
[2K
| Adam | epoch: 015 | loss: 0.04525 - acc: 0.9851 -- iter: 0288/1856
[A[ATraining Step: 822  | total loss: [1m[32m0.04841[0m[0m | time: 110.503s
[2K
| Adam | epoch: 015 | loss: 0.04841 - acc: 0.9835 -- iter: 0320/1856
[A[ATraining Step: 823  | total loss: [1m[32m0.04696[0m[0m | time: 124.167s
[2K
| Adam | epoch: 015 | loss: 0.04696 - acc: 0.9820 -- iter: 0352/1856
[A[ATraining Step: 824  | total loss: [1m[32m0.04242[0m[0m | time: 137.997s
[2K
| Adam | epoch: 015 | loss: 0.04242 - acc: 0.9838 -- iter: 0384/1856
[A[ATraining Step: 825  | total loss: [1m[32m0.03860[0m[0m | time: 151.542s
[2K
| Adam | epoch: 015 | loss: 0.03860 - acc: 0.9854 -- iter: 0416/1856
[A[ATraining Step: 826  | total loss: [1m[32m0.03667[0m[0m | time: 165.101s
[2K
| Adam | epoch: 015 | loss: 0.03667 - acc: 0.9869 -- iter: 0448/1856
[A[ATraining Step: 827  | total loss: [1m[32m0.03431[0m[0m | time: 178.243s
[2K
| Adam | epoch: 015 | loss: 0.03431 - acc: 0.9882 -- iter: 0480/1856
[A[ATraining Step: 828  | total loss: [1m[32m0.03587[0m[0m | time: 191.221s
[2K
| Adam | epoch: 015 | loss: 0.03587 - acc: 0.9862 -- iter: 0512/1856
[A[ATraining Step: 829  | total loss: [1m[32m0.03435[0m[0m | time: 204.238s
[2K
| Adam | epoch: 015 | loss: 0.03435 - acc: 0.9876 -- iter: 0544/1856
[A[ATraining Step: 830  | total loss: [1m[32m0.03419[0m[0m | time: 216.755s
[2K
| Adam | epoch: 015 | loss: 0.03419 - acc: 0.9857 -- iter: 0576/1856
[A[ATraining Step: 831  | total loss: [1m[32m0.03311[0m[0m | time: 229.874s
[2K
| Adam | epoch: 015 | loss: 0.03311 - acc: 0.9872 -- iter: 0608/1856
[A[ATraining Step: 832  | total loss: [1m[32m0.03047[0m[0m | time: 243.139s
[2K
| Adam | epoch: 015 | loss: 0.03047 - acc: 0.9884 -- iter: 0640/1856
[A[ATraining Step: 833  | total loss: [1m[32m0.02774[0m[0m | time: 256.611s
[2K
| Adam | epoch: 015 | loss: 0.02774 - acc: 0.9896 -- iter: 0672/1856
[A[ATraining Step: 834  | total loss: [1m[32m0.03053[0m[0m | time: 269.694s
[2K
| Adam | epoch: 015 | loss: 0.03053 - acc: 0.9875 -- iter: 0704/1856
[A[ATraining Step: 835  | total loss: [1m[32m0.02802[0m[0m | time: 282.372s
[2K
| Adam | epoch: 015 | loss: 0.02802 - acc: 0.9888 -- iter: 0736/1856
[A[ATraining Step: 836  | total loss: [1m[32m0.03224[0m[0m | time: 295.348s
[2K
| Adam | epoch: 015 | loss: 0.03224 - acc: 0.9868 -- iter: 0768/1856
[A[ATraining Step: 837  | total loss: [1m[32m0.02933[0m[0m | time: 308.047s
[2K
| Adam | epoch: 015 | loss: 0.02933 - acc: 0.9881 -- iter: 0800/1856
[A[ATraining Step: 838  | total loss: [1m[32m0.02936[0m[0m | time: 320.894s
[2K
| Adam | epoch: 015 | loss: 0.02936 - acc: 0.9893 -- iter: 0832/1856
[A[ATraining Step: 839  | total loss: [1m[32m0.02681[0m[0m | time: 334.175s
[2K
| Adam | epoch: 015 | loss: 0.02681 - acc: 0.9904 -- iter: 0864/1856
[A[ATraining Step: 840  | total loss: [1m[32m0.02439[0m[0m | time: 346.981s
[2K
| Adam | epoch: 015 | loss: 0.02439 - acc: 0.9913 -- iter: 0896/1856
[A[ATraining Step: 841  | total loss: [1m[32m0.02227[0m[0m | time: 360.217s
[2K
| Adam | epoch: 015 | loss: 0.02227 - acc: 0.9922 -- iter: 0928/1856
[A[ATraining Step: 842  | total loss: [1m[32m0.02039[0m[0m | time: 373.263s
[2K
| Adam | epoch: 015 | loss: 0.02039 - acc: 0.9930 -- iter: 0960/1856
[A[ATraining Step: 843  | total loss: [1m[32m0.01936[0m[0m | time: 386.036s
[2K
| Adam | epoch: 015 | loss: 0.01936 - acc: 0.9937 -- iter: 0992/1856
[A[ATraining Step: 844  | total loss: [1m[32m0.01945[0m[0m | time: 399.575s
[2K
| Adam | epoch: 015 | loss: 0.01945 - acc: 0.9943 -- iter: 1024/1856
[A[ATraining Step: 845  | total loss: [1m[32m0.01905[0m[0m | time: 412.683s
[2K
| Adam | epoch: 015 | loss: 0.01905 - acc: 0.9949 -- iter: 1056/1856
[A[ATraining Step: 846  | total loss: [1m[32m0.01739[0m[0m | time: 425.842s
[2K
| Adam | epoch: 015 | loss: 0.01739 - acc: 0.9954 -- iter: 1088/1856
[A[ATraining Step: 847  | total loss: [1m[32m0.01607[0m[0m | time: 439.312s
[2K
| Adam | epoch: 015 | loss: 0.01607 - acc: 0.9958 -- iter: 1120/1856
[A[ATraining Step: 848  | total loss: [1m[32m0.01531[0m[0m | time: 452.542s
[2K
| Adam | epoch: 015 | loss: 0.01531 - acc: 0.9963 -- iter: 1152/1856
[A[ATraining Step: 849  | total loss: [1m[32m0.02257[0m[0m | time: 465.712s
[2K
| Adam | epoch: 015 | loss: 0.02257 - acc: 0.9935 -- iter: 1184/1856
[A[ATraining Step: 850  | total loss: [1m[32m0.02166[0m[0m | time: 478.747s
[2K
| Adam | epoch: 015 | loss: 0.02166 - acc: 0.9942 -- iter: 1216/1856
[A[ATraining Step: 851  | total loss: [1m[32m0.01999[0m[0m | time: 491.502s
[2K
| Adam | epoch: 015 | loss: 0.01999 - acc: 0.9947 -- iter: 1248/1856
[A[ATraining Step: 852  | total loss: [1m[32m0.02911[0m[0m | time: 504.775s
[2K
| Adam | epoch: 015 | loss: 0.02911 - acc: 0.9921 -- iter: 1280/1856
[A[ATraining Step: 853  | total loss: [1m[32m0.02730[0m[0m | time: 518.142s
[2K
| Adam | epoch: 015 | loss: 0.02730 - acc: 0.9929 -- iter: 1312/1856
[A[ATraining Step: 854  | total loss: [1m[32m0.02541[0m[0m | time: 534.787s
[2K
| Adam | epoch: 015 | loss: 0.02541 - acc: 0.9936 -- iter: 1344/1856
[A[ATraining Step: 855  | total loss: [1m[32m0.02474[0m[0m | time: 551.186s
[2K
| Adam | epoch: 015 | loss: 0.02474 - acc: 0.9943 -- iter: 1376/1856
[A[ATraining Step: 856  | total loss: [1m[32m0.02458[0m[0m | time: 567.542s
[2K
| Adam | epoch: 015 | loss: 0.02458 - acc: 0.9948 -- iter: 1408/1856
[A[ATraining Step: 857  | total loss: [1m[32m0.02293[0m[0m | time: 584.015s
[2K
| Adam | epoch: 015 | loss: 0.02293 - acc: 0.9954 -- iter: 1440/1856
[A[ATraining Step: 858  | total loss: [1m[32m0.02985[0m[0m | time: 600.059s
[2K
| Adam | epoch: 015 | loss: 0.02985 - acc: 0.9896 -- iter: 1472/1856
[A[ATraining Step: 859  | total loss: [1m[32m0.02691[0m[0m | time: 616.452s
[2K
| Adam | epoch: 015 | loss: 0.02691 - acc: 0.9906 -- iter: 1504/1856
[A[ATraining Step: 860  | total loss: [1m[32m0.02641[0m[0m | time: 633.053s
[2K
| Adam | epoch: 015 | loss: 0.02641 - acc: 0.9916 -- iter: 1536/1856
[A[ATraining Step: 861  | total loss: [1m[32m0.02404[0m[0m | time: 649.538s
[2K
| Adam | epoch: 015 | loss: 0.02404 - acc: 0.9924 -- iter: 1568/1856
[A[ATraining Step: 862  | total loss: [1m[32m0.02191[0m[0m | time: 666.122s
[2K
| Adam | epoch: 015 | loss: 0.02191 - acc: 0.9932 -- iter: 1600/1856
[A[ATraining Step: 863  | total loss: [1m[32m0.02020[0m[0m | time: 676.415s
[2K
| Adam | epoch: 015 | loss: 0.02020 - acc: 0.9938 -- iter: 1632/1856
[A[ATraining Step: 864  | total loss: [1m[32m0.01870[0m[0m | time: 687.282s
[2K
| Adam | epoch: 015 | loss: 0.01870 - acc: 0.9945 -- iter: 1664/1856
[A[ATraining Step: 865  | total loss: [1m[32m0.01707[0m[0m | time: 702.602s
[2K
| Adam | epoch: 015 | loss: 0.01707 - acc: 0.9950 -- iter: 1696/1856
[A[ATraining Step: 866  | total loss: [1m[32m0.02029[0m[0m | time: 717.922s
[2K
| Adam | epoch: 015 | loss: 0.02029 - acc: 0.9924 -- iter: 1728/1856
[A[ATraining Step: 867  | total loss: [1m[32m0.01905[0m[0m | time: 734.317s
[2K
| Adam | epoch: 015 | loss: 0.01905 - acc: 0.9931 -- iter: 1760/1856
[A[ATraining Step: 868  | total loss: [1m[32m0.01976[0m[0m | time: 749.769s
[2K
| Adam | epoch: 015 | loss: 0.01976 - acc: 0.9938 -- iter: 1792/1856
[A[ATraining Step: 869  | total loss: [1m[32m0.02297[0m[0m | time: 766.134s
[2K
| Adam | epoch: 015 | loss: 0.02297 - acc: 0.9913 -- iter: 1824/1856
[A[ATraining Step: 870  | total loss: [1m[32m0.02137[0m[0m | time: 835.825s
[2K
| Adam | epoch: 015 | loss: 0.02137 - acc: 0.9922 | val_loss: 0.40135 - val_acc: 0.8966 -- iter: 1856/1856
--
Validation AUC:0.9843370914799486
Validation AUPRC:0.9831893696699223
Test AUC:0.9786851474773455
Test AUPRC:0.9752810932353165
BestTestF1Score	0.95	0.89	0.94	0.95	0.94	284	15	264	17	0.01
BestTestMCCScore	0.95	0.89	0.94	0.95	0.94	284	15	264	17	0.01
BestTestAccuracyScore	0.95	0.89	0.94	0.95	0.94	284	15	264	17	0.01
BestValidationF1Score	0.95	0.9	0.95	0.95	0.95	271	14	280	15	0.01
BestValidationMCC	0.95	0.9	0.95	0.95	0.95	271	14	280	15	0.01
BestValidationAccuracy	0.95	0.9	0.95	0.95	0.95	271	14	280	15	0.01
TestPredictions (Threshold:0.01)
CHEMBL101691,TP,ACT,1.0	CHEMBL285380,TN,INACT,0.0	CHEMBL461088,TN,INACT,0.0	CHEMBL2031474,TP,ACT,1.0	CHEMBL291394,TP,ACT,1.0	CHEMBL3314886,TN,INACT,0.0	CHEMBL101554,TN,INACT,0.0	CHEMBL166736,FP,INACT,1.0	CHEMBL113,TN,INACT,0.0	CHEMBL560799,TP,ACT,0.6100000143051147	CHEMBL553082,TN,INACT,0.0	CHEMBL112314,TN,INACT,0.0	CHEMBL2436824,TN,INACT,0.0	CHEMBL555146,TP,ACT,1.0	CHEMBL2373213,TN,INACT,0.0	CHEMBL303792,TN,INACT,0.0	CHEMBL1829486,TP,ACT,0.4399999976158142	CHEMBL161133,TP,ACT,0.9900000095367432	CHEMBL163488,TN,INACT,0.0	CHEMBL105762,TP,ACT,1.0	CHEMBL323245,TN,INACT,0.0	CHEMBL366183,TP,ACT,1.0	CHEMBL426537,TN,INACT,0.0	CHEMBL418691,TP,ACT,1.0	CHEMBL2013053,TP,ACT,1.0	CHEMBL300926,TN,INACT,0.0	CHEMBL118954,TN,INACT,0.0	CHEMBL25205,TP,ACT,1.0	CHEMBL24352,TP,ACT,0.9800000190734863	CHEMBL107155,TN,INACT,0.0	CHEMBL305371,TP,ACT,0.6600000262260437	CHEMBL679,TN,INACT,0.0	CHEMBL301331,TN,INACT,0.0	CHEMBL27403,TN,INACT,0.0	CHEMBL457862,TP,ACT,1.0	CHEMBL103404,TN,INACT,0.0	CHEMBL335971,TN,INACT,0.0	CHEMBL1783890,TP,ACT,0.2199999988079071	CHEMBL2112499,TP,ACT,1.0	CHEMBL3608771,TN,INACT,0.0	CHEMBL159282,TP,ACT,1.0	CHEMBL247505,TP,ACT,1.0	CHEMBL2112157,TN,INACT,0.0	CHEMBL124396,TN,INACT,0.0	CHEMBL488891,TP,ACT,1.0	CHEMBL563409,TP,ACT,1.0	CHEMBL150696,TN,INACT,0.0	CHEMBL349221,TP,ACT,0.8899999856948853	CHEMBL20993,TN,INACT,0.0	CHEMBL1098359,TN,INACT,0.0	CHEMBL1788233,TN,INACT,0.0	CHEMBL80505,TN,INACT,0.0	CHEMBL208311,TN,INACT,0.0	CHEMBL167335,FP,INACT,0.9900000095367432	CHEMBL104848,TN,INACT,0.0	CHEMBL442242,TP,ACT,1.0	CHEMBL302447,TN,INACT,0.0	CHEMBL67313,TN,INACT,0.0	CHEMBL273202,TP,ACT,0.8899999856948853	CHEMBL101239,TN,INACT,0.0	CHEMBL74505,TN,INACT,0.0	CHEMBL280367,TN,INACT,0.0	CHEMBL44842,TP,ACT,1.0	CHEMBL29416,TN,INACT,0.0	CHEMBL402873,TP,ACT,1.0	CHEMBL228738,TN,INACT,0.0	CHEMBL246316,TP,ACT,0.07999999821186066	CHEMBL47404,TN,INACT,0.0	CHEMBL157493,TP,ACT,0.9900000095367432	CHEMBL447953,TP,ACT,0.3700000047683716	CHEMBL3290994,TN,INACT,0.0	CHEMBL2112411,TN,INACT,0.0	CHEMBL1096827,FN,ACT,0.0	CHEMBL30057,TN,INACT,0.0	CHEMBL3403334,TN,INACT,0.0	CHEMBL1089390,TP,ACT,0.029999999329447746	CHEMBL1791403,TN,INACT,0.0	CHEMBL62949,TP,ACT,1.0	CHEMBL608462,TN,INACT,0.0	CHEMBL2322893,TN,INACT,0.0	CHEMBL345357,TN,INACT,0.0	CHEMBL46458,FN,ACT,0.009999999776482582	CHEMBL468633,TN,INACT,0.0	CHEMBL2436823,TN,INACT,0.0	CHEMBL351531,TN,INACT,0.0	CHEMBL312567,TN,INACT,0.0	CHEMBL95986,TN,INACT,0.009999999776482582	CHEMBL564405,TP,ACT,0.9900000095367432	CHEMBL75002,TN,INACT,0.0	CHEMBL277989,TP,ACT,1.0	CHEMBL64259,TP,ACT,0.9200000166893005	CHEMBL143304,TN,INACT,0.0	CHEMBL3109772,TN,INACT,0.0	CHEMBL27343,TP,ACT,0.4099999964237213	CHEMBL179263,TP,ACT,0.9700000286102295	CHEMBL64120,TP,ACT,1.0	CHEMBL257684,TN,INACT,0.0	CHEMBL189192,TN,INACT,0.0	CHEMBL1835771,TP,ACT,0.4099999964237213	CHEMBL74342,TN,INACT,0.0	CHEMBL168196,TP,ACT,0.05999999865889549	CHEMBL3121101,TP,ACT,0.2800000011920929	CHEMBL1795025,TP,ACT,1.0	CHEMBL2113698,TN,INACT,0.0	CHEMBL469856,TN,INACT,0.0	CHEMBL60401,TP,ACT,0.9900000095367432	CHEMBL3092821,FN,ACT,0.009999999776482582	CHEMBL2037608,TP,ACT,1.0	CHEMBL1823402,TP,ACT,1.0	CHEMBL140495,TN,INACT,0.0	CHEMBL109498,TP,ACT,1.0	CHEMBL3121100,TP,ACT,0.07999999821186066	CHEMBL277079,TN,INACT,0.0	CHEMBL368133,TN,INACT,0.0	CHEMBL245319,TN,INACT,0.0	CHEMBL1835782,TP,ACT,0.949999988079071	CHEMBL158659,TP,ACT,0.8299999833106995	CHEMBL3121090,TP,ACT,0.8399999737739563	CHEMBL270439,TP,ACT,1.0	CHEMBL106545,TP,ACT,1.0	CHEMBL344602,TN,INACT,0.0	CHEMBL285357,TN,INACT,0.0	CHEMBL233535,FP,INACT,0.05000000074505806	CHEMBL422959,TN,INACT,0.0	CHEMBL80504,TN,INACT,0.0	CHEMBL331504,TN,INACT,0.0	CHEMBL1934527,TP,ACT,1.0	CHEMBL3417582,TP,ACT,1.0	CHEMBL233957,TN,INACT,0.0	CHEMBL281633,TN,INACT,0.0	CHEMBL169348,TP,ACT,0.9900000095367432	CHEMBL1090461,TN,INACT,0.0	CHEMBL108797,TN,INACT,0.0	CHEMBL24863,TP,ACT,1.0	CHEMBL378178,TP,ACT,1.0	CHEMBL170651,TP,ACT,1.0	CHEMBL216406,TN,INACT,0.0	CHEMBL341031,TN,INACT,0.0	CHEMBL254985,FN,ACT,0.0	CHEMBL1084314,TP,ACT,1.0	CHEMBL542544,TN,INACT,0.0	CHEMBL406698,TP,ACT,1.0	CHEMBL3577345,FP,INACT,0.12999999523162842	CHEMBL602474,TN,INACT,0.0	CHEMBL412569,TN,INACT,0.0	CHEMBL502704,TP,ACT,0.18000000715255737	CHEMBL422411,TN,INACT,0.0	CHEMBL452150,TN,INACT,0.0	CHEMBL128926,TP,ACT,0.15000000596046448	CHEMBL72861,TN,INACT,0.0	CHEMBL561262,TN,INACT,0.0	CHEMBL494890,TP,ACT,0.9599999785423279	CHEMBL2181144,TN,INACT,0.0	CHEMBL67495,TP,ACT,0.46000000834465027	CHEMBL2207493,TN,INACT,0.0	CHEMBL336881,TN,INACT,0.0	CHEMBL1263,FP,INACT,1.0	CHEMBL1076300,TP,ACT,0.9900000095367432	CHEMBL67949,TN,INACT,0.009999999776482582	CHEMBL2031741,TP,ACT,0.10000000149011612	CHEMBL602269,TN,INACT,0.0	CHEMBL302445,TP,ACT,0.49000000953674316	CHEMBL104198,TN,INACT,0.0	CHEMBL1934060,TP,ACT,0.9900000095367432	CHEMBL1086292,TP,ACT,1.0	CHEMBL24468,TP,ACT,1.0	CHEMBL3403741,TN,INACT,0.0	CHEMBL434063,TN,INACT,0.0	CHEMBL158200,TP,ACT,0.9800000190734863	CHEMBL574597,TN,INACT,0.0	CHEMBL1170953,TP,ACT,0.8899999856948853	CHEMBL322695,TP,ACT,1.0	CHEMBL233721,TN,INACT,0.0	CHEMBL125874,TN,INACT,0.0	CHEMBL550198,TP,ACT,0.30000001192092896	CHEMBL402220,TP,ACT,0.9700000286102295	CHEMBL215040,TN,INACT,0.0	CHEMBL3604305,TN,INACT,0.0	CHEMBL1945847,TP,ACT,0.25	CHEMBL443926,TN,INACT,0.0	CHEMBL159565,TP,ACT,0.949999988079071	CHEMBL161645,TP,ACT,0.75	CHEMBL282688,TP,ACT,1.0	CHEMBL44345,TN,INACT,0.0	CHEMBL1813056,TP,ACT,0.8899999856948853	CHEMBL1171002,TP,ACT,0.36000001430511475	CHEMBL27835,TP,ACT,1.0	CHEMBL494678,FN,ACT,0.0	CHEMBL13095,TN,INACT,0.0	CHEMBL301826,TN,INACT,0.0	CHEMBL159623,TN,INACT,0.0	CHEMBL3665435,TN,INACT,0.0	CHEMBL3818301,TN,INACT,0.0	CHEMBL288967,TN,INACT,0.0	CHEMBL3092831,TP,ACT,0.3799999952316284	CHEMBL1835780,TP,ACT,0.7900000214576721	CHEMBL1934357,TP,ACT,1.0	CHEMBL74902,TN,INACT,0.0	CHEMBL59798,TP,ACT,1.0	CHEMBL1084583,FN,ACT,0.009999999776482582	CHEMBL404505,TN,INACT,0.0	CHEMBL62840,TP,ACT,0.5600000023841858	CHEMBL418375,TN,INACT,0.0	CHEMBL344568,TN,INACT,0.0	CHEMBL1085828,TP,ACT,1.0	CHEMBL115608,TN,INACT,0.0	CHEMBL3092829,TP,ACT,0.36000001430511475	CHEMBL128851,TP,ACT,1.0	CHEMBL1170790,TP,ACT,0.3700000047683716	CHEMBL1950743,TP,ACT,0.9200000166893005	CHEMBL3423407,TN,INACT,0.0	CHEMBL286800,TN,INACT,0.0	CHEMBL423445,TP,ACT,1.0	CHEMBL3589594,TN,INACT,0.0	CHEMBL257607,TP,ACT,1.0	CHEMBL291882,TP,ACT,1.0	CHEMBL83747,TN,INACT,0.0	CHEMBL1945851,TP,ACT,0.9900000095367432	CHEMBL441305,TN,INACT,0.0	CHEMBL280895,TP,ACT,0.9700000286102295	CHEMBL20328,TP,ACT,0.8100000023841858	CHEMBL1813061,TP,ACT,1.0	CHEMBL471555,TP,ACT,1.0	CHEMBL3604304,TN,INACT,0.0	CHEMBL240021,TN,INACT,0.0	CHEMBL1945845,TP,ACT,0.8799999952316284	CHEMBL1922023,TN,INACT,0.0	CHEMBL392149,TN,INACT,0.0	CHEMBL16331,TP,ACT,0.8799999952316284	CHEMBL27209,TP,ACT,1.0	CHEMBL511657,TP,ACT,0.9100000262260437	CHEMBL170068,TN,INACT,0.0	CHEMBL214390,TP,ACT,0.9900000095367432	CHEMBL284969,TN,INACT,0.0	CHEMBL369359,TN,INACT,0.0	CHEMBL549470,TP,ACT,0.49000000953674316	CHEMBL255962,TP,ACT,1.0	CHEMBL27065,TN,INACT,0.0	CHEMBL25126,TP,ACT,0.9700000286102295	CHEMBL3633663,TN,INACT,0.0	CHEMBL50740,TN,INACT,0.0	CHEMBL519889,FN,ACT,0.0	CHEMBL273953,TN,INACT,0.0	CHEMBL1428,TN,INACT,0.0	CHEMBL246940,TP,ACT,0.019999999552965164	CHEMBL28057,TN,INACT,0.0	CHEMBL2062852,TN,INACT,0.0	CHEMBL429238,TN,INACT,0.0	CHEMBL64667,TP,ACT,1.0	CHEMBL180368,TP,ACT,1.0	CHEMBL64608,TP,ACT,1.0	CHEMBL2036648,TP,ACT,0.7200000286102295	CHEMBL345951,TN,INACT,0.0	CHEMBL127901,TP,ACT,0.3700000047683716	CHEMBL159085,TP,ACT,1.0	CHEMBL123099,TN,INACT,0.0	CHEMBL128380,TP,ACT,1.0	CHEMBL211486,TP,ACT,0.9900000095367432	CHEMBL72084,TN,INACT,0.009999999776482582	CHEMBL310425,TN,INACT,0.0	CHEMBL102853,TP,ACT,0.550000011920929	CHEMBL3143400,TN,INACT,0.0	CHEMBL1923730,TP,ACT,1.0	CHEMBL2042400,TN,INACT,0.0	CHEMBL414085,TN,INACT,0.0	CHEMBL449398,TP,ACT,0.949999988079071	CHEMBL101634,TP,ACT,0.75	CHEMBL1250,TN,INACT,0.0	CHEMBL594376,TN,INACT,0.0	CHEMBL194506,TP,ACT,0.9399999976158142	CHEMBL61396,TP,ACT,1.0	CHEMBL575160,TN,INACT,0.0	CHEMBL1171754,TP,ACT,0.9200000166893005	CHEMBL1829483,TP,ACT,0.8100000023841858	CHEMBL2443003,TN,INACT,0.0	CHEMBL393700,TP,ACT,1.0	CHEMBL165537,TP,ACT,0.14000000059604645	CHEMBL73933,TN,INACT,0.0	CHEMBL157585,TP,ACT,1.0	CHEMBL461709,TN,INACT,0.0	CHEMBL2036649,TP,ACT,1.0	CHEMBL119385,TN,INACT,0.0	CHEMBL1084294,TP,ACT,0.8999999761581421	CHEMBL541424,TN,INACT,0.0	CHEMBL267476,FP,INACT,1.0	CHEMBL1934052,TP,ACT,1.0	CHEMBL502593,TN,INACT,0.0	CHEMBL360885,TP,ACT,1.0	CHEMBL270011,TP,ACT,1.0	CHEMBL1084581,TP,ACT,1.0	CHEMBL2372075,TN,INACT,0.0	CHEMBL323723,TN,INACT,0.0	CHEMBL589,FP,INACT,0.9100000262260437	CHEMBL319005,TN,INACT,0.0	CHEMBL3417506,TP,ACT,1.0	CHEMBL62716,TP,ACT,0.8399999737739563	CHEMBL7505,FP,INACT,0.15000000596046448	CHEMBL89358,TN,INACT,0.0	CHEMBL352895,TP,ACT,0.9200000166893005	CHEMBL2387310,FN,ACT,0.0	CHEMBL2113224,TP,ACT,1.0	CHEMBL351671,TP,ACT,1.0	CHEMBL316857,TN,INACT,0.0	CHEMBL194620,TP,ACT,1.0	CHEMBL275987,TN,INACT,0.0	CHEMBL80438,TN,INACT,0.0	CHEMBL3694836,FN,ACT,0.0	CHEMBL434674,TN,INACT,0.0	CHEMBL325935,TN,INACT,0.0	CHEMBL49532,TP,ACT,1.0	CHEMBL3423404,TN,INACT,0.0	CHEMBL1192069,TN,INACT,0.0	CHEMBL1950742,TP,ACT,1.0	CHEMBL378072,TP,ACT,0.9900000095367432	CHEMBL113077,TP,ACT,1.0	CHEMBL3121097,TP,ACT,0.8299999833106995	CHEMBL3221637,FN,ACT,0.0	CHEMBL1823403,TP,ACT,1.0	CHEMBL258302,TP,ACT,1.0	CHEMBL1923736,TP,ACT,1.0	CHEMBL305248,FN,ACT,0.0	CHEMBL2436717,TN,INACT,0.0	CHEMBL488210,TP,ACT,0.7599999904632568	CHEMBL3627863,TN,INACT,0.0	CHEMBL3633650,TN,INACT,0.0	CHEMBL2111789,TN,INACT,0.0	CHEMBL513277,TN,INACT,0.0	CHEMBL44134,TN,INACT,0.0	CHEMBL458947,TN,INACT,0.0	CHEMBL1907932,TN,INACT,0.0	CHEMBL3694828,TP,ACT,0.3400000035762787	CHEMBL62660,TP,ACT,0.9900000095367432	CHEMBL324685,TN,INACT,0.0	CHEMBL61792,TP,ACT,0.949999988079071	CHEMBL25373,TN,INACT,0.0	CHEMBL210051,TP,ACT,1.0	CHEMBL1223054,FP,INACT,0.6700000166893005	CHEMBL16407,TP,ACT,1.0	CHEMBL1935111,TP,ACT,1.0	CHEMBL106487,TN,INACT,0.0	CHEMBL72057,TN,INACT,0.0	CHEMBL142324,TN,INACT,0.0	CHEMBL2403549,TP,ACT,0.8700000047683716	CHEMBL279898,TN,INACT,0.0	CHEMBL279617,TP,ACT,1.0	CHEMBL105267,TP,ACT,1.0	CHEMBL1084877,TP,ACT,0.9200000166893005	CHEMBL346573,TP,ACT,1.0	CHEMBL3403732,TN,INACT,0.0	CHEMBL312372,TN,INACT,0.0	CHEMBL3740042,FP,INACT,0.019999999552965164	CHEMBL493091,FN,ACT,0.0	CHEMBL422701,TN,INACT,0.0	CHEMBL3092826,FN,ACT,0.0	CHEMBL1160082,TP,ACT,0.14000000059604645	CHEMBL130707,FP,INACT,0.25	CHEMBL2031473,TP,ACT,1.0	CHEMBL354348,FN,ACT,0.009999999776482582	CHEMBL262787,FP,INACT,0.019999999552965164	CHEMBL14690,TP,ACT,0.6100000143051147	CHEMBL2386728,TP,ACT,0.9800000190734863	CHEMBL158702,TP,ACT,1.0	CHEMBL560340,TP,ACT,1.0	CHEMBL46195,TN,INACT,0.0	CHEMBL305338,TP,ACT,1.0	CHEMBL165462,TN,INACT,0.0	CHEMBL536044,TN,INACT,0.0	CHEMBL2367888,TN,INACT,0.0	CHEMBL2113067,TN,INACT,0.0	CHEMBL392888,TN,INACT,0.0	CHEMBL1085124,TP,ACT,1.0	CHEMBL16404,TP,ACT,0.019999999552965164	CHEMBL100874,TN,INACT,0.0	CHEMBL434785,FN,ACT,0.0	CHEMBL401028,TN,INACT,0.0	CHEMBL1090124,TN,INACT,0.0	CHEMBL423473,TP,ACT,0.9900000095367432	CHEMBL1933091,TP,ACT,0.9800000190734863	CHEMBL470898,TP,ACT,0.9100000262260437	CHEMBL161232,TP,ACT,0.49000000953674316	CHEMBL14811,TP,ACT,1.0	CHEMBL62527,TP,ACT,1.0	CHEMBL1829475,TP,ACT,1.0	CHEMBL350631,TN,INACT,0.0	CHEMBL3403337,TN,INACT,0.0	CHEMBL45028,TP,ACT,0.4300000071525574	CHEMBL474091,TN,INACT,0.0	CHEMBL1076275,TP,ACT,0.9900000095367432	CHEMBL559447,TP,ACT,1.0	CHEMBL302231,TP,ACT,1.0	CHEMBL2312346,TN,INACT,0.0	CHEMBL179472,TP,ACT,0.949999988079071	CHEMBL2391166,TP,ACT,0.5099999904632568	CHEMBL1945846,TP,ACT,0.9200000166893005	CHEMBL255793,FP,INACT,0.20000000298023224	CHEMBL191703,TP,ACT,0.05000000074505806	CHEMBL564380,TP,ACT,1.0	CHEMBL575027,TN,INACT,0.0	CHEMBL118553,TN,INACT,0.0	CHEMBL1098507,TN,INACT,0.0	CHEMBL27883,TN,INACT,0.0	CHEMBL322873,TP,ACT,1.0	CHEMBL434495,TP,ACT,1.0	CHEMBL522243,TP,ACT,0.9900000095367432	CHEMBL389129,FP,INACT,0.019999999552965164	CHEMBL93867,TN,INACT,0.0	CHEMBL161138,TP,ACT,1.0	CHEMBL123852,TN,INACT,0.0	CHEMBL62601,TN,INACT,0.0	CHEMBL378173,TN,INACT,0.0	CHEMBL429418,TP,ACT,1.0	CHEMBL161346,TP,ACT,0.949999988079071	CHEMBL208830,TP,ACT,0.9100000262260437	CHEMBL437404,TP,ACT,0.6100000143051147	CHEMBL2031742,TP,ACT,0.9700000286102295	CHEMBL348766,TN,INACT,0.0	CHEMBL344154,TN,INACT,0.0	CHEMBL62050,TP,ACT,1.0	CHEMBL178191,TP,ACT,0.8700000047683716	CHEMBL52867,TN,INACT,0.0	CHEMBL2036650,TP,ACT,0.9900000095367432	CHEMBL146983,TN,INACT,0.0	CHEMBL92318,TN,INACT,0.0	CHEMBL26880,TP,ACT,1.0	CHEMBL449040,TP,ACT,0.6499999761581421	CHEMBL1084385,TP,ACT,1.0	CHEMBL434250,TN,INACT,0.0	CHEMBL322801,TN,INACT,0.0	CHEMBL1829482,TP,ACT,1.0	CHEMBL497030,TP,ACT,0.7900000214576721	CHEMBL408395,TN,INACT,0.0	CHEMBL20211,TP,ACT,0.20000000298023224	CHEMBL98014,TN,INACT,0.0	CHEMBL196868,TP,ACT,0.7900000214576721	CHEMBL550405,TP,ACT,0.27000001072883606	CHEMBL115556,TN,INACT,0.0	CHEMBL267014,TN,INACT,0.0	CHEMBL254374,TP,ACT,1.0	CHEMBL395131,TP,ACT,0.9900000095367432	CHEMBL105457,TN,INACT,0.0	CHEMBL3092828,TP,ACT,0.8299999833106995	CHEMBL2206290,TP,ACT,0.8899999856948853	CHEMBL359462,TP,ACT,1.0	CHEMBL461087,TN,INACT,0.0	CHEMBL2031751,TP,ACT,0.15000000596046448	CHEMBL283535,TN,INACT,0.0	CHEMBL350649,TP,ACT,1.0	CHEMBL129607,TP,ACT,0.9900000095367432	CHEMBL383805,TN,INACT,0.009999999776482582	CHEMBL104222,TN,INACT,0.0	CHEMBL1951052,TP,ACT,1.0	CHEMBL2436722,TN,INACT,0.0	CHEMBL345678,TP,ACT,0.33000001311302185	CHEMBL100513,TN,INACT,0.0	CHEMBL457005,TP,ACT,0.8299999833106995	CHEMBL27933,TP,ACT,1.0	CHEMBL439429,TP,ACT,1.0	CHEMBL1813065,TP,ACT,1.0	CHEMBL159087,TP,ACT,1.0	CHEMBL159122,TP,ACT,0.8799999952316284	CHEMBL405070,TP,ACT,1.0	CHEMBL2436716,TN,INACT,0.0	CHEMBL212775,TP,ACT,0.9900000095367432	CHEMBL129025,TP,ACT,0.949999988079071	CHEMBL1917641,TP,ACT,1.0	CHEMBL314104,TN,INACT,0.0	CHEMBL209099,TP,ACT,0.9100000262260437	CHEMBL314959,TN,INACT,0.0	CHEMBL63003,TP,ACT,0.7400000095367432	CHEMBL3092832,TP,ACT,0.41999998688697815	CHEMBL76779,TN,INACT,0.0	CHEMBL2031743,TP,ACT,0.5099999904632568	CHEMBL1090509,TN,INACT,0.0	CHEMBL1082496,TP,ACT,1.0	CHEMBL439648,TN,INACT,0.0	CHEMBL63632,TP,ACT,0.7099999785423279	CHEMBL3403335,TN,INACT,0.0	CHEMBL3694826,TP,ACT,1.0	CHEMBL257179,TP,ACT,0.8999999761581421	CHEMBL571448,TP,ACT,0.019999999552965164	CHEMBL124780,TN,INACT,0.0	CHEMBL227429,TN,INACT,0.0	CHEMBL157534,TP,ACT,0.8700000047683716	CHEMBL327016,TN,INACT,0.0	CHEMBL169178,TN,INACT,0.0	CHEMBL2062861,TN,INACT,0.0	CHEMBL291830,TP,ACT,0.9200000166893005	CHEMBL3092838,TP,ACT,0.029999999329447746	CHEMBL1835708,TP,ACT,0.949999988079071	CHEMBL2062858,TN,INACT,0.0	CHEMBL29541,TN,INACT,0.0	CHEMBL3423400,TN,INACT,0.0	CHEMBL476323,TP,ACT,0.019999999552965164	CHEMBL103950,TN,INACT,0.0	CHEMBL2031747,TP,ACT,0.15000000596046448	CHEMBL161801,TP,ACT,1.0	CHEMBL2112461,TP,ACT,1.0	CHEMBL59859,TN,INACT,0.0	CHEMBL161743,TP,ACT,1.0	CHEMBL276676,TN,INACT,0.0	CHEMBL291821,TP,ACT,1.0	CHEMBL320779,TN,INACT,0.0	CHEMBL1950739,TP,ACT,0.9900000095367432	CHEMBL608814,TN,INACT,0.0	CHEMBL129198,FN,ACT,0.0	CHEMBL429644,FP,INACT,0.019999999552965164	CHEMBL350007,TP,ACT,0.9800000190734863	CHEMBL74170,TN,INACT,0.0	CHEMBL3092835,TP,ACT,0.03999999910593033	CHEMBL1829337,TP,ACT,1.0	CHEMBL414165,TN,INACT,0.0	CHEMBL65849,TP,ACT,0.9300000071525574	CHEMBL610956,TN,INACT,0.0	CHEMBL128690,TP,ACT,1.0	CHEMBL107680,TN,INACT,0.0	CHEMBL2113222,TP,ACT,1.0	CHEMBL3114165,TN,INACT,0.0	CHEMBL1950736,TP,ACT,0.10999999940395355	CHEMBL323562,TP,ACT,1.0	CHEMBL226694,TN,INACT,0.0	CHEMBL353905,TP,ACT,1.0	CHEMBL91786,TN,INACT,0.0	CHEMBL2094002,TN,INACT,0.0	CHEMBL158774,TP,ACT,1.0	CHEMBL3694839,TP,ACT,0.8600000143051147	CHEMBL371258,TP,ACT,1.0	CHEMBL399203,TN,INACT,0.0	CHEMBL2403548,TP,ACT,0.8600000143051147	CHEMBL117739,TN,INACT,0.0	CHEMBL1934059,TP,ACT,0.9599999785423279	CHEMBL3326905,TN,INACT,0.0	CHEMBL305313,TP,ACT,1.0	CHEMBL363645,TP,ACT,1.0	CHEMBL1823411,TP,ACT,0.07000000029802322	CHEMBL322537,TN,INACT,0.0	CHEMBL3091477,TP,ACT,0.3499999940395355	CHEMBL2391836,TN,INACT,0.0	CHEMBL45370,TP,ACT,1.0	CHEMBL158662,TP,ACT,1.0	CHEMBL314614,TP,ACT,0.9800000190734863	CHEMBL2112672,TN,INACT,0.0	CHEMBL16592,TP,ACT,0.9399999976158142	CHEMBL320763,TN,INACT,0.0	CHEMBL2031750,TP,ACT,0.019999999552965164	CHEMBL350639,TP,ACT,1.0	CHEMBL27545,TP,ACT,0.9800000190734863	CHEMBL63905,TN,INACT,0.0	CHEMBL551355,TP,ACT,0.9399999976158142	CHEMBL25342,TP,ACT,0.9700000286102295	CHEMBL159190,TP,ACT,0.9700000286102295	CHEMBL3665433,TN,INACT,0.0	CHEMBL558084,TP,ACT,0.23999999463558197	CHEMBL104236,TP,ACT,0.5299999713897705	CHEMBL270241,TP,ACT,1.0	CHEMBL1085326,TP,ACT,1.0	CHEMBL9746,TN,INACT,0.0	CHEMBL150260,TN,INACT,0.0	CHEMBL19469,FN,ACT,0.0	CHEMBL288641,TN,INACT,0.0	CHEMBL2113072,TN,INACT,0.0	CHEMBL1084878,TP,ACT,0.9399999976158142	CHEMBL63112,TP,ACT,1.0	CHEMBL2153622,TN,INACT,0.0	CHEMBL352869,TP,ACT,1.0	CHEMBL1829335,TP,ACT,1.0	CHEMBL107681,TN,INACT,0.0	CHEMBL86968,TN,INACT,0.0	CHEMBL435810,TN,INACT,0.0	CHEMBL323854,TN,INACT,0.0	CHEMBL3290985,TN,INACT,0.0	CHEMBL248155,TP,ACT,1.0	CHEMBL208610,TP,ACT,1.0	CHEMBL316524,TP,ACT,0.6700000166893005	CHEMBL128360,TN,INACT,0.0	CHEMBL104981,TN,INACT,0.0	CHEMBL3735036,TN,INACT,0.0	CHEMBL148967,TN,INACT,0.0	CHEMBL293874,TN,INACT,0.0	CHEMBL104106,TP,ACT,1.0	CHEMBL51280,TN,INACT,0.0	

