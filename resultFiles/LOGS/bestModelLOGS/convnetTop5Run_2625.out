CNNModel CHEMBL267 adam 0.0001 30 256 0 0.6 False True
Number of active compounds :	2413
Number of inactive compounds :	2413
---------------------------------
Run id: CNNModel_CHEMBL267_adam_0.0001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL267_adam_0.0001_30_256_0.6_True/
---------------------------------
Training samples: 3072
Validation samples: 961
--
Training Step: 1  | time: 1.485s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/3072
[A[ATraining Step: 2  | total loss: [1m[32m0.62377[0m[0m | time: 2.645s
[2K
| Adam | epoch: 001 | loss: 0.62377 - acc: 0.4500 -- iter: 0064/3072
[A[ATraining Step: 3  | total loss: [1m[32m0.68051[0m[0m | time: 3.982s
[2K
| Adam | epoch: 001 | loss: 0.68051 - acc: 0.4653 -- iter: 0096/3072
[A[ATraining Step: 4  | total loss: [1m[32m0.69015[0m[0m | time: 5.334s
[2K
| Adam | epoch: 001 | loss: 0.69015 - acc: 0.4445 -- iter: 0128/3072
[A[ATraining Step: 5  | total loss: [1m[32m0.69243[0m[0m | time: 6.480s
[2K
| Adam | epoch: 001 | loss: 0.69243 - acc: 0.4396 -- iter: 0160/3072
[A[ATraining Step: 6  | total loss: [1m[32m0.69291[0m[0m | time: 7.478s
[2K
| Adam | epoch: 001 | loss: 0.69291 - acc: 0.4182 -- iter: 0192/3072
[A[ATraining Step: 7  | total loss: [1m[32m0.69306[0m[0m | time: 8.616s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.4860 -- iter: 0224/3072
[A[ATraining Step: 8  | total loss: [1m[32m0.69285[0m[0m | time: 9.794s
[2K
| Adam | epoch: 001 | loss: 0.69285 - acc: 0.5818 -- iter: 0256/3072
[A[ATraining Step: 9  | total loss: [1m[32m0.69276[0m[0m | time: 11.021s
[2K
| Adam | epoch: 001 | loss: 0.69276 - acc: 0.5716 -- iter: 0288/3072
[A[ATraining Step: 10  | total loss: [1m[32m0.69252[0m[0m | time: 12.174s
[2K
| Adam | epoch: 001 | loss: 0.69252 - acc: 0.5827 -- iter: 0320/3072
[A[ATraining Step: 11  | total loss: [1m[32m0.69254[0m[0m | time: 13.471s
[2K
| Adam | epoch: 001 | loss: 0.69254 - acc: 0.5731 -- iter: 0352/3072
[A[ATraining Step: 12  | total loss: [1m[32m0.69271[0m[0m | time: 14.719s
[2K
| Adam | epoch: 001 | loss: 0.69271 - acc: 0.5402 -- iter: 0384/3072
[A[ATraining Step: 13  | total loss: [1m[32m0.69284[0m[0m | time: 15.892s
[2K
| Adam | epoch: 001 | loss: 0.69284 - acc: 0.5364 -- iter: 0416/3072
[A[ATraining Step: 14  | total loss: [1m[32m0.69379[0m[0m | time: 17.076s
[2K
| Adam | epoch: 001 | loss: 0.69379 - acc: 0.4831 -- iter: 0448/3072
[A[ATraining Step: 15  | total loss: [1m[32m0.69319[0m[0m | time: 18.290s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5142 -- iter: 0480/3072
[A[ATraining Step: 16  | total loss: [1m[32m0.69270[0m[0m | time: 19.669s
[2K
| Adam | epoch: 001 | loss: 0.69270 - acc: 0.5323 -- iter: 0512/3072
[A[ATraining Step: 17  | total loss: [1m[32m0.69263[0m[0m | time: 20.760s
[2K
| Adam | epoch: 001 | loss: 0.69263 - acc: 0.5319 -- iter: 0544/3072
[A[ATraining Step: 18  | total loss: [1m[32m0.69273[0m[0m | time: 21.901s
[2K
| Adam | epoch: 001 | loss: 0.69273 - acc: 0.5209 -- iter: 0576/3072
[A[ATraining Step: 19  | total loss: [1m[32m0.69349[0m[0m | time: 22.878s
[2K
| Adam | epoch: 001 | loss: 0.69349 - acc: 0.4827 -- iter: 0608/3072
[A[ATraining Step: 20  | total loss: [1m[32m0.69261[0m[0m | time: 23.929s
[2K
| Adam | epoch: 001 | loss: 0.69261 - acc: 0.5083 -- iter: 0640/3072
[A[ATraining Step: 21  | total loss: [1m[32m0.69333[0m[0m | time: 25.018s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.4863 -- iter: 0672/3072
[A[ATraining Step: 22  | total loss: [1m[32m0.69370[0m[0m | time: 26.121s
[2K
| Adam | epoch: 001 | loss: 0.69370 - acc: 0.4811 -- iter: 0704/3072
[A[ATraining Step: 23  | total loss: [1m[32m0.69396[0m[0m | time: 27.308s
[2K
| Adam | epoch: 001 | loss: 0.69396 - acc: 0.4775 -- iter: 0736/3072
[A[ATraining Step: 24  | total loss: [1m[32m0.69384[0m[0m | time: 28.487s
[2K
| Adam | epoch: 001 | loss: 0.69384 - acc: 0.4838 -- iter: 0768/3072
[A[ATraining Step: 25  | total loss: [1m[32m0.69305[0m[0m | time: 29.594s
[2K
| Adam | epoch: 001 | loss: 0.69305 - acc: 0.5138 -- iter: 0800/3072
[A[ATraining Step: 26  | total loss: [1m[32m0.69289[0m[0m | time: 30.670s
[2K
| Adam | epoch: 001 | loss: 0.69289 - acc: 0.5184 -- iter: 0832/3072
[A[ATraining Step: 27  | total loss: [1m[32m0.69377[0m[0m | time: 31.888s
[2K
| Adam | epoch: 001 | loss: 0.69377 - acc: 0.4815 -- iter: 0864/3072
[A[ATraining Step: 28  | total loss: [1m[32m0.69321[0m[0m | time: 33.082s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.5018 -- iter: 0896/3072
[A[ATraining Step: 29  | total loss: [1m[32m0.69306[0m[0m | time: 34.261s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.5089 -- iter: 0928/3072
[A[ATraining Step: 30  | total loss: [1m[32m0.69232[0m[0m | time: 35.144s
[2K
| Adam | epoch: 001 | loss: 0.69232 - acc: 0.5364 -- iter: 0960/3072
[A[ATraining Step: 31  | total loss: [1m[32m0.69337[0m[0m | time: 36.348s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.4992 -- iter: 0992/3072
[A[ATraining Step: 32  | total loss: [1m[32m0.69344[0m[0m | time: 37.580s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.4923 -- iter: 1024/3072
[A[ATraining Step: 33  | total loss: [1m[32m0.69380[0m[0m | time: 38.788s
[2K
| Adam | epoch: 001 | loss: 0.69380 - acc: 0.4803 -- iter: 1056/3072
[A[ATraining Step: 34  | total loss: [1m[32m0.69392[0m[0m | time: 39.740s
[2K
| Adam | epoch: 001 | loss: 0.69392 - acc: 0.4711 -- iter: 1088/3072
[A[ATraining Step: 35  | total loss: [1m[32m0.69360[0m[0m | time: 40.918s
[2K
| Adam | epoch: 001 | loss: 0.69360 - acc: 0.4837 -- iter: 1120/3072
[A[ATraining Step: 36  | total loss: [1m[32m0.69349[0m[0m | time: 42.099s
[2K
| Adam | epoch: 001 | loss: 0.69349 - acc: 0.4870 -- iter: 1152/3072
[A[ATraining Step: 37  | total loss: [1m[32m0.69343[0m[0m | time: 43.190s
[2K
| Adam | epoch: 001 | loss: 0.69343 - acc: 0.4896 -- iter: 1184/3072
[A[ATraining Step: 38  | total loss: [1m[32m0.69362[0m[0m | time: 44.206s
[2K
| Adam | epoch: 001 | loss: 0.69362 - acc: 0.4855 -- iter: 1216/3072
[A[ATraining Step: 39  | total loss: [1m[32m0.69363[0m[0m | time: 45.414s
[2K
| Adam | epoch: 001 | loss: 0.69363 - acc: 0.4823 -- iter: 1248/3072
[A[ATraining Step: 40  | total loss: [1m[32m0.69371[0m[0m | time: 46.698s
[2K
| Adam | epoch: 001 | loss: 0.69371 - acc: 0.4739 -- iter: 1280/3072
[A[ATraining Step: 41  | total loss: [1m[32m0.69349[0m[0m | time: 47.921s
[2K
| Adam | epoch: 001 | loss: 0.69349 - acc: 0.4845 -- iter: 1312/3072
[A[ATraining Step: 42  | total loss: [1m[32m0.69326[0m[0m | time: 48.891s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.5041 -- iter: 1344/3072
[A[ATraining Step: 43  | total loss: [1m[32m0.69309[0m[0m | time: 49.962s
[2K
| Adam | epoch: 001 | loss: 0.69309 - acc: 0.5144 -- iter: 1376/3072
[A[ATraining Step: 44  | total loss: [1m[32m0.69294[0m[0m | time: 51.046s
[2K
| Adam | epoch: 001 | loss: 0.69294 - acc: 0.5282 -- iter: 1408/3072
[A[ATraining Step: 45  | total loss: [1m[32m0.69315[0m[0m | time: 52.103s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.5075 -- iter: 1440/3072
[A[ATraining Step: 46  | total loss: [1m[32m0.69315[0m[0m | time: 53.332s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.5062 -- iter: 1472/3072
[A[ATraining Step: 47  | total loss: [1m[32m0.69327[0m[0m | time: 54.563s
[2K
| Adam | epoch: 001 | loss: 0.69327 - acc: 0.4950 -- iter: 1504/3072
[A[ATraining Step: 48  | total loss: [1m[32m0.69320[0m[0m | time: 55.771s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5008 -- iter: 1536/3072
[A[ATraining Step: 49  | total loss: [1m[32m0.69293[0m[0m | time: 56.826s
[2K
| Adam | epoch: 001 | loss: 0.69293 - acc: 0.5253 -- iter: 1568/3072
[A[ATraining Step: 50  | total loss: [1m[32m0.69277[0m[0m | time: 57.804s
[2K
| Adam | epoch: 001 | loss: 0.69277 - acc: 0.5360 -- iter: 1600/3072
[A[ATraining Step: 51  | total loss: [1m[32m0.69287[0m[0m | time: 58.974s
[2K
| Adam | epoch: 001 | loss: 0.69287 - acc: 0.5257 -- iter: 1632/3072
[A[ATraining Step: 52  | total loss: [1m[32m0.69288[0m[0m | time: 60.197s
[2K
| Adam | epoch: 001 | loss: 0.69288 - acc: 0.5172 -- iter: 1664/3072
[A[ATraining Step: 53  | total loss: [1m[32m0.69286[0m[0m | time: 61.438s
[2K
| Adam | epoch: 001 | loss: 0.69286 - acc: 0.5192 -- iter: 1696/3072
[A[ATraining Step: 54  | total loss: [1m[32m0.69313[0m[0m | time: 62.578s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.4983 -- iter: 1728/3072
[A[ATraining Step: 55  | total loss: [1m[32m0.69292[0m[0m | time: 63.628s
[2K
| Adam | epoch: 001 | loss: 0.69292 - acc: 0.5119 -- iter: 1760/3072
[A[ATraining Step: 56  | total loss: [1m[32m0.69312[0m[0m | time: 64.838s
[2K
| Adam | epoch: 001 | loss: 0.69312 - acc: 0.4927 -- iter: 1792/3072
[A[ATraining Step: 57  | total loss: [1m[32m0.69326[0m[0m | time: 65.923s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.4850 -- iter: 1824/3072
[A[ATraining Step: 58  | total loss: [1m[32m0.69353[0m[0m | time: 67.092s
[2K
| Adam | epoch: 001 | loss: 0.69353 - acc: 0.4700 -- iter: 1856/3072
[A[ATraining Step: 59  | total loss: [1m[32m0.69346[0m[0m | time: 68.187s
[2K
| Adam | epoch: 001 | loss: 0.69346 - acc: 0.4741 -- iter: 1888/3072
[A[ATraining Step: 60  | total loss: [1m[32m0.69340[0m[0m | time: 69.302s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.4734 -- iter: 1920/3072
[A[ATraining Step: 61  | total loss: [1m[32m0.69336[0m[0m | time: 70.685s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4809 -- iter: 1952/3072
[A[ATraining Step: 62  | total loss: [1m[32m0.69318[0m[0m | time: 71.946s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.4994 -- iter: 1984/3072
[A[ATraining Step: 63  | total loss: [1m[32m0.69326[0m[0m | time: 73.040s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.4916 -- iter: 2016/3072
[A[ATraining Step: 64  | total loss: [1m[32m0.69305[0m[0m | time: 74.084s
[2K
| Adam | epoch: 001 | loss: 0.69305 - acc: 0.5161 -- iter: 2048/3072
[A[ATraining Step: 65  | total loss: [1m[32m0.69313[0m[0m | time: 75.197s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.5025 -- iter: 2080/3072
[A[ATraining Step: 66  | total loss: [1m[32m0.69324[0m[0m | time: 76.346s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.4908 -- iter: 2112/3072
[A[ATraining Step: 67  | total loss: [1m[32m0.69317[0m[0m | time: 77.336s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.5032 -- iter: 2144/3072
[A[ATraining Step: 68  | total loss: [1m[32m0.69329[0m[0m | time: 78.422s
[2K
| Adam | epoch: 001 | loss: 0.69329 - acc: 0.4917 -- iter: 2176/3072
[A[ATraining Step: 69  | total loss: [1m[32m0.69339[0m[0m | time: 79.522s
[2K
| Adam | epoch: 001 | loss: 0.69339 - acc: 0.4854 -- iter: 2208/3072
[A[ATraining Step: 70  | total loss: [1m[32m0.69340[0m[0m | time: 80.637s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.4762 -- iter: 2240/3072
[A[ATraining Step: 71  | total loss: [1m[32m0.69345[0m[0m | time: 81.757s
[2K
| Adam | epoch: 001 | loss: 0.69345 - acc: 0.4683 -- iter: 2272/3072
[A[ATraining Step: 72  | total loss: [1m[32m0.69341[0m[0m | time: 82.976s
[2K
| Adam | epoch: 001 | loss: 0.69341 - acc: 0.4683 -- iter: 2304/3072
[A[ATraining Step: 73  | total loss: [1m[32m0.69342[0m[0m | time: 84.205s
[2K
| Adam | epoch: 001 | loss: 0.69342 - acc: 0.4545 -- iter: 2336/3072
[A[ATraining Step: 74  | total loss: [1m[32m0.69340[0m[0m | time: 85.382s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.4595 -- iter: 2368/3072
[A[ATraining Step: 75  | total loss: [1m[32m0.69341[0m[0m | time: 86.435s
[2K
| Adam | epoch: 001 | loss: 0.69341 - acc: 0.4469 -- iter: 2400/3072
[A[ATraining Step: 76  | total loss: [1m[32m0.69340[0m[0m | time: 87.746s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.4526 -- iter: 2432/3072
[A[ATraining Step: 77  | total loss: [1m[32m0.69336[0m[0m | time: 89.056s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4642 -- iter: 2464/3072
[A[ATraining Step: 78  | total loss: [1m[32m0.69333[0m[0m | time: 90.382s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.4614 -- iter: 2496/3072
[A[ATraining Step: 79  | total loss: [1m[32m0.69334[0m[0m | time: 91.328s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.4557 -- iter: 2528/3072
[A[ATraining Step: 80  | total loss: [1m[32m0.69334[0m[0m | time: 92.393s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.4475 -- iter: 2560/3072
[A[ATraining Step: 81  | total loss: [1m[32m0.69333[0m[0m | time: 93.551s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.4528 -- iter: 2592/3072
[A[ATraining Step: 82  | total loss: [1m[32m0.69334[0m[0m | time: 94.691s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.4513 -- iter: 2624/3072
[A[ATraining Step: 83  | total loss: [1m[32m0.69331[0m[0m | time: 95.795s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4686 -- iter: 2656/3072
[A[ATraining Step: 84  | total loss: [1m[32m0.69328[0m[0m | time: 97.095s
[2K
| Adam | epoch: 001 | loss: 0.69328 - acc: 0.4718 -- iter: 2688/3072
[A[ATraining Step: 85  | total loss: [1m[32m0.69329[0m[0m | time: 98.412s
[2K
| Adam | epoch: 001 | loss: 0.69329 - acc: 0.4746 -- iter: 2720/3072
[A[ATraining Step: 86  | total loss: [1m[32m0.69330[0m[0m | time: 99.543s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.4709 -- iter: 2752/3072
[A[ATraining Step: 87  | total loss: [1m[32m0.69325[0m[0m | time: 100.617s
[2K
| Adam | epoch: 001 | loss: 0.69325 - acc: 0.4925 -- iter: 2784/3072
[A[ATraining Step: 88  | total loss: [1m[32m0.69324[0m[0m | time: 101.863s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.4995 -- iter: 2816/3072
[A[ATraining Step: 89  | total loss: [1m[32m0.69321[0m[0m | time: 102.964s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.5027 -- iter: 2848/3072
[A[ATraining Step: 90  | total loss: [1m[32m0.69323[0m[0m | time: 104.179s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.4962 -- iter: 2880/3072
[A[ATraining Step: 91  | total loss: [1m[32m0.69326[0m[0m | time: 105.309s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.4903 -- iter: 2912/3072
[A[ATraining Step: 92  | total loss: [1m[32m0.69323[0m[0m | time: 106.454s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.4944 -- iter: 2944/3072
[A[ATraining Step: 93  | total loss: [1m[32m0.69321[0m[0m | time: 107.396s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.4918 -- iter: 2976/3072
[A[ATraining Step: 94  | total loss: [1m[32m0.69322[0m[0m | time: 108.497s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4927 -- iter: 3008/3072
[A[ATraining Step: 95  | total loss: [1m[32m0.69319[0m[0m | time: 109.642s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.4934 -- iter: 3040/3072
[A[ATraining Step: 96  | total loss: [1m[32m0.69309[0m[0m | time: 117.094s
[2K
| Adam | epoch: 001 | loss: 0.69309 - acc: 0.5128 | val_loss: 0.69316 - val_acc: 0.4891 -- iter: 3072/3072
--
Training Step: 97  | total loss: [1m[32m0.69308[0m[0m | time: 0.994s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5115 -- iter: 0032/3072
[A[ATraining Step: 98  | total loss: [1m[32m0.69309[0m[0m | time: 2.180s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5104 -- iter: 0064/3072
[A[ATraining Step: 99  | total loss: [1m[32m0.69305[0m[0m | time: 3.420s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5156 -- iter: 0096/3072
[A[ATraining Step: 100  | total loss: [1m[32m0.69306[0m[0m | time: 4.615s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5140 -- iter: 0128/3072
[A[ATraining Step: 101  | total loss: [1m[32m0.69316[0m[0m | time: 5.787s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5001 -- iter: 0160/3072
[A[ATraining Step: 102  | total loss: [1m[32m0.69321[0m[0m | time: 7.016s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4939 -- iter: 0192/3072
[A[ATraining Step: 103  | total loss: [1m[32m0.69320[0m[0m | time: 8.307s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.4945 -- iter: 0224/3072
[A[ATraining Step: 104  | total loss: [1m[32m0.69322[0m[0m | time: 9.510s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4919 -- iter: 0256/3072
[A[ATraining Step: 105  | total loss: [1m[32m0.69325[0m[0m | time: 10.621s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4865 -- iter: 0288/3072
[A[ATraining Step: 106  | total loss: [1m[32m0.69332[0m[0m | time: 11.834s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4691 -- iter: 0320/3072
[A[ATraining Step: 107  | total loss: [1m[32m0.69329[0m[0m | time: 13.092s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4753 -- iter: 0352/3072
[A[ATraining Step: 108  | total loss: [1m[32m0.69328[0m[0m | time: 14.392s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4778 -- iter: 0384/3072
[A[ATraining Step: 109  | total loss: [1m[32m0.69324[0m[0m | time: 15.307s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4862 -- iter: 0416/3072
[A[ATraining Step: 110  | total loss: [1m[32m0.69328[0m[0m | time: 16.475s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4782 -- iter: 0448/3072
[A[ATraining Step: 111  | total loss: [1m[32m0.69326[0m[0m | time: 17.666s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4804 -- iter: 0480/3072
[A[ATraining Step: 112  | total loss: [1m[32m0.69324[0m[0m | time: 18.836s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4855 -- iter: 0512/3072
[A[ATraining Step: 113  | total loss: [1m[32m0.69321[0m[0m | time: 20.040s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4932 -- iter: 0544/3072
[A[ATraining Step: 114  | total loss: [1m[32m0.69321[0m[0m | time: 21.186s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4970 -- iter: 0576/3072
[A[ATraining Step: 115  | total loss: [1m[32m0.69318[0m[0m | time: 22.456s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5067 -- iter: 0608/3072
[A[ATraining Step: 116  | total loss: [1m[32m0.69321[0m[0m | time: 23.670s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5060 -- iter: 0640/3072
[A[ATraining Step: 117  | total loss: [1m[32m0.69319[0m[0m | time: 24.867s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5085 -- iter: 0672/3072
[A[ATraining Step: 118  | total loss: [1m[32m0.69318[0m[0m | time: 26.075s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5108 -- iter: 0704/3072
[A[ATraining Step: 119  | total loss: [1m[32m0.69315[0m[0m | time: 27.283s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5191 -- iter: 0736/3072
[A[ATraining Step: 120  | total loss: [1m[32m0.69312[0m[0m | time: 28.587s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5359 -- iter: 0768/3072
[A[ATraining Step: 121  | total loss: [1m[32m0.69310[0m[0m | time: 29.917s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5386 -- iter: 0800/3072
[A[ATraining Step: 122  | total loss: [1m[32m0.69314[0m[0m | time: 30.897s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5285 -- iter: 0832/3072
[A[ATraining Step: 123  | total loss: [1m[32m0.69302[0m[0m | time: 32.004s
[2K
| Adam | epoch: 002 | loss: 0.69302 - acc: 0.5506 -- iter: 0864/3072
[A[ATraining Step: 124  | total loss: [1m[32m0.69300[0m[0m | time: 33.199s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5456 -- iter: 0896/3072
[A[ATraining Step: 125  | total loss: [1m[32m0.69307[0m[0m | time: 34.359s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5348 -- iter: 0928/3072
[A[ATraining Step: 126  | total loss: [1m[32m0.69306[0m[0m | time: 35.535s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5344 -- iter: 0960/3072
[A[ATraining Step: 127  | total loss: [1m[32m0.69307[0m[0m | time: 36.801s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5310 -- iter: 0992/3072
[A[ATraining Step: 128  | total loss: [1m[32m0.69305[0m[0m | time: 38.016s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5279 -- iter: 1024/3072
[A[ATraining Step: 129  | total loss: [1m[32m0.69323[0m[0m | time: 39.269s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.5126 -- iter: 1056/3072
[A[ATraining Step: 130  | total loss: [1m[32m0.69330[0m[0m | time: 40.422s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.5051 -- iter: 1088/3072
[A[ATraining Step: 131  | total loss: [1m[32m0.69321[0m[0m | time: 41.643s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5077 -- iter: 1120/3072
[A[ATraining Step: 132  | total loss: [1m[32m0.69320[0m[0m | time: 42.875s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5069 -- iter: 1152/3072
[A[ATraining Step: 133  | total loss: [1m[32m0.69317[0m[0m | time: 44.127s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.5094 -- iter: 1184/3072
[A[ATraining Step: 134  | total loss: [1m[32m0.69339[0m[0m | time: 45.385s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.4928 -- iter: 1216/3072
[A[ATraining Step: 135  | total loss: [1m[32m0.69333[0m[0m | time: 46.478s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4935 -- iter: 1248/3072
[A[ATraining Step: 136  | total loss: [1m[32m0.69306[0m[0m | time: 47.688s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5160 -- iter: 1280/3072
[A[ATraining Step: 137  | total loss: [1m[32m0.69306[0m[0m | time: 48.785s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5144 -- iter: 1312/3072
[A[ATraining Step: 138  | total loss: [1m[32m0.69315[0m[0m | time: 49.947s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5067 -- iter: 1344/3072
[A[ATraining Step: 139  | total loss: [1m[32m0.69300[0m[0m | time: 51.201s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5186 -- iter: 1376/3072
[A[ATraining Step: 140  | total loss: [1m[32m0.69313[0m[0m | time: 52.427s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.5105 -- iter: 1408/3072
[A[ATraining Step: 141  | total loss: [1m[32m0.69314[0m[0m | time: 53.702s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5063 -- iter: 1440/3072
[A[ATraining Step: 142  | total loss: [1m[32m0.69313[0m[0m | time: 55.011s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.5057 -- iter: 1472/3072
[A[ATraining Step: 143  | total loss: [1m[32m0.69321[0m[0m | time: 56.189s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5020 -- iter: 1504/3072
[A[ATraining Step: 144  | total loss: [1m[32m0.69327[0m[0m | time: 57.424s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.5018 -- iter: 1536/3072
[A[ATraining Step: 145  | total loss: [1m[32m0.69314[0m[0m | time: 58.668s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5078 -- iter: 1568/3072
[A[ATraining Step: 146  | total loss: [1m[32m0.69339[0m[0m | time: 59.829s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.4883 -- iter: 1600/3072
[A[ATraining Step: 147  | total loss: [1m[32m0.69328[0m[0m | time: 60.890s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4989 -- iter: 1632/3072
[A[ATraining Step: 148  | total loss: [1m[32m0.69340[0m[0m | time: 61.985s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.4865 -- iter: 1664/3072
[A[ATraining Step: 149  | total loss: [1m[32m0.69330[0m[0m | time: 63.147s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4972 -- iter: 1696/3072
[A[ATraining Step: 150  | total loss: [1m[32m0.69341[0m[0m | time: 64.243s
[2K
| Adam | epoch: 002 | loss: 0.69341 - acc: 0.4819 -- iter: 1728/3072
[A[ATraining Step: 151  | total loss: [1m[32m0.69332[0m[0m | time: 65.444s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4930 -- iter: 1760/3072
[A[ATraining Step: 152  | total loss: [1m[32m0.69333[0m[0m | time: 66.593s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4906 -- iter: 1792/3072
[A[ATraining Step: 153  | total loss: [1m[32m0.69329[0m[0m | time: 67.758s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4947 -- iter: 1824/3072
[A[ATraining Step: 154  | total loss: [1m[32m0.69326[0m[0m | time: 68.982s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4983 -- iter: 1856/3072
[A[ATraining Step: 155  | total loss: [1m[32m0.69329[0m[0m | time: 70.203s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4891 -- iter: 1888/3072
[A[ATraining Step: 156  | total loss: [1m[32m0.69326[0m[0m | time: 71.406s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4965 -- iter: 1920/3072
[A[ATraining Step: 157  | total loss: [1m[32m0.69324[0m[0m | time: 72.651s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4968 -- iter: 1952/3072
[A[ATraining Step: 158  | total loss: [1m[32m0.69321[0m[0m | time: 73.941s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4940 -- iter: 1984/3072
[A[ATraining Step: 159  | total loss: [1m[32m0.69329[0m[0m | time: 75.194s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4759 -- iter: 2016/3072
[A[ATraining Step: 160  | total loss: [1m[32m0.69329[0m[0m | time: 76.389s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4751 -- iter: 2048/3072
[A[ATraining Step: 161  | total loss: [1m[32m0.69327[0m[0m | time: 77.666s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4839 -- iter: 2080/3072
[A[ATraining Step: 162  | total loss: [1m[32m0.69327[0m[0m | time: 78.967s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4792 -- iter: 2112/3072
[A[ATraining Step: 163  | total loss: [1m[32m0.69328[0m[0m | time: 80.160s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4751 -- iter: 2144/3072
[A[ATraining Step: 164  | total loss: [1m[32m0.69324[0m[0m | time: 81.465s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4869 -- iter: 2176/3072
[A[ATraining Step: 165  | total loss: [1m[32m0.69321[0m[0m | time: 82.699s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4914 -- iter: 2208/3072
[A[ATraining Step: 166  | total loss: [1m[32m0.69325[0m[0m | time: 83.987s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4766 -- iter: 2240/3072
[A[ATraining Step: 167  | total loss: [1m[32m0.69318[0m[0m | time: 85.170s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.4946 -- iter: 2272/3072
[A[ATraining Step: 168  | total loss: [1m[32m0.69324[0m[0m | time: 86.472s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4701 -- iter: 2304/3072
[A[ATraining Step: 169  | total loss: [1m[32m0.69322[0m[0m | time: 87.823s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4700 -- iter: 2336/3072
[A[ATraining Step: 170  | total loss: [1m[32m0.69322[0m[0m | time: 89.107s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4761 -- iter: 2368/3072
[A[ATraining Step: 171  | total loss: [1m[32m0.69320[0m[0m | time: 90.285s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.4785 -- iter: 2400/3072
[A[ATraining Step: 172  | total loss: [1m[32m0.69320[0m[0m | time: 91.446s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.4806 -- iter: 2432/3072
[A[ATraining Step: 173  | total loss: [1m[32m0.69319[0m[0m | time: 92.320s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.4826 -- iter: 2464/3072
[A[ATraining Step: 174  | total loss: [1m[32m0.69316[0m[0m | time: 93.242s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.4999 -- iter: 2496/3072
[A[ATraining Step: 175  | total loss: [1m[32m0.69320[0m[0m | time: 94.204s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.4812 -- iter: 2528/3072
[A[ATraining Step: 176  | total loss: [1m[32m0.69314[0m[0m | time: 95.181s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5050 -- iter: 2560/3072
[A[ATraining Step: 177  | total loss: [1m[32m0.69312[0m[0m | time: 96.076s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5045 -- iter: 2592/3072
[A[ATraining Step: 178  | total loss: [1m[32m0.69314[0m[0m | time: 96.994s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.4946 -- iter: 2624/3072
[A[ATraining Step: 179  | total loss: [1m[32m0.69308[0m[0m | time: 97.941s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5046 -- iter: 2656/3072
[A[ATraining Step: 180  | total loss: [1m[32m0.69306[0m[0m | time: 98.864s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5072 -- iter: 2688/3072
[A[ATraining Step: 181  | total loss: [1m[32m0.69303[0m[0m | time: 99.799s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5127 -- iter: 2720/3072
[A[ATraining Step: 182  | total loss: [1m[32m0.69303[0m[0m | time: 100.724s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5115 -- iter: 2752/3072
[A[ATraining Step: 183  | total loss: [1m[32m0.69309[0m[0m | time: 101.653s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5041 -- iter: 2784/3072
[A[ATraining Step: 184  | total loss: [1m[32m0.69313[0m[0m | time: 102.563s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.4974 -- iter: 2816/3072
[A[ATraining Step: 185  | total loss: [1m[32m0.69314[0m[0m | time: 103.497s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.4977 -- iter: 2848/3072
[A[ATraining Step: 186  | total loss: [1m[32m0.69315[0m[0m | time: 104.392s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.4948 -- iter: 2880/3072
[A[ATraining Step: 187  | total loss: [1m[32m0.69321[0m[0m | time: 105.319s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4922 -- iter: 2912/3072
[A[ATraining Step: 188  | total loss: [1m[32m0.69307[0m[0m | time: 106.255s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5023 -- iter: 2944/3072
[A[ATraining Step: 189  | total loss: [1m[32m0.69321[0m[0m | time: 107.202s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4927 -- iter: 2976/3072
[A[ATraining Step: 190  | total loss: [1m[32m0.69337[0m[0m | time: 108.106s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4778 -- iter: 3008/3072
[A[ATraining Step: 191  | total loss: [1m[32m0.69333[0m[0m | time: 109.061s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4769 -- iter: 3040/3072
[A[ATraining Step: 192  | total loss: [1m[32m0.69340[0m[0m | time: 114.427s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.4667 | val_loss: 0.69309 - val_acc: 0.4891 -- iter: 3072/3072
--
Training Step: 193  | total loss: [1m[32m0.69337[0m[0m | time: 0.918s
[2K
| Adam | epoch: 003 | loss: 0.69337 - acc: 0.4701 -- iter: 0032/3072
[A[ATraining Step: 194  | total loss: [1m[32m0.69327[0m[0m | time: 1.875s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.4856 -- iter: 0064/3072
[A[ATraining Step: 195  | total loss: [1m[32m0.69321[0m[0m | time: 3.124s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.4995 -- iter: 0096/3072
[A[ATraining Step: 196  | total loss: [1m[32m0.69316[0m[0m | time: 4.352s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.5058 -- iter: 0128/3072
[A[ATraining Step: 197  | total loss: [1m[32m0.69315[0m[0m | time: 5.201s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5052 -- iter: 0160/3072
[A[ATraining Step: 198  | total loss: [1m[32m0.69317[0m[0m | time: 6.102s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.5016 -- iter: 0192/3072
[A[ATraining Step: 199  | total loss: [1m[32m0.69320[0m[0m | time: 6.963s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.4952 -- iter: 0224/3072
[A[ATraining Step: 200  | total loss: [1m[32m0.69324[0m[0m | time: 12.145s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4894 | val_loss: 0.69307 - val_acc: 0.4891 -- iter: 0256/3072
--
Training Step: 201  | total loss: [1m[32m0.69329[0m[0m | time: 13.167s
[2K
| Adam | epoch: 003 | loss: 0.69329 - acc: 0.4748 -- iter: 0288/3072
[A[ATraining Step: 202  | total loss: [1m[32m0.69323[0m[0m | time: 14.212s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.4836 -- iter: 0320/3072
[A[ATraining Step: 203  | total loss: [1m[32m0.69324[0m[0m | time: 14.986s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4852 -- iter: 0352/3072
[A[ATraining Step: 204  | total loss: [1m[32m0.69324[0m[0m | time: 15.810s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4836 -- iter: 0384/3072
[A[ATraining Step: 205  | total loss: [1m[32m0.69321[0m[0m | time: 16.733s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.4821 -- iter: 0416/3072
[A[ATraining Step: 206  | total loss: [1m[32m0.69315[0m[0m | time: 17.673s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.4995 -- iter: 0448/3072
[A[ATraining Step: 207  | total loss: [1m[32m0.69318[0m[0m | time: 18.598s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.4871 -- iter: 0480/3072
[A[ATraining Step: 208  | total loss: [1m[32m0.69315[0m[0m | time: 19.566s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.4977 -- iter: 0512/3072
[A[ATraining Step: 209  | total loss: [1m[32m0.69311[0m[0m | time: 20.516s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5073 -- iter: 0544/3072
[A[ATraining Step: 210  | total loss: [1m[32m0.69310[0m[0m | time: 21.316s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5097 -- iter: 0576/3072
[A[ATraining Step: 211  | total loss: [1m[32m0.69308[0m[0m | time: 22.373s
[2K
| Adam | epoch: 003 | loss: 0.69308 - acc: 0.5119 -- iter: 0608/3072
[A[ATraining Step: 212  | total loss: [1m[32m0.69307[0m[0m | time: 23.483s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5107 -- iter: 0640/3072
[A[ATraining Step: 213  | total loss: [1m[32m0.69307[0m[0m | time: 24.542s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5096 -- iter: 0672/3072
[A[ATraining Step: 214  | total loss: [1m[32m0.69302[0m[0m | time: 25.394s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5180 -- iter: 0704/3072
[A[ATraining Step: 215  | total loss: [1m[32m0.69300[0m[0m | time: 26.338s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5225 -- iter: 0736/3072
[A[ATraining Step: 216  | total loss: [1m[32m0.69313[0m[0m | time: 27.235s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5046 -- iter: 0768/3072
[A[ATraining Step: 217  | total loss: [1m[32m0.69312[0m[0m | time: 28.205s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.5010 -- iter: 0800/3072
[A[ATraining Step: 218  | total loss: [1m[32m0.69310[0m[0m | time: 29.184s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5040 -- iter: 0832/3072
[A[ATraining Step: 219  | total loss: [1m[32m0.69313[0m[0m | time: 30.135s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.4974 -- iter: 0864/3072
[A[ATraining Step: 220  | total loss: [1m[32m0.69313[0m[0m | time: 31.004s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.4945 -- iter: 0896/3072
[A[ATraining Step: 221  | total loss: [1m[32m0.69311[0m[0m | time: 31.885s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.4982 -- iter: 0928/3072
[A[ATraining Step: 222  | total loss: [1m[32m0.69316[0m[0m | time: 32.912s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4859 -- iter: 0960/3072
[A[ATraining Step: 223  | total loss: [1m[32m0.69309[0m[0m | time: 33.995s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.4967 -- iter: 0992/3072
[A[ATraining Step: 224  | total loss: [1m[32m0.69306[0m[0m | time: 34.929s
[2K
| Adam | epoch: 003 | loss: 0.69306 - acc: 0.5001 -- iter: 1024/3072
[A[ATraining Step: 225  | total loss: [1m[32m0.69309[0m[0m | time: 35.772s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.4876 -- iter: 1056/3072
[A[ATraining Step: 226  | total loss: [1m[32m0.69301[0m[0m | time: 36.684s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5232 -- iter: 1088/3072
[A[ATraining Step: 227  | total loss: [1m[32m0.69301[0m[0m | time: 38.248s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5334 -- iter: 1120/3072
[A[ATraining Step: 228  | total loss: [1m[32m0.69299[0m[0m | time: 46.580s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5363 -- iter: 1152/3072
[A[ATraining Step: 229  | total loss: [1m[32m0.69297[0m[0m | time: 56.007s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5421 -- iter: 1184/3072
[A[ATraining Step: 230  | total loss: [1m[32m0.69297[0m[0m | time: 56.934s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5379 -- iter: 1216/3072
[A[ATraining Step: 231  | total loss: [1m[32m0.69297[0m[0m | time: 57.834s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5309 -- iter: 1248/3072
[A[ATraining Step: 232  | total loss: [1m[32m0.69300[0m[0m | time: 59.865s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5247 -- iter: 1280/3072
[A[ATraining Step: 233  | total loss: [1m[32m0.69298[0m[0m | time: 82.986s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5316 -- iter: 1312/3072
[A[ATraining Step: 234  | total loss: [1m[32m0.69295[0m[0m | time: 90.522s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5347 -- iter: 1344/3072
[A[ATraining Step: 235  | total loss: [1m[32m0.69288[0m[0m | time: 91.681s
[2K
| Adam | epoch: 003 | loss: 0.69288 - acc: 0.5469 -- iter: 1376/3072
[A[ATraining Step: 236  | total loss: [1m[32m0.69299[0m[0m | time: 92.623s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5297 -- iter: 1408/3072
[A[ATraining Step: 237  | total loss: [1m[32m0.69297[0m[0m | time: 93.979s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5330 -- iter: 1440/3072
[A[ATraining Step: 238  | total loss: [1m[32m0.69283[0m[0m | time: 96.168s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5453 -- iter: 1472/3072
[A[ATraining Step: 239  | total loss: [1m[32m0.69284[0m[0m | time: 110.931s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5439 -- iter: 1504/3072
[A[ATraining Step: 240  | total loss: [1m[32m0.69297[0m[0m | time: 112.449s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5301 -- iter: 1536/3072
[A[ATraining Step: 241  | total loss: [1m[32m0.69316[0m[0m | time: 113.872s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.5146 -- iter: 1568/3072
[A[ATraining Step: 242  | total loss: [1m[32m0.69315[0m[0m | time: 115.337s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5131 -- iter: 1600/3072
[A[ATraining Step: 243  | total loss: [1m[32m0.69286[0m[0m | time: 116.908s
[2K
| Adam | epoch: 003 | loss: 0.69286 - acc: 0.5368 -- iter: 1632/3072
[A[ATraining Step: 244  | total loss: [1m[32m0.69289[0m[0m | time: 118.633s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.5332 -- iter: 1664/3072
[A[ATraining Step: 245  | total loss: [1m[32m0.69283[0m[0m | time: 120.567s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5361 -- iter: 1696/3072
[A[ATraining Step: 246  | total loss: [1m[32m0.69276[0m[0m | time: 122.112s
[2K
| Adam | epoch: 003 | loss: 0.69276 - acc: 0.5387 -- iter: 1728/3072
[A[ATraining Step: 247  | total loss: [1m[32m0.69274[0m[0m | time: 123.798s
[2K
| Adam | epoch: 003 | loss: 0.69274 - acc: 0.5380 -- iter: 1760/3072
[A[ATraining Step: 248  | total loss: [1m[32m0.69273[0m[0m | time: 125.851s
[2K
| Adam | epoch: 003 | loss: 0.69273 - acc: 0.5373 -- iter: 1792/3072
[A[ATraining Step: 249  | total loss: [1m[32m0.69300[0m[0m | time: 127.917s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5211 -- iter: 1824/3072
[A[ATraining Step: 250  | total loss: [1m[32m0.69266[0m[0m | time: 130.219s
[2K
| Adam | epoch: 003 | loss: 0.69266 - acc: 0.5377 -- iter: 1856/3072
[A[ATraining Step: 251  | total loss: [1m[32m0.69254[0m[0m | time: 131.767s
[2K
| Adam | epoch: 003 | loss: 0.69254 - acc: 0.5402 -- iter: 1888/3072
[A[ATraining Step: 252  | total loss: [1m[32m0.69272[0m[0m | time: 133.835s
[2K
| Adam | epoch: 003 | loss: 0.69272 - acc: 0.5299 -- iter: 1920/3072
[A[ATraining Step: 253  | total loss: [1m[32m0.69291[0m[0m | time: 135.873s
[2K
| Adam | epoch: 003 | loss: 0.69291 - acc: 0.5207 -- iter: 1952/3072
[A[ATraining Step: 254  | total loss: [1m[32m0.69311[0m[0m | time: 137.949s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5124 -- iter: 1984/3072
[A[ATraining Step: 255  | total loss: [1m[32m0.69306[0m[0m | time: 139.505s
[2K
| Adam | epoch: 003 | loss: 0.69306 - acc: 0.5111 -- iter: 2016/3072
[A[ATraining Step: 256  | total loss: [1m[32m0.69324[0m[0m | time: 141.209s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.5006 -- iter: 2048/3072
[A[ATraining Step: 257  | total loss: [1m[32m0.69322[0m[0m | time: 142.847s
[2K
| Adam | epoch: 003 | loss: 0.69322 - acc: 0.5037 -- iter: 2080/3072
[A[ATraining Step: 258  | total loss: [1m[32m0.69325[0m[0m | time: 144.567s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.5002 -- iter: 2112/3072
[A[ATraining Step: 259  | total loss: [1m[32m0.69315[0m[0m | time: 146.144s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5064 -- iter: 2144/3072
[A[ATraining Step: 260  | total loss: [1m[32m0.69317[0m[0m | time: 147.764s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.5027 -- iter: 2176/3072
[A[ATraining Step: 261  | total loss: [1m[32m0.69313[0m[0m | time: 149.391s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5055 -- iter: 2208/3072
[A[ATraining Step: 262  | total loss: [1m[32m0.69339[0m[0m | time: 151.245s
[2K
| Adam | epoch: 003 | loss: 0.69339 - acc: 0.4925 -- iter: 2240/3072
[A[ATraining Step: 263  | total loss: [1m[32m0.69308[0m[0m | time: 152.970s
[2K
| Adam | epoch: 003 | loss: 0.69308 - acc: 0.5026 -- iter: 2272/3072
[A[ATraining Step: 264  | total loss: [1m[32m0.69311[0m[0m | time: 154.749s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5023 -- iter: 2304/3072
[A[ATraining Step: 265  | total loss: [1m[32m0.69277[0m[0m | time: 156.354s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5115 -- iter: 2336/3072
[A[ATraining Step: 266  | total loss: [1m[32m0.69242[0m[0m | time: 157.986s
[2K
| Adam | epoch: 003 | loss: 0.69242 - acc: 0.5228 -- iter: 2368/3072
[A[ATraining Step: 267  | total loss: [1m[32m0.69224[0m[0m | time: 159.537s
[2K
| Adam | epoch: 003 | loss: 0.69224 - acc: 0.5268 -- iter: 2400/3072
[A[ATraining Step: 268  | total loss: [1m[32m0.69250[0m[0m | time: 161.399s
[2K
| Adam | epoch: 003 | loss: 0.69250 - acc: 0.5210 -- iter: 2432/3072
[A[ATraining Step: 269  | total loss: [1m[32m0.69301[0m[0m | time: 163.128s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5126 -- iter: 2464/3072
[A[ATraining Step: 270  | total loss: [1m[32m0.69327[0m[0m | time: 164.922s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.5083 -- iter: 2496/3072
[A[ATraining Step: 271  | total loss: [1m[32m0.69388[0m[0m | time: 166.703s
[2K
| Adam | epoch: 003 | loss: 0.69388 - acc: 0.4981 -- iter: 2528/3072
[A[ATraining Step: 272  | total loss: [1m[32m0.69414[0m[0m | time: 168.532s
[2K
| Adam | epoch: 003 | loss: 0.69414 - acc: 0.4920 -- iter: 2560/3072
[A[ATraining Step: 273  | total loss: [1m[32m0.69347[0m[0m | time: 170.139s
[2K
| Adam | epoch: 003 | loss: 0.69347 - acc: 0.5053 -- iter: 2592/3072
[A[ATraining Step: 274  | total loss: [1m[32m0.69370[0m[0m | time: 171.927s
[2K
| Adam | epoch: 003 | loss: 0.69370 - acc: 0.4985 -- iter: 2624/3072
[A[ATraining Step: 275  | total loss: [1m[32m0.69355[0m[0m | time: 173.473s
[2K
| Adam | epoch: 003 | loss: 0.69355 - acc: 0.5018 -- iter: 2656/3072
[A[ATraining Step: 276  | total loss: [1m[32m0.69335[0m[0m | time: 175.256s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.5047 -- iter: 2688/3072
[A[ATraining Step: 277  | total loss: [1m[32m0.69342[0m[0m | time: 176.847s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.5011 -- iter: 2720/3072
[A[ATraining Step: 278  | total loss: [1m[32m0.69322[0m[0m | time: 178.399s
[2K
| Adam | epoch: 003 | loss: 0.69322 - acc: 0.5042 -- iter: 2752/3072
[A[ATraining Step: 279  | total loss: [1m[32m0.69287[0m[0m | time: 180.153s
[2K
| Adam | epoch: 003 | loss: 0.69287 - acc: 0.5162 -- iter: 2784/3072
[A[ATraining Step: 280  | total loss: [1m[32m0.69291[0m[0m | time: 181.487s
[2K
| Adam | epoch: 003 | loss: 0.69291 - acc: 0.5115 -- iter: 2816/3072
[A[ATraining Step: 281  | total loss: [1m[32m0.69273[0m[0m | time: 183.307s
[2K
| Adam | epoch: 003 | loss: 0.69273 - acc: 0.5135 -- iter: 2848/3072
[A[ATraining Step: 282  | total loss: [1m[32m0.69257[0m[0m | time: 200.292s
[2K
| Adam | epoch: 003 | loss: 0.69257 - acc: 0.5152 -- iter: 2880/3072
[A[ATraining Step: 283  | total loss: [1m[32m0.69252[0m[0m | time: 201.199s
[2K
| Adam | epoch: 003 | loss: 0.69252 - acc: 0.5137 -- iter: 2912/3072
[A[ATraining Step: 284  | total loss: [1m[32m0.69260[0m[0m | time: 202.031s
[2K
| Adam | epoch: 003 | loss: 0.69260 - acc: 0.5092 -- iter: 2944/3072
[A[ATraining Step: 285  | total loss: [1m[32m0.69288[0m[0m | time: 203.021s
[2K
| Adam | epoch: 003 | loss: 0.69288 - acc: 0.5020 -- iter: 2976/3072
[A[ATraining Step: 286  | total loss: [1m[32m0.69295[0m[0m | time: 203.950s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.4987 -- iter: 3008/3072
[A[ATraining Step: 287  | total loss: [1m[32m0.69293[0m[0m | time: 204.867s
[2K
| Adam | epoch: 003 | loss: 0.69293 - acc: 0.4957 -- iter: 3040/3072
[A[ATraining Step: 288  | total loss: [1m[32m0.69294[0m[0m | time: 210.154s
[2K
| Adam | epoch: 003 | loss: 0.69294 - acc: 0.4961 | val_loss: 0.69253 - val_acc: 0.4891 -- iter: 3072/3072
--
Training Step: 289  | total loss: [1m[32m0.69272[0m[0m | time: 1.017s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.4997 -- iter: 0032/3072
[A[ATraining Step: 290  | total loss: [1m[32m0.69272[0m[0m | time: 1.885s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.4997 -- iter: 0064/3072
[A[ATraining Step: 291  | total loss: [1m[32m0.69252[0m[0m | time: 2.806s
[2K
| Adam | epoch: 004 | loss: 0.69252 - acc: 0.5060 -- iter: 0096/3072
[A[ATraining Step: 292  | total loss: [1m[32m0.69229[0m[0m | time: 3.757s
[2K
| Adam | epoch: 004 | loss: 0.69229 - acc: 0.5116 -- iter: 0128/3072
[A[ATraining Step: 293  | total loss: [1m[32m0.69239[0m[0m | time: 4.671s
[2K
| Adam | epoch: 004 | loss: 0.69239 - acc: 0.5073 -- iter: 0160/3072
[A[ATraining Step: 294  | total loss: [1m[32m0.69216[0m[0m | time: 5.551s
[2K
| Adam | epoch: 004 | loss: 0.69216 - acc: 0.5097 -- iter: 0192/3072
[A[ATraining Step: 295  | total loss: [1m[32m0.69205[0m[0m | time: 6.582s
[2K
| Adam | epoch: 004 | loss: 0.69205 - acc: 0.5088 -- iter: 0224/3072
[A[ATraining Step: 296  | total loss: [1m[32m0.69127[0m[0m | time: 7.630s
[2K
| Adam | epoch: 004 | loss: 0.69127 - acc: 0.5298 -- iter: 0256/3072
[A[ATraining Step: 297  | total loss: [1m[32m0.69140[0m[0m | time: 8.472s
[2K
| Adam | epoch: 004 | loss: 0.69140 - acc: 0.5237 -- iter: 0288/3072
[A[ATraining Step: 298  | total loss: [1m[32m0.69202[0m[0m | time: 9.390s
[2K
| Adam | epoch: 004 | loss: 0.69202 - acc: 0.5150 -- iter: 0320/3072
[A[ATraining Step: 299  | total loss: [1m[32m0.69228[0m[0m | time: 10.269s
[2K
| Adam | epoch: 004 | loss: 0.69228 - acc: 0.5073 -- iter: 0352/3072
[A[ATraining Step: 300  | total loss: [1m[32m0.69212[0m[0m | time: 11.295s
[2K
| Adam | epoch: 004 | loss: 0.69212 - acc: 0.5097 -- iter: 0384/3072
[A[ATraining Step: 301  | total loss: [1m[32m0.69225[0m[0m | time: 12.165s
[2K
| Adam | epoch: 004 | loss: 0.69225 - acc: 0.5056 -- iter: 0416/3072
[A[ATraining Step: 302  | total loss: [1m[32m0.69181[0m[0m | time: 13.102s
[2K
| Adam | epoch: 004 | loss: 0.69181 - acc: 0.5082 -- iter: 0448/3072
[A[ATraining Step: 303  | total loss: [1m[32m0.69187[0m[0m | time: 14.078s
[2K
| Adam | epoch: 004 | loss: 0.69187 - acc: 0.5042 -- iter: 0480/3072
[A[ATraining Step: 304  | total loss: [1m[32m0.69111[0m[0m | time: 14.981s
[2K
| Adam | epoch: 004 | loss: 0.69111 - acc: 0.5163 -- iter: 0512/3072
[A[ATraining Step: 305  | total loss: [1m[32m0.69113[0m[0m | time: 16.122s
[2K
| Adam | epoch: 004 | loss: 0.69113 - acc: 0.5147 -- iter: 0544/3072
[A[ATraining Step: 306  | total loss: [1m[32m0.69249[0m[0m | time: 17.269s
[2K
| Adam | epoch: 004 | loss: 0.69249 - acc: 0.4944 -- iter: 0576/3072
[A[ATraining Step: 307  | total loss: [1m[32m0.69259[0m[0m | time: 18.108s
[2K
| Adam | epoch: 004 | loss: 0.69259 - acc: 0.4919 -- iter: 0608/3072
[A[ATraining Step: 308  | total loss: [1m[32m0.69258[0m[0m | time: 18.931s
[2K
| Adam | epoch: 004 | loss: 0.69258 - acc: 0.4896 -- iter: 0640/3072
[A[ATraining Step: 309  | total loss: [1m[32m0.69251[0m[0m | time: 19.862s
[2K
| Adam | epoch: 004 | loss: 0.69251 - acc: 0.5000 -- iter: 0672/3072
[A[ATraining Step: 310  | total loss: [1m[32m0.69223[0m[0m | time: 20.747s
[2K
| Adam | epoch: 004 | loss: 0.69223 - acc: 0.5094 -- iter: 0704/3072
[A[ATraining Step: 311  | total loss: [1m[32m0.69230[0m[0m | time: 21.642s
[2K
| Adam | epoch: 004 | loss: 0.69230 - acc: 0.5022 -- iter: 0736/3072
[A[ATraining Step: 312  | total loss: [1m[32m0.69218[0m[0m | time: 22.587s
[2K
| Adam | epoch: 004 | loss: 0.69218 - acc: 0.5082 -- iter: 0768/3072
[A[ATraining Step: 313  | total loss: [1m[32m0.69206[0m[0m | time: 23.572s
[2K
| Adam | epoch: 004 | loss: 0.69206 - acc: 0.5136 -- iter: 0800/3072
[A[ATraining Step: 314  | total loss: [1m[32m0.69228[0m[0m | time: 24.460s
[2K
| Adam | epoch: 004 | loss: 0.69228 - acc: 0.5091 -- iter: 0832/3072
[A[ATraining Step: 315  | total loss: [1m[32m0.69205[0m[0m | time: 25.435s
[2K
| Adam | epoch: 004 | loss: 0.69205 - acc: 0.5145 -- iter: 0864/3072
[A[ATraining Step: 316  | total loss: [1m[32m0.69255[0m[0m | time: 26.480s
[2K
| Adam | epoch: 004 | loss: 0.69255 - acc: 0.5037 -- iter: 0896/3072
[A[ATraining Step: 317  | total loss: [1m[32m0.69256[0m[0m | time: 27.460s
[2K
| Adam | epoch: 004 | loss: 0.69256 - acc: 0.5033 -- iter: 0928/3072
[A[ATraining Step: 318  | total loss: [1m[32m0.69246[0m[0m | time: 28.202s
[2K
| Adam | epoch: 004 | loss: 0.69246 - acc: 0.5061 -- iter: 0960/3072
[A[ATraining Step: 319  | total loss: [1m[32m0.69265[0m[0m | time: 29.035s
[2K
| Adam | epoch: 004 | loss: 0.69265 - acc: 0.5024 -- iter: 0992/3072
[A[ATraining Step: 320  | total loss: [1m[32m0.69269[0m[0m | time: 29.904s
[2K
| Adam | epoch: 004 | loss: 0.69269 - acc: 0.4990 -- iter: 1024/3072
[A[ATraining Step: 321  | total loss: [1m[32m0.69267[0m[0m | time: 30.769s
[2K
| Adam | epoch: 004 | loss: 0.69267 - acc: 0.4991 -- iter: 1056/3072
[A[ATraining Step: 322  | total loss: [1m[32m0.69241[0m[0m | time: 31.684s
[2K
| Adam | epoch: 004 | loss: 0.69241 - acc: 0.5054 -- iter: 1088/3072
[A[ATraining Step: 323  | total loss: [1m[32m0.69238[0m[0m | time: 32.758s
[2K
| Adam | epoch: 004 | loss: 0.69238 - acc: 0.5111 -- iter: 1120/3072
[A[ATraining Step: 324  | total loss: [1m[32m0.69228[0m[0m | time: 33.868s
[2K
| Adam | epoch: 004 | loss: 0.69228 - acc: 0.5038 -- iter: 1152/3072
[A[ATraining Step: 325  | total loss: [1m[32m0.69174[0m[0m | time: 34.704s
[2K
| Adam | epoch: 004 | loss: 0.69174 - acc: 0.5097 -- iter: 1184/3072
[A[ATraining Step: 326  | total loss: [1m[32m0.69138[0m[0m | time: 35.783s
[2K
| Adam | epoch: 004 | loss: 0.69138 - acc: 0.5181 -- iter: 1216/3072
[A[ATraining Step: 327  | total loss: [1m[32m0.69030[0m[0m | time: 36.847s
[2K
| Adam | epoch: 004 | loss: 0.69030 - acc: 0.5319 -- iter: 1248/3072
[A[ATraining Step: 328  | total loss: [1m[32m0.69137[0m[0m | time: 37.719s
[2K
| Adam | epoch: 004 | loss: 0.69137 - acc: 0.5224 -- iter: 1280/3072
[A[ATraining Step: 329  | total loss: [1m[32m0.69159[0m[0m | time: 38.572s
[2K
| Adam | epoch: 004 | loss: 0.69159 - acc: 0.5139 -- iter: 1312/3072
[A[ATraining Step: 330  | total loss: [1m[32m0.69162[0m[0m | time: 39.470s
[2K
| Adam | epoch: 004 | loss: 0.69162 - acc: 0.5126 -- iter: 1344/3072
[A[ATraining Step: 331  | total loss: [1m[32m0.69351[0m[0m | time: 40.414s
[2K
| Adam | epoch: 004 | loss: 0.69351 - acc: 0.4957 -- iter: 1376/3072
[A[ATraining Step: 332  | total loss: [1m[32m0.69228[0m[0m | time: 41.321s
[2K
| Adam | epoch: 004 | loss: 0.69228 - acc: 0.5055 -- iter: 1408/3072
[A[ATraining Step: 333  | total loss: [1m[32m0.69113[0m[0m | time: 42.261s
[2K
| Adam | epoch: 004 | loss: 0.69113 - acc: 0.5081 -- iter: 1440/3072
[A[ATraining Step: 334  | total loss: [1m[32m0.69326[0m[0m | time: 43.186s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.4854 -- iter: 1472/3072
[A[ATraining Step: 335  | total loss: [1m[32m0.69407[0m[0m | time: 44.046s
[2K
| Adam | epoch: 004 | loss: 0.69407 - acc: 0.4806 -- iter: 1504/3072
[A[ATraining Step: 336  | total loss: [1m[32m0.69440[0m[0m | time: 45.004s
[2K
| Adam | epoch: 004 | loss: 0.69440 - acc: 0.4794 -- iter: 1536/3072
[A[ATraining Step: 337  | total loss: [1m[32m0.69416[0m[0m | time: 46.024s
[2K
| Adam | epoch: 004 | loss: 0.69416 - acc: 0.4815 -- iter: 1568/3072
[A[ATraining Step: 338  | total loss: [1m[32m0.69353[0m[0m | time: 46.987s
[2K
| Adam | epoch: 004 | loss: 0.69353 - acc: 0.4927 -- iter: 1600/3072
[A[ATraining Step: 339  | total loss: [1m[32m0.69303[0m[0m | time: 47.741s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5059 -- iter: 1632/3072
[A[ATraining Step: 340  | total loss: [1m[32m0.69276[0m[0m | time: 48.561s
[2K
| Adam | epoch: 004 | loss: 0.69276 - acc: 0.5085 -- iter: 1664/3072
[A[ATraining Step: 341  | total loss: [1m[32m0.69267[0m[0m | time: 49.511s
[2K
| Adam | epoch: 004 | loss: 0.69267 - acc: 0.5170 -- iter: 1696/3072
[A[ATraining Step: 342  | total loss: [1m[32m0.69246[0m[0m | time: 50.368s
[2K
| Adam | epoch: 004 | loss: 0.69246 - acc: 0.5215 -- iter: 1728/3072
[A[ATraining Step: 343  | total loss: [1m[32m0.69229[0m[0m | time: 51.343s
[2K
| Adam | epoch: 004 | loss: 0.69229 - acc: 0.5194 -- iter: 1760/3072
[A[ATraining Step: 344  | total loss: [1m[32m0.69192[0m[0m | time: 52.308s
[2K
| Adam | epoch: 004 | loss: 0.69192 - acc: 0.5299 -- iter: 1792/3072
[A[ATraining Step: 345  | total loss: [1m[32m0.69257[0m[0m | time: 53.257s
[2K
| Adam | epoch: 004 | loss: 0.69257 - acc: 0.5207 -- iter: 1824/3072
[A[ATraining Step: 346  | total loss: [1m[32m0.69215[0m[0m | time: 54.153s
[2K
| Adam | epoch: 004 | loss: 0.69215 - acc: 0.5218 -- iter: 1856/3072
[A[ATraining Step: 347  | total loss: [1m[32m0.69096[0m[0m | time: 55.169s
[2K
| Adam | epoch: 004 | loss: 0.69096 - acc: 0.5415 -- iter: 1888/3072
[A[ATraining Step: 348  | total loss: [1m[32m0.69060[0m[0m | time: 56.280s
[2K
| Adam | epoch: 004 | loss: 0.69060 - acc: 0.5467 -- iter: 1920/3072
[A[ATraining Step: 349  | total loss: [1m[32m0.69010[0m[0m | time: 57.187s
[2K
| Adam | epoch: 004 | loss: 0.69010 - acc: 0.5576 -- iter: 1952/3072
[A[ATraining Step: 350  | total loss: [1m[32m0.69032[0m[0m | time: 57.981s
[2K
| Adam | epoch: 004 | loss: 0.69032 - acc: 0.5550 -- iter: 1984/3072
[A[ATraining Step: 351  | total loss: [1m[32m0.68981[0m[0m | time: 58.899s
[2K
| Adam | epoch: 004 | loss: 0.68981 - acc: 0.5526 -- iter: 2016/3072
[A[ATraining Step: 352  | total loss: [1m[32m0.69011[0m[0m | time: 59.781s
[2K
| Adam | epoch: 004 | loss: 0.69011 - acc: 0.5474 -- iter: 2048/3072
[A[ATraining Step: 353  | total loss: [1m[32m0.68971[0m[0m | time: 60.724s
[2K
| Adam | epoch: 004 | loss: 0.68971 - acc: 0.5520 -- iter: 2080/3072
[A[ATraining Step: 354  | total loss: [1m[32m0.68928[0m[0m | time: 61.715s
[2K
| Adam | epoch: 004 | loss: 0.68928 - acc: 0.5624 -- iter: 2112/3072
[A[ATraining Step: 355  | total loss: [1m[32m0.68810[0m[0m | time: 62.667s
[2K
| Adam | epoch: 004 | loss: 0.68810 - acc: 0.5843 -- iter: 2144/3072
[A[ATraining Step: 356  | total loss: [1m[32m0.68814[0m[0m | time: 63.603s
[2K
| Adam | epoch: 004 | loss: 0.68814 - acc: 0.5915 -- iter: 2176/3072
[A[ATraining Step: 357  | total loss: [1m[32m0.68740[0m[0m | time: 64.522s
[2K
| Adam | epoch: 004 | loss: 0.68740 - acc: 0.6011 -- iter: 2208/3072
[A[ATraining Step: 358  | total loss: [1m[32m0.68708[0m[0m | time: 65.590s
[2K
| Adam | epoch: 004 | loss: 0.68708 - acc: 0.6004 -- iter: 2240/3072
[A[ATraining Step: 359  | total loss: [1m[32m0.68514[0m[0m | time: 66.677s
[2K
| Adam | epoch: 004 | loss: 0.68514 - acc: 0.6122 -- iter: 2272/3072
[A[ATraining Step: 360  | total loss: [1m[32m0.68604[0m[0m | time: 67.412s
[2K
| Adam | epoch: 004 | loss: 0.68604 - acc: 0.6072 -- iter: 2304/3072
[A[ATraining Step: 361  | total loss: [1m[32m0.68545[0m[0m | time: 68.258s
[2K
| Adam | epoch: 004 | loss: 0.68545 - acc: 0.6090 -- iter: 2336/3072
[A[ATraining Step: 362  | total loss: [1m[32m0.68422[0m[0m | time: 69.185s
[2K
| Adam | epoch: 004 | loss: 0.68422 - acc: 0.6169 -- iter: 2368/3072
[A[ATraining Step: 363  | total loss: [1m[32m0.68370[0m[0m | time: 70.079s
[2K
| Adam | epoch: 004 | loss: 0.68370 - acc: 0.6114 -- iter: 2400/3072
[A[ATraining Step: 364  | total loss: [1m[32m0.68660[0m[0m | time: 71.003s
[2K
| Adam | epoch: 004 | loss: 0.68660 - acc: 0.5940 -- iter: 2432/3072
[A[ATraining Step: 365  | total loss: [1m[32m0.68539[0m[0m | time: 71.964s
[2K
| Adam | epoch: 004 | loss: 0.68539 - acc: 0.5940 -- iter: 2464/3072
[A[ATraining Step: 366  | total loss: [1m[32m0.68481[0m[0m | time: 72.897s
[2K
| Adam | epoch: 004 | loss: 0.68481 - acc: 0.5909 -- iter: 2496/3072
[A[ATraining Step: 367  | total loss: [1m[32m0.68601[0m[0m | time: 73.760s
[2K
| Adam | epoch: 004 | loss: 0.68601 - acc: 0.5755 -- iter: 2528/3072
[A[ATraining Step: 368  | total loss: [1m[32m0.68127[0m[0m | time: 74.738s
[2K
| Adam | epoch: 004 | loss: 0.68127 - acc: 0.5898 -- iter: 2560/3072
[A[ATraining Step: 369  | total loss: [1m[32m0.68475[0m[0m | time: 75.768s
[2K
| Adam | epoch: 004 | loss: 0.68475 - acc: 0.5684 -- iter: 2592/3072
[A[ATraining Step: 370  | total loss: [1m[32m0.68738[0m[0m | time: 76.708s
[2K
| Adam | epoch: 004 | loss: 0.68738 - acc: 0.5615 -- iter: 2624/3072
[A[ATraining Step: 371  | total loss: [1m[32m0.68441[0m[0m | time: 77.517s
[2K
| Adam | epoch: 004 | loss: 0.68441 - acc: 0.5616 -- iter: 2656/3072
[A[ATraining Step: 372  | total loss: [1m[32m0.68481[0m[0m | time: 78.406s
[2K
| Adam | epoch: 004 | loss: 0.68481 - acc: 0.5555 -- iter: 2688/3072
[A[ATraining Step: 373  | total loss: [1m[32m0.68402[0m[0m | time: 79.267s
[2K
| Adam | epoch: 004 | loss: 0.68402 - acc: 0.5593 -- iter: 2720/3072
[A[ATraining Step: 374  | total loss: [1m[32m0.68691[0m[0m | time: 80.135s
[2K
| Adam | epoch: 004 | loss: 0.68691 - acc: 0.5409 -- iter: 2752/3072
[A[ATraining Step: 375  | total loss: [1m[32m0.68442[0m[0m | time: 81.007s
[2K
| Adam | epoch: 004 | loss: 0.68442 - acc: 0.5524 -- iter: 2784/3072
[A[ATraining Step: 376  | total loss: [1m[32m0.68399[0m[0m | time: 81.984s
[2K
| Adam | epoch: 004 | loss: 0.68399 - acc: 0.5565 -- iter: 2816/3072
[A[ATraining Step: 377  | total loss: [1m[32m0.68506[0m[0m | time: 82.981s
[2K
| Adam | epoch: 004 | loss: 0.68506 - acc: 0.5478 -- iter: 2848/3072
[A[ATraining Step: 378  | total loss: [1m[32m0.68199[0m[0m | time: 83.803s
[2K
| Adam | epoch: 004 | loss: 0.68199 - acc: 0.5617 -- iter: 2880/3072
[A[ATraining Step: 379  | total loss: [1m[32m0.68231[0m[0m | time: 84.794s
[2K
| Adam | epoch: 004 | loss: 0.68231 - acc: 0.5524 -- iter: 2912/3072
[A[ATraining Step: 380  | total loss: [1m[32m0.68095[0m[0m | time: 85.791s
[2K
| Adam | epoch: 004 | loss: 0.68095 - acc: 0.5659 -- iter: 2944/3072
[A[ATraining Step: 381  | total loss: [1m[32m0.68109[0m[0m | time: 86.783s
[2K
| Adam | epoch: 004 | loss: 0.68109 - acc: 0.5750 -- iter: 2976/3072
[A[ATraining Step: 382  | total loss: [1m[32m0.68560[0m[0m | time: 87.514s
[2K
| Adam | epoch: 004 | loss: 0.68560 - acc: 0.5612 -- iter: 3008/3072
[A[ATraining Step: 383  | total loss: [1m[32m0.68426[0m[0m | time: 88.452s
[2K
| Adam | epoch: 004 | loss: 0.68426 - acc: 0.5707 -- iter: 3040/3072
[A[ATraining Step: 384  | total loss: [1m[32m0.68338[0m[0m | time: 94.135s
[2K
| Adam | epoch: 004 | loss: 0.68338 - acc: 0.5762 | val_loss: 0.66886 - val_acc: 0.6098 -- iter: 3072/3072
--
Training Step: 385  | total loss: [1m[32m0.68120[0m[0m | time: 0.987s
[2K
| Adam | epoch: 005 | loss: 0.68120 - acc: 0.5842 -- iter: 0032/3072
[A[ATraining Step: 386  | total loss: [1m[32m0.68075[0m[0m | time: 1.730s
[2K
| Adam | epoch: 005 | loss: 0.68075 - acc: 0.5789 -- iter: 0064/3072
[A[ATraining Step: 387  | total loss: [1m[32m0.68022[0m[0m | time: 2.628s
[2K
| Adam | epoch: 005 | loss: 0.68022 - acc: 0.5835 -- iter: 0096/3072
[A[ATraining Step: 388  | total loss: [1m[32m0.67867[0m[0m | time: 3.531s
[2K
| Adam | epoch: 005 | loss: 0.67867 - acc: 0.5845 -- iter: 0128/3072
[A[ATraining Step: 389  | total loss: [1m[32m0.67627[0m[0m | time: 4.440s
[2K
| Adam | epoch: 005 | loss: 0.67627 - acc: 0.5854 -- iter: 0160/3072
[A[ATraining Step: 390  | total loss: [1m[32m0.67141[0m[0m | time: 5.389s
[2K
| Adam | epoch: 005 | loss: 0.67141 - acc: 0.5925 -- iter: 0192/3072
[A[ATraining Step: 391  | total loss: [1m[32m0.67014[0m[0m | time: 6.346s
[2K
| Adam | epoch: 005 | loss: 0.67014 - acc: 0.5958 -- iter: 0224/3072
[A[ATraining Step: 392  | total loss: [1m[32m0.66459[0m[0m | time: 7.275s
[2K
| Adam | epoch: 005 | loss: 0.66459 - acc: 0.6049 -- iter: 0256/3072
[A[ATraining Step: 393  | total loss: [1m[32m0.66902[0m[0m | time: 8.083s
[2K
| Adam | epoch: 005 | loss: 0.66902 - acc: 0.5913 -- iter: 0288/3072
[A[ATraining Step: 394  | total loss: [1m[32m0.67114[0m[0m | time: 9.074s
[2K
| Adam | epoch: 005 | loss: 0.67114 - acc: 0.5884 -- iter: 0320/3072
[A[ATraining Step: 395  | total loss: [1m[32m0.68661[0m[0m | time: 10.172s
[2K
| Adam | epoch: 005 | loss: 0.68661 - acc: 0.5671 -- iter: 0352/3072
[A[ATraining Step: 396  | total loss: [1m[32m0.69055[0m[0m | time: 11.057s
[2K
| Adam | epoch: 005 | loss: 0.69055 - acc: 0.5573 -- iter: 0384/3072
[A[ATraining Step: 397  | total loss: [1m[32m0.68464[0m[0m | time: 11.860s
[2K
| Adam | epoch: 005 | loss: 0.68464 - acc: 0.5609 -- iter: 0416/3072
[A[ATraining Step: 398  | total loss: [1m[32m0.68152[0m[0m | time: 12.747s
[2K
| Adam | epoch: 005 | loss: 0.68152 - acc: 0.5642 -- iter: 0448/3072
[A[ATraining Step: 399  | total loss: [1m[32m0.67880[0m[0m | time: 13.630s
[2K
| Adam | epoch: 005 | loss: 0.67880 - acc: 0.5765 -- iter: 0480/3072
[A[ATraining Step: 400  | total loss: [1m[32m0.67482[0m[0m | time: 19.062s
[2K
| Adam | epoch: 005 | loss: 0.67482 - acc: 0.5845 | val_loss: 0.66230 - val_acc: 0.6191 -- iter: 0512/3072
--
Training Step: 401  | total loss: [1m[32m0.67367[0m[0m | time: 20.101s
[2K
| Adam | epoch: 005 | loss: 0.67367 - acc: 0.5854 -- iter: 0544/3072
[A[ATraining Step: 402  | total loss: [1m[32m0.67229[0m[0m | time: 21.166s
[2K
| Adam | epoch: 005 | loss: 0.67229 - acc: 0.5925 -- iter: 0576/3072
[A[ATraining Step: 403  | total loss: [1m[32m0.67263[0m[0m | time: 21.983s
[2K
| Adam | epoch: 005 | loss: 0.67263 - acc: 0.5958 -- iter: 0608/3072
[A[ATraining Step: 404  | total loss: [1m[32m0.67392[0m[0m | time: 22.853s
[2K
| Adam | epoch: 005 | loss: 0.67392 - acc: 0.5956 -- iter: 0640/3072
[A[ATraining Step: 405  | total loss: [1m[32m0.66839[0m[0m | time: 23.768s
[2K
| Adam | epoch: 005 | loss: 0.66839 - acc: 0.6141 -- iter: 0672/3072
[A[ATraining Step: 406  | total loss: [1m[32m0.66413[0m[0m | time: 24.644s
[2K
| Adam | epoch: 005 | loss: 0.66413 - acc: 0.6277 -- iter: 0704/3072
[A[ATraining Step: 407  | total loss: [1m[32m0.66690[0m[0m | time: 25.581s
[2K
| Adam | epoch: 005 | loss: 0.66690 - acc: 0.6149 -- iter: 0736/3072
[A[ATraining Step: 408  | total loss: [1m[32m0.66939[0m[0m | time: 26.530s
[2K
| Adam | epoch: 005 | loss: 0.66939 - acc: 0.6097 -- iter: 0768/3072
[A[ATraining Step: 409  | total loss: [1m[32m0.67225[0m[0m | time: 27.464s
[2K
| Adam | epoch: 005 | loss: 0.67225 - acc: 0.5987 -- iter: 0800/3072
[A[ATraining Step: 410  | total loss: [1m[32m0.67435[0m[0m | time: 28.358s
[2K
| Adam | epoch: 005 | loss: 0.67435 - acc: 0.5857 -- iter: 0832/3072
[A[ATraining Step: 411  | total loss: [1m[32m0.67223[0m[0m | time: 29.484s
[2K
| Adam | epoch: 005 | loss: 0.67223 - acc: 0.5928 -- iter: 0864/3072
[A[ATraining Step: 412  | total loss: [1m[32m0.67112[0m[0m | time: 30.581s
[2K
| Adam | epoch: 005 | loss: 0.67112 - acc: 0.5991 -- iter: 0896/3072
[A[ATraining Step: 413  | total loss: [1m[32m0.66930[0m[0m | time: 31.423s
[2K
| Adam | epoch: 005 | loss: 0.66930 - acc: 0.6111 -- iter: 0928/3072
[A[ATraining Step: 414  | total loss: [1m[32m0.66895[0m[0m | time: 32.344s
[2K
| Adam | epoch: 005 | loss: 0.66895 - acc: 0.6094 -- iter: 0960/3072
[A[ATraining Step: 415  | total loss: [1m[32m0.66441[0m[0m | time: 33.332s
[2K
| Adam | epoch: 005 | loss: 0.66441 - acc: 0.6234 -- iter: 0992/3072
[A[ATraining Step: 416  | total loss: [1m[32m0.66344[0m[0m | time: 34.220s
[2K
| Adam | epoch: 005 | loss: 0.66344 - acc: 0.6236 -- iter: 1024/3072
[A[ATraining Step: 417  | total loss: [1m[32m0.66379[0m[0m | time: 35.137s
[2K
| Adam | epoch: 005 | loss: 0.66379 - acc: 0.6268 -- iter: 1056/3072
[A[ATraining Step: 418  | total loss: [1m[32m0.66080[0m[0m | time: 36.123s
[2K
| Adam | epoch: 005 | loss: 0.66080 - acc: 0.6392 -- iter: 1088/3072
[A[ATraining Step: 419  | total loss: [1m[32m0.66028[0m[0m | time: 37.077s
[2K
| Adam | epoch: 005 | loss: 0.66028 - acc: 0.6377 -- iter: 1120/3072
[A[ATraining Step: 420  | total loss: [1m[32m0.66223[0m[0m | time: 37.863s
[2K
| Adam | epoch: 005 | loss: 0.66223 - acc: 0.6271 -- iter: 1152/3072
[A[ATraining Step: 421  | total loss: [1m[32m0.66776[0m[0m | time: 38.942s
[2K
| Adam | epoch: 005 | loss: 0.66776 - acc: 0.6113 -- iter: 1184/3072
[A[ATraining Step: 422  | total loss: [1m[32m0.66877[0m[0m | time: 39.962s
[2K
| Adam | epoch: 005 | loss: 0.66877 - acc: 0.6033 -- iter: 1216/3072
[A[ATraining Step: 423  | total loss: [1m[32m0.67307[0m[0m | time: 40.795s
[2K
| Adam | epoch: 005 | loss: 0.67307 - acc: 0.5929 -- iter: 1248/3072
[A[ATraining Step: 424  | total loss: [1m[32m0.67360[0m[0m | time: 41.619s
[2K
| Adam | epoch: 005 | loss: 0.67360 - acc: 0.5868 -- iter: 1280/3072
[A[ATraining Step: 425  | total loss: [1m[32m0.66435[0m[0m | time: 42.551s
[2K
| Adam | epoch: 005 | loss: 0.66435 - acc: 0.6062 -- iter: 1312/3072
[A[ATraining Step: 426  | total loss: [1m[32m0.66513[0m[0m | time: 43.413s
[2K
| Adam | epoch: 005 | loss: 0.66513 - acc: 0.6081 -- iter: 1344/3072
[A[ATraining Step: 427  | total loss: [1m[32m0.66431[0m[0m | time: 44.338s
[2K
| Adam | epoch: 005 | loss: 0.66431 - acc: 0.6035 -- iter: 1376/3072
[A[ATraining Step: 428  | total loss: [1m[32m0.66162[0m[0m | time: 45.309s
[2K
| Adam | epoch: 005 | loss: 0.66162 - acc: 0.6088 -- iter: 1408/3072
[A[ATraining Step: 429  | total loss: [1m[32m0.66029[0m[0m | time: 46.254s
[2K
| Adam | epoch: 005 | loss: 0.66029 - acc: 0.6167 -- iter: 1440/3072
[A[ATraining Step: 430  | total loss: [1m[32m0.66317[0m[0m | time: 47.126s
[2K
| Adam | epoch: 005 | loss: 0.66317 - acc: 0.6175 -- iter: 1472/3072
[A[ATraining Step: 431  | total loss: [1m[32m0.66422[0m[0m | time: 48.029s
[2K
| Adam | epoch: 005 | loss: 0.66422 - acc: 0.6245 -- iter: 1504/3072
[A[ATraining Step: 432  | total loss: [1m[32m0.66481[0m[0m | time: 49.083s
[2K
| Adam | epoch: 005 | loss: 0.66481 - acc: 0.6214 -- iter: 1536/3072
[A[ATraining Step: 433  | total loss: [1m[32m0.66025[0m[0m | time: 50.178s
[2K
| Adam | epoch: 005 | loss: 0.66025 - acc: 0.6249 -- iter: 1568/3072
[A[ATraining Step: 434  | total loss: [1m[32m0.65639[0m[0m | time: 50.889s
[2K
| Adam | epoch: 005 | loss: 0.65639 - acc: 0.6280 -- iter: 1600/3072
[A[ATraining Step: 435  | total loss: [1m[32m0.65905[0m[0m | time: 51.857s
[2K
| Adam | epoch: 005 | loss: 0.65905 - acc: 0.6215 -- iter: 1632/3072
[A[ATraining Step: 436  | total loss: [1m[32m0.66481[0m[0m | time: 52.712s
[2K
| Adam | epoch: 005 | loss: 0.66481 - acc: 0.6031 -- iter: 1664/3072
[A[ATraining Step: 437  | total loss: [1m[32m0.65699[0m[0m | time: 53.560s
[2K
| Adam | epoch: 005 | loss: 0.65699 - acc: 0.6178 -- iter: 1696/3072
[A[ATraining Step: 438  | total loss: [1m[32m0.65761[0m[0m | time: 54.484s
[2K
| Adam | epoch: 005 | loss: 0.65761 - acc: 0.6154 -- iter: 1728/3072
[A[ATraining Step: 439  | total loss: [1m[32m0.65228[0m[0m | time: 55.420s
[2K
| Adam | epoch: 005 | loss: 0.65228 - acc: 0.6195 -- iter: 1760/3072
[A[ATraining Step: 440  | total loss: [1m[32m0.66307[0m[0m | time: 56.356s
[2K
| Adam | epoch: 005 | loss: 0.66307 - acc: 0.5981 -- iter: 1792/3072
[A[ATraining Step: 441  | total loss: [1m[32m0.65890[0m[0m | time: 57.234s
[2K
| Adam | epoch: 005 | loss: 0.65890 - acc: 0.6102 -- iter: 1824/3072
[A[ATraining Step: 442  | total loss: [1m[32m0.65492[0m[0m | time: 58.264s
[2K
| Adam | epoch: 005 | loss: 0.65492 - acc: 0.6336 -- iter: 1856/3072
[A[ATraining Step: 443  | total loss: [1m[32m0.66237[0m[0m | time: 59.323s
[2K
| Adam | epoch: 005 | loss: 0.66237 - acc: 0.6171 -- iter: 1888/3072
[A[ATraining Step: 444  | total loss: [1m[32m0.65811[0m[0m | time: 60.309s
[2K
| Adam | epoch: 005 | loss: 0.65811 - acc: 0.6241 -- iter: 1920/3072
[A[ATraining Step: 445  | total loss: [1m[32m0.65833[0m[0m | time: 61.094s
[2K
| Adam | epoch: 005 | loss: 0.65833 - acc: 0.6180 -- iter: 1952/3072
[A[ATraining Step: 446  | total loss: [1m[32m0.66292[0m[0m | time: 62.064s
[2K
| Adam | epoch: 005 | loss: 0.66292 - acc: 0.5968 -- iter: 1984/3072
[A[ATraining Step: 447  | total loss: [1m[32m0.66640[0m[0m | time: 62.972s
[2K
| Adam | epoch: 005 | loss: 0.66640 - acc: 0.5840 -- iter: 2016/3072
[A[ATraining Step: 448  | total loss: [1m[32m0.66702[0m[0m | time: 63.935s
[2K
| Adam | epoch: 005 | loss: 0.66702 - acc: 0.5881 -- iter: 2048/3072
[A[ATraining Step: 449  | total loss: [1m[32m0.66136[0m[0m | time: 64.859s
[2K
| Adam | epoch: 005 | loss: 0.66136 - acc: 0.5980 -- iter: 2080/3072
[A[ATraining Step: 450  | total loss: [1m[32m0.65977[0m[0m | time: 65.811s
[2K
| Adam | epoch: 005 | loss: 0.65977 - acc: 0.5976 -- iter: 2112/3072
[A[ATraining Step: 451  | total loss: [1m[32m0.65453[0m[0m | time: 66.743s
[2K
| Adam | epoch: 005 | loss: 0.65453 - acc: 0.6160 -- iter: 2144/3072
[A[ATraining Step: 452  | total loss: [1m[32m0.64912[0m[0m | time: 67.660s
[2K
| Adam | epoch: 005 | loss: 0.64912 - acc: 0.6294 -- iter: 2176/3072
[A[ATraining Step: 453  | total loss: [1m[32m0.65590[0m[0m | time: 68.762s
[2K
| Adam | epoch: 005 | loss: 0.65590 - acc: 0.6196 -- iter: 2208/3072
[A[ATraining Step: 454  | total loss: [1m[32m0.65007[0m[0m | time: 69.823s
[2K
| Adam | epoch: 005 | loss: 0.65007 - acc: 0.6326 -- iter: 2240/3072
[A[ATraining Step: 455  | total loss: [1m[32m0.65361[0m[0m | time: 70.833s
[2K
| Adam | epoch: 005 | loss: 0.65361 - acc: 0.6225 -- iter: 2272/3072
[A[ATraining Step: 456  | total loss: [1m[32m0.64983[0m[0m | time: 71.817s
[2K
| Adam | epoch: 005 | loss: 0.64983 - acc: 0.6290 -- iter: 2304/3072
[A[ATraining Step: 457  | total loss: [1m[32m0.64607[0m[0m | time: 72.954s
[2K
| Adam | epoch: 005 | loss: 0.64607 - acc: 0.6254 -- iter: 2336/3072
[A[ATraining Step: 458  | total loss: [1m[32m0.63911[0m[0m | time: 73.996s
[2K
| Adam | epoch: 005 | loss: 0.63911 - acc: 0.6348 -- iter: 2368/3072
[A[ATraining Step: 459  | total loss: [1m[32m0.63574[0m[0m | time: 74.987s
[2K
| Adam | epoch: 005 | loss: 0.63574 - acc: 0.6338 -- iter: 2400/3072
[A[ATraining Step: 460  | total loss: [1m[32m0.64136[0m[0m | time: 75.919s
[2K
| Adam | epoch: 005 | loss: 0.64136 - acc: 0.6329 -- iter: 2432/3072
[A[ATraining Step: 461  | total loss: [1m[32m0.63467[0m[0m | time: 76.995s
[2K
| Adam | epoch: 005 | loss: 0.63467 - acc: 0.6384 -- iter: 2464/3072
[A[ATraining Step: 462  | total loss: [1m[32m0.63471[0m[0m | time: 77.931s
[2K
| Adam | epoch: 005 | loss: 0.63471 - acc: 0.6277 -- iter: 2496/3072
[A[ATraining Step: 463  | total loss: [1m[32m0.63683[0m[0m | time: 79.014s
[2K
| Adam | epoch: 005 | loss: 0.63683 - acc: 0.6086 -- iter: 2528/3072
[A[ATraining Step: 464  | total loss: [1m[32m0.63966[0m[0m | time: 80.005s
[2K
| Adam | epoch: 005 | loss: 0.63966 - acc: 0.6009 -- iter: 2560/3072
[A[ATraining Step: 465  | total loss: [1m[32m0.63106[0m[0m | time: 80.916s
[2K
| Adam | epoch: 005 | loss: 0.63106 - acc: 0.6189 -- iter: 2592/3072
[A[ATraining Step: 466  | total loss: [1m[32m0.63284[0m[0m | time: 81.536s
[2K
| Adam | epoch: 005 | loss: 0.63284 - acc: 0.6133 -- iter: 2624/3072
[A[ATraining Step: 467  | total loss: [1m[32m0.63737[0m[0m | time: 82.146s
[2K
| Adam | epoch: 005 | loss: 0.63737 - acc: 0.6082 -- iter: 2656/3072
[A[ATraining Step: 468  | total loss: [1m[32m0.64102[0m[0m | time: 82.755s
[2K
| Adam | epoch: 005 | loss: 0.64102 - acc: 0.6068 -- iter: 2688/3072
[A[ATraining Step: 469  | total loss: [1m[32m0.63693[0m[0m | time: 83.392s
[2K
| Adam | epoch: 005 | loss: 0.63693 - acc: 0.6180 -- iter: 2720/3072
[A[ATraining Step: 470  | total loss: [1m[32m0.64363[0m[0m | time: 84.063s
[2K
| Adam | epoch: 005 | loss: 0.64363 - acc: 0.6155 -- iter: 2752/3072
[A[ATraining Step: 471  | total loss: [1m[32m0.64303[0m[0m | time: 84.674s
[2K
| Adam | epoch: 005 | loss: 0.64303 - acc: 0.6227 -- iter: 2784/3072
[A[ATraining Step: 472  | total loss: [1m[32m0.64596[0m[0m | time: 85.284s
[2K
| Adam | epoch: 005 | loss: 0.64596 - acc: 0.6198 -- iter: 2816/3072
[A[ATraining Step: 473  | total loss: [1m[32m0.64424[0m[0m | time: 85.902s
[2K
| Adam | epoch: 005 | loss: 0.64424 - acc: 0.6266 -- iter: 2848/3072
[A[ATraining Step: 474  | total loss: [1m[32m0.63889[0m[0m | time: 86.505s
[2K
| Adam | epoch: 005 | loss: 0.63889 - acc: 0.6327 -- iter: 2880/3072
[A[ATraining Step: 475  | total loss: [1m[32m0.63348[0m[0m | time: 87.128s
[2K
| Adam | epoch: 005 | loss: 0.63348 - acc: 0.6382 -- iter: 2912/3072
[A[ATraining Step: 476  | total loss: [1m[32m0.63246[0m[0m | time: 87.738s
[2K
| Adam | epoch: 005 | loss: 0.63246 - acc: 0.6369 -- iter: 2944/3072
[A[ATraining Step: 477  | total loss: [1m[32m0.63074[0m[0m | time: 88.361s
[2K
| Adam | epoch: 005 | loss: 0.63074 - acc: 0.6419 -- iter: 2976/3072
[A[ATraining Step: 478  | total loss: [1m[32m0.62783[0m[0m | time: 89.009s
[2K
| Adam | epoch: 005 | loss: 0.62783 - acc: 0.6371 -- iter: 3008/3072
[A[ATraining Step: 479  | total loss: [1m[32m0.62793[0m[0m | time: 89.612s
[2K
| Adam | epoch: 005 | loss: 0.62793 - acc: 0.6421 -- iter: 3040/3072
[A[ATraining Step: 480  | total loss: [1m[32m0.62477[0m[0m | time: 93.312s
[2K
| Adam | epoch: 005 | loss: 0.62477 - acc: 0.6467 | val_loss: 0.61489 - val_acc: 0.6608 -- iter: 3072/3072
--
Training Step: 481  | total loss: [1m[32m0.63327[0m[0m | time: 0.614s
[2K
| Adam | epoch: 006 | loss: 0.63327 - acc: 0.6351 -- iter: 0032/3072
[A[ATraining Step: 482  | total loss: [1m[32m0.62585[0m[0m | time: 1.239s
[2K
| Adam | epoch: 006 | loss: 0.62585 - acc: 0.6435 -- iter: 0064/3072
[A[ATraining Step: 483  | total loss: [1m[32m0.62856[0m[0m | time: 1.892s
[2K
| Adam | epoch: 006 | loss: 0.62856 - acc: 0.6510 -- iter: 0096/3072
[A[ATraining Step: 484  | total loss: [1m[32m0.63597[0m[0m | time: 2.520s
[2K
| Adam | epoch: 006 | loss: 0.63597 - acc: 0.6390 -- iter: 0128/3072
[A[ATraining Step: 485  | total loss: [1m[32m0.63022[0m[0m | time: 3.149s
[2K
| Adam | epoch: 006 | loss: 0.63022 - acc: 0.6439 -- iter: 0160/3072
[A[ATraining Step: 486  | total loss: [1m[32m0.62430[0m[0m | time: 4.012s
[2K
| Adam | epoch: 006 | loss: 0.62430 - acc: 0.6514 -- iter: 0192/3072
[A[ATraining Step: 487  | total loss: [1m[32m0.62912[0m[0m | time: 5.108s
[2K
| Adam | epoch: 006 | loss: 0.62912 - acc: 0.6487 -- iter: 0224/3072
[A[ATraining Step: 488  | total loss: [1m[32m0.63080[0m[0m | time: 5.955s
[2K
| Adam | epoch: 006 | loss: 0.63080 - acc: 0.6464 -- iter: 0256/3072
[A[ATraining Step: 489  | total loss: [1m[32m0.62299[0m[0m | time: 6.806s
[2K
| Adam | epoch: 006 | loss: 0.62299 - acc: 0.6505 -- iter: 0288/3072
[A[ATraining Step: 490  | total loss: [1m[32m0.61662[0m[0m | time: 7.737s
[2K
| Adam | epoch: 006 | loss: 0.61662 - acc: 0.6604 -- iter: 0320/3072
[A[ATraining Step: 491  | total loss: [1m[32m0.61750[0m[0m | time: 8.593s
[2K
| Adam | epoch: 006 | loss: 0.61750 - acc: 0.6569 -- iter: 0352/3072
[A[ATraining Step: 492  | total loss: [1m[32m0.61237[0m[0m | time: 9.501s
[2K
| Adam | epoch: 006 | loss: 0.61237 - acc: 0.6631 -- iter: 0384/3072
[A[ATraining Step: 493  | total loss: [1m[32m0.60915[0m[0m | time: 10.595s
[2K
| Adam | epoch: 006 | loss: 0.60915 - acc: 0.6718 -- iter: 0416/3072
[A[ATraining Step: 494  | total loss: [1m[32m0.61223[0m[0m | time: 11.443s
[2K
| Adam | epoch: 006 | loss: 0.61223 - acc: 0.6702 -- iter: 0448/3072
[A[ATraining Step: 495  | total loss: [1m[32m0.60970[0m[0m | time: 12.412s
[2K
| Adam | epoch: 006 | loss: 0.60970 - acc: 0.6719 -- iter: 0480/3072
[A[ATraining Step: 496  | total loss: [1m[32m0.61351[0m[0m | time: 13.466s
[2K
| Adam | epoch: 006 | loss: 0.61351 - acc: 0.6672 -- iter: 0512/3072
[A[ATraining Step: 497  | total loss: [1m[32m0.61649[0m[0m | time: 14.341s
[2K
| Adam | epoch: 006 | loss: 0.61649 - acc: 0.6630 -- iter: 0544/3072
[A[ATraining Step: 498  | total loss: [1m[32m0.62904[0m[0m | time: 15.189s
[2K
| Adam | epoch: 006 | loss: 0.62904 - acc: 0.6498 -- iter: 0576/3072
[A[ATraining Step: 499  | total loss: [1m[32m0.62842[0m[0m | time: 16.035s
[2K
| Adam | epoch: 006 | loss: 0.62842 - acc: 0.6567 -- iter: 0608/3072
[A[ATraining Step: 500  | total loss: [1m[32m0.63433[0m[0m | time: 16.901s
[2K
| Adam | epoch: 006 | loss: 0.63433 - acc: 0.6567 -- iter: 0640/3072
[A[ATraining Step: 501  | total loss: [1m[32m0.63755[0m[0m | time: 17.830s
[2K
| Adam | epoch: 006 | loss: 0.63755 - acc: 0.6441 -- iter: 0672/3072
[A[ATraining Step: 502  | total loss: [1m[32m0.63464[0m[0m | time: 18.754s
[2K
| Adam | epoch: 006 | loss: 0.63464 - acc: 0.6422 -- iter: 0704/3072
[A[ATraining Step: 503  | total loss: [1m[32m0.62219[0m[0m | time: 19.689s
[2K
| Adam | epoch: 006 | loss: 0.62219 - acc: 0.6499 -- iter: 0736/3072
[A[ATraining Step: 504  | total loss: [1m[32m0.63043[0m[0m | time: 20.683s
[2K
| Adam | epoch: 006 | loss: 0.63043 - acc: 0.6286 -- iter: 0768/3072
[A[ATraining Step: 505  | total loss: [1m[32m0.63378[0m[0m | time: 21.680s
[2K
| Adam | epoch: 006 | loss: 0.63378 - acc: 0.6283 -- iter: 0800/3072
[A[ATraining Step: 506  | total loss: [1m[32m0.62805[0m[0m | time: 22.659s
[2K
| Adam | epoch: 006 | loss: 0.62805 - acc: 0.6280 -- iter: 0832/3072
[A[ATraining Step: 507  | total loss: [1m[32m0.62775[0m[0m | time: 23.424s
[2K
| Adam | epoch: 006 | loss: 0.62775 - acc: 0.6308 -- iter: 0864/3072
[A[ATraining Step: 508  | total loss: [1m[32m0.62543[0m[0m | time: 24.326s
[2K
| Adam | epoch: 006 | loss: 0.62543 - acc: 0.6396 -- iter: 0896/3072
[A[ATraining Step: 509  | total loss: [1m[32m0.62362[0m[0m | time: 25.182s
[2K
| Adam | epoch: 006 | loss: 0.62362 - acc: 0.6444 -- iter: 0928/3072
[A[ATraining Step: 510  | total loss: [1m[32m0.62927[0m[0m | time: 26.200s
[2K
| Adam | epoch: 006 | loss: 0.62927 - acc: 0.6424 -- iter: 0960/3072
[A[ATraining Step: 511  | total loss: [1m[32m0.63251[0m[0m | time: 27.086s
[2K
| Adam | epoch: 006 | loss: 0.63251 - acc: 0.6438 -- iter: 0992/3072
[A[ATraining Step: 512  | total loss: [1m[32m0.62843[0m[0m | time: 28.123s
[2K
| Adam | epoch: 006 | loss: 0.62843 - acc: 0.6451 -- iter: 1024/3072
[A[ATraining Step: 513  | total loss: [1m[32m0.62682[0m[0m | time: 29.121s
[2K
| Adam | epoch: 006 | loss: 0.62682 - acc: 0.6462 -- iter: 1056/3072
[A[ATraining Step: 514  | total loss: [1m[32m0.62712[0m[0m | time: 29.985s
[2K
| Adam | epoch: 006 | loss: 0.62712 - acc: 0.6503 -- iter: 1088/3072
[A[ATraining Step: 515  | total loss: [1m[32m0.61842[0m[0m | time: 31.019s
[2K
| Adam | epoch: 006 | loss: 0.61842 - acc: 0.6603 -- iter: 1120/3072
[A[ATraining Step: 516  | total loss: [1m[32m0.61215[0m[0m | time: 32.092s
[2K
| Adam | epoch: 006 | loss: 0.61215 - acc: 0.6661 -- iter: 1152/3072
[A[ATraining Step: 517  | total loss: [1m[32m0.61075[0m[0m | time: 32.902s
[2K
| Adam | epoch: 006 | loss: 0.61075 - acc: 0.6651 -- iter: 1184/3072
[A[ATraining Step: 518  | total loss: [1m[32m0.60829[0m[0m | time: 33.758s
[2K
| Adam | epoch: 006 | loss: 0.60829 - acc: 0.6767 -- iter: 1216/3072
[A[ATraining Step: 519  | total loss: [1m[32m0.61163[0m[0m | time: 34.681s
[2K
| Adam | epoch: 006 | loss: 0.61163 - acc: 0.6809 -- iter: 1248/3072
[A[ATraining Step: 520  | total loss: [1m[32m0.61200[0m[0m | time: 35.643s
[2K
| Adam | epoch: 006 | loss: 0.61200 - acc: 0.6785 -- iter: 1280/3072
[A[ATraining Step: 521  | total loss: [1m[32m0.60760[0m[0m | time: 36.588s
[2K
| Adam | epoch: 006 | loss: 0.60760 - acc: 0.6825 -- iter: 1312/3072
[A[ATraining Step: 522  | total loss: [1m[32m0.60733[0m[0m | time: 37.521s
[2K
| Adam | epoch: 006 | loss: 0.60733 - acc: 0.6830 -- iter: 1344/3072
[A[ATraining Step: 523  | total loss: [1m[32m0.60043[0m[0m | time: 38.470s
[2K
| Adam | epoch: 006 | loss: 0.60043 - acc: 0.6866 -- iter: 1376/3072
[A[ATraining Step: 524  | total loss: [1m[32m0.59436[0m[0m | time: 39.363s
[2K
| Adam | epoch: 006 | loss: 0.59436 - acc: 0.6960 -- iter: 1408/3072
[A[ATraining Step: 525  | total loss: [1m[32m0.59288[0m[0m | time: 40.301s
[2K
| Adam | epoch: 006 | loss: 0.59288 - acc: 0.6952 -- iter: 1440/3072
[A[ATraining Step: 526  | total loss: [1m[32m0.60003[0m[0m | time: 41.365s
[2K
| Adam | epoch: 006 | loss: 0.60003 - acc: 0.6882 -- iter: 1472/3072
[A[ATraining Step: 527  | total loss: [1m[32m0.59773[0m[0m | time: 42.355s
[2K
| Adam | epoch: 006 | loss: 0.59773 - acc: 0.6975 -- iter: 1504/3072
[A[ATraining Step: 528  | total loss: [1m[32m0.60712[0m[0m | time: 43.117s
[2K
| Adam | epoch: 006 | loss: 0.60712 - acc: 0.6809 -- iter: 1536/3072
[A[ATraining Step: 529  | total loss: [1m[32m0.60876[0m[0m | time: 44.021s
[2K
| Adam | epoch: 006 | loss: 0.60876 - acc: 0.6753 -- iter: 1568/3072
[A[ATraining Step: 530  | total loss: [1m[32m0.61117[0m[0m | time: 44.875s
[2K
| Adam | epoch: 006 | loss: 0.61117 - acc: 0.6702 -- iter: 1600/3072
[A[ATraining Step: 531  | total loss: [1m[32m0.61589[0m[0m | time: 45.803s
[2K
| Adam | epoch: 006 | loss: 0.61589 - acc: 0.6626 -- iter: 1632/3072
[A[ATraining Step: 532  | total loss: [1m[32m0.60712[0m[0m | time: 46.703s
[2K
| Adam | epoch: 006 | loss: 0.60712 - acc: 0.6776 -- iter: 1664/3072
[A[ATraining Step: 533  | total loss: [1m[32m0.60656[0m[0m | time: 47.760s
[2K
| Adam | epoch: 006 | loss: 0.60656 - acc: 0.6786 -- iter: 1696/3072
[A[ATraining Step: 534  | total loss: [1m[32m0.60799[0m[0m | time: 48.742s
[2K
| Adam | epoch: 006 | loss: 0.60799 - acc: 0.6857 -- iter: 1728/3072
[A[ATraining Step: 535  | total loss: [1m[32m0.61008[0m[0m | time: 49.589s
[2K
| Adam | epoch: 006 | loss: 0.61008 - acc: 0.6828 -- iter: 1760/3072
[A[ATraining Step: 536  | total loss: [1m[32m0.63010[0m[0m | time: 50.620s
[2K
| Adam | epoch: 006 | loss: 0.63010 - acc: 0.6645 -- iter: 1792/3072
[A[ATraining Step: 537  | total loss: [1m[32m0.62882[0m[0m | time: 51.633s
[2K
| Adam | epoch: 006 | loss: 0.62882 - acc: 0.6574 -- iter: 1824/3072
[A[ATraining Step: 538  | total loss: [1m[32m0.61232[0m[0m | time: 52.590s
[2K
| Adam | epoch: 006 | loss: 0.61232 - acc: 0.6667 -- iter: 1856/3072
[A[ATraining Step: 539  | total loss: [1m[32m0.61859[0m[0m | time: 53.331s
[2K
| Adam | epoch: 006 | loss: 0.61859 - acc: 0.6531 -- iter: 1888/3072
[A[ATraining Step: 540  | total loss: [1m[32m0.62139[0m[0m | time: 54.240s
[2K
| Adam | epoch: 006 | loss: 0.62139 - acc: 0.6441 -- iter: 1920/3072
[A[ATraining Step: 541  | total loss: [1m[32m0.60840[0m[0m | time: 55.109s
[2K
| Adam | epoch: 006 | loss: 0.60840 - acc: 0.6515 -- iter: 1952/3072
[A[ATraining Step: 542  | total loss: [1m[32m0.59921[0m[0m | time: 56.009s
[2K
| Adam | epoch: 006 | loss: 0.59921 - acc: 0.6645 -- iter: 1984/3072
[A[ATraining Step: 543  | total loss: [1m[32m0.61197[0m[0m | time: 56.888s
[2K
| Adam | epoch: 006 | loss: 0.61197 - acc: 0.6543 -- iter: 2016/3072
[A[ATraining Step: 544  | total loss: [1m[32m0.60576[0m[0m | time: 57.879s
[2K
| Adam | epoch: 006 | loss: 0.60576 - acc: 0.6545 -- iter: 2048/3072
[A[ATraining Step: 545  | total loss: [1m[32m0.62120[0m[0m | time: 58.830s
[2K
| Adam | epoch: 006 | loss: 0.62120 - acc: 0.6391 -- iter: 2080/3072
[A[ATraining Step: 546  | total loss: [1m[32m0.62362[0m[0m | time: 59.638s
[2K
| Adam | epoch: 006 | loss: 0.62362 - acc: 0.6439 -- iter: 2112/3072
[A[ATraining Step: 547  | total loss: [1m[32m0.62770[0m[0m | time: 60.776s
[2K
| Adam | epoch: 006 | loss: 0.62770 - acc: 0.6389 -- iter: 2144/3072
[A[ATraining Step: 548  | total loss: [1m[32m0.63216[0m[0m | time: 61.841s
[2K
| Adam | epoch: 006 | loss: 0.63216 - acc: 0.6250 -- iter: 2176/3072
[A[ATraining Step: 549  | total loss: [1m[32m0.63302[0m[0m | time: 62.663s
[2K
| Adam | epoch: 006 | loss: 0.63302 - acc: 0.6250 -- iter: 2208/3072
[A[ATraining Step: 550  | total loss: [1m[32m0.64810[0m[0m | time: 63.495s
[2K
| Adam | epoch: 006 | loss: 0.64810 - acc: 0.6094 -- iter: 2240/3072
[A[ATraining Step: 551  | total loss: [1m[32m0.63248[0m[0m | time: 64.387s
[2K
| Adam | epoch: 006 | loss: 0.63248 - acc: 0.6359 -- iter: 2272/3072
[A[ATraining Step: 552  | total loss: [1m[32m0.63421[0m[0m | time: 65.278s
[2K
| Adam | epoch: 006 | loss: 0.63421 - acc: 0.6286 -- iter: 2304/3072
[A[ATraining Step: 553  | total loss: [1m[32m0.63941[0m[0m | time: 66.108s
[2K
| Adam | epoch: 006 | loss: 0.63941 - acc: 0.6189 -- iter: 2336/3072
[A[ATraining Step: 554  | total loss: [1m[32m0.63287[0m[0m | time: 67.040s
[2K
| Adam | epoch: 006 | loss: 0.63287 - acc: 0.6320 -- iter: 2368/3072
[A[ATraining Step: 555  | total loss: [1m[32m0.62508[0m[0m | time: 68.112s
[2K
| Adam | epoch: 006 | loss: 0.62508 - acc: 0.6406 -- iter: 2400/3072
[A[ATraining Step: 556  | total loss: [1m[32m0.62194[0m[0m | time: 69.055s
[2K
| Adam | epoch: 006 | loss: 0.62194 - acc: 0.6516 -- iter: 2432/3072
[A[ATraining Step: 557  | total loss: [1m[32m0.61510[0m[0m | time: 69.929s
[2K
| Adam | epoch: 006 | loss: 0.61510 - acc: 0.6646 -- iter: 2464/3072
[A[ATraining Step: 558  | total loss: [1m[32m0.61256[0m[0m | time: 71.156s
[2K
| Adam | epoch: 006 | loss: 0.61256 - acc: 0.6637 -- iter: 2496/3072
[A[ATraining Step: 559  | total loss: [1m[32m0.62210[0m[0m | time: 72.212s
[2K
| Adam | epoch: 006 | loss: 0.62210 - acc: 0.6567 -- iter: 2528/3072
[A[ATraining Step: 560  | total loss: [1m[32m0.61734[0m[0m | time: 72.969s
[2K
| Adam | epoch: 006 | loss: 0.61734 - acc: 0.6567 -- iter: 2560/3072
[A[ATraining Step: 561  | total loss: [1m[32m0.61530[0m[0m | time: 73.819s
[2K
| Adam | epoch: 006 | loss: 0.61530 - acc: 0.6598 -- iter: 2592/3072
[A[ATraining Step: 562  | total loss: [1m[32m0.61397[0m[0m | time: 74.697s
[2K
| Adam | epoch: 006 | loss: 0.61397 - acc: 0.6594 -- iter: 2624/3072
[A[ATraining Step: 563  | total loss: [1m[32m0.60122[0m[0m | time: 75.581s
[2K
| Adam | epoch: 006 | loss: 0.60122 - acc: 0.6716 -- iter: 2656/3072
[A[ATraining Step: 564  | total loss: [1m[32m0.60072[0m[0m | time: 76.442s
[2K
| Adam | epoch: 006 | loss: 0.60072 - acc: 0.6701 -- iter: 2688/3072
[A[ATraining Step: 565  | total loss: [1m[32m0.59464[0m[0m | time: 77.404s
[2K
| Adam | epoch: 006 | loss: 0.59464 - acc: 0.6687 -- iter: 2720/3072
[A[ATraining Step: 566  | total loss: [1m[32m0.59467[0m[0m | time: 78.418s
[2K
| Adam | epoch: 006 | loss: 0.59467 - acc: 0.6706 -- iter: 2752/3072
[A[ATraining Step: 567  | total loss: [1m[32m0.59380[0m[0m | time: 79.335s
[2K
| Adam | epoch: 006 | loss: 0.59380 - acc: 0.6691 -- iter: 2784/3072
[A[ATraining Step: 568  | total loss: [1m[32m0.59231[0m[0m | time: 80.368s
[2K
| Adam | epoch: 006 | loss: 0.59231 - acc: 0.6741 -- iter: 2816/3072
[A[ATraining Step: 569  | total loss: [1m[32m0.59695[0m[0m | time: 81.438s
[2K
| Adam | epoch: 006 | loss: 0.59695 - acc: 0.6661 -- iter: 2848/3072
[A[ATraining Step: 570  | total loss: [1m[32m0.59952[0m[0m | time: 82.404s
[2K
| Adam | epoch: 006 | loss: 0.59952 - acc: 0.6682 -- iter: 2880/3072
[A[ATraining Step: 571  | total loss: [1m[32m0.59657[0m[0m | time: 83.333s
[2K
| Adam | epoch: 006 | loss: 0.59657 - acc: 0.6733 -- iter: 2912/3072
[A[ATraining Step: 572  | total loss: [1m[32m0.61027[0m[0m | time: 84.263s
[2K
| Adam | epoch: 006 | loss: 0.61027 - acc: 0.6559 -- iter: 2944/3072
[A[ATraining Step: 573  | total loss: [1m[32m0.61251[0m[0m | time: 85.191s
[2K
| Adam | epoch: 006 | loss: 0.61251 - acc: 0.6528 -- iter: 2976/3072
[A[ATraining Step: 574  | total loss: [1m[32m0.61267[0m[0m | time: 86.143s
[2K
| Adam | epoch: 006 | loss: 0.61267 - acc: 0.6594 -- iter: 3008/3072
[A[ATraining Step: 575  | total loss: [1m[32m0.60872[0m[0m | time: 87.120s
[2K
| Adam | epoch: 006 | loss: 0.60872 - acc: 0.6685 -- iter: 3040/3072
[A[ATraining Step: 576  | total loss: [1m[32m0.60467[0m[0m | time: 92.627s
[2K
| Adam | epoch: 006 | loss: 0.60467 - acc: 0.6673 | val_loss: 0.65210 - val_acc: 0.6327 -- iter: 3072/3072
--
Training Step: 577  | total loss: [1m[32m0.60095[0m[0m | time: 1.002s
[2K
| Adam | epoch: 007 | loss: 0.60095 - acc: 0.6693 -- iter: 0032/3072
[A[ATraining Step: 578  | total loss: [1m[32m0.62560[0m[0m | time: 1.870s
[2K
| Adam | epoch: 007 | loss: 0.62560 - acc: 0.6555 -- iter: 0064/3072
[A[ATraining Step: 579  | total loss: [1m[32m0.63217[0m[0m | time: 2.763s
[2K
| Adam | epoch: 007 | loss: 0.63217 - acc: 0.6524 -- iter: 0096/3072
[A[ATraining Step: 580  | total loss: [1m[32m0.62492[0m[0m | time: 3.699s
[2K
| Adam | epoch: 007 | loss: 0.62492 - acc: 0.6559 -- iter: 0128/3072
[A[ATraining Step: 581  | total loss: [1m[32m0.61824[0m[0m | time: 4.760s
[2K
| Adam | epoch: 007 | loss: 0.61824 - acc: 0.6560 -- iter: 0160/3072
[A[ATraining Step: 582  | total loss: [1m[32m0.62265[0m[0m | time: 5.669s
[2K
| Adam | epoch: 007 | loss: 0.62265 - acc: 0.6497 -- iter: 0192/3072
[A[ATraining Step: 583  | total loss: [1m[32m0.62444[0m[0m | time: 6.687s
[2K
| Adam | epoch: 007 | loss: 0.62444 - acc: 0.6473 -- iter: 0224/3072
[A[ATraining Step: 584  | total loss: [1m[32m0.62710[0m[0m | time: 7.804s
[2K
| Adam | epoch: 007 | loss: 0.62710 - acc: 0.6482 -- iter: 0256/3072
[A[ATraining Step: 585  | total loss: [1m[32m0.62351[0m[0m | time: 8.773s
[2K
| Adam | epoch: 007 | loss: 0.62351 - acc: 0.6521 -- iter: 0288/3072
[A[ATraining Step: 586  | total loss: [1m[32m0.62858[0m[0m | time: 9.489s
[2K
| Adam | epoch: 007 | loss: 0.62858 - acc: 0.6494 -- iter: 0320/3072
[A[ATraining Step: 587  | total loss: [1m[32m0.62236[0m[0m | time: 10.388s
[2K
| Adam | epoch: 007 | loss: 0.62236 - acc: 0.6626 -- iter: 0352/3072
[A[ATraining Step: 588  | total loss: [1m[32m0.62457[0m[0m | time: 11.239s
[2K
| Adam | epoch: 007 | loss: 0.62457 - acc: 0.6526 -- iter: 0384/3072
[A[ATraining Step: 589  | total loss: [1m[32m0.60859[0m[0m | time: 12.063s
[2K
| Adam | epoch: 007 | loss: 0.60859 - acc: 0.6842 -- iter: 0416/3072
[A[ATraining Step: 590  | total loss: [1m[32m0.60404[0m[0m | time: 12.968s
[2K
| Adam | epoch: 007 | loss: 0.60404 - acc: 0.6908 -- iter: 0448/3072
[A[ATraining Step: 591  | total loss: [1m[32m0.60207[0m[0m | time: 13.858s
[2K
| Adam | epoch: 007 | loss: 0.60207 - acc: 0.6936 -- iter: 0480/3072
[A[ATraining Step: 592  | total loss: [1m[32m0.60354[0m[0m | time: 14.905s
[2K
| Adam | epoch: 007 | loss: 0.60354 - acc: 0.6898 -- iter: 0512/3072
[A[ATraining Step: 593  | total loss: [1m[32m0.60944[0m[0m | time: 15.807s
[2K
| Adam | epoch: 007 | loss: 0.60944 - acc: 0.6802 -- iter: 0544/3072
[A[ATraining Step: 594  | total loss: [1m[32m0.60107[0m[0m | time: 16.816s
[2K
| Adam | epoch: 007 | loss: 0.60107 - acc: 0.6872 -- iter: 0576/3072
[A[ATraining Step: 595  | total loss: [1m[32m0.59431[0m[0m | time: 17.878s
[2K
| Adam | epoch: 007 | loss: 0.59431 - acc: 0.6966 -- iter: 0608/3072
[A[ATraining Step: 596  | total loss: [1m[32m0.59393[0m[0m | time: 18.832s
[2K
| Adam | epoch: 007 | loss: 0.59393 - acc: 0.6894 -- iter: 0640/3072
[A[ATraining Step: 597  | total loss: [1m[32m0.59256[0m[0m | time: 19.597s
[2K
| Adam | epoch: 007 | loss: 0.59256 - acc: 0.6861 -- iter: 0672/3072
[A[ATraining Step: 598  | total loss: [1m[32m0.60390[0m[0m | time: 20.510s
[2K
| Adam | epoch: 007 | loss: 0.60390 - acc: 0.6738 -- iter: 0704/3072
[A[ATraining Step: 599  | total loss: [1m[32m0.60373[0m[0m | time: 21.388s
[2K
| Adam | epoch: 007 | loss: 0.60373 - acc: 0.6751 -- iter: 0736/3072
[A[ATraining Step: 600  | total loss: [1m[32m0.60106[0m[0m | time: 26.852s
[2K
| Adam | epoch: 007 | loss: 0.60106 - acc: 0.6764 | val_loss: 0.59824 - val_acc: 0.6649 -- iter: 0768/3072
--
Training Step: 601  | total loss: [1m[32m0.59355[0m[0m | time: 27.819s
[2K
| Adam | epoch: 007 | loss: 0.59355 - acc: 0.6806 -- iter: 0800/3072
[A[ATraining Step: 602  | total loss: [1m[32m0.59641[0m[0m | time: 28.699s
[2K
| Adam | epoch: 007 | loss: 0.59641 - acc: 0.6751 -- iter: 0832/3072
[A[ATraining Step: 603  | total loss: [1m[32m0.59348[0m[0m | time: 29.563s
[2K
| Adam | epoch: 007 | loss: 0.59348 - acc: 0.6888 -- iter: 0864/3072
[A[ATraining Step: 604  | total loss: [1m[32m0.59643[0m[0m | time: 30.435s
[2K
| Adam | epoch: 007 | loss: 0.59643 - acc: 0.6793 -- iter: 0896/3072
[A[ATraining Step: 605  | total loss: [1m[32m0.59219[0m[0m | time: 31.391s
[2K
| Adam | epoch: 007 | loss: 0.59219 - acc: 0.6832 -- iter: 0928/3072
[A[ATraining Step: 606  | total loss: [1m[32m0.59236[0m[0m | time: 32.336s
[2K
| Adam | epoch: 007 | loss: 0.59236 - acc: 0.6837 -- iter: 0960/3072
[A[ATraining Step: 607  | total loss: [1m[32m0.60725[0m[0m | time: 33.418s
[2K
| Adam | epoch: 007 | loss: 0.60725 - acc: 0.6622 -- iter: 0992/3072
[A[ATraining Step: 608  | total loss: [1m[32m0.60767[0m[0m | time: 34.327s
[2K
| Adam | epoch: 007 | loss: 0.60767 - acc: 0.6678 -- iter: 1024/3072
[A[ATraining Step: 609  | total loss: [1m[32m0.60362[0m[0m | time: 35.325s
[2K
| Adam | epoch: 007 | loss: 0.60362 - acc: 0.6792 -- iter: 1056/3072
[A[ATraining Step: 610  | total loss: [1m[32m0.59833[0m[0m | time: 36.339s
[2K
| Adam | epoch: 007 | loss: 0.59833 - acc: 0.6894 -- iter: 1088/3072
[A[ATraining Step: 611  | total loss: [1m[32m0.59304[0m[0m | time: 37.330s
[2K
| Adam | epoch: 007 | loss: 0.59304 - acc: 0.6861 -- iter: 1120/3072
[A[ATraining Step: 612  | total loss: [1m[32m0.59021[0m[0m | time: 38.141s
[2K
| Adam | epoch: 007 | loss: 0.59021 - acc: 0.6831 -- iter: 1152/3072
[A[ATraining Step: 613  | total loss: [1m[32m0.59101[0m[0m | time: 38.982s
[2K
| Adam | epoch: 007 | loss: 0.59101 - acc: 0.6867 -- iter: 1184/3072
[A[ATraining Step: 614  | total loss: [1m[32m0.59356[0m[0m | time: 39.889s
[2K
| Adam | epoch: 007 | loss: 0.59356 - acc: 0.6836 -- iter: 1216/3072
[A[ATraining Step: 615  | total loss: [1m[32m0.59448[0m[0m | time: 40.817s
[2K
| Adam | epoch: 007 | loss: 0.59448 - acc: 0.6840 -- iter: 1248/3072
[A[ATraining Step: 616  | total loss: [1m[32m0.59769[0m[0m | time: 41.808s
[2K
| Adam | epoch: 007 | loss: 0.59769 - acc: 0.6844 -- iter: 1280/3072
[A[ATraining Step: 617  | total loss: [1m[32m0.59582[0m[0m | time: 42.764s
[2K
| Adam | epoch: 007 | loss: 0.59582 - acc: 0.6847 -- iter: 1312/3072
[A[ATraining Step: 618  | total loss: [1m[32m0.58719[0m[0m | time: 43.693s
[2K
| Adam | epoch: 007 | loss: 0.58719 - acc: 0.6974 -- iter: 1344/3072
[A[ATraining Step: 619  | total loss: [1m[32m0.58318[0m[0m | time: 44.500s
[2K
| Adam | epoch: 007 | loss: 0.58318 - acc: 0.6902 -- iter: 1376/3072
[A[ATraining Step: 620  | total loss: [1m[32m0.58758[0m[0m | time: 45.564s
[2K
| Adam | epoch: 007 | loss: 0.58758 - acc: 0.6962 -- iter: 1408/3072
[A[ATraining Step: 621  | total loss: [1m[32m0.58676[0m[0m | time: 46.594s
[2K
| Adam | epoch: 007 | loss: 0.58676 - acc: 0.7016 -- iter: 1440/3072
[A[ATraining Step: 622  | total loss: [1m[32m0.58127[0m[0m | time: 47.444s
[2K
| Adam | epoch: 007 | loss: 0.58127 - acc: 0.7033 -- iter: 1472/3072
[A[ATraining Step: 623  | total loss: [1m[32m0.58180[0m[0m | time: 48.332s
[2K
| Adam | epoch: 007 | loss: 0.58180 - acc: 0.6986 -- iter: 1504/3072
[A[ATraining Step: 624  | total loss: [1m[32m0.56679[0m[0m | time: 49.187s
[2K
| Adam | epoch: 007 | loss: 0.56679 - acc: 0.7131 -- iter: 1536/3072
[A[ATraining Step: 625  | total loss: [1m[32m0.57127[0m[0m | time: 50.063s
[2K
| Adam | epoch: 007 | loss: 0.57127 - acc: 0.7043 -- iter: 1568/3072
[A[ATraining Step: 626  | total loss: [1m[32m0.58514[0m[0m | time: 50.959s
[2K
| Adam | epoch: 007 | loss: 0.58514 - acc: 0.6839 -- iter: 1600/3072
[A[ATraining Step: 627  | total loss: [1m[32m0.58614[0m[0m | time: 51.881s
[2K
| Adam | epoch: 007 | loss: 0.58614 - acc: 0.6936 -- iter: 1632/3072
[A[ATraining Step: 628  | total loss: [1m[32m0.58956[0m[0m | time: 52.905s
[2K
| Adam | epoch: 007 | loss: 0.58956 - acc: 0.6930 -- iter: 1664/3072
[A[ATraining Step: 629  | total loss: [1m[32m0.60784[0m[0m | time: 53.760s
[2K
| Adam | epoch: 007 | loss: 0.60784 - acc: 0.6737 -- iter: 1696/3072
[A[ATraining Step: 630  | total loss: [1m[32m0.60539[0m[0m | time: 54.692s
[2K
| Adam | epoch: 007 | loss: 0.60539 - acc: 0.6688 -- iter: 1728/3072
[A[ATraining Step: 631  | total loss: [1m[32m0.60147[0m[0m | time: 55.730s
[2K
| Adam | epoch: 007 | loss: 0.60147 - acc: 0.6801 -- iter: 1760/3072
[A[ATraining Step: 632  | total loss: [1m[32m0.60224[0m[0m | time: 56.777s
[2K
| Adam | epoch: 007 | loss: 0.60224 - acc: 0.6777 -- iter: 1792/3072
[A[ATraining Step: 633  | total loss: [1m[32m0.60616[0m[0m | time: 57.505s
[2K
| Adam | epoch: 007 | loss: 0.60616 - acc: 0.6693 -- iter: 1824/3072
[A[ATraining Step: 634  | total loss: [1m[32m0.59507[0m[0m | time: 58.418s
[2K
| Adam | epoch: 007 | loss: 0.59507 - acc: 0.6836 -- iter: 1856/3072
[A[ATraining Step: 635  | total loss: [1m[32m0.58511[0m[0m | time: 59.290s
[2K
| Adam | epoch: 007 | loss: 0.58511 - acc: 0.6902 -- iter: 1888/3072
[A[ATraining Step: 636  | total loss: [1m[32m0.57785[0m[0m | time: 60.182s
[2K
| Adam | epoch: 007 | loss: 0.57785 - acc: 0.6993 -- iter: 1920/3072
[A[ATraining Step: 637  | total loss: [1m[32m0.58444[0m[0m | time: 61.090s
[2K
| Adam | epoch: 007 | loss: 0.58444 - acc: 0.6982 -- iter: 1952/3072
[A[ATraining Step: 638  | total loss: [1m[32m0.58278[0m[0m | time: 62.088s
[2K
| Adam | epoch: 007 | loss: 0.58278 - acc: 0.7002 -- iter: 1984/3072
[A[ATraining Step: 639  | total loss: [1m[32m0.58190[0m[0m | time: 63.060s
[2K
| Adam | epoch: 007 | loss: 0.58190 - acc: 0.7021 -- iter: 2016/3072
[A[ATraining Step: 640  | total loss: [1m[32m0.58035[0m[0m | time: 64.029s
[2K
| Adam | epoch: 007 | loss: 0.58035 - acc: 0.7069 -- iter: 2048/3072
[A[ATraining Step: 641  | total loss: [1m[32m0.57659[0m[0m | time: 65.044s
[2K
| Adam | epoch: 007 | loss: 0.57659 - acc: 0.7112 -- iter: 2080/3072
[A[ATraining Step: 642  | total loss: [1m[32m0.58394[0m[0m | time: 66.096s
[2K
| Adam | epoch: 007 | loss: 0.58394 - acc: 0.6963 -- iter: 2112/3072
[A[ATraining Step: 643  | total loss: [1m[32m0.58237[0m[0m | time: 66.926s
[2K
| Adam | epoch: 007 | loss: 0.58237 - acc: 0.7017 -- iter: 2144/3072
[A[ATraining Step: 644  | total loss: [1m[32m0.57830[0m[0m | time: 67.766s
[2K
| Adam | epoch: 007 | loss: 0.57830 - acc: 0.7003 -- iter: 2176/3072
[A[ATraining Step: 645  | total loss: [1m[32m0.57560[0m[0m | time: 68.622s
[2K
| Adam | epoch: 007 | loss: 0.57560 - acc: 0.6990 -- iter: 2208/3072
[A[ATraining Step: 646  | total loss: [1m[32m0.56690[0m[0m | time: 69.574s
[2K
| Adam | epoch: 007 | loss: 0.56690 - acc: 0.7103 -- iter: 2240/3072
[A[ATraining Step: 647  | total loss: [1m[32m0.58767[0m[0m | time: 70.477s
[2K
| Adam | epoch: 007 | loss: 0.58767 - acc: 0.6924 -- iter: 2272/3072
[A[ATraining Step: 648  | total loss: [1m[32m0.58712[0m[0m | time: 71.430s
[2K
| Adam | epoch: 007 | loss: 0.58712 - acc: 0.6888 -- iter: 2304/3072
[A[ATraining Step: 649  | total loss: [1m[32m0.59807[0m[0m | time: 72.428s
[2K
| Adam | epoch: 007 | loss: 0.59807 - acc: 0.6699 -- iter: 2336/3072
[A[ATraining Step: 650  | total loss: [1m[32m0.58894[0m[0m | time: 73.333s
[2K
| Adam | epoch: 007 | loss: 0.58894 - acc: 0.6811 -- iter: 2368/3072
[A[ATraining Step: 651  | total loss: [1m[32m0.58466[0m[0m | time: 74.399s
[2K
| Adam | epoch: 007 | loss: 0.58466 - acc: 0.6817 -- iter: 2400/3072
[A[ATraining Step: 652  | total loss: [1m[32m0.58980[0m[0m | time: 75.534s
[2K
| Adam | epoch: 007 | loss: 0.58980 - acc: 0.6760 -- iter: 2432/3072
[A[ATraining Step: 653  | total loss: [1m[32m0.59971[0m[0m | time: 76.444s
[2K
| Adam | epoch: 007 | loss: 0.59971 - acc: 0.6678 -- iter: 2464/3072
[A[ATraining Step: 654  | total loss: [1m[32m0.58793[0m[0m | time: 77.300s
[2K
| Adam | epoch: 007 | loss: 0.58793 - acc: 0.6823 -- iter: 2496/3072
[A[ATraining Step: 655  | total loss: [1m[32m0.58294[0m[0m | time: 78.181s
[2K
| Adam | epoch: 007 | loss: 0.58294 - acc: 0.6984 -- iter: 2528/3072
[A[ATraining Step: 656  | total loss: [1m[32m0.58249[0m[0m | time: 79.135s
[2K
| Adam | epoch: 007 | loss: 0.58249 - acc: 0.6942 -- iter: 2560/3072
[A[ATraining Step: 657  | total loss: [1m[32m0.57690[0m[0m | time: 80.021s
[2K
| Adam | epoch: 007 | loss: 0.57690 - acc: 0.6967 -- iter: 2592/3072
[A[ATraining Step: 658  | total loss: [1m[32m0.57474[0m[0m | time: 81.011s
[2K
| Adam | epoch: 007 | loss: 0.57474 - acc: 0.6957 -- iter: 2624/3072
[A[ATraining Step: 659  | total loss: [1m[32m0.57325[0m[0m | time: 82.042s
[2K
| Adam | epoch: 007 | loss: 0.57325 - acc: 0.7012 -- iter: 2656/3072
[A[ATraining Step: 660  | total loss: [1m[32m0.58106[0m[0m | time: 82.954s
[2K
| Adam | epoch: 007 | loss: 0.58106 - acc: 0.6904 -- iter: 2688/3072
[A[ATraining Step: 661  | total loss: [1m[32m0.58122[0m[0m | time: 83.828s
[2K
| Adam | epoch: 007 | loss: 0.58122 - acc: 0.6870 -- iter: 2720/3072
[A[ATraining Step: 662  | total loss: [1m[32m0.57987[0m[0m | time: 84.899s
[2K
| Adam | epoch: 007 | loss: 0.57987 - acc: 0.6933 -- iter: 2752/3072
[A[ATraining Step: 663  | total loss: [1m[32m0.57885[0m[0m | time: 85.914s
[2K
| Adam | epoch: 007 | loss: 0.57885 - acc: 0.6990 -- iter: 2784/3072
[A[ATraining Step: 664  | total loss: [1m[32m0.57006[0m[0m | time: 86.656s
[2K
| Adam | epoch: 007 | loss: 0.57006 - acc: 0.7103 -- iter: 2816/3072
[A[ATraining Step: 665  | total loss: [1m[32m0.57228[0m[0m | time: 87.498s
[2K
| Adam | epoch: 007 | loss: 0.57228 - acc: 0.7049 -- iter: 2848/3072
[A[ATraining Step: 666  | total loss: [1m[32m0.57973[0m[0m | time: 88.399s
[2K
| Adam | epoch: 007 | loss: 0.57973 - acc: 0.6876 -- iter: 2880/3072
[A[ATraining Step: 667  | total loss: [1m[32m0.58071[0m[0m | time: 89.410s
[2K
| Adam | epoch: 007 | loss: 0.58071 - acc: 0.6844 -- iter: 2912/3072
[A[ATraining Step: 668  | total loss: [1m[32m0.58199[0m[0m | time: 90.435s
[2K
| Adam | epoch: 007 | loss: 0.58199 - acc: 0.6910 -- iter: 2944/3072
[A[ATraining Step: 669  | total loss: [1m[32m0.57001[0m[0m | time: 91.373s
[2K
| Adam | epoch: 007 | loss: 0.57001 - acc: 0.7031 -- iter: 2976/3072
[A[ATraining Step: 670  | total loss: [1m[32m0.55634[0m[0m | time: 92.327s
[2K
| Adam | epoch: 007 | loss: 0.55634 - acc: 0.7141 -- iter: 3008/3072
[A[ATraining Step: 671  | total loss: [1m[32m0.54812[0m[0m | time: 93.225s
[2K
| Adam | epoch: 007 | loss: 0.54812 - acc: 0.7208 -- iter: 3040/3072
[A[ATraining Step: 672  | total loss: [1m[32m0.55264[0m[0m | time: 98.701s
[2K
| Adam | epoch: 007 | loss: 0.55264 - acc: 0.7175 | val_loss: 0.57018 - val_acc: 0.7024 -- iter: 3072/3072
--
Training Step: 673  | total loss: [1m[32m0.55208[0m[0m | time: 0.853s
[2K
| Adam | epoch: 008 | loss: 0.55208 - acc: 0.7238 -- iter: 0032/3072
[A[ATraining Step: 674  | total loss: [1m[32m0.54811[0m[0m | time: 1.793s
[2K
| Adam | epoch: 008 | loss: 0.54811 - acc: 0.7327 -- iter: 0064/3072
[A[ATraining Step: 675  | total loss: [1m[32m0.55320[0m[0m | time: 2.776s
[2K
| Adam | epoch: 008 | loss: 0.55320 - acc: 0.7313 -- iter: 0096/3072
[A[ATraining Step: 676  | total loss: [1m[32m0.55153[0m[0m | time: 3.741s
[2K
| Adam | epoch: 008 | loss: 0.55153 - acc: 0.7332 -- iter: 0128/3072
[A[ATraining Step: 677  | total loss: [1m[32m0.53892[0m[0m | time: 4.587s
[2K
| Adam | epoch: 008 | loss: 0.53892 - acc: 0.7442 -- iter: 0160/3072
[A[ATraining Step: 678  | total loss: [1m[32m0.54144[0m[0m | time: 5.611s
[2K
| Adam | epoch: 008 | loss: 0.54144 - acc: 0.7354 -- iter: 0192/3072
[A[ATraining Step: 679  | total loss: [1m[32m0.55146[0m[0m | time: 6.674s
[2K
| Adam | epoch: 008 | loss: 0.55146 - acc: 0.7244 -- iter: 0224/3072
[A[ATraining Step: 680  | total loss: [1m[32m0.55929[0m[0m | time: 7.472s
[2K
| Adam | epoch: 008 | loss: 0.55929 - acc: 0.7207 -- iter: 0256/3072
[A[ATraining Step: 681  | total loss: [1m[32m0.55257[0m[0m | time: 8.320s
[2K
| Adam | epoch: 008 | loss: 0.55257 - acc: 0.7299 -- iter: 0288/3072
[A[ATraining Step: 682  | total loss: [1m[32m0.54961[0m[0m | time: 9.245s
[2K
| Adam | epoch: 008 | loss: 0.54961 - acc: 0.7319 -- iter: 0320/3072
[A[ATraining Step: 683  | total loss: [1m[32m0.55602[0m[0m | time: 10.163s
[2K
| Adam | epoch: 008 | loss: 0.55602 - acc: 0.7306 -- iter: 0352/3072
[A[ATraining Step: 684  | total loss: [1m[32m0.54420[0m[0m | time: 11.091s
[2K
| Adam | epoch: 008 | loss: 0.54420 - acc: 0.7450 -- iter: 0384/3072
[A[ATraining Step: 685  | total loss: [1m[32m0.54791[0m[0m | time: 12.042s
[2K
| Adam | epoch: 008 | loss: 0.54791 - acc: 0.7361 -- iter: 0416/3072
[A[ATraining Step: 686  | total loss: [1m[32m0.56264[0m[0m | time: 12.931s
[2K
| Adam | epoch: 008 | loss: 0.56264 - acc: 0.7250 -- iter: 0448/3072
[A[ATraining Step: 687  | total loss: [1m[32m0.56729[0m[0m | time: 13.852s
[2K
| Adam | epoch: 008 | loss: 0.56729 - acc: 0.7119 -- iter: 0480/3072
[A[ATraining Step: 688  | total loss: [1m[32m0.56803[0m[0m | time: 14.972s
[2K
| Adam | epoch: 008 | loss: 0.56803 - acc: 0.7157 -- iter: 0512/3072
[A[ATraining Step: 689  | total loss: [1m[32m0.57152[0m[0m | time: 16.013s
[2K
| Adam | epoch: 008 | loss: 0.57152 - acc: 0.7098 -- iter: 0544/3072
[A[ATraining Step: 690  | total loss: [1m[32m0.56841[0m[0m | time: 16.862s
[2K
| Adam | epoch: 008 | loss: 0.56841 - acc: 0.7107 -- iter: 0576/3072
[A[ATraining Step: 691  | total loss: [1m[32m0.57204[0m[0m | time: 17.803s
[2K
| Adam | epoch: 008 | loss: 0.57204 - acc: 0.6990 -- iter: 0608/3072
[A[ATraining Step: 692  | total loss: [1m[32m0.58763[0m[0m | time: 18.755s
[2K
| Adam | epoch: 008 | loss: 0.58763 - acc: 0.6947 -- iter: 0640/3072
[A[ATraining Step: 693  | total loss: [1m[32m0.59103[0m[0m | time: 19.667s
[2K
| Adam | epoch: 008 | loss: 0.59103 - acc: 0.6877 -- iter: 0672/3072
[A[ATraining Step: 694  | total loss: [1m[32m0.58778[0m[0m | time: 20.530s
[2K
| Adam | epoch: 008 | loss: 0.58778 - acc: 0.6877 -- iter: 0704/3072
[A[ATraining Step: 695  | total loss: [1m[32m0.58866[0m[0m | time: 21.544s
[2K
| Adam | epoch: 008 | loss: 0.58866 - acc: 0.6814 -- iter: 0736/3072
[A[ATraining Step: 696  | total loss: [1m[32m0.58906[0m[0m | time: 22.519s
[2K
| Adam | epoch: 008 | loss: 0.58906 - acc: 0.6820 -- iter: 0768/3072
[A[ATraining Step: 697  | total loss: [1m[32m0.58168[0m[0m | time: 23.358s
[2K
| Adam | epoch: 008 | loss: 0.58168 - acc: 0.6951 -- iter: 0800/3072
[A[ATraining Step: 698  | total loss: [1m[32m0.57995[0m[0m | time: 24.464s
[2K
| Adam | epoch: 008 | loss: 0.57995 - acc: 0.6943 -- iter: 0832/3072
[A[ATraining Step: 699  | total loss: [1m[32m0.57109[0m[0m | time: 25.494s
[2K
| Adam | epoch: 008 | loss: 0.57109 - acc: 0.6968 -- iter: 0864/3072
[A[ATraining Step: 700  | total loss: [1m[32m0.56259[0m[0m | time: 26.451s
[2K
| Adam | epoch: 008 | loss: 0.56259 - acc: 0.7052 -- iter: 0896/3072
[A[ATraining Step: 701  | total loss: [1m[32m0.55151[0m[0m | time: 27.219s
[2K
| Adam | epoch: 008 | loss: 0.55151 - acc: 0.7253 -- iter: 0928/3072
[A[ATraining Step: 702  | total loss: [1m[32m0.55846[0m[0m | time: 28.179s
[2K
| Adam | epoch: 008 | loss: 0.55846 - acc: 0.7184 -- iter: 0960/3072
[A[ATraining Step: 703  | total loss: [1m[32m0.56383[0m[0m | time: 29.058s
[2K
| Adam | epoch: 008 | loss: 0.56383 - acc: 0.7059 -- iter: 0992/3072
[A[ATraining Step: 704  | total loss: [1m[32m0.56636[0m[0m | time: 29.947s
[2K
| Adam | epoch: 008 | loss: 0.56636 - acc: 0.7104 -- iter: 1024/3072
[A[ATraining Step: 705  | total loss: [1m[32m0.55372[0m[0m | time: 30.957s
[2K
| Adam | epoch: 008 | loss: 0.55372 - acc: 0.7237 -- iter: 1056/3072
[A[ATraining Step: 706  | total loss: [1m[32m0.55603[0m[0m | time: 31.923s
[2K
| Adam | epoch: 008 | loss: 0.55603 - acc: 0.7138 -- iter: 1088/3072
[A[ATraining Step: 707  | total loss: [1m[32m0.57338[0m[0m | time: 32.793s
[2K
| Adam | epoch: 008 | loss: 0.57338 - acc: 0.6924 -- iter: 1120/3072
[A[ATraining Step: 708  | total loss: [1m[32m0.56076[0m[0m | time: 33.666s
[2K
| Adam | epoch: 008 | loss: 0.56076 - acc: 0.7076 -- iter: 1152/3072
[A[ATraining Step: 709  | total loss: [1m[32m0.54787[0m[0m | time: 34.718s
[2K
| Adam | epoch: 008 | loss: 0.54787 - acc: 0.7212 -- iter: 1184/3072
[A[ATraining Step: 710  | total loss: [1m[32m0.55096[0m[0m | time: 35.760s
[2K
| Adam | epoch: 008 | loss: 0.55096 - acc: 0.7147 -- iter: 1216/3072
[A[ATraining Step: 711  | total loss: [1m[32m0.55783[0m[0m | time: 36.570s
[2K
| Adam | epoch: 008 | loss: 0.55783 - acc: 0.7057 -- iter: 1248/3072
[A[ATraining Step: 712  | total loss: [1m[32m0.54485[0m[0m | time: 37.517s
[2K
| Adam | epoch: 008 | loss: 0.54485 - acc: 0.7195 -- iter: 1280/3072
[A[ATraining Step: 713  | total loss: [1m[32m0.54865[0m[0m | time: 38.430s
[2K
| Adam | epoch: 008 | loss: 0.54865 - acc: 0.7101 -- iter: 1312/3072
[A[ATraining Step: 714  | total loss: [1m[32m0.53839[0m[0m | time: 39.288s
[2K
| Adam | epoch: 008 | loss: 0.53839 - acc: 0.7172 -- iter: 1344/3072
[A[ATraining Step: 715  | total loss: [1m[32m0.55880[0m[0m | time: 40.210s
[2K
| Adam | epoch: 008 | loss: 0.55880 - acc: 0.6923 -- iter: 1376/3072
[A[ATraining Step: 716  | total loss: [1m[32m0.56152[0m[0m | time: 41.181s
[2K
| Adam | epoch: 008 | loss: 0.56152 - acc: 0.6919 -- iter: 1408/3072
[A[ATraining Step: 717  | total loss: [1m[32m0.55407[0m[0m | time: 42.115s
[2K
| Adam | epoch: 008 | loss: 0.55407 - acc: 0.7008 -- iter: 1440/3072
[A[ATraining Step: 718  | total loss: [1m[32m0.54625[0m[0m | time: 42.931s
[2K
| Adam | epoch: 008 | loss: 0.54625 - acc: 0.7182 -- iter: 1472/3072
[A[ATraining Step: 719  | total loss: [1m[32m0.54987[0m[0m | time: 44.086s
[2K
| Adam | epoch: 008 | loss: 0.54987 - acc: 0.7120 -- iter: 1504/3072
[A[ATraining Step: 720  | total loss: [1m[32m0.54582[0m[0m | time: 45.200s
[2K
| Adam | epoch: 008 | loss: 0.54582 - acc: 0.7158 -- iter: 1536/3072
[A[ATraining Step: 721  | total loss: [1m[32m0.55593[0m[0m | time: 46.121s
[2K
| Adam | epoch: 008 | loss: 0.55593 - acc: 0.7005 -- iter: 1568/3072
[A[ATraining Step: 722  | total loss: [1m[32m0.56727[0m[0m | time: 47.012s
[2K
| Adam | epoch: 008 | loss: 0.56727 - acc: 0.6836 -- iter: 1600/3072
[A[ATraining Step: 723  | total loss: [1m[32m0.56547[0m[0m | time: 47.892s
[2K
| Adam | epoch: 008 | loss: 0.56547 - acc: 0.6777 -- iter: 1632/3072
[A[ATraining Step: 724  | total loss: [1m[32m0.56301[0m[0m | time: 48.764s
[2K
| Adam | epoch: 008 | loss: 0.56301 - acc: 0.6818 -- iter: 1664/3072
[A[ATraining Step: 725  | total loss: [1m[32m0.55619[0m[0m | time: 49.685s
[2K
| Adam | epoch: 008 | loss: 0.55619 - acc: 0.6918 -- iter: 1696/3072
[A[ATraining Step: 726  | total loss: [1m[32m0.56082[0m[0m | time: 50.668s
[2K
| Adam | epoch: 008 | loss: 0.56082 - acc: 0.6882 -- iter: 1728/3072
[A[ATraining Step: 727  | total loss: [1m[32m0.57147[0m[0m | time: 51.591s
[2K
| Adam | epoch: 008 | loss: 0.57147 - acc: 0.6788 -- iter: 1760/3072
[A[ATraining Step: 728  | total loss: [1m[32m0.59482[0m[0m | time: 52.424s
[2K
| Adam | epoch: 008 | loss: 0.59482 - acc: 0.6671 -- iter: 1792/3072
[A[ATraining Step: 729  | total loss: [1m[32m0.60056[0m[0m | time: 53.360s
[2K
| Adam | epoch: 008 | loss: 0.60056 - acc: 0.6629 -- iter: 1824/3072
[A[ATraining Step: 730  | total loss: [1m[32m0.61175[0m[0m | time: 54.268s
[2K
| Adam | epoch: 008 | loss: 0.61175 - acc: 0.6560 -- iter: 1856/3072
[A[ATraining Step: 731  | total loss: [1m[32m0.61104[0m[0m | time: 55.270s
[2K
| Adam | epoch: 008 | loss: 0.61104 - acc: 0.6560 -- iter: 1888/3072
[A[ATraining Step: 732  | total loss: [1m[32m0.60016[0m[0m | time: 56.217s
[2K
| Adam | epoch: 008 | loss: 0.60016 - acc: 0.6717 -- iter: 1920/3072
[A[ATraining Step: 733  | total loss: [1m[32m0.60025[0m[0m | time: 57.236s
[2K
| Adam | epoch: 008 | loss: 0.60025 - acc: 0.6764 -- iter: 1952/3072
[A[ATraining Step: 734  | total loss: [1m[32m0.59021[0m[0m | time: 58.221s
[2K
| Adam | epoch: 008 | loss: 0.59021 - acc: 0.6869 -- iter: 1984/3072
[A[ATraining Step: 735  | total loss: [1m[32m0.58379[0m[0m | time: 59.128s
[2K
| Adam | epoch: 008 | loss: 0.58379 - acc: 0.6932 -- iter: 2016/3072
[A[ATraining Step: 736  | total loss: [1m[32m0.57957[0m[0m | time: 60.091s
[2K
| Adam | epoch: 008 | loss: 0.57957 - acc: 0.6989 -- iter: 2048/3072
[A[ATraining Step: 737  | total loss: [1m[32m0.56865[0m[0m | time: 61.071s
[2K
| Adam | epoch: 008 | loss: 0.56865 - acc: 0.7071 -- iter: 2080/3072
[A[ATraining Step: 738  | total loss: [1m[32m0.56212[0m[0m | time: 62.188s
[2K
| Adam | epoch: 008 | loss: 0.56212 - acc: 0.7083 -- iter: 2112/3072
[A[ATraining Step: 739  | total loss: [1m[32m0.56065[0m[0m | time: 63.184s
[2K
| Adam | epoch: 008 | loss: 0.56065 - acc: 0.7093 -- iter: 2144/3072
[A[ATraining Step: 740  | total loss: [1m[32m0.56774[0m[0m | time: 64.272s
[2K
| Adam | epoch: 008 | loss: 0.56774 - acc: 0.6978 -- iter: 2176/3072
[A[ATraining Step: 741  | total loss: [1m[32m0.56783[0m[0m | time: 65.232s
[2K
| Adam | epoch: 008 | loss: 0.56783 - acc: 0.7030 -- iter: 2208/3072
[A[ATraining Step: 742  | total loss: [1m[32m0.56186[0m[0m | time: 66.205s
[2K
| Adam | epoch: 008 | loss: 0.56186 - acc: 0.7108 -- iter: 2240/3072
[A[ATraining Step: 743  | total loss: [1m[32m0.56345[0m[0m | time: 66.860s
[2K
| Adam | epoch: 008 | loss: 0.56345 - acc: 0.7085 -- iter: 2272/3072
[A[ATraining Step: 744  | total loss: [1m[32m0.55821[0m[0m | time: 67.490s
[2K
| Adam | epoch: 008 | loss: 0.55821 - acc: 0.7158 -- iter: 2304/3072
[A[ATraining Step: 745  | total loss: [1m[32m0.54776[0m[0m | time: 68.106s
[2K
| Adam | epoch: 008 | loss: 0.54776 - acc: 0.7254 -- iter: 2336/3072
[A[ATraining Step: 746  | total loss: [1m[32m0.53940[0m[0m | time: 68.766s
[2K
| Adam | epoch: 008 | loss: 0.53940 - acc: 0.7310 -- iter: 2368/3072
[A[ATraining Step: 747  | total loss: [1m[32m0.54694[0m[0m | time: 69.371s
[2K
| Adam | epoch: 008 | loss: 0.54694 - acc: 0.7204 -- iter: 2400/3072
[A[ATraining Step: 748  | total loss: [1m[32m0.54561[0m[0m | time: 69.978s
[2K
| Adam | epoch: 008 | loss: 0.54561 - acc: 0.7202 -- iter: 2432/3072
[A[ATraining Step: 749  | total loss: [1m[32m0.53565[0m[0m | time: 70.583s
[2K
| Adam | epoch: 008 | loss: 0.53565 - acc: 0.7295 -- iter: 2464/3072
[A[ATraining Step: 750  | total loss: [1m[32m0.54186[0m[0m | time: 71.238s
[2K
| Adam | epoch: 008 | loss: 0.54186 - acc: 0.7284 -- iter: 2496/3072
[A[ATraining Step: 751  | total loss: [1m[32m0.54876[0m[0m | time: 71.865s
[2K
| Adam | epoch: 008 | loss: 0.54876 - acc: 0.7181 -- iter: 2528/3072
[A[ATraining Step: 752  | total loss: [1m[32m0.54309[0m[0m | time: 72.460s
[2K
| Adam | epoch: 008 | loss: 0.54309 - acc: 0.7181 -- iter: 2560/3072
[A[ATraining Step: 753  | total loss: [1m[32m0.54374[0m[0m | time: 73.100s
[2K
| Adam | epoch: 008 | loss: 0.54374 - acc: 0.7182 -- iter: 2592/3072
[A[ATraining Step: 754  | total loss: [1m[32m0.53724[0m[0m | time: 73.697s
[2K
| Adam | epoch: 008 | loss: 0.53724 - acc: 0.7276 -- iter: 2624/3072
[A[ATraining Step: 755  | total loss: [1m[32m0.53600[0m[0m | time: 74.315s
[2K
| Adam | epoch: 008 | loss: 0.53600 - acc: 0.7299 -- iter: 2656/3072
[A[ATraining Step: 756  | total loss: [1m[32m0.55021[0m[0m | time: 74.938s
[2K
| Adam | epoch: 008 | loss: 0.55021 - acc: 0.7069 -- iter: 2688/3072
[A[ATraining Step: 757  | total loss: [1m[32m0.54878[0m[0m | time: 75.609s
[2K
| Adam | epoch: 008 | loss: 0.54878 - acc: 0.7049 -- iter: 2720/3072
[A[ATraining Step: 758  | total loss: [1m[32m0.54579[0m[0m | time: 76.207s
[2K
| Adam | epoch: 008 | loss: 0.54579 - acc: 0.7157 -- iter: 2752/3072
[A[ATraining Step: 759  | total loss: [1m[32m0.53109[0m[0m | time: 76.889s
[2K
| Adam | epoch: 008 | loss: 0.53109 - acc: 0.7254 -- iter: 2784/3072
[A[ATraining Step: 760  | total loss: [1m[32m0.54656[0m[0m | time: 77.526s
[2K
| Adam | epoch: 008 | loss: 0.54656 - acc: 0.7060 -- iter: 2816/3072
[A[ATraining Step: 761  | total loss: [1m[32m0.54088[0m[0m | time: 78.212s
[2K
| Adam | epoch: 008 | loss: 0.54088 - acc: 0.7166 -- iter: 2848/3072
[A[ATraining Step: 762  | total loss: [1m[32m0.54531[0m[0m | time: 78.809s
[2K
| Adam | epoch: 008 | loss: 0.54531 - acc: 0.7200 -- iter: 2880/3072
[A[ATraining Step: 763  | total loss: [1m[32m0.55792[0m[0m | time: 79.408s
[2K
| Adam | epoch: 008 | loss: 0.55792 - acc: 0.6980 -- iter: 2912/3072
[A[ATraining Step: 764  | total loss: [1m[32m0.54432[0m[0m | time: 80.010s
[2K
| Adam | epoch: 008 | loss: 0.54432 - acc: 0.7157 -- iter: 2944/3072
[A[ATraining Step: 765  | total loss: [1m[32m0.55301[0m[0m | time: 80.628s
[2K
| Adam | epoch: 008 | loss: 0.55301 - acc: 0.7128 -- iter: 2976/3072
[A[ATraining Step: 766  | total loss: [1m[32m0.56027[0m[0m | time: 81.246s
[2K
| Adam | epoch: 008 | loss: 0.56027 - acc: 0.7041 -- iter: 3008/3072
[A[ATraining Step: 767  | total loss: [1m[32m0.55882[0m[0m | time: 81.904s
[2K
| Adam | epoch: 008 | loss: 0.55882 - acc: 0.7087 -- iter: 3040/3072
[A[ATraining Step: 768  | total loss: [1m[32m0.53773[0m[0m | time: 86.617s
[2K
| Adam | epoch: 008 | loss: 0.53773 - acc: 0.7284 | val_loss: 0.55802 - val_acc: 0.7118 -- iter: 3072/3072
--
Training Step: 769  | total loss: [1m[32m0.54765[0m[0m | time: 0.889s
[2K
| Adam | epoch: 009 | loss: 0.54765 - acc: 0.7118 -- iter: 0032/3072
[A[ATraining Step: 770  | total loss: [1m[32m0.56908[0m[0m | time: 1.847s
[2K
| Adam | epoch: 009 | loss: 0.56908 - acc: 0.6969 -- iter: 0064/3072
[A[ATraining Step: 771  | total loss: [1m[32m0.55384[0m[0m | time: 2.765s
[2K
| Adam | epoch: 009 | loss: 0.55384 - acc: 0.7116 -- iter: 0096/3072
[A[ATraining Step: 772  | total loss: [1m[32m0.55761[0m[0m | time: 3.692s
[2K
| Adam | epoch: 009 | loss: 0.55761 - acc: 0.7123 -- iter: 0128/3072
[A[ATraining Step: 773  | total loss: [1m[32m0.55289[0m[0m | time: 4.627s
[2K
| Adam | epoch: 009 | loss: 0.55289 - acc: 0.7254 -- iter: 0160/3072
[A[ATraining Step: 774  | total loss: [1m[32m0.54204[0m[0m | time: 5.561s
[2K
| Adam | epoch: 009 | loss: 0.54204 - acc: 0.7279 -- iter: 0192/3072
[A[ATraining Step: 775  | total loss: [1m[32m0.53640[0m[0m | time: 6.392s
[2K
| Adam | epoch: 009 | loss: 0.53640 - acc: 0.7332 -- iter: 0224/3072
[A[ATraining Step: 776  | total loss: [1m[32m0.53325[0m[0m | time: 7.430s
[2K
| Adam | epoch: 009 | loss: 0.53325 - acc: 0.7349 -- iter: 0256/3072
[A[ATraining Step: 777  | total loss: [1m[32m0.52995[0m[0m | time: 8.500s
[2K
| Adam | epoch: 009 | loss: 0.52995 - acc: 0.7364 -- iter: 0288/3072
[A[ATraining Step: 778  | total loss: [1m[32m0.52811[0m[0m | time: 9.316s
[2K
| Adam | epoch: 009 | loss: 0.52811 - acc: 0.7378 -- iter: 0320/3072
[A[ATraining Step: 779  | total loss: [1m[32m0.53741[0m[0m | time: 10.134s
[2K
| Adam | epoch: 009 | loss: 0.53741 - acc: 0.7296 -- iter: 0352/3072
[A[ATraining Step: 780  | total loss: [1m[32m0.53335[0m[0m | time: 11.009s
[2K
| Adam | epoch: 009 | loss: 0.53335 - acc: 0.7348 -- iter: 0384/3072
[A[ATraining Step: 781  | total loss: [1m[32m0.53755[0m[0m | time: 11.906s
[2K
| Adam | epoch: 009 | loss: 0.53755 - acc: 0.7363 -- iter: 0416/3072
[A[ATraining Step: 782  | total loss: [1m[32m0.52335[0m[0m | time: 12.874s
[2K
| Adam | epoch: 009 | loss: 0.52335 - acc: 0.7533 -- iter: 0448/3072
[A[ATraining Step: 783  | total loss: [1m[32m0.53789[0m[0m | time: 13.867s
[2K
| Adam | epoch: 009 | loss: 0.53789 - acc: 0.7373 -- iter: 0480/3072
[A[ATraining Step: 784  | total loss: [1m[32m0.53871[0m[0m | time: 14.678s
[2K
| Adam | epoch: 009 | loss: 0.53871 - acc: 0.7355 -- iter: 0512/3072
[A[ATraining Step: 785  | total loss: [1m[32m0.54418[0m[0m | time: 15.707s
[2K
| Adam | epoch: 009 | loss: 0.54418 - acc: 0.7369 -- iter: 0544/3072
[A[ATraining Step: 786  | total loss: [1m[32m0.53555[0m[0m | time: 16.751s
[2K
| Adam | epoch: 009 | loss: 0.53555 - acc: 0.7445 -- iter: 0576/3072
[A[ATraining Step: 787  | total loss: [1m[32m0.53316[0m[0m | time: 17.523s
[2K
| Adam | epoch: 009 | loss: 0.53316 - acc: 0.7482 -- iter: 0608/3072
[A[ATraining Step: 788  | total loss: [1m[32m0.52962[0m[0m | time: 18.409s
[2K
| Adam | epoch: 009 | loss: 0.52962 - acc: 0.7546 -- iter: 0640/3072
[A[ATraining Step: 789  | total loss: [1m[32m0.52819[0m[0m | time: 19.272s
[2K
| Adam | epoch: 009 | loss: 0.52819 - acc: 0.7541 -- iter: 0672/3072
[A[ATraining Step: 790  | total loss: [1m[32m0.53182[0m[0m | time: 20.194s
[2K
| Adam | epoch: 009 | loss: 0.53182 - acc: 0.7537 -- iter: 0704/3072
[A[ATraining Step: 791  | total loss: [1m[32m0.53242[0m[0m | time: 21.086s
[2K
| Adam | epoch: 009 | loss: 0.53242 - acc: 0.7440 -- iter: 0736/3072
[A[ATraining Step: 792  | total loss: [1m[32m0.52498[0m[0m | time: 22.056s
[2K
| Adam | epoch: 009 | loss: 0.52498 - acc: 0.7540 -- iter: 0768/3072
[A[ATraining Step: 793  | total loss: [1m[32m0.52299[0m[0m | time: 22.970s
[2K
| Adam | epoch: 009 | loss: 0.52299 - acc: 0.7504 -- iter: 0800/3072
[A[ATraining Step: 794  | total loss: [1m[32m0.52058[0m[0m | time: 23.948s
[2K
| Adam | epoch: 009 | loss: 0.52058 - acc: 0.7473 -- iter: 0832/3072
[A[ATraining Step: 795  | total loss: [1m[32m0.52765[0m[0m | time: 24.962s
[2K
| Adam | epoch: 009 | loss: 0.52765 - acc: 0.7382 -- iter: 0864/3072
[A[ATraining Step: 796  | total loss: [1m[32m0.53057[0m[0m | time: 25.912s
[2K
| Adam | epoch: 009 | loss: 0.53057 - acc: 0.7300 -- iter: 0896/3072
[A[ATraining Step: 797  | total loss: [1m[32m0.52411[0m[0m | time: 26.677s
[2K
| Adam | epoch: 009 | loss: 0.52411 - acc: 0.7382 -- iter: 0928/3072
[A[ATraining Step: 798  | total loss: [1m[32m0.52333[0m[0m | time: 27.598s
[2K
| Adam | epoch: 009 | loss: 0.52333 - acc: 0.7332 -- iter: 0960/3072
[A[ATraining Step: 799  | total loss: [1m[32m0.51547[0m[0m | time: 28.577s
[2K
| Adam | epoch: 009 | loss: 0.51547 - acc: 0.7442 -- iter: 0992/3072
[A[ATraining Step: 800  | total loss: [1m[32m0.52400[0m[0m | time: 34.151s
[2K
| Adam | epoch: 009 | loss: 0.52400 - acc: 0.7323 | val_loss: 0.55071 - val_acc: 0.7149 -- iter: 1024/3072
--
Training Step: 801  | total loss: [1m[32m0.52935[0m[0m | time: 35.175s
[2K
| Adam | epoch: 009 | loss: 0.52935 - acc: 0.7247 -- iter: 1056/3072
[A[ATraining Step: 802  | total loss: [1m[32m0.53009[0m[0m | time: 35.917s
[2K
| Adam | epoch: 009 | loss: 0.53009 - acc: 0.7241 -- iter: 1088/3072
[A[ATraining Step: 803  | total loss: [1m[32m0.52880[0m[0m | time: 36.921s
[2K
| Adam | epoch: 009 | loss: 0.52880 - acc: 0.7298 -- iter: 1120/3072
[A[ATraining Step: 804  | total loss: [1m[32m0.51516[0m[0m | time: 37.826s
[2K
| Adam | epoch: 009 | loss: 0.51516 - acc: 0.7443 -- iter: 1152/3072
[A[ATraining Step: 805  | total loss: [1m[32m0.52904[0m[0m | time: 38.776s
[2K
| Adam | epoch: 009 | loss: 0.52904 - acc: 0.7324 -- iter: 1184/3072
[A[ATraining Step: 806  | total loss: [1m[32m0.52885[0m[0m | time: 39.771s
[2K
| Adam | epoch: 009 | loss: 0.52885 - acc: 0.7342 -- iter: 1216/3072
[A[ATraining Step: 807  | total loss: [1m[32m0.52382[0m[0m | time: 40.838s
[2K
| Adam | epoch: 009 | loss: 0.52382 - acc: 0.7482 -- iter: 1248/3072
[A[ATraining Step: 808  | total loss: [1m[32m0.51693[0m[0m | time: 41.776s
[2K
| Adam | epoch: 009 | loss: 0.51693 - acc: 0.7515 -- iter: 1280/3072
[A[ATraining Step: 809  | total loss: [1m[32m0.51757[0m[0m | time: 42.801s
[2K
| Adam | epoch: 009 | loss: 0.51757 - acc: 0.7420 -- iter: 1312/3072
[A[ATraining Step: 810  | total loss: [1m[32m0.51222[0m[0m | time: 43.880s
[2K
| Adam | epoch: 009 | loss: 0.51222 - acc: 0.7459 -- iter: 1344/3072
[A[ATraining Step: 811  | total loss: [1m[32m0.51449[0m[0m | time: 44.888s
[2K
| Adam | epoch: 009 | loss: 0.51449 - acc: 0.7495 -- iter: 1376/3072
[A[ATraining Step: 812  | total loss: [1m[32m0.51576[0m[0m | time: 45.811s
[2K
| Adam | epoch: 009 | loss: 0.51576 - acc: 0.7464 -- iter: 1408/3072
[A[ATraining Step: 813  | total loss: [1m[32m0.50733[0m[0m | time: 46.767s
[2K
| Adam | epoch: 009 | loss: 0.50733 - acc: 0.7530 -- iter: 1440/3072
[A[ATraining Step: 814  | total loss: [1m[32m0.51266[0m[0m | time: 47.710s
[2K
| Adam | epoch: 009 | loss: 0.51266 - acc: 0.7496 -- iter: 1472/3072
[A[ATraining Step: 815  | total loss: [1m[32m0.50660[0m[0m | time: 48.636s
[2K
| Adam | epoch: 009 | loss: 0.50660 - acc: 0.7496 -- iter: 1504/3072
[A[ATraining Step: 816  | total loss: [1m[32m0.49868[0m[0m | time: 49.685s
[2K
| Adam | epoch: 009 | loss: 0.49868 - acc: 0.7559 -- iter: 1536/3072
[A[ATraining Step: 817  | total loss: [1m[32m0.49533[0m[0m | time: 50.704s
[2K
| Adam | epoch: 009 | loss: 0.49533 - acc: 0.7616 -- iter: 1568/3072
[A[ATraining Step: 818  | total loss: [1m[32m0.49031[0m[0m | time: 51.522s
[2K
| Adam | epoch: 009 | loss: 0.49031 - acc: 0.7698 -- iter: 1600/3072
[A[ATraining Step: 819  | total loss: [1m[32m0.49090[0m[0m | time: 52.706s
[2K
| Adam | epoch: 009 | loss: 0.49090 - acc: 0.7647 -- iter: 1632/3072
[A[ATraining Step: 820  | total loss: [1m[32m0.48562[0m[0m | time: 53.728s
[2K
| Adam | epoch: 009 | loss: 0.48562 - acc: 0.7632 -- iter: 1664/3072
[A[ATraining Step: 821  | total loss: [1m[32m0.48741[0m[0m | time: 54.628s
[2K
| Adam | epoch: 009 | loss: 0.48741 - acc: 0.7619 -- iter: 1696/3072
[A[ATraining Step: 822  | total loss: [1m[32m0.49279[0m[0m | time: 55.481s
[2K
| Adam | epoch: 009 | loss: 0.49279 - acc: 0.7638 -- iter: 1728/3072
[A[ATraining Step: 823  | total loss: [1m[32m0.50031[0m[0m | time: 56.349s
[2K
| Adam | epoch: 009 | loss: 0.50031 - acc: 0.7624 -- iter: 1760/3072
[A[ATraining Step: 824  | total loss: [1m[32m0.49287[0m[0m | time: 57.330s
[2K
| Adam | epoch: 009 | loss: 0.49287 - acc: 0.7675 -- iter: 1792/3072
[A[ATraining Step: 825  | total loss: [1m[32m0.50911[0m[0m | time: 58.284s
[2K
| Adam | epoch: 009 | loss: 0.50911 - acc: 0.7563 -- iter: 1824/3072
[A[ATraining Step: 826  | total loss: [1m[32m0.49309[0m[0m | time: 59.243s
[2K
| Adam | epoch: 009 | loss: 0.49309 - acc: 0.7651 -- iter: 1856/3072
[A[ATraining Step: 827  | total loss: [1m[32m0.49390[0m[0m | time: 60.124s
[2K
| Adam | epoch: 009 | loss: 0.49390 - acc: 0.7698 -- iter: 1888/3072
[A[ATraining Step: 828  | total loss: [1m[32m0.49036[0m[0m | time: 60.969s
[2K
| Adam | epoch: 009 | loss: 0.49036 - acc: 0.7710 -- iter: 1920/3072
[A[ATraining Step: 829  | total loss: [1m[32m0.50111[0m[0m | time: 62.055s
[2K
| Adam | epoch: 009 | loss: 0.50111 - acc: 0.7626 -- iter: 1952/3072
[A[ATraining Step: 830  | total loss: [1m[32m0.50683[0m[0m | time: 63.146s
[2K
| Adam | epoch: 009 | loss: 0.50683 - acc: 0.7676 -- iter: 1984/3072
[A[ATraining Step: 831  | total loss: [1m[32m0.51112[0m[0m | time: 64.033s
[2K
| Adam | epoch: 009 | loss: 0.51112 - acc: 0.7596 -- iter: 2016/3072
[A[ATraining Step: 832  | total loss: [1m[32m0.51039[0m[0m | time: 64.826s
[2K
| Adam | epoch: 009 | loss: 0.51039 - acc: 0.7555 -- iter: 2048/3072
[A[ATraining Step: 833  | total loss: [1m[32m0.51591[0m[0m | time: 65.747s
[2K
| Adam | epoch: 009 | loss: 0.51591 - acc: 0.7518 -- iter: 2080/3072
[A[ATraining Step: 834  | total loss: [1m[32m0.50633[0m[0m | time: 66.702s
[2K
| Adam | epoch: 009 | loss: 0.50633 - acc: 0.7579 -- iter: 2112/3072
[A[ATraining Step: 835  | total loss: [1m[32m0.52471[0m[0m | time: 67.612s
[2K
| Adam | epoch: 009 | loss: 0.52471 - acc: 0.7477 -- iter: 2144/3072
[A[ATraining Step: 836  | total loss: [1m[32m0.51910[0m[0m | time: 68.522s
[2K
| Adam | epoch: 009 | loss: 0.51910 - acc: 0.7511 -- iter: 2176/3072
[A[ATraining Step: 837  | total loss: [1m[32m0.51679[0m[0m | time: 69.440s
[2K
| Adam | epoch: 009 | loss: 0.51679 - acc: 0.7541 -- iter: 2208/3072
[A[ATraining Step: 838  | total loss: [1m[32m0.51485[0m[0m | time: 70.348s
[2K
| Adam | epoch: 009 | loss: 0.51485 - acc: 0.7599 -- iter: 2240/3072
[A[ATraining Step: 839  | total loss: [1m[32m0.52142[0m[0m | time: 71.154s
[2K
| Adam | epoch: 009 | loss: 0.52142 - acc: 0.7527 -- iter: 2272/3072
[A[ATraining Step: 840  | total loss: [1m[32m0.53113[0m[0m | time: 72.190s
[2K
| Adam | epoch: 009 | loss: 0.53113 - acc: 0.7431 -- iter: 2304/3072
[A[ATraining Step: 841  | total loss: [1m[32m0.52145[0m[0m | time: 73.169s
[2K
| Adam | epoch: 009 | loss: 0.52145 - acc: 0.7406 -- iter: 2336/3072
[A[ATraining Step: 842  | total loss: [1m[32m0.51246[0m[0m | time: 74.050s
[2K
| Adam | epoch: 009 | loss: 0.51246 - acc: 0.7384 -- iter: 2368/3072
[A[ATraining Step: 843  | total loss: [1m[32m0.51203[0m[0m | time: 74.860s
[2K
| Adam | epoch: 009 | loss: 0.51203 - acc: 0.7396 -- iter: 2400/3072
[A[ATraining Step: 844  | total loss: [1m[32m0.51726[0m[0m | time: 75.691s
[2K
| Adam | epoch: 009 | loss: 0.51726 - acc: 0.7406 -- iter: 2432/3072
[A[ATraining Step: 845  | total loss: [1m[32m0.50804[0m[0m | time: 76.600s
[2K
| Adam | epoch: 009 | loss: 0.50804 - acc: 0.7478 -- iter: 2464/3072
[A[ATraining Step: 846  | total loss: [1m[32m0.51680[0m[0m | time: 77.535s
[2K
| Adam | epoch: 009 | loss: 0.51680 - acc: 0.7480 -- iter: 2496/3072
[A[ATraining Step: 847  | total loss: [1m[32m0.51489[0m[0m | time: 78.450s
[2K
| Adam | epoch: 009 | loss: 0.51489 - acc: 0.7451 -- iter: 2528/3072
[A[ATraining Step: 848  | total loss: [1m[32m0.51490[0m[0m | time: 79.375s
[2K
| Adam | epoch: 009 | loss: 0.51490 - acc: 0.7487 -- iter: 2560/3072
[A[ATraining Step: 849  | total loss: [1m[32m0.50885[0m[0m | time: 80.318s
[2K
| Adam | epoch: 009 | loss: 0.50885 - acc: 0.7582 -- iter: 2592/3072
[A[ATraining Step: 850  | total loss: [1m[32m0.49913[0m[0m | time: 81.127s
[2K
| Adam | epoch: 009 | loss: 0.49913 - acc: 0.7637 -- iter: 2624/3072
[A[ATraining Step: 851  | total loss: [1m[32m0.49167[0m[0m | time: 82.209s
[2K
| Adam | epoch: 009 | loss: 0.49167 - acc: 0.7717 -- iter: 2656/3072
[A[ATraining Step: 852  | total loss: [1m[32m0.48516[0m[0m | time: 83.225s
[2K
| Adam | epoch: 009 | loss: 0.48516 - acc: 0.7757 -- iter: 2688/3072
[A[ATraining Step: 853  | total loss: [1m[32m0.47803[0m[0m | time: 84.051s
[2K
| Adam | epoch: 009 | loss: 0.47803 - acc: 0.7763 -- iter: 2720/3072
[A[ATraining Step: 854  | total loss: [1m[32m0.47601[0m[0m | time: 84.908s
[2K
| Adam | epoch: 009 | loss: 0.47601 - acc: 0.7799 -- iter: 2752/3072
[A[ATraining Step: 855  | total loss: [1m[32m0.48607[0m[0m | time: 85.949s
[2K
| Adam | epoch: 009 | loss: 0.48607 - acc: 0.7707 -- iter: 2784/3072
[A[ATraining Step: 856  | total loss: [1m[32m0.48055[0m[0m | time: 86.844s
[2K
| Adam | epoch: 009 | loss: 0.48055 - acc: 0.7686 -- iter: 2816/3072
[A[ATraining Step: 857  | total loss: [1m[32m0.47908[0m[0m | time: 87.739s
[2K
| Adam | epoch: 009 | loss: 0.47908 - acc: 0.7761 -- iter: 2848/3072
[A[ATraining Step: 858  | total loss: [1m[32m0.48273[0m[0m | time: 88.754s
[2K
| Adam | epoch: 009 | loss: 0.48273 - acc: 0.7735 -- iter: 2880/3072
[A[ATraining Step: 859  | total loss: [1m[32m0.49019[0m[0m | time: 89.757s
[2K
| Adam | epoch: 009 | loss: 0.49019 - acc: 0.7680 -- iter: 2912/3072
[A[ATraining Step: 860  | total loss: [1m[32m0.49398[0m[0m | time: 90.574s
[2K
| Adam | epoch: 009 | loss: 0.49398 - acc: 0.7662 -- iter: 2944/3072
[A[ATraining Step: 861  | total loss: [1m[32m0.49735[0m[0m | time: 91.604s
[2K
| Adam | epoch: 009 | loss: 0.49735 - acc: 0.7646 -- iter: 2976/3072
[A[ATraining Step: 862  | total loss: [1m[32m0.48599[0m[0m | time: 92.691s
[2K
| Adam | epoch: 009 | loss: 0.48599 - acc: 0.7725 -- iter: 3008/3072
[A[ATraining Step: 863  | total loss: [1m[32m0.50122[0m[0m | time: 93.530s
[2K
| Adam | epoch: 009 | loss: 0.50122 - acc: 0.7484 -- iter: 3040/3072
[A[ATraining Step: 864  | total loss: [1m[32m0.50416[0m[0m | time: 98.902s
[2K
| Adam | epoch: 009 | loss: 0.50416 - acc: 0.7423 | val_loss: 0.56512 - val_acc: 0.7055 -- iter: 3072/3072
--
Training Step: 865  | total loss: [1m[32m0.50216[0m[0m | time: 0.869s
[2K
| Adam | epoch: 010 | loss: 0.50216 - acc: 0.7493 -- iter: 0032/3072
[A[ATraining Step: 866  | total loss: [1m[32m0.49538[0m[0m | time: 1.820s
[2K
| Adam | epoch: 010 | loss: 0.49538 - acc: 0.7588 -- iter: 0064/3072
[A[ATraining Step: 867  | total loss: [1m[32m0.50829[0m[0m | time: 2.848s
[2K
| Adam | epoch: 010 | loss: 0.50829 - acc: 0.7516 -- iter: 0096/3072
[A[ATraining Step: 868  | total loss: [1m[32m0.51152[0m[0m | time: 3.881s
[2K
| Adam | epoch: 010 | loss: 0.51152 - acc: 0.7515 -- iter: 0128/3072
[A[ATraining Step: 869  | total loss: [1m[32m0.53136[0m[0m | time: 4.615s
[2K
| Adam | epoch: 010 | loss: 0.53136 - acc: 0.7388 -- iter: 0160/3072
[A[ATraining Step: 870  | total loss: [1m[32m0.52028[0m[0m | time: 5.521s
[2K
| Adam | epoch: 010 | loss: 0.52028 - acc: 0.7524 -- iter: 0192/3072
[A[ATraining Step: 871  | total loss: [1m[32m0.51792[0m[0m | time: 6.376s
[2K
| Adam | epoch: 010 | loss: 0.51792 - acc: 0.7553 -- iter: 0224/3072
[A[ATraining Step: 872  | total loss: [1m[32m0.52098[0m[0m | time: 7.249s
[2K
| Adam | epoch: 010 | loss: 0.52098 - acc: 0.7548 -- iter: 0256/3072
[A[ATraining Step: 873  | total loss: [1m[32m0.52573[0m[0m | time: 8.156s
[2K
| Adam | epoch: 010 | loss: 0.52573 - acc: 0.7481 -- iter: 0288/3072
[A[ATraining Step: 874  | total loss: [1m[32m0.52702[0m[0m | time: 9.138s
[2K
| Adam | epoch: 010 | loss: 0.52702 - acc: 0.7420 -- iter: 0320/3072
[A[ATraining Step: 875  | total loss: [1m[32m0.53439[0m[0m | time: 10.050s
[2K
| Adam | epoch: 010 | loss: 0.53439 - acc: 0.7428 -- iter: 0352/3072
[A[ATraining Step: 876  | total loss: [1m[32m0.52954[0m[0m | time: 10.897s
[2K
| Adam | epoch: 010 | loss: 0.52954 - acc: 0.7373 -- iter: 0384/3072
[A[ATraining Step: 877  | total loss: [1m[32m0.52829[0m[0m | time: 11.886s
[2K
| Adam | epoch: 010 | loss: 0.52829 - acc: 0.7385 -- iter: 0416/3072
[A[ATraining Step: 878  | total loss: [1m[32m0.53518[0m[0m | time: 12.939s
[2K
| Adam | epoch: 010 | loss: 0.53518 - acc: 0.7241 -- iter: 0448/3072
[A[ATraining Step: 879  | total loss: [1m[32m0.53142[0m[0m | time: 13.967s
[2K
| Adam | epoch: 010 | loss: 0.53142 - acc: 0.7267 -- iter: 0480/3072
[A[ATraining Step: 880  | total loss: [1m[32m0.52017[0m[0m | time: 14.690s
[2K
| Adam | epoch: 010 | loss: 0.52017 - acc: 0.7352 -- iter: 0512/3072
[A[ATraining Step: 881  | total loss: [1m[32m0.51779[0m[0m | time: 15.538s
[2K
| Adam | epoch: 010 | loss: 0.51779 - acc: 0.7398 -- iter: 0544/3072
[A[ATraining Step: 882  | total loss: [1m[32m0.52817[0m[0m | time: 16.388s
[2K
| Adam | epoch: 010 | loss: 0.52817 - acc: 0.7252 -- iter: 0576/3072
[A[ATraining Step: 883  | total loss: [1m[32m0.53973[0m[0m | time: 17.346s
[2K
| Adam | epoch: 010 | loss: 0.53973 - acc: 0.7152 -- iter: 0608/3072
[A[ATraining Step: 884  | total loss: [1m[32m0.52411[0m[0m | time: 18.201s
[2K
| Adam | epoch: 010 | loss: 0.52411 - acc: 0.7281 -- iter: 0640/3072
[A[ATraining Step: 885  | total loss: [1m[32m0.52349[0m[0m | time: 19.156s
[2K
| Adam | epoch: 010 | loss: 0.52349 - acc: 0.7303 -- iter: 0672/3072
[A[ATraining Step: 886  | total loss: [1m[32m0.52700[0m[0m | time: 20.150s
[2K
| Adam | epoch: 010 | loss: 0.52700 - acc: 0.7260 -- iter: 0704/3072
[A[ATraining Step: 887  | total loss: [1m[32m0.52897[0m[0m | time: 21.060s
[2K
| Adam | epoch: 010 | loss: 0.52897 - acc: 0.7284 -- iter: 0736/3072
[A[ATraining Step: 888  | total loss: [1m[32m0.52779[0m[0m | time: 22.150s
[2K
| Adam | epoch: 010 | loss: 0.52779 - acc: 0.7274 -- iter: 0768/3072
[A[ATraining Step: 889  | total loss: [1m[32m0.51192[0m[0m | time: 23.195s
[2K
| Adam | epoch: 010 | loss: 0.51192 - acc: 0.7359 -- iter: 0800/3072
[A[ATraining Step: 890  | total loss: [1m[32m0.51391[0m[0m | time: 24.164s
[2K
| Adam | epoch: 010 | loss: 0.51391 - acc: 0.7405 -- iter: 0832/3072
[A[ATraining Step: 891  | total loss: [1m[32m0.50224[0m[0m | time: 25.011s
[2K
| Adam | epoch: 010 | loss: 0.50224 - acc: 0.7477 -- iter: 0864/3072
[A[ATraining Step: 892  | total loss: [1m[32m0.50708[0m[0m | time: 25.884s
[2K
| Adam | epoch: 010 | loss: 0.50708 - acc: 0.7479 -- iter: 0896/3072
[A[ATraining Step: 893  | total loss: [1m[32m0.50064[0m[0m | time: 26.779s
[2K
| Adam | epoch: 010 | loss: 0.50064 - acc: 0.7481 -- iter: 0928/3072
[A[ATraining Step: 894  | total loss: [1m[32m0.49497[0m[0m | time: 27.664s
[2K
| Adam | epoch: 010 | loss: 0.49497 - acc: 0.7514 -- iter: 0960/3072
[A[ATraining Step: 895  | total loss: [1m[32m0.48891[0m[0m | time: 28.592s
[2K
| Adam | epoch: 010 | loss: 0.48891 - acc: 0.7544 -- iter: 0992/3072
[A[ATraining Step: 896  | total loss: [1m[32m0.49125[0m[0m | time: 29.644s
[2K
| Adam | epoch: 010 | loss: 0.49125 - acc: 0.7540 -- iter: 1024/3072
[A[ATraining Step: 897  | total loss: [1m[32m0.49470[0m[0m | time: 30.493s
[2K
| Adam | epoch: 010 | loss: 0.49470 - acc: 0.7567 -- iter: 1056/3072
[A[ATraining Step: 898  | total loss: [1m[32m0.49705[0m[0m | time: 31.416s
[2K
| Adam | epoch: 010 | loss: 0.49705 - acc: 0.7560 -- iter: 1088/3072
[A[ATraining Step: 899  | total loss: [1m[32m0.48633[0m[0m | time: 32.530s
[2K
| Adam | epoch: 010 | loss: 0.48633 - acc: 0.7585 -- iter: 1120/3072
[A[ATraining Step: 900  | total loss: [1m[32m0.48403[0m[0m | time: 33.626s
[2K
| Adam | epoch: 010 | loss: 0.48403 - acc: 0.7639 -- iter: 1152/3072
[A[ATraining Step: 901  | total loss: [1m[32m0.48217[0m[0m | time: 34.354s
[2K
| Adam | epoch: 010 | loss: 0.48217 - acc: 0.7657 -- iter: 1184/3072
[A[ATraining Step: 902  | total loss: [1m[32m0.47756[0m[0m | time: 35.246s
[2K
| Adam | epoch: 010 | loss: 0.47756 - acc: 0.7672 -- iter: 1216/3072
[A[ATraining Step: 903  | total loss: [1m[32m0.49085[0m[0m | time: 36.140s
[2K
| Adam | epoch: 010 | loss: 0.49085 - acc: 0.7499 -- iter: 1248/3072
[A[ATraining Step: 904  | total loss: [1m[32m0.49460[0m[0m | time: 37.094s
[2K
| Adam | epoch: 010 | loss: 0.49460 - acc: 0.7468 -- iter: 1280/3072
[A[ATraining Step: 905  | total loss: [1m[32m0.47702[0m[0m | time: 37.963s
[2K
| Adam | epoch: 010 | loss: 0.47702 - acc: 0.7627 -- iter: 1312/3072
[A[ATraining Step: 906  | total loss: [1m[32m0.48093[0m[0m | time: 38.894s
[2K
| Adam | epoch: 010 | loss: 0.48093 - acc: 0.7614 -- iter: 1344/3072
[A[ATraining Step: 907  | total loss: [1m[32m0.48314[0m[0m | time: 39.831s
[2K
| Adam | epoch: 010 | loss: 0.48314 - acc: 0.7666 -- iter: 1376/3072
[A[ATraining Step: 908  | total loss: [1m[32m0.48548[0m[0m | time: 40.651s
[2K
| Adam | epoch: 010 | loss: 0.48548 - acc: 0.7680 -- iter: 1408/3072
[A[ATraining Step: 909  | total loss: [1m[32m0.48625[0m[0m | time: 41.629s
[2K
| Adam | epoch: 010 | loss: 0.48625 - acc: 0.7662 -- iter: 1440/3072
[A[ATraining Step: 910  | total loss: [1m[32m0.48099[0m[0m | time: 42.705s
[2K
| Adam | epoch: 010 | loss: 0.48099 - acc: 0.7615 -- iter: 1472/3072
[A[ATraining Step: 911  | total loss: [1m[32m0.49136[0m[0m | time: 43.682s
[2K
| Adam | epoch: 010 | loss: 0.49136 - acc: 0.7509 -- iter: 1504/3072
[A[ATraining Step: 912  | total loss: [1m[32m0.48505[0m[0m | time: 44.463s
[2K
| Adam | epoch: 010 | loss: 0.48505 - acc: 0.7571 -- iter: 1536/3072
[A[ATraining Step: 913  | total loss: [1m[32m0.47852[0m[0m | time: 45.320s
[2K
| Adam | epoch: 010 | loss: 0.47852 - acc: 0.7658 -- iter: 1568/3072
[A[ATraining Step: 914  | total loss: [1m[32m0.46938[0m[0m | time: 46.303s
[2K
| Adam | epoch: 010 | loss: 0.46938 - acc: 0.7736 -- iter: 1600/3072
[A[ATraining Step: 915  | total loss: [1m[32m0.46394[0m[0m | time: 47.262s
[2K
| Adam | epoch: 010 | loss: 0.46394 - acc: 0.7775 -- iter: 1632/3072
[A[ATraining Step: 916  | total loss: [1m[32m0.45887[0m[0m | time: 48.220s
[2K
| Adam | epoch: 010 | loss: 0.45887 - acc: 0.7810 -- iter: 1664/3072
[A[ATraining Step: 917  | total loss: [1m[32m0.47971[0m[0m | time: 49.229s
[2K
| Adam | epoch: 010 | loss: 0.47971 - acc: 0.7747 -- iter: 1696/3072
[A[ATraining Step: 918  | total loss: [1m[32m0.46800[0m[0m | time: 50.132s
[2K
| Adam | epoch: 010 | loss: 0.46800 - acc: 0.7848 -- iter: 1728/3072
[A[ATraining Step: 919  | total loss: [1m[32m0.46260[0m[0m | time: 50.992s
[2K
| Adam | epoch: 010 | loss: 0.46260 - acc: 0.7907 -- iter: 1760/3072
[A[ATraining Step: 920  | total loss: [1m[32m0.45423[0m[0m | time: 51.994s
[2K
| Adam | epoch: 010 | loss: 0.45423 - acc: 0.8022 -- iter: 1792/3072
[A[ATraining Step: 921  | total loss: [1m[32m0.46035[0m[0m | time: 53.088s
[2K
| Adam | epoch: 010 | loss: 0.46035 - acc: 0.7939 -- iter: 1824/3072
[A[ATraining Step: 922  | total loss: [1m[32m0.47560[0m[0m | time: 53.852s
[2K
| Adam | epoch: 010 | loss: 0.47560 - acc: 0.7770 -- iter: 1856/3072
[A[ATraining Step: 923  | total loss: [1m[32m0.47289[0m[0m | time: 54.713s
[2K
| Adam | epoch: 010 | loss: 0.47289 - acc: 0.7805 -- iter: 1888/3072
[A[ATraining Step: 924  | total loss: [1m[32m0.46585[0m[0m | time: 55.612s
[2K
| Adam | epoch: 010 | loss: 0.46585 - acc: 0.7931 -- iter: 1920/3072
[A[ATraining Step: 925  | total loss: [1m[32m0.47847[0m[0m | time: 56.665s
[2K
| Adam | epoch: 010 | loss: 0.47847 - acc: 0.7763 -- iter: 1952/3072
[A[ATraining Step: 926  | total loss: [1m[32m0.48735[0m[0m | time: 57.598s
[2K
| Adam | epoch: 010 | loss: 0.48735 - acc: 0.7705 -- iter: 1984/3072
[A[ATraining Step: 927  | total loss: [1m[32m0.47739[0m[0m | time: 58.596s
[2K
| Adam | epoch: 010 | loss: 0.47739 - acc: 0.7716 -- iter: 2016/3072
[A[ATraining Step: 928  | total loss: [1m[32m0.48259[0m[0m | time: 59.547s
[2K
| Adam | epoch: 010 | loss: 0.48259 - acc: 0.7757 -- iter: 2048/3072
[A[ATraining Step: 929  | total loss: [1m[32m0.48144[0m[0m | time: 60.421s
[2K
| Adam | epoch: 010 | loss: 0.48144 - acc: 0.7825 -- iter: 2080/3072
[A[ATraining Step: 930  | total loss: [1m[32m0.46215[0m[0m | time: 61.455s
[2K
| Adam | epoch: 010 | loss: 0.46215 - acc: 0.7949 -- iter: 2112/3072
[A[ATraining Step: 931  | total loss: [1m[32m0.45539[0m[0m | time: 62.588s
[2K
| Adam | epoch: 010 | loss: 0.45539 - acc: 0.7998 -- iter: 2144/3072
[A[ATraining Step: 932  | total loss: [1m[32m0.47182[0m[0m | time: 63.388s
[2K
| Adam | epoch: 010 | loss: 0.47182 - acc: 0.7854 -- iter: 2176/3072
[A[ATraining Step: 933  | total loss: [1m[32m0.46990[0m[0m | time: 64.234s
[2K
| Adam | epoch: 010 | loss: 0.46990 - acc: 0.7881 -- iter: 2208/3072
[A[ATraining Step: 934  | total loss: [1m[32m0.46349[0m[0m | time: 65.242s
[2K
| Adam | epoch: 010 | loss: 0.46349 - acc: 0.7937 -- iter: 2240/3072
[A[ATraining Step: 935  | total loss: [1m[32m0.48487[0m[0m | time: 66.137s
[2K
| Adam | epoch: 010 | loss: 0.48487 - acc: 0.7737 -- iter: 2272/3072
[A[ATraining Step: 936  | total loss: [1m[32m0.48629[0m[0m | time: 67.058s
[2K
| Adam | epoch: 010 | loss: 0.48629 - acc: 0.7713 -- iter: 2304/3072
[A[ATraining Step: 937  | total loss: [1m[32m0.48759[0m[0m | time: 68.071s
[2K
| Adam | epoch: 010 | loss: 0.48759 - acc: 0.7723 -- iter: 2336/3072
[A[ATraining Step: 938  | total loss: [1m[32m0.48528[0m[0m | time: 69.030s
[2K
| Adam | epoch: 010 | loss: 0.48528 - acc: 0.7701 -- iter: 2368/3072
[A[ATraining Step: 939  | total loss: [1m[32m0.47746[0m[0m | time: 69.977s
[2K
| Adam | epoch: 010 | loss: 0.47746 - acc: 0.7775 -- iter: 2400/3072
[A[ATraining Step: 940  | total loss: [1m[32m0.48750[0m[0m | time: 71.089s
[2K
| Adam | epoch: 010 | loss: 0.48750 - acc: 0.7653 -- iter: 2432/3072
[A[ATraining Step: 941  | total loss: [1m[32m0.49164[0m[0m | time: 72.099s
[2K
| Adam | epoch: 010 | loss: 0.49164 - acc: 0.7607 -- iter: 2464/3072
[A[ATraining Step: 942  | total loss: [1m[32m0.49231[0m[0m | time: 72.886s
[2K
| Adam | epoch: 010 | loss: 0.49231 - acc: 0.7565 -- iter: 2496/3072
[A[ATraining Step: 943  | total loss: [1m[32m0.48472[0m[0m | time: 73.723s
[2K
| Adam | epoch: 010 | loss: 0.48472 - acc: 0.7652 -- iter: 2528/3072
[A[ATraining Step: 944  | total loss: [1m[32m0.48035[0m[0m | time: 74.650s
[2K
| Adam | epoch: 010 | loss: 0.48035 - acc: 0.7699 -- iter: 2560/3072
[A[ATraining Step: 945  | total loss: [1m[32m0.46136[0m[0m | time: 75.545s
[2K
| Adam | epoch: 010 | loss: 0.46136 - acc: 0.7836 -- iter: 2592/3072
[A[ATraining Step: 946  | total loss: [1m[32m0.46969[0m[0m | time: 76.533s
[2K
| Adam | epoch: 010 | loss: 0.46969 - acc: 0.7771 -- iter: 2624/3072
[A[ATraining Step: 947  | total loss: [1m[32m0.46578[0m[0m | time: 77.520s
[2K
| Adam | epoch: 010 | loss: 0.46578 - acc: 0.7838 -- iter: 2656/3072
[A[ATraining Step: 948  | total loss: [1m[32m0.45761[0m[0m | time: 78.446s
[2K
| Adam | epoch: 010 | loss: 0.45761 - acc: 0.7898 -- iter: 2688/3072
[A[ATraining Step: 949  | total loss: [1m[32m0.45226[0m[0m | time: 79.265s
[2K
| Adam | epoch: 010 | loss: 0.45226 - acc: 0.7952 -- iter: 2720/3072
[A[ATraining Step: 950  | total loss: [1m[32m0.45745[0m[0m | time: 80.376s
[2K
| Adam | epoch: 010 | loss: 0.45745 - acc: 0.7969 -- iter: 2752/3072
[A[ATraining Step: 951  | total loss: [1m[32m0.45204[0m[0m | time: 81.493s
[2K
| Adam | epoch: 010 | loss: 0.45204 - acc: 0.7953 -- iter: 2784/3072
[A[ATraining Step: 952  | total loss: [1m[32m0.45224[0m[0m | time: 82.332s
[2K
| Adam | epoch: 010 | loss: 0.45224 - acc: 0.7939 -- iter: 2816/3072
[A[ATraining Step: 953  | total loss: [1m[32m0.44431[0m[0m | time: 83.183s
[2K
| Adam | epoch: 010 | loss: 0.44431 - acc: 0.7864 -- iter: 2848/3072
[A[ATraining Step: 954  | total loss: [1m[32m0.44073[0m[0m | time: 84.101s
[2K
| Adam | epoch: 010 | loss: 0.44073 - acc: 0.7890 -- iter: 2880/3072
[A[ATraining Step: 955  | total loss: [1m[32m0.45202[0m[0m | time: 85.029s
[2K
| Adam | epoch: 010 | loss: 0.45202 - acc: 0.7914 -- iter: 2912/3072
[A[ATraining Step: 956  | total loss: [1m[32m0.44424[0m[0m | time: 85.948s
[2K
| Adam | epoch: 010 | loss: 0.44424 - acc: 0.7935 -- iter: 2944/3072
[A[ATraining Step: 957  | total loss: [1m[32m0.43564[0m[0m | time: 87.040s
[2K
| Adam | epoch: 010 | loss: 0.43564 - acc: 0.7985 -- iter: 2976/3072
[A[ATraining Step: 958  | total loss: [1m[32m0.44612[0m[0m | time: 88.035s
[2K
| Adam | epoch: 010 | loss: 0.44612 - acc: 0.7874 -- iter: 3008/3072
[A[ATraining Step: 959  | total loss: [1m[32m0.43020[0m[0m | time: 88.802s
[2K
| Adam | epoch: 010 | loss: 0.43020 - acc: 0.7993 -- iter: 3040/3072
[A[ATraining Step: 960  | total loss: [1m[32m0.43754[0m[0m | time: 94.327s
[2K
| Adam | epoch: 010 | loss: 0.43754 - acc: 0.7912 | val_loss: 0.56514 - val_acc: 0.7086 -- iter: 3072/3072
--
Training Step: 961  | total loss: [1m[32m0.44596[0m[0m | time: 0.914s
[2K
| Adam | epoch: 011 | loss: 0.44596 - acc: 0.7902 -- iter: 0032/3072
[A[ATraining Step: 962  | total loss: [1m[32m0.45509[0m[0m | time: 1.841s
[2K
| Adam | epoch: 011 | loss: 0.45509 - acc: 0.7862 -- iter: 0064/3072
[A[ATraining Step: 963  | total loss: [1m[32m0.45588[0m[0m | time: 2.774s
[2K
| Adam | epoch: 011 | loss: 0.45588 - acc: 0.7888 -- iter: 0096/3072
[A[ATraining Step: 964  | total loss: [1m[32m0.45004[0m[0m | time: 3.716s
[2K
| Adam | epoch: 011 | loss: 0.45004 - acc: 0.7881 -- iter: 0128/3072
[A[ATraining Step: 965  | total loss: [1m[32m0.44875[0m[0m | time: 4.636s
[2K
| Adam | epoch: 011 | loss: 0.44875 - acc: 0.7905 -- iter: 0160/3072
[A[ATraining Step: 966  | total loss: [1m[32m0.44642[0m[0m | time: 5.549s
[2K
| Adam | epoch: 011 | loss: 0.44642 - acc: 0.7927 -- iter: 0192/3072
[A[ATraining Step: 967  | total loss: [1m[32m0.43750[0m[0m | time: 6.567s
[2K
| Adam | epoch: 011 | loss: 0.43750 - acc: 0.8009 -- iter: 0224/3072
[A[ATraining Step: 968  | total loss: [1m[32m0.43494[0m[0m | time: 7.686s
[2K
| Adam | epoch: 011 | loss: 0.43494 - acc: 0.7990 -- iter: 0256/3072
[A[ATraining Step: 969  | total loss: [1m[32m0.44299[0m[0m | time: 8.484s
[2K
| Adam | epoch: 011 | loss: 0.44299 - acc: 0.7847 -- iter: 0288/3072
[A[ATraining Step: 970  | total loss: [1m[32m0.46828[0m[0m | time: 9.332s
[2K
| Adam | epoch: 011 | loss: 0.46828 - acc: 0.7750 -- iter: 0320/3072
[A[ATraining Step: 971  | total loss: [1m[32m0.48474[0m[0m | time: 10.251s
[2K
| Adam | epoch: 011 | loss: 0.48474 - acc: 0.7662 -- iter: 0352/3072
[A[ATraining Step: 972  | total loss: [1m[32m0.47947[0m[0m | time: 11.123s
[2K
| Adam | epoch: 011 | loss: 0.47947 - acc: 0.7740 -- iter: 0384/3072
[A[ATraining Step: 973  | total loss: [1m[32m0.48003[0m[0m | time: 11.959s
[2K
| Adam | epoch: 011 | loss: 0.48003 - acc: 0.7778 -- iter: 0416/3072
[A[ATraining Step: 974  | total loss: [1m[32m0.47749[0m[0m | time: 12.886s
[2K
| Adam | epoch: 011 | loss: 0.47749 - acc: 0.7751 -- iter: 0448/3072
[A[ATraining Step: 975  | total loss: [1m[32m0.46565[0m[0m | time: 13.832s
[2K
| Adam | epoch: 011 | loss: 0.46565 - acc: 0.7819 -- iter: 0480/3072
[A[ATraining Step: 976  | total loss: [1m[32m0.45675[0m[0m | time: 14.735s
[2K
| Adam | epoch: 011 | loss: 0.45675 - acc: 0.7912 -- iter: 0512/3072
[A[ATraining Step: 977  | total loss: [1m[32m0.44789[0m[0m | time: 15.721s
[2K
| Adam | epoch: 011 | loss: 0.44789 - acc: 0.7965 -- iter: 0544/3072
[A[ATraining Step: 978  | total loss: [1m[32m0.43645[0m[0m | time: 16.738s
[2K
| Adam | epoch: 011 | loss: 0.43645 - acc: 0.7981 -- iter: 0576/3072
[A[ATraining Step: 979  | total loss: [1m[32m0.43170[0m[0m | time: 17.672s
[2K
| Adam | epoch: 011 | loss: 0.43170 - acc: 0.8058 -- iter: 0608/3072
[A[ATraining Step: 980  | total loss: [1m[32m0.42225[0m[0m | time: 18.452s
[2K
| Adam | epoch: 011 | loss: 0.42225 - acc: 0.8158 -- iter: 0640/3072
[A[ATraining Step: 981  | total loss: [1m[32m0.42622[0m[0m | time: 19.342s
[2K
| Adam | epoch: 011 | loss: 0.42622 - acc: 0.8155 -- iter: 0672/3072
[A[ATraining Step: 982  | total loss: [1m[32m0.42190[0m[0m | time: 20.213s
[2K
| Adam | epoch: 011 | loss: 0.42190 - acc: 0.8214 -- iter: 0704/3072
[A[ATraining Step: 983  | total loss: [1m[32m0.42511[0m[0m | time: 21.218s
[2K
| Adam | epoch: 011 | loss: 0.42511 - acc: 0.8143 -- iter: 0736/3072
[A[ATraining Step: 984  | total loss: [1m[32m0.44216[0m[0m | time: 22.165s
[2K
| Adam | epoch: 011 | loss: 0.44216 - acc: 0.8016 -- iter: 0768/3072
[A[ATraining Step: 985  | total loss: [1m[32m0.43631[0m[0m | time: 23.168s
[2K
| Adam | epoch: 011 | loss: 0.43631 - acc: 0.7996 -- iter: 0800/3072
[A[ATraining Step: 986  | total loss: [1m[32m0.43084[0m[0m | time: 24.132s
[2K
| Adam | epoch: 011 | loss: 0.43084 - acc: 0.8040 -- iter: 0832/3072
[A[ATraining Step: 987  | total loss: [1m[32m0.42863[0m[0m | time: 25.025s
[2K
| Adam | epoch: 011 | loss: 0.42863 - acc: 0.7955 -- iter: 0864/3072
[A[ATraining Step: 988  | total loss: [1m[32m0.42842[0m[0m | time: 26.026s
[2K
| Adam | epoch: 011 | loss: 0.42842 - acc: 0.8003 -- iter: 0896/3072
[A[ATraining Step: 989  | total loss: [1m[32m0.42796[0m[0m | time: 27.133s
[2K
| Adam | epoch: 011 | loss: 0.42796 - acc: 0.7984 -- iter: 0928/3072
[A[ATraining Step: 990  | total loss: [1m[32m0.42798[0m[0m | time: 27.921s
[2K
| Adam | epoch: 011 | loss: 0.42798 - acc: 0.7967 -- iter: 0960/3072
[A[ATraining Step: 991  | total loss: [1m[32m0.44006[0m[0m | time: 28.786s
[2K
| Adam | epoch: 011 | loss: 0.44006 - acc: 0.7889 -- iter: 0992/3072
[A[ATraining Step: 992  | total loss: [1m[32m0.42576[0m[0m | time: 29.781s
[2K
| Adam | epoch: 011 | loss: 0.42576 - acc: 0.8006 -- iter: 1024/3072
[A[ATraining Step: 993  | total loss: [1m[32m0.42257[0m[0m | time: 30.647s
[2K
| Adam | epoch: 011 | loss: 0.42257 - acc: 0.7924 -- iter: 1056/3072
[A[ATraining Step: 994  | total loss: [1m[32m0.41368[0m[0m | time: 31.644s
[2K
| Adam | epoch: 011 | loss: 0.41368 - acc: 0.7976 -- iter: 1088/3072
[A[ATraining Step: 995  | total loss: [1m[32m0.40112[0m[0m | time: 32.592s
[2K
| Adam | epoch: 011 | loss: 0.40112 - acc: 0.8053 -- iter: 1120/3072
[A[ATraining Step: 996  | total loss: [1m[32m0.40868[0m[0m | time: 33.515s
[2K
| Adam | epoch: 011 | loss: 0.40868 - acc: 0.7998 -- iter: 1152/3072
[A[ATraining Step: 997  | total loss: [1m[32m0.40301[0m[0m | time: 34.321s
[2K
| Adam | epoch: 011 | loss: 0.40301 - acc: 0.8042 -- iter: 1184/3072
[A[ATraining Step: 998  | total loss: [1m[32m0.39446[0m[0m | time: 35.371s
[2K
| Adam | epoch: 011 | loss: 0.39446 - acc: 0.8144 -- iter: 1216/3072
[A[ATraining Step: 999  | total loss: [1m[32m0.40097[0m[0m | time: 36.436s
[2K
| Adam | epoch: 011 | loss: 0.40097 - acc: 0.8142 -- iter: 1248/3072
[A[ATraining Step: 1000  | total loss: [1m[32m0.41049[0m[0m | time: 41.640s
[2K
| Adam | epoch: 011 | loss: 0.41049 - acc: 0.8078 | val_loss: 0.51134 - val_acc: 0.7399 -- iter: 1280/3072
--
Training Step: 1001  | total loss: [1m[32m0.40541[0m[0m | time: 42.638s
[2K
| Adam | epoch: 011 | loss: 0.40541 - acc: 0.8114 -- iter: 1312/3072
[A[ATraining Step: 1002  | total loss: [1m[32m0.41407[0m[0m | time: 43.584s
[2K
| Adam | epoch: 011 | loss: 0.41407 - acc: 0.8084 -- iter: 1344/3072
[A[ATraining Step: 1003  | total loss: [1m[32m0.40666[0m[0m | time: 44.569s
[2K
| Adam | epoch: 011 | loss: 0.40666 - acc: 0.8182 -- iter: 1376/3072
[A[ATraining Step: 1004  | total loss: [1m[32m0.41294[0m[0m | time: 45.529s
[2K
| Adam | epoch: 011 | loss: 0.41294 - acc: 0.8082 -- iter: 1408/3072
[A[ATraining Step: 1005  | total loss: [1m[32m0.41997[0m[0m | time: 46.470s
[2K
| Adam | epoch: 011 | loss: 0.41997 - acc: 0.8055 -- iter: 1440/3072
[A[ATraining Step: 1006  | total loss: [1m[32m0.41480[0m[0m | time: 47.502s
[2K
| Adam | epoch: 011 | loss: 0.41480 - acc: 0.8031 -- iter: 1472/3072
[A[ATraining Step: 1007  | total loss: [1m[32m0.40291[0m[0m | time: 48.466s
[2K
| Adam | epoch: 011 | loss: 0.40291 - acc: 0.8165 -- iter: 1504/3072
[A[ATraining Step: 1008  | total loss: [1m[32m0.41154[0m[0m | time: 49.471s
[2K
| Adam | epoch: 011 | loss: 0.41154 - acc: 0.8130 -- iter: 1536/3072
[A[ATraining Step: 1009  | total loss: [1m[32m0.40792[0m[0m | time: 50.439s
[2K
| Adam | epoch: 011 | loss: 0.40792 - acc: 0.8098 -- iter: 1568/3072
[A[ATraining Step: 1010  | total loss: [1m[32m0.41421[0m[0m | time: 51.466s
[2K
| Adam | epoch: 011 | loss: 0.41421 - acc: 0.8007 -- iter: 1600/3072
[A[ATraining Step: 1011  | total loss: [1m[32m0.41958[0m[0m | time: 52.454s
[2K
| Adam | epoch: 011 | loss: 0.41958 - acc: 0.7988 -- iter: 1632/3072
[A[ATraining Step: 1012  | total loss: [1m[32m0.40996[0m[0m | time: 53.433s
[2K
| Adam | epoch: 011 | loss: 0.40996 - acc: 0.8126 -- iter: 1664/3072
[A[ATraining Step: 1013  | total loss: [1m[32m0.41991[0m[0m | time: 54.534s
[2K
| Adam | epoch: 011 | loss: 0.41991 - acc: 0.8095 -- iter: 1696/3072
[A[ATraining Step: 1014  | total loss: [1m[32m0.42851[0m[0m | time: 55.522s
[2K
| Adam | epoch: 011 | loss: 0.42851 - acc: 0.8067 -- iter: 1728/3072
[A[ATraining Step: 1015  | total loss: [1m[32m0.42940[0m[0m | time: 56.495s
[2K
| Adam | epoch: 011 | loss: 0.42940 - acc: 0.7979 -- iter: 1760/3072
[A[ATraining Step: 1016  | total loss: [1m[32m0.43624[0m[0m | time: 57.313s
[2K
| Adam | epoch: 011 | loss: 0.43624 - acc: 0.7868 -- iter: 1792/3072
[A[ATraining Step: 1017  | total loss: [1m[32m0.46083[0m[0m | time: 57.923s
[2K
| Adam | epoch: 011 | loss: 0.46083 - acc: 0.7675 -- iter: 1824/3072
[A[ATraining Step: 1018  | total loss: [1m[32m0.46212[0m[0m | time: 58.554s
[2K
| Adam | epoch: 011 | loss: 0.46212 - acc: 0.7658 -- iter: 1856/3072
[A[ATraining Step: 1019  | total loss: [1m[32m0.46392[0m[0m | time: 59.164s
[2K
| Adam | epoch: 011 | loss: 0.46392 - acc: 0.7517 -- iter: 1888/3072
[A[ATraining Step: 1020  | total loss: [1m[32m0.46384[0m[0m | time: 59.795s
[2K
| Adam | epoch: 011 | loss: 0.46384 - acc: 0.7515 -- iter: 1920/3072
[A[ATraining Step: 1021  | total loss: [1m[32m0.44833[0m[0m | time: 60.403s
[2K
| Adam | epoch: 011 | loss: 0.44833 - acc: 0.7670 -- iter: 1952/3072
[A[ATraining Step: 1022  | total loss: [1m[32m0.46847[0m[0m | time: 61.015s
[2K
| Adam | epoch: 011 | loss: 0.46847 - acc: 0.7559 -- iter: 1984/3072
[A[ATraining Step: 1023  | total loss: [1m[32m0.47275[0m[0m | time: 61.623s
[2K
| Adam | epoch: 011 | loss: 0.47275 - acc: 0.7522 -- iter: 2016/3072
[A[ATraining Step: 1024  | total loss: [1m[32m0.48085[0m[0m | time: 62.217s
[2K
| Adam | epoch: 011 | loss: 0.48085 - acc: 0.7520 -- iter: 2048/3072
[A[ATraining Step: 1025  | total loss: [1m[32m0.47276[0m[0m | time: 62.826s
[2K
| Adam | epoch: 011 | loss: 0.47276 - acc: 0.7549 -- iter: 2080/3072
[A[ATraining Step: 1026  | total loss: [1m[32m0.46204[0m[0m | time: 63.454s
[2K
| Adam | epoch: 011 | loss: 0.46204 - acc: 0.7607 -- iter: 2112/3072
[A[ATraining Step: 1027  | total loss: [1m[32m0.45142[0m[0m | time: 64.055s
[2K
| Adam | epoch: 011 | loss: 0.45142 - acc: 0.7690 -- iter: 2144/3072
[A[ATraining Step: 1028  | total loss: [1m[32m0.44838[0m[0m | time: 64.667s
[2K
| Adam | epoch: 011 | loss: 0.44838 - acc: 0.7765 -- iter: 2176/3072
[A[ATraining Step: 1029  | total loss: [1m[32m0.45352[0m[0m | time: 65.322s
[2K
| Adam | epoch: 011 | loss: 0.45352 - acc: 0.7707 -- iter: 2208/3072
[A[ATraining Step: 1030  | total loss: [1m[32m0.47190[0m[0m | time: 65.976s
[2K
| Adam | epoch: 011 | loss: 0.47190 - acc: 0.7655 -- iter: 2240/3072
[A[ATraining Step: 1031  | total loss: [1m[32m0.47405[0m[0m | time: 66.611s
[2K
| Adam | epoch: 011 | loss: 0.47405 - acc: 0.7733 -- iter: 2272/3072
[A[ATraining Step: 1032  | total loss: [1m[32m0.47912[0m[0m | time: 67.230s
[2K
| Adam | epoch: 011 | loss: 0.47912 - acc: 0.7741 -- iter: 2304/3072
[A[ATraining Step: 1033  | total loss: [1m[32m0.48260[0m[0m | time: 67.865s
[2K
| Adam | epoch: 011 | loss: 0.48260 - acc: 0.7686 -- iter: 2336/3072
[A[ATraining Step: 1034  | total loss: [1m[32m0.46579[0m[0m | time: 68.471s
[2K
| Adam | epoch: 011 | loss: 0.46579 - acc: 0.7823 -- iter: 2368/3072
[A[ATraining Step: 1035  | total loss: [1m[32m0.45294[0m[0m | time: 69.080s
[2K
| Adam | epoch: 011 | loss: 0.45294 - acc: 0.7916 -- iter: 2400/3072
[A[ATraining Step: 1036  | total loss: [1m[32m0.45381[0m[0m | time: 69.704s
[2K
| Adam | epoch: 011 | loss: 0.45381 - acc: 0.7906 -- iter: 2432/3072
[A[ATraining Step: 1037  | total loss: [1m[32m0.45863[0m[0m | time: 70.347s
[2K
| Adam | epoch: 011 | loss: 0.45863 - acc: 0.7803 -- iter: 2464/3072
[A[ATraining Step: 1038  | total loss: [1m[32m0.44922[0m[0m | time: 70.965s
[2K
| Adam | epoch: 011 | loss: 0.44922 - acc: 0.7835 -- iter: 2496/3072
[A[ATraining Step: 1039  | total loss: [1m[32m0.45366[0m[0m | time: 71.580s
[2K
| Adam | epoch: 011 | loss: 0.45366 - acc: 0.7833 -- iter: 2528/3072
[A[ATraining Step: 1040  | total loss: [1m[32m0.44551[0m[0m | time: 72.189s
[2K
| Adam | epoch: 011 | loss: 0.44551 - acc: 0.7924 -- iter: 2560/3072
[A[ATraining Step: 1041  | total loss: [1m[32m0.44072[0m[0m | time: 72.806s
[2K
| Adam | epoch: 011 | loss: 0.44072 - acc: 0.7913 -- iter: 2592/3072
[A[ATraining Step: 1042  | total loss: [1m[32m0.42943[0m[0m | time: 73.446s
[2K
| Adam | epoch: 011 | loss: 0.42943 - acc: 0.7997 -- iter: 2624/3072
[A[ATraining Step: 1043  | total loss: [1m[32m0.42246[0m[0m | time: 74.071s
[2K
| Adam | epoch: 011 | loss: 0.42246 - acc: 0.8072 -- iter: 2656/3072
[A[ATraining Step: 1044  | total loss: [1m[32m0.41094[0m[0m | time: 74.688s
[2K
| Adam | epoch: 011 | loss: 0.41094 - acc: 0.8140 -- iter: 2688/3072
[A[ATraining Step: 1045  | total loss: [1m[32m0.41043[0m[0m | time: 75.360s
[2K
| Adam | epoch: 011 | loss: 0.41043 - acc: 0.8138 -- iter: 2720/3072
[A[ATraining Step: 1046  | total loss: [1m[32m0.40273[0m[0m | time: 76.021s
[2K
| Adam | epoch: 011 | loss: 0.40273 - acc: 0.8168 -- iter: 2752/3072
[A[ATraining Step: 1047  | total loss: [1m[32m0.38759[0m[0m | time: 76.643s
[2K
| Adam | epoch: 011 | loss: 0.38759 - acc: 0.8289 -- iter: 2784/3072
[A[ATraining Step: 1048  | total loss: [1m[32m0.39299[0m[0m | time: 77.256s
[2K
| Adam | epoch: 011 | loss: 0.39299 - acc: 0.8273 -- iter: 2816/3072
[A[ATraining Step: 1049  | total loss: [1m[32m0.39322[0m[0m | time: 77.863s
[2K
| Adam | epoch: 011 | loss: 0.39322 - acc: 0.8320 -- iter: 2848/3072
[A[ATraining Step: 1050  | total loss: [1m[32m0.39283[0m[0m | time: 78.474s
[2K
| Adam | epoch: 011 | loss: 0.39283 - acc: 0.8332 -- iter: 2880/3072
[A[ATraining Step: 1051  | total loss: [1m[32m0.40029[0m[0m | time: 79.123s
[2K
| Adam | epoch: 011 | loss: 0.40029 - acc: 0.8343 -- iter: 2912/3072
[A[ATraining Step: 1052  | total loss: [1m[32m0.41188[0m[0m | time: 79.728s
[2K
| Adam | epoch: 011 | loss: 0.41188 - acc: 0.8227 -- iter: 2944/3072
[A[ATraining Step: 1053  | total loss: [1m[32m0.40682[0m[0m | time: 80.362s
[2K
| Adam | epoch: 011 | loss: 0.40682 - acc: 0.8248 -- iter: 2976/3072
[A[ATraining Step: 1054  | total loss: [1m[32m0.40638[0m[0m | time: 80.976s
[2K
| Adam | epoch: 011 | loss: 0.40638 - acc: 0.8173 -- iter: 3008/3072
[A[ATraining Step: 1055  | total loss: [1m[32m0.39860[0m[0m | time: 81.712s
[2K
| Adam | epoch: 011 | loss: 0.39860 - acc: 0.8200 -- iter: 3040/3072
[A[ATraining Step: 1056  | total loss: [1m[32m0.39511[0m[0m | time: 89.310s
[2K
| Adam | epoch: 011 | loss: 0.39511 - acc: 0.8161 | val_loss: 0.50076 - val_acc: 0.7617 -- iter: 3072/3072
--
Training Step: 1057  | total loss: [1m[32m0.39029[0m[0m | time: 1.268s
[2K
| Adam | epoch: 012 | loss: 0.39029 - acc: 0.8189 -- iter: 0032/3072
[A[ATraining Step: 1058  | total loss: [1m[32m0.38389[0m[0m | time: 2.550s
[2K
| Adam | epoch: 012 | loss: 0.38389 - acc: 0.8151 -- iter: 0064/3072
[A[ATraining Step: 1059  | total loss: [1m[32m0.37440[0m[0m | time: 3.666s
[2K
| Adam | epoch: 012 | loss: 0.37440 - acc: 0.8273 -- iter: 0096/3072
[A[ATraining Step: 1060  | total loss: [1m[32m0.37505[0m[0m | time: 4.946s
[2K
| Adam | epoch: 012 | loss: 0.37505 - acc: 0.8259 -- iter: 0128/3072
[A[ATraining Step: 1061  | total loss: [1m[32m0.37151[0m[0m | time: 6.356s
[2K
| Adam | epoch: 012 | loss: 0.37151 - acc: 0.8308 -- iter: 0160/3072
[A[ATraining Step: 1062  | total loss: [1m[32m0.37103[0m[0m | time: 7.534s
[2K
| Adam | epoch: 012 | loss: 0.37103 - acc: 0.8321 -- iter: 0192/3072
[A[ATraining Step: 1063  | total loss: [1m[32m0.36880[0m[0m | time: 8.626s
[2K
| Adam | epoch: 012 | loss: 0.36880 - acc: 0.8364 -- iter: 0224/3072
[A[ATraining Step: 1064  | total loss: [1m[32m0.37053[0m[0m | time: 9.871s
[2K
| Adam | epoch: 012 | loss: 0.37053 - acc: 0.8340 -- iter: 0256/3072
[A[ATraining Step: 1065  | total loss: [1m[32m0.37081[0m[0m | time: 11.057s
[2K
| Adam | epoch: 012 | loss: 0.37081 - acc: 0.8350 -- iter: 0288/3072
[A[ATraining Step: 1066  | total loss: [1m[32m0.38184[0m[0m | time: 12.214s
[2K
| Adam | epoch: 012 | loss: 0.38184 - acc: 0.8358 -- iter: 0320/3072
[A[ATraining Step: 1067  | total loss: [1m[32m0.38554[0m[0m | time: 13.451s
[2K
| Adam | epoch: 012 | loss: 0.38554 - acc: 0.8304 -- iter: 0352/3072
[A[ATraining Step: 1068  | total loss: [1m[32m0.38482[0m[0m | time: 14.578s
[2K
| Adam | epoch: 012 | loss: 0.38482 - acc: 0.8255 -- iter: 0384/3072
[A[ATraining Step: 1069  | total loss: [1m[32m0.38249[0m[0m | time: 15.783s
[2K
| Adam | epoch: 012 | loss: 0.38249 - acc: 0.8273 -- iter: 0416/3072
[A[ATraining Step: 1070  | total loss: [1m[32m0.38906[0m[0m | time: 16.852s
[2K
| Adam | epoch: 012 | loss: 0.38906 - acc: 0.8196 -- iter: 0448/3072
[A[ATraining Step: 1071  | total loss: [1m[32m0.38565[0m[0m | time: 17.473s
[2K
| Adam | epoch: 012 | loss: 0.38565 - acc: 0.8220 -- iter: 0480/3072
[A[ATraining Step: 1072  | total loss: [1m[32m0.39871[0m[0m | time: 18.076s
[2K
| Adam | epoch: 012 | loss: 0.39871 - acc: 0.8117 -- iter: 0512/3072
[A[ATraining Step: 1073  | total loss: [1m[32m0.41646[0m[0m | time: 18.732s
[2K
| Adam | epoch: 012 | loss: 0.41646 - acc: 0.8055 -- iter: 0544/3072
[A[ATraining Step: 1074  | total loss: [1m[32m0.42601[0m[0m | time: 19.353s
[2K
| Adam | epoch: 012 | loss: 0.42601 - acc: 0.7968 -- iter: 0576/3072
[A[ATraining Step: 1075  | total loss: [1m[32m0.40580[0m[0m | time: 19.965s
[2K
| Adam | epoch: 012 | loss: 0.40580 - acc: 0.8078 -- iter: 0608/3072
[A[ATraining Step: 1076  | total loss: [1m[32m0.40057[0m[0m | time: 20.614s
[2K
| Adam | epoch: 012 | loss: 0.40057 - acc: 0.8114 -- iter: 0640/3072
[A[ATraining Step: 1077  | total loss: [1m[32m0.39887[0m[0m | time: 21.249s
[2K
| Adam | epoch: 012 | loss: 0.39887 - acc: 0.8115 -- iter: 0672/3072
[A[ATraining Step: 1078  | total loss: [1m[32m0.38683[0m[0m | time: 21.861s
[2K
| Adam | epoch: 012 | loss: 0.38683 - acc: 0.8210 -- iter: 0704/3072
[A[ATraining Step: 1079  | total loss: [1m[32m0.38518[0m[0m | time: 22.469s
[2K
| Adam | epoch: 012 | loss: 0.38518 - acc: 0.8264 -- iter: 0736/3072
[A[ATraining Step: 1080  | total loss: [1m[32m0.40357[0m[0m | time: 23.065s
[2K
| Adam | epoch: 012 | loss: 0.40357 - acc: 0.8125 -- iter: 0768/3072
[A[ATraining Step: 1081  | total loss: [1m[32m0.40643[0m[0m | time: 23.694s
[2K
| Adam | epoch: 012 | loss: 0.40643 - acc: 0.8093 -- iter: 0800/3072
[A[ATraining Step: 1082  | total loss: [1m[32m0.39520[0m[0m | time: 24.305s
[2K
| Adam | epoch: 012 | loss: 0.39520 - acc: 0.8190 -- iter: 0832/3072
[A[ATraining Step: 1083  | total loss: [1m[32m0.39201[0m[0m | time: 24.943s
[2K
| Adam | epoch: 012 | loss: 0.39201 - acc: 0.8246 -- iter: 0864/3072
[A[ATraining Step: 1084  | total loss: [1m[32m0.41098[0m[0m | time: 25.543s
[2K
| Adam | epoch: 012 | loss: 0.41098 - acc: 0.8078 -- iter: 0896/3072
[A[ATraining Step: 1085  | total loss: [1m[32m0.40979[0m[0m | time: 26.164s
[2K
| Adam | epoch: 012 | loss: 0.40979 - acc: 0.8083 -- iter: 0928/3072
[A[ATraining Step: 1086  | total loss: [1m[32m0.41160[0m[0m | time: 26.794s
[2K
| Adam | epoch: 012 | loss: 0.41160 - acc: 0.8087 -- iter: 0960/3072
[A[ATraining Step: 1087  | total loss: [1m[32m0.41886[0m[0m | time: 27.437s
[2K
| Adam | epoch: 012 | loss: 0.41886 - acc: 0.7997 -- iter: 0992/3072
[A[ATraining Step: 1088  | total loss: [1m[32m0.41027[0m[0m | time: 28.081s
[2K
| Adam | epoch: 012 | loss: 0.41027 - acc: 0.8041 -- iter: 1024/3072
[A[ATraining Step: 1089  | total loss: [1m[32m0.41885[0m[0m | time: 28.728s
[2K
| Adam | epoch: 012 | loss: 0.41885 - acc: 0.7987 -- iter: 1056/3072
[A[ATraining Step: 1090  | total loss: [1m[32m0.41533[0m[0m | time: 29.346s
[2K
| Adam | epoch: 012 | loss: 0.41533 - acc: 0.8001 -- iter: 1088/3072
[A[ATraining Step: 1091  | total loss: [1m[32m0.41876[0m[0m | time: 29.958s
[2K
| Adam | epoch: 012 | loss: 0.41876 - acc: 0.7951 -- iter: 1120/3072
[A[ATraining Step: 1092  | total loss: [1m[32m0.40331[0m[0m | time: 30.557s
[2K
| Adam | epoch: 012 | loss: 0.40331 - acc: 0.8062 -- iter: 1152/3072
[A[ATraining Step: 1093  | total loss: [1m[32m0.40711[0m[0m | time: 31.199s
[2K
| Adam | epoch: 012 | loss: 0.40711 - acc: 0.8037 -- iter: 1184/3072
[A[ATraining Step: 1094  | total loss: [1m[32m0.40730[0m[0m | time: 31.802s
[2K
| Adam | epoch: 012 | loss: 0.40730 - acc: 0.8108 -- iter: 1216/3072
[A[ATraining Step: 1095  | total loss: [1m[32m0.40647[0m[0m | time: 32.426s
[2K
| Adam | epoch: 012 | loss: 0.40647 - acc: 0.8141 -- iter: 1248/3072
[A[ATraining Step: 1096  | total loss: [1m[32m0.39100[0m[0m | time: 33.050s
[2K
| Adam | epoch: 012 | loss: 0.39100 - acc: 0.8202 -- iter: 1280/3072
[A[ATraining Step: 1097  | total loss: [1m[32m0.39132[0m[0m | time: 33.668s
[2K
| Adam | epoch: 012 | loss: 0.39132 - acc: 0.8194 -- iter: 1312/3072
[A[ATraining Step: 1098  | total loss: [1m[32m0.37550[0m[0m | time: 34.272s
[2K
| Adam | epoch: 012 | loss: 0.37550 - acc: 0.8312 -- iter: 1344/3072
[A[ATraining Step: 1099  | total loss: [1m[32m0.37665[0m[0m | time: 34.894s
[2K
| Adam | epoch: 012 | loss: 0.37665 - acc: 0.8325 -- iter: 1376/3072
[A[ATraining Step: 1100  | total loss: [1m[32m0.38873[0m[0m | time: 35.563s
[2K
| Adam | epoch: 012 | loss: 0.38873 - acc: 0.8305 -- iter: 1408/3072
[A[ATraining Step: 1101  | total loss: [1m[32m0.39060[0m[0m | time: 36.182s
[2K
| Adam | epoch: 012 | loss: 0.39060 - acc: 0.8256 -- iter: 1440/3072
[A[ATraining Step: 1102  | total loss: [1m[32m0.38690[0m[0m | time: 36.805s
[2K
| Adam | epoch: 012 | loss: 0.38690 - acc: 0.8243 -- iter: 1472/3072
[A[ATraining Step: 1103  | total loss: [1m[32m0.38672[0m[0m | time: 37.472s
[2K
| Adam | epoch: 012 | loss: 0.38672 - acc: 0.8293 -- iter: 1504/3072
[A[ATraining Step: 1104  | total loss: [1m[32m0.37555[0m[0m | time: 38.082s
[2K
| Adam | epoch: 012 | loss: 0.37555 - acc: 0.8370 -- iter: 1536/3072
[A[ATraining Step: 1105  | total loss: [1m[32m0.37829[0m[0m | time: 38.697s
[2K
| Adam | epoch: 012 | loss: 0.37829 - acc: 0.8377 -- iter: 1568/3072
[A[ATraining Step: 1106  | total loss: [1m[32m0.37196[0m[0m | time: 39.329s
[2K
| Adam | epoch: 012 | loss: 0.37196 - acc: 0.8383 -- iter: 1600/3072
[A[ATraining Step: 1107  | total loss: [1m[32m0.36875[0m[0m | time: 39.976s
[2K
| Adam | epoch: 012 | loss: 0.36875 - acc: 0.8357 -- iter: 1632/3072
[A[ATraining Step: 1108  | total loss: [1m[32m0.37763[0m[0m | time: 40.630s
[2K
| Adam | epoch: 012 | loss: 0.37763 - acc: 0.8272 -- iter: 1664/3072
[A[ATraining Step: 1109  | total loss: [1m[32m0.38055[0m[0m | time: 41.283s
[2K
| Adam | epoch: 012 | loss: 0.38055 - acc: 0.8351 -- iter: 1696/3072
[A[ATraining Step: 1110  | total loss: [1m[32m0.39796[0m[0m | time: 41.972s
[2K
| Adam | epoch: 012 | loss: 0.39796 - acc: 0.8328 -- iter: 1728/3072
[A[ATraining Step: 1111  | total loss: [1m[32m0.39962[0m[0m | time: 42.581s
[2K
| Adam | epoch: 012 | loss: 0.39962 - acc: 0.8339 -- iter: 1760/3072
[A[ATraining Step: 1112  | total loss: [1m[32m0.38114[0m[0m | time: 43.181s
[2K
| Adam | epoch: 012 | loss: 0.38114 - acc: 0.8474 -- iter: 1792/3072
[A[ATraining Step: 1113  | total loss: [1m[32m0.38710[0m[0m | time: 43.876s
[2K
| Adam | epoch: 012 | loss: 0.38710 - acc: 0.8470 -- iter: 1824/3072
[A[ATraining Step: 1114  | total loss: [1m[32m0.39767[0m[0m | time: 44.480s
[2K
| Adam | epoch: 012 | loss: 0.39767 - acc: 0.8342 -- iter: 1856/3072
[A[ATraining Step: 1115  | total loss: [1m[32m0.39008[0m[0m | time: 45.128s
[2K
| Adam | epoch: 012 | loss: 0.39008 - acc: 0.8383 -- iter: 1888/3072
[A[ATraining Step: 1116  | total loss: [1m[32m0.39553[0m[0m | time: 45.737s
[2K
| Adam | epoch: 012 | loss: 0.39553 - acc: 0.8357 -- iter: 1920/3072
[A[ATraining Step: 1117  | total loss: [1m[32m0.38481[0m[0m | time: 46.383s
[2K
| Adam | epoch: 012 | loss: 0.38481 - acc: 0.8396 -- iter: 1952/3072
[A[ATraining Step: 1118  | total loss: [1m[32m0.37848[0m[0m | time: 46.994s
[2K
| Adam | epoch: 012 | loss: 0.37848 - acc: 0.8432 -- iter: 1984/3072
[A[ATraining Step: 1119  | total loss: [1m[32m0.39239[0m[0m | time: 47.602s
[2K
| Adam | epoch: 012 | loss: 0.39239 - acc: 0.8370 -- iter: 2016/3072
[A[ATraining Step: 1120  | total loss: [1m[32m0.39610[0m[0m | time: 48.216s
[2K
| Adam | epoch: 012 | loss: 0.39610 - acc: 0.8377 -- iter: 2048/3072
[A[ATraining Step: 1121  | total loss: [1m[32m0.39345[0m[0m | time: 48.844s
[2K
| Adam | epoch: 012 | loss: 0.39345 - acc: 0.8351 -- iter: 2080/3072
[A[ATraining Step: 1122  | total loss: [1m[32m0.40933[0m[0m | time: 49.437s
[2K
| Adam | epoch: 012 | loss: 0.40933 - acc: 0.8266 -- iter: 2112/3072
[A[ATraining Step: 1123  | total loss: [1m[32m0.39052[0m[0m | time: 50.035s
[2K
| Adam | epoch: 012 | loss: 0.39052 - acc: 0.8377 -- iter: 2144/3072
[A[ATraining Step: 1124  | total loss: [1m[32m0.37452[0m[0m | time: 50.650s
[2K
| Adam | epoch: 012 | loss: 0.37452 - acc: 0.8508 -- iter: 2176/3072
[A[ATraining Step: 1125  | total loss: [1m[32m0.38636[0m[0m | time: 51.259s
[2K
| Adam | epoch: 012 | loss: 0.38636 - acc: 0.8439 -- iter: 2208/3072
[A[ATraining Step: 1126  | total loss: [1m[32m0.38899[0m[0m | time: 51.871s
[2K
| Adam | epoch: 012 | loss: 0.38899 - acc: 0.8470 -- iter: 2240/3072
[A[ATraining Step: 1127  | total loss: [1m[32m0.38284[0m[0m | time: 52.469s
[2K
| Adam | epoch: 012 | loss: 0.38284 - acc: 0.8466 -- iter: 2272/3072
[A[ATraining Step: 1128  | total loss: [1m[32m0.38917[0m[0m | time: 53.118s
[2K
| Adam | epoch: 012 | loss: 0.38917 - acc: 0.8370 -- iter: 2304/3072
[A[ATraining Step: 1129  | total loss: [1m[32m0.39080[0m[0m | time: 53.768s
[2K
| Adam | epoch: 012 | loss: 0.39080 - acc: 0.8377 -- iter: 2336/3072
[A[ATraining Step: 1130  | total loss: [1m[32m0.39762[0m[0m | time: 54.400s
[2K
| Adam | epoch: 012 | loss: 0.39762 - acc: 0.8320 -- iter: 2368/3072
[A[ATraining Step: 1131  | total loss: [1m[32m0.41982[0m[0m | time: 54.995s
[2K
| Adam | epoch: 012 | loss: 0.41982 - acc: 0.8176 -- iter: 2400/3072
[A[ATraining Step: 1132  | total loss: [1m[32m0.42235[0m[0m | time: 55.599s
[2K
| Adam | epoch: 012 | loss: 0.42235 - acc: 0.8202 -- iter: 2432/3072
[A[ATraining Step: 1133  | total loss: [1m[32m0.42250[0m[0m | time: 56.217s
[2K
| Adam | epoch: 012 | loss: 0.42250 - acc: 0.8163 -- iter: 2464/3072
[A[ATraining Step: 1134  | total loss: [1m[32m0.41134[0m[0m | time: 56.828s
[2K
| Adam | epoch: 012 | loss: 0.41134 - acc: 0.8284 -- iter: 2496/3072
[A[ATraining Step: 1135  | total loss: [1m[32m0.40380[0m[0m | time: 57.433s
[2K
| Adam | epoch: 012 | loss: 0.40380 - acc: 0.8331 -- iter: 2528/3072
[A[ATraining Step: 1136  | total loss: [1m[32m0.38547[0m[0m | time: 58.134s
[2K
| Adam | epoch: 012 | loss: 0.38547 - acc: 0.8435 -- iter: 2560/3072
[A[ATraining Step: 1137  | total loss: [1m[32m0.38725[0m[0m | time: 58.736s
[2K
| Adam | epoch: 012 | loss: 0.38725 - acc: 0.8373 -- iter: 2592/3072
[A[ATraining Step: 1138  | total loss: [1m[32m0.39290[0m[0m | time: 59.343s
[2K
| Adam | epoch: 012 | loss: 0.39290 - acc: 0.8317 -- iter: 2624/3072
[A[ATraining Step: 1139  | total loss: [1m[32m0.37651[0m[0m | time: 59.948s
[2K
| Adam | epoch: 012 | loss: 0.37651 - acc: 0.8454 -- iter: 2656/3072
[A[ATraining Step: 1140  | total loss: [1m[32m0.36291[0m[0m | time: 60.541s
[2K
| Adam | epoch: 012 | loss: 0.36291 - acc: 0.8484 -- iter: 2688/3072
[A[ATraining Step: 1141  | total loss: [1m[32m0.36919[0m[0m | time: 61.198s
[2K
| Adam | epoch: 012 | loss: 0.36919 - acc: 0.8448 -- iter: 2720/3072
[A[ATraining Step: 1142  | total loss: [1m[32m0.35565[0m[0m | time: 61.803s
[2K
| Adam | epoch: 012 | loss: 0.35565 - acc: 0.8540 -- iter: 2752/3072
[A[ATraining Step: 1143  | total loss: [1m[32m0.34486[0m[0m | time: 62.404s
[2K
| Adam | epoch: 012 | loss: 0.34486 - acc: 0.8624 -- iter: 2784/3072
[A[ATraining Step: 1144  | total loss: [1m[32m0.35033[0m[0m | time: 63.018s
[2K
| Adam | epoch: 012 | loss: 0.35033 - acc: 0.8574 -- iter: 2816/3072
[A[ATraining Step: 1145  | total loss: [1m[32m0.34382[0m[0m | time: 63.650s
[2K
| Adam | epoch: 012 | loss: 0.34382 - acc: 0.8592 -- iter: 2848/3072
[A[ATraining Step: 1146  | total loss: [1m[32m0.33871[0m[0m | time: 64.327s
[2K
| Adam | epoch: 012 | loss: 0.33871 - acc: 0.8607 -- iter: 2880/3072
[A[ATraining Step: 1147  | total loss: [1m[32m0.34986[0m[0m | time: 64.939s
[2K
| Adam | epoch: 012 | loss: 0.34986 - acc: 0.8528 -- iter: 2912/3072
[A[ATraining Step: 1148  | total loss: [1m[32m0.34429[0m[0m | time: 65.551s
[2K
| Adam | epoch: 012 | loss: 0.34429 - acc: 0.8550 -- iter: 2944/3072
[A[ATraining Step: 1149  | total loss: [1m[32m0.33774[0m[0m | time: 66.153s
[2K
| Adam | epoch: 012 | loss: 0.33774 - acc: 0.8539 -- iter: 2976/3072
[A[ATraining Step: 1150  | total loss: [1m[32m0.33808[0m[0m | time: 66.846s
[2K
| Adam | epoch: 012 | loss: 0.33808 - acc: 0.8529 -- iter: 3008/3072
[A[ATraining Step: 1151  | total loss: [1m[32m0.33617[0m[0m | time: 67.453s
[2K
| Adam | epoch: 012 | loss: 0.33617 - acc: 0.8551 -- iter: 3040/3072
[A[ATraining Step: 1152  | total loss: [1m[32m0.32536[0m[0m | time: 71.232s
[2K
| Adam | epoch: 012 | loss: 0.32536 - acc: 0.8665 | val_loss: 0.60610 - val_acc: 0.7222 -- iter: 3072/3072
--
Training Step: 1153  | total loss: [1m[32m0.31841[0m[0m | time: 0.615s
[2K
| Adam | epoch: 013 | loss: 0.31841 - acc: 0.8673 -- iter: 0032/3072
[A[ATraining Step: 1154  | total loss: [1m[32m0.31499[0m[0m | time: 1.255s
[2K
| Adam | epoch: 013 | loss: 0.31499 - acc: 0.8712 -- iter: 0064/3072
[A[ATraining Step: 1155  | total loss: [1m[32m0.31709[0m[0m | time: 1.873s
[2K
| Adam | epoch: 013 | loss: 0.31709 - acc: 0.8716 -- iter: 0096/3072
[A[ATraining Step: 1156  | total loss: [1m[32m0.32323[0m[0m | time: 2.479s
[2K
| Adam | epoch: 013 | loss: 0.32323 - acc: 0.8688 -- iter: 0128/3072
[A[ATraining Step: 1157  | total loss: [1m[32m0.31406[0m[0m | time: 3.081s
[2K
| Adam | epoch: 013 | loss: 0.31406 - acc: 0.8694 -- iter: 0160/3072
[A[ATraining Step: 1158  | total loss: [1m[32m0.31608[0m[0m | time: 3.692s
[2K
| Adam | epoch: 013 | loss: 0.31608 - acc: 0.8731 -- iter: 0192/3072
[A[ATraining Step: 1159  | total loss: [1m[32m0.31324[0m[0m | time: 4.285s
[2K
| Adam | epoch: 013 | loss: 0.31324 - acc: 0.8764 -- iter: 0224/3072
[A[ATraining Step: 1160  | total loss: [1m[32m0.33346[0m[0m | time: 4.883s
[2K
| Adam | epoch: 013 | loss: 0.33346 - acc: 0.8700 -- iter: 0256/3072
[A[ATraining Step: 1161  | total loss: [1m[32m0.35101[0m[0m | time: 5.488s
[2K
| Adam | epoch: 013 | loss: 0.35101 - acc: 0.8580 -- iter: 0288/3072
[A[ATraining Step: 1162  | total loss: [1m[32m0.34410[0m[0m | time: 6.104s
[2K
| Adam | epoch: 013 | loss: 0.34410 - acc: 0.8628 -- iter: 0320/3072
[A[ATraining Step: 1163  | total loss: [1m[32m0.34619[0m[0m | time: 6.710s
[2K
| Adam | epoch: 013 | loss: 0.34619 - acc: 0.8609 -- iter: 0352/3072
[A[ATraining Step: 1164  | total loss: [1m[32m0.34950[0m[0m | time: 7.313s
[2K
| Adam | epoch: 013 | loss: 0.34950 - acc: 0.8592 -- iter: 0384/3072
[A[ATraining Step: 1165  | total loss: [1m[32m0.34945[0m[0m | time: 7.956s
[2K
| Adam | epoch: 013 | loss: 0.34945 - acc: 0.8545 -- iter: 0416/3072
[A[ATraining Step: 1166  | total loss: [1m[32m0.34896[0m[0m | time: 8.545s
[2K
| Adam | epoch: 013 | loss: 0.34896 - acc: 0.8503 -- iter: 0448/3072
[A[ATraining Step: 1167  | total loss: [1m[32m0.35276[0m[0m | time: 9.146s
[2K
| Adam | epoch: 013 | loss: 0.35276 - acc: 0.8466 -- iter: 0480/3072
[A[ATraining Step: 1168  | total loss: [1m[32m0.35975[0m[0m | time: 9.761s
[2K
| Adam | epoch: 013 | loss: 0.35975 - acc: 0.8463 -- iter: 0512/3072
[A[ATraining Step: 1169  | total loss: [1m[32m0.38245[0m[0m | time: 10.386s
[2K
| Adam | epoch: 013 | loss: 0.38245 - acc: 0.8366 -- iter: 0544/3072
[A[ATraining Step: 1170  | total loss: [1m[32m0.36286[0m[0m | time: 11.001s
[2K
| Adam | epoch: 013 | loss: 0.36286 - acc: 0.8499 -- iter: 0576/3072
[A[ATraining Step: 1171  | total loss: [1m[32m0.38092[0m[0m | time: 11.609s
[2K
| Adam | epoch: 013 | loss: 0.38092 - acc: 0.8430 -- iter: 0608/3072
[A[ATraining Step: 1172  | total loss: [1m[32m0.39312[0m[0m | time: 12.204s
[2K
| Adam | epoch: 013 | loss: 0.39312 - acc: 0.8337 -- iter: 0640/3072
[A[ATraining Step: 1173  | total loss: [1m[32m0.39015[0m[0m | time: 12.794s
[2K
| Adam | epoch: 013 | loss: 0.39015 - acc: 0.8285 -- iter: 0672/3072
[A[ATraining Step: 1174  | total loss: [1m[32m0.40546[0m[0m | time: 13.409s
[2K
| Adam | epoch: 013 | loss: 0.40546 - acc: 0.8206 -- iter: 0704/3072
[A[ATraining Step: 1175  | total loss: [1m[32m0.39506[0m[0m | time: 14.050s
[2K
| Adam | epoch: 013 | loss: 0.39506 - acc: 0.8260 -- iter: 0736/3072
[A[ATraining Step: 1176  | total loss: [1m[32m0.38992[0m[0m | time: 14.669s
[2K
| Adam | epoch: 013 | loss: 0.38992 - acc: 0.8341 -- iter: 0768/3072
[A[ATraining Step: 1177  | total loss: [1m[32m0.41117[0m[0m | time: 15.270s
[2K
| Adam | epoch: 013 | loss: 0.41117 - acc: 0.8257 -- iter: 0800/3072
[A[ATraining Step: 1178  | total loss: [1m[32m0.43056[0m[0m | time: 15.868s
[2K
| Adam | epoch: 013 | loss: 0.43056 - acc: 0.8181 -- iter: 0832/3072
[A[ATraining Step: 1179  | total loss: [1m[32m0.41812[0m[0m | time: 16.506s
[2K
| Adam | epoch: 013 | loss: 0.41812 - acc: 0.8238 -- iter: 0864/3072
[A[ATraining Step: 1180  | total loss: [1m[32m0.39685[0m[0m | time: 17.129s
[2K
| Adam | epoch: 013 | loss: 0.39685 - acc: 0.8383 -- iter: 0896/3072
[A[ATraining Step: 1181  | total loss: [1m[32m0.39988[0m[0m | time: 17.758s
[2K
| Adam | epoch: 013 | loss: 0.39988 - acc: 0.8420 -- iter: 0928/3072
[A[ATraining Step: 1182  | total loss: [1m[32m0.39239[0m[0m | time: 18.357s
[2K
| Adam | epoch: 013 | loss: 0.39239 - acc: 0.8484 -- iter: 0960/3072
[A[ATraining Step: 1183  | total loss: [1m[32m0.40510[0m[0m | time: 18.980s
[2K
| Adam | epoch: 013 | loss: 0.40510 - acc: 0.8385 -- iter: 0992/3072
[A[ATraining Step: 1184  | total loss: [1m[32m0.39978[0m[0m | time: 19.577s
[2K
| Adam | epoch: 013 | loss: 0.39978 - acc: 0.8391 -- iter: 1024/3072
[A[ATraining Step: 1185  | total loss: [1m[32m0.40344[0m[0m | time: 20.185s
[2K
| Adam | epoch: 013 | loss: 0.40344 - acc: 0.8395 -- iter: 1056/3072
[A[ATraining Step: 1186  | total loss: [1m[32m0.39905[0m[0m | time: 20.794s
[2K
| Adam | epoch: 013 | loss: 0.39905 - acc: 0.8462 -- iter: 1088/3072
[A[ATraining Step: 1187  | total loss: [1m[32m0.39706[0m[0m | time: 21.406s
[2K
| Adam | epoch: 013 | loss: 0.39706 - acc: 0.8428 -- iter: 1120/3072
[A[ATraining Step: 1188  | total loss: [1m[32m0.42373[0m[0m | time: 22.035s
[2K
| Adam | epoch: 013 | loss: 0.42373 - acc: 0.8304 -- iter: 1152/3072
[A[ATraining Step: 1189  | total loss: [1m[32m0.39984[0m[0m | time: 22.639s
[2K
| Adam | epoch: 013 | loss: 0.39984 - acc: 0.8411 -- iter: 1184/3072
[A[ATraining Step: 1190  | total loss: [1m[32m0.38754[0m[0m | time: 23.244s
[2K
| Adam | epoch: 013 | loss: 0.38754 - acc: 0.8445 -- iter: 1216/3072
[A[ATraining Step: 1191  | total loss: [1m[32m0.38510[0m[0m | time: 23.851s
[2K
| Adam | epoch: 013 | loss: 0.38510 - acc: 0.8382 -- iter: 1248/3072
[A[ATraining Step: 1192  | total loss: [1m[32m0.38760[0m[0m | time: 24.446s
[2K
| Adam | epoch: 013 | loss: 0.38760 - acc: 0.8419 -- iter: 1280/3072
[A[ATraining Step: 1193  | total loss: [1m[32m0.38195[0m[0m | time: 25.072s
[2K
| Adam | epoch: 013 | loss: 0.38195 - acc: 0.8421 -- iter: 1312/3072
[A[ATraining Step: 1194  | total loss: [1m[32m0.38678[0m[0m | time: 25.683s
[2K
| Adam | epoch: 013 | loss: 0.38678 - acc: 0.8329 -- iter: 1344/3072
[A[ATraining Step: 1195  | total loss: [1m[32m0.39577[0m[0m | time: 26.283s
[2K
| Adam | epoch: 013 | loss: 0.39577 - acc: 0.8214 -- iter: 1376/3072
[A[ATraining Step: 1196  | total loss: [1m[32m0.39559[0m[0m | time: 26.883s
[2K
| Adam | epoch: 013 | loss: 0.39559 - acc: 0.8268 -- iter: 1408/3072
[A[ATraining Step: 1197  | total loss: [1m[32m0.38209[0m[0m | time: 27.490s
[2K
| Adam | epoch: 013 | loss: 0.38209 - acc: 0.8347 -- iter: 1440/3072
[A[ATraining Step: 1198  | total loss: [1m[32m0.38022[0m[0m | time: 28.106s
[2K
| Adam | epoch: 013 | loss: 0.38022 - acc: 0.8325 -- iter: 1472/3072
[A[ATraining Step: 1199  | total loss: [1m[32m0.40936[0m[0m | time: 28.752s
[2K
| Adam | epoch: 013 | loss: 0.40936 - acc: 0.8211 -- iter: 1504/3072
[A[ATraining Step: 1200  | total loss: [1m[32m0.41366[0m[0m | time: 32.373s
[2K
| Adam | epoch: 013 | loss: 0.41366 - acc: 0.8203 | val_loss: 0.52276 - val_acc: 0.7430 -- iter: 1536/3072
--
Training Step: 1201  | total loss: [1m[32m0.40392[0m[0m | time: 32.992s
[2K
| Adam | epoch: 013 | loss: 0.40392 - acc: 0.8258 -- iter: 1568/3072
[A[ATraining Step: 1202  | total loss: [1m[32m0.40928[0m[0m | time: 33.595s
[2K
| Adam | epoch: 013 | loss: 0.40928 - acc: 0.8276 -- iter: 1600/3072
[A[ATraining Step: 1203  | total loss: [1m[32m0.42407[0m[0m | time: 34.209s
[2K
| Adam | epoch: 013 | loss: 0.42407 - acc: 0.8135 -- iter: 1632/3072
[A[ATraining Step: 1204  | total loss: [1m[32m0.42158[0m[0m | time: 34.814s
[2K
| Adam | epoch: 013 | loss: 0.42158 - acc: 0.8228 -- iter: 1664/3072
[A[ATraining Step: 1205  | total loss: [1m[32m0.43147[0m[0m | time: 35.458s
[2K
| Adam | epoch: 013 | loss: 0.43147 - acc: 0.8155 -- iter: 1696/3072
[A[ATraining Step: 1206  | total loss: [1m[32m0.42897[0m[0m | time: 36.062s
[2K
| Adam | epoch: 013 | loss: 0.42897 - acc: 0.8152 -- iter: 1728/3072
[A[ATraining Step: 1207  | total loss: [1m[32m0.43718[0m[0m | time: 36.665s
[2K
| Adam | epoch: 013 | loss: 0.43718 - acc: 0.8087 -- iter: 1760/3072
[A[ATraining Step: 1208  | total loss: [1m[32m0.41929[0m[0m | time: 37.263s
[2K
| Adam | epoch: 013 | loss: 0.41929 - acc: 0.8216 -- iter: 1792/3072
[A[ATraining Step: 1209  | total loss: [1m[32m0.41422[0m[0m | time: 37.884s
[2K
| Adam | epoch: 013 | loss: 0.41422 - acc: 0.8207 -- iter: 1824/3072
[A[ATraining Step: 1210  | total loss: [1m[32m0.41312[0m[0m | time: 38.488s
[2K
| Adam | epoch: 013 | loss: 0.41312 - acc: 0.8167 -- iter: 1856/3072
[A[ATraining Step: 1211  | total loss: [1m[32m0.40538[0m[0m | time: 39.134s
[2K
| Adam | epoch: 013 | loss: 0.40538 - acc: 0.8194 -- iter: 1888/3072
[A[ATraining Step: 1212  | total loss: [1m[32m0.39160[0m[0m | time: 39.735s
[2K
| Adam | epoch: 013 | loss: 0.39160 - acc: 0.8250 -- iter: 1920/3072
[A[ATraining Step: 1213  | total loss: [1m[32m0.38939[0m[0m | time: 40.336s
[2K
| Adam | epoch: 013 | loss: 0.38939 - acc: 0.8300 -- iter: 1952/3072
[A[ATraining Step: 1214  | total loss: [1m[32m0.38296[0m[0m | time: 40.930s
[2K
| Adam | epoch: 013 | loss: 0.38296 - acc: 0.8376 -- iter: 1984/3072
[A[ATraining Step: 1215  | total loss: [1m[32m0.38145[0m[0m | time: 41.530s
[2K
| Adam | epoch: 013 | loss: 0.38145 - acc: 0.8414 -- iter: 2016/3072
[A[ATraining Step: 1216  | total loss: [1m[32m0.37979[0m[0m | time: 42.118s
[2K
| Adam | epoch: 013 | loss: 0.37979 - acc: 0.8478 -- iter: 2048/3072
[A[ATraining Step: 1217  | total loss: [1m[32m0.37826[0m[0m | time: 42.730s
[2K
| Adam | epoch: 013 | loss: 0.37826 - acc: 0.8506 -- iter: 2080/3072
[A[ATraining Step: 1218  | total loss: [1m[32m0.37407[0m[0m | time: 43.353s
[2K
| Adam | epoch: 013 | loss: 0.37407 - acc: 0.8561 -- iter: 2112/3072
[A[ATraining Step: 1219  | total loss: [1m[32m0.36573[0m[0m | time: 43.990s
[2K
| Adam | epoch: 013 | loss: 0.36573 - acc: 0.8549 -- iter: 2144/3072
[A[ATraining Step: 1220  | total loss: [1m[32m0.35658[0m[0m | time: 44.664s
[2K
| Adam | epoch: 013 | loss: 0.35658 - acc: 0.8569 -- iter: 2176/3072
[A[ATraining Step: 1221  | total loss: [1m[32m0.35831[0m[0m | time: 45.269s
[2K
| Adam | epoch: 013 | loss: 0.35831 - acc: 0.8556 -- iter: 2208/3072
[A[ATraining Step: 1222  | total loss: [1m[32m0.35483[0m[0m | time: 45.882s
[2K
| Adam | epoch: 013 | loss: 0.35483 - acc: 0.8575 -- iter: 2240/3072
[A[ATraining Step: 1223  | total loss: [1m[32m0.36771[0m[0m | time: 46.493s
[2K
| Adam | epoch: 013 | loss: 0.36771 - acc: 0.8468 -- iter: 2272/3072
[A[ATraining Step: 1224  | total loss: [1m[32m0.36950[0m[0m | time: 47.103s
[2K
| Adam | epoch: 013 | loss: 0.36950 - acc: 0.8402 -- iter: 2304/3072
[A[ATraining Step: 1225  | total loss: [1m[32m0.35403[0m[0m | time: 47.705s
[2K
| Adam | epoch: 013 | loss: 0.35403 - acc: 0.8500 -- iter: 2336/3072
[A[ATraining Step: 1226  | total loss: [1m[32m0.35346[0m[0m | time: 48.321s
[2K
| Adam | epoch: 013 | loss: 0.35346 - acc: 0.8431 -- iter: 2368/3072
[A[ATraining Step: 1227  | total loss: [1m[32m0.34299[0m[0m | time: 49.006s
[2K
| Adam | epoch: 013 | loss: 0.34299 - acc: 0.8494 -- iter: 2400/3072
[A[ATraining Step: 1228  | total loss: [1m[32m0.32879[0m[0m | time: 49.628s
[2K
| Adam | epoch: 013 | loss: 0.32879 - acc: 0.8582 -- iter: 2432/3072
[A[ATraining Step: 1229  | total loss: [1m[32m0.33656[0m[0m | time: 50.289s
[2K
| Adam | epoch: 013 | loss: 0.33656 - acc: 0.8536 -- iter: 2464/3072
[A[ATraining Step: 1230  | total loss: [1m[32m0.34920[0m[0m | time: 50.934s
[2K
| Adam | epoch: 013 | loss: 0.34920 - acc: 0.8464 -- iter: 2496/3072
[A[ATraining Step: 1231  | total loss: [1m[32m0.34503[0m[0m | time: 51.539s
[2K
| Adam | epoch: 013 | loss: 0.34503 - acc: 0.8524 -- iter: 2528/3072
[A[ATraining Step: 1232  | total loss: [1m[32m0.33903[0m[0m | time: 52.148s
[2K
| Adam | epoch: 013 | loss: 0.33903 - acc: 0.8546 -- iter: 2560/3072
[A[ATraining Step: 1233  | total loss: [1m[32m0.33537[0m[0m | time: 52.774s
[2K
| Adam | epoch: 013 | loss: 0.33537 - acc: 0.8629 -- iter: 2592/3072
[A[ATraining Step: 1234  | total loss: [1m[32m0.32725[0m[0m | time: 53.395s
[2K
| Adam | epoch: 013 | loss: 0.32725 - acc: 0.8673 -- iter: 2624/3072
[A[ATraining Step: 1235  | total loss: [1m[32m0.33806[0m[0m | time: 54.024s
[2K
| Adam | epoch: 013 | loss: 0.33806 - acc: 0.8618 -- iter: 2656/3072
[A[ATraining Step: 1236  | total loss: [1m[32m0.33356[0m[0m | time: 54.651s
[2K
| Adam | epoch: 013 | loss: 0.33356 - acc: 0.8662 -- iter: 2688/3072
[A[ATraining Step: 1237  | total loss: [1m[32m0.32241[0m[0m | time: 55.259s
[2K
| Adam | epoch: 013 | loss: 0.32241 - acc: 0.8640 -- iter: 2720/3072
[A[ATraining Step: 1238  | total loss: [1m[32m0.31555[0m[0m | time: 55.861s
[2K
| Adam | epoch: 013 | loss: 0.31555 - acc: 0.8620 -- iter: 2752/3072
[A[ATraining Step: 1239  | total loss: [1m[32m0.30538[0m[0m | time: 56.453s
[2K
| Adam | epoch: 013 | loss: 0.30538 - acc: 0.8726 -- iter: 2784/3072
[A[ATraining Step: 1240  | total loss: [1m[32m0.31138[0m[0m | time: 57.080s
[2K
| Adam | epoch: 013 | loss: 0.31138 - acc: 0.8729 -- iter: 2816/3072
[A[ATraining Step: 1241  | total loss: [1m[32m0.30503[0m[0m | time: 57.690s
[2K
| Adam | epoch: 013 | loss: 0.30503 - acc: 0.8793 -- iter: 2848/3072
[A[ATraining Step: 1242  | total loss: [1m[32m0.30333[0m[0m | time: 58.289s
[2K
| Adam | epoch: 013 | loss: 0.30333 - acc: 0.8758 -- iter: 2880/3072
[A[ATraining Step: 1243  | total loss: [1m[32m0.31071[0m[0m | time: 58.912s
[2K
| Adam | epoch: 013 | loss: 0.31071 - acc: 0.8663 -- iter: 2912/3072
[A[ATraining Step: 1244  | total loss: [1m[32m0.31624[0m[0m | time: 59.526s
[2K
| Adam | epoch: 013 | loss: 0.31624 - acc: 0.8672 -- iter: 2944/3072
[A[ATraining Step: 1245  | total loss: [1m[32m0.31838[0m[0m | time: 60.155s
[2K
| Adam | epoch: 013 | loss: 0.31838 - acc: 0.8617 -- iter: 2976/3072
[A[ATraining Step: 1246  | total loss: [1m[32m0.30409[0m[0m | time: 60.784s
[2K
| Adam | epoch: 013 | loss: 0.30409 - acc: 0.8724 -- iter: 3008/3072
[A[ATraining Step: 1247  | total loss: [1m[32m0.30663[0m[0m | time: 61.399s
[2K
| Adam | epoch: 013 | loss: 0.30663 - acc: 0.8696 -- iter: 3040/3072
[A[ATraining Step: 1248  | total loss: [1m[32m0.29795[0m[0m | time: 65.129s
[2K
| Adam | epoch: 013 | loss: 0.29795 - acc: 0.8764 | val_loss: 0.48826 - val_acc: 0.7784 -- iter: 3072/3072
--
Training Step: 1249  | total loss: [1m[32m0.29418[0m[0m | time: 0.614s
[2K
| Adam | epoch: 014 | loss: 0.29418 - acc: 0.8825 -- iter: 0032/3072
[A[ATraining Step: 1250  | total loss: [1m[32m0.28896[0m[0m | time: 1.214s
[2K
| Adam | epoch: 014 | loss: 0.28896 - acc: 0.8911 -- iter: 0064/3072
[A[ATraining Step: 1251  | total loss: [1m[32m0.28477[0m[0m | time: 1.826s
[2K
| Adam | epoch: 014 | loss: 0.28477 - acc: 0.8926 -- iter: 0096/3072
[A[ATraining Step: 1252  | total loss: [1m[32m0.28835[0m[0m | time: 2.457s
[2K
| Adam | epoch: 014 | loss: 0.28835 - acc: 0.8815 -- iter: 0128/3072
[A[ATraining Step: 1253  | total loss: [1m[32m0.27874[0m[0m | time: 3.064s
[2K
| Adam | epoch: 014 | loss: 0.27874 - acc: 0.8902 -- iter: 0160/3072
[A[ATraining Step: 1254  | total loss: [1m[32m0.27747[0m[0m | time: 3.690s
[2K
| Adam | epoch: 014 | loss: 0.27747 - acc: 0.8949 -- iter: 0192/3072
[A[ATraining Step: 1255  | total loss: [1m[32m0.28307[0m[0m | time: 4.353s
[2K
| Adam | epoch: 014 | loss: 0.28307 - acc: 0.8867 -- iter: 0224/3072
[A[ATraining Step: 1256  | total loss: [1m[32m0.28774[0m[0m | time: 4.977s
[2K
| Adam | epoch: 014 | loss: 0.28774 - acc: 0.8824 -- iter: 0256/3072
[A[ATraining Step: 1257  | total loss: [1m[32m0.28426[0m[0m | time: 5.581s
[2K
| Adam | epoch: 014 | loss: 0.28426 - acc: 0.8848 -- iter: 0288/3072
[A[ATraining Step: 1258  | total loss: [1m[32m0.27827[0m[0m | time: 6.219s
[2K
| Adam | epoch: 014 | loss: 0.27827 - acc: 0.8869 -- iter: 0320/3072
[A[ATraining Step: 1259  | total loss: [1m[32m0.29255[0m[0m | time: 6.867s
[2K
| Adam | epoch: 014 | loss: 0.29255 - acc: 0.8826 -- iter: 0352/3072
[A[ATraining Step: 1260  | total loss: [1m[32m0.31411[0m[0m | time: 7.478s
[2K
| Adam | epoch: 014 | loss: 0.31411 - acc: 0.8693 -- iter: 0384/3072
[A[ATraining Step: 1261  | total loss: [1m[32m0.31541[0m[0m | time: 8.144s
[2K
| Adam | epoch: 014 | loss: 0.31541 - acc: 0.8730 -- iter: 0416/3072
[A[ATraining Step: 1262  | total loss: [1m[32m0.31608[0m[0m | time: 8.739s
[2K
| Adam | epoch: 014 | loss: 0.31608 - acc: 0.8732 -- iter: 0448/3072
[A[ATraining Step: 1263  | total loss: [1m[32m0.30381[0m[0m | time: 9.398s
[2K
| Adam | epoch: 014 | loss: 0.30381 - acc: 0.8828 -- iter: 0480/3072
[A[ATraining Step: 1264  | total loss: [1m[32m0.30418[0m[0m | time: 10.031s
[2K
| Adam | epoch: 014 | loss: 0.30418 - acc: 0.8789 -- iter: 0512/3072
[A[ATraining Step: 1265  | total loss: [1m[32m0.30047[0m[0m | time: 10.653s
[2K
| Adam | epoch: 014 | loss: 0.30047 - acc: 0.8785 -- iter: 0544/3072
[A[ATraining Step: 1266  | total loss: [1m[32m0.28970[0m[0m | time: 11.250s
[2K
| Adam | epoch: 014 | loss: 0.28970 - acc: 0.8813 -- iter: 0576/3072
[A[ATraining Step: 1267  | total loss: [1m[32m0.29762[0m[0m | time: 11.882s
[2K
| Adam | epoch: 014 | loss: 0.29762 - acc: 0.8775 -- iter: 0608/3072
[A[ATraining Step: 1268  | total loss: [1m[32m0.29824[0m[0m | time: 12.553s
[2K
| Adam | epoch: 014 | loss: 0.29824 - acc: 0.8804 -- iter: 0640/3072
[A[ATraining Step: 1269  | total loss: [1m[32m0.28947[0m[0m | time: 13.163s
[2K
| Adam | epoch: 014 | loss: 0.28947 - acc: 0.8861 -- iter: 0672/3072
[A[ATraining Step: 1270  | total loss: [1m[32m0.30157[0m[0m | time: 13.821s
[2K
| Adam | epoch: 014 | loss: 0.30157 - acc: 0.8694 -- iter: 0704/3072
[A[ATraining Step: 1271  | total loss: [1m[32m0.31010[0m[0m | time: 14.492s
[2K
| Adam | epoch: 014 | loss: 0.31010 - acc: 0.8606 -- iter: 0736/3072
[A[ATraining Step: 1272  | total loss: [1m[32m0.32450[0m[0m | time: 15.147s
[2K
| Adam | epoch: 014 | loss: 0.32450 - acc: 0.8464 -- iter: 0768/3072
[A[ATraining Step: 1273  | total loss: [1m[32m0.33240[0m[0m | time: 15.765s
[2K
| Adam | epoch: 014 | loss: 0.33240 - acc: 0.8492 -- iter: 0800/3072
[A[ATraining Step: 1274  | total loss: [1m[32m0.32857[0m[0m | time: 16.389s
[2K
| Adam | epoch: 014 | loss: 0.32857 - acc: 0.8487 -- iter: 0832/3072
[A[ATraining Step: 1275  | total loss: [1m[32m0.34501[0m[0m | time: 16.989s
[2K
| Adam | epoch: 014 | loss: 0.34501 - acc: 0.8451 -- iter: 0864/3072
[A[ATraining Step: 1276  | total loss: [1m[32m0.35007[0m[0m | time: 17.599s
[2K
| Adam | epoch: 014 | loss: 0.35007 - acc: 0.8356 -- iter: 0896/3072
[A[ATraining Step: 1277  | total loss: [1m[32m0.36041[0m[0m | time: 18.207s
[2K
| Adam | epoch: 014 | loss: 0.36041 - acc: 0.8395 -- iter: 0928/3072
[A[ATraining Step: 1278  | total loss: [1m[32m0.35201[0m[0m | time: 18.810s
[2K
| Adam | epoch: 014 | loss: 0.35201 - acc: 0.8462 -- iter: 0960/3072
[A[ATraining Step: 1279  | total loss: [1m[32m0.35502[0m[0m | time: 19.430s
[2K
| Adam | epoch: 014 | loss: 0.35502 - acc: 0.8428 -- iter: 0992/3072
[A[ATraining Step: 1280  | total loss: [1m[32m0.37180[0m[0m | time: 20.034s
[2K
| Adam | epoch: 014 | loss: 0.37180 - acc: 0.8335 -- iter: 1024/3072
[A[ATraining Step: 1281  | total loss: [1m[32m0.36353[0m[0m | time: 20.639s
[2K
| Adam | epoch: 014 | loss: 0.36353 - acc: 0.8377 -- iter: 1056/3072
[A[ATraining Step: 1282  | total loss: [1m[32m0.36653[0m[0m | time: 21.245s
[2K
| Adam | epoch: 014 | loss: 0.36653 - acc: 0.8258 -- iter: 1088/3072
[A[ATraining Step: 1283  | total loss: [1m[32m0.36283[0m[0m | time: 21.916s
[2K
| Adam | epoch: 014 | loss: 0.36283 - acc: 0.8307 -- iter: 1120/3072
[A[ATraining Step: 1284  | total loss: [1m[32m0.36106[0m[0m | time: 22.555s
[2K
| Adam | epoch: 014 | loss: 0.36106 - acc: 0.8320 -- iter: 1152/3072
[A[ATraining Step: 1285  | total loss: [1m[32m0.35661[0m[0m | time: 23.240s
[2K
| Adam | epoch: 014 | loss: 0.35661 - acc: 0.8301 -- iter: 1184/3072
[A[ATraining Step: 1286  | total loss: [1m[32m0.35782[0m[0m | time: 23.865s
[2K
| Adam | epoch: 014 | loss: 0.35782 - acc: 0.8314 -- iter: 1216/3072
[A[ATraining Step: 1287  | total loss: [1m[32m0.33787[0m[0m | time: 24.472s
[2K
| Adam | epoch: 014 | loss: 0.33787 - acc: 0.8389 -- iter: 1248/3072
[A[ATraining Step: 1288  | total loss: [1m[32m0.33615[0m[0m | time: 25.076s
[2K
| Adam | epoch: 014 | loss: 0.33615 - acc: 0.8425 -- iter: 1280/3072
[A[ATraining Step: 1289  | total loss: [1m[32m0.33190[0m[0m | time: 25.678s
[2K
| Adam | epoch: 014 | loss: 0.33190 - acc: 0.8489 -- iter: 1312/3072
[A[ATraining Step: 1290  | total loss: [1m[32m0.33327[0m[0m | time: 26.278s
[2K
| Adam | epoch: 014 | loss: 0.33327 - acc: 0.8453 -- iter: 1344/3072
[A[ATraining Step: 1291  | total loss: [1m[32m0.33861[0m[0m | time: 26.895s
[2K
| Adam | epoch: 014 | loss: 0.33861 - acc: 0.8389 -- iter: 1376/3072
[A[ATraining Step: 1292  | total loss: [1m[32m0.35347[0m[0m | time: 27.514s
[2K
| Adam | epoch: 014 | loss: 0.35347 - acc: 0.8331 -- iter: 1408/3072
[A[ATraining Step: 1293  | total loss: [1m[32m0.34526[0m[0m | time: 28.151s
[2K
| Adam | epoch: 014 | loss: 0.34526 - acc: 0.8404 -- iter: 1440/3072
[A[ATraining Step: 1294  | total loss: [1m[32m0.35008[0m[0m | time: 28.748s
[2K
| Adam | epoch: 014 | loss: 0.35008 - acc: 0.8407 -- iter: 1472/3072
[A[ATraining Step: 1295  | total loss: [1m[32m0.35177[0m[0m | time: 29.359s
[2K
| Adam | epoch: 014 | loss: 0.35177 - acc: 0.8442 -- iter: 1504/3072
[A[ATraining Step: 1296  | total loss: [1m[32m0.35919[0m[0m | time: 29.987s
[2K
| Adam | epoch: 014 | loss: 0.35919 - acc: 0.8379 -- iter: 1536/3072
[A[ATraining Step: 1297  | total loss: [1m[32m0.37108[0m[0m | time: 30.590s
[2K
| Adam | epoch: 014 | loss: 0.37108 - acc: 0.8322 -- iter: 1568/3072
[A[ATraining Step: 1298  | total loss: [1m[32m0.35521[0m[0m | time: 31.233s
[2K
| Adam | epoch: 014 | loss: 0.35521 - acc: 0.8427 -- iter: 1600/3072
[A[ATraining Step: 1299  | total loss: [1m[32m0.33637[0m[0m | time: 31.864s
[2K
| Adam | epoch: 014 | loss: 0.33637 - acc: 0.8553 -- iter: 1632/3072
[A[ATraining Step: 1300  | total loss: [1m[32m0.34507[0m[0m | time: 32.474s
[2K
| Adam | epoch: 014 | loss: 0.34507 - acc: 0.8417 -- iter: 1664/3072
[A[ATraining Step: 1301  | total loss: [1m[32m0.35471[0m[0m | time: 33.080s
[2K
| Adam | epoch: 014 | loss: 0.35471 - acc: 0.8325 -- iter: 1696/3072
[A[ATraining Step: 1302  | total loss: [1m[32m0.35198[0m[0m | time: 33.681s
[2K
| Adam | epoch: 014 | loss: 0.35198 - acc: 0.8336 -- iter: 1728/3072
[A[ATraining Step: 1303  | total loss: [1m[32m0.36002[0m[0m | time: 34.285s
[2K
| Adam | epoch: 014 | loss: 0.36002 - acc: 0.8347 -- iter: 1760/3072
[A[ATraining Step: 1304  | total loss: [1m[32m0.35615[0m[0m | time: 34.881s
[2K
| Adam | epoch: 014 | loss: 0.35615 - acc: 0.8387 -- iter: 1792/3072
[A[ATraining Step: 1305  | total loss: [1m[32m0.36324[0m[0m | time: 35.494s
[2K
| Adam | epoch: 014 | loss: 0.36324 - acc: 0.8267 -- iter: 1824/3072
[A[ATraining Step: 1306  | total loss: [1m[32m0.34269[0m[0m | time: 36.113s
[2K
| Adam | epoch: 014 | loss: 0.34269 - acc: 0.8409 -- iter: 1856/3072
[A[ATraining Step: 1307  | total loss: [1m[32m0.33717[0m[0m | time: 36.741s
[2K
| Adam | epoch: 014 | loss: 0.33717 - acc: 0.8474 -- iter: 1888/3072
[A[ATraining Step: 1308  | total loss: [1m[32m0.33250[0m[0m | time: 37.361s
[2K
| Adam | epoch: 014 | loss: 0.33250 - acc: 0.8564 -- iter: 1920/3072
[A[ATraining Step: 1309  | total loss: [1m[32m0.32841[0m[0m | time: 37.975s
[2K
| Adam | epoch: 014 | loss: 0.32841 - acc: 0.8583 -- iter: 1952/3072
[A[ATraining Step: 1310  | total loss: [1m[32m0.31976[0m[0m | time: 38.581s
[2K
| Adam | epoch: 014 | loss: 0.31976 - acc: 0.8631 -- iter: 1984/3072
[A[ATraining Step: 1311  | total loss: [1m[32m0.31549[0m[0m | time: 39.217s
[2K
| Adam | epoch: 014 | loss: 0.31549 - acc: 0.8643 -- iter: 2016/3072
[A[ATraining Step: 1312  | total loss: [1m[32m0.30686[0m[0m | time: 39.843s
[2K
| Adam | epoch: 014 | loss: 0.30686 - acc: 0.8747 -- iter: 2048/3072
[A[ATraining Step: 1313  | total loss: [1m[32m0.31566[0m[0m | time: 40.444s
[2K
| Adam | epoch: 014 | loss: 0.31566 - acc: 0.8654 -- iter: 2080/3072
[A[ATraining Step: 1314  | total loss: [1m[32m0.32593[0m[0m | time: 41.059s
[2K
| Adam | epoch: 014 | loss: 0.32593 - acc: 0.8570 -- iter: 2112/3072
[A[ATraining Step: 1315  | total loss: [1m[32m0.32134[0m[0m | time: 41.665s
[2K
| Adam | epoch: 014 | loss: 0.32134 - acc: 0.8588 -- iter: 2144/3072
[A[ATraining Step: 1316  | total loss: [1m[32m0.31522[0m[0m | time: 42.274s
[2K
| Adam | epoch: 014 | loss: 0.31522 - acc: 0.8666 -- iter: 2176/3072
[A[ATraining Step: 1317  | total loss: [1m[32m0.30519[0m[0m | time: 42.866s
[2K
| Adam | epoch: 014 | loss: 0.30519 - acc: 0.8737 -- iter: 2208/3072
[A[ATraining Step: 1318  | total loss: [1m[32m0.30194[0m[0m | time: 43.552s
[2K
| Adam | epoch: 014 | loss: 0.30194 - acc: 0.8801 -- iter: 2240/3072
[A[ATraining Step: 1319  | total loss: [1m[32m0.32602[0m[0m | time: 44.167s
[2K
| Adam | epoch: 014 | loss: 0.32602 - acc: 0.8702 -- iter: 2272/3072
[A[ATraining Step: 1320  | total loss: [1m[32m0.36946[0m[0m | time: 44.778s
[2K
| Adam | epoch: 014 | loss: 0.36946 - acc: 0.8457 -- iter: 2304/3072
[A[ATraining Step: 1321  | total loss: [1m[32m0.37049[0m[0m | time: 45.395s
[2K
| Adam | epoch: 014 | loss: 0.37049 - acc: 0.8393 -- iter: 2336/3072
[A[ATraining Step: 1322  | total loss: [1m[32m0.36233[0m[0m | time: 46.148s
[2K
| Adam | epoch: 014 | loss: 0.36233 - acc: 0.8366 -- iter: 2368/3072
[A[ATraining Step: 1323  | total loss: [1m[32m0.38130[0m[0m | time: 46.747s
[2K
| Adam | epoch: 014 | loss: 0.38130 - acc: 0.8310 -- iter: 2400/3072
[A[ATraining Step: 1324  | total loss: [1m[32m0.36585[0m[0m | time: 47.409s
[2K
| Adam | epoch: 014 | loss: 0.36585 - acc: 0.8417 -- iter: 2432/3072
[A[ATraining Step: 1325  | total loss: [1m[32m0.34870[0m[0m | time: 48.049s
[2K
| Adam | epoch: 014 | loss: 0.34870 - acc: 0.8544 -- iter: 2464/3072
[A[ATraining Step: 1326  | total loss: [1m[32m0.35491[0m[0m | time: 48.678s
[2K
| Adam | epoch: 014 | loss: 0.35491 - acc: 0.8533 -- iter: 2496/3072
[A[ATraining Step: 1327  | total loss: [1m[32m0.35887[0m[0m | time: 49.317s
[2K
| Adam | epoch: 014 | loss: 0.35887 - acc: 0.8492 -- iter: 2528/3072
[A[ATraining Step: 1328  | total loss: [1m[32m0.38209[0m[0m | time: 49.920s
[2K
| Adam | epoch: 014 | loss: 0.38209 - acc: 0.8393 -- iter: 2560/3072
[A[ATraining Step: 1329  | total loss: [1m[32m0.38582[0m[0m | time: 50.520s
[2K
| Adam | epoch: 014 | loss: 0.38582 - acc: 0.8335 -- iter: 2592/3072
[A[ATraining Step: 1330  | total loss: [1m[32m0.36436[0m[0m | time: 51.122s
[2K
| Adam | epoch: 014 | loss: 0.36436 - acc: 0.8439 -- iter: 2624/3072
[A[ATraining Step: 1331  | total loss: [1m[32m0.37807[0m[0m | time: 51.734s
[2K
| Adam | epoch: 014 | loss: 0.37807 - acc: 0.8314 -- iter: 2656/3072
[A[ATraining Step: 1332  | total loss: [1m[32m0.35966[0m[0m | time: 52.351s
[2K
| Adam | epoch: 014 | loss: 0.35966 - acc: 0.8451 -- iter: 2688/3072
[A[ATraining Step: 1333  | total loss: [1m[32m0.35283[0m[0m | time: 52.954s
[2K
| Adam | epoch: 014 | loss: 0.35283 - acc: 0.8450 -- iter: 2720/3072
[A[ATraining Step: 1334  | total loss: [1m[32m0.34839[0m[0m | time: 53.569s
[2K
| Adam | epoch: 014 | loss: 0.34839 - acc: 0.8480 -- iter: 2752/3072
[A[ATraining Step: 1335  | total loss: [1m[32m0.34863[0m[0m | time: 54.181s
[2K
| Adam | epoch: 014 | loss: 0.34863 - acc: 0.8476 -- iter: 2784/3072
[A[ATraining Step: 1336  | total loss: [1m[32m0.35096[0m[0m | time: 54.797s
[2K
| Adam | epoch: 014 | loss: 0.35096 - acc: 0.8441 -- iter: 2816/3072
[A[ATraining Step: 1337  | total loss: [1m[32m0.36495[0m[0m | time: 55.419s
[2K
| Adam | epoch: 014 | loss: 0.36495 - acc: 0.8315 -- iter: 2848/3072
[A[ATraining Step: 1338  | total loss: [1m[32m0.35323[0m[0m | time: 56.008s
[2K
| Adam | epoch: 014 | loss: 0.35323 - acc: 0.8296 -- iter: 2880/3072
[A[ATraining Step: 1339  | total loss: [1m[32m0.34892[0m[0m | time: 56.611s
[2K
| Adam | epoch: 014 | loss: 0.34892 - acc: 0.8404 -- iter: 2912/3072
[A[ATraining Step: 1340  | total loss: [1m[32m0.34231[0m[0m | time: 57.260s
[2K
| Adam | epoch: 014 | loss: 0.34231 - acc: 0.8439 -- iter: 2944/3072
[A[ATraining Step: 1341  | total loss: [1m[32m0.33588[0m[0m | time: 57.870s
[2K
| Adam | epoch: 014 | loss: 0.33588 - acc: 0.8439 -- iter: 2976/3072
[A[ATraining Step: 1342  | total loss: [1m[32m0.32437[0m[0m | time: 58.486s
[2K
| Adam | epoch: 014 | loss: 0.32437 - acc: 0.8470 -- iter: 3008/3072
[A[ATraining Step: 1343  | total loss: [1m[32m0.32194[0m[0m | time: 59.104s
[2K
| Adam | epoch: 014 | loss: 0.32194 - acc: 0.8498 -- iter: 3040/3072
[A[ATraining Step: 1344  | total loss: [1m[32m0.33033[0m[0m | time: 62.818s
[2K
| Adam | epoch: 014 | loss: 0.33033 - acc: 0.8492 | val_loss: 0.49212 - val_acc: 0.7825 -- iter: 3072/3072
--
Training Step: 1345  | total loss: [1m[32m0.32700[0m[0m | time: 0.603s
[2K
| Adam | epoch: 015 | loss: 0.32700 - acc: 0.8518 -- iter: 0032/3072
[A[ATraining Step: 1346  | total loss: [1m[32m0.33495[0m[0m | time: 1.201s
[2K
| Adam | epoch: 015 | loss: 0.33495 - acc: 0.8510 -- iter: 0064/3072
[A[ATraining Step: 1347  | total loss: [1m[32m0.33187[0m[0m | time: 1.820s
[2K
| Adam | epoch: 015 | loss: 0.33187 - acc: 0.8534 -- iter: 0096/3072
[A[ATraining Step: 1348  | total loss: [1m[32m0.32569[0m[0m | time: 2.503s
[2K
| Adam | epoch: 015 | loss: 0.32569 - acc: 0.8555 -- iter: 0128/3072
[A[ATraining Step: 1349  | total loss: [1m[32m0.31163[0m[0m | time: 3.162s
[2K
| Adam | epoch: 015 | loss: 0.31163 - acc: 0.8606 -- iter: 0160/3072
[A[ATraining Step: 1350  | total loss: [1m[32m0.31338[0m[0m | time: 3.794s
[2K
| Adam | epoch: 015 | loss: 0.31338 - acc: 0.8620 -- iter: 0192/3072
[A[ATraining Step: 1351  | total loss: [1m[32m0.31208[0m[0m | time: 4.393s
[2K
| Adam | epoch: 015 | loss: 0.31208 - acc: 0.8665 -- iter: 0224/3072
[A[ATraining Step: 1352  | total loss: [1m[32m0.31299[0m[0m | time: 5.053s
[2K
| Adam | epoch: 015 | loss: 0.31299 - acc: 0.8673 -- iter: 0256/3072
[A[ATraining Step: 1353  | total loss: [1m[32m0.31596[0m[0m | time: 5.677s
[2K
| Adam | epoch: 015 | loss: 0.31596 - acc: 0.8618 -- iter: 0288/3072
[A[ATraining Step: 1354  | total loss: [1m[32m0.31520[0m[0m | time: 6.279s
[2K
| Adam | epoch: 015 | loss: 0.31520 - acc: 0.8600 -- iter: 0320/3072
[A[ATraining Step: 1355  | total loss: [1m[32m0.31850[0m[0m | time: 6.965s
[2K
| Adam | epoch: 015 | loss: 0.31850 - acc: 0.8615 -- iter: 0352/3072
[A[ATraining Step: 1356  | total loss: [1m[32m0.30507[0m[0m | time: 7.573s
[2K
| Adam | epoch: 015 | loss: 0.30507 - acc: 0.8722 -- iter: 0384/3072
[A[ATraining Step: 1357  | total loss: [1m[32m0.31035[0m[0m | time: 8.178s
[2K
| Adam | epoch: 015 | loss: 0.31035 - acc: 0.8663 -- iter: 0416/3072
[A[ATraining Step: 1358  | total loss: [1m[32m0.29681[0m[0m | time: 8.834s
[2K
| Adam | epoch: 015 | loss: 0.29681 - acc: 0.8734 -- iter: 0448/3072
[A[ATraining Step: 1359  | total loss: [1m[32m0.28122[0m[0m | time: 9.468s
[2K
| Adam | epoch: 015 | loss: 0.28122 - acc: 0.8829 -- iter: 0480/3072
[A[ATraining Step: 1360  | total loss: [1m[32m0.29116[0m[0m | time: 10.071s
[2K
| Adam | epoch: 015 | loss: 0.29116 - acc: 0.8759 -- iter: 0512/3072
[A[ATraining Step: 1361  | total loss: [1m[32m0.29313[0m[0m | time: 10.687s
[2K
| Adam | epoch: 015 | loss: 0.29313 - acc: 0.8758 -- iter: 0544/3072
[A[ATraining Step: 1362  | total loss: [1m[32m0.29647[0m[0m | time: 11.291s
[2K
| Adam | epoch: 015 | loss: 0.29647 - acc: 0.8726 -- iter: 0576/3072
[A[ATraining Step: 1363  | total loss: [1m[32m0.29489[0m[0m | time: 11.898s
[2K
| Adam | epoch: 015 | loss: 0.29489 - acc: 0.8697 -- iter: 0608/3072
[A[ATraining Step: 1364  | total loss: [1m[32m0.28664[0m[0m | time: 12.511s
[2K
| Adam | epoch: 015 | loss: 0.28664 - acc: 0.8765 -- iter: 0640/3072
[A[ATraining Step: 1365  | total loss: [1m[32m0.29219[0m[0m | time: 13.139s
[2K
| Adam | epoch: 015 | loss: 0.29219 - acc: 0.8732 -- iter: 0672/3072
[A[ATraining Step: 1366  | total loss: [1m[32m0.29422[0m[0m | time: 13.774s
[2K
| Adam | epoch: 015 | loss: 0.29422 - acc: 0.8671 -- iter: 0704/3072
[A[ATraining Step: 1367  | total loss: [1m[32m0.28849[0m[0m | time: 14.379s
[2K
| Adam | epoch: 015 | loss: 0.28849 - acc: 0.8711 -- iter: 0736/3072
[A[ATraining Step: 1368  | total loss: [1m[32m0.27844[0m[0m | time: 14.993s
[2K
| Adam | epoch: 015 | loss: 0.27844 - acc: 0.8746 -- iter: 0768/3072
[A[ATraining Step: 1369  | total loss: [1m[32m0.28324[0m[0m | time: 15.659s
[2K
| Adam | epoch: 015 | loss: 0.28324 - acc: 0.8684 -- iter: 0800/3072
[A[ATraining Step: 1370  | total loss: [1m[32m0.29936[0m[0m | time: 16.264s
[2K
| Adam | epoch: 015 | loss: 0.29936 - acc: 0.8659 -- iter: 0832/3072
[A[ATraining Step: 1371  | total loss: [1m[32m0.29317[0m[0m | time: 16.869s
[2K
| Adam | epoch: 015 | loss: 0.29317 - acc: 0.8731 -- iter: 0864/3072
[A[ATraining Step: 1372  | total loss: [1m[32m0.28429[0m[0m | time: 17.466s
[2K
| Adam | epoch: 015 | loss: 0.28429 - acc: 0.8764 -- iter: 0896/3072
[A[ATraining Step: 1373  | total loss: [1m[32m0.28745[0m[0m | time: 18.074s
[2K
| Adam | epoch: 015 | loss: 0.28745 - acc: 0.8731 -- iter: 0928/3072
[A[ATraining Step: 1374  | total loss: [1m[32m0.28595[0m[0m | time: 18.716s
[2K
| Adam | epoch: 015 | loss: 0.28595 - acc: 0.8702 -- iter: 0960/3072
[A[ATraining Step: 1375  | total loss: [1m[32m0.28737[0m[0m | time: 19.343s
[2K
| Adam | epoch: 015 | loss: 0.28737 - acc: 0.8675 -- iter: 0992/3072
[A[ATraining Step: 1376  | total loss: [1m[32m0.27683[0m[0m | time: 19.950s
[2K
| Adam | epoch: 015 | loss: 0.27683 - acc: 0.8777 -- iter: 1024/3072
[A[ATraining Step: 1377  | total loss: [1m[32m0.28071[0m[0m | time: 20.571s
[2K
| Adam | epoch: 015 | loss: 0.28071 - acc: 0.8743 -- iter: 1056/3072
[A[ATraining Step: 1378  | total loss: [1m[32m0.26952[0m[0m | time: 21.353s
[2K
| Adam | epoch: 015 | loss: 0.26952 - acc: 0.8868 -- iter: 1088/3072
[A[ATraining Step: 1379  | total loss: [1m[32m0.27143[0m[0m | time: 22.001s
[2K
| Adam | epoch: 015 | loss: 0.27143 - acc: 0.8888 -- iter: 1120/3072
[A[ATraining Step: 1380  | total loss: [1m[32m0.25629[0m[0m | time: 22.616s
[2K
| Adam | epoch: 015 | loss: 0.25629 - acc: 0.8968 -- iter: 1152/3072
[A[ATraining Step: 1381  | total loss: [1m[32m0.25138[0m[0m | time: 23.221s
[2K
| Adam | epoch: 015 | loss: 0.25138 - acc: 0.9009 -- iter: 1184/3072
[A[ATraining Step: 1382  | total loss: [1m[32m0.25309[0m[0m | time: 23.832s
[2K
| Adam | epoch: 015 | loss: 0.25309 - acc: 0.8951 -- iter: 1216/3072
[A[ATraining Step: 1383  | total loss: [1m[32m0.24810[0m[0m | time: 24.429s
[2K
| Adam | epoch: 015 | loss: 0.24810 - acc: 0.9025 -- iter: 1248/3072
[A[ATraining Step: 1384  | total loss: [1m[32m0.24266[0m[0m | time: 25.042s
[2K
| Adam | epoch: 015 | loss: 0.24266 - acc: 0.8998 -- iter: 1280/3072
[A[ATraining Step: 1385  | total loss: [1m[32m0.23260[0m[0m | time: 25.639s
[2K
| Adam | epoch: 015 | loss: 0.23260 - acc: 0.9067 -- iter: 1312/3072
[A[ATraining Step: 1386  | total loss: [1m[32m0.23377[0m[0m | time: 26.279s
[2K
| Adam | epoch: 015 | loss: 0.23377 - acc: 0.9097 -- iter: 1344/3072
[A[ATraining Step: 1387  | total loss: [1m[32m0.24608[0m[0m | time: 26.914s
[2K
| Adam | epoch: 015 | loss: 0.24608 - acc: 0.9000 -- iter: 1376/3072
[A[ATraining Step: 1388  | total loss: [1m[32m0.24083[0m[0m | time: 27.570s
[2K
| Adam | epoch: 015 | loss: 0.24083 - acc: 0.9038 -- iter: 1408/3072
[A[ATraining Step: 1389  | total loss: [1m[32m0.23986[0m[0m | time: 28.204s
[2K
| Adam | epoch: 015 | loss: 0.23986 - acc: 0.9040 -- iter: 1440/3072
[A[ATraining Step: 1390  | total loss: [1m[32m0.23806[0m[0m | time: 28.857s
[2K
| Adam | epoch: 015 | loss: 0.23806 - acc: 0.9042 -- iter: 1472/3072
[A[ATraining Step: 1391  | total loss: [1m[32m0.25082[0m[0m | time: 29.469s
[2K
| Adam | epoch: 015 | loss: 0.25082 - acc: 0.8951 -- iter: 1504/3072
[A[ATraining Step: 1392  | total loss: [1m[32m0.26336[0m[0m | time: 30.080s
[2K
| Adam | epoch: 015 | loss: 0.26336 - acc: 0.8931 -- iter: 1536/3072
[A[ATraining Step: 1393  | total loss: [1m[32m0.25758[0m[0m | time: 30.690s
[2K
| Adam | epoch: 015 | loss: 0.25758 - acc: 0.9006 -- iter: 1568/3072
[A[ATraining Step: 1394  | total loss: [1m[32m0.26176[0m[0m | time: 31.294s
[2K
| Adam | epoch: 015 | loss: 0.26176 - acc: 0.9012 -- iter: 1600/3072
[A[ATraining Step: 1395  | total loss: [1m[32m0.26229[0m[0m | time: 31.893s
[2K
| Adam | epoch: 015 | loss: 0.26229 - acc: 0.9048 -- iter: 1632/3072
[A[ATraining Step: 1396  | total loss: [1m[32m0.26941[0m[0m | time: 32.514s
[2K
| Adam | epoch: 015 | loss: 0.26941 - acc: 0.8956 -- iter: 1664/3072
[A[ATraining Step: 1397  | total loss: [1m[32m0.27101[0m[0m | time: 33.122s
[2K
| Adam | epoch: 015 | loss: 0.27101 - acc: 0.8967 -- iter: 1696/3072
[A[ATraining Step: 1398  | total loss: [1m[32m0.28036[0m[0m | time: 33.732s
[2K
| Adam | epoch: 015 | loss: 0.28036 - acc: 0.8945 -- iter: 1728/3072
[A[ATraining Step: 1399  | total loss: [1m[32m0.27156[0m[0m | time: 34.335s
[2K
| Adam | epoch: 015 | loss: 0.27156 - acc: 0.9019 -- iter: 1760/3072
[A[ATraining Step: 1400  | total loss: [1m[32m0.27782[0m[0m | time: 38.004s
[2K
| Adam | epoch: 015 | loss: 0.27782 - acc: 0.8961 | val_loss: 0.52047 - val_acc: 0.7877 -- iter: 1792/3072
--
Training Step: 1401  | total loss: [1m[32m0.28062[0m[0m | time: 38.613s
[2K
| Adam | epoch: 015 | loss: 0.28062 - acc: 0.8909 -- iter: 1824/3072
[A[ATraining Step: 1402  | total loss: [1m[32m0.29324[0m[0m | time: 39.228s
[2K
| Adam | epoch: 015 | loss: 0.29324 - acc: 0.8862 -- iter: 1856/3072
[A[ATraining Step: 1403  | total loss: [1m[32m0.29406[0m[0m | time: 39.828s
[2K
| Adam | epoch: 015 | loss: 0.29406 - acc: 0.8850 -- iter: 1888/3072
[A[ATraining Step: 1404  | total loss: [1m[32m0.29077[0m[0m | time: 40.484s
[2K
| Adam | epoch: 015 | loss: 0.29077 - acc: 0.8903 -- iter: 1920/3072
[A[ATraining Step: 1405  | total loss: [1m[32m0.28469[0m[0m | time: 41.091s
[2K
| Adam | epoch: 015 | loss: 0.28469 - acc: 0.8950 -- iter: 1952/3072
[A[ATraining Step: 1406  | total loss: [1m[32m0.27809[0m[0m | time: 41.713s
[2K
| Adam | epoch: 015 | loss: 0.27809 - acc: 0.8961 -- iter: 1984/3072
[A[ATraining Step: 1407  | total loss: [1m[32m0.26283[0m[0m | time: 42.364s
[2K
| Adam | epoch: 015 | loss: 0.26283 - acc: 0.9003 -- iter: 2016/3072
[A[ATraining Step: 1408  | total loss: [1m[32m0.27643[0m[0m | time: 42.981s
[2K
| Adam | epoch: 015 | loss: 0.27643 - acc: 0.8915 -- iter: 2048/3072
[A[ATraining Step: 1409  | total loss: [1m[32m0.27910[0m[0m | time: 43.597s
[2K
| Adam | epoch: 015 | loss: 0.27910 - acc: 0.8836 -- iter: 2080/3072
[A[ATraining Step: 1410  | total loss: [1m[32m0.26926[0m[0m | time: 44.249s
[2K
| Adam | epoch: 015 | loss: 0.26926 - acc: 0.8890 -- iter: 2112/3072
[A[ATraining Step: 1411  | total loss: [1m[32m0.27298[0m[0m | time: 44.855s
[2K
| Adam | epoch: 015 | loss: 0.27298 - acc: 0.8907 -- iter: 2144/3072
[A[ATraining Step: 1412  | total loss: [1m[32m0.26354[0m[0m | time: 45.461s
[2K
| Adam | epoch: 015 | loss: 0.26354 - acc: 0.8923 -- iter: 2176/3072
[A[ATraining Step: 1413  | total loss: [1m[32m0.27034[0m[0m | time: 46.104s
[2K
| Adam | epoch: 015 | loss: 0.27034 - acc: 0.8874 -- iter: 2208/3072
[A[ATraining Step: 1414  | total loss: [1m[32m0.26385[0m[0m | time: 46.715s
[2K
| Adam | epoch: 015 | loss: 0.26385 - acc: 0.8893 -- iter: 2240/3072
[A[ATraining Step: 1415  | total loss: [1m[32m0.26195[0m[0m | time: 47.360s
[2K
| Adam | epoch: 015 | loss: 0.26195 - acc: 0.8910 -- iter: 2272/3072
[A[ATraining Step: 1416  | total loss: [1m[32m0.25828[0m[0m | time: 47.960s
[2K
| Adam | epoch: 015 | loss: 0.25828 - acc: 0.8894 -- iter: 2304/3072
[A[ATraining Step: 1417  | total loss: [1m[32m0.25948[0m[0m | time: 48.564s
[2K
| Adam | epoch: 015 | loss: 0.25948 - acc: 0.8911 -- iter: 2336/3072
[A[ATraining Step: 1418  | total loss: [1m[32m0.27195[0m[0m | time: 49.177s
[2K
| Adam | epoch: 015 | loss: 0.27195 - acc: 0.8832 -- iter: 2368/3072
[A[ATraining Step: 1419  | total loss: [1m[32m0.26879[0m[0m | time: 49.776s
[2K
| Adam | epoch: 015 | loss: 0.26879 - acc: 0.8855 -- iter: 2400/3072
[A[ATraining Step: 1420  | total loss: [1m[32m0.26249[0m[0m | time: 50.376s
[2K
| Adam | epoch: 015 | loss: 0.26249 - acc: 0.8907 -- iter: 2432/3072
[A[ATraining Step: 1421  | total loss: [1m[32m0.26811[0m[0m | time: 50.997s
[2K
| Adam | epoch: 015 | loss: 0.26811 - acc: 0.8860 -- iter: 2464/3072
[A[ATraining Step: 1422  | total loss: [1m[32m0.25968[0m[0m | time: 51.603s
[2K
| Adam | epoch: 015 | loss: 0.25968 - acc: 0.8912 -- iter: 2496/3072
[A[ATraining Step: 1423  | total loss: [1m[32m0.25304[0m[0m | time: 52.211s
[2K
| Adam | epoch: 015 | loss: 0.25304 - acc: 0.8927 -- iter: 2528/3072
[A[ATraining Step: 1424  | total loss: [1m[32m0.25522[0m[0m | time: 52.877s
[2K
| Adam | epoch: 015 | loss: 0.25522 - acc: 0.8909 -- iter: 2560/3072
[A[ATraining Step: 1425  | total loss: [1m[32m0.25955[0m[0m | time: 53.489s
[2K
| Adam | epoch: 015 | loss: 0.25955 - acc: 0.8956 -- iter: 2592/3072
[A[ATraining Step: 1426  | total loss: [1m[32m0.27932[0m[0m | time: 54.132s
[2K
| Adam | epoch: 015 | loss: 0.27932 - acc: 0.8904 -- iter: 2624/3072
[A[ATraining Step: 1427  | total loss: [1m[32m0.28585[0m[0m | time: 54.770s
[2K
| Adam | epoch: 015 | loss: 0.28585 - acc: 0.8857 -- iter: 2656/3072
[A[ATraining Step: 1428  | total loss: [1m[32m0.28502[0m[0m | time: 55.419s
[2K
| Adam | epoch: 015 | loss: 0.28502 - acc: 0.8815 -- iter: 2688/3072
[A[ATraining Step: 1429  | total loss: [1m[32m0.27413[0m[0m | time: 56.022s
[2K
| Adam | epoch: 015 | loss: 0.27413 - acc: 0.8902 -- iter: 2720/3072
[A[ATraining Step: 1430  | total loss: [1m[32m0.27245[0m[0m | time: 56.631s
[2K
| Adam | epoch: 015 | loss: 0.27245 - acc: 0.8950 -- iter: 2752/3072
[A[ATraining Step: 1431  | total loss: [1m[32m0.25510[0m[0m | time: 57.317s
[2K
| Adam | epoch: 015 | loss: 0.25510 - acc: 0.9055 -- iter: 2784/3072
[A[ATraining Step: 1432  | total loss: [1m[32m0.24531[0m[0m | time: 57.914s
[2K
| Adam | epoch: 015 | loss: 0.24531 - acc: 0.9087 -- iter: 2816/3072
[A[ATraining Step: 1433  | total loss: [1m[32m0.24601[0m[0m | time: 58.533s
[2K
| Adam | epoch: 015 | loss: 0.24601 - acc: 0.9084 -- iter: 2848/3072
[A[ATraining Step: 1434  | total loss: [1m[32m0.24585[0m[0m | time: 59.137s
[2K
| Adam | epoch: 015 | loss: 0.24585 - acc: 0.9145 -- iter: 2880/3072
[A[ATraining Step: 1435  | total loss: [1m[32m0.23673[0m[0m | time: 59.737s
[2K
| Adam | epoch: 015 | loss: 0.23673 - acc: 0.9168 -- iter: 2912/3072
[A[ATraining Step: 1436  | total loss: [1m[32m0.24299[0m[0m | time: 60.342s
[2K
| Adam | epoch: 015 | loss: 0.24299 - acc: 0.9095 -- iter: 2944/3072
[A[ATraining Step: 1437  | total loss: [1m[32m0.22823[0m[0m | time: 60.994s
[2K
| Adam | epoch: 015 | loss: 0.22823 - acc: 0.9185 -- iter: 2976/3072
[A[ATraining Step: 1438  | total loss: [1m[32m0.21918[0m[0m | time: 61.602s
[2K
| Adam | epoch: 015 | loss: 0.21918 - acc: 0.9235 -- iter: 3008/3072
[A[ATraining Step: 1439  | total loss: [1m[32m0.22946[0m[0m | time: 62.200s
[2K
| Adam | epoch: 015 | loss: 0.22946 - acc: 0.9249 -- iter: 3040/3072
[A[ATraining Step: 1440  | total loss: [1m[32m0.22215[0m[0m | time: 65.890s
[2K
| Adam | epoch: 015 | loss: 0.22215 - acc: 0.9293 | val_loss: 0.51779 - val_acc: 0.7825 -- iter: 3072/3072
--
Training Step: 1441  | total loss: [1m[32m0.22394[0m[0m | time: 0.740s
[2K
| Adam | epoch: 016 | loss: 0.22394 - acc: 0.9301 -- iter: 0032/3072
[A[ATraining Step: 1442  | total loss: [1m[32m0.23930[0m[0m | time: 1.342s
[2K
| Adam | epoch: 016 | loss: 0.23930 - acc: 0.9215 -- iter: 0064/3072
[A[ATraining Step: 1443  | total loss: [1m[32m0.24060[0m[0m | time: 1.965s
[2K
| Adam | epoch: 016 | loss: 0.24060 - acc: 0.9200 -- iter: 0096/3072
[A[ATraining Step: 1444  | total loss: [1m[32m0.23067[0m[0m | time: 2.572s
[2K
| Adam | epoch: 016 | loss: 0.23067 - acc: 0.9249 -- iter: 0128/3072
[A[ATraining Step: 1445  | total loss: [1m[32m0.22992[0m[0m | time: 3.184s
[2K
| Adam | epoch: 016 | loss: 0.22992 - acc: 0.9199 -- iter: 0160/3072
[A[ATraining Step: 1446  | total loss: [1m[32m0.22878[0m[0m | time: 3.796s
[2K
| Adam | epoch: 016 | loss: 0.22878 - acc: 0.9216 -- iter: 0192/3072
[A[ATraining Step: 1447  | total loss: [1m[32m0.24330[0m[0m | time: 4.428s
[2K
| Adam | epoch: 016 | loss: 0.24330 - acc: 0.9170 -- iter: 0224/3072
[A[ATraining Step: 1448  | total loss: [1m[32m0.23354[0m[0m | time: 5.093s
[2K
| Adam | epoch: 016 | loss: 0.23354 - acc: 0.9253 -- iter: 0256/3072
[A[ATraining Step: 1449  | total loss: [1m[32m0.22922[0m[0m | time: 5.792s
[2K
| Adam | epoch: 016 | loss: 0.22922 - acc: 0.9234 -- iter: 0288/3072
[A[ATraining Step: 1450  | total loss: [1m[32m0.21989[0m[0m | time: 6.394s
[2K
| Adam | epoch: 016 | loss: 0.21989 - acc: 0.9279 -- iter: 0320/3072
[A[ATraining Step: 1451  | total loss: [1m[32m0.21931[0m[0m | time: 7.030s
[2K
| Adam | epoch: 016 | loss: 0.21931 - acc: 0.9289 -- iter: 0352/3072
[A[ATraining Step: 1452  | total loss: [1m[32m0.22283[0m[0m | time: 7.640s
[2K
| Adam | epoch: 016 | loss: 0.22283 - acc: 0.9266 -- iter: 0384/3072
[A[ATraining Step: 1453  | total loss: [1m[32m0.21265[0m[0m | time: 8.301s
[2K
| Adam | epoch: 016 | loss: 0.21265 - acc: 0.9339 -- iter: 0416/3072
[A[ATraining Step: 1454  | total loss: [1m[32m0.21142[0m[0m | time: 8.914s
[2K
| Adam | epoch: 016 | loss: 0.21142 - acc: 0.9343 -- iter: 0448/3072
[A[ATraining Step: 1455  | total loss: [1m[32m0.21432[0m[0m | time: 9.531s
[2K
| Adam | epoch: 016 | loss: 0.21432 - acc: 0.9315 -- iter: 0480/3072
[A[ATraining Step: 1456  | total loss: [1m[32m0.22283[0m[0m | time: 10.135s
[2K
| Adam | epoch: 016 | loss: 0.22283 - acc: 0.9290 -- iter: 0512/3072
[A[ATraining Step: 1457  | total loss: [1m[32m0.22925[0m[0m | time: 10.736s
[2K
| Adam | epoch: 016 | loss: 0.22925 - acc: 0.9236 -- iter: 0544/3072
[A[ATraining Step: 1458  | total loss: [1m[32m0.22723[0m[0m | time: 11.362s
[2K
| Adam | epoch: 016 | loss: 0.22723 - acc: 0.9250 -- iter: 0576/3072
[A[ATraining Step: 1459  | total loss: [1m[32m0.22793[0m[0m | time: 12.066s
[2K
| Adam | epoch: 016 | loss: 0.22793 - acc: 0.9231 -- iter: 0608/3072
[A[ATraining Step: 1460  | total loss: [1m[32m0.23870[0m[0m | time: 12.663s
[2K
| Adam | epoch: 016 | loss: 0.23870 - acc: 0.9120 -- iter: 0640/3072
[A[ATraining Step: 1461  | total loss: [1m[32m0.23046[0m[0m | time: 13.308s
[2K
| Adam | epoch: 016 | loss: 0.23046 - acc: 0.9177 -- iter: 0672/3072
[A[ATraining Step: 1462  | total loss: [1m[32m0.23555[0m[0m | time: 14.015s
[2K
| Adam | epoch: 016 | loss: 0.23555 - acc: 0.9166 -- iter: 0704/3072
[A[ATraining Step: 1463  | total loss: [1m[32m0.23522[0m[0m | time: 14.633s
[2K
| Adam | epoch: 016 | loss: 0.23522 - acc: 0.9187 -- iter: 0736/3072
[A[ATraining Step: 1464  | total loss: [1m[32m0.23006[0m[0m | time: 15.232s
[2K
| Adam | epoch: 016 | loss: 0.23006 - acc: 0.9205 -- iter: 0768/3072
[A[ATraining Step: 1465  | total loss: [1m[32m0.22114[0m[0m | time: 15.907s
[2K
| Adam | epoch: 016 | loss: 0.22114 - acc: 0.9222 -- iter: 0800/3072
[A[ATraining Step: 1466  | total loss: [1m[32m0.21599[0m[0m | time: 16.528s
[2K
| Adam | epoch: 016 | loss: 0.21599 - acc: 0.9238 -- iter: 0832/3072
[A[ATraining Step: 1467  | total loss: [1m[32m0.23088[0m[0m | time: 17.163s
[2K
| Adam | epoch: 016 | loss: 0.23088 - acc: 0.9126 -- iter: 0864/3072
[A[ATraining Step: 1468  | total loss: [1m[32m0.21878[0m[0m | time: 17.938s
[2K
| Adam | epoch: 016 | loss: 0.21878 - acc: 0.9214 -- iter: 0896/3072
[A[ATraining Step: 1469  | total loss: [1m[32m0.22676[0m[0m | time: 18.553s
[2K
| Adam | epoch: 016 | loss: 0.22676 - acc: 0.9199 -- iter: 0928/3072
[A[ATraining Step: 1470  | total loss: [1m[32m0.22426[0m[0m | time: 19.178s
[2K
| Adam | epoch: 016 | loss: 0.22426 - acc: 0.9216 -- iter: 0960/3072
[A[ATraining Step: 1471  | total loss: [1m[32m0.23171[0m[0m | time: 19.770s
[2K
| Adam | epoch: 016 | loss: 0.23171 - acc: 0.9138 -- iter: 0992/3072
[A[ATraining Step: 1472  | total loss: [1m[32m0.22849[0m[0m | time: 20.467s
[2K
| Adam | epoch: 016 | loss: 0.22849 - acc: 0.9131 -- iter: 1024/3072
[A[ATraining Step: 1473  | total loss: [1m[32m0.24731[0m[0m | time: 21.077s
[2K
| Adam | epoch: 016 | loss: 0.24731 - acc: 0.9030 -- iter: 1056/3072
[A[ATraining Step: 1474  | total loss: [1m[32m0.24732[0m[0m | time: 21.723s
[2K
| Adam | epoch: 016 | loss: 0.24732 - acc: 0.8971 -- iter: 1088/3072
[A[ATraining Step: 1475  | total loss: [1m[32m0.25949[0m[0m | time: 22.313s
[2K
| Adam | epoch: 016 | loss: 0.25949 - acc: 0.8949 -- iter: 1120/3072
[A[ATraining Step: 1476  | total loss: [1m[32m0.26826[0m[0m | time: 22.959s
[2K
| Adam | epoch: 016 | loss: 0.26826 - acc: 0.8866 -- iter: 1152/3072
[A[ATraining Step: 1477  | total loss: [1m[32m0.26334[0m[0m | time: 23.568s
[2K
| Adam | epoch: 016 | loss: 0.26334 - acc: 0.8917 -- iter: 1184/3072
[A[ATraining Step: 1478  | total loss: [1m[32m0.25773[0m[0m | time: 24.200s
[2K
| Adam | epoch: 016 | loss: 0.25773 - acc: 0.8963 -- iter: 1216/3072
[A[ATraining Step: 1479  | total loss: [1m[32m0.25459[0m[0m | time: 24.865s
[2K
| Adam | epoch: 016 | loss: 0.25459 - acc: 0.9004 -- iter: 1248/3072
[A[ATraining Step: 1480  | total loss: [1m[32m0.24483[0m[0m | time: 25.465s
[2K
| Adam | epoch: 016 | loss: 0.24483 - acc: 0.9073 -- iter: 1280/3072
[A[ATraining Step: 1481  | total loss: [1m[32m0.24548[0m[0m | time: 26.076s
[2K
| Adam | epoch: 016 | loss: 0.24548 - acc: 0.9040 -- iter: 1312/3072
[A[ATraining Step: 1482  | total loss: [1m[32m0.25360[0m[0m | time: 26.725s
[2K
| Adam | epoch: 016 | loss: 0.25360 - acc: 0.9011 -- iter: 1344/3072
[A[ATraining Step: 1483  | total loss: [1m[32m0.24837[0m[0m | time: 27.385s
[2K
| Adam | epoch: 016 | loss: 0.24837 - acc: 0.9016 -- iter: 1376/3072
[A[ATraining Step: 1484  | total loss: [1m[32m0.26776[0m[0m | time: 28.012s
[2K
| Adam | epoch: 016 | loss: 0.26776 - acc: 0.8896 -- iter: 1408/3072
[A[ATraining Step: 1485  | total loss: [1m[32m0.26845[0m[0m | time: 28.633s
[2K
| Adam | epoch: 016 | loss: 0.26845 - acc: 0.8850 -- iter: 1440/3072
[A[ATraining Step: 1486  | total loss: [1m[32m0.27949[0m[0m | time: 29.245s
[2K
| Adam | epoch: 016 | loss: 0.27949 - acc: 0.8778 -- iter: 1472/3072
[A[ATraining Step: 1487  | total loss: [1m[32m0.28658[0m[0m | time: 29.850s
[2K
| Adam | epoch: 016 | loss: 0.28658 - acc: 0.8806 -- iter: 1504/3072
[A[ATraining Step: 1488  | total loss: [1m[32m0.27946[0m[0m | time: 30.463s
[2K
| Adam | epoch: 016 | loss: 0.27946 - acc: 0.8832 -- iter: 1536/3072
[A[ATraining Step: 1489  | total loss: [1m[32m0.28347[0m[0m | time: 31.071s
[2K
| Adam | epoch: 016 | loss: 0.28347 - acc: 0.8792 -- iter: 1568/3072
[A[ATraining Step: 1490  | total loss: [1m[32m0.30672[0m[0m | time: 31.675s
[2K
| Adam | epoch: 016 | loss: 0.30672 - acc: 0.8694 -- iter: 1600/3072
[A[ATraining Step: 1491  | total loss: [1m[32m0.30169[0m[0m | time: 32.291s
[2K
| Adam | epoch: 016 | loss: 0.30169 - acc: 0.8731 -- iter: 1632/3072
[A[ATraining Step: 1492  | total loss: [1m[32m0.29288[0m[0m | time: 32.894s
[2K
| Adam | epoch: 016 | loss: 0.29288 - acc: 0.8827 -- iter: 1664/3072
[A[ATraining Step: 1493  | total loss: [1m[32m0.28905[0m[0m | time: 33.499s
[2K
| Adam | epoch: 016 | loss: 0.28905 - acc: 0.8819 -- iter: 1696/3072
[A[ATraining Step: 1494  | total loss: [1m[32m0.27325[0m[0m | time: 34.150s
[2K
| Adam | epoch: 016 | loss: 0.27325 - acc: 0.8875 -- iter: 1728/3072
[A[ATraining Step: 1495  | total loss: [1m[32m0.28848[0m[0m | time: 34.751s
[2K
| Adam | epoch: 016 | loss: 0.28848 - acc: 0.8831 -- iter: 1760/3072
[A[ATraining Step: 1496  | total loss: [1m[32m0.33356[0m[0m | time: 35.356s
[2K
| Adam | epoch: 016 | loss: 0.33356 - acc: 0.8667 -- iter: 1792/3072
[A[ATraining Step: 1497  | total loss: [1m[32m0.32964[0m[0m | time: 35.979s
[2K
| Adam | epoch: 016 | loss: 0.32964 - acc: 0.8644 -- iter: 1824/3072
[A[ATraining Step: 1498  | total loss: [1m[32m0.36236[0m[0m | time: 36.615s
[2K
| Adam | epoch: 016 | loss: 0.36236 - acc: 0.8467 -- iter: 1856/3072
[A[ATraining Step: 1499  | total loss: [1m[32m0.33939[0m[0m | time: 37.256s
[2K
| Adam | epoch: 016 | loss: 0.33939 - acc: 0.8589 -- iter: 1888/3072
[A[ATraining Step: 1500  | total loss: [1m[32m0.32596[0m[0m | time: 37.873s
[2K
| Adam | epoch: 016 | loss: 0.32596 - acc: 0.8636 -- iter: 1920/3072
[A[ATraining Step: 1501  | total loss: [1m[32m0.31043[0m[0m | time: 38.568s
[2K
| Adam | epoch: 016 | loss: 0.31043 - acc: 0.8710 -- iter: 1952/3072
[A[ATraining Step: 1502  | total loss: [1m[32m0.32352[0m[0m | time: 39.254s
[2K
| Adam | epoch: 016 | loss: 0.32352 - acc: 0.8652 -- iter: 1984/3072
[A[ATraining Step: 1503  | total loss: [1m[32m0.33148[0m[0m | time: 39.865s
[2K
| Adam | epoch: 016 | loss: 0.33148 - acc: 0.8568 -- iter: 2016/3072
[A[ATraining Step: 1504  | total loss: [1m[32m0.35055[0m[0m | time: 40.479s
[2K
| Adam | epoch: 016 | loss: 0.35055 - acc: 0.8398 -- iter: 2048/3072
[A[ATraining Step: 1505  | total loss: [1m[32m0.33564[0m[0m | time: 41.088s
[2K
| Adam | epoch: 016 | loss: 0.33564 - acc: 0.8496 -- iter: 2080/3072
[A[ATraining Step: 1506  | total loss: [1m[32m0.33195[0m[0m | time: 41.703s
[2K
| Adam | epoch: 016 | loss: 0.33195 - acc: 0.8521 -- iter: 2112/3072
[A[ATraining Step: 1507  | total loss: [1m[32m0.32512[0m[0m | time: 42.337s
[2K
| Adam | epoch: 016 | loss: 0.32512 - acc: 0.8638 -- iter: 2144/3072
[A[ATraining Step: 1508  | total loss: [1m[32m0.30953[0m[0m | time: 42.950s
[2K
| Adam | epoch: 016 | loss: 0.30953 - acc: 0.8743 -- iter: 2176/3072
[A[ATraining Step: 1509  | total loss: [1m[32m0.30511[0m[0m | time: 43.554s
[2K
| Adam | epoch: 016 | loss: 0.30511 - acc: 0.8744 -- iter: 2208/3072
[A[ATraining Step: 1510  | total loss: [1m[32m0.30145[0m[0m | time: 44.152s
[2K
| Adam | epoch: 016 | loss: 0.30145 - acc: 0.8776 -- iter: 2240/3072
[A[ATraining Step: 1511  | total loss: [1m[32m0.29758[0m[0m | time: 44.820s
[2K
| Adam | epoch: 016 | loss: 0.29758 - acc: 0.8742 -- iter: 2272/3072
[A[ATraining Step: 1512  | total loss: [1m[32m0.28792[0m[0m | time: 45.422s
[2K
| Adam | epoch: 016 | loss: 0.28792 - acc: 0.8743 -- iter: 2304/3072
[A[ATraining Step: 1513  | total loss: [1m[32m0.28243[0m[0m | time: 46.017s
[2K
| Adam | epoch: 016 | loss: 0.28243 - acc: 0.8712 -- iter: 2336/3072
[A[ATraining Step: 1514  | total loss: [1m[32m0.28446[0m[0m | time: 46.618s
[2K
| Adam | epoch: 016 | loss: 0.28446 - acc: 0.8747 -- iter: 2368/3072
[A[ATraining Step: 1515  | total loss: [1m[32m0.28239[0m[0m | time: 47.241s
[2K
| Adam | epoch: 016 | loss: 0.28239 - acc: 0.8747 -- iter: 2400/3072
[A[ATraining Step: 1516  | total loss: [1m[32m0.27315[0m[0m | time: 47.882s
[2K
| Adam | epoch: 016 | loss: 0.27315 - acc: 0.8810 -- iter: 2432/3072
[A[ATraining Step: 1517  | total loss: [1m[32m0.26279[0m[0m | time: 48.512s
[2K
| Adam | epoch: 016 | loss: 0.26279 - acc: 0.8867 -- iter: 2464/3072
[A[ATraining Step: 1518  | total loss: [1m[32m0.25449[0m[0m | time: 49.186s
[2K
| Adam | epoch: 016 | loss: 0.25449 - acc: 0.8918 -- iter: 2496/3072
[A[ATraining Step: 1519  | total loss: [1m[32m0.24472[0m[0m | time: 49.791s
[2K
| Adam | epoch: 016 | loss: 0.24472 - acc: 0.8963 -- iter: 2528/3072
[A[ATraining Step: 1520  | total loss: [1m[32m0.23669[0m[0m | time: 50.419s
[2K
| Adam | epoch: 016 | loss: 0.23669 - acc: 0.9036 -- iter: 2560/3072
[A[ATraining Step: 1521  | total loss: [1m[32m0.22980[0m[0m | time: 51.077s
[2K
| Adam | epoch: 016 | loss: 0.22980 - acc: 0.9070 -- iter: 2592/3072
[A[ATraining Step: 1522  | total loss: [1m[32m0.22456[0m[0m | time: 51.725s
[2K
| Adam | epoch: 016 | loss: 0.22456 - acc: 0.9100 -- iter: 2624/3072
[A[ATraining Step: 1523  | total loss: [1m[32m0.21527[0m[0m | time: 52.345s
[2K
| Adam | epoch: 016 | loss: 0.21527 - acc: 0.9159 -- iter: 2656/3072
[A[ATraining Step: 1524  | total loss: [1m[32m0.22016[0m[0m | time: 52.974s
[2K
| Adam | epoch: 016 | loss: 0.22016 - acc: 0.9180 -- iter: 2688/3072
[A[ATraining Step: 1525  | total loss: [1m[32m0.22783[0m[0m | time: 53.566s
[2K
| Adam | epoch: 016 | loss: 0.22783 - acc: 0.9137 -- iter: 2720/3072
[A[ATraining Step: 1526  | total loss: [1m[32m0.22205[0m[0m | time: 54.173s
[2K
| Adam | epoch: 016 | loss: 0.22205 - acc: 0.9161 -- iter: 2752/3072
[A[ATraining Step: 1527  | total loss: [1m[32m0.21718[0m[0m | time: 54.818s
[2K
| Adam | epoch: 016 | loss: 0.21718 - acc: 0.9183 -- iter: 2784/3072
[A[ATraining Step: 1528  | total loss: [1m[32m0.20957[0m[0m | time: 55.419s
[2K
| Adam | epoch: 016 | loss: 0.20957 - acc: 0.9202 -- iter: 2816/3072
[A[ATraining Step: 1529  | total loss: [1m[32m0.22268[0m[0m | time: 56.024s
[2K
| Adam | epoch: 016 | loss: 0.22268 - acc: 0.9125 -- iter: 2848/3072
[A[ATraining Step: 1530  | total loss: [1m[32m0.21054[0m[0m | time: 56.652s
[2K
| Adam | epoch: 016 | loss: 0.21054 - acc: 0.9213 -- iter: 2880/3072
[A[ATraining Step: 1531  | total loss: [1m[32m0.20644[0m[0m | time: 57.256s
[2K
| Adam | epoch: 016 | loss: 0.20644 - acc: 0.9229 -- iter: 2912/3072
[A[ATraining Step: 1532  | total loss: [1m[32m0.19721[0m[0m | time: 57.858s
[2K
| Adam | epoch: 016 | loss: 0.19721 - acc: 0.9306 -- iter: 2944/3072
[A[ATraining Step: 1533  | total loss: [1m[32m0.19307[0m[0m | time: 58.513s
[2K
| Adam | epoch: 016 | loss: 0.19307 - acc: 0.9344 -- iter: 2976/3072
[A[ATraining Step: 1534  | total loss: [1m[32m0.18474[0m[0m | time: 59.129s
[2K
| Adam | epoch: 016 | loss: 0.18474 - acc: 0.9347 -- iter: 3008/3072
[A[ATraining Step: 1535  | total loss: [1m[32m0.19435[0m[0m | time: 59.771s
[2K
| Adam | epoch: 016 | loss: 0.19435 - acc: 0.9319 -- iter: 3040/3072
[A[ATraining Step: 1536  | total loss: [1m[32m0.19851[0m[0m | time: 63.474s
[2K
| Adam | epoch: 016 | loss: 0.19851 - acc: 0.9293 | val_loss: 0.50584 - val_acc: 0.8106 -- iter: 3072/3072
--
Training Step: 1537  | total loss: [1m[32m0.19015[0m[0m | time: 0.651s
[2K
| Adam | epoch: 017 | loss: 0.19015 - acc: 0.9364 -- iter: 0032/3072
[A[ATraining Step: 1538  | total loss: [1m[32m0.18615[0m[0m | time: 1.275s
[2K
| Adam | epoch: 017 | loss: 0.18615 - acc: 0.9396 -- iter: 0064/3072
[A[ATraining Step: 1539  | total loss: [1m[32m0.20221[0m[0m | time: 1.872s
[2K
| Adam | epoch: 017 | loss: 0.20221 - acc: 0.9300 -- iter: 0096/3072
[A[ATraining Step: 1540  | total loss: [1m[32m0.20356[0m[0m | time: 2.483s
[2K
| Adam | epoch: 017 | loss: 0.20356 - acc: 0.9245 -- iter: 0128/3072
[A[ATraining Step: 1541  | total loss: [1m[32m0.20092[0m[0m | time: 3.097s
[2K
| Adam | epoch: 017 | loss: 0.20092 - acc: 0.9227 -- iter: 0160/3072
[A[ATraining Step: 1542  | total loss: [1m[32m0.19564[0m[0m | time: 3.725s
[2K
| Adam | epoch: 017 | loss: 0.19564 - acc: 0.9273 -- iter: 0192/3072
[A[ATraining Step: 1543  | total loss: [1m[32m0.19730[0m[0m | time: 4.342s
[2K
| Adam | epoch: 017 | loss: 0.19730 - acc: 0.9283 -- iter: 0224/3072
[A[ATraining Step: 1544  | total loss: [1m[32m0.19556[0m[0m | time: 4.957s
[2K
| Adam | epoch: 017 | loss: 0.19556 - acc: 0.9292 -- iter: 0256/3072
[A[ATraining Step: 1545  | total loss: [1m[32m0.18846[0m[0m | time: 5.570s
[2K
| Adam | epoch: 017 | loss: 0.18846 - acc: 0.9301 -- iter: 0288/3072
[A[ATraining Step: 1546  | total loss: [1m[32m0.18038[0m[0m | time: 6.183s
[2K
| Adam | epoch: 017 | loss: 0.18038 - acc: 0.9371 -- iter: 0320/3072
[A[ATraining Step: 1547  | total loss: [1m[32m0.17589[0m[0m | time: 6.789s
[2K
| Adam | epoch: 017 | loss: 0.17589 - acc: 0.9402 -- iter: 0352/3072
[A[ATraining Step: 1548  | total loss: [1m[32m0.17190[0m[0m | time: 7.420s
[2K
| Adam | epoch: 017 | loss: 0.17190 - acc: 0.9431 -- iter: 0384/3072
[A[ATraining Step: 1549  | total loss: [1m[32m0.16203[0m[0m | time: 8.028s
[2K
| Adam | epoch: 017 | loss: 0.16203 - acc: 0.9488 -- iter: 0416/3072
[A[ATraining Step: 1550  | total loss: [1m[32m0.17280[0m[0m | time: 8.626s
[2K
| Adam | epoch: 017 | loss: 0.17280 - acc: 0.9445 -- iter: 0448/3072
[A[ATraining Step: 1551  | total loss: [1m[32m0.18014[0m[0m | time: 9.240s
[2K
| Adam | epoch: 017 | loss: 0.18014 - acc: 0.9407 -- iter: 0480/3072
[A[ATraining Step: 1552  | total loss: [1m[32m0.17891[0m[0m | time: 9.855s
[2K
| Adam | epoch: 017 | loss: 0.17891 - acc: 0.9435 -- iter: 0512/3072
[A[ATraining Step: 1553  | total loss: [1m[32m0.17688[0m[0m | time: 10.508s
[2K
| Adam | epoch: 017 | loss: 0.17688 - acc: 0.9429 -- iter: 0544/3072
[A[ATraining Step: 1554  | total loss: [1m[32m0.16969[0m[0m | time: 11.143s
[2K
| Adam | epoch: 017 | loss: 0.16969 - acc: 0.9455 -- iter: 0576/3072
[A[ATraining Step: 1555  | total loss: [1m[32m0.16819[0m[0m | time: 11.746s
[2K
| Adam | epoch: 017 | loss: 0.16819 - acc: 0.9416 -- iter: 0608/3072
[A[ATraining Step: 1556  | total loss: [1m[32m0.16538[0m[0m | time: 12.362s
[2K
| Adam | epoch: 017 | loss: 0.16538 - acc: 0.9443 -- iter: 0640/3072
[A[ATraining Step: 1557  | total loss: [1m[32m0.16798[0m[0m | time: 13.016s
[2K
| Adam | epoch: 017 | loss: 0.16798 - acc: 0.9436 -- iter: 0672/3072
[A[ATraining Step: 1558  | total loss: [1m[32m0.18074[0m[0m | time: 13.634s
[2K
| Adam | epoch: 017 | loss: 0.18074 - acc: 0.9367 -- iter: 0704/3072
[A[ATraining Step: 1559  | total loss: [1m[32m0.18323[0m[0m | time: 14.231s
[2K
| Adam | epoch: 017 | loss: 0.18323 - acc: 0.9368 -- iter: 0736/3072
[A[ATraining Step: 1560  | total loss: [1m[32m0.17594[0m[0m | time: 14.841s
[2K
| Adam | epoch: 017 | loss: 0.17594 - acc: 0.9431 -- iter: 0768/3072
[A[ATraining Step: 1561  | total loss: [1m[32m0.17678[0m[0m | time: 15.441s
[2K
| Adam | epoch: 017 | loss: 0.17678 - acc: 0.9394 -- iter: 0800/3072
[A[ATraining Step: 1562  | total loss: [1m[32m0.17385[0m[0m | time: 16.064s
[2K
| Adam | epoch: 017 | loss: 0.17385 - acc: 0.9393 -- iter: 0832/3072
[A[ATraining Step: 1563  | total loss: [1m[32m0.17583[0m[0m | time: 16.742s
[2K
| Adam | epoch: 017 | loss: 0.17583 - acc: 0.9391 -- iter: 0864/3072
[A[ATraining Step: 1564  | total loss: [1m[32m0.19324[0m[0m | time: 17.343s
[2K
| Adam | epoch: 017 | loss: 0.19324 - acc: 0.9327 -- iter: 0896/3072
[A[ATraining Step: 1565  | total loss: [1m[32m0.20426[0m[0m | time: 17.944s
[2K
| Adam | epoch: 017 | loss: 0.20426 - acc: 0.9269 -- iter: 0928/3072
[A[ATraining Step: 1566  | total loss: [1m[32m0.20133[0m[0m | time: 18.569s
[2K
| Adam | epoch: 017 | loss: 0.20133 - acc: 0.9280 -- iter: 0960/3072
[A[ATraining Step: 1567  | total loss: [1m[32m0.20307[0m[0m | time: 19.179s
[2K
| Adam | epoch: 017 | loss: 0.20307 - acc: 0.9289 -- iter: 0992/3072
[A[ATraining Step: 1568  | total loss: [1m[32m0.20982[0m[0m | time: 19.797s
[2K
| Adam | epoch: 017 | loss: 0.20982 - acc: 0.9204 -- iter: 1024/3072
[A[ATraining Step: 1569  | total loss: [1m[32m0.21784[0m[0m | time: 20.398s
[2K
| Adam | epoch: 017 | loss: 0.21784 - acc: 0.9190 -- iter: 1056/3072
[A[ATraining Step: 1570  | total loss: [1m[32m0.21867[0m[0m | time: 21.036s
[2K
| Adam | epoch: 017 | loss: 0.21867 - acc: 0.9146 -- iter: 1088/3072
[A[ATraining Step: 1571  | total loss: [1m[32m0.21205[0m[0m | time: 21.676s
[2K
| Adam | epoch: 017 | loss: 0.21205 - acc: 0.9231 -- iter: 1120/3072
[A[ATraining Step: 1572  | total loss: [1m[32m0.20618[0m[0m | time: 22.326s
[2K
| Adam | epoch: 017 | loss: 0.20618 - acc: 0.9246 -- iter: 1152/3072
[A[ATraining Step: 1573  | total loss: [1m[32m0.21307[0m[0m | time: 22.943s
[2K
| Adam | epoch: 017 | loss: 0.21307 - acc: 0.9259 -- iter: 1184/3072
[A[ATraining Step: 1574  | total loss: [1m[32m0.20753[0m[0m | time: 23.594s
[2K
| Adam | epoch: 017 | loss: 0.20753 - acc: 0.9301 -- iter: 1216/3072
[A[ATraining Step: 1575  | total loss: [1m[32m0.19748[0m[0m | time: 24.250s
[2K
| Adam | epoch: 017 | loss: 0.19748 - acc: 0.9340 -- iter: 1248/3072
[A[ATraining Step: 1576  | total loss: [1m[32m0.19434[0m[0m | time: 24.864s
[2K
| Adam | epoch: 017 | loss: 0.19434 - acc: 0.9375 -- iter: 1280/3072
[A[ATraining Step: 1577  | total loss: [1m[32m0.20303[0m[0m | time: 25.508s
[2K
| Adam | epoch: 017 | loss: 0.20303 - acc: 0.9344 -- iter: 1312/3072
[A[ATraining Step: 1578  | total loss: [1m[32m0.21530[0m[0m | time: 26.115s
[2K
| Adam | epoch: 017 | loss: 0.21530 - acc: 0.9190 -- iter: 1344/3072
[A[ATraining Step: 1579  | total loss: [1m[32m0.21336[0m[0m | time: 26.728s
[2K
| Adam | epoch: 017 | loss: 0.21336 - acc: 0.9209 -- iter: 1376/3072
[A[ATraining Step: 1580  | total loss: [1m[32m0.23052[0m[0m | time: 27.331s
[2K
| Adam | epoch: 017 | loss: 0.23052 - acc: 0.9132 -- iter: 1408/3072
[A[ATraining Step: 1581  | total loss: [1m[32m0.21973[0m[0m | time: 27.945s
[2K
| Adam | epoch: 017 | loss: 0.21973 - acc: 0.9219 -- iter: 1440/3072
[A[ATraining Step: 1582  | total loss: [1m[32m0.20567[0m[0m | time: 28.568s
[2K
| Adam | epoch: 017 | loss: 0.20567 - acc: 0.9297 -- iter: 1472/3072
[A[ATraining Step: 1583  | total loss: [1m[32m0.22649[0m[0m | time: 29.183s
[2K
| Adam | epoch: 017 | loss: 0.22649 - acc: 0.9242 -- iter: 1504/3072
[A[ATraining Step: 1584  | total loss: [1m[32m0.22513[0m[0m | time: 29.774s
[2K
| Adam | epoch: 017 | loss: 0.22513 - acc: 0.9193 -- iter: 1536/3072
[A[ATraining Step: 1585  | total loss: [1m[32m0.21052[0m[0m | time: 30.378s
[2K
| Adam | epoch: 017 | loss: 0.21052 - acc: 0.9274 -- iter: 1568/3072
[A[ATraining Step: 1586  | total loss: [1m[32m0.20623[0m[0m | time: 30.977s
[2K
| Adam | epoch: 017 | loss: 0.20623 - acc: 0.9252 -- iter: 1600/3072
[A[ATraining Step: 1587  | total loss: [1m[32m0.19672[0m[0m | time: 31.589s
[2K
| Adam | epoch: 017 | loss: 0.19672 - acc: 0.9296 -- iter: 1632/3072
[A[ATraining Step: 1588  | total loss: [1m[32m0.20727[0m[0m | time: 32.281s
[2K
| Adam | epoch: 017 | loss: 0.20727 - acc: 0.9273 -- iter: 1664/3072
[A[ATraining Step: 1589  | total loss: [1m[32m0.19817[0m[0m | time: 32.898s
[2K
| Adam | epoch: 017 | loss: 0.19817 - acc: 0.9345 -- iter: 1696/3072
[A[ATraining Step: 1590  | total loss: [1m[32m0.18949[0m[0m | time: 33.526s
[2K
| Adam | epoch: 017 | loss: 0.18949 - acc: 0.9380 -- iter: 1728/3072
[A[ATraining Step: 1591  | total loss: [1m[32m0.19010[0m[0m | time: 34.135s
[2K
| Adam | epoch: 017 | loss: 0.19010 - acc: 0.9348 -- iter: 1760/3072
[A[ATraining Step: 1592  | total loss: [1m[32m0.18499[0m[0m | time: 34.906s
[2K
| Adam | epoch: 017 | loss: 0.18499 - acc: 0.9351 -- iter: 1792/3072
[A[ATraining Step: 1593  | total loss: [1m[32m0.18496[0m[0m | time: 35.499s
[2K
| Adam | epoch: 017 | loss: 0.18496 - acc: 0.9353 -- iter: 1824/3072
[A[ATraining Step: 1594  | total loss: [1m[32m0.18121[0m[0m | time: 36.124s
[2K
| Adam | epoch: 017 | loss: 0.18121 - acc: 0.9418 -- iter: 1856/3072
[A[ATraining Step: 1595  | total loss: [1m[32m0.17921[0m[0m | time: 36.736s
[2K
| Adam | epoch: 017 | loss: 0.17921 - acc: 0.9382 -- iter: 1888/3072
[A[ATraining Step: 1596  | total loss: [1m[32m0.19970[0m[0m | time: 37.342s
[2K
| Adam | epoch: 017 | loss: 0.19970 - acc: 0.9256 -- iter: 1920/3072
[A[ATraining Step: 1597  | total loss: [1m[32m0.20169[0m[0m | time: 37.955s
[2K
| Adam | epoch: 017 | loss: 0.20169 - acc: 0.9268 -- iter: 1952/3072
[A[ATraining Step: 1598  | total loss: [1m[32m0.19293[0m[0m | time: 38.559s
[2K
| Adam | epoch: 017 | loss: 0.19293 - acc: 0.9310 -- iter: 1984/3072
[A[ATraining Step: 1599  | total loss: [1m[32m0.20302[0m[0m | time: 39.174s
[2K
| Adam | epoch: 017 | loss: 0.20302 - acc: 0.9223 -- iter: 2016/3072
[A[ATraining Step: 1600  | total loss: [1m[32m0.20663[0m[0m | time: 42.866s
[2K
| Adam | epoch: 017 | loss: 0.20663 - acc: 0.9269 | val_loss: 0.56970 - val_acc: 0.7721 -- iter: 2048/3072
--
Training Step: 1601  | total loss: [1m[32m0.22871[0m[0m | time: 43.496s
[2K
| Adam | epoch: 017 | loss: 0.22871 - acc: 0.9155 -- iter: 2080/3072
[A[ATraining Step: 1602  | total loss: [1m[32m0.23993[0m[0m | time: 44.126s
[2K
| Adam | epoch: 017 | loss: 0.23993 - acc: 0.9052 -- iter: 2112/3072
[A[ATraining Step: 1603  | total loss: [1m[32m0.25194[0m[0m | time: 44.731s
[2K
| Adam | epoch: 017 | loss: 0.25194 - acc: 0.8991 -- iter: 2144/3072
[A[ATraining Step: 1604  | total loss: [1m[32m0.24477[0m[0m | time: 45.344s
[2K
| Adam | epoch: 017 | loss: 0.24477 - acc: 0.9060 -- iter: 2176/3072
[A[ATraining Step: 1605  | total loss: [1m[32m0.23652[0m[0m | time: 45.994s
[2K
| Adam | epoch: 017 | loss: 0.23652 - acc: 0.9060 -- iter: 2208/3072
[A[ATraining Step: 1606  | total loss: [1m[32m0.23384[0m[0m | time: 46.587s
[2K
| Adam | epoch: 017 | loss: 0.23384 - acc: 0.9029 -- iter: 2240/3072
[A[ATraining Step: 1607  | total loss: [1m[32m0.24198[0m[0m | time: 47.206s
[2K
| Adam | epoch: 017 | loss: 0.24198 - acc: 0.8939 -- iter: 2272/3072
[A[ATraining Step: 1608  | total loss: [1m[32m0.23088[0m[0m | time: 47.811s
[2K
| Adam | epoch: 017 | loss: 0.23088 - acc: 0.8983 -- iter: 2304/3072
[A[ATraining Step: 1609  | total loss: [1m[32m0.21870[0m[0m | time: 48.426s
[2K
| Adam | epoch: 017 | loss: 0.21870 - acc: 0.9053 -- iter: 2336/3072
[A[ATraining Step: 1610  | total loss: [1m[32m0.21948[0m[0m | time: 49.050s
[2K
| Adam | epoch: 017 | loss: 0.21948 - acc: 0.9085 -- iter: 2368/3072
[A[ATraining Step: 1611  | total loss: [1m[32m0.22160[0m[0m | time: 49.757s
[2K
| Adam | epoch: 017 | loss: 0.22160 - acc: 0.9052 -- iter: 2400/3072
[A[ATraining Step: 1612  | total loss: [1m[32m0.21489[0m[0m | time: 50.368s
[2K
| Adam | epoch: 017 | loss: 0.21489 - acc: 0.9053 -- iter: 2432/3072
[A[ATraining Step: 1613  | total loss: [1m[32m0.22647[0m[0m | time: 50.969s
[2K
| Adam | epoch: 017 | loss: 0.22647 - acc: 0.8991 -- iter: 2464/3072
[A[ATraining Step: 1614  | total loss: [1m[32m0.22287[0m[0m | time: 51.584s
[2K
| Adam | epoch: 017 | loss: 0.22287 - acc: 0.8998 -- iter: 2496/3072
[A[ATraining Step: 1615  | total loss: [1m[32m0.21918[0m[0m | time: 52.172s
[2K
| Adam | epoch: 017 | loss: 0.21918 - acc: 0.9005 -- iter: 2528/3072
[A[ATraining Step: 1616  | total loss: [1m[32m0.21407[0m[0m | time: 52.973s
[2K
| Adam | epoch: 017 | loss: 0.21407 - acc: 0.9042 -- iter: 2560/3072
[A[ATraining Step: 1617  | total loss: [1m[32m0.23604[0m[0m | time: 53.613s
[2K
| Adam | epoch: 017 | loss: 0.23604 - acc: 0.9013 -- iter: 2592/3072
[A[ATraining Step: 1618  | total loss: [1m[32m0.22152[0m[0m | time: 54.239s
[2K
| Adam | epoch: 017 | loss: 0.22152 - acc: 0.9080 -- iter: 2624/3072
[A[ATraining Step: 1619  | total loss: [1m[32m0.21205[0m[0m | time: 54.853s
[2K
| Adam | epoch: 017 | loss: 0.21205 - acc: 0.9141 -- iter: 2656/3072
[A[ATraining Step: 1620  | total loss: [1m[32m0.20136[0m[0m | time: 55.501s
[2K
| Adam | epoch: 017 | loss: 0.20136 - acc: 0.9196 -- iter: 2688/3072
[A[ATraining Step: 1621  | total loss: [1m[32m0.19421[0m[0m | time: 56.143s
[2K
| Adam | epoch: 017 | loss: 0.19421 - acc: 0.9245 -- iter: 2720/3072
[A[ATraining Step: 1622  | total loss: [1m[32m0.18177[0m[0m | time: 56.769s
[2K
| Adam | epoch: 017 | loss: 0.18177 - acc: 0.9320 -- iter: 2752/3072
[A[ATraining Step: 1623  | total loss: [1m[32m0.17458[0m[0m | time: 57.438s
[2K
| Adam | epoch: 017 | loss: 0.17458 - acc: 0.9357 -- iter: 2784/3072
[A[ATraining Step: 1624  | total loss: [1m[32m0.17098[0m[0m | time: 58.077s
[2K
| Adam | epoch: 017 | loss: 0.17098 - acc: 0.9390 -- iter: 2816/3072
[A[ATraining Step: 1625  | total loss: [1m[32m0.16216[0m[0m | time: 58.727s
[2K
| Adam | epoch: 017 | loss: 0.16216 - acc: 0.9451 -- iter: 2848/3072
[A[ATraining Step: 1626  | total loss: [1m[32m0.16616[0m[0m | time: 59.371s
[2K
| Adam | epoch: 017 | loss: 0.16616 - acc: 0.9443 -- iter: 2880/3072
[A[ATraining Step: 1627  | total loss: [1m[32m0.15761[0m[0m | time: 59.994s
[2K
| Adam | epoch: 017 | loss: 0.15761 - acc: 0.9499 -- iter: 2912/3072
[A[ATraining Step: 1628  | total loss: [1m[32m0.15068[0m[0m | time: 60.590s
[2K
| Adam | epoch: 017 | loss: 0.15068 - acc: 0.9518 -- iter: 2944/3072
[A[ATraining Step: 1629  | total loss: [1m[32m0.15516[0m[0m | time: 61.261s
[2K
| Adam | epoch: 017 | loss: 0.15516 - acc: 0.9472 -- iter: 2976/3072
[A[ATraining Step: 1630  | total loss: [1m[32m0.14536[0m[0m | time: 61.868s
[2K
| Adam | epoch: 017 | loss: 0.14536 - acc: 0.9525 -- iter: 3008/3072
[A[ATraining Step: 1631  | total loss: [1m[32m0.14340[0m[0m | time: 62.557s
[2K
| Adam | epoch: 017 | loss: 0.14340 - acc: 0.9541 -- iter: 3040/3072
[A[ATraining Step: 1632  | total loss: [1m[32m0.14561[0m[0m | time: 66.231s
[2K
| Adam | epoch: 017 | loss: 0.14561 - acc: 0.9556 | val_loss: 0.54094 - val_acc: 0.8065 -- iter: 3072/3072
--
Training Step: 1633  | total loss: [1m[32m0.16170[0m[0m | time: 0.598s
[2K
| Adam | epoch: 018 | loss: 0.16170 - acc: 0.9475 -- iter: 0032/3072
[A[ATraining Step: 1634  | total loss: [1m[32m0.15563[0m[0m | time: 1.200s
[2K
| Adam | epoch: 018 | loss: 0.15563 - acc: 0.9528 -- iter: 0064/3072
[A[ATraining Step: 1635  | total loss: [1m[32m0.15033[0m[0m | time: 1.803s
[2K
| Adam | epoch: 018 | loss: 0.15033 - acc: 0.9544 -- iter: 0096/3072
[A[ATraining Step: 1636  | total loss: [1m[32m0.15316[0m[0m | time: 2.422s
[2K
| Adam | epoch: 018 | loss: 0.15316 - acc: 0.9527 -- iter: 0128/3072
[A[ATraining Step: 1637  | total loss: [1m[32m0.15624[0m[0m | time: 3.070s
[2K
| Adam | epoch: 018 | loss: 0.15624 - acc: 0.9512 -- iter: 0160/3072
[A[ATraining Step: 1638  | total loss: [1m[32m0.16573[0m[0m | time: 3.681s
[2K
| Adam | epoch: 018 | loss: 0.16573 - acc: 0.9436 -- iter: 0192/3072
[A[ATraining Step: 1639  | total loss: [1m[32m0.17281[0m[0m | time: 4.296s
[2K
| Adam | epoch: 018 | loss: 0.17281 - acc: 0.9398 -- iter: 0224/3072
[A[ATraining Step: 1640  | total loss: [1m[32m0.16795[0m[0m | time: 4.908s
[2K
| Adam | epoch: 018 | loss: 0.16795 - acc: 0.9365 -- iter: 0256/3072
[A[ATraining Step: 1641  | total loss: [1m[32m0.16795[0m[0m | time: 5.507s
[2K
| Adam | epoch: 018 | loss: 0.16795 - acc: 0.9303 -- iter: 0288/3072
[A[ATraining Step: 1642  | total loss: [1m[32m0.16092[0m[0m | time: 6.116s
[2K
| Adam | epoch: 018 | loss: 0.16092 - acc: 0.9342 -- iter: 0320/3072
[A[ATraining Step: 1643  | total loss: [1m[32m0.16033[0m[0m | time: 6.758s
[2K
| Adam | epoch: 018 | loss: 0.16033 - acc: 0.9376 -- iter: 0352/3072
[A[ATraining Step: 1644  | total loss: [1m[32m0.15684[0m[0m | time: 7.356s
[2K
| Adam | epoch: 018 | loss: 0.15684 - acc: 0.9407 -- iter: 0384/3072
[A[ATraining Step: 1645  | total loss: [1m[32m0.15251[0m[0m | time: 7.969s
[2K
| Adam | epoch: 018 | loss: 0.15251 - acc: 0.9467 -- iter: 0416/3072
[A[ATraining Step: 1646  | total loss: [1m[32m0.14610[0m[0m | time: 8.568s
[2K
| Adam | epoch: 018 | loss: 0.14610 - acc: 0.9520 -- iter: 0448/3072
[A[ATraining Step: 1647  | total loss: [1m[32m0.13851[0m[0m | time: 9.175s
[2K
| Adam | epoch: 018 | loss: 0.13851 - acc: 0.9537 -- iter: 0480/3072
[A[ATraining Step: 1648  | total loss: [1m[32m0.15719[0m[0m | time: 9.786s
[2K
| Adam | epoch: 018 | loss: 0.15719 - acc: 0.9489 -- iter: 0512/3072
[A[ATraining Step: 1649  | total loss: [1m[32m0.14983[0m[0m | time: 10.397s
[2K
| Adam | epoch: 018 | loss: 0.14983 - acc: 0.9509 -- iter: 0544/3072
[A[ATraining Step: 1650  | total loss: [1m[32m0.14109[0m[0m | time: 11.081s
[2K
| Adam | epoch: 018 | loss: 0.14109 - acc: 0.9558 -- iter: 0576/3072
[A[ATraining Step: 1651  | total loss: [1m[32m0.15129[0m[0m | time: 11.681s
[2K
| Adam | epoch: 018 | loss: 0.15129 - acc: 0.9509 -- iter: 0608/3072
[A[ATraining Step: 1652  | total loss: [1m[32m0.15505[0m[0m | time: 12.309s
[2K
| Adam | epoch: 018 | loss: 0.15505 - acc: 0.9464 -- iter: 0640/3072
[A[ATraining Step: 1653  | total loss: [1m[32m0.16642[0m[0m | time: 12.911s
[2K
| Adam | epoch: 018 | loss: 0.16642 - acc: 0.9424 -- iter: 0672/3072
[A[ATraining Step: 1654  | total loss: [1m[32m0.16362[0m[0m | time: 13.512s
[2K
| Adam | epoch: 018 | loss: 0.16362 - acc: 0.9419 -- iter: 0704/3072
[A[ATraining Step: 1655  | total loss: [1m[32m0.16644[0m[0m | time: 14.127s
[2K
| Adam | epoch: 018 | loss: 0.16644 - acc: 0.9383 -- iter: 0736/3072
[A[ATraining Step: 1656  | total loss: [1m[32m0.16708[0m[0m | time: 14.730s
[2K
| Adam | epoch: 018 | loss: 0.16708 - acc: 0.9351 -- iter: 0768/3072
[A[ATraining Step: 1657  | total loss: [1m[32m0.18887[0m[0m | time: 15.383s
[2K
| Adam | epoch: 018 | loss: 0.18887 - acc: 0.9260 -- iter: 0800/3072
[A[ATraining Step: 1658  | total loss: [1m[32m0.19206[0m[0m | time: 15.984s
[2K
| Adam | epoch: 018 | loss: 0.19206 - acc: 0.9271 -- iter: 0832/3072
[A[ATraining Step: 1659  | total loss: [1m[32m0.18716[0m[0m | time: 16.591s
[2K
| Adam | epoch: 018 | loss: 0.18716 - acc: 0.9282 -- iter: 0864/3072
[A[ATraining Step: 1660  | total loss: [1m[32m0.18859[0m[0m | time: 17.193s
[2K
| Adam | epoch: 018 | loss: 0.18859 - acc: 0.9260 -- iter: 0896/3072
[A[ATraining Step: 1661  | total loss: [1m[32m0.18102[0m[0m | time: 17.874s
[2K
| Adam | epoch: 018 | loss: 0.18102 - acc: 0.9334 -- iter: 0928/3072
[A[ATraining Step: 1662  | total loss: [1m[32m0.18277[0m[0m | time: 18.478s
[2K
| Adam | epoch: 018 | loss: 0.18277 - acc: 0.9307 -- iter: 0960/3072
[A[ATraining Step: 1663  | total loss: [1m[32m0.17604[0m[0m | time: 19.094s
[2K
| Adam | epoch: 018 | loss: 0.17604 - acc: 0.9376 -- iter: 0992/3072
[A[ATraining Step: 1664  | total loss: [1m[32m0.18658[0m[0m | time: 19.696s
[2K
| Adam | epoch: 018 | loss: 0.18658 - acc: 0.9345 -- iter: 1024/3072
[A[ATraining Step: 1665  | total loss: [1m[32m0.17876[0m[0m | time: 20.300s
[2K
| Adam | epoch: 018 | loss: 0.17876 - acc: 0.9410 -- iter: 1056/3072
[A[ATraining Step: 1666  | total loss: [1m[32m0.17787[0m[0m | time: 20.970s
[2K
| Adam | epoch: 018 | loss: 0.17787 - acc: 0.9438 -- iter: 1088/3072
[A[ATraining Step: 1667  | total loss: [1m[32m0.17156[0m[0m | time: 21.601s
[2K
| Adam | epoch: 018 | loss: 0.17156 - acc: 0.9463 -- iter: 1120/3072
[A[ATraining Step: 1668  | total loss: [1m[32m0.17112[0m[0m | time: 22.206s
[2K
| Adam | epoch: 018 | loss: 0.17112 - acc: 0.9423 -- iter: 1152/3072
[A[ATraining Step: 1669  | total loss: [1m[32m0.17462[0m[0m | time: 22.833s
[2K
| Adam | epoch: 018 | loss: 0.17462 - acc: 0.9418 -- iter: 1184/3072
[A[ATraining Step: 1670  | total loss: [1m[32m0.16771[0m[0m | time: 23.446s
[2K
| Adam | epoch: 018 | loss: 0.16771 - acc: 0.9445 -- iter: 1216/3072
[A[ATraining Step: 1671  | total loss: [1m[32m0.16718[0m[0m | time: 24.051s
[2K
| Adam | epoch: 018 | loss: 0.16718 - acc: 0.9438 -- iter: 1248/3072
[A[ATraining Step: 1672  | total loss: [1m[32m0.15694[0m[0m | time: 24.670s
[2K
| Adam | epoch: 018 | loss: 0.15694 - acc: 0.9494 -- iter: 1280/3072
[A[ATraining Step: 1673  | total loss: [1m[32m0.15381[0m[0m | time: 25.281s
[2K
| Adam | epoch: 018 | loss: 0.15381 - acc: 0.9482 -- iter: 1312/3072
[A[ATraining Step: 1674  | total loss: [1m[32m0.15939[0m[0m | time: 25.949s
[2K
| Adam | epoch: 018 | loss: 0.15939 - acc: 0.9440 -- iter: 1344/3072
[A[ATraining Step: 1675  | total loss: [1m[32m0.16304[0m[0m | time: 26.610s
[2K
| Adam | epoch: 018 | loss: 0.16304 - acc: 0.9434 -- iter: 1376/3072
[A[ATraining Step: 1676  | total loss: [1m[32m0.16555[0m[0m | time: 27.250s
[2K
| Adam | epoch: 018 | loss: 0.16555 - acc: 0.9397 -- iter: 1408/3072
[A[ATraining Step: 1677  | total loss: [1m[32m0.16385[0m[0m | time: 27.890s
[2K
| Adam | epoch: 018 | loss: 0.16385 - acc: 0.9426 -- iter: 1440/3072
[A[ATraining Step: 1678  | total loss: [1m[32m0.15953[0m[0m | time: 28.528s
[2K
| Adam | epoch: 018 | loss: 0.15953 - acc: 0.9483 -- iter: 1472/3072
[A[ATraining Step: 1679  | total loss: [1m[32m0.16020[0m[0m | time: 29.162s
[2K
| Adam | epoch: 018 | loss: 0.16020 - acc: 0.9472 -- iter: 1504/3072
[A[ATraining Step: 1680  | total loss: [1m[32m0.15215[0m[0m | time: 29.765s
[2K
| Adam | epoch: 018 | loss: 0.15215 - acc: 0.9494 -- iter: 1536/3072
[A[ATraining Step: 1681  | total loss: [1m[32m0.15197[0m[0m | time: 30.392s
[2K
| Adam | epoch: 018 | loss: 0.15197 - acc: 0.9482 -- iter: 1568/3072
[A[ATraining Step: 1682  | total loss: [1m[32m0.15092[0m[0m | time: 31.001s
[2K
| Adam | epoch: 018 | loss: 0.15092 - acc: 0.9471 -- iter: 1600/3072
[A[ATraining Step: 1683  | total loss: [1m[32m0.14969[0m[0m | time: 31.663s
[2K
| Adam | epoch: 018 | loss: 0.14969 - acc: 0.9462 -- iter: 1632/3072
[A[ATraining Step: 1684  | total loss: [1m[32m0.17014[0m[0m | time: 32.274s
[2K
| Adam | epoch: 018 | loss: 0.17014 - acc: 0.9422 -- iter: 1664/3072
[A[ATraining Step: 1685  | total loss: [1m[32m0.17915[0m[0m | time: 32.896s
[2K
| Adam | epoch: 018 | loss: 0.17915 - acc: 0.9386 -- iter: 1696/3072
[A[ATraining Step: 1686  | total loss: [1m[32m0.18151[0m[0m | time: 33.535s
[2K
| Adam | epoch: 018 | loss: 0.18151 - acc: 0.9385 -- iter: 1728/3072
[A[ATraining Step: 1687  | total loss: [1m[32m0.18224[0m[0m | time: 34.206s
[2K
| Adam | epoch: 018 | loss: 0.18224 - acc: 0.9353 -- iter: 1760/3072
[A[ATraining Step: 1688  | total loss: [1m[32m0.17758[0m[0m | time: 34.833s
[2K
| Adam | epoch: 018 | loss: 0.17758 - acc: 0.9386 -- iter: 1792/3072
[A[ATraining Step: 1689  | total loss: [1m[32m0.18094[0m[0m | time: 35.531s
[2K
| Adam | epoch: 018 | loss: 0.18094 - acc: 0.9354 -- iter: 1824/3072
[A[ATraining Step: 1690  | total loss: [1m[32m0.17759[0m[0m | time: 36.148s
[2K
| Adam | epoch: 018 | loss: 0.17759 - acc: 0.9356 -- iter: 1856/3072
[A[ATraining Step: 1691  | total loss: [1m[32m0.17838[0m[0m | time: 36.759s
[2K
| Adam | epoch: 018 | loss: 0.17838 - acc: 0.9358 -- iter: 1888/3072
[A[ATraining Step: 1692  | total loss: [1m[32m0.18072[0m[0m | time: 37.363s
[2K
| Adam | epoch: 018 | loss: 0.18072 - acc: 0.9328 -- iter: 1920/3072
[A[ATraining Step: 1693  | total loss: [1m[32m0.18025[0m[0m | time: 37.968s
[2K
| Adam | epoch: 018 | loss: 0.18025 - acc: 0.9302 -- iter: 1952/3072
[A[ATraining Step: 1694  | total loss: [1m[32m0.18270[0m[0m | time: 38.578s
[2K
| Adam | epoch: 018 | loss: 0.18270 - acc: 0.9246 -- iter: 1984/3072
[A[ATraining Step: 1695  | total loss: [1m[32m0.19726[0m[0m | time: 39.233s
[2K
| Adam | epoch: 018 | loss: 0.19726 - acc: 0.9166 -- iter: 2016/3072
[A[ATraining Step: 1696  | total loss: [1m[32m0.22072[0m[0m | time: 39.871s
[2K
| Adam | epoch: 018 | loss: 0.22072 - acc: 0.9062 -- iter: 2048/3072
[A[ATraining Step: 1697  | total loss: [1m[32m0.20808[0m[0m | time: 40.488s
[2K
| Adam | epoch: 018 | loss: 0.20808 - acc: 0.9124 -- iter: 2080/3072
[A[ATraining Step: 1698  | total loss: [1m[32m0.19994[0m[0m | time: 41.095s
[2K
| Adam | epoch: 018 | loss: 0.19994 - acc: 0.9180 -- iter: 2112/3072
[A[ATraining Step: 1699  | total loss: [1m[32m0.19110[0m[0m | time: 41.715s
[2K
| Adam | epoch: 018 | loss: 0.19110 - acc: 0.9200 -- iter: 2144/3072
[A[ATraining Step: 1700  | total loss: [1m[32m0.20047[0m[0m | time: 42.331s
[2K
| Adam | epoch: 018 | loss: 0.20047 - acc: 0.9092 -- iter: 2176/3072
[A[ATraining Step: 1701  | total loss: [1m[32m0.21608[0m[0m | time: 42.922s
[2K
| Adam | epoch: 018 | loss: 0.21608 - acc: 0.9027 -- iter: 2208/3072
[A[ATraining Step: 1702  | total loss: [1m[32m0.23545[0m[0m | time: 43.573s
[2K
| Adam | epoch: 018 | loss: 0.23545 - acc: 0.8937 -- iter: 2240/3072
[A[ATraining Step: 1703  | total loss: [1m[32m0.25238[0m[0m | time: 44.271s
[2K
| Adam | epoch: 018 | loss: 0.25238 - acc: 0.8824 -- iter: 2272/3072
[A[ATraining Step: 1704  | total loss: [1m[32m0.24020[0m[0m | time: 44.875s
[2K
| Adam | epoch: 018 | loss: 0.24020 - acc: 0.8879 -- iter: 2304/3072
[A[ATraining Step: 1705  | total loss: [1m[32m0.22704[0m[0m | time: 45.490s
[2K
| Adam | epoch: 018 | loss: 0.22704 - acc: 0.8929 -- iter: 2336/3072
[A[ATraining Step: 1706  | total loss: [1m[32m0.23992[0m[0m | time: 46.099s
[2K
| Adam | epoch: 018 | loss: 0.23992 - acc: 0.8849 -- iter: 2368/3072
[A[ATraining Step: 1707  | total loss: [1m[32m0.24670[0m[0m | time: 46.708s
[2K
| Adam | epoch: 018 | loss: 0.24670 - acc: 0.8807 -- iter: 2400/3072
[A[ATraining Step: 1708  | total loss: [1m[32m0.22671[0m[0m | time: 47.313s
[2K
| Adam | epoch: 018 | loss: 0.22671 - acc: 0.8927 -- iter: 2432/3072
[A[ATraining Step: 1709  | total loss: [1m[32m0.22465[0m[0m | time: 47.954s
[2K
| Adam | epoch: 018 | loss: 0.22465 - acc: 0.8940 -- iter: 2464/3072
[A[ATraining Step: 1710  | total loss: [1m[32m0.21702[0m[0m | time: 48.666s
[2K
| Adam | epoch: 018 | loss: 0.21702 - acc: 0.8984 -- iter: 2496/3072
[A[ATraining Step: 1711  | total loss: [1m[32m0.21084[0m[0m | time: 49.309s
[2K
| Adam | epoch: 018 | loss: 0.21084 - acc: 0.9023 -- iter: 2528/3072
[A[ATraining Step: 1712  | total loss: [1m[32m0.20528[0m[0m | time: 49.921s
[2K
| Adam | epoch: 018 | loss: 0.20528 - acc: 0.9027 -- iter: 2560/3072
[A[ATraining Step: 1713  | total loss: [1m[32m0.20104[0m[0m | time: 50.524s
[2K
| Adam | epoch: 018 | loss: 0.20104 - acc: 0.9062 -- iter: 2592/3072
[A[ATraining Step: 1714  | total loss: [1m[32m0.19851[0m[0m | time: 51.127s
[2K
| Adam | epoch: 018 | loss: 0.19851 - acc: 0.9093 -- iter: 2624/3072
[A[ATraining Step: 1715  | total loss: [1m[32m0.21010[0m[0m | time: 51.739s
[2K
| Adam | epoch: 018 | loss: 0.21010 - acc: 0.9059 -- iter: 2656/3072
[A[ATraining Step: 1716  | total loss: [1m[32m0.21050[0m[0m | time: 52.387s
[2K
| Adam | epoch: 018 | loss: 0.21050 - acc: 0.9059 -- iter: 2688/3072
[A[ATraining Step: 1717  | total loss: [1m[32m0.23200[0m[0m | time: 52.994s
[2K
| Adam | epoch: 018 | loss: 0.23200 - acc: 0.8934 -- iter: 2720/3072
[A[ATraining Step: 1718  | total loss: [1m[32m0.22148[0m[0m | time: 53.604s
[2K
| Adam | epoch: 018 | loss: 0.22148 - acc: 0.9010 -- iter: 2752/3072
[A[ATraining Step: 1719  | total loss: [1m[32m0.21185[0m[0m | time: 54.235s
[2K
| Adam | epoch: 018 | loss: 0.21185 - acc: 0.9015 -- iter: 2784/3072
[A[ATraining Step: 1720  | total loss: [1m[32m0.20462[0m[0m | time: 54.846s
[2K
| Adam | epoch: 018 | loss: 0.20462 - acc: 0.9082 -- iter: 2816/3072
[A[ATraining Step: 1721  | total loss: [1m[32m0.21986[0m[0m | time: 55.447s
[2K
| Adam | epoch: 018 | loss: 0.21986 - acc: 0.9049 -- iter: 2848/3072
[A[ATraining Step: 1722  | total loss: [1m[32m0.21739[0m[0m | time: 56.056s
[2K
| Adam | epoch: 018 | loss: 0.21739 - acc: 0.9019 -- iter: 2880/3072
[A[ATraining Step: 1723  | total loss: [1m[32m0.21045[0m[0m | time: 56.666s
[2K
| Adam | epoch: 018 | loss: 0.21045 - acc: 0.9055 -- iter: 2912/3072
[A[ATraining Step: 1724  | total loss: [1m[32m0.20216[0m[0m | time: 57.265s
[2K
| Adam | epoch: 018 | loss: 0.20216 - acc: 0.9087 -- iter: 2944/3072
[A[ATraining Step: 1725  | total loss: [1m[32m0.19843[0m[0m | time: 57.873s
[2K
| Adam | epoch: 018 | loss: 0.19843 - acc: 0.9084 -- iter: 2976/3072
[A[ATraining Step: 1726  | total loss: [1m[32m0.18279[0m[0m | time: 58.491s
[2K
| Adam | epoch: 018 | loss: 0.18279 - acc: 0.9176 -- iter: 3008/3072
[A[ATraining Step: 1727  | total loss: [1m[32m0.17047[0m[0m | time: 59.133s
[2K
| Adam | epoch: 018 | loss: 0.17047 - acc: 0.9258 -- iter: 3040/3072
[A[ATraining Step: 1728  | total loss: [1m[32m0.17221[0m[0m | time: 62.849s
[2K
| Adam | epoch: 018 | loss: 0.17221 - acc: 0.9270 | val_loss: 0.66701 - val_acc: 0.7669 -- iter: 3072/3072
--
Training Step: 1729  | total loss: [1m[32m0.17277[0m[0m | time: 0.614s
[2K
| Adam | epoch: 019 | loss: 0.17277 - acc: 0.9280 -- iter: 0032/3072
[A[ATraining Step: 1730  | total loss: [1m[32m0.18270[0m[0m | time: 1.240s
[2K
| Adam | epoch: 019 | loss: 0.18270 - acc: 0.9196 -- iter: 0064/3072
[A[ATraining Step: 1731  | total loss: [1m[32m0.17577[0m[0m | time: 1.845s
[2K
| Adam | epoch: 019 | loss: 0.17577 - acc: 0.9214 -- iter: 0096/3072
[A[ATraining Step: 1732  | total loss: [1m[32m0.16178[0m[0m | time: 2.542s
[2K
| Adam | epoch: 019 | loss: 0.16178 - acc: 0.9293 -- iter: 0128/3072
[A[ATraining Step: 1733  | total loss: [1m[32m0.15744[0m[0m | time: 3.163s
[2K
| Adam | epoch: 019 | loss: 0.15744 - acc: 0.9332 -- iter: 0160/3072
[A[ATraining Step: 1734  | total loss: [1m[32m0.15427[0m[0m | time: 3.780s
[2K
| Adam | epoch: 019 | loss: 0.15427 - acc: 0.9336 -- iter: 0192/3072
[A[ATraining Step: 1735  | total loss: [1m[32m0.15635[0m[0m | time: 4.427s
[2K
| Adam | epoch: 019 | loss: 0.15635 - acc: 0.9309 -- iter: 0224/3072
[A[ATraining Step: 1736  | total loss: [1m[32m0.16648[0m[0m | time: 5.070s
[2K
| Adam | epoch: 019 | loss: 0.16648 - acc: 0.9191 -- iter: 0256/3072
[A[ATraining Step: 1737  | total loss: [1m[32m0.17766[0m[0m | time: 5.681s
[2K
| Adam | epoch: 019 | loss: 0.17766 - acc: 0.9178 -- iter: 0288/3072
[A[ATraining Step: 1738  | total loss: [1m[32m0.16821[0m[0m | time: 6.314s
[2K
| Adam | epoch: 019 | loss: 0.16821 - acc: 0.9260 -- iter: 0320/3072
[A[ATraining Step: 1739  | total loss: [1m[32m0.15843[0m[0m | time: 6.970s
[2K
| Adam | epoch: 019 | loss: 0.15843 - acc: 0.9334 -- iter: 0352/3072
[A[ATraining Step: 1740  | total loss: [1m[32m0.16123[0m[0m | time: 7.609s
[2K
| Adam | epoch: 019 | loss: 0.16123 - acc: 0.9276 -- iter: 0384/3072
[A[ATraining Step: 1741  | total loss: [1m[32m0.16046[0m[0m | time: 8.215s
[2K
| Adam | epoch: 019 | loss: 0.16046 - acc: 0.9286 -- iter: 0416/3072
[A[ATraining Step: 1742  | total loss: [1m[32m0.17850[0m[0m | time: 8.832s
[2K
| Adam | epoch: 019 | loss: 0.17850 - acc: 0.9170 -- iter: 0448/3072
[A[ATraining Step: 1743  | total loss: [1m[32m0.18907[0m[0m | time: 9.447s
[2K
| Adam | epoch: 019 | loss: 0.18907 - acc: 0.9128 -- iter: 0480/3072
[A[ATraining Step: 1744  | total loss: [1m[32m0.20438[0m[0m | time: 10.048s
[2K
| Adam | epoch: 019 | loss: 0.20438 - acc: 0.9027 -- iter: 0512/3072
[A[ATraining Step: 1745  | total loss: [1m[32m0.19282[0m[0m | time: 10.662s
[2K
| Adam | epoch: 019 | loss: 0.19282 - acc: 0.9125 -- iter: 0544/3072
[A[ATraining Step: 1746  | total loss: [1m[32m0.18076[0m[0m | time: 11.338s
[2K
| Adam | epoch: 019 | loss: 0.18076 - acc: 0.9212 -- iter: 0576/3072
[A[ATraining Step: 1747  | total loss: [1m[32m0.17016[0m[0m | time: 11.954s
[2K
| Adam | epoch: 019 | loss: 0.17016 - acc: 0.9291 -- iter: 0608/3072
[A[ATraining Step: 1748  | total loss: [1m[32m0.16706[0m[0m | time: 12.551s
[2K
| Adam | epoch: 019 | loss: 0.16706 - acc: 0.9299 -- iter: 0640/3072
[A[ATraining Step: 1749  | total loss: [1m[32m0.15528[0m[0m | time: 13.157s
[2K
| Adam | epoch: 019 | loss: 0.15528 - acc: 0.9369 -- iter: 0672/3072
[A[ATraining Step: 1750  | total loss: [1m[32m0.15752[0m[0m | time: 13.826s
[2K
| Adam | epoch: 019 | loss: 0.15752 - acc: 0.9339 -- iter: 0704/3072
[A[ATraining Step: 1751  | total loss: [1m[32m0.15925[0m[0m | time: 14.549s
[2K
| Adam | epoch: 019 | loss: 0.15925 - acc: 0.9311 -- iter: 0736/3072
[A[ATraining Step: 1752  | total loss: [1m[32m0.15892[0m[0m | time: 15.338s
[2K
| Adam | epoch: 019 | loss: 0.15892 - acc: 0.9317 -- iter: 0768/3072
[A[ATraining Step: 1753  | total loss: [1m[32m0.16465[0m[0m | time: 16.015s
[2K
| Adam | epoch: 019 | loss: 0.16465 - acc: 0.9292 -- iter: 0800/3072
[A[ATraining Step: 1754  | total loss: [1m[32m0.15819[0m[0m | time: 16.620s
[2K
| Adam | epoch: 019 | loss: 0.15819 - acc: 0.9332 -- iter: 0832/3072
[A[ATraining Step: 1755  | total loss: [1m[32m0.15288[0m[0m | time: 17.239s
[2K
| Adam | epoch: 019 | loss: 0.15288 - acc: 0.9336 -- iter: 0864/3072
[A[ATraining Step: 1756  | total loss: [1m[32m0.15851[0m[0m | time: 17.868s
[2K
| Adam | epoch: 019 | loss: 0.15851 - acc: 0.9277 -- iter: 0896/3072
[A[ATraining Step: 1757  | total loss: [1m[32m0.15940[0m[0m | time: 18.473s
[2K
| Adam | epoch: 019 | loss: 0.15940 - acc: 0.9287 -- iter: 0928/3072
[A[ATraining Step: 1758  | total loss: [1m[32m0.15776[0m[0m | time: 19.090s
[2K
| Adam | epoch: 019 | loss: 0.15776 - acc: 0.9327 -- iter: 0960/3072
[A[ATraining Step: 1759  | total loss: [1m[32m0.15166[0m[0m | time: 19.695s
[2K
| Adam | epoch: 019 | loss: 0.15166 - acc: 0.9363 -- iter: 0992/3072
[A[ATraining Step: 1760  | total loss: [1m[32m0.14968[0m[0m | time: 20.318s
[2K
| Adam | epoch: 019 | loss: 0.14968 - acc: 0.9364 -- iter: 1024/3072
[A[ATraining Step: 1761  | total loss: [1m[32m0.15265[0m[0m | time: 20.979s
[2K
| Adam | epoch: 019 | loss: 0.15265 - acc: 0.9334 -- iter: 1056/3072
[A[ATraining Step: 1762  | total loss: [1m[32m0.15027[0m[0m | time: 21.589s
[2K
| Adam | epoch: 019 | loss: 0.15027 - acc: 0.9338 -- iter: 1088/3072
[A[ATraining Step: 1763  | total loss: [1m[32m0.14209[0m[0m | time: 22.191s
[2K
| Adam | epoch: 019 | loss: 0.14209 - acc: 0.9404 -- iter: 1120/3072
[A[ATraining Step: 1764  | total loss: [1m[32m0.13812[0m[0m | time: 22.792s
[2K
| Adam | epoch: 019 | loss: 0.13812 - acc: 0.9464 -- iter: 1152/3072
[A[ATraining Step: 1765  | total loss: [1m[32m0.13949[0m[0m | time: 23.410s
[2K
| Adam | epoch: 019 | loss: 0.13949 - acc: 0.9455 -- iter: 1184/3072
[A[ATraining Step: 1766  | total loss: [1m[32m0.14884[0m[0m | time: 24.044s
[2K
| Adam | epoch: 019 | loss: 0.14884 - acc: 0.9385 -- iter: 1216/3072
[A[ATraining Step: 1767  | total loss: [1m[32m0.16579[0m[0m | time: 24.701s
[2K
| Adam | epoch: 019 | loss: 0.16579 - acc: 0.9352 -- iter: 1248/3072
[A[ATraining Step: 1768  | total loss: [1m[32m0.16740[0m[0m | time: 25.309s
[2K
| Adam | epoch: 019 | loss: 0.16740 - acc: 0.9386 -- iter: 1280/3072
[A[ATraining Step: 1769  | total loss: [1m[32m0.15733[0m[0m | time: 25.992s
[2K
| Adam | epoch: 019 | loss: 0.15733 - acc: 0.9416 -- iter: 1312/3072
[A[ATraining Step: 1770  | total loss: [1m[32m0.15791[0m[0m | time: 26.591s
[2K
| Adam | epoch: 019 | loss: 0.15791 - acc: 0.9412 -- iter: 1344/3072
[A[ATraining Step: 1771  | total loss: [1m[32m0.15352[0m[0m | time: 27.202s
[2K
| Adam | epoch: 019 | loss: 0.15352 - acc: 0.9408 -- iter: 1376/3072
[A[ATraining Step: 1772  | total loss: [1m[32m0.14744[0m[0m | time: 27.817s
[2K
| Adam | epoch: 019 | loss: 0.14744 - acc: 0.9467 -- iter: 1408/3072
[A[ATraining Step: 1773  | total loss: [1m[32m0.16264[0m[0m | time: 28.465s
[2K
| Adam | epoch: 019 | loss: 0.16264 - acc: 0.9364 -- iter: 1440/3072
[A[ATraining Step: 1774  | total loss: [1m[32m0.16020[0m[0m | time: 29.094s
[2K
| Adam | epoch: 019 | loss: 0.16020 - acc: 0.9334 -- iter: 1472/3072
[A[ATraining Step: 1775  | total loss: [1m[32m0.15449[0m[0m | time: 29.754s
[2K
| Adam | epoch: 019 | loss: 0.15449 - acc: 0.9401 -- iter: 1504/3072
[A[ATraining Step: 1776  | total loss: [1m[32m0.15338[0m[0m | time: 30.386s
[2K
| Adam | epoch: 019 | loss: 0.15338 - acc: 0.9367 -- iter: 1536/3072
[A[ATraining Step: 1777  | total loss: [1m[32m0.15555[0m[0m | time: 30.998s
[2K
| Adam | epoch: 019 | loss: 0.15555 - acc: 0.9337 -- iter: 1568/3072
[A[ATraining Step: 1778  | total loss: [1m[32m0.17461[0m[0m | time: 31.616s
[2K
| Adam | epoch: 019 | loss: 0.17461 - acc: 0.9215 -- iter: 1600/3072
[A[ATraining Step: 1779  | total loss: [1m[32m0.17435[0m[0m | time: 32.224s
[2K
| Adam | epoch: 019 | loss: 0.17435 - acc: 0.9231 -- iter: 1632/3072
[A[ATraining Step: 1780  | total loss: [1m[32m0.16863[0m[0m | time: 32.835s
[2K
| Adam | epoch: 019 | loss: 0.16863 - acc: 0.9277 -- iter: 1664/3072
[A[ATraining Step: 1781  | total loss: [1m[32m0.16379[0m[0m | time: 33.478s
[2K
| Adam | epoch: 019 | loss: 0.16379 - acc: 0.9318 -- iter: 1696/3072
[A[ATraining Step: 1782  | total loss: [1m[32m0.15898[0m[0m | time: 34.074s
[2K
| Adam | epoch: 019 | loss: 0.15898 - acc: 0.9324 -- iter: 1728/3072
[A[ATraining Step: 1783  | total loss: [1m[32m0.15612[0m[0m | time: 34.713s
[2K
| Adam | epoch: 019 | loss: 0.15612 - acc: 0.9329 -- iter: 1760/3072
[A[ATraining Step: 1784  | total loss: [1m[32m0.16082[0m[0m | time: 35.370s
[2K
| Adam | epoch: 019 | loss: 0.16082 - acc: 0.9302 -- iter: 1792/3072
[A[ATraining Step: 1785  | total loss: [1m[32m0.15615[0m[0m | time: 36.019s
[2K
| Adam | epoch: 019 | loss: 0.15615 - acc: 0.9278 -- iter: 1824/3072
[A[ATraining Step: 1786  | total loss: [1m[32m0.15431[0m[0m | time: 36.635s
[2K
| Adam | epoch: 019 | loss: 0.15431 - acc: 0.9288 -- iter: 1856/3072
[A[ATraining Step: 1787  | total loss: [1m[32m0.15198[0m[0m | time: 37.269s
[2K
| Adam | epoch: 019 | loss: 0.15198 - acc: 0.9328 -- iter: 1888/3072
[A[ATraining Step: 1788  | total loss: [1m[32m0.15327[0m[0m | time: 37.882s
[2K
| Adam | epoch: 019 | loss: 0.15327 - acc: 0.9333 -- iter: 1920/3072
[A[ATraining Step: 1789  | total loss: [1m[32m0.14996[0m[0m | time: 38.492s
[2K
| Adam | epoch: 019 | loss: 0.14996 - acc: 0.9337 -- iter: 1952/3072
[A[ATraining Step: 1790  | total loss: [1m[32m0.14540[0m[0m | time: 39.123s
[2K
| Adam | epoch: 019 | loss: 0.14540 - acc: 0.9403 -- iter: 1984/3072
[A[ATraining Step: 1791  | total loss: [1m[32m0.16631[0m[0m | time: 39.755s
[2K
| Adam | epoch: 019 | loss: 0.16631 - acc: 0.9307 -- iter: 2016/3072
[A[ATraining Step: 1792  | total loss: [1m[32m0.17055[0m[0m | time: 40.355s
[2K
| Adam | epoch: 019 | loss: 0.17055 - acc: 0.9251 -- iter: 2048/3072
[A[ATraining Step: 1793  | total loss: [1m[32m0.16135[0m[0m | time: 40.986s
[2K
| Adam | epoch: 019 | loss: 0.16135 - acc: 0.9326 -- iter: 2080/3072
[A[ATraining Step: 1794  | total loss: [1m[32m0.15818[0m[0m | time: 41.621s
[2K
| Adam | epoch: 019 | loss: 0.15818 - acc: 0.9331 -- iter: 2112/3072
[A[ATraining Step: 1795  | total loss: [1m[32m0.15370[0m[0m | time: 42.278s
[2K
| Adam | epoch: 019 | loss: 0.15370 - acc: 0.9366 -- iter: 2144/3072
[A[ATraining Step: 1796  | total loss: [1m[32m0.14760[0m[0m | time: 42.889s
[2K
| Adam | epoch: 019 | loss: 0.14760 - acc: 0.9430 -- iter: 2176/3072
[A[ATraining Step: 1797  | total loss: [1m[32m0.15269[0m[0m | time: 43.504s
[2K
| Adam | epoch: 019 | loss: 0.15269 - acc: 0.9424 -- iter: 2208/3072
[A[ATraining Step: 1798  | total loss: [1m[32m0.15392[0m[0m | time: 44.112s
[2K
| Adam | epoch: 019 | loss: 0.15392 - acc: 0.9388 -- iter: 2240/3072
[A[ATraining Step: 1799  | total loss: [1m[32m0.15551[0m[0m | time: 44.739s
[2K
| Adam | epoch: 019 | loss: 0.15551 - acc: 0.9356 -- iter: 2272/3072
[A[ATraining Step: 1800  | total loss: [1m[32m0.14589[0m[0m | time: 48.548s
[2K
| Adam | epoch: 019 | loss: 0.14589 - acc: 0.9420 | val_loss: 0.58174 - val_acc: 0.8033 -- iter: 2304/3072
--
Training Step: 1801  | total loss: [1m[32m0.15012[0m[0m | time: 49.147s
[2K
| Adam | epoch: 019 | loss: 0.15012 - acc: 0.9416 -- iter: 2336/3072
[A[ATraining Step: 1802  | total loss: [1m[32m0.14940[0m[0m | time: 49.800s
[2K
| Adam | epoch: 019 | loss: 0.14940 - acc: 0.9380 -- iter: 2368/3072
[A[ATraining Step: 1803  | total loss: [1m[32m0.14219[0m[0m | time: 50.448s
[2K
| Adam | epoch: 019 | loss: 0.14219 - acc: 0.9411 -- iter: 2400/3072
[A[ATraining Step: 1804  | total loss: [1m[32m0.14055[0m[0m | time: 51.082s
[2K
| Adam | epoch: 019 | loss: 0.14055 - acc: 0.9439 -- iter: 2432/3072
[A[ATraining Step: 1805  | total loss: [1m[32m0.13706[0m[0m | time: 51.692s
[2K
| Adam | epoch: 019 | loss: 0.13706 - acc: 0.9495 -- iter: 2464/3072
[A[ATraining Step: 1806  | total loss: [1m[32m0.12880[0m[0m | time: 52.350s
[2K
| Adam | epoch: 019 | loss: 0.12880 - acc: 0.9514 -- iter: 2496/3072
[A[ATraining Step: 1807  | total loss: [1m[32m0.12467[0m[0m | time: 52.999s
[2K
| Adam | epoch: 019 | loss: 0.12467 - acc: 0.9531 -- iter: 2528/3072
[A[ATraining Step: 1808  | total loss: [1m[32m0.12827[0m[0m | time: 53.621s
[2K
| Adam | epoch: 019 | loss: 0.12827 - acc: 0.9484 -- iter: 2560/3072
[A[ATraining Step: 1809  | total loss: [1m[32m0.12416[0m[0m | time: 54.238s
[2K
| Adam | epoch: 019 | loss: 0.12416 - acc: 0.9505 -- iter: 2592/3072
[A[ATraining Step: 1810  | total loss: [1m[32m0.12004[0m[0m | time: 54.841s
[2K
| Adam | epoch: 019 | loss: 0.12004 - acc: 0.9554 -- iter: 2624/3072
[A[ATraining Step: 1811  | total loss: [1m[32m0.14058[0m[0m | time: 55.495s
[2K
| Adam | epoch: 019 | loss: 0.14058 - acc: 0.9536 -- iter: 2656/3072
[A[ATraining Step: 1812  | total loss: [1m[32m0.13287[0m[0m | time: 56.096s
[2K
| Adam | epoch: 019 | loss: 0.13287 - acc: 0.9583 -- iter: 2688/3072
[A[ATraining Step: 1813  | total loss: [1m[32m0.12712[0m[0m | time: 56.703s
[2K
| Adam | epoch: 019 | loss: 0.12712 - acc: 0.9593 -- iter: 2720/3072
[A[ATraining Step: 1814  | total loss: [1m[32m0.11916[0m[0m | time: 57.310s
[2K
| Adam | epoch: 019 | loss: 0.11916 - acc: 0.9634 -- iter: 2752/3072
[A[ATraining Step: 1815  | total loss: [1m[32m0.11056[0m[0m | time: 57.959s
[2K
| Adam | epoch: 019 | loss: 0.11056 - acc: 0.9670 -- iter: 2784/3072
[A[ATraining Step: 1816  | total loss: [1m[32m0.11329[0m[0m | time: 58.569s
[2K
| Adam | epoch: 019 | loss: 0.11329 - acc: 0.9672 -- iter: 2816/3072
[A[ATraining Step: 1817  | total loss: [1m[32m0.10892[0m[0m | time: 59.204s
[2K
| Adam | epoch: 019 | loss: 0.10892 - acc: 0.9674 -- iter: 2848/3072
[A[ATraining Step: 1818  | total loss: [1m[32m0.11308[0m[0m | time: 59.850s
[2K
| Adam | epoch: 019 | loss: 0.11308 - acc: 0.9613 -- iter: 2880/3072
[A[ATraining Step: 1819  | total loss: [1m[32m0.10728[0m[0m | time: 60.493s
[2K
| Adam | epoch: 019 | loss: 0.10728 - acc: 0.9651 -- iter: 2912/3072
[A[ATraining Step: 1820  | total loss: [1m[32m0.10292[0m[0m | time: 61.135s
[2K
| Adam | epoch: 019 | loss: 0.10292 - acc: 0.9655 -- iter: 2944/3072
[A[ATraining Step: 1821  | total loss: [1m[32m0.09924[0m[0m | time: 61.774s
[2K
| Adam | epoch: 019 | loss: 0.09924 - acc: 0.9658 -- iter: 2976/3072
[A[ATraining Step: 1822  | total loss: [1m[32m0.09627[0m[0m | time: 62.407s
[2K
| Adam | epoch: 019 | loss: 0.09627 - acc: 0.9692 -- iter: 3008/3072
[A[ATraining Step: 1823  | total loss: [1m[32m0.09502[0m[0m | time: 63.092s
[2K
| Adam | epoch: 019 | loss: 0.09502 - acc: 0.9692 -- iter: 3040/3072
[A[ATraining Step: 1824  | total loss: [1m[32m0.09089[0m[0m | time: 66.802s
[2K
| Adam | epoch: 019 | loss: 0.09089 - acc: 0.9723 | val_loss: 0.60240 - val_acc: 0.8085 -- iter: 3072/3072
--
Training Step: 1825  | total loss: [1m[32m0.09636[0m[0m | time: 0.667s
[2K
| Adam | epoch: 020 | loss: 0.09636 - acc: 0.9688 -- iter: 0032/3072
[A[ATraining Step: 1826  | total loss: [1m[32m0.09572[0m[0m | time: 1.279s
[2K
| Adam | epoch: 020 | loss: 0.09572 - acc: 0.9657 -- iter: 0064/3072
[A[ATraining Step: 1827  | total loss: [1m[32m0.09708[0m[0m | time: 1.895s
[2K
| Adam | epoch: 020 | loss: 0.09708 - acc: 0.9660 -- iter: 0096/3072
[A[ATraining Step: 1828  | total loss: [1m[32m0.10177[0m[0m | time: 2.497s
[2K
| Adam | epoch: 020 | loss: 0.10177 - acc: 0.9663 -- iter: 0128/3072
[A[ATraining Step: 1829  | total loss: [1m[32m0.10060[0m[0m | time: 3.110s
[2K
| Adam | epoch: 020 | loss: 0.10060 - acc: 0.9696 -- iter: 0160/3072
[A[ATraining Step: 1830  | total loss: [1m[32m0.10020[0m[0m | time: 3.782s
[2K
| Adam | epoch: 020 | loss: 0.10020 - acc: 0.9727 -- iter: 0192/3072
[A[ATraining Step: 1831  | total loss: [1m[32m0.09923[0m[0m | time: 4.380s
[2K
| Adam | epoch: 020 | loss: 0.09923 - acc: 0.9723 -- iter: 0224/3072
[A[ATraining Step: 1832  | total loss: [1m[32m0.10548[0m[0m | time: 4.972s
[2K
| Adam | epoch: 020 | loss: 0.10548 - acc: 0.9657 -- iter: 0256/3072
[A[ATraining Step: 1833  | total loss: [1m[32m0.09895[0m[0m | time: 5.641s
[2K
| Adam | epoch: 020 | loss: 0.09895 - acc: 0.9691 -- iter: 0288/3072
[A[ATraining Step: 1834  | total loss: [1m[32m0.09567[0m[0m | time: 6.263s
[2K
| Adam | epoch: 020 | loss: 0.09567 - acc: 0.9722 -- iter: 0320/3072
[A[ATraining Step: 1835  | total loss: [1m[32m0.09978[0m[0m | time: 6.883s
[2K
| Adam | epoch: 020 | loss: 0.09978 - acc: 0.9718 -- iter: 0352/3072
[A[ATraining Step: 1836  | total loss: [1m[32m0.09547[0m[0m | time: 7.522s
[2K
| Adam | epoch: 020 | loss: 0.09547 - acc: 0.9747 -- iter: 0384/3072
[A[ATraining Step: 1837  | total loss: [1m[32m0.09156[0m[0m | time: 8.128s
[2K
| Adam | epoch: 020 | loss: 0.09156 - acc: 0.9741 -- iter: 0416/3072
[A[ATraining Step: 1838  | total loss: [1m[32m0.09377[0m[0m | time: 8.736s
[2K
| Adam | epoch: 020 | loss: 0.09377 - acc: 0.9735 -- iter: 0448/3072
[A[ATraining Step: 1839  | total loss: [1m[32m0.09100[0m[0m | time: 9.392s
[2K
| Adam | epoch: 020 | loss: 0.09100 - acc: 0.9731 -- iter: 0480/3072
[A[ATraining Step: 1840  | total loss: [1m[32m0.08690[0m[0m | time: 10.019s
[2K
| Adam | epoch: 020 | loss: 0.08690 - acc: 0.9726 -- iter: 0512/3072
[A[ATraining Step: 1841  | total loss: [1m[32m0.08549[0m[0m | time: 10.624s
[2K
| Adam | epoch: 020 | loss: 0.08549 - acc: 0.9722 -- iter: 0544/3072
[A[ATraining Step: 1842  | total loss: [1m[32m0.09805[0m[0m | time: 11.230s
[2K
| Adam | epoch: 020 | loss: 0.09805 - acc: 0.9656 -- iter: 0576/3072
[A[ATraining Step: 1843  | total loss: [1m[32m0.09502[0m[0m | time: 11.844s
[2K
| Adam | epoch: 020 | loss: 0.09502 - acc: 0.9691 -- iter: 0608/3072
[A[ATraining Step: 1844  | total loss: [1m[32m0.09100[0m[0m | time: 12.456s
[2K
| Adam | epoch: 020 | loss: 0.09100 - acc: 0.9722 -- iter: 0640/3072
[A[ATraining Step: 1845  | total loss: [1m[32m0.08930[0m[0m | time: 13.064s
[2K
| Adam | epoch: 020 | loss: 0.08930 - acc: 0.9750 -- iter: 0672/3072
[A[ATraining Step: 1846  | total loss: [1m[32m0.08812[0m[0m | time: 13.674s
[2K
| Adam | epoch: 020 | loss: 0.08812 - acc: 0.9743 -- iter: 0704/3072
[A[ATraining Step: 1847  | total loss: [1m[32m0.10047[0m[0m | time: 14.281s
[2K
| Adam | epoch: 020 | loss: 0.10047 - acc: 0.9675 -- iter: 0736/3072
[A[ATraining Step: 1848  | total loss: [1m[32m0.11330[0m[0m | time: 14.935s
[2K
| Adam | epoch: 020 | loss: 0.11330 - acc: 0.9614 -- iter: 0768/3072
[A[ATraining Step: 1849  | total loss: [1m[32m0.11126[0m[0m | time: 15.575s
[2K
| Adam | epoch: 020 | loss: 0.11126 - acc: 0.9590 -- iter: 0800/3072
[A[ATraining Step: 1850  | total loss: [1m[32m0.11288[0m[0m | time: 16.195s
[2K
| Adam | epoch: 020 | loss: 0.11288 - acc: 0.9600 -- iter: 0832/3072
[A[ATraining Step: 1851  | total loss: [1m[32m0.11500[0m[0m | time: 16.814s
[2K
| Adam | epoch: 020 | loss: 0.11500 - acc: 0.9577 -- iter: 0864/3072
[A[ATraining Step: 1852  | total loss: [1m[32m0.14168[0m[0m | time: 17.413s
[2K
| Adam | epoch: 020 | loss: 0.14168 - acc: 0.9495 -- iter: 0896/3072
[A[ATraining Step: 1853  | total loss: [1m[32m0.15370[0m[0m | time: 18.320s
[2K
| Adam | epoch: 020 | loss: 0.15370 - acc: 0.9483 -- iter: 0928/3072
[A[ATraining Step: 1854  | total loss: [1m[32m0.17699[0m[0m | time: 18.948s
[2K
| Adam | epoch: 020 | loss: 0.17699 - acc: 0.9316 -- iter: 0960/3072
[A[ATraining Step: 1855  | total loss: [1m[32m0.18946[0m[0m | time: 19.584s
[2K
| Adam | epoch: 020 | loss: 0.18946 - acc: 0.9290 -- iter: 0992/3072
[A[ATraining Step: 1856  | total loss: [1m[32m0.18625[0m[0m | time: 20.197s
[2K
| Adam | epoch: 020 | loss: 0.18625 - acc: 0.9268 -- iter: 1024/3072
[A[ATraining Step: 1857  | total loss: [1m[32m0.18514[0m[0m | time: 20.823s
[2K
| Adam | epoch: 020 | loss: 0.18514 - acc: 0.9278 -- iter: 1056/3072
[A[ATraining Step: 1858  | total loss: [1m[32m0.18602[0m[0m | time: 21.441s
[2K
| Adam | epoch: 020 | loss: 0.18602 - acc: 0.9257 -- iter: 1088/3072
[A[ATraining Step: 1859  | total loss: [1m[32m0.20550[0m[0m | time: 22.046s
[2K
| Adam | epoch: 020 | loss: 0.20550 - acc: 0.9206 -- iter: 1120/3072
[A[ATraining Step: 1860  | total loss: [1m[32m0.20382[0m[0m | time: 22.664s
[2K
| Adam | epoch: 020 | loss: 0.20382 - acc: 0.9223 -- iter: 1152/3072
[A[ATraining Step: 1861  | total loss: [1m[32m0.19635[0m[0m | time: 23.276s
[2K
| Adam | epoch: 020 | loss: 0.19635 - acc: 0.9238 -- iter: 1184/3072
[A[ATraining Step: 1862  | total loss: [1m[32m0.18202[0m[0m | time: 23.911s
[2K
| Adam | epoch: 020 | loss: 0.18202 - acc: 0.9283 -- iter: 1216/3072
[A[ATraining Step: 1863  | total loss: [1m[32m0.18941[0m[0m | time: 24.716s
[2K
| Adam | epoch: 020 | loss: 0.18941 - acc: 0.9292 -- iter: 1248/3072
[A[ATraining Step: 1864  | total loss: [1m[32m0.17976[0m[0m | time: 25.322s
[2K
| Adam | epoch: 020 | loss: 0.17976 - acc: 0.9332 -- iter: 1280/3072
[A[ATraining Step: 1865  | total loss: [1m[32m0.19547[0m[0m | time: 25.933s
[2K
| Adam | epoch: 020 | loss: 0.19547 - acc: 0.9274 -- iter: 1312/3072
[A[ATraining Step: 1866  | total loss: [1m[32m0.20167[0m[0m | time: 26.525s
[2K
| Adam | epoch: 020 | loss: 0.20167 - acc: 0.9221 -- iter: 1344/3072
[A[ATraining Step: 1867  | total loss: [1m[32m0.18728[0m[0m | time: 27.172s
[2K
| Adam | epoch: 020 | loss: 0.18728 - acc: 0.9299 -- iter: 1376/3072
[A[ATraining Step: 1868  | total loss: [1m[32m0.17759[0m[0m | time: 27.932s
[2K
| Adam | epoch: 020 | loss: 0.17759 - acc: 0.9338 -- iter: 1408/3072
[A[ATraining Step: 1869  | total loss: [1m[32m0.17192[0m[0m | time: 28.567s
[2K
| Adam | epoch: 020 | loss: 0.17192 - acc: 0.9373 -- iter: 1440/3072
[A[ATraining Step: 1870  | total loss: [1m[32m0.16683[0m[0m | time: 29.206s
[2K
| Adam | epoch: 020 | loss: 0.16683 - acc: 0.9404 -- iter: 1472/3072
[A[ATraining Step: 1871  | total loss: [1m[32m0.17326[0m[0m | time: 29.812s
[2K
| Adam | epoch: 020 | loss: 0.17326 - acc: 0.9370 -- iter: 1504/3072
[A[ATraining Step: 1872  | total loss: [1m[32m0.16845[0m[0m | time: 30.460s
[2K
| Adam | epoch: 020 | loss: 0.16845 - acc: 0.9402 -- iter: 1536/3072
[A[ATraining Step: 1873  | total loss: [1m[32m0.16229[0m[0m | time: 31.061s
[2K
| Adam | epoch: 020 | loss: 0.16229 - acc: 0.9430 -- iter: 1568/3072
[A[ATraining Step: 1874  | total loss: [1m[32m0.14963[0m[0m | time: 31.670s
[2K
| Adam | epoch: 020 | loss: 0.14963 - acc: 0.9487 -- iter: 1600/3072
[A[ATraining Step: 1875  | total loss: [1m[32m0.14819[0m[0m | time: 32.273s
[2K
| Adam | epoch: 020 | loss: 0.14819 - acc: 0.9476 -- iter: 1632/3072
[A[ATraining Step: 1876  | total loss: [1m[32m0.14061[0m[0m | time: 32.899s
[2K
| Adam | epoch: 020 | loss: 0.14061 - acc: 0.9497 -- iter: 1664/3072
[A[ATraining Step: 1877  | total loss: [1m[32m0.13520[0m[0m | time: 33.493s
[2K
| Adam | epoch: 020 | loss: 0.13520 - acc: 0.9516 -- iter: 1696/3072
[A[ATraining Step: 1878  | total loss: [1m[32m0.14587[0m[0m | time: 34.098s
[2K
| Adam | epoch: 020 | loss: 0.14587 - acc: 0.9502 -- iter: 1728/3072
[A[ATraining Step: 1879  | total loss: [1m[32m0.14291[0m[0m | time: 34.749s
[2K
| Adam | epoch: 020 | loss: 0.14291 - acc: 0.9521 -- iter: 1760/3072
[A[ATraining Step: 1880  | total loss: [1m[32m0.14420[0m[0m | time: 35.371s
[2K
| Adam | epoch: 020 | loss: 0.14420 - acc: 0.9537 -- iter: 1792/3072
[A[ATraining Step: 1881  | total loss: [1m[32m0.15682[0m[0m | time: 35.971s
[2K
| Adam | epoch: 020 | loss: 0.15682 - acc: 0.9459 -- iter: 1824/3072
[A[ATraining Step: 1882  | total loss: [1m[32m0.14551[0m[0m | time: 36.567s
[2K
| Adam | epoch: 020 | loss: 0.14551 - acc: 0.9513 -- iter: 1856/3072
[A[ATraining Step: 1883  | total loss: [1m[32m0.13990[0m[0m | time: 37.216s
[2K
| Adam | epoch: 020 | loss: 0.13990 - acc: 0.9530 -- iter: 1888/3072
[A[ATraining Step: 1884  | total loss: [1m[32m0.13679[0m[0m | time: 37.819s
[2K
| Adam | epoch: 020 | loss: 0.13679 - acc: 0.9546 -- iter: 1920/3072
[A[ATraining Step: 1885  | total loss: [1m[32m0.13576[0m[0m | time: 38.426s
[2K
| Adam | epoch: 020 | loss: 0.13576 - acc: 0.9560 -- iter: 1952/3072
[A[ATraining Step: 1886  | total loss: [1m[32m0.15069[0m[0m | time: 39.037s
[2K
| Adam | epoch: 020 | loss: 0.15069 - acc: 0.9510 -- iter: 1984/3072
[A[ATraining Step: 1887  | total loss: [1m[32m0.14874[0m[0m | time: 39.682s
[2K
| Adam | epoch: 020 | loss: 0.14874 - acc: 0.9497 -- iter: 2016/3072
[A[ATraining Step: 1888  | total loss: [1m[32m0.13682[0m[0m | time: 40.292s
[2K
| Adam | epoch: 020 | loss: 0.13682 - acc: 0.9547 -- iter: 2048/3072
[A[ATraining Step: 1889  | total loss: [1m[32m0.13084[0m[0m | time: 40.936s
[2K
| Adam | epoch: 020 | loss: 0.13084 - acc: 0.9561 -- iter: 2080/3072
[A[ATraining Step: 1890  | total loss: [1m[32m0.12523[0m[0m | time: 41.528s
[2K
| Adam | epoch: 020 | loss: 0.12523 - acc: 0.9605 -- iter: 2112/3072
[A[ATraining Step: 1891  | total loss: [1m[32m0.12383[0m[0m | time: 42.154s
[2K
| Adam | epoch: 020 | loss: 0.12383 - acc: 0.9613 -- iter: 2144/3072
[A[ATraining Step: 1892  | total loss: [1m[32m0.12497[0m[0m | time: 42.766s
[2K
| Adam | epoch: 020 | loss: 0.12497 - acc: 0.9558 -- iter: 2176/3072
[A[ATraining Step: 1893  | total loss: [1m[32m0.11935[0m[0m | time: 43.383s
[2K
| Adam | epoch: 020 | loss: 0.11935 - acc: 0.9602 -- iter: 2208/3072
[A[ATraining Step: 1894  | total loss: [1m[32m0.13263[0m[0m | time: 44.022s
[2K
| Adam | epoch: 020 | loss: 0.13263 - acc: 0.9517 -- iter: 2240/3072
[A[ATraining Step: 1895  | total loss: [1m[32m0.12984[0m[0m | time: 44.627s
[2K
| Adam | epoch: 020 | loss: 0.12984 - acc: 0.9534 -- iter: 2272/3072
[A[ATraining Step: 1896  | total loss: [1m[32m0.11999[0m[0m | time: 45.272s
[2K
| Adam | epoch: 020 | loss: 0.11999 - acc: 0.9581 -- iter: 2304/3072
[A[ATraining Step: 1897  | total loss: [1m[32m0.11234[0m[0m | time: 45.903s
[2K
| Adam | epoch: 020 | loss: 0.11234 - acc: 0.9623 -- iter: 2336/3072
[A[ATraining Step: 1898  | total loss: [1m[32m0.11302[0m[0m | time: 46.519s
[2K
| Adam | epoch: 020 | loss: 0.11302 - acc: 0.9598 -- iter: 2368/3072
[A[ATraining Step: 1899  | total loss: [1m[32m0.12034[0m[0m | time: 47.118s
[2K
| Adam | epoch: 020 | loss: 0.12034 - acc: 0.9576 -- iter: 2400/3072
[A[ATraining Step: 1900  | total loss: [1m[32m0.11291[0m[0m | time: 47.788s
[2K
| Adam | epoch: 020 | loss: 0.11291 - acc: 0.9618 -- iter: 2432/3072
[A[ATraining Step: 1901  | total loss: [1m[32m0.10814[0m[0m | time: 48.399s
[2K
| Adam | epoch: 020 | loss: 0.10814 - acc: 0.9625 -- iter: 2464/3072
[A[ATraining Step: 1902  | total loss: [1m[32m0.10568[0m[0m | time: 49.020s
[2K
| Adam | epoch: 020 | loss: 0.10568 - acc: 0.9631 -- iter: 2496/3072
[A[ATraining Step: 1903  | total loss: [1m[32m0.12321[0m[0m | time: 49.622s
[2K
| Adam | epoch: 020 | loss: 0.12321 - acc: 0.9606 -- iter: 2528/3072
[A[ATraining Step: 1904  | total loss: [1m[32m0.13723[0m[0m | time: 50.249s
[2K
| Adam | epoch: 020 | loss: 0.13723 - acc: 0.9583 -- iter: 2560/3072
[A[ATraining Step: 1905  | total loss: [1m[32m0.12754[0m[0m | time: 50.880s
[2K
| Adam | epoch: 020 | loss: 0.12754 - acc: 0.9624 -- iter: 2592/3072
[A[ATraining Step: 1906  | total loss: [1m[32m0.12552[0m[0m | time: 51.513s
[2K
| Adam | epoch: 020 | loss: 0.12552 - acc: 0.9631 -- iter: 2624/3072
[A[ATraining Step: 1907  | total loss: [1m[32m0.13238[0m[0m | time: 52.116s
[2K
| Adam | epoch: 020 | loss: 0.13238 - acc: 0.9636 -- iter: 2656/3072
[A[ATraining Step: 1908  | total loss: [1m[32m0.13429[0m[0m | time: 52.769s
[2K
| Adam | epoch: 020 | loss: 0.13429 - acc: 0.9641 -- iter: 2688/3072
[A[ATraining Step: 1909  | total loss: [1m[32m0.12494[0m[0m | time: 53.384s
[2K
| Adam | epoch: 020 | loss: 0.12494 - acc: 0.9677 -- iter: 2720/3072
[A[ATraining Step: 1910  | total loss: [1m[32m0.12005[0m[0m | time: 54.023s
[2K
| Adam | epoch: 020 | loss: 0.12005 - acc: 0.9710 -- iter: 2752/3072
[A[ATraining Step: 1911  | total loss: [1m[32m0.11267[0m[0m | time: 54.690s
[2K
| Adam | epoch: 020 | loss: 0.11267 - acc: 0.9739 -- iter: 2784/3072
[A[ATraining Step: 1912  | total loss: [1m[32m0.10913[0m[0m | time: 55.296s
[2K
| Adam | epoch: 020 | loss: 0.10913 - acc: 0.9733 -- iter: 2816/3072
[A[ATraining Step: 1913  | total loss: [1m[32m0.10551[0m[0m | time: 55.933s
[2K
| Adam | epoch: 020 | loss: 0.10551 - acc: 0.9729 -- iter: 2848/3072
[A[ATraining Step: 1914  | total loss: [1m[32m0.10448[0m[0m | time: 56.531s
[2K
| Adam | epoch: 020 | loss: 0.10448 - acc: 0.9725 -- iter: 2880/3072
[A[ATraining Step: 1915  | total loss: [1m[32m0.09681[0m[0m | time: 57.156s
[2K
| Adam | epoch: 020 | loss: 0.09681 - acc: 0.9752 -- iter: 2912/3072
[A[ATraining Step: 1916  | total loss: [1m[32m0.09256[0m[0m | time: 57.783s
[2K
| Adam | epoch: 020 | loss: 0.09256 - acc: 0.9746 -- iter: 2944/3072
[A[ATraining Step: 1917  | total loss: [1m[32m0.08930[0m[0m | time: 58.412s
[2K
| Adam | epoch: 020 | loss: 0.08930 - acc: 0.9740 -- iter: 2976/3072
[A[ATraining Step: 1918  | total loss: [1m[32m0.09072[0m[0m | time: 59.026s
[2K
| Adam | epoch: 020 | loss: 0.09072 - acc: 0.9703 -- iter: 3008/3072
[A[ATraining Step: 1919  | total loss: [1m[32m0.08798[0m[0m | time: 59.640s
[2K
| Adam | epoch: 020 | loss: 0.08798 - acc: 0.9733 -- iter: 3040/3072
[A[ATraining Step: 1920  | total loss: [1m[32m0.08127[0m[0m | time: 63.340s
[2K
| Adam | epoch: 020 | loss: 0.08127 - acc: 0.9760 | val_loss: 0.68371 - val_acc: 0.7742 -- iter: 3072/3072
--
Training Step: 1921  | total loss: [1m[32m0.09608[0m[0m | time: 0.610s
[2K
| Adam | epoch: 021 | loss: 0.09608 - acc: 0.9753 -- iter: 0032/3072
[A[ATraining Step: 1922  | total loss: [1m[32m0.10161[0m[0m | time: 1.222s
[2K
| Adam | epoch: 021 | loss: 0.10161 - acc: 0.9746 -- iter: 0064/3072
[A[ATraining Step: 1923  | total loss: [1m[32m0.09716[0m[0m | time: 1.852s
[2K
| Adam | epoch: 021 | loss: 0.09716 - acc: 0.9771 -- iter: 0096/3072
[A[ATraining Step: 1924  | total loss: [1m[32m0.10072[0m[0m | time: 2.448s
[2K
| Adam | epoch: 021 | loss: 0.10072 - acc: 0.9732 -- iter: 0128/3072
[A[ATraining Step: 1925  | total loss: [1m[32m0.09413[0m[0m | time: 3.075s
[2K
| Adam | epoch: 021 | loss: 0.09413 - acc: 0.9759 -- iter: 0160/3072
[A[ATraining Step: 1926  | total loss: [1m[32m0.09572[0m[0m | time: 3.680s
[2K
| Adam | epoch: 021 | loss: 0.09572 - acc: 0.9752 -- iter: 0192/3072
[A[ATraining Step: 1927  | total loss: [1m[32m0.10253[0m[0m | time: 4.291s
[2K
| Adam | epoch: 021 | loss: 0.10253 - acc: 0.9714 -- iter: 0224/3072
[A[ATraining Step: 1928  | total loss: [1m[32m0.10099[0m[0m | time: 4.935s
[2K
| Adam | epoch: 021 | loss: 0.10099 - acc: 0.9680 -- iter: 0256/3072
[A[ATraining Step: 1929  | total loss: [1m[32m0.09507[0m[0m | time: 5.543s
[2K
| Adam | epoch: 021 | loss: 0.09507 - acc: 0.9712 -- iter: 0288/3072
[A[ATraining Step: 1930  | total loss: [1m[32m0.09030[0m[0m | time: 6.199s
[2K
| Adam | epoch: 021 | loss: 0.09030 - acc: 0.9741 -- iter: 0320/3072
[A[ATraining Step: 1931  | total loss: [1m[32m0.08399[0m[0m | time: 6.835s
[2K
| Adam | epoch: 021 | loss: 0.08399 - acc: 0.9767 -- iter: 0352/3072
[A[ATraining Step: 1932  | total loss: [1m[32m0.08256[0m[0m | time: 7.438s
[2K
| Adam | epoch: 021 | loss: 0.08256 - acc: 0.9790 -- iter: 0384/3072
[A[ATraining Step: 1933  | total loss: [1m[32m0.08023[0m[0m | time: 8.086s
[2K
| Adam | epoch: 021 | loss: 0.08023 - acc: 0.9811 -- iter: 0416/3072
[A[ATraining Step: 1934  | total loss: [1m[32m0.08191[0m[0m | time: 8.690s
[2K
| Adam | epoch: 021 | loss: 0.08191 - acc: 0.9799 -- iter: 0448/3072
[A[ATraining Step: 1935  | total loss: [1m[32m0.07649[0m[0m | time: 9.294s
[2K
| Adam | epoch: 021 | loss: 0.07649 - acc: 0.9819 -- iter: 0480/3072
[A[ATraining Step: 1936  | total loss: [1m[32m0.07695[0m[0m | time: 9.911s
[2K
| Adam | epoch: 021 | loss: 0.07695 - acc: 0.9806 -- iter: 0512/3072
[A[ATraining Step: 1937  | total loss: [1m[32m0.08141[0m[0m | time: 10.542s
[2K
| Adam | epoch: 021 | loss: 0.08141 - acc: 0.9763 -- iter: 0544/3072
[A[ATraining Step: 1938  | total loss: [1m[32m0.08106[0m[0m | time: 11.160s
[2K
| Adam | epoch: 021 | loss: 0.08106 - acc: 0.9786 -- iter: 0576/3072
[A[ATraining Step: 1939  | total loss: [1m[32m0.07617[0m[0m | time: 11.774s
[2K
| Adam | epoch: 021 | loss: 0.07617 - acc: 0.9808 -- iter: 0608/3072
[A[ATraining Step: 1940  | total loss: [1m[32m0.07763[0m[0m | time: 12.394s
[2K
| Adam | epoch: 021 | loss: 0.07763 - acc: 0.9796 -- iter: 0640/3072
[A[ATraining Step: 1941  | total loss: [1m[32m0.07769[0m[0m | time: 13.034s
[2K
| Adam | epoch: 021 | loss: 0.07769 - acc: 0.9785 -- iter: 0672/3072
[A[ATraining Step: 1942  | total loss: [1m[32m0.07760[0m[0m | time: 13.637s
[2K
| Adam | epoch: 021 | loss: 0.07760 - acc: 0.9806 -- iter: 0704/3072
[A[ATraining Step: 1943  | total loss: [1m[32m0.08415[0m[0m | time: 14.264s
[2K
| Adam | epoch: 021 | loss: 0.08415 - acc: 0.9794 -- iter: 0736/3072
[A[ATraining Step: 1944  | total loss: [1m[32m0.08091[0m[0m | time: 14.907s
[2K
| Adam | epoch: 021 | loss: 0.08091 - acc: 0.9815 -- iter: 0768/3072
[A[ATraining Step: 1945  | total loss: [1m[32m0.08603[0m[0m | time: 15.609s
[2K
| Adam | epoch: 021 | loss: 0.08603 - acc: 0.9802 -- iter: 0800/3072
[A[ATraining Step: 1946  | total loss: [1m[32m0.08338[0m[0m | time: 16.252s
[2K
| Adam | epoch: 021 | loss: 0.08338 - acc: 0.9822 -- iter: 0832/3072
[A[ATraining Step: 1947  | total loss: [1m[32m0.08166[0m[0m | time: 16.866s
[2K
| Adam | epoch: 021 | loss: 0.08166 - acc: 0.9840 -- iter: 0864/3072
[A[ATraining Step: 1948  | total loss: [1m[32m0.08638[0m[0m | time: 17.507s
[2K
| Adam | epoch: 021 | loss: 0.08638 - acc: 0.9762 -- iter: 0896/3072
[A[ATraining Step: 1949  | total loss: [1m[32m0.09181[0m[0m | time: 18.124s
[2K
| Adam | epoch: 021 | loss: 0.09181 - acc: 0.9723 -- iter: 0928/3072
[A[ATraining Step: 1950  | total loss: [1m[32m0.09256[0m[0m | time: 18.749s
[2K
| Adam | epoch: 021 | loss: 0.09256 - acc: 0.9720 -- iter: 0960/3072
[A[ATraining Step: 1951  | total loss: [1m[32m0.09639[0m[0m | time: 19.389s
[2K
| Adam | epoch: 021 | loss: 0.09639 - acc: 0.9717 -- iter: 0992/3072
[A[ATraining Step: 1952  | total loss: [1m[32m0.09225[0m[0m | time: 20.040s
[2K
| Adam | epoch: 021 | loss: 0.09225 - acc: 0.9745 -- iter: 1024/3072
[A[ATraining Step: 1953  | total loss: [1m[32m0.09439[0m[0m | time: 20.674s
[2K
| Adam | epoch: 021 | loss: 0.09439 - acc: 0.9739 -- iter: 1056/3072
[A[ATraining Step: 1954  | total loss: [1m[32m0.11096[0m[0m | time: 21.491s
[2K
| Adam | epoch: 021 | loss: 0.11096 - acc: 0.9672 -- iter: 1088/3072
[A[ATraining Step: 1955  | total loss: [1m[32m0.11265[0m[0m | time: 22.095s
[2K
| Adam | epoch: 021 | loss: 0.11265 - acc: 0.9642 -- iter: 1120/3072
[A[ATraining Step: 1956  | total loss: [1m[32m0.11908[0m[0m | time: 22.712s
[2K
| Adam | epoch: 021 | loss: 0.11908 - acc: 0.9553 -- iter: 1152/3072
[A[ATraining Step: 1957  | total loss: [1m[32m0.11873[0m[0m | time: 23.397s
[2K
| Adam | epoch: 021 | loss: 0.11873 - acc: 0.9535 -- iter: 1184/3072
[A[ATraining Step: 1958  | total loss: [1m[32m0.11404[0m[0m | time: 23.999s
[2K
| Adam | epoch: 021 | loss: 0.11404 - acc: 0.9581 -- iter: 1216/3072
[A[ATraining Step: 1959  | total loss: [1m[32m0.12508[0m[0m | time: 24.644s
[2K
| Adam | epoch: 021 | loss: 0.12508 - acc: 0.9561 -- iter: 1248/3072
[A[ATraining Step: 1960  | total loss: [1m[32m0.12870[0m[0m | time: 25.255s
[2K
| Adam | epoch: 021 | loss: 0.12870 - acc: 0.9573 -- iter: 1280/3072
[A[ATraining Step: 1961  | total loss: [1m[32m0.13984[0m[0m | time: 25.861s
[2K
| Adam | epoch: 021 | loss: 0.13984 - acc: 0.9491 -- iter: 1312/3072
[A[ATraining Step: 1962  | total loss: [1m[32m0.13839[0m[0m | time: 26.473s
[2K
| Adam | epoch: 021 | loss: 0.13839 - acc: 0.9511 -- iter: 1344/3072
[A[ATraining Step: 1963  | total loss: [1m[32m0.13519[0m[0m | time: 27.073s
[2K
| Adam | epoch: 021 | loss: 0.13519 - acc: 0.9497 -- iter: 1376/3072
[A[ATraining Step: 1964  | total loss: [1m[32m0.14180[0m[0m | time: 27.682s
[2K
| Adam | epoch: 021 | loss: 0.14180 - acc: 0.9454 -- iter: 1408/3072
[A[ATraining Step: 1965  | total loss: [1m[32m0.15360[0m[0m | time: 28.286s
[2K
| Adam | epoch: 021 | loss: 0.15360 - acc: 0.9446 -- iter: 1440/3072
[A[ATraining Step: 1966  | total loss: [1m[32m0.14921[0m[0m | time: 28.896s
[2K
| Adam | epoch: 021 | loss: 0.14921 - acc: 0.9470 -- iter: 1472/3072
[A[ATraining Step: 1967  | total loss: [1m[32m0.14441[0m[0m | time: 29.517s
[2K
| Adam | epoch: 021 | loss: 0.14441 - acc: 0.9460 -- iter: 1504/3072
[A[ATraining Step: 1968  | total loss: [1m[32m0.13503[0m[0m | time: 30.124s
[2K
| Adam | epoch: 021 | loss: 0.13503 - acc: 0.9514 -- iter: 1536/3072
[A[ATraining Step: 1969  | total loss: [1m[32m0.12881[0m[0m | time: 30.728s
[2K
| Adam | epoch: 021 | loss: 0.12881 - acc: 0.9532 -- iter: 1568/3072
[A[ATraining Step: 1970  | total loss: [1m[32m0.14544[0m[0m | time: 31.365s
[2K
| Adam | epoch: 021 | loss: 0.14544 - acc: 0.9485 -- iter: 1600/3072
[A[ATraining Step: 1971  | total loss: [1m[32m0.14005[0m[0m | time: 31.967s
[2K
| Adam | epoch: 021 | loss: 0.14005 - acc: 0.9474 -- iter: 1632/3072
[A[ATraining Step: 1972  | total loss: [1m[32m0.14803[0m[0m | time: 32.572s
[2K
| Adam | epoch: 021 | loss: 0.14803 - acc: 0.9495 -- iter: 1664/3072
[A[ATraining Step: 1973  | total loss: [1m[32m0.13516[0m[0m | time: 33.336s
[2K
| Adam | epoch: 021 | loss: 0.13516 - acc: 0.9546 -- iter: 1696/3072
[A[ATraining Step: 1974  | total loss: [1m[32m0.12665[0m[0m | time: 33.976s
[2K
| Adam | epoch: 021 | loss: 0.12665 - acc: 0.9591 -- iter: 1728/3072
[A[ATraining Step: 1975  | total loss: [1m[32m0.13192[0m[0m | time: 34.594s
[2K
| Adam | epoch: 021 | loss: 0.13192 - acc: 0.9538 -- iter: 1760/3072
[A[ATraining Step: 1976  | total loss: [1m[32m0.13538[0m[0m | time: 35.196s
[2K
| Adam | epoch: 021 | loss: 0.13538 - acc: 0.9491 -- iter: 1792/3072
[A[ATraining Step: 1977  | total loss: [1m[32m0.12768[0m[0m | time: 35.810s
[2K
| Adam | epoch: 021 | loss: 0.12768 - acc: 0.9542 -- iter: 1824/3072
[A[ATraining Step: 1978  | total loss: [1m[32m0.14110[0m[0m | time: 36.515s
[2K
| Adam | epoch: 021 | loss: 0.14110 - acc: 0.9494 -- iter: 1856/3072
[A[ATraining Step: 1979  | total loss: [1m[32m0.13125[0m[0m | time: 37.124s
[2K
| Adam | epoch: 021 | loss: 0.13125 - acc: 0.9544 -- iter: 1888/3072
[A[ATraining Step: 1980  | total loss: [1m[32m0.13695[0m[0m | time: 37.752s
[2K
| Adam | epoch: 021 | loss: 0.13695 - acc: 0.9465 -- iter: 1920/3072
[A[ATraining Step: 1981  | total loss: [1m[32m0.13056[0m[0m | time: 38.354s
[2K
| Adam | epoch: 021 | loss: 0.13056 - acc: 0.9456 -- iter: 1952/3072
[A[ATraining Step: 1982  | total loss: [1m[32m0.11948[0m[0m | time: 38.970s
[2K
| Adam | epoch: 021 | loss: 0.11948 - acc: 0.9510 -- iter: 1984/3072
[A[ATraining Step: 1983  | total loss: [1m[32m0.12119[0m[0m | time: 39.609s
[2K
| Adam | epoch: 021 | loss: 0.12119 - acc: 0.9497 -- iter: 2016/3072
[A[ATraining Step: 1984  | total loss: [1m[32m0.11526[0m[0m | time: 40.219s
[2K
| Adam | epoch: 021 | loss: 0.11526 - acc: 0.9547 -- iter: 2048/3072
[A[ATraining Step: 1985  | total loss: [1m[32m0.11047[0m[0m | time: 40.831s
[2K
| Adam | epoch: 021 | loss: 0.11047 - acc: 0.9561 -- iter: 2080/3072
[A[ATraining Step: 1986  | total loss: [1m[32m0.10100[0m[0m | time: 41.446s
[2K
| Adam | epoch: 021 | loss: 0.10100 - acc: 0.9605 -- iter: 2112/3072
[A[ATraining Step: 1987  | total loss: [1m[32m0.09308[0m[0m | time: 42.111s
[2K
| Adam | epoch: 021 | loss: 0.09308 - acc: 0.9645 -- iter: 2144/3072
[A[ATraining Step: 1988  | total loss: [1m[32m0.10950[0m[0m | time: 42.778s
[2K
| Adam | epoch: 021 | loss: 0.10950 - acc: 0.9555 -- iter: 2176/3072
[A[ATraining Step: 1989  | total loss: [1m[32m0.10471[0m[0m | time: 43.393s
[2K
| Adam | epoch: 021 | loss: 0.10471 - acc: 0.9600 -- iter: 2208/3072
[A[ATraining Step: 1990  | total loss: [1m[32m0.09915[0m[0m | time: 44.012s
[2K
| Adam | epoch: 021 | loss: 0.09915 - acc: 0.9640 -- iter: 2240/3072
[A[ATraining Step: 1991  | total loss: [1m[32m0.09305[0m[0m | time: 44.616s
[2K
| Adam | epoch: 021 | loss: 0.09305 - acc: 0.9676 -- iter: 2272/3072
[A[ATraining Step: 1992  | total loss: [1m[32m0.09421[0m[0m | time: 45.228s
[2K
| Adam | epoch: 021 | loss: 0.09421 - acc: 0.9646 -- iter: 2304/3072
[A[ATraining Step: 1993  | total loss: [1m[32m0.08827[0m[0m | time: 45.844s
[2K
| Adam | epoch: 021 | loss: 0.08827 - acc: 0.9681 -- iter: 2336/3072
[A[ATraining Step: 1994  | total loss: [1m[32m0.09049[0m[0m | time: 46.454s
[2K
| Adam | epoch: 021 | loss: 0.09049 - acc: 0.9682 -- iter: 2368/3072
[A[ATraining Step: 1995  | total loss: [1m[32m0.08436[0m[0m | time: 47.066s
[2K
| Adam | epoch: 021 | loss: 0.08436 - acc: 0.9714 -- iter: 2400/3072
[A[ATraining Step: 1996  | total loss: [1m[32m0.08014[0m[0m | time: 47.669s
[2K
| Adam | epoch: 021 | loss: 0.08014 - acc: 0.9711 -- iter: 2432/3072
[A[ATraining Step: 1997  | total loss: [1m[32m0.08105[0m[0m | time: 48.274s
[2K
| Adam | epoch: 021 | loss: 0.08105 - acc: 0.9709 -- iter: 2464/3072
[A[ATraining Step: 1998  | total loss: [1m[32m0.08230[0m[0m | time: 48.908s
[2K
| Adam | epoch: 021 | loss: 0.08230 - acc: 0.9706 -- iter: 2496/3072
[A[ATraining Step: 1999  | total loss: [1m[32m0.08848[0m[0m | time: 49.520s
[2K
| Adam | epoch: 021 | loss: 0.08848 - acc: 0.9673 -- iter: 2528/3072
[A[ATraining Step: 2000  | total loss: [1m[32m0.08730[0m[0m | time: 53.235s
[2K
| Adam | epoch: 021 | loss: 0.08730 - acc: 0.9675 | val_loss: 0.59296 - val_acc: 0.8148 -- iter: 2560/3072
--
Training Step: 2001  | total loss: [1m[32m0.08331[0m[0m | time: 53.852s
[2K
| Adam | epoch: 021 | loss: 0.08331 - acc: 0.9707 -- iter: 2592/3072
[A[ATraining Step: 2002  | total loss: [1m[32m0.07860[0m[0m | time: 54.487s
[2K
| Adam | epoch: 021 | loss: 0.07860 - acc: 0.9737 -- iter: 2624/3072
[A[ATraining Step: 2003  | total loss: [1m[32m0.07544[0m[0m | time: 55.112s
[2K
| Adam | epoch: 021 | loss: 0.07544 - acc: 0.9763 -- iter: 2656/3072
[A[ATraining Step: 2004  | total loss: [1m[32m0.07781[0m[0m | time: 55.745s
[2K
| Adam | epoch: 021 | loss: 0.07781 - acc: 0.9755 -- iter: 2688/3072
[A[ATraining Step: 2005  | total loss: [1m[32m0.08457[0m[0m | time: 56.392s
[2K
| Adam | epoch: 021 | loss: 0.08457 - acc: 0.9717 -- iter: 2720/3072
[A[ATraining Step: 2006  | total loss: [1m[32m0.08173[0m[0m | time: 57.002s
[2K
| Adam | epoch: 021 | loss: 0.08173 - acc: 0.9746 -- iter: 2752/3072
[A[ATraining Step: 2007  | total loss: [1m[32m0.07781[0m[0m | time: 57.664s
[2K
| Adam | epoch: 021 | loss: 0.07781 - acc: 0.9771 -- iter: 2784/3072
[A[ATraining Step: 2008  | total loss: [1m[32m0.07465[0m[0m | time: 58.298s
[2K
| Adam | epoch: 021 | loss: 0.07465 - acc: 0.9794 -- iter: 2816/3072
[A[ATraining Step: 2009  | total loss: [1m[32m0.07090[0m[0m | time: 58.907s
[2K
| Adam | epoch: 021 | loss: 0.07090 - acc: 0.9815 -- iter: 2848/3072
[A[ATraining Step: 2010  | total loss: [1m[32m0.07066[0m[0m | time: 59.514s
[2K
| Adam | epoch: 021 | loss: 0.07066 - acc: 0.9802 -- iter: 2880/3072
[A[ATraining Step: 2011  | total loss: [1m[32m0.06722[0m[0m | time: 60.171s
[2K
| Adam | epoch: 021 | loss: 0.06722 - acc: 0.9822 -- iter: 2912/3072
[A[ATraining Step: 2012  | total loss: [1m[32m0.06294[0m[0m | time: 60.804s
[2K
| Adam | epoch: 021 | loss: 0.06294 - acc: 0.9839 -- iter: 2944/3072
[A[ATraining Step: 2013  | total loss: [1m[32m0.06332[0m[0m | time: 61.441s
[2K
| Adam | epoch: 021 | loss: 0.06332 - acc: 0.9824 -- iter: 2976/3072
[A[ATraining Step: 2014  | total loss: [1m[32m0.06432[0m[0m | time: 62.091s
[2K
| Adam | epoch: 021 | loss: 0.06432 - acc: 0.9811 -- iter: 3008/3072
[A[ATraining Step: 2015  | total loss: [1m[32m0.06258[0m[0m | time: 62.708s
[2K
| Adam | epoch: 021 | loss: 0.06258 - acc: 0.9830 -- iter: 3040/3072
[A[ATraining Step: 2016  | total loss: [1m[32m0.06556[0m[0m | time: 66.476s
[2K
| Adam | epoch: 021 | loss: 0.06556 - acc: 0.9784 | val_loss: 0.67604 - val_acc: 0.8054 -- iter: 3072/3072
--
Training Step: 2017  | total loss: [1m[32m0.06931[0m[0m | time: 0.620s
[2K
| Adam | epoch: 022 | loss: 0.06931 - acc: 0.9774 -- iter: 0032/3072
[A[ATraining Step: 2018  | total loss: [1m[32m0.07099[0m[0m | time: 1.259s
[2K
| Adam | epoch: 022 | loss: 0.07099 - acc: 0.9766 -- iter: 0064/3072
[A[ATraining Step: 2019  | total loss: [1m[32m0.06983[0m[0m | time: 1.864s
[2K
| Adam | epoch: 022 | loss: 0.06983 - acc: 0.9758 -- iter: 0096/3072
[A[ATraining Step: 2020  | total loss: [1m[32m0.06635[0m[0m | time: 2.498s
[2K
| Adam | epoch: 022 | loss: 0.06635 - acc: 0.9782 -- iter: 0128/3072
[A[ATraining Step: 2021  | total loss: [1m[32m0.07244[0m[0m | time: 3.132s
[2K
| Adam | epoch: 022 | loss: 0.07244 - acc: 0.9741 -- iter: 0160/3072
[A[ATraining Step: 2022  | total loss: [1m[32m0.06771[0m[0m | time: 3.742s
[2K
| Adam | epoch: 022 | loss: 0.06771 - acc: 0.9767 -- iter: 0192/3072
[A[ATraining Step: 2023  | total loss: [1m[32m0.06459[0m[0m | time: 4.378s
[2K
| Adam | epoch: 022 | loss: 0.06459 - acc: 0.9791 -- iter: 0224/3072
[A[ATraining Step: 2024  | total loss: [1m[32m0.06756[0m[0m | time: 5.043s
[2K
| Adam | epoch: 022 | loss: 0.06756 - acc: 0.9749 -- iter: 0256/3072
[A[ATraining Step: 2025  | total loss: [1m[32m0.06519[0m[0m | time: 5.697s
[2K
| Adam | epoch: 022 | loss: 0.06519 - acc: 0.9774 -- iter: 0288/3072
[A[ATraining Step: 2026  | total loss: [1m[32m0.06443[0m[0m | time: 6.343s
[2K
| Adam | epoch: 022 | loss: 0.06443 - acc: 0.9797 -- iter: 0320/3072
[A[ATraining Step: 2027  | total loss: [1m[32m0.06244[0m[0m | time: 6.977s
[2K
| Adam | epoch: 022 | loss: 0.06244 - acc: 0.9786 -- iter: 0352/3072
[A[ATraining Step: 2028  | total loss: [1m[32m0.06278[0m[0m | time: 7.590s
[2K
| Adam | epoch: 022 | loss: 0.06278 - acc: 0.9807 -- iter: 0384/3072
[A[ATraining Step: 2029  | total loss: [1m[32m0.06503[0m[0m | time: 8.232s
[2K
| Adam | epoch: 022 | loss: 0.06503 - acc: 0.9795 -- iter: 0416/3072
[A[ATraining Step: 2030  | total loss: [1m[32m0.10588[0m[0m | time: 8.842s
[2K
| Adam | epoch: 022 | loss: 0.10588 - acc: 0.9722 -- iter: 0448/3072
[A[ATraining Step: 2031  | total loss: [1m[32m0.10063[0m[0m | time: 9.505s
[2K
| Adam | epoch: 022 | loss: 0.10063 - acc: 0.9719 -- iter: 0480/3072
[A[ATraining Step: 2032  | total loss: [1m[32m0.09569[0m[0m | time: 10.116s
[2K
| Adam | epoch: 022 | loss: 0.09569 - acc: 0.9747 -- iter: 0512/3072
[A[ATraining Step: 2033  | total loss: [1m[32m0.09037[0m[0m | time: 10.759s
[2K
| Adam | epoch: 022 | loss: 0.09037 - acc: 0.9772 -- iter: 0544/3072
[A[ATraining Step: 2034  | total loss: [1m[32m0.08812[0m[0m | time: 11.400s
[2K
| Adam | epoch: 022 | loss: 0.08812 - acc: 0.9764 -- iter: 0576/3072
[A[ATraining Step: 2035  | total loss: [1m[32m0.08467[0m[0m | time: 12.003s
[2K
| Adam | epoch: 022 | loss: 0.08467 - acc: 0.9787 -- iter: 0608/3072
[A[ATraining Step: 2036  | total loss: [1m[32m0.08360[0m[0m | time: 12.672s
[2K
| Adam | epoch: 022 | loss: 0.08360 - acc: 0.9746 -- iter: 0640/3072
[A[ATraining Step: 2037  | total loss: [1m[32m0.08019[0m[0m | time: 13.292s
[2K
| Adam | epoch: 022 | loss: 0.08019 - acc: 0.9771 -- iter: 0672/3072
[A[ATraining Step: 2038  | total loss: [1m[32m0.07651[0m[0m | time: 13.926s
[2K
| Adam | epoch: 022 | loss: 0.07651 - acc: 0.9794 -- iter: 0704/3072
[A[ATraining Step: 2039  | total loss: [1m[32m0.07602[0m[0m | time: 14.722s
[2K
| Adam | epoch: 022 | loss: 0.07602 - acc: 0.9784 -- iter: 0736/3072
[A[ATraining Step: 2040  | total loss: [1m[32m0.07294[0m[0m | time: 15.340s
[2K
| Adam | epoch: 022 | loss: 0.07294 - acc: 0.9805 -- iter: 0768/3072
[A[ATraining Step: 2041  | total loss: [1m[32m0.06952[0m[0m | time: 15.985s
[2K
| Adam | epoch: 022 | loss: 0.06952 - acc: 0.9825 -- iter: 0800/3072
[A[ATraining Step: 2042  | total loss: [1m[32m0.06808[0m[0m | time: 16.598s
[2K
| Adam | epoch: 022 | loss: 0.06808 - acc: 0.9811 -- iter: 0832/3072
[A[ATraining Step: 2043  | total loss: [1m[32m0.07139[0m[0m | time: 17.272s
[2K
| Adam | epoch: 022 | loss: 0.07139 - acc: 0.9799 -- iter: 0864/3072
[A[ATraining Step: 2044  | total loss: [1m[32m0.07161[0m[0m | time: 17.901s
[2K
| Adam | epoch: 022 | loss: 0.07161 - acc: 0.9819 -- iter: 0896/3072
[A[ATraining Step: 2045  | total loss: [1m[32m0.06839[0m[0m | time: 18.511s
[2K
| Adam | epoch: 022 | loss: 0.06839 - acc: 0.9837 -- iter: 0928/3072
[A[ATraining Step: 2046  | total loss: [1m[32m0.07016[0m[0m | time: 19.150s
[2K
| Adam | epoch: 022 | loss: 0.07016 - acc: 0.9853 -- iter: 0960/3072
[A[ATraining Step: 2047  | total loss: [1m[32m0.07323[0m[0m | time: 19.761s
[2K
| Adam | epoch: 022 | loss: 0.07323 - acc: 0.9868 -- iter: 0992/3072
[A[ATraining Step: 2048  | total loss: [1m[32m0.06901[0m[0m | time: 20.387s
[2K
| Adam | epoch: 022 | loss: 0.06901 - acc: 0.9881 -- iter: 1024/3072
[A[ATraining Step: 2049  | total loss: [1m[32m0.07295[0m[0m | time: 21.066s
[2K
| Adam | epoch: 022 | loss: 0.07295 - acc: 0.9830 -- iter: 1056/3072
[A[ATraining Step: 2050  | total loss: [1m[32m0.07412[0m[0m | time: 21.732s
[2K
| Adam | epoch: 022 | loss: 0.07412 - acc: 0.9816 -- iter: 1088/3072
[A[ATraining Step: 2051  | total loss: [1m[32m0.06965[0m[0m | time: 22.352s
[2K
| Adam | epoch: 022 | loss: 0.06965 - acc: 0.9835 -- iter: 1120/3072
[A[ATraining Step: 2052  | total loss: [1m[32m0.06492[0m[0m | time: 22.983s
[2K
| Adam | epoch: 022 | loss: 0.06492 - acc: 0.9851 -- iter: 1152/3072
[A[ATraining Step: 2053  | total loss: [1m[32m0.07184[0m[0m | time: 23.580s
[2K
| Adam | epoch: 022 | loss: 0.07184 - acc: 0.9772 -- iter: 1184/3072
[A[ATraining Step: 2054  | total loss: [1m[32m0.06754[0m[0m | time: 24.253s
[2K
| Adam | epoch: 022 | loss: 0.06754 - acc: 0.9795 -- iter: 1216/3072
[A[ATraining Step: 2055  | total loss: [1m[32m0.06510[0m[0m | time: 24.899s
[2K
| Adam | epoch: 022 | loss: 0.06510 - acc: 0.9816 -- iter: 1248/3072
[A[ATraining Step: 2056  | total loss: [1m[32m0.06201[0m[0m | time: 25.637s
[2K
| Adam | epoch: 022 | loss: 0.06201 - acc: 0.9803 -- iter: 1280/3072
[A[ATraining Step: 2057  | total loss: [1m[32m0.06421[0m[0m | time: 26.228s
[2K
| Adam | epoch: 022 | loss: 0.06421 - acc: 0.9791 -- iter: 1312/3072
[A[ATraining Step: 2058  | total loss: [1m[32m0.07428[0m[0m | time: 26.833s
[2K
| Adam | epoch: 022 | loss: 0.07428 - acc: 0.9718 -- iter: 1344/3072
[A[ATraining Step: 2059  | total loss: [1m[32m0.08167[0m[0m | time: 27.433s
[2K
| Adam | epoch: 022 | loss: 0.08167 - acc: 0.9684 -- iter: 1376/3072
[A[ATraining Step: 2060  | total loss: [1m[32m0.08556[0m[0m | time: 28.063s
[2K
| Adam | epoch: 022 | loss: 0.08556 - acc: 0.9653 -- iter: 1408/3072
[A[ATraining Step: 2061  | total loss: [1m[32m0.09215[0m[0m | time: 28.699s
[2K
| Adam | epoch: 022 | loss: 0.09215 - acc: 0.9657 -- iter: 1440/3072
[A[ATraining Step: 2062  | total loss: [1m[32m0.08967[0m[0m | time: 29.330s
[2K
| Adam | epoch: 022 | loss: 0.08967 - acc: 0.9660 -- iter: 1472/3072
[A[ATraining Step: 2063  | total loss: [1m[32m0.08660[0m[0m | time: 29.944s
[2K
| Adam | epoch: 022 | loss: 0.08660 - acc: 0.9694 -- iter: 1504/3072
[A[ATraining Step: 2064  | total loss: [1m[32m0.08651[0m[0m | time: 30.561s
[2K
| Adam | epoch: 022 | loss: 0.08651 - acc: 0.9662 -- iter: 1536/3072
[A[ATraining Step: 2065  | total loss: [1m[32m0.09112[0m[0m | time: 31.165s
[2K
| Adam | epoch: 022 | loss: 0.09112 - acc: 0.9664 -- iter: 1568/3072
[A[ATraining Step: 2066  | total loss: [1m[32m0.08738[0m[0m | time: 31.878s
[2K
| Adam | epoch: 022 | loss: 0.08738 - acc: 0.9667 -- iter: 1600/3072
[A[ATraining Step: 2067  | total loss: [1m[32m0.10007[0m[0m | time: 32.490s
[2K
| Adam | epoch: 022 | loss: 0.10007 - acc: 0.9638 -- iter: 1632/3072
[A[ATraining Step: 2068  | total loss: [1m[32m0.13043[0m[0m | time: 33.084s
[2K
| Adam | epoch: 022 | loss: 0.13043 - acc: 0.9549 -- iter: 1664/3072
[A[ATraining Step: 2069  | total loss: [1m[32m0.12493[0m[0m | time: 33.688s
[2K
| Adam | epoch: 022 | loss: 0.12493 - acc: 0.9563 -- iter: 1696/3072
[A[ATraining Step: 2070  | total loss: [1m[32m0.11491[0m[0m | time: 34.294s
[2K
| Adam | epoch: 022 | loss: 0.11491 - acc: 0.9606 -- iter: 1728/3072
[A[ATraining Step: 2071  | total loss: [1m[32m0.10897[0m[0m | time: 34.933s
[2K
| Adam | epoch: 022 | loss: 0.10897 - acc: 0.9646 -- iter: 1760/3072
[A[ATraining Step: 2072  | total loss: [1m[32m0.10161[0m[0m | time: 35.628s
[2K
| Adam | epoch: 022 | loss: 0.10161 - acc: 0.9681 -- iter: 1792/3072
[A[ATraining Step: 2073  | total loss: [1m[32m0.09856[0m[0m | time: 36.272s
[2K
| Adam | epoch: 022 | loss: 0.09856 - acc: 0.9713 -- iter: 1824/3072
[A[ATraining Step: 2074  | total loss: [1m[32m0.09227[0m[0m | time: 36.885s
[2K
| Adam | epoch: 022 | loss: 0.09227 - acc: 0.9742 -- iter: 1856/3072
[A[ATraining Step: 2075  | total loss: [1m[32m0.08901[0m[0m | time: 37.519s
[2K
| Adam | epoch: 022 | loss: 0.08901 - acc: 0.9736 -- iter: 1888/3072
[A[ATraining Step: 2076  | total loss: [1m[32m0.08660[0m[0m | time: 38.275s
[2K
| Adam | epoch: 022 | loss: 0.08660 - acc: 0.9700 -- iter: 1920/3072
[A[ATraining Step: 2077  | total loss: [1m[32m0.08506[0m[0m | time: 38.922s
[2K
| Adam | epoch: 022 | loss: 0.08506 - acc: 0.9730 -- iter: 1952/3072
[A[ATraining Step: 2078  | total loss: [1m[32m0.08015[0m[0m | time: 39.522s
[2K
| Adam | epoch: 022 | loss: 0.08015 - acc: 0.9757 -- iter: 1984/3072
[A[ATraining Step: 2079  | total loss: [1m[32m0.07995[0m[0m | time: 40.135s
[2K
| Adam | epoch: 022 | loss: 0.07995 - acc: 0.9750 -- iter: 2016/3072
[A[ATraining Step: 2080  | total loss: [1m[32m0.07447[0m[0m | time: 40.737s
[2K
| Adam | epoch: 022 | loss: 0.07447 - acc: 0.9775 -- iter: 2048/3072
[A[ATraining Step: 2081  | total loss: [1m[32m0.07078[0m[0m | time: 41.390s
[2K
| Adam | epoch: 022 | loss: 0.07078 - acc: 0.9798 -- iter: 2080/3072
[A[ATraining Step: 2082  | total loss: [1m[32m0.07487[0m[0m | time: 41.993s
[2K
| Adam | epoch: 022 | loss: 0.07487 - acc: 0.9755 -- iter: 2112/3072
[A[ATraining Step: 2083  | total loss: [1m[32m0.07863[0m[0m | time: 42.597s
[2K
| Adam | epoch: 022 | loss: 0.07863 - acc: 0.9749 -- iter: 2144/3072
[A[ATraining Step: 2084  | total loss: [1m[32m0.08915[0m[0m | time: 43.209s
[2K
| Adam | epoch: 022 | loss: 0.08915 - acc: 0.9742 -- iter: 2176/3072
[A[ATraining Step: 2085  | total loss: [1m[32m0.09774[0m[0m | time: 43.808s
[2K
| Adam | epoch: 022 | loss: 0.09774 - acc: 0.9737 -- iter: 2208/3072
[A[ATraining Step: 2086  | total loss: [1m[32m0.09898[0m[0m | time: 44.421s
[2K
| Adam | epoch: 022 | loss: 0.09898 - acc: 0.9732 -- iter: 2240/3072
[A[ATraining Step: 2087  | total loss: [1m[32m0.09254[0m[0m | time: 45.046s
[2K
| Adam | epoch: 022 | loss: 0.09254 - acc: 0.9759 -- iter: 2272/3072
[A[ATraining Step: 2088  | total loss: [1m[32m0.08675[0m[0m | time: 45.664s
[2K
| Adam | epoch: 022 | loss: 0.08675 - acc: 0.9783 -- iter: 2304/3072
[A[ATraining Step: 2089  | total loss: [1m[32m0.08606[0m[0m | time: 46.271s
[2K
| Adam | epoch: 022 | loss: 0.08606 - acc: 0.9773 -- iter: 2336/3072
[A[ATraining Step: 2090  | total loss: [1m[32m0.08111[0m[0m | time: 46.910s
[2K
| Adam | epoch: 022 | loss: 0.08111 - acc: 0.9796 -- iter: 2368/3072
[A[ATraining Step: 2091  | total loss: [1m[32m0.08441[0m[0m | time: 47.552s
[2K
| Adam | epoch: 022 | loss: 0.08441 - acc: 0.9785 -- iter: 2400/3072
[A[ATraining Step: 2092  | total loss: [1m[32m0.08369[0m[0m | time: 48.164s
[2K
| Adam | epoch: 022 | loss: 0.08369 - acc: 0.9775 -- iter: 2432/3072
[A[ATraining Step: 2093  | total loss: [1m[32m0.08093[0m[0m | time: 48.762s
[2K
| Adam | epoch: 022 | loss: 0.08093 - acc: 0.9767 -- iter: 2464/3072
[A[ATraining Step: 2094  | total loss: [1m[32m0.10084[0m[0m | time: 49.362s
[2K
| Adam | epoch: 022 | loss: 0.10084 - acc: 0.9696 -- iter: 2496/3072
[A[ATraining Step: 2095  | total loss: [1m[32m0.10175[0m[0m | time: 50.000s
[2K
| Adam | epoch: 022 | loss: 0.10175 - acc: 0.9695 -- iter: 2528/3072
[A[ATraining Step: 2096  | total loss: [1m[32m0.09709[0m[0m | time: 50.606s
[2K
| Adam | epoch: 022 | loss: 0.09709 - acc: 0.9695 -- iter: 2560/3072
[A[ATraining Step: 2097  | total loss: [1m[32m0.11058[0m[0m | time: 51.304s
[2K
| Adam | epoch: 022 | loss: 0.11058 - acc: 0.9663 -- iter: 2592/3072
[A[ATraining Step: 2098  | total loss: [1m[32m0.12066[0m[0m | time: 51.915s
[2K
| Adam | epoch: 022 | loss: 0.12066 - acc: 0.9665 -- iter: 2624/3072
[A[ATraining Step: 2099  | total loss: [1m[32m0.12520[0m[0m | time: 52.513s
[2K
| Adam | epoch: 022 | loss: 0.12520 - acc: 0.9667 -- iter: 2656/3072
[A[ATraining Step: 2100  | total loss: [1m[32m0.11559[0m[0m | time: 53.162s
[2K
| Adam | epoch: 022 | loss: 0.11559 - acc: 0.9701 -- iter: 2688/3072
[A[ATraining Step: 2101  | total loss: [1m[32m0.10701[0m[0m | time: 53.772s
[2K
| Adam | epoch: 022 | loss: 0.10701 - acc: 0.9731 -- iter: 2720/3072
[A[ATraining Step: 2102  | total loss: [1m[32m0.13566[0m[0m | time: 54.379s
[2K
| Adam | epoch: 022 | loss: 0.13566 - acc: 0.9726 -- iter: 2752/3072
[A[ATraining Step: 2103  | total loss: [1m[32m0.12528[0m[0m | time: 55.027s
[2K
| Adam | epoch: 022 | loss: 0.12528 - acc: 0.9754 -- iter: 2784/3072
[A[ATraining Step: 2104  | total loss: [1m[32m0.11838[0m[0m | time: 55.631s
[2K
| Adam | epoch: 022 | loss: 0.11838 - acc: 0.9747 -- iter: 2816/3072
[A[ATraining Step: 2105  | total loss: [1m[32m0.11024[0m[0m | time: 56.285s
[2K
| Adam | epoch: 022 | loss: 0.11024 - acc: 0.9741 -- iter: 2848/3072
[A[ATraining Step: 2106  | total loss: [1m[32m0.10861[0m[0m | time: 56.886s
[2K
| Adam | epoch: 022 | loss: 0.10861 - acc: 0.9736 -- iter: 2880/3072
[A[ATraining Step: 2107  | total loss: [1m[32m0.10579[0m[0m | time: 57.530s
[2K
| Adam | epoch: 022 | loss: 0.10579 - acc: 0.9731 -- iter: 2912/3072
[A[ATraining Step: 2108  | total loss: [1m[32m0.11074[0m[0m | time: 58.159s
[2K
| Adam | epoch: 022 | loss: 0.11074 - acc: 0.9727 -- iter: 2944/3072
[A[ATraining Step: 2109  | total loss: [1m[32m0.10583[0m[0m | time: 58.777s
[2K
| Adam | epoch: 022 | loss: 0.10583 - acc: 0.9723 -- iter: 2976/3072
[A[ATraining Step: 2110  | total loss: [1m[32m0.10153[0m[0m | time: 59.425s
[2K
| Adam | epoch: 022 | loss: 0.10153 - acc: 0.9719 -- iter: 3008/3072
[A[ATraining Step: 2111  | total loss: [1m[32m0.09603[0m[0m | time: 60.029s
[2K
| Adam | epoch: 022 | loss: 0.09603 - acc: 0.9747 -- iter: 3040/3072
[A[ATraining Step: 2112  | total loss: [1m[32m0.08981[0m[0m | time: 63.835s
[2K
| Adam | epoch: 022 | loss: 0.08981 - acc: 0.9772 | val_loss: 0.65992 - val_acc: 0.8033 -- iter: 3072/3072
--
Training Step: 2113  | total loss: [1m[32m0.08694[0m[0m | time: 0.624s
[2K
| Adam | epoch: 023 | loss: 0.08694 - acc: 0.9764 -- iter: 0032/3072
[A[ATraining Step: 2114  | total loss: [1m[32m0.08093[0m[0m | time: 1.300s
[2K
| Adam | epoch: 023 | loss: 0.08093 - acc: 0.9788 -- iter: 0064/3072
[A[ATraining Step: 2115  | total loss: [1m[32m0.08044[0m[0m | time: 1.941s
[2K
| Adam | epoch: 023 | loss: 0.08044 - acc: 0.9778 -- iter: 0096/3072
[A[ATraining Step: 2116  | total loss: [1m[32m0.07322[0m[0m | time: 2.549s
[2K
| Adam | epoch: 023 | loss: 0.07322 - acc: 0.9800 -- iter: 0128/3072
[A[ATraining Step: 2117  | total loss: [1m[32m0.07096[0m[0m | time: 3.188s
[2K
| Adam | epoch: 023 | loss: 0.07096 - acc: 0.9820 -- iter: 0160/3072
[A[ATraining Step: 2118  | total loss: [1m[32m0.06693[0m[0m | time: 3.821s
[2K
| Adam | epoch: 023 | loss: 0.06693 - acc: 0.9838 -- iter: 0192/3072
[A[ATraining Step: 2119  | total loss: [1m[32m0.06560[0m[0m | time: 4.421s
[2K
| Adam | epoch: 023 | loss: 0.06560 - acc: 0.9854 -- iter: 0224/3072
[A[ATraining Step: 2120  | total loss: [1m[32m0.06114[0m[0m | time: 5.034s
[2K
| Adam | epoch: 023 | loss: 0.06114 - acc: 0.9869 -- iter: 0256/3072
[A[ATraining Step: 2121  | total loss: [1m[32m0.05824[0m[0m | time: 5.641s
[2K
| Adam | epoch: 023 | loss: 0.05824 - acc: 0.9882 -- iter: 0288/3072
[A[ATraining Step: 2122  | total loss: [1m[32m0.06073[0m[0m | time: 6.258s
[2K
| Adam | epoch: 023 | loss: 0.06073 - acc: 0.9862 -- iter: 0320/3072
[A[ATraining Step: 2123  | total loss: [1m[32m0.05534[0m[0m | time: 6.869s
[2K
| Adam | epoch: 023 | loss: 0.05534 - acc: 0.9876 -- iter: 0352/3072
[A[ATraining Step: 2124  | total loss: [1m[32m0.05456[0m[0m | time: 7.500s
[2K
| Adam | epoch: 023 | loss: 0.05456 - acc: 0.9889 -- iter: 0384/3072
[A[ATraining Step: 2125  | total loss: [1m[32m0.05400[0m[0m | time: 8.112s
[2K
| Adam | epoch: 023 | loss: 0.05400 - acc: 0.9900 -- iter: 0416/3072
[A[ATraining Step: 2126  | total loss: [1m[32m0.05453[0m[0m | time: 8.740s
[2K
| Adam | epoch: 023 | loss: 0.05453 - acc: 0.9878 -- iter: 0448/3072
[A[ATraining Step: 2127  | total loss: [1m[32m0.05618[0m[0m | time: 9.390s
[2K
| Adam | epoch: 023 | loss: 0.05618 - acc: 0.9891 -- iter: 0480/3072
[A[ATraining Step: 2128  | total loss: [1m[32m0.05326[0m[0m | time: 10.017s
[2K
| Adam | epoch: 023 | loss: 0.05326 - acc: 0.9902 -- iter: 0512/3072
[A[ATraining Step: 2129  | total loss: [1m[32m0.05002[0m[0m | time: 10.639s
[2K
| Adam | epoch: 023 | loss: 0.05002 - acc: 0.9911 -- iter: 0544/3072
[A[ATraining Step: 2130  | total loss: [1m[32m0.06181[0m[0m | time: 11.239s
[2K
| Adam | epoch: 023 | loss: 0.06181 - acc: 0.9858 -- iter: 0576/3072
[A[ATraining Step: 2131  | total loss: [1m[32m0.07245[0m[0m | time: 11.861s
[2K
| Adam | epoch: 023 | loss: 0.07245 - acc: 0.9809 -- iter: 0608/3072
[A[ATraining Step: 2132  | total loss: [1m[32m0.07090[0m[0m | time: 12.467s
[2K
| Adam | epoch: 023 | loss: 0.07090 - acc: 0.9829 -- iter: 0640/3072
[A[ATraining Step: 2133  | total loss: [1m[32m0.06806[0m[0m | time: 13.079s
[2K
| Adam | epoch: 023 | loss: 0.06806 - acc: 0.9846 -- iter: 0672/3072
[A[ATraining Step: 2134  | total loss: [1m[32m0.08598[0m[0m | time: 13.759s
[2K
| Adam | epoch: 023 | loss: 0.08598 - acc: 0.9767 -- iter: 0704/3072
[A[ATraining Step: 2135  | total loss: [1m[32m0.10666[0m[0m | time: 14.363s
[2K
| Adam | epoch: 023 | loss: 0.10666 - acc: 0.9697 -- iter: 0736/3072
[A[ATraining Step: 2136  | total loss: [1m[32m0.11424[0m[0m | time: 14.967s
[2K
| Adam | epoch: 023 | loss: 0.11424 - acc: 0.9696 -- iter: 0768/3072
[A[ATraining Step: 2137  | total loss: [1m[32m0.10736[0m[0m | time: 15.591s
[2K
| Adam | epoch: 023 | loss: 0.10736 - acc: 0.9726 -- iter: 0800/3072
[A[ATraining Step: 2138  | total loss: [1m[32m0.09859[0m[0m | time: 16.227s
[2K
| Adam | epoch: 023 | loss: 0.09859 - acc: 0.9754 -- iter: 0832/3072
[A[ATraining Step: 2139  | total loss: [1m[32m0.09135[0m[0m | time: 16.833s
[2K
| Adam | epoch: 023 | loss: 0.09135 - acc: 0.9778 -- iter: 0864/3072
[A[ATraining Step: 2140  | total loss: [1m[32m0.08654[0m[0m | time: 17.438s
[2K
| Adam | epoch: 023 | loss: 0.08654 - acc: 0.9801 -- iter: 0896/3072
[A[ATraining Step: 2141  | total loss: [1m[32m0.08606[0m[0m | time: 18.043s
[2K
| Adam | epoch: 023 | loss: 0.08606 - acc: 0.9789 -- iter: 0928/3072
[A[ATraining Step: 2142  | total loss: [1m[32m0.07966[0m[0m | time: 18.693s
[2K
| Adam | epoch: 023 | loss: 0.07966 - acc: 0.9810 -- iter: 0960/3072
[A[ATraining Step: 2143  | total loss: [1m[32m0.07351[0m[0m | time: 19.464s
[2K
| Adam | epoch: 023 | loss: 0.07351 - acc: 0.9829 -- iter: 0992/3072
[A[ATraining Step: 2144  | total loss: [1m[32m0.08329[0m[0m | time: 20.075s
[2K
| Adam | epoch: 023 | loss: 0.08329 - acc: 0.9784 -- iter: 1024/3072
[A[ATraining Step: 2145  | total loss: [1m[32m0.08375[0m[0m | time: 20.684s
[2K
| Adam | epoch: 023 | loss: 0.08375 - acc: 0.9774 -- iter: 1056/3072
[A[ATraining Step: 2146  | total loss: [1m[32m0.07940[0m[0m | time: 21.287s
[2K
| Adam | epoch: 023 | loss: 0.07940 - acc: 0.9797 -- iter: 1088/3072
[A[ATraining Step: 2147  | total loss: [1m[32m0.07378[0m[0m | time: 21.909s
[2K
| Adam | epoch: 023 | loss: 0.07378 - acc: 0.9817 -- iter: 1120/3072
[A[ATraining Step: 2148  | total loss: [1m[32m0.07928[0m[0m | time: 22.536s
[2K
| Adam | epoch: 023 | loss: 0.07928 - acc: 0.9773 -- iter: 1152/3072
[A[ATraining Step: 2149  | total loss: [1m[32m0.07353[0m[0m | time: 23.150s
[2K
| Adam | epoch: 023 | loss: 0.07353 - acc: 0.9796 -- iter: 1184/3072
[A[ATraining Step: 2150  | total loss: [1m[32m0.06850[0m[0m | time: 23.792s
[2K
| Adam | epoch: 023 | loss: 0.06850 - acc: 0.9816 -- iter: 1216/3072
[A[ATraining Step: 2151  | total loss: [1m[32m0.06356[0m[0m | time: 24.403s
[2K
| Adam | epoch: 023 | loss: 0.06356 - acc: 0.9834 -- iter: 1248/3072
[A[ATraining Step: 2152  | total loss: [1m[32m0.08274[0m[0m | time: 25.017s
[2K
| Adam | epoch: 023 | loss: 0.08274 - acc: 0.9820 -- iter: 1280/3072
[A[ATraining Step: 2153  | total loss: [1m[32m0.08398[0m[0m | time: 25.667s
[2K
| Adam | epoch: 023 | loss: 0.08398 - acc: 0.9807 -- iter: 1312/3072
[A[ATraining Step: 2154  | total loss: [1m[32m0.07818[0m[0m | time: 26.310s
[2K
| Adam | epoch: 023 | loss: 0.07818 - acc: 0.9826 -- iter: 1344/3072
[A[ATraining Step: 2155  | total loss: [1m[32m0.07283[0m[0m | time: 26.912s
[2K
| Adam | epoch: 023 | loss: 0.07283 - acc: 0.9843 -- iter: 1376/3072
[A[ATraining Step: 2156  | total loss: [1m[32m0.07170[0m[0m | time: 27.520s
[2K
| Adam | epoch: 023 | loss: 0.07170 - acc: 0.9859 -- iter: 1408/3072
[A[ATraining Step: 2157  | total loss: [1m[32m0.06686[0m[0m | time: 28.152s
[2K
| Adam | epoch: 023 | loss: 0.06686 - acc: 0.9873 -- iter: 1440/3072
[A[ATraining Step: 2158  | total loss: [1m[32m0.06517[0m[0m | time: 28.791s
[2K
| Adam | epoch: 023 | loss: 0.06517 - acc: 0.9886 -- iter: 1472/3072
[A[ATraining Step: 2159  | total loss: [1m[32m0.06110[0m[0m | time: 29.390s
[2K
| Adam | epoch: 023 | loss: 0.06110 - acc: 0.9897 -- iter: 1504/3072
[A[ATraining Step: 2160  | total loss: [1m[32m0.06400[0m[0m | time: 30.039s
[2K
| Adam | epoch: 023 | loss: 0.06400 - acc: 0.9845 -- iter: 1536/3072
[A[ATraining Step: 2161  | total loss: [1m[32m0.08409[0m[0m | time: 30.664s
[2K
| Adam | epoch: 023 | loss: 0.08409 - acc: 0.9798 -- iter: 1568/3072
[A[ATraining Step: 2162  | total loss: [1m[32m0.08078[0m[0m | time: 31.322s
[2K
| Adam | epoch: 023 | loss: 0.08078 - acc: 0.9818 -- iter: 1600/3072
[A[ATraining Step: 2163  | total loss: [1m[32m0.07721[0m[0m | time: 31.935s
[2K
| Adam | epoch: 023 | loss: 0.07721 - acc: 0.9805 -- iter: 1632/3072
[A[ATraining Step: 2164  | total loss: [1m[32m0.07081[0m[0m | time: 32.540s
[2K
| Adam | epoch: 023 | loss: 0.07081 - acc: 0.9825 -- iter: 1664/3072
[A[ATraining Step: 2165  | total loss: [1m[32m0.08563[0m[0m | time: 33.155s
[2K
| Adam | epoch: 023 | loss: 0.08563 - acc: 0.9748 -- iter: 1696/3072
[A[ATraining Step: 2166  | total loss: [1m[32m0.07925[0m[0m | time: 33.766s
[2K
| Adam | epoch: 023 | loss: 0.07925 - acc: 0.9774 -- iter: 1728/3072
[A[ATraining Step: 2167  | total loss: [1m[32m0.07595[0m[0m | time: 34.409s
[2K
| Adam | epoch: 023 | loss: 0.07595 - acc: 0.9796 -- iter: 1760/3072
[A[ATraining Step: 2168  | total loss: [1m[32m0.07418[0m[0m | time: 35.058s
[2K
| Adam | epoch: 023 | loss: 0.07418 - acc: 0.9785 -- iter: 1792/3072
[A[ATraining Step: 2169  | total loss: [1m[32m0.06828[0m[0m | time: 35.671s
[2K
| Adam | epoch: 023 | loss: 0.06828 - acc: 0.9807 -- iter: 1824/3072
[A[ATraining Step: 2170  | total loss: [1m[32m0.06513[0m[0m | time: 36.326s
[2K
| Adam | epoch: 023 | loss: 0.06513 - acc: 0.9826 -- iter: 1856/3072
[A[ATraining Step: 2171  | total loss: [1m[32m0.06564[0m[0m | time: 36.937s
[2K
| Adam | epoch: 023 | loss: 0.06564 - acc: 0.9812 -- iter: 1888/3072
[A[ATraining Step: 2172  | total loss: [1m[32m0.06559[0m[0m | time: 37.550s
[2K
| Adam | epoch: 023 | loss: 0.06559 - acc: 0.9800 -- iter: 1920/3072
[A[ATraining Step: 2173  | total loss: [1m[32m0.06416[0m[0m | time: 38.189s
[2K
| Adam | epoch: 023 | loss: 0.06416 - acc: 0.9789 -- iter: 1952/3072
[A[ATraining Step: 2174  | total loss: [1m[32m0.06158[0m[0m | time: 38.791s
[2K
| Adam | epoch: 023 | loss: 0.06158 - acc: 0.9810 -- iter: 1984/3072
[A[ATraining Step: 2175  | total loss: [1m[32m0.05650[0m[0m | time: 39.444s
[2K
| Adam | epoch: 023 | loss: 0.05650 - acc: 0.9829 -- iter: 2016/3072
[A[ATraining Step: 2176  | total loss: [1m[32m0.05567[0m[0m | time: 40.053s
[2K
| Adam | epoch: 023 | loss: 0.05567 - acc: 0.9815 -- iter: 2048/3072
[A[ATraining Step: 2177  | total loss: [1m[32m0.05249[0m[0m | time: 40.658s
[2K
| Adam | epoch: 023 | loss: 0.05249 - acc: 0.9833 -- iter: 2080/3072
[A[ATraining Step: 2178  | total loss: [1m[32m0.05045[0m[0m | time: 41.294s
[2K
| Adam | epoch: 023 | loss: 0.05045 - acc: 0.9850 -- iter: 2112/3072
[A[ATraining Step: 2179  | total loss: [1m[32m0.04597[0m[0m | time: 41.946s
[2K
| Adam | epoch: 023 | loss: 0.04597 - acc: 0.9865 -- iter: 2144/3072
[A[ATraining Step: 2180  | total loss: [1m[32m0.04331[0m[0m | time: 42.584s
[2K
| Adam | epoch: 023 | loss: 0.04331 - acc: 0.9878 -- iter: 2176/3072
[A[ATraining Step: 2181  | total loss: [1m[32m0.04074[0m[0m | time: 43.212s
[2K
| Adam | epoch: 023 | loss: 0.04074 - acc: 0.9891 -- iter: 2208/3072
[A[ATraining Step: 2182  | total loss: [1m[32m0.05100[0m[0m | time: 43.873s
[2K
| Adam | epoch: 023 | loss: 0.05100 - acc: 0.9870 -- iter: 2240/3072
[A[ATraining Step: 2183  | total loss: [1m[32m0.05933[0m[0m | time: 44.480s
[2K
| Adam | epoch: 023 | loss: 0.05933 - acc: 0.9852 -- iter: 2272/3072
[A[ATraining Step: 2184  | total loss: [1m[32m0.05748[0m[0m | time: 45.085s
[2K
| Adam | epoch: 023 | loss: 0.05748 - acc: 0.9867 -- iter: 2304/3072
[A[ATraining Step: 2185  | total loss: [1m[32m0.05813[0m[0m | time: 45.705s
[2K
| Adam | epoch: 023 | loss: 0.05813 - acc: 0.9849 -- iter: 2336/3072
[A[ATraining Step: 2186  | total loss: [1m[32m0.05538[0m[0m | time: 46.391s
[2K
| Adam | epoch: 023 | loss: 0.05538 - acc: 0.9864 -- iter: 2368/3072
[A[ATraining Step: 2187  | total loss: [1m[32m0.05658[0m[0m | time: 47.006s
[2K
| Adam | epoch: 023 | loss: 0.05658 - acc: 0.9846 -- iter: 2400/3072
[A[ATraining Step: 2188  | total loss: [1m[32m0.05884[0m[0m | time: 47.642s
[2K
| Adam | epoch: 023 | loss: 0.05884 - acc: 0.9830 -- iter: 2432/3072
[A[ATraining Step: 2189  | total loss: [1m[32m0.05863[0m[0m | time: 48.273s
[2K
| Adam | epoch: 023 | loss: 0.05863 - acc: 0.9816 -- iter: 2464/3072
[A[ATraining Step: 2190  | total loss: [1m[32m0.05705[0m[0m | time: 48.891s
[2K
| Adam | epoch: 023 | loss: 0.05705 - acc: 0.9835 -- iter: 2496/3072
[A[ATraining Step: 2191  | total loss: [1m[32m0.06042[0m[0m | time: 49.500s
[2K
| Adam | epoch: 023 | loss: 0.06042 - acc: 0.9789 -- iter: 2528/3072
[A[ATraining Step: 2192  | total loss: [1m[32m0.06563[0m[0m | time: 50.115s
[2K
| Adam | epoch: 023 | loss: 0.06563 - acc: 0.9778 -- iter: 2560/3072
[A[ATraining Step: 2193  | total loss: [1m[32m0.06295[0m[0m | time: 50.719s
[2K
| Adam | epoch: 023 | loss: 0.06295 - acc: 0.9801 -- iter: 2592/3072
[A[ATraining Step: 2194  | total loss: [1m[32m0.06811[0m[0m | time: 51.361s
[2K
| Adam | epoch: 023 | loss: 0.06811 - acc: 0.9758 -- iter: 2624/3072
[A[ATraining Step: 2195  | total loss: [1m[32m0.07599[0m[0m | time: 52.007s
[2K
| Adam | epoch: 023 | loss: 0.07599 - acc: 0.9688 -- iter: 2656/3072
[A[ATraining Step: 2196  | total loss: [1m[32m0.08337[0m[0m | time: 52.657s
[2K
| Adam | epoch: 023 | loss: 0.08337 - acc: 0.9595 -- iter: 2688/3072
[A[ATraining Step: 2197  | total loss: [1m[32m0.07639[0m[0m | time: 53.296s
[2K
| Adam | epoch: 023 | loss: 0.07639 - acc: 0.9635 -- iter: 2720/3072
[A[ATraining Step: 2198  | total loss: [1m[32m0.08340[0m[0m | time: 53.918s
[2K
| Adam | epoch: 023 | loss: 0.08340 - acc: 0.9609 -- iter: 2752/3072
[A[ATraining Step: 2199  | total loss: [1m[32m0.10179[0m[0m | time: 54.549s
[2K
| Adam | epoch: 023 | loss: 0.10179 - acc: 0.9617 -- iter: 2784/3072
[A[ATraining Step: 2200  | total loss: [1m[32m0.09476[0m[0m | time: 58.308s
[2K
| Adam | epoch: 023 | loss: 0.09476 - acc: 0.9655 | val_loss: 0.67647 - val_acc: 0.8117 -- iter: 2816/3072
--
Training Step: 2201  | total loss: [1m[32m0.08738[0m[0m | time: 58.990s
[2K
| Adam | epoch: 023 | loss: 0.08738 - acc: 0.9690 -- iter: 2848/3072
[A[ATraining Step: 2202  | total loss: [1m[32m0.08076[0m[0m | time: 59.624s
[2K
| Adam | epoch: 023 | loss: 0.08076 - acc: 0.9721 -- iter: 2880/3072
[A[ATraining Step: 2203  | total loss: [1m[32m0.07497[0m[0m | time: 60.262s
[2K
| Adam | epoch: 023 | loss: 0.07497 - acc: 0.9749 -- iter: 2912/3072
[A[ATraining Step: 2204  | total loss: [1m[32m0.06897[0m[0m | time: 60.888s
[2K
| Adam | epoch: 023 | loss: 0.06897 - acc: 0.9774 -- iter: 2944/3072
[A[ATraining Step: 2205  | total loss: [1m[32m0.06846[0m[0m | time: 61.505s
[2K
| Adam | epoch: 023 | loss: 0.06846 - acc: 0.9796 -- iter: 2976/3072
[A[ATraining Step: 2206  | total loss: [1m[32m0.06379[0m[0m | time: 62.216s
[2K
| Adam | epoch: 023 | loss: 0.06379 - acc: 0.9817 -- iter: 3008/3072
[A[ATraining Step: 2207  | total loss: [1m[32m0.05877[0m[0m | time: 62.873s
[2K
| Adam | epoch: 023 | loss: 0.05877 - acc: 0.9835 -- iter: 3040/3072
[A[ATraining Step: 2208  | total loss: [1m[32m0.05446[0m[0m | time: 66.936s
[2K
| Adam | epoch: 023 | loss: 0.05446 - acc: 0.9852 | val_loss: 0.76350 - val_acc: 0.7960 -- iter: 3072/3072
--
Training Step: 2209  | total loss: [1m[32m0.05664[0m[0m | time: 0.651s
[2K
| Adam | epoch: 024 | loss: 0.05664 - acc: 0.9835 -- iter: 0032/3072
[A[ATraining Step: 2210  | total loss: [1m[32m0.06004[0m[0m | time: 1.340s
[2K
| Adam | epoch: 024 | loss: 0.06004 - acc: 0.9820 -- iter: 0064/3072
[A[ATraining Step: 2211  | total loss: [1m[32m0.05597[0m[0m | time: 2.028s
[2K
| Adam | epoch: 024 | loss: 0.05597 - acc: 0.9838 -- iter: 0096/3072
[A[ATraining Step: 2212  | total loss: [1m[32m0.05687[0m[0m | time: 2.672s
[2K
| Adam | epoch: 024 | loss: 0.05687 - acc: 0.9823 -- iter: 0128/3072
[A[ATraining Step: 2213  | total loss: [1m[32m0.05325[0m[0m | time: 3.299s
[2K
| Adam | epoch: 024 | loss: 0.05325 - acc: 0.9841 -- iter: 0160/3072
[A[ATraining Step: 2214  | total loss: [1m[32m0.05110[0m[0m | time: 3.908s
[2K
| Adam | epoch: 024 | loss: 0.05110 - acc: 0.9857 -- iter: 0192/3072
[A[ATraining Step: 2215  | total loss: [1m[32m0.04738[0m[0m | time: 4.509s
[2K
| Adam | epoch: 024 | loss: 0.04738 - acc: 0.9871 -- iter: 0224/3072
[A[ATraining Step: 2216  | total loss: [1m[32m0.06059[0m[0m | time: 5.125s
[2K
| Adam | epoch: 024 | loss: 0.06059 - acc: 0.9822 -- iter: 0256/3072
[A[ATraining Step: 2217  | total loss: [1m[32m0.05782[0m[0m | time: 5.813s
[2K
| Adam | epoch: 024 | loss: 0.05782 - acc: 0.9839 -- iter: 0288/3072
[A[ATraining Step: 2218  | total loss: [1m[32m0.05400[0m[0m | time: 6.495s
[2K
| Adam | epoch: 024 | loss: 0.05400 - acc: 0.9855 -- iter: 0320/3072
[A[ATraining Step: 2219  | total loss: [1m[32m0.06347[0m[0m | time: 7.133s
[2K
| Adam | epoch: 024 | loss: 0.06347 - acc: 0.9839 -- iter: 0352/3072
[A[ATraining Step: 2220  | total loss: [1m[32m0.06336[0m[0m | time: 7.737s
[2K
| Adam | epoch: 024 | loss: 0.06336 - acc: 0.9824 -- iter: 0384/3072
[A[ATraining Step: 2221  | total loss: [1m[32m0.05965[0m[0m | time: 8.391s
[2K
| Adam | epoch: 024 | loss: 0.05965 - acc: 0.9841 -- iter: 0416/3072
[A[ATraining Step: 2222  | total loss: [1m[32m0.06286[0m[0m | time: 9.036s
[2K
| Adam | epoch: 024 | loss: 0.06286 - acc: 0.9826 -- iter: 0448/3072
[A[ATraining Step: 2223  | total loss: [1m[32m0.05795[0m[0m | time: 9.677s
[2K
| Adam | epoch: 024 | loss: 0.05795 - acc: 0.9843 -- iter: 0480/3072
[A[ATraining Step: 2224  | total loss: [1m[32m0.05727[0m[0m | time: 10.298s
[2K
| Adam | epoch: 024 | loss: 0.05727 - acc: 0.9859 -- iter: 0512/3072
[A[ATraining Step: 2225  | total loss: [1m[32m0.06259[0m[0m | time: 10.903s
[2K
| Adam | epoch: 024 | loss: 0.06259 - acc: 0.9811 -- iter: 0544/3072
[A[ATraining Step: 2226  | total loss: [1m[32m0.05761[0m[0m | time: 11.530s
[2K
| Adam | epoch: 024 | loss: 0.05761 - acc: 0.9829 -- iter: 0576/3072
[A[ATraining Step: 2227  | total loss: [1m[32m0.05521[0m[0m | time: 12.136s
[2K
| Adam | epoch: 024 | loss: 0.05521 - acc: 0.9815 -- iter: 0608/3072
[A[ATraining Step: 2228  | total loss: [1m[32m0.05133[0m[0m | time: 12.745s
[2K
| Adam | epoch: 024 | loss: 0.05133 - acc: 0.9834 -- iter: 0640/3072
[A[ATraining Step: 2229  | total loss: [1m[32m0.04766[0m[0m | time: 13.463s
[2K
| Adam | epoch: 024 | loss: 0.04766 - acc: 0.9850 -- iter: 0672/3072
[A[ATraining Step: 2230  | total loss: [1m[32m0.04404[0m[0m | time: 14.051s
[2K
| Adam | epoch: 024 | loss: 0.04404 - acc: 0.9865 -- iter: 0704/3072
[A[ATraining Step: 2231  | total loss: [1m[32m0.04223[0m[0m | time: 14.653s
[2K
| Adam | epoch: 024 | loss: 0.04223 - acc: 0.9879 -- iter: 0736/3072
[A[ATraining Step: 2232  | total loss: [1m[32m0.04010[0m[0m | time: 15.289s
[2K
| Adam | epoch: 024 | loss: 0.04010 - acc: 0.9891 -- iter: 0768/3072
[A[ATraining Step: 2233  | total loss: [1m[32m0.04198[0m[0m | time: 15.903s
[2K
| Adam | epoch: 024 | loss: 0.04198 - acc: 0.9871 -- iter: 0800/3072
[A[ATraining Step: 2234  | total loss: [1m[32m0.03986[0m[0m | time: 16.544s
[2K
| Adam | epoch: 024 | loss: 0.03986 - acc: 0.9884 -- iter: 0832/3072
[A[ATraining Step: 2235  | total loss: [1m[32m0.03717[0m[0m | time: 17.218s
[2K
| Adam | epoch: 024 | loss: 0.03717 - acc: 0.9895 -- iter: 0864/3072
[A[ATraining Step: 2236  | total loss: [1m[32m0.03950[0m[0m | time: 17.853s
[2K
| Adam | epoch: 024 | loss: 0.03950 - acc: 0.9874 -- iter: 0896/3072
[A[ATraining Step: 2237  | total loss: [1m[32m0.04029[0m[0m | time: 18.473s
[2K
| Adam | epoch: 024 | loss: 0.04029 - acc: 0.9887 -- iter: 0928/3072
[A[ATraining Step: 2238  | total loss: [1m[32m0.04564[0m[0m | time: 19.110s
[2K
| Adam | epoch: 024 | loss: 0.04564 - acc: 0.9867 -- iter: 0960/3072
[A[ATraining Step: 2239  | total loss: [1m[32m0.04422[0m[0m | time: 19.721s
[2K
| Adam | epoch: 024 | loss: 0.04422 - acc: 0.9880 -- iter: 0992/3072
[A[ATraining Step: 2240  | total loss: [1m[32m0.04161[0m[0m | time: 20.325s
[2K
| Adam | epoch: 024 | loss: 0.04161 - acc: 0.9892 -- iter: 1024/3072
[A[ATraining Step: 2241  | total loss: [1m[32m0.03895[0m[0m | time: 20.931s
[2K
| Adam | epoch: 024 | loss: 0.03895 - acc: 0.9903 -- iter: 1056/3072
[A[ATraining Step: 2242  | total loss: [1m[32m0.03835[0m[0m | time: 21.565s
[2K
| Adam | epoch: 024 | loss: 0.03835 - acc: 0.9913 -- iter: 1088/3072
[A[ATraining Step: 2243  | total loss: [1m[32m0.04208[0m[0m | time: 22.181s
[2K
| Adam | epoch: 024 | loss: 0.04208 - acc: 0.9890 -- iter: 1120/3072
[A[ATraining Step: 2244  | total loss: [1m[32m0.04300[0m[0m | time: 22.850s
[2K
| Adam | epoch: 024 | loss: 0.04300 - acc: 0.9901 -- iter: 1152/3072
[A[ATraining Step: 2245  | total loss: [1m[32m0.04609[0m[0m | time: 23.464s
[2K
| Adam | epoch: 024 | loss: 0.04609 - acc: 0.9880 -- iter: 1184/3072
[A[ATraining Step: 2246  | total loss: [1m[32m0.05642[0m[0m | time: 24.110s
[2K
| Adam | epoch: 024 | loss: 0.05642 - acc: 0.9829 -- iter: 1216/3072
[A[ATraining Step: 2247  | total loss: [1m[32m0.08098[0m[0m | time: 24.713s
[2K
| Adam | epoch: 024 | loss: 0.08098 - acc: 0.9784 -- iter: 1248/3072
[A[ATraining Step: 2248  | total loss: [1m[32m0.10152[0m[0m | time: 25.348s
[2K
| Adam | epoch: 024 | loss: 0.10152 - acc: 0.9774 -- iter: 1280/3072
[A[ATraining Step: 2249  | total loss: [1m[32m0.09727[0m[0m | time: 25.990s
[2K
| Adam | epoch: 024 | loss: 0.09727 - acc: 0.9797 -- iter: 1312/3072
[A[ATraining Step: 2250  | total loss: [1m[32m0.09513[0m[0m | time: 26.629s
[2K
| Adam | epoch: 024 | loss: 0.09513 - acc: 0.9786 -- iter: 1344/3072
[A[ATraining Step: 2251  | total loss: [1m[32m0.08711[0m[0m | time: 27.285s
[2K
| Adam | epoch: 024 | loss: 0.08711 - acc: 0.9807 -- iter: 1376/3072
[A[ATraining Step: 2252  | total loss: [1m[32m0.09588[0m[0m | time: 27.920s
[2K
| Adam | epoch: 024 | loss: 0.09588 - acc: 0.9733 -- iter: 1408/3072
[A[ATraining Step: 2253  | total loss: [1m[32m0.12516[0m[0m | time: 28.561s
[2K
| Adam | epoch: 024 | loss: 0.12516 - acc: 0.9603 -- iter: 1440/3072
[A[ATraining Step: 2254  | total loss: [1m[32m0.14148[0m[0m | time: 29.165s
[2K
| Adam | epoch: 024 | loss: 0.14148 - acc: 0.9580 -- iter: 1472/3072
[A[ATraining Step: 2255  | total loss: [1m[32m0.13043[0m[0m | time: 29.784s
[2K
| Adam | epoch: 024 | loss: 0.13043 - acc: 0.9622 -- iter: 1504/3072
[A[ATraining Step: 2256  | total loss: [1m[32m0.11794[0m[0m | time: 30.425s
[2K
| Adam | epoch: 024 | loss: 0.11794 - acc: 0.9660 -- iter: 1536/3072
[A[ATraining Step: 2257  | total loss: [1m[32m0.10962[0m[0m | time: 31.065s
[2K
| Adam | epoch: 024 | loss: 0.10962 - acc: 0.9694 -- iter: 1568/3072
[A[ATraining Step: 2258  | total loss: [1m[32m0.12356[0m[0m | time: 31.671s
[2K
| Adam | epoch: 024 | loss: 0.12356 - acc: 0.9568 -- iter: 1600/3072
[A[ATraining Step: 2259  | total loss: [1m[32m0.12740[0m[0m | time: 32.297s
[2K
| Adam | epoch: 024 | loss: 0.12740 - acc: 0.9518 -- iter: 1632/3072
[A[ATraining Step: 2260  | total loss: [1m[32m0.13890[0m[0m | time: 32.940s
[2K
| Adam | epoch: 024 | loss: 0.13890 - acc: 0.9472 -- iter: 1664/3072
[A[ATraining Step: 2261  | total loss: [1m[32m0.12563[0m[0m | time: 33.549s
[2K
| Adam | epoch: 024 | loss: 0.12563 - acc: 0.9525 -- iter: 1696/3072
[A[ATraining Step: 2262  | total loss: [1m[32m0.11777[0m[0m | time: 34.153s
[2K
| Adam | epoch: 024 | loss: 0.11777 - acc: 0.9541 -- iter: 1728/3072
[A[ATraining Step: 2263  | total loss: [1m[32m0.11868[0m[0m | time: 34.822s
[2K
| Adam | epoch: 024 | loss: 0.11868 - acc: 0.9556 -- iter: 1760/3072
[A[ATraining Step: 2264  | total loss: [1m[32m0.11740[0m[0m | time: 35.468s
[2K
| Adam | epoch: 024 | loss: 0.11740 - acc: 0.9569 -- iter: 1792/3072
[A[ATraining Step: 2265  | total loss: [1m[32m0.10713[0m[0m | time: 36.083s
[2K
| Adam | epoch: 024 | loss: 0.10713 - acc: 0.9612 -- iter: 1824/3072
[A[ATraining Step: 2266  | total loss: [1m[32m0.11372[0m[0m | time: 36.756s
[2K
| Adam | epoch: 024 | loss: 0.11372 - acc: 0.9588 -- iter: 1856/3072
[A[ATraining Step: 2267  | total loss: [1m[32m0.10369[0m[0m | time: 37.360s
[2K
| Adam | epoch: 024 | loss: 0.10369 - acc: 0.9630 -- iter: 1888/3072
[A[ATraining Step: 2268  | total loss: [1m[32m0.09535[0m[0m | time: 37.971s
[2K
| Adam | epoch: 024 | loss: 0.09535 - acc: 0.9667 -- iter: 1920/3072
[A[ATraining Step: 2269  | total loss: [1m[32m0.09015[0m[0m | time: 38.634s
[2K
| Adam | epoch: 024 | loss: 0.09015 - acc: 0.9700 -- iter: 1952/3072
[A[ATraining Step: 2270  | total loss: [1m[32m0.08358[0m[0m | time: 39.317s
[2K
| Adam | epoch: 024 | loss: 0.08358 - acc: 0.9730 -- iter: 1984/3072
[A[ATraining Step: 2271  | total loss: [1m[32m0.07975[0m[0m | time: 40.015s
[2K
| Adam | epoch: 024 | loss: 0.07975 - acc: 0.9726 -- iter: 2016/3072
[A[ATraining Step: 2272  | total loss: [1m[32m0.07636[0m[0m | time: 40.648s
[2K
| Adam | epoch: 024 | loss: 0.07636 - acc: 0.9722 -- iter: 2048/3072
[A[ATraining Step: 2273  | total loss: [1m[32m0.07752[0m[0m | time: 41.269s
[2K
| Adam | epoch: 024 | loss: 0.07752 - acc: 0.9718 -- iter: 2080/3072
[A[ATraining Step: 2274  | total loss: [1m[32m0.07197[0m[0m | time: 41.870s
[2K
| Adam | epoch: 024 | loss: 0.07197 - acc: 0.9747 -- iter: 2112/3072
[A[ATraining Step: 2275  | total loss: [1m[32m0.06600[0m[0m | time: 42.537s
[2K
| Adam | epoch: 024 | loss: 0.06600 - acc: 0.9772 -- iter: 2144/3072
[A[ATraining Step: 2276  | total loss: [1m[32m0.06661[0m[0m | time: 43.152s
[2K
| Adam | epoch: 024 | loss: 0.06661 - acc: 0.9764 -- iter: 2176/3072
[A[ATraining Step: 2277  | total loss: [1m[32m0.06112[0m[0m | time: 43.760s
[2K
| Adam | epoch: 024 | loss: 0.06112 - acc: 0.9787 -- iter: 2208/3072
[A[ATraining Step: 2278  | total loss: [1m[32m0.06001[0m[0m | time: 44.363s
[2K
| Adam | epoch: 024 | loss: 0.06001 - acc: 0.9777 -- iter: 2240/3072
[A[ATraining Step: 2279  | total loss: [1m[32m0.07757[0m[0m | time: 44.969s
[2K
| Adam | epoch: 024 | loss: 0.07757 - acc: 0.9768 -- iter: 2272/3072
[A[ATraining Step: 2280  | total loss: [1m[32m0.07331[0m[0m | time: 45.650s
[2K
| Adam | epoch: 024 | loss: 0.07331 - acc: 0.9791 -- iter: 2304/3072
[A[ATraining Step: 2281  | total loss: [1m[32m0.06872[0m[0m | time: 46.272s
[2K
| Adam | epoch: 024 | loss: 0.06872 - acc: 0.9812 -- iter: 2336/3072
[A[ATraining Step: 2282  | total loss: [1m[32m0.06331[0m[0m | time: 46.922s
[2K
| Adam | epoch: 024 | loss: 0.06331 - acc: 0.9831 -- iter: 2368/3072
[A[ATraining Step: 2283  | total loss: [1m[32m0.06851[0m[0m | time: 47.524s
[2K
| Adam | epoch: 024 | loss: 0.06851 - acc: 0.9785 -- iter: 2400/3072
[A[ATraining Step: 2284  | total loss: [1m[32m0.06505[0m[0m | time: 48.176s
[2K
| Adam | epoch: 024 | loss: 0.06505 - acc: 0.9807 -- iter: 2432/3072
[A[ATraining Step: 2285  | total loss: [1m[32m0.06048[0m[0m | time: 48.770s
[2K
| Adam | epoch: 024 | loss: 0.06048 - acc: 0.9826 -- iter: 2464/3072
[A[ATraining Step: 2286  | total loss: [1m[32m0.05606[0m[0m | time: 49.364s
[2K
| Adam | epoch: 024 | loss: 0.05606 - acc: 0.9844 -- iter: 2496/3072
[A[ATraining Step: 2287  | total loss: [1m[32m0.05448[0m[0m | time: 49.974s
[2K
| Adam | epoch: 024 | loss: 0.05448 - acc: 0.9859 -- iter: 2528/3072
[A[ATraining Step: 2288  | total loss: [1m[32m0.05553[0m[0m | time: 50.588s
[2K
| Adam | epoch: 024 | loss: 0.05553 - acc: 0.9842 -- iter: 2560/3072
[A[ATraining Step: 2289  | total loss: [1m[32m0.05150[0m[0m | time: 51.222s
[2K
| Adam | epoch: 024 | loss: 0.05150 - acc: 0.9858 -- iter: 2592/3072
[A[ATraining Step: 2290  | total loss: [1m[32m0.05340[0m[0m | time: 51.937s
[2K
| Adam | epoch: 024 | loss: 0.05340 - acc: 0.9841 -- iter: 2624/3072
[A[ATraining Step: 2291  | total loss: [1m[32m0.05253[0m[0m | time: 52.627s
[2K
| Adam | epoch: 024 | loss: 0.05253 - acc: 0.9857 -- iter: 2656/3072
[A[ATraining Step: 2292  | total loss: [1m[32m0.05018[0m[0m | time: 53.240s
[2K
| Adam | epoch: 024 | loss: 0.05018 - acc: 0.9871 -- iter: 2688/3072
[A[ATraining Step: 2293  | total loss: [1m[32m0.05305[0m[0m | time: 53.860s
[2K
| Adam | epoch: 024 | loss: 0.05305 - acc: 0.9853 -- iter: 2720/3072
[A[ATraining Step: 2294  | total loss: [1m[32m0.04997[0m[0m | time: 54.465s
[2K
| Adam | epoch: 024 | loss: 0.04997 - acc: 0.9867 -- iter: 2752/3072
[A[ATraining Step: 2295  | total loss: [1m[32m0.04585[0m[0m | time: 55.086s
[2K
| Adam | epoch: 024 | loss: 0.04585 - acc: 0.9881 -- iter: 2784/3072
[A[ATraining Step: 2296  | total loss: [1m[32m0.07251[0m[0m | time: 55.697s
[2K
| Adam | epoch: 024 | loss: 0.07251 - acc: 0.9861 -- iter: 2816/3072
[A[ATraining Step: 2297  | total loss: [1m[32m0.08008[0m[0m | time: 56.342s
[2K
| Adam | epoch: 024 | loss: 0.08008 - acc: 0.9813 -- iter: 2848/3072
[A[ATraining Step: 2298  | total loss: [1m[32m0.07371[0m[0m | time: 56.945s
[2K
| Adam | epoch: 024 | loss: 0.07371 - acc: 0.9831 -- iter: 2880/3072
[A[ATraining Step: 2299  | total loss: [1m[32m0.07101[0m[0m | time: 57.587s
[2K
| Adam | epoch: 024 | loss: 0.07101 - acc: 0.9848 -- iter: 2912/3072
[A[ATraining Step: 2300  | total loss: [1m[32m0.06513[0m[0m | time: 58.216s
[2K
| Adam | epoch: 024 | loss: 0.06513 - acc: 0.9863 -- iter: 2944/3072
[A[ATraining Step: 2301  | total loss: [1m[32m0.06701[0m[0m | time: 58.850s
[2K
| Adam | epoch: 024 | loss: 0.06701 - acc: 0.9846 -- iter: 2976/3072
[A[ATraining Step: 2302  | total loss: [1m[32m0.07484[0m[0m | time: 59.460s
[2K
| Adam | epoch: 024 | loss: 0.07484 - acc: 0.9799 -- iter: 3008/3072
[A[ATraining Step: 2303  | total loss: [1m[32m0.07709[0m[0m | time: 60.116s
[2K
| Adam | epoch: 024 | loss: 0.07709 - acc: 0.9788 -- iter: 3040/3072
[A[ATraining Step: 2304  | total loss: [1m[32m0.07100[0m[0m | time: 64.055s
[2K
| Adam | epoch: 024 | loss: 0.07100 - acc: 0.9809 | val_loss: 0.75631 - val_acc: 0.8012 -- iter: 3072/3072
--
Training Step: 2305  | total loss: [1m[32m0.07508[0m[0m | time: 0.664s
[2K
| Adam | epoch: 025 | loss: 0.07508 - acc: 0.9797 -- iter: 0032/3072
[A[ATraining Step: 2306  | total loss: [1m[32m0.07100[0m[0m | time: 1.278s
[2K
| Adam | epoch: 025 | loss: 0.07100 - acc: 0.9786 -- iter: 0064/3072
[A[ATraining Step: 2307  | total loss: [1m[32m0.06416[0m[0m | time: 1.960s
[2K
| Adam | epoch: 025 | loss: 0.06416 - acc: 0.9807 -- iter: 0096/3072
[A[ATraining Step: 2308  | total loss: [1m[32m0.06261[0m[0m | time: 2.545s
[2K
| Adam | epoch: 025 | loss: 0.06261 - acc: 0.9795 -- iter: 0128/3072
[A[ATraining Step: 2309  | total loss: [1m[32m0.06008[0m[0m | time: 3.159s
[2K
| Adam | epoch: 025 | loss: 0.06008 - acc: 0.9816 -- iter: 0160/3072
[A[ATraining Step: 2310  | total loss: [1m[32m0.06250[0m[0m | time: 3.796s
[2K
| Adam | epoch: 025 | loss: 0.06250 - acc: 0.9834 -- iter: 0192/3072
[A[ATraining Step: 2311  | total loss: [1m[32m0.07273[0m[0m | time: 4.428s
[2K
| Adam | epoch: 025 | loss: 0.07273 - acc: 0.9788 -- iter: 0224/3072
[A[ATraining Step: 2312  | total loss: [1m[32m0.07035[0m[0m | time: 5.056s
[2K
| Adam | epoch: 025 | loss: 0.07035 - acc: 0.9809 -- iter: 0256/3072
[A[ATraining Step: 2313  | total loss: [1m[32m0.06424[0m[0m | time: 5.714s
[2K
| Adam | epoch: 025 | loss: 0.06424 - acc: 0.9828 -- iter: 0288/3072
[A[ATraining Step: 2314  | total loss: [1m[32m0.06113[0m[0m | time: 6.342s
[2K
| Adam | epoch: 025 | loss: 0.06113 - acc: 0.9846 -- iter: 0320/3072
[A[ATraining Step: 2315  | total loss: [1m[32m0.06216[0m[0m | time: 6.990s
[2K
| Adam | epoch: 025 | loss: 0.06216 - acc: 0.9830 -- iter: 0352/3072
[A[ATraining Step: 2316  | total loss: [1m[32m0.06913[0m[0m | time: 7.595s
[2K
| Adam | epoch: 025 | loss: 0.06913 - acc: 0.9753 -- iter: 0384/3072
[A[ATraining Step: 2317  | total loss: [1m[32m0.06723[0m[0m | time: 8.198s
[2K
| Adam | epoch: 025 | loss: 0.06723 - acc: 0.9747 -- iter: 0416/3072
[A[ATraining Step: 2318  | total loss: [1m[32m0.06257[0m[0m | time: 8.839s
[2K
| Adam | epoch: 025 | loss: 0.06257 - acc: 0.9772 -- iter: 0448/3072
[A[ATraining Step: 2319  | total loss: [1m[32m0.06221[0m[0m | time: 9.484s
[2K
| Adam | epoch: 025 | loss: 0.06221 - acc: 0.9763 -- iter: 0480/3072
[A[ATraining Step: 2320  | total loss: [1m[32m0.05772[0m[0m | time: 10.093s
[2K
| Adam | epoch: 025 | loss: 0.05772 - acc: 0.9787 -- iter: 0512/3072
[A[ATraining Step: 2321  | total loss: [1m[32m0.05411[0m[0m | time: 10.709s
[2K
| Adam | epoch: 025 | loss: 0.05411 - acc: 0.9808 -- iter: 0544/3072
[A[ATraining Step: 2322  | total loss: [1m[32m0.05033[0m[0m | time: 11.306s
[2K
| Adam | epoch: 025 | loss: 0.05033 - acc: 0.9828 -- iter: 0576/3072
[A[ATraining Step: 2323  | total loss: [1m[32m0.04693[0m[0m | time: 11.913s
[2K
| Adam | epoch: 025 | loss: 0.04693 - acc: 0.9845 -- iter: 0608/3072
[A[ATraining Step: 2324  | total loss: [1m[32m0.04319[0m[0m | time: 12.520s
[2K
| Adam | epoch: 025 | loss: 0.04319 - acc: 0.9860 -- iter: 0640/3072
[A[ATraining Step: 2325  | total loss: [1m[32m0.04201[0m[0m | time: 13.158s
[2K
| Adam | epoch: 025 | loss: 0.04201 - acc: 0.9843 -- iter: 0672/3072
[A[ATraining Step: 2326  | total loss: [1m[32m0.03864[0m[0m | time: 13.759s
[2K
| Adam | epoch: 025 | loss: 0.03864 - acc: 0.9859 -- iter: 0704/3072
[A[ATraining Step: 2327  | total loss: [1m[32m0.03568[0m[0m | time: 14.367s
[2K
| Adam | epoch: 025 | loss: 0.03568 - acc: 0.9873 -- iter: 0736/3072
[A[ATraining Step: 2328  | total loss: [1m[32m0.03275[0m[0m | time: 14.973s
[2K
| Adam | epoch: 025 | loss: 0.03275 - acc: 0.9886 -- iter: 0768/3072
[A[ATraining Step: 2329  | total loss: [1m[32m0.03008[0m[0m | time: 15.587s
[2K
| Adam | epoch: 025 | loss: 0.03008 - acc: 0.9897 -- iter: 0800/3072
[A[ATraining Step: 2330  | total loss: [1m[32m0.02954[0m[0m | time: 16.202s
[2K
| Adam | epoch: 025 | loss: 0.02954 - acc: 0.9907 -- iter: 0832/3072
[A[ATraining Step: 2331  | total loss: [1m[32m0.02745[0m[0m | time: 16.857s
[2K
| Adam | epoch: 025 | loss: 0.02745 - acc: 0.9917 -- iter: 0864/3072
[A[ATraining Step: 2332  | total loss: [1m[32m0.02681[0m[0m | time: 17.513s
[2K
| Adam | epoch: 025 | loss: 0.02681 - acc: 0.9925 -- iter: 0896/3072
[A[ATraining Step: 2333  | total loss: [1m[32m0.02575[0m[0m | time: 18.139s
[2K
| Adam | epoch: 025 | loss: 0.02575 - acc: 0.9932 -- iter: 0928/3072
[A[ATraining Step: 2334  | total loss: [1m[32m0.02456[0m[0m | time: 18.741s
[2K
| Adam | epoch: 025 | loss: 0.02456 - acc: 0.9939 -- iter: 0960/3072
[A[ATraining Step: 2335  | total loss: [1m[32m0.02316[0m[0m | time: 19.344s
[2K
| Adam | epoch: 025 | loss: 0.02316 - acc: 0.9945 -- iter: 0992/3072
[A[ATraining Step: 2336  | total loss: [1m[32m0.02225[0m[0m | time: 19.978s
[2K
| Adam | epoch: 025 | loss: 0.02225 - acc: 0.9951 -- iter: 1024/3072
[A[ATraining Step: 2337  | total loss: [1m[32m0.02319[0m[0m | time: 20.601s
[2K
| Adam | epoch: 025 | loss: 0.02319 - acc: 0.9956 -- iter: 1056/3072
[A[ATraining Step: 2338  | total loss: [1m[32m0.02195[0m[0m | time: 21.218s
[2K
| Adam | epoch: 025 | loss: 0.02195 - acc: 0.9960 -- iter: 1088/3072
[A[ATraining Step: 2339  | total loss: [1m[32m0.02150[0m[0m | time: 21.817s
[2K
| Adam | epoch: 025 | loss: 0.02150 - acc: 0.9964 -- iter: 1120/3072
[A[ATraining Step: 2340  | total loss: [1m[32m0.02512[0m[0m | time: 22.424s
[2K
| Adam | epoch: 025 | loss: 0.02512 - acc: 0.9936 -- iter: 1152/3072
[A[ATraining Step: 2341  | total loss: [1m[32m0.03702[0m[0m | time: 23.070s
[2K
| Adam | epoch: 025 | loss: 0.03702 - acc: 0.9912 -- iter: 1184/3072
[A[ATraining Step: 2342  | total loss: [1m[32m0.03440[0m[0m | time: 23.676s
[2K
| Adam | epoch: 025 | loss: 0.03440 - acc: 0.9920 -- iter: 1216/3072
[A[ATraining Step: 2343  | total loss: [1m[32m0.03159[0m[0m | time: 24.293s
[2K
| Adam | epoch: 025 | loss: 0.03159 - acc: 0.9928 -- iter: 1248/3072
[A[ATraining Step: 2344  | total loss: [1m[32m0.04163[0m[0m | time: 24.927s
[2K
| Adam | epoch: 025 | loss: 0.04163 - acc: 0.9904 -- iter: 1280/3072
[A[ATraining Step: 2345  | total loss: [1m[32m0.03915[0m[0m | time: 25.595s
[2K
| Adam | epoch: 025 | loss: 0.03915 - acc: 0.9914 -- iter: 1312/3072
[A[ATraining Step: 2346  | total loss: [1m[32m0.04660[0m[0m | time: 26.230s
[2K
| Adam | epoch: 025 | loss: 0.04660 - acc: 0.9891 -- iter: 1344/3072
[A[ATraining Step: 2347  | total loss: [1m[32m0.05838[0m[0m | time: 26.846s
[2K
| Adam | epoch: 025 | loss: 0.05838 - acc: 0.9840 -- iter: 1376/3072
[A[ATraining Step: 2348  | total loss: [1m[32m0.05956[0m[0m | time: 27.456s
[2K
| Adam | epoch: 025 | loss: 0.05956 - acc: 0.9824 -- iter: 1408/3072
[A[ATraining Step: 2349  | total loss: [1m[32m0.05460[0m[0m | time: 28.049s
[2K
| Adam | epoch: 025 | loss: 0.05460 - acc: 0.9842 -- iter: 1440/3072
[A[ATraining Step: 2350  | total loss: [1m[32m0.05249[0m[0m | time: 28.655s
[2K
| Adam | epoch: 025 | loss: 0.05249 - acc: 0.9858 -- iter: 1472/3072
[A[ATraining Step: 2351  | total loss: [1m[32m0.05232[0m[0m | time: 29.329s
[2K
| Adam | epoch: 025 | loss: 0.05232 - acc: 0.9841 -- iter: 1504/3072
[A[ATraining Step: 2352  | total loss: [1m[32m0.05099[0m[0m | time: 29.937s
[2K
| Adam | epoch: 025 | loss: 0.05099 - acc: 0.9857 -- iter: 1536/3072
[A[ATraining Step: 2353  | total loss: [1m[32m0.05108[0m[0m | time: 30.549s
[2K
| Adam | epoch: 025 | loss: 0.05108 - acc: 0.9871 -- iter: 1568/3072
[A[ATraining Step: 2354  | total loss: [1m[32m0.04649[0m[0m | time: 31.149s
[2K
| Adam | epoch: 025 | loss: 0.04649 - acc: 0.9884 -- iter: 1600/3072
[A[ATraining Step: 2355  | total loss: [1m[32m0.04642[0m[0m | time: 31.747s
[2K
| Adam | epoch: 025 | loss: 0.04642 - acc: 0.9864 -- iter: 1632/3072
[A[ATraining Step: 2356  | total loss: [1m[32m0.05267[0m[0m | time: 32.351s
[2K
| Adam | epoch: 025 | loss: 0.05267 - acc: 0.9815 -- iter: 1664/3072
[A[ATraining Step: 2357  | total loss: [1m[32m0.05299[0m[0m | time: 32.966s
[2K
| Adam | epoch: 025 | loss: 0.05299 - acc: 0.9803 -- iter: 1696/3072
[A[ATraining Step: 2358  | total loss: [1m[32m0.04973[0m[0m | time: 33.584s
[2K
| Adam | epoch: 025 | loss: 0.04973 - acc: 0.9822 -- iter: 1728/3072
[A[ATraining Step: 2359  | total loss: [1m[32m0.04512[0m[0m | time: 34.185s
[2K
| Adam | epoch: 025 | loss: 0.04512 - acc: 0.9840 -- iter: 1760/3072
[A[ATraining Step: 2360  | total loss: [1m[32m0.04304[0m[0m | time: 34.829s
[2K
| Adam | epoch: 025 | loss: 0.04304 - acc: 0.9856 -- iter: 1792/3072
[A[ATraining Step: 2361  | total loss: [1m[32m0.04094[0m[0m | time: 35.461s
[2K
| Adam | epoch: 025 | loss: 0.04094 - acc: 0.9870 -- iter: 1824/3072
[A[ATraining Step: 2362  | total loss: [1m[32m0.05931[0m[0m | time: 36.063s
[2K
| Adam | epoch: 025 | loss: 0.05931 - acc: 0.9852 -- iter: 1856/3072
[A[ATraining Step: 2363  | total loss: [1m[32m0.06857[0m[0m | time: 36.676s
[2K
| Adam | epoch: 025 | loss: 0.06857 - acc: 0.9836 -- iter: 1888/3072
[A[ATraining Step: 2364  | total loss: [1m[32m0.06960[0m[0m | time: 37.298s
[2K
| Adam | epoch: 025 | loss: 0.06960 - acc: 0.9821 -- iter: 1920/3072
[A[ATraining Step: 2365  | total loss: [1m[32m0.06469[0m[0m | time: 37.917s
[2K
| Adam | epoch: 025 | loss: 0.06469 - acc: 0.9839 -- iter: 1952/3072
[A[ATraining Step: 2366  | total loss: [1m[32m0.06170[0m[0m | time: 38.518s
[2K
| Adam | epoch: 025 | loss: 0.06170 - acc: 0.9824 -- iter: 1984/3072
[A[ATraining Step: 2367  | total loss: [1m[32m0.07548[0m[0m | time: 39.167s
[2K
| Adam | epoch: 025 | loss: 0.07548 - acc: 0.9810 -- iter: 2016/3072
[A[ATraining Step: 2368  | total loss: [1m[32m0.06975[0m[0m | time: 39.770s
[2K
| Adam | epoch: 025 | loss: 0.06975 - acc: 0.9829 -- iter: 2048/3072
[A[ATraining Step: 2369  | total loss: [1m[32m0.06422[0m[0m | time: 40.398s
[2K
| Adam | epoch: 025 | loss: 0.06422 - acc: 0.9846 -- iter: 2080/3072
[A[ATraining Step: 2370  | total loss: [1m[32m0.05922[0m[0m | time: 41.038s
[2K
| Adam | epoch: 025 | loss: 0.05922 - acc: 0.9862 -- iter: 2112/3072
[A[ATraining Step: 2371  | total loss: [1m[32m0.05788[0m[0m | time: 41.657s
[2K
| Adam | epoch: 025 | loss: 0.05788 - acc: 0.9844 -- iter: 2144/3072
[A[ATraining Step: 2372  | total loss: [1m[32m0.05968[0m[0m | time: 42.288s
[2K
| Adam | epoch: 025 | loss: 0.05968 - acc: 0.9797 -- iter: 2176/3072
[A[ATraining Step: 2373  | total loss: [1m[32m0.05504[0m[0m | time: 42.973s
[2K
| Adam | epoch: 025 | loss: 0.05504 - acc: 0.9817 -- iter: 2208/3072
[A[ATraining Step: 2374  | total loss: [1m[32m0.05317[0m[0m | time: 43.580s
[2K
| Adam | epoch: 025 | loss: 0.05317 - acc: 0.9804 -- iter: 2240/3072
[A[ATraining Step: 2375  | total loss: [1m[32m0.05635[0m[0m | time: 44.206s
[2K
| Adam | epoch: 025 | loss: 0.05635 - acc: 0.9793 -- iter: 2272/3072
[A[ATraining Step: 2376  | total loss: [1m[32m0.06544[0m[0m | time: 44.849s
[2K
| Adam | epoch: 025 | loss: 0.06544 - acc: 0.9782 -- iter: 2304/3072
[A[ATraining Step: 2377  | total loss: [1m[32m0.06046[0m[0m | time: 45.472s
[2K
| Adam | epoch: 025 | loss: 0.06046 - acc: 0.9804 -- iter: 2336/3072
[A[ATraining Step: 2378  | total loss: [1m[32m0.06113[0m[0m | time: 46.118s
[2K
| Adam | epoch: 025 | loss: 0.06113 - acc: 0.9792 -- iter: 2368/3072
[A[ATraining Step: 2379  | total loss: [1m[32m0.05575[0m[0m | time: 46.771s
[2K
| Adam | epoch: 025 | loss: 0.05575 - acc: 0.9813 -- iter: 2400/3072
[A[ATraining Step: 2380  | total loss: [1m[32m0.05386[0m[0m | time: 47.384s
[2K
| Adam | epoch: 025 | loss: 0.05386 - acc: 0.9832 -- iter: 2432/3072
[A[ATraining Step: 2381  | total loss: [1m[32m0.05179[0m[0m | time: 47.993s
[2K
| Adam | epoch: 025 | loss: 0.05179 - acc: 0.9849 -- iter: 2464/3072
[A[ATraining Step: 2382  | total loss: [1m[32m0.04715[0m[0m | time: 48.609s
[2K
| Adam | epoch: 025 | loss: 0.04715 - acc: 0.9864 -- iter: 2496/3072
[A[ATraining Step: 2383  | total loss: [1m[32m0.04374[0m[0m | time: 49.214s
[2K
| Adam | epoch: 025 | loss: 0.04374 - acc: 0.9877 -- iter: 2528/3072
[A[ATraining Step: 2384  | total loss: [1m[32m0.06122[0m[0m | time: 49.822s
[2K
| Adam | epoch: 025 | loss: 0.06122 - acc: 0.9858 -- iter: 2560/3072
[A[ATraining Step: 2385  | total loss: [1m[32m0.05699[0m[0m | time: 50.445s
[2K
| Adam | epoch: 025 | loss: 0.05699 - acc: 0.9873 -- iter: 2592/3072
[A[ATraining Step: 2386  | total loss: [1m[32m0.06165[0m[0m | time: 51.057s
[2K
| Adam | epoch: 025 | loss: 0.06165 - acc: 0.9854 -- iter: 2624/3072
[A[ATraining Step: 2387  | total loss: [1m[32m0.05730[0m[0m | time: 51.706s
[2K
| Adam | epoch: 025 | loss: 0.05730 - acc: 0.9869 -- iter: 2656/3072
[A[ATraining Step: 2388  | total loss: [1m[32m0.05222[0m[0m | time: 52.320s
[2K
| Adam | epoch: 025 | loss: 0.05222 - acc: 0.9882 -- iter: 2688/3072
[A[ATraining Step: 2389  | total loss: [1m[32m0.04892[0m[0m | time: 52.973s
[2K
| Adam | epoch: 025 | loss: 0.04892 - acc: 0.9894 -- iter: 2720/3072
[A[ATraining Step: 2390  | total loss: [1m[32m0.04513[0m[0m | time: 53.603s
[2K
| Adam | epoch: 025 | loss: 0.04513 - acc: 0.9904 -- iter: 2752/3072
[A[ATraining Step: 2391  | total loss: [1m[32m0.05769[0m[0m | time: 54.207s
[2K
| Adam | epoch: 025 | loss: 0.05769 - acc: 0.9883 -- iter: 2784/3072
[A[ATraining Step: 2392  | total loss: [1m[32m0.05297[0m[0m | time: 54.827s
[2K
| Adam | epoch: 025 | loss: 0.05297 - acc: 0.9894 -- iter: 2816/3072
[A[ATraining Step: 2393  | total loss: [1m[32m0.04933[0m[0m | time: 55.501s
[2K
| Adam | epoch: 025 | loss: 0.04933 - acc: 0.9905 -- iter: 2848/3072
[A[ATraining Step: 2394  | total loss: [1m[32m0.05108[0m[0m | time: 56.109s
[2K
| Adam | epoch: 025 | loss: 0.05108 - acc: 0.9883 -- iter: 2880/3072
[A[ATraining Step: 2395  | total loss: [1m[32m0.04735[0m[0m | time: 56.756s
[2K
| Adam | epoch: 025 | loss: 0.04735 - acc: 0.9895 -- iter: 2912/3072
[A[ATraining Step: 2396  | total loss: [1m[32m0.04561[0m[0m | time: 57.371s
[2K
| Adam | epoch: 025 | loss: 0.04561 - acc: 0.9905 -- iter: 2944/3072
[A[ATraining Step: 2397  | total loss: [1m[32m0.05291[0m[0m | time: 58.000s
[2K
| Adam | epoch: 025 | loss: 0.05291 - acc: 0.9884 -- iter: 2976/3072
[A[ATraining Step: 2398  | total loss: [1m[32m0.04887[0m[0m | time: 58.624s
[2K
| Adam | epoch: 025 | loss: 0.04887 - acc: 0.9895 -- iter: 3008/3072
[A[ATraining Step: 2399  | total loss: [1m[32m0.04727[0m[0m | time: 59.253s
[2K
| Adam | epoch: 025 | loss: 0.04727 - acc: 0.9906 -- iter: 3040/3072
[A[ATraining Step: 2400  | total loss: [1m[32m0.04334[0m[0m | time: 62.882s
[2K
| Adam | epoch: 025 | loss: 0.04334 - acc: 0.9915 | val_loss: 0.76299 - val_acc: 0.8012 -- iter: 3072/3072
--
Training Step: 2401  | total loss: [1m[32m0.04111[0m[0m | time: 0.613s
[2K
| Adam | epoch: 026 | loss: 0.04111 - acc: 0.9924 -- iter: 0032/3072
[A[ATraining Step: 2402  | total loss: [1m[32m0.03828[0m[0m | time: 1.226s
[2K
| Adam | epoch: 026 | loss: 0.03828 - acc: 0.9931 -- iter: 0064/3072
[A[ATraining Step: 2403  | total loss: [1m[32m0.03536[0m[0m | time: 1.869s
[2K
| Adam | epoch: 026 | loss: 0.03536 - acc: 0.9938 -- iter: 0096/3072
[A[ATraining Step: 2404  | total loss: [1m[32m0.04422[0m[0m | time: 2.506s
[2K
| Adam | epoch: 026 | loss: 0.04422 - acc: 0.9882 -- iter: 0128/3072
[A[ATraining Step: 2405  | total loss: [1m[32m0.04319[0m[0m | time: 3.127s
[2K
| Adam | epoch: 026 | loss: 0.04319 - acc: 0.9894 -- iter: 0160/3072
[A[ATraining Step: 2406  | total loss: [1m[32m0.04436[0m[0m | time: 3.747s
[2K
| Adam | epoch: 026 | loss: 0.04436 - acc: 0.9873 -- iter: 0192/3072
[A[ATraining Step: 2407  | total loss: [1m[32m0.05126[0m[0m | time: 4.357s
[2K
| Adam | epoch: 026 | loss: 0.05126 - acc: 0.9854 -- iter: 0224/3072
[A[ATraining Step: 2408  | total loss: [1m[32m0.05203[0m[0m | time: 4.994s
[2K
| Adam | epoch: 026 | loss: 0.05203 - acc: 0.9838 -- iter: 0256/3072
[A[ATraining Step: 2409  | total loss: [1m[32m0.05765[0m[0m | time: 5.602s
[2K
| Adam | epoch: 026 | loss: 0.05765 - acc: 0.9823 -- iter: 0288/3072
[A[ATraining Step: 2410  | total loss: [1m[32m0.05973[0m[0m | time: 6.220s
[2K
| Adam | epoch: 026 | loss: 0.05973 - acc: 0.9809 -- iter: 0320/3072
[A[ATraining Step: 2411  | total loss: [1m[32m0.05542[0m[0m | time: 6.835s
[2K
| Adam | epoch: 026 | loss: 0.05542 - acc: 0.9828 -- iter: 0352/3072
[A[ATraining Step: 2412  | total loss: [1m[32m0.05168[0m[0m | time: 7.446s
[2K
| Adam | epoch: 026 | loss: 0.05168 - acc: 0.9845 -- iter: 0384/3072
[A[ATraining Step: 2413  | total loss: [1m[32m0.04958[0m[0m | time: 8.056s
[2K
| Adam | epoch: 026 | loss: 0.04958 - acc: 0.9861 -- iter: 0416/3072
[A[ATraining Step: 2414  | total loss: [1m[32m0.04795[0m[0m | time: 8.659s
[2K
| Adam | epoch: 026 | loss: 0.04795 - acc: 0.9875 -- iter: 0448/3072
[A[ATraining Step: 2415  | total loss: [1m[32m0.04517[0m[0m | time: 9.287s
[2K
| Adam | epoch: 026 | loss: 0.04517 - acc: 0.9887 -- iter: 0480/3072
[A[ATraining Step: 2416  | total loss: [1m[32m0.04374[0m[0m | time: 9.887s
[2K
| Adam | epoch: 026 | loss: 0.04374 - acc: 0.9867 -- iter: 0512/3072
[A[ATraining Step: 2417  | total loss: [1m[32m0.04477[0m[0m | time: 10.527s
[2K
| Adam | epoch: 026 | loss: 0.04477 - acc: 0.9849 -- iter: 0544/3072
[A[ATraining Step: 2418  | total loss: [1m[32m0.05520[0m[0m | time: 11.132s
[2K
| Adam | epoch: 026 | loss: 0.05520 - acc: 0.9771 -- iter: 0576/3072
[A[ATraining Step: 2419  | total loss: [1m[32m0.05132[0m[0m | time: 11.793s
[2K
| Adam | epoch: 026 | loss: 0.05132 - acc: 0.9794 -- iter: 0608/3072
[A[ATraining Step: 2420  | total loss: [1m[32m0.05113[0m[0m | time: 12.427s
[2K
| Adam | epoch: 026 | loss: 0.05113 - acc: 0.9814 -- iter: 0640/3072
[A[ATraining Step: 2421  | total loss: [1m[32m0.05133[0m[0m | time: 13.033s
[2K
| Adam | epoch: 026 | loss: 0.05133 - acc: 0.9802 -- iter: 0672/3072
[A[ATraining Step: 2422  | total loss: [1m[32m0.04758[0m[0m | time: 13.650s
[2K
| Adam | epoch: 026 | loss: 0.04758 - acc: 0.9821 -- iter: 0704/3072
[A[ATraining Step: 2423  | total loss: [1m[32m0.04758[0m[0m | time: 14.275s
[2K
| Adam | epoch: 026 | loss: 0.04758 - acc: 0.9839 -- iter: 0736/3072
[A[ATraining Step: 2424  | total loss: [1m[32m0.04416[0m[0m | time: 14.877s
[2K
| Adam | epoch: 026 | loss: 0.04416 - acc: 0.9855 -- iter: 0768/3072
[A[ATraining Step: 2425  | total loss: [1m[32m0.04234[0m[0m | time: 15.495s
[2K
| Adam | epoch: 026 | loss: 0.04234 - acc: 0.9870 -- iter: 0800/3072
[A[ATraining Step: 2426  | total loss: [1m[32m0.03917[0m[0m | time: 16.120s
[2K
| Adam | epoch: 026 | loss: 0.03917 - acc: 0.9883 -- iter: 0832/3072
[A[ATraining Step: 2427  | total loss: [1m[32m0.03555[0m[0m | time: 16.742s
[2K
| Adam | epoch: 026 | loss: 0.03555 - acc: 0.9895 -- iter: 0864/3072
[A[ATraining Step: 2428  | total loss: [1m[32m0.04017[0m[0m | time: 17.357s
[2K
| Adam | epoch: 026 | loss: 0.04017 - acc: 0.9874 -- iter: 0896/3072
[A[ATraining Step: 2429  | total loss: [1m[32m0.03869[0m[0m | time: 17.977s
[2K
| Adam | epoch: 026 | loss: 0.03869 - acc: 0.9886 -- iter: 0928/3072
[A[ATraining Step: 2430  | total loss: [1m[32m0.03637[0m[0m | time: 18.584s
[2K
| Adam | epoch: 026 | loss: 0.03637 - acc: 0.9898 -- iter: 0960/3072
[A[ATraining Step: 2431  | total loss: [1m[32m0.03769[0m[0m | time: 19.191s
[2K
| Adam | epoch: 026 | loss: 0.03769 - acc: 0.9908 -- iter: 0992/3072
[A[ATraining Step: 2432  | total loss: [1m[32m0.03479[0m[0m | time: 19.792s
[2K
| Adam | epoch: 026 | loss: 0.03479 - acc: 0.9917 -- iter: 1024/3072
[A[ATraining Step: 2433  | total loss: [1m[32m0.03325[0m[0m | time: 20.419s
[2K
| Adam | epoch: 026 | loss: 0.03325 - acc: 0.9926 -- iter: 1056/3072
[A[ATraining Step: 2434  | total loss: [1m[32m0.03309[0m[0m | time: 21.077s
[2K
| Adam | epoch: 026 | loss: 0.03309 - acc: 0.9902 -- iter: 1088/3072
[A[ATraining Step: 2435  | total loss: [1m[32m0.03302[0m[0m | time: 21.713s
[2K
| Adam | epoch: 026 | loss: 0.03302 - acc: 0.9912 -- iter: 1120/3072
[A[ATraining Step: 2436  | total loss: [1m[32m0.03067[0m[0m | time: 22.328s
[2K
| Adam | epoch: 026 | loss: 0.03067 - acc: 0.9920 -- iter: 1152/3072
[A[ATraining Step: 2437  | total loss: [1m[32m0.02894[0m[0m | time: 22.916s
[2K
| Adam | epoch: 026 | loss: 0.02894 - acc: 0.9928 -- iter: 1184/3072
[A[ATraining Step: 2438  | total loss: [1m[32m0.02805[0m[0m | time: 23.565s
[2K
| Adam | epoch: 026 | loss: 0.02805 - acc: 0.9936 -- iter: 1216/3072
[A[ATraining Step: 2439  | total loss: [1m[32m0.02665[0m[0m | time: 24.171s
[2K
| Adam | epoch: 026 | loss: 0.02665 - acc: 0.9942 -- iter: 1248/3072
[A[ATraining Step: 2440  | total loss: [1m[32m0.02577[0m[0m | time: 24.824s
[2K
| Adam | epoch: 026 | loss: 0.02577 - acc: 0.9948 -- iter: 1280/3072
[A[ATraining Step: 2441  | total loss: [1m[32m0.03341[0m[0m | time: 25.481s
[2K
| Adam | epoch: 026 | loss: 0.03341 - acc: 0.9922 -- iter: 1312/3072
[A[ATraining Step: 2442  | total loss: [1m[32m0.03259[0m[0m | time: 26.095s
[2K
| Adam | epoch: 026 | loss: 0.03259 - acc: 0.9930 -- iter: 1344/3072
[A[ATraining Step: 2443  | total loss: [1m[32m0.03052[0m[0m | time: 26.729s
[2K
| Adam | epoch: 026 | loss: 0.03052 - acc: 0.9937 -- iter: 1376/3072
[A[ATraining Step: 2444  | total loss: [1m[32m0.03436[0m[0m | time: 27.348s
[2K
| Adam | epoch: 026 | loss: 0.03436 - acc: 0.9912 -- iter: 1408/3072
[A[ATraining Step: 2445  | total loss: [1m[32m0.03717[0m[0m | time: 27.943s
[2K
| Adam | epoch: 026 | loss: 0.03717 - acc: 0.9889 -- iter: 1440/3072
[A[ATraining Step: 2446  | total loss: [1m[32m0.04293[0m[0m | time: 28.557s
[2K
| Adam | epoch: 026 | loss: 0.04293 - acc: 0.9838 -- iter: 1472/3072
[A[ATraining Step: 2447  | total loss: [1m[32m0.03966[0m[0m | time: 29.205s
[2K
| Adam | epoch: 026 | loss: 0.03966 - acc: 0.9854 -- iter: 1504/3072
[A[ATraining Step: 2448  | total loss: [1m[32m0.03764[0m[0m | time: 29.845s
[2K
| Adam | epoch: 026 | loss: 0.03764 - acc: 0.9869 -- iter: 1536/3072
[A[ATraining Step: 2449  | total loss: [1m[32m0.03409[0m[0m | time: 30.443s
[2K
| Adam | epoch: 026 | loss: 0.03409 - acc: 0.9882 -- iter: 1568/3072
[A[ATraining Step: 2450  | total loss: [1m[32m0.05297[0m[0m | time: 31.048s
[2K
| Adam | epoch: 026 | loss: 0.05297 - acc: 0.9831 -- iter: 1600/3072
[A[ATraining Step: 2451  | total loss: [1m[32m0.05473[0m[0m | time: 31.664s
[2K
| Adam | epoch: 026 | loss: 0.05473 - acc: 0.9848 -- iter: 1632/3072
[A[ATraining Step: 2452  | total loss: [1m[32m0.05537[0m[0m | time: 32.315s
[2K
| Adam | epoch: 026 | loss: 0.05537 - acc: 0.9832 -- iter: 1664/3072
[A[ATraining Step: 2453  | total loss: [1m[32m0.05622[0m[0m | time: 32.929s
[2K
| Adam | epoch: 026 | loss: 0.05622 - acc: 0.9818 -- iter: 1696/3072
[A[ATraining Step: 2454  | total loss: [1m[32m0.05189[0m[0m | time: 33.571s
[2K
| Adam | epoch: 026 | loss: 0.05189 - acc: 0.9836 -- iter: 1728/3072
[A[ATraining Step: 2455  | total loss: [1m[32m0.07243[0m[0m | time: 34.214s
[2K
| Adam | epoch: 026 | loss: 0.07243 - acc: 0.9790 -- iter: 1760/3072
[A[ATraining Step: 2456  | total loss: [1m[32m0.06652[0m[0m | time: 34.843s
[2K
| Adam | epoch: 026 | loss: 0.06652 - acc: 0.9811 -- iter: 1792/3072
[A[ATraining Step: 2457  | total loss: [1m[32m0.06519[0m[0m | time: 35.462s
[2K
| Adam | epoch: 026 | loss: 0.06519 - acc: 0.9830 -- iter: 1824/3072
[A[ATraining Step: 2458  | total loss: [1m[32m0.06132[0m[0m | time: 36.102s
[2K
| Adam | epoch: 026 | loss: 0.06132 - acc: 0.9847 -- iter: 1856/3072
[A[ATraining Step: 2459  | total loss: [1m[32m0.05651[0m[0m | time: 36.785s
[2K
| Adam | epoch: 026 | loss: 0.05651 - acc: 0.9862 -- iter: 1888/3072
[A[ATraining Step: 2460  | total loss: [1m[32m0.05400[0m[0m | time: 37.428s
[2K
| Adam | epoch: 026 | loss: 0.05400 - acc: 0.9845 -- iter: 1920/3072
[A[ATraining Step: 2461  | total loss: [1m[32m0.04915[0m[0m | time: 38.132s
[2K
| Adam | epoch: 026 | loss: 0.04915 - acc: 0.9860 -- iter: 1952/3072
[A[ATraining Step: 2462  | total loss: [1m[32m0.04470[0m[0m | time: 38.732s
[2K
| Adam | epoch: 026 | loss: 0.04470 - acc: 0.9874 -- iter: 1984/3072
[A[ATraining Step: 2463  | total loss: [1m[32m0.04320[0m[0m | time: 39.346s
[2K
| Adam | epoch: 026 | loss: 0.04320 - acc: 0.9887 -- iter: 2016/3072
[A[ATraining Step: 2464  | total loss: [1m[32m0.04102[0m[0m | time: 39.973s
[2K
| Adam | epoch: 026 | loss: 0.04102 - acc: 0.9898 -- iter: 2048/3072
[A[ATraining Step: 2465  | total loss: [1m[32m0.03852[0m[0m | time: 40.581s
[2K
| Adam | epoch: 026 | loss: 0.03852 - acc: 0.9908 -- iter: 2080/3072
[A[ATraining Step: 2466  | total loss: [1m[32m0.04349[0m[0m | time: 41.193s
[2K
| Adam | epoch: 026 | loss: 0.04349 - acc: 0.9886 -- iter: 2112/3072
[A[ATraining Step: 2467  | total loss: [1m[32m0.04650[0m[0m | time: 41.788s
[2K
| Adam | epoch: 026 | loss: 0.04650 - acc: 0.9866 -- iter: 2144/3072
[A[ATraining Step: 2468  | total loss: [1m[32m0.04986[0m[0m | time: 42.403s
[2K
| Adam | epoch: 026 | loss: 0.04986 - acc: 0.9817 -- iter: 2176/3072
[A[ATraining Step: 2469  | total loss: [1m[32m0.05003[0m[0m | time: 43.003s
[2K
| Adam | epoch: 026 | loss: 0.05003 - acc: 0.9835 -- iter: 2208/3072
[A[ATraining Step: 2470  | total loss: [1m[32m0.04589[0m[0m | time: 43.609s
[2K
| Adam | epoch: 026 | loss: 0.04589 - acc: 0.9852 -- iter: 2240/3072
[A[ATraining Step: 2471  | total loss: [1m[32m0.04172[0m[0m | time: 44.258s
[2K
| Adam | epoch: 026 | loss: 0.04172 - acc: 0.9867 -- iter: 2272/3072
[A[ATraining Step: 2472  | total loss: [1m[32m0.03853[0m[0m | time: 44.893s
[2K
| Adam | epoch: 026 | loss: 0.03853 - acc: 0.9880 -- iter: 2304/3072
[A[ATraining Step: 2473  | total loss: [1m[32m0.03600[0m[0m | time: 45.548s
[2K
| Adam | epoch: 026 | loss: 0.03600 - acc: 0.9892 -- iter: 2336/3072
[A[ATraining Step: 2474  | total loss: [1m[32m0.03770[0m[0m | time: 46.194s
[2K
| Adam | epoch: 026 | loss: 0.03770 - acc: 0.9903 -- iter: 2368/3072
[A[ATraining Step: 2475  | total loss: [1m[32m0.03587[0m[0m | time: 46.808s
[2K
| Adam | epoch: 026 | loss: 0.03587 - acc: 0.9913 -- iter: 2400/3072
[A[ATraining Step: 2476  | total loss: [1m[32m0.03283[0m[0m | time: 47.495s
[2K
| Adam | epoch: 026 | loss: 0.03283 - acc: 0.9921 -- iter: 2432/3072
[A[ATraining Step: 2477  | total loss: [1m[32m0.03348[0m[0m | time: 48.130s
[2K
| Adam | epoch: 026 | loss: 0.03348 - acc: 0.9929 -- iter: 2464/3072
[A[ATraining Step: 2478  | total loss: [1m[32m0.04395[0m[0m | time: 48.731s
[2K
| Adam | epoch: 026 | loss: 0.04395 - acc: 0.9905 -- iter: 2496/3072
[A[ATraining Step: 2479  | total loss: [1m[32m0.04880[0m[0m | time: 49.400s
[2K
| Adam | epoch: 026 | loss: 0.04880 - acc: 0.9883 -- iter: 2528/3072
[A[ATraining Step: 2480  | total loss: [1m[32m0.05663[0m[0m | time: 50.008s
[2K
| Adam | epoch: 026 | loss: 0.05663 - acc: 0.9801 -- iter: 2560/3072
[A[ATraining Step: 2481  | total loss: [1m[32m0.05627[0m[0m | time: 50.622s
[2K
| Adam | epoch: 026 | loss: 0.05627 - acc: 0.9790 -- iter: 2592/3072
[A[ATraining Step: 2482  | total loss: [1m[32m0.06882[0m[0m | time: 51.258s
[2K
| Adam | epoch: 026 | loss: 0.06882 - acc: 0.9748 -- iter: 2624/3072
[A[ATraining Step: 2483  | total loss: [1m[32m0.06958[0m[0m | time: 51.860s
[2K
| Adam | epoch: 026 | loss: 0.06958 - acc: 0.9711 -- iter: 2656/3072
[A[ATraining Step: 2484  | total loss: [1m[32m0.06752[0m[0m | time: 52.476s
[2K
| Adam | epoch: 026 | loss: 0.06752 - acc: 0.9740 -- iter: 2688/3072
[A[ATraining Step: 2485  | total loss: [1m[32m0.07068[0m[0m | time: 53.086s
[2K
| Adam | epoch: 026 | loss: 0.07068 - acc: 0.9703 -- iter: 2720/3072
[A[ATraining Step: 2486  | total loss: [1m[32m0.07066[0m[0m | time: 53.773s
[2K
| Adam | epoch: 026 | loss: 0.07066 - acc: 0.9702 -- iter: 2752/3072
[A[ATraining Step: 2487  | total loss: [1m[32m0.06494[0m[0m | time: 54.403s
[2K
| Adam | epoch: 026 | loss: 0.06494 - acc: 0.9732 -- iter: 2784/3072
[A[ATraining Step: 2488  | total loss: [1m[32m0.06161[0m[0m | time: 55.049s
[2K
| Adam | epoch: 026 | loss: 0.06161 - acc: 0.9727 -- iter: 2816/3072
[A[ATraining Step: 2489  | total loss: [1m[32m0.06099[0m[0m | time: 55.665s
[2K
| Adam | epoch: 026 | loss: 0.06099 - acc: 0.9723 -- iter: 2848/3072
[A[ATraining Step: 2490  | total loss: [1m[32m0.06316[0m[0m | time: 56.270s
[2K
| Adam | epoch: 026 | loss: 0.06316 - acc: 0.9720 -- iter: 2880/3072
[A[ATraining Step: 2491  | total loss: [1m[32m0.06450[0m[0m | time: 56.896s
[2K
| Adam | epoch: 026 | loss: 0.06450 - acc: 0.9716 -- iter: 2912/3072
[A[ATraining Step: 2492  | total loss: [1m[32m0.05879[0m[0m | time: 57.511s
[2K
| Adam | epoch: 026 | loss: 0.05879 - acc: 0.9745 -- iter: 2944/3072
[A[ATraining Step: 2493  | total loss: [1m[32m0.05454[0m[0m | time: 58.153s
[2K
| Adam | epoch: 026 | loss: 0.05454 - acc: 0.9770 -- iter: 2976/3072
[A[ATraining Step: 2494  | total loss: [1m[32m0.04967[0m[0m | time: 58.783s
[2K
| Adam | epoch: 026 | loss: 0.04967 - acc: 0.9793 -- iter: 3008/3072
[A[ATraining Step: 2495  | total loss: [1m[32m0.04582[0m[0m | time: 59.397s
[2K
| Adam | epoch: 026 | loss: 0.04582 - acc: 0.9814 -- iter: 3040/3072
[A[ATraining Step: 2496  | total loss: [1m[32m0.04235[0m[0m | time: 63.107s
[2K
| Adam | epoch: 026 | loss: 0.04235 - acc: 0.9833 | val_loss: 0.80396 - val_acc: 0.7950 -- iter: 3072/3072
--
Training Step: 2497  | total loss: [1m[32m0.04052[0m[0m | time: 0.621s
[2K
| Adam | epoch: 027 | loss: 0.04052 - acc: 0.9849 -- iter: 0032/3072
[A[ATraining Step: 2498  | total loss: [1m[32m0.03828[0m[0m | time: 1.241s
[2K
| Adam | epoch: 027 | loss: 0.03828 - acc: 0.9864 -- iter: 0064/3072
[A[ATraining Step: 2499  | total loss: [1m[32m0.03549[0m[0m | time: 1.853s
[2K
| Adam | epoch: 027 | loss: 0.03549 - acc: 0.9878 -- iter: 0096/3072
[A[ATraining Step: 2500  | total loss: [1m[32m0.03263[0m[0m | time: 2.465s
[2K
| Adam | epoch: 027 | loss: 0.03263 - acc: 0.9890 -- iter: 0128/3072
[A[ATraining Step: 2501  | total loss: [1m[32m0.03221[0m[0m | time: 3.158s
[2K
| Adam | epoch: 027 | loss: 0.03221 - acc: 0.9901 -- iter: 0160/3072
[A[ATraining Step: 2502  | total loss: [1m[32m0.03041[0m[0m | time: 3.779s
[2K
| Adam | epoch: 027 | loss: 0.03041 - acc: 0.9911 -- iter: 0192/3072
[A[ATraining Step: 2503  | total loss: [1m[32m0.03020[0m[0m | time: 4.389s
[2K
| Adam | epoch: 027 | loss: 0.03020 - acc: 0.9920 -- iter: 0224/3072
[A[ATraining Step: 2504  | total loss: [1m[32m0.02852[0m[0m | time: 5.033s
[2K
| Adam | epoch: 027 | loss: 0.02852 - acc: 0.9928 -- iter: 0256/3072
[A[ATraining Step: 2505  | total loss: [1m[32m0.02719[0m[0m | time: 5.658s
[2K
| Adam | epoch: 027 | loss: 0.02719 - acc: 0.9935 -- iter: 0288/3072
[A[ATraining Step: 2506  | total loss: [1m[32m0.02541[0m[0m | time: 6.260s
[2K
| Adam | epoch: 027 | loss: 0.02541 - acc: 0.9942 -- iter: 0320/3072
[A[ATraining Step: 2507  | total loss: [1m[32m0.02456[0m[0m | time: 6.890s
[2K
| Adam | epoch: 027 | loss: 0.02456 - acc: 0.9947 -- iter: 0352/3072
[A[ATraining Step: 2508  | total loss: [1m[32m0.02354[0m[0m | time: 7.486s
[2K
| Adam | epoch: 027 | loss: 0.02354 - acc: 0.9953 -- iter: 0384/3072
[A[ATraining Step: 2509  | total loss: [1m[32m0.02248[0m[0m | time: 8.080s
[2K
| Adam | epoch: 027 | loss: 0.02248 - acc: 0.9957 -- iter: 0416/3072
[A[ATraining Step: 2510  | total loss: [1m[32m0.02198[0m[0m | time: 8.724s
[2K
| Adam | epoch: 027 | loss: 0.02198 - acc: 0.9962 -- iter: 0448/3072
[A[ATraining Step: 2511  | total loss: [1m[32m0.02142[0m[0m | time: 9.325s
[2K
| Adam | epoch: 027 | loss: 0.02142 - acc: 0.9966 -- iter: 0480/3072
[A[ATraining Step: 2512  | total loss: [1m[32m0.02034[0m[0m | time: 9.939s
[2K
| Adam | epoch: 027 | loss: 0.02034 - acc: 0.9969 -- iter: 0512/3072
[A[ATraining Step: 2513  | total loss: [1m[32m0.02747[0m[0m | time: 10.545s
[2K
| Adam | epoch: 027 | loss: 0.02747 - acc: 0.9941 -- iter: 0544/3072
[A[ATraining Step: 2514  | total loss: [1m[32m0.02726[0m[0m | time: 11.137s
[2K
| Adam | epoch: 027 | loss: 0.02726 - acc: 0.9947 -- iter: 0576/3072
[A[ATraining Step: 2515  | total loss: [1m[32m0.02621[0m[0m | time: 11.734s
[2K
| Adam | epoch: 027 | loss: 0.02621 - acc: 0.9952 -- iter: 0608/3072
[A[ATraining Step: 2516  | total loss: [1m[32m0.02498[0m[0m | time: 12.363s
[2K
| Adam | epoch: 027 | loss: 0.02498 - acc: 0.9957 -- iter: 0640/3072
[A[ATraining Step: 2517  | total loss: [1m[32m0.02309[0m[0m | time: 12.956s
[2K
| Adam | epoch: 027 | loss: 0.02309 - acc: 0.9961 -- iter: 0672/3072
[A[ATraining Step: 2518  | total loss: [1m[32m0.02153[0m[0m | time: 13.570s
[2K
| Adam | epoch: 027 | loss: 0.02153 - acc: 0.9965 -- iter: 0704/3072
[A[ATraining Step: 2519  | total loss: [1m[32m0.01997[0m[0m | time: 14.191s
[2K
| Adam | epoch: 027 | loss: 0.01997 - acc: 0.9969 -- iter: 0736/3072
[A[ATraining Step: 2520  | total loss: [1m[32m0.01909[0m[0m | time: 14.812s
[2K
| Adam | epoch: 027 | loss: 0.01909 - acc: 0.9972 -- iter: 0768/3072
[A[ATraining Step: 2521  | total loss: [1m[32m0.02597[0m[0m | time: 15.426s
[2K
| Adam | epoch: 027 | loss: 0.02597 - acc: 0.9943 -- iter: 0800/3072
[A[ATraining Step: 2522  | total loss: [1m[32m0.02447[0m[0m | time: 16.023s
[2K
| Adam | epoch: 027 | loss: 0.02447 - acc: 0.9949 -- iter: 0832/3072
[A[ATraining Step: 2523  | total loss: [1m[32m0.02268[0m[0m | time: 16.682s
[2K
| Adam | epoch: 027 | loss: 0.02268 - acc: 0.9954 -- iter: 0864/3072
[A[ATraining Step: 2524  | total loss: [1m[32m0.02195[0m[0m | time: 17.371s
[2K
| Adam | epoch: 027 | loss: 0.02195 - acc: 0.9959 -- iter: 0896/3072
[A[ATraining Step: 2525  | total loss: [1m[32m0.02140[0m[0m | time: 18.032s
[2K
| Adam | epoch: 027 | loss: 0.02140 - acc: 0.9963 -- iter: 0928/3072
[A[ATraining Step: 2526  | total loss: [1m[32m0.02415[0m[0m | time: 18.686s
[2K
| Adam | epoch: 027 | loss: 0.02415 - acc: 0.9935 -- iter: 0960/3072
[A[ATraining Step: 2527  | total loss: [1m[32m0.02292[0m[0m | time: 19.307s
[2K
| Adam | epoch: 027 | loss: 0.02292 - acc: 0.9942 -- iter: 0992/3072
[A[ATraining Step: 2528  | total loss: [1m[32m0.02647[0m[0m | time: 19.913s
[2K
| Adam | epoch: 027 | loss: 0.02647 - acc: 0.9916 -- iter: 1024/3072
[A[ATraining Step: 2529  | total loss: [1m[32m0.02465[0m[0m | time: 20.594s
[2K
| Adam | epoch: 027 | loss: 0.02465 - acc: 0.9925 -- iter: 1056/3072
[A[ATraining Step: 2530  | total loss: [1m[32m0.02285[0m[0m | time: 21.203s
[2K
| Adam | epoch: 027 | loss: 0.02285 - acc: 0.9932 -- iter: 1088/3072
[A[ATraining Step: 2531  | total loss: [1m[32m0.02864[0m[0m | time: 21.814s
[2K
| Adam | epoch: 027 | loss: 0.02864 - acc: 0.9908 -- iter: 1120/3072
[A[ATraining Step: 2532  | total loss: [1m[32m0.02627[0m[0m | time: 22.471s
[2K
| Adam | epoch: 027 | loss: 0.02627 - acc: 0.9917 -- iter: 1152/3072
[A[ATraining Step: 2533  | total loss: [1m[32m0.02480[0m[0m | time: 23.080s
[2K
| Adam | epoch: 027 | loss: 0.02480 - acc: 0.9925 -- iter: 1184/3072
[A[ATraining Step: 2534  | total loss: [1m[32m0.02363[0m[0m | time: 23.674s
[2K
| Adam | epoch: 027 | loss: 0.02363 - acc: 0.9933 -- iter: 1216/3072
[A[ATraining Step: 2535  | total loss: [1m[32m0.02278[0m[0m | time: 24.302s
[2K
| Adam | epoch: 027 | loss: 0.02278 - acc: 0.9939 -- iter: 1248/3072
[A[ATraining Step: 2536  | total loss: [1m[32m0.02093[0m[0m | time: 24.957s
[2K
| Adam | epoch: 027 | loss: 0.02093 - acc: 0.9946 -- iter: 1280/3072
[A[ATraining Step: 2537  | total loss: [1m[32m0.02126[0m[0m | time: 25.552s
[2K
| Adam | epoch: 027 | loss: 0.02126 - acc: 0.9920 -- iter: 1312/3072
[A[ATraining Step: 2538  | total loss: [1m[32m0.03483[0m[0m | time: 26.153s
[2K
| Adam | epoch: 027 | loss: 0.03483 - acc: 0.9896 -- iter: 1344/3072
[A[ATraining Step: 2539  | total loss: [1m[32m0.03356[0m[0m | time: 26.759s
[2K
| Adam | epoch: 027 | loss: 0.03356 - acc: 0.9907 -- iter: 1376/3072
[A[ATraining Step: 2540  | total loss: [1m[32m0.03093[0m[0m | time: 27.514s
[2K
| Adam | epoch: 027 | loss: 0.03093 - acc: 0.9916 -- iter: 1408/3072
[A[ATraining Step: 2541  | total loss: [1m[32m0.02855[0m[0m | time: 28.127s
[2K
| Adam | epoch: 027 | loss: 0.02855 - acc: 0.9925 -- iter: 1440/3072
[A[ATraining Step: 2542  | total loss: [1m[32m0.03405[0m[0m | time: 28.714s
[2K
| Adam | epoch: 027 | loss: 0.03405 - acc: 0.9901 -- iter: 1472/3072
[A[ATraining Step: 2543  | total loss: [1m[32m0.04127[0m[0m | time: 29.369s
[2K
| Adam | epoch: 027 | loss: 0.04127 - acc: 0.9880 -- iter: 1504/3072
[A[ATraining Step: 2544  | total loss: [1m[32m0.03816[0m[0m | time: 29.989s
[2K
| Adam | epoch: 027 | loss: 0.03816 - acc: 0.9892 -- iter: 1536/3072
[A[ATraining Step: 2545  | total loss: [1m[32m0.03561[0m[0m | time: 30.613s
[2K
| Adam | epoch: 027 | loss: 0.03561 - acc: 0.9902 -- iter: 1568/3072
[A[ATraining Step: 2546  | total loss: [1m[32m0.03288[0m[0m | time: 31.214s
[2K
| Adam | epoch: 027 | loss: 0.03288 - acc: 0.9912 -- iter: 1600/3072
[A[ATraining Step: 2547  | total loss: [1m[32m0.03032[0m[0m | time: 31.837s
[2K
| Adam | epoch: 027 | loss: 0.03032 - acc: 0.9921 -- iter: 1632/3072
[A[ATraining Step: 2548  | total loss: [1m[32m0.02856[0m[0m | time: 32.442s
[2K
| Adam | epoch: 027 | loss: 0.02856 - acc: 0.9929 -- iter: 1664/3072
[A[ATraining Step: 2549  | total loss: [1m[32m0.05054[0m[0m | time: 33.044s
[2K
| Adam | epoch: 027 | loss: 0.05054 - acc: 0.9873 -- iter: 1696/3072
[A[ATraining Step: 2550  | total loss: [1m[32m0.06851[0m[0m | time: 33.645s
[2K
| Adam | epoch: 027 | loss: 0.06851 - acc: 0.9824 -- iter: 1728/3072
[A[ATraining Step: 2551  | total loss: [1m[32m0.06836[0m[0m | time: 34.259s
[2K
| Adam | epoch: 027 | loss: 0.06836 - acc: 0.9779 -- iter: 1760/3072
[A[ATraining Step: 2552  | total loss: [1m[32m0.06212[0m[0m | time: 34.875s
[2K
| Adam | epoch: 027 | loss: 0.06212 - acc: 0.9801 -- iter: 1792/3072
[A[ATraining Step: 2553  | total loss: [1m[32m0.06080[0m[0m | time: 35.472s
[2K
| Adam | epoch: 027 | loss: 0.06080 - acc: 0.9790 -- iter: 1824/3072
[A[ATraining Step: 2554  | total loss: [1m[32m0.06107[0m[0m | time: 36.071s
[2K
| Adam | epoch: 027 | loss: 0.06107 - acc: 0.9811 -- iter: 1856/3072
[A[ATraining Step: 2555  | total loss: [1m[32m0.06114[0m[0m | time: 36.712s
[2K
| Adam | epoch: 027 | loss: 0.06114 - acc: 0.9830 -- iter: 1888/3072
[A[ATraining Step: 2556  | total loss: [1m[32m0.05570[0m[0m | time: 37.365s
[2K
| Adam | epoch: 027 | loss: 0.05570 - acc: 0.9847 -- iter: 1920/3072
[A[ATraining Step: 2557  | total loss: [1m[32m0.05404[0m[0m | time: 37.995s
[2K
| Adam | epoch: 027 | loss: 0.05404 - acc: 0.9831 -- iter: 1952/3072
[A[ATraining Step: 2558  | total loss: [1m[32m0.06847[0m[0m | time: 38.580s
[2K
| Adam | epoch: 027 | loss: 0.06847 - acc: 0.9816 -- iter: 1984/3072
[A[ATraining Step: 2559  | total loss: [1m[32m0.06534[0m[0m | time: 39.198s
[2K
| Adam | epoch: 027 | loss: 0.06534 - acc: 0.9835 -- iter: 2016/3072
[A[ATraining Step: 2560  | total loss: [1m[32m0.06816[0m[0m | time: 39.853s
[2K
| Adam | epoch: 027 | loss: 0.06816 - acc: 0.9820 -- iter: 2048/3072
[A[ATraining Step: 2561  | total loss: [1m[32m0.07652[0m[0m | time: 40.461s
[2K
| Adam | epoch: 027 | loss: 0.07652 - acc: 0.9713 -- iter: 2080/3072
[A[ATraining Step: 2562  | total loss: [1m[32m0.07915[0m[0m | time: 41.120s
[2K
| Adam | epoch: 027 | loss: 0.07915 - acc: 0.9679 -- iter: 2112/3072
[A[ATraining Step: 2563  | total loss: [1m[32m0.07954[0m[0m | time: 41.727s
[2K
| Adam | epoch: 027 | loss: 0.07954 - acc: 0.9680 -- iter: 2144/3072
[A[ATraining Step: 2564  | total loss: [1m[32m0.07183[0m[0m | time: 42.484s
[2K
| Adam | epoch: 027 | loss: 0.07183 - acc: 0.9712 -- iter: 2176/3072
[A[ATraining Step: 2565  | total loss: [1m[32m0.07582[0m[0m | time: 43.123s
[2K
| Adam | epoch: 027 | loss: 0.07582 - acc: 0.9710 -- iter: 2208/3072
[A[ATraining Step: 2566  | total loss: [1m[32m0.07271[0m[0m | time: 43.742s
[2K
| Adam | epoch: 027 | loss: 0.07271 - acc: 0.9707 -- iter: 2240/3072
[A[ATraining Step: 2567  | total loss: [1m[32m0.07001[0m[0m | time: 44.366s
[2K
| Adam | epoch: 027 | loss: 0.07001 - acc: 0.9737 -- iter: 2272/3072
[A[ATraining Step: 2568  | total loss: [1m[32m0.07075[0m[0m | time: 44.966s
[2K
| Adam | epoch: 027 | loss: 0.07075 - acc: 0.9700 -- iter: 2304/3072
[A[ATraining Step: 2569  | total loss: [1m[32m0.07148[0m[0m | time: 45.577s
[2K
| Adam | epoch: 027 | loss: 0.07148 - acc: 0.9699 -- iter: 2336/3072
[A[ATraining Step: 2570  | total loss: [1m[32m0.06986[0m[0m | time: 46.209s
[2K
| Adam | epoch: 027 | loss: 0.06986 - acc: 0.9698 -- iter: 2368/3072
[A[ATraining Step: 2571  | total loss: [1m[32m0.06455[0m[0m | time: 46.809s
[2K
| Adam | epoch: 027 | loss: 0.06455 - acc: 0.9728 -- iter: 2400/3072
[A[ATraining Step: 2572  | total loss: [1m[32m0.06794[0m[0m | time: 47.460s
[2K
| Adam | epoch: 027 | loss: 0.06794 - acc: 0.9724 -- iter: 2432/3072
[A[ATraining Step: 2573  | total loss: [1m[32m0.07592[0m[0m | time: 48.074s
[2K
| Adam | epoch: 027 | loss: 0.07592 - acc: 0.9689 -- iter: 2464/3072
[A[ATraining Step: 2574  | total loss: [1m[32m0.08787[0m[0m | time: 48.689s
[2K
| Adam | epoch: 027 | loss: 0.08787 - acc: 0.9689 -- iter: 2496/3072
[A[ATraining Step: 2575  | total loss: [1m[32m0.08102[0m[0m | time: 49.318s
[2K
| Adam | epoch: 027 | loss: 0.08102 - acc: 0.9720 -- iter: 2528/3072
[A[ATraining Step: 2576  | total loss: [1m[32m0.07551[0m[0m | time: 49.945s
[2K
| Adam | epoch: 027 | loss: 0.07551 - acc: 0.9748 -- iter: 2560/3072
[A[ATraining Step: 2577  | total loss: [1m[32m0.06845[0m[0m | time: 50.560s
[2K
| Adam | epoch: 027 | loss: 0.06845 - acc: 0.9773 -- iter: 2592/3072
[A[ATraining Step: 2578  | total loss: [1m[32m0.06423[0m[0m | time: 51.187s
[2K
| Adam | epoch: 027 | loss: 0.06423 - acc: 0.9796 -- iter: 2624/3072
[A[ATraining Step: 2579  | total loss: [1m[32m0.06605[0m[0m | time: 51.951s
[2K
| Adam | epoch: 027 | loss: 0.06605 - acc: 0.9785 -- iter: 2656/3072
[A[ATraining Step: 2580  | total loss: [1m[32m0.06231[0m[0m | time: 52.567s
[2K
| Adam | epoch: 027 | loss: 0.06231 - acc: 0.9807 -- iter: 2688/3072
[A[ATraining Step: 2581  | total loss: [1m[32m0.05685[0m[0m | time: 53.202s
[2K
| Adam | epoch: 027 | loss: 0.05685 - acc: 0.9826 -- iter: 2720/3072
[A[ATraining Step: 2582  | total loss: [1m[32m0.06071[0m[0m | time: 53.796s
[2K
| Adam | epoch: 027 | loss: 0.06071 - acc: 0.9812 -- iter: 2752/3072
[A[ATraining Step: 2583  | total loss: [1m[32m0.06855[0m[0m | time: 54.395s
[2K
| Adam | epoch: 027 | loss: 0.06855 - acc: 0.9800 -- iter: 2784/3072
[A[ATraining Step: 2584  | total loss: [1m[32m0.06605[0m[0m | time: 55.012s
[2K
| Adam | epoch: 027 | loss: 0.06605 - acc: 0.9820 -- iter: 2816/3072
[A[ATraining Step: 2585  | total loss: [1m[32m0.06020[0m[0m | time: 55.615s
[2K
| Adam | epoch: 027 | loss: 0.06020 - acc: 0.9838 -- iter: 2848/3072
[A[ATraining Step: 2586  | total loss: [1m[32m0.05725[0m[0m | time: 56.672s
[2K
| Adam | epoch: 027 | loss: 0.05725 - acc: 0.9854 -- iter: 2880/3072
[A[ATraining Step: 2587  | total loss: [1m[32m0.05245[0m[0m | time: 57.705s
[2K
| Adam | epoch: 027 | loss: 0.05245 - acc: 0.9869 -- iter: 2912/3072
[A[ATraining Step: 2588  | total loss: [1m[32m0.04797[0m[0m | time: 58.724s
[2K
| Adam | epoch: 027 | loss: 0.04797 - acc: 0.9882 -- iter: 2944/3072
[A[ATraining Step: 2589  | total loss: [1m[32m0.04656[0m[0m | time: 59.560s
[2K
| Adam | epoch: 027 | loss: 0.04656 - acc: 0.9894 -- iter: 2976/3072
[A[ATraining Step: 2590  | total loss: [1m[32m0.04271[0m[0m | time: 60.526s
[2K
| Adam | epoch: 027 | loss: 0.04271 - acc: 0.9904 -- iter: 3008/3072
[A[ATraining Step: 2591  | total loss: [1m[32m0.04014[0m[0m | time: 61.517s
[2K
| Adam | epoch: 027 | loss: 0.04014 - acc: 0.9914 -- iter: 3040/3072
[A[ATraining Step: 2592  | total loss: [1m[32m0.03783[0m[0m | time: 66.970s
[2K
| Adam | epoch: 027 | loss: 0.03783 - acc: 0.9922 | val_loss: 0.82960 - val_acc: 0.8085 -- iter: 3072/3072
--
Training Step: 2593  | total loss: [1m[32m0.05329[0m[0m | time: 0.666s
[2K
| Adam | epoch: 028 | loss: 0.05329 - acc: 0.9899 -- iter: 0032/3072
[A[ATraining Step: 2594  | total loss: [1m[32m0.05612[0m[0m | time: 1.752s
[2K
| Adam | epoch: 028 | loss: 0.05612 - acc: 0.9878 -- iter: 0064/3072
[A[ATraining Step: 2595  | total loss: [1m[32m0.05069[0m[0m | time: 2.868s
[2K
| Adam | epoch: 028 | loss: 0.05069 - acc: 0.9890 -- iter: 0096/3072
[A[ATraining Step: 2596  | total loss: [1m[32m0.04593[0m[0m | time: 3.921s
[2K
| Adam | epoch: 028 | loss: 0.04593 - acc: 0.9901 -- iter: 0128/3072
[A[ATraining Step: 2597  | total loss: [1m[32m0.04372[0m[0m | time: 4.792s
[2K
| Adam | epoch: 028 | loss: 0.04372 - acc: 0.9911 -- iter: 0160/3072
[A[ATraining Step: 2598  | total loss: [1m[32m0.04451[0m[0m | time: 5.789s
[2K
| Adam | epoch: 028 | loss: 0.04451 - acc: 0.9889 -- iter: 0192/3072
[A[ATraining Step: 2599  | total loss: [1m[32m0.04148[0m[0m | time: 6.756s
[2K
| Adam | epoch: 028 | loss: 0.04148 - acc: 0.9900 -- iter: 0224/3072
[A[ATraining Step: 2600  | total loss: [1m[32m0.05404[0m[0m | time: 12.558s
[2K
| Adam | epoch: 028 | loss: 0.05404 - acc: 0.9847 | val_loss: 0.79114 - val_acc: 0.8189 -- iter: 0256/3072
--
Training Step: 2601  | total loss: [1m[32m0.05668[0m[0m | time: 13.587s
[2K
| Adam | epoch: 028 | loss: 0.05668 - acc: 0.9831 -- iter: 0288/3072
[A[ATraining Step: 2602  | total loss: [1m[32m0.05181[0m[0m | time: 14.496s
[2K
| Adam | epoch: 028 | loss: 0.05181 - acc: 0.9848 -- iter: 0320/3072
[A[ATraining Step: 2603  | total loss: [1m[32m0.04727[0m[0m | time: 15.455s
[2K
| Adam | epoch: 028 | loss: 0.04727 - acc: 0.9863 -- iter: 0352/3072
[A[ATraining Step: 2604  | total loss: [1m[32m0.04462[0m[0m | time: 16.448s
[2K
| Adam | epoch: 028 | loss: 0.04462 - acc: 0.9877 -- iter: 0384/3072
[A[ATraining Step: 2605  | total loss: [1m[32m0.04170[0m[0m | time: 17.491s
[2K
| Adam | epoch: 028 | loss: 0.04170 - acc: 0.9889 -- iter: 0416/3072
[A[ATraining Step: 2606  | total loss: [1m[32m0.03797[0m[0m | time: 18.606s
[2K
| Adam | epoch: 028 | loss: 0.03797 - acc: 0.9900 -- iter: 0448/3072
[A[ATraining Step: 2607  | total loss: [1m[32m0.03619[0m[0m | time: 19.470s
[2K
| Adam | epoch: 028 | loss: 0.03619 - acc: 0.9910 -- iter: 0480/3072
[A[ATraining Step: 2608  | total loss: [1m[32m0.03342[0m[0m | time: 20.499s
[2K
| Adam | epoch: 028 | loss: 0.03342 - acc: 0.9919 -- iter: 0512/3072
[A[ATraining Step: 2609  | total loss: [1m[32m0.03165[0m[0m | time: 21.666s
[2K
| Adam | epoch: 028 | loss: 0.03165 - acc: 0.9927 -- iter: 0544/3072
[A[ATraining Step: 2610  | total loss: [1m[32m0.03100[0m[0m | time: 22.693s
[2K
| Adam | epoch: 028 | loss: 0.03100 - acc: 0.9935 -- iter: 0576/3072
[A[ATraining Step: 2611  | total loss: [1m[32m0.02847[0m[0m | time: 23.568s
[2K
| Adam | epoch: 028 | loss: 0.02847 - acc: 0.9941 -- iter: 0608/3072
[A[ATraining Step: 2612  | total loss: [1m[32m0.03128[0m[0m | time: 24.514s
[2K
| Adam | epoch: 028 | loss: 0.03128 - acc: 0.9916 -- iter: 0640/3072
[A[ATraining Step: 2613  | total loss: [1m[32m0.03040[0m[0m | time: 25.474s
[2K
| Adam | epoch: 028 | loss: 0.03040 - acc: 0.9924 -- iter: 0672/3072
[A[ATraining Step: 2614  | total loss: [1m[32m0.02928[0m[0m | time: 26.423s
[2K
| Adam | epoch: 028 | loss: 0.02928 - acc: 0.9932 -- iter: 0704/3072
[A[ATraining Step: 2615  | total loss: [1m[32m0.02786[0m[0m | time: 27.462s
[2K
| Adam | epoch: 028 | loss: 0.02786 - acc: 0.9939 -- iter: 0736/3072
[A[ATraining Step: 2616  | total loss: [1m[32m0.02764[0m[0m | time: 28.584s
[2K
| Adam | epoch: 028 | loss: 0.02764 - acc: 0.9945 -- iter: 0768/3072
[A[ATraining Step: 2617  | total loss: [1m[32m0.02567[0m[0m | time: 29.402s
[2K
| Adam | epoch: 028 | loss: 0.02567 - acc: 0.9950 -- iter: 0800/3072
[A[ATraining Step: 2618  | total loss: [1m[32m0.02466[0m[0m | time: 30.550s
[2K
| Adam | epoch: 028 | loss: 0.02466 - acc: 0.9955 -- iter: 0832/3072
[A[ATraining Step: 2619  | total loss: [1m[32m0.02455[0m[0m | time: 31.684s
[2K
| Adam | epoch: 028 | loss: 0.02455 - acc: 0.9960 -- iter: 0864/3072
[A[ATraining Step: 2620  | total loss: [1m[32m0.02407[0m[0m | time: 32.627s
[2K
| Adam | epoch: 028 | loss: 0.02407 - acc: 0.9964 -- iter: 0896/3072
[A[ATraining Step: 2621  | total loss: [1m[32m0.02519[0m[0m | time: 33.574s
[2K
| Adam | epoch: 028 | loss: 0.02519 - acc: 0.9967 -- iter: 0928/3072
[A[ATraining Step: 2622  | total loss: [1m[32m0.02341[0m[0m | time: 34.586s
[2K
| Adam | epoch: 028 | loss: 0.02341 - acc: 0.9971 -- iter: 0960/3072
[A[ATraining Step: 2623  | total loss: [1m[32m0.02330[0m[0m | time: 35.604s
[2K
| Adam | epoch: 028 | loss: 0.02330 - acc: 0.9974 -- iter: 0992/3072
[A[ATraining Step: 2624  | total loss: [1m[32m0.02131[0m[0m | time: 36.668s
[2K
| Adam | epoch: 028 | loss: 0.02131 - acc: 0.9976 -- iter: 1024/3072
[A[ATraining Step: 2625  | total loss: [1m[32m0.02356[0m[0m | time: 37.772s
[2K
| Adam | epoch: 028 | loss: 0.02356 - acc: 0.9947 -- iter: 1056/3072
[A[ATraining Step: 2626  | total loss: [1m[32m0.02255[0m[0m | time: 38.626s
[2K
| Adam | epoch: 028 | loss: 0.02255 - acc: 0.9953 -- iter: 1088/3072
[A[ATraining Step: 2627  | total loss: [1m[32m0.02141[0m[0m | time: 39.708s
[2K
| Adam | epoch: 028 | loss: 0.02141 - acc: 0.9957 -- iter: 1120/3072
[A[ATraining Step: 2628  | total loss: [1m[32m0.02261[0m[0m | time: 40.754s
[2K
| Adam | epoch: 028 | loss: 0.02261 - acc: 0.9930 -- iter: 1152/3072
[A[ATraining Step: 2629  | total loss: [1m[32m0.03285[0m[0m | time: 41.856s
[2K
| Adam | epoch: 028 | loss: 0.03285 - acc: 0.9906 -- iter: 1184/3072
[A[ATraining Step: 2630  | total loss: [1m[32m0.03708[0m[0m | time: 42.727s
[2K
| Adam | epoch: 028 | loss: 0.03708 - acc: 0.9884 -- iter: 1216/3072
[A[ATraining Step: 2631  | total loss: [1m[32m0.03555[0m[0m | time: 43.686s
[2K
| Adam | epoch: 028 | loss: 0.03555 - acc: 0.9896 -- iter: 1248/3072
[A[ATraining Step: 2632  | total loss: [1m[32m0.03500[0m[0m | time: 44.666s
[2K
| Adam | epoch: 028 | loss: 0.03500 - acc: 0.9906 -- iter: 1280/3072
[A[ATraining Step: 2633  | total loss: [1m[32m0.03386[0m[0m | time: 45.584s
[2K
| Adam | epoch: 028 | loss: 0.03386 - acc: 0.9916 -- iter: 1312/3072
[A[ATraining Step: 2634  | total loss: [1m[32m0.03062[0m[0m | time: 46.630s
[2K
| Adam | epoch: 028 | loss: 0.03062 - acc: 0.9924 -- iter: 1344/3072
[A[ATraining Step: 2635  | total loss: [1m[32m0.03154[0m[0m | time: 47.690s
[2K
| Adam | epoch: 028 | loss: 0.03154 - acc: 0.9900 -- iter: 1376/3072
[A[ATraining Step: 2636  | total loss: [1m[32m0.03560[0m[0m | time: 48.536s
[2K
| Adam | epoch: 028 | loss: 0.03560 - acc: 0.9879 -- iter: 1408/3072
[A[ATraining Step: 2637  | total loss: [1m[32m0.04509[0m[0m | time: 49.602s
[2K
| Adam | epoch: 028 | loss: 0.04509 - acc: 0.9829 -- iter: 1440/3072
[A[ATraining Step: 2638  | total loss: [1m[32m0.04248[0m[0m | time: 50.764s
[2K
| Adam | epoch: 028 | loss: 0.04248 - acc: 0.9846 -- iter: 1472/3072
[A[ATraining Step: 2639  | total loss: [1m[32m0.04584[0m[0m | time: 51.718s
[2K
| Adam | epoch: 028 | loss: 0.04584 - acc: 0.9830 -- iter: 1504/3072
[A[ATraining Step: 2640  | total loss: [1m[32m0.04541[0m[0m | time: 52.677s
[2K
| Adam | epoch: 028 | loss: 0.04541 - acc: 0.9816 -- iter: 1536/3072
[A[ATraining Step: 2641  | total loss: [1m[32m0.05221[0m[0m | time: 53.677s
[2K
| Adam | epoch: 028 | loss: 0.05221 - acc: 0.9803 -- iter: 1568/3072
[A[ATraining Step: 2642  | total loss: [1m[32m0.05141[0m[0m | time: 54.621s
[2K
| Adam | epoch: 028 | loss: 0.05141 - acc: 0.9823 -- iter: 1600/3072
[A[ATraining Step: 2643  | total loss: [1m[32m0.06005[0m[0m | time: 55.584s
[2K
| Adam | epoch: 028 | loss: 0.06005 - acc: 0.9809 -- iter: 1632/3072
[A[ATraining Step: 2644  | total loss: [1m[32m0.05444[0m[0m | time: 56.822s
[2K
| Adam | epoch: 028 | loss: 0.05444 - acc: 0.9828 -- iter: 1664/3072
[A[ATraining Step: 2645  | total loss: [1m[32m0.04983[0m[0m | time: 57.750s
[2K
| Adam | epoch: 028 | loss: 0.04983 - acc: 0.9845 -- iter: 1696/3072
[A[ATraining Step: 2646  | total loss: [1m[32m0.04824[0m[0m | time: 58.790s
[2K
| Adam | epoch: 028 | loss: 0.04824 - acc: 0.9830 -- iter: 1728/3072
[A[ATraining Step: 2647  | total loss: [1m[32m0.04384[0m[0m | time: 59.866s
[2K
| Adam | epoch: 028 | loss: 0.04384 - acc: 0.9847 -- iter: 1760/3072
[A[ATraining Step: 2648  | total loss: [1m[32m0.04150[0m[0m | time: 60.926s
[2K
| Adam | epoch: 028 | loss: 0.04150 - acc: 0.9862 -- iter: 1792/3072
[A[ATraining Step: 2649  | total loss: [1m[32m0.03800[0m[0m | time: 61.847s
[2K
| Adam | epoch: 028 | loss: 0.03800 - acc: 0.9876 -- iter: 1824/3072
[A[ATraining Step: 2650  | total loss: [1m[32m0.03491[0m[0m | time: 62.858s
[2K
| Adam | epoch: 028 | loss: 0.03491 - acc: 0.9888 -- iter: 1856/3072
[A[ATraining Step: 2651  | total loss: [1m[32m0.05097[0m[0m | time: 63.809s
[2K
| Adam | epoch: 028 | loss: 0.05097 - acc: 0.9868 -- iter: 1888/3072
[A[ATraining Step: 2652  | total loss: [1m[32m0.05741[0m[0m | time: 64.795s
[2K
| Adam | epoch: 028 | loss: 0.05741 - acc: 0.9850 -- iter: 1920/3072
[A[ATraining Step: 2653  | total loss: [1m[32m0.05245[0m[0m | time: 65.960s
[2K
| Adam | epoch: 028 | loss: 0.05245 - acc: 0.9865 -- iter: 1952/3072
[A[ATraining Step: 2654  | total loss: [1m[32m0.04759[0m[0m | time: 67.050s
[2K
| Adam | epoch: 028 | loss: 0.04759 - acc: 0.9879 -- iter: 1984/3072
[A[ATraining Step: 2655  | total loss: [1m[32m0.04389[0m[0m | time: 68.061s
[2K
| Adam | epoch: 028 | loss: 0.04389 - acc: 0.9891 -- iter: 2016/3072
[A[ATraining Step: 2656  | total loss: [1m[32m0.04107[0m[0m | time: 69.233s
[2K
| Adam | epoch: 028 | loss: 0.04107 - acc: 0.9902 -- iter: 2048/3072
[A[ATraining Step: 2657  | total loss: [1m[32m0.04025[0m[0m | time: 70.311s
[2K
| Adam | epoch: 028 | loss: 0.04025 - acc: 0.9880 -- iter: 2080/3072
[A[ATraining Step: 2658  | total loss: [1m[32m0.03748[0m[0m | time: 71.168s
[2K
| Adam | epoch: 028 | loss: 0.03748 - acc: 0.9892 -- iter: 2112/3072
[A[ATraining Step: 2659  | total loss: [1m[32m0.04745[0m[0m | time: 72.180s
[2K
| Adam | epoch: 028 | loss: 0.04745 - acc: 0.9840 -- iter: 2144/3072
[A[ATraining Step: 2660  | total loss: [1m[32m0.04450[0m[0m | time: 73.209s
[2K
| Adam | epoch: 028 | loss: 0.04450 - acc: 0.9856 -- iter: 2176/3072
[A[ATraining Step: 2661  | total loss: [1m[32m0.04117[0m[0m | time: 74.301s
[2K
| Adam | epoch: 028 | loss: 0.04117 - acc: 0.9871 -- iter: 2208/3072
[A[ATraining Step: 2662  | total loss: [1m[32m0.03841[0m[0m | time: 75.575s
[2K
| Adam | epoch: 028 | loss: 0.03841 - acc: 0.9884 -- iter: 2240/3072
[A[ATraining Step: 2663  | total loss: [1m[32m0.03554[0m[0m | time: 76.538s
[2K
| Adam | epoch: 028 | loss: 0.03554 - acc: 0.9895 -- iter: 2272/3072
[A[ATraining Step: 2664  | total loss: [1m[32m0.03343[0m[0m | time: 77.624s
[2K
| Adam | epoch: 028 | loss: 0.03343 - acc: 0.9906 -- iter: 2304/3072
[A[ATraining Step: 2665  | total loss: [1m[32m0.03209[0m[0m | time: 78.716s
[2K
| Adam | epoch: 028 | loss: 0.03209 - acc: 0.9915 -- iter: 2336/3072
[A[ATraining Step: 2666  | total loss: [1m[32m0.03536[0m[0m | time: 79.756s
[2K
| Adam | epoch: 028 | loss: 0.03536 - acc: 0.9892 -- iter: 2368/3072
[A[ATraining Step: 2667  | total loss: [1m[32m0.03310[0m[0m | time: 80.611s
[2K
| Adam | epoch: 028 | loss: 0.03310 - acc: 0.9903 -- iter: 2400/3072
[A[ATraining Step: 2668  | total loss: [1m[32m0.03502[0m[0m | time: 81.571s
[2K
| Adam | epoch: 028 | loss: 0.03502 - acc: 0.9882 -- iter: 2432/3072
[A[ATraining Step: 2669  | total loss: [1m[32m0.03244[0m[0m | time: 82.570s
[2K
| Adam | epoch: 028 | loss: 0.03244 - acc: 0.9893 -- iter: 2464/3072
[A[ATraining Step: 2670  | total loss: [1m[32m0.02963[0m[0m | time: 83.691s
[2K
| Adam | epoch: 028 | loss: 0.02963 - acc: 0.9904 -- iter: 2496/3072
[A[ATraining Step: 2671  | total loss: [1m[32m0.02738[0m[0m | time: 84.850s
[2K
| Adam | epoch: 028 | loss: 0.02738 - acc: 0.9914 -- iter: 2528/3072
[A[ATraining Step: 2672  | total loss: [1m[32m0.02492[0m[0m | time: 85.770s
[2K
| Adam | epoch: 028 | loss: 0.02492 - acc: 0.9922 -- iter: 2560/3072
[A[ATraining Step: 2673  | total loss: [1m[32m0.02315[0m[0m | time: 86.683s
[2K
| Adam | epoch: 028 | loss: 0.02315 - acc: 0.9930 -- iter: 2592/3072
[A[ATraining Step: 2674  | total loss: [1m[32m0.02117[0m[0m | time: 87.877s
[2K
| Adam | epoch: 028 | loss: 0.02117 - acc: 0.9937 -- iter: 2624/3072
[A[ATraining Step: 2675  | total loss: [1m[32m0.01981[0m[0m | time: 88.970s
[2K
| Adam | epoch: 028 | loss: 0.01981 - acc: 0.9943 -- iter: 2656/3072
[A[ATraining Step: 2676  | total loss: [1m[32m0.01876[0m[0m | time: 89.815s
[2K
| Adam | epoch: 028 | loss: 0.01876 - acc: 0.9949 -- iter: 2688/3072
[A[ATraining Step: 2677  | total loss: [1m[32m0.01758[0m[0m | time: 90.832s
[2K
| Adam | epoch: 028 | loss: 0.01758 - acc: 0.9954 -- iter: 2720/3072
[A[ATraining Step: 2678  | total loss: [1m[32m0.01602[0m[0m | time: 91.868s
[2K
| Adam | epoch: 028 | loss: 0.01602 - acc: 0.9959 -- iter: 2752/3072
[A[ATraining Step: 2679  | total loss: [1m[32m0.02127[0m[0m | time: 92.845s
[2K
| Adam | epoch: 028 | loss: 0.02127 - acc: 0.9932 -- iter: 2784/3072
[A[ATraining Step: 2680  | total loss: [1m[32m0.01983[0m[0m | time: 94.040s
[2K
| Adam | epoch: 028 | loss: 0.01983 - acc: 0.9938 -- iter: 2816/3072
[A[ATraining Step: 2681  | total loss: [1m[32m0.01831[0m[0m | time: 95.071s
[2K
| Adam | epoch: 028 | loss: 0.01831 - acc: 0.9945 -- iter: 2848/3072
[A[ATraining Step: 2682  | total loss: [1m[32m0.01804[0m[0m | time: 96.000s
[2K
| Adam | epoch: 028 | loss: 0.01804 - acc: 0.9950 -- iter: 2880/3072
[A[ATraining Step: 2683  | total loss: [1m[32m0.02770[0m[0m | time: 97.103s
[2K
| Adam | epoch: 028 | loss: 0.02770 - acc: 0.9893 -- iter: 2912/3072
[A[ATraining Step: 2684  | total loss: [1m[32m0.02543[0m[0m | time: 98.161s
[2K
| Adam | epoch: 028 | loss: 0.02543 - acc: 0.9903 -- iter: 2944/3072
[A[ATraining Step: 2685  | total loss: [1m[32m0.02703[0m[0m | time: 99.045s
[2K
| Adam | epoch: 028 | loss: 0.02703 - acc: 0.9882 -- iter: 2976/3072
[A[ATraining Step: 2686  | total loss: [1m[32m0.02713[0m[0m | time: 100.020s
[2K
| Adam | epoch: 028 | loss: 0.02713 - acc: 0.9894 -- iter: 3008/3072
[A[ATraining Step: 2687  | total loss: [1m[32m0.02765[0m[0m | time: 101.020s
[2K
| Adam | epoch: 028 | loss: 0.02765 - acc: 0.9904 -- iter: 3040/3072
[A[ATraining Step: 2688  | total loss: [1m[32m0.02725[0m[0m | time: 107.102s
[2K
| Adam | epoch: 028 | loss: 0.02725 - acc: 0.9914 | val_loss: 0.84700 - val_acc: 0.7992 -- iter: 3072/3072
--
Training Step: 2689  | total loss: [1m[32m0.03813[0m[0m | time: 1.020s
[2K
| Adam | epoch: 029 | loss: 0.03813 - acc: 0.9891 -- iter: 0032/3072
[A[ATraining Step: 2690  | total loss: [1m[32m0.03557[0m[0m | time: 1.890s
[2K
| Adam | epoch: 029 | loss: 0.03557 - acc: 0.9902 -- iter: 0064/3072
[A[ATraining Step: 2691  | total loss: [1m[32m0.03345[0m[0m | time: 2.817s
[2K
| Adam | epoch: 029 | loss: 0.03345 - acc: 0.9912 -- iter: 0096/3072
[A[ATraining Step: 2692  | total loss: [1m[32m0.03061[0m[0m | time: 3.783s
[2K
| Adam | epoch: 029 | loss: 0.03061 - acc: 0.9921 -- iter: 0128/3072
[A[ATraining Step: 2693  | total loss: [1m[32m0.02841[0m[0m | time: 4.772s
[2K
| Adam | epoch: 029 | loss: 0.02841 - acc: 0.9929 -- iter: 0160/3072
[A[ATraining Step: 2694  | total loss: [1m[32m0.02700[0m[0m | time: 5.935s
[2K
| Adam | epoch: 029 | loss: 0.02700 - acc: 0.9936 -- iter: 0192/3072
[A[ATraining Step: 2695  | total loss: [1m[32m0.02651[0m[0m | time: 6.870s
[2K
| Adam | epoch: 029 | loss: 0.02651 - acc: 0.9942 -- iter: 0224/3072
[A[ATraining Step: 2696  | total loss: [1m[32m0.02426[0m[0m | time: 7.786s
[2K
| Adam | epoch: 029 | loss: 0.02426 - acc: 0.9948 -- iter: 0256/3072
[A[ATraining Step: 2697  | total loss: [1m[32m0.02262[0m[0m | time: 8.945s
[2K
| Adam | epoch: 029 | loss: 0.02262 - acc: 0.9953 -- iter: 0288/3072
[A[ATraining Step: 2698  | total loss: [1m[32m0.02177[0m[0m | time: 10.021s
[2K
| Adam | epoch: 029 | loss: 0.02177 - acc: 0.9958 -- iter: 0320/3072
[A[ATraining Step: 2699  | total loss: [1m[32m0.03078[0m[0m | time: 10.927s
[2K
| Adam | epoch: 029 | loss: 0.03078 - acc: 0.9931 -- iter: 0352/3072
[A[ATraining Step: 2700  | total loss: [1m[32m0.02850[0m[0m | time: 11.937s
[2K
| Adam | epoch: 029 | loss: 0.02850 - acc: 0.9938 -- iter: 0384/3072
[A[ATraining Step: 2701  | total loss: [1m[32m0.02659[0m[0m | time: 12.952s
[2K
| Adam | epoch: 029 | loss: 0.02659 - acc: 0.9944 -- iter: 0416/3072
[A[ATraining Step: 2702  | total loss: [1m[32m0.02447[0m[0m | time: 13.867s
[2K
| Adam | epoch: 029 | loss: 0.02447 - acc: 0.9950 -- iter: 0448/3072
[A[ATraining Step: 2703  | total loss: [1m[32m0.02264[0m[0m | time: 15.056s
[2K
| Adam | epoch: 029 | loss: 0.02264 - acc: 0.9955 -- iter: 0480/3072
[A[ATraining Step: 2704  | total loss: [1m[32m0.03093[0m[0m | time: 16.111s
[2K
| Adam | epoch: 029 | loss: 0.03093 - acc: 0.9928 -- iter: 0512/3072
[A[ATraining Step: 2705  | total loss: [1m[32m0.02913[0m[0m | time: 17.070s
[2K
| Adam | epoch: 029 | loss: 0.02913 - acc: 0.9935 -- iter: 0544/3072
[A[ATraining Step: 2706  | total loss: [1m[32m0.04055[0m[0m | time: 18.083s
[2K
| Adam | epoch: 029 | loss: 0.04055 - acc: 0.9910 -- iter: 0576/3072
[A[ATraining Step: 2707  | total loss: [1m[32m0.03670[0m[0m | time: 19.163s
[2K
| Adam | epoch: 029 | loss: 0.03670 - acc: 0.9919 -- iter: 0608/3072
[A[ATraining Step: 2708  | total loss: [1m[32m0.03333[0m[0m | time: 20.037s
[2K
| Adam | epoch: 029 | loss: 0.03333 - acc: 0.9927 -- iter: 0640/3072
[A[ATraining Step: 2709  | total loss: [1m[32m0.03069[0m[0m | time: 21.009s
[2K
| Adam | epoch: 029 | loss: 0.03069 - acc: 0.9935 -- iter: 0672/3072
[A[ATraining Step: 2710  | total loss: [1m[32m0.02873[0m[0m | time: 21.946s
[2K
| Adam | epoch: 029 | loss: 0.02873 - acc: 0.9941 -- iter: 0704/3072
[A[ATraining Step: 2711  | total loss: [1m[32m0.02727[0m[0m | time: 22.901s
[2K
| Adam | epoch: 029 | loss: 0.02727 - acc: 0.9947 -- iter: 0736/3072
[A[ATraining Step: 2712  | total loss: [1m[32m0.02495[0m[0m | time: 23.892s
[2K
| Adam | epoch: 029 | loss: 0.02495 - acc: 0.9952 -- iter: 0768/3072
[A[ATraining Step: 2713  | total loss: [1m[32m0.02274[0m[0m | time: 24.960s
[2K
| Adam | epoch: 029 | loss: 0.02274 - acc: 0.9957 -- iter: 0800/3072
[A[ATraining Step: 2714  | total loss: [1m[32m0.02247[0m[0m | time: 25.879s
[2K
| Adam | epoch: 029 | loss: 0.02247 - acc: 0.9961 -- iter: 0832/3072
[A[ATraining Step: 2715  | total loss: [1m[32m0.02091[0m[0m | time: 26.989s
[2K
| Adam | epoch: 029 | loss: 0.02091 - acc: 0.9965 -- iter: 0864/3072
[A[ATraining Step: 2716  | total loss: [1m[32m0.02288[0m[0m | time: 28.067s
[2K
| Adam | epoch: 029 | loss: 0.02288 - acc: 0.9937 -- iter: 0896/3072
[A[ATraining Step: 2717  | total loss: [1m[32m0.02177[0m[0m | time: 29.200s
[2K
| Adam | epoch: 029 | loss: 0.02177 - acc: 0.9944 -- iter: 0928/3072
[A[ATraining Step: 2718  | total loss: [1m[32m0.02584[0m[0m | time: 30.117s
[2K
| Adam | epoch: 029 | loss: 0.02584 - acc: 0.9918 -- iter: 0960/3072
[A[ATraining Step: 2719  | total loss: [1m[32m0.02576[0m[0m | time: 31.123s
[2K
| Adam | epoch: 029 | loss: 0.02576 - acc: 0.9926 -- iter: 0992/3072
[A[ATraining Step: 2720  | total loss: [1m[32m0.02378[0m[0m | time: 32.121s
[2K
| Adam | epoch: 029 | loss: 0.02378 - acc: 0.9934 -- iter: 1024/3072
[A[ATraining Step: 2721  | total loss: [1m[32m0.02204[0m[0m | time: 33.062s
[2K
| Adam | epoch: 029 | loss: 0.02204 - acc: 0.9940 -- iter: 1056/3072
[A[ATraining Step: 2722  | total loss: [1m[32m0.02034[0m[0m | time: 34.362s
[2K
| Adam | epoch: 029 | loss: 0.02034 - acc: 0.9946 -- iter: 1088/3072
[A[ATraining Step: 2723  | total loss: [1m[32m0.02010[0m[0m | time: 35.303s
[2K
| Adam | epoch: 029 | loss: 0.02010 - acc: 0.9952 -- iter: 1120/3072
[A[ATraining Step: 2724  | total loss: [1m[32m0.01946[0m[0m | time: 36.396s
[2K
| Adam | epoch: 029 | loss: 0.01946 - acc: 0.9956 -- iter: 1152/3072
[A[ATraining Step: 2725  | total loss: [1m[32m0.02043[0m[0m | time: 37.440s
[2K
| Adam | epoch: 029 | loss: 0.02043 - acc: 0.9961 -- iter: 1184/3072
[A[ATraining Step: 2726  | total loss: [1m[32m0.02518[0m[0m | time: 38.502s
[2K
| Adam | epoch: 029 | loss: 0.02518 - acc: 0.9934 -- iter: 1216/3072
[A[ATraining Step: 2727  | total loss: [1m[32m0.02324[0m[0m | time: 39.376s
[2K
| Adam | epoch: 029 | loss: 0.02324 - acc: 0.9940 -- iter: 1248/3072
[A[ATraining Step: 2728  | total loss: [1m[32m0.02200[0m[0m | time: 40.353s
[2K
| Adam | epoch: 029 | loss: 0.02200 - acc: 0.9946 -- iter: 1280/3072
[A[ATraining Step: 2729  | total loss: [1m[32m0.02129[0m[0m | time: 41.257s
[2K
| Adam | epoch: 029 | loss: 0.02129 - acc: 0.9952 -- iter: 1312/3072
[A[ATraining Step: 2730  | total loss: [1m[32m0.02071[0m[0m | time: 42.185s
[2K
| Adam | epoch: 029 | loss: 0.02071 - acc: 0.9956 -- iter: 1344/3072
[A[ATraining Step: 2731  | total loss: [1m[32m0.02015[0m[0m | time: 43.484s
[2K
| Adam | epoch: 029 | loss: 0.02015 - acc: 0.9961 -- iter: 1376/3072
[A[ATraining Step: 2732  | total loss: [1m[32m0.02040[0m[0m | time: 44.484s
[2K
| Adam | epoch: 029 | loss: 0.02040 - acc: 0.9965 -- iter: 1408/3072
[A[ATraining Step: 2733  | total loss: [1m[32m0.02054[0m[0m | time: 45.403s
[2K
| Adam | epoch: 029 | loss: 0.02054 - acc: 0.9968 -- iter: 1440/3072
[A[ATraining Step: 2734  | total loss: [1m[32m0.01908[0m[0m | time: 46.556s
[2K
| Adam | epoch: 029 | loss: 0.01908 - acc: 0.9971 -- iter: 1472/3072
[A[ATraining Step: 2735  | total loss: [1m[32m0.01805[0m[0m | time: 47.669s
[2K
| Adam | epoch: 029 | loss: 0.01805 - acc: 0.9974 -- iter: 1504/3072
[A[ATraining Step: 2736  | total loss: [1m[32m0.01663[0m[0m | time: 48.577s
[2K
| Adam | epoch: 029 | loss: 0.01663 - acc: 0.9977 -- iter: 1536/3072
[A[ATraining Step: 2737  | total loss: [1m[32m0.01528[0m[0m | time: 49.594s
[2K
| Adam | epoch: 029 | loss: 0.01528 - acc: 0.9979 -- iter: 1568/3072
[A[ATraining Step: 2738  | total loss: [1m[32m0.01900[0m[0m | time: 50.540s
[2K
| Adam | epoch: 029 | loss: 0.01900 - acc: 0.9950 -- iter: 1600/3072
[A[ATraining Step: 2739  | total loss: [1m[32m0.02810[0m[0m | time: 51.569s
[2K
| Adam | epoch: 029 | loss: 0.02810 - acc: 0.9924 -- iter: 1632/3072
[A[ATraining Step: 2740  | total loss: [1m[32m0.03395[0m[0m | time: 52.717s
[2K
| Adam | epoch: 029 | loss: 0.03395 - acc: 0.9900 -- iter: 1664/3072
[A[ATraining Step: 2741  | total loss: [1m[32m0.03781[0m[0m | time: 53.761s
[2K
| Adam | epoch: 029 | loss: 0.03781 - acc: 0.9879 -- iter: 1696/3072
[A[ATraining Step: 2742  | total loss: [1m[32m0.03454[0m[0m | time: 54.689s
[2K
| Adam | epoch: 029 | loss: 0.03454 - acc: 0.9891 -- iter: 1728/3072
[A[ATraining Step: 2743  | total loss: [1m[32m0.03382[0m[0m | time: 55.828s
[2K
| Adam | epoch: 029 | loss: 0.03382 - acc: 0.9902 -- iter: 1760/3072
[A[ATraining Step: 2744  | total loss: [1m[32m0.03137[0m[0m | time: 56.943s
[2K
| Adam | epoch: 029 | loss: 0.03137 - acc: 0.9912 -- iter: 1792/3072
[A[ATraining Step: 2745  | total loss: [1m[32m0.02909[0m[0m | time: 57.790s
[2K
| Adam | epoch: 029 | loss: 0.02909 - acc: 0.9921 -- iter: 1824/3072
[A[ATraining Step: 2746  | total loss: [1m[32m0.02681[0m[0m | time: 58.726s
[2K
| Adam | epoch: 029 | loss: 0.02681 - acc: 0.9928 -- iter: 1856/3072
[A[ATraining Step: 2747  | total loss: [1m[32m0.02443[0m[0m | time: 59.790s
[2K
| Adam | epoch: 029 | loss: 0.02443 - acc: 0.9936 -- iter: 1888/3072
[A[ATraining Step: 2748  | total loss: [1m[32m0.02239[0m[0m | time: 60.795s
[2K
| Adam | epoch: 029 | loss: 0.02239 - acc: 0.9942 -- iter: 1920/3072
[A[ATraining Step: 2749  | total loss: [1m[32m0.02048[0m[0m | time: 61.883s
[2K
| Adam | epoch: 029 | loss: 0.02048 - acc: 0.9948 -- iter: 1952/3072
[A[ATraining Step: 2750  | total loss: [1m[32m0.01953[0m[0m | time: 62.960s
[2K
| Adam | epoch: 029 | loss: 0.01953 - acc: 0.9953 -- iter: 1984/3072
[A[ATraining Step: 2751  | total loss: [1m[32m0.01884[0m[0m | time: 63.946s
[2K
| Adam | epoch: 029 | loss: 0.01884 - acc: 0.9958 -- iter: 2016/3072
[A[ATraining Step: 2752  | total loss: [1m[32m0.01792[0m[0m | time: 65.106s
[2K
| Adam | epoch: 029 | loss: 0.01792 - acc: 0.9962 -- iter: 2048/3072
[A[ATraining Step: 2753  | total loss: [1m[32m0.01650[0m[0m | time: 66.236s
[2K
| Adam | epoch: 029 | loss: 0.01650 - acc: 0.9966 -- iter: 2080/3072
[A[ATraining Step: 2754  | total loss: [1m[32m0.01572[0m[0m | time: 67.149s
[2K
| Adam | epoch: 029 | loss: 0.01572 - acc: 0.9969 -- iter: 2112/3072
[A[ATraining Step: 2755  | total loss: [1m[32m0.01785[0m[0m | time: 68.095s
[2K
| Adam | epoch: 029 | loss: 0.01785 - acc: 0.9941 -- iter: 2144/3072
[A[ATraining Step: 2756  | total loss: [1m[32m0.01670[0m[0m | time: 69.119s
[2K
| Adam | epoch: 029 | loss: 0.01670 - acc: 0.9947 -- iter: 2176/3072
[A[ATraining Step: 2757  | total loss: [1m[32m0.02923[0m[0m | time: 70.062s
[2K
| Adam | epoch: 029 | loss: 0.02923 - acc: 0.9890 -- iter: 2208/3072
[A[ATraining Step: 2758  | total loss: [1m[32m0.03136[0m[0m | time: 71.123s
[2K
| Adam | epoch: 029 | loss: 0.03136 - acc: 0.9870 -- iter: 2240/3072
[A[ATraining Step: 2759  | total loss: [1m[32m0.02956[0m[0m | time: 72.193s
[2K
| Adam | epoch: 029 | loss: 0.02956 - acc: 0.9883 -- iter: 2272/3072
[A[ATraining Step: 2760  | total loss: [1m[32m0.02726[0m[0m | time: 73.093s
[2K
| Adam | epoch: 029 | loss: 0.02726 - acc: 0.9894 -- iter: 2304/3072
[A[ATraining Step: 2761  | total loss: [1m[32m0.02631[0m[0m | time: 74.166s
[2K
| Adam | epoch: 029 | loss: 0.02631 - acc: 0.9905 -- iter: 2336/3072
[A[ATraining Step: 2762  | total loss: [1m[32m0.03451[0m[0m | time: 75.317s
[2K
| Adam | epoch: 029 | loss: 0.03451 - acc: 0.9883 -- iter: 2368/3072
[A[ATraining Step: 2763  | total loss: [1m[32m0.03678[0m[0m | time: 76.193s
[2K
| Adam | epoch: 029 | loss: 0.03678 - acc: 0.9895 -- iter: 2400/3072
[A[ATraining Step: 2764  | total loss: [1m[32m0.06443[0m[0m | time: 77.083s
[2K
| Adam | epoch: 029 | loss: 0.06443 - acc: 0.9874 -- iter: 2432/3072
[A[ATraining Step: 2765  | total loss: [1m[32m0.05897[0m[0m | time: 78.052s
[2K
| Adam | epoch: 029 | loss: 0.05897 - acc: 0.9887 -- iter: 2464/3072
[A[ATraining Step: 2766  | total loss: [1m[32m0.05918[0m[0m | time: 78.982s
[2K
| Adam | epoch: 029 | loss: 0.05918 - acc: 0.9836 -- iter: 2496/3072
[A[ATraining Step: 2767  | total loss: [1m[32m0.05344[0m[0m | time: 80.138s
[2K
| Adam | epoch: 029 | loss: 0.05344 - acc: 0.9852 -- iter: 2528/3072
[A[ATraining Step: 2768  | total loss: [1m[32m0.05365[0m[0m | time: 81.236s
[2K
| Adam | epoch: 029 | loss: 0.05365 - acc: 0.9836 -- iter: 2560/3072
[A[ATraining Step: 2769  | total loss: [1m[32m0.07371[0m[0m | time: 82.228s
[2K
| Adam | epoch: 029 | loss: 0.07371 - acc: 0.9758 -- iter: 2592/3072
[A[ATraining Step: 2770  | total loss: [1m[32m0.07023[0m[0m | time: 83.366s
[2K
| Adam | epoch: 029 | loss: 0.07023 - acc: 0.9751 -- iter: 2624/3072
[A[ATraining Step: 2771  | total loss: [1m[32m0.06556[0m[0m | time: 84.519s
[2K
| Adam | epoch: 029 | loss: 0.06556 - acc: 0.9776 -- iter: 2656/3072
[A[ATraining Step: 2772  | total loss: [1m[32m0.06028[0m[0m | time: 85.509s
[2K
| Adam | epoch: 029 | loss: 0.06028 - acc: 0.9798 -- iter: 2688/3072
[A[ATraining Step: 2773  | total loss: [1m[32m0.05614[0m[0m | time: 86.457s
[2K
| Adam | epoch: 029 | loss: 0.05614 - acc: 0.9819 -- iter: 2720/3072
[A[ATraining Step: 2774  | total loss: [1m[32m0.05422[0m[0m | time: 87.444s
[2K
| Adam | epoch: 029 | loss: 0.05422 - acc: 0.9805 -- iter: 2752/3072
[A[ATraining Step: 2775  | total loss: [1m[32m0.05976[0m[0m | time: 88.385s
[2K
| Adam | epoch: 029 | loss: 0.05976 - acc: 0.9794 -- iter: 2784/3072
[A[ATraining Step: 2776  | total loss: [1m[32m0.06799[0m[0m | time: 89.455s
[2K
| Adam | epoch: 029 | loss: 0.06799 - acc: 0.9721 -- iter: 2816/3072
[A[ATraining Step: 2777  | total loss: [1m[32m0.06391[0m[0m | time: 90.583s
[2K
| Adam | epoch: 029 | loss: 0.06391 - acc: 0.9749 -- iter: 2848/3072
[A[ATraining Step: 2778  | total loss: [1m[32m0.05808[0m[0m | time: 91.576s
[2K
| Adam | epoch: 029 | loss: 0.05808 - acc: 0.9774 -- iter: 2880/3072
[A[ATraining Step: 2779  | total loss: [1m[32m0.05674[0m[0m | time: 92.785s
[2K
| Adam | epoch: 029 | loss: 0.05674 - acc: 0.9765 -- iter: 2912/3072
[A[ATraining Step: 2780  | total loss: [1m[32m0.05389[0m[0m | time: 93.899s
[2K
| Adam | epoch: 029 | loss: 0.05389 - acc: 0.9757 -- iter: 2944/3072
[A[ATraining Step: 2781  | total loss: [1m[32m0.05025[0m[0m | time: 94.830s
[2K
| Adam | epoch: 029 | loss: 0.05025 - acc: 0.9782 -- iter: 2976/3072
[A[ATraining Step: 2782  | total loss: [1m[32m0.04555[0m[0m | time: 95.675s
[2K
| Adam | epoch: 029 | loss: 0.04555 - acc: 0.9803 -- iter: 3008/3072
[A[ATraining Step: 2783  | total loss: [1m[32m0.04220[0m[0m | time: 96.656s
[2K
| Adam | epoch: 029 | loss: 0.04220 - acc: 0.9823 -- iter: 3040/3072
[A[ATraining Step: 2784  | total loss: [1m[32m0.03883[0m[0m | time: 102.889s
[2K
| Adam | epoch: 029 | loss: 0.03883 - acc: 0.9841 | val_loss: 1.05318 - val_acc: 0.7680 -- iter: 3072/3072
--
Training Step: 2785  | total loss: [1m[32m0.04336[0m[0m | time: 1.088s
[2K
| Adam | epoch: 030 | loss: 0.04336 - acc: 0.9857 -- iter: 0032/3072
[A[ATraining Step: 2786  | total loss: [1m[32m0.04113[0m[0m | time: 2.026s
[2K
| Adam | epoch: 030 | loss: 0.04113 - acc: 0.9871 -- iter: 0064/3072
[A[ATraining Step: 2787  | total loss: [1m[32m0.04494[0m[0m | time: 2.898s
[2K
| Adam | epoch: 030 | loss: 0.04494 - acc: 0.9853 -- iter: 0096/3072
[A[ATraining Step: 2788  | total loss: [1m[32m0.04077[0m[0m | time: 3.983s
[2K
| Adam | epoch: 030 | loss: 0.04077 - acc: 0.9867 -- iter: 0128/3072
[A[ATraining Step: 2789  | total loss: [1m[32m0.03774[0m[0m | time: 5.004s
[2K
| Adam | epoch: 030 | loss: 0.03774 - acc: 0.9881 -- iter: 0160/3072
[A[ATraining Step: 2790  | total loss: [1m[32m0.06088[0m[0m | time: 6.192s
[2K
| Adam | epoch: 030 | loss: 0.06088 - acc: 0.9768 -- iter: 0192/3072
[A[ATraining Step: 2791  | total loss: [1m[32m0.05535[0m[0m | time: 7.246s
[2K
| Adam | epoch: 030 | loss: 0.05535 - acc: 0.9791 -- iter: 0224/3072
[A[ATraining Step: 2792  | total loss: [1m[32m0.06020[0m[0m | time: 8.238s
[2K
| Adam | epoch: 030 | loss: 0.06020 - acc: 0.9780 -- iter: 0256/3072
[A[ATraining Step: 2793  | total loss: [1m[32m0.06842[0m[0m | time: 9.336s
[2K
| Adam | epoch: 030 | loss: 0.06842 - acc: 0.9740 -- iter: 0288/3072
[A[ATraining Step: 2794  | total loss: [1m[32m0.06600[0m[0m | time: 10.437s
[2K
| Adam | epoch: 030 | loss: 0.06600 - acc: 0.9735 -- iter: 0320/3072
[A[ATraining Step: 2795  | total loss: [1m[32m0.07389[0m[0m | time: 11.411s
[2K
| Adam | epoch: 030 | loss: 0.07389 - acc: 0.9730 -- iter: 0352/3072
[A[ATraining Step: 2796  | total loss: [1m[32m0.06858[0m[0m | time: 12.347s
[2K
| Adam | epoch: 030 | loss: 0.06858 - acc: 0.9757 -- iter: 0384/3072
[A[ATraining Step: 2797  | total loss: [1m[32m0.06217[0m[0m | time: 13.305s
[2K
| Adam | epoch: 030 | loss: 0.06217 - acc: 0.9781 -- iter: 0416/3072
[A[ATraining Step: 2798  | total loss: [1m[32m0.05616[0m[0m | time: 14.268s
[2K
| Adam | epoch: 030 | loss: 0.05616 - acc: 0.9803 -- iter: 0448/3072
[A[ATraining Step: 2799  | total loss: [1m[32m0.07014[0m[0m | time: 15.382s
[2K
| Adam | epoch: 030 | loss: 0.07014 - acc: 0.9792 -- iter: 0480/3072
[A[ATraining Step: 2800  | total loss: [1m[32m0.06327[0m[0m | time: 21.263s
[2K
| Adam | epoch: 030 | loss: 0.06327 - acc: 0.9812 | val_loss: 0.85957 - val_acc: 0.7992 -- iter: 0512/3072
--
Training Step: 2801  | total loss: [1m[32m0.05756[0m[0m | time: 22.236s
[2K
| Adam | epoch: 030 | loss: 0.05756 - acc: 0.9831 -- iter: 0544/3072
[A[ATraining Step: 2802  | total loss: [1m[32m0.05198[0m[0m | time: 23.242s
[2K
| Adam | epoch: 030 | loss: 0.05198 - acc: 0.9848 -- iter: 0576/3072
[A[ATraining Step: 2803  | total loss: [1m[32m0.04927[0m[0m | time: 24.218s
[2K
| Adam | epoch: 030 | loss: 0.04927 - acc: 0.9863 -- iter: 0608/3072
[A[ATraining Step: 2804  | total loss: [1m[32m0.04487[0m[0m | time: 25.284s
[2K
| Adam | epoch: 030 | loss: 0.04487 - acc: 0.9877 -- iter: 0640/3072
[A[ATraining Step: 2805  | total loss: [1m[32m0.04157[0m[0m | time: 26.401s
[2K
| Adam | epoch: 030 | loss: 0.04157 - acc: 0.9889 -- iter: 0672/3072
[A[ATraining Step: 2806  | total loss: [1m[32m0.03781[0m[0m | time: 27.301s
[2K
| Adam | epoch: 030 | loss: 0.03781 - acc: 0.9900 -- iter: 0704/3072
[A[ATraining Step: 2807  | total loss: [1m[32m0.03530[0m[0m | time: 28.384s
[2K
| Adam | epoch: 030 | loss: 0.03530 - acc: 0.9910 -- iter: 0736/3072
[A[ATraining Step: 2808  | total loss: [1m[32m0.03291[0m[0m | time: 29.475s
[2K
| Adam | epoch: 030 | loss: 0.03291 - acc: 0.9919 -- iter: 0768/3072
[A[ATraining Step: 2809  | total loss: [1m[32m0.03082[0m[0m | time: 30.517s
[2K
| Adam | epoch: 030 | loss: 0.03082 - acc: 0.9927 -- iter: 0800/3072
[A[ATraining Step: 2810  | total loss: [1m[32m0.03007[0m[0m | time: 31.339s
[2K
| Adam | epoch: 030 | loss: 0.03007 - acc: 0.9935 -- iter: 0832/3072
[A[ATraining Step: 2811  | total loss: [1m[32m0.02801[0m[0m | time: 32.365s
[2K
| Adam | epoch: 030 | loss: 0.02801 - acc: 0.9941 -- iter: 0864/3072
[A[ATraining Step: 2812  | total loss: [1m[32m0.02567[0m[0m | time: 33.309s
[2K
| Adam | epoch: 030 | loss: 0.02567 - acc: 0.9947 -- iter: 0896/3072
[A[ATraining Step: 2813  | total loss: [1m[32m0.02332[0m[0m | time: 34.306s
[2K
| Adam | epoch: 030 | loss: 0.02332 - acc: 0.9952 -- iter: 0928/3072
[A[ATraining Step: 2814  | total loss: [1m[32m0.02134[0m[0m | time: 35.474s
[2K
| Adam | epoch: 030 | loss: 0.02134 - acc: 0.9957 -- iter: 0960/3072
[A[ATraining Step: 2815  | total loss: [1m[32m0.02584[0m[0m | time: 36.511s
[2K
| Adam | epoch: 030 | loss: 0.02584 - acc: 0.9930 -- iter: 0992/3072
[A[ATraining Step: 2816  | total loss: [1m[32m0.02348[0m[0m | time: 37.322s
[2K
| Adam | epoch: 030 | loss: 0.02348 - acc: 0.9937 -- iter: 1024/3072
[A[ATraining Step: 2817  | total loss: [1m[32m0.02164[0m[0m | time: 38.488s
[2K
| Adam | epoch: 030 | loss: 0.02164 - acc: 0.9943 -- iter: 1056/3072
[A[ATraining Step: 2818  | total loss: [1m[32m0.02013[0m[0m | time: 39.522s
[2K
| Adam | epoch: 030 | loss: 0.02013 - acc: 0.9949 -- iter: 1088/3072
[A[ATraining Step: 2819  | total loss: [1m[32m0.02491[0m[0m | time: 40.449s
[2K
| Adam | epoch: 030 | loss: 0.02491 - acc: 0.9923 -- iter: 1120/3072
[A[ATraining Step: 2820  | total loss: [1m[32m0.02681[0m[0m | time: 41.346s
[2K
| Adam | epoch: 030 | loss: 0.02681 - acc: 0.9899 -- iter: 1152/3072
[A[ATraining Step: 2821  | total loss: [1m[32m0.03257[0m[0m | time: 42.346s
[2K
| Adam | epoch: 030 | loss: 0.03257 - acc: 0.9878 -- iter: 1184/3072
[A[ATraining Step: 2822  | total loss: [1m[32m0.04194[0m[0m | time: 43.331s
[2K
| Adam | epoch: 030 | loss: 0.04194 - acc: 0.9859 -- iter: 1216/3072
[A[ATraining Step: 2823  | total loss: [1m[32m0.03899[0m[0m | time: 44.393s
[2K
| Adam | epoch: 030 | loss: 0.03899 - acc: 0.9873 -- iter: 1248/3072
[A[ATraining Step: 2824  | total loss: [1m[32m0.03554[0m[0m | time: 45.457s
[2K
| Adam | epoch: 030 | loss: 0.03554 - acc: 0.9886 -- iter: 1280/3072
[A[ATraining Step: 2825  | total loss: [1m[32m0.03232[0m[0m | time: 46.323s
[2K
| Adam | epoch: 030 | loss: 0.03232 - acc: 0.9897 -- iter: 1312/3072
[A[ATraining Step: 2826  | total loss: [1m[32m0.02975[0m[0m | time: 47.374s
[2K
| Adam | epoch: 030 | loss: 0.02975 - acc: 0.9908 -- iter: 1344/3072
[A[ATraining Step: 2827  | total loss: [1m[32m0.02703[0m[0m | time: 48.472s
[2K
| Adam | epoch: 030 | loss: 0.02703 - acc: 0.9917 -- iter: 1376/3072
[A[ATraining Step: 2828  | total loss: [1m[32m0.04710[0m[0m | time: 49.518s
[2K
| Adam | epoch: 030 | loss: 0.04710 - acc: 0.9894 -- iter: 1408/3072
[A[ATraining Step: 2829  | total loss: [1m[32m0.04473[0m[0m | time: 50.398s
[2K
| Adam | epoch: 030 | loss: 0.04473 - acc: 0.9904 -- iter: 1440/3072
[A[ATraining Step: 2830  | total loss: [1m[32m0.07010[0m[0m | time: 51.387s
[2K
| Adam | epoch: 030 | loss: 0.07010 - acc: 0.9852 -- iter: 1472/3072
[A[ATraining Step: 2831  | total loss: [1m[32m0.06338[0m[0m | time: 52.457s
[2K
| Adam | epoch: 030 | loss: 0.06338 - acc: 0.9866 -- iter: 1504/3072
[A[ATraining Step: 2832  | total loss: [1m[32m0.05769[0m[0m | time: 53.449s
[2K
| Adam | epoch: 030 | loss: 0.05769 - acc: 0.9880 -- iter: 1536/3072
[A[ATraining Step: 2833  | total loss: [1m[32m0.05661[0m[0m | time: 54.561s
[2K
| Adam | epoch: 030 | loss: 0.05661 - acc: 0.9861 -- iter: 1568/3072
[A[ATraining Step: 2834  | total loss: [1m[32m0.07037[0m[0m | time: 55.629s
[2K
| Adam | epoch: 030 | loss: 0.07037 - acc: 0.9843 -- iter: 1600/3072
[A[ATraining Step: 2835  | total loss: [1m[32m0.06916[0m[0m | time: 56.556s
[2K
| Adam | epoch: 030 | loss: 0.06916 - acc: 0.9859 -- iter: 1632/3072
[A[ATraining Step: 2836  | total loss: [1m[32m0.06939[0m[0m | time: 57.655s
[2K
| Adam | epoch: 030 | loss: 0.06939 - acc: 0.9842 -- iter: 1664/3072
[A[ATraining Step: 2837  | total loss: [1m[32m0.06440[0m[0m | time: 58.679s
[2K
| Adam | epoch: 030 | loss: 0.06440 - acc: 0.9858 -- iter: 1696/3072
[A[ATraining Step: 2838  | total loss: [1m[32m0.06231[0m[0m | time: 59.562s
[2K
| Adam | epoch: 030 | loss: 0.06231 - acc: 0.9841 -- iter: 1728/3072
[A[ATraining Step: 2839  | total loss: [1m[32m0.05850[0m[0m | time: 60.482s
[2K
| Adam | epoch: 030 | loss: 0.05850 - acc: 0.9857 -- iter: 1760/3072
[A[ATraining Step: 2840  | total loss: [1m[32m0.05759[0m[0m | time: 61.510s
[2K
| Adam | epoch: 030 | loss: 0.05759 - acc: 0.9840 -- iter: 1792/3072
[A[ATraining Step: 2841  | total loss: [1m[32m0.06661[0m[0m | time: 62.529s
[2K
| Adam | epoch: 030 | loss: 0.06661 - acc: 0.9793 -- iter: 1824/3072
[A[ATraining Step: 2842  | total loss: [1m[32m0.06452[0m[0m | time: 63.600s
[2K
| Adam | epoch: 030 | loss: 0.06452 - acc: 0.9814 -- iter: 1856/3072
[A[ATraining Step: 2843  | total loss: [1m[32m0.06107[0m[0m | time: 64.753s
[2K
| Adam | epoch: 030 | loss: 0.06107 - acc: 0.9832 -- iter: 1888/3072
[A[ATraining Step: 2844  | total loss: [1m[32m0.05547[0m[0m | time: 65.686s
[2K
| Adam | epoch: 030 | loss: 0.05547 - acc: 0.9849 -- iter: 1920/3072
[A[ATraining Step: 2845  | total loss: [1m[32m0.05039[0m[0m | time: 66.814s
[2K
| Adam | epoch: 030 | loss: 0.05039 - acc: 0.9864 -- iter: 1952/3072
[A[ATraining Step: 2846  | total loss: [1m[32m0.05272[0m[0m | time: 67.923s
[2K
| Adam | epoch: 030 | loss: 0.05272 - acc: 0.9847 -- iter: 1984/3072
[A[ATraining Step: 2847  | total loss: [1m[32m0.05172[0m[0m | time: 68.847s
[2K
| Adam | epoch: 030 | loss: 0.05172 - acc: 0.9862 -- iter: 2016/3072
[A[ATraining Step: 2848  | total loss: [1m[32m0.05179[0m[0m | time: 69.766s
[2K
| Adam | epoch: 030 | loss: 0.05179 - acc: 0.9845 -- iter: 2048/3072
[A[ATraining Step: 2849  | total loss: [1m[32m0.05046[0m[0m | time: 70.755s
[2K
| Adam | epoch: 030 | loss: 0.05046 - acc: 0.9829 -- iter: 2080/3072
[A[ATraining Step: 2850  | total loss: [1m[32m0.04687[0m[0m | time: 71.725s
[2K
| Adam | epoch: 030 | loss: 0.04687 - acc: 0.9846 -- iter: 2112/3072
[A[ATraining Step: 2851  | total loss: [1m[32m0.04607[0m[0m | time: 72.738s
[2K
| Adam | epoch: 030 | loss: 0.04607 - acc: 0.9830 -- iter: 2144/3072
[A[ATraining Step: 2852  | total loss: [1m[32m0.04260[0m[0m | time: 73.796s
[2K
| Adam | epoch: 030 | loss: 0.04260 - acc: 0.9847 -- iter: 2176/3072
[A[ATraining Step: 2853  | total loss: [1m[32m0.04079[0m[0m | time: 74.684s
[2K
| Adam | epoch: 030 | loss: 0.04079 - acc: 0.9862 -- iter: 2208/3072
[A[ATraining Step: 2854  | total loss: [1m[32m0.03767[0m[0m | time: 75.702s
[2K
| Adam | epoch: 030 | loss: 0.03767 - acc: 0.9876 -- iter: 2240/3072
[A[ATraining Step: 2855  | total loss: [1m[32m0.03474[0m[0m | time: 76.727s
[2K
| Adam | epoch: 030 | loss: 0.03474 - acc: 0.9889 -- iter: 2272/3072
[A[ATraining Step: 2856  | total loss: [1m[32m0.03153[0m[0m | time: 77.784s
[2K
| Adam | epoch: 030 | loss: 0.03153 - acc: 0.9900 -- iter: 2304/3072
[A[ATraining Step: 2857  | total loss: [1m[32m0.03044[0m[0m | time: 78.689s
[2K
| Adam | epoch: 030 | loss: 0.03044 - acc: 0.9910 -- iter: 2336/3072
[A[ATraining Step: 2858  | total loss: [1m[32m0.04441[0m[0m | time: 79.635s
[2K
| Adam | epoch: 030 | loss: 0.04441 - acc: 0.9887 -- iter: 2368/3072
[A[ATraining Step: 2859  | total loss: [1m[32m0.04144[0m[0m | time: 80.675s
[2K
| Adam | epoch: 030 | loss: 0.04144 - acc: 0.9899 -- iter: 2400/3072
[A[ATraining Step: 2860  | total loss: [1m[32m0.03852[0m[0m | time: 81.697s
[2K
| Adam | epoch: 030 | loss: 0.03852 - acc: 0.9909 -- iter: 2432/3072
[A[ATraining Step: 2861  | total loss: [1m[32m0.03480[0m[0m | time: 82.768s
[2K
| Adam | epoch: 030 | loss: 0.03480 - acc: 0.9918 -- iter: 2464/3072
[A[ATraining Step: 2862  | total loss: [1m[32m0.03611[0m[0m | time: 83.767s
[2K
| Adam | epoch: 030 | loss: 0.03611 - acc: 0.9895 -- iter: 2496/3072
[A[ATraining Step: 2863  | total loss: [1m[32m0.03788[0m[0m | time: 84.728s
[2K
| Adam | epoch: 030 | loss: 0.03788 - acc: 0.9874 -- iter: 2528/3072
[A[ATraining Step: 2864  | total loss: [1m[32m0.03441[0m[0m | time: 85.822s
[2K
| Adam | epoch: 030 | loss: 0.03441 - acc: 0.9887 -- iter: 2560/3072
[A[ATraining Step: 2865  | total loss: [1m[32m0.03198[0m[0m | time: 86.913s
[2K
| Adam | epoch: 030 | loss: 0.03198 - acc: 0.9898 -- iter: 2592/3072
[A[ATraining Step: 2866  | total loss: [1m[32m0.03035[0m[0m | time: 87.776s
[2K
| Adam | epoch: 030 | loss: 0.03035 - acc: 0.9908 -- iter: 2624/3072
[A[ATraining Step: 2867  | total loss: [1m[32m0.02800[0m[0m | time: 88.692s
[2K
| Adam | epoch: 030 | loss: 0.02800 - acc: 0.9917 -- iter: 2656/3072
[A[ATraining Step: 2868  | total loss: [1m[32m0.02558[0m[0m | time: 89.753s
[2K
| Adam | epoch: 030 | loss: 0.02558 - acc: 0.9926 -- iter: 2688/3072
[A[ATraining Step: 2869  | total loss: [1m[32m0.02343[0m[0m | time: 90.734s
[2K
| Adam | epoch: 030 | loss: 0.02343 - acc: 0.9933 -- iter: 2720/3072
[A[ATraining Step: 2870  | total loss: [1m[32m0.02309[0m[0m | time: 91.908s
[2K
| Adam | epoch: 030 | loss: 0.02309 - acc: 0.9940 -- iter: 2752/3072
[A[ATraining Step: 2871  | total loss: [1m[32m0.02120[0m[0m | time: 92.920s
[2K
| Adam | epoch: 030 | loss: 0.02120 - acc: 0.9946 -- iter: 2784/3072
[A[ATraining Step: 2872  | total loss: [1m[32m0.02074[0m[0m | time: 93.928s
[2K
| Adam | epoch: 030 | loss: 0.02074 - acc: 0.9951 -- iter: 2816/3072
[A[ATraining Step: 2873  | total loss: [1m[32m0.03699[0m[0m | time: 95.067s
[2K
| Adam | epoch: 030 | loss: 0.03699 - acc: 0.9925 -- iter: 2848/3072
[A[ATraining Step: 2874  | total loss: [1m[32m0.03366[0m[0m | time: 96.093s
[2K
| Adam | epoch: 030 | loss: 0.03366 - acc: 0.9932 -- iter: 2880/3072
[A[ATraining Step: 2875  | total loss: [1m[32m0.04091[0m[0m | time: 96.934s
[2K
| Adam | epoch: 030 | loss: 0.04091 - acc: 0.9877 -- iter: 2912/3072
[A[ATraining Step: 2876  | total loss: [1m[32m0.03817[0m[0m | time: 97.868s
[2K
| Adam | epoch: 030 | loss: 0.03817 - acc: 0.9889 -- iter: 2944/3072
[A[ATraining Step: 2877  | total loss: [1m[32m0.04445[0m[0m | time: 98.845s
[2K
| Adam | epoch: 030 | loss: 0.04445 - acc: 0.9838 -- iter: 2976/3072
[A[ATraining Step: 2878  | total loss: [1m[32m0.15655[0m[0m | time: 99.807s
[2K
| Adam | epoch: 030 | loss: 0.15655 - acc: 0.9635 -- iter: 3008/3072
[A[ATraining Step: 2879  | total loss: [1m[32m0.14234[0m[0m | time: 100.863s
[2K
| Adam | epoch: 030 | loss: 0.14234 - acc: 0.9672 -- iter: 3040/3072
[A[ATraining Step: 2880  | total loss: [1m[32m0.12897[0m[0m | time: 106.902s
[2K
| Adam | epoch: 030 | loss: 0.12897 - acc: 0.9704 | val_loss: 0.90618 - val_acc: 0.7950 -- iter: 3072/3072
--
2018-08-02 04:34:14.196692: W tensorflow/core/framework/allocator.cc:101] Allocation of 8703554048 exceeds 10% of system memory.
2018-08-02 04:34:17.505723: W tensorflow/core/framework/allocator.cc:101] Allocation of 8703554048 exceeds 10% of system memory.
Validation AUC:0.8615937946873511
Validation AUPRC:0.8581528003016174
Test AUC:0.8808091070126082
Test AUPRC:0.8878784908205817
BestTestF1Score	0.8	0.59	0.8	0.81	0.8	402	94	363	102	0.3
BestTestMCCScore	0.8	0.61	0.8	0.85	0.75	380	68	389	124	0.64
BestTestAccuracyScore	0.8	0.61	0.8	0.85	0.75	380	68	389	124	0.64
BestValidationF1Score	0.8	0.6	0.8	0.79	0.8	378	102	389	92	0.3
BestValidationMCC	0.79	0.61	0.8	0.83	0.76	355	74	417	115	0.64
BestValidationAccuracy	0.79	0.61	0.8	0.83	0.76	355	74	417	115	0.64
TestPredictions (Threshold:0.64)
CHEMBL55592,TN,INACT,0.009999999776482582	CHEMBL99637,TP,ACT,1.0	CHEMBL519590,FP,INACT,0.9900000095367432	CHEMBL320382,TP,ACT,1.0	CHEMBL502543,FP,INACT,0.9100000262260437	CHEMBL1241439,FN,ACT,0.009999999776482582	CHEMBL413526,TP,ACT,1.0	CHEMBL1829271,TN,INACT,0.0	CHEMBL378600,TN,INACT,0.009999999776482582	CHEMBL324399,FP,INACT,1.0	CHEMBL1642280,TN,INACT,0.05999999865889549	CHEMBL3128232,TN,INACT,0.009999999776482582	CHEMBL1916949,TN,INACT,0.0	CHEMBL1287914,TN,INACT,0.0	CHEMBL45477,TN,INACT,0.019999999552965164	CHEMBL3115324,TN,INACT,0.05000000074505806	CHEMBL117114,FP,INACT,1.0	CHEMBL3648041,TP,ACT,0.9900000095367432	CHEMBL511670,FN,ACT,0.019999999552965164	CHEMBL1242293,TP,ACT,0.9900000095367432	CHEMBL1790805,TN,INACT,0.0	CHEMBL71884,TN,INACT,0.20000000298023224	CHEMBL308438,TP,ACT,0.75	CHEMBL3799332,TN,INACT,0.0	CHEMBL59850,TP,ACT,1.0	CHEMBL507056,TN,INACT,0.009999999776482582	CHEMBL3426220,TP,ACT,0.9900000095367432	CHEMBL1170748,TN,INACT,0.2800000011920929	CHEMBL2397803,TP,ACT,1.0	CHEMBL1090975,TP,ACT,1.0	CHEMBL92812,TN,INACT,0.009999999776482582	CHEMBL3648055,TP,ACT,1.0	CHEMBL1734241,TN,INACT,0.0	CHEMBL568789,TN,INACT,0.009999999776482582	CHEMBL499120,FN,ACT,0.3799999952316284	CHEMBL337027,TP,ACT,0.8399999737739563	CHEMBL100446,TN,INACT,0.0	CHEMBL333231,FN,ACT,0.019999999552965164	CHEMBL56109,TP,ACT,0.9900000095367432	CHEMBL99699,TN,INACT,0.029999999329447746	CHEMBL1650736,FP,INACT,0.7200000286102295	CHEMBL231251,TP,ACT,1.0	CHEMBL1242847,TP,ACT,1.0	CHEMBL1077095,TN,INACT,0.0	CHEMBL272888,TP,ACT,1.0	CHEMBL353901,TP,ACT,0.9800000190734863	CHEMBL590083,TN,INACT,0.0	CHEMBL1084411,FN,ACT,0.019999999552965164	CHEMBL358866,TP,ACT,1.0	CHEMBL1828883,TN,INACT,0.0	CHEMBL2029518,TN,INACT,0.0	CHEMBL1599242,TN,INACT,0.0	CHEMBL2425140,TN,INACT,0.0	CHEMBL484950,TP,ACT,0.9100000262260437	CHEMBL43577,TP,ACT,1.0	CHEMBL1643146,TN,INACT,0.1899999976158142	CHEMBL2179821,FP,INACT,1.0	CHEMBL2391132,TN,INACT,0.0	CHEMBL3658032,TN,INACT,0.46000000834465027	CHEMBL2152969,FP,INACT,0.8500000238418579	CHEMBL1241775,FP,INACT,1.0	CHEMBL67878,TP,ACT,1.0	CHEMBL401447,TP,ACT,1.0	CHEMBL258015,TP,ACT,1.0	CHEMBL3665657,FP,INACT,0.8999999761581421	CHEMBL67747,TN,INACT,0.0	CHEMBL105436,TP,ACT,1.0	CHEMBL387385,TP,ACT,1.0	CHEMBL131098,TN,INACT,0.0	CHEMBL291546,TN,INACT,0.0	CHEMBL104779,TP,ACT,1.0	CHEMBL130109,TN,INACT,0.009999999776482582	CHEMBL3262565,TN,INACT,0.0	CHEMBL301845,TN,INACT,0.0	CHEMBL2011304,FN,ACT,0.009999999776482582	CHEMBL142141,TN,INACT,0.30000001192092896	CHEMBL1172459,FP,INACT,0.6899999976158142	CHEMBL3651289,FN,ACT,0.0	CHEMBL2370323,TN,INACT,0.009999999776482582	CHEMBL2397805,TP,ACT,1.0	CHEMBL1094167,TN,INACT,0.009999999776482582	CHEMBL383316,FN,ACT,0.009999999776482582	CHEMBL55979,TN,INACT,0.0	CHEMBL313433,TN,INACT,0.0	CHEMBL1950043,TN,INACT,0.0	CHEMBL101917,TP,ACT,1.0	CHEMBL40913,TP,ACT,1.0	CHEMBL202863,TN,INACT,0.07000000029802322	CHEMBL42136,TP,ACT,1.0	CHEMBL91748,TN,INACT,0.019999999552965164	CHEMBL589413,TN,INACT,0.009999999776482582	CHEMBL1643460,TN,INACT,0.0	CHEMBL2086760,TP,ACT,0.9900000095367432	CHEMBL162157,TN,INACT,0.0	CHEMBL370473,TP,ACT,1.0	CHEMBL407516,TP,ACT,1.0	CHEMBL1076471,TP,ACT,1.0	CHEMBL291759,TP,ACT,0.8600000143051147	CHEMBL3353407,TN,INACT,0.009999999776482582	CHEMBL428067,TN,INACT,0.009999999776482582	CHEMBL1910373,TN,INACT,0.0	CHEMBL2070058,TP,ACT,0.8700000047683716	CHEMBL473727,TP,ACT,1.0	CHEMBL198946,FN,ACT,0.07000000029802322	CHEMBL3392166,FN,ACT,0.30000001192092896	CHEMBL122182,TP,ACT,1.0	CHEMBL67237,FN,ACT,0.0	CHEMBL3651231,TP,ACT,1.0	CHEMBL2382015,FP,INACT,0.9100000262260437	CHEMBL484274,TN,INACT,0.0	CHEMBL1683298,TN,INACT,0.0	CHEMBL1791360,FP,INACT,0.9700000286102295	CHEMBL370371,TP,ACT,0.9700000286102295	CHEMBL1161235,TN,INACT,0.0	CHEMBL2069957,TP,ACT,1.0	CHEMBL3219018,TN,INACT,0.0	CHEMBL416439,TP,ACT,1.0	CHEMBL120719,TN,INACT,0.0	CHEMBL1242663,FN,ACT,0.029999999329447746	CHEMBL128158,TP,ACT,1.0	CHEMBL2151192,TN,INACT,0.0	CHEMBL128568,TN,INACT,0.0	CHEMBL236384,TN,INACT,0.0	CHEMBL3764798,FP,INACT,0.8299999833106995	CHEMBL333038,FN,ACT,0.27000001072883606	CHEMBL498248,TN,INACT,0.33000001311302185	CHEMBL51283,TP,ACT,0.949999988079071	CHEMBL1762110,TP,ACT,0.9599999785423279	CHEMBL81073,TP,ACT,1.0	CHEMBL551545,TN,INACT,0.0	CHEMBL53463,FP,INACT,1.0	CHEMBL378603,TP,ACT,0.9800000190734863	CHEMBL213525,TN,INACT,0.0	CHEMBL1821883,TN,INACT,0.0	CHEMBL78393,FN,ACT,0.2800000011920929	CHEMBL169202,TP,ACT,1.0	CHEMBL3622957,TN,INACT,0.0	CHEMBL173453,FN,ACT,0.38999998569488525	CHEMBL3401987,FN,ACT,0.009999999776482582	CHEMBL359482,TP,ACT,1.0	CHEMBL1784649,TN,INACT,0.41999998688697815	CHEMBL2408777,FN,ACT,0.0	CHEMBL1933802,FP,INACT,0.9599999785423279	CHEMBL473154,FN,ACT,0.0	CHEMBL484907,TP,ACT,0.9399999976158142	CHEMBL3629604,TN,INACT,0.0	CHEMBL496494,TP,ACT,0.9599999785423279	CHEMBL1088681,TP,ACT,0.9399999976158142	CHEMBL3617733,FN,ACT,0.0	CHEMBL488671,TN,INACT,0.0	CHEMBL3658115,TP,ACT,0.9800000190734863	CHEMBL316485,TN,INACT,0.0	CHEMBL197713,TP,ACT,1.0	CHEMBL357488,TP,ACT,1.0	CHEMBL3651226,TP,ACT,0.9100000262260437	CHEMBL1173484,TP,ACT,1.0	CHEMBL2064515,TN,INACT,0.0	CHEMBL213745,TP,ACT,1.0	CHEMBL236691,TN,INACT,0.0	CHEMBL2348167,TN,INACT,0.0	CHEMBL1968515,TN,INACT,0.0	CHEMBL1088680,TP,ACT,1.0	CHEMBL69240,TP,ACT,0.9300000071525574	CHEMBL3617731,TP,ACT,0.9900000095367432	CHEMBL3628360,TN,INACT,0.0	CHEMBL24453,FN,ACT,0.3100000023841858	CHEMBL2088259,TN,INACT,0.0	CHEMBL2205467,TN,INACT,0.0	CHEMBL1097368,TN,INACT,0.009999999776482582	CHEMBL3661094,TN,INACT,0.23999999463558197	CHEMBL3822591,TP,ACT,1.0	CHEMBL3310054,FN,ACT,0.11999999731779099	CHEMBL299083,TN,INACT,0.0	CHEMBL131725,TP,ACT,1.0	CHEMBL1242112,TP,ACT,1.0	CHEMBL47940,TP,ACT,1.0	CHEMBL571040,FN,ACT,0.029999999329447746	CHEMBL3639713,FP,INACT,0.949999988079071	CHEMBL477817,TP,ACT,0.9900000095367432	CHEMBL3393985,FN,ACT,0.0	CHEMBL481969,FN,ACT,0.019999999552965164	CHEMBL499145,TN,INACT,0.07999999821186066	CHEMBL172973,TP,ACT,1.0	CHEMBL373834,FP,INACT,0.8799999952316284	CHEMBL454868,FN,ACT,0.27000001072883606	CHEMBL2059876,FP,INACT,0.75	CHEMBL194815,TP,ACT,0.9900000095367432	CHEMBL1775038,FN,ACT,0.3499999940395355	CHEMBL1242115,FN,ACT,0.12999999523162842	CHEMBL2392227,TN,INACT,0.0	CHEMBL337451,FP,INACT,1.0	CHEMBL484312,TP,ACT,0.8999999761581421	CHEMBL1233881,TP,ACT,1.0	CHEMBL308734,TP,ACT,1.0	CHEMBL366734,TN,INACT,0.029999999329447746	CHEMBL75188,FN,ACT,0.44999998807907104	CHEMBL410251,TP,ACT,1.0	CHEMBL2347053,FN,ACT,0.019999999552965164	CHEMBL171423,TP,ACT,1.0	CHEMBL516231,FP,INACT,0.6700000166893005	CHEMBL1765558,TP,ACT,1.0	CHEMBL1945644,TN,INACT,0.0	CHEMBL155607,FN,ACT,0.0	CHEMBL438075,FP,INACT,1.0	CHEMBL78794,TN,INACT,0.0	CHEMBL84807,TP,ACT,0.9800000190734863	CHEMBL3651268,TP,ACT,1.0	CHEMBL1242660,TP,ACT,1.0	CHEMBL86531,TP,ACT,1.0	CHEMBL300853,TP,ACT,0.9300000071525574	CHEMBL2047059,TN,INACT,0.0	CHEMBL1627260,TN,INACT,0.05999999865889549	CHEMBL214893,TP,ACT,1.0	CHEMBL566174,TP,ACT,1.0	CHEMBL1242290,TP,ACT,1.0	CHEMBL169780,TP,ACT,0.9900000095367432	CHEMBL3261188,TN,INACT,0.0	CHEMBL1082940,FP,INACT,0.7599999904632568	CHEMBL1242031,TP,ACT,0.9900000095367432	CHEMBL265448,TN,INACT,0.0	CHEMBL431996,TP,ACT,1.0	CHEMBL3823104,TP,ACT,1.0	CHEMBL69599,TP,ACT,1.0	CHEMBL1682354,TN,INACT,0.0	CHEMBL2029520,TN,INACT,0.0	CHEMBL180299,FN,ACT,0.0	CHEMBL472037,TP,ACT,0.9599999785423279	CHEMBL1241864,FP,INACT,1.0	CHEMBL202831,FP,INACT,0.8500000238418579	CHEMBL603463,TN,INACT,0.0	CHEMBL1788116,FN,ACT,0.1599999964237213	CHEMBL539739,TP,ACT,0.9800000190734863	CHEMBL3651227,TP,ACT,1.0	CHEMBL3421978,FP,INACT,0.8700000047683716	CHEMBL3394085,TP,ACT,1.0	CHEMBL314021,TN,INACT,0.0	CHEMBL1241858,TP,ACT,0.9900000095367432	CHEMBL2064379,TN,INACT,0.6399999856948853	CHEMBL487737,TN,INACT,0.0	CHEMBL1933801,FP,INACT,0.9200000166893005	CHEMBL296185,TP,ACT,1.0	CHEMBL514140,FN,ACT,0.05000000074505806	CHEMBL2047241,TN,INACT,0.0	CHEMBL2059869,TN,INACT,0.029999999329447746	CHEMBL406845,TP,ACT,1.0	CHEMBL2069625,TN,INACT,0.0	CHEMBL130529,TP,ACT,1.0	CHEMBL1922123,TN,INACT,0.0	CHEMBL109525,FP,INACT,0.8700000047683716	CHEMBL1241772,TN,INACT,0.4699999988079071	CHEMBL193966,TN,INACT,0.0	CHEMBL1241943,FN,ACT,0.23000000417232513	CHEMBL120127,TN,INACT,0.0	CHEMBL69827,TP,ACT,1.0	CHEMBL1076198,TP,ACT,1.0	CHEMBL1084028,TP,ACT,0.7400000095367432	CHEMBL78455,TP,ACT,1.0	CHEMBL2437296,TP,ACT,0.8999999761581421	CHEMBL514511,FP,INACT,0.9900000095367432	CHEMBL3347466,TP,ACT,0.9900000095367432	CHEMBL77030,TN,INACT,0.0	CHEMBL113690,TN,INACT,0.05999999865889549	CHEMBL129459,TP,ACT,1.0	CHEMBL220444,TN,INACT,0.009999999776482582	CHEMBL194352,TP,ACT,1.0	CHEMBL3736006,TN,INACT,0.019999999552965164	CHEMBL1765557,TP,ACT,0.9700000286102295	CHEMBL412298,TP,ACT,1.0	CHEMBL169725,TP,ACT,0.8700000047683716	CHEMBL49350,TN,INACT,0.0	CHEMBL3651266,TP,ACT,1.0	CHEMBL100811,TN,INACT,0.0	CHEMBL1242755,TP,ACT,1.0	CHEMBL387641,TP,ACT,1.0	CHEMBL488840,TP,ACT,0.9599999785423279	CHEMBL59099,FN,ACT,0.07000000029802322	CHEMBL590023,TN,INACT,0.0	CHEMBL1242113,FN,ACT,0.029999999329447746	CHEMBL198701,TP,ACT,1.0	CHEMBL407817,TN,INACT,0.0	CHEMBL1950040,TN,INACT,0.029999999329447746	CHEMBL436943,FP,INACT,1.0	CHEMBL2336578,TN,INACT,0.0	CHEMBL477560,FN,ACT,0.0	CHEMBL216646,TN,INACT,0.0	CHEMBL559069,TN,INACT,0.41999998688697815	CHEMBL106992,TP,ACT,1.0	CHEMBL227859,TP,ACT,0.9800000190734863	CHEMBL2312645,FP,INACT,0.9800000190734863	CHEMBL349065,FN,ACT,0.23999999463558197	CHEMBL446317,TN,INACT,0.009999999776482582	CHEMBL2407913,TN,INACT,0.009999999776482582	CHEMBL1627243,TN,INACT,0.0	CHEMBL1821888,TN,INACT,0.0	CHEMBL1627106,TN,INACT,0.0	CHEMBL2381609,TN,INACT,0.0	CHEMBL3695586,FN,ACT,0.12999999523162842	CHEMBL1172418,TN,INACT,0.0	CHEMBL77085,TN,INACT,0.10999999940395355	CHEMBL3426225,TP,ACT,1.0	CHEMBL79328,TN,INACT,0.0	CHEMBL3098313,TN,INACT,0.0	CHEMBL88771,FN,ACT,0.4399999976158142	CHEMBL1085061,TP,ACT,0.9900000095367432	CHEMBL1683951,TN,INACT,0.17000000178813934	CHEMBL203922,FN,ACT,0.07999999821186066	CHEMBL150,TN,INACT,0.0	CHEMBL352619,TP,ACT,0.8799999952316284	CHEMBL349322,TP,ACT,1.0	CHEMBL2392233,TN,INACT,0.0	CHEMBL3695570,TP,ACT,1.0	CHEMBL3648046,TP,ACT,1.0	CHEMBL589630,FN,ACT,0.5	CHEMBL236375,TP,ACT,1.0	CHEMBL591457,TN,INACT,0.0	CHEMBL340177,TP,ACT,0.8500000238418579	CHEMBL309682,TP,ACT,0.7099999785423279	CHEMBL3108912,FN,ACT,0.009999999776482582	CHEMBL3706656,TN,INACT,0.0	CHEMBL3658102,FN,ACT,0.009999999776482582	CHEMBL1650113,FP,INACT,0.9700000286102295	CHEMBL3262567,TN,INACT,0.0	CHEMBL497754,FN,ACT,0.019999999552965164	CHEMBL420952,FN,ACT,0.05999999865889549	CHEMBL450622,FP,INACT,1.0	CHEMBL1642266,TN,INACT,0.009999999776482582	CHEMBL80192,TN,INACT,0.009999999776482582	CHEMBL1095445,TN,INACT,0.0	CHEMBL564449,TP,ACT,0.9900000095367432	CHEMBL293500,TN,INACT,0.05999999865889549	CHEMBL347256,FN,ACT,0.029999999329447746	CHEMBL1230609,FN,ACT,0.23999999463558197	CHEMBL2408780,TP,ACT,0.9900000095367432	CHEMBL255164,FN,ACT,0.0	CHEMBL1241946,TP,ACT,1.0	CHEMBL399203,TN,INACT,0.009999999776482582	CHEMBL499864,TN,INACT,0.0	CHEMBL3651239,FN,ACT,0.6000000238418579	CHEMBL399914,TN,INACT,0.6200000047683716	CHEMBL2348958,TN,INACT,0.0	CHEMBL629,TN,INACT,0.0	CHEMBL3318025,TN,INACT,0.0	CHEMBL410119,TP,ACT,1.0	CHEMBL387093,TP,ACT,0.8600000143051147	CHEMBL54372,TN,INACT,0.14000000059604645	CHEMBL3651265,TP,ACT,0.9300000071525574	CHEMBL226813,TN,INACT,0.0	CHEMBL80915,TN,INACT,0.0	CHEMBL410295,TP,ACT,1.0	CHEMBL233373,TN,INACT,0.0	CHEMBL3651236,TP,ACT,0.9800000190734863	CHEMBL377654,TN,INACT,0.0	CHEMBL136289,TP,ACT,1.0	CHEMBL460003,TN,INACT,0.0	CHEMBL1760505,TN,INACT,0.0	CHEMBL434578,TP,ACT,1.0	CHEMBL472959,FN,ACT,0.07999999821186066	CHEMBL294466,TP,ACT,1.0	CHEMBL3648030,TP,ACT,1.0	CHEMBL1796187,TN,INACT,0.0	CHEMBL560245,FP,INACT,0.9900000095367432	CHEMBL3623850,TN,INACT,0.0	CHEMBL3706664,TP,ACT,0.9200000166893005	CHEMBL1791356,TP,ACT,0.949999988079071	CHEMBL496713,FN,ACT,0.3499999940395355	CHEMBL3347601,TP,ACT,1.0	CHEMBL1908396,TP,ACT,0.8799999952316284	CHEMBL457077,FP,INACT,0.8799999952316284	CHEMBL3261189,TN,INACT,0.0	CHEMBL158275,TP,ACT,1.0	CHEMBL3680499,TN,INACT,0.10999999940395355	CHEMBL2048912,FN,ACT,0.0	CHEMBL56359,FN,ACT,0.029999999329447746	CHEMBL1240545,TP,ACT,0.8700000047683716	CHEMBL2325100,TN,INACT,0.0	CHEMBL1241485,TP,ACT,1.0	CHEMBL3658088,TP,ACT,0.9900000095367432	CHEMBL189197,TN,INACT,0.0	CHEMBL334026,FP,INACT,0.9900000095367432	CHEMBL1775034,FN,ACT,0.0	CHEMBL56504,TP,ACT,1.0	CHEMBL3658086,TP,ACT,1.0	CHEMBL570175,TP,ACT,1.0	CHEMBL467321,TN,INACT,0.009999999776482582	CHEMBL1170124,TN,INACT,0.0	CHEMBL1830265,TN,INACT,0.0	CHEMBL505610,TN,INACT,0.4300000071525574	CHEMBL190201,TN,INACT,0.0	CHEMBL263947,TP,ACT,0.9399999976158142	CHEMBL3397287,TN,INACT,0.009999999776482582	CHEMBL3086109,TN,INACT,0.6100000143051147	CHEMBL523586,TN,INACT,0.0	CHEMBL518732,TN,INACT,0.009999999776482582	CHEMBL324371,TN,INACT,0.0	CHEMBL3401984,TP,ACT,0.9599999785423279	CHEMBL45683,FN,ACT,0.6000000238418579	CHEMBL515714,TP,ACT,0.9100000262260437	CHEMBL222548,TP,ACT,0.7200000286102295	CHEMBL118200,FP,INACT,0.9700000286102295	CHEMBL230508,TP,ACT,0.7699999809265137	CHEMBL421025,TP,ACT,1.0	CHEMBL1790806,FN,ACT,0.3100000023841858	CHEMBL166765,TP,ACT,1.0	CHEMBL543600,TN,INACT,0.0	CHEMBL214894,TP,ACT,1.0	CHEMBL3237851,TN,INACT,0.0	CHEMBL274532,TP,ACT,1.0	CHEMBL300830,TP,ACT,1.0	CHEMBL1775045,TP,ACT,1.0	CHEMBL451544,TN,INACT,0.0	CHEMBL22978,TN,INACT,0.5199999809265137	CHEMBL2036010,FN,ACT,0.009999999776482582	CHEMBL66278,TN,INACT,0.23000000417232513	CHEMBL304361,TP,ACT,1.0	CHEMBL1762181,TN,INACT,0.0	CHEMBL352977,TP,ACT,1.0	CHEMBL450367,TN,INACT,0.0	CHEMBL2047245,TN,INACT,0.07999999821186066	CHEMBL2216906,TN,INACT,0.5899999737739563	CHEMBL2064381,TN,INACT,0.05999999865889549	CHEMBL2070057,FN,ACT,0.23999999463558197	CHEMBL59487,TP,ACT,1.0	CHEMBL517956,TP,ACT,0.9800000190734863	CHEMBL69237,TP,ACT,0.9100000262260437	CHEMBL482489,TN,INACT,0.0	CHEMBL293803,TP,ACT,1.0	CHEMBL406504,FN,ACT,0.0	CHEMBL261143,TN,INACT,0.23999999463558197	CHEMBL339856,TN,INACT,0.0	CHEMBL2163610,TN,INACT,0.07000000029802322	CHEMBL69129,TP,ACT,0.9900000095367432	CHEMBL2441273,TP,ACT,0.9100000262260437	CHEMBL499587,TN,INACT,0.5199999809265137	CHEMBL55993,TN,INACT,0.0	CHEMBL408244,TN,INACT,0.0	CHEMBL3261190,TN,INACT,0.0	CHEMBL2179826,FP,INACT,1.0	CHEMBL328452,TN,INACT,0.0	CHEMBL452563,FN,ACT,0.28999999165534973	CHEMBL390479,TP,ACT,1.0	CHEMBL1688214,TN,INACT,0.0	CHEMBL313578,TN,INACT,0.0	CHEMBL3115492,TN,INACT,0.0	CHEMBL564575,TN,INACT,0.0	CHEMBL322640,TN,INACT,0.0	CHEMBL518185,TN,INACT,0.0	CHEMBL309625,TN,INACT,0.0	CHEMBL397022,FN,ACT,0.3100000023841858	CHEMBL1945450,TN,INACT,0.0	CHEMBL1791364,TN,INACT,0.0	CHEMBL84945,TP,ACT,1.0	CHEMBL589120,TN,INACT,0.2800000011920929	CHEMBL606245,FN,ACT,0.0	CHEMBL310313,FP,INACT,0.9900000095367432	CHEMBL277430,FP,INACT,0.9800000190734863	CHEMBL102000,TP,ACT,0.9700000286102295	CHEMBL1765784,TP,ACT,0.9900000095367432	CHEMBL1082693,FN,ACT,0.15000000596046448	CHEMBL411163,FP,INACT,0.9900000095367432	CHEMBL2178352,TP,ACT,1.0	CHEMBL55496,TP,ACT,1.0	CHEMBL3326756,TN,INACT,0.23000000417232513	CHEMBL2337364,TN,INACT,0.0	CHEMBL58224,FN,ACT,0.11999999731779099	CHEMBL365398,TP,ACT,1.0	CHEMBL2407915,TN,INACT,0.0	CHEMBL2070086,TP,ACT,1.0	CHEMBL1241580,TP,ACT,1.0	CHEMBL281492,TP,ACT,0.9399999976158142	CHEMBL355891,TP,ACT,1.0	CHEMBL3360681,TN,INACT,0.019999999552965164	CHEMBL2409594,TN,INACT,0.0	CHEMBL2425111,TN,INACT,0.0	CHEMBL2047244,TN,INACT,0.0	CHEMBL271010,TP,ACT,0.949999988079071	CHEMBL3133906,TN,INACT,0.0	CHEMBL321116,TP,ACT,1.0	CHEMBL3261194,TN,INACT,0.0	CHEMBL57393,TP,ACT,0.8500000238418579	CHEMBL56081,TN,INACT,0.0	CHEMBL3360318,TN,INACT,0.5099999904632568	CHEMBL1173398,TN,INACT,0.0	CHEMBL87325,TN,INACT,0.3100000023841858	CHEMBL49120,FN,ACT,0.019999999552965164	CHEMBL1765097,TP,ACT,0.9900000095367432	CHEMBL319179,TN,INACT,0.009999999776482582	CHEMBL421405,FN,ACT,0.009999999776482582	CHEMBL2036725,TN,INACT,0.0	CHEMBL3393986,FN,ACT,0.0	CHEMBL3262566,TN,INACT,0.0	CHEMBL1240565,TP,ACT,1.0	CHEMBL1077069,TN,INACT,0.029999999329447746	CHEMBL1080956,TN,INACT,0.0	CHEMBL168146,TP,ACT,1.0	CHEMBL212987,FP,INACT,1.0	CHEMBL434105,TP,ACT,1.0	CHEMBL598727,TN,INACT,0.0	CHEMBL103464,TN,INACT,0.0	CHEMBL3695572,TP,ACT,1.0	CHEMBL3263640,TP,ACT,0.7300000190734863	CHEMBL1241270,FN,ACT,0.0	CHEMBL217090,FP,INACT,1.0	CHEMBL133511,TN,INACT,0.0	CHEMBL1172709,TP,ACT,1.0	CHEMBL3623844,TN,INACT,0.0	CHEMBL3651278,TP,ACT,1.0	CHEMBL1765783,TP,ACT,1.0	CHEMBL230898,TP,ACT,1.0	CHEMBL391724,FP,INACT,1.0	CHEMBL88466,TN,INACT,0.15000000596046448	CHEMBL2177670,TN,INACT,0.0	CHEMBL2111833,TP,ACT,1.0	CHEMBL427544,TP,ACT,1.0	CHEMBL408137,TP,ACT,1.0	CHEMBL3335244,TN,INACT,0.0	CHEMBL2036013,FN,ACT,0.0	CHEMBL312148,TP,ACT,0.9599999785423279	CHEMBL418693,TP,ACT,1.0	CHEMBL1221633,TN,INACT,0.0	CHEMBL1240683,TN,INACT,0.0	CHEMBL2036007,TP,ACT,0.8600000143051147	CHEMBL1242380,TP,ACT,1.0	CHEMBL342929,TP,ACT,0.7300000190734863	CHEMBL379431,TP,ACT,0.9800000190734863	CHEMBL285441,TP,ACT,1.0	CHEMBL496916,TP,ACT,0.7599999904632568	CHEMBL566850,TP,ACT,0.9800000190734863	CHEMBL605161,TN,INACT,0.0	CHEMBL2059862,TN,INACT,0.0	CHEMBL1173789,TN,INACT,0.0	CHEMBL347854,FN,ACT,0.029999999329447746	CHEMBL116423,TN,INACT,0.0	CHEMBL1000,TN,INACT,0.0	CHEMBL1079904,FP,INACT,0.6499999761581421	CHEMBL3657211,TN,INACT,0.17000000178813934	CHEMBL57690,TN,INACT,0.05000000074505806	CHEMBL1097743,TN,INACT,0.0	CHEMBL2312652,TN,INACT,0.27000001072883606	CHEMBL1076199,TP,ACT,0.8999999761581421	CHEMBL3326144,FP,INACT,0.7900000214576721	CHEMBL261827,TP,ACT,1.0	CHEMBL563387,TN,INACT,0.14000000059604645	CHEMBL1956896,TN,INACT,0.0	CHEMBL3393983,TP,ACT,1.0	CHEMBL1784660,TN,INACT,0.0	CHEMBL3658098,TP,ACT,1.0	CHEMBL207071,TN,INACT,0.0	CHEMBL472822,TP,ACT,0.9599999785423279	CHEMBL2322988,TN,INACT,0.0	CHEMBL1808239,TN,INACT,0.0	CHEMBL3335234,TN,INACT,0.0	CHEMBL1644619,TN,INACT,0.0	CHEMBL3824228,TP,ACT,1.0	CHEMBL1956892,TN,INACT,0.009999999776482582	CHEMBL422531,TP,ACT,1.0	CHEMBL1242198,TP,ACT,0.9900000095367432	CHEMBL106295,TP,ACT,1.0	CHEMBL238304,TP,ACT,1.0	CHEMBL1236798,TN,INACT,0.0	CHEMBL470732,TP,ACT,1.0	CHEMBL210766,TP,ACT,0.9100000262260437	CHEMBL220931,TP,ACT,1.0	CHEMBL329244,TP,ACT,1.0	CHEMBL2408779,TP,ACT,1.0	CHEMBL3341793,TN,INACT,0.0	CHEMBL407279,TP,ACT,1.0	CHEMBL2425110,TN,INACT,0.0	CHEMBL3665661,FP,INACT,1.0	CHEMBL213100,TP,ACT,1.0	CHEMBL352829,TP,ACT,1.0	CHEMBL564941,TP,ACT,0.8700000047683716	CHEMBL255738,TP,ACT,0.9900000095367432	CHEMBL1765781,TP,ACT,0.9900000095367432	CHEMBL367442,TP,ACT,0.9900000095367432	CHEMBL2029514,TN,INACT,0.0	CHEMBL1765549,FN,ACT,0.0	CHEMBL3361128,TN,INACT,0.0	CHEMBL245800,TP,ACT,1.0	CHEMBL301741,TN,INACT,0.0	CHEMBL322689,TP,ACT,0.949999988079071	CHEMBL346770,FN,ACT,0.0	CHEMBL513336,TN,INACT,0.0	CHEMBL402355,FP,INACT,0.9399999976158142	CHEMBL3426221,TP,ACT,1.0	CHEMBL210036,FN,ACT,0.10999999940395355	CHEMBL1684376,FP,INACT,0.7200000286102295	CHEMBL304471,TP,ACT,1.0	CHEMBL2392242,TN,INACT,0.0	CHEMBL2064400,TN,INACT,0.0	CHEMBL513563,TP,ACT,1.0	CHEMBL313821,TP,ACT,1.0	CHEMBL1214135,TP,ACT,1.0	CHEMBL407087,TP,ACT,1.0	CHEMBL194664,TP,ACT,1.0	CHEMBL488659,TP,ACT,0.9900000095367432	CHEMBL1078238,TN,INACT,0.0	CHEMBL1221600,TN,INACT,0.0	CHEMBL519948,TN,INACT,0.0	CHEMBL1910754,TN,INACT,0.0	CHEMBL488506,TN,INACT,0.0	CHEMBL2112638,FP,INACT,1.0	CHEMBL511811,FN,ACT,0.2199999988079071	CHEMBL427325,TN,INACT,0.05000000074505806	CHEMBL1254224,TN,INACT,0.0	CHEMBL3586447,FN,ACT,0.0	CHEMBL226471,TN,INACT,0.0	CHEMBL427741,TP,ACT,1.0	CHEMBL2179829,TN,INACT,0.07999999821186066	CHEMBL274654,TN,INACT,0.0	CHEMBL230685,TP,ACT,1.0	CHEMBL553719,TN,INACT,0.0	CHEMBL2163624,TN,INACT,0.0	CHEMBL214035,TP,ACT,1.0	CHEMBL458248,TN,INACT,0.0	CHEMBL3799345,TN,INACT,0.0	CHEMBL47787,TP,ACT,1.0	CHEMBL100651,TP,ACT,1.0	CHEMBL555797,TN,INACT,0.0	CHEMBL243985,TN,INACT,0.18000000715255737	CHEMBL1775040,TP,ACT,0.7200000286102295	CHEMBL1094475,TN,INACT,0.0	CHEMBL270777,FN,ACT,0.029999999329447746	CHEMBL3706663,TP,ACT,0.9300000071525574	CHEMBL1081090,TP,ACT,1.0	CHEMBL71,TN,INACT,0.0	CHEMBL75049,TN,INACT,0.0	CHEMBL592224,TN,INACT,0.009999999776482582	CHEMBL90002,TP,ACT,1.0	CHEMBL509161,FN,ACT,0.0	CHEMBL3651213,FN,ACT,0.5	CHEMBL3651286,TP,ACT,1.0	CHEMBL132963,TN,INACT,0.0	CHEMBL353070,TP,ACT,1.0	CHEMBL2092742,TP,ACT,1.0	CHEMBL56964,TN,INACT,0.05999999865889549	CHEMBL272233,TP,ACT,1.0	CHEMBL423330,TN,INACT,0.0	CHEMBL3651282,TP,ACT,0.9900000095367432	CHEMBL3120959,TN,INACT,0.0	CHEMBL2069940,TP,ACT,1.0	CHEMBL565372,TP,ACT,0.8999999761581421	CHEMBL340944,TP,ACT,1.0	CHEMBL1933734,TN,INACT,0.0	CHEMBL1083092,FN,ACT,0.46000000834465027	CHEMBL24811,TN,INACT,0.0	CHEMBL353630,TP,ACT,1.0	CHEMBL3651196,TP,ACT,0.7799999713897705	CHEMBL199865,TN,INACT,0.0	CHEMBL1241950,TP,ACT,1.0	CHEMBL386584,FN,ACT,0.28999999165534973	CHEMBL1080114,TN,INACT,0.029999999329447746	CHEMBL375012,TP,ACT,0.9900000095367432	CHEMBL78698,TN,INACT,0.009999999776482582	CHEMBL236487,TN,INACT,0.0	CHEMBL474046,TN,INACT,0.0	CHEMBL473533,TN,INACT,0.0	CHEMBL235758,TP,ACT,0.6600000262260437	CHEMBL1254309,TN,INACT,0.0	CHEMBL3695580,TP,ACT,1.0	CHEMBL196889,TP,ACT,1.0	CHEMBL295601,TP,ACT,1.0	CHEMBL280074,TN,INACT,0.0	CHEMBL67293,TP,ACT,1.0	CHEMBL485320,TN,INACT,0.0	CHEMBL3651203,TP,ACT,1.0	CHEMBL376993,TP,ACT,0.75	CHEMBL1172419,TN,INACT,0.019999999552965164	CHEMBL138209,TN,INACT,0.0	CHEMBL475008,TP,ACT,1.0	CHEMBL514928,FN,ACT,0.3799999952316284	CHEMBL227376,FN,ACT,0.0	CHEMBL172574,TP,ACT,1.0	CHEMBL1790807,FN,ACT,0.09000000357627869	CHEMBL3604910,FN,ACT,0.019999999552965164	CHEMBL1828876,TN,INACT,0.0	CHEMBL78444,TN,INACT,0.0	CHEMBL129842,TN,INACT,0.0	CHEMBL2397811,TP,ACT,1.0	CHEMBL526321,TP,ACT,1.0	CHEMBL3335229,TN,INACT,0.0	CHEMBL516644,TN,INACT,0.25999999046325684	CHEMBL2029691,TN,INACT,0.0	CHEMBL150573,TN,INACT,0.0	CHEMBL574059,TP,ACT,1.0	CHEMBL296103,TP,ACT,0.9599999785423279	CHEMBL542887,TN,INACT,0.009999999776482582	CHEMBL2323556,TN,INACT,0.0	CHEMBL98350,TN,INACT,0.0	CHEMBL1908395,TP,ACT,0.9300000071525574	CHEMBL432359,TP,ACT,1.0	CHEMBL1916897,TP,ACT,0.9700000286102295	CHEMBL2437477,FP,INACT,1.0	CHEMBL1087216,TP,ACT,1.0	CHEMBL3651295,TP,ACT,1.0	CHEMBL404595,TP,ACT,0.9700000286102295	CHEMBL460746,FN,ACT,0.0	CHEMBL2420909,TN,INACT,0.0	CHEMBL410296,TP,ACT,1.0	CHEMBL195029,TP,ACT,1.0	CHEMBL306146,TN,INACT,0.0	CHEMBL592240,TN,INACT,0.0	CHEMBL169231,TP,ACT,1.0	CHEMBL248044,FN,ACT,0.10999999940395355	CHEMBL336958,TN,INACT,0.029999999329447746	CHEMBL286160,TN,INACT,0.6100000143051147	CHEMBL1765777,TP,ACT,1.0	CHEMBL607581,FP,INACT,0.8999999761581421	CHEMBL104304,TP,ACT,0.8899999856948853	CHEMBL109259,TN,INACT,0.009999999776482582	CHEMBL246356,TP,ACT,0.9599999785423279	CHEMBL395427,FP,INACT,0.9700000286102295	CHEMBL2029693,FP,INACT,0.7099999785423279	CHEMBL3143155,FN,ACT,0.14000000059604645	CHEMBL1683957,TN,INACT,0.5400000214576721	CHEMBL312933,FN,ACT,0.0	CHEMBL316887,TN,INACT,0.05999999865889549	CHEMBL340350,TP,ACT,1.0	CHEMBL311119,TN,INACT,0.0	CHEMBL381279,FN,ACT,0.09000000357627869	CHEMBL1242658,TP,ACT,1.0	CHEMBL1080271,FP,INACT,0.6700000166893005	CHEMBL267322,TP,ACT,0.9800000190734863	CHEMBL84803,TP,ACT,1.0	CHEMBL2397802,FN,ACT,0.27000001072883606	CHEMBL121190,FN,ACT,0.0	CHEMBL1173485,TP,ACT,1.0	CHEMBL2029510,TN,INACT,0.0	CHEMBL113356,FP,INACT,0.7200000286102295	CHEMBL132284,TP,ACT,1.0	CHEMBL2029695,TN,INACT,0.0	CHEMBL381206,TP,ACT,1.0	CHEMBL475354,TP,ACT,0.9900000095367432	CHEMBL259247,TP,ACT,0.9800000190734863	CHEMBL434369,FN,ACT,0.2199999988079071	CHEMBL328029,FN,ACT,0.0	CHEMBL280668,FN,ACT,0.03999999910593033	CHEMBL1232944,FN,ACT,0.019999999552965164	CHEMBL218656,TP,ACT,0.9399999976158142	CHEMBL266188,TP,ACT,0.9900000095367432	CHEMBL105516,TP,ACT,1.0	CHEMBL198868,TP,ACT,1.0	CHEMBL1828880,TN,INACT,0.0	CHEMBL235757,TP,ACT,0.9100000262260437	CHEMBL305107,TN,INACT,0.0	CHEMBL592210,TN,INACT,0.009999999776482582	CHEMBL2036726,TN,INACT,0.009999999776482582	CHEMBL1078902,TN,INACT,0.0	CHEMBL3780985,TN,INACT,0.6100000143051147	CHEMBL1242657,TP,ACT,1.0	CHEMBL2407911,TN,INACT,0.0	CHEMBL372219,TP,ACT,0.8899999856948853	CHEMBL1221822,TN,INACT,0.05999999865889549	CHEMBL116211,TN,INACT,0.0	CHEMBL121954,TP,ACT,0.9800000190734863	CHEMBL1271641,FN,ACT,0.20999999344348907	CHEMBL597366,TN,INACT,0.5099999904632568	CHEMBL107423,TP,ACT,1.0	CHEMBL501256,TN,INACT,0.0	CHEMBL504805,TP,ACT,1.0	CHEMBL338049,TP,ACT,1.0	CHEMBL398279,TP,ACT,1.0	CHEMBL1160760,TP,ACT,1.0	CHEMBL426148,TP,ACT,1.0	CHEMBL214137,FP,INACT,0.9100000262260437	CHEMBL84179,TP,ACT,1.0	CHEMBL78037,TN,INACT,0.05000000074505806	CHEMBL59812,FN,ACT,0.009999999776482582	CHEMBL422240,TN,INACT,0.550000011920929	CHEMBL211417,TP,ACT,1.0	CHEMBL326711,FP,INACT,0.8600000143051147	CHEMBL2070062,TP,ACT,1.0	CHEMBL499067,TN,INACT,0.05000000074505806	CHEMBL1765563,FN,ACT,0.07999999821186066	CHEMBL2070060,TP,ACT,0.9800000190734863	CHEMBL1242748,TP,ACT,1.0	CHEMBL47203,TP,ACT,1.0	CHEMBL1173114,TP,ACT,1.0	CHEMBL485460,TN,INACT,0.0	CHEMBL381813,TN,INACT,0.20999999344348907	CHEMBL23311,FN,ACT,0.0	CHEMBL209045,FN,ACT,0.4300000071525574	CHEMBL406804,TP,ACT,1.0	CHEMBL99687,TN,INACT,0.0	CHEMBL396788,TN,INACT,0.0	CHEMBL3651223,TP,ACT,1.0	CHEMBL263528,TP,ACT,0.949999988079071	CHEMBL477165,FP,INACT,0.9900000095367432	CHEMBL520540,TP,ACT,0.9100000262260437	CHEMBL102946,TP,ACT,0.9900000095367432	CHEMBL3318026,TN,INACT,0.0	CHEMBL562342,TN,INACT,0.019999999552965164	CHEMBL3651224,TP,ACT,1.0	CHEMBL50,FN,ACT,0.0	CHEMBL241749,FN,ACT,0.0	CHEMBL1084863,TN,INACT,0.0	CHEMBL321359,TN,INACT,0.009999999776482582	CHEMBL89505,TN,INACT,0.009999999776482582	CHEMBL1765554,FN,ACT,0.0	CHEMBL3681949,TP,ACT,1.0	CHEMBL422957,TN,INACT,0.3400000035762787	CHEMBL58421,FN,ACT,0.0	CHEMBL565366,TP,ACT,1.0	CHEMBL431336,TN,INACT,0.0	CHEMBL3394078,TP,ACT,1.0	CHEMBL3617735,TP,ACT,1.0	CHEMBL1172147,FP,INACT,0.8399999737739563	CHEMBL441643,TN,INACT,0.0	CHEMBL541988,FP,INACT,0.9900000095367432	CHEMBL2385543,FP,INACT,0.8700000047683716	CHEMBL3628799,TP,ACT,0.7400000095367432	CHEMBL1271480,TP,ACT,0.8100000023841858	CHEMBL413670,TP,ACT,1.0	CHEMBL384031,TP,ACT,0.9599999785423279	CHEMBL335373,TN,INACT,0.009999999776482582	CHEMBL1173389,TP,ACT,1.0	CHEMBL388596,TN,INACT,0.0	CHEMBL1933074,TN,INACT,0.0	CHEMBL255873,TN,INACT,0.0	CHEMBL31965,TP,ACT,1.0	CHEMBL1684370,FP,INACT,0.9900000095367432	CHEMBL203579,TN,INACT,0.0	CHEMBL3426229,TP,ACT,1.0	CHEMBL1922213,TN,INACT,0.0	CHEMBL1796175,TN,INACT,0.0	CHEMBL1076437,TP,ACT,1.0	CHEMBL2392238,TN,INACT,0.0	CHEMBL94581,TN,INACT,0.0	CHEMBL603198,TN,INACT,0.05000000074505806	CHEMBL118130,TP,ACT,0.9700000286102295	CHEMBL485304,TP,ACT,0.9800000190734863	CHEMBL1341067,TN,INACT,0.17000000178813934	CHEMBL80295,TN,INACT,0.0	CHEMBL19996,TN,INACT,0.0	CHEMBL116012,TN,INACT,0.05999999865889549	CHEMBL355191,TP,ACT,1.0	CHEMBL3651264,TP,ACT,1.0	CHEMBL302824,FN,ACT,0.3199999928474426	CHEMBL3665664,TN,INACT,0.0	CHEMBL1076469,TP,ACT,1.0	CHEMBL311959,TP,ACT,0.9599999785423279	CHEMBL3651234,TP,ACT,1.0	CHEMBL1793843,TN,INACT,0.019999999552965164	CHEMBL2069944,TP,ACT,0.9700000286102295	CHEMBL525921,TN,INACT,0.0	CHEMBL104322,TP,ACT,0.9399999976158142	CHEMBL57229,TN,INACT,0.029999999329447746	CHEMBL291914,TP,ACT,1.0	CHEMBL261743,TP,ACT,0.9900000095367432	CHEMBL420477,FN,ACT,0.12999999523162842	CHEMBL58628,TN,INACT,0.03999999910593033	CHEMBL397691,TP,ACT,1.0	CHEMBL3651285,TP,ACT,1.0	CHEMBL1242848,TP,ACT,1.0	CHEMBL3651251,FN,ACT,0.0	CHEMBL355019,TP,ACT,0.6700000166893005	CHEMBL1721885,TP,ACT,1.0	CHEMBL3648040,TP,ACT,1.0	CHEMBL100675,TN,INACT,0.0	CHEMBL1929314,TN,INACT,0.0	CHEMBL1929306,TN,INACT,0.0	CHEMBL199210,FN,ACT,0.009999999776482582	CHEMBL70346,FN,ACT,0.3700000047683716	CHEMBL424359,FN,ACT,0.5299999713897705	CHEMBL398610,FN,ACT,0.0	CHEMBL79152,TN,INACT,0.6399999856948853	CHEMBL1688204,TN,INACT,0.0	CHEMBL2335377,TN,INACT,0.0	CHEMBL598201,TN,INACT,0.0	CHEMBL367457,TN,INACT,0.0	CHEMBL475190,FN,ACT,0.07000000029802322	CHEMBL1161236,TN,INACT,0.0	CHEMBL218317,FN,ACT,0.1899999976158142	CHEMBL1929554,TN,INACT,0.0	CHEMBL1762119,TN,INACT,0.07000000029802322	CHEMBL304983,TP,ACT,0.9300000071525574	CHEMBL360499,TP,ACT,1.0	CHEMBL551542,FN,ACT,0.019999999552965164	CHEMBL80510,TN,INACT,0.3100000023841858	CHEMBL66171,TP,ACT,1.0	CHEMBL3645543,TN,INACT,0.0	CHEMBL378903,FN,ACT,0.14000000059604645	CHEMBL1779744,TN,INACT,0.0	CHEMBL1172959,TP,ACT,1.0	CHEMBL2163616,TN,INACT,0.6299999952316284	CHEMBL476011,TN,INACT,0.0	CHEMBL2336586,TN,INACT,0.28999999165534973	CHEMBL408291,TP,ACT,1.0	CHEMBL3426891,FN,ACT,0.0	CHEMBL3125820,TN,INACT,0.0	CHEMBL218598,FN,ACT,0.029999999329447746	CHEMBL352877,TP,ACT,0.9800000190734863	CHEMBL1765556,FN,ACT,0.0	CHEMBL3628818,TN,INACT,0.0	CHEMBL511157,TP,ACT,1.0	CHEMBL511124,TP,ACT,1.0	CHEMBL1092013,FP,INACT,0.8799999952316284	CHEMBL1596723,TN,INACT,0.03999999910593033	CHEMBL1076480,TP,ACT,1.0	CHEMBL2397799,TP,ACT,0.9900000095367432	CHEMBL99724,FN,ACT,0.15000000596046448	CHEMBL323405,TP,ACT,1.0	CHEMBL1522339,TN,INACT,0.0	CHEMBL3658126,TP,ACT,1.0	CHEMBL3661093,FP,INACT,1.0	CHEMBL28120,TN,INACT,0.0	CHEMBL218177,FN,ACT,0.27000001072883606	CHEMBL221431,TP,ACT,1.0	CHEMBL1241483,TP,ACT,1.0	CHEMBL301483,FN,ACT,0.4300000071525574	CHEMBL3658116,TP,ACT,0.9900000095367432	CHEMBL211399,TP,ACT,0.9900000095367432	CHEMBL1230790,TP,ACT,0.9900000095367432	CHEMBL345970,TN,INACT,0.0	CHEMBL307179,TN,INACT,0.0	CHEMBL1643353,TN,INACT,0.0	CHEMBL3651267,TP,ACT,1.0	CHEMBL131695,TN,INACT,0.0	CHEMBL3814099,TN,INACT,0.0	CHEMBL2070079,TP,ACT,1.0	CHEMBL599844,TN,INACT,0.0	CHEMBL2391100,TN,INACT,0.0	CHEMBL270958,TP,ACT,0.9900000095367432	CHEMBL602472,TN,INACT,0.0	CHEMBL2375549,TN,INACT,0.14000000059604645	CHEMBL259041,TN,INACT,0.0	CHEMBL2397807,TP,ACT,0.9599999785423279	CHEMBL56219,TN,INACT,0.0	CHEMBL425209,TP,ACT,0.7799999713897705	CHEMBL2152971,TN,INACT,0.0	CHEMBL68729,TP,ACT,1.0	CHEMBL567678,TP,ACT,0.9800000190734863	CHEMBL282575,TN,INACT,0.0	CHEMBL520104,TN,INACT,0.0	CHEMBL472478,TP,ACT,0.8199999928474426	CHEMBL1288582,FN,ACT,0.0	CHEMBL3234892,TN,INACT,0.6399999856948853	CHEMBL1254545,TN,INACT,0.0	CHEMBL1081312,TP,ACT,1.0	CHEMBL3651207,TP,ACT,1.0	CHEMBL2011303,TN,INACT,0.0	CHEMBL1683308,TP,ACT,0.9200000166893005	CHEMBL1738829,TP,ACT,0.9900000095367432	CHEMBL454923,TP,ACT,0.9900000095367432	CHEMBL1830260,FP,INACT,1.0	CHEMBL174634,TP,ACT,1.0	CHEMBL377355,FP,INACT,0.9100000262260437	CHEMBL395665,TN,INACT,0.0	CHEMBL295901,TP,ACT,1.0	CHEMBL2070080,TP,ACT,1.0	CHEMBL2403073,TN,INACT,0.0	CHEMBL3823711,TP,ACT,1.0	CHEMBL377481,FN,ACT,0.3100000023841858	CHEMBL56645,TP,ACT,0.9900000095367432	CHEMBL76905,TN,INACT,0.3100000023841858	CHEMBL3398595,TN,INACT,0.019999999552965164	CHEMBL445319,TP,ACT,1.0	CHEMBL168862,TP,ACT,0.8299999833106995	CHEMBL426989,FP,INACT,0.9700000286102295	CHEMBL279193,TN,INACT,0.2800000011920929	CHEMBL139269,TN,INACT,0.0	CHEMBL3314280,FP,INACT,1.0	

