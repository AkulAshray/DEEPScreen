CNNModel CHEMBL2016 adam 0.001 30 32 0 0.6 False True
Number of active compounds :	268
Number of inactive compounds :	268
---------------------------------
Run id: CNNModel_CHEMBL2016_adam_0.001_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2016_adam_0.001_30_32_0.6_True/
---------------------------------
Training samples: 342
Validation samples: 108
--
Training Step: 1  | time: 0.852s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/342
[A[ATraining Step: 2  | total loss: [1m[32m0.62382[0m[0m | time: 1.497s
[2K
| Adam | epoch: 001 | loss: 0.62382 - acc: 0.4781 -- iter: 064/342
[A[ATraining Step: 3  | total loss: [1m[32m0.68265[0m[0m | time: 2.143s
[2K
| Adam | epoch: 001 | loss: 0.68265 - acc: 0.3682 -- iter: 096/342
[A[ATraining Step: 4  | total loss: [1m[32m0.69057[0m[0m | time: 2.792s
[2K
| Adam | epoch: 001 | loss: 0.69057 - acc: 0.4436 -- iter: 128/342
[A[ATraining Step: 5  | total loss: [1m[32m0.69188[0m[0m | time: 3.434s
[2K
| Adam | epoch: 001 | loss: 0.69188 - acc: 0.5259 -- iter: 160/342
[A[ATraining Step: 6  | total loss: [1m[32m0.69052[0m[0m | time: 4.100s
[2K
| Adam | epoch: 001 | loss: 0.69052 - acc: 0.6097 -- iter: 192/342
[A[ATraining Step: 7  | total loss: [1m[32m0.69049[0m[0m | time: 4.760s
[2K
| Adam | epoch: 001 | loss: 0.69049 - acc: 0.5814 -- iter: 224/342
[A[ATraining Step: 8  | total loss: [1m[32m0.70555[0m[0m | time: 5.416s
[2K
| Adam | epoch: 001 | loss: 0.70555 - acc: 0.4477 -- iter: 256/342
[A[ATraining Step: 9  | total loss: [1m[32m0.69364[0m[0m | time: 6.083s
[2K
| Adam | epoch: 001 | loss: 0.69364 - acc: 0.5416 -- iter: 288/342
[A[ATraining Step: 10  | total loss: [1m[32m0.69007[0m[0m | time: 6.748s
[2K
| Adam | epoch: 001 | loss: 0.69007 - acc: 0.5677 -- iter: 320/342
[A[ATraining Step: 11  | total loss: [1m[32m0.69660[0m[0m | time: 8.241s
[2K
| Adam | epoch: 001 | loss: 0.69660 - acc: 0.4764 | val_loss: 0.69780 - val_acc: 0.4444 -- iter: 342/342
--
Training Step: 12  | total loss: [1m[32m0.68710[0m[0m | time: 0.476s
[2K
| Adam | epoch: 002 | loss: 0.68710 - acc: 0.6097 -- iter: 032/342
[A[ATraining Step: 13  | total loss: [1m[32m0.68145[0m[0m | time: 1.133s
[2K
| Adam | epoch: 002 | loss: 0.68145 - acc: 0.6796 -- iter: 064/342
[A[ATraining Step: 14  | total loss: [1m[32m0.68654[0m[0m | time: 1.798s
[2K
| Adam | epoch: 002 | loss: 0.68654 - acc: 0.6061 -- iter: 096/342
[A[ATraining Step: 15  | total loss: [1m[32m0.69344[0m[0m | time: 2.447s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.5279 -- iter: 128/342
[A[ATraining Step: 16  | total loss: [1m[32m0.69117[0m[0m | time: 3.118s
[2K
| Adam | epoch: 002 | loss: 0.69117 - acc: 0.5409 -- iter: 160/342
[A[ATraining Step: 17  | total loss: [1m[32m0.69430[0m[0m | time: 3.798s
[2K
| Adam | epoch: 002 | loss: 0.69430 - acc: 0.5149 -- iter: 192/342
[A[ATraining Step: 18  | total loss: [1m[32m0.69321[0m[0m | time: 4.479s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5206 -- iter: 224/342
[A[ATraining Step: 19  | total loss: [1m[32m0.69380[0m[0m | time: 5.120s
[2K
| Adam | epoch: 002 | loss: 0.69380 - acc: 0.5137 -- iter: 256/342
[A[ATraining Step: 20  | total loss: [1m[32m0.69281[0m[0m | time: 5.786s
[2K
| Adam | epoch: 002 | loss: 0.69281 - acc: 0.5193 -- iter: 288/342
[A[ATraining Step: 21  | total loss: [1m[32m0.69217[0m[0m | time: 6.447s
[2K
| Adam | epoch: 002 | loss: 0.69217 - acc: 0.5230 -- iter: 320/342
[A[ATraining Step: 22  | total loss: [1m[32m0.69047[0m[0m | time: 8.123s
[2K
| Adam | epoch: 002 | loss: 0.69047 - acc: 0.5349 | val_loss: 0.70101 - val_acc: 0.4444 -- iter: 342/342
--
Training Step: 23  | total loss: [1m[32m0.69284[0m[0m | time: 0.461s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5157 -- iter: 032/342
[A[ATraining Step: 24  | total loss: [1m[32m0.68729[0m[0m | time: 0.925s
[2K
| Adam | epoch: 003 | loss: 0.68729 - acc: 0.5624 -- iter: 064/342
[A[ATraining Step: 25  | total loss: [1m[32m0.68251[0m[0m | time: 1.574s
[2K
| Adam | epoch: 003 | loss: 0.68251 - acc: 0.5950 -- iter: 096/342
[A[ATraining Step: 26  | total loss: [1m[32m0.68603[0m[0m | time: 2.203s
[2K
| Adam | epoch: 003 | loss: 0.68603 - acc: 0.5698 -- iter: 128/342
[A[ATraining Step: 27  | total loss: [1m[32m0.68703[0m[0m | time: 2.842s
[2K
| Adam | epoch: 003 | loss: 0.68703 - acc: 0.5599 -- iter: 160/342
[A[ATraining Step: 28  | total loss: [1m[32m0.68992[0m[0m | time: 3.497s
[2K
| Adam | epoch: 003 | loss: 0.68992 - acc: 0.5449 -- iter: 192/342
[A[ATraining Step: 29  | total loss: [1m[32m0.68883[0m[0m | time: 4.145s
[2K
| Adam | epoch: 003 | loss: 0.68883 - acc: 0.5492 -- iter: 224/342
[A[ATraining Step: 30  | total loss: [1m[32m0.69115[0m[0m | time: 4.828s
[2K
| Adam | epoch: 003 | loss: 0.69115 - acc: 0.5376 -- iter: 256/342
[A[ATraining Step: 31  | total loss: [1m[32m0.68921[0m[0m | time: 5.472s
[2K
| Adam | epoch: 003 | loss: 0.68921 - acc: 0.5433 -- iter: 288/342
[A[ATraining Step: 32  | total loss: [1m[32m0.69265[0m[0m | time: 6.143s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5265 -- iter: 320/342
[A[ATraining Step: 33  | total loss: [1m[32m0.69503[0m[0m | time: 7.820s
[2K
| Adam | epoch: 003 | loss: 0.69503 - acc: 0.5138 | val_loss: 0.70092 - val_acc: 0.4444 -- iter: 342/342
--
Training Step: 34  | total loss: [1m[32m0.69500[0m[0m | time: 0.670s
[2K
| Adam | epoch: 004 | loss: 0.69500 - acc: 0.5109 -- iter: 032/342
[A[ATraining Step: 35  | total loss: [1m[32m0.69406[0m[0m | time: 1.125s
[2K
| Adam | epoch: 004 | loss: 0.69406 - acc: 0.5151 -- iter: 064/342
[A[ATraining Step: 36  | total loss: [1m[32m0.69200[0m[0m | time: 1.581s
[2K
| Adam | epoch: 004 | loss: 0.69200 - acc: 0.5306 -- iter: 096/342
[A[ATraining Step: 37  | total loss: [1m[32m0.69060[0m[0m | time: 2.242s
[2K
| Adam | epoch: 004 | loss: 0.69060 - acc: 0.5427 -- iter: 128/342
[A[ATraining Step: 38  | total loss: [1m[32m0.68843[0m[0m | time: 2.933s
[2K
| Adam | epoch: 004 | loss: 0.68843 - acc: 0.5649 -- iter: 160/342
[A[ATraining Step: 39  | total loss: [1m[32m0.68919[0m[0m | time: 3.598s
[2K
| Adam | epoch: 004 | loss: 0.68919 - acc: 0.5525 -- iter: 192/342
[A[ATraining Step: 40  | total loss: [1m[32m0.68813[0m[0m | time: 4.263s
[2K
| Adam | epoch: 004 | loss: 0.68813 - acc: 0.5602 -- iter: 224/342
[A[ATraining Step: 41  | total loss: [1m[32m0.68834[0m[0m | time: 4.912s
[2K
| Adam | epoch: 004 | loss: 0.68834 - acc: 0.5549 -- iter: 256/342
[A[ATraining Step: 42  | total loss: [1m[32m0.69057[0m[0m | time: 5.556s
[2K
| Adam | epoch: 004 | loss: 0.69057 - acc: 0.5338 -- iter: 288/342
[A[ATraining Step: 43  | total loss: [1m[32m0.69055[0m[0m | time: 6.217s
[2K
| Adam | epoch: 004 | loss: 0.69055 - acc: 0.5333 -- iter: 320/342
[A[ATraining Step: 44  | total loss: [1m[32m0.69270[0m[0m | time: 7.862s
[2K
| Adam | epoch: 004 | loss: 0.69270 - acc: 0.5113 | val_loss: 0.69844 - val_acc: 0.4444 -- iter: 342/342
--
Training Step: 45  | total loss: [1m[32m0.68982[0m[0m | time: 0.651s
[2K
| Adam | epoch: 005 | loss: 0.68982 - acc: 0.5359 -- iter: 032/342
[A[ATraining Step: 46  | total loss: [1m[32m0.68774[0m[0m | time: 1.302s
[2K
| Adam | epoch: 005 | loss: 0.68774 - acc: 0.5508 -- iter: 064/342
[A[ATraining Step: 47  | total loss: [1m[32m0.68650[0m[0m | time: 1.783s
[2K
| Adam | epoch: 005 | loss: 0.68650 - acc: 0.5578 -- iter: 096/342
[A[ATraining Step: 48  | total loss: [1m[32m0.68961[0m[0m | time: 2.256s
[2K
| Adam | epoch: 005 | loss: 0.68961 - acc: 0.5339 -- iter: 128/342
[A[ATraining Step: 49  | total loss: [1m[32m0.69233[0m[0m | time: 2.911s
[2K
| Adam | epoch: 005 | loss: 0.69233 - acc: 0.5142 -- iter: 160/342
[A[ATraining Step: 50  | total loss: [1m[32m0.69066[0m[0m | time: 3.584s
[2K
| Adam | epoch: 005 | loss: 0.69066 - acc: 0.5217 -- iter: 192/342
[A[ATraining Step: 51  | total loss: [1m[32m0.69228[0m[0m | time: 4.239s
[2K
| Adam | epoch: 005 | loss: 0.69228 - acc: 0.5089 -- iter: 224/342
[A[ATraining Step: 52  | total loss: [1m[32m0.69136[0m[0m | time: 4.905s
[2K
| Adam | epoch: 005 | loss: 0.69136 - acc: 0.5122 -- iter: 256/342
[A[ATraining Step: 53  | total loss: [1m[32m0.69047[0m[0m | time: 5.592s
[2K
| Adam | epoch: 005 | loss: 0.69047 - acc: 0.5150 -- iter: 288/342
[A[ATraining Step: 54  | total loss: [1m[32m0.69112[0m[0m | time: 6.250s
[2K
| Adam | epoch: 005 | loss: 0.69112 - acc: 0.5038 -- iter: 320/342
[A[ATraining Step: 55  | total loss: [1m[32m0.69201[0m[0m | time: 7.910s
[2K
| Adam | epoch: 005 | loss: 0.69201 - acc: 0.4898 | val_loss: 0.68866 - val_acc: 0.4444 -- iter: 342/342
--
Training Step: 56  | total loss: [1m[32m0.69140[0m[0m | time: 0.684s
[2K
| Adam | epoch: 006 | loss: 0.69140 - acc: 0.4913 -- iter: 032/342
[A[ATraining Step: 57  | total loss: [1m[32m0.68892[0m[0m | time: 1.356s
[2K
| Adam | epoch: 006 | loss: 0.68892 - acc: 0.5141 -- iter: 064/342
[A[ATraining Step: 58  | total loss: [1m[32m0.68585[0m[0m | time: 2.015s
[2K
| Adam | epoch: 006 | loss: 0.68585 - acc: 0.5292 -- iter: 096/342
[A[ATraining Step: 59  | total loss: [1m[32m0.68251[0m[0m | time: 2.468s
[2K
| Adam | epoch: 006 | loss: 0.68251 - acc: 0.5337 -- iter: 128/342
[A[ATraining Step: 60  | total loss: [1m[32m0.67392[0m[0m | time: 2.943s
[2K
| Adam | epoch: 006 | loss: 0.67392 - acc: 0.5533 -- iter: 160/342
[A[ATraining Step: 61  | total loss: [1m[32m0.66232[0m[0m | time: 3.601s
[2K
| Adam | epoch: 006 | loss: 0.66232 - acc: 0.5701 -- iter: 192/342
[A[ATraining Step: 62  | total loss: [1m[32m0.68076[0m[0m | time: 4.270s
[2K
| Adam | epoch: 006 | loss: 0.68076 - acc: 0.5651 -- iter: 224/342
[A[ATraining Step: 63  | total loss: [1m[32m0.69692[0m[0m | time: 4.952s
[2K
| Adam | epoch: 006 | loss: 0.69692 - acc: 0.5449 -- iter: 256/342
[A[ATraining Step: 64  | total loss: [1m[32m0.69513[0m[0m | time: 5.603s
[2K
| Adam | epoch: 006 | loss: 0.69513 - acc: 0.5393 -- iter: 288/342
[A[ATraining Step: 65  | total loss: [1m[32m0.69354[0m[0m | time: 6.218s
[2K
| Adam | epoch: 006 | loss: 0.69354 - acc: 0.5460 -- iter: 320/342
[A[ATraining Step: 66  | total loss: [1m[32m0.69193[0m[0m | time: 7.887s
[2K
| Adam | epoch: 006 | loss: 0.69193 - acc: 0.5480 | val_loss: 0.68631 - val_acc: 0.5556 -- iter: 342/342
--
Training Step: 67  | total loss: [1m[32m0.69040[0m[0m | time: 0.683s
[2K
| Adam | epoch: 007 | loss: 0.69040 - acc: 0.5573 -- iter: 032/342
[A[ATraining Step: 68  | total loss: [1m[32m0.69332[0m[0m | time: 1.354s
[2K
| Adam | epoch: 007 | loss: 0.69332 - acc: 0.5320 -- iter: 064/342
[A[ATraining Step: 69  | total loss: [1m[32m0.69445[0m[0m | time: 2.004s
[2K
| Adam | epoch: 007 | loss: 0.69445 - acc: 0.5173 -- iter: 096/342
[A[ATraining Step: 70  | total loss: [1m[32m0.69488[0m[0m | time: 2.689s
[2K
| Adam | epoch: 007 | loss: 0.69488 - acc: 0.5045 -- iter: 128/342
[A[ATraining Step: 71  | total loss: [1m[32m0.69429[0m[0m | time: 3.152s
[2K
| Adam | epoch: 007 | loss: 0.69429 - acc: 0.5075 -- iter: 160/342
[A[ATraining Step: 72  | total loss: [1m[32m0.69368[0m[0m | time: 3.619s
[2K
| Adam | epoch: 007 | loss: 0.69368 - acc: 0.5169 -- iter: 192/342
[A[ATraining Step: 73  | total loss: [1m[32m0.69317[0m[0m | time: 4.273s
[2K
| Adam | epoch: 007 | loss: 0.69317 - acc: 0.5302 -- iter: 224/342
[A[ATraining Step: 74  | total loss: [1m[32m0.69322[0m[0m | time: 4.923s
[2K
| Adam | epoch: 007 | loss: 0.69322 - acc: 0.5200 -- iter: 256/342
[A[ATraining Step: 75  | total loss: [1m[32m0.69319[0m[0m | time: 5.580s
[2K
| Adam | epoch: 007 | loss: 0.69319 - acc: 0.5145 -- iter: 288/342
[A[ATraining Step: 76  | total loss: [1m[32m0.69283[0m[0m | time: 6.229s
[2K
| Adam | epoch: 007 | loss: 0.69283 - acc: 0.5196 -- iter: 320/342
[A[ATraining Step: 77  | total loss: [1m[32m0.69284[0m[0m | time: 7.875s
[2K
| Adam | epoch: 007 | loss: 0.69284 - acc: 0.5142 | val_loss: 0.69296 - val_acc: 0.4444 -- iter: 342/342
--
Training Step: 78  | total loss: [1m[32m0.69189[0m[0m | time: 0.665s
[2K
| Adam | epoch: 008 | loss: 0.69189 - acc: 0.5258 -- iter: 032/342
[A[ATraining Step: 79  | total loss: [1m[32m0.69090[0m[0m | time: 1.340s
[2K
| Adam | epoch: 008 | loss: 0.69090 - acc: 0.5328 -- iter: 064/342
[A[ATraining Step: 80  | total loss: [1m[32m0.69000[0m[0m | time: 1.998s
[2K
| Adam | epoch: 008 | loss: 0.69000 - acc: 0.5391 -- iter: 096/342
[A[ATraining Step: 81  | total loss: [1m[32m0.68903[0m[0m | time: 2.637s
[2K
| Adam | epoch: 008 | loss: 0.68903 - acc: 0.5478 -- iter: 128/342
[A[ATraining Step: 82  | total loss: [1m[32m0.68921[0m[0m | time: 3.290s
[2K
| Adam | epoch: 008 | loss: 0.68921 - acc: 0.5367 -- iter: 160/342
[A[ATraining Step: 83  | total loss: [1m[32m0.68839[0m[0m | time: 3.754s
[2K
| Adam | epoch: 008 | loss: 0.68839 - acc: 0.5487 -- iter: 192/342
[A[ATraining Step: 84  | total loss: [1m[32m0.68723[0m[0m | time: 4.193s
[2K
| Adam | epoch: 008 | loss: 0.68723 - acc: 0.5484 -- iter: 224/342
[A[ATraining Step: 85  | total loss: [1m[32m0.68444[0m[0m | time: 4.857s
[2K
| Adam | epoch: 008 | loss: 0.68444 - acc: 0.5663 -- iter: 256/342
[A[ATraining Step: 86  | total loss: [1m[32m0.68373[0m[0m | time: 5.519s
[2K
| Adam | epoch: 008 | loss: 0.68373 - acc: 0.5721 -- iter: 288/342
[A[ATraining Step: 87  | total loss: [1m[32m0.68321[0m[0m | time: 6.181s
[2K
| Adam | epoch: 008 | loss: 0.68321 - acc: 0.5712 -- iter: 320/342
[A[ATraining Step: 88  | total loss: [1m[32m0.68011[0m[0m | time: 7.819s
[2K
| Adam | epoch: 008 | loss: 0.68011 - acc: 0.5797 | val_loss: 0.66422 - val_acc: 0.5370 -- iter: 342/342
--
Training Step: 89  | total loss: [1m[32m0.67598[0m[0m | time: 0.665s
[2K
| Adam | epoch: 009 | loss: 0.67598 - acc: 0.5936 -- iter: 032/342
[A[ATraining Step: 90  | total loss: [1m[32m0.67538[0m[0m | time: 1.331s
[2K
| Adam | epoch: 009 | loss: 0.67538 - acc: 0.5905 -- iter: 064/342
[A[ATraining Step: 91  | total loss: [1m[32m0.66958[0m[0m | time: 1.976s
[2K
| Adam | epoch: 009 | loss: 0.66958 - acc: 0.6002 -- iter: 096/342
[A[ATraining Step: 92  | total loss: [1m[32m0.66082[0m[0m | time: 2.636s
[2K
| Adam | epoch: 009 | loss: 0.66082 - acc: 0.6089 -- iter: 128/342
[A[ATraining Step: 93  | total loss: [1m[32m0.65841[0m[0m | time: 3.302s
[2K
| Adam | epoch: 009 | loss: 0.65841 - acc: 0.6168 -- iter: 160/342
[A[ATraining Step: 94  | total loss: [1m[32m0.66028[0m[0m | time: 3.966s
[2K
| Adam | epoch: 009 | loss: 0.66028 - acc: 0.6145 -- iter: 192/342
[A[ATraining Step: 95  | total loss: [1m[32m0.65380[0m[0m | time: 4.416s
[2K
| Adam | epoch: 009 | loss: 0.65380 - acc: 0.6155 -- iter: 224/342
[A[ATraining Step: 96  | total loss: [1m[32m0.63566[0m[0m | time: 4.885s
[2K
| Adam | epoch: 009 | loss: 0.63566 - acc: 0.6267 -- iter: 256/342
[A[ATraining Step: 97  | total loss: [1m[32m0.61800[0m[0m | time: 5.536s
[2K
| Adam | epoch: 009 | loss: 0.61800 - acc: 0.6368 -- iter: 288/342
[A[ATraining Step: 98  | total loss: [1m[32m0.61683[0m[0m | time: 6.182s
[2K
| Adam | epoch: 009 | loss: 0.61683 - acc: 0.6418 -- iter: 320/342
[A[ATraining Step: 99  | total loss: [1m[32m0.61663[0m[0m | time: 7.834s
[2K
| Adam | epoch: 009 | loss: 0.61663 - acc: 0.6433 | val_loss: 0.62599 - val_acc: 0.6574 -- iter: 342/342
--
Training Step: 100  | total loss: [1m[32m0.62078[0m[0m | time: 0.685s
[2K
| Adam | epoch: 010 | loss: 0.62078 - acc: 0.6508 -- iter: 032/342
[A[ATraining Step: 101  | total loss: [1m[32m0.63459[0m[0m | time: 1.337s
[2K
| Adam | epoch: 010 | loss: 0.63459 - acc: 0.6420 -- iter: 064/342
[A[ATraining Step: 102  | total loss: [1m[32m0.62842[0m[0m | time: 1.998s
[2K
| Adam | epoch: 010 | loss: 0.62842 - acc: 0.6434 -- iter: 096/342
[A[ATraining Step: 103  | total loss: [1m[32m0.61057[0m[0m | time: 2.628s
[2K
| Adam | epoch: 010 | loss: 0.61057 - acc: 0.6572 -- iter: 128/342
[A[ATraining Step: 104  | total loss: [1m[32m0.60912[0m[0m | time: 3.305s
[2K
| Adam | epoch: 010 | loss: 0.60912 - acc: 0.6571 -- iter: 160/342
[A[ATraining Step: 105  | total loss: [1m[32m0.61201[0m[0m | time: 4.010s
[2K
| Adam | epoch: 010 | loss: 0.61201 - acc: 0.6476 -- iter: 192/342
[A[ATraining Step: 106  | total loss: [1m[32m0.61173[0m[0m | time: 4.666s
[2K
| Adam | epoch: 010 | loss: 0.61173 - acc: 0.6485 -- iter: 224/342
[A[ATraining Step: 107  | total loss: [1m[32m0.61099[0m[0m | time: 5.112s
[2K
| Adam | epoch: 010 | loss: 0.61099 - acc: 0.6493 -- iter: 256/342
[A[ATraining Step: 108  | total loss: [1m[32m0.60703[0m[0m | time: 5.571s
[2K
| Adam | epoch: 010 | loss: 0.60703 - acc: 0.6525 -- iter: 288/342
[A[ATraining Step: 109  | total loss: [1m[32m0.60275[0m[0m | time: 6.227s
[2K
| Adam | epoch: 010 | loss: 0.60275 - acc: 0.6646 -- iter: 320/342
[A[ATraining Step: 110  | total loss: [1m[32m0.60665[0m[0m | time: 7.889s
[2K
| Adam | epoch: 010 | loss: 0.60665 - acc: 0.6637 | val_loss: 0.64371 - val_acc: 0.6389 -- iter: 342/342
--
Training Step: 111  | total loss: [1m[32m0.61111[0m[0m | time: 0.668s
[2K
| Adam | epoch: 011 | loss: 0.61111 - acc: 0.6598 -- iter: 032/342
[A[ATraining Step: 112  | total loss: [1m[32m0.61051[0m[0m | time: 1.340s
[2K
| Adam | epoch: 011 | loss: 0.61051 - acc: 0.6657 -- iter: 064/342
[A[ATraining Step: 113  | total loss: [1m[32m0.61983[0m[0m | time: 1.989s
[2K
| Adam | epoch: 011 | loss: 0.61983 - acc: 0.6429 -- iter: 096/342
[A[ATraining Step: 114  | total loss: [1m[32m0.62106[0m[0m | time: 2.659s
[2K
| Adam | epoch: 011 | loss: 0.62106 - acc: 0.6411 -- iter: 128/342
[A[ATraining Step: 115  | total loss: [1m[32m0.61420[0m[0m | time: 3.322s
[2K
| Adam | epoch: 011 | loss: 0.61420 - acc: 0.6583 -- iter: 160/342
[A[ATraining Step: 116  | total loss: [1m[32m0.60599[0m[0m | time: 3.977s
[2K
| Adam | epoch: 011 | loss: 0.60599 - acc: 0.6674 -- iter: 192/342
[A[ATraining Step: 117  | total loss: [1m[32m0.60462[0m[0m | time: 4.636s
[2K
| Adam | epoch: 011 | loss: 0.60462 - acc: 0.6726 -- iter: 224/342
[A[ATraining Step: 118  | total loss: [1m[32m0.59997[0m[0m | time: 5.291s
[2K
| Adam | epoch: 011 | loss: 0.59997 - acc: 0.6741 -- iter: 256/342
[A[ATraining Step: 119  | total loss: [1m[32m0.58797[0m[0m | time: 5.741s
[2K
| Adam | epoch: 011 | loss: 0.58797 - acc: 0.6785 -- iter: 288/342
[A[ATraining Step: 120  | total loss: [1m[32m0.56618[0m[0m | time: 6.203s
[2K
| Adam | epoch: 011 | loss: 0.56618 - acc: 0.7061 -- iter: 320/342
[A[ATraining Step: 121  | total loss: [1m[32m0.54338[0m[0m | time: 7.852s
[2K
| Adam | epoch: 011 | loss: 0.54338 - acc: 0.7310 | val_loss: 0.72123 - val_acc: 0.6481 -- iter: 342/342
--
Training Step: 122  | total loss: [1m[32m0.52856[0m[0m | time: 0.674s
[2K
| Adam | epoch: 012 | loss: 0.52856 - acc: 0.7454 -- iter: 032/342
[A[ATraining Step: 123  | total loss: [1m[32m0.53447[0m[0m | time: 1.309s
[2K
| Adam | epoch: 012 | loss: 0.53447 - acc: 0.7427 -- iter: 064/342
[A[ATraining Step: 124  | total loss: [1m[32m0.52404[0m[0m | time: 1.982s
[2K
| Adam | epoch: 012 | loss: 0.52404 - acc: 0.7466 -- iter: 096/342
[A[ATraining Step: 125  | total loss: [1m[32m0.51601[0m[0m | time: 2.633s
[2K
| Adam | epoch: 012 | loss: 0.51601 - acc: 0.7500 -- iter: 128/342
[A[ATraining Step: 126  | total loss: [1m[32m0.50684[0m[0m | time: 3.327s
[2K
| Adam | epoch: 012 | loss: 0.50684 - acc: 0.7500 -- iter: 160/342
[A[ATraining Step: 127  | total loss: [1m[32m0.53094[0m[0m | time: 3.960s
[2K
| Adam | epoch: 012 | loss: 0.53094 - acc: 0.7313 -- iter: 192/342
[A[ATraining Step: 128  | total loss: [1m[32m0.52136[0m[0m | time: 4.613s
[2K
| Adam | epoch: 012 | loss: 0.52136 - acc: 0.7394 -- iter: 224/342
[A[ATraining Step: 129  | total loss: [1m[32m0.50698[0m[0m | time: 5.277s
[2K
| Adam | epoch: 012 | loss: 0.50698 - acc: 0.7530 -- iter: 256/342
[A[ATraining Step: 130  | total loss: [1m[32m0.49366[0m[0m | time: 5.932s
[2K
| Adam | epoch: 012 | loss: 0.49366 - acc: 0.7620 -- iter: 288/342
[A[ATraining Step: 131  | total loss: [1m[32m0.48839[0m[0m | time: 6.391s
[2K
| Adam | epoch: 012 | loss: 0.48839 - acc: 0.7640 -- iter: 320/342
[A[ATraining Step: 132  | total loss: [1m[32m0.48188[0m[0m | time: 7.846s
[2K
| Adam | epoch: 012 | loss: 0.48188 - acc: 0.7694 | val_loss: 0.43943 - val_acc: 0.8056 -- iter: 342/342
--
Training Step: 133  | total loss: [1m[32m0.47906[0m[0m | time: 0.648s
[2K
| Adam | epoch: 013 | loss: 0.47906 - acc: 0.7743 -- iter: 032/342
[A[ATraining Step: 134  | total loss: [1m[32m0.47098[0m[0m | time: 1.296s
[2K
| Adam | epoch: 013 | loss: 0.47098 - acc: 0.7843 -- iter: 064/342
[A[ATraining Step: 135  | total loss: [1m[32m0.46362[0m[0m | time: 1.975s
[2K
| Adam | epoch: 013 | loss: 0.46362 - acc: 0.7903 -- iter: 096/342
[A[ATraining Step: 136  | total loss: [1m[32m0.44891[0m[0m | time: 2.654s
[2K
| Adam | epoch: 013 | loss: 0.44891 - acc: 0.7956 -- iter: 128/342
[A[ATraining Step: 137  | total loss: [1m[32m0.43736[0m[0m | time: 3.283s
[2K
| Adam | epoch: 013 | loss: 0.43736 - acc: 0.8004 -- iter: 160/342
[A[ATraining Step: 138  | total loss: [1m[32m0.42574[0m[0m | time: 3.967s
[2K
| Adam | epoch: 013 | loss: 0.42574 - acc: 0.8016 -- iter: 192/342
[A[ATraining Step: 139  | total loss: [1m[32m0.41128[0m[0m | time: 4.628s
[2K
| Adam | epoch: 013 | loss: 0.41128 - acc: 0.8152 -- iter: 224/342
[A[ATraining Step: 140  | total loss: [1m[32m0.40380[0m[0m | time: 5.287s
[2K
| Adam | epoch: 013 | loss: 0.40380 - acc: 0.8212 -- iter: 256/342
[A[ATraining Step: 141  | total loss: [1m[32m0.40083[0m[0m | time: 5.939s
[2K
| Adam | epoch: 013 | loss: 0.40083 - acc: 0.8297 -- iter: 288/342
[A[ATraining Step: 142  | total loss: [1m[32m0.37870[0m[0m | time: 6.604s
[2K
| Adam | epoch: 013 | loss: 0.37870 - acc: 0.8436 -- iter: 320/342
[A[ATraining Step: 143  | total loss: [1m[32m0.35429[0m[0m | time: 8.065s
[2K
| Adam | epoch: 013 | loss: 0.35429 - acc: 0.8561 | val_loss: 0.39556 - val_acc: 0.8148 -- iter: 342/342
--
Training Step: 144  | total loss: [1m[32m0.35105[0m[0m | time: 0.467s
[2K
| Adam | epoch: 014 | loss: 0.35105 - acc: 0.8614 -- iter: 032/342
[A[ATraining Step: 145  | total loss: [1m[32m0.34315[0m[0m | time: 1.122s
[2K
| Adam | epoch: 014 | loss: 0.34315 - acc: 0.8662 -- iter: 064/342
[A[ATraining Step: 146  | total loss: [1m[32m0.33517[0m[0m | time: 1.793s
[2K
| Adam | epoch: 014 | loss: 0.33517 - acc: 0.8639 -- iter: 096/342
[A[ATraining Step: 147  | total loss: [1m[32m0.33514[0m[0m | time: 2.453s
[2K
| Adam | epoch: 014 | loss: 0.33514 - acc: 0.8651 -- iter: 128/342
[A[ATraining Step: 148  | total loss: [1m[32m0.31942[0m[0m | time: 3.132s
[2K
| Adam | epoch: 014 | loss: 0.31942 - acc: 0.8723 -- iter: 160/342
[A[ATraining Step: 149  | total loss: [1m[32m0.31784[0m[0m | time: 3.793s
[2K
| Adam | epoch: 014 | loss: 0.31784 - acc: 0.8757 -- iter: 192/342
[A[ATraining Step: 150  | total loss: [1m[32m0.29826[0m[0m | time: 4.449s
[2K
| Adam | epoch: 014 | loss: 0.29826 - acc: 0.8819 -- iter: 224/342
[A[ATraining Step: 151  | total loss: [1m[32m0.29887[0m[0m | time: 5.119s
[2K
| Adam | epoch: 014 | loss: 0.29887 - acc: 0.8812 -- iter: 256/342
[A[ATraining Step: 152  | total loss: [1m[32m0.28178[0m[0m | time: 5.765s
[2K
| Adam | epoch: 014 | loss: 0.28178 - acc: 0.8868 -- iter: 288/342
[A[ATraining Step: 153  | total loss: [1m[32m0.26765[0m[0m | time: 6.423s
[2K
| Adam | epoch: 014 | loss: 0.26765 - acc: 0.8919 -- iter: 320/342
[A[ATraining Step: 154  | total loss: [1m[32m0.25793[0m[0m | time: 8.108s
[2K
| Adam | epoch: 014 | loss: 0.25793 - acc: 0.8996 | val_loss: 0.37165 - val_acc: 0.8611 -- iter: 342/342
--
Training Step: 155  | total loss: [1m[32m0.24613[0m[0m | time: 0.456s
[2K
| Adam | epoch: 015 | loss: 0.24613 - acc: 0.9065 -- iter: 032/342
[A[ATraining Step: 156  | total loss: [1m[32m0.23014[0m[0m | time: 0.914s
[2K
| Adam | epoch: 015 | loss: 0.23014 - acc: 0.9158 -- iter: 064/342
[A[ATraining Step: 157  | total loss: [1m[32m0.21620[0m[0m | time: 1.577s
[2K
| Adam | epoch: 015 | loss: 0.21620 - acc: 0.9243 -- iter: 096/342
[A[ATraining Step: 158  | total loss: [1m[32m0.22680[0m[0m | time: 2.221s
[2K
| Adam | epoch: 015 | loss: 0.22680 - acc: 0.9131 -- iter: 128/342
[A[ATraining Step: 159  | total loss: [1m[32m0.20989[0m[0m | time: 2.870s
[2K
| Adam | epoch: 015 | loss: 0.20989 - acc: 0.9186 -- iter: 160/342
[A[ATraining Step: 160  | total loss: [1m[32m0.23150[0m[0m | time: 3.527s
[2K
| Adam | epoch: 015 | loss: 0.23150 - acc: 0.9112 -- iter: 192/342
[A[ATraining Step: 161  | total loss: [1m[32m0.21432[0m[0m | time: 4.178s
[2K
| Adam | epoch: 015 | loss: 0.21432 - acc: 0.9169 -- iter: 224/342
[A[ATraining Step: 162  | total loss: [1m[32m0.20045[0m[0m | time: 4.832s
[2K
| Adam | epoch: 015 | loss: 0.20045 - acc: 0.9221 -- iter: 256/342
[A[ATraining Step: 163  | total loss: [1m[32m0.18317[0m[0m | time: 5.462s
[2K
| Adam | epoch: 015 | loss: 0.18317 - acc: 0.9299 -- iter: 288/342
[A[ATraining Step: 164  | total loss: [1m[32m0.18007[0m[0m | time: 6.110s
[2K
| Adam | epoch: 015 | loss: 0.18007 - acc: 0.9307 -- iter: 320/342
[A[ATraining Step: 165  | total loss: [1m[32m0.16338[0m[0m | time: 7.784s
[2K
| Adam | epoch: 015 | loss: 0.16338 - acc: 0.9376 | val_loss: 0.37704 - val_acc: 0.8704 -- iter: 342/342
--
Training Step: 166  | total loss: [1m[32m0.15154[0m[0m | time: 0.677s
[2K
| Adam | epoch: 016 | loss: 0.15154 - acc: 0.9438 -- iter: 032/342
[A[ATraining Step: 167  | total loss: [1m[32m0.14689[0m[0m | time: 1.146s
[2K
| Adam | epoch: 016 | loss: 0.14689 - acc: 0.9463 -- iter: 064/342
[A[ATraining Step: 168  | total loss: [1m[32m0.15128[0m[0m | time: 1.606s
[2K
| Adam | epoch: 016 | loss: 0.15128 - acc: 0.9471 -- iter: 096/342
[A[ATraining Step: 169  | total loss: [1m[32m0.15433[0m[0m | time: 2.274s
[2K
| Adam | epoch: 016 | loss: 0.15433 - acc: 0.9479 -- iter: 128/342
[A[ATraining Step: 170  | total loss: [1m[32m0.15214[0m[0m | time: 2.937s
[2K
| Adam | epoch: 016 | loss: 0.15214 - acc: 0.9468 -- iter: 160/342
[A[ATraining Step: 171  | total loss: [1m[32m0.16631[0m[0m | time: 3.588s
[2K
| Adam | epoch: 016 | loss: 0.16631 - acc: 0.9365 -- iter: 192/342
[A[ATraining Step: 172  | total loss: [1m[32m0.17394[0m[0m | time: 4.265s
[2K
| Adam | epoch: 016 | loss: 0.17394 - acc: 0.9335 -- iter: 224/342
[A[ATraining Step: 173  | total loss: [1m[32m0.16936[0m[0m | time: 4.915s
[2K
| Adam | epoch: 016 | loss: 0.16936 - acc: 0.9370 -- iter: 256/342
[A[ATraining Step: 174  | total loss: [1m[32m0.16860[0m[0m | time: 5.562s
[2K
| Adam | epoch: 016 | loss: 0.16860 - acc: 0.9371 -- iter: 288/342
[A[ATraining Step: 175  | total loss: [1m[32m0.15516[0m[0m | time: 6.232s
[2K
| Adam | epoch: 016 | loss: 0.15516 - acc: 0.9434 -- iter: 320/342
[A[ATraining Step: 176  | total loss: [1m[32m0.14908[0m[0m | time: 7.904s
[2K
| Adam | epoch: 016 | loss: 0.14908 - acc: 0.9428 | val_loss: 0.41818 - val_acc: 0.8704 -- iter: 342/342
--
Training Step: 177  | total loss: [1m[32m0.15369[0m[0m | time: 0.673s
[2K
| Adam | epoch: 017 | loss: 0.15369 - acc: 0.9423 -- iter: 032/342
[A[ATraining Step: 178  | total loss: [1m[32m0.14378[0m[0m | time: 1.327s
[2K
| Adam | epoch: 017 | loss: 0.14378 - acc: 0.9480 -- iter: 064/342
[A[ATraining Step: 179  | total loss: [1m[32m0.13937[0m[0m | time: 1.788s
[2K
| Adam | epoch: 017 | loss: 0.13937 - acc: 0.9470 -- iter: 096/342
[A[ATraining Step: 180  | total loss: [1m[32m0.12773[0m[0m | time: 2.244s
[2K
| Adam | epoch: 017 | loss: 0.12773 - acc: 0.9523 -- iter: 128/342
[A[ATraining Step: 181  | total loss: [1m[32m0.11722[0m[0m | time: 2.908s
[2K
| Adam | epoch: 017 | loss: 0.11722 - acc: 0.9571 -- iter: 160/342
[A[ATraining Step: 182  | total loss: [1m[32m0.10745[0m[0m | time: 3.568s
[2K
| Adam | epoch: 017 | loss: 0.10745 - acc: 0.9613 -- iter: 192/342
[A[ATraining Step: 183  | total loss: [1m[32m0.10620[0m[0m | time: 4.220s
[2K
| Adam | epoch: 017 | loss: 0.10620 - acc: 0.9621 -- iter: 224/342
[A[ATraining Step: 184  | total loss: [1m[32m0.12301[0m[0m | time: 4.871s
[2K
| Adam | epoch: 017 | loss: 0.12301 - acc: 0.9596 -- iter: 256/342
[A[ATraining Step: 185  | total loss: [1m[32m0.11901[0m[0m | time: 5.507s
[2K
| Adam | epoch: 017 | loss: 0.11901 - acc: 0.9605 -- iter: 288/342
[A[ATraining Step: 186  | total loss: [1m[32m0.11358[0m[0m | time: 6.162s
[2K
| Adam | epoch: 017 | loss: 0.11358 - acc: 0.9614 -- iter: 320/342
[A[ATraining Step: 187  | total loss: [1m[32m0.10522[0m[0m | time: 7.837s
[2K
| Adam | epoch: 017 | loss: 0.10522 - acc: 0.9652 | val_loss: 0.51034 - val_acc: 0.8611 -- iter: 342/342
--
Training Step: 188  | total loss: [1m[32m0.09590[0m[0m | time: 0.698s
[2K
| Adam | epoch: 018 | loss: 0.09590 - acc: 0.9687 -- iter: 032/342
[A[ATraining Step: 189  | total loss: [1m[32m0.08779[0m[0m | time: 1.356s
[2K
| Adam | epoch: 018 | loss: 0.08779 - acc: 0.9718 -- iter: 064/342
[A[ATraining Step: 190  | total loss: [1m[32m0.08747[0m[0m | time: 2.024s
[2K
| Adam | epoch: 018 | loss: 0.08747 - acc: 0.9715 -- iter: 096/342
[A[ATraining Step: 191  | total loss: [1m[32m0.11516[0m[0m | time: 2.482s
[2K
| Adam | epoch: 018 | loss: 0.11516 - acc: 0.9650 -- iter: 128/342
[A[ATraining Step: 192  | total loss: [1m[32m0.11036[0m[0m | time: 2.953s
[2K
| Adam | epoch: 018 | loss: 0.11036 - acc: 0.9640 -- iter: 160/342
[A[ATraining Step: 193  | total loss: [1m[32m0.10018[0m[0m | time: 3.632s
[2K
| Adam | epoch: 018 | loss: 0.10018 - acc: 0.9676 -- iter: 192/342
[A[ATraining Step: 194  | total loss: [1m[32m0.10693[0m[0m | time: 4.320s
[2K
| Adam | epoch: 018 | loss: 0.10693 - acc: 0.9677 -- iter: 224/342
[A[ATraining Step: 195  | total loss: [1m[32m0.09882[0m[0m | time: 4.994s
[2K
| Adam | epoch: 018 | loss: 0.09882 - acc: 0.9709 -- iter: 256/342
[A[ATraining Step: 196  | total loss: [1m[32m0.11372[0m[0m | time: 5.648s
[2K
| Adam | epoch: 018 | loss: 0.11372 - acc: 0.9707 -- iter: 288/342
[A[ATraining Step: 197  | total loss: [1m[32m0.10432[0m[0m | time: 6.309s
[2K
| Adam | epoch: 018 | loss: 0.10432 - acc: 0.9736 -- iter: 320/342
[A[ATraining Step: 198  | total loss: [1m[32m0.10315[0m[0m | time: 7.966s
[2K
| Adam | epoch: 018 | loss: 0.10315 - acc: 0.9731 | val_loss: 0.46888 - val_acc: 0.8704 -- iter: 342/342
--
Training Step: 199  | total loss: [1m[32m0.09574[0m[0m | time: 0.661s
[2K
| Adam | epoch: 019 | loss: 0.09574 - acc: 0.9758 -- iter: 032/342
[A[ATraining Step: 200  | total loss: [1m[32m0.10191[0m[0m | time: 2.317s
[2K
| Adam | epoch: 019 | loss: 0.10191 - acc: 0.9720 | val_loss: 0.68778 - val_acc: 0.7222 -- iter: 064/342
--
Training Step: 201  | total loss: [1m[32m0.09327[0m[0m | time: 2.972s
[2K
| Adam | epoch: 019 | loss: 0.09327 - acc: 0.9748 -- iter: 096/342
[A[ATraining Step: 202  | total loss: [1m[32m0.10958[0m[0m | time: 3.619s
[2K
| Adam | epoch: 019 | loss: 0.10958 - acc: 0.9711 -- iter: 128/342
[A[ATraining Step: 203  | total loss: [1m[32m0.10112[0m[0m | time: 4.089s
[2K
| Adam | epoch: 019 | loss: 0.10112 - acc: 0.9740 -- iter: 160/342
[A[ATraining Step: 204  | total loss: [1m[32m0.09238[0m[0m | time: 4.551s
[2K
| Adam | epoch: 019 | loss: 0.09238 - acc: 0.9766 -- iter: 192/342
[A[ATraining Step: 205  | total loss: [1m[32m0.08478[0m[0m | time: 5.207s
[2K
| Adam | epoch: 019 | loss: 0.08478 - acc: 0.9789 -- iter: 224/342
[A[ATraining Step: 206  | total loss: [1m[32m0.08897[0m[0m | time: 5.860s
[2K
| Adam | epoch: 019 | loss: 0.08897 - acc: 0.9779 -- iter: 256/342
[A[ATraining Step: 207  | total loss: [1m[32m0.08159[0m[0m | time: 6.522s
[2K
| Adam | epoch: 019 | loss: 0.08159 - acc: 0.9801 -- iter: 288/342
[A[ATraining Step: 208  | total loss: [1m[32m0.11063[0m[0m | time: 7.203s
[2K
| Adam | epoch: 019 | loss: 0.11063 - acc: 0.9758 -- iter: 320/342
[A[ATraining Step: 209  | total loss: [1m[32m0.10407[0m[0m | time: 8.871s
[2K
| Adam | epoch: 019 | loss: 0.10407 - acc: 0.9783 | val_loss: 0.46585 - val_acc: 0.8241 -- iter: 342/342
--
Training Step: 210  | total loss: [1m[32m0.10488[0m[0m | time: 1.378s
[2K
| Adam | epoch: 020 | loss: 0.10488 - acc: 0.9742 -- iter: 032/342
[A[ATraining Step: 211  | total loss: [1m[32m0.09585[0m[0m | time: 2.422s
[2K
| Adam | epoch: 020 | loss: 0.09585 - acc: 0.9768 -- iter: 064/342
[A[ATraining Step: 212  | total loss: [1m[32m0.08838[0m[0m | time: 3.430s
[2K
| Adam | epoch: 020 | loss: 0.08838 - acc: 0.9791 -- iter: 096/342
[A[ATraining Step: 213  | total loss: [1m[32m0.08342[0m[0m | time: 4.592s
[2K
| Adam | epoch: 020 | loss: 0.08342 - acc: 0.9812 -- iter: 128/342
[A[ATraining Step: 214  | total loss: [1m[32m0.08457[0m[0m | time: 5.771s
[2K
| Adam | epoch: 020 | loss: 0.08457 - acc: 0.9799 -- iter: 160/342
[A[ATraining Step: 215  | total loss: [1m[32m0.09162[0m[0m | time: 6.601s
[2K
| Adam | epoch: 020 | loss: 0.09162 - acc: 0.9788 -- iter: 192/342
[A[ATraining Step: 216  | total loss: [1m[32m0.08325[0m[0m | time: 7.610s
[2K
| Adam | epoch: 020 | loss: 0.08325 - acc: 0.9809 -- iter: 224/342
[A[ATraining Step: 217  | total loss: [1m[32m0.07562[0m[0m | time: 8.970s
[2K
| Adam | epoch: 020 | loss: 0.07562 - acc: 0.9828 -- iter: 256/342
[A[ATraining Step: 218  | total loss: [1m[32m0.09299[0m[0m | time: 10.001s
[2K
| Adam | epoch: 020 | loss: 0.09299 - acc: 0.9752 -- iter: 288/342
[A[ATraining Step: 219  | total loss: [1m[32m0.08601[0m[0m | time: 10.662s
[2K
| Adam | epoch: 020 | loss: 0.08601 - acc: 0.9777 -- iter: 320/342
[A[ATraining Step: 220  | total loss: [1m[32m0.10863[0m[0m | time: 12.336s
[2K
| Adam | epoch: 020 | loss: 0.10863 - acc: 0.9736 | val_loss: 0.39843 - val_acc: 0.8889 -- iter: 342/342
--
Training Step: 221  | total loss: [1m[32m0.10020[0m[0m | time: 1.252s
[2K
| Adam | epoch: 021 | loss: 0.10020 - acc: 0.9763 -- iter: 032/342
[A[ATraining Step: 222  | total loss: [1m[32m0.09209[0m[0m | time: 2.250s
[2K
| Adam | epoch: 021 | loss: 0.09209 - acc: 0.9787 -- iter: 064/342
[A[ATraining Step: 223  | total loss: [1m[32m0.08523[0m[0m | time: 3.356s
[2K
| Adam | epoch: 021 | loss: 0.08523 - acc: 0.9808 -- iter: 096/342
[A[ATraining Step: 224  | total loss: [1m[32m0.07939[0m[0m | time: 4.464s
[2K
| Adam | epoch: 021 | loss: 0.07939 - acc: 0.9827 -- iter: 128/342
[A[ATraining Step: 225  | total loss: [1m[32m0.07339[0m[0m | time: 5.593s
[2K
| Adam | epoch: 021 | loss: 0.07339 - acc: 0.9844 -- iter: 160/342
[A[ATraining Step: 226  | total loss: [1m[32m0.07615[0m[0m | time: 6.891s
[2K
| Adam | epoch: 021 | loss: 0.07615 - acc: 0.9829 -- iter: 192/342
[A[ATraining Step: 227  | total loss: [1m[32m0.07071[0m[0m | time: 7.976s
[2K
| Adam | epoch: 021 | loss: 0.07071 - acc: 0.9846 -- iter: 224/342
[A[ATraining Step: 228  | total loss: [1m[32m0.08191[0m[0m | time: 8.823s
[2K
| Adam | epoch: 021 | loss: 0.08191 - acc: 0.9816 -- iter: 256/342
[A[ATraining Step: 229  | total loss: [1m[32m0.08964[0m[0m | time: 9.884s
[2K
| Adam | epoch: 021 | loss: 0.08964 - acc: 0.9789 -- iter: 288/342
[A[ATraining Step: 230  | total loss: [1m[32m0.08263[0m[0m | time: 11.427s
[2K
| Adam | epoch: 021 | loss: 0.08263 - acc: 0.9810 -- iter: 320/342
[A[ATraining Step: 231  | total loss: [1m[32m0.07827[0m[0m | time: 13.729s
[2K
| Adam | epoch: 021 | loss: 0.07827 - acc: 0.9829 | val_loss: 0.50998 - val_acc: 0.8241 -- iter: 342/342
--
Training Step: 232  | total loss: [1m[32m0.07811[0m[0m | time: 1.093s
[2K
| Adam | epoch: 022 | loss: 0.07811 - acc: 0.9784 -- iter: 032/342
[A[ATraining Step: 233  | total loss: [1m[32m0.07211[0m[0m | time: 2.267s
[2K
| Adam | epoch: 022 | loss: 0.07211 - acc: 0.9805 -- iter: 064/342
[A[ATraining Step: 234  | total loss: [1m[32m0.06681[0m[0m | time: 3.407s
[2K
| Adam | epoch: 022 | loss: 0.06681 - acc: 0.9825 -- iter: 096/342
[A[ATraining Step: 235  | total loss: [1m[32m0.06349[0m[0m | time: 4.698s
[2K
| Adam | epoch: 022 | loss: 0.06349 - acc: 0.9842 -- iter: 128/342
[A[ATraining Step: 236  | total loss: [1m[32m0.06592[0m[0m | time: 6.237s
[2K
| Adam | epoch: 022 | loss: 0.06592 - acc: 0.9827 -- iter: 160/342
[A[ATraining Step: 237  | total loss: [1m[32m0.07091[0m[0m | time: 7.304s
[2K
| Adam | epoch: 022 | loss: 0.07091 - acc: 0.9813 -- iter: 192/342
[A[ATraining Step: 238  | total loss: [1m[32m0.07578[0m[0m | time: 8.504s
[2K
| Adam | epoch: 022 | loss: 0.07578 - acc: 0.9800 -- iter: 224/342
[A[ATraining Step: 239  | total loss: [1m[32m0.07139[0m[0m | time: 9.591s
[2K
| Adam | epoch: 022 | loss: 0.07139 - acc: 0.9820 -- iter: 256/342
[A[ATraining Step: 240  | total loss: [1m[32m0.12057[0m[0m | time: 10.545s
[2K
| Adam | epoch: 022 | loss: 0.12057 - acc: 0.9611 -- iter: 288/342
[A[ATraining Step: 241  | total loss: [1m[32m0.14392[0m[0m | time: 11.943s
[2K
| Adam | epoch: 022 | loss: 0.14392 - acc: 0.9604 -- iter: 320/342
[A[ATraining Step: 242  | total loss: [1m[32m0.13118[0m[0m | time: 13.966s
[2K
| Adam | epoch: 022 | loss: 0.13118 - acc: 0.9644 | val_loss: 0.80476 - val_acc: 0.6944 -- iter: 342/342
--
Training Step: 243  | total loss: [1m[32m0.11894[0m[0m | time: 1.257s
[2K
| Adam | epoch: 023 | loss: 0.11894 - acc: 0.9680 -- iter: 032/342
[A[ATraining Step: 244  | total loss: [1m[32m0.11040[0m[0m | time: 2.725s
[2K
| Adam | epoch: 023 | loss: 0.11040 - acc: 0.9712 -- iter: 064/342
[A[ATraining Step: 245  | total loss: [1m[32m0.10503[0m[0m | time: 3.763s
[2K
| Adam | epoch: 023 | loss: 0.10503 - acc: 0.9709 -- iter: 096/342
[A[ATraining Step: 246  | total loss: [1m[32m0.11034[0m[0m | time: 4.956s
[2K
| Adam | epoch: 023 | loss: 0.11034 - acc: 0.9707 -- iter: 128/342
[A[ATraining Step: 247  | total loss: [1m[32m0.11177[0m[0m | time: 6.338s
[2K
| Adam | epoch: 023 | loss: 0.11177 - acc: 0.9705 -- iter: 160/342
[A[ATraining Step: 248  | total loss: [1m[32m0.10234[0m[0m | time: 7.708s
[2K
| Adam | epoch: 023 | loss: 0.10234 - acc: 0.9735 -- iter: 192/342
[A[ATraining Step: 249  | total loss: [1m[32m0.09328[0m[0m | time: 8.999s
[2K
| Adam | epoch: 023 | loss: 0.09328 - acc: 0.9761 -- iter: 224/342
[A[ATraining Step: 250  | total loss: [1m[32m0.08670[0m[0m | time: 9.915s
[2K
| Adam | epoch: 023 | loss: 0.08670 - acc: 0.9785 -- iter: 256/342
[A[ATraining Step: 251  | total loss: [1m[32m0.08123[0m[0m | time: 10.691s
[2K
| Adam | epoch: 023 | loss: 0.08123 - acc: 0.9806 -- iter: 288/342
[A[ATraining Step: 252  | total loss: [1m[32m0.07865[0m[0m | time: 11.553s
[2K
| Adam | epoch: 023 | loss: 0.07865 - acc: 0.9780 -- iter: 320/342
[A[ATraining Step: 253  | total loss: [1m[32m0.07218[0m[0m | time: 13.756s
[2K
| Adam | epoch: 023 | loss: 0.07218 - acc: 0.9802 | val_loss: 0.53604 - val_acc: 0.8241 -- iter: 342/342
--
Training Step: 254  | total loss: [1m[32m0.07084[0m[0m | time: 1.000s
[2K
| Adam | epoch: 024 | loss: 0.07084 - acc: 0.9791 -- iter: 032/342
[A[ATraining Step: 255  | total loss: [1m[32m0.06444[0m[0m | time: 2.500s
[2K
| Adam | epoch: 024 | loss: 0.06444 - acc: 0.9812 -- iter: 064/342
[A[ATraining Step: 256  | total loss: [1m[32m0.10937[0m[0m | time: 3.851s
[2K
| Adam | epoch: 024 | loss: 0.10937 - acc: 0.9737 -- iter: 096/342
[A[ATraining Step: 257  | total loss: [1m[32m0.09960[0m[0m | time: 5.244s
[2K
| Adam | epoch: 024 | loss: 0.09960 - acc: 0.9763 -- iter: 128/342
[A[ATraining Step: 258  | total loss: [1m[32m0.09117[0m[0m | time: 6.197s
[2K
| Adam | epoch: 024 | loss: 0.09117 - acc: 0.9787 -- iter: 160/342
[A[ATraining Step: 259  | total loss: [1m[32m0.08544[0m[0m | time: 7.237s
[2K
| Adam | epoch: 024 | loss: 0.08544 - acc: 0.9808 -- iter: 192/342
[A[ATraining Step: 260  | total loss: [1m[32m0.07812[0m[0m | time: 8.403s
[2K
| Adam | epoch: 024 | loss: 0.07812 - acc: 0.9827 -- iter: 224/342
[A[ATraining Step: 261  | total loss: [1m[32m0.07124[0m[0m | time: 9.504s
[2K
| Adam | epoch: 024 | loss: 0.07124 - acc: 0.9845 -- iter: 256/342
[A[ATraining Step: 262  | total loss: [1m[32m0.07262[0m[0m | time: 10.731s
[2K
| Adam | epoch: 024 | loss: 0.07262 - acc: 0.9829 -- iter: 288/342
[A[ATraining Step: 263  | total loss: [1m[32m0.06638[0m[0m | time: 11.824s
[2K
| Adam | epoch: 024 | loss: 0.06638 - acc: 0.9846 -- iter: 320/342
[A[ATraining Step: 264  | total loss: [1m[32m0.06039[0m[0m | time: 13.783s
[2K
| Adam | epoch: 024 | loss: 0.06039 - acc: 0.9861 | val_loss: 0.53059 - val_acc: 0.8611 -- iter: 342/342
--
Training Step: 265  | total loss: [1m[32m0.05515[0m[0m | time: 1.345s
[2K
| Adam | epoch: 025 | loss: 0.05515 - acc: 0.9875 -- iter: 032/342
[A[ATraining Step: 266  | total loss: [1m[32m0.07929[0m[0m | time: 2.717s
[2K
| Adam | epoch: 025 | loss: 0.07929 - acc: 0.9763 -- iter: 064/342
[A[ATraining Step: 267  | total loss: [1m[32m0.07778[0m[0m | time: 3.730s
[2K
| Adam | epoch: 025 | loss: 0.07778 - acc: 0.9755 -- iter: 096/342
[A[ATraining Step: 268  | total loss: [1m[32m0.15880[0m[0m | time: 4.839s
[2K
| Adam | epoch: 025 | loss: 0.15880 - acc: 0.9592 -- iter: 128/342
[A[ATraining Step: 269  | total loss: [1m[32m0.14542[0m[0m | time: 6.027s
[2K
| Adam | epoch: 025 | loss: 0.14542 - acc: 0.9633 -- iter: 160/342
[A[ATraining Step: 270  | total loss: [1m[32m0.13333[0m[0m | time: 7.201s
[2K
| Adam | epoch: 025 | loss: 0.13333 - acc: 0.9670 -- iter: 192/342
[A[ATraining Step: 271  | total loss: [1m[32m0.13328[0m[0m | time: 8.412s
[2K
| Adam | epoch: 025 | loss: 0.13328 - acc: 0.9640 -- iter: 224/342
[A[ATraining Step: 272  | total loss: [1m[32m0.12786[0m[0m | time: 9.975s
[2K
| Adam | epoch: 025 | loss: 0.12786 - acc: 0.9645 -- iter: 256/342
[A[ATraining Step: 273  | total loss: [1m[32m0.13136[0m[0m | time: 11.051s
[2K
| Adam | epoch: 025 | loss: 0.13136 - acc: 0.9649 -- iter: 288/342
[A[ATraining Step: 274  | total loss: [1m[32m0.12292[0m[0m | time: 12.185s
[2K
| Adam | epoch: 025 | loss: 0.12292 - acc: 0.9684 -- iter: 320/342
[A[ATraining Step: 275  | total loss: [1m[32m0.11688[0m[0m | time: 14.346s
[2K
| Adam | epoch: 025 | loss: 0.11688 - acc: 0.9716 | val_loss: 0.37432 - val_acc: 0.8426 -- iter: 342/342
--
Training Step: 276  | total loss: [1m[32m0.11367[0m[0m | time: 0.642s
[2K
| Adam | epoch: 026 | loss: 0.11367 - acc: 0.9744 -- iter: 032/342
[A[ATraining Step: 277  | total loss: [1m[32m0.10931[0m[0m | time: 1.711s
[2K
| Adam | epoch: 026 | loss: 0.10931 - acc: 0.9770 -- iter: 064/342
[A[ATraining Step: 278  | total loss: [1m[32m0.10283[0m[0m | time: 2.883s
[2K
| Adam | epoch: 026 | loss: 0.10283 - acc: 0.9793 -- iter: 096/342
[A[ATraining Step: 279  | total loss: [1m[32m0.09623[0m[0m | time: 4.009s
[2K
| Adam | epoch: 026 | loss: 0.09623 - acc: 0.9814 -- iter: 128/342
[A[ATraining Step: 280  | total loss: [1m[32m0.08826[0m[0m | time: 5.305s
[2K
| Adam | epoch: 026 | loss: 0.08826 - acc: 0.9832 -- iter: 160/342
[A[ATraining Step: 281  | total loss: [1m[32m0.08132[0m[0m | time: 6.761s
[2K
| Adam | epoch: 026 | loss: 0.08132 - acc: 0.9849 -- iter: 192/342
[A[ATraining Step: 282  | total loss: [1m[32m0.07456[0m[0m | time: 7.818s
[2K
| Adam | epoch: 026 | loss: 0.07456 - acc: 0.9864 -- iter: 224/342
[A[ATraining Step: 283  | total loss: [1m[32m0.06832[0m[0m | time: 9.040s
[2K
| Adam | epoch: 026 | loss: 0.06832 - acc: 0.9878 -- iter: 256/342
[A[ATraining Step: 284  | total loss: [1m[32m0.06211[0m[0m | time: 10.455s
[2K
| Adam | epoch: 026 | loss: 0.06211 - acc: 0.9890 -- iter: 288/342
[A[ATraining Step: 285  | total loss: [1m[32m0.05659[0m[0m | time: 11.758s
[2K
| Adam | epoch: 026 | loss: 0.05659 - acc: 0.9901 -- iter: 320/342
[A[ATraining Step: 286  | total loss: [1m[32m0.05125[0m[0m | time: 13.969s
[2K
| Adam | epoch: 026 | loss: 0.05125 - acc: 0.9911 | val_loss: 0.66986 - val_acc: 0.8056 -- iter: 342/342
--
Training Step: 287  | total loss: [1m[32m0.06820[0m[0m | time: 0.857s
[2K
| Adam | epoch: 027 | loss: 0.06820 - acc: 0.9888 -- iter: 032/342
[A[ATraining Step: 288  | total loss: [1m[32m0.06150[0m[0m | time: 1.740s
[2K
| Adam | epoch: 027 | loss: 0.06150 - acc: 0.9900 -- iter: 064/342
[A[ATraining Step: 289  | total loss: [1m[32m0.05549[0m[0m | time: 3.260s
[2K
| Adam | epoch: 027 | loss: 0.05549 - acc: 0.9910 -- iter: 096/342
[A[ATraining Step: 290  | total loss: [1m[32m0.05042[0m[0m | time: 4.365s
[2K
| Adam | epoch: 027 | loss: 0.05042 - acc: 0.9919 -- iter: 128/342
[A[ATraining Step: 291  | total loss: [1m[32m0.04751[0m[0m | time: 5.098s
[2K
| Adam | epoch: 027 | loss: 0.04751 - acc: 0.9927 -- iter: 160/342
[A[ATraining Step: 292  | total loss: [1m[32m0.08431[0m[0m | time: 5.737s
[2K
| Adam | epoch: 027 | loss: 0.08431 - acc: 0.9872 -- iter: 192/342
[A[ATraining Step: 293  | total loss: [1m[32m0.07608[0m[0m | time: 6.395s
[2K
| Adam | epoch: 027 | loss: 0.07608 - acc: 0.9884 -- iter: 224/342
[A[ATraining Step: 294  | total loss: [1m[32m0.06943[0m[0m | time: 7.041s
[2K
| Adam | epoch: 027 | loss: 0.06943 - acc: 0.9896 -- iter: 256/342
[A[ATraining Step: 295  | total loss: [1m[32m0.06343[0m[0m | time: 7.693s
[2K
| Adam | epoch: 027 | loss: 0.06343 - acc: 0.9906 -- iter: 288/342
[A[ATraining Step: 296  | total loss: [1m[32m0.06132[0m[0m | time: 8.345s
[2K
| Adam | epoch: 027 | loss: 0.06132 - acc: 0.9916 -- iter: 320/342
[A[ATraining Step: 297  | total loss: [1m[32m0.05572[0m[0m | time: 10.006s
[2K
| Adam | epoch: 027 | loss: 0.05572 - acc: 0.9924 | val_loss: 0.51919 - val_acc: 0.8241 -- iter: 342/342
--
Training Step: 298  | total loss: [1m[32m0.05056[0m[0m | time: 1.230s
[2K
| Adam | epoch: 028 | loss: 0.05056 - acc: 0.9932 -- iter: 032/342
[A[ATraining Step: 299  | total loss: [1m[32m0.04597[0m[0m | time: 2.215s
[2K
| Adam | epoch: 028 | loss: 0.04597 - acc: 0.9939 -- iter: 064/342
[A[ATraining Step: 300  | total loss: [1m[32m0.04201[0m[0m | time: 3.028s
[2K
| Adam | epoch: 028 | loss: 0.04201 - acc: 0.9945 -- iter: 096/342
[A[ATraining Step: 301  | total loss: [1m[32m0.03855[0m[0m | time: 4.321s
[2K
| Adam | epoch: 028 | loss: 0.03855 - acc: 0.9950 -- iter: 128/342
[A[ATraining Step: 302  | total loss: [1m[32m0.03661[0m[0m | time: 5.255s
[2K
| Adam | epoch: 028 | loss: 0.03661 - acc: 0.9955 -- iter: 160/342
[A[ATraining Step: 303  | total loss: [1m[32m0.03353[0m[0m | time: 5.902s
[2K
| Adam | epoch: 028 | loss: 0.03353 - acc: 0.9960 -- iter: 192/342
[A[ATraining Step: 304  | total loss: [1m[32m0.14083[0m[0m | time: 6.572s
[2K
| Adam | epoch: 028 | loss: 0.14083 - acc: 0.9745 -- iter: 224/342
[A[ATraining Step: 305  | total loss: [1m[32m0.13212[0m[0m | time: 7.233s
[2K
| Adam | epoch: 028 | loss: 0.13212 - acc: 0.9739 -- iter: 256/342
[A[ATraining Step: 306  | total loss: [1m[32m0.12806[0m[0m | time: 7.859s
[2K
| Adam | epoch: 028 | loss: 0.12806 - acc: 0.9734 -- iter: 288/342
[A[ATraining Step: 307  | total loss: [1m[32m0.11738[0m[0m | time: 8.531s
[2K
| Adam | epoch: 028 | loss: 0.11738 - acc: 0.9761 -- iter: 320/342
[A[ATraining Step: 308  | total loss: [1m[32m0.10896[0m[0m | time: 10.189s
[2K
| Adam | epoch: 028 | loss: 0.10896 - acc: 0.9785 | val_loss: 0.38431 - val_acc: 0.8611 -- iter: 342/342
--
Training Step: 309  | total loss: [1m[32m0.10093[0m[0m | time: 0.680s
[2K
| Adam | epoch: 029 | loss: 0.10093 - acc: 0.9806 -- iter: 032/342
[A[ATraining Step: 310  | total loss: [1m[32m0.09303[0m[0m | time: 1.342s
[2K
| Adam | epoch: 029 | loss: 0.09303 - acc: 0.9826 -- iter: 064/342
[A[ATraining Step: 311  | total loss: [1m[32m0.08914[0m[0m | time: 1.792s
[2K
| Adam | epoch: 029 | loss: 0.08914 - acc: 0.9812 -- iter: 096/342
[A[ATraining Step: 312  | total loss: [1m[32m0.08275[0m[0m | time: 2.263s
[2K
| Adam | epoch: 029 | loss: 0.08275 - acc: 0.9831 -- iter: 128/342
[A[ATraining Step: 313  | total loss: [1m[32m0.07678[0m[0m | time: 2.929s
[2K
| Adam | epoch: 029 | loss: 0.07678 - acc: 0.9847 -- iter: 160/342
[A[ATraining Step: 314  | total loss: [1m[32m0.07166[0m[0m | time: 3.596s
[2K
| Adam | epoch: 029 | loss: 0.07166 - acc: 0.9863 -- iter: 192/342
[A[ATraining Step: 315  | total loss: [1m[32m0.06777[0m[0m | time: 4.268s
[2K
| Adam | epoch: 029 | loss: 0.06777 - acc: 0.9876 -- iter: 224/342
[A[ATraining Step: 316  | total loss: [1m[32m0.10837[0m[0m | time: 4.934s
[2K
| Adam | epoch: 029 | loss: 0.10837 - acc: 0.9795 -- iter: 256/342
[A[ATraining Step: 317  | total loss: [1m[32m0.10105[0m[0m | time: 5.594s
[2K
| Adam | epoch: 029 | loss: 0.10105 - acc: 0.9816 -- iter: 288/342
[A[ATraining Step: 318  | total loss: [1m[32m0.09384[0m[0m | time: 6.271s
[2K
| Adam | epoch: 029 | loss: 0.09384 - acc: 0.9834 -- iter: 320/342
[A[ATraining Step: 319  | total loss: [1m[32m0.10295[0m[0m | time: 7.938s
[2K
| Adam | epoch: 029 | loss: 0.10295 - acc: 0.9819 | val_loss: 0.45577 - val_acc: 0.8519 -- iter: 342/342
--
Training Step: 320  | total loss: [1m[32m0.09440[0m[0m | time: 0.672s
[2K
| Adam | epoch: 030 | loss: 0.09440 - acc: 0.9837 -- iter: 032/342
[A[ATraining Step: 321  | total loss: [1m[32m0.08677[0m[0m | time: 1.324s
[2K
| Adam | epoch: 030 | loss: 0.08677 - acc: 0.9854 -- iter: 064/342
[A[ATraining Step: 322  | total loss: [1m[32m0.08035[0m[0m | time: 2.010s
[2K
| Adam | epoch: 030 | loss: 0.08035 - acc: 0.9868 -- iter: 096/342
[A[ATraining Step: 323  | total loss: [1m[32m0.07414[0m[0m | time: 2.474s
[2K
| Adam | epoch: 030 | loss: 0.07414 - acc: 0.9881 -- iter: 128/342
[A[ATraining Step: 324  | total loss: [1m[32m0.07070[0m[0m | time: 2.959s
[2K
| Adam | epoch: 030 | loss: 0.07070 - acc: 0.9893 -- iter: 160/342
[A[ATraining Step: 325  | total loss: [1m[32m0.06531[0m[0m | time: 3.624s
[2K
| Adam | epoch: 030 | loss: 0.06531 - acc: 0.9904 -- iter: 192/342
[A[ATraining Step: 326  | total loss: [1m[32m0.05990[0m[0m | time: 4.297s
[2K
| Adam | epoch: 030 | loss: 0.05990 - acc: 0.9914 -- iter: 224/342
[A[ATraining Step: 327  | total loss: [1m[32m0.05661[0m[0m | time: 4.969s
[2K
| Adam | epoch: 030 | loss: 0.05661 - acc: 0.9922 -- iter: 256/342
[A[ATraining Step: 328  | total loss: [1m[32m0.05353[0m[0m | time: 5.630s
[2K
| Adam | epoch: 030 | loss: 0.05353 - acc: 0.9930 -- iter: 288/342
[A[ATraining Step: 329  | total loss: [1m[32m0.04935[0m[0m | time: 6.319s
[2K
| Adam | epoch: 030 | loss: 0.04935 - acc: 0.9937 -- iter: 320/342
[A[ATraining Step: 330  | total loss: [1m[32m0.04513[0m[0m | time: 8.001s
[2K
| Adam | epoch: 030 | loss: 0.04513 - acc: 0.9943 | val_loss: 0.47107 - val_acc: 0.8704 -- iter: 342/342
--
Validation AUC:0.9236111111111112
Validation AUPRC:0.9246695728830395
Test AUC:0.9315115876859218
Test AUPRC:0.9431980898281566
BestTestF1Score	0.85	0.72	0.86	0.83	0.88	43	9	50	6	0.47
BestTestMCCScore	0.87	0.78	0.89	0.95	0.8	39	2	57	10	0.93
BestTestAccuracyScore	0.87	0.78	0.89	0.95	0.8	39	2	57	10	0.93
BestValidationF1Score	0.87	0.76	0.88	0.84	0.9	43	8	52	5	0.47
BestValidationMCC	0.85	0.76	0.88	0.93	0.79	38	3	57	10	0.93
BestValidationAccuracy	0.85	0.76	0.88	0.93	0.79	38	3	57	10	0.93
TestPredictions (Threshold:0.93)
CHEMBL3658390,FN,ACT,0.6600000262260437	CHEMBL504657,TN,INACT,0.0	CHEMBL506502,TN,INACT,0.0	CHEMBL362184,TP,ACT,1.0	CHEMBL64708,TN,INACT,0.0	CHEMBL181116,TP,ACT,0.9900000095367432	CHEMBL3654416,TP,ACT,0.9700000286102295	CHEMBL1462676,TN,INACT,0.03999999910593033	CHEMBL3421647,TP,ACT,0.9800000190734863	CHEMBL175779,TN,INACT,0.009999999776482582	CHEMBL206335,TP,ACT,0.9599999785423279	CHEMBL128685,TN,INACT,0.0	CHEMBL3408419,TN,INACT,0.0	CHEMBL598191,FN,ACT,0.8799999952316284	CHEMBL105920,TN,INACT,0.8999999761581421	CHEMBL3629109,TP,ACT,1.0	CHEMBL2003901,TN,INACT,0.03999999910593033	CHEMBL2372696,TN,INACT,0.009999999776482582	CHEMBL3423054,TP,ACT,0.9900000095367432	CHEMBL2159294,TN,INACT,0.009999999776482582	CHEMBL1571193,TN,INACT,0.03999999910593033	CHEMBL2159291,TN,INACT,0.0	CHEMBL367575,TP,ACT,0.9800000190734863	CHEMBL597759,TP,ACT,0.9900000095367432	CHEMBL605564,TP,ACT,1.0	CHEMBL3628962,TP,ACT,0.9900000095367432	CHEMBL598370,TP,ACT,0.9300000071525574	CHEMBL3423045,TP,ACT,0.9900000095367432	CHEMBL68169,TN,INACT,0.0	CHEMBL3628958,TP,ACT,1.0	CHEMBL279367,TN,INACT,0.05000000074505806	CHEMBL290025,TN,INACT,0.18000000715255737	CHEMBL433179,TN,INACT,0.0	CHEMBL3099875,TN,INACT,0.009999999776482582	CHEMBL309394,TN,INACT,0.8399999737739563	CHEMBL604289,TP,ACT,1.0	CHEMBL2159303,TN,INACT,0.0	CHEMBL361327,TP,ACT,0.9800000190734863	CHEMBL3423051,TP,ACT,0.9900000095367432	CHEMBL604500,TP,ACT,1.0	CHEMBL182800,FN,ACT,0.03999999910593033	CHEMBL1409121,TN,INACT,0.009999999776482582	CHEMBL339878,TN,INACT,0.0	CHEMBL2372455,TN,INACT,0.0	CHEMBL292235,TN,INACT,0.18000000715255737	CHEMBL1612826,TN,INACT,0.46000000834465027	CHEMBL350048,TN,INACT,0.05000000074505806	CHEMBL1733342,TN,INACT,0.009999999776482582	CHEMBL3423033,TP,ACT,0.9800000190734863	CHEMBL598384,FN,ACT,0.009999999776482582	CHEMBL1360994,TN,INACT,0.2800000011920929	CHEMBL1441135,TN,INACT,0.4300000071525574	CHEMBL92964,TN,INACT,0.009999999776482582	CHEMBL3143648,TN,INACT,0.009999999776482582	CHEMBL345710,TN,INACT,0.009999999776482582	CHEMBL254439,TN,INACT,0.6700000166893005	CHEMBL2417895,TP,ACT,0.9900000095367432	CHEMBL596766,TP,ACT,0.9900000095367432	CHEMBL596950,TP,ACT,0.9700000286102295	CHEMBL1532234,TN,INACT,0.019999999552965164	CHEMBL204084,TN,INACT,0.0	CHEMBL597376,TP,ACT,1.0	CHEMBL603670,TP,ACT,0.9900000095367432	CHEMBL1812021,TN,INACT,0.5199999809265137	CHEMBL3423031,TN,INACT,0.8799999952316284	CHEMBL281719,TN,INACT,0.2199999988079071	CHEMBL3423028,FP,INACT,0.9599999785423279	CHEMBL1339887,TN,INACT,0.0	CHEMBL1413681,TN,INACT,0.0	CHEMBL3628834,FN,ACT,0.009999999776482582	CHEMBL3627871,TP,ACT,1.0	CHEMBL3627868,TP,ACT,1.0	CHEMBL186693,TP,ACT,0.9700000286102295	CHEMBL3628960,TP,ACT,1.0	CHEMBL3085154,TN,INACT,0.03999999910593033	CHEMBL364580,TP,ACT,0.9800000190734863	CHEMBL2029056,TN,INACT,0.0	CHEMBL2159390,TN,INACT,0.019999999552965164	CHEMBL212401,TN,INACT,0.8399999737739563	CHEMBL1744048,TN,INACT,0.0	CHEMBL3628833,FN,ACT,0.5199999809265137	CHEMBL3629112,TP,ACT,1.0	CHEMBL601018,TP,ACT,0.9900000095367432	CHEMBL598383,FN,ACT,0.10000000149011612	CHEMBL3423049,FN,ACT,0.009999999776482582	CHEMBL302913,TN,INACT,0.0	CHEMBL363962,TP,ACT,1.0	CHEMBL604294,TP,ACT,0.9900000095367432	CHEMBL3109168,TN,INACT,0.0	CHEMBL1160813,TN,INACT,0.009999999776482582	CHEMBL1744051,TN,INACT,0.0	CHEMBL183417,TP,ACT,0.9700000286102295	CHEMBL3627899,TP,ACT,0.9900000095367432	CHEMBL2372656,FP,INACT,0.9399999976158142	CHEMBL294326,TN,INACT,0.0	CHEMBL3628837,TP,ACT,0.9900000095367432	CHEMBL2159391,TN,INACT,0.019999999552965164	CHEMBL599415,TP,ACT,0.9900000095367432	CHEMBL3628964,TP,ACT,0.9900000095367432	CHEMBL3423029,TN,INACT,0.7099999785423279	CHEMBL295786,TN,INACT,0.019999999552965164	CHEMBL40380,TN,INACT,0.0	CHEMBL3408416,TN,INACT,0.0	CHEMBL1468612,TN,INACT,0.07999999821186066	CHEMBL3423057,FN,ACT,0.8999999761581421	CHEMBL1927662,TN,INACT,0.14000000059604645	CHEMBL3628955,FN,ACT,0.0	CHEMBL186900,TP,ACT,1.0	

