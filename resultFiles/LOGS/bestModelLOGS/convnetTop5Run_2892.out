CNNModel CHEMBL4101 adam 0.001 30 128 0 0.8 False True
Number of active compounds :	110
Number of inactive compounds :	110
---------------------------------
Run id: CNNModel_CHEMBL4101_adam_0.001_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4101_adam_0.001_30_128_0.8_True/
---------------------------------
Training samples: 140
Validation samples: 44
--
Training Step: 1  | time: 1.313s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/140
[A[ATraining Step: 2  | total loss: [1m[32m0.62362[0m[0m | time: 2.112s
[2K
| Adam | epoch: 001 | loss: 0.62362 - acc: 0.5062 -- iter: 064/140
[A[ATraining Step: 3  | total loss: [1m[32m0.68051[0m[0m | time: 2.978s
[2K
| Adam | epoch: 001 | loss: 0.68051 - acc: 0.5011 -- iter: 096/140
[A[ATraining Step: 4  | total loss: [1m[32m0.69217[0m[0m | time: 3.872s
[2K
| Adam | epoch: 001 | loss: 0.69217 - acc: 0.4534 -- iter: 128/140
[A[ATraining Step: 5  | total loss: [1m[32m0.69491[0m[0m | time: 5.257s
[2K
| Adam | epoch: 001 | loss: 0.69491 - acc: 0.3991 | val_loss: 0.69352 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 6  | total loss: [1m[32m0.69417[0m[0m | time: 0.344s
[2K
| Adam | epoch: 002 | loss: 0.69417 - acc: 0.3568 -- iter: 032/140
[A[ATraining Step: 7  | total loss: [1m[32m0.69461[0m[0m | time: 1.212s
[2K
| Adam | epoch: 002 | loss: 0.69461 - acc: 0.2427 -- iter: 064/140
[A[ATraining Step: 8  | total loss: [1m[32m0.69378[0m[0m | time: 2.249s
[2K
| Adam | epoch: 002 | loss: 0.69378 - acc: 0.3523 -- iter: 096/140
[A[ATraining Step: 9  | total loss: [1m[32m0.69349[0m[0m | time: 3.374s
[2K
| Adam | epoch: 002 | loss: 0.69349 - acc: 0.4636 -- iter: 128/140
[A[ATraining Step: 10  | total loss: [1m[32m0.69318[0m[0m | time: 5.131s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5755 | val_loss: 0.69386 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 11  | total loss: [1m[32m0.69303[0m[0m | time: 0.355s
[2K
| Adam | epoch: 003 | loss: 0.69303 - acc: 0.5694 -- iter: 032/140
[A[ATraining Step: 12  | total loss: [1m[32m0.69331[0m[0m | time: 0.686s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.5006 -- iter: 064/140
[A[ATraining Step: 13  | total loss: [1m[32m0.69351[0m[0m | time: 1.570s
[2K
| Adam | epoch: 003 | loss: 0.69351 - acc: 0.4647 -- iter: 096/140
[A[ATraining Step: 14  | total loss: [1m[32m0.69311[0m[0m | time: 2.391s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5175 -- iter: 128/140
[A[ATraining Step: 15  | total loss: [1m[32m0.69324[0m[0m | time: 4.291s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4862 | val_loss: 0.69379 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 16  | total loss: [1m[32m0.69302[0m[0m | time: 0.883s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5265 -- iter: 032/140
[A[ATraining Step: 17  | total loss: [1m[32m0.69275[0m[0m | time: 1.259s
[2K
| Adam | epoch: 004 | loss: 0.69275 - acc: 0.5620 -- iter: 064/140
[A[ATraining Step: 18  | total loss: [1m[32m0.69238[0m[0m | time: 1.625s
[2K
| Adam | epoch: 004 | loss: 0.69238 - acc: 0.5982 -- iter: 096/140
[A[ATraining Step: 19  | total loss: [1m[32m0.69180[0m[0m | time: 2.454s
[2K
| Adam | epoch: 004 | loss: 0.69180 - acc: 0.6210 -- iter: 128/140
[A[ATraining Step: 20  | total loss: [1m[32m0.69200[0m[0m | time: 4.321s
[2K
| Adam | epoch: 004 | loss: 0.69200 - acc: 0.5922 | val_loss: 0.69644 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 21  | total loss: [1m[32m0.69358[0m[0m | time: 1.221s
[2K
| Adam | epoch: 005 | loss: 0.69358 - acc: 0.5248 -- iter: 032/140
[A[ATraining Step: 22  | total loss: [1m[32m0.69261[0m[0m | time: 2.035s
[2K
| Adam | epoch: 005 | loss: 0.69261 - acc: 0.5455 -- iter: 064/140
[A[ATraining Step: 23  | total loss: [1m[32m0.69244[0m[0m | time: 2.348s
[2K
| Adam | epoch: 005 | loss: 0.69244 - acc: 0.5413 -- iter: 096/140
[A[ATraining Step: 24  | total loss: [1m[32m0.69163[0m[0m | time: 2.680s
[2K
| Adam | epoch: 005 | loss: 0.69163 - acc: 0.5532 -- iter: 128/140
[A[ATraining Step: 25  | total loss: [1m[32m0.69074[0m[0m | time: 4.483s
[2K
| Adam | epoch: 005 | loss: 0.69074 - acc: 0.5614 | val_loss: 0.69988 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 26  | total loss: [1m[32m0.69299[0m[0m | time: 1.083s
[2K
| Adam | epoch: 006 | loss: 0.69299 - acc: 0.5203 -- iter: 032/140
[A[ATraining Step: 27  | total loss: [1m[32m0.69209[0m[0m | time: 2.253s
[2K
| Adam | epoch: 006 | loss: 0.69209 - acc: 0.5312 -- iter: 064/140
[A[ATraining Step: 28  | total loss: [1m[32m0.69258[0m[0m | time: 3.088s
[2K
| Adam | epoch: 006 | loss: 0.69258 - acc: 0.5234 -- iter: 096/140
[A[ATraining Step: 29  | total loss: [1m[32m0.69404[0m[0m | time: 3.399s
[2K
| Adam | epoch: 006 | loss: 0.69404 - acc: 0.5025 -- iter: 128/140
[A[ATraining Step: 30  | total loss: [1m[32m0.69261[0m[0m | time: 4.738s
[2K
| Adam | epoch: 006 | loss: 0.69261 - acc: 0.5216 | val_loss: 0.70125 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 31  | total loss: [1m[32m0.69133[0m[0m | time: 0.883s
[2K
| Adam | epoch: 007 | loss: 0.69133 - acc: 0.5359 -- iter: 032/140
[A[ATraining Step: 32  | total loss: [1m[32m0.68801[0m[0m | time: 1.710s
[2K
| Adam | epoch: 007 | loss: 0.68801 - acc: 0.5770 -- iter: 064/140
[A[ATraining Step: 33  | total loss: [1m[32m0.69065[0m[0m | time: 2.698s
[2K
| Adam | epoch: 007 | loss: 0.69065 - acc: 0.5464 -- iter: 096/140
[A[ATraining Step: 34  | total loss: [1m[32m0.69120[0m[0m | time: 3.908s
[2K
| Adam | epoch: 007 | loss: 0.69120 - acc: 0.5365 -- iter: 128/140
[A[ATraining Step: 35  | total loss: [1m[32m0.69333[0m[0m | time: 5.453s
[2K
| Adam | epoch: 007 | loss: 0.69333 - acc: 0.5157 | val_loss: 0.70464 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 36  | total loss: [1m[32m0.69169[0m[0m | time: 0.351s
[2K
| Adam | epoch: 008 | loss: 0.69169 - acc: 0.5296 -- iter: 032/140
[A[ATraining Step: 37  | total loss: [1m[32m0.69031[0m[0m | time: 1.262s
[2K
| Adam | epoch: 008 | loss: 0.69031 - acc: 0.5403 -- iter: 064/140
[A[ATraining Step: 38  | total loss: [1m[32m0.68830[0m[0m | time: 2.150s
[2K
| Adam | epoch: 008 | loss: 0.68830 - acc: 0.5569 -- iter: 096/140
[A[ATraining Step: 39  | total loss: [1m[32m0.68895[0m[0m | time: 2.970s
[2K
| Adam | epoch: 008 | loss: 0.68895 - acc: 0.5520 -- iter: 128/140
[A[ATraining Step: 40  | total loss: [1m[32m0.69243[0m[0m | time: 5.074s
[2K
| Adam | epoch: 008 | loss: 0.69243 - acc: 0.5305 | val_loss: 0.71455 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 41  | total loss: [1m[32m0.68728[0m[0m | time: 0.371s
[2K
| Adam | epoch: 009 | loss: 0.68728 - acc: 0.5593 -- iter: 032/140
[A[ATraining Step: 42  | total loss: [1m[32m0.68370[0m[0m | time: 0.720s
[2K
| Adam | epoch: 009 | loss: 0.68370 - acc: 0.5787 -- iter: 064/140
[A[ATraining Step: 43  | total loss: [1m[32m0.67939[0m[0m | time: 1.571s
[2K
| Adam | epoch: 009 | loss: 0.67939 - acc: 0.5942 -- iter: 096/140
[A[ATraining Step: 44  | total loss: [1m[32m0.69100[0m[0m | time: 2.443s
[2K
| Adam | epoch: 009 | loss: 0.69100 - acc: 0.5617 -- iter: 128/140
[A[ATraining Step: 45  | total loss: [1m[32m0.69189[0m[0m | time: 4.313s
[2K
| Adam | epoch: 009 | loss: 0.69189 - acc: 0.5565 | val_loss: 0.71905 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 46  | total loss: [1m[32m0.69699[0m[0m | time: 0.838s
[2K
| Adam | epoch: 010 | loss: 0.69699 - acc: 0.5367 -- iter: 032/140
[A[ATraining Step: 47  | total loss: [1m[32m0.69596[0m[0m | time: 1.190s
[2K
| Adam | epoch: 010 | loss: 0.69596 - acc: 0.5358 -- iter: 064/140
[A[ATraining Step: 48  | total loss: [1m[32m0.68704[0m[0m | time: 1.529s
[2K
| Adam | epoch: 010 | loss: 0.68704 - acc: 0.5836 -- iter: 096/140
[A[ATraining Step: 49  | total loss: [1m[32m0.67970[0m[0m | time: 2.377s
[2K
| Adam | epoch: 010 | loss: 0.67970 - acc: 0.6230 -- iter: 128/140
[A[ATraining Step: 50  | total loss: [1m[32m0.67901[0m[0m | time: 4.214s
[2K
| Adam | epoch: 010 | loss: 0.67901 - acc: 0.6233 | val_loss: 0.71528 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 51  | total loss: [1m[32m0.68359[0m[0m | time: 1.133s
[2K
| Adam | epoch: 011 | loss: 0.68359 - acc: 0.5950 -- iter: 032/140
[A[ATraining Step: 52  | total loss: [1m[32m0.68470[0m[0m | time: 2.004s
[2K
| Adam | epoch: 011 | loss: 0.68470 - acc: 0.5854 -- iter: 064/140
[A[ATraining Step: 53  | total loss: [1m[32m0.68116[0m[0m | time: 2.314s
[2K
| Adam | epoch: 011 | loss: 0.68116 - acc: 0.6005 -- iter: 096/140
[A[ATraining Step: 54  | total loss: [1m[32m0.68579[0m[0m | time: 2.632s
[2K
| Adam | epoch: 011 | loss: 0.68579 - acc: 0.5738 -- iter: 128/140
[A[ATraining Step: 55  | total loss: [1m[32m0.69014[0m[0m | time: 4.495s
[2K
| Adam | epoch: 011 | loss: 0.69014 - acc: 0.5514 | val_loss: 0.71315 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 56  | total loss: [1m[32m0.69579[0m[0m | time: 0.900s
[2K
| Adam | epoch: 012 | loss: 0.69579 - acc: 0.5222 -- iter: 032/140
[A[ATraining Step: 57  | total loss: [1m[32m0.69358[0m[0m | time: 1.723s
[2K
| Adam | epoch: 012 | loss: 0.69358 - acc: 0.5321 -- iter: 064/140
[A[ATraining Step: 58  | total loss: [1m[32m0.69240[0m[0m | time: 2.539s
[2K
| Adam | epoch: 012 | loss: 0.69240 - acc: 0.5362 -- iter: 096/140
[A[ATraining Step: 59  | total loss: [1m[32m0.69148[0m[0m | time: 2.993s
[2K
| Adam | epoch: 012 | loss: 0.69148 - acc: 0.5398 -- iter: 128/140
[A[ATraining Step: 60  | total loss: [1m[32m0.69548[0m[0m | time: 4.479s
[2K
| Adam | epoch: 012 | loss: 0.69548 - acc: 0.5124 | val_loss: 0.70612 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 61  | total loss: [1m[32m0.69848[0m[0m | time: 0.871s
[2K
| Adam | epoch: 013 | loss: 0.69848 - acc: 0.4891 -- iter: 032/140
[A[ATraining Step: 62  | total loss: [1m[32m0.69704[0m[0m | time: 1.758s
[2K
| Adam | epoch: 013 | loss: 0.69704 - acc: 0.4985 -- iter: 064/140
[A[ATraining Step: 63  | total loss: [1m[32m0.69675[0m[0m | time: 2.626s
[2K
| Adam | epoch: 013 | loss: 0.69675 - acc: 0.4987 -- iter: 096/140
[A[ATraining Step: 64  | total loss: [1m[32m0.69560[0m[0m | time: 3.460s
[2K
| Adam | epoch: 013 | loss: 0.69560 - acc: 0.5067 -- iter: 128/140
[A[ATraining Step: 65  | total loss: [1m[32m0.69654[0m[0m | time: 4.786s
[2K
| Adam | epoch: 013 | loss: 0.69654 - acc: 0.4943 | val_loss: 0.70317 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 66  | total loss: [1m[32m0.69325[0m[0m | time: 0.381s
[2K
| Adam | epoch: 014 | loss: 0.69325 - acc: 0.5254 -- iter: 032/140
[A[ATraining Step: 67  | total loss: [1m[32m0.69045[0m[0m | time: 1.265s
[2K
| Adam | epoch: 014 | loss: 0.69045 - acc: 0.5523 -- iter: 064/140
[A[ATraining Step: 68  | total loss: [1m[32m0.68978[0m[0m | time: 2.110s
[2K
| Adam | epoch: 014 | loss: 0.68978 - acc: 0.5572 -- iter: 096/140
[A[ATraining Step: 69  | total loss: [1m[32m0.69075[0m[0m | time: 2.986s
[2K
| Adam | epoch: 014 | loss: 0.69075 - acc: 0.5469 -- iter: 128/140
[A[ATraining Step: 70  | total loss: [1m[32m0.68998[0m[0m | time: 4.926s
[2K
| Adam | epoch: 014 | loss: 0.68998 - acc: 0.5523 | val_loss: 0.70523 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 71  | total loss: [1m[32m0.69129[0m[0m | time: 0.265s
[2K
| Adam | epoch: 015 | loss: 0.69129 - acc: 0.5392 -- iter: 032/140
[A[ATraining Step: 72  | total loss: [1m[32m0.69372[0m[0m | time: 0.565s
[2K
| Adam | epoch: 015 | loss: 0.69372 - acc: 0.5161 -- iter: 064/140
[A[ATraining Step: 73  | total loss: [1m[32m0.69601[0m[0m | time: 1.426s
[2K
| Adam | epoch: 015 | loss: 0.69601 - acc: 0.4958 -- iter: 096/140
[A[ATraining Step: 74  | total loss: [1m[32m0.69484[0m[0m | time: 2.269s
[2K
| Adam | epoch: 015 | loss: 0.69484 - acc: 0.5065 -- iter: 128/140
[A[ATraining Step: 75  | total loss: [1m[32m0.69411[0m[0m | time: 4.125s
[2K
| Adam | epoch: 015 | loss: 0.69411 - acc: 0.5126 | val_loss: 0.70259 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 76  | total loss: [1m[32m0.69412[0m[0m | time: 1.142s
[2K
| Adam | epoch: 016 | loss: 0.69412 - acc: 0.5112 -- iter: 032/140
[A[ATraining Step: 77  | total loss: [1m[32m0.69378[0m[0m | time: 1.570s
[2K
| Adam | epoch: 016 | loss: 0.69378 - acc: 0.5134 -- iter: 064/140
[A[ATraining Step: 78  | total loss: [1m[32m0.69295[0m[0m | time: 2.076s
[2K
| Adam | epoch: 016 | loss: 0.69295 - acc: 0.5207 -- iter: 096/140
[A[ATraining Step: 79  | total loss: [1m[32m0.69218[0m[0m | time: 3.114s
[2K
| Adam | epoch: 016 | loss: 0.69218 - acc: 0.5272 -- iter: 128/140
[A[ATraining Step: 80  | total loss: [1m[32m0.69183[0m[0m | time: 5.062s
[2K
| Adam | epoch: 016 | loss: 0.69183 - acc: 0.5308 | val_loss: 0.70236 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 81  | total loss: [1m[32m0.69210[0m[0m | time: 0.857s
[2K
| Adam | epoch: 017 | loss: 0.69210 - acc: 0.5277 -- iter: 032/140
[A[ATraining Step: 82  | total loss: [1m[32m0.69143[0m[0m | time: 1.697s
[2K
| Adam | epoch: 017 | loss: 0.69143 - acc: 0.5343 -- iter: 064/140
[A[ATraining Step: 83  | total loss: [1m[32m0.69193[0m[0m | time: 2.008s
[2K
| Adam | epoch: 017 | loss: 0.69193 - acc: 0.5277 -- iter: 096/140
[A[ATraining Step: 84  | total loss: [1m[32m0.69297[0m[0m | time: 2.373s
[2K
| Adam | epoch: 017 | loss: 0.69297 - acc: 0.5166 -- iter: 128/140
[A[ATraining Step: 85  | total loss: [1m[32m0.69382[0m[0m | time: 4.568s
[2K
| Adam | epoch: 017 | loss: 0.69382 - acc: 0.5066 | val_loss: 0.70193 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 86  | total loss: [1m[32m0.69295[0m[0m | time: 0.832s
[2K
| Adam | epoch: 018 | loss: 0.69295 - acc: 0.5153 -- iter: 032/140
[A[ATraining Step: 87  | total loss: [1m[32m0.69302[0m[0m | time: 1.710s
[2K
| Adam | epoch: 018 | loss: 0.69302 - acc: 0.5138 -- iter: 064/140
[A[ATraining Step: 88  | total loss: [1m[32m0.69173[0m[0m | time: 2.568s
[2K
| Adam | epoch: 018 | loss: 0.69173 - acc: 0.5280 -- iter: 096/140
[A[ATraining Step: 89  | total loss: [1m[32m0.69274[0m[0m | time: 2.935s
[2K
| Adam | epoch: 018 | loss: 0.69274 - acc: 0.5159 -- iter: 128/140
[A[ATraining Step: 90  | total loss: [1m[32m0.69123[0m[0m | time: 4.269s
[2K
| Adam | epoch: 018 | loss: 0.69123 - acc: 0.5309 | val_loss: 0.70250 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 91  | total loss: [1m[32m0.69002[0m[0m | time: 0.910s
[2K
| Adam | epoch: 019 | loss: 0.69002 - acc: 0.5445 -- iter: 032/140
[A[ATraining Step: 92  | total loss: [1m[32m0.69007[0m[0m | time: 1.720s
[2K
| Adam | epoch: 019 | loss: 0.69007 - acc: 0.5432 -- iter: 064/140
[A[ATraining Step: 93  | total loss: [1m[32m0.69075[0m[0m | time: 2.552s
[2K
| Adam | epoch: 019 | loss: 0.69075 - acc: 0.5357 -- iter: 096/140
[A[ATraining Step: 94  | total loss: [1m[32m0.69074[0m[0m | time: 3.416s
[2K
| Adam | epoch: 019 | loss: 0.69074 - acc: 0.5353 -- iter: 128/140
[A[ATraining Step: 95  | total loss: [1m[32m0.69141[0m[0m | time: 4.757s
[2K
| Adam | epoch: 019 | loss: 0.69141 - acc: 0.5286 | val_loss: 0.70454 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 96  | total loss: [1m[32m0.68893[0m[0m | time: 0.370s
[2K
| Adam | epoch: 020 | loss: 0.68893 - acc: 0.5508 -- iter: 032/140
[A[ATraining Step: 97  | total loss: [1m[32m0.68654[0m[0m | time: 1.220s
[2K
| Adam | epoch: 020 | loss: 0.68654 - acc: 0.5707 -- iter: 064/140
[A[ATraining Step: 98  | total loss: [1m[32m0.68697[0m[0m | time: 2.140s
[2K
| Adam | epoch: 020 | loss: 0.68697 - acc: 0.5668 -- iter: 096/140
[A[ATraining Step: 99  | total loss: [1m[32m0.68768[0m[0m | time: 3.209s
[2K
| Adam | epoch: 020 | loss: 0.68768 - acc: 0.5601 -- iter: 128/140
[A[ATraining Step: 100  | total loss: [1m[32m0.68553[0m[0m | time: 5.310s
[2K
| Adam | epoch: 020 | loss: 0.68553 - acc: 0.5728 | val_loss: 0.71643 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 101  | total loss: [1m[32m0.68467[0m[0m | time: 0.377s
[2K
| Adam | epoch: 021 | loss: 0.68467 - acc: 0.5749 -- iter: 032/140
[A[ATraining Step: 102  | total loss: [1m[32m0.68960[0m[0m | time: 0.739s
[2K
| Adam | epoch: 021 | loss: 0.68960 - acc: 0.5508 -- iter: 064/140
[A[ATraining Step: 103  | total loss: [1m[32m0.69394[0m[0m | time: 1.612s
[2K
| Adam | epoch: 021 | loss: 0.69394 - acc: 0.5290 -- iter: 096/140
[A[ATraining Step: 104  | total loss: [1m[32m0.69408[0m[0m | time: 2.489s
[2K
| Adam | epoch: 021 | loss: 0.69408 - acc: 0.5261 -- iter: 128/140
[A[ATraining Step: 105  | total loss: [1m[32m0.69543[0m[0m | time: 4.282s
[2K
| Adam | epoch: 021 | loss: 0.69543 - acc: 0.5141 | val_loss: 0.70540 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 106  | total loss: [1m[32m0.69451[0m[0m | time: 0.930s
[2K
| Adam | epoch: 022 | loss: 0.69451 - acc: 0.5190 -- iter: 032/140
[A[ATraining Step: 107  | total loss: [1m[32m0.69524[0m[0m | time: 1.308s
[2K
| Adam | epoch: 022 | loss: 0.69524 - acc: 0.5108 -- iter: 064/140
[A[ATraining Step: 108  | total loss: [1m[32m0.69318[0m[0m | time: 1.665s
[2K
| Adam | epoch: 022 | loss: 0.69318 - acc: 0.5264 -- iter: 096/140
[A[ATraining Step: 109  | total loss: [1m[32m0.69136[0m[0m | time: 2.558s
[2K
| Adam | epoch: 022 | loss: 0.69136 - acc: 0.5404 -- iter: 128/140
[A[ATraining Step: 110  | total loss: [1m[32m0.69120[0m[0m | time: 4.447s
[2K
| Adam | epoch: 022 | loss: 0.69120 - acc: 0.5395 | val_loss: 0.70537 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 111  | total loss: [1m[32m0.69105[0m[0m | time: 0.852s
[2K
| Adam | epoch: 023 | loss: 0.69105 - acc: 0.5387 -- iter: 032/140
[A[ATraining Step: 112  | total loss: [1m[32m0.69082[0m[0m | time: 1.628s
[2K
| Adam | epoch: 023 | loss: 0.69082 - acc: 0.5411 -- iter: 064/140
[A[ATraining Step: 113  | total loss: [1m[32m0.68987[0m[0m | time: 1.966s
[2K
| Adam | epoch: 023 | loss: 0.68987 - acc: 0.5463 -- iter: 096/140
[A[ATraining Step: 114  | total loss: [1m[32m0.69106[0m[0m | time: 2.297s
[2K
| Adam | epoch: 023 | loss: 0.69106 - acc: 0.5334 -- iter: 128/140
[A[ATraining Step: 115  | total loss: [1m[32m0.69243[0m[0m | time: 4.131s
[2K
| Adam | epoch: 023 | loss: 0.69243 - acc: 0.5217 | val_loss: 0.70556 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 116  | total loss: [1m[32m0.69280[0m[0m | time: 0.884s
[2K
| Adam | epoch: 024 | loss: 0.69280 - acc: 0.5164 -- iter: 032/140
[A[ATraining Step: 117  | total loss: [1m[32m0.69238[0m[0m | time: 1.777s
[2K
| Adam | epoch: 024 | loss: 0.69238 - acc: 0.5179 -- iter: 064/140
[A[ATraining Step: 118  | total loss: [1m[32m0.69231[0m[0m | time: 2.897s
[2K
| Adam | epoch: 024 | loss: 0.69231 - acc: 0.5161 -- iter: 096/140
[A[ATraining Step: 119  | total loss: [1m[32m0.69342[0m[0m | time: 3.361s
[2K
| Adam | epoch: 024 | loss: 0.69342 - acc: 0.5051 -- iter: 128/140
[A[ATraining Step: 120  | total loss: [1m[32m0.68838[0m[0m | time: 4.816s
[2K
| Adam | epoch: 024 | loss: 0.68838 - acc: 0.5463 | val_loss: 0.70703 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 121  | total loss: [1m[32m0.68311[0m[0m | time: 0.933s
[2K
| Adam | epoch: 025 | loss: 0.68311 - acc: 0.5833 -- iter: 032/140
[A[ATraining Step: 122  | total loss: [1m[32m0.68254[0m[0m | time: 1.840s
[2K
| Adam | epoch: 025 | loss: 0.68254 - acc: 0.5844 -- iter: 064/140
[A[ATraining Step: 123  | total loss: [1m[32m0.68402[0m[0m | time: 2.759s
[2K
| Adam | epoch: 025 | loss: 0.68402 - acc: 0.5728 -- iter: 096/140
[A[ATraining Step: 124  | total loss: [1m[32m0.68482[0m[0m | time: 3.612s
[2K
| Adam | epoch: 025 | loss: 0.68482 - acc: 0.5655 -- iter: 128/140
[A[ATraining Step: 125  | total loss: [1m[32m0.68494[0m[0m | time: 5.065s
[2K
| Adam | epoch: 025 | loss: 0.68494 - acc: 0.5621 | val_loss: 0.71444 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 126  | total loss: [1m[32m0.68483[0m[0m | time: 0.353s
[2K
| Adam | epoch: 026 | loss: 0.68483 - acc: 0.5559 -- iter: 032/140
[A[ATraining Step: 127  | total loss: [1m[32m0.68444[0m[0m | time: 1.253s
[2K
| Adam | epoch: 026 | loss: 0.68444 - acc: 0.5503 -- iter: 064/140
[A[ATraining Step: 128  | total loss: [1m[32m0.68225[0m[0m | time: 2.204s
[2K
| Adam | epoch: 026 | loss: 0.68225 - acc: 0.5546 -- iter: 096/140
[A[ATraining Step: 129  | total loss: [1m[32m0.68270[0m[0m | time: 3.089s
[2K
| Adam | epoch: 026 | loss: 0.68270 - acc: 0.5492 -- iter: 128/140
[A[ATraining Step: 130  | total loss: [1m[32m0.68212[0m[0m | time: 4.966s
[2K
| Adam | epoch: 026 | loss: 0.68212 - acc: 0.5443 | val_loss: 0.72452 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 131  | total loss: [1m[32m0.67961[0m[0m | time: 0.305s
[2K
| Adam | epoch: 027 | loss: 0.67961 - acc: 0.5430 -- iter: 032/140
[A[ATraining Step: 132  | total loss: [1m[32m0.68005[0m[0m | time: 0.608s
[2K
| Adam | epoch: 027 | loss: 0.68005 - acc: 0.5387 -- iter: 064/140
[A[ATraining Step: 133  | total loss: [1m[32m0.67931[0m[0m | time: 1.481s
[2K
| Adam | epoch: 027 | loss: 0.67931 - acc: 0.5348 -- iter: 096/140
[A[ATraining Step: 134  | total loss: [1m[32m0.67634[0m[0m | time: 2.361s
[2K
| Adam | epoch: 027 | loss: 0.67634 - acc: 0.5407 -- iter: 128/140
[A[ATraining Step: 135  | total loss: [1m[32m0.67333[0m[0m | time: 4.220s
[2K
| Adam | epoch: 027 | loss: 0.67333 - acc: 0.5366 | val_loss: 0.68449 - val_acc: 0.4091 -- iter: 140/140
--
Training Step: 136  | total loss: [1m[32m0.68814[0m[0m | time: 0.857s
[2K
| Adam | epoch: 028 | loss: 0.68814 - acc: 0.5111 -- iter: 032/140
[A[ATraining Step: 137  | total loss: [1m[32m0.67892[0m[0m | time: 1.202s
[2K
| Adam | epoch: 028 | loss: 0.67892 - acc: 0.5225 -- iter: 064/140
[A[ATraining Step: 138  | total loss: [1m[32m0.67668[0m[0m | time: 1.668s
[2K
| Adam | epoch: 028 | loss: 0.67668 - acc: 0.5202 -- iter: 096/140
[A[ATraining Step: 139  | total loss: [1m[32m0.67403[0m[0m | time: 2.828s
[2K
| Adam | epoch: 028 | loss: 0.67403 - acc: 0.5265 -- iter: 128/140
[A[ATraining Step: 140  | total loss: [1m[32m0.66269[0m[0m | time: 5.016s
[2K
| Adam | epoch: 028 | loss: 0.66269 - acc: 0.5520 | val_loss: 0.77820 - val_acc: 0.4318 -- iter: 140/140
--
Training Step: 141  | total loss: [1m[32m0.65237[0m[0m | time: 0.829s
[2K
| Adam | epoch: 029 | loss: 0.65237 - acc: 0.5624 -- iter: 032/140
[A[ATraining Step: 142  | total loss: [1m[32m0.65943[0m[0m | time: 1.861s
[2K
| Adam | epoch: 029 | loss: 0.65943 - acc: 0.5562 -- iter: 064/140
[A[ATraining Step: 143  | total loss: [1m[32m0.64421[0m[0m | time: 2.302s
[2K
| Adam | epoch: 029 | loss: 0.64421 - acc: 0.5912 -- iter: 096/140
[A[ATraining Step: 144  | total loss: [1m[32m0.62636[0m[0m | time: 2.740s
[2K
| Adam | epoch: 029 | loss: 0.62636 - acc: 0.6237 -- iter: 128/140
[A[ATraining Step: 145  | total loss: [1m[32m0.60167[0m[0m | time: 4.897s
[2K
| Adam | epoch: 029 | loss: 0.60167 - acc: 0.6530 | val_loss: 0.65932 - val_acc: 0.6364 -- iter: 140/140
--
Training Step: 146  | total loss: [1m[32m0.60110[0m[0m | time: 0.833s
[2K
| Adam | epoch: 030 | loss: 0.60110 - acc: 0.6502 -- iter: 032/140
[A[ATraining Step: 147  | total loss: [1m[32m0.58022[0m[0m | time: 2.002s
[2K
| Adam | epoch: 030 | loss: 0.58022 - acc: 0.6633 -- iter: 064/140
[A[ATraining Step: 148  | total loss: [1m[32m0.57912[0m[0m | time: 3.196s
[2K
| Adam | epoch: 030 | loss: 0.57912 - acc: 0.6658 -- iter: 096/140
[A[ATraining Step: 149  | total loss: [1m[32m0.55406[0m[0m | time: 3.635s
[2K
| Adam | epoch: 030 | loss: 0.55406 - acc: 0.6929 -- iter: 128/140
[A[ATraining Step: 150  | total loss: [1m[32m0.52884[0m[0m | time: 4.957s
[2K
| Adam | epoch: 030 | loss: 0.52884 - acc: 0.7153 | val_loss: 0.49564 - val_acc: 0.7727 -- iter: 140/140
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8675213675213675
Validation AUPRC:0.9225132310613166
Test AUC:0.8944099378881987
Test AUPRC:0.92812539087589
BestTestF1Score	0.83	0.64	0.82	0.8	0.87	20	5	16	3	0.75
BestTestMCCScore	0.83	0.64	0.82	0.8	0.87	20	5	16	3	0.75
BestTestAccuracyScore	0.83	0.64	0.82	0.8	0.87	20	5	16	3	0.75
BestValidationF1Score	0.86	0.69	0.84	0.91	0.81	21	2	16	5	0.75
BestValidationMCC	0.86	0.69	0.84	0.91	0.81	21	2	16	5	0.75
BestValidationAccuracy	0.86	0.69	0.84	0.91	0.81	21	2	16	5	0.75
TestPredictions (Threshold:0.75)
CHEMBL1078930,TP,ACT,0.8700000047683716	CHEMBL505949,TP,ACT,0.8799999952316284	CHEMBL432168,TP,ACT,0.8199999928474426	CHEMBL557050,TN,INACT,0.1899999976158142	CHEMBL1767294,FP,INACT,0.8100000023841858	CHEMBL509499,TN,INACT,0.10000000149011612	CHEMBL456113,TN,INACT,0.28999999165534973	CHEMBL78129,TP,ACT,0.8600000143051147	CHEMBL1079294,TP,ACT,0.8999999761581421	CHEMBL527039,TN,INACT,0.07999999821186066	CHEMBL488811,TN,INACT,0.18000000715255737	CHEMBL521201,TN,INACT,0.7099999785423279	CHEMBL1734241,TN,INACT,0.4699999988079071	CHEMBL1241674,FN,ACT,0.05999999865889549	CHEMBL230761,FP,INACT,0.7599999904632568	CHEMBL1801932,FP,INACT,0.8600000143051147	CHEMBL457179,TN,INACT,0.029999999329447746	CHEMBL3581138,TP,ACT,0.8999999761581421	CHEMBL447678,TP,ACT,0.8799999952316284	CHEMBL60254,TP,ACT,0.9100000262260437	CHEMBL307708,TP,ACT,0.8799999952316284	CHEMBL365286,TP,ACT,0.8700000047683716	CHEMBL309078,TN,INACT,0.7099999785423279	CHEMBL101868,FP,INACT,0.8100000023841858	CHEMBL304549,TP,ACT,0.9100000262260437	CHEMBL3401979,TP,ACT,0.8700000047683716	CHEMBL3581121,TP,ACT,0.8999999761581421	CHEMBL300138,FN,ACT,0.38999998569488525	CHEMBL318485,TN,INACT,0.10999999940395355	CHEMBL2420584,TN,INACT,0.5799999833106995	CHEMBL549792,TN,INACT,0.17000000178813934	CHEMBL498924,TP,ACT,0.8600000143051147	CHEMBL379218,FN,ACT,0.6399999856948853	CHEMBL496365,FP,INACT,0.8500000238418579	CHEMBL497454,TN,INACT,0.10999999940395355	CHEMBL438491,TP,ACT,0.8899999856948853	CHEMBL1079243,TP,ACT,0.8299999833106995	CHEMBL279185,TP,ACT,0.8899999856948853	CHEMBL558849,TN,INACT,0.4000000059604645	CHEMBL306580,TP,ACT,0.800000011920929	CHEMBL308263,TP,ACT,0.8799999952316284	CHEMBL3361128,TN,INACT,0.5799999833106995	CHEMBL494089,TP,ACT,0.800000011920929	CHEMBL488646,TN,INACT,0.2800000011920929	

