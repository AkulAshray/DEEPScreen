CNNModel CHEMBL1790 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	488
Number of inactive compounds :	488
---------------------------------
Run id: CNNModel_CHEMBL1790_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1790_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 582
Validation samples: 182
--
Training Step: 1  | time: 0.859s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/582
[A[ATraining Step: 2  | total loss: [1m[32m0.62369[0m[0m | time: 1.461s
[2K
| Adam | epoch: 001 | loss: 0.62369 - acc: 0.4500 -- iter: 064/582
[A[ATraining Step: 3  | total loss: [1m[32m0.68031[0m[0m | time: 2.089s
[2K
| Adam | epoch: 001 | loss: 0.68031 - acc: 0.4909 -- iter: 096/582
[A[ATraining Step: 4  | total loss: [1m[32m0.68965[0m[0m | time: 2.683s
[2K
| Adam | epoch: 001 | loss: 0.68965 - acc: 0.5212 -- iter: 128/582
[A[ATraining Step: 5  | total loss: [1m[32m0.69403[0m[0m | time: 3.288s
[2K
| Adam | epoch: 001 | loss: 0.69403 - acc: 0.4416 -- iter: 160/582
[A[ATraining Step: 6  | total loss: [1m[32m0.69415[0m[0m | time: 3.913s
[2K
| Adam | epoch: 001 | loss: 0.69415 - acc: 0.4390 -- iter: 192/582
[A[ATraining Step: 7  | total loss: [1m[32m0.69366[0m[0m | time: 4.523s
[2K
| Adam | epoch: 001 | loss: 0.69366 - acc: 0.4756 -- iter: 224/582
[A[ATraining Step: 8  | total loss: [1m[32m0.69382[0m[0m | time: 5.259s
[2K
| Adam | epoch: 001 | loss: 0.69382 - acc: 0.4542 -- iter: 256/582
[A[ATraining Step: 9  | total loss: [1m[32m0.69464[0m[0m | time: 5.947s
[2K
| Adam | epoch: 001 | loss: 0.69464 - acc: 0.4288 -- iter: 288/582
[A[ATraining Step: 10  | total loss: [1m[32m0.69338[0m[0m | time: 6.727s
[2K
| Adam | epoch: 001 | loss: 0.69338 - acc: 0.4956 -- iter: 320/582
[A[ATraining Step: 11  | total loss: [1m[32m0.69319[0m[0m | time: 7.515s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.4977 -- iter: 352/582
[A[ATraining Step: 12  | total loss: [1m[32m0.69174[0m[0m | time: 8.143s
[2K
| Adam | epoch: 001 | loss: 0.69174 - acc: 0.5831 -- iter: 384/582
[A[ATraining Step: 13  | total loss: [1m[32m0.69373[0m[0m | time: 8.779s
[2K
| Adam | epoch: 001 | loss: 0.69373 - acc: 0.4939 -- iter: 416/582
[A[ATraining Step: 14  | total loss: [1m[32m0.69238[0m[0m | time: 9.408s
[2K
| Adam | epoch: 001 | loss: 0.69238 - acc: 0.5348 -- iter: 448/582
[A[ATraining Step: 15  | total loss: [1m[32m0.69227[0m[0m | time: 10.015s
[2K
| Adam | epoch: 001 | loss: 0.69227 - acc: 0.5334 -- iter: 480/582
[A[ATraining Step: 16  | total loss: [1m[32m0.69267[0m[0m | time: 10.661s
[2K
| Adam | epoch: 001 | loss: 0.69267 - acc: 0.5209 -- iter: 512/582
[A[ATraining Step: 17  | total loss: [1m[32m0.69332[0m[0m | time: 11.284s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.5021 -- iter: 544/582
[A[ATraining Step: 18  | total loss: [1m[32m0.69201[0m[0m | time: 11.897s
[2K
| Adam | epoch: 001 | loss: 0.69201 - acc: 0.5338 -- iter: 576/582
[A[ATraining Step: 19  | total loss: [1m[32m0.69275[0m[0m | time: 13.084s
[2K
| Adam | epoch: 001 | loss: 0.69275 - acc: 0.5121 | val_loss: 0.69442 - val_acc: 0.4890 -- iter: 582/582
--
Training Step: 20  | total loss: [1m[32m0.68703[0m[0m | time: 0.154s
[2K
| Adam | epoch: 002 | loss: 0.68703 - acc: 0.6154 -- iter: 032/582
[A[ATraining Step: 21  | total loss: [1m[32m0.68050[0m[0m | time: 0.782s
[2K
| Adam | epoch: 002 | loss: 0.68050 - acc: 0.6830 -- iter: 064/582
[A[ATraining Step: 22  | total loss: [1m[32m0.68225[0m[0m | time: 1.401s
[2K
| Adam | epoch: 002 | loss: 0.68225 - acc: 0.6469 -- iter: 096/582
[A[ATraining Step: 23  | total loss: [1m[32m0.67569[0m[0m | time: 2.014s
[2K
| Adam | epoch: 002 | loss: 0.67569 - acc: 0.6587 -- iter: 128/582
[A[ATraining Step: 24  | total loss: [1m[32m0.68493[0m[0m | time: 2.614s
[2K
| Adam | epoch: 002 | loss: 0.68493 - acc: 0.6140 -- iter: 160/582
[A[ATraining Step: 25  | total loss: [1m[32m0.69222[0m[0m | time: 3.384s
[2K
| Adam | epoch: 002 | loss: 0.69222 - acc: 0.5829 -- iter: 192/582
[A[ATraining Step: 26  | total loss: [1m[32m0.68433[0m[0m | time: 4.170s
[2K
| Adam | epoch: 002 | loss: 0.68433 - acc: 0.5941 -- iter: 224/582
[A[ATraining Step: 27  | total loss: [1m[32m0.69197[0m[0m | time: 4.975s
[2K
| Adam | epoch: 002 | loss: 0.69197 - acc: 0.5699 -- iter: 256/582
[A[ATraining Step: 28  | total loss: [1m[32m0.69076[0m[0m | time: 5.689s
[2K
| Adam | epoch: 002 | loss: 0.69076 - acc: 0.5680 -- iter: 288/582
[A[ATraining Step: 29  | total loss: [1m[32m0.70310[0m[0m | time: 6.300s
[2K
| Adam | epoch: 002 | loss: 0.70310 - acc: 0.5211 -- iter: 320/582
[A[ATraining Step: 30  | total loss: [1m[32m0.70689[0m[0m | time: 6.907s
[2K
| Adam | epoch: 002 | loss: 0.70689 - acc: 0.4939 -- iter: 352/582
[A[ATraining Step: 31  | total loss: [1m[32m0.70288[0m[0m | time: 7.517s
[2K
| Adam | epoch: 002 | loss: 0.70288 - acc: 0.5025 -- iter: 384/582
[A[ATraining Step: 32  | total loss: [1m[32m0.69948[0m[0m | time: 8.128s
[2K
| Adam | epoch: 002 | loss: 0.69948 - acc: 0.5160 -- iter: 416/582
[A[ATraining Step: 33  | total loss: [1m[32m0.69863[0m[0m | time: 8.760s
[2K
| Adam | epoch: 002 | loss: 0.69863 - acc: 0.5056 -- iter: 448/582
[A[ATraining Step: 34  | total loss: [1m[32m0.69742[0m[0m | time: 9.366s
[2K
| Adam | epoch: 002 | loss: 0.69742 - acc: 0.5044 -- iter: 480/582
[A[ATraining Step: 35  | total loss: [1m[32m0.69740[0m[0m | time: 9.990s
[2K
| Adam | epoch: 002 | loss: 0.69740 - acc: 0.4839 -- iter: 512/582
[A[ATraining Step: 36  | total loss: [1m[32m0.69732[0m[0m | time: 10.627s
[2K
| Adam | epoch: 002 | loss: 0.69732 - acc: 0.4680 -- iter: 544/582
[A[ATraining Step: 37  | total loss: [1m[32m0.69590[0m[0m | time: 11.354s
[2K
| Adam | epoch: 002 | loss: 0.69590 - acc: 0.4931 -- iter: 576/582
[A[ATraining Step: 38  | total loss: [1m[32m0.69504[0m[0m | time: 13.086s
[2K
| Adam | epoch: 002 | loss: 0.69504 - acc: 0.5067 | val_loss: 0.69335 - val_acc: 0.4890 -- iter: 582/582
--
Training Step: 39  | total loss: [1m[32m0.69511[0m[0m | time: 0.160s
[2K
| Adam | epoch: 003 | loss: 0.69511 - acc: 0.4875 -- iter: 032/582
[A[ATraining Step: 40  | total loss: [1m[32m0.69471[0m[0m | time: 0.302s
[2K
| Adam | epoch: 003 | loss: 0.69471 - acc: 0.4898 -- iter: 064/582
[A[ATraining Step: 41  | total loss: [1m[32m0.69444[0m[0m | time: 0.909s
[2K
| Adam | epoch: 003 | loss: 0.69444 - acc: 0.4917 -- iter: 096/582
[A[ATraining Step: 42  | total loss: [1m[32m0.69365[0m[0m | time: 1.527s
[2K
| Adam | epoch: 003 | loss: 0.69365 - acc: 0.5269 -- iter: 128/582
[A[ATraining Step: 43  | total loss: [1m[32m0.69336[0m[0m | time: 2.149s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.5332 -- iter: 160/582
[A[ATraining Step: 44  | total loss: [1m[32m0.69322[0m[0m | time: 2.759s
[2K
| Adam | epoch: 003 | loss: 0.69322 - acc: 0.5329 -- iter: 192/582
[A[ATraining Step: 45  | total loss: [1m[32m0.69249[0m[0m | time: 3.562s
[2K
| Adam | epoch: 003 | loss: 0.69249 - acc: 0.5644 -- iter: 224/582
[A[ATraining Step: 46  | total loss: [1m[32m0.69168[0m[0m | time: 4.304s
[2K
| Adam | epoch: 003 | loss: 0.69168 - acc: 0.5954 -- iter: 256/582
[A[ATraining Step: 47  | total loss: [1m[32m0.69179[0m[0m | time: 5.034s
[2K
| Adam | epoch: 003 | loss: 0.69179 - acc: 0.5849 -- iter: 288/582
[A[ATraining Step: 48  | total loss: [1m[32m0.69241[0m[0m | time: 5.796s
[2K
| Adam | epoch: 003 | loss: 0.69241 - acc: 0.5562 -- iter: 320/582
[A[ATraining Step: 49  | total loss: [1m[32m0.69265[0m[0m | time: 6.485s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5424 -- iter: 352/582
[A[ATraining Step: 50  | total loss: [1m[32m0.69305[0m[0m | time: 7.089s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5261 -- iter: 384/582
[A[ATraining Step: 51  | total loss: [1m[32m0.69215[0m[0m | time: 7.699s
[2K
| Adam | epoch: 003 | loss: 0.69215 - acc: 0.5507 -- iter: 416/582
[A[ATraining Step: 52  | total loss: [1m[32m0.69230[0m[0m | time: 8.309s
[2K
| Adam | epoch: 003 | loss: 0.69230 - acc: 0.5431 -- iter: 448/582
[A[ATraining Step: 53  | total loss: [1m[32m0.69258[0m[0m | time: 8.931s
[2K
| Adam | epoch: 003 | loss: 0.69258 - acc: 0.5321 -- iter: 480/582
[A[ATraining Step: 54  | total loss: [1m[32m0.69282[0m[0m | time: 9.550s
[2K
| Adam | epoch: 003 | loss: 0.69282 - acc: 0.5229 -- iter: 512/582
[A[ATraining Step: 55  | total loss: [1m[32m0.69243[0m[0m | time: 10.158s
[2K
| Adam | epoch: 003 | loss: 0.69243 - acc: 0.5331 -- iter: 544/582
[A[ATraining Step: 56  | total loss: [1m[32m0.69222[0m[0m | time: 10.757s
[2K
| Adam | epoch: 003 | loss: 0.69222 - acc: 0.5372 -- iter: 576/582
[A[ATraining Step: 57  | total loss: [1m[32m0.69233[0m[0m | time: 12.447s
[2K
| Adam | epoch: 003 | loss: 0.69233 - acc: 0.5320 | val_loss: 0.69370 - val_acc: 0.4890 -- iter: 582/582
--
Training Step: 58  | total loss: [1m[32m0.69316[0m[0m | time: 0.606s
[2K
| Adam | epoch: 004 | loss: 0.69316 - acc: 0.5106 -- iter: 032/582
[A[ATraining Step: 59  | total loss: [1m[32m0.69302[0m[0m | time: 0.753s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5134 -- iter: 064/582
[A[ATraining Step: 60  | total loss: [1m[32m0.69307[0m[0m | time: 0.903s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5116 -- iter: 096/582
[A[ATraining Step: 61  | total loss: [1m[32m0.69306[0m[0m | time: 1.510s
[2K
| Adam | epoch: 004 | loss: 0.69306 - acc: 0.5101 -- iter: 128/582
[A[ATraining Step: 62  | total loss: [1m[32m0.69225[0m[0m | time: 2.127s
[2K
| Adam | epoch: 004 | loss: 0.69225 - acc: 0.5289 -- iter: 160/582
[A[ATraining Step: 63  | total loss: [1m[32m0.69255[0m[0m | time: 2.786s
[2K
| Adam | epoch: 004 | loss: 0.69255 - acc: 0.5213 -- iter: 192/582
[A[ATraining Step: 64  | total loss: [1m[32m0.69211[0m[0m | time: 3.500s
[2K
| Adam | epoch: 004 | loss: 0.69211 - acc: 0.5303 -- iter: 224/582
[A[ATraining Step: 65  | total loss: [1m[32m0.69208[0m[0m | time: 4.332s
[2K
| Adam | epoch: 004 | loss: 0.69208 - acc: 0.5304 -- iter: 256/582
[A[ATraining Step: 66  | total loss: [1m[32m0.69151[0m[0m | time: 5.034s
[2K
| Adam | epoch: 004 | loss: 0.69151 - acc: 0.5419 -- iter: 288/582
[A[ATraining Step: 67  | total loss: [1m[32m0.69059[0m[0m | time: 5.740s
[2K
| Adam | epoch: 004 | loss: 0.69059 - acc: 0.5594 -- iter: 320/582
[A[ATraining Step: 68  | total loss: [1m[32m0.69008[0m[0m | time: 6.350s
[2K
| Adam | epoch: 004 | loss: 0.69008 - acc: 0.5672 -- iter: 352/582
[A[ATraining Step: 69  | total loss: [1m[32m0.69112[0m[0m | time: 6.960s
[2K
| Adam | epoch: 004 | loss: 0.69112 - acc: 0.5484 -- iter: 384/582
[A[ATraining Step: 70  | total loss: [1m[32m0.68991[0m[0m | time: 7.568s
[2K
| Adam | epoch: 004 | loss: 0.68991 - acc: 0.5644 -- iter: 416/582
[A[ATraining Step: 71  | total loss: [1m[32m0.69089[0m[0m | time: 8.163s
[2K
| Adam | epoch: 004 | loss: 0.69089 - acc: 0.5500 -- iter: 448/582
[A[ATraining Step: 72  | total loss: [1m[32m0.69120[0m[0m | time: 8.776s
[2K
| Adam | epoch: 004 | loss: 0.69120 - acc: 0.5443 -- iter: 480/582
[A[ATraining Step: 73  | total loss: [1m[32m0.69210[0m[0m | time: 9.391s
[2K
| Adam | epoch: 004 | loss: 0.69210 - acc: 0.5325 -- iter: 512/582
[A[ATraining Step: 74  | total loss: [1m[32m0.69223[0m[0m | time: 10.025s
[2K
| Adam | epoch: 004 | loss: 0.69223 - acc: 0.5289 -- iter: 544/582
[A[ATraining Step: 75  | total loss: [1m[32m0.69386[0m[0m | time: 10.637s
[2K
| Adam | epoch: 004 | loss: 0.69386 - acc: 0.5088 -- iter: 576/582
[A[ATraining Step: 76  | total loss: [1m[32m0.69380[0m[0m | time: 12.395s
[2K
| Adam | epoch: 004 | loss: 0.69380 - acc: 0.5079 | val_loss: 0.69408 - val_acc: 0.4890 -- iter: 582/582
--
Training Step: 77  | total loss: [1m[32m0.69301[0m[0m | time: 0.619s
[2K
| Adam | epoch: 005 | loss: 0.69301 - acc: 0.5170 -- iter: 032/582
[A[ATraining Step: 78  | total loss: [1m[32m0.69320[0m[0m | time: 1.235s
[2K
| Adam | epoch: 005 | loss: 0.69320 - acc: 0.5119 -- iter: 064/582
[A[ATraining Step: 79  | total loss: [1m[32m0.69229[0m[0m | time: 1.387s
[2K
| Adam | epoch: 005 | loss: 0.69229 - acc: 0.5236 -- iter: 096/582
[A[ATraining Step: 80  | total loss: [1m[32m0.69236[0m[0m | time: 1.536s
[2K
| Adam | epoch: 005 | loss: 0.69236 - acc: 0.5212 -- iter: 128/582
[A[ATraining Step: 81  | total loss: [1m[32m0.69236[0m[0m | time: 2.131s
[2K
| Adam | epoch: 005 | loss: 0.69236 - acc: 0.5191 -- iter: 160/582
[A[ATraining Step: 82  | total loss: [1m[32m0.69163[0m[0m | time: 2.737s
[2K
| Adam | epoch: 005 | loss: 0.69163 - acc: 0.5265 -- iter: 192/582
[A[ATraining Step: 83  | total loss: [1m[32m0.69092[0m[0m | time: 3.459s
[2K
| Adam | epoch: 005 | loss: 0.69092 - acc: 0.5333 -- iter: 224/582
[A[ATraining Step: 84  | total loss: [1m[32m0.68984[0m[0m | time: 4.197s
[2K
| Adam | epoch: 005 | loss: 0.68984 - acc: 0.5456 -- iter: 256/582
[A[ATraining Step: 85  | total loss: [1m[32m0.68987[0m[0m | time: 4.916s
[2K
| Adam | epoch: 005 | loss: 0.68987 - acc: 0.5441 -- iter: 288/582
[A[ATraining Step: 86  | total loss: [1m[32m0.68927[0m[0m | time: 5.614s
[2K
| Adam | epoch: 005 | loss: 0.68927 - acc: 0.5491 -- iter: 320/582
[A[ATraining Step: 87  | total loss: [1m[32m0.68988[0m[0m | time: 6.254s
[2K
| Adam | epoch: 005 | loss: 0.68988 - acc: 0.5411 -- iter: 352/582
[A[ATraining Step: 88  | total loss: [1m[32m0.69027[0m[0m | time: 6.833s
[2K
| Adam | epoch: 005 | loss: 0.69027 - acc: 0.5369 -- iter: 384/582
[A[ATraining Step: 89  | total loss: [1m[32m0.68967[0m[0m | time: 7.447s
[2K
| Adam | epoch: 005 | loss: 0.68967 - acc: 0.5395 -- iter: 416/582
[A[ATraining Step: 90  | total loss: [1m[32m0.68855[0m[0m | time: 8.059s
[2K
| Adam | epoch: 005 | loss: 0.68855 - acc: 0.5449 -- iter: 448/582
[A[ATraining Step: 91  | total loss: [1m[32m0.69089[0m[0m | time: 8.662s
[2K
| Adam | epoch: 005 | loss: 0.69089 - acc: 0.5311 -- iter: 480/582
[A[ATraining Step: 92  | total loss: [1m[32m0.69137[0m[0m | time: 9.274s
[2K
| Adam | epoch: 005 | loss: 0.69137 - acc: 0.5248 -- iter: 512/582
[A[ATraining Step: 93  | total loss: [1m[32m0.68969[0m[0m | time: 9.878s
[2K
| Adam | epoch: 005 | loss: 0.68969 - acc: 0.5317 -- iter: 544/582
[A[ATraining Step: 94  | total loss: [1m[32m0.68980[0m[0m | time: 10.637s
[2K
| Adam | epoch: 005 | loss: 0.68980 - acc: 0.5285 -- iter: 576/582
[A[ATraining Step: 95  | total loss: [1m[32m0.69006[0m[0m | time: 12.257s
[2K
| Adam | epoch: 005 | loss: 0.69006 - acc: 0.5226 | val_loss: 0.69053 - val_acc: 0.4890 -- iter: 582/582
--
Training Step: 96  | total loss: [1m[32m0.68892[0m[0m | time: 0.617s
[2K
| Adam | epoch: 006 | loss: 0.68892 - acc: 0.5266 -- iter: 032/582
[A[ATraining Step: 97  | total loss: [1m[32m0.68855[0m[0m | time: 1.229s
[2K
| Adam | epoch: 006 | loss: 0.68855 - acc: 0.5270 -- iter: 064/582
[A[ATraining Step: 98  | total loss: [1m[32m0.68655[0m[0m | time: 1.842s
[2K
| Adam | epoch: 006 | loss: 0.68655 - acc: 0.5306 -- iter: 096/582
[A[ATraining Step: 99  | total loss: [1m[32m0.68606[0m[0m | time: 1.980s
[2K
| Adam | epoch: 006 | loss: 0.68606 - acc: 0.5244 -- iter: 128/582
[A[ATraining Step: 100  | total loss: [1m[32m0.67551[0m[0m | time: 2.121s
[2K
| Adam | epoch: 006 | loss: 0.67551 - acc: 0.5553 -- iter: 160/582
[A[ATraining Step: 101  | total loss: [1m[32m0.66115[0m[0m | time: 2.728s
[2K
| Adam | epoch: 006 | loss: 0.66115 - acc: 0.5831 -- iter: 192/582
[A[ATraining Step: 102  | total loss: [1m[32m0.67143[0m[0m | time: 3.376s
[2K
| Adam | epoch: 006 | loss: 0.67143 - acc: 0.5654 -- iter: 224/582
[A[ATraining Step: 103  | total loss: [1m[32m0.67005[0m[0m | time: 3.977s
[2K
| Adam | epoch: 006 | loss: 0.67005 - acc: 0.5682 -- iter: 256/582
[A[ATraining Step: 104  | total loss: [1m[32m0.67060[0m[0m | time: 4.559s
[2K
| Adam | epoch: 006 | loss: 0.67060 - acc: 0.5677 -- iter: 288/582
[A[ATraining Step: 105  | total loss: [1m[32m0.66241[0m[0m | time: 5.168s
[2K
| Adam | epoch: 006 | loss: 0.66241 - acc: 0.5797 -- iter: 320/582
[A[ATraining Step: 106  | total loss: [1m[32m0.66418[0m[0m | time: 5.776s
[2K
| Adam | epoch: 006 | loss: 0.66418 - acc: 0.5748 -- iter: 352/582
[A[ATraining Step: 107  | total loss: [1m[32m0.66547[0m[0m | time: 6.389s
[2K
| Adam | epoch: 006 | loss: 0.66547 - acc: 0.5673 -- iter: 384/582
[A[ATraining Step: 108  | total loss: [1m[32m0.65899[0m[0m | time: 7.015s
[2K
| Adam | epoch: 006 | loss: 0.65899 - acc: 0.5762 -- iter: 416/582
[A[ATraining Step: 109  | total loss: [1m[32m0.66641[0m[0m | time: 7.631s
[2K
| Adam | epoch: 006 | loss: 0.66641 - acc: 0.5530 -- iter: 448/582
[A[ATraining Step: 110  | total loss: [1m[32m0.66690[0m[0m | time: 8.245s
[2K
| Adam | epoch: 006 | loss: 0.66690 - acc: 0.5383 -- iter: 480/582
[A[ATraining Step: 111  | total loss: [1m[32m0.66655[0m[0m | time: 8.855s
[2K
| Adam | epoch: 006 | loss: 0.66655 - acc: 0.5438 -- iter: 512/582
[A[ATraining Step: 112  | total loss: [1m[32m0.66533[0m[0m | time: 9.468s
[2K
| Adam | epoch: 006 | loss: 0.66533 - acc: 0.5520 -- iter: 544/582
[A[ATraining Step: 113  | total loss: [1m[32m0.66807[0m[0m | time: 10.068s
[2K
| Adam | epoch: 006 | loss: 0.66807 - acc: 0.5468 -- iter: 576/582
[A[ATraining Step: 114  | total loss: [1m[32m0.66711[0m[0m | time: 11.671s
[2K
| Adam | epoch: 006 | loss: 0.66711 - acc: 0.5515 | val_loss: 0.68435 - val_acc: 0.5385 -- iter: 582/582
--
Training Step: 115  | total loss: [1m[32m0.66426[0m[0m | time: 0.598s
[2K
| Adam | epoch: 007 | loss: 0.66426 - acc: 0.5526 -- iter: 032/582
[A[ATraining Step: 116  | total loss: [1m[32m0.66736[0m[0m | time: 1.232s
[2K
| Adam | epoch: 007 | loss: 0.66736 - acc: 0.5473 -- iter: 064/582
[A[ATraining Step: 117  | total loss: [1m[32m0.66107[0m[0m | time: 1.832s
[2K
| Adam | epoch: 007 | loss: 0.66107 - acc: 0.5582 -- iter: 096/582
[A[ATraining Step: 118  | total loss: [1m[32m0.65038[0m[0m | time: 2.429s
[2K
| Adam | epoch: 007 | loss: 0.65038 - acc: 0.5743 -- iter: 128/582
[A[ATraining Step: 119  | total loss: [1m[32m0.64741[0m[0m | time: 2.579s
[2K
| Adam | epoch: 007 | loss: 0.64741 - acc: 0.5856 -- iter: 160/582
[A[ATraining Step: 120  | total loss: [1m[32m0.66815[0m[0m | time: 2.731s
[2K
| Adam | epoch: 007 | loss: 0.66815 - acc: 0.5770 -- iter: 192/582
[A[ATraining Step: 121  | total loss: [1m[32m0.67979[0m[0m | time: 3.343s
[2K
| Adam | epoch: 007 | loss: 0.67979 - acc: 0.5693 -- iter: 224/582
[A[ATraining Step: 122  | total loss: [1m[32m0.67639[0m[0m | time: 3.955s
[2K
| Adam | epoch: 007 | loss: 0.67639 - acc: 0.5780 -- iter: 256/582
[A[ATraining Step: 123  | total loss: [1m[32m0.67195[0m[0m | time: 4.567s
[2K
| Adam | epoch: 007 | loss: 0.67195 - acc: 0.5983 -- iter: 288/582
[A[ATraining Step: 124  | total loss: [1m[32m0.66975[0m[0m | time: 5.172s
[2K
| Adam | epoch: 007 | loss: 0.66975 - acc: 0.6073 -- iter: 320/582
[A[ATraining Step: 125  | total loss: [1m[32m0.66250[0m[0m | time: 5.794s
[2K
| Adam | epoch: 007 | loss: 0.66250 - acc: 0.6340 -- iter: 352/582
[A[ATraining Step: 126  | total loss: [1m[32m0.66058[0m[0m | time: 6.403s
[2K
| Adam | epoch: 007 | loss: 0.66058 - acc: 0.6394 -- iter: 384/582
[A[ATraining Step: 127  | total loss: [1m[32m0.66135[0m[0m | time: 7.009s
[2K
| Adam | epoch: 007 | loss: 0.66135 - acc: 0.6317 -- iter: 416/582
[A[ATraining Step: 128  | total loss: [1m[32m0.65868[0m[0m | time: 7.621s
[2K
| Adam | epoch: 007 | loss: 0.65868 - acc: 0.6373 -- iter: 448/582
[A[ATraining Step: 129  | total loss: [1m[32m0.65720[0m[0m | time: 8.235s
[2K
| Adam | epoch: 007 | loss: 0.65720 - acc: 0.6392 -- iter: 480/582
[A[ATraining Step: 130  | total loss: [1m[32m0.64660[0m[0m | time: 8.855s
[2K
| Adam | epoch: 007 | loss: 0.64660 - acc: 0.6596 -- iter: 512/582
[A[ATraining Step: 131  | total loss: [1m[32m0.63951[0m[0m | time: 9.441s
[2K
| Adam | epoch: 007 | loss: 0.63951 - acc: 0.6687 -- iter: 544/582
[A[ATraining Step: 132  | total loss: [1m[32m0.62790[0m[0m | time: 10.036s
[2K
| Adam | epoch: 007 | loss: 0.62790 - acc: 0.6768 -- iter: 576/582
[A[ATraining Step: 133  | total loss: [1m[32m0.61392[0m[0m | time: 11.668s
[2K
| Adam | epoch: 007 | loss: 0.61392 - acc: 0.6872 | val_loss: 0.59401 - val_acc: 0.6648 -- iter: 582/582
--
Training Step: 134  | total loss: [1m[32m0.60799[0m[0m | time: 0.707s
[2K
| Adam | epoch: 008 | loss: 0.60799 - acc: 0.6998 -- iter: 032/582
[A[ATraining Step: 135  | total loss: [1m[32m0.59073[0m[0m | time: 1.286s
[2K
| Adam | epoch: 008 | loss: 0.59073 - acc: 0.7204 -- iter: 064/582
[A[ATraining Step: 136  | total loss: [1m[32m0.58114[0m[0m | time: 1.885s
[2K
| Adam | epoch: 008 | loss: 0.58114 - acc: 0.7296 -- iter: 096/582
[A[ATraining Step: 137  | total loss: [1m[32m0.58228[0m[0m | time: 2.492s
[2K
| Adam | epoch: 008 | loss: 0.58228 - acc: 0.7192 -- iter: 128/582
[A[ATraining Step: 138  | total loss: [1m[32m0.58566[0m[0m | time: 3.090s
[2K
| Adam | epoch: 008 | loss: 0.58566 - acc: 0.7191 -- iter: 160/582
[A[ATraining Step: 139  | total loss: [1m[32m0.57751[0m[0m | time: 3.248s
[2K
| Adam | epoch: 008 | loss: 0.57751 - acc: 0.7222 -- iter: 192/582
[A[ATraining Step: 140  | total loss: [1m[32m0.61511[0m[0m | time: 3.397s
[2K
| Adam | epoch: 008 | loss: 0.61511 - acc: 0.7000 -- iter: 224/582
[A[ATraining Step: 141  | total loss: [1m[32m0.63717[0m[0m | time: 4.004s
[2K
| Adam | epoch: 008 | loss: 0.63717 - acc: 0.6800 -- iter: 256/582
[A[ATraining Step: 142  | total loss: [1m[32m0.63380[0m[0m | time: 4.612s
[2K
| Adam | epoch: 008 | loss: 0.63380 - acc: 0.6776 -- iter: 288/582
[A[ATraining Step: 143  | total loss: [1m[32m0.62021[0m[0m | time: 5.221s
[2K
| Adam | epoch: 008 | loss: 0.62021 - acc: 0.6849 -- iter: 320/582
[A[ATraining Step: 144  | total loss: [1m[32m0.60745[0m[0m | time: 5.823s
[2K
| Adam | epoch: 008 | loss: 0.60745 - acc: 0.6914 -- iter: 352/582
[A[ATraining Step: 145  | total loss: [1m[32m0.62058[0m[0m | time: 6.422s
[2K
| Adam | epoch: 008 | loss: 0.62058 - acc: 0.6785 -- iter: 384/582
[A[ATraining Step: 146  | total loss: [1m[32m0.60281[0m[0m | time: 7.020s
[2K
| Adam | epoch: 008 | loss: 0.60281 - acc: 0.6919 -- iter: 416/582
[A[ATraining Step: 147  | total loss: [1m[32m0.60839[0m[0m | time: 7.611s
[2K
| Adam | epoch: 008 | loss: 0.60839 - acc: 0.6821 -- iter: 448/582
[A[ATraining Step: 148  | total loss: [1m[32m0.59846[0m[0m | time: 8.210s
[2K
| Adam | epoch: 008 | loss: 0.59846 - acc: 0.6920 -- iter: 480/582
[A[ATraining Step: 149  | total loss: [1m[32m0.58625[0m[0m | time: 8.821s
[2K
| Adam | epoch: 008 | loss: 0.58625 - acc: 0.7040 -- iter: 512/582
[A[ATraining Step: 150  | total loss: [1m[32m0.57885[0m[0m | time: 9.425s
[2K
| Adam | epoch: 008 | loss: 0.57885 - acc: 0.7211 -- iter: 544/582
[A[ATraining Step: 151  | total loss: [1m[32m0.57069[0m[0m | time: 10.024s
[2K
| Adam | epoch: 008 | loss: 0.57069 - acc: 0.7271 -- iter: 576/582
[A[ATraining Step: 152  | total loss: [1m[32m0.56994[0m[0m | time: 11.633s
[2K
| Adam | epoch: 008 | loss: 0.56994 - acc: 0.7294 | val_loss: 0.55305 - val_acc: 0.7418 -- iter: 582/582
--
Training Step: 153  | total loss: [1m[32m0.56645[0m[0m | time: 0.613s
[2K
| Adam | epoch: 009 | loss: 0.56645 - acc: 0.7346 -- iter: 032/582
[A[ATraining Step: 154  | total loss: [1m[32m0.55381[0m[0m | time: 1.214s
[2K
| Adam | epoch: 009 | loss: 0.55381 - acc: 0.7487 -- iter: 064/582
[A[ATraining Step: 155  | total loss: [1m[32m0.54890[0m[0m | time: 1.816s
[2K
| Adam | epoch: 009 | loss: 0.54890 - acc: 0.7519 -- iter: 096/582
[A[ATraining Step: 156  | total loss: [1m[32m0.54842[0m[0m | time: 2.460s
[2K
| Adam | epoch: 009 | loss: 0.54842 - acc: 0.7455 -- iter: 128/582
[A[ATraining Step: 157  | total loss: [1m[32m0.53690[0m[0m | time: 3.089s
[2K
| Adam | epoch: 009 | loss: 0.53690 - acc: 0.7553 -- iter: 160/582
[A[ATraining Step: 158  | total loss: [1m[32m0.52722[0m[0m | time: 3.708s
[2K
| Adam | epoch: 009 | loss: 0.52722 - acc: 0.7579 -- iter: 192/582
[A[ATraining Step: 159  | total loss: [1m[32m0.52721[0m[0m | time: 3.850s
[2K
| Adam | epoch: 009 | loss: 0.52721 - acc: 0.7540 -- iter: 224/582
[A[ATraining Step: 160  | total loss: [1m[32m0.56384[0m[0m | time: 3.996s
[2K
| Adam | epoch: 009 | loss: 0.56384 - acc: 0.7119 -- iter: 256/582
[A[ATraining Step: 161  | total loss: [1m[32m0.56346[0m[0m | time: 4.615s
[2K
| Adam | epoch: 009 | loss: 0.56346 - acc: 0.7074 -- iter: 288/582
[A[ATraining Step: 162  | total loss: [1m[32m0.56079[0m[0m | time: 5.226s
[2K
| Adam | epoch: 009 | loss: 0.56079 - acc: 0.6992 -- iter: 320/582
[A[ATraining Step: 163  | total loss: [1m[32m0.56629[0m[0m | time: 5.829s
[2K
| Adam | epoch: 009 | loss: 0.56629 - acc: 0.6949 -- iter: 352/582
[A[ATraining Step: 164  | total loss: [1m[32m0.56595[0m[0m | time: 6.442s
[2K
| Adam | epoch: 009 | loss: 0.56595 - acc: 0.6941 -- iter: 384/582
[A[ATraining Step: 165  | total loss: [1m[32m0.56019[0m[0m | time: 7.036s
[2K
| Adam | epoch: 009 | loss: 0.56019 - acc: 0.6997 -- iter: 416/582
[A[ATraining Step: 166  | total loss: [1m[32m0.54847[0m[0m | time: 7.636s
[2K
| Adam | epoch: 009 | loss: 0.54847 - acc: 0.7141 -- iter: 448/582
[A[ATraining Step: 167  | total loss: [1m[32m0.54544[0m[0m | time: 8.247s
[2K
| Adam | epoch: 009 | loss: 0.54544 - acc: 0.7146 -- iter: 480/582
[A[ATraining Step: 168  | total loss: [1m[32m0.53126[0m[0m | time: 8.848s
[2K
| Adam | epoch: 009 | loss: 0.53126 - acc: 0.7275 -- iter: 512/582
[A[ATraining Step: 169  | total loss: [1m[32m0.54051[0m[0m | time: 9.471s
[2K
| Adam | epoch: 009 | loss: 0.54051 - acc: 0.7172 -- iter: 544/582
[A[ATraining Step: 170  | total loss: [1m[32m0.51979[0m[0m | time: 10.091s
[2K
| Adam | epoch: 009 | loss: 0.51979 - acc: 0.7330 -- iter: 576/582
[A[ATraining Step: 171  | total loss: [1m[32m0.51254[0m[0m | time: 11.695s
[2K
| Adam | epoch: 009 | loss: 0.51254 - acc: 0.7410 | val_loss: 0.49634 - val_acc: 0.7582 -- iter: 582/582
--
Training Step: 172  | total loss: [1m[32m0.50245[0m[0m | time: 0.629s
[2K
| Adam | epoch: 010 | loss: 0.50245 - acc: 0.7481 -- iter: 032/582
[A[ATraining Step: 173  | total loss: [1m[32m0.48863[0m[0m | time: 1.228s
[2K
| Adam | epoch: 010 | loss: 0.48863 - acc: 0.7671 -- iter: 064/582
[A[ATraining Step: 174  | total loss: [1m[32m0.47537[0m[0m | time: 1.855s
[2K
| Adam | epoch: 010 | loss: 0.47537 - acc: 0.7716 -- iter: 096/582
[A[ATraining Step: 175  | total loss: [1m[32m0.46869[0m[0m | time: 2.468s
[2K
| Adam | epoch: 010 | loss: 0.46869 - acc: 0.7788 -- iter: 128/582
[A[ATraining Step: 176  | total loss: [1m[32m0.45632[0m[0m | time: 3.076s
[2K
| Adam | epoch: 010 | loss: 0.45632 - acc: 0.7916 -- iter: 160/582
[A[ATraining Step: 177  | total loss: [1m[32m0.44915[0m[0m | time: 3.680s
[2K
| Adam | epoch: 010 | loss: 0.44915 - acc: 0.7968 -- iter: 192/582
[A[ATraining Step: 178  | total loss: [1m[32m0.42393[0m[0m | time: 4.312s
[2K
| Adam | epoch: 010 | loss: 0.42393 - acc: 0.8077 -- iter: 224/582
[A[ATraining Step: 179  | total loss: [1m[32m0.41866[0m[0m | time: 4.474s
[2K
| Adam | epoch: 010 | loss: 0.41866 - acc: 0.8113 -- iter: 256/582
[A[ATraining Step: 180  | total loss: [1m[32m0.44549[0m[0m | time: 4.627s
[2K
| Adam | epoch: 010 | loss: 0.44549 - acc: 0.7969 -- iter: 288/582
[A[ATraining Step: 181  | total loss: [1m[32m0.45494[0m[0m | time: 5.229s
[2K
| Adam | epoch: 010 | loss: 0.45494 - acc: 0.7838 -- iter: 320/582
[A[ATraining Step: 182  | total loss: [1m[32m0.43682[0m[0m | time: 5.834s
[2K
| Adam | epoch: 010 | loss: 0.43682 - acc: 0.7992 -- iter: 352/582
[A[ATraining Step: 183  | total loss: [1m[32m0.42516[0m[0m | time: 6.418s
[2K
| Adam | epoch: 010 | loss: 0.42516 - acc: 0.8130 -- iter: 384/582
[A[ATraining Step: 184  | total loss: [1m[32m0.42194[0m[0m | time: 7.017s
[2K
| Adam | epoch: 010 | loss: 0.42194 - acc: 0.8192 -- iter: 416/582
[A[ATraining Step: 185  | total loss: [1m[32m0.41169[0m[0m | time: 7.623s
[2K
| Adam | epoch: 010 | loss: 0.41169 - acc: 0.8217 -- iter: 448/582
[A[ATraining Step: 186  | total loss: [1m[32m0.40696[0m[0m | time: 8.229s
[2K
| Adam | epoch: 010 | loss: 0.40696 - acc: 0.8270 -- iter: 480/582
[A[ATraining Step: 187  | total loss: [1m[32m0.40444[0m[0m | time: 8.841s
[2K
| Adam | epoch: 010 | loss: 0.40444 - acc: 0.8287 -- iter: 512/582
[A[ATraining Step: 188  | total loss: [1m[32m0.39931[0m[0m | time: 9.432s
[2K
| Adam | epoch: 010 | loss: 0.39931 - acc: 0.8333 -- iter: 544/582
[A[ATraining Step: 189  | total loss: [1m[32m0.39140[0m[0m | time: 10.040s
[2K
| Adam | epoch: 010 | loss: 0.39140 - acc: 0.8344 -- iter: 576/582
[A[ATraining Step: 190  | total loss: [1m[32m0.37258[0m[0m | time: 11.650s
[2K
| Adam | epoch: 010 | loss: 0.37258 - acc: 0.8478 | val_loss: 0.45864 - val_acc: 0.7912 -- iter: 582/582
--
Training Step: 191  | total loss: [1m[32m0.36748[0m[0m | time: 0.621s
[2K
| Adam | epoch: 011 | loss: 0.36748 - acc: 0.8474 -- iter: 032/582
[A[ATraining Step: 192  | total loss: [1m[32m0.35080[0m[0m | time: 1.223s
[2K
| Adam | epoch: 011 | loss: 0.35080 - acc: 0.8564 -- iter: 064/582
[A[ATraining Step: 193  | total loss: [1m[32m0.34967[0m[0m | time: 1.829s
[2K
| Adam | epoch: 011 | loss: 0.34967 - acc: 0.8520 -- iter: 096/582
[A[ATraining Step: 194  | total loss: [1m[32m0.36469[0m[0m | time: 2.424s
[2K
| Adam | epoch: 011 | loss: 0.36469 - acc: 0.8418 -- iter: 128/582
[A[ATraining Step: 195  | total loss: [1m[32m0.34543[0m[0m | time: 3.026s
[2K
| Adam | epoch: 011 | loss: 0.34543 - acc: 0.8576 -- iter: 160/582
[A[ATraining Step: 196  | total loss: [1m[32m0.35317[0m[0m | time: 3.620s
[2K
| Adam | epoch: 011 | loss: 0.35317 - acc: 0.8500 -- iter: 192/582
[A[ATraining Step: 197  | total loss: [1m[32m0.34104[0m[0m | time: 4.220s
[2K
| Adam | epoch: 011 | loss: 0.34104 - acc: 0.8556 -- iter: 224/582
[A[ATraining Step: 198  | total loss: [1m[32m0.33187[0m[0m | time: 4.837s
[2K
| Adam | epoch: 011 | loss: 0.33187 - acc: 0.8607 -- iter: 256/582
[A[ATraining Step: 199  | total loss: [1m[32m0.31715[0m[0m | time: 4.975s
[2K
| Adam | epoch: 011 | loss: 0.31715 - acc: 0.8715 -- iter: 288/582
[A[ATraining Step: 200  | total loss: [1m[32m0.30520[0m[0m | time: 6.126s
[2K
| Adam | epoch: 011 | loss: 0.30520 - acc: 0.8677 | val_loss: 0.59924 - val_acc: 0.7692 -- iter: 320/582
--
Training Step: 201  | total loss: [1m[32m0.28622[0m[0m | time: 6.735s
[2K
| Adam | epoch: 011 | loss: 0.28622 - acc: 0.8809 -- iter: 352/582
[A[ATraining Step: 202  | total loss: [1m[32m0.28195[0m[0m | time: 7.361s
[2K
| Adam | epoch: 011 | loss: 0.28195 - acc: 0.8834 -- iter: 384/582
[A[ATraining Step: 203  | total loss: [1m[32m0.28850[0m[0m | time: 7.983s
[2K
| Adam | epoch: 011 | loss: 0.28850 - acc: 0.8826 -- iter: 416/582
[A[ATraining Step: 204  | total loss: [1m[32m0.31369[0m[0m | time: 8.643s
[2K
| Adam | epoch: 011 | loss: 0.31369 - acc: 0.8725 -- iter: 448/582
[A[ATraining Step: 205  | total loss: [1m[32m0.30911[0m[0m | time: 9.243s
[2K
| Adam | epoch: 011 | loss: 0.30911 - acc: 0.8790 -- iter: 480/582
[A[ATraining Step: 206  | total loss: [1m[32m0.30808[0m[0m | time: 9.851s
[2K
| Adam | epoch: 011 | loss: 0.30808 - acc: 0.8817 -- iter: 512/582
[A[ATraining Step: 207  | total loss: [1m[32m0.34050[0m[0m | time: 10.457s
[2K
| Adam | epoch: 011 | loss: 0.34050 - acc: 0.8592 -- iter: 544/582
[A[ATraining Step: 208  | total loss: [1m[32m0.33027[0m[0m | time: 11.064s
[2K
| Adam | epoch: 011 | loss: 0.33027 - acc: 0.8607 -- iter: 576/582
[A[ATraining Step: 209  | total loss: [1m[32m0.31310[0m[0m | time: 12.680s
[2K
| Adam | epoch: 011 | loss: 0.31310 - acc: 0.8715 | val_loss: 0.51486 - val_acc: 0.7857 -- iter: 582/582
--
Training Step: 210  | total loss: [1m[32m0.31389[0m[0m | time: 0.636s
[2K
| Adam | epoch: 012 | loss: 0.31389 - acc: 0.8719 -- iter: 032/582
[A[ATraining Step: 211  | total loss: [1m[32m0.30435[0m[0m | time: 1.238s
[2K
| Adam | epoch: 012 | loss: 0.30435 - acc: 0.8722 -- iter: 064/582
[A[ATraining Step: 212  | total loss: [1m[32m0.29135[0m[0m | time: 1.857s
[2K
| Adam | epoch: 012 | loss: 0.29135 - acc: 0.8787 -- iter: 096/582
[A[ATraining Step: 213  | total loss: [1m[32m0.30059[0m[0m | time: 2.484s
[2K
| Adam | epoch: 012 | loss: 0.30059 - acc: 0.8752 -- iter: 128/582
[A[ATraining Step: 214  | total loss: [1m[32m0.31413[0m[0m | time: 3.106s
[2K
| Adam | epoch: 012 | loss: 0.31413 - acc: 0.8721 -- iter: 160/582
[A[ATraining Step: 215  | total loss: [1m[32m0.29918[0m[0m | time: 3.717s
[2K
| Adam | epoch: 012 | loss: 0.29918 - acc: 0.8786 -- iter: 192/582
[A[ATraining Step: 216  | total loss: [1m[32m0.29428[0m[0m | time: 4.323s
[2K
| Adam | epoch: 012 | loss: 0.29428 - acc: 0.8783 -- iter: 224/582
[A[ATraining Step: 217  | total loss: [1m[32m0.27789[0m[0m | time: 4.938s
[2K
| Adam | epoch: 012 | loss: 0.27789 - acc: 0.8904 -- iter: 256/582
[A[ATraining Step: 218  | total loss: [1m[32m0.26553[0m[0m | time: 5.561s
[2K
| Adam | epoch: 012 | loss: 0.26553 - acc: 0.8983 -- iter: 288/582
[A[ATraining Step: 219  | total loss: [1m[32m0.25379[0m[0m | time: 5.710s
[2K
| Adam | epoch: 012 | loss: 0.25379 - acc: 0.9084 -- iter: 320/582
[A[ATraining Step: 220  | total loss: [1m[32m0.27946[0m[0m | time: 5.868s
[2K
| Adam | epoch: 012 | loss: 0.27946 - acc: 0.9009 -- iter: 352/582
[A[ATraining Step: 221  | total loss: [1m[32m0.28859[0m[0m | time: 6.471s
[2K
| Adam | epoch: 012 | loss: 0.28859 - acc: 0.8942 -- iter: 384/582
[A[ATraining Step: 222  | total loss: [1m[32m0.28329[0m[0m | time: 7.075s
[2K
| Adam | epoch: 012 | loss: 0.28329 - acc: 0.8954 -- iter: 416/582
[A[ATraining Step: 223  | total loss: [1m[32m0.27557[0m[0m | time: 7.712s
[2K
| Adam | epoch: 012 | loss: 0.27557 - acc: 0.8965 -- iter: 448/582
[A[ATraining Step: 224  | total loss: [1m[32m0.27955[0m[0m | time: 8.315s
[2K
| Adam | epoch: 012 | loss: 0.27955 - acc: 0.8943 -- iter: 480/582
[A[ATraining Step: 225  | total loss: [1m[32m0.27386[0m[0m | time: 8.928s
[2K
| Adam | epoch: 012 | loss: 0.27386 - acc: 0.9018 -- iter: 512/582
[A[ATraining Step: 226  | total loss: [1m[32m0.29850[0m[0m | time: 9.537s
[2K
| Adam | epoch: 012 | loss: 0.29850 - acc: 0.8835 -- iter: 544/582
[A[ATraining Step: 227  | total loss: [1m[32m0.28119[0m[0m | time: 10.169s
[2K
| Adam | epoch: 012 | loss: 0.28119 - acc: 0.8920 -- iter: 576/582
[A[ATraining Step: 228  | total loss: [1m[32m0.28929[0m[0m | time: 11.773s
[2K
| Adam | epoch: 012 | loss: 0.28929 - acc: 0.8934 | val_loss: 0.42892 - val_acc: 0.8297 -- iter: 582/582
--
Training Step: 229  | total loss: [1m[32m0.26732[0m[0m | time: 0.620s
[2K
| Adam | epoch: 013 | loss: 0.26732 - acc: 0.9041 -- iter: 032/582
[A[ATraining Step: 230  | total loss: [1m[32m0.25117[0m[0m | time: 1.230s
[2K
| Adam | epoch: 013 | loss: 0.25117 - acc: 0.9137 -- iter: 064/582
[A[ATraining Step: 231  | total loss: [1m[32m0.24869[0m[0m | time: 1.824s
[2K
| Adam | epoch: 013 | loss: 0.24869 - acc: 0.9129 -- iter: 096/582
[A[ATraining Step: 232  | total loss: [1m[32m0.23369[0m[0m | time: 2.423s
[2K
| Adam | epoch: 013 | loss: 0.23369 - acc: 0.9185 -- iter: 128/582
[A[ATraining Step: 233  | total loss: [1m[32m0.23378[0m[0m | time: 3.020s
[2K
| Adam | epoch: 013 | loss: 0.23378 - acc: 0.9235 -- iter: 160/582
[A[ATraining Step: 234  | total loss: [1m[32m0.22067[0m[0m | time: 3.650s
[2K
| Adam | epoch: 013 | loss: 0.22067 - acc: 0.9312 -- iter: 192/582
[A[ATraining Step: 235  | total loss: [1m[32m0.21889[0m[0m | time: 4.275s
[2K
| Adam | epoch: 013 | loss: 0.21889 - acc: 0.9318 -- iter: 224/582
[A[ATraining Step: 236  | total loss: [1m[32m0.21908[0m[0m | time: 4.877s
[2K
| Adam | epoch: 013 | loss: 0.21908 - acc: 0.9324 -- iter: 256/582
[A[ATraining Step: 237  | total loss: [1m[32m0.22551[0m[0m | time: 5.463s
[2K
| Adam | epoch: 013 | loss: 0.22551 - acc: 0.9298 -- iter: 288/582
[A[ATraining Step: 238  | total loss: [1m[32m0.22721[0m[0m | time: 6.078s
[2K
| Adam | epoch: 013 | loss: 0.22721 - acc: 0.9274 -- iter: 320/582
[A[ATraining Step: 239  | total loss: [1m[32m0.22667[0m[0m | time: 6.219s
[2K
| Adam | epoch: 013 | loss: 0.22667 - acc: 0.9222 -- iter: 352/582
[A[ATraining Step: 240  | total loss: [1m[32m0.22026[0m[0m | time: 6.365s
[2K
| Adam | epoch: 013 | loss: 0.22026 - acc: 0.9300 -- iter: 384/582
[A[ATraining Step: 241  | total loss: [1m[32m0.20566[0m[0m | time: 6.971s
[2K
| Adam | epoch: 013 | loss: 0.20566 - acc: 0.9370 -- iter: 416/582
[A[ATraining Step: 242  | total loss: [1m[32m0.20452[0m[0m | time: 7.584s
[2K
| Adam | epoch: 013 | loss: 0.20452 - acc: 0.9308 -- iter: 448/582
[A[ATraining Step: 243  | total loss: [1m[32m0.19239[0m[0m | time: 8.191s
[2K
| Adam | epoch: 013 | loss: 0.19239 - acc: 0.9346 -- iter: 480/582
[A[ATraining Step: 244  | total loss: [1m[32m0.18548[0m[0m | time: 8.818s
[2K
| Adam | epoch: 013 | loss: 0.18548 - acc: 0.9349 -- iter: 512/582
[A[ATraining Step: 245  | total loss: [1m[32m0.17395[0m[0m | time: 9.417s
[2K
| Adam | epoch: 013 | loss: 0.17395 - acc: 0.9414 -- iter: 544/582
[A[ATraining Step: 246  | total loss: [1m[32m0.18164[0m[0m | time: 10.015s
[2K
| Adam | epoch: 013 | loss: 0.18164 - acc: 0.9379 -- iter: 576/582
[A[ATraining Step: 247  | total loss: [1m[32m0.17404[0m[0m | time: 11.616s
[2K
| Adam | epoch: 013 | loss: 0.17404 - acc: 0.9409 | val_loss: 0.42162 - val_acc: 0.8462 -- iter: 582/582
--
Training Step: 248  | total loss: [1m[32m0.17218[0m[0m | time: 0.621s
[2K
| Adam | epoch: 014 | loss: 0.17218 - acc: 0.9375 -- iter: 032/582
[A[ATraining Step: 249  | total loss: [1m[32m0.16896[0m[0m | time: 1.229s
[2K
| Adam | epoch: 014 | loss: 0.16896 - acc: 0.9344 -- iter: 064/582
[A[ATraining Step: 250  | total loss: [1m[32m0.16386[0m[0m | time: 1.829s
[2K
| Adam | epoch: 014 | loss: 0.16386 - acc: 0.9378 -- iter: 096/582
[A[ATraining Step: 251  | total loss: [1m[32m0.14953[0m[0m | time: 2.429s
[2K
| Adam | epoch: 014 | loss: 0.14953 - acc: 0.9440 -- iter: 128/582
[A[ATraining Step: 252  | total loss: [1m[32m0.14289[0m[0m | time: 3.068s
[2K
| Adam | epoch: 014 | loss: 0.14289 - acc: 0.9496 -- iter: 160/582
[A[ATraining Step: 253  | total loss: [1m[32m0.13092[0m[0m | time: 3.671s
[2K
| Adam | epoch: 014 | loss: 0.13092 - acc: 0.9547 -- iter: 192/582
[A[ATraining Step: 254  | total loss: [1m[32m0.12789[0m[0m | time: 4.280s
[2K
| Adam | epoch: 014 | loss: 0.12789 - acc: 0.9529 -- iter: 224/582
[A[ATraining Step: 255  | total loss: [1m[32m0.13316[0m[0m | time: 4.876s
[2K
| Adam | epoch: 014 | loss: 0.13316 - acc: 0.9514 -- iter: 256/582
[A[ATraining Step: 256  | total loss: [1m[32m0.13228[0m[0m | time: 5.473s
[2K
| Adam | epoch: 014 | loss: 0.13228 - acc: 0.9531 -- iter: 288/582
[A[ATraining Step: 257  | total loss: [1m[32m0.13429[0m[0m | time: 6.087s
[2K
| Adam | epoch: 014 | loss: 0.13429 - acc: 0.9516 -- iter: 320/582
[A[ATraining Step: 258  | total loss: [1m[32m0.13758[0m[0m | time: 6.691s
[2K
| Adam | epoch: 014 | loss: 0.13758 - acc: 0.9502 -- iter: 352/582
[A[ATraining Step: 259  | total loss: [1m[32m0.12983[0m[0m | time: 6.830s
[2K
| Adam | epoch: 014 | loss: 0.12983 - acc: 0.9551 -- iter: 384/582
[A[ATraining Step: 260  | total loss: [1m[32m0.15541[0m[0m | time: 6.999s
[2K
| Adam | epoch: 014 | loss: 0.15541 - acc: 0.9263 -- iter: 416/582
[A[ATraining Step: 261  | total loss: [1m[32m0.16425[0m[0m | time: 7.582s
[2K
| Adam | epoch: 014 | loss: 0.16425 - acc: 0.9170 -- iter: 448/582
[A[ATraining Step: 262  | total loss: [1m[32m0.16988[0m[0m | time: 8.272s
[2K
| Adam | epoch: 014 | loss: 0.16988 - acc: 0.9222 -- iter: 480/582
[A[ATraining Step: 263  | total loss: [1m[32m0.17681[0m[0m | time: 8.870s
[2K
| Adam | epoch: 014 | loss: 0.17681 - acc: 0.9237 -- iter: 512/582
[A[ATraining Step: 264  | total loss: [1m[32m0.16388[0m[0m | time: 9.468s
[2K
| Adam | epoch: 014 | loss: 0.16388 - acc: 0.9313 -- iter: 544/582
[A[ATraining Step: 265  | total loss: [1m[32m0.15864[0m[0m | time: 10.065s
[2K
| Adam | epoch: 014 | loss: 0.15864 - acc: 0.9351 -- iter: 576/582
[A[ATraining Step: 266  | total loss: [1m[32m0.14539[0m[0m | time: 11.699s
[2K
| Adam | epoch: 014 | loss: 0.14539 - acc: 0.9416 | val_loss: 0.39999 - val_acc: 0.8571 -- iter: 582/582
--
Training Step: 267  | total loss: [1m[32m0.14393[0m[0m | time: 0.605s
[2K
| Adam | epoch: 015 | loss: 0.14393 - acc: 0.9412 -- iter: 032/582
[A[ATraining Step: 268  | total loss: [1m[32m0.17296[0m[0m | time: 1.216s
[2K
| Adam | epoch: 015 | loss: 0.17296 - acc: 0.9377 -- iter: 064/582
[A[ATraining Step: 269  | total loss: [1m[32m0.15771[0m[0m | time: 1.815s
[2K
| Adam | epoch: 015 | loss: 0.15771 - acc: 0.9439 -- iter: 096/582
[A[ATraining Step: 270  | total loss: [1m[32m0.14898[0m[0m | time: 2.423s
[2K
| Adam | epoch: 015 | loss: 0.14898 - acc: 0.9495 -- iter: 128/582
[A[ATraining Step: 271  | total loss: [1m[32m0.13981[0m[0m | time: 3.014s
[2K
| Adam | epoch: 015 | loss: 0.13981 - acc: 0.9514 -- iter: 160/582
[A[ATraining Step: 272  | total loss: [1m[32m0.13086[0m[0m | time: 3.624s
[2K
| Adam | epoch: 015 | loss: 0.13086 - acc: 0.9563 -- iter: 192/582
[A[ATraining Step: 273  | total loss: [1m[32m0.12125[0m[0m | time: 4.223s
[2K
| Adam | epoch: 015 | loss: 0.12125 - acc: 0.9607 -- iter: 224/582
[A[ATraining Step: 274  | total loss: [1m[32m0.11649[0m[0m | time: 4.848s
[2K
| Adam | epoch: 015 | loss: 0.11649 - acc: 0.9646 -- iter: 256/582
[A[ATraining Step: 275  | total loss: [1m[32m0.11097[0m[0m | time: 5.455s
[2K
| Adam | epoch: 015 | loss: 0.11097 - acc: 0.9650 -- iter: 288/582
[A[ATraining Step: 276  | total loss: [1m[32m0.11411[0m[0m | time: 6.038s
[2K
| Adam | epoch: 015 | loss: 0.11411 - acc: 0.9623 -- iter: 320/582
[A[ATraining Step: 277  | total loss: [1m[32m0.10899[0m[0m | time: 6.659s
[2K
| Adam | epoch: 015 | loss: 0.10899 - acc: 0.9629 -- iter: 352/582
[A[ATraining Step: 278  | total loss: [1m[32m0.11512[0m[0m | time: 7.264s
[2K
| Adam | epoch: 015 | loss: 0.11512 - acc: 0.9635 -- iter: 384/582
[A[ATraining Step: 279  | total loss: [1m[32m0.10771[0m[0m | time: 7.415s
[2K
| Adam | epoch: 015 | loss: 0.10771 - acc: 0.9671 -- iter: 416/582
[A[ATraining Step: 280  | total loss: [1m[32m0.10185[0m[0m | time: 7.551s
[2K
| Adam | epoch: 015 | loss: 0.10185 - acc: 0.9704 -- iter: 448/582
[A[ATraining Step: 281  | total loss: [1m[32m0.09569[0m[0m | time: 8.144s
[2K
| Adam | epoch: 015 | loss: 0.09569 - acc: 0.9734 -- iter: 480/582
[A[ATraining Step: 282  | total loss: [1m[32m0.08747[0m[0m | time: 8.752s
[2K
| Adam | epoch: 015 | loss: 0.08747 - acc: 0.9760 -- iter: 512/582
[A[ATraining Step: 283  | total loss: [1m[32m0.08261[0m[0m | time: 9.369s
[2K
| Adam | epoch: 015 | loss: 0.08261 - acc: 0.9784 -- iter: 544/582
[A[ATraining Step: 284  | total loss: [1m[32m0.08721[0m[0m | time: 9.982s
[2K
| Adam | epoch: 015 | loss: 0.08721 - acc: 0.9775 -- iter: 576/582
[A[ATraining Step: 285  | total loss: [1m[32m0.08064[0m[0m | time: 11.583s
[2K
| Adam | epoch: 015 | loss: 0.08064 - acc: 0.9797 | val_loss: 0.37076 - val_acc: 0.8736 -- iter: 582/582
--
Validation AUC:0.9359671378518787
Validation AUPRC:0.9396291549364236
Test AUC:0.9638778550148956
Test AUPRC:0.9508179985243097
BestTestF1Score	0.88	0.8	0.9	0.89	0.87	66	8	98	10	0.75
BestTestMCCScore	0.88	0.8	0.9	0.89	0.87	66	8	98	10	0.75
BestTestAccuracyScore	0.88	0.8	0.9	0.89	0.87	66	8	98	10	0.75
BestValidationF1Score	0.9	0.8	0.9	0.92	0.88	78	7	86	11	0.75
BestValidationMCC	0.9	0.8	0.9	0.92	0.88	78	7	86	11	0.75
BestValidationAccuracy	0.9	0.8	0.9	0.92	0.88	78	7	86	11	0.75
TestPredictions (Threshold:0.75)
CHEMBL3642137,TN,INACT,0.029999999329447746	CHEMBL308414,TN,INACT,0.07999999821186066	CHEMBL203739,TP,ACT,0.9900000095367432	CHEMBL365889,TN,INACT,0.0	CHEMBL1765667,FP,INACT,0.9200000166893005	CHEMBL72841,TN,INACT,0.0	CHEMBL130861,TN,INACT,0.1599999964237213	CHEMBL319418,TP,ACT,1.0	CHEMBL475684,TP,ACT,1.0	CHEMBL404097,TN,INACT,0.7099999785423279	CHEMBL301805,FP,INACT,0.9800000190734863	CHEMBL3086829,TN,INACT,0.009999999776482582	CHEMBL1921995,TN,INACT,0.019999999552965164	CHEMBL351508,TN,INACT,0.05999999865889549	CHEMBL1765668,FP,INACT,0.9200000166893005	CHEMBL124459,TN,INACT,0.009999999776482582	CHEMBL354363,TN,INACT,0.0	CHEMBL313981,TN,INACT,0.009999999776482582	CHEMBL1076625,TN,INACT,0.009999999776482582	CHEMBL2442639,TN,INACT,0.25999999046325684	CHEMBL42065,TN,INACT,0.07000000029802322	CHEMBL49429,TP,ACT,1.0	CHEMBL139863,TP,ACT,0.9900000095367432	CHEMBL605373,TP,ACT,0.9900000095367432	CHEMBL415176,TN,INACT,0.1899999976158142	CHEMBL2369831,TP,ACT,0.9900000095367432	CHEMBL141051,TN,INACT,0.009999999776482582	CHEMBL144894,TN,INACT,0.019999999552965164	CHEMBL3354572,TP,ACT,0.9900000095367432	CHEMBL86384,TP,ACT,0.8899999856948853	CHEMBL142292,TN,INACT,0.0	CHEMBL327242,TP,ACT,0.9900000095367432	CHEMBL329026,TP,ACT,1.0	CHEMBL420762,FN,ACT,0.6200000047683716	CHEMBL128360,TN,INACT,0.019999999552965164	CHEMBL2442638,TN,INACT,0.10000000149011612	CHEMBL312750,TN,INACT,0.5400000214576721	CHEMBL74515,TN,INACT,0.0	CHEMBL431185,TN,INACT,0.009999999776482582	CHEMBL309017,TN,INACT,0.019999999552965164	CHEMBL268351,TN,INACT,0.17000000178813934	CHEMBL101706,TN,INACT,0.0	CHEMBL1922023,FP,INACT,0.75	CHEMBL320416,TP,ACT,0.7699999809265137	CHEMBL3354591,TP,ACT,1.0	CHEMBL1765671,FP,INACT,0.8600000143051147	CHEMBL343158,TN,INACT,0.0	CHEMBL3301668,TP,ACT,1.0	CHEMBL1921903,TN,INACT,0.2199999988079071	CHEMBL435815,TN,INACT,0.029999999329447746	CHEMBL590175,TP,ACT,0.9700000286102295	CHEMBL80626,TN,INACT,0.23999999463558197	CHEMBL140495,TN,INACT,0.09000000357627869	CHEMBL252231,TN,INACT,0.009999999776482582	CHEMBL311230,TP,ACT,1.0	CHEMBL3354596,TP,ACT,1.0	CHEMBL349062,TP,ACT,0.9700000286102295	CHEMBL3325705,TN,INACT,0.3799999952316284	CHEMBL332447,TP,ACT,0.9300000071525574	CHEMBL443300,TP,ACT,0.9900000095367432	CHEMBL388528,TN,INACT,0.12999999523162842	CHEMBL128687,TP,ACT,1.0	CHEMBL59900,TN,INACT,0.11999999731779099	CHEMBL135405,TN,INACT,0.0	CHEMBL3416770,TP,ACT,0.9800000190734863	CHEMBL462650,TN,INACT,0.019999999552965164	CHEMBL3354570,TP,ACT,0.9900000095367432	CHEMBL1083765,TP,ACT,0.8100000023841858	CHEMBL251335,TN,INACT,0.550000011920929	CHEMBL2092990,TN,INACT,0.0	CHEMBL334363,TP,ACT,1.0	CHEMBL3416750,FN,ACT,0.10999999940395355	CHEMBL424324,TN,INACT,0.0	CHEMBL3354576,TP,ACT,0.9900000095367432	CHEMBL185152,TP,ACT,0.9599999785423279	CHEMBL509183,TP,ACT,1.0	CHEMBL419997,TN,INACT,0.0	CHEMBL442,TN,INACT,0.009999999776482582	CHEMBL19018,TN,INACT,0.25999999046325684	CHEMBL340755,TN,INACT,0.09000000357627869	CHEMBL134525,FN,ACT,0.4300000071525574	CHEMBL420216,TP,ACT,1.0	CHEMBL1084824,TP,ACT,0.9900000095367432	CHEMBL368791,TP,ACT,0.7799999713897705	CHEMBL119291,TN,INACT,0.0	CHEMBL151803,TN,INACT,0.0	CHEMBL510500,TP,ACT,0.949999988079071	CHEMBL1907728,TN,INACT,0.009999999776482582	CHEMBL51569,TN,INACT,0.0	CHEMBL423260,TN,INACT,0.0	CHEMBL3416749,FN,ACT,0.27000001072883606	CHEMBL423803,TN,INACT,0.11999999731779099	CHEMBL326085,FP,INACT,0.8399999737739563	CHEMBL139415,FN,ACT,0.3199999928474426	CHEMBL366790,TP,ACT,0.9200000166893005	CHEMBL2172391,TP,ACT,0.9100000262260437	CHEMBL24781,TN,INACT,0.009999999776482582	CHEMBL344159,TP,ACT,0.9800000190734863	CHEMBL214122,TN,INACT,0.029999999329447746	CHEMBL3416767,FN,ACT,0.14000000059604645	CHEMBL123785,TN,INACT,0.009999999776482582	CHEMBL266077,TN,INACT,0.12999999523162842	CHEMBL330094,TP,ACT,0.9700000286102295	CHEMBL86949,FN,ACT,0.38999998569488525	CHEMBL85089,TN,INACT,0.029999999329447746	CHEMBL1086070,TP,ACT,0.9300000071525574	CHEMBL293184,TN,INACT,0.0	CHEMBL408395,TN,INACT,0.0	CHEMBL7550,TN,INACT,0.11999999731779099	CHEMBL1084825,TP,ACT,0.949999988079071	CHEMBL20514,TN,INACT,0.0	CHEMBL49322,TP,ACT,1.0	CHEMBL276906,TN,INACT,0.17000000178813934	CHEMBL500371,TP,ACT,1.0	CHEMBL172788,TN,INACT,0.0	CHEMBL2369840,TP,ACT,0.9700000286102295	CHEMBL557576,TN,INACT,0.019999999552965164	CHEMBL560597,TN,INACT,0.28999999165534973	CHEMBL334933,TN,INACT,0.07999999821186066	CHEMBL337725,TP,ACT,0.9900000095367432	CHEMBL164968,TN,INACT,0.0	CHEMBL1085378,TP,ACT,0.9399999976158142	CHEMBL365667,TN,INACT,0.0	CHEMBL480104,TP,ACT,0.9800000190734863	CHEMBL2369841,TP,ACT,1.0	CHEMBL582857,TP,ACT,0.8600000143051147	CHEMBL2037511,FN,ACT,0.05999999865889549	CHEMBL53491,TN,INACT,0.07000000029802322	CHEMBL3582248,TN,INACT,0.41999998688697815	CHEMBL1083732,FN,ACT,0.5199999809265137	CHEMBL86936,TP,ACT,0.8999999761581421	CHEMBL475496,TN,INACT,0.0	CHEMBL422701,TN,INACT,0.009999999776482582	CHEMBL505517,TP,ACT,0.8500000238418579	CHEMBL262404,TN,INACT,0.09000000357627869	CHEMBL1907856,TN,INACT,0.03999999910593033	CHEMBL399288,TP,ACT,0.8700000047683716	CHEMBL93209,TP,ACT,0.9800000190734863	CHEMBL520040,TP,ACT,1.0	CHEMBL3338859,TN,INACT,0.0	CHEMBL339254,TN,INACT,0.0	CHEMBL72710,TN,INACT,0.0	CHEMBL2431726,TN,INACT,0.6200000047683716	CHEMBL2178724,TN,INACT,0.05999999865889549	CHEMBL136628,TP,ACT,0.8199999928474426	CHEMBL2172294,TP,ACT,0.9399999976158142	CHEMBL3353932,TP,ACT,0.9900000095367432	CHEMBL1779400,TP,ACT,0.8700000047683716	CHEMBL351587,FN,ACT,0.3100000023841858	CHEMBL316849,TP,ACT,0.9399999976158142	CHEMBL336256,TN,INACT,0.36000001430511475	CHEMBL479919,TP,ACT,0.9800000190734863	CHEMBL1187471,FP,INACT,0.9800000190734863	CHEMBL340893,TP,ACT,0.9900000095367432	CHEMBL254505,TN,INACT,0.009999999776482582	CHEMBL2369848,TP,ACT,0.9900000095367432	CHEMBL503924,FP,INACT,0.9300000071525574	CHEMBL1907665,TN,INACT,0.0	CHEMBL357975,TN,INACT,0.009999999776482582	CHEMBL124780,TN,INACT,0.09000000357627869	CHEMBL162111,TN,INACT,0.07999999821186066	CHEMBL336081,TN,INACT,0.019999999552965164	CHEMBL478083,TP,ACT,0.9900000095367432	CHEMBL2369829,TP,ACT,1.0	CHEMBL417712,TN,INACT,0.009999999776482582	CHEMBL3353955,TP,ACT,1.0	CHEMBL72738,TN,INACT,0.019999999552965164	CHEMBL3338850,TN,INACT,0.0	CHEMBL128422,TN,INACT,0.0	CHEMBL171108,TN,INACT,0.009999999776482582	CHEMBL2369842,TP,ACT,0.9900000095367432	CHEMBL368133,TN,INACT,0.0	CHEMBL136990,TN,INACT,0.0	CHEMBL3780248,TN,INACT,0.009999999776482582	CHEMBL400266,TP,ACT,0.9800000190734863	CHEMBL87887,TP,ACT,0.949999988079071	CHEMBL1085850,TP,ACT,0.8199999928474426	CHEMBL302282,TN,INACT,0.0	CHEMBL3142843,TN,INACT,0.0	CHEMBL408492,TN,INACT,0.029999999329447746	CHEMBL42799,TN,INACT,0.009999999776482582	CHEMBL229018,TN,INACT,0.009999999776482582	

