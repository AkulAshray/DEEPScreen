CNNModel CHEMBL280 RMSprop 0.001 30 128 0 0.8 False True
Number of active compounds :	981
Number of inactive compounds :	654
---------------------------------
Run id: CNNModel_CHEMBL280_RMSprop_0.001_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL280_RMSprop_0.001_30_128_0.8_True/
---------------------------------
Training samples: 986
Validation samples: 309
--
Training Step: 1  | time: 1.382s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/986
[A[ATraining Step: 2  | total loss: [1m[32m0.62326[0m[0m | time: 2.759s
[2K
| RMSProp | epoch: 001 | loss: 0.62326 - acc: 0.6187 -- iter: 064/986
[A[ATraining Step: 3  | total loss: [1m[32m0.68011[0m[0m | time: 3.839s
[2K
| RMSProp | epoch: 001 | loss: 0.68011 - acc: 0.5983 -- iter: 096/986
[A[ATraining Step: 4  | total loss: [1m[32m0.68901[0m[0m | time: 4.732s
[2K
| RMSProp | epoch: 001 | loss: 0.68901 - acc: 0.7355 -- iter: 128/986
[A[ATraining Step: 5  | total loss: [1m[32m0.69157[0m[0m | time: 5.571s
[2K
| RMSProp | epoch: 001 | loss: 0.69157 - acc: 0.6374 -- iter: 160/986
[A[ATraining Step: 6  | total loss: [1m[32m0.69234[0m[0m | time: 6.468s
[2K
| RMSProp | epoch: 001 | loss: 0.69234 - acc: 0.6093 -- iter: 192/986
[A[ATraining Step: 7  | total loss: [1m[32m0.69241[0m[0m | time: 7.570s
[2K
| RMSProp | epoch: 001 | loss: 0.69241 - acc: 0.6000 -- iter: 224/986
[A[ATraining Step: 8  | total loss: [1m[32m0.69294[0m[0m | time: 8.606s
[2K
| RMSProp | epoch: 001 | loss: 0.69294 - acc: 0.5262 -- iter: 256/986
[A[ATraining Step: 9  | total loss: [1m[32m0.69272[0m[0m | time: 9.778s
[2K
| RMSProp | epoch: 001 | loss: 0.69272 - acc: 0.5619 -- iter: 288/986
[A[ATraining Step: 10  | total loss: [1m[32m0.69312[0m[0m | time: 10.927s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5153 -- iter: 320/986
[A[ATraining Step: 11  | total loss: [1m[32m0.69279[0m[0m | time: 11.961s
[2K
| RMSProp | epoch: 001 | loss: 0.69279 - acc: 0.5673 -- iter: 352/986
[A[ATraining Step: 12  | total loss: [1m[32m0.69295[0m[0m | time: 13.023s
[2K
| RMSProp | epoch: 001 | loss: 0.69295 - acc: 0.5511 -- iter: 384/986
[A[ATraining Step: 13  | total loss: [1m[32m0.69283[0m[0m | time: 14.149s
[2K
| RMSProp | epoch: 001 | loss: 0.69283 - acc: 0.5694 -- iter: 416/986
[A[ATraining Step: 14  | total loss: [1m[32m0.69267[0m[0m | time: 15.254s
[2K
| RMSProp | epoch: 001 | loss: 0.69267 - acc: 0.5793 -- iter: 448/986
[A[ATraining Step: 15  | total loss: [1m[32m0.69286[0m[0m | time: 16.461s
[2K
| RMSProp | epoch: 001 | loss: 0.69286 - acc: 0.5483 -- iter: 480/986
[A[ATraining Step: 16  | total loss: [1m[32m0.69286[0m[0m | time: 17.418s
[2K
| RMSProp | epoch: 001 | loss: 0.69286 - acc: 0.5536 -- iter: 512/986
[A[ATraining Step: 17  | total loss: [1m[32m0.69234[0m[0m | time: 18.372s
[2K
| RMSProp | epoch: 001 | loss: 0.69234 - acc: 0.6131 -- iter: 544/986
[A[ATraining Step: 18  | total loss: [1m[32m0.69246[0m[0m | time: 19.401s
[2K
| RMSProp | epoch: 001 | loss: 0.69246 - acc: 0.5956 -- iter: 576/986
[A[ATraining Step: 19  | total loss: [1m[32m0.69203[0m[0m | time: 20.459s
[2K
| RMSProp | epoch: 001 | loss: 0.69203 - acc: 0.6366 -- iter: 608/986
[A[ATraining Step: 20  | total loss: [1m[32m0.69183[0m[0m | time: 21.457s
[2K
| RMSProp | epoch: 001 | loss: 0.69183 - acc: 0.6429 -- iter: 640/986
[A[ATraining Step: 21  | total loss: [1m[32m0.69168[0m[0m | time: 22.507s
[2K
| RMSProp | epoch: 001 | loss: 0.69168 - acc: 0.6471 -- iter: 672/986
[A[ATraining Step: 22  | total loss: [1m[32m0.69180[0m[0m | time: 23.536s
[2K
| RMSProp | epoch: 001 | loss: 0.69180 - acc: 0.6311 -- iter: 704/986
[A[ATraining Step: 23  | total loss: [1m[32m0.69177[0m[0m | time: 24.622s
[2K
| RMSProp | epoch: 001 | loss: 0.69177 - acc: 0.6202 -- iter: 736/986
[A[ATraining Step: 24  | total loss: [1m[32m0.69166[0m[0m | time: 25.591s
[2K
| RMSProp | epoch: 001 | loss: 0.69166 - acc: 0.6216 -- iter: 768/986
[A[ATraining Step: 25  | total loss: [1m[32m0.69133[0m[0m | time: 26.599s
[2K
| RMSProp | epoch: 001 | loss: 0.69133 - acc: 0.6396 -- iter: 800/986
[A[ATraining Step: 26  | total loss: [1m[32m0.69196[0m[0m | time: 27.790s
[2K
| RMSProp | epoch: 001 | loss: 0.69196 - acc: 0.5943 -- iter: 832/986
[A[ATraining Step: 27  | total loss: [1m[32m0.69231[0m[0m | time: 29.007s
[2K
| RMSProp | epoch: 001 | loss: 0.69231 - acc: 0.5701 -- iter: 864/986
[A[ATraining Step: 28  | total loss: [1m[32m0.69227[0m[0m | time: 30.015s
[2K
| RMSProp | epoch: 001 | loss: 0.69227 - acc: 0.5682 -- iter: 896/986
[A[ATraining Step: 29  | total loss: [1m[32m0.69162[0m[0m | time: 30.991s
[2K
| RMSProp | epoch: 001 | loss: 0.69162 - acc: 0.6048 -- iter: 928/986
[A[ATraining Step: 30  | total loss: [1m[32m0.69170[0m[0m | time: 31.970s
[2K
| RMSProp | epoch: 001 | loss: 0.69170 - acc: 0.5948 -- iter: 960/986
[A[ATraining Step: 31  | total loss: [1m[32m0.69137[0m[0m | time: 34.568s
[2K
| RMSProp | epoch: 001 | loss: 0.69137 - acc: 0.6090 | val_loss: 0.69158 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 32  | total loss: [1m[32m0.69142[0m[0m | time: 0.985s
[2K
| RMSProp | epoch: 002 | loss: 0.69142 - acc: 0.6018 -- iter: 032/986
[A[ATraining Step: 33  | total loss: [1m[32m0.69150[0m[0m | time: 2.055s
[2K
| RMSProp | epoch: 002 | loss: 0.69150 - acc: 0.5963 -- iter: 064/986
[A[ATraining Step: 34  | total loss: [1m[32m0.69100[0m[0m | time: 3.380s
[2K
| RMSProp | epoch: 002 | loss: 0.69100 - acc: 0.6159 -- iter: 096/986
[A[ATraining Step: 35  | total loss: [1m[32m0.69106[0m[0m | time: 4.645s
[2K
| RMSProp | epoch: 002 | loss: 0.69106 - acc: 0.6112 -- iter: 128/986
[A[ATraining Step: 36  | total loss: [1m[32m0.69135[0m[0m | time: 5.512s
[2K
| RMSProp | epoch: 002 | loss: 0.69135 - acc: 0.5949 -- iter: 160/986
[A[ATraining Step: 37  | total loss: [1m[32m0.69122[0m[0m | time: 6.450s
[2K
| RMSProp | epoch: 002 | loss: 0.69122 - acc: 0.5946 -- iter: 192/986
[A[ATraining Step: 38  | total loss: [1m[32m0.69199[0m[0m | time: 7.518s
[2K
| RMSProp | epoch: 002 | loss: 0.69199 - acc: 0.5639 -- iter: 224/986
[A[ATraining Step: 39  | total loss: [1m[32m0.69144[0m[0m | time: 8.562s
[2K
| RMSProp | epoch: 002 | loss: 0.69144 - acc: 0.5816 -- iter: 256/986
[A[ATraining Step: 40  | total loss: [1m[32m0.69127[0m[0m | time: 9.630s
[2K
| RMSProp | epoch: 002 | loss: 0.69127 - acc: 0.5839 -- iter: 288/986
[A[ATraining Step: 41  | total loss: [1m[32m0.69114[0m[0m | time: 10.666s
[2K
| RMSProp | epoch: 002 | loss: 0.69114 - acc: 0.5857 -- iter: 320/986
[A[ATraining Step: 42  | total loss: [1m[32m0.69084[0m[0m | time: 11.676s
[2K
| RMSProp | epoch: 002 | loss: 0.69084 - acc: 0.5928 -- iter: 352/986
[A[ATraining Step: 43  | total loss: [1m[32m0.69019[0m[0m | time: 12.691s
[2K
| RMSProp | epoch: 002 | loss: 0.69019 - acc: 0.6095 -- iter: 384/986
[A[ATraining Step: 44  | total loss: [1m[32m0.69054[0m[0m | time: 13.675s
[2K
| RMSProp | epoch: 002 | loss: 0.69054 - acc: 0.5959 -- iter: 416/986
[A[ATraining Step: 45  | total loss: [1m[32m0.68966[0m[0m | time: 14.683s
[2K
| RMSProp | epoch: 002 | loss: 0.68966 - acc: 0.6168 -- iter: 448/986
[A[ATraining Step: 46  | total loss: [1m[32m0.68844[0m[0m | time: 15.784s
[2K
| RMSProp | epoch: 002 | loss: 0.68844 - acc: 0.6442 -- iter: 480/986
[A[ATraining Step: 47  | total loss: [1m[32m0.68833[0m[0m | time: 16.888s
[2K
| RMSProp | epoch: 002 | loss: 0.68833 - acc: 0.6411 -- iter: 512/986
[A[ATraining Step: 48  | total loss: [1m[32m0.68913[0m[0m | time: 17.991s
[2K
| RMSProp | epoch: 002 | loss: 0.68913 - acc: 0.6184 -- iter: 544/986
[A[ATraining Step: 49  | total loss: [1m[32m0.68982[0m[0m | time: 19.090s
[2K
| RMSProp | epoch: 002 | loss: 0.68982 - acc: 0.5997 -- iter: 576/986
[A[ATraining Step: 50  | total loss: [1m[32m0.68952[0m[0m | time: 20.309s
[2K
| RMSProp | epoch: 002 | loss: 0.68952 - acc: 0.6036 -- iter: 608/986
[A[ATraining Step: 51  | total loss: [1m[32m0.68897[0m[0m | time: 21.362s
[2K
| RMSProp | epoch: 002 | loss: 0.68897 - acc: 0.6117 -- iter: 640/986
[A[ATraining Step: 52  | total loss: [1m[32m0.68823[0m[0m | time: 22.513s
[2K
| RMSProp | epoch: 002 | loss: 0.68823 - acc: 0.6230 -- iter: 672/986
[A[ATraining Step: 53  | total loss: [1m[32m0.68802[0m[0m | time: 23.636s
[2K
| RMSProp | epoch: 002 | loss: 0.68802 - acc: 0.6233 -- iter: 704/986
[A[ATraining Step: 54  | total loss: [1m[32m0.68832[0m[0m | time: 24.700s
[2K
| RMSProp | epoch: 002 | loss: 0.68832 - acc: 0.6145 -- iter: 736/986
[A[ATraining Step: 55  | total loss: [1m[32m0.68807[0m[0m | time: 25.724s
[2K
| RMSProp | epoch: 002 | loss: 0.68807 - acc: 0.6160 -- iter: 768/986
[A[ATraining Step: 56  | total loss: [1m[32m0.68804[0m[0m | time: 26.808s
[2K
| RMSProp | epoch: 002 | loss: 0.68804 - acc: 0.6129 -- iter: 800/986
[A[ATraining Step: 57  | total loss: [1m[32m0.68802[0m[0m | time: 27.929s
[2K
| RMSProp | epoch: 002 | loss: 0.68802 - acc: 0.6102 -- iter: 832/986
[A[ATraining Step: 58  | total loss: [1m[32m0.68695[0m[0m | time: 29.000s
[2K
| RMSProp | epoch: 002 | loss: 0.68695 - acc: 0.6250 -- iter: 864/986
[A[ATraining Step: 59  | total loss: [1m[32m0.68730[0m[0m | time: 30.123s
[2K
| RMSProp | epoch: 002 | loss: 0.68730 - acc: 0.6166 -- iter: 896/986
[A[ATraining Step: 60  | total loss: [1m[32m0.68648[0m[0m | time: 31.263s
[2K
| RMSProp | epoch: 002 | loss: 0.68648 - acc: 0.6260 -- iter: 928/986
[A[ATraining Step: 61  | total loss: [1m[32m0.68742[0m[0m | time: 32.312s
[2K
| RMSProp | epoch: 002 | loss: 0.68742 - acc: 0.6096 -- iter: 960/986
[A[ATraining Step: 62  | total loss: [1m[32m0.68827[0m[0m | time: 35.134s
[2K
| RMSProp | epoch: 002 | loss: 0.68827 - acc: 0.5955 | val_loss: 0.68834 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 63  | total loss: [1m[32m0.68870[0m[0m | time: 0.702s
[2K
| RMSProp | epoch: 003 | loss: 0.68870 - acc: 0.5873 -- iter: 032/986
[A[ATraining Step: 64  | total loss: [1m[32m0.68830[0m[0m | time: 1.327s
[2K
| RMSProp | epoch: 003 | loss: 0.68830 - acc: 0.5908 -- iter: 064/986
[A[ATraining Step: 65  | total loss: [1m[32m0.68795[0m[0m | time: 2.150s
[2K
| RMSProp | epoch: 003 | loss: 0.68795 - acc: 0.5939 -- iter: 096/986
[A[ATraining Step: 66  | total loss: [1m[32m0.68782[0m[0m | time: 3.078s
[2K
| RMSProp | epoch: 003 | loss: 0.68782 - acc: 0.5939 -- iter: 128/986
[A[ATraining Step: 67  | total loss: [1m[32m0.68886[0m[0m | time: 3.716s
[2K
| RMSProp | epoch: 003 | loss: 0.68886 - acc: 0.5788 -- iter: 160/986
[A[ATraining Step: 68  | total loss: [1m[32m0.68945[0m[0m | time: 4.335s
[2K
| RMSProp | epoch: 003 | loss: 0.68945 - acc: 0.5695 -- iter: 192/986
[A[ATraining Step: 69  | total loss: [1m[32m0.68969[0m[0m | time: 4.970s
[2K
| RMSProp | epoch: 003 | loss: 0.68969 - acc: 0.5650 -- iter: 224/986
[A[ATraining Step: 70  | total loss: [1m[32m0.69044[0m[0m | time: 5.585s
[2K
| RMSProp | epoch: 003 | loss: 0.69044 - acc: 0.5539 -- iter: 256/986
[A[ATraining Step: 71  | total loss: [1m[32m0.68974[0m[0m | time: 6.214s
[2K
| RMSProp | epoch: 003 | loss: 0.68974 - acc: 0.5620 -- iter: 288/986
[A[ATraining Step: 72  | total loss: [1m[32m0.68906[0m[0m | time: 6.826s
[2K
| RMSProp | epoch: 003 | loss: 0.68906 - acc: 0.5691 -- iter: 320/986
[A[ATraining Step: 73  | total loss: [1m[32m0.68758[0m[0m | time: 7.565s
[2K
| RMSProp | epoch: 003 | loss: 0.68758 - acc: 0.5857 -- iter: 352/986
[A[ATraining Step: 74  | total loss: [1m[32m0.68706[0m[0m | time: 8.277s
[2K
| RMSProp | epoch: 003 | loss: 0.68706 - acc: 0.5900 -- iter: 384/986
[A[ATraining Step: 75  | total loss: [1m[32m0.68659[0m[0m | time: 9.025s
[2K
| RMSProp | epoch: 003 | loss: 0.68659 - acc: 0.5938 -- iter: 416/986
[A[ATraining Step: 76  | total loss: [1m[32m0.68641[0m[0m | time: 9.800s
[2K
| RMSProp | epoch: 003 | loss: 0.68641 - acc: 0.5938 -- iter: 448/986
[A[ATraining Step: 77  | total loss: [1m[32m0.68523[0m[0m | time: 10.568s
[2K
| RMSProp | epoch: 003 | loss: 0.68523 - acc: 0.6037 -- iter: 480/986
[A[ATraining Step: 78  | total loss: [1m[32m0.68553[0m[0m | time: 11.324s
[2K
| RMSProp | epoch: 003 | loss: 0.68553 - acc: 0.5994 -- iter: 512/986
[A[ATraining Step: 79  | total loss: [1m[32m0.68472[0m[0m | time: 12.051s
[2K
| RMSProp | epoch: 003 | loss: 0.68472 - acc: 0.6053 -- iter: 544/986
[A[ATraining Step: 80  | total loss: [1m[32m0.68347[0m[0m | time: 12.813s
[2K
| RMSProp | epoch: 003 | loss: 0.68347 - acc: 0.6137 -- iter: 576/986
[A[ATraining Step: 81  | total loss: [1m[32m0.68386[0m[0m | time: 13.568s
[2K
| RMSProp | epoch: 003 | loss: 0.68386 - acc: 0.6085 -- iter: 608/986
[A[ATraining Step: 82  | total loss: [1m[32m0.68422[0m[0m | time: 14.317s
[2K
| RMSProp | epoch: 003 | loss: 0.68422 - acc: 0.6039 -- iter: 640/986
[A[ATraining Step: 83  | total loss: [1m[32m0.68573[0m[0m | time: 15.135s
[2K
| RMSProp | epoch: 003 | loss: 0.68573 - acc: 0.5904 -- iter: 672/986
[A[ATraining Step: 84  | total loss: [1m[32m0.68512[0m[0m | time: 15.901s
[2K
| RMSProp | epoch: 003 | loss: 0.68512 - acc: 0.5939 -- iter: 704/986
[A[ATraining Step: 85  | total loss: [1m[32m0.68534[0m[0m | time: 16.624s
[2K
| RMSProp | epoch: 003 | loss: 0.68534 - acc: 0.5907 -- iter: 736/986
[A[ATraining Step: 86  | total loss: [1m[32m0.68594[0m[0m | time: 17.343s
[2K
| RMSProp | epoch: 003 | loss: 0.68594 - acc: 0.5848 -- iter: 768/986
[A[ATraining Step: 87  | total loss: [1m[32m0.68609[0m[0m | time: 18.090s
[2K
| RMSProp | epoch: 003 | loss: 0.68609 - acc: 0.5826 -- iter: 800/986
[A[ATraining Step: 88  | total loss: [1m[32m0.68414[0m[0m | time: 18.833s
[2K
| RMSProp | epoch: 003 | loss: 0.68414 - acc: 0.5962 -- iter: 832/986
[A[ATraining Step: 89  | total loss: [1m[32m0.68489[0m[0m | time: 19.540s
[2K
| RMSProp | epoch: 003 | loss: 0.68489 - acc: 0.5897 -- iter: 864/986
[A[ATraining Step: 90  | total loss: [1m[32m0.68422[0m[0m | time: 20.285s
[2K
| RMSProp | epoch: 003 | loss: 0.68422 - acc: 0.5932 -- iter: 896/986
[A[ATraining Step: 91  | total loss: [1m[32m0.68304[0m[0m | time: 21.040s
[2K
| RMSProp | epoch: 003 | loss: 0.68304 - acc: 0.5995 -- iter: 928/986
[A[ATraining Step: 92  | total loss: [1m[32m0.68039[0m[0m | time: 21.763s
[2K
| RMSProp | epoch: 003 | loss: 0.68039 - acc: 0.6146 -- iter: 960/986
[A[ATraining Step: 93  | total loss: [1m[32m0.67758[0m[0m | time: 23.688s
[2K
| RMSProp | epoch: 003 | loss: 0.67758 - acc: 0.6281 | val_loss: 0.68263 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 94  | total loss: [1m[32m0.67714[0m[0m | time: 0.771s
[2K
| RMSProp | epoch: 004 | loss: 0.67714 - acc: 0.6278 -- iter: 032/986
[A[ATraining Step: 95  | total loss: [1m[32m0.67731[0m[0m | time: 1.417s
[2K
| RMSProp | epoch: 004 | loss: 0.67731 - acc: 0.6244 -- iter: 064/986
[A[ATraining Step: 96  | total loss: [1m[32m0.67948[0m[0m | time: 2.049s
[2K
| RMSProp | epoch: 004 | loss: 0.67948 - acc: 0.6120 -- iter: 096/986
[A[ATraining Step: 97  | total loss: [1m[32m0.68142[0m[0m | time: 2.806s
[2K
| RMSProp | epoch: 004 | loss: 0.68142 - acc: 0.6008 -- iter: 128/986
[A[ATraining Step: 98  | total loss: [1m[32m0.68183[0m[0m | time: 3.661s
[2K
| RMSProp | epoch: 004 | loss: 0.68183 - acc: 0.5969 -- iter: 160/986
[A[ATraining Step: 99  | total loss: [1m[32m0.68213[0m[0m | time: 4.601s
[2K
| RMSProp | epoch: 004 | loss: 0.68213 - acc: 0.5935 -- iter: 192/986
[A[ATraining Step: 100  | total loss: [1m[32m0.67786[0m[0m | time: 5.651s
[2K
| RMSProp | epoch: 004 | loss: 0.67786 - acc: 0.6123 -- iter: 224/986
[A[ATraining Step: 101  | total loss: [1m[32m0.67867[0m[0m | time: 6.759s
[2K
| RMSProp | epoch: 004 | loss: 0.67867 - acc: 0.6073 -- iter: 256/986
[A[ATraining Step: 102  | total loss: [1m[32m0.67607[0m[0m | time: 7.614s
[2K
| RMSProp | epoch: 004 | loss: 0.67607 - acc: 0.6153 -- iter: 288/986
[A[ATraining Step: 103  | total loss: [1m[32m0.67897[0m[0m | time: 8.548s
[2K
| RMSProp | epoch: 004 | loss: 0.67897 - acc: 0.6038 -- iter: 320/986
[A[ATraining Step: 104  | total loss: [1m[32m0.67970[0m[0m | time: 9.610s
[2K
| RMSProp | epoch: 004 | loss: 0.67970 - acc: 0.5997 -- iter: 352/986
[A[ATraining Step: 105  | total loss: [1m[32m0.67535[0m[0m | time: 10.555s
[2K
| RMSProp | epoch: 004 | loss: 0.67535 - acc: 0.6147 -- iter: 384/986
[A[ATraining Step: 106  | total loss: [1m[32m0.67533[0m[0m | time: 11.518s
[2K
| RMSProp | epoch: 004 | loss: 0.67533 - acc: 0.6126 -- iter: 416/986
[A[ATraining Step: 107  | total loss: [1m[32m0.68654[0m[0m | time: 12.582s
[2K
| RMSProp | epoch: 004 | loss: 0.68654 - acc: 0.5795 -- iter: 448/986
[A[ATraining Step: 108  | total loss: [1m[32m0.68640[0m[0m | time: 13.861s
[2K
| RMSProp | epoch: 004 | loss: 0.68640 - acc: 0.5778 -- iter: 480/986
[A[ATraining Step: 109  | total loss: [1m[32m0.68512[0m[0m | time: 15.042s
[2K
| RMSProp | epoch: 004 | loss: 0.68512 - acc: 0.5825 -- iter: 512/986
[A[ATraining Step: 110  | total loss: [1m[32m0.68320[0m[0m | time: 16.085s
[2K
| RMSProp | epoch: 004 | loss: 0.68320 - acc: 0.5899 -- iter: 544/986
[A[ATraining Step: 111  | total loss: [1m[32m0.68199[0m[0m | time: 17.108s
[2K
| RMSProp | epoch: 004 | loss: 0.68199 - acc: 0.5934 -- iter: 576/986
[A[ATraining Step: 112  | total loss: [1m[32m0.68004[0m[0m | time: 18.300s
[2K
| RMSProp | epoch: 004 | loss: 0.68004 - acc: 0.5997 -- iter: 608/986
[A[ATraining Step: 113  | total loss: [1m[32m0.67703[0m[0m | time: 19.476s
[2K
| RMSProp | epoch: 004 | loss: 0.67703 - acc: 0.6084 -- iter: 640/986
[A[ATraining Step: 114  | total loss: [1m[32m0.67381[0m[0m | time: 20.547s
[2K
| RMSProp | epoch: 004 | loss: 0.67381 - acc: 0.6164 -- iter: 672/986
[A[ATraining Step: 115  | total loss: [1m[32m0.67141[0m[0m | time: 21.448s
[2K
| RMSProp | epoch: 004 | loss: 0.67141 - acc: 0.6203 -- iter: 704/986
[A[ATraining Step: 116  | total loss: [1m[32m0.67712[0m[0m | time: 22.412s
[2K
| RMSProp | epoch: 004 | loss: 0.67712 - acc: 0.6083 -- iter: 736/986
[A[ATraining Step: 117  | total loss: [1m[32m0.67703[0m[0m | time: 23.429s
[2K
| RMSProp | epoch: 004 | loss: 0.67703 - acc: 0.6069 -- iter: 768/986
[A[ATraining Step: 118  | total loss: [1m[32m0.67522[0m[0m | time: 24.395s
[2K
| RMSProp | epoch: 004 | loss: 0.67522 - acc: 0.6118 -- iter: 800/986
[A[ATraining Step: 119  | total loss: [1m[32m0.67862[0m[0m | time: 25.390s
[2K
| RMSProp | epoch: 004 | loss: 0.67862 - acc: 0.6006 -- iter: 832/986
[A[ATraining Step: 120  | total loss: [1m[32m0.67671[0m[0m | time: 26.440s
[2K
| RMSProp | epoch: 004 | loss: 0.67671 - acc: 0.6062 -- iter: 864/986
[A[ATraining Step: 121  | total loss: [1m[32m0.67661[0m[0m | time: 27.480s
[2K
| RMSProp | epoch: 004 | loss: 0.67661 - acc: 0.6049 -- iter: 896/986
[A[ATraining Step: 122  | total loss: [1m[32m0.67552[0m[0m | time: 28.565s
[2K
| RMSProp | epoch: 004 | loss: 0.67552 - acc: 0.6069 -- iter: 928/986
[A[ATraining Step: 123  | total loss: [1m[32m0.67096[0m[0m | time: 29.613s
[2K
| RMSProp | epoch: 004 | loss: 0.67096 - acc: 0.6181 -- iter: 960/986
[A[ATraining Step: 124  | total loss: [1m[32m0.67766[0m[0m | time: 32.313s
[2K
| RMSProp | epoch: 004 | loss: 0.67766 - acc: 0.6063 | val_loss: 0.68148 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 125  | total loss: [1m[32m0.67600[0m[0m | time: 0.999s
[2K
| RMSProp | epoch: 005 | loss: 0.67600 - acc: 0.6113 -- iter: 032/986
[A[ATraining Step: 126  | total loss: [1m[32m0.67606[0m[0m | time: 2.042s
[2K
| RMSProp | epoch: 005 | loss: 0.67606 - acc: 0.6095 -- iter: 064/986
[A[ATraining Step: 127  | total loss: [1m[32m0.67608[0m[0m | time: 2.888s
[2K
| RMSProp | epoch: 005 | loss: 0.67608 - acc: 0.6080 -- iter: 096/986
[A[ATraining Step: 128  | total loss: [1m[32m0.68021[0m[0m | time: 3.788s
[2K
| RMSProp | epoch: 005 | loss: 0.68021 - acc: 0.5933 -- iter: 128/986
[A[ATraining Step: 129  | total loss: [1m[32m0.68324[0m[0m | time: 4.840s
[2K
| RMSProp | epoch: 005 | loss: 0.68324 - acc: 0.5801 -- iter: 160/986
[A[ATraining Step: 130  | total loss: [1m[32m0.68138[0m[0m | time: 6.237s
[2K
| RMSProp | epoch: 005 | loss: 0.68138 - acc: 0.5878 -- iter: 192/986
[A[ATraining Step: 131  | total loss: [1m[32m0.68183[0m[0m | time: 7.048s
[2K
| RMSProp | epoch: 005 | loss: 0.68183 - acc: 0.5852 -- iter: 224/986
[A[ATraining Step: 132  | total loss: [1m[32m0.67985[0m[0m | time: 8.105s
[2K
| RMSProp | epoch: 005 | loss: 0.67985 - acc: 0.5923 -- iter: 256/986
[A[ATraining Step: 133  | total loss: [1m[32m0.67868[0m[0m | time: 9.134s
[2K
| RMSProp | epoch: 005 | loss: 0.67868 - acc: 0.5956 -- iter: 288/986
[A[ATraining Step: 134  | total loss: [1m[32m0.67552[0m[0m | time: 10.055s
[2K
| RMSProp | epoch: 005 | loss: 0.67552 - acc: 0.6048 -- iter: 320/986
[A[ATraining Step: 135  | total loss: [1m[32m0.67703[0m[0m | time: 11.033s
[2K
| RMSProp | epoch: 005 | loss: 0.67703 - acc: 0.6006 -- iter: 352/986
[A[ATraining Step: 136  | total loss: [1m[32m0.67580[0m[0m | time: 12.043s
[2K
| RMSProp | epoch: 005 | loss: 0.67580 - acc: 0.6030 -- iter: 384/986
[A[ATraining Step: 137  | total loss: [1m[32m0.67592[0m[0m | time: 13.156s
[2K
| RMSProp | epoch: 005 | loss: 0.67592 - acc: 0.6021 -- iter: 416/986
[A[ATraining Step: 138  | total loss: [1m[32m0.67016[0m[0m | time: 14.177s
[2K
| RMSProp | epoch: 005 | loss: 0.67016 - acc: 0.6169 -- iter: 448/986
[A[ATraining Step: 139  | total loss: [1m[32m0.67751[0m[0m | time: 15.289s
[2K
| RMSProp | epoch: 005 | loss: 0.67751 - acc: 0.6083 -- iter: 480/986
[A[ATraining Step: 140  | total loss: [1m[32m0.67831[0m[0m | time: 16.340s
[2K
| RMSProp | epoch: 005 | loss: 0.67831 - acc: 0.6037 -- iter: 512/986
[A[ATraining Step: 141  | total loss: [1m[32m0.67748[0m[0m | time: 17.384s
[2K
| RMSProp | epoch: 005 | loss: 0.67748 - acc: 0.6059 -- iter: 544/986
[A[ATraining Step: 142  | total loss: [1m[32m0.67487[0m[0m | time: 18.524s
[2K
| RMSProp | epoch: 005 | loss: 0.67487 - acc: 0.6140 -- iter: 576/986
[A[ATraining Step: 143  | total loss: [1m[32m0.67311[0m[0m | time: 19.495s
[2K
| RMSProp | epoch: 005 | loss: 0.67311 - acc: 0.6182 -- iter: 608/986
[A[ATraining Step: 144  | total loss: [1m[32m0.67130[0m[0m | time: 20.564s
[2K
| RMSProp | epoch: 005 | loss: 0.67130 - acc: 0.6220 -- iter: 640/986
[A[ATraining Step: 145  | total loss: [1m[32m0.67053[0m[0m | time: 21.708s
[2K
| RMSProp | epoch: 005 | loss: 0.67053 - acc: 0.6223 -- iter: 672/986
[A[ATraining Step: 146  | total loss: [1m[32m0.67089[0m[0m | time: 22.861s
[2K
| RMSProp | epoch: 005 | loss: 0.67089 - acc: 0.6195 -- iter: 704/986
[A[ATraining Step: 147  | total loss: [1m[32m0.67129[0m[0m | time: 23.714s
[2K
| RMSProp | epoch: 005 | loss: 0.67129 - acc: 0.6169 -- iter: 736/986
[A[ATraining Step: 148  | total loss: [1m[32m0.67786[0m[0m | time: 24.611s
[2K
| RMSProp | epoch: 005 | loss: 0.67786 - acc: 0.5990 -- iter: 768/986
[A[ATraining Step: 149  | total loss: [1m[32m0.67693[0m[0m | time: 25.637s
[2K
| RMSProp | epoch: 005 | loss: 0.67693 - acc: 0.6016 -- iter: 800/986
[A[ATraining Step: 150  | total loss: [1m[32m0.67870[0m[0m | time: 26.662s
[2K
| RMSProp | epoch: 005 | loss: 0.67870 - acc: 0.5945 -- iter: 832/986
[A[ATraining Step: 151  | total loss: [1m[32m0.67943[0m[0m | time: 27.666s
[2K
| RMSProp | epoch: 005 | loss: 0.67943 - acc: 0.5913 -- iter: 864/986
[A[ATraining Step: 152  | total loss: [1m[32m0.67996[0m[0m | time: 28.692s
[2K
| RMSProp | epoch: 005 | loss: 0.67996 - acc: 0.5885 -- iter: 896/986
[A[ATraining Step: 153  | total loss: [1m[32m0.68133[0m[0m | time: 29.725s
[2K
| RMSProp | epoch: 005 | loss: 0.68133 - acc: 0.5827 -- iter: 928/986
[A[ATraining Step: 154  | total loss: [1m[32m0.67847[0m[0m | time: 30.754s
[2K
| RMSProp | epoch: 005 | loss: 0.67847 - acc: 0.5932 -- iter: 960/986
[A[ATraining Step: 155  | total loss: [1m[32m0.68015[0m[0m | time: 33.415s
[2K
| RMSProp | epoch: 005 | loss: 0.68015 - acc: 0.5870 | val_loss: 0.68139 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 156  | total loss: [1m[32m0.68069[0m[0m | time: 0.954s
[2K
| RMSProp | epoch: 006 | loss: 0.68069 - acc: 0.5846 -- iter: 032/986
[A[ATraining Step: 157  | total loss: [1m[32m0.67680[0m[0m | time: 1.994s
[2K
| RMSProp | epoch: 006 | loss: 0.67680 - acc: 0.5980 -- iter: 064/986
[A[ATraining Step: 158  | total loss: [1m[32m0.67880[0m[0m | time: 2.995s
[2K
| RMSProp | epoch: 006 | loss: 0.67880 - acc: 0.5913 -- iter: 096/986
[A[ATraining Step: 159  | total loss: [1m[32m0.67555[0m[0m | time: 3.866s
[2K
| RMSProp | epoch: 006 | loss: 0.67555 - acc: 0.6009 -- iter: 128/986
[A[ATraining Step: 160  | total loss: [1m[32m0.67765[0m[0m | time: 4.725s
[2K
| RMSProp | epoch: 006 | loss: 0.67765 - acc: 0.5947 -- iter: 160/986
[A[ATraining Step: 161  | total loss: [1m[32m0.67922[0m[0m | time: 5.800s
[2K
| RMSProp | epoch: 006 | loss: 0.67922 - acc: 0.5891 -- iter: 192/986
[A[ATraining Step: 162  | total loss: [1m[32m0.67980[0m[0m | time: 6.943s
[2K
| RMSProp | epoch: 006 | loss: 0.67980 - acc: 0.5864 -- iter: 224/986
[A[ATraining Step: 163  | total loss: [1m[32m0.68217[0m[0m | time: 8.285s
[2K
| RMSProp | epoch: 006 | loss: 0.68217 - acc: 0.5778 -- iter: 256/986
[A[ATraining Step: 164  | total loss: [1m[32m0.68246[0m[0m | time: 9.111s
[2K
| RMSProp | epoch: 006 | loss: 0.68246 - acc: 0.5762 -- iter: 288/986
[A[ATraining Step: 165  | total loss: [1m[32m0.67914[0m[0m | time: 10.204s
[2K
| RMSProp | epoch: 006 | loss: 0.67914 - acc: 0.5874 -- iter: 320/986
[A[ATraining Step: 166  | total loss: [1m[32m0.68194[0m[0m | time: 11.260s
[2K
| RMSProp | epoch: 006 | loss: 0.68194 - acc: 0.5786 -- iter: 352/986
[A[ATraining Step: 167  | total loss: [1m[32m0.68315[0m[0m | time: 12.121s
[2K
| RMSProp | epoch: 006 | loss: 0.68315 - acc: 0.5739 -- iter: 384/986
[A[ATraining Step: 168  | total loss: [1m[32m0.67919[0m[0m | time: 12.945s
[2K
| RMSProp | epoch: 006 | loss: 0.67919 - acc: 0.5884 -- iter: 416/986
[A[ATraining Step: 169  | total loss: [1m[32m0.67780[0m[0m | time: 13.963s
[2K
| RMSProp | epoch: 006 | loss: 0.67780 - acc: 0.5920 -- iter: 448/986
[A[ATraining Step: 170  | total loss: [1m[32m0.67526[0m[0m | time: 14.959s
[2K
| RMSProp | epoch: 006 | loss: 0.67526 - acc: 0.5985 -- iter: 480/986
[A[ATraining Step: 171  | total loss: [1m[32m0.67239[0m[0m | time: 15.945s
[2K
| RMSProp | epoch: 006 | loss: 0.67239 - acc: 0.6042 -- iter: 512/986
[A[ATraining Step: 172  | total loss: [1m[32m0.66934[0m[0m | time: 16.985s
[2K
| RMSProp | epoch: 006 | loss: 0.66934 - acc: 0.6094 -- iter: 544/986
[A[ATraining Step: 173  | total loss: [1m[32m0.66859[0m[0m | time: 18.040s
[2K
| RMSProp | epoch: 006 | loss: 0.66859 - acc: 0.6110 -- iter: 576/986
[A[ATraining Step: 174  | total loss: [1m[32m0.66457[0m[0m | time: 19.112s
[2K
| RMSProp | epoch: 006 | loss: 0.66457 - acc: 0.6186 -- iter: 608/986
[A[ATraining Step: 175  | total loss: [1m[32m0.69480[0m[0m | time: 20.245s
[2K
| RMSProp | epoch: 006 | loss: 0.69480 - acc: 0.6037 -- iter: 640/986
[A[ATraining Step: 176  | total loss: [1m[32m0.69200[0m[0m | time: 21.271s
[2K
| RMSProp | epoch: 006 | loss: 0.69200 - acc: 0.6058 -- iter: 672/986
[A[ATraining Step: 177  | total loss: [1m[32m0.69037[0m[0m | time: 22.588s
[2K
| RMSProp | epoch: 006 | loss: 0.69037 - acc: 0.6046 -- iter: 704/986
[A[ATraining Step: 178  | total loss: [1m[32m0.69183[0m[0m | time: 23.794s
[2K
| RMSProp | epoch: 006 | loss: 0.69183 - acc: 0.5941 -- iter: 736/986
[A[ATraining Step: 179  | total loss: [1m[32m0.69310[0m[0m | time: 24.680s
[2K
| RMSProp | epoch: 006 | loss: 0.69310 - acc: 0.5847 -- iter: 768/986
[A[ATraining Step: 180  | total loss: [1m[32m0.68972[0m[0m | time: 25.576s
[2K
| RMSProp | epoch: 006 | loss: 0.68972 - acc: 0.5919 -- iter: 800/986
[A[ATraining Step: 181  | total loss: [1m[32m0.68464[0m[0m | time: 26.400s
[2K
| RMSProp | epoch: 006 | loss: 0.68464 - acc: 0.6046 -- iter: 832/986
[A[ATraining Step: 182  | total loss: [1m[32m0.68072[0m[0m | time: 27.286s
[2K
| RMSProp | epoch: 006 | loss: 0.68072 - acc: 0.6129 -- iter: 864/986
[A[ATraining Step: 183  | total loss: [1m[32m0.67788[0m[0m | time: 28.197s
[2K
| RMSProp | epoch: 006 | loss: 0.67788 - acc: 0.6172 -- iter: 896/986
[A[ATraining Step: 184  | total loss: [1m[32m0.68388[0m[0m | time: 29.299s
[2K
| RMSProp | epoch: 006 | loss: 0.68388 - acc: 0.5992 -- iter: 928/986
[A[ATraining Step: 185  | total loss: [1m[32m0.67896[0m[0m | time: 30.297s
[2K
| RMSProp | epoch: 006 | loss: 0.67896 - acc: 0.6112 -- iter: 960/986
[A[ATraining Step: 186  | total loss: [1m[32m0.68085[0m[0m | time: 33.166s
[2K
| RMSProp | epoch: 006 | loss: 0.68085 - acc: 0.6032 | val_loss: 0.68168 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 187  | total loss: [1m[32m0.67915[0m[0m | time: 0.919s
[2K
| RMSProp | epoch: 007 | loss: 0.67915 - acc: 0.6054 -- iter: 032/986
[A[ATraining Step: 188  | total loss: [1m[32m0.67431[0m[0m | time: 1.872s
[2K
| RMSProp | epoch: 007 | loss: 0.67431 - acc: 0.6167 -- iter: 064/986
[A[ATraining Step: 189  | total loss: [1m[32m0.67701[0m[0m | time: 2.954s
[2K
| RMSProp | epoch: 007 | loss: 0.67701 - acc: 0.6082 -- iter: 096/986
[A[ATraining Step: 190  | total loss: [1m[32m0.67679[0m[0m | time: 3.950s
[2K
| RMSProp | epoch: 007 | loss: 0.67679 - acc: 0.6067 -- iter: 128/986
[A[ATraining Step: 191  | total loss: [1m[32m0.67565[0m[0m | time: 4.827s
[2K
| RMSProp | epoch: 007 | loss: 0.67565 - acc: 0.6085 -- iter: 160/986
[A[ATraining Step: 192  | total loss: [1m[32m0.67769[0m[0m | time: 5.734s
[2K
| RMSProp | epoch: 007 | loss: 0.67769 - acc: 0.6015 -- iter: 192/986
[A[ATraining Step: 193  | total loss: [1m[32m0.67949[0m[0m | time: 6.857s
[2K
| RMSProp | epoch: 007 | loss: 0.67949 - acc: 0.5952 -- iter: 224/986
[A[ATraining Step: 194  | total loss: [1m[32m0.68320[0m[0m | time: 7.952s
[2K
| RMSProp | epoch: 007 | loss: 0.68320 - acc: 0.5826 -- iter: 256/986
[A[ATraining Step: 195  | total loss: [1m[32m0.68333[0m[0m | time: 8.870s
[2K
| RMSProp | epoch: 007 | loss: 0.68333 - acc: 0.5806 -- iter: 288/986
[A[ATraining Step: 196  | total loss: [1m[32m0.67793[0m[0m | time: 10.081s
[2K
| RMSProp | epoch: 007 | loss: 0.67793 - acc: 0.5975 -- iter: 320/986
[A[ATraining Step: 197  | total loss: [1m[32m0.67761[0m[0m | time: 11.270s
[2K
| RMSProp | epoch: 007 | loss: 0.67761 - acc: 0.5971 -- iter: 352/986
[A[ATraining Step: 198  | total loss: [1m[32m0.67851[0m[0m | time: 12.414s
[2K
| RMSProp | epoch: 007 | loss: 0.67851 - acc: 0.5937 -- iter: 384/986
[A[ATraining Step: 199  | total loss: [1m[32m0.67386[0m[0m | time: 13.264s
[2K
| RMSProp | epoch: 007 | loss: 0.67386 - acc: 0.6062 -- iter: 416/986
[A[ATraining Step: 200  | total loss: [1m[32m0.67877[0m[0m | time: 15.914s
[2K
| RMSProp | epoch: 007 | loss: 0.67877 - acc: 0.5924 | val_loss: 0.68130 - val_acc: 0.5761 -- iter: 448/986
--
Training Step: 201  | total loss: [1m[32m0.67845[0m[0m | time: 16.836s
[2K
| RMSProp | epoch: 007 | loss: 0.67845 - acc: 0.5926 -- iter: 480/986
[A[ATraining Step: 202  | total loss: [1m[32m0.67263[0m[0m | time: 17.679s
[2K
| RMSProp | epoch: 007 | loss: 0.67263 - acc: 0.6083 -- iter: 512/986
[A[ATraining Step: 203  | total loss: [1m[32m0.68284[0m[0m | time: 18.504s
[2K
| RMSProp | epoch: 007 | loss: 0.68284 - acc: 0.5819 -- iter: 544/986
[A[ATraining Step: 204  | total loss: [1m[32m0.68518[0m[0m | time: 19.442s
[2K
| RMSProp | epoch: 007 | loss: 0.68518 - acc: 0.5737 -- iter: 576/986
[A[ATraining Step: 205  | total loss: [1m[32m0.68334[0m[0m | time: 20.344s
[2K
| RMSProp | epoch: 007 | loss: 0.68334 - acc: 0.5788 -- iter: 608/986
[A[ATraining Step: 206  | total loss: [1m[32m0.68459[0m[0m | time: 21.284s
[2K
| RMSProp | epoch: 007 | loss: 0.68459 - acc: 0.5740 -- iter: 640/986
[A[ATraining Step: 207  | total loss: [1m[32m0.68747[0m[0m | time: 22.230s
[2K
| RMSProp | epoch: 007 | loss: 0.68747 - acc: 0.5635 -- iter: 672/986
[A[ATraining Step: 208  | total loss: [1m[32m0.68453[0m[0m | time: 23.198s
[2K
| RMSProp | epoch: 007 | loss: 0.68453 - acc: 0.5728 -- iter: 704/986
[A[ATraining Step: 209  | total loss: [1m[32m0.68276[0m[0m | time: 24.167s
[2K
| RMSProp | epoch: 007 | loss: 0.68276 - acc: 0.5780 -- iter: 736/986
[A[ATraining Step: 210  | total loss: [1m[32m0.68103[0m[0m | time: 25.189s
[2K
| RMSProp | epoch: 007 | loss: 0.68103 - acc: 0.5827 -- iter: 768/986
[A[ATraining Step: 211  | total loss: [1m[32m0.67946[0m[0m | time: 26.154s
[2K
| RMSProp | epoch: 007 | loss: 0.67946 - acc: 0.5869 -- iter: 800/986
[A[ATraining Step: 212  | total loss: [1m[32m0.67474[0m[0m | time: 27.113s
[2K
| RMSProp | epoch: 007 | loss: 0.67474 - acc: 0.6001 -- iter: 832/986
[A[ATraining Step: 213  | total loss: [1m[32m0.67088[0m[0m | time: 28.125s
[2K
| RMSProp | epoch: 007 | loss: 0.67088 - acc: 0.6089 -- iter: 864/986
[A[ATraining Step: 214  | total loss: [1m[32m0.67440[0m[0m | time: 29.289s
[2K
| RMSProp | epoch: 007 | loss: 0.67440 - acc: 0.6042 -- iter: 896/986
[A[ATraining Step: 215  | total loss: [1m[32m0.67096[0m[0m | time: 30.439s
[2K
| RMSProp | epoch: 007 | loss: 0.67096 - acc: 0.6126 -- iter: 928/986
[A[ATraining Step: 216  | total loss: [1m[32m0.67257[0m[0m | time: 31.489s
[2K
| RMSProp | epoch: 007 | loss: 0.67257 - acc: 0.6075 -- iter: 960/986
[A[ATraining Step: 217  | total loss: [1m[32m0.67631[0m[0m | time: 34.103s
[2K
| RMSProp | epoch: 007 | loss: 0.67631 - acc: 0.5968 | val_loss: 0.68186 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 218  | total loss: [1m[32m0.67291[0m[0m | time: 1.058s
[2K
| RMSProp | epoch: 008 | loss: 0.67291 - acc: 0.6059 -- iter: 032/986
[A[ATraining Step: 219  | total loss: [1m[32m0.67548[0m[0m | time: 2.190s
[2K
| RMSProp | epoch: 008 | loss: 0.67548 - acc: 0.5984 -- iter: 064/986
[A[ATraining Step: 220  | total loss: [1m[32m0.67315[0m[0m | time: 3.227s
[2K
| RMSProp | epoch: 008 | loss: 0.67315 - acc: 0.6042 -- iter: 096/986
[A[ATraining Step: 221  | total loss: [1m[32m0.66581[0m[0m | time: 4.410s
[2K
| RMSProp | epoch: 008 | loss: 0.66581 - acc: 0.6219 -- iter: 128/986
[A[ATraining Step: 222  | total loss: [1m[32m0.66382[0m[0m | time: 5.510s
[2K
| RMSProp | epoch: 008 | loss: 0.66382 - acc: 0.6253 -- iter: 160/986
[A[ATraining Step: 223  | total loss: [1m[32m0.66192[0m[0m | time: 6.563s
[2K
| RMSProp | epoch: 008 | loss: 0.66192 - acc: 0.6284 -- iter: 192/986
[A[ATraining Step: 224  | total loss: [1m[32m0.66701[0m[0m | time: 7.387s
[2K
| RMSProp | epoch: 008 | loss: 0.66701 - acc: 0.6194 -- iter: 224/986
[A[ATraining Step: 225  | total loss: [1m[32m0.66997[0m[0m | time: 8.312s
[2K
| RMSProp | epoch: 008 | loss: 0.66997 - acc: 0.6113 -- iter: 256/986
[A[ATraining Step: 226  | total loss: [1m[32m0.66805[0m[0m | time: 9.294s
[2K
| RMSProp | epoch: 008 | loss: 0.66805 - acc: 0.6158 -- iter: 288/986
[A[ATraining Step: 227  | total loss: [1m[32m0.66044[0m[0m | time: 10.275s
[2K
| RMSProp | epoch: 008 | loss: 0.66044 - acc: 0.6324 -- iter: 320/986
[A[ATraining Step: 228  | total loss: [1m[32m0.66575[0m[0m | time: 11.270s
[2K
| RMSProp | epoch: 008 | loss: 0.66575 - acc: 0.6223 -- iter: 352/986
[A[ATraining Step: 229  | total loss: [1m[32m0.66414[0m[0m | time: 12.333s
[2K
| RMSProp | epoch: 008 | loss: 0.66414 - acc: 0.6257 -- iter: 384/986
[A[ATraining Step: 230  | total loss: [1m[32m0.65796[0m[0m | time: 13.374s
[2K
| RMSProp | epoch: 008 | loss: 0.65796 - acc: 0.6381 -- iter: 416/986
[A[ATraining Step: 231  | total loss: [1m[32m0.67169[0m[0m | time: 14.469s
[2K
| RMSProp | epoch: 008 | loss: 0.67169 - acc: 0.6212 -- iter: 448/986
[A[ATraining Step: 232  | total loss: [1m[32m0.67203[0m[0m | time: 15.811s
[2K
| RMSProp | epoch: 008 | loss: 0.67203 - acc: 0.6184 -- iter: 480/986
[A[ATraining Step: 233  | total loss: [1m[32m0.67371[0m[0m | time: 16.619s
[2K
| RMSProp | epoch: 008 | loss: 0.67371 - acc: 0.6128 -- iter: 512/986
[A[ATraining Step: 234  | total loss: [1m[32m0.68010[0m[0m | time: 17.702s
[2K
| RMSProp | epoch: 008 | loss: 0.68010 - acc: 0.5953 -- iter: 544/986
[A[ATraining Step: 235  | total loss: [1m[32m0.67526[0m[0m | time: 18.710s
[2K
| RMSProp | epoch: 008 | loss: 0.67526 - acc: 0.6076 -- iter: 576/986
[A[ATraining Step: 236  | total loss: [1m[32m0.67782[0m[0m | time: 19.690s
[2K
| RMSProp | epoch: 008 | loss: 0.67782 - acc: 0.6000 -- iter: 608/986
[A[ATraining Step: 237  | total loss: [1m[32m0.67629[0m[0m | time: 20.622s
[2K
| RMSProp | epoch: 008 | loss: 0.67629 - acc: 0.6025 -- iter: 640/986
[A[ATraining Step: 238  | total loss: [1m[32m0.67263[0m[0m | time: 21.562s
[2K
| RMSProp | epoch: 008 | loss: 0.67263 - acc: 0.6110 -- iter: 672/986
[A[ATraining Step: 239  | total loss: [1m[32m0.67032[0m[0m | time: 22.568s
[2K
| RMSProp | epoch: 008 | loss: 0.67032 - acc: 0.6155 -- iter: 704/986
[A[ATraining Step: 240  | total loss: [1m[32m0.66529[0m[0m | time: 23.563s
[2K
| RMSProp | epoch: 008 | loss: 0.66529 - acc: 0.6258 -- iter: 736/986
[A[ATraining Step: 241  | total loss: [1m[32m0.66991[0m[0m | time: 24.568s
[2K
| RMSProp | epoch: 008 | loss: 0.66991 - acc: 0.6164 -- iter: 768/986
[A[ATraining Step: 242  | total loss: [1m[32m0.67052[0m[0m | time: 25.656s
[2K
| RMSProp | epoch: 008 | loss: 0.67052 - acc: 0.6141 -- iter: 800/986
[A[ATraining Step: 243  | total loss: [1m[32m0.67218[0m[0m | time: 26.656s
[2K
| RMSProp | epoch: 008 | loss: 0.67218 - acc: 0.6090 -- iter: 832/986
[A[ATraining Step: 244  | total loss: [1m[32m0.67510[0m[0m | time: 27.723s
[2K
| RMSProp | epoch: 008 | loss: 0.67510 - acc: 0.6012 -- iter: 864/986
[A[ATraining Step: 245  | total loss: [1m[32m0.67393[0m[0m | time: 28.697s
[2K
| RMSProp | epoch: 008 | loss: 0.67393 - acc: 0.6036 -- iter: 896/986
[A[ATraining Step: 246  | total loss: [1m[32m0.67410[0m[0m | time: 29.750s
[2K
| RMSProp | epoch: 008 | loss: 0.67410 - acc: 0.6026 -- iter: 928/986
[A[ATraining Step: 247  | total loss: [1m[32m0.67172[0m[0m | time: 30.967s
[2K
| RMSProp | epoch: 008 | loss: 0.67172 - acc: 0.6080 -- iter: 960/986
[A[ATraining Step: 248  | total loss: [1m[32m0.67211[0m[0m | time: 33.628s
[2K
| RMSProp | epoch: 008 | loss: 0.67211 - acc: 0.6065 | val_loss: 0.68138 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 249  | total loss: [1m[32m0.67495[0m[0m | time: 1.023s
[2K
| RMSProp | epoch: 009 | loss: 0.67495 - acc: 0.5990 -- iter: 032/986
[A[ATraining Step: 250  | total loss: [1m[32m0.67373[0m[0m | time: 2.091s
[2K
| RMSProp | epoch: 009 | loss: 0.67373 - acc: 0.6016 -- iter: 064/986
[A[ATraining Step: 251  | total loss: [1m[32m0.68891[0m[0m | time: 3.124s
[2K
| RMSProp | epoch: 009 | loss: 0.68891 - acc: 0.5633 -- iter: 096/986
[A[ATraining Step: 252  | total loss: [1m[32m0.68778[0m[0m | time: 4.240s
[2K
| RMSProp | epoch: 009 | loss: 0.68778 - acc: 0.5664 -- iter: 128/986
[A[ATraining Step: 253  | total loss: [1m[32m0.68754[0m[0m | time: 5.174s
[2K
| RMSProp | epoch: 009 | loss: 0.68754 - acc: 0.5660 -- iter: 160/986
[A[ATraining Step: 254  | total loss: [1m[32m0.67671[0m[0m | time: 6.236s
[2K
| RMSProp | epoch: 009 | loss: 0.67671 - acc: 0.6000 -- iter: 192/986
[A[ATraining Step: 255  | total loss: [1m[32m0.67447[0m[0m | time: 7.208s
[2K
| RMSProp | epoch: 009 | loss: 0.67447 - acc: 0.6056 -- iter: 224/986
[A[ATraining Step: 256  | total loss: [1m[32m0.67362[0m[0m | time: 8.168s
[2K
| RMSProp | epoch: 009 | loss: 0.67362 - acc: 0.6066 -- iter: 256/986
[A[ATraining Step: 257  | total loss: [1m[32m0.67283[0m[0m | time: 9.181s
[2K
| RMSProp | epoch: 009 | loss: 0.67283 - acc: 0.6075 -- iter: 288/986
[A[ATraining Step: 258  | total loss: [1m[32m0.66938[0m[0m | time: 10.179s
[2K
| RMSProp | epoch: 009 | loss: 0.66938 - acc: 0.6155 -- iter: 320/986
[A[ATraining Step: 259  | total loss: [1m[32m0.66993[0m[0m | time: 11.240s
[2K
| RMSProp | epoch: 009 | loss: 0.66993 - acc: 0.6133 -- iter: 352/986
[A[ATraining Step: 260  | total loss: [1m[32m0.66625[0m[0m | time: 12.296s
[2K
| RMSProp | epoch: 009 | loss: 0.66625 - acc: 0.6207 -- iter: 384/986
[A[ATraining Step: 261  | total loss: [1m[32m0.66744[0m[0m | time: 13.262s
[2K
| RMSProp | epoch: 009 | loss: 0.66744 - acc: 0.6180 -- iter: 416/986
[A[ATraining Step: 262  | total loss: [1m[32m0.66519[0m[0m | time: 14.261s
[2K
| RMSProp | epoch: 009 | loss: 0.66519 - acc: 0.6219 -- iter: 448/986
[A[ATraining Step: 263  | total loss: [1m[32m0.67391[0m[0m | time: 15.322s
[2K
| RMSProp | epoch: 009 | loss: 0.67391 - acc: 0.6034 -- iter: 480/986
[A[ATraining Step: 264  | total loss: [1m[32m0.67981[0m[0m | time: 16.667s
[2K
| RMSProp | epoch: 009 | loss: 0.67981 - acc: 0.5868 -- iter: 512/986
[A[ATraining Step: 265  | total loss: [1m[32m0.67832[0m[0m | time: 17.553s
[2K
| RMSProp | epoch: 009 | loss: 0.67832 - acc: 0.5906 -- iter: 544/986
[A[ATraining Step: 266  | total loss: [1m[32m0.68012[0m[0m | time: 18.433s
[2K
| RMSProp | epoch: 009 | loss: 0.68012 - acc: 0.5847 -- iter: 576/986
[A[ATraining Step: 267  | total loss: [1m[32m0.68283[0m[0m | time: 19.366s
[2K
| RMSProp | epoch: 009 | loss: 0.68283 - acc: 0.5762 -- iter: 608/986
[A[ATraining Step: 268  | total loss: [1m[32m0.68316[0m[0m | time: 20.434s
[2K
| RMSProp | epoch: 009 | loss: 0.68316 - acc: 0.5749 -- iter: 640/986
[A[ATraining Step: 269  | total loss: [1m[32m0.68030[0m[0m | time: 21.556s
[2K
| RMSProp | epoch: 009 | loss: 0.68030 - acc: 0.5830 -- iter: 672/986
[A[ATraining Step: 270  | total loss: [1m[32m0.68650[0m[0m | time: 22.407s
[2K
| RMSProp | epoch: 009 | loss: 0.68650 - acc: 0.5653 -- iter: 704/986
[A[ATraining Step: 271  | total loss: [1m[32m0.68639[0m[0m | time: 23.406s
[2K
| RMSProp | epoch: 009 | loss: 0.68639 - acc: 0.5650 -- iter: 736/986
[A[ATraining Step: 272  | total loss: [1m[32m0.68239[0m[0m | time: 24.423s
[2K
| RMSProp | epoch: 009 | loss: 0.68239 - acc: 0.5773 -- iter: 768/986
[A[ATraining Step: 273  | total loss: [1m[32m0.68359[0m[0m | time: 25.466s
[2K
| RMSProp | epoch: 009 | loss: 0.68359 - acc: 0.5727 -- iter: 800/986
[A[ATraining Step: 274  | total loss: [1m[32m0.68350[0m[0m | time: 26.466s
[2K
| RMSProp | epoch: 009 | loss: 0.68350 - acc: 0.5717 -- iter: 832/986
[A[ATraining Step: 275  | total loss: [1m[32m0.68412[0m[0m | time: 27.590s
[2K
| RMSProp | epoch: 009 | loss: 0.68412 - acc: 0.5676 -- iter: 864/986
[A[ATraining Step: 276  | total loss: [1m[32m0.68012[0m[0m | time: 28.697s
[2K
| RMSProp | epoch: 009 | loss: 0.68012 - acc: 0.5796 -- iter: 896/986
[A[ATraining Step: 277  | total loss: [1m[32m0.67720[0m[0m | time: 29.701s
[2K
| RMSProp | epoch: 009 | loss: 0.67720 - acc: 0.5842 -- iter: 928/986
[A[ATraining Step: 278  | total loss: [1m[32m0.67215[0m[0m | time: 30.702s
[2K
| RMSProp | epoch: 009 | loss: 0.67215 - acc: 0.5882 -- iter: 960/986
[A[ATraining Step: 279  | total loss: [1m[32m0.67142[0m[0m | time: 33.587s
[2K
| RMSProp | epoch: 009 | loss: 0.67142 - acc: 0.5857 | val_loss: 0.67282 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 280  | total loss: [1m[32m0.66910[0m[0m | time: 1.038s
[2K
| RMSProp | epoch: 010 | loss: 0.66910 - acc: 0.5958 -- iter: 032/986
[A[ATraining Step: 281  | total loss: [1m[32m0.65748[0m[0m | time: 2.053s
[2K
| RMSProp | epoch: 010 | loss: 0.65748 - acc: 0.6081 -- iter: 064/986
[A[ATraining Step: 282  | total loss: [1m[32m0.65517[0m[0m | time: 3.108s
[2K
| RMSProp | epoch: 010 | loss: 0.65517 - acc: 0.6192 -- iter: 096/986
[A[ATraining Step: 283  | total loss: [1m[32m0.65215[0m[0m | time: 4.111s
[2K
| RMSProp | epoch: 010 | loss: 0.65215 - acc: 0.6260 -- iter: 128/986
[A[ATraining Step: 284  | total loss: [1m[32m0.65503[0m[0m | time: 5.150s
[2K
| RMSProp | epoch: 010 | loss: 0.65503 - acc: 0.6228 -- iter: 160/986
[A[ATraining Step: 285  | total loss: [1m[32m0.65209[0m[0m | time: 6.212s
[2K
| RMSProp | epoch: 010 | loss: 0.65209 - acc: 0.6261 -- iter: 192/986
[A[ATraining Step: 286  | total loss: [1m[32m0.64072[0m[0m | time: 7.249s
[2K
| RMSProp | epoch: 010 | loss: 0.64072 - acc: 0.6417 -- iter: 224/986
[A[ATraining Step: 287  | total loss: [1m[32m0.65780[0m[0m | time: 8.015s
[2K
| RMSProp | epoch: 010 | loss: 0.65780 - acc: 0.6275 -- iter: 256/986
[A[ATraining Step: 288  | total loss: [1m[32m0.64596[0m[0m | time: 8.952s
[2K
| RMSProp | epoch: 010 | loss: 0.64596 - acc: 0.6532 -- iter: 288/986
[A[ATraining Step: 289  | total loss: [1m[32m0.62510[0m[0m | time: 10.113s
[2K
| RMSProp | epoch: 010 | loss: 0.62510 - acc: 0.6763 -- iter: 320/986
[A[ATraining Step: 290  | total loss: [1m[32m0.62664[0m[0m | time: 11.298s
[2K
| RMSProp | epoch: 010 | loss: 0.62664 - acc: 0.6681 -- iter: 352/986
[A[ATraining Step: 291  | total loss: [1m[32m0.63656[0m[0m | time: 12.231s
[2K
| RMSProp | epoch: 010 | loss: 0.63656 - acc: 0.6513 -- iter: 384/986
[A[ATraining Step: 292  | total loss: [1m[32m0.64373[0m[0m | time: 13.243s
[2K
| RMSProp | epoch: 010 | loss: 0.64373 - acc: 0.6330 -- iter: 416/986
[A[ATraining Step: 293  | total loss: [1m[32m0.64709[0m[0m | time: 14.273s
[2K
| RMSProp | epoch: 010 | loss: 0.64709 - acc: 0.6260 -- iter: 448/986
[A[ATraining Step: 294  | total loss: [1m[32m0.64569[0m[0m | time: 15.345s
[2K
| RMSProp | epoch: 010 | loss: 0.64569 - acc: 0.6259 -- iter: 480/986
[A[ATraining Step: 295  | total loss: [1m[32m0.64766[0m[0m | time: 16.378s
[2K
| RMSProp | epoch: 010 | loss: 0.64766 - acc: 0.6195 -- iter: 512/986
[A[ATraining Step: 296  | total loss: [1m[32m0.65070[0m[0m | time: 17.426s
[2K
| RMSProp | epoch: 010 | loss: 0.65070 - acc: 0.6107 -- iter: 544/986
[A[ATraining Step: 297  | total loss: [1m[32m0.65190[0m[0m | time: 18.730s
[2K
| RMSProp | epoch: 010 | loss: 0.65190 - acc: 0.6121 -- iter: 576/986
[A[ATraining Step: 298  | total loss: [1m[32m0.65072[0m[0m | time: 19.831s
[2K
| RMSProp | epoch: 010 | loss: 0.65072 - acc: 0.6197 -- iter: 608/986
[A[ATraining Step: 299  | total loss: [1m[32m0.65607[0m[0m | time: 20.675s
[2K
| RMSProp | epoch: 010 | loss: 0.65607 - acc: 0.6140 -- iter: 640/986
[A[ATraining Step: 300  | total loss: [1m[32m0.65951[0m[0m | time: 21.593s
[2K
| RMSProp | epoch: 010 | loss: 0.65951 - acc: 0.6057 -- iter: 672/986
[A[ATraining Step: 301  | total loss: [1m[32m0.65591[0m[0m | time: 22.759s
[2K
| RMSProp | epoch: 010 | loss: 0.65591 - acc: 0.6045 -- iter: 704/986
[A[ATraining Step: 302  | total loss: [1m[32m0.65764[0m[0m | time: 23.877s
[2K
| RMSProp | epoch: 010 | loss: 0.65764 - acc: 0.6003 -- iter: 736/986
[A[ATraining Step: 303  | total loss: [1m[32m0.65345[0m[0m | time: 24.845s
[2K
| RMSProp | epoch: 010 | loss: 0.65345 - acc: 0.5996 -- iter: 768/986
[A[ATraining Step: 304  | total loss: [1m[32m0.64702[0m[0m | time: 25.803s
[2K
| RMSProp | epoch: 010 | loss: 0.64702 - acc: 0.5959 -- iter: 800/986
[A[ATraining Step: 305  | total loss: [1m[32m0.65145[0m[0m | time: 26.827s
[2K
| RMSProp | epoch: 010 | loss: 0.65145 - acc: 0.5957 -- iter: 832/986
[A[ATraining Step: 306  | total loss: [1m[32m0.65230[0m[0m | time: 27.808s
[2K
| RMSProp | epoch: 010 | loss: 0.65230 - acc: 0.5924 -- iter: 864/986
[A[ATraining Step: 307  | total loss: [1m[32m0.65397[0m[0m | time: 28.769s
[2K
| RMSProp | epoch: 010 | loss: 0.65397 - acc: 0.5863 -- iter: 896/986
[A[ATraining Step: 308  | total loss: [1m[32m0.65930[0m[0m | time: 29.768s
[2K
| RMSProp | epoch: 010 | loss: 0.65930 - acc: 0.5839 -- iter: 928/986
[A[ATraining Step: 309  | total loss: [1m[32m0.66118[0m[0m | time: 30.794s
[2K
| RMSProp | epoch: 010 | loss: 0.66118 - acc: 0.5755 -- iter: 960/986
[A[ATraining Step: 310  | total loss: [1m[32m0.66005[0m[0m | time: 33.628s
[2K
| RMSProp | epoch: 010 | loss: 0.66005 - acc: 0.5836 | val_loss: 0.64674 - val_acc: 0.5761 -- iter: 986/986
--
Training Step: 311  | total loss: [1m[32m0.65835[0m[0m | time: 1.126s
[2K
| RMSProp | epoch: 011 | loss: 0.65835 - acc: 0.5815 -- iter: 032/986
[A[ATraining Step: 312  | total loss: [1m[32m0.64699[0m[0m | time: 2.042s
[2K
| RMSProp | epoch: 011 | loss: 0.64699 - acc: 0.5858 -- iter: 064/986
[A[ATraining Step: 313  | total loss: [1m[32m0.62390[0m[0m | time: 3.080s
[2K
| RMSProp | epoch: 011 | loss: 0.62390 - acc: 0.6022 -- iter: 096/986
[A[ATraining Step: 314  | total loss: [1m[32m0.61380[0m[0m | time: 4.074s
[2K
| RMSProp | epoch: 011 | loss: 0.61380 - acc: 0.6201 -- iter: 128/986
[A[ATraining Step: 315  | total loss: [1m[32m0.61179[0m[0m | time: 5.113s
[2K
| RMSProp | epoch: 011 | loss: 0.61179 - acc: 0.6269 -- iter: 160/986
[A[ATraining Step: 316  | total loss: [1m[32m0.62106[0m[0m | time: 6.182s
[2K
| RMSProp | epoch: 011 | loss: 0.62106 - acc: 0.6204 -- iter: 192/986
[A[ATraining Step: 317  | total loss: [1m[32m0.61360[0m[0m | time: 7.239s
[2K
| RMSProp | epoch: 011 | loss: 0.61360 - acc: 0.6396 -- iter: 224/986
[A[ATraining Step: 318  | total loss: [1m[32m0.60511[0m[0m | time: 8.330s
[2K
| RMSProp | epoch: 011 | loss: 0.60511 - acc: 0.6507 -- iter: 256/986
[A[ATraining Step: 319  | total loss: [1m[32m0.60859[0m[0m | time: 9.231s
[2K
| RMSProp | epoch: 011 | loss: 0.60859 - acc: 0.6481 -- iter: 288/986
[A[ATraining Step: 320  | total loss: [1m[32m0.58380[0m[0m | time: 10.150s
[2K
| RMSProp | epoch: 011 | loss: 0.58380 - acc: 0.6756 -- iter: 320/986
[A[ATraining Step: 321  | total loss: [1m[32m0.60699[0m[0m | time: 11.213s
[2K
| RMSProp | epoch: 011 | loss: 0.60699 - acc: 0.6734 -- iter: 352/986
[A[ATraining Step: 322  | total loss: [1m[32m0.60788[0m[0m | time: 12.438s
[2K
| RMSProp | epoch: 011 | loss: 0.60788 - acc: 0.6623 -- iter: 384/986
[A[ATraining Step: 323  | total loss: [1m[32m0.60660[0m[0m | time: 13.660s
[2K
| RMSProp | epoch: 011 | loss: 0.60660 - acc: 0.6711 -- iter: 416/986
[A[ATraining Step: 324  | total loss: [1m[32m0.59752[0m[0m | time: 14.690s
[2K
| RMSProp | epoch: 011 | loss: 0.59752 - acc: 0.6790 -- iter: 448/986
[A[ATraining Step: 325  | total loss: [1m[32m0.60207[0m[0m | time: 15.764s
[2K
| RMSProp | epoch: 011 | loss: 0.60207 - acc: 0.6798 -- iter: 480/986
[A[ATraining Step: 326  | total loss: [1m[32m0.60946[0m[0m | time: 16.853s
[2K
| RMSProp | epoch: 011 | loss: 0.60946 - acc: 0.6806 -- iter: 512/986
[A[ATraining Step: 327  | total loss: [1m[32m0.61591[0m[0m | time: 17.872s
[2K
| RMSProp | epoch: 011 | loss: 0.61591 - acc: 0.6657 -- iter: 544/986
[A[ATraining Step: 328  | total loss: [1m[32m0.62011[0m[0m | time: 18.935s
[2K
| RMSProp | epoch: 011 | loss: 0.62011 - acc: 0.6429 -- iter: 576/986
[A[ATraining Step: 329  | total loss: [1m[32m0.62029[0m[0m | time: 20.356s
[2K
| RMSProp | epoch: 011 | loss: 0.62029 - acc: 0.6473 -- iter: 608/986
[A[ATraining Step: 330  | total loss: [1m[32m0.61716[0m[0m | time: 21.447s
[2K
| RMSProp | epoch: 011 | loss: 0.61716 - acc: 0.6638 -- iter: 640/986
[A[ATraining Step: 331  | total loss: [1m[32m0.61387[0m[0m | time: 22.387s
[2K
| RMSProp | epoch: 011 | loss: 0.61387 - acc: 0.6725 -- iter: 672/986
[A[ATraining Step: 332  | total loss: [1m[32m0.60492[0m[0m | time: 23.252s
[2K
| RMSProp | epoch: 011 | loss: 0.60492 - acc: 0.6740 -- iter: 704/986
[A[ATraining Step: 333  | total loss: [1m[32m0.60358[0m[0m | time: 24.247s
[2K
| RMSProp | epoch: 011 | loss: 0.60358 - acc: 0.6691 -- iter: 736/986
[A[ATraining Step: 334  | total loss: [1m[32m0.59911[0m[0m | time: 25.421s
[2K
| RMSProp | epoch: 011 | loss: 0.59911 - acc: 0.6740 -- iter: 768/986
[A[ATraining Step: 335  | total loss: [1m[32m0.60545[0m[0m | time: 26.579s
[2K
| RMSProp | epoch: 011 | loss: 0.60545 - acc: 0.6660 -- iter: 800/986
[A[ATraining Step: 336  | total loss: [1m[32m0.60382[0m[0m | time: 27.478s
[2K
| RMSProp | epoch: 011 | loss: 0.60382 - acc: 0.6682 -- iter: 832/986
[A[ATraining Step: 337  | total loss: [1m[32m0.60643[0m[0m | time: 28.473s
[2K
| RMSProp | epoch: 011 | loss: 0.60643 - acc: 0.6607 -- iter: 864/986
[A[ATraining Step: 338  | total loss: [1m[32m0.59604[0m[0m | time: 29.503s
[2K
| RMSProp | epoch: 011 | loss: 0.59604 - acc: 0.6634 -- iter: 896/986
[A[ATraining Step: 339  | total loss: [1m[32m0.59332[0m[0m | time: 30.529s
[2K
| RMSProp | epoch: 011 | loss: 0.59332 - acc: 0.6658 -- iter: 928/986
[A[ATraining Step: 340  | total loss: [1m[32m0.59622[0m[0m | time: 31.578s
[2K
| RMSProp | epoch: 011 | loss: 0.59622 - acc: 0.6648 -- iter: 960/986
[A[ATraining Step: 341  | total loss: [1m[32m0.59379[0m[0m | time: 34.330s
[2K
| RMSProp | epoch: 011 | loss: 0.59379 - acc: 0.6702 | val_loss: 0.71920 - val_acc: 0.4790 -- iter: 986/986
--
Training Step: 342  | total loss: [1m[32m0.59688[0m[0m | time: 1.272s
[2K
| RMSProp | epoch: 012 | loss: 0.59688 - acc: 0.6751 -- iter: 032/986
[A[ATraining Step: 343  | total loss: [1m[32m0.60644[0m[0m | time: 2.461s
[2K
| RMSProp | epoch: 012 | loss: 0.60644 - acc: 0.6607 -- iter: 064/986
[A[ATraining Step: 344  | total loss: [1m[32m0.60625[0m[0m | time: 3.436s
[2K
| RMSProp | epoch: 012 | loss: 0.60625 - acc: 0.6634 -- iter: 096/986
[A[ATraining Step: 345  | total loss: [1m[32m0.60624[0m[0m | time: 4.394s
[2K
| RMSProp | epoch: 012 | loss: 0.60624 - acc: 0.6627 -- iter: 128/986
[A[ATraining Step: 346  | total loss: [1m[32m0.61319[0m[0m | time: 5.444s
[2K
| RMSProp | epoch: 012 | loss: 0.61319 - acc: 0.6495 -- iter: 160/986
[A[ATraining Step: 347  | total loss: [1m[32m0.61565[0m[0m | time: 6.540s
[2K
| RMSProp | epoch: 012 | loss: 0.61565 - acc: 0.6533 -- iter: 192/986
[A[ATraining Step: 348  | total loss: [1m[32m0.60853[0m[0m | time: 7.593s
[2K
| RMSProp | epoch: 012 | loss: 0.60853 - acc: 0.6661 -- iter: 224/986
[A[ATraining Step: 349  | total loss: [1m[32m0.60592[0m[0m | time: 8.699s
[2K
| RMSProp | epoch: 012 | loss: 0.60592 - acc: 0.6683 -- iter: 256/986
[A[ATraining Step: 350  | total loss: [1m[32m0.61437[0m[0m | time: 9.723s
[2K
| RMSProp | epoch: 012 | loss: 0.61437 - acc: 0.6671 -- iter: 288/986
[A[ATraining Step: 351  | total loss: [1m[32m0.62298[0m[0m | time: 10.653s
[2K
| RMSProp | epoch: 012 | loss: 0.62298 - acc: 0.6472 -- iter: 320/986
[A[ATraining Step: 352  | total loss: [1m[32m0.62595[0m[0m | time: 11.534s
[2K
| RMSProp | epoch: 012 | loss: 0.62595 - acc: 0.6479 -- iter: 352/986
[A[ATraining Step: 353  | total loss: [1m[32m0.61950[0m[0m | time: 12.614s
[2K
| RMSProp | epoch: 012 | loss: 0.61950 - acc: 0.6523 -- iter: 384/986
[A[ATraining Step: 354  | total loss: [1m[32m0.62329[0m[0m | time: 13.793s
[2K
| RMSProp | epoch: 012 | loss: 0.62329 - acc: 0.6496 -- iter: 416/986
[A[ATraining Step: 355  | total loss: [1m[32m0.62157[0m[0m | time: 15.059s
[2K
| RMSProp | epoch: 012 | loss: 0.62157 - acc: 0.6565 -- iter: 448/986
[A[ATraining Step: 356  | total loss: [1m[32m0.60997[0m[0m | time: 16.113s
[2K
| RMSProp | epoch: 012 | loss: 0.60997 - acc: 0.6659 -- iter: 480/986
[A[ATraining Step: 357  | total loss: [1m[32m0.58933[0m[0m | time: 17.069s
[2K
| RMSProp | epoch: 012 | loss: 0.58933 - acc: 0.6836 -- iter: 512/986
[A[ATraining Step: 358  | total loss: [1m[32m0.62094[0m[0m | time: 18.140s
[2K
| RMSProp | epoch: 012 | loss: 0.62094 - acc: 0.6809 -- iter: 544/986
[A[ATraining Step: 359  | total loss: [1m[32m0.62562[0m[0m | time: 19.184s
[2K
| RMSProp | epoch: 012 | loss: 0.62562 - acc: 0.6691 -- iter: 576/986
[A[ATraining Step: 360  | total loss: [1m[32m0.63137[0m[0m | time: 20.219s
[2K
| RMSProp | epoch: 012 | loss: 0.63137 - acc: 0.6584 -- iter: 608/986
[A[ATraining Step: 361  | total loss: [1m[32m0.62983[0m[0m | time: 21.260s
[2K
| RMSProp | epoch: 012 | loss: 0.62983 - acc: 0.6644 -- iter: 640/986
[A[ATraining Step: 362  | total loss: [1m[32m0.62714[0m[0m | time: 22.402s
[2K
| RMSProp | epoch: 012 | loss: 0.62714 - acc: 0.6668 -- iter: 672/986
[A[ATraining Step: 363  | total loss: [1m[32m0.62979[0m[0m | time: 23.702s
[2K
| RMSProp | epoch: 012 | loss: 0.62979 - acc: 0.6563 -- iter: 704/986
[A[ATraining Step: 364  | total loss: [1m[32m0.63719[0m[0m | time: 24.681s
[2K
| RMSProp | epoch: 012 | loss: 0.63719 - acc: 0.6407 -- iter: 736/986
[A[ATraining Step: 365  | total loss: [1m[32m0.63959[0m[0m | time: 25.510s
[2K
| RMSProp | epoch: 012 | loss: 0.63959 - acc: 0.6329 -- iter: 768/986
[A[ATraining Step: 366  | total loss: [1m[32m0.63682[0m[0m | time: 26.602s
[2K
| RMSProp | epoch: 012 | loss: 0.63682 - acc: 0.6415 -- iter: 800/986
[A[ATraining Step: 367  | total loss: [1m[32m0.62747[0m[0m | time: 27.718s
[2K
| RMSProp | epoch: 012 | loss: 0.62747 - acc: 0.6429 -- iter: 832/986
[A[ATraining Step: 368  | total loss: [1m[32m0.62194[0m[0m | time: 28.780s
[2K
| RMSProp | epoch: 012 | loss: 0.62194 - acc: 0.6380 -- iter: 864/986
[A[ATraining Step: 369  | total loss: [1m[32m0.61609[0m[0m | time: 30.026s
[2K
| RMSProp | epoch: 012 | loss: 0.61609 - acc: 0.6586 -- iter: 896/986
[A[ATraining Step: 370  | total loss: [1m[32m0.60442[0m[0m | time: 31.439s
[2K
| RMSProp | epoch: 012 | loss: 0.60442 - acc: 0.6709 -- iter: 928/986
[A[ATraining Step: 371  | total loss: [1m[32m0.60825[0m[0m | time: 32.828s
[2K
| RMSProp | epoch: 012 | loss: 0.60825 - acc: 0.6663 -- iter: 960/986
[A[ATraining Step: 372  | total loss: [1m[32m0.59177[0m[0m | time: 36.486s
[2K
| RMSProp | epoch: 012 | loss: 0.59177 - acc: 0.6871 | val_loss: 0.60509 - val_acc: 0.7184 -- iter: 986/986
--
Training Step: 373  | total loss: [1m[32m0.59982[0m[0m | time: 1.358s
[2K
| RMSProp | epoch: 013 | loss: 0.59982 - acc: 0.6716 -- iter: 032/986
[A[ATraining Step: 374  | total loss: [1m[32m0.59397[0m[0m | time: 2.869s
[2K
| RMSProp | epoch: 013 | loss: 0.59397 - acc: 0.6825 -- iter: 064/986
[A[ATraining Step: 375  | total loss: [1m[32m0.59155[0m[0m | time: 4.361s
[2K
| RMSProp | epoch: 013 | loss: 0.59155 - acc: 0.6893 -- iter: 096/986
[A[ATraining Step: 376  | total loss: [1m[32m0.58916[0m[0m | time: 5.687s
[2K
| RMSProp | epoch: 013 | loss: 0.58916 - acc: 0.6922 -- iter: 128/986
[A[ATraining Step: 377  | total loss: [1m[32m0.60356[0m[0m | time: 6.710s
[2K
| RMSProp | epoch: 013 | loss: 0.60356 - acc: 0.6667 -- iter: 160/986
[A[ATraining Step: 378  | total loss: [1m[32m0.60488[0m[0m | time: 7.725s
[2K
| RMSProp | epoch: 013 | loss: 0.60488 - acc: 0.6751 -- iter: 192/986
[A[ATraining Step: 379  | total loss: [1m[32m0.59939[0m[0m | time: 9.261s
[2K
| RMSProp | epoch: 013 | loss: 0.59939 - acc: 0.6826 -- iter: 224/986
[A[ATraining Step: 380  | total loss: [1m[32m0.59079[0m[0m | time: 10.528s
[2K
| RMSProp | epoch: 013 | loss: 0.59079 - acc: 0.6924 -- iter: 256/986
[A[ATraining Step: 381  | total loss: [1m[32m0.58648[0m[0m | time: 11.843s
[2K
| RMSProp | epoch: 013 | loss: 0.58648 - acc: 0.7013 -- iter: 288/986
[A[ATraining Step: 382  | total loss: [1m[32m0.57992[0m[0m | time: 13.365s
[2K
| RMSProp | epoch: 013 | loss: 0.57992 - acc: 0.7031 -- iter: 320/986
[A[ATraining Step: 383  | total loss: [1m[32m0.59571[0m[0m | time: 14.423s
[2K
| RMSProp | epoch: 013 | loss: 0.59571 - acc: 0.6859 -- iter: 352/986
[A[ATraining Step: 384  | total loss: [1m[32m0.59257[0m[0m | time: 15.522s
[2K
| RMSProp | epoch: 013 | loss: 0.59257 - acc: 0.6904 -- iter: 384/986
[A[ATraining Step: 385  | total loss: [1m[32m0.59403[0m[0m | time: 16.952s
[2K
| RMSProp | epoch: 013 | loss: 0.59403 - acc: 0.6906 -- iter: 416/986
[A[ATraining Step: 386  | total loss: [1m[32m0.59795[0m[0m | time: 18.412s
[2K
| RMSProp | epoch: 013 | loss: 0.59795 - acc: 0.6903 -- iter: 448/986
[A[ATraining Step: 387  | total loss: [1m[32m0.58884[0m[0m | time: 19.981s
[2K
| RMSProp | epoch: 013 | loss: 0.58884 - acc: 0.6962 -- iter: 480/986
[A[ATraining Step: 388  | total loss: [1m[32m0.59632[0m[0m | time: 21.545s
[2K
| RMSProp | epoch: 013 | loss: 0.59632 - acc: 0.6891 -- iter: 512/986
[A[ATraining Step: 389  | total loss: [1m[32m0.60947[0m[0m | time: 23.267s
[2K
| RMSProp | epoch: 013 | loss: 0.60947 - acc: 0.6608 -- iter: 544/986
[A[ATraining Step: 390  | total loss: [1m[32m0.60579[0m[0m | time: 24.853s
[2K
| RMSProp | epoch: 013 | loss: 0.60579 - acc: 0.6697 -- iter: 576/986
[A[ATraining Step: 391  | total loss: [1m[32m0.60689[0m[0m | time: 26.384s
[2K
| RMSProp | epoch: 013 | loss: 0.60689 - acc: 0.6746 -- iter: 608/986
[A[ATraining Step: 392  | total loss: [1m[32m0.59548[0m[0m | time: 27.763s
[2K
| RMSProp | epoch: 013 | loss: 0.59548 - acc: 0.6916 -- iter: 640/986
[A[ATraining Step: 393  | total loss: [1m[32m0.58285[0m[0m | time: 29.278s
[2K
| RMSProp | epoch: 013 | loss: 0.58285 - acc: 0.7005 -- iter: 672/986
[A[ATraining Step: 394  | total loss: [1m[32m0.57921[0m[0m | time: 30.725s
[2K
| RMSProp | epoch: 013 | loss: 0.57921 - acc: 0.7086 -- iter: 704/986
[A[ATraining Step: 395  | total loss: [1m[32m0.58130[0m[0m | time: 32.144s
[2K
| RMSProp | epoch: 013 | loss: 0.58130 - acc: 0.7065 -- iter: 736/986
[A[ATraining Step: 396  | total loss: [1m[32m0.57684[0m[0m | time: 33.552s
[2K
| RMSProp | epoch: 013 | loss: 0.57684 - acc: 0.7108 -- iter: 768/986
[A[ATraining Step: 397  | total loss: [1m[32m0.59726[0m[0m | time: 35.250s
[2K
| RMSProp | epoch: 013 | loss: 0.59726 - acc: 0.6929 -- iter: 800/986
[A[ATraining Step: 398  | total loss: [1m[32m0.59475[0m[0m | time: 36.832s
[2K
| RMSProp | epoch: 013 | loss: 0.59475 - acc: 0.7017 -- iter: 832/986
[A[ATraining Step: 399  | total loss: [1m[32m0.59508[0m[0m | time: 38.155s
[2K
| RMSProp | epoch: 013 | loss: 0.59508 - acc: 0.7003 -- iter: 864/986
[A[ATraining Step: 400  | total loss: [1m[32m0.58128[0m[0m | time: 41.772s
[2K
| RMSProp | epoch: 013 | loss: 0.58128 - acc: 0.7146 | val_loss: 0.60102 - val_acc: 0.6893 -- iter: 896/986
--
Training Step: 401  | total loss: [1m[32m0.58449[0m[0m | time: 43.263s
[2K
| RMSProp | epoch: 013 | loss: 0.58449 - acc: 0.7057 -- iter: 928/986
[A[ATraining Step: 402  | total loss: [1m[32m0.59346[0m[0m | time: 44.579s
[2K
| RMSProp | epoch: 013 | loss: 0.59346 - acc: 0.6945 -- iter: 960/986
[A[ATraining Step: 403  | total loss: [1m[32m0.59182[0m[0m | time: 48.566s
[2K
| RMSProp | epoch: 013 | loss: 0.59182 - acc: 0.6969 | val_loss: 0.57293 - val_acc: 0.7314 -- iter: 986/986
--
Training Step: 404  | total loss: [1m[32m0.59153[0m[0m | time: 1.284s
[2K
| RMSProp | epoch: 014 | loss: 0.59153 - acc: 0.6928 -- iter: 032/986
[A[ATraining Step: 405  | total loss: [1m[32m0.58426[0m[0m | time: 2.552s
[2K
| RMSProp | epoch: 014 | loss: 0.58426 - acc: 0.7048 -- iter: 064/986
[A[ATraining Step: 406  | total loss: [1m[32m0.59410[0m[0m | time: 3.699s
[2K
| RMSProp | epoch: 014 | loss: 0.59410 - acc: 0.7000 -- iter: 096/986
[A[ATraining Step: 407  | total loss: [1m[32m0.59439[0m[0m | time: 4.719s
[2K
| RMSProp | epoch: 014 | loss: 0.59439 - acc: 0.6987 -- iter: 128/986
[A[ATraining Step: 408  | total loss: [1m[32m0.59833[0m[0m | time: 5.824s
[2K
| RMSProp | epoch: 014 | loss: 0.59833 - acc: 0.6976 -- iter: 160/986
[A[ATraining Step: 409  | total loss: [1m[32m0.60580[0m[0m | time: 7.081s
[2K
| RMSProp | epoch: 014 | loss: 0.60580 - acc: 0.6872 -- iter: 192/986
[A[ATraining Step: 410  | total loss: [1m[32m0.59275[0m[0m | time: 8.246s
[2K
| RMSProp | epoch: 014 | loss: 0.59275 - acc: 0.6872 -- iter: 224/986
[A[ATraining Step: 411  | total loss: [1m[32m0.59237[0m[0m | time: 9.308s
[2K
| RMSProp | epoch: 014 | loss: 0.59237 - acc: 0.6904 -- iter: 256/986
[A[ATraining Step: 412  | total loss: [1m[32m0.59193[0m[0m | time: 10.423s
[2K
| RMSProp | epoch: 014 | loss: 0.59193 - acc: 0.6963 -- iter: 288/986
[A[ATraining Step: 413  | total loss: [1m[32m0.57860[0m[0m | time: 11.552s
[2K
| RMSProp | epoch: 014 | loss: 0.57860 - acc: 0.7017 -- iter: 320/986
[A[ATraining Step: 414  | total loss: [1m[32m0.56431[0m[0m | time: 12.624s
[2K
| RMSProp | epoch: 014 | loss: 0.56431 - acc: 0.7159 -- iter: 352/986
[A[ATraining Step: 415  | total loss: [1m[32m0.57061[0m[0m | time: 13.599s
[2K
| RMSProp | epoch: 014 | loss: 0.57061 - acc: 0.7162 -- iter: 384/986
[A[ATraining Step: 416  | total loss: [1m[32m0.57533[0m[0m | time: 14.647s
[2K
| RMSProp | epoch: 014 | loss: 0.57533 - acc: 0.7100 -- iter: 416/986
[A[ATraining Step: 417  | total loss: [1m[32m0.56049[0m[0m | time: 15.957s
[2K
| RMSProp | epoch: 014 | loss: 0.56049 - acc: 0.7236 -- iter: 448/986
[A[ATraining Step: 418  | total loss: [1m[32m0.55530[0m[0m | time: 17.096s
[2K
| RMSProp | epoch: 014 | loss: 0.55530 - acc: 0.7325 -- iter: 480/986
[A[ATraining Step: 419  | total loss: [1m[32m0.55963[0m[0m | time: 18.072s
[2K
| RMSProp | epoch: 014 | loss: 0.55963 - acc: 0.7311 -- iter: 512/986
[A[ATraining Step: 420  | total loss: [1m[32m0.56052[0m[0m | time: 19.321s
[2K
| RMSProp | epoch: 014 | loss: 0.56052 - acc: 0.7267 -- iter: 544/986
[A[ATraining Step: 421  | total loss: [1m[32m0.55181[0m[0m | time: 20.622s
[2K
| RMSProp | epoch: 014 | loss: 0.55181 - acc: 0.7353 -- iter: 576/986
[A[ATraining Step: 422  | total loss: [1m[32m0.56752[0m[0m | time: 21.903s
[2K
| RMSProp | epoch: 014 | loss: 0.56752 - acc: 0.7149 -- iter: 608/986
[A[ATraining Step: 423  | total loss: [1m[32m0.57133[0m[0m | time: 22.906s
[2K
| RMSProp | epoch: 014 | loss: 0.57133 - acc: 0.7153 -- iter: 640/986
[A[ATraining Step: 424  | total loss: [1m[32m0.55641[0m[0m | time: 24.084s
[2K
| RMSProp | epoch: 014 | loss: 0.55641 - acc: 0.7344 -- iter: 672/986
[A[ATraining Step: 425  | total loss: [1m[32m0.55414[0m[0m | time: 25.209s
[2K
| RMSProp | epoch: 014 | loss: 0.55414 - acc: 0.7360 -- iter: 704/986
[A[ATraining Step: 426  | total loss: [1m[32m0.55492[0m[0m | time: 26.561s
[2K
| RMSProp | epoch: 014 | loss: 0.55492 - acc: 0.7311 -- iter: 736/986
[A[ATraining Step: 427  | total loss: [1m[32m0.55441[0m[0m | time: 27.662s
[2K
| RMSProp | epoch: 014 | loss: 0.55441 - acc: 0.7299 -- iter: 768/986
[A[ATraining Step: 428  | total loss: [1m[32m0.55729[0m[0m | time: 28.809s
[2K
| RMSProp | epoch: 014 | loss: 0.55729 - acc: 0.7225 -- iter: 800/986
[A[ATraining Step: 429  | total loss: [1m[32m0.55634[0m[0m | time: 29.699s
[2K
| RMSProp | epoch: 014 | loss: 0.55634 - acc: 0.7221 -- iter: 832/986
[A[ATraining Step: 430  | total loss: [1m[32m0.55689[0m[0m | time: 30.515s
[2K
| RMSProp | epoch: 014 | loss: 0.55689 - acc: 0.7124 -- iter: 864/986
[A[ATraining Step: 431  | total loss: [1m[32m0.54955[0m[0m | time: 31.695s
[2K
| RMSProp | epoch: 014 | loss: 0.54955 - acc: 0.7162 -- iter: 896/986
[A[ATraining Step: 432  | total loss: [1m[32m0.54267[0m[0m | time: 32.879s
[2K
| RMSProp | epoch: 014 | loss: 0.54267 - acc: 0.7196 -- iter: 928/986
[A[ATraining Step: 433  | total loss: [1m[32m0.55136[0m[0m | time: 34.120s
[2K
| RMSProp | epoch: 014 | loss: 0.55136 - acc: 0.7164 -- iter: 960/986
[A[ATraining Step: 434  | total loss: [1m[32m0.55108[0m[0m | time: 36.717s
[2K
| RMSProp | epoch: 014 | loss: 0.55108 - acc: 0.7135 | val_loss: 0.68937 - val_acc: 0.5113 -- iter: 986/986
--
Training Step: 435  | total loss: [1m[32m0.60148[0m[0m | time: 1.021s
[2K
| RMSProp | epoch: 015 | loss: 0.60148 - acc: 0.6827 -- iter: 032/986
[A[ATraining Step: 436  | total loss: [1m[32m0.61316[0m[0m | time: 2.077s
[2K
| RMSProp | epoch: 015 | loss: 0.61316 - acc: 0.6582 -- iter: 064/986
[A[ATraining Step: 437  | total loss: [1m[32m0.61814[0m[0m | time: 3.325s
[2K
| RMSProp | epoch: 015 | loss: 0.61814 - acc: 0.6518 -- iter: 096/986
[A[ATraining Step: 438  | total loss: [1m[32m0.60669[0m[0m | time: 4.757s
[2K
| RMSProp | epoch: 015 | loss: 0.60669 - acc: 0.6678 -- iter: 128/986
[A[ATraining Step: 439  | total loss: [1m[32m0.60225[0m[0m | time: 6.273s
[2K
| RMSProp | epoch: 015 | loss: 0.60225 - acc: 0.6636 -- iter: 160/986
[A[ATraining Step: 440  | total loss: [1m[32m0.59470[0m[0m | time: 7.780s
[2K
| RMSProp | epoch: 015 | loss: 0.59470 - acc: 0.6753 -- iter: 192/986
[A[ATraining Step: 441  | total loss: [1m[32m0.59032[0m[0m | time: 9.252s
[2K
| RMSProp | epoch: 015 | loss: 0.59032 - acc: 0.6859 -- iter: 224/986
[A[ATraining Step: 442  | total loss: [1m[32m0.59345[0m[0m | time: 10.535s
[2K
| RMSProp | epoch: 015 | loss: 0.59345 - acc: 0.6861 -- iter: 256/986
[A[ATraining Step: 443  | total loss: [1m[32m0.58727[0m[0m | time: 11.743s
[2K
| RMSProp | epoch: 015 | loss: 0.58727 - acc: 0.6893 -- iter: 288/986
[A[ATraining Step: 444  | total loss: [1m[32m0.58937[0m[0m | time: 12.644s
[2K
| RMSProp | epoch: 015 | loss: 0.58937 - acc: 0.6892 -- iter: 320/986
[A[ATraining Step: 445  | total loss: [1m[32m0.59362[0m[0m | time: 13.650s
[2K
| RMSProp | epoch: 015 | loss: 0.59362 - acc: 0.6921 -- iter: 352/986
[A[ATraining Step: 446  | total loss: [1m[32m0.58720[0m[0m | time: 14.643s
[2K
| RMSProp | epoch: 015 | loss: 0.58720 - acc: 0.7010 -- iter: 384/986
[A[ATraining Step: 447  | total loss: [1m[32m0.57942[0m[0m | time: 15.504s
[2K
| RMSProp | epoch: 015 | loss: 0.57942 - acc: 0.7122 -- iter: 416/986
[A[ATraining Step: 448  | total loss: [1m[32m0.57717[0m[0m | time: 16.372s
[2K
| RMSProp | epoch: 015 | loss: 0.57717 - acc: 0.7102 -- iter: 448/986
[A[ATraining Step: 449  | total loss: [1m[32m0.56865[0m[0m | time: 17.424s
[2K
| RMSProp | epoch: 015 | loss: 0.56865 - acc: 0.7199 -- iter: 480/986
[A[ATraining Step: 450  | total loss: [1m[32m0.57278[0m[0m | time: 18.512s
[2K
| RMSProp | epoch: 015 | loss: 0.57278 - acc: 0.7198 -- iter: 512/986
[A[ATraining Step: 451  | total loss: [1m[32m0.56315[0m[0m | time: 19.632s
[2K
| RMSProp | epoch: 015 | loss: 0.56315 - acc: 0.7291 -- iter: 544/986
[A[ATraining Step: 452  | total loss: [1m[32m0.55615[0m[0m | time: 20.763s
[2K
| RMSProp | epoch: 015 | loss: 0.55615 - acc: 0.7374 -- iter: 576/986
[A[ATraining Step: 453  | total loss: [1m[32m0.55300[0m[0m | time: 21.726s
[2K
| RMSProp | epoch: 015 | loss: 0.55300 - acc: 0.7418 -- iter: 608/986
[A[ATraining Step: 454  | total loss: [1m[32m0.54372[0m[0m | time: 22.862s
[2K
| RMSProp | epoch: 015 | loss: 0.54372 - acc: 0.7489 -- iter: 640/986
[A[ATraining Step: 455  | total loss: [1m[32m0.55266[0m[0m | time: 24.030s
[2K
| RMSProp | epoch: 015 | loss: 0.55266 - acc: 0.7365 -- iter: 672/986
[A[ATraining Step: 456  | total loss: [1m[32m0.54253[0m[0m | time: 25.073s
[2K
| RMSProp | epoch: 015 | loss: 0.54253 - acc: 0.7441 -- iter: 704/986
[A[ATraining Step: 457  | total loss: [1m[32m0.54445[0m[0m | time: 25.929s
[2K
| RMSProp | epoch: 015 | loss: 0.54445 - acc: 0.7384 -- iter: 736/986
[A[ATraining Step: 458  | total loss: [1m[32m0.55821[0m[0m | time: 26.966s
[2K
| RMSProp | epoch: 015 | loss: 0.55821 - acc: 0.7333 -- iter: 768/986
[A[ATraining Step: 459  | total loss: [1m[32m0.56245[0m[0m | time: 27.975s
[2K
| RMSProp | epoch: 015 | loss: 0.56245 - acc: 0.7194 -- iter: 800/986
[A[ATraining Step: 460  | total loss: [1m[32m0.55687[0m[0m | time: 29.341s
[2K
| RMSProp | epoch: 015 | loss: 0.55687 - acc: 0.7287 -- iter: 832/986
[A[ATraining Step: 461  | total loss: [1m[32m0.56108[0m[0m | time: 30.223s
[2K
| RMSProp | epoch: 015 | loss: 0.56108 - acc: 0.7215 -- iter: 864/986
[A[ATraining Step: 462  | total loss: [1m[32m0.55526[0m[0m | time: 31.277s
[2K
| RMSProp | epoch: 015 | loss: 0.55526 - acc: 0.7368 -- iter: 896/986
[A[ATraining Step: 463  | total loss: [1m[32m0.54457[0m[0m | time: 32.310s
[2K
| RMSProp | epoch: 015 | loss: 0.54457 - acc: 0.7444 -- iter: 928/986
[A[ATraining Step: 464  | total loss: [1m[32m0.53843[0m[0m | time: 33.398s
[2K
| RMSProp | epoch: 015 | loss: 0.53843 - acc: 0.7449 -- iter: 960/986
[A[ATraining Step: 465  | total loss: [1m[32m0.55344[0m[0m | time: 36.036s
[2K
| RMSProp | epoch: 015 | loss: 0.55344 - acc: 0.7329 | val_loss: 0.64380 - val_acc: 0.6246 -- iter: 986/986
--
Training Step: 466  | total loss: [1m[32m0.54953[0m[0m | time: 1.157s
[2K
| RMSProp | epoch: 016 | loss: 0.54953 - acc: 0.7409 -- iter: 032/986
[A[ATraining Step: 467  | total loss: [1m[32m0.54374[0m[0m | time: 2.348s
[2K
| RMSProp | epoch: 016 | loss: 0.54374 - acc: 0.7324 -- iter: 064/986
[A[ATraining Step: 468  | total loss: [1m[32m0.53668[0m[0m | time: 3.589s
[2K
| RMSProp | epoch: 016 | loss: 0.53668 - acc: 0.7467 -- iter: 096/986
[A[ATraining Step: 469  | total loss: [1m[32m0.54024[0m[0m | time: 4.758s
[2K
| RMSProp | epoch: 016 | loss: 0.54024 - acc: 0.7439 -- iter: 128/986
[A[ATraining Step: 470  | total loss: [1m[32m0.53602[0m[0m | time: 6.006s
[2K
| RMSProp | epoch: 016 | loss: 0.53602 - acc: 0.7476 -- iter: 160/986
[A[ATraining Step: 471  | total loss: [1m[32m0.52339[0m[0m | time: 7.128s
[2K
| RMSProp | epoch: 016 | loss: 0.52339 - acc: 0.7572 -- iter: 192/986
[A[ATraining Step: 472  | total loss: [1m[32m0.50502[0m[0m | time: 8.332s
[2K
| RMSProp | epoch: 016 | loss: 0.50502 - acc: 0.7690 -- iter: 224/986
[A[ATraining Step: 473  | total loss: [1m[32m0.51452[0m[0m | time: 9.394s
[2K
| RMSProp | epoch: 016 | loss: 0.51452 - acc: 0.7577 -- iter: 256/986
[A[ATraining Step: 474  | total loss: [1m[32m0.52972[0m[0m | time: 10.502s
[2K
| RMSProp | epoch: 016 | loss: 0.52972 - acc: 0.7538 -- iter: 288/986
[A[ATraining Step: 475  | total loss: [1m[32m0.53200[0m[0m | time: 11.629s
[2K
| RMSProp | epoch: 016 | loss: 0.53200 - acc: 0.7566 -- iter: 320/986
[A[ATraining Step: 476  | total loss: [1m[32m0.51783[0m[0m | time: 12.805s
[2K
| RMSProp | epoch: 016 | loss: 0.51783 - acc: 0.7653 -- iter: 352/986
[A[ATraining Step: 477  | total loss: [1m[32m0.51475[0m[0m | time: 13.909s
[2K
| RMSProp | epoch: 016 | loss: 0.51475 - acc: 0.7669 -- iter: 384/986
[A[ATraining Step: 478  | total loss: [1m[32m0.50835[0m[0m | time: 15.215s
[2K
| RMSProp | epoch: 016 | loss: 0.50835 - acc: 0.7715 -- iter: 416/986
[A[ATraining Step: 479  | total loss: [1m[32m0.51878[0m[0m | time: 16.324s
[2K
| RMSProp | epoch: 016 | loss: 0.51878 - acc: 0.7662 -- iter: 448/986
[A[ATraining Step: 480  | total loss: [1m[32m0.52129[0m[0m | time: 17.588s
[2K
| RMSProp | epoch: 016 | loss: 0.52129 - acc: 0.7626 -- iter: 480/986
[A[ATraining Step: 481  | total loss: [1m[32m0.50946[0m[0m | time: 19.087s
[2K
| RMSProp | epoch: 016 | loss: 0.50946 - acc: 0.7710 -- iter: 512/986
[A[ATraining Step: 482  | total loss: [1m[32m0.49357[0m[0m | time: 20.560s
[2K
| RMSProp | epoch: 016 | loss: 0.49357 - acc: 0.7845 -- iter: 544/986
[A[ATraining Step: 483  | total loss: [1m[32m0.48005[0m[0m | time: 21.925s
[2K
| RMSProp | epoch: 016 | loss: 0.48005 - acc: 0.7904 -- iter: 576/986
[A[ATraining Step: 484  | total loss: [1m[32m0.49208[0m[0m | time: 23.077s
[2K
| RMSProp | epoch: 016 | loss: 0.49208 - acc: 0.7864 -- iter: 608/986
[A[ATraining Step: 485  | total loss: [1m[32m0.49572[0m[0m | time: 24.233s
[2K
| RMSProp | epoch: 016 | loss: 0.49572 - acc: 0.7796 -- iter: 640/986
[A[ATraining Step: 486  | total loss: [1m[32m0.49538[0m[0m | time: 25.426s
[2K
| RMSProp | epoch: 016 | loss: 0.49538 - acc: 0.7704 -- iter: 672/986
[A[ATraining Step: 487  | total loss: [1m[32m0.50541[0m[0m | time: 26.642s
[2K
| RMSProp | epoch: 016 | loss: 0.50541 - acc: 0.7559 -- iter: 704/986
[A[ATraining Step: 488  | total loss: [1m[32m0.49725[0m[0m | time: 28.054s
[2K
| RMSProp | epoch: 016 | loss: 0.49725 - acc: 0.7615 -- iter: 736/986
[A[ATraining Step: 489  | total loss: [1m[32m0.49483[0m[0m | time: 29.214s
[2K
| RMSProp | epoch: 016 | loss: 0.49483 - acc: 0.7573 -- iter: 768/986
[A[ATraining Step: 490  | total loss: [1m[32m0.48780[0m[0m | time: 30.494s
[2K
| RMSProp | epoch: 016 | loss: 0.48780 - acc: 0.7628 -- iter: 800/986
[A[ATraining Step: 491  | total loss: [1m[32m0.49681[0m[0m | time: 31.769s
[2K
| RMSProp | epoch: 016 | loss: 0.49681 - acc: 0.7615 -- iter: 832/986
[A[ATraining Step: 492  | total loss: [1m[32m0.48578[0m[0m | time: 32.948s
[2K
| RMSProp | epoch: 016 | loss: 0.48578 - acc: 0.7729 -- iter: 864/986
[A[ATraining Step: 493  | total loss: [1m[32m0.48149[0m[0m | time: 34.105s
[2K
| RMSProp | epoch: 016 | loss: 0.48149 - acc: 0.7799 -- iter: 896/986
[A[ATraining Step: 494  | total loss: [1m[32m0.49625[0m[0m | time: 35.097s
[2K
| RMSProp | epoch: 016 | loss: 0.49625 - acc: 0.7676 -- iter: 928/986
[A[ATraining Step: 495  | total loss: [1m[32m0.51125[0m[0m | time: 36.293s
[2K
| RMSProp | epoch: 016 | loss: 0.51125 - acc: 0.7533 -- iter: 960/986
[A[ATraining Step: 496  | total loss: [1m[32m0.51715[0m[0m | time: 39.249s
[2K
| RMSProp | epoch: 016 | loss: 0.51715 - acc: 0.7499 | val_loss: 0.53494 - val_acc: 0.7670 -- iter: 986/986
--
Training Step: 497  | total loss: [1m[32m0.53150[0m[0m | time: 1.331s
[2K
| RMSProp | epoch: 017 | loss: 0.53150 - acc: 0.7405 -- iter: 032/986
[A[ATraining Step: 498  | total loss: [1m[32m0.51768[0m[0m | time: 2.508s
[2K
| RMSProp | epoch: 017 | loss: 0.51768 - acc: 0.7633 -- iter: 064/986
[A[ATraining Step: 499  | total loss: [1m[32m0.51350[0m[0m | time: 3.598s
[2K
| RMSProp | epoch: 017 | loss: 0.51350 - acc: 0.7620 -- iter: 096/986
[A[ATraining Step: 500  | total loss: [1m[32m0.50477[0m[0m | time: 4.641s
[2K
| RMSProp | epoch: 017 | loss: 0.50477 - acc: 0.7639 -- iter: 128/986
[A[ATraining Step: 501  | total loss: [1m[32m0.50057[0m[0m | time: 5.816s
[2K
| RMSProp | epoch: 017 | loss: 0.50057 - acc: 0.7719 -- iter: 160/986
[A[ATraining Step: 502  | total loss: [1m[32m0.50508[0m[0m | time: 7.090s
[2K
| RMSProp | epoch: 017 | loss: 0.50508 - acc: 0.7697 -- iter: 192/986
[A[ATraining Step: 503  | total loss: [1m[32m0.50628[0m[0m | time: 8.604s
[2K
| RMSProp | epoch: 017 | loss: 0.50628 - acc: 0.7740 -- iter: 224/986
[A[ATraining Step: 504  | total loss: [1m[32m0.50995[0m[0m | time: 10.168s
[2K
| RMSProp | epoch: 017 | loss: 0.50995 - acc: 0.7685 -- iter: 256/986
[A[ATraining Step: 505  | total loss: [1m[32m0.50748[0m[0m | time: 11.939s
[2K
| RMSProp | epoch: 017 | loss: 0.50748 - acc: 0.7729 -- iter: 288/986
[A[ATraining Step: 506  | total loss: [1m[32m0.50577[0m[0m | time: 13.116s
[2K
| RMSProp | epoch: 017 | loss: 0.50577 - acc: 0.7706 -- iter: 320/986
[A[ATraining Step: 507  | total loss: [1m[32m0.50815[0m[0m | time: 14.432s
[2K
| RMSProp | epoch: 017 | loss: 0.50815 - acc: 0.7654 -- iter: 352/986
[A[ATraining Step: 508  | total loss: [1m[32m0.49203[0m[0m | time: 15.862s
[2K
| RMSProp | epoch: 017 | loss: 0.49203 - acc: 0.7732 -- iter: 384/986
[A[ATraining Step: 509  | total loss: [1m[32m0.50827[0m[0m | time: 17.297s
[2K
| RMSProp | epoch: 017 | loss: 0.50827 - acc: 0.7615 -- iter: 416/986
[A[ATraining Step: 510  | total loss: [1m[32m0.53466[0m[0m | time: 18.841s
[2K
| RMSProp | epoch: 017 | loss: 0.53466 - acc: 0.7479 -- iter: 448/986
[A[ATraining Step: 511  | total loss: [1m[32m0.54583[0m[0m | time: 20.070s
[2K
| RMSProp | epoch: 017 | loss: 0.54583 - acc: 0.7387 -- iter: 480/986
[A[ATraining Step: 512  | total loss: [1m[32m0.53455[0m[0m | time: 21.195s
[2K
| RMSProp | epoch: 017 | loss: 0.53455 - acc: 0.7456 -- iter: 512/986
[A[ATraining Step: 513  | total loss: [1m[32m0.51499[0m[0m | time: 22.828s
[2K
| RMSProp | epoch: 017 | loss: 0.51499 - acc: 0.7672 -- iter: 544/986
[A[ATraining Step: 514  | total loss: [1m[32m0.50055[0m[0m | time: 24.326s
[2K
| RMSProp | epoch: 017 | loss: 0.50055 - acc: 0.7842 -- iter: 576/986
[A[ATraining Step: 515  | total loss: [1m[32m0.50230[0m[0m | time: 25.860s
[2K
| RMSProp | epoch: 017 | loss: 0.50230 - acc: 0.7777 -- iter: 608/986
[A[ATraining Step: 516  | total loss: [1m[32m0.52016[0m[0m | time: 27.412s
[2K
| RMSProp | epoch: 017 | loss: 0.52016 - acc: 0.7624 -- iter: 640/986
[A[ATraining Step: 517  | total loss: [1m[32m0.52795[0m[0m | time: 29.039s
[2K
| RMSProp | epoch: 017 | loss: 0.52795 - acc: 0.7518 -- iter: 672/986
[A[ATraining Step: 518  | total loss: [1m[32m0.51038[0m[0m | time: 30.647s
[2K
| RMSProp | epoch: 017 | loss: 0.51038 - acc: 0.7672 -- iter: 704/986
[A[ATraining Step: 519  | total loss: [1m[32m0.50823[0m[0m | time: 32.085s
[2K
| RMSProp | epoch: 017 | loss: 0.50823 - acc: 0.7686 -- iter: 736/986
[A[ATraining Step: 520  | total loss: [1m[32m0.51077[0m[0m | time: 33.425s
[2K
| RMSProp | epoch: 017 | loss: 0.51077 - acc: 0.7668 -- iter: 768/986
[A[ATraining Step: 521  | total loss: [1m[32m0.50519[0m[0m | time: 35.071s
[2K
| RMSProp | epoch: 017 | loss: 0.50519 - acc: 0.7714 -- iter: 800/986
[A[ATraining Step: 522  | total loss: [1m[32m0.52181[0m[0m | time: 36.731s
[2K
| RMSProp | epoch: 017 | loss: 0.52181 - acc: 0.7598 -- iter: 832/986
[A[ATraining Step: 523  | total loss: [1m[32m0.52754[0m[0m | time: 37.993s
[2K
| RMSProp | epoch: 017 | loss: 0.52754 - acc: 0.7557 -- iter: 864/986
[A[ATraining Step: 524  | total loss: [1m[32m0.52182[0m[0m | time: 39.142s
[2K
| RMSProp | epoch: 017 | loss: 0.52182 - acc: 0.7614 -- iter: 896/986
[A[ATraining Step: 525  | total loss: [1m[32m0.52259[0m[0m | time: 40.492s
[2K
| RMSProp | epoch: 017 | loss: 0.52259 - acc: 0.7571 -- iter: 928/986
[A[ATraining Step: 526  | total loss: [1m[32m0.52642[0m[0m | time: 41.984s
[2K
| RMSProp | epoch: 017 | loss: 0.52642 - acc: 0.7533 -- iter: 960/986
[A[ATraining Step: 527  | total loss: [1m[32m0.53535[0m[0m | time: 46.187s
[2K
| RMSProp | epoch: 017 | loss: 0.53535 - acc: 0.7499 | val_loss: 0.50040 - val_acc: 0.7929 -- iter: 986/986
--
Training Step: 528  | total loss: [1m[32m0.53120[0m[0m | time: 1.465s
[2K
| RMSProp | epoch: 018 | loss: 0.53120 - acc: 0.7467 -- iter: 032/986
[A[ATraining Step: 529  | total loss: [1m[32m0.52333[0m[0m | time: 2.833s
[2K
| RMSProp | epoch: 018 | loss: 0.52333 - acc: 0.7533 -- iter: 064/986
[A[ATraining Step: 530  | total loss: [1m[32m0.50958[0m[0m | time: 4.358s
[2K
| RMSProp | epoch: 018 | loss: 0.50958 - acc: 0.7655 -- iter: 096/986
[A[ATraining Step: 531  | total loss: [1m[32m0.50206[0m[0m | time: 5.816s
[2K
| RMSProp | epoch: 018 | loss: 0.50206 - acc: 0.7733 -- iter: 128/986
[A[ATraining Step: 532  | total loss: [1m[32m0.49367[0m[0m | time: 7.055s
[2K
| RMSProp | epoch: 018 | loss: 0.49367 - acc: 0.7772 -- iter: 160/986
[A[ATraining Step: 533  | total loss: [1m[32m0.53162[0m[0m | time: 8.387s
[2K
| RMSProp | epoch: 018 | loss: 0.53162 - acc: 0.7651 -- iter: 192/986
[A[ATraining Step: 534  | total loss: [1m[32m0.53246[0m[0m | time: 9.768s
[2K
| RMSProp | epoch: 018 | loss: 0.53246 - acc: 0.7605 -- iter: 224/986
[A[ATraining Step: 535  | total loss: [1m[32m0.51977[0m[0m | time: 11.146s
[2K
| RMSProp | epoch: 018 | loss: 0.51977 - acc: 0.7657 -- iter: 256/986
[A[ATraining Step: 536  | total loss: [1m[32m0.51502[0m[0m | time: 12.601s
[2K
| RMSProp | epoch: 018 | loss: 0.51502 - acc: 0.7673 -- iter: 288/986
[A[ATraining Step: 537  | total loss: [1m[32m0.52764[0m[0m | time: 14.002s
[2K
| RMSProp | epoch: 018 | loss: 0.52764 - acc: 0.7562 -- iter: 320/986
[A[ATraining Step: 538  | total loss: [1m[32m0.51820[0m[0m | time: 15.608s
[2K
| RMSProp | epoch: 018 | loss: 0.51820 - acc: 0.7618 -- iter: 352/986
[A[ATraining Step: 539  | total loss: [1m[32m0.50725[0m[0m | time: 16.912s
[2K
| RMSProp | epoch: 018 | loss: 0.50725 - acc: 0.7762 -- iter: 384/986
[A[ATraining Step: 540  | total loss: [1m[32m0.49590[0m[0m | time: 18.328s
[2K
| RMSProp | epoch: 018 | loss: 0.49590 - acc: 0.7861 -- iter: 416/986
[A[ATraining Step: 541  | total loss: [1m[32m0.48116[0m[0m | time: 19.893s
[2K
| RMSProp | epoch: 018 | loss: 0.48116 - acc: 0.7950 -- iter: 448/986
[A[ATraining Step: 542  | total loss: [1m[32m0.47020[0m[0m | time: 21.342s
[2K
| RMSProp | epoch: 018 | loss: 0.47020 - acc: 0.7967 -- iter: 480/986
[A[ATraining Step: 543  | total loss: [1m[32m0.45461[0m[0m | time: 22.544s
[2K
| RMSProp | epoch: 018 | loss: 0.45461 - acc: 0.8077 -- iter: 512/986
[A[ATraining Step: 544  | total loss: [1m[32m0.48016[0m[0m | time: 23.665s
[2K
| RMSProp | epoch: 018 | loss: 0.48016 - acc: 0.7962 -- iter: 544/986
[A[ATraining Step: 545  | total loss: [1m[32m0.47539[0m[0m | time: 24.924s
[2K
| RMSProp | epoch: 018 | loss: 0.47539 - acc: 0.7973 -- iter: 576/986
[A[ATraining Step: 546  | total loss: [1m[32m0.47161[0m[0m | time: 25.948s
[2K
| RMSProp | epoch: 018 | loss: 0.47161 - acc: 0.7957 -- iter: 608/986
[A[ATraining Step: 547  | total loss: [1m[32m0.52203[0m[0m | time: 27.027s
[2K
| RMSProp | epoch: 018 | loss: 0.52203 - acc: 0.7661 -- iter: 640/986
[A[ATraining Step: 548  | total loss: [1m[32m0.51841[0m[0m | time: 28.092s
[2K
| RMSProp | epoch: 018 | loss: 0.51841 - acc: 0.7708 -- iter: 672/986
[A[ATraining Step: 549  | total loss: [1m[32m0.51165[0m[0m | time: 29.117s
[2K
| RMSProp | epoch: 018 | loss: 0.51165 - acc: 0.7687 -- iter: 704/986
[A[ATraining Step: 550  | total loss: [1m[32m0.50693[0m[0m | time: 30.208s
[2K
| RMSProp | epoch: 018 | loss: 0.50693 - acc: 0.7637 -- iter: 736/986
[A[ATraining Step: 551  | total loss: [1m[32m0.48884[0m[0m | time: 31.230s
[2K
| RMSProp | epoch: 018 | loss: 0.48884 - acc: 0.7811 -- iter: 768/986
[A[ATraining Step: 552  | total loss: [1m[32m0.48885[0m[0m | time: 32.245s
[2K
| RMSProp | epoch: 018 | loss: 0.48885 - acc: 0.7842 -- iter: 800/986
[A[ATraining Step: 553  | total loss: [1m[32m0.47148[0m[0m | time: 33.247s
[2K
| RMSProp | epoch: 018 | loss: 0.47148 - acc: 0.7933 -- iter: 832/986
[A[ATraining Step: 554  | total loss: [1m[32m0.45762[0m[0m | time: 34.582s
[2K
| RMSProp | epoch: 018 | loss: 0.45762 - acc: 0.8015 -- iter: 864/986
[A[ATraining Step: 555  | total loss: [1m[32m0.47606[0m[0m | time: 35.631s
[2K
| RMSProp | epoch: 018 | loss: 0.47606 - acc: 0.7901 -- iter: 896/986
[A[ATraining Step: 556  | total loss: [1m[32m0.49894[0m[0m | time: 36.749s
[2K
| RMSProp | epoch: 018 | loss: 0.49894 - acc: 0.7767 -- iter: 928/986
[A[ATraining Step: 557  | total loss: [1m[32m0.49781[0m[0m | time: 37.675s
[2K
| RMSProp | epoch: 018 | loss: 0.49781 - acc: 0.7771 -- iter: 960/986
[A[ATraining Step: 558  | total loss: [1m[32m0.47855[0m[0m | time: 40.319s
[2K
| RMSProp | epoch: 018 | loss: 0.47855 - acc: 0.7901 | val_loss: 0.50048 - val_acc: 0.7864 -- iter: 986/986
--
Training Step: 559  | total loss: [1m[32m0.48533[0m[0m | time: 1.198s
[2K
| RMSProp | epoch: 019 | loss: 0.48533 - acc: 0.7829 -- iter: 032/986
[A[ATraining Step: 560  | total loss: [1m[32m0.46835[0m[0m | time: 2.284s
[2K
| RMSProp | epoch: 019 | loss: 0.46835 - acc: 0.7953 -- iter: 064/986
[A[ATraining Step: 561  | total loss: [1m[32m0.46648[0m[0m | time: 3.334s
[2K
| RMSProp | epoch: 019 | loss: 0.46648 - acc: 0.7876 -- iter: 096/986
[A[ATraining Step: 562  | total loss: [1m[32m0.49199[0m[0m | time: 4.420s
[2K
| RMSProp | epoch: 019 | loss: 0.49199 - acc: 0.7713 -- iter: 128/986
[A[ATraining Step: 563  | total loss: [1m[32m0.48283[0m[0m | time: 5.545s
[2K
| RMSProp | epoch: 019 | loss: 0.48283 - acc: 0.7755 -- iter: 160/986
[A[ATraining Step: 564  | total loss: [1m[32m0.46957[0m[0m | time: 6.772s
[2K
| RMSProp | epoch: 019 | loss: 0.46957 - acc: 0.7885 -- iter: 192/986
[A[ATraining Step: 565  | total loss: [1m[32m0.45876[0m[0m | time: 8.070s
[2K
| RMSProp | epoch: 019 | loss: 0.45876 - acc: 0.8003 -- iter: 224/986
[A[ATraining Step: 566  | total loss: [1m[32m0.47276[0m[0m | time: 9.474s
[2K
| RMSProp | epoch: 019 | loss: 0.47276 - acc: 0.7953 -- iter: 256/986
[A[ATraining Step: 567  | total loss: [1m[32m0.47603[0m[0m | time: 10.988s
[2K
| RMSProp | epoch: 019 | loss: 0.47603 - acc: 0.7939 -- iter: 288/986
[A[ATraining Step: 568  | total loss: [1m[32m0.47947[0m[0m | time: 12.677s
[2K
| RMSProp | epoch: 019 | loss: 0.47947 - acc: 0.7895 -- iter: 320/986
[A[ATraining Step: 569  | total loss: [1m[32m0.48367[0m[0m | time: 14.258s
[2K
| RMSProp | epoch: 019 | loss: 0.48367 - acc: 0.7824 -- iter: 352/986
[A[ATraining Step: 570  | total loss: [1m[32m0.47471[0m[0m | time: 15.510s
[2K
| RMSProp | epoch: 019 | loss: 0.47471 - acc: 0.7854 -- iter: 384/986
[A[ATraining Step: 571  | total loss: [1m[32m0.46561[0m[0m | time: 16.836s
[2K
| RMSProp | epoch: 019 | loss: 0.46561 - acc: 0.7913 -- iter: 416/986
[A[ATraining Step: 572  | total loss: [1m[32m0.45962[0m[0m | time: 18.546s
[2K
| RMSProp | epoch: 019 | loss: 0.45962 - acc: 0.7996 -- iter: 448/986
[A[ATraining Step: 573  | total loss: [1m[32m0.44877[0m[0m | time: 20.025s
[2K
| RMSProp | epoch: 019 | loss: 0.44877 - acc: 0.8009 -- iter: 480/986
[A[ATraining Step: 574  | total loss: [1m[32m0.47249[0m[0m | time: 21.583s
[2K
| RMSProp | epoch: 019 | loss: 0.47249 - acc: 0.7927 -- iter: 512/986
[A[ATraining Step: 575  | total loss: [1m[32m0.47477[0m[0m | time: 22.856s
[2K
| RMSProp | epoch: 019 | loss: 0.47477 - acc: 0.7884 -- iter: 544/986
[A[ATraining Step: 576  | total loss: [1m[32m0.52074[0m[0m | time: 24.056s
[2K
| RMSProp | epoch: 019 | loss: 0.52074 - acc: 0.7634 -- iter: 576/986
[A[ATraining Step: 577  | total loss: [1m[32m0.51989[0m[0m | time: 25.619s
[2K
| RMSProp | epoch: 019 | loss: 0.51989 - acc: 0.7717 -- iter: 608/986
[A[ATraining Step: 578  | total loss: [1m[32m0.51192[0m[0m | time: 27.022s
[2K
| RMSProp | epoch: 019 | loss: 0.51192 - acc: 0.7789 -- iter: 640/986
[A[ATraining Step: 579  | total loss: [1m[32m0.49965[0m[0m | time: 28.404s
[2K
| RMSProp | epoch: 019 | loss: 0.49965 - acc: 0.7854 -- iter: 672/986
[A[ATraining Step: 580  | total loss: [1m[32m0.49466[0m[0m | time: 29.966s
[2K
| RMSProp | epoch: 019 | loss: 0.49466 - acc: 0.7912 -- iter: 704/986
[A[ATraining Step: 581  | total loss: [1m[32m0.52814[0m[0m | time: 31.627s
[2K
| RMSProp | epoch: 019 | loss: 0.52814 - acc: 0.7715 -- iter: 736/986
[A[ATraining Step: 582  | total loss: [1m[32m0.52384[0m[0m | time: 32.912s
[2K
| RMSProp | epoch: 019 | loss: 0.52384 - acc: 0.7756 -- iter: 768/986
[A[ATraining Step: 583  | total loss: [1m[32m0.50876[0m[0m | time: 34.176s
[2K
| RMSProp | epoch: 019 | loss: 0.50876 - acc: 0.7824 -- iter: 800/986
[A[ATraining Step: 584  | total loss: [1m[32m0.50595[0m[0m | time: 35.636s
[2K
| RMSProp | epoch: 019 | loss: 0.50595 - acc: 0.7792 -- iter: 832/986
[A[ATraining Step: 585  | total loss: [1m[32m0.49857[0m[0m | time: 36.994s
[2K
| RMSProp | epoch: 019 | loss: 0.49857 - acc: 0.7825 -- iter: 864/986
[A[ATraining Step: 586  | total loss: [1m[32m0.48391[0m[0m | time: 38.398s
[2K
| RMSProp | epoch: 019 | loss: 0.48391 - acc: 0.7917 -- iter: 896/986
[A[ATraining Step: 587  | total loss: [1m[32m0.47342[0m[0m | time: 39.864s
[2K
| RMSProp | epoch: 019 | loss: 0.47342 - acc: 0.8001 -- iter: 928/986
[A[ATraining Step: 588  | total loss: [1m[32m0.48456[0m[0m | time: 41.404s
[2K
| RMSProp | epoch: 019 | loss: 0.48456 - acc: 0.7919 -- iter: 960/986
[A[ATraining Step: 589  | total loss: [1m[32m0.50100[0m[0m | time: 45.279s
[2K
| RMSProp | epoch: 019 | loss: 0.50100 - acc: 0.7784 | val_loss: 0.54355 - val_acc: 0.7702 -- iter: 986/986
--
Training Step: 590  | total loss: [1m[32m0.48051[0m[0m | time: 1.552s
[2K
| RMSProp | epoch: 020 | loss: 0.48051 - acc: 0.7943 -- iter: 032/986
[A[ATraining Step: 591  | total loss: [1m[32m0.46473[0m[0m | time: 3.281s
[2K
| RMSProp | epoch: 020 | loss: 0.46473 - acc: 0.8055 -- iter: 064/986
[A[ATraining Step: 592  | total loss: [1m[32m0.46027[0m[0m | time: 4.534s
[2K
| RMSProp | epoch: 020 | loss: 0.46027 - acc: 0.8093 -- iter: 096/986
[A[ATraining Step: 593  | total loss: [1m[32m0.46094[0m[0m | time: 5.981s
[2K
| RMSProp | epoch: 020 | loss: 0.46094 - acc: 0.8128 -- iter: 128/986
[A[ATraining Step: 594  | total loss: [1m[32m0.46275[0m[0m | time: 7.417s
[2K
| RMSProp | epoch: 020 | loss: 0.46275 - acc: 0.8065 -- iter: 160/986
[A[ATraining Step: 595  | total loss: [1m[32m0.44640[0m[0m | time: 9.017s
[2K
| RMSProp | epoch: 020 | loss: 0.44640 - acc: 0.8133 -- iter: 192/986
[A[ATraining Step: 596  | total loss: [1m[32m0.43180[0m[0m | time: 10.591s
[2K
| RMSProp | epoch: 020 | loss: 0.43180 - acc: 0.8195 -- iter: 224/986
[A[ATraining Step: 597  | total loss: [1m[32m0.42398[0m[0m | time: 12.163s
[2K
| RMSProp | epoch: 020 | loss: 0.42398 - acc: 0.8250 -- iter: 256/986
[A[ATraining Step: 598  | total loss: [1m[32m0.42824[0m[0m | time: 13.667s
[2K
| RMSProp | epoch: 020 | loss: 0.42824 - acc: 0.8175 -- iter: 288/986
[A[ATraining Step: 599  | total loss: [1m[32m0.44371[0m[0m | time: 15.111s
[2K
| RMSProp | epoch: 020 | loss: 0.44371 - acc: 0.8045 -- iter: 320/986
[A[ATraining Step: 600  | total loss: [1m[32m0.43471[0m[0m | time: 19.482s
[2K
| RMSProp | epoch: 020 | loss: 0.43471 - acc: 0.8116 | val_loss: 0.48848 - val_acc: 0.7961 -- iter: 352/986
--
Training Step: 601  | total loss: [1m[32m0.43424[0m[0m | time: 21.245s
[2K
| RMSProp | epoch: 020 | loss: 0.43424 - acc: 0.8148 -- iter: 384/986
[A[ATraining Step: 602  | total loss: [1m[32m0.41902[0m[0m | time: 22.546s
[2K
| RMSProp | epoch: 020 | loss: 0.41902 - acc: 0.8239 -- iter: 416/986
[A[ATraining Step: 603  | total loss: [1m[32m0.41968[0m[0m | time: 23.951s
[2K
| RMSProp | epoch: 020 | loss: 0.41968 - acc: 0.8259 -- iter: 448/986
[A[ATraining Step: 604  | total loss: [1m[32m0.43664[0m[0m | time: 25.459s
[2K
| RMSProp | epoch: 020 | loss: 0.43664 - acc: 0.8183 -- iter: 480/986
[A[ATraining Step: 605  | total loss: [1m[32m0.45255[0m[0m | time: 26.965s
[2K
| RMSProp | epoch: 020 | loss: 0.45255 - acc: 0.7990 -- iter: 512/986
[A[ATraining Step: 606  | total loss: [1m[32m0.45108[0m[0m | time: 28.364s
[2K
| RMSProp | epoch: 020 | loss: 0.45108 - acc: 0.8003 -- iter: 544/986
[A[ATraining Step: 607  | total loss: [1m[32m0.44521[0m[0m | time: 29.572s
[2K
| RMSProp | epoch: 020 | loss: 0.44521 - acc: 0.8078 -- iter: 576/986
[A[ATraining Step: 608  | total loss: [1m[32m0.46048[0m[0m | time: 30.808s
[2K
| RMSProp | epoch: 020 | loss: 0.46048 - acc: 0.7963 -- iter: 608/986
[A[ATraining Step: 609  | total loss: [1m[32m0.44884[0m[0m | time: 32.371s
[2K
| RMSProp | epoch: 020 | loss: 0.44884 - acc: 0.8089 -- iter: 640/986
[A[ATraining Step: 610  | total loss: [1m[32m0.45620[0m[0m | time: 33.954s
[2K
| RMSProp | epoch: 020 | loss: 0.45620 - acc: 0.8124 -- iter: 672/986
[A[ATraining Step: 611  | total loss: [1m[32m0.43842[0m[0m | time: 35.438s
[2K
| RMSProp | epoch: 020 | loss: 0.43842 - acc: 0.8249 -- iter: 704/986
[A[ATraining Step: 612  | total loss: [1m[32m0.42601[0m[0m | time: 36.762s
[2K
| RMSProp | epoch: 020 | loss: 0.42601 - acc: 0.8299 -- iter: 736/986
[A[ATraining Step: 613  | total loss: [1m[32m0.41112[0m[0m | time: 38.189s
[2K
| RMSProp | epoch: 020 | loss: 0.41112 - acc: 0.8407 -- iter: 768/986
[A[ATraining Step: 614  | total loss: [1m[32m0.42693[0m[0m | time: 39.749s
[2K
| RMSProp | epoch: 020 | loss: 0.42693 - acc: 0.8348 -- iter: 800/986
[A[ATraining Step: 615  | total loss: [1m[32m0.43158[0m[0m | time: 41.389s
[2K
| RMSProp | epoch: 020 | loss: 0.43158 - acc: 0.8294 -- iter: 832/986
[A[ATraining Step: 616  | total loss: [1m[32m0.44452[0m[0m | time: 42.855s
[2K
| RMSProp | epoch: 020 | loss: 0.44452 - acc: 0.8215 -- iter: 864/986
[A[ATraining Step: 617  | total loss: [1m[32m0.44025[0m[0m | time: 44.497s
[2K
| RMSProp | epoch: 020 | loss: 0.44025 - acc: 0.8237 -- iter: 896/986
[A[ATraining Step: 618  | total loss: [1m[32m0.42533[0m[0m | time: 46.289s
[2K
| RMSProp | epoch: 020 | loss: 0.42533 - acc: 0.8288 -- iter: 928/986
[A[ATraining Step: 619  | total loss: [1m[32m0.40998[0m[0m | time: 47.568s
[2K
| RMSProp | epoch: 020 | loss: 0.40998 - acc: 0.8397 -- iter: 960/986
[A[ATraining Step: 620  | total loss: [1m[32m0.42735[0m[0m | time: 51.869s
[2K
| RMSProp | epoch: 020 | loss: 0.42735 - acc: 0.8307 | val_loss: 0.56483 - val_acc: 0.7152 -- iter: 986/986
--
Training Step: 621  | total loss: [1m[32m0.42755[0m[0m | time: 1.461s
[2K
| RMSProp | epoch: 021 | loss: 0.42755 - acc: 0.8289 -- iter: 032/986
[A[ATraining Step: 622  | total loss: [1m[32m0.41649[0m[0m | time: 2.936s
[2K
| RMSProp | epoch: 021 | loss: 0.41649 - acc: 0.8335 -- iter: 064/986
[A[ATraining Step: 623  | total loss: [1m[32m0.42812[0m[0m | time: 4.394s
[2K
| RMSProp | epoch: 021 | loss: 0.42812 - acc: 0.8314 -- iter: 096/986
[A[ATraining Step: 624  | total loss: [1m[32m0.42436[0m[0m | time: 5.865s
[2K
| RMSProp | epoch: 021 | loss: 0.42436 - acc: 0.8358 -- iter: 128/986
[A[ATraining Step: 625  | total loss: [1m[32m0.40895[0m[0m | time: 7.532s
[2K
| RMSProp | epoch: 021 | loss: 0.40895 - acc: 0.8428 -- iter: 160/986
[A[ATraining Step: 626  | total loss: [1m[32m0.40879[0m[0m | time: 8.942s
[2K
| RMSProp | epoch: 021 | loss: 0.40879 - acc: 0.8398 -- iter: 192/986
[A[ATraining Step: 627  | total loss: [1m[32m0.41216[0m[0m | time: 10.341s
[2K
| RMSProp | epoch: 021 | loss: 0.41216 - acc: 0.8277 -- iter: 224/986
[A[ATraining Step: 628  | total loss: [1m[32m0.41964[0m[0m | time: 11.996s
[2K
| RMSProp | epoch: 021 | loss: 0.41964 - acc: 0.8262 -- iter: 256/986
[A[ATraining Step: 629  | total loss: [1m[32m0.42475[0m[0m | time: 13.330s
[2K
| RMSProp | epoch: 021 | loss: 0.42475 - acc: 0.8217 -- iter: 288/986
[A[ATraining Step: 630  | total loss: [1m[32m0.40794[0m[0m | time: 14.781s
[2K
| RMSProp | epoch: 021 | loss: 0.40794 - acc: 0.8333 -- iter: 320/986
[A[ATraining Step: 631  | total loss: [1m[32m0.39184[0m[0m | time: 16.184s
[2K
| RMSProp | epoch: 021 | loss: 0.39184 - acc: 0.8437 -- iter: 352/986
[A[ATraining Step: 632  | total loss: [1m[32m0.37951[0m[0m | time: 17.532s
[2K
| RMSProp | epoch: 021 | loss: 0.37951 - acc: 0.8531 -- iter: 384/986
[A[ATraining Step: 633  | total loss: [1m[32m0.36402[0m[0m | time: 18.588s
[2K
| RMSProp | epoch: 021 | loss: 0.36402 - acc: 0.8584 -- iter: 416/986
[A[ATraining Step: 634  | total loss: [1m[32m0.38654[0m[0m | time: 19.686s
[2K
| RMSProp | epoch: 021 | loss: 0.38654 - acc: 0.8475 -- iter: 448/986
[A[ATraining Step: 635  | total loss: [1m[32m0.40188[0m[0m | time: 20.732s
[2K
| RMSProp | epoch: 021 | loss: 0.40188 - acc: 0.8409 -- iter: 480/986
[A[ATraining Step: 636  | total loss: [1m[32m0.40807[0m[0m | time: 21.796s
[2K
| RMSProp | epoch: 021 | loss: 0.40807 - acc: 0.8318 -- iter: 512/986
[A[ATraining Step: 637  | total loss: [1m[32m0.40156[0m[0m | time: 22.731s
[2K
| RMSProp | epoch: 021 | loss: 0.40156 - acc: 0.8393 -- iter: 544/986
[A[ATraining Step: 638  | total loss: [1m[32m0.43148[0m[0m | time: 23.742s
[2K
| RMSProp | epoch: 021 | loss: 0.43148 - acc: 0.8210 -- iter: 576/986
[A[ATraining Step: 639  | total loss: [1m[32m0.44974[0m[0m | time: 24.482s
[2K
| RMSProp | epoch: 021 | loss: 0.44974 - acc: 0.8107 -- iter: 608/986
[A[ATraining Step: 640  | total loss: [1m[32m0.44128[0m[0m | time: 25.308s
[2K
| RMSProp | epoch: 021 | loss: 0.44128 - acc: 0.8143 -- iter: 640/986
[A[ATraining Step: 641  | total loss: [1m[32m0.44285[0m[0m | time: 26.357s
[2K
| RMSProp | epoch: 021 | loss: 0.44285 - acc: 0.8136 -- iter: 672/986
[A[ATraining Step: 642  | total loss: [1m[32m0.46759[0m[0m | time: 27.321s
[2K
| RMSProp | epoch: 021 | loss: 0.46759 - acc: 0.7948 -- iter: 704/986
[A[ATraining Step: 643  | total loss: [1m[32m0.45683[0m[0m | time: 28.289s
[2K
| RMSProp | epoch: 021 | loss: 0.45683 - acc: 0.7997 -- iter: 736/986
[A[ATraining Step: 644  | total loss: [1m[32m0.44596[0m[0m | time: 29.239s
[2K
| RMSProp | epoch: 021 | loss: 0.44596 - acc: 0.8072 -- iter: 768/986
[A[ATraining Step: 645  | total loss: [1m[32m0.44280[0m[0m | time: 30.198s
[2K
| RMSProp | epoch: 021 | loss: 0.44280 - acc: 0.8108 -- iter: 800/986
[A[ATraining Step: 646  | total loss: [1m[32m0.44484[0m[0m | time: 31.375s
[2K
| RMSProp | epoch: 021 | loss: 0.44484 - acc: 0.8048 -- iter: 832/986
[A[ATraining Step: 647  | total loss: [1m[32m0.42483[0m[0m | time: 32.618s
[2K
| RMSProp | epoch: 021 | loss: 0.42483 - acc: 0.8149 -- iter: 864/986
[A[ATraining Step: 648  | total loss: [1m[32m0.41476[0m[0m | time: 33.855s
[2K
| RMSProp | epoch: 021 | loss: 0.41476 - acc: 0.8209 -- iter: 896/986
[A[ATraining Step: 649  | total loss: [1m[32m0.39147[0m[0m | time: 35.106s
[2K
| RMSProp | epoch: 021 | loss: 0.39147 - acc: 0.8357 -- iter: 928/986
[A[ATraining Step: 650  | total loss: [1m[32m0.37172[0m[0m | time: 36.074s
[2K
| RMSProp | epoch: 021 | loss: 0.37172 - acc: 0.8459 -- iter: 960/986
[A[ATraining Step: 651  | total loss: [1m[32m0.36924[0m[0m | time: 38.419s
[2K
| RMSProp | epoch: 021 | loss: 0.36924 - acc: 0.8488 | val_loss: 0.59394 - val_acc: 0.7735 -- iter: 986/986
--
Training Step: 652  | total loss: [1m[32m0.39063[0m[0m | time: 1.071s
[2K
| RMSProp | epoch: 022 | loss: 0.39063 - acc: 0.8389 -- iter: 032/986
[A[ATraining Step: 653  | total loss: [1m[32m0.41661[0m[0m | time: 2.195s
[2K
| RMSProp | epoch: 022 | loss: 0.41661 - acc: 0.8269 -- iter: 064/986
[A[ATraining Step: 654  | total loss: [1m[32m0.40549[0m[0m | time: 3.310s
[2K
| RMSProp | epoch: 022 | loss: 0.40549 - acc: 0.8380 -- iter: 096/986
[A[ATraining Step: 655  | total loss: [1m[32m0.40394[0m[0m | time: 4.755s
[2K
| RMSProp | epoch: 022 | loss: 0.40394 - acc: 0.8354 -- iter: 128/986
[A[ATraining Step: 656  | total loss: [1m[32m0.40757[0m[0m | time: 6.367s
[2K
| RMSProp | epoch: 022 | loss: 0.40757 - acc: 0.8362 -- iter: 160/986
[A[ATraining Step: 657  | total loss: [1m[32m0.41909[0m[0m | time: 7.997s
[2K
| RMSProp | epoch: 022 | loss: 0.41909 - acc: 0.8245 -- iter: 192/986
[A[ATraining Step: 658  | total loss: [1m[32m0.42420[0m[0m | time: 9.632s
[2K
| RMSProp | epoch: 022 | loss: 0.42420 - acc: 0.8139 -- iter: 224/986
[A[ATraining Step: 659  | total loss: [1m[32m0.41458[0m[0m | time: 12.181s
[2K
| RMSProp | epoch: 022 | loss: 0.41458 - acc: 0.8232 -- iter: 256/986
[A[ATraining Step: 660  | total loss: [1m[32m0.41110[0m[0m | time: 13.510s
[2K
| RMSProp | epoch: 022 | loss: 0.41110 - acc: 0.8252 -- iter: 288/986
[A[ATraining Step: 661  | total loss: [1m[32m0.39445[0m[0m | time: 14.833s
[2K
| RMSProp | epoch: 022 | loss: 0.39445 - acc: 0.8364 -- iter: 320/986
[A[ATraining Step: 662  | total loss: [1m[32m0.39436[0m[0m | time: 16.438s
[2K
| RMSProp | epoch: 022 | loss: 0.39436 - acc: 0.8340 -- iter: 352/986
[A[ATraining Step: 663  | total loss: [1m[32m0.42759[0m[0m | time: 17.970s
[2K
| RMSProp | epoch: 022 | loss: 0.42759 - acc: 0.8225 -- iter: 384/986
[A[ATraining Step: 664  | total loss: [1m[32m0.43380[0m[0m | time: 19.355s
[2K
| RMSProp | epoch: 022 | loss: 0.43380 - acc: 0.8184 -- iter: 416/986
[A[ATraining Step: 665  | total loss: [1m[32m0.42757[0m[0m | time: 21.069s
[2K
| RMSProp | epoch: 022 | loss: 0.42757 - acc: 0.8178 -- iter: 448/986
[A[ATraining Step: 666  | total loss: [1m[32m0.40618[0m[0m | time: 22.616s
[2K
| RMSProp | epoch: 022 | loss: 0.40618 - acc: 0.8329 -- iter: 480/986
[A[ATraining Step: 667  | total loss: [1m[32m0.38235[0m[0m | time: 23.988s
[2K
| RMSProp | epoch: 022 | loss: 0.38235 - acc: 0.8465 -- iter: 512/986
[A[ATraining Step: 668  | total loss: [1m[32m0.38257[0m[0m | time: 25.568s
[2K
| RMSProp | epoch: 022 | loss: 0.38257 - acc: 0.8493 -- iter: 544/986
[A[ATraining Step: 669  | total loss: [1m[32m0.37046[0m[0m | time: 27.052s
[2K
| RMSProp | epoch: 022 | loss: 0.37046 - acc: 0.8613 -- iter: 576/986
[A[ATraining Step: 670  | total loss: [1m[32m0.37496[0m[0m | time: 28.788s
[2K
| RMSProp | epoch: 022 | loss: 0.37496 - acc: 0.8626 -- iter: 608/986
[A[ATraining Step: 671  | total loss: [1m[32m0.38641[0m[0m | time: 29.953s
[2K
| RMSProp | epoch: 022 | loss: 0.38641 - acc: 0.8545 -- iter: 640/986
[A[ATraining Step: 672  | total loss: [1m[32m0.37813[0m[0m | time: 31.091s
[2K
| RMSProp | epoch: 022 | loss: 0.37813 - acc: 0.8537 -- iter: 672/986
[A[ATraining Step: 673  | total loss: [1m[32m0.35068[0m[0m | time: 32.703s
[2K
| RMSProp | epoch: 022 | loss: 0.35068 - acc: 0.8683 -- iter: 704/986
[A[ATraining Step: 674  | total loss: [1m[32m0.35550[0m[0m | time: 34.160s
[2K
| RMSProp | epoch: 022 | loss: 0.35550 - acc: 0.8690 -- iter: 736/986
[A[ATraining Step: 675  | total loss: [1m[32m0.35121[0m[0m | time: 35.560s
[2K
| RMSProp | epoch: 022 | loss: 0.35121 - acc: 0.8696 -- iter: 768/986
[A[ATraining Step: 676  | total loss: [1m[32m0.36256[0m[0m | time: 37.058s
[2K
| RMSProp | epoch: 022 | loss: 0.36256 - acc: 0.8545 -- iter: 800/986
[A[ATraining Step: 677  | total loss: [1m[32m0.36179[0m[0m | time: 38.513s
[2K
| RMSProp | epoch: 022 | loss: 0.36179 - acc: 0.8503 -- iter: 832/986
[A[ATraining Step: 678  | total loss: [1m[32m0.35515[0m[0m | time: 39.919s
[2K
| RMSProp | epoch: 022 | loss: 0.35515 - acc: 0.8528 -- iter: 864/986
[A[ATraining Step: 679  | total loss: [1m[32m0.39119[0m[0m | time: 41.122s
[2K
| RMSProp | epoch: 022 | loss: 0.39119 - acc: 0.8331 -- iter: 896/986
[A[ATraining Step: 680  | total loss: [1m[32m0.38261[0m[0m | time: 42.638s
[2K
| RMSProp | epoch: 022 | loss: 0.38261 - acc: 0.8373 -- iter: 928/986
[A[ATraining Step: 681  | total loss: [1m[32m0.37393[0m[0m | time: 44.248s
[2K
| RMSProp | epoch: 022 | loss: 0.37393 - acc: 0.8442 -- iter: 960/986
[A[ATraining Step: 682  | total loss: [1m[32m0.37375[0m[0m | time: 48.911s
[2K
| RMSProp | epoch: 022 | loss: 0.37375 - acc: 0.8442 | val_loss: 0.57890 - val_acc: 0.7638 -- iter: 986/986
--
Training Step: 683  | total loss: [1m[32m0.35251[0m[0m | time: 1.453s
[2K
| RMSProp | epoch: 023 | loss: 0.35251 - acc: 0.8597 -- iter: 032/986
[A[ATraining Step: 684  | total loss: [1m[32m0.35486[0m[0m | time: 3.114s
[2K
| RMSProp | epoch: 023 | loss: 0.35486 - acc: 0.8613 -- iter: 064/986
[A[ATraining Step: 685  | total loss: [1m[32m0.33918[0m[0m | time: 4.539s
[2K
| RMSProp | epoch: 023 | loss: 0.33918 - acc: 0.8658 -- iter: 096/986
[A[ATraining Step: 686  | total loss: [1m[32m0.33385[0m[0m | time: 6.004s
[2K
| RMSProp | epoch: 023 | loss: 0.33385 - acc: 0.8698 -- iter: 128/986
[A[ATraining Step: 687  | total loss: [1m[32m0.34229[0m[0m | time: 7.526s
[2K
| RMSProp | epoch: 023 | loss: 0.34229 - acc: 0.8610 -- iter: 160/986
[A[ATraining Step: 688  | total loss: [1m[32m0.35150[0m[0m | time: 8.972s
[2K
| RMSProp | epoch: 023 | loss: 0.35150 - acc: 0.8530 -- iter: 192/986
[A[ATraining Step: 689  | total loss: [1m[32m0.35351[0m[0m | time: 10.411s
[2K
| RMSProp | epoch: 023 | loss: 0.35351 - acc: 0.8521 -- iter: 224/986
[A[ATraining Step: 690  | total loss: [1m[32m0.34467[0m[0m | time: 12.101s
[2K
| RMSProp | epoch: 023 | loss: 0.34467 - acc: 0.8606 -- iter: 256/986
[A[ATraining Step: 691  | total loss: [1m[32m0.35030[0m[0m | time: 13.711s
[2K
| RMSProp | epoch: 023 | loss: 0.35030 - acc: 0.8620 -- iter: 288/986
[A[ATraining Step: 692  | total loss: [1m[32m0.34861[0m[0m | time: 15.038s
[2K
| RMSProp | epoch: 023 | loss: 0.34861 - acc: 0.8633 -- iter: 320/986
[A[ATraining Step: 693  | total loss: [1m[32m0.33622[0m[0m | time: 16.476s
[2K
| RMSProp | epoch: 023 | loss: 0.33622 - acc: 0.8708 -- iter: 352/986
[A[ATraining Step: 694  | total loss: [1m[32m0.39196[0m[0m | time: 17.785s
[2K
| RMSProp | epoch: 023 | loss: 0.39196 - acc: 0.8556 -- iter: 384/986
[A[ATraining Step: 695  | total loss: [1m[32m0.38181[0m[0m | time: 19.208s
[2K
| RMSProp | epoch: 023 | loss: 0.38181 - acc: 0.8606 -- iter: 416/986
[A[ATraining Step: 696  | total loss: [1m[32m0.37243[0m[0m | time: 20.679s
[2K
| RMSProp | epoch: 023 | loss: 0.37243 - acc: 0.8621 -- iter: 448/986
[A[ATraining Step: 697  | total loss: [1m[32m0.37546[0m[0m | time: 22.211s
[2K
| RMSProp | epoch: 023 | loss: 0.37546 - acc: 0.8634 -- iter: 480/986
[A[ATraining Step: 698  | total loss: [1m[32m0.40413[0m[0m | time: 23.909s
[2K
| RMSProp | epoch: 023 | loss: 0.40413 - acc: 0.8426 -- iter: 512/986
[A[ATraining Step: 699  | total loss: [1m[32m0.38687[0m[0m | time: 25.205s
[2K
| RMSProp | epoch: 023 | loss: 0.38687 - acc: 0.8521 -- iter: 544/986
[A[ATraining Step: 700  | total loss: [1m[32m0.36841[0m[0m | time: 26.514s
[2K
| RMSProp | epoch: 023 | loss: 0.36841 - acc: 0.8575 -- iter: 576/986
[A[ATraining Step: 701  | total loss: [1m[32m0.37214[0m[0m | time: 27.840s
[2K
| RMSProp | epoch: 023 | loss: 0.37214 - acc: 0.8499 -- iter: 608/986
[A[ATraining Step: 702  | total loss: [1m[32m0.36327[0m[0m | time: 29.259s
[2K
| RMSProp | epoch: 023 | loss: 0.36327 - acc: 0.8524 -- iter: 640/986
[A[ATraining Step: 703  | total loss: [1m[32m0.35361[0m[0m | time: 30.482s
[2K
| RMSProp | epoch: 023 | loss: 0.35361 - acc: 0.8609 -- iter: 672/986
[A[ATraining Step: 704  | total loss: [1m[32m0.40912[0m[0m | time: 31.890s
[2K
| RMSProp | epoch: 023 | loss: 0.40912 - acc: 0.8441 -- iter: 704/986
[A[ATraining Step: 705  | total loss: [1m[32m0.40378[0m[0m | time: 33.423s
[2K
| RMSProp | epoch: 023 | loss: 0.40378 - acc: 0.8481 -- iter: 736/986
[A[ATraining Step: 706  | total loss: [1m[32m0.39449[0m[0m | time: 34.694s
[2K
| RMSProp | epoch: 023 | loss: 0.39449 - acc: 0.8508 -- iter: 768/986
[A[ATraining Step: 707  | total loss: [1m[32m0.37769[0m[0m | time: 36.072s
[2K
| RMSProp | epoch: 023 | loss: 0.37769 - acc: 0.8626 -- iter: 800/986
[A[ATraining Step: 708  | total loss: [1m[32m0.35891[0m[0m | time: 37.535s
[2K
| RMSProp | epoch: 023 | loss: 0.35891 - acc: 0.8763 -- iter: 832/986
[A[ATraining Step: 709  | total loss: [1m[32m0.35248[0m[0m | time: 38.831s
[2K
| RMSProp | epoch: 023 | loss: 0.35248 - acc: 0.8793 -- iter: 864/986
[A[ATraining Step: 710  | total loss: [1m[32m0.37700[0m[0m | time: 40.319s
[2K
| RMSProp | epoch: 023 | loss: 0.37700 - acc: 0.8602 -- iter: 896/986
[A[ATraining Step: 711  | total loss: [1m[32m0.36473[0m[0m | time: 41.821s
[2K
| RMSProp | epoch: 023 | loss: 0.36473 - acc: 0.8679 -- iter: 928/986
[A[ATraining Step: 712  | total loss: [1m[32m0.35066[0m[0m | time: 43.345s
[2K
| RMSProp | epoch: 023 | loss: 0.35066 - acc: 0.8717 -- iter: 960/986
[A[ATraining Step: 713  | total loss: [1m[32m0.33452[0m[0m | time: 46.860s
[2K
| RMSProp | epoch: 023 | loss: 0.33452 - acc: 0.8783 | val_loss: 0.73535 - val_acc: 0.6990 -- iter: 986/986
--
Training Step: 714  | total loss: [1m[32m0.34452[0m[0m | time: 1.674s
[2K
| RMSProp | epoch: 024 | loss: 0.34452 - acc: 0.8686 -- iter: 032/986
[A[ATraining Step: 715  | total loss: [1m[32m0.34511[0m[0m | time: 2.825s
[2K
| RMSProp | epoch: 024 | loss: 0.34511 - acc: 0.8630 -- iter: 064/986
[A[ATraining Step: 716  | total loss: [1m[32m0.36413[0m[0m | time: 4.200s
[2K
| RMSProp | epoch: 024 | loss: 0.36413 - acc: 0.8548 -- iter: 096/986
[A[ATraining Step: 717  | total loss: [1m[32m0.35084[0m[0m | time: 5.642s
[2K
| RMSProp | epoch: 024 | loss: 0.35084 - acc: 0.8631 -- iter: 128/986
[A[ATraining Step: 718  | total loss: [1m[32m0.33496[0m[0m | time: 7.071s
[2K
| RMSProp | epoch: 024 | loss: 0.33496 - acc: 0.8705 -- iter: 160/986
[A[ATraining Step: 719  | total loss: [1m[32m0.32380[0m[0m | time: 8.491s
[2K
| RMSProp | epoch: 024 | loss: 0.32380 - acc: 0.8772 -- iter: 192/986
[A[ATraining Step: 720  | total loss: [1m[32m0.30537[0m[0m | time: 9.970s
[2K
| RMSProp | epoch: 024 | loss: 0.30537 - acc: 0.8832 -- iter: 224/986
[A[ATraining Step: 721  | total loss: [1m[32m0.31177[0m[0m | time: 11.405s
[2K
| RMSProp | epoch: 024 | loss: 0.31177 - acc: 0.8793 -- iter: 256/986
[A[ATraining Step: 722  | total loss: [1m[32m0.33262[0m[0m | time: 12.873s
[2K
| RMSProp | epoch: 024 | loss: 0.33262 - acc: 0.8726 -- iter: 288/986
[A[ATraining Step: 723  | total loss: [1m[32m0.32409[0m[0m | time: 14.222s
[2K
| RMSProp | epoch: 024 | loss: 0.32409 - acc: 0.8791 -- iter: 320/986
[A[ATraining Step: 724  | total loss: [1m[32m0.31040[0m[0m | time: 15.759s
[2K
| RMSProp | epoch: 024 | loss: 0.31040 - acc: 0.8849 -- iter: 352/986
[A[ATraining Step: 725  | total loss: [1m[32m0.30383[0m[0m | time: 17.095s
[2K
| RMSProp | epoch: 024 | loss: 0.30383 - acc: 0.8871 -- iter: 384/986
[A[ATraining Step: 726  | total loss: [1m[32m0.30394[0m[0m | time: 18.434s
[2K
| RMSProp | epoch: 024 | loss: 0.30394 - acc: 0.8890 -- iter: 416/986
[A[ATraining Step: 727  | total loss: [1m[32m0.30901[0m[0m | time: 19.787s
[2K
| RMSProp | epoch: 024 | loss: 0.30901 - acc: 0.8813 -- iter: 448/986
[A[ATraining Step: 728  | total loss: [1m[32m0.31524[0m[0m | time: 20.945s
[2K
| RMSProp | epoch: 024 | loss: 0.31524 - acc: 0.8776 -- iter: 480/986
[A[ATraining Step: 729  | total loss: [1m[32m0.33110[0m[0m | time: 21.933s
[2K
| RMSProp | epoch: 024 | loss: 0.33110 - acc: 0.8711 -- iter: 512/986
[A[ATraining Step: 730  | total loss: [1m[32m0.34178[0m[0m | time: 22.910s
[2K
| RMSProp | epoch: 024 | loss: 0.34178 - acc: 0.8715 -- iter: 544/986
[A[ATraining Step: 731  | total loss: [1m[32m0.33322[0m[0m | time: 23.913s
[2K
| RMSProp | epoch: 024 | loss: 0.33322 - acc: 0.8781 -- iter: 576/986
[A[ATraining Step: 732  | total loss: [1m[32m0.32692[0m[0m | time: 24.916s
[2K
| RMSProp | epoch: 024 | loss: 0.32692 - acc: 0.8809 -- iter: 608/986
[A[ATraining Step: 733  | total loss: [1m[32m0.32464[0m[0m | time: 26.034s
[2K
| RMSProp | epoch: 024 | loss: 0.32464 - acc: 0.8803 -- iter: 640/986
[A[ATraining Step: 734  | total loss: [1m[32m0.31355[0m[0m | time: 27.090s
[2K
| RMSProp | epoch: 024 | loss: 0.31355 - acc: 0.8829 -- iter: 672/986
[A[ATraining Step: 735  | total loss: [1m[32m0.32318[0m[0m | time: 28.056s
[2K
| RMSProp | epoch: 024 | loss: 0.32318 - acc: 0.8790 -- iter: 704/986
[A[ATraining Step: 736  | total loss: [1m[32m0.39551[0m[0m | time: 29.082s
[2K
| RMSProp | epoch: 024 | loss: 0.39551 - acc: 0.8488 -- iter: 736/986
[A[ATraining Step: 737  | total loss: [1m[32m0.37876[0m[0m | time: 30.350s
[2K
| RMSProp | epoch: 024 | loss: 0.37876 - acc: 0.8562 -- iter: 768/986
[A[ATraining Step: 738  | total loss: [1m[32m0.35878[0m[0m | time: 31.278s
[2K
| RMSProp | epoch: 024 | loss: 0.35878 - acc: 0.8675 -- iter: 800/986
[A[ATraining Step: 739  | total loss: [1m[32m0.37009[0m[0m | time: 32.287s
[2K
| RMSProp | epoch: 024 | loss: 0.37009 - acc: 0.8620 -- iter: 832/986
[A[ATraining Step: 740  | total loss: [1m[32m0.38140[0m[0m | time: 33.269s
[2K
| RMSProp | epoch: 024 | loss: 0.38140 - acc: 0.8508 -- iter: 864/986
[A[ATraining Step: 741  | total loss: [1m[32m0.36924[0m[0m | time: 34.247s
[2K
| RMSProp | epoch: 024 | loss: 0.36924 - acc: 0.8563 -- iter: 896/986
[A[ATraining Step: 742  | total loss: [1m[32m0.34756[0m[0m | time: 35.310s
[2K
| RMSProp | epoch: 024 | loss: 0.34756 - acc: 0.8676 -- iter: 928/986
[A[ATraining Step: 743  | total loss: [1m[32m0.34038[0m[0m | time: 36.421s
[2K
| RMSProp | epoch: 024 | loss: 0.34038 - acc: 0.8652 -- iter: 960/986
[A[ATraining Step: 744  | total loss: [1m[32m0.32266[0m[0m | time: 39.465s
[2K
| RMSProp | epoch: 024 | loss: 0.32266 - acc: 0.8724 | val_loss: 0.64963 - val_acc: 0.7282 -- iter: 986/986
--
Training Step: 745  | total loss: [1m[32m0.32542[0m[0m | time: 1.146s
[2K
| RMSProp | epoch: 025 | loss: 0.32542 - acc: 0.8633 -- iter: 032/986
[A[ATraining Step: 746  | total loss: [1m[32m0.33757[0m[0m | time: 2.039s
[2K
| RMSProp | epoch: 025 | loss: 0.33757 - acc: 0.8551 -- iter: 064/986
[A[ATraining Step: 747  | total loss: [1m[32m0.33880[0m[0m | time: 3.095s
[2K
| RMSProp | epoch: 025 | loss: 0.33880 - acc: 0.8540 -- iter: 096/986
[A[ATraining Step: 748  | total loss: [1m[32m0.33791[0m[0m | time: 4.342s
[2K
| RMSProp | epoch: 025 | loss: 0.33791 - acc: 0.8623 -- iter: 128/986
[A[ATraining Step: 749  | total loss: [1m[32m0.33258[0m[0m | time: 5.966s
[2K
| RMSProp | epoch: 025 | loss: 0.33258 - acc: 0.8667 -- iter: 160/986
[A[ATraining Step: 750  | total loss: [1m[32m0.31463[0m[0m | time: 7.578s
[2K
| RMSProp | epoch: 025 | loss: 0.31463 - acc: 0.8800 -- iter: 192/986
[A[ATraining Step: 751  | total loss: [1m[32m0.29691[0m[0m | time: 8.892s
[2K
| RMSProp | epoch: 025 | loss: 0.29691 - acc: 0.8889 -- iter: 224/986
[A[ATraining Step: 752  | total loss: [1m[32m0.27534[0m[0m | time: 10.265s
[2K
| RMSProp | epoch: 025 | loss: 0.27534 - acc: 0.8969 -- iter: 256/986
[A[ATraining Step: 753  | total loss: [1m[32m0.26927[0m[0m | time: 11.732s
[2K
| RMSProp | epoch: 025 | loss: 0.26927 - acc: 0.8978 -- iter: 288/986
[A[ATraining Step: 754  | total loss: [1m[32m0.31436[0m[0m | time: 13.221s
[2K
| RMSProp | epoch: 025 | loss: 0.31436 - acc: 0.8799 -- iter: 320/986
[A[ATraining Step: 755  | total loss: [1m[32m0.33297[0m[0m | time: 14.586s
[2K
| RMSProp | epoch: 025 | loss: 0.33297 - acc: 0.8701 -- iter: 352/986
[A[ATraining Step: 756  | total loss: [1m[32m0.32788[0m[0m | time: 16.036s
[2K
| RMSProp | epoch: 025 | loss: 0.32788 - acc: 0.8737 -- iter: 384/986
[A[ATraining Step: 757  | total loss: [1m[32m0.31374[0m[0m | time: 17.678s
[2K
| RMSProp | epoch: 025 | loss: 0.31374 - acc: 0.8801 -- iter: 416/986
[A[ATraining Step: 758  | total loss: [1m[32m0.30978[0m[0m | time: 19.182s
[2K
| RMSProp | epoch: 025 | loss: 0.30978 - acc: 0.8795 -- iter: 448/986
[A[ATraining Step: 759  | total loss: [1m[32m0.29578[0m[0m | time: 20.501s
[2K
| RMSProp | epoch: 025 | loss: 0.29578 - acc: 0.8853 -- iter: 480/986
[A[ATraining Step: 760  | total loss: [1m[32m0.28630[0m[0m | time: 21.955s
[2K
| RMSProp | epoch: 025 | loss: 0.28630 - acc: 0.8906 -- iter: 512/986
[A[ATraining Step: 761  | total loss: [1m[32m0.26526[0m[0m | time: 23.512s
[2K
| RMSProp | epoch: 025 | loss: 0.26526 - acc: 0.9015 -- iter: 544/986
[A[ATraining Step: 762  | total loss: [1m[32m0.24825[0m[0m | time: 25.134s
[2K
| RMSProp | epoch: 025 | loss: 0.24825 - acc: 0.9082 -- iter: 576/986
[A[ATraining Step: 763  | total loss: [1m[32m0.28946[0m[0m | time: 26.755s
[2K
| RMSProp | epoch: 025 | loss: 0.28946 - acc: 0.8924 -- iter: 608/986
[A[ATraining Step: 764  | total loss: [1m[32m0.32447[0m[0m | time: 28.052s
[2K
| RMSProp | epoch: 025 | loss: 0.32447 - acc: 0.8750 -- iter: 640/986
[A[ATraining Step: 765  | total loss: [1m[32m0.31050[0m[0m | time: 29.464s
[2K
| RMSProp | epoch: 025 | loss: 0.31050 - acc: 0.8813 -- iter: 672/986
[A[ATraining Step: 766  | total loss: [1m[32m0.29287[0m[0m | time: 30.896s
[2K
| RMSProp | epoch: 025 | loss: 0.29287 - acc: 0.8869 -- iter: 704/986
[A[ATraining Step: 767  | total loss: [1m[32m0.27690[0m[0m | time: 32.096s
[2K
| RMSProp | epoch: 025 | loss: 0.27690 - acc: 0.8920 -- iter: 736/986
[A[ATraining Step: 768  | total loss: [1m[32m0.28283[0m[0m | time: 33.307s
[2K
| RMSProp | epoch: 025 | loss: 0.28283 - acc: 0.8912 -- iter: 768/986
[A[ATraining Step: 769  | total loss: [1m[32m0.27670[0m[0m | time: 34.890s
[2K
| RMSProp | epoch: 025 | loss: 0.27670 - acc: 0.8906 -- iter: 800/986
[A[ATraining Step: 770  | total loss: [1m[32m0.28564[0m[0m | time: 36.465s
[2K
| RMSProp | epoch: 025 | loss: 0.28564 - acc: 0.8921 -- iter: 832/986
[A[ATraining Step: 771  | total loss: [1m[32m0.27942[0m[0m | time: 38.000s
[2K
| RMSProp | epoch: 025 | loss: 0.27942 - acc: 0.8935 -- iter: 864/986
[A[ATraining Step: 772  | total loss: [1m[32m0.25927[0m[0m | time: 39.477s
[2K
| RMSProp | epoch: 025 | loss: 0.25927 - acc: 0.9042 -- iter: 896/986
[A[ATraining Step: 773  | total loss: [1m[32m0.25493[0m[0m | time: 41.299s
[2K
| RMSProp | epoch: 025 | loss: 0.25493 - acc: 0.9013 -- iter: 928/986
[A[ATraining Step: 774  | total loss: [1m[32m0.24806[0m[0m | time: 43.019s
[2K
| RMSProp | epoch: 025 | loss: 0.24806 - acc: 0.9049 -- iter: 960/986
[A[ATraining Step: 775  | total loss: [1m[32m0.25743[0m[0m | time: 47.052s
[2K
| RMSProp | epoch: 025 | loss: 0.25743 - acc: 0.9019 | val_loss: 0.56366 - val_acc: 0.8026 -- iter: 986/986
--
Training Step: 776  | total loss: [1m[32m0.25269[0m[0m | time: 1.884s
[2K
| RMSProp | epoch: 026 | loss: 0.25269 - acc: 0.9023 -- iter: 032/986
[A[ATraining Step: 777  | total loss: [1m[32m0.25218[0m[0m | time: 3.301s
[2K
| RMSProp | epoch: 026 | loss: 0.25218 - acc: 0.9027 -- iter: 064/986
[A[ATraining Step: 778  | total loss: [1m[32m0.24605[0m[0m | time: 4.454s
[2K
| RMSProp | epoch: 026 | loss: 0.24605 - acc: 0.9093 -- iter: 096/986
[A[ATraining Step: 779  | total loss: [1m[32m0.23570[0m[0m | time: 5.697s
[2K
| RMSProp | epoch: 026 | loss: 0.23570 - acc: 0.9153 -- iter: 128/986
[A[ATraining Step: 780  | total loss: [1m[32m0.21912[0m[0m | time: 7.247s
[2K
| RMSProp | epoch: 026 | loss: 0.21912 - acc: 0.9206 -- iter: 160/986
[A[ATraining Step: 781  | total loss: [1m[32m0.22202[0m[0m | time: 9.198s
[2K
| RMSProp | epoch: 026 | loss: 0.22202 - acc: 0.9161 -- iter: 192/986
[A[ATraining Step: 782  | total loss: [1m[32m0.21448[0m[0m | time: 10.814s
[2K
| RMSProp | epoch: 026 | loss: 0.21448 - acc: 0.9213 -- iter: 224/986
[A[ATraining Step: 783  | total loss: [1m[32m0.22666[0m[0m | time: 12.892s
[2K
| RMSProp | epoch: 026 | loss: 0.22666 - acc: 0.9167 -- iter: 256/986
[A[ATraining Step: 784  | total loss: [1m[32m0.24467[0m[0m | time: 15.625s
[2K
| RMSProp | epoch: 026 | loss: 0.24467 - acc: 0.9063 -- iter: 288/986
[A[ATraining Step: 785  | total loss: [1m[32m0.25879[0m[0m | time: 17.022s
[2K
| RMSProp | epoch: 026 | loss: 0.25879 - acc: 0.9000 -- iter: 320/986
[A[ATraining Step: 786  | total loss: [1m[32m0.26035[0m[0m | time: 18.483s
[2K
| RMSProp | epoch: 026 | loss: 0.26035 - acc: 0.8975 -- iter: 352/986
[A[ATraining Step: 787  | total loss: [1m[32m0.27370[0m[0m | time: 19.863s
[2K
| RMSProp | epoch: 026 | loss: 0.27370 - acc: 0.8890 -- iter: 384/986
[A[ATraining Step: 788  | total loss: [1m[32m0.28018[0m[0m | time: 21.329s
[2K
| RMSProp | epoch: 026 | loss: 0.28018 - acc: 0.8845 -- iter: 416/986
[A[ATraining Step: 789  | total loss: [1m[32m0.25949[0m[0m | time: 22.903s
[2K
| RMSProp | epoch: 026 | loss: 0.25949 - acc: 0.8960 -- iter: 448/986
[A[ATraining Step: 790  | total loss: [1m[32m0.27007[0m[0m | time: 24.559s
[2K
| RMSProp | epoch: 026 | loss: 0.27007 - acc: 0.8908 -- iter: 480/986
[A[ATraining Step: 791  | total loss: [1m[32m0.28543[0m[0m | time: 26.039s
[2K
| RMSProp | epoch: 026 | loss: 0.28543 - acc: 0.8799 -- iter: 512/986
[A[ATraining Step: 792  | total loss: [1m[32m0.27386[0m[0m | time: 27.418s
[2K
| RMSProp | epoch: 026 | loss: 0.27386 - acc: 0.8856 -- iter: 544/986
[A[ATraining Step: 793  | total loss: [1m[32m0.26931[0m[0m | time: 28.947s
[2K
| RMSProp | epoch: 026 | loss: 0.26931 - acc: 0.8908 -- iter: 576/986
[A[ATraining Step: 794  | total loss: [1m[32m0.29735[0m[0m | time: 30.604s
[2K
| RMSProp | epoch: 026 | loss: 0.29735 - acc: 0.8799 -- iter: 608/986
[A[ATraining Step: 795  | total loss: [1m[32m0.28759[0m[0m | time: 32.315s
[2K
| RMSProp | epoch: 026 | loss: 0.28759 - acc: 0.8856 -- iter: 640/986
[A[ATraining Step: 796  | total loss: [1m[32m0.28649[0m[0m | time: 38.259s
[2K
| RMSProp | epoch: 026 | loss: 0.28649 - acc: 0.8846 -- iter: 672/986
[A[ATraining Step: 797  | total loss: [1m[32m0.28126[0m[0m | time: 39.703s
[2K
| RMSProp | epoch: 026 | loss: 0.28126 - acc: 0.8836 -- iter: 704/986
[A[ATraining Step: 798  | total loss: [1m[32m0.27047[0m[0m | time: 41.041s
[2K
| RMSProp | epoch: 026 | loss: 0.27047 - acc: 0.8859 -- iter: 736/986
[A[ATraining Step: 799  | total loss: [1m[32m0.27628[0m[0m | time: 42.305s
[2K
| RMSProp | epoch: 026 | loss: 0.27628 - acc: 0.8848 -- iter: 768/986
[A[ATraining Step: 800  | total loss: [1m[32m0.26298[0m[0m | time: 45.949s
[2K
| RMSProp | epoch: 026 | loss: 0.26298 - acc: 0.8925 | val_loss: 0.47619 - val_acc: 0.8350 -- iter: 800/986
--
Training Step: 801  | total loss: [1m[32m0.24297[0m[0m | time: 47.386s
[2K
| RMSProp | epoch: 026 | loss: 0.24297 - acc: 0.9032 -- iter: 832/986
[A[ATraining Step: 802  | total loss: [1m[32m0.24655[0m[0m | time: 48.854s
[2K
| RMSProp | epoch: 026 | loss: 0.24655 - acc: 0.9066 -- iter: 864/986
[A[ATraining Step: 803  | total loss: [1m[32m0.24417[0m[0m | time: 50.495s
[2K
| RMSProp | epoch: 026 | loss: 0.24417 - acc: 0.9097 -- iter: 896/986
[A[ATraining Step: 804  | total loss: [1m[32m0.22777[0m[0m | time: 51.969s
[2K
| RMSProp | epoch: 026 | loss: 0.22777 - acc: 0.9188 -- iter: 928/986
[A[ATraining Step: 805  | total loss: [1m[32m0.22674[0m[0m | time: 53.514s
[2K
| RMSProp | epoch: 026 | loss: 0.22674 - acc: 0.9144 -- iter: 960/986
[A[ATraining Step: 806  | total loss: [1m[32m0.22402[0m[0m | time: 57.898s
[2K
| RMSProp | epoch: 026 | loss: 0.22402 - acc: 0.9167 | val_loss: 0.53787 - val_acc: 0.8123 -- iter: 986/986
--
Training Step: 807  | total loss: [1m[32m0.21493[0m[0m | time: 1.357s
[2K
| RMSProp | epoch: 027 | loss: 0.21493 - acc: 0.9188 -- iter: 032/986
[A[ATraining Step: 808  | total loss: [1m[32m0.20669[0m[0m | time: 2.955s
[2K
| RMSProp | epoch: 027 | loss: 0.20669 - acc: 0.9206 -- iter: 064/986
[A[ATraining Step: 809  | total loss: [1m[32m0.22393[0m[0m | time: 4.410s
[2K
| RMSProp | epoch: 027 | loss: 0.22393 - acc: 0.9067 -- iter: 096/986
[A[ATraining Step: 810  | total loss: [1m[32m0.22886[0m[0m | time: 5.810s
[2K
| RMSProp | epoch: 027 | loss: 0.22886 - acc: 0.9067 -- iter: 128/986
[A[ATraining Step: 811  | total loss: [1m[32m0.22753[0m[0m | time: 7.243s
[2K
| RMSProp | epoch: 027 | loss: 0.22753 - acc: 0.9066 -- iter: 160/986
[A[ATraining Step: 812  | total loss: [1m[32m0.23520[0m[0m | time: 8.765s
[2K
| RMSProp | epoch: 027 | loss: 0.23520 - acc: 0.9003 -- iter: 192/986
[A[ATraining Step: 813  | total loss: [1m[32m0.23702[0m[0m | time: 10.218s
[2K
| RMSProp | epoch: 027 | loss: 0.23702 - acc: 0.9009 -- iter: 224/986
[A[ATraining Step: 814  | total loss: [1m[32m0.22403[0m[0m | time: 11.436s
[2K
| RMSProp | epoch: 027 | loss: 0.22403 - acc: 0.9077 -- iter: 256/986
[A[ATraining Step: 815  | total loss: [1m[32m0.21177[0m[0m | time: 12.634s
[2K
| RMSProp | epoch: 027 | loss: 0.21177 - acc: 0.9138 -- iter: 288/986
[A[ATraining Step: 816  | total loss: [1m[32m0.21062[0m[0m | time: 13.886s
[2K
| RMSProp | epoch: 027 | loss: 0.21062 - acc: 0.9193 -- iter: 320/986
[A[ATraining Step: 817  | total loss: [1m[32m0.21574[0m[0m | time: 15.090s
[2K
| RMSProp | epoch: 027 | loss: 0.21574 - acc: 0.9180 -- iter: 352/986
[A[ATraining Step: 818  | total loss: [1m[32m0.20622[0m[0m | time: 16.027s
[2K
| RMSProp | epoch: 027 | loss: 0.20622 - acc: 0.9231 -- iter: 384/986
[A[ATraining Step: 819  | total loss: [1m[32m0.21277[0m[0m | time: 17.065s
[2K
| RMSProp | epoch: 027 | loss: 0.21277 - acc: 0.9214 -- iter: 416/986
[A[ATraining Step: 820  | total loss: [1m[32m0.23603[0m[0m | time: 18.097s
[2K
| RMSProp | epoch: 027 | loss: 0.23603 - acc: 0.9105 -- iter: 448/986
[A[ATraining Step: 821  | total loss: [1m[32m0.23128[0m[0m | time: 19.083s
[2K
| RMSProp | epoch: 027 | loss: 0.23128 - acc: 0.9163 -- iter: 480/986
[A[ATraining Step: 822  | total loss: [1m[32m0.23035[0m[0m | time: 20.069s
[2K
| RMSProp | epoch: 027 | loss: 0.23035 - acc: 0.9153 -- iter: 512/986
[A[ATraining Step: 823  | total loss: [1m[32m0.21947[0m[0m | time: 21.122s
[2K
| RMSProp | epoch: 027 | loss: 0.21947 - acc: 0.9207 -- iter: 544/986
[A[ATraining Step: 824  | total loss: [1m[32m0.21174[0m[0m | time: 22.161s
[2K
| RMSProp | epoch: 027 | loss: 0.21174 - acc: 0.9223 -- iter: 576/986
[A[ATraining Step: 825  | total loss: [1m[32m0.22183[0m[0m | time: 23.239s
[2K
| RMSProp | epoch: 027 | loss: 0.22183 - acc: 0.9145 -- iter: 608/986
[A[ATraining Step: 826  | total loss: [1m[32m0.23333[0m[0m | time: 24.406s
[2K
| RMSProp | epoch: 027 | loss: 0.23333 - acc: 0.9137 -- iter: 640/986
[A[ATraining Step: 827  | total loss: [1m[32m0.23713[0m[0m | time: 25.478s
[2K
| RMSProp | epoch: 027 | loss: 0.23713 - acc: 0.9160 -- iter: 672/986
[A[ATraining Step: 828  | total loss: [1m[32m0.23777[0m[0m | time: 26.748s
[2K
| RMSProp | epoch: 027 | loss: 0.23777 - acc: 0.9119 -- iter: 704/986
[A[ATraining Step: 829  | total loss: [1m[32m0.23755[0m[0m | time: 27.984s
[2K
| RMSProp | epoch: 027 | loss: 0.23755 - acc: 0.9145 -- iter: 736/986
[A[ATraining Step: 830  | total loss: [1m[32m0.22668[0m[0m | time: 28.955s
[2K
| RMSProp | epoch: 027 | loss: 0.22668 - acc: 0.9168 -- iter: 768/986
[A[ATraining Step: 831  | total loss: [1m[32m0.22135[0m[0m | time: 29.840s
[2K
| RMSProp | epoch: 027 | loss: 0.22135 - acc: 0.9189 -- iter: 800/986
[A[ATraining Step: 832  | total loss: [1m[32m0.25583[0m[0m | time: 30.765s
[2K
| RMSProp | epoch: 027 | loss: 0.25583 - acc: 0.9116 -- iter: 832/986
[A[ATraining Step: 833  | total loss: [1m[32m0.24770[0m[0m | time: 31.719s
[2K
| RMSProp | epoch: 027 | loss: 0.24770 - acc: 0.9127 -- iter: 864/986
[A[ATraining Step: 834  | total loss: [1m[32m0.24340[0m[0m | time: 32.717s
[2K
| RMSProp | epoch: 027 | loss: 0.24340 - acc: 0.9090 -- iter: 896/986
[A[ATraining Step: 835  | total loss: [1m[32m0.23915[0m[0m | time: 33.761s
[2K
| RMSProp | epoch: 027 | loss: 0.23915 - acc: 0.9149 -- iter: 928/986
[A[ATraining Step: 836  | total loss: [1m[32m0.23383[0m[0m | time: 34.818s
[2K
| RMSProp | epoch: 027 | loss: 0.23383 - acc: 0.9172 -- iter: 960/986
[A[ATraining Step: 837  | total loss: [1m[32m0.22132[0m[0m | time: 37.734s
[2K
| RMSProp | epoch: 027 | loss: 0.22132 - acc: 0.9224 | val_loss: 0.58965 - val_acc: 0.7864 -- iter: 986/986
--
Training Step: 838  | total loss: [1m[32m0.24012[0m[0m | time: 1.360s
[2K
| RMSProp | epoch: 028 | loss: 0.24012 - acc: 0.9082 -- iter: 032/986
[A[ATraining Step: 839  | total loss: [1m[32m0.23795[0m[0m | time: 2.313s
[2K
| RMSProp | epoch: 028 | loss: 0.23795 - acc: 0.9049 -- iter: 064/986
[A[ATraining Step: 840  | total loss: [1m[32m0.25163[0m[0m | time: 3.179s
[2K
| RMSProp | epoch: 028 | loss: 0.25163 - acc: 0.8988 -- iter: 096/986
[A[ATraining Step: 841  | total loss: [1m[32m0.23814[0m[0m | time: 4.126s
[2K
| RMSProp | epoch: 028 | loss: 0.23814 - acc: 0.9058 -- iter: 128/986
[A[ATraining Step: 842  | total loss: [1m[32m0.22771[0m[0m | time: 5.185s
[2K
| RMSProp | epoch: 028 | loss: 0.22771 - acc: 0.9090 -- iter: 160/986
[A[ATraining Step: 843  | total loss: [1m[32m0.22158[0m[0m | time: 6.239s
[2K
| RMSProp | epoch: 028 | loss: 0.22158 - acc: 0.9087 -- iter: 192/986
[A[ATraining Step: 844  | total loss: [1m[32m0.21423[0m[0m | time: 7.351s
[2K
| RMSProp | epoch: 028 | loss: 0.21423 - acc: 0.9116 -- iter: 224/986
[A[ATraining Step: 845  | total loss: [1m[32m0.22834[0m[0m | time: 8.428s
[2K
| RMSProp | epoch: 028 | loss: 0.22834 - acc: 0.9079 -- iter: 256/986
[A[ATraining Step: 846  | total loss: [1m[32m0.22652[0m[0m | time: 9.474s
[2K
| RMSProp | epoch: 028 | loss: 0.22652 - acc: 0.9046 -- iter: 288/986
[A[ATraining Step: 847  | total loss: [1m[32m0.22428[0m[0m | time: 10.676s
[2K
| RMSProp | epoch: 028 | loss: 0.22428 - acc: 0.9110 -- iter: 320/986
[A[ATraining Step: 848  | total loss: [1m[32m0.22221[0m[0m | time: 12.064s
[2K
| RMSProp | epoch: 028 | loss: 0.22221 - acc: 0.9137 -- iter: 352/986
[A[ATraining Step: 849  | total loss: [1m[32m0.21095[0m[0m | time: 13.475s
[2K
| RMSProp | epoch: 028 | loss: 0.21095 - acc: 0.9223 -- iter: 384/986
[A[ATraining Step: 850  | total loss: [1m[32m0.19385[0m[0m | time: 15.121s
[2K
| RMSProp | epoch: 028 | loss: 0.19385 - acc: 0.9301 -- iter: 416/986
[A[ATraining Step: 851  | total loss: [1m[32m0.19171[0m[0m | time: 16.659s
[2K
| RMSProp | epoch: 028 | loss: 0.19171 - acc: 0.9308 -- iter: 448/986
[A[ATraining Step: 852  | total loss: [1m[32m0.23581[0m[0m | time: 18.135s
[2K
| RMSProp | epoch: 028 | loss: 0.23581 - acc: 0.9159 -- iter: 480/986
[A[ATraining Step: 853  | total loss: [1m[32m0.22075[0m[0m | time: 19.534s
[2K
| RMSProp | epoch: 028 | loss: 0.22075 - acc: 0.9243 -- iter: 512/986
[A[ATraining Step: 854  | total loss: [1m[32m0.22481[0m[0m | time: 20.887s
[2K
| RMSProp | epoch: 028 | loss: 0.22481 - acc: 0.9225 -- iter: 544/986
[A[ATraining Step: 855  | total loss: [1m[32m0.20854[0m[0m | time: 22.494s
[2K
| RMSProp | epoch: 028 | loss: 0.20854 - acc: 0.9302 -- iter: 576/986
[A[ATraining Step: 856  | total loss: [1m[32m0.19417[0m[0m | time: 23.926s
[2K
| RMSProp | epoch: 028 | loss: 0.19417 - acc: 0.9341 -- iter: 608/986
[A[ATraining Step: 857  | total loss: [1m[32m0.20824[0m[0m | time: 25.548s
[2K
| RMSProp | epoch: 028 | loss: 0.20824 - acc: 0.9282 -- iter: 640/986
[A[ATraining Step: 858  | total loss: [1m[32m0.25054[0m[0m | time: 27.075s
[2K
| RMSProp | epoch: 028 | loss: 0.25054 - acc: 0.9041 -- iter: 672/986
[A[ATraining Step: 859  | total loss: [1m[32m0.24001[0m[0m | time: 28.480s
[2K
| RMSProp | epoch: 028 | loss: 0.24001 - acc: 0.9106 -- iter: 704/986
[A[ATraining Step: 860  | total loss: [1m[32m0.22955[0m[0m | time: 29.948s
[2K
| RMSProp | epoch: 028 | loss: 0.22955 - acc: 0.9164 -- iter: 736/986
[A[ATraining Step: 861  | total loss: [1m[32m0.22517[0m[0m | time: 31.554s
[2K
| RMSProp | epoch: 028 | loss: 0.22517 - acc: 0.9185 -- iter: 768/986
[A[ATraining Step: 862  | total loss: [1m[32m0.21880[0m[0m | time: 33.149s
[2K
| RMSProp | epoch: 028 | loss: 0.21880 - acc: 0.9204 -- iter: 800/986
[A[ATraining Step: 863  | total loss: [1m[32m0.21130[0m[0m | time: 34.346s
[2K
| RMSProp | epoch: 028 | loss: 0.21130 - acc: 0.9221 -- iter: 832/986
[A[ATraining Step: 864  | total loss: [1m[32m0.19963[0m[0m | time: 35.602s
[2K
| RMSProp | epoch: 028 | loss: 0.19963 - acc: 0.9261 -- iter: 864/986
[A[ATraining Step: 865  | total loss: [1m[32m0.18742[0m[0m | time: 37.210s
[2K
| RMSProp | epoch: 028 | loss: 0.18742 - acc: 0.9296 -- iter: 896/986
[A[ATraining Step: 866  | total loss: [1m[32m0.17076[0m[0m | time: 38.746s
[2K
| RMSProp | epoch: 028 | loss: 0.17076 - acc: 0.9366 -- iter: 928/986
[A[ATraining Step: 867  | total loss: [1m[32m0.15775[0m[0m | time: 40.080s
[2K
| RMSProp | epoch: 028 | loss: 0.15775 - acc: 0.9430 -- iter: 960/986
[A[ATraining Step: 868  | total loss: [1m[32m0.15092[0m[0m | time: 44.179s
[2K
| RMSProp | epoch: 028 | loss: 0.15092 - acc: 0.9456 | val_loss: 0.55158 - val_acc: 0.8123 -- iter: 986/986
--
Training Step: 869  | total loss: [1m[32m0.21987[0m[0m | time: 1.722s
[2K
| RMSProp | epoch: 029 | loss: 0.21987 - acc: 0.9260 -- iter: 032/986
[A[ATraining Step: 870  | total loss: [1m[32m0.20696[0m[0m | time: 3.621s
[2K
| RMSProp | epoch: 029 | loss: 0.20696 - acc: 0.9334 -- iter: 064/986
[A[ATraining Step: 871  | total loss: [1m[32m0.20283[0m[0m | time: 4.984s
[2K
| RMSProp | epoch: 029 | loss: 0.20283 - acc: 0.9338 -- iter: 096/986
[A[ATraining Step: 872  | total loss: [1m[32m0.20171[0m[0m | time: 6.412s
[2K
| RMSProp | epoch: 029 | loss: 0.20171 - acc: 0.9342 -- iter: 128/986
[A[ATraining Step: 873  | total loss: [1m[32m0.19550[0m[0m | time: 8.010s
[2K
| RMSProp | epoch: 029 | loss: 0.19550 - acc: 0.9345 -- iter: 160/986
[A[ATraining Step: 874  | total loss: [1m[32m0.19758[0m[0m | time: 9.511s
[2K
| RMSProp | epoch: 029 | loss: 0.19758 - acc: 0.9348 -- iter: 192/986
[A[ATraining Step: 875  | total loss: [1m[32m0.18720[0m[0m | time: 11.153s
[2K
| RMSProp | epoch: 029 | loss: 0.18720 - acc: 0.9382 -- iter: 224/986
[A[ATraining Step: 876  | total loss: [1m[32m0.18125[0m[0m | time: 12.781s
[2K
| RMSProp | epoch: 029 | loss: 0.18125 - acc: 0.9413 -- iter: 256/986
[A[ATraining Step: 877  | total loss: [1m[32m0.18588[0m[0m | time: 14.470s
[2K
| RMSProp | epoch: 029 | loss: 0.18588 - acc: 0.9440 -- iter: 288/986
[A[ATraining Step: 878  | total loss: [1m[32m0.19001[0m[0m | time: 15.980s
[2K
| RMSProp | epoch: 029 | loss: 0.19001 - acc: 0.9434 -- iter: 320/986
[A[ATraining Step: 879  | total loss: [1m[32m0.17913[0m[0m | time: 17.267s
[2K
| RMSProp | epoch: 029 | loss: 0.17913 - acc: 0.9459 -- iter: 352/986
[A[ATraining Step: 880  | total loss: [1m[32m0.17862[0m[0m | time: 18.805s
[2K
| RMSProp | epoch: 029 | loss: 0.17862 - acc: 0.9419 -- iter: 384/986
[A[ATraining Step: 881  | total loss: [1m[32m0.17110[0m[0m | time: 20.330s
[2K
| RMSProp | epoch: 029 | loss: 0.17110 - acc: 0.9446 -- iter: 416/986
[A[ATraining Step: 882  | total loss: [1m[32m0.16133[0m[0m | time: 21.928s
[2K
| RMSProp | epoch: 029 | loss: 0.16133 - acc: 0.9470 -- iter: 448/986
[A[ATraining Step: 883  | total loss: [1m[32m0.16203[0m[0m | time: 23.315s
[2K
| RMSProp | epoch: 029 | loss: 0.16203 - acc: 0.9492 -- iter: 480/986
[A[ATraining Step: 884  | total loss: [1m[32m0.14733[0m[0m | time: 24.391s
[2K
| RMSProp | epoch: 029 | loss: 0.14733 - acc: 0.9543 -- iter: 512/986
[A[ATraining Step: 885  | total loss: [1m[32m0.14130[0m[0m | time: 25.659s
[2K
| RMSProp | epoch: 029 | loss: 0.14130 - acc: 0.9557 -- iter: 544/986
[A[ATraining Step: 886  | total loss: [1m[32m0.14043[0m[0m | time: 26.813s
[2K
| RMSProp | epoch: 029 | loss: 0.14043 - acc: 0.9570 -- iter: 576/986
[A[ATraining Step: 887  | total loss: [1m[32m0.14973[0m[0m | time: 28.042s
[2K
| RMSProp | epoch: 029 | loss: 0.14973 - acc: 0.9551 -- iter: 608/986
[A[ATraining Step: 888  | total loss: [1m[32m0.15008[0m[0m | time: 29.274s
[2K
| RMSProp | epoch: 029 | loss: 0.15008 - acc: 0.9533 -- iter: 640/986
[A[ATraining Step: 889  | total loss: [1m[32m0.16058[0m[0m | time: 30.520s
[2K
| RMSProp | epoch: 029 | loss: 0.16058 - acc: 0.9486 -- iter: 672/986
[A[ATraining Step: 890  | total loss: [1m[32m0.21290[0m[0m | time: 31.492s
[2K
| RMSProp | epoch: 029 | loss: 0.21290 - acc: 0.9288 -- iter: 704/986
[A[ATraining Step: 891  | total loss: [1m[32m0.20656[0m[0m | time: 32.682s
[2K
| RMSProp | epoch: 029 | loss: 0.20656 - acc: 0.9328 -- iter: 736/986
[A[ATraining Step: 892  | total loss: [1m[32m0.19983[0m[0m | time: 33.940s
[2K
| RMSProp | epoch: 029 | loss: 0.19983 - acc: 0.9364 -- iter: 768/986
[A[ATraining Step: 893  | total loss: [1m[32m0.19525[0m[0m | time: 35.268s
[2K
| RMSProp | epoch: 029 | loss: 0.19525 - acc: 0.9396 -- iter: 800/986
[A[ATraining Step: 894  | total loss: [1m[32m0.19492[0m[0m | time: 36.361s
[2K
| RMSProp | epoch: 029 | loss: 0.19492 - acc: 0.9394 -- iter: 832/986
[A[ATraining Step: 895  | total loss: [1m[32m0.18283[0m[0m | time: 37.282s
[2K
| RMSProp | epoch: 029 | loss: 0.18283 - acc: 0.9454 -- iter: 864/986
[A[ATraining Step: 896  | total loss: [1m[32m0.16582[0m[0m | time: 38.363s
[2K
| RMSProp | epoch: 029 | loss: 0.16582 - acc: 0.9509 -- iter: 896/986
[A[ATraining Step: 897  | total loss: [1m[32m0.15015[0m[0m | time: 39.673s
[2K
| RMSProp | epoch: 029 | loss: 0.15015 - acc: 0.9558 -- iter: 928/986
[A[ATraining Step: 898  | total loss: [1m[32m0.14102[0m[0m | time: 40.892s
[2K
| RMSProp | epoch: 029 | loss: 0.14102 - acc: 0.9571 -- iter: 960/986
[A[ATraining Step: 899  | total loss: [1m[32m0.13052[0m[0m | time: 43.966s
[2K
| RMSProp | epoch: 029 | loss: 0.13052 - acc: 0.9614 | val_loss: 0.61931 - val_acc: 0.8350 -- iter: 986/986
--
Training Step: 900  | total loss: [1m[32m0.11879[0m[0m | time: 1.331s
[2K
| RMSProp | epoch: 030 | loss: 0.11879 - acc: 0.9653 -- iter: 032/986
[A[ATraining Step: 901  | total loss: [1m[32m0.10906[0m[0m | time: 2.482s
[2K
| RMSProp | epoch: 030 | loss: 0.10906 - acc: 0.9687 -- iter: 064/986
[A[ATraining Step: 902  | total loss: [1m[32m0.10070[0m[0m | time: 3.799s
[2K
| RMSProp | epoch: 030 | loss: 0.10070 - acc: 0.9719 -- iter: 096/986
[A[ATraining Step: 903  | total loss: [1m[32m0.12050[0m[0m | time: 5.225s
[2K
| RMSProp | epoch: 030 | loss: 0.12050 - acc: 0.9684 -- iter: 128/986
[A[ATraining Step: 904  | total loss: [1m[32m0.18143[0m[0m | time: 6.644s
[2K
| RMSProp | epoch: 030 | loss: 0.18143 - acc: 0.9528 -- iter: 160/986
[A[ATraining Step: 905  | total loss: [1m[32m0.17882[0m[0m | time: 8.320s
[2K
| RMSProp | epoch: 030 | loss: 0.17882 - acc: 0.9513 -- iter: 192/986
[A[ATraining Step: 906  | total loss: [1m[32m0.16712[0m[0m | time: 9.554s
[2K
| RMSProp | epoch: 030 | loss: 0.16712 - acc: 0.9530 -- iter: 224/986
[A[ATraining Step: 907  | total loss: [1m[32m0.16915[0m[0m | time: 10.998s
[2K
| RMSProp | epoch: 030 | loss: 0.16915 - acc: 0.9515 -- iter: 256/986
[A[ATraining Step: 908  | total loss: [1m[32m0.17346[0m[0m | time: 12.465s
[2K
| RMSProp | epoch: 030 | loss: 0.17346 - acc: 0.9532 -- iter: 288/986
[A[ATraining Step: 909  | total loss: [1m[32m0.16501[0m[0m | time: 13.867s
[2K
| RMSProp | epoch: 030 | loss: 0.16501 - acc: 0.9516 -- iter: 320/986
[A[ATraining Step: 910  | total loss: [1m[32m0.15729[0m[0m | time: 15.304s
[2K
| RMSProp | epoch: 030 | loss: 0.15729 - acc: 0.9534 -- iter: 352/986
[A[ATraining Step: 911  | total loss: [1m[32m0.14868[0m[0m | time: 16.755s
[2K
| RMSProp | epoch: 030 | loss: 0.14868 - acc: 0.9549 -- iter: 384/986
[A[ATraining Step: 912  | total loss: [1m[32m0.14774[0m[0m | time: 18.201s
[2K
| RMSProp | epoch: 030 | loss: 0.14774 - acc: 0.9563 -- iter: 416/986
[A[ATraining Step: 913  | total loss: [1m[32m0.17441[0m[0m | time: 19.353s
[2K
| RMSProp | epoch: 030 | loss: 0.17441 - acc: 0.9419 -- iter: 448/986
[A[ATraining Step: 914  | total loss: [1m[32m0.16681[0m[0m | time: 20.447s
[2K
| RMSProp | epoch: 030 | loss: 0.16681 - acc: 0.9446 -- iter: 480/986
[A[ATraining Step: 915  | total loss: [1m[32m0.15428[0m[0m | time: 21.315s
[2K
| RMSProp | epoch: 030 | loss: 0.15428 - acc: 0.9501 -- iter: 512/986
[A[ATraining Step: 916  | total loss: [1m[32m0.14253[0m[0m | time: 22.430s
[2K
| RMSProp | epoch: 030 | loss: 0.14253 - acc: 0.9551 -- iter: 544/986
[A[ATraining Step: 917  | total loss: [1m[32m0.14613[0m[0m | time: 23.505s
[2K
| RMSProp | epoch: 030 | loss: 0.14613 - acc: 0.9534 -- iter: 576/986
[A[ATraining Step: 918  | total loss: [1m[32m0.14598[0m[0m | time: 24.810s
[2K
| RMSProp | epoch: 030 | loss: 0.14598 - acc: 0.9486 -- iter: 608/986
[A[ATraining Step: 919  | total loss: [1m[32m0.18270[0m[0m | time: 25.787s
[2K
| RMSProp | epoch: 030 | loss: 0.18270 - acc: 0.9382 -- iter: 640/986
[A[ATraining Step: 920  | total loss: [1m[32m0.20462[0m[0m | time: 26.787s
[2K
| RMSProp | epoch: 030 | loss: 0.20462 - acc: 0.9287 -- iter: 672/986
[A[ATraining Step: 921  | total loss: [1m[32m0.21016[0m[0m | time: 27.851s
[2K
| RMSProp | epoch: 030 | loss: 0.21016 - acc: 0.9233 -- iter: 704/986
[A[ATraining Step: 922  | total loss: [1m[32m0.20467[0m[0m | time: 28.882s
[2K
| RMSProp | epoch: 030 | loss: 0.20467 - acc: 0.9248 -- iter: 736/986
[A[ATraining Step: 923  | total loss: [1m[32m0.19510[0m[0m | time: 29.911s
[2K
| RMSProp | epoch: 030 | loss: 0.19510 - acc: 0.9292 -- iter: 768/986
[A[ATraining Step: 924  | total loss: [1m[32m0.18150[0m[0m | time: 30.944s
[2K
| RMSProp | epoch: 030 | loss: 0.18150 - acc: 0.9362 -- iter: 800/986
[A[ATraining Step: 925  | total loss: [1m[32m0.16602[0m[0m | time: 31.967s
[2K
| RMSProp | epoch: 030 | loss: 0.16602 - acc: 0.9426 -- iter: 832/986
[A[ATraining Step: 926  | total loss: [1m[32m0.15585[0m[0m | time: 33.124s
[2K
| RMSProp | epoch: 030 | loss: 0.15585 - acc: 0.9484 -- iter: 864/986
[A[ATraining Step: 927  | total loss: [1m[32m0.16298[0m[0m | time: 34.029s
[2K
| RMSProp | epoch: 030 | loss: 0.16298 - acc: 0.9504 -- iter: 896/986
[A[ATraining Step: 928  | total loss: [1m[32m0.18448[0m[0m | time: 34.879s
[2K
| RMSProp | epoch: 030 | loss: 0.18448 - acc: 0.9515 -- iter: 928/986
[A[ATraining Step: 929  | total loss: [1m[32m0.17647[0m[0m | time: 36.034s
[2K
| RMSProp | epoch: 030 | loss: 0.17647 - acc: 0.9525 -- iter: 960/986
[A[ATraining Step: 930  | total loss: [1m[32m0.16671[0m[0m | time: 39.038s
[2K
| RMSProp | epoch: 030 | loss: 0.16671 - acc: 0.9541 | val_loss: 0.57658 - val_acc: 0.8091 -- iter: 986/986
--
Validation AUC:0.8916287846298997
Validation AUPRC:0.9168831122776437
Test AUC:0.8912857020327644
Test AUPRC:0.9021657054007335
BestTestF1Score	0.86	0.65	0.83	0.84	0.87	155	29	102	23	0.82
BestTestMCCScore	0.86	0.65	0.83	0.84	0.87	155	29	102	23	0.82
BestTestAccuracyScore	0.86	0.65	0.83	0.84	0.87	155	29	102	23	0.82
BestValidationF1Score	0.86	0.67	0.84	0.84	0.89	158	30	101	20	0.82
BestValidationMCC	0.86	0.67	0.84	0.84	0.89	158	30	101	20	0.82
BestValidationAccuracy	0.86	0.67	0.84	0.84	0.89	158	30	101	20	0.82
TestPredictions (Threshold:0.82)
CHEMBL575947,TN,INACT,0.07999999821186066	CHEMBL1916661,FN,ACT,0.05000000074505806	CHEMBL111475,FN,ACT,0.41999998688697815	CHEMBL171466,TN,INACT,0.009999999776482582	CHEMBL18895,TP,ACT,0.9900000095367432	CHEMBL1214543,TN,INACT,0.009999999776482582	CHEMBL1082657,TP,ACT,0.9900000095367432	CHEMBL473315,TP,ACT,0.9800000190734863	CHEMBL46818,TP,ACT,0.9900000095367432	CHEMBL561039,TP,ACT,0.9900000095367432	CHEMBL147903,TP,ACT,0.9900000095367432	CHEMBL2425946,TP,ACT,1.0	CHEMBL240850,FP,INACT,0.9800000190734863	CHEMBL602902,TN,INACT,0.009999999776482582	CHEMBL1801426,TP,ACT,0.9700000286102295	CHEMBL2431018,TN,INACT,0.6399999856948853	CHEMBL562716,TN,INACT,0.019999999552965164	CHEMBL63415,TN,INACT,0.029999999329447746	CHEMBL574589,TP,ACT,0.9700000286102295	CHEMBL324578,TP,ACT,0.9700000286102295	CHEMBL469138,TP,ACT,1.0	CHEMBL424792,TN,INACT,0.38999998569488525	CHEMBL1082789,TP,ACT,0.949999988079071	CHEMBL2409710,TP,ACT,0.9800000190734863	CHEMBL10646,TP,ACT,0.9900000095367432	CHEMBL552362,TP,ACT,1.0	CHEMBL2380402,TP,ACT,0.9599999785423279	CHEMBL10761,TP,ACT,1.0	CHEMBL502796,FN,ACT,0.7400000095367432	CHEMBL596273,TP,ACT,0.9900000095367432	CHEMBL121592,TN,INACT,0.029999999329447746	CHEMBL62186,TN,INACT,0.2199999988079071	CHEMBL501081,TN,INACT,0.019999999552965164	CHEMBL43479,TP,ACT,1.0	CHEMBL360916,TP,ACT,1.0	CHEMBL3774826,TN,INACT,0.019999999552965164	CHEMBL2431021,FP,INACT,0.9399999976158142	CHEMBL489026,TN,INACT,0.029999999329447746	CHEMBL3649602,TN,INACT,0.5299999713897705	CHEMBL19005,TP,ACT,0.9900000095367432	CHEMBL311966,TP,ACT,0.9900000095367432	CHEMBL2409688,TP,ACT,0.9900000095367432	CHEMBL596300,TP,ACT,0.9900000095367432	CHEMBL507420,FN,ACT,0.25	CHEMBL3670707,TP,ACT,0.9700000286102295	CHEMBL175165,TP,ACT,0.949999988079071	CHEMBL1801051,TP,ACT,0.9399999976158142	CHEMBL83209,TP,ACT,0.9700000286102295	CHEMBL33915,TN,INACT,0.0	CHEMBL438832,TN,INACT,0.12999999523162842	CHEMBL429250,FN,ACT,0.6000000238418579	CHEMBL2380398,TN,INACT,0.1899999976158142	CHEMBL332134,TP,ACT,0.9399999976158142	CHEMBL3751997,TP,ACT,0.9800000190734863	CHEMBL420023,TP,ACT,1.0	CHEMBL1946149,FN,ACT,0.029999999329447746	CHEMBL319782,TP,ACT,1.0	CHEMBL2385492,TP,ACT,0.9300000071525574	CHEMBL3649595,TN,INACT,0.7900000214576721	CHEMBL432346,TN,INACT,0.0	CHEMBL551655,TP,ACT,0.9900000095367432	CHEMBL202806,TP,ACT,0.9700000286102295	CHEMBL123499,TP,ACT,0.9599999785423279	CHEMBL248941,TP,ACT,1.0	CHEMBL1083584,TP,ACT,0.9900000095367432	CHEMBL150655,FN,ACT,0.41999998688697815	CHEMBL251426,TN,INACT,0.07000000029802322	CHEMBL1834422,TN,INACT,0.029999999329447746	CHEMBL10672,TP,ACT,0.949999988079071	CHEMBL493179,TP,ACT,0.9800000190734863	CHEMBL3649599,TN,INACT,0.03999999910593033	CHEMBL93231,TP,ACT,0.9700000286102295	CHEMBL604139,TP,ACT,0.9900000095367432	CHEMBL339137,TP,ACT,1.0	CHEMBL573935,TP,ACT,0.9300000071525574	CHEMBL2369492,FP,INACT,0.9599999785423279	CHEMBL115223,TP,ACT,0.9800000190734863	CHEMBL2147937,TN,INACT,0.029999999329447746	CHEMBL3639695,TP,ACT,0.8999999761581421	CHEMBL254627,TN,INACT,0.019999999552965164	CHEMBL1744413,TN,INACT,0.8100000023841858	CHEMBL605144,TN,INACT,0.07000000029802322	CHEMBL1650630,TN,INACT,0.009999999776482582	CHEMBL342210,TP,ACT,0.9599999785423279	CHEMBL370667,TP,ACT,0.9900000095367432	CHEMBL75114,FP,INACT,0.8899999856948853	CHEMBL280998,TN,INACT,0.019999999552965164	CHEMBL180627,TP,ACT,0.9700000286102295	CHEMBL389020,FP,INACT,0.8799999952316284	CHEMBL1770700,TP,ACT,0.9599999785423279	CHEMBL420447,TN,INACT,0.7099999785423279	CHEMBL323885,TN,INACT,0.0	CHEMBL3291003,TN,INACT,0.029999999329447746	CHEMBL1223135,TP,ACT,1.0	CHEMBL1910469,FP,INACT,1.0	CHEMBL370825,TP,ACT,0.9900000095367432	CHEMBL237078,TN,INACT,0.009999999776482582	CHEMBL243874,TP,ACT,0.9900000095367432	CHEMBL121559,TN,INACT,0.05000000074505806	CHEMBL559294,TN,INACT,0.009999999776482582	CHEMBL68271,TP,ACT,0.9800000190734863	CHEMBL2064552,TP,ACT,0.9800000190734863	CHEMBL3359071,TP,ACT,0.8799999952316284	CHEMBL3337891,TP,ACT,0.9900000095367432	CHEMBL433171,FN,ACT,0.7799999713897705	CHEMBL1927209,TP,ACT,0.9900000095367432	CHEMBL293411,TP,ACT,0.9900000095367432	CHEMBL1632640,TP,ACT,0.9399999976158142	CHEMBL3098998,TN,INACT,0.019999999552965164	CHEMBL3758657,TP,ACT,0.9800000190734863	CHEMBL123105,TN,INACT,0.019999999552965164	CHEMBL2431016,FP,INACT,0.9800000190734863	CHEMBL98852,TN,INACT,0.009999999776482582	CHEMBL328162,TP,ACT,0.9900000095367432	CHEMBL115330,FP,INACT,0.9900000095367432	CHEMBL582839,TN,INACT,0.07999999821186066	CHEMBL333122,TN,INACT,0.029999999329447746	CHEMBL147489,FP,INACT,0.9399999976158142	CHEMBL330588,TP,ACT,0.9900000095367432	CHEMBL567341,FP,INACT,0.9599999785423279	CHEMBL1910476,TP,ACT,1.0	CHEMBL8943,FP,INACT,0.8700000047683716	CHEMBL80732,TP,ACT,0.9900000095367432	CHEMBL478078,TN,INACT,0.029999999329447746	CHEMBL3359063,TP,ACT,1.0	CHEMBL263909,TN,INACT,0.7599999904632568	CHEMBL36682,TN,INACT,0.05000000074505806	CHEMBL468731,TP,ACT,1.0	CHEMBL1784339,TP,ACT,1.0	CHEMBL3092093,FP,INACT,0.9700000286102295	CHEMBL567893,TP,ACT,0.9700000286102295	CHEMBL1223202,TP,ACT,0.9900000095367432	CHEMBL254006,TN,INACT,0.009999999776482582	CHEMBL399304,TN,INACT,0.009999999776482582	CHEMBL312770,TP,ACT,0.8799999952316284	CHEMBL1819333,TN,INACT,0.38999998569488525	CHEMBL309067,TN,INACT,0.019999999552965164	CHEMBL2385487,FN,ACT,0.1599999964237213	CHEMBL367959,TN,INACT,0.5099999904632568	CHEMBL235318,FP,INACT,0.9900000095367432	CHEMBL125384,TP,ACT,0.9700000286102295	CHEMBL466052,TP,ACT,0.9900000095367432	CHEMBL1801414,TP,ACT,1.0	CHEMBL575534,FN,ACT,0.07000000029802322	CHEMBL481712,TN,INACT,0.75	CHEMBL2425947,TP,ACT,0.9900000095367432	CHEMBL503690,TN,INACT,0.019999999552965164	CHEMBL115468,TN,INACT,0.019999999552965164	CHEMBL1801049,TP,ACT,0.9599999785423279	CHEMBL1957575,TN,INACT,0.46000000834465027	CHEMBL342005,TN,INACT,0.009999999776482582	CHEMBL2440435,TN,INACT,0.019999999552965164	CHEMBL287820,TP,ACT,0.9700000286102295	CHEMBL315114,TP,ACT,0.9800000190734863	CHEMBL523446,TN,INACT,0.019999999552965164	CHEMBL3359089,TP,ACT,1.0	CHEMBL412910,TP,ACT,0.9300000071525574	CHEMBL1651846,TN,INACT,0.27000001072883606	CHEMBL61354,TP,ACT,0.9599999785423279	CHEMBL109353,TP,ACT,0.9900000095367432	CHEMBL473610,TP,ACT,0.8299999833106995	CHEMBL591774,FN,ACT,0.0	CHEMBL345305,TN,INACT,0.7799999713897705	CHEMBL1744412,FP,INACT,0.9700000286102295	CHEMBL1927184,TN,INACT,0.029999999329447746	CHEMBL1940284,TP,ACT,1.0	CHEMBL80412,TP,ACT,0.9900000095367432	CHEMBL399685,TN,INACT,0.009999999776482582	CHEMBL3774803,TN,INACT,0.009999999776482582	CHEMBL270502,FN,ACT,0.1899999976158142	CHEMBL1916398,TN,INACT,0.11999999731779099	CHEMBL179285,FN,ACT,0.7400000095367432	CHEMBL3775011,TN,INACT,0.019999999552965164	CHEMBL466118,TP,ACT,0.9900000095367432	CHEMBL1795861,FP,INACT,1.0	CHEMBL316298,TP,ACT,0.9300000071525574	CHEMBL370662,TN,INACT,0.03999999910593033	CHEMBL2409685,FN,ACT,0.41999998688697815	CHEMBL3649592,TN,INACT,0.019999999552965164	CHEMBL1796298,TP,ACT,1.0	CHEMBL1234370,TP,ACT,0.9900000095367432	CHEMBL3142591,TN,INACT,0.7799999713897705	CHEMBL358182,TP,ACT,1.0	CHEMBL55371,TN,INACT,0.07999999821186066	CHEMBL561038,TP,ACT,0.9100000262260437	CHEMBL117664,TN,INACT,0.019999999552965164	CHEMBL79267,TP,ACT,0.9900000095367432	CHEMBL220964,TP,ACT,1.0	CHEMBL1231240,FP,INACT,0.9399999976158142	CHEMBL427366,TP,ACT,0.9900000095367432	CHEMBL1910460,TP,ACT,1.0	CHEMBL1160686,FP,INACT,0.9399999976158142	CHEMBL399998,TN,INACT,0.009999999776482582	CHEMBL254403,TN,INACT,0.009999999776482582	CHEMBL1819324,TN,INACT,0.009999999776482582	CHEMBL3759727,TP,ACT,0.9800000190734863	CHEMBL468095,TP,ACT,1.0	CHEMBL574666,FP,INACT,0.9900000095367432	CHEMBL97951,TN,INACT,0.019999999552965164	CHEMBL449228,FN,ACT,0.029999999329447746	CHEMBL91636,FN,ACT,0.47999998927116394	CHEMBL3670704,FN,ACT,0.8100000023841858	CHEMBL2380399,FP,INACT,0.9200000166893005	CHEMBL3359080,TP,ACT,1.0	CHEMBL43065,TN,INACT,0.029999999329447746	CHEMBL115877,TP,ACT,0.9700000286102295	CHEMBL3675605,FN,ACT,0.44999998807907104	CHEMBL392571,TP,ACT,0.949999988079071	CHEMBL191106,FP,INACT,1.0	CHEMBL141080,TP,ACT,0.949999988079071	CHEMBL194627,TP,ACT,0.9900000095367432	CHEMBL332439,TN,INACT,0.029999999329447746	CHEMBL485492,FP,INACT,0.949999988079071	CHEMBL24398,FP,INACT,0.9800000190734863	CHEMBL99745,TP,ACT,1.0	CHEMBL226852,TN,INACT,0.5400000214576721	CHEMBL1649594,TN,INACT,0.05999999865889549	CHEMBL77258,TP,ACT,0.949999988079071	CHEMBL3617405,TP,ACT,0.9900000095367432	CHEMBL2164113,TP,ACT,0.9700000286102295	CHEMBL253801,TN,INACT,0.009999999776482582	CHEMBL1916644,TP,ACT,0.9800000190734863	CHEMBL102839,TN,INACT,0.6399999856948853	CHEMBL112609,TP,ACT,0.9900000095367432	CHEMBL3092082,FP,INACT,0.9399999976158142	CHEMBL1083908,TP,ACT,1.0	CHEMBL27213,TP,ACT,0.9900000095367432	CHEMBL1085257,TP,ACT,0.9900000095367432	CHEMBL150077,TP,ACT,0.9900000095367432	CHEMBL91434,TP,ACT,0.9700000286102295	CHEMBL2064541,TP,ACT,0.8399999737739563	CHEMBL275345,TP,ACT,0.9900000095367432	CHEMBL3759109,TP,ACT,0.9900000095367432	CHEMBL231878,TP,ACT,0.9200000166893005	CHEMBL227484,TP,ACT,0.9900000095367432	CHEMBL2147933,TN,INACT,0.18000000715255737	CHEMBL1916643,FN,ACT,0.009999999776482582	CHEMBL271535,TP,ACT,0.9900000095367432	CHEMBL3398611,TN,INACT,0.029999999329447746	CHEMBL445894,TP,ACT,0.9900000095367432	CHEMBL462629,FN,ACT,0.4099999964237213	CHEMBL421,TN,INACT,0.23000000417232513	CHEMBL316489,TP,ACT,1.0	CHEMBL289375,TN,INACT,0.3400000035762787	CHEMBL114523,TN,INACT,0.20000000298023224	CHEMBL489415,TN,INACT,0.029999999329447746	CHEMBL190215,FN,ACT,0.3100000023841858	CHEMBL1819331,TN,INACT,0.07999999821186066	CHEMBL10953,TP,ACT,0.9900000095367432	CHEMBL381163,TP,ACT,1.0	CHEMBL42114,TP,ACT,0.9800000190734863	CHEMBL1800089,TP,ACT,1.0	CHEMBL249847,TN,INACT,0.019999999552965164	CHEMBL289207,FP,INACT,0.9300000071525574	CHEMBL102785,TP,ACT,1.0	CHEMBL572982,TN,INACT,0.029999999329447746	CHEMBL3758194,TP,ACT,0.9900000095367432	CHEMBL2151354,FP,INACT,0.9900000095367432	CHEMBL328645,TP,ACT,1.0	CHEMBL1784367,TP,ACT,0.9800000190734863	CHEMBL2440581,TN,INACT,0.05000000074505806	CHEMBL180925,FN,ACT,0.029999999329447746	CHEMBL19278,TP,ACT,1.0	CHEMBL253835,TN,INACT,0.03999999910593033	CHEMBL399999,TN,INACT,0.05000000074505806	CHEMBL197587,TP,ACT,1.0	CHEMBL35606,TP,ACT,1.0	CHEMBL97389,TN,INACT,0.07999999821186066	CHEMBL10848,TP,ACT,1.0	CHEMBL3649594,TN,INACT,0.05999999865889549	CHEMBL523279,TN,INACT,0.0	CHEMBL1916207,TP,ACT,0.9900000095367432	CHEMBL42938,TP,ACT,1.0	CHEMBL497908,FP,INACT,0.9900000095367432	CHEMBL1796287,TN,INACT,0.20999999344348907	CHEMBL308084,TP,ACT,1.0	CHEMBL94873,TN,INACT,0.019999999552965164	CHEMBL96417,TP,ACT,0.9900000095367432	CHEMBL1083290,TP,ACT,1.0	CHEMBL2409694,TP,ACT,0.9900000095367432	CHEMBL377862,TP,ACT,0.9900000095367432	CHEMBL512243,TP,ACT,0.9900000095367432	CHEMBL1335679,FP,INACT,0.9700000286102295	CHEMBL417885,TN,INACT,0.029999999329447746	CHEMBL1940309,TP,ACT,1.0	CHEMBL343414,TP,ACT,0.9900000095367432	CHEMBL307057,TN,INACT,0.07000000029802322	CHEMBL3646215,FP,INACT,0.9300000071525574	CHEMBL1916641,FN,ACT,0.5699999928474426	CHEMBL66143,TN,INACT,0.07000000029802322	CHEMBL148120,TP,ACT,0.949999988079071	CHEMBL123233,TN,INACT,0.029999999329447746	CHEMBL1223421,TP,ACT,1.0	CHEMBL526558,TN,INACT,0.05999999865889549	CHEMBL94357,TP,ACT,0.9700000286102295	CHEMBL317132,TP,ACT,0.9900000095367432	CHEMBL524533,TP,ACT,0.8999999761581421	CHEMBL1229868,TP,ACT,1.0	CHEMBL550907,TP,ACT,1.0	CHEMBL1795858,FP,INACT,0.9700000286102295	CHEMBL77972,TP,ACT,1.0	CHEMBL1834420,TN,INACT,0.14000000059604645	CHEMBL3775142,TN,INACT,0.029999999329447746	CHEMBL18742,TP,ACT,0.9900000095367432	CHEMBL365892,TP,ACT,1.0	CHEMBL410649,TN,INACT,0.12999999523162842	CHEMBL2326365,TP,ACT,1.0	CHEMBL238081,TP,ACT,1.0	CHEMBL173382,TN,INACT,0.019999999552965164	

