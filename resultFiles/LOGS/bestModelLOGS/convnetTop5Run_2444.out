ImageNetInceptionV2 CHEMBL1836 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	458
Number of inactive compounds :	458
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1836_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1836_adam_0.0005_15_0.8/
---------------------------------
Training samples: 569
Validation samples: 178
--
Training Step: 1  | time: 39.410s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/569
[A[ATraining Step: 2  | total loss: [1m[32m0.68409[0m[0m | time: 50.043s
[2K
| Adam | epoch: 001 | loss: 0.68409 - acc: 0.3656 -- iter: 064/569
[A[ATraining Step: 3  | total loss: [1m[32m0.76314[0m[0m | time: 60.792s
[2K
| Adam | epoch: 001 | loss: 0.76314 - acc: 0.5523 -- iter: 096/569
[A[ATraining Step: 4  | total loss: [1m[32m0.60859[0m[0m | time: 71.570s
[2K
| Adam | epoch: 001 | loss: 0.60859 - acc: 0.6537 -- iter: 128/569
[A[ATraining Step: 5  | total loss: [1m[32m0.59973[0m[0m | time: 82.296s
[2K
| Adam | epoch: 001 | loss: 0.59973 - acc: 0.7204 -- iter: 160/569
[A[ATraining Step: 6  | total loss: [1m[32m0.54014[0m[0m | time: 92.763s
[2K
| Adam | epoch: 001 | loss: 0.54014 - acc: 0.7796 -- iter: 192/569
[A[ATraining Step: 7  | total loss: [1m[32m0.62158[0m[0m | time: 103.024s
[2K
| Adam | epoch: 001 | loss: 0.62158 - acc: 0.7243 -- iter: 224/569
[A[ATraining Step: 8  | total loss: [1m[32m0.62344[0m[0m | time: 113.455s
[2K
| Adam | epoch: 001 | loss: 0.62344 - acc: 0.6685 -- iter: 256/569
[A[ATraining Step: 9  | total loss: [1m[32m0.60019[0m[0m | time: 123.810s
[2K
| Adam | epoch: 001 | loss: 0.60019 - acc: 0.6620 -- iter: 288/569
[A[ATraining Step: 10  | total loss: [1m[32m0.59094[0m[0m | time: 133.967s
[2K
| Adam | epoch: 001 | loss: 0.59094 - acc: 0.6747 -- iter: 320/569
[A[ATraining Step: 11  | total loss: [1m[32m0.57167[0m[0m | time: 144.573s
[2K
| Adam | epoch: 001 | loss: 0.57167 - acc: 0.7104 -- iter: 352/569
[A[ATraining Step: 12  | total loss: [1m[32m0.50576[0m[0m | time: 154.843s
[2K
| Adam | epoch: 001 | loss: 0.50576 - acc: 0.7704 -- iter: 384/569
[A[ATraining Step: 13  | total loss: [1m[32m0.53100[0m[0m | time: 165.141s
[2K
| Adam | epoch: 001 | loss: 0.53100 - acc: 0.7349 -- iter: 416/569
[A[ATraining Step: 14  | total loss: [1m[32m0.46396[0m[0m | time: 175.295s
[2K
| Adam | epoch: 001 | loss: 0.46396 - acc: 0.7666 -- iter: 448/569
[A[ATraining Step: 15  | total loss: [1m[32m0.46012[0m[0m | time: 185.494s
[2K
| Adam | epoch: 001 | loss: 0.46012 - acc: 0.7846 -- iter: 480/569
[A[ATraining Step: 16  | total loss: [1m[32m0.38393[0m[0m | time: 195.929s
[2K
| Adam | epoch: 001 | loss: 0.38393 - acc: 0.8419 -- iter: 512/569
[A[ATraining Step: 17  | total loss: [1m[32m0.34935[0m[0m | time: 206.459s
[2K
| Adam | epoch: 001 | loss: 0.34935 - acc: 0.8763 -- iter: 544/569
[A[ATraining Step: 18  | total loss: [1m[32m0.36553[0m[0m | time: 231.335s
[2K
| Adam | epoch: 001 | loss: 0.36553 - acc: 0.8434 | val_loss: 0.83012 - val_acc: 0.5337 -- iter: 569/569
--
Training Step: 19  | total loss: [1m[32m0.34828[0m[0m | time: 8.844s
[2K
| Adam | epoch: 002 | loss: 0.34828 - acc: 0.8689 -- iter: 032/569
[A[ATraining Step: 20  | total loss: [1m[32m0.27493[0m[0m | time: 19.362s
[2K
| Adam | epoch: 002 | loss: 0.27493 - acc: 0.8982 -- iter: 064/569
[A[ATraining Step: 21  | total loss: [1m[32m0.25119[0m[0m | time: 30.420s
[2K
| Adam | epoch: 002 | loss: 0.25119 - acc: 0.9007 -- iter: 096/569
[A[ATraining Step: 22  | total loss: [1m[32m0.28311[0m[0m | time: 41.032s
[2K
| Adam | epoch: 002 | loss: 0.28311 - acc: 0.8649 -- iter: 128/569
[A[ATraining Step: 23  | total loss: [1m[32m0.31596[0m[0m | time: 51.026s
[2K
| Adam | epoch: 002 | loss: 0.31596 - acc: 0.8587 -- iter: 160/569
[A[ATraining Step: 24  | total loss: [1m[32m0.39803[0m[0m | time: 61.232s
[2K
| Adam | epoch: 002 | loss: 0.39803 - acc: 0.8545 -- iter: 192/569
[A[ATraining Step: 25  | total loss: [1m[32m0.36805[0m[0m | time: 71.736s
[2K
| Adam | epoch: 002 | loss: 0.36805 - acc: 0.8601 -- iter: 224/569
[A[ATraining Step: 26  | total loss: [1m[32m0.35279[0m[0m | time: 82.194s
[2K
| Adam | epoch: 002 | loss: 0.35279 - acc: 0.8723 -- iter: 256/569
[A[ATraining Step: 27  | total loss: [1m[32m0.32579[0m[0m | time: 92.629s
[2K
| Adam | epoch: 002 | loss: 0.32579 - acc: 0.8730 -- iter: 288/569
[A[ATraining Step: 28  | total loss: [1m[32m0.28191[0m[0m | time: 102.776s
[2K
| Adam | epoch: 002 | loss: 0.28191 - acc: 0.8891 -- iter: 320/569
[A[ATraining Step: 29  | total loss: [1m[32m0.27460[0m[0m | time: 113.257s
[2K
| Adam | epoch: 002 | loss: 0.27460 - acc: 0.8933 -- iter: 352/569
[A[ATraining Step: 30  | total loss: [1m[32m0.24983[0m[0m | time: 123.648s
[2K
| Adam | epoch: 002 | loss: 0.24983 - acc: 0.9038 -- iter: 384/569
[A[ATraining Step: 31  | total loss: [1m[32m0.26914[0m[0m | time: 134.261s
[2K
| Adam | epoch: 002 | loss: 0.26914 - acc: 0.9043 -- iter: 416/569
[A[ATraining Step: 32  | total loss: [1m[32m0.28116[0m[0m | time: 144.565s
[2K
| Adam | epoch: 002 | loss: 0.28116 - acc: 0.8977 -- iter: 448/569
[A[ATraining Step: 33  | total loss: [1m[32m0.29817[0m[0m | time: 154.763s
[2K
| Adam | epoch: 002 | loss: 0.29817 - acc: 0.8859 -- iter: 480/569
[A[ATraining Step: 34  | total loss: [1m[32m0.30702[0m[0m | time: 165.192s
[2K
| Adam | epoch: 002 | loss: 0.30702 - acc: 0.8702 -- iter: 512/569
[A[ATraining Step: 35  | total loss: [1m[32m0.27708[0m[0m | time: 175.213s
[2K
| Adam | epoch: 002 | loss: 0.27708 - acc: 0.8908 -- iter: 544/569
[A[ATraining Step: 36  | total loss: [1m[32m0.28889[0m[0m | time: 194.889s
[2K
| Adam | epoch: 002 | loss: 0.28889 - acc: 0.8748 | val_loss: 1.91160 - val_acc: 0.5337 -- iter: 569/569
--
Training Step: 37  | total loss: [1m[32m0.25370[0m[0m | time: 8.753s
[2K
| Adam | epoch: 003 | loss: 0.25370 - acc: 0.8936 -- iter: 032/569
[A[ATraining Step: 38  | total loss: [1m[32m0.28413[0m[0m | time: 17.211s
[2K
| Adam | epoch: 003 | loss: 0.28413 - acc: 0.8753 -- iter: 064/569
[A[ATraining Step: 39  | total loss: [1m[32m0.26252[0m[0m | time: 28.212s
[2K
| Adam | epoch: 003 | loss: 0.26252 - acc: 0.8838 -- iter: 096/569
[A[ATraining Step: 40  | total loss: [1m[32m0.24962[0m[0m | time: 54.463s
[2K
| Adam | epoch: 003 | loss: 0.24962 - acc: 0.8880 -- iter: 128/569
[A[ATraining Step: 41  | total loss: [1m[32m0.26323[0m[0m | time: 111.944s
[2K
| Adam | epoch: 003 | loss: 0.26323 - acc: 0.8799 -- iter: 160/569
[A[ATraining Step: 42  | total loss: [1m[32m0.26414[0m[0m | time: 142.437s
[2K
| Adam | epoch: 003 | loss: 0.26414 - acc: 0.8790 -- iter: 192/569
[A[ATraining Step: 43  | total loss: [1m[32m0.25837[0m[0m | time: 229.265s
[2K
| Adam | epoch: 003 | loss: 0.25837 - acc: 0.8838 -- iter: 224/569
[A[ATraining Step: 44  | total loss: [1m[32m0.25321[0m[0m | time: 293.060s
[2K
| Adam | epoch: 003 | loss: 0.25321 - acc: 0.8931 -- iter: 256/569
[A[ATraining Step: 45  | total loss: [1m[32m0.25547[0m[0m | time: 340.325s
[2K
| Adam | epoch: 003 | loss: 0.25547 - acc: 0.8847 -- iter: 288/569
[A[ATraining Step: 46  | total loss: [1m[32m0.23756[0m[0m | time: 383.278s
[2K
| Adam | epoch: 003 | loss: 0.23756 - acc: 0.8935 -- iter: 320/569
[A[ATraining Step: 47  | total loss: [1m[32m0.24206[0m[0m | time: 423.681s
[2K
| Adam | epoch: 003 | loss: 0.24206 - acc: 0.8956 -- iter: 352/569
[A[ATraining Step: 48  | total loss: [1m[32m0.24229[0m[0m | time: 448.423s
[2K
| Adam | epoch: 003 | loss: 0.24229 - acc: 0.9023 -- iter: 384/569
[A[ATraining Step: 49  | total loss: [1m[32m0.24274[0m[0m | time: 480.115s
[2K
| Adam | epoch: 003 | loss: 0.24274 - acc: 0.8980 -- iter: 416/569
[A[ATraining Step: 50  | total loss: [1m[32m0.22106[0m[0m | time: 499.774s
[2K
| Adam | epoch: 003 | loss: 0.22106 - acc: 0.9090 -- iter: 448/569
[A[ATraining Step: 51  | total loss: [1m[32m0.20421[0m[0m | time: 528.503s
[2K
| Adam | epoch: 003 | loss: 0.20421 - acc: 0.9181 -- iter: 480/569
[A[ATraining Step: 52  | total loss: [1m[32m0.21737[0m[0m | time: 558.851s
[2K
| Adam | epoch: 003 | loss: 0.21737 - acc: 0.9163 -- iter: 512/569
[A[ATraining Step: 53  | total loss: [1m[32m0.20553[0m[0m | time: 596.981s
[2K
| Adam | epoch: 003 | loss: 0.20553 - acc: 0.9241 -- iter: 544/569
[A[ATraining Step: 54  | total loss: [1m[32m0.20346[0m[0m | time: 631.716s
[2K
| Adam | epoch: 003 | loss: 0.20346 - acc: 0.9306 | val_loss: 3.11671 - val_acc: 0.5337 -- iter: 569/569
--
Training Step: 55  | total loss: [1m[32m0.18751[0m[0m | time: 61.583s
[2K
| Adam | epoch: 004 | loss: 0.18751 - acc: 0.9360 -- iter: 032/569
[A[ATraining Step: 56  | total loss: [1m[32m0.16931[0m[0m | time: 77.030s
[2K
| Adam | epoch: 004 | loss: 0.16931 - acc: 0.9450 -- iter: 064/569
[A[ATraining Step: 57  | total loss: [1m[32m0.15440[0m[0m | time: 117.601s
[2K
| Adam | epoch: 004 | loss: 0.15440 - acc: 0.9526 -- iter: 096/569
[A[ATraining Step: 58  | total loss: [1m[32m0.13737[0m[0m | time: 254.209s
[2K
| Adam | epoch: 004 | loss: 0.13737 - acc: 0.9591 -- iter: 128/569
[A[ATraining Step: 59  | total loss: [1m[32m0.13429[0m[0m | time: 342.958s
[2K
| Adam | epoch: 004 | loss: 0.13429 - acc: 0.9562 -- iter: 160/569
[A[ATraining Step: 60  | total loss: [1m[32m0.14027[0m[0m | time: 373.215s
[2K
| Adam | epoch: 004 | loss: 0.14027 - acc: 0.9537 -- iter: 192/569
[A[ATraining Step: 61  | total loss: [1m[32m0.12351[0m[0m | time: 433.983s
[2K
| Adam | epoch: 004 | loss: 0.12351 - acc: 0.9597 -- iter: 224/569
[A[ATraining Step: 62  | total loss: [1m[32m0.11518[0m[0m | time: 458.341s
[2K
| Adam | epoch: 004 | loss: 0.11518 - acc: 0.9609 -- iter: 256/569
[A[ATraining Step: 63  | total loss: [1m[32m0.10675[0m[0m | time: 486.579s
[2K
| Adam | epoch: 004 | loss: 0.10675 - acc: 0.9619 -- iter: 288/569
[A[ATraining Step: 64  | total loss: [1m[32m0.09975[0m[0m | time: 508.565s
[2K
| Adam | epoch: 004 | loss: 0.09975 - acc: 0.9667 -- iter: 320/569
[A[ATraining Step: 65  | total loss: [1m[32m0.09458[0m[0m | time: 531.857s
[2K
| Adam | epoch: 004 | loss: 0.09458 - acc: 0.9669 -- iter: 352/569
[A[ATraining Step: 66  | total loss: [1m[32m0.08757[0m[0m | time: 548.701s
[2K
| Adam | epoch: 004 | loss: 0.08757 - acc: 0.9709 -- iter: 384/569
[A[ATraining Step: 67  | total loss: [1m[32m0.07804[0m[0m | time: 565.728s
[2K
| Adam | epoch: 004 | loss: 0.07804 - acc: 0.9744 -- iter: 416/569
[A[ATraining Step: 68  | total loss: [1m[32m0.07561[0m[0m | time: 582.857s
[2K
| Adam | epoch: 004 | loss: 0.07561 - acc: 0.9738 -- iter: 448/569
[A[ATraining Step: 69  | total loss: [1m[32m0.06985[0m[0m | time: 600.023s
[2K
| Adam | epoch: 004 | loss: 0.06985 - acc: 0.9768 -- iter: 480/569
[A[ATraining Step: 70  | total loss: [1m[32m0.06232[0m[0m | time: 616.981s
[2K
| Adam | epoch: 004 | loss: 0.06232 - acc: 0.9795 -- iter: 512/569
[A[ATraining Step: 71  | total loss: [1m[32m0.05671[0m[0m | time: 634.112s
[2K
| Adam | epoch: 004 | loss: 0.05671 - acc: 0.9818 -- iter: 544/569
[A[ATraining Step: 72  | total loss: [1m[32m0.05744[0m[0m | time: 668.076s
[2K
| Adam | epoch: 004 | loss: 0.05744 - acc: 0.9804 | val_loss: 0.52068 - val_acc: 0.8539 -- iter: 569/569
--
Training Step: 73  | total loss: [1m[32m0.07127[0m[0m | time: 15.766s
[2K
| Adam | epoch: 005 | loss: 0.07127 - acc: 0.9756 -- iter: 032/569
[A[ATraining Step: 74  | total loss: [1m[32m0.06554[0m[0m | time: 26.885s
[2K
| Adam | epoch: 005 | loss: 0.06554 - acc: 0.9783 -- iter: 064/569
[A[ATraining Step: 75  | total loss: [1m[32m0.06335[0m[0m | time: 41.215s
[2K
| Adam | epoch: 005 | loss: 0.06335 - acc: 0.9772 -- iter: 096/569
[A[ATraining Step: 76  | total loss: [1m[32m0.06132[0m[0m | time: 56.035s
[2K
| Adam | epoch: 005 | loss: 0.06132 - acc: 0.9797 -- iter: 128/569
[A[ATraining Step: 77  | total loss: [1m[32m0.05678[0m[0m | time: 68.982s
[2K
| Adam | epoch: 005 | loss: 0.05678 - acc: 0.9818 -- iter: 160/569
[A[ATraining Step: 78  | total loss: [1m[32m0.06418[0m[0m | time: 80.203s
[2K
| Adam | epoch: 005 | loss: 0.06418 - acc: 0.9772 -- iter: 192/569
[A[ATraining Step: 79  | total loss: [1m[32m0.06106[0m[0m | time: 91.591s
[2K
| Adam | epoch: 005 | loss: 0.06106 - acc: 0.9796 -- iter: 224/569
[A[ATraining Step: 80  | total loss: [1m[32m0.05782[0m[0m | time: 102.625s
[2K
| Adam | epoch: 005 | loss: 0.05782 - acc: 0.9816 -- iter: 256/569
[A[ATraining Step: 81  | total loss: [1m[32m0.05306[0m[0m | time: 118.017s
[2K
| Adam | epoch: 005 | loss: 0.05306 - acc: 0.9835 -- iter: 288/569
[A[ATraining Step: 82  | total loss: [1m[32m0.07810[0m[0m | time: 134.643s
[2K
| Adam | epoch: 005 | loss: 0.07810 - acc: 0.9789 -- iter: 320/569
[A[ATraining Step: 83  | total loss: [1m[32m0.07154[0m[0m | time: 151.583s
[2K
| Adam | epoch: 005 | loss: 0.07154 - acc: 0.9810 -- iter: 352/569
[A[ATraining Step: 84  | total loss: [1m[32m0.06975[0m[0m | time: 168.101s
[2K
| Adam | epoch: 005 | loss: 0.06975 - acc: 0.9798 -- iter: 384/569
[A[ATraining Step: 85  | total loss: [1m[32m0.07604[0m[0m | time: 184.925s
[2K
| Adam | epoch: 005 | loss: 0.07604 - acc: 0.9756 -- iter: 416/569
[A[ATraining Step: 86  | total loss: [1m[32m0.07632[0m[0m | time: 201.862s
[2K
| Adam | epoch: 005 | loss: 0.07632 - acc: 0.9749 -- iter: 448/569
[A[ATraining Step: 87  | total loss: [1m[32m0.06985[0m[0m | time: 218.732s
[2K
| Adam | epoch: 005 | loss: 0.06985 - acc: 0.9774 -- iter: 480/569
[A[ATraining Step: 88  | total loss: [1m[32m0.06425[0m[0m | time: 235.029s
[2K
| Adam | epoch: 005 | loss: 0.06425 - acc: 0.9796 -- iter: 512/569
[A[ATraining Step: 89  | total loss: [1m[32m0.06323[0m[0m | time: 251.690s
[2K
| Adam | epoch: 005 | loss: 0.06323 - acc: 0.9786 -- iter: 544/569
[A[ATraining Step: 90  | total loss: [1m[32m0.05942[0m[0m | time: 286.002s
[2K
| Adam | epoch: 005 | loss: 0.05942 - acc: 0.9807 | val_loss: 0.34086 - val_acc: 0.8989 -- iter: 569/569
--
Training Step: 91  | total loss: [1m[32m0.05722[0m[0m | time: 17.325s
[2K
| Adam | epoch: 006 | loss: 0.05722 - acc: 0.9826 -- iter: 032/569
[A[ATraining Step: 92  | total loss: [1m[32m0.05446[0m[0m | time: 34.019s
[2K
| Adam | epoch: 006 | loss: 0.05446 - acc: 0.9844 -- iter: 064/569
[A[ATraining Step: 93  | total loss: [1m[32m0.05114[0m[0m | time: 50.680s
[2K
| Adam | epoch: 006 | loss: 0.05114 - acc: 0.9859 -- iter: 096/569
[A[ATraining Step: 94  | total loss: [1m[32m0.05725[0m[0m | time: 65.061s
[2K
| Adam | epoch: 006 | loss: 0.05725 - acc: 0.9811 -- iter: 128/569
[A[ATraining Step: 95  | total loss: [1m[32m0.09252[0m[0m | time: 79.607s
[2K
| Adam | epoch: 006 | loss: 0.09252 - acc: 0.9790 -- iter: 160/569
[A[ATraining Step: 96  | total loss: [1m[32m0.11649[0m[0m | time: 95.745s
[2K
| Adam | epoch: 006 | loss: 0.11649 - acc: 0.9771 -- iter: 192/569
[A[ATraining Step: 97  | total loss: [1m[32m0.14315[0m[0m | time: 111.571s
[2K
| Adam | epoch: 006 | loss: 0.14315 - acc: 0.9669 -- iter: 224/569
[A[ATraining Step: 98  | total loss: [1m[32m0.14131[0m[0m | time: 128.622s
[2K
| Adam | epoch: 006 | loss: 0.14131 - acc: 0.9639 -- iter: 256/569
[A[ATraining Step: 99  | total loss: [1m[32m0.13117[0m[0m | time: 145.400s
[2K
| Adam | epoch: 006 | loss: 0.13117 - acc: 0.9675 -- iter: 288/569
[A[ATraining Step: 100  | total loss: [1m[32m0.13108[0m[0m | time: 161.968s
[2K
| Adam | epoch: 006 | loss: 0.13108 - acc: 0.9677 -- iter: 320/569
[A[ATraining Step: 101  | total loss: [1m[32m0.13504[0m[0m | time: 178.608s
[2K
| Adam | epoch: 006 | loss: 0.13504 - acc: 0.9678 -- iter: 352/569
[A[ATraining Step: 102  | total loss: [1m[32m0.12627[0m[0m | time: 195.008s
[2K
| Adam | epoch: 006 | loss: 0.12627 - acc: 0.9710 -- iter: 384/569
[A[ATraining Step: 103  | total loss: [1m[32m0.12147[0m[0m | time: 211.372s
[2K
| Adam | epoch: 006 | loss: 0.12147 - acc: 0.9676 -- iter: 416/569
[A[ATraining Step: 104  | total loss: [1m[32m0.11531[0m[0m | time: 227.585s
[2K
| Adam | epoch: 006 | loss: 0.11531 - acc: 0.9678 -- iter: 448/569
[A[ATraining Step: 105  | total loss: [1m[32m0.10927[0m[0m | time: 243.303s
[2K
| Adam | epoch: 006 | loss: 0.10927 - acc: 0.9710 -- iter: 480/569
[A[ATraining Step: 106  | total loss: [1m[32m0.10279[0m[0m | time: 259.370s
[2K
| Adam | epoch: 006 | loss: 0.10279 - acc: 0.9739 -- iter: 512/569
[A[ATraining Step: 107  | total loss: [1m[32m0.11331[0m[0m | time: 275.980s
[2K
| Adam | epoch: 006 | loss: 0.11331 - acc: 0.9671 -- iter: 544/569
[A[ATraining Step: 108  | total loss: [1m[32m0.10436[0m[0m | time: 307.102s
[2K
| Adam | epoch: 006 | loss: 0.10436 - acc: 0.9704 | val_loss: 0.50079 - val_acc: 0.8315 -- iter: 569/569
--
Training Step: 109  | total loss: [1m[32m0.10465[0m[0m | time: 13.154s
[2K
| Adam | epoch: 007 | loss: 0.10465 - acc: 0.9671 -- iter: 032/569
[A[ATraining Step: 110  | total loss: [1m[32m0.09930[0m[0m | time: 26.655s
[2K
| Adam | epoch: 007 | loss: 0.09930 - acc: 0.9673 -- iter: 064/569
[A[ATraining Step: 111  | total loss: [1m[32m0.09166[0m[0m | time: 40.932s
[2K
| Adam | epoch: 007 | loss: 0.09166 - acc: 0.9706 -- iter: 096/569
[A[ATraining Step: 112  | total loss: [1m[32m0.08714[0m[0m | time: 54.733s
[2K
| Adam | epoch: 007 | loss: 0.08714 - acc: 0.9704 -- iter: 128/569
[A[ATraining Step: 113  | total loss: [1m[32m0.08005[0m[0m | time: 62.174s
[2K
| Adam | epoch: 007 | loss: 0.08005 - acc: 0.9733 -- iter: 160/569
[A[ATraining Step: 114  | total loss: [1m[32m0.07544[0m[0m | time: 69.446s
[2K
| Adam | epoch: 007 | loss: 0.07544 - acc: 0.9720 -- iter: 192/569
[A[ATraining Step: 115  | total loss: [1m[32m0.06846[0m[0m | time: 77.911s
[2K
| Adam | epoch: 007 | loss: 0.06846 - acc: 0.9748 -- iter: 224/569
[A[ATraining Step: 116  | total loss: [1m[32m0.07799[0m[0m | time: 86.355s
[2K
| Adam | epoch: 007 | loss: 0.07799 - acc: 0.9742 -- iter: 256/569
[A[ATraining Step: 117  | total loss: [1m[32m0.07347[0m[0m | time: 98.249s
[2K
| Adam | epoch: 007 | loss: 0.07347 - acc: 0.9737 -- iter: 288/569
[A[ATraining Step: 118  | total loss: [1m[32m0.06834[0m[0m | time: 111.659s
[2K
| Adam | epoch: 007 | loss: 0.06834 - acc: 0.9763 -- iter: 320/569
[A[ATraining Step: 119  | total loss: [1m[32m0.06221[0m[0m | time: 124.898s
[2K
| Adam | epoch: 007 | loss: 0.06221 - acc: 0.9787 -- iter: 352/569
[A[ATraining Step: 120  | total loss: [1m[32m0.16701[0m[0m | time: 138.771s
[2K
| Adam | epoch: 007 | loss: 0.16701 - acc: 0.9589 -- iter: 384/569
[A[ATraining Step: 121  | total loss: [1m[32m0.15479[0m[0m | time: 152.398s
[2K
| Adam | epoch: 007 | loss: 0.15479 - acc: 0.9599 -- iter: 416/569
[A[ATraining Step: 122  | total loss: [1m[32m0.17734[0m[0m | time: 165.186s
[2K
| Adam | epoch: 007 | loss: 0.17734 - acc: 0.9577 -- iter: 448/569
[A[ATraining Step: 123  | total loss: [1m[32m0.19232[0m[0m | time: 178.396s
[2K
| Adam | epoch: 007 | loss: 0.19232 - acc: 0.9556 -- iter: 480/569
[A[ATraining Step: 124  | total loss: [1m[32m0.18288[0m[0m | time: 192.135s
[2K
| Adam | epoch: 007 | loss: 0.18288 - acc: 0.9570 -- iter: 512/569
[A[ATraining Step: 125  | total loss: [1m[32m0.16722[0m[0m | time: 205.642s
[2K
| Adam | epoch: 007 | loss: 0.16722 - acc: 0.9613 -- iter: 544/569
[A[ATraining Step: 126  | total loss: [1m[32m0.16322[0m[0m | time: 232.487s
[2K
| Adam | epoch: 007 | loss: 0.16322 - acc: 0.9589 | val_loss: 1.58195 - val_acc: 0.5562 -- iter: 569/569
--
Training Step: 127  | total loss: [1m[32m0.15373[0m[0m | time: 13.363s
[2K
| Adam | epoch: 008 | loss: 0.15373 - acc: 0.9599 -- iter: 032/569
[A[ATraining Step: 128  | total loss: [1m[32m0.14078[0m[0m | time: 26.085s
[2K
| Adam | epoch: 008 | loss: 0.14078 - acc: 0.9639 -- iter: 064/569
[A[ATraining Step: 129  | total loss: [1m[32m0.13848[0m[0m | time: 39.617s
[2K
| Adam | epoch: 008 | loss: 0.13848 - acc: 0.9644 -- iter: 096/569
[A[ATraining Step: 130  | total loss: [1m[32m0.15580[0m[0m | time: 52.239s
[2K
| Adam | epoch: 008 | loss: 0.15580 - acc: 0.9617 -- iter: 128/569
[A[ATraining Step: 131  | total loss: [1m[32m0.14562[0m[0m | time: 65.119s
[2K
| Adam | epoch: 008 | loss: 0.14562 - acc: 0.9624 -- iter: 160/569
[A[ATraining Step: 132  | total loss: [1m[32m0.15933[0m[0m | time: 75.986s
[2K
| Adam | epoch: 008 | loss: 0.15933 - acc: 0.9537 -- iter: 192/569
[A[ATraining Step: 133  | total loss: [1m[32m0.14580[0m[0m | time: 86.822s
[2K
| Adam | epoch: 008 | loss: 0.14580 - acc: 0.9583 -- iter: 224/569
[A[ATraining Step: 134  | total loss: [1m[32m0.13246[0m[0m | time: 100.313s
[2K
| Adam | epoch: 008 | loss: 0.13246 - acc: 0.9625 -- iter: 256/569
[A[ATraining Step: 135  | total loss: [1m[32m0.12109[0m[0m | time: 114.013s
[2K
| Adam | epoch: 008 | loss: 0.12109 - acc: 0.9662 -- iter: 288/569
[A[ATraining Step: 136  | total loss: [1m[32m0.11107[0m[0m | time: 127.066s
[2K
| Adam | epoch: 008 | loss: 0.11107 - acc: 0.9696 -- iter: 320/569
[A[ATraining Step: 137  | total loss: [1m[32m0.10184[0m[0m | time: 139.966s
[2K
| Adam | epoch: 008 | loss: 0.10184 - acc: 0.9726 -- iter: 352/569
[A[ATraining Step: 138  | total loss: [1m[32m0.15022[0m[0m | time: 153.698s
[2K
| Adam | epoch: 008 | loss: 0.15022 - acc: 0.9472 -- iter: 384/569
[A[ATraining Step: 139  | total loss: [1m[32m0.43338[0m[0m | time: 167.211s
[2K
| Adam | epoch: 008 | loss: 0.43338 - acc: 0.9088 -- iter: 416/569
[A[ATraining Step: 140  | total loss: [1m[32m0.40827[0m[0m | time: 180.736s
[2K
| Adam | epoch: 008 | loss: 0.40827 - acc: 0.9085 -- iter: 448/569
[A[ATraining Step: 141  | total loss: [1m[32m0.37373[0m[0m | time: 194.269s
[2K
| Adam | epoch: 008 | loss: 0.37373 - acc: 0.9145 -- iter: 480/569
[A[ATraining Step: 142  | total loss: [1m[32m0.34127[0m[0m | time: 207.440s
[2K
| Adam | epoch: 008 | loss: 0.34127 - acc: 0.9231 -- iter: 512/569
[A[ATraining Step: 143  | total loss: [1m[32m0.31088[0m[0m | time: 220.853s
[2K
| Adam | epoch: 008 | loss: 0.31088 - acc: 0.9308 -- iter: 544/569
[A[ATraining Step: 144  | total loss: [1m[32m0.28326[0m[0m | time: 247.953s
[2K
| Adam | epoch: 008 | loss: 0.28326 - acc: 0.9377 | val_loss: 0.86787 - val_acc: 0.7135 -- iter: 569/569
--
Training Step: 145  | total loss: [1m[32m0.26001[0m[0m | time: 13.821s
[2K
| Adam | epoch: 009 | loss: 0.26001 - acc: 0.9439 -- iter: 032/569
[A[ATraining Step: 146  | total loss: [1m[32m0.25601[0m[0m | time: 27.797s
[2K
| Adam | epoch: 009 | loss: 0.25601 - acc: 0.9464 -- iter: 064/569
[A[ATraining Step: 147  | total loss: [1m[32m0.23328[0m[0m | time: 42.245s
[2K
| Adam | epoch: 009 | loss: 0.23328 - acc: 0.9518 -- iter: 096/569
[A[ATraining Step: 148  | total loss: [1m[32m0.23106[0m[0m | time: 52.425s
[2K
| Adam | epoch: 009 | loss: 0.23106 - acc: 0.9472 -- iter: 128/569
[A[ATraining Step: 149  | total loss: [1m[32m0.21350[0m[0m | time: 60.967s
[2K
| Adam | epoch: 009 | loss: 0.21350 - acc: 0.9525 -- iter: 160/569
[A[ATraining Step: 150  | total loss: [1m[32m0.20207[0m[0m | time: 69.661s
[2K
| Adam | epoch: 009 | loss: 0.20207 - acc: 0.9541 -- iter: 192/569
[A[ATraining Step: 151  | total loss: [1m[32m0.18912[0m[0m | time: 80.447s
[2K
| Adam | epoch: 009 | loss: 0.18912 - acc: 0.9556 -- iter: 224/569
[A[ATraining Step: 152  | total loss: [1m[32m0.17291[0m[0m | time: 90.621s
[2K
| Adam | epoch: 009 | loss: 0.17291 - acc: 0.9600 -- iter: 256/569
[A[ATraining Step: 153  | total loss: [1m[32m0.15823[0m[0m | time: 103.216s
[2K
| Adam | epoch: 009 | loss: 0.15823 - acc: 0.9640 -- iter: 288/569
[A[ATraining Step: 154  | total loss: [1m[32m0.15692[0m[0m | time: 117.110s
[2K
| Adam | epoch: 009 | loss: 0.15692 - acc: 0.9645 -- iter: 320/569
[A[ATraining Step: 155  | total loss: [1m[32m0.15503[0m[0m | time: 130.980s
[2K
| Adam | epoch: 009 | loss: 0.15503 - acc: 0.9649 -- iter: 352/569
[A[ATraining Step: 156  | total loss: [1m[32m0.18698[0m[0m | time: 144.127s
[2K
| Adam | epoch: 009 | loss: 0.18698 - acc: 0.9528 -- iter: 384/569
[A[ATraining Step: 157  | total loss: [1m[32m0.17039[0m[0m | time: 157.407s
[2K
| Adam | epoch: 009 | loss: 0.17039 - acc: 0.9575 -- iter: 416/569
[A[ATraining Step: 158  | total loss: [1m[32m0.18261[0m[0m | time: 170.668s
[2K
| Adam | epoch: 009 | loss: 0.18261 - acc: 0.9524 -- iter: 448/569
[A[ATraining Step: 159  | total loss: [1m[32m0.17901[0m[0m | time: 184.437s
[2K
| Adam | epoch: 009 | loss: 0.17901 - acc: 0.9509 -- iter: 480/569
[A[ATraining Step: 160  | total loss: [1m[32m0.16284[0m[0m | time: 197.348s
[2K
| Adam | epoch: 009 | loss: 0.16284 - acc: 0.9558 -- iter: 512/569
[A[ATraining Step: 161  | total loss: [1m[32m0.14972[0m[0m | time: 210.723s
[2K
| Adam | epoch: 009 | loss: 0.14972 - acc: 0.9602 -- iter: 544/569
[A[ATraining Step: 162  | total loss: [1m[32m0.13892[0m[0m | time: 237.268s
[2K
| Adam | epoch: 009 | loss: 0.13892 - acc: 0.9642 | val_loss: 2.37478 - val_acc: 0.5281 -- iter: 569/569
--
Training Step: 163  | total loss: [1m[32m0.16607[0m[0m | time: 13.421s
[2K
| Adam | epoch: 010 | loss: 0.16607 - acc: 0.9428 -- iter: 032/569
[A[ATraining Step: 164  | total loss: [1m[32m0.15469[0m[0m | time: 26.417s
[2K
| Adam | epoch: 010 | loss: 0.15469 - acc: 0.9485 -- iter: 064/569
[A[ATraining Step: 165  | total loss: [1m[32m0.14537[0m[0m | time: 39.867s
[2K
| Adam | epoch: 010 | loss: 0.14537 - acc: 0.9505 -- iter: 096/569
[A[ATraining Step: 166  | total loss: [1m[32m0.13498[0m[0m | time: 53.122s
[2K
| Adam | epoch: 010 | loss: 0.13498 - acc: 0.9555 -- iter: 128/569
[A[ATraining Step: 167  | total loss: [1m[32m0.12521[0m[0m | time: 66.602s
[2K
| Adam | epoch: 010 | loss: 0.12521 - acc: 0.9599 -- iter: 160/569
[A[ATraining Step: 168  | total loss: [1m[32m0.12537[0m[0m | time: 80.386s
[2K
| Adam | epoch: 010 | loss: 0.12537 - acc: 0.9577 -- iter: 192/569
[A[ATraining Step: 169  | total loss: [1m[32m0.11934[0m[0m | time: 93.692s
[2K
| Adam | epoch: 010 | loss: 0.11934 - acc: 0.9588 -- iter: 224/569
[A[ATraining Step: 170  | total loss: [1m[32m0.12831[0m[0m | time: 105.426s
[2K
| Adam | epoch: 010 | loss: 0.12831 - acc: 0.9567 -- iter: 256/569
[A[ATraining Step: 171  | total loss: [1m[32m0.12165[0m[0m | time: 116.648s
[2K
| Adam | epoch: 010 | loss: 0.12165 - acc: 0.9610 -- iter: 288/569
[A[ATraining Step: 172  | total loss: [1m[32m0.11391[0m[0m | time: 129.842s
[2K
| Adam | epoch: 010 | loss: 0.11391 - acc: 0.9649 -- iter: 320/569
[A[ATraining Step: 173  | total loss: [1m[32m0.13356[0m[0m | time: 143.304s
[2K
| Adam | epoch: 010 | loss: 0.13356 - acc: 0.9590 -- iter: 352/569
[A[ATraining Step: 174  | total loss: [1m[32m0.12334[0m[0m | time: 156.990s
[2K
| Adam | epoch: 010 | loss: 0.12334 - acc: 0.9631 -- iter: 384/569
[A[ATraining Step: 175  | total loss: [1m[32m0.11936[0m[0m | time: 170.242s
[2K
| Adam | epoch: 010 | loss: 0.11936 - acc: 0.9637 -- iter: 416/569
[A[ATraining Step: 176  | total loss: [1m[32m0.12104[0m[0m | time: 184.418s
[2K
| Adam | epoch: 010 | loss: 0.12104 - acc: 0.9611 -- iter: 448/569
[A[ATraining Step: 177  | total loss: [1m[32m0.15728[0m[0m | time: 197.723s
[2K
| Adam | epoch: 010 | loss: 0.15728 - acc: 0.9587 -- iter: 480/569
[A[ATraining Step: 178  | total loss: [1m[32m0.14340[0m[0m | time: 211.026s
[2K
| Adam | epoch: 010 | loss: 0.14340 - acc: 0.9628 -- iter: 512/569
[A[ATraining Step: 179  | total loss: [1m[32m0.13115[0m[0m | time: 224.230s
[2K
| Adam | epoch: 010 | loss: 0.13115 - acc: 0.9666 -- iter: 544/569
[A[ATraining Step: 180  | total loss: [1m[32m0.11950[0m[0m | time: 251.364s
[2K
| Adam | epoch: 010 | loss: 0.11950 - acc: 0.9699 | val_loss: 0.32975 - val_acc: 0.9101 -- iter: 569/569
--
Training Step: 181  | total loss: [1m[32m0.10887[0m[0m | time: 14.546s
[2K
| Adam | epoch: 011 | loss: 0.10887 - acc: 0.9729 -- iter: 032/569
[A[ATraining Step: 182  | total loss: [1m[32m0.10316[0m[0m | time: 27.295s
[2K
| Adam | epoch: 011 | loss: 0.10316 - acc: 0.9725 -- iter: 064/569
[A[ATraining Step: 183  | total loss: [1m[32m0.09366[0m[0m | time: 35.987s
[2K
| Adam | epoch: 011 | loss: 0.09366 - acc: 0.9752 -- iter: 096/569
[A[ATraining Step: 184  | total loss: [1m[32m0.08576[0m[0m | time: 44.481s
[2K
| Adam | epoch: 011 | loss: 0.08576 - acc: 0.9777 -- iter: 128/569
[A[ATraining Step: 185  | total loss: [1m[32m0.07884[0m[0m | time: 55.727s
[2K
| Adam | epoch: 011 | loss: 0.07884 - acc: 0.9800 -- iter: 160/569
[A[ATraining Step: 186  | total loss: [1m[32m0.07566[0m[0m | time: 68.981s
[2K
| Adam | epoch: 011 | loss: 0.07566 - acc: 0.9820 -- iter: 192/569
[A[ATraining Step: 187  | total loss: [1m[32m0.08532[0m[0m | time: 81.897s
[2K
| Adam | epoch: 011 | loss: 0.08532 - acc: 0.9775 -- iter: 224/569
[A[ATraining Step: 188  | total loss: [1m[32m0.08036[0m[0m | time: 94.570s
[2K
| Adam | epoch: 011 | loss: 0.08036 - acc: 0.9766 -- iter: 256/569
[A[ATraining Step: 189  | total loss: [1m[32m0.07746[0m[0m | time: 106.008s
[2K
| Adam | epoch: 011 | loss: 0.07746 - acc: 0.9790 -- iter: 288/569
[A[ATraining Step: 190  | total loss: [1m[32m0.07056[0m[0m | time: 117.029s
[2K
| Adam | epoch: 011 | loss: 0.07056 - acc: 0.9811 -- iter: 320/569
[A[ATraining Step: 191  | total loss: [1m[32m0.06413[0m[0m | time: 130.196s
[2K
| Adam | epoch: 011 | loss: 0.06413 - acc: 0.9830 -- iter: 352/569
[A[ATraining Step: 192  | total loss: [1m[32m0.05989[0m[0m | time: 143.214s
[2K
| Adam | epoch: 011 | loss: 0.05989 - acc: 0.9847 -- iter: 384/569
[A[ATraining Step: 193  | total loss: [1m[32m0.05626[0m[0m | time: 156.450s
[2K
| Adam | epoch: 011 | loss: 0.05626 - acc: 0.9862 -- iter: 416/569
[A[ATraining Step: 194  | total loss: [1m[32m0.05153[0m[0m | time: 169.702s
[2K
| Adam | epoch: 011 | loss: 0.05153 - acc: 0.9876 -- iter: 448/569
[A[ATraining Step: 195  | total loss: [1m[32m0.06158[0m[0m | time: 183.096s
[2K
| Adam | epoch: 011 | loss: 0.06158 - acc: 0.9826 -- iter: 480/569
[A[ATraining Step: 196  | total loss: [1m[32m0.09844[0m[0m | time: 197.188s
[2K
| Adam | epoch: 011 | loss: 0.09844 - acc: 0.9781 -- iter: 512/569
[A[ATraining Step: 197  | total loss: [1m[32m0.09232[0m[0m | time: 211.296s
[2K
| Adam | epoch: 011 | loss: 0.09232 - acc: 0.9771 -- iter: 544/569
[A[ATraining Step: 198  | total loss: [1m[32m0.08453[0m[0m | time: 238.015s
[2K
| Adam | epoch: 011 | loss: 0.08453 - acc: 0.9794 | val_loss: 2.45749 - val_acc: 0.5393 -- iter: 569/569
--
Training Step: 199  | total loss: [1m[32m0.07791[0m[0m | time: 13.489s
[2K
| Adam | epoch: 012 | loss: 0.07791 - acc: 0.9815 -- iter: 032/569
[A[ATraining Step: 200  | total loss: [1m[32m0.07107[0m[0m | time: 41.002s
[2K
| Adam | epoch: 012 | loss: 0.07107 - acc: 0.9833 | val_loss: 1.27820 - val_acc: 0.6124 -- iter: 064/569
--
Training Step: 201  | total loss: [1m[32m0.06799[0m[0m | time: 54.655s
[2K
| Adam | epoch: 012 | loss: 0.06799 - acc: 0.9850 -- iter: 096/569
[A[ATraining Step: 202  | total loss: [1m[32m0.06696[0m[0m | time: 68.154s
[2K
| Adam | epoch: 012 | loss: 0.06696 - acc: 0.9834 -- iter: 128/569
[A[ATraining Step: 203  | total loss: [1m[32m0.07428[0m[0m | time: 82.251s
[2K
| Adam | epoch: 012 | loss: 0.07428 - acc: 0.9788 -- iter: 160/569
[A[ATraining Step: 204  | total loss: [1m[32m0.06778[0m[0m | time: 95.599s
[2K
| Adam | epoch: 012 | loss: 0.06778 - acc: 0.9809 -- iter: 192/569
[A[ATraining Step: 205  | total loss: [1m[32m0.06338[0m[0m | time: 108.996s
[2K
| Adam | epoch: 012 | loss: 0.06338 - acc: 0.9828 -- iter: 224/569
[A[ATraining Step: 206  | total loss: [1m[32m0.05871[0m[0m | time: 122.699s
[2K
| Adam | epoch: 012 | loss: 0.05871 - acc: 0.9845 -- iter: 256/569
[A[ATraining Step: 207  | total loss: [1m[32m0.05400[0m[0m | time: 136.331s
[2K
| Adam | epoch: 012 | loss: 0.05400 - acc: 0.9861 -- iter: 288/569
[A[ATraining Step: 208  | total loss: [1m[32m0.04972[0m[0m | time: 147.651s
[2K
| Adam | epoch: 012 | loss: 0.04972 - acc: 0.9875 -- iter: 320/569
[A[ATraining Step: 209  | total loss: [1m[32m0.05099[0m[0m | time: 158.940s
[2K
| Adam | epoch: 012 | loss: 0.05099 - acc: 0.9847 -- iter: 352/569
[A[ATraining Step: 210  | total loss: [1m[32m0.04772[0m[0m | time: 172.874s
[2K
| Adam | epoch: 012 | loss: 0.04772 - acc: 0.9863 -- iter: 384/569
[A[ATraining Step: 211  | total loss: [1m[32m0.06513[0m[0m | time: 186.271s
[2K
| Adam | epoch: 012 | loss: 0.06513 - acc: 0.9783 -- iter: 416/569
[A[ATraining Step: 212  | total loss: [1m[32m0.06420[0m[0m | time: 199.656s
[2K
| Adam | epoch: 012 | loss: 0.06420 - acc: 0.9773 -- iter: 448/569
[A[ATraining Step: 213  | total loss: [1m[32m0.06547[0m[0m | time: 213.467s
[2K
| Adam | epoch: 012 | loss: 0.06547 - acc: 0.9764 -- iter: 480/569
[A[ATraining Step: 214  | total loss: [1m[32m0.06191[0m[0m | time: 226.503s
[2K
| Adam | epoch: 012 | loss: 0.06191 - acc: 0.9788 -- iter: 512/569
[A[ATraining Step: 215  | total loss: [1m[32m0.06095[0m[0m | time: 240.268s
[2K
| Adam | epoch: 012 | loss: 0.06095 - acc: 0.9778 -- iter: 544/569
[A[ATraining Step: 216  | total loss: [1m[32m0.05547[0m[0m | time: 268.829s
[2K
| Adam | epoch: 012 | loss: 0.05547 - acc: 0.9800 | val_loss: 1.47292 - val_acc: 0.6854 -- iter: 569/569
--
Training Step: 217  | total loss: [1m[32m0.05048[0m[0m | time: 10.055s
[2K
| Adam | epoch: 013 | loss: 0.05048 - acc: 0.9820 -- iter: 032/569
[A[ATraining Step: 218  | total loss: [1m[32m0.04632[0m[0m | time: 24.165s
[2K
| Adam | epoch: 013 | loss: 0.04632 - acc: 0.9838 -- iter: 064/569
[A[ATraining Step: 219  | total loss: [1m[32m0.04946[0m[0m | time: 37.883s
[2K
| Adam | epoch: 013 | loss: 0.04946 - acc: 0.9823 -- iter: 096/569
[A[ATraining Step: 220  | total loss: [1m[32m0.04517[0m[0m | time: 51.219s
[2K
| Adam | epoch: 013 | loss: 0.04517 - acc: 0.9841 -- iter: 128/569
[A[ATraining Step: 221  | total loss: [1m[32m0.04171[0m[0m | time: 63.813s
[2K
| Adam | epoch: 013 | loss: 0.04171 - acc: 0.9857 -- iter: 160/569
[A[ATraining Step: 222  | total loss: [1m[32m0.04147[0m[0m | time: 77.676s
[2K
| Adam | epoch: 013 | loss: 0.04147 - acc: 0.9840 -- iter: 192/569
[A[ATraining Step: 223  | total loss: [1m[32m0.03812[0m[0m | time: 91.381s
[2K
| Adam | epoch: 013 | loss: 0.03812 - acc: 0.9856 -- iter: 224/569
[A[ATraining Step: 224  | total loss: [1m[32m0.03731[0m[0m | time: 105.191s
[2K
| Adam | epoch: 013 | loss: 0.03731 - acc: 0.9839 -- iter: 256/569
[A[ATraining Step: 225  | total loss: [1m[32m0.03476[0m[0m | time: 119.267s
[2K
| Adam | epoch: 013 | loss: 0.03476 - acc: 0.9855 -- iter: 288/569
[A[ATraining Step: 226  | total loss: [1m[32m0.08315[0m[0m | time: 132.614s
[2K
| Adam | epoch: 013 | loss: 0.08315 - acc: 0.9713 -- iter: 320/569
[A[ATraining Step: 227  | total loss: [1m[32m0.07513[0m[0m | time: 144.667s
[2K
| Adam | epoch: 013 | loss: 0.07513 - acc: 0.9742 -- iter: 352/569
[A[ATraining Step: 228  | total loss: [1m[32m0.06914[0m[0m | time: 156.806s
[2K
| Adam | epoch: 013 | loss: 0.06914 - acc: 0.9768 -- iter: 384/569
[A[ATraining Step: 229  | total loss: [1m[32m0.06317[0m[0m | time: 166.200s
[2K
| Adam | epoch: 013 | loss: 0.06317 - acc: 0.9791 -- iter: 416/569
[A[ATraining Step: 230  | total loss: [1m[32m0.05758[0m[0m | time: 176.542s
[2K
| Adam | epoch: 013 | loss: 0.05758 - acc: 0.9812 -- iter: 448/569
[A[ATraining Step: 231  | total loss: [1m[32m0.05369[0m[0m | time: 189.896s
[2K
| Adam | epoch: 013 | loss: 0.05369 - acc: 0.9831 -- iter: 480/569
[A[ATraining Step: 232  | total loss: [1m[32m0.05648[0m[0m | time: 203.399s
[2K
| Adam | epoch: 013 | loss: 0.05648 - acc: 0.9816 -- iter: 512/569
[A[ATraining Step: 233  | total loss: [1m[32m0.05539[0m[0m | time: 216.779s
[2K
| Adam | epoch: 013 | loss: 0.05539 - acc: 0.9804 -- iter: 544/569
[A[ATraining Step: 234  | total loss: [1m[32m0.39055[0m[0m | time: 243.911s
[2K
| Adam | epoch: 013 | loss: 0.39055 - acc: 0.9292 | val_loss: 1.08797 - val_acc: 0.7247 -- iter: 569/569
--
Training Step: 235  | total loss: [1m[32m0.35350[0m[0m | time: 13.414s
[2K
| Adam | epoch: 014 | loss: 0.35350 - acc: 0.9363 -- iter: 032/569
[A[ATraining Step: 236  | total loss: [1m[32m0.32217[0m[0m | time: 26.907s
[2K
| Adam | epoch: 014 | loss: 0.32217 - acc: 0.9395 -- iter: 064/569
[A[ATraining Step: 237  | total loss: [1m[32m0.29154[0m[0m | time: 40.613s
[2K
| Adam | epoch: 014 | loss: 0.29154 - acc: 0.9456 -- iter: 096/569
[A[ATraining Step: 238  | total loss: [1m[32m0.26480[0m[0m | time: 54.294s
[2K
| Adam | epoch: 014 | loss: 0.26480 - acc: 0.9510 -- iter: 128/569
[A[ATraining Step: 239  | total loss: [1m[32m0.25838[0m[0m | time: 67.835s
[2K
| Adam | epoch: 014 | loss: 0.25838 - acc: 0.9403 -- iter: 160/569
[A[ATraining Step: 240  | total loss: [1m[32m0.24281[0m[0m | time: 81.519s
[2K
| Adam | epoch: 014 | loss: 0.24281 - acc: 0.9431 -- iter: 192/569
[A[ATraining Step: 241  | total loss: [1m[32m0.22130[0m[0m | time: 95.161s
[2K
| Adam | epoch: 014 | loss: 0.22130 - acc: 0.9488 -- iter: 224/569
[A[ATraining Step: 242  | total loss: [1m[32m0.20923[0m[0m | time: 108.692s
[2K
| Adam | epoch: 014 | loss: 0.20923 - acc: 0.9508 -- iter: 256/569
[A[ATraining Step: 243  | total loss: [1m[32m0.19250[0m[0m | time: 121.636s
[2K
| Adam | epoch: 014 | loss: 0.19250 - acc: 0.9557 -- iter: 288/569
[A[ATraining Step: 244  | total loss: [1m[32m0.17708[0m[0m | time: 135.235s
[2K
| Adam | epoch: 014 | loss: 0.17708 - acc: 0.9602 -- iter: 320/569
[A[ATraining Step: 245  | total loss: [1m[32m0.16656[0m[0m | time: 148.528s
[2K
| Adam | epoch: 014 | loss: 0.16656 - acc: 0.9610 -- iter: 352/569
[A[ATraining Step: 246  | total loss: [1m[32m0.15662[0m[0m | time: 159.966s
[2K
| Adam | epoch: 014 | loss: 0.15662 - acc: 0.9618 -- iter: 384/569
[A[ATraining Step: 247  | total loss: [1m[32m0.15963[0m[0m | time: 171.471s
[2K
| Adam | epoch: 014 | loss: 0.15963 - acc: 0.9576 -- iter: 416/569
[A[ATraining Step: 248  | total loss: [1m[32m0.14703[0m[0m | time: 184.895s
[2K
| Adam | epoch: 014 | loss: 0.14703 - acc: 0.9618 -- iter: 448/569
[A[ATraining Step: 249  | total loss: [1m[32m0.15539[0m[0m | time: 198.418s
[2K
| Adam | epoch: 014 | loss: 0.15539 - acc: 0.9532 -- iter: 480/569
[A[ATraining Step: 250  | total loss: [1m[32m0.14596[0m[0m | time: 212.440s
[2K
| Adam | epoch: 014 | loss: 0.14596 - acc: 0.9547 -- iter: 512/569
[A[ATraining Step: 251  | total loss: [1m[32m0.13283[0m[0m | time: 225.751s
[2K
| Adam | epoch: 014 | loss: 0.13283 - acc: 0.9593 -- iter: 544/569
[A[ATraining Step: 252  | total loss: [1m[32m0.12592[0m[0m | time: 253.313s
[2K
| Adam | epoch: 014 | loss: 0.12592 - acc: 0.9602 | val_loss: 0.55800 - val_acc: 0.8483 -- iter: 569/569
--
Training Step: 253  | total loss: [1m[32m0.12033[0m[0m | time: 13.215s
[2K
| Adam | epoch: 015 | loss: 0.12033 - acc: 0.9611 -- iter: 032/569
[A[ATraining Step: 254  | total loss: [1m[32m0.11113[0m[0m | time: 22.262s
[2K
| Adam | epoch: 015 | loss: 0.11113 - acc: 0.9650 -- iter: 064/569
[A[ATraining Step: 255  | total loss: [1m[32m0.10102[0m[0m | time: 31.138s
[2K
| Adam | epoch: 015 | loss: 0.10102 - acc: 0.9685 -- iter: 096/569
[A[ATraining Step: 256  | total loss: [1m[32m0.09743[0m[0m | time: 42.470s
[2K
| Adam | epoch: 015 | loss: 0.09743 - acc: 0.9685 -- iter: 128/569
[A[ATraining Step: 257  | total loss: [1m[32m0.08926[0m[0m | time: 55.893s
[2K
| Adam | epoch: 015 | loss: 0.08926 - acc: 0.9716 -- iter: 160/569
[A[ATraining Step: 258  | total loss: [1m[32m0.08149[0m[0m | time: 69.597s
[2K
| Adam | epoch: 015 | loss: 0.08149 - acc: 0.9745 -- iter: 192/569
[A[ATraining Step: 259  | total loss: [1m[32m0.07623[0m[0m | time: 83.317s
[2K
| Adam | epoch: 015 | loss: 0.07623 - acc: 0.9770 -- iter: 224/569
[A[ATraining Step: 260  | total loss: [1m[32m0.07055[0m[0m | time: 96.124s
[2K
| Adam | epoch: 015 | loss: 0.07055 - acc: 0.9793 -- iter: 256/569
[A[ATraining Step: 261  | total loss: [1m[32m0.08037[0m[0m | time: 109.138s
[2K
| Adam | epoch: 015 | loss: 0.08037 - acc: 0.9751 -- iter: 288/569
[A[ATraining Step: 262  | total loss: [1m[32m0.07478[0m[0m | time: 122.797s
[2K
| Adam | epoch: 015 | loss: 0.07478 - acc: 0.9776 -- iter: 320/569
[A[ATraining Step: 263  | total loss: [1m[32m0.07184[0m[0m | time: 136.326s
[2K
| Adam | epoch: 015 | loss: 0.07184 - acc: 0.9767 -- iter: 352/569
[A[ATraining Step: 264  | total loss: [1m[32m0.06711[0m[0m | time: 150.026s
[2K
| Adam | epoch: 015 | loss: 0.06711 - acc: 0.9791 -- iter: 384/569
[A[ATraining Step: 265  | total loss: [1m[32m0.07083[0m[0m | time: 161.440s
[2K
| Adam | epoch: 015 | loss: 0.07083 - acc: 0.9780 -- iter: 416/569
[A[ATraining Step: 266  | total loss: [1m[32m0.06478[0m[0m | time: 172.766s
[2K
| Adam | epoch: 015 | loss: 0.06478 - acc: 0.9802 -- iter: 448/569
[A[ATraining Step: 267  | total loss: [1m[32m0.05951[0m[0m | time: 185.965s
[2K
| Adam | epoch: 015 | loss: 0.05951 - acc: 0.9822 -- iter: 480/569
[A[ATraining Step: 268  | total loss: [1m[32m0.05447[0m[0m | time: 199.232s
[2K
| Adam | epoch: 015 | loss: 0.05447 - acc: 0.9840 -- iter: 512/569
[A[ATraining Step: 269  | total loss: [1m[32m0.05830[0m[0m | time: 212.642s
[2K
| Adam | epoch: 015 | loss: 0.05830 - acc: 0.9825 -- iter: 544/569
[A[ATraining Step: 270  | total loss: [1m[32m0.05644[0m[0m | time: 239.366s
[2K
| Adam | epoch: 015 | loss: 0.05644 - acc: 0.9811 | val_loss: 0.33632 - val_acc: 0.9045 -- iter: 569/569
--
Validation AUC:0.9639822447685479
Validation AUPRC:0.9469677276725523
Test AUC:0.9645202020202019
Test AUPRC:0.9666477293927764
BestTestF1Score	0.92	0.83	0.92	0.9	0.93	84	9	79	6	0.87
BestTestMCCScore	0.92	0.83	0.92	0.9	0.93	84	9	79	6	0.87
BestTestAccuracyScore	0.92	0.83	0.92	0.9	0.93	84	9	79	6	0.87
BestValidationF1Score	0.92	0.84	0.92	0.9	0.94	78	9	86	5	0.87
BestValidationMCC	0.92	0.84	0.92	0.9	0.94	78	9	86	5	0.87
BestValidationAccuracy	0.92	0.84	0.92	0.9	0.94	78	9	86	5	0.87
TestPredictions (Threshold:0.87)
CHEMBL1237300,TP,ACT,1.0	CHEMBL380054,TN,INACT,0.009999999776482582	CHEMBL271095,TP,ACT,1.0	CHEMBL156814,TN,INACT,0.0	CHEMBL521777,TP,ACT,0.9300000071525574	CHEMBL1645155,TP,ACT,1.0	CHEMBL300926,TN,INACT,0.18000000715255737	CHEMBL1644002,TP,ACT,0.9900000095367432	CHEMBL111218,TN,INACT,0.0	CHEMBL302150,TN,INACT,0.0	CHEMBL467632,TP,ACT,0.9800000190734863	CHEMBL423405,TN,INACT,0.0	CHEMBL42359,TN,INACT,0.0	CHEMBL279225,TN,INACT,0.019999999552965164	CHEMBL595265,TN,INACT,0.0	CHEMBL294087,TN,INACT,0.0	CHEMBL323175,TN,INACT,0.0	CHEMBL91063,TP,ACT,0.9900000095367432	CHEMBL593861,TN,INACT,0.0	CHEMBL332405,TN,INACT,0.07000000029802322	CHEMBL91537,TP,ACT,1.0	CHEMBL398827,TP,ACT,0.9900000095367432	CHEMBL272363,TP,ACT,1.0	CHEMBL398947,TP,ACT,1.0	CHEMBL248678,TP,ACT,1.0	CHEMBL220821,TP,ACT,0.9800000190734863	CHEMBL404199,TP,ACT,1.0	CHEMBL110695,TN,INACT,0.0	CHEMBL3600788,FN,ACT,0.05999999865889549	CHEMBL2096894,TP,ACT,0.9800000190734863	CHEMBL21937,TN,INACT,0.0	CHEMBL446098,TP,ACT,1.0	CHEMBL80438,TN,INACT,0.0	CHEMBL1910022,TP,ACT,0.9900000095367432	CHEMBL1645141,TP,ACT,0.9399999976158142	CHEMBL45875,TN,INACT,0.0	CHEMBL1910025,TP,ACT,1.0	CHEMBL394642,TN,INACT,0.14000000059604645	CHEMBL218699,TP,ACT,1.0	CHEMBL1237302,TP,ACT,1.0	CHEMBL258332,TP,ACT,1.0	CHEMBL132589,TP,ACT,1.0	CHEMBL14334,TP,ACT,1.0	CHEMBL3752948,TP,ACT,1.0	CHEMBL61120,TN,INACT,0.0	CHEMBL218228,TP,ACT,1.0	CHEMBL39879,TN,INACT,0.0	CHEMBL43330,FP,INACT,0.949999988079071	CHEMBL2062858,TN,INACT,0.03999999910593033	CHEMBL294349,TN,INACT,0.0	CHEMBL125588,TP,ACT,1.0	CHEMBL479664,TP,ACT,0.9599999785423279	CHEMBL140495,TN,INACT,0.009999999776482582	CHEMBL87797,TP,ACT,1.0	CHEMBL3804978,TP,ACT,0.9800000190734863	CHEMBL76360,TN,INACT,0.0	CHEMBL3260460,TP,ACT,0.9800000190734863	CHEMBL1643998,TP,ACT,0.9300000071525574	CHEMBL62716,TN,INACT,0.0	CHEMBL2322893,TN,INACT,0.019999999552965164	CHEMBL3753788,TP,ACT,1.0	CHEMBL191638,TP,ACT,1.0	CHEMBL217988,TP,ACT,1.0	CHEMBL72738,TN,INACT,0.009999999776482582	CHEMBL112417,TN,INACT,0.0	CHEMBL251504,TP,ACT,0.9700000286102295	CHEMBL109206,TN,INACT,0.0	CHEMBL313700,FN,ACT,0.8199999928474426	CHEMBL90491,FP,INACT,1.0	CHEMBL1669016,TP,ACT,1.0	CHEMBL1669010,TP,ACT,1.0	CHEMBL297139,TP,ACT,0.9700000286102295	CHEMBL249952,TP,ACT,1.0	CHEMBL10808,TN,INACT,0.009999999776482582	CHEMBL423918,FP,INACT,0.9300000071525574	CHEMBL1907840,FP,INACT,0.9399999976158142	CHEMBL414570,TN,INACT,0.0	CHEMBL314812,FN,ACT,0.0	CHEMBL3260772,FN,ACT,0.009999999776482582	CHEMBL357077,TN,INACT,0.0	CHEMBL545363,TN,INACT,0.019999999552965164	CHEMBL3260428,TP,ACT,1.0	CHEMBL1259241,TN,INACT,0.05000000074505806	CHEMBL129198,TN,INACT,0.009999999776482582	CHEMBL180191,TP,ACT,1.0	CHEMBL403492,TP,ACT,1.0	CHEMBL109778,TN,INACT,0.009999999776482582	CHEMBL1258999,TN,INACT,0.05000000074505806	CHEMBL308756,TN,INACT,0.07000000029802322	CHEMBL357983,FP,INACT,0.9900000095367432	CHEMBL479263,TP,ACT,0.9399999976158142	CHEMBL293874,TN,INACT,0.0	CHEMBL1644016,TP,ACT,0.9300000071525574	CHEMBL1180343,TN,INACT,0.8399999737739563	CHEMBL461089,TN,INACT,0.0	CHEMBL312551,TN,INACT,0.0	CHEMBL276676,FP,INACT,0.9100000262260437	CHEMBL1085081,TP,ACT,1.0	CHEMBL255529,TP,ACT,1.0	CHEMBL303538,TN,INACT,0.009999999776482582	CHEMBL107574,TN,INACT,0.009999999776482582	CHEMBL3260767,TP,ACT,0.9900000095367432	CHEMBL86886,TP,ACT,1.0	CHEMBL1083746,TP,ACT,1.0	CHEMBL1237299,TP,ACT,1.0	CHEMBL413509,TP,ACT,0.949999988079071	CHEMBL1237304,TP,ACT,1.0	CHEMBL595022,TN,INACT,0.0	CHEMBL221946,TP,ACT,1.0	CHEMBL255422,TP,ACT,1.0	CHEMBL166089,TN,INACT,0.0	CHEMBL160932,TN,INACT,0.3100000023841858	CHEMBL3753567,TP,ACT,1.0	CHEMBL48031,TN,INACT,0.009999999776482582	CHEMBL141365,TN,INACT,0.029999999329447746	CHEMBL147365,FP,INACT,0.9599999785423279	CHEMBL3260435,TP,ACT,1.0	CHEMBL359141,TN,INACT,0.0	CHEMBL3740325,TP,ACT,1.0	CHEMBL47018,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.019999999552965164	CHEMBL589973,TN,INACT,0.5600000023841858	CHEMBL256220,TP,ACT,1.0	CHEMBL334933,TN,INACT,0.05000000074505806	CHEMBL2112332,TP,ACT,1.0	CHEMBL353502,TN,INACT,0.009999999776482582	CHEMBL320763,TN,INACT,0.0	CHEMBL302282,TN,INACT,0.009999999776482582	CHEMBL288967,TN,INACT,0.3100000023841858	CHEMBL104994,TN,INACT,0.05000000074505806	CHEMBL2112451,TN,INACT,0.09000000357627869	CHEMBL1645133,TP,ACT,0.9900000095367432	CHEMBL3260463,TP,ACT,1.0	CHEMBL483991,TN,INACT,0.009999999776482582	CHEMBL527880,TN,INACT,0.0	CHEMBL3260444,TP,ACT,1.0	CHEMBL249954,FN,ACT,0.8500000238418579	CHEMBL369359,TN,INACT,0.15000000596046448	CHEMBL249341,TP,ACT,0.9399999976158142	CHEMBL1669006,TP,ACT,1.0	CHEMBL3752377,TP,ACT,1.0	CHEMBL190185,TP,ACT,1.0	CHEMBL3260763,TP,ACT,1.0	CHEMBL430121,TP,ACT,0.9900000095367432	CHEMBL42360,TN,INACT,0.27000001072883606	CHEMBL424214,TN,INACT,0.03999999910593033	CHEMBL148967,TN,INACT,0.0	CHEMBL302027,FP,INACT,0.9700000286102295	CHEMBL78853,TN,INACT,0.0	CHEMBL3753274,TP,ACT,1.0	CHEMBL15096,TP,ACT,1.0	CHEMBL255906,TP,ACT,1.0	CHEMBL3793994,TP,ACT,0.9700000286102295	CHEMBL2369493,TN,INACT,0.0	CHEMBL275245,FN,ACT,0.8199999928474426	CHEMBL3670689,TP,ACT,1.0	CHEMBL1237298,TP,ACT,1.0	CHEMBL109248,TN,INACT,0.0	CHEMBL435810,TN,INACT,0.0	CHEMBL432334,TN,INACT,0.0	CHEMBL141051,TN,INACT,0.36000001430511475	CHEMBL174448,TN,INACT,0.0	CHEMBL1083445,TP,ACT,1.0	CHEMBL180752,TP,ACT,1.0	CHEMBL59,TN,INACT,0.0	CHEMBL21328,TN,INACT,0.019999999552965164	CHEMBL353304,TN,INACT,0.029999999329447746	CHEMBL3260430,TP,ACT,0.9900000095367432	CHEMBL297473,TN,INACT,0.0	CHEMBL64120,TN,INACT,0.0	CHEMBL217991,TP,ACT,0.9900000095367432	CHEMBL218123,TP,ACT,1.0	CHEMBL1645136,TP,ACT,1.0	CHEMBL417358,TN,INACT,0.09000000357627869	CHEMBL273410,FP,INACT,1.0	CHEMBL88629,TN,INACT,0.7799999713897705	CHEMBL1237296,TP,ACT,1.0	CHEMBL3260766,TP,ACT,1.0	

