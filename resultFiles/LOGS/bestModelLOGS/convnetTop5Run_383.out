CNNModel CHEMBL2492 RMSprop 0.0005 30 256 0 0.6 False True
Number of active compounds :	295
Number of inactive compounds :	197
---------------------------------
Run id: CNNModel_CHEMBL2492_RMSprop_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2492_RMSprop_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 314
Validation samples: 99
--
Training Step: 1  | time: 1.032s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/314
[A[ATraining Step: 2  | total loss: [1m[32m0.62381[0m[0m | time: 1.816s
[2K
| RMSProp | epoch: 001 | loss: 0.62381 - acc: 0.3937 -- iter: 064/314
[A[ATraining Step: 3  | total loss: [1m[32m0.68110[0m[0m | time: 2.570s
[2K
| RMSProp | epoch: 001 | loss: 0.68110 - acc: 0.3017 -- iter: 096/314
[A[ATraining Step: 4  | total loss: [1m[32m0.69043[0m[0m | time: 3.524s
[2K
| RMSProp | epoch: 001 | loss: 0.69043 - acc: 0.3801 -- iter: 128/314
[A[ATraining Step: 5  | total loss: [1m[32m0.69296[0m[0m | time: 4.635s
[2K
| RMSProp | epoch: 001 | loss: 0.69296 - acc: 0.2900 -- iter: 160/314
[A[ATraining Step: 6  | total loss: [1m[32m0.69299[0m[0m | time: 5.912s
[2K
| RMSProp | epoch: 001 | loss: 0.69299 - acc: 0.4049 -- iter: 192/314
[A[ATraining Step: 7  | total loss: [1m[32m0.69275[0m[0m | time: 6.719s
[2K
| RMSProp | epoch: 001 | loss: 0.69275 - acc: 0.5557 -- iter: 224/314
[A[ATraining Step: 8  | total loss: [1m[32m0.69296[0m[0m | time: 7.594s
[2K
| RMSProp | epoch: 001 | loss: 0.69296 - acc: 0.5595 -- iter: 256/314
[A[ATraining Step: 9  | total loss: [1m[32m0.69326[0m[0m | time: 8.568s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.4784 -- iter: 288/314
[A[ATraining Step: 10  | total loss: [1m[32m0.69332[0m[0m | time: 10.439s
[2K
| RMSProp | epoch: 001 | loss: 0.69332 - acc: 0.4579 | val_loss: 0.69348 - val_acc: 0.3838 -- iter: 314/314
--
Training Step: 11  | total loss: [1m[32m0.69362[0m[0m | time: 0.727s
[2K
| RMSProp | epoch: 002 | loss: 0.69362 - acc: 0.4050 -- iter: 032/314
[A[ATraining Step: 12  | total loss: [1m[32m0.69357[0m[0m | time: 1.786s
[2K
| RMSProp | epoch: 002 | loss: 0.69357 - acc: 0.4131 -- iter: 064/314
[A[ATraining Step: 13  | total loss: [1m[32m0.69366[0m[0m | time: 2.873s
[2K
| RMSProp | epoch: 002 | loss: 0.69366 - acc: 0.3432 -- iter: 096/314
[A[ATraining Step: 14  | total loss: [1m[32m0.69357[0m[0m | time: 3.869s
[2K
| RMSProp | epoch: 002 | loss: 0.69357 - acc: 0.3690 -- iter: 128/314
[A[ATraining Step: 15  | total loss: [1m[32m0.69345[0m[0m | time: 4.647s
[2K
| RMSProp | epoch: 002 | loss: 0.69345 - acc: 0.3958 -- iter: 160/314
[A[ATraining Step: 16  | total loss: [1m[32m0.69335[0m[0m | time: 5.506s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.4349 -- iter: 192/314
[A[ATraining Step: 17  | total loss: [1m[32m0.69336[0m[0m | time: 6.428s
[2K
| RMSProp | epoch: 002 | loss: 0.69336 - acc: 0.4471 -- iter: 224/314
[A[ATraining Step: 18  | total loss: [1m[32m0.69328[0m[0m | time: 7.331s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4762 -- iter: 256/314
[A[ATraining Step: 19  | total loss: [1m[32m0.69334[0m[0m | time: 8.236s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4529 -- iter: 288/314
[A[ATraining Step: 20  | total loss: [1m[32m0.69334[0m[0m | time: 10.211s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4379 | val_loss: 0.69327 - val_acc: 0.3838 -- iter: 314/314
--
Training Step: 21  | total loss: [1m[32m0.69331[0m[0m | time: 1.086s
[2K
| RMSProp | epoch: 003 | loss: 0.69331 - acc: 0.4475 -- iter: 032/314
[A[ATraining Step: 22  | total loss: [1m[32m0.69333[0m[0m | time: 1.987s
[2K
| RMSProp | epoch: 003 | loss: 0.69333 - acc: 0.4402 -- iter: 064/314
[A[ATraining Step: 23  | total loss: [1m[32m0.69332[0m[0m | time: 3.080s
[2K
| RMSProp | epoch: 003 | loss: 0.69332 - acc: 0.4352 -- iter: 096/314
[A[ATraining Step: 24  | total loss: [1m[32m0.69330[0m[0m | time: 3.866s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.4534 -- iter: 128/314
[A[ATraining Step: 25  | total loss: [1m[32m0.69327[0m[0m | time: 4.816s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.4491 -- iter: 160/314
[A[ATraining Step: 26  | total loss: [1m[32m0.69319[0m[0m | time: 5.776s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.4874 -- iter: 192/314
[A[ATraining Step: 27  | total loss: [1m[32m0.69316[0m[0m | time: 6.695s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.4987 -- iter: 224/314
[A[ATraining Step: 28  | total loss: [1m[32m0.69316[0m[0m | time: 7.628s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.4990 -- iter: 256/314
[A[ATraining Step: 29  | total loss: [1m[32m0.69302[0m[0m | time: 8.641s
[2K
| RMSProp | epoch: 003 | loss: 0.69302 - acc: 0.5524 -- iter: 288/314
[A[ATraining Step: 30  | total loss: [1m[32m0.69307[0m[0m | time: 10.798s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5400 | val_loss: 0.69289 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 31  | total loss: [1m[32m0.69318[0m[0m | time: 1.007s
[2K
| RMSProp | epoch: 004 | loss: 0.69318 - acc: 0.5092 -- iter: 032/314
[A[ATraining Step: 32  | total loss: [1m[32m0.69317[0m[0m | time: 1.812s
[2K
| RMSProp | epoch: 004 | loss: 0.69317 - acc: 0.5071 -- iter: 064/314
[A[ATraining Step: 33  | total loss: [1m[32m0.69308[0m[0m | time: 2.604s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5393 -- iter: 096/314
[A[ATraining Step: 34  | total loss: [1m[32m0.69308[0m[0m | time: 3.550s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5391 -- iter: 128/314
[A[ATraining Step: 35  | total loss: [1m[32m0.69304[0m[0m | time: 4.527s
[2K
| RMSProp | epoch: 004 | loss: 0.69304 - acc: 0.5506 -- iter: 160/314
[A[ATraining Step: 36  | total loss: [1m[32m0.69303[0m[0m | time: 5.520s
[2K
| RMSProp | epoch: 004 | loss: 0.69303 - acc: 0.5530 -- iter: 192/314
[A[ATraining Step: 37  | total loss: [1m[32m0.69297[0m[0m | time: 6.399s
[2K
| RMSProp | epoch: 004 | loss: 0.69297 - acc: 0.5612 -- iter: 224/314
[A[ATraining Step: 38  | total loss: [1m[32m0.69291[0m[0m | time: 7.373s
[2K
| RMSProp | epoch: 004 | loss: 0.69291 - acc: 0.5614 -- iter: 256/314
[A[ATraining Step: 39  | total loss: [1m[32m0.69286[0m[0m | time: 8.460s
[2K
| RMSProp | epoch: 004 | loss: 0.69286 - acc: 0.5676 -- iter: 288/314
[A[ATraining Step: 40  | total loss: [1m[32m0.69291[0m[0m | time: 10.557s
[2K
| RMSProp | epoch: 004 | loss: 0.69291 - acc: 0.5608 | val_loss: 0.69233 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 41  | total loss: [1m[32m0.69283[0m[0m | time: 0.908s
[2K
| RMSProp | epoch: 005 | loss: 0.69283 - acc: 0.5726 -- iter: 032/314
[A[ATraining Step: 42  | total loss: [1m[32m0.69270[0m[0m | time: 1.938s
[2K
| RMSProp | epoch: 005 | loss: 0.69270 - acc: 0.5820 -- iter: 064/314
[A[ATraining Step: 43  | total loss: [1m[32m0.69283[0m[0m | time: 2.748s
[2K
| RMSProp | epoch: 005 | loss: 0.69283 - acc: 0.5675 -- iter: 096/314
[A[ATraining Step: 44  | total loss: [1m[32m0.69284[0m[0m | time: 3.539s
[2K
| RMSProp | epoch: 005 | loss: 0.69284 - acc: 0.5625 -- iter: 128/314
[A[ATraining Step: 45  | total loss: [1m[32m0.69297[0m[0m | time: 4.454s
[2K
| RMSProp | epoch: 005 | loss: 0.69297 - acc: 0.5454 -- iter: 160/314
[A[ATraining Step: 46  | total loss: [1m[32m0.69313[0m[0m | time: 5.553s
[2K
| RMSProp | epoch: 005 | loss: 0.69313 - acc: 0.5222 -- iter: 192/314
[A[ATraining Step: 47  | total loss: [1m[32m0.69287[0m[0m | time: 6.723s
[2K
| RMSProp | epoch: 005 | loss: 0.69287 - acc: 0.5543 -- iter: 224/314
[A[ATraining Step: 48  | total loss: [1m[32m0.69272[0m[0m | time: 7.948s
[2K
| RMSProp | epoch: 005 | loss: 0.69272 - acc: 0.5657 -- iter: 256/314
[A[ATraining Step: 49  | total loss: [1m[32m0.69287[0m[0m | time: 8.690s
[2K
| RMSProp | epoch: 005 | loss: 0.69287 - acc: 0.5455 -- iter: 288/314
[A[ATraining Step: 50  | total loss: [1m[32m0.69267[0m[0m | time: 10.663s
[2K
| RMSProp | epoch: 005 | loss: 0.69267 - acc: 0.5627 | val_loss: 0.69174 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 51  | total loss: [1m[32m0.69254[0m[0m | time: 0.928s
[2K
| RMSProp | epoch: 006 | loss: 0.69254 - acc: 0.5722 -- iter: 032/314
[A[ATraining Step: 52  | total loss: [1m[32m0.69256[0m[0m | time: 1.900s
[2K
| RMSProp | epoch: 006 | loss: 0.69256 - acc: 0.5660 -- iter: 064/314
[A[ATraining Step: 53  | total loss: [1m[32m0.69257[0m[0m | time: 2.991s
[2K
| RMSProp | epoch: 006 | loss: 0.69257 - acc: 0.5609 -- iter: 096/314
[A[ATraining Step: 54  | total loss: [1m[32m0.69225[0m[0m | time: 3.943s
[2K
| RMSProp | epoch: 006 | loss: 0.69225 - acc: 0.5838 -- iter: 128/314
[A[ATraining Step: 55  | total loss: [1m[32m0.69248[0m[0m | time: 4.695s
[2K
| RMSProp | epoch: 006 | loss: 0.69248 - acc: 0.5663 -- iter: 160/314
[A[ATraining Step: 56  | total loss: [1m[32m0.69234[0m[0m | time: 5.447s
[2K
| RMSProp | epoch: 006 | loss: 0.69234 - acc: 0.5732 -- iter: 192/314
[A[ATraining Step: 57  | total loss: [1m[32m0.69232[0m[0m | time: 6.350s
[2K
| RMSProp | epoch: 006 | loss: 0.69232 - acc: 0.5718 -- iter: 224/314
[A[ATraining Step: 58  | total loss: [1m[32m0.69245[0m[0m | time: 7.275s
[2K
| RMSProp | epoch: 006 | loss: 0.69245 - acc: 0.5620 -- iter: 256/314
[A[ATraining Step: 59  | total loss: [1m[32m0.69226[0m[0m | time: 8.210s
[2K
| RMSProp | epoch: 006 | loss: 0.69226 - acc: 0.5704 -- iter: 288/314
[A[ATraining Step: 60  | total loss: [1m[32m0.69216[0m[0m | time: 10.113s
[2K
| RMSProp | epoch: 006 | loss: 0.69216 - acc: 0.5735 | val_loss: 0.69072 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 61  | total loss: [1m[32m0.69182[0m[0m | time: 1.130s
[2K
| RMSProp | epoch: 007 | loss: 0.69182 - acc: 0.5884 -- iter: 032/314
[A[ATraining Step: 62  | total loss: [1m[32m0.69235[0m[0m | time: 2.183s
[2K
| RMSProp | epoch: 007 | loss: 0.69235 - acc: 0.5610 -- iter: 064/314
[A[ATraining Step: 63  | total loss: [1m[32m0.69214[0m[0m | time: 3.288s
[2K
| RMSProp | epoch: 007 | loss: 0.69214 - acc: 0.5691 -- iter: 096/314
[A[ATraining Step: 64  | total loss: [1m[32m0.69213[0m[0m | time: 4.252s
[2K
| RMSProp | epoch: 007 | loss: 0.69213 - acc: 0.5682 -- iter: 128/314
[A[ATraining Step: 65  | total loss: [1m[32m0.69202[0m[0m | time: 5.104s
[2K
| RMSProp | epoch: 007 | loss: 0.69202 - acc: 0.5714 -- iter: 160/314
[A[ATraining Step: 66  | total loss: [1m[32m0.69183[0m[0m | time: 5.910s
[2K
| RMSProp | epoch: 007 | loss: 0.69183 - acc: 0.5767 -- iter: 192/314
[A[ATraining Step: 67  | total loss: [1m[32m0.69186[0m[0m | time: 6.828s
[2K
| RMSProp | epoch: 007 | loss: 0.69186 - acc: 0.5721 -- iter: 224/314
[A[ATraining Step: 68  | total loss: [1m[32m0.69127[0m[0m | time: 7.530s
[2K
| RMSProp | epoch: 007 | loss: 0.69127 - acc: 0.5932 -- iter: 256/314
[A[ATraining Step: 69  | total loss: [1m[32m0.69141[0m[0m | time: 8.202s
[2K
| RMSProp | epoch: 007 | loss: 0.69141 - acc: 0.5860 -- iter: 288/314
[A[ATraining Step: 70  | total loss: [1m[32m0.69141[0m[0m | time: 9.864s
[2K
| RMSProp | epoch: 007 | loss: 0.69141 - acc: 0.5833 | val_loss: 0.68965 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 71  | total loss: [1m[32m0.69130[0m[0m | time: 0.662s
[2K
| RMSProp | epoch: 008 | loss: 0.69130 - acc: 0.5845 -- iter: 032/314
[A[ATraining Step: 72  | total loss: [1m[32m0.69175[0m[0m | time: 1.316s
[2K
| RMSProp | epoch: 008 | loss: 0.69175 - acc: 0.5679 -- iter: 064/314
[A[ATraining Step: 73  | total loss: [1m[32m0.69108[0m[0m | time: 1.969s
[2K
| RMSProp | epoch: 008 | loss: 0.69108 - acc: 0.5882 -- iter: 096/314
[A[ATraining Step: 74  | total loss: [1m[32m0.69167[0m[0m | time: 2.613s
[2K
| RMSProp | epoch: 008 | loss: 0.69167 - acc: 0.5682 -- iter: 128/314
[A[ATraining Step: 75  | total loss: [1m[32m0.69174[0m[0m | time: 3.239s
[2K
| RMSProp | epoch: 008 | loss: 0.69174 - acc: 0.5642 -- iter: 160/314
[A[ATraining Step: 76  | total loss: [1m[32m0.69149[0m[0m | time: 3.768s
[2K
| RMSProp | epoch: 008 | loss: 0.69149 - acc: 0.5707 -- iter: 192/314
[A[ATraining Step: 77  | total loss: [1m[32m0.69154[0m[0m | time: 4.311s
[2K
| RMSProp | epoch: 008 | loss: 0.69154 - acc: 0.5673 -- iter: 224/314
[A[ATraining Step: 78  | total loss: [1m[32m0.69200[0m[0m | time: 4.967s
[2K
| RMSProp | epoch: 008 | loss: 0.69200 - acc: 0.5522 -- iter: 256/314
[A[ATraining Step: 79  | total loss: [1m[32m0.69202[0m[0m | time: 5.604s
[2K
| RMSProp | epoch: 008 | loss: 0.69202 - acc: 0.5500 -- iter: 288/314
[A[ATraining Step: 80  | total loss: [1m[32m0.69159[0m[0m | time: 7.244s
[2K
| RMSProp | epoch: 008 | loss: 0.69159 - acc: 0.5609 | val_loss: 0.68920 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 81  | total loss: [1m[32m0.69202[0m[0m | time: 0.676s
[2K
| RMSProp | epoch: 009 | loss: 0.69202 - acc: 0.5484 -- iter: 032/314
[A[ATraining Step: 82  | total loss: [1m[32m0.69160[0m[0m | time: 1.337s
[2K
| RMSProp | epoch: 009 | loss: 0.69160 - acc: 0.5592 -- iter: 064/314
[A[ATraining Step: 83  | total loss: [1m[32m0.69142[0m[0m | time: 2.006s
[2K
| RMSProp | epoch: 009 | loss: 0.69142 - acc: 0.5627 -- iter: 096/314
[A[ATraining Step: 84  | total loss: [1m[32m0.69124[0m[0m | time: 2.635s
[2K
| RMSProp | epoch: 009 | loss: 0.69124 - acc: 0.5658 -- iter: 128/314
[A[ATraining Step: 85  | total loss: [1m[32m0.69095[0m[0m | time: 3.296s
[2K
| RMSProp | epoch: 009 | loss: 0.69095 - acc: 0.5717 -- iter: 160/314
[A[ATraining Step: 86  | total loss: [1m[32m0.69091[0m[0m | time: 3.931s
[2K
| RMSProp | epoch: 009 | loss: 0.69091 - acc: 0.5708 -- iter: 192/314
[A[ATraining Step: 87  | total loss: [1m[32m0.69060[0m[0m | time: 4.461s
[2K
| RMSProp | epoch: 009 | loss: 0.69060 - acc: 0.5762 -- iter: 224/314
[A[ATraining Step: 88  | total loss: [1m[32m0.69127[0m[0m | time: 4.966s
[2K
| RMSProp | epoch: 009 | loss: 0.69127 - acc: 0.5609 -- iter: 256/314
[A[ATraining Step: 89  | total loss: [1m[32m0.69149[0m[0m | time: 5.593s
[2K
| RMSProp | epoch: 009 | loss: 0.69149 - acc: 0.5548 -- iter: 288/314
[A[ATraining Step: 90  | total loss: [1m[32m0.69155[0m[0m | time: 7.669s
[2K
| RMSProp | epoch: 009 | loss: 0.69155 - acc: 0.5524 | val_loss: 0.68779 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 91  | total loss: [1m[32m0.69130[0m[0m | time: 0.885s
[2K
| RMSProp | epoch: 010 | loss: 0.69130 - acc: 0.5566 -- iter: 032/314
[A[ATraining Step: 92  | total loss: [1m[32m0.69137[0m[0m | time: 1.787s
[2K
| RMSProp | epoch: 010 | loss: 0.69137 - acc: 0.5540 -- iter: 064/314
[A[ATraining Step: 93  | total loss: [1m[32m0.69095[0m[0m | time: 2.696s
[2K
| RMSProp | epoch: 010 | loss: 0.69095 - acc: 0.5611 -- iter: 096/314
[A[ATraining Step: 94  | total loss: [1m[32m0.69169[0m[0m | time: 3.686s
[2K
| RMSProp | epoch: 010 | loss: 0.69169 - acc: 0.5456 -- iter: 128/314
[A[ATraining Step: 95  | total loss: [1m[32m0.69170[0m[0m | time: 4.612s
[2K
| RMSProp | epoch: 010 | loss: 0.69170 - acc: 0.5442 -- iter: 160/314
[A[ATraining Step: 96  | total loss: [1m[32m0.69204[0m[0m | time: 5.514s
[2K
| RMSProp | epoch: 010 | loss: 0.69204 - acc: 0.5367 -- iter: 192/314
[A[ATraining Step: 97  | total loss: [1m[32m0.69096[0m[0m | time: 6.422s
[2K
| RMSProp | epoch: 010 | loss: 0.69096 - acc: 0.5580 -- iter: 224/314
[A[ATraining Step: 98  | total loss: [1m[32m0.68965[0m[0m | time: 7.379s
[2K
| RMSProp | epoch: 010 | loss: 0.68965 - acc: 0.5803 -- iter: 256/314
[A[ATraining Step: 99  | total loss: [1m[32m0.69004[0m[0m | time: 8.237s
[2K
| RMSProp | epoch: 010 | loss: 0.69004 - acc: 0.5723 -- iter: 288/314
[A[ATraining Step: 100  | total loss: [1m[32m0.69039[0m[0m | time: 10.166s
[2K
| RMSProp | epoch: 010 | loss: 0.69039 - acc: 0.5651 | val_loss: 0.68620 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 101  | total loss: [1m[32m0.69031[0m[0m | time: 0.964s
[2K
| RMSProp | epoch: 011 | loss: 0.69031 - acc: 0.5648 -- iter: 032/314
[A[ATraining Step: 102  | total loss: [1m[32m0.69003[0m[0m | time: 1.850s
[2K
| RMSProp | epoch: 011 | loss: 0.69003 - acc: 0.5677 -- iter: 064/314
[A[ATraining Step: 103  | total loss: [1m[32m0.69041[0m[0m | time: 2.784s
[2K
| RMSProp | epoch: 011 | loss: 0.69041 - acc: 0.5609 -- iter: 096/314
[A[ATraining Step: 104  | total loss: [1m[32m0.68952[0m[0m | time: 3.719s
[2K
| RMSProp | epoch: 011 | loss: 0.68952 - acc: 0.5736 -- iter: 128/314
[A[ATraining Step: 105  | total loss: [1m[32m0.68993[0m[0m | time: 4.523s
[2K
| RMSProp | epoch: 011 | loss: 0.68993 - acc: 0.5662 -- iter: 160/314
[A[ATraining Step: 106  | total loss: [1m[32m0.69056[0m[0m | time: 5.552s
[2K
| RMSProp | epoch: 011 | loss: 0.69056 - acc: 0.5565 -- iter: 192/314
[A[ATraining Step: 107  | total loss: [1m[32m0.69022[0m[0m | time: 6.584s
[2K
| RMSProp | epoch: 011 | loss: 0.69022 - acc: 0.5602 -- iter: 224/314
[A[ATraining Step: 108  | total loss: [1m[32m0.68967[0m[0m | time: 7.576s
[2K
| RMSProp | epoch: 011 | loss: 0.68967 - acc: 0.5667 -- iter: 256/314
[A[ATraining Step: 109  | total loss: [1m[32m0.68864[0m[0m | time: 8.236s
[2K
| RMSProp | epoch: 011 | loss: 0.68864 - acc: 0.5788 -- iter: 288/314
[A[ATraining Step: 110  | total loss: [1m[32m0.68921[0m[0m | time: 10.023s
[2K
| RMSProp | epoch: 011 | loss: 0.68921 - acc: 0.5709 | val_loss: 0.68441 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 111  | total loss: [1m[32m0.68971[0m[0m | time: 1.010s
[2K
| RMSProp | epoch: 012 | loss: 0.68971 - acc: 0.5638 -- iter: 032/314
[A[ATraining Step: 112  | total loss: [1m[32m0.68937[0m[0m | time: 1.984s
[2K
| RMSProp | epoch: 012 | loss: 0.68937 - acc: 0.5668 -- iter: 064/314
[A[ATraining Step: 113  | total loss: [1m[32m0.68847[0m[0m | time: 2.894s
[2K
| RMSProp | epoch: 012 | loss: 0.68847 - acc: 0.5757 -- iter: 096/314
[A[ATraining Step: 114  | total loss: [1m[32m0.68904[0m[0m | time: 3.709s
[2K
| RMSProp | epoch: 012 | loss: 0.68904 - acc: 0.5682 -- iter: 128/314
[A[ATraining Step: 115  | total loss: [1m[32m0.68927[0m[0m | time: 4.415s
[2K
| RMSProp | epoch: 012 | loss: 0.68927 - acc: 0.5645 -- iter: 160/314
[A[ATraining Step: 116  | total loss: [1m[32m0.68659[0m[0m | time: 5.170s
[2K
| RMSProp | epoch: 012 | loss: 0.68659 - acc: 0.5924 -- iter: 192/314
[A[ATraining Step: 117  | total loss: [1m[32m0.68776[0m[0m | time: 5.910s
[2K
| RMSProp | epoch: 012 | loss: 0.68776 - acc: 0.5800 -- iter: 224/314
[A[ATraining Step: 118  | total loss: [1m[32m0.68810[0m[0m | time: 6.633s
[2K
| RMSProp | epoch: 012 | loss: 0.68810 - acc: 0.5752 -- iter: 256/314
[A[ATraining Step: 119  | total loss: [1m[32m0.68812[0m[0m | time: 7.480s
[2K
| RMSProp | epoch: 012 | loss: 0.68812 - acc: 0.5739 -- iter: 288/314
[A[ATraining Step: 120  | total loss: [1m[32m0.68841[0m[0m | time: 9.453s
[2K
| RMSProp | epoch: 012 | loss: 0.68841 - acc: 0.5696 | val_loss: 0.68211 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 121  | total loss: [1m[32m0.68900[0m[0m | time: 0.750s
[2K
| RMSProp | epoch: 013 | loss: 0.68900 - acc: 0.5627 -- iter: 032/314
[A[ATraining Step: 122  | total loss: [1m[32m0.69000[0m[0m | time: 1.654s
[2K
| RMSProp | epoch: 013 | loss: 0.69000 - acc: 0.5526 -- iter: 064/314
[A[ATraining Step: 123  | total loss: [1m[32m0.69010[0m[0m | time: 2.570s
[2K
| RMSProp | epoch: 013 | loss: 0.69010 - acc: 0.5504 -- iter: 096/314
[A[ATraining Step: 124  | total loss: [1m[32m0.68988[0m[0m | time: 3.537s
[2K
| RMSProp | epoch: 013 | loss: 0.68988 - acc: 0.5516 -- iter: 128/314
[A[ATraining Step: 125  | total loss: [1m[32m0.68867[0m[0m | time: 4.548s
[2K
| RMSProp | epoch: 013 | loss: 0.68867 - acc: 0.5621 -- iter: 160/314
[A[ATraining Step: 126  | total loss: [1m[32m0.68955[0m[0m | time: 5.396s
[2K
| RMSProp | epoch: 013 | loss: 0.68955 - acc: 0.5528 -- iter: 192/314
[A[ATraining Step: 127  | total loss: [1m[32m0.68863[0m[0m | time: 6.277s
[2K
| RMSProp | epoch: 013 | loss: 0.68863 - acc: 0.5600 -- iter: 224/314
[A[ATraining Step: 128  | total loss: [1m[32m0.68698[0m[0m | time: 7.467s
[2K
| RMSProp | epoch: 013 | loss: 0.68698 - acc: 0.5727 -- iter: 256/314
[A[ATraining Step: 129  | total loss: [1m[32m0.68563[0m[0m | time: 8.495s
[2K
| RMSProp | epoch: 013 | loss: 0.68563 - acc: 0.5811 -- iter: 288/314
[A[ATraining Step: 130  | total loss: [1m[32m0.68668[0m[0m | time: 10.301s
[2K
| RMSProp | epoch: 013 | loss: 0.68668 - acc: 0.5730 | val_loss: 0.67742 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 131  | total loss: [1m[32m0.68661[0m[0m | time: 0.873s
[2K
| RMSProp | epoch: 014 | loss: 0.68661 - acc: 0.5719 -- iter: 032/314
[A[ATraining Step: 132  | total loss: [1m[32m0.68824[0m[0m | time: 1.703s
[2K
| RMSProp | epoch: 014 | loss: 0.68824 - acc: 0.5609 -- iter: 064/314
[A[ATraining Step: 133  | total loss: [1m[32m0.68626[0m[0m | time: 2.606s
[2K
| RMSProp | epoch: 014 | loss: 0.68626 - acc: 0.5740 -- iter: 096/314
[A[ATraining Step: 134  | total loss: [1m[32m0.68780[0m[0m | time: 3.609s
[2K
| RMSProp | epoch: 014 | loss: 0.68780 - acc: 0.5635 -- iter: 128/314
[A[ATraining Step: 135  | total loss: [1m[32m0.68854[0m[0m | time: 4.757s
[2K
| RMSProp | epoch: 014 | loss: 0.68854 - acc: 0.5572 -- iter: 160/314
[A[ATraining Step: 136  | total loss: [1m[32m0.68649[0m[0m | time: 5.781s
[2K
| RMSProp | epoch: 014 | loss: 0.68649 - acc: 0.5702 -- iter: 192/314
[A[ATraining Step: 137  | total loss: [1m[32m0.68577[0m[0m | time: 6.517s
[2K
| RMSProp | epoch: 014 | loss: 0.68577 - acc: 0.5725 -- iter: 224/314
[A[ATraining Step: 138  | total loss: [1m[32m0.68696[0m[0m | time: 7.382s
[2K
| RMSProp | epoch: 014 | loss: 0.68696 - acc: 0.5653 -- iter: 256/314
[A[ATraining Step: 139  | total loss: [1m[32m0.68508[0m[0m | time: 8.258s
[2K
| RMSProp | epoch: 014 | loss: 0.68508 - acc: 0.5744 -- iter: 288/314
[A[ATraining Step: 140  | total loss: [1m[32m0.68568[0m[0m | time: 10.133s
[2K
| RMSProp | epoch: 014 | loss: 0.68568 - acc: 0.5701 | val_loss: 0.66970 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 141  | total loss: [1m[32m0.68417[0m[0m | time: 1.033s
[2K
| RMSProp | epoch: 015 | loss: 0.68417 - acc: 0.5756 -- iter: 032/314
[A[ATraining Step: 142  | total loss: [1m[32m0.68594[0m[0m | time: 1.662s
[2K
| RMSProp | epoch: 015 | loss: 0.68594 - acc: 0.5680 -- iter: 064/314
[A[ATraining Step: 143  | total loss: [1m[32m0.68306[0m[0m | time: 2.407s
[2K
| RMSProp | epoch: 015 | loss: 0.68306 - acc: 0.5804 -- iter: 096/314
[A[ATraining Step: 144  | total loss: [1m[32m0.68527[0m[0m | time: 3.270s
[2K
| RMSProp | epoch: 015 | loss: 0.68527 - acc: 0.5724 -- iter: 128/314
[A[ATraining Step: 145  | total loss: [1m[32m0.68743[0m[0m | time: 4.213s
[2K
| RMSProp | epoch: 015 | loss: 0.68743 - acc: 0.5620 -- iter: 160/314
[A[ATraining Step: 146  | total loss: [1m[32m0.68837[0m[0m | time: 5.083s
[2K
| RMSProp | epoch: 015 | loss: 0.68837 - acc: 0.5558 -- iter: 192/314
[A[ATraining Step: 147  | total loss: [1m[32m0.68599[0m[0m | time: 6.046s
[2K
| RMSProp | epoch: 015 | loss: 0.68599 - acc: 0.5690 -- iter: 224/314
[A[ATraining Step: 148  | total loss: [1m[32m0.68585[0m[0m | time: 6.970s
[2K
| RMSProp | epoch: 015 | loss: 0.68585 - acc: 0.5683 -- iter: 256/314
[A[ATraining Step: 149  | total loss: [1m[32m0.68347[0m[0m | time: 7.934s
[2K
| RMSProp | epoch: 015 | loss: 0.68347 - acc: 0.5771 -- iter: 288/314
[A[ATraining Step: 150  | total loss: [1m[32m0.68639[0m[0m | time: 9.827s
[2K
| RMSProp | epoch: 015 | loss: 0.68639 - acc: 0.5663 | val_loss: 0.66900 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 151  | total loss: [1m[32m0.68430[0m[0m | time: 0.928s
[2K
| RMSProp | epoch: 016 | loss: 0.68430 - acc: 0.5753 -- iter: 032/314
[A[ATraining Step: 152  | total loss: [1m[32m0.68171[0m[0m | time: 1.945s
[2K
| RMSProp | epoch: 016 | loss: 0.68171 - acc: 0.5834 -- iter: 064/314
[A[ATraining Step: 153  | total loss: [1m[32m0.68188[0m[0m | time: 2.747s
[2K
| RMSProp | epoch: 016 | loss: 0.68188 - acc: 0.5813 -- iter: 096/314
[A[ATraining Step: 154  | total loss: [1m[32m0.68429[0m[0m | time: 3.518s
[2K
| RMSProp | epoch: 016 | loss: 0.68429 - acc: 0.5732 -- iter: 128/314
[A[ATraining Step: 155  | total loss: [1m[32m0.68390[0m[0m | time: 4.592s
[2K
| RMSProp | epoch: 016 | loss: 0.68390 - acc: 0.5735 -- iter: 160/314
[A[ATraining Step: 156  | total loss: [1m[32m0.68226[0m[0m | time: 5.597s
[2K
| RMSProp | epoch: 016 | loss: 0.68226 - acc: 0.5787 -- iter: 192/314
[A[ATraining Step: 157  | total loss: [1m[32m0.68337[0m[0m | time: 6.470s
[2K
| RMSProp | epoch: 016 | loss: 0.68337 - acc: 0.5739 -- iter: 224/314
[A[ATraining Step: 158  | total loss: [1m[32m0.68254[0m[0m | time: 7.381s
[2K
| RMSProp | epoch: 016 | loss: 0.68254 - acc: 0.5759 -- iter: 256/314
[A[ATraining Step: 159  | total loss: [1m[32m0.68271[0m[0m | time: 8.570s
[2K
| RMSProp | epoch: 016 | loss: 0.68271 - acc: 0.5746 -- iter: 288/314
[A[ATraining Step: 160  | total loss: [1m[32m0.67896[0m[0m | time: 10.603s
[2K
| RMSProp | epoch: 016 | loss: 0.67896 - acc: 0.5859 | val_loss: 0.66495 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 161  | total loss: [1m[32m0.67543[0m[0m | time: 0.977s
[2K
| RMSProp | epoch: 017 | loss: 0.67543 - acc: 0.5929 -- iter: 032/314
[A[ATraining Step: 162  | total loss: [1m[32m0.68177[0m[0m | time: 1.989s
[2K
| RMSProp | epoch: 017 | loss: 0.68177 - acc: 0.5836 -- iter: 064/314
[A[ATraining Step: 163  | total loss: [1m[32m0.68518[0m[0m | time: 2.862s
[2K
| RMSProp | epoch: 017 | loss: 0.68518 - acc: 0.5659 -- iter: 096/314
[A[ATraining Step: 164  | total loss: [1m[32m0.68472[0m[0m | time: 3.548s
[2K
| RMSProp | epoch: 017 | loss: 0.68472 - acc: 0.5687 -- iter: 128/314
[A[ATraining Step: 165  | total loss: [1m[32m0.68441[0m[0m | time: 4.366s
[2K
| RMSProp | epoch: 017 | loss: 0.68441 - acc: 0.5695 -- iter: 160/314
[A[ATraining Step: 166  | total loss: [1m[32m0.68327[0m[0m | time: 5.321s
[2K
| RMSProp | epoch: 017 | loss: 0.68327 - acc: 0.5741 -- iter: 192/314
[A[ATraining Step: 167  | total loss: [1m[32m0.68236[0m[0m | time: 6.306s
[2K
| RMSProp | epoch: 017 | loss: 0.68236 - acc: 0.5761 -- iter: 224/314
[A[ATraining Step: 168  | total loss: [1m[32m0.68345[0m[0m | time: 7.254s
[2K
| RMSProp | epoch: 017 | loss: 0.68345 - acc: 0.5716 -- iter: 256/314
[A[ATraining Step: 169  | total loss: [1m[32m0.68178[0m[0m | time: 8.201s
[2K
| RMSProp | epoch: 017 | loss: 0.68178 - acc: 0.5769 -- iter: 288/314
[A[ATraining Step: 170  | total loss: [1m[32m0.68264[0m[0m | time: 10.142s
[2K
| RMSProp | epoch: 017 | loss: 0.68264 - acc: 0.5723 | val_loss: 0.67005 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 171  | total loss: [1m[32m0.68356[0m[0m | time: 0.672s
[2K
| RMSProp | epoch: 018 | loss: 0.68356 - acc: 0.5682 -- iter: 032/314
[A[ATraining Step: 172  | total loss: [1m[32m0.68116[0m[0m | time: 1.283s
[2K
| RMSProp | epoch: 018 | loss: 0.68116 - acc: 0.5770 -- iter: 064/314
[A[ATraining Step: 173  | total loss: [1m[32m0.68086[0m[0m | time: 1.902s
[2K
| RMSProp | epoch: 018 | loss: 0.68086 - acc: 0.5756 -- iter: 096/314
[A[ATraining Step: 174  | total loss: [1m[32m0.68322[0m[0m | time: 2.570s
[2K
| RMSProp | epoch: 018 | loss: 0.68322 - acc: 0.5680 -- iter: 128/314
[A[ATraining Step: 175  | total loss: [1m[32m0.68266[0m[0m | time: 3.105s
[2K
| RMSProp | epoch: 018 | loss: 0.68266 - acc: 0.5706 -- iter: 160/314
[A[ATraining Step: 176  | total loss: [1m[32m0.68115[0m[0m | time: 3.628s
[2K
| RMSProp | epoch: 018 | loss: 0.68115 - acc: 0.5751 -- iter: 192/314
[A[ATraining Step: 177  | total loss: [1m[32m0.68430[0m[0m | time: 4.241s
[2K
| RMSProp | epoch: 018 | loss: 0.68430 - acc: 0.5637 -- iter: 224/314
[A[ATraining Step: 178  | total loss: [1m[32m0.68413[0m[0m | time: 4.847s
[2K
| RMSProp | epoch: 018 | loss: 0.68413 - acc: 0.5636 -- iter: 256/314
[A[ATraining Step: 179  | total loss: [1m[32m0.68515[0m[0m | time: 5.485s
[2K
| RMSProp | epoch: 018 | loss: 0.68515 - acc: 0.5572 -- iter: 288/314
[A[ATraining Step: 180  | total loss: [1m[32m0.68476[0m[0m | time: 7.122s
[2K
| RMSProp | epoch: 018 | loss: 0.68476 - acc: 0.5578 | val_loss: 0.65822 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 181  | total loss: [1m[32m0.68206[0m[0m | time: 0.628s
[2K
| RMSProp | epoch: 019 | loss: 0.68206 - acc: 0.5676 -- iter: 032/314
[A[ATraining Step: 182  | total loss: [1m[32m0.68466[0m[0m | time: 1.249s
[2K
| RMSProp | epoch: 019 | loss: 0.68466 - acc: 0.5609 -- iter: 064/314
[A[ATraining Step: 183  | total loss: [1m[32m0.68399[0m[0m | time: 1.887s
[2K
| RMSProp | epoch: 019 | loss: 0.68399 - acc: 0.5610 -- iter: 096/314
[A[ATraining Step: 184  | total loss: [1m[32m0.68477[0m[0m | time: 2.510s
[2K
| RMSProp | epoch: 019 | loss: 0.68477 - acc: 0.5549 -- iter: 128/314
[A[ATraining Step: 185  | total loss: [1m[32m0.68099[0m[0m | time: 3.125s
[2K
| RMSProp | epoch: 019 | loss: 0.68099 - acc: 0.5744 -- iter: 160/314
[A[ATraining Step: 186  | total loss: [1m[32m0.67715[0m[0m | time: 3.634s
[2K
| RMSProp | epoch: 019 | loss: 0.67715 - acc: 0.5826 -- iter: 192/314
[A[ATraining Step: 187  | total loss: [1m[32m0.68469[0m[0m | time: 4.145s
[2K
| RMSProp | epoch: 019 | loss: 0.68469 - acc: 0.5705 -- iter: 224/314
[A[ATraining Step: 188  | total loss: [1m[32m0.68392[0m[0m | time: 4.744s
[2K
| RMSProp | epoch: 019 | loss: 0.68392 - acc: 0.5711 -- iter: 256/314
[A[ATraining Step: 189  | total loss: [1m[32m0.68192[0m[0m | time: 5.359s
[2K
| RMSProp | epoch: 019 | loss: 0.68192 - acc: 0.5765 -- iter: 288/314
[A[ATraining Step: 190  | total loss: [1m[32m0.67749[0m[0m | time: 6.973s
[2K
| RMSProp | epoch: 019 | loss: 0.67749 - acc: 0.5876 | val_loss: 0.65378 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 191  | total loss: [1m[32m0.67593[0m[0m | time: 0.992s
[2K
| RMSProp | epoch: 020 | loss: 0.67593 - acc: 0.5882 -- iter: 032/314
[A[ATraining Step: 192  | total loss: [1m[32m0.67860[0m[0m | time: 1.826s
[2K
| RMSProp | epoch: 020 | loss: 0.67860 - acc: 0.5794 -- iter: 064/314
[A[ATraining Step: 193  | total loss: [1m[32m0.67906[0m[0m | time: 2.686s
[2K
| RMSProp | epoch: 020 | loss: 0.67906 - acc: 0.5746 -- iter: 096/314
[A[ATraining Step: 194  | total loss: [1m[32m0.68090[0m[0m | time: 3.588s
[2K
| RMSProp | epoch: 020 | loss: 0.68090 - acc: 0.5640 -- iter: 128/314
[A[ATraining Step: 195  | total loss: [1m[32m0.68164[0m[0m | time: 4.497s
[2K
| RMSProp | epoch: 020 | loss: 0.68164 - acc: 0.5576 -- iter: 160/314
[A[ATraining Step: 196  | total loss: [1m[32m0.67815[0m[0m | time: 5.421s
[2K
| RMSProp | epoch: 020 | loss: 0.67815 - acc: 0.5644 -- iter: 192/314
[A[ATraining Step: 197  | total loss: [1m[32m0.67495[0m[0m | time: 6.211s
[2K
| RMSProp | epoch: 020 | loss: 0.67495 - acc: 0.5704 -- iter: 224/314
[A[ATraining Step: 198  | total loss: [1m[32m0.67345[0m[0m | time: 7.001s
[2K
| RMSProp | epoch: 020 | loss: 0.67345 - acc: 0.5711 -- iter: 256/314
[A[ATraining Step: 199  | total loss: [1m[32m0.67323[0m[0m | time: 7.916s
[2K
| RMSProp | epoch: 020 | loss: 0.67323 - acc: 0.5678 -- iter: 288/314
[A[ATraining Step: 200  | total loss: [1m[32m0.67160[0m[0m | time: 9.854s
[2K
| RMSProp | epoch: 020 | loss: 0.67160 - acc: 0.5642 | val_loss: 0.64209 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 201  | total loss: [1m[32m0.66639[0m[0m | time: 0.898s
[2K
| RMSProp | epoch: 021 | loss: 0.66639 - acc: 0.5702 -- iter: 032/314
[A[ATraining Step: 202  | total loss: [1m[32m0.66420[0m[0m | time: 1.773s
[2K
| RMSProp | epoch: 021 | loss: 0.66420 - acc: 0.5726 -- iter: 064/314
[A[ATraining Step: 203  | total loss: [1m[32m0.66121[0m[0m | time: 2.721s
[2K
| RMSProp | epoch: 021 | loss: 0.66121 - acc: 0.5747 -- iter: 096/314
[A[ATraining Step: 204  | total loss: [1m[32m0.65763[0m[0m | time: 3.662s
[2K
| RMSProp | epoch: 021 | loss: 0.65763 - acc: 0.5922 -- iter: 128/314
[A[ATraining Step: 205  | total loss: [1m[32m0.66048[0m[0m | time: 4.644s
[2K
| RMSProp | epoch: 021 | loss: 0.66048 - acc: 0.5986 -- iter: 160/314
[A[ATraining Step: 206  | total loss: [1m[32m0.67009[0m[0m | time: 5.684s
[2K
| RMSProp | epoch: 021 | loss: 0.67009 - acc: 0.5731 -- iter: 192/314
[A[ATraining Step: 207  | total loss: [1m[32m0.66917[0m[0m | time: 6.652s
[2K
| RMSProp | epoch: 021 | loss: 0.66917 - acc: 0.5721 -- iter: 224/314
[A[ATraining Step: 208  | total loss: [1m[32m0.66817[0m[0m | time: 7.337s
[2K
| RMSProp | epoch: 021 | loss: 0.66817 - acc: 0.5711 -- iter: 256/314
[A[ATraining Step: 209  | total loss: [1m[32m0.66632[0m[0m | time: 8.064s
[2K
| RMSProp | epoch: 021 | loss: 0.66632 - acc: 0.5679 -- iter: 288/314
[A[ATraining Step: 210  | total loss: [1m[32m0.66242[0m[0m | time: 10.078s
[2K
| RMSProp | epoch: 021 | loss: 0.66242 - acc: 0.5726 | val_loss: 0.62623 - val_acc: 0.6263 -- iter: 314/314
--
Training Step: 211  | total loss: [1m[32m0.65684[0m[0m | time: 0.621s
[2K
| RMSProp | epoch: 022 | loss: 0.65684 - acc: 0.5810 -- iter: 032/314
[A[ATraining Step: 212  | total loss: [1m[32m0.65102[0m[0m | time: 1.261s
[2K
| RMSProp | epoch: 022 | loss: 0.65102 - acc: 0.5979 -- iter: 064/314
[A[ATraining Step: 213  | total loss: [1m[32m0.64954[0m[0m | time: 1.902s
[2K
| RMSProp | epoch: 022 | loss: 0.64954 - acc: 0.5975 -- iter: 096/314
[A[ATraining Step: 214  | total loss: [1m[32m0.65056[0m[0m | time: 2.538s
[2K
| RMSProp | epoch: 022 | loss: 0.65056 - acc: 0.6033 -- iter: 128/314
[A[ATraining Step: 215  | total loss: [1m[32m0.65096[0m[0m | time: 3.165s
[2K
| RMSProp | epoch: 022 | loss: 0.65096 - acc: 0.6024 -- iter: 160/314
[A[ATraining Step: 216  | total loss: [1m[32m0.64613[0m[0m | time: 3.815s
[2K
| RMSProp | epoch: 022 | loss: 0.64613 - acc: 0.6046 -- iter: 192/314
[A[ATraining Step: 217  | total loss: [1m[32m0.64403[0m[0m | time: 4.483s
[2K
| RMSProp | epoch: 022 | loss: 0.64403 - acc: 0.6067 -- iter: 224/314
[A[ATraining Step: 218  | total loss: [1m[32m0.64195[0m[0m | time: 5.135s
[2K
| RMSProp | epoch: 022 | loss: 0.64195 - acc: 0.6241 -- iter: 256/314
[A[ATraining Step: 219  | total loss: [1m[32m0.63717[0m[0m | time: 5.658s
[2K
| RMSProp | epoch: 022 | loss: 0.63717 - acc: 0.6461 -- iter: 288/314
[A[ATraining Step: 220  | total loss: [1m[32m0.62949[0m[0m | time: 7.168s
[2K
| RMSProp | epoch: 022 | loss: 0.62949 - acc: 0.6507 | val_loss: 0.61651 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 221  | total loss: [1m[32m0.63416[0m[0m | time: 1.050s
[2K
| RMSProp | epoch: 023 | loss: 0.63416 - acc: 0.6433 -- iter: 032/314
[A[ATraining Step: 222  | total loss: [1m[32m0.63361[0m[0m | time: 2.141s
[2K
| RMSProp | epoch: 023 | loss: 0.63361 - acc: 0.6446 -- iter: 064/314
[A[ATraining Step: 223  | total loss: [1m[32m0.63147[0m[0m | time: 3.115s
[2K
| RMSProp | epoch: 023 | loss: 0.63147 - acc: 0.6614 -- iter: 096/314
[A[ATraining Step: 224  | total loss: [1m[32m0.63221[0m[0m | time: 3.835s
[2K
| RMSProp | epoch: 023 | loss: 0.63221 - acc: 0.6515 -- iter: 128/314
[A[ATraining Step: 225  | total loss: [1m[32m0.63009[0m[0m | time: 4.637s
[2K
| RMSProp | epoch: 023 | loss: 0.63009 - acc: 0.6582 -- iter: 160/314
[A[ATraining Step: 226  | total loss: [1m[32m0.61719[0m[0m | time: 5.483s
[2K
| RMSProp | epoch: 023 | loss: 0.61719 - acc: 0.6768 -- iter: 192/314
[A[ATraining Step: 227  | total loss: [1m[32m0.60554[0m[0m | time: 6.404s
[2K
| RMSProp | epoch: 023 | loss: 0.60554 - acc: 0.6841 -- iter: 224/314
[A[ATraining Step: 228  | total loss: [1m[32m0.62137[0m[0m | time: 7.320s
[2K
| RMSProp | epoch: 023 | loss: 0.62137 - acc: 0.6782 -- iter: 256/314
[A[ATraining Step: 229  | total loss: [1m[32m0.61236[0m[0m | time: 8.258s
[2K
| RMSProp | epoch: 023 | loss: 0.61236 - acc: 0.6916 -- iter: 288/314
[A[ATraining Step: 230  | total loss: [1m[32m0.60453[0m[0m | time: 10.108s
[2K
| RMSProp | epoch: 023 | loss: 0.60453 - acc: 0.6975 | val_loss: 0.61185 - val_acc: 0.6162 -- iter: 314/314
--
Training Step: 231  | total loss: [1m[32m0.60005[0m[0m | time: 0.969s
[2K
| RMSProp | epoch: 024 | loss: 0.60005 - acc: 0.7046 -- iter: 032/314
[A[ATraining Step: 232  | total loss: [1m[32m0.59399[0m[0m | time: 1.721s
[2K
| RMSProp | epoch: 024 | loss: 0.59399 - acc: 0.6996 -- iter: 064/314
[A[ATraining Step: 233  | total loss: [1m[32m0.61527[0m[0m | time: 2.592s
[2K
| RMSProp | epoch: 024 | loss: 0.61527 - acc: 0.6796 -- iter: 096/314
[A[ATraining Step: 234  | total loss: [1m[32m0.61910[0m[0m | time: 3.536s
[2K
| RMSProp | epoch: 024 | loss: 0.61910 - acc: 0.6710 -- iter: 128/314
[A[ATraining Step: 235  | total loss: [1m[32m0.61268[0m[0m | time: 4.426s
[2K
| RMSProp | epoch: 024 | loss: 0.61268 - acc: 0.6727 -- iter: 160/314
[A[ATraining Step: 236  | total loss: [1m[32m0.60257[0m[0m | time: 5.345s
[2K
| RMSProp | epoch: 024 | loss: 0.60257 - acc: 0.6929 -- iter: 192/314
[A[ATraining Step: 237  | total loss: [1m[32m0.59857[0m[0m | time: 6.224s
[2K
| RMSProp | epoch: 024 | loss: 0.59857 - acc: 0.6924 -- iter: 224/314
[A[ATraining Step: 238  | total loss: [1m[32m0.58554[0m[0m | time: 7.231s
[2K
| RMSProp | epoch: 024 | loss: 0.58554 - acc: 0.7044 -- iter: 256/314
[A[ATraining Step: 239  | total loss: [1m[32m0.56803[0m[0m | time: 8.250s
[2K
| RMSProp | epoch: 024 | loss: 0.56803 - acc: 0.7246 -- iter: 288/314
[A[ATraining Step: 240  | total loss: [1m[32m0.55462[0m[0m | time: 10.115s
[2K
| RMSProp | epoch: 024 | loss: 0.55462 - acc: 0.7271 | val_loss: 0.63889 - val_acc: 0.6263 -- iter: 314/314
--
Training Step: 241  | total loss: [1m[32m0.55964[0m[0m | time: 0.627s
[2K
| RMSProp | epoch: 025 | loss: 0.55964 - acc: 0.7231 -- iter: 032/314
[A[ATraining Step: 242  | total loss: [1m[32m0.55959[0m[0m | time: 1.495s
[2K
| RMSProp | epoch: 025 | loss: 0.55959 - acc: 0.7162 -- iter: 064/314
[A[ATraining Step: 243  | total loss: [1m[32m0.55502[0m[0m | time: 2.668s
[2K
| RMSProp | epoch: 025 | loss: 0.55502 - acc: 0.7254 -- iter: 096/314
[A[ATraining Step: 244  | total loss: [1m[32m0.54910[0m[0m | time: 3.789s
[2K
| RMSProp | epoch: 025 | loss: 0.54910 - acc: 0.7247 -- iter: 128/314
[A[ATraining Step: 245  | total loss: [1m[32m0.53796[0m[0m | time: 4.617s
[2K
| RMSProp | epoch: 025 | loss: 0.53796 - acc: 0.7397 -- iter: 160/314
[A[ATraining Step: 246  | total loss: [1m[32m0.53381[0m[0m | time: 5.517s
[2K
| RMSProp | epoch: 025 | loss: 0.53381 - acc: 0.7470 -- iter: 192/314
[A[ATraining Step: 247  | total loss: [1m[32m0.56078[0m[0m | time: 6.492s
[2K
| RMSProp | epoch: 025 | loss: 0.56078 - acc: 0.7223 -- iter: 224/314
[A[ATraining Step: 248  | total loss: [1m[32m0.55928[0m[0m | time: 7.461s
[2K
| RMSProp | epoch: 025 | loss: 0.55928 - acc: 0.7188 -- iter: 256/314
[A[ATraining Step: 249  | total loss: [1m[32m0.55108[0m[0m | time: 8.469s
[2K
| RMSProp | epoch: 025 | loss: 0.55108 - acc: 0.7313 -- iter: 288/314
[A[ATraining Step: 250  | total loss: [1m[32m0.53423[0m[0m | time: 10.496s
[2K
| RMSProp | epoch: 025 | loss: 0.53423 - acc: 0.7551 | val_loss: 0.55808 - val_acc: 0.7273 -- iter: 314/314
--
Training Step: 251  | total loss: [1m[32m0.51088[0m[0m | time: 0.877s
[2K
| RMSProp | epoch: 026 | loss: 0.51088 - acc: 0.7733 -- iter: 032/314
[A[ATraining Step: 252  | total loss: [1m[32m0.51972[0m[0m | time: 1.656s
[2K
| RMSProp | epoch: 026 | loss: 0.51972 - acc: 0.7679 -- iter: 064/314
[A[ATraining Step: 253  | total loss: [1m[32m0.51929[0m[0m | time: 2.433s
[2K
| RMSProp | epoch: 026 | loss: 0.51929 - acc: 0.7603 -- iter: 096/314
[A[ATraining Step: 254  | total loss: [1m[32m0.52617[0m[0m | time: 3.394s
[2K
| RMSProp | epoch: 026 | loss: 0.52617 - acc: 0.7497 -- iter: 128/314
[A[ATraining Step: 255  | total loss: [1m[32m0.51223[0m[0m | time: 4.313s
[2K
| RMSProp | epoch: 026 | loss: 0.51223 - acc: 0.7684 -- iter: 160/314
[A[ATraining Step: 256  | total loss: [1m[32m0.51096[0m[0m | time: 5.270s
[2K
| RMSProp | epoch: 026 | loss: 0.51096 - acc: 0.7697 -- iter: 192/314
[A[ATraining Step: 257  | total loss: [1m[32m0.49218[0m[0m | time: 6.255s
[2K
| RMSProp | epoch: 026 | loss: 0.49218 - acc: 0.7896 -- iter: 224/314
[A[ATraining Step: 258  | total loss: [1m[32m0.48208[0m[0m | time: 7.139s
[2K
| RMSProp | epoch: 026 | loss: 0.48208 - acc: 0.7950 -- iter: 256/314
[A[ATraining Step: 259  | total loss: [1m[32m0.49825[0m[0m | time: 8.274s
[2K
| RMSProp | epoch: 026 | loss: 0.49825 - acc: 0.7780 -- iter: 288/314
[A[ATraining Step: 260  | total loss: [1m[32m0.52759[0m[0m | time: 10.316s
[2K
| RMSProp | epoch: 026 | loss: 0.52759 - acc: 0.7596 | val_loss: 0.56720 - val_acc: 0.7071 -- iter: 314/314
--
Training Step: 261  | total loss: [1m[32m0.51941[0m[0m | time: 0.961s
[2K
| RMSProp | epoch: 027 | loss: 0.51941 - acc: 0.7711 -- iter: 032/314
[A[ATraining Step: 262  | total loss: [1m[32m0.51104[0m[0m | time: 1.894s
[2K
| RMSProp | epoch: 027 | loss: 0.51104 - acc: 0.7784 -- iter: 064/314
[A[ATraining Step: 263  | total loss: [1m[32m0.48891[0m[0m | time: 2.692s
[2K
| RMSProp | epoch: 027 | loss: 0.48891 - acc: 0.7912 -- iter: 096/314
[A[ATraining Step: 264  | total loss: [1m[32m0.47611[0m[0m | time: 3.437s
[2K
| RMSProp | epoch: 027 | loss: 0.47611 - acc: 0.7967 -- iter: 128/314
[A[ATraining Step: 265  | total loss: [1m[32m0.47184[0m[0m | time: 4.327s
[2K
| RMSProp | epoch: 027 | loss: 0.47184 - acc: 0.8016 -- iter: 160/314
[A[ATraining Step: 266  | total loss: [1m[32m0.46924[0m[0m | time: 5.182s
[2K
| RMSProp | epoch: 027 | loss: 0.46924 - acc: 0.8027 -- iter: 192/314
[A[ATraining Step: 267  | total loss: [1m[32m0.45128[0m[0m | time: 6.407s
[2K
| RMSProp | epoch: 027 | loss: 0.45128 - acc: 0.8131 -- iter: 224/314
[A[ATraining Step: 268  | total loss: [1m[32m0.43169[0m[0m | time: 7.568s
[2K
| RMSProp | epoch: 027 | loss: 0.43169 - acc: 0.8193 -- iter: 256/314
[A[ATraining Step: 269  | total loss: [1m[32m0.40785[0m[0m | time: 8.521s
[2K
| RMSProp | epoch: 027 | loss: 0.40785 - acc: 0.8311 -- iter: 288/314
[A[ATraining Step: 270  | total loss: [1m[32m0.39106[0m[0m | time: 10.295s
[2K
| RMSProp | epoch: 027 | loss: 0.39106 - acc: 0.8417 | val_loss: 1.05484 - val_acc: 0.4747 -- iter: 314/314
--
Training Step: 271  | total loss: [1m[32m0.44370[0m[0m | time: 1.022s
[2K
| RMSProp | epoch: 028 | loss: 0.44370 - acc: 0.8201 -- iter: 032/314
[A[ATraining Step: 272  | total loss: [1m[32m0.48166[0m[0m | time: 1.990s
[2K
| RMSProp | epoch: 028 | loss: 0.48166 - acc: 0.7943 -- iter: 064/314
[A[ATraining Step: 273  | total loss: [1m[32m0.47844[0m[0m | time: 2.878s
[2K
| RMSProp | epoch: 028 | loss: 0.47844 - acc: 0.7899 -- iter: 096/314
[A[ATraining Step: 274  | total loss: [1m[32m0.46235[0m[0m | time: 3.775s
[2K
| RMSProp | epoch: 028 | loss: 0.46235 - acc: 0.8015 -- iter: 128/314
[A[ATraining Step: 275  | total loss: [1m[32m0.44316[0m[0m | time: 4.686s
[2K
| RMSProp | epoch: 028 | loss: 0.44316 - acc: 0.8098 -- iter: 160/314
[A[ATraining Step: 276  | total loss: [1m[32m0.42615[0m[0m | time: 5.693s
[2K
| RMSProp | epoch: 028 | loss: 0.42615 - acc: 0.8173 -- iter: 192/314
[A[ATraining Step: 277  | total loss: [1m[32m0.43824[0m[0m | time: 6.508s
[2K
| RMSProp | epoch: 028 | loss: 0.43824 - acc: 0.8106 -- iter: 224/314
[A[ATraining Step: 278  | total loss: [1m[32m0.43096[0m[0m | time: 7.400s
[2K
| RMSProp | epoch: 028 | loss: 0.43096 - acc: 0.8139 -- iter: 256/314
[A[ATraining Step: 279  | total loss: [1m[32m0.42361[0m[0m | time: 8.313s
[2K
| RMSProp | epoch: 028 | loss: 0.42361 - acc: 0.8169 -- iter: 288/314
[A[ATraining Step: 280  | total loss: [1m[32m0.40902[0m[0m | time: 10.221s
[2K
| RMSProp | epoch: 028 | loss: 0.40902 - acc: 0.8258 | val_loss: 0.64540 - val_acc: 0.6970 -- iter: 314/314
--
Training Step: 281  | total loss: [1m[32m0.39914[0m[0m | time: 0.861s
[2K
| RMSProp | epoch: 029 | loss: 0.39914 - acc: 0.8307 -- iter: 032/314
[A[ATraining Step: 282  | total loss: [1m[32m0.40074[0m[0m | time: 1.802s
[2K
| RMSProp | epoch: 029 | loss: 0.40074 - acc: 0.8289 -- iter: 064/314
[A[ATraining Step: 283  | total loss: [1m[32m0.38833[0m[0m | time: 2.784s
[2K
| RMSProp | epoch: 029 | loss: 0.38833 - acc: 0.8335 -- iter: 096/314
[A[ATraining Step: 284  | total loss: [1m[32m0.37724[0m[0m | time: 3.761s
[2K
| RMSProp | epoch: 029 | loss: 0.37724 - acc: 0.8408 -- iter: 128/314
[A[ATraining Step: 285  | total loss: [1m[32m0.40665[0m[0m | time: 4.572s
[2K
| RMSProp | epoch: 029 | loss: 0.40665 - acc: 0.8223 -- iter: 160/314
[A[ATraining Step: 286  | total loss: [1m[32m0.38934[0m[0m | time: 5.459s
[2K
| RMSProp | epoch: 029 | loss: 0.38934 - acc: 0.8286 -- iter: 192/314
[A[ATraining Step: 287  | total loss: [1m[32m0.38611[0m[0m | time: 6.418s
[2K
| RMSProp | epoch: 029 | loss: 0.38611 - acc: 0.8342 -- iter: 224/314
[A[ATraining Step: 288  | total loss: [1m[32m0.37641[0m[0m | time: 7.226s
[2K
| RMSProp | epoch: 029 | loss: 0.37641 - acc: 0.8414 -- iter: 256/314
[A[ATraining Step: 289  | total loss: [1m[32m0.37053[0m[0m | time: 7.888s
[2K
| RMSProp | epoch: 029 | loss: 0.37053 - acc: 0.8416 -- iter: 288/314
[A[ATraining Step: 290  | total loss: [1m[32m0.35333[0m[0m | time: 9.555s
[2K
| RMSProp | epoch: 029 | loss: 0.35333 - acc: 0.8512 | val_loss: 0.60964 - val_acc: 0.7374 -- iter: 314/314
--
Training Step: 291  | total loss: [1m[32m0.33469[0m[0m | time: 0.840s
[2K
| RMSProp | epoch: 030 | loss: 0.33469 - acc: 0.8630 -- iter: 032/314
[A[ATraining Step: 292  | total loss: [1m[32m0.33360[0m[0m | time: 1.672s
[2K
| RMSProp | epoch: 030 | loss: 0.33360 - acc: 0.8673 -- iter: 064/314
[A[ATraining Step: 293  | total loss: [1m[32m0.37551[0m[0m | time: 2.477s
[2K
| RMSProp | epoch: 030 | loss: 0.37551 - acc: 0.8399 -- iter: 096/314
[A[ATraining Step: 294  | total loss: [1m[32m0.38421[0m[0m | time: 3.298s
[2K
| RMSProp | epoch: 030 | loss: 0.38421 - acc: 0.8372 -- iter: 128/314
[A[ATraining Step: 295  | total loss: [1m[32m0.37246[0m[0m | time: 4.131s
[2K
| RMSProp | epoch: 030 | loss: 0.37246 - acc: 0.8472 -- iter: 160/314
[A[ATraining Step: 296  | total loss: [1m[32m0.34508[0m[0m | time: 4.821s
[2K
| RMSProp | epoch: 030 | loss: 0.34508 - acc: 0.8625 -- iter: 192/314
[A[ATraining Step: 297  | total loss: [1m[32m0.33184[0m[0m | time: 5.483s
[2K
| RMSProp | epoch: 030 | loss: 0.33184 - acc: 0.8686 -- iter: 224/314
[A[ATraining Step: 298  | total loss: [1m[32m0.33943[0m[0m | time: 6.369s
[2K
| RMSProp | epoch: 030 | loss: 0.33943 - acc: 0.8663 -- iter: 256/314
[A[ATraining Step: 299  | total loss: [1m[32m0.33797[0m[0m | time: 7.225s
[2K
| RMSProp | epoch: 030 | loss: 0.33797 - acc: 0.8672 -- iter: 288/314
[A[ATraining Step: 300  | total loss: [1m[32m0.35352[0m[0m | time: 9.151s
[2K
| RMSProp | epoch: 030 | loss: 0.35352 - acc: 0.8555 | val_loss: 0.47464 - val_acc: 0.8081 -- iter: 314/314
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8433994823123383
Validation AUPRC:0.8904705037034399
Test AUC:0.8402203856749312
Test AUPRC:0.9011548126895033
BestTestF1Score	0.88	0.6	0.83	0.82	0.95	63	14	19	3	0.5
BestTestMCCScore	0.88	0.6	0.83	0.82	0.95	63	14	19	3	0.5
BestTestAccuracyScore	0.88	0.6	0.83	0.82	0.95	63	14	19	3	0.54
BestValidationF1Score	0.85	0.59	0.81	0.8	0.92	56	14	24	5	0.5
BestValidationMCC	0.85	0.59	0.81	0.8	0.92	56	14	24	5	0.5
BestValidationAccuracy	0.85	0.59	0.81	0.81	0.9	55	13	25	6	0.54
TestPredictions (Threshold:0.5)
CHEMBL2338389,TP,ACT,0.7200000286102295	CHEMBL1209243,FN,ACT,0.41999998688697815	CHEMBL3787063,TP,ACT,0.8700000047683716	CHEMBL257155,TP,ACT,0.8600000143051147	CHEMBL965,TN,INACT,0.10999999940395355	CHEMBL3085543,TP,ACT,0.8999999761581421	CHEMBL195345,TP,ACT,0.800000011920929	CHEMBL3786820,TP,ACT,0.8899999856948853	CHEMBL409988,TP,ACT,0.8899999856948853	CHEMBL2112852,FP,INACT,0.9100000262260437	CHEMBL194100,TP,ACT,0.8799999952316284	CHEMBL298826,TP,ACT,0.9300000071525574	CHEMBL333465,TN,INACT,0.05999999865889549	CHEMBL2323566,TN,INACT,0.46000000834465027	CHEMBL3274975,TN,INACT,0.18000000715255737	CHEMBL3235495,TP,ACT,0.7699999809265137	CHEMBL2441756,TN,INACT,0.10999999940395355	CHEMBL289469,FP,INACT,0.8299999833106995	CHEMBL1255907,TP,ACT,0.9399999976158142	CHEMBL524813,FP,INACT,0.7799999713897705	CHEMBL2381567,TN,INACT,0.1899999976158142	CHEMBL479015,TN,INACT,0.25999999046325684	CHEMBL2179862,TP,ACT,0.8100000023841858	CHEMBL448,FP,INACT,0.6800000071525574	CHEMBL2179866,TP,ACT,0.9700000286102295	CHEMBL2371820,TP,ACT,0.9100000262260437	CHEMBL280963,TP,ACT,0.8600000143051147	CHEMBL1209070,TP,ACT,0.8600000143051147	CHEMBL2179539,TP,ACT,0.8799999952316284	CHEMBL3121475,TN,INACT,0.17000000178813934	CHEMBL403858,TP,ACT,0.8999999761581421	CHEMBL486781,TN,INACT,0.09000000357627869	CHEMBL1258125,TP,ACT,0.9599999785423279	CHEMBL2179878,TP,ACT,0.8999999761581421	CHEMBL2177520,TP,ACT,0.8600000143051147	CHEMBL2177526,TP,ACT,0.8899999856948853	CHEMBL191491,FN,ACT,0.09000000357627869	CHEMBL3133452,TP,ACT,0.6800000071525574	CHEMBL3337865,TP,ACT,0.9200000166893005	CHEMBL3612361,TN,INACT,0.09000000357627869	CHEMBL3787561,TP,ACT,0.8999999761581421	CHEMBL2178155,TP,ACT,0.9300000071525574	CHEMBL2180253,TP,ACT,0.9599999785423279	CHEMBL2409486,TP,ACT,0.9399999976158142	CHEMBL2402893,TN,INACT,0.07999999821186066	CHEMBL2179880,TP,ACT,0.9599999785423279	CHEMBL142049,FN,ACT,0.49000000953674316	CHEMBL3133450,TP,ACT,0.949999988079071	CHEMBL199152,TP,ACT,0.8799999952316284	CHEMBL415570,TP,ACT,0.8299999833106995	CHEMBL2151439,TP,ACT,0.75	CHEMBL488381,TN,INACT,0.10000000149011612	CHEMBL2177521,TP,ACT,0.8299999833106995	CHEMBL3699106,TP,ACT,0.8600000143051147	CHEMBL2441758,TN,INACT,0.12999999523162842	CHEMBL1210518,TP,ACT,0.5600000023841858	CHEMBL2179526,TP,ACT,0.75	CHEMBL191947,TN,INACT,0.05999999865889549	CHEMBL11608,FP,INACT,0.8299999833106995	CHEMBL2180257,TP,ACT,0.949999988079071	CHEMBL510275,TP,ACT,0.8799999952316284	CHEMBL2178156,TP,ACT,0.9300000071525574	CHEMBL46,FP,INACT,0.8899999856948853	CHEMBL508949,TN,INACT,0.4000000059604645	CHEMBL415568,TP,ACT,0.9399999976158142	CHEMBL3335589,TP,ACT,0.9100000262260437	CHEMBL274413,FP,INACT,0.8500000238418579	CHEMBL2179854,TP,ACT,0.9700000286102295	CHEMBL2409476,TP,ACT,0.7900000214576721	CHEMBL2179554,TP,ACT,0.6700000166893005	CHEMBL3121480,TN,INACT,0.18000000715255737	CHEMBL3094062,TP,ACT,0.8399999737739563	CHEMBL1258240,TP,ACT,0.9399999976158142	CHEMBL2177523,TP,ACT,0.9300000071525574	CHEMBL2177545,TP,ACT,0.8199999928474426	CHEMBL2151444,TP,ACT,0.7900000214576721	CHEMBL16117,TN,INACT,0.10999999940395355	CHEMBL231592,FP,INACT,0.8799999952316284	CHEMBL3699089,TP,ACT,0.9100000262260437	CHEMBL3302240,TP,ACT,0.9300000071525574	CHEMBL1669092,TP,ACT,0.7300000190734863	CHEMBL1917227,TN,INACT,0.10000000149011612	CHEMBL1209187,TP,ACT,0.6000000238418579	CHEMBL3104241,TP,ACT,0.8999999761581421	CHEMBL3341962,TP,ACT,0.75	CHEMBL2440299,TP,ACT,0.9399999976158142	CHEMBL2179870,TP,ACT,0.9300000071525574	CHEMBL388047,TP,ACT,0.6700000166893005	CHEMBL1210458,TP,ACT,0.8600000143051147	CHEMBL2409484,FP,INACT,0.9300000071525574	CHEMBL1917223,FP,INACT,0.6399999856948853	CHEMBL2177553,TP,ACT,0.9599999785423279	CHEMBL3759208,FP,INACT,0.7799999713897705	CHEMBL3699087,TP,ACT,0.9200000166893005	CHEMBL3355097,TP,ACT,0.5400000214576721	CHEMBL1276200,FP,INACT,0.6000000238418579	CHEMBL2297684,FP,INACT,0.9200000166893005	CHEMBL480686,TN,INACT,0.1899999976158142	CHEMBL111864,FP,INACT,0.7200000286102295	

