ImageNetInceptionV2 CHEMBL4204 adam 0.0001 5 0 0 0.6 False True
Number of active compounds :	264
Number of inactive compounds :	264
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4204_adam_0.0001_5_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4204_adam_0.0001_5_0.6/
---------------------------------
Training samples: 336
Validation samples: 106
--
Training Step: 1  | time: 1306.742s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/336
[A[ATraining Step: 2  | total loss: [1m[32m0.72493[0m[0m | time: 1883.105s
[2K
| Adam | epoch: 001 | loss: 0.72493 - acc: 0.4219 -- iter: 064/336
[A[ATraining Step: 3  | total loss: [1m[32m0.70898[0m[0m | time: 2169.925s
[2K
| Adam | epoch: 001 | loss: 0.70898 - acc: 0.5114 -- iter: 096/336
[A[ATraining Step: 4  | total loss: [1m[32m0.65420[0m[0m | time: 2295.528s
[2K
| Adam | epoch: 001 | loss: 0.65420 - acc: 0.6669 -- iter: 128/336
[A[ATraining Step: 5  | total loss: [1m[32m0.67179[0m[0m | time: 2449.393s
[2K
| Adam | epoch: 001 | loss: 0.67179 - acc: 0.5730 -- iter: 160/336
[A[ATraining Step: 6  | total loss: [1m[32m0.63618[0m[0m | time: 2577.851s
[2K
| Adam | epoch: 001 | loss: 0.63618 - acc: 0.6265 -- iter: 192/336
[A[ATraining Step: 7  | total loss: [1m[32m0.56726[0m[0m | time: 2708.250s
[2K
| Adam | epoch: 001 | loss: 0.56726 - acc: 0.6819 -- iter: 224/336
[A[ATraining Step: 8  | total loss: [1m[32m0.55114[0m[0m | time: 2919.555s
[2K
| Adam | epoch: 001 | loss: 0.55114 - acc: 0.6675 -- iter: 256/336
[A[ATraining Step: 9  | total loss: [1m[32m0.55231[0m[0m | time: 2932.124s
[2K
| Adam | epoch: 001 | loss: 0.55231 - acc: 0.7277 -- iter: 288/336
[A[ATraining Step: 10  | total loss: [1m[32m0.52683[0m[0m | time: 3189.305s
[2K
| Adam | epoch: 001 | loss: 0.52683 - acc: 0.7545 -- iter: 320/336
[A[ATraining Step: 11  | total loss: [1m[32m0.61722[0m[0m | time: 3219.267s
[2K
| Adam | epoch: 001 | loss: 0.61722 - acc: 0.6783 | val_loss: 1.62716 - val_acc: 0.4528 -- iter: 336/336
--
Training Step: 12  | total loss: [1m[32m0.55516[0m[0m | time: 75.370s
[2K
| Adam | epoch: 002 | loss: 0.55516 - acc: 0.7668 -- iter: 032/336
[A[ATraining Step: 13  | total loss: [1m[32m0.46027[0m[0m | time: 280.373s
[2K
| Adam | epoch: 002 | loss: 0.46027 - acc: 0.8132 -- iter: 064/336
[A[ATraining Step: 14  | total loss: [1m[32m0.45975[0m[0m | time: 291.439s
[2K
| Adam | epoch: 002 | loss: 0.45975 - acc: 0.8129 -- iter: 096/336
[A[ATraining Step: 15  | total loss: [1m[32m0.45708[0m[0m | time: 299.923s
[2K
| Adam | epoch: 002 | loss: 0.45708 - acc: 0.8372 -- iter: 128/336
[A[ATraining Step: 16  | total loss: [1m[32m0.42736[0m[0m | time: 308.548s
[2K
| Adam | epoch: 002 | loss: 0.42736 - acc: 0.8631 -- iter: 160/336
[A[ATraining Step: 17  | total loss: [1m[32m0.38307[0m[0m | time: 317.348s
[2K
| Adam | epoch: 002 | loss: 0.38307 - acc: 0.8899 -- iter: 192/336
[A[ATraining Step: 18  | total loss: [1m[32m0.33916[0m[0m | time: 325.587s
[2K
| Adam | epoch: 002 | loss: 0.33916 - acc: 0.9172 -- iter: 224/336
[A[ATraining Step: 19  | total loss: [1m[32m0.31279[0m[0m | time: 335.557s
[2K
| Adam | epoch: 002 | loss: 0.31279 - acc: 0.9135 -- iter: 256/336
[A[ATraining Step: 20  | total loss: [1m[32m0.34374[0m[0m | time: 344.571s
[2K
| Adam | epoch: 002 | loss: 0.34374 - acc: 0.8911 -- iter: 288/336
[A[ATraining Step: 21  | total loss: [1m[32m0.33240[0m[0m | time: 352.685s
[2K
| Adam | epoch: 002 | loss: 0.33240 - acc: 0.8861 -- iter: 320/336
[A[ATraining Step: 22  | total loss: [1m[32m0.33493[0m[0m | time: 386.516s
[2K
| Adam | epoch: 002 | loss: 0.33493 - acc: 0.8640 | val_loss: 1.93307 - val_acc: 0.4528 -- iter: 336/336
--
Training Step: 23  | total loss: [1m[32m0.33871[0m[0m | time: 5.035s
[2K
| Adam | epoch: 003 | loss: 0.33871 - acc: 0.8672 -- iter: 032/336
[A[ATraining Step: 24  | total loss: [1m[32m0.30823[0m[0m | time: 9.767s
[2K
| Adam | epoch: 003 | loss: 0.30823 - acc: 0.8694 -- iter: 064/336
[A[ATraining Step: 25  | total loss: [1m[32m0.26200[0m[0m | time: 65.211s
[2K
| Adam | epoch: 003 | loss: 0.26200 - acc: 0.9050 -- iter: 096/336
[A[ATraining Step: 26  | total loss: [1m[32m0.29699[0m[0m | time: 98.803s
[2K
| Adam | epoch: 003 | loss: 0.29699 - acc: 0.8888 -- iter: 128/336
[A[ATraining Step: 27  | total loss: [1m[32m0.27465[0m[0m | time: 107.712s
[2K
| Adam | epoch: 003 | loss: 0.27465 - acc: 0.8933 -- iter: 160/336
[A[ATraining Step: 28  | total loss: [1m[32m0.24119[0m[0m | time: 116.553s
[2K
| Adam | epoch: 003 | loss: 0.24119 - acc: 0.9122 -- iter: 192/336
[A[ATraining Step: 29  | total loss: [1m[32m0.20924[0m[0m | time: 131.874s
[2K
| Adam | epoch: 003 | loss: 0.20924 - acc: 0.9335 -- iter: 224/336
[A[ATraining Step: 30  | total loss: [1m[32m0.17946[0m[0m | time: 140.350s
[2K
| Adam | epoch: 003 | loss: 0.17946 - acc: 0.9493 -- iter: 256/336
[A[ATraining Step: 31  | total loss: [1m[32m0.15395[0m[0m | time: 148.914s
[2K
| Adam | epoch: 003 | loss: 0.15395 - acc: 0.9610 -- iter: 288/336
[A[ATraining Step: 32  | total loss: [1m[32m0.13293[0m[0m | time: 157.591s
[2K
| Adam | epoch: 003 | loss: 0.13293 - acc: 0.9698 -- iter: 320/336
[A[ATraining Step: 33  | total loss: [1m[32m0.11543[0m[0m | time: 171.177s
[2K
| Adam | epoch: 003 | loss: 0.11543 - acc: 0.9764 | val_loss: 1.50547 - val_acc: 0.4528 -- iter: 336/336
--
Training Step: 34  | total loss: [1m[32m0.10461[0m[0m | time: 12.257s
[2K
| Adam | epoch: 004 | loss: 0.10461 - acc: 0.9748 -- iter: 032/336
[A[ATraining Step: 35  | total loss: [1m[32m0.09051[0m[0m | time: 16.995s
[2K
| Adam | epoch: 004 | loss: 0.09051 - acc: 0.9800 -- iter: 064/336
[A[ATraining Step: 36  | total loss: [1m[32m0.08617[0m[0m | time: 21.770s
[2K
| Adam | epoch: 004 | loss: 0.08617 - acc: 0.9841 -- iter: 096/336
[A[ATraining Step: 37  | total loss: [1m[32m0.07339[0m[0m | time: 42.398s
[2K
| Adam | epoch: 004 | loss: 0.07339 - acc: 0.9873 -- iter: 128/336
[A[ATraining Step: 38  | total loss: [1m[32m0.06827[0m[0m | time: 50.660s
[2K
| Adam | epoch: 004 | loss: 0.06827 - acc: 0.9898 -- iter: 160/336
[A[ATraining Step: 39  | total loss: [1m[32m0.05920[0m[0m | time: 109.038s
[2K
| Adam | epoch: 004 | loss: 0.05920 - acc: 0.9917 -- iter: 192/336
[A[ATraining Step: 40  | total loss: [1m[32m0.10467[0m[0m | time: 117.744s
[2K
| Adam | epoch: 004 | loss: 0.10467 - acc: 0.9874 -- iter: 224/336
[A[ATraining Step: 41  | total loss: [1m[32m0.08728[0m[0m | time: 142.628s
[2K
| Adam | epoch: 004 | loss: 0.08728 - acc: 0.9897 -- iter: 256/336
[A[ATraining Step: 42  | total loss: [1m[32m0.08367[0m[0m | time: 151.036s
[2K
| Adam | epoch: 004 | loss: 0.08367 - acc: 0.9916 -- iter: 288/336
[A[ATraining Step: 43  | total loss: [1m[32m0.07020[0m[0m | time: 159.504s
[2K
| Adam | epoch: 004 | loss: 0.07020 - acc: 0.9931 -- iter: 320/336
[A[ATraining Step: 44  | total loss: [1m[32m0.05970[0m[0m | time: 173.265s
[2K
| Adam | epoch: 004 | loss: 0.05970 - acc: 0.9943 | val_loss: 1.66577 - val_acc: 0.4528 -- iter: 336/336
--
Training Step: 45  | total loss: [1m[32m0.05764[0m[0m | time: 8.827s
[2K
| Adam | epoch: 005 | loss: 0.05764 - acc: 0.9899 -- iter: 032/336
[A[ATraining Step: 46  | total loss: [1m[32m0.04947[0m[0m | time: 17.086s
[2K
| Adam | epoch: 005 | loss: 0.04947 - acc: 0.9916 -- iter: 064/336
[A[ATraining Step: 47  | total loss: [1m[32m0.05158[0m[0m | time: 21.665s
[2K
| Adam | epoch: 005 | loss: 0.05158 - acc: 0.9879 -- iter: 096/336
[A[ATraining Step: 48  | total loss: [1m[32m0.04424[0m[0m | time: 26.230s
[2K
| Adam | epoch: 005 | loss: 0.04424 - acc: 0.9898 -- iter: 128/336
[A[ATraining Step: 49  | total loss: [1m[32m0.03780[0m[0m | time: 42.386s
[2K
| Adam | epoch: 005 | loss: 0.03780 - acc: 0.9914 -- iter: 160/336
[A[ATraining Step: 50  | total loss: [1m[32m0.03367[0m[0m | time: 51.003s
[2K
| Adam | epoch: 005 | loss: 0.03367 - acc: 0.9928 -- iter: 192/336
[A[ATraining Step: 51  | total loss: [1m[32m0.03163[0m[0m | time: 62.077s
[2K
| Adam | epoch: 005 | loss: 0.03163 - acc: 0.9939 -- iter: 224/336
[A[ATraining Step: 52  | total loss: [1m[32m0.05864[0m[0m | time: 70.399s
[2K
| Adam | epoch: 005 | loss: 0.05864 - acc: 0.9901 -- iter: 256/336
[A[ATraining Step: 53  | total loss: [1m[32m0.05155[0m[0m | time: 96.580s
[2K
| Adam | epoch: 005 | loss: 0.05155 - acc: 0.9916 -- iter: 288/336
[A[ATraining Step: 54  | total loss: [1m[32m0.04565[0m[0m | time: 104.948s
[2K
| Adam | epoch: 005 | loss: 0.04565 - acc: 0.9928 -- iter: 320/336
[A[ATraining Step: 55  | total loss: [1m[32m0.04228[0m[0m | time: 128.706s
[2K
| Adam | epoch: 005 | loss: 0.04228 - acc: 0.9938 | val_loss: 0.81068 - val_acc: 0.5943 -- iter: 336/336
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9292385057471264
Validation AUPRC:0.9331656658241164
Test AUC:0.8809269162210339
Test AUPRC:0.9073858141408095
BestTestF1Score	0.87	0.78	0.89	0.95	0.8	41	2	53	10	0.94
BestTestMCCScore	0.87	0.78	0.89	0.95	0.8	41	2	53	10	0.94
BestTestAccuracyScore	0.87	0.78	0.89	0.95	0.8	41	2	53	10	0.94
BestValidationF1Score	0.88	0.79	0.9	0.93	0.83	40	3	55	8	0.94
BestValidationMCC	0.88	0.79	0.9	0.93	0.83	40	3	55	8	0.94
BestValidationAccuracy	0.88	0.79	0.9	0.93	0.83	40	3	55	8	0.94
TestPredictions (Threshold:0.94)
CHEMBL3702294,TP,ACT,0.9800000190734863	CHEMBL3623850,TN,INACT,0.8700000047683716	CHEMBL3640011,TP,ACT,0.9900000095367432	CHEMBL3698921,TP,ACT,0.9800000190734863	CHEMBL3335362,TN,INACT,0.38999998569488525	CHEMBL523938,TN,INACT,0.5799999833106995	CHEMBL2178352,TP,ACT,0.9599999785423279	CHEMBL1688219,TN,INACT,0.23000000417232513	CHEMBL3702349,TP,ACT,0.9900000095367432	CHEMBL337454,TN,INACT,0.9200000166893005	CHEMBL1171125,TN,INACT,0.9399999976158142	CHEMBL3680499,TN,INACT,0.10000000149011612	CHEMBL396487,TN,INACT,0.9300000071525574	CHEMBL3698914,TP,ACT,0.9900000095367432	CHEMBL563281,TN,INACT,0.4699999988079071	CHEMBL1287914,TN,INACT,0.8100000023841858	CHEMBL402355,TN,INACT,0.23999999463558197	CHEMBL3698953,FN,ACT,0.8799999952316284	CHEMBL3702279,TP,ACT,0.9800000190734863	CHEMBL1241462,FN,ACT,0.23000000417232513	CHEMBL173478,TN,INACT,0.28999999165534973	CHEMBL3702301,TP,ACT,0.9900000095367432	CHEMBL3702347,TP,ACT,0.9900000095367432	CHEMBL3702356,TP,ACT,0.9900000095367432	CHEMBL367442,TN,INACT,0.5699999928474426	CHEMBL3698949,TP,ACT,1.0	CHEMBL506669,TN,INACT,0.7799999713897705	CHEMBL3632744,TP,ACT,0.9800000190734863	CHEMBL3702313,TP,ACT,0.9900000095367432	CHEMBL3702263,TP,ACT,0.9900000095367432	CHEMBL3702338,TP,ACT,0.9900000095367432	CHEMBL3698932,TP,ACT,0.9900000095367432	CHEMBL3417204,TP,ACT,0.9800000190734863	CHEMBL3702299,TP,ACT,0.9900000095367432	CHEMBL3702331,TP,ACT,0.9599999785423279	CHEMBL3702319,TP,ACT,0.9800000190734863	CHEMBL2420909,TN,INACT,0.25999999046325684	CHEMBL3797559,FN,ACT,0.20000000298023224	CHEMBL3698926,TP,ACT,0.9700000286102295	CHEMBL2392385,TN,INACT,0.07000000029802322	CHEMBL603469,FN,ACT,0.03999999910593033	CHEMBL3702315,TP,ACT,0.9800000190734863	CHEMBL2029522,TN,INACT,0.3400000035762787	CHEMBL100670,TN,INACT,0.46000000834465027	CHEMBL3596524,TN,INACT,0.75	CHEMBL2164716,TN,INACT,0.6499999761581421	CHEMBL1767294,TN,INACT,0.9399999976158142	CHEMBL1922121,TN,INACT,0.4099999964237213	CHEMBL3691604,TN,INACT,0.8399999737739563	CHEMBL95477,TN,INACT,0.4300000071525574	CHEMBL558859,TN,INACT,0.25999999046325684	CHEMBL3698944,TP,ACT,0.9800000190734863	CHEMBL1336,FN,ACT,0.8899999856948853	CHEMBL2312652,TN,INACT,0.8600000143051147	CHEMBL3702342,TP,ACT,0.9900000095367432	CHEMBL419069,TN,INACT,0.8100000023841858	CHEMBL1762116,TN,INACT,0.8199999928474426	CHEMBL3639713,TN,INACT,0.07999999821186066	CHEMBL3806189,TP,ACT,0.9800000190734863	CHEMBL319709,TN,INACT,0.36000001430511475	CHEMBL495758,TN,INACT,0.5	CHEMBL77155,FP,INACT,0.9700000286102295	CHEMBL1910759,TN,INACT,0.8100000023841858	CHEMBL226471,TN,INACT,0.6100000143051147	CHEMBL3659486,TP,ACT,0.9800000190734863	CHEMBL3702268,TP,ACT,0.9800000190734863	CHEMBL3805956,TP,ACT,0.9900000095367432	CHEMBL3698947,TP,ACT,0.9800000190734863	CHEMBL550856,TN,INACT,0.03999999910593033	CHEMBL2012390,FN,ACT,0.6899999976158142	CHEMBL3085242,TN,INACT,0.7599999904632568	CHEMBL3698938,TP,ACT,0.9900000095367432	CHEMBL296468,FN,ACT,0.7900000214576721	CHEMBL173453,TN,INACT,0.8199999928474426	CHEMBL3417208,TP,ACT,0.9700000286102295	CHEMBL169757,TN,INACT,0.05999999865889549	CHEMBL3702282,TP,ACT,0.9900000095367432	CHEMBL3698931,TP,ACT,0.9900000095367432	CHEMBL133477,TN,INACT,0.6399999856948853	CHEMBL1789941,FN,ACT,0.25999999046325684	CHEMBL3702318,FN,ACT,0.9300000071525574	CHEMBL1257164,TN,INACT,0.6399999856948853	CHEMBL3702278,TP,ACT,0.9900000095367432	CHEMBL1240885,FN,ACT,0.46000000834465027	CHEMBL2392390,TN,INACT,0.6200000047683716	CHEMBL1933802,TN,INACT,0.8999999761581421	CHEMBL3702314,TP,ACT,0.9800000190734863	CHEMBL3702310,TP,ACT,0.949999988079071	CHEMBL1734241,TN,INACT,0.8600000143051147	CHEMBL1910373,TN,INACT,0.4699999988079071	CHEMBL3746916,TN,INACT,0.8299999833106995	CHEMBL1688212,TN,INACT,0.550000011920929	CHEMBL261143,TN,INACT,0.3700000047683716	CHEMBL3698958,TP,ACT,0.9599999785423279	CHEMBL3417201,TP,ACT,0.949999988079071	CHEMBL2420584,TN,INACT,0.5199999809265137	CHEMBL3698940,TP,ACT,0.9900000095367432	CHEMBL86771,TN,INACT,0.8399999737739563	CHEMBL599519,FP,INACT,0.9900000095367432	CHEMBL3680484,TN,INACT,0.8899999856948853	CHEMBL3698941,TP,ACT,0.9900000095367432	CHEMBL228114,TN,INACT,0.05000000074505806	CHEMBL1688206,TN,INACT,0.6399999856948853	CHEMBL2070409,TN,INACT,0.9200000166893005	CHEMBL3702259,TP,ACT,0.9900000095367432	CHEMBL1287945,TN,INACT,0.8600000143051147	

