ImageNetInceptionV2 CHEMBL3905 adam 0.0001 5 0 0 0.6 False True
Number of active compounds :	239
Number of inactive compounds :	239
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3905_adam_0.0001_5_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3905_adam_0.0001_5_0.6/
---------------------------------
Training samples: 274
Validation samples: 86
--
Training Step: 1  | time: 55.784s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/274
[A[ATraining Step: 2  | total loss: [1m[32m0.58945[0m[0m | time: 73.810s
[2K
| Adam | epoch: 001 | loss: 0.58945 - acc: 0.6187 -- iter: 064/274
[A[ATraining Step: 3  | total loss: [1m[32m0.72875[0m[0m | time: 91.194s
[2K
| Adam | epoch: 001 | loss: 0.72875 - acc: 0.4705 -- iter: 096/274
[A[ATraining Step: 4  | total loss: [1m[32m0.73050[0m[0m | time: 108.691s
[2K
| Adam | epoch: 001 | loss: 0.73050 - acc: 0.5161 -- iter: 128/274
[A[ATraining Step: 5  | total loss: [1m[32m0.66932[0m[0m | time: 126.514s
[2K
| Adam | epoch: 001 | loss: 0.66932 - acc: 0.6347 -- iter: 160/274
[A[ATraining Step: 6  | total loss: [1m[32m0.61953[0m[0m | time: 139.566s
[2K
| Adam | epoch: 001 | loss: 0.61953 - acc: 0.6887 -- iter: 192/274
[A[ATraining Step: 7  | total loss: [1m[32m0.61837[0m[0m | time: 150.543s
[2K
| Adam | epoch: 001 | loss: 0.61837 - acc: 0.7067 -- iter: 224/274
[A[ATraining Step: 8  | total loss: [1m[32m0.65153[0m[0m | time: 160.895s
[2K
| Adam | epoch: 001 | loss: 0.65153 - acc: 0.6080 -- iter: 256/274
[A[ATraining Step: 9  | total loss: [1m[32m0.62519[0m[0m | time: 191.840s
[2K
| Adam | epoch: 001 | loss: 0.62519 - acc: 0.6336 | val_loss: 0.86279 - val_acc: 0.4884 -- iter: 274/274
--
Training Step: 10  | total loss: [1m[32m0.51420[0m[0m | time: 7.799s
[2K
| Adam | epoch: 002 | loss: 0.51420 - acc: 0.7612 -- iter: 032/274
[A[ATraining Step: 11  | total loss: [1m[32m0.45109[0m[0m | time: 18.546s
[2K
| Adam | epoch: 002 | loss: 0.45109 - acc: 0.8217 -- iter: 064/274
[A[ATraining Step: 12  | total loss: [1m[32m0.40735[0m[0m | time: 31.374s
[2K
| Adam | epoch: 002 | loss: 0.40735 - acc: 0.8738 -- iter: 096/274
[A[ATraining Step: 13  | total loss: [1m[32m0.43381[0m[0m | time: 46.686s
[2K
| Adam | epoch: 002 | loss: 0.43381 - acc: 0.8074 -- iter: 128/274
[A[ATraining Step: 14  | total loss: [1m[32m0.37857[0m[0m | time: 66.007s
[2K
| Adam | epoch: 002 | loss: 0.37857 - acc: 0.8478 -- iter: 160/274
[A[ATraining Step: 15  | total loss: [1m[32m0.41106[0m[0m | time: 84.400s
[2K
| Adam | epoch: 002 | loss: 0.41106 - acc: 0.8462 -- iter: 192/274
[A[ATraining Step: 16  | total loss: [1m[32m0.42834[0m[0m | time: 101.147s
[2K
| Adam | epoch: 002 | loss: 0.42834 - acc: 0.8101 -- iter: 224/274
[A[ATraining Step: 17  | total loss: [1m[32m0.47439[0m[0m | time: 114.395s
[2K
| Adam | epoch: 002 | loss: 0.47439 - acc: 0.7772 -- iter: 256/274
[A[ATraining Step: 18  | total loss: [1m[32m0.44901[0m[0m | time: 135.732s
[2K
| Adam | epoch: 002 | loss: 0.44901 - acc: 0.8003 | val_loss: 0.91824 - val_acc: 0.4884 -- iter: 274/274
--
Training Step: 19  | total loss: [1m[32m0.39413[0m[0m | time: 11.730s
[2K
| Adam | epoch: 003 | loss: 0.39413 - acc: 0.8252 -- iter: 032/274
[A[ATraining Step: 20  | total loss: [1m[32m0.32553[0m[0m | time: 23.350s
[2K
| Adam | epoch: 003 | loss: 0.32553 - acc: 0.8814 -- iter: 064/274
[A[ATraining Step: 21  | total loss: [1m[32m0.25574[0m[0m | time: 37.976s
[2K
| Adam | epoch: 003 | loss: 0.25574 - acc: 0.9182 -- iter: 096/274
[A[ATraining Step: 22  | total loss: [1m[32m0.23652[0m[0m | time: 51.059s
[2K
| Adam | epoch: 003 | loss: 0.23652 - acc: 0.9427 -- iter: 128/274
[A[ATraining Step: 23  | total loss: [1m[32m0.29110[0m[0m | time: 67.719s
[2K
| Adam | epoch: 003 | loss: 0.29110 - acc: 0.8868 -- iter: 160/274
[A[ATraining Step: 24  | total loss: [1m[32m0.24388[0m[0m | time: 94.230s
[2K
| Adam | epoch: 003 | loss: 0.24388 - acc: 0.9010 -- iter: 192/274
[A[ATraining Step: 25  | total loss: [1m[32m0.23921[0m[0m | time: 191.782s
[2K
| Adam | epoch: 003 | loss: 0.23921 - acc: 0.8769 -- iter: 224/274
[A[ATraining Step: 26  | total loss: [1m[32m0.21398[0m[0m | time: 285.099s
[2K
| Adam | epoch: 003 | loss: 0.21398 - acc: 0.9095 -- iter: 256/274
[A[ATraining Step: 27  | total loss: [1m[32m0.23024[0m[0m | time: 651.830s
[2K
| Adam | epoch: 003 | loss: 0.23024 - acc: 0.8926 | val_loss: 0.83090 - val_acc: 0.5116 -- iter: 274/274
--
Training Step: 28  | total loss: [1m[32m0.24338[0m[0m | time: 13.001s
[2K
| Adam | epoch: 004 | loss: 0.24338 - acc: 0.8804 -- iter: 032/274
[A[ATraining Step: 29  | total loss: [1m[32m0.20349[0m[0m | time: 21.762s
[2K
| Adam | epoch: 004 | loss: 0.20349 - acc: 0.9095 -- iter: 064/274
[A[ATraining Step: 30  | total loss: [1m[32m0.16857[0m[0m | time: 30.034s
[2K
| Adam | epoch: 004 | loss: 0.16857 - acc: 0.9309 -- iter: 096/274
[A[ATraining Step: 31  | total loss: [1m[32m0.13951[0m[0m | time: 41.850s
[2K
| Adam | epoch: 004 | loss: 0.13951 - acc: 0.9469 -- iter: 128/274
[A[ATraining Step: 32  | total loss: [1m[32m0.11814[0m[0m | time: 61.849s
[2K
| Adam | epoch: 004 | loss: 0.11814 - acc: 0.9588 -- iter: 160/274
[A[ATraining Step: 33  | total loss: [1m[32m0.13266[0m[0m | time: 74.573s
[2K
| Adam | epoch: 004 | loss: 0.13266 - acc: 0.9541 -- iter: 192/274
[A[ATraining Step: 34  | total loss: [1m[32m0.13225[0m[0m | time: 96.370s
[2K
| Adam | epoch: 004 | loss: 0.13225 - acc: 0.9439 -- iter: 224/274
[A[ATraining Step: 35  | total loss: [1m[32m0.13975[0m[0m | time: 135.895s
[2K
| Adam | epoch: 004 | loss: 0.13975 - acc: 0.9425 -- iter: 256/274
[A[ATraining Step: 36  | total loss: [1m[32m0.11778[0m[0m | time: 162.338s
[2K
| Adam | epoch: 004 | loss: 0.11778 - acc: 0.9543 | val_loss: 1.14543 - val_acc: 0.5116 -- iter: 274/274
--
Training Step: 37  | total loss: [1m[32m0.10218[0m[0m | time: 8.229s
[2K
| Adam | epoch: 005 | loss: 0.10218 - acc: 0.9634 -- iter: 032/274
[A[ATraining Step: 38  | total loss: [1m[32m0.16224[0m[0m | time: 16.898s
[2K
| Adam | epoch: 005 | loss: 0.16224 - acc: 0.9522 -- iter: 064/274
[A[ATraining Step: 39  | total loss: [1m[32m0.13554[0m[0m | time: 27.892s
[2K
| Adam | epoch: 005 | loss: 0.13554 - acc: 0.9614 -- iter: 096/274
[A[ATraining Step: 40  | total loss: [1m[32m0.11366[0m[0m | time: 39.818s
[2K
| Adam | epoch: 005 | loss: 0.11366 - acc: 0.9686 -- iter: 128/274
[A[ATraining Step: 41  | total loss: [1m[32m0.09595[0m[0m | time: 57.656s
[2K
| Adam | epoch: 005 | loss: 0.09595 - acc: 0.9744 -- iter: 160/274
[A[ATraining Step: 42  | total loss: [1m[32m0.08580[0m[0m | time: 74.293s
[2K
| Adam | epoch: 005 | loss: 0.08580 - acc: 0.9790 -- iter: 192/274
[A[ATraining Step: 43  | total loss: [1m[32m0.08857[0m[0m | time: 91.736s
[2K
| Adam | epoch: 005 | loss: 0.08857 - acc: 0.9772 -- iter: 224/274
[A[ATraining Step: 44  | total loss: [1m[32m0.07888[0m[0m | time: 105.918s
[2K
| Adam | epoch: 005 | loss: 0.07888 - acc: 0.9811 -- iter: 256/274
[A[ATraining Step: 45  | total loss: [1m[32m0.06969[0m[0m | time: 123.590s
[2K
| Adam | epoch: 005 | loss: 0.06969 - acc: 0.9843 | val_loss: 1.51189 - val_acc: 0.5116 -- iter: 274/274
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8869047619047619
Validation AUPRC:0.822614167249399
Test AUC:0.8641774891774893
Test AUPRC:0.8341352817979972
BestTestF1Score	0.82	0.63	0.81	0.8	0.84	37	9	33	7	0.02
BestTestMCCScore	0.82	0.63	0.81	0.8	0.84	37	9	33	7	0.02
BestTestAccuracyScore	0.82	0.63	0.81	0.8	0.84	37	9	33	7	0.02
BestValidationF1Score	0.81	0.63	0.81	0.8	0.83	35	9	35	7	0.02
BestValidationMCC	0.81	0.63	0.81	0.8	0.83	35	9	35	7	0.02
BestValidationAccuracy	0.81	0.63	0.81	0.8	0.83	35	9	35	7	0.02
TestPredictions (Threshold:0.02)
CHEMBL1287914,TN,INACT,0.009999999776482582	CHEMBL1086860,TP,ACT,0.07999999821186066	CHEMBL364623,FN,ACT,0.019999999552965164	CHEMBL1933806,FP,INACT,0.029999999329447746	CHEMBL99280,TN,INACT,0.009999999776482582	CHEMBL1079945,TP,ACT,0.07000000029802322	CHEMBL131695,TN,INACT,0.009999999776482582	CHEMBL2311806,FN,ACT,0.009999999776482582	CHEMBL101779,TN,INACT,0.019999999552965164	CHEMBL1762119,TN,INACT,0.009999999776482582	CHEMBL2048912,TP,ACT,0.03999999910593033	CHEMBL456759,TN,INACT,0.009999999776482582	CHEMBL1076480,TP,ACT,0.07999999821186066	CHEMBL530335,FP,INACT,0.029999999329447746	CHEMBL259084,FN,ACT,0.019999999552965164	CHEMBL517154,FP,INACT,0.029999999329447746	CHEMBL595048,FP,INACT,0.05000000074505806	CHEMBL522892,TP,ACT,0.05000000074505806	CHEMBL1916885,TP,ACT,0.05999999865889549	CHEMBL1910753,TN,INACT,0.019999999552965164	CHEMBL1734241,TN,INACT,0.019999999552965164	CHEMBL1908395,TP,ACT,0.03999999910593033	CHEMBL480223,TP,ACT,0.03999999910593033	CHEMBL1922211,TN,INACT,0.009999999776482582	CHEMBL536983,TP,ACT,0.03999999910593033	CHEMBL1089116,TP,ACT,0.029999999329447746	CHEMBL558752,TP,ACT,0.07000000029802322	CHEMBL2392241,TN,INACT,0.019999999552965164	CHEMBL1076436,TP,ACT,0.07999999821186066	CHEMBL2070409,FP,INACT,0.05999999865889549	CHEMBL1916889,TP,ACT,0.05999999865889549	CHEMBL1079422,TP,ACT,0.03999999910593033	CHEMBL173478,TN,INACT,0.009999999776482582	CHEMBL120703,TN,INACT,0.019999999552965164	CHEMBL99779,TN,INACT,0.009999999776482582	CHEMBL491473,TP,ACT,0.05000000074505806	CHEMBL518942,TP,ACT,0.05000000074505806	CHEMBL337454,TN,INACT,0.019999999552965164	CHEMBL489246,TN,INACT,0.019999999552965164	CHEMBL1076478,TP,ACT,0.07000000029802322	CHEMBL271984,TP,ACT,0.029999999329447746	CHEMBL553,TP,ACT,0.029999999329447746	CHEMBL436137,FN,ACT,0.019999999552965164	CHEMBL3691629,FP,INACT,0.03999999910593033	CHEMBL255863,FN,ACT,0.009999999776482582	CHEMBL95477,TN,INACT,0.009999999776482582	CHEMBL1916895,TP,ACT,0.05999999865889549	CHEMBL1076199,TP,ACT,0.05000000074505806	CHEMBL109981,TP,ACT,0.07000000029802322	CHEMBL1090360,TP,ACT,0.07999999821186066	CHEMBL1076466,TP,ACT,0.07999999821186066	CHEMBL77155,TN,INACT,0.019999999552965164	CHEMBL1834657,TP,ACT,0.07000000029802322	CHEMBL457180,TN,INACT,0.019999999552965164	CHEMBL1910757,TN,INACT,0.009999999776482582	CHEMBL2392388,TN,INACT,0.019999999552965164	CHEMBL328164,TN,INACT,0.009999999776482582	CHEMBL232542,TP,ACT,0.07999999821186066	CHEMBL2392227,FP,INACT,0.029999999329447746	CHEMBL1916904,TP,ACT,0.029999999329447746	CHEMBL1076198,TP,ACT,0.05999999865889549	CHEMBL482919,FP,INACT,0.03999999910593033	CHEMBL558601,TN,INACT,0.009999999776482582	CHEMBL396487,TN,INACT,0.009999999776482582	CHEMBL271188,TP,ACT,0.07000000029802322	CHEMBL458076,TN,INACT,0.009999999776482582	CHEMBL78223,TN,INACT,0.009999999776482582	CHEMBL3609569,TN,INACT,0.019999999552965164	CHEMBL1087421,TN,INACT,0.0	CHEMBL1916879,TP,ACT,0.07000000029802322	CHEMBL101868,TN,INACT,0.019999999552965164	CHEMBL1916886,TP,ACT,0.09000000357627869	CHEMBL386051,TP,ACT,0.03999999910593033	CHEMBL402818,TP,ACT,0.05000000074505806	CHEMBL1910761,TN,INACT,0.0	CHEMBL243575,TP,ACT,0.07000000029802322	CHEMBL3335362,TN,INACT,0.009999999776482582	CHEMBL3085242,TN,INACT,0.009999999776482582	CHEMBL419069,TN,INACT,0.009999999776482582	CHEMBL498705,FP,INACT,0.11999999731779099	CHEMBL1076201,TP,ACT,0.05000000074505806	CHEMBL47203,TP,ACT,0.05999999865889549	CHEMBL536073,FN,ACT,0.019999999552965164	CHEMBL1076437,TP,ACT,0.05999999865889549	CHEMBL3262619,FN,ACT,0.009999999776482582	CHEMBL1767292,TN,INACT,0.009999999776482582	

