CNNModel CHEMBL3836 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	230
Number of inactive compounds :	230
---------------------------------
Run id: CNNModel_CHEMBL3836_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3836_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 294
Validation samples: 92
--
Training Step: 1  | time: 0.832s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/294
[A[ATraining Step: 2  | total loss: [1m[32m0.62412[0m[0m | time: 1.439s
[2K
| Adam | epoch: 001 | loss: 0.62412 - acc: 0.3937 -- iter: 064/294
[A[ATraining Step: 3  | total loss: [1m[32m0.68121[0m[0m | time: 2.036s
[2K
| Adam | epoch: 001 | loss: 0.68121 - acc: 0.4551 -- iter: 096/294
[A[ATraining Step: 4  | total loss: [1m[32m0.69092[0m[0m | time: 2.646s
[2K
| Adam | epoch: 001 | loss: 0.69092 - acc: 0.4419 -- iter: 128/294
[A[ATraining Step: 5  | total loss: [1m[32m0.69229[0m[0m | time: 3.252s
[2K
| Adam | epoch: 001 | loss: 0.69229 - acc: 0.5038 -- iter: 160/294
[A[ATraining Step: 6  | total loss: [1m[32m0.69303[0m[0m | time: 3.844s
[2K
| Adam | epoch: 001 | loss: 0.69303 - acc: 0.4813 -- iter: 192/294
[A[ATraining Step: 7  | total loss: [1m[32m0.69383[0m[0m | time: 4.444s
[2K
| Adam | epoch: 001 | loss: 0.69383 - acc: 0.3800 -- iter: 224/294
[A[ATraining Step: 8  | total loss: [1m[32m0.69335[0m[0m | time: 5.039s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.5002 -- iter: 256/294
[A[ATraining Step: 9  | total loss: [1m[32m0.69336[0m[0m | time: 5.635s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4670 -- iter: 288/294
[A[ATraining Step: 10  | total loss: [1m[32m0.69267[0m[0m | time: 6.813s
[2K
| Adam | epoch: 001 | loss: 0.69267 - acc: 0.5616 | val_loss: 0.69327 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 11  | total loss: [1m[32m0.69500[0m[0m | time: 0.159s
[2K
| Adam | epoch: 002 | loss: 0.69500 - acc: 0.3745 -- iter: 032/294
[A[ATraining Step: 12  | total loss: [1m[32m0.69552[0m[0m | time: 0.802s
[2K
| Adam | epoch: 002 | loss: 0.69552 - acc: 0.2060 -- iter: 064/294
[A[ATraining Step: 13  | total loss: [1m[32m0.69438[0m[0m | time: 1.420s
[2K
| Adam | epoch: 002 | loss: 0.69438 - acc: 0.3454 -- iter: 096/294
[A[ATraining Step: 14  | total loss: [1m[32m0.69426[0m[0m | time: 2.021s
[2K
| Adam | epoch: 002 | loss: 0.69426 - acc: 0.3703 -- iter: 128/294
[A[ATraining Step: 15  | total loss: [1m[32m0.69363[0m[0m | time: 2.633s
[2K
| Adam | epoch: 002 | loss: 0.69363 - acc: 0.4210 -- iter: 160/294
[A[ATraining Step: 16  | total loss: [1m[32m0.69366[0m[0m | time: 3.242s
[2K
| Adam | epoch: 002 | loss: 0.69366 - acc: 0.4389 -- iter: 192/294
[A[ATraining Step: 17  | total loss: [1m[32m0.69393[0m[0m | time: 3.855s
[2K
| Adam | epoch: 002 | loss: 0.69393 - acc: 0.4272 -- iter: 224/294
[A[ATraining Step: 18  | total loss: [1m[32m0.69327[0m[0m | time: 4.460s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4848 -- iter: 256/294
[A[ATraining Step: 19  | total loss: [1m[32m0.69332[0m[0m | time: 5.091s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4795 -- iter: 288/294
[A[ATraining Step: 20  | total loss: [1m[32m0.69325[0m[0m | time: 6.727s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4861 | val_loss: 0.69300 - val_acc: 0.5109 -- iter: 294/294
--
Training Step: 21  | total loss: [1m[32m0.69309[0m[0m | time: 0.150s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5001 -- iter: 032/294
[A[ATraining Step: 22  | total loss: [1m[32m0.69166[0m[0m | time: 0.310s
[2K
| Adam | epoch: 003 | loss: 0.69166 - acc: 0.6001 -- iter: 064/294
[A[ATraining Step: 23  | total loss: [1m[32m0.69441[0m[0m | time: 0.935s
[2K
| Adam | epoch: 003 | loss: 0.69441 - acc: 0.4742 -- iter: 096/294
[A[ATraining Step: 24  | total loss: [1m[32m0.69514[0m[0m | time: 1.559s
[2K
| Adam | epoch: 003 | loss: 0.69514 - acc: 0.4287 -- iter: 128/294
[A[ATraining Step: 25  | total loss: [1m[32m0.69479[0m[0m | time: 2.175s
[2K
| Adam | epoch: 003 | loss: 0.69479 - acc: 0.4397 -- iter: 160/294
[A[ATraining Step: 26  | total loss: [1m[32m0.69424[0m[0m | time: 2.805s
[2K
| Adam | epoch: 003 | loss: 0.69424 - acc: 0.4639 -- iter: 192/294
[A[ATraining Step: 27  | total loss: [1m[32m0.69319[0m[0m | time: 3.426s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5294 -- iter: 224/294
[A[ATraining Step: 28  | total loss: [1m[32m0.69342[0m[0m | time: 4.034s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.5065 -- iter: 256/294
[A[ATraining Step: 29  | total loss: [1m[32m0.69379[0m[0m | time: 4.662s
[2K
| Adam | epoch: 003 | loss: 0.69379 - acc: 0.4745 -- iter: 288/294
[A[ATraining Step: 30  | total loss: [1m[32m0.69344[0m[0m | time: 6.288s
[2K
| Adam | epoch: 003 | loss: 0.69344 - acc: 0.4953 | val_loss: 0.69302 - val_acc: 0.5109 -- iter: 294/294
--
Training Step: 31  | total loss: [1m[32m0.69312[0m[0m | time: 0.612s
[2K
| Adam | epoch: 004 | loss: 0.69312 - acc: 0.5180 -- iter: 032/294
[A[ATraining Step: 32  | total loss: [1m[32m0.69312[0m[0m | time: 0.766s
[2K
| Adam | epoch: 004 | loss: 0.69312 - acc: 0.5140 -- iter: 064/294
[A[ATraining Step: 33  | total loss: [1m[32m0.69412[0m[0m | time: 0.921s
[2K
| Adam | epoch: 004 | loss: 0.69412 - acc: 0.4377 -- iter: 096/294
[A[ATraining Step: 34  | total loss: [1m[32m0.69434[0m[0m | time: 1.538s
[2K
| Adam | epoch: 004 | loss: 0.69434 - acc: 0.4154 -- iter: 128/294
[A[ATraining Step: 35  | total loss: [1m[32m0.69429[0m[0m | time: 2.155s
[2K
| Adam | epoch: 004 | loss: 0.69429 - acc: 0.4135 -- iter: 160/294
[A[ATraining Step: 36  | total loss: [1m[32m0.69401[0m[0m | time: 2.776s
[2K
| Adam | epoch: 004 | loss: 0.69401 - acc: 0.4376 -- iter: 192/294
[A[ATraining Step: 37  | total loss: [1m[32m0.69392[0m[0m | time: 3.394s
[2K
| Adam | epoch: 004 | loss: 0.69392 - acc: 0.4375 -- iter: 224/294
[A[ATraining Step: 38  | total loss: [1m[32m0.69375[0m[0m | time: 4.007s
[2K
| Adam | epoch: 004 | loss: 0.69375 - acc: 0.4498 -- iter: 256/294
[A[ATraining Step: 39  | total loss: [1m[32m0.69360[0m[0m | time: 4.614s
[2K
| Adam | epoch: 004 | loss: 0.69360 - acc: 0.4714 -- iter: 288/294
[A[ATraining Step: 40  | total loss: [1m[32m0.69353[0m[0m | time: 6.248s
[2K
| Adam | epoch: 004 | loss: 0.69353 - acc: 0.4709 | val_loss: 0.69316 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 41  | total loss: [1m[32m0.69345[0m[0m | time: 0.602s
[2K
| Adam | epoch: 005 | loss: 0.69345 - acc: 0.4762 -- iter: 032/294
[A[ATraining Step: 42  | total loss: [1m[32m0.69340[0m[0m | time: 1.210s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.4805 -- iter: 064/294
[A[ATraining Step: 43  | total loss: [1m[32m0.69339[0m[0m | time: 1.362s
[2K
| Adam | epoch: 005 | loss: 0.69339 - acc: 0.4729 -- iter: 096/294
[A[ATraining Step: 44  | total loss: [1m[32m0.69322[0m[0m | time: 1.530s
[2K
| Adam | epoch: 005 | loss: 0.69322 - acc: 0.5064 -- iter: 128/294
[A[ATraining Step: 45  | total loss: [1m[32m0.69349[0m[0m | time: 2.147s
[2K
| Adam | epoch: 005 | loss: 0.69349 - acc: 0.4204 -- iter: 160/294
[A[ATraining Step: 46  | total loss: [1m[32m0.69342[0m[0m | time: 2.758s
[2K
| Adam | epoch: 005 | loss: 0.69342 - acc: 0.4493 -- iter: 192/294
[A[ATraining Step: 47  | total loss: [1m[32m0.69343[0m[0m | time: 3.354s
[2K
| Adam | epoch: 005 | loss: 0.69343 - acc: 0.4321 -- iter: 224/294
[A[ATraining Step: 48  | total loss: [1m[32m0.69337[0m[0m | time: 3.958s
[2K
| Adam | epoch: 005 | loss: 0.69337 - acc: 0.4530 -- iter: 256/294
[A[ATraining Step: 49  | total loss: [1m[32m0.69333[0m[0m | time: 4.571s
[2K
| Adam | epoch: 005 | loss: 0.69333 - acc: 0.4506 -- iter: 288/294
[A[ATraining Step: 50  | total loss: [1m[32m0.69329[0m[0m | time: 6.173s
[2K
| Adam | epoch: 005 | loss: 0.69329 - acc: 0.4873 | val_loss: 0.69314 - val_acc: 0.5109 -- iter: 294/294
--
Training Step: 51  | total loss: [1m[32m0.69327[0m[0m | time: 0.605s
[2K
| Adam | epoch: 006 | loss: 0.69327 - acc: 0.4845 -- iter: 032/294
[A[ATraining Step: 52  | total loss: [1m[32m0.69325[0m[0m | time: 1.228s
[2K
| Adam | epoch: 006 | loss: 0.69325 - acc: 0.4868 -- iter: 064/294
[A[ATraining Step: 53  | total loss: [1m[32m0.69323[0m[0m | time: 1.856s
[2K
| Adam | epoch: 006 | loss: 0.69323 - acc: 0.4980 -- iter: 096/294
[A[ATraining Step: 54  | total loss: [1m[32m0.69324[0m[0m | time: 2.014s
[2K
| Adam | epoch: 006 | loss: 0.69324 - acc: 0.4847 -- iter: 128/294
[A[ATraining Step: 55  | total loss: [1m[32m0.69317[0m[0m | time: 2.164s
[2K
| Adam | epoch: 006 | loss: 0.69317 - acc: 0.5345 -- iter: 160/294
[A[ATraining Step: 56  | total loss: [1m[32m0.69304[0m[0m | time: 2.778s
[2K
| Adam | epoch: 006 | loss: 0.69304 - acc: 0.5765 -- iter: 192/294
[A[ATraining Step: 57  | total loss: [1m[32m0.69308[0m[0m | time: 3.374s
[2K
| Adam | epoch: 006 | loss: 0.69308 - acc: 0.5616 -- iter: 224/294
[A[ATraining Step: 58  | total loss: [1m[32m0.69298[0m[0m | time: 3.969s
[2K
| Adam | epoch: 006 | loss: 0.69298 - acc: 0.5660 -- iter: 256/294
[A[ATraining Step: 59  | total loss: [1m[32m0.69288[0m[0m | time: 4.567s
[2K
| Adam | epoch: 006 | loss: 0.69288 - acc: 0.5697 -- iter: 288/294
[A[ATraining Step: 60  | total loss: [1m[32m0.69292[0m[0m | time: 6.175s
[2K
| Adam | epoch: 006 | loss: 0.69292 - acc: 0.5605 | val_loss: 0.69300 - val_acc: 0.5109 -- iter: 294/294
--
Training Step: 61  | total loss: [1m[32m0.69315[0m[0m | time: 0.661s
[2K
| Adam | epoch: 007 | loss: 0.69315 - acc: 0.5404 -- iter: 032/294
[A[ATraining Step: 62  | total loss: [1m[32m0.69330[0m[0m | time: 1.282s
[2K
| Adam | epoch: 007 | loss: 0.69330 - acc: 0.5271 -- iter: 064/294
[A[ATraining Step: 63  | total loss: [1m[32m0.69338[0m[0m | time: 1.891s
[2K
| Adam | epoch: 007 | loss: 0.69338 - acc: 0.5197 -- iter: 096/294
[A[ATraining Step: 64  | total loss: [1m[32m0.69366[0m[0m | time: 2.499s
[2K
| Adam | epoch: 007 | loss: 0.69366 - acc: 0.5016 -- iter: 128/294
[A[ATraining Step: 65  | total loss: [1m[32m0.69353[0m[0m | time: 2.655s
[2K
| Adam | epoch: 007 | loss: 0.69353 - acc: 0.5053 -- iter: 160/294
[A[ATraining Step: 66  | total loss: [1m[32m0.69271[0m[0m | time: 2.806s
[2K
| Adam | epoch: 007 | loss: 0.69271 - acc: 0.5452 -- iter: 192/294
[A[ATraining Step: 67  | total loss: [1m[32m0.69359[0m[0m | time: 3.399s
[2K
| Adam | epoch: 007 | loss: 0.69359 - acc: 0.4998 -- iter: 224/294
[A[ATraining Step: 68  | total loss: [1m[32m0.69353[0m[0m | time: 4.022s
[2K
| Adam | epoch: 007 | loss: 0.69353 - acc: 0.4998 -- iter: 256/294
[A[ATraining Step: 69  | total loss: [1m[32m0.69334[0m[0m | time: 4.630s
[2K
| Adam | epoch: 007 | loss: 0.69334 - acc: 0.5071 -- iter: 288/294
[A[ATraining Step: 70  | total loss: [1m[32m0.69345[0m[0m | time: 6.248s
[2K
| Adam | epoch: 007 | loss: 0.69345 - acc: 0.4991 | val_loss: 0.69298 - val_acc: 0.5109 -- iter: 294/294
--
Training Step: 71  | total loss: [1m[32m0.69355[0m[0m | time: 0.636s
[2K
| Adam | epoch: 008 | loss: 0.69355 - acc: 0.4921 -- iter: 032/294
[A[ATraining Step: 72  | total loss: [1m[32m0.69373[0m[0m | time: 1.241s
[2K
| Adam | epoch: 008 | loss: 0.69373 - acc: 0.4824 -- iter: 064/294
[A[ATraining Step: 73  | total loss: [1m[32m0.69380[0m[0m | time: 1.856s
[2K
| Adam | epoch: 008 | loss: 0.69380 - acc: 0.4774 -- iter: 096/294
[A[ATraining Step: 74  | total loss: [1m[32m0.69373[0m[0m | time: 2.479s
[2K
| Adam | epoch: 008 | loss: 0.69373 - acc: 0.4799 -- iter: 128/294
[A[ATraining Step: 75  | total loss: [1m[32m0.69328[0m[0m | time: 3.080s
[2K
| Adam | epoch: 008 | loss: 0.69328 - acc: 0.5024 -- iter: 160/294
[A[ATraining Step: 76  | total loss: [1m[32m0.69322[0m[0m | time: 3.229s
[2K
| Adam | epoch: 008 | loss: 0.69322 - acc: 0.5055 -- iter: 192/294
[A[ATraining Step: 77  | total loss: [1m[32m0.69387[0m[0m | time: 3.384s
[2K
| Adam | epoch: 008 | loss: 0.69387 - acc: 0.4696 -- iter: 224/294
[A[ATraining Step: 78  | total loss: [1m[32m0.69439[0m[0m | time: 3.995s
[2K
| Adam | epoch: 008 | loss: 0.69439 - acc: 0.4379 -- iter: 256/294
[A[ATraining Step: 79  | total loss: [1m[32m0.69416[0m[0m | time: 4.589s
[2K
| Adam | epoch: 008 | loss: 0.69416 - acc: 0.4508 -- iter: 288/294
[A[ATraining Step: 80  | total loss: [1m[32m0.69406[0m[0m | time: 6.200s
[2K
| Adam | epoch: 008 | loss: 0.69406 - acc: 0.4558 | val_loss: 0.69304 - val_acc: 0.5109 -- iter: 294/294
--
Training Step: 81  | total loss: [1m[32m0.69417[0m[0m | time: 0.616s
[2K
| Adam | epoch: 009 | loss: 0.69417 - acc: 0.4445 -- iter: 032/294
[A[ATraining Step: 82  | total loss: [1m[32m0.69399[0m[0m | time: 1.228s
[2K
| Adam | epoch: 009 | loss: 0.69399 - acc: 0.4563 -- iter: 064/294
[A[ATraining Step: 83  | total loss: [1m[32m0.69397[0m[0m | time: 1.838s
[2K
| Adam | epoch: 009 | loss: 0.69397 - acc: 0.4544 -- iter: 096/294
[A[ATraining Step: 84  | total loss: [1m[32m0.69387[0m[0m | time: 2.431s
[2K
| Adam | epoch: 009 | loss: 0.69387 - acc: 0.4621 -- iter: 128/294
[A[ATraining Step: 85  | total loss: [1m[32m0.69383[0m[0m | time: 3.032s
[2K
| Adam | epoch: 009 | loss: 0.69383 - acc: 0.4628 -- iter: 160/294
[A[ATraining Step: 86  | total loss: [1m[32m0.69367[0m[0m | time: 3.643s
[2K
| Adam | epoch: 009 | loss: 0.69367 - acc: 0.4790 -- iter: 192/294
[A[ATraining Step: 87  | total loss: [1m[32m0.69363[0m[0m | time: 3.787s
[2K
| Adam | epoch: 009 | loss: 0.69363 - acc: 0.4780 -- iter: 224/294
[A[ATraining Step: 88  | total loss: [1m[32m0.69376[0m[0m | time: 3.941s
[2K
| Adam | epoch: 009 | loss: 0.69376 - acc: 0.4468 -- iter: 256/294
[A[ATraining Step: 89  | total loss: [1m[32m0.69383[0m[0m | time: 4.552s
[2K
| Adam | epoch: 009 | loss: 0.69383 - acc: 0.4188 -- iter: 288/294
[A[ATraining Step: 90  | total loss: [1m[32m0.69374[0m[0m | time: 6.168s
[2K
| Adam | epoch: 009 | loss: 0.69374 - acc: 0.4332 | val_loss: 0.69317 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 91  | total loss: [1m[32m0.69367[0m[0m | time: 0.620s
[2K
| Adam | epoch: 010 | loss: 0.69367 - acc: 0.4492 -- iter: 032/294
[A[ATraining Step: 92  | total loss: [1m[32m0.69361[0m[0m | time: 1.218s
[2K
| Adam | epoch: 010 | loss: 0.69361 - acc: 0.4574 -- iter: 064/294
[A[ATraining Step: 93  | total loss: [1m[32m0.69359[0m[0m | time: 1.836s
[2K
| Adam | epoch: 010 | loss: 0.69359 - acc: 0.4523 -- iter: 096/294
[A[ATraining Step: 94  | total loss: [1m[32m0.69356[0m[0m | time: 2.433s
[2K
| Adam | epoch: 010 | loss: 0.69356 - acc: 0.4540 -- iter: 128/294
[A[ATraining Step: 95  | total loss: [1m[32m0.69351[0m[0m | time: 3.041s
[2K
| Adam | epoch: 010 | loss: 0.69351 - acc: 0.4586 -- iter: 160/294
[A[ATraining Step: 96  | total loss: [1m[32m0.69341[0m[0m | time: 3.650s
[2K
| Adam | epoch: 010 | loss: 0.69341 - acc: 0.4721 -- iter: 192/294
[A[ATraining Step: 97  | total loss: [1m[32m0.69339[0m[0m | time: 4.255s
[2K
| Adam | epoch: 010 | loss: 0.69339 - acc: 0.4749 -- iter: 224/294
[A[ATraining Step: 98  | total loss: [1m[32m0.69343[0m[0m | time: 4.412s
[2K
| Adam | epoch: 010 | loss: 0.69343 - acc: 0.4711 -- iter: 256/294
[A[ATraining Step: 99  | total loss: [1m[32m0.69308[0m[0m | time: 4.563s
[2K
| Adam | epoch: 010 | loss: 0.69308 - acc: 0.5074 -- iter: 288/294
[A[ATraining Step: 100  | total loss: [1m[32m0.69308[0m[0m | time: 6.186s
[2K
| Adam | epoch: 010 | loss: 0.69308 - acc: 0.5066 | val_loss: 0.69333 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 101  | total loss: [1m[32m0.69297[0m[0m | time: 0.622s
[2K
| Adam | epoch: 011 | loss: 0.69297 - acc: 0.5153 -- iter: 032/294
[A[ATraining Step: 102  | total loss: [1m[32m0.69312[0m[0m | time: 1.239s
[2K
| Adam | epoch: 011 | loss: 0.69312 - acc: 0.5044 -- iter: 064/294
[A[ATraining Step: 103  | total loss: [1m[32m0.69312[0m[0m | time: 1.856s
[2K
| Adam | epoch: 011 | loss: 0.69312 - acc: 0.5040 -- iter: 096/294
[A[ATraining Step: 104  | total loss: [1m[32m0.69312[0m[0m | time: 2.470s
[2K
| Adam | epoch: 011 | loss: 0.69312 - acc: 0.5036 -- iter: 128/294
[A[ATraining Step: 105  | total loss: [1m[32m0.69296[0m[0m | time: 3.106s
[2K
| Adam | epoch: 011 | loss: 0.69296 - acc: 0.5126 -- iter: 160/294
[A[ATraining Step: 106  | total loss: [1m[32m0.69304[0m[0m | time: 3.730s
[2K
| Adam | epoch: 011 | loss: 0.69304 - acc: 0.5082 -- iter: 192/294
[A[ATraining Step: 107  | total loss: [1m[32m0.69297[0m[0m | time: 4.338s
[2K
| Adam | epoch: 011 | loss: 0.69297 - acc: 0.5105 -- iter: 224/294
[A[ATraining Step: 108  | total loss: [1m[32m0.69313[0m[0m | time: 4.947s
[2K
| Adam | epoch: 011 | loss: 0.69313 - acc: 0.5032 -- iter: 256/294
[A[ATraining Step: 109  | total loss: [1m[32m0.69309[0m[0m | time: 5.098s
[2K
| Adam | epoch: 011 | loss: 0.69309 - acc: 0.5060 -- iter: 288/294
[A[ATraining Step: 110  | total loss: [1m[32m0.69310[0m[0m | time: 6.250s
[2K
| Adam | epoch: 011 | loss: 0.69310 - acc: 0.5054 | val_loss: 0.69346 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 111  | total loss: [1m[32m0.69314[0m[0m | time: 0.605s
[2K
| Adam | epoch: 012 | loss: 0.69314 - acc: 0.5049 -- iter: 032/294
[A[ATraining Step: 112  | total loss: [1m[32m0.69323[0m[0m | time: 1.213s
[2K
| Adam | epoch: 012 | loss: 0.69323 - acc: 0.5013 -- iter: 064/294
[A[ATraining Step: 113  | total loss: [1m[32m0.69316[0m[0m | time: 1.856s
[2K
| Adam | epoch: 012 | loss: 0.69316 - acc: 0.5043 -- iter: 096/294
[A[ATraining Step: 114  | total loss: [1m[32m0.69316[0m[0m | time: 2.452s
[2K
| Adam | epoch: 012 | loss: 0.69316 - acc: 0.5038 -- iter: 128/294
[A[ATraining Step: 115  | total loss: [1m[32m0.69295[0m[0m | time: 3.055s
[2K
| Adam | epoch: 012 | loss: 0.69295 - acc: 0.5128 -- iter: 160/294
[A[ATraining Step: 116  | total loss: [1m[32m0.69305[0m[0m | time: 3.665s
[2K
| Adam | epoch: 012 | loss: 0.69305 - acc: 0.5084 -- iter: 192/294
[A[ATraining Step: 117  | total loss: [1m[32m0.69290[0m[0m | time: 4.283s
[2K
| Adam | epoch: 012 | loss: 0.69290 - acc: 0.5138 -- iter: 224/294
[A[ATraining Step: 118  | total loss: [1m[32m0.69278[0m[0m | time: 4.928s
[2K
| Adam | epoch: 012 | loss: 0.69278 - acc: 0.5187 -- iter: 256/294
[A[ATraining Step: 119  | total loss: [1m[32m0.69298[0m[0m | time: 5.546s
[2K
| Adam | epoch: 012 | loss: 0.69298 - acc: 0.5106 -- iter: 288/294
[A[ATraining Step: 120  | total loss: [1m[32m0.69318[0m[0m | time: 6.714s
[2K
| Adam | epoch: 012 | loss: 0.69318 - acc: 0.5033 | val_loss: 0.69352 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 121  | total loss: [1m[32m0.69314[0m[0m | time: 0.161s
[2K
| Adam | epoch: 013 | loss: 0.69314 - acc: 0.5029 -- iter: 032/294
[A[ATraining Step: 122  | total loss: [1m[32m0.69315[0m[0m | time: 0.786s
[2K
| Adam | epoch: 013 | loss: 0.69315 - acc: 0.5026 -- iter: 064/294
[A[ATraining Step: 123  | total loss: [1m[32m0.69298[0m[0m | time: 1.401s
[2K
| Adam | epoch: 013 | loss: 0.69298 - acc: 0.5086 -- iter: 096/294
[A[ATraining Step: 124  | total loss: [1m[32m0.69302[0m[0m | time: 2.009s
[2K
| Adam | epoch: 013 | loss: 0.69302 - acc: 0.5078 -- iter: 128/294
[A[ATraining Step: 125  | total loss: [1m[32m0.69313[0m[0m | time: 2.625s
[2K
| Adam | epoch: 013 | loss: 0.69313 - acc: 0.5039 -- iter: 160/294
[A[ATraining Step: 126  | total loss: [1m[32m0.69303[0m[0m | time: 3.219s
[2K
| Adam | epoch: 013 | loss: 0.69303 - acc: 0.5066 -- iter: 192/294
[A[ATraining Step: 127  | total loss: [1m[32m0.69296[0m[0m | time: 3.822s
[2K
| Adam | epoch: 013 | loss: 0.69296 - acc: 0.5091 -- iter: 224/294
[A[ATraining Step: 128  | total loss: [1m[32m0.69315[0m[0m | time: 4.451s
[2K
| Adam | epoch: 013 | loss: 0.69315 - acc: 0.5019 -- iter: 256/294
[A[ATraining Step: 129  | total loss: [1m[32m0.69298[0m[0m | time: 5.046s
[2K
| Adam | epoch: 013 | loss: 0.69298 - acc: 0.5080 -- iter: 288/294
[A[ATraining Step: 130  | total loss: [1m[32m0.69327[0m[0m | time: 6.648s
[2K
| Adam | epoch: 013 | loss: 0.69327 - acc: 0.4978 | val_loss: 0.69352 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 131  | total loss: [1m[32m0.69310[0m[0m | time: 0.158s
[2K
| Adam | epoch: 014 | loss: 0.69310 - acc: 0.5043 -- iter: 032/294
[A[ATraining Step: 132  | total loss: [1m[32m0.69312[0m[0m | time: 0.296s
[2K
| Adam | epoch: 014 | loss: 0.69312 - acc: 0.5038 -- iter: 064/294
[A[ATraining Step: 133  | total loss: [1m[32m0.69263[0m[0m | time: 0.928s
[2K
| Adam | epoch: 014 | loss: 0.69263 - acc: 0.5201 -- iter: 096/294
[A[ATraining Step: 134  | total loss: [1m[32m0.69232[0m[0m | time: 1.568s
[2K
| Adam | epoch: 014 | loss: 0.69232 - acc: 0.5306 -- iter: 128/294
[A[ATraining Step: 135  | total loss: [1m[32m0.69250[0m[0m | time: 2.186s
[2K
| Adam | epoch: 014 | loss: 0.69250 - acc: 0.5244 -- iter: 160/294
[A[ATraining Step: 136  | total loss: [1m[32m0.69269[0m[0m | time: 2.801s
[2K
| Adam | epoch: 014 | loss: 0.69269 - acc: 0.5189 -- iter: 192/294
[A[ATraining Step: 137  | total loss: [1m[32m0.69295[0m[0m | time: 3.425s
[2K
| Adam | epoch: 014 | loss: 0.69295 - acc: 0.5107 -- iter: 224/294
[A[ATraining Step: 138  | total loss: [1m[32m0.69318[0m[0m | time: 4.041s
[2K
| Adam | epoch: 014 | loss: 0.69318 - acc: 0.5034 -- iter: 256/294
[A[ATraining Step: 139  | total loss: [1m[32m0.69328[0m[0m | time: 4.690s
[2K
| Adam | epoch: 014 | loss: 0.69328 - acc: 0.4999 -- iter: 288/294
[A[ATraining Step: 140  | total loss: [1m[32m0.69349[0m[0m | time: 6.304s
[2K
| Adam | epoch: 014 | loss: 0.69349 - acc: 0.4937 | val_loss: 0.69355 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 141  | total loss: [1m[32m0.69345[0m[0m | time: 0.622s
[2K
| Adam | epoch: 015 | loss: 0.69345 - acc: 0.4943 -- iter: 032/294
[A[ATraining Step: 142  | total loss: [1m[32m0.69286[0m[0m | time: 0.773s
[2K
| Adam | epoch: 015 | loss: 0.69286 - acc: 0.5136 -- iter: 064/294
[A[ATraining Step: 143  | total loss: [1m[32m0.69238[0m[0m | time: 0.917s
[2K
| Adam | epoch: 015 | loss: 0.69238 - acc: 0.5289 -- iter: 096/294
[A[ATraining Step: 144  | total loss: [1m[32m0.69256[0m[0m | time: 1.520s
[2K
| Adam | epoch: 015 | loss: 0.69256 - acc: 0.5260 -- iter: 128/294
[A[ATraining Step: 145  | total loss: [1m[32m0.69285[0m[0m | time: 2.125s
[2K
| Adam | epoch: 015 | loss: 0.69285 - acc: 0.5172 -- iter: 160/294
[A[ATraining Step: 146  | total loss: [1m[32m0.69320[0m[0m | time: 2.734s
[2K
| Adam | epoch: 015 | loss: 0.69320 - acc: 0.5061 -- iter: 192/294
[A[ATraining Step: 147  | total loss: [1m[32m0.69365[0m[0m | time: 3.336s
[2K
| Adam | epoch: 015 | loss: 0.69365 - acc: 0.4930 -- iter: 224/294
[A[ATraining Step: 148  | total loss: [1m[32m0.69318[0m[0m | time: 3.944s
[2K
| Adam | epoch: 015 | loss: 0.69318 - acc: 0.5062 -- iter: 256/294
[A[ATraining Step: 149  | total loss: [1m[32m0.69280[0m[0m | time: 4.558s
[2K
| Adam | epoch: 015 | loss: 0.69280 - acc: 0.5181 -- iter: 288/294
[A[ATraining Step: 150  | total loss: [1m[32m0.69266[0m[0m | time: 6.167s
[2K
| Adam | epoch: 015 | loss: 0.69266 - acc: 0.5225 | val_loss: 0.69361 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 151  | total loss: [1m[32m0.69249[0m[0m | time: 0.620s
[2K
| Adam | epoch: 016 | loss: 0.69249 - acc: 0.5265 -- iter: 032/294
[A[ATraining Step: 152  | total loss: [1m[32m0.69278[0m[0m | time: 1.240s
[2K
| Adam | epoch: 016 | loss: 0.69278 - acc: 0.5176 -- iter: 064/294
[A[ATraining Step: 153  | total loss: [1m[32m0.69270[0m[0m | time: 1.389s
[2K
| Adam | epoch: 016 | loss: 0.69270 - acc: 0.5190 -- iter: 096/294
[A[ATraining Step: 154  | total loss: [1m[32m0.69267[0m[0m | time: 1.541s
[2K
| Adam | epoch: 016 | loss: 0.69267 - acc: 0.5171 -- iter: 128/294
[A[ATraining Step: 155  | total loss: [1m[32m0.69271[0m[0m | time: 2.127s
[2K
| Adam | epoch: 016 | loss: 0.69271 - acc: 0.5154 -- iter: 160/294
[A[ATraining Step: 156  | total loss: [1m[32m0.69262[0m[0m | time: 2.741s
[2K
| Adam | epoch: 016 | loss: 0.69262 - acc: 0.5170 -- iter: 192/294
[A[ATraining Step: 157  | total loss: [1m[32m0.69253[0m[0m | time: 3.352s
[2K
| Adam | epoch: 016 | loss: 0.69253 - acc: 0.5184 -- iter: 224/294
[A[ATraining Step: 158  | total loss: [1m[32m0.69271[0m[0m | time: 3.971s
[2K
| Adam | epoch: 016 | loss: 0.69271 - acc: 0.5134 -- iter: 256/294
[A[ATraining Step: 159  | total loss: [1m[32m0.69211[0m[0m | time: 4.580s
[2K
| Adam | epoch: 016 | loss: 0.69211 - acc: 0.5246 -- iter: 288/294
[A[ATraining Step: 160  | total loss: [1m[32m0.69201[0m[0m | time: 6.198s
[2K
| Adam | epoch: 016 | loss: 0.69201 - acc: 0.5252 | val_loss: 0.69388 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 161  | total loss: [1m[32m0.69289[0m[0m | time: 0.608s
[2K
| Adam | epoch: 017 | loss: 0.69289 - acc: 0.5102 -- iter: 032/294
[A[ATraining Step: 162  | total loss: [1m[32m0.69306[0m[0m | time: 1.230s
[2K
| Adam | epoch: 017 | loss: 0.69306 - acc: 0.5061 -- iter: 064/294
[A[ATraining Step: 163  | total loss: [1m[32m0.69291[0m[0m | time: 1.846s
[2K
| Adam | epoch: 017 | loss: 0.69291 - acc: 0.5086 -- iter: 096/294
[A[ATraining Step: 164  | total loss: [1m[32m0.69289[0m[0m | time: 2.002s
[2K
| Adam | epoch: 017 | loss: 0.69289 - acc: 0.5077 -- iter: 128/294
[A[ATraining Step: 165  | total loss: [1m[32m0.69273[0m[0m | time: 2.163s
[2K
| Adam | epoch: 017 | loss: 0.69273 - acc: 0.5070 -- iter: 160/294
[A[ATraining Step: 166  | total loss: [1m[32m0.69172[0m[0m | time: 2.770s
[2K
| Adam | epoch: 017 | loss: 0.69172 - acc: 0.5229 -- iter: 192/294
[A[ATraining Step: 167  | total loss: [1m[32m0.69102[0m[0m | time: 3.391s
[2K
| Adam | epoch: 017 | loss: 0.69102 - acc: 0.5331 -- iter: 224/294
[A[ATraining Step: 168  | total loss: [1m[32m0.69146[0m[0m | time: 4.026s
[2K
| Adam | epoch: 017 | loss: 0.69146 - acc: 0.5267 -- iter: 256/294
[A[ATraining Step: 169  | total loss: [1m[32m0.69187[0m[0m | time: 4.640s
[2K
| Adam | epoch: 017 | loss: 0.69187 - acc: 0.5209 -- iter: 288/294
[A[ATraining Step: 170  | total loss: [1m[32m0.69148[0m[0m | time: 6.292s
[2K
| Adam | epoch: 017 | loss: 0.69148 - acc: 0.5219 | val_loss: 0.69452 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 171  | total loss: [1m[32m0.69269[0m[0m | time: 0.623s
[2K
| Adam | epoch: 018 | loss: 0.69269 - acc: 0.5104 -- iter: 032/294
[A[ATraining Step: 172  | total loss: [1m[32m0.69347[0m[0m | time: 1.246s
[2K
| Adam | epoch: 018 | loss: 0.69347 - acc: 0.5000 -- iter: 064/294
[A[ATraining Step: 173  | total loss: [1m[32m0.69319[0m[0m | time: 1.864s
[2K
| Adam | epoch: 018 | loss: 0.69319 - acc: 0.5031 -- iter: 096/294
[A[ATraining Step: 174  | total loss: [1m[32m0.69274[0m[0m | time: 2.496s
[2K
| Adam | epoch: 018 | loss: 0.69274 - acc: 0.5090 -- iter: 128/294
[A[ATraining Step: 175  | total loss: [1m[32m0.69256[0m[0m | time: 2.643s
[2K
| Adam | epoch: 018 | loss: 0.69256 - acc: 0.5113 -- iter: 160/294
[A[ATraining Step: 176  | total loss: [1m[32m0.69135[0m[0m | time: 2.798s
[2K
| Adam | epoch: 018 | loss: 0.69135 - acc: 0.5268 -- iter: 192/294
[A[ATraining Step: 177  | total loss: [1m[32m0.69242[0m[0m | time: 3.409s
[2K
| Adam | epoch: 018 | loss: 0.69242 - acc: 0.5074 -- iter: 224/294
[A[ATraining Step: 178  | total loss: [1m[32m0.69257[0m[0m | time: 4.013s
[2K
| Adam | epoch: 018 | loss: 0.69257 - acc: 0.5005 -- iter: 256/294
[A[ATraining Step: 179  | total loss: [1m[32m0.69208[0m[0m | time: 4.619s
[2K
| Adam | epoch: 018 | loss: 0.69208 - acc: 0.5035 -- iter: 288/294
[A[ATraining Step: 180  | total loss: [1m[32m0.69052[0m[0m | time: 6.221s
[2K
| Adam | epoch: 018 | loss: 0.69052 - acc: 0.5251 | val_loss: 0.69415 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 181  | total loss: [1m[32m0.68952[0m[0m | time: 0.611s
[2K
| Adam | epoch: 019 | loss: 0.68952 - acc: 0.5319 -- iter: 032/294
[A[ATraining Step: 182  | total loss: [1m[32m0.68783[0m[0m | time: 1.225s
[2K
| Adam | epoch: 019 | loss: 0.68783 - acc: 0.5412 -- iter: 064/294
[A[ATraining Step: 183  | total loss: [1m[32m0.69031[0m[0m | time: 1.844s
[2K
| Adam | epoch: 019 | loss: 0.69031 - acc: 0.5246 -- iter: 096/294
[A[ATraining Step: 184  | total loss: [1m[32m0.68874[0m[0m | time: 2.442s
[2K
| Adam | epoch: 019 | loss: 0.68874 - acc: 0.5284 -- iter: 128/294
[A[ATraining Step: 185  | total loss: [1m[32m0.69088[0m[0m | time: 3.051s
[2K
| Adam | epoch: 019 | loss: 0.69088 - acc: 0.5162 -- iter: 160/294
[A[ATraining Step: 186  | total loss: [1m[32m0.69258[0m[0m | time: 3.199s
[2K
| Adam | epoch: 019 | loss: 0.69258 - acc: 0.4989 -- iter: 192/294
[A[ATraining Step: 187  | total loss: [1m[32m0.69274[0m[0m | time: 3.349s
[2K
| Adam | epoch: 019 | loss: 0.69274 - acc: 0.4824 -- iter: 224/294
[A[ATraining Step: 188  | total loss: [1m[32m0.69281[0m[0m | time: 3.955s
[2K
| Adam | epoch: 019 | loss: 0.69281 - acc: 0.4675 -- iter: 256/294
[A[ATraining Step: 189  | total loss: [1m[32m0.69281[0m[0m | time: 4.559s
[2K
| Adam | epoch: 019 | loss: 0.69281 - acc: 0.4801 -- iter: 288/294
[A[ATraining Step: 190  | total loss: [1m[32m0.69293[0m[0m | time: 6.168s
[2K
| Adam | epoch: 019 | loss: 0.69293 - acc: 0.4758 | val_loss: 0.69333 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 191  | total loss: [1m[32m0.69309[0m[0m | time: 0.605s
[2K
| Adam | epoch: 020 | loss: 0.69309 - acc: 0.4720 -- iter: 032/294
[A[ATraining Step: 192  | total loss: [1m[32m0.69305[0m[0m | time: 1.216s
[2K
| Adam | epoch: 020 | loss: 0.69305 - acc: 0.4811 -- iter: 064/294
[A[ATraining Step: 193  | total loss: [1m[32m0.69287[0m[0m | time: 1.817s
[2K
| Adam | epoch: 020 | loss: 0.69287 - acc: 0.4955 -- iter: 096/294
[A[ATraining Step: 194  | total loss: [1m[32m0.69316[0m[0m | time: 2.430s
[2K
| Adam | epoch: 020 | loss: 0.69316 - acc: 0.4834 -- iter: 128/294
[A[ATraining Step: 195  | total loss: [1m[32m0.69296[0m[0m | time: 3.021s
[2K
| Adam | epoch: 020 | loss: 0.69296 - acc: 0.4944 -- iter: 160/294
[A[ATraining Step: 196  | total loss: [1m[32m0.69299[0m[0m | time: 3.626s
[2K
| Adam | epoch: 020 | loss: 0.69299 - acc: 0.4919 -- iter: 192/294
[A[ATraining Step: 197  | total loss: [1m[32m0.69333[0m[0m | time: 3.779s
[2K
| Adam | epoch: 020 | loss: 0.69333 - acc: 0.4833 -- iter: 224/294
[A[ATraining Step: 198  | total loss: [1m[32m0.69108[0m[0m | time: 3.933s
[2K
| Adam | epoch: 020 | loss: 0.69108 - acc: 0.5350 -- iter: 256/294
[A[ATraining Step: 199  | total loss: [1m[32m0.68978[0m[0m | time: 4.545s
[2K
| Adam | epoch: 020 | loss: 0.68978 - acc: 0.5481 -- iter: 288/294
[A[ATraining Step: 200  | total loss: [1m[32m0.69003[0m[0m | time: 6.179s
[2K
| Adam | epoch: 020 | loss: 0.69003 - acc: 0.5433 | val_loss: 0.70411 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 201  | total loss: [1m[32m0.68972[0m[0m | time: 0.621s
[2K
| Adam | epoch: 021 | loss: 0.68972 - acc: 0.5421 -- iter: 032/294
[A[ATraining Step: 202  | total loss: [1m[32m0.69361[0m[0m | time: 1.253s
[2K
| Adam | epoch: 021 | loss: 0.69361 - acc: 0.5254 -- iter: 064/294
[A[ATraining Step: 203  | total loss: [1m[32m0.69121[0m[0m | time: 1.864s
[2K
| Adam | epoch: 021 | loss: 0.69121 - acc: 0.5322 -- iter: 096/294
[A[ATraining Step: 204  | total loss: [1m[32m0.69004[0m[0m | time: 2.488s
[2K
| Adam | epoch: 021 | loss: 0.69004 - acc: 0.5353 -- iter: 128/294
[A[ATraining Step: 205  | total loss: [1m[32m0.69067[0m[0m | time: 3.103s
[2K
| Adam | epoch: 021 | loss: 0.69067 - acc: 0.5286 -- iter: 160/294
[A[ATraining Step: 206  | total loss: [1m[32m0.69127[0m[0m | time: 3.715s
[2K
| Adam | epoch: 021 | loss: 0.69127 - acc: 0.5258 -- iter: 192/294
[A[ATraining Step: 207  | total loss: [1m[32m0.68995[0m[0m | time: 4.330s
[2K
| Adam | epoch: 021 | loss: 0.68995 - acc: 0.5294 -- iter: 224/294
[A[ATraining Step: 208  | total loss: [1m[32m0.69127[0m[0m | time: 4.479s
[2K
| Adam | epoch: 021 | loss: 0.69127 - acc: 0.5202 -- iter: 256/294
[A[ATraining Step: 209  | total loss: [1m[32m0.68839[0m[0m | time: 4.625s
[2K
| Adam | epoch: 021 | loss: 0.68839 - acc: 0.5349 -- iter: 288/294
[A[ATraining Step: 210  | total loss: [1m[32m0.68402[0m[0m | time: 6.258s
[2K
| Adam | epoch: 021 | loss: 0.68402 - acc: 0.5647 | val_loss: 0.70689 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 211  | total loss: [1m[32m0.68301[0m[0m | time: 0.628s
[2K
| Adam | epoch: 022 | loss: 0.68301 - acc: 0.5645 -- iter: 032/294
[A[ATraining Step: 212  | total loss: [1m[32m0.68641[0m[0m | time: 1.247s
[2K
| Adam | epoch: 022 | loss: 0.68641 - acc: 0.5518 -- iter: 064/294
[A[ATraining Step: 213  | total loss: [1m[32m0.68905[0m[0m | time: 1.850s
[2K
| Adam | epoch: 022 | loss: 0.68905 - acc: 0.5372 -- iter: 096/294
[A[ATraining Step: 214  | total loss: [1m[32m0.68792[0m[0m | time: 2.463s
[2K
| Adam | epoch: 022 | loss: 0.68792 - acc: 0.5366 -- iter: 128/294
[A[ATraining Step: 215  | total loss: [1m[32m0.68817[0m[0m | time: 3.084s
[2K
| Adam | epoch: 022 | loss: 0.68817 - acc: 0.5299 -- iter: 160/294
[A[ATraining Step: 216  | total loss: [1m[32m0.68893[0m[0m | time: 3.732s
[2K
| Adam | epoch: 022 | loss: 0.68893 - acc: 0.5175 -- iter: 192/294
[A[ATraining Step: 217  | total loss: [1m[32m0.68864[0m[0m | time: 4.342s
[2K
| Adam | epoch: 022 | loss: 0.68864 - acc: 0.5189 -- iter: 224/294
[A[ATraining Step: 218  | total loss: [1m[32m0.68714[0m[0m | time: 4.955s
[2K
| Adam | epoch: 022 | loss: 0.68714 - acc: 0.5264 -- iter: 256/294
[A[ATraining Step: 219  | total loss: [1m[32m0.68543[0m[0m | time: 5.109s
[2K
| Adam | epoch: 022 | loss: 0.68543 - acc: 0.5300 -- iter: 288/294
[A[ATraining Step: 220  | total loss: [1m[32m0.68003[0m[0m | time: 6.261s
[2K
| Adam | epoch: 022 | loss: 0.68003 - acc: 0.5603 | val_loss: 0.69044 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 221  | total loss: [1m[32m0.68613[0m[0m | time: 0.606s
[2K
| Adam | epoch: 023 | loss: 0.68613 - acc: 0.5376 -- iter: 032/294
[A[ATraining Step: 222  | total loss: [1m[32m0.68226[0m[0m | time: 1.215s
[2K
| Adam | epoch: 023 | loss: 0.68226 - acc: 0.5464 -- iter: 064/294
[A[ATraining Step: 223  | total loss: [1m[32m0.68021[0m[0m | time: 1.823s
[2K
| Adam | epoch: 023 | loss: 0.68021 - acc: 0.5448 -- iter: 096/294
[A[ATraining Step: 224  | total loss: [1m[32m0.68071[0m[0m | time: 2.433s
[2K
| Adam | epoch: 023 | loss: 0.68071 - acc: 0.5310 -- iter: 128/294
[A[ATraining Step: 225  | total loss: [1m[32m0.67661[0m[0m | time: 3.032s
[2K
| Adam | epoch: 023 | loss: 0.67661 - acc: 0.5404 -- iter: 160/294
[A[ATraining Step: 226  | total loss: [1m[32m0.67516[0m[0m | time: 3.646s
[2K
| Adam | epoch: 023 | loss: 0.67516 - acc: 0.5395 -- iter: 192/294
[A[ATraining Step: 227  | total loss: [1m[32m0.67299[0m[0m | time: 4.260s
[2K
| Adam | epoch: 023 | loss: 0.67299 - acc: 0.5355 -- iter: 224/294
[A[ATraining Step: 228  | total loss: [1m[32m0.67265[0m[0m | time: 4.873s
[2K
| Adam | epoch: 023 | loss: 0.67265 - acc: 0.5320 -- iter: 256/294
[A[ATraining Step: 229  | total loss: [1m[32m0.67003[0m[0m | time: 5.497s
[2K
| Adam | epoch: 023 | loss: 0.67003 - acc: 0.5288 -- iter: 288/294
[A[ATraining Step: 230  | total loss: [1m[32m0.66868[0m[0m | time: 6.664s
[2K
| Adam | epoch: 023 | loss: 0.66868 - acc: 0.5134 | val_loss: 0.67743 - val_acc: 0.4891 -- iter: 294/294
--
Training Step: 231  | total loss: [1m[32m0.66866[0m[0m | time: 0.156s
[2K
| Adam | epoch: 024 | loss: 0.66866 - acc: 0.4954 -- iter: 032/294
[A[ATraining Step: 232  | total loss: [1m[32m0.66831[0m[0m | time: 0.780s
[2K
| Adam | epoch: 024 | loss: 0.66831 - acc: 0.5125 -- iter: 064/294
[A[ATraining Step: 233  | total loss: [1m[32m0.66808[0m[0m | time: 1.392s
[2K
| Adam | epoch: 024 | loss: 0.66808 - acc: 0.5456 -- iter: 096/294
[A[ATraining Step: 234  | total loss: [1m[32m0.66287[0m[0m | time: 2.011s
[2K
| Adam | epoch: 024 | loss: 0.66287 - acc: 0.5723 -- iter: 128/294
[A[ATraining Step: 235  | total loss: [1m[32m0.65151[0m[0m | time: 2.642s
[2K
| Adam | epoch: 024 | loss: 0.65151 - acc: 0.5901 -- iter: 160/294
[A[ATraining Step: 236  | total loss: [1m[32m0.64074[0m[0m | time: 3.248s
[2K
| Adam | epoch: 024 | loss: 0.64074 - acc: 0.5967 -- iter: 192/294
[A[ATraining Step: 237  | total loss: [1m[32m0.65781[0m[0m | time: 3.864s
[2K
| Adam | epoch: 024 | loss: 0.65781 - acc: 0.5714 -- iter: 224/294
[A[ATraining Step: 238  | total loss: [1m[32m0.64821[0m[0m | time: 4.489s
[2K
| Adam | epoch: 024 | loss: 0.64821 - acc: 0.5955 -- iter: 256/294
[A[ATraining Step: 239  | total loss: [1m[32m0.64545[0m[0m | time: 5.100s
[2K
| Adam | epoch: 024 | loss: 0.64545 - acc: 0.6078 -- iter: 288/294
[A[ATraining Step: 240  | total loss: [1m[32m0.64518[0m[0m | time: 6.710s
[2K
| Adam | epoch: 024 | loss: 0.64518 - acc: 0.6221 | val_loss: 0.66040 - val_acc: 0.6196 -- iter: 294/294
--
Training Step: 241  | total loss: [1m[32m0.64464[0m[0m | time: 0.159s
[2K
| Adam | epoch: 025 | loss: 0.64464 - acc: 0.6255 -- iter: 032/294
[A[ATraining Step: 242  | total loss: [1m[32m0.63793[0m[0m | time: 0.314s
[2K
| Adam | epoch: 025 | loss: 0.63793 - acc: 0.6629 -- iter: 064/294
[A[ATraining Step: 243  | total loss: [1m[32m0.63738[0m[0m | time: 0.927s
[2K
| Adam | epoch: 025 | loss: 0.63738 - acc: 0.6800 -- iter: 096/294
[A[ATraining Step: 244  | total loss: [1m[32m0.62508[0m[0m | time: 1.545s
[2K
| Adam | epoch: 025 | loss: 0.62508 - acc: 0.6932 -- iter: 128/294
[A[ATraining Step: 245  | total loss: [1m[32m0.61473[0m[0m | time: 2.141s
[2K
| Adam | epoch: 025 | loss: 0.61473 - acc: 0.7083 -- iter: 160/294
[A[ATraining Step: 246  | total loss: [1m[32m0.61293[0m[0m | time: 2.738s
[2K
| Adam | epoch: 025 | loss: 0.61293 - acc: 0.7093 -- iter: 192/294
[A[ATraining Step: 247  | total loss: [1m[32m0.60795[0m[0m | time: 3.365s
[2K
| Adam | epoch: 025 | loss: 0.60795 - acc: 0.7103 -- iter: 224/294
[A[ATraining Step: 248  | total loss: [1m[32m0.58643[0m[0m | time: 3.971s
[2K
| Adam | epoch: 025 | loss: 0.58643 - acc: 0.7330 -- iter: 256/294
[A[ATraining Step: 249  | total loss: [1m[32m0.57497[0m[0m | time: 4.595s
[2K
| Adam | epoch: 025 | loss: 0.57497 - acc: 0.7441 -- iter: 288/294
[A[ATraining Step: 250  | total loss: [1m[32m0.56369[0m[0m | time: 6.213s
[2K
| Adam | epoch: 025 | loss: 0.56369 - acc: 0.7540 | val_loss: 0.67213 - val_acc: 0.6522 -- iter: 294/294
--
Training Step: 251  | total loss: [1m[32m0.56715[0m[0m | time: 0.625s
[2K
| Adam | epoch: 026 | loss: 0.56715 - acc: 0.7474 -- iter: 032/294
[A[ATraining Step: 252  | total loss: [1m[32m0.56306[0m[0m | time: 0.777s
[2K
| Adam | epoch: 026 | loss: 0.56306 - acc: 0.7445 -- iter: 064/294
[A[ATraining Step: 253  | total loss: [1m[32m0.55409[0m[0m | time: 0.929s
[2K
| Adam | epoch: 026 | loss: 0.55409 - acc: 0.7367 -- iter: 096/294
[A[ATraining Step: 254  | total loss: [1m[32m0.56509[0m[0m | time: 1.538s
[2K
| Adam | epoch: 026 | loss: 0.56509 - acc: 0.7297 -- iter: 128/294
[A[ATraining Step: 255  | total loss: [1m[32m0.55469[0m[0m | time: 2.140s
[2K
| Adam | epoch: 026 | loss: 0.55469 - acc: 0.7349 -- iter: 160/294
[A[ATraining Step: 256  | total loss: [1m[32m0.53431[0m[0m | time: 2.753s
[2K
| Adam | epoch: 026 | loss: 0.53431 - acc: 0.7489 -- iter: 192/294
[A[ATraining Step: 257  | total loss: [1m[32m0.52386[0m[0m | time: 3.370s
[2K
| Adam | epoch: 026 | loss: 0.52386 - acc: 0.7553 -- iter: 224/294
[A[ATraining Step: 258  | total loss: [1m[32m0.51915[0m[0m | time: 3.983s
[2K
| Adam | epoch: 026 | loss: 0.51915 - acc: 0.7641 -- iter: 256/294
[A[ATraining Step: 259  | total loss: [1m[32m0.54050[0m[0m | time: 4.591s
[2K
| Adam | epoch: 026 | loss: 0.54050 - acc: 0.7439 -- iter: 288/294
[A[ATraining Step: 260  | total loss: [1m[32m0.51684[0m[0m | time: 6.215s
[2K
| Adam | epoch: 026 | loss: 0.51684 - acc: 0.7602 | val_loss: 0.67312 - val_acc: 0.6522 -- iter: 294/294
--
Training Step: 261  | total loss: [1m[32m0.50833[0m[0m | time: 0.612s
[2K
| Adam | epoch: 027 | loss: 0.50833 - acc: 0.7654 -- iter: 032/294
[A[ATraining Step: 262  | total loss: [1m[32m0.51571[0m[0m | time: 1.219s
[2K
| Adam | epoch: 027 | loss: 0.51571 - acc: 0.7607 -- iter: 064/294
[A[ATraining Step: 263  | total loss: [1m[32m0.51739[0m[0m | time: 1.374s
[2K
| Adam | epoch: 027 | loss: 0.51739 - acc: 0.7628 -- iter: 096/294
[A[ATraining Step: 264  | total loss: [1m[32m0.48756[0m[0m | time: 1.524s
[2K
| Adam | epoch: 027 | loss: 0.48756 - acc: 0.7865 -- iter: 128/294
[A[ATraining Step: 265  | total loss: [1m[32m0.46203[0m[0m | time: 2.127s
[2K
| Adam | epoch: 027 | loss: 0.46203 - acc: 0.8079 -- iter: 160/294
[A[ATraining Step: 266  | total loss: [1m[32m0.46304[0m[0m | time: 2.725s
[2K
| Adam | epoch: 027 | loss: 0.46304 - acc: 0.7989 -- iter: 192/294
[A[ATraining Step: 267  | total loss: [1m[32m0.45699[0m[0m | time: 3.346s
[2K
| Adam | epoch: 027 | loss: 0.45699 - acc: 0.8003 -- iter: 224/294
[A[ATraining Step: 268  | total loss: [1m[32m0.45539[0m[0m | time: 3.944s
[2K
| Adam | epoch: 027 | loss: 0.45539 - acc: 0.7984 -- iter: 256/294
[A[ATraining Step: 269  | total loss: [1m[32m0.47736[0m[0m | time: 4.563s
[2K
| Adam | epoch: 027 | loss: 0.47736 - acc: 0.7811 -- iter: 288/294
[A[ATraining Step: 270  | total loss: [1m[32m0.47692[0m[0m | time: 6.173s
[2K
| Adam | epoch: 027 | loss: 0.47692 - acc: 0.7842 | val_loss: 0.75630 - val_acc: 0.6413 -- iter: 294/294
--
Training Step: 271  | total loss: [1m[32m0.46986[0m[0m | time: 0.598s
[2K
| Adam | epoch: 028 | loss: 0.46986 - acc: 0.7870 -- iter: 032/294
[A[ATraining Step: 272  | total loss: [1m[32m0.46419[0m[0m | time: 1.193s
[2K
| Adam | epoch: 028 | loss: 0.46419 - acc: 0.7865 -- iter: 064/294
[A[ATraining Step: 273  | total loss: [1m[32m0.45546[0m[0m | time: 1.799s
[2K
| Adam | epoch: 028 | loss: 0.45546 - acc: 0.7859 -- iter: 096/294
[A[ATraining Step: 274  | total loss: [1m[32m0.43215[0m[0m | time: 1.945s
[2K
| Adam | epoch: 028 | loss: 0.43215 - acc: 0.7980 -- iter: 128/294
[A[ATraining Step: 275  | total loss: [1m[32m0.40789[0m[0m | time: 2.096s
[2K
| Adam | epoch: 028 | loss: 0.40789 - acc: 0.8182 -- iter: 160/294
[A[ATraining Step: 276  | total loss: [1m[32m0.42053[0m[0m | time: 2.715s
[2K
| Adam | epoch: 028 | loss: 0.42053 - acc: 0.8197 -- iter: 192/294
[A[ATraining Step: 277  | total loss: [1m[32m0.43032[0m[0m | time: 3.331s
[2K
| Adam | epoch: 028 | loss: 0.43032 - acc: 0.8127 -- iter: 224/294
[A[ATraining Step: 278  | total loss: [1m[32m0.42758[0m[0m | time: 3.924s
[2K
| Adam | epoch: 028 | loss: 0.42758 - acc: 0.8096 -- iter: 256/294
[A[ATraining Step: 279  | total loss: [1m[32m0.40560[0m[0m | time: 4.556s
[2K
| Adam | epoch: 028 | loss: 0.40560 - acc: 0.8255 -- iter: 288/294
[A[ATraining Step: 280  | total loss: [1m[32m0.40913[0m[0m | time: 6.162s
[2K
| Adam | epoch: 028 | loss: 0.40913 - acc: 0.8273 | val_loss: 0.69715 - val_acc: 0.6413 -- iter: 294/294
--
Training Step: 281  | total loss: [1m[32m0.40669[0m[0m | time: 0.617s
[2K
| Adam | epoch: 029 | loss: 0.40669 - acc: 0.8321 -- iter: 032/294
[A[ATraining Step: 282  | total loss: [1m[32m0.40280[0m[0m | time: 1.278s
[2K
| Adam | epoch: 029 | loss: 0.40280 - acc: 0.8270 -- iter: 064/294
[A[ATraining Step: 283  | total loss: [1m[32m0.39274[0m[0m | time: 1.890s
[2K
| Adam | epoch: 029 | loss: 0.39274 - acc: 0.8349 -- iter: 096/294
[A[ATraining Step: 284  | total loss: [1m[32m0.39702[0m[0m | time: 2.495s
[2K
| Adam | epoch: 029 | loss: 0.39702 - acc: 0.8358 -- iter: 128/294
[A[ATraining Step: 285  | total loss: [1m[32m0.39319[0m[0m | time: 2.643s
[2K
| Adam | epoch: 029 | loss: 0.39319 - acc: 0.8397 -- iter: 160/294
[A[ATraining Step: 286  | total loss: [1m[32m0.36817[0m[0m | time: 2.797s
[2K
| Adam | epoch: 029 | loss: 0.36817 - acc: 0.8558 -- iter: 192/294
[A[ATraining Step: 287  | total loss: [1m[32m0.40028[0m[0m | time: 3.396s
[2K
| Adam | epoch: 029 | loss: 0.40028 - acc: 0.8535 -- iter: 224/294
[A[ATraining Step: 288  | total loss: [1m[32m0.38015[0m[0m | time: 4.005s
[2K
| Adam | epoch: 029 | loss: 0.38015 - acc: 0.8650 -- iter: 256/294
[A[ATraining Step: 289  | total loss: [1m[32m0.37360[0m[0m | time: 4.612s
[2K
| Adam | epoch: 029 | loss: 0.37360 - acc: 0.8660 -- iter: 288/294
[A[ATraining Step: 290  | total loss: [1m[32m0.36367[0m[0m | time: 6.246s
[2K
| Adam | epoch: 029 | loss: 0.36367 - acc: 0.8669 | val_loss: 0.58015 - val_acc: 0.6848 -- iter: 294/294
--
Training Step: 291  | total loss: [1m[32m0.35838[0m[0m | time: 0.616s
[2K
| Adam | epoch: 030 | loss: 0.35838 - acc: 0.8677 -- iter: 032/294
[A[ATraining Step: 292  | total loss: [1m[32m0.35888[0m[0m | time: 1.240s
[2K
| Adam | epoch: 030 | loss: 0.35888 - acc: 0.8622 -- iter: 064/294
[A[ATraining Step: 293  | total loss: [1m[32m0.34786[0m[0m | time: 1.839s
[2K
| Adam | epoch: 030 | loss: 0.34786 - acc: 0.8697 -- iter: 096/294
[A[ATraining Step: 294  | total loss: [1m[32m0.34906[0m[0m | time: 2.454s
[2K
| Adam | epoch: 030 | loss: 0.34906 - acc: 0.8703 -- iter: 128/294
[A[ATraining Step: 295  | total loss: [1m[32m0.33664[0m[0m | time: 3.059s
[2K
| Adam | epoch: 030 | loss: 0.33664 - acc: 0.8770 -- iter: 160/294
[A[ATraining Step: 296  | total loss: [1m[32m0.33279[0m[0m | time: 3.204s
[2K
| Adam | epoch: 030 | loss: 0.33279 - acc: 0.8737 -- iter: 192/294
[A[ATraining Step: 297  | total loss: [1m[32m0.31637[0m[0m | time: 3.351s
[2K
| Adam | epoch: 030 | loss: 0.31637 - acc: 0.8863 -- iter: 224/294
[A[ATraining Step: 298  | total loss: [1m[32m0.38622[0m[0m | time: 3.969s
[2K
| Adam | epoch: 030 | loss: 0.38622 - acc: 0.8643 -- iter: 256/294
[A[ATraining Step: 299  | total loss: [1m[32m0.37740[0m[0m | time: 4.580s
[2K
| Adam | epoch: 030 | loss: 0.37740 - acc: 0.8654 -- iter: 288/294
[A[ATraining Step: 300  | total loss: [1m[32m0.36629[0m[0m | time: 6.186s
[2K
| Adam | epoch: 030 | loss: 0.36629 - acc: 0.8632 | val_loss: 0.52748 - val_acc: 0.7500 -- iter: 294/294
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.840661938534279
Validation AUPRC:0.8604864987796291
Test AUC:0.9109848484848485
Test AUPRC:0.9259354714019823
BestTestF1Score	0.83	0.61	0.8	0.77	0.9	43	13	31	5	0.44
BestTestMCCScore	0.83	0.65	0.83	0.83	0.83	40	8	36	8	0.58
BestTestAccuracyScore	0.83	0.65	0.83	0.83	0.83	40	8	36	8	0.58
BestValidationF1Score	0.8	0.55	0.77	0.73	0.87	41	15	30	6	0.44
BestValidationMCC	0.79	0.57	0.78	0.79	0.79	37	10	35	10	0.58
BestValidationAccuracy	0.79	0.57	0.78	0.79	0.79	37	10	35	10	0.58
TestPredictions (Threshold:0.58)
CHEMBL523938,TN,INACT,0.15000000596046448	CHEMBL525530,TN,INACT,0.009999999776482582	CHEMBL527039,TN,INACT,0.3799999952316284	CHEMBL570313,TN,INACT,0.009999999776482582	CHEMBL487737,FP,INACT,0.6000000238418579	CHEMBL3410031,TP,ACT,0.7099999785423279	CHEMBL3613604,TP,ACT,0.9300000071525574	CHEMBL3410056,TP,ACT,0.949999988079071	CHEMBL3085242,TN,INACT,0.4099999964237213	CHEMBL458076,TN,INACT,0.029999999329447746	CHEMBL3613622,TP,ACT,0.949999988079071	CHEMBL497454,TN,INACT,0.019999999552965164	CHEMBL2070492,TP,ACT,0.6600000262260437	CHEMBL489344,TN,INACT,0.11999999731779099	CHEMBL525921,FP,INACT,0.6399999856948853	CHEMBL2141887,FN,ACT,0.09000000357627869	CHEMBL2070616,FN,ACT,0.4099999964237213	CHEMBL3347527,TP,ACT,0.9700000286102295	CHEMBL3347679,TP,ACT,0.9700000286102295	CHEMBL521201,TN,INACT,0.1599999964237213	CHEMBL1836472,TP,ACT,0.9700000286102295	CHEMBL568904,FP,INACT,0.6800000071525574	CHEMBL3347513,TP,ACT,0.8600000143051147	CHEMBL2392240,TN,INACT,0.009999999776482582	CHEMBL176815,TN,INACT,0.03999999910593033	CHEMBL2070617,TP,ACT,0.75	CHEMBL3613607,TP,ACT,0.9599999785423279	CHEMBL3347515,TP,ACT,0.9300000071525574	CHEMBL1784660,TN,INACT,0.09000000357627869	CHEMBL2070501,TP,ACT,0.9100000262260437	CHEMBL3421968,TN,INACT,0.029999999329447746	CHEMBL3219011,TP,ACT,0.7400000095367432	CHEMBL3356432,TP,ACT,0.949999988079071	CHEMBL3623436,TP,ACT,0.8899999856948853	CHEMBL1784649,TN,INACT,0.550000011920929	CHEMBL2392388,TN,INACT,0.009999999776482582	CHEMBL456965,TN,INACT,0.019999999552965164	CHEMBL1331525,TN,INACT,0.029999999329447746	CHEMBL3410047,TP,ACT,0.9700000286102295	CHEMBL2070495,TP,ACT,0.9100000262260437	CHEMBL318485,TN,INACT,0.07999999821186066	CHEMBL3347685,FN,ACT,0.5699999928474426	CHEMBL3347689,TP,ACT,0.9200000166893005	CHEMBL523780,TN,INACT,0.30000001192092896	CHEMBL332342,TN,INACT,0.07999999821186066	CHEMBL2205426,TP,ACT,0.8700000047683716	CHEMBL1288069,TN,INACT,0.5099999904632568	CHEMBL173453,TN,INACT,0.5799999833106995	CHEMBL3347691,TP,ACT,0.949999988079071	CHEMBL132948,TN,INACT,0.15000000596046448	CHEMBL3347690,TP,ACT,0.9599999785423279	CHEMBL3691660,FP,INACT,0.7099999785423279	CHEMBL574738,FN,ACT,0.3400000035762787	CHEMBL120703,TN,INACT,0.3199999928474426	CHEMBL3623433,TP,ACT,0.9300000071525574	CHEMBL3347678,TP,ACT,0.9700000286102295	CHEMBL131382,TN,INACT,0.009999999776482582	CHEMBL3623440,TP,ACT,0.9100000262260437	CHEMBL2070613,TP,ACT,0.9700000286102295	CHEMBL570820,FN,ACT,0.5299999713897705	CHEMBL3347677,TP,ACT,0.9700000286102295	CHEMBL169757,TN,INACT,0.3700000047683716	CHEMBL557050,TN,INACT,0.03999999910593033	CHEMBL509032,TP,ACT,0.6600000262260437	CHEMBL457401,TN,INACT,0.5099999904632568	CHEMBL2392233,TN,INACT,0.0	CHEMBL3623434,TP,ACT,0.8899999856948853	CHEMBL1287975,TN,INACT,0.07999999821186066	CHEMBL3629279,TP,ACT,0.9100000262260437	CHEMBL328164,TN,INACT,0.4399999976158142	CHEMBL3613603,TP,ACT,0.9700000286102295	CHEMBL3613599,TP,ACT,0.9399999976158142	CHEMBL337454,TN,INACT,0.03999999910593033	CHEMBL3410046,TP,ACT,0.9700000286102295	CHEMBL457191,TN,INACT,0.029999999329447746	CHEMBL3613598,TP,ACT,0.9200000166893005	CHEMBL3347656,TP,ACT,0.9599999785423279	CHEMBL120127,FP,INACT,0.7599999904632568	CHEMBL133213,TN,INACT,0.5199999809265137	CHEMBL3410032,TP,ACT,0.9100000262260437	CHEMBL2070493,TP,ACT,0.9100000262260437	CHEMBL3609656,TN,INACT,0.3100000023841858	CHEMBL319709,FP,INACT,0.8600000143051147	CHEMBL2070504,FN,ACT,0.23000000417232513	CHEMBL512658,TN,INACT,0.3799999952316284	CHEMBL3613618,FN,ACT,0.44999998807907104	CHEMBL3219018,FP,INACT,0.9399999976158142	CHEMBL570116,TP,ACT,0.6600000262260437	CHEMBL3410036,TP,ACT,0.9599999785423279	CHEMBL562198,FP,INACT,0.8199999928474426	CHEMBL3116050,FN,ACT,0.05999999865889549	CHEMBL2070614,TP,ACT,0.8799999952316284	

