CNNModel CHEMBL2252 RMSprop 0.001 30 128 0 0.6 False True
Number of active compounds :	604
Number of inactive compounds :	403
---------------------------------
Run id: CNNModel_CHEMBL2252_RMSprop_0.001_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2252_RMSprop_0.001_30_128_0.6_True/
---------------------------------
Training samples: 616
Validation samples: 193
--
Training Step: 1  | time: 0.782s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/616
[A[ATraining Step: 2  | total loss: [1m[32m0.62388[0m[0m | time: 1.401s
[2K
| RMSProp | epoch: 001 | loss: 0.62388 - acc: 0.3937 -- iter: 064/616
[A[ATraining Step: 3  | total loss: [1m[32m0.68031[0m[0m | time: 1.998s
[2K
| RMSProp | epoch: 001 | loss: 0.68031 - acc: 0.6341 -- iter: 096/616
[A[ATraining Step: 4  | total loss: [1m[32m0.68998[0m[0m | time: 2.637s
[2K
| RMSProp | epoch: 001 | loss: 0.68998 - acc: 0.5804 -- iter: 128/616
[A[ATraining Step: 5  | total loss: [1m[32m0.69215[0m[0m | time: 3.247s
[2K
| RMSProp | epoch: 001 | loss: 0.69215 - acc: 0.5464 -- iter: 160/616
[A[ATraining Step: 6  | total loss: [1m[32m0.69269[0m[0m | time: 3.852s
[2K
| RMSProp | epoch: 001 | loss: 0.69269 - acc: 0.5567 -- iter: 192/616
[A[ATraining Step: 7  | total loss: [1m[32m0.69275[0m[0m | time: 4.467s
[2K
| RMSProp | epoch: 001 | loss: 0.69275 - acc: 0.6352 -- iter: 224/616
[A[ATraining Step: 8  | total loss: [1m[32m0.69295[0m[0m | time: 5.078s
[2K
| RMSProp | epoch: 001 | loss: 0.69295 - acc: 0.5591 -- iter: 256/616
[A[ATraining Step: 9  | total loss: [1m[32m0.69292[0m[0m | time: 5.681s
[2K
| RMSProp | epoch: 001 | loss: 0.69292 - acc: 0.5444 -- iter: 288/616
[A[ATraining Step: 10  | total loss: [1m[32m0.69323[0m[0m | time: 6.295s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4753 -- iter: 320/616
[A[ATraining Step: 11  | total loss: [1m[32m0.69322[0m[0m | time: 6.909s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4574 -- iter: 352/616
[A[ATraining Step: 12  | total loss: [1m[32m0.69302[0m[0m | time: 7.523s
[2K
| RMSProp | epoch: 001 | loss: 0.69302 - acc: 0.5750 -- iter: 384/616
[A[ATraining Step: 13  | total loss: [1m[32m0.69314[0m[0m | time: 8.155s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5161 -- iter: 416/616
[A[ATraining Step: 14  | total loss: [1m[32m0.69304[0m[0m | time: 8.791s
[2K
| RMSProp | epoch: 001 | loss: 0.69304 - acc: 0.5734 -- iter: 448/616
[A[ATraining Step: 15  | total loss: [1m[32m0.69294[0m[0m | time: 9.446s
[2K
| RMSProp | epoch: 001 | loss: 0.69294 - acc: 0.5936 -- iter: 480/616
[A[ATraining Step: 16  | total loss: [1m[32m0.69298[0m[0m | time: 10.064s
[2K
| RMSProp | epoch: 001 | loss: 0.69298 - acc: 0.5702 -- iter: 512/616
[A[ATraining Step: 17  | total loss: [1m[32m0.69273[0m[0m | time: 10.708s
[2K
| RMSProp | epoch: 001 | loss: 0.69273 - acc: 0.6124 -- iter: 544/616
[A[ATraining Step: 18  | total loss: [1m[32m0.69248[0m[0m | time: 11.323s
[2K
| RMSProp | epoch: 001 | loss: 0.69248 - acc: 0.6601 -- iter: 576/616
[A[ATraining Step: 19  | total loss: [1m[32m0.69266[0m[0m | time: 11.954s
[2K
| RMSProp | epoch: 001 | loss: 0.69266 - acc: 0.6171 -- iter: 608/616
[A[ATraining Step: 20  | total loss: [1m[32m0.69254[0m[0m | time: 13.163s
[2K
| RMSProp | epoch: 001 | loss: 0.69254 - acc: 0.6197 | val_loss: 0.69237 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 21  | total loss: [1m[32m0.69273[0m[0m | time: 0.195s
[2K
| RMSProp | epoch: 002 | loss: 0.69273 - acc: 0.5825 -- iter: 032/616
[A[ATraining Step: 22  | total loss: [1m[32m0.69293[0m[0m | time: 0.796s
[2K
| RMSProp | epoch: 002 | loss: 0.69293 - acc: 0.5578 -- iter: 064/616
[A[ATraining Step: 23  | total loss: [1m[32m0.69277[0m[0m | time: 1.417s
[2K
| RMSProp | epoch: 002 | loss: 0.69277 - acc: 0.5682 -- iter: 096/616
[A[ATraining Step: 24  | total loss: [1m[32m0.69267[0m[0m | time: 2.043s
[2K
| RMSProp | epoch: 002 | loss: 0.69267 - acc: 0.5754 -- iter: 128/616
[A[ATraining Step: 25  | total loss: [1m[32m0.69248[0m[0m | time: 2.657s
[2K
| RMSProp | epoch: 002 | loss: 0.69248 - acc: 0.5889 -- iter: 160/616
[A[ATraining Step: 26  | total loss: [1m[32m0.69249[0m[0m | time: 3.287s
[2K
| RMSProp | epoch: 002 | loss: 0.69249 - acc: 0.5819 -- iter: 192/616
[A[ATraining Step: 27  | total loss: [1m[32m0.69249[0m[0m | time: 3.918s
[2K
| RMSProp | epoch: 002 | loss: 0.69249 - acc: 0.5769 -- iter: 224/616
[A[ATraining Step: 28  | total loss: [1m[32m0.69231[0m[0m | time: 4.546s
[2K
| RMSProp | epoch: 002 | loss: 0.69231 - acc: 0.5889 -- iter: 256/616
[A[ATraining Step: 29  | total loss: [1m[32m0.69279[0m[0m | time: 5.180s
[2K
| RMSProp | epoch: 002 | loss: 0.69279 - acc: 0.5445 -- iter: 288/616
[A[ATraining Step: 30  | total loss: [1m[32m0.69250[0m[0m | time: 5.837s
[2K
| RMSProp | epoch: 002 | loss: 0.69250 - acc: 0.5710 -- iter: 320/616
[A[ATraining Step: 31  | total loss: [1m[32m0.69220[0m[0m | time: 6.442s
[2K
| RMSProp | epoch: 002 | loss: 0.69220 - acc: 0.5907 -- iter: 352/616
[A[ATraining Step: 32  | total loss: [1m[32m0.69192[0m[0m | time: 7.079s
[2K
| RMSProp | epoch: 002 | loss: 0.69192 - acc: 0.6054 -- iter: 384/616
[A[ATraining Step: 33  | total loss: [1m[32m0.69155[0m[0m | time: 7.709s
[2K
| RMSProp | epoch: 002 | loss: 0.69155 - acc: 0.6234 -- iter: 416/616
[A[ATraining Step: 34  | total loss: [1m[32m0.69131[0m[0m | time: 8.327s
[2K
| RMSProp | epoch: 002 | loss: 0.69131 - acc: 0.6305 -- iter: 448/616
[A[ATraining Step: 35  | total loss: [1m[32m0.69142[0m[0m | time: 8.958s
[2K
| RMSProp | epoch: 002 | loss: 0.69142 - acc: 0.6162 -- iter: 480/616
[A[ATraining Step: 36  | total loss: [1m[32m0.69217[0m[0m | time: 9.567s
[2K
| RMSProp | epoch: 002 | loss: 0.69217 - acc: 0.5733 -- iter: 512/616
[A[ATraining Step: 37  | total loss: [1m[32m0.69199[0m[0m | time: 10.190s
[2K
| RMSProp | epoch: 002 | loss: 0.69199 - acc: 0.5774 -- iter: 544/616
[A[ATraining Step: 38  | total loss: [1m[32m0.69246[0m[0m | time: 10.796s
[2K
| RMSProp | epoch: 002 | loss: 0.69246 - acc: 0.5500 -- iter: 576/616
[A[ATraining Step: 39  | total loss: [1m[32m0.69204[0m[0m | time: 11.408s
[2K
| RMSProp | epoch: 002 | loss: 0.69204 - acc: 0.5704 -- iter: 608/616
[A[ATraining Step: 40  | total loss: [1m[32m0.69178[0m[0m | time: 13.028s
[2K
| RMSProp | epoch: 002 | loss: 0.69178 - acc: 0.5806 | val_loss: 0.69059 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 41  | total loss: [1m[32m0.69163[0m[0m | time: 0.178s
[2K
| RMSProp | epoch: 003 | loss: 0.69163 - acc: 0.5830 -- iter: 032/616
[A[ATraining Step: 42  | total loss: [1m[32m0.69199[0m[0m | time: 0.371s
[2K
| RMSProp | epoch: 003 | loss: 0.69199 - acc: 0.5681 -- iter: 064/616
[A[ATraining Step: 43  | total loss: [1m[32m0.69217[0m[0m | time: 1.024s
[2K
| RMSProp | epoch: 003 | loss: 0.69217 - acc: 0.5561 -- iter: 096/616
[A[ATraining Step: 44  | total loss: [1m[32m0.69212[0m[0m | time: 1.658s
[2K
| RMSProp | epoch: 003 | loss: 0.69212 - acc: 0.5572 -- iter: 128/616
[A[ATraining Step: 45  | total loss: [1m[32m0.69284[0m[0m | time: 2.276s
[2K
| RMSProp | epoch: 003 | loss: 0.69284 - acc: 0.5262 -- iter: 160/616
[A[ATraining Step: 46  | total loss: [1m[32m0.69291[0m[0m | time: 2.907s
[2K
| RMSProp | epoch: 003 | loss: 0.69291 - acc: 0.5219 -- iter: 192/616
[A[ATraining Step: 47  | total loss: [1m[32m0.69272[0m[0m | time: 3.529s
[2K
| RMSProp | epoch: 003 | loss: 0.69272 - acc: 0.5285 -- iter: 224/616
[A[ATraining Step: 48  | total loss: [1m[32m0.69256[0m[0m | time: 4.165s
[2K
| RMSProp | epoch: 003 | loss: 0.69256 - acc: 0.5340 -- iter: 256/616
[A[ATraining Step: 49  | total loss: [1m[32m0.69169[0m[0m | time: 4.777s
[2K
| RMSProp | epoch: 003 | loss: 0.69169 - acc: 0.5681 -- iter: 288/616
[A[ATraining Step: 50  | total loss: [1m[32m0.69061[0m[0m | time: 5.397s
[2K
| RMSProp | epoch: 003 | loss: 0.69061 - acc: 0.6012 -- iter: 320/616
[A[ATraining Step: 51  | total loss: [1m[32m0.69087[0m[0m | time: 6.010s
[2K
| RMSProp | epoch: 003 | loss: 0.69087 - acc: 0.5905 -- iter: 352/616
[A[ATraining Step: 52  | total loss: [1m[32m0.69107[0m[0m | time: 6.622s
[2K
| RMSProp | epoch: 003 | loss: 0.69107 - acc: 0.5816 -- iter: 384/616
[A[ATraining Step: 53  | total loss: [1m[32m0.69056[0m[0m | time: 7.225s
[2K
| RMSProp | epoch: 003 | loss: 0.69056 - acc: 0.5926 -- iter: 416/616
[A[ATraining Step: 54  | total loss: [1m[32m0.68970[0m[0m | time: 7.845s
[2K
| RMSProp | epoch: 003 | loss: 0.68970 - acc: 0.6109 -- iter: 448/616
[A[ATraining Step: 55  | total loss: [1m[32m0.69061[0m[0m | time: 8.461s
[2K
| RMSProp | epoch: 003 | loss: 0.69061 - acc: 0.5862 -- iter: 480/616
[A[ATraining Step: 56  | total loss: [1m[32m0.69025[0m[0m | time: 9.095s
[2K
| RMSProp | epoch: 003 | loss: 0.69025 - acc: 0.5916 -- iter: 512/616
[A[ATraining Step: 57  | total loss: [1m[32m0.68972[0m[0m | time: 9.740s
[2K
| RMSProp | epoch: 003 | loss: 0.68972 - acc: 0.6006 -- iter: 544/616
[A[ATraining Step: 58  | total loss: [1m[32m0.68962[0m[0m | time: 10.353s
[2K
| RMSProp | epoch: 003 | loss: 0.68962 - acc: 0.5996 -- iter: 576/616
[A[ATraining Step: 59  | total loss: [1m[32m0.68972[0m[0m | time: 10.972s
[2K
| RMSProp | epoch: 003 | loss: 0.68972 - acc: 0.5946 -- iter: 608/616
[A[ATraining Step: 60  | total loss: [1m[32m0.69041[0m[0m | time: 12.591s
[2K
| RMSProp | epoch: 003 | loss: 0.69041 - acc: 0.5780 | val_loss: 0.68832 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 61  | total loss: [1m[32m0.69103[0m[0m | time: 0.628s
[2K
| RMSProp | epoch: 004 | loss: 0.69103 - acc: 0.5637 -- iter: 032/616
[A[ATraining Step: 62  | total loss: [1m[32m0.69035[0m[0m | time: 0.808s
[2K
| RMSProp | epoch: 004 | loss: 0.69035 - acc: 0.5756 -- iter: 064/616
[A[ATraining Step: 63  | total loss: [1m[32m0.68985[0m[0m | time: 0.997s
[2K
| RMSProp | epoch: 004 | loss: 0.68985 - acc: 0.5819 -- iter: 096/616
[A[ATraining Step: 64  | total loss: [1m[32m0.68944[0m[0m | time: 1.620s
[2K
| RMSProp | epoch: 004 | loss: 0.68944 - acc: 0.5873 -- iter: 128/616
[A[ATraining Step: 65  | total loss: [1m[32m0.68881[0m[0m | time: 2.253s
[2K
| RMSProp | epoch: 004 | loss: 0.68881 - acc: 0.5958 -- iter: 160/616
[A[ATraining Step: 66  | total loss: [1m[32m0.68798[0m[0m | time: 2.875s
[2K
| RMSProp | epoch: 004 | loss: 0.68798 - acc: 0.6069 -- iter: 192/616
[A[ATraining Step: 67  | total loss: [1m[32m0.68765[0m[0m | time: 3.485s
[2K
| RMSProp | epoch: 004 | loss: 0.68765 - acc: 0.6091 -- iter: 224/616
[A[ATraining Step: 68  | total loss: [1m[32m0.68785[0m[0m | time: 4.125s
[2K
| RMSProp | epoch: 004 | loss: 0.68785 - acc: 0.6036 -- iter: 256/616
[A[ATraining Step: 69  | total loss: [1m[32m0.68804[0m[0m | time: 4.745s
[2K
| RMSProp | epoch: 004 | loss: 0.68804 - acc: 0.5988 -- iter: 288/616
[A[ATraining Step: 70  | total loss: [1m[32m0.68763[0m[0m | time: 5.378s
[2K
| RMSProp | epoch: 004 | loss: 0.68763 - acc: 0.6018 -- iter: 320/616
[A[ATraining Step: 71  | total loss: [1m[32m0.68834[0m[0m | time: 6.006s
[2K
| RMSProp | epoch: 004 | loss: 0.68834 - acc: 0.5902 -- iter: 352/616
[A[ATraining Step: 72  | total loss: [1m[32m0.68871[0m[0m | time: 6.618s
[2K
| RMSProp | epoch: 004 | loss: 0.68871 - acc: 0.5836 -- iter: 384/616
[A[ATraining Step: 73  | total loss: [1m[32m0.68898[0m[0m | time: 7.240s
[2K
| RMSProp | epoch: 004 | loss: 0.68898 - acc: 0.5778 -- iter: 416/616
[A[ATraining Step: 74  | total loss: [1m[32m0.68978[0m[0m | time: 7.891s
[2K
| RMSProp | epoch: 004 | loss: 0.68978 - acc: 0.5658 -- iter: 448/616
[A[ATraining Step: 75  | total loss: [1m[32m0.68997[0m[0m | time: 8.530s
[2K
| RMSProp | epoch: 004 | loss: 0.68997 - acc: 0.5621 -- iter: 480/616
[A[ATraining Step: 76  | total loss: [1m[32m0.68916[0m[0m | time: 9.135s
[2K
| RMSProp | epoch: 004 | loss: 0.68916 - acc: 0.5721 -- iter: 512/616
[A[ATraining Step: 77  | total loss: [1m[32m0.68967[0m[0m | time: 9.763s
[2K
| RMSProp | epoch: 004 | loss: 0.68967 - acc: 0.5645 -- iter: 544/616
[A[ATraining Step: 78  | total loss: [1m[32m0.68831[0m[0m | time: 10.386s
[2K
| RMSProp | epoch: 004 | loss: 0.68831 - acc: 0.5806 -- iter: 576/616
[A[ATraining Step: 79  | total loss: [1m[32m0.68753[0m[0m | time: 10.998s
[2K
| RMSProp | epoch: 004 | loss: 0.68753 - acc: 0.5885 -- iter: 608/616
[A[ATraining Step: 80  | total loss: [1m[32m0.68793[0m[0m | time: 12.627s
[2K
| RMSProp | epoch: 004 | loss: 0.68793 - acc: 0.5826 | val_loss: 0.68361 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 81  | total loss: [1m[32m0.68650[0m[0m | time: 0.608s
[2K
| RMSProp | epoch: 005 | loss: 0.68650 - acc: 0.5964 -- iter: 032/616
[A[ATraining Step: 82  | total loss: [1m[32m0.68603[0m[0m | time: 1.226s
[2K
| RMSProp | epoch: 005 | loss: 0.68603 - acc: 0.5992 -- iter: 064/616
[A[ATraining Step: 83  | total loss: [1m[32m0.68654[0m[0m | time: 1.417s
[2K
| RMSProp | epoch: 005 | loss: 0.68654 - acc: 0.5924 -- iter: 096/616
[A[ATraining Step: 84  | total loss: [1m[32m0.68468[0m[0m | time: 1.592s
[2K
| RMSProp | epoch: 005 | loss: 0.68468 - acc: 0.6082 -- iter: 128/616
[A[ATraining Step: 85  | total loss: [1m[32m0.68271[0m[0m | time: 2.210s
[2K
| RMSProp | epoch: 005 | loss: 0.68271 - acc: 0.6224 -- iter: 160/616
[A[ATraining Step: 86  | total loss: [1m[32m0.68274[0m[0m | time: 2.848s
[2K
| RMSProp | epoch: 005 | loss: 0.68274 - acc: 0.6195 -- iter: 192/616
[A[ATraining Step: 87  | total loss: [1m[32m0.68274[0m[0m | time: 3.465s
[2K
| RMSProp | epoch: 005 | loss: 0.68274 - acc: 0.6169 -- iter: 224/616
[A[ATraining Step: 88  | total loss: [1m[32m0.68364[0m[0m | time: 4.091s
[2K
| RMSProp | epoch: 005 | loss: 0.68364 - acc: 0.6084 -- iter: 256/616
[A[ATraining Step: 89  | total loss: [1m[32m0.68314[0m[0m | time: 4.728s
[2K
| RMSProp | epoch: 005 | loss: 0.68314 - acc: 0.6100 -- iter: 288/616
[A[ATraining Step: 90  | total loss: [1m[32m0.68350[0m[0m | time: 5.342s
[2K
| RMSProp | epoch: 005 | loss: 0.68350 - acc: 0.6053 -- iter: 320/616
[A[ATraining Step: 91  | total loss: [1m[32m0.68245[0m[0m | time: 5.958s
[2K
| RMSProp | epoch: 005 | loss: 0.68245 - acc: 0.6104 -- iter: 352/616
[A[ATraining Step: 92  | total loss: [1m[32m0.68378[0m[0m | time: 6.582s
[2K
| RMSProp | epoch: 005 | loss: 0.68378 - acc: 0.5993 -- iter: 384/616
[A[ATraining Step: 93  | total loss: [1m[32m0.68405[0m[0m | time: 7.190s
[2K
| RMSProp | epoch: 005 | loss: 0.68405 - acc: 0.5957 -- iter: 416/616
[A[ATraining Step: 94  | total loss: [1m[32m0.68286[0m[0m | time: 7.808s
[2K
| RMSProp | epoch: 005 | loss: 0.68286 - acc: 0.6017 -- iter: 448/616
[A[ATraining Step: 95  | total loss: [1m[32m0.68266[0m[0m | time: 8.416s
[2K
| RMSProp | epoch: 005 | loss: 0.68266 - acc: 0.6009 -- iter: 480/616
[A[ATraining Step: 96  | total loss: [1m[32m0.68351[0m[0m | time: 9.016s
[2K
| RMSProp | epoch: 005 | loss: 0.68351 - acc: 0.5940 -- iter: 512/616
[A[ATraining Step: 97  | total loss: [1m[32m0.68701[0m[0m | time: 9.621s
[2K
| RMSProp | epoch: 005 | loss: 0.68701 - acc: 0.5721 -- iter: 544/616
[A[ATraining Step: 98  | total loss: [1m[32m0.68928[0m[0m | time: 10.229s
[2K
| RMSProp | epoch: 005 | loss: 0.68928 - acc: 0.5555 -- iter: 576/616
[A[ATraining Step: 99  | total loss: [1m[32m0.68782[0m[0m | time: 10.864s
[2K
| RMSProp | epoch: 005 | loss: 0.68782 - acc: 0.5656 -- iter: 608/616
[A[ATraining Step: 100  | total loss: [1m[32m0.69044[0m[0m | time: 12.497s
[2K
| RMSProp | epoch: 005 | loss: 0.69044 - acc: 0.5465 | val_loss: 0.68108 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 101  | total loss: [1m[32m0.68972[0m[0m | time: 0.623s
[2K
| RMSProp | epoch: 006 | loss: 0.68972 - acc: 0.5512 -- iter: 032/616
[A[ATraining Step: 102  | total loss: [1m[32m0.68910[0m[0m | time: 1.238s
[2K
| RMSProp | epoch: 006 | loss: 0.68910 - acc: 0.5555 -- iter: 064/616
[A[ATraining Step: 103  | total loss: [1m[32m0.68667[0m[0m | time: 1.868s
[2K
| RMSProp | epoch: 006 | loss: 0.68667 - acc: 0.5718 -- iter: 096/616
[A[ATraining Step: 104  | total loss: [1m[32m0.68609[0m[0m | time: 2.063s
[2K
| RMSProp | epoch: 006 | loss: 0.68609 - acc: 0.5740 -- iter: 128/616
[A[ATraining Step: 105  | total loss: [1m[32m0.68937[0m[0m | time: 2.237s
[2K
| RMSProp | epoch: 006 | loss: 0.68937 - acc: 0.5541 -- iter: 160/616
[A[ATraining Step: 106  | total loss: [1m[32m0.69193[0m[0m | time: 2.851s
[2K
| RMSProp | epoch: 006 | loss: 0.69193 - acc: 0.5362 -- iter: 192/616
[A[ATraining Step: 107  | total loss: [1m[32m0.69071[0m[0m | time: 3.481s
[2K
| RMSProp | epoch: 006 | loss: 0.69071 - acc: 0.5451 -- iter: 224/616
[A[ATraining Step: 108  | total loss: [1m[32m0.68992[0m[0m | time: 4.078s
[2K
| RMSProp | epoch: 006 | loss: 0.68992 - acc: 0.5499 -- iter: 256/616
[A[ATraining Step: 109  | total loss: [1m[32m0.68785[0m[0m | time: 4.681s
[2K
| RMSProp | epoch: 006 | loss: 0.68785 - acc: 0.5637 -- iter: 288/616
[A[ATraining Step: 110  | total loss: [1m[32m0.68464[0m[0m | time: 5.317s
[2K
| RMSProp | epoch: 006 | loss: 0.68464 - acc: 0.5823 -- iter: 320/616
[A[ATraining Step: 111  | total loss: [1m[32m0.68603[0m[0m | time: 5.952s
[2K
| RMSProp | epoch: 006 | loss: 0.68603 - acc: 0.5741 -- iter: 352/616
[A[ATraining Step: 112  | total loss: [1m[32m0.68549[0m[0m | time: 6.571s
[2K
| RMSProp | epoch: 006 | loss: 0.68549 - acc: 0.5761 -- iter: 384/616
[A[ATraining Step: 113  | total loss: [1m[32m0.68171[0m[0m | time: 7.208s
[2K
| RMSProp | epoch: 006 | loss: 0.68171 - acc: 0.5935 -- iter: 416/616
[A[ATraining Step: 114  | total loss: [1m[32m0.68135[0m[0m | time: 7.823s
[2K
| RMSProp | epoch: 006 | loss: 0.68135 - acc: 0.5935 -- iter: 448/616
[A[ATraining Step: 115  | total loss: [1m[32m0.68533[0m[0m | time: 8.445s
[2K
| RMSProp | epoch: 006 | loss: 0.68533 - acc: 0.5779 -- iter: 480/616
[A[ATraining Step: 116  | total loss: [1m[32m0.68593[0m[0m | time: 9.074s
[2K
| RMSProp | epoch: 006 | loss: 0.68593 - acc: 0.5732 -- iter: 512/616
[A[ATraining Step: 117  | total loss: [1m[32m0.68581[0m[0m | time: 9.711s
[2K
| RMSProp | epoch: 006 | loss: 0.68581 - acc: 0.5721 -- iter: 544/616
[A[ATraining Step: 118  | total loss: [1m[32m0.68453[0m[0m | time: 10.326s
[2K
| RMSProp | epoch: 006 | loss: 0.68453 - acc: 0.5774 -- iter: 576/616
[A[ATraining Step: 119  | total loss: [1m[32m0.68459[0m[0m | time: 10.932s
[2K
| RMSProp | epoch: 006 | loss: 0.68459 - acc: 0.5759 -- iter: 608/616
[A[ATraining Step: 120  | total loss: [1m[32m0.68326[0m[0m | time: 12.566s
[2K
| RMSProp | epoch: 006 | loss: 0.68326 - acc: 0.5808 | val_loss: 0.67272 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 121  | total loss: [1m[32m0.68271[0m[0m | time: 0.612s
[2K
| RMSProp | epoch: 007 | loss: 0.68271 - acc: 0.5821 -- iter: 032/616
[A[ATraining Step: 122  | total loss: [1m[32m0.68210[0m[0m | time: 1.227s
[2K
| RMSProp | epoch: 007 | loss: 0.68210 - acc: 0.5833 -- iter: 064/616
[A[ATraining Step: 123  | total loss: [1m[32m0.68224[0m[0m | time: 1.828s
[2K
| RMSProp | epoch: 007 | loss: 0.68224 - acc: 0.5812 -- iter: 096/616
[A[ATraining Step: 124  | total loss: [1m[32m0.67766[0m[0m | time: 2.457s
[2K
| RMSProp | epoch: 007 | loss: 0.67766 - acc: 0.5950 -- iter: 128/616
[A[ATraining Step: 125  | total loss: [1m[32m0.67418[0m[0m | time: 2.636s
[2K
| RMSProp | epoch: 007 | loss: 0.67418 - acc: 0.6011 -- iter: 160/616
[A[ATraining Step: 126  | total loss: [1m[32m0.68209[0m[0m | time: 2.810s
[2K
| RMSProp | epoch: 007 | loss: 0.68209 - acc: 0.5910 -- iter: 192/616
[A[ATraining Step: 127  | total loss: [1m[32m0.68349[0m[0m | time: 3.438s
[2K
| RMSProp | epoch: 007 | loss: 0.68349 - acc: 0.5819 -- iter: 224/616
[A[ATraining Step: 128  | total loss: [1m[32m0.68419[0m[0m | time: 4.049s
[2K
| RMSProp | epoch: 007 | loss: 0.68419 - acc: 0.5768 -- iter: 256/616
[A[ATraining Step: 129  | total loss: [1m[32m0.68270[0m[0m | time: 4.654s
[2K
| RMSProp | epoch: 007 | loss: 0.68270 - acc: 0.5848 -- iter: 288/616
[A[ATraining Step: 130  | total loss: [1m[32m0.67905[0m[0m | time: 5.262s
[2K
| RMSProp | epoch: 007 | loss: 0.67905 - acc: 0.6013 -- iter: 320/616
[A[ATraining Step: 131  | total loss: [1m[32m0.67973[0m[0m | time: 5.861s
[2K
| RMSProp | epoch: 007 | loss: 0.67973 - acc: 0.5974 -- iter: 352/616
[A[ATraining Step: 132  | total loss: [1m[32m0.67951[0m[0m | time: 6.474s
[2K
| RMSProp | epoch: 007 | loss: 0.67951 - acc: 0.5970 -- iter: 384/616
[A[ATraining Step: 133  | total loss: [1m[32m0.68103[0m[0m | time: 7.069s
[2K
| RMSProp | epoch: 007 | loss: 0.68103 - acc: 0.5905 -- iter: 416/616
[A[ATraining Step: 134  | total loss: [1m[32m0.68231[0m[0m | time: 7.679s
[2K
| RMSProp | epoch: 007 | loss: 0.68231 - acc: 0.5845 -- iter: 448/616
[A[ATraining Step: 135  | total loss: [1m[32m0.68327[0m[0m | time: 8.271s
[2K
| RMSProp | epoch: 007 | loss: 0.68327 - acc: 0.5792 -- iter: 480/616
[A[ATraining Step: 136  | total loss: [1m[32m0.68060[0m[0m | time: 8.891s
[2K
| RMSProp | epoch: 007 | loss: 0.68060 - acc: 0.5900 -- iter: 512/616
[A[ATraining Step: 137  | total loss: [1m[32m0.68283[0m[0m | time: 9.486s
[2K
| RMSProp | epoch: 007 | loss: 0.68283 - acc: 0.5810 -- iter: 544/616
[A[ATraining Step: 138  | total loss: [1m[32m0.68151[0m[0m | time: 10.107s
[2K
| RMSProp | epoch: 007 | loss: 0.68151 - acc: 0.5854 -- iter: 576/616
[A[ATraining Step: 139  | total loss: [1m[32m0.68179[0m[0m | time: 10.737s
[2K
| RMSProp | epoch: 007 | loss: 0.68179 - acc: 0.5831 -- iter: 608/616
[A[ATraining Step: 140  | total loss: [1m[32m0.67599[0m[0m | time: 12.385s
[2K
| RMSProp | epoch: 007 | loss: 0.67599 - acc: 0.6030 | val_loss: 0.69705 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 141  | total loss: [1m[32m0.67144[0m[0m | time: 0.604s
[2K
| RMSProp | epoch: 008 | loss: 0.67144 - acc: 0.6114 -- iter: 032/616
[A[ATraining Step: 142  | total loss: [1m[32m0.68956[0m[0m | time: 1.254s
[2K
| RMSProp | epoch: 008 | loss: 0.68956 - acc: 0.5940 -- iter: 064/616
[A[ATraining Step: 143  | total loss: [1m[32m0.68788[0m[0m | time: 1.887s
[2K
| RMSProp | epoch: 008 | loss: 0.68788 - acc: 0.5971 -- iter: 096/616
[A[ATraining Step: 144  | total loss: [1m[32m0.68974[0m[0m | time: 2.509s
[2K
| RMSProp | epoch: 008 | loss: 0.68974 - acc: 0.5843 -- iter: 128/616
[A[ATraining Step: 145  | total loss: [1m[32m0.69054[0m[0m | time: 3.164s
[2K
| RMSProp | epoch: 008 | loss: 0.69054 - acc: 0.5759 -- iter: 160/616
[A[ATraining Step: 146  | total loss: [1m[32m0.69011[0m[0m | time: 3.357s
[2K
| RMSProp | epoch: 008 | loss: 0.69011 - acc: 0.5745 -- iter: 192/616
[A[ATraining Step: 147  | total loss: [1m[32m0.68843[0m[0m | time: 3.530s
[2K
| RMSProp | epoch: 008 | loss: 0.68843 - acc: 0.5796 -- iter: 224/616
[A[ATraining Step: 148  | total loss: [1m[32m0.68679[0m[0m | time: 4.170s
[2K
| RMSProp | epoch: 008 | loss: 0.68679 - acc: 0.5841 -- iter: 256/616
[A[ATraining Step: 149  | total loss: [1m[32m0.68731[0m[0m | time: 4.800s
[2K
| RMSProp | epoch: 008 | loss: 0.68731 - acc: 0.5788 -- iter: 288/616
[A[ATraining Step: 150  | total loss: [1m[32m0.68573[0m[0m | time: 5.416s
[2K
| RMSProp | epoch: 008 | loss: 0.68573 - acc: 0.5834 -- iter: 320/616
[A[ATraining Step: 151  | total loss: [1m[32m0.68337[0m[0m | time: 6.042s
[2K
| RMSProp | epoch: 008 | loss: 0.68337 - acc: 0.5907 -- iter: 352/616
[A[ATraining Step: 152  | total loss: [1m[32m0.68192[0m[0m | time: 6.660s
[2K
| RMSProp | epoch: 008 | loss: 0.68192 - acc: 0.5941 -- iter: 384/616
[A[ATraining Step: 153  | total loss: [1m[32m0.68321[0m[0m | time: 7.316s
[2K
| RMSProp | epoch: 008 | loss: 0.68321 - acc: 0.5879 -- iter: 416/616
[A[ATraining Step: 154  | total loss: [1m[32m0.68678[0m[0m | time: 7.924s
[2K
| RMSProp | epoch: 008 | loss: 0.68678 - acc: 0.5728 -- iter: 448/616
[A[ATraining Step: 155  | total loss: [1m[32m0.68152[0m[0m | time: 8.551s
[2K
| RMSProp | epoch: 008 | loss: 0.68152 - acc: 0.5937 -- iter: 480/616
[A[ATraining Step: 156  | total loss: [1m[32m0.68368[0m[0m | time: 9.198s
[2K
| RMSProp | epoch: 008 | loss: 0.68368 - acc: 0.5843 -- iter: 512/616
[A[ATraining Step: 157  | total loss: [1m[32m0.68308[0m[0m | time: 9.818s
[2K
| RMSProp | epoch: 008 | loss: 0.68308 - acc: 0.5852 -- iter: 544/616
[A[ATraining Step: 158  | total loss: [1m[32m0.68171[0m[0m | time: 10.438s
[2K
| RMSProp | epoch: 008 | loss: 0.68171 - acc: 0.5892 -- iter: 576/616
[A[ATraining Step: 159  | total loss: [1m[32m0.68213[0m[0m | time: 11.060s
[2K
| RMSProp | epoch: 008 | loss: 0.68213 - acc: 0.5865 -- iter: 608/616
[A[ATraining Step: 160  | total loss: [1m[32m0.68333[0m[0m | time: 12.670s
[2K
| RMSProp | epoch: 008 | loss: 0.68333 - acc: 0.5810 | val_loss: 0.67421 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 161  | total loss: [1m[32m0.68432[0m[0m | time: 0.636s
[2K
| RMSProp | epoch: 009 | loss: 0.68432 - acc: 0.5760 -- iter: 032/616
[A[ATraining Step: 162  | total loss: [1m[32m0.68361[0m[0m | time: 1.251s
[2K
| RMSProp | epoch: 009 | loss: 0.68361 - acc: 0.5778 -- iter: 064/616
[A[ATraining Step: 163  | total loss: [1m[32m0.68459[0m[0m | time: 1.861s
[2K
| RMSProp | epoch: 009 | loss: 0.68459 - acc: 0.5732 -- iter: 096/616
[A[ATraining Step: 164  | total loss: [1m[32m0.68616[0m[0m | time: 2.496s
[2K
| RMSProp | epoch: 009 | loss: 0.68616 - acc: 0.5658 -- iter: 128/616
[A[ATraining Step: 165  | total loss: [1m[32m0.68674[0m[0m | time: 3.109s
[2K
| RMSProp | epoch: 009 | loss: 0.68674 - acc: 0.5624 -- iter: 160/616
[A[ATraining Step: 166  | total loss: [1m[32m0.68796[0m[0m | time: 3.715s
[2K
| RMSProp | epoch: 009 | loss: 0.68796 - acc: 0.5561 -- iter: 192/616
[A[ATraining Step: 167  | total loss: [1m[32m0.68706[0m[0m | time: 3.885s
[2K
| RMSProp | epoch: 009 | loss: 0.68706 - acc: 0.5599 -- iter: 224/616
[A[ATraining Step: 168  | total loss: [1m[32m0.68549[0m[0m | time: 4.086s
[2K
| RMSProp | epoch: 009 | loss: 0.68549 - acc: 0.5664 -- iter: 256/616
[A[ATraining Step: 169  | total loss: [1m[32m0.68400[0m[0m | time: 4.698s
[2K
| RMSProp | epoch: 009 | loss: 0.68400 - acc: 0.5723 -- iter: 288/616
[A[ATraining Step: 170  | total loss: [1m[32m0.67993[0m[0m | time: 5.305s
[2K
| RMSProp | epoch: 009 | loss: 0.67993 - acc: 0.5869 -- iter: 320/616
[A[ATraining Step: 171  | total loss: [1m[32m0.68163[0m[0m | time: 5.921s
[2K
| RMSProp | epoch: 009 | loss: 0.68163 - acc: 0.5814 -- iter: 352/616
[A[ATraining Step: 172  | total loss: [1m[32m0.68301[0m[0m | time: 6.536s
[2K
| RMSProp | epoch: 009 | loss: 0.68301 - acc: 0.5763 -- iter: 384/616
[A[ATraining Step: 173  | total loss: [1m[32m0.68574[0m[0m | time: 7.135s
[2K
| RMSProp | epoch: 009 | loss: 0.68574 - acc: 0.5656 -- iter: 416/616
[A[ATraining Step: 174  | total loss: [1m[32m0.67931[0m[0m | time: 7.750s
[2K
| RMSProp | epoch: 009 | loss: 0.67931 - acc: 0.5934 -- iter: 448/616
[A[ATraining Step: 175  | total loss: [1m[32m0.68091[0m[0m | time: 8.369s
[2K
| RMSProp | epoch: 009 | loss: 0.68091 - acc: 0.5872 -- iter: 480/616
[A[ATraining Step: 176  | total loss: [1m[32m0.67876[0m[0m | time: 8.981s
[2K
| RMSProp | epoch: 009 | loss: 0.67876 - acc: 0.5941 -- iter: 512/616
[A[ATraining Step: 177  | total loss: [1m[32m0.67339[0m[0m | time: 9.620s
[2K
| RMSProp | epoch: 009 | loss: 0.67339 - acc: 0.6097 -- iter: 544/616
[A[ATraining Step: 178  | total loss: [1m[32m0.66719[0m[0m | time: 10.256s
[2K
| RMSProp | epoch: 009 | loss: 0.66719 - acc: 0.6206 -- iter: 576/616
[A[ATraining Step: 179  | total loss: [1m[32m0.72474[0m[0m | time: 10.863s
[2K
| RMSProp | epoch: 009 | loss: 0.72474 - acc: 0.6054 -- iter: 608/616
[A[ATraining Step: 180  | total loss: [1m[32m0.71689[0m[0m | time: 12.491s
[2K
| RMSProp | epoch: 009 | loss: 0.71689 - acc: 0.6136 | val_loss: 0.67187 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 181  | total loss: [1m[32m0.71718[0m[0m | time: 0.634s
[2K
| RMSProp | epoch: 010 | loss: 0.71718 - acc: 0.5991 -- iter: 032/616
[A[ATraining Step: 182  | total loss: [1m[32m0.71198[0m[0m | time: 1.245s
[2K
| RMSProp | epoch: 010 | loss: 0.71198 - acc: 0.6017 -- iter: 064/616
[A[ATraining Step: 183  | total loss: [1m[32m0.70837[0m[0m | time: 1.889s
[2K
| RMSProp | epoch: 010 | loss: 0.70837 - acc: 0.6009 -- iter: 096/616
[A[ATraining Step: 184  | total loss: [1m[32m0.70614[0m[0m | time: 2.515s
[2K
| RMSProp | epoch: 010 | loss: 0.70614 - acc: 0.5971 -- iter: 128/616
[A[ATraining Step: 185  | total loss: [1m[32m0.70205[0m[0m | time: 3.137s
[2K
| RMSProp | epoch: 010 | loss: 0.70205 - acc: 0.5999 -- iter: 160/616
[A[ATraining Step: 186  | total loss: [1m[32m0.69943[0m[0m | time: 3.761s
[2K
| RMSProp | epoch: 010 | loss: 0.69943 - acc: 0.5993 -- iter: 192/616
[A[ATraining Step: 187  | total loss: [1m[32m0.69501[0m[0m | time: 4.400s
[2K
| RMSProp | epoch: 010 | loss: 0.69501 - acc: 0.6050 -- iter: 224/616
[A[ATraining Step: 188  | total loss: [1m[32m0.69767[0m[0m | time: 4.572s
[2K
| RMSProp | epoch: 010 | loss: 0.69767 - acc: 0.5913 -- iter: 256/616
[A[ATraining Step: 189  | total loss: [1m[32m0.69879[0m[0m | time: 4.749s
[2K
| RMSProp | epoch: 010 | loss: 0.69879 - acc: 0.5822 -- iter: 288/616
[A[ATraining Step: 190  | total loss: [1m[32m0.69923[0m[0m | time: 5.379s
[2K
| RMSProp | epoch: 010 | loss: 0.69923 - acc: 0.5740 -- iter: 320/616
[A[ATraining Step: 191  | total loss: [1m[32m0.70042[0m[0m | time: 6.029s
[2K
| RMSProp | epoch: 010 | loss: 0.70042 - acc: 0.5635 -- iter: 352/616
[A[ATraining Step: 192  | total loss: [1m[32m0.69881[0m[0m | time: 6.663s
[2K
| RMSProp | epoch: 010 | loss: 0.69881 - acc: 0.5634 -- iter: 384/616
[A[ATraining Step: 193  | total loss: [1m[32m0.69510[0m[0m | time: 7.294s
[2K
| RMSProp | epoch: 010 | loss: 0.69510 - acc: 0.5727 -- iter: 416/616
[A[ATraining Step: 194  | total loss: [1m[32m0.69042[0m[0m | time: 7.936s
[2K
| RMSProp | epoch: 010 | loss: 0.69042 - acc: 0.5841 -- iter: 448/616
[A[ATraining Step: 195  | total loss: [1m[32m0.69000[0m[0m | time: 8.574s
[2K
| RMSProp | epoch: 010 | loss: 0.69000 - acc: 0.5820 -- iter: 480/616
[A[ATraining Step: 196  | total loss: [1m[32m0.69476[0m[0m | time: 9.188s
[2K
| RMSProp | epoch: 010 | loss: 0.69476 - acc: 0.5644 -- iter: 512/616
[A[ATraining Step: 197  | total loss: [1m[32m0.69052[0m[0m | time: 9.800s
[2K
| RMSProp | epoch: 010 | loss: 0.69052 - acc: 0.5767 -- iter: 544/616
[A[ATraining Step: 198  | total loss: [1m[32m0.68718[0m[0m | time: 10.412s
[2K
| RMSProp | epoch: 010 | loss: 0.68718 - acc: 0.5847 -- iter: 576/616
[A[ATraining Step: 199  | total loss: [1m[32m0.68304[0m[0m | time: 11.023s
[2K
| RMSProp | epoch: 010 | loss: 0.68304 - acc: 0.5949 -- iter: 608/616
[A[ATraining Step: 200  | total loss: [1m[32m0.68574[0m[0m | time: 12.646s
[2K
| RMSProp | epoch: 010 | loss: 0.68574 - acc: 0.5855 | val_loss: 0.67127 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 201  | total loss: [1m[32m0.68289[0m[0m | time: 0.622s
[2K
| RMSProp | epoch: 011 | loss: 0.68289 - acc: 0.5925 -- iter: 032/616
[A[ATraining Step: 202  | total loss: [1m[32m0.68225[0m[0m | time: 1.240s
[2K
| RMSProp | epoch: 011 | loss: 0.68225 - acc: 0.5927 -- iter: 064/616
[A[ATraining Step: 203  | total loss: [1m[32m0.67942[0m[0m | time: 1.886s
[2K
| RMSProp | epoch: 011 | loss: 0.67942 - acc: 0.5990 -- iter: 096/616
[A[ATraining Step: 204  | total loss: [1m[32m0.67789[0m[0m | time: 2.496s
[2K
| RMSProp | epoch: 011 | loss: 0.67789 - acc: 0.6016 -- iter: 128/616
[A[ATraining Step: 205  | total loss: [1m[32m0.68375[0m[0m | time: 3.141s
[2K
| RMSProp | epoch: 011 | loss: 0.68375 - acc: 0.5852 -- iter: 160/616
[A[ATraining Step: 206  | total loss: [1m[32m0.68386[0m[0m | time: 3.753s
[2K
| RMSProp | epoch: 011 | loss: 0.68386 - acc: 0.5829 -- iter: 192/616
[A[ATraining Step: 207  | total loss: [1m[32m0.68200[0m[0m | time: 4.374s
[2K
| RMSProp | epoch: 011 | loss: 0.68200 - acc: 0.5871 -- iter: 224/616
[A[ATraining Step: 208  | total loss: [1m[32m0.68031[0m[0m | time: 5.016s
[2K
| RMSProp | epoch: 011 | loss: 0.68031 - acc: 0.5909 -- iter: 256/616
[A[ATraining Step: 209  | total loss: [1m[32m0.67758[0m[0m | time: 5.191s
[2K
| RMSProp | epoch: 011 | loss: 0.67758 - acc: 0.5975 -- iter: 288/616
[A[ATraining Step: 210  | total loss: [1m[32m0.68601[0m[0m | time: 5.382s
[2K
| RMSProp | epoch: 011 | loss: 0.68601 - acc: 0.5752 -- iter: 320/616
[A[ATraining Step: 211  | total loss: [1m[32m0.69144[0m[0m | time: 6.007s
[2K
| RMSProp | epoch: 011 | loss: 0.69144 - acc: 0.5552 -- iter: 352/616
[A[ATraining Step: 212  | total loss: [1m[32m0.69086[0m[0m | time: 6.637s
[2K
| RMSProp | epoch: 011 | loss: 0.69086 - acc: 0.5559 -- iter: 384/616
[A[ATraining Step: 213  | total loss: [1m[32m0.68878[0m[0m | time: 7.294s
[2K
| RMSProp | epoch: 011 | loss: 0.68878 - acc: 0.5628 -- iter: 416/616
[A[ATraining Step: 214  | total loss: [1m[32m0.68429[0m[0m | time: 7.951s
[2K
| RMSProp | epoch: 011 | loss: 0.68429 - acc: 0.5784 -- iter: 448/616
[A[ATraining Step: 215  | total loss: [1m[32m0.68158[0m[0m | time: 8.585s
[2K
| RMSProp | epoch: 011 | loss: 0.68158 - acc: 0.5862 -- iter: 480/616
[A[ATraining Step: 216  | total loss: [1m[32m0.68747[0m[0m | time: 9.193s
[2K
| RMSProp | epoch: 011 | loss: 0.68747 - acc: 0.5682 -- iter: 512/616
[A[ATraining Step: 217  | total loss: [1m[32m0.68563[0m[0m | time: 9.827s
[2K
| RMSProp | epoch: 011 | loss: 0.68563 - acc: 0.5739 -- iter: 544/616
[A[ATraining Step: 218  | total loss: [1m[32m0.68915[0m[0m | time: 10.465s
[2K
| RMSProp | epoch: 011 | loss: 0.68915 - acc: 0.5602 -- iter: 576/616
[A[ATraining Step: 219  | total loss: [1m[32m0.68951[0m[0m | time: 11.108s
[2K
| RMSProp | epoch: 011 | loss: 0.68951 - acc: 0.5573 -- iter: 608/616
[A[ATraining Step: 220  | total loss: [1m[32m0.68830[0m[0m | time: 12.731s
[2K
| RMSProp | epoch: 011 | loss: 0.68830 - acc: 0.5610 | val_loss: 0.67389 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 221  | total loss: [1m[32m0.68723[0m[0m | time: 0.641s
[2K
| RMSProp | epoch: 012 | loss: 0.68723 - acc: 0.5643 -- iter: 032/616
[A[ATraining Step: 222  | total loss: [1m[32m0.68622[0m[0m | time: 1.293s
[2K
| RMSProp | epoch: 012 | loss: 0.68622 - acc: 0.5672 -- iter: 064/616
[A[ATraining Step: 223  | total loss: [1m[32m0.68517[0m[0m | time: 1.923s
[2K
| RMSProp | epoch: 012 | loss: 0.68517 - acc: 0.5699 -- iter: 096/616
[A[ATraining Step: 224  | total loss: [1m[32m0.68613[0m[0m | time: 2.535s
[2K
| RMSProp | epoch: 012 | loss: 0.68613 - acc: 0.5660 -- iter: 128/616
[A[ATraining Step: 225  | total loss: [1m[32m0.68704[0m[0m | time: 3.137s
[2K
| RMSProp | epoch: 012 | loss: 0.68704 - acc: 0.5625 -- iter: 160/616
[A[ATraining Step: 226  | total loss: [1m[32m0.68764[0m[0m | time: 3.758s
[2K
| RMSProp | epoch: 012 | loss: 0.68764 - acc: 0.5594 -- iter: 192/616
[A[ATraining Step: 227  | total loss: [1m[32m0.68517[0m[0m | time: 4.420s
[2K
| RMSProp | epoch: 012 | loss: 0.68517 - acc: 0.5691 -- iter: 224/616
[A[ATraining Step: 228  | total loss: [1m[32m0.68518[0m[0m | time: 5.050s
[2K
| RMSProp | epoch: 012 | loss: 0.68518 - acc: 0.5684 -- iter: 256/616
[A[ATraining Step: 229  | total loss: [1m[32m0.68934[0m[0m | time: 5.667s
[2K
| RMSProp | epoch: 012 | loss: 0.68934 - acc: 0.5522 -- iter: 288/616
[A[ATraining Step: 230  | total loss: [1m[32m0.68608[0m[0m | time: 5.854s
[2K
| RMSProp | epoch: 012 | loss: 0.68608 - acc: 0.5657 -- iter: 320/616
[A[ATraining Step: 231  | total loss: [1m[32m0.68441[0m[0m | time: 6.024s
[2K
| RMSProp | epoch: 012 | loss: 0.68441 - acc: 0.5717 -- iter: 352/616
[A[ATraining Step: 232  | total loss: [1m[32m0.68274[0m[0m | time: 6.639s
[2K
| RMSProp | epoch: 012 | loss: 0.68274 - acc: 0.5770 -- iter: 384/616
[A[ATraining Step: 233  | total loss: [1m[32m0.68190[0m[0m | time: 7.295s
[2K
| RMSProp | epoch: 012 | loss: 0.68190 - acc: 0.5787 -- iter: 416/616
[A[ATraining Step: 234  | total loss: [1m[32m0.67860[0m[0m | time: 7.945s
[2K
| RMSProp | epoch: 012 | loss: 0.67860 - acc: 0.5896 -- iter: 448/616
[A[ATraining Step: 235  | total loss: [1m[32m0.67940[0m[0m | time: 8.640s
[2K
| RMSProp | epoch: 012 | loss: 0.67940 - acc: 0.5869 -- iter: 480/616
[A[ATraining Step: 236  | total loss: [1m[32m0.67503[0m[0m | time: 9.282s
[2K
| RMSProp | epoch: 012 | loss: 0.67503 - acc: 0.6000 -- iter: 512/616
[A[ATraining Step: 237  | total loss: [1m[32m0.67665[0m[0m | time: 9.930s
[2K
| RMSProp | epoch: 012 | loss: 0.67665 - acc: 0.5963 -- iter: 544/616
[A[ATraining Step: 238  | total loss: [1m[32m0.67329[0m[0m | time: 10.544s
[2K
| RMSProp | epoch: 012 | loss: 0.67329 - acc: 0.6054 -- iter: 576/616
[A[ATraining Step: 239  | total loss: [1m[32m0.67886[0m[0m | time: 11.160s
[2K
| RMSProp | epoch: 012 | loss: 0.67886 - acc: 0.5917 -- iter: 608/616
[A[ATraining Step: 240  | total loss: [1m[32m0.67954[0m[0m | time: 12.817s
[2K
| RMSProp | epoch: 012 | loss: 0.67954 - acc: 0.5888 | val_loss: 0.67083 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 241  | total loss: [1m[32m0.67429[0m[0m | time: 0.620s
[2K
| RMSProp | epoch: 013 | loss: 0.67429 - acc: 0.6049 -- iter: 032/616
[A[ATraining Step: 242  | total loss: [1m[32m0.67441[0m[0m | time: 1.244s
[2K
| RMSProp | epoch: 013 | loss: 0.67441 - acc: 0.6038 -- iter: 064/616
[A[ATraining Step: 243  | total loss: [1m[32m0.67461[0m[0m | time: 1.860s
[2K
| RMSProp | epoch: 013 | loss: 0.67461 - acc: 0.6028 -- iter: 096/616
[A[ATraining Step: 244  | total loss: [1m[32m0.68271[0m[0m | time: 2.481s
[2K
| RMSProp | epoch: 013 | loss: 0.68271 - acc: 0.5800 -- iter: 128/616
[A[ATraining Step: 245  | total loss: [1m[32m0.68119[0m[0m | time: 3.102s
[2K
| RMSProp | epoch: 013 | loss: 0.68119 - acc: 0.5845 -- iter: 160/616
[A[ATraining Step: 246  | total loss: [1m[32m0.67879[0m[0m | time: 3.708s
[2K
| RMSProp | epoch: 013 | loss: 0.67879 - acc: 0.5917 -- iter: 192/616
[A[ATraining Step: 247  | total loss: [1m[32m0.67854[0m[0m | time: 4.336s
[2K
| RMSProp | epoch: 013 | loss: 0.67854 - acc: 0.5919 -- iter: 224/616
[A[ATraining Step: 248  | total loss: [1m[32m0.67922[0m[0m | time: 4.961s
[2K
| RMSProp | epoch: 013 | loss: 0.67922 - acc: 0.5890 -- iter: 256/616
[A[ATraining Step: 249  | total loss: [1m[32m0.67892[0m[0m | time: 5.576s
[2K
| RMSProp | epoch: 013 | loss: 0.67892 - acc: 0.5894 -- iter: 288/616
[A[ATraining Step: 250  | total loss: [1m[32m0.67663[0m[0m | time: 6.177s
[2K
| RMSProp | epoch: 013 | loss: 0.67663 - acc: 0.5961 -- iter: 320/616
[A[ATraining Step: 251  | total loss: [1m[32m0.68311[0m[0m | time: 6.362s
[2K
| RMSProp | epoch: 013 | loss: 0.68311 - acc: 0.5771 -- iter: 352/616
[A[ATraining Step: 252  | total loss: [1m[32m0.68528[0m[0m | time: 6.560s
[2K
| RMSProp | epoch: 013 | loss: 0.68528 - acc: 0.5694 -- iter: 384/616
[A[ATraining Step: 253  | total loss: [1m[32m0.68703[0m[0m | time: 7.176s
[2K
| RMSProp | epoch: 013 | loss: 0.68703 - acc: 0.5625 -- iter: 416/616
[A[ATraining Step: 254  | total loss: [1m[32m0.68192[0m[0m | time: 7.776s
[2K
| RMSProp | epoch: 013 | loss: 0.68192 - acc: 0.5812 -- iter: 448/616
[A[ATraining Step: 255  | total loss: [1m[32m0.68041[0m[0m | time: 8.385s
[2K
| RMSProp | epoch: 013 | loss: 0.68041 - acc: 0.5856 -- iter: 480/616
[A[ATraining Step: 256  | total loss: [1m[32m0.68578[0m[0m | time: 9.001s
[2K
| RMSProp | epoch: 013 | loss: 0.68578 - acc: 0.5677 -- iter: 512/616
[A[ATraining Step: 257  | total loss: [1m[32m0.68582[0m[0m | time: 9.598s
[2K
| RMSProp | epoch: 013 | loss: 0.68582 - acc: 0.5672 -- iter: 544/616
[A[ATraining Step: 258  | total loss: [1m[32m0.68755[0m[0m | time: 10.212s
[2K
| RMSProp | epoch: 013 | loss: 0.68755 - acc: 0.5604 -- iter: 576/616
[A[ATraining Step: 259  | total loss: [1m[32m0.68325[0m[0m | time: 10.824s
[2K
| RMSProp | epoch: 013 | loss: 0.68325 - acc: 0.5763 -- iter: 608/616
[A[ATraining Step: 260  | total loss: [1m[32m0.68253[0m[0m | time: 12.457s
[2K
| RMSProp | epoch: 013 | loss: 0.68253 - acc: 0.5780 | val_loss: 0.67222 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 261  | total loss: [1m[32m0.68198[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 014 | loss: 0.68198 - acc: 0.5796 -- iter: 032/616
[A[ATraining Step: 262  | total loss: [1m[32m0.68321[0m[0m | time: 1.247s
[2K
| RMSProp | epoch: 014 | loss: 0.68321 - acc: 0.5748 -- iter: 064/616
[A[ATraining Step: 263  | total loss: [1m[32m0.68255[0m[0m | time: 1.874s
[2K
| RMSProp | epoch: 014 | loss: 0.68255 - acc: 0.5767 -- iter: 096/616
[A[ATraining Step: 264  | total loss: [1m[32m0.67726[0m[0m | time: 2.486s
[2K
| RMSProp | epoch: 014 | loss: 0.67726 - acc: 0.5940 -- iter: 128/616
[A[ATraining Step: 265  | total loss: [1m[32m0.67819[0m[0m | time: 3.095s
[2K
| RMSProp | epoch: 014 | loss: 0.67819 - acc: 0.5908 -- iter: 160/616
[A[ATraining Step: 266  | total loss: [1m[32m0.68320[0m[0m | time: 3.719s
[2K
| RMSProp | epoch: 014 | loss: 0.68320 - acc: 0.5755 -- iter: 192/616
[A[ATraining Step: 267  | total loss: [1m[32m0.67981[0m[0m | time: 4.326s
[2K
| RMSProp | epoch: 014 | loss: 0.67981 - acc: 0.5867 -- iter: 224/616
[A[ATraining Step: 268  | total loss: [1m[32m0.67840[0m[0m | time: 4.940s
[2K
| RMSProp | epoch: 014 | loss: 0.67840 - acc: 0.5905 -- iter: 256/616
[A[ATraining Step: 269  | total loss: [1m[32m0.67801[0m[0m | time: 5.530s
[2K
| RMSProp | epoch: 014 | loss: 0.67801 - acc: 0.5909 -- iter: 288/616
[A[ATraining Step: 270  | total loss: [1m[32m0.67786[0m[0m | time: 6.147s
[2K
| RMSProp | epoch: 014 | loss: 0.67786 - acc: 0.5911 -- iter: 320/616
[A[ATraining Step: 271  | total loss: [1m[32m0.67767[0m[0m | time: 6.757s
[2K
| RMSProp | epoch: 014 | loss: 0.67767 - acc: 0.5914 -- iter: 352/616
[A[ATraining Step: 272  | total loss: [1m[32m0.68293[0m[0m | time: 6.936s
[2K
| RMSProp | epoch: 014 | loss: 0.68293 - acc: 0.5760 -- iter: 384/616
[A[ATraining Step: 273  | total loss: [1m[32m0.68487[0m[0m | time: 7.109s
[2K
| RMSProp | epoch: 014 | loss: 0.68487 - acc: 0.5684 -- iter: 416/616
[A[ATraining Step: 274  | total loss: [1m[32m0.68646[0m[0m | time: 7.736s
[2K
| RMSProp | epoch: 014 | loss: 0.68646 - acc: 0.5616 -- iter: 448/616
[A[ATraining Step: 275  | total loss: [1m[32m0.68736[0m[0m | time: 8.342s
[2K
| RMSProp | epoch: 014 | loss: 0.68736 - acc: 0.5554 -- iter: 480/616
[A[ATraining Step: 276  | total loss: [1m[32m0.69679[0m[0m | time: 8.950s
[2K
| RMSProp | epoch: 014 | loss: 0.69679 - acc: 0.5186 -- iter: 512/616
[A[ATraining Step: 277  | total loss: [1m[32m0.69402[0m[0m | time: 9.548s
[2K
| RMSProp | epoch: 014 | loss: 0.69402 - acc: 0.5293 -- iter: 544/616
[A[ATraining Step: 278  | total loss: [1m[32m0.69314[0m[0m | time: 10.158s
[2K
| RMSProp | epoch: 014 | loss: 0.69314 - acc: 0.5326 -- iter: 576/616
[A[ATraining Step: 279  | total loss: [1m[32m0.69501[0m[0m | time: 10.756s
[2K
| RMSProp | epoch: 014 | loss: 0.69501 - acc: 0.5262 -- iter: 608/616
[A[ATraining Step: 280  | total loss: [1m[32m0.69240[0m[0m | time: 12.365s
[2K
| RMSProp | epoch: 014 | loss: 0.69240 - acc: 0.5361 | val_loss: 0.67190 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 281  | total loss: [1m[32m0.68749[0m[0m | time: 0.608s
[2K
| RMSProp | epoch: 015 | loss: 0.68749 - acc: 0.5543 -- iter: 032/616
[A[ATraining Step: 282  | total loss: [1m[32m0.69119[0m[0m | time: 1.201s
[2K
| RMSProp | epoch: 015 | loss: 0.69119 - acc: 0.5427 -- iter: 064/616
[A[ATraining Step: 283  | total loss: [1m[32m0.68888[0m[0m | time: 1.816s
[2K
| RMSProp | epoch: 015 | loss: 0.68888 - acc: 0.5509 -- iter: 096/616
[A[ATraining Step: 284  | total loss: [1m[32m0.69217[0m[0m | time: 2.419s
[2K
| RMSProp | epoch: 015 | loss: 0.69217 - acc: 0.5396 -- iter: 128/616
[A[ATraining Step: 285  | total loss: [1m[32m0.68836[0m[0m | time: 3.050s
[2K
| RMSProp | epoch: 015 | loss: 0.68836 - acc: 0.5544 -- iter: 160/616
[A[ATraining Step: 286  | total loss: [1m[32m0.68994[0m[0m | time: 3.684s
[2K
| RMSProp | epoch: 015 | loss: 0.68994 - acc: 0.5489 -- iter: 192/616
[A[ATraining Step: 287  | total loss: [1m[32m0.68441[0m[0m | time: 4.304s
[2K
| RMSProp | epoch: 015 | loss: 0.68441 - acc: 0.5690 -- iter: 224/616
[A[ATraining Step: 288  | total loss: [1m[32m0.68260[0m[0m | time: 4.947s
[2K
| RMSProp | epoch: 015 | loss: 0.68260 - acc: 0.5746 -- iter: 256/616
[A[ATraining Step: 289  | total loss: [1m[32m0.68084[0m[0m | time: 5.566s
[2K
| RMSProp | epoch: 015 | loss: 0.68084 - acc: 0.5797 -- iter: 288/616
[A[ATraining Step: 290  | total loss: [1m[32m0.68265[0m[0m | time: 6.176s
[2K
| RMSProp | epoch: 015 | loss: 0.68265 - acc: 0.5748 -- iter: 320/616
[A[ATraining Step: 291  | total loss: [1m[32m0.67895[0m[0m | time: 6.776s
[2K
| RMSProp | epoch: 015 | loss: 0.67895 - acc: 0.5861 -- iter: 352/616
[A[ATraining Step: 292  | total loss: [1m[32m0.67644[0m[0m | time: 7.382s
[2K
| RMSProp | epoch: 015 | loss: 0.67644 - acc: 0.5931 -- iter: 384/616
[A[ATraining Step: 293  | total loss: [1m[32m0.67402[0m[0m | time: 7.566s
[2K
| RMSProp | epoch: 015 | loss: 0.67402 - acc: 0.5994 -- iter: 416/616
[A[ATraining Step: 294  | total loss: [1m[32m0.68344[0m[0m | time: 7.772s
[2K
| RMSProp | epoch: 015 | loss: 0.68344 - acc: 0.5770 -- iter: 448/616
[A[ATraining Step: 295  | total loss: [1m[32m0.69000[0m[0m | time: 8.383s
[2K
| RMSProp | epoch: 015 | loss: 0.69000 - acc: 0.5568 -- iter: 480/616
[A[ATraining Step: 296  | total loss: [1m[32m0.69222[0m[0m | time: 9.020s
[2K
| RMSProp | epoch: 015 | loss: 0.69222 - acc: 0.5480 -- iter: 512/616
[A[ATraining Step: 297  | total loss: [1m[32m0.69051[0m[0m | time: 9.615s
[2K
| RMSProp | epoch: 015 | loss: 0.69051 - acc: 0.5526 -- iter: 544/616
[A[ATraining Step: 298  | total loss: [1m[32m0.69169[0m[0m | time: 10.273s
[2K
| RMSProp | epoch: 015 | loss: 0.69169 - acc: 0.5473 -- iter: 576/616
[A[ATraining Step: 299  | total loss: [1m[32m0.69105[0m[0m | time: 10.889s
[2K
| RMSProp | epoch: 015 | loss: 0.69105 - acc: 0.5488 -- iter: 608/616
[A[ATraining Step: 300  | total loss: [1m[32m0.68881[0m[0m | time: 12.501s
[2K
| RMSProp | epoch: 015 | loss: 0.68881 - acc: 0.5564 | val_loss: 0.67239 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 301  | total loss: [1m[32m0.68581[0m[0m | time: 0.607s
[2K
| RMSProp | epoch: 016 | loss: 0.68581 - acc: 0.5664 -- iter: 032/616
[A[ATraining Step: 302  | total loss: [1m[32m0.69139[0m[0m | time: 1.227s
[2K
| RMSProp | epoch: 016 | loss: 0.69139 - acc: 0.5473 -- iter: 064/616
[A[ATraining Step: 303  | total loss: [1m[32m0.68911[0m[0m | time: 1.861s
[2K
| RMSProp | epoch: 016 | loss: 0.68911 - acc: 0.5550 -- iter: 096/616
[A[ATraining Step: 304  | total loss: [1m[32m0.68777[0m[0m | time: 2.507s
[2K
| RMSProp | epoch: 016 | loss: 0.68777 - acc: 0.5589 -- iter: 128/616
[A[ATraining Step: 305  | total loss: [1m[32m0.68746[0m[0m | time: 3.117s
[2K
| RMSProp | epoch: 016 | loss: 0.68746 - acc: 0.5593 -- iter: 160/616
[A[ATraining Step: 306  | total loss: [1m[32m0.68641[0m[0m | time: 3.752s
[2K
| RMSProp | epoch: 016 | loss: 0.68641 - acc: 0.5627 -- iter: 192/616
[A[ATraining Step: 307  | total loss: [1m[32m0.68554[0m[0m | time: 4.362s
[2K
| RMSProp | epoch: 016 | loss: 0.68554 - acc: 0.5658 -- iter: 224/616
[A[ATraining Step: 308  | total loss: [1m[32m0.68922[0m[0m | time: 4.983s
[2K
| RMSProp | epoch: 016 | loss: 0.68922 - acc: 0.5530 -- iter: 256/616
[A[ATraining Step: 309  | total loss: [1m[32m0.68241[0m[0m | time: 5.620s
[2K
| RMSProp | epoch: 016 | loss: 0.68241 - acc: 0.5789 -- iter: 288/616
[A[ATraining Step: 310  | total loss: [1m[32m0.68454[0m[0m | time: 6.224s
[2K
| RMSProp | epoch: 016 | loss: 0.68454 - acc: 0.5711 -- iter: 320/616
[A[ATraining Step: 311  | total loss: [1m[32m0.68181[0m[0m | time: 6.852s
[2K
| RMSProp | epoch: 016 | loss: 0.68181 - acc: 0.5796 -- iter: 352/616
[A[ATraining Step: 312  | total loss: [1m[32m0.68125[0m[0m | time: 7.455s
[2K
| RMSProp | epoch: 016 | loss: 0.68125 - acc: 0.5810 -- iter: 384/616
[A[ATraining Step: 313  | total loss: [1m[32m0.68067[0m[0m | time: 8.078s
[2K
| RMSProp | epoch: 016 | loss: 0.68067 - acc: 0.5823 -- iter: 416/616
[A[ATraining Step: 314  | total loss: [1m[32m0.68498[0m[0m | time: 8.267s
[2K
| RMSProp | epoch: 016 | loss: 0.68498 - acc: 0.5678 -- iter: 448/616
[A[ATraining Step: 315  | total loss: [1m[32m0.68334[0m[0m | time: 8.445s
[2K
| RMSProp | epoch: 016 | loss: 0.68334 - acc: 0.5735 -- iter: 480/616
[A[ATraining Step: 316  | total loss: [1m[32m0.68183[0m[0m | time: 9.052s
[2K
| RMSProp | epoch: 016 | loss: 0.68183 - acc: 0.5787 -- iter: 512/616
[A[ATraining Step: 317  | total loss: [1m[32m0.67835[0m[0m | time: 9.651s
[2K
| RMSProp | epoch: 016 | loss: 0.67835 - acc: 0.5895 -- iter: 544/616
[A[ATraining Step: 318  | total loss: [1m[32m0.67816[0m[0m | time: 10.258s
[2K
| RMSProp | epoch: 016 | loss: 0.67816 - acc: 0.5900 -- iter: 576/616
[A[ATraining Step: 319  | total loss: [1m[32m0.68004[0m[0m | time: 10.894s
[2K
| RMSProp | epoch: 016 | loss: 0.68004 - acc: 0.5841 -- iter: 608/616
[A[ATraining Step: 320  | total loss: [1m[32m0.68066[0m[0m | time: 12.506s
[2K
| RMSProp | epoch: 016 | loss: 0.68066 - acc: 0.5819 | val_loss: 0.67157 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 321  | total loss: [1m[32m0.67914[0m[0m | time: 0.639s
[2K
| RMSProp | epoch: 017 | loss: 0.67914 - acc: 0.5862 -- iter: 032/616
[A[ATraining Step: 322  | total loss: [1m[32m0.67979[0m[0m | time: 1.244s
[2K
| RMSProp | epoch: 017 | loss: 0.67979 - acc: 0.5839 -- iter: 064/616
[A[ATraining Step: 323  | total loss: [1m[32m0.68236[0m[0m | time: 1.877s
[2K
| RMSProp | epoch: 017 | loss: 0.68236 - acc: 0.5755 -- iter: 096/616
[A[ATraining Step: 324  | total loss: [1m[32m0.67881[0m[0m | time: 2.498s
[2K
| RMSProp | epoch: 017 | loss: 0.67881 - acc: 0.5867 -- iter: 128/616
[A[ATraining Step: 325  | total loss: [1m[32m0.67437[0m[0m | time: 3.125s
[2K
| RMSProp | epoch: 017 | loss: 0.67437 - acc: 0.5999 -- iter: 160/616
[A[ATraining Step: 326  | total loss: [1m[32m0.67342[0m[0m | time: 3.728s
[2K
| RMSProp | epoch: 017 | loss: 0.67342 - acc: 0.6024 -- iter: 192/616
[A[ATraining Step: 327  | total loss: [1m[32m0.67106[0m[0m | time: 4.323s
[2K
| RMSProp | epoch: 017 | loss: 0.67106 - acc: 0.6078 -- iter: 224/616
[A[ATraining Step: 328  | total loss: [1m[32m0.67149[0m[0m | time: 4.926s
[2K
| RMSProp | epoch: 017 | loss: 0.67149 - acc: 0.6064 -- iter: 256/616
[A[ATraining Step: 329  | total loss: [1m[32m0.66676[0m[0m | time: 5.531s
[2K
| RMSProp | epoch: 017 | loss: 0.66676 - acc: 0.6176 -- iter: 288/616
[A[ATraining Step: 330  | total loss: [1m[32m0.67397[0m[0m | time: 6.146s
[2K
| RMSProp | epoch: 017 | loss: 0.67397 - acc: 0.6059 -- iter: 320/616
[A[ATraining Step: 331  | total loss: [1m[32m0.67048[0m[0m | time: 6.748s
[2K
| RMSProp | epoch: 017 | loss: 0.67048 - acc: 0.6140 -- iter: 352/616
[A[ATraining Step: 332  | total loss: [1m[32m0.67635[0m[0m | time: 7.369s
[2K
| RMSProp | epoch: 017 | loss: 0.67635 - acc: 0.5995 -- iter: 384/616
[A[ATraining Step: 333  | total loss: [1m[32m0.68073[0m[0m | time: 7.980s
[2K
| RMSProp | epoch: 017 | loss: 0.68073 - acc: 0.5864 -- iter: 416/616
[A[ATraining Step: 334  | total loss: [1m[32m0.68348[0m[0m | time: 8.591s
[2K
| RMSProp | epoch: 017 | loss: 0.68348 - acc: 0.5778 -- iter: 448/616
[A[ATraining Step: 335  | total loss: [1m[32m0.68070[0m[0m | time: 8.780s
[2K
| RMSProp | epoch: 017 | loss: 0.68070 - acc: 0.5856 -- iter: 480/616
[A[ATraining Step: 336  | total loss: [1m[32m0.67473[0m[0m | time: 8.969s
[2K
| RMSProp | epoch: 017 | loss: 0.67473 - acc: 0.6021 -- iter: 512/616
[A[ATraining Step: 337  | total loss: [1m[32m0.66902[0m[0m | time: 9.586s
[2K
| RMSProp | epoch: 017 | loss: 0.66902 - acc: 0.6169 -- iter: 544/616
[A[ATraining Step: 338  | total loss: [1m[32m0.66700[0m[0m | time: 10.209s
[2K
| RMSProp | epoch: 017 | loss: 0.66700 - acc: 0.6208 -- iter: 576/616
[A[ATraining Step: 339  | total loss: [1m[32m0.67192[0m[0m | time: 10.841s
[2K
| RMSProp | epoch: 017 | loss: 0.67192 - acc: 0.6087 -- iter: 608/616
[A[ATraining Step: 340  | total loss: [1m[32m0.67599[0m[0m | time: 12.475s
[2K
| RMSProp | epoch: 017 | loss: 0.67599 - acc: 0.5978 | val_loss: 0.67016 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 341  | total loss: [1m[32m0.67016[0m[0m | time: 0.609s
[2K
| RMSProp | epoch: 018 | loss: 0.67016 - acc: 0.6131 -- iter: 032/616
[A[ATraining Step: 342  | total loss: [1m[32m0.67446[0m[0m | time: 1.229s
[2K
| RMSProp | epoch: 018 | loss: 0.67446 - acc: 0.6018 -- iter: 064/616
[A[ATraining Step: 343  | total loss: [1m[32m0.68164[0m[0m | time: 1.831s
[2K
| RMSProp | epoch: 018 | loss: 0.68164 - acc: 0.5822 -- iter: 096/616
[A[ATraining Step: 344  | total loss: [1m[32m0.67888[0m[0m | time: 2.446s
[2K
| RMSProp | epoch: 018 | loss: 0.67888 - acc: 0.5896 -- iter: 128/616
[A[ATraining Step: 345  | total loss: [1m[32m0.68068[0m[0m | time: 3.091s
[2K
| RMSProp | epoch: 018 | loss: 0.68068 - acc: 0.5838 -- iter: 160/616
[A[ATraining Step: 346  | total loss: [1m[32m0.69192[0m[0m | time: 3.726s
[2K
| RMSProp | epoch: 018 | loss: 0.69192 - acc: 0.5504 -- iter: 192/616
[A[ATraining Step: 347  | total loss: [1m[32m0.68850[0m[0m | time: 4.342s
[2K
| RMSProp | epoch: 018 | loss: 0.68850 - acc: 0.5610 -- iter: 224/616
[A[ATraining Step: 348  | total loss: [1m[32m0.68823[0m[0m | time: 4.967s
[2K
| RMSProp | epoch: 018 | loss: 0.68823 - acc: 0.5611 -- iter: 256/616
[A[ATraining Step: 349  | total loss: [1m[32m0.68418[0m[0m | time: 5.607s
[2K
| RMSProp | epoch: 018 | loss: 0.68418 - acc: 0.5738 -- iter: 288/616
[A[ATraining Step: 350  | total loss: [1m[32m0.68732[0m[0m | time: 6.226s
[2K
| RMSProp | epoch: 018 | loss: 0.68732 - acc: 0.5633 -- iter: 320/616
[A[ATraining Step: 351  | total loss: [1m[32m0.68620[0m[0m | time: 6.832s
[2K
| RMSProp | epoch: 018 | loss: 0.68620 - acc: 0.5663 -- iter: 352/616
[A[ATraining Step: 352  | total loss: [1m[32m0.68812[0m[0m | time: 7.448s
[2K
| RMSProp | epoch: 018 | loss: 0.68812 - acc: 0.5597 -- iter: 384/616
[A[ATraining Step: 353  | total loss: [1m[32m0.69142[0m[0m | time: 8.078s
[2K
| RMSProp | epoch: 018 | loss: 0.69142 - acc: 0.5475 -- iter: 416/616
[A[ATraining Step: 354  | total loss: [1m[32m0.68738[0m[0m | time: 8.716s
[2K
| RMSProp | epoch: 018 | loss: 0.68738 - acc: 0.5615 -- iter: 448/616
[A[ATraining Step: 355  | total loss: [1m[32m0.68511[0m[0m | time: 9.326s
[2K
| RMSProp | epoch: 018 | loss: 0.68511 - acc: 0.5678 -- iter: 480/616
[A[ATraining Step: 356  | total loss: [1m[32m0.68059[0m[0m | time: 9.500s
[2K
| RMSProp | epoch: 018 | loss: 0.68059 - acc: 0.5798 -- iter: 512/616
[A[ATraining Step: 357  | total loss: [1m[32m0.68384[0m[0m | time: 9.673s
[2K
| RMSProp | epoch: 018 | loss: 0.68384 - acc: 0.5718 -- iter: 544/616
[A[ATraining Step: 358  | total loss: [1m[32m0.68534[0m[0m | time: 10.291s
[2K
| RMSProp | epoch: 018 | loss: 0.68534 - acc: 0.5646 -- iter: 576/616
[A[ATraining Step: 359  | total loss: [1m[32m0.68219[0m[0m | time: 10.891s
[2K
| RMSProp | epoch: 018 | loss: 0.68219 - acc: 0.5738 -- iter: 608/616
[A[ATraining Step: 360  | total loss: [1m[32m0.68201[0m[0m | time: 12.504s
[2K
| RMSProp | epoch: 018 | loss: 0.68201 - acc: 0.5727 | val_loss: 0.66360 - val_acc: 0.6062 -- iter: 616/616
--
Training Step: 361  | total loss: [1m[32m0.68272[0m[0m | time: 0.638s
[2K
| RMSProp | epoch: 019 | loss: 0.68272 - acc: 0.5685 -- iter: 032/616
[A[ATraining Step: 362  | total loss: [1m[32m0.67794[0m[0m | time: 1.239s
[2K
| RMSProp | epoch: 019 | loss: 0.67794 - acc: 0.5835 -- iter: 064/616
[A[ATraining Step: 363  | total loss: [1m[32m0.66975[0m[0m | time: 1.920s
[2K
| RMSProp | epoch: 019 | loss: 0.66975 - acc: 0.5971 -- iter: 096/616
[A[ATraining Step: 364  | total loss: [1m[32m0.68678[0m[0m | time: 2.538s
[2K
| RMSProp | epoch: 019 | loss: 0.68678 - acc: 0.5874 -- iter: 128/616
[A[ATraining Step: 365  | total loss: [1m[32m0.68494[0m[0m | time: 3.147s
[2K
| RMSProp | epoch: 019 | loss: 0.68494 - acc: 0.5880 -- iter: 160/616
[A[ATraining Step: 366  | total loss: [1m[32m0.67649[0m[0m | time: 3.759s
[2K
| RMSProp | epoch: 019 | loss: 0.67649 - acc: 0.6011 -- iter: 192/616
[A[ATraining Step: 367  | total loss: [1m[32m0.67502[0m[0m | time: 4.373s
[2K
| RMSProp | epoch: 019 | loss: 0.67502 - acc: 0.6003 -- iter: 224/616
[A[ATraining Step: 368  | total loss: [1m[32m0.67414[0m[0m | time: 5.007s
[2K
| RMSProp | epoch: 019 | loss: 0.67414 - acc: 0.5934 -- iter: 256/616
[A[ATraining Step: 369  | total loss: [1m[32m0.66774[0m[0m | time: 5.606s
[2K
| RMSProp | epoch: 019 | loss: 0.66774 - acc: 0.6028 -- iter: 288/616
[A[ATraining Step: 370  | total loss: [1m[32m0.66052[0m[0m | time: 6.234s
[2K
| RMSProp | epoch: 019 | loss: 0.66052 - acc: 0.6113 -- iter: 320/616
[A[ATraining Step: 371  | total loss: [1m[32m0.65328[0m[0m | time: 6.868s
[2K
| RMSProp | epoch: 019 | loss: 0.65328 - acc: 0.6189 -- iter: 352/616
[A[ATraining Step: 372  | total loss: [1m[32m0.65651[0m[0m | time: 7.483s
[2K
| RMSProp | epoch: 019 | loss: 0.65651 - acc: 0.6102 -- iter: 384/616
[A[ATraining Step: 373  | total loss: [1m[32m0.65835[0m[0m | time: 8.091s
[2K
| RMSProp | epoch: 019 | loss: 0.65835 - acc: 0.5991 -- iter: 416/616
[A[ATraining Step: 374  | total loss: [1m[32m0.65845[0m[0m | time: 8.699s
[2K
| RMSProp | epoch: 019 | loss: 0.65845 - acc: 0.5955 -- iter: 448/616
[A[ATraining Step: 375  | total loss: [1m[32m0.65792[0m[0m | time: 9.309s
[2K
| RMSProp | epoch: 019 | loss: 0.65792 - acc: 0.5859 -- iter: 480/616
[A[ATraining Step: 376  | total loss: [1m[32m0.64952[0m[0m | time: 9.937s
[2K
| RMSProp | epoch: 019 | loss: 0.64952 - acc: 0.5867 -- iter: 512/616
[A[ATraining Step: 377  | total loss: [1m[32m0.65893[0m[0m | time: 10.105s
[2K
| RMSProp | epoch: 019 | loss: 0.65893 - acc: 0.5749 -- iter: 544/616
[A[ATraining Step: 378  | total loss: [1m[32m0.66164[0m[0m | time: 10.272s
[2K
| RMSProp | epoch: 019 | loss: 0.66164 - acc: 0.5799 -- iter: 576/616
[A[ATraining Step: 379  | total loss: [1m[32m0.66244[0m[0m | time: 10.875s
[2K
| RMSProp | epoch: 019 | loss: 0.66244 - acc: 0.5844 -- iter: 608/616
[A[ATraining Step: 380  | total loss: [1m[32m0.66154[0m[0m | time: 12.485s
[2K
| RMSProp | epoch: 019 | loss: 0.66154 - acc: 0.5916 | val_loss: 0.55149 - val_acc: 0.7202 -- iter: 616/616
--
Training Step: 381  | total loss: [1m[32m0.65401[0m[0m | time: 0.612s
[2K
| RMSProp | epoch: 020 | loss: 0.65401 - acc: 0.5981 -- iter: 032/616
[A[ATraining Step: 382  | total loss: [1m[32m0.64189[0m[0m | time: 1.216s
[2K
| RMSProp | epoch: 020 | loss: 0.64189 - acc: 0.6070 -- iter: 064/616
[A[ATraining Step: 383  | total loss: [1m[32m0.64777[0m[0m | time: 1.848s
[2K
| RMSProp | epoch: 020 | loss: 0.64777 - acc: 0.5994 -- iter: 096/616
[A[ATraining Step: 384  | total loss: [1m[32m0.64182[0m[0m | time: 2.457s
[2K
| RMSProp | epoch: 020 | loss: 0.64182 - acc: 0.6082 -- iter: 128/616
[A[ATraining Step: 385  | total loss: [1m[32m0.63680[0m[0m | time: 3.078s
[2K
| RMSProp | epoch: 020 | loss: 0.63680 - acc: 0.6099 -- iter: 160/616
[A[ATraining Step: 386  | total loss: [1m[32m0.63574[0m[0m | time: 3.693s
[2K
| RMSProp | epoch: 020 | loss: 0.63574 - acc: 0.6083 -- iter: 192/616
[A[ATraining Step: 387  | total loss: [1m[32m0.62793[0m[0m | time: 4.299s
[2K
| RMSProp | epoch: 020 | loss: 0.62793 - acc: 0.6131 -- iter: 224/616
[A[ATraining Step: 388  | total loss: [1m[32m0.61707[0m[0m | time: 4.905s
[2K
| RMSProp | epoch: 020 | loss: 0.61707 - acc: 0.6268 -- iter: 256/616
[A[ATraining Step: 389  | total loss: [1m[32m0.63021[0m[0m | time: 5.521s
[2K
| RMSProp | epoch: 020 | loss: 0.63021 - acc: 0.6079 -- iter: 288/616
[A[ATraining Step: 390  | total loss: [1m[32m0.62256[0m[0m | time: 6.123s
[2K
| RMSProp | epoch: 020 | loss: 0.62256 - acc: 0.6221 -- iter: 320/616
[A[ATraining Step: 391  | total loss: [1m[32m0.61188[0m[0m | time: 6.714s
[2K
| RMSProp | epoch: 020 | loss: 0.61188 - acc: 0.6349 -- iter: 352/616
[A[ATraining Step: 392  | total loss: [1m[32m0.60085[0m[0m | time: 7.338s
[2K
| RMSProp | epoch: 020 | loss: 0.60085 - acc: 0.6495 -- iter: 384/616
[A[ATraining Step: 393  | total loss: [1m[32m0.59981[0m[0m | time: 7.943s
[2K
| RMSProp | epoch: 020 | loss: 0.59981 - acc: 0.6533 -- iter: 416/616
[A[ATraining Step: 394  | total loss: [1m[32m0.59325[0m[0m | time: 8.557s
[2K
| RMSProp | epoch: 020 | loss: 0.59325 - acc: 0.6630 -- iter: 448/616
[A[ATraining Step: 395  | total loss: [1m[32m0.58972[0m[0m | time: 9.153s
[2K
| RMSProp | epoch: 020 | loss: 0.58972 - acc: 0.6717 -- iter: 480/616
[A[ATraining Step: 396  | total loss: [1m[32m0.58997[0m[0m | time: 9.766s
[2K
| RMSProp | epoch: 020 | loss: 0.58997 - acc: 0.6639 -- iter: 512/616
[A[ATraining Step: 397  | total loss: [1m[32m0.57036[0m[0m | time: 10.404s
[2K
| RMSProp | epoch: 020 | loss: 0.57036 - acc: 0.6850 -- iter: 544/616
[A[ATraining Step: 398  | total loss: [1m[32m0.56445[0m[0m | time: 10.576s
[2K
| RMSProp | epoch: 020 | loss: 0.56445 - acc: 0.6915 -- iter: 576/616
[A[ATraining Step: 399  | total loss: [1m[32m0.60039[0m[0m | time: 10.762s
[2K
| RMSProp | epoch: 020 | loss: 0.60039 - acc: 0.6473 -- iter: 608/616
[A[ATraining Step: 400  | total loss: [1m[32m0.60785[0m[0m | time: 12.370s
[2K
| RMSProp | epoch: 020 | loss: 0.60785 - acc: 0.6576 | val_loss: 0.51615 - val_acc: 0.6373 -- iter: 616/616
--
Training Step: 401  | total loss: [1m[32m0.60883[0m[0m | time: 0.609s
[2K
| RMSProp | epoch: 021 | loss: 0.60883 - acc: 0.6512 -- iter: 032/616
[A[ATraining Step: 402  | total loss: [1m[32m0.59149[0m[0m | time: 1.224s
[2K
| RMSProp | epoch: 021 | loss: 0.59149 - acc: 0.6549 -- iter: 064/616
[A[ATraining Step: 403  | total loss: [1m[32m0.57971[0m[0m | time: 1.848s
[2K
| RMSProp | epoch: 021 | loss: 0.57971 - acc: 0.6706 -- iter: 096/616
[A[ATraining Step: 404  | total loss: [1m[32m0.56304[0m[0m | time: 2.478s
[2K
| RMSProp | epoch: 021 | loss: 0.56304 - acc: 0.6911 -- iter: 128/616
[A[ATraining Step: 405  | total loss: [1m[32m0.55374[0m[0m | time: 3.079s
[2K
| RMSProp | epoch: 021 | loss: 0.55374 - acc: 0.7032 -- iter: 160/616
[A[ATraining Step: 406  | total loss: [1m[32m0.54939[0m[0m | time: 3.683s
[2K
| RMSProp | epoch: 021 | loss: 0.54939 - acc: 0.7079 -- iter: 192/616
[A[ATraining Step: 407  | total loss: [1m[32m0.55432[0m[0m | time: 4.304s
[2K
| RMSProp | epoch: 021 | loss: 0.55432 - acc: 0.7090 -- iter: 224/616
[A[ATraining Step: 408  | total loss: [1m[32m0.53885[0m[0m | time: 4.943s
[2K
| RMSProp | epoch: 021 | loss: 0.53885 - acc: 0.7318 -- iter: 256/616
[A[ATraining Step: 409  | total loss: [1m[32m0.52587[0m[0m | time: 5.539s
[2K
| RMSProp | epoch: 021 | loss: 0.52587 - acc: 0.7399 -- iter: 288/616
[A[ATraining Step: 410  | total loss: [1m[32m0.53294[0m[0m | time: 6.144s
[2K
| RMSProp | epoch: 021 | loss: 0.53294 - acc: 0.7440 -- iter: 320/616
[A[ATraining Step: 411  | total loss: [1m[32m0.52398[0m[0m | time: 6.753s
[2K
| RMSProp | epoch: 021 | loss: 0.52398 - acc: 0.7477 -- iter: 352/616
[A[ATraining Step: 412  | total loss: [1m[32m0.52159[0m[0m | time: 7.367s
[2K
| RMSProp | epoch: 021 | loss: 0.52159 - acc: 0.7417 -- iter: 384/616
[A[ATraining Step: 413  | total loss: [1m[32m0.52474[0m[0m | time: 7.983s
[2K
| RMSProp | epoch: 021 | loss: 0.52474 - acc: 0.7394 -- iter: 416/616
[A[ATraining Step: 414  | total loss: [1m[32m0.50948[0m[0m | time: 8.604s
[2K
| RMSProp | epoch: 021 | loss: 0.50948 - acc: 0.7530 -- iter: 448/616
[A[ATraining Step: 415  | total loss: [1m[32m0.49399[0m[0m | time: 9.226s
[2K
| RMSProp | epoch: 021 | loss: 0.49399 - acc: 0.7652 -- iter: 480/616
[A[ATraining Step: 416  | total loss: [1m[32m0.48498[0m[0m | time: 9.883s
[2K
| RMSProp | epoch: 021 | loss: 0.48498 - acc: 0.7605 -- iter: 512/616
[A[ATraining Step: 417  | total loss: [1m[32m0.49000[0m[0m | time: 10.488s
[2K
| RMSProp | epoch: 021 | loss: 0.49000 - acc: 0.7532 -- iter: 544/616
[A[ATraining Step: 418  | total loss: [1m[32m0.48501[0m[0m | time: 11.117s
[2K
| RMSProp | epoch: 021 | loss: 0.48501 - acc: 0.7623 -- iter: 576/616
[A[ATraining Step: 419  | total loss: [1m[32m0.47715[0m[0m | time: 11.301s
[2K
| RMSProp | epoch: 021 | loss: 0.47715 - acc: 0.7611 -- iter: 608/616
[A[ATraining Step: 420  | total loss: [1m[32m0.46188[0m[0m | time: 12.483s
[2K
| RMSProp | epoch: 021 | loss: 0.46188 - acc: 0.7725 | val_loss: 0.37928 - val_acc: 0.8135 -- iter: 616/616
--
Training Step: 421  | total loss: [1m[32m0.44454[0m[0m | time: 0.605s
[2K
| RMSProp | epoch: 022 | loss: 0.44454 - acc: 0.7827 -- iter: 032/616
[A[ATraining Step: 422  | total loss: [1m[32m0.43885[0m[0m | time: 1.246s
[2K
| RMSProp | epoch: 022 | loss: 0.43885 - acc: 0.7888 -- iter: 064/616
[A[ATraining Step: 423  | total loss: [1m[32m0.44659[0m[0m | time: 1.905s
[2K
| RMSProp | epoch: 022 | loss: 0.44659 - acc: 0.7787 -- iter: 096/616
[A[ATraining Step: 424  | total loss: [1m[32m0.45752[0m[0m | time: 2.544s
[2K
| RMSProp | epoch: 022 | loss: 0.45752 - acc: 0.7758 -- iter: 128/616
[A[ATraining Step: 425  | total loss: [1m[32m0.45047[0m[0m | time: 3.169s
[2K
| RMSProp | epoch: 022 | loss: 0.45047 - acc: 0.7795 -- iter: 160/616
[A[ATraining Step: 426  | total loss: [1m[32m0.43305[0m[0m | time: 3.782s
[2K
| RMSProp | epoch: 022 | loss: 0.43305 - acc: 0.7859 -- iter: 192/616
[A[ATraining Step: 427  | total loss: [1m[32m0.42783[0m[0m | time: 4.414s
[2K
| RMSProp | epoch: 022 | loss: 0.42783 - acc: 0.7917 -- iter: 224/616
[A[ATraining Step: 428  | total loss: [1m[32m0.43985[0m[0m | time: 5.021s
[2K
| RMSProp | epoch: 022 | loss: 0.43985 - acc: 0.7813 -- iter: 256/616
[A[ATraining Step: 429  | total loss: [1m[32m0.44347[0m[0m | time: 5.642s
[2K
| RMSProp | epoch: 022 | loss: 0.44347 - acc: 0.7813 -- iter: 288/616
[A[ATraining Step: 430  | total loss: [1m[32m0.44542[0m[0m | time: 6.279s
[2K
| RMSProp | epoch: 022 | loss: 0.44542 - acc: 0.7906 -- iter: 320/616
[A[ATraining Step: 431  | total loss: [1m[32m0.43224[0m[0m | time: 6.889s
[2K
| RMSProp | epoch: 022 | loss: 0.43224 - acc: 0.7991 -- iter: 352/616
[A[ATraining Step: 432  | total loss: [1m[32m0.42846[0m[0m | time: 7.502s
[2K
| RMSProp | epoch: 022 | loss: 0.42846 - acc: 0.7973 -- iter: 384/616
[A[ATraining Step: 433  | total loss: [1m[32m0.41660[0m[0m | time: 8.122s
[2K
| RMSProp | epoch: 022 | loss: 0.41660 - acc: 0.8051 -- iter: 416/616
[A[ATraining Step: 434  | total loss: [1m[32m0.42194[0m[0m | time: 8.746s
[2K
| RMSProp | epoch: 022 | loss: 0.42194 - acc: 0.8058 -- iter: 448/616
[A[ATraining Step: 435  | total loss: [1m[32m0.42712[0m[0m | time: 9.367s
[2K
| RMSProp | epoch: 022 | loss: 0.42712 - acc: 0.7971 -- iter: 480/616
[A[ATraining Step: 436  | total loss: [1m[32m0.42667[0m[0m | time: 9.992s
[2K
| RMSProp | epoch: 022 | loss: 0.42667 - acc: 0.7955 -- iter: 512/616
[A[ATraining Step: 437  | total loss: [1m[32m0.41218[0m[0m | time: 10.607s
[2K
| RMSProp | epoch: 022 | loss: 0.41218 - acc: 0.8066 -- iter: 544/616
[A[ATraining Step: 438  | total loss: [1m[32m0.40204[0m[0m | time: 11.220s
[2K
| RMSProp | epoch: 022 | loss: 0.40204 - acc: 0.8072 -- iter: 576/616
[A[ATraining Step: 439  | total loss: [1m[32m0.41636[0m[0m | time: 11.834s
[2K
| RMSProp | epoch: 022 | loss: 0.41636 - acc: 0.7983 -- iter: 608/616
[A[ATraining Step: 440  | total loss: [1m[32m0.41159[0m[0m | time: 13.021s
[2K
| RMSProp | epoch: 022 | loss: 0.41159 - acc: 0.7998 | val_loss: 0.41708 - val_acc: 0.8187 -- iter: 616/616
--
Training Step: 441  | total loss: [1m[32m0.40542[0m[0m | time: 0.191s
[2K
| RMSProp | epoch: 023 | loss: 0.40542 - acc: 0.8073 -- iter: 032/616
[A[ATraining Step: 442  | total loss: [1m[32m0.40904[0m[0m | time: 0.827s
[2K
| RMSProp | epoch: 023 | loss: 0.40904 - acc: 0.8141 -- iter: 064/616
[A[ATraining Step: 443  | total loss: [1m[32m0.40828[0m[0m | time: 1.438s
[2K
| RMSProp | epoch: 023 | loss: 0.40828 - acc: 0.8108 -- iter: 096/616
[A[ATraining Step: 444  | total loss: [1m[32m0.38964[0m[0m | time: 2.053s
[2K
| RMSProp | epoch: 023 | loss: 0.38964 - acc: 0.8234 -- iter: 128/616
[A[ATraining Step: 445  | total loss: [1m[32m0.38289[0m[0m | time: 2.671s
[2K
| RMSProp | epoch: 023 | loss: 0.38289 - acc: 0.8286 -- iter: 160/616
[A[ATraining Step: 446  | total loss: [1m[32m0.37657[0m[0m | time: 3.302s
[2K
| RMSProp | epoch: 023 | loss: 0.37657 - acc: 0.8270 -- iter: 192/616
[A[ATraining Step: 447  | total loss: [1m[32m0.36600[0m[0m | time: 3.913s
[2K
| RMSProp | epoch: 023 | loss: 0.36600 - acc: 0.8380 -- iter: 224/616
[A[ATraining Step: 448  | total loss: [1m[32m0.36108[0m[0m | time: 4.512s
[2K
| RMSProp | epoch: 023 | loss: 0.36108 - acc: 0.8386 -- iter: 256/616
[A[ATraining Step: 449  | total loss: [1m[32m0.34408[0m[0m | time: 5.125s
[2K
| RMSProp | epoch: 023 | loss: 0.34408 - acc: 0.8485 -- iter: 288/616
[A[ATraining Step: 450  | total loss: [1m[32m0.34580[0m[0m | time: 5.742s
[2K
| RMSProp | epoch: 023 | loss: 0.34580 - acc: 0.8512 -- iter: 320/616
[A[ATraining Step: 451  | total loss: [1m[32m0.38954[0m[0m | time: 6.353s
[2K
| RMSProp | epoch: 023 | loss: 0.38954 - acc: 0.8317 -- iter: 352/616
[A[ATraining Step: 452  | total loss: [1m[32m0.38557[0m[0m | time: 6.975s
[2K
| RMSProp | epoch: 023 | loss: 0.38557 - acc: 0.8360 -- iter: 384/616
[A[ATraining Step: 453  | total loss: [1m[32m0.38813[0m[0m | time: 7.565s
[2K
| RMSProp | epoch: 023 | loss: 0.38813 - acc: 0.8305 -- iter: 416/616
[A[ATraining Step: 454  | total loss: [1m[32m0.38187[0m[0m | time: 8.161s
[2K
| RMSProp | epoch: 023 | loss: 0.38187 - acc: 0.8287 -- iter: 448/616
[A[ATraining Step: 455  | total loss: [1m[32m0.36344[0m[0m | time: 8.765s
[2K
| RMSProp | epoch: 023 | loss: 0.36344 - acc: 0.8427 -- iter: 480/616
[A[ATraining Step: 456  | total loss: [1m[32m0.36899[0m[0m | time: 9.374s
[2K
| RMSProp | epoch: 023 | loss: 0.36899 - acc: 0.8428 -- iter: 512/616
[A[ATraining Step: 457  | total loss: [1m[32m0.35314[0m[0m | time: 9.973s
[2K
| RMSProp | epoch: 023 | loss: 0.35314 - acc: 0.8492 -- iter: 544/616
[A[ATraining Step: 458  | total loss: [1m[32m0.34598[0m[0m | time: 10.573s
[2K
| RMSProp | epoch: 023 | loss: 0.34598 - acc: 0.8518 -- iter: 576/616
[A[ATraining Step: 459  | total loss: [1m[32m0.33018[0m[0m | time: 11.203s
[2K
| RMSProp | epoch: 023 | loss: 0.33018 - acc: 0.8603 -- iter: 608/616
[A[ATraining Step: 460  | total loss: [1m[32m0.31501[0m[0m | time: 12.819s
[2K
| RMSProp | epoch: 023 | loss: 0.31501 - acc: 0.8680 | val_loss: 0.40990 - val_acc: 0.8394 -- iter: 616/616
--
Training Step: 461  | total loss: [1m[32m0.30920[0m[0m | time: 0.182s
[2K
| RMSProp | epoch: 024 | loss: 0.30920 - acc: 0.8750 -- iter: 032/616
[A[ATraining Step: 462  | total loss: [1m[32m0.35773[0m[0m | time: 0.355s
[2K
| RMSProp | epoch: 024 | loss: 0.35773 - acc: 0.8500 -- iter: 064/616
[A[ATraining Step: 463  | total loss: [1m[32m0.37292[0m[0m | time: 0.980s
[2K
| RMSProp | epoch: 024 | loss: 0.37292 - acc: 0.8400 -- iter: 096/616
[A[ATraining Step: 464  | total loss: [1m[32m0.38074[0m[0m | time: 1.592s
[2K
| RMSProp | epoch: 024 | loss: 0.38074 - acc: 0.8310 -- iter: 128/616
[A[ATraining Step: 465  | total loss: [1m[32m0.37806[0m[0m | time: 2.217s
[2K
| RMSProp | epoch: 024 | loss: 0.37806 - acc: 0.8260 -- iter: 160/616
[A[ATraining Step: 466  | total loss: [1m[32m0.36060[0m[0m | time: 2.822s
[2K
| RMSProp | epoch: 024 | loss: 0.36060 - acc: 0.8340 -- iter: 192/616
[A[ATraining Step: 467  | total loss: [1m[32m0.34811[0m[0m | time: 3.441s
[2K
| RMSProp | epoch: 024 | loss: 0.34811 - acc: 0.8444 -- iter: 224/616
[A[ATraining Step: 468  | total loss: [1m[32m0.34564[0m[0m | time: 4.067s
[2K
| RMSProp | epoch: 024 | loss: 0.34564 - acc: 0.8443 -- iter: 256/616
[A[ATraining Step: 469  | total loss: [1m[32m0.33290[0m[0m | time: 4.686s
[2K
| RMSProp | epoch: 024 | loss: 0.33290 - acc: 0.8505 -- iter: 288/616
[A[ATraining Step: 470  | total loss: [1m[32m0.33769[0m[0m | time: 5.324s
[2K
| RMSProp | epoch: 024 | loss: 0.33769 - acc: 0.8530 -- iter: 320/616
[A[ATraining Step: 471  | total loss: [1m[32m0.33483[0m[0m | time: 5.946s
[2K
| RMSProp | epoch: 024 | loss: 0.33483 - acc: 0.8552 -- iter: 352/616
[A[ATraining Step: 472  | total loss: [1m[32m0.32532[0m[0m | time: 6.560s
[2K
| RMSProp | epoch: 024 | loss: 0.32532 - acc: 0.8603 -- iter: 384/616
[A[ATraining Step: 473  | total loss: [1m[32m0.34702[0m[0m | time: 7.171s
[2K
| RMSProp | epoch: 024 | loss: 0.34702 - acc: 0.8492 -- iter: 416/616
[A[ATraining Step: 474  | total loss: [1m[32m0.36090[0m[0m | time: 7.798s
[2K
| RMSProp | epoch: 024 | loss: 0.36090 - acc: 0.8362 -- iter: 448/616
[A[ATraining Step: 475  | total loss: [1m[32m0.34932[0m[0m | time: 8.409s
[2K
| RMSProp | epoch: 024 | loss: 0.34932 - acc: 0.8495 -- iter: 480/616
[A[ATraining Step: 476  | total loss: [1m[32m0.34311[0m[0m | time: 9.046s
[2K
| RMSProp | epoch: 024 | loss: 0.34311 - acc: 0.8520 -- iter: 512/616
[A[ATraining Step: 477  | total loss: [1m[32m0.31740[0m[0m | time: 9.666s
[2K
| RMSProp | epoch: 024 | loss: 0.31740 - acc: 0.8637 -- iter: 544/616
[A[ATraining Step: 478  | total loss: [1m[32m0.32542[0m[0m | time: 10.290s
[2K
| RMSProp | epoch: 024 | loss: 0.32542 - acc: 0.8586 -- iter: 576/616
[A[ATraining Step: 479  | total loss: [1m[32m0.35695[0m[0m | time: 10.925s
[2K
| RMSProp | epoch: 024 | loss: 0.35695 - acc: 0.8383 -- iter: 608/616
[A[ATraining Step: 480  | total loss: [1m[32m0.35992[0m[0m | time: 12.545s
[2K
| RMSProp | epoch: 024 | loss: 0.35992 - acc: 0.8357 | val_loss: 0.28264 - val_acc: 0.8912 -- iter: 616/616
--
Training Step: 481  | total loss: [1m[32m0.34913[0m[0m | time: 0.647s
[2K
| RMSProp | epoch: 025 | loss: 0.34913 - acc: 0.8459 -- iter: 032/616
[A[ATraining Step: 482  | total loss: [1m[32m0.33712[0m[0m | time: 0.834s
[2K
| RMSProp | epoch: 025 | loss: 0.33712 - acc: 0.8520 -- iter: 064/616
[A[ATraining Step: 483  | total loss: [1m[32m0.32249[0m[0m | time: 1.023s
[2K
| RMSProp | epoch: 025 | loss: 0.32249 - acc: 0.8668 -- iter: 096/616
[A[ATraining Step: 484  | total loss: [1m[32m0.30414[0m[0m | time: 1.640s
[2K
| RMSProp | epoch: 025 | loss: 0.30414 - acc: 0.8801 -- iter: 128/616
[A[ATraining Step: 485  | total loss: [1m[32m0.29387[0m[0m | time: 2.254s
[2K
| RMSProp | epoch: 025 | loss: 0.29387 - acc: 0.8827 -- iter: 160/616
[A[ATraining Step: 486  | total loss: [1m[32m0.27778[0m[0m | time: 2.880s
[2K
| RMSProp | epoch: 025 | loss: 0.27778 - acc: 0.8913 -- iter: 192/616
[A[ATraining Step: 487  | total loss: [1m[32m0.27264[0m[0m | time: 3.495s
[2K
| RMSProp | epoch: 025 | loss: 0.27264 - acc: 0.8928 -- iter: 224/616
[A[ATraining Step: 488  | total loss: [1m[32m0.27827[0m[0m | time: 4.112s
[2K
| RMSProp | epoch: 025 | loss: 0.27827 - acc: 0.8910 -- iter: 256/616
[A[ATraining Step: 489  | total loss: [1m[32m0.27696[0m[0m | time: 4.714s
[2K
| RMSProp | epoch: 025 | loss: 0.27696 - acc: 0.8863 -- iter: 288/616
[A[ATraining Step: 490  | total loss: [1m[32m0.27907[0m[0m | time: 5.327s
[2K
| RMSProp | epoch: 025 | loss: 0.27907 - acc: 0.8852 -- iter: 320/616
[A[ATraining Step: 491  | total loss: [1m[32m0.28122[0m[0m | time: 5.938s
[2K
| RMSProp | epoch: 025 | loss: 0.28122 - acc: 0.8810 -- iter: 352/616
[A[ATraining Step: 492  | total loss: [1m[32m0.27706[0m[0m | time: 6.554s
[2K
| RMSProp | epoch: 025 | loss: 0.27706 - acc: 0.8867 -- iter: 384/616
[A[ATraining Step: 493  | total loss: [1m[32m0.27606[0m[0m | time: 7.174s
[2K
| RMSProp | epoch: 025 | loss: 0.27606 - acc: 0.8918 -- iter: 416/616
[A[ATraining Step: 494  | total loss: [1m[32m0.27096[0m[0m | time: 7.804s
[2K
| RMSProp | epoch: 025 | loss: 0.27096 - acc: 0.8932 -- iter: 448/616
[A[ATraining Step: 495  | total loss: [1m[32m0.25896[0m[0m | time: 8.444s
[2K
| RMSProp | epoch: 025 | loss: 0.25896 - acc: 0.8976 -- iter: 480/616
[A[ATraining Step: 496  | total loss: [1m[32m0.24554[0m[0m | time: 9.068s
[2K
| RMSProp | epoch: 025 | loss: 0.24554 - acc: 0.9047 -- iter: 512/616
[A[ATraining Step: 497  | total loss: [1m[32m0.25091[0m[0m | time: 9.710s
[2K
| RMSProp | epoch: 025 | loss: 0.25091 - acc: 0.9049 -- iter: 544/616
[A[ATraining Step: 498  | total loss: [1m[32m0.23513[0m[0m | time: 10.339s
[2K
| RMSProp | epoch: 025 | loss: 0.23513 - acc: 0.9144 -- iter: 576/616
[A[ATraining Step: 499  | total loss: [1m[32m0.22562[0m[0m | time: 10.962s
[2K
| RMSProp | epoch: 025 | loss: 0.22562 - acc: 0.9198 -- iter: 608/616
[A[ATraining Step: 500  | total loss: [1m[32m0.21981[0m[0m | time: 12.577s
[2K
| RMSProp | epoch: 025 | loss: 0.21981 - acc: 0.9247 | val_loss: 0.51860 - val_acc: 0.7617 -- iter: 616/616
--
Training Step: 501  | total loss: [1m[32m0.22875[0m[0m | time: 0.637s
[2K
| RMSProp | epoch: 026 | loss: 0.22875 - acc: 0.9198 -- iter: 032/616
[A[ATraining Step: 502  | total loss: [1m[32m0.27530[0m[0m | time: 1.271s
[2K
| RMSProp | epoch: 026 | loss: 0.27530 - acc: 0.9028 -- iter: 064/616
[A[ATraining Step: 503  | total loss: [1m[32m0.27785[0m[0m | time: 1.458s
[2K
| RMSProp | epoch: 026 | loss: 0.27785 - acc: 0.9031 -- iter: 096/616
[A[ATraining Step: 504  | total loss: [1m[32m0.30772[0m[0m | time: 1.642s
[2K
| RMSProp | epoch: 026 | loss: 0.30772 - acc: 0.8753 -- iter: 128/616
[A[ATraining Step: 505  | total loss: [1m[32m0.32668[0m[0m | time: 2.278s
[2K
| RMSProp | epoch: 026 | loss: 0.32668 - acc: 0.8628 -- iter: 160/616
[A[ATraining Step: 506  | total loss: [1m[32m0.31946[0m[0m | time: 2.905s
[2K
| RMSProp | epoch: 026 | loss: 0.31946 - acc: 0.8671 -- iter: 192/616
[A[ATraining Step: 507  | total loss: [1m[32m0.31318[0m[0m | time: 3.517s
[2K
| RMSProp | epoch: 026 | loss: 0.31318 - acc: 0.8742 -- iter: 224/616
[A[ATraining Step: 508  | total loss: [1m[32m0.32439[0m[0m | time: 4.127s
[2K
| RMSProp | epoch: 026 | loss: 0.32439 - acc: 0.8618 -- iter: 256/616
[A[ATraining Step: 509  | total loss: [1m[32m0.31493[0m[0m | time: 4.753s
[2K
| RMSProp | epoch: 026 | loss: 0.31493 - acc: 0.8693 -- iter: 288/616
[A[ATraining Step: 510  | total loss: [1m[32m0.30944[0m[0m | time: 5.358s
[2K
| RMSProp | epoch: 026 | loss: 0.30944 - acc: 0.8699 -- iter: 320/616
[A[ATraining Step: 511  | total loss: [1m[32m0.29692[0m[0m | time: 5.994s
[2K
| RMSProp | epoch: 026 | loss: 0.29692 - acc: 0.8767 -- iter: 352/616
[A[ATraining Step: 512  | total loss: [1m[32m0.27610[0m[0m | time: 6.639s
[2K
| RMSProp | epoch: 026 | loss: 0.27610 - acc: 0.8890 -- iter: 384/616
[A[ATraining Step: 513  | total loss: [1m[32m0.30953[0m[0m | time: 7.254s
[2K
| RMSProp | epoch: 026 | loss: 0.30953 - acc: 0.8751 -- iter: 416/616
[A[ATraining Step: 514  | total loss: [1m[32m0.29567[0m[0m | time: 7.870s
[2K
| RMSProp | epoch: 026 | loss: 0.29567 - acc: 0.8813 -- iter: 448/616
[A[ATraining Step: 515  | total loss: [1m[32m0.30450[0m[0m | time: 8.488s
[2K
| RMSProp | epoch: 026 | loss: 0.30450 - acc: 0.8776 -- iter: 480/616
[A[ATraining Step: 516  | total loss: [1m[32m0.30003[0m[0m | time: 9.096s
[2K
| RMSProp | epoch: 026 | loss: 0.30003 - acc: 0.8742 -- iter: 512/616
[A[ATraining Step: 517  | total loss: [1m[32m0.28528[0m[0m | time: 9.700s
[2K
| RMSProp | epoch: 026 | loss: 0.28528 - acc: 0.8805 -- iter: 544/616
[A[ATraining Step: 518  | total loss: [1m[32m0.27127[0m[0m | time: 10.339s
[2K
| RMSProp | epoch: 026 | loss: 0.27127 - acc: 0.8862 -- iter: 576/616
[A[ATraining Step: 519  | total loss: [1m[32m0.27123[0m[0m | time: 10.968s
[2K
| RMSProp | epoch: 026 | loss: 0.27123 - acc: 0.8820 -- iter: 608/616
[A[ATraining Step: 520  | total loss: [1m[32m0.26829[0m[0m | time: 12.595s
[2K
| RMSProp | epoch: 026 | loss: 0.26829 - acc: 0.8813 | val_loss: 0.28007 - val_acc: 0.8964 -- iter: 616/616
--
Training Step: 521  | total loss: [1m[32m0.25524[0m[0m | time: 0.660s
[2K
| RMSProp | epoch: 027 | loss: 0.25524 - acc: 0.8900 -- iter: 032/616
[A[ATraining Step: 522  | total loss: [1m[32m0.24991[0m[0m | time: 1.307s
[2K
| RMSProp | epoch: 027 | loss: 0.24991 - acc: 0.8885 -- iter: 064/616
[A[ATraining Step: 523  | total loss: [1m[32m0.24576[0m[0m | time: 1.937s
[2K
| RMSProp | epoch: 027 | loss: 0.24576 - acc: 0.8934 -- iter: 096/616
[A[ATraining Step: 524  | total loss: [1m[32m0.24538[0m[0m | time: 2.131s
[2K
| RMSProp | epoch: 027 | loss: 0.24538 - acc: 0.8947 -- iter: 128/616
[A[ATraining Step: 525  | total loss: [1m[32m0.22591[0m[0m | time: 2.322s
[2K
| RMSProp | epoch: 027 | loss: 0.22591 - acc: 0.9052 -- iter: 160/616
[A[ATraining Step: 526  | total loss: [1m[32m0.20575[0m[0m | time: 2.973s
[2K
| RMSProp | epoch: 027 | loss: 0.20575 - acc: 0.9147 -- iter: 192/616
[A[ATraining Step: 527  | total loss: [1m[32m0.23092[0m[0m | time: 3.618s
[2K
| RMSProp | epoch: 027 | loss: 0.23092 - acc: 0.9107 -- iter: 224/616
[A[ATraining Step: 528  | total loss: [1m[32m0.24318[0m[0m | time: 4.272s
[2K
| RMSProp | epoch: 027 | loss: 0.24318 - acc: 0.9040 -- iter: 256/616
[A[ATraining Step: 529  | total loss: [1m[32m0.23863[0m[0m | time: 4.893s
[2K
| RMSProp | epoch: 027 | loss: 0.23863 - acc: 0.9074 -- iter: 288/616
[A[ATraining Step: 530  | total loss: [1m[32m0.24018[0m[0m | time: 5.525s
[2K
| RMSProp | epoch: 027 | loss: 0.24018 - acc: 0.9073 -- iter: 320/616
[A[ATraining Step: 531  | total loss: [1m[32m0.23988[0m[0m | time: 6.143s
[2K
| RMSProp | epoch: 027 | loss: 0.23988 - acc: 0.9072 -- iter: 352/616
[A[ATraining Step: 532  | total loss: [1m[32m0.23448[0m[0m | time: 6.746s
[2K
| RMSProp | epoch: 027 | loss: 0.23448 - acc: 0.9071 -- iter: 384/616
[A[ATraining Step: 533  | total loss: [1m[32m0.22537[0m[0m | time: 7.371s
[2K
| RMSProp | epoch: 027 | loss: 0.22537 - acc: 0.9101 -- iter: 416/616
[A[ATraining Step: 534  | total loss: [1m[32m0.23322[0m[0m | time: 7.991s
[2K
| RMSProp | epoch: 027 | loss: 0.23322 - acc: 0.9066 -- iter: 448/616
[A[ATraining Step: 535  | total loss: [1m[32m0.22868[0m[0m | time: 8.619s
[2K
| RMSProp | epoch: 027 | loss: 0.22868 - acc: 0.9034 -- iter: 480/616
[A[ATraining Step: 536  | total loss: [1m[32m0.21413[0m[0m | time: 9.220s
[2K
| RMSProp | epoch: 027 | loss: 0.21413 - acc: 0.9131 -- iter: 512/616
[A[ATraining Step: 537  | total loss: [1m[32m0.22310[0m[0m | time: 9.876s
[2K
| RMSProp | epoch: 027 | loss: 0.22310 - acc: 0.9093 -- iter: 544/616
[A[ATraining Step: 538  | total loss: [1m[32m0.21283[0m[0m | time: 10.494s
[2K
| RMSProp | epoch: 027 | loss: 0.21283 - acc: 0.9152 -- iter: 576/616
[A[ATraining Step: 539  | total loss: [1m[32m0.20924[0m[0m | time: 11.134s
[2K
| RMSProp | epoch: 027 | loss: 0.20924 - acc: 0.9175 -- iter: 608/616
[A[ATraining Step: 540  | total loss: [1m[32m0.21225[0m[0m | time: 12.754s
[2K
| RMSProp | epoch: 027 | loss: 0.21225 - acc: 0.9132 | val_loss: 0.46367 - val_acc: 0.8187 -- iter: 616/616
--
Training Step: 541  | total loss: [1m[32m0.21002[0m[0m | time: 0.648s
[2K
| RMSProp | epoch: 028 | loss: 0.21002 - acc: 0.9125 -- iter: 032/616
[A[ATraining Step: 542  | total loss: [1m[32m0.21688[0m[0m | time: 1.312s
[2K
| RMSProp | epoch: 028 | loss: 0.21688 - acc: 0.9088 -- iter: 064/616
[A[ATraining Step: 543  | total loss: [1m[32m0.22850[0m[0m | time: 1.939s
[2K
| RMSProp | epoch: 028 | loss: 0.22850 - acc: 0.9023 -- iter: 096/616
[A[ATraining Step: 544  | total loss: [1m[32m0.23089[0m[0m | time: 2.565s
[2K
| RMSProp | epoch: 028 | loss: 0.23089 - acc: 0.8995 -- iter: 128/616
[A[ATraining Step: 545  | total loss: [1m[32m0.22156[0m[0m | time: 2.753s
[2K
| RMSProp | epoch: 028 | loss: 0.22156 - acc: 0.9065 -- iter: 160/616
[A[ATraining Step: 546  | total loss: [1m[32m0.23234[0m[0m | time: 2.940s
[2K
| RMSProp | epoch: 028 | loss: 0.23234 - acc: 0.9033 -- iter: 192/616
[A[ATraining Step: 547  | total loss: [1m[32m0.22217[0m[0m | time: 3.559s
[2K
| RMSProp | epoch: 028 | loss: 0.22217 - acc: 0.9130 -- iter: 224/616
[A[ATraining Step: 548  | total loss: [1m[32m0.23777[0m[0m | time: 4.170s
[2K
| RMSProp | epoch: 028 | loss: 0.23777 - acc: 0.9029 -- iter: 256/616
[A[ATraining Step: 549  | total loss: [1m[32m0.22732[0m[0m | time: 4.810s
[2K
| RMSProp | epoch: 028 | loss: 0.22732 - acc: 0.9095 -- iter: 288/616
[A[ATraining Step: 550  | total loss: [1m[32m0.23650[0m[0m | time: 5.422s
[2K
| RMSProp | epoch: 028 | loss: 0.23650 - acc: 0.9029 -- iter: 320/616
[A[ATraining Step: 551  | total loss: [1m[32m0.25059[0m[0m | time: 6.024s
[2K
| RMSProp | epoch: 028 | loss: 0.25059 - acc: 0.8939 -- iter: 352/616
[A[ATraining Step: 552  | total loss: [1m[32m0.24382[0m[0m | time: 6.655s
[2K
| RMSProp | epoch: 028 | loss: 0.24382 - acc: 0.8983 -- iter: 384/616
[A[ATraining Step: 553  | total loss: [1m[32m0.22602[0m[0m | time: 7.275s
[2K
| RMSProp | epoch: 028 | loss: 0.22602 - acc: 0.9084 -- iter: 416/616
[A[ATraining Step: 554  | total loss: [1m[32m0.21348[0m[0m | time: 7.876s
[2K
| RMSProp | epoch: 028 | loss: 0.21348 - acc: 0.9145 -- iter: 448/616
[A[ATraining Step: 555  | total loss: [1m[32m0.21394[0m[0m | time: 8.498s
[2K
| RMSProp | epoch: 028 | loss: 0.21394 - acc: 0.9168 -- iter: 480/616
[A[ATraining Step: 556  | total loss: [1m[32m0.20136[0m[0m | time: 9.119s
[2K
| RMSProp | epoch: 028 | loss: 0.20136 - acc: 0.9220 -- iter: 512/616
[A[ATraining Step: 557  | total loss: [1m[32m0.21132[0m[0m | time: 9.732s
[2K
| RMSProp | epoch: 028 | loss: 0.21132 - acc: 0.9204 -- iter: 544/616
[A[ATraining Step: 558  | total loss: [1m[32m0.21810[0m[0m | time: 10.344s
[2K
| RMSProp | epoch: 028 | loss: 0.21810 - acc: 0.9190 -- iter: 576/616
[A[ATraining Step: 559  | total loss: [1m[32m0.21443[0m[0m | time: 10.974s
[2K
| RMSProp | epoch: 028 | loss: 0.21443 - acc: 0.9177 -- iter: 608/616
[A[ATraining Step: 560  | total loss: [1m[32m0.19574[0m[0m | time: 12.592s
[2K
| RMSProp | epoch: 028 | loss: 0.19574 - acc: 0.9259 | val_loss: 0.36830 - val_acc: 0.8446 -- iter: 616/616
--
Training Step: 561  | total loss: [1m[32m0.19436[0m[0m | time: 0.625s
[2K
| RMSProp | epoch: 029 | loss: 0.19436 - acc: 0.9271 -- iter: 032/616
[A[ATraining Step: 562  | total loss: [1m[32m0.18477[0m[0m | time: 1.241s
[2K
| RMSProp | epoch: 029 | loss: 0.18477 - acc: 0.9313 -- iter: 064/616
[A[ATraining Step: 563  | total loss: [1m[32m0.19988[0m[0m | time: 1.850s
[2K
| RMSProp | epoch: 029 | loss: 0.19988 - acc: 0.9256 -- iter: 096/616
[A[ATraining Step: 564  | total loss: [1m[32m0.19950[0m[0m | time: 2.463s
[2K
| RMSProp | epoch: 029 | loss: 0.19950 - acc: 0.9268 -- iter: 128/616
[A[ATraining Step: 565  | total loss: [1m[32m0.20914[0m[0m | time: 3.065s
[2K
| RMSProp | epoch: 029 | loss: 0.20914 - acc: 0.9216 -- iter: 160/616
[A[ATraining Step: 566  | total loss: [1m[32m0.20123[0m[0m | time: 3.250s
[2K
| RMSProp | epoch: 029 | loss: 0.20123 - acc: 0.9232 -- iter: 192/616
[A[ATraining Step: 567  | total loss: [1m[32m0.18777[0m[0m | time: 3.427s
[2K
| RMSProp | epoch: 029 | loss: 0.18777 - acc: 0.9309 -- iter: 224/616
[A[ATraining Step: 568  | total loss: [1m[32m0.17037[0m[0m | time: 4.031s
[2K
| RMSProp | epoch: 029 | loss: 0.17037 - acc: 0.9378 -- iter: 256/616
[A[ATraining Step: 569  | total loss: [1m[32m0.17457[0m[0m | time: 4.644s
[2K
| RMSProp | epoch: 029 | loss: 0.17457 - acc: 0.9378 -- iter: 288/616
[A[ATraining Step: 570  | total loss: [1m[32m0.17381[0m[0m | time: 5.265s
[2K
| RMSProp | epoch: 029 | loss: 0.17381 - acc: 0.9378 -- iter: 320/616
[A[ATraining Step: 571  | total loss: [1m[32m0.18294[0m[0m | time: 5.900s
[2K
| RMSProp | epoch: 029 | loss: 0.18294 - acc: 0.9346 -- iter: 352/616
[A[ATraining Step: 572  | total loss: [1m[32m0.18545[0m[0m | time: 6.509s
[2K
| RMSProp | epoch: 029 | loss: 0.18545 - acc: 0.9349 -- iter: 384/616
[A[ATraining Step: 573  | total loss: [1m[32m0.17598[0m[0m | time: 7.129s
[2K
| RMSProp | epoch: 029 | loss: 0.17598 - acc: 0.9383 -- iter: 416/616
[A[ATraining Step: 574  | total loss: [1m[32m0.16524[0m[0m | time: 7.721s
[2K
| RMSProp | epoch: 029 | loss: 0.16524 - acc: 0.9444 -- iter: 448/616
[A[ATraining Step: 575  | total loss: [1m[32m0.16994[0m[0m | time: 8.338s
[2K
| RMSProp | epoch: 029 | loss: 0.16994 - acc: 0.9406 -- iter: 480/616
[A[ATraining Step: 576  | total loss: [1m[32m0.16188[0m[0m | time: 8.954s
[2K
| RMSProp | epoch: 029 | loss: 0.16188 - acc: 0.9434 -- iter: 512/616
[A[ATraining Step: 577  | total loss: [1m[32m0.20256[0m[0m | time: 9.599s
[2K
| RMSProp | epoch: 029 | loss: 0.20256 - acc: 0.9366 -- iter: 544/616
[A[ATraining Step: 578  | total loss: [1m[32m0.20836[0m[0m | time: 10.225s
[2K
| RMSProp | epoch: 029 | loss: 0.20836 - acc: 0.9304 -- iter: 576/616
[A[ATraining Step: 579  | total loss: [1m[32m0.20151[0m[0m | time: 10.849s
[2K
| RMSProp | epoch: 029 | loss: 0.20151 - acc: 0.9311 -- iter: 608/616
[A[ATraining Step: 580  | total loss: [1m[32m0.18836[0m[0m | time: 12.471s
[2K
| RMSProp | epoch: 029 | loss: 0.18836 - acc: 0.9380 | val_loss: 0.33790 - val_acc: 0.8549 -- iter: 616/616
--
Training Step: 581  | total loss: [1m[32m0.18532[0m[0m | time: 0.618s
[2K
| RMSProp | epoch: 030 | loss: 0.18532 - acc: 0.9380 -- iter: 032/616
[A[ATraining Step: 582  | total loss: [1m[32m0.18308[0m[0m | time: 1.239s
[2K
| RMSProp | epoch: 030 | loss: 0.18308 - acc: 0.9348 -- iter: 064/616
[A[ATraining Step: 583  | total loss: [1m[32m0.19168[0m[0m | time: 1.850s
[2K
| RMSProp | epoch: 030 | loss: 0.19168 - acc: 0.9319 -- iter: 096/616
[A[ATraining Step: 584  | total loss: [1m[32m0.18387[0m[0m | time: 2.468s
[2K
| RMSProp | epoch: 030 | loss: 0.18387 - acc: 0.9356 -- iter: 128/616
[A[ATraining Step: 585  | total loss: [1m[32m0.18089[0m[0m | time: 3.075s
[2K
| RMSProp | epoch: 030 | loss: 0.18089 - acc: 0.9358 -- iter: 160/616
[A[ATraining Step: 586  | total loss: [1m[32m0.16872[0m[0m | time: 3.692s
[2K
| RMSProp | epoch: 030 | loss: 0.16872 - acc: 0.9422 -- iter: 192/616
[A[ATraining Step: 587  | total loss: [1m[32m0.16450[0m[0m | time: 3.869s
[2K
| RMSProp | epoch: 030 | loss: 0.16450 - acc: 0.9449 -- iter: 224/616
[A[ATraining Step: 588  | total loss: [1m[32m0.17309[0m[0m | time: 4.051s
[2K
| RMSProp | epoch: 030 | loss: 0.17309 - acc: 0.9379 -- iter: 256/616
[A[ATraining Step: 589  | total loss: [1m[32m0.15739[0m[0m | time: 4.659s
[2K
| RMSProp | epoch: 030 | loss: 0.15739 - acc: 0.9441 -- iter: 288/616
[A[ATraining Step: 590  | total loss: [1m[32m0.16468[0m[0m | time: 5.289s
[2K
| RMSProp | epoch: 030 | loss: 0.16468 - acc: 0.9341 -- iter: 320/616
[A[ATraining Step: 591  | total loss: [1m[32m0.19774[0m[0m | time: 5.902s
[2K
| RMSProp | epoch: 030 | loss: 0.19774 - acc: 0.9219 -- iter: 352/616
[A[ATraining Step: 592  | total loss: [1m[32m0.18952[0m[0m | time: 6.538s
[2K
| RMSProp | epoch: 030 | loss: 0.18952 - acc: 0.9297 -- iter: 384/616
[A[ATraining Step: 593  | total loss: [1m[32m0.18338[0m[0m | time: 7.154s
[2K
| RMSProp | epoch: 030 | loss: 0.18338 - acc: 0.9305 -- iter: 416/616
[A[ATraining Step: 594  | total loss: [1m[32m0.17600[0m[0m | time: 7.763s
[2K
| RMSProp | epoch: 030 | loss: 0.17600 - acc: 0.9343 -- iter: 448/616
[A[ATraining Step: 595  | total loss: [1m[32m0.17124[0m[0m | time: 8.365s
[2K
| RMSProp | epoch: 030 | loss: 0.17124 - acc: 0.9346 -- iter: 480/616
[A[ATraining Step: 596  | total loss: [1m[32m0.16450[0m[0m | time: 8.992s
[2K
| RMSProp | epoch: 030 | loss: 0.16450 - acc: 0.9381 -- iter: 512/616
[A[ATraining Step: 597  | total loss: [1m[32m0.17392[0m[0m | time: 9.613s
[2K
| RMSProp | epoch: 030 | loss: 0.17392 - acc: 0.9317 -- iter: 544/616
[A[ATraining Step: 598  | total loss: [1m[32m0.19963[0m[0m | time: 10.230s
[2K
| RMSProp | epoch: 030 | loss: 0.19963 - acc: 0.9323 -- iter: 576/616
[A[ATraining Step: 599  | total loss: [1m[32m0.19009[0m[0m | time: 10.857s
[2K
| RMSProp | epoch: 030 | loss: 0.19009 - acc: 0.9391 -- iter: 608/616
[A[ATraining Step: 600  | total loss: [1m[32m0.17526[0m[0m | time: 12.499s
[2K
| RMSProp | epoch: 030 | loss: 0.17526 - acc: 0.9452 | val_loss: 0.34253 - val_acc: 0.8705 -- iter: 616/616
--
Validation AUC:0.9536662168241116
Validation AUPRC:0.976730351112781
Test AUC:0.9639649507119387
Test AUPRC:0.9779850801438995
BestTestF1Score	0.93	0.83	0.92	0.94	0.92	101	7	76	9	0.92
BestTestMCCScore	0.93	0.86	0.93	0.96	0.91	100	4	79	10	0.95
BestTestAccuracyScore	0.93	0.86	0.93	0.96	0.91	100	4	79	10	0.95
BestValidationF1Score	0.93	0.83	0.92	0.96	0.9	105	4	72	12	0.92
BestValidationMCC	0.93	0.83	0.92	0.97	0.89	104	3	73	13	0.95
BestValidationAccuracy	0.93	0.83	0.92	0.97	0.89	104	3	73	13	0.95
TestPredictions (Threshold:0.95)
CHEMBL3695332,TP,ACT,1.0	CHEMBL3662626,TP,ACT,1.0	CHEMBL190053,TN,INACT,0.029999999329447746	CHEMBL3661024,TN,INACT,0.009999999776482582	CHEMBL200374,TN,INACT,0.029999999329447746	CHEMBL324834,TN,INACT,0.009999999776482582	CHEMBL1241348,FP,INACT,0.9700000286102295	CHEMBL3702574,TP,ACT,1.0	CHEMBL3662582,TP,ACT,1.0	CHEMBL117891,TN,INACT,0.550000011920929	CHEMBL3702580,TP,ACT,1.0	CHEMBL1162478,FN,ACT,0.5600000023841858	CHEMBL3662683,TP,ACT,1.0	CHEMBL446669,TN,INACT,0.10999999940395355	CHEMBL3657570,TP,ACT,0.9900000095367432	CHEMBL155102,TN,INACT,0.029999999329447746	CHEMBL2153163,TN,INACT,0.029999999329447746	CHEMBL3702570,TP,ACT,1.0	CHEMBL3658570,TP,ACT,1.0	CHEMBL3649388,TN,INACT,0.4300000071525574	CHEMBL383816,TN,INACT,0.009999999776482582	CHEMBL3658602,TP,ACT,1.0	CHEMBL3658528,TP,ACT,1.0	CHEMBL3662557,TP,ACT,1.0	CHEMBL1082054,FN,ACT,0.05999999865889549	CHEMBL3261919,TP,ACT,0.9700000286102295	CHEMBL3662674,TP,ACT,1.0	CHEMBL3667312,TP,ACT,1.0	CHEMBL1171636,TN,INACT,0.8199999928474426	CHEMBL117905,TN,INACT,0.27000001072883606	CHEMBL2336582,TN,INACT,0.9300000071525574	CHEMBL3702582,FN,ACT,0.07000000029802322	CHEMBL3354498,TN,INACT,0.019999999552965164	CHEMBL3662675,TP,ACT,1.0	CHEMBL3662653,TP,ACT,1.0	CHEMBL3667323,TP,ACT,1.0	CHEMBL3218467,TN,INACT,0.5799999833106995	CHEMBL3667268,TP,ACT,1.0	CHEMBL3667381,TP,ACT,1.0	CHEMBL1567424,TN,INACT,0.5099999904632568	CHEMBL3662599,TP,ACT,1.0	CHEMBL3662518,TP,ACT,1.0	CHEMBL2336574,TN,INACT,0.41999998688697815	CHEMBL3667341,TP,ACT,1.0	CHEMBL2042451,TN,INACT,0.7200000286102295	CHEMBL3658486,TP,ACT,1.0	CHEMBL2325755,TN,INACT,0.4300000071525574	CHEMBL1350793,TN,INACT,0.4699999988079071	CHEMBL1171803,TN,INACT,0.019999999552965164	CHEMBL1086431,TN,INACT,0.029999999329447746	CHEMBL2312215,TN,INACT,0.029999999329447746	CHEMBL3657571,TP,ACT,1.0	CHEMBL1928930,TN,INACT,0.14000000059604645	CHEMBL390643,FN,ACT,0.05000000074505806	CHEMBL3658516,TP,ACT,1.0	CHEMBL3662531,TP,ACT,1.0	CHEMBL340663,TN,INACT,0.03999999910593033	CHEMBL3662544,TP,ACT,1.0	CHEMBL3702587,TP,ACT,1.0	CHEMBL3658485,TP,ACT,1.0	CHEMBL3662648,TP,ACT,1.0	CHEMBL3702568,TP,ACT,1.0	CHEMBL3702594,FN,ACT,0.10000000149011612	CHEMBL3658471,TP,ACT,1.0	CHEMBL3658568,TP,ACT,1.0	CHEMBL381191,TN,INACT,0.03999999910593033	CHEMBL2381994,TN,INACT,0.009999999776482582	CHEMBL3667338,TP,ACT,1.0	CHEMBL212723,TN,INACT,0.27000001072883606	CHEMBL3662621,TP,ACT,1.0	CHEMBL3662718,TP,ACT,1.0	CHEMBL251959,TN,INACT,0.029999999329447746	CHEMBL1928785,TN,INACT,0.17000000178813934	CHEMBL3662707,TP,ACT,1.0	CHEMBL3695350,TP,ACT,1.0	CHEMBL2312211,TN,INACT,0.8999999761581421	CHEMBL1077640,FN,ACT,0.30000001192092896	CHEMBL2437297,FP,INACT,1.0	CHEMBL383529,TN,INACT,0.20000000298023224	CHEMBL2382080,TN,INACT,0.23000000417232513	CHEMBL426819,TN,INACT,0.009999999776482582	CHEMBL3143392,TN,INACT,0.009999999776482582	CHEMBL3667336,TP,ACT,1.0	CHEMBL3667406,TP,ACT,1.0	CHEMBL3649363,TN,INACT,0.03999999910593033	CHEMBL2370490,TN,INACT,0.05000000074505806	CHEMBL199358,TN,INACT,0.30000001192092896	CHEMBL116358,TN,INACT,0.25999999046325684	CHEMBL3261925,TP,ACT,0.9900000095367432	CHEMBL3658507,TP,ACT,1.0	CHEMBL258818,TN,INACT,0.019999999552965164	CHEMBL3662721,TP,ACT,1.0	CHEMBL3667407,TP,ACT,1.0	CHEMBL3667383,TP,ACT,1.0	CHEMBL3658504,TP,ACT,1.0	CHEMBL1086429,TN,INACT,0.6499999761581421	CHEMBL3667337,TP,ACT,1.0	CHEMBL3695338,TP,ACT,1.0	CHEMBL424441,TN,INACT,0.28999999165534973	CHEMBL3702573,TP,ACT,1.0	CHEMBL3662637,TP,ACT,1.0	CHEMBL3662681,TP,ACT,1.0	CHEMBL3667304,TP,ACT,1.0	CHEMBL448143,FN,ACT,0.17000000178813934	CHEMBL3662586,TP,ACT,1.0	CHEMBL2381998,TN,INACT,0.009999999776482582	CHEMBL3662620,TP,ACT,1.0	CHEMBL3261928,TP,ACT,1.0	CHEMBL3667327,TP,ACT,1.0	CHEMBL2382119,TN,INACT,0.019999999552965164	CHEMBL3662630,TP,ACT,1.0	CHEMBL169264,TN,INACT,0.07000000029802322	CHEMBL2382056,TN,INACT,0.029999999329447746	CHEMBL191178,TN,INACT,0.009999999776482582	CHEMBL2437302,TN,INACT,0.9200000166893005	CHEMBL3667318,TP,ACT,1.0	CHEMBL3662597,TP,ACT,1.0	CHEMBL3639573,TP,ACT,1.0	CHEMBL381474,TN,INACT,0.7200000286102295	CHEMBL3658483,TP,ACT,1.0	CHEMBL189604,FP,INACT,0.9599999785423279	CHEMBL2382000,TN,INACT,0.009999999776482582	CHEMBL377768,FN,ACT,0.3799999952316284	CHEMBL188400,TN,INACT,0.029999999329447746	CHEMBL3658531,TP,ACT,1.0	CHEMBL3662596,TP,ACT,1.0	CHEMBL3662526,TP,ACT,1.0	CHEMBL2164679,TN,INACT,0.05999999865889549	CHEMBL3657565,TP,ACT,1.0	CHEMBL3662717,TP,ACT,1.0	CHEMBL3667272,TP,ACT,1.0	CHEMBL3093926,TN,INACT,0.4000000059604645	CHEMBL3658522,TP,ACT,1.0	CHEMBL482167,TN,INACT,0.029999999329447746	CHEMBL1086438,TN,INACT,0.1899999976158142	CHEMBL3237999,TN,INACT,0.07000000029802322	CHEMBL2336586,TN,INACT,0.699999988079071	CHEMBL2387617,TN,INACT,0.09000000357627869	CHEMBL3238001,TN,INACT,0.7699999809265137	CHEMBL133016,TN,INACT,0.009999999776482582	CHEMBL1836516,TN,INACT,0.10000000149011612	CHEMBL3662594,TP,ACT,1.0	CHEMBL3662583,TP,ACT,1.0	CHEMBL1162208,TN,INACT,0.9100000262260437	CHEMBL3667326,TP,ACT,1.0	CHEMBL3662705,TP,ACT,1.0	CHEMBL191584,TN,INACT,0.009999999776482582	CHEMBL3658524,TP,ACT,1.0	CHEMBL3662666,TP,ACT,1.0	CHEMBL3667389,FN,ACT,0.7300000190734863	CHEMBL3662542,TP,ACT,1.0	CHEMBL87946,FP,INACT,1.0	CHEMBL470707,TN,INACT,0.11999999731779099	CHEMBL208015,TN,INACT,0.17000000178813934	CHEMBL210625,TN,INACT,0.05000000074505806	CHEMBL3658534,TP,ACT,1.0	CHEMBL2382114,TN,INACT,0.05000000074505806	CHEMBL3238002,TN,INACT,0.07999999821186066	CHEMBL3667366,TP,ACT,1.0	CHEMBL3662647,TP,ACT,0.9900000095367432	CHEMBL2437299,TN,INACT,0.9200000166893005	CHEMBL3695343,TP,ACT,1.0	CHEMBL3662589,TP,ACT,1.0	CHEMBL358704,TN,INACT,0.6100000143051147	CHEMBL438442,TN,INACT,0.6299999952316284	CHEMBL96875,TN,INACT,0.05000000074505806	CHEMBL3662613,TP,ACT,1.0	CHEMBL3658562,TP,ACT,1.0	CHEMBL517082,TN,INACT,0.019999999552965164	CHEMBL382180,TN,INACT,0.029999999329447746	CHEMBL378575,TN,INACT,0.6700000166893005	CHEMBL2312205,TN,INACT,0.019999999552965164	CHEMBL187864,TN,INACT,0.009999999776482582	CHEMBL1079536,FN,ACT,0.9200000166893005	CHEMBL3662669,TP,ACT,1.0	CHEMBL1672426,TP,ACT,1.0	CHEMBL3658495,TP,ACT,1.0	CHEMBL3662576,TP,ACT,0.9800000190734863	CHEMBL115145,TN,INACT,0.23000000417232513	CHEMBL3662559,TP,ACT,1.0	CHEMBL3658541,TP,ACT,1.0	CHEMBL3667362,TP,ACT,1.0	CHEMBL3658598,TP,ACT,1.0	CHEMBL3658503,TP,ACT,1.0	CHEMBL3667285,TP,ACT,1.0	CHEMBL3662703,TP,ACT,1.0	CHEMBL1080786,TP,ACT,0.9900000095367432	CHEMBL213144,TN,INACT,0.03999999910593033	CHEMBL3658472,TP,ACT,1.0	CHEMBL3695348,TP,ACT,1.0	CHEMBL3667339,TP,ACT,1.0	CHEMBL3662658,TP,ACT,1.0	CHEMBL3662535,TP,ACT,1.0	

