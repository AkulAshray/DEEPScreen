ImageNetInceptionV2 CHEMBL1942 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	474
Number of inactive compounds :	474
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1942_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1942_adam_0.0005_15_0.6/
---------------------------------
Training samples: 550
Validation samples: 172
--
Training Step: 1  | time: 255.237s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/550
[A[ATraining Step: 2  | total loss: [1m[32m0.71195[0m[0m | time: 458.062s
[2K
| Adam | epoch: 001 | loss: 0.71195 - acc: 0.2812 -- iter: 064/550
[A[ATraining Step: 3  | total loss: [1m[32m0.74978[0m[0m | time: 553.697s
[2K
| Adam | epoch: 001 | loss: 0.74978 - acc: 0.4091 -- iter: 096/550
[A[ATraining Step: 4  | total loss: [1m[32m0.73393[0m[0m | time: 694.544s
[2K
| Adam | epoch: 001 | loss: 0.73393 - acc: 0.5476 -- iter: 128/550
[A[ATraining Step: 5  | total loss: [1m[32m0.62257[0m[0m | time: 775.088s
[2K
| Adam | epoch: 001 | loss: 0.62257 - acc: 0.6444 -- iter: 160/550
[A[ATraining Step: 6  | total loss: [1m[32m0.66748[0m[0m | time: 909.042s
[2K
| Adam | epoch: 001 | loss: 0.66748 - acc: 0.5717 -- iter: 192/550
[A[ATraining Step: 7  | total loss: [1m[32m0.58908[0m[0m | time: 982.844s
[2K
| Adam | epoch: 001 | loss: 0.58908 - acc: 0.6787 -- iter: 224/550
[A[ATraining Step: 8  | total loss: [1m[32m0.62694[0m[0m | time: 1031.335s
[2K
| Adam | epoch: 001 | loss: 0.62694 - acc: 0.6836 -- iter: 256/550
[A[ATraining Step: 9  | total loss: [1m[32m0.64819[0m[0m | time: 1117.528s
[2K
| Adam | epoch: 001 | loss: 0.64819 - acc: 0.5864 -- iter: 288/550
[A[ATraining Step: 10  | total loss: [1m[32m0.67881[0m[0m | time: 1157.614s
[2K
| Adam | epoch: 001 | loss: 0.67881 - acc: 0.5588 -- iter: 320/550
[A[ATraining Step: 11  | total loss: [1m[32m0.63113[0m[0m | time: 1218.051s
[2K
| Adam | epoch: 001 | loss: 0.63113 - acc: 0.6494 -- iter: 352/550
[A[ATraining Step: 12  | total loss: [1m[32m0.60829[0m[0m | time: 1317.251s
[2K
| Adam | epoch: 001 | loss: 0.60829 - acc: 0.6665 -- iter: 384/550
[A[ATraining Step: 13  | total loss: [1m[32m0.56235[0m[0m | time: 1340.055s
[2K
| Adam | epoch: 001 | loss: 0.56235 - acc: 0.6755 -- iter: 416/550
[A[ATraining Step: 14  | total loss: [1m[32m0.60680[0m[0m | time: 1394.439s
[2K
| Adam | epoch: 001 | loss: 0.60680 - acc: 0.6421 -- iter: 448/550
[A[ATraining Step: 15  | total loss: [1m[32m0.61719[0m[0m | time: 1424.427s
[2K
| Adam | epoch: 001 | loss: 0.61719 - acc: 0.6598 -- iter: 480/550
[A[ATraining Step: 16  | total loss: [1m[32m0.57761[0m[0m | time: 1503.603s
[2K
| Adam | epoch: 001 | loss: 0.57761 - acc: 0.6819 -- iter: 512/550
[A[ATraining Step: 17  | total loss: [1m[32m0.56662[0m[0m | time: 1535.113s
[2K
| Adam | epoch: 001 | loss: 0.56662 - acc: 0.6952 -- iter: 544/550
[A[ATraining Step: 18  | total loss: [1m[32m0.55771[0m[0m | time: 1557.121s
[2K
| Adam | epoch: 001 | loss: 0.55771 - acc: 0.6925 | val_loss: 0.76637 - val_acc: 0.5698 -- iter: 550/550
--
Training Step: 19  | total loss: [1m[32m0.53660[0m[0m | time: 2.929s
[2K
| Adam | epoch: 002 | loss: 0.53660 - acc: 0.7395 -- iter: 032/550
[A[ATraining Step: 20  | total loss: [1m[32m0.41081[0m[0m | time: 54.058s
[2K
| Adam | epoch: 002 | loss: 0.41081 - acc: 0.8232 -- iter: 064/550
[A[ATraining Step: 21  | total loss: [1m[32m0.47490[0m[0m | time: 131.760s
[2K
| Adam | epoch: 002 | loss: 0.47490 - acc: 0.7714 -- iter: 096/550
[A[ATraining Step: 22  | total loss: [1m[32m0.51881[0m[0m | time: 234.921s
[2K
| Adam | epoch: 002 | loss: 0.51881 - acc: 0.7181 -- iter: 128/550
[A[ATraining Step: 23  | total loss: [1m[32m0.49262[0m[0m | time: 254.242s
[2K
| Adam | epoch: 002 | loss: 0.49262 - acc: 0.7455 -- iter: 160/550
[A[ATraining Step: 24  | total loss: [1m[32m0.49266[0m[0m | time: 265.337s
[2K
| Adam | epoch: 002 | loss: 0.49266 - acc: 0.7556 -- iter: 192/550
[A[ATraining Step: 25  | total loss: [1m[32m0.52158[0m[0m | time: 362.961s
[2K
| Adam | epoch: 002 | loss: 0.52158 - acc: 0.7370 -- iter: 224/550
[A[ATraining Step: 26  | total loss: [1m[32m0.46758[0m[0m | time: 397.823s
[2K
| Adam | epoch: 002 | loss: 0.46758 - acc: 0.7818 -- iter: 256/550
[A[ATraining Step: 27  | total loss: [1m[32m0.44903[0m[0m | time: 421.282s
[2K
| Adam | epoch: 002 | loss: 0.44903 - acc: 0.7977 -- iter: 288/550
[A[ATraining Step: 28  | total loss: [1m[32m0.42708[0m[0m | time: 480.943s
[2K
| Adam | epoch: 002 | loss: 0.42708 - acc: 0.8014 -- iter: 320/550
[A[ATraining Step: 29  | total loss: [1m[32m0.40806[0m[0m | time: 518.179s
[2K
| Adam | epoch: 002 | loss: 0.40806 - acc: 0.8117 -- iter: 352/550
[A[ATraining Step: 30  | total loss: [1m[32m0.35860[0m[0m | time: 529.166s
[2K
| Adam | epoch: 002 | loss: 0.35860 - acc: 0.8341 -- iter: 384/550
[A[ATraining Step: 31  | total loss: [1m[32m0.38949[0m[0m | time: 549.312s
[2K
| Adam | epoch: 002 | loss: 0.38949 - acc: 0.8291 -- iter: 416/550
[A[ATraining Step: 32  | total loss: [1m[32m0.38134[0m[0m | time: 583.683s
[2K
| Adam | epoch: 002 | loss: 0.38134 - acc: 0.8254 -- iter: 448/550
[A[ATraining Step: 33  | total loss: [1m[32m0.37394[0m[0m | time: 616.344s
[2K
| Adam | epoch: 002 | loss: 0.37394 - acc: 0.8363 -- iter: 480/550
[A[ATraining Step: 34  | total loss: [1m[32m0.34605[0m[0m | time: 642.138s
[2K
| Adam | epoch: 002 | loss: 0.34605 - acc: 0.8580 -- iter: 512/550
[A[ATraining Step: 35  | total loss: [1m[32m0.36864[0m[0m | time: 658.438s
[2K
| Adam | epoch: 002 | loss: 0.36864 - acc: 0.8288 -- iter: 544/550
[A[ATraining Step: 36  | total loss: [1m[32m0.37944[0m[0m | time: 682.715s
[2K
| Adam | epoch: 002 | loss: 0.37944 - acc: 0.8127 | val_loss: 2.10005 - val_acc: 0.5698 -- iter: 550/550
--
Training Step: 37  | total loss: [1m[32m0.36690[0m[0m | time: 2.838s
[2K
| Adam | epoch: 003 | loss: 0.36690 - acc: 0.8252 -- iter: 032/550
[A[ATraining Step: 38  | total loss: [1m[32m0.51537[0m[0m | time: 5.694s
[2K
| Adam | epoch: 003 | loss: 0.51537 - acc: 0.7615 -- iter: 064/550
[A[ATraining Step: 39  | total loss: [1m[32m0.61476[0m[0m | time: 17.236s
[2K
| Adam | epoch: 003 | loss: 0.61476 - acc: 0.6476 -- iter: 096/550
[A[ATraining Step: 40  | total loss: [1m[32m0.56457[0m[0m | time: 46.659s
[2K
| Adam | epoch: 003 | loss: 0.56457 - acc: 0.6844 -- iter: 128/550
[A[ATraining Step: 41  | total loss: [1m[32m0.57280[0m[0m | time: 91.959s
[2K
| Adam | epoch: 003 | loss: 0.57280 - acc: 0.6735 -- iter: 160/550
[A[ATraining Step: 42  | total loss: [1m[32m0.56021[0m[0m | time: 168.016s
[2K
| Adam | epoch: 003 | loss: 0.56021 - acc: 0.6704 -- iter: 192/550
[A[ATraining Step: 43  | total loss: [1m[32m0.50892[0m[0m | time: 198.036s
[2K
| Adam | epoch: 003 | loss: 0.50892 - acc: 0.7120 -- iter: 224/550
[A[ATraining Step: 44  | total loss: [1m[32m0.46251[0m[0m | time: 213.107s
[2K
| Adam | epoch: 003 | loss: 0.46251 - acc: 0.7456 -- iter: 256/550
[A[ATraining Step: 45  | total loss: [1m[32m0.43961[0m[0m | time: 223.683s
[2K
| Adam | epoch: 003 | loss: 0.43961 - acc: 0.7517 -- iter: 288/550
[A[ATraining Step: 46  | total loss: [1m[32m0.40361[0m[0m | time: 241.499s
[2K
| Adam | epoch: 003 | loss: 0.40361 - acc: 0.7879 -- iter: 320/550
[A[ATraining Step: 47  | total loss: [1m[32m0.36526[0m[0m | time: 276.954s
[2K
| Adam | epoch: 003 | loss: 0.36526 - acc: 0.8021 -- iter: 352/550
[A[ATraining Step: 48  | total loss: [1m[32m0.32482[0m[0m | time: 308.015s
[2K
| Adam | epoch: 003 | loss: 0.32482 - acc: 0.8189 -- iter: 384/550
[A[ATraining Step: 49  | total loss: [1m[32m0.30701[0m[0m | time: 332.470s
[2K
| Adam | epoch: 003 | loss: 0.30701 - acc: 0.8277 -- iter: 416/550
[A[ATraining Step: 50  | total loss: [1m[32m0.28573[0m[0m | time: 344.778s
[2K
| Adam | epoch: 003 | loss: 0.28573 - acc: 0.8496 -- iter: 448/550
[A[ATraining Step: 51  | total loss: [1m[32m0.26350[0m[0m | time: 359.557s
[2K
| Adam | epoch: 003 | loss: 0.26350 - acc: 0.8630 -- iter: 480/550
[A[ATraining Step: 52  | total loss: [1m[32m0.24344[0m[0m | time: 371.021s
[2K
| Adam | epoch: 003 | loss: 0.24344 - acc: 0.8789 -- iter: 512/550
[A[ATraining Step: 53  | total loss: [1m[32m0.25279[0m[0m | time: 396.667s
[2K
| Adam | epoch: 003 | loss: 0.25279 - acc: 0.8829 -- iter: 544/550
[A[ATraining Step: 54  | total loss: [1m[32m0.26879[0m[0m | time: 427.309s
[2K
| Adam | epoch: 003 | loss: 0.26879 - acc: 0.8818 | val_loss: 1.55810 - val_acc: 0.5872 -- iter: 550/550
--
Training Step: 55  | total loss: [1m[32m0.31040[0m[0m | time: 11.984s
[2K
| Adam | epoch: 004 | loss: 0.31040 - acc: 0.8674 -- iter: 032/550
[A[ATraining Step: 56  | total loss: [1m[32m0.32212[0m[0m | time: 14.741s
[2K
| Adam | epoch: 004 | loss: 0.32212 - acc: 0.8729 -- iter: 064/550
[A[ATraining Step: 57  | total loss: [1m[32m0.28231[0m[0m | time: 17.531s
[2K
| Adam | epoch: 004 | loss: 0.28231 - acc: 0.8905 -- iter: 096/550
[A[ATraining Step: 58  | total loss: [1m[32m0.24673[0m[0m | time: 42.845s
[2K
| Adam | epoch: 004 | loss: 0.24673 - acc: 0.9054 -- iter: 128/550
[A[ATraining Step: 59  | total loss: [1m[32m0.29058[0m[0m | time: 58.623s
[2K
| Adam | epoch: 004 | loss: 0.29058 - acc: 0.8929 -- iter: 160/550
[A[ATraining Step: 60  | total loss: [1m[32m0.29792[0m[0m | time: 72.344s
[2K
| Adam | epoch: 004 | loss: 0.29792 - acc: 0.8864 -- iter: 192/550
[A[ATraining Step: 61  | total loss: [1m[32m0.28847[0m[0m | time: 91.005s
[2K
| Adam | epoch: 004 | loss: 0.28847 - acc: 0.8931 -- iter: 224/550
[A[ATraining Step: 62  | total loss: [1m[32m0.26262[0m[0m | time: 151.156s
[2K
| Adam | epoch: 004 | loss: 0.26262 - acc: 0.9068 -- iter: 256/550
[A[ATraining Step: 63  | total loss: [1m[32m0.26717[0m[0m | time: 160.044s
[2K
| Adam | epoch: 004 | loss: 0.26717 - acc: 0.9028 -- iter: 288/550
[A[ATraining Step: 64  | total loss: [1m[32m0.24440[0m[0m | time: 168.497s
[2K
| Adam | epoch: 004 | loss: 0.24440 - acc: 0.9110 -- iter: 320/550
[A[ATraining Step: 65  | total loss: [1m[32m0.22801[0m[0m | time: 177.234s
[2K
| Adam | epoch: 004 | loss: 0.22801 - acc: 0.9143 -- iter: 352/550
[A[ATraining Step: 66  | total loss: [1m[32m0.21217[0m[0m | time: 185.714s
[2K
| Adam | epoch: 004 | loss: 0.21217 - acc: 0.9247 -- iter: 384/550
[A[ATraining Step: 67  | total loss: [1m[32m0.20707[0m[0m | time: 194.507s
[2K
| Adam | epoch: 004 | loss: 0.20707 - acc: 0.9263 -- iter: 416/550
[A[ATraining Step: 68  | total loss: [1m[32m0.19983[0m[0m | time: 203.203s
[2K
| Adam | epoch: 004 | loss: 0.19983 - acc: 0.9239 -- iter: 448/550
[A[ATraining Step: 69  | total loss: [1m[32m0.19072[0m[0m | time: 211.864s
[2K
| Adam | epoch: 004 | loss: 0.19072 - acc: 0.9255 -- iter: 480/550
[A[ATraining Step: 70  | total loss: [1m[32m0.18665[0m[0m | time: 220.789s
[2K
| Adam | epoch: 004 | loss: 0.18665 - acc: 0.9269 -- iter: 512/550
[A[ATraining Step: 71  | total loss: [1m[32m0.18567[0m[0m | time: 229.684s
[2K
| Adam | epoch: 004 | loss: 0.18567 - acc: 0.9245 -- iter: 544/550
[A[ATraining Step: 72  | total loss: [1m[32m0.26037[0m[0m | time: 246.871s
[2K
| Adam | epoch: 004 | loss: 0.26037 - acc: 0.9014 | val_loss: 2.22451 - val_acc: 0.4360 -- iter: 550/550
--
Training Step: 73  | total loss: [1m[32m0.24739[0m[0m | time: 8.724s
[2K
| Adam | epoch: 005 | loss: 0.24739 - acc: 0.9089 -- iter: 032/550
[A[ATraining Step: 74  | total loss: [1m[32m0.22231[0m[0m | time: 17.658s
[2K
| Adam | epoch: 005 | loss: 0.22231 - acc: 0.9189 -- iter: 064/550
[A[ATraining Step: 75  | total loss: [1m[32m0.21778[0m[0m | time: 19.957s
[2K
| Adam | epoch: 005 | loss: 0.21778 - acc: 0.9141 -- iter: 096/550
[A[ATraining Step: 76  | total loss: [1m[32m0.19600[0m[0m | time: 22.171s
[2K
| Adam | epoch: 005 | loss: 0.19600 - acc: 0.9233 -- iter: 128/550
[A[ATraining Step: 77  | total loss: [1m[32m0.17775[0m[0m | time: 31.077s
[2K
| Adam | epoch: 005 | loss: 0.17775 - acc: 0.9314 -- iter: 160/550
[A[ATraining Step: 78  | total loss: [1m[32m0.18210[0m[0m | time: 39.607s
[2K
| Adam | epoch: 005 | loss: 0.18210 - acc: 0.9288 -- iter: 192/550
[A[ATraining Step: 79  | total loss: [1m[32m0.20135[0m[0m | time: 48.469s
[2K
| Adam | epoch: 005 | loss: 0.20135 - acc: 0.9265 -- iter: 224/550
[A[ATraining Step: 80  | total loss: [1m[32m0.19101[0m[0m | time: 57.359s
[2K
| Adam | epoch: 005 | loss: 0.19101 - acc: 0.9276 -- iter: 256/550
[A[ATraining Step: 81  | total loss: [1m[32m0.22171[0m[0m | time: 65.912s
[2K
| Adam | epoch: 005 | loss: 0.22171 - acc: 0.9160 -- iter: 288/550
[A[ATraining Step: 82  | total loss: [1m[32m0.21570[0m[0m | time: 74.813s
[2K
| Adam | epoch: 005 | loss: 0.21570 - acc: 0.9150 -- iter: 320/550
[A[ATraining Step: 83  | total loss: [1m[32m0.21597[0m[0m | time: 83.687s
[2K
| Adam | epoch: 005 | loss: 0.21597 - acc: 0.9172 -- iter: 352/550
[A[ATraining Step: 84  | total loss: [1m[32m0.21464[0m[0m | time: 92.678s
[2K
| Adam | epoch: 005 | loss: 0.21464 - acc: 0.9161 -- iter: 384/550
[A[ATraining Step: 85  | total loss: [1m[32m0.20443[0m[0m | time: 101.464s
[2K
| Adam | epoch: 005 | loss: 0.20443 - acc: 0.9183 -- iter: 416/550
[A[ATraining Step: 86  | total loss: [1m[32m0.20855[0m[0m | time: 110.018s
[2K
| Adam | epoch: 005 | loss: 0.20855 - acc: 0.9108 -- iter: 448/550
[A[ATraining Step: 87  | total loss: [1m[32m0.20511[0m[0m | time: 118.542s
[2K
| Adam | epoch: 005 | loss: 0.20511 - acc: 0.9135 -- iter: 480/550
[A[ATraining Step: 88  | total loss: [1m[32m0.21682[0m[0m | time: 127.024s
[2K
| Adam | epoch: 005 | loss: 0.21682 - acc: 0.9034 -- iter: 512/550
[A[ATraining Step: 89  | total loss: [1m[32m0.21448[0m[0m | time: 135.691s
[2K
| Adam | epoch: 005 | loss: 0.21448 - acc: 0.9005 -- iter: 544/550
[A[ATraining Step: 90  | total loss: [1m[32m0.22283[0m[0m | time: 152.247s
[2K
| Adam | epoch: 005 | loss: 0.22283 - acc: 0.8980 | val_loss: 2.63594 - val_acc: 0.4360 -- iter: 550/550
--
Training Step: 91  | total loss: [1m[32m0.21430[0m[0m | time: 8.827s
[2K
| Adam | epoch: 006 | loss: 0.21430 - acc: 0.9051 -- iter: 032/550
[A[ATraining Step: 92  | total loss: [1m[32m0.21394[0m[0m | time: 17.318s
[2K
| Adam | epoch: 006 | loss: 0.21394 - acc: 0.9052 -- iter: 064/550
[A[ATraining Step: 93  | total loss: [1m[32m0.21186[0m[0m | time: 25.762s
[2K
| Adam | epoch: 006 | loss: 0.21186 - acc: 0.9022 -- iter: 096/550
[A[ATraining Step: 94  | total loss: [1m[32m0.19890[0m[0m | time: 28.004s
[2K
| Adam | epoch: 006 | loss: 0.19890 - acc: 0.9057 -- iter: 128/550
[A[ATraining Step: 95  | total loss: [1m[32m0.24036[0m[0m | time: 30.287s
[2K
| Adam | epoch: 006 | loss: 0.24036 - acc: 0.8818 -- iter: 160/550
[A[ATraining Step: 96  | total loss: [1m[32m0.26742[0m[0m | time: 38.724s
[2K
| Adam | epoch: 006 | loss: 0.26742 - acc: 0.8603 -- iter: 192/550
[A[ATraining Step: 97  | total loss: [1m[32m0.25380[0m[0m | time: 47.491s
[2K
| Adam | epoch: 006 | loss: 0.25380 - acc: 0.8680 -- iter: 224/550
[A[ATraining Step: 98  | total loss: [1m[32m0.24682[0m[0m | time: 55.869s
[2K
| Adam | epoch: 006 | loss: 0.24682 - acc: 0.8750 -- iter: 256/550
[A[ATraining Step: 99  | total loss: [1m[32m0.22823[0m[0m | time: 64.386s
[2K
| Adam | epoch: 006 | loss: 0.22823 - acc: 0.8875 -- iter: 288/550
[A[ATraining Step: 100  | total loss: [1m[32m0.25208[0m[0m | time: 73.085s
[2K
| Adam | epoch: 006 | loss: 0.25208 - acc: 0.8831 -- iter: 320/550
[A[ATraining Step: 101  | total loss: [1m[32m0.23422[0m[0m | time: 81.922s
[2K
| Adam | epoch: 006 | loss: 0.23422 - acc: 0.8917 -- iter: 352/550
[A[ATraining Step: 102  | total loss: [1m[32m0.21860[0m[0m | time: 90.274s
[2K
| Adam | epoch: 006 | loss: 0.21860 - acc: 0.8994 -- iter: 384/550
[A[ATraining Step: 103  | total loss: [1m[32m0.20250[0m[0m | time: 98.781s
[2K
| Adam | epoch: 006 | loss: 0.20250 - acc: 0.9063 -- iter: 416/550
[A[ATraining Step: 104  | total loss: [1m[32m0.19454[0m[0m | time: 107.273s
[2K
| Adam | epoch: 006 | loss: 0.19454 - acc: 0.9063 -- iter: 448/550
[A[ATraining Step: 105  | total loss: [1m[32m0.18070[0m[0m | time: 116.543s
[2K
| Adam | epoch: 006 | loss: 0.18070 - acc: 0.9157 -- iter: 480/550
[A[ATraining Step: 106  | total loss: [1m[32m0.18162[0m[0m | time: 125.131s
[2K
| Adam | epoch: 006 | loss: 0.18162 - acc: 0.9179 -- iter: 512/550
[A[ATraining Step: 107  | total loss: [1m[32m0.17569[0m[0m | time: 133.516s
[2K
| Adam | epoch: 006 | loss: 0.17569 - acc: 0.9229 -- iter: 544/550
[A[ATraining Step: 108  | total loss: [1m[32m0.16383[0m[0m | time: 150.419s
[2K
| Adam | epoch: 006 | loss: 0.16383 - acc: 0.9306 | val_loss: 7.81560 - val_acc: 0.5698 -- iter: 550/550
--
Training Step: 109  | total loss: [1m[32m0.15030[0m[0m | time: 8.863s
[2K
| Adam | epoch: 007 | loss: 0.15030 - acc: 0.9376 -- iter: 032/550
[A[ATraining Step: 110  | total loss: [1m[32m0.14265[0m[0m | time: 17.496s
[2K
| Adam | epoch: 007 | loss: 0.14265 - acc: 0.9407 -- iter: 064/550
[A[ATraining Step: 111  | total loss: [1m[32m0.14712[0m[0m | time: 26.325s
[2K
| Adam | epoch: 007 | loss: 0.14712 - acc: 0.9373 -- iter: 096/550
[A[ATraining Step: 112  | total loss: [1m[32m0.14282[0m[0m | time: 35.183s
[2K
| Adam | epoch: 007 | loss: 0.14282 - acc: 0.9342 -- iter: 128/550
[A[ATraining Step: 113  | total loss: [1m[32m0.14253[0m[0m | time: 37.449s
[2K
| Adam | epoch: 007 | loss: 0.14253 - acc: 0.9345 -- iter: 160/550
[A[ATraining Step: 114  | total loss: [1m[32m0.13750[0m[0m | time: 39.674s
[2K
| Adam | epoch: 007 | loss: 0.13750 - acc: 0.9410 -- iter: 192/550
[A[ATraining Step: 115  | total loss: [1m[32m0.12816[0m[0m | time: 48.212s
[2K
| Adam | epoch: 007 | loss: 0.12816 - acc: 0.9469 -- iter: 224/550
[A[ATraining Step: 116  | total loss: [1m[32m0.13253[0m[0m | time: 56.860s
[2K
| Adam | epoch: 007 | loss: 0.13253 - acc: 0.9491 -- iter: 256/550
[A[ATraining Step: 117  | total loss: [1m[32m0.12761[0m[0m | time: 65.367s
[2K
| Adam | epoch: 007 | loss: 0.12761 - acc: 0.9511 -- iter: 288/550
[A[ATraining Step: 118  | total loss: [1m[32m0.13280[0m[0m | time: 73.955s
[2K
| Adam | epoch: 007 | loss: 0.13280 - acc: 0.9435 -- iter: 320/550
[A[ATraining Step: 119  | total loss: [1m[32m0.13078[0m[0m | time: 82.491s
[2K
| Adam | epoch: 007 | loss: 0.13078 - acc: 0.9460 -- iter: 352/550
[A[ATraining Step: 120  | total loss: [1m[32m0.14749[0m[0m | time: 92.206s
[2K
| Adam | epoch: 007 | loss: 0.14749 - acc: 0.9452 -- iter: 384/550
[A[ATraining Step: 121  | total loss: [1m[32m0.14343[0m[0m | time: 100.521s
[2K
| Adam | epoch: 007 | loss: 0.14343 - acc: 0.9475 -- iter: 416/550
[A[ATraining Step: 122  | total loss: [1m[32m0.13199[0m[0m | time: 109.068s
[2K
| Adam | epoch: 007 | loss: 0.13199 - acc: 0.9528 -- iter: 448/550
[A[ATraining Step: 123  | total loss: [1m[32m0.12562[0m[0m | time: 117.625s
[2K
| Adam | epoch: 007 | loss: 0.12562 - acc: 0.9544 -- iter: 480/550
[A[ATraining Step: 124  | total loss: [1m[32m0.12152[0m[0m | time: 126.370s
[2K
| Adam | epoch: 007 | loss: 0.12152 - acc: 0.9558 -- iter: 512/550
[A[ATraining Step: 125  | total loss: [1m[32m0.12723[0m[0m | time: 135.120s
[2K
| Adam | epoch: 007 | loss: 0.12723 - acc: 0.9508 -- iter: 544/550
[A[ATraining Step: 126  | total loss: [1m[32m0.11733[0m[0m | time: 151.884s
[2K
| Adam | epoch: 007 | loss: 0.11733 - acc: 0.9558 | val_loss: 4.37178 - val_acc: 0.4302 -- iter: 550/550
--
Training Step: 127  | total loss: [1m[32m0.13148[0m[0m | time: 9.087s
[2K
| Adam | epoch: 008 | loss: 0.13148 - acc: 0.9508 -- iter: 032/550
[A[ATraining Step: 128  | total loss: [1m[32m0.13909[0m[0m | time: 17.616s
[2K
| Adam | epoch: 008 | loss: 0.13909 - acc: 0.9432 -- iter: 064/550
[A[ATraining Step: 129  | total loss: [1m[32m0.17326[0m[0m | time: 26.414s
[2K
| Adam | epoch: 008 | loss: 0.17326 - acc: 0.9364 -- iter: 096/550
[A[ATraining Step: 130  | total loss: [1m[32m0.16005[0m[0m | time: 35.008s
[2K
| Adam | epoch: 008 | loss: 0.16005 - acc: 0.9428 -- iter: 128/550
[A[ATraining Step: 131  | total loss: [1m[32m0.15009[0m[0m | time: 43.967s
[2K
| Adam | epoch: 008 | loss: 0.15009 - acc: 0.9485 -- iter: 160/550
[A[ATraining Step: 132  | total loss: [1m[32m0.14713[0m[0m | time: 46.336s
[2K
| Adam | epoch: 008 | loss: 0.14713 - acc: 0.9443 -- iter: 192/550
[A[ATraining Step: 133  | total loss: [1m[32m0.14047[0m[0m | time: 48.649s
[2K
| Adam | epoch: 008 | loss: 0.14047 - acc: 0.9498 -- iter: 224/550
[A[ATraining Step: 134  | total loss: [1m[32m0.12851[0m[0m | time: 57.482s
[2K
| Adam | epoch: 008 | loss: 0.12851 - acc: 0.9549 -- iter: 256/550
[A[ATraining Step: 135  | total loss: [1m[32m0.12460[0m[0m | time: 66.324s
[2K
| Adam | epoch: 008 | loss: 0.12460 - acc: 0.9562 -- iter: 288/550
[A[ATraining Step: 136  | total loss: [1m[32m0.12512[0m[0m | time: 75.357s
[2K
| Adam | epoch: 008 | loss: 0.12512 - acc: 0.9544 -- iter: 320/550
[A[ATraining Step: 137  | total loss: [1m[32m0.12082[0m[0m | time: 84.172s
[2K
| Adam | epoch: 008 | loss: 0.12082 - acc: 0.9558 -- iter: 352/550
[A[ATraining Step: 138  | total loss: [1m[32m0.11338[0m[0m | time: 92.918s
[2K
| Adam | epoch: 008 | loss: 0.11338 - acc: 0.9602 -- iter: 384/550
[A[ATraining Step: 139  | total loss: [1m[32m0.10919[0m[0m | time: 101.777s
[2K
| Adam | epoch: 008 | loss: 0.10919 - acc: 0.9611 -- iter: 416/550
[A[ATraining Step: 140  | total loss: [1m[32m0.10964[0m[0m | time: 110.419s
[2K
| Adam | epoch: 008 | loss: 0.10964 - acc: 0.9556 -- iter: 448/550
[A[ATraining Step: 141  | total loss: [1m[32m0.10154[0m[0m | time: 119.034s
[2K
| Adam | epoch: 008 | loss: 0.10154 - acc: 0.9600 -- iter: 480/550
[A[ATraining Step: 142  | total loss: [1m[32m0.11345[0m[0m | time: 127.778s
[2K
| Adam | epoch: 008 | loss: 0.11345 - acc: 0.9547 -- iter: 512/550
[A[ATraining Step: 143  | total loss: [1m[32m0.10961[0m[0m | time: 136.315s
[2K
| Adam | epoch: 008 | loss: 0.10961 - acc: 0.9561 -- iter: 544/550
[A[ATraining Step: 144  | total loss: [1m[32m0.10267[0m[0m | time: 153.903s
[2K
| Adam | epoch: 008 | loss: 0.10267 - acc: 0.9605 | val_loss: 1.56276 - val_acc: 0.5640 -- iter: 550/550
--
Training Step: 145  | total loss: [1m[32m0.10882[0m[0m | time: 8.729s
[2K
| Adam | epoch: 009 | loss: 0.10882 - acc: 0.9582 -- iter: 032/550
[A[ATraining Step: 146  | total loss: [1m[32m0.11317[0m[0m | time: 17.813s
[2K
| Adam | epoch: 009 | loss: 0.11317 - acc: 0.9498 -- iter: 064/550
[A[ATraining Step: 147  | total loss: [1m[32m0.10874[0m[0m | time: 26.437s
[2K
| Adam | epoch: 009 | loss: 0.10874 - acc: 0.9517 -- iter: 096/550
[A[ATraining Step: 148  | total loss: [1m[32m0.10419[0m[0m | time: 37.046s
[2K
| Adam | epoch: 009 | loss: 0.10419 - acc: 0.9534 -- iter: 128/550
[A[ATraining Step: 149  | total loss: [1m[32m0.10179[0m[0m | time: 45.520s
[2K
| Adam | epoch: 009 | loss: 0.10179 - acc: 0.9550 -- iter: 160/550
[A[ATraining Step: 150  | total loss: [1m[32m0.09618[0m[0m | time: 54.243s
[2K
| Adam | epoch: 009 | loss: 0.09618 - acc: 0.9563 -- iter: 192/550
[A[ATraining Step: 151  | total loss: [1m[32m0.09024[0m[0m | time: 56.511s
[2K
| Adam | epoch: 009 | loss: 0.09024 - acc: 0.9576 -- iter: 224/550
[A[ATraining Step: 152  | total loss: [1m[32m0.10300[0m[0m | time: 58.852s
[2K
| Adam | epoch: 009 | loss: 0.10300 - acc: 0.9618 -- iter: 256/550
[A[ATraining Step: 153  | total loss: [1m[32m0.09315[0m[0m | time: 67.697s
[2K
| Adam | epoch: 009 | loss: 0.09315 - acc: 0.9656 -- iter: 288/550
[A[ATraining Step: 154  | total loss: [1m[32m0.10964[0m[0m | time: 76.530s
[2K
| Adam | epoch: 009 | loss: 0.10964 - acc: 0.9628 -- iter: 320/550
[A[ATraining Step: 155  | total loss: [1m[32m0.11825[0m[0m | time: 85.703s
[2K
| Adam | epoch: 009 | loss: 0.11825 - acc: 0.9603 -- iter: 352/550
[A[ATraining Step: 156  | total loss: [1m[32m0.11641[0m[0m | time: 94.782s
[2K
| Adam | epoch: 009 | loss: 0.11641 - acc: 0.9580 -- iter: 384/550
[A[ATraining Step: 157  | total loss: [1m[32m0.10682[0m[0m | time: 103.477s
[2K
| Adam | epoch: 009 | loss: 0.10682 - acc: 0.9622 -- iter: 416/550
[A[ATraining Step: 158  | total loss: [1m[32m0.14804[0m[0m | time: 112.110s
[2K
| Adam | epoch: 009 | loss: 0.14804 - acc: 0.9535 -- iter: 448/550
[A[ATraining Step: 159  | total loss: [1m[32m0.13683[0m[0m | time: 120.831s
[2K
| Adam | epoch: 009 | loss: 0.13683 - acc: 0.9581 -- iter: 480/550
[A[ATraining Step: 160  | total loss: [1m[32m0.12426[0m[0m | time: 129.287s
[2K
| Adam | epoch: 009 | loss: 0.12426 - acc: 0.9623 -- iter: 512/550
[A[ATraining Step: 161  | total loss: [1m[32m0.11550[0m[0m | time: 137.943s
[2K
| Adam | epoch: 009 | loss: 0.11550 - acc: 0.9661 -- iter: 544/550
[A[ATraining Step: 162  | total loss: [1m[32m0.10898[0m[0m | time: 154.747s
[2K
| Adam | epoch: 009 | loss: 0.10898 - acc: 0.9664 | val_loss: 1.11313 - val_acc: 0.7209 -- iter: 550/550
--
Training Step: 163  | total loss: [1m[32m0.10230[0m[0m | time: 8.472s
[2K
| Adam | epoch: 010 | loss: 0.10230 - acc: 0.9666 -- iter: 032/550
[A[ATraining Step: 164  | total loss: [1m[32m0.09656[0m[0m | time: 17.150s
[2K
| Adam | epoch: 010 | loss: 0.09656 - acc: 0.9699 -- iter: 064/550
[A[ATraining Step: 165  | total loss: [1m[32m0.09941[0m[0m | time: 25.765s
[2K
| Adam | epoch: 010 | loss: 0.09941 - acc: 0.9667 -- iter: 096/550
[A[ATraining Step: 166  | total loss: [1m[32m0.09852[0m[0m | time: 34.598s
[2K
| Adam | epoch: 010 | loss: 0.09852 - acc: 0.9669 -- iter: 128/550
[A[ATraining Step: 167  | total loss: [1m[32m0.09055[0m[0m | time: 43.444s
[2K
| Adam | epoch: 010 | loss: 0.09055 - acc: 0.9702 -- iter: 160/550
[A[ATraining Step: 168  | total loss: [1m[32m0.10702[0m[0m | time: 52.096s
[2K
| Adam | epoch: 010 | loss: 0.10702 - acc: 0.9607 -- iter: 192/550
[A[ATraining Step: 169  | total loss: [1m[32m0.10029[0m[0m | time: 60.748s
[2K
| Adam | epoch: 010 | loss: 0.10029 - acc: 0.9615 -- iter: 224/550
[A[ATraining Step: 170  | total loss: [1m[32m0.09231[0m[0m | time: 63.024s
[2K
| Adam | epoch: 010 | loss: 0.09231 - acc: 0.9653 -- iter: 256/550
[A[ATraining Step: 171  | total loss: [1m[32m0.08410[0m[0m | time: 65.248s
[2K
| Adam | epoch: 010 | loss: 0.08410 - acc: 0.9688 -- iter: 288/550
[A[ATraining Step: 172  | total loss: [1m[32m0.07666[0m[0m | time: 73.835s
[2K
| Adam | epoch: 010 | loss: 0.07666 - acc: 0.9719 -- iter: 320/550
[A[ATraining Step: 173  | total loss: [1m[32m0.08456[0m[0m | time: 82.954s
[2K
| Adam | epoch: 010 | loss: 0.08456 - acc: 0.9654 -- iter: 352/550
[A[ATraining Step: 174  | total loss: [1m[32m0.08327[0m[0m | time: 91.821s
[2K
| Adam | epoch: 010 | loss: 0.08327 - acc: 0.9657 -- iter: 384/550
[A[ATraining Step: 175  | total loss: [1m[32m0.11321[0m[0m | time: 100.767s
[2K
| Adam | epoch: 010 | loss: 0.11321 - acc: 0.9566 -- iter: 416/550
[A[ATraining Step: 176  | total loss: [1m[32m0.10364[0m[0m | time: 109.491s
[2K
| Adam | epoch: 010 | loss: 0.10364 - acc: 0.9610 -- iter: 448/550
[A[ATraining Step: 177  | total loss: [1m[32m0.09423[0m[0m | time: 117.944s
[2K
| Adam | epoch: 010 | loss: 0.09423 - acc: 0.9649 -- iter: 480/550
[A[ATraining Step: 178  | total loss: [1m[32m0.08730[0m[0m | time: 126.541s
[2K
| Adam | epoch: 010 | loss: 0.08730 - acc: 0.9684 -- iter: 512/550
[A[ATraining Step: 179  | total loss: [1m[32m0.08056[0m[0m | time: 136.416s
[2K
| Adam | epoch: 010 | loss: 0.08056 - acc: 0.9715 -- iter: 544/550
[A[ATraining Step: 180  | total loss: [1m[32m0.07335[0m[0m | time: 153.221s
[2K
| Adam | epoch: 010 | loss: 0.07335 - acc: 0.9744 | val_loss: 0.55380 - val_acc: 0.8314 -- iter: 550/550
--
Training Step: 181  | total loss: [1m[32m0.07460[0m[0m | time: 8.644s
[2K
| Adam | epoch: 011 | loss: 0.07460 - acc: 0.9707 -- iter: 032/550
[A[ATraining Step: 182  | total loss: [1m[32m0.07894[0m[0m | time: 17.273s
[2K
| Adam | epoch: 011 | loss: 0.07894 - acc: 0.9705 -- iter: 064/550
[A[ATraining Step: 183  | total loss: [1m[32m0.07360[0m[0m | time: 25.638s
[2K
| Adam | epoch: 011 | loss: 0.07360 - acc: 0.9735 -- iter: 096/550
[A[ATraining Step: 184  | total loss: [1m[32m0.07510[0m[0m | time: 34.450s
[2K
| Adam | epoch: 011 | loss: 0.07510 - acc: 0.9699 -- iter: 128/550
[A[ATraining Step: 185  | total loss: [1m[32m0.08165[0m[0m | time: 43.244s
[2K
| Adam | epoch: 011 | loss: 0.08165 - acc: 0.9635 -- iter: 160/550
[A[ATraining Step: 186  | total loss: [1m[32m0.09542[0m[0m | time: 51.926s
[2K
| Adam | epoch: 011 | loss: 0.09542 - acc: 0.9609 -- iter: 192/550
[A[ATraining Step: 187  | total loss: [1m[32m0.09268[0m[0m | time: 60.511s
[2K
| Adam | epoch: 011 | loss: 0.09268 - acc: 0.9617 -- iter: 224/550
[A[ATraining Step: 188  | total loss: [1m[32m0.08673[0m[0m | time: 69.194s
[2K
| Adam | epoch: 011 | loss: 0.08673 - acc: 0.9624 -- iter: 256/550
[A[ATraining Step: 189  | total loss: [1m[32m0.08724[0m[0m | time: 71.446s
[2K
| Adam | epoch: 011 | loss: 0.08724 - acc: 0.9630 -- iter: 288/550
[A[ATraining Step: 190  | total loss: [1m[32m0.09409[0m[0m | time: 73.697s
[2K
| Adam | epoch: 011 | loss: 0.09409 - acc: 0.9667 -- iter: 320/550
[A[ATraining Step: 191  | total loss: [1m[32m0.08608[0m[0m | time: 82.537s
[2K
| Adam | epoch: 011 | loss: 0.08608 - acc: 0.9701 -- iter: 352/550
[A[ATraining Step: 192  | total loss: [1m[32m0.09105[0m[0m | time: 91.118s
[2K
| Adam | epoch: 011 | loss: 0.09105 - acc: 0.9637 -- iter: 384/550
[A[ATraining Step: 193  | total loss: [1m[32m0.09750[0m[0m | time: 99.570s
[2K
| Adam | epoch: 011 | loss: 0.09750 - acc: 0.9611 -- iter: 416/550
[A[ATraining Step: 194  | total loss: [1m[32m0.09879[0m[0m | time: 108.037s
[2K
| Adam | epoch: 011 | loss: 0.09879 - acc: 0.9587 -- iter: 448/550
[A[ATraining Step: 195  | total loss: [1m[32m0.09941[0m[0m | time: 116.607s
[2K
| Adam | epoch: 011 | loss: 0.09941 - acc: 0.9566 -- iter: 480/550
[A[ATraining Step: 196  | total loss: [1m[32m0.09003[0m[0m | time: 125.020s
[2K
| Adam | epoch: 011 | loss: 0.09003 - acc: 0.9609 -- iter: 512/550
[A[ATraining Step: 197  | total loss: [1m[32m0.08433[0m[0m | time: 133.514s
[2K
| Adam | epoch: 011 | loss: 0.08433 - acc: 0.9617 -- iter: 544/550
[A[ATraining Step: 198  | total loss: [1m[32m0.07916[0m[0m | time: 150.291s
[2K
| Adam | epoch: 011 | loss: 0.07916 - acc: 0.9655 | val_loss: 1.06580 - val_acc: 0.6919 -- iter: 550/550
--
Training Step: 199  | total loss: [1m[32m0.07665[0m[0m | time: 8.521s
[2K
| Adam | epoch: 012 | loss: 0.07665 - acc: 0.9659 -- iter: 032/550
[A[ATraining Step: 200  | total loss: [1m[32m0.10071[0m[0m | time: 25.213s
[2K
| Adam | epoch: 012 | loss: 0.10071 - acc: 0.9599 | val_loss: 1.48398 - val_acc: 0.6395 -- iter: 064/550
--
Training Step: 201  | total loss: [1m[32m0.09335[0m[0m | time: 33.615s
[2K
| Adam | epoch: 012 | loss: 0.09335 - acc: 0.9639 -- iter: 096/550
[A[ATraining Step: 202  | total loss: [1m[32m0.09332[0m[0m | time: 41.978s
[2K
| Adam | epoch: 012 | loss: 0.09332 - acc: 0.9581 -- iter: 128/550
[A[ATraining Step: 203  | total loss: [1m[32m0.08844[0m[0m | time: 50.575s
[2K
| Adam | epoch: 012 | loss: 0.08844 - acc: 0.9592 -- iter: 160/550
[A[ATraining Step: 204  | total loss: [1m[32m0.09490[0m[0m | time: 59.086s
[2K
| Adam | epoch: 012 | loss: 0.09490 - acc: 0.9602 -- iter: 192/550
[A[ATraining Step: 205  | total loss: [1m[32m0.08804[0m[0m | time: 67.540s
[2K
| Adam | epoch: 012 | loss: 0.08804 - acc: 0.9641 -- iter: 224/550
[A[ATraining Step: 206  | total loss: [1m[32m0.08271[0m[0m | time: 75.808s
[2K
| Adam | epoch: 012 | loss: 0.08271 - acc: 0.9677 -- iter: 256/550
[A[ATraining Step: 207  | total loss: [1m[32m0.08360[0m[0m | time: 84.325s
[2K
| Adam | epoch: 012 | loss: 0.08360 - acc: 0.9678 -- iter: 288/550
[A[ATraining Step: 208  | total loss: [1m[32m0.09579[0m[0m | time: 86.510s
[2K
| Adam | epoch: 012 | loss: 0.09579 - acc: 0.9585 -- iter: 320/550
[A[ATraining Step: 209  | total loss: [1m[32m0.08658[0m[0m | time: 88.767s
[2K
| Adam | epoch: 012 | loss: 0.08658 - acc: 0.9627 -- iter: 352/550
[A[ATraining Step: 210  | total loss: [1m[32m0.07808[0m[0m | time: 97.271s
[2K
| Adam | epoch: 012 | loss: 0.07808 - acc: 0.9664 -- iter: 384/550
[A[ATraining Step: 211  | total loss: [1m[32m0.07243[0m[0m | time: 105.766s
[2K
| Adam | epoch: 012 | loss: 0.07243 - acc: 0.9698 -- iter: 416/550
[A[ATraining Step: 212  | total loss: [1m[32m0.07028[0m[0m | time: 114.164s
[2K
| Adam | epoch: 012 | loss: 0.07028 - acc: 0.9697 -- iter: 448/550
[A[ATraining Step: 213  | total loss: [1m[32m0.08235[0m[0m | time: 122.686s
[2K
| Adam | epoch: 012 | loss: 0.08235 - acc: 0.9665 -- iter: 480/550
[A[ATraining Step: 214  | total loss: [1m[32m0.07894[0m[0m | time: 131.016s
[2K
| Adam | epoch: 012 | loss: 0.07894 - acc: 0.9667 -- iter: 512/550
[A[ATraining Step: 215  | total loss: [1m[32m0.09330[0m[0m | time: 139.469s
[2K
| Adam | epoch: 012 | loss: 0.09330 - acc: 0.9669 -- iter: 544/550
[A[ATraining Step: 216  | total loss: [1m[32m0.08809[0m[0m | time: 156.095s
[2K
| Adam | epoch: 012 | loss: 0.08809 - acc: 0.9671 | val_loss: 0.89939 - val_acc: 0.7849 -- iter: 550/550
--
Training Step: 217  | total loss: [1m[32m0.08504[0m[0m | time: 8.544s
[2K
| Adam | epoch: 013 | loss: 0.08504 - acc: 0.9672 -- iter: 032/550
[A[ATraining Step: 218  | total loss: [1m[32m0.12676[0m[0m | time: 17.071s
[2K
| Adam | epoch: 013 | loss: 0.12676 - acc: 0.9611 -- iter: 064/550
[A[ATraining Step: 219  | total loss: [1m[32m0.12846[0m[0m | time: 25.744s
[2K
| Adam | epoch: 013 | loss: 0.12846 - acc: 0.9588 -- iter: 096/550
[A[ATraining Step: 220  | total loss: [1m[32m0.11924[0m[0m | time: 34.178s
[2K
| Adam | epoch: 013 | loss: 0.11924 - acc: 0.9629 -- iter: 128/550
[A[ATraining Step: 221  | total loss: [1m[32m0.10804[0m[0m | time: 42.528s
[2K
| Adam | epoch: 013 | loss: 0.10804 - acc: 0.9666 -- iter: 160/550
[A[ATraining Step: 222  | total loss: [1m[32m0.09846[0m[0m | time: 51.215s
[2K
| Adam | epoch: 013 | loss: 0.09846 - acc: 0.9700 -- iter: 192/550
[A[ATraining Step: 223  | total loss: [1m[32m0.08992[0m[0m | time: 59.633s
[2K
| Adam | epoch: 013 | loss: 0.08992 - acc: 0.9730 -- iter: 224/550
[A[ATraining Step: 224  | total loss: [1m[32m0.08290[0m[0m | time: 69.517s
[2K
| Adam | epoch: 013 | loss: 0.08290 - acc: 0.9757 -- iter: 256/550
[A[ATraining Step: 225  | total loss: [1m[32m0.07874[0m[0m | time: 77.909s
[2K
| Adam | epoch: 013 | loss: 0.07874 - acc: 0.9781 -- iter: 288/550
[A[ATraining Step: 226  | total loss: [1m[32m0.07859[0m[0m | time: 86.428s
[2K
| Adam | epoch: 013 | loss: 0.07859 - acc: 0.9772 -- iter: 320/550
[A[ATraining Step: 227  | total loss: [1m[32m0.07184[0m[0m | time: 88.679s
[2K
| Adam | epoch: 013 | loss: 0.07184 - acc: 0.9794 -- iter: 352/550
[A[ATraining Step: 228  | total loss: [1m[32m0.06739[0m[0m | time: 90.908s
[2K
| Adam | epoch: 013 | loss: 0.06739 - acc: 0.9815 -- iter: 384/550
[A[ATraining Step: 229  | total loss: [1m[32m0.06180[0m[0m | time: 99.412s
[2K
| Adam | epoch: 013 | loss: 0.06180 - acc: 0.9834 -- iter: 416/550
[A[ATraining Step: 230  | total loss: [1m[32m0.06046[0m[0m | time: 108.358s
[2K
| Adam | epoch: 013 | loss: 0.06046 - acc: 0.9819 -- iter: 448/550
[A[ATraining Step: 231  | total loss: [1m[32m0.06581[0m[0m | time: 116.899s
[2K
| Adam | epoch: 013 | loss: 0.06581 - acc: 0.9806 -- iter: 480/550
[A[ATraining Step: 232  | total loss: [1m[32m0.06221[0m[0m | time: 125.338s
[2K
| Adam | epoch: 013 | loss: 0.06221 - acc: 0.9825 -- iter: 512/550
[A[ATraining Step: 233  | total loss: [1m[32m0.05653[0m[0m | time: 133.988s
[2K
| Adam | epoch: 013 | loss: 0.05653 - acc: 0.9843 -- iter: 544/550
[A[ATraining Step: 234  | total loss: [1m[32m0.12932[0m[0m | time: 150.701s
[2K
| Adam | epoch: 013 | loss: 0.12932 - acc: 0.9796 | val_loss: 2.94293 - val_acc: 0.4884 -- iter: 550/550
--
Training Step: 235  | total loss: [1m[32m0.11807[0m[0m | time: 8.532s
[2K
| Adam | epoch: 014 | loss: 0.11807 - acc: 0.9816 -- iter: 032/550
[A[ATraining Step: 236  | total loss: [1m[32m0.11462[0m[0m | time: 17.129s
[2K
| Adam | epoch: 014 | loss: 0.11462 - acc: 0.9803 -- iter: 064/550
[A[ATraining Step: 237  | total loss: [1m[32m0.10418[0m[0m | time: 25.741s
[2K
| Adam | epoch: 014 | loss: 0.10418 - acc: 0.9823 -- iter: 096/550
[A[ATraining Step: 238  | total loss: [1m[32m0.09559[0m[0m | time: 34.237s
[2K
| Adam | epoch: 014 | loss: 0.09559 - acc: 0.9841 -- iter: 128/550
[A[ATraining Step: 239  | total loss: [1m[32m0.08849[0m[0m | time: 42.823s
[2K
| Adam | epoch: 014 | loss: 0.08849 - acc: 0.9857 -- iter: 160/550
[A[ATraining Step: 240  | total loss: [1m[32m0.08273[0m[0m | time: 51.534s
[2K
| Adam | epoch: 014 | loss: 0.08273 - acc: 0.9871 -- iter: 192/550
[A[ATraining Step: 241  | total loss: [1m[32m0.08203[0m[0m | time: 60.142s
[2K
| Adam | epoch: 014 | loss: 0.08203 - acc: 0.9853 -- iter: 224/550
[A[ATraining Step: 242  | total loss: [1m[32m0.07603[0m[0m | time: 68.890s
[2K
| Adam | epoch: 014 | loss: 0.07603 - acc: 0.9867 -- iter: 256/550
[A[ATraining Step: 243  | total loss: [1m[32m0.07219[0m[0m | time: 77.325s
[2K
| Adam | epoch: 014 | loss: 0.07219 - acc: 0.9881 -- iter: 288/550
[A[ATraining Step: 244  | total loss: [1m[32m0.06657[0m[0m | time: 85.761s
[2K
| Adam | epoch: 014 | loss: 0.06657 - acc: 0.9893 -- iter: 320/550
[A[ATraining Step: 245  | total loss: [1m[32m0.06097[0m[0m | time: 94.517s
[2K
| Adam | epoch: 014 | loss: 0.06097 - acc: 0.9903 -- iter: 352/550
[A[ATraining Step: 246  | total loss: [1m[32m0.05910[0m[0m | time: 96.745s
[2K
| Adam | epoch: 014 | loss: 0.05910 - acc: 0.9882 -- iter: 384/550
[A[ATraining Step: 247  | total loss: [1m[32m0.05501[0m[0m | time: 99.007s
[2K
| Adam | epoch: 014 | loss: 0.05501 - acc: 0.9894 -- iter: 416/550
[A[ATraining Step: 248  | total loss: [1m[32m0.04991[0m[0m | time: 107.440s
[2K
| Adam | epoch: 014 | loss: 0.04991 - acc: 0.9904 -- iter: 448/550
[A[ATraining Step: 249  | total loss: [1m[32m0.07649[0m[0m | time: 115.808s
[2K
| Adam | epoch: 014 | loss: 0.07649 - acc: 0.9851 -- iter: 480/550
[A[ATraining Step: 250  | total loss: [1m[32m0.07686[0m[0m | time: 124.523s
[2K
| Adam | epoch: 014 | loss: 0.07686 - acc: 0.9835 -- iter: 512/550
[A[ATraining Step: 251  | total loss: [1m[32m0.07010[0m[0m | time: 132.907s
[2K
| Adam | epoch: 014 | loss: 0.07010 - acc: 0.9851 -- iter: 544/550
[A[ATraining Step: 252  | total loss: [1m[32m0.07161[0m[0m | time: 149.784s
[2K
| Adam | epoch: 014 | loss: 0.07161 - acc: 0.9835 | val_loss: 1.93253 - val_acc: 0.6395 -- iter: 550/550
--
Training Step: 253  | total loss: [1m[32m0.14135[0m[0m | time: 8.701s
[2K
| Adam | epoch: 015 | loss: 0.14135 - acc: 0.9758 -- iter: 032/550
[A[ATraining Step: 254  | total loss: [1m[32m0.13200[0m[0m | time: 17.209s
[2K
| Adam | epoch: 015 | loss: 0.13200 - acc: 0.9751 -- iter: 064/550
[A[ATraining Step: 255  | total loss: [1m[32m0.11903[0m[0m | time: 25.768s
[2K
| Adam | epoch: 015 | loss: 0.11903 - acc: 0.9776 -- iter: 096/550
[A[ATraining Step: 256  | total loss: [1m[32m0.10886[0m[0m | time: 34.307s
[2K
| Adam | epoch: 015 | loss: 0.10886 - acc: 0.9798 -- iter: 128/550
[A[ATraining Step: 257  | total loss: [1m[32m0.10022[0m[0m | time: 57.443s
[2K
| Adam | epoch: 015 | loss: 0.10022 - acc: 0.9818 -- iter: 160/550
[A[ATraining Step: 258  | total loss: [1m[32m0.11337[0m[0m | time: 66.011s
[2K
| Adam | epoch: 015 | loss: 0.11337 - acc: 0.9774 -- iter: 192/550
[A[ATraining Step: 259  | total loss: [1m[32m0.10289[0m[0m | time: 74.588s
[2K
| Adam | epoch: 015 | loss: 0.10289 - acc: 0.9797 -- iter: 224/550
[A[ATraining Step: 260  | total loss: [1m[32m0.10064[0m[0m | time: 83.528s
[2K
| Adam | epoch: 015 | loss: 0.10064 - acc: 0.9786 -- iter: 256/550
[A[ATraining Step: 261  | total loss: [1m[32m0.09374[0m[0m | time: 92.217s
[2K
| Adam | epoch: 015 | loss: 0.09374 - acc: 0.9807 -- iter: 288/550
[A[ATraining Step: 262  | total loss: [1m[32m0.08935[0m[0m | time: 100.877s
[2K
| Adam | epoch: 015 | loss: 0.08935 - acc: 0.9826 -- iter: 320/550
[A[ATraining Step: 263  | total loss: [1m[32m0.09709[0m[0m | time: 109.450s
[2K
| Adam | epoch: 015 | loss: 0.09709 - acc: 0.9750 -- iter: 352/550
[A[ATraining Step: 264  | total loss: [1m[32m0.08998[0m[0m | time: 117.945s
[2K
| Adam | epoch: 015 | loss: 0.08998 - acc: 0.9775 -- iter: 384/550
[A[ATraining Step: 265  | total loss: [1m[32m0.08492[0m[0m | time: 120.195s
[2K
| Adam | epoch: 015 | loss: 0.08492 - acc: 0.9798 -- iter: 416/550
[A[ATraining Step: 266  | total loss: [1m[32m0.08175[0m[0m | time: 122.429s
[2K
| Adam | epoch: 015 | loss: 0.08175 - acc: 0.9818 -- iter: 448/550
[A[ATraining Step: 267  | total loss: [1m[32m0.07409[0m[0m | time: 130.819s
[2K
| Adam | epoch: 015 | loss: 0.07409 - acc: 0.9836 -- iter: 480/550
[A[ATraining Step: 268  | total loss: [1m[32m0.07768[0m[0m | time: 139.747s
[2K
| Adam | epoch: 015 | loss: 0.07768 - acc: 0.9790 -- iter: 512/550
[A[ATraining Step: 269  | total loss: [1m[32m0.07162[0m[0m | time: 148.517s
[2K
| Adam | epoch: 015 | loss: 0.07162 - acc: 0.9811 -- iter: 544/550
[A[ATraining Step: 270  | total loss: [1m[32m0.06991[0m[0m | time: 165.322s
[2K
| Adam | epoch: 015 | loss: 0.06991 - acc: 0.9830 | val_loss: 0.92399 - val_acc: 0.7326 -- iter: 550/550
--
Validation AUC:0.9373965802537231
Validation AUPRC:0.9252064222543249
Test AUC:0.923573883161512
Test AUPRC:0.8833493716479347
BestTestF1Score	0.84	0.71	0.85	0.82	0.85	64	14	83	11	0.01
BestTestMCCScore	0.82	0.69	0.85	0.87	0.77	58	9	88	17	0.05
BestTestAccuracyScore	0.82	0.69	0.85	0.87	0.77	58	9	88	17	0.05
BestValidationF1Score	0.84	0.73	0.87	0.87	0.81	60	9	89	14	0.01
BestValidationMCC	0.83	0.73	0.87	0.9	0.77	57	6	92	17	0.05
BestValidationAccuracy	0.83	0.73	0.87	0.9	0.77	57	6	92	17	0.05
TestPredictions (Threshold:0.05)
CHEMBL384318,TP,ACT,0.3100000023841858	CHEMBL122404,TP,ACT,0.30000001192092896	CHEMBL209121,TN,INACT,0.009999999776482582	CHEMBL833,FN,ACT,0.019999999552965164	CHEMBL328377,TP,ACT,0.949999988079071	CHEMBL283535,TN,INACT,0.0	CHEMBL295186,TP,ACT,0.5899999737739563	CHEMBL306792,TP,ACT,0.6600000262260437	CHEMBL72738,TN,INACT,0.0	CHEMBL3392246,TP,ACT,0.9599999785423279	CHEMBL322678,TN,INACT,0.0	CHEMBL396013,TP,ACT,0.1599999964237213	CHEMBL353304,TN,INACT,0.0	CHEMBL73272,TN,INACT,0.0	CHEMBL323517,TN,INACT,0.0	CHEMBL241100,TN,INACT,0.0	CHEMBL343969,TN,INACT,0.0	CHEMBL328476,TN,INACT,0.0	CHEMBL297473,TN,INACT,0.0	CHEMBL296291,TN,INACT,0.0	CHEMBL10316,TP,ACT,0.8700000047683716	CHEMBL328114,TP,ACT,1.0	CHEMBL1255770,TP,ACT,0.8799999952316284	CHEMBL2203713,TN,INACT,0.009999999776482582	CHEMBL900,TP,ACT,0.5199999809265137	CHEMBL3343700,TP,ACT,0.5400000214576721	CHEMBL221753,TP,ACT,0.44999998807907104	CHEMBL223829,TP,ACT,0.09000000357627869	CHEMBL216072,FN,ACT,0.029999999329447746	CHEMBL453,TN,INACT,0.0	CHEMBL357983,TN,INACT,0.0	CHEMBL72147,FN,ACT,0.0	CHEMBL168632,TN,INACT,0.009999999776482582	CHEMBL217366,FN,ACT,0.03999999910593033	CHEMBL477608,TP,ACT,0.5	CHEMBL9666,TN,INACT,0.0	CHEMBL221523,TP,ACT,0.27000001072883606	CHEMBL247664,TP,ACT,0.11999999731779099	CHEMBL222928,FN,ACT,0.009999999776482582	CHEMBL297215,TN,INACT,0.0	CHEMBL175698,TN,INACT,0.0	CHEMBL1916635,TN,INACT,0.0	CHEMBL279225,FP,INACT,0.09000000357627869	CHEMBL202861,TN,INACT,0.019999999552965164	CHEMBL523048,TP,ACT,0.05000000074505806	CHEMBL163190,TP,ACT,0.9900000095367432	CHEMBL78669,TN,INACT,0.0	CHEMBL284470,TP,ACT,0.9700000286102295	CHEMBL3780248,TN,INACT,0.0	CHEMBL302359,TN,INACT,0.0	CHEMBL155866,TP,ACT,0.3199999928474426	CHEMBL516,TP,ACT,0.05000000074505806	CHEMBL432974,TN,INACT,0.0	CHEMBL91956,TP,ACT,0.10999999940395355	CHEMBL353972,TP,ACT,1.0	CHEMBL553155,TN,INACT,0.0	CHEMBL305660,TP,ACT,0.9100000262260437	CHEMBL302829,TN,INACT,0.0	CHEMBL44463,TN,INACT,0.0	CHEMBL310335,TP,ACT,0.8899999856948853	CHEMBL926,FN,ACT,0.0	CHEMBL320736,TP,ACT,0.9800000190734863	CHEMBL1276140,TP,ACT,0.20000000298023224	CHEMBL60401,TN,INACT,0.0	CHEMBL320124,TN,INACT,0.0	CHEMBL844,TP,ACT,0.2199999988079071	CHEMBL460470,TN,INACT,0.0	CHEMBL17860,TP,ACT,0.09000000357627869	CHEMBL1276218,TP,ACT,0.12999999523162842	CHEMBL170335,TN,INACT,0.0	CHEMBL279520,TN,INACT,0.0	CHEMBL179648,TP,ACT,0.8600000143051147	CHEMBL723,FN,ACT,0.019999999552965164	CHEMBL268217,TP,ACT,0.5699999928474426	CHEMBL404557,TN,INACT,0.0	CHEMBL162490,TP,ACT,0.7599999904632568	CHEMBL83,FN,ACT,0.0	CHEMBL181035,TN,INACT,0.0	CHEMBL252232,TN,INACT,0.0	CHEMBL1956191,TP,ACT,0.6299999952316284	CHEMBL1219,TP,ACT,0.05999999865889549	CHEMBL415879,TN,INACT,0.0	CHEMBL76779,TN,INACT,0.0	CHEMBL142822,TN,INACT,0.03999999910593033	CHEMBL295001,TP,ACT,0.9800000190734863	CHEMBL307034,TN,INACT,0.0	CHEMBL63937,TN,INACT,0.0	CHEMBL90419,TP,ACT,1.0	CHEMBL1956201,FN,ACT,0.0	CHEMBL80945,TN,INACT,0.0	CHEMBL233552,FP,INACT,0.5400000214576721	CHEMBL217278,FN,ACT,0.03999999910593033	CHEMBL315974,TN,INACT,0.0	CHEMBL194849,TP,ACT,0.7099999785423279	CHEMBL241279,FP,INACT,0.3499999940395355	CHEMBL76576,TN,INACT,0.0	CHEMBL3354069,FP,INACT,1.0	CHEMBL310427,FP,INACT,0.09000000357627869	CHEMBL451335,TN,INACT,0.0	CHEMBL3752900,TP,ACT,0.3100000023841858	CHEMBL391191,TN,INACT,0.0	CHEMBL140984,TN,INACT,0.0	CHEMBL294349,TN,INACT,0.0	CHEMBL320254,TN,INACT,0.0	CHEMBL195893,FP,INACT,0.05000000074505806	CHEMBL99331,TN,INACT,0.0	CHEMBL306645,TN,INACT,0.009999999776482582	CHEMBL227378,TN,INACT,0.0	CHEMBL59733,TN,INACT,0.0	CHEMBL49395,TP,ACT,0.4300000071525574	CHEMBL505086,TN,INACT,0.019999999552965164	CHEMBL2058633,FN,ACT,0.019999999552965164	CHEMBL422701,TN,INACT,0.0	CHEMBL102390,TN,INACT,0.0	CHEMBL114478,FP,INACT,0.4699999988079071	CHEMBL12131,FN,ACT,0.0	CHEMBL327775,TP,ACT,0.9800000190734863	CHEMBL2042551,TN,INACT,0.0	CHEMBL545363,TN,INACT,0.0	CHEMBL527880,TN,INACT,0.0	CHEMBL169675,TN,INACT,0.0	CHEMBL319910,TN,INACT,0.029999999329447746	CHEMBL162232,TP,ACT,0.33000001311302185	CHEMBL216399,TP,ACT,0.7799999713897705	CHEMBL2431280,FN,ACT,0.009999999776482582	CHEMBL44262,TN,INACT,0.0	CHEMBL246228,FN,ACT,0.009999999776482582	CHEMBL307659,TN,INACT,0.0	CHEMBL114074,TN,INACT,0.0	CHEMBL392991,TP,ACT,0.36000001430511475	CHEMBL91157,TP,ACT,1.0	CHEMBL72841,TN,INACT,0.0	CHEMBL59,TN,INACT,0.009999999776482582	CHEMBL442045,TP,ACT,0.4399999976158142	CHEMBL15245,TP,ACT,0.44999998807907104	CHEMBL1172,FN,ACT,0.0	CHEMBL119443,TP,ACT,0.15000000596046448	CHEMBL223836,TP,ACT,0.6899999976158142	CHEMBL109206,TN,INACT,0.0	CHEMBL62660,TN,INACT,0.0	CHEMBL328089,TN,INACT,0.0	CHEMBL80180,TN,INACT,0.009999999776482582	CHEMBL106525,TP,ACT,0.25999999046325684	CHEMBL2051956,TP,ACT,0.9200000166893005	CHEMBL2164612,TN,INACT,0.0	CHEMBL218457,FN,ACT,0.0	CHEMBL309397,TN,INACT,0.0	CHEMBL88448,TP,ACT,0.9800000190734863	CHEMBL45269,TN,INACT,0.0	CHEMBL291293,FP,INACT,0.36000001430511475	CHEMBL2112451,TN,INACT,0.0	CHEMBL1237302,TN,INACT,0.0	CHEMBL515170,TN,INACT,0.0	CHEMBL2432038,TP,ACT,0.8700000047683716	CHEMBL359141,TN,INACT,0.0	CHEMBL47404,TN,INACT,0.0	CHEMBL245319,TN,INACT,0.0	CHEMBL1765671,TN,INACT,0.0	CHEMBL343158,TN,INACT,0.0	CHEMBL1076,FP,INACT,0.2199999988079071	CHEMBL48031,TN,INACT,0.0	CHEMBL24781,TN,INACT,0.0	CHEMBL2058635,FN,ACT,0.0	CHEMBL217568,TP,ACT,0.3499999940395355	CHEMBL345951,TN,INACT,0.0	CHEMBL3104093,TP,ACT,0.05999999865889549	CHEMBL332405,TN,INACT,0.0	CHEMBL310250,TN,INACT,0.0	CHEMBL293874,TN,INACT,0.0	CHEMBL425983,TP,ACT,0.20000000298023224	CHEMBL315538,TP,ACT,0.949999988079071	CHEMBL1956200,TN,INACT,0.029999999329447746	

