CNNModel CHEMBL3476 adam 0.001 30 32 0 0.6 False True
Number of active compounds :	280
Number of inactive compounds :	280
---------------------------------
Run id: CNNModel_CHEMBL3476_adam_0.001_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3476_adam_0.001_30_32_0.6_True/
---------------------------------
Training samples: 346
Validation samples: 109
--
Training Step: 1  | time: 0.785s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/346
[A[ATraining Step: 2  | total loss: [1m[32m0.62399[0m[0m | time: 1.387s
[2K
| Adam | epoch: 001 | loss: 0.62399 - acc: 0.3937 -- iter: 064/346
[A[ATraining Step: 3  | total loss: [1m[32m0.68302[0m[0m | time: 2.000s
[2K
| Adam | epoch: 001 | loss: 0.68302 - acc: 0.4040 -- iter: 096/346
[A[ATraining Step: 4  | total loss: [1m[32m0.69023[0m[0m | time: 2.611s
[2K
| Adam | epoch: 001 | loss: 0.69023 - acc: 0.5229 -- iter: 128/346
[A[ATraining Step: 5  | total loss: [1m[32m0.69287[0m[0m | time: 3.251s
[2K
| Adam | epoch: 001 | loss: 0.69287 - acc: 0.4638 -- iter: 160/346
[A[ATraining Step: 6  | total loss: [1m[32m0.69316[0m[0m | time: 3.871s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.4469 -- iter: 192/346
[A[ATraining Step: 7  | total loss: [1m[32m0.69331[0m[0m | time: 4.561s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4600 -- iter: 224/346
[A[ATraining Step: 8  | total loss: [1m[32m0.69237[0m[0m | time: 5.163s
[2K
| Adam | epoch: 001 | loss: 0.69237 - acc: 0.5704 -- iter: 256/346
[A[ATraining Step: 9  | total loss: [1m[32m0.69476[0m[0m | time: 5.796s
[2K
| Adam | epoch: 001 | loss: 0.69476 - acc: 0.4835 -- iter: 288/346
[A[ATraining Step: 10  | total loss: [1m[32m0.69195[0m[0m | time: 6.431s
[2K
| Adam | epoch: 001 | loss: 0.69195 - acc: 0.5542 -- iter: 320/346
[A[ATraining Step: 11  | total loss: [1m[32m0.68883[0m[0m | time: 8.033s
[2K
| Adam | epoch: 001 | loss: 0.68883 - acc: 0.6026 | val_loss: 0.71170 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 12  | total loss: [1m[32m0.68752[0m[0m | time: 0.999s
[2K
| Adam | epoch: 002 | loss: 0.68752 - acc: 0.5910 -- iter: 032/346
[A[ATraining Step: 13  | total loss: [1m[32m0.68504[0m[0m | time: 1.922s
[2K
| Adam | epoch: 002 | loss: 0.68504 - acc: 0.5850 -- iter: 064/346
[A[ATraining Step: 14  | total loss: [1m[32m0.70853[0m[0m | time: 2.962s
[2K
| Adam | epoch: 002 | loss: 0.70853 - acc: 0.5246 -- iter: 096/346
[A[ATraining Step: 15  | total loss: [1m[32m0.71694[0m[0m | time: 3.945s
[2K
| Adam | epoch: 002 | loss: 0.71694 - acc: 0.4783 -- iter: 128/346
[A[ATraining Step: 16  | total loss: [1m[32m0.70554[0m[0m | time: 5.043s
[2K
| Adam | epoch: 002 | loss: 0.70554 - acc: 0.5099 -- iter: 160/346
[A[ATraining Step: 17  | total loss: [1m[32m0.70042[0m[0m | time: 5.966s
[2K
| Adam | epoch: 002 | loss: 0.70042 - acc: 0.5176 -- iter: 192/346
[A[ATraining Step: 18  | total loss: [1m[32m0.69755[0m[0m | time: 7.207s
[2K
| Adam | epoch: 002 | loss: 0.69755 - acc: 0.5223 -- iter: 224/346
[A[ATraining Step: 19  | total loss: [1m[32m0.69612[0m[0m | time: 8.479s
[2K
| Adam | epoch: 002 | loss: 0.69612 - acc: 0.5149 -- iter: 256/346
[A[ATraining Step: 20  | total loss: [1m[32m0.69449[0m[0m | time: 9.696s
[2K
| Adam | epoch: 002 | loss: 0.69449 - acc: 0.5302 -- iter: 288/346
[A[ATraining Step: 21  | total loss: [1m[32m0.69509[0m[0m | time: 10.955s
[2K
| Adam | epoch: 002 | loss: 0.69509 - acc: 0.4820 -- iter: 320/346
[A[ATraining Step: 22  | total loss: [1m[32m0.69488[0m[0m | time: 12.792s
[2K
| Adam | epoch: 002 | loss: 0.69488 - acc: 0.4687 | val_loss: 0.69393 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 23  | total loss: [1m[32m0.69409[0m[0m | time: 1.080s
[2K
| Adam | epoch: 003 | loss: 0.69409 - acc: 0.4959 -- iter: 032/346
[A[ATraining Step: 24  | total loss: [1m[32m0.69343[0m[0m | time: 1.968s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.5295 -- iter: 064/346
[A[ATraining Step: 25  | total loss: [1m[32m0.69295[0m[0m | time: 2.861s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5529 -- iter: 096/346
[A[ATraining Step: 26  | total loss: [1m[32m0.69202[0m[0m | time: 4.039s
[2K
| Adam | epoch: 003 | loss: 0.69202 - acc: 0.6051 -- iter: 128/346
[A[ATraining Step: 27  | total loss: [1m[32m0.69292[0m[0m | time: 5.367s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5459 -- iter: 160/346
[A[ATraining Step: 28  | total loss: [1m[32m0.69269[0m[0m | time: 6.429s
[2K
| Adam | epoch: 003 | loss: 0.69269 - acc: 0.5501 -- iter: 192/346
[A[ATraining Step: 29  | total loss: [1m[32m0.69283[0m[0m | time: 8.046s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5379 -- iter: 224/346
[A[ATraining Step: 30  | total loss: [1m[32m0.69235[0m[0m | time: 8.887s
[2K
| Adam | epoch: 003 | loss: 0.69235 - acc: 0.5511 -- iter: 256/346
[A[ATraining Step: 31  | total loss: [1m[32m0.69276[0m[0m | time: 9.840s
[2K
| Adam | epoch: 003 | loss: 0.69276 - acc: 0.5321 -- iter: 288/346
[A[ATraining Step: 32  | total loss: [1m[32m0.69265[0m[0m | time: 10.807s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5319 -- iter: 320/346
[A[ATraining Step: 33  | total loss: [1m[32m0.69301[0m[0m | time: 12.794s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5181 | val_loss: 0.69541 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 34  | total loss: [1m[32m0.69241[0m[0m | time: 1.266s
[2K
| Adam | epoch: 004 | loss: 0.69241 - acc: 0.5343 -- iter: 032/346
[A[ATraining Step: 35  | total loss: [1m[32m0.69305[0m[0m | time: 2.490s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5140 -- iter: 064/346
[A[ATraining Step: 36  | total loss: [1m[32m0.69280[0m[0m | time: 4.329s
[2K
| Adam | epoch: 004 | loss: 0.69280 - acc: 0.5190 -- iter: 096/346
[A[ATraining Step: 37  | total loss: [1m[32m0.69264[0m[0m | time: 5.246s
[2K
| Adam | epoch: 004 | loss: 0.69264 - acc: 0.5229 -- iter: 128/346
[A[ATraining Step: 38  | total loss: [1m[32m0.69282[0m[0m | time: 6.224s
[2K
| Adam | epoch: 004 | loss: 0.69282 - acc: 0.5184 -- iter: 160/346
[A[ATraining Step: 39  | total loss: [1m[32m0.69222[0m[0m | time: 7.213s
[2K
| Adam | epoch: 004 | loss: 0.69222 - acc: 0.5328 -- iter: 192/346
[A[ATraining Step: 40  | total loss: [1m[32m0.69195[0m[0m | time: 8.342s
[2K
| Adam | epoch: 004 | loss: 0.69195 - acc: 0.5384 -- iter: 224/346
[A[ATraining Step: 41  | total loss: [1m[32m0.69145[0m[0m | time: 9.434s
[2K
| Adam | epoch: 004 | loss: 0.69145 - acc: 0.5486 -- iter: 256/346
[A[ATraining Step: 42  | total loss: [1m[32m0.69212[0m[0m | time: 10.281s
[2K
| Adam | epoch: 004 | loss: 0.69212 - acc: 0.5342 -- iter: 288/346
[A[ATraining Step: 43  | total loss: [1m[32m0.69178[0m[0m | time: 11.309s
[2K
| Adam | epoch: 004 | loss: 0.69178 - acc: 0.5392 -- iter: 320/346
[A[ATraining Step: 44  | total loss: [1m[32m0.69243[0m[0m | time: 13.646s
[2K
| Adam | epoch: 004 | loss: 0.69243 - acc: 0.5270 | val_loss: 0.69690 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 45  | total loss: [1m[32m0.69356[0m[0m | time: 2.878s
[2K
| Adam | epoch: 005 | loss: 0.69356 - acc: 0.5065 -- iter: 032/346
[A[ATraining Step: 46  | total loss: [1m[32m0.69297[0m[0m | time: 3.823s
[2K
| Adam | epoch: 005 | loss: 0.69297 - acc: 0.5158 -- iter: 064/346
[A[ATraining Step: 47  | total loss: [1m[32m0.69221[0m[0m | time: 4.607s
[2K
| Adam | epoch: 005 | loss: 0.69221 - acc: 0.5286 -- iter: 096/346
[A[ATraining Step: 48  | total loss: [1m[32m0.69244[0m[0m | time: 5.433s
[2K
| Adam | epoch: 005 | loss: 0.69244 - acc: 0.5240 -- iter: 128/346
[A[ATraining Step: 49  | total loss: [1m[32m0.69263[0m[0m | time: 6.385s
[2K
| Adam | epoch: 005 | loss: 0.69263 - acc: 0.5202 -- iter: 160/346
[A[ATraining Step: 50  | total loss: [1m[32m0.69215[0m[0m | time: 7.525s
[2K
| Adam | epoch: 005 | loss: 0.69215 - acc: 0.5268 -- iter: 192/346
[A[ATraining Step: 51  | total loss: [1m[32m0.69235[0m[0m | time: 8.472s
[2K
| Adam | epoch: 005 | loss: 0.69235 - acc: 0.5227 -- iter: 224/346
[A[ATraining Step: 52  | total loss: [1m[32m0.69255[0m[0m | time: 9.357s
[2K
| Adam | epoch: 005 | loss: 0.69255 - acc: 0.5193 -- iter: 256/346
[A[ATraining Step: 53  | total loss: [1m[32m0.69239[0m[0m | time: 10.418s
[2K
| Adam | epoch: 005 | loss: 0.69239 - acc: 0.5210 -- iter: 288/346
[A[ATraining Step: 54  | total loss: [1m[32m0.69263[0m[0m | time: 11.394s
[2K
| Adam | epoch: 005 | loss: 0.69263 - acc: 0.5180 -- iter: 320/346
[A[ATraining Step: 55  | total loss: [1m[32m0.69249[0m[0m | time: 13.046s
[2K
| Adam | epoch: 005 | loss: 0.69249 - acc: 0.5199 | val_loss: 0.69780 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 56  | total loss: [1m[32m0.69262[0m[0m | time: 0.606s
[2K
| Adam | epoch: 006 | loss: 0.69262 - acc: 0.5171 -- iter: 032/346
[A[ATraining Step: 57  | total loss: [1m[32m0.69250[0m[0m | time: 1.262s
[2K
| Adam | epoch: 006 | loss: 0.69250 - acc: 0.5190 -- iter: 064/346
[A[ATraining Step: 58  | total loss: [1m[32m0.69241[0m[0m | time: 1.869s
[2K
| Adam | epoch: 006 | loss: 0.69241 - acc: 0.5207 -- iter: 096/346
[A[ATraining Step: 59  | total loss: [1m[32m0.69283[0m[0m | time: 2.362s
[2K
| Adam | epoch: 006 | loss: 0.69283 - acc: 0.5137 -- iter: 128/346
[A[ATraining Step: 60  | total loss: [1m[32m0.69328[0m[0m | time: 2.864s
[2K
| Adam | epoch: 006 | loss: 0.69328 - acc: 0.5068 -- iter: 160/346
[A[ATraining Step: 61  | total loss: [1m[32m0.69363[0m[0m | time: 3.472s
[2K
| Adam | epoch: 006 | loss: 0.69363 - acc: 0.5009 -- iter: 192/346
[A[ATraining Step: 62  | total loss: [1m[32m0.69363[0m[0m | time: 4.094s
[2K
| Adam | epoch: 006 | loss: 0.69363 - acc: 0.5008 -- iter: 224/346
[A[ATraining Step: 63  | total loss: [1m[32m0.69180[0m[0m | time: 4.732s
[2K
| Adam | epoch: 006 | loss: 0.69180 - acc: 0.5284 -- iter: 256/346
[A[ATraining Step: 64  | total loss: [1m[32m0.69418[0m[0m | time: 5.350s
[2K
| Adam | epoch: 006 | loss: 0.69418 - acc: 0.4936 -- iter: 288/346
[A[ATraining Step: 65  | total loss: [1m[32m0.69387[0m[0m | time: 5.963s
[2K
| Adam | epoch: 006 | loss: 0.69387 - acc: 0.4983 -- iter: 320/346
[A[ATraining Step: 66  | total loss: [1m[32m0.69357[0m[0m | time: 7.607s
[2K
| Adam | epoch: 006 | loss: 0.69357 - acc: 0.5023 | val_loss: 0.69724 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 67  | total loss: [1m[32m0.69382[0m[0m | time: 0.630s
[2K
| Adam | epoch: 007 | loss: 0.69382 - acc: 0.4983 -- iter: 032/346
[A[ATraining Step: 68  | total loss: [1m[32m0.69375[0m[0m | time: 1.237s
[2K
| Adam | epoch: 007 | loss: 0.69375 - acc: 0.4985 -- iter: 064/346
[A[ATraining Step: 69  | total loss: [1m[32m0.69244[0m[0m | time: 1.895s
[2K
| Adam | epoch: 007 | loss: 0.69244 - acc: 0.5206 -- iter: 096/346
[A[ATraining Step: 70  | total loss: [1m[32m0.69108[0m[0m | time: 2.560s
[2K
| Adam | epoch: 007 | loss: 0.69108 - acc: 0.5434 -- iter: 128/346
[A[ATraining Step: 71  | total loss: [1m[32m0.69050[0m[0m | time: 3.082s
[2K
| Adam | epoch: 007 | loss: 0.69050 - acc: 0.5527 -- iter: 160/346
[A[ATraining Step: 72  | total loss: [1m[32m0.69031[0m[0m | time: 3.586s
[2K
| Adam | epoch: 007 | loss: 0.69031 - acc: 0.5554 -- iter: 192/346
[A[ATraining Step: 73  | total loss: [1m[32m0.69013[0m[0m | time: 4.203s
[2K
| Adam | epoch: 007 | loss: 0.69013 - acc: 0.5578 -- iter: 224/346
[A[ATraining Step: 74  | total loss: [1m[32m0.69108[0m[0m | time: 4.867s
[2K
| Adam | epoch: 007 | loss: 0.69108 - acc: 0.5446 -- iter: 256/346
[A[ATraining Step: 75  | total loss: [1m[32m0.69162[0m[0m | time: 6.060s
[2K
| Adam | epoch: 007 | loss: 0.69162 - acc: 0.5364 -- iter: 288/346
[A[ATraining Step: 76  | total loss: [1m[32m0.69212[0m[0m | time: 7.261s
[2K
| Adam | epoch: 007 | loss: 0.69212 - acc: 0.5291 -- iter: 320/346
[A[ATraining Step: 77  | total loss: [1m[32m0.69099[0m[0m | time: 9.336s
[2K
| Adam | epoch: 007 | loss: 0.69099 - acc: 0.5426 | val_loss: 0.69907 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 78  | total loss: [1m[32m0.69269[0m[0m | time: 1.010s
[2K
| Adam | epoch: 008 | loss: 0.69269 - acc: 0.5218 -- iter: 032/346
[A[ATraining Step: 79  | total loss: [1m[32m0.69117[0m[0m | time: 1.954s
[2K
| Adam | epoch: 008 | loss: 0.69117 - acc: 0.5389 -- iter: 064/346
[A[ATraining Step: 80  | total loss: [1m[32m0.69148[0m[0m | time: 2.959s
[2K
| Adam | epoch: 008 | loss: 0.69148 - acc: 0.5350 -- iter: 096/346
[A[ATraining Step: 81  | total loss: [1m[32m0.69063[0m[0m | time: 4.148s
[2K
| Adam | epoch: 008 | loss: 0.69063 - acc: 0.5441 -- iter: 128/346
[A[ATraining Step: 82  | total loss: [1m[32m0.69042[0m[0m | time: 5.424s
[2K
| Adam | epoch: 008 | loss: 0.69042 - acc: 0.5459 -- iter: 160/346
[A[ATraining Step: 83  | total loss: [1m[32m0.69051[0m[0m | time: 6.115s
[2K
| Adam | epoch: 008 | loss: 0.69051 - acc: 0.5444 -- iter: 192/346
[A[ATraining Step: 84  | total loss: [1m[32m0.69242[0m[0m | time: 6.911s
[2K
| Adam | epoch: 008 | loss: 0.69242 - acc: 0.5246 -- iter: 224/346
[A[ATraining Step: 85  | total loss: [1m[32m0.69419[0m[0m | time: 7.845s
[2K
| Adam | epoch: 008 | loss: 0.69419 - acc: 0.5068 -- iter: 256/346
[A[ATraining Step: 86  | total loss: [1m[32m0.69303[0m[0m | time: 8.859s
[2K
| Adam | epoch: 008 | loss: 0.69303 - acc: 0.5186 -- iter: 288/346
[A[ATraining Step: 87  | total loss: [1m[32m0.69404[0m[0m | time: 9.885s
[2K
| Adam | epoch: 008 | loss: 0.69404 - acc: 0.5074 -- iter: 320/346
[A[ATraining Step: 88  | total loss: [1m[32m0.69460[0m[0m | time: 11.872s
[2K
| Adam | epoch: 008 | loss: 0.69460 - acc: 0.5004 | val_loss: 0.69911 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 89  | total loss: [1m[32m0.69424[0m[0m | time: 0.967s
[2K
| Adam | epoch: 009 | loss: 0.69424 - acc: 0.5035 -- iter: 032/346
[A[ATraining Step: 90  | total loss: [1m[32m0.69444[0m[0m | time: 3.684s
[2K
| Adam | epoch: 009 | loss: 0.69444 - acc: 0.5000 -- iter: 064/346
[A[ATraining Step: 91  | total loss: [1m[32m0.69338[0m[0m | time: 4.621s
[2K
| Adam | epoch: 009 | loss: 0.69338 - acc: 0.5125 -- iter: 096/346
[A[ATraining Step: 92  | total loss: [1m[32m0.69347[0m[0m | time: 5.604s
[2K
| Adam | epoch: 009 | loss: 0.69347 - acc: 0.5112 -- iter: 128/346
[A[ATraining Step: 93  | total loss: [1m[32m0.69328[0m[0m | time: 6.589s
[2K
| Adam | epoch: 009 | loss: 0.69328 - acc: 0.5132 -- iter: 160/346
[A[ATraining Step: 94  | total loss: [1m[32m0.69385[0m[0m | time: 7.677s
[2K
| Adam | epoch: 009 | loss: 0.69385 - acc: 0.5057 -- iter: 192/346
[A[ATraining Step: 95  | total loss: [1m[32m0.69335[0m[0m | time: 8.613s
[2K
| Adam | epoch: 009 | loss: 0.69335 - acc: 0.5113 -- iter: 224/346
[A[ATraining Step: 96  | total loss: [1m[32m0.69340[0m[0m | time: 9.375s
[2K
| Adam | epoch: 009 | loss: 0.69340 - acc: 0.5102 -- iter: 256/346
[A[ATraining Step: 97  | total loss: [1m[32m0.69345[0m[0m | time: 10.411s
[2K
| Adam | epoch: 009 | loss: 0.69345 - acc: 0.5092 -- iter: 288/346
[A[ATraining Step: 98  | total loss: [1m[32m0.69281[0m[0m | time: 11.669s
[2K
| Adam | epoch: 009 | loss: 0.69281 - acc: 0.5176 -- iter: 320/346
[A[ATraining Step: 99  | total loss: [1m[32m0.69220[0m[0m | time: 14.037s
[2K
| Adam | epoch: 009 | loss: 0.69220 - acc: 0.5253 | val_loss: 0.69806 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 100  | total loss: [1m[32m0.69280[0m[0m | time: 0.977s
[2K
| Adam | epoch: 010 | loss: 0.69280 - acc: 0.5165 -- iter: 032/346
[A[ATraining Step: 101  | total loss: [1m[32m0.69289[0m[0m | time: 2.028s
[2K
| Adam | epoch: 010 | loss: 0.69289 - acc: 0.5148 -- iter: 064/346
[A[ATraining Step: 102  | total loss: [1m[32m0.69231[0m[0m | time: 3.189s
[2K
| Adam | epoch: 010 | loss: 0.69231 - acc: 0.5227 -- iter: 096/346
[A[ATraining Step: 103  | total loss: [1m[32m0.69177[0m[0m | time: 4.034s
[2K
| Adam | epoch: 010 | loss: 0.69177 - acc: 0.5298 -- iter: 128/346
[A[ATraining Step: 104  | total loss: [1m[32m0.69082[0m[0m | time: 5.312s
[2K
| Adam | epoch: 010 | loss: 0.69082 - acc: 0.5425 -- iter: 160/346
[A[ATraining Step: 105  | total loss: [1m[32m0.69088[0m[0m | time: 6.558s
[2K
| Adam | epoch: 010 | loss: 0.69088 - acc: 0.5413 -- iter: 192/346
[A[ATraining Step: 106  | total loss: [1m[32m0.68968[0m[0m | time: 7.736s
[2K
| Adam | epoch: 010 | loss: 0.68968 - acc: 0.5560 -- iter: 224/346
[A[ATraining Step: 107  | total loss: [1m[32m0.68933[0m[0m | time: 9.220s
[2K
| Adam | epoch: 010 | loss: 0.68933 - acc: 0.5597 -- iter: 256/346
[A[ATraining Step: 108  | total loss: [1m[32m0.69008[0m[0m | time: 9.984s
[2K
| Adam | epoch: 010 | loss: 0.69008 - acc: 0.5499 -- iter: 288/346
[A[ATraining Step: 109  | total loss: [1m[32m0.69088[0m[0m | time: 10.982s
[2K
| Adam | epoch: 010 | loss: 0.69088 - acc: 0.5411 -- iter: 320/346
[A[ATraining Step: 110  | total loss: [1m[32m0.69212[0m[0m | time: 12.926s
[2K
| Adam | epoch: 010 | loss: 0.69212 - acc: 0.5276 | val_loss: 0.69986 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 111  | total loss: [1m[32m0.69409[0m[0m | time: 1.111s
[2K
| Adam | epoch: 011 | loss: 0.69409 - acc: 0.5061 -- iter: 032/346
[A[ATraining Step: 112  | total loss: [1m[32m0.69464[0m[0m | time: 2.104s
[2K
| Adam | epoch: 011 | loss: 0.69464 - acc: 0.4992 -- iter: 064/346
[A[ATraining Step: 113  | total loss: [1m[32m0.69402[0m[0m | time: 3.009s
[2K
| Adam | epoch: 011 | loss: 0.69402 - acc: 0.5056 -- iter: 096/346
[A[ATraining Step: 114  | total loss: [1m[32m0.69379[0m[0m | time: 3.611s
[2K
| Adam | epoch: 011 | loss: 0.69379 - acc: 0.5081 -- iter: 128/346
[A[ATraining Step: 115  | total loss: [1m[32m0.69323[0m[0m | time: 4.221s
[2K
| Adam | epoch: 011 | loss: 0.69323 - acc: 0.5136 -- iter: 160/346
[A[ATraining Step: 116  | total loss: [1m[32m0.69305[0m[0m | time: 4.854s
[2K
| Adam | epoch: 011 | loss: 0.69305 - acc: 0.5153 -- iter: 192/346
[A[ATraining Step: 117  | total loss: [1m[32m0.69260[0m[0m | time: 5.493s
[2K
| Adam | epoch: 011 | loss: 0.69260 - acc: 0.5200 -- iter: 224/346
[A[ATraining Step: 118  | total loss: [1m[32m0.69218[0m[0m | time: 6.106s
[2K
| Adam | epoch: 011 | loss: 0.69218 - acc: 0.5243 -- iter: 256/346
[A[ATraining Step: 119  | total loss: [1m[32m0.69236[0m[0m | time: 6.628s
[2K
| Adam | epoch: 011 | loss: 0.69236 - acc: 0.5219 -- iter: 288/346
[A[ATraining Step: 120  | total loss: [1m[32m0.69225[0m[0m | time: 7.172s
[2K
| Adam | epoch: 011 | loss: 0.69225 - acc: 0.5235 -- iter: 320/346
[A[ATraining Step: 121  | total loss: [1m[32m0.69205[0m[0m | time: 8.795s
[2K
| Adam | epoch: 011 | loss: 0.69205 - acc: 0.5250 | val_loss: 0.69919 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 122  | total loss: [1m[32m0.69225[0m[0m | time: 0.638s
[2K
| Adam | epoch: 012 | loss: 0.69225 - acc: 0.5225 -- iter: 032/346
[A[ATraining Step: 123  | total loss: [1m[32m0.69247[0m[0m | time: 1.268s
[2K
| Adam | epoch: 012 | loss: 0.69247 - acc: 0.5203 -- iter: 064/346
[A[ATraining Step: 124  | total loss: [1m[32m0.69262[0m[0m | time: 1.953s
[2K
| Adam | epoch: 012 | loss: 0.69262 - acc: 0.5182 -- iter: 096/346
[A[ATraining Step: 125  | total loss: [1m[32m0.69217[0m[0m | time: 2.584s
[2K
| Adam | epoch: 012 | loss: 0.69217 - acc: 0.5227 -- iter: 128/346
[A[ATraining Step: 126  | total loss: [1m[32m0.69156[0m[0m | time: 3.222s
[2K
| Adam | epoch: 012 | loss: 0.69156 - acc: 0.5298 -- iter: 160/346
[A[ATraining Step: 127  | total loss: [1m[32m0.69045[0m[0m | time: 3.834s
[2K
| Adam | epoch: 012 | loss: 0.69045 - acc: 0.5424 -- iter: 192/346
[A[ATraining Step: 128  | total loss: [1m[32m0.69108[0m[0m | time: 4.457s
[2K
| Adam | epoch: 012 | loss: 0.69108 - acc: 0.5351 -- iter: 224/346
[A[ATraining Step: 129  | total loss: [1m[32m0.69260[0m[0m | time: 5.080s
[2K
| Adam | epoch: 012 | loss: 0.69260 - acc: 0.5190 -- iter: 256/346
[A[ATraining Step: 130  | total loss: [1m[32m0.69247[0m[0m | time: 5.708s
[2K
| Adam | epoch: 012 | loss: 0.69247 - acc: 0.5203 -- iter: 288/346
[A[ATraining Step: 131  | total loss: [1m[32m0.69288[0m[0m | time: 6.232s
[2K
| Adam | epoch: 012 | loss: 0.69288 - acc: 0.5151 -- iter: 320/346
[A[ATraining Step: 132  | total loss: [1m[32m0.69297[0m[0m | time: 7.766s
[2K
| Adam | epoch: 012 | loss: 0.69297 - acc: 0.5136 | val_loss: 0.69878 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 133  | total loss: [1m[32m0.69300[0m[0m | time: 0.627s
[2K
| Adam | epoch: 013 | loss: 0.69300 - acc: 0.5122 -- iter: 032/346
[A[ATraining Step: 134  | total loss: [1m[32m0.69337[0m[0m | time: 1.708s
[2K
| Adam | epoch: 013 | loss: 0.69337 - acc: 0.5079 -- iter: 064/346
[A[ATraining Step: 135  | total loss: [1m[32m0.69216[0m[0m | time: 2.946s
[2K
| Adam | epoch: 013 | loss: 0.69216 - acc: 0.5227 -- iter: 096/346
[A[ATraining Step: 136  | total loss: [1m[32m0.69232[0m[0m | time: 4.277s
[2K
| Adam | epoch: 013 | loss: 0.69232 - acc: 0.5205 -- iter: 128/346
[A[ATraining Step: 137  | total loss: [1m[32m0.69193[0m[0m | time: 5.452s
[2K
| Adam | epoch: 013 | loss: 0.69193 - acc: 0.5247 -- iter: 160/346
[A[ATraining Step: 138  | total loss: [1m[32m0.69126[0m[0m | time: 6.414s
[2K
| Adam | epoch: 013 | loss: 0.69126 - acc: 0.5316 -- iter: 192/346
[A[ATraining Step: 139  | total loss: [1m[32m0.69199[0m[0m | time: 7.353s
[2K
| Adam | epoch: 013 | loss: 0.69199 - acc: 0.5222 -- iter: 224/346
[A[ATraining Step: 140  | total loss: [1m[32m0.69227[0m[0m | time: 8.352s
[2K
| Adam | epoch: 013 | loss: 0.69227 - acc: 0.5168 -- iter: 256/346
[A[ATraining Step: 141  | total loss: [1m[32m0.69239[0m[0m | time: 9.390s
[2K
| Adam | epoch: 013 | loss: 0.69239 - acc: 0.5151 -- iter: 288/346
[A[ATraining Step: 142  | total loss: [1m[32m0.69252[0m[0m | time: 10.522s
[2K
| Adam | epoch: 013 | loss: 0.69252 - acc: 0.5105 -- iter: 320/346
[A[ATraining Step: 143  | total loss: [1m[32m0.69200[0m[0m | time: 12.264s
[2K
| Adam | epoch: 013 | loss: 0.69200 - acc: 0.5157 | val_loss: 0.69442 - val_acc: 0.4404 -- iter: 346/346
--
Training Step: 144  | total loss: [1m[32m0.69119[0m[0m | time: 0.817s
[2K
| Adam | epoch: 014 | loss: 0.69119 - acc: 0.5218 -- iter: 032/346
[A[ATraining Step: 145  | total loss: [1m[32m0.69018[0m[0m | time: 1.681s
[2K
| Adam | epoch: 014 | loss: 0.69018 - acc: 0.5273 -- iter: 064/346
[A[ATraining Step: 146  | total loss: [1m[32m0.68924[0m[0m | time: 2.708s
[2K
| Adam | epoch: 014 | loss: 0.68924 - acc: 0.5308 -- iter: 096/346
[A[ATraining Step: 147  | total loss: [1m[32m0.68872[0m[0m | time: 3.667s
[2K
| Adam | epoch: 014 | loss: 0.68872 - acc: 0.5246 -- iter: 128/346
[A[ATraining Step: 148  | total loss: [1m[32m0.68761[0m[0m | time: 4.736s
[2K
| Adam | epoch: 014 | loss: 0.68761 - acc: 0.5441 -- iter: 160/346
[A[ATraining Step: 149  | total loss: [1m[32m0.68719[0m[0m | time: 5.624s
[2K
| Adam | epoch: 014 | loss: 0.68719 - acc: 0.5490 -- iter: 192/346
[A[ATraining Step: 150  | total loss: [1m[32m0.68404[0m[0m | time: 6.791s
[2K
| Adam | epoch: 014 | loss: 0.68404 - acc: 0.5660 -- iter: 224/346
[A[ATraining Step: 151  | total loss: [1m[32m0.68490[0m[0m | time: 8.136s
[2K
| Adam | epoch: 014 | loss: 0.68490 - acc: 0.5563 -- iter: 256/346
[A[ATraining Step: 152  | total loss: [1m[32m0.68308[0m[0m | time: 9.114s
[2K
| Adam | epoch: 014 | loss: 0.68308 - acc: 0.5663 -- iter: 288/346
[A[ATraining Step: 153  | total loss: [1m[32m0.67649[0m[0m | time: 10.177s
[2K
| Adam | epoch: 014 | loss: 0.67649 - acc: 0.5878 -- iter: 320/346
[A[ATraining Step: 154  | total loss: [1m[32m0.67083[0m[0m | time: 12.117s
[2K
| Adam | epoch: 014 | loss: 0.67083 - acc: 0.5977 | val_loss: 0.66333 - val_acc: 0.6239 -- iter: 346/346
--
Training Step: 155  | total loss: [1m[32m0.66419[0m[0m | time: 1.215s
[2K
| Adam | epoch: 015 | loss: 0.66419 - acc: 0.6161 -- iter: 032/346
[A[ATraining Step: 156  | total loss: [1m[32m0.65515[0m[0m | time: 2.357s
[2K
| Adam | epoch: 015 | loss: 0.65515 - acc: 0.6314 -- iter: 064/346
[A[ATraining Step: 157  | total loss: [1m[32m0.64345[0m[0m | time: 3.239s
[2K
| Adam | epoch: 015 | loss: 0.64345 - acc: 0.6452 -- iter: 096/346
[A[ATraining Step: 158  | total loss: [1m[32m0.64406[0m[0m | time: 4.229s
[2K
| Adam | epoch: 015 | loss: 0.64406 - acc: 0.6432 -- iter: 128/346
[A[ATraining Step: 159  | total loss: [1m[32m0.65259[0m[0m | time: 5.201s
[2K
| Adam | epoch: 015 | loss: 0.65259 - acc: 0.6445 -- iter: 160/346
[A[ATraining Step: 160  | total loss: [1m[32m0.64247[0m[0m | time: 6.188s
[2K
| Adam | epoch: 015 | loss: 0.64247 - acc: 0.6488 -- iter: 192/346
[A[ATraining Step: 161  | total loss: [1m[32m0.64789[0m[0m | time: 7.259s
[2K
| Adam | epoch: 015 | loss: 0.64789 - acc: 0.6370 -- iter: 224/346
[A[ATraining Step: 162  | total loss: [1m[32m0.64632[0m[0m | time: 8.343s
[2K
| Adam | epoch: 015 | loss: 0.64632 - acc: 0.6421 -- iter: 256/346
[A[ATraining Step: 163  | total loss: [1m[32m0.63788[0m[0m | time: 9.116s
[2K
| Adam | epoch: 015 | loss: 0.63788 - acc: 0.6529 -- iter: 288/346
[A[ATraining Step: 164  | total loss: [1m[32m0.63354[0m[0m | time: 10.149s
[2K
| Adam | epoch: 015 | loss: 0.63354 - acc: 0.6532 -- iter: 320/346
[A[ATraining Step: 165  | total loss: [1m[32m0.63412[0m[0m | time: 12.515s
[2K
| Adam | epoch: 015 | loss: 0.63412 - acc: 0.6504 | val_loss: 0.61351 - val_acc: 0.6422 -- iter: 346/346
--
Training Step: 166  | total loss: [1m[32m0.63201[0m[0m | time: 0.994s
[2K
| Adam | epoch: 016 | loss: 0.63201 - acc: 0.6478 -- iter: 032/346
[A[ATraining Step: 167  | total loss: [1m[32m0.62827[0m[0m | time: 1.774s
[2K
| Adam | epoch: 016 | loss: 0.62827 - acc: 0.6549 -- iter: 064/346
[A[ATraining Step: 168  | total loss: [1m[32m0.62808[0m[0m | time: 2.591s
[2K
| Adam | epoch: 016 | loss: 0.62808 - acc: 0.6548 -- iter: 096/346
[A[ATraining Step: 169  | total loss: [1m[32m0.62007[0m[0m | time: 3.745s
[2K
| Adam | epoch: 016 | loss: 0.62007 - acc: 0.6624 -- iter: 128/346
[A[ATraining Step: 170  | total loss: [1m[32m0.60882[0m[0m | time: 4.717s
[2K
| Adam | epoch: 016 | loss: 0.60882 - acc: 0.6774 -- iter: 160/346
[A[ATraining Step: 171  | total loss: [1m[32m0.60848[0m[0m | time: 5.631s
[2K
| Adam | epoch: 016 | loss: 0.60848 - acc: 0.6753 -- iter: 192/346
[A[ATraining Step: 172  | total loss: [1m[32m0.61709[0m[0m | time: 6.669s
[2K
| Adam | epoch: 016 | loss: 0.61709 - acc: 0.6640 -- iter: 224/346
[A[ATraining Step: 173  | total loss: [1m[32m0.60266[0m[0m | time: 7.754s
[2K
| Adam | epoch: 016 | loss: 0.60266 - acc: 0.6758 -- iter: 256/346
[A[ATraining Step: 174  | total loss: [1m[32m0.59335[0m[0m | time: 8.448s
[2K
| Adam | epoch: 016 | loss: 0.59335 - acc: 0.6863 -- iter: 288/346
[A[ATraining Step: 175  | total loss: [1m[32m0.57299[0m[0m | time: 9.080s
[2K
| Adam | epoch: 016 | loss: 0.57299 - acc: 0.6989 -- iter: 320/346
[A[ATraining Step: 176  | total loss: [1m[32m0.56407[0m[0m | time: 10.702s
[2K
| Adam | epoch: 016 | loss: 0.56407 - acc: 0.7072 | val_loss: 0.56072 - val_acc: 0.6881 -- iter: 346/346
--
Training Step: 177  | total loss: [1m[32m0.54902[0m[0m | time: 0.617s
[2K
| Adam | epoch: 017 | loss: 0.54902 - acc: 0.7208 -- iter: 032/346
[A[ATraining Step: 178  | total loss: [1m[32m0.52897[0m[0m | time: 1.222s
[2K
| Adam | epoch: 017 | loss: 0.52897 - acc: 0.7331 -- iter: 064/346
[A[ATraining Step: 179  | total loss: [1m[32m0.51645[0m[0m | time: 1.734s
[2K
| Adam | epoch: 017 | loss: 0.51645 - acc: 0.7410 -- iter: 096/346
[A[ATraining Step: 180  | total loss: [1m[32m0.53637[0m[0m | time: 2.228s
[2K
| Adam | epoch: 017 | loss: 0.53637 - acc: 0.7323 -- iter: 128/346
[A[ATraining Step: 181  | total loss: [1m[32m0.52947[0m[0m | time: 2.841s
[2K
| Adam | epoch: 017 | loss: 0.52947 - acc: 0.7283 -- iter: 160/346
[A[ATraining Step: 182  | total loss: [1m[32m0.52987[0m[0m | time: 3.439s
[2K
| Adam | epoch: 017 | loss: 0.52987 - acc: 0.7274 -- iter: 192/346
[A[ATraining Step: 183  | total loss: [1m[32m0.53194[0m[0m | time: 4.050s
[2K
| Adam | epoch: 017 | loss: 0.53194 - acc: 0.7265 -- iter: 224/346
[A[ATraining Step: 184  | total loss: [1m[32m0.52231[0m[0m | time: 4.651s
[2K
| Adam | epoch: 017 | loss: 0.52231 - acc: 0.7351 -- iter: 256/346
[A[ATraining Step: 185  | total loss: [1m[32m0.51255[0m[0m | time: 5.235s
[2K
| Adam | epoch: 017 | loss: 0.51255 - acc: 0.7397 -- iter: 288/346
[A[ATraining Step: 186  | total loss: [1m[32m0.51078[0m[0m | time: 5.844s
[2K
| Adam | epoch: 017 | loss: 0.51078 - acc: 0.7376 -- iter: 320/346
[A[ATraining Step: 187  | total loss: [1m[32m0.49574[0m[0m | time: 7.478s
[2K
| Adam | epoch: 017 | loss: 0.49574 - acc: 0.7545 | val_loss: 0.49323 - val_acc: 0.7248 -- iter: 346/346
--
Training Step: 188  | total loss: [1m[32m0.47206[0m[0m | time: 0.604s
[2K
| Adam | epoch: 018 | loss: 0.47206 - acc: 0.7728 -- iter: 032/346
[A[ATraining Step: 189  | total loss: [1m[32m0.45462[0m[0m | time: 1.223s
[2K
| Adam | epoch: 018 | loss: 0.45462 - acc: 0.7893 -- iter: 064/346
[A[ATraining Step: 190  | total loss: [1m[32m0.44995[0m[0m | time: 1.872s
[2K
| Adam | epoch: 018 | loss: 0.44995 - acc: 0.7916 -- iter: 096/346
[A[ATraining Step: 191  | total loss: [1m[32m0.43680[0m[0m | time: 2.392s
[2K
| Adam | epoch: 018 | loss: 0.43680 - acc: 0.8030 -- iter: 128/346
[A[ATraining Step: 192  | total loss: [1m[32m0.41674[0m[0m | time: 2.901s
[2K
| Adam | epoch: 018 | loss: 0.41674 - acc: 0.8189 -- iter: 160/346
[A[ATraining Step: 193  | total loss: [1m[32m0.39781[0m[0m | time: 3.531s
[2K
| Adam | epoch: 018 | loss: 0.39781 - acc: 0.8332 -- iter: 192/346
[A[ATraining Step: 194  | total loss: [1m[32m0.39835[0m[0m | time: 4.153s
[2K
| Adam | epoch: 018 | loss: 0.39835 - acc: 0.8217 -- iter: 224/346
[A[ATraining Step: 195  | total loss: [1m[32m0.38905[0m[0m | time: 4.900s
[2K
| Adam | epoch: 018 | loss: 0.38905 - acc: 0.8270 -- iter: 256/346
[A[ATraining Step: 196  | total loss: [1m[32m0.36158[0m[0m | time: 5.510s
[2K
| Adam | epoch: 018 | loss: 0.36158 - acc: 0.8443 -- iter: 288/346
[A[ATraining Step: 197  | total loss: [1m[32m0.34683[0m[0m | time: 6.153s
[2K
| Adam | epoch: 018 | loss: 0.34683 - acc: 0.8537 -- iter: 320/346
[A[ATraining Step: 198  | total loss: [1m[32m0.32638[0m[0m | time: 7.799s
[2K
| Adam | epoch: 018 | loss: 0.32638 - acc: 0.8620 | val_loss: 0.56439 - val_acc: 0.7706 -- iter: 346/346
--
Training Step: 199  | total loss: [1m[32m0.31164[0m[0m | time: 0.618s
[2K
| Adam | epoch: 019 | loss: 0.31164 - acc: 0.8665 -- iter: 032/346
[A[ATraining Step: 200  | total loss: [1m[32m0.31392[0m[0m | time: 2.230s
[2K
| Adam | epoch: 019 | loss: 0.31392 - acc: 0.8673 | val_loss: 0.60392 - val_acc: 0.7523 -- iter: 064/346
--
Training Step: 201  | total loss: [1m[32m0.31533[0m[0m | time: 2.837s
[2K
| Adam | epoch: 019 | loss: 0.31533 - acc: 0.8618 -- iter: 096/346
[A[ATraining Step: 202  | total loss: [1m[32m0.31187[0m[0m | time: 3.449s
[2K
| Adam | epoch: 019 | loss: 0.31187 - acc: 0.8632 -- iter: 128/346
[A[ATraining Step: 203  | total loss: [1m[32m0.32604[0m[0m | time: 4.006s
[2K
| Adam | epoch: 019 | loss: 0.32604 - acc: 0.8581 -- iter: 160/346
[A[ATraining Step: 204  | total loss: [1m[32m0.30858[0m[0m | time: 4.672s
[2K
| Adam | epoch: 019 | loss: 0.30858 - acc: 0.8684 -- iter: 192/346
[A[ATraining Step: 205  | total loss: [1m[32m0.30126[0m[0m | time: 5.883s
[2K
| Adam | epoch: 019 | loss: 0.30126 - acc: 0.8701 -- iter: 224/346
[A[ATraining Step: 206  | total loss: [1m[32m0.30635[0m[0m | time: 7.211s
[2K
| Adam | epoch: 019 | loss: 0.30635 - acc: 0.8643 -- iter: 256/346
[A[ATraining Step: 207  | total loss: [1m[32m0.28973[0m[0m | time: 8.443s
[2K
| Adam | epoch: 019 | loss: 0.28973 - acc: 0.8747 -- iter: 288/346
[A[ATraining Step: 208  | total loss: [1m[32m0.30674[0m[0m | time: 9.374s
[2K
| Adam | epoch: 019 | loss: 0.30674 - acc: 0.8779 -- iter: 320/346
[A[ATraining Step: 209  | total loss: [1m[32m0.28702[0m[0m | time: 11.367s
[2K
| Adam | epoch: 019 | loss: 0.28702 - acc: 0.8870 | val_loss: 0.58626 - val_acc: 0.7615 -- iter: 346/346
--
Training Step: 210  | total loss: [1m[32m0.27271[0m[0m | time: 0.976s
[2K
| Adam | epoch: 020 | loss: 0.27271 - acc: 0.8952 -- iter: 032/346
[A[ATraining Step: 211  | total loss: [1m[32m0.26983[0m[0m | time: 1.984s
[2K
| Adam | epoch: 020 | loss: 0.26983 - acc: 0.8963 -- iter: 064/346
[A[ATraining Step: 212  | total loss: [1m[32m0.26348[0m[0m | time: 3.245s
[2K
| Adam | epoch: 020 | loss: 0.26348 - acc: 0.8973 -- iter: 096/346
[A[ATraining Step: 213  | total loss: [1m[32m0.24968[0m[0m | time: 4.543s
[2K
| Adam | epoch: 020 | loss: 0.24968 - acc: 0.9044 -- iter: 128/346
[A[ATraining Step: 214  | total loss: [1m[32m0.23589[0m[0m | time: 5.617s
[2K
| Adam | epoch: 020 | loss: 0.23589 - acc: 0.9140 -- iter: 160/346
[A[ATraining Step: 215  | total loss: [1m[32m0.22711[0m[0m | time: 6.409s
[2K
| Adam | epoch: 020 | loss: 0.22711 - acc: 0.9163 -- iter: 192/346
[A[ATraining Step: 216  | total loss: [1m[32m0.22000[0m[0m | time: 7.185s
[2K
| Adam | epoch: 020 | loss: 0.22000 - acc: 0.9208 -- iter: 224/346
[A[ATraining Step: 217  | total loss: [1m[32m0.21251[0m[0m | time: 8.136s
[2K
| Adam | epoch: 020 | loss: 0.21251 - acc: 0.9249 -- iter: 256/346
[A[ATraining Step: 218  | total loss: [1m[32m0.20863[0m[0m | time: 9.094s
[2K
| Adam | epoch: 020 | loss: 0.20863 - acc: 0.9230 -- iter: 288/346
[A[ATraining Step: 219  | total loss: [1m[32m0.22082[0m[0m | time: 10.156s
[2K
| Adam | epoch: 020 | loss: 0.22082 - acc: 0.9151 -- iter: 320/346
[A[ATraining Step: 220  | total loss: [1m[32m0.21474[0m[0m | time: 12.153s
[2K
| Adam | epoch: 020 | loss: 0.21474 - acc: 0.9174 | val_loss: 0.61526 - val_acc: 0.8073 -- iter: 346/346
--
Training Step: 221  | total loss: [1m[32m0.19873[0m[0m | time: 0.949s
[2K
| Adam | epoch: 021 | loss: 0.19873 - acc: 0.9256 -- iter: 032/346
[A[ATraining Step: 222  | total loss: [1m[32m0.20722[0m[0m | time: 1.892s
[2K
| Adam | epoch: 021 | loss: 0.20722 - acc: 0.9206 -- iter: 064/346
[A[ATraining Step: 223  | total loss: [1m[32m0.19692[0m[0m | time: 2.828s
[2K
| Adam | epoch: 021 | loss: 0.19692 - acc: 0.9254 -- iter: 096/346
[A[ATraining Step: 224  | total loss: [1m[32m0.18847[0m[0m | time: 3.787s
[2K
| Adam | epoch: 021 | loss: 0.18847 - acc: 0.9297 -- iter: 128/346
[A[ATraining Step: 225  | total loss: [1m[32m0.17708[0m[0m | time: 4.876s
[2K
| Adam | epoch: 021 | loss: 0.17708 - acc: 0.9336 -- iter: 160/346
[A[ATraining Step: 226  | total loss: [1m[32m0.16337[0m[0m | time: 5.739s
[2K
| Adam | epoch: 021 | loss: 0.16337 - acc: 0.9403 -- iter: 192/346
[A[ATraining Step: 227  | total loss: [1m[32m0.15141[0m[0m | time: 6.701s
[2K
| Adam | epoch: 021 | loss: 0.15141 - acc: 0.9462 -- iter: 224/346
[A[ATraining Step: 228  | total loss: [1m[32m0.13872[0m[0m | time: 7.750s
[2K
| Adam | epoch: 021 | loss: 0.13872 - acc: 0.9516 -- iter: 256/346
[A[ATraining Step: 229  | total loss: [1m[32m0.12615[0m[0m | time: 8.863s
[2K
| Adam | epoch: 021 | loss: 0.12615 - acc: 0.9564 -- iter: 288/346
[A[ATraining Step: 230  | total loss: [1m[32m0.13502[0m[0m | time: 9.719s
[2K
| Adam | epoch: 021 | loss: 0.13502 - acc: 0.9514 -- iter: 320/346
[A[ATraining Step: 231  | total loss: [1m[32m0.12839[0m[0m | time: 11.701s
[2K
| Adam | epoch: 021 | loss: 0.12839 - acc: 0.9532 | val_loss: 0.63381 - val_acc: 0.7982 -- iter: 346/346
--
Training Step: 232  | total loss: [1m[32m0.11937[0m[0m | time: 1.193s
[2K
| Adam | epoch: 022 | loss: 0.11937 - acc: 0.9578 -- iter: 032/346
[A[ATraining Step: 233  | total loss: [1m[32m0.11768[0m[0m | time: 2.576s
[2K
| Adam | epoch: 022 | loss: 0.11768 - acc: 0.9558 -- iter: 064/346
[A[ATraining Step: 234  | total loss: [1m[32m0.10940[0m[0m | time: 3.922s
[2K
| Adam | epoch: 022 | loss: 0.10940 - acc: 0.9602 -- iter: 096/346
[A[ATraining Step: 235  | total loss: [1m[32m0.10663[0m[0m | time: 4.778s
[2K
| Adam | epoch: 022 | loss: 0.10663 - acc: 0.9642 -- iter: 128/346
[A[ATraining Step: 236  | total loss: [1m[32m0.09848[0m[0m | time: 5.801s
[2K
| Adam | epoch: 022 | loss: 0.09848 - acc: 0.9678 -- iter: 160/346
[A[ATraining Step: 237  | total loss: [1m[32m0.09458[0m[0m | time: 6.764s
[2K
| Adam | epoch: 022 | loss: 0.09458 - acc: 0.9679 -- iter: 192/346
[A[ATraining Step: 238  | total loss: [1m[32m0.09385[0m[0m | time: 7.703s
[2K
| Adam | epoch: 022 | loss: 0.09385 - acc: 0.9648 -- iter: 224/346
[A[ATraining Step: 239  | total loss: [1m[32m0.09895[0m[0m | time: 8.607s
[2K
| Adam | epoch: 022 | loss: 0.09895 - acc: 0.9652 -- iter: 256/346
[A[ATraining Step: 240  | total loss: [1m[32m0.09042[0m[0m | time: 9.547s
[2K
| Adam | epoch: 022 | loss: 0.09042 - acc: 0.9687 -- iter: 288/346
[A[ATraining Step: 241  | total loss: [1m[32m0.08263[0m[0m | time: 10.470s
[2K
| Adam | epoch: 022 | loss: 0.08263 - acc: 0.9718 -- iter: 320/346
[A[ATraining Step: 242  | total loss: [1m[32m0.08451[0m[0m | time: 12.420s
[2K
| Adam | epoch: 022 | loss: 0.08451 - acc: 0.9684 | val_loss: 0.88537 - val_acc: 0.7706 -- iter: 346/346
--
Training Step: 243  | total loss: [1m[32m0.07845[0m[0m | time: 0.635s
[2K
| Adam | epoch: 023 | loss: 0.07845 - acc: 0.9716 -- iter: 032/346
[A[ATraining Step: 244  | total loss: [1m[32m0.13585[0m[0m | time: 1.252s
[2K
| Adam | epoch: 023 | loss: 0.13585 - acc: 0.9619 -- iter: 064/346
[A[ATraining Step: 245  | total loss: [1m[32m0.13714[0m[0m | time: 1.867s
[2K
| Adam | epoch: 023 | loss: 0.13714 - acc: 0.9595 -- iter: 096/346
[A[ATraining Step: 246  | total loss: [1m[32m0.13945[0m[0m | time: 2.491s
[2K
| Adam | epoch: 023 | loss: 0.13945 - acc: 0.9573 -- iter: 128/346
[A[ATraining Step: 247  | total loss: [1m[32m0.12673[0m[0m | time: 3.095s
[2K
| Adam | epoch: 023 | loss: 0.12673 - acc: 0.9615 -- iter: 160/346
[A[ATraining Step: 248  | total loss: [1m[32m0.12450[0m[0m | time: 3.723s
[2K
| Adam | epoch: 023 | loss: 0.12450 - acc: 0.9591 -- iter: 192/346
[A[ATraining Step: 249  | total loss: [1m[32m0.12433[0m[0m | time: 4.331s
[2K
| Adam | epoch: 023 | loss: 0.12433 - acc: 0.9570 -- iter: 224/346
[A[ATraining Step: 250  | total loss: [1m[32m0.11497[0m[0m | time: 4.984s
[2K
| Adam | epoch: 023 | loss: 0.11497 - acc: 0.9613 -- iter: 256/346
[A[ATraining Step: 251  | total loss: [1m[32m0.11790[0m[0m | time: 5.495s
[2K
| Adam | epoch: 023 | loss: 0.11790 - acc: 0.9589 -- iter: 288/346
[A[ATraining Step: 252  | total loss: [1m[32m0.10753[0m[0m | time: 5.990s
[2K
| Adam | epoch: 023 | loss: 0.10753 - acc: 0.9630 -- iter: 320/346
[A[ATraining Step: 253  | total loss: [1m[32m0.09812[0m[0m | time: 7.604s
[2K
| Adam | epoch: 023 | loss: 0.09812 - acc: 0.9667 | val_loss: 0.52916 - val_acc: 0.8257 -- iter: 346/346
--
Training Step: 254  | total loss: [1m[32m0.09243[0m[0m | time: 0.638s
[2K
| Adam | epoch: 024 | loss: 0.09243 - acc: 0.9700 -- iter: 032/346
[A[ATraining Step: 255  | total loss: [1m[32m0.08931[0m[0m | time: 1.231s
[2K
| Adam | epoch: 024 | loss: 0.08931 - acc: 0.9730 -- iter: 064/346
[A[ATraining Step: 256  | total loss: [1m[32m0.08225[0m[0m | time: 1.841s
[2K
| Adam | epoch: 024 | loss: 0.08225 - acc: 0.9757 -- iter: 096/346
[A[ATraining Step: 257  | total loss: [1m[32m0.07806[0m[0m | time: 2.453s
[2K
| Adam | epoch: 024 | loss: 0.07806 - acc: 0.9782 -- iter: 128/346
[A[ATraining Step: 258  | total loss: [1m[32m0.07496[0m[0m | time: 3.049s
[2K
| Adam | epoch: 024 | loss: 0.07496 - acc: 0.9803 -- iter: 160/346
[A[ATraining Step: 259  | total loss: [1m[32m0.07088[0m[0m | time: 3.661s
[2K
| Adam | epoch: 024 | loss: 0.07088 - acc: 0.9823 -- iter: 192/346
[A[ATraining Step: 260  | total loss: [1m[32m0.06716[0m[0m | time: 4.256s
[2K
| Adam | epoch: 024 | loss: 0.06716 - acc: 0.9841 -- iter: 224/346
[A[ATraining Step: 261  | total loss: [1m[32m0.06238[0m[0m | time: 4.850s
[2K
| Adam | epoch: 024 | loss: 0.06238 - acc: 0.9857 -- iter: 256/346
[A[ATraining Step: 262  | total loss: [1m[32m0.05973[0m[0m | time: 5.481s
[2K
| Adam | epoch: 024 | loss: 0.05973 - acc: 0.9871 -- iter: 288/346
[A[ATraining Step: 263  | total loss: [1m[32m0.05516[0m[0m | time: 6.020s
[2K
| Adam | epoch: 024 | loss: 0.05516 - acc: 0.9884 -- iter: 320/346
[A[ATraining Step: 264  | total loss: [1m[32m0.05218[0m[0m | time: 7.554s
[2K
| Adam | epoch: 024 | loss: 0.05218 - acc: 0.9896 | val_loss: 0.59875 - val_acc: 0.8165 -- iter: 346/346
--
Training Step: 265  | total loss: [1m[32m0.04865[0m[0m | time: 1.343s
[2K
| Adam | epoch: 025 | loss: 0.04865 - acc: 0.9906 -- iter: 032/346
[A[ATraining Step: 266  | total loss: [1m[32m0.04442[0m[0m | time: 2.551s
[2K
| Adam | epoch: 025 | loss: 0.04442 - acc: 0.9915 -- iter: 064/346
[A[ATraining Step: 267  | total loss: [1m[32m0.04128[0m[0m | time: 3.412s
[2K
| Adam | epoch: 025 | loss: 0.04128 - acc: 0.9924 -- iter: 096/346
[A[ATraining Step: 268  | total loss: [1m[32m0.05969[0m[0m | time: 4.406s
[2K
| Adam | epoch: 025 | loss: 0.05969 - acc: 0.9900 -- iter: 128/346
[A[ATraining Step: 269  | total loss: [1m[32m0.05445[0m[0m | time: 5.399s
[2K
| Adam | epoch: 025 | loss: 0.05445 - acc: 0.9910 -- iter: 160/346
[A[ATraining Step: 270  | total loss: [1m[32m0.05099[0m[0m | time: 6.417s
[2K
| Adam | epoch: 025 | loss: 0.05099 - acc: 0.9919 -- iter: 192/346
[A[ATraining Step: 271  | total loss: [1m[32m0.04649[0m[0m | time: 7.504s
[2K
| Adam | epoch: 025 | loss: 0.04649 - acc: 0.9927 -- iter: 224/346
[A[ATraining Step: 272  | total loss: [1m[32m0.04223[0m[0m | time: 8.594s
[2K
| Adam | epoch: 025 | loss: 0.04223 - acc: 0.9935 -- iter: 256/346
[A[ATraining Step: 273  | total loss: [1m[32m0.03837[0m[0m | time: 9.425s
[2K
| Adam | epoch: 025 | loss: 0.03837 - acc: 0.9941 -- iter: 288/346
[A[ATraining Step: 274  | total loss: [1m[32m0.03490[0m[0m | time: 10.718s
[2K
| Adam | epoch: 025 | loss: 0.03490 - acc: 0.9947 -- iter: 320/346
[A[ATraining Step: 275  | total loss: [1m[32m0.03179[0m[0m | time: 12.766s
[2K
| Adam | epoch: 025 | loss: 0.03179 - acc: 0.9952 | val_loss: 0.76744 - val_acc: 0.8165 -- iter: 346/346
--
Training Step: 276  | total loss: [1m[32m0.02906[0m[0m | time: 0.789s
[2K
| Adam | epoch: 026 | loss: 0.02906 - acc: 0.9957 -- iter: 032/346
[A[ATraining Step: 277  | total loss: [1m[32m0.02654[0m[0m | time: 1.716s
[2K
| Adam | epoch: 026 | loss: 0.02654 - acc: 0.9961 -- iter: 064/346
[A[ATraining Step: 278  | total loss: [1m[32m0.02482[0m[0m | time: 2.653s
[2K
| Adam | epoch: 026 | loss: 0.02482 - acc: 0.9965 -- iter: 096/346
[A[ATraining Step: 279  | total loss: [1m[32m0.02253[0m[0m | time: 3.762s
[2K
| Adam | epoch: 026 | loss: 0.02253 - acc: 0.9969 -- iter: 128/346
[A[ATraining Step: 280  | total loss: [1m[32m0.06221[0m[0m | time: 4.782s
[2K
| Adam | epoch: 026 | loss: 0.06221 - acc: 0.9909 -- iter: 160/346
[A[ATraining Step: 281  | total loss: [1m[32m0.05652[0m[0m | time: 5.632s
[2K
| Adam | epoch: 026 | loss: 0.05652 - acc: 0.9918 -- iter: 192/346
[A[ATraining Step: 282  | total loss: [1m[32m0.05165[0m[0m | time: 6.839s
[2K
| Adam | epoch: 026 | loss: 0.05165 - acc: 0.9927 -- iter: 224/346
[A[ATraining Step: 283  | total loss: [1m[32m0.04688[0m[0m | time: 8.174s
[2K
| Adam | epoch: 026 | loss: 0.04688 - acc: 0.9934 -- iter: 256/346
[A[ATraining Step: 284  | total loss: [1m[32m0.04261[0m[0m | time: 9.417s
[2K
| Adam | epoch: 026 | loss: 0.04261 - acc: 0.9941 -- iter: 288/346
[A[ATraining Step: 285  | total loss: [1m[32m0.03874[0m[0m | time: 10.293s
[2K
| Adam | epoch: 026 | loss: 0.03874 - acc: 0.9946 -- iter: 320/346
[A[ATraining Step: 286  | total loss: [1m[32m0.03534[0m[0m | time: 12.299s
[2K
| Adam | epoch: 026 | loss: 0.03534 - acc: 0.9952 | val_loss: 0.58155 - val_acc: 0.8532 -- iter: 346/346
--
Training Step: 287  | total loss: [1m[32m0.03254[0m[0m | time: 0.745s
[2K
| Adam | epoch: 027 | loss: 0.03254 - acc: 0.9957 -- iter: 032/346
[A[ATraining Step: 288  | total loss: [1m[32m0.03873[0m[0m | time: 1.705s
[2K
| Adam | epoch: 027 | loss: 0.03873 - acc: 0.9923 -- iter: 064/346
[A[ATraining Step: 289  | total loss: [1m[32m0.03644[0m[0m | time: 2.960s
[2K
| Adam | epoch: 027 | loss: 0.03644 - acc: 0.9930 -- iter: 096/346
[A[ATraining Step: 290  | total loss: [1m[32m0.03547[0m[0m | time: 4.104s
[2K
| Adam | epoch: 027 | loss: 0.03547 - acc: 0.9937 -- iter: 128/346
[A[ATraining Step: 291  | total loss: [1m[32m0.03988[0m[0m | time: 5.011s
[2K
| Adam | epoch: 027 | loss: 0.03988 - acc: 0.9912 -- iter: 160/346
[A[ATraining Step: 292  | total loss: [1m[32m0.04508[0m[0m | time: 5.973s
[2K
| Adam | epoch: 027 | loss: 0.04508 - acc: 0.9890 -- iter: 192/346
[A[ATraining Step: 293  | total loss: [1m[32m0.04314[0m[0m | time: 6.914s
[2K
| Adam | epoch: 027 | loss: 0.04314 - acc: 0.9901 -- iter: 224/346
[A[ATraining Step: 294  | total loss: [1m[32m0.07428[0m[0m | time: 7.948s
[2K
| Adam | epoch: 027 | loss: 0.07428 - acc: 0.9786 -- iter: 256/346
[A[ATraining Step: 295  | total loss: [1m[32m0.07824[0m[0m | time: 8.808s
[2K
| Adam | epoch: 027 | loss: 0.07824 - acc: 0.9713 -- iter: 288/346
[A[ATraining Step: 296  | total loss: [1m[32m0.07166[0m[0m | time: 9.912s
[2K
| Adam | epoch: 027 | loss: 0.07166 - acc: 0.9742 -- iter: 320/346
[A[ATraining Step: 297  | total loss: [1m[32m0.06685[0m[0m | time: 12.151s
[2K
| Adam | epoch: 027 | loss: 0.06685 - acc: 0.9768 | val_loss: 0.66266 - val_acc: 0.8257 -- iter: 346/346
--
Training Step: 298  | total loss: [1m[32m0.06511[0m[0m | time: 1.006s
[2K
| Adam | epoch: 028 | loss: 0.06511 - acc: 0.9760 -- iter: 032/346
[A[ATraining Step: 299  | total loss: [1m[32m0.06522[0m[0m | time: 1.953s
[2K
| Adam | epoch: 028 | loss: 0.06522 - acc: 0.9784 -- iter: 064/346
[A[ATraining Step: 300  | total loss: [1m[32m0.07137[0m[0m | time: 2.684s
[2K
| Adam | epoch: 028 | loss: 0.07137 - acc: 0.9767 -- iter: 096/346
[A[ATraining Step: 301  | total loss: [1m[32m0.07258[0m[0m | time: 3.769s
[2K
| Adam | epoch: 028 | loss: 0.07258 - acc: 0.9752 -- iter: 128/346
[A[ATraining Step: 302  | total loss: [1m[32m0.06656[0m[0m | time: 4.764s
[2K
| Adam | epoch: 028 | loss: 0.06656 - acc: 0.9777 -- iter: 160/346
[A[ATraining Step: 303  | total loss: [1m[32m0.06342[0m[0m | time: 5.633s
[2K
| Adam | epoch: 028 | loss: 0.06342 - acc: 0.9799 -- iter: 192/346
[A[ATraining Step: 304  | total loss: [1m[32m0.07561[0m[0m | time: 6.239s
[2K
| Adam | epoch: 028 | loss: 0.07561 - acc: 0.9788 -- iter: 224/346
[A[ATraining Step: 305  | total loss: [1m[32m0.06862[0m[0m | time: 6.903s
[2K
| Adam | epoch: 028 | loss: 0.06862 - acc: 0.9809 -- iter: 256/346
[A[ATraining Step: 306  | total loss: [1m[32m0.06266[0m[0m | time: 7.515s
[2K
| Adam | epoch: 028 | loss: 0.06266 - acc: 0.9828 -- iter: 288/346
[A[ATraining Step: 307  | total loss: [1m[32m0.05721[0m[0m | time: 8.154s
[2K
| Adam | epoch: 028 | loss: 0.05721 - acc: 0.9845 -- iter: 320/346
[A[ATraining Step: 308  | total loss: [1m[32m0.05557[0m[0m | time: 9.789s
[2K
| Adam | epoch: 028 | loss: 0.05557 - acc: 0.9830 | val_loss: 0.66045 - val_acc: 0.8073 -- iter: 346/346
--
Training Step: 309  | total loss: [1m[32m0.05203[0m[0m | time: 0.651s
[2K
| Adam | epoch: 029 | loss: 0.05203 - acc: 0.9847 -- iter: 032/346
[A[ATraining Step: 310  | total loss: [1m[32m0.05086[0m[0m | time: 1.267s
[2K
| Adam | epoch: 029 | loss: 0.05086 - acc: 0.9831 -- iter: 064/346
[A[ATraining Step: 311  | total loss: [1m[32m0.04944[0m[0m | time: 1.773s
[2K
| Adam | epoch: 029 | loss: 0.04944 - acc: 0.9848 -- iter: 096/346
[A[ATraining Step: 312  | total loss: [1m[32m0.04574[0m[0m | time: 2.284s
[2K
| Adam | epoch: 029 | loss: 0.04574 - acc: 0.9863 -- iter: 128/346
[A[ATraining Step: 313  | total loss: [1m[32m0.04228[0m[0m | time: 2.894s
[2K
| Adam | epoch: 029 | loss: 0.04228 - acc: 0.9877 -- iter: 160/346
[A[ATraining Step: 314  | total loss: [1m[32m0.03868[0m[0m | time: 3.515s
[2K
| Adam | epoch: 029 | loss: 0.03868 - acc: 0.9889 -- iter: 192/346
[A[ATraining Step: 315  | total loss: [1m[32m0.03527[0m[0m | time: 4.141s
[2K
| Adam | epoch: 029 | loss: 0.03527 - acc: 0.9900 -- iter: 224/346
[A[ATraining Step: 316  | total loss: [1m[32m0.07216[0m[0m | time: 4.762s
[2K
| Adam | epoch: 029 | loss: 0.07216 - acc: 0.9848 -- iter: 256/346
[A[ATraining Step: 317  | total loss: [1m[32m0.06528[0m[0m | time: 5.394s
[2K
| Adam | epoch: 029 | loss: 0.06528 - acc: 0.9863 -- iter: 288/346
[A[ATraining Step: 318  | total loss: [1m[32m0.05920[0m[0m | time: 6.021s
[2K
| Adam | epoch: 029 | loss: 0.05920 - acc: 0.9876 -- iter: 320/346
[A[ATraining Step: 319  | total loss: [1m[32m0.05413[0m[0m | time: 7.631s
[2K
| Adam | epoch: 029 | loss: 0.05413 - acc: 0.9889 | val_loss: 0.59539 - val_acc: 0.8532 -- iter: 346/346
--
Training Step: 320  | total loss: [1m[32m0.05102[0m[0m | time: 0.640s
[2K
| Adam | epoch: 030 | loss: 0.05102 - acc: 0.9900 -- iter: 032/346
[A[ATraining Step: 321  | total loss: [1m[32m0.04679[0m[0m | time: 1.267s
[2K
| Adam | epoch: 030 | loss: 0.04679 - acc: 0.9910 -- iter: 064/346
[A[ATraining Step: 322  | total loss: [1m[32m0.04266[0m[0m | time: 1.888s
[2K
| Adam | epoch: 030 | loss: 0.04266 - acc: 0.9919 -- iter: 096/346
[A[ATraining Step: 323  | total loss: [1m[32m0.03896[0m[0m | time: 2.682s
[2K
| Adam | epoch: 030 | loss: 0.03896 - acc: 0.9927 -- iter: 128/346
[A[ATraining Step: 324  | total loss: [1m[32m0.03555[0m[0m | time: 3.676s
[2K
| Adam | epoch: 030 | loss: 0.03555 - acc: 0.9934 -- iter: 160/346
[A[ATraining Step: 325  | total loss: [1m[32m0.03264[0m[0m | time: 4.955s
[2K
| Adam | epoch: 030 | loss: 0.03264 - acc: 0.9941 -- iter: 192/346
[A[ATraining Step: 326  | total loss: [1m[32m0.03040[0m[0m | time: 6.167s
[2K
| Adam | epoch: 030 | loss: 0.03040 - acc: 0.9947 -- iter: 224/346
[A[ATraining Step: 327  | total loss: [1m[32m0.02776[0m[0m | time: 7.053s
[2K
| Adam | epoch: 030 | loss: 0.02776 - acc: 0.9952 -- iter: 256/346
[A[ATraining Step: 328  | total loss: [1m[32m0.35738[0m[0m | time: 8.040s
[2K
| Adam | epoch: 030 | loss: 0.35738 - acc: 0.9457 -- iter: 288/346
[A[ATraining Step: 329  | total loss: [1m[32m0.32230[0m[0m | time: 8.979s
[2K
| Adam | epoch: 030 | loss: 0.32230 - acc: 0.9511 -- iter: 320/346
[A[ATraining Step: 330  | total loss: [1m[32m0.29106[0m[0m | time: 11.008s
[2K
| Adam | epoch: 030 | loss: 0.29106 - acc: 0.9560 | val_loss: 0.55195 - val_acc: 0.8165 -- iter: 346/346
--
Validation AUC:0.8995901639344261
Validation AUPRC:0.9347513127418492
Test AUC:0.8633603238866396
Test AUPRC:0.8490614312446758
BestTestF1Score	0.79	0.6	0.8	0.78	0.81	42	12	45	10	0.12
BestTestMCCScore	0.79	0.6	0.8	0.78	0.81	42	12	45	10	0.14
BestTestAccuracyScore	0.79	0.6	0.8	0.78	0.81	42	12	45	10	0.14
BestValidationF1Score	0.87	0.72	0.86	0.9	0.85	52	6	42	9	0.12
BestValidationMCC	0.87	0.73	0.86	0.91	0.84	51	5	43	10	0.14
BestValidationAccuracy	0.87	0.73	0.86	0.91	0.84	51	5	43	10	0.14
TestPredictions (Threshold:0.14)
CHEMBL78885,FN,ACT,0.029999999329447746	CHEMBL562198,TN,INACT,0.009999999776482582	CHEMBL373834,TN,INACT,0.03999999910593033	CHEMBL535,TP,ACT,0.8299999833106995	CHEMBL336594,TP,ACT,0.9900000095367432	CHEMBL608533,FN,ACT,0.009999999776482582	CHEMBL522760,TN,INACT,0.009999999776482582	CHEMBL454973,TP,ACT,0.9700000286102295	CHEMBL489246,TN,INACT,0.019999999552965164	CHEMBL2164411,TP,ACT,0.8899999856948853	CHEMBL483165,TP,ACT,0.9700000286102295	CHEMBL1287853,FN,ACT,0.029999999329447746	CHEMBL382945,TP,ACT,0.5600000023841858	CHEMBL490053,TN,INACT,0.009999999776482582	CHEMBL130511,TP,ACT,0.9900000095367432	CHEMBL367442,FP,INACT,0.8700000047683716	CHEMBL1087421,TN,INACT,0.009999999776482582	CHEMBL120127,TN,INACT,0.009999999776482582	CHEMBL281957,FP,INACT,0.949999988079071	CHEMBL1287945,TN,INACT,0.009999999776482582	CHEMBL79004,TP,ACT,0.9900000095367432	CHEMBL489627,TN,INACT,0.009999999776482582	CHEMBL318188,TN,INACT,0.009999999776482582	CHEMBL199837,TP,ACT,0.8500000238418579	CHEMBL2164415,TP,ACT,0.9700000286102295	CHEMBL231614,TP,ACT,0.6700000166893005	CHEMBL2346665,TN,INACT,0.019999999552965164	CHEMBL231108,TP,ACT,0.5600000023841858	CHEMBL100312,TN,INACT,0.10999999940395355	CHEMBL1767126,TN,INACT,0.019999999552965164	CHEMBL102622,TN,INACT,0.029999999329447746	CHEMBL230699,TP,ACT,0.9900000095367432	CHEMBL129981,FN,ACT,0.029999999329447746	CHEMBL523780,TN,INACT,0.03999999910593033	CHEMBL396487,TN,INACT,0.019999999552965164	CHEMBL210032,FN,ACT,0.019999999552965164	CHEMBL2420584,FP,INACT,0.33000001311302185	CHEMBL2436978,TP,ACT,0.9700000286102295	CHEMBL504727,TP,ACT,0.8899999856948853	CHEMBL1910757,FP,INACT,0.25999999046325684	CHEMBL101779,TN,INACT,0.029999999329447746	CHEMBL482946,FN,ACT,0.03999999910593033	CHEMBL249280,TP,ACT,1.0	CHEMBL1761512,TP,ACT,0.4300000071525574	CHEMBL382752,FN,ACT,0.009999999776482582	CHEMBL493745,TP,ACT,0.9900000095367432	CHEMBL1287914,TN,INACT,0.03999999910593033	CHEMBL318461,TN,INACT,0.009999999776482582	CHEMBL131382,TN,INACT,0.009999999776482582	CHEMBL133928,TP,ACT,0.949999988079071	CHEMBL456759,TN,INACT,0.0	CHEMBL3691629,TN,INACT,0.03999999910593033	CHEMBL520655,TP,ACT,0.9399999976158142	CHEMBL419069,TN,INACT,0.009999999776482582	CHEMBL512658,TN,INACT,0.029999999329447746	CHEMBL437586,TP,ACT,0.9900000095367432	CHEMBL3217993,TN,INACT,0.019999999552965164	CHEMBL230488,TP,ACT,0.6800000071525574	CHEMBL199980,TP,ACT,0.75	CHEMBL402041,FN,ACT,0.07000000029802322	CHEMBL457179,TN,INACT,0.009999999776482582	CHEMBL1773329,FP,INACT,0.9900000095367432	CHEMBL1642549,TP,ACT,0.9700000286102295	CHEMBL2392388,TN,INACT,0.009999999776482582	CHEMBL231512,TP,ACT,0.9700000286102295	CHEMBL2392242,TN,INACT,0.0	CHEMBL249103,TP,ACT,0.17000000178813934	CHEMBL82136,TP,ACT,0.6000000238418579	CHEMBL485502,TN,INACT,0.009999999776482582	CHEMBL463384,TN,INACT,0.019999999552965164	CHEMBL489344,TN,INACT,0.029999999329447746	CHEMBL86795,FP,INACT,0.5600000023841858	CHEMBL3746916,FP,INACT,0.75	CHEMBL521201,TN,INACT,0.03999999910593033	CHEMBL549303,TN,INACT,0.0	CHEMBL173453,FP,INACT,0.9300000071525574	CHEMBL551722,FP,INACT,0.4399999976158142	CHEMBL452812,TN,INACT,0.029999999329447746	CHEMBL335949,TP,ACT,0.949999988079071	CHEMBL483557,TP,ACT,0.9900000095367432	CHEMBL1222474,FN,ACT,0.07999999821186066	CHEMBL251724,TP,ACT,0.7200000286102295	CHEMBL523189,TP,ACT,0.9700000286102295	CHEMBL129857,TP,ACT,0.6700000166893005	CHEMBL249697,TP,ACT,0.7400000095367432	CHEMBL101868,TN,INACT,0.03999999910593033	CHEMBL2163610,FP,INACT,0.1599999964237213	CHEMBL77732,TN,INACT,0.019999999552965164	CHEMBL249901,TP,ACT,0.9900000095367432	CHEMBL249681,TP,ACT,0.6000000238418579	CHEMBL562370,TP,ACT,0.9700000286102295	CHEMBL95477,TN,INACT,0.029999999329447746	CHEMBL1761509,TP,ACT,0.36000001430511475	CHEMBL3691604,TN,INACT,0.0	CHEMBL1235213,FP,INACT,0.27000001072883606	CHEMBL3691660,TN,INACT,0.029999999329447746	CHEMBL3102933,TN,INACT,0.009999999776482582	CHEMBL1922211,TN,INACT,0.0	CHEMBL200832,TP,ACT,0.949999988079071	CHEMBL249279,TP,ACT,0.9900000095367432	CHEMBL563674,TN,INACT,0.029999999329447746	CHEMBL3609569,TN,INACT,0.019999999552965164	CHEMBL230761,TN,INACT,0.029999999329447746	CHEMBL370166,FN,ACT,0.009999999776482582	CHEMBL495758,FP,INACT,0.6399999856948853	CHEMBL1642545,TP,ACT,0.949999988079071	CHEMBL249721,TP,ACT,0.9599999785423279	CHEMBL81170,TP,ACT,0.7599999904632568	CHEMBL317398,TN,INACT,0.05000000074505806	

