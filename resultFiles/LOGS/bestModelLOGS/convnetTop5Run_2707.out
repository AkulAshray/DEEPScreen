CNNModel CHEMBL4899 adam 0.0005 30 256 0 0.8 False True
Number of active compounds :	165
Number of inactive compounds :	165
---------------------------------
Run id: CNNModel_CHEMBL4899_adam_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4899_adam_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 191
Validation samples: 60
--
Training Step: 1  | time: 1.096s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/191
[A[ATraining Step: 2  | total loss: [1m[32m0.62378[0m[0m | time: 2.008s
[2K
| Adam | epoch: 001 | loss: 0.62378 - acc: 0.4500 -- iter: 064/191
[A[ATraining Step: 3  | total loss: [1m[32m0.68115[0m[0m | time: 2.910s
[2K
| Adam | epoch: 001 | loss: 0.68115 - acc: 0.4653 -- iter: 096/191
[A[ATraining Step: 4  | total loss: [1m[32m0.68725[0m[0m | time: 3.829s
[2K
| Adam | epoch: 001 | loss: 0.68725 - acc: 0.6788 -- iter: 128/191
[A[ATraining Step: 5  | total loss: [1m[32m0.69301[0m[0m | time: 4.880s
[2K
| Adam | epoch: 001 | loss: 0.69301 - acc: 0.5334 -- iter: 160/191
[A[ATraining Step: 6  | total loss: [1m[32m0.69400[0m[0m | time: 6.934s
[2K
| Adam | epoch: 001 | loss: 0.69400 - acc: 0.4918 | val_loss: 0.68826 - val_acc: 0.5833 -- iter: 191/191
--
Training Step: 7  | total loss: [1m[32m0.69221[0m[0m | time: 0.856s
[2K
| Adam | epoch: 002 | loss: 0.69221 - acc: 0.5258 -- iter: 032/191
[A[ATraining Step: 8  | total loss: [1m[32m0.69091[0m[0m | time: 1.905s
[2K
| Adam | epoch: 002 | loss: 0.69091 - acc: 0.5385 -- iter: 064/191
[A[ATraining Step: 9  | total loss: [1m[32m0.69404[0m[0m | time: 3.034s
[2K
| Adam | epoch: 002 | loss: 0.69404 - acc: 0.5016 -- iter: 096/191
[A[ATraining Step: 10  | total loss: [1m[32m0.69306[0m[0m | time: 4.153s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5164 -- iter: 128/191
[A[ATraining Step: 11  | total loss: [1m[32m0.69006[0m[0m | time: 5.250s
[2K
| Adam | epoch: 002 | loss: 0.69006 - acc: 0.5530 -- iter: 160/191
[A[ATraining Step: 12  | total loss: [1m[32m0.70028[0m[0m | time: 7.473s
[2K
| Adam | epoch: 002 | loss: 0.70028 - acc: 0.4448 | val_loss: 0.68859 - val_acc: 0.5833 -- iter: 191/191
--
Training Step: 13  | total loss: [1m[32m0.69708[0m[0m | time: 0.943s
[2K
| Adam | epoch: 003 | loss: 0.69708 - acc: 0.4685 -- iter: 032/191
[A[ATraining Step: 14  | total loss: [1m[32m0.69341[0m[0m | time: 1.979s
[2K
| Adam | epoch: 003 | loss: 0.69341 - acc: 0.5144 -- iter: 064/191
[A[ATraining Step: 15  | total loss: [1m[32m0.69152[0m[0m | time: 3.180s
[2K
| Adam | epoch: 003 | loss: 0.69152 - acc: 0.5403 -- iter: 096/191
[A[ATraining Step: 16  | total loss: [1m[32m0.68921[0m[0m | time: 3.936s
[2K
| Adam | epoch: 003 | loss: 0.68921 - acc: 0.5838 -- iter: 128/191
[A[ATraining Step: 17  | total loss: [1m[32m0.69179[0m[0m | time: 4.676s
[2K
| Adam | epoch: 003 | loss: 0.69179 - acc: 0.5311 -- iter: 160/191
[A[ATraining Step: 18  | total loss: [1m[32m0.69485[0m[0m | time: 6.434s
[2K
| Adam | epoch: 003 | loss: 0.69485 - acc: 0.4771 | val_loss: 0.68810 - val_acc: 0.5833 -- iter: 191/191
--
Training Step: 19  | total loss: [1m[32m0.69195[0m[0m | time: 0.604s
[2K
| Adam | epoch: 004 | loss: 0.69195 - acc: 0.5264 -- iter: 032/191
[A[ATraining Step: 20  | total loss: [1m[32m0.69333[0m[0m | time: 1.291s
[2K
| Adam | epoch: 004 | loss: 0.69333 - acc: 0.4978 -- iter: 064/191
[A[ATraining Step: 21  | total loss: [1m[32m0.69119[0m[0m | time: 2.131s
[2K
| Adam | epoch: 004 | loss: 0.69119 - acc: 0.5335 -- iter: 096/191
[A[ATraining Step: 22  | total loss: [1m[32m0.68936[0m[0m | time: 2.918s
[2K
| Adam | epoch: 004 | loss: 0.68936 - acc: 0.5573 -- iter: 128/191
[A[ATraining Step: 23  | total loss: [1m[32m0.68651[0m[0m | time: 3.639s
[2K
| Adam | epoch: 004 | loss: 0.68651 - acc: 0.5951 -- iter: 160/191
[A[ATraining Step: 24  | total loss: [1m[32m0.68756[0m[0m | time: 5.463s
[2K
| Adam | epoch: 004 | loss: 0.68756 - acc: 0.5772 | val_loss: 0.68219 - val_acc: 0.5833 -- iter: 191/191
--
Training Step: 25  | total loss: [1m[32m0.69037[0m[0m | time: 0.720s
[2K
| Adam | epoch: 005 | loss: 0.69037 - acc: 0.5476 -- iter: 032/191
[A[ATraining Step: 26  | total loss: [1m[32m0.68864[0m[0m | time: 1.409s
[2K
| Adam | epoch: 005 | loss: 0.68864 - acc: 0.5515 -- iter: 064/191
[A[ATraining Step: 27  | total loss: [1m[32m0.68837[0m[0m | time: 2.146s
[2K
| Adam | epoch: 005 | loss: 0.68837 - acc: 0.5463 -- iter: 096/191
[A[ATraining Step: 28  | total loss: [1m[32m0.68273[0m[0m | time: 2.887s
[2K
| Adam | epoch: 005 | loss: 0.68273 - acc: 0.5710 -- iter: 128/191
[A[ATraining Step: 29  | total loss: [1m[32m0.67687[0m[0m | time: 3.651s
[2K
| Adam | epoch: 005 | loss: 0.67687 - acc: 0.5891 -- iter: 160/191
[A[ATraining Step: 30  | total loss: [1m[32m0.68986[0m[0m | time: 5.420s
[2K
| Adam | epoch: 005 | loss: 0.68986 - acc: 0.5532 | val_loss: 0.67401 - val_acc: 0.5833 -- iter: 191/191
--
Training Step: 31  | total loss: [1m[32m0.69147[0m[0m | time: 1.148s
[2K
| Adam | epoch: 006 | loss: 0.69147 - acc: 0.5481 -- iter: 032/191
[A[ATraining Step: 32  | total loss: [1m[32m0.68781[0m[0m | time: 2.357s
[2K
| Adam | epoch: 006 | loss: 0.68781 - acc: 0.5513 -- iter: 064/191
[A[ATraining Step: 33  | total loss: [1m[32m0.68411[0m[0m | time: 3.643s
[2K
| Adam | epoch: 006 | loss: 0.68411 - acc: 0.5607 -- iter: 096/191
[A[ATraining Step: 34  | total loss: [1m[32m0.68698[0m[0m | time: 4.514s
[2K
| Adam | epoch: 006 | loss: 0.68698 - acc: 0.5410 -- iter: 128/191
[A[ATraining Step: 35  | total loss: [1m[32m0.68885[0m[0m | time: 5.474s
[2K
| Adam | epoch: 006 | loss: 0.68885 - acc: 0.5223 -- iter: 160/191
[A[ATraining Step: 36  | total loss: [1m[32m0.68950[0m[0m | time: 7.529s
[2K
| Adam | epoch: 006 | loss: 0.68950 - acc: 0.5078 | val_loss: 0.68331 - val_acc: 0.5833 -- iter: 191/191
--
Training Step: 37  | total loss: [1m[32m0.68779[0m[0m | time: 1.052s
[2K
| Adam | epoch: 007 | loss: 0.68779 - acc: 0.5187 -- iter: 032/191
[A[ATraining Step: 38  | total loss: [1m[32m0.68717[0m[0m | time: 2.095s
[2K
| Adam | epoch: 007 | loss: 0.68717 - acc: 0.5212 -- iter: 064/191
[A[ATraining Step: 39  | total loss: [1m[32m0.68449[0m[0m | time: 3.239s
[2K
| Adam | epoch: 007 | loss: 0.68449 - acc: 0.5471 -- iter: 096/191
[A[ATraining Step: 40  | total loss: [1m[32m0.68560[0m[0m | time: 4.490s
[2K
| Adam | epoch: 007 | loss: 0.68560 - acc: 0.5265 -- iter: 128/191
[A[ATraining Step: 41  | total loss: [1m[32m0.68330[0m[0m | time: 5.297s
[2K
| Adam | epoch: 007 | loss: 0.68330 - acc: 0.5274 -- iter: 160/191
[A[ATraining Step: 42  | total loss: [1m[32m0.68620[0m[0m | time: 7.148s
[2K
| Adam | epoch: 007 | loss: 0.68620 - acc: 0.4963 | val_loss: 0.67432 - val_acc: 0.7000 -- iter: 191/191
--
Training Step: 43  | total loss: [1m[32m0.68641[0m[0m | time: 1.058s
[2K
| Adam | epoch: 008 | loss: 0.68641 - acc: 0.4714 -- iter: 032/191
[A[ATraining Step: 44  | total loss: [1m[32m0.68257[0m[0m | time: 1.944s
[2K
| Adam | epoch: 008 | loss: 0.68257 - acc: 0.5250 -- iter: 064/191
[A[ATraining Step: 45  | total loss: [1m[32m0.68001[0m[0m | time: 3.054s
[2K
| Adam | epoch: 008 | loss: 0.68001 - acc: 0.5473 -- iter: 096/191
[A[ATraining Step: 46  | total loss: [1m[32m0.67597[0m[0m | time: 3.878s
[2K
| Adam | epoch: 008 | loss: 0.67597 - acc: 0.5759 -- iter: 128/191
[A[ATraining Step: 47  | total loss: [1m[32m0.67293[0m[0m | time: 4.721s
[2K
| Adam | epoch: 008 | loss: 0.67293 - acc: 0.5839 -- iter: 160/191
[A[ATraining Step: 48  | total loss: [1m[32m0.66859[0m[0m | time: 6.536s
[2K
| Adam | epoch: 008 | loss: 0.66859 - acc: 0.6006 | val_loss: 0.62287 - val_acc: 0.6500 -- iter: 191/191
--
Training Step: 49  | total loss: [1m[32m0.66248[0m[0m | time: 0.965s
[2K
| Adam | epoch: 009 | loss: 0.66248 - acc: 0.6178 -- iter: 032/191
[A[ATraining Step: 50  | total loss: [1m[32m0.65473[0m[0m | time: 2.030s
[2K
| Adam | epoch: 009 | loss: 0.65473 - acc: 0.6320 -- iter: 064/191
[A[ATraining Step: 51  | total loss: [1m[32m0.64545[0m[0m | time: 2.994s
[2K
| Adam | epoch: 009 | loss: 0.64545 - acc: 0.6310 -- iter: 096/191
[A[ATraining Step: 52  | total loss: [1m[32m0.64029[0m[0m | time: 3.868s
[2K
| Adam | epoch: 009 | loss: 0.64029 - acc: 0.6488 -- iter: 128/191
[A[ATraining Step: 53  | total loss: [1m[32m0.63125[0m[0m | time: 4.903s
[2K
| Adam | epoch: 009 | loss: 0.63125 - acc: 0.6684 -- iter: 160/191
[A[ATraining Step: 54  | total loss: [1m[32m0.61138[0m[0m | time: 6.855s
[2K
| Adam | epoch: 009 | loss: 0.61138 - acc: 0.6938 | val_loss: 0.55487 - val_acc: 0.7167 -- iter: 191/191
--
Training Step: 55  | total loss: [1m[32m0.60099[0m[0m | time: 0.709s
[2K
| Adam | epoch: 010 | loss: 0.60099 - acc: 0.6974 -- iter: 032/191
[A[ATraining Step: 56  | total loss: [1m[32m0.59371[0m[0m | time: 1.434s
[2K
| Adam | epoch: 010 | loss: 0.59371 - acc: 0.6991 -- iter: 064/191
[A[ATraining Step: 57  | total loss: [1m[32m0.58592[0m[0m | time: 2.152s
[2K
| Adam | epoch: 010 | loss: 0.58592 - acc: 0.7140 -- iter: 096/191
[A[ATraining Step: 58  | total loss: [1m[32m0.58479[0m[0m | time: 2.767s
[2K
| Adam | epoch: 010 | loss: 0.58479 - acc: 0.7104 -- iter: 128/191
[A[ATraining Step: 59  | total loss: [1m[32m0.55929[0m[0m | time: 3.372s
[2K
| Adam | epoch: 010 | loss: 0.55929 - acc: 0.7283 -- iter: 160/191
[A[ATraining Step: 60  | total loss: [1m[32m0.59482[0m[0m | time: 5.007s
[2K
| Adam | epoch: 010 | loss: 0.59482 - acc: 0.7146 | val_loss: 0.62502 - val_acc: 0.6833 -- iter: 191/191
--
Training Step: 61  | total loss: [1m[32m0.61790[0m[0m | time: 0.748s
[2K
| Adam | epoch: 011 | loss: 0.61790 - acc: 0.7029 -- iter: 032/191
[A[ATraining Step: 62  | total loss: [1m[32m0.60145[0m[0m | time: 1.459s
[2K
| Adam | epoch: 011 | loss: 0.60145 - acc: 0.7130 -- iter: 064/191
[A[ATraining Step: 63  | total loss: [1m[32m0.57537[0m[0m | time: 2.532s
[2K
| Adam | epoch: 011 | loss: 0.57537 - acc: 0.7289 -- iter: 096/191
[A[ATraining Step: 64  | total loss: [1m[32m0.55700[0m[0m | time: 3.558s
[2K
| Adam | epoch: 011 | loss: 0.55700 - acc: 0.7427 -- iter: 128/191
[A[ATraining Step: 65  | total loss: [1m[32m0.56396[0m[0m | time: 4.562s
[2K
| Adam | epoch: 011 | loss: 0.56396 - acc: 0.7281 -- iter: 160/191
[A[ATraining Step: 66  | total loss: [1m[32m0.57473[0m[0m | time: 6.473s
[2K
| Adam | epoch: 011 | loss: 0.57473 - acc: 0.7194 | val_loss: 0.57019 - val_acc: 0.6833 -- iter: 191/191
--
Training Step: 67  | total loss: [1m[32m0.58275[0m[0m | time: 1.116s
[2K
| Adam | epoch: 012 | loss: 0.58275 - acc: 0.7006 -- iter: 032/191
[A[ATraining Step: 68  | total loss: [1m[32m0.56860[0m[0m | time: 2.052s
[2K
| Adam | epoch: 012 | loss: 0.56860 - acc: 0.7175 -- iter: 064/191
[A[ATraining Step: 69  | total loss: [1m[32m0.54962[0m[0m | time: 2.991s
[2K
| Adam | epoch: 012 | loss: 0.54962 - acc: 0.7286 -- iter: 096/191
[A[ATraining Step: 70  | total loss: [1m[32m0.54269[0m[0m | time: 3.906s
[2K
| Adam | epoch: 012 | loss: 0.54269 - acc: 0.7339 -- iter: 128/191
[A[ATraining Step: 71  | total loss: [1m[32m0.54209[0m[0m | time: 4.944s
[2K
| Adam | epoch: 012 | loss: 0.54209 - acc: 0.7385 -- iter: 160/191
[A[ATraining Step: 72  | total loss: [1m[32m0.53475[0m[0m | time: 7.186s
[2K
| Adam | epoch: 012 | loss: 0.53475 - acc: 0.7433 | val_loss: 0.50360 - val_acc: 0.7500 -- iter: 191/191
--
Training Step: 73  | total loss: [1m[32m0.52782[0m[0m | time: 0.989s
[2K
| Adam | epoch: 013 | loss: 0.52782 - acc: 0.7440 -- iter: 032/191
[A[ATraining Step: 74  | total loss: [1m[32m0.51730[0m[0m | time: 2.070s
[2K
| Adam | epoch: 013 | loss: 0.51730 - acc: 0.7516 -- iter: 064/191
[A[ATraining Step: 75  | total loss: [1m[32m0.49935[0m[0m | time: 3.035s
[2K
| Adam | epoch: 013 | loss: 0.49935 - acc: 0.7683 -- iter: 096/191
[A[ATraining Step: 76  | total loss: [1m[32m0.49767[0m[0m | time: 4.106s
[2K
| Adam | epoch: 013 | loss: 0.49767 - acc: 0.7630 -- iter: 128/191
[A[ATraining Step: 77  | total loss: [1m[32m0.48867[0m[0m | time: 5.246s
[2K
| Adam | epoch: 013 | loss: 0.48867 - acc: 0.7744 -- iter: 160/191
[A[ATraining Step: 78  | total loss: [1m[32m0.47863[0m[0m | time: 7.373s
[2K
| Adam | epoch: 013 | loss: 0.47863 - acc: 0.7845 | val_loss: 0.46380 - val_acc: 0.7667 -- iter: 191/191
--
Training Step: 79  | total loss: [1m[32m0.45729[0m[0m | time: 1.161s
[2K
| Adam | epoch: 014 | loss: 0.45729 - acc: 0.8004 -- iter: 032/191
[A[ATraining Step: 80  | total loss: [1m[32m0.44213[0m[0m | time: 2.305s
[2K
| Adam | epoch: 014 | loss: 0.44213 - acc: 0.8080 -- iter: 064/191
[A[ATraining Step: 81  | total loss: [1m[32m0.44957[0m[0m | time: 3.351s
[2K
| Adam | epoch: 014 | loss: 0.44957 - acc: 0.8085 -- iter: 096/191
[A[ATraining Step: 82  | total loss: [1m[32m0.43540[0m[0m | time: 4.462s
[2K
| Adam | epoch: 014 | loss: 0.43540 - acc: 0.8120 -- iter: 128/191
[A[ATraining Step: 83  | total loss: [1m[32m0.42335[0m[0m | time: 5.574s
[2K
| Adam | epoch: 014 | loss: 0.42335 - acc: 0.8183 -- iter: 160/191
[A[ATraining Step: 84  | total loss: [1m[32m0.39655[0m[0m | time: 7.657s
[2K
| Adam | epoch: 014 | loss: 0.39655 - acc: 0.8332 | val_loss: 0.48260 - val_acc: 0.8167 -- iter: 191/191
--
Training Step: 85  | total loss: [1m[32m0.36826[0m[0m | time: 0.760s
[2K
| Adam | epoch: 015 | loss: 0.36826 - acc: 0.8499 -- iter: 032/191
[A[ATraining Step: 86  | total loss: [1m[32m0.36197[0m[0m | time: 1.494s
[2K
| Adam | epoch: 015 | loss: 0.36197 - acc: 0.8555 -- iter: 064/191
[A[ATraining Step: 87  | total loss: [1m[32m0.39691[0m[0m | time: 2.256s
[2K
| Adam | epoch: 015 | loss: 0.39691 - acc: 0.8450 -- iter: 096/191
[A[ATraining Step: 88  | total loss: [1m[32m0.40355[0m[0m | time: 2.991s
[2K
| Adam | epoch: 015 | loss: 0.40355 - acc: 0.8355 -- iter: 128/191
[A[ATraining Step: 89  | total loss: [1m[32m0.37951[0m[0m | time: 3.600s
[2K
| Adam | epoch: 015 | loss: 0.37951 - acc: 0.8457 -- iter: 160/191
[A[ATraining Step: 90  | total loss: [1m[32m0.36978[0m[0m | time: 5.214s
[2K
| Adam | epoch: 015 | loss: 0.36978 - acc: 0.8549 | val_loss: 0.47935 - val_acc: 0.7667 -- iter: 191/191
--
Training Step: 91  | total loss: [1m[32m0.35840[0m[0m | time: 0.747s
[2K
| Adam | epoch: 016 | loss: 0.35840 - acc: 0.8533 -- iter: 032/191
[A[ATraining Step: 92  | total loss: [1m[32m0.34216[0m[0m | time: 1.475s
[2K
| Adam | epoch: 016 | loss: 0.34216 - acc: 0.8647 -- iter: 064/191
[A[ATraining Step: 93  | total loss: [1m[32m0.32848[0m[0m | time: 2.221s
[2K
| Adam | epoch: 016 | loss: 0.32848 - acc: 0.8720 -- iter: 096/191
[A[ATraining Step: 94  | total loss: [1m[32m0.32065[0m[0m | time: 2.953s
[2K
| Adam | epoch: 016 | loss: 0.32065 - acc: 0.8754 -- iter: 128/191
[A[ATraining Step: 95  | total loss: [1m[32m0.31282[0m[0m | time: 3.557s
[2K
| Adam | epoch: 016 | loss: 0.31282 - acc: 0.8754 -- iter: 160/191
[A[ATraining Step: 96  | total loss: [1m[32m0.30479[0m[0m | time: 5.172s
[2K
| Adam | epoch: 016 | loss: 0.30479 - acc: 0.8816 | val_loss: 0.58806 - val_acc: 0.7333 -- iter: 191/191
--
Training Step: 97  | total loss: [1m[32m0.29123[0m[0m | time: 0.728s
[2K
| Adam | epoch: 017 | loss: 0.29123 - acc: 0.8872 -- iter: 032/191
[A[ATraining Step: 98  | total loss: [1m[32m0.28738[0m[0m | time: 1.445s
[2K
| Adam | epoch: 017 | loss: 0.28738 - acc: 0.8888 -- iter: 064/191
[A[ATraining Step: 99  | total loss: [1m[32m0.28068[0m[0m | time: 2.203s
[2K
| Adam | epoch: 017 | loss: 0.28068 - acc: 0.8934 -- iter: 096/191
[A[ATraining Step: 100  | total loss: [1m[32m0.27062[0m[0m | time: 2.945s
[2K
| Adam | epoch: 017 | loss: 0.27062 - acc: 0.8979 -- iter: 128/191
[A[ATraining Step: 101  | total loss: [1m[32m0.25935[0m[0m | time: 3.547s
[2K
| Adam | epoch: 017 | loss: 0.25935 - acc: 0.9049 -- iter: 160/191
[A[ATraining Step: 102  | total loss: [1m[32m0.26986[0m[0m | time: 5.155s
[2K
| Adam | epoch: 017 | loss: 0.26986 - acc: 0.9019 | val_loss: 0.46513 - val_acc: 0.8500 -- iter: 191/191
--
Training Step: 103  | total loss: [1m[32m0.28720[0m[0m | time: 0.966s
[2K
| Adam | epoch: 018 | loss: 0.28720 - acc: 0.8930 -- iter: 032/191
[A[ATraining Step: 104  | total loss: [1m[32m0.27454[0m[0m | time: 2.053s
[2K
| Adam | epoch: 018 | loss: 0.27454 - acc: 0.8975 -- iter: 064/191
[A[ATraining Step: 105  | total loss: [1m[32m0.26099[0m[0m | time: 2.949s
[2K
| Adam | epoch: 018 | loss: 0.26099 - acc: 0.9045 -- iter: 096/191
[A[ATraining Step: 106  | total loss: [1m[32m0.25036[0m[0m | time: 3.888s
[2K
| Adam | epoch: 018 | loss: 0.25036 - acc: 0.9108 -- iter: 128/191
[A[ATraining Step: 107  | total loss: [1m[32m0.25762[0m[0m | time: 4.938s
[2K
| Adam | epoch: 018 | loss: 0.25762 - acc: 0.9072 -- iter: 160/191
[A[ATraining Step: 108  | total loss: [1m[32m0.24891[0m[0m | time: 7.019s
[2K
| Adam | epoch: 018 | loss: 0.24891 - acc: 0.9071 | val_loss: 0.46744 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 109  | total loss: [1m[32m0.24194[0m[0m | time: 1.268s
[2K
| Adam | epoch: 019 | loss: 0.24194 - acc: 0.9102 -- iter: 032/191
[A[ATraining Step: 110  | total loss: [1m[32m0.22751[0m[0m | time: 2.292s
[2K
| Adam | epoch: 019 | loss: 0.22751 - acc: 0.9160 -- iter: 064/191
[A[ATraining Step: 111  | total loss: [1m[32m0.21689[0m[0m | time: 3.063s
[2K
| Adam | epoch: 019 | loss: 0.21689 - acc: 0.9213 -- iter: 096/191
[A[ATraining Step: 112  | total loss: [1m[32m0.20816[0m[0m | time: 4.042s
[2K
| Adam | epoch: 019 | loss: 0.20816 - acc: 0.9227 -- iter: 128/191
[A[ATraining Step: 113  | total loss: [1m[32m0.19904[0m[0m | time: 5.058s
[2K
| Adam | epoch: 019 | loss: 0.19904 - acc: 0.9272 -- iter: 160/191
[A[ATraining Step: 114  | total loss: [1m[32m0.21040[0m[0m | time: 7.157s
[2K
| Adam | epoch: 019 | loss: 0.21040 - acc: 0.9189 | val_loss: 0.46144 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 115  | total loss: [1m[32m0.21890[0m[0m | time: 0.838s
[2K
| Adam | epoch: 020 | loss: 0.21890 - acc: 0.9207 -- iter: 032/191
[A[ATraining Step: 116  | total loss: [1m[32m0.20919[0m[0m | time: 1.862s
[2K
| Adam | epoch: 020 | loss: 0.20919 - acc: 0.9255 -- iter: 064/191
[A[ATraining Step: 117  | total loss: [1m[32m0.19798[0m[0m | time: 2.935s
[2K
| Adam | epoch: 020 | loss: 0.19798 - acc: 0.9330 -- iter: 096/191
[A[ATraining Step: 118  | total loss: [1m[32m0.18301[0m[0m | time: 3.897s
[2K
| Adam | epoch: 020 | loss: 0.18301 - acc: 0.9397 -- iter: 128/191
[A[ATraining Step: 119  | total loss: [1m[32m0.18953[0m[0m | time: 4.921s
[2K
| Adam | epoch: 020 | loss: 0.18953 - acc: 0.9328 -- iter: 160/191
[A[ATraining Step: 120  | total loss: [1m[32m0.19370[0m[0m | time: 6.986s
[2K
| Adam | epoch: 020 | loss: 0.19370 - acc: 0.9266 | val_loss: 0.53918 - val_acc: 0.7500 -- iter: 191/191
--
Training Step: 121  | total loss: [1m[32m0.18267[0m[0m | time: 1.154s
[2K
| Adam | epoch: 021 | loss: 0.18267 - acc: 0.9340 -- iter: 032/191
[A[ATraining Step: 122  | total loss: [1m[32m0.18555[0m[0m | time: 2.063s
[2K
| Adam | epoch: 021 | loss: 0.18555 - acc: 0.9343 -- iter: 064/191
[A[ATraining Step: 123  | total loss: [1m[32m0.17613[0m[0m | time: 2.904s
[2K
| Adam | epoch: 021 | loss: 0.17613 - acc: 0.9378 -- iter: 096/191
[A[ATraining Step: 124  | total loss: [1m[32m0.17420[0m[0m | time: 3.982s
[2K
| Adam | epoch: 021 | loss: 0.17420 - acc: 0.9377 -- iter: 128/191
[A[ATraining Step: 125  | total loss: [1m[32m0.16770[0m[0m | time: 4.841s
[2K
| Adam | epoch: 021 | loss: 0.16770 - acc: 0.9408 -- iter: 160/191
[A[ATraining Step: 126  | total loss: [1m[32m0.15854[0m[0m | time: 6.809s
[2K
| Adam | epoch: 021 | loss: 0.15854 - acc: 0.9468 | val_loss: 0.52359 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 127  | total loss: [1m[32m0.14756[0m[0m | time: 0.838s
[2K
| Adam | epoch: 022 | loss: 0.14756 - acc: 0.9521 -- iter: 032/191
[A[ATraining Step: 128  | total loss: [1m[32m0.13753[0m[0m | time: 1.699s
[2K
| Adam | epoch: 022 | loss: 0.13753 - acc: 0.9569 -- iter: 064/191
[A[ATraining Step: 129  | total loss: [1m[32m0.15039[0m[0m | time: 2.624s
[2K
| Adam | epoch: 022 | loss: 0.15039 - acc: 0.9518 -- iter: 096/191
[A[ATraining Step: 130  | total loss: [1m[32m0.13953[0m[0m | time: 3.788s
[2K
| Adam | epoch: 022 | loss: 0.13953 - acc: 0.9535 -- iter: 128/191
[A[ATraining Step: 131  | total loss: [1m[32m0.12773[0m[0m | time: 5.059s
[2K
| Adam | epoch: 022 | loss: 0.12773 - acc: 0.9582 -- iter: 160/191
[A[ATraining Step: 132  | total loss: [1m[32m0.13012[0m[0m | time: 6.979s
[2K
| Adam | epoch: 022 | loss: 0.13012 - acc: 0.9561 | val_loss: 0.54843 - val_acc: 0.8167 -- iter: 191/191
--
Training Step: 133  | total loss: [1m[32m0.13756[0m[0m | time: 1.038s
[2K
| Adam | epoch: 023 | loss: 0.13756 - acc: 0.9540 -- iter: 032/191
[A[ATraining Step: 134  | total loss: [1m[32m0.13373[0m[0m | time: 2.017s
[2K
| Adam | epoch: 023 | loss: 0.13373 - acc: 0.9522 -- iter: 064/191
[A[ATraining Step: 135  | total loss: [1m[32m0.14646[0m[0m | time: 3.054s
[2K
| Adam | epoch: 023 | loss: 0.14646 - acc: 0.9476 -- iter: 096/191
[A[ATraining Step: 136  | total loss: [1m[32m0.18046[0m[0m | time: 4.038s
[2K
| Adam | epoch: 023 | loss: 0.18046 - acc: 0.9434 -- iter: 128/191
[A[ATraining Step: 137  | total loss: [1m[32m0.16876[0m[0m | time: 5.131s
[2K
| Adam | epoch: 023 | loss: 0.16876 - acc: 0.9460 -- iter: 160/191
[A[ATraining Step: 138  | total loss: [1m[32m0.15653[0m[0m | time: 7.403s
[2K
| Adam | epoch: 023 | loss: 0.15653 - acc: 0.9514 | val_loss: 0.62136 - val_acc: 0.7833 -- iter: 191/191
--
Training Step: 139  | total loss: [1m[32m0.15284[0m[0m | time: 0.942s
[2K
| Adam | epoch: 024 | loss: 0.15284 - acc: 0.9531 -- iter: 032/191
[A[ATraining Step: 140  | total loss: [1m[32m0.14638[0m[0m | time: 2.017s
[2K
| Adam | epoch: 024 | loss: 0.14638 - acc: 0.9546 -- iter: 064/191
[A[ATraining Step: 141  | total loss: [1m[32m0.13842[0m[0m | time: 3.116s
[2K
| Adam | epoch: 024 | loss: 0.13842 - acc: 0.9591 -- iter: 096/191
[A[ATraining Step: 142  | total loss: [1m[32m0.12646[0m[0m | time: 4.208s
[2K
| Adam | epoch: 024 | loss: 0.12646 - acc: 0.9632 -- iter: 128/191
[A[ATraining Step: 143  | total loss: [1m[32m0.11817[0m[0m | time: 5.268s
[2K
| Adam | epoch: 024 | loss: 0.11817 - acc: 0.9669 -- iter: 160/191
[A[ATraining Step: 144  | total loss: [1m[32m0.11122[0m[0m | time: 7.295s
[2K
| Adam | epoch: 024 | loss: 0.11122 - acc: 0.9702 | val_loss: 0.55811 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 145  | total loss: [1m[32m0.11525[0m[0m | time: 0.612s
[2K
| Adam | epoch: 025 | loss: 0.11525 - acc: 0.9701 -- iter: 032/191
[A[ATraining Step: 146  | total loss: [1m[32m0.12176[0m[0m | time: 1.324s
[2K
| Adam | epoch: 025 | loss: 0.12176 - acc: 0.9699 -- iter: 064/191
[A[ATraining Step: 147  | total loss: [1m[32m0.11125[0m[0m | time: 2.059s
[2K
| Adam | epoch: 025 | loss: 0.11125 - acc: 0.9729 -- iter: 096/191
[A[ATraining Step: 148  | total loss: [1m[32m0.10305[0m[0m | time: 2.791s
[2K
| Adam | epoch: 025 | loss: 0.10305 - acc: 0.9756 -- iter: 128/191
[A[ATraining Step: 149  | total loss: [1m[32m0.10451[0m[0m | time: 3.528s
[2K
| Adam | epoch: 025 | loss: 0.10451 - acc: 0.9749 -- iter: 160/191
[A[ATraining Step: 150  | total loss: [1m[32m0.10873[0m[0m | time: 5.375s
[2K
| Adam | epoch: 025 | loss: 0.10873 - acc: 0.9743 | val_loss: 0.57075 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 151  | total loss: [1m[32m0.09914[0m[0m | time: 0.776s
[2K
| Adam | epoch: 026 | loss: 0.09914 - acc: 0.9769 -- iter: 032/191
[A[ATraining Step: 152  | total loss: [1m[32m0.09225[0m[0m | time: 1.538s
[2K
| Adam | epoch: 026 | loss: 0.09225 - acc: 0.9792 -- iter: 064/191
[A[ATraining Step: 153  | total loss: [1m[32m0.09864[0m[0m | time: 2.261s
[2K
| Adam | epoch: 026 | loss: 0.09864 - acc: 0.9750 -- iter: 096/191
[A[ATraining Step: 154  | total loss: [1m[32m0.09819[0m[0m | time: 3.005s
[2K
| Adam | epoch: 026 | loss: 0.09819 - acc: 0.9711 -- iter: 128/191
[A[ATraining Step: 155  | total loss: [1m[32m0.09015[0m[0m | time: 3.756s
[2K
| Adam | epoch: 026 | loss: 0.09015 - acc: 0.9740 -- iter: 160/191
[A[ATraining Step: 156  | total loss: [1m[32m0.10950[0m[0m | time: 5.476s
[2K
| Adam | epoch: 026 | loss: 0.10950 - acc: 0.9672 | val_loss: 0.67302 - val_acc: 0.7667 -- iter: 191/191
--
Training Step: 157  | total loss: [1m[32m0.11964[0m[0m | time: 0.802s
[2K
| Adam | epoch: 027 | loss: 0.11964 - acc: 0.9642 -- iter: 032/191
[A[ATraining Step: 158  | total loss: [1m[32m0.12381[0m[0m | time: 1.560s
[2K
| Adam | epoch: 027 | loss: 0.12381 - acc: 0.9647 -- iter: 064/191
[A[ATraining Step: 159  | total loss: [1m[32m0.11617[0m[0m | time: 2.305s
[2K
| Adam | epoch: 027 | loss: 0.11617 - acc: 0.9651 -- iter: 096/191
[A[ATraining Step: 160  | total loss: [1m[32m0.10513[0m[0m | time: 3.015s
[2K
| Adam | epoch: 027 | loss: 0.10513 - acc: 0.9686 -- iter: 128/191
[A[ATraining Step: 161  | total loss: [1m[32m0.10317[0m[0m | time: 3.719s
[2K
| Adam | epoch: 027 | loss: 0.10317 - acc: 0.9685 -- iter: 160/191
[A[ATraining Step: 162  | total loss: [1m[32m0.10201[0m[0m | time: 5.351s
[2K
| Adam | epoch: 027 | loss: 0.10201 - acc: 0.9684 | val_loss: 0.56725 - val_acc: 0.8500 -- iter: 191/191
--
Training Step: 163  | total loss: [1m[32m0.09933[0m[0m | time: 0.716s
[2K
| Adam | epoch: 028 | loss: 0.09933 - acc: 0.9685 -- iter: 032/191
[A[ATraining Step: 164  | total loss: [1m[32m0.10700[0m[0m | time: 1.392s
[2K
| Adam | epoch: 028 | loss: 0.10700 - acc: 0.9622 -- iter: 064/191
[A[ATraining Step: 165  | total loss: [1m[32m0.10177[0m[0m | time: 2.114s
[2K
| Adam | epoch: 028 | loss: 0.10177 - acc: 0.9629 -- iter: 096/191
[A[ATraining Step: 166  | total loss: [1m[32m0.09333[0m[0m | time: 2.789s
[2K
| Adam | epoch: 028 | loss: 0.09333 - acc: 0.9666 -- iter: 128/191
[A[ATraining Step: 167  | total loss: [1m[32m0.08475[0m[0m | time: 3.871s
[2K
| Adam | epoch: 028 | loss: 0.08475 - acc: 0.9699 -- iter: 160/191
[A[ATraining Step: 168  | total loss: [1m[32m0.08290[0m[0m | time: 6.108s
[2K
| Adam | epoch: 028 | loss: 0.08290 - acc: 0.9697 | val_loss: 0.61119 - val_acc: 0.8000 -- iter: 191/191
--
Training Step: 169  | total loss: [1m[32m0.08159[0m[0m | time: 1.332s
[2K
| Adam | epoch: 029 | loss: 0.08159 - acc: 0.9695 -- iter: 032/191
[A[ATraining Step: 170  | total loss: [1m[32m0.07422[0m[0m | time: 2.506s
[2K
| Adam | epoch: 029 | loss: 0.07422 - acc: 0.9726 -- iter: 064/191
[A[ATraining Step: 171  | total loss: [1m[32m0.10229[0m[0m | time: 3.365s
[2K
| Adam | epoch: 029 | loss: 0.10229 - acc: 0.9691 -- iter: 096/191
[A[ATraining Step: 172  | total loss: [1m[32m0.10668[0m[0m | time: 3.990s
[2K
| Adam | epoch: 029 | loss: 0.10668 - acc: 0.9659 -- iter: 128/191
[A[ATraining Step: 173  | total loss: [1m[32m0.10696[0m[0m | time: 4.601s
[2K
| Adam | epoch: 029 | loss: 0.10696 - acc: 0.9631 -- iter: 160/191
[A[ATraining Step: 174  | total loss: [1m[32m0.09733[0m[0m | time: 6.270s
[2K
| Adam | epoch: 029 | loss: 0.09733 - acc: 0.9668 | val_loss: 0.63538 - val_acc: 0.8167 -- iter: 191/191
--
Training Step: 175  | total loss: [1m[32m0.10604[0m[0m | time: 0.672s
[2K
| Adam | epoch: 030 | loss: 0.10604 - acc: 0.9604 -- iter: 032/191
[A[ATraining Step: 176  | total loss: [1m[32m0.10889[0m[0m | time: 1.291s
[2K
| Adam | epoch: 030 | loss: 0.10889 - acc: 0.9547 -- iter: 064/191
[A[ATraining Step: 177  | total loss: [1m[32m0.10132[0m[0m | time: 1.915s
[2K
| Adam | epoch: 030 | loss: 0.10132 - acc: 0.9592 -- iter: 096/191
[A[ATraining Step: 178  | total loss: [1m[32m0.10982[0m[0m | time: 2.518s
[2K
| Adam | epoch: 030 | loss: 0.10982 - acc: 0.9602 -- iter: 128/191
[A[ATraining Step: 179  | total loss: [1m[32m0.11682[0m[0m | time: 3.135s
[2K
| Adam | epoch: 030 | loss: 0.11682 - acc: 0.9610 -- iter: 160/191
[A[ATraining Step: 180  | total loss: [1m[32m0.10875[0m[0m | time: 4.739s
[2K
| Adam | epoch: 030 | loss: 0.10875 - acc: 0.9649 | val_loss: 0.52336 - val_acc: 0.8000 -- iter: 191/191
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8925714285714286
Validation AUPRC:0.8261600803532263
Test AUC:0.88
Test AUPRC:0.8388415610327564
BestTestF1Score	0.83	0.64	0.82	0.77	0.9	27	8	22	3	0.23
BestTestMCCScore	0.83	0.64	0.82	0.77	0.9	27	8	22	3	0.23
BestTestAccuracyScore	0.79	0.57	0.78	0.77	0.8	24	7	23	6	0.33
BestValidationF1Score	0.81	0.67	0.83	0.76	0.88	22	7	28	3	0.23
BestValidationMCC	0.81	0.67	0.83	0.76	0.88	22	7	28	3	0.23
BestValidationAccuracy	0.81	0.66	0.83	0.78	0.84	21	6	29	4	0.33
TestPredictions (Threshold:0.23)
CHEMBL318485,TN,INACT,0.009999999776482582	CHEMBL504550,FP,INACT,0.3799999952316284	CHEMBL522760,TN,INACT,0.03999999910593033	CHEMBL2392232,TN,INACT,0.009999999776482582	CHEMBL220685,FP,INACT,0.9800000190734863	CHEMBL476228,TP,ACT,0.9200000166893005	CHEMBL561136,TN,INACT,0.0	CHEMBL491435,TP,ACT,0.9300000071525574	CHEMBL332342,FP,INACT,0.47999998927116394	CHEMBL1836639,TP,ACT,0.23999999463558197	CHEMBL1933806,TN,INACT,0.009999999776482582	CHEMBL456797,TN,INACT,0.029999999329447746	CHEMBL456965,TN,INACT,0.009999999776482582	CHEMBL221269,TP,ACT,0.9800000190734863	CHEMBL1331525,FP,INACT,0.41999998688697815	CHEMBL1288069,TN,INACT,0.019999999552965164	CHEMBL230870,TP,ACT,0.9800000190734863	CHEMBL219628,TP,ACT,0.9700000286102295	CHEMBL221221,TP,ACT,0.9800000190734863	CHEMBL230116,TP,ACT,0.4099999964237213	CHEMBL230755,TP,ACT,0.8799999952316284	CHEMBL396487,FP,INACT,0.6000000238418579	CHEMBL1087421,TN,INACT,0.03999999910593033	CHEMBL496388,TP,ACT,0.9900000095367432	CHEMBL524468,TP,ACT,0.7099999785423279	CHEMBL505637,FN,ACT,0.10000000149011612	CHEMBL2164696,TN,INACT,0.029999999329447746	CHEMBL1836638,TP,ACT,0.9399999976158142	CHEMBL496752,TP,ACT,0.6200000047683716	CHEMBL2392355,TN,INACT,0.03999999910593033	CHEMBL491434,TP,ACT,0.9399999976158142	CHEMBL507453,TP,ACT,0.9599999785423279	CHEMBL1808587,TP,ACT,0.9800000190734863	CHEMBL447512,TP,ACT,0.9300000071525574	CHEMBL1836716,TP,ACT,0.28999999165534973	CHEMBL1836717,TP,ACT,0.28999999165534973	CHEMBL456113,TN,INACT,0.009999999776482582	CHEMBL2392236,TN,INACT,0.009999999776482582	CHEMBL230762,TP,ACT,0.9700000286102295	CHEMBL230553,TP,ACT,0.9800000190734863	CHEMBL2392375,TN,INACT,0.1599999964237213	CHEMBL557321,TN,INACT,0.009999999776482582	CHEMBL522217,FP,INACT,0.9800000190734863	CHEMBL242637,FN,ACT,0.10999999940395355	CHEMBL2392390,TN,INACT,0.009999999776482582	CHEMBL1808576,TP,ACT,0.9700000286102295	CHEMBL6246,FN,ACT,0.009999999776482582	CHEMBL457180,TN,INACT,0.009999999776482582	CHEMBL599519,TN,INACT,0.029999999329447746	CHEMBL2392378,TN,INACT,0.019999999552965164	CHEMBL495617,TP,ACT,0.9800000190734863	CHEMBL1909651,FP,INACT,0.2800000011920929	CHEMBL376501,TP,ACT,0.9900000095367432	CHEMBL1836722,TP,ACT,0.3799999952316284	CHEMBL220233,TP,ACT,0.9900000095367432	CHEMBL482864,TP,ACT,0.9800000190734863	CHEMBL1910373,FP,INACT,0.8500000238418579	CHEMBL463384,TN,INACT,0.009999999776482582	CHEMBL2392233,TN,INACT,0.009999999776482582	CHEMBL498520,TN,INACT,0.0	

