CNNModel CHEMBL2954 RMSprop 0.001 30 32 0 0.6 False True
Number of active compounds :	1014
Number of inactive compounds :	676
---------------------------------
Run id: CNNModel_CHEMBL2954_RMSprop_0.001_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2954_RMSprop_0.001_30_32_0.6_True/
---------------------------------
Training samples: 1068
Validation samples: 334
--
Training Step: 1  | time: 0.785s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1068
[A[ATraining Step: 2  | total loss: [1m[32m0.62376[0m[0m | time: 1.382s
[2K
| RMSProp | epoch: 001 | loss: 0.62376 - acc: 0.4781 -- iter: 0064/1068
[A[ATraining Step: 3  | total loss: [1m[32m0.68032[0m[0m | time: 1.983s
[2K
| RMSProp | epoch: 001 | loss: 0.68032 - acc: 0.5472 -- iter: 0096/1068
[A[ATraining Step: 4  | total loss: [1m[32m0.68967[0m[0m | time: 2.612s
[2K
| RMSProp | epoch: 001 | loss: 0.68967 - acc: 0.5821 -- iter: 0128/1068
[A[ATraining Step: 5  | total loss: [1m[32m0.69173[0m[0m | time: 3.220s
[2K
| RMSProp | epoch: 001 | loss: 0.69173 - acc: 0.6118 -- iter: 0160/1068
[A[ATraining Step: 6  | total loss: [1m[32m0.69276[0m[0m | time: 3.831s
[2K
| RMSProp | epoch: 001 | loss: 0.69276 - acc: 0.4998 -- iter: 0192/1068
[A[ATraining Step: 7  | total loss: [1m[32m0.69312[0m[0m | time: 4.436s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.4812 -- iter: 0224/1068
[A[ATraining Step: 8  | total loss: [1m[32m0.69306[0m[0m | time: 5.040s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5093 -- iter: 0256/1068
[A[ATraining Step: 9  | total loss: [1m[32m0.69278[0m[0m | time: 5.652s
[2K
| RMSProp | epoch: 001 | loss: 0.69278 - acc: 0.6037 -- iter: 0288/1068
[A[ATraining Step: 10  | total loss: [1m[32m0.69275[0m[0m | time: 6.280s
[2K
| RMSProp | epoch: 001 | loss: 0.69275 - acc: 0.5987 -- iter: 0320/1068
[A[ATraining Step: 11  | total loss: [1m[32m0.69255[0m[0m | time: 6.876s
[2K
| RMSProp | epoch: 001 | loss: 0.69255 - acc: 0.6408 -- iter: 0352/1068
[A[ATraining Step: 12  | total loss: [1m[32m0.69224[0m[0m | time: 7.493s
[2K
| RMSProp | epoch: 001 | loss: 0.69224 - acc: 0.6899 -- iter: 0384/1068
[A[ATraining Step: 13  | total loss: [1m[32m0.69247[0m[0m | time: 8.096s
[2K
| RMSProp | epoch: 001 | loss: 0.69247 - acc: 0.6353 -- iter: 0416/1068
[A[ATraining Step: 14  | total loss: [1m[32m0.69253[0m[0m | time: 8.706s
[2K
| RMSProp | epoch: 001 | loss: 0.69253 - acc: 0.6055 -- iter: 0448/1068
[A[ATraining Step: 15  | total loss: [1m[32m0.69234[0m[0m | time: 9.307s
[2K
| RMSProp | epoch: 001 | loss: 0.69234 - acc: 0.6254 -- iter: 0480/1068
[A[ATraining Step: 16  | total loss: [1m[32m0.69266[0m[0m | time: 9.912s
[2K
| RMSProp | epoch: 001 | loss: 0.69266 - acc: 0.5901 -- iter: 0512/1068
[A[ATraining Step: 17  | total loss: [1m[32m0.69293[0m[0m | time: 10.518s
[2K
| RMSProp | epoch: 001 | loss: 0.69293 - acc: 0.5464 -- iter: 0544/1068
[A[ATraining Step: 18  | total loss: [1m[32m0.69222[0m[0m | time: 11.122s
[2K
| RMSProp | epoch: 001 | loss: 0.69222 - acc: 0.6385 -- iter: 0576/1068
[A[ATraining Step: 19  | total loss: [1m[32m0.69247[0m[0m | time: 11.743s
[2K
| RMSProp | epoch: 001 | loss: 0.69247 - acc: 0.6028 -- iter: 0608/1068
[A[ATraining Step: 20  | total loss: [1m[32m0.69215[0m[0m | time: 12.338s
[2K
| RMSProp | epoch: 001 | loss: 0.69215 - acc: 0.6300 -- iter: 0640/1068
[A[ATraining Step: 21  | total loss: [1m[32m0.69216[0m[0m | time: 12.924s
[2K
| RMSProp | epoch: 001 | loss: 0.69216 - acc: 0.6187 -- iter: 0672/1068
[A[ATraining Step: 22  | total loss: [1m[32m0.69218[0m[0m | time: 13.520s
[2K
| RMSProp | epoch: 001 | loss: 0.69218 - acc: 0.6112 -- iter: 0704/1068
[A[ATraining Step: 23  | total loss: [1m[32m0.69151[0m[0m | time: 14.116s
[2K
| RMSProp | epoch: 001 | loss: 0.69151 - acc: 0.6606 -- iter: 0736/1068
[A[ATraining Step: 24  | total loss: [1m[32m0.69110[0m[0m | time: 14.727s
[2K
| RMSProp | epoch: 001 | loss: 0.69110 - acc: 0.6770 -- iter: 0768/1068
[A[ATraining Step: 25  | total loss: [1m[32m0.69156[0m[0m | time: 15.335s
[2K
| RMSProp | epoch: 001 | loss: 0.69156 - acc: 0.6372 -- iter: 0800/1068
[A[ATraining Step: 26  | total loss: [1m[32m0.69158[0m[0m | time: 15.964s
[2K
| RMSProp | epoch: 001 | loss: 0.69158 - acc: 0.6257 -- iter: 0832/1068
[A[ATraining Step: 27  | total loss: [1m[32m0.69145[0m[0m | time: 16.571s
[2K
| RMSProp | epoch: 001 | loss: 0.69145 - acc: 0.6255 -- iter: 0864/1068
[A[ATraining Step: 28  | total loss: [1m[32m0.69257[0m[0m | time: 17.159s
[2K
| RMSProp | epoch: 001 | loss: 0.69257 - acc: 0.5551 -- iter: 0896/1068
[A[ATraining Step: 29  | total loss: [1m[32m0.69225[0m[0m | time: 17.787s
[2K
| RMSProp | epoch: 001 | loss: 0.69225 - acc: 0.5721 -- iter: 0928/1068
[A[ATraining Step: 30  | total loss: [1m[32m0.69182[0m[0m | time: 18.392s
[2K
| RMSProp | epoch: 001 | loss: 0.69182 - acc: 0.5920 -- iter: 0960/1068
[A[ATraining Step: 31  | total loss: [1m[32m0.69159[0m[0m | time: 19.004s
[2K
| RMSProp | epoch: 001 | loss: 0.69159 - acc: 0.5996 -- iter: 0992/1068
[A[ATraining Step: 32  | total loss: [1m[32m0.69182[0m[0m | time: 19.606s
[2K
| RMSProp | epoch: 001 | loss: 0.69182 - acc: 0.5842 -- iter: 1024/1068
[A[ATraining Step: 33  | total loss: [1m[32m0.69180[0m[0m | time: 20.215s
[2K
| RMSProp | epoch: 001 | loss: 0.69180 - acc: 0.5795 -- iter: 1056/1068
[A[ATraining Step: 34  | total loss: [1m[32m0.69210[0m[0m | time: 21.571s
[2K
| RMSProp | epoch: 001 | loss: 0.69210 - acc: 0.5624 | val_loss: 0.69067 - val_acc: 0.6257 -- iter: 1068/1068
--
Training Step: 35  | total loss: [1m[32m0.69238[0m[0m | time: 0.253s
[2K
| RMSProp | epoch: 002 | loss: 0.69238 - acc: 0.5494 -- iter: 0032/1068
[A[ATraining Step: 36  | total loss: [1m[32m0.69251[0m[0m | time: 0.858s
[2K
| RMSProp | epoch: 002 | loss: 0.69251 - acc: 0.5393 -- iter: 0064/1068
[A[ATraining Step: 37  | total loss: [1m[32m0.69277[0m[0m | time: 1.462s
[2K
| RMSProp | epoch: 002 | loss: 0.69277 - acc: 0.5252 -- iter: 0096/1068
[A[ATraining Step: 38  | total loss: [1m[32m0.69275[0m[0m | time: 2.064s
[2K
| RMSProp | epoch: 002 | loss: 0.69275 - acc: 0.5264 -- iter: 0128/1068
[A[ATraining Step: 39  | total loss: [1m[32m0.69198[0m[0m | time: 2.676s
[2K
| RMSProp | epoch: 002 | loss: 0.69198 - acc: 0.5632 -- iter: 0160/1068
[A[ATraining Step: 40  | total loss: [1m[32m0.69219[0m[0m | time: 3.301s
[2K
| RMSProp | epoch: 002 | loss: 0.69219 - acc: 0.5514 -- iter: 0192/1068
[A[ATraining Step: 41  | total loss: [1m[32m0.69162[0m[0m | time: 3.903s
[2K
| RMSProp | epoch: 002 | loss: 0.69162 - acc: 0.5764 -- iter: 0224/1068
[A[ATraining Step: 42  | total loss: [1m[32m0.69136[0m[0m | time: 4.512s
[2K
| RMSProp | epoch: 002 | loss: 0.69136 - acc: 0.5851 -- iter: 0256/1068
[A[ATraining Step: 43  | total loss: [1m[32m0.69109[0m[0m | time: 5.122s
[2K
| RMSProp | epoch: 002 | loss: 0.69109 - acc: 0.5922 -- iter: 0288/1068
[A[ATraining Step: 44  | total loss: [1m[32m0.69053[0m[0m | time: 5.732s
[2K
| RMSProp | epoch: 002 | loss: 0.69053 - acc: 0.6087 -- iter: 0320/1068
[A[ATraining Step: 45  | total loss: [1m[32m0.69064[0m[0m | time: 6.350s
[2K
| RMSProp | epoch: 002 | loss: 0.69064 - acc: 0.6008 -- iter: 0352/1068
[A[ATraining Step: 46  | total loss: [1m[32m0.69125[0m[0m | time: 6.954s
[2K
| RMSProp | epoch: 002 | loss: 0.69125 - acc: 0.5788 -- iter: 0384/1068
[A[ATraining Step: 47  | total loss: [1m[32m0.69176[0m[0m | time: 7.560s
[2K
| RMSProp | epoch: 002 | loss: 0.69176 - acc: 0.5608 -- iter: 0416/1068
[A[ATraining Step: 48  | total loss: [1m[32m0.69170[0m[0m | time: 8.171s
[2K
| RMSProp | epoch: 002 | loss: 0.69170 - acc: 0.5611 -- iter: 0448/1068
[A[ATraining Step: 49  | total loss: [1m[32m0.69164[0m[0m | time: 8.808s
[2K
| RMSProp | epoch: 002 | loss: 0.69164 - acc: 0.5613 -- iter: 0480/1068
[A[ATraining Step: 50  | total loss: [1m[32m0.69088[0m[0m | time: 9.414s
[2K
| RMSProp | epoch: 002 | loss: 0.69088 - acc: 0.5809 -- iter: 0512/1068
[A[ATraining Step: 51  | total loss: [1m[32m0.69003[0m[0m | time: 10.018s
[2K
| RMSProp | epoch: 002 | loss: 0.69003 - acc: 0.6019 -- iter: 0544/1068
[A[ATraining Step: 52  | total loss: [1m[32m0.68939[0m[0m | time: 10.631s
[2K
| RMSProp | epoch: 002 | loss: 0.68939 - acc: 0.6147 -- iter: 0576/1068
[A[ATraining Step: 53  | total loss: [1m[32m0.68978[0m[0m | time: 11.259s
[2K
| RMSProp | epoch: 002 | loss: 0.68978 - acc: 0.6024 -- iter: 0608/1068
[A[ATraining Step: 54  | total loss: [1m[32m0.69034[0m[0m | time: 11.865s
[2K
| RMSProp | epoch: 002 | loss: 0.69034 - acc: 0.5876 -- iter: 0640/1068
[A[ATraining Step: 55  | total loss: [1m[32m0.69099[0m[0m | time: 12.470s
[2K
| RMSProp | epoch: 002 | loss: 0.69099 - acc: 0.5706 -- iter: 0672/1068
[A[ATraining Step: 56  | total loss: [1m[32m0.69077[0m[0m | time: 13.094s
[2K
| RMSProp | epoch: 002 | loss: 0.69077 - acc: 0.5738 -- iter: 0704/1068
[A[ATraining Step: 57  | total loss: [1m[32m0.69033[0m[0m | time: 13.707s
[2K
| RMSProp | epoch: 002 | loss: 0.69033 - acc: 0.5809 -- iter: 0736/1068
[A[ATraining Step: 58  | total loss: [1m[32m0.69036[0m[0m | time: 14.326s
[2K
| RMSProp | epoch: 002 | loss: 0.69036 - acc: 0.5784 -- iter: 0768/1068
[A[ATraining Step: 59  | total loss: [1m[32m0.69056[0m[0m | time: 14.953s
[2K
| RMSProp | epoch: 002 | loss: 0.69056 - acc: 0.5721 -- iter: 0800/1068
[A[ATraining Step: 60  | total loss: [1m[32m0.68927[0m[0m | time: 15.562s
[2K
| RMSProp | epoch: 002 | loss: 0.68927 - acc: 0.5956 -- iter: 0832/1068
[A[ATraining Step: 61  | total loss: [1m[32m0.68956[0m[0m | time: 16.163s
[2K
| RMSProp | epoch: 002 | loss: 0.68956 - acc: 0.5872 -- iter: 0864/1068
[A[ATraining Step: 62  | total loss: [1m[32m0.69076[0m[0m | time: 16.769s
[2K
| RMSProp | epoch: 002 | loss: 0.69076 - acc: 0.5640 -- iter: 0896/1068
[A[ATraining Step: 63  | total loss: [1m[32m0.68945[0m[0m | time: 17.403s
[2K
| RMSProp | epoch: 002 | loss: 0.68945 - acc: 0.5875 -- iter: 0928/1068
[A[ATraining Step: 64  | total loss: [1m[32m0.68927[0m[0m | time: 18.014s
[2K
| RMSProp | epoch: 002 | loss: 0.68927 - acc: 0.5883 -- iter: 0960/1068
[A[ATraining Step: 65  | total loss: [1m[32m0.69005[0m[0m | time: 18.639s
[2K
| RMSProp | epoch: 002 | loss: 0.69005 - acc: 0.5736 -- iter: 0992/1068
[A[ATraining Step: 66  | total loss: [1m[32m0.69001[0m[0m | time: 19.246s
[2K
| RMSProp | epoch: 002 | loss: 0.69001 - acc: 0.5722 -- iter: 1024/1068
[A[ATraining Step: 67  | total loss: [1m[32m0.68955[0m[0m | time: 19.862s
[2K
| RMSProp | epoch: 002 | loss: 0.68955 - acc: 0.5786 -- iter: 1056/1068
[A[ATraining Step: 68  | total loss: [1m[32m0.68930[0m[0m | time: 21.529s
[2K
| RMSProp | epoch: 002 | loss: 0.68930 - acc: 0.5804 | val_loss: 0.68531 - val_acc: 0.6257 -- iter: 1068/1068
--
Training Step: 69  | total loss: [1m[32m0.68959[0m[0m | time: 0.268s
[2K
| RMSProp | epoch: 003 | loss: 0.68959 - acc: 0.5746 -- iter: 0032/1068
[A[ATraining Step: 70  | total loss: [1m[32m0.68686[0m[0m | time: 0.520s
[2K
| RMSProp | epoch: 003 | loss: 0.68686 - acc: 0.6141 -- iter: 0064/1068
[A[ATraining Step: 71  | total loss: [1m[32m0.68399[0m[0m | time: 1.169s
[2K
| RMSProp | epoch: 003 | loss: 0.68399 - acc: 0.6486 -- iter: 0096/1068
[A[ATraining Step: 72  | total loss: [1m[32m0.68391[0m[0m | time: 1.787s
[2K
| RMSProp | epoch: 003 | loss: 0.68391 - acc: 0.6459 -- iter: 0128/1068
[A[ATraining Step: 73  | total loss: [1m[32m0.68414[0m[0m | time: 2.398s
[2K
| RMSProp | epoch: 003 | loss: 0.68414 - acc: 0.6401 -- iter: 0160/1068
[A[ATraining Step: 74  | total loss: [1m[32m0.68336[0m[0m | time: 3.026s
[2K
| RMSProp | epoch: 003 | loss: 0.68336 - acc: 0.6453 -- iter: 0192/1068
[A[ATraining Step: 75  | total loss: [1m[32m0.68389[0m[0m | time: 3.615s
[2K
| RMSProp | epoch: 003 | loss: 0.68389 - acc: 0.6363 -- iter: 0224/1068
[A[ATraining Step: 76  | total loss: [1m[32m0.68368[0m[0m | time: 4.205s
[2K
| RMSProp | epoch: 003 | loss: 0.68368 - acc: 0.6351 -- iter: 0256/1068
[A[ATraining Step: 77  | total loss: [1m[32m0.68349[0m[0m | time: 4.808s
[2K
| RMSProp | epoch: 003 | loss: 0.68349 - acc: 0.6340 -- iter: 0288/1068
[A[ATraining Step: 78  | total loss: [1m[32m0.68359[0m[0m | time: 5.416s
[2K
| RMSProp | epoch: 003 | loss: 0.68359 - acc: 0.6298 -- iter: 0320/1068
[A[ATraining Step: 79  | total loss: [1m[32m0.68406[0m[0m | time: 6.038s
[2K
| RMSProp | epoch: 003 | loss: 0.68406 - acc: 0.6229 -- iter: 0352/1068
[A[ATraining Step: 80  | total loss: [1m[32m0.68515[0m[0m | time: 6.645s
[2K
| RMSProp | epoch: 003 | loss: 0.68515 - acc: 0.6103 -- iter: 0384/1068
[A[ATraining Step: 81  | total loss: [1m[32m0.68611[0m[0m | time: 7.253s
[2K
| RMSProp | epoch: 003 | loss: 0.68611 - acc: 0.5991 -- iter: 0416/1068
[A[ATraining Step: 82  | total loss: [1m[32m0.68665[0m[0m | time: 7.865s
[2K
| RMSProp | epoch: 003 | loss: 0.68665 - acc: 0.5924 -- iter: 0448/1068
[A[ATraining Step: 83  | total loss: [1m[32m0.68744[0m[0m | time: 8.463s
[2K
| RMSProp | epoch: 003 | loss: 0.68744 - acc: 0.5831 -- iter: 0480/1068
[A[ATraining Step: 84  | total loss: [1m[32m0.68720[0m[0m | time: 9.123s
[2K
| RMSProp | epoch: 003 | loss: 0.68720 - acc: 0.5842 -- iter: 0512/1068
[A[ATraining Step: 85  | total loss: [1m[32m0.68661[0m[0m | time: 9.742s
[2K
| RMSProp | epoch: 003 | loss: 0.68661 - acc: 0.5883 -- iter: 0544/1068
[A[ATraining Step: 86  | total loss: [1m[32m0.68565[0m[0m | time: 10.353s
[2K
| RMSProp | epoch: 003 | loss: 0.68565 - acc: 0.5951 -- iter: 0576/1068
[A[ATraining Step: 87  | total loss: [1m[32m0.68506[0m[0m | time: 10.957s
[2K
| RMSProp | epoch: 003 | loss: 0.68506 - acc: 0.5981 -- iter: 0608/1068
[A[ATraining Step: 88  | total loss: [1m[32m0.68769[0m[0m | time: 11.553s
[2K
| RMSProp | epoch: 003 | loss: 0.68769 - acc: 0.5758 -- iter: 0640/1068
[A[ATraining Step: 89  | total loss: [1m[32m0.68587[0m[0m | time: 12.156s
[2K
| RMSProp | epoch: 003 | loss: 0.68587 - acc: 0.5901 -- iter: 0672/1068
[A[ATraining Step: 90  | total loss: [1m[32m0.68683[0m[0m | time: 12.748s
[2K
| RMSProp | epoch: 003 | loss: 0.68683 - acc: 0.5810 -- iter: 0704/1068
[A[ATraining Step: 91  | total loss: [1m[32m0.68654[0m[0m | time: 13.352s
[2K
| RMSProp | epoch: 003 | loss: 0.68654 - acc: 0.5823 -- iter: 0736/1068
[A[ATraining Step: 92  | total loss: [1m[32m0.68454[0m[0m | time: 13.949s
[2K
| RMSProp | epoch: 003 | loss: 0.68454 - acc: 0.5960 -- iter: 0768/1068
[A[ATraining Step: 93  | total loss: [1m[32m0.68341[0m[0m | time: 14.559s
[2K
| RMSProp | epoch: 003 | loss: 0.68341 - acc: 0.6020 -- iter: 0800/1068
[A[ATraining Step: 94  | total loss: [1m[32m0.68176[0m[0m | time: 15.207s
[2K
| RMSProp | epoch: 003 | loss: 0.68176 - acc: 0.6105 -- iter: 0832/1068
[A[ATraining Step: 95  | total loss: [1m[32m0.68225[0m[0m | time: 15.818s
[2K
| RMSProp | epoch: 003 | loss: 0.68225 - acc: 0.6057 -- iter: 0864/1068
[A[ATraining Step: 96  | total loss: [1m[32m0.68320[0m[0m | time: 16.422s
[2K
| RMSProp | epoch: 003 | loss: 0.68320 - acc: 0.5983 -- iter: 0896/1068
[A[ATraining Step: 97  | total loss: [1m[32m0.68297[0m[0m | time: 17.026s
[2K
| RMSProp | epoch: 003 | loss: 0.68297 - acc: 0.5978 -- iter: 0928/1068
[A[ATraining Step: 98  | total loss: [1m[32m0.68278[0m[0m | time: 17.631s
[2K
| RMSProp | epoch: 003 | loss: 0.68278 - acc: 0.5974 -- iter: 0960/1068
[A[ATraining Step: 99  | total loss: [1m[32m0.68366[0m[0m | time: 18.232s
[2K
| RMSProp | epoch: 003 | loss: 0.68366 - acc: 0.5908 -- iter: 0992/1068
[A[ATraining Step: 100  | total loss: [1m[32m0.68276[0m[0m | time: 18.843s
[2K
| RMSProp | epoch: 003 | loss: 0.68276 - acc: 0.5942 -- iter: 1024/1068
[A[ATraining Step: 101  | total loss: [1m[32m0.68430[0m[0m | time: 19.439s
[2K
| RMSProp | epoch: 003 | loss: 0.68430 - acc: 0.5848 -- iter: 1056/1068
[A[ATraining Step: 102  | total loss: [1m[32m0.68211[0m[0m | time: 21.114s
[2K
| RMSProp | epoch: 003 | loss: 0.68211 - acc: 0.5951 | val_loss: 0.67222 - val_acc: 0.6257 -- iter: 1068/1068
--
Training Step: 103  | total loss: [1m[32m0.68307[0m[0m | time: 0.621s
[2K
| RMSProp | epoch: 004 | loss: 0.68307 - acc: 0.5887 -- iter: 0032/1068
[A[ATraining Step: 104  | total loss: [1m[32m0.68132[0m[0m | time: 0.868s
[2K
| RMSProp | epoch: 004 | loss: 0.68132 - acc: 0.5954 -- iter: 0064/1068
[A[ATraining Step: 105  | total loss: [1m[32m0.67701[0m[0m | time: 1.110s
[2K
| RMSProp | epoch: 004 | loss: 0.67701 - acc: 0.6109 -- iter: 0096/1068
[A[ATraining Step: 106  | total loss: [1m[32m0.67208[0m[0m | time: 1.709s
[2K
| RMSProp | epoch: 004 | loss: 0.67208 - acc: 0.6248 -- iter: 0128/1068
[A[ATraining Step: 107  | total loss: [1m[32m0.67383[0m[0m | time: 2.312s
[2K
| RMSProp | epoch: 004 | loss: 0.67383 - acc: 0.6186 -- iter: 0160/1068
[A[ATraining Step: 108  | total loss: [1m[32m0.67279[0m[0m | time: 2.917s
[2K
| RMSProp | epoch: 004 | loss: 0.67279 - acc: 0.6192 -- iter: 0192/1068
[A[ATraining Step: 109  | total loss: [1m[32m0.67154[0m[0m | time: 3.530s
[2K
| RMSProp | epoch: 004 | loss: 0.67154 - acc: 0.6198 -- iter: 0224/1068
[A[ATraining Step: 110  | total loss: [1m[32m0.67200[0m[0m | time: 4.125s
[2K
| RMSProp | epoch: 004 | loss: 0.67200 - acc: 0.6172 -- iter: 0256/1068
[A[ATraining Step: 111  | total loss: [1m[32m0.67224[0m[0m | time: 4.735s
[2K
| RMSProp | epoch: 004 | loss: 0.67224 - acc: 0.6149 -- iter: 0288/1068
[A[ATraining Step: 112  | total loss: [1m[32m0.67406[0m[0m | time: 5.348s
[2K
| RMSProp | epoch: 004 | loss: 0.67406 - acc: 0.6096 -- iter: 0320/1068
[A[ATraining Step: 113  | total loss: [1m[32m0.67552[0m[0m | time: 5.978s
[2K
| RMSProp | epoch: 004 | loss: 0.67552 - acc: 0.6049 -- iter: 0352/1068
[A[ATraining Step: 114  | total loss: [1m[32m0.67750[0m[0m | time: 6.580s
[2K
| RMSProp | epoch: 004 | loss: 0.67750 - acc: 0.5975 -- iter: 0384/1068
[A[ATraining Step: 115  | total loss: [1m[32m0.67391[0m[0m | time: 7.182s
[2K
| RMSProp | epoch: 004 | loss: 0.67391 - acc: 0.6097 -- iter: 0416/1068
[A[ATraining Step: 116  | total loss: [1m[32m0.68173[0m[0m | time: 7.785s
[2K
| RMSProp | epoch: 004 | loss: 0.68173 - acc: 0.5893 -- iter: 0448/1068
[A[ATraining Step: 117  | total loss: [1m[32m0.68083[0m[0m | time: 8.409s
[2K
| RMSProp | epoch: 004 | loss: 0.68083 - acc: 0.5929 -- iter: 0480/1068
[A[ATraining Step: 118  | total loss: [1m[32m0.68413[0m[0m | time: 9.019s
[2K
| RMSProp | epoch: 004 | loss: 0.68413 - acc: 0.5773 -- iter: 0512/1068
[A[ATraining Step: 119  | total loss: [1m[32m0.68493[0m[0m | time: 9.630s
[2K
| RMSProp | epoch: 004 | loss: 0.68493 - acc: 0.5727 -- iter: 0544/1068
[A[ATraining Step: 120  | total loss: [1m[32m0.68265[0m[0m | time: 10.235s
[2K
| RMSProp | epoch: 004 | loss: 0.68265 - acc: 0.5842 -- iter: 0576/1068
[A[ATraining Step: 121  | total loss: [1m[32m0.68499[0m[0m | time: 10.850s
[2K
| RMSProp | epoch: 004 | loss: 0.68499 - acc: 0.5727 -- iter: 0608/1068
[A[ATraining Step: 122  | total loss: [1m[32m0.68753[0m[0m | time: 11.453s
[2K
| RMSProp | epoch: 004 | loss: 0.68753 - acc: 0.5592 -- iter: 0640/1068
[A[ATraining Step: 123  | total loss: [1m[32m0.68532[0m[0m | time: 12.060s
[2K
| RMSProp | epoch: 004 | loss: 0.68532 - acc: 0.5720 -- iter: 0672/1068
[A[ATraining Step: 124  | total loss: [1m[32m0.68160[0m[0m | time: 12.678s
[2K
| RMSProp | epoch: 004 | loss: 0.68160 - acc: 0.5898 -- iter: 0704/1068
[A[ATraining Step: 125  | total loss: [1m[32m0.67767[0m[0m | time: 13.282s
[2K
| RMSProp | epoch: 004 | loss: 0.67767 - acc: 0.6027 -- iter: 0736/1068
[A[ATraining Step: 126  | total loss: [1m[32m0.67876[0m[0m | time: 13.905s
[2K
| RMSProp | epoch: 004 | loss: 0.67876 - acc: 0.5987 -- iter: 0768/1068
[A[ATraining Step: 127  | total loss: [1m[32m0.67529[0m[0m | time: 14.514s
[2K
| RMSProp | epoch: 004 | loss: 0.67529 - acc: 0.6075 -- iter: 0800/1068
[A[ATraining Step: 128  | total loss: [1m[32m0.67350[0m[0m | time: 15.121s
[2K
| RMSProp | epoch: 004 | loss: 0.67350 - acc: 0.6093 -- iter: 0832/1068
[A[ATraining Step: 129  | total loss: [1m[32m0.67237[0m[0m | time: 15.747s
[2K
| RMSProp | epoch: 004 | loss: 0.67237 - acc: 0.6109 -- iter: 0864/1068
[A[ATraining Step: 130  | total loss: [1m[32m0.66962[0m[0m | time: 16.381s
[2K
| RMSProp | epoch: 004 | loss: 0.66962 - acc: 0.6154 -- iter: 0896/1068
[A[ATraining Step: 131  | total loss: [1m[32m0.66465[0m[0m | time: 16.991s
[2K
| RMSProp | epoch: 004 | loss: 0.66465 - acc: 0.6226 -- iter: 0928/1068
[A[ATraining Step: 132  | total loss: [1m[32m0.66632[0m[0m | time: 17.626s
[2K
| RMSProp | epoch: 004 | loss: 0.66632 - acc: 0.6229 -- iter: 0960/1068
[A[ATraining Step: 133  | total loss: [1m[32m0.66814[0m[0m | time: 18.232s
[2K
| RMSProp | epoch: 004 | loss: 0.66814 - acc: 0.6168 -- iter: 0992/1068
[A[ATraining Step: 134  | total loss: [1m[32m0.67148[0m[0m | time: 18.835s
[2K
| RMSProp | epoch: 004 | loss: 0.67148 - acc: 0.6051 -- iter: 1024/1068
[A[ATraining Step: 135  | total loss: [1m[32m0.67497[0m[0m | time: 19.440s
[2K
| RMSProp | epoch: 004 | loss: 0.67497 - acc: 0.5915 -- iter: 1056/1068
[A[ATraining Step: 136  | total loss: [1m[32m0.67783[0m[0m | time: 21.110s
[2K
| RMSProp | epoch: 004 | loss: 0.67783 - acc: 0.5792 | val_loss: 0.67347 - val_acc: 0.6257 -- iter: 1068/1068
--
Training Step: 137  | total loss: [1m[32m0.67764[0m[0m | time: 0.661s
[2K
| RMSProp | epoch: 005 | loss: 0.67764 - acc: 0.5838 -- iter: 0032/1068
[A[ATraining Step: 138  | total loss: [1m[32m0.67611[0m[0m | time: 1.270s
[2K
| RMSProp | epoch: 005 | loss: 0.67611 - acc: 0.5942 -- iter: 0064/1068
[A[ATraining Step: 139  | total loss: [1m[32m0.67790[0m[0m | time: 1.520s
[2K
| RMSProp | epoch: 005 | loss: 0.67790 - acc: 0.5879 -- iter: 0096/1068
[A[ATraining Step: 140  | total loss: [1m[32m0.68008[0m[0m | time: 1.770s
[2K
| RMSProp | epoch: 005 | loss: 0.68008 - acc: 0.5791 -- iter: 0128/1068
[A[ATraining Step: 141  | total loss: [1m[32m0.68185[0m[0m | time: 2.426s
[2K
| RMSProp | epoch: 005 | loss: 0.68185 - acc: 0.5712 -- iter: 0160/1068
[A[ATraining Step: 142  | total loss: [1m[32m0.68105[0m[0m | time: 3.032s
[2K
| RMSProp | epoch: 005 | loss: 0.68105 - acc: 0.5766 -- iter: 0192/1068
[A[ATraining Step: 143  | total loss: [1m[32m0.67800[0m[0m | time: 3.652s
[2K
| RMSProp | epoch: 005 | loss: 0.67800 - acc: 0.5908 -- iter: 0224/1068
[A[ATraining Step: 144  | total loss: [1m[32m0.67861[0m[0m | time: 4.266s
[2K
| RMSProp | epoch: 005 | loss: 0.67861 - acc: 0.5880 -- iter: 0256/1068
[A[ATraining Step: 145  | total loss: [1m[32m0.67540[0m[0m | time: 4.869s
[2K
| RMSProp | epoch: 005 | loss: 0.67540 - acc: 0.5979 -- iter: 0288/1068
[A[ATraining Step: 146  | total loss: [1m[32m0.68070[0m[0m | time: 5.479s
[2K
| RMSProp | epoch: 005 | loss: 0.68070 - acc: 0.5881 -- iter: 0320/1068
[A[ATraining Step: 147  | total loss: [1m[32m0.67853[0m[0m | time: 6.089s
[2K
| RMSProp | epoch: 005 | loss: 0.67853 - acc: 0.5981 -- iter: 0352/1068
[A[ATraining Step: 148  | total loss: [1m[32m0.67919[0m[0m | time: 6.689s
[2K
| RMSProp | epoch: 005 | loss: 0.67919 - acc: 0.5945 -- iter: 0384/1068
[A[ATraining Step: 149  | total loss: [1m[32m0.67589[0m[0m | time: 7.310s
[2K
| RMSProp | epoch: 005 | loss: 0.67589 - acc: 0.6069 -- iter: 0416/1068
[A[ATraining Step: 150  | total loss: [1m[32m0.67890[0m[0m | time: 7.941s
[2K
| RMSProp | epoch: 005 | loss: 0.67890 - acc: 0.5962 -- iter: 0448/1068
[A[ATraining Step: 151  | total loss: [1m[32m0.67949[0m[0m | time: 8.567s
[2K
| RMSProp | epoch: 005 | loss: 0.67949 - acc: 0.5929 -- iter: 0480/1068
[A[ATraining Step: 152  | total loss: [1m[32m0.68015[0m[0m | time: 9.193s
[2K
| RMSProp | epoch: 005 | loss: 0.68015 - acc: 0.5898 -- iter: 0512/1068
[A[ATraining Step: 153  | total loss: [1m[32m0.67732[0m[0m | time: 9.789s
[2K
| RMSProp | epoch: 005 | loss: 0.67732 - acc: 0.5996 -- iter: 0544/1068
[A[ATraining Step: 154  | total loss: [1m[32m0.67707[0m[0m | time: 10.394s
[2K
| RMSProp | epoch: 005 | loss: 0.67707 - acc: 0.5990 -- iter: 0576/1068
[A[ATraining Step: 155  | total loss: [1m[32m0.68137[0m[0m | time: 10.986s
[2K
| RMSProp | epoch: 005 | loss: 0.68137 - acc: 0.5860 -- iter: 0608/1068
[A[ATraining Step: 156  | total loss: [1m[32m0.68177[0m[0m | time: 11.579s
[2K
| RMSProp | epoch: 005 | loss: 0.68177 - acc: 0.5836 -- iter: 0640/1068
[A[ATraining Step: 157  | total loss: [1m[32m0.68444[0m[0m | time: 12.185s
[2K
| RMSProp | epoch: 005 | loss: 0.68444 - acc: 0.5721 -- iter: 0672/1068
[A[ATraining Step: 158  | total loss: [1m[32m0.68389[0m[0m | time: 12.816s
[2K
| RMSProp | epoch: 005 | loss: 0.68389 - acc: 0.5743 -- iter: 0704/1068
[A[ATraining Step: 159  | total loss: [1m[32m0.68051[0m[0m | time: 13.432s
[2K
| RMSProp | epoch: 005 | loss: 0.68051 - acc: 0.5887 -- iter: 0736/1068
[A[ATraining Step: 160  | total loss: [1m[32m0.67830[0m[0m | time: 14.061s
[2K
| RMSProp | epoch: 005 | loss: 0.67830 - acc: 0.5955 -- iter: 0768/1068
[A[ATraining Step: 161  | total loss: [1m[32m0.67682[0m[0m | time: 14.675s
[2K
| RMSProp | epoch: 005 | loss: 0.67682 - acc: 0.5984 -- iter: 0800/1068
[A[ATraining Step: 162  | total loss: [1m[32m0.67674[0m[0m | time: 15.297s
[2K
| RMSProp | epoch: 005 | loss: 0.67674 - acc: 0.5980 -- iter: 0832/1068
[A[ATraining Step: 163  | total loss: [1m[32m0.68006[0m[0m | time: 15.905s
[2K
| RMSProp | epoch: 005 | loss: 0.68006 - acc: 0.5882 -- iter: 0864/1068
[A[ATraining Step: 164  | total loss: [1m[32m0.68047[0m[0m | time: 16.540s
[2K
| RMSProp | epoch: 005 | loss: 0.68047 - acc: 0.5856 -- iter: 0896/1068
[A[ATraining Step: 165  | total loss: [1m[32m0.68080[0m[0m | time: 17.172s
[2K
| RMSProp | epoch: 005 | loss: 0.68080 - acc: 0.5833 -- iter: 0928/1068
[A[ATraining Step: 166  | total loss: [1m[32m0.68034[0m[0m | time: 17.789s
[2K
| RMSProp | epoch: 005 | loss: 0.68034 - acc: 0.5843 -- iter: 0960/1068
[A[ATraining Step: 167  | total loss: [1m[32m0.68167[0m[0m | time: 18.387s
[2K
| RMSProp | epoch: 005 | loss: 0.68167 - acc: 0.5790 -- iter: 0992/1068
[A[ATraining Step: 168  | total loss: [1m[32m0.67709[0m[0m | time: 18.988s
[2K
| RMSProp | epoch: 005 | loss: 0.67709 - acc: 0.5961 -- iter: 1024/1068
[A[ATraining Step: 169  | total loss: [1m[32m0.68052[0m[0m | time: 19.586s
[2K
| RMSProp | epoch: 005 | loss: 0.68052 - acc: 0.5865 -- iter: 1056/1068
[A[ATraining Step: 170  | total loss: [1m[32m0.68431[0m[0m | time: 21.251s
[2K
| RMSProp | epoch: 005 | loss: 0.68431 - acc: 0.5716 | val_loss: 0.66990 - val_acc: 0.6257 -- iter: 1068/1068
--
Training Step: 171  | total loss: [1m[32m0.68362[0m[0m | time: 0.612s
[2K
| RMSProp | epoch: 006 | loss: 0.68362 - acc: 0.5738 -- iter: 0032/1068
[A[ATraining Step: 172  | total loss: [1m[32m0.68224[0m[0m | time: 1.228s
[2K
| RMSProp | epoch: 006 | loss: 0.68224 - acc: 0.5789 -- iter: 0064/1068
[A[ATraining Step: 173  | total loss: [1m[32m0.68080[0m[0m | time: 1.839s
[2K
| RMSProp | epoch: 006 | loss: 0.68080 - acc: 0.5836 -- iter: 0096/1068
[A[ATraining Step: 174  | total loss: [1m[32m0.68400[0m[0m | time: 2.085s
[2K
| RMSProp | epoch: 006 | loss: 0.68400 - acc: 0.5721 -- iter: 0128/1068
[A[ATraining Step: 175  | total loss: [1m[32m0.68158[0m[0m | time: 2.343s
[2K
| RMSProp | epoch: 006 | loss: 0.68158 - acc: 0.5815 -- iter: 0160/1068
[A[ATraining Step: 176  | total loss: [1m[32m0.67901[0m[0m | time: 2.953s
[2K
| RMSProp | epoch: 006 | loss: 0.67901 - acc: 0.5900 -- iter: 0192/1068
[A[ATraining Step: 177  | total loss: [1m[32m0.67652[0m[0m | time: 3.548s
[2K
| RMSProp | epoch: 006 | loss: 0.67652 - acc: 0.5967 -- iter: 0224/1068
[A[ATraining Step: 178  | total loss: [1m[32m0.67356[0m[0m | time: 4.141s
[2K
| RMSProp | epoch: 006 | loss: 0.67356 - acc: 0.6026 -- iter: 0256/1068
[A[ATraining Step: 179  | total loss: [1m[32m0.67069[0m[0m | time: 4.742s
[2K
| RMSProp | epoch: 006 | loss: 0.67069 - acc: 0.6080 -- iter: 0288/1068
[A[ATraining Step: 180  | total loss: [1m[32m0.67021[0m[0m | time: 5.346s
[2K
| RMSProp | epoch: 006 | loss: 0.67021 - acc: 0.6097 -- iter: 0320/1068
[A[ATraining Step: 181  | total loss: [1m[32m0.67069[0m[0m | time: 5.947s
[2K
| RMSProp | epoch: 006 | loss: 0.67069 - acc: 0.6081 -- iter: 0352/1068
[A[ATraining Step: 182  | total loss: [1m[32m0.67121[0m[0m | time: 6.549s
[2K
| RMSProp | epoch: 006 | loss: 0.67121 - acc: 0.6067 -- iter: 0384/1068
[A[ATraining Step: 183  | total loss: [1m[32m0.67057[0m[0m | time: 7.165s
[2K
| RMSProp | epoch: 006 | loss: 0.67057 - acc: 0.6085 -- iter: 0416/1068
[A[ATraining Step: 184  | total loss: [1m[32m0.66870[0m[0m | time: 7.756s
[2K
| RMSProp | epoch: 006 | loss: 0.66870 - acc: 0.6133 -- iter: 0448/1068
[A[ATraining Step: 185  | total loss: [1m[32m0.67241[0m[0m | time: 8.356s
[2K
| RMSProp | epoch: 006 | loss: 0.67241 - acc: 0.6051 -- iter: 0480/1068
[A[ATraining Step: 186  | total loss: [1m[32m0.66663[0m[0m | time: 8.970s
[2K
| RMSProp | epoch: 006 | loss: 0.66663 - acc: 0.6227 -- iter: 0512/1068
[A[ATraining Step: 187  | total loss: [1m[32m0.66881[0m[0m | time: 9.573s
[2K
| RMSProp | epoch: 006 | loss: 0.66881 - acc: 0.6167 -- iter: 0544/1068
[A[ATraining Step: 188  | total loss: [1m[32m0.67173[0m[0m | time: 10.176s
[2K
| RMSProp | epoch: 006 | loss: 0.67173 - acc: 0.6081 -- iter: 0576/1068
[A[ATraining Step: 189  | total loss: [1m[32m0.67422[0m[0m | time: 10.787s
[2K
| RMSProp | epoch: 006 | loss: 0.67422 - acc: 0.6004 -- iter: 0608/1068
[A[ATraining Step: 190  | total loss: [1m[32m0.67630[0m[0m | time: 11.386s
[2K
| RMSProp | epoch: 006 | loss: 0.67630 - acc: 0.5935 -- iter: 0640/1068
[A[ATraining Step: 191  | total loss: [1m[32m0.67532[0m[0m | time: 11.986s
[2K
| RMSProp | epoch: 006 | loss: 0.67532 - acc: 0.5967 -- iter: 0672/1068
[A[ATraining Step: 192  | total loss: [1m[32m0.67211[0m[0m | time: 12.590s
[2K
| RMSProp | epoch: 006 | loss: 0.67211 - acc: 0.6058 -- iter: 0704/1068
[A[ATraining Step: 193  | total loss: [1m[32m0.67631[0m[0m | time: 13.200s
[2K
| RMSProp | epoch: 006 | loss: 0.67631 - acc: 0.5952 -- iter: 0736/1068
[A[ATraining Step: 194  | total loss: [1m[32m0.67616[0m[0m | time: 13.813s
[2K
| RMSProp | epoch: 006 | loss: 0.67616 - acc: 0.5950 -- iter: 0768/1068
[A[ATraining Step: 195  | total loss: [1m[32m0.68118[0m[0m | time: 14.428s
[2K
| RMSProp | epoch: 006 | loss: 0.68118 - acc: 0.5793 -- iter: 0800/1068
[A[ATraining Step: 196  | total loss: [1m[32m0.68073[0m[0m | time: 15.035s
[2K
| RMSProp | epoch: 006 | loss: 0.68073 - acc: 0.5807 -- iter: 0832/1068
[A[ATraining Step: 197  | total loss: [1m[32m0.67840[0m[0m | time: 15.666s
[2K
| RMSProp | epoch: 006 | loss: 0.67840 - acc: 0.5883 -- iter: 0864/1068
[A[ATraining Step: 198  | total loss: [1m[32m0.67264[0m[0m | time: 16.266s
[2K
| RMSProp | epoch: 006 | loss: 0.67264 - acc: 0.6045 -- iter: 0896/1068
[A[ATraining Step: 199  | total loss: [1m[32m0.68012[0m[0m | time: 16.884s
[2K
| RMSProp | epoch: 006 | loss: 0.68012 - acc: 0.5940 -- iter: 0928/1068
[A[ATraining Step: 200  | total loss: [1m[32m0.68250[0m[0m | time: 18.532s
[2K
| RMSProp | epoch: 006 | loss: 0.68250 - acc: 0.5846 | val_loss: 0.66615 - val_acc: 0.6257 -- iter: 0960/1068
--
Training Step: 201  | total loss: [1m[32m0.68008[0m[0m | time: 19.127s
[2K
| RMSProp | epoch: 006 | loss: 0.68008 - acc: 0.5918 -- iter: 0992/1068
[A[ATraining Step: 202  | total loss: [1m[32m0.68071[0m[0m | time: 19.761s
[2K
| RMSProp | epoch: 006 | loss: 0.68071 - acc: 0.5888 -- iter: 1024/1068
[A[ATraining Step: 203  | total loss: [1m[32m0.68218[0m[0m | time: 20.361s
[2K
| RMSProp | epoch: 006 | loss: 0.68218 - acc: 0.5831 -- iter: 1056/1068
[A[ATraining Step: 204  | total loss: [1m[32m0.67886[0m[0m | time: 22.011s
[2K
| RMSProp | epoch: 006 | loss: 0.67886 - acc: 0.5935 | val_loss: 0.66690 - val_acc: 0.6257 -- iter: 1068/1068
--
Training Step: 205  | total loss: [1m[32m0.68253[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 007 | loss: 0.68253 - acc: 0.5810 -- iter: 0032/1068
[A[ATraining Step: 206  | total loss: [1m[32m0.68101[0m[0m | time: 1.209s
[2K
| RMSProp | epoch: 007 | loss: 0.68101 - acc: 0.5854 -- iter: 0064/1068
[A[ATraining Step: 207  | total loss: [1m[32m0.68715[0m[0m | time: 1.812s
[2K
| RMSProp | epoch: 007 | loss: 0.68715 - acc: 0.5644 -- iter: 0096/1068
[A[ATraining Step: 208  | total loss: [1m[32m0.68293[0m[0m | time: 2.428s
[2K
| RMSProp | epoch: 007 | loss: 0.68293 - acc: 0.5798 -- iter: 0128/1068
[A[ATraining Step: 209  | total loss: [1m[32m0.68499[0m[0m | time: 2.678s
[2K
| RMSProp | epoch: 007 | loss: 0.68499 - acc: 0.5719 -- iter: 0160/1068
[A[ATraining Step: 210  | total loss: [1m[32m0.68234[0m[0m | time: 2.921s
[2K
| RMSProp | epoch: 007 | loss: 0.68234 - acc: 0.5813 -- iter: 0192/1068
[A[ATraining Step: 211  | total loss: [1m[32m0.67957[0m[0m | time: 3.539s
[2K
| RMSProp | epoch: 007 | loss: 0.67957 - acc: 0.5899 -- iter: 0224/1068
[A[ATraining Step: 212  | total loss: [1m[32m0.67925[0m[0m | time: 4.132s
[2K
| RMSProp | epoch: 007 | loss: 0.67925 - acc: 0.5903 -- iter: 0256/1068
[A[ATraining Step: 213  | total loss: [1m[32m0.67975[0m[0m | time: 4.728s
[2K
| RMSProp | epoch: 007 | loss: 0.67975 - acc: 0.5875 -- iter: 0288/1068
[A[ATraining Step: 214  | total loss: [1m[32m0.68125[0m[0m | time: 5.344s
[2K
| RMSProp | epoch: 007 | loss: 0.68125 - acc: 0.5819 -- iter: 0320/1068
[A[ATraining Step: 215  | total loss: [1m[32m0.67983[0m[0m | time: 5.940s
[2K
| RMSProp | epoch: 007 | loss: 0.67983 - acc: 0.5862 -- iter: 0352/1068
[A[ATraining Step: 216  | total loss: [1m[32m0.67308[0m[0m | time: 6.552s
[2K
| RMSProp | epoch: 007 | loss: 0.67308 - acc: 0.6057 -- iter: 0384/1068
[A[ATraining Step: 217  | total loss: [1m[32m0.67190[0m[0m | time: 7.143s
[2K
| RMSProp | epoch: 007 | loss: 0.67190 - acc: 0.6076 -- iter: 0416/1068
[A[ATraining Step: 218  | total loss: [1m[32m0.67079[0m[0m | time: 7.736s
[2K
| RMSProp | epoch: 007 | loss: 0.67079 - acc: 0.6093 -- iter: 0448/1068
[A[ATraining Step: 219  | total loss: [1m[32m0.67319[0m[0m | time: 8.347s
[2K
| RMSProp | epoch: 007 | loss: 0.67319 - acc: 0.6047 -- iter: 0480/1068
[A[ATraining Step: 220  | total loss: [1m[32m0.66831[0m[0m | time: 8.971s
[2K
| RMSProp | epoch: 007 | loss: 0.66831 - acc: 0.6192 -- iter: 0512/1068
[A[ATraining Step: 221  | total loss: [1m[32m0.66767[0m[0m | time: 9.563s
[2K
| RMSProp | epoch: 007 | loss: 0.66767 - acc: 0.6198 -- iter: 0544/1068
[A[ATraining Step: 222  | total loss: [1m[32m0.67028[0m[0m | time: 10.168s
[2K
| RMSProp | epoch: 007 | loss: 0.67028 - acc: 0.6141 -- iter: 0576/1068
[A[ATraining Step: 223  | total loss: [1m[32m0.67171[0m[0m | time: 10.783s
[2K
| RMSProp | epoch: 007 | loss: 0.67171 - acc: 0.6089 -- iter: 0608/1068
[A[ATraining Step: 224  | total loss: [1m[32m0.67295[0m[0m | time: 11.384s
[2K
| RMSProp | epoch: 007 | loss: 0.67295 - acc: 0.6043 -- iter: 0640/1068
[A[ATraining Step: 225  | total loss: [1m[32m0.67614[0m[0m | time: 11.998s
[2K
| RMSProp | epoch: 007 | loss: 0.67614 - acc: 0.5938 -- iter: 0672/1068
[A[ATraining Step: 226  | total loss: [1m[32m0.67970[0m[0m | time: 12.624s
[2K
| RMSProp | epoch: 007 | loss: 0.67970 - acc: 0.5813 -- iter: 0704/1068
[A[ATraining Step: 227  | total loss: [1m[32m0.67949[0m[0m | time: 13.242s
[2K
| RMSProp | epoch: 007 | loss: 0.67949 - acc: 0.5826 -- iter: 0736/1068
[A[ATraining Step: 228  | total loss: [1m[32m0.67651[0m[0m | time: 13.847s
[2K
| RMSProp | epoch: 007 | loss: 0.67651 - acc: 0.5899 -- iter: 0768/1068
[A[ATraining Step: 229  | total loss: [1m[32m0.67114[0m[0m | time: 14.448s
[2K
| RMSProp | epoch: 007 | loss: 0.67114 - acc: 0.5997 -- iter: 0800/1068
[A[ATraining Step: 230  | total loss: [1m[32m0.68195[0m[0m | time: 15.086s
[2K
| RMSProp | epoch: 007 | loss: 0.68195 - acc: 0.6053 -- iter: 0832/1068
[A[ATraining Step: 231  | total loss: [1m[32m0.68202[0m[0m | time: 15.718s
[2K
| RMSProp | epoch: 007 | loss: 0.68202 - acc: 0.6011 -- iter: 0864/1068
[A[ATraining Step: 232  | total loss: [1m[32m0.68178[0m[0m | time: 16.324s
[2K
| RMSProp | epoch: 007 | loss: 0.68178 - acc: 0.5972 -- iter: 0896/1068
[A[ATraining Step: 233  | total loss: [1m[32m0.68425[0m[0m | time: 16.926s
[2K
| RMSProp | epoch: 007 | loss: 0.68425 - acc: 0.5844 -- iter: 0928/1068
[A[ATraining Step: 234  | total loss: [1m[32m0.68460[0m[0m | time: 17.521s
[2K
| RMSProp | epoch: 007 | loss: 0.68460 - acc: 0.5790 -- iter: 0960/1068
[A[ATraining Step: 235  | total loss: [1m[32m0.68407[0m[0m | time: 18.128s
[2K
| RMSProp | epoch: 007 | loss: 0.68407 - acc: 0.5774 -- iter: 0992/1068
[A[ATraining Step: 236  | total loss: [1m[32m0.68471[0m[0m | time: 18.738s
[2K
| RMSProp | epoch: 007 | loss: 0.68471 - acc: 0.5759 -- iter: 1024/1068
[A[ATraining Step: 237  | total loss: [1m[32m0.68097[0m[0m | time: 19.339s
[2K
| RMSProp | epoch: 007 | loss: 0.68097 - acc: 0.5871 -- iter: 1056/1068
[A[ATraining Step: 238  | total loss: [1m[32m0.68133[0m[0m | time: 21.001s
[2K
| RMSProp | epoch: 007 | loss: 0.68133 - acc: 0.5846 | val_loss: 0.65788 - val_acc: 0.6257 -- iter: 1068/1068
--
Training Step: 239  | total loss: [1m[32m0.68033[0m[0m | time: 0.597s
[2K
| RMSProp | epoch: 008 | loss: 0.68033 - acc: 0.5855 -- iter: 0032/1068
[A[ATraining Step: 240  | total loss: [1m[32m0.68284[0m[0m | time: 1.200s
[2K
| RMSProp | epoch: 008 | loss: 0.68284 - acc: 0.5770 -- iter: 0064/1068
[A[ATraining Step: 241  | total loss: [1m[32m0.68566[0m[0m | time: 1.811s
[2K
| RMSProp | epoch: 008 | loss: 0.68566 - acc: 0.5630 -- iter: 0096/1068
[A[ATraining Step: 242  | total loss: [1m[32m0.68435[0m[0m | time: 2.441s
[2K
| RMSProp | epoch: 008 | loss: 0.68435 - acc: 0.5755 -- iter: 0128/1068
[A[ATraining Step: 243  | total loss: [1m[32m0.68250[0m[0m | time: 3.036s
[2K
| RMSProp | epoch: 008 | loss: 0.68250 - acc: 0.5773 -- iter: 0160/1068
[A[ATraining Step: 244  | total loss: [1m[32m0.68118[0m[0m | time: 3.280s
[2K
| RMSProp | epoch: 008 | loss: 0.68118 - acc: 0.5789 -- iter: 0192/1068
[A[ATraining Step: 245  | total loss: [1m[32m0.67837[0m[0m | time: 3.549s
[2K
| RMSProp | epoch: 008 | loss: 0.67837 - acc: 0.5877 -- iter: 0224/1068
[A[ATraining Step: 246  | total loss: [1m[32m0.67464[0m[0m | time: 4.174s
[2K
| RMSProp | epoch: 008 | loss: 0.67464 - acc: 0.5956 -- iter: 0256/1068
[A[ATraining Step: 247  | total loss: [1m[32m0.67373[0m[0m | time: 4.779s
[2K
| RMSProp | epoch: 008 | loss: 0.67373 - acc: 0.5954 -- iter: 0288/1068
[A[ATraining Step: 248  | total loss: [1m[32m0.66660[0m[0m | time: 5.376s
[2K
| RMSProp | epoch: 008 | loss: 0.66660 - acc: 0.6078 -- iter: 0320/1068
[A[ATraining Step: 249  | total loss: [1m[32m0.66463[0m[0m | time: 5.995s
[2K
| RMSProp | epoch: 008 | loss: 0.66463 - acc: 0.6095 -- iter: 0352/1068
[A[ATraining Step: 250  | total loss: [1m[32m0.65448[0m[0m | time: 6.596s
[2K
| RMSProp | epoch: 008 | loss: 0.65448 - acc: 0.6267 -- iter: 0384/1068
[A[ATraining Step: 251  | total loss: [1m[32m0.66537[0m[0m | time: 7.192s
[2K
| RMSProp | epoch: 008 | loss: 0.66537 - acc: 0.6140 -- iter: 0416/1068
[A[ATraining Step: 252  | total loss: [1m[32m0.67048[0m[0m | time: 7.808s
[2K
| RMSProp | epoch: 008 | loss: 0.67048 - acc: 0.5901 -- iter: 0448/1068
[A[ATraining Step: 253  | total loss: [1m[32m0.66969[0m[0m | time: 8.442s
[2K
| RMSProp | epoch: 008 | loss: 0.66969 - acc: 0.5967 -- iter: 0480/1068
[A[ATraining Step: 254  | total loss: [1m[32m0.67664[0m[0m | time: 9.060s
[2K
| RMSProp | epoch: 008 | loss: 0.67664 - acc: 0.5745 -- iter: 0512/1068
[A[ATraining Step: 255  | total loss: [1m[32m0.67700[0m[0m | time: 9.693s
[2K
| RMSProp | epoch: 008 | loss: 0.67700 - acc: 0.5827 -- iter: 0544/1068
[A[ATraining Step: 256  | total loss: [1m[32m0.67548[0m[0m | time: 10.297s
[2K
| RMSProp | epoch: 008 | loss: 0.67548 - acc: 0.5807 -- iter: 0576/1068
[A[ATraining Step: 257  | total loss: [1m[32m0.67391[0m[0m | time: 10.934s
[2K
| RMSProp | epoch: 008 | loss: 0.67391 - acc: 0.5789 -- iter: 0608/1068
[A[ATraining Step: 258  | total loss: [1m[32m0.67313[0m[0m | time: 11.569s
[2K
| RMSProp | epoch: 008 | loss: 0.67313 - acc: 0.5772 -- iter: 0640/1068
[A[ATraining Step: 259  | total loss: [1m[32m0.67725[0m[0m | time: 12.183s
[2K
| RMSProp | epoch: 008 | loss: 0.67725 - acc: 0.5664 -- iter: 0672/1068
[A[ATraining Step: 260  | total loss: [1m[32m0.68252[0m[0m | time: 12.797s
[2K
| RMSProp | epoch: 008 | loss: 0.68252 - acc: 0.5566 -- iter: 0704/1068
[A[ATraining Step: 261  | total loss: [1m[32m0.68048[0m[0m | time: 13.409s
[2K
| RMSProp | epoch: 008 | loss: 0.68048 - acc: 0.5635 -- iter: 0736/1068
[A[ATraining Step: 262  | total loss: [1m[32m0.68852[0m[0m | time: 14.032s
[2K
| RMSProp | epoch: 008 | loss: 0.68852 - acc: 0.5415 -- iter: 0768/1068
[A[ATraining Step: 263  | total loss: [1m[32m0.68554[0m[0m | time: 14.631s
[2K
| RMSProp | epoch: 008 | loss: 0.68554 - acc: 0.5498 -- iter: 0800/1068
[A[ATraining Step: 264  | total loss: [1m[32m0.68250[0m[0m | time: 15.248s
[2K
| RMSProp | epoch: 008 | loss: 0.68250 - acc: 0.5542 -- iter: 0832/1068
[A[ATraining Step: 265  | total loss: [1m[32m0.68104[0m[0m | time: 15.872s
[2K
| RMSProp | epoch: 008 | loss: 0.68104 - acc: 0.5613 -- iter: 0864/1068
[A[ATraining Step: 266  | total loss: [1m[32m0.67801[0m[0m | time: 16.483s
[2K
| RMSProp | epoch: 008 | loss: 0.67801 - acc: 0.5771 -- iter: 0896/1068
[A[ATraining Step: 267  | total loss: [1m[32m0.67328[0m[0m | time: 17.100s
[2K
| RMSProp | epoch: 008 | loss: 0.67328 - acc: 0.5850 -- iter: 0928/1068
[A[ATraining Step: 268  | total loss: [1m[32m0.65822[0m[0m | time: 17.725s
[2K
| RMSProp | epoch: 008 | loss: 0.65822 - acc: 0.6046 -- iter: 0960/1068
[A[ATraining Step: 269  | total loss: [1m[32m0.70170[0m[0m | time: 18.328s
[2K
| RMSProp | epoch: 008 | loss: 0.70170 - acc: 0.5941 -- iter: 0992/1068
[A[ATraining Step: 270  | total loss: [1m[32m0.69526[0m[0m | time: 18.931s
[2K
| RMSProp | epoch: 008 | loss: 0.69526 - acc: 0.6066 -- iter: 1024/1068
[A[ATraining Step: 271  | total loss: [1m[32m0.68807[0m[0m | time: 19.539s
[2K
| RMSProp | epoch: 008 | loss: 0.68807 - acc: 0.6147 -- iter: 1056/1068
[A[ATraining Step: 272  | total loss: [1m[32m0.68527[0m[0m | time: 21.185s
[2K
| RMSProp | epoch: 008 | loss: 0.68527 - acc: 0.6095 | val_loss: 0.62548 - val_acc: 0.6796 -- iter: 1068/1068
--
Training Step: 273  | total loss: [1m[32m0.68406[0m[0m | time: 0.603s
[2K
| RMSProp | epoch: 009 | loss: 0.68406 - acc: 0.6079 -- iter: 0032/1068
[A[ATraining Step: 274  | total loss: [1m[32m0.68251[0m[0m | time: 1.230s
[2K
| RMSProp | epoch: 009 | loss: 0.68251 - acc: 0.6065 -- iter: 0064/1068
[A[ATraining Step: 275  | total loss: [1m[32m0.67249[0m[0m | time: 1.834s
[2K
| RMSProp | epoch: 009 | loss: 0.67249 - acc: 0.6302 -- iter: 0096/1068
[A[ATraining Step: 276  | total loss: [1m[32m0.67495[0m[0m | time: 2.445s
[2K
| RMSProp | epoch: 009 | loss: 0.67495 - acc: 0.6172 -- iter: 0128/1068
[A[ATraining Step: 277  | total loss: [1m[32m0.66552[0m[0m | time: 3.035s
[2K
| RMSProp | epoch: 009 | loss: 0.66552 - acc: 0.6305 -- iter: 0160/1068
[A[ATraining Step: 278  | total loss: [1m[32m0.65548[0m[0m | time: 3.637s
[2K
| RMSProp | epoch: 009 | loss: 0.65548 - acc: 0.6455 -- iter: 0192/1068
[A[ATraining Step: 279  | total loss: [1m[32m0.65663[0m[0m | time: 3.899s
[2K
| RMSProp | epoch: 009 | loss: 0.65663 - acc: 0.6372 -- iter: 0224/1068
[A[ATraining Step: 280  | total loss: [1m[32m0.65726[0m[0m | time: 4.157s
[2K
| RMSProp | epoch: 009 | loss: 0.65726 - acc: 0.6319 -- iter: 0256/1068
[A[ATraining Step: 281  | total loss: [1m[32m0.63871[0m[0m | time: 4.756s
[2K
| RMSProp | epoch: 009 | loss: 0.63871 - acc: 0.6520 -- iter: 0288/1068
[A[ATraining Step: 282  | total loss: [1m[32m0.64696[0m[0m | time: 5.353s
[2K
| RMSProp | epoch: 009 | loss: 0.64696 - acc: 0.6462 -- iter: 0320/1068
[A[ATraining Step: 283  | total loss: [1m[32m0.64937[0m[0m | time: 5.961s
[2K
| RMSProp | epoch: 009 | loss: 0.64937 - acc: 0.6409 -- iter: 0352/1068
[A[ATraining Step: 284  | total loss: [1m[32m0.65349[0m[0m | time: 6.595s
[2K
| RMSProp | epoch: 009 | loss: 0.65349 - acc: 0.6300 -- iter: 0384/1068
[A[ATraining Step: 285  | total loss: [1m[32m0.65427[0m[0m | time: 7.190s
[2K
| RMSProp | epoch: 009 | loss: 0.65427 - acc: 0.6326 -- iter: 0416/1068
[A[ATraining Step: 286  | total loss: [1m[32m0.65580[0m[0m | time: 7.786s
[2K
| RMSProp | epoch: 009 | loss: 0.65580 - acc: 0.6350 -- iter: 0448/1068
[A[ATraining Step: 287  | total loss: [1m[32m0.64885[0m[0m | time: 8.394s
[2K
| RMSProp | epoch: 009 | loss: 0.64885 - acc: 0.6433 -- iter: 0480/1068
[A[ATraining Step: 288  | total loss: [1m[32m0.64887[0m[0m | time: 8.998s
[2K
| RMSProp | epoch: 009 | loss: 0.64887 - acc: 0.6478 -- iter: 0512/1068
[A[ATraining Step: 289  | total loss: [1m[32m0.65024[0m[0m | time: 9.604s
[2K
| RMSProp | epoch: 009 | loss: 0.65024 - acc: 0.6455 -- iter: 0544/1068
[A[ATraining Step: 290  | total loss: [1m[32m0.64691[0m[0m | time: 10.201s
[2K
| RMSProp | epoch: 009 | loss: 0.64691 - acc: 0.6434 -- iter: 0576/1068
[A[ATraining Step: 291  | total loss: [1m[32m0.64313[0m[0m | time: 10.810s
[2K
| RMSProp | epoch: 009 | loss: 0.64313 - acc: 0.6478 -- iter: 0608/1068
[A[ATraining Step: 292  | total loss: [1m[32m0.64019[0m[0m | time: 11.426s
[2K
| RMSProp | epoch: 009 | loss: 0.64019 - acc: 0.6487 -- iter: 0640/1068
[A[ATraining Step: 293  | total loss: [1m[32m0.63729[0m[0m | time: 12.028s
[2K
| RMSProp | epoch: 009 | loss: 0.63729 - acc: 0.6463 -- iter: 0672/1068
[A[ATraining Step: 294  | total loss: [1m[32m0.63550[0m[0m | time: 12.632s
[2K
| RMSProp | epoch: 009 | loss: 0.63550 - acc: 0.6442 -- iter: 0704/1068
[A[ATraining Step: 295  | total loss: [1m[32m0.63316[0m[0m | time: 13.235s
[2K
| RMSProp | epoch: 009 | loss: 0.63316 - acc: 0.6485 -- iter: 0736/1068
[A[ATraining Step: 296  | total loss: [1m[32m0.62507[0m[0m | time: 13.834s
[2K
| RMSProp | epoch: 009 | loss: 0.62507 - acc: 0.6555 -- iter: 0768/1068
[A[ATraining Step: 297  | total loss: [1m[32m0.62978[0m[0m | time: 14.434s
[2K
| RMSProp | epoch: 009 | loss: 0.62978 - acc: 0.6462 -- iter: 0800/1068
[A[ATraining Step: 298  | total loss: [1m[32m0.62706[0m[0m | time: 15.034s
[2K
| RMSProp | epoch: 009 | loss: 0.62706 - acc: 0.6566 -- iter: 0832/1068
[A[ATraining Step: 299  | total loss: [1m[32m0.62118[0m[0m | time: 15.627s
[2K
| RMSProp | epoch: 009 | loss: 0.62118 - acc: 0.6628 -- iter: 0864/1068
[A[ATraining Step: 300  | total loss: [1m[32m0.63801[0m[0m | time: 16.230s
[2K
| RMSProp | epoch: 009 | loss: 0.63801 - acc: 0.6434 -- iter: 0896/1068
[A[ATraining Step: 301  | total loss: [1m[32m0.64318[0m[0m | time: 16.826s
[2K
| RMSProp | epoch: 009 | loss: 0.64318 - acc: 0.6416 -- iter: 0928/1068
[A[ATraining Step: 302  | total loss: [1m[32m0.64159[0m[0m | time: 17.463s
[2K
| RMSProp | epoch: 009 | loss: 0.64159 - acc: 0.6399 -- iter: 0960/1068
[A[ATraining Step: 303  | total loss: [1m[32m0.63884[0m[0m | time: 18.092s
[2K
| RMSProp | epoch: 009 | loss: 0.63884 - acc: 0.6509 -- iter: 0992/1068
[A[ATraining Step: 304  | total loss: [1m[32m0.64937[0m[0m | time: 18.691s
[2K
| RMSProp | epoch: 009 | loss: 0.64937 - acc: 0.6358 -- iter: 1024/1068
[A[ATraining Step: 305  | total loss: [1m[32m0.64863[0m[0m | time: 19.277s
[2K
| RMSProp | epoch: 009 | loss: 0.64863 - acc: 0.6347 -- iter: 1056/1068
[A[ATraining Step: 306  | total loss: [1m[32m0.63905[0m[0m | time: 20.920s
[2K
| RMSProp | epoch: 009 | loss: 0.63905 - acc: 0.6431 | val_loss: 0.56670 - val_acc: 0.7036 -- iter: 1068/1068
--
Training Step: 307  | total loss: [1m[32m0.63810[0m[0m | time: 0.604s
[2K
| RMSProp | epoch: 010 | loss: 0.63810 - acc: 0.6445 -- iter: 0032/1068
[A[ATraining Step: 308  | total loss: [1m[32m0.62178[0m[0m | time: 1.208s
[2K
| RMSProp | epoch: 010 | loss: 0.62178 - acc: 0.6644 -- iter: 0064/1068
[A[ATraining Step: 309  | total loss: [1m[32m0.63252[0m[0m | time: 1.808s
[2K
| RMSProp | epoch: 010 | loss: 0.63252 - acc: 0.6573 -- iter: 0096/1068
[A[ATraining Step: 310  | total loss: [1m[32m0.63029[0m[0m | time: 2.405s
[2K
| RMSProp | epoch: 010 | loss: 0.63029 - acc: 0.6603 -- iter: 0128/1068
[A[ATraining Step: 311  | total loss: [1m[32m0.62791[0m[0m | time: 3.006s
[2K
| RMSProp | epoch: 010 | loss: 0.62791 - acc: 0.6631 -- iter: 0160/1068
[A[ATraining Step: 312  | total loss: [1m[32m0.62295[0m[0m | time: 3.602s
[2K
| RMSProp | epoch: 010 | loss: 0.62295 - acc: 0.6686 -- iter: 0192/1068
[A[ATraining Step: 313  | total loss: [1m[32m0.61429[0m[0m | time: 4.196s
[2K
| RMSProp | epoch: 010 | loss: 0.61429 - acc: 0.6736 -- iter: 0224/1068
[A[ATraining Step: 314  | total loss: [1m[32m0.59497[0m[0m | time: 4.444s
[2K
| RMSProp | epoch: 010 | loss: 0.59497 - acc: 0.6907 -- iter: 0256/1068
[A[ATraining Step: 315  | total loss: [1m[32m0.57263[0m[0m | time: 4.681s
[2K
| RMSProp | epoch: 010 | loss: 0.57263 - acc: 0.7049 -- iter: 0288/1068
[A[ATraining Step: 316  | total loss: [1m[32m0.54921[0m[0m | time: 5.278s
[2K
| RMSProp | epoch: 010 | loss: 0.54921 - acc: 0.7178 -- iter: 0320/1068
[A[ATraining Step: 317  | total loss: [1m[32m0.53502[0m[0m | time: 5.870s
[2K
| RMSProp | epoch: 010 | loss: 0.53502 - acc: 0.7272 -- iter: 0352/1068
[A[ATraining Step: 318  | total loss: [1m[32m0.53412[0m[0m | time: 6.486s
[2K
| RMSProp | epoch: 010 | loss: 0.53412 - acc: 0.7326 -- iter: 0384/1068
[A[ATraining Step: 319  | total loss: [1m[32m0.52557[0m[0m | time: 7.117s
[2K
| RMSProp | epoch: 010 | loss: 0.52557 - acc: 0.7344 -- iter: 0416/1068
[A[ATraining Step: 320  | total loss: [1m[32m0.57184[0m[0m | time: 7.764s
[2K
| RMSProp | epoch: 010 | loss: 0.57184 - acc: 0.7172 -- iter: 0448/1068
[A[ATraining Step: 321  | total loss: [1m[32m0.58408[0m[0m | time: 8.351s
[2K
| RMSProp | epoch: 010 | loss: 0.58408 - acc: 0.7017 -- iter: 0480/1068
[A[ATraining Step: 322  | total loss: [1m[32m0.58025[0m[0m | time: 8.974s
[2K
| RMSProp | epoch: 010 | loss: 0.58025 - acc: 0.7159 -- iter: 0512/1068
[A[ATraining Step: 323  | total loss: [1m[32m0.58087[0m[0m | time: 9.572s
[2K
| RMSProp | epoch: 010 | loss: 0.58087 - acc: 0.7193 -- iter: 0544/1068
[A[ATraining Step: 324  | total loss: [1m[32m0.57734[0m[0m | time: 10.165s
[2K
| RMSProp | epoch: 010 | loss: 0.57734 - acc: 0.7193 -- iter: 0576/1068
[A[ATraining Step: 325  | total loss: [1m[32m0.58352[0m[0m | time: 10.761s
[2K
| RMSProp | epoch: 010 | loss: 0.58352 - acc: 0.7036 -- iter: 0608/1068
[A[ATraining Step: 326  | total loss: [1m[32m0.58002[0m[0m | time: 11.352s
[2K
| RMSProp | epoch: 010 | loss: 0.58002 - acc: 0.7114 -- iter: 0640/1068
[A[ATraining Step: 327  | total loss: [1m[32m0.57460[0m[0m | time: 11.944s
[2K
| RMSProp | epoch: 010 | loss: 0.57460 - acc: 0.7152 -- iter: 0672/1068
[A[ATraining Step: 328  | total loss: [1m[32m0.58569[0m[0m | time: 12.538s
[2K
| RMSProp | epoch: 010 | loss: 0.58569 - acc: 0.7093 -- iter: 0704/1068
[A[ATraining Step: 329  | total loss: [1m[32m0.58432[0m[0m | time: 13.146s
[2K
| RMSProp | epoch: 010 | loss: 0.58432 - acc: 0.7103 -- iter: 0736/1068
[A[ATraining Step: 330  | total loss: [1m[32m0.58922[0m[0m | time: 13.762s
[2K
| RMSProp | epoch: 010 | loss: 0.58922 - acc: 0.7049 -- iter: 0768/1068
[A[ATraining Step: 331  | total loss: [1m[32m0.59279[0m[0m | time: 14.366s
[2K
| RMSProp | epoch: 010 | loss: 0.59279 - acc: 0.6969 -- iter: 0800/1068
[A[ATraining Step: 332  | total loss: [1m[32m0.59414[0m[0m | time: 14.985s
[2K
| RMSProp | epoch: 010 | loss: 0.59414 - acc: 0.6959 -- iter: 0832/1068
[A[ATraining Step: 333  | total loss: [1m[32m0.59594[0m[0m | time: 15.602s
[2K
| RMSProp | epoch: 010 | loss: 0.59594 - acc: 0.6951 -- iter: 0864/1068
[A[ATraining Step: 334  | total loss: [1m[32m0.59813[0m[0m | time: 16.227s
[2K
| RMSProp | epoch: 010 | loss: 0.59813 - acc: 0.6975 -- iter: 0896/1068
[A[ATraining Step: 335  | total loss: [1m[32m0.59514[0m[0m | time: 16.835s
[2K
| RMSProp | epoch: 010 | loss: 0.59514 - acc: 0.6965 -- iter: 0928/1068
[A[ATraining Step: 336  | total loss: [1m[32m0.59297[0m[0m | time: 17.436s
[2K
| RMSProp | epoch: 010 | loss: 0.59297 - acc: 0.6987 -- iter: 0960/1068
[A[ATraining Step: 337  | total loss: [1m[32m0.59249[0m[0m | time: 18.028s
[2K
| RMSProp | epoch: 010 | loss: 0.59249 - acc: 0.7038 -- iter: 0992/1068
[A[ATraining Step: 338  | total loss: [1m[32m0.58867[0m[0m | time: 18.626s
[2K
| RMSProp | epoch: 010 | loss: 0.58867 - acc: 0.7022 -- iter: 1024/1068
[A[ATraining Step: 339  | total loss: [1m[32m0.59163[0m[0m | time: 19.232s
[2K
| RMSProp | epoch: 010 | loss: 0.59163 - acc: 0.6976 -- iter: 1056/1068
[A[ATraining Step: 340  | total loss: [1m[32m0.58227[0m[0m | time: 20.891s
[2K
| RMSProp | epoch: 010 | loss: 0.58227 - acc: 0.7122 | val_loss: 0.52194 - val_acc: 0.7575 -- iter: 1068/1068
--
Training Step: 341  | total loss: [1m[32m0.57136[0m[0m | time: 0.600s
[2K
| RMSProp | epoch: 011 | loss: 0.57136 - acc: 0.7222 -- iter: 0032/1068
[A[ATraining Step: 342  | total loss: [1m[32m0.56633[0m[0m | time: 1.191s
[2K
| RMSProp | epoch: 011 | loss: 0.56633 - acc: 0.7219 -- iter: 0064/1068
[A[ATraining Step: 343  | total loss: [1m[32m0.56617[0m[0m | time: 1.794s
[2K
| RMSProp | epoch: 011 | loss: 0.56617 - acc: 0.7216 -- iter: 0096/1068
[A[ATraining Step: 344  | total loss: [1m[32m0.57174[0m[0m | time: 2.387s
[2K
| RMSProp | epoch: 011 | loss: 0.57174 - acc: 0.7182 -- iter: 0128/1068
[A[ATraining Step: 345  | total loss: [1m[32m0.56485[0m[0m | time: 3.003s
[2K
| RMSProp | epoch: 011 | loss: 0.56485 - acc: 0.7307 -- iter: 0160/1068
[A[ATraining Step: 346  | total loss: [1m[32m0.55010[0m[0m | time: 3.607s
[2K
| RMSProp | epoch: 011 | loss: 0.55010 - acc: 0.7389 -- iter: 0192/1068
[A[ATraining Step: 347  | total loss: [1m[32m0.53056[0m[0m | time: 4.209s
[2K
| RMSProp | epoch: 011 | loss: 0.53056 - acc: 0.7556 -- iter: 0224/1068
[A[ATraining Step: 348  | total loss: [1m[32m0.50828[0m[0m | time: 4.828s
[2K
| RMSProp | epoch: 011 | loss: 0.50828 - acc: 0.7707 -- iter: 0256/1068
[A[ATraining Step: 349  | total loss: [1m[32m0.51144[0m[0m | time: 5.075s
[2K
| RMSProp | epoch: 011 | loss: 0.51144 - acc: 0.7686 -- iter: 0288/1068
[A[ATraining Step: 350  | total loss: [1m[32m0.51337[0m[0m | time: 5.338s
[2K
| RMSProp | epoch: 011 | loss: 0.51337 - acc: 0.7668 -- iter: 0320/1068
[A[ATraining Step: 351  | total loss: [1m[32m0.51339[0m[0m | time: 5.952s
[2K
| RMSProp | epoch: 011 | loss: 0.51339 - acc: 0.7568 -- iter: 0352/1068
[A[ATraining Step: 352  | total loss: [1m[32m0.51487[0m[0m | time: 6.572s
[2K
| RMSProp | epoch: 011 | loss: 0.51487 - acc: 0.7530 -- iter: 0384/1068
[A[ATraining Step: 353  | total loss: [1m[32m0.49551[0m[0m | time: 7.191s
[2K
| RMSProp | epoch: 011 | loss: 0.49551 - acc: 0.7683 -- iter: 0416/1068
[A[ATraining Step: 354  | total loss: [1m[32m0.48677[0m[0m | time: 7.782s
[2K
| RMSProp | epoch: 011 | loss: 0.48677 - acc: 0.7696 -- iter: 0448/1068
[A[ATraining Step: 355  | total loss: [1m[32m0.49364[0m[0m | time: 8.382s
[2K
| RMSProp | epoch: 011 | loss: 0.49364 - acc: 0.7645 -- iter: 0480/1068
[A[ATraining Step: 356  | total loss: [1m[32m0.48869[0m[0m | time: 8.988s
[2K
| RMSProp | epoch: 011 | loss: 0.48869 - acc: 0.7662 -- iter: 0512/1068
[A[ATraining Step: 357  | total loss: [1m[32m0.51251[0m[0m | time: 9.622s
[2K
| RMSProp | epoch: 011 | loss: 0.51251 - acc: 0.7552 -- iter: 0544/1068
[A[ATraining Step: 358  | total loss: [1m[32m0.51703[0m[0m | time: 10.259s
[2K
| RMSProp | epoch: 011 | loss: 0.51703 - acc: 0.7515 -- iter: 0576/1068
[A[ATraining Step: 359  | total loss: [1m[32m0.51556[0m[0m | time: 10.864s
[2K
| RMSProp | epoch: 011 | loss: 0.51556 - acc: 0.7576 -- iter: 0608/1068
[A[ATraining Step: 360  | total loss: [1m[32m0.52237[0m[0m | time: 11.466s
[2K
| RMSProp | epoch: 011 | loss: 0.52237 - acc: 0.7506 -- iter: 0640/1068
[A[ATraining Step: 361  | total loss: [1m[32m0.52060[0m[0m | time: 12.073s
[2K
| RMSProp | epoch: 011 | loss: 0.52060 - acc: 0.7474 -- iter: 0672/1068
[A[ATraining Step: 362  | total loss: [1m[32m0.52536[0m[0m | time: 12.720s
[2K
| RMSProp | epoch: 011 | loss: 0.52536 - acc: 0.7414 -- iter: 0704/1068
[A[ATraining Step: 363  | total loss: [1m[32m0.55691[0m[0m | time: 13.348s
[2K
| RMSProp | epoch: 011 | loss: 0.55691 - acc: 0.7142 -- iter: 0736/1068
[A[ATraining Step: 364  | total loss: [1m[32m0.55157[0m[0m | time: 13.961s
[2K
| RMSProp | epoch: 011 | loss: 0.55157 - acc: 0.7365 -- iter: 0768/1068
[A[ATraining Step: 365  | total loss: [1m[32m0.53974[0m[0m | time: 14.566s
[2K
| RMSProp | epoch: 011 | loss: 0.53974 - acc: 0.7504 -- iter: 0800/1068
[A[ATraining Step: 366  | total loss: [1m[32m0.52361[0m[0m | time: 15.174s
[2K
| RMSProp | epoch: 011 | loss: 0.52361 - acc: 0.7659 -- iter: 0832/1068
[A[ATraining Step: 367  | total loss: [1m[32m0.50724[0m[0m | time: 15.777s
[2K
| RMSProp | epoch: 011 | loss: 0.50724 - acc: 0.7737 -- iter: 0864/1068
[A[ATraining Step: 368  | total loss: [1m[32m0.48839[0m[0m | time: 16.382s
[2K
| RMSProp | epoch: 011 | loss: 0.48839 - acc: 0.7870 -- iter: 0896/1068
[A[ATraining Step: 369  | total loss: [1m[32m0.49099[0m[0m | time: 16.988s
[2K
| RMSProp | epoch: 011 | loss: 0.49099 - acc: 0.7833 -- iter: 0928/1068
[A[ATraining Step: 370  | total loss: [1m[32m0.50099[0m[0m | time: 17.621s
[2K
| RMSProp | epoch: 011 | loss: 0.50099 - acc: 0.7768 -- iter: 0960/1068
[A[ATraining Step: 371  | total loss: [1m[32m0.51035[0m[0m | time: 18.230s
[2K
| RMSProp | epoch: 011 | loss: 0.51035 - acc: 0.7648 -- iter: 0992/1068
[A[ATraining Step: 372  | total loss: [1m[32m0.50849[0m[0m | time: 18.838s
[2K
| RMSProp | epoch: 011 | loss: 0.50849 - acc: 0.7695 -- iter: 1024/1068
[A[ATraining Step: 373  | total loss: [1m[32m0.50203[0m[0m | time: 19.453s
[2K
| RMSProp | epoch: 011 | loss: 0.50203 - acc: 0.7645 -- iter: 1056/1068
[A[ATraining Step: 374  | total loss: [1m[32m0.49037[0m[0m | time: 21.103s
[2K
| RMSProp | epoch: 011 | loss: 0.49037 - acc: 0.7661 | val_loss: 0.45763 - val_acc: 0.7994 -- iter: 1068/1068
--
Training Step: 375  | total loss: [1m[32m0.48630[0m[0m | time: 0.616s
[2K
| RMSProp | epoch: 012 | loss: 0.48630 - acc: 0.7677 -- iter: 0032/1068
[A[ATraining Step: 376  | total loss: [1m[32m0.46056[0m[0m | time: 1.242s
[2K
| RMSProp | epoch: 012 | loss: 0.46056 - acc: 0.7846 -- iter: 0064/1068
[A[ATraining Step: 377  | total loss: [1m[32m0.47538[0m[0m | time: 1.839s
[2K
| RMSProp | epoch: 012 | loss: 0.47538 - acc: 0.7843 -- iter: 0096/1068
[A[ATraining Step: 378  | total loss: [1m[32m0.47656[0m[0m | time: 2.445s
[2K
| RMSProp | epoch: 012 | loss: 0.47656 - acc: 0.7840 -- iter: 0128/1068
[A[ATraining Step: 379  | total loss: [1m[32m0.46627[0m[0m | time: 3.048s
[2K
| RMSProp | epoch: 012 | loss: 0.46627 - acc: 0.7931 -- iter: 0160/1068
[A[ATraining Step: 380  | total loss: [1m[32m0.47042[0m[0m | time: 3.640s
[2K
| RMSProp | epoch: 012 | loss: 0.47042 - acc: 0.7919 -- iter: 0192/1068
[A[ATraining Step: 381  | total loss: [1m[32m0.48041[0m[0m | time: 4.222s
[2K
| RMSProp | epoch: 012 | loss: 0.48041 - acc: 0.7877 -- iter: 0224/1068
[A[ATraining Step: 382  | total loss: [1m[32m0.48479[0m[0m | time: 4.838s
[2K
| RMSProp | epoch: 012 | loss: 0.48479 - acc: 0.7808 -- iter: 0256/1068
[A[ATraining Step: 383  | total loss: [1m[32m0.47683[0m[0m | time: 5.441s
[2K
| RMSProp | epoch: 012 | loss: 0.47683 - acc: 0.7902 -- iter: 0288/1068
[A[ATraining Step: 384  | total loss: [1m[32m0.47941[0m[0m | time: 5.684s
[2K
| RMSProp | epoch: 012 | loss: 0.47941 - acc: 0.7893 -- iter: 0320/1068
[A[ATraining Step: 385  | total loss: [1m[32m0.47209[0m[0m | time: 5.926s
[2K
| RMSProp | epoch: 012 | loss: 0.47209 - acc: 0.7937 -- iter: 0352/1068
[A[ATraining Step: 386  | total loss: [1m[32m0.45917[0m[0m | time: 6.521s
[2K
| RMSProp | epoch: 012 | loss: 0.45917 - acc: 0.7977 -- iter: 0384/1068
[A[ATraining Step: 387  | total loss: [1m[32m0.49802[0m[0m | time: 7.112s
[2K
| RMSProp | epoch: 012 | loss: 0.49802 - acc: 0.7773 -- iter: 0416/1068
[A[ATraining Step: 388  | total loss: [1m[32m0.50007[0m[0m | time: 7.725s
[2K
| RMSProp | epoch: 012 | loss: 0.50007 - acc: 0.7839 -- iter: 0448/1068
[A[ATraining Step: 389  | total loss: [1m[32m0.49560[0m[0m | time: 8.345s
[2K
| RMSProp | epoch: 012 | loss: 0.49560 - acc: 0.7868 -- iter: 0480/1068
[A[ATraining Step: 390  | total loss: [1m[32m0.50336[0m[0m | time: 8.954s
[2K
| RMSProp | epoch: 012 | loss: 0.50336 - acc: 0.7769 -- iter: 0512/1068
[A[ATraining Step: 391  | total loss: [1m[32m0.49501[0m[0m | time: 9.550s
[2K
| RMSProp | epoch: 012 | loss: 0.49501 - acc: 0.7804 -- iter: 0544/1068
[A[ATraining Step: 392  | total loss: [1m[32m0.50048[0m[0m | time: 10.156s
[2K
| RMSProp | epoch: 012 | loss: 0.50048 - acc: 0.7649 -- iter: 0576/1068
[A[ATraining Step: 393  | total loss: [1m[32m0.49473[0m[0m | time: 10.758s
[2K
| RMSProp | epoch: 012 | loss: 0.49473 - acc: 0.7665 -- iter: 0608/1068
[A[ATraining Step: 394  | total loss: [1m[32m0.48113[0m[0m | time: 11.367s
[2K
| RMSProp | epoch: 012 | loss: 0.48113 - acc: 0.7805 -- iter: 0640/1068
[A[ATraining Step: 395  | total loss: [1m[32m0.48140[0m[0m | time: 11.958s
[2K
| RMSProp | epoch: 012 | loss: 0.48140 - acc: 0.7806 -- iter: 0672/1068
[A[ATraining Step: 396  | total loss: [1m[32m0.46493[0m[0m | time: 12.551s
[2K
| RMSProp | epoch: 012 | loss: 0.46493 - acc: 0.7963 -- iter: 0704/1068
[A[ATraining Step: 397  | total loss: [1m[32m0.46589[0m[0m | time: 13.146s
[2K
| RMSProp | epoch: 012 | loss: 0.46589 - acc: 0.7948 -- iter: 0736/1068
[A[ATraining Step: 398  | total loss: [1m[32m0.46365[0m[0m | time: 13.755s
[2K
| RMSProp | epoch: 012 | loss: 0.46365 - acc: 0.7934 -- iter: 0768/1068
[A[ATraining Step: 399  | total loss: [1m[32m0.45872[0m[0m | time: 14.355s
[2K
| RMSProp | epoch: 012 | loss: 0.45872 - acc: 0.7922 -- iter: 0800/1068
[A[ATraining Step: 400  | total loss: [1m[32m0.46235[0m[0m | time: 16.002s
[2K
| RMSProp | epoch: 012 | loss: 0.46235 - acc: 0.7974 | val_loss: 0.42120 - val_acc: 0.8144 -- iter: 0832/1068
--
Training Step: 401  | total loss: [1m[32m0.45335[0m[0m | time: 16.634s
[2K
| RMSProp | epoch: 012 | loss: 0.45335 - acc: 0.8082 -- iter: 0864/1068
[A[ATraining Step: 402  | total loss: [1m[32m0.44946[0m[0m | time: 17.233s
[2K
| RMSProp | epoch: 012 | loss: 0.44946 - acc: 0.8087 -- iter: 0896/1068
[A[ATraining Step: 403  | total loss: [1m[32m0.44404[0m[0m | time: 17.827s
[2K
| RMSProp | epoch: 012 | loss: 0.44404 - acc: 0.8028 -- iter: 0928/1068
[A[ATraining Step: 404  | total loss: [1m[32m0.44231[0m[0m | time: 18.442s
[2K
| RMSProp | epoch: 012 | loss: 0.44231 - acc: 0.8038 -- iter: 0960/1068
[A[ATraining Step: 405  | total loss: [1m[32m0.42569[0m[0m | time: 19.055s
[2K
| RMSProp | epoch: 012 | loss: 0.42569 - acc: 0.8171 -- iter: 0992/1068
[A[ATraining Step: 406  | total loss: [1m[32m0.42028[0m[0m | time: 19.659s
[2K
| RMSProp | epoch: 012 | loss: 0.42028 - acc: 0.8229 -- iter: 1024/1068
[A[ATraining Step: 407  | total loss: [1m[32m0.42657[0m[0m | time: 20.269s
[2K
| RMSProp | epoch: 012 | loss: 0.42657 - acc: 0.8219 -- iter: 1056/1068
[A[ATraining Step: 408  | total loss: [1m[32m0.41790[0m[0m | time: 21.942s
[2K
| RMSProp | epoch: 012 | loss: 0.41790 - acc: 0.8303 | val_loss: 0.42852 - val_acc: 0.8174 -- iter: 1068/1068
--
Training Step: 409  | total loss: [1m[32m0.41166[0m[0m | time: 0.604s
[2K
| RMSProp | epoch: 013 | loss: 0.41166 - acc: 0.8317 -- iter: 0032/1068
[A[ATraining Step: 410  | total loss: [1m[32m0.43261[0m[0m | time: 1.231s
[2K
| RMSProp | epoch: 013 | loss: 0.43261 - acc: 0.8204 -- iter: 0064/1068
[A[ATraining Step: 411  | total loss: [1m[32m0.46930[0m[0m | time: 1.836s
[2K
| RMSProp | epoch: 013 | loss: 0.46930 - acc: 0.7915 -- iter: 0096/1068
[A[ATraining Step: 412  | total loss: [1m[32m0.47570[0m[0m | time: 2.453s
[2K
| RMSProp | epoch: 013 | loss: 0.47570 - acc: 0.7811 -- iter: 0128/1068
[A[ATraining Step: 413  | total loss: [1m[32m0.47300[0m[0m | time: 3.065s
[2K
| RMSProp | epoch: 013 | loss: 0.47300 - acc: 0.7811 -- iter: 0160/1068
[A[ATraining Step: 414  | total loss: [1m[32m0.48057[0m[0m | time: 3.678s
[2K
| RMSProp | epoch: 013 | loss: 0.48057 - acc: 0.7717 -- iter: 0192/1068
[A[ATraining Step: 415  | total loss: [1m[32m0.47114[0m[0m | time: 4.285s
[2K
| RMSProp | epoch: 013 | loss: 0.47114 - acc: 0.7758 -- iter: 0224/1068
[A[ATraining Step: 416  | total loss: [1m[32m0.45923[0m[0m | time: 4.892s
[2K
| RMSProp | epoch: 013 | loss: 0.45923 - acc: 0.7857 -- iter: 0256/1068
[A[ATraining Step: 417  | total loss: [1m[32m0.45203[0m[0m | time: 5.491s
[2K
| RMSProp | epoch: 013 | loss: 0.45203 - acc: 0.7947 -- iter: 0288/1068
[A[ATraining Step: 418  | total loss: [1m[32m0.44687[0m[0m | time: 6.137s
[2K
| RMSProp | epoch: 013 | loss: 0.44687 - acc: 0.7933 -- iter: 0320/1068
[A[ATraining Step: 419  | total loss: [1m[32m0.45528[0m[0m | time: 6.381s
[2K
| RMSProp | epoch: 013 | loss: 0.45528 - acc: 0.7890 -- iter: 0352/1068
[A[ATraining Step: 420  | total loss: [1m[32m0.44789[0m[0m | time: 6.629s
[2K
| RMSProp | epoch: 013 | loss: 0.44789 - acc: 0.7934 -- iter: 0384/1068
[A[ATraining Step: 421  | total loss: [1m[32m0.42871[0m[0m | time: 7.226s
[2K
| RMSProp | epoch: 013 | loss: 0.42871 - acc: 0.8057 -- iter: 0416/1068
[A[ATraining Step: 422  | total loss: [1m[32m0.42137[0m[0m | time: 7.838s
[2K
| RMSProp | epoch: 013 | loss: 0.42137 - acc: 0.8095 -- iter: 0448/1068
[A[ATraining Step: 423  | total loss: [1m[32m0.41192[0m[0m | time: 8.454s
[2K
| RMSProp | epoch: 013 | loss: 0.41192 - acc: 0.8161 -- iter: 0480/1068
[A[ATraining Step: 424  | total loss: [1m[32m0.39736[0m[0m | time: 9.054s
[2K
| RMSProp | epoch: 013 | loss: 0.39736 - acc: 0.8251 -- iter: 0512/1068
[A[ATraining Step: 425  | total loss: [1m[32m0.37793[0m[0m | time: 9.647s
[2K
| RMSProp | epoch: 013 | loss: 0.37793 - acc: 0.8395 -- iter: 0544/1068
[A[ATraining Step: 426  | total loss: [1m[32m0.37569[0m[0m | time: 10.260s
[2K
| RMSProp | epoch: 013 | loss: 0.37569 - acc: 0.8430 -- iter: 0576/1068
[A[ATraining Step: 427  | total loss: [1m[32m0.36359[0m[0m | time: 10.877s
[2K
| RMSProp | epoch: 013 | loss: 0.36359 - acc: 0.8493 -- iter: 0608/1068
[A[ATraining Step: 428  | total loss: [1m[32m0.35168[0m[0m | time: 11.512s
[2K
| RMSProp | epoch: 013 | loss: 0.35168 - acc: 0.8550 -- iter: 0640/1068
[A[ATraining Step: 429  | total loss: [1m[32m0.36603[0m[0m | time: 12.123s
[2K
| RMSProp | epoch: 013 | loss: 0.36603 - acc: 0.8445 -- iter: 0672/1068
[A[ATraining Step: 430  | total loss: [1m[32m0.40719[0m[0m | time: 12.724s
[2K
| RMSProp | epoch: 013 | loss: 0.40719 - acc: 0.8226 -- iter: 0704/1068
[A[ATraining Step: 431  | total loss: [1m[32m0.41523[0m[0m | time: 13.323s
[2K
| RMSProp | epoch: 013 | loss: 0.41523 - acc: 0.8091 -- iter: 0736/1068
[A[ATraining Step: 432  | total loss: [1m[32m0.41090[0m[0m | time: 13.935s
[2K
| RMSProp | epoch: 013 | loss: 0.41090 - acc: 0.8157 -- iter: 0768/1068
[A[ATraining Step: 433  | total loss: [1m[32m0.39936[0m[0m | time: 14.535s
[2K
| RMSProp | epoch: 013 | loss: 0.39936 - acc: 0.8247 -- iter: 0800/1068
[A[ATraining Step: 434  | total loss: [1m[32m0.39762[0m[0m | time: 15.137s
[2K
| RMSProp | epoch: 013 | loss: 0.39762 - acc: 0.8235 -- iter: 0832/1068
[A[ATraining Step: 435  | total loss: [1m[32m0.39395[0m[0m | time: 15.737s
[2K
| RMSProp | epoch: 013 | loss: 0.39395 - acc: 0.8286 -- iter: 0864/1068
[A[ATraining Step: 436  | total loss: [1m[32m0.38442[0m[0m | time: 16.350s
[2K
| RMSProp | epoch: 013 | loss: 0.38442 - acc: 0.8333 -- iter: 0896/1068
[A[ATraining Step: 437  | total loss: [1m[32m0.39028[0m[0m | time: 16.958s
[2K
| RMSProp | epoch: 013 | loss: 0.39028 - acc: 0.8375 -- iter: 0928/1068
[A[ATraining Step: 438  | total loss: [1m[32m0.39191[0m[0m | time: 17.554s
[2K
| RMSProp | epoch: 013 | loss: 0.39191 - acc: 0.8381 -- iter: 0960/1068
[A[ATraining Step: 439  | total loss: [1m[32m0.38481[0m[0m | time: 18.168s
[2K
| RMSProp | epoch: 013 | loss: 0.38481 - acc: 0.8418 -- iter: 0992/1068
[A[ATraining Step: 440  | total loss: [1m[32m0.40011[0m[0m | time: 18.766s
[2K
| RMSProp | epoch: 013 | loss: 0.40011 - acc: 0.8295 -- iter: 1024/1068
[A[ATraining Step: 441  | total loss: [1m[32m0.39596[0m[0m | time: 19.390s
[2K
| RMSProp | epoch: 013 | loss: 0.39596 - acc: 0.8309 -- iter: 1056/1068
[A[ATraining Step: 442  | total loss: [1m[32m0.38379[0m[0m | time: 21.039s
[2K
| RMSProp | epoch: 013 | loss: 0.38379 - acc: 0.8353 | val_loss: 0.42822 - val_acc: 0.8323 -- iter: 1068/1068
--
Training Step: 443  | total loss: [1m[32m0.36709[0m[0m | time: 0.607s
[2K
| RMSProp | epoch: 014 | loss: 0.36709 - acc: 0.8455 -- iter: 0032/1068
[A[ATraining Step: 444  | total loss: [1m[32m0.36764[0m[0m | time: 1.211s
[2K
| RMSProp | epoch: 014 | loss: 0.36764 - acc: 0.8391 -- iter: 0064/1068
[A[ATraining Step: 445  | total loss: [1m[32m0.38521[0m[0m | time: 1.813s
[2K
| RMSProp | epoch: 014 | loss: 0.38521 - acc: 0.8302 -- iter: 0096/1068
[A[ATraining Step: 446  | total loss: [1m[32m0.38473[0m[0m | time: 2.427s
[2K
| RMSProp | epoch: 014 | loss: 0.38473 - acc: 0.8284 -- iter: 0128/1068
[A[ATraining Step: 447  | total loss: [1m[32m0.36948[0m[0m | time: 3.024s
[2K
| RMSProp | epoch: 014 | loss: 0.36948 - acc: 0.8393 -- iter: 0160/1068
[A[ATraining Step: 448  | total loss: [1m[32m0.37123[0m[0m | time: 3.615s
[2K
| RMSProp | epoch: 014 | loss: 0.37123 - acc: 0.8366 -- iter: 0192/1068
[A[ATraining Step: 449  | total loss: [1m[32m0.35971[0m[0m | time: 4.205s
[2K
| RMSProp | epoch: 014 | loss: 0.35971 - acc: 0.8436 -- iter: 0224/1068
[A[ATraining Step: 450  | total loss: [1m[32m0.36070[0m[0m | time: 4.801s
[2K
| RMSProp | epoch: 014 | loss: 0.36070 - acc: 0.8374 -- iter: 0256/1068
[A[ATraining Step: 451  | total loss: [1m[32m0.38895[0m[0m | time: 5.398s
[2K
| RMSProp | epoch: 014 | loss: 0.38895 - acc: 0.8224 -- iter: 0288/1068
[A[ATraining Step: 452  | total loss: [1m[32m0.38259[0m[0m | time: 6.006s
[2K
| RMSProp | epoch: 014 | loss: 0.38259 - acc: 0.8276 -- iter: 0320/1068
[A[ATraining Step: 453  | total loss: [1m[32m0.37248[0m[0m | time: 6.624s
[2K
| RMSProp | epoch: 014 | loss: 0.37248 - acc: 0.8324 -- iter: 0352/1068
[A[ATraining Step: 454  | total loss: [1m[32m0.37449[0m[0m | time: 6.875s
[2K
| RMSProp | epoch: 014 | loss: 0.37449 - acc: 0.8304 -- iter: 0384/1068
[A[ATraining Step: 455  | total loss: [1m[32m0.36925[0m[0m | time: 7.132s
[2K
| RMSProp | epoch: 014 | loss: 0.36925 - acc: 0.8390 -- iter: 0416/1068
[A[ATraining Step: 456  | total loss: [1m[32m0.38343[0m[0m | time: 7.730s
[2K
| RMSProp | epoch: 014 | loss: 0.38343 - acc: 0.8301 -- iter: 0448/1068
[A[ATraining Step: 457  | total loss: [1m[32m0.38206[0m[0m | time: 8.328s
[2K
| RMSProp | epoch: 014 | loss: 0.38206 - acc: 0.8315 -- iter: 0480/1068
[A[ATraining Step: 458  | total loss: [1m[32m0.37583[0m[0m | time: 8.924s
[2K
| RMSProp | epoch: 014 | loss: 0.37583 - acc: 0.8390 -- iter: 0512/1068
[A[ATraining Step: 459  | total loss: [1m[32m0.36148[0m[0m | time: 9.517s
[2K
| RMSProp | epoch: 014 | loss: 0.36148 - acc: 0.8488 -- iter: 0544/1068
[A[ATraining Step: 460  | total loss: [1m[32m0.37425[0m[0m | time: 10.136s
[2K
| RMSProp | epoch: 014 | loss: 0.37425 - acc: 0.8421 -- iter: 0576/1068
[A[ATraining Step: 461  | total loss: [1m[32m0.40637[0m[0m | time: 10.738s
[2K
| RMSProp | epoch: 014 | loss: 0.40637 - acc: 0.8297 -- iter: 0608/1068
[A[ATraining Step: 462  | total loss: [1m[32m0.38773[0m[0m | time: 11.338s
[2K
| RMSProp | epoch: 014 | loss: 0.38773 - acc: 0.8405 -- iter: 0640/1068
[A[ATraining Step: 463  | total loss: [1m[32m0.37315[0m[0m | time: 11.947s
[2K
| RMSProp | epoch: 014 | loss: 0.37315 - acc: 0.8471 -- iter: 0672/1068
[A[ATraining Step: 464  | total loss: [1m[32m0.35926[0m[0m | time: 12.555s
[2K
| RMSProp | epoch: 014 | loss: 0.35926 - acc: 0.8561 -- iter: 0704/1068
[A[ATraining Step: 465  | total loss: [1m[32m0.37920[0m[0m | time: 13.155s
[2K
| RMSProp | epoch: 014 | loss: 0.37920 - acc: 0.8393 -- iter: 0736/1068
[A[ATraining Step: 466  | total loss: [1m[32m0.38160[0m[0m | time: 13.745s
[2K
| RMSProp | epoch: 014 | loss: 0.38160 - acc: 0.8397 -- iter: 0768/1068
[A[ATraining Step: 467  | total loss: [1m[32m0.36146[0m[0m | time: 14.340s
[2K
| RMSProp | epoch: 014 | loss: 0.36146 - acc: 0.8526 -- iter: 0800/1068
[A[ATraining Step: 468  | total loss: [1m[32m0.36387[0m[0m | time: 14.949s
[2K
| RMSProp | epoch: 014 | loss: 0.36387 - acc: 0.8517 -- iter: 0832/1068
[A[ATraining Step: 469  | total loss: [1m[32m0.35344[0m[0m | time: 15.557s
[2K
| RMSProp | epoch: 014 | loss: 0.35344 - acc: 0.8572 -- iter: 0864/1068
[A[ATraining Step: 470  | total loss: [1m[32m0.35190[0m[0m | time: 16.173s
[2K
| RMSProp | epoch: 014 | loss: 0.35190 - acc: 0.8590 -- iter: 0896/1068
[A[ATraining Step: 471  | total loss: [1m[32m0.34585[0m[0m | time: 16.777s
[2K
| RMSProp | epoch: 014 | loss: 0.34585 - acc: 0.8574 -- iter: 0928/1068
[A[ATraining Step: 472  | total loss: [1m[32m0.34162[0m[0m | time: 17.378s
[2K
| RMSProp | epoch: 014 | loss: 0.34162 - acc: 0.8623 -- iter: 0960/1068
[A[ATraining Step: 473  | total loss: [1m[32m0.33358[0m[0m | time: 17.986s
[2K
| RMSProp | epoch: 014 | loss: 0.33358 - acc: 0.8698 -- iter: 0992/1068
[A[ATraining Step: 474  | total loss: [1m[32m0.33203[0m[0m | time: 18.584s
[2K
| RMSProp | epoch: 014 | loss: 0.33203 - acc: 0.8672 -- iter: 1024/1068
[A[ATraining Step: 475  | total loss: [1m[32m0.31943[0m[0m | time: 19.205s
[2K
| RMSProp | epoch: 014 | loss: 0.31943 - acc: 0.8774 -- iter: 1056/1068
[A[ATraining Step: 476  | total loss: [1m[32m0.31131[0m[0m | time: 20.873s
[2K
| RMSProp | epoch: 014 | loss: 0.31131 - acc: 0.8803 | val_loss: 0.92296 - val_acc: 0.6557 -- iter: 1068/1068
--
Training Step: 477  | total loss: [1m[32m0.32037[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 015 | loss: 0.32037 - acc: 0.8704 -- iter: 0032/1068
[A[ATraining Step: 478  | total loss: [1m[32m0.36804[0m[0m | time: 1.262s
[2K
| RMSProp | epoch: 015 | loss: 0.36804 - acc: 0.8583 -- iter: 0064/1068
[A[ATraining Step: 479  | total loss: [1m[32m0.35453[0m[0m | time: 1.900s
[2K
| RMSProp | epoch: 015 | loss: 0.35453 - acc: 0.8631 -- iter: 0096/1068
[A[ATraining Step: 480  | total loss: [1m[32m0.33528[0m[0m | time: 2.511s
[2K
| RMSProp | epoch: 015 | loss: 0.33528 - acc: 0.8737 -- iter: 0128/1068
[A[ATraining Step: 481  | total loss: [1m[32m0.32802[0m[0m | time: 3.107s
[2K
| RMSProp | epoch: 015 | loss: 0.32802 - acc: 0.8707 -- iter: 0160/1068
[A[ATraining Step: 482  | total loss: [1m[32m0.32556[0m[0m | time: 3.707s
[2K
| RMSProp | epoch: 015 | loss: 0.32556 - acc: 0.8680 -- iter: 0192/1068
[A[ATraining Step: 483  | total loss: [1m[32m0.32835[0m[0m | time: 4.315s
[2K
| RMSProp | epoch: 015 | loss: 0.32835 - acc: 0.8656 -- iter: 0224/1068
[A[ATraining Step: 484  | total loss: [1m[32m0.34396[0m[0m | time: 4.925s
[2K
| RMSProp | epoch: 015 | loss: 0.34396 - acc: 0.8571 -- iter: 0256/1068
[A[ATraining Step: 485  | total loss: [1m[32m0.33542[0m[0m | time: 5.547s
[2K
| RMSProp | epoch: 015 | loss: 0.33542 - acc: 0.8621 -- iter: 0288/1068
[A[ATraining Step: 486  | total loss: [1m[32m0.32522[0m[0m | time: 6.136s
[2K
| RMSProp | epoch: 015 | loss: 0.32522 - acc: 0.8665 -- iter: 0320/1068
[A[ATraining Step: 487  | total loss: [1m[32m0.30679[0m[0m | time: 6.731s
[2K
| RMSProp | epoch: 015 | loss: 0.30679 - acc: 0.8767 -- iter: 0352/1068
[A[ATraining Step: 488  | total loss: [1m[32m0.29520[0m[0m | time: 7.327s
[2K
| RMSProp | epoch: 015 | loss: 0.29520 - acc: 0.8765 -- iter: 0384/1068
[A[ATraining Step: 489  | total loss: [1m[32m0.33696[0m[0m | time: 7.576s
[2K
| RMSProp | epoch: 015 | loss: 0.33696 - acc: 0.8576 -- iter: 0416/1068
[A[ATraining Step: 490  | total loss: [1m[32m0.37115[0m[0m | time: 7.818s
[2K
| RMSProp | epoch: 015 | loss: 0.37115 - acc: 0.8385 -- iter: 0448/1068
[A[ATraining Step: 491  | total loss: [1m[32m0.34911[0m[0m | time: 8.419s
[2K
| RMSProp | epoch: 015 | loss: 0.34911 - acc: 0.8547 -- iter: 0480/1068
[A[ATraining Step: 492  | total loss: [1m[32m0.34705[0m[0m | time: 9.025s
[2K
| RMSProp | epoch: 015 | loss: 0.34705 - acc: 0.8567 -- iter: 0512/1068
[A[ATraining Step: 493  | total loss: [1m[32m0.34435[0m[0m | time: 9.617s
[2K
| RMSProp | epoch: 015 | loss: 0.34435 - acc: 0.8554 -- iter: 0544/1068
[A[ATraining Step: 494  | total loss: [1m[32m0.33169[0m[0m | time: 10.215s
[2K
| RMSProp | epoch: 015 | loss: 0.33169 - acc: 0.8636 -- iter: 0576/1068
[A[ATraining Step: 495  | total loss: [1m[32m0.31223[0m[0m | time: 10.814s
[2K
| RMSProp | epoch: 015 | loss: 0.31223 - acc: 0.8710 -- iter: 0608/1068
[A[ATraining Step: 496  | total loss: [1m[32m0.29129[0m[0m | time: 11.402s
[2K
| RMSProp | epoch: 015 | loss: 0.29129 - acc: 0.8777 -- iter: 0640/1068
[A[ATraining Step: 497  | total loss: [1m[32m0.27014[0m[0m | time: 12.008s
[2K
| RMSProp | epoch: 015 | loss: 0.27014 - acc: 0.8899 -- iter: 0672/1068
[A[ATraining Step: 498  | total loss: [1m[32m0.26058[0m[0m | time: 12.621s
[2K
| RMSProp | epoch: 015 | loss: 0.26058 - acc: 0.8915 -- iter: 0704/1068
[A[ATraining Step: 499  | total loss: [1m[32m0.27121[0m[0m | time: 13.217s
[2K
| RMSProp | epoch: 015 | loss: 0.27121 - acc: 0.8868 -- iter: 0736/1068
[A[ATraining Step: 500  | total loss: [1m[32m0.28534[0m[0m | time: 13.822s
[2K
| RMSProp | epoch: 015 | loss: 0.28534 - acc: 0.8856 -- iter: 0768/1068
[A[ATraining Step: 501  | total loss: [1m[32m0.27044[0m[0m | time: 14.422s
[2K
| RMSProp | epoch: 015 | loss: 0.27044 - acc: 0.8939 -- iter: 0800/1068
[A[ATraining Step: 502  | total loss: [1m[32m0.26153[0m[0m | time: 15.036s
[2K
| RMSProp | epoch: 015 | loss: 0.26153 - acc: 0.8951 -- iter: 0832/1068
[A[ATraining Step: 503  | total loss: [1m[32m0.24735[0m[0m | time: 15.652s
[2K
| RMSProp | epoch: 015 | loss: 0.24735 - acc: 0.9056 -- iter: 0864/1068
[A[ATraining Step: 504  | total loss: [1m[32m0.25052[0m[0m | time: 16.254s
[2K
| RMSProp | epoch: 015 | loss: 0.25052 - acc: 0.8994 -- iter: 0896/1068
[A[ATraining Step: 505  | total loss: [1m[32m0.28442[0m[0m | time: 16.843s
[2K
| RMSProp | epoch: 015 | loss: 0.28442 - acc: 0.8751 -- iter: 0928/1068
[A[ATraining Step: 506  | total loss: [1m[32m0.27084[0m[0m | time: 17.437s
[2K
| RMSProp | epoch: 015 | loss: 0.27084 - acc: 0.8814 -- iter: 0960/1068
[A[ATraining Step: 507  | total loss: [1m[32m0.26844[0m[0m | time: 18.058s
[2K
| RMSProp | epoch: 015 | loss: 0.26844 - acc: 0.8838 -- iter: 0992/1068
[A[ATraining Step: 508  | total loss: [1m[32m0.27220[0m[0m | time: 18.668s
[2K
| RMSProp | epoch: 015 | loss: 0.27220 - acc: 0.8798 -- iter: 1024/1068
[A[ATraining Step: 509  | total loss: [1m[32m0.25796[0m[0m | time: 19.264s
[2K
| RMSProp | epoch: 015 | loss: 0.25796 - acc: 0.8887 -- iter: 1056/1068
[A[ATraining Step: 510  | total loss: [1m[32m0.24530[0m[0m | time: 20.910s
[2K
| RMSProp | epoch: 015 | loss: 0.24530 - acc: 0.8967 | val_loss: 0.50613 - val_acc: 0.7784 -- iter: 1068/1068
--
Training Step: 511  | total loss: [1m[32m0.25472[0m[0m | time: 0.616s
[2K
| RMSProp | epoch: 016 | loss: 0.25472 - acc: 0.8946 -- iter: 0032/1068
[A[ATraining Step: 512  | total loss: [1m[32m0.25132[0m[0m | time: 1.215s
[2K
| RMSProp | epoch: 016 | loss: 0.25132 - acc: 0.8988 -- iter: 0064/1068
[A[ATraining Step: 513  | total loss: [1m[32m0.23970[0m[0m | time: 1.805s
[2K
| RMSProp | epoch: 016 | loss: 0.23970 - acc: 0.9058 -- iter: 0096/1068
[A[ATraining Step: 514  | total loss: [1m[32m0.22960[0m[0m | time: 2.422s
[2K
| RMSProp | epoch: 016 | loss: 0.22960 - acc: 0.9090 -- iter: 0128/1068
[A[ATraining Step: 515  | total loss: [1m[32m0.21586[0m[0m | time: 3.024s
[2K
| RMSProp | epoch: 016 | loss: 0.21586 - acc: 0.9150 -- iter: 0160/1068
[A[ATraining Step: 516  | total loss: [1m[32m0.23707[0m[0m | time: 3.622s
[2K
| RMSProp | epoch: 016 | loss: 0.23707 - acc: 0.9079 -- iter: 0192/1068
[A[ATraining Step: 517  | total loss: [1m[32m0.24810[0m[0m | time: 4.227s
[2K
| RMSProp | epoch: 016 | loss: 0.24810 - acc: 0.9046 -- iter: 0224/1068
[A[ATraining Step: 518  | total loss: [1m[32m0.24646[0m[0m | time: 4.844s
[2K
| RMSProp | epoch: 016 | loss: 0.24646 - acc: 0.9047 -- iter: 0256/1068
[A[ATraining Step: 519  | total loss: [1m[32m0.23560[0m[0m | time: 5.445s
[2K
| RMSProp | epoch: 016 | loss: 0.23560 - acc: 0.9111 -- iter: 0288/1068
[A[ATraining Step: 520  | total loss: [1m[32m0.22985[0m[0m | time: 6.053s
[2K
| RMSProp | epoch: 016 | loss: 0.22985 - acc: 0.9138 -- iter: 0320/1068
[A[ATraining Step: 521  | total loss: [1m[32m0.22562[0m[0m | time: 6.654s
[2K
| RMSProp | epoch: 016 | loss: 0.22562 - acc: 0.9161 -- iter: 0352/1068
[A[ATraining Step: 522  | total loss: [1m[32m0.21778[0m[0m | time: 7.260s
[2K
| RMSProp | epoch: 016 | loss: 0.21778 - acc: 0.9152 -- iter: 0384/1068
[A[ATraining Step: 523  | total loss: [1m[32m0.24275[0m[0m | time: 7.870s
[2K
| RMSProp | epoch: 016 | loss: 0.24275 - acc: 0.9111 -- iter: 0416/1068
[A[ATraining Step: 524  | total loss: [1m[32m0.30286[0m[0m | time: 8.117s
[2K
| RMSProp | epoch: 016 | loss: 0.30286 - acc: 0.8888 -- iter: 0448/1068
[A[ATraining Step: 525  | total loss: [1m[32m0.31426[0m[0m | time: 8.362s
[2K
| RMSProp | epoch: 016 | loss: 0.31426 - acc: 0.8832 -- iter: 0480/1068
[A[ATraining Step: 526  | total loss: [1m[32m0.29427[0m[0m | time: 8.961s
[2K
| RMSProp | epoch: 016 | loss: 0.29427 - acc: 0.8949 -- iter: 0512/1068
[A[ATraining Step: 527  | total loss: [1m[32m0.29432[0m[0m | time: 9.563s
[2K
| RMSProp | epoch: 016 | loss: 0.29432 - acc: 0.8898 -- iter: 0544/1068
[A[ATraining Step: 528  | total loss: [1m[32m0.27016[0m[0m | time: 10.171s
[2K
| RMSProp | epoch: 016 | loss: 0.27016 - acc: 0.9008 -- iter: 0576/1068
[A[ATraining Step: 529  | total loss: [1m[32m0.25405[0m[0m | time: 10.762s
[2K
| RMSProp | epoch: 016 | loss: 0.25405 - acc: 0.9076 -- iter: 0608/1068
[A[ATraining Step: 530  | total loss: [1m[32m0.25159[0m[0m | time: 11.362s
[2K
| RMSProp | epoch: 016 | loss: 0.25159 - acc: 0.9075 -- iter: 0640/1068
[A[ATraining Step: 531  | total loss: [1m[32m0.24833[0m[0m | time: 11.975s
[2K
| RMSProp | epoch: 016 | loss: 0.24833 - acc: 0.9042 -- iter: 0672/1068
[A[ATraining Step: 532  | total loss: [1m[32m0.24637[0m[0m | time: 12.592s
[2K
| RMSProp | epoch: 016 | loss: 0.24637 - acc: 0.9076 -- iter: 0704/1068
[A[ATraining Step: 533  | total loss: [1m[32m0.23113[0m[0m | time: 13.196s
[2K
| RMSProp | epoch: 016 | loss: 0.23113 - acc: 0.9137 -- iter: 0736/1068
[A[ATraining Step: 534  | total loss: [1m[32m0.21461[0m[0m | time: 13.801s
[2K
| RMSProp | epoch: 016 | loss: 0.21461 - acc: 0.9223 -- iter: 0768/1068
[A[ATraining Step: 535  | total loss: [1m[32m0.20341[0m[0m | time: 14.428s
[2K
| RMSProp | epoch: 016 | loss: 0.20341 - acc: 0.9269 -- iter: 0800/1068
[A[ATraining Step: 536  | total loss: [1m[32m0.19111[0m[0m | time: 15.036s
[2K
| RMSProp | epoch: 016 | loss: 0.19111 - acc: 0.9311 -- iter: 0832/1068
[A[ATraining Step: 537  | total loss: [1m[32m0.18149[0m[0m | time: 15.652s
[2K
| RMSProp | epoch: 016 | loss: 0.18149 - acc: 0.9380 -- iter: 0864/1068
[A[ATraining Step: 538  | total loss: [1m[32m0.16621[0m[0m | time: 16.259s
[2K
| RMSProp | epoch: 016 | loss: 0.16621 - acc: 0.9442 -- iter: 0896/1068
[A[ATraining Step: 539  | total loss: [1m[32m0.15373[0m[0m | time: 16.894s
[2K
| RMSProp | epoch: 016 | loss: 0.15373 - acc: 0.9467 -- iter: 0928/1068
[A[ATraining Step: 540  | total loss: [1m[32m0.15277[0m[0m | time: 17.503s
[2K
| RMSProp | epoch: 016 | loss: 0.15277 - acc: 0.9426 -- iter: 0960/1068
[A[ATraining Step: 541  | total loss: [1m[32m0.21153[0m[0m | time: 18.123s
[2K
| RMSProp | epoch: 016 | loss: 0.21153 - acc: 0.9296 -- iter: 0992/1068
[A[ATraining Step: 542  | total loss: [1m[32m0.21684[0m[0m | time: 18.743s
[2K
| RMSProp | epoch: 016 | loss: 0.21684 - acc: 0.9242 -- iter: 1024/1068
[A[ATraining Step: 543  | total loss: [1m[32m0.23690[0m[0m | time: 19.347s
[2K
| RMSProp | epoch: 016 | loss: 0.23690 - acc: 0.9161 -- iter: 1056/1068
[A[ATraining Step: 544  | total loss: [1m[32m0.23005[0m[0m | time: 20.995s
[2K
| RMSProp | epoch: 016 | loss: 0.23005 - acc: 0.9214 | val_loss: 0.40296 - val_acc: 0.8323 -- iter: 1068/1068
--
Training Step: 545  | total loss: [1m[32m0.22043[0m[0m | time: 0.607s
[2K
| RMSProp | epoch: 017 | loss: 0.22043 - acc: 0.9261 -- iter: 0032/1068
[A[ATraining Step: 546  | total loss: [1m[32m0.20409[0m[0m | time: 1.220s
[2K
| RMSProp | epoch: 017 | loss: 0.20409 - acc: 0.9335 -- iter: 0064/1068
[A[ATraining Step: 547  | total loss: [1m[32m0.19347[0m[0m | time: 1.812s
[2K
| RMSProp | epoch: 017 | loss: 0.19347 - acc: 0.9370 -- iter: 0096/1068
[A[ATraining Step: 548  | total loss: [1m[32m0.18637[0m[0m | time: 2.429s
[2K
| RMSProp | epoch: 017 | loss: 0.18637 - acc: 0.9402 -- iter: 0128/1068
[A[ATraining Step: 549  | total loss: [1m[32m0.19525[0m[0m | time: 3.044s
[2K
| RMSProp | epoch: 017 | loss: 0.19525 - acc: 0.9399 -- iter: 0160/1068
[A[ATraining Step: 550  | total loss: [1m[32m0.19212[0m[0m | time: 3.652s
[2K
| RMSProp | epoch: 017 | loss: 0.19212 - acc: 0.9397 -- iter: 0192/1068
[A[ATraining Step: 551  | total loss: [1m[32m0.19027[0m[0m | time: 4.268s
[2K
| RMSProp | epoch: 017 | loss: 0.19027 - acc: 0.9363 -- iter: 0224/1068
[A[ATraining Step: 552  | total loss: [1m[32m0.20038[0m[0m | time: 4.868s
[2K
| RMSProp | epoch: 017 | loss: 0.20038 - acc: 0.9333 -- iter: 0256/1068
[A[ATraining Step: 553  | total loss: [1m[32m0.19527[0m[0m | time: 5.462s
[2K
| RMSProp | epoch: 017 | loss: 0.19527 - acc: 0.9338 -- iter: 0288/1068
[A[ATraining Step: 554  | total loss: [1m[32m0.18869[0m[0m | time: 6.062s
[2K
| RMSProp | epoch: 017 | loss: 0.18869 - acc: 0.9310 -- iter: 0320/1068
[A[ATraining Step: 555  | total loss: [1m[32m0.19892[0m[0m | time: 6.679s
[2K
| RMSProp | epoch: 017 | loss: 0.19892 - acc: 0.9285 -- iter: 0352/1068
[A[ATraining Step: 556  | total loss: [1m[32m0.20677[0m[0m | time: 7.320s
[2K
| RMSProp | epoch: 017 | loss: 0.20677 - acc: 0.9263 -- iter: 0384/1068
[A[ATraining Step: 557  | total loss: [1m[32m0.21118[0m[0m | time: 7.927s
[2K
| RMSProp | epoch: 017 | loss: 0.21118 - acc: 0.9212 -- iter: 0416/1068
[A[ATraining Step: 558  | total loss: [1m[32m0.22472[0m[0m | time: 8.528s
[2K
| RMSProp | epoch: 017 | loss: 0.22472 - acc: 0.9166 -- iter: 0448/1068
[A[ATraining Step: 559  | total loss: [1m[32m0.22407[0m[0m | time: 8.771s
[2K
| RMSProp | epoch: 017 | loss: 0.22407 - acc: 0.9186 -- iter: 0480/1068
[A[ATraining Step: 560  | total loss: [1m[32m0.22323[0m[0m | time: 9.025s
[2K
| RMSProp | epoch: 017 | loss: 0.22323 - acc: 0.9184 -- iter: 0512/1068
[A[ATraining Step: 561  | total loss: [1m[32m0.20561[0m[0m | time: 9.630s
[2K
| RMSProp | epoch: 017 | loss: 0.20561 - acc: 0.9266 -- iter: 0544/1068
[A[ATraining Step: 562  | total loss: [1m[32m0.19016[0m[0m | time: 10.234s
[2K
| RMSProp | epoch: 017 | loss: 0.19016 - acc: 0.9339 -- iter: 0576/1068
[A[ATraining Step: 563  | total loss: [1m[32m0.18657[0m[0m | time: 10.842s
[2K
| RMSProp | epoch: 017 | loss: 0.18657 - acc: 0.9343 -- iter: 0608/1068
[A[ATraining Step: 564  | total loss: [1m[32m0.17032[0m[0m | time: 11.440s
[2K
| RMSProp | epoch: 017 | loss: 0.17032 - acc: 0.9409 -- iter: 0640/1068
[A[ATraining Step: 565  | total loss: [1m[32m0.17316[0m[0m | time: 12.069s
[2K
| RMSProp | epoch: 017 | loss: 0.17316 - acc: 0.9405 -- iter: 0672/1068
[A[ATraining Step: 566  | total loss: [1m[32m0.16631[0m[0m | time: 12.676s
[2K
| RMSProp | epoch: 017 | loss: 0.16631 - acc: 0.9402 -- iter: 0704/1068
[A[ATraining Step: 567  | total loss: [1m[32m0.17918[0m[0m | time: 13.285s
[2K
| RMSProp | epoch: 017 | loss: 0.17918 - acc: 0.9306 -- iter: 0736/1068
[A[ATraining Step: 568  | total loss: [1m[32m0.17179[0m[0m | time: 13.902s
[2K
| RMSProp | epoch: 017 | loss: 0.17179 - acc: 0.9344 -- iter: 0768/1068
[A[ATraining Step: 569  | total loss: [1m[32m0.16902[0m[0m | time: 14.508s
[2K
| RMSProp | epoch: 017 | loss: 0.16902 - acc: 0.9347 -- iter: 0800/1068
[A[ATraining Step: 570  | total loss: [1m[32m0.15804[0m[0m | time: 15.108s
[2K
| RMSProp | epoch: 017 | loss: 0.15804 - acc: 0.9412 -- iter: 0832/1068
[A[ATraining Step: 571  | total loss: [1m[32m0.15579[0m[0m | time: 15.724s
[2K
| RMSProp | epoch: 017 | loss: 0.15579 - acc: 0.9409 -- iter: 0864/1068
[A[ATraining Step: 572  | total loss: [1m[32m0.15326[0m[0m | time: 16.337s
[2K
| RMSProp | epoch: 017 | loss: 0.15326 - acc: 0.9405 -- iter: 0896/1068
[A[ATraining Step: 573  | total loss: [1m[32m0.14292[0m[0m | time: 16.938s
[2K
| RMSProp | epoch: 017 | loss: 0.14292 - acc: 0.9465 -- iter: 0928/1068
[A[ATraining Step: 574  | total loss: [1m[32m0.13200[0m[0m | time: 17.578s
[2K
| RMSProp | epoch: 017 | loss: 0.13200 - acc: 0.9518 -- iter: 0960/1068
[A[ATraining Step: 575  | total loss: [1m[32m0.12512[0m[0m | time: 18.190s
[2K
| RMSProp | epoch: 017 | loss: 0.12512 - acc: 0.9535 -- iter: 0992/1068
[A[ATraining Step: 576  | total loss: [1m[32m0.13023[0m[0m | time: 18.801s
[2K
| RMSProp | epoch: 017 | loss: 0.13023 - acc: 0.9488 -- iter: 1024/1068
[A[ATraining Step: 577  | total loss: [1m[32m0.20543[0m[0m | time: 19.422s
[2K
| RMSProp | epoch: 017 | loss: 0.20543 - acc: 0.9227 -- iter: 1056/1068
[A[ATraining Step: 578  | total loss: [1m[32m0.20930[0m[0m | time: 21.087s
[2K
| RMSProp | epoch: 017 | loss: 0.20930 - acc: 0.9179 | val_loss: 0.47237 - val_acc: 0.8383 -- iter: 1068/1068
--
Training Step: 579  | total loss: [1m[32m0.20934[0m[0m | time: 0.609s
[2K
| RMSProp | epoch: 018 | loss: 0.20934 - acc: 0.9199 -- iter: 0032/1068
[A[ATraining Step: 580  | total loss: [1m[32m0.20531[0m[0m | time: 1.219s
[2K
| RMSProp | epoch: 018 | loss: 0.20531 - acc: 0.9216 -- iter: 0064/1068
[A[ATraining Step: 581  | total loss: [1m[32m0.18917[0m[0m | time: 1.840s
[2K
| RMSProp | epoch: 018 | loss: 0.18917 - acc: 0.9295 -- iter: 0096/1068
[A[ATraining Step: 582  | total loss: [1m[32m0.17321[0m[0m | time: 2.437s
[2K
| RMSProp | epoch: 018 | loss: 0.17321 - acc: 0.9365 -- iter: 0128/1068
[A[ATraining Step: 583  | total loss: [1m[32m0.16106[0m[0m | time: 3.049s
[2K
| RMSProp | epoch: 018 | loss: 0.16106 - acc: 0.9429 -- iter: 0160/1068
[A[ATraining Step: 584  | total loss: [1m[32m0.16841[0m[0m | time: 3.675s
[2K
| RMSProp | epoch: 018 | loss: 0.16841 - acc: 0.9361 -- iter: 0192/1068
[A[ATraining Step: 585  | total loss: [1m[32m0.17562[0m[0m | time: 4.289s
[2K
| RMSProp | epoch: 018 | loss: 0.17562 - acc: 0.9300 -- iter: 0224/1068
[A[ATraining Step: 586  | total loss: [1m[32m0.16586[0m[0m | time: 4.868s
[2K
| RMSProp | epoch: 018 | loss: 0.16586 - acc: 0.9338 -- iter: 0256/1068
[A[ATraining Step: 587  | total loss: [1m[32m0.15483[0m[0m | time: 5.470s
[2K
| RMSProp | epoch: 018 | loss: 0.15483 - acc: 0.9373 -- iter: 0288/1068
[A[ATraining Step: 588  | total loss: [1m[32m0.15192[0m[0m | time: 6.077s
[2K
| RMSProp | epoch: 018 | loss: 0.15192 - acc: 0.9374 -- iter: 0320/1068
[A[ATraining Step: 589  | total loss: [1m[32m0.14048[0m[0m | time: 6.681s
[2K
| RMSProp | epoch: 018 | loss: 0.14048 - acc: 0.9436 -- iter: 0352/1068
[A[ATraining Step: 590  | total loss: [1m[32m0.13010[0m[0m | time: 7.303s
[2K
| RMSProp | epoch: 018 | loss: 0.13010 - acc: 0.9493 -- iter: 0384/1068
[A[ATraining Step: 591  | total loss: [1m[32m0.12122[0m[0m | time: 7.921s
[2K
| RMSProp | epoch: 018 | loss: 0.12122 - acc: 0.9543 -- iter: 0416/1068
[A[ATraining Step: 592  | total loss: [1m[32m0.12247[0m[0m | time: 8.522s
[2K
| RMSProp | epoch: 018 | loss: 0.12247 - acc: 0.9558 -- iter: 0448/1068
[A[ATraining Step: 593  | total loss: [1m[32m0.16143[0m[0m | time: 9.132s
[2K
| RMSProp | epoch: 018 | loss: 0.16143 - acc: 0.9352 -- iter: 0480/1068
[A[ATraining Step: 594  | total loss: [1m[32m0.14822[0m[0m | time: 9.405s
[2K
| RMSProp | epoch: 018 | loss: 0.14822 - acc: 0.9417 -- iter: 0512/1068
[A[ATraining Step: 595  | total loss: [1m[32m0.13462[0m[0m | time: 9.657s
[2K
| RMSProp | epoch: 018 | loss: 0.13462 - acc: 0.9475 -- iter: 0544/1068
[A[ATraining Step: 596  | total loss: [1m[32m0.12170[0m[0m | time: 10.286s
[2K
| RMSProp | epoch: 018 | loss: 0.12170 - acc: 0.9528 -- iter: 0576/1068
[A[ATraining Step: 597  | total loss: [1m[32m0.11634[0m[0m | time: 10.899s
[2K
| RMSProp | epoch: 018 | loss: 0.11634 - acc: 0.9544 -- iter: 0608/1068
[A[ATraining Step: 598  | total loss: [1m[32m0.12858[0m[0m | time: 11.518s
[2K
| RMSProp | epoch: 018 | loss: 0.12858 - acc: 0.9527 -- iter: 0640/1068
[A[ATraining Step: 599  | total loss: [1m[32m0.12381[0m[0m | time: 12.123s
[2K
| RMSProp | epoch: 018 | loss: 0.12381 - acc: 0.9574 -- iter: 0672/1068
[A[ATraining Step: 600  | total loss: [1m[32m0.12211[0m[0m | time: 13.804s
[2K
| RMSProp | epoch: 018 | loss: 0.12211 - acc: 0.9585 | val_loss: 0.44100 - val_acc: 0.8443 -- iter: 0704/1068
--
Training Step: 601  | total loss: [1m[32m0.12380[0m[0m | time: 14.409s
[2K
| RMSProp | epoch: 018 | loss: 0.12380 - acc: 0.9596 -- iter: 0736/1068
[A[ATraining Step: 602  | total loss: [1m[32m0.13547[0m[0m | time: 15.023s
[2K
| RMSProp | epoch: 018 | loss: 0.13547 - acc: 0.9574 -- iter: 0768/1068
[A[ATraining Step: 603  | total loss: [1m[32m0.14137[0m[0m | time: 15.629s
[2K
| RMSProp | epoch: 018 | loss: 0.14137 - acc: 0.9585 -- iter: 0800/1068
[A[ATraining Step: 604  | total loss: [1m[32m0.13435[0m[0m | time: 16.274s
[2K
| RMSProp | epoch: 018 | loss: 0.13435 - acc: 0.9626 -- iter: 0832/1068
[A[ATraining Step: 605  | total loss: [1m[32m0.12270[0m[0m | time: 16.874s
[2K
| RMSProp | epoch: 018 | loss: 0.12270 - acc: 0.9664 -- iter: 0864/1068
[A[ATraining Step: 606  | total loss: [1m[32m0.11105[0m[0m | time: 17.474s
[2K
| RMSProp | epoch: 018 | loss: 0.11105 - acc: 0.9697 -- iter: 0896/1068
[A[ATraining Step: 607  | total loss: [1m[32m0.10169[0m[0m | time: 18.090s
[2K
| RMSProp | epoch: 018 | loss: 0.10169 - acc: 0.9728 -- iter: 0928/1068
[A[ATraining Step: 608  | total loss: [1m[32m0.09915[0m[0m | time: 18.721s
[2K
| RMSProp | epoch: 018 | loss: 0.09915 - acc: 0.9724 -- iter: 0960/1068
[A[ATraining Step: 609  | total loss: [1m[32m0.12142[0m[0m | time: 19.340s
[2K
| RMSProp | epoch: 018 | loss: 0.12142 - acc: 0.9658 -- iter: 0992/1068
[A[ATraining Step: 610  | total loss: [1m[32m0.11918[0m[0m | time: 19.941s
[2K
| RMSProp | epoch: 018 | loss: 0.11918 - acc: 0.9661 -- iter: 1024/1068
[A[ATraining Step: 611  | total loss: [1m[32m0.11298[0m[0m | time: 20.545s
[2K
| RMSProp | epoch: 018 | loss: 0.11298 - acc: 0.9663 -- iter: 1056/1068
[A[ATraining Step: 612  | total loss: [1m[32m0.10787[0m[0m | time: 22.203s
[2K
| RMSProp | epoch: 018 | loss: 0.10787 - acc: 0.9666 | val_loss: 0.53133 - val_acc: 0.8234 -- iter: 1068/1068
--
Training Step: 613  | total loss: [1m[32m0.10005[0m[0m | time: 0.616s
[2K
| RMSProp | epoch: 019 | loss: 0.10005 - acc: 0.9699 -- iter: 0032/1068
[A[ATraining Step: 614  | total loss: [1m[32m0.10233[0m[0m | time: 1.225s
[2K
| RMSProp | epoch: 019 | loss: 0.10233 - acc: 0.9698 -- iter: 0064/1068
[A[ATraining Step: 615  | total loss: [1m[32m0.09594[0m[0m | time: 1.843s
[2K
| RMSProp | epoch: 019 | loss: 0.09594 - acc: 0.9728 -- iter: 0096/1068
[A[ATraining Step: 616  | total loss: [1m[32m0.08841[0m[0m | time: 2.455s
[2K
| RMSProp | epoch: 019 | loss: 0.08841 - acc: 0.9755 -- iter: 0128/1068
[A[ATraining Step: 617  | total loss: [1m[32m0.08081[0m[0m | time: 3.055s
[2K
| RMSProp | epoch: 019 | loss: 0.08081 - acc: 0.9780 -- iter: 0160/1068
[A[ATraining Step: 618  | total loss: [1m[32m0.07478[0m[0m | time: 3.662s
[2K
| RMSProp | epoch: 019 | loss: 0.07478 - acc: 0.9802 -- iter: 0192/1068
[A[ATraining Step: 619  | total loss: [1m[32m0.08042[0m[0m | time: 4.274s
[2K
| RMSProp | epoch: 019 | loss: 0.08042 - acc: 0.9697 -- iter: 0224/1068
[A[ATraining Step: 620  | total loss: [1m[32m0.11318[0m[0m | time: 4.877s
[2K
| RMSProp | epoch: 019 | loss: 0.11318 - acc: 0.9508 -- iter: 0256/1068
[A[ATraining Step: 621  | total loss: [1m[32m0.11646[0m[0m | time: 5.491s
[2K
| RMSProp | epoch: 019 | loss: 0.11646 - acc: 0.9526 -- iter: 0288/1068
[A[ATraining Step: 622  | total loss: [1m[32m0.11498[0m[0m | time: 6.108s
[2K
| RMSProp | epoch: 019 | loss: 0.11498 - acc: 0.9542 -- iter: 0320/1068
[A[ATraining Step: 623  | total loss: [1m[32m0.10528[0m[0m | time: 6.710s
[2K
| RMSProp | epoch: 019 | loss: 0.10528 - acc: 0.9588 -- iter: 0352/1068
[A[ATraining Step: 624  | total loss: [1m[32m0.10370[0m[0m | time: 7.342s
[2K
| RMSProp | epoch: 019 | loss: 0.10370 - acc: 0.9598 -- iter: 0384/1068
[A[ATraining Step: 625  | total loss: [1m[32m0.10497[0m[0m | time: 7.946s
[2K
| RMSProp | epoch: 019 | loss: 0.10497 - acc: 0.9607 -- iter: 0416/1068
[A[ATraining Step: 626  | total loss: [1m[32m0.10674[0m[0m | time: 8.551s
[2K
| RMSProp | epoch: 019 | loss: 0.10674 - acc: 0.9615 -- iter: 0448/1068
[A[ATraining Step: 627  | total loss: [1m[32m0.14301[0m[0m | time: 9.212s
[2K
| RMSProp | epoch: 019 | loss: 0.14301 - acc: 0.9591 -- iter: 0480/1068
[A[ATraining Step: 628  | total loss: [1m[32m0.13398[0m[0m | time: 9.833s
[2K
| RMSProp | epoch: 019 | loss: 0.13398 - acc: 0.9632 -- iter: 0512/1068
[A[ATraining Step: 629  | total loss: [1m[32m0.12583[0m[0m | time: 10.087s
[2K
| RMSProp | epoch: 019 | loss: 0.12583 - acc: 0.9637 -- iter: 0544/1068
[A[ATraining Step: 630  | total loss: [1m[32m0.12464[0m[0m | time: 10.331s
[2K
| RMSProp | epoch: 019 | loss: 0.12464 - acc: 0.9590 -- iter: 0576/1068
[A[ATraining Step: 631  | total loss: [1m[32m0.11606[0m[0m | time: 10.955s
[2K
| RMSProp | epoch: 019 | loss: 0.11606 - acc: 0.9631 -- iter: 0608/1068
[A[ATraining Step: 632  | total loss: [1m[32m0.11535[0m[0m | time: 11.558s
[2K
| RMSProp | epoch: 019 | loss: 0.11535 - acc: 0.9606 -- iter: 0640/1068
[A[ATraining Step: 633  | total loss: [1m[32m0.10669[0m[0m | time: 12.155s
[2K
| RMSProp | epoch: 019 | loss: 0.10669 - acc: 0.9645 -- iter: 0672/1068
[A[ATraining Step: 634  | total loss: [1m[32m0.11763[0m[0m | time: 12.788s
[2K
| RMSProp | epoch: 019 | loss: 0.11763 - acc: 0.9618 -- iter: 0704/1068
[A[ATraining Step: 635  | total loss: [1m[32m0.14652[0m[0m | time: 13.416s
[2K
| RMSProp | epoch: 019 | loss: 0.14652 - acc: 0.9469 -- iter: 0736/1068
[A[ATraining Step: 636  | total loss: [1m[32m0.15524[0m[0m | time: 14.028s
[2K
| RMSProp | epoch: 019 | loss: 0.15524 - acc: 0.9397 -- iter: 0768/1068
[A[ATraining Step: 637  | total loss: [1m[32m0.15572[0m[0m | time: 14.654s
[2K
| RMSProp | epoch: 019 | loss: 0.15572 - acc: 0.9426 -- iter: 0800/1068
[A[ATraining Step: 638  | total loss: [1m[32m0.15464[0m[0m | time: 15.274s
[2K
| RMSProp | epoch: 019 | loss: 0.15464 - acc: 0.9390 -- iter: 0832/1068
[A[ATraining Step: 639  | total loss: [1m[32m0.16279[0m[0m | time: 15.875s
[2K
| RMSProp | epoch: 019 | loss: 0.16279 - acc: 0.9388 -- iter: 0864/1068
[A[ATraining Step: 640  | total loss: [1m[32m0.16389[0m[0m | time: 16.493s
[2K
| RMSProp | epoch: 019 | loss: 0.16389 - acc: 0.9356 -- iter: 0896/1068
[A[ATraining Step: 641  | total loss: [1m[32m0.15912[0m[0m | time: 17.098s
[2K
| RMSProp | epoch: 019 | loss: 0.15912 - acc: 0.9326 -- iter: 0928/1068
[A[ATraining Step: 642  | total loss: [1m[32m0.14682[0m[0m | time: 17.703s
[2K
| RMSProp | epoch: 019 | loss: 0.14682 - acc: 0.9394 -- iter: 0960/1068
[A[ATraining Step: 643  | total loss: [1m[32m0.13581[0m[0m | time: 18.311s
[2K
| RMSProp | epoch: 019 | loss: 0.13581 - acc: 0.9423 -- iter: 0992/1068
[A[ATraining Step: 644  | total loss: [1m[32m0.12303[0m[0m | time: 18.920s
[2K
| RMSProp | epoch: 019 | loss: 0.12303 - acc: 0.9481 -- iter: 1024/1068
[A[ATraining Step: 645  | total loss: [1m[32m0.12379[0m[0m | time: 19.564s
[2K
| RMSProp | epoch: 019 | loss: 0.12379 - acc: 0.9439 -- iter: 1056/1068
[A[ATraining Step: 646  | total loss: [1m[32m0.12970[0m[0m | time: 21.342s
[2K
| RMSProp | epoch: 019 | loss: 0.12970 - acc: 0.9464 | val_loss: 0.59007 - val_acc: 0.8204 -- iter: 1068/1068
--
Training Step: 647  | total loss: [1m[32m0.11927[0m[0m | time: 0.644s
[2K
| RMSProp | epoch: 020 | loss: 0.11927 - acc: 0.9517 -- iter: 0032/1068
[A[ATraining Step: 648  | total loss: [1m[32m0.11805[0m[0m | time: 1.270s
[2K
| RMSProp | epoch: 020 | loss: 0.11805 - acc: 0.9503 -- iter: 0064/1068
[A[ATraining Step: 649  | total loss: [1m[32m0.13528[0m[0m | time: 1.895s
[2K
| RMSProp | epoch: 020 | loss: 0.13528 - acc: 0.9397 -- iter: 0096/1068
[A[ATraining Step: 650  | total loss: [1m[32m0.13399[0m[0m | time: 2.508s
[2K
| RMSProp | epoch: 020 | loss: 0.13399 - acc: 0.9426 -- iter: 0128/1068
[A[ATraining Step: 651  | total loss: [1m[32m0.12727[0m[0m | time: 3.134s
[2K
| RMSProp | epoch: 020 | loss: 0.12727 - acc: 0.9452 -- iter: 0160/1068
[A[ATraining Step: 652  | total loss: [1m[32m0.11581[0m[0m | time: 3.763s
[2K
| RMSProp | epoch: 020 | loss: 0.11581 - acc: 0.9507 -- iter: 0192/1068
[A[ATraining Step: 653  | total loss: [1m[32m0.10863[0m[0m | time: 4.370s
[2K
| RMSProp | epoch: 020 | loss: 0.10863 - acc: 0.9556 -- iter: 0224/1068
[A[ATraining Step: 654  | total loss: [1m[32m0.09933[0m[0m | time: 4.982s
[2K
| RMSProp | epoch: 020 | loss: 0.09933 - acc: 0.9600 -- iter: 0256/1068
[A[ATraining Step: 655  | total loss: [1m[32m0.08995[0m[0m | time: 5.599s
[2K
| RMSProp | epoch: 020 | loss: 0.08995 - acc: 0.9640 -- iter: 0288/1068
[A[ATraining Step: 656  | total loss: [1m[32m0.08224[0m[0m | time: 6.210s
[2K
| RMSProp | epoch: 020 | loss: 0.08224 - acc: 0.9676 -- iter: 0320/1068
[A[ATraining Step: 657  | total loss: [1m[32m0.07591[0m[0m | time: 6.822s
[2K
| RMSProp | epoch: 020 | loss: 0.07591 - acc: 0.9709 -- iter: 0352/1068
[A[ATraining Step: 658  | total loss: [1m[32m0.06912[0m[0m | time: 7.453s
[2K
| RMSProp | epoch: 020 | loss: 0.06912 - acc: 0.9738 -- iter: 0384/1068
[A[ATraining Step: 659  | total loss: [1m[32m0.06685[0m[0m | time: 8.062s
[2K
| RMSProp | epoch: 020 | loss: 0.06685 - acc: 0.9733 -- iter: 0416/1068
[A[ATraining Step: 660  | total loss: [1m[32m0.10787[0m[0m | time: 8.667s
[2K
| RMSProp | epoch: 020 | loss: 0.10787 - acc: 0.9603 -- iter: 0448/1068
[A[ATraining Step: 661  | total loss: [1m[32m0.10168[0m[0m | time: 9.274s
[2K
| RMSProp | epoch: 020 | loss: 0.10168 - acc: 0.9643 -- iter: 0480/1068
[A[ATraining Step: 662  | total loss: [1m[32m0.10115[0m[0m | time: 9.873s
[2K
| RMSProp | epoch: 020 | loss: 0.10115 - acc: 0.9647 -- iter: 0512/1068
[A[ATraining Step: 663  | total loss: [1m[32m0.09192[0m[0m | time: 10.467s
[2K
| RMSProp | epoch: 020 | loss: 0.09192 - acc: 0.9683 -- iter: 0544/1068
[A[ATraining Step: 664  | total loss: [1m[32m0.08378[0m[0m | time: 10.728s
[2K
| RMSProp | epoch: 020 | loss: 0.08378 - acc: 0.9714 -- iter: 0576/1068
[A[ATraining Step: 665  | total loss: [1m[32m0.07710[0m[0m | time: 10.972s
[2K
| RMSProp | epoch: 020 | loss: 0.07710 - acc: 0.9743 -- iter: 0608/1068
[A[ATraining Step: 666  | total loss: [1m[32m0.06988[0m[0m | time: 11.587s
[2K
| RMSProp | epoch: 020 | loss: 0.06988 - acc: 0.9769 -- iter: 0640/1068
[A[ATraining Step: 667  | total loss: [1m[32m0.06310[0m[0m | time: 12.214s
[2K
| RMSProp | epoch: 020 | loss: 0.06310 - acc: 0.9792 -- iter: 0672/1068
[A[ATraining Step: 668  | total loss: [1m[32m0.10804[0m[0m | time: 12.816s
[2K
| RMSProp | epoch: 020 | loss: 0.10804 - acc: 0.9719 -- iter: 0704/1068
[A[ATraining Step: 669  | total loss: [1m[32m0.10359[0m[0m | time: 13.424s
[2K
| RMSProp | epoch: 020 | loss: 0.10359 - acc: 0.9747 -- iter: 0736/1068
[A[ATraining Step: 670  | total loss: [1m[32m0.09462[0m[0m | time: 14.053s
[2K
| RMSProp | epoch: 020 | loss: 0.09462 - acc: 0.9772 -- iter: 0768/1068
[A[ATraining Step: 671  | total loss: [1m[32m0.08764[0m[0m | time: 14.670s
[2K
| RMSProp | epoch: 020 | loss: 0.08764 - acc: 0.9795 -- iter: 0800/1068
[A[ATraining Step: 672  | total loss: [1m[32m0.08004[0m[0m | time: 15.267s
[2K
| RMSProp | epoch: 020 | loss: 0.08004 - acc: 0.9816 -- iter: 0832/1068
[A[ATraining Step: 673  | total loss: [1m[32m0.07799[0m[0m | time: 15.884s
[2K
| RMSProp | epoch: 020 | loss: 0.07799 - acc: 0.9803 -- iter: 0864/1068
[A[ATraining Step: 674  | total loss: [1m[32m0.08372[0m[0m | time: 16.491s
[2K
| RMSProp | epoch: 020 | loss: 0.08372 - acc: 0.9791 -- iter: 0896/1068
[A[ATraining Step: 675  | total loss: [1m[32m0.11398[0m[0m | time: 17.094s
[2K
| RMSProp | epoch: 020 | loss: 0.11398 - acc: 0.9718 -- iter: 0928/1068
[A[ATraining Step: 676  | total loss: [1m[32m0.10604[0m[0m | time: 17.697s
[2K
| RMSProp | epoch: 020 | loss: 0.10604 - acc: 0.9747 -- iter: 0960/1068
[A[ATraining Step: 677  | total loss: [1m[32m0.09595[0m[0m | time: 18.324s
[2K
| RMSProp | epoch: 020 | loss: 0.09595 - acc: 0.9772 -- iter: 0992/1068
[A[ATraining Step: 678  | total loss: [1m[32m0.09486[0m[0m | time: 18.927s
[2K
| RMSProp | epoch: 020 | loss: 0.09486 - acc: 0.9763 -- iter: 1024/1068
[A[ATraining Step: 679  | total loss: [1m[32m0.09869[0m[0m | time: 19.531s
[2K
| RMSProp | epoch: 020 | loss: 0.09869 - acc: 0.9756 -- iter: 1056/1068
[A[ATraining Step: 680  | total loss: [1m[32m0.09098[0m[0m | time: 21.180s
[2K
| RMSProp | epoch: 020 | loss: 0.09098 - acc: 0.9780 | val_loss: 0.56492 - val_acc: 0.8263 -- iter: 1068/1068
--
Training Step: 681  | total loss: [1m[32m0.08860[0m[0m | time: 0.610s
[2K
| RMSProp | epoch: 021 | loss: 0.08860 - acc: 0.9771 -- iter: 0032/1068
[A[ATraining Step: 682  | total loss: [1m[32m0.10453[0m[0m | time: 1.234s
[2K
| RMSProp | epoch: 021 | loss: 0.10453 - acc: 0.9763 -- iter: 0064/1068
[A[ATraining Step: 683  | total loss: [1m[32m0.09624[0m[0m | time: 1.834s
[2K
| RMSProp | epoch: 021 | loss: 0.09624 - acc: 0.9786 -- iter: 0096/1068
[A[ATraining Step: 684  | total loss: [1m[32m0.08758[0m[0m | time: 2.432s
[2K
| RMSProp | epoch: 021 | loss: 0.08758 - acc: 0.9808 -- iter: 0128/1068
[A[ATraining Step: 685  | total loss: [1m[32m0.08386[0m[0m | time: 3.026s
[2K
| RMSProp | epoch: 021 | loss: 0.08386 - acc: 0.9827 -- iter: 0160/1068
[A[ATraining Step: 686  | total loss: [1m[32m0.10888[0m[0m | time: 3.623s
[2K
| RMSProp | epoch: 021 | loss: 0.10888 - acc: 0.9719 -- iter: 0192/1068
[A[ATraining Step: 687  | total loss: [1m[32m0.10780[0m[0m | time: 4.250s
[2K
| RMSProp | epoch: 021 | loss: 0.10780 - acc: 0.9716 -- iter: 0224/1068
[A[ATraining Step: 688  | total loss: [1m[32m0.10949[0m[0m | time: 4.853s
[2K
| RMSProp | epoch: 021 | loss: 0.10949 - acc: 0.9713 -- iter: 0256/1068
[A[ATraining Step: 689  | total loss: [1m[32m0.10433[0m[0m | time: 5.461s
[2K
| RMSProp | epoch: 021 | loss: 0.10433 - acc: 0.9711 -- iter: 0288/1068
[A[ATraining Step: 690  | total loss: [1m[32m0.09489[0m[0m | time: 6.083s
[2K
| RMSProp | epoch: 021 | loss: 0.09489 - acc: 0.9740 -- iter: 0320/1068
[A[ATraining Step: 691  | total loss: [1m[32m0.09426[0m[0m | time: 6.705s
[2K
| RMSProp | epoch: 021 | loss: 0.09426 - acc: 0.9734 -- iter: 0352/1068
[A[ATraining Step: 692  | total loss: [1m[32m0.08788[0m[0m | time: 7.311s
[2K
| RMSProp | epoch: 021 | loss: 0.08788 - acc: 0.9761 -- iter: 0384/1068
[A[ATraining Step: 693  | total loss: [1m[32m0.10133[0m[0m | time: 7.913s
[2K
| RMSProp | epoch: 021 | loss: 0.10133 - acc: 0.9722 -- iter: 0416/1068
[A[ATraining Step: 694  | total loss: [1m[32m0.09712[0m[0m | time: 8.511s
[2K
| RMSProp | epoch: 021 | loss: 0.09712 - acc: 0.9750 -- iter: 0448/1068
[A[ATraining Step: 695  | total loss: [1m[32m0.10216[0m[0m | time: 9.118s
[2K
| RMSProp | epoch: 021 | loss: 0.10216 - acc: 0.9713 -- iter: 0480/1068
[A[ATraining Step: 696  | total loss: [1m[32m0.09719[0m[0m | time: 9.719s
[2K
| RMSProp | epoch: 021 | loss: 0.09719 - acc: 0.9710 -- iter: 0512/1068
[A[ATraining Step: 697  | total loss: [1m[32m0.08977[0m[0m | time: 10.343s
[2K
| RMSProp | epoch: 021 | loss: 0.08977 - acc: 0.9739 -- iter: 0544/1068
[A[ATraining Step: 698  | total loss: [1m[32m0.09028[0m[0m | time: 10.953s
[2K
| RMSProp | epoch: 021 | loss: 0.09028 - acc: 0.9734 -- iter: 0576/1068
[A[ATraining Step: 699  | total loss: [1m[32m0.08473[0m[0m | time: 11.197s
[2K
| RMSProp | epoch: 021 | loss: 0.08473 - acc: 0.9761 -- iter: 0608/1068
[A[ATraining Step: 700  | total loss: [1m[32m0.07725[0m[0m | time: 11.445s
[2K
| RMSProp | epoch: 021 | loss: 0.07725 - acc: 0.9784 -- iter: 0640/1068
[A[ATraining Step: 701  | total loss: [1m[32m0.06974[0m[0m | time: 12.080s
[2K
| RMSProp | epoch: 021 | loss: 0.06974 - acc: 0.9806 -- iter: 0672/1068
[A[ATraining Step: 702  | total loss: [1m[32m0.06338[0m[0m | time: 12.681s
[2K
| RMSProp | epoch: 021 | loss: 0.06338 - acc: 0.9825 -- iter: 0704/1068
[A[ATraining Step: 703  | total loss: [1m[32m0.10385[0m[0m | time: 13.279s
[2K
| RMSProp | epoch: 021 | loss: 0.10385 - acc: 0.9687 -- iter: 0736/1068
[A[ATraining Step: 704  | total loss: [1m[32m0.11791[0m[0m | time: 13.881s
[2K
| RMSProp | epoch: 021 | loss: 0.11791 - acc: 0.9655 -- iter: 0768/1068
[A[ATraining Step: 705  | total loss: [1m[32m0.12443[0m[0m | time: 14.476s
[2K
| RMSProp | epoch: 021 | loss: 0.12443 - acc: 0.9627 -- iter: 0800/1068
[A[ATraining Step: 706  | total loss: [1m[32m0.11438[0m[0m | time: 15.075s
[2K
| RMSProp | epoch: 021 | loss: 0.11438 - acc: 0.9665 -- iter: 0832/1068
[A[ATraining Step: 707  | total loss: [1m[32m0.11480[0m[0m | time: 15.673s
[2K
| RMSProp | epoch: 021 | loss: 0.11480 - acc: 0.9667 -- iter: 0864/1068
[A[ATraining Step: 708  | total loss: [1m[32m0.10690[0m[0m | time: 16.264s
[2K
| RMSProp | epoch: 021 | loss: 0.10690 - acc: 0.9700 -- iter: 0896/1068
[A[ATraining Step: 709  | total loss: [1m[32m0.11335[0m[0m | time: 16.872s
[2K
| RMSProp | epoch: 021 | loss: 0.11335 - acc: 0.9699 -- iter: 0928/1068
[A[ATraining Step: 710  | total loss: [1m[32m0.10465[0m[0m | time: 17.517s
[2K
| RMSProp | epoch: 021 | loss: 0.10465 - acc: 0.9729 -- iter: 0960/1068
[A[ATraining Step: 711  | total loss: [1m[32m0.10412[0m[0m | time: 18.151s
[2K
| RMSProp | epoch: 021 | loss: 0.10412 - acc: 0.9725 -- iter: 0992/1068
[A[ATraining Step: 712  | total loss: [1m[32m0.09687[0m[0m | time: 18.765s
[2K
| RMSProp | epoch: 021 | loss: 0.09687 - acc: 0.9752 -- iter: 1024/1068
[A[ATraining Step: 713  | total loss: [1m[32m0.08875[0m[0m | time: 19.377s
[2K
| RMSProp | epoch: 021 | loss: 0.08875 - acc: 0.9777 -- iter: 1056/1068
[A[ATraining Step: 714  | total loss: [1m[32m0.08053[0m[0m | time: 21.043s
[2K
| RMSProp | epoch: 021 | loss: 0.08053 - acc: 0.9799 | val_loss: 0.55977 - val_acc: 0.8204 -- iter: 1068/1068
--
Training Step: 715  | total loss: [1m[32m0.07315[0m[0m | time: 0.634s
[2K
| RMSProp | epoch: 022 | loss: 0.07315 - acc: 0.9820 -- iter: 0032/1068
[A[ATraining Step: 716  | total loss: [1m[32m0.06719[0m[0m | time: 1.237s
[2K
| RMSProp | epoch: 022 | loss: 0.06719 - acc: 0.9838 -- iter: 0064/1068
[A[ATraining Step: 717  | total loss: [1m[32m0.06157[0m[0m | time: 1.852s
[2K
| RMSProp | epoch: 022 | loss: 0.06157 - acc: 0.9854 -- iter: 0096/1068
[A[ATraining Step: 718  | total loss: [1m[32m0.05562[0m[0m | time: 2.463s
[2K
| RMSProp | epoch: 022 | loss: 0.05562 - acc: 0.9868 -- iter: 0128/1068
[A[ATraining Step: 719  | total loss: [1m[32m0.05046[0m[0m | time: 3.058s
[2K
| RMSProp | epoch: 022 | loss: 0.05046 - acc: 0.9882 -- iter: 0160/1068
[A[ATraining Step: 720  | total loss: [1m[32m0.04583[0m[0m | time: 3.672s
[2K
| RMSProp | epoch: 022 | loss: 0.04583 - acc: 0.9893 -- iter: 0192/1068
[A[ATraining Step: 721  | total loss: [1m[32m0.04139[0m[0m | time: 4.291s
[2K
| RMSProp | epoch: 022 | loss: 0.04139 - acc: 0.9904 -- iter: 0224/1068
[A[ATraining Step: 722  | total loss: [1m[32m0.05596[0m[0m | time: 4.901s
[2K
| RMSProp | epoch: 022 | loss: 0.05596 - acc: 0.9882 -- iter: 0256/1068
[A[ATraining Step: 723  | total loss: [1m[32m0.05435[0m[0m | time: 5.506s
[2K
| RMSProp | epoch: 022 | loss: 0.05435 - acc: 0.9863 -- iter: 0288/1068
[A[ATraining Step: 724  | total loss: [1m[32m0.07135[0m[0m | time: 6.119s
[2K
| RMSProp | epoch: 022 | loss: 0.07135 - acc: 0.9814 -- iter: 0320/1068
[A[ATraining Step: 725  | total loss: [1m[32m0.10419[0m[0m | time: 6.753s
[2K
| RMSProp | epoch: 022 | loss: 0.10419 - acc: 0.9645 -- iter: 0352/1068
[A[ATraining Step: 726  | total loss: [1m[32m0.11610[0m[0m | time: 7.366s
[2K
| RMSProp | epoch: 022 | loss: 0.11610 - acc: 0.9587 -- iter: 0384/1068
[A[ATraining Step: 727  | total loss: [1m[32m0.10549[0m[0m | time: 7.975s
[2K
| RMSProp | epoch: 022 | loss: 0.10549 - acc: 0.9628 -- iter: 0416/1068
[A[ATraining Step: 728  | total loss: [1m[32m0.10026[0m[0m | time: 8.599s
[2K
| RMSProp | epoch: 022 | loss: 0.10026 - acc: 0.9634 -- iter: 0448/1068
[A[ATraining Step: 729  | total loss: [1m[32m0.09071[0m[0m | time: 9.216s
[2K
| RMSProp | epoch: 022 | loss: 0.09071 - acc: 0.9671 -- iter: 0480/1068
[A[ATraining Step: 730  | total loss: [1m[32m0.08473[0m[0m | time: 9.824s
[2K
| RMSProp | epoch: 022 | loss: 0.08473 - acc: 0.9704 -- iter: 0512/1068
[A[ATraining Step: 731  | total loss: [1m[32m0.09045[0m[0m | time: 10.437s
[2K
| RMSProp | epoch: 022 | loss: 0.09045 - acc: 0.9702 -- iter: 0544/1068
[A[ATraining Step: 732  | total loss: [1m[32m0.08375[0m[0m | time: 11.053s
[2K
| RMSProp | epoch: 022 | loss: 0.08375 - acc: 0.9732 -- iter: 0576/1068
[A[ATraining Step: 733  | total loss: [1m[32m0.07679[0m[0m | time: 11.674s
[2K
| RMSProp | epoch: 022 | loss: 0.07679 - acc: 0.9759 -- iter: 0608/1068
[A[ATraining Step: 734  | total loss: [1m[32m0.06988[0m[0m | time: 11.941s
[2K
| RMSProp | epoch: 022 | loss: 0.06988 - acc: 0.9783 -- iter: 0640/1068
[A[ATraining Step: 735  | total loss: [1m[32m0.06533[0m[0m | time: 12.201s
[2K
| RMSProp | epoch: 022 | loss: 0.06533 - acc: 0.9805 -- iter: 0672/1068
[A[ATraining Step: 736  | total loss: [1m[32m0.06093[0m[0m | time: 12.809s
[2K
| RMSProp | epoch: 022 | loss: 0.06093 - acc: 0.9824 -- iter: 0704/1068
[A[ATraining Step: 737  | total loss: [1m[32m0.05515[0m[0m | time: 13.417s
[2K
| RMSProp | epoch: 022 | loss: 0.05515 - acc: 0.9842 -- iter: 0736/1068
[A[ATraining Step: 738  | total loss: [1m[32m0.07334[0m[0m | time: 14.020s
[2K
| RMSProp | epoch: 022 | loss: 0.07334 - acc: 0.9826 -- iter: 0768/1068
[A[ATraining Step: 739  | total loss: [1m[32m0.06726[0m[0m | time: 14.635s
[2K
| RMSProp | epoch: 022 | loss: 0.06726 - acc: 0.9844 -- iter: 0800/1068
[A[ATraining Step: 740  | total loss: [1m[32m0.06940[0m[0m | time: 15.249s
[2K
| RMSProp | epoch: 022 | loss: 0.06940 - acc: 0.9828 -- iter: 0832/1068
[A[ATraining Step: 741  | total loss: [1m[32m0.06946[0m[0m | time: 15.880s
[2K
| RMSProp | epoch: 022 | loss: 0.06946 - acc: 0.9814 -- iter: 0864/1068
[A[ATraining Step: 742  | total loss: [1m[32m0.06838[0m[0m | time: 16.491s
[2K
| RMSProp | epoch: 022 | loss: 0.06838 - acc: 0.9801 -- iter: 0896/1068
[A[ATraining Step: 743  | total loss: [1m[32m0.08150[0m[0m | time: 17.114s
[2K
| RMSProp | epoch: 022 | loss: 0.08150 - acc: 0.9759 -- iter: 0928/1068
[A[ATraining Step: 744  | total loss: [1m[32m0.09724[0m[0m | time: 17.736s
[2K
| RMSProp | epoch: 022 | loss: 0.09724 - acc: 0.9720 -- iter: 0960/1068
[A[ATraining Step: 745  | total loss: [1m[32m0.09507[0m[0m | time: 18.343s
[2K
| RMSProp | epoch: 022 | loss: 0.09507 - acc: 0.9717 -- iter: 0992/1068
[A[ATraining Step: 746  | total loss: [1m[32m0.09480[0m[0m | time: 18.947s
[2K
| RMSProp | epoch: 022 | loss: 0.09480 - acc: 0.9714 -- iter: 1024/1068
[A[ATraining Step: 747  | total loss: [1m[32m0.09996[0m[0m | time: 19.576s
[2K
| RMSProp | epoch: 022 | loss: 0.09996 - acc: 0.9680 -- iter: 1056/1068
[A[ATraining Step: 748  | total loss: [1m[32m0.11848[0m[0m | time: 21.240s
[2K
| RMSProp | epoch: 022 | loss: 0.11848 - acc: 0.9618 | val_loss: 0.60894 - val_acc: 0.8174 -- iter: 1068/1068
--
Training Step: 749  | total loss: [1m[32m0.11111[0m[0m | time: 0.615s
[2K
| RMSProp | epoch: 023 | loss: 0.11111 - acc: 0.9657 -- iter: 0032/1068
[A[ATraining Step: 750  | total loss: [1m[32m0.10067[0m[0m | time: 1.210s
[2K
| RMSProp | epoch: 023 | loss: 0.10067 - acc: 0.9691 -- iter: 0064/1068
[A[ATraining Step: 751  | total loss: [1m[32m0.09297[0m[0m | time: 1.813s
[2K
| RMSProp | epoch: 023 | loss: 0.09297 - acc: 0.9722 -- iter: 0096/1068
[A[ATraining Step: 752  | total loss: [1m[32m0.09115[0m[0m | time: 2.423s
[2K
| RMSProp | epoch: 023 | loss: 0.09115 - acc: 0.9718 -- iter: 0128/1068
[A[ATraining Step: 753  | total loss: [1m[32m0.08311[0m[0m | time: 3.025s
[2K
| RMSProp | epoch: 023 | loss: 0.08311 - acc: 0.9747 -- iter: 0160/1068
[A[ATraining Step: 754  | total loss: [1m[32m0.07532[0m[0m | time: 3.626s
[2K
| RMSProp | epoch: 023 | loss: 0.07532 - acc: 0.9772 -- iter: 0192/1068
[A[ATraining Step: 755  | total loss: [1m[32m0.06837[0m[0m | time: 4.232s
[2K
| RMSProp | epoch: 023 | loss: 0.06837 - acc: 0.9795 -- iter: 0224/1068
[A[ATraining Step: 756  | total loss: [1m[32m0.06213[0m[0m | time: 4.842s
[2K
| RMSProp | epoch: 023 | loss: 0.06213 - acc: 0.9815 -- iter: 0256/1068
[A[ATraining Step: 757  | total loss: [1m[32m0.05643[0m[0m | time: 5.443s
[2K
| RMSProp | epoch: 023 | loss: 0.05643 - acc: 0.9834 -- iter: 0288/1068
[A[ATraining Step: 758  | total loss: [1m[32m0.05105[0m[0m | time: 6.081s
[2K
| RMSProp | epoch: 023 | loss: 0.05105 - acc: 0.9850 -- iter: 0320/1068
[A[ATraining Step: 759  | total loss: [1m[32m0.04653[0m[0m | time: 6.680s
[2K
| RMSProp | epoch: 023 | loss: 0.04653 - acc: 0.9865 -- iter: 0352/1068
[A[ATraining Step: 760  | total loss: [1m[32m0.04219[0m[0m | time: 7.306s
[2K
| RMSProp | epoch: 023 | loss: 0.04219 - acc: 0.9879 -- iter: 0384/1068
[A[ATraining Step: 761  | total loss: [1m[32m0.03816[0m[0m | time: 7.903s
[2K
| RMSProp | epoch: 023 | loss: 0.03816 - acc: 0.9891 -- iter: 0416/1068
[A[ATraining Step: 762  | total loss: [1m[32m0.03449[0m[0m | time: 8.532s
[2K
| RMSProp | epoch: 023 | loss: 0.03449 - acc: 0.9902 -- iter: 0448/1068
[A[ATraining Step: 763  | total loss: [1m[32m0.03516[0m[0m | time: 9.131s
[2K
| RMSProp | epoch: 023 | loss: 0.03516 - acc: 0.9880 -- iter: 0480/1068
[A[ATraining Step: 764  | total loss: [1m[32m0.15321[0m[0m | time: 9.725s
[2K
| RMSProp | epoch: 023 | loss: 0.15321 - acc: 0.9642 -- iter: 0512/1068
[A[ATraining Step: 765  | total loss: [1m[32m0.15254[0m[0m | time: 10.321s
[2K
| RMSProp | epoch: 023 | loss: 0.15254 - acc: 0.9647 -- iter: 0544/1068
[A[ATraining Step: 766  | total loss: [1m[32m0.14373[0m[0m | time: 10.928s
[2K
| RMSProp | epoch: 023 | loss: 0.14373 - acc: 0.9651 -- iter: 0576/1068
[A[ATraining Step: 767  | total loss: [1m[32m0.16403[0m[0m | time: 11.531s
[2K
| RMSProp | epoch: 023 | loss: 0.16403 - acc: 0.9561 -- iter: 0608/1068
[A[ATraining Step: 768  | total loss: [1m[32m0.19515[0m[0m | time: 12.169s
[2K
| RMSProp | epoch: 023 | loss: 0.19515 - acc: 0.9448 -- iter: 0640/1068
[A[ATraining Step: 769  | total loss: [1m[32m0.17968[0m[0m | time: 12.409s
[2K
| RMSProp | epoch: 023 | loss: 0.17968 - acc: 0.9472 -- iter: 0672/1068
[A[ATraining Step: 770  | total loss: [1m[32m0.16507[0m[0m | time: 12.653s
[2K
| RMSProp | epoch: 023 | loss: 0.16507 - acc: 0.9525 -- iter: 0704/1068
[A[ATraining Step: 771  | total loss: [1m[32m0.14908[0m[0m | time: 13.250s
[2K
| RMSProp | epoch: 023 | loss: 0.14908 - acc: 0.9573 -- iter: 0736/1068
[A[ATraining Step: 772  | total loss: [1m[32m0.13972[0m[0m | time: 13.858s
[2K
| RMSProp | epoch: 023 | loss: 0.13972 - acc: 0.9584 -- iter: 0768/1068
[A[ATraining Step: 773  | total loss: [1m[32m0.18119[0m[0m | time: 14.467s
[2K
| RMSProp | epoch: 023 | loss: 0.18119 - acc: 0.9563 -- iter: 0800/1068
[A[ATraining Step: 774  | total loss: [1m[32m0.16716[0m[0m | time: 15.074s
[2K
| RMSProp | epoch: 023 | loss: 0.16716 - acc: 0.9607 -- iter: 0832/1068
[A[ATraining Step: 775  | total loss: [1m[32m0.15262[0m[0m | time: 15.698s
[2K
| RMSProp | epoch: 023 | loss: 0.15262 - acc: 0.9646 -- iter: 0864/1068
[A[ATraining Step: 776  | total loss: [1m[32m0.14098[0m[0m | time: 16.313s
[2K
| RMSProp | epoch: 023 | loss: 0.14098 - acc: 0.9650 -- iter: 0896/1068
[A[ATraining Step: 777  | total loss: [1m[32m0.12845[0m[0m | time: 16.929s
[2K
| RMSProp | epoch: 023 | loss: 0.12845 - acc: 0.9685 -- iter: 0928/1068
[A[ATraining Step: 778  | total loss: [1m[32m0.11989[0m[0m | time: 17.556s
[2K
| RMSProp | epoch: 023 | loss: 0.11989 - acc: 0.9686 -- iter: 0960/1068
[A[ATraining Step: 779  | total loss: [1m[32m0.12075[0m[0m | time: 18.187s
[2K
| RMSProp | epoch: 023 | loss: 0.12075 - acc: 0.9654 -- iter: 0992/1068
[A[ATraining Step: 780  | total loss: [1m[32m0.12107[0m[0m | time: 18.802s
[2K
| RMSProp | epoch: 023 | loss: 0.12107 - acc: 0.9627 -- iter: 1024/1068
[A[ATraining Step: 781  | total loss: [1m[32m0.11155[0m[0m | time: 19.398s
[2K
| RMSProp | epoch: 023 | loss: 0.11155 - acc: 0.9664 -- iter: 1056/1068
[A[ATraining Step: 782  | total loss: [1m[32m0.10910[0m[0m | time: 21.082s
[2K
| RMSProp | epoch: 023 | loss: 0.10910 - acc: 0.9666 | val_loss: 0.61035 - val_acc: 0.8293 -- iter: 1068/1068
--
Training Step: 783  | total loss: [1m[32m0.09989[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 024 | loss: 0.09989 - acc: 0.9700 -- iter: 0032/1068
[A[ATraining Step: 784  | total loss: [1m[32m0.09054[0m[0m | time: 1.232s
[2K
| RMSProp | epoch: 024 | loss: 0.09054 - acc: 0.9730 -- iter: 0064/1068
[A[ATraining Step: 785  | total loss: [1m[32m0.08357[0m[0m | time: 1.832s
[2K
| RMSProp | epoch: 024 | loss: 0.08357 - acc: 0.9757 -- iter: 0096/1068
[A[ATraining Step: 786  | total loss: [1m[32m0.07556[0m[0m | time: 2.436s
[2K
| RMSProp | epoch: 024 | loss: 0.07556 - acc: 0.9781 -- iter: 0128/1068
[A[ATraining Step: 787  | total loss: [1m[32m0.07573[0m[0m | time: 3.046s
[2K
| RMSProp | epoch: 024 | loss: 0.07573 - acc: 0.9772 -- iter: 0160/1068
[A[ATraining Step: 788  | total loss: [1m[32m0.08834[0m[0m | time: 3.668s
[2K
| RMSProp | epoch: 024 | loss: 0.08834 - acc: 0.9763 -- iter: 0192/1068
[A[ATraining Step: 789  | total loss: [1m[32m0.09289[0m[0m | time: 4.294s
[2K
| RMSProp | epoch: 024 | loss: 0.09289 - acc: 0.9756 -- iter: 0224/1068
[A[ATraining Step: 790  | total loss: [1m[32m0.08770[0m[0m | time: 4.896s
[2K
| RMSProp | epoch: 024 | loss: 0.08770 - acc: 0.9780 -- iter: 0256/1068
[A[ATraining Step: 791  | total loss: [1m[32m0.08482[0m[0m | time: 5.512s
[2K
| RMSProp | epoch: 024 | loss: 0.08482 - acc: 0.9771 -- iter: 0288/1068
[A[ATraining Step: 792  | total loss: [1m[32m0.09290[0m[0m | time: 6.143s
[2K
| RMSProp | epoch: 024 | loss: 0.09290 - acc: 0.9763 -- iter: 0320/1068
[A[ATraining Step: 793  | total loss: [1m[32m0.08445[0m[0m | time: 6.764s
[2K
| RMSProp | epoch: 024 | loss: 0.08445 - acc: 0.9786 -- iter: 0352/1068
[A[ATraining Step: 794  | total loss: [1m[32m0.07686[0m[0m | time: 7.365s
[2K
| RMSProp | epoch: 024 | loss: 0.07686 - acc: 0.9808 -- iter: 0384/1068
[A[ATraining Step: 795  | total loss: [1m[32m0.06970[0m[0m | time: 7.986s
[2K
| RMSProp | epoch: 024 | loss: 0.06970 - acc: 0.9827 -- iter: 0416/1068
[A[ATraining Step: 796  | total loss: [1m[32m0.06826[0m[0m | time: 8.598s
[2K
| RMSProp | epoch: 024 | loss: 0.06826 - acc: 0.9813 -- iter: 0448/1068
[A[ATraining Step: 797  | total loss: [1m[32m0.08703[0m[0m | time: 9.189s
[2K
| RMSProp | epoch: 024 | loss: 0.08703 - acc: 0.9769 -- iter: 0480/1068
[A[ATraining Step: 798  | total loss: [1m[32m0.08148[0m[0m | time: 9.795s
[2K
| RMSProp | epoch: 024 | loss: 0.08148 - acc: 0.9792 -- iter: 0512/1068
[A[ATraining Step: 799  | total loss: [1m[32m0.07514[0m[0m | time: 10.440s
[2K
| RMSProp | epoch: 024 | loss: 0.07514 - acc: 0.9813 -- iter: 0544/1068
[A[ATraining Step: 800  | total loss: [1m[32m0.06806[0m[0m | time: 12.133s
[2K
| RMSProp | epoch: 024 | loss: 0.06806 - acc: 0.9832 | val_loss: 0.65116 - val_acc: 0.8084 -- iter: 0576/1068
--
Training Step: 801  | total loss: [1m[32m0.06729[0m[0m | time: 12.742s
[2K
| RMSProp | epoch: 024 | loss: 0.06729 - acc: 0.9817 -- iter: 0608/1068
[A[ATraining Step: 802  | total loss: [1m[32m0.07593[0m[0m | time: 13.365s
[2K
| RMSProp | epoch: 024 | loss: 0.07593 - acc: 0.9804 -- iter: 0640/1068
[A[ATraining Step: 803  | total loss: [1m[32m0.06929[0m[0m | time: 14.013s
[2K
| RMSProp | epoch: 024 | loss: 0.06929 - acc: 0.9824 -- iter: 0672/1068
[A[ATraining Step: 804  | total loss: [1m[32m0.06369[0m[0m | time: 14.265s
[2K
| RMSProp | epoch: 024 | loss: 0.06369 - acc: 0.9841 -- iter: 0704/1068
[A[ATraining Step: 805  | total loss: [1m[32m0.05799[0m[0m | time: 14.519s
[2K
| RMSProp | epoch: 024 | loss: 0.05799 - acc: 0.9857 -- iter: 0736/1068
[A[ATraining Step: 806  | total loss: [1m[32m0.05249[0m[0m | time: 15.149s
[2K
| RMSProp | epoch: 024 | loss: 0.05249 - acc: 0.9872 -- iter: 0768/1068
[A[ATraining Step: 807  | total loss: [1m[32m0.05662[0m[0m | time: 15.749s
[2K
| RMSProp | epoch: 024 | loss: 0.05662 - acc: 0.9853 -- iter: 0800/1068
[A[ATraining Step: 808  | total loss: [1m[32m0.05174[0m[0m | time: 16.348s
[2K
| RMSProp | epoch: 024 | loss: 0.05174 - acc: 0.9868 -- iter: 0832/1068
[A[ATraining Step: 809  | total loss: [1m[32m0.05285[0m[0m | time: 16.958s
[2K
| RMSProp | epoch: 024 | loss: 0.05285 - acc: 0.9850 -- iter: 0864/1068
[A[ATraining Step: 810  | total loss: [1m[32m0.04986[0m[0m | time: 17.571s
[2K
| RMSProp | epoch: 024 | loss: 0.04986 - acc: 0.9865 -- iter: 0896/1068
[A[ATraining Step: 811  | total loss: [1m[32m0.04574[0m[0m | time: 18.170s
[2K
| RMSProp | epoch: 024 | loss: 0.04574 - acc: 0.9878 -- iter: 0928/1068
[A[ATraining Step: 812  | total loss: [1m[32m0.04176[0m[0m | time: 18.783s
[2K
| RMSProp | epoch: 024 | loss: 0.04176 - acc: 0.9891 -- iter: 0960/1068
[A[ATraining Step: 813  | total loss: [1m[32m0.04798[0m[0m | time: 19.403s
[2K
| RMSProp | epoch: 024 | loss: 0.04798 - acc: 0.9839 -- iter: 0992/1068
[A[ATraining Step: 814  | total loss: [1m[32m0.08574[0m[0m | time: 20.045s
[2K
| RMSProp | epoch: 024 | loss: 0.08574 - acc: 0.9730 -- iter: 1024/1068
[A[ATraining Step: 815  | total loss: [1m[32m0.08123[0m[0m | time: 20.678s
[2K
| RMSProp | epoch: 024 | loss: 0.08123 - acc: 0.9757 -- iter: 1056/1068
[A[ATraining Step: 816  | total loss: [1m[32m0.07375[0m[0m | time: 22.361s
[2K
| RMSProp | epoch: 024 | loss: 0.07375 - acc: 0.9781 | val_loss: 0.61498 - val_acc: 0.8293 -- iter: 1068/1068
--
Training Step: 817  | total loss: [1m[32m0.06685[0m[0m | time: 0.621s
[2K
| RMSProp | epoch: 025 | loss: 0.06685 - acc: 0.9803 -- iter: 0032/1068
[A[ATraining Step: 818  | total loss: [1m[32m0.06055[0m[0m | time: 1.235s
[2K
| RMSProp | epoch: 025 | loss: 0.06055 - acc: 0.9823 -- iter: 0064/1068
[A[ATraining Step: 819  | total loss: [1m[32m0.05585[0m[0m | time: 1.849s
[2K
| RMSProp | epoch: 025 | loss: 0.05585 - acc: 0.9841 -- iter: 0096/1068
[A[ATraining Step: 820  | total loss: [1m[32m0.05109[0m[0m | time: 2.455s
[2K
| RMSProp | epoch: 025 | loss: 0.05109 - acc: 0.9857 -- iter: 0128/1068
[A[ATraining Step: 821  | total loss: [1m[32m0.06236[0m[0m | time: 3.059s
[2K
| RMSProp | epoch: 025 | loss: 0.06236 - acc: 0.9840 -- iter: 0160/1068
[A[ATraining Step: 822  | total loss: [1m[32m0.05790[0m[0m | time: 3.669s
[2K
| RMSProp | epoch: 025 | loss: 0.05790 - acc: 0.9856 -- iter: 0192/1068
[A[ATraining Step: 823  | total loss: [1m[32m0.07734[0m[0m | time: 4.264s
[2K
| RMSProp | epoch: 025 | loss: 0.07734 - acc: 0.9808 -- iter: 0224/1068
[A[ATraining Step: 824  | total loss: [1m[32m0.07209[0m[0m | time: 4.877s
[2K
| RMSProp | epoch: 025 | loss: 0.07209 - acc: 0.9827 -- iter: 0256/1068
[A[ATraining Step: 825  | total loss: [1m[32m0.06568[0m[0m | time: 5.474s
[2K
| RMSProp | epoch: 025 | loss: 0.06568 - acc: 0.9844 -- iter: 0288/1068
[A[ATraining Step: 826  | total loss: [1m[32m0.05965[0m[0m | time: 6.079s
[2K
| RMSProp | epoch: 025 | loss: 0.05965 - acc: 0.9860 -- iter: 0320/1068
[A[ATraining Step: 827  | total loss: [1m[32m0.05486[0m[0m | time: 6.694s
[2K
| RMSProp | epoch: 025 | loss: 0.05486 - acc: 0.9874 -- iter: 0352/1068
[A[ATraining Step: 828  | total loss: [1m[32m0.04965[0m[0m | time: 7.299s
[2K
| RMSProp | epoch: 025 | loss: 0.04965 - acc: 0.9886 -- iter: 0384/1068
[A[ATraining Step: 829  | total loss: [1m[32m0.04493[0m[0m | time: 7.924s
[2K
| RMSProp | epoch: 025 | loss: 0.04493 - acc: 0.9898 -- iter: 0416/1068
[A[ATraining Step: 830  | total loss: [1m[32m0.04078[0m[0m | time: 8.514s
[2K
| RMSProp | epoch: 025 | loss: 0.04078 - acc: 0.9908 -- iter: 0448/1068
[A[ATraining Step: 831  | total loss: [1m[32m0.03731[0m[0m | time: 9.102s
[2K
| RMSProp | epoch: 025 | loss: 0.03731 - acc: 0.9917 -- iter: 0480/1068
[A[ATraining Step: 832  | total loss: [1m[32m0.03370[0m[0m | time: 9.698s
[2K
| RMSProp | epoch: 025 | loss: 0.03370 - acc: 0.9925 -- iter: 0512/1068
[A[ATraining Step: 833  | total loss: [1m[32m0.03281[0m[0m | time: 10.297s
[2K
| RMSProp | epoch: 025 | loss: 0.03281 - acc: 0.9902 -- iter: 0544/1068
[A[ATraining Step: 834  | total loss: [1m[32m0.05329[0m[0m | time: 10.905s
[2K
| RMSProp | epoch: 025 | loss: 0.05329 - acc: 0.9849 -- iter: 0576/1068
[A[ATraining Step: 835  | total loss: [1m[32m0.14269[0m[0m | time: 11.497s
[2K
| RMSProp | epoch: 025 | loss: 0.14269 - acc: 0.9645 -- iter: 0608/1068
[A[ATraining Step: 836  | total loss: [1m[32m0.15551[0m[0m | time: 12.184s
[2K
| RMSProp | epoch: 025 | loss: 0.15551 - acc: 0.9587 -- iter: 0640/1068
[A[ATraining Step: 837  | total loss: [1m[32m0.14424[0m[0m | time: 13.276s
[2K
| RMSProp | epoch: 025 | loss: 0.14424 - acc: 0.9628 -- iter: 0672/1068
[A[ATraining Step: 838  | total loss: [1m[32m0.13332[0m[0m | time: 14.154s
[2K
| RMSProp | epoch: 025 | loss: 0.13332 - acc: 0.9634 -- iter: 0704/1068
[A[ATraining Step: 839  | total loss: [1m[32m0.13544[0m[0m | time: 17.272s
[2K
| RMSProp | epoch: 025 | loss: 0.13544 - acc: 0.9640 -- iter: 0736/1068
[A[ATraining Step: 840  | total loss: [1m[32m0.12413[0m[0m | time: 24.639s
[2K
| RMSProp | epoch: 025 | loss: 0.12413 - acc: 0.9676 -- iter: 0768/1068
[A[ATraining Step: 841  | total loss: [1m[32m0.11210[0m[0m | time: 29.081s
[2K
| RMSProp | epoch: 025 | loss: 0.11210 - acc: 0.9708 -- iter: 0800/1068
[A[ATraining Step: 842  | total loss: [1m[32m0.10202[0m[0m | time: 33.890s
[2K
| RMSProp | epoch: 025 | loss: 0.10202 - acc: 0.9737 -- iter: 0832/1068
[A[ATraining Step: 843  | total loss: [1m[32m0.12973[0m[0m | time: 43.350s
[2K
| RMSProp | epoch: 025 | loss: 0.12973 - acc: 0.9701 -- iter: 0864/1068
[A[ATraining Step: 844  | total loss: [1m[32m0.12118[0m[0m | time: 54.812s
[2K
| RMSProp | epoch: 025 | loss: 0.12118 - acc: 0.9731 -- iter: 0896/1068
[A[ATraining Step: 845  | total loss: [1m[32m0.11019[0m[0m | time: 73.176s
[2K
| RMSProp | epoch: 025 | loss: 0.11019 - acc: 0.9758 -- iter: 0928/1068
[A[ATraining Step: 846  | total loss: [1m[32m0.09990[0m[0m | time: 77.872s
[2K
| RMSProp | epoch: 025 | loss: 0.09990 - acc: 0.9782 -- iter: 0960/1068
[A[ATraining Step: 847  | total loss: [1m[32m0.09035[0m[0m | time: 90.833s
[2K
| RMSProp | epoch: 025 | loss: 0.09035 - acc: 0.9804 -- iter: 0992/1068
[A[ATraining Step: 848  | total loss: [1m[32m0.08639[0m[0m | time: 102.928s
[2K
| RMSProp | epoch: 025 | loss: 0.08639 - acc: 0.9792 -- iter: 1024/1068
[A[ATraining Step: 849  | total loss: [1m[32m0.08863[0m[0m | time: 111.073s
[2K
| RMSProp | epoch: 025 | loss: 0.08863 - acc: 0.9782 -- iter: 1056/1068
[A[ATraining Step: 850  | total loss: [1m[32m0.08450[0m[0m | time: 139.907s
[2K
| RMSProp | epoch: 025 | loss: 0.08450 - acc: 0.9772 | val_loss: 0.70383 - val_acc: 0.7605 -- iter: 1068/1068
--
Training Step: 851  | total loss: [1m[32m0.07709[0m[0m | time: 0.993s
[2K
| RMSProp | epoch: 026 | loss: 0.07709 - acc: 0.9795 -- iter: 0032/1068
[A[ATraining Step: 852  | total loss: [1m[32m0.07102[0m[0m | time: 1.974s
[2K
| RMSProp | epoch: 026 | loss: 0.07102 - acc: 0.9816 -- iter: 0064/1068
[A[ATraining Step: 853  | total loss: [1m[32m0.06578[0m[0m | time: 2.913s
[2K
| RMSProp | epoch: 026 | loss: 0.06578 - acc: 0.9834 -- iter: 0096/1068
[A[ATraining Step: 854  | total loss: [1m[32m0.09611[0m[0m | time: 4.082s
[2K
| RMSProp | epoch: 026 | loss: 0.09611 - acc: 0.9726 -- iter: 0128/1068
[A[ATraining Step: 855  | total loss: [1m[32m0.10159[0m[0m | time: 5.136s
[2K
| RMSProp | epoch: 026 | loss: 0.10159 - acc: 0.9659 -- iter: 0160/1068
[A[ATraining Step: 856  | total loss: [1m[32m0.11431[0m[0m | time: 5.946s
[2K
| RMSProp | epoch: 026 | loss: 0.11431 - acc: 0.9568 -- iter: 0192/1068
[A[ATraining Step: 857  | total loss: [1m[32m0.10608[0m[0m | time: 6.562s
[2K
| RMSProp | epoch: 026 | loss: 0.10608 - acc: 0.9612 -- iter: 0224/1068
[A[ATraining Step: 858  | total loss: [1m[32m0.09716[0m[0m | time: 7.430s
[2K
| RMSProp | epoch: 026 | loss: 0.09716 - acc: 0.9650 -- iter: 0256/1068
[A[ATraining Step: 859  | total loss: [1m[32m0.08940[0m[0m | time: 8.482s
[2K
| RMSProp | epoch: 026 | loss: 0.08940 - acc: 0.9685 -- iter: 0288/1068
[A[ATraining Step: 860  | total loss: [1m[32m0.08961[0m[0m | time: 10.040s
[2K
| RMSProp | epoch: 026 | loss: 0.08961 - acc: 0.9686 -- iter: 0320/1068
[A[ATraining Step: 861  | total loss: [1m[32m0.08556[0m[0m | time: 13.831s
[2K
| RMSProp | epoch: 026 | loss: 0.08556 - acc: 0.9686 -- iter: 0352/1068
[A[ATraining Step: 862  | total loss: [1m[32m0.07798[0m[0m | time: 17.872s
[2K
| RMSProp | epoch: 026 | loss: 0.07798 - acc: 0.9717 -- iter: 0384/1068
[A[ATraining Step: 863  | total loss: [1m[32m0.07043[0m[0m | time: 25.998s
[2K
| RMSProp | epoch: 026 | loss: 0.07043 - acc: 0.9745 -- iter: 0416/1068
[A[ATraining Step: 864  | total loss: [1m[32m0.07260[0m[0m | time: 34.393s
[2K
| RMSProp | epoch: 026 | loss: 0.07260 - acc: 0.9740 -- iter: 0448/1068
[A[ATraining Step: 865  | total loss: [1m[32m0.06756[0m[0m | time: 44.415s
[2K
| RMSProp | epoch: 026 | loss: 0.06756 - acc: 0.9766 -- iter: 0480/1068
[A[ATraining Step: 866  | total loss: [1m[32m0.06122[0m[0m | time: 54.101s
[2K
| RMSProp | epoch: 026 | loss: 0.06122 - acc: 0.9789 -- iter: 0512/1068
[A[ATraining Step: 867  | total loss: [1m[32m0.05606[0m[0m | time: 59.325s
[2K
| RMSProp | epoch: 026 | loss: 0.05606 - acc: 0.9810 -- iter: 0544/1068
[A[ATraining Step: 868  | total loss: [1m[32m0.06167[0m[0m | time: 64.305s
[2K
| RMSProp | epoch: 026 | loss: 0.06167 - acc: 0.9798 -- iter: 0576/1068
[A[ATraining Step: 869  | total loss: [1m[32m0.05698[0m[0m | time: 71.765s
[2K
| RMSProp | epoch: 026 | loss: 0.05698 - acc: 0.9818 -- iter: 0608/1068
[A[ATraining Step: 870  | total loss: [1m[32m0.05348[0m[0m | time: 76.144s
[2K
| RMSProp | epoch: 026 | loss: 0.05348 - acc: 0.9836 -- iter: 0640/1068
[A[ATraining Step: 871  | total loss: [1m[32m0.05497[0m[0m | time: 85.771s
[2K
| RMSProp | epoch: 026 | loss: 0.05497 - acc: 0.9821 -- iter: 0672/1068
[A[ATraining Step: 872  | total loss: [1m[32m0.11178[0m[0m | time: 91.477s
[2K
| RMSProp | epoch: 026 | loss: 0.11178 - acc: 0.9652 -- iter: 0704/1068
[A[ATraining Step: 873  | total loss: [1m[32m0.10553[0m[0m | time: 103.646s
[2K
| RMSProp | epoch: 026 | loss: 0.10553 - acc: 0.9655 -- iter: 0736/1068
[A[ATraining Step: 874  | total loss: [1m[32m0.09595[0m[0m | time: 110.441s
[2K
| RMSProp | epoch: 026 | loss: 0.09595 - acc: 0.9690 -- iter: 0768/1068
[A[ATraining Step: 875  | total loss: [1m[32m0.08663[0m[0m | time: 114.951s
[2K
| RMSProp | epoch: 026 | loss: 0.08663 - acc: 0.9721 -- iter: 0800/1068
[A[ATraining Step: 876  | total loss: [1m[32m0.07817[0m[0m | time: 120.789s
[2K
| RMSProp | epoch: 026 | loss: 0.07817 - acc: 0.9749 -- iter: 0832/1068
[A[ATraining Step: 877  | total loss: [1m[32m0.07077[0m[0m | time: 127.164s
[2K
| RMSProp | epoch: 026 | loss: 0.07077 - acc: 0.9774 -- iter: 0864/1068
[A[ATraining Step: 878  | total loss: [1m[32m0.14662[0m[0m | time: 130.489s
[2K
| RMSProp | epoch: 026 | loss: 0.14662 - acc: 0.9703 -- iter: 0896/1068
[A[ATraining Step: 879  | total loss: [1m[32m0.13740[0m[0m | time: 141.200s
[2K
| RMSProp | epoch: 026 | loss: 0.13740 - acc: 0.9732 -- iter: 0928/1068
[A[ATraining Step: 880  | total loss: [1m[32m0.12675[0m[0m | time: 143.984s
[2K
| RMSProp | epoch: 026 | loss: 0.12675 - acc: 0.9759 -- iter: 0960/1068
[A[ATraining Step: 881  | total loss: [1m[32m0.11535[0m[0m | time: 144.943s
[2K
| RMSProp | epoch: 026 | loss: 0.11535 - acc: 0.9783 -- iter: 0992/1068
[A[ATraining Step: 882  | total loss: [1m[32m0.10670[0m[0m | time: 145.950s
[2K
| RMSProp | epoch: 026 | loss: 0.10670 - acc: 0.9805 -- iter: 1024/1068
[A[ATraining Step: 883  | total loss: [1m[32m0.09703[0m[0m | time: 147.105s
[2K
| RMSProp | epoch: 026 | loss: 0.09703 - acc: 0.9824 -- iter: 1056/1068
[A[ATraining Step: 884  | total loss: [1m[32m0.08807[0m[0m | time: 150.291s
[2K
| RMSProp | epoch: 026 | loss: 0.08807 - acc: 0.9842 | val_loss: 0.66016 - val_acc: 0.8054 -- iter: 1068/1068
--
Training Step: 885  | total loss: [1m[32m0.08057[0m[0m | time: 0.998s
[2K
| RMSProp | epoch: 027 | loss: 0.08057 - acc: 0.9858 -- iter: 0032/1068
[A[ATraining Step: 886  | total loss: [1m[32m0.09033[0m[0m | time: 7.987s
[2K
| RMSProp | epoch: 027 | loss: 0.09033 - acc: 0.9810 -- iter: 0064/1068
[A[ATraining Step: 887  | total loss: [1m[32m0.08273[0m[0m | time: 13.765s
[2K
| RMSProp | epoch: 027 | loss: 0.08273 - acc: 0.9829 -- iter: 0096/1068
[A[ATraining Step: 888  | total loss: [1m[32m0.07527[0m[0m | time: 19.672s
[2K
| RMSProp | epoch: 027 | loss: 0.07527 - acc: 0.9846 -- iter: 0128/1068
[A[ATraining Step: 889  | total loss: [1m[32m0.06822[0m[0m | time: 32.447s
[2K
| RMSProp | epoch: 027 | loss: 0.06822 - acc: 0.9861 -- iter: 0160/1068
[A[ATraining Step: 890  | total loss: [1m[32m0.07383[0m[0m | time: 36.417s
[2K
| RMSProp | epoch: 027 | loss: 0.07383 - acc: 0.9844 -- iter: 0192/1068
[A[ATraining Step: 891  | total loss: [1m[32m0.06739[0m[0m | time: 48.877s
[2K
| RMSProp | epoch: 027 | loss: 0.06739 - acc: 0.9859 -- iter: 0224/1068
[A[ATraining Step: 892  | total loss: [1m[32m0.06128[0m[0m | time: 53.701s
[2K
| RMSProp | epoch: 027 | loss: 0.06128 - acc: 0.9873 -- iter: 0256/1068
[A[ATraining Step: 893  | total loss: [1m[32m0.05584[0m[0m | time: 65.105s
[2K
| RMSProp | epoch: 027 | loss: 0.05584 - acc: 0.9886 -- iter: 0288/1068
[A[ATraining Step: 894  | total loss: [1m[32m0.05068[0m[0m | time: 69.240s
[2K
| RMSProp | epoch: 027 | loss: 0.05068 - acc: 0.9898 -- iter: 0320/1068
[A[ATraining Step: 895  | total loss: [1m[32m0.04579[0m[0m | time: 79.428s
[2K
| RMSProp | epoch: 027 | loss: 0.04579 - acc: 0.9908 -- iter: 0352/1068
[A[ATraining Step: 896  | total loss: [1m[32m0.04138[0m[0m | time: 88.512s
[2K
| RMSProp | epoch: 027 | loss: 0.04138 - acc: 0.9917 -- iter: 0384/1068
[A[ATraining Step: 897  | total loss: [1m[32m0.03736[0m[0m | time: 97.656s
[2K
| RMSProp | epoch: 027 | loss: 0.03736 - acc: 0.9925 -- iter: 0416/1068
[A[ATraining Step: 898  | total loss: [1m[32m0.04275[0m[0m | time: 106.078s
[2K
| RMSProp | epoch: 027 | loss: 0.04275 - acc: 0.9902 -- iter: 0448/1068
[A[ATraining Step: 899  | total loss: [1m[32m0.03966[0m[0m | time: 108.310s
[2K
| RMSProp | epoch: 027 | loss: 0.03966 - acc: 0.9911 -- iter: 0480/1068
[A[ATraining Step: 900  | total loss: [1m[32m0.03588[0m[0m | time: 109.304s
[2K
| RMSProp | epoch: 027 | loss: 0.03588 - acc: 0.9920 -- iter: 0512/1068
[A[ATraining Step: 901  | total loss: [1m[32m0.03340[0m[0m | time: 110.355s
[2K
| RMSProp | epoch: 027 | loss: 0.03340 - acc: 0.9928 -- iter: 0544/1068
[A[ATraining Step: 902  | total loss: [1m[32m0.04019[0m[0m | time: 111.306s
[2K
| RMSProp | epoch: 027 | loss: 0.04019 - acc: 0.9904 -- iter: 0576/1068
[A[ATraining Step: 903  | total loss: [1m[32m0.05617[0m[0m | time: 112.484s
[2K
| RMSProp | epoch: 027 | loss: 0.05617 - acc: 0.9882 -- iter: 0608/1068
[A[ATraining Step: 904  | total loss: [1m[32m0.05523[0m[0m | time: 113.658s
[2K
| RMSProp | epoch: 027 | loss: 0.05523 - acc: 0.9894 -- iter: 0640/1068
[A[ATraining Step: 905  | total loss: [1m[32m0.05099[0m[0m | time: 114.584s
[2K
| RMSProp | epoch: 027 | loss: 0.05099 - acc: 0.9905 -- iter: 0672/1068
[A[ATraining Step: 906  | total loss: [1m[32m0.04675[0m[0m | time: 115.764s
[2K
| RMSProp | epoch: 027 | loss: 0.04675 - acc: 0.9914 -- iter: 0704/1068
[A[ATraining Step: 907  | total loss: [1m[32m0.04239[0m[0m | time: 116.908s
[2K
| RMSProp | epoch: 027 | loss: 0.04239 - acc: 0.9923 -- iter: 0736/1068
[A[ATraining Step: 908  | total loss: [1m[32m0.03912[0m[0m | time: 119.756s
[2K
| RMSProp | epoch: 027 | loss: 0.03912 - acc: 0.9931 -- iter: 0768/1068
[A[ATraining Step: 909  | total loss: [1m[32m0.03695[0m[0m | time: 120.145s
[2K
| RMSProp | epoch: 027 | loss: 0.03695 - acc: 0.9938 -- iter: 0800/1068
[A[ATraining Step: 910  | total loss: [1m[32m0.03326[0m[0m | time: 120.800s
[2K
| RMSProp | epoch: 027 | loss: 0.03326 - acc: 0.9944 -- iter: 0832/1068
[A[ATraining Step: 911  | total loss: [1m[32m0.02994[0m[0m | time: 133.453s
[2K
| RMSProp | epoch: 027 | loss: 0.02994 - acc: 0.9949 -- iter: 0864/1068
[A[ATraining Step: 912  | total loss: [1m[32m0.02779[0m[0m | time: 138.721s
[2K
| RMSProp | epoch: 027 | loss: 0.02779 - acc: 0.9954 -- iter: 0896/1068
[A[ATraining Step: 913  | total loss: [1m[32m0.04261[0m[0m | time: 145.558s
[2K
| RMSProp | epoch: 027 | loss: 0.04261 - acc: 0.9928 -- iter: 0928/1068
[A[ATraining Step: 914  | total loss: [1m[32m0.03917[0m[0m | time: 148.618s
[2K
| RMSProp | epoch: 027 | loss: 0.03917 - acc: 0.9935 -- iter: 0960/1068
[A[ATraining Step: 915  | total loss: [1m[32m0.03592[0m[0m | time: 166.416s
[2K
| RMSProp | epoch: 027 | loss: 0.03592 - acc: 0.9941 -- iter: 0992/1068
[A[ATraining Step: 916  | total loss: [1m[32m0.03260[0m[0m | time: 173.600s
[2K
| RMSProp | epoch: 027 | loss: 0.03260 - acc: 0.9947 -- iter: 1024/1068
[A[ATraining Step: 917  | total loss: [1m[32m0.02954[0m[0m | time: 176.835s
[2K
| RMSProp | epoch: 027 | loss: 0.02954 - acc: 0.9953 -- iter: 1056/1068
[A[ATraining Step: 918  | total loss: [1m[32m0.02675[0m[0m | time: 205.156s
[2K
| RMSProp | epoch: 027 | loss: 0.02675 - acc: 0.9957 | val_loss: 0.74380 - val_acc: 0.8383 -- iter: 1068/1068
--
Training Step: 919  | total loss: [1m[32m0.02423[0m[0m | time: 1.118s
[2K
| RMSProp | epoch: 028 | loss: 0.02423 - acc: 0.9962 -- iter: 0032/1068
[A[ATraining Step: 920  | total loss: [1m[32m0.02199[0m[0m | time: 2.161s
[2K
| RMSProp | epoch: 028 | loss: 0.02199 - acc: 0.9965 -- iter: 0064/1068
[A[ATraining Step: 921  | total loss: [1m[32m0.01994[0m[0m | time: 3.349s
[2K
| RMSProp | epoch: 028 | loss: 0.01994 - acc: 0.9969 -- iter: 0096/1068
[A[ATraining Step: 922  | total loss: [1m[32m0.01800[0m[0m | time: 4.607s
[2K
| RMSProp | epoch: 028 | loss: 0.01800 - acc: 0.9972 -- iter: 0128/1068
[A[ATraining Step: 923  | total loss: [1m[32m0.01625[0m[0m | time: 5.611s
[2K
| RMSProp | epoch: 028 | loss: 0.01625 - acc: 0.9975 -- iter: 0160/1068
[A[ATraining Step: 924  | total loss: [1m[32m0.01464[0m[0m | time: 6.765s
[2K
| RMSProp | epoch: 028 | loss: 0.01464 - acc: 0.9977 -- iter: 0192/1068
[A[ATraining Step: 925  | total loss: [1m[32m0.01319[0m[0m | time: 7.800s
[2K
| RMSProp | epoch: 028 | loss: 0.01319 - acc: 0.9980 -- iter: 0224/1068
[A[ATraining Step: 926  | total loss: [1m[32m0.01194[0m[0m | time: 11.313s
[2K
| RMSProp | epoch: 028 | loss: 0.01194 - acc: 0.9982 -- iter: 0256/1068
[A[ATraining Step: 927  | total loss: [1m[32m0.03752[0m[0m | time: 13.477s
[2K
| RMSProp | epoch: 028 | loss: 0.03752 - acc: 0.9952 -- iter: 0288/1068
[A[ATraining Step: 928  | total loss: [1m[32m0.03599[0m[0m | time: 18.947s
[2K
| RMSProp | epoch: 028 | loss: 0.03599 - acc: 0.9957 -- iter: 0320/1068
[A[ATraining Step: 929  | total loss: [1m[32m0.03438[0m[0m | time: 24.447s
[2K
| RMSProp | epoch: 028 | loss: 0.03438 - acc: 0.9961 -- iter: 0352/1068
[A[ATraining Step: 930  | total loss: [1m[32m0.03902[0m[0m | time: 33.100s
[2K
| RMSProp | epoch: 028 | loss: 0.03902 - acc: 0.9934 -- iter: 0384/1068
[A[ATraining Step: 931  | total loss: [1m[32m0.10577[0m[0m | time: 35.837s
[2K
| RMSProp | epoch: 028 | loss: 0.10577 - acc: 0.9753 -- iter: 0416/1068
[A[ATraining Step: 932  | total loss: [1m[32m0.12236[0m[0m | time: 42.780s
[2K
| RMSProp | epoch: 028 | loss: 0.12236 - acc: 0.9684 -- iter: 0448/1068
[A[ATraining Step: 933  | total loss: [1m[32m0.11233[0m[0m | time: 47.194s
[2K
| RMSProp | epoch: 028 | loss: 0.11233 - acc: 0.9716 -- iter: 0480/1068
[A[ATraining Step: 934  | total loss: [1m[32m0.10683[0m[0m | time: 50.756s
[2K
| RMSProp | epoch: 028 | loss: 0.10683 - acc: 0.9713 -- iter: 0512/1068
[A[ATraining Step: 935  | total loss: [1m[32m0.09672[0m[0m | time: 59.028s
[2K
| RMSProp | epoch: 028 | loss: 0.09672 - acc: 0.9741 -- iter: 0544/1068
[A[ATraining Step: 936  | total loss: [1m[32m0.09856[0m[0m | time: 64.387s
[2K
| RMSProp | epoch: 028 | loss: 0.09856 - acc: 0.9736 -- iter: 0576/1068
[A[ATraining Step: 937  | total loss: [1m[32m0.09118[0m[0m | time: 68.345s
[2K
| RMSProp | epoch: 028 | loss: 0.09118 - acc: 0.9762 -- iter: 0608/1068
[A[ATraining Step: 938  | total loss: [1m[32m0.08274[0m[0m | time: 74.380s
[2K
| RMSProp | epoch: 028 | loss: 0.08274 - acc: 0.9786 -- iter: 0640/1068
[A[ATraining Step: 939  | total loss: [1m[32m0.07763[0m[0m | time: 91.020s
[2K
| RMSProp | epoch: 028 | loss: 0.07763 - acc: 0.9776 -- iter: 0672/1068
[A[ATraining Step: 940  | total loss: [1m[32m0.07728[0m[0m | time: 96.376s
[2K
| RMSProp | epoch: 028 | loss: 0.07728 - acc: 0.9767 -- iter: 0704/1068
[A[ATraining Step: 941  | total loss: [1m[32m0.10870[0m[0m | time: 101.962s
[2K
| RMSProp | epoch: 028 | loss: 0.10870 - acc: 0.9572 -- iter: 0736/1068
[A[ATraining Step: 942  | total loss: [1m[32m0.09918[0m[0m | time: 112.303s
[2K
| RMSProp | epoch: 028 | loss: 0.09918 - acc: 0.9615 -- iter: 0768/1068
[A[ATraining Step: 943  | total loss: [1m[32m0.09608[0m[0m | time: 115.020s
[2K
| RMSProp | epoch: 028 | loss: 0.09608 - acc: 0.9622 -- iter: 0800/1068
[A[ATraining Step: 944  | total loss: [1m[32m0.08800[0m[0m | time: 115.450s
[2K
| RMSProp | epoch: 028 | loss: 0.08800 - acc: 0.9660 -- iter: 0832/1068
[A[ATraining Step: 945  | total loss: [1m[32m0.07977[0m[0m | time: 115.883s
[2K
| RMSProp | epoch: 028 | loss: 0.07977 - acc: 0.9694 -- iter: 0864/1068
[A[ATraining Step: 946  | total loss: [1m[32m0.07209[0m[0m | time: 116.879s
[2K
| RMSProp | epoch: 028 | loss: 0.07209 - acc: 0.9724 -- iter: 0896/1068
[A[ATraining Step: 947  | total loss: [1m[32m0.07175[0m[0m | time: 117.899s
[2K
| RMSProp | epoch: 028 | loss: 0.07175 - acc: 0.9721 -- iter: 0928/1068
[A[ATraining Step: 948  | total loss: [1m[32m0.06661[0m[0m | time: 119.003s
[2K
| RMSProp | epoch: 028 | loss: 0.06661 - acc: 0.9749 -- iter: 0960/1068
[A[ATraining Step: 949  | total loss: [1m[32m0.06036[0m[0m | time: 120.122s
[2K
| RMSProp | epoch: 028 | loss: 0.06036 - acc: 0.9774 -- iter: 0992/1068
[A[ATraining Step: 950  | total loss: [1m[32m0.05671[0m[0m | time: 121.107s
[2K
| RMSProp | epoch: 028 | loss: 0.05671 - acc: 0.9796 -- iter: 1024/1068
[A[ATraining Step: 951  | total loss: [1m[32m0.05132[0m[0m | time: 122.123s
[2K
| RMSProp | epoch: 028 | loss: 0.05132 - acc: 0.9817 -- iter: 1056/1068
[A[ATraining Step: 952  | total loss: [1m[32m0.05184[0m[0m | time: 141.751s
[2K
| RMSProp | epoch: 028 | loss: 0.05184 - acc: 0.9804 | val_loss: 0.57031 - val_acc: 0.8473 -- iter: 1068/1068
--
Training Step: 953  | total loss: [1m[32m0.04721[0m[0m | time: 1.063s
[2K
| RMSProp | epoch: 029 | loss: 0.04721 - acc: 0.9823 -- iter: 0032/1068
[A[ATraining Step: 954  | total loss: [1m[32m0.04284[0m[0m | time: 2.134s
[2K
| RMSProp | epoch: 029 | loss: 0.04284 - acc: 0.9841 -- iter: 0064/1068
[A[ATraining Step: 955  | total loss: [1m[32m0.03864[0m[0m | time: 3.177s
[2K
| RMSProp | epoch: 029 | loss: 0.03864 - acc: 0.9857 -- iter: 0096/1068
[A[ATraining Step: 956  | total loss: [1m[32m0.03523[0m[0m | time: 4.291s
[2K
| RMSProp | epoch: 029 | loss: 0.03523 - acc: 0.9871 -- iter: 0128/1068
[A[ATraining Step: 957  | total loss: [1m[32m0.03195[0m[0m | time: 5.481s
[2K
| RMSProp | epoch: 029 | loss: 0.03195 - acc: 0.9884 -- iter: 0160/1068
[A[ATraining Step: 958  | total loss: [1m[32m0.02916[0m[0m | time: 6.574s
[2K
| RMSProp | epoch: 029 | loss: 0.02916 - acc: 0.9896 -- iter: 0192/1068
[A[ATraining Step: 959  | total loss: [1m[32m0.02634[0m[0m | time: 7.749s
[2K
| RMSProp | epoch: 029 | loss: 0.02634 - acc: 0.9906 -- iter: 0224/1068
[A[ATraining Step: 960  | total loss: [1m[32m0.02373[0m[0m | time: 10.110s
[2K
| RMSProp | epoch: 029 | loss: 0.02373 - acc: 0.9916 -- iter: 0256/1068
[A[ATraining Step: 961  | total loss: [1m[32m0.02139[0m[0m | time: 13.471s
[2K
| RMSProp | epoch: 029 | loss: 0.02139 - acc: 0.9924 -- iter: 0288/1068
[A[ATraining Step: 962  | total loss: [1m[32m0.03746[0m[0m | time: 21.681s
[2K
| RMSProp | epoch: 029 | loss: 0.03746 - acc: 0.9900 -- iter: 0320/1068
[A[ATraining Step: 963  | total loss: [1m[32m0.03966[0m[0m | time: 24.528s
[2K
| RMSProp | epoch: 029 | loss: 0.03966 - acc: 0.9879 -- iter: 0352/1068
[A[ATraining Step: 964  | total loss: [1m[32m0.03732[0m[0m | time: 31.623s
[2K
| RMSProp | epoch: 029 | loss: 0.03732 - acc: 0.9891 -- iter: 0384/1068
[A[ATraining Step: 965  | total loss: [1m[32m0.03402[0m[0m | time: 37.308s
[2K
| RMSProp | epoch: 029 | loss: 0.03402 - acc: 0.9902 -- iter: 0416/1068
[A[ATraining Step: 966  | total loss: [1m[32m0.03096[0m[0m | time: 56.476s
[2K
| RMSProp | epoch: 029 | loss: 0.03096 - acc: 0.9912 -- iter: 0448/1068
[A[ATraining Step: 967  | total loss: [1m[32m0.02807[0m[0m | time: 59.599s
[2K
| RMSProp | epoch: 029 | loss: 0.02807 - acc: 0.9921 -- iter: 0480/1068
[A[ATraining Step: 968  | total loss: [1m[32m0.02532[0m[0m | time: 69.175s
[2K
| RMSProp | epoch: 029 | loss: 0.02532 - acc: 0.9929 -- iter: 0512/1068
[A[ATraining Step: 969  | total loss: [1m[32m0.02303[0m[0m | time: 81.791s
[2K
| RMSProp | epoch: 029 | loss: 0.02303 - acc: 0.9936 -- iter: 0544/1068
[A[ATraining Step: 970  | total loss: [1m[32m0.02076[0m[0m | time: 96.264s
[2K
| RMSProp | epoch: 029 | loss: 0.02076 - acc: 0.9942 -- iter: 0576/1068
[A[ATraining Step: 971  | total loss: [1m[32m0.01870[0m[0m | time: 100.680s
[2K
| RMSProp | epoch: 029 | loss: 0.01870 - acc: 0.9948 -- iter: 0608/1068
[A[ATraining Step: 972  | total loss: [1m[32m0.02187[0m[0m | time: 115.157s
[2K
| RMSProp | epoch: 029 | loss: 0.02187 - acc: 0.9922 -- iter: 0640/1068
[A[ATraining Step: 973  | total loss: [1m[32m0.03068[0m[0m | time: 129.231s
[2K
| RMSProp | epoch: 029 | loss: 0.03068 - acc: 0.9867 -- iter: 0672/1068
[A[ATraining Step: 974  | total loss: [1m[32m0.02865[0m[0m | time: 135.678s
[2K
| RMSProp | epoch: 029 | loss: 0.02865 - acc: 0.9880 -- iter: 0704/1068
[A[ATraining Step: 975  | total loss: [1m[32m0.03849[0m[0m | time: 142.174s
[2K
| RMSProp | epoch: 029 | loss: 0.03849 - acc: 0.9830 -- iter: 0736/1068
[A[ATraining Step: 976  | total loss: [1m[32m0.08758[0m[0m | time: 145.879s
[2K
| RMSProp | epoch: 029 | loss: 0.08758 - acc: 0.9691 -- iter: 0768/1068
[A[ATraining Step: 977  | total loss: [1m[32m0.08738[0m[0m | time: 152.046s
[2K
| RMSProp | epoch: 029 | loss: 0.08738 - acc: 0.9659 -- iter: 0800/1068
[A[ATraining Step: 978  | total loss: [1m[32m0.07931[0m[0m | time: 158.759s
[2K
| RMSProp | epoch: 029 | loss: 0.07931 - acc: 0.9693 -- iter: 0832/1068
[A[ATraining Step: 979  | total loss: [1m[32m0.07173[0m[0m | time: 159.237s
[2K
| RMSProp | epoch: 029 | loss: 0.07173 - acc: 0.9724 -- iter: 0864/1068
[A[ATraining Step: 980  | total loss: [1m[32m0.06702[0m[0m | time: 163.126s
[2K
| RMSProp | epoch: 029 | loss: 0.06702 - acc: 0.9752 -- iter: 0896/1068
[A[ATraining Step: 981  | total loss: [1m[32m0.06048[0m[0m | time: 164.072s
[2K
| RMSProp | epoch: 029 | loss: 0.06048 - acc: 0.9776 -- iter: 0928/1068
[A[ATraining Step: 982  | total loss: [1m[32m0.05692[0m[0m | time: 165.132s
[2K
| RMSProp | epoch: 029 | loss: 0.05692 - acc: 0.9767 -- iter: 0960/1068
[A[ATraining Step: 983  | total loss: [1m[32m0.09507[0m[0m | time: 166.151s
[2K
| RMSProp | epoch: 029 | loss: 0.09507 - acc: 0.9728 -- iter: 0992/1068
[A[ATraining Step: 984  | total loss: [1m[32m0.10777[0m[0m | time: 167.213s
[2K
| RMSProp | epoch: 029 | loss: 0.10777 - acc: 0.9662 -- iter: 1024/1068
[A[ATraining Step: 985  | total loss: [1m[32m0.10302[0m[0m | time: 168.433s
[2K
| RMSProp | epoch: 029 | loss: 0.10302 - acc: 0.9664 -- iter: 1056/1068
[A[ATraining Step: 986  | total loss: [1m[32m0.09331[0m[0m | time: 171.770s
[2K
| RMSProp | epoch: 029 | loss: 0.09331 - acc: 0.9698 | val_loss: 0.49063 - val_acc: 0.8503 -- iter: 1068/1068
--
Training Step: 987  | total loss: [1m[32m0.08550[0m[0m | time: 2.023s
[2K
| RMSProp | epoch: 030 | loss: 0.08550 - acc: 0.9728 -- iter: 0032/1068
[A[ATraining Step: 988  | total loss: [1m[32m0.07905[0m[0m | time: 13.925s
[2K
| RMSProp | epoch: 030 | loss: 0.07905 - acc: 0.9755 -- iter: 0064/1068
[A[ATraining Step: 989  | total loss: [1m[32m0.07181[0m[0m | time: 27.362s
[2K
| RMSProp | epoch: 030 | loss: 0.07181 - acc: 0.9780 -- iter: 0096/1068
[A[ATraining Step: 990  | total loss: [1m[32m0.06473[0m[0m | time: 40.298s
[2K
| RMSProp | epoch: 030 | loss: 0.06473 - acc: 0.9802 -- iter: 0128/1068
[A[ATraining Step: 991  | total loss: [1m[32m0.05965[0m[0m | time: 44.562s
[2K
| RMSProp | epoch: 030 | loss: 0.05965 - acc: 0.9822 -- iter: 0160/1068
[A[ATraining Step: 992  | total loss: [1m[32m0.05397[0m[0m | time: 58.578s
[2K
| RMSProp | epoch: 030 | loss: 0.05397 - acc: 0.9839 -- iter: 0192/1068
[A[ATraining Step: 993  | total loss: [1m[32m0.04866[0m[0m | time: 61.846s
[2K
| RMSProp | epoch: 030 | loss: 0.04866 - acc: 0.9855 -- iter: 0224/1068
[A[ATraining Step: 994  | total loss: [1m[32m0.04393[0m[0m | time: 78.835s
[2K
| RMSProp | epoch: 030 | loss: 0.04393 - acc: 0.9870 -- iter: 0256/1068
[A[ATraining Step: 995  | total loss: [1m[32m0.04004[0m[0m | time: 87.199s
[2K
| RMSProp | epoch: 030 | loss: 0.04004 - acc: 0.9883 -- iter: 0288/1068
[A[ATraining Step: 996  | total loss: [1m[32m0.04485[0m[0m | time: 101.748s
[2K
| RMSProp | epoch: 030 | loss: 0.04485 - acc: 0.9863 -- iter: 0320/1068
[A[ATraining Step: 997  | total loss: [1m[32m0.04077[0m[0m | time: 114.752s
[2K
| RMSProp | epoch: 030 | loss: 0.04077 - acc: 0.9877 -- iter: 0352/1068
[A[ATraining Step: 998  | total loss: [1m[32m0.03799[0m[0m | time: 128.733s
[2K
| RMSProp | epoch: 030 | loss: 0.03799 - acc: 0.9889 -- iter: 0384/1068
[A[ATraining Step: 999  | total loss: [1m[32m0.03434[0m[0m | time: 138.763s
[2K
| RMSProp | epoch: 030 | loss: 0.03434 - acc: 0.9900 -- iter: 0416/1068
[A[ATraining Step: 1000  | total loss: [1m[32m0.03277[0m[0m | time: 198.870s
[2K
| RMSProp | epoch: 030 | loss: 0.03277 - acc: 0.9910 | val_loss: 0.71797 - val_acc: 0.8413 -- iter: 0448/1068
--
Training Step: 1001  | total loss: [1m[32m0.02991[0m[0m | time: 199.850s
[2K
| RMSProp | epoch: 030 | loss: 0.02991 - acc: 0.9919 -- iter: 0480/1068
[A[ATraining Step: 1002  | total loss: [1m[32m0.03373[0m[0m | time: 200.886s
[2K
| RMSProp | epoch: 030 | loss: 0.03373 - acc: 0.9896 -- iter: 0512/1068
[A[ATraining Step: 1003  | total loss: [1m[32m0.09724[0m[0m | time: 201.981s
[2K
| RMSProp | epoch: 030 | loss: 0.09724 - acc: 0.9750 -- iter: 0544/1068
[A[ATraining Step: 1004  | total loss: [1m[32m0.10400[0m[0m | time: 203.096s
[2K
| RMSProp | epoch: 030 | loss: 0.10400 - acc: 0.9713 -- iter: 0576/1068
[A[ATraining Step: 1005  | total loss: [1m[32m0.10036[0m[0m | time: 204.296s
[2K
| RMSProp | epoch: 030 | loss: 0.10036 - acc: 0.9710 -- iter: 0608/1068
[A[ATraining Step: 1006  | total loss: [1m[32m0.10496[0m[0m | time: 205.290s
[2K
| RMSProp | epoch: 030 | loss: 0.10496 - acc: 0.9677 -- iter: 0640/1068
[A[ATraining Step: 1007  | total loss: [1m[32m0.10152[0m[0m | time: 206.435s
[2K
| RMSProp | epoch: 030 | loss: 0.10152 - acc: 0.9678 -- iter: 0672/1068
[A[ATraining Step: 1008  | total loss: [1m[32m0.09211[0m[0m | time: 207.595s
[2K
| RMSProp | epoch: 030 | loss: 0.09211 - acc: 0.9710 -- iter: 0704/1068
[A[ATraining Step: 1009  | total loss: [1m[32m0.08435[0m[0m | time: 208.635s
[2K
| RMSProp | epoch: 030 | loss: 0.08435 - acc: 0.9739 -- iter: 0736/1068
[A[ATraining Step: 1010  | total loss: [1m[32m0.07832[0m[0m | time: 211.595s
[2K
| RMSProp | epoch: 030 | loss: 0.07832 - acc: 0.9734 -- iter: 0768/1068
[A[ATraining Step: 1011  | total loss: [1m[32m0.08059[0m[0m | time: 222.071s
[2K
| RMSProp | epoch: 030 | loss: 0.08059 - acc: 0.9729 -- iter: 0800/1068
[A[ATraining Step: 1012  | total loss: [1m[32m0.07659[0m[0m | time: 226.564s
[2K
| RMSProp | epoch: 030 | loss: 0.07659 - acc: 0.9725 -- iter: 0832/1068
[A[ATraining Step: 1013  | total loss: [1m[32m0.06984[0m[0m | time: 230.600s
[2K
| RMSProp | epoch: 030 | loss: 0.06984 - acc: 0.9753 -- iter: 0864/1068
[A[ATraining Step: 1014  | total loss: [1m[32m0.06303[0m[0m | time: 234.422s
[2K
| RMSProp | epoch: 030 | loss: 0.06303 - acc: 0.9777 -- iter: 0896/1068
[A[ATraining Step: 1015  | total loss: [1m[32m0.10489[0m[0m | time: 235.898s
[2K
| RMSProp | epoch: 030 | loss: 0.10489 - acc: 0.9716 -- iter: 0928/1068
[A[ATraining Step: 1016  | total loss: [1m[32m0.09870[0m[0m | time: 239.194s
[2K
| RMSProp | epoch: 030 | loss: 0.09870 - acc: 0.9745 -- iter: 0960/1068
[A[ATraining Step: 1017  | total loss: [1m[32m0.08989[0m[0m | time: 241.885s
[2K
| RMSProp | epoch: 030 | loss: 0.08989 - acc: 0.9770 -- iter: 0992/1068
[A[ATraining Step: 1018  | total loss: [1m[32m0.26407[0m[0m | time: 242.945s
[2K
| RMSProp | epoch: 030 | loss: 0.26407 - acc: 0.9543 -- iter: 1024/1068
[A[ATraining Step: 1019  | total loss: [1m[32m0.25637[0m[0m | time: 244.070s
[2K
| RMSProp | epoch: 030 | loss: 0.25637 - acc: 0.9558 -- iter: 1056/1068
[A[ATraining Step: 1020  | total loss: [1m[32m0.23417[0m[0m | time: 247.544s
[2K
| RMSProp | epoch: 030 | loss: 0.23417 - acc: 0.9602 | val_loss: 0.42009 - val_acc: 0.8353 -- iter: 1068/1068
--
Validation AUC:0.9234449760765551
Validation AUPRC:0.9512380097594586
Test AUC:0.9101865671641791
Test AUPRC:0.9174726185427486
BestTestF1Score	0.88	0.68	0.84	0.82	0.94	188	40	94	12	0.12
BestTestMCCScore	0.87	0.68	0.84	0.89	0.85	170	22	112	30	0.72
BestTestAccuracyScore	0.88	0.68	0.84	0.82	0.94	188	40	94	12	0.12
BestValidationF1Score	0.89	0.68	0.85	0.84	0.94	196	36	89	13	0.12
BestValidationMCC	0.87	0.69	0.85	0.91	0.84	175	17	108	34	0.72
BestValidationAccuracy	0.89	0.68	0.85	0.84	0.94	196	36	89	13	0.12
TestPredictions (Threshold:0.72)
CHEMBL1682976,TN,INACT,0.009999999776482582	CHEMBL493473,TP,ACT,0.9800000190734863	CHEMBL149736,FN,ACT,0.6200000047683716	CHEMBL370165,TP,ACT,0.9700000286102295	CHEMBL523336,FN,ACT,0.27000001072883606	CHEMBL491749,TN,INACT,0.33000001311302185	CHEMBL180297,TP,ACT,1.0	CHEMBL240017,TP,ACT,1.0	CHEMBL400387,FN,ACT,0.11999999731779099	CHEMBL126718,TN,INACT,0.6600000262260437	CHEMBL380496,TN,INACT,0.019999999552965164	CHEMBL1209449,TP,ACT,0.9599999785423279	CHEMBL1093961,TP,ACT,1.0	CHEMBL1651349,TP,ACT,0.8399999737739563	CHEMBL62453,TN,INACT,0.07999999821186066	CHEMBL3669129,TP,ACT,0.9900000095367432	CHEMBL175629,TN,INACT,0.009999999776482582	CHEMBL3701884,TP,ACT,1.0	CHEMBL446669,TN,INACT,0.03999999910593033	CHEMBL2203326,TP,ACT,1.0	CHEMBL367803,TP,ACT,1.0	CHEMBL2207170,TP,ACT,0.9700000286102295	CHEMBL218024,TP,ACT,1.0	CHEMBL3093929,TP,ACT,0.9700000286102295	CHEMBL561725,TP,ACT,1.0	CHEMBL1089621,TP,ACT,0.9900000095367432	CHEMBL368156,TN,INACT,0.029999999329447746	CHEMBL2312218,TN,INACT,0.03999999910593033	CHEMBL575686,TP,ACT,1.0	CHEMBL213712,TP,ACT,1.0	CHEMBL198570,FN,ACT,0.03999999910593033	CHEMBL205320,FN,ACT,0.03999999910593033	CHEMBL3649404,TP,ACT,0.9900000095367432	CHEMBL363512,TP,ACT,1.0	CHEMBL3354498,TN,INACT,0.03999999910593033	CHEMBL2312673,TP,ACT,1.0	CHEMBL200531,TP,ACT,0.9200000166893005	CHEMBL3651540,TP,ACT,0.9800000190734863	CHEMBL3651499,TP,ACT,0.9900000095367432	CHEMBL179687,TN,INACT,0.009999999776482582	CHEMBL144027,TN,INACT,0.009999999776482582	CHEMBL3701882,TP,ACT,1.0	CHEMBL69332,TN,INACT,0.03999999910593033	CHEMBL3290111,TN,INACT,0.6800000071525574	CHEMBL482269,TP,ACT,0.9900000095367432	CHEMBL379230,FN,ACT,0.6800000071525574	CHEMBL197958,TP,ACT,0.9800000190734863	CHEMBL3661024,TN,INACT,0.49000000953674316	CHEMBL216178,TN,INACT,0.03999999910593033	CHEMBL1289536,TP,ACT,1.0	CHEMBL511659,TN,INACT,0.03999999910593033	CHEMBL390080,TN,INACT,0.009999999776482582	CHEMBL479461,TP,ACT,1.0	CHEMBL3357770,TN,INACT,0.019999999552965164	CHEMBL494517,TP,ACT,1.0	CHEMBL2425070,TN,INACT,0.07999999821186066	CHEMBL230474,FN,ACT,0.07999999821186066	CHEMBL563886,TP,ACT,0.9800000190734863	CHEMBL213244,TP,ACT,1.0	CHEMBL482268,TP,ACT,1.0	CHEMBL207891,FN,ACT,0.029999999329447746	CHEMBL2312204,TN,INACT,0.09000000357627869	CHEMBL3701867,TP,ACT,1.0	CHEMBL1089714,TP,ACT,0.9599999785423279	CHEMBL205566,TP,ACT,1.0	CHEMBL2071096,TP,ACT,1.0	CHEMBL2437302,TN,INACT,0.009999999776482582	CHEMBL168471,TN,INACT,0.03999999910593033	CHEMBL3142429,FN,ACT,0.12999999523162842	CHEMBL1085984,TP,ACT,0.9900000095367432	CHEMBL153248,TP,ACT,0.9900000095367432	CHEMBL215378,TP,ACT,0.9900000095367432	CHEMBL116746,TN,INACT,0.07999999821186066	CHEMBL2373062,FP,INACT,0.7599999904632568	CHEMBL206024,TP,ACT,1.0	CHEMBL2203960,TP,ACT,0.9700000286102295	CHEMBL249367,TP,ACT,0.9800000190734863	CHEMBL2380718,TP,ACT,1.0	CHEMBL209064,TN,INACT,0.03999999910593033	CHEMBL230985,TN,INACT,0.019999999552965164	CHEMBL1085978,FN,ACT,0.28999999165534973	CHEMBL208284,TP,ACT,0.9900000095367432	CHEMBL1209450,TP,ACT,0.9599999785423279	CHEMBL390945,TP,ACT,0.9800000190734863	CHEMBL473418,TN,INACT,0.029999999329447746	CHEMBL3357669,TN,INACT,0.05000000074505806	CHEMBL210198,FP,INACT,0.9200000166893005	CHEMBL1086431,TN,INACT,0.05999999865889549	CHEMBL251114,TP,ACT,0.9300000071525574	CHEMBL238963,TP,ACT,1.0	CHEMBL3640715,TP,ACT,0.9800000190734863	CHEMBL2382005,TN,INACT,0.009999999776482582	CHEMBL371059,TN,INACT,0.1599999964237213	CHEMBL452520,FP,INACT,0.8899999856948853	CHEMBL556504,TP,ACT,0.8399999737739563	CHEMBL336228,TP,ACT,0.9700000286102295	CHEMBL2382002,FP,INACT,1.0	CHEMBL233563,TN,INACT,0.05999999865889549	CHEMBL426493,TP,ACT,0.9200000166893005	CHEMBL399026,TN,INACT,0.25	CHEMBL1162922,TP,ACT,0.9800000190734863	CHEMBL162631,FN,ACT,0.6700000166893005	CHEMBL1683128,TN,INACT,0.03999999910593033	CHEMBL93507,TN,INACT,0.03999999910593033	CHEMBL250119,FN,ACT,0.25999999046325684	CHEMBL1651351,FN,ACT,0.10000000149011612	CHEMBL2207567,FN,ACT,0.699999988079071	CHEMBL197413,TN,INACT,0.029999999329447746	CHEMBL264315,TP,ACT,0.9900000095367432	CHEMBL1683109,TN,INACT,0.009999999776482582	CHEMBL1162208,FP,INACT,1.0	CHEMBL573656,TP,ACT,1.0	CHEMBL183306,TP,ACT,0.9900000095367432	CHEMBL400068,TN,INACT,0.11999999731779099	CHEMBL2380726,TP,ACT,0.8199999928474426	CHEMBL200004,TP,ACT,1.0	CHEMBL3649394,TP,ACT,0.8399999737739563	CHEMBL549913,TN,INACT,0.019999999552965164	CHEMBL1083318,TP,ACT,0.9900000095367432	CHEMBL436303,TP,ACT,0.9800000190734863	CHEMBL1672422,TP,ACT,0.9800000190734863	CHEMBL198859,TN,INACT,0.05000000074505806	CHEMBL552479,TN,INACT,0.029999999329447746	CHEMBL512367,TP,ACT,0.8700000047683716	CHEMBL362538,FP,INACT,1.0	CHEMBL3701865,TP,ACT,1.0	CHEMBL439836,FP,INACT,0.9399999976158142	CHEMBL1683141,TN,INACT,0.009999999776482582	CHEMBL2164675,TP,ACT,1.0	CHEMBL152940,FN,ACT,0.17000000178813934	CHEMBL390474,FN,ACT,0.25	CHEMBL1090995,TP,ACT,1.0	CHEMBL482388,TP,ACT,0.9900000095367432	CHEMBL172051,TN,INACT,0.11999999731779099	CHEMBL2382000,TN,INACT,0.009999999776482582	CHEMBL184986,TN,INACT,0.019999999552965164	CHEMBL503274,TN,INACT,0.029999999329447746	CHEMBL1236882,TP,ACT,0.9900000095367432	CHEMBL424441,FP,INACT,0.9300000071525574	CHEMBL1089295,TP,ACT,1.0	CHEMBL2312996,TP,ACT,0.9599999785423279	CHEMBL250919,TP,ACT,0.8399999737739563	CHEMBL3651496,TP,ACT,1.0	CHEMBL178975,TN,INACT,0.07000000029802322	CHEMBL425379,TP,ACT,1.0	CHEMBL3218467,TN,INACT,0.6700000166893005	CHEMBL186062,FN,ACT,0.1599999964237213	CHEMBL248788,TN,INACT,0.019999999552965164	CHEMBL178194,FN,ACT,0.10000000149011612	CHEMBL3221926,TN,INACT,0.20999999344348907	CHEMBL3649420,TP,ACT,0.9900000095367432	CHEMBL607122,FN,ACT,0.1599999964237213	CHEMBL2381998,TN,INACT,0.019999999552965164	CHEMBL200521,TP,ACT,0.9900000095367432	CHEMBL205865,TP,ACT,1.0	CHEMBL231196,TN,INACT,0.029999999329447746	CHEMBL251205,TN,INACT,0.009999999776482582	CHEMBL3701863,FN,ACT,0.10000000149011612	CHEMBL203032,TN,INACT,0.019999999552965164	CHEMBL250181,TP,ACT,0.949999988079071	CHEMBL274740,TN,INACT,0.009999999776482582	CHEMBL200455,TN,INACT,0.019999999552965164	CHEMBL3649409,TP,ACT,1.0	CHEMBL1209309,TP,ACT,0.9900000095367432	CHEMBL1208846,TP,ACT,1.0	CHEMBL2380617,TP,ACT,0.9900000095367432	CHEMBL489722,FP,INACT,0.9800000190734863	CHEMBL450997,TN,INACT,0.4399999976158142	CHEMBL250202,TN,INACT,0.009999999776482582	CHEMBL61887,TP,ACT,0.9900000095367432	CHEMBL87332,TN,INACT,0.029999999329447746	CHEMBL360488,FP,INACT,0.9800000190734863	CHEMBL146995,TN,INACT,0.009999999776482582	CHEMBL2207591,TP,ACT,1.0	CHEMBL370677,TN,INACT,0.17000000178813934	CHEMBL397242,TN,INACT,0.029999999329447746	CHEMBL113761,TP,ACT,0.9900000095367432	CHEMBL180528,TP,ACT,0.8299999833106995	CHEMBL1836516,TN,INACT,0.019999999552965164	CHEMBL3735129,TN,INACT,0.3499999940395355	CHEMBL201544,TN,INACT,0.009999999776482582	CHEMBL389804,TN,INACT,0.029999999329447746	CHEMBL202747,TP,ACT,0.9800000190734863	CHEMBL1683098,TN,INACT,0.009999999776482582	CHEMBL1090372,TP,ACT,1.0	CHEMBL184329,FN,ACT,0.550000011920929	CHEMBL197543,TP,ACT,1.0	CHEMBL397817,TP,ACT,1.0	CHEMBL209293,TP,ACT,0.9900000095367432	CHEMBL1836513,TN,INACT,0.05999999865889549	CHEMBL1682981,TN,INACT,0.14000000059604645	CHEMBL2070942,TP,ACT,0.8700000047683716	CHEMBL390241,TN,INACT,0.009999999776482582	CHEMBL3649368,TP,ACT,0.9900000095367432	CHEMBL181413,TP,ACT,1.0	CHEMBL1089292,TP,ACT,0.9900000095367432	CHEMBL400954,TN,INACT,0.019999999552965164	CHEMBL2312205,TN,INACT,0.07000000029802322	CHEMBL2380736,TP,ACT,1.0	CHEMBL428417,TP,ACT,0.9800000190734863	CHEMBL176062,TN,INACT,0.05000000074505806	CHEMBL2381994,FP,INACT,0.9700000286102295	CHEMBL2312213,TN,INACT,0.3700000047683716	CHEMBL559248,TP,ACT,1.0	CHEMBL1209858,TP,ACT,0.9900000095367432	CHEMBL200815,FP,INACT,1.0	CHEMBL3649376,TP,ACT,1.0	CHEMBL2382067,FP,INACT,0.9700000286102295	CHEMBL340384,TN,INACT,0.009999999776482582	CHEMBL3701874,TP,ACT,1.0	CHEMBL378731,FP,INACT,0.9300000071525574	CHEMBL385632,TP,ACT,0.9700000286102295	CHEMBL3651530,TP,ACT,1.0	CHEMBL412867,TP,ACT,1.0	CHEMBL2207570,FN,ACT,0.10000000149011612	CHEMBL3651460,TP,ACT,1.0	CHEMBL3143410,TN,INACT,0.05999999865889549	CHEMBL1683142,TN,INACT,0.009999999776482582	CHEMBL3640724,TP,ACT,0.9399999976158142	CHEMBL3651506,TP,ACT,1.0	CHEMBL206913,TP,ACT,0.9800000190734863	CHEMBL3671355,TP,ACT,1.0	CHEMBL128946,TN,INACT,0.009999999776482582	CHEMBL234488,TP,ACT,1.0	CHEMBL482348,TP,ACT,1.0	CHEMBL474257,TP,ACT,0.9800000190734863	CHEMBL519136,TP,ACT,1.0	CHEMBL2171988,TP,ACT,1.0	CHEMBL3736085,TN,INACT,0.10000000149011612	CHEMBL572971,TP,ACT,0.9300000071525574	CHEMBL541919,TN,INACT,0.029999999329447746	CHEMBL1683120,TN,INACT,0.019999999552965164	CHEMBL570897,TN,INACT,0.10999999940395355	CHEMBL2206474,FP,INACT,0.9399999976158142	CHEMBL3330060,TN,INACT,0.009999999776482582	CHEMBL536999,TN,INACT,0.03999999910593033	CHEMBL452029,TN,INACT,0.07000000029802322	CHEMBL1090996,TP,ACT,1.0	CHEMBL3238000,TN,INACT,0.07000000029802322	CHEMBL62207,TP,ACT,0.9800000190734863	CHEMBL3651536,TP,ACT,0.8299999833106995	CHEMBL205835,TP,ACT,0.9399999976158142	CHEMBL2312992,TP,ACT,0.9700000286102295	CHEMBL196333,TN,INACT,0.009999999776482582	CHEMBL2171997,FP,INACT,0.9599999785423279	CHEMBL207162,FP,INACT,0.9599999785423279	CHEMBL3221922,TN,INACT,0.05000000074505806	CHEMBL1090987,TP,ACT,1.0	CHEMBL250147,TN,INACT,0.10000000149011612	CHEMBL250121,FN,ACT,0.10000000149011612	CHEMBL1672427,TP,ACT,0.8700000047683716	CHEMBL561927,FN,ACT,0.6499999761581421	CHEMBL514299,TP,ACT,0.8100000023841858	CHEMBL250284,TN,INACT,0.07000000029802322	CHEMBL2312200,TN,INACT,0.07999999821186066	CHEMBL3649392,TP,ACT,0.9900000095367432	CHEMBL561793,TN,INACT,0.019999999552965164	CHEMBL1085729,TP,ACT,0.9900000095367432	CHEMBL1089608,TP,ACT,0.9900000095367432	CHEMBL1672426,TP,ACT,0.949999988079071	CHEMBL195454,TP,ACT,1.0	CHEMBL188643,TN,INACT,0.03999999910593033	CHEMBL2207155,TP,ACT,0.949999988079071	CHEMBL198798,FP,INACT,0.9900000095367432	CHEMBL2312666,TP,ACT,1.0	CHEMBL214757,TP,ACT,1.0	CHEMBL238962,TP,ACT,1.0	CHEMBL1210690,TP,ACT,1.0	CHEMBL1683114,TN,INACT,0.009999999776482582	CHEMBL3093933,TP,ACT,0.9900000095367432	CHEMBL1090997,TP,ACT,1.0	CHEMBL2164672,TP,ACT,0.9900000095367432	CHEMBL117255,TN,INACT,0.009999999776482582	CHEMBL519459,TP,ACT,1.0	CHEMBL189055,TN,INACT,0.009999999776482582	CHEMBL199163,TP,ACT,1.0	CHEMBL381847,TP,ACT,0.9700000286102295	CHEMBL383943,FP,INACT,0.9599999785423279	CHEMBL429829,TN,INACT,0.019999999552965164	CHEMBL382180,FP,INACT,0.9399999976158142	CHEMBL578633,TP,ACT,0.9900000095367432	CHEMBL252156,TN,INACT,0.6899999976158142	CHEMBL562462,FN,ACT,0.20999999344348907	CHEMBL123199,TP,ACT,0.9900000095367432	CHEMBL1086436,TN,INACT,0.10999999940395355	CHEMBL349445,TP,ACT,0.8600000143051147	CHEMBL207560,FN,ACT,0.07000000029802322	CHEMBL3289841,TN,INACT,0.699999988079071	CHEMBL1209313,TP,ACT,1.0	CHEMBL3671360,TP,ACT,0.9900000095367432	CHEMBL539350,TN,INACT,0.05000000074505806	CHEMBL563517,TP,ACT,0.800000011920929	CHEMBL521115,TP,ACT,1.0	CHEMBL1204389,TN,INACT,0.009999999776482582	CHEMBL3640726,TP,ACT,0.9700000286102295	CHEMBL3309805,FP,INACT,0.9900000095367432	CHEMBL3093947,TP,ACT,1.0	CHEMBL523037,TP,ACT,1.0	CHEMBL3649401,TP,ACT,1.0	CHEMBL146190,TN,INACT,0.009999999776482582	CHEMBL437579,FN,ACT,0.18000000715255737	CHEMBL474865,TP,ACT,0.8700000047683716	CHEMBL482218,TP,ACT,1.0	CHEMBL1209308,TP,ACT,0.9900000095367432	CHEMBL234367,TP,ACT,0.800000011920929	CHEMBL196938,TN,INACT,0.009999999776482582	CHEMBL1083919,TP,ACT,0.9900000095367432	CHEMBL1683108,TN,INACT,0.019999999552965164	CHEMBL513921,TP,ACT,0.9900000095367432	CHEMBL238948,TP,ACT,1.0	CHEMBL397622,TP,ACT,1.0	CHEMBL356442,FN,ACT,0.029999999329447746	CHEMBL3649417,TP,ACT,1.0	CHEMBL230602,TN,INACT,0.03999999910593033	CHEMBL362134,TP,ACT,0.9700000286102295	CHEMBL2380724,TP,ACT,0.7200000286102295	CHEMBL1807696,TP,ACT,1.0	CHEMBL1289644,TP,ACT,1.0	CHEMBL1171094,TN,INACT,0.6399999856948853	CHEMBL389538,TN,INACT,0.009999999776482582	CHEMBL385899,TN,INACT,0.6899999976158142	CHEMBL435440,TP,ACT,0.949999988079071	CHEMBL2380719,TP,ACT,1.0	CHEMBL249698,FN,ACT,0.15000000596046448	CHEMBL184403,FN,ACT,0.6000000238418579	CHEMBL3093824,TP,ACT,0.8999999761581421	CHEMBL1651359,TP,ACT,0.9900000095367432	CHEMBL401304,TN,INACT,0.23999999463558197	CHEMBL3093911,TN,INACT,0.03999999910593033	CHEMBL397241,TN,INACT,0.009999999776482582	CHEMBL200506,FP,INACT,0.9200000166893005	CHEMBL3671353,TP,ACT,1.0	CHEMBL1209246,TP,ACT,0.7400000095367432	CHEMBL380361,TP,ACT,0.9399999976158142	

