ImageNetInceptionV2 CHEMBL2276 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	1215
Number of inactive compounds :	1215
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2276_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2276_adam_0.001_15_0.8/
---------------------------------
Training samples: 1517
Validation samples: 475
--
Training Step: 1  | time: 35.805s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1517
[A[ATraining Step: 2  | total loss: [1m[32m0.65885[0m[0m | time: 44.253s
[2K
| Adam | epoch: 001 | loss: 0.65885 - acc: 0.4500 -- iter: 0064/1517
[A[ATraining Step: 3  | total loss: [1m[32m0.96071[0m[0m | time: 52.549s
[2K
| Adam | epoch: 001 | loss: 0.96071 - acc: 0.3886 -- iter: 0096/1517
[A[ATraining Step: 4  | total loss: [1m[32m0.74245[0m[0m | time: 61.052s
[2K
| Adam | epoch: 001 | loss: 0.74245 - acc: 0.4956 -- iter: 0128/1517
[A[ATraining Step: 5  | total loss: [1m[32m1.09203[0m[0m | time: 69.425s
[2K
| Adam | epoch: 001 | loss: 1.09203 - acc: 0.4986 -- iter: 0160/1517
[A[ATraining Step: 6  | total loss: [1m[32m1.00587[0m[0m | time: 77.889s
[2K
| Adam | epoch: 001 | loss: 1.00587 - acc: 0.4392 -- iter: 0192/1517
[A[ATraining Step: 7  | total loss: [1m[32m0.76951[0m[0m | time: 86.367s
[2K
| Adam | epoch: 001 | loss: 0.76951 - acc: 0.5507 -- iter: 0224/1517
[A[ATraining Step: 8  | total loss: [1m[32m0.82196[0m[0m | time: 94.842s
[2K
| Adam | epoch: 001 | loss: 0.82196 - acc: 0.4870 -- iter: 0256/1517
[A[ATraining Step: 9  | total loss: [1m[32m0.72678[0m[0m | time: 103.076s
[2K
| Adam | epoch: 001 | loss: 0.72678 - acc: 0.5435 -- iter: 0288/1517
[A[ATraining Step: 10  | total loss: [1m[32m0.68503[0m[0m | time: 111.349s
[2K
| Adam | epoch: 001 | loss: 0.68503 - acc: 0.6155 -- iter: 0320/1517
[A[ATraining Step: 11  | total loss: [1m[32m0.65467[0m[0m | time: 119.925s
[2K
| Adam | epoch: 001 | loss: 0.65467 - acc: 0.6348 -- iter: 0352/1517
[A[ATraining Step: 12  | total loss: [1m[32m0.75312[0m[0m | time: 128.166s
[2K
| Adam | epoch: 001 | loss: 0.75312 - acc: 0.5882 -- iter: 0384/1517
[A[ATraining Step: 13  | total loss: [1m[32m0.69999[0m[0m | time: 136.535s
[2K
| Adam | epoch: 001 | loss: 0.69999 - acc: 0.6040 -- iter: 0416/1517
[A[ATraining Step: 14  | total loss: [1m[32m0.70001[0m[0m | time: 144.998s
[2K
| Adam | epoch: 001 | loss: 0.70001 - acc: 0.5742 -- iter: 0448/1517
[A[ATraining Step: 15  | total loss: [1m[32m0.70965[0m[0m | time: 153.424s
[2K
| Adam | epoch: 001 | loss: 0.70965 - acc: 0.5085 -- iter: 0480/1517
[A[ATraining Step: 16  | total loss: [1m[32m0.67315[0m[0m | time: 161.975s
[2K
| Adam | epoch: 001 | loss: 0.67315 - acc: 0.5991 -- iter: 0512/1517
[A[ATraining Step: 17  | total loss: [1m[32m0.64382[0m[0m | time: 170.458s
[2K
| Adam | epoch: 001 | loss: 0.64382 - acc: 0.5971 -- iter: 0544/1517
[A[ATraining Step: 18  | total loss: [1m[32m0.62834[0m[0m | time: 179.000s
[2K
| Adam | epoch: 001 | loss: 0.62834 - acc: 0.6392 -- iter: 0576/1517
[A[ATraining Step: 19  | total loss: [1m[32m0.65571[0m[0m | time: 187.570s
[2K
| Adam | epoch: 001 | loss: 0.65571 - acc: 0.6241 -- iter: 0608/1517
[A[ATraining Step: 20  | total loss: [1m[32m0.64310[0m[0m | time: 196.089s
[2K
| Adam | epoch: 001 | loss: 0.64310 - acc: 0.6244 -- iter: 0640/1517
[A[ATraining Step: 21  | total loss: [1m[32m0.64345[0m[0m | time: 204.566s
[2K
| Adam | epoch: 001 | loss: 0.64345 - acc: 0.6246 -- iter: 0672/1517
[A[ATraining Step: 22  | total loss: [1m[32m0.64255[0m[0m | time: 213.065s
[2K
| Adam | epoch: 001 | loss: 0.64255 - acc: 0.6716 -- iter: 0704/1517
[A[ATraining Step: 23  | total loss: [1m[32m0.66075[0m[0m | time: 221.485s
[2K
| Adam | epoch: 001 | loss: 0.66075 - acc: 0.6671 -- iter: 0736/1517
[A[ATraining Step: 24  | total loss: [1m[32m0.67642[0m[0m | time: 230.054s
[2K
| Adam | epoch: 001 | loss: 0.67642 - acc: 0.6289 -- iter: 0768/1517
[A[ATraining Step: 25  | total loss: [1m[32m0.67925[0m[0m | time: 238.372s
[2K
| Adam | epoch: 001 | loss: 0.67925 - acc: 0.6108 -- iter: 0800/1517
[A[ATraining Step: 26  | total loss: [1m[32m0.66769[0m[0m | time: 246.768s
[2K
| Adam | epoch: 001 | loss: 0.66769 - acc: 0.6228 -- iter: 0832/1517
[A[ATraining Step: 27  | total loss: [1m[32m0.67105[0m[0m | time: 255.246s
[2K
| Adam | epoch: 001 | loss: 0.67105 - acc: 0.6234 -- iter: 0864/1517
[A[ATraining Step: 28  | total loss: [1m[32m0.66782[0m[0m | time: 263.678s
[2K
| Adam | epoch: 001 | loss: 0.66782 - acc: 0.6316 -- iter: 0896/1517
[A[ATraining Step: 29  | total loss: [1m[32m0.66657[0m[0m | time: 272.127s
[2K
| Adam | epoch: 001 | loss: 0.66657 - acc: 0.6224 -- iter: 0928/1517
[A[ATraining Step: 30  | total loss: [1m[32m0.63153[0m[0m | time: 280.621s
[2K
| Adam | epoch: 001 | loss: 0.63153 - acc: 0.6526 -- iter: 0960/1517
[A[ATraining Step: 31  | total loss: [1m[32m0.65969[0m[0m | time: 289.074s
[2K
| Adam | epoch: 001 | loss: 0.65969 - acc: 0.6462 -- iter: 0992/1517
[A[ATraining Step: 32  | total loss: [1m[32m0.64904[0m[0m | time: 297.599s
[2K
| Adam | epoch: 001 | loss: 0.64904 - acc: 0.6344 -- iter: 1024/1517
[A[ATraining Step: 33  | total loss: [1m[32m0.63946[0m[0m | time: 306.015s
[2K
| Adam | epoch: 001 | loss: 0.63946 - acc: 0.6598 -- iter: 1056/1517
[A[ATraining Step: 34  | total loss: [1m[32m0.66397[0m[0m | time: 314.542s
[2K
| Adam | epoch: 001 | loss: 0.66397 - acc: 0.6523 -- iter: 1088/1517
[A[ATraining Step: 35  | total loss: [1m[32m0.62513[0m[0m | time: 322.953s
[2K
| Adam | epoch: 001 | loss: 0.62513 - acc: 0.6662 -- iter: 1120/1517
[A[ATraining Step: 36  | total loss: [1m[32m0.63009[0m[0m | time: 331.492s
[2K
| Adam | epoch: 001 | loss: 0.63009 - acc: 0.6322 -- iter: 1152/1517
[A[ATraining Step: 37  | total loss: [1m[32m0.64032[0m[0m | time: 340.008s
[2K
| Adam | epoch: 001 | loss: 0.64032 - acc: 0.6245 -- iter: 1184/1517
[A[ATraining Step: 38  | total loss: [1m[32m0.64791[0m[0m | time: 348.413s
[2K
| Adam | epoch: 001 | loss: 0.64791 - acc: 0.6369 -- iter: 1216/1517
[A[ATraining Step: 39  | total loss: [1m[32m0.63870[0m[0m | time: 356.755s
[2K
| Adam | epoch: 001 | loss: 0.63870 - acc: 0.6346 -- iter: 1248/1517
[A[ATraining Step: 40  | total loss: [1m[32m0.62011[0m[0m | time: 365.063s
[2K
| Adam | epoch: 001 | loss: 0.62011 - acc: 0.6562 -- iter: 1280/1517
[A[ATraining Step: 41  | total loss: [1m[32m0.63510[0m[0m | time: 373.653s
[2K
| Adam | epoch: 001 | loss: 0.63510 - acc: 0.6390 -- iter: 1312/1517
[A[ATraining Step: 42  | total loss: [1m[32m0.63348[0m[0m | time: 382.033s
[2K
| Adam | epoch: 001 | loss: 0.63348 - acc: 0.6365 -- iter: 1344/1517
[A[ATraining Step: 43  | total loss: [1m[32m0.63129[0m[0m | time: 390.546s
[2K
| Adam | epoch: 001 | loss: 0.63129 - acc: 0.6455 -- iter: 1376/1517
[A[ATraining Step: 44  | total loss: [1m[32m0.62369[0m[0m | time: 399.019s
[2K
| Adam | epoch: 001 | loss: 0.62369 - acc: 0.6528 -- iter: 1408/1517
[A[ATraining Step: 45  | total loss: [1m[32m0.64100[0m[0m | time: 407.509s
[2K
| Adam | epoch: 001 | loss: 0.64100 - acc: 0.6321 -- iter: 1440/1517
[A[ATraining Step: 46  | total loss: [1m[32m0.61843[0m[0m | time: 415.903s
[2K
| Adam | epoch: 001 | loss: 0.61843 - acc: 0.6570 -- iter: 1472/1517
[A[ATraining Step: 47  | total loss: [1m[32m0.61729[0m[0m | time: 424.498s
[2K
| Adam | epoch: 001 | loss: 0.61729 - acc: 0.6517 -- iter: 1504/1517
[A[ATraining Step: 48  | total loss: [1m[32m0.63016[0m[0m | time: 454.909s
[2K
| Adam | epoch: 001 | loss: 0.63016 - acc: 0.6274 | val_loss: 0.93360 - val_acc: 0.5347 -- iter: 1517/1517
--
Training Step: 49  | total loss: [1m[32m0.61891[0m[0m | time: 3.823s
[2K
| Adam | epoch: 002 | loss: 0.61891 - acc: 0.6498 -- iter: 0032/1517
[A[ATraining Step: 50  | total loss: [1m[32m0.57919[0m[0m | time: 12.401s
[2K
| Adam | epoch: 002 | loss: 0.57919 - acc: 0.7041 -- iter: 0064/1517
[A[ATraining Step: 51  | total loss: [1m[32m0.58389[0m[0m | time: 20.831s
[2K
| Adam | epoch: 002 | loss: 0.58389 - acc: 0.6873 -- iter: 0096/1517
[A[ATraining Step: 52  | total loss: [1m[32m0.58989[0m[0m | time: 29.260s
[2K
| Adam | epoch: 002 | loss: 0.58989 - acc: 0.6732 -- iter: 0128/1517
[A[ATraining Step: 53  | total loss: [1m[32m0.60289[0m[0m | time: 37.693s
[2K
| Adam | epoch: 002 | loss: 0.60289 - acc: 0.6753 -- iter: 0160/1517
[A[ATraining Step: 54  | total loss: [1m[32m0.62030[0m[0m | time: 46.128s
[2K
| Adam | epoch: 002 | loss: 0.62030 - acc: 0.6635 -- iter: 0192/1517
[A[ATraining Step: 55  | total loss: [1m[32m0.64540[0m[0m | time: 54.686s
[2K
| Adam | epoch: 002 | loss: 0.64540 - acc: 0.6714 -- iter: 0224/1517
[A[ATraining Step: 56  | total loss: [1m[32m0.64127[0m[0m | time: 63.240s
[2K
| Adam | epoch: 002 | loss: 0.64127 - acc: 0.6649 -- iter: 0256/1517
[A[ATraining Step: 57  | total loss: [1m[32m0.63941[0m[0m | time: 71.643s
[2K
| Adam | epoch: 002 | loss: 0.63941 - acc: 0.6637 -- iter: 0288/1517
[A[ATraining Step: 58  | total loss: [1m[32m0.64037[0m[0m | time: 80.040s
[2K
| Adam | epoch: 002 | loss: 0.64037 - acc: 0.6797 -- iter: 0320/1517
[A[ATraining Step: 59  | total loss: [1m[32m0.63817[0m[0m | time: 88.470s
[2K
| Adam | epoch: 002 | loss: 0.63817 - acc: 0.6808 -- iter: 0352/1517
[A[ATraining Step: 60  | total loss: [1m[32m0.63589[0m[0m | time: 97.126s
[2K
| Adam | epoch: 002 | loss: 0.63589 - acc: 0.6899 -- iter: 0384/1517
[A[ATraining Step: 61  | total loss: [1m[32m0.62611[0m[0m | time: 105.634s
[2K
| Adam | epoch: 002 | loss: 0.62611 - acc: 0.6855 -- iter: 0416/1517
[A[ATraining Step: 62  | total loss: [1m[32m0.63056[0m[0m | time: 114.205s
[2K
| Adam | epoch: 002 | loss: 0.63056 - acc: 0.6858 -- iter: 0448/1517
[A[ATraining Step: 63  | total loss: [1m[32m0.62307[0m[0m | time: 122.858s
[2K
| Adam | epoch: 002 | loss: 0.62307 - acc: 0.6860 -- iter: 0480/1517
[A[ATraining Step: 64  | total loss: [1m[32m0.63154[0m[0m | time: 131.410s
[2K
| Adam | epoch: 002 | loss: 0.63154 - acc: 0.6784 -- iter: 0512/1517
[A[ATraining Step: 65  | total loss: [1m[32m0.62321[0m[0m | time: 139.939s
[2K
| Adam | epoch: 002 | loss: 0.62321 - acc: 0.6872 -- iter: 0544/1517
[A[ATraining Step: 66  | total loss: [1m[32m0.61530[0m[0m | time: 148.590s
[2K
| Adam | epoch: 002 | loss: 0.61530 - acc: 0.6986 -- iter: 0576/1517
[A[ATraining Step: 67  | total loss: [1m[32m0.62278[0m[0m | time: 157.242s
[2K
| Adam | epoch: 002 | loss: 0.62278 - acc: 0.6786 -- iter: 0608/1517
[A[ATraining Step: 68  | total loss: [1m[32m0.65029[0m[0m | time: 165.877s
[2K
| Adam | epoch: 002 | loss: 0.65029 - acc: 0.6722 -- iter: 0640/1517
[A[ATraining Step: 69  | total loss: [1m[32m0.63477[0m[0m | time: 174.452s
[2K
| Adam | epoch: 002 | loss: 0.63477 - acc: 0.6813 -- iter: 0672/1517
[A[ATraining Step: 70  | total loss: [1m[32m0.64306[0m[0m | time: 183.096s
[2K
| Adam | epoch: 002 | loss: 0.64306 - acc: 0.6712 -- iter: 0704/1517
[A[ATraining Step: 71  | total loss: [1m[32m0.64496[0m[0m | time: 191.686s
[2K
| Adam | epoch: 002 | loss: 0.64496 - acc: 0.6731 -- iter: 0736/1517
[A[ATraining Step: 72  | total loss: [1m[32m0.63374[0m[0m | time: 200.237s
[2K
| Adam | epoch: 002 | loss: 0.63374 - acc: 0.6782 -- iter: 0768/1517
[A[ATraining Step: 73  | total loss: [1m[32m0.62721[0m[0m | time: 208.910s
[2K
| Adam | epoch: 002 | loss: 0.62721 - acc: 0.6862 -- iter: 0800/1517
[A[ATraining Step: 74  | total loss: [1m[32m0.62414[0m[0m | time: 217.432s
[2K
| Adam | epoch: 002 | loss: 0.62414 - acc: 0.6863 -- iter: 0832/1517
[A[ATraining Step: 75  | total loss: [1m[32m0.63207[0m[0m | time: 225.958s
[2K
| Adam | epoch: 002 | loss: 0.63207 - acc: 0.6661 -- iter: 0864/1517
[A[ATraining Step: 76  | total loss: [1m[32m0.64026[0m[0m | time: 234.734s
[2K
| Adam | epoch: 002 | loss: 0.64026 - acc: 0.6584 -- iter: 0896/1517
[A[ATraining Step: 77  | total loss: [1m[32m0.63020[0m[0m | time: 243.224s
[2K
| Adam | epoch: 002 | loss: 0.63020 - acc: 0.6714 -- iter: 0928/1517
[A[ATraining Step: 78  | total loss: [1m[32m0.62932[0m[0m | time: 251.743s
[2K
| Adam | epoch: 002 | loss: 0.62932 - acc: 0.6763 -- iter: 0960/1517
[A[ATraining Step: 79  | total loss: [1m[32m0.63035[0m[0m | time: 260.284s
[2K
| Adam | epoch: 002 | loss: 0.63035 - acc: 0.6807 -- iter: 0992/1517
[A[ATraining Step: 80  | total loss: [1m[32m0.61658[0m[0m | time: 268.821s
[2K
| Adam | epoch: 002 | loss: 0.61658 - acc: 0.6942 -- iter: 1024/1517
[A[ATraining Step: 81  | total loss: [1m[32m0.60910[0m[0m | time: 277.336s
[2K
| Adam | epoch: 002 | loss: 0.60910 - acc: 0.7062 -- iter: 1056/1517
[A[ATraining Step: 82  | total loss: [1m[32m0.60252[0m[0m | time: 286.001s
[2K
| Adam | epoch: 002 | loss: 0.60252 - acc: 0.7074 -- iter: 1088/1517
[A[ATraining Step: 83  | total loss: [1m[32m0.59440[0m[0m | time: 294.474s
[2K
| Adam | epoch: 002 | loss: 0.59440 - acc: 0.7117 -- iter: 1120/1517
[A[ATraining Step: 84  | total loss: [1m[32m0.59134[0m[0m | time: 302.944s
[2K
| Adam | epoch: 002 | loss: 0.59134 - acc: 0.7155 -- iter: 1152/1517
[A[ATraining Step: 85  | total loss: [1m[32m0.57843[0m[0m | time: 311.487s
[2K
| Adam | epoch: 002 | loss: 0.57843 - acc: 0.7283 -- iter: 1184/1517
[A[ATraining Step: 86  | total loss: [1m[32m0.58826[0m[0m | time: 320.033s
[2K
| Adam | epoch: 002 | loss: 0.58826 - acc: 0.7211 -- iter: 1216/1517
[A[ATraining Step: 87  | total loss: [1m[32m0.61339[0m[0m | time: 328.678s
[2K
| Adam | epoch: 002 | loss: 0.61339 - acc: 0.7021 -- iter: 1248/1517
[A[ATraining Step: 88  | total loss: [1m[32m0.59578[0m[0m | time: 337.383s
[2K
| Adam | epoch: 002 | loss: 0.59578 - acc: 0.7100 -- iter: 1280/1517
[A[ATraining Step: 89  | total loss: [1m[32m0.60125[0m[0m | time: 346.063s
[2K
| Adam | epoch: 002 | loss: 0.60125 - acc: 0.7109 -- iter: 1312/1517
[A[ATraining Step: 90  | total loss: [1m[32m0.61941[0m[0m | time: 354.769s
[2K
| Adam | epoch: 002 | loss: 0.61941 - acc: 0.6961 -- iter: 1344/1517
[A[ATraining Step: 91  | total loss: [1m[32m0.61725[0m[0m | time: 363.422s
[2K
| Adam | epoch: 002 | loss: 0.61725 - acc: 0.6921 -- iter: 1376/1517
[A[ATraining Step: 92  | total loss: [1m[32m0.61986[0m[0m | time: 372.076s
[2K
| Adam | epoch: 002 | loss: 0.61986 - acc: 0.6823 -- iter: 1408/1517
[A[ATraining Step: 93  | total loss: [1m[32m0.62591[0m[0m | time: 380.724s
[2K
| Adam | epoch: 002 | loss: 0.62591 - acc: 0.6703 -- iter: 1440/1517
[A[ATraining Step: 94  | total loss: [1m[32m0.62367[0m[0m | time: 389.599s
[2K
| Adam | epoch: 002 | loss: 0.62367 - acc: 0.6689 -- iter: 1472/1517
[A[ATraining Step: 95  | total loss: [1m[32m0.62104[0m[0m | time: 398.378s
[2K
| Adam | epoch: 002 | loss: 0.62104 - acc: 0.6832 -- iter: 1504/1517
[A[ATraining Step: 96  | total loss: [1m[32m0.61106[0m[0m | time: 427.620s
[2K
| Adam | epoch: 002 | loss: 0.61106 - acc: 0.6930 | val_loss: 0.67418 - val_acc: 0.5579 -- iter: 1517/1517
--
Training Step: 97  | total loss: [1m[32m0.61401[0m[0m | time: 3.859s
[2K
| Adam | epoch: 003 | loss: 0.61401 - acc: 0.6769 -- iter: 0032/1517
[A[ATraining Step: 98  | total loss: [1m[32m0.63089[0m[0m | time: 7.797s
[2K
| Adam | epoch: 003 | loss: 0.63089 - acc: 0.6784 -- iter: 0064/1517
[A[ATraining Step: 99  | total loss: [1m[32m0.62110[0m[0m | time: 16.485s
[2K
| Adam | epoch: 003 | loss: 0.62110 - acc: 0.6952 -- iter: 0096/1517
[A[ATraining Step: 100  | total loss: [1m[32m0.64251[0m[0m | time: 25.048s
[2K
| Adam | epoch: 003 | loss: 0.64251 - acc: 0.6725 -- iter: 0128/1517
[A[ATraining Step: 101  | total loss: [1m[32m0.63715[0m[0m | time: 33.614s
[2K
| Adam | epoch: 003 | loss: 0.63715 - acc: 0.6772 -- iter: 0160/1517
[A[ATraining Step: 102  | total loss: [1m[32m0.62841[0m[0m | time: 42.229s
[2K
| Adam | epoch: 003 | loss: 0.62841 - acc: 0.6813 -- iter: 0192/1517
[A[ATraining Step: 103  | total loss: [1m[32m0.64044[0m[0m | time: 50.789s
[2K
| Adam | epoch: 003 | loss: 0.64044 - acc: 0.6663 -- iter: 0224/1517
[A[ATraining Step: 104  | total loss: [1m[32m0.63117[0m[0m | time: 59.419s
[2K
| Adam | epoch: 003 | loss: 0.63117 - acc: 0.6684 -- iter: 0256/1517
[A[ATraining Step: 105  | total loss: [1m[32m0.62317[0m[0m | time: 67.935s
[2K
| Adam | epoch: 003 | loss: 0.62317 - acc: 0.6672 -- iter: 0288/1517
[A[ATraining Step: 106  | total loss: [1m[32m0.60359[0m[0m | time: 76.534s
[2K
| Adam | epoch: 003 | loss: 0.60359 - acc: 0.6786 -- iter: 0320/1517
[A[ATraining Step: 107  | total loss: [1m[32m0.60279[0m[0m | time: 85.030s
[2K
| Adam | epoch: 003 | loss: 0.60279 - acc: 0.6826 -- iter: 0352/1517
[A[ATraining Step: 108  | total loss: [1m[32m0.60851[0m[0m | time: 93.588s
[2K
| Adam | epoch: 003 | loss: 0.60851 - acc: 0.6831 -- iter: 0384/1517
[A[ATraining Step: 109  | total loss: [1m[32m0.61163[0m[0m | time: 102.196s
[2K
| Adam | epoch: 003 | loss: 0.61163 - acc: 0.6773 -- iter: 0416/1517
[A[ATraining Step: 110  | total loss: [1m[32m0.59994[0m[0m | time: 110.810s
[2K
| Adam | epoch: 003 | loss: 0.59994 - acc: 0.6908 -- iter: 0448/1517
[A[ATraining Step: 111  | total loss: [1m[32m0.59603[0m[0m | time: 119.202s
[2K
| Adam | epoch: 003 | loss: 0.59603 - acc: 0.6874 -- iter: 0480/1517
[A[ATraining Step: 112  | total loss: [1m[32m0.58468[0m[0m | time: 127.757s
[2K
| Adam | epoch: 003 | loss: 0.58468 - acc: 0.6999 -- iter: 0512/1517
[A[ATraining Step: 113  | total loss: [1m[32m0.58106[0m[0m | time: 136.366s
[2K
| Adam | epoch: 003 | loss: 0.58106 - acc: 0.7080 -- iter: 0544/1517
[A[ATraining Step: 114  | total loss: [1m[32m0.56580[0m[0m | time: 144.830s
[2K
| Adam | epoch: 003 | loss: 0.56580 - acc: 0.7216 -- iter: 0576/1517
[A[ATraining Step: 115  | total loss: [1m[32m0.58107[0m[0m | time: 153.613s
[2K
| Adam | epoch: 003 | loss: 0.58107 - acc: 0.7119 -- iter: 0608/1517
[A[ATraining Step: 116  | total loss: [1m[32m0.58670[0m[0m | time: 162.242s
[2K
| Adam | epoch: 003 | loss: 0.58670 - acc: 0.7001 -- iter: 0640/1517
[A[ATraining Step: 117  | total loss: [1m[32m0.60129[0m[0m | time: 170.985s
[2K
| Adam | epoch: 003 | loss: 0.60129 - acc: 0.6926 -- iter: 0672/1517
[A[ATraining Step: 118  | total loss: [1m[32m0.58681[0m[0m | time: 179.695s
[2K
| Adam | epoch: 003 | loss: 0.58681 - acc: 0.7046 -- iter: 0704/1517
[A[ATraining Step: 119  | total loss: [1m[32m0.57273[0m[0m | time: 188.299s
[2K
| Adam | epoch: 003 | loss: 0.57273 - acc: 0.7185 -- iter: 0736/1517
[A[ATraining Step: 120  | total loss: [1m[32m0.56014[0m[0m | time: 196.872s
[2K
| Adam | epoch: 003 | loss: 0.56014 - acc: 0.7185 -- iter: 0768/1517
[A[ATraining Step: 121  | total loss: [1m[32m0.55009[0m[0m | time: 205.473s
[2K
| Adam | epoch: 003 | loss: 0.55009 - acc: 0.7217 -- iter: 0800/1517
[A[ATraining Step: 122  | total loss: [1m[32m0.52763[0m[0m | time: 214.063s
[2K
| Adam | epoch: 003 | loss: 0.52763 - acc: 0.7370 -- iter: 0832/1517
[A[ATraining Step: 123  | total loss: [1m[32m0.53064[0m[0m | time: 222.862s
[2K
| Adam | epoch: 003 | loss: 0.53064 - acc: 0.7352 -- iter: 0864/1517
[A[ATraining Step: 124  | total loss: [1m[32m0.51827[0m[0m | time: 231.403s
[2K
| Adam | epoch: 003 | loss: 0.51827 - acc: 0.7367 -- iter: 0896/1517
[A[ATraining Step: 125  | total loss: [1m[32m0.53401[0m[0m | time: 240.061s
[2K
| Adam | epoch: 003 | loss: 0.53401 - acc: 0.7349 -- iter: 0928/1517
[A[ATraining Step: 126  | total loss: [1m[32m0.53836[0m[0m | time: 248.647s
[2K
| Adam | epoch: 003 | loss: 0.53836 - acc: 0.7333 -- iter: 0960/1517
[A[ATraining Step: 127  | total loss: [1m[32m0.50965[0m[0m | time: 257.318s
[2K
| Adam | epoch: 003 | loss: 0.50965 - acc: 0.7537 -- iter: 0992/1517
[A[ATraining Step: 128  | total loss: [1m[32m0.50587[0m[0m | time: 265.927s
[2K
| Adam | epoch: 003 | loss: 0.50587 - acc: 0.7471 -- iter: 1024/1517
[A[ATraining Step: 129  | total loss: [1m[32m0.50908[0m[0m | time: 274.567s
[2K
| Adam | epoch: 003 | loss: 0.50908 - acc: 0.7474 -- iter: 1056/1517
[A[ATraining Step: 130  | total loss: [1m[32m0.48819[0m[0m | time: 283.096s
[2K
| Adam | epoch: 003 | loss: 0.48819 - acc: 0.7601 -- iter: 1088/1517
[A[ATraining Step: 131  | total loss: [1m[32m0.51199[0m[0m | time: 291.691s
[2K
| Adam | epoch: 003 | loss: 0.51199 - acc: 0.7466 -- iter: 1120/1517
[A[ATraining Step: 132  | total loss: [1m[32m0.53194[0m[0m | time: 300.324s
[2K
| Adam | epoch: 003 | loss: 0.53194 - acc: 0.7438 -- iter: 1152/1517
[A[ATraining Step: 133  | total loss: [1m[32m0.56828[0m[0m | time: 308.894s
[2K
| Adam | epoch: 003 | loss: 0.56828 - acc: 0.7319 -- iter: 1184/1517
[A[ATraining Step: 134  | total loss: [1m[32m0.58133[0m[0m | time: 317.545s
[2K
| Adam | epoch: 003 | loss: 0.58133 - acc: 0.7306 -- iter: 1216/1517
[A[ATraining Step: 135  | total loss: [1m[32m0.59525[0m[0m | time: 326.195s
[2K
| Adam | epoch: 003 | loss: 0.59525 - acc: 0.7232 -- iter: 1248/1517
[A[ATraining Step: 136  | total loss: [1m[32m0.58744[0m[0m | time: 334.731s
[2K
| Adam | epoch: 003 | loss: 0.58744 - acc: 0.7196 -- iter: 1280/1517
[A[ATraining Step: 137  | total loss: [1m[32m0.57052[0m[0m | time: 343.172s
[2K
| Adam | epoch: 003 | loss: 0.57052 - acc: 0.7320 -- iter: 1312/1517
[A[ATraining Step: 138  | total loss: [1m[32m0.56077[0m[0m | time: 351.806s
[2K
| Adam | epoch: 003 | loss: 0.56077 - acc: 0.7432 -- iter: 1344/1517
[A[ATraining Step: 139  | total loss: [1m[32m0.56085[0m[0m | time: 360.441s
[2K
| Adam | epoch: 003 | loss: 0.56085 - acc: 0.7376 -- iter: 1376/1517
[A[ATraining Step: 140  | total loss: [1m[32m0.56003[0m[0m | time: 368.966s
[2K
| Adam | epoch: 003 | loss: 0.56003 - acc: 0.7295 -- iter: 1408/1517
[A[ATraining Step: 141  | total loss: [1m[32m0.55658[0m[0m | time: 377.596s
[2K
| Adam | epoch: 003 | loss: 0.55658 - acc: 0.7284 -- iter: 1440/1517
[A[ATraining Step: 142  | total loss: [1m[32m0.57284[0m[0m | time: 386.059s
[2K
| Adam | epoch: 003 | loss: 0.57284 - acc: 0.7150 -- iter: 1472/1517
[A[ATraining Step: 143  | total loss: [1m[32m0.57221[0m[0m | time: 394.883s
[2K
| Adam | epoch: 003 | loss: 0.57221 - acc: 0.7216 -- iter: 1504/1517
[A[ATraining Step: 144  | total loss: [1m[32m0.56819[0m[0m | time: 424.107s
[2K
| Adam | epoch: 003 | loss: 0.56819 - acc: 0.7244 | val_loss: 0.66076 - val_acc: 0.6842 -- iter: 1517/1517
--
Training Step: 145  | total loss: [1m[32m0.56466[0m[0m | time: 8.524s
[2K
| Adam | epoch: 004 | loss: 0.56466 - acc: 0.7176 -- iter: 0032/1517
[A[ATraining Step: 146  | total loss: [1m[32m0.55682[0m[0m | time: 12.515s
[2K
| Adam | epoch: 004 | loss: 0.55682 - acc: 0.7240 -- iter: 0064/1517
[A[ATraining Step: 147  | total loss: [1m[32m0.57092[0m[0m | time: 16.377s
[2K
| Adam | epoch: 004 | loss: 0.57092 - acc: 0.7131 -- iter: 0096/1517
[A[ATraining Step: 148  | total loss: [1m[32m0.56397[0m[0m | time: 24.950s
[2K
| Adam | epoch: 004 | loss: 0.56397 - acc: 0.7187 -- iter: 0128/1517
[A[ATraining Step: 149  | total loss: [1m[32m0.56357[0m[0m | time: 33.416s
[2K
| Adam | epoch: 004 | loss: 0.56357 - acc: 0.7125 -- iter: 0160/1517
[A[ATraining Step: 150  | total loss: [1m[32m0.56287[0m[0m | time: 41.953s
[2K
| Adam | epoch: 004 | loss: 0.56287 - acc: 0.7069 -- iter: 0192/1517
[A[ATraining Step: 151  | total loss: [1m[32m0.57749[0m[0m | time: 50.465s
[2K
| Adam | epoch: 004 | loss: 0.57749 - acc: 0.6955 -- iter: 0224/1517
[A[ATraining Step: 152  | total loss: [1m[32m0.56712[0m[0m | time: 59.266s
[2K
| Adam | epoch: 004 | loss: 0.56712 - acc: 0.7041 -- iter: 0256/1517
[A[ATraining Step: 153  | total loss: [1m[32m0.56581[0m[0m | time: 67.799s
[2K
| Adam | epoch: 004 | loss: 0.56581 - acc: 0.7056 -- iter: 0288/1517
[A[ATraining Step: 154  | total loss: [1m[32m0.56846[0m[0m | time: 76.502s
[2K
| Adam | epoch: 004 | loss: 0.56846 - acc: 0.7069 -- iter: 0320/1517
[A[ATraining Step: 155  | total loss: [1m[32m0.57851[0m[0m | time: 85.187s
[2K
| Adam | epoch: 004 | loss: 0.57851 - acc: 0.7081 -- iter: 0352/1517
[A[ATraining Step: 156  | total loss: [1m[32m0.58122[0m[0m | time: 93.914s
[2K
| Adam | epoch: 004 | loss: 0.58122 - acc: 0.6998 -- iter: 0384/1517
[A[ATraining Step: 157  | total loss: [1m[32m0.57724[0m[0m | time: 102.423s
[2K
| Adam | epoch: 004 | loss: 0.57724 - acc: 0.7017 -- iter: 0416/1517
[A[ATraining Step: 158  | total loss: [1m[32m0.56744[0m[0m | time: 110.840s
[2K
| Adam | epoch: 004 | loss: 0.56744 - acc: 0.7190 -- iter: 0448/1517
[A[ATraining Step: 159  | total loss: [1m[32m0.56454[0m[0m | time: 119.315s
[2K
| Adam | epoch: 004 | loss: 0.56454 - acc: 0.7252 -- iter: 0480/1517
[A[ATraining Step: 160  | total loss: [1m[32m0.55093[0m[0m | time: 127.817s
[2K
| Adam | epoch: 004 | loss: 0.55093 - acc: 0.7402 -- iter: 0512/1517
[A[ATraining Step: 161  | total loss: [1m[32m0.54193[0m[0m | time: 136.463s
[2K
| Adam | epoch: 004 | loss: 0.54193 - acc: 0.7381 -- iter: 0544/1517
[A[ATraining Step: 162  | total loss: [1m[32m0.54319[0m[0m | time: 145.091s
[2K
| Adam | epoch: 004 | loss: 0.54319 - acc: 0.7330 -- iter: 0576/1517
[A[ATraining Step: 163  | total loss: [1m[32m0.54201[0m[0m | time: 153.539s
[2K
| Adam | epoch: 004 | loss: 0.54201 - acc: 0.7378 -- iter: 0608/1517
[A[ATraining Step: 164  | total loss: [1m[32m0.55017[0m[0m | time: 161.987s
[2K
| Adam | epoch: 004 | loss: 0.55017 - acc: 0.7359 -- iter: 0640/1517
[A[ATraining Step: 165  | total loss: [1m[32m0.52943[0m[0m | time: 170.553s
[2K
| Adam | epoch: 004 | loss: 0.52943 - acc: 0.7530 -- iter: 0672/1517
[A[ATraining Step: 166  | total loss: [1m[32m0.52159[0m[0m | time: 179.093s
[2K
| Adam | epoch: 004 | loss: 0.52159 - acc: 0.7558 -- iter: 0704/1517
[A[ATraining Step: 167  | total loss: [1m[32m0.50205[0m[0m | time: 187.732s
[2K
| Adam | epoch: 004 | loss: 0.50205 - acc: 0.7740 -- iter: 0736/1517
[A[ATraining Step: 168  | total loss: [1m[32m0.49553[0m[0m | time: 196.397s
[2K
| Adam | epoch: 004 | loss: 0.49553 - acc: 0.7747 -- iter: 0768/1517
[A[ATraining Step: 169  | total loss: [1m[32m0.49360[0m[0m | time: 204.978s
[2K
| Adam | epoch: 004 | loss: 0.49360 - acc: 0.7722 -- iter: 0800/1517
[A[ATraining Step: 170  | total loss: [1m[32m0.48686[0m[0m | time: 213.524s
[2K
| Adam | epoch: 004 | loss: 0.48686 - acc: 0.7825 -- iter: 0832/1517
[A[ATraining Step: 171  | total loss: [1m[32m0.47279[0m[0m | time: 221.962s
[2K
| Adam | epoch: 004 | loss: 0.47279 - acc: 0.7886 -- iter: 0864/1517
[A[ATraining Step: 172  | total loss: [1m[32m0.46126[0m[0m | time: 230.474s
[2K
| Adam | epoch: 004 | loss: 0.46126 - acc: 0.7848 -- iter: 0896/1517
[A[ATraining Step: 173  | total loss: [1m[32m0.45468[0m[0m | time: 238.997s
[2K
| Adam | epoch: 004 | loss: 0.45468 - acc: 0.7907 -- iter: 0928/1517
[A[ATraining Step: 174  | total loss: [1m[32m0.44399[0m[0m | time: 247.557s
[2K
| Adam | epoch: 004 | loss: 0.44399 - acc: 0.7960 -- iter: 0960/1517
[A[ATraining Step: 175  | total loss: [1m[32m0.44909[0m[0m | time: 255.965s
[2K
| Adam | epoch: 004 | loss: 0.44909 - acc: 0.7976 -- iter: 0992/1517
[A[ATraining Step: 176  | total loss: [1m[32m0.46035[0m[0m | time: 264.334s
[2K
| Adam | epoch: 004 | loss: 0.46035 - acc: 0.7866 -- iter: 1024/1517
[A[ATraining Step: 177  | total loss: [1m[32m0.46971[0m[0m | time: 272.700s
[2K
| Adam | epoch: 004 | loss: 0.46971 - acc: 0.7829 -- iter: 1056/1517
[A[ATraining Step: 178  | total loss: [1m[32m0.45971[0m[0m | time: 281.278s
[2K
| Adam | epoch: 004 | loss: 0.45971 - acc: 0.7890 -- iter: 1088/1517
[A[ATraining Step: 179  | total loss: [1m[32m0.45304[0m[0m | time: 289.676s
[2K
| Adam | epoch: 004 | loss: 0.45304 - acc: 0.7945 -- iter: 1120/1517
[A[ATraining Step: 180  | total loss: [1m[32m0.43905[0m[0m | time: 298.390s
[2K
| Adam | epoch: 004 | loss: 0.43905 - acc: 0.8025 -- iter: 1152/1517
[A[ATraining Step: 181  | total loss: [1m[32m0.45551[0m[0m | time: 306.893s
[2K
| Adam | epoch: 004 | loss: 0.45551 - acc: 0.7879 -- iter: 1184/1517
[A[ATraining Step: 182  | total loss: [1m[32m0.47778[0m[0m | time: 315.360s
[2K
| Adam | epoch: 004 | loss: 0.47778 - acc: 0.7841 -- iter: 1216/1517
[A[ATraining Step: 183  | total loss: [1m[32m0.46192[0m[0m | time: 323.826s
[2K
| Adam | epoch: 004 | loss: 0.46192 - acc: 0.7901 -- iter: 1248/1517
[A[ATraining Step: 184  | total loss: [1m[32m0.45999[0m[0m | time: 332.323s
[2K
| Adam | epoch: 004 | loss: 0.45999 - acc: 0.7955 -- iter: 1280/1517
[A[ATraining Step: 185  | total loss: [1m[32m0.47431[0m[0m | time: 340.833s
[2K
| Adam | epoch: 004 | loss: 0.47431 - acc: 0.7847 -- iter: 1312/1517
[A[ATraining Step: 186  | total loss: [1m[32m0.47558[0m[0m | time: 349.263s
[2K
| Adam | epoch: 004 | loss: 0.47558 - acc: 0.7874 -- iter: 1344/1517
[A[ATraining Step: 187  | total loss: [1m[32m0.48538[0m[0m | time: 357.780s
[2K
| Adam | epoch: 004 | loss: 0.48538 - acc: 0.7743 -- iter: 1376/1517
[A[ATraining Step: 188  | total loss: [1m[32m0.51414[0m[0m | time: 366.201s
[2K
| Adam | epoch: 004 | loss: 0.51414 - acc: 0.7625 -- iter: 1408/1517
[A[ATraining Step: 189  | total loss: [1m[32m0.52245[0m[0m | time: 374.748s
[2K
| Adam | epoch: 004 | loss: 0.52245 - acc: 0.7519 -- iter: 1440/1517
[A[ATraining Step: 190  | total loss: [1m[32m0.51135[0m[0m | time: 383.122s
[2K
| Adam | epoch: 004 | loss: 0.51135 - acc: 0.7580 -- iter: 1472/1517
[A[ATraining Step: 191  | total loss: [1m[32m0.50892[0m[0m | time: 391.667s
[2K
| Adam | epoch: 004 | loss: 0.50892 - acc: 0.7634 -- iter: 1504/1517
[A[ATraining Step: 192  | total loss: [1m[32m0.50075[0m[0m | time: 421.116s
[2K
| Adam | epoch: 004 | loss: 0.50075 - acc: 0.7683 | val_loss: 3.37330 - val_acc: 0.4989 -- iter: 1517/1517
--
Training Step: 193  | total loss: [1m[32m0.50035[0m[0m | time: 8.552s
[2K
| Adam | epoch: 005 | loss: 0.50035 - acc: 0.7602 -- iter: 0032/1517
[A[ATraining Step: 194  | total loss: [1m[32m0.50009[0m[0m | time: 17.217s
[2K
| Adam | epoch: 005 | loss: 0.50009 - acc: 0.7498 -- iter: 0064/1517
[A[ATraining Step: 195  | total loss: [1m[32m0.48511[0m[0m | time: 21.010s
[2K
| Adam | epoch: 005 | loss: 0.48511 - acc: 0.7592 -- iter: 0096/1517
[A[ATraining Step: 196  | total loss: [1m[32m0.50262[0m[0m | time: 24.969s
[2K
| Adam | epoch: 005 | loss: 0.50262 - acc: 0.7525 -- iter: 0128/1517
[A[ATraining Step: 197  | total loss: [1m[32m0.50068[0m[0m | time: 33.625s
[2K
| Adam | epoch: 005 | loss: 0.50068 - acc: 0.7465 -- iter: 0160/1517
[A[ATraining Step: 198  | total loss: [1m[32m0.50565[0m[0m | time: 42.223s
[2K
| Adam | epoch: 005 | loss: 0.50565 - acc: 0.7469 -- iter: 0192/1517
[A[ATraining Step: 199  | total loss: [1m[32m0.52302[0m[0m | time: 50.819s
[2K
| Adam | epoch: 005 | loss: 0.52302 - acc: 0.7316 -- iter: 0224/1517
[A[ATraining Step: 200  | total loss: [1m[32m0.52417[0m[0m | time: 80.056s
[2K
| Adam | epoch: 005 | loss: 0.52417 - acc: 0.7365 | val_loss: 1.93805 - val_acc: 0.5305 -- iter: 0256/1517
--
Training Step: 201  | total loss: [1m[32m0.51709[0m[0m | time: 88.567s
[2K
| Adam | epoch: 005 | loss: 0.51709 - acc: 0.7410 -- iter: 0288/1517
[A[ATraining Step: 202  | total loss: [1m[32m0.51981[0m[0m | time: 97.032s
[2K
| Adam | epoch: 005 | loss: 0.51981 - acc: 0.7356 -- iter: 0320/1517
[A[ATraining Step: 203  | total loss: [1m[32m0.52740[0m[0m | time: 105.415s
[2K
| Adam | epoch: 005 | loss: 0.52740 - acc: 0.7340 -- iter: 0352/1517
[A[ATraining Step: 204  | total loss: [1m[32m0.53417[0m[0m | time: 113.907s
[2K
| Adam | epoch: 005 | loss: 0.53417 - acc: 0.7324 -- iter: 0384/1517
[A[ATraining Step: 205  | total loss: [1m[32m0.56509[0m[0m | time: 122.284s
[2K
| Adam | epoch: 005 | loss: 0.56509 - acc: 0.7217 -- iter: 0416/1517
[A[ATraining Step: 206  | total loss: [1m[32m0.57830[0m[0m | time: 130.641s
[2K
| Adam | epoch: 005 | loss: 0.57830 - acc: 0.7089 -- iter: 0448/1517
[A[ATraining Step: 207  | total loss: [1m[32m0.58097[0m[0m | time: 139.260s
[2K
| Adam | epoch: 005 | loss: 0.58097 - acc: 0.7099 -- iter: 0480/1517
[A[ATraining Step: 208  | total loss: [1m[32m0.56593[0m[0m | time: 147.814s
[2K
| Adam | epoch: 005 | loss: 0.56593 - acc: 0.7201 -- iter: 0512/1517
[A[ATraining Step: 209  | total loss: [1m[32m0.56539[0m[0m | time: 156.423s
[2K
| Adam | epoch: 005 | loss: 0.56539 - acc: 0.7200 -- iter: 0544/1517
[A[ATraining Step: 210  | total loss: [1m[32m0.56621[0m[0m | time: 164.829s
[2K
| Adam | epoch: 005 | loss: 0.56621 - acc: 0.7230 -- iter: 0576/1517
[A[ATraining Step: 211  | total loss: [1m[32m0.56310[0m[0m | time: 173.506s
[2K
| Adam | epoch: 005 | loss: 0.56310 - acc: 0.7288 -- iter: 0608/1517
[A[ATraining Step: 212  | total loss: [1m[32m0.57700[0m[0m | time: 182.128s
[2K
| Adam | epoch: 005 | loss: 0.57700 - acc: 0.7341 -- iter: 0640/1517
[A[ATraining Step: 213  | total loss: [1m[32m0.56755[0m[0m | time: 190.766s
[2K
| Adam | epoch: 005 | loss: 0.56755 - acc: 0.7325 -- iter: 0672/1517
[A[ATraining Step: 214  | total loss: [1m[32m0.55518[0m[0m | time: 199.393s
[2K
| Adam | epoch: 005 | loss: 0.55518 - acc: 0.7437 -- iter: 0704/1517
[A[ATraining Step: 215  | total loss: [1m[32m0.54102[0m[0m | time: 207.842s
[2K
| Adam | epoch: 005 | loss: 0.54102 - acc: 0.7537 -- iter: 0736/1517
[A[ATraining Step: 216  | total loss: [1m[32m0.52882[0m[0m | time: 216.383s
[2K
| Adam | epoch: 005 | loss: 0.52882 - acc: 0.7596 -- iter: 0768/1517
[A[ATraining Step: 217  | total loss: [1m[32m0.51520[0m[0m | time: 224.971s
[2K
| Adam | epoch: 005 | loss: 0.51520 - acc: 0.7680 -- iter: 0800/1517
[A[ATraining Step: 218  | total loss: [1m[32m0.49622[0m[0m | time: 233.524s
[2K
| Adam | epoch: 005 | loss: 0.49622 - acc: 0.7818 -- iter: 0832/1517
[A[ATraining Step: 219  | total loss: [1m[32m0.48027[0m[0m | time: 241.907s
[2K
| Adam | epoch: 005 | loss: 0.48027 - acc: 0.7911 -- iter: 0864/1517
[A[ATraining Step: 220  | total loss: [1m[32m0.46096[0m[0m | time: 250.469s
[2K
| Adam | epoch: 005 | loss: 0.46096 - acc: 0.8026 -- iter: 0896/1517
[A[ATraining Step: 221  | total loss: [1m[32m0.45282[0m[0m | time: 259.016s
[2K
| Adam | epoch: 005 | loss: 0.45282 - acc: 0.8005 -- iter: 0928/1517
[A[ATraining Step: 222  | total loss: [1m[32m0.43657[0m[0m | time: 267.346s
[2K
| Adam | epoch: 005 | loss: 0.43657 - acc: 0.8111 -- iter: 0960/1517
[A[ATraining Step: 223  | total loss: [1m[32m0.43607[0m[0m | time: 275.919s
[2K
| Adam | epoch: 005 | loss: 0.43607 - acc: 0.8081 -- iter: 0992/1517
[A[ATraining Step: 224  | total loss: [1m[32m0.42933[0m[0m | time: 284.464s
[2K
| Adam | epoch: 005 | loss: 0.42933 - acc: 0.8117 -- iter: 1024/1517
[A[ATraining Step: 225  | total loss: [1m[32m0.43572[0m[0m | time: 293.125s
[2K
| Adam | epoch: 005 | loss: 0.43572 - acc: 0.8180 -- iter: 1056/1517
[A[ATraining Step: 226  | total loss: [1m[32m0.41864[0m[0m | time: 301.609s
[2K
| Adam | epoch: 005 | loss: 0.41864 - acc: 0.8237 -- iter: 1088/1517
[A[ATraining Step: 227  | total loss: [1m[32m0.39997[0m[0m | time: 310.348s
[2K
| Adam | epoch: 005 | loss: 0.39997 - acc: 0.8319 -- iter: 1120/1517
[A[ATraining Step: 228  | total loss: [1m[32m0.40512[0m[0m | time: 318.989s
[2K
| Adam | epoch: 005 | loss: 0.40512 - acc: 0.8269 -- iter: 1152/1517
[A[ATraining Step: 229  | total loss: [1m[32m0.39752[0m[0m | time: 327.477s
[2K
| Adam | epoch: 005 | loss: 0.39752 - acc: 0.8286 -- iter: 1184/1517
[A[ATraining Step: 230  | total loss: [1m[32m0.41614[0m[0m | time: 336.139s
[2K
| Adam | epoch: 005 | loss: 0.41614 - acc: 0.8238 -- iter: 1216/1517
[A[ATraining Step: 231  | total loss: [1m[32m0.41996[0m[0m | time: 344.763s
[2K
| Adam | epoch: 005 | loss: 0.41996 - acc: 0.8196 -- iter: 1248/1517
[A[ATraining Step: 232  | total loss: [1m[32m0.41466[0m[0m | time: 353.523s
[2K
| Adam | epoch: 005 | loss: 0.41466 - acc: 0.8189 -- iter: 1280/1517
[A[ATraining Step: 233  | total loss: [1m[32m0.41492[0m[0m | time: 362.176s
[2K
| Adam | epoch: 005 | loss: 0.41492 - acc: 0.8151 -- iter: 1312/1517
[A[ATraining Step: 234  | total loss: [1m[32m0.41737[0m[0m | time: 370.823s
[2K
| Adam | epoch: 005 | loss: 0.41737 - acc: 0.8180 -- iter: 1344/1517
[A[ATraining Step: 235  | total loss: [1m[32m0.41312[0m[0m | time: 379.543s
[2K
| Adam | epoch: 005 | loss: 0.41312 - acc: 0.8174 -- iter: 1376/1517
[A[ATraining Step: 236  | total loss: [1m[32m0.41953[0m[0m | time: 388.261s
[2K
| Adam | epoch: 005 | loss: 0.41953 - acc: 0.8107 -- iter: 1408/1517
[A[ATraining Step: 237  | total loss: [1m[32m0.42286[0m[0m | time: 396.873s
[2K
| Adam | epoch: 005 | loss: 0.42286 - acc: 0.8171 -- iter: 1440/1517
[A[ATraining Step: 238  | total loss: [1m[32m0.43036[0m[0m | time: 405.477s
[2K
| Adam | epoch: 005 | loss: 0.43036 - acc: 0.8104 -- iter: 1472/1517
[A[ATraining Step: 239  | total loss: [1m[32m0.44249[0m[0m | time: 414.140s
[2K
| Adam | epoch: 005 | loss: 0.44249 - acc: 0.7950 -- iter: 1504/1517
[A[ATraining Step: 240  | total loss: [1m[32m0.43064[0m[0m | time: 443.938s
[2K
| Adam | epoch: 005 | loss: 0.43064 - acc: 0.8061 | val_loss: 0.99962 - val_acc: 0.6442 -- iter: 1517/1517
--
Training Step: 241  | total loss: [1m[32m0.43697[0m[0m | time: 8.559s
[2K
| Adam | epoch: 006 | loss: 0.43697 - acc: 0.7974 -- iter: 0032/1517
[A[ATraining Step: 242  | total loss: [1m[32m0.43153[0m[0m | time: 16.965s
[2K
| Adam | epoch: 006 | loss: 0.43153 - acc: 0.7989 -- iter: 0064/1517
[A[ATraining Step: 243  | total loss: [1m[32m0.43015[0m[0m | time: 25.467s
[2K
| Adam | epoch: 006 | loss: 0.43015 - acc: 0.8002 -- iter: 0096/1517
[A[ATraining Step: 244  | total loss: [1m[32m0.44194[0m[0m | time: 29.282s
[2K
| Adam | epoch: 006 | loss: 0.44194 - acc: 0.7983 -- iter: 0128/1517
[A[ATraining Step: 245  | total loss: [1m[32m0.46064[0m[0m | time: 33.176s
[2K
| Adam | epoch: 006 | loss: 0.46064 - acc: 0.7877 -- iter: 0160/1517
[A[ATraining Step: 246  | total loss: [1m[32m0.46296[0m[0m | time: 41.454s
[2K
| Adam | epoch: 006 | loss: 0.46296 - acc: 0.7859 -- iter: 0192/1517
[A[ATraining Step: 247  | total loss: [1m[32m0.46213[0m[0m | time: 50.040s
[2K
| Adam | epoch: 006 | loss: 0.46213 - acc: 0.7823 -- iter: 0224/1517
[A[ATraining Step: 248  | total loss: [1m[32m0.45804[0m[0m | time: 58.374s
[2K
| Adam | epoch: 006 | loss: 0.45804 - acc: 0.7822 -- iter: 0256/1517
[A[ATraining Step: 249  | total loss: [1m[32m0.45730[0m[0m | time: 66.949s
[2K
| Adam | epoch: 006 | loss: 0.45730 - acc: 0.7821 -- iter: 0288/1517
[A[ATraining Step: 250  | total loss: [1m[32m0.44741[0m[0m | time: 75.280s
[2K
| Adam | epoch: 006 | loss: 0.44741 - acc: 0.7851 -- iter: 0320/1517
[A[ATraining Step: 251  | total loss: [1m[32m0.45720[0m[0m | time: 83.734s
[2K
| Adam | epoch: 006 | loss: 0.45720 - acc: 0.7785 -- iter: 0352/1517
[A[ATraining Step: 252  | total loss: [1m[32m0.45807[0m[0m | time: 92.167s
[2K
| Adam | epoch: 006 | loss: 0.45807 - acc: 0.7757 -- iter: 0384/1517
[A[ATraining Step: 253  | total loss: [1m[32m0.49426[0m[0m | time: 100.906s
[2K
| Adam | epoch: 006 | loss: 0.49426 - acc: 0.7481 -- iter: 0416/1517
[A[ATraining Step: 254  | total loss: [1m[32m0.49367[0m[0m | time: 109.289s
[2K
| Adam | epoch: 006 | loss: 0.49367 - acc: 0.7452 -- iter: 0448/1517
[A[ATraining Step: 255  | total loss: [1m[32m0.49100[0m[0m | time: 117.741s
[2K
| Adam | epoch: 006 | loss: 0.49100 - acc: 0.7488 -- iter: 0480/1517
[A[ATraining Step: 256  | total loss: [1m[32m0.47278[0m[0m | time: 126.213s
[2K
| Adam | epoch: 006 | loss: 0.47278 - acc: 0.7676 -- iter: 0512/1517
[A[ATraining Step: 257  | total loss: [1m[32m0.47851[0m[0m | time: 134.667s
[2K
| Adam | epoch: 006 | loss: 0.47851 - acc: 0.7659 -- iter: 0544/1517
[A[ATraining Step: 258  | total loss: [1m[32m0.48456[0m[0m | time: 143.165s
[2K
| Adam | epoch: 006 | loss: 0.48456 - acc: 0.7580 -- iter: 0576/1517
[A[ATraining Step: 259  | total loss: [1m[32m0.51311[0m[0m | time: 151.420s
[2K
| Adam | epoch: 006 | loss: 0.51311 - acc: 0.7479 -- iter: 0608/1517
[A[ATraining Step: 260  | total loss: [1m[32m0.50721[0m[0m | time: 159.815s
[2K
| Adam | epoch: 006 | loss: 0.50721 - acc: 0.7512 -- iter: 0640/1517
[A[ATraining Step: 261  | total loss: [1m[32m0.51762[0m[0m | time: 168.368s
[2K
| Adam | epoch: 006 | loss: 0.51762 - acc: 0.7386 -- iter: 0672/1517
[A[ATraining Step: 262  | total loss: [1m[32m0.50490[0m[0m | time: 176.878s
[2K
| Adam | epoch: 006 | loss: 0.50490 - acc: 0.7553 -- iter: 0704/1517
[A[ATraining Step: 263  | total loss: [1m[32m0.49114[0m[0m | time: 185.423s
[2K
| Adam | epoch: 006 | loss: 0.49114 - acc: 0.7673 -- iter: 0736/1517
[A[ATraining Step: 264  | total loss: [1m[32m0.46907[0m[0m | time: 193.892s
[2K
| Adam | epoch: 006 | loss: 0.46907 - acc: 0.7843 -- iter: 0768/1517
[A[ATraining Step: 265  | total loss: [1m[32m0.46020[0m[0m | time: 202.533s
[2K
| Adam | epoch: 006 | loss: 0.46020 - acc: 0.7965 -- iter: 0800/1517
[A[ATraining Step: 266  | total loss: [1m[32m0.45379[0m[0m | time: 211.126s
[2K
| Adam | epoch: 006 | loss: 0.45379 - acc: 0.7981 -- iter: 0832/1517
[A[ATraining Step: 267  | total loss: [1m[32m0.43154[0m[0m | time: 219.661s
[2K
| Adam | epoch: 006 | loss: 0.43154 - acc: 0.8121 -- iter: 0864/1517
[A[ATraining Step: 268  | total loss: [1m[32m0.44533[0m[0m | time: 228.242s
[2K
| Adam | epoch: 006 | loss: 0.44533 - acc: 0.7996 -- iter: 0896/1517
[A[ATraining Step: 269  | total loss: [1m[32m0.44001[0m[0m | time: 236.868s
[2K
| Adam | epoch: 006 | loss: 0.44001 - acc: 0.8071 -- iter: 0928/1517
[A[ATraining Step: 270  | total loss: [1m[32m0.42317[0m[0m | time: 245.410s
[2K
| Adam | epoch: 006 | loss: 0.42317 - acc: 0.8171 -- iter: 0960/1517
[A[ATraining Step: 271  | total loss: [1m[32m0.42890[0m[0m | time: 254.129s
[2K
| Adam | epoch: 006 | loss: 0.42890 - acc: 0.8103 -- iter: 0992/1517
[A[ATraining Step: 272  | total loss: [1m[32m0.44093[0m[0m | time: 262.711s
[2K
| Adam | epoch: 006 | loss: 0.44093 - acc: 0.8106 -- iter: 1024/1517
[A[ATraining Step: 273  | total loss: [1m[32m0.43045[0m[0m | time: 271.431s
[2K
| Adam | epoch: 006 | loss: 0.43045 - acc: 0.8170 -- iter: 1056/1517
[A[ATraining Step: 274  | total loss: [1m[32m0.41826[0m[0m | time: 282.029s
[2K
| Adam | epoch: 006 | loss: 0.41826 - acc: 0.8197 -- iter: 1088/1517
[A[ATraining Step: 275  | total loss: [1m[32m0.42245[0m[0m | time: 292.974s
[2K
| Adam | epoch: 006 | loss: 0.42245 - acc: 0.8127 -- iter: 1120/1517
[A[ATraining Step: 276  | total loss: [1m[32m0.42084[0m[0m | time: 304.026s
[2K
| Adam | epoch: 006 | loss: 0.42084 - acc: 0.8096 -- iter: 1152/1517
[A[ATraining Step: 277  | total loss: [1m[32m0.41941[0m[0m | time: 315.072s
[2K
| Adam | epoch: 006 | loss: 0.41941 - acc: 0.8099 -- iter: 1184/1517
[A[ATraining Step: 278  | total loss: [1m[32m0.40227[0m[0m | time: 325.927s
[2K
| Adam | epoch: 006 | loss: 0.40227 - acc: 0.8164 -- iter: 1216/1517
[A[ATraining Step: 279  | total loss: [1m[32m0.40826[0m[0m | time: 336.531s
[2K
| Adam | epoch: 006 | loss: 0.40826 - acc: 0.8097 -- iter: 1248/1517
[A[ATraining Step: 280  | total loss: [1m[32m0.39273[0m[0m | time: 348.602s
[2K
| Adam | epoch: 006 | loss: 0.39273 - acc: 0.8225 -- iter: 1280/1517
[A[ATraining Step: 281  | total loss: [1m[32m0.37752[0m[0m | time: 359.651s
[2K
| Adam | epoch: 006 | loss: 0.37752 - acc: 0.8309 -- iter: 1312/1517
[A[ATraining Step: 282  | total loss: [1m[32m0.40977[0m[0m | time: 371.000s
[2K
| Adam | epoch: 006 | loss: 0.40977 - acc: 0.8072 -- iter: 1344/1517
[A[ATraining Step: 283  | total loss: [1m[32m0.39554[0m[0m | time: 382.572s
[2K
| Adam | epoch: 006 | loss: 0.39554 - acc: 0.8171 -- iter: 1376/1517
[A[ATraining Step: 284  | total loss: [1m[32m0.38042[0m[0m | time: 393.659s
[2K
| Adam | epoch: 006 | loss: 0.38042 - acc: 0.8260 -- iter: 1408/1517
[A[ATraining Step: 285  | total loss: [1m[32m0.39264[0m[0m | time: 405.254s
[2K
| Adam | epoch: 006 | loss: 0.39264 - acc: 0.8184 -- iter: 1440/1517
[A[ATraining Step: 286  | total loss: [1m[32m0.41071[0m[0m | time: 416.371s
[2K
| Adam | epoch: 006 | loss: 0.41071 - acc: 0.7928 -- iter: 1472/1517
[A[ATraining Step: 287  | total loss: [1m[32m0.39994[0m[0m | time: 427.553s
[2K
| Adam | epoch: 006 | loss: 0.39994 - acc: 0.7979 -- iter: 1504/1517
[A[ATraining Step: 288  | total loss: [1m[32m0.38718[0m[0m | time: 464.577s
[2K
| Adam | epoch: 006 | loss: 0.38718 - acc: 0.8087 | val_loss: 0.60074 - val_acc: 0.6821 -- iter: 1517/1517
--
Training Step: 289  | total loss: [1m[32m0.38812[0m[0m | time: 11.848s
[2K
| Adam | epoch: 007 | loss: 0.38812 - acc: 0.8029 -- iter: 0032/1517
[A[ATraining Step: 290  | total loss: [1m[32m0.37741[0m[0m | time: 22.330s
[2K
| Adam | epoch: 007 | loss: 0.37741 - acc: 0.8101 -- iter: 0064/1517
[A[ATraining Step: 291  | total loss: [1m[32m0.37385[0m[0m | time: 32.942s
[2K
| Adam | epoch: 007 | loss: 0.37385 - acc: 0.8134 -- iter: 0096/1517
[A[ATraining Step: 292  | total loss: [1m[32m0.37360[0m[0m | time: 43.637s
[2K
| Adam | epoch: 007 | loss: 0.37360 - acc: 0.8227 -- iter: 0128/1517
[A[ATraining Step: 293  | total loss: [1m[32m0.36885[0m[0m | time: 48.839s
[2K
| Adam | epoch: 007 | loss: 0.36885 - acc: 0.8217 -- iter: 0160/1517
[A[ATraining Step: 294  | total loss: [1m[32m0.35560[0m[0m | time: 53.921s
[2K
| Adam | epoch: 007 | loss: 0.35560 - acc: 0.8318 -- iter: 0192/1517
[A[ATraining Step: 295  | total loss: [1m[32m0.33009[0m[0m | time: 64.379s
[2K
| Adam | epoch: 007 | loss: 0.33009 - acc: 0.8487 -- iter: 0224/1517
[A[ATraining Step: 296  | total loss: [1m[32m0.33448[0m[0m | time: 75.678s
[2K
| Adam | epoch: 007 | loss: 0.33448 - acc: 0.8513 -- iter: 0256/1517
[A[ATraining Step: 297  | total loss: [1m[32m0.33871[0m[0m | time: 86.214s
[2K
| Adam | epoch: 007 | loss: 0.33871 - acc: 0.8505 -- iter: 0288/1517
[A[ATraining Step: 298  | total loss: [1m[32m0.33344[0m[0m | time: 96.607s
[2K
| Adam | epoch: 007 | loss: 0.33344 - acc: 0.8499 -- iter: 0320/1517
[A[ATraining Step: 299  | total loss: [1m[32m0.33826[0m[0m | time: 106.966s
[2K
| Adam | epoch: 007 | loss: 0.33826 - acc: 0.8492 -- iter: 0352/1517
[A[ATraining Step: 300  | total loss: [1m[32m0.34108[0m[0m | time: 117.641s
[2K
| Adam | epoch: 007 | loss: 0.34108 - acc: 0.8518 -- iter: 0384/1517
[A[ATraining Step: 301  | total loss: [1m[32m0.33419[0m[0m | time: 128.230s
[2K
| Adam | epoch: 007 | loss: 0.33419 - acc: 0.8541 -- iter: 0416/1517
[A[ATraining Step: 302  | total loss: [1m[32m0.34975[0m[0m | time: 139.867s
[2K
| Adam | epoch: 007 | loss: 0.34975 - acc: 0.8469 -- iter: 0448/1517
[A[ATraining Step: 303  | total loss: [1m[32m0.35884[0m[0m | time: 150.595s
[2K
| Adam | epoch: 007 | loss: 0.35884 - acc: 0.8372 -- iter: 0480/1517
[A[ATraining Step: 304  | total loss: [1m[32m0.34940[0m[0m | time: 161.364s
[2K
| Adam | epoch: 007 | loss: 0.34940 - acc: 0.8472 -- iter: 0512/1517
[A[ATraining Step: 305  | total loss: [1m[32m0.36972[0m[0m | time: 172.264s
[2K
| Adam | epoch: 007 | loss: 0.36972 - acc: 0.8344 -- iter: 0544/1517
[A[ATraining Step: 306  | total loss: [1m[32m0.36494[0m[0m | time: 182.685s
[2K
| Adam | epoch: 007 | loss: 0.36494 - acc: 0.8322 -- iter: 0576/1517
[A[ATraining Step: 307  | total loss: [1m[32m0.38725[0m[0m | time: 193.517s
[2K
| Adam | epoch: 007 | loss: 0.38725 - acc: 0.8240 -- iter: 0608/1517
[A[ATraining Step: 308  | total loss: [1m[32m0.37117[0m[0m | time: 204.313s
[2K
| Adam | epoch: 007 | loss: 0.37117 - acc: 0.8322 -- iter: 0640/1517
[A[ATraining Step: 309  | total loss: [1m[32m0.38108[0m[0m | time: 215.240s
[2K
| Adam | epoch: 007 | loss: 0.38108 - acc: 0.8240 -- iter: 0672/1517
[A[ATraining Step: 310  | total loss: [1m[32m0.37155[0m[0m | time: 225.937s
[2K
| Adam | epoch: 007 | loss: 0.37155 - acc: 0.8291 -- iter: 0704/1517
[A[ATraining Step: 311  | total loss: [1m[32m0.36657[0m[0m | time: 236.433s
[2K
| Adam | epoch: 007 | loss: 0.36657 - acc: 0.8305 -- iter: 0736/1517
[A[ATraining Step: 312  | total loss: [1m[32m0.35481[0m[0m | time: 248.860s
[2K
| Adam | epoch: 007 | loss: 0.35481 - acc: 0.8350 -- iter: 0768/1517
[A[ATraining Step: 313  | total loss: [1m[32m0.35336[0m[0m | time: 259.869s
[2K
| Adam | epoch: 007 | loss: 0.35336 - acc: 0.8359 -- iter: 0800/1517
[A[ATraining Step: 314  | total loss: [1m[32m0.34216[0m[0m | time: 270.977s
[2K
| Adam | epoch: 007 | loss: 0.34216 - acc: 0.8398 -- iter: 0832/1517
[A[ATraining Step: 315  | total loss: [1m[32m0.33199[0m[0m | time: 282.252s
[2K
| Adam | epoch: 007 | loss: 0.33199 - acc: 0.8464 -- iter: 0864/1517
[A[ATraining Step: 316  | total loss: [1m[32m0.35036[0m[0m | time: 293.896s
[2K
| Adam | epoch: 007 | loss: 0.35036 - acc: 0.8399 -- iter: 0896/1517
[A[ATraining Step: 317  | total loss: [1m[32m0.38648[0m[0m | time: 304.866s
[2K
| Adam | epoch: 007 | loss: 0.38648 - acc: 0.8247 -- iter: 0928/1517
[A[ATraining Step: 318  | total loss: [1m[32m0.38472[0m[0m | time: 315.997s
[2K
| Adam | epoch: 007 | loss: 0.38472 - acc: 0.8203 -- iter: 0960/1517
[A[ATraining Step: 319  | total loss: [1m[32m0.37754[0m[0m | time: 327.154s
[2K
| Adam | epoch: 007 | loss: 0.37754 - acc: 0.8227 -- iter: 0992/1517
[A[ATraining Step: 320  | total loss: [1m[32m0.35748[0m[0m | time: 338.053s
[2K
| Adam | epoch: 007 | loss: 0.35748 - acc: 0.8341 -- iter: 1024/1517
[A[ATraining Step: 321  | total loss: [1m[32m0.36478[0m[0m | time: 348.959s
[2K
| Adam | epoch: 007 | loss: 0.36478 - acc: 0.8351 -- iter: 1056/1517
[A[ATraining Step: 322  | total loss: [1m[32m0.35199[0m[0m | time: 361.071s
[2K
| Adam | epoch: 007 | loss: 0.35199 - acc: 0.8422 -- iter: 1088/1517
[A[ATraining Step: 323  | total loss: [1m[32m0.33404[0m[0m | time: 371.406s
[2K
| Adam | epoch: 007 | loss: 0.33404 - acc: 0.8518 -- iter: 1120/1517
[A[ATraining Step: 324  | total loss: [1m[32m0.32583[0m[0m | time: 382.846s
[2K
| Adam | epoch: 007 | loss: 0.32583 - acc: 0.8572 -- iter: 1152/1517
[A[ATraining Step: 325  | total loss: [1m[32m0.32103[0m[0m | time: 393.784s
[2K
| Adam | epoch: 007 | loss: 0.32103 - acc: 0.8590 -- iter: 1184/1517
[A[ATraining Step: 326  | total loss: [1m[32m0.32934[0m[0m | time: 405.380s
[2K
| Adam | epoch: 007 | loss: 0.32934 - acc: 0.8575 -- iter: 1216/1517
[A[ATraining Step: 327  | total loss: [1m[32m0.31617[0m[0m | time: 416.677s
[2K
| Adam | epoch: 007 | loss: 0.31617 - acc: 0.8655 -- iter: 1248/1517
[A[ATraining Step: 328  | total loss: [1m[32m0.30351[0m[0m | time: 428.243s
[2K
| Adam | epoch: 007 | loss: 0.30351 - acc: 0.8758 -- iter: 1280/1517
[A[ATraining Step: 329  | total loss: [1m[32m0.28937[0m[0m | time: 440.121s
[2K
| Adam | epoch: 007 | loss: 0.28937 - acc: 0.8820 -- iter: 1312/1517
[A[ATraining Step: 330  | total loss: [1m[32m0.30067[0m[0m | time: 450.883s
[2K
| Adam | epoch: 007 | loss: 0.30067 - acc: 0.8813 -- iter: 1344/1517
[A[ATraining Step: 331  | total loss: [1m[32m0.29770[0m[0m | time: 461.346s
[2K
| Adam | epoch: 007 | loss: 0.29770 - acc: 0.8775 -- iter: 1376/1517
[A[ATraining Step: 332  | total loss: [1m[32m0.31058[0m[0m | time: 473.406s
[2K
| Adam | epoch: 007 | loss: 0.31058 - acc: 0.8741 -- iter: 1408/1517
[A[ATraining Step: 333  | total loss: [1m[32m0.30666[0m[0m | time: 483.760s
[2K
| Adam | epoch: 007 | loss: 0.30666 - acc: 0.8742 -- iter: 1440/1517
[A[ATraining Step: 334  | total loss: [1m[32m0.29456[0m[0m | time: 494.631s
[2K
| Adam | epoch: 007 | loss: 0.29456 - acc: 0.8743 -- iter: 1472/1517
[A[ATraining Step: 335  | total loss: [1m[32m0.30866[0m[0m | time: 505.734s
[2K
| Adam | epoch: 007 | loss: 0.30866 - acc: 0.8619 -- iter: 1504/1517
[A[ATraining Step: 336  | total loss: [1m[32m0.30374[0m[0m | time: 545.102s
[2K
| Adam | epoch: 007 | loss: 0.30374 - acc: 0.8601 | val_loss: 0.89025 - val_acc: 0.6863 -- iter: 1517/1517
--
Training Step: 337  | total loss: [1m[32m0.30585[0m[0m | time: 10.656s
[2K
| Adam | epoch: 008 | loss: 0.30585 - acc: 0.8584 -- iter: 0032/1517
[A[ATraining Step: 338  | total loss: [1m[32m0.30946[0m[0m | time: 21.400s
[2K
| Adam | epoch: 008 | loss: 0.30946 - acc: 0.8601 -- iter: 0064/1517
[A[ATraining Step: 339  | total loss: [1m[32m0.31297[0m[0m | time: 31.961s
[2K
| Adam | epoch: 008 | loss: 0.31297 - acc: 0.8616 -- iter: 0096/1517
[A[ATraining Step: 340  | total loss: [1m[32m0.32388[0m[0m | time: 42.526s
[2K
| Adam | epoch: 008 | loss: 0.32388 - acc: 0.8598 -- iter: 0128/1517
[A[ATraining Step: 341  | total loss: [1m[32m0.33139[0m[0m | time: 53.328s
[2K
| Adam | epoch: 008 | loss: 0.33139 - acc: 0.8613 -- iter: 0160/1517
[A[ATraining Step: 342  | total loss: [1m[32m0.33983[0m[0m | time: 59.032s
[2K
| Adam | epoch: 008 | loss: 0.33983 - acc: 0.8533 -- iter: 0192/1517
[A[ATraining Step: 343  | total loss: [1m[32m0.34862[0m[0m | time: 63.868s
[2K
| Adam | epoch: 008 | loss: 0.34862 - acc: 0.8449 -- iter: 0224/1517
[A[ATraining Step: 344  | total loss: [1m[32m0.32994[0m[0m | time: 74.177s
[2K
| Adam | epoch: 008 | loss: 0.32994 - acc: 0.8527 -- iter: 0256/1517
[A[ATraining Step: 345  | total loss: [1m[32m0.32669[0m[0m | time: 84.789s
[2K
| Adam | epoch: 008 | loss: 0.32669 - acc: 0.8581 -- iter: 0288/1517
[A[ATraining Step: 346  | total loss: [1m[32m0.32737[0m[0m | time: 95.153s
[2K
| Adam | epoch: 008 | loss: 0.32737 - acc: 0.8629 -- iter: 0320/1517
[A[ATraining Step: 347  | total loss: [1m[32m0.34301[0m[0m | time: 106.250s
[2K
| Adam | epoch: 008 | loss: 0.34301 - acc: 0.8547 -- iter: 0352/1517
[A[ATraining Step: 348  | total loss: [1m[32m0.32478[0m[0m | time: 116.924s
[2K
| Adam | epoch: 008 | loss: 0.32478 - acc: 0.8661 -- iter: 0384/1517
[A[ATraining Step: 349  | total loss: [1m[32m0.34871[0m[0m | time: 127.302s
[2K
| Adam | epoch: 008 | loss: 0.34871 - acc: 0.8639 -- iter: 0416/1517
[A[ATraining Step: 350  | total loss: [1m[32m0.33903[0m[0m | time: 138.404s
[2K
| Adam | epoch: 008 | loss: 0.33903 - acc: 0.8619 -- iter: 0448/1517
[A[ATraining Step: 351  | total loss: [1m[32m0.32499[0m[0m | time: 149.117s
[2K
| Adam | epoch: 008 | loss: 0.32499 - acc: 0.8694 -- iter: 0480/1517
[A[ATraining Step: 352  | total loss: [1m[32m0.36762[0m[0m | time: 159.631s
[2K
| Adam | epoch: 008 | loss: 0.36762 - acc: 0.8575 -- iter: 0512/1517
[A[ATraining Step: 353  | total loss: [1m[32m0.36283[0m[0m | time: 170.090s
[2K
| Adam | epoch: 008 | loss: 0.36283 - acc: 0.8530 -- iter: 0544/1517
[A[ATraining Step: 354  | total loss: [1m[32m0.34169[0m[0m | time: 180.547s
[2K
| Adam | epoch: 008 | loss: 0.34169 - acc: 0.8614 -- iter: 0576/1517
[A[ATraining Step: 355  | total loss: [1m[32m0.33621[0m[0m | time: 191.010s
[2K
| Adam | epoch: 008 | loss: 0.33621 - acc: 0.8597 -- iter: 0608/1517
[A[ATraining Step: 356  | total loss: [1m[32m0.32642[0m[0m | time: 202.502s
[2K
| Adam | epoch: 008 | loss: 0.32642 - acc: 0.8643 -- iter: 0640/1517
[A[ATraining Step: 357  | total loss: [1m[32m0.36456[0m[0m | time: 213.361s
[2K
| Adam | epoch: 008 | loss: 0.36456 - acc: 0.8404 -- iter: 0672/1517
[A[ATraining Step: 358  | total loss: [1m[32m0.35847[0m[0m | time: 224.261s
[2K
| Adam | epoch: 008 | loss: 0.35847 - acc: 0.8439 -- iter: 0704/1517
[A[ATraining Step: 359  | total loss: [1m[32m0.34909[0m[0m | time: 234.606s
[2K
| Adam | epoch: 008 | loss: 0.34909 - acc: 0.8563 -- iter: 0736/1517
[A[ATraining Step: 360  | total loss: [1m[32m0.34098[0m[0m | time: 245.126s
[2K
| Adam | epoch: 008 | loss: 0.34098 - acc: 0.8645 -- iter: 0768/1517
[A[ATraining Step: 361  | total loss: [1m[32m0.33310[0m[0m | time: 255.555s
[2K
| Adam | epoch: 008 | loss: 0.33310 - acc: 0.8655 -- iter: 0800/1517
[A[ATraining Step: 362  | total loss: [1m[32m0.32119[0m[0m | time: 266.324s
[2K
| Adam | epoch: 008 | loss: 0.32119 - acc: 0.8790 -- iter: 0832/1517
[A[ATraining Step: 363  | total loss: [1m[32m0.31744[0m[0m | time: 280.517s
[2K
| Adam | epoch: 008 | loss: 0.31744 - acc: 0.8754 -- iter: 0864/1517
[A[ATraining Step: 364  | total loss: [1m[32m0.31224[0m[0m | time: 288.448s
[2K
| Adam | epoch: 008 | loss: 0.31224 - acc: 0.8816 -- iter: 0896/1517
[A[ATraining Step: 365  | total loss: [1m[32m0.31346[0m[0m | time: 296.190s
[2K
| Adam | epoch: 008 | loss: 0.31346 - acc: 0.8779 -- iter: 0928/1517
[A[ATraining Step: 366  | total loss: [1m[32m0.31164[0m[0m | time: 303.955s
[2K
| Adam | epoch: 008 | loss: 0.31164 - acc: 0.8776 -- iter: 0960/1517
[A[ATraining Step: 367  | total loss: [1m[32m0.30109[0m[0m | time: 311.649s
[2K
| Adam | epoch: 008 | loss: 0.30109 - acc: 0.8804 -- iter: 0992/1517
[A[ATraining Step: 368  | total loss: [1m[32m0.31016[0m[0m | time: 319.352s
[2K
| Adam | epoch: 008 | loss: 0.31016 - acc: 0.8736 -- iter: 1024/1517
[A[ATraining Step: 369  | total loss: [1m[32m0.29986[0m[0m | time: 327.133s
[2K
| Adam | epoch: 008 | loss: 0.29986 - acc: 0.8800 -- iter: 1056/1517
[A[ATraining Step: 370  | total loss: [1m[32m0.29372[0m[0m | time: 334.677s
[2K
| Adam | epoch: 008 | loss: 0.29372 - acc: 0.8795 -- iter: 1088/1517
[A[ATraining Step: 371  | total loss: [1m[32m0.27767[0m[0m | time: 342.315s
[2K
| Adam | epoch: 008 | loss: 0.27767 - acc: 0.8885 -- iter: 1120/1517
[A[ATraining Step: 372  | total loss: [1m[32m0.28792[0m[0m | time: 350.170s
[2K
| Adam | epoch: 008 | loss: 0.28792 - acc: 0.8840 -- iter: 1152/1517
[A[ATraining Step: 373  | total loss: [1m[32m0.28057[0m[0m | time: 358.032s
[2K
| Adam | epoch: 008 | loss: 0.28057 - acc: 0.8893 -- iter: 1184/1517
[A[ATraining Step: 374  | total loss: [1m[32m0.28004[0m[0m | time: 365.815s
[2K
| Adam | epoch: 008 | loss: 0.28004 - acc: 0.8879 -- iter: 1216/1517
[A[ATraining Step: 375  | total loss: [1m[32m0.26801[0m[0m | time: 373.500s
[2K
| Adam | epoch: 008 | loss: 0.26801 - acc: 0.8897 -- iter: 1248/1517
[A[ATraining Step: 376  | total loss: [1m[32m0.25587[0m[0m | time: 381.228s
[2K
| Adam | epoch: 008 | loss: 0.25587 - acc: 0.8976 -- iter: 1280/1517
[A[ATraining Step: 377  | total loss: [1m[32m0.25879[0m[0m | time: 388.961s
[2K
| Adam | epoch: 008 | loss: 0.25879 - acc: 0.9016 -- iter: 1312/1517
[A[ATraining Step: 378  | total loss: [1m[32m0.25542[0m[0m | time: 396.725s
[2K
| Adam | epoch: 008 | loss: 0.25542 - acc: 0.8958 -- iter: 1344/1517
[A[ATraining Step: 379  | total loss: [1m[32m0.25133[0m[0m | time: 404.480s
[2K
| Adam | epoch: 008 | loss: 0.25133 - acc: 0.9000 -- iter: 1376/1517
[A[ATraining Step: 380  | total loss: [1m[32m0.26195[0m[0m | time: 412.194s
[2K
| Adam | epoch: 008 | loss: 0.26195 - acc: 0.8913 -- iter: 1408/1517
[A[ATraining Step: 381  | total loss: [1m[32m0.25173[0m[0m | time: 419.920s
[2K
| Adam | epoch: 008 | loss: 0.25173 - acc: 0.8959 -- iter: 1440/1517
[A[ATraining Step: 382  | total loss: [1m[32m0.23999[0m[0m | time: 427.598s
[2K
| Adam | epoch: 008 | loss: 0.23999 - acc: 0.9000 -- iter: 1472/1517
[A[ATraining Step: 383  | total loss: [1m[32m0.22658[0m[0m | time: 435.464s
[2K
| Adam | epoch: 008 | loss: 0.22658 - acc: 0.9100 -- iter: 1504/1517
[A[ATraining Step: 384  | total loss: [1m[32m0.26941[0m[0m | time: 464.027s
[2K
| Adam | epoch: 008 | loss: 0.26941 - acc: 0.8909 | val_loss: 6.84342 - val_acc: 0.4674 -- iter: 1517/1517
--
Training Step: 385  | total loss: [1m[32m0.27916[0m[0m | time: 13.782s
[2K
| Adam | epoch: 009 | loss: 0.27916 - acc: 0.8862 -- iter: 0032/1517
[A[ATraining Step: 386  | total loss: [1m[32m0.27686[0m[0m | time: 28.084s
[2K
| Adam | epoch: 009 | loss: 0.27686 - acc: 0.8851 -- iter: 0064/1517
[A[ATraining Step: 387  | total loss: [1m[32m0.30846[0m[0m | time: 41.508s
[2K
| Adam | epoch: 009 | loss: 0.30846 - acc: 0.8747 -- iter: 0096/1517
[A[ATraining Step: 388  | total loss: [1m[32m0.29444[0m[0m | time: 56.294s
[2K
| Adam | epoch: 009 | loss: 0.29444 - acc: 0.8810 -- iter: 0128/1517
[A[ATraining Step: 389  | total loss: [1m[32m0.30133[0m[0m | time: 69.763s
[2K
| Adam | epoch: 009 | loss: 0.30133 - acc: 0.8741 -- iter: 0160/1517
[A[ATraining Step: 390  | total loss: [1m[32m0.30979[0m[0m | time: 83.106s
[2K
| Adam | epoch: 009 | loss: 0.30979 - acc: 0.8742 -- iter: 0192/1517
[A[ATraining Step: 391  | total loss: [1m[32m0.30687[0m[0m | time: 90.160s
[2K
| Adam | epoch: 009 | loss: 0.30687 - acc: 0.8712 -- iter: 0224/1517
[A[ATraining Step: 392  | total loss: [1m[32m0.32951[0m[0m | time: 99.311s
[2K
| Adam | epoch: 009 | loss: 0.32951 - acc: 0.8533 -- iter: 0256/1517
[A[ATraining Step: 393  | total loss: [1m[32m0.32822[0m[0m | time: 124.059s
[2K
| Adam | epoch: 009 | loss: 0.32822 - acc: 0.8449 -- iter: 0288/1517
[A[ATraining Step: 394  | total loss: [1m[32m0.33145[0m[0m | time: 146.768s
[2K
| Adam | epoch: 009 | loss: 0.33145 - acc: 0.8448 -- iter: 0320/1517
[A[ATraining Step: 395  | total loss: [1m[32m0.34486[0m[0m | time: 165.691s
[2K
| Adam | epoch: 009 | loss: 0.34486 - acc: 0.8353 -- iter: 0352/1517
[A[ATraining Step: 396  | total loss: [1m[32m0.34966[0m[0m | time: 189.932s
[2K
| Adam | epoch: 009 | loss: 0.34966 - acc: 0.8330 -- iter: 0384/1517
[A[ATraining Step: 397  | total loss: [1m[32m0.33005[0m[0m | time: 210.015s
[2K
| Adam | epoch: 009 | loss: 0.33005 - acc: 0.8497 -- iter: 0416/1517
[A[ATraining Step: 398  | total loss: [1m[32m0.31759[0m[0m | time: 224.039s
[2K
| Adam | epoch: 009 | loss: 0.31759 - acc: 0.8585 -- iter: 0448/1517
[A[ATraining Step: 399  | total loss: [1m[32m0.32155[0m[0m | time: 241.847s
[2K
| Adam | epoch: 009 | loss: 0.32155 - acc: 0.8570 -- iter: 0480/1517
[A[ATraining Step: 400  | total loss: [1m[32m0.32133[0m[0m | time: 293.748s
[2K
| Adam | epoch: 009 | loss: 0.32133 - acc: 0.8588 | val_loss: 1.15685 - val_acc: 0.6884 -- iter: 0512/1517
--
Training Step: 401  | total loss: [1m[32m0.32072[0m[0m | time: 307.781s
[2K
| Adam | epoch: 009 | loss: 0.32072 - acc: 0.8542 -- iter: 0544/1517
[A[ATraining Step: 402  | total loss: [1m[32m0.30613[0m[0m | time: 321.109s
[2K
| Adam | epoch: 009 | loss: 0.30613 - acc: 0.8625 -- iter: 0576/1517
[A[ATraining Step: 403  | total loss: [1m[32m0.30238[0m[0m | time: 334.351s
[2K
| Adam | epoch: 009 | loss: 0.30238 - acc: 0.8669 -- iter: 0608/1517
[A[ATraining Step: 404  | total loss: [1m[32m0.30174[0m[0m | time: 347.636s
[2K
| Adam | epoch: 009 | loss: 0.30174 - acc: 0.8677 -- iter: 0640/1517
[A[ATraining Step: 405  | total loss: [1m[32m0.30660[0m[0m | time: 370.234s
[2K
| Adam | epoch: 009 | loss: 0.30660 - acc: 0.8747 -- iter: 0672/1517
[A[ATraining Step: 406  | total loss: [1m[32m0.30079[0m[0m | time: 395.375s
[2K
| Adam | epoch: 009 | loss: 0.30079 - acc: 0.8841 -- iter: 0704/1517
[A[ATraining Step: 407  | total loss: [1m[32m0.31776[0m[0m | time: 430.426s
[2K
| Adam | epoch: 009 | loss: 0.31776 - acc: 0.8738 -- iter: 0736/1517
[A[ATraining Step: 408  | total loss: [1m[32m0.30937[0m[0m | time: 452.551s
[2K
| Adam | epoch: 009 | loss: 0.30937 - acc: 0.8739 -- iter: 0768/1517
[A[ATraining Step: 409  | total loss: [1m[32m0.30990[0m[0m | time: 465.477s
[2K
| Adam | epoch: 009 | loss: 0.30990 - acc: 0.8709 -- iter: 0800/1517
[A[ATraining Step: 410  | total loss: [1m[32m0.29113[0m[0m | time: 478.271s
[2K
| Adam | epoch: 009 | loss: 0.29113 - acc: 0.8807 -- iter: 0832/1517
[A[ATraining Step: 411  | total loss: [1m[32m0.28012[0m[0m | time: 490.763s
[2K
| Adam | epoch: 009 | loss: 0.28012 - acc: 0.8832 -- iter: 0864/1517
[A[ATraining Step: 412  | total loss: [1m[32m0.26936[0m[0m | time: 503.650s
[2K
| Adam | epoch: 009 | loss: 0.26936 - acc: 0.8855 -- iter: 0896/1517
[A[ATraining Step: 413  | total loss: [1m[32m0.26872[0m[0m | time: 516.435s
[2K
| Adam | epoch: 009 | loss: 0.26872 - acc: 0.8845 -- iter: 0928/1517
[A[ATraining Step: 414  | total loss: [1m[32m0.26394[0m[0m | time: 529.159s
[2K
| Adam | epoch: 009 | loss: 0.26394 - acc: 0.8898 -- iter: 0960/1517
[A[ATraining Step: 415  | total loss: [1m[32m0.25779[0m[0m | time: 541.556s
[2K
| Adam | epoch: 009 | loss: 0.25779 - acc: 0.8946 -- iter: 0992/1517
[A[ATraining Step: 416  | total loss: [1m[32m0.25746[0m[0m | time: 554.275s
[2K
| Adam | epoch: 009 | loss: 0.25746 - acc: 0.8926 -- iter: 1024/1517
[A[ATraining Step: 417  | total loss: [1m[32m0.24240[0m[0m | time: 567.465s
[2K
| Adam | epoch: 009 | loss: 0.24240 - acc: 0.9002 -- iter: 1056/1517
[A[ATraining Step: 418  | total loss: [1m[32m0.24845[0m[0m | time: 580.027s
[2K
| Adam | epoch: 009 | loss: 0.24845 - acc: 0.8977 -- iter: 1088/1517
[A[ATraining Step: 419  | total loss: [1m[32m0.26619[0m[0m | time: 593.823s
[2K
| Adam | epoch: 009 | loss: 0.26619 - acc: 0.8829 -- iter: 1120/1517
[A[ATraining Step: 420  | total loss: [1m[32m0.24513[0m[0m | time: 606.847s
[2K
| Adam | epoch: 009 | loss: 0.24513 - acc: 0.8946 -- iter: 1152/1517
[A[ATraining Step: 421  | total loss: [1m[32m0.23698[0m[0m | time: 642.830s
[2K
| Adam | epoch: 009 | loss: 0.23698 - acc: 0.8958 -- iter: 1184/1517
[A[ATraining Step: 422  | total loss: [1m[32m0.25453[0m[0m | time: 655.183s
[2K
| Adam | epoch: 009 | loss: 0.25453 - acc: 0.8937 -- iter: 1216/1517
[A[ATraining Step: 423  | total loss: [1m[32m0.24504[0m[0m | time: 668.178s
[2K
| Adam | epoch: 009 | loss: 0.24504 - acc: 0.8981 -- iter: 1248/1517
[A[ATraining Step: 424  | total loss: [1m[32m0.25628[0m[0m | time: 680.914s
[2K
| Adam | epoch: 009 | loss: 0.25628 - acc: 0.8864 -- iter: 1280/1517
[A[ATraining Step: 425  | total loss: [1m[32m0.26644[0m[0m | time: 693.575s
[2K
| Adam | epoch: 009 | loss: 0.26644 - acc: 0.8853 -- iter: 1312/1517
[A[ATraining Step: 426  | total loss: [1m[32m0.26210[0m[0m | time: 706.414s
[2K
| Adam | epoch: 009 | loss: 0.26210 - acc: 0.8874 -- iter: 1344/1517
[A[ATraining Step: 427  | total loss: [1m[32m0.24853[0m[0m | time: 719.196s
[2K
| Adam | epoch: 009 | loss: 0.24853 - acc: 0.8924 -- iter: 1376/1517
[A[ATraining Step: 428  | total loss: [1m[32m0.24571[0m[0m | time: 731.641s
[2K
| Adam | epoch: 009 | loss: 0.24571 - acc: 0.8906 -- iter: 1408/1517
[A[ATraining Step: 429  | total loss: [1m[32m0.22998[0m[0m | time: 744.813s
[2K
| Adam | epoch: 009 | loss: 0.22998 - acc: 0.9016 -- iter: 1440/1517
[A[ATraining Step: 430  | total loss: [1m[32m0.24221[0m[0m | time: 757.318s
[2K
| Adam | epoch: 009 | loss: 0.24221 - acc: 0.8989 -- iter: 1472/1517
[A[ATraining Step: 431  | total loss: [1m[32m0.23069[0m[0m | time: 770.266s
[2K
| Adam | epoch: 009 | loss: 0.23069 - acc: 0.9090 -- iter: 1504/1517
[A[ATraining Step: 432  | total loss: [1m[32m0.23927[0m[0m | time: 821.754s
[2K
| Adam | epoch: 009 | loss: 0.23927 - acc: 0.9025 | val_loss: 0.59351 - val_acc: 0.7200 -- iter: 1517/1517
--
Training Step: 433  | total loss: [1m[32m0.23659[0m[0m | time: 31.560s
[2K
| Adam | epoch: 010 | loss: 0.23659 - acc: 0.9060 -- iter: 0032/1517
[A[ATraining Step: 434  | total loss: [1m[32m0.24872[0m[0m | time: 54.753s
[2K
| Adam | epoch: 010 | loss: 0.24872 - acc: 0.8998 -- iter: 0064/1517
[A[ATraining Step: 435  | total loss: [1m[32m0.27305[0m[0m | time: 68.720s
[2K
| Adam | epoch: 010 | loss: 0.27305 - acc: 0.8910 -- iter: 0096/1517
[A[ATraining Step: 436  | total loss: [1m[32m0.28552[0m[0m | time: 81.280s
[2K
| Adam | epoch: 010 | loss: 0.28552 - acc: 0.8832 -- iter: 0128/1517
[A[ATraining Step: 437  | total loss: [1m[32m0.27008[0m[0m | time: 93.478s
[2K
| Adam | epoch: 010 | loss: 0.27008 - acc: 0.8917 -- iter: 0160/1517
[A[ATraining Step: 438  | total loss: [1m[32m0.28827[0m[0m | time: 106.313s
[2K
| Adam | epoch: 010 | loss: 0.28827 - acc: 0.8838 -- iter: 0192/1517
[A[ATraining Step: 439  | total loss: [1m[32m0.28175[0m[0m | time: 119.292s
[2K
| Adam | epoch: 010 | loss: 0.28175 - acc: 0.8861 -- iter: 0224/1517
[A[ATraining Step: 440  | total loss: [1m[32m0.26385[0m[0m | time: 126.542s
[2K
| Adam | epoch: 010 | loss: 0.26385 - acc: 0.8943 -- iter: 0256/1517
[A[ATraining Step: 441  | total loss: [1m[32m0.46308[0m[0m | time: 132.935s
[2K
| Adam | epoch: 010 | loss: 0.46308 - acc: 0.8511 -- iter: 0288/1517
[A[ATraining Step: 442  | total loss: [1m[32m0.58594[0m[0m | time: 146.590s
[2K
| Adam | epoch: 010 | loss: 0.58594 - acc: 0.8198 -- iter: 0320/1517
[A[ATraining Step: 443  | total loss: [1m[32m0.59633[0m[0m | time: 159.424s
[2K
| Adam | epoch: 010 | loss: 0.59633 - acc: 0.8128 -- iter: 0352/1517
[A[ATraining Step: 444  | total loss: [1m[32m0.58054[0m[0m | time: 176.443s
[2K
| Adam | epoch: 010 | loss: 0.58054 - acc: 0.8159 -- iter: 0384/1517
[A[ATraining Step: 445  | total loss: [1m[32m0.55333[0m[0m | time: 198.063s
[2K
| Adam | epoch: 010 | loss: 0.55333 - acc: 0.8249 -- iter: 0416/1517
[A[ATraining Step: 446  | total loss: [1m[32m0.55126[0m[0m | time: 210.787s
[2K
| Adam | epoch: 010 | loss: 0.55126 - acc: 0.8237 -- iter: 0448/1517
[A[ATraining Step: 447  | total loss: [1m[32m0.53403[0m[0m | time: 223.457s
[2K
| Adam | epoch: 010 | loss: 0.53403 - acc: 0.8257 -- iter: 0480/1517
[A[ATraining Step: 448  | total loss: [1m[32m0.50576[0m[0m | time: 236.498s
[2K
| Adam | epoch: 010 | loss: 0.50576 - acc: 0.8306 -- iter: 0512/1517
[A[ATraining Step: 449  | total loss: [1m[32m0.47415[0m[0m | time: 249.311s
[2K
| Adam | epoch: 010 | loss: 0.47415 - acc: 0.8382 -- iter: 0544/1517
[A[ATraining Step: 450  | total loss: [1m[32m0.46021[0m[0m | time: 262.229s
[2K
| Adam | epoch: 010 | loss: 0.46021 - acc: 0.8388 -- iter: 0576/1517
[A[ATraining Step: 451  | total loss: [1m[32m0.46036[0m[0m | time: 275.458s
[2K
| Adam | epoch: 010 | loss: 0.46036 - acc: 0.8299 -- iter: 0608/1517
[A[ATraining Step: 452  | total loss: [1m[32m0.45763[0m[0m | time: 288.502s
[2K
| Adam | epoch: 010 | loss: 0.45763 - acc: 0.8219 -- iter: 0640/1517
[A[ATraining Step: 453  | total loss: [1m[32m0.45262[0m[0m | time: 303.308s
[2K
| Adam | epoch: 010 | loss: 0.45262 - acc: 0.8147 -- iter: 0672/1517
[A[ATraining Step: 454  | total loss: [1m[32m0.47685[0m[0m | time: 336.172s
[2K
| Adam | epoch: 010 | loss: 0.47685 - acc: 0.7989 -- iter: 0704/1517
[A[ATraining Step: 455  | total loss: [1m[32m0.48156[0m[0m | time: 349.406s
[2K
| Adam | epoch: 010 | loss: 0.48156 - acc: 0.7877 -- iter: 0736/1517
[A[ATraining Step: 456  | total loss: [1m[32m0.46083[0m[0m | time: 362.044s
[2K
| Adam | epoch: 010 | loss: 0.46083 - acc: 0.7964 -- iter: 0768/1517
[A[ATraining Step: 457  | total loss: [1m[32m0.44718[0m[0m | time: 374.674s
[2K
| Adam | epoch: 010 | loss: 0.44718 - acc: 0.8043 -- iter: 0800/1517
[A[ATraining Step: 458  | total loss: [1m[32m0.44201[0m[0m | time: 387.189s
[2K
| Adam | epoch: 010 | loss: 0.44201 - acc: 0.8082 -- iter: 0832/1517
[A[ATraining Step: 459  | total loss: [1m[32m0.42580[0m[0m | time: 399.720s
[2K
| Adam | epoch: 010 | loss: 0.42580 - acc: 0.8118 -- iter: 0864/1517
[A[ATraining Step: 460  | total loss: [1m[32m0.42189[0m[0m | time: 412.455s
[2K
| Adam | epoch: 010 | loss: 0.42189 - acc: 0.8119 -- iter: 0896/1517
[A[ATraining Step: 461  | total loss: [1m[32m0.40807[0m[0m | time: 425.367s
[2K
| Adam | epoch: 010 | loss: 0.40807 - acc: 0.8182 -- iter: 0928/1517
[A[ATraining Step: 462  | total loss: [1m[32m0.40290[0m[0m | time: 438.223s
[2K
| Adam | epoch: 010 | loss: 0.40290 - acc: 0.8239 -- iter: 0960/1517
[A[ATraining Step: 463  | total loss: [1m[32m0.38381[0m[0m | time: 451.276s
[2K
| Adam | epoch: 010 | loss: 0.38381 - acc: 0.8321 -- iter: 0992/1517
[A[ATraining Step: 464  | total loss: [1m[32m0.37300[0m[0m | time: 471.481s
[2K
| Adam | epoch: 010 | loss: 0.37300 - acc: 0.8458 -- iter: 1024/1517
[A[ATraining Step: 465  | total loss: [1m[32m0.35647[0m[0m | time: 495.384s
[2K
| Adam | epoch: 010 | loss: 0.35647 - acc: 0.8549 -- iter: 1056/1517
[A[ATraining Step: 466  | total loss: [1m[32m0.34354[0m[0m | time: 508.240s
[2K
| Adam | epoch: 010 | loss: 0.34354 - acc: 0.8632 -- iter: 1088/1517
[A[ATraining Step: 467  | total loss: [1m[32m0.33092[0m[0m | time: 521.074s
[2K
| Adam | epoch: 010 | loss: 0.33092 - acc: 0.8706 -- iter: 1120/1517
[A[ATraining Step: 468  | total loss: [1m[32m0.31692[0m[0m | time: 533.479s
[2K
| Adam | epoch: 010 | loss: 0.31692 - acc: 0.8773 -- iter: 1152/1517
[A[ATraining Step: 469  | total loss: [1m[32m0.29845[0m[0m | time: 546.126s
[2K
| Adam | epoch: 010 | loss: 0.29845 - acc: 0.8865 -- iter: 1184/1517
[A[ATraining Step: 470  | total loss: [1m[32m0.29490[0m[0m | time: 558.741s
[2K
| Adam | epoch: 010 | loss: 0.29490 - acc: 0.8916 -- iter: 1216/1517
[A[ATraining Step: 471  | total loss: [1m[32m0.27536[0m[0m | time: 571.137s
[2K
| Adam | epoch: 010 | loss: 0.27536 - acc: 0.9024 -- iter: 1248/1517
[A[ATraining Step: 472  | total loss: [1m[32m0.27272[0m[0m | time: 583.726s
[2K
| Adam | epoch: 010 | loss: 0.27272 - acc: 0.9059 -- iter: 1280/1517
[A[ATraining Step: 473  | total loss: [1m[32m0.27580[0m[0m | time: 596.367s
[2K
| Adam | epoch: 010 | loss: 0.27580 - acc: 0.9059 -- iter: 1312/1517
[A[ATraining Step: 474  | total loss: [1m[32m0.28424[0m[0m | time: 608.975s
[2K
| Adam | epoch: 010 | loss: 0.28424 - acc: 0.8966 -- iter: 1344/1517
[A[ATraining Step: 475  | total loss: [1m[32m0.27916[0m[0m | time: 621.771s
[2K
| Adam | epoch: 010 | loss: 0.27916 - acc: 0.9038 -- iter: 1376/1517
[A[ATraining Step: 476  | total loss: [1m[32m0.27668[0m[0m | time: 634.917s
[2K
| Adam | epoch: 010 | loss: 0.27668 - acc: 0.9072 -- iter: 1408/1517
[A[ATraining Step: 477  | total loss: [1m[32m0.26006[0m[0m | time: 660.523s
[2K
| Adam | epoch: 010 | loss: 0.26006 - acc: 0.9165 -- iter: 1440/1517
[A[ATraining Step: 478  | total loss: [1m[32m0.25270[0m[0m | time: 672.745s
[2K
| Adam | epoch: 010 | loss: 0.25270 - acc: 0.9186 -- iter: 1472/1517
[A[ATraining Step: 479  | total loss: [1m[32m0.25054[0m[0m | time: 681.911s
[2K
| Adam | epoch: 010 | loss: 0.25054 - acc: 0.9173 -- iter: 1504/1517
[A[ATraining Step: 480  | total loss: [1m[32m0.24177[0m[0m | time: 733.173s
[2K
| Adam | epoch: 010 | loss: 0.24177 - acc: 0.9162 | val_loss: 0.72776 - val_acc: 0.6484 -- iter: 1517/1517
--
Training Step: 481  | total loss: [1m[32m0.23686[0m[0m | time: 8.041s
[2K
| Adam | epoch: 011 | loss: 0.23686 - acc: 0.9184 -- iter: 0032/1517
[A[ATraining Step: 482  | total loss: [1m[32m0.22946[0m[0m | time: 16.101s
[2K
| Adam | epoch: 011 | loss: 0.22946 - acc: 0.9234 -- iter: 0064/1517
[A[ATraining Step: 483  | total loss: [1m[32m0.21636[0m[0m | time: 24.135s
[2K
| Adam | epoch: 011 | loss: 0.21636 - acc: 0.9279 -- iter: 0096/1517
[A[ATraining Step: 484  | total loss: [1m[32m0.20360[0m[0m | time: 31.943s
[2K
| Adam | epoch: 011 | loss: 0.20360 - acc: 0.9351 -- iter: 0128/1517
[A[ATraining Step: 485  | total loss: [1m[32m0.20897[0m[0m | time: 43.151s
[2K
| Adam | epoch: 011 | loss: 0.20897 - acc: 0.9322 -- iter: 0160/1517
[A[ATraining Step: 486  | total loss: [1m[32m0.20484[0m[0m | time: 55.824s
[2K
| Adam | epoch: 011 | loss: 0.20484 - acc: 0.9328 -- iter: 0192/1517
[A[ATraining Step: 487  | total loss: [1m[32m0.21243[0m[0m | time: 68.735s
[2K
| Adam | epoch: 011 | loss: 0.21243 - acc: 0.9301 -- iter: 0224/1517
[A[ATraining Step: 488  | total loss: [1m[32m0.20166[0m[0m | time: 81.429s
[2K
| Adam | epoch: 011 | loss: 0.20166 - acc: 0.9371 -- iter: 0256/1517
[A[ATraining Step: 489  | total loss: [1m[32m0.22102[0m[0m | time: 88.133s
[2K
| Adam | epoch: 011 | loss: 0.22102 - acc: 0.9309 -- iter: 0288/1517
[A[ATraining Step: 490  | total loss: [1m[32m0.21572[0m[0m | time: 94.777s
[2K
| Adam | epoch: 011 | loss: 0.21572 - acc: 0.9224 -- iter: 0320/1517
[A[ATraining Step: 491  | total loss: [1m[32m0.19898[0m[0m | time: 114.724s
[2K
| Adam | epoch: 011 | loss: 0.19898 - acc: 0.9302 -- iter: 0352/1517
[A[ATraining Step: 492  | total loss: [1m[32m0.18829[0m[0m | time: 131.497s
[2K
| Adam | epoch: 011 | loss: 0.18829 - acc: 0.9340 -- iter: 0384/1517
[A[ATraining Step: 493  | total loss: [1m[32m0.17927[0m[0m | time: 144.404s
[2K
| Adam | epoch: 011 | loss: 0.17927 - acc: 0.9375 -- iter: 0416/1517
[A[ATraining Step: 494  | total loss: [1m[32m0.17754[0m[0m | time: 156.934s
[2K
| Adam | epoch: 011 | loss: 0.17754 - acc: 0.9344 -- iter: 0448/1517
[A[ATraining Step: 495  | total loss: [1m[32m0.18207[0m[0m | time: 169.766s
[2K
| Adam | epoch: 011 | loss: 0.18207 - acc: 0.9284 -- iter: 0480/1517
[A[ATraining Step: 496  | total loss: [1m[32m0.17056[0m[0m | time: 182.483s
[2K
| Adam | epoch: 011 | loss: 0.17056 - acc: 0.9356 -- iter: 0512/1517
[A[ATraining Step: 497  | total loss: [1m[32m0.16615[0m[0m | time: 195.326s
[2K
| Adam | epoch: 011 | loss: 0.16615 - acc: 0.9420 -- iter: 0544/1517
[A[ATraining Step: 498  | total loss: [1m[32m0.17685[0m[0m | time: 207.956s
[2K
| Adam | epoch: 011 | loss: 0.17685 - acc: 0.9322 -- iter: 0576/1517
[A[ATraining Step: 499  | total loss: [1m[32m0.17868[0m[0m | time: 221.253s
[2K
| Adam | epoch: 011 | loss: 0.17868 - acc: 0.9327 -- iter: 0608/1517
[A[ATraining Step: 500  | total loss: [1m[32m0.17444[0m[0m | time: 234.072s
[2K
| Adam | epoch: 011 | loss: 0.17444 - acc: 0.9301 -- iter: 0640/1517
[A[ATraining Step: 501  | total loss: [1m[32m0.18043[0m[0m | time: 254.871s
[2K
| Adam | epoch: 011 | loss: 0.18043 - acc: 0.9277 -- iter: 0672/1517
[A[ATraining Step: 502  | total loss: [1m[32m0.17322[0m[0m | time: 272.374s
[2K
| Adam | epoch: 011 | loss: 0.17322 - acc: 0.9318 -- iter: 0704/1517
[A[ATraining Step: 503  | total loss: [1m[32m0.17677[0m[0m | time: 285.316s
[2K
| Adam | epoch: 011 | loss: 0.17677 - acc: 0.9293 -- iter: 0736/1517
[A[ATraining Step: 504  | total loss: [1m[32m0.16196[0m[0m | time: 297.884s
[2K
| Adam | epoch: 011 | loss: 0.16196 - acc: 0.9363 -- iter: 0768/1517
[A[ATraining Step: 505  | total loss: [1m[32m0.18653[0m[0m | time: 310.427s
[2K
| Adam | epoch: 011 | loss: 0.18653 - acc: 0.9333 -- iter: 0800/1517
[A[ATraining Step: 506  | total loss: [1m[32m0.21477[0m[0m | time: 323.319s
[2K
| Adam | epoch: 011 | loss: 0.21477 - acc: 0.9212 -- iter: 0832/1517
[A[ATraining Step: 507  | total loss: [1m[32m0.24116[0m[0m | time: 335.993s
[2K
| Adam | epoch: 011 | loss: 0.24116 - acc: 0.9166 -- iter: 0864/1517
[A[ATraining Step: 508  | total loss: [1m[32m0.22538[0m[0m | time: 348.689s
[2K
| Adam | epoch: 011 | loss: 0.22538 - acc: 0.9187 -- iter: 0896/1517
[A[ATraining Step: 509  | total loss: [1m[32m0.22034[0m[0m | time: 361.981s
[2K
| Adam | epoch: 011 | loss: 0.22034 - acc: 0.9206 -- iter: 0928/1517
[A[ATraining Step: 510  | total loss: [1m[32m0.20595[0m[0m | time: 375.220s
[2K
| Adam | epoch: 011 | loss: 0.20595 - acc: 0.9285 -- iter: 0960/1517
[A[ATraining Step: 511  | total loss: [1m[32m0.20451[0m[0m | time: 387.647s
[2K
| Adam | epoch: 011 | loss: 0.20451 - acc: 0.9263 -- iter: 0992/1517
[A[ATraining Step: 512  | total loss: [1m[32m0.21021[0m[0m | time: 404.115s
[2K
| Adam | epoch: 011 | loss: 0.21021 - acc: 0.9274 -- iter: 1024/1517
[A[ATraining Step: 513  | total loss: [1m[32m0.20762[0m[0m | time: 422.034s
[2K
| Adam | epoch: 011 | loss: 0.20762 - acc: 0.9253 -- iter: 1056/1517
[A[ATraining Step: 514  | total loss: [1m[32m0.20149[0m[0m | time: 434.767s
[2K
| Adam | epoch: 011 | loss: 0.20149 - acc: 0.9265 -- iter: 1088/1517
[A[ATraining Step: 515  | total loss: [1m[32m0.19523[0m[0m | time: 447.292s
[2K
| Adam | epoch: 011 | loss: 0.19523 - acc: 0.9307 -- iter: 1120/1517
[A[ATraining Step: 516  | total loss: [1m[32m0.18081[0m[0m | time: 459.852s
[2K
| Adam | epoch: 011 | loss: 0.18081 - acc: 0.9377 -- iter: 1152/1517
[A[ATraining Step: 517  | total loss: [1m[32m0.17295[0m[0m | time: 472.333s
[2K
| Adam | epoch: 011 | loss: 0.17295 - acc: 0.9408 -- iter: 1184/1517
[A[ATraining Step: 518  | total loss: [1m[32m0.17116[0m[0m | time: 484.658s
[2K
| Adam | epoch: 011 | loss: 0.17116 - acc: 0.9404 -- iter: 1216/1517
[A[ATraining Step: 519  | total loss: [1m[32m0.16390[0m[0m | time: 497.355s
[2K
| Adam | epoch: 011 | loss: 0.16390 - acc: 0.9464 -- iter: 1248/1517
[A[ATraining Step: 520  | total loss: [1m[32m0.17759[0m[0m | time: 510.114s
[2K
| Adam | epoch: 011 | loss: 0.17759 - acc: 0.9393 -- iter: 1280/1517
[A[ATraining Step: 521  | total loss: [1m[32m0.17289[0m[0m | time: 522.984s
[2K
| Adam | epoch: 011 | loss: 0.17289 - acc: 0.9422 -- iter: 1312/1517
[A[ATraining Step: 522  | total loss: [1m[32m0.16986[0m[0m | time: 535.831s
[2K
| Adam | epoch: 011 | loss: 0.16986 - acc: 0.9417 -- iter: 1344/1517
[A[ATraining Step: 523  | total loss: [1m[32m0.17674[0m[0m | time: 548.753s
[2K
| Adam | epoch: 011 | loss: 0.17674 - acc: 0.9413 -- iter: 1376/1517
[A[ATraining Step: 524  | total loss: [1m[32m0.17800[0m[0m | time: 561.199s
[2K
| Adam | epoch: 011 | loss: 0.17800 - acc: 0.9409 -- iter: 1408/1517
[A[ATraining Step: 525  | total loss: [1m[32m0.17281[0m[0m | time: 573.802s
[2K
| Adam | epoch: 011 | loss: 0.17281 - acc: 0.9406 -- iter: 1440/1517
[A[ATraining Step: 526  | total loss: [1m[32m0.19612[0m[0m | time: 591.158s
[2K
| Adam | epoch: 011 | loss: 0.19612 - acc: 0.9403 -- iter: 1472/1517
[A[ATraining Step: 527  | total loss: [1m[32m0.18635[0m[0m | time: 610.046s
[2K
| Adam | epoch: 011 | loss: 0.18635 - acc: 0.9400 -- iter: 1504/1517
[A[ATraining Step: 528  | total loss: [1m[32m0.18001[0m[0m | time: 657.299s
[2K
| Adam | epoch: 011 | loss: 0.18001 - acc: 0.9429 | val_loss: 1.32408 - val_acc: 0.5958 -- iter: 1517/1517
--
Training Step: 529  | total loss: [1m[32m0.17384[0m[0m | time: 12.344s
[2K
| Adam | epoch: 012 | loss: 0.17384 - acc: 0.9392 -- iter: 0032/1517
[A[ATraining Step: 530  | total loss: [1m[32m0.17395[0m[0m | time: 24.886s
[2K
| Adam | epoch: 012 | loss: 0.17395 - acc: 0.9359 -- iter: 0064/1517
[A[ATraining Step: 531  | total loss: [1m[32m0.18002[0m[0m | time: 37.947s
[2K
| Adam | epoch: 012 | loss: 0.18002 - acc: 0.9298 -- iter: 0096/1517
[A[ATraining Step: 532  | total loss: [1m[32m0.18187[0m[0m | time: 51.100s
[2K
| Adam | epoch: 012 | loss: 0.18187 - acc: 0.9243 -- iter: 0128/1517
[A[ATraining Step: 533  | total loss: [1m[32m0.19199[0m[0m | time: 63.966s
[2K
| Adam | epoch: 012 | loss: 0.19199 - acc: 0.9100 -- iter: 0160/1517
[A[ATraining Step: 534  | total loss: [1m[32m0.18944[0m[0m | time: 77.142s
[2K
| Adam | epoch: 012 | loss: 0.18944 - acc: 0.9128 -- iter: 0192/1517
[A[ATraining Step: 535  | total loss: [1m[32m0.17590[0m[0m | time: 89.627s
[2K
| Adam | epoch: 012 | loss: 0.17590 - acc: 0.9215 -- iter: 0224/1517
[A[ATraining Step: 536  | total loss: [1m[32m0.18229[0m[0m | time: 101.913s
[2K
| Adam | epoch: 012 | loss: 0.18229 - acc: 0.9169 -- iter: 0256/1517
[A[ATraining Step: 537  | total loss: [1m[32m0.17140[0m[0m | time: 114.558s
[2K
| Adam | epoch: 012 | loss: 0.17140 - acc: 0.9252 -- iter: 0288/1517
[A[ATraining Step: 538  | total loss: [1m[32m0.16547[0m[0m | time: 121.181s
[2K
| Adam | epoch: 012 | loss: 0.16547 - acc: 0.9295 -- iter: 0320/1517
[A[ATraining Step: 539  | total loss: [1m[32m0.15905[0m[0m | time: 127.696s
[2K
| Adam | epoch: 012 | loss: 0.15905 - acc: 0.9289 -- iter: 0352/1517
[A[ATraining Step: 540  | total loss: [1m[32m0.14670[0m[0m | time: 140.015s
[2K
| Adam | epoch: 012 | loss: 0.14670 - acc: 0.9360 -- iter: 0384/1517
[A[ATraining Step: 541  | total loss: [1m[32m0.15414[0m[0m | time: 152.811s
[2K
| Adam | epoch: 012 | loss: 0.15414 - acc: 0.9361 -- iter: 0416/1517
[A[ATraining Step: 542  | total loss: [1m[32m0.16568[0m[0m | time: 165.619s
[2K
| Adam | epoch: 012 | loss: 0.16568 - acc: 0.9300 -- iter: 0448/1517
[A[ATraining Step: 543  | total loss: [1m[32m0.17883[0m[0m | time: 178.132s
[2K
| Adam | epoch: 012 | loss: 0.17883 - acc: 0.9152 -- iter: 0480/1517
[A[ATraining Step: 544  | total loss: [1m[32m0.17418[0m[0m | time: 190.994s
[2K
| Adam | epoch: 012 | loss: 0.17418 - acc: 0.9174 -- iter: 0512/1517
[A[ATraining Step: 545  | total loss: [1m[32m0.17467[0m[0m | time: 205.868s
[2K
| Adam | epoch: 012 | loss: 0.17467 - acc: 0.9194 -- iter: 0544/1517
[A[ATraining Step: 546  | total loss: [1m[32m0.18858[0m[0m | time: 220.143s
[2K
| Adam | epoch: 012 | loss: 0.18858 - acc: 0.9087 -- iter: 0576/1517
[A[ATraining Step: 547  | total loss: [1m[32m0.22360[0m[0m | time: 240.111s
[2K
| Adam | epoch: 012 | loss: 0.22360 - acc: 0.8991 -- iter: 0608/1517
[A[ATraining Step: 548  | total loss: [1m[32m0.21061[0m[0m | time: 252.690s
[2K
| Adam | epoch: 012 | loss: 0.21061 - acc: 0.9061 -- iter: 0640/1517
[A[ATraining Step: 549  | total loss: [1m[32m0.20988[0m[0m | time: 265.256s
[2K
| Adam | epoch: 012 | loss: 0.20988 - acc: 0.9092 -- iter: 0672/1517
[A[ATraining Step: 550  | total loss: [1m[32m0.21356[0m[0m | time: 278.003s
[2K
| Adam | epoch: 012 | loss: 0.21356 - acc: 0.9058 -- iter: 0704/1517
[A[ATraining Step: 551  | total loss: [1m[32m0.19932[0m[0m | time: 290.341s
[2K
| Adam | epoch: 012 | loss: 0.19932 - acc: 0.9152 -- iter: 0736/1517
[A[ATraining Step: 552  | total loss: [1m[32m0.18841[0m[0m | time: 302.569s
[2K
| Adam | epoch: 012 | loss: 0.18841 - acc: 0.9206 -- iter: 0768/1517
[A[ATraining Step: 553  | total loss: [1m[32m0.18362[0m[0m | time: 315.231s
[2K
| Adam | epoch: 012 | loss: 0.18362 - acc: 0.9222 -- iter: 0800/1517
[A[ATraining Step: 554  | total loss: [1m[32m0.19212[0m[0m | time: 328.324s
[2K
| Adam | epoch: 012 | loss: 0.19212 - acc: 0.9238 -- iter: 0832/1517
[A[ATraining Step: 555  | total loss: [1m[32m0.19165[0m[0m | time: 341.032s
[2K
| Adam | epoch: 012 | loss: 0.19165 - acc: 0.9251 -- iter: 0864/1517
[A[ATraining Step: 556  | total loss: [1m[32m0.19583[0m[0m | time: 354.215s
[2K
| Adam | epoch: 012 | loss: 0.19583 - acc: 0.9170 -- iter: 0896/1517
[A[ATraining Step: 557  | total loss: [1m[32m0.18797[0m[0m | time: 367.057s
[2K
| Adam | epoch: 012 | loss: 0.18797 - acc: 0.9191 -- iter: 0928/1517
[A[ATraining Step: 558  | total loss: [1m[32m0.18905[0m[0m | time: 382.163s
[2K
| Adam | epoch: 012 | loss: 0.18905 - acc: 0.9147 -- iter: 0960/1517
[A[ATraining Step: 559  | total loss: [1m[32m0.19344[0m[0m | time: 404.211s
[2K
| Adam | epoch: 012 | loss: 0.19344 - acc: 0.9138 -- iter: 0992/1517
[A[ATraining Step: 560  | total loss: [1m[32m0.18830[0m[0m | time: 416.941s
[2K
| Adam | epoch: 012 | loss: 0.18830 - acc: 0.9162 -- iter: 1024/1517
[A[ATraining Step: 561  | total loss: [1m[32m0.19193[0m[0m | time: 431.098s
[2K
| Adam | epoch: 012 | loss: 0.19193 - acc: 0.9152 -- iter: 1056/1517
[A[ATraining Step: 562  | total loss: [1m[32m0.18911[0m[0m | time: 445.386s
[2K
| Adam | epoch: 012 | loss: 0.18911 - acc: 0.9174 -- iter: 1088/1517
[A[ATraining Step: 563  | total loss: [1m[32m0.17571[0m[0m | time: 459.522s
[2K
| Adam | epoch: 012 | loss: 0.17571 - acc: 0.9257 -- iter: 1120/1517
[A[ATraining Step: 564  | total loss: [1m[32m0.17513[0m[0m | time: 473.482s
[2K
| Adam | epoch: 012 | loss: 0.17513 - acc: 0.9237 -- iter: 1152/1517
[A[ATraining Step: 565  | total loss: [1m[32m0.16630[0m[0m | time: 487.641s
[2K
| Adam | epoch: 012 | loss: 0.16630 - acc: 0.9282 -- iter: 1184/1517
[A[ATraining Step: 566  | total loss: [1m[32m0.16663[0m[0m | time: 497.702s
[2K
| Adam | epoch: 012 | loss: 0.16663 - acc: 0.9292 -- iter: 1216/1517
[A[ATraining Step: 567  | total loss: [1m[32m0.15444[0m[0m | time: 505.585s
[2K
| Adam | epoch: 012 | loss: 0.15444 - acc: 0.9362 -- iter: 1248/1517
[A[ATraining Step: 568  | total loss: [1m[32m0.14176[0m[0m | time: 513.640s
[2K
| Adam | epoch: 012 | loss: 0.14176 - acc: 0.9426 -- iter: 1280/1517
[A[ATraining Step: 569  | total loss: [1m[32m0.14073[0m[0m | time: 524.158s
[2K
| Adam | epoch: 012 | loss: 0.14073 - acc: 0.9421 -- iter: 1312/1517
[A[ATraining Step: 570  | total loss: [1m[32m0.17125[0m[0m | time: 536.212s
[2K
| Adam | epoch: 012 | loss: 0.17125 - acc: 0.9323 -- iter: 1344/1517
[A[ATraining Step: 571  | total loss: [1m[32m0.19057[0m[0m | time: 548.877s
[2K
| Adam | epoch: 012 | loss: 0.19057 - acc: 0.9234 -- iter: 1376/1517
[A[ATraining Step: 572  | total loss: [1m[32m0.18464[0m[0m | time: 561.402s
[2K
| Adam | epoch: 012 | loss: 0.18464 - acc: 0.9280 -- iter: 1408/1517
[A[ATraining Step: 573  | total loss: [1m[32m0.17768[0m[0m | time: 574.481s
[2K
| Adam | epoch: 012 | loss: 0.17768 - acc: 0.9289 -- iter: 1440/1517
[A[ATraining Step: 574  | total loss: [1m[32m0.17978[0m[0m | time: 587.156s
[2K
| Adam | epoch: 012 | loss: 0.17978 - acc: 0.9235 -- iter: 1472/1517
[A[ATraining Step: 575  | total loss: [1m[32m0.22079[0m[0m | time: 604.772s
[2K
| Adam | epoch: 012 | loss: 0.22079 - acc: 0.9124 -- iter: 1504/1517
[A[ATraining Step: 576  | total loss: [1m[32m0.22362[0m[0m | time: 657.491s
[2K
| Adam | epoch: 012 | loss: 0.22362 - acc: 0.9118 | val_loss: 0.51567 - val_acc: 0.8021 -- iter: 1517/1517
--
Training Step: 577  | total loss: [1m[32m0.21902[0m[0m | time: 12.331s
[2K
| Adam | epoch: 013 | loss: 0.21902 - acc: 0.9112 -- iter: 0032/1517
[A[ATraining Step: 578  | total loss: [1m[32m0.21457[0m[0m | time: 25.352s
[2K
| Adam | epoch: 013 | loss: 0.21457 - acc: 0.9139 -- iter: 0064/1517
[A[ATraining Step: 579  | total loss: [1m[32m0.19775[0m[0m | time: 37.732s
[2K
| Adam | epoch: 013 | loss: 0.19775 - acc: 0.9194 -- iter: 0096/1517
[A[ATraining Step: 580  | total loss: [1m[32m0.21305[0m[0m | time: 50.563s
[2K
| Adam | epoch: 013 | loss: 0.21305 - acc: 0.9149 -- iter: 0128/1517
[A[ATraining Step: 581  | total loss: [1m[32m0.20154[0m[0m | time: 63.183s
[2K
| Adam | epoch: 013 | loss: 0.20154 - acc: 0.9203 -- iter: 0160/1517
[A[ATraining Step: 582  | total loss: [1m[32m0.18945[0m[0m | time: 77.553s
[2K
| Adam | epoch: 013 | loss: 0.18945 - acc: 0.9283 -- iter: 0192/1517
[A[ATraining Step: 583  | total loss: [1m[32m0.18424[0m[0m | time: 90.012s
[2K
| Adam | epoch: 013 | loss: 0.18424 - acc: 0.9292 -- iter: 0224/1517
[A[ATraining Step: 584  | total loss: [1m[32m0.19755[0m[0m | time: 102.389s
[2K
| Adam | epoch: 013 | loss: 0.19755 - acc: 0.9207 -- iter: 0256/1517
[A[ATraining Step: 585  | total loss: [1m[32m0.20408[0m[0m | time: 114.807s
[2K
| Adam | epoch: 013 | loss: 0.20408 - acc: 0.9098 -- iter: 0288/1517
[A[ATraining Step: 586  | total loss: [1m[32m0.19403[0m[0m | time: 127.230s
[2K
| Adam | epoch: 013 | loss: 0.19403 - acc: 0.9157 -- iter: 0320/1517
[A[ATraining Step: 587  | total loss: [1m[32m0.19174[0m[0m | time: 133.615s
[2K
| Adam | epoch: 013 | loss: 0.19174 - acc: 0.9179 -- iter: 0352/1517
[A[ATraining Step: 588  | total loss: [1m[32m0.17694[0m[0m | time: 139.962s
[2K
| Adam | epoch: 013 | loss: 0.17694 - acc: 0.9261 -- iter: 0384/1517
[A[ATraining Step: 589  | total loss: [1m[32m0.16159[0m[0m | time: 152.999s
[2K
| Adam | epoch: 013 | loss: 0.16159 - acc: 0.9335 -- iter: 0416/1517
[A[ATraining Step: 590  | total loss: [1m[32m0.15229[0m[0m | time: 166.720s
[2K
| Adam | epoch: 013 | loss: 0.15229 - acc: 0.9402 -- iter: 0448/1517
[A[ATraining Step: 591  | total loss: [1m[32m0.16239[0m[0m | time: 180.977s
[2K
| Adam | epoch: 013 | loss: 0.16239 - acc: 0.9336 -- iter: 0480/1517
[A[ATraining Step: 592  | total loss: [1m[32m0.15853[0m[0m | time: 194.442s
[2K
| Adam | epoch: 013 | loss: 0.15853 - acc: 0.9340 -- iter: 0512/1517
[A[ATraining Step: 593  | total loss: [1m[32m0.15397[0m[0m | time: 208.389s
[2K
| Adam | epoch: 013 | loss: 0.15397 - acc: 0.9344 -- iter: 0544/1517
[A[ATraining Step: 594  | total loss: [1m[32m0.14670[0m[0m | time: 222.469s
[2K
| Adam | epoch: 013 | loss: 0.14670 - acc: 0.9409 -- iter: 0576/1517
[A[ATraining Step: 595  | total loss: [1m[32m0.14173[0m[0m | time: 230.818s
[2K
| Adam | epoch: 013 | loss: 0.14173 - acc: 0.9437 -- iter: 0608/1517
[A[ATraining Step: 596  | total loss: [1m[32m0.14128[0m[0m | time: 238.872s
[2K
| Adam | epoch: 013 | loss: 0.14128 - acc: 0.9431 -- iter: 0640/1517
[A[ATraining Step: 597  | total loss: [1m[32m0.14013[0m[0m | time: 247.142s
[2K
| Adam | epoch: 013 | loss: 0.14013 - acc: 0.9425 -- iter: 0672/1517
[A[ATraining Step: 598  | total loss: [1m[32m0.14740[0m[0m | time: 257.523s
[2K
| Adam | epoch: 013 | loss: 0.14740 - acc: 0.9420 -- iter: 0704/1517
[A[ATraining Step: 599  | total loss: [1m[32m0.15512[0m[0m | time: 270.280s
[2K
| Adam | epoch: 013 | loss: 0.15512 - acc: 0.9322 -- iter: 0736/1517
[A[ATraining Step: 600  | total loss: [1m[32m0.15660[0m[0m | time: 317.630s
[2K
| Adam | epoch: 013 | loss: 0.15660 - acc: 0.9359 | val_loss: 2.45891 - val_acc: 0.6547 -- iter: 0768/1517
--
Training Step: 601  | total loss: [1m[32m0.15332[0m[0m | time: 330.366s
[2K
| Adam | epoch: 013 | loss: 0.15332 - acc: 0.9360 -- iter: 0800/1517
[A[ATraining Step: 602  | total loss: [1m[32m0.14245[0m[0m | time: 342.371s
[2K
| Adam | epoch: 013 | loss: 0.14245 - acc: 0.9424 -- iter: 0832/1517
[A[ATraining Step: 603  | total loss: [1m[32m0.13496[0m[0m | time: 354.835s
[2K
| Adam | epoch: 013 | loss: 0.13496 - acc: 0.9482 -- iter: 0864/1517
[A[ATraining Step: 604  | total loss: [1m[32m0.14157[0m[0m | time: 367.022s
[2K
| Adam | epoch: 013 | loss: 0.14157 - acc: 0.9471 -- iter: 0896/1517
[A[ATraining Step: 605  | total loss: [1m[32m0.15355[0m[0m | time: 379.337s
[2K
| Adam | epoch: 013 | loss: 0.15355 - acc: 0.9430 -- iter: 0928/1517
[A[ATraining Step: 606  | total loss: [1m[32m0.15859[0m[0m | time: 391.360s
[2K
| Adam | epoch: 013 | loss: 0.15859 - acc: 0.9393 -- iter: 0960/1517
[A[ATraining Step: 607  | total loss: [1m[32m0.15361[0m[0m | time: 404.113s
[2K
| Adam | epoch: 013 | loss: 0.15361 - acc: 0.9392 -- iter: 0992/1517
[A[ATraining Step: 608  | total loss: [1m[32m0.14108[0m[0m | time: 416.803s
[2K
| Adam | epoch: 013 | loss: 0.14108 - acc: 0.9452 -- iter: 1024/1517
[A[ATraining Step: 609  | total loss: [1m[32m0.13175[0m[0m | time: 429.078s
[2K
| Adam | epoch: 013 | loss: 0.13175 - acc: 0.9507 -- iter: 1056/1517
[A[ATraining Step: 610  | total loss: [1m[32m0.14002[0m[0m | time: 441.718s
[2K
| Adam | epoch: 013 | loss: 0.14002 - acc: 0.9463 -- iter: 1088/1517
[A[ATraining Step: 611  | total loss: [1m[32m0.13230[0m[0m | time: 454.212s
[2K
| Adam | epoch: 013 | loss: 0.13230 - acc: 0.9485 -- iter: 1120/1517
[A[ATraining Step: 612  | total loss: [1m[32m0.12529[0m[0m | time: 466.569s
[2K
| Adam | epoch: 013 | loss: 0.12529 - acc: 0.9505 -- iter: 1152/1517
[A[ATraining Step: 613  | total loss: [1m[32m0.12306[0m[0m | time: 479.168s
[2K
| Adam | epoch: 013 | loss: 0.12306 - acc: 0.9555 -- iter: 1184/1517
[A[ATraining Step: 614  | total loss: [1m[32m0.11968[0m[0m | time: 491.641s
[2K
| Adam | epoch: 013 | loss: 0.11968 - acc: 0.9537 -- iter: 1216/1517
[A[ATraining Step: 615  | total loss: [1m[32m0.12100[0m[0m | time: 504.262s
[2K
| Adam | epoch: 013 | loss: 0.12100 - acc: 0.9521 -- iter: 1248/1517
[A[ATraining Step: 616  | total loss: [1m[32m0.11528[0m[0m | time: 517.412s
[2K
| Adam | epoch: 013 | loss: 0.11528 - acc: 0.9569 -- iter: 1280/1517
[A[ATraining Step: 617  | total loss: [1m[32m0.11654[0m[0m | time: 529.811s
[2K
| Adam | epoch: 013 | loss: 0.11654 - acc: 0.9549 -- iter: 1312/1517
[A[ATraining Step: 618  | total loss: [1m[32m0.12336[0m[0m | time: 542.362s
[2K
| Adam | epoch: 013 | loss: 0.12336 - acc: 0.9532 -- iter: 1344/1517
[A[ATraining Step: 619  | total loss: [1m[32m0.13037[0m[0m | time: 554.642s
[2K
| Adam | epoch: 013 | loss: 0.13037 - acc: 0.9547 -- iter: 1376/1517
[A[ATraining Step: 620  | total loss: [1m[32m0.12401[0m[0m | time: 567.130s
[2K
| Adam | epoch: 013 | loss: 0.12401 - acc: 0.9561 -- iter: 1408/1517
[A[ATraining Step: 621  | total loss: [1m[32m0.14033[0m[0m | time: 579.623s
[2K
| Adam | epoch: 013 | loss: 0.14033 - acc: 0.9512 -- iter: 1440/1517
[A[ATraining Step: 622  | total loss: [1m[32m0.13147[0m[0m | time: 591.954s
[2K
| Adam | epoch: 013 | loss: 0.13147 - acc: 0.9529 -- iter: 1472/1517
[A[ATraining Step: 623  | total loss: [1m[32m0.12077[0m[0m | time: 604.226s
[2K
| Adam | epoch: 013 | loss: 0.12077 - acc: 0.9576 -- iter: 1504/1517
[A[ATraining Step: 624  | total loss: [1m[32m0.11205[0m[0m | time: 651.918s
[2K
| Adam | epoch: 013 | loss: 0.11205 - acc: 0.9619 | val_loss: 0.64389 - val_acc: 0.6716 -- iter: 1517/1517
--
Training Step: 625  | total loss: [1m[32m0.12442[0m[0m | time: 12.123s
[2K
| Adam | epoch: 014 | loss: 0.12442 - acc: 0.9563 -- iter: 0032/1517
[A[ATraining Step: 626  | total loss: [1m[32m0.14701[0m[0m | time: 24.315s
[2K
| Adam | epoch: 014 | loss: 0.14701 - acc: 0.9482 -- iter: 0064/1517
[A[ATraining Step: 627  | total loss: [1m[32m0.16843[0m[0m | time: 36.639s
[2K
| Adam | epoch: 014 | loss: 0.16843 - acc: 0.9409 -- iter: 0096/1517
[A[ATraining Step: 628  | total loss: [1m[32m0.15653[0m[0m | time: 49.132s
[2K
| Adam | epoch: 014 | loss: 0.15653 - acc: 0.9468 -- iter: 0128/1517
[A[ATraining Step: 629  | total loss: [1m[32m0.14759[0m[0m | time: 61.626s
[2K
| Adam | epoch: 014 | loss: 0.14759 - acc: 0.9490 -- iter: 0160/1517
[A[ATraining Step: 630  | total loss: [1m[32m0.15646[0m[0m | time: 73.970s
[2K
| Adam | epoch: 014 | loss: 0.15646 - acc: 0.9447 -- iter: 0192/1517
[A[ATraining Step: 631  | total loss: [1m[32m0.16041[0m[0m | time: 86.603s
[2K
| Adam | epoch: 014 | loss: 0.16041 - acc: 0.9440 -- iter: 0224/1517
[A[ATraining Step: 632  | total loss: [1m[32m0.14858[0m[0m | time: 98.705s
[2K
| Adam | epoch: 014 | loss: 0.14858 - acc: 0.9496 -- iter: 0256/1517
[A[ATraining Step: 633  | total loss: [1m[32m0.15902[0m[0m | time: 110.772s
[2K
| Adam | epoch: 014 | loss: 0.15902 - acc: 0.9484 -- iter: 0288/1517
[A[ATraining Step: 634  | total loss: [1m[32m0.16970[0m[0m | time: 123.114s
[2K
| Adam | epoch: 014 | loss: 0.16970 - acc: 0.9473 -- iter: 0320/1517
[A[ATraining Step: 635  | total loss: [1m[32m0.16120[0m[0m | time: 135.449s
[2K
| Adam | epoch: 014 | loss: 0.16120 - acc: 0.9494 -- iter: 0352/1517
[A[ATraining Step: 636  | total loss: [1m[32m0.16694[0m[0m | time: 142.155s
[2K
| Adam | epoch: 014 | loss: 0.16694 - acc: 0.9420 -- iter: 0384/1517
[A[ATraining Step: 637  | total loss: [1m[32m0.19196[0m[0m | time: 148.445s
[2K
| Adam | epoch: 014 | loss: 0.19196 - acc: 0.9247 -- iter: 0416/1517
[A[ATraining Step: 638  | total loss: [1m[32m0.18878[0m[0m | time: 161.616s
[2K
| Adam | epoch: 014 | loss: 0.18878 - acc: 0.9322 -- iter: 0448/1517
[A[ATraining Step: 639  | total loss: [1m[32m0.17896[0m[0m | time: 177.082s
[2K
| Adam | epoch: 014 | loss: 0.17896 - acc: 0.9359 -- iter: 0480/1517
[A[ATraining Step: 640  | total loss: [1m[32m0.18616[0m[0m | time: 203.242s
[2K
| Adam | epoch: 014 | loss: 0.18616 - acc: 0.9298 -- iter: 0512/1517
[A[ATraining Step: 641  | total loss: [1m[32m0.18318[0m[0m | time: 215.809s
[2K
| Adam | epoch: 014 | loss: 0.18318 - acc: 0.9306 -- iter: 0544/1517
[A[ATraining Step: 642  | total loss: [1m[32m0.19458[0m[0m | time: 228.945s
[2K
| Adam | epoch: 014 | loss: 0.19458 - acc: 0.9281 -- iter: 0576/1517
[A[ATraining Step: 643  | total loss: [1m[32m0.19246[0m[0m | time: 241.079s
[2K
| Adam | epoch: 014 | loss: 0.19246 - acc: 0.9260 -- iter: 0608/1517
[A[ATraining Step: 644  | total loss: [1m[32m0.20554[0m[0m | time: 253.382s
[2K
| Adam | epoch: 014 | loss: 0.20554 - acc: 0.9271 -- iter: 0640/1517
[A[ATraining Step: 645  | total loss: [1m[32m0.20209[0m[0m | time: 266.045s
[2K
| Adam | epoch: 014 | loss: 0.20209 - acc: 0.9219 -- iter: 0672/1517
[A[ATraining Step: 646  | total loss: [1m[32m0.19867[0m[0m | time: 278.336s
[2K
| Adam | epoch: 014 | loss: 0.19867 - acc: 0.9235 -- iter: 0704/1517
[A[ATraining Step: 647  | total loss: [1m[32m0.20902[0m[0m | time: 290.904s
[2K
| Adam | epoch: 014 | loss: 0.20902 - acc: 0.9186 -- iter: 0736/1517
[A[ATraining Step: 648  | total loss: [1m[32m0.20387[0m[0m | time: 303.446s
[2K
| Adam | epoch: 014 | loss: 0.20387 - acc: 0.9205 -- iter: 0768/1517
[A[ATraining Step: 649  | total loss: [1m[32m0.19656[0m[0m | time: 315.909s
[2K
| Adam | epoch: 014 | loss: 0.19656 - acc: 0.9253 -- iter: 0800/1517
[A[ATraining Step: 650  | total loss: [1m[32m0.19049[0m[0m | time: 328.704s
[2K
| Adam | epoch: 014 | loss: 0.19049 - acc: 0.9265 -- iter: 0832/1517
[A[ATraining Step: 651  | total loss: [1m[32m0.19627[0m[0m | time: 341.873s
[2K
| Adam | epoch: 014 | loss: 0.19627 - acc: 0.9276 -- iter: 0864/1517
[A[ATraining Step: 652  | total loss: [1m[32m0.20268[0m[0m | time: 354.512s
[2K
| Adam | epoch: 014 | loss: 0.20268 - acc: 0.9224 -- iter: 0896/1517
[A[ATraining Step: 653  | total loss: [1m[32m0.19761[0m[0m | time: 367.135s
[2K
| Adam | epoch: 014 | loss: 0.19761 - acc: 0.9239 -- iter: 0928/1517
[A[ATraining Step: 654  | total loss: [1m[32m0.26051[0m[0m | time: 379.968s
[2K
| Adam | epoch: 014 | loss: 0.26051 - acc: 0.9065 -- iter: 0960/1517
[A[ATraining Step: 655  | total loss: [1m[32m0.24220[0m[0m | time: 392.664s
[2K
| Adam | epoch: 014 | loss: 0.24220 - acc: 0.9096 -- iter: 0992/1517
[A[ATraining Step: 656  | total loss: [1m[32m0.22217[0m[0m | time: 405.286s
[2K
| Adam | epoch: 014 | loss: 0.22217 - acc: 0.9155 -- iter: 1024/1517
[A[ATraining Step: 657  | total loss: [1m[32m0.21952[0m[0m | time: 417.312s
[2K
| Adam | epoch: 014 | loss: 0.21952 - acc: 0.9146 -- iter: 1056/1517
[A[ATraining Step: 658  | total loss: [1m[32m0.20982[0m[0m | time: 430.011s
[2K
| Adam | epoch: 014 | loss: 0.20982 - acc: 0.9169 -- iter: 1088/1517
[A[ATraining Step: 659  | total loss: [1m[32m0.19654[0m[0m | time: 442.684s
[2K
| Adam | epoch: 014 | loss: 0.19654 - acc: 0.9221 -- iter: 1120/1517
[A[ATraining Step: 660  | total loss: [1m[32m0.19394[0m[0m | time: 454.932s
[2K
| Adam | epoch: 014 | loss: 0.19394 - acc: 0.9267 -- iter: 1152/1517
[A[ATraining Step: 661  | total loss: [1m[32m0.18840[0m[0m | time: 467.531s
[2K
| Adam | epoch: 014 | loss: 0.18840 - acc: 0.9278 -- iter: 1184/1517
[A[ATraining Step: 662  | total loss: [1m[32m0.19589[0m[0m | time: 480.008s
[2K
| Adam | epoch: 014 | loss: 0.19589 - acc: 0.9257 -- iter: 1216/1517
[A[ATraining Step: 663  | total loss: [1m[32m0.18960[0m[0m | time: 492.612s
[2K
| Adam | epoch: 014 | loss: 0.18960 - acc: 0.9300 -- iter: 1248/1517
[A[ATraining Step: 664  | total loss: [1m[32m0.19004[0m[0m | time: 505.501s
[2K
| Adam | epoch: 014 | loss: 0.19004 - acc: 0.9276 -- iter: 1280/1517
[A[ATraining Step: 665  | total loss: [1m[32m0.18437[0m[0m | time: 517.492s
[2K
| Adam | epoch: 014 | loss: 0.18437 - acc: 0.9286 -- iter: 1312/1517
[A[ATraining Step: 666  | total loss: [1m[32m0.17671[0m[0m | time: 530.255s
[2K
| Adam | epoch: 014 | loss: 0.17671 - acc: 0.9326 -- iter: 1344/1517
[A[ATraining Step: 667  | total loss: [1m[32m0.17270[0m[0m | time: 542.728s
[2K
| Adam | epoch: 014 | loss: 0.17270 - acc: 0.9300 -- iter: 1376/1517
[A[ATraining Step: 668  | total loss: [1m[32m0.16959[0m[0m | time: 555.801s
[2K
| Adam | epoch: 014 | loss: 0.16959 - acc: 0.9307 -- iter: 1408/1517
[A[ATraining Step: 669  | total loss: [1m[32m0.16908[0m[0m | time: 568.421s
[2K
| Adam | epoch: 014 | loss: 0.16908 - acc: 0.9314 -- iter: 1440/1517
[A[ATraining Step: 670  | total loss: [1m[32m0.15425[0m[0m | time: 581.009s
[2K
| Adam | epoch: 014 | loss: 0.15425 - acc: 0.9383 -- iter: 1472/1517
[A[ATraining Step: 671  | total loss: [1m[32m0.14446[0m[0m | time: 593.378s
[2K
| Adam | epoch: 014 | loss: 0.14446 - acc: 0.9444 -- iter: 1504/1517
[A[ATraining Step: 672  | total loss: [1m[32m0.14813[0m[0m | time: 649.402s
[2K
| Adam | epoch: 014 | loss: 0.14813 - acc: 0.9406 | val_loss: 0.54412 - val_acc: 0.7684 -- iter: 1517/1517
--
Training Step: 673  | total loss: [1m[32m0.14614[0m[0m | time: 12.628s
[2K
| Adam | epoch: 015 | loss: 0.14614 - acc: 0.9403 -- iter: 0032/1517
[A[ATraining Step: 674  | total loss: [1m[32m0.14166[0m[0m | time: 24.844s
[2K
| Adam | epoch: 015 | loss: 0.14166 - acc: 0.9431 -- iter: 0064/1517
[A[ATraining Step: 675  | total loss: [1m[32m0.13627[0m[0m | time: 37.285s
[2K
| Adam | epoch: 015 | loss: 0.13627 - acc: 0.9488 -- iter: 0096/1517
[A[ATraining Step: 676  | total loss: [1m[32m0.12562[0m[0m | time: 49.814s
[2K
| Adam | epoch: 015 | loss: 0.12562 - acc: 0.9539 -- iter: 0128/1517
[A[ATraining Step: 677  | total loss: [1m[32m0.12819[0m[0m | time: 62.862s
[2K
| Adam | epoch: 015 | loss: 0.12819 - acc: 0.9523 -- iter: 0160/1517
[A[ATraining Step: 678  | total loss: [1m[32m0.12549[0m[0m | time: 75.725s
[2K
| Adam | epoch: 015 | loss: 0.12549 - acc: 0.9539 -- iter: 0192/1517
[A[ATraining Step: 679  | total loss: [1m[32m0.11695[0m[0m | time: 89.046s
[2K
| Adam | epoch: 015 | loss: 0.11695 - acc: 0.9586 -- iter: 0224/1517
[A[ATraining Step: 680  | total loss: [1m[32m0.10697[0m[0m | time: 101.893s
[2K
| Adam | epoch: 015 | loss: 0.10697 - acc: 0.9627 -- iter: 0256/1517
[A[ATraining Step: 681  | total loss: [1m[32m0.10205[0m[0m | time: 114.493s
[2K
| Adam | epoch: 015 | loss: 0.10205 - acc: 0.9633 -- iter: 0288/1517
[A[ATraining Step: 682  | total loss: [1m[32m0.09361[0m[0m | time: 127.043s
[2K
| Adam | epoch: 015 | loss: 0.09361 - acc: 0.9670 -- iter: 0320/1517
[A[ATraining Step: 683  | total loss: [1m[32m0.09909[0m[0m | time: 139.485s
[2K
| Adam | epoch: 015 | loss: 0.09909 - acc: 0.9640 -- iter: 0352/1517
[A[ATraining Step: 684  | total loss: [1m[32m0.09574[0m[0m | time: 151.851s
[2K
| Adam | epoch: 015 | loss: 0.09574 - acc: 0.9645 -- iter: 0384/1517
[A[ATraining Step: 685  | total loss: [1m[32m0.09099[0m[0m | time: 158.500s
[2K
| Adam | epoch: 015 | loss: 0.09099 - acc: 0.9649 -- iter: 0416/1517
[A[ATraining Step: 686  | total loss: [1m[32m0.08783[0m[0m | time: 164.622s
[2K
| Adam | epoch: 015 | loss: 0.08783 - acc: 0.9684 -- iter: 0448/1517
[A[ATraining Step: 687  | total loss: [1m[32m0.08050[0m[0m | time: 177.034s
[2K
| Adam | epoch: 015 | loss: 0.08050 - acc: 0.9716 -- iter: 0480/1517
[A[ATraining Step: 688  | total loss: [1m[32m0.07547[0m[0m | time: 189.651s
[2K
| Adam | epoch: 015 | loss: 0.07547 - acc: 0.9713 -- iter: 0512/1517
[A[ATraining Step: 689  | total loss: [1m[32m0.06969[0m[0m | time: 201.904s
[2K
| Adam | epoch: 015 | loss: 0.06969 - acc: 0.9742 -- iter: 0544/1517
[A[ATraining Step: 690  | total loss: [1m[32m0.08026[0m[0m | time: 214.067s
[2K
| Adam | epoch: 015 | loss: 0.08026 - acc: 0.9705 -- iter: 0576/1517
[A[ATraining Step: 691  | total loss: [1m[32m0.08419[0m[0m | time: 227.502s
[2K
| Adam | epoch: 015 | loss: 0.08419 - acc: 0.9672 -- iter: 0608/1517
[A[ATraining Step: 692  | total loss: [1m[32m0.08715[0m[0m | time: 240.806s
[2K
| Adam | epoch: 015 | loss: 0.08715 - acc: 0.9611 -- iter: 0640/1517
[A[ATraining Step: 693  | total loss: [1m[32m0.08514[0m[0m | time: 255.389s
[2K
| Adam | epoch: 015 | loss: 0.08514 - acc: 0.9587 -- iter: 0672/1517
[A[ATraining Step: 694  | total loss: [1m[32m0.09508[0m[0m | time: 269.603s
[2K
| Adam | epoch: 015 | loss: 0.09508 - acc: 0.9597 -- iter: 0704/1517
[A[ATraining Step: 695  | total loss: [1m[32m0.10836[0m[0m | time: 283.558s
[2K
| Adam | epoch: 015 | loss: 0.10836 - acc: 0.9513 -- iter: 0736/1517
[A[ATraining Step: 696  | total loss: [1m[32m0.12231[0m[0m | time: 297.644s
[2K
| Adam | epoch: 015 | loss: 0.12231 - acc: 0.9436 -- iter: 0768/1517
[A[ATraining Step: 697  | total loss: [1m[32m0.11370[0m[0m | time: 309.764s
[2K
| Adam | epoch: 015 | loss: 0.11370 - acc: 0.9493 -- iter: 0800/1517
[A[ATraining Step: 698  | total loss: [1m[32m0.12653[0m[0m | time: 317.746s
[2K
| Adam | epoch: 015 | loss: 0.12653 - acc: 0.9481 -- iter: 0832/1517
[A[ATraining Step: 699  | total loss: [1m[32m0.13185[0m[0m | time: 325.678s
[2K
| Adam | epoch: 015 | loss: 0.13185 - acc: 0.9439 -- iter: 0864/1517
[A[ATraining Step: 700  | total loss: [1m[32m0.13367[0m[0m | time: 334.935s
[2K
| Adam | epoch: 015 | loss: 0.13367 - acc: 0.9433 -- iter: 0896/1517
[A[ATraining Step: 701  | total loss: [1m[32m0.12824[0m[0m | time: 346.792s
[2K
| Adam | epoch: 015 | loss: 0.12824 - acc: 0.9458 -- iter: 0928/1517
[A[ATraining Step: 702  | total loss: [1m[32m0.12774[0m[0m | time: 358.609s
[2K
| Adam | epoch: 015 | loss: 0.12774 - acc: 0.9481 -- iter: 0960/1517
[A[ATraining Step: 703  | total loss: [1m[32m0.13716[0m[0m | time: 371.683s
[2K
| Adam | epoch: 015 | loss: 0.13716 - acc: 0.9439 -- iter: 0992/1517
[A[ATraining Step: 704  | total loss: [1m[32m0.12849[0m[0m | time: 384.793s
[2K
| Adam | epoch: 015 | loss: 0.12849 - acc: 0.9495 -- iter: 1024/1517
[A[ATraining Step: 705  | total loss: [1m[32m0.12111[0m[0m | time: 397.563s
[2K
| Adam | epoch: 015 | loss: 0.12111 - acc: 0.9515 -- iter: 1056/1517
[A[ATraining Step: 706  | total loss: [1m[32m0.13238[0m[0m | time: 410.320s
[2K
| Adam | epoch: 015 | loss: 0.13238 - acc: 0.9469 -- iter: 1088/1517
[A[ATraining Step: 707  | total loss: [1m[32m0.12548[0m[0m | time: 423.259s
[2K
| Adam | epoch: 015 | loss: 0.12548 - acc: 0.9491 -- iter: 1120/1517
[A[ATraining Step: 708  | total loss: [1m[32m0.13810[0m[0m | time: 436.385s
[2K
| Adam | epoch: 015 | loss: 0.13810 - acc: 0.9448 -- iter: 1152/1517
[A[ATraining Step: 709  | total loss: [1m[32m0.12949[0m[0m | time: 448.856s
[2K
| Adam | epoch: 015 | loss: 0.12949 - acc: 0.9503 -- iter: 1184/1517
[A[ATraining Step: 710  | total loss: [1m[32m0.12020[0m[0m | time: 461.669s
[2K
| Adam | epoch: 015 | loss: 0.12020 - acc: 0.9522 -- iter: 1216/1517
[A[ATraining Step: 711  | total loss: [1m[32m0.11151[0m[0m | time: 474.287s
[2K
| Adam | epoch: 015 | loss: 0.11151 - acc: 0.9570 -- iter: 1248/1517
[A[ATraining Step: 712  | total loss: [1m[32m0.10728[0m[0m | time: 487.207s
[2K
| Adam | epoch: 015 | loss: 0.10728 - acc: 0.9613 -- iter: 1280/1517
[A[ATraining Step: 713  | total loss: [1m[32m0.10898[0m[0m | time: 500.229s
[2K
| Adam | epoch: 015 | loss: 0.10898 - acc: 0.9589 -- iter: 1312/1517
[A[ATraining Step: 714  | total loss: [1m[32m0.11785[0m[0m | time: 513.089s
[2K
| Adam | epoch: 015 | loss: 0.11785 - acc: 0.9599 -- iter: 1344/1517
[A[ATraining Step: 715  | total loss: [1m[32m0.11164[0m[0m | time: 526.335s
[2K
| Adam | epoch: 015 | loss: 0.11164 - acc: 0.9608 -- iter: 1376/1517
[A[ATraining Step: 716  | total loss: [1m[32m0.11035[0m[0m | time: 539.379s
[2K
| Adam | epoch: 015 | loss: 0.11035 - acc: 0.9584 -- iter: 1408/1517
[A[ATraining Step: 717  | total loss: [1m[32m0.10040[0m[0m | time: 552.246s
[2K
| Adam | epoch: 015 | loss: 0.10040 - acc: 0.9626 -- iter: 1440/1517
[A[ATraining Step: 718  | total loss: [1m[32m0.10407[0m[0m | time: 565.863s
[2K
| Adam | epoch: 015 | loss: 0.10407 - acc: 0.9601 -- iter: 1472/1517
[A[ATraining Step: 719  | total loss: [1m[32m0.10140[0m[0m | time: 579.154s
[2K
| Adam | epoch: 015 | loss: 0.10140 - acc: 0.9610 -- iter: 1504/1517
[A[ATraining Step: 720  | total loss: [1m[32m0.11686[0m[0m | time: 627.051s
[2K
| Adam | epoch: 015 | loss: 0.11686 - acc: 0.9586 | val_loss: 0.78098 - val_acc: 0.7600 -- iter: 1517/1517
--
Validation AUC:0.8729290626002066
Validation AUPRC:0.867048534190299
Test AUC:0.8927997715346446
Test AUPRC:0.8980264946482679
BestTestF1Score	0.83	0.62	0.81	0.79	0.88	226	59	159	31	0.69
BestTestMCCScore	0.8	0.62	0.8	0.9	0.72	184	21	197	73	0.97
BestTestAccuracyScore	0.8	0.62	0.8	0.9	0.72	184	21	197	73	0.97
BestValidationF1Score	0.79	0.58	0.79	0.73	0.85	188	68	186	33	0.69
BestValidationMCC	0.77	0.6	0.8	0.84	0.71	157	31	223	64	0.97
BestValidationAccuracy	0.77	0.6	0.8	0.84	0.71	157	31	223	64	0.97
TestPredictions (Threshold:0.97)
CHEMBL102622,TN,INACT,0.41999998688697815	CHEMBL1277663,TN,INACT,0.23000000417232513	CHEMBL1950292,FN,ACT,0.699999988079071	CHEMBL2204105,FN,ACT,0.8600000143051147	CHEMBL300936,TN,INACT,0.1599999964237213	CHEMBL3680491,TN,INACT,0.3100000023841858	CHEMBL2420558,TP,ACT,1.0	CHEMBL3674709,TP,ACT,0.9800000190734863	CHEMBL375795,TP,ACT,1.0	CHEMBL77002,TN,INACT,0.11999999731779099	CHEMBL1783493,FN,ACT,0.9599999785423279	CHEMBL3655582,FN,ACT,0.9300000071525574	CHEMBL3679475,TP,ACT,1.0	CHEMBL245334,TP,ACT,1.0	CHEMBL3746969,TP,ACT,1.0	CHEMBL3674711,TP,ACT,1.0	CHEMBL2420556,TP,ACT,1.0	CHEMBL9352,TN,INACT,0.0	CHEMBL3217993,TN,INACT,0.03999999910593033	CHEMBL209740,TP,ACT,1.0	CHEMBL384951,TP,ACT,1.0	CHEMBL395077,TN,INACT,0.03999999910593033	CHEMBL1910628,TN,INACT,0.8999999761581421	CHEMBL242651,TP,ACT,1.0	CHEMBL2163608,TN,INACT,0.6899999976158142	CHEMBL3693949,TN,INACT,0.14000000059604645	CHEMBL3104852,TN,INACT,0.029999999329447746	CHEMBL220607,FN,ACT,0.8500000238418579	CHEMBL345639,TN,INACT,0.10999999940395355	CHEMBL3577869,TP,ACT,0.9900000095367432	CHEMBL2153261,TN,INACT,0.009999999776482582	CHEMBL3421974,TN,INACT,0.05000000074505806	CHEMBL1644640,FN,ACT,0.36000001430511475	CHEMBL2392235,TN,INACT,0.029999999329447746	CHEMBL3665663,TN,INACT,0.0	CHEMBL3109955,TN,INACT,0.18000000715255737	CHEMBL159149,TN,INACT,0.11999999731779099	CHEMBL50226,TN,INACT,0.07999999821186066	CHEMBL2420567,FN,ACT,0.7300000190734863	CHEMBL1440703,FP,INACT,0.9900000095367432	CHEMBL1783496,TP,ACT,1.0	CHEMBL571525,TN,INACT,0.949999988079071	CHEMBL3674703,TP,ACT,1.0	CHEMBL484326,TP,ACT,1.0	CHEMBL2376914,FN,ACT,0.9300000071525574	CHEMBL3679583,TP,ACT,0.9900000095367432	CHEMBL2204108,TP,ACT,1.0	CHEMBL1910757,TN,INACT,0.1899999976158142	CHEMBL3679565,TP,ACT,1.0	CHEMBL1923192,TP,ACT,1.0	CHEMBL377408,TP,ACT,1.0	CHEMBL210655,TP,ACT,1.0	CHEMBL1784649,TN,INACT,0.0	CHEMBL1429633,TN,INACT,0.7599999904632568	CHEMBL3679504,TP,ACT,1.0	CHEMBL3393607,FN,ACT,0.5199999809265137	CHEMBL1950304,TP,ACT,1.0	CHEMBL174634,TN,INACT,0.10000000149011612	CHEMBL218194,TP,ACT,1.0	CHEMBL3691604,FP,INACT,1.0	CHEMBL3640056,FN,ACT,0.9200000166893005	CHEMBL2071609,FP,INACT,0.9700000286102295	CHEMBL3640052,TP,ACT,1.0	CHEMBL206466,TP,ACT,1.0	CHEMBL246356,TN,INACT,0.3400000035762787	CHEMBL221075,FN,ACT,0.8600000143051147	CHEMBL284125,TN,INACT,0.7699999809265137	CHEMBL3679483,TP,ACT,1.0	CHEMBL2392827,TP,ACT,1.0	CHEMBL3679427,TP,ACT,1.0	CHEMBL525921,TN,INACT,0.0	CHEMBL1946328,TP,ACT,1.0	CHEMBL1784665,TP,ACT,0.9900000095367432	CHEMBL3628248,TN,INACT,0.6499999761581421	CHEMBL3355172,FN,ACT,0.9599999785423279	CHEMBL3679464,TP,ACT,1.0	CHEMBL1372214,TN,INACT,0.10999999940395355	CHEMBL372160,FP,INACT,1.0	CHEMBL208095,FN,ACT,0.8999999761581421	CHEMBL203839,FN,ACT,0.9300000071525574	CHEMBL456796,TN,INACT,0.0	CHEMBL1910602,TN,INACT,0.2199999988079071	CHEMBL207050,FN,ACT,0.9599999785423279	CHEMBL482559,FN,ACT,0.8999999761581421	CHEMBL3679494,TP,ACT,1.0	CHEMBL3640047,FN,ACT,0.8600000143051147	CHEMBL1767261,TP,ACT,1.0	CHEMBL258676,TP,ACT,1.0	CHEMBL188282,TN,INACT,0.7799999713897705	CHEMBL2420588,FN,ACT,0.11999999731779099	CHEMBL2346665,TN,INACT,0.03999999910593033	CHEMBL576353,TN,INACT,0.0	CHEMBL3193799,TN,INACT,0.0	CHEMBL3679433,TP,ACT,1.0	CHEMBL236279,TN,INACT,0.800000011920929	CHEMBL1682004,TP,ACT,0.9900000095367432	CHEMBL1946337,TP,ACT,1.0	CHEMBL484274,TN,INACT,0.0	CHEMBL3342928,TP,ACT,1.0	CHEMBL208558,TP,ACT,1.0	CHEMBL492828,TN,INACT,0.11999999731779099	CHEMBL388978,FN,ACT,0.7799999713897705	CHEMBL2059859,FP,INACT,0.9900000095367432	CHEMBL1436125,TN,INACT,0.6000000238418579	CHEMBL1574263,TN,INACT,0.6700000166893005	CHEMBL1288214,TP,ACT,1.0	CHEMBL499521,TN,INACT,0.9200000166893005	CHEMBL3355168,FN,ACT,0.05000000074505806	CHEMBL178468,TN,INACT,0.699999988079071	CHEMBL609039,FN,ACT,0.30000001192092896	CHEMBL2392834,TP,ACT,1.0	CHEMBL3628257,TN,INACT,0.009999999776482582	CHEMBL345348,TN,INACT,0.009999999776482582	CHEMBL3355159,TP,ACT,1.0	CHEMBL3577871,TP,ACT,1.0	CHEMBL1873703,TN,INACT,0.9599999785423279	CHEMBL3679584,TP,ACT,1.0	CHEMBL3342913,TP,ACT,0.9900000095367432	CHEMBL3679588,TP,ACT,1.0	CHEMBL1438559,TN,INACT,0.18000000715255737	CHEMBL2420581,TP,ACT,0.9700000286102295	CHEMBL1950043,FP,INACT,1.0	CHEMBL3679436,TP,ACT,1.0	CHEMBL1946327,TP,ACT,1.0	CHEMBL3628254,TN,INACT,0.0	CHEMBL2059872,FP,INACT,1.0	CHEMBL1319281,TN,INACT,0.5400000214576721	CHEMBL3679571,TP,ACT,1.0	CHEMBL236487,FP,INACT,1.0	CHEMBL2392369,TN,INACT,0.5	CHEMBL1822151,TP,ACT,1.0	CHEMBL3640055,FN,ACT,0.9300000071525574	CHEMBL1910629,TN,INACT,0.8399999737739563	CHEMBL407956,FN,ACT,0.9599999785423279	CHEMBL3355169,TP,ACT,1.0	CHEMBL1410917,TN,INACT,0.029999999329447746	CHEMBL1517409,TN,INACT,0.9599999785423279	CHEMBL131382,TN,INACT,0.009999999776482582	CHEMBL236937,TN,INACT,0.0	CHEMBL2204094,TP,ACT,1.0	CHEMBL204757,TP,ACT,1.0	CHEMBL3781795,TN,INACT,0.07999999821186066	CHEMBL1950293,TP,ACT,1.0	CHEMBL1644636,TP,ACT,1.0	CHEMBL395839,TN,INACT,0.0	CHEMBL3640068,TP,ACT,0.9900000095367432	CHEMBL1345738,TN,INACT,0.03999999910593033	CHEMBL463116,TP,ACT,1.0	CHEMBL3609568,FP,INACT,0.9800000190734863	CHEMBL2177818,FP,INACT,1.0	CHEMBL209769,TP,ACT,0.9900000095367432	CHEMBL1241935,TN,INACT,0.0	CHEMBL3109933,FP,INACT,1.0	CHEMBL1946336,TP,ACT,1.0	CHEMBL377201,TP,ACT,1.0	CHEMBL1089007,FN,ACT,0.6299999952316284	CHEMBL2398100,TN,INACT,0.019999999552965164	CHEMBL403233,TN,INACT,0.009999999776482582	CHEMBL2391118,TN,INACT,0.49000000953674316	CHEMBL3674716,TP,ACT,1.0	CHEMBL208877,TP,ACT,1.0	CHEMBL2392241,TN,INACT,0.5899999737739563	CHEMBL1242367,TN,INACT,0.8799999952316284	CHEMBL1092764,FN,ACT,0.8600000143051147	CHEMBL3679503,TP,ACT,1.0	CHEMBL377747,FN,ACT,0.8299999833106995	CHEMBL1783592,TP,ACT,0.9900000095367432	CHEMBL412278,TN,INACT,0.009999999776482582	CHEMBL3745772,TN,INACT,0.0	CHEMBL3640058,TP,ACT,1.0	CHEMBL1644641,TP,ACT,1.0	CHEMBL3680499,TN,INACT,0.5299999713897705	CHEMBL3628364,TN,INACT,0.0	CHEMBL334248,FP,INACT,1.0	CHEMBL2163616,FP,INACT,1.0	CHEMBL3674734,TP,ACT,1.0	CHEMBL312065,TN,INACT,0.7099999785423279	CHEMBL2089253,TP,ACT,1.0	CHEMBL221126,TP,ACT,1.0	CHEMBL1767283,TP,ACT,1.0	CHEMBL541445,TN,INACT,0.07000000029802322	CHEMBL101557,TN,INACT,0.14000000059604645	CHEMBL194009,TN,INACT,0.0	CHEMBL3679543,TP,ACT,1.0	CHEMBL444877,TN,INACT,0.03999999910593033	CHEMBL1928704,TN,INACT,0.5799999833106995	CHEMBL557456,TN,INACT,0.029999999329447746	CHEMBL1923191,TP,ACT,1.0	CHEMBL2111784,FN,ACT,0.009999999776482582	CHEMBL3674736,TP,ACT,1.0	CHEMBL259041,TN,INACT,0.0	CHEMBL3577857,FN,ACT,0.8500000238418579	CHEMBL2334799,TN,INACT,0.029999999329447746	CHEMBL219112,FN,ACT,0.8500000238418579	CHEMBL520488,TP,ACT,0.9900000095367432	CHEMBL100811,TN,INACT,0.0	CHEMBL3355175,TP,ACT,0.9800000190734863	CHEMBL1923190,TP,ACT,0.9800000190734863	CHEMBL2024347,TN,INACT,0.019999999552965164	CHEMBL220811,FN,ACT,0.8399999737739563	CHEMBL3214457,TN,INACT,0.28999999165534973	CHEMBL3679440,TP,ACT,1.0	CHEMBL1527476,TN,INACT,0.5299999713897705	CHEMBL226471,TN,INACT,0.14000000059604645	CHEMBL3674718,TP,ACT,0.9700000286102295	CHEMBL1584161,TP,ACT,1.0	CHEMBL3661096,FP,INACT,1.0	CHEMBL1320813,TN,INACT,0.029999999329447746	CHEMBL453336,TN,INACT,0.23000000417232513	CHEMBL572922,TN,INACT,0.07999999821186066	CHEMBL243297,TP,ACT,1.0	CHEMBL188606,FN,ACT,0.9399999976158142	CHEMBL261086,FN,ACT,0.009999999776482582	CHEMBL1910608,TN,INACT,0.0	CHEMBL3679581,TP,ACT,1.0	CHEMBL1288039,FN,ACT,0.009999999776482582	CHEMBL2391127,TN,INACT,0.0	CHEMBL1784085,TP,ACT,1.0	CHEMBL220812,TP,ACT,1.0	CHEMBL1922205,TN,INACT,0.20000000298023224	CHEMBL207861,TP,ACT,0.9900000095367432	CHEMBL3674702,TP,ACT,1.0	CHEMBL3679486,TP,ACT,1.0	CHEMBL3679534,TP,ACT,1.0	CHEMBL64040,FN,ACT,0.25999999046325684	CHEMBL1802609,TN,INACT,0.7099999785423279	CHEMBL3679474,TP,ACT,1.0	CHEMBL209136,TP,ACT,1.0	CHEMBL120185,FN,ACT,0.5099999904632568	CHEMBL1783587,TP,ACT,1.0	CHEMBL451532,TN,INACT,0.029999999329447746	CHEMBL2380575,FN,ACT,0.46000000834465027	CHEMBL521551,TN,INACT,0.0	CHEMBL2204110,TP,ACT,0.9900000095367432	CHEMBL422714,TN,INACT,0.019999999552965164	CHEMBL1644633,TP,ACT,1.0	CHEMBL1288156,TP,ACT,0.9900000095367432	CHEMBL3400830,FP,INACT,0.9900000095367432	CHEMBL3781939,TN,INACT,0.20000000298023224	CHEMBL3355150,TP,ACT,1.0	CHEMBL1089405,TN,INACT,0.4399999976158142	CHEMBL485878,TN,INACT,0.23000000417232513	CHEMBL1761555,TP,ACT,0.9700000286102295	CHEMBL599110,FN,ACT,0.7799999713897705	CHEMBL215943,FN,ACT,0.6100000143051147	CHEMBL1922121,TN,INACT,0.8700000047683716	CHEMBL3679522,TP,ACT,1.0	CHEMBL3670430,TN,INACT,0.019999999552965164	CHEMBL2380580,FN,ACT,0.7799999713897705	CHEMBL3640048,TP,ACT,1.0	CHEMBL2163611,TN,INACT,0.8100000023841858	CHEMBL3674732,TP,ACT,1.0	CHEMBL207051,TP,ACT,0.9900000095367432	CHEMBL116438,TN,INACT,0.009999999776482582	CHEMBL1922208,TN,INACT,0.009999999776482582	CHEMBL3679564,TP,ACT,1.0	CHEMBL2348165,TN,INACT,0.800000011920929	CHEMBL1511773,TN,INACT,0.009999999776482582	CHEMBL197613,TP,ACT,1.0	CHEMBL2153267,TN,INACT,0.5	CHEMBL1767273,FN,ACT,0.5199999809265137	CHEMBL3609569,TN,INACT,0.25	CHEMBL3679497,TP,ACT,1.0	CHEMBL1784097,FN,ACT,0.7300000190734863	CHEMBL2334791,TN,INACT,0.0	CHEMBL3747699,TP,ACT,1.0	CHEMBL469776,TN,INACT,0.019999999552965164	CHEMBL3679510,TP,ACT,1.0	CHEMBL1822137,TP,ACT,1.0	CHEMBL259084,FP,INACT,1.0	CHEMBL202639,TP,ACT,1.0	CHEMBL504550,TN,INACT,0.9300000071525574	CHEMBL457401,TN,INACT,0.03999999910593033	CHEMBL1681791,TP,ACT,0.9900000095367432	CHEMBL2392390,TN,INACT,0.0	CHEMBL99699,TN,INACT,0.2199999988079071	CHEMBL2392366,TN,INACT,0.2199999988079071	CHEMBL2392375,TN,INACT,0.4000000059604645	CHEMBL379414,TP,ACT,1.0	CHEMBL1287858,TP,ACT,1.0	CHEMBL2420577,FN,ACT,0.15000000596046448	CHEMBL259040,TN,INACT,0.17000000178813934	CHEMBL3393600,FN,ACT,0.33000001311302185	CHEMBL59009,TN,INACT,0.10999999940395355	CHEMBL517340,TP,ACT,1.0	CHEMBL1923185,TP,ACT,1.0	CHEMBL246545,TP,ACT,1.0	CHEMBL485502,TN,INACT,0.0	CHEMBL101868,TN,INACT,0.05999999865889549	CHEMBL1644622,TP,ACT,1.0	CHEMBL1784086,FN,ACT,0.9399999976158142	CHEMBL1093745,TN,INACT,0.0	CHEMBL1425417,TN,INACT,0.8600000143051147	CHEMBL230806,TN,INACT,0.9200000166893005	CHEMBL245925,TP,ACT,1.0	CHEMBL1644624,TP,ACT,1.0	CHEMBL244581,TP,ACT,1.0	CHEMBL1644634,TP,ACT,1.0	CHEMBL1288966,TP,ACT,0.9900000095367432	CHEMBL1681996,TP,ACT,1.0	CHEMBL1783589,TP,ACT,1.0	CHEMBL450660,TP,ACT,1.0	CHEMBL1822309,FN,ACT,0.9200000166893005	CHEMBL151,TN,INACT,0.0	CHEMBL437107,TP,ACT,1.0	CHEMBL3679511,TP,ACT,1.0	CHEMBL464551,TP,ACT,1.0	CHEMBL3355183,FN,ACT,0.5099999904632568	CHEMBL3679541,TP,ACT,1.0	CHEMBL97844,TN,INACT,0.009999999776482582	CHEMBL495233,TP,ACT,1.0	CHEMBL2029510,TN,INACT,0.3700000047683716	CHEMBL1439904,TN,INACT,0.0	CHEMBL187845,TP,ACT,1.0	CHEMBL498249,TN,INACT,0.8500000238418579	CHEMBL1946647,TP,ACT,1.0	CHEMBL3402481,TN,INACT,0.0	CHEMBL188979,FN,ACT,0.949999988079071	CHEMBL3679472,TP,ACT,1.0	CHEMBL1641799,TN,INACT,0.8799999952316284	CHEMBL3679496,TP,ACT,1.0	CHEMBL1975622,TN,INACT,0.28999999165534973	CHEMBL218367,TP,ACT,0.9800000190734863	CHEMBL3674697,TP,ACT,1.0	CHEMBL487737,TN,INACT,0.019999999552965164	CHEMBL399493,TN,INACT,0.4399999976158142	CHEMBL523586,TN,INACT,0.75	CHEMBL1644623,FN,ACT,0.8899999856948853	CHEMBL1377449,TN,INACT,0.029999999329447746	CHEMBL102047,TN,INACT,0.49000000953674316	CHEMBL1783584,TP,ACT,0.9800000190734863	CHEMBL259092,TP,ACT,1.0	CHEMBL3679580,TP,ACT,1.0	CHEMBL482753,TP,ACT,1.0	CHEMBL3355184,FN,ACT,0.6100000143051147	CHEMBL221315,TP,ACT,0.9800000190734863	CHEMBL3679450,TP,ACT,1.0	CHEMBL3640045,FN,ACT,0.949999988079071	CHEMBL239785,FN,ACT,0.8700000047683716	CHEMBL603494,TN,INACT,0.05999999865889549	CHEMBL497196,TN,INACT,0.029999999329447746	CHEMBL3679443,TP,ACT,1.0	CHEMBL269881,TN,INACT,0.20000000298023224	CHEMBL210363,FN,ACT,0.8399999737739563	CHEMBL2207946,TN,INACT,0.03999999910593033	CHEMBL2420560,TP,ACT,1.0	CHEMBL386051,TP,ACT,1.0	CHEMBL3679562,TP,ACT,1.0	CHEMBL1910630,TN,INACT,0.9300000071525574	CHEMBL116211,TN,INACT,0.0	CHEMBL200796,TN,INACT,0.7400000095367432	CHEMBL2392242,TN,INACT,0.5899999737739563	CHEMBL1288038,FN,ACT,0.9599999785423279	CHEMBL2059867,TN,INACT,0.07999999821186066	CHEMBL1761567,FN,ACT,0.8500000238418579	CHEMBL571626,FN,ACT,0.800000011920929	CHEMBL1392612,TN,INACT,0.05999999865889549	CHEMBL1910193,TN,INACT,0.3199999928474426	CHEMBL260429,FN,ACT,0.6800000071525574	CHEMBL88962,TN,INACT,0.1899999976158142	CHEMBL1765740,TN,INACT,0.8199999928474426	CHEMBL2334797,TN,INACT,0.0	CHEMBL95477,TN,INACT,0.05000000074505806	CHEMBL378955,TP,ACT,0.9900000095367432	CHEMBL3679445,FN,ACT,0.07999999821186066	CHEMBL150894,FN,ACT,0.4099999964237213	CHEMBL604748,TN,INACT,0.07000000029802322	CHEMBL1923187,TP,ACT,1.0	CHEMBL38380,TN,INACT,0.18000000715255737	CHEMBL1096292,TN,INACT,0.0	CHEMBL450919,TP,ACT,1.0	CHEMBL2425646,TP,ACT,1.0	CHEMBL1784666,TP,ACT,0.9800000190734863	CHEMBL3674713,TP,ACT,0.9800000190734863	CHEMBL1789941,FN,ACT,0.550000011920929	CHEMBL120127,TN,INACT,0.8999999761581421	CHEMBL2158866,TN,INACT,0.5699999928474426	CHEMBL2380582,TP,ACT,1.0	CHEMBL570554,FN,ACT,0.7799999713897705	CHEMBL1761565,FN,ACT,0.9300000071525574	CHEMBL472566,TN,INACT,0.009999999776482582	CHEMBL1767267,FN,ACT,0.3100000023841858	CHEMBL1094014,FN,ACT,0.18000000715255737	CHEMBL2425631,TP,ACT,1.0	CHEMBL367442,TN,INACT,0.9300000071525574	CHEMBL220864,TP,ACT,1.0	CHEMBL2392828,TP,ACT,1.0	CHEMBL2152387,FN,ACT,0.20000000298023224	CHEMBL345800,TN,INACT,0.3100000023841858	CHEMBL1761563,TP,ACT,0.9900000095367432	CHEMBL3679579,TP,ACT,0.9900000095367432	CHEMBL2164696,TN,INACT,0.009999999776482582	CHEMBL3109937,TN,INACT,0.6700000166893005	CHEMBL3356452,TN,INACT,0.009999999776482582	CHEMBL309078,TN,INACT,0.3199999928474426	CHEMBL2401963,TN,INACT,0.9200000166893005	CHEMBL1641793,TN,INACT,0.30000001192092896	CHEMBL1461987,TN,INACT,0.07000000029802322	CHEMBL3679576,TP,ACT,0.9900000095367432	CHEMBL1331525,TN,INACT,0.14000000059604645	CHEMBL1374204,TN,INACT,0.6800000071525574	CHEMBL170993,TN,INACT,0.11999999731779099	CHEMBL266540,TN,INACT,0.8999999761581421	CHEMBL3640064,TP,ACT,1.0	CHEMBL345801,TN,INACT,0.0	CHEMBL1767274,FN,ACT,0.44999998807907104	CHEMBL1644629,FN,ACT,0.17000000178813934	CHEMBL1682020,TP,ACT,1.0	CHEMBL1548132,TN,INACT,0.009999999776482582	CHEMBL482919,TN,INACT,0.36000001430511475	CHEMBL3639783,TP,ACT,1.0	CHEMBL1688214,TN,INACT,0.009999999776482582	CHEMBL3679447,TP,ACT,1.0	CHEMBL1345922,FP,INACT,1.0	CHEMBL603469,TP,ACT,1.0	CHEMBL1923198,TP,ACT,0.9800000190734863	CHEMBL1767237,TP,ACT,1.0	CHEMBL3679528,TP,ACT,1.0	CHEMBL210804,FN,ACT,0.38999998569488525	CHEMBL524820,TN,INACT,0.05999999865889549	CHEMBL343821,TN,INACT,0.0	CHEMBL392613,TP,ACT,1.0	CHEMBL495406,TP,ACT,0.9900000095367432	CHEMBL2334789,TN,INACT,0.0	CHEMBL245935,TP,ACT,1.0	CHEMBL3679505,TP,ACT,1.0	CHEMBL2425642,TP,ACT,1.0	CHEMBL386010,TP,ACT,1.0	CHEMBL3679478,TP,ACT,1.0	CHEMBL1287944,TP,ACT,0.9800000190734863	CHEMBL1922219,TN,INACT,0.009999999776482582	CHEMBL77267,TN,INACT,0.0	CHEMBL1432472,FP,INACT,1.0	CHEMBL1644617,TN,INACT,0.5199999809265137	CHEMBL3342915,FN,ACT,0.27000001072883606	CHEMBL460472,TN,INACT,0.4399999976158142	CHEMBL486302,TN,INACT,0.800000011920929	CHEMBL1233749,FN,ACT,0.7200000286102295	CHEMBL1928684,FP,INACT,1.0	CHEMBL3674721,TP,ACT,0.9900000095367432	CHEMBL1288582,TN,INACT,0.10999999940395355	CHEMBL3680492,FP,INACT,1.0	CHEMBL243519,TP,ACT,1.0	CHEMBL486285,TN,INACT,0.0	CHEMBL1950290,TP,ACT,0.9700000286102295	CHEMBL1287915,TP,ACT,1.0	CHEMBL220658,TP,ACT,1.0	CHEMBL1459123,TN,INACT,0.36000001430511475	CHEMBL1448,TN,INACT,0.0	CHEMBL133477,TN,INACT,0.9599999785423279	CHEMBL377991,TP,ACT,1.0	CHEMBL1822308,FN,ACT,0.8700000047683716	CHEMBL1784090,TP,ACT,1.0	CHEMBL425413,TP,ACT,1.0	CHEMBL458076,TN,INACT,0.14000000059604645	CHEMBL1767251,TP,ACT,0.9900000095367432	CHEMBL3655587,TP,ACT,1.0	CHEMBL1470122,TN,INACT,0.33000001311302185	CHEMBL1802781,TN,INACT,0.12999999523162842	CHEMBL1414184,TN,INACT,0.8999999761581421	CHEMBL1582724,TN,INACT,0.4699999988079071	CHEMBL3199093,TN,INACT,0.7400000095367432	CHEMBL602232,TN,INACT,0.46000000834465027	CHEMBL2207940,TN,INACT,0.009999999776482582	CHEMBL2059871,TN,INACT,0.949999988079071	CHEMBL3577856,FN,ACT,0.30000001192092896	CHEMBL346721,FP,INACT,0.9800000190734863	CHEMBL1822133,FN,ACT,0.699999988079071	CHEMBL1558177,TN,INACT,0.009999999776482582	CHEMBL1688212,TN,INACT,0.949999988079071	CHEMBL496778,TN,INACT,0.17000000178813934	CHEMBL380724,TP,ACT,1.0	CHEMBL2380578,FN,ACT,0.23999999463558197	CHEMBL1359999,TN,INACT,0.8299999833106995	CHEMBL1806525,TN,INACT,0.949999988079071	

