CNNModel CHEMBL335 adam 0.0001 30 256 0 0.6 False True
Number of active compounds :	1074
Number of inactive compounds :	716
---------------------------------
Run id: CNNModel_CHEMBL335_adam_0.0001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL335_adam_0.0001_30_256_0.6_True/
---------------------------------
Training samples: 1140
Validation samples: 357
--
Training Step: 1  | time: 1.591s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1140
[A[ATraining Step: 2  | total loss: [1m[32m0.62389[0m[0m | time: 2.824s
[2K
| Adam | epoch: 001 | loss: 0.62389 - acc: 0.3656 -- iter: 0064/1140
[A[ATraining Step: 3  | total loss: [1m[32m0.68049[0m[0m | time: 4.119s
[2K
| Adam | epoch: 001 | loss: 0.68049 - acc: 0.5011 -- iter: 0096/1140
[A[ATraining Step: 4  | total loss: [1m[32m0.69010[0m[0m | time: 5.374s
[2K
| Adam | epoch: 001 | loss: 0.69010 - acc: 0.4768 -- iter: 0128/1140
[A[ATraining Step: 5  | total loss: [1m[32m0.69223[0m[0m | time: 6.653s
[2K
| Adam | epoch: 001 | loss: 0.69223 - acc: 0.4929 -- iter: 0160/1140
[A[ATraining Step: 6  | total loss: [1m[32m0.69217[0m[0m | time: 7.842s
[2K
| Adam | epoch: 001 | loss: 0.69217 - acc: 0.5376 -- iter: 0192/1140
[A[ATraining Step: 7  | total loss: [1m[32m0.69263[0m[0m | time: 9.064s
[2K
| Adam | epoch: 001 | loss: 0.69263 - acc: 0.5338 -- iter: 0224/1140
[A[ATraining Step: 8  | total loss: [1m[32m0.69236[0m[0m | time: 10.421s
[2K
| Adam | epoch: 001 | loss: 0.69236 - acc: 0.5324 -- iter: 0256/1140
[A[ATraining Step: 9  | total loss: [1m[32m0.69230[0m[0m | time: 11.747s
[2K
| Adam | epoch: 001 | loss: 0.69230 - acc: 0.5483 -- iter: 0288/1140
[A[ATraining Step: 10  | total loss: [1m[32m0.69060[0m[0m | time: 13.235s
[2K
| Adam | epoch: 001 | loss: 0.69060 - acc: 0.6179 -- iter: 0320/1140
[A[ATraining Step: 11  | total loss: [1m[32m0.68959[0m[0m | time: 19.163s
[2K
| Adam | epoch: 001 | loss: 0.68959 - acc: 0.6509 -- iter: 0352/1140
[A[ATraining Step: 12  | total loss: [1m[32m0.68981[0m[0m | time: 27.005s
[2K
| Adam | epoch: 001 | loss: 0.68981 - acc: 0.6252 -- iter: 0384/1140
[A[ATraining Step: 13  | total loss: [1m[32m0.69159[0m[0m | time: 28.024s
[2K
| Adam | epoch: 001 | loss: 0.69159 - acc: 0.5715 -- iter: 0416/1140
[A[ATraining Step: 14  | total loss: [1m[32m0.69114[0m[0m | time: 29.252s
[2K
| Adam | epoch: 001 | loss: 0.69114 - acc: 0.5678 -- iter: 0448/1140
[A[ATraining Step: 15  | total loss: [1m[32m0.68983[0m[0m | time: 30.326s
[2K
| Adam | epoch: 001 | loss: 0.68983 - acc: 0.5780 -- iter: 0480/1140
[A[ATraining Step: 16  | total loss: [1m[32m0.68788[0m[0m | time: 31.464s
[2K
| Adam | epoch: 001 | loss: 0.68788 - acc: 0.5956 -- iter: 0512/1140
[A[ATraining Step: 17  | total loss: [1m[32m0.68661[0m[0m | time: 32.558s
[2K
| Adam | epoch: 001 | loss: 0.68661 - acc: 0.6062 -- iter: 0544/1140
[A[ATraining Step: 18  | total loss: [1m[32m0.68588[0m[0m | time: 33.762s
[2K
| Adam | epoch: 001 | loss: 0.68588 - acc: 0.6019 -- iter: 0576/1140
[A[ATraining Step: 19  | total loss: [1m[32m0.68197[0m[0m | time: 34.862s
[2K
| Adam | epoch: 001 | loss: 0.68197 - acc: 0.6200 -- iter: 0608/1140
[A[ATraining Step: 20  | total loss: [1m[32m0.68466[0m[0m | time: 36.080s
[2K
| Adam | epoch: 001 | loss: 0.68466 - acc: 0.5915 -- iter: 0640/1140
[A[ATraining Step: 21  | total loss: [1m[32m0.68204[0m[0m | time: 36.933s
[2K
| Adam | epoch: 001 | loss: 0.68204 - acc: 0.6019 -- iter: 0672/1140
[A[ATraining Step: 22  | total loss: [1m[32m0.67623[0m[0m | time: 37.856s
[2K
| Adam | epoch: 001 | loss: 0.67623 - acc: 0.6276 -- iter: 0704/1140
[A[ATraining Step: 23  | total loss: [1m[32m0.67178[0m[0m | time: 39.068s
[2K
| Adam | epoch: 001 | loss: 0.67178 - acc: 0.6359 -- iter: 0736/1140
[A[ATraining Step: 24  | total loss: [1m[32m0.65531[0m[0m | time: 40.123s
[2K
| Adam | epoch: 001 | loss: 0.65531 - acc: 0.6856 -- iter: 0768/1140
[A[ATraining Step: 25  | total loss: [1m[32m0.66596[0m[0m | time: 43.862s
[2K
| Adam | epoch: 001 | loss: 0.66596 - acc: 0.6435 -- iter: 0800/1140
[A[ATraining Step: 26  | total loss: [1m[32m0.67067[0m[0m | time: 51.757s
[2K
| Adam | epoch: 001 | loss: 0.67067 - acc: 0.6220 -- iter: 0832/1140
[A[ATraining Step: 27  | total loss: [1m[32m0.68136[0m[0m | time: 69.289s
[2K
| Adam | epoch: 001 | loss: 0.68136 - acc: 0.5907 -- iter: 0864/1140
[A[ATraining Step: 28  | total loss: [1m[32m0.68067[0m[0m | time: 77.082s
[2K
| Adam | epoch: 001 | loss: 0.68067 - acc: 0.5914 -- iter: 0896/1140
[A[ATraining Step: 29  | total loss: [1m[32m0.68593[0m[0m | time: 80.696s
[2K
| Adam | epoch: 001 | loss: 0.68593 - acc: 0.5768 -- iter: 0928/1140
[A[ATraining Step: 30  | total loss: [1m[32m0.67356[0m[0m | time: 81.910s
[2K
| Adam | epoch: 001 | loss: 0.67356 - acc: 0.6030 -- iter: 0960/1140
[A[ATraining Step: 31  | total loss: [1m[32m0.66646[0m[0m | time: 82.910s
[2K
| Adam | epoch: 001 | loss: 0.66646 - acc: 0.6153 -- iter: 0992/1140
[A[ATraining Step: 32  | total loss: [1m[32m0.67895[0m[0m | time: 83.915s
[2K
| Adam | epoch: 001 | loss: 0.67895 - acc: 0.5894 -- iter: 1024/1140
[A[ATraining Step: 33  | total loss: [1m[32m0.68543[0m[0m | time: 85.027s
[2K
| Adam | epoch: 001 | loss: 0.68543 - acc: 0.5766 -- iter: 1056/1140
[A[ATraining Step: 34  | total loss: [1m[32m0.66626[0m[0m | time: 86.143s
[2K
| Adam | epoch: 001 | loss: 0.66626 - acc: 0.6138 -- iter: 1088/1140
[A[ATraining Step: 35  | total loss: [1m[32m0.65611[0m[0m | time: 87.435s
[2K
| Adam | epoch: 001 | loss: 0.65611 - acc: 0.6357 -- iter: 1120/1140
[A[ATraining Step: 36  | total loss: [1m[32m0.65662[0m[0m | time: 90.667s
[2K
| Adam | epoch: 001 | loss: 0.65662 - acc: 0.6335 | val_loss: 0.67639 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 37  | total loss: [1m[32m0.64936[0m[0m | time: 9.541s
[2K
| Adam | epoch: 002 | loss: 0.64936 - acc: 0.6468 -- iter: 0032/1140
[A[ATraining Step: 38  | total loss: [1m[32m0.64364[0m[0m | time: 30.466s
[2K
| Adam | epoch: 002 | loss: 0.64364 - acc: 0.6572 -- iter: 0064/1140
[A[ATraining Step: 39  | total loss: [1m[32m0.65736[0m[0m | time: 49.348s
[2K
| Adam | epoch: 002 | loss: 0.65736 - acc: 0.6331 -- iter: 0096/1140
[A[ATraining Step: 40  | total loss: [1m[32m0.67242[0m[0m | time: 50.400s
[2K
| Adam | epoch: 002 | loss: 0.67242 - acc: 0.6082 -- iter: 0128/1140
[A[ATraining Step: 41  | total loss: [1m[32m0.67546[0m[0m | time: 51.490s
[2K
| Adam | epoch: 002 | loss: 0.67546 - acc: 0.6055 -- iter: 0160/1140
[A[ATraining Step: 42  | total loss: [1m[32m0.66683[0m[0m | time: 52.503s
[2K
| Adam | epoch: 002 | loss: 0.66683 - acc: 0.6203 -- iter: 0192/1140
[A[ATraining Step: 43  | total loss: [1m[32m0.67223[0m[0m | time: 53.731s
[2K
| Adam | epoch: 002 | loss: 0.67223 - acc: 0.6101 -- iter: 0224/1140
[A[ATraining Step: 44  | total loss: [1m[32m0.66738[0m[0m | time: 54.879s
[2K
| Adam | epoch: 002 | loss: 0.66738 - acc: 0.6181 -- iter: 0256/1140
[A[ATraining Step: 45  | total loss: [1m[32m0.67467[0m[0m | time: 56.090s
[2K
| Adam | epoch: 002 | loss: 0.67467 - acc: 0.6033 -- iter: 0288/1140
[A[ATraining Step: 46  | total loss: [1m[32m0.68504[0m[0m | time: 57.237s
[2K
| Adam | epoch: 002 | loss: 0.68504 - acc: 0.5809 -- iter: 0320/1140
[A[ATraining Step: 47  | total loss: [1m[32m0.68866[0m[0m | time: 58.600s
[2K
| Adam | epoch: 002 | loss: 0.68866 - acc: 0.5728 -- iter: 0352/1140
[A[ATraining Step: 48  | total loss: [1m[32m0.69531[0m[0m | time: 59.638s
[2K
| Adam | epoch: 002 | loss: 0.69531 - acc: 0.5561 -- iter: 0384/1140
[A[ATraining Step: 49  | total loss: [1m[32m0.69526[0m[0m | time: 60.867s
[2K
| Adam | epoch: 002 | loss: 0.69526 - acc: 0.5521 -- iter: 0416/1140
[A[ATraining Step: 50  | total loss: [1m[32m0.69016[0m[0m | time: 62.197s
[2K
| Adam | epoch: 002 | loss: 0.69016 - acc: 0.5634 -- iter: 0448/1140
[A[ATraining Step: 51  | total loss: [1m[32m0.69479[0m[0m | time: 63.365s
[2K
| Adam | epoch: 002 | loss: 0.69479 - acc: 0.5490 -- iter: 0480/1140
[A[ATraining Step: 52  | total loss: [1m[32m0.68521[0m[0m | time: 71.434s
[2K
| Adam | epoch: 002 | loss: 0.68521 - acc: 0.5791 -- iter: 0512/1140
[A[ATraining Step: 53  | total loss: [1m[32m0.68397[0m[0m | time: 75.970s
[2K
| Adam | epoch: 002 | loss: 0.68397 - acc: 0.5813 -- iter: 0544/1140
[A[ATraining Step: 54  | total loss: [1m[32m0.68327[0m[0m | time: 87.585s
[2K
| Adam | epoch: 002 | loss: 0.68327 - acc: 0.5831 -- iter: 0576/1140
[A[ATraining Step: 55  | total loss: [1m[32m0.68439[0m[0m | time: 89.379s
[2K
| Adam | epoch: 002 | loss: 0.68439 - acc: 0.5757 -- iter: 0608/1140
[A[ATraining Step: 56  | total loss: [1m[32m0.68318[0m[0m | time: 90.585s
[2K
| Adam | epoch: 002 | loss: 0.68318 - acc: 0.5782 -- iter: 0640/1140
[A[ATraining Step: 57  | total loss: [1m[32m0.67812[0m[0m | time: 91.589s
[2K
| Adam | epoch: 002 | loss: 0.67812 - acc: 0.5977 -- iter: 0672/1140
[A[ATraining Step: 58  | total loss: [1m[32m0.67902[0m[0m | time: 92.730s
[2K
| Adam | epoch: 002 | loss: 0.67902 - acc: 0.5929 -- iter: 0704/1140
[A[ATraining Step: 59  | total loss: [1m[32m0.68077[0m[0m | time: 93.899s
[2K
| Adam | epoch: 002 | loss: 0.68077 - acc: 0.5846 -- iter: 0736/1140
[A[ATraining Step: 60  | total loss: [1m[32m0.68361[0m[0m | time: 95.115s
[2K
| Adam | epoch: 002 | loss: 0.68361 - acc: 0.5734 -- iter: 0768/1140
[A[ATraining Step: 61  | total loss: [1m[32m0.67641[0m[0m | time: 96.320s
[2K
| Adam | epoch: 002 | loss: 0.67641 - acc: 0.6046 -- iter: 0800/1140
[A[ATraining Step: 62  | total loss: [1m[32m0.67684[0m[0m | time: 97.480s
[2K
| Adam | epoch: 002 | loss: 0.67684 - acc: 0.6032 -- iter: 0832/1140
[A[ATraining Step: 63  | total loss: [1m[32m0.67491[0m[0m | time: 98.759s
[2K
| Adam | epoch: 002 | loss: 0.67491 - acc: 0.6099 -- iter: 0864/1140
[A[ATraining Step: 64  | total loss: [1m[32m0.67334[0m[0m | time: 99.981s
[2K
| Adam | epoch: 002 | loss: 0.67334 - acc: 0.6157 -- iter: 0896/1140
[A[ATraining Step: 65  | total loss: [1m[32m0.66740[0m[0m | time: 101.342s
[2K
| Adam | epoch: 002 | loss: 0.66740 - acc: 0.6400 -- iter: 0928/1140
[A[ATraining Step: 66  | total loss: [1m[32m0.67132[0m[0m | time: 102.775s
[2K
| Adam | epoch: 002 | loss: 0.67132 - acc: 0.6230 -- iter: 0960/1140
[A[ATraining Step: 67  | total loss: [1m[32m0.67274[0m[0m | time: 116.136s
[2K
| Adam | epoch: 002 | loss: 0.67274 - acc: 0.6157 -- iter: 0992/1140
[A[ATraining Step: 68  | total loss: [1m[32m0.67074[0m[0m | time: 124.758s
[2K
| Adam | epoch: 002 | loss: 0.67074 - acc: 0.6205 -- iter: 1024/1140
[A[ATraining Step: 69  | total loss: [1m[32m0.67451[0m[0m | time: 133.675s
[2K
| Adam | epoch: 002 | loss: 0.67451 - acc: 0.6064 -- iter: 1056/1140
[A[ATraining Step: 70  | total loss: [1m[32m0.67461[0m[0m | time: 140.743s
[2K
| Adam | epoch: 002 | loss: 0.67461 - acc: 0.6050 -- iter: 1088/1140
[A[ATraining Step: 71  | total loss: [1m[32m0.66392[0m[0m | time: 141.794s
[2K
| Adam | epoch: 002 | loss: 0.66392 - acc: 0.6357 -- iter: 1120/1140
[A[ATraining Step: 72  | total loss: [1m[32m0.66407[0m[0m | time: 145.479s
[2K
| Adam | epoch: 002 | loss: 0.66407 - acc: 0.6345 | val_loss: 0.67363 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 73  | total loss: [1m[32m0.65976[0m[0m | time: 0.773s
[2K
| Adam | epoch: 003 | loss: 0.65976 - acc: 0.6439 -- iter: 0032/1140
[A[ATraining Step: 74  | total loss: [1m[32m0.66760[0m[0m | time: 1.448s
[2K
| Adam | epoch: 003 | loss: 0.66760 - acc: 0.6226 -- iter: 0064/1140
[A[ATraining Step: 75  | total loss: [1m[32m0.67540[0m[0m | time: 2.545s
[2K
| Adam | epoch: 003 | loss: 0.67540 - acc: 0.6039 -- iter: 0096/1140
[A[ATraining Step: 76  | total loss: [1m[32m0.67266[0m[0m | time: 3.688s
[2K
| Adam | epoch: 003 | loss: 0.67266 - acc: 0.6095 -- iter: 0128/1140
[A[ATraining Step: 77  | total loss: [1m[32m0.67904[0m[0m | time: 4.934s
[2K
| Adam | epoch: 003 | loss: 0.67904 - acc: 0.5946 -- iter: 0160/1140
[A[ATraining Step: 78  | total loss: [1m[32m0.68279[0m[0m | time: 6.317s
[2K
| Adam | epoch: 003 | loss: 0.68279 - acc: 0.5847 -- iter: 0192/1140
[A[ATraining Step: 79  | total loss: [1m[32m0.68481[0m[0m | time: 7.595s
[2K
| Adam | epoch: 003 | loss: 0.68481 - acc: 0.5792 -- iter: 0224/1140
[A[ATraining Step: 80  | total loss: [1m[32m0.67959[0m[0m | time: 8.967s
[2K
| Adam | epoch: 003 | loss: 0.67959 - acc: 0.5902 -- iter: 0256/1140
[A[ATraining Step: 81  | total loss: [1m[32m0.68289[0m[0m | time: 18.489s
[2K
| Adam | epoch: 003 | loss: 0.68289 - acc: 0.5811 -- iter: 0288/1140
[A[ATraining Step: 82  | total loss: [1m[32m0.68340[0m[0m | time: 22.987s
[2K
| Adam | epoch: 003 | loss: 0.68340 - acc: 0.5793 -- iter: 0320/1140
[A[ATraining Step: 83  | total loss: [1m[32m0.68020[0m[0m | time: 27.757s
[2K
| Adam | epoch: 003 | loss: 0.68020 - acc: 0.5870 -- iter: 0352/1140
[A[ATraining Step: 84  | total loss: [1m[32m0.68194[0m[0m | time: 28.741s
[2K
| Adam | epoch: 003 | loss: 0.68194 - acc: 0.5814 -- iter: 0384/1140
[A[ATraining Step: 85  | total loss: [1m[32m0.67888[0m[0m | time: 29.873s
[2K
| Adam | epoch: 003 | loss: 0.67888 - acc: 0.5889 -- iter: 0416/1140
[A[ATraining Step: 86  | total loss: [1m[32m0.68202[0m[0m | time: 31.056s
[2K
| Adam | epoch: 003 | loss: 0.68202 - acc: 0.5800 -- iter: 0448/1140
[A[ATraining Step: 87  | total loss: [1m[32m0.67366[0m[0m | time: 32.267s
[2K
| Adam | epoch: 003 | loss: 0.67366 - acc: 0.6032 -- iter: 0480/1140
[A[ATraining Step: 88  | total loss: [1m[32m0.68065[0m[0m | time: 33.401s
[2K
| Adam | epoch: 003 | loss: 0.68065 - acc: 0.5835 -- iter: 0512/1140
[A[ATraining Step: 89  | total loss: [1m[32m0.68107[0m[0m | time: 34.664s
[2K
| Adam | epoch: 003 | loss: 0.68107 - acc: 0.5814 -- iter: 0544/1140
[A[ATraining Step: 90  | total loss: [1m[32m0.67851[0m[0m | time: 35.842s
[2K
| Adam | epoch: 003 | loss: 0.67851 - acc: 0.5889 -- iter: 0576/1140
[A[ATraining Step: 91  | total loss: [1m[32m0.67577[0m[0m | time: 37.066s
[2K
| Adam | epoch: 003 | loss: 0.67577 - acc: 0.5956 -- iter: 0608/1140
[A[ATraining Step: 92  | total loss: [1m[32m0.67789[0m[0m | time: 38.127s
[2K
| Adam | epoch: 003 | loss: 0.67789 - acc: 0.5892 -- iter: 0640/1140
[A[ATraining Step: 93  | total loss: [1m[32m0.67896[0m[0m | time: 39.053s
[2K
| Adam | epoch: 003 | loss: 0.67896 - acc: 0.5865 -- iter: 0672/1140
[A[ATraining Step: 94  | total loss: [1m[32m0.67946[0m[0m | time: 39.977s
[2K
| Adam | epoch: 003 | loss: 0.67946 - acc: 0.5841 -- iter: 0704/1140
[A[ATraining Step: 95  | total loss: [1m[32m0.67802[0m[0m | time: 40.975s
[2K
| Adam | epoch: 003 | loss: 0.67802 - acc: 0.5882 -- iter: 0736/1140
[A[ATraining Step: 96  | total loss: [1m[32m0.67656[0m[0m | time: 42.233s
[2K
| Adam | epoch: 003 | loss: 0.67656 - acc: 0.5919 -- iter: 0768/1140
[A[ATraining Step: 97  | total loss: [1m[32m0.67731[0m[0m | time: 43.526s
[2K
| Adam | epoch: 003 | loss: 0.67731 - acc: 0.5890 -- iter: 0800/1140
[A[ATraining Step: 98  | total loss: [1m[32m0.67707[0m[0m | time: 44.660s
[2K
| Adam | epoch: 003 | loss: 0.67707 - acc: 0.5894 -- iter: 0832/1140
[A[ATraining Step: 99  | total loss: [1m[32m0.67704[0m[0m | time: 45.799s
[2K
| Adam | epoch: 003 | loss: 0.67704 - acc: 0.5899 -- iter: 0864/1140
[A[ATraining Step: 100  | total loss: [1m[32m0.67368[0m[0m | time: 47.089s
[2K
| Adam | epoch: 003 | loss: 0.67368 - acc: 0.5996 -- iter: 0896/1140
[A[ATraining Step: 101  | total loss: [1m[32m0.67068[0m[0m | time: 48.307s
[2K
| Adam | epoch: 003 | loss: 0.67068 - acc: 0.6084 -- iter: 0928/1140
[A[ATraining Step: 102  | total loss: [1m[32m0.67126[0m[0m | time: 49.265s
[2K
| Adam | epoch: 003 | loss: 0.67126 - acc: 0.6070 -- iter: 0960/1140
[A[ATraining Step: 103  | total loss: [1m[32m0.67173[0m[0m | time: 50.162s
[2K
| Adam | epoch: 003 | loss: 0.67173 - acc: 0.6056 -- iter: 0992/1140
[A[ATraining Step: 104  | total loss: [1m[32m0.66366[0m[0m | time: 51.056s
[2K
| Adam | epoch: 003 | loss: 0.66366 - acc: 0.6263 -- iter: 1024/1140
[A[ATraining Step: 105  | total loss: [1m[32m0.66350[0m[0m | time: 52.004s
[2K
| Adam | epoch: 003 | loss: 0.66350 - acc: 0.6262 -- iter: 1056/1140
[A[ATraining Step: 106  | total loss: [1m[32m0.66181[0m[0m | time: 52.967s
[2K
| Adam | epoch: 003 | loss: 0.66181 - acc: 0.6292 -- iter: 1088/1140
[A[ATraining Step: 107  | total loss: [1m[32m0.66515[0m[0m | time: 53.835s
[2K
| Adam | epoch: 003 | loss: 0.66515 - acc: 0.6225 -- iter: 1120/1140
[A[ATraining Step: 108  | total loss: [1m[32m0.66282[0m[0m | time: 56.888s
[2K
| Adam | epoch: 003 | loss: 0.66282 - acc: 0.6259 | val_loss: 0.67433 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 109  | total loss: [1m[32m0.67321[0m[0m | time: 0.981s
[2K
| Adam | epoch: 004 | loss: 0.67321 - acc: 0.6039 -- iter: 0032/1140
[A[ATraining Step: 110  | total loss: [1m[32m0.66927[0m[0m | time: 1.585s
[2K
| Adam | epoch: 004 | loss: 0.66927 - acc: 0.6123 -- iter: 0064/1140
[A[ATraining Step: 111  | total loss: [1m[32m0.68007[0m[0m | time: 2.190s
[2K
| Adam | epoch: 004 | loss: 0.68007 - acc: 0.5911 -- iter: 0096/1140
[A[ATraining Step: 112  | total loss: [1m[32m0.68934[0m[0m | time: 3.049s
[2K
| Adam | epoch: 004 | loss: 0.68934 - acc: 0.5720 -- iter: 0128/1140
[A[ATraining Step: 113  | total loss: [1m[32m0.68522[0m[0m | time: 4.046s
[2K
| Adam | epoch: 004 | loss: 0.68522 - acc: 0.5804 -- iter: 0160/1140
[A[ATraining Step: 114  | total loss: [1m[32m0.68755[0m[0m | time: 4.911s
[2K
| Adam | epoch: 004 | loss: 0.68755 - acc: 0.5723 -- iter: 0192/1140
[A[ATraining Step: 115  | total loss: [1m[32m0.68502[0m[0m | time: 5.736s
[2K
| Adam | epoch: 004 | loss: 0.68502 - acc: 0.5776 -- iter: 0224/1140
[A[ATraining Step: 116  | total loss: [1m[32m0.68163[0m[0m | time: 6.724s
[2K
| Adam | epoch: 004 | loss: 0.68163 - acc: 0.5855 -- iter: 0256/1140
[A[ATraining Step: 117  | total loss: [1m[32m0.68065[0m[0m | time: 7.897s
[2K
| Adam | epoch: 004 | loss: 0.68065 - acc: 0.5863 -- iter: 0288/1140
[A[ATraining Step: 118  | total loss: [1m[32m0.68228[0m[0m | time: 8.843s
[2K
| Adam | epoch: 004 | loss: 0.68228 - acc: 0.5808 -- iter: 0320/1140
[A[ATraining Step: 119  | total loss: [1m[32m0.68636[0m[0m | time: 9.711s
[2K
| Adam | epoch: 004 | loss: 0.68636 - acc: 0.5696 -- iter: 0352/1140
[A[ATraining Step: 120  | total loss: [1m[32m0.68190[0m[0m | time: 10.592s
[2K
| Adam | epoch: 004 | loss: 0.68190 - acc: 0.5814 -- iter: 0384/1140
[A[ATraining Step: 121  | total loss: [1m[32m0.68001[0m[0m | time: 11.535s
[2K
| Adam | epoch: 004 | loss: 0.68001 - acc: 0.5857 -- iter: 0416/1140
[A[ATraining Step: 122  | total loss: [1m[32m0.68038[0m[0m | time: 12.484s
[2K
| Adam | epoch: 004 | loss: 0.68038 - acc: 0.5834 -- iter: 0448/1140
[A[ATraining Step: 123  | total loss: [1m[32m0.68009[0m[0m | time: 13.410s
[2K
| Adam | epoch: 004 | loss: 0.68009 - acc: 0.5845 -- iter: 0480/1140
[A[ATraining Step: 124  | total loss: [1m[32m0.67612[0m[0m | time: 14.297s
[2K
| Adam | epoch: 004 | loss: 0.67612 - acc: 0.5979 -- iter: 0512/1140
[A[ATraining Step: 125  | total loss: [1m[32m0.67335[0m[0m | time: 15.262s
[2K
| Adam | epoch: 004 | loss: 0.67335 - acc: 0.6068 -- iter: 0544/1140
[A[ATraining Step: 126  | total loss: [1m[32m0.67444[0m[0m | time: 16.116s
[2K
| Adam | epoch: 004 | loss: 0.67444 - acc: 0.6024 -- iter: 0576/1140
[A[ATraining Step: 127  | total loss: [1m[32m0.67435[0m[0m | time: 16.911s
[2K
| Adam | epoch: 004 | loss: 0.67435 - acc: 0.6015 -- iter: 0608/1140
[A[ATraining Step: 128  | total loss: [1m[32m0.67513[0m[0m | time: 17.887s
[2K
| Adam | epoch: 004 | loss: 0.67513 - acc: 0.5976 -- iter: 0640/1140
[A[ATraining Step: 129  | total loss: [1m[32m0.67518[0m[0m | time: 18.827s
[2K
| Adam | epoch: 004 | loss: 0.67518 - acc: 0.5973 -- iter: 0672/1140
[A[ATraining Step: 130  | total loss: [1m[32m0.67533[0m[0m | time: 19.894s
[2K
| Adam | epoch: 004 | loss: 0.67533 - acc: 0.5969 -- iter: 0704/1140
[A[ATraining Step: 131  | total loss: [1m[32m0.67959[0m[0m | time: 20.900s
[2K
| Adam | epoch: 004 | loss: 0.67959 - acc: 0.5841 -- iter: 0736/1140
[A[ATraining Step: 132  | total loss: [1m[32m0.67490[0m[0m | time: 21.925s
[2K
| Adam | epoch: 004 | loss: 0.67490 - acc: 0.5976 -- iter: 0768/1140
[A[ATraining Step: 133  | total loss: [1m[32m0.67497[0m[0m | time: 22.943s
[2K
| Adam | epoch: 004 | loss: 0.67497 - acc: 0.5972 -- iter: 0800/1140
[A[ATraining Step: 134  | total loss: [1m[32m0.67100[0m[0m | time: 23.912s
[2K
| Adam | epoch: 004 | loss: 0.67100 - acc: 0.6093 -- iter: 0832/1140
[A[ATraining Step: 135  | total loss: [1m[32m0.66926[0m[0m | time: 24.971s
[2K
| Adam | epoch: 004 | loss: 0.66926 - acc: 0.6140 -- iter: 0864/1140
[A[ATraining Step: 136  | total loss: [1m[32m0.66771[0m[0m | time: 25.990s
[2K
| Adam | epoch: 004 | loss: 0.66771 - acc: 0.6182 -- iter: 0896/1140
[A[ATraining Step: 137  | total loss: [1m[32m0.67178[0m[0m | time: 27.199s
[2K
| Adam | epoch: 004 | loss: 0.67178 - acc: 0.6064 -- iter: 0928/1140
[A[ATraining Step: 138  | total loss: [1m[32m0.66936[0m[0m | time: 28.271s
[2K
| Adam | epoch: 004 | loss: 0.66936 - acc: 0.6114 -- iter: 0960/1140
[A[ATraining Step: 139  | total loss: [1m[32m0.66382[0m[0m | time: 29.401s
[2K
| Adam | epoch: 004 | loss: 0.66382 - acc: 0.6253 -- iter: 0992/1140
[A[ATraining Step: 140  | total loss: [1m[32m0.66766[0m[0m | time: 30.598s
[2K
| Adam | epoch: 004 | loss: 0.66766 - acc: 0.6159 -- iter: 1024/1140
[A[ATraining Step: 141  | total loss: [1m[32m0.67224[0m[0m | time: 31.793s
[2K
| Adam | epoch: 004 | loss: 0.67224 - acc: 0.6043 -- iter: 1056/1140
[A[ATraining Step: 142  | total loss: [1m[32m0.67123[0m[0m | time: 33.216s
[2K
| Adam | epoch: 004 | loss: 0.67123 - acc: 0.6063 -- iter: 1088/1140
[A[ATraining Step: 143  | total loss: [1m[32m0.67459[0m[0m | time: 34.613s
[2K
| Adam | epoch: 004 | loss: 0.67459 - acc: 0.5988 -- iter: 1120/1140
[A[ATraining Step: 144  | total loss: [1m[32m0.68006[0m[0m | time: 82.830s
[2K
| Adam | epoch: 004 | loss: 0.68006 - acc: 0.5858 | val_loss: 0.67329 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 145  | total loss: [1m[32m0.67662[0m[0m | time: 1.178s
[2K
| Adam | epoch: 005 | loss: 0.67662 - acc: 0.5929 -- iter: 0032/1140
[A[ATraining Step: 146  | total loss: [1m[32m0.67634[0m[0m | time: 2.501s
[2K
| Adam | epoch: 005 | loss: 0.67634 - acc: 0.5930 -- iter: 0064/1140
[A[ATraining Step: 147  | total loss: [1m[32m0.67598[0m[0m | time: 3.314s
[2K
| Adam | epoch: 005 | loss: 0.67598 - acc: 0.5930 -- iter: 0096/1140
[A[ATraining Step: 148  | total loss: [1m[32m0.67751[0m[0m | time: 4.105s
[2K
| Adam | epoch: 005 | loss: 0.67751 - acc: 0.5887 -- iter: 0128/1140
[A[ATraining Step: 149  | total loss: [1m[32m0.67915[0m[0m | time: 5.364s
[2K
| Adam | epoch: 005 | loss: 0.67915 - acc: 0.5849 -- iter: 0160/1140
[A[ATraining Step: 150  | total loss: [1m[32m0.68166[0m[0m | time: 6.756s
[2K
| Adam | epoch: 005 | loss: 0.68166 - acc: 0.5795 -- iter: 0192/1140
[A[ATraining Step: 151  | total loss: [1m[32m0.68382[0m[0m | time: 8.087s
[2K
| Adam | epoch: 005 | loss: 0.68382 - acc: 0.5747 -- iter: 0224/1140
[A[ATraining Step: 152  | total loss: [1m[32m0.67823[0m[0m | time: 9.546s
[2K
| Adam | epoch: 005 | loss: 0.67823 - acc: 0.5891 -- iter: 0256/1140
[A[ATraining Step: 153  | total loss: [1m[32m0.68027[0m[0m | time: 10.913s
[2K
| Adam | epoch: 005 | loss: 0.68027 - acc: 0.5833 -- iter: 0288/1140
[A[ATraining Step: 154  | total loss: [1m[32m0.67856[0m[0m | time: 18.139s
[2K
| Adam | epoch: 005 | loss: 0.67856 - acc: 0.5875 -- iter: 0320/1140
[A[ATraining Step: 155  | total loss: [1m[32m0.68032[0m[0m | time: 25.413s
[2K
| Adam | epoch: 005 | loss: 0.68032 - acc: 0.5818 -- iter: 0352/1140
[A[ATraining Step: 156  | total loss: [1m[32m0.68599[0m[0m | time: 32.825s
[2K
| Adam | epoch: 005 | loss: 0.68599 - acc: 0.5643 -- iter: 0384/1140
[A[ATraining Step: 157  | total loss: [1m[32m0.68177[0m[0m | time: 35.562s
[2K
| Adam | epoch: 005 | loss: 0.68177 - acc: 0.5766 -- iter: 0416/1140
[A[ATraining Step: 158  | total loss: [1m[32m0.67790[0m[0m | time: 36.849s
[2K
| Adam | epoch: 005 | loss: 0.67790 - acc: 0.5877 -- iter: 0448/1140
[A[ATraining Step: 159  | total loss: [1m[32m0.67333[0m[0m | time: 38.024s
[2K
| Adam | epoch: 005 | loss: 0.67333 - acc: 0.6008 -- iter: 0480/1140
[A[ATraining Step: 160  | total loss: [1m[32m0.67150[0m[0m | time: 39.281s
[2K
| Adam | epoch: 005 | loss: 0.67150 - acc: 0.6063 -- iter: 0512/1140
[A[ATraining Step: 161  | total loss: [1m[32m0.66339[0m[0m | time: 40.592s
[2K
| Adam | epoch: 005 | loss: 0.66339 - acc: 0.6301 -- iter: 0544/1140
[A[ATraining Step: 162  | total loss: [1m[32m0.66164[0m[0m | time: 41.882s
[2K
| Adam | epoch: 005 | loss: 0.66164 - acc: 0.6358 -- iter: 0576/1140
[A[ATraining Step: 163  | total loss: [1m[32m0.66755[0m[0m | time: 43.173s
[2K
| Adam | epoch: 005 | loss: 0.66755 - acc: 0.6191 -- iter: 0608/1140
[A[ATraining Step: 164  | total loss: [1m[32m0.66457[0m[0m | time: 44.534s
[2K
| Adam | epoch: 005 | loss: 0.66457 - acc: 0.6260 -- iter: 0640/1140
[A[ATraining Step: 165  | total loss: [1m[32m0.66366[0m[0m | time: 45.938s
[2K
| Adam | epoch: 005 | loss: 0.66366 - acc: 0.6290 -- iter: 0672/1140
[A[ATraining Step: 166  | total loss: [1m[32m0.66730[0m[0m | time: 47.233s
[2K
| Adam | epoch: 005 | loss: 0.66730 - acc: 0.6192 -- iter: 0704/1140
[A[ATraining Step: 167  | total loss: [1m[32m0.66796[0m[0m | time: 48.665s
[2K
| Adam | epoch: 005 | loss: 0.66796 - acc: 0.6167 -- iter: 0736/1140
[A[ATraining Step: 168  | total loss: [1m[32m0.66666[0m[0m | time: 49.995s
[2K
| Adam | epoch: 005 | loss: 0.66666 - acc: 0.6175 -- iter: 0768/1140
[A[ATraining Step: 169  | total loss: [1m[32m0.67613[0m[0m | time: 56.319s
[2K
| Adam | epoch: 005 | loss: 0.67613 - acc: 0.5964 -- iter: 0800/1140
[A[ATraining Step: 170  | total loss: [1m[32m0.66901[0m[0m | time: 63.119s
[2K
| Adam | epoch: 005 | loss: 0.66901 - acc: 0.6117 -- iter: 0832/1140
[A[ATraining Step: 171  | total loss: [1m[32m0.67383[0m[0m | time: 71.434s
[2K
| Adam | epoch: 005 | loss: 0.67383 - acc: 0.6006 -- iter: 0864/1140
[A[ATraining Step: 172  | total loss: [1m[32m0.67523[0m[0m | time: 75.242s
[2K
| Adam | epoch: 005 | loss: 0.67523 - acc: 0.5968 -- iter: 0896/1140
[A[ATraining Step: 173  | total loss: [1m[32m0.67503[0m[0m | time: 83.314s
[2K
| Adam | epoch: 005 | loss: 0.67503 - acc: 0.5965 -- iter: 0928/1140
[A[ATraining Step: 174  | total loss: [1m[32m0.67660[0m[0m | time: 100.277s
[2K
| Adam | epoch: 005 | loss: 0.67660 - acc: 0.5931 -- iter: 0960/1140
[A[ATraining Step: 175  | total loss: [1m[32m0.67957[0m[0m | time: 101.381s
[2K
| Adam | epoch: 005 | loss: 0.67957 - acc: 0.5869 -- iter: 0992/1140
[A[ATraining Step: 176  | total loss: [1m[32m0.68188[0m[0m | time: 102.666s
[2K
| Adam | epoch: 005 | loss: 0.68188 - acc: 0.5813 -- iter: 1024/1140
[A[ATraining Step: 177  | total loss: [1m[32m0.67854[0m[0m | time: 103.919s
[2K
| Adam | epoch: 005 | loss: 0.67854 - acc: 0.5888 -- iter: 1056/1140
[A[ATraining Step: 178  | total loss: [1m[32m0.67585[0m[0m | time: 105.258s
[2K
| Adam | epoch: 005 | loss: 0.67585 - acc: 0.5956 -- iter: 1088/1140
[A[ATraining Step: 179  | total loss: [1m[32m0.67587[0m[0m | time: 106.369s
[2K
| Adam | epoch: 005 | loss: 0.67587 - acc: 0.5954 -- iter: 1120/1140
[A[ATraining Step: 180  | total loss: [1m[32m0.67622[0m[0m | time: 110.680s
[2K
| Adam | epoch: 005 | loss: 0.67622 - acc: 0.5952 | val_loss: 0.67283 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 181  | total loss: [1m[32m0.67590[0m[0m | time: 1.412s
[2K
| Adam | epoch: 006 | loss: 0.67590 - acc: 0.5951 -- iter: 0032/1140
[A[ATraining Step: 182  | total loss: [1m[32m0.67940[0m[0m | time: 2.751s
[2K
| Adam | epoch: 006 | loss: 0.67940 - acc: 0.5856 -- iter: 0064/1140
[A[ATraining Step: 183  | total loss: [1m[32m0.67551[0m[0m | time: 6.053s
[2K
| Adam | epoch: 006 | loss: 0.67551 - acc: 0.5958 -- iter: 0096/1140
[A[ATraining Step: 184  | total loss: [1m[32m0.68005[0m[0m | time: 12.076s
[2K
| Adam | epoch: 006 | loss: 0.68005 - acc: 0.5831 -- iter: 0128/1140
[A[ATraining Step: 185  | total loss: [1m[32m0.68281[0m[0m | time: 12.800s
[2K
| Adam | epoch: 006 | loss: 0.68281 - acc: 0.5747 -- iter: 0160/1140
[A[ATraining Step: 186  | total loss: [1m[32m0.68506[0m[0m | time: 13.942s
[2K
| Adam | epoch: 006 | loss: 0.68506 - acc: 0.5673 -- iter: 0192/1140
[A[ATraining Step: 187  | total loss: [1m[32m0.68201[0m[0m | time: 15.174s
[2K
| Adam | epoch: 006 | loss: 0.68201 - acc: 0.5762 -- iter: 0224/1140
[A[ATraining Step: 188  | total loss: [1m[32m0.68325[0m[0m | time: 16.432s
[2K
| Adam | epoch: 006 | loss: 0.68325 - acc: 0.5717 -- iter: 0256/1140
[A[ATraining Step: 189  | total loss: [1m[32m0.67803[0m[0m | time: 17.717s
[2K
| Adam | epoch: 006 | loss: 0.67803 - acc: 0.5895 -- iter: 0288/1140
[A[ATraining Step: 190  | total loss: [1m[32m0.67947[0m[0m | time: 18.911s
[2K
| Adam | epoch: 006 | loss: 0.67947 - acc: 0.5837 -- iter: 0320/1140
[A[ATraining Step: 191  | total loss: [1m[32m0.67896[0m[0m | time: 20.275s
[2K
| Adam | epoch: 006 | loss: 0.67896 - acc: 0.5847 -- iter: 0352/1140
[A[ATraining Step: 192  | total loss: [1m[32m0.67879[0m[0m | time: 21.627s
[2K
| Adam | epoch: 006 | loss: 0.67879 - acc: 0.5856 -- iter: 0384/1140
[A[ATraining Step: 193  | total loss: [1m[32m0.67967[0m[0m | time: 22.949s
[2K
| Adam | epoch: 006 | loss: 0.67967 - acc: 0.5833 -- iter: 0416/1140
[A[ATraining Step: 194  | total loss: [1m[32m0.67704[0m[0m | time: 24.190s
[2K
| Adam | epoch: 006 | loss: 0.67704 - acc: 0.5906 -- iter: 0448/1140
[A[ATraining Step: 195  | total loss: [1m[32m0.67562[0m[0m | time: 25.532s
[2K
| Adam | epoch: 006 | loss: 0.67562 - acc: 0.5940 -- iter: 0480/1140
[A[ATraining Step: 196  | total loss: [1m[32m0.67474[0m[0m | time: 26.998s
[2K
| Adam | epoch: 006 | loss: 0.67474 - acc: 0.5971 -- iter: 0512/1140
[A[ATraining Step: 197  | total loss: [1m[32m0.67473[0m[0m | time: 36.319s
[2K
| Adam | epoch: 006 | loss: 0.67473 - acc: 0.5968 -- iter: 0544/1140
[A[ATraining Step: 198  | total loss: [1m[32m0.67471[0m[0m | time: 42.735s
[2K
| Adam | epoch: 006 | loss: 0.67471 - acc: 0.5965 -- iter: 0576/1140
[A[ATraining Step: 199  | total loss: [1m[32m0.67257[0m[0m | time: 56.122s
[2K
| Adam | epoch: 006 | loss: 0.67257 - acc: 0.6025 -- iter: 0608/1140
[A[ATraining Step: 200  | total loss: [1m[32m0.66628[0m[0m | time: 79.406s
[2K
| Adam | epoch: 006 | loss: 0.66628 - acc: 0.6203 | val_loss: 0.67268 - val_acc: 0.5966 -- iter: 0640/1140
--
Training Step: 201  | total loss: [1m[32m0.67222[0m[0m | time: 80.697s
[2K
| Adam | epoch: 006 | loss: 0.67222 - acc: 0.6021 -- iter: 0672/1140
[A[ATraining Step: 202  | total loss: [1m[32m0.67425[0m[0m | time: 81.985s
[2K
| Adam | epoch: 006 | loss: 0.67425 - acc: 0.5950 -- iter: 0704/1140
[A[ATraining Step: 203  | total loss: [1m[32m0.67896[0m[0m | time: 83.366s
[2K
| Adam | epoch: 006 | loss: 0.67896 - acc: 0.5824 -- iter: 0736/1140
[A[ATraining Step: 204  | total loss: [1m[32m0.67367[0m[0m | time: 84.702s
[2K
| Adam | epoch: 006 | loss: 0.67367 - acc: 0.5960 -- iter: 0768/1140
[A[ATraining Step: 205  | total loss: [1m[32m0.68177[0m[0m | time: 86.027s
[2K
| Adam | epoch: 006 | loss: 0.68177 - acc: 0.5739 -- iter: 0800/1140
[A[ATraining Step: 206  | total loss: [1m[32m0.68440[0m[0m | time: 87.271s
[2K
| Adam | epoch: 006 | loss: 0.68440 - acc: 0.5665 -- iter: 0832/1140
[A[ATraining Step: 207  | total loss: [1m[32m0.68434[0m[0m | time: 88.649s
[2K
| Adam | epoch: 006 | loss: 0.68434 - acc: 0.5661 -- iter: 0864/1140
[A[ATraining Step: 208  | total loss: [1m[32m0.68598[0m[0m | time: 90.172s
[2K
| Adam | epoch: 006 | loss: 0.68598 - acc: 0.5595 -- iter: 0896/1140
[A[ATraining Step: 209  | total loss: [1m[32m0.68484[0m[0m | time: 106.282s
[2K
| Adam | epoch: 006 | loss: 0.68484 - acc: 0.5629 -- iter: 0928/1140
[A[ATraining Step: 210  | total loss: [1m[32m0.68688[0m[0m | time: 122.151s
[2K
| Adam | epoch: 006 | loss: 0.68688 - acc: 0.5566 -- iter: 0960/1140
[A[ATraining Step: 211  | total loss: [1m[32m0.68644[0m[0m | time: 128.534s
[2K
| Adam | epoch: 006 | loss: 0.68644 - acc: 0.5572 -- iter: 0992/1140
[A[ATraining Step: 212  | total loss: [1m[32m0.68515[0m[0m | time: 135.763s
[2K
| Adam | epoch: 006 | loss: 0.68515 - acc: 0.5609 -- iter: 1024/1140
[A[ATraining Step: 213  | total loss: [1m[32m0.68191[0m[0m | time: 143.236s
[2K
| Adam | epoch: 006 | loss: 0.68191 - acc: 0.5704 -- iter: 1056/1140
[A[ATraining Step: 214  | total loss: [1m[32m0.68053[0m[0m | time: 147.526s
[2K
| Adam | epoch: 006 | loss: 0.68053 - acc: 0.5759 -- iter: 1088/1140
[A[ATraining Step: 215  | total loss: [1m[32m0.68105[0m[0m | time: 148.745s
[2K
| Adam | epoch: 006 | loss: 0.68105 - acc: 0.5745 -- iter: 1120/1140
[A[ATraining Step: 216  | total loss: [1m[32m0.67767[0m[0m | time: 152.887s
[2K
| Adam | epoch: 006 | loss: 0.67767 - acc: 0.5858 | val_loss: 0.67362 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 217  | total loss: [1m[32m0.67658[0m[0m | time: 1.011s
[2K
| Adam | epoch: 007 | loss: 0.67658 - acc: 0.5897 -- iter: 0032/1140
[A[ATraining Step: 218  | total loss: [1m[32m0.67805[0m[0m | time: 2.152s
[2K
| Adam | epoch: 007 | loss: 0.67805 - acc: 0.5839 -- iter: 0064/1140
[A[ATraining Step: 219  | total loss: [1m[32m0.67868[0m[0m | time: 3.328s
[2K
| Adam | epoch: 007 | loss: 0.67868 - acc: 0.5818 -- iter: 0096/1140
[A[ATraining Step: 220  | total loss: [1m[32m0.67442[0m[0m | time: 4.419s
[2K
| Adam | epoch: 007 | loss: 0.67442 - acc: 0.5955 -- iter: 0128/1140
[A[ATraining Step: 221  | total loss: [1m[32m0.66963[0m[0m | time: 4.948s
[2K
| Adam | epoch: 007 | loss: 0.66963 - acc: 0.6109 -- iter: 0160/1140
[A[ATraining Step: 222  | total loss: [1m[32m0.67003[0m[0m | time: 5.560s
[2K
| Adam | epoch: 007 | loss: 0.67003 - acc: 0.6098 -- iter: 0192/1140
[A[ATraining Step: 223  | total loss: [1m[32m0.66976[0m[0m | time: 6.591s
[2K
| Adam | epoch: 007 | loss: 0.66976 - acc: 0.6088 -- iter: 0224/1140
[A[ATraining Step: 224  | total loss: [1m[32m0.66663[0m[0m | time: 7.608s
[2K
| Adam | epoch: 007 | loss: 0.66663 - acc: 0.6167 -- iter: 0256/1140
[A[ATraining Step: 225  | total loss: [1m[32m0.66259[0m[0m | time: 8.654s
[2K
| Adam | epoch: 007 | loss: 0.66259 - acc: 0.6269 -- iter: 0288/1140
[A[ATraining Step: 226  | total loss: [1m[32m0.65830[0m[0m | time: 9.703s
[2K
| Adam | epoch: 007 | loss: 0.65830 - acc: 0.6361 -- iter: 0320/1140
[A[ATraining Step: 227  | total loss: [1m[32m0.66023[0m[0m | time: 10.775s
[2K
| Adam | epoch: 007 | loss: 0.66023 - acc: 0.6287 -- iter: 0352/1140
[A[ATraining Step: 228  | total loss: [1m[32m0.65826[0m[0m | time: 11.751s
[2K
| Adam | epoch: 007 | loss: 0.65826 - acc: 0.6315 -- iter: 0384/1140
[A[ATraining Step: 229  | total loss: [1m[32m0.66527[0m[0m | time: 12.980s
[2K
| Adam | epoch: 007 | loss: 0.66527 - acc: 0.6183 -- iter: 0416/1140
[A[ATraining Step: 230  | total loss: [1m[32m0.66445[0m[0m | time: 14.183s
[2K
| Adam | epoch: 007 | loss: 0.66445 - acc: 0.6190 -- iter: 0448/1140
[A[ATraining Step: 231  | total loss: [1m[32m0.66074[0m[0m | time: 15.060s
[2K
| Adam | epoch: 007 | loss: 0.66074 - acc: 0.6259 -- iter: 0480/1140
[A[ATraining Step: 232  | total loss: [1m[32m0.66296[0m[0m | time: 16.013s
[2K
| Adam | epoch: 007 | loss: 0.66296 - acc: 0.6226 -- iter: 0512/1140
[A[ATraining Step: 233  | total loss: [1m[32m0.66296[0m[0m | time: 17.043s
[2K
| Adam | epoch: 007 | loss: 0.66296 - acc: 0.6229 -- iter: 0544/1140
[A[ATraining Step: 234  | total loss: [1m[32m0.65845[0m[0m | time: 18.032s
[2K
| Adam | epoch: 007 | loss: 0.65845 - acc: 0.6293 -- iter: 0576/1140
[A[ATraining Step: 235  | total loss: [1m[32m0.65831[0m[0m | time: 19.090s
[2K
| Adam | epoch: 007 | loss: 0.65831 - acc: 0.6289 -- iter: 0608/1140
[A[ATraining Step: 236  | total loss: [1m[32m0.65466[0m[0m | time: 20.185s
[2K
| Adam | epoch: 007 | loss: 0.65466 - acc: 0.6348 -- iter: 0640/1140
[A[ATraining Step: 237  | total loss: [1m[32m0.65329[0m[0m | time: 21.249s
[2K
| Adam | epoch: 007 | loss: 0.65329 - acc: 0.6369 -- iter: 0672/1140
[A[ATraining Step: 238  | total loss: [1m[32m0.65994[0m[0m | time: 22.285s
[2K
| Adam | epoch: 007 | loss: 0.65994 - acc: 0.6263 -- iter: 0704/1140
[A[ATraining Step: 239  | total loss: [1m[32m0.66396[0m[0m | time: 23.369s
[2K
| Adam | epoch: 007 | loss: 0.66396 - acc: 0.6200 -- iter: 0736/1140
[A[ATraining Step: 240  | total loss: [1m[32m0.66562[0m[0m | time: 24.464s
[2K
| Adam | epoch: 007 | loss: 0.66562 - acc: 0.6173 -- iter: 0768/1140
[A[ATraining Step: 241  | total loss: [1m[32m0.66121[0m[0m | time: 25.555s
[2K
| Adam | epoch: 007 | loss: 0.66121 - acc: 0.6244 -- iter: 0800/1140
[A[ATraining Step: 242  | total loss: [1m[32m0.66486[0m[0m | time: 26.465s
[2K
| Adam | epoch: 007 | loss: 0.66486 - acc: 0.6182 -- iter: 0832/1140
[A[ATraining Step: 243  | total loss: [1m[32m0.66396[0m[0m | time: 27.143s
[2K
| Adam | epoch: 007 | loss: 0.66396 - acc: 0.6189 -- iter: 0864/1140
[A[ATraining Step: 244  | total loss: [1m[32m0.66339[0m[0m | time: 27.832s
[2K
| Adam | epoch: 007 | loss: 0.66339 - acc: 0.6195 -- iter: 0896/1140
[A[ATraining Step: 245  | total loss: [1m[32m0.66120[0m[0m | time: 28.558s
[2K
| Adam | epoch: 007 | loss: 0.66120 - acc: 0.6231 -- iter: 0928/1140
[A[ATraining Step: 246  | total loss: [1m[32m0.66467[0m[0m | time: 29.212s
[2K
| Adam | epoch: 007 | loss: 0.66467 - acc: 0.6171 -- iter: 0960/1140
[A[ATraining Step: 247  | total loss: [1m[32m0.66564[0m[0m | time: 29.851s
[2K
| Adam | epoch: 007 | loss: 0.66564 - acc: 0.6147 -- iter: 0992/1140
[A[ATraining Step: 248  | total loss: [1m[32m0.66818[0m[0m | time: 30.501s
[2K
| Adam | epoch: 007 | loss: 0.66818 - acc: 0.6095 -- iter: 1024/1140
[A[ATraining Step: 249  | total loss: [1m[32m0.66842[0m[0m | time: 31.189s
[2K
| Adam | epoch: 007 | loss: 0.66842 - acc: 0.6079 -- iter: 1056/1140
[A[ATraining Step: 250  | total loss: [1m[32m0.66502[0m[0m | time: 31.862s
[2K
| Adam | epoch: 007 | loss: 0.66502 - acc: 0.6159 -- iter: 1088/1140
[A[ATraining Step: 251  | total loss: [1m[32m0.67259[0m[0m | time: 32.582s
[2K
| Adam | epoch: 007 | loss: 0.67259 - acc: 0.5981 -- iter: 1120/1140
[A[ATraining Step: 252  | total loss: [1m[32m0.67242[0m[0m | time: 34.587s
[2K
| Adam | epoch: 007 | loss: 0.67242 - acc: 0.5976 | val_loss: 0.67166 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 253  | total loss: [1m[32m0.67703[0m[0m | time: 0.804s
[2K
| Adam | epoch: 008 | loss: 0.67703 - acc: 0.5847 -- iter: 0032/1140
[A[ATraining Step: 254  | total loss: [1m[32m0.67912[0m[0m | time: 1.807s
[2K
| Adam | epoch: 008 | loss: 0.67912 - acc: 0.5794 -- iter: 0064/1140
[A[ATraining Step: 255  | total loss: [1m[32m0.68059[0m[0m | time: 2.788s
[2K
| Adam | epoch: 008 | loss: 0.68059 - acc: 0.5746 -- iter: 0096/1140
[A[ATraining Step: 256  | total loss: [1m[32m0.67986[0m[0m | time: 3.683s
[2K
| Adam | epoch: 008 | loss: 0.67986 - acc: 0.5765 -- iter: 0128/1140
[A[ATraining Step: 257  | total loss: [1m[32m0.68016[0m[0m | time: 4.656s
[2K
| Adam | epoch: 008 | loss: 0.68016 - acc: 0.5751 -- iter: 0160/1140
[A[ATraining Step: 258  | total loss: [1m[32m0.68013[0m[0m | time: 5.234s
[2K
| Adam | epoch: 008 | loss: 0.68013 - acc: 0.5738 -- iter: 0192/1140
[A[ATraining Step: 259  | total loss: [1m[32m0.67273[0m[0m | time: 5.893s
[2K
| Adam | epoch: 008 | loss: 0.67273 - acc: 0.6015 -- iter: 0224/1140
[A[ATraining Step: 260  | total loss: [1m[32m0.66591[0m[0m | time: 6.733s
[2K
| Adam | epoch: 008 | loss: 0.66591 - acc: 0.6263 -- iter: 0256/1140
[A[ATraining Step: 261  | total loss: [1m[32m0.66834[0m[0m | time: 7.585s
[2K
| Adam | epoch: 008 | loss: 0.66834 - acc: 0.6168 -- iter: 0288/1140
[A[ATraining Step: 262  | total loss: [1m[32m0.66702[0m[0m | time: 8.632s
[2K
| Adam | epoch: 008 | loss: 0.66702 - acc: 0.6207 -- iter: 0320/1140
[A[ATraining Step: 263  | total loss: [1m[32m0.66689[0m[0m | time: 9.644s
[2K
| Adam | epoch: 008 | loss: 0.66689 - acc: 0.6212 -- iter: 0352/1140
[A[ATraining Step: 264  | total loss: [1m[32m0.66846[0m[0m | time: 10.587s
[2K
| Adam | epoch: 008 | loss: 0.66846 - acc: 0.6153 -- iter: 0384/1140
[A[ATraining Step: 265  | total loss: [1m[32m0.67192[0m[0m | time: 11.570s
[2K
| Adam | epoch: 008 | loss: 0.67192 - acc: 0.6038 -- iter: 0416/1140
[A[ATraining Step: 266  | total loss: [1m[32m0.67436[0m[0m | time: 12.720s
[2K
| Adam | epoch: 008 | loss: 0.67436 - acc: 0.5965 -- iter: 0448/1140
[A[ATraining Step: 267  | total loss: [1m[32m0.66950[0m[0m | time: 13.869s
[2K
| Adam | epoch: 008 | loss: 0.66950 - acc: 0.6087 -- iter: 0480/1140
[A[ATraining Step: 268  | total loss: [1m[32m0.66827[0m[0m | time: 14.996s
[2K
| Adam | epoch: 008 | loss: 0.66827 - acc: 0.6104 -- iter: 0512/1140
[A[ATraining Step: 269  | total loss: [1m[32m0.67237[0m[0m | time: 16.147s
[2K
| Adam | epoch: 008 | loss: 0.67237 - acc: 0.5993 -- iter: 0544/1140
[A[ATraining Step: 270  | total loss: [1m[32m0.67117[0m[0m | time: 17.216s
[2K
| Adam | epoch: 008 | loss: 0.67117 - acc: 0.6019 -- iter: 0576/1140
[A[ATraining Step: 271  | total loss: [1m[32m0.67457[0m[0m | time: 18.499s
[2K
| Adam | epoch: 008 | loss: 0.67457 - acc: 0.5917 -- iter: 0608/1140
[A[ATraining Step: 272  | total loss: [1m[32m0.67636[0m[0m | time: 19.766s
[2K
| Adam | epoch: 008 | loss: 0.67636 - acc: 0.5857 -- iter: 0640/1140
[A[ATraining Step: 273  | total loss: [1m[32m0.67348[0m[0m | time: 21.201s
[2K
| Adam | epoch: 008 | loss: 0.67348 - acc: 0.5927 -- iter: 0672/1140
[A[ATraining Step: 274  | total loss: [1m[32m0.67214[0m[0m | time: 22.394s
[2K
| Adam | epoch: 008 | loss: 0.67214 - acc: 0.5960 -- iter: 0704/1140
[A[ATraining Step: 275  | total loss: [1m[32m0.66602[0m[0m | time: 23.463s
[2K
| Adam | epoch: 008 | loss: 0.66602 - acc: 0.6114 -- iter: 0736/1140
[A[ATraining Step: 276  | total loss: [1m[32m0.67140[0m[0m | time: 24.531s
[2K
| Adam | epoch: 008 | loss: 0.67140 - acc: 0.5971 -- iter: 0768/1140
[A[ATraining Step: 277  | total loss: [1m[32m0.66977[0m[0m | time: 25.715s
[2K
| Adam | epoch: 008 | loss: 0.66977 - acc: 0.5999 -- iter: 0800/1140
[A[ATraining Step: 278  | total loss: [1m[32m0.67428[0m[0m | time: 26.853s
[2K
| Adam | epoch: 008 | loss: 0.67428 - acc: 0.5899 -- iter: 0832/1140
[A[ATraining Step: 279  | total loss: [1m[32m0.67265[0m[0m | time: 28.017s
[2K
| Adam | epoch: 008 | loss: 0.67265 - acc: 0.5934 -- iter: 0864/1140
[A[ATraining Step: 280  | total loss: [1m[32m0.67413[0m[0m | time: 29.210s
[2K
| Adam | epoch: 008 | loss: 0.67413 - acc: 0.5903 -- iter: 0896/1140
[A[ATraining Step: 281  | total loss: [1m[32m0.67173[0m[0m | time: 30.475s
[2K
| Adam | epoch: 008 | loss: 0.67173 - acc: 0.5969 -- iter: 0928/1140
[A[ATraining Step: 282  | total loss: [1m[32m0.66760[0m[0m | time: 31.583s
[2K
| Adam | epoch: 008 | loss: 0.66760 - acc: 0.6060 -- iter: 0960/1140
[A[ATraining Step: 283  | total loss: [1m[32m0.66624[0m[0m | time: 32.869s
[2K
| Adam | epoch: 008 | loss: 0.66624 - acc: 0.6079 -- iter: 0992/1140
[A[ATraining Step: 284  | total loss: [1m[32m0.66964[0m[0m | time: 34.268s
[2K
| Adam | epoch: 008 | loss: 0.66964 - acc: 0.6002 -- iter: 1024/1140
[A[ATraining Step: 285  | total loss: [1m[32m0.67524[0m[0m | time: 35.678s
[2K
| Adam | epoch: 008 | loss: 0.67524 - acc: 0.5871 -- iter: 1056/1140
[A[ATraining Step: 286  | total loss: [1m[32m0.66938[0m[0m | time: 36.813s
[2K
| Adam | epoch: 008 | loss: 0.66938 - acc: 0.6002 -- iter: 1088/1140
[A[ATraining Step: 287  | total loss: [1m[32m0.67379[0m[0m | time: 37.906s
[2K
| Adam | epoch: 008 | loss: 0.67379 - acc: 0.5902 -- iter: 1120/1140
[A[ATraining Step: 288  | total loss: [1m[32m0.67029[0m[0m | time: 41.657s
[2K
| Adam | epoch: 008 | loss: 0.67029 - acc: 0.5968 | val_loss: 0.66990 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 289  | total loss: [1m[32m0.67063[0m[0m | time: 1.346s
[2K
| Adam | epoch: 009 | loss: 0.67063 - acc: 0.5965 -- iter: 0032/1140
[A[ATraining Step: 290  | total loss: [1m[32m0.66667[0m[0m | time: 2.454s
[2K
| Adam | epoch: 009 | loss: 0.66667 - acc: 0.6056 -- iter: 0064/1140
[A[ATraining Step: 291  | total loss: [1m[32m0.66249[0m[0m | time: 3.772s
[2K
| Adam | epoch: 009 | loss: 0.66249 - acc: 0.6138 -- iter: 0096/1140
[A[ATraining Step: 292  | total loss: [1m[32m0.66201[0m[0m | time: 5.155s
[2K
| Adam | epoch: 009 | loss: 0.66201 - acc: 0.6149 -- iter: 0128/1140
[A[ATraining Step: 293  | total loss: [1m[32m0.65294[0m[0m | time: 6.300s
[2K
| Adam | epoch: 009 | loss: 0.65294 - acc: 0.6347 -- iter: 0160/1140
[A[ATraining Step: 294  | total loss: [1m[32m0.65991[0m[0m | time: 7.527s
[2K
| Adam | epoch: 009 | loss: 0.65991 - acc: 0.6212 -- iter: 0192/1140
[A[ATraining Step: 295  | total loss: [1m[32m0.66477[0m[0m | time: 8.289s
[2K
| Adam | epoch: 009 | loss: 0.66477 - acc: 0.6122 -- iter: 0224/1140
[A[ATraining Step: 296  | total loss: [1m[32m0.66004[0m[0m | time: 9.112s
[2K
| Adam | epoch: 009 | loss: 0.66004 - acc: 0.6210 -- iter: 0256/1140
[A[ATraining Step: 297  | total loss: [1m[32m0.65566[0m[0m | time: 10.206s
[2K
| Adam | epoch: 009 | loss: 0.65566 - acc: 0.6289 -- iter: 0288/1140
[A[ATraining Step: 298  | total loss: [1m[32m0.66120[0m[0m | time: 11.345s
[2K
| Adam | epoch: 009 | loss: 0.66120 - acc: 0.6191 -- iter: 0320/1140
[A[ATraining Step: 299  | total loss: [1m[32m0.66889[0m[0m | time: 12.608s
[2K
| Adam | epoch: 009 | loss: 0.66889 - acc: 0.6041 -- iter: 0352/1140
[A[ATraining Step: 300  | total loss: [1m[32m0.66046[0m[0m | time: 13.878s
[2K
| Adam | epoch: 009 | loss: 0.66046 - acc: 0.6187 -- iter: 0384/1140
[A[ATraining Step: 301  | total loss: [1m[32m0.65785[0m[0m | time: 15.152s
[2K
| Adam | epoch: 009 | loss: 0.65785 - acc: 0.6224 -- iter: 0416/1140
[A[ATraining Step: 302  | total loss: [1m[32m0.66243[0m[0m | time: 16.371s
[2K
| Adam | epoch: 009 | loss: 0.66243 - acc: 0.6133 -- iter: 0448/1140
[A[ATraining Step: 303  | total loss: [1m[32m0.65978[0m[0m | time: 17.570s
[2K
| Adam | epoch: 009 | loss: 0.65978 - acc: 0.6176 -- iter: 0480/1140
[A[ATraining Step: 304  | total loss: [1m[32m0.66107[0m[0m | time: 18.943s
[2K
| Adam | epoch: 009 | loss: 0.66107 - acc: 0.6152 -- iter: 0512/1140
[A[ATraining Step: 305  | total loss: [1m[32m0.65973[0m[0m | time: 20.253s
[2K
| Adam | epoch: 009 | loss: 0.65973 - acc: 0.6162 -- iter: 0544/1140
[A[ATraining Step: 306  | total loss: [1m[32m0.66266[0m[0m | time: 21.501s
[2K
| Adam | epoch: 009 | loss: 0.66266 - acc: 0.6108 -- iter: 0576/1140
[A[ATraining Step: 307  | total loss: [1m[32m0.66767[0m[0m | time: 22.547s
[2K
| Adam | epoch: 009 | loss: 0.66767 - acc: 0.6029 -- iter: 0608/1140
[A[ATraining Step: 308  | total loss: [1m[32m0.66645[0m[0m | time: 23.770s
[2K
| Adam | epoch: 009 | loss: 0.66645 - acc: 0.6051 -- iter: 0640/1140
[A[ATraining Step: 309  | total loss: [1m[32m0.66378[0m[0m | time: 24.999s
[2K
| Adam | epoch: 009 | loss: 0.66378 - acc: 0.6102 -- iter: 0672/1140
[A[ATraining Step: 310  | total loss: [1m[32m0.66458[0m[0m | time: 26.012s
[2K
| Adam | epoch: 009 | loss: 0.66458 - acc: 0.6086 -- iter: 0704/1140
[A[ATraining Step: 311  | total loss: [1m[32m0.66527[0m[0m | time: 27.200s
[2K
| Adam | epoch: 009 | loss: 0.66527 - acc: 0.6071 -- iter: 0736/1140
[A[ATraining Step: 312  | total loss: [1m[32m0.66734[0m[0m | time: 28.466s
[2K
| Adam | epoch: 009 | loss: 0.66734 - acc: 0.5995 -- iter: 0768/1140
[A[ATraining Step: 313  | total loss: [1m[32m0.66792[0m[0m | time: 29.770s
[2K
| Adam | epoch: 009 | loss: 0.66792 - acc: 0.5989 -- iter: 0800/1140
[A[ATraining Step: 314  | total loss: [1m[32m0.66570[0m[0m | time: 31.015s
[2K
| Adam | epoch: 009 | loss: 0.66570 - acc: 0.6015 -- iter: 0832/1140
[A[ATraining Step: 315  | total loss: [1m[32m0.65820[0m[0m | time: 32.187s
[2K
| Adam | epoch: 009 | loss: 0.65820 - acc: 0.6195 -- iter: 0864/1140
[A[ATraining Step: 316  | total loss: [1m[32m0.65783[0m[0m | time: 33.613s
[2K
| Adam | epoch: 009 | loss: 0.65783 - acc: 0.6201 -- iter: 0896/1140
[A[ATraining Step: 317  | total loss: [1m[32m0.65670[0m[0m | time: 34.991s
[2K
| Adam | epoch: 009 | loss: 0.65670 - acc: 0.6237 -- iter: 0928/1140
[A[ATraining Step: 318  | total loss: [1m[32m0.65887[0m[0m | time: 36.314s
[2K
| Adam | epoch: 009 | loss: 0.65887 - acc: 0.6176 -- iter: 0960/1140
[A[ATraining Step: 319  | total loss: [1m[32m0.66356[0m[0m | time: 37.253s
[2K
| Adam | epoch: 009 | loss: 0.66356 - acc: 0.6058 -- iter: 0992/1140
[A[ATraining Step: 320  | total loss: [1m[32m0.66314[0m[0m | time: 38.596s
[2K
| Adam | epoch: 009 | loss: 0.66314 - acc: 0.6077 -- iter: 1024/1140
[A[ATraining Step: 321  | total loss: [1m[32m0.66685[0m[0m | time: 39.866s
[2K
| Adam | epoch: 009 | loss: 0.66685 - acc: 0.6001 -- iter: 1056/1140
[A[ATraining Step: 322  | total loss: [1m[32m0.66630[0m[0m | time: 41.087s
[2K
| Adam | epoch: 009 | loss: 0.66630 - acc: 0.6026 -- iter: 1088/1140
[A[ATraining Step: 323  | total loss: [1m[32m0.66681[0m[0m | time: 42.138s
[2K
| Adam | epoch: 009 | loss: 0.66681 - acc: 0.6017 -- iter: 1120/1140
[A[ATraining Step: 324  | total loss: [1m[32m0.66789[0m[0m | time: 46.122s
[2K
| Adam | epoch: 009 | loss: 0.66789 - acc: 0.5978 | val_loss: 0.66740 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 325  | total loss: [1m[32m0.67695[0m[0m | time: 1.500s
[2K
| Adam | epoch: 010 | loss: 0.67695 - acc: 0.5755 -- iter: 0032/1140
[A[ATraining Step: 326  | total loss: [1m[32m0.67692[0m[0m | time: 3.099s
[2K
| Adam | epoch: 010 | loss: 0.67692 - acc: 0.5742 -- iter: 0064/1140
[A[ATraining Step: 327  | total loss: [1m[32m0.67279[0m[0m | time: 4.898s
[2K
| Adam | epoch: 010 | loss: 0.67279 - acc: 0.5855 -- iter: 0096/1140
[A[ATraining Step: 328  | total loss: [1m[32m0.67105[0m[0m | time: 7.045s
[2K
| Adam | epoch: 010 | loss: 0.67105 - acc: 0.5895 -- iter: 0128/1140
[A[ATraining Step: 329  | total loss: [1m[32m0.67762[0m[0m | time: 8.280s
[2K
| Adam | epoch: 010 | loss: 0.67762 - acc: 0.5711 -- iter: 0160/1140
[A[ATraining Step: 330  | total loss: [1m[32m0.67122[0m[0m | time: 9.595s
[2K
| Adam | epoch: 010 | loss: 0.67122 - acc: 0.5859 -- iter: 0192/1140
[A[ATraining Step: 331  | total loss: [1m[32m0.67437[0m[0m | time: 10.636s
[2K
| Adam | epoch: 010 | loss: 0.67437 - acc: 0.5773 -- iter: 0224/1140
[A[ATraining Step: 332  | total loss: [1m[32m0.67042[0m[0m | time: 11.408s
[2K
| Adam | epoch: 010 | loss: 0.67042 - acc: 0.5883 -- iter: 0256/1140
[A[ATraining Step: 333  | total loss: [1m[32m0.66676[0m[0m | time: 12.217s
[2K
| Adam | epoch: 010 | loss: 0.66676 - acc: 0.5995 -- iter: 0288/1140
[A[ATraining Step: 334  | total loss: [1m[32m0.66315[0m[0m | time: 13.487s
[2K
| Adam | epoch: 010 | loss: 0.66315 - acc: 0.6096 -- iter: 0320/1140
[A[ATraining Step: 335  | total loss: [1m[32m0.66349[0m[0m | time: 14.831s
[2K
| Adam | epoch: 010 | loss: 0.66349 - acc: 0.6080 -- iter: 0352/1140
[A[ATraining Step: 336  | total loss: [1m[32m0.65916[0m[0m | time: 15.978s
[2K
| Adam | epoch: 010 | loss: 0.65916 - acc: 0.6190 -- iter: 0384/1140
[A[ATraining Step: 337  | total loss: [1m[32m0.65839[0m[0m | time: 17.213s
[2K
| Adam | epoch: 010 | loss: 0.65839 - acc: 0.6196 -- iter: 0416/1140
[A[ATraining Step: 338  | total loss: [1m[32m0.66272[0m[0m | time: 18.615s
[2K
| Adam | epoch: 010 | loss: 0.66272 - acc: 0.6108 -- iter: 0448/1140
[A[ATraining Step: 339  | total loss: [1m[32m0.66742[0m[0m | time: 20.027s
[2K
| Adam | epoch: 010 | loss: 0.66742 - acc: 0.5997 -- iter: 0480/1140
[A[ATraining Step: 340  | total loss: [1m[32m0.67340[0m[0m | time: 21.039s
[2K
| Adam | epoch: 010 | loss: 0.67340 - acc: 0.5866 -- iter: 0512/1140
[A[ATraining Step: 341  | total loss: [1m[32m0.66910[0m[0m | time: 22.164s
[2K
| Adam | epoch: 010 | loss: 0.66910 - acc: 0.5936 -- iter: 0544/1140
[A[ATraining Step: 342  | total loss: [1m[32m0.66894[0m[0m | time: 23.391s
[2K
| Adam | epoch: 010 | loss: 0.66894 - acc: 0.5936 -- iter: 0576/1140
[A[ATraining Step: 343  | total loss: [1m[32m0.67176[0m[0m | time: 24.714s
[2K
| Adam | epoch: 010 | loss: 0.67176 - acc: 0.5874 -- iter: 0608/1140
[A[ATraining Step: 344  | total loss: [1m[32m0.66372[0m[0m | time: 25.939s
[2K
| Adam | epoch: 010 | loss: 0.66372 - acc: 0.6036 -- iter: 0640/1140
[A[ATraining Step: 345  | total loss: [1m[32m0.65909[0m[0m | time: 27.026s
[2K
| Adam | epoch: 010 | loss: 0.65909 - acc: 0.6151 -- iter: 0672/1140
[A[ATraining Step: 346  | total loss: [1m[32m0.66366[0m[0m | time: 28.140s
[2K
| Adam | epoch: 010 | loss: 0.66366 - acc: 0.6036 -- iter: 0704/1140
[A[ATraining Step: 347  | total loss: [1m[32m0.65929[0m[0m | time: 29.447s
[2K
| Adam | epoch: 010 | loss: 0.65929 - acc: 0.6120 -- iter: 0736/1140
[A[ATraining Step: 348  | total loss: [1m[32m0.66442[0m[0m | time: 30.680s
[2K
| Adam | epoch: 010 | loss: 0.66442 - acc: 0.6008 -- iter: 0768/1140
[A[ATraining Step: 349  | total loss: [1m[32m0.66380[0m[0m | time: 31.926s
[2K
| Adam | epoch: 010 | loss: 0.66380 - acc: 0.6032 -- iter: 0800/1140
[A[ATraining Step: 350  | total loss: [1m[32m0.66589[0m[0m | time: 33.216s
[2K
| Adam | epoch: 010 | loss: 0.66589 - acc: 0.5992 -- iter: 0832/1140
[A[ATraining Step: 351  | total loss: [1m[32m0.66311[0m[0m | time: 34.622s
[2K
| Adam | epoch: 010 | loss: 0.66311 - acc: 0.6049 -- iter: 0864/1140
[A[ATraining Step: 352  | total loss: [1m[32m0.66689[0m[0m | time: 35.883s
[2K
| Adam | epoch: 010 | loss: 0.66689 - acc: 0.5975 -- iter: 0896/1140
[A[ATraining Step: 353  | total loss: [1m[32m0.66107[0m[0m | time: 37.324s
[2K
| Adam | epoch: 010 | loss: 0.66107 - acc: 0.6065 -- iter: 0928/1140
[A[ATraining Step: 354  | total loss: [1m[32m0.65911[0m[0m | time: 38.525s
[2K
| Adam | epoch: 010 | loss: 0.65911 - acc: 0.6115 -- iter: 0960/1140
[A[ATraining Step: 355  | total loss: [1m[32m0.65382[0m[0m | time: 39.632s
[2K
| Adam | epoch: 010 | loss: 0.65382 - acc: 0.6191 -- iter: 0992/1140
[A[ATraining Step: 356  | total loss: [1m[32m0.65433[0m[0m | time: 40.668s
[2K
| Adam | epoch: 010 | loss: 0.65433 - acc: 0.6197 -- iter: 1024/1140
[A[ATraining Step: 357  | total loss: [1m[32m0.65668[0m[0m | time: 41.537s
[2K
| Adam | epoch: 010 | loss: 0.65668 - acc: 0.6140 -- iter: 1056/1140
[A[ATraining Step: 358  | total loss: [1m[32m0.65998[0m[0m | time: 42.433s
[2K
| Adam | epoch: 010 | loss: 0.65998 - acc: 0.6057 -- iter: 1088/1140
[A[ATraining Step: 359  | total loss: [1m[32m0.65220[0m[0m | time: 43.385s
[2K
| Adam | epoch: 010 | loss: 0.65220 - acc: 0.6201 -- iter: 1120/1140
[A[ATraining Step: 360  | total loss: [1m[32m0.65198[0m[0m | time: 46.313s
[2K
| Adam | epoch: 010 | loss: 0.65198 - acc: 0.6206 | val_loss: 0.66436 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 361  | total loss: [1m[32m0.65844[0m[0m | time: 1.125s
[2K
| Adam | epoch: 011 | loss: 0.65844 - acc: 0.6085 -- iter: 0032/1140
[A[ATraining Step: 362  | total loss: [1m[32m0.65590[0m[0m | time: 2.115s
[2K
| Adam | epoch: 011 | loss: 0.65590 - acc: 0.6133 -- iter: 0064/1140
[A[ATraining Step: 363  | total loss: [1m[32m0.66445[0m[0m | time: 2.813s
[2K
| Adam | epoch: 011 | loss: 0.66445 - acc: 0.5926 -- iter: 0096/1140
[A[ATraining Step: 364  | total loss: [1m[32m0.66151[0m[0m | time: 3.732s
[2K
| Adam | epoch: 011 | loss: 0.66151 - acc: 0.5958 -- iter: 0128/1140
[A[ATraining Step: 365  | total loss: [1m[32m0.66310[0m[0m | time: 4.635s
[2K
| Adam | epoch: 011 | loss: 0.66310 - acc: 0.5894 -- iter: 0160/1140
[A[ATraining Step: 366  | total loss: [1m[32m0.65748[0m[0m | time: 5.562s
[2K
| Adam | epoch: 011 | loss: 0.65748 - acc: 0.5992 -- iter: 0192/1140
[A[ATraining Step: 367  | total loss: [1m[32m0.66572[0m[0m | time: 6.496s
[2K
| Adam | epoch: 011 | loss: 0.66572 - acc: 0.5830 -- iter: 0224/1140
[A[ATraining Step: 368  | total loss: [1m[32m0.65619[0m[0m | time: 7.410s
[2K
| Adam | epoch: 011 | loss: 0.65619 - acc: 0.6060 -- iter: 0256/1140
[A[ATraining Step: 369  | total loss: [1m[32m0.65794[0m[0m | time: 8.037s
[2K
| Adam | epoch: 011 | loss: 0.65794 - acc: 0.6016 -- iter: 0288/1140
[A[ATraining Step: 370  | total loss: [1m[32m0.65296[0m[0m | time: 8.613s
[2K
| Adam | epoch: 011 | loss: 0.65296 - acc: 0.6115 -- iter: 0320/1140
[A[ATraining Step: 371  | total loss: [1m[32m0.64801[0m[0m | time: 9.573s
[2K
| Adam | epoch: 011 | loss: 0.64801 - acc: 0.6203 -- iter: 0352/1140
[A[ATraining Step: 372  | total loss: [1m[32m0.65293[0m[0m | time: 10.462s
[2K
| Adam | epoch: 011 | loss: 0.65293 - acc: 0.6114 -- iter: 0384/1140
[A[ATraining Step: 373  | total loss: [1m[32m0.65206[0m[0m | time: 11.597s
[2K
| Adam | epoch: 011 | loss: 0.65206 - acc: 0.6128 -- iter: 0416/1140
[A[ATraining Step: 374  | total loss: [1m[32m0.64974[0m[0m | time: 12.656s
[2K
| Adam | epoch: 011 | loss: 0.64974 - acc: 0.6140 -- iter: 0448/1140
[A[ATraining Step: 375  | total loss: [1m[32m0.65407[0m[0m | time: 13.442s
[2K
| Adam | epoch: 011 | loss: 0.65407 - acc: 0.6057 -- iter: 0480/1140
[A[ATraining Step: 376  | total loss: [1m[32m0.64625[0m[0m | time: 14.387s
[2K
| Adam | epoch: 011 | loss: 0.64625 - acc: 0.6201 -- iter: 0512/1140
[A[ATraining Step: 377  | total loss: [1m[32m0.65298[0m[0m | time: 15.393s
[2K
| Adam | epoch: 011 | loss: 0.65298 - acc: 0.6081 -- iter: 0544/1140
[A[ATraining Step: 378  | total loss: [1m[32m0.65010[0m[0m | time: 16.444s
[2K
| Adam | epoch: 011 | loss: 0.65010 - acc: 0.6098 -- iter: 0576/1140
[A[ATraining Step: 379  | total loss: [1m[32m0.65024[0m[0m | time: 17.418s
[2K
| Adam | epoch: 011 | loss: 0.65024 - acc: 0.6113 -- iter: 0608/1140
[A[ATraining Step: 380  | total loss: [1m[32m0.64596[0m[0m | time: 18.489s
[2K
| Adam | epoch: 011 | loss: 0.64596 - acc: 0.6190 -- iter: 0640/1140
[A[ATraining Step: 381  | total loss: [1m[32m0.64009[0m[0m | time: 19.409s
[2K
| Adam | epoch: 011 | loss: 0.64009 - acc: 0.6289 -- iter: 0672/1140
[A[ATraining Step: 382  | total loss: [1m[32m0.64207[0m[0m | time: 20.273s
[2K
| Adam | epoch: 011 | loss: 0.64207 - acc: 0.6254 -- iter: 0704/1140
[A[ATraining Step: 383  | total loss: [1m[32m0.65217[0m[0m | time: 21.159s
[2K
| Adam | epoch: 011 | loss: 0.65217 - acc: 0.6097 -- iter: 0736/1140
[A[ATraining Step: 384  | total loss: [1m[32m0.65143[0m[0m | time: 22.215s
[2K
| Adam | epoch: 011 | loss: 0.65143 - acc: 0.6113 -- iter: 0768/1140
[A[ATraining Step: 385  | total loss: [1m[32m0.66084[0m[0m | time: 23.229s
[2K
| Adam | epoch: 011 | loss: 0.66084 - acc: 0.5970 -- iter: 0800/1140
[A[ATraining Step: 386  | total loss: [1m[32m0.65405[0m[0m | time: 24.040s
[2K
| Adam | epoch: 011 | loss: 0.65405 - acc: 0.6092 -- iter: 0832/1140
[A[ATraining Step: 387  | total loss: [1m[32m0.65177[0m[0m | time: 24.966s
[2K
| Adam | epoch: 011 | loss: 0.65177 - acc: 0.6108 -- iter: 0864/1140
[A[ATraining Step: 388  | total loss: [1m[32m0.65184[0m[0m | time: 26.328s
[2K
| Adam | epoch: 011 | loss: 0.65184 - acc: 0.6091 -- iter: 0896/1140
[A[ATraining Step: 389  | total loss: [1m[32m0.65075[0m[0m | time: 27.635s
[2K
| Adam | epoch: 011 | loss: 0.65075 - acc: 0.6107 -- iter: 0928/1140
[A[ATraining Step: 390  | total loss: [1m[32m0.64886[0m[0m | time: 29.000s
[2K
| Adam | epoch: 011 | loss: 0.64886 - acc: 0.6090 -- iter: 0960/1140
[A[ATraining Step: 391  | total loss: [1m[32m0.64984[0m[0m | time: 30.119s
[2K
| Adam | epoch: 011 | loss: 0.64984 - acc: 0.6043 -- iter: 0992/1140
[A[ATraining Step: 392  | total loss: [1m[32m0.64817[0m[0m | time: 31.335s
[2K
| Adam | epoch: 011 | loss: 0.64817 - acc: 0.6064 -- iter: 1024/1140
[A[ATraining Step: 393  | total loss: [1m[32m0.64427[0m[0m | time: 32.692s
[2K
| Adam | epoch: 011 | loss: 0.64427 - acc: 0.6114 -- iter: 1056/1140
[A[ATraining Step: 394  | total loss: [1m[32m0.65012[0m[0m | time: 33.964s
[2K
| Adam | epoch: 011 | loss: 0.65012 - acc: 0.5940 -- iter: 1088/1140
[A[ATraining Step: 395  | total loss: [1m[32m0.65007[0m[0m | time: 35.197s
[2K
| Adam | epoch: 011 | loss: 0.65007 - acc: 0.5940 -- iter: 1120/1140
[A[ATraining Step: 396  | total loss: [1m[32m0.65073[0m[0m | time: 39.290s
[2K
| Adam | epoch: 011 | loss: 0.65073 - acc: 0.5939 | val_loss: 0.65156 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 397  | total loss: [1m[32m0.64382[0m[0m | time: 1.195s
[2K
| Adam | epoch: 012 | loss: 0.64382 - acc: 0.6033 -- iter: 0032/1140
[A[ATraining Step: 398  | total loss: [1m[32m0.64966[0m[0m | time: 2.308s
[2K
| Adam | epoch: 012 | loss: 0.64966 - acc: 0.5930 -- iter: 0064/1140
[A[ATraining Step: 399  | total loss: [1m[32m0.64781[0m[0m | time: 3.371s
[2K
| Adam | epoch: 012 | loss: 0.64781 - acc: 0.5993 -- iter: 0096/1140
[A[ATraining Step: 400  | total loss: [1m[32m0.64244[0m[0m | time: 7.383s
[2K
| Adam | epoch: 012 | loss: 0.64244 - acc: 0.6112 | val_loss: 0.65097 - val_acc: 0.5966 -- iter: 0128/1140
--
Training Step: 401  | total loss: [1m[32m0.63766[0m[0m | time: 8.521s
[2K
| Adam | epoch: 012 | loss: 0.63766 - acc: 0.6220 -- iter: 0160/1140
[A[ATraining Step: 402  | total loss: [1m[32m0.64591[0m[0m | time: 9.788s
[2K
| Adam | epoch: 012 | loss: 0.64591 - acc: 0.6067 -- iter: 0192/1140
[A[ATraining Step: 403  | total loss: [1m[32m0.64696[0m[0m | time: 10.927s
[2K
| Adam | epoch: 012 | loss: 0.64696 - acc: 0.6023 -- iter: 0224/1140
[A[ATraining Step: 404  | total loss: [1m[32m0.64619[0m[0m | time: 12.181s
[2K
| Adam | epoch: 012 | loss: 0.64619 - acc: 0.6014 -- iter: 0256/1140
[A[ATraining Step: 405  | total loss: [1m[32m0.65661[0m[0m | time: 13.409s
[2K
| Adam | epoch: 012 | loss: 0.65661 - acc: 0.5850 -- iter: 0288/1140
[A[ATraining Step: 406  | total loss: [1m[32m0.65593[0m[0m | time: 14.207s
[2K
| Adam | epoch: 012 | loss: 0.65593 - acc: 0.5828 -- iter: 0320/1140
[A[ATraining Step: 407  | total loss: [1m[32m0.64988[0m[0m | time: 15.030s
[2K
| Adam | epoch: 012 | loss: 0.64988 - acc: 0.5945 -- iter: 0352/1140
[A[ATraining Step: 408  | total loss: [1m[32m0.64480[0m[0m | time: 16.261s
[2K
| Adam | epoch: 012 | loss: 0.64480 - acc: 0.6050 -- iter: 0384/1140
[A[ATraining Step: 409  | total loss: [1m[32m0.64036[0m[0m | time: 17.480s
[2K
| Adam | epoch: 012 | loss: 0.64036 - acc: 0.6102 -- iter: 0416/1140
[A[ATraining Step: 410  | total loss: [1m[32m0.64149[0m[0m | time: 18.793s
[2K
| Adam | epoch: 012 | loss: 0.64149 - acc: 0.6054 -- iter: 0448/1140
[A[ATraining Step: 411  | total loss: [1m[32m0.64256[0m[0m | time: 20.250s
[2K
| Adam | epoch: 012 | loss: 0.64256 - acc: 0.6042 -- iter: 0480/1140
[A[ATraining Step: 412  | total loss: [1m[32m0.64011[0m[0m | time: 21.433s
[2K
| Adam | epoch: 012 | loss: 0.64011 - acc: 0.6063 -- iter: 0512/1140
[A[ATraining Step: 413  | total loss: [1m[32m0.63930[0m[0m | time: 22.713s
[2K
| Adam | epoch: 012 | loss: 0.63930 - acc: 0.6050 -- iter: 0544/1140
[A[ATraining Step: 414  | total loss: [1m[32m0.63745[0m[0m | time: 23.771s
[2K
| Adam | epoch: 012 | loss: 0.63745 - acc: 0.6070 -- iter: 0576/1140
[A[ATraining Step: 415  | total loss: [1m[32m0.63658[0m[0m | time: 24.955s
[2K
| Adam | epoch: 012 | loss: 0.63658 - acc: 0.6026 -- iter: 0608/1140
[A[ATraining Step: 416  | total loss: [1m[32m0.64502[0m[0m | time: 26.188s
[2K
| Adam | epoch: 012 | loss: 0.64502 - acc: 0.5923 -- iter: 0640/1140
[A[ATraining Step: 417  | total loss: [1m[32m0.64648[0m[0m | time: 27.377s
[2K
| Adam | epoch: 012 | loss: 0.64648 - acc: 0.5925 -- iter: 0672/1140
[A[ATraining Step: 418  | total loss: [1m[32m0.64482[0m[0m | time: 28.632s
[2K
| Adam | epoch: 012 | loss: 0.64482 - acc: 0.5926 -- iter: 0704/1140
[A[ATraining Step: 419  | total loss: [1m[32m0.65200[0m[0m | time: 29.994s
[2K
| Adam | epoch: 012 | loss: 0.65200 - acc: 0.5802 -- iter: 0736/1140
[A[ATraining Step: 420  | total loss: [1m[32m0.64747[0m[0m | time: 31.167s
[2K
| Adam | epoch: 012 | loss: 0.64747 - acc: 0.5909 -- iter: 0768/1140
[A[ATraining Step: 421  | total loss: [1m[32m0.64724[0m[0m | time: 32.602s
[2K
| Adam | epoch: 012 | loss: 0.64724 - acc: 0.5850 -- iter: 0800/1140
[A[ATraining Step: 422  | total loss: [1m[32m0.64112[0m[0m | time: 33.901s
[2K
| Adam | epoch: 012 | loss: 0.64112 - acc: 0.5984 -- iter: 0832/1140
[A[ATraining Step: 423  | total loss: [1m[32m0.64157[0m[0m | time: 35.183s
[2K
| Adam | epoch: 012 | loss: 0.64157 - acc: 0.5948 -- iter: 0864/1140
[A[ATraining Step: 424  | total loss: [1m[32m0.63430[0m[0m | time: 36.142s
[2K
| Adam | epoch: 012 | loss: 0.63430 - acc: 0.6072 -- iter: 0896/1140
[A[ATraining Step: 425  | total loss: [1m[32m0.63233[0m[0m | time: 37.375s
[2K
| Adam | epoch: 012 | loss: 0.63233 - acc: 0.6089 -- iter: 0928/1140
[A[ATraining Step: 426  | total loss: [1m[32m0.63362[0m[0m | time: 38.685s
[2K
| Adam | epoch: 012 | loss: 0.63362 - acc: 0.6074 -- iter: 0960/1140
[A[ATraining Step: 427  | total loss: [1m[32m0.63210[0m[0m | time: 39.900s
[2K
| Adam | epoch: 012 | loss: 0.63210 - acc: 0.5998 -- iter: 0992/1140
[A[ATraining Step: 428  | total loss: [1m[32m0.62695[0m[0m | time: 40.955s
[2K
| Adam | epoch: 012 | loss: 0.62695 - acc: 0.6086 -- iter: 1024/1140
[A[ATraining Step: 429  | total loss: [1m[32m0.62743[0m[0m | time: 42.124s
[2K
| Adam | epoch: 012 | loss: 0.62743 - acc: 0.6008 -- iter: 1056/1140
[A[ATraining Step: 430  | total loss: [1m[32m0.62589[0m[0m | time: 43.449s
[2K
| Adam | epoch: 012 | loss: 0.62589 - acc: 0.6064 -- iter: 1088/1140
[A[ATraining Step: 431  | total loss: [1m[32m0.60881[0m[0m | time: 44.760s
[2K
| Adam | epoch: 012 | loss: 0.60881 - acc: 0.6270 -- iter: 1120/1140
[A[ATraining Step: 432  | total loss: [1m[32m0.61996[0m[0m | time: 49.076s
[2K
| Adam | epoch: 012 | loss: 0.61996 - acc: 0.6143 | val_loss: 0.64321 - val_acc: 0.5966 -- iter: 1140/1140
--
Training Step: 433  | total loss: [1m[32m0.60836[0m[0m | time: 4.818s
[2K
| Adam | epoch: 013 | loss: 0.60836 - acc: 0.6216 -- iter: 0032/1140
[A[ATraining Step: 434  | total loss: [1m[32m0.61644[0m[0m | time: 8.142s
[2K
| Adam | epoch: 013 | loss: 0.61644 - acc: 0.6126 -- iter: 0064/1140
[A[ATraining Step: 435  | total loss: [1m[32m0.61316[0m[0m | time: 9.315s
[2K
| Adam | epoch: 013 | loss: 0.61316 - acc: 0.6138 -- iter: 0096/1140
[A[ATraining Step: 436  | total loss: [1m[32m0.61419[0m[0m | time: 10.421s
[2K
| Adam | epoch: 013 | loss: 0.61419 - acc: 0.6024 -- iter: 0128/1140
[A[ATraining Step: 437  | total loss: [1m[32m0.61293[0m[0m | time: 11.476s
[2K
| Adam | epoch: 013 | loss: 0.61293 - acc: 0.6047 -- iter: 0160/1140
[A[ATraining Step: 438  | total loss: [1m[32m0.61602[0m[0m | time: 12.676s
[2K
| Adam | epoch: 013 | loss: 0.61602 - acc: 0.6036 -- iter: 0192/1140
[A[ATraining Step: 439  | total loss: [1m[32m0.61673[0m[0m | time: 14.020s
[2K
| Adam | epoch: 013 | loss: 0.61673 - acc: 0.5995 -- iter: 0224/1140
[A[ATraining Step: 440  | total loss: [1m[32m0.61664[0m[0m | time: 15.340s
[2K
| Adam | epoch: 013 | loss: 0.61664 - acc: 0.6052 -- iter: 0256/1140
[A[ATraining Step: 441  | total loss: [1m[32m0.61718[0m[0m | time: 16.648s
[2K
| Adam | epoch: 013 | loss: 0.61718 - acc: 0.6134 -- iter: 0288/1140
[A[ATraining Step: 442  | total loss: [1m[32m0.62161[0m[0m | time: 17.932s
[2K
| Adam | epoch: 013 | loss: 0.62161 - acc: 0.6114 -- iter: 0320/1140
[A[ATraining Step: 443  | total loss: [1m[32m0.62162[0m[0m | time: 18.815s
[2K
| Adam | epoch: 013 | loss: 0.62162 - acc: 0.6190 -- iter: 0352/1140
[A[ATraining Step: 444  | total loss: [1m[32m0.61707[0m[0m | time: 19.686s
[2K
| Adam | epoch: 013 | loss: 0.61707 - acc: 0.6221 -- iter: 0384/1140
[A[ATraining Step: 445  | total loss: [1m[32m0.61143[0m[0m | time: 20.951s
[2K
| Adam | epoch: 013 | loss: 0.61143 - acc: 0.6399 -- iter: 0416/1140
[A[ATraining Step: 446  | total loss: [1m[32m0.61230[0m[0m | time: 22.174s
[2K
| Adam | epoch: 013 | loss: 0.61230 - acc: 0.6353 -- iter: 0448/1140
[A[ATraining Step: 447  | total loss: [1m[32m0.62336[0m[0m | time: 23.104s
[2K
| Adam | epoch: 013 | loss: 0.62336 - acc: 0.6218 -- iter: 0480/1140
[A[ATraining Step: 448  | total loss: [1m[32m0.63197[0m[0m | time: 24.232s
[2K
| Adam | epoch: 013 | loss: 0.63197 - acc: 0.6158 -- iter: 0512/1140
[A[ATraining Step: 449  | total loss: [1m[32m0.62605[0m[0m | time: 25.461s
[2K
| Adam | epoch: 013 | loss: 0.62605 - acc: 0.6261 -- iter: 0544/1140
[A[ATraining Step: 450  | total loss: [1m[32m0.62184[0m[0m | time: 26.593s
[2K
| Adam | epoch: 013 | loss: 0.62184 - acc: 0.6229 -- iter: 0576/1140
[A[ATraining Step: 451  | total loss: [1m[32m0.63056[0m[0m | time: 27.740s
[2K
| Adam | epoch: 013 | loss: 0.63056 - acc: 0.6044 -- iter: 0608/1140
[A[ATraining Step: 452  | total loss: [1m[32m0.63049[0m[0m | time: 28.942s
[2K
| Adam | epoch: 013 | loss: 0.63049 - acc: 0.6095 -- iter: 0640/1140
[A[ATraining Step: 453  | total loss: [1m[32m0.62864[0m[0m | time: 30.223s
[2K
| Adam | epoch: 013 | loss: 0.62864 - acc: 0.6236 -- iter: 0672/1140
[A[ATraining Step: 454  | total loss: [1m[32m0.62579[0m[0m | time: 31.530s
[2K
| Adam | epoch: 013 | loss: 0.62579 - acc: 0.6269 -- iter: 0704/1140
[A[ATraining Step: 455  | total loss: [1m[32m0.62391[0m[0m | time: 32.695s
[2K
| Adam | epoch: 013 | loss: 0.62391 - acc: 0.6392 -- iter: 0736/1140
[A[ATraining Step: 456  | total loss: [1m[32m0.62561[0m[0m | time: 34.112s
[2K
| Adam | epoch: 013 | loss: 0.62561 - acc: 0.6315 -- iter: 0768/1140
[A[ATraining Step: 457  | total loss: [1m[32m0.61638[0m[0m | time: 35.611s
[2K
| Adam | epoch: 013 | loss: 0.61638 - acc: 0.6340 -- iter: 0800/1140
[A[ATraining Step: 458  | total loss: [1m[32m0.61352[0m[0m | time: 36.868s
[2K
| Adam | epoch: 013 | loss: 0.61352 - acc: 0.6393 -- iter: 0832/1140
[A[ATraining Step: 459  | total loss: [1m[32m0.60817[0m[0m | time: 37.965s
[2K
| Adam | epoch: 013 | loss: 0.60817 - acc: 0.6566 -- iter: 0864/1140
[A[ATraining Step: 460  | total loss: [1m[32m0.60523[0m[0m | time: 39.232s
[2K
| Adam | epoch: 013 | loss: 0.60523 - acc: 0.6472 -- iter: 0896/1140
[A[ATraining Step: 461  | total loss: [1m[32m0.59384[0m[0m | time: 40.462s
[2K
| Adam | epoch: 013 | loss: 0.59384 - acc: 0.6606 -- iter: 0928/1140
[A[ATraining Step: 462  | total loss: [1m[32m0.59023[0m[0m | time: 41.755s
[2K
| Adam | epoch: 013 | loss: 0.59023 - acc: 0.6664 -- iter: 0960/1140
[A[ATraining Step: 463  | total loss: [1m[32m0.60262[0m[0m | time: 42.968s
[2K
| Adam | epoch: 013 | loss: 0.60262 - acc: 0.6529 -- iter: 0992/1140
[A[ATraining Step: 464  | total loss: [1m[32m0.60997[0m[0m | time: 44.210s
[2K
| Adam | epoch: 013 | loss: 0.60997 - acc: 0.6470 -- iter: 1024/1140
[A[ATraining Step: 465  | total loss: [1m[32m0.60000[0m[0m | time: 45.526s
[2K
| Adam | epoch: 013 | loss: 0.60000 - acc: 0.6636 -- iter: 1056/1140
[A[ATraining Step: 466  | total loss: [1m[32m0.61096[0m[0m | time: 46.731s
[2K
| Adam | epoch: 013 | loss: 0.61096 - acc: 0.6503 -- iter: 1088/1140
[A[ATraining Step: 467  | total loss: [1m[32m0.60807[0m[0m | time: 47.854s
[2K
| Adam | epoch: 013 | loss: 0.60807 - acc: 0.6603 -- iter: 1120/1140
[A[ATraining Step: 468  | total loss: [1m[32m0.61389[0m[0m | time: 52.331s
[2K
| Adam | epoch: 013 | loss: 0.61389 - acc: 0.6599 | val_loss: 0.63295 - val_acc: 0.6415 -- iter: 1140/1140
--
Training Step: 469  | total loss: [1m[32m0.60497[0m[0m | time: 0.919s
[2K
| Adam | epoch: 014 | loss: 0.60497 - acc: 0.6689 -- iter: 0032/1140
[A[ATraining Step: 470  | total loss: [1m[32m0.60728[0m[0m | time: 1.825s
[2K
| Adam | epoch: 014 | loss: 0.60728 - acc: 0.6770 -- iter: 0064/1140
[A[ATraining Step: 471  | total loss: [1m[32m0.60770[0m[0m | time: 2.777s
[2K
| Adam | epoch: 014 | loss: 0.60770 - acc: 0.6874 -- iter: 0096/1140
[A[ATraining Step: 472  | total loss: [1m[32m0.60797[0m[0m | time: 3.687s
[2K
| Adam | epoch: 014 | loss: 0.60797 - acc: 0.6812 -- iter: 0128/1140
[A[ATraining Step: 473  | total loss: [1m[32m0.60738[0m[0m | time: 4.666s
[2K
| Adam | epoch: 014 | loss: 0.60738 - acc: 0.6787 -- iter: 0160/1140
[A[ATraining Step: 474  | total loss: [1m[32m0.60593[0m[0m | time: 5.662s
[2K
| Adam | epoch: 014 | loss: 0.60593 - acc: 0.6702 -- iter: 0192/1140
[A[ATraining Step: 475  | total loss: [1m[32m0.60072[0m[0m | time: 6.572s
[2K
| Adam | epoch: 014 | loss: 0.60072 - acc: 0.6782 -- iter: 0224/1140
[A[ATraining Step: 476  | total loss: [1m[32m0.59894[0m[0m | time: 7.489s
[2K
| Adam | epoch: 014 | loss: 0.59894 - acc: 0.6791 -- iter: 0256/1140
[A[ATraining Step: 477  | total loss: [1m[32m0.59873[0m[0m | time: 8.509s
[2K
| Adam | epoch: 014 | loss: 0.59873 - acc: 0.6737 -- iter: 0288/1140
[A[ATraining Step: 478  | total loss: [1m[32m0.60013[0m[0m | time: 9.677s
[2K
| Adam | epoch: 014 | loss: 0.60013 - acc: 0.6657 -- iter: 0320/1140
[A[ATraining Step: 479  | total loss: [1m[32m0.60809[0m[0m | time: 10.479s
[2K
| Adam | epoch: 014 | loss: 0.60809 - acc: 0.6554 -- iter: 0352/1140
[A[ATraining Step: 480  | total loss: [1m[32m0.62078[0m[0m | time: 10.979s
[2K
| Adam | epoch: 014 | loss: 0.62078 - acc: 0.6461 -- iter: 0384/1140
[A[ATraining Step: 481  | total loss: [1m[32m0.62384[0m[0m | time: 11.564s
[2K
| Adam | epoch: 014 | loss: 0.62384 - acc: 0.6565 -- iter: 0416/1140
[A[ATraining Step: 482  | total loss: [1m[32m0.62620[0m[0m | time: 12.491s
[2K
| Adam | epoch: 014 | loss: 0.62620 - acc: 0.6608 -- iter: 0448/1140
[A[ATraining Step: 483  | total loss: [1m[32m0.62806[0m[0m | time: 13.448s
[2K
| Adam | epoch: 014 | loss: 0.62806 - acc: 0.6573 -- iter: 0480/1140
[A[ATraining Step: 484  | total loss: [1m[32m0.62969[0m[0m | time: 14.366s
[2K
| Adam | epoch: 014 | loss: 0.62969 - acc: 0.6540 -- iter: 0512/1140
[A[ATraining Step: 485  | total loss: [1m[32m0.63269[0m[0m | time: 15.364s
[2K
| Adam | epoch: 014 | loss: 0.63269 - acc: 0.6324 -- iter: 0544/1140
[A[ATraining Step: 486  | total loss: [1m[32m0.63511[0m[0m | time: 16.364s
[2K
| Adam | epoch: 014 | loss: 0.63511 - acc: 0.6254 -- iter: 0576/1140
[A[ATraining Step: 487  | total loss: [1m[32m0.63223[0m[0m | time: 17.380s
[2K
| Adam | epoch: 014 | loss: 0.63223 - acc: 0.6347 -- iter: 0608/1140
[A[ATraining Step: 488  | total loss: [1m[32m0.62492[0m[0m | time: 18.291s
[2K
| Adam | epoch: 014 | loss: 0.62492 - acc: 0.6431 -- iter: 0640/1140
[A[ATraining Step: 489  | total loss: [1m[32m0.61977[0m[0m | time: 19.352s
[2K
| Adam | epoch: 014 | loss: 0.61977 - acc: 0.6444 -- iter: 0672/1140
[A[ATraining Step: 490  | total loss: [1m[32m0.62217[0m[0m | time: 20.811s
[2K
| Adam | epoch: 014 | loss: 0.62217 - acc: 0.6269 -- iter: 0704/1140
[A[ATraining Step: 491  | total loss: [1m[32m0.61106[0m[0m | time: 22.180s
[2K
| Adam | epoch: 014 | loss: 0.61106 - acc: 0.6267 -- iter: 0736/1140
[A[ATraining Step: 492  | total loss: [1m[32m0.60851[0m[0m | time: 23.336s
[2K
| Adam | epoch: 014 | loss: 0.60851 - acc: 0.6359 -- iter: 0768/1140
[A[ATraining Step: 493  | total loss: [1m[32m0.60620[0m[0m | time: 24.380s
[2K
| Adam | epoch: 014 | loss: 0.60620 - acc: 0.6286 -- iter: 0800/1140
[A[ATraining Step: 494  | total loss: [1m[32m0.58228[0m[0m | time: 25.480s
[2K
| Adam | epoch: 014 | loss: 0.58228 - acc: 0.6594 -- iter: 0832/1140
[A[ATraining Step: 495  | total loss: [1m[32m0.58178[0m[0m | time: 26.604s
[2K
| Adam | epoch: 014 | loss: 0.58178 - acc: 0.6591 -- iter: 0864/1140
[A[ATraining Step: 496  | total loss: [1m[32m0.58628[0m[0m | time: 27.884s
[2K
| Adam | epoch: 014 | loss: 0.58628 - acc: 0.6588 -- iter: 0896/1140
[A[ATraining Step: 497  | total loss: [1m[32m0.59738[0m[0m | time: 29.125s
[2K
| Adam | epoch: 014 | loss: 0.59738 - acc: 0.6648 -- iter: 0928/1140
[A[ATraining Step: 498  | total loss: [1m[32m0.60307[0m[0m | time: 30.315s
[2K
| Adam | epoch: 014 | loss: 0.60307 - acc: 0.6577 -- iter: 0960/1140
[A[ATraining Step: 499  | total loss: [1m[32m0.59890[0m[0m | time: 31.601s
[2K
| Adam | epoch: 014 | loss: 0.59890 - acc: 0.6638 -- iter: 0992/1140
[A[ATraining Step: 500  | total loss: [1m[32m0.59150[0m[0m | time: 32.940s
[2K
| Adam | epoch: 014 | loss: 0.59150 - acc: 0.6756 -- iter: 1024/1140
[A[ATraining Step: 501  | total loss: [1m[32m0.59193[0m[0m | time: 34.079s
[2K
| Adam | epoch: 014 | loss: 0.59193 - acc: 0.6736 -- iter: 1056/1140
[A[ATraining Step: 502  | total loss: [1m[32m0.59239[0m[0m | time: 35.498s
[2K
| Adam | epoch: 014 | loss: 0.59239 - acc: 0.6719 -- iter: 1088/1140
[A[ATraining Step: 503  | total loss: [1m[32m0.59449[0m[0m | time: 36.879s
[2K
| Adam | epoch: 014 | loss: 0.59449 - acc: 0.6610 -- iter: 1120/1140
[A[ATraining Step: 504  | total loss: [1m[32m0.59838[0m[0m | time: 43.237s
[2K
| Adam | epoch: 014 | loss: 0.59838 - acc: 0.6574 | val_loss: 0.62710 - val_acc: 0.6303 -- iter: 1140/1140
--
Training Step: 505  | total loss: [1m[32m0.60002[0m[0m | time: 1.189s
[2K
| Adam | epoch: 015 | loss: 0.60002 - acc: 0.6573 -- iter: 0032/1140
[A[ATraining Step: 506  | total loss: [1m[32m0.59543[0m[0m | time: 2.561s
[2K
| Adam | epoch: 015 | loss: 0.59543 - acc: 0.6603 -- iter: 0064/1140
[A[ATraining Step: 507  | total loss: [1m[32m0.61429[0m[0m | time: 3.837s
[2K
| Adam | epoch: 015 | loss: 0.61429 - acc: 0.6411 -- iter: 0096/1140
[A[ATraining Step: 508  | total loss: [1m[32m0.61571[0m[0m | time: 5.164s
[2K
| Adam | epoch: 015 | loss: 0.61571 - acc: 0.6426 -- iter: 0128/1140
[A[ATraining Step: 509  | total loss: [1m[32m0.61751[0m[0m | time: 6.232s
[2K
| Adam | epoch: 015 | loss: 0.61751 - acc: 0.6315 -- iter: 0160/1140
[A[ATraining Step: 510  | total loss: [1m[32m0.61810[0m[0m | time: 7.440s
[2K
| Adam | epoch: 015 | loss: 0.61810 - acc: 0.6308 -- iter: 0192/1140
[A[ATraining Step: 511  | total loss: [1m[32m0.61368[0m[0m | time: 8.614s
[2K
| Adam | epoch: 015 | loss: 0.61368 - acc: 0.6365 -- iter: 0224/1140
[A[ATraining Step: 512  | total loss: [1m[32m0.60327[0m[0m | time: 9.773s
[2K
| Adam | epoch: 015 | loss: 0.60327 - acc: 0.6479 -- iter: 0256/1140
[A[ATraining Step: 513  | total loss: [1m[32m0.58373[0m[0m | time: 10.718s
[2K
| Adam | epoch: 015 | loss: 0.58373 - acc: 0.6675 -- iter: 0288/1140
[A[ATraining Step: 514  | total loss: [1m[32m0.60713[0m[0m | time: 11.746s
[2K
| Adam | epoch: 015 | loss: 0.60713 - acc: 0.6507 -- iter: 0320/1140
[A[ATraining Step: 515  | total loss: [1m[32m0.61764[0m[0m | time: 12.854s
[2K
| Adam | epoch: 015 | loss: 0.61764 - acc: 0.6419 -- iter: 0352/1140
[A[ATraining Step: 516  | total loss: [1m[32m0.61339[0m[0m | time: 13.897s
[2K
| Adam | epoch: 015 | loss: 0.61339 - acc: 0.6496 -- iter: 0384/1140
[A[ATraining Step: 517  | total loss: [1m[32m0.60954[0m[0m | time: 14.566s
[2K
| Adam | epoch: 015 | loss: 0.60954 - acc: 0.6502 -- iter: 0416/1140
[A[ATraining Step: 518  | total loss: [1m[32m0.61047[0m[0m | time: 15.322s
[2K
| Adam | epoch: 015 | loss: 0.61047 - acc: 0.6552 -- iter: 0448/1140
[A[ATraining Step: 519  | total loss: [1m[32m0.61146[0m[0m | time: 16.605s
[2K
| Adam | epoch: 015 | loss: 0.61146 - acc: 0.6597 -- iter: 0480/1140
[A[ATraining Step: 520  | total loss: [1m[32m0.60798[0m[0m | time: 17.928s
[2K
| Adam | epoch: 015 | loss: 0.60798 - acc: 0.6750 -- iter: 0512/1140
[A[ATraining Step: 521  | total loss: [1m[32m0.60498[0m[0m | time: 19.325s
[2K
| Adam | epoch: 015 | loss: 0.60498 - acc: 0.6762 -- iter: 0544/1140
[A[ATraining Step: 522  | total loss: [1m[32m0.60115[0m[0m | time: 20.289s
[2K
| Adam | epoch: 015 | loss: 0.60115 - acc: 0.6805 -- iter: 0576/1140
[A[ATraining Step: 523  | total loss: [1m[32m0.60272[0m[0m | time: 21.331s
[2K
| Adam | epoch: 015 | loss: 0.60272 - acc: 0.6812 -- iter: 0608/1140
[A[ATraining Step: 524  | total loss: [1m[32m0.60913[0m[0m | time: 22.563s
[2K
| Adam | epoch: 015 | loss: 0.60913 - acc: 0.6756 -- iter: 0640/1140
[A[ATraining Step: 525  | total loss: [1m[32m0.60347[0m[0m | time: 23.878s
[2K
| Adam | epoch: 015 | loss: 0.60347 - acc: 0.6768 -- iter: 0672/1140
[A[ATraining Step: 526  | total loss: [1m[32m0.58982[0m[0m | time: 25.065s
[2K
| Adam | epoch: 015 | loss: 0.58982 - acc: 0.6903 -- iter: 0704/1140
[A[ATraining Step: 527  | total loss: [1m[32m0.59783[0m[0m | time: 26.170s
[2K
| Adam | epoch: 015 | loss: 0.59783 - acc: 0.6838 -- iter: 0736/1140
[A[ATraining Step: 528  | total loss: [1m[32m0.58989[0m[0m | time: 27.463s
[2K
| Adam | epoch: 015 | loss: 0.58989 - acc: 0.6967 -- iter: 0768/1140
[A[ATraining Step: 529  | total loss: [1m[32m0.59150[0m[0m | time: 28.730s
[2K
| Adam | epoch: 015 | loss: 0.59150 - acc: 0.6801 -- iter: 0800/1140
[A[ATraining Step: 530  | total loss: [1m[32m0.59212[0m[0m | time: 30.020s
[2K
| Adam | epoch: 015 | loss: 0.59212 - acc: 0.6684 -- iter: 0832/1140
[A[ATraining Step: 531  | total loss: [1m[32m0.59665[0m[0m | time: 31.419s
[2K
| Adam | epoch: 015 | loss: 0.59665 - acc: 0.6578 -- iter: 0864/1140
[A[ATraining Step: 532  | total loss: [1m[32m0.59379[0m[0m | time: 32.748s
[2K
| Adam | epoch: 015 | loss: 0.59379 - acc: 0.6639 -- iter: 0896/1140
[A[ATraining Step: 533  | total loss: [1m[32m0.58851[0m[0m | time: 34.095s
[2K
| Adam | epoch: 015 | loss: 0.58851 - acc: 0.6662 -- iter: 0928/1140
[A[ATraining Step: 534  | total loss: [1m[32m0.58801[0m[0m | time: 35.802s
[2K
| Adam | epoch: 015 | loss: 0.58801 - acc: 0.6652 -- iter: 0960/1140
[A[ATraining Step: 535  | total loss: [1m[32m0.58858[0m[0m | time: 37.003s
[2K
| Adam | epoch: 015 | loss: 0.58858 - acc: 0.6768 -- iter: 0992/1140
[A[ATraining Step: 536  | total loss: [1m[32m0.58319[0m[0m | time: 38.311s
[2K
| Adam | epoch: 015 | loss: 0.58319 - acc: 0.6904 -- iter: 1024/1140
[A[ATraining Step: 537  | total loss: [1m[32m0.57800[0m[0m | time: 39.573s
[2K
| Adam | epoch: 015 | loss: 0.57800 - acc: 0.6901 -- iter: 1056/1140
[A[ATraining Step: 538  | total loss: [1m[32m0.57894[0m[0m | time: 40.955s
[2K
| Adam | epoch: 015 | loss: 0.57894 - acc: 0.6930 -- iter: 1088/1140
[A[ATraining Step: 539  | total loss: [1m[32m0.58412[0m[0m | time: 42.123s
[2K
| Adam | epoch: 015 | loss: 0.58412 - acc: 0.6862 -- iter: 1120/1140
[A[ATraining Step: 540  | total loss: [1m[32m0.57625[0m[0m | time: 46.191s
[2K
| Adam | epoch: 015 | loss: 0.57625 - acc: 0.6988 | val_loss: 0.61739 - val_acc: 0.6527 -- iter: 1140/1140
--
Training Step: 541  | total loss: [1m[32m0.58703[0m[0m | time: 1.288s
[2K
| Adam | epoch: 016 | loss: 0.58703 - acc: 0.6914 -- iter: 0032/1140
[A[ATraining Step: 542  | total loss: [1m[32m0.58850[0m[0m | time: 2.465s
[2K
| Adam | epoch: 016 | loss: 0.58850 - acc: 0.6910 -- iter: 0064/1140
[A[ATraining Step: 543  | total loss: [1m[32m0.58163[0m[0m | time: 3.709s
[2K
| Adam | epoch: 016 | loss: 0.58163 - acc: 0.7032 -- iter: 0096/1140
[A[ATraining Step: 544  | total loss: [1m[32m0.57652[0m[0m | time: 5.031s
[2K
| Adam | epoch: 016 | loss: 0.57652 - acc: 0.7110 -- iter: 0128/1140
[A[ATraining Step: 545  | total loss: [1m[32m0.57638[0m[0m | time: 6.307s
[2K
| Adam | epoch: 016 | loss: 0.57638 - acc: 0.7243 -- iter: 0160/1140
[A[ATraining Step: 546  | total loss: [1m[32m0.56598[0m[0m | time: 7.418s
[2K
| Adam | epoch: 016 | loss: 0.56598 - acc: 0.7362 -- iter: 0192/1140
[A[ATraining Step: 547  | total loss: [1m[32m0.56179[0m[0m | time: 8.582s
[2K
| Adam | epoch: 016 | loss: 0.56179 - acc: 0.7313 -- iter: 0224/1140
[A[ATraining Step: 548  | total loss: [1m[32m0.56265[0m[0m | time: 9.808s
[2K
| Adam | epoch: 016 | loss: 0.56265 - acc: 0.7301 -- iter: 0256/1140
[A[ATraining Step: 549  | total loss: [1m[32m0.56798[0m[0m | time: 11.170s
[2K
| Adam | epoch: 016 | loss: 0.56798 - acc: 0.7227 -- iter: 0288/1140
[A[ATraining Step: 550  | total loss: [1m[32m0.57364[0m[0m | time: 12.513s
[2K
| Adam | epoch: 016 | loss: 0.57364 - acc: 0.7067 -- iter: 0320/1140
[A[ATraining Step: 551  | total loss: [1m[32m0.57069[0m[0m | time: 13.722s
[2K
| Adam | epoch: 016 | loss: 0.57069 - acc: 0.7079 -- iter: 0352/1140
[A[ATraining Step: 552  | total loss: [1m[32m0.56331[0m[0m | time: 16.757s
[2K
| Adam | epoch: 016 | loss: 0.56331 - acc: 0.7183 -- iter: 0384/1140
[A[ATraining Step: 553  | total loss: [1m[32m0.56786[0m[0m | time: 17.941s
[2K
| Adam | epoch: 016 | loss: 0.56786 - acc: 0.7028 -- iter: 0416/1140
[A[ATraining Step: 554  | total loss: [1m[32m0.56845[0m[0m | time: 18.763s
[2K
| Adam | epoch: 016 | loss: 0.56845 - acc: 0.6950 -- iter: 0448/1140
[A[ATraining Step: 555  | total loss: [1m[32m0.57446[0m[0m | time: 19.534s
[2K
| Adam | epoch: 016 | loss: 0.57446 - acc: 0.6855 -- iter: 0480/1140
[A[ATraining Step: 556  | total loss: [1m[32m0.57931[0m[0m | time: 20.935s
[2K
| Adam | epoch: 016 | loss: 0.57931 - acc: 0.6769 -- iter: 0512/1140
[A[ATraining Step: 557  | total loss: [1m[32m0.58628[0m[0m | time: 22.260s
[2K
| Adam | epoch: 016 | loss: 0.58628 - acc: 0.6655 -- iter: 0544/1140
[A[ATraining Step: 558  | total loss: [1m[32m0.57928[0m[0m | time: 23.511s
[2K
| Adam | epoch: 016 | loss: 0.57928 - acc: 0.6677 -- iter: 0576/1140
[A[ATraining Step: 559  | total loss: [1m[32m0.58374[0m[0m | time: 24.741s
[2K
| Adam | epoch: 016 | loss: 0.58374 - acc: 0.6666 -- iter: 0608/1140
[A[ATraining Step: 560  | total loss: [1m[32m0.58004[0m[0m | time: 25.918s
[2K
| Adam | epoch: 016 | loss: 0.58004 - acc: 0.6749 -- iter: 0640/1140
[A[ATraining Step: 561  | total loss: [1m[32m0.57973[0m[0m | time: 27.189s
[2K
| Adam | epoch: 016 | loss: 0.57973 - acc: 0.6824 -- iter: 0672/1140
[A[ATraining Step: 562  | total loss: [1m[32m0.58015[0m[0m | time: 28.501s
[2K
| Adam | epoch: 016 | loss: 0.58015 - acc: 0.6829 -- iter: 0704/1140
[A[ATraining Step: 563  | total loss: [1m[32m0.57055[0m[0m | time: 29.817s
[2K
| Adam | epoch: 016 | loss: 0.57055 - acc: 0.6959 -- iter: 0736/1140
[A[ATraining Step: 564  | total loss: [1m[32m0.57951[0m[0m | time: 30.949s
[2K
| Adam | epoch: 016 | loss: 0.57951 - acc: 0.6857 -- iter: 0768/1140
[A[ATraining Step: 565  | total loss: [1m[32m0.57500[0m[0m | time: 31.965s
[2K
| Adam | epoch: 016 | loss: 0.57500 - acc: 0.6890 -- iter: 0800/1140
[A[ATraining Step: 566  | total loss: [1m[32m0.57953[0m[0m | time: 33.085s
[2K
| Adam | epoch: 016 | loss: 0.57953 - acc: 0.6857 -- iter: 0832/1140
[A[ATraining Step: 567  | total loss: [1m[32m0.57277[0m[0m | time: 34.357s
[2K
| Adam | epoch: 016 | loss: 0.57277 - acc: 0.6859 -- iter: 0864/1140
[A[ATraining Step: 568  | total loss: [1m[32m0.57514[0m[0m | time: 35.471s
[2K
| Adam | epoch: 016 | loss: 0.57514 - acc: 0.6798 -- iter: 0896/1140
[A[ATraining Step: 569  | total loss: [1m[32m0.56828[0m[0m | time: 36.745s
[2K
| Adam | epoch: 016 | loss: 0.56828 - acc: 0.6837 -- iter: 0928/1140
[A[ATraining Step: 570  | total loss: [1m[32m0.56414[0m[0m | time: 38.103s
[2K
| Adam | epoch: 016 | loss: 0.56414 - acc: 0.6934 -- iter: 0960/1140
[A[ATraining Step: 571  | total loss: [1m[32m0.56805[0m[0m | time: 39.453s
[2K
| Adam | epoch: 016 | loss: 0.56805 - acc: 0.6866 -- iter: 0992/1140
[A[ATraining Step: 572  | total loss: [1m[32m0.56091[0m[0m | time: 40.526s
[2K
| Adam | epoch: 016 | loss: 0.56091 - acc: 0.6961 -- iter: 1024/1140
[A[ATraining Step: 573  | total loss: [1m[32m0.56126[0m[0m | time: 41.682s
[2K
| Adam | epoch: 016 | loss: 0.56126 - acc: 0.6921 -- iter: 1056/1140
[A[ATraining Step: 574  | total loss: [1m[32m0.55261[0m[0m | time: 42.864s
[2K
| Adam | epoch: 016 | loss: 0.55261 - acc: 0.7041 -- iter: 1088/1140
[A[ATraining Step: 575  | total loss: [1m[32m0.54570[0m[0m | time: 44.180s
[2K
| Adam | epoch: 016 | loss: 0.54570 - acc: 0.7150 -- iter: 1120/1140
[A[ATraining Step: 576  | total loss: [1m[32m0.55166[0m[0m | time: 48.367s
[2K
| Adam | epoch: 016 | loss: 0.55166 - acc: 0.7153 | val_loss: 0.63402 - val_acc: 0.6246 -- iter: 1140/1140
--
Training Step: 577  | total loss: [1m[32m0.54472[0m[0m | time: 0.989s
[2K
| Adam | epoch: 017 | loss: 0.54472 - acc: 0.7251 -- iter: 0032/1140
[A[ATraining Step: 578  | total loss: [1m[32m0.54482[0m[0m | time: 2.055s
[2K
| Adam | epoch: 017 | loss: 0.54482 - acc: 0.7244 -- iter: 0064/1140
[A[ATraining Step: 579  | total loss: [1m[32m0.55216[0m[0m | time: 3.073s
[2K
| Adam | epoch: 017 | loss: 0.55216 - acc: 0.7145 -- iter: 0096/1140
[A[ATraining Step: 580  | total loss: [1m[32m0.56191[0m[0m | time: 3.848s
[2K
| Adam | epoch: 017 | loss: 0.56191 - acc: 0.7087 -- iter: 0128/1140
[A[ATraining Step: 581  | total loss: [1m[32m0.56576[0m[0m | time: 4.761s
[2K
| Adam | epoch: 017 | loss: 0.56576 - acc: 0.7003 -- iter: 0160/1140
[A[ATraining Step: 582  | total loss: [1m[32m0.56169[0m[0m | time: 5.630s
[2K
| Adam | epoch: 017 | loss: 0.56169 - acc: 0.7021 -- iter: 0192/1140
[A[ATraining Step: 583  | total loss: [1m[32m0.55733[0m[0m | time: 6.589s
[2K
| Adam | epoch: 017 | loss: 0.55733 - acc: 0.7069 -- iter: 0224/1140
[A[ATraining Step: 584  | total loss: [1m[32m0.57046[0m[0m | time: 7.485s
[2K
| Adam | epoch: 017 | loss: 0.57046 - acc: 0.6925 -- iter: 0256/1140
[A[ATraining Step: 585  | total loss: [1m[32m0.58488[0m[0m | time: 8.422s
[2K
| Adam | epoch: 017 | loss: 0.58488 - acc: 0.6795 -- iter: 0288/1140
[A[ATraining Step: 586  | total loss: [1m[32m0.58887[0m[0m | time: 9.327s
[2K
| Adam | epoch: 017 | loss: 0.58887 - acc: 0.6772 -- iter: 0320/1140
[A[ATraining Step: 587  | total loss: [1m[32m0.58211[0m[0m | time: 10.310s
[2K
| Adam | epoch: 017 | loss: 0.58211 - acc: 0.6813 -- iter: 0352/1140
[A[ATraining Step: 588  | total loss: [1m[32m0.58397[0m[0m | time: 11.147s
[2K
| Adam | epoch: 017 | loss: 0.58397 - acc: 0.6757 -- iter: 0384/1140
[A[ATraining Step: 589  | total loss: [1m[32m0.59239[0m[0m | time: 12.178s
[2K
| Adam | epoch: 017 | loss: 0.59239 - acc: 0.6675 -- iter: 0416/1140
[A[ATraining Step: 590  | total loss: [1m[32m0.59674[0m[0m | time: 13.272s
[2K
| Adam | epoch: 017 | loss: 0.59674 - acc: 0.6632 -- iter: 0448/1140
[A[ATraining Step: 591  | total loss: [1m[32m0.58564[0m[0m | time: 14.053s
[2K
| Adam | epoch: 017 | loss: 0.58564 - acc: 0.6750 -- iter: 0480/1140
[A[ATraining Step: 592  | total loss: [1m[32m0.58357[0m[0m | time: 14.655s
[2K
| Adam | epoch: 017 | loss: 0.58357 - acc: 0.6675 -- iter: 0512/1140
[A[ATraining Step: 593  | total loss: [1m[32m0.58227[0m[0m | time: 15.473s
[2K
| Adam | epoch: 017 | loss: 0.58227 - acc: 0.6558 -- iter: 0544/1140
[A[ATraining Step: 594  | total loss: [1m[32m0.58066[0m[0m | time: 16.409s
[2K
| Adam | epoch: 017 | loss: 0.58066 - acc: 0.6496 -- iter: 0576/1140
[A[ATraining Step: 595  | total loss: [1m[32m0.57025[0m[0m | time: 17.451s
[2K
| Adam | epoch: 017 | loss: 0.57025 - acc: 0.6596 -- iter: 0608/1140
[A[ATraining Step: 596  | total loss: [1m[32m0.55819[0m[0m | time: 18.345s
[2K
| Adam | epoch: 017 | loss: 0.55819 - acc: 0.6749 -- iter: 0640/1140
[A[ATraining Step: 597  | total loss: [1m[32m0.55858[0m[0m | time: 19.319s
[2K
| Adam | epoch: 017 | loss: 0.55858 - acc: 0.6793 -- iter: 0672/1140
[A[ATraining Step: 598  | total loss: [1m[32m0.55706[0m[0m | time: 20.308s
[2K
| Adam | epoch: 017 | loss: 0.55706 - acc: 0.6832 -- iter: 0704/1140
[A[ATraining Step: 599  | total loss: [1m[32m0.56017[0m[0m | time: 21.278s
[2K
| Adam | epoch: 017 | loss: 0.56017 - acc: 0.6899 -- iter: 0736/1140
[A[ATraining Step: 600  | total loss: [1m[32m0.56550[0m[0m | time: 24.500s
[2K
| Adam | epoch: 017 | loss: 0.56550 - acc: 0.6834 | val_loss: 0.61259 - val_acc: 0.6359 -- iter: 0768/1140
--
Training Step: 601  | total loss: [1m[32m0.55694[0m[0m | time: 25.472s
[2K
| Adam | epoch: 017 | loss: 0.55694 - acc: 0.6870 -- iter: 0800/1140
[A[ATraining Step: 602  | total loss: [1m[32m0.56151[0m[0m | time: 26.393s
[2K
| Adam | epoch: 017 | loss: 0.56151 - acc: 0.6839 -- iter: 0832/1140
[A[ATraining Step: 603  | total loss: [1m[32m0.56453[0m[0m | time: 27.458s
[2K
| Adam | epoch: 017 | loss: 0.56453 - acc: 0.6842 -- iter: 0864/1140
[A[ATraining Step: 604  | total loss: [1m[32m0.56419[0m[0m | time: 28.933s
[2K
| Adam | epoch: 017 | loss: 0.56419 - acc: 0.6846 -- iter: 0896/1140
[A[ATraining Step: 605  | total loss: [1m[32m0.56032[0m[0m | time: 30.283s
[2K
| Adam | epoch: 017 | loss: 0.56032 - acc: 0.6880 -- iter: 0928/1140
[A[ATraining Step: 606  | total loss: [1m[32m0.55517[0m[0m | time: 31.715s
[2K
| Adam | epoch: 017 | loss: 0.55517 - acc: 0.7004 -- iter: 0960/1140
[A[ATraining Step: 607  | total loss: [1m[32m0.54962[0m[0m | time: 33.066s
[2K
| Adam | epoch: 017 | loss: 0.54962 - acc: 0.7085 -- iter: 0992/1140
[A[ATraining Step: 608  | total loss: [1m[32m0.53879[0m[0m | time: 34.519s
[2K
| Adam | epoch: 017 | loss: 0.53879 - acc: 0.7189 -- iter: 1024/1140
[A[ATraining Step: 609  | total loss: [1m[32m0.54343[0m[0m | time: 36.012s
[2K
| Adam | epoch: 017 | loss: 0.54343 - acc: 0.7189 -- iter: 1056/1140
[A[ATraining Step: 610  | total loss: [1m[32m0.53859[0m[0m | time: 37.569s
[2K
| Adam | epoch: 017 | loss: 0.53859 - acc: 0.7220 -- iter: 1088/1140
[A[ATraining Step: 611  | total loss: [1m[32m0.53293[0m[0m | time: 39.035s
[2K
| Adam | epoch: 017 | loss: 0.53293 - acc: 0.7248 -- iter: 1120/1140
[A[ATraining Step: 612  | total loss: [1m[32m0.53515[0m[0m | time: 42.086s
[2K
| Adam | epoch: 017 | loss: 0.53515 - acc: 0.7211 | val_loss: 0.67637 - val_acc: 0.6443 -- iter: 1140/1140
--
Training Step: 613  | total loss: [1m[32m0.54398[0m[0m | time: 0.952s
[2K
| Adam | epoch: 018 | loss: 0.54398 - acc: 0.7052 -- iter: 0032/1140
[A[ATraining Step: 614  | total loss: [1m[32m0.54601[0m[0m | time: 1.902s
[2K
| Adam | epoch: 018 | loss: 0.54601 - acc: 0.7003 -- iter: 0064/1140
[A[ATraining Step: 615  | total loss: [1m[32m0.56193[0m[0m | time: 2.868s
[2K
| Adam | epoch: 018 | loss: 0.56193 - acc: 0.6803 -- iter: 0096/1140
[A[ATraining Step: 616  | total loss: [1m[32m0.56528[0m[0m | time: 3.834s
[2K
| Adam | epoch: 018 | loss: 0.56528 - acc: 0.6810 -- iter: 0128/1140
[A[ATraining Step: 617  | total loss: [1m[32m0.56413[0m[0m | time: 4.930s
[2K
| Adam | epoch: 018 | loss: 0.56413 - acc: 0.6817 -- iter: 0160/1140
[A[ATraining Step: 618  | total loss: [1m[32m0.55797[0m[0m | time: 5.931s
[2K
| Adam | epoch: 018 | loss: 0.55797 - acc: 0.6885 -- iter: 0192/1140
[A[ATraining Step: 619  | total loss: [1m[32m0.55923[0m[0m | time: 6.645s
[2K
| Adam | epoch: 018 | loss: 0.55923 - acc: 0.6946 -- iter: 0224/1140
[A[ATraining Step: 620  | total loss: [1m[32m0.56563[0m[0m | time: 7.581s
[2K
| Adam | epoch: 018 | loss: 0.56563 - acc: 0.6908 -- iter: 0256/1140
[A[ATraining Step: 621  | total loss: [1m[32m0.57062[0m[0m | time: 8.524s
[2K
| Adam | epoch: 018 | loss: 0.57062 - acc: 0.6874 -- iter: 0288/1140
[A[ATraining Step: 622  | total loss: [1m[32m0.57988[0m[0m | time: 9.390s
[2K
| Adam | epoch: 018 | loss: 0.57988 - acc: 0.6717 -- iter: 0320/1140
[A[ATraining Step: 623  | total loss: [1m[32m0.58933[0m[0m | time: 10.336s
[2K
| Adam | epoch: 018 | loss: 0.58933 - acc: 0.6608 -- iter: 0352/1140
[A[ATraining Step: 624  | total loss: [1m[32m0.59477[0m[0m | time: 11.323s
[2K
| Adam | epoch: 018 | loss: 0.59477 - acc: 0.6416 -- iter: 0384/1140
[A[ATraining Step: 625  | total loss: [1m[32m0.58966[0m[0m | time: 12.226s
[2K
| Adam | epoch: 018 | loss: 0.58966 - acc: 0.6431 -- iter: 0416/1140
[A[ATraining Step: 626  | total loss: [1m[32m0.57702[0m[0m | time: 13.112s
[2K
| Adam | epoch: 018 | loss: 0.57702 - acc: 0.6569 -- iter: 0448/1140
[A[ATraining Step: 627  | total loss: [1m[32m0.58416[0m[0m | time: 14.015s
[2K
| Adam | epoch: 018 | loss: 0.58416 - acc: 0.6475 -- iter: 0480/1140
[A[ATraining Step: 628  | total loss: [1m[32m0.59036[0m[0m | time: 14.576s
[2K
| Adam | epoch: 018 | loss: 0.59036 - acc: 0.6452 -- iter: 0512/1140
[A[ATraining Step: 629  | total loss: [1m[32m0.58669[0m[0m | time: 15.311s
[2K
| Adam | epoch: 018 | loss: 0.58669 - acc: 0.6507 -- iter: 0544/1140
[A[ATraining Step: 630  | total loss: [1m[32m0.58376[0m[0m | time: 16.428s
[2K
| Adam | epoch: 018 | loss: 0.58376 - acc: 0.6506 -- iter: 0576/1140
[A[ATraining Step: 631  | total loss: [1m[32m0.57904[0m[0m | time: 17.254s
[2K
| Adam | epoch: 018 | loss: 0.57904 - acc: 0.6449 -- iter: 0608/1140
[A[ATraining Step: 632  | total loss: [1m[32m0.56774[0m[0m | time: 18.238s
[2K
| Adam | epoch: 018 | loss: 0.56774 - acc: 0.6554 -- iter: 0640/1140
[A[ATraining Step: 633  | total loss: [1m[32m0.57095[0m[0m | time: 19.125s
[2K
| Adam | epoch: 018 | loss: 0.57095 - acc: 0.6618 -- iter: 0672/1140
[A[ATraining Step: 634  | total loss: [1m[32m0.56214[0m[0m | time: 19.987s
[2K
| Adam | epoch: 018 | loss: 0.56214 - acc: 0.6768 -- iter: 0704/1140
[A[ATraining Step: 635  | total loss: [1m[32m0.55298[0m[0m | time: 20.881s
[2K
| Adam | epoch: 018 | loss: 0.55298 - acc: 0.6873 -- iter: 0736/1140
[A[ATraining Step: 636  | total loss: [1m[32m0.54873[0m[0m | time: 21.870s
[2K
| Adam | epoch: 018 | loss: 0.54873 - acc: 0.6842 -- iter: 0768/1140
[A[ATraining Step: 637  | total loss: [1m[32m0.55063[0m[0m | time: 22.776s
[2K
| Adam | epoch: 018 | loss: 0.55063 - acc: 0.6845 -- iter: 0800/1140
[A[ATraining Step: 638  | total loss: [1m[32m0.55621[0m[0m | time: 23.759s
[2K
| Adam | epoch: 018 | loss: 0.55621 - acc: 0.6848 -- iter: 0832/1140
[A[ATraining Step: 639  | total loss: [1m[32m0.55915[0m[0m | time: 24.602s
[2K
| Adam | epoch: 018 | loss: 0.55915 - acc: 0.6882 -- iter: 0864/1140
[A[ATraining Step: 640  | total loss: [1m[32m0.55807[0m[0m | time: 25.594s
[2K
| Adam | epoch: 018 | loss: 0.55807 - acc: 0.6975 -- iter: 0896/1140
[A[ATraining Step: 641  | total loss: [1m[32m0.55680[0m[0m | time: 26.556s
[2K
| Adam | epoch: 018 | loss: 0.55680 - acc: 0.7028 -- iter: 0928/1140
[A[ATraining Step: 642  | total loss: [1m[32m0.55372[0m[0m | time: 27.576s
[2K
| Adam | epoch: 018 | loss: 0.55372 - acc: 0.7075 -- iter: 0960/1140
[A[ATraining Step: 643  | total loss: [1m[32m0.55309[0m[0m | time: 28.361s
[2K
| Adam | epoch: 018 | loss: 0.55309 - acc: 0.7149 -- iter: 0992/1140
[A[ATraining Step: 644  | total loss: [1m[32m0.55032[0m[0m | time: 29.249s
[2K
| Adam | epoch: 018 | loss: 0.55032 - acc: 0.7152 -- iter: 1024/1140
[A[ATraining Step: 645  | total loss: [1m[32m0.54557[0m[0m | time: 30.097s
[2K
| Adam | epoch: 018 | loss: 0.54557 - acc: 0.7187 -- iter: 1056/1140
[A[ATraining Step: 646  | total loss: [1m[32m0.54010[0m[0m | time: 30.991s
[2K
| Adam | epoch: 018 | loss: 0.54010 - acc: 0.7281 -- iter: 1088/1140
[A[ATraining Step: 647  | total loss: [1m[32m0.52793[0m[0m | time: 31.943s
[2K
| Adam | epoch: 018 | loss: 0.52793 - acc: 0.7365 -- iter: 1120/1140
[A[ATraining Step: 648  | total loss: [1m[32m0.53286[0m[0m | time: 34.952s
[2K
| Adam | epoch: 018 | loss: 0.53286 - acc: 0.7316 | val_loss: 0.70186 - val_acc: 0.6471 -- iter: 1140/1140
--
Training Step: 649  | total loss: [1m[32m0.54281[0m[0m | time: 0.810s
[2K
| Adam | epoch: 019 | loss: 0.54281 - acc: 0.7335 -- iter: 0032/1140
[A[ATraining Step: 650  | total loss: [1m[32m0.55769[0m[0m | time: 1.754s
[2K
| Adam | epoch: 019 | loss: 0.55769 - acc: 0.7289 -- iter: 0064/1140
[A[ATraining Step: 651  | total loss: [1m[32m0.56068[0m[0m | time: 2.652s
[2K
| Adam | epoch: 019 | loss: 0.56068 - acc: 0.7247 -- iter: 0096/1140
[A[ATraining Step: 652  | total loss: [1m[32m0.58365[0m[0m | time: 3.549s
[2K
| Adam | epoch: 019 | loss: 0.58365 - acc: 0.7023 -- iter: 0128/1140
[A[ATraining Step: 653  | total loss: [1m[32m0.59427[0m[0m | time: 4.501s
[2K
| Adam | epoch: 019 | loss: 0.59427 - acc: 0.7008 -- iter: 0160/1140
[A[ATraining Step: 654  | total loss: [1m[32m0.58881[0m[0m | time: 5.425s
[2K
| Adam | epoch: 019 | loss: 0.58881 - acc: 0.6995 -- iter: 0192/1140
[A[ATraining Step: 655  | total loss: [1m[32m0.58804[0m[0m | time: 6.414s
[2K
| Adam | epoch: 019 | loss: 0.58804 - acc: 0.7014 -- iter: 0224/1140
[A[ATraining Step: 656  | total loss: [1m[32m0.58622[0m[0m | time: 7.343s
[2K
| Adam | epoch: 019 | loss: 0.58622 - acc: 0.7062 -- iter: 0256/1140
[A[ATraining Step: 657  | total loss: [1m[32m0.57306[0m[0m | time: 8.343s
[2K
| Adam | epoch: 019 | loss: 0.57306 - acc: 0.7169 -- iter: 0288/1140
[A[ATraining Step: 658  | total loss: [1m[32m0.57900[0m[0m | time: 9.223s
[2K
| Adam | epoch: 019 | loss: 0.57900 - acc: 0.7046 -- iter: 0320/1140
[A[ATraining Step: 659  | total loss: [1m[32m0.57439[0m[0m | time: 10.315s
[2K
| Adam | epoch: 019 | loss: 0.57439 - acc: 0.6997 -- iter: 0352/1140
[A[ATraining Step: 660  | total loss: [1m[32m0.56370[0m[0m | time: 11.252s
[2K
| Adam | epoch: 019 | loss: 0.56370 - acc: 0.7141 -- iter: 0384/1140
[A[ATraining Step: 661  | total loss: [1m[32m0.56103[0m[0m | time: 11.998s
[2K
| Adam | epoch: 019 | loss: 0.56103 - acc: 0.7115 -- iter: 0416/1140
[A[ATraining Step: 662  | total loss: [1m[32m0.56559[0m[0m | time: 12.952s
[2K
| Adam | epoch: 019 | loss: 0.56559 - acc: 0.7091 -- iter: 0448/1140
[A[ATraining Step: 663  | total loss: [1m[32m0.56407[0m[0m | time: 13.953s
[2K
| Adam | epoch: 019 | loss: 0.56407 - acc: 0.7163 -- iter: 0480/1140
[A[ATraining Step: 664  | total loss: [1m[32m0.55565[0m[0m | time: 14.919s
[2K
| Adam | epoch: 019 | loss: 0.55565 - acc: 0.7290 -- iter: 0512/1140
[A[ATraining Step: 665  | total loss: [1m[32m0.54685[0m[0m | time: 15.497s
[2K
| Adam | epoch: 019 | loss: 0.54685 - acc: 0.7343 -- iter: 0544/1140
[A[ATraining Step: 666  | total loss: [1m[32m0.55783[0m[0m | time: 16.060s
[2K
| Adam | epoch: 019 | loss: 0.55783 - acc: 0.7108 -- iter: 0576/1140
[A[ATraining Step: 667  | total loss: [1m[32m0.56745[0m[0m | time: 16.987s
[2K
| Adam | epoch: 019 | loss: 0.56745 - acc: 0.6997 -- iter: 0608/1140
[A[ATraining Step: 668  | total loss: [1m[32m0.56808[0m[0m | time: 17.947s
[2K
| Adam | epoch: 019 | loss: 0.56808 - acc: 0.6954 -- iter: 0640/1140
[A[ATraining Step: 669  | total loss: [1m[32m0.56789[0m[0m | time: 18.912s
[2K
| Adam | epoch: 019 | loss: 0.56789 - acc: 0.7009 -- iter: 0672/1140
[A[ATraining Step: 670  | total loss: [1m[32m0.56329[0m[0m | time: 19.777s
[2K
| Adam | epoch: 019 | loss: 0.56329 - acc: 0.7026 -- iter: 0704/1140
[A[ATraining Step: 671  | total loss: [1m[32m0.56179[0m[0m | time: 20.843s
[2K
| Adam | epoch: 019 | loss: 0.56179 - acc: 0.6980 -- iter: 0736/1140
[A[ATraining Step: 672  | total loss: [1m[32m0.56111[0m[0m | time: 21.870s
[2K
| Adam | epoch: 019 | loss: 0.56111 - acc: 0.7032 -- iter: 0768/1140
[A[ATraining Step: 673  | total loss: [1m[32m0.56328[0m[0m | time: 22.619s
[2K
| Adam | epoch: 019 | loss: 0.56328 - acc: 0.7048 -- iter: 0800/1140
[A[ATraining Step: 674  | total loss: [1m[32m0.56830[0m[0m | time: 23.571s
[2K
| Adam | epoch: 019 | loss: 0.56830 - acc: 0.6937 -- iter: 0832/1140
[A[ATraining Step: 675  | total loss: [1m[32m0.57944[0m[0m | time: 24.649s
[2K
| Adam | epoch: 019 | loss: 0.57944 - acc: 0.6712 -- iter: 0864/1140
[A[ATraining Step: 676  | total loss: [1m[32m0.57900[0m[0m | time: 25.544s
[2K
| Adam | epoch: 019 | loss: 0.57900 - acc: 0.6759 -- iter: 0896/1140
[A[ATraining Step: 677  | total loss: [1m[32m0.57025[0m[0m | time: 26.548s
[2K
| Adam | epoch: 019 | loss: 0.57025 - acc: 0.6865 -- iter: 0928/1140
[A[ATraining Step: 678  | total loss: [1m[32m0.57055[0m[0m | time: 27.544s
[2K
| Adam | epoch: 019 | loss: 0.57055 - acc: 0.6866 -- iter: 0960/1140
[A[ATraining Step: 679  | total loss: [1m[32m0.56822[0m[0m | time: 28.558s
[2K
| Adam | epoch: 019 | loss: 0.56822 - acc: 0.6898 -- iter: 0992/1140
[A[ATraining Step: 680  | total loss: [1m[32m0.55675[0m[0m | time: 29.464s
[2K
| Adam | epoch: 019 | loss: 0.55675 - acc: 0.6958 -- iter: 1024/1140
[A[ATraining Step: 681  | total loss: [1m[32m0.55004[0m[0m | time: 30.373s
[2K
| Adam | epoch: 019 | loss: 0.55004 - acc: 0.6950 -- iter: 1056/1140
[A[ATraining Step: 682  | total loss: [1m[32m0.53047[0m[0m | time: 31.558s
[2K
| Adam | epoch: 019 | loss: 0.53047 - acc: 0.7161 -- iter: 1088/1140
[A[ATraining Step: 683  | total loss: [1m[32m0.53469[0m[0m | time: 32.592s
[2K
| Adam | epoch: 019 | loss: 0.53469 - acc: 0.7070 -- iter: 1120/1140
[A[ATraining Step: 684  | total loss: [1m[32m0.52529[0m[0m | time: 35.224s
[2K
| Adam | epoch: 019 | loss: 0.52529 - acc: 0.7175 | val_loss: 0.69286 - val_acc: 0.6359 -- iter: 1140/1140
--
Training Step: 685  | total loss: [1m[32m0.54150[0m[0m | time: 0.882s
[2K
| Adam | epoch: 020 | loss: 0.54150 - acc: 0.7114 -- iter: 0032/1140
[A[ATraining Step: 686  | total loss: [1m[32m0.52928[0m[0m | time: 1.856s
[2K
| Adam | epoch: 020 | loss: 0.52928 - acc: 0.7184 -- iter: 0064/1140
[A[ATraining Step: 687  | total loss: [1m[32m0.53969[0m[0m | time: 2.734s
[2K
| Adam | epoch: 020 | loss: 0.53969 - acc: 0.7091 -- iter: 0096/1140
[A[ATraining Step: 688  | total loss: [1m[32m0.56467[0m[0m | time: 3.665s
[2K
| Adam | epoch: 020 | loss: 0.56467 - acc: 0.6913 -- iter: 0128/1140
[A[ATraining Step: 689  | total loss: [1m[32m0.56390[0m[0m | time: 4.694s
[2K
| Adam | epoch: 020 | loss: 0.56390 - acc: 0.6878 -- iter: 0160/1140
[A[ATraining Step: 690  | total loss: [1m[32m0.56201[0m[0m | time: 5.730s
[2K
| Adam | epoch: 020 | loss: 0.56201 - acc: 0.6909 -- iter: 0192/1140
[A[ATraining Step: 691  | total loss: [1m[32m0.56295[0m[0m | time: 6.465s
[2K
| Adam | epoch: 020 | loss: 0.56295 - acc: 0.6937 -- iter: 0224/1140
[A[ATraining Step: 692  | total loss: [1m[32m0.56655[0m[0m | time: 7.352s
[2K
| Adam | epoch: 020 | loss: 0.56655 - acc: 0.6868 -- iter: 0256/1140
[A[ATraining Step: 693  | total loss: [1m[32m0.56837[0m[0m | time: 8.290s
[2K
| Adam | epoch: 020 | loss: 0.56837 - acc: 0.6931 -- iter: 0288/1140
[A[ATraining Step: 694  | total loss: [1m[32m0.56956[0m[0m | time: 9.210s
[2K
| Adam | epoch: 020 | loss: 0.56956 - acc: 0.6926 -- iter: 0320/1140
[A[ATraining Step: 695  | total loss: [1m[32m0.56810[0m[0m | time: 10.184s
[2K
| Adam | epoch: 020 | loss: 0.56810 - acc: 0.6983 -- iter: 0352/1140
[A[ATraining Step: 696  | total loss: [1m[32m0.57116[0m[0m | time: 11.138s
[2K
| Adam | epoch: 020 | loss: 0.57116 - acc: 0.7035 -- iter: 0384/1140
[A[ATraining Step: 697  | total loss: [1m[32m0.56088[0m[0m | time: 12.141s
[2K
| Adam | epoch: 020 | loss: 0.56088 - acc: 0.7112 -- iter: 0416/1140
[A[ATraining Step: 698  | total loss: [1m[32m0.55704[0m[0m | time: 13.100s
[2K
| Adam | epoch: 020 | loss: 0.55704 - acc: 0.7182 -- iter: 0448/1140
[A[ATraining Step: 699  | total loss: [1m[32m0.55720[0m[0m | time: 14.025s
[2K
| Adam | epoch: 020 | loss: 0.55720 - acc: 0.7152 -- iter: 0480/1140
[A[ATraining Step: 700  | total loss: [1m[32m0.55471[0m[0m | time: 14.899s
[2K
| Adam | epoch: 020 | loss: 0.55471 - acc: 0.7187 -- iter: 0512/1140
[A[ATraining Step: 701  | total loss: [1m[32m0.55097[0m[0m | time: 15.935s
[2K
| Adam | epoch: 020 | loss: 0.55097 - acc: 0.7124 -- iter: 0544/1140
[A[ATraining Step: 702  | total loss: [1m[32m0.54806[0m[0m | time: 16.576s
[2K
| Adam | epoch: 020 | loss: 0.54806 - acc: 0.7193 -- iter: 0576/1140
[A[ATraining Step: 703  | total loss: [1m[32m0.55152[0m[0m | time: 17.119s
[2K
| Adam | epoch: 020 | loss: 0.55152 - acc: 0.7074 -- iter: 0608/1140
[A[ATraining Step: 704  | total loss: [1m[32m0.55339[0m[0m | time: 17.911s
[2K
| Adam | epoch: 020 | loss: 0.55339 - acc: 0.6966 -- iter: 0640/1140
[A[ATraining Step: 705  | total loss: [1m[32m0.55632[0m[0m | time: 18.871s
[2K
| Adam | epoch: 020 | loss: 0.55632 - acc: 0.6957 -- iter: 0672/1140
[A[ATraining Step: 706  | total loss: [1m[32m0.55042[0m[0m | time: 19.758s
[2K
| Adam | epoch: 020 | loss: 0.55042 - acc: 0.7136 -- iter: 0704/1140
[A[ATraining Step: 707  | total loss: [1m[32m0.55372[0m[0m | time: 20.776s
[2K
| Adam | epoch: 020 | loss: 0.55372 - acc: 0.7079 -- iter: 0736/1140
[A[ATraining Step: 708  | total loss: [1m[32m0.54490[0m[0m | time: 21.793s
[2K
| Adam | epoch: 020 | loss: 0.54490 - acc: 0.7184 -- iter: 0768/1140
[A[ATraining Step: 709  | total loss: [1m[32m0.54362[0m[0m | time: 22.746s
[2K
| Adam | epoch: 020 | loss: 0.54362 - acc: 0.7247 -- iter: 0800/1140
[A[ATraining Step: 710  | total loss: [1m[32m0.53511[0m[0m | time: 23.667s
[2K
| Adam | epoch: 020 | loss: 0.53511 - acc: 0.7366 -- iter: 0832/1140
[A[ATraining Step: 711  | total loss: [1m[32m0.54341[0m[0m | time: 24.523s
[2K
| Adam | epoch: 020 | loss: 0.54341 - acc: 0.7285 -- iter: 0864/1140
[A[ATraining Step: 712  | total loss: [1m[32m0.54276[0m[0m | time: 25.453s
[2K
| Adam | epoch: 020 | loss: 0.54276 - acc: 0.7307 -- iter: 0896/1140
[A[ATraining Step: 713  | total loss: [1m[32m0.52501[0m[0m | time: 26.595s
[2K
| Adam | epoch: 020 | loss: 0.52501 - acc: 0.7420 -- iter: 0928/1140
[A[ATraining Step: 714  | total loss: [1m[32m0.52807[0m[0m | time: 27.626s
[2K
| Adam | epoch: 020 | loss: 0.52807 - acc: 0.7272 -- iter: 0960/1140
[A[ATraining Step: 715  | total loss: [1m[32m0.53318[0m[0m | time: 28.399s
[2K
| Adam | epoch: 020 | loss: 0.53318 - acc: 0.7232 -- iter: 0992/1140
[A[ATraining Step: 716  | total loss: [1m[32m0.52655[0m[0m | time: 29.338s
[2K
| Adam | epoch: 020 | loss: 0.52655 - acc: 0.7259 -- iter: 1024/1140
[A[ATraining Step: 717  | total loss: [1m[32m0.52169[0m[0m | time: 30.307s
[2K
| Adam | epoch: 020 | loss: 0.52169 - acc: 0.7314 -- iter: 1056/1140
[A[ATraining Step: 718  | total loss: [1m[32m0.52009[0m[0m | time: 31.191s
[2K
| Adam | epoch: 020 | loss: 0.52009 - acc: 0.7364 -- iter: 1088/1140
[A[ATraining Step: 719  | total loss: [1m[32m0.52907[0m[0m | time: 32.118s
[2K
| Adam | epoch: 020 | loss: 0.52907 - acc: 0.7284 -- iter: 1120/1140
[A[ATraining Step: 720  | total loss: [1m[32m0.54294[0m[0m | time: 35.167s
[2K
| Adam | epoch: 020 | loss: 0.54294 - acc: 0.7118 | val_loss: 0.61736 - val_acc: 0.6527 -- iter: 1140/1140
--
Training Step: 721  | total loss: [1m[32m0.53515[0m[0m | time: 1.079s
[2K
| Adam | epoch: 021 | loss: 0.53515 - acc: 0.7156 -- iter: 0032/1140
[A[ATraining Step: 722  | total loss: [1m[32m0.54228[0m[0m | time: 1.845s
[2K
| Adam | epoch: 021 | loss: 0.54228 - acc: 0.7159 -- iter: 0064/1140
[A[ATraining Step: 723  | total loss: [1m[32m0.53683[0m[0m | time: 2.743s
[2K
| Adam | epoch: 021 | loss: 0.53683 - acc: 0.7162 -- iter: 0096/1140
[A[ATraining Step: 724  | total loss: [1m[32m0.52968[0m[0m | time: 3.724s
[2K
| Adam | epoch: 021 | loss: 0.52968 - acc: 0.7196 -- iter: 0128/1140
[A[ATraining Step: 725  | total loss: [1m[32m0.52515[0m[0m | time: 4.629s
[2K
| Adam | epoch: 021 | loss: 0.52515 - acc: 0.7258 -- iter: 0160/1140
[A[ATraining Step: 726  | total loss: [1m[32m0.53155[0m[0m | time: 5.502s
[2K
| Adam | epoch: 021 | loss: 0.53155 - acc: 0.7219 -- iter: 0192/1140
[A[ATraining Step: 727  | total loss: [1m[32m0.54019[0m[0m | time: 6.389s
[2K
| Adam | epoch: 021 | loss: 0.54019 - acc: 0.7091 -- iter: 0224/1140
[A[ATraining Step: 728  | total loss: [1m[32m0.54163[0m[0m | time: 7.283s
[2K
| Adam | epoch: 021 | loss: 0.54163 - acc: 0.7101 -- iter: 0256/1140
[A[ATraining Step: 729  | total loss: [1m[32m0.53128[0m[0m | time: 8.199s
[2K
| Adam | epoch: 021 | loss: 0.53128 - acc: 0.7203 -- iter: 0288/1140
[A[ATraining Step: 730  | total loss: [1m[32m0.53803[0m[0m | time: 9.096s
[2K
| Adam | epoch: 021 | loss: 0.53803 - acc: 0.7170 -- iter: 0320/1140
[A[ATraining Step: 731  | total loss: [1m[32m0.52142[0m[0m | time: 10.108s
[2K
| Adam | epoch: 021 | loss: 0.52142 - acc: 0.7297 -- iter: 0352/1140
[A[ATraining Step: 732  | total loss: [1m[32m0.50474[0m[0m | time: 11.139s
[2K
| Adam | epoch: 021 | loss: 0.50474 - acc: 0.7474 -- iter: 0384/1140
[A[ATraining Step: 733  | total loss: [1m[32m0.52411[0m[0m | time: 12.050s
[2K
| Adam | epoch: 021 | loss: 0.52411 - acc: 0.7414 -- iter: 0416/1140
[A[ATraining Step: 734  | total loss: [1m[32m0.52642[0m[0m | time: 12.879s
[2K
| Adam | epoch: 021 | loss: 0.52642 - acc: 0.7422 -- iter: 0448/1140
[A[ATraining Step: 735  | total loss: [1m[32m0.52253[0m[0m | time: 13.818s
[2K
| Adam | epoch: 021 | loss: 0.52253 - acc: 0.7430 -- iter: 0480/1140
[A[ATraining Step: 736  | total loss: [1m[32m0.51296[0m[0m | time: 14.762s
[2K
| Adam | epoch: 021 | loss: 0.51296 - acc: 0.7500 -- iter: 0512/1140
[A[ATraining Step: 737  | total loss: [1m[32m0.51190[0m[0m | time: 15.781s
[2K
| Adam | epoch: 021 | loss: 0.51190 - acc: 0.7562 -- iter: 0544/1140
[A[ATraining Step: 738  | total loss: [1m[32m0.52800[0m[0m | time: 16.738s
[2K
| Adam | epoch: 021 | loss: 0.52800 - acc: 0.7368 -- iter: 0576/1140
[A[ATraining Step: 739  | total loss: [1m[32m0.52804[0m[0m | time: 17.313s
[2K
| Adam | epoch: 021 | loss: 0.52804 - acc: 0.7413 -- iter: 0608/1140
[A[ATraining Step: 740  | total loss: [1m[32m0.52879[0m[0m | time: 17.917s
[2K
| Adam | epoch: 021 | loss: 0.52879 - acc: 0.7522 -- iter: 0640/1140
[A[ATraining Step: 741  | total loss: [1m[32m0.52858[0m[0m | time: 18.857s
[2K
| Adam | epoch: 021 | loss: 0.52858 - acc: 0.7519 -- iter: 0672/1140
[A[ATraining Step: 742  | total loss: [1m[32m0.53174[0m[0m | time: 19.824s
[2K
| Adam | epoch: 021 | loss: 0.53174 - acc: 0.7455 -- iter: 0704/1140
[A[ATraining Step: 743  | total loss: [1m[32m0.52717[0m[0m | time: 20.837s
[2K
| Adam | epoch: 021 | loss: 0.52717 - acc: 0.7522 -- iter: 0736/1140
[A[ATraining Step: 744  | total loss: [1m[32m0.54253[0m[0m | time: 21.960s
[2K
| Adam | epoch: 021 | loss: 0.54253 - acc: 0.7395 -- iter: 0768/1140
[A[ATraining Step: 745  | total loss: [1m[32m0.54827[0m[0m | time: 22.922s
[2K
| Adam | epoch: 021 | loss: 0.54827 - acc: 0.7437 -- iter: 0800/1140
[A[ATraining Step: 746  | total loss: [1m[32m0.53910[0m[0m | time: 23.698s
[2K
| Adam | epoch: 021 | loss: 0.53910 - acc: 0.7505 -- iter: 0832/1140
[A[ATraining Step: 747  | total loss: [1m[32m0.53590[0m[0m | time: 24.592s
[2K
| Adam | epoch: 021 | loss: 0.53590 - acc: 0.7411 -- iter: 0864/1140
[A[ATraining Step: 748  | total loss: [1m[32m0.52575[0m[0m | time: 25.540s
[2K
| Adam | epoch: 021 | loss: 0.52575 - acc: 0.7545 -- iter: 0896/1140
[A[ATraining Step: 749  | total loss: [1m[32m0.51804[0m[0m | time: 26.403s
[2K
| Adam | epoch: 021 | loss: 0.51804 - acc: 0.7572 -- iter: 0928/1140
[A[ATraining Step: 750  | total loss: [1m[32m0.51269[0m[0m | time: 27.372s
[2K
| Adam | epoch: 021 | loss: 0.51269 - acc: 0.7502 -- iter: 0960/1140
[A[ATraining Step: 751  | total loss: [1m[32m0.50658[0m[0m | time: 28.361s
[2K
| Adam | epoch: 021 | loss: 0.50658 - acc: 0.7564 -- iter: 0992/1140
[A[ATraining Step: 752  | total loss: [1m[32m0.50878[0m[0m | time: 29.366s
[2K
| Adam | epoch: 021 | loss: 0.50878 - acc: 0.7652 -- iter: 1024/1140
[A[ATraining Step: 753  | total loss: [1m[32m0.51689[0m[0m | time: 30.340s
[2K
| Adam | epoch: 021 | loss: 0.51689 - acc: 0.7512 -- iter: 1056/1140
[A[ATraining Step: 754  | total loss: [1m[32m0.51482[0m[0m | time: 31.226s
[2K
| Adam | epoch: 021 | loss: 0.51482 - acc: 0.7542 -- iter: 1088/1140
[A[ATraining Step: 755  | total loss: [1m[32m0.51550[0m[0m | time: 32.274s
[2K
| Adam | epoch: 021 | loss: 0.51550 - acc: 0.7537 -- iter: 1120/1140
[A[ATraining Step: 756  | total loss: [1m[32m0.52041[0m[0m | time: 35.209s
[2K
| Adam | epoch: 021 | loss: 0.52041 - acc: 0.7502 | val_loss: 0.61642 - val_acc: 0.6611 -- iter: 1140/1140
--
Training Step: 757  | total loss: [1m[32m0.51798[0m[0m | time: 0.890s
[2K
| Adam | epoch: 022 | loss: 0.51798 - acc: 0.7533 -- iter: 0032/1140
[A[ATraining Step: 758  | total loss: [1m[32m0.51345[0m[0m | time: 1.926s
[2K
| Adam | epoch: 022 | loss: 0.51345 - acc: 0.7624 -- iter: 0064/1140
[A[ATraining Step: 759  | total loss: [1m[32m0.52394[0m[0m | time: 2.978s
[2K
| Adam | epoch: 022 | loss: 0.52394 - acc: 0.7424 -- iter: 0096/1140
[A[ATraining Step: 760  | total loss: [1m[32m0.54029[0m[0m | time: 3.845s
[2K
| Adam | epoch: 022 | loss: 0.54029 - acc: 0.7275 -- iter: 0128/1140
[A[ATraining Step: 761  | total loss: [1m[32m0.53699[0m[0m | time: 4.592s
[2K
| Adam | epoch: 022 | loss: 0.53699 - acc: 0.7267 -- iter: 0160/1140
[A[ATraining Step: 762  | total loss: [1m[32m0.52438[0m[0m | time: 5.427s
[2K
| Adam | epoch: 022 | loss: 0.52438 - acc: 0.7384 -- iter: 0192/1140
[A[ATraining Step: 763  | total loss: [1m[32m0.53660[0m[0m | time: 6.448s
[2K
| Adam | epoch: 022 | loss: 0.53660 - acc: 0.7333 -- iter: 0224/1140
[A[ATraining Step: 764  | total loss: [1m[32m0.53668[0m[0m | time: 7.339s
[2K
| Adam | epoch: 022 | loss: 0.53668 - acc: 0.7318 -- iter: 0256/1140
[A[ATraining Step: 765  | total loss: [1m[32m0.53043[0m[0m | time: 8.296s
[2K
| Adam | epoch: 022 | loss: 0.53043 - acc: 0.7399 -- iter: 0288/1140
[A[ATraining Step: 766  | total loss: [1m[32m0.51663[0m[0m | time: 9.270s
[2K
| Adam | epoch: 022 | loss: 0.51663 - acc: 0.7440 -- iter: 0320/1140
[A[ATraining Step: 767  | total loss: [1m[32m0.52388[0m[0m | time: 10.287s
[2K
| Adam | epoch: 022 | loss: 0.52388 - acc: 0.7384 -- iter: 0352/1140
[A[ATraining Step: 768  | total loss: [1m[32m0.52364[0m[0m | time: 11.176s
[2K
| Adam | epoch: 022 | loss: 0.52364 - acc: 0.7395 -- iter: 0384/1140
[A[ATraining Step: 769  | total loss: [1m[32m0.51647[0m[0m | time: 12.072s
[2K
| Adam | epoch: 022 | loss: 0.51647 - acc: 0.7531 -- iter: 0416/1140
[A[ATraining Step: 770  | total loss: [1m[32m0.50746[0m[0m | time: 13.201s
[2K
| Adam | epoch: 022 | loss: 0.50746 - acc: 0.7590 -- iter: 0448/1140
[A[ATraining Step: 771  | total loss: [1m[32m0.51846[0m[0m | time: 14.269s
[2K
| Adam | epoch: 022 | loss: 0.51846 - acc: 0.7487 -- iter: 0480/1140
[A[ATraining Step: 772  | total loss: [1m[32m0.52086[0m[0m | time: 15.098s
[2K
| Adam | epoch: 022 | loss: 0.52086 - acc: 0.7489 -- iter: 0512/1140
[A[ATraining Step: 773  | total loss: [1m[32m0.51438[0m[0m | time: 16.072s
[2K
| Adam | epoch: 022 | loss: 0.51438 - acc: 0.7521 -- iter: 0544/1140
[A[ATraining Step: 774  | total loss: [1m[32m0.50855[0m[0m | time: 16.958s
[2K
| Adam | epoch: 022 | loss: 0.50855 - acc: 0.7581 -- iter: 0576/1140
[A[ATraining Step: 775  | total loss: [1m[32m0.51369[0m[0m | time: 17.891s
[2K
| Adam | epoch: 022 | loss: 0.51369 - acc: 0.7573 -- iter: 0608/1140
[A[ATraining Step: 776  | total loss: [1m[32m0.50838[0m[0m | time: 18.481s
[2K
| Adam | epoch: 022 | loss: 0.50838 - acc: 0.7597 -- iter: 0640/1140
[A[ATraining Step: 777  | total loss: [1m[32m0.50638[0m[0m | time: 19.105s
[2K
| Adam | epoch: 022 | loss: 0.50638 - acc: 0.7588 -- iter: 0672/1140
[A[ATraining Step: 778  | total loss: [1m[32m0.50527[0m[0m | time: 20.082s
[2K
| Adam | epoch: 022 | loss: 0.50527 - acc: 0.7579 -- iter: 0704/1140
[A[ATraining Step: 779  | total loss: [1m[32m0.49201[0m[0m | time: 21.049s
[2K
| Adam | epoch: 022 | loss: 0.49201 - acc: 0.7696 -- iter: 0736/1140
[A[ATraining Step: 780  | total loss: [1m[32m0.48626[0m[0m | time: 21.933s
[2K
| Adam | epoch: 022 | loss: 0.48626 - acc: 0.7739 -- iter: 0768/1140
[A[ATraining Step: 781  | total loss: [1m[32m0.49248[0m[0m | time: 22.878s
[2K
| Adam | epoch: 022 | loss: 0.49248 - acc: 0.7684 -- iter: 0800/1140
[A[ATraining Step: 782  | total loss: [1m[32m0.49920[0m[0m | time: 23.937s
[2K
| Adam | epoch: 022 | loss: 0.49920 - acc: 0.7509 -- iter: 0832/1140
[A[ATraining Step: 783  | total loss: [1m[32m0.50813[0m[0m | time: 25.068s
[2K
| Adam | epoch: 022 | loss: 0.50813 - acc: 0.7383 -- iter: 0864/1140
[A[ATraining Step: 784  | total loss: [1m[32m0.50668[0m[0m | time: 25.974s
[2K
| Adam | epoch: 022 | loss: 0.50668 - acc: 0.7332 -- iter: 0896/1140
[A[ATraining Step: 785  | total loss: [1m[32m0.51776[0m[0m | time: 26.767s
[2K
| Adam | epoch: 022 | loss: 0.51776 - acc: 0.7255 -- iter: 0928/1140
[A[ATraining Step: 786  | total loss: [1m[32m0.50979[0m[0m | time: 27.702s
[2K
| Adam | epoch: 022 | loss: 0.50979 - acc: 0.7374 -- iter: 0960/1140
[A[ATraining Step: 787  | total loss: [1m[32m0.51037[0m[0m | time: 28.650s
[2K
| Adam | epoch: 022 | loss: 0.51037 - acc: 0.7386 -- iter: 0992/1140
[A[ATraining Step: 788  | total loss: [1m[32m0.51292[0m[0m | time: 29.583s
[2K
| Adam | epoch: 022 | loss: 0.51292 - acc: 0.7366 -- iter: 1024/1140
[A[ATraining Step: 789  | total loss: [1m[32m0.54317[0m[0m | time: 30.566s
[2K
| Adam | epoch: 022 | loss: 0.54317 - acc: 0.7192 -- iter: 1056/1140
[A[ATraining Step: 790  | total loss: [1m[32m0.54141[0m[0m | time: 31.528s
[2K
| Adam | epoch: 022 | loss: 0.54141 - acc: 0.7254 -- iter: 1088/1140
[A[ATraining Step: 791  | total loss: [1m[32m0.53691[0m[0m | time: 32.493s
[2K
| Adam | epoch: 022 | loss: 0.53691 - acc: 0.7310 -- iter: 1120/1140
[A[ATraining Step: 792  | total loss: [1m[32m0.52144[0m[0m | time: 35.408s
[2K
| Adam | epoch: 022 | loss: 0.52144 - acc: 0.7454 | val_loss: 0.61805 - val_acc: 0.6331 -- iter: 1140/1140
--
Training Step: 793  | total loss: [1m[32m0.52604[0m[0m | time: 0.998s
[2K
| Adam | epoch: 023 | loss: 0.52604 - acc: 0.7396 -- iter: 0032/1140
[A[ATraining Step: 794  | total loss: [1m[32m0.52730[0m[0m | time: 1.929s
[2K
| Adam | epoch: 023 | loss: 0.52730 - acc: 0.7407 -- iter: 0064/1140
[A[ATraining Step: 795  | total loss: [1m[32m0.51410[0m[0m | time: 2.919s
[2K
| Adam | epoch: 023 | loss: 0.51410 - acc: 0.7510 -- iter: 0096/1140
[A[ATraining Step: 796  | total loss: [1m[32m0.52475[0m[0m | time: 3.976s
[2K
| Adam | epoch: 023 | loss: 0.52475 - acc: 0.7352 -- iter: 0128/1140
[A[ATraining Step: 797  | total loss: [1m[32m0.51897[0m[0m | time: 4.889s
[2K
| Adam | epoch: 023 | loss: 0.51897 - acc: 0.7430 -- iter: 0160/1140
[A[ATraining Step: 798  | total loss: [1m[32m0.51921[0m[0m | time: 5.910s
[2K
| Adam | epoch: 023 | loss: 0.51921 - acc: 0.7405 -- iter: 0192/1140
[A[ATraining Step: 799  | total loss: [1m[32m0.51736[0m[0m | time: 7.087s
[2K
| Adam | epoch: 023 | loss: 0.51736 - acc: 0.7446 -- iter: 0224/1140
[A[ATraining Step: 800  | total loss: [1m[32m0.51679[0m[0m | time: 9.773s
[2K
| Adam | epoch: 023 | loss: 0.51679 - acc: 0.7514 | val_loss: 0.63435 - val_acc: 0.6779 -- iter: 0256/1140
--
Training Step: 801  | total loss: [1m[32m0.52238[0m[0m | time: 10.732s
[2K
| Adam | epoch: 023 | loss: 0.52238 - acc: 0.7481 -- iter: 0288/1140
[A[ATraining Step: 802  | total loss: [1m[32m0.51241[0m[0m | time: 11.626s
[2K
| Adam | epoch: 023 | loss: 0.51241 - acc: 0.7515 -- iter: 0320/1140
[A[ATraining Step: 803  | total loss: [1m[32m0.50565[0m[0m | time: 12.812s
[2K
| Adam | epoch: 023 | loss: 0.50565 - acc: 0.7513 -- iter: 0352/1140
[A[ATraining Step: 804  | total loss: [1m[32m0.50364[0m[0m | time: 13.834s
[2K
| Adam | epoch: 023 | loss: 0.50364 - acc: 0.7512 -- iter: 0384/1140
[A[ATraining Step: 805  | total loss: [1m[32m0.49772[0m[0m | time: 14.630s
[2K
| Adam | epoch: 023 | loss: 0.49772 - acc: 0.7573 -- iter: 0416/1140
[A[ATraining Step: 806  | total loss: [1m[32m0.49198[0m[0m | time: 15.524s
[2K
| Adam | epoch: 023 | loss: 0.49198 - acc: 0.7597 -- iter: 0448/1140
[A[ATraining Step: 807  | total loss: [1m[32m0.50009[0m[0m | time: 16.478s
[2K
| Adam | epoch: 023 | loss: 0.50009 - acc: 0.7525 -- iter: 0480/1140
[A[ATraining Step: 808  | total loss: [1m[32m0.49561[0m[0m | time: 17.461s
[2K
| Adam | epoch: 023 | loss: 0.49561 - acc: 0.7554 -- iter: 0512/1140
[A[ATraining Step: 809  | total loss: [1m[32m0.48634[0m[0m | time: 18.360s
[2K
| Adam | epoch: 023 | loss: 0.48634 - acc: 0.7673 -- iter: 0544/1140
[A[ATraining Step: 810  | total loss: [1m[32m0.47512[0m[0m | time: 19.332s
[2K
| Adam | epoch: 023 | loss: 0.47512 - acc: 0.7781 -- iter: 0576/1140
[A[ATraining Step: 811  | total loss: [1m[32m0.48329[0m[0m | time: 20.235s
[2K
| Adam | epoch: 023 | loss: 0.48329 - acc: 0.7690 -- iter: 0608/1140
[A[ATraining Step: 812  | total loss: [1m[32m0.48087[0m[0m | time: 21.242s
[2K
| Adam | epoch: 023 | loss: 0.48087 - acc: 0.7796 -- iter: 0640/1140
[A[ATraining Step: 813  | total loss: [1m[32m0.47120[0m[0m | time: 21.807s
[2K
| Adam | epoch: 023 | loss: 0.47120 - acc: 0.7923 -- iter: 0672/1140
[A[ATraining Step: 814  | total loss: [1m[32m0.46422[0m[0m | time: 22.329s
[2K
| Adam | epoch: 023 | loss: 0.46422 - acc: 0.8031 -- iter: 0704/1140
[A[ATraining Step: 815  | total loss: [1m[32m0.45659[0m[0m | time: 23.508s
[2K
| Adam | epoch: 023 | loss: 0.45659 - acc: 0.8128 -- iter: 0736/1140
[A[ATraining Step: 816  | total loss: [1m[32m0.46328[0m[0m | time: 24.598s
[2K
| Adam | epoch: 023 | loss: 0.46328 - acc: 0.8127 -- iter: 0768/1140
[A[ATraining Step: 817  | total loss: [1m[32m0.47866[0m[0m | time: 25.433s
[2K
| Adam | epoch: 023 | loss: 0.47866 - acc: 0.7971 -- iter: 0800/1140
[A[ATraining Step: 818  | total loss: [1m[32m0.46290[0m[0m | time: 26.279s
[2K
| Adam | epoch: 023 | loss: 0.46290 - acc: 0.8049 -- iter: 0832/1140
[A[ATraining Step: 819  | total loss: [1m[32m0.45374[0m[0m | time: 27.216s
[2K
| Adam | epoch: 023 | loss: 0.45374 - acc: 0.8119 -- iter: 0864/1140
[A[ATraining Step: 820  | total loss: [1m[32m0.44183[0m[0m | time: 28.205s
[2K
| Adam | epoch: 023 | loss: 0.44183 - acc: 0.8213 -- iter: 0896/1140
[A[ATraining Step: 821  | total loss: [1m[32m0.45396[0m[0m | time: 29.214s
[2K
| Adam | epoch: 023 | loss: 0.45396 - acc: 0.8111 -- iter: 0928/1140
[A[ATraining Step: 822  | total loss: [1m[32m0.46206[0m[0m | time: 30.199s
[2K
| Adam | epoch: 023 | loss: 0.46206 - acc: 0.8112 -- iter: 0960/1140
[A[ATraining Step: 823  | total loss: [1m[32m0.47048[0m[0m | time: 31.176s
[2K
| Adam | epoch: 023 | loss: 0.47048 - acc: 0.7957 -- iter: 0992/1140
[A[ATraining Step: 824  | total loss: [1m[32m0.47550[0m[0m | time: 32.124s
[2K
| Adam | epoch: 023 | loss: 0.47550 - acc: 0.7880 -- iter: 1024/1140
[A[ATraining Step: 825  | total loss: [1m[32m0.47178[0m[0m | time: 33.049s
[2K
| Adam | epoch: 023 | loss: 0.47178 - acc: 0.7936 -- iter: 1056/1140
[A[ATraining Step: 826  | total loss: [1m[32m0.47252[0m[0m | time: 34.282s
[2K
| Adam | epoch: 023 | loss: 0.47252 - acc: 0.7924 -- iter: 1088/1140
[A[ATraining Step: 827  | total loss: [1m[32m0.47284[0m[0m | time: 35.399s
[2K
| Adam | epoch: 023 | loss: 0.47284 - acc: 0.7912 -- iter: 1120/1140
[A[ATraining Step: 828  | total loss: [1m[32m0.47838[0m[0m | time: 38.052s
[2K
| Adam | epoch: 023 | loss: 0.47838 - acc: 0.7777 | val_loss: 0.61078 - val_acc: 0.7031 -- iter: 1140/1140
--
Training Step: 829  | total loss: [1m[32m0.46949[0m[0m | time: 0.979s
[2K
| Adam | epoch: 024 | loss: 0.46949 - acc: 0.7875 -- iter: 0032/1140
[A[ATraining Step: 830  | total loss: [1m[32m0.47436[0m[0m | time: 2.106s
[2K
| Adam | epoch: 024 | loss: 0.47436 - acc: 0.7837 -- iter: 0064/1140
[A[ATraining Step: 831  | total loss: [1m[32m0.46797[0m[0m | time: 3.070s
[2K
| Adam | epoch: 024 | loss: 0.46797 - acc: 0.7866 -- iter: 0096/1140
[A[ATraining Step: 832  | total loss: [1m[32m0.47112[0m[0m | time: 3.832s
[2K
| Adam | epoch: 024 | loss: 0.47112 - acc: 0.7861 -- iter: 0128/1140
[A[ATraining Step: 833  | total loss: [1m[32m0.46555[0m[0m | time: 4.768s
[2K
| Adam | epoch: 024 | loss: 0.46555 - acc: 0.7856 -- iter: 0160/1140
[A[ATraining Step: 834  | total loss: [1m[32m0.46119[0m[0m | time: 5.782s
[2K
| Adam | epoch: 024 | loss: 0.46119 - acc: 0.7883 -- iter: 0192/1140
[A[ATraining Step: 835  | total loss: [1m[32m0.46559[0m[0m | time: 6.729s
[2K
| Adam | epoch: 024 | loss: 0.46559 - acc: 0.7813 -- iter: 0224/1140
[A[ATraining Step: 836  | total loss: [1m[32m0.46763[0m[0m | time: 7.703s
[2K
| Adam | epoch: 024 | loss: 0.46763 - acc: 0.7813 -- iter: 0256/1140
[A[ATraining Step: 837  | total loss: [1m[32m0.46257[0m[0m | time: 8.598s
[2K
| Adam | epoch: 024 | loss: 0.46257 - acc: 0.7876 -- iter: 0288/1140
[A[ATraining Step: 838  | total loss: [1m[32m0.46333[0m[0m | time: 9.573s
[2K
| Adam | epoch: 024 | loss: 0.46333 - acc: 0.7932 -- iter: 0320/1140
[A[ATraining Step: 839  | total loss: [1m[32m0.45561[0m[0m | time: 10.493s
[2K
| Adam | epoch: 024 | loss: 0.45561 - acc: 0.8014 -- iter: 0352/1140
[A[ATraining Step: 840  | total loss: [1m[32m0.47059[0m[0m | time: 11.401s
[2K
| Adam | epoch: 024 | loss: 0.47059 - acc: 0.7868 -- iter: 0384/1140
[A[ATraining Step: 841  | total loss: [1m[32m0.48898[0m[0m | time: 12.543s
[2K
| Adam | epoch: 024 | loss: 0.48898 - acc: 0.7675 -- iter: 0416/1140
[A[ATraining Step: 842  | total loss: [1m[32m0.48453[0m[0m | time: 13.526s
[2K
| Adam | epoch: 024 | loss: 0.48453 - acc: 0.7658 -- iter: 0448/1140
[A[ATraining Step: 843  | total loss: [1m[32m0.49890[0m[0m | time: 14.298s
[2K
| Adam | epoch: 024 | loss: 0.49890 - acc: 0.7517 -- iter: 0480/1140
[A[ATraining Step: 844  | total loss: [1m[32m0.48669[0m[0m | time: 15.193s
[2K
| Adam | epoch: 024 | loss: 0.48669 - acc: 0.7640 -- iter: 0512/1140
[A[ATraining Step: 845  | total loss: [1m[32m0.48859[0m[0m | time: 16.149s
[2K
| Adam | epoch: 024 | loss: 0.48859 - acc: 0.7595 -- iter: 0544/1140
[A[ATraining Step: 846  | total loss: [1m[32m0.47797[0m[0m | time: 17.052s
[2K
| Adam | epoch: 024 | loss: 0.47797 - acc: 0.7554 -- iter: 0576/1140
[A[ATraining Step: 847  | total loss: [1m[32m0.49733[0m[0m | time: 17.991s
[2K
| Adam | epoch: 024 | loss: 0.49733 - acc: 0.7455 -- iter: 0608/1140
[A[ATraining Step: 848  | total loss: [1m[32m0.48842[0m[0m | time: 18.915s
[2K
| Adam | epoch: 024 | loss: 0.48842 - acc: 0.7585 -- iter: 0640/1140
[A[ATraining Step: 849  | total loss: [1m[32m0.47721[0m[0m | time: 19.922s
[2K
| Adam | epoch: 024 | loss: 0.47721 - acc: 0.7576 -- iter: 0672/1140
[A[ATraining Step: 850  | total loss: [1m[32m0.47904[0m[0m | time: 20.536s
[2K
| Adam | epoch: 024 | loss: 0.47904 - acc: 0.7662 -- iter: 0704/1140
[A[ATraining Step: 851  | total loss: [1m[32m0.48821[0m[0m | time: 21.100s
[2K
| Adam | epoch: 024 | loss: 0.48821 - acc: 0.7546 -- iter: 0736/1140
[A[ATraining Step: 852  | total loss: [1m[32m0.49312[0m[0m | time: 22.096s
[2K
| Adam | epoch: 024 | loss: 0.49312 - acc: 0.7541 -- iter: 0768/1140
[A[ATraining Step: 853  | total loss: [1m[32m0.48744[0m[0m | time: 23.212s
[2K
| Adam | epoch: 024 | loss: 0.48744 - acc: 0.7600 -- iter: 0800/1140
[A[ATraining Step: 854  | total loss: [1m[32m0.48721[0m[0m | time: 24.127s
[2K
| Adam | epoch: 024 | loss: 0.48721 - acc: 0.7652 -- iter: 0832/1140
[A[ATraining Step: 855  | total loss: [1m[32m0.48626[0m[0m | time: 24.897s
[2K
| Adam | epoch: 024 | loss: 0.48626 - acc: 0.7637 -- iter: 0864/1140
[A[ATraining Step: 856  | total loss: [1m[32m0.49554[0m[0m | time: 25.813s
[2K
| Adam | epoch: 024 | loss: 0.49554 - acc: 0.7561 -- iter: 0896/1140
[A[ATraining Step: 857  | total loss: [1m[32m0.49793[0m[0m | time: 26.726s
[2K
| Adam | epoch: 024 | loss: 0.49793 - acc: 0.7524 -- iter: 0928/1140
[A[ATraining Step: 858  | total loss: [1m[32m0.48770[0m[0m | time: 27.665s
[2K
| Adam | epoch: 024 | loss: 0.48770 - acc: 0.7615 -- iter: 0960/1140
[A[ATraining Step: 859  | total loss: [1m[32m0.48401[0m[0m | time: 28.591s
[2K
| Adam | epoch: 024 | loss: 0.48401 - acc: 0.7666 -- iter: 0992/1140
[A[ATraining Step: 860  | total loss: [1m[32m0.48851[0m[0m | time: 29.582s
[2K
| Adam | epoch: 024 | loss: 0.48851 - acc: 0.7618 -- iter: 1024/1140
[A[ATraining Step: 861  | total loss: [1m[32m0.48124[0m[0m | time: 30.569s
[2K
| Adam | epoch: 024 | loss: 0.48124 - acc: 0.7638 -- iter: 1056/1140
[A[ATraining Step: 862  | total loss: [1m[32m0.48346[0m[0m | time: 31.580s
[2K
| Adam | epoch: 024 | loss: 0.48346 - acc: 0.7624 -- iter: 1088/1140
[A[ATraining Step: 863  | total loss: [1m[32m0.48656[0m[0m | time: 32.556s
[2K
| Adam | epoch: 024 | loss: 0.48656 - acc: 0.7611 -- iter: 1120/1140
[A[ATraining Step: 864  | total loss: [1m[32m0.48129[0m[0m | time: 35.317s
[2K
| Adam | epoch: 024 | loss: 0.48129 - acc: 0.7663 | val_loss: 0.62429 - val_acc: 0.6583 -- iter: 1140/1140
--
Training Step: 865  | total loss: [1m[32m0.47075[0m[0m | time: 0.919s
[2K
| Adam | epoch: 025 | loss: 0.47075 - acc: 0.7709 -- iter: 0032/1140
[A[ATraining Step: 866  | total loss: [1m[32m0.47433[0m[0m | time: 1.889s
[2K
| Adam | epoch: 025 | loss: 0.47433 - acc: 0.7688 -- iter: 0064/1140
[A[ATraining Step: 867  | total loss: [1m[32m0.46191[0m[0m | time: 2.930s
[2K
| Adam | epoch: 025 | loss: 0.46191 - acc: 0.7794 -- iter: 0096/1140
[A[ATraining Step: 868  | total loss: [1m[32m0.45642[0m[0m | time: 3.785s
[2K
| Adam | epoch: 025 | loss: 0.45642 - acc: 0.7827 -- iter: 0128/1140
[A[ATraining Step: 869  | total loss: [1m[32m0.45806[0m[0m | time: 4.897s
[2K
| Adam | epoch: 025 | loss: 0.45806 - acc: 0.7888 -- iter: 0160/1140
[A[ATraining Step: 870  | total loss: [1m[32m0.44598[0m[0m | time: 5.962s
[2K
| Adam | epoch: 025 | loss: 0.44598 - acc: 0.8006 -- iter: 0192/1140
[A[ATraining Step: 871  | total loss: [1m[32m0.44675[0m[0m | time: 6.736s
[2K
| Adam | epoch: 025 | loss: 0.44675 - acc: 0.8049 -- iter: 0224/1140
[A[ATraining Step: 872  | total loss: [1m[32m0.44312[0m[0m | time: 7.549s
[2K
| Adam | epoch: 025 | loss: 0.44312 - acc: 0.8057 -- iter: 0256/1140
[A[ATraining Step: 873  | total loss: [1m[32m0.45163[0m[0m | time: 8.484s
[2K
| Adam | epoch: 025 | loss: 0.45163 - acc: 0.8095 -- iter: 0288/1140
[A[ATraining Step: 874  | total loss: [1m[32m0.44270[0m[0m | time: 9.381s
[2K
| Adam | epoch: 025 | loss: 0.44270 - acc: 0.8191 -- iter: 0320/1140
[A[ATraining Step: 875  | total loss: [1m[32m0.43242[0m[0m | time: 10.251s
[2K
| Adam | epoch: 025 | loss: 0.43242 - acc: 0.8310 -- iter: 0352/1140
[A[ATraining Step: 876  | total loss: [1m[32m0.43234[0m[0m | time: 11.124s
[2K
| Adam | epoch: 025 | loss: 0.43234 - acc: 0.8323 -- iter: 0384/1140
[A[ATraining Step: 877  | total loss: [1m[32m0.44168[0m[0m | time: 12.098s
[2K
| Adam | epoch: 025 | loss: 0.44168 - acc: 0.8303 -- iter: 0416/1140
[A[ATraining Step: 878  | total loss: [1m[32m0.43391[0m[0m | time: 13.210s
[2K
| Adam | epoch: 025 | loss: 0.43391 - acc: 0.8285 -- iter: 0448/1140
[A[ATraining Step: 879  | total loss: [1m[32m0.44582[0m[0m | time: 14.038s
[2K
| Adam | epoch: 025 | loss: 0.44582 - acc: 0.8207 -- iter: 0480/1140
[A[ATraining Step: 880  | total loss: [1m[32m0.43526[0m[0m | time: 14.932s
[2K
| Adam | epoch: 025 | loss: 0.43526 - acc: 0.8230 -- iter: 0512/1140
[A[ATraining Step: 881  | total loss: [1m[32m0.43084[0m[0m | time: 15.985s
[2K
| Adam | epoch: 025 | loss: 0.43084 - acc: 0.8282 -- iter: 0544/1140
[A[ATraining Step: 882  | total loss: [1m[32m0.43924[0m[0m | time: 17.031s
[2K
| Adam | epoch: 025 | loss: 0.43924 - acc: 0.8235 -- iter: 0576/1140
[A[ATraining Step: 883  | total loss: [1m[32m0.45081[0m[0m | time: 17.800s
[2K
| Adam | epoch: 025 | loss: 0.45081 - acc: 0.8130 -- iter: 0608/1140
[A[ATraining Step: 884  | total loss: [1m[32m0.44465[0m[0m | time: 18.673s
[2K
| Adam | epoch: 025 | loss: 0.44465 - acc: 0.8130 -- iter: 0640/1140
[A[ATraining Step: 885  | total loss: [1m[32m0.45608[0m[0m | time: 19.590s
[2K
| Adam | epoch: 025 | loss: 0.45608 - acc: 0.7910 -- iter: 0672/1140
[A[ATraining Step: 886  | total loss: [1m[32m0.44111[0m[0m | time: 20.453s
[2K
| Adam | epoch: 025 | loss: 0.44111 - acc: 0.8026 -- iter: 0704/1140
[A[ATraining Step: 887  | total loss: [1m[32m0.44958[0m[0m | time: 21.068s
[2K
| Adam | epoch: 025 | loss: 0.44958 - acc: 0.7942 -- iter: 0736/1140
[A[ATraining Step: 888  | total loss: [1m[32m0.45391[0m[0m | time: 21.680s
[2K
| Adam | epoch: 025 | loss: 0.45391 - acc: 0.7948 -- iter: 0768/1140
[A[ATraining Step: 889  | total loss: [1m[32m0.45153[0m[0m | time: 22.591s
[2K
| Adam | epoch: 025 | loss: 0.45153 - acc: 0.8003 -- iter: 0800/1140
[A[ATraining Step: 890  | total loss: [1m[32m0.45334[0m[0m | time: 23.611s
[2K
| Adam | epoch: 025 | loss: 0.45334 - acc: 0.7890 -- iter: 0832/1140
[A[ATraining Step: 891  | total loss: [1m[32m0.45033[0m[0m | time: 24.574s
[2K
| Adam | epoch: 025 | loss: 0.45033 - acc: 0.7851 -- iter: 0864/1140
[A[ATraining Step: 892  | total loss: [1m[32m0.46469[0m[0m | time: 25.504s
[2K
| Adam | epoch: 025 | loss: 0.46469 - acc: 0.7691 -- iter: 0896/1140
[A[ATraining Step: 893  | total loss: [1m[32m0.47552[0m[0m | time: 26.537s
[2K
| Adam | epoch: 025 | loss: 0.47552 - acc: 0.7547 -- iter: 0928/1140
[A[ATraining Step: 894  | total loss: [1m[32m0.47404[0m[0m | time: 27.648s
[2K
| Adam | epoch: 025 | loss: 0.47404 - acc: 0.7573 -- iter: 0960/1140
[A[ATraining Step: 895  | total loss: [1m[32m0.44946[0m[0m | time: 28.469s
[2K
| Adam | epoch: 025 | loss: 0.44946 - acc: 0.7785 -- iter: 0992/1140
[A[ATraining Step: 896  | total loss: [1m[32m0.43310[0m[0m | time: 29.383s
[2K
| Adam | epoch: 025 | loss: 0.43310 - acc: 0.7881 -- iter: 1024/1140
[A[ATraining Step: 897  | total loss: [1m[32m0.43887[0m[0m | time: 30.272s
[2K
| Adam | epoch: 025 | loss: 0.43887 - acc: 0.7874 -- iter: 1056/1140
[A[ATraining Step: 898  | total loss: [1m[32m0.43996[0m[0m | time: 31.235s
[2K
| Adam | epoch: 025 | loss: 0.43996 - acc: 0.7774 -- iter: 1088/1140
[A[ATraining Step: 899  | total loss: [1m[32m0.43482[0m[0m | time: 32.135s
[2K
| Adam | epoch: 025 | loss: 0.43482 - acc: 0.7778 -- iter: 1120/1140
[A[ATraining Step: 900  | total loss: [1m[32m0.43421[0m[0m | time: 35.100s
[2K
| Adam | epoch: 025 | loss: 0.43421 - acc: 0.7907 | val_loss: 0.60453 - val_acc: 0.7031 -- iter: 1140/1140
--
Training Step: 901  | total loss: [1m[32m0.43144[0m[0m | time: 0.870s
[2K
| Adam | epoch: 026 | loss: 0.43144 - acc: 0.7960 -- iter: 0032/1140
[A[ATraining Step: 902  | total loss: [1m[32m0.41547[0m[0m | time: 1.861s
[2K
| Adam | epoch: 026 | loss: 0.41547 - acc: 0.8101 -- iter: 0064/1140
[A[ATraining Step: 903  | total loss: [1m[32m0.40930[0m[0m | time: 2.840s
[2K
| Adam | epoch: 026 | loss: 0.40930 - acc: 0.8197 -- iter: 0096/1140
[A[ATraining Step: 904  | total loss: [1m[32m0.40769[0m[0m | time: 3.782s
[2K
| Adam | epoch: 026 | loss: 0.40769 - acc: 0.8190 -- iter: 0128/1140
[A[ATraining Step: 905  | total loss: [1m[32m0.40255[0m[0m | time: 4.759s
[2K
| Adam | epoch: 026 | loss: 0.40255 - acc: 0.8246 -- iter: 0160/1140
[A[ATraining Step: 906  | total loss: [1m[32m0.41296[0m[0m | time: 5.697s
[2K
| Adam | epoch: 026 | loss: 0.41296 - acc: 0.8172 -- iter: 0192/1140
[A[ATraining Step: 907  | total loss: [1m[32m0.42492[0m[0m | time: 6.652s
[2K
| Adam | epoch: 026 | loss: 0.42492 - acc: 0.8073 -- iter: 0224/1140
[A[ATraining Step: 908  | total loss: [1m[32m0.41914[0m[0m | time: 7.544s
[2K
| Adam | epoch: 026 | loss: 0.41914 - acc: 0.8172 -- iter: 0256/1140
[A[ATraining Step: 909  | total loss: [1m[32m0.42826[0m[0m | time: 8.681s
[2K
| Adam | epoch: 026 | loss: 0.42826 - acc: 0.8074 -- iter: 0288/1140
[A[ATraining Step: 910  | total loss: [1m[32m0.41409[0m[0m | time: 9.722s
[2K
| Adam | epoch: 026 | loss: 0.41409 - acc: 0.8141 -- iter: 0320/1140
[A[ATraining Step: 911  | total loss: [1m[32m0.39990[0m[0m | time: 10.490s
[2K
| Adam | epoch: 026 | loss: 0.39990 - acc: 0.8296 -- iter: 0352/1140
[A[ATraining Step: 912  | total loss: [1m[32m0.39857[0m[0m | time: 11.428s
[2K
| Adam | epoch: 026 | loss: 0.39857 - acc: 0.8310 -- iter: 0384/1140
[A[ATraining Step: 913  | total loss: [1m[32m0.41295[0m[0m | time: 12.372s
[2K
| Adam | epoch: 026 | loss: 0.41295 - acc: 0.8229 -- iter: 0416/1140
[A[ATraining Step: 914  | total loss: [1m[32m0.41109[0m[0m | time: 13.369s
[2K
| Adam | epoch: 026 | loss: 0.41109 - acc: 0.8281 -- iter: 0448/1140
[A[ATraining Step: 915  | total loss: [1m[32m0.41860[0m[0m | time: 14.271s
[2K
| Adam | epoch: 026 | loss: 0.41860 - acc: 0.8203 -- iter: 0480/1140
[A[ATraining Step: 916  | total loss: [1m[32m0.42209[0m[0m | time: 15.217s
[2K
| Adam | epoch: 026 | loss: 0.42209 - acc: 0.8164 -- iter: 0512/1140
[A[ATraining Step: 917  | total loss: [1m[32m0.43288[0m[0m | time: 16.199s
[2K
| Adam | epoch: 026 | loss: 0.43288 - acc: 0.8098 -- iter: 0544/1140
[A[ATraining Step: 918  | total loss: [1m[32m0.44640[0m[0m | time: 17.142s
[2K
| Adam | epoch: 026 | loss: 0.44640 - acc: 0.7975 -- iter: 0576/1140
[A[ATraining Step: 919  | total loss: [1m[32m0.45208[0m[0m | time: 18.022s
[2K
| Adam | epoch: 026 | loss: 0.45208 - acc: 0.7865 -- iter: 0608/1140
[A[ATraining Step: 920  | total loss: [1m[32m0.45656[0m[0m | time: 19.078s
[2K
| Adam | epoch: 026 | loss: 0.45656 - acc: 0.7798 -- iter: 0640/1140
[A[ATraining Step: 921  | total loss: [1m[32m0.47256[0m[0m | time: 20.092s
[2K
| Adam | epoch: 026 | loss: 0.47256 - acc: 0.7674 -- iter: 0672/1140
[A[ATraining Step: 922  | total loss: [1m[32m0.46982[0m[0m | time: 20.908s
[2K
| Adam | epoch: 026 | loss: 0.46982 - acc: 0.7688 -- iter: 0704/1140
[A[ATraining Step: 923  | total loss: [1m[32m0.46820[0m[0m | time: 21.734s
[2K
| Adam | epoch: 026 | loss: 0.46820 - acc: 0.7794 -- iter: 0736/1140
[A[ATraining Step: 924  | total loss: [1m[32m0.46100[0m[0m | time: 22.377s
[2K
| Adam | epoch: 026 | loss: 0.46100 - acc: 0.7827 -- iter: 0768/1140
[A[ATraining Step: 925  | total loss: [1m[32m0.46864[0m[0m | time: 22.961s
[2K
| Adam | epoch: 026 | loss: 0.46864 - acc: 0.7644 -- iter: 0800/1140
[A[ATraining Step: 926  | total loss: [1m[32m0.47321[0m[0m | time: 23.852s
[2K
| Adam | epoch: 026 | loss: 0.47321 - acc: 0.7530 -- iter: 0832/1140
[A[ATraining Step: 927  | total loss: [1m[32m0.45315[0m[0m | time: 24.688s
[2K
| Adam | epoch: 026 | loss: 0.45315 - acc: 0.7652 -- iter: 0864/1140
[A[ATraining Step: 928  | total loss: [1m[32m0.45754[0m[0m | time: 25.632s
[2K
| Adam | epoch: 026 | loss: 0.45754 - acc: 0.7699 -- iter: 0896/1140
[A[ATraining Step: 929  | total loss: [1m[32m0.46111[0m[0m | time: 26.621s
[2K
| Adam | epoch: 026 | loss: 0.46111 - acc: 0.7711 -- iter: 0928/1140
[A[ATraining Step: 930  | total loss: [1m[32m0.46258[0m[0m | time: 27.710s
[2K
| Adam | epoch: 026 | loss: 0.46258 - acc: 0.7783 -- iter: 0960/1140
[A[ATraining Step: 931  | total loss: [1m[32m0.47253[0m[0m | time: 28.836s
[2K
| Adam | epoch: 026 | loss: 0.47253 - acc: 0.7724 -- iter: 0992/1140
[A[ATraining Step: 932  | total loss: [1m[32m0.45495[0m[0m | time: 29.973s
[2K
| Adam | epoch: 026 | loss: 0.45495 - acc: 0.7858 -- iter: 1024/1140
[A[ATraining Step: 933  | total loss: [1m[32m0.47777[0m[0m | time: 31.284s
[2K
| Adam | epoch: 026 | loss: 0.47777 - acc: 0.7666 -- iter: 1056/1140
[A[ATraining Step: 934  | total loss: [1m[32m0.47327[0m[0m | time: 32.476s
[2K
| Adam | epoch: 026 | loss: 0.47327 - acc: 0.7743 -- iter: 1088/1140
[A[ATraining Step: 935  | total loss: [1m[32m0.47373[0m[0m | time: 33.459s
[2K
| Adam | epoch: 026 | loss: 0.47373 - acc: 0.7719 -- iter: 1120/1140
[A[ATraining Step: 936  | total loss: [1m[32m0.46211[0m[0m | time: 37.053s
[2K
| Adam | epoch: 026 | loss: 0.46211 - acc: 0.7822 | val_loss: 0.62608 - val_acc: 0.7031 -- iter: 1140/1140
--
Training Step: 937  | total loss: [1m[32m0.44675[0m[0m | time: 1.156s
[2K
| Adam | epoch: 027 | loss: 0.44675 - acc: 0.7977 -- iter: 0032/1140
[A[ATraining Step: 938  | total loss: [1m[32m0.43457[0m[0m | time: 2.265s
[2K
| Adam | epoch: 027 | loss: 0.43457 - acc: 0.8054 -- iter: 0064/1140
[A[ATraining Step: 939  | total loss: [1m[32m0.42852[0m[0m | time: 3.373s
[2K
| Adam | epoch: 027 | loss: 0.42852 - acc: 0.8124 -- iter: 0096/1140
[A[ATraining Step: 940  | total loss: [1m[32m0.42426[0m[0m | time: 4.385s
[2K
| Adam | epoch: 027 | loss: 0.42426 - acc: 0.8186 -- iter: 0128/1140
[A[ATraining Step: 941  | total loss: [1m[32m0.42881[0m[0m | time: 5.598s
[2K
| Adam | epoch: 027 | loss: 0.42881 - acc: 0.8149 -- iter: 0160/1140
[A[ATraining Step: 942  | total loss: [1m[32m0.43877[0m[0m | time: 6.769s
[2K
| Adam | epoch: 027 | loss: 0.43877 - acc: 0.8115 -- iter: 0192/1140
[A[ATraining Step: 943  | total loss: [1m[32m0.43595[0m[0m | time: 7.742s
[2K
| Adam | epoch: 027 | loss: 0.43595 - acc: 0.8179 -- iter: 0224/1140
[A[ATraining Step: 944  | total loss: [1m[32m0.44725[0m[0m | time: 8.792s
[2K
| Adam | epoch: 027 | loss: 0.44725 - acc: 0.8080 -- iter: 0256/1140
[A[ATraining Step: 945  | total loss: [1m[32m0.45329[0m[0m | time: 9.928s
[2K
| Adam | epoch: 027 | loss: 0.45329 - acc: 0.8053 -- iter: 0288/1140
[A[ATraining Step: 946  | total loss: [1m[32m0.44166[0m[0m | time: 11.042s
[2K
| Adam | epoch: 027 | loss: 0.44166 - acc: 0.8091 -- iter: 0320/1140
[A[ATraining Step: 947  | total loss: [1m[32m0.44820[0m[0m | time: 12.188s
[2K
| Adam | epoch: 027 | loss: 0.44820 - acc: 0.7970 -- iter: 0352/1140
[A[ATraining Step: 948  | total loss: [1m[32m0.43505[0m[0m | time: 13.371s
[2K
| Adam | epoch: 027 | loss: 0.43505 - acc: 0.8079 -- iter: 0384/1140
[A[ATraining Step: 949  | total loss: [1m[32m0.43916[0m[0m | time: 14.454s
[2K
| Adam | epoch: 027 | loss: 0.43916 - acc: 0.8084 -- iter: 0416/1140
[A[ATraining Step: 950  | total loss: [1m[32m0.41811[0m[0m | time: 15.743s
[2K
| Adam | epoch: 027 | loss: 0.41811 - acc: 0.8213 -- iter: 0448/1140
[A[ATraining Step: 951  | total loss: [1m[32m0.42662[0m[0m | time: 16.833s
[2K
| Adam | epoch: 027 | loss: 0.42662 - acc: 0.8204 -- iter: 0480/1140
[A[ATraining Step: 952  | total loss: [1m[32m0.42630[0m[0m | time: 17.872s
[2K
| Adam | epoch: 027 | loss: 0.42630 - acc: 0.8227 -- iter: 0512/1140
[A[ATraining Step: 953  | total loss: [1m[32m0.41541[0m[0m | time: 19.272s
[2K
| Adam | epoch: 027 | loss: 0.41541 - acc: 0.8311 -- iter: 0544/1140
[A[ATraining Step: 954  | total loss: [1m[32m0.40939[0m[0m | time: 20.513s
[2K
| Adam | epoch: 027 | loss: 0.40939 - acc: 0.8355 -- iter: 0576/1140
[A[ATraining Step: 955  | total loss: [1m[32m0.41084[0m[0m | time: 21.501s
[2K
| Adam | epoch: 027 | loss: 0.41084 - acc: 0.8332 -- iter: 0608/1140
[A[ATraining Step: 956  | total loss: [1m[32m0.40062[0m[0m | time: 22.314s
[2K
| Adam | epoch: 027 | loss: 0.40062 - acc: 0.8405 -- iter: 0640/1140
[A[ATraining Step: 957  | total loss: [1m[32m0.40374[0m[0m | time: 23.383s
[2K
| Adam | epoch: 027 | loss: 0.40374 - acc: 0.8408 -- iter: 0672/1140
[A[ATraining Step: 958  | total loss: [1m[32m0.40220[0m[0m | time: 24.518s
[2K
| Adam | epoch: 027 | loss: 0.40220 - acc: 0.8380 -- iter: 0704/1140
[A[ATraining Step: 959  | total loss: [1m[32m0.40291[0m[0m | time: 25.654s
[2K
| Adam | epoch: 027 | loss: 0.40291 - acc: 0.8386 -- iter: 0736/1140
[A[ATraining Step: 960  | total loss: [1m[32m0.39390[0m[0m | time: 26.893s
[2K
| Adam | epoch: 027 | loss: 0.39390 - acc: 0.8391 -- iter: 0768/1140
[A[ATraining Step: 961  | total loss: [1m[32m0.40201[0m[0m | time: 27.636s
[2K
| Adam | epoch: 027 | loss: 0.40201 - acc: 0.8302 -- iter: 0800/1140
[A[ATraining Step: 962  | total loss: [1m[32m0.40054[0m[0m | time: 28.378s
[2K
| Adam | epoch: 027 | loss: 0.40054 - acc: 0.8272 -- iter: 0832/1140
[A[ATraining Step: 963  | total loss: [1m[32m0.39780[0m[0m | time: 29.557s
[2K
| Adam | epoch: 027 | loss: 0.39780 - acc: 0.8294 -- iter: 0864/1140
[A[ATraining Step: 964  | total loss: [1m[32m0.40189[0m[0m | time: 30.654s
[2K
| Adam | epoch: 027 | loss: 0.40189 - acc: 0.8309 -- iter: 0896/1140
[A[ATraining Step: 965  | total loss: [1m[32m0.40168[0m[0m | time: 31.660s
[2K
| Adam | epoch: 027 | loss: 0.40168 - acc: 0.8353 -- iter: 0928/1140
[A[ATraining Step: 966  | total loss: [1m[32m0.40522[0m[0m | time: 32.911s
[2K
| Adam | epoch: 027 | loss: 0.40522 - acc: 0.8361 -- iter: 0960/1140
[A[ATraining Step: 967  | total loss: [1m[32m0.42475[0m[0m | time: 34.184s
[2K
| Adam | epoch: 027 | loss: 0.42475 - acc: 0.8275 -- iter: 0992/1140
[A[ATraining Step: 968  | total loss: [1m[32m0.41823[0m[0m | time: 35.315s
[2K
| Adam | epoch: 027 | loss: 0.41823 - acc: 0.8260 -- iter: 1024/1140
[A[ATraining Step: 969  | total loss: [1m[32m0.40302[0m[0m | time: 36.230s
[2K
| Adam | epoch: 027 | loss: 0.40302 - acc: 0.8372 -- iter: 1056/1140
[A[ATraining Step: 970  | total loss: [1m[32m0.39523[0m[0m | time: 37.438s
[2K
| Adam | epoch: 027 | loss: 0.39523 - acc: 0.8409 -- iter: 1088/1140
[A[ATraining Step: 971  | total loss: [1m[32m0.39526[0m[0m | time: 38.405s
[2K
| Adam | epoch: 027 | loss: 0.39526 - acc: 0.8381 -- iter: 1120/1140
[A[ATraining Step: 972  | total loss: [1m[32m0.39338[0m[0m | time: 41.809s
[2K
| Adam | epoch: 027 | loss: 0.39338 - acc: 0.8355 | val_loss: 0.60771 - val_acc: 0.7255 -- iter: 1140/1140
--
Training Step: 973  | total loss: [1m[32m0.38719[0m[0m | time: 1.115s
[2K
| Adam | epoch: 028 | loss: 0.38719 - acc: 0.8426 -- iter: 0032/1140
[A[ATraining Step: 974  | total loss: [1m[32m0.37860[0m[0m | time: 2.398s
[2K
| Adam | epoch: 028 | loss: 0.37860 - acc: 0.8459 -- iter: 0064/1140
[A[ATraining Step: 975  | total loss: [1m[32m0.36770[0m[0m | time: 3.655s
[2K
| Adam | epoch: 028 | loss: 0.36770 - acc: 0.8613 -- iter: 0096/1140
[A[ATraining Step: 976  | total loss: [1m[32m0.36193[0m[0m | time: 4.805s
[2K
| Adam | epoch: 028 | loss: 0.36193 - acc: 0.8689 -- iter: 0128/1140
[A[ATraining Step: 977  | total loss: [1m[32m0.35931[0m[0m | time: 5.876s
[2K
| Adam | epoch: 028 | loss: 0.35931 - acc: 0.8695 -- iter: 0160/1140
[A[ATraining Step: 978  | total loss: [1m[32m0.35633[0m[0m | time: 7.016s
[2K
| Adam | epoch: 028 | loss: 0.35633 - acc: 0.8638 -- iter: 0192/1140
[A[ATraining Step: 979  | total loss: [1m[32m0.36611[0m[0m | time: 8.224s
[2K
| Adam | epoch: 028 | loss: 0.36611 - acc: 0.8555 -- iter: 0224/1140
[A[ATraining Step: 980  | total loss: [1m[32m0.36038[0m[0m | time: 9.450s
[2K
| Adam | epoch: 028 | loss: 0.36038 - acc: 0.8606 -- iter: 0256/1140
[A[ATraining Step: 981  | total loss: [1m[32m0.35677[0m[0m | time: 10.539s
[2K
| Adam | epoch: 028 | loss: 0.35677 - acc: 0.8589 -- iter: 0288/1140
[A[ATraining Step: 982  | total loss: [1m[32m0.36382[0m[0m | time: 11.519s
[2K
| Adam | epoch: 028 | loss: 0.36382 - acc: 0.8574 -- iter: 0320/1140
[A[ATraining Step: 983  | total loss: [1m[32m0.36295[0m[0m | time: 12.635s
[2K
| Adam | epoch: 028 | loss: 0.36295 - acc: 0.8560 -- iter: 0352/1140
[A[ATraining Step: 984  | total loss: [1m[32m0.36686[0m[0m | time: 13.691s
[2K
| Adam | epoch: 028 | loss: 0.36686 - acc: 0.8548 -- iter: 0384/1140
[A[ATraining Step: 985  | total loss: [1m[32m0.37445[0m[0m | time: 14.828s
[2K
| Adam | epoch: 028 | loss: 0.37445 - acc: 0.8568 -- iter: 0416/1140
[A[ATraining Step: 986  | total loss: [1m[32m0.38144[0m[0m | time: 16.115s
[2K
| Adam | epoch: 028 | loss: 0.38144 - acc: 0.8524 -- iter: 0448/1140
[A[ATraining Step: 987  | total loss: [1m[32m0.36597[0m[0m | time: 17.368s
[2K
| Adam | epoch: 028 | loss: 0.36597 - acc: 0.8640 -- iter: 0480/1140
[A[ATraining Step: 988  | total loss: [1m[32m0.36416[0m[0m | time: 18.447s
[2K
| Adam | epoch: 028 | loss: 0.36416 - acc: 0.8651 -- iter: 0512/1140
[A[ATraining Step: 989  | total loss: [1m[32m0.36203[0m[0m | time: 19.599s
[2K
| Adam | epoch: 028 | loss: 0.36203 - acc: 0.8630 -- iter: 0544/1140
[A[ATraining Step: 990  | total loss: [1m[32m0.34886[0m[0m | time: 20.731s
[2K
| Adam | epoch: 028 | loss: 0.34886 - acc: 0.8673 -- iter: 0576/1140
[A[ATraining Step: 991  | total loss: [1m[32m0.35534[0m[0m | time: 21.883s
[2K
| Adam | epoch: 028 | loss: 0.35534 - acc: 0.8618 -- iter: 0608/1140
[A[ATraining Step: 992  | total loss: [1m[32m0.34093[0m[0m | time: 23.058s
[2K
| Adam | epoch: 028 | loss: 0.34093 - acc: 0.8725 -- iter: 0640/1140
[A[ATraining Step: 993  | total loss: [1m[32m0.34505[0m[0m | time: 24.181s
[2K
| Adam | epoch: 028 | loss: 0.34505 - acc: 0.8728 -- iter: 0672/1140
[A[ATraining Step: 994  | total loss: [1m[32m0.35278[0m[0m | time: 25.351s
[2K
| Adam | epoch: 028 | loss: 0.35278 - acc: 0.8730 -- iter: 0704/1140
[A[ATraining Step: 995  | total loss: [1m[32m0.34226[0m[0m | time: 26.619s
[2K
| Adam | epoch: 028 | loss: 0.34226 - acc: 0.8794 -- iter: 0736/1140
[A[ATraining Step: 996  | total loss: [1m[32m0.35336[0m[0m | time: 27.650s
[2K
| Adam | epoch: 028 | loss: 0.35336 - acc: 0.8728 -- iter: 0768/1140
[A[ATraining Step: 997  | total loss: [1m[32m0.35162[0m[0m | time: 28.658s
[2K
| Adam | epoch: 028 | loss: 0.35162 - acc: 0.8699 -- iter: 0800/1140
[A[ATraining Step: 998  | total loss: [1m[32m0.37067[0m[0m | time: 29.560s
[2K
| Adam | epoch: 028 | loss: 0.37067 - acc: 0.8485 -- iter: 0832/1140
[A[ATraining Step: 999  | total loss: [1m[32m0.35026[0m[0m | time: 30.477s
[2K
| Adam | epoch: 028 | loss: 0.35026 - acc: 0.8636 -- iter: 0864/1140
[A[ATraining Step: 1000  | total loss: [1m[32m0.33065[0m[0m | time: 33.873s
[2K
| Adam | epoch: 028 | loss: 0.33065 - acc: 0.8773 | val_loss: 0.64041 - val_acc: 0.7115 -- iter: 0896/1140
--
Training Step: 1001  | total loss: [1m[32m0.33468[0m[0m | time: 35.073s
[2K
| Adam | epoch: 028 | loss: 0.33468 - acc: 0.8771 -- iter: 0928/1140
[A[ATraining Step: 1002  | total loss: [1m[32m0.35352[0m[0m | time: 36.234s
[2K
| Adam | epoch: 028 | loss: 0.35352 - acc: 0.8675 -- iter: 0960/1140
[A[ATraining Step: 1003  | total loss: [1m[32m0.35905[0m[0m | time: 37.373s
[2K
| Adam | epoch: 028 | loss: 0.35905 - acc: 0.8620 -- iter: 0992/1140
[A[ATraining Step: 1004  | total loss: [1m[32m0.35435[0m[0m | time: 38.472s
[2K
| Adam | epoch: 028 | loss: 0.35435 - acc: 0.8570 -- iter: 1024/1140
[A[ATraining Step: 1005  | total loss: [1m[32m0.35394[0m[0m | time: 39.585s
[2K
| Adam | epoch: 028 | loss: 0.35394 - acc: 0.8588 -- iter: 1056/1140
[A[ATraining Step: 1006  | total loss: [1m[32m0.34292[0m[0m | time: 40.701s
[2K
| Adam | epoch: 028 | loss: 0.34292 - acc: 0.8667 -- iter: 1088/1140
[A[ATraining Step: 1007  | total loss: [1m[32m0.33906[0m[0m | time: 41.924s
[2K
| Adam | epoch: 028 | loss: 0.33906 - acc: 0.8706 -- iter: 1120/1140
[A[ATraining Step: 1008  | total loss: [1m[32m0.33382[0m[0m | time: 45.493s
[2K
| Adam | epoch: 028 | loss: 0.33382 - acc: 0.8773 | val_loss: 0.64621 - val_acc: 0.7059 -- iter: 1140/1140
--
Training Step: 1009  | total loss: [1m[32m0.33055[0m[0m | time: 1.179s
[2K
| Adam | epoch: 029 | loss: 0.33055 - acc: 0.8771 -- iter: 0032/1140
[A[ATraining Step: 1010  | total loss: [1m[32m0.33422[0m[0m | time: 2.270s
[2K
| Adam | epoch: 029 | loss: 0.33422 - acc: 0.8706 -- iter: 0064/1140
[A[ATraining Step: 1011  | total loss: [1m[32m0.33384[0m[0m | time: 3.379s
[2K
| Adam | epoch: 029 | loss: 0.33384 - acc: 0.8680 -- iter: 0096/1140
[A[ATraining Step: 1012  | total loss: [1m[32m0.34238[0m[0m | time: 4.524s
[2K
| Adam | epoch: 029 | loss: 0.34238 - acc: 0.8593 -- iter: 0128/1140
[A[ATraining Step: 1013  | total loss: [1m[32m0.32984[0m[0m | time: 5.644s
[2K
| Adam | epoch: 029 | loss: 0.32984 - acc: 0.8577 -- iter: 0160/1140
[A[ATraining Step: 1014  | total loss: [1m[32m0.32908[0m[0m | time: 6.784s
[2K
| Adam | epoch: 029 | loss: 0.32908 - acc: 0.8563 -- iter: 0192/1140
[A[ATraining Step: 1015  | total loss: [1m[32m0.32773[0m[0m | time: 7.968s
[2K
| Adam | epoch: 029 | loss: 0.32773 - acc: 0.8613 -- iter: 0224/1140
[A[ATraining Step: 1016  | total loss: [1m[32m0.34348[0m[0m | time: 9.497s
[2K
| Adam | epoch: 029 | loss: 0.34348 - acc: 0.8533 -- iter: 0256/1140
[A[ATraining Step: 1017  | total loss: [1m[32m0.36695[0m[0m | time: 10.816s
[2K
| Adam | epoch: 029 | loss: 0.36695 - acc: 0.8367 -- iter: 0288/1140
[A[ATraining Step: 1018  | total loss: [1m[32m0.35327[0m[0m | time: 11.769s
[2K
| Adam | epoch: 029 | loss: 0.35327 - acc: 0.8437 -- iter: 0320/1140
[A[ATraining Step: 1019  | total loss: [1m[32m0.34722[0m[0m | time: 12.921s
[2K
| Adam | epoch: 029 | loss: 0.34722 - acc: 0.8499 -- iter: 0352/1140
[A[ATraining Step: 1020  | total loss: [1m[32m0.35315[0m[0m | time: 13.863s
[2K
| Adam | epoch: 029 | loss: 0.35315 - acc: 0.8462 -- iter: 0384/1140
[A[ATraining Step: 1021  | total loss: [1m[32m0.34456[0m[0m | time: 14.828s
[2K
| Adam | epoch: 029 | loss: 0.34456 - acc: 0.8585 -- iter: 0416/1140
[A[ATraining Step: 1022  | total loss: [1m[32m0.33721[0m[0m | time: 15.806s
[2K
| Adam | epoch: 029 | loss: 0.33721 - acc: 0.8632 -- iter: 0448/1140
[A[ATraining Step: 1023  | total loss: [1m[32m0.33354[0m[0m | time: 16.968s
[2K
| Adam | epoch: 029 | loss: 0.33354 - acc: 0.8644 -- iter: 0480/1140
[A[ATraining Step: 1024  | total loss: [1m[32m0.33319[0m[0m | time: 18.107s
[2K
| Adam | epoch: 029 | loss: 0.33319 - acc: 0.8686 -- iter: 0512/1140
[A[ATraining Step: 1025  | total loss: [1m[32m0.32989[0m[0m | time: 19.175s
[2K
| Adam | epoch: 029 | loss: 0.32989 - acc: 0.8755 -- iter: 0544/1140
[A[ATraining Step: 1026  | total loss: [1m[32m0.32181[0m[0m | time: 20.330s
[2K
| Adam | epoch: 029 | loss: 0.32181 - acc: 0.8754 -- iter: 0576/1140
[A[ATraining Step: 1027  | total loss: [1m[32m0.32572[0m[0m | time: 21.471s
[2K
| Adam | epoch: 029 | loss: 0.32572 - acc: 0.8754 -- iter: 0608/1140
[A[ATraining Step: 1028  | total loss: [1m[32m0.31913[0m[0m | time: 22.764s
[2K
| Adam | epoch: 029 | loss: 0.31913 - acc: 0.8785 -- iter: 0640/1140
[A[ATraining Step: 1029  | total loss: [1m[32m0.31396[0m[0m | time: 24.076s
[2K
| Adam | epoch: 029 | loss: 0.31396 - acc: 0.8813 -- iter: 0672/1140
[A[ATraining Step: 1030  | total loss: [1m[32m0.30841[0m[0m | time: 25.276s
[2K
| Adam | epoch: 029 | loss: 0.30841 - acc: 0.8838 -- iter: 0704/1140
[A[ATraining Step: 1031  | total loss: [1m[32m0.31161[0m[0m | time: 26.314s
[2K
| Adam | epoch: 029 | loss: 0.31161 - acc: 0.8798 -- iter: 0736/1140
[A[ATraining Step: 1032  | total loss: [1m[32m0.31017[0m[0m | time: 27.343s
[2K
| Adam | epoch: 029 | loss: 0.31017 - acc: 0.8824 -- iter: 0768/1140
[A[ATraining Step: 1033  | total loss: [1m[32m0.32280[0m[0m | time: 28.416s
[2K
| Adam | epoch: 029 | loss: 0.32280 - acc: 0.8754 -- iter: 0800/1140
[A[ATraining Step: 1034  | total loss: [1m[32m0.32767[0m[0m | time: 29.640s
[2K
| Adam | epoch: 029 | loss: 0.32767 - acc: 0.8754 -- iter: 0832/1140
[A[ATraining Step: 1035  | total loss: [1m[32m0.33347[0m[0m | time: 30.512s
[2K
| Adam | epoch: 029 | loss: 0.33347 - acc: 0.8722 -- iter: 0864/1140
[A[ATraining Step: 1036  | total loss: [1m[32m0.34809[0m[0m | time: 31.094s
[2K
| Adam | epoch: 029 | loss: 0.34809 - acc: 0.8600 -- iter: 0896/1140
[A[ATraining Step: 1037  | total loss: [1m[32m0.35536[0m[0m | time: 32.140s
[2K
| Adam | epoch: 029 | loss: 0.35536 - acc: 0.8440 -- iter: 0928/1140
[A[ATraining Step: 1038  | total loss: [1m[32m0.36542[0m[0m | time: 33.159s
[2K
| Adam | epoch: 029 | loss: 0.36542 - acc: 0.8440 -- iter: 0960/1140
[A[ATraining Step: 1039  | total loss: [1m[32m0.36360[0m[0m | time: 34.353s
[2K
| Adam | epoch: 029 | loss: 0.36360 - acc: 0.8408 -- iter: 0992/1140
[A[ATraining Step: 1040  | total loss: [1m[32m0.34421[0m[0m | time: 35.331s
[2K
| Adam | epoch: 029 | loss: 0.34421 - acc: 0.8536 -- iter: 1024/1140
[A[ATraining Step: 1041  | total loss: [1m[32m0.36022[0m[0m | time: 36.502s
[2K
| Adam | epoch: 029 | loss: 0.36022 - acc: 0.8464 -- iter: 1056/1140
[A[ATraining Step: 1042  | total loss: [1m[32m0.36017[0m[0m | time: 37.829s
[2K
| Adam | epoch: 029 | loss: 0.36017 - acc: 0.8461 -- iter: 1088/1140
[A[ATraining Step: 1043  | total loss: [1m[32m0.35338[0m[0m | time: 39.060s
[2K
| Adam | epoch: 029 | loss: 0.35338 - acc: 0.8521 -- iter: 1120/1140
[A[ATraining Step: 1044  | total loss: [1m[32m0.34494[0m[0m | time: 42.518s
[2K
| Adam | epoch: 029 | loss: 0.34494 - acc: 0.8544 | val_loss: 0.61268 - val_acc: 0.7311 -- iter: 1140/1140
--
Training Step: 1045  | total loss: [1m[32m0.33418[0m[0m | time: 1.293s
[2K
| Adam | epoch: 030 | loss: 0.33418 - acc: 0.8627 -- iter: 0032/1140
[A[ATraining Step: 1046  | total loss: [1m[32m0.32806[0m[0m | time: 2.244s
[2K
| Adam | epoch: 030 | loss: 0.32806 - acc: 0.8608 -- iter: 0064/1140
[A[ATraining Step: 1047  | total loss: [1m[32m0.32678[0m[0m | time: 3.318s
[2K
| Adam | epoch: 030 | loss: 0.32678 - acc: 0.8591 -- iter: 0096/1140
[A[ATraining Step: 1048  | total loss: [1m[32m0.32850[0m[0m | time: 4.419s
[2K
| Adam | epoch: 030 | loss: 0.32850 - acc: 0.8513 -- iter: 0128/1140
[A[ATraining Step: 1049  | total loss: [1m[32m0.31737[0m[0m | time: 5.685s
[2K
| Adam | epoch: 030 | loss: 0.31737 - acc: 0.8631 -- iter: 0160/1140
[A[ATraining Step: 1050  | total loss: [1m[32m0.30619[0m[0m | time: 6.938s
[2K
| Adam | epoch: 030 | loss: 0.30619 - acc: 0.8736 -- iter: 0192/1140
[A[ATraining Step: 1051  | total loss: [1m[32m0.30131[0m[0m | time: 7.936s
[2K
| Adam | epoch: 030 | loss: 0.30131 - acc: 0.8769 -- iter: 0224/1140
[A[ATraining Step: 1052  | total loss: [1m[32m0.29628[0m[0m | time: 8.887s
[2K
| Adam | epoch: 030 | loss: 0.29628 - acc: 0.8767 -- iter: 0256/1140
[A[ATraining Step: 1053  | total loss: [1m[32m0.29970[0m[0m | time: 9.988s
[2K
| Adam | epoch: 030 | loss: 0.29970 - acc: 0.8765 -- iter: 0288/1140
[A[ATraining Step: 1054  | total loss: [1m[32m0.29625[0m[0m | time: 11.111s
[2K
| Adam | epoch: 030 | loss: 0.29625 - acc: 0.8795 -- iter: 0320/1140
[A[ATraining Step: 1055  | total loss: [1m[32m0.28864[0m[0m | time: 12.219s
[2K
| Adam | epoch: 030 | loss: 0.28864 - acc: 0.8853 -- iter: 0352/1140
[A[ATraining Step: 1056  | total loss: [1m[32m0.28751[0m[0m | time: 13.374s
[2K
| Adam | epoch: 030 | loss: 0.28751 - acc: 0.8843 -- iter: 0384/1140
[A[ATraining Step: 1057  | total loss: [1m[32m0.27875[0m[0m | time: 14.585s
[2K
| Adam | epoch: 030 | loss: 0.27875 - acc: 0.8896 -- iter: 0416/1140
[A[ATraining Step: 1058  | total loss: [1m[32m0.27124[0m[0m | time: 15.749s
[2K
| Adam | epoch: 030 | loss: 0.27124 - acc: 0.8944 -- iter: 0448/1140
[A[ATraining Step: 1059  | total loss: [1m[32m0.28567[0m[0m | time: 16.984s
[2K
| Adam | epoch: 030 | loss: 0.28567 - acc: 0.8893 -- iter: 0480/1140
[A[ATraining Step: 1060  | total loss: [1m[32m0.27055[0m[0m | time: 18.087s
[2K
| Adam | epoch: 030 | loss: 0.27055 - acc: 0.9004 -- iter: 0512/1140
[A[ATraining Step: 1061  | total loss: [1m[32m0.27835[0m[0m | time: 19.206s
[2K
| Adam | epoch: 030 | loss: 0.27835 - acc: 0.8947 -- iter: 0544/1140
[A[ATraining Step: 1062  | total loss: [1m[32m0.27483[0m[0m | time: 20.484s
[2K
| Adam | epoch: 030 | loss: 0.27483 - acc: 0.8990 -- iter: 0576/1140
[A[ATraining Step: 1063  | total loss: [1m[32m0.27737[0m[0m | time: 21.635s
[2K
| Adam | epoch: 030 | loss: 0.27737 - acc: 0.8997 -- iter: 0608/1140
[A[ATraining Step: 1064  | total loss: [1m[32m0.28392[0m[0m | time: 22.688s
[2K
| Adam | epoch: 030 | loss: 0.28392 - acc: 0.8973 -- iter: 0640/1140
[A[ATraining Step: 1065  | total loss: [1m[32m0.27984[0m[0m | time: 23.886s
[2K
| Adam | epoch: 030 | loss: 0.27984 - acc: 0.9013 -- iter: 0672/1140
[A[ATraining Step: 1066  | total loss: [1m[32m0.28228[0m[0m | time: 25.000s
[2K
| Adam | epoch: 030 | loss: 0.28228 - acc: 0.9049 -- iter: 0704/1140
[A[ATraining Step: 1067  | total loss: [1m[32m0.28829[0m[0m | time: 26.083s
[2K
| Adam | epoch: 030 | loss: 0.28829 - acc: 0.9019 -- iter: 0736/1140
[A[ATraining Step: 1068  | total loss: [1m[32m0.29845[0m[0m | time: 27.191s
[2K
| Adam | epoch: 030 | loss: 0.29845 - acc: 0.8867 -- iter: 0768/1140
[A[ATraining Step: 1069  | total loss: [1m[32m0.29553[0m[0m | time: 28.389s
[2K
| Adam | epoch: 030 | loss: 0.29553 - acc: 0.8918 -- iter: 0800/1140
[A[ATraining Step: 1070  | total loss: [1m[32m0.29284[0m[0m | time: 29.518s
[2K
| Adam | epoch: 030 | loss: 0.29284 - acc: 0.8932 -- iter: 0832/1140
[A[ATraining Step: 1071  | total loss: [1m[32m0.30729[0m[0m | time: 30.626s
[2K
| Adam | epoch: 030 | loss: 0.30729 - acc: 0.8820 -- iter: 0864/1140
[A[ATraining Step: 1072  | total loss: [1m[32m0.30386[0m[0m | time: 31.435s
[2K
| Adam | epoch: 030 | loss: 0.30386 - acc: 0.8876 -- iter: 0896/1140
[A[ATraining Step: 1073  | total loss: [1m[32m0.29093[0m[0m | time: 32.253s
[2K
| Adam | epoch: 030 | loss: 0.29093 - acc: 0.8938 -- iter: 0928/1140
[A[ATraining Step: 1074  | total loss: [1m[32m0.27877[0m[0m | time: 33.717s
[2K
| Adam | epoch: 030 | loss: 0.27877 - acc: 0.8944 -- iter: 0960/1140
[A[ATraining Step: 1075  | total loss: [1m[32m0.28352[0m[0m | time: 34.764s
[2K
| Adam | epoch: 030 | loss: 0.28352 - acc: 0.8925 -- iter: 0992/1140
[A[ATraining Step: 1076  | total loss: [1m[32m0.27686[0m[0m | time: 35.506s
[2K
| Adam | epoch: 030 | loss: 0.27686 - acc: 0.8908 -- iter: 1024/1140
[A[ATraining Step: 1077  | total loss: [1m[32m0.26908[0m[0m | time: 36.614s
[2K
| Adam | epoch: 030 | loss: 0.26908 - acc: 0.8954 -- iter: 1056/1140
[A[ATraining Step: 1078  | total loss: [1m[32m0.28752[0m[0m | time: 37.842s
[2K
| Adam | epoch: 030 | loss: 0.28752 - acc: 0.8871 -- iter: 1088/1140
[A[ATraining Step: 1079  | total loss: [1m[32m0.27670[0m[0m | time: 39.121s
[2K
| Adam | epoch: 030 | loss: 0.27670 - acc: 0.8953 -- iter: 1120/1140
[A[ATraining Step: 1080  | total loss: [1m[32m0.28178[0m[0m | time: 43.128s
[2K
| Adam | epoch: 030 | loss: 0.28178 - acc: 0.8964 | val_loss: 0.62978 - val_acc: 0.7451 -- iter: 1140/1140
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7780712050078247
Validation AUPRC:0.8330895928296255
Test AUC:0.827620173364854
Test AUPRC:0.8731048503318355
BestTestF1Score	0.81	0.49	0.76	0.77	0.86	185	54	87	31	0.33
BestTestMCCScore	0.8	0.51	0.76	0.83	0.77	166	35	106	50	0.47
BestTestAccuracyScore	0.8	0.51	0.76	0.83	0.77	166	35	106	50	0.47
BestValidationF1Score	0.8	0.47	0.75	0.75	0.86	184	61	83	29	0.33
BestValidationMCC	0.8	0.49	0.75	0.79	0.8	171	46	98	42	0.47
BestValidationAccuracy	0.8	0.49	0.75	0.79	0.8	171	46	98	42	0.47
TestPredictions (Threshold:0.47)
CHEMBL555016,FN,ACT,0.3499999940395355	CHEMBL2419073,TN,INACT,0.3499999940395355	CHEMBL2205884,FN,ACT,0.36000001430511475	CHEMBL238628,TN,INACT,0.23999999463558197	CHEMBL3693888,TN,INACT,0.11999999731779099	CHEMBL2206077,FN,ACT,0.4399999976158142	CHEMBL272861,TP,ACT,0.6499999761581421	CHEMBL7167,FP,INACT,0.8700000047683716	CHEMBL87768,TN,INACT,0.07999999821186066	CHEMBL3088252,TP,ACT,0.9399999976158142	CHEMBL2419068,TN,INACT,0.10999999940395355	CHEMBL3403308,TN,INACT,0.07999999821186066	CHEMBL233147,TN,INACT,0.14000000059604645	CHEMBL514239,TP,ACT,0.9700000286102295	CHEMBL452449,TP,ACT,0.6299999952316284	CHEMBL210837,TP,ACT,0.9900000095367432	CHEMBL3098851,TP,ACT,0.9700000286102295	CHEMBL1086499,TP,ACT,1.0	CHEMBL3402409,FN,ACT,0.23000000417232513	CHEMBL2370296,TP,ACT,0.9900000095367432	CHEMBL2414197,FN,ACT,0.10000000149011612	CHEMBL2436026,TP,ACT,0.9900000095367432	CHEMBL2262836,TP,ACT,1.0	CHEMBL2259739,FP,INACT,0.5400000214576721	CHEMBL1778921,FN,ACT,0.25999999046325684	CHEMBL341806,TN,INACT,0.14000000059604645	CHEMBL499061,FN,ACT,0.20999999344348907	CHEMBL3752820,TN,INACT,0.10999999940395355	CHEMBL1910966,TN,INACT,0.38999998569488525	CHEMBL59402,FN,ACT,0.27000001072883606	CHEMBL1242552,TP,ACT,0.8600000143051147	CHEMBL3427137,TP,ACT,0.6899999976158142	CHEMBL1779052,FN,ACT,0.23000000417232513	CHEMBL246659,TP,ACT,0.9300000071525574	CHEMBL3393171,TN,INACT,0.07999999821186066	CHEMBL3634593,TP,ACT,0.9800000190734863	CHEMBL515252,TP,ACT,0.7599999904632568	CHEMBL244146,TP,ACT,0.9200000166893005	CHEMBL2206735,TN,INACT,0.10000000149011612	CHEMBL446073,TP,ACT,0.9800000190734863	CHEMBL197681,TP,ACT,0.9900000095367432	CHEMBL2419077,TN,INACT,0.05999999865889549	CHEMBL2424705,TN,INACT,0.1599999964237213	CHEMBL1765359,FN,ACT,0.03999999910593033	CHEMBL363977,TP,ACT,0.7400000095367432	CHEMBL1242553,TP,ACT,0.9700000286102295	CHEMBL304307,TN,INACT,0.07000000029802322	CHEMBL2235924,TN,INACT,0.07000000029802322	CHEMBL202917,TN,INACT,0.1899999976158142	CHEMBL526866,TN,INACT,0.029999999329447746	CHEMBL230751,TP,ACT,0.8999999761581421	CHEMBL1822607,TP,ACT,0.9599999785423279	CHEMBL508948,TN,INACT,0.3700000047683716	CHEMBL3692119,TN,INACT,0.05999999865889549	CHEMBL290496,TP,ACT,0.8399999737739563	CHEMBL509868,TP,ACT,0.9399999976158142	CHEMBL2017841,TP,ACT,0.800000011920929	CHEMBL509059,TP,ACT,0.5600000023841858	CHEMBL244563,TP,ACT,0.9300000071525574	CHEMBL383033,TN,INACT,0.05000000074505806	CHEMBL3360914,TN,INACT,0.09000000357627869	CHEMBL482965,FP,INACT,0.8199999928474426	CHEMBL1801440,TP,ACT,0.9900000095367432	CHEMBL102015,FP,INACT,0.75	CHEMBL116901,TP,ACT,1.0	CHEMBL400144,TN,INACT,0.05000000074505806	CHEMBL126613,TP,ACT,0.9900000095367432	CHEMBL1778922,FN,ACT,0.46000000834465027	CHEMBL198496,FN,ACT,0.4300000071525574	CHEMBL289069,TN,INACT,0.05000000074505806	CHEMBL108473,TP,ACT,0.9800000190734863	CHEMBL3350939,TP,ACT,0.9900000095367432	CHEMBL1667957,TP,ACT,0.6100000143051147	CHEMBL2263109,TP,ACT,0.9800000190734863	CHEMBL267877,FP,INACT,0.9900000095367432	CHEMBL213452,FP,INACT,0.8399999737739563	CHEMBL99271,TN,INACT,0.14000000059604645	CHEMBL139393,TP,ACT,0.7200000286102295	CHEMBL199133,FP,INACT,0.9399999976158142	CHEMBL2235528,TN,INACT,0.07000000029802322	CHEMBL1774309,TN,INACT,0.23000000417232513	CHEMBL3818251,TP,ACT,0.8600000143051147	CHEMBL1088462,FP,INACT,0.699999988079071	CHEMBL138106,TP,ACT,0.8500000238418579	CHEMBL253268,FN,ACT,0.2800000011920929	CHEMBL508233,FP,INACT,0.8999999761581421	CHEMBL326115,FN,ACT,0.23000000417232513	CHEMBL2205892,TP,ACT,0.6499999761581421	CHEMBL200475,FP,INACT,0.9599999785423279	CHEMBL393682,TP,ACT,0.9100000262260437	CHEMBL1923783,FN,ACT,0.4399999976158142	CHEMBL52347,FN,ACT,0.15000000596046448	CHEMBL266474,FP,INACT,0.9900000095367432	CHEMBL1223582,TN,INACT,0.33000001311302185	CHEMBL3758490,FN,ACT,0.2800000011920929	CHEMBL24501,TP,ACT,0.949999988079071	CHEMBL9374,TP,ACT,1.0	CHEMBL24557,TP,ACT,0.9800000190734863	CHEMBL9321,TP,ACT,0.9700000286102295	CHEMBL525078,TN,INACT,0.3700000047683716	CHEMBL3628463,TP,ACT,1.0	CHEMBL2205889,FP,INACT,0.6899999976158142	CHEMBL339225,TP,ACT,0.9599999785423279	CHEMBL2159949,TN,INACT,0.4300000071525574	CHEMBL25368,TP,ACT,1.0	CHEMBL403908,TP,ACT,0.9700000286102295	CHEMBL462721,TN,INACT,0.4399999976158142	CHEMBL2316904,FP,INACT,0.8600000143051147	CHEMBL437119,TP,ACT,0.9900000095367432	CHEMBL1164947,TP,ACT,0.9900000095367432	CHEMBL400023,TP,ACT,0.8999999761581421	CHEMBL2159049,FP,INACT,0.949999988079071	CHEMBL559311,FP,INACT,0.5799999833106995	CHEMBL3822923,TP,ACT,0.9300000071525574	CHEMBL2087681,FP,INACT,0.9599999785423279	CHEMBL341947,FN,ACT,0.2199999988079071	CHEMBL2375442,TN,INACT,0.10000000149011612	CHEMBL110566,TN,INACT,0.07000000029802322	CHEMBL198589,TP,ACT,0.6299999952316284	CHEMBL2431708,TN,INACT,0.25	CHEMBL1086279,TP,ACT,0.949999988079071	CHEMBL106993,FN,ACT,0.20000000298023224	CHEMBL254464,TN,INACT,0.33000001311302185	CHEMBL362917,TP,ACT,0.5099999904632568	CHEMBL291557,TP,ACT,0.9900000095367432	CHEMBL410483,FN,ACT,0.05000000074505806	CHEMBL323976,TN,INACT,0.1899999976158142	CHEMBL64690,TN,INACT,0.14000000059604645	CHEMBL25243,TP,ACT,0.9399999976158142	CHEMBL2373418,TP,ACT,0.9599999785423279	CHEMBL1710150,TN,INACT,0.4399999976158142	CHEMBL336435,FP,INACT,0.9100000262260437	CHEMBL590122,TP,ACT,1.0	CHEMBL1823964,TP,ACT,0.8299999833106995	CHEMBL2377808,TP,ACT,0.5699999928474426	CHEMBL1235987,TP,ACT,0.8299999833106995	CHEMBL424880,TP,ACT,0.9900000095367432	CHEMBL2205518,FN,ACT,0.36000001430511475	CHEMBL369005,TP,ACT,0.9800000190734863	CHEMBL420818,TN,INACT,0.11999999731779099	CHEMBL283635,TP,ACT,1.0	CHEMBL2431669,TN,INACT,0.30000001192092896	CHEMBL261362,FN,ACT,0.07000000029802322	CHEMBL2206073,TP,ACT,0.5699999928474426	CHEMBL315736,TN,INACT,0.05999999865889549	CHEMBL3360903,TN,INACT,0.3799999952316284	CHEMBL103709,FP,INACT,0.6000000238418579	CHEMBL253500,TP,ACT,0.9599999785423279	CHEMBL1823755,TP,ACT,0.9599999785423279	CHEMBL1081369,TN,INACT,0.05999999865889549	CHEMBL173395,TN,INACT,0.20000000298023224	CHEMBL2263116,TP,ACT,0.9399999976158142	CHEMBL254254,FP,INACT,0.47999998927116394	CHEMBL87203,TN,INACT,0.30000001192092896	CHEMBL397791,FN,ACT,0.3199999928474426	CHEMBL3238201,TP,ACT,0.8999999761581421	CHEMBL463947,TN,INACT,0.4000000059604645	CHEMBL3310445,TP,ACT,0.8999999761581421	CHEMBL230862,TP,ACT,0.9900000095367432	CHEMBL333158,TN,INACT,0.3400000035762787	CHEMBL307095,TN,INACT,0.10000000149011612	CHEMBL2375444,TP,ACT,0.550000011920929	CHEMBL2087693,TP,ACT,0.7799999713897705	CHEMBL1783784,FN,ACT,0.10999999940395355	CHEMBL562468,TP,ACT,0.6899999976158142	CHEMBL1253293,FP,INACT,0.6600000262260437	CHEMBL3818579,TP,ACT,0.9800000190734863	CHEMBL1795948,TN,INACT,0.05000000074505806	CHEMBL396555,FN,ACT,0.44999998807907104	CHEMBL2207337,TN,INACT,0.20000000298023224	CHEMBL1778920,TP,ACT,0.6299999952316284	CHEMBL3402414,FN,ACT,0.1899999976158142	CHEMBL133541,TP,ACT,0.6800000071525574	CHEMBL539154,TP,ACT,0.9900000095367432	CHEMBL1801401,TP,ACT,0.6899999976158142	CHEMBL197910,TP,ACT,0.7200000286102295	CHEMBL110642,TP,ACT,0.7699999809265137	CHEMBL26100,TP,ACT,0.949999988079071	CHEMBL3596431,TN,INACT,0.05999999865889549	CHEMBL243267,TP,ACT,0.6299999952316284	CHEMBL1223641,TN,INACT,0.4699999988079071	CHEMBL1951708,FP,INACT,0.6600000262260437	CHEMBL294767,TP,ACT,0.9900000095367432	CHEMBL3759405,TP,ACT,0.5	CHEMBL561967,FN,ACT,0.4300000071525574	CHEMBL558103,TN,INACT,0.20000000298023224	CHEMBL2017843,TP,ACT,0.8100000023841858	CHEMBL237915,TP,ACT,0.6000000238418579	CHEMBL247278,TP,ACT,0.8199999928474426	CHEMBL3098945,FN,ACT,0.25	CHEMBL3310431,TP,ACT,0.49000000953674316	CHEMBL1783778,TN,INACT,0.07999999821186066	CHEMBL3692082,TN,INACT,0.029999999329447746	CHEMBL271751,TN,INACT,0.05999999865889549	CHEMBL1779057,TN,INACT,0.05000000074505806	CHEMBL264833,TP,ACT,0.6100000143051147	CHEMBL321599,TN,INACT,0.05000000074505806	CHEMBL2419079,TN,INACT,0.4300000071525574	CHEMBL101423,FP,INACT,0.5099999904632568	CHEMBL590480,TP,ACT,0.9900000095367432	CHEMBL1910887,TN,INACT,0.10999999940395355	CHEMBL212147,TP,ACT,0.9900000095367432	CHEMBL1823762,TP,ACT,0.8999999761581421	CHEMBL9339,TP,ACT,0.9800000190734863	CHEMBL1935497,TP,ACT,0.949999988079071	CHEMBL1223852,FN,ACT,0.44999998807907104	CHEMBL187460,TN,INACT,0.07999999821186066	CHEMBL2424692,FN,ACT,0.4699999988079071	CHEMBL198220,TP,ACT,0.6700000166893005	CHEMBL1076247,FP,INACT,0.5099999904632568	CHEMBL303581,FN,ACT,0.4399999976158142	CHEMBL197590,TP,ACT,0.9200000166893005	CHEMBL366343,FP,INACT,0.9300000071525574	CHEMBL99776,TN,INACT,0.07000000029802322	CHEMBL2206074,TP,ACT,0.8799999952316284	CHEMBL385251,TP,ACT,0.8100000023841858	CHEMBL574276,FN,ACT,0.1599999964237213	CHEMBL377774,TP,ACT,0.9900000095367432	CHEMBL487412,TP,ACT,0.6200000047683716	CHEMBL2419074,TN,INACT,0.09000000357627869	CHEMBL317046,TN,INACT,0.12999999523162842	CHEMBL51447,TP,ACT,0.7400000095367432	CHEMBL24566,TP,ACT,0.9900000095367432	CHEMBL140954,TP,ACT,0.9700000286102295	CHEMBL87002,TN,INACT,0.3700000047683716	CHEMBL377141,TP,ACT,1.0	CHEMBL325309,TN,INACT,0.03999999910593033	CHEMBL430200,TP,ACT,0.800000011920929	CHEMBL1823962,TP,ACT,0.8199999928474426	CHEMBL1688937,TN,INACT,0.07000000029802322	CHEMBL1917280,TN,INACT,0.10999999940395355	CHEMBL3393150,TN,INACT,0.15000000596046448	CHEMBL372159,TN,INACT,0.23999999463558197	CHEMBL58737,TP,ACT,0.8500000238418579	CHEMBL3692100,TN,INACT,0.05999999865889549	CHEMBL3234650,TP,ACT,0.8299999833106995	CHEMBL2349152,TP,ACT,0.9800000190734863	CHEMBL2431675,TN,INACT,0.27000001072883606	CHEMBL110922,TN,INACT,0.1599999964237213	CHEMBL2011698,FP,INACT,0.8500000238418579	CHEMBL2205886,TP,ACT,0.5400000214576721	CHEMBL565371,TP,ACT,0.7599999904632568	CHEMBL2424693,FN,ACT,0.27000001072883606	CHEMBL2159047,FN,ACT,0.23999999463558197	CHEMBL2205519,TP,ACT,0.699999988079071	CHEMBL276983,TP,ACT,1.0	CHEMBL1082299,TP,ACT,0.9900000095367432	CHEMBL514711,TN,INACT,0.14000000059604645	CHEMBL1822604,FP,INACT,0.9700000286102295	CHEMBL1667954,TN,INACT,0.05000000074505806	CHEMBL2436037,TP,ACT,0.9900000095367432	CHEMBL2002784,FN,ACT,0.1599999964237213	CHEMBL504726,TP,ACT,0.9399999976158142	CHEMBL551671,FN,ACT,0.3499999940395355	CHEMBL2431706,TN,INACT,0.07999999821186066	CHEMBL441959,TP,ACT,1.0	CHEMBL572574,TP,ACT,0.6600000262260437	CHEMBL206462,TP,ACT,0.6600000262260437	CHEMBL246660,TP,ACT,0.7699999809265137	CHEMBL2431703,TN,INACT,0.17000000178813934	CHEMBL3632913,TP,ACT,0.8500000238418579	CHEMBL1938823,FN,ACT,0.4300000071525574	CHEMBL377476,TP,ACT,0.9900000095367432	CHEMBL1254103,FP,INACT,0.6399999856948853	CHEMBL377439,TN,INACT,0.3100000023841858	CHEMBL3751917,TN,INACT,0.05000000074505806	CHEMBL129681,TP,ACT,0.9700000286102295	CHEMBL388425,TP,ACT,0.9599999785423279	CHEMBL2263111,TP,ACT,1.0	CHEMBL2414202,TN,INACT,0.07999999821186066	CHEMBL1164948,TP,ACT,0.9900000095367432	CHEMBL1241315,TP,ACT,1.0	CHEMBL2437370,TN,INACT,0.1899999976158142	CHEMBL320852,FP,INACT,0.6399999856948853	CHEMBL235596,TP,ACT,0.8199999928474426	CHEMBL58292,TN,INACT,0.4099999964237213	CHEMBL208604,TP,ACT,0.9900000095367432	CHEMBL325319,FP,INACT,0.9900000095367432	CHEMBL2424704,FN,ACT,0.3799999952316284	CHEMBL1098728,TP,ACT,0.8299999833106995	CHEMBL3098857,TP,ACT,0.8299999833106995	CHEMBL3238194,TP,ACT,0.8600000143051147	CHEMBL9470,FP,INACT,0.5400000214576721	CHEMBL205730,TN,INACT,0.10000000149011612	CHEMBL1938820,TP,ACT,0.6899999976158142	CHEMBL1169,TN,INACT,0.05000000074505806	CHEMBL235805,FN,ACT,0.20999999344348907	CHEMBL3693932,TN,INACT,0.029999999329447746	CHEMBL476666,TP,ACT,0.9200000166893005	CHEMBL2158214,TP,ACT,0.9900000095367432	CHEMBL198012,FN,ACT,0.38999998569488525	CHEMBL2349150,TP,ACT,0.9700000286102295	CHEMBL18927,TN,INACT,0.1899999976158142	CHEMBL24098,TP,ACT,0.9800000190734863	CHEMBL96952,FN,ACT,0.07000000029802322	CHEMBL285125,TP,ACT,1.0	CHEMBL320836,TN,INACT,0.18000000715255737	CHEMBL1478,FP,INACT,0.7300000190734863	CHEMBL3692121,TN,INACT,0.05000000074505806	CHEMBL233766,TN,INACT,0.25999999046325684	CHEMBL2206067,TP,ACT,0.8299999833106995	CHEMBL601290,TP,ACT,0.47999998927116394	CHEMBL322377,TN,INACT,0.23000000417232513	CHEMBL2159931,TN,INACT,0.09000000357627869	CHEMBL1795951,TP,ACT,0.699999988079071	CHEMBL476655,TN,INACT,0.11999999731779099	CHEMBL1242826,TP,ACT,0.6000000238418579	CHEMBL538192,TP,ACT,0.8399999737739563	CHEMBL3608571,TP,ACT,0.9700000286102295	CHEMBL1078307,TP,ACT,0.5	CHEMBL63354,TP,ACT,0.8700000047683716	CHEMBL3400665,TN,INACT,0.25	CHEMBL1938818,TP,ACT,0.75	CHEMBL61121,FP,INACT,0.6100000143051147	CHEMBL1667953,TN,INACT,0.07999999821186066	CHEMBL3581315,TP,ACT,0.8899999856948853	CHEMBL364604,FN,ACT,0.11999999731779099	CHEMBL2414204,TN,INACT,0.4300000071525574	CHEMBL517247,FN,ACT,0.44999998807907104	CHEMBL1160953,TN,INACT,0.07999999821186066	CHEMBL1617285,FP,INACT,0.8899999856948853	CHEMBL523885,TP,ACT,0.9300000071525574	CHEMBL139356,TP,ACT,0.5199999809265137	CHEMBL3696135,TN,INACT,0.3799999952316284	CHEMBL364328,TN,INACT,0.09000000357627869	CHEMBL424840,TP,ACT,0.6600000262260437	CHEMBL320065,TP,ACT,0.9900000095367432	CHEMBL3238203,TP,ACT,0.800000011920929	CHEMBL3360916,FP,INACT,0.699999988079071	CHEMBL2419072,FN,ACT,0.09000000357627869	CHEMBL2235525,TN,INACT,0.05999999865889549	CHEMBL370304,TP,ACT,0.5199999809265137	CHEMBL140757,FN,ACT,0.27000001072883606	CHEMBL57974,FN,ACT,0.07999999821186066	CHEMBL2262831,TP,ACT,0.9800000190734863	CHEMBL253066,FN,ACT,0.4000000059604645	CHEMBL1631840,TP,ACT,0.9900000095367432	CHEMBL403093,TP,ACT,0.5299999713897705	CHEMBL472896,TP,ACT,0.8700000047683716	CHEMBL26216,TP,ACT,0.9900000095367432	CHEMBL381809,TN,INACT,0.07999999821186066	CHEMBL2259738,TN,INACT,0.4099999964237213	CHEMBL549297,TP,ACT,0.9200000166893005	CHEMBL465069,TP,ACT,0.7300000190734863	CHEMBL3220072,FN,ACT,0.20000000298023224	CHEMBL3692076,TN,INACT,0.05000000074505806	CHEMBL556729,TP,ACT,0.699999988079071	CHEMBL199124,FN,ACT,0.33000001311302185	CHEMBL403674,TN,INACT,0.20000000298023224	CHEMBL521821,TP,ACT,0.8399999737739563	CHEMBL228563,FP,INACT,0.9200000166893005	CHEMBL1160372,TN,INACT,0.07000000029802322	CHEMBL1650892,TP,ACT,0.8299999833106995	CHEMBL382338,TP,ACT,0.9100000262260437	CHEMBL2431667,TN,INACT,0.3199999928474426	CHEMBL86966,TN,INACT,0.07999999821186066	CHEMBL2207335,FN,ACT,0.019999999552965164	

