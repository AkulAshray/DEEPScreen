ImageNetInceptionV2 CHEMBL5147 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	384
Number of inactive compounds :	384
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5147_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5147_adam_0.0001_15_0.6/
---------------------------------
Training samples: 472
Validation samples: 148
--
Training Step: 1  | time: 38.001s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/472
[A[ATraining Step: 2  | total loss: [1m[32m0.60247[0m[0m | time: 47.333s
[2K
| Adam | epoch: 001 | loss: 0.60247 - acc: 0.5062 -- iter: 064/472
[A[ATraining Step: 3  | total loss: [1m[32m0.69537[0m[0m | time: 56.564s
[2K
| Adam | epoch: 001 | loss: 0.69537 - acc: 0.5778 -- iter: 096/472
[A[ATraining Step: 4  | total loss: [1m[32m0.67001[0m[0m | time: 65.867s
[2K
| Adam | epoch: 001 | loss: 0.67001 - acc: 0.5663 -- iter: 128/472
[A[ATraining Step: 5  | total loss: [1m[32m0.68411[0m[0m | time: 75.162s
[2K
| Adam | epoch: 001 | loss: 0.68411 - acc: 0.5420 -- iter: 160/472
[A[ATraining Step: 6  | total loss: [1m[32m0.66199[0m[0m | time: 84.420s
[2K
| Adam | epoch: 001 | loss: 0.66199 - acc: 0.5753 -- iter: 192/472
[A[ATraining Step: 7  | total loss: [1m[32m0.63695[0m[0m | time: 93.525s
[2K
| Adam | epoch: 001 | loss: 0.63695 - acc: 0.6239 -- iter: 224/472
[A[ATraining Step: 8  | total loss: [1m[32m0.60816[0m[0m | time: 102.821s
[2K
| Adam | epoch: 001 | loss: 0.60816 - acc: 0.6948 -- iter: 256/472
[A[ATraining Step: 9  | total loss: [1m[32m0.62937[0m[0m | time: 112.061s
[2K
| Adam | epoch: 001 | loss: 0.62937 - acc: 0.6413 -- iter: 288/472
[A[ATraining Step: 10  | total loss: [1m[32m0.65389[0m[0m | time: 121.460s
[2K
| Adam | epoch: 001 | loss: 0.65389 - acc: 0.6488 -- iter: 320/472
[A[ATraining Step: 11  | total loss: [1m[32m0.65485[0m[0m | time: 130.824s
[2K
| Adam | epoch: 001 | loss: 0.65485 - acc: 0.6375 -- iter: 352/472
[A[ATraining Step: 12  | total loss: [1m[32m0.69108[0m[0m | time: 140.007s
[2K
| Adam | epoch: 001 | loss: 0.69108 - acc: 0.5897 -- iter: 384/472
[A[ATraining Step: 13  | total loss: [1m[32m0.66376[0m[0m | time: 149.687s
[2K
| Adam | epoch: 001 | loss: 0.66376 - acc: 0.5914 -- iter: 416/472
[A[ATraining Step: 14  | total loss: [1m[32m0.59671[0m[0m | time: 159.244s
[2K
| Adam | epoch: 001 | loss: 0.59671 - acc: 0.6819 -- iter: 448/472
[A[ATraining Step: 15  | total loss: [1m[32m0.56769[0m[0m | time: 179.259s
[2K
| Adam | epoch: 001 | loss: 0.56769 - acc: 0.7208 | val_loss: 1.38670 - val_acc: 0.4662 -- iter: 472/472
--
Training Step: 16  | total loss: [1m[32m0.52490[0m[0m | time: 7.415s
[2K
| Adam | epoch: 002 | loss: 0.52490 - acc: 0.7630 -- iter: 032/472
[A[ATraining Step: 17  | total loss: [1m[32m0.47681[0m[0m | time: 19.644s
[2K
| Adam | epoch: 002 | loss: 0.47681 - acc: 0.8183 -- iter: 064/472
[A[ATraining Step: 18  | total loss: [1m[32m0.46482[0m[0m | time: 31.122s
[2K
| Adam | epoch: 002 | loss: 0.46482 - acc: 0.8271 -- iter: 096/472
[A[ATraining Step: 19  | total loss: [1m[32m0.42950[0m[0m | time: 41.981s
[2K
| Adam | epoch: 002 | loss: 0.42950 - acc: 0.8639 -- iter: 128/472
[A[ATraining Step: 20  | total loss: [1m[32m0.40633[0m[0m | time: 53.798s
[2K
| Adam | epoch: 002 | loss: 0.40633 - acc: 0.8675 -- iter: 160/472
[A[ATraining Step: 21  | total loss: [1m[32m0.41789[0m[0m | time: 63.112s
[2K
| Adam | epoch: 002 | loss: 0.41789 - acc: 0.8504 -- iter: 192/472
[A[ATraining Step: 22  | total loss: [1m[32m0.38967[0m[0m | time: 72.278s
[2K
| Adam | epoch: 002 | loss: 0.38967 - acc: 0.8672 -- iter: 224/472
[A[ATraining Step: 23  | total loss: [1m[32m0.35796[0m[0m | time: 81.641s
[2K
| Adam | epoch: 002 | loss: 0.35796 - acc: 0.8967 -- iter: 256/472
[A[ATraining Step: 24  | total loss: [1m[32m0.35921[0m[0m | time: 93.023s
[2K
| Adam | epoch: 002 | loss: 0.35921 - acc: 0.8818 -- iter: 288/472
[A[ATraining Step: 25  | total loss: [1m[32m0.32401[0m[0m | time: 104.174s
[2K
| Adam | epoch: 002 | loss: 0.32401 - acc: 0.8885 -- iter: 320/472
[A[ATraining Step: 26  | total loss: [1m[32m0.30133[0m[0m | time: 114.095s
[2K
| Adam | epoch: 002 | loss: 0.30133 - acc: 0.8932 -- iter: 352/472
[A[ATraining Step: 27  | total loss: [1m[32m0.34821[0m[0m | time: 123.153s
[2K
| Adam | epoch: 002 | loss: 0.34821 - acc: 0.8724 -- iter: 384/472
[A[ATraining Step: 28  | total loss: [1m[32m0.36811[0m[0m | time: 136.887s
[2K
| Adam | epoch: 002 | loss: 0.36811 - acc: 0.8653 -- iter: 416/472
[A[ATraining Step: 29  | total loss: [1m[32m0.38058[0m[0m | time: 147.510s
[2K
| Adam | epoch: 002 | loss: 0.38058 - acc: 0.8600 -- iter: 448/472
[A[ATraining Step: 30  | total loss: [1m[32m0.38008[0m[0m | time: 163.662s
[2K
| Adam | epoch: 002 | loss: 0.38008 - acc: 0.8710 | val_loss: 3.15062 - val_acc: 0.4662 -- iter: 472/472
--
Training Step: 31  | total loss: [1m[32m0.36126[0m[0m | time: 9.377s
[2K
| Adam | epoch: 003 | loss: 0.36126 - acc: 0.8575 -- iter: 032/472
[A[ATraining Step: 32  | total loss: [1m[32m0.31105[0m[0m | time: 19.078s
[2K
| Adam | epoch: 003 | loss: 0.31105 - acc: 0.8708 -- iter: 064/472
[A[ATraining Step: 33  | total loss: [1m[32m0.26633[0m[0m | time: 90.604s
[2K
| Adam | epoch: 003 | loss: 0.26633 - acc: 0.8992 -- iter: 096/472
[A[ATraining Step: 34  | total loss: [1m[32m0.23709[0m[0m | time: 152.649s
[2K
| Adam | epoch: 003 | loss: 0.23709 - acc: 0.9074 -- iter: 128/472
[A[ATraining Step: 35  | total loss: [1m[32m0.20779[0m[0m | time: 209.368s
[2K
| Adam | epoch: 003 | loss: 0.20779 - acc: 0.9268 -- iter: 160/472
[A[ATraining Step: 36  | total loss: [1m[32m0.17701[0m[0m | time: 236.371s
[2K
| Adam | epoch: 003 | loss: 0.17701 - acc: 0.9417 -- iter: 192/472
[A[ATraining Step: 37  | total loss: [1m[32m0.16385[0m[0m | time: 279.516s
[2K
| Adam | epoch: 003 | loss: 0.16385 - acc: 0.9471 -- iter: 224/472
[A[ATraining Step: 38  | total loss: [1m[32m0.14394[0m[0m | time: 292.070s
[2K
| Adam | epoch: 003 | loss: 0.14394 - acc: 0.9514 -- iter: 256/472
[A[ATraining Step: 39  | total loss: [1m[32m0.12562[0m[0m | time: 341.915s
[2K
| Adam | epoch: 003 | loss: 0.12562 - acc: 0.9607 -- iter: 288/472
[A[ATraining Step: 40  | total loss: [1m[32m0.15325[0m[0m | time: 378.879s
[2K
| Adam | epoch: 003 | loss: 0.15325 - acc: 0.9622 -- iter: 320/472
[A[ATraining Step: 41  | total loss: [1m[32m0.16026[0m[0m | time: 393.482s
[2K
| Adam | epoch: 003 | loss: 0.16026 - acc: 0.9577 -- iter: 352/472
[A[ATraining Step: 42  | total loss: [1m[32m0.14328[0m[0m | time: 405.213s
[2K
| Adam | epoch: 003 | loss: 0.14328 - acc: 0.9653 -- iter: 384/472
[A[ATraining Step: 43  | total loss: [1m[32m0.15201[0m[0m | time: 424.888s
[2K
| Adam | epoch: 003 | loss: 0.15201 - acc: 0.9659 -- iter: 416/472
[A[ATraining Step: 44  | total loss: [1m[32m0.13096[0m[0m | time: 440.065s
[2K
| Adam | epoch: 003 | loss: 0.13096 - acc: 0.9718 -- iter: 448/472
[A[ATraining Step: 45  | total loss: [1m[32m0.12021[0m[0m | time: 648.088s
[2K
| Adam | epoch: 003 | loss: 0.12021 - acc: 0.9713 | val_loss: 1.28389 - val_acc: 0.4662 -- iter: 472/472
--
Training Step: 46  | total loss: [1m[32m0.13002[0m[0m | time: 150.647s
[2K
| Adam | epoch: 004 | loss: 0.13002 - acc: 0.9709 -- iter: 032/472
[A[ATraining Step: 47  | total loss: [1m[32m0.12653[0m[0m | time: 168.790s
[2K
| Adam | epoch: 004 | loss: 0.12653 - acc: 0.9654 -- iter: 064/472
[A[ATraining Step: 48  | total loss: [1m[32m0.16370[0m[0m | time: 186.088s
[2K
| Adam | epoch: 004 | loss: 0.16370 - acc: 0.9643 -- iter: 096/472
[A[ATraining Step: 49  | total loss: [1m[32m0.14515[0m[0m | time: 286.521s
[2K
| Adam | epoch: 004 | loss: 0.14515 - acc: 0.9633 -- iter: 128/472
[A[ATraining Step: 50  | total loss: [1m[32m0.12459[0m[0m | time: 421.797s
[2K
| Adam | epoch: 004 | loss: 0.12459 - acc: 0.9690 -- iter: 160/472
[A[ATraining Step: 51  | total loss: [1m[32m0.11225[0m[0m | time: 524.353s
[2K
| Adam | epoch: 004 | loss: 0.11225 - acc: 0.9690 -- iter: 192/472
[A[ATraining Step: 52  | total loss: [1m[32m0.10090[0m[0m | time: 611.329s
[2K
| Adam | epoch: 004 | loss: 0.10090 - acc: 0.9736 -- iter: 224/472
[A[ATraining Step: 53  | total loss: [1m[32m0.14083[0m[0m | time: 683.133s
[2K
| Adam | epoch: 004 | loss: 0.14083 - acc: 0.9683 -- iter: 256/472
[A[ATraining Step: 54  | total loss: [1m[32m0.14782[0m[0m | time: 760.949s
[2K
| Adam | epoch: 004 | loss: 0.14782 - acc: 0.9684 -- iter: 288/472
[A[ATraining Step: 55  | total loss: [1m[32m0.14779[0m[0m | time: 822.167s
[2K
| Adam | epoch: 004 | loss: 0.14779 - acc: 0.9684 -- iter: 320/472
[A[ATraining Step: 56  | total loss: [1m[32m0.13011[0m[0m | time: 834.859s
[2K
| Adam | epoch: 004 | loss: 0.13011 - acc: 0.9729 -- iter: 352/472
[A[ATraining Step: 57  | total loss: [1m[32m0.11578[0m[0m | time: 848.311s
[2K
| Adam | epoch: 004 | loss: 0.11578 - acc: 0.9766 -- iter: 384/472
[A[ATraining Step: 58  | total loss: [1m[32m0.14124[0m[0m | time: 861.569s
[2K
| Adam | epoch: 004 | loss: 0.14124 - acc: 0.9713 -- iter: 416/472
[A[ATraining Step: 59  | total loss: [1m[32m0.13654[0m[0m | time: 874.793s
[2K
| Adam | epoch: 004 | loss: 0.13654 - acc: 0.9709 -- iter: 448/472
[A[ATraining Step: 60  | total loss: [1m[32m0.12189[0m[0m | time: 897.253s
[2K
| Adam | epoch: 004 | loss: 0.12189 - acc: 0.9748 | val_loss: 0.91498 - val_acc: 0.6081 -- iter: 472/472
--
Training Step: 61  | total loss: [1m[32m0.11683[0m[0m | time: 13.156s
[2K
| Adam | epoch: 005 | loss: 0.11683 - acc: 0.9740 -- iter: 032/472
[A[ATraining Step: 62  | total loss: [1m[32m0.10560[0m[0m | time: 26.315s
[2K
| Adam | epoch: 005 | loss: 0.10560 - acc: 0.9773 -- iter: 064/472
[A[ATraining Step: 63  | total loss: [1m[32m0.10986[0m[0m | time: 36.610s
[2K
| Adam | epoch: 005 | loss: 0.10986 - acc: 0.9763 -- iter: 096/472
[A[ATraining Step: 64  | total loss: [1m[32m0.12550[0m[0m | time: 46.865s
[2K
| Adam | epoch: 005 | loss: 0.12550 - acc: 0.9688 -- iter: 128/472
[A[ATraining Step: 65  | total loss: [1m[32m0.11619[0m[0m | time: 60.342s
[2K
| Adam | epoch: 005 | loss: 0.11619 - acc: 0.9675 -- iter: 160/472
[A[ATraining Step: 66  | total loss: [1m[32m0.10545[0m[0m | time: 72.477s
[2K
| Adam | epoch: 005 | loss: 0.10545 - acc: 0.9715 -- iter: 192/472
[A[ATraining Step: 67  | total loss: [1m[32m0.11296[0m[0m | time: 85.374s
[2K
| Adam | epoch: 005 | loss: 0.11296 - acc: 0.9711 -- iter: 224/472
[A[ATraining Step: 68  | total loss: [1m[32m0.10314[0m[0m | time: 98.216s
[2K
| Adam | epoch: 005 | loss: 0.10314 - acc: 0.9746 -- iter: 256/472
[A[ATraining Step: 69  | total loss: [1m[32m0.12284[0m[0m | time: 111.290s
[2K
| Adam | epoch: 005 | loss: 0.12284 - acc: 0.9702 -- iter: 288/472
[A[ATraining Step: 70  | total loss: [1m[32m0.10984[0m[0m | time: 124.333s
[2K
| Adam | epoch: 005 | loss: 0.10984 - acc: 0.9737 -- iter: 320/472
[A[ATraining Step: 71  | total loss: [1m[32m0.09859[0m[0m | time: 137.265s
[2K
| Adam | epoch: 005 | loss: 0.09859 - acc: 0.9767 -- iter: 352/472
[A[ATraining Step: 72  | total loss: [1m[32m0.08905[0m[0m | time: 150.389s
[2K
| Adam | epoch: 005 | loss: 0.08905 - acc: 0.9793 -- iter: 384/472
[A[ATraining Step: 73  | total loss: [1m[32m0.11548[0m[0m | time: 164.110s
[2K
| Adam | epoch: 005 | loss: 0.11548 - acc: 0.9746 -- iter: 416/472
[A[ATraining Step: 74  | total loss: [1m[32m0.11421[0m[0m | time: 177.382s
[2K
| Adam | epoch: 005 | loss: 0.11421 - acc: 0.9740 -- iter: 448/472
[A[ATraining Step: 75  | total loss: [1m[32m0.11864[0m[0m | time: 200.409s
[2K
| Adam | epoch: 005 | loss: 0.11864 - acc: 0.9734 | val_loss: 0.69196 - val_acc: 0.7365 -- iter: 472/472
--
Training Step: 76  | total loss: [1m[32m0.11511[0m[0m | time: 13.068s
[2K
| Adam | epoch: 006 | loss: 0.11511 - acc: 0.9729 -- iter: 032/472
[A[ATraining Step: 77  | total loss: [1m[32m0.12062[0m[0m | time: 26.092s
[2K
| Adam | epoch: 006 | loss: 0.12062 - acc: 0.9725 -- iter: 064/472
[A[ATraining Step: 78  | total loss: [1m[32m0.10909[0m[0m | time: 39.050s
[2K
| Adam | epoch: 006 | loss: 0.10909 - acc: 0.9754 -- iter: 096/472
[A[ATraining Step: 79  | total loss: [1m[32m0.09933[0m[0m | time: 49.448s
[2K
| Adam | epoch: 006 | loss: 0.09933 - acc: 0.9779 -- iter: 128/472
[A[ATraining Step: 80  | total loss: [1m[32m0.23420[0m[0m | time: 59.520s
[2K
| Adam | epoch: 006 | loss: 0.23420 - acc: 0.9503 -- iter: 160/472
[A[ATraining Step: 81  | total loss: [1m[32m0.22114[0m[0m | time: 72.512s
[2K
| Adam | epoch: 006 | loss: 0.22114 - acc: 0.9512 -- iter: 192/472
[A[ATraining Step: 82  | total loss: [1m[32m0.20096[0m[0m | time: 85.186s
[2K
| Adam | epoch: 006 | loss: 0.20096 - acc: 0.9560 -- iter: 224/472
[A[ATraining Step: 83  | total loss: [1m[32m0.19042[0m[0m | time: 98.167s
[2K
| Adam | epoch: 006 | loss: 0.19042 - acc: 0.9573 -- iter: 256/472
[A[ATraining Step: 84  | total loss: [1m[32m0.18747[0m[0m | time: 111.414s
[2K
| Adam | epoch: 006 | loss: 0.18747 - acc: 0.9585 -- iter: 288/472
[A[ATraining Step: 85  | total loss: [1m[32m0.18574[0m[0m | time: 123.673s
[2K
| Adam | epoch: 006 | loss: 0.18574 - acc: 0.9595 -- iter: 320/472
[A[ATraining Step: 86  | total loss: [1m[32m0.17062[0m[0m | time: 136.263s
[2K
| Adam | epoch: 006 | loss: 0.17062 - acc: 0.9635 -- iter: 352/472
[A[ATraining Step: 87  | total loss: [1m[32m0.15594[0m[0m | time: 148.400s
[2K
| Adam | epoch: 006 | loss: 0.15594 - acc: 0.9672 -- iter: 384/472
[A[ATraining Step: 88  | total loss: [1m[32m0.15688[0m[0m | time: 162.034s
[2K
| Adam | epoch: 006 | loss: 0.15688 - acc: 0.9673 -- iter: 416/472
[A[ATraining Step: 89  | total loss: [1m[32m0.14578[0m[0m | time: 173.713s
[2K
| Adam | epoch: 006 | loss: 0.14578 - acc: 0.9675 -- iter: 448/472
[A[ATraining Step: 90  | total loss: [1m[32m0.13695[0m[0m | time: 196.579s
[2K
| Adam | epoch: 006 | loss: 0.13695 - acc: 0.9707 | val_loss: 2.14254 - val_acc: 0.5473 -- iter: 472/472
--
Training Step: 91  | total loss: [1m[32m0.12619[0m[0m | time: 10.320s
[2K
| Adam | epoch: 007 | loss: 0.12619 - acc: 0.9737 -- iter: 032/472
[A[ATraining Step: 92  | total loss: [1m[32m0.13118[0m[0m | time: 20.213s
[2K
| Adam | epoch: 007 | loss: 0.13118 - acc: 0.9732 -- iter: 064/472
[A[ATraining Step: 93  | total loss: [1m[32m0.12591[0m[0m | time: 30.599s
[2K
| Adam | epoch: 007 | loss: 0.12591 - acc: 0.9727 -- iter: 096/472
[A[ATraining Step: 94  | total loss: [1m[32m0.12984[0m[0m | time: 40.878s
[2K
| Adam | epoch: 007 | loss: 0.12984 - acc: 0.9723 -- iter: 128/472
[A[ATraining Step: 95  | total loss: [1m[32m0.12881[0m[0m | time: 49.443s
[2K
| Adam | epoch: 007 | loss: 0.12881 - acc: 0.9720 -- iter: 160/472
[A[ATraining Step: 96  | total loss: [1m[32m0.12024[0m[0m | time: 58.119s
[2K
| Adam | epoch: 007 | loss: 0.12024 - acc: 0.9748 -- iter: 192/472
[A[ATraining Step: 97  | total loss: [1m[32m0.10991[0m[0m | time: 68.420s
[2K
| Adam | epoch: 007 | loss: 0.10991 - acc: 0.9773 -- iter: 224/472
[A[ATraining Step: 98  | total loss: [1m[32m0.10000[0m[0m | time: 79.185s
[2K
| Adam | epoch: 007 | loss: 0.10000 - acc: 0.9796 -- iter: 256/472
[A[ATraining Step: 99  | total loss: [1m[32m0.09402[0m[0m | time: 89.820s
[2K
| Adam | epoch: 007 | loss: 0.09402 - acc: 0.9816 -- iter: 288/472
[A[ATraining Step: 100  | total loss: [1m[32m0.08639[0m[0m | time: 100.541s
[2K
| Adam | epoch: 007 | loss: 0.08639 - acc: 0.9834 -- iter: 320/472
[A[ATraining Step: 101  | total loss: [1m[32m0.07920[0m[0m | time: 110.776s
[2K
| Adam | epoch: 007 | loss: 0.07920 - acc: 0.9851 -- iter: 352/472
[A[ATraining Step: 102  | total loss: [1m[32m0.07246[0m[0m | time: 121.583s
[2K
| Adam | epoch: 007 | loss: 0.07246 - acc: 0.9866 -- iter: 384/472
[A[ATraining Step: 103  | total loss: [1m[32m0.06771[0m[0m | time: 131.935s
[2K
| Adam | epoch: 007 | loss: 0.06771 - acc: 0.9879 -- iter: 416/472
[A[ATraining Step: 104  | total loss: [1m[32m0.06297[0m[0m | time: 142.219s
[2K
| Adam | epoch: 007 | loss: 0.06297 - acc: 0.9891 -- iter: 448/472
[A[ATraining Step: 105  | total loss: [1m[32m0.05815[0m[0m | time: 160.989s
[2K
| Adam | epoch: 007 | loss: 0.05815 - acc: 0.9902 | val_loss: 0.97291 - val_acc: 0.7365 -- iter: 472/472
--
Training Step: 106  | total loss: [1m[32m0.05321[0m[0m | time: 10.607s
[2K
| Adam | epoch: 008 | loss: 0.05321 - acc: 0.9912 -- iter: 032/472
[A[ATraining Step: 107  | total loss: [1m[32m0.05918[0m[0m | time: 21.222s
[2K
| Adam | epoch: 008 | loss: 0.05918 - acc: 0.9890 -- iter: 064/472
[A[ATraining Step: 108  | total loss: [1m[32m0.05608[0m[0m | time: 31.987s
[2K
| Adam | epoch: 008 | loss: 0.05608 - acc: 0.9901 -- iter: 096/472
[A[ATraining Step: 109  | total loss: [1m[32m0.05203[0m[0m | time: 42.198s
[2K
| Adam | epoch: 008 | loss: 0.05203 - acc: 0.9911 -- iter: 128/472
[A[ATraining Step: 110  | total loss: [1m[32m0.06732[0m[0m | time: 52.935s
[2K
| Adam | epoch: 008 | loss: 0.06732 - acc: 0.9888 -- iter: 160/472
[A[ATraining Step: 111  | total loss: [1m[32m0.08747[0m[0m | time: 60.773s
[2K
| Adam | epoch: 008 | loss: 0.08747 - acc: 0.9837 -- iter: 192/472
[A[ATraining Step: 112  | total loss: [1m[32m0.09174[0m[0m | time: 69.313s
[2K
| Adam | epoch: 008 | loss: 0.09174 - acc: 0.9812 -- iter: 224/472
[A[ATraining Step: 113  | total loss: [1m[32m0.08327[0m[0m | time: 79.713s
[2K
| Adam | epoch: 008 | loss: 0.08327 - acc: 0.9830 -- iter: 256/472
[A[ATraining Step: 114  | total loss: [1m[32m0.07659[0m[0m | time: 90.091s
[2K
| Adam | epoch: 008 | loss: 0.07659 - acc: 0.9847 -- iter: 288/472
[A[ATraining Step: 115  | total loss: [1m[32m0.08854[0m[0m | time: 100.754s
[2K
| Adam | epoch: 008 | loss: 0.08854 - acc: 0.9831 -- iter: 320/472
[A[ATraining Step: 116  | total loss: [1m[32m0.08913[0m[0m | time: 111.418s
[2K
| Adam | epoch: 008 | loss: 0.08913 - acc: 0.9786 -- iter: 352/472
[A[ATraining Step: 117  | total loss: [1m[32m0.08124[0m[0m | time: 122.174s
[2K
| Adam | epoch: 008 | loss: 0.08124 - acc: 0.9807 -- iter: 384/472
[A[ATraining Step: 118  | total loss: [1m[32m0.07432[0m[0m | time: 132.848s
[2K
| Adam | epoch: 008 | loss: 0.07432 - acc: 0.9826 -- iter: 416/472
[A[ATraining Step: 119  | total loss: [1m[32m0.06999[0m[0m | time: 143.678s
[2K
| Adam | epoch: 008 | loss: 0.06999 - acc: 0.9844 -- iter: 448/472
[A[ATraining Step: 120  | total loss: [1m[32m0.06500[0m[0m | time: 162.226s
[2K
| Adam | epoch: 008 | loss: 0.06500 - acc: 0.9859 | val_loss: 0.91698 - val_acc: 0.7500 -- iter: 472/472
--
Training Step: 121  | total loss: [1m[32m0.05961[0m[0m | time: 10.882s
[2K
| Adam | epoch: 009 | loss: 0.05961 - acc: 0.9873 -- iter: 032/472
[A[ATraining Step: 122  | total loss: [1m[32m0.05449[0m[0m | time: 21.509s
[2K
| Adam | epoch: 009 | loss: 0.05449 - acc: 0.9886 -- iter: 064/472
[A[ATraining Step: 123  | total loss: [1m[32m0.06651[0m[0m | time: 31.810s
[2K
| Adam | epoch: 009 | loss: 0.06651 - acc: 0.9866 -- iter: 096/472
[A[ATraining Step: 124  | total loss: [1m[32m0.06065[0m[0m | time: 42.581s
[2K
| Adam | epoch: 009 | loss: 0.06065 - acc: 0.9880 -- iter: 128/472
[A[ATraining Step: 125  | total loss: [1m[32m0.05599[0m[0m | time: 53.264s
[2K
| Adam | epoch: 009 | loss: 0.05599 - acc: 0.9892 -- iter: 160/472
[A[ATraining Step: 126  | total loss: [1m[32m0.05618[0m[0m | time: 63.930s
[2K
| Adam | epoch: 009 | loss: 0.05618 - acc: 0.9903 -- iter: 192/472
[A[ATraining Step: 127  | total loss: [1m[32m0.06694[0m[0m | time: 72.346s
[2K
| Adam | epoch: 009 | loss: 0.06694 - acc: 0.9881 -- iter: 224/472
[A[ATraining Step: 128  | total loss: [1m[32m0.08620[0m[0m | time: 79.901s
[2K
| Adam | epoch: 009 | loss: 0.08620 - acc: 0.9810 -- iter: 256/472
[A[ATraining Step: 129  | total loss: [1m[32m0.07906[0m[0m | time: 90.534s
[2K
| Adam | epoch: 009 | loss: 0.07906 - acc: 0.9829 -- iter: 288/472
[A[ATraining Step: 130  | total loss: [1m[32m0.07310[0m[0m | time: 101.316s
[2K
| Adam | epoch: 009 | loss: 0.07310 - acc: 0.9846 -- iter: 320/472
[A[ATraining Step: 131  | total loss: [1m[32m0.06745[0m[0m | time: 111.875s
[2K
| Adam | epoch: 009 | loss: 0.06745 - acc: 0.9861 -- iter: 352/472
[A[ATraining Step: 132  | total loss: [1m[32m0.06212[0m[0m | time: 122.798s
[2K
| Adam | epoch: 009 | loss: 0.06212 - acc: 0.9875 -- iter: 384/472
[A[ATraining Step: 133  | total loss: [1m[32m0.06022[0m[0m | time: 133.050s
[2K
| Adam | epoch: 009 | loss: 0.06022 - acc: 0.9888 -- iter: 416/472
[A[ATraining Step: 134  | total loss: [1m[32m0.05673[0m[0m | time: 143.523s
[2K
| Adam | epoch: 009 | loss: 0.05673 - acc: 0.9899 -- iter: 448/472
[A[ATraining Step: 135  | total loss: [1m[32m0.05420[0m[0m | time: 162.378s
[2K
| Adam | epoch: 009 | loss: 0.05420 - acc: 0.9909 | val_loss: 2.66697 - val_acc: 0.5068 -- iter: 472/472
--
Training Step: 136  | total loss: [1m[32m0.04978[0m[0m | time: 10.511s
[2K
| Adam | epoch: 010 | loss: 0.04978 - acc: 0.9918 -- iter: 032/472
[A[ATraining Step: 137  | total loss: [1m[32m0.04690[0m[0m | time: 21.332s
[2K
| Adam | epoch: 010 | loss: 0.04690 - acc: 0.9926 -- iter: 064/472
[A[ATraining Step: 138  | total loss: [1m[32m0.05140[0m[0m | time: 32.263s
[2K
| Adam | epoch: 010 | loss: 0.05140 - acc: 0.9871 -- iter: 096/472
[A[ATraining Step: 139  | total loss: [1m[32m0.04871[0m[0m | time: 41.921s
[2K
| Adam | epoch: 010 | loss: 0.04871 - acc: 0.9884 -- iter: 128/472
[A[ATraining Step: 140  | total loss: [1m[32m0.04423[0m[0m | time: 50.681s
[2K
| Adam | epoch: 010 | loss: 0.04423 - acc: 0.9896 -- iter: 160/472
[A[ATraining Step: 141  | total loss: [1m[32m0.04853[0m[0m | time: 59.494s
[2K
| Adam | epoch: 010 | loss: 0.04853 - acc: 0.9875 -- iter: 192/472
[A[ATraining Step: 142  | total loss: [1m[32m0.06582[0m[0m | time: 68.205s
[2K
| Adam | epoch: 010 | loss: 0.06582 - acc: 0.9856 -- iter: 224/472
[A[ATraining Step: 143  | total loss: [1m[32m0.06011[0m[0m | time: 75.092s
[2K
| Adam | epoch: 010 | loss: 0.06011 - acc: 0.9870 -- iter: 256/472
[A[ATraining Step: 144  | total loss: [1m[32m0.05529[0m[0m | time: 82.106s
[2K
| Adam | epoch: 010 | loss: 0.05529 - acc: 0.9883 -- iter: 288/472
[A[ATraining Step: 145  | total loss: [1m[32m0.05072[0m[0m | time: 90.843s
[2K
| Adam | epoch: 010 | loss: 0.05072 - acc: 0.9895 -- iter: 320/472
[A[ATraining Step: 146  | total loss: [1m[32m0.04842[0m[0m | time: 99.732s
[2K
| Adam | epoch: 010 | loss: 0.04842 - acc: 0.9874 -- iter: 352/472
[A[ATraining Step: 147  | total loss: [1m[32m0.05594[0m[0m | time: 108.488s
[2K
| Adam | epoch: 010 | loss: 0.05594 - acc: 0.9856 -- iter: 384/472
[A[ATraining Step: 148  | total loss: [1m[32m0.05169[0m[0m | time: 117.338s
[2K
| Adam | epoch: 010 | loss: 0.05169 - acc: 0.9870 -- iter: 416/472
[A[ATraining Step: 149  | total loss: [1m[32m0.05252[0m[0m | time: 126.026s
[2K
| Adam | epoch: 010 | loss: 0.05252 - acc: 0.9852 -- iter: 448/472
[A[ATraining Step: 150  | total loss: [1m[32m0.04893[0m[0m | time: 141.371s
[2K
| Adam | epoch: 010 | loss: 0.04893 - acc: 0.9867 | val_loss: 1.43877 - val_acc: 0.6892 -- iter: 472/472
--
Training Step: 151  | total loss: [1m[32m0.04518[0m[0m | time: 8.894s
[2K
| Adam | epoch: 011 | loss: 0.04518 - acc: 0.9880 -- iter: 032/472
[A[ATraining Step: 152  | total loss: [1m[32m0.04166[0m[0m | time: 17.652s
[2K
| Adam | epoch: 011 | loss: 0.04166 - acc: 0.9892 -- iter: 064/472
[A[ATraining Step: 153  | total loss: [1m[32m0.03803[0m[0m | time: 26.358s
[2K
| Adam | epoch: 011 | loss: 0.03803 - acc: 0.9903 -- iter: 096/472
[A[ATraining Step: 154  | total loss: [1m[32m0.03879[0m[0m | time: 35.400s
[2K
| Adam | epoch: 011 | loss: 0.03879 - acc: 0.9881 -- iter: 128/472
[A[ATraining Step: 155  | total loss: [1m[32m0.03604[0m[0m | time: 44.293s
[2K
| Adam | epoch: 011 | loss: 0.03604 - acc: 0.9893 -- iter: 160/472
[A[ATraining Step: 156  | total loss: [1m[32m0.03479[0m[0m | time: 53.019s
[2K
| Adam | epoch: 011 | loss: 0.03479 - acc: 0.9904 -- iter: 192/472
[A[ATraining Step: 157  | total loss: [1m[32m0.03736[0m[0m | time: 61.871s
[2K
| Adam | epoch: 011 | loss: 0.03736 - acc: 0.9882 -- iter: 224/472
[A[ATraining Step: 158  | total loss: [1m[32m0.03859[0m[0m | time: 70.857s
[2K
| Adam | epoch: 011 | loss: 0.03859 - acc: 0.9894 -- iter: 256/472
[A[ATraining Step: 159  | total loss: [1m[32m0.03518[0m[0m | time: 77.972s
[2K
| Adam | epoch: 011 | loss: 0.03518 - acc: 0.9905 -- iter: 288/472
[A[ATraining Step: 160  | total loss: [1m[32m0.03267[0m[0m | time: 84.994s
[2K
| Adam | epoch: 011 | loss: 0.03267 - acc: 0.9914 -- iter: 320/472
[A[ATraining Step: 161  | total loss: [1m[32m0.02976[0m[0m | time: 93.903s
[2K
| Adam | epoch: 011 | loss: 0.02976 - acc: 0.9923 -- iter: 352/472
[A[ATraining Step: 162  | total loss: [1m[32m0.03019[0m[0m | time: 102.816s
[2K
| Adam | epoch: 011 | loss: 0.03019 - acc: 0.9899 -- iter: 384/472
[A[ATraining Step: 163  | total loss: [1m[32m0.02916[0m[0m | time: 111.425s
[2K
| Adam | epoch: 011 | loss: 0.02916 - acc: 0.9909 -- iter: 416/472
[A[ATraining Step: 164  | total loss: [1m[32m0.03188[0m[0m | time: 120.227s
[2K
| Adam | epoch: 011 | loss: 0.03188 - acc: 0.9887 -- iter: 448/472
[A[ATraining Step: 165  | total loss: [1m[32m0.02900[0m[0m | time: 135.554s
[2K
| Adam | epoch: 011 | loss: 0.02900 - acc: 0.9898 | val_loss: 0.81934 - val_acc: 0.7297 -- iter: 472/472
--
Training Step: 166  | total loss: [1m[32m0.03368[0m[0m | time: 8.857s
[2K
| Adam | epoch: 012 | loss: 0.03368 - acc: 0.9877 -- iter: 032/472
[A[ATraining Step: 167  | total loss: [1m[32m0.03083[0m[0m | time: 17.718s
[2K
| Adam | epoch: 012 | loss: 0.03083 - acc: 0.9890 -- iter: 064/472
[A[ATraining Step: 168  | total loss: [1m[32m0.02797[0m[0m | time: 26.454s
[2K
| Adam | epoch: 012 | loss: 0.02797 - acc: 0.9901 -- iter: 096/472
[A[ATraining Step: 169  | total loss: [1m[32m0.02726[0m[0m | time: 35.376s
[2K
| Adam | epoch: 012 | loss: 0.02726 - acc: 0.9911 -- iter: 128/472
[A[ATraining Step: 170  | total loss: [1m[32m0.02606[0m[0m | time: 44.126s
[2K
| Adam | epoch: 012 | loss: 0.02606 - acc: 0.9919 -- iter: 160/472
[A[ATraining Step: 171  | total loss: [1m[32m0.02729[0m[0m | time: 53.069s
[2K
| Adam | epoch: 012 | loss: 0.02729 - acc: 0.9928 -- iter: 192/472
[A[ATraining Step: 172  | total loss: [1m[32m0.02509[0m[0m | time: 62.051s
[2K
| Adam | epoch: 012 | loss: 0.02509 - acc: 0.9935 -- iter: 224/472
[A[ATraining Step: 173  | total loss: [1m[32m0.02317[0m[0m | time: 70.859s
[2K
| Adam | epoch: 012 | loss: 0.02317 - acc: 0.9941 -- iter: 256/472
[A[ATraining Step: 174  | total loss: [1m[32m0.02102[0m[0m | time: 79.619s
[2K
| Adam | epoch: 012 | loss: 0.02102 - acc: 0.9947 -- iter: 288/472
[A[ATraining Step: 175  | total loss: [1m[32m0.03467[0m[0m | time: 86.750s
[2K
| Adam | epoch: 012 | loss: 0.03467 - acc: 0.9921 -- iter: 320/472
[A[ATraining Step: 176  | total loss: [1m[32m0.05517[0m[0m | time: 93.685s
[2K
| Adam | epoch: 012 | loss: 0.05517 - acc: 0.9887 -- iter: 352/472
[A[ATraining Step: 177  | total loss: [1m[32m0.05022[0m[0m | time: 102.457s
[2K
| Adam | epoch: 012 | loss: 0.05022 - acc: 0.9899 -- iter: 384/472
[A[ATraining Step: 178  | total loss: [1m[32m0.04555[0m[0m | time: 111.272s
[2K
| Adam | epoch: 012 | loss: 0.04555 - acc: 0.9909 -- iter: 416/472
[A[ATraining Step: 179  | total loss: [1m[32m0.04217[0m[0m | time: 120.096s
[2K
| Adam | epoch: 012 | loss: 0.04217 - acc: 0.9918 -- iter: 448/472
[A[ATraining Step: 180  | total loss: [1m[32m0.04260[0m[0m | time: 135.615s
[2K
| Adam | epoch: 012 | loss: 0.04260 - acc: 0.9926 | val_loss: 1.11077 - val_acc: 0.7095 -- iter: 472/472
--
Training Step: 181  | total loss: [1m[32m0.03921[0m[0m | time: 9.147s
[2K
| Adam | epoch: 013 | loss: 0.03921 - acc: 0.9934 -- iter: 032/472
[A[ATraining Step: 182  | total loss: [1m[32m0.03571[0m[0m | time: 18.112s
[2K
| Adam | epoch: 013 | loss: 0.03571 - acc: 0.9940 -- iter: 064/472
[A[ATraining Step: 183  | total loss: [1m[32m0.06464[0m[0m | time: 26.782s
[2K
| Adam | epoch: 013 | loss: 0.06464 - acc: 0.9915 -- iter: 096/472
[A[ATraining Step: 184  | total loss: [1m[32m0.06581[0m[0m | time: 35.512s
[2K
| Adam | epoch: 013 | loss: 0.06581 - acc: 0.9892 -- iter: 128/472
[A[ATraining Step: 185  | total loss: [1m[32m0.05944[0m[0m | time: 44.248s
[2K
| Adam | epoch: 013 | loss: 0.05944 - acc: 0.9903 -- iter: 160/472
[A[ATraining Step: 186  | total loss: [1m[32m0.05577[0m[0m | time: 53.112s
[2K
| Adam | epoch: 013 | loss: 0.05577 - acc: 0.9913 -- iter: 192/472
[A[ATraining Step: 187  | total loss: [1m[32m0.05145[0m[0m | time: 61.829s
[2K
| Adam | epoch: 013 | loss: 0.05145 - acc: 0.9921 -- iter: 224/472
[A[ATraining Step: 188  | total loss: [1m[32m0.04726[0m[0m | time: 70.543s
[2K
| Adam | epoch: 013 | loss: 0.04726 - acc: 0.9929 -- iter: 256/472
[A[ATraining Step: 189  | total loss: [1m[32m0.04291[0m[0m | time: 79.241s
[2K
| Adam | epoch: 013 | loss: 0.04291 - acc: 0.9936 -- iter: 288/472
[A[ATraining Step: 190  | total loss: [1m[32m0.03899[0m[0m | time: 88.182s
[2K
| Adam | epoch: 013 | loss: 0.03899 - acc: 0.9943 -- iter: 320/472
[A[ATraining Step: 191  | total loss: [1m[32m0.04355[0m[0m | time: 95.365s
[2K
| Adam | epoch: 013 | loss: 0.04355 - acc: 0.9917 -- iter: 352/472
[A[ATraining Step: 192  | total loss: [1m[32m0.04230[0m[0m | time: 102.479s
[2K
| Adam | epoch: 013 | loss: 0.04230 - acc: 0.9925 -- iter: 384/472
[A[ATraining Step: 193  | total loss: [1m[32m0.03930[0m[0m | time: 111.149s
[2K
| Adam | epoch: 013 | loss: 0.03930 - acc: 0.9933 -- iter: 416/472
[A[ATraining Step: 194  | total loss: [1m[32m0.03635[0m[0m | time: 120.024s
[2K
| Adam | epoch: 013 | loss: 0.03635 - acc: 0.9940 -- iter: 448/472
[A[ATraining Step: 195  | total loss: [1m[32m0.04250[0m[0m | time: 135.795s
[2K
| Adam | epoch: 013 | loss: 0.04250 - acc: 0.9914 | val_loss: 5.65766 - val_acc: 0.4662 -- iter: 472/472
--
Training Step: 196  | total loss: [1m[32m0.03907[0m[0m | time: 8.845s
[2K
| Adam | epoch: 014 | loss: 0.03907 - acc: 0.9923 -- iter: 032/472
[A[ATraining Step: 197  | total loss: [1m[32m0.03627[0m[0m | time: 17.553s
[2K
| Adam | epoch: 014 | loss: 0.03627 - acc: 0.9931 -- iter: 064/472
[A[ATraining Step: 198  | total loss: [1m[32m0.03296[0m[0m | time: 26.260s
[2K
| Adam | epoch: 014 | loss: 0.03296 - acc: 0.9938 -- iter: 096/472
[A[ATraining Step: 199  | total loss: [1m[32m0.03133[0m[0m | time: 35.139s
[2K
| Adam | epoch: 014 | loss: 0.03133 - acc: 0.9944 -- iter: 128/472
[A[ATraining Step: 200  | total loss: [1m[32m0.02907[0m[0m | time: 50.299s
[2K
| Adam | epoch: 014 | loss: 0.02907 - acc: 0.9949 | val_loss: 5.45914 - val_acc: 0.4662 -- iter: 160/472
--
Training Step: 201  | total loss: [1m[32m0.02891[0m[0m | time: 59.157s
[2K
| Adam | epoch: 014 | loss: 0.02891 - acc: 0.9955 -- iter: 192/472
[A[ATraining Step: 202  | total loss: [1m[32m0.02645[0m[0m | time: 67.848s
[2K
| Adam | epoch: 014 | loss: 0.02645 - acc: 0.9959 -- iter: 224/472
[A[ATraining Step: 203  | total loss: [1m[32m0.02430[0m[0m | time: 76.827s
[2K
| Adam | epoch: 014 | loss: 0.02430 - acc: 0.9963 -- iter: 256/472
[A[ATraining Step: 204  | total loss: [1m[32m0.02234[0m[0m | time: 85.783s
[2K
| Adam | epoch: 014 | loss: 0.02234 - acc: 0.9967 -- iter: 288/472
[A[ATraining Step: 205  | total loss: [1m[32m0.02050[0m[0m | time: 94.979s
[2K
| Adam | epoch: 014 | loss: 0.02050 - acc: 0.9970 -- iter: 320/472
[A[ATraining Step: 206  | total loss: [1m[32m0.01867[0m[0m | time: 104.234s
[2K
| Adam | epoch: 014 | loss: 0.01867 - acc: 0.9973 -- iter: 352/472
[A[ATraining Step: 207  | total loss: [1m[32m0.01703[0m[0m | time: 111.110s
[2K
| Adam | epoch: 014 | loss: 0.01703 - acc: 0.9976 -- iter: 384/472
[A[ATraining Step: 208  | total loss: [1m[32m0.07668[0m[0m | time: 118.255s
[2K
| Adam | epoch: 014 | loss: 0.07668 - acc: 0.9895 -- iter: 416/472
[A[ATraining Step: 209  | total loss: [1m[32m0.07076[0m[0m | time: 127.133s
[2K
| Adam | epoch: 014 | loss: 0.07076 - acc: 0.9905 -- iter: 448/472
[A[ATraining Step: 210  | total loss: [1m[32m0.06465[0m[0m | time: 142.766s
[2K
| Adam | epoch: 014 | loss: 0.06465 - acc: 0.9915 | val_loss: 2.30652 - val_acc: 0.5676 -- iter: 472/472
--
Training Step: 211  | total loss: [1m[32m0.07687[0m[0m | time: 9.422s
[2K
| Adam | epoch: 015 | loss: 0.07687 - acc: 0.9892 -- iter: 032/472
[A[ATraining Step: 212  | total loss: [1m[32m0.06959[0m[0m | time: 18.715s
[2K
| Adam | epoch: 015 | loss: 0.06959 - acc: 0.9903 -- iter: 064/472
[A[ATraining Step: 213  | total loss: [1m[32m0.06857[0m[0m | time: 27.688s
[2K
| Adam | epoch: 015 | loss: 0.06857 - acc: 0.9881 -- iter: 096/472
[A[ATraining Step: 214  | total loss: [1m[32m0.06402[0m[0m | time: 36.890s
[2K
| Adam | epoch: 015 | loss: 0.06402 - acc: 0.9893 -- iter: 128/472
[A[ATraining Step: 215  | total loss: [1m[32m0.05892[0m[0m | time: 46.107s
[2K
| Adam | epoch: 015 | loss: 0.05892 - acc: 0.9904 -- iter: 160/472
[A[ATraining Step: 216  | total loss: [1m[32m0.06250[0m[0m | time: 55.439s
[2K
| Adam | epoch: 015 | loss: 0.06250 - acc: 0.9882 -- iter: 192/472
[A[ATraining Step: 217  | total loss: [1m[32m0.05810[0m[0m | time: 64.590s
[2K
| Adam | epoch: 015 | loss: 0.05810 - acc: 0.9894 -- iter: 224/472
[A[ATraining Step: 218  | total loss: [1m[32m0.05650[0m[0m | time: 73.757s
[2K
| Adam | epoch: 015 | loss: 0.05650 - acc: 0.9905 -- iter: 256/472
[A[ATraining Step: 219  | total loss: [1m[32m0.05144[0m[0m | time: 82.887s
[2K
| Adam | epoch: 015 | loss: 0.05144 - acc: 0.9914 -- iter: 288/472
[A[ATraining Step: 220  | total loss: [1m[32m0.04648[0m[0m | time: 92.287s
[2K
| Adam | epoch: 015 | loss: 0.04648 - acc: 0.9923 -- iter: 320/472
[A[ATraining Step: 221  | total loss: [1m[32m0.04231[0m[0m | time: 101.580s
[2K
| Adam | epoch: 015 | loss: 0.04231 - acc: 0.9930 -- iter: 352/472
[A[ATraining Step: 222  | total loss: [1m[32m0.04694[0m[0m | time: 110.894s
[2K
| Adam | epoch: 015 | loss: 0.04694 - acc: 0.9906 -- iter: 384/472
[A[ATraining Step: 223  | total loss: [1m[32m0.04237[0m[0m | time: 118.305s
[2K
| Adam | epoch: 015 | loss: 0.04237 - acc: 0.9916 -- iter: 416/472
[A[ATraining Step: 224  | total loss: [1m[32m0.03867[0m[0m | time: 125.786s
[2K
| Adam | epoch: 015 | loss: 0.03867 - acc: 0.9924 -- iter: 448/472
[A[ATraining Step: 225  | total loss: [1m[32m0.03514[0m[0m | time: 142.544s
[2K
| Adam | epoch: 015 | loss: 0.03514 - acc: 0.9932 | val_loss: 0.83798 - val_acc: 0.7365 -- iter: 472/472
--
Validation AUC:0.8284718400293525
Validation AUPRC:0.8336513464889483
Test AUC:0.8379120879120879
Test AUPRC:0.8527652304433586
BestTestF1Score	0.72	0.4	0.68	0.62	0.86	60	37	41	10	0.07
BestTestMCCScore	0.75	0.5	0.74	0.7	0.81	57	25	53	13	0.31
BestTestAccuracyScore	0.75	0.5	0.74	0.7	0.81	57	25	53	13	0.31
BestValidationF1Score	0.78	0.49	0.74	0.71	0.87	69	28	41	10	0.07
BestValidationMCC	0.78	0.53	0.76	0.78	0.77	61	17	52	18	0.31
BestValidationAccuracy	0.78	0.53	0.76	0.78	0.77	61	17	52	18	0.31
TestPredictions (Threshold:0.31)
CHEMBL3421636,FP,INACT,0.800000011920929	CHEMBL391692,TP,ACT,1.0	CHEMBL456113,TN,INACT,0.0	CHEMBL572878,TP,ACT,0.8399999737739563	CHEMBL1929238,TP,ACT,0.44999998807907104	CHEMBL1242117,FP,INACT,0.6800000071525574	CHEMBL1081025,TP,ACT,1.0	CHEMBL482919,FP,INACT,0.9700000286102295	CHEMBL477064,TN,INACT,0.019999999552965164	CHEMBL396913,TP,ACT,0.6399999856948853	CHEMBL1241674,FN,ACT,0.009999999776482582	CHEMBL550856,TN,INACT,0.019999999552965164	CHEMBL253292,TP,ACT,0.6200000047683716	CHEMBL335938,TN,INACT,0.09000000357627869	CHEMBL230761,TN,INACT,0.0	CHEMBL1242203,TP,ACT,0.8899999856948853	CHEMBL1242844,FP,INACT,0.5099999904632568	CHEMBL2333603,TP,ACT,1.0	CHEMBL3321822,TP,ACT,0.8299999833106995	CHEMBL3356062,TP,ACT,0.8199999928474426	CHEMBL1762544,TP,ACT,1.0	CHEMBL558849,TN,INACT,0.009999999776482582	CHEMBL1270279,TP,ACT,1.0	CHEMBL227924,TN,INACT,0.009999999776482582	CHEMBL1080530,TP,ACT,1.0	CHEMBL1762539,TP,ACT,1.0	CHEMBL2392238,TN,INACT,0.0	CHEMBL1241772,FP,INACT,0.3199999928474426	CHEMBL131695,TN,INACT,0.0	CHEMBL1242295,TP,ACT,1.0	CHEMBL3321814,TP,ACT,1.0	CHEMBL1767294,TN,INACT,0.019999999552965164	CHEMBL521201,FP,INACT,0.6700000166893005	CHEMBL3321803,FN,ACT,0.14000000059604645	CHEMBL575325,TP,ACT,0.9700000286102295	CHEMBL1242027,TP,ACT,0.9900000095367432	CHEMBL1080206,FN,ACT,0.1899999976158142	CHEMBL1270076,TP,ACT,0.9599999785423279	CHEMBL486487,FP,INACT,0.699999988079071	CHEMBL486285,FP,INACT,0.3799999952316284	CHEMBL1287853,FN,ACT,0.0	CHEMBL1241487,TP,ACT,0.8899999856948853	CHEMBL404178,TN,INACT,0.0	CHEMBL396912,TP,ACT,0.3700000047683716	CHEMBL3797559,TN,INACT,0.25	CHEMBL176815,TN,INACT,0.05999999865889549	CHEMBL1762541,TP,ACT,1.0	CHEMBL2177830,FP,INACT,0.9900000095367432	CHEMBL1241490,TP,ACT,1.0	CHEMBL1270671,TP,ACT,1.0	CHEMBL498404,TP,ACT,1.0	CHEMBL1910762,TN,INACT,0.25	CHEMBL456796,TN,INACT,0.009999999776482582	CHEMBL1762534,TP,ACT,1.0	CHEMBL525538,FP,INACT,0.7799999713897705	CHEMBL241516,TP,ACT,0.8899999856948853	CHEMBL1242568,TP,ACT,0.9900000095367432	CHEMBL1241769,FN,ACT,0.029999999329447746	CHEMBL1242110,TP,ACT,0.8199999928474426	CHEMBL249821,FN,ACT,0.05999999865889549	CHEMBL497454,TN,INACT,0.009999999776482582	CHEMBL557237,TN,INACT,0.11999999731779099	CHEMBL132948,TN,INACT,0.029999999329447746	CHEMBL2164696,TN,INACT,0.0	CHEMBL1081222,TP,ACT,1.0	CHEMBL1270378,TP,ACT,1.0	CHEMBL1079960,FP,INACT,0.8600000143051147	CHEMBL1230790,TP,ACT,0.9700000286102295	CHEMBL470851,FP,INACT,0.5199999809265137	CHEMBL1242209,TP,ACT,0.6299999952316284	CHEMBL558925,TN,INACT,0.0	CHEMBL1762536,TP,ACT,0.9599999785423279	CHEMBL1241948,FP,INACT,0.9599999785423279	CHEMBL3545110,FP,INACT,0.38999998569488525	CHEMBL561136,TN,INACT,0.0	CHEMBL1242026,TP,ACT,1.0	CHEMBL599519,TN,INACT,0.009999999776482582	CHEMBL99699,FP,INACT,0.6399999856948853	CHEMBL515051,TN,INACT,0.009999999776482582	CHEMBL1080359,TP,ACT,1.0	CHEMBL557525,TN,INACT,0.019999999552965164	CHEMBL258435,TP,ACT,0.4099999964237213	CHEMBL1242666,FN,ACT,0.029999999329447746	CHEMBL402933,TP,ACT,1.0	CHEMBL317281,TN,INACT,0.0	CHEMBL2392378,TN,INACT,0.1599999964237213	CHEMBL1242661,FN,ACT,0.0	CHEMBL3356117,FP,INACT,0.3799999952316284	CHEMBL255875,TP,ACT,0.9700000286102295	CHEMBL1762524,TP,ACT,1.0	CHEMBL1287914,TN,INACT,0.009999999776482582	CHEMBL560393,TN,INACT,0.10999999940395355	CHEMBL271179,FN,ACT,0.23999999463558197	CHEMBL2163624,FP,INACT,0.6499999761581421	CHEMBL1242290,TP,ACT,0.9599999785423279	CHEMBL1762521,TP,ACT,0.9599999785423279	CHEMBL488646,TN,INACT,0.029999999329447746	CHEMBL456965,TN,INACT,0.0	CHEMBL551663,FP,INACT,0.8100000023841858	CHEMBL1241684,TN,INACT,0.009999999776482582	CHEMBL2163608,FP,INACT,0.36000001430511475	CHEMBL1241944,TP,ACT,0.7900000214576721	CHEMBL445420,TN,INACT,0.11999999731779099	CHEMBL562198,TN,INACT,0.0	CHEMBL2392227,TN,INACT,0.029999999329447746	CHEMBL3421968,TN,INACT,0.019999999552965164	CHEMBL1241677,FN,ACT,0.019999999552965164	CHEMBL2392390,FP,INACT,0.5099999904632568	CHEMBL485502,TN,INACT,0.029999999329447746	CHEMBL1242376,TP,ACT,0.9900000095367432	CHEMBL1910758,FP,INACT,0.9399999976158142	CHEMBL223360,TP,ACT,0.3100000023841858	CHEMBL404445,TP,ACT,1.0	CHEMBL1806525,FP,INACT,0.6899999976158142	CHEMBL1270874,TP,ACT,1.0	CHEMBL1242749,FN,ACT,0.05999999865889549	CHEMBL1081062,TP,ACT,0.9200000166893005	CHEMBL2392241,TN,INACT,0.0	CHEMBL100312,FP,INACT,0.9300000071525574	CHEMBL522785,FN,ACT,0.0	CHEMBL1922122,TN,INACT,0.03999999910593033	CHEMBL271967,TP,ACT,0.4000000059604645	CHEMBL553,TP,ACT,0.9599999785423279	CHEMBL255947,TP,ACT,1.0	CHEMBL3321812,TP,ACT,0.9700000286102295	CHEMBL1242118,TP,ACT,0.4300000071525574	CHEMBL563281,TN,INACT,0.009999999776482582	CHEMBL456760,TN,INACT,0.05999999865889549	CHEMBL1922120,TN,INACT,0.15000000596046448	CHEMBL3335362,TN,INACT,0.0	CHEMBL574461,TP,ACT,1.0	CHEMBL1242750,TP,ACT,0.47999998927116394	CHEMBL549792,TN,INACT,0.12999999523162842	CHEMBL3648039,FN,ACT,0.05000000074505806	CHEMBL3321800,TP,ACT,0.949999988079071	CHEMBL48614,TN,INACT,0.05000000074505806	CHEMBL457191,TN,INACT,0.0	CHEMBL38380,TN,INACT,0.029999999329447746	CHEMBL1784660,TN,INACT,0.009999999776482582	CHEMBL563948,TN,INACT,0.0	CHEMBL1933806,TN,INACT,0.029999999329447746	CHEMBL489646,FP,INACT,1.0	CHEMBL1762549,TP,ACT,1.0	CHEMBL100675,TN,INACT,0.0	CHEMBL2070409,TN,INACT,0.07000000029802322	CHEMBL2346665,TN,INACT,0.2800000011920929	CHEMBL1081754,FP,INACT,0.38999998569488525	CHEMBL522011,TN,INACT,0.25	

