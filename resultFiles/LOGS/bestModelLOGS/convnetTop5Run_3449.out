ImageNetInceptionV2 CHEMBL3590 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	281
Number of inactive compounds :	281
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3590_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3590_adam_0.0001_15_0.6/
---------------------------------
Training samples: 348
Validation samples: 109
--
Training Step: 1  | time: 50.008s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/348
[A[ATraining Step: 2  | total loss: [1m[32m0.66986[0m[0m | time: 62.262s
[2K
| Adam | epoch: 001 | loss: 0.66986 - acc: 0.3937 -- iter: 064/348
[A[ATraining Step: 3  | total loss: [1m[32m0.64047[0m[0m | time: 136.798s
[2K
| Adam | epoch: 001 | loss: 0.64047 - acc: 0.5830 -- iter: 096/348
[A[ATraining Step: 4  | total loss: [1m[32m0.60806[0m[0m | time: 176.137s
[2K
| Adam | epoch: 001 | loss: 0.60806 - acc: 0.6145 -- iter: 128/348
[A[ATraining Step: 5  | total loss: [1m[32m0.64350[0m[0m | time: 240.551s
[2K
| Adam | epoch: 001 | loss: 0.64350 - acc: 0.6218 -- iter: 160/348
[A[ATraining Step: 6  | total loss: [1m[32m0.60150[0m[0m | time: 281.959s
[2K
| Adam | epoch: 001 | loss: 0.60150 - acc: 0.6238 -- iter: 192/348
[A[ATraining Step: 7  | total loss: [1m[32m0.55904[0m[0m | time: 315.263s
[2K
| Adam | epoch: 001 | loss: 0.55904 - acc: 0.6245 -- iter: 224/348
[A[ATraining Step: 8  | total loss: [1m[32m0.52417[0m[0m | time: 331.648s
[2K
| Adam | epoch: 001 | loss: 0.52417 - acc: 0.7127 -- iter: 256/348
[A[ATraining Step: 9  | total loss: [1m[32m0.45165[0m[0m | time: 355.129s
[2K
| Adam | epoch: 001 | loss: 0.45165 - acc: 0.7986 -- iter: 288/348
[A[ATraining Step: 10  | total loss: [1m[32m0.54001[0m[0m | time: 376.127s
[2K
| Adam | epoch: 001 | loss: 0.54001 - acc: 0.6962 -- iter: 320/348
[A[ATraining Step: 11  | total loss: [1m[32m0.44314[0m[0m | time: 410.834s
[2K
| Adam | epoch: 001 | loss: 0.44314 - acc: 0.7957 | val_loss: 0.89500 - val_acc: 0.4862 -- iter: 348/348
--
Training Step: 12  | total loss: [1m[32m0.49637[0m[0m | time: 19.630s
[2K
| Adam | epoch: 002 | loss: 0.49637 - acc: 0.7430 -- iter: 032/348
[A[ATraining Step: 13  | total loss: [1m[32m0.46824[0m[0m | time: 42.633s
[2K
| Adam | epoch: 002 | loss: 0.46824 - acc: 0.7460 -- iter: 064/348
[A[ATraining Step: 14  | total loss: [1m[32m0.53749[0m[0m | time: 71.593s
[2K
| Adam | epoch: 002 | loss: 0.53749 - acc: 0.7093 -- iter: 096/348
[A[ATraining Step: 15  | total loss: [1m[32m0.46668[0m[0m | time: 88.298s
[2K
| Adam | epoch: 002 | loss: 0.46668 - acc: 0.7619 -- iter: 128/348
[A[ATraining Step: 16  | total loss: [1m[32m0.47303[0m[0m | time: 105.509s
[2K
| Adam | epoch: 002 | loss: 0.47303 - acc: 0.7574 -- iter: 160/348
[A[ATraining Step: 17  | total loss: [1m[32m0.37767[0m[0m | time: 126.181s
[2K
| Adam | epoch: 002 | loss: 0.37767 - acc: 0.8223 -- iter: 192/348
[A[ATraining Step: 18  | total loss: [1m[32m0.33323[0m[0m | time: 157.754s
[2K
| Adam | epoch: 002 | loss: 0.33323 - acc: 0.8622 -- iter: 224/348
[A[ATraining Step: 19  | total loss: [1m[32m0.27540[0m[0m | time: 183.749s
[2K
| Adam | epoch: 002 | loss: 0.27540 - acc: 0.8873 -- iter: 256/348
[A[ATraining Step: 20  | total loss: [1m[32m0.26084[0m[0m | time: 203.721s
[2K
| Adam | epoch: 002 | loss: 0.26084 - acc: 0.8934 -- iter: 288/348
[A[ATraining Step: 21  | total loss: [1m[32m0.28162[0m[0m | time: 222.524s
[2K
| Adam | epoch: 002 | loss: 0.28162 - acc: 0.8683 -- iter: 320/348
[A[ATraining Step: 22  | total loss: [1m[32m0.28699[0m[0m | time: 248.798s
[2K
| Adam | epoch: 002 | loss: 0.28699 - acc: 0.8609 | val_loss: 1.05934 - val_acc: 0.4862 -- iter: 348/348
--
Training Step: 23  | total loss: [1m[32m0.30806[0m[0m | time: 49.176s
[2K
| Adam | epoch: 003 | loss: 0.30806 - acc: 0.8378 -- iter: 032/348
[A[ATraining Step: 24  | total loss: [1m[32m0.31576[0m[0m | time: 75.830s
[2K
| Adam | epoch: 003 | loss: 0.31576 - acc: 0.8633 -- iter: 064/348
[A[ATraining Step: 25  | total loss: [1m[32m0.28362[0m[0m | time: 108.761s
[2K
| Adam | epoch: 003 | loss: 0.28362 - acc: 0.8811 -- iter: 096/348
[A[ATraining Step: 26  | total loss: [1m[32m0.26243[0m[0m | time: 123.290s
[2K
| Adam | epoch: 003 | loss: 0.26243 - acc: 0.8878 -- iter: 128/348
[A[ATraining Step: 27  | total loss: [1m[32m0.23898[0m[0m | time: 149.150s
[2K
| Adam | epoch: 003 | loss: 0.23898 - acc: 0.9086 -- iter: 160/348
[A[ATraining Step: 28  | total loss: [1m[32m0.23776[0m[0m | time: 163.846s
[2K
| Adam | epoch: 003 | loss: 0.23776 - acc: 0.9236 -- iter: 192/348
[A[ATraining Step: 29  | total loss: [1m[32m0.20169[0m[0m | time: 180.699s
[2K
| Adam | epoch: 003 | loss: 0.20169 - acc: 0.9422 -- iter: 224/348
[A[ATraining Step: 30  | total loss: [1m[32m0.17112[0m[0m | time: 200.565s
[2K
| Adam | epoch: 003 | loss: 0.17112 - acc: 0.9559 -- iter: 256/348
[A[ATraining Step: 31  | total loss: [1m[32m0.14902[0m[0m | time: 219.390s
[2K
| Adam | epoch: 003 | loss: 0.14902 - acc: 0.9661 -- iter: 288/348
[A[ATraining Step: 32  | total loss: [1m[32m0.14897[0m[0m | time: 233.995s
[2K
| Adam | epoch: 003 | loss: 0.14897 - acc: 0.9596 -- iter: 320/348
[A[ATraining Step: 33  | total loss: [1m[32m0.13176[0m[0m | time: 260.496s
[2K
| Adam | epoch: 003 | loss: 0.13176 - acc: 0.9616 | val_loss: 1.06056 - val_acc: 0.4862 -- iter: 348/348
--
Training Step: 34  | total loss: [1m[32m0.12716[0m[0m | time: 41.851s
[2K
| Adam | epoch: 004 | loss: 0.12716 - acc: 0.9632 -- iter: 032/348
[A[ATraining Step: 35  | total loss: [1m[32m0.10772[0m[0m | time: 75.137s
[2K
| Adam | epoch: 004 | loss: 0.10772 - acc: 0.9709 -- iter: 064/348
[A[ATraining Step: 36  | total loss: [1m[32m0.09550[0m[0m | time: 89.227s
[2K
| Adam | epoch: 004 | loss: 0.09550 - acc: 0.9768 -- iter: 096/348
[A[ATraining Step: 37  | total loss: [1m[32m0.08081[0m[0m | time: 106.092s
[2K
| Adam | epoch: 004 | loss: 0.08081 - acc: 0.9815 -- iter: 128/348
[A[ATraining Step: 38  | total loss: [1m[32m0.08361[0m[0m | time: 118.203s
[2K
| Adam | epoch: 004 | loss: 0.08361 - acc: 0.9790 -- iter: 160/348
[A[ATraining Step: 39  | total loss: [1m[32m0.07354[0m[0m | time: 130.496s
[2K
| Adam | epoch: 004 | loss: 0.07354 - acc: 0.9830 -- iter: 192/348
[A[ATraining Step: 40  | total loss: [1m[32m0.07130[0m[0m | time: 149.232s
[2K
| Adam | epoch: 004 | loss: 0.07130 - acc: 0.9862 -- iter: 224/348
[A[ATraining Step: 41  | total loss: [1m[32m0.06041[0m[0m | time: 168.920s
[2K
| Adam | epoch: 004 | loss: 0.06041 - acc: 0.9887 -- iter: 256/348
[A[ATraining Step: 42  | total loss: [1m[32m0.05297[0m[0m | time: 183.808s
[2K
| Adam | epoch: 004 | loss: 0.05297 - acc: 0.9908 -- iter: 288/348
[A[ATraining Step: 43  | total loss: [1m[32m0.04659[0m[0m | time: 201.611s
[2K
| Adam | epoch: 004 | loss: 0.04659 - acc: 0.9924 -- iter: 320/348
[A[ATraining Step: 44  | total loss: [1m[32m0.04373[0m[0m | time: 227.793s
[2K
| Adam | epoch: 004 | loss: 0.04373 - acc: 0.9937 | val_loss: 1.35293 - val_acc: 0.4862 -- iter: 348/348
--
Training Step: 45  | total loss: [1m[32m0.03810[0m[0m | time: 42.149s
[2K
| Adam | epoch: 005 | loss: 0.03810 - acc: 0.9948 -- iter: 032/348
[A[ATraining Step: 46  | total loss: [1m[32m0.03521[0m[0m | time: 55.495s
[2K
| Adam | epoch: 005 | loss: 0.03521 - acc: 0.9956 -- iter: 064/348
[A[ATraining Step: 47  | total loss: [1m[32m0.03060[0m[0m | time: 68.469s
[2K
| Adam | epoch: 005 | loss: 0.03060 - acc: 0.9964 -- iter: 096/348
[A[ATraining Step: 48  | total loss: [1m[32m0.03322[0m[0m | time: 83.276s
[2K
| Adam | epoch: 005 | loss: 0.03322 - acc: 0.9969 -- iter: 128/348
[A[ATraining Step: 49  | total loss: [1m[32m0.03053[0m[0m | time: 101.145s
[2K
| Adam | epoch: 005 | loss: 0.03053 - acc: 0.9974 -- iter: 160/348
[A[ATraining Step: 50  | total loss: [1m[32m0.02664[0m[0m | time: 115.751s
[2K
| Adam | epoch: 005 | loss: 0.02664 - acc: 0.9978 -- iter: 192/348
[A[ATraining Step: 51  | total loss: [1m[32m0.02634[0m[0m | time: 132.395s
[2K
| Adam | epoch: 005 | loss: 0.02634 - acc: 0.9982 -- iter: 224/348
[A[ATraining Step: 52  | total loss: [1m[32m0.07582[0m[0m | time: 147.879s
[2K
| Adam | epoch: 005 | loss: 0.07582 - acc: 0.9891 -- iter: 256/348
[A[ATraining Step: 53  | total loss: [1m[32m0.06572[0m[0m | time: 169.372s
[2K
| Adam | epoch: 005 | loss: 0.06572 - acc: 0.9907 -- iter: 288/348
[A[ATraining Step: 54  | total loss: [1m[32m0.05893[0m[0m | time: 186.710s
[2K
| Adam | epoch: 005 | loss: 0.05893 - acc: 0.9920 -- iter: 320/348
[A[ATraining Step: 55  | total loss: [1m[32m0.06638[0m[0m | time: 214.224s
[2K
| Adam | epoch: 005 | loss: 0.06638 - acc: 0.9887 | val_loss: 2.97635 - val_acc: 0.4862 -- iter: 348/348
--
Training Step: 56  | total loss: [1m[32m0.06476[0m[0m | time: 16.071s
[2K
| Adam | epoch: 006 | loss: 0.06476 - acc: 0.9859 -- iter: 032/348
[A[ATraining Step: 57  | total loss: [1m[32m0.05776[0m[0m | time: 28.896s
[2K
| Adam | epoch: 006 | loss: 0.05776 - acc: 0.9878 -- iter: 064/348
[A[ATraining Step: 58  | total loss: [1m[32m0.05210[0m[0m | time: 39.742s
[2K
| Adam | epoch: 006 | loss: 0.05210 - acc: 0.9895 -- iter: 096/348
[A[ATraining Step: 59  | total loss: [1m[32m0.05135[0m[0m | time: 49.242s
[2K
| Adam | epoch: 006 | loss: 0.05135 - acc: 0.9909 -- iter: 128/348
[A[ATraining Step: 60  | total loss: [1m[32m0.04525[0m[0m | time: 60.783s
[2K
| Adam | epoch: 006 | loss: 0.04525 - acc: 0.9921 -- iter: 160/348
[A[ATraining Step: 61  | total loss: [1m[32m0.03967[0m[0m | time: 78.009s
[2K
| Adam | epoch: 006 | loss: 0.03967 - acc: 0.9931 -- iter: 192/348
[A[ATraining Step: 62  | total loss: [1m[32m0.03541[0m[0m | time: 96.202s
[2K
| Adam | epoch: 006 | loss: 0.03541 - acc: 0.9940 -- iter: 224/348
[A[ATraining Step: 63  | total loss: [1m[32m0.03125[0m[0m | time: 112.598s
[2K
| Adam | epoch: 006 | loss: 0.03125 - acc: 0.9948 -- iter: 256/348
[A[ATraining Step: 64  | total loss: [1m[32m0.08305[0m[0m | time: 129.214s
[2K
| Adam | epoch: 006 | loss: 0.08305 - acc: 0.9876 -- iter: 288/348
[A[ATraining Step: 65  | total loss: [1m[32m0.07343[0m[0m | time: 149.088s
[2K
| Adam | epoch: 006 | loss: 0.07343 - acc: 0.9891 -- iter: 320/348
[A[ATraining Step: 66  | total loss: [1m[32m0.06507[0m[0m | time: 177.698s
[2K
| Adam | epoch: 006 | loss: 0.06507 - acc: 0.9905 | val_loss: 0.49096 - val_acc: 0.8440 -- iter: 348/348
--
Training Step: 67  | total loss: [1m[32m0.05833[0m[0m | time: 13.062s
[2K
| Adam | epoch: 007 | loss: 0.05833 - acc: 0.9916 -- iter: 032/348
[A[ATraining Step: 68  | total loss: [1m[32m0.06752[0m[0m | time: 60.258s
[2K
| Adam | epoch: 007 | loss: 0.06752 - acc: 0.9815 -- iter: 064/348
[A[ATraining Step: 69  | total loss: [1m[32m0.06113[0m[0m | time: 74.289s
[2K
| Adam | epoch: 007 | loss: 0.06113 - acc: 0.9837 -- iter: 096/348
[A[ATraining Step: 70  | total loss: [1m[32m0.07148[0m[0m | time: 86.703s
[2K
| Adam | epoch: 007 | loss: 0.07148 - acc: 0.9819 -- iter: 128/348
[A[ATraining Step: 71  | total loss: [1m[32m0.06449[0m[0m | time: 97.470s
[2K
| Adam | epoch: 007 | loss: 0.06449 - acc: 0.9840 -- iter: 160/348
[A[ATraining Step: 72  | total loss: [1m[32m0.05789[0m[0m | time: 108.309s
[2K
| Adam | epoch: 007 | loss: 0.05789 - acc: 0.9858 -- iter: 192/348
[A[ATraining Step: 73  | total loss: [1m[32m0.05207[0m[0m | time: 120.203s
[2K
| Adam | epoch: 007 | loss: 0.05207 - acc: 0.9874 -- iter: 224/348
[A[ATraining Step: 74  | total loss: [1m[32m0.04757[0m[0m | time: 132.346s
[2K
| Adam | epoch: 007 | loss: 0.04757 - acc: 0.9888 -- iter: 256/348
[A[ATraining Step: 75  | total loss: [1m[32m0.04356[0m[0m | time: 144.111s
[2K
| Adam | epoch: 007 | loss: 0.04356 - acc: 0.9900 -- iter: 288/348
[A[ATraining Step: 76  | total loss: [1m[32m0.03969[0m[0m | time: 155.949s
[2K
| Adam | epoch: 007 | loss: 0.03969 - acc: 0.9911 -- iter: 320/348
[A[ATraining Step: 77  | total loss: [1m[32m0.03913[0m[0m | time: 175.963s
[2K
| Adam | epoch: 007 | loss: 0.03913 - acc: 0.9920 | val_loss: 1.34151 - val_acc: 0.6789 -- iter: 348/348
--
Training Step: 78  | total loss: [1m[32m0.03560[0m[0m | time: 8.252s
[2K
| Adam | epoch: 008 | loss: 0.03560 - acc: 0.9928 -- iter: 032/348
[A[ATraining Step: 79  | total loss: [1m[32m0.03788[0m[0m | time: 16.518s
[2K
| Adam | epoch: 008 | loss: 0.03788 - acc: 0.9903 -- iter: 064/348
[A[ATraining Step: 80  | total loss: [1m[32m0.03580[0m[0m | time: 28.392s
[2K
| Adam | epoch: 008 | loss: 0.03580 - acc: 0.9913 -- iter: 096/348
[A[ATraining Step: 81  | total loss: [1m[32m0.03262[0m[0m | time: 40.805s
[2K
| Adam | epoch: 008 | loss: 0.03262 - acc: 0.9922 -- iter: 128/348
[A[ATraining Step: 82  | total loss: [1m[32m0.02979[0m[0m | time: 52.844s
[2K
| Adam | epoch: 008 | loss: 0.02979 - acc: 0.9930 -- iter: 160/348
[A[ATraining Step: 83  | total loss: [1m[32m0.02990[0m[0m | time: 63.586s
[2K
| Adam | epoch: 008 | loss: 0.02990 - acc: 0.9937 -- iter: 192/348
[A[ATraining Step: 84  | total loss: [1m[32m0.02752[0m[0m | time: 74.781s
[2K
| Adam | epoch: 008 | loss: 0.02752 - acc: 0.9943 -- iter: 224/348
[A[ATraining Step: 85  | total loss: [1m[32m0.02536[0m[0m | time: 87.021s
[2K
| Adam | epoch: 008 | loss: 0.02536 - acc: 0.9949 -- iter: 256/348
[A[ATraining Step: 86  | total loss: [1m[32m0.02322[0m[0m | time: 99.214s
[2K
| Adam | epoch: 008 | loss: 0.02322 - acc: 0.9954 -- iter: 288/348
[A[ATraining Step: 87  | total loss: [1m[32m0.02178[0m[0m | time: 110.537s
[2K
| Adam | epoch: 008 | loss: 0.02178 - acc: 0.9959 -- iter: 320/348
[A[ATraining Step: 88  | total loss: [1m[32m0.05818[0m[0m | time: 135.791s
[2K
| Adam | epoch: 008 | loss: 0.05818 - acc: 0.9900 | val_loss: 1.82435 - val_acc: 0.6789 -- iter: 348/348
--
Training Step: 89  | total loss: [1m[32m0.05303[0m[0m | time: 10.346s
[2K
| Adam | epoch: 009 | loss: 0.05303 - acc: 0.9910 -- iter: 032/348
[A[ATraining Step: 90  | total loss: [1m[32m0.04834[0m[0m | time: 22.231s
[2K
| Adam | epoch: 009 | loss: 0.04834 - acc: 0.9919 -- iter: 064/348
[A[ATraining Step: 91  | total loss: [1m[32m0.04446[0m[0m | time: 34.376s
[2K
| Adam | epoch: 009 | loss: 0.04446 - acc: 0.9927 -- iter: 096/348
[A[ATraining Step: 92  | total loss: [1m[32m0.04037[0m[0m | time: 46.528s
[2K
| Adam | epoch: 009 | loss: 0.04037 - acc: 0.9935 -- iter: 128/348
[A[ATraining Step: 93  | total loss: [1m[32m0.03654[0m[0m | time: 58.796s
[2K
| Adam | epoch: 009 | loss: 0.03654 - acc: 0.9941 -- iter: 160/348
[A[ATraining Step: 94  | total loss: [1m[32m0.03317[0m[0m | time: 70.829s
[2K
| Adam | epoch: 009 | loss: 0.03317 - acc: 0.9947 -- iter: 192/348
[A[ATraining Step: 95  | total loss: [1m[32m0.06620[0m[0m | time: 81.596s
[2K
| Adam | epoch: 009 | loss: 0.06620 - acc: 0.9921 -- iter: 224/348
[A[ATraining Step: 96  | total loss: [1m[32m0.05984[0m[0m | time: 92.112s
[2K
| Adam | epoch: 009 | loss: 0.05984 - acc: 0.9929 -- iter: 256/348
[A[ATraining Step: 97  | total loss: [1m[32m0.05414[0m[0m | time: 104.168s
[2K
| Adam | epoch: 009 | loss: 0.05414 - acc: 0.9936 -- iter: 288/348
[A[ATraining Step: 98  | total loss: [1m[32m0.04982[0m[0m | time: 119.016s
[2K
| Adam | epoch: 009 | loss: 0.04982 - acc: 0.9942 -- iter: 320/348
[A[ATraining Step: 99  | total loss: [1m[32m0.04553[0m[0m | time: 139.260s
[2K
| Adam | epoch: 009 | loss: 0.04553 - acc: 0.9948 | val_loss: 1.54316 - val_acc: 0.6972 -- iter: 348/348
--
Training Step: 100  | total loss: [1m[32m0.10045[0m[0m | time: 8.375s
[2K
| Adam | epoch: 010 | loss: 0.10045 - acc: 0.9891 -- iter: 032/348
[A[ATraining Step: 101  | total loss: [1m[32m0.09452[0m[0m | time: 20.915s
[2K
| Adam | epoch: 010 | loss: 0.09452 - acc: 0.9871 -- iter: 064/348
[A[ATraining Step: 102  | total loss: [1m[32m0.08721[0m[0m | time: 32.753s
[2K
| Adam | epoch: 010 | loss: 0.08721 - acc: 0.9883 -- iter: 096/348
[A[ATraining Step: 103  | total loss: [1m[32m0.07892[0m[0m | time: 44.663s
[2K
| Adam | epoch: 010 | loss: 0.07892 - acc: 0.9895 -- iter: 128/348
[A[ATraining Step: 104  | total loss: [1m[32m0.07459[0m[0m | time: 56.169s
[2K
| Adam | epoch: 010 | loss: 0.07459 - acc: 0.9906 -- iter: 160/348
[A[ATraining Step: 105  | total loss: [1m[32m0.06743[0m[0m | time: 68.230s
[2K
| Adam | epoch: 010 | loss: 0.06743 - acc: 0.9915 -- iter: 192/348
[A[ATraining Step: 106  | total loss: [1m[32m0.06097[0m[0m | time: 80.305s
[2K
| Adam | epoch: 010 | loss: 0.06097 - acc: 0.9924 -- iter: 224/348
[A[ATraining Step: 107  | total loss: [1m[32m0.05531[0m[0m | time: 91.439s
[2K
| Adam | epoch: 010 | loss: 0.05531 - acc: 0.9931 -- iter: 256/348
[A[ATraining Step: 108  | total loss: [1m[32m0.07129[0m[0m | time: 102.399s
[2K
| Adam | epoch: 010 | loss: 0.07129 - acc: 0.9902 -- iter: 288/348
[A[ATraining Step: 109  | total loss: [1m[32m0.07835[0m[0m | time: 114.072s
[2K
| Adam | epoch: 010 | loss: 0.07835 - acc: 0.9876 -- iter: 320/348
[A[ATraining Step: 110  | total loss: [1m[32m0.07116[0m[0m | time: 138.350s
[2K
| Adam | epoch: 010 | loss: 0.07116 - acc: 0.9889 | val_loss: 0.98616 - val_acc: 0.7798 -- iter: 348/348
--
Training Step: 111  | total loss: [1m[32m0.07023[0m[0m | time: 10.719s
[2K
| Adam | epoch: 011 | loss: 0.07023 - acc: 0.9869 -- iter: 032/348
[A[ATraining Step: 112  | total loss: [1m[32m0.07043[0m[0m | time: 22.792s
[2K
| Adam | epoch: 011 | loss: 0.07043 - acc: 0.9851 -- iter: 064/348
[A[ATraining Step: 113  | total loss: [1m[32m0.06419[0m[0m | time: 34.421s
[2K
| Adam | epoch: 011 | loss: 0.06419 - acc: 0.9865 -- iter: 096/348
[A[ATraining Step: 114  | total loss: [1m[32m0.06979[0m[0m | time: 46.394s
[2K
| Adam | epoch: 011 | loss: 0.06979 - acc: 0.9816 -- iter: 128/348
[A[ATraining Step: 115  | total loss: [1m[32m0.06497[0m[0m | time: 58.242s
[2K
| Adam | epoch: 011 | loss: 0.06497 - acc: 0.9835 -- iter: 160/348
[A[ATraining Step: 116  | total loss: [1m[32m0.05948[0m[0m | time: 70.159s
[2K
| Adam | epoch: 011 | loss: 0.05948 - acc: 0.9851 -- iter: 192/348
[A[ATraining Step: 117  | total loss: [1m[32m0.05469[0m[0m | time: 82.383s
[2K
| Adam | epoch: 011 | loss: 0.05469 - acc: 0.9866 -- iter: 224/348
[A[ATraining Step: 118  | total loss: [1m[32m0.05657[0m[0m | time: 94.048s
[2K
| Adam | epoch: 011 | loss: 0.05657 - acc: 0.9848 -- iter: 256/348
[A[ATraining Step: 119  | total loss: [1m[32m0.05174[0m[0m | time: 105.427s
[2K
| Adam | epoch: 011 | loss: 0.05174 - acc: 0.9863 -- iter: 288/348
[A[ATraining Step: 120  | total loss: [1m[32m0.04817[0m[0m | time: 116.412s
[2K
| Adam | epoch: 011 | loss: 0.04817 - acc: 0.9877 -- iter: 320/348
[A[ATraining Step: 121  | total loss: [1m[32m0.04446[0m[0m | time: 137.222s
[2K
| Adam | epoch: 011 | loss: 0.04446 - acc: 0.9889 | val_loss: 1.04764 - val_acc: 0.7431 -- iter: 348/348
--
Training Step: 122  | total loss: [1m[32m0.04796[0m[0m | time: 8.270s
[2K
| Adam | epoch: 012 | loss: 0.04796 - acc: 0.9869 -- iter: 032/348
[A[ATraining Step: 123  | total loss: [1m[32m0.04735[0m[0m | time: 16.443s
[2K
| Adam | epoch: 012 | loss: 0.04735 - acc: 0.9882 -- iter: 064/348
[A[ATraining Step: 124  | total loss: [1m[32m0.06214[0m[0m | time: 27.378s
[2K
| Adam | epoch: 012 | loss: 0.06214 - acc: 0.9863 -- iter: 096/348
[A[ATraining Step: 125  | total loss: [1m[32m0.05755[0m[0m | time: 45.480s
[2K
| Adam | epoch: 012 | loss: 0.05755 - acc: 0.9877 -- iter: 128/348
[A[ATraining Step: 126  | total loss: [1m[32m0.05259[0m[0m | time: 54.850s
[2K
| Adam | epoch: 012 | loss: 0.05259 - acc: 0.9889 -- iter: 160/348
[A[ATraining Step: 127  | total loss: [1m[32m0.04789[0m[0m | time: 63.172s
[2K
| Adam | epoch: 012 | loss: 0.04789 - acc: 0.9900 -- iter: 192/348
[A[ATraining Step: 128  | total loss: [1m[32m0.04526[0m[0m | time: 71.210s
[2K
| Adam | epoch: 012 | loss: 0.04526 - acc: 0.9910 -- iter: 224/348
[A[ATraining Step: 129  | total loss: [1m[32m0.07255[0m[0m | time: 79.361s
[2K
| Adam | epoch: 012 | loss: 0.07255 - acc: 0.9856 -- iter: 256/348
[A[ATraining Step: 130  | total loss: [1m[32m0.06558[0m[0m | time: 87.369s
[2K
| Adam | epoch: 012 | loss: 0.06558 - acc: 0.9871 -- iter: 288/348
[A[ATraining Step: 131  | total loss: [1m[32m0.06249[0m[0m | time: 94.739s
[2K
| Adam | epoch: 012 | loss: 0.06249 - acc: 0.9853 -- iter: 320/348
[A[ATraining Step: 132  | total loss: [1m[32m0.05664[0m[0m | time: 107.017s
[2K
| Adam | epoch: 012 | loss: 0.05664 - acc: 0.9867 | val_loss: 0.34827 - val_acc: 0.8899 -- iter: 348/348
--
Training Step: 133  | total loss: [1m[32m0.05141[0m[0m | time: 8.002s
[2K
| Adam | epoch: 013 | loss: 0.05141 - acc: 0.9881 -- iter: 032/348
[A[ATraining Step: 134  | total loss: [1m[32m0.04824[0m[0m | time: 16.092s
[2K
| Adam | epoch: 013 | loss: 0.04824 - acc: 0.9892 -- iter: 064/348
[A[ATraining Step: 135  | total loss: [1m[32m0.04421[0m[0m | time: 24.038s
[2K
| Adam | epoch: 013 | loss: 0.04421 - acc: 0.9903 -- iter: 096/348
[A[ATraining Step: 136  | total loss: [1m[32m0.04088[0m[0m | time: 32.075s
[2K
| Adam | epoch: 013 | loss: 0.04088 - acc: 0.9913 -- iter: 128/348
[A[ATraining Step: 137  | total loss: [1m[32m0.03725[0m[0m | time: 40.043s
[2K
| Adam | epoch: 013 | loss: 0.03725 - acc: 0.9922 -- iter: 160/348
[A[ATraining Step: 138  | total loss: [1m[32m0.03381[0m[0m | time: 48.219s
[2K
| Adam | epoch: 013 | loss: 0.03381 - acc: 0.9929 -- iter: 192/348
[A[ATraining Step: 139  | total loss: [1m[32m0.03089[0m[0m | time: 56.330s
[2K
| Adam | epoch: 013 | loss: 0.03089 - acc: 0.9937 -- iter: 224/348
[A[ATraining Step: 140  | total loss: [1m[32m0.02844[0m[0m | time: 64.425s
[2K
| Adam | epoch: 013 | loss: 0.02844 - acc: 0.9943 -- iter: 256/348
[A[ATraining Step: 141  | total loss: [1m[32m0.02586[0m[0m | time: 72.661s
[2K
| Adam | epoch: 013 | loss: 0.02586 - acc: 0.9949 -- iter: 288/348
[A[ATraining Step: 142  | total loss: [1m[32m0.02472[0m[0m | time: 80.704s
[2K
| Adam | epoch: 013 | loss: 0.02472 - acc: 0.9954 -- iter: 320/348
[A[ATraining Step: 143  | total loss: [1m[32m0.02253[0m[0m | time: 92.932s
[2K
| Adam | epoch: 013 | loss: 0.02253 - acc: 0.9958 | val_loss: 0.51990 - val_acc: 0.8165 -- iter: 348/348
--
Training Step: 144  | total loss: [1m[32m0.02080[0m[0m | time: 7.497s
[2K
| Adam | epoch: 014 | loss: 0.02080 - acc: 0.9963 -- iter: 032/348
[A[ATraining Step: 145  | total loss: [1m[32m0.01921[0m[0m | time: 15.356s
[2K
| Adam | epoch: 014 | loss: 0.01921 - acc: 0.9966 -- iter: 064/348
[A[ATraining Step: 146  | total loss: [1m[32m0.01754[0m[0m | time: 23.520s
[2K
| Adam | epoch: 014 | loss: 0.01754 - acc: 0.9970 -- iter: 096/348
[A[ATraining Step: 147  | total loss: [1m[32m0.01643[0m[0m | time: 31.522s
[2K
| Adam | epoch: 014 | loss: 0.01643 - acc: 0.9973 -- iter: 128/348
[A[ATraining Step: 148  | total loss: [1m[32m0.07348[0m[0m | time: 39.501s
[2K
| Adam | epoch: 014 | loss: 0.07348 - acc: 0.9913 -- iter: 160/348
[A[ATraining Step: 149  | total loss: [1m[32m0.06646[0m[0m | time: 47.460s
[2K
| Adam | epoch: 014 | loss: 0.06646 - acc: 0.9922 -- iter: 192/348
[A[ATraining Step: 150  | total loss: [1m[32m0.06015[0m[0m | time: 55.554s
[2K
| Adam | epoch: 014 | loss: 0.06015 - acc: 0.9929 -- iter: 224/348
[A[ATraining Step: 151  | total loss: [1m[32m0.05478[0m[0m | time: 63.704s
[2K
| Adam | epoch: 014 | loss: 0.05478 - acc: 0.9937 -- iter: 256/348
[A[ATraining Step: 152  | total loss: [1m[32m0.04979[0m[0m | time: 71.674s
[2K
| Adam | epoch: 014 | loss: 0.04979 - acc: 0.9943 -- iter: 288/348
[A[ATraining Step: 153  | total loss: [1m[32m0.04889[0m[0m | time: 79.555s
[2K
| Adam | epoch: 014 | loss: 0.04889 - acc: 0.9917 -- iter: 320/348
[A[ATraining Step: 154  | total loss: [1m[32m0.04421[0m[0m | time: 92.708s
[2K
| Adam | epoch: 014 | loss: 0.04421 - acc: 0.9926 | val_loss: 0.66848 - val_acc: 0.7798 -- iter: 348/348
--
Training Step: 155  | total loss: [1m[32m0.04007[0m[0m | time: 7.282s
[2K
| Adam | epoch: 015 | loss: 0.04007 - acc: 0.9933 -- iter: 032/348
[A[ATraining Step: 156  | total loss: [1m[32m0.03627[0m[0m | time: 14.596s
[2K
| Adam | epoch: 015 | loss: 0.03627 - acc: 0.9940 -- iter: 064/348
[A[ATraining Step: 157  | total loss: [1m[32m0.03289[0m[0m | time: 22.647s
[2K
| Adam | epoch: 015 | loss: 0.03289 - acc: 0.9946 -- iter: 096/348
[A[ATraining Step: 158  | total loss: [1m[32m0.02979[0m[0m | time: 30.638s
[2K
| Adam | epoch: 015 | loss: 0.02979 - acc: 0.9951 -- iter: 128/348
[A[ATraining Step: 159  | total loss: [1m[32m0.03171[0m[0m | time: 38.556s
[2K
| Adam | epoch: 015 | loss: 0.03171 - acc: 0.9925 -- iter: 160/348
[A[ATraining Step: 160  | total loss: [1m[32m0.04624[0m[0m | time: 46.765s
[2K
| Adam | epoch: 015 | loss: 0.04624 - acc: 0.9901 -- iter: 192/348
[A[ATraining Step: 161  | total loss: [1m[32m0.04193[0m[0m | time: 54.941s
[2K
| Adam | epoch: 015 | loss: 0.04193 - acc: 0.9911 -- iter: 224/348
[A[ATraining Step: 162  | total loss: [1m[32m0.03796[0m[0m | time: 63.084s
[2K
| Adam | epoch: 015 | loss: 0.03796 - acc: 0.9920 -- iter: 256/348
[A[ATraining Step: 163  | total loss: [1m[32m0.03458[0m[0m | time: 71.219s
[2K
| Adam | epoch: 015 | loss: 0.03458 - acc: 0.9928 -- iter: 288/348
[A[ATraining Step: 164  | total loss: [1m[32m0.03148[0m[0m | time: 79.429s
[2K
| Adam | epoch: 015 | loss: 0.03148 - acc: 0.9935 -- iter: 320/348
[A[ATraining Step: 165  | total loss: [1m[32m0.02865[0m[0m | time: 92.509s
[2K
| Adam | epoch: 015 | loss: 0.02865 - acc: 0.9942 | val_loss: 0.63376 - val_acc: 0.8349 -- iter: 348/348
--
Validation AUC:0.9056603773584906
Validation AUPRC:0.925424687765857
Test AUC:0.902020202020202
Test AUPRC:0.8947820142800843
BestTestF1Score	0.82	0.63	0.82	0.8	0.83	45	11	44	9	0.25
BestTestMCCScore	0.81	0.63	0.82	0.84	0.78	42	8	47	12	0.46
BestTestAccuracyScore	0.81	0.63	0.82	0.84	0.78	42	8	47	12	0.46
BestValidationF1Score	0.84	0.71	0.85	0.88	0.81	43	6	50	10	0.25
BestValidationMCC	0.83	0.72	0.85	0.95	0.74	39	2	54	14	0.46
BestValidationAccuracy	0.83	0.72	0.85	0.95	0.74	39	2	54	14	0.46
TestPredictions (Threshold:0.46)
CHEMBL3260555,TN,INACT,0.009999999776482582	CHEMBL3640203,FN,ACT,0.44999998807907104	CHEMBL110716,TP,ACT,0.8899999856948853	CHEMBL343365,FP,INACT,0.7200000286102295	CHEMBL334395,FN,ACT,0.14000000059604645	CHEMBL517605,TN,INACT,0.05999999865889549	CHEMBL50178,TP,ACT,0.9700000286102295	CHEMBL3337471,TN,INACT,0.17000000178813934	CHEMBL1773482,TN,INACT,0.05000000074505806	CHEMBL3127383,TN,INACT,0.009999999776482582	CHEMBL3770071,TN,INACT,0.0	CHEMBL1594358,TN,INACT,0.0	CHEMBL3260177,TN,INACT,0.0	CHEMBL109116,TP,ACT,0.9599999785423279	CHEMBL241960,TN,INACT,0.0	CHEMBL3764900,TN,INACT,0.0	CHEMBL3640190,TP,ACT,0.949999988079071	CHEMBL110763,TP,ACT,0.7300000190734863	CHEMBL238085,TP,ACT,0.9900000095367432	CHEMBL1773486,TN,INACT,0.009999999776482582	CHEMBL378404,FP,INACT,0.7200000286102295	CHEMBL591232,TN,INACT,0.0	CHEMBL106314,TP,ACT,0.8600000143051147	CHEMBL3643713,TP,ACT,0.9599999785423279	CHEMBL3643704,TP,ACT,0.8500000238418579	CHEMBL3237537,TN,INACT,0.0	CHEMBL105834,TP,ACT,0.6700000166893005	CHEMBL110597,TP,ACT,0.949999988079071	CHEMBL324436,TP,ACT,0.9700000286102295	CHEMBL49896,TP,ACT,1.0	CHEMBL3674439,TP,ACT,1.0	CHEMBL3674445,TP,ACT,0.9599999785423279	CHEMBL322051,TP,ACT,0.9900000095367432	CHEMBL2396908,FP,INACT,0.9700000286102295	CHEMBL3770206,TN,INACT,0.0	CHEMBL118139,TN,INACT,0.0	CHEMBL3605418,TN,INACT,0.0	CHEMBL1912064,FP,INACT,0.800000011920929	CHEMBL3674465,TP,ACT,1.0	CHEMBL390809,TN,INACT,0.0	CHEMBL106420,TP,ACT,0.5	CHEMBL235761,FN,ACT,0.019999999552965164	CHEMBL3640208,TP,ACT,1.0	CHEMBL3643711,TP,ACT,0.8899999856948853	CHEMBL236173,FN,ACT,0.009999999776482582	CHEMBL3605419,TN,INACT,0.0	CHEMBL108326,FN,ACT,0.17000000178813934	CHEMBL2160217,TN,INACT,0.0	CHEMBL3674443,TP,ACT,1.0	CHEMBL117447,TN,INACT,0.0	CHEMBL3339003,TN,INACT,0.25	CHEMBL3674461,TP,ACT,0.9900000095367432	CHEMBL278020,FP,INACT,0.4699999988079071	CHEMBL97501,FP,INACT,0.949999988079071	CHEMBL3639733,TP,ACT,0.949999988079071	CHEMBL45985,TP,ACT,0.9900000095367432	CHEMBL561846,TN,INACT,0.0	CHEMBL3674455,TP,ACT,1.0	CHEMBL3260182,FP,INACT,0.6399999856948853	CHEMBL3674451,TP,ACT,0.9900000095367432	CHEMBL2160225,TN,INACT,0.0	CHEMBL316549,TP,ACT,0.7300000190734863	CHEMBL97145,FP,INACT,0.9900000095367432	CHEMBL119528,TN,INACT,0.0	CHEMBL1940615,TN,INACT,0.019999999552965164	CHEMBL491526,TN,INACT,0.0	CHEMBL222795,TN,INACT,0.25	CHEMBL223000,TN,INACT,0.009999999776482582	CHEMBL262299,TN,INACT,0.14000000059604645	CHEMBL48254,TP,ACT,0.5199999809265137	CHEMBL556939,TN,INACT,0.0	CHEMBL3339006,TN,INACT,0.0	CHEMBL3690093,TP,ACT,0.7900000214576721	CHEMBL3690098,TP,ACT,1.0	CHEMBL45570,FN,ACT,0.0	CHEMBL322780,TP,ACT,0.6100000143051147	CHEMBL3763832,TN,INACT,0.0	CHEMBL563968,TN,INACT,0.0	CHEMBL225366,TN,INACT,0.019999999552965164	CHEMBL453096,TN,INACT,0.0	CHEMBL320000,TN,INACT,0.17000000178813934	CHEMBL3640182,TP,ACT,0.7699999809265137	CHEMBL238571,FN,ACT,0.23999999463558197	CHEMBL323458,TP,ACT,0.8999999761581421	CHEMBL49628,FN,ACT,0.44999998807907104	CHEMBL3393679,TN,INACT,0.0	CHEMBL1773484,TN,INACT,0.07000000029802322	CHEMBL1761993,TN,INACT,0.0	CHEMBL110935,TP,ACT,0.46000000834465027	CHEMBL321903,FN,ACT,0.05000000074505806	CHEMBL3674476,TP,ACT,0.9700000286102295	CHEMBL3643718,FN,ACT,0.4300000071525574	CHEMBL1327885,TN,INACT,0.0	CHEMBL3690100,TP,ACT,0.7900000214576721	CHEMBL375304,TN,INACT,0.009999999776482582	CHEMBL206093,TN,INACT,0.17000000178813934	CHEMBL2158994,TN,INACT,0.1599999964237213	CHEMBL337714,FN,ACT,0.10999999940395355	CHEMBL130645,TP,ACT,0.9900000095367432	CHEMBL3674454,TP,ACT,1.0	CHEMBL575830,TN,INACT,0.0	CHEMBL3640199,TP,ACT,1.0	CHEMBL3277220,TN,INACT,0.4300000071525574	CHEMBL320525,TP,ACT,0.949999988079071	CHEMBL3674456,TP,ACT,1.0	CHEMBL45629,FN,ACT,0.09000000357627869	CHEMBL3289924,TN,INACT,0.0	CHEMBL323173,TP,ACT,0.949999988079071	CHEMBL7976,TN,INACT,0.0	

