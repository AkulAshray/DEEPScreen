ImageNetInceptionV2 CHEMBL5141 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	131
Number of inactive compounds :	131
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5141_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5141_adam_0.0005_15_0.6/
---------------------------------
Training samples: 167
Validation samples: 53
--
Training Step: 1  | time: 212.443s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/167
[A[ATraining Step: 2  | total loss: [1m[32m0.62840[0m[0m | time: 414.886s
[2K
| Adam | epoch: 001 | loss: 0.62840 - acc: 0.4219 -- iter: 064/167
[A[ATraining Step: 3  | total loss: [1m[32m0.71155[0m[0m | time: 644.775s
[2K
| Adam | epoch: 001 | loss: 0.71155 - acc: 0.4602 -- iter: 096/167
[A[ATraining Step: 4  | total loss: [1m[32m0.81444[0m[0m | time: 813.833s
[2K
| Adam | epoch: 001 | loss: 0.81444 - acc: 0.4197 -- iter: 128/167
[A[ATraining Step: 5  | total loss: [1m[32m0.79575[0m[0m | time: 899.026s
[2K
| Adam | epoch: 001 | loss: 0.79575 - acc: 0.5186 -- iter: 160/167
[A[ATraining Step: 6  | total loss: [1m[32m0.66678[0m[0m | time: 912.082s
[2K
| Adam | epoch: 001 | loss: 0.66678 - acc: 0.6272 | val_loss: 0.69944 - val_acc: 0.4717 -- iter: 167/167
--
Training Step: 7  | total loss: [1m[32m0.58278[0m[0m | time: 3.899s
[2K
| Adam | epoch: 002 | loss: 0.58278 - acc: 0.6794 -- iter: 032/167
[A[ATraining Step: 8  | total loss: [1m[32m0.33617[0m[0m | time: 109.024s
[2K
| Adam | epoch: 002 | loss: 0.33617 - acc: 0.8598 -- iter: 064/167
[A[ATraining Step: 9  | total loss: [1m[32m0.39059[0m[0m | time: 158.128s
[2K
| Adam | epoch: 002 | loss: 0.39059 - acc: 0.8347 -- iter: 096/167
[A[ATraining Step: 10  | total loss: [1m[32m0.41512[0m[0m | time: 209.692s
[2K
| Adam | epoch: 002 | loss: 0.41512 - acc: 0.8080 -- iter: 128/167
[A[ATraining Step: 11  | total loss: [1m[32m0.40331[0m[0m | time: 260.052s
[2K
| Adam | epoch: 002 | loss: 0.40331 - acc: 0.8249 -- iter: 160/167
[A[ATraining Step: 12  | total loss: [1m[32m0.38083[0m[0m | time: 295.794s
[2K
| Adam | epoch: 002 | loss: 0.38083 - acc: 0.8334 | val_loss: 0.77660 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 13  | total loss: [1m[32m0.32672[0m[0m | time: 3.828s
[2K
| Adam | epoch: 003 | loss: 0.32672 - acc: 0.8646 -- iter: 032/167
[A[ATraining Step: 14  | total loss: [1m[32m0.34712[0m[0m | time: 7.160s
[2K
| Adam | epoch: 003 | loss: 0.34712 - acc: 0.8616 -- iter: 064/167
[A[ATraining Step: 15  | total loss: [1m[32m0.23406[0m[0m | time: 45.021s
[2K
| Adam | epoch: 003 | loss: 0.23406 - acc: 0.9157 -- iter: 096/167
[A[ATraining Step: 16  | total loss: [1m[32m0.21885[0m[0m | time: 105.664s
[2K
| Adam | epoch: 003 | loss: 0.21885 - acc: 0.9239 -- iter: 128/167
[A[ATraining Step: 17  | total loss: [1m[32m0.17891[0m[0m | time: 142.404s
[2K
| Adam | epoch: 003 | loss: 0.17891 - acc: 0.9400 -- iter: 160/167
[A[ATraining Step: 18  | total loss: [1m[32m0.19663[0m[0m | time: 165.043s
[2K
| Adam | epoch: 003 | loss: 0.19663 - acc: 0.9392 | val_loss: 0.78011 - val_acc: 0.4717 -- iter: 167/167
--
Training Step: 19  | total loss: [1m[32m0.21588[0m[0m | time: 22.228s
[2K
| Adam | epoch: 004 | loss: 0.21588 - acc: 0.9490 -- iter: 032/167
[A[ATraining Step: 20  | total loss: [1m[32m0.18526[0m[0m | time: 25.854s
[2K
| Adam | epoch: 004 | loss: 0.18526 - acc: 0.9554 -- iter: 064/167
[A[ATraining Step: 21  | total loss: [1m[32m0.21726[0m[0m | time: 29.647s
[2K
| Adam | epoch: 004 | loss: 0.21726 - acc: 0.8805 -- iter: 096/167
[A[ATraining Step: 22  | total loss: [1m[32m0.16318[0m[0m | time: 65.709s
[2K
| Adam | epoch: 004 | loss: 0.16318 - acc: 0.9164 -- iter: 128/167
[A[ATraining Step: 23  | total loss: [1m[32m0.15444[0m[0m | time: 84.170s
[2K
| Adam | epoch: 004 | loss: 0.15444 - acc: 0.9225 -- iter: 160/167
[A[ATraining Step: 24  | total loss: [1m[32m0.12192[0m[0m | time: 99.774s
[2K
| Adam | epoch: 004 | loss: 0.12192 - acc: 0.9443 | val_loss: 0.76341 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 25  | total loss: [1m[32m0.09782[0m[0m | time: 62.149s
[2K
| Adam | epoch: 005 | loss: 0.09782 - acc: 0.9595 -- iter: 032/167
[A[ATraining Step: 26  | total loss: [1m[32m0.09529[0m[0m | time: 74.322s
[2K
| Adam | epoch: 005 | loss: 0.09529 - acc: 0.9619 -- iter: 064/167
[A[ATraining Step: 27  | total loss: [1m[32m0.07704[0m[0m | time: 78.378s
[2K
| Adam | epoch: 005 | loss: 0.07704 - acc: 0.9717 -- iter: 096/167
[A[ATraining Step: 28  | total loss: [1m[32m0.05935[0m[0m | time: 81.697s
[2K
| Adam | epoch: 005 | loss: 0.05935 - acc: 0.9788 -- iter: 128/167
[A[ATraining Step: 29  | total loss: [1m[32m0.04599[0m[0m | time: 124.921s
[2K
| Adam | epoch: 005 | loss: 0.04599 - acc: 0.9840 -- iter: 160/167
[A[ATraining Step: 30  | total loss: [1m[32m0.03810[0m[0m | time: 178.592s
[2K
| Adam | epoch: 005 | loss: 0.03810 - acc: 0.9878 | val_loss: 0.72357 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 31  | total loss: [1m[32m0.07140[0m[0m | time: 15.592s
[2K
| Adam | epoch: 006 | loss: 0.07140 - acc: 0.9834 -- iter: 032/167
[A[ATraining Step: 32  | total loss: [1m[32m0.05858[0m[0m | time: 54.277s
[2K
| Adam | epoch: 006 | loss: 0.05858 - acc: 0.9871 -- iter: 064/167
[A[ATraining Step: 33  | total loss: [1m[32m0.08085[0m[0m | time: 97.146s
[2K
| Adam | epoch: 006 | loss: 0.08085 - acc: 0.9831 -- iter: 096/167
[A[ATraining Step: 34  | total loss: [1m[32m0.06497[0m[0m | time: 101.622s
[2K
| Adam | epoch: 006 | loss: 0.06497 - acc: 0.9867 -- iter: 128/167
[A[ATraining Step: 35  | total loss: [1m[32m0.05493[0m[0m | time: 106.343s
[2K
| Adam | epoch: 006 | loss: 0.05493 - acc: 0.9895 -- iter: 160/167
[A[ATraining Step: 36  | total loss: [1m[32m0.04426[0m[0m | time: 136.706s
[2K
| Adam | epoch: 006 | loss: 0.04426 - acc: 0.9916 | val_loss: 1.04680 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 37  | total loss: [1m[32m0.03621[0m[0m | time: 41.050s
[2K
| Adam | epoch: 007 | loss: 0.03621 - acc: 0.9933 -- iter: 032/167
[A[ATraining Step: 38  | total loss: [1m[32m0.07257[0m[0m | time: 96.779s
[2K
| Adam | epoch: 007 | loss: 0.07257 - acc: 0.9885 -- iter: 064/167
[A[ATraining Step: 39  | total loss: [1m[32m0.06442[0m[0m | time: 112.280s
[2K
| Adam | epoch: 007 | loss: 0.06442 - acc: 0.9907 -- iter: 096/167
[A[ATraining Step: 40  | total loss: [1m[32m0.05575[0m[0m | time: 141.282s
[2K
| Adam | epoch: 007 | loss: 0.05575 - acc: 0.9924 -- iter: 128/167
[A[ATraining Step: 41  | total loss: [1m[32m0.09329[0m[0m | time: 146.254s
[2K
| Adam | epoch: 007 | loss: 0.09329 - acc: 0.9824 -- iter: 160/167
[A[ATraining Step: 42  | total loss: [1m[32m0.07781[0m[0m | time: 155.880s
[2K
| Adam | epoch: 007 | loss: 0.07781 - acc: 0.9855 | val_loss: 1.64221 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 43  | total loss: [1m[32m0.06550[0m[0m | time: 31.098s
[2K
| Adam | epoch: 008 | loss: 0.06550 - acc: 0.9881 -- iter: 032/167
[A[ATraining Step: 44  | total loss: [1m[32m0.05680[0m[0m | time: 81.018s
[2K
| Adam | epoch: 008 | loss: 0.05680 - acc: 0.9901 -- iter: 064/167
[A[ATraining Step: 45  | total loss: [1m[32m0.07800[0m[0m | time: 108.351s
[2K
| Adam | epoch: 008 | loss: 0.07800 - acc: 0.9865 -- iter: 096/167
[A[ATraining Step: 46  | total loss: [1m[32m0.07028[0m[0m | time: 160.520s
[2K
| Adam | epoch: 008 | loss: 0.07028 - acc: 0.9836 -- iter: 128/167
[A[ATraining Step: 47  | total loss: [1m[32m0.06478[0m[0m | time: 197.579s
[2K
| Adam | epoch: 008 | loss: 0.06478 - acc: 0.9862 -- iter: 160/167
[A[ATraining Step: 48  | total loss: [1m[32m0.05637[0m[0m | time: 206.862s
[2K
| Adam | epoch: 008 | loss: 0.05637 - acc: 0.9885 | val_loss: 0.66745 - val_acc: 0.7547 -- iter: 167/167
--
Training Step: 49  | total loss: [1m[32m0.04794[0m[0m | time: 5.044s
[2K
| Adam | epoch: 009 | loss: 0.04794 - acc: 0.9903 -- iter: 032/167
[A[ATraining Step: 50  | total loss: [1m[32m0.04103[0m[0m | time: 27.299s
[2K
| Adam | epoch: 009 | loss: 0.04103 - acc: 0.9918 -- iter: 064/167
[A[ATraining Step: 51  | total loss: [1m[32m0.05027[0m[0m | time: 55.616s
[2K
| Adam | epoch: 009 | loss: 0.05027 - acc: 0.9835 -- iter: 096/167
[A[ATraining Step: 52  | total loss: [1m[32m0.07978[0m[0m | time: 70.478s
[2K
| Adam | epoch: 009 | loss: 0.07978 - acc: 0.9813 -- iter: 128/167
[A[ATraining Step: 53  | total loss: [1m[32m0.09016[0m[0m | time: 89.810s
[2K
| Adam | epoch: 009 | loss: 0.09016 - acc: 0.9794 -- iter: 160/167
[A[ATraining Step: 54  | total loss: [1m[32m0.07833[0m[0m | time: 110.634s
[2K
| Adam | epoch: 009 | loss: 0.07833 - acc: 0.9824 | val_loss: 2.72742 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 55  | total loss: [1m[32m0.06868[0m[0m | time: 4.688s
[2K
| Adam | epoch: 010 | loss: 0.06868 - acc: 0.9849 -- iter: 032/167
[A[ATraining Step: 56  | total loss: [1m[32m0.06232[0m[0m | time: 9.717s
[2K
| Adam | epoch: 010 | loss: 0.06232 - acc: 0.9871 -- iter: 064/167
[A[ATraining Step: 57  | total loss: [1m[32m0.05507[0m[0m | time: 40.959s
[2K
| Adam | epoch: 010 | loss: 0.05507 - acc: 0.9888 -- iter: 096/167
[A[ATraining Step: 58  | total loss: [1m[32m0.04908[0m[0m | time: 62.723s
[2K
| Adam | epoch: 010 | loss: 0.04908 - acc: 0.9904 -- iter: 128/167
[A[ATraining Step: 59  | total loss: [1m[32m0.20372[0m[0m | time: 80.728s
[2K
| Adam | epoch: 010 | loss: 0.20372 - acc: 0.9665 -- iter: 160/167
[A[ATraining Step: 60  | total loss: [1m[32m0.18039[0m[0m | time: 100.387s
[2K
| Adam | epoch: 010 | loss: 0.18039 - acc: 0.9709 | val_loss: 3.95126 - val_acc: 0.5283 -- iter: 167/167
--
Training Step: 61  | total loss: [1m[32m0.16216[0m[0m | time: 18.261s
[2K
| Adam | epoch: 011 | loss: 0.16216 - acc: 0.9706 -- iter: 032/167
[A[ATraining Step: 62  | total loss: [1m[32m0.15418[0m[0m | time: 23.120s
[2K
| Adam | epoch: 011 | loss: 0.15418 - acc: 0.9664 -- iter: 064/167
[A[ATraining Step: 63  | total loss: [1m[32m0.14907[0m[0m | time: 27.889s
[2K
| Adam | epoch: 011 | loss: 0.14907 - acc: 0.9525 -- iter: 096/167
[A[ATraining Step: 64  | total loss: [1m[32m0.13379[0m[0m | time: 61.235s
[2K
| Adam | epoch: 011 | loss: 0.13379 - acc: 0.9585 -- iter: 128/167
[A[ATraining Step: 65  | total loss: [1m[32m0.13562[0m[0m | time: 75.860s
[2K
| Adam | epoch: 011 | loss: 0.13562 - acc: 0.9597 -- iter: 160/167
[A[ATraining Step: 66  | total loss: [1m[32m0.13788[0m[0m | time: 112.279s
[2K
| Adam | epoch: 011 | loss: 0.13788 - acc: 0.9608 | val_loss: 0.64330 - val_acc: 0.7547 -- iter: 167/167
--
Training Step: 67  | total loss: [1m[32m0.12629[0m[0m | time: 15.267s
[2K
| Adam | epoch: 012 | loss: 0.12629 - acc: 0.9655 -- iter: 032/167
[A[ATraining Step: 68  | total loss: [1m[32m0.12963[0m[0m | time: 33.397s
[2K
| Adam | epoch: 012 | loss: 0.12963 - acc: 0.9622 -- iter: 064/167
[A[ATraining Step: 69  | total loss: [1m[32m0.11977[0m[0m | time: 38.624s
[2K
| Adam | epoch: 012 | loss: 0.11977 - acc: 0.9666 -- iter: 096/167
[A[ATraining Step: 70  | total loss: [1m[32m0.11027[0m[0m | time: 44.093s
[2K
| Adam | epoch: 012 | loss: 0.11027 - acc: 0.9705 -- iter: 128/167
[A[ATraining Step: 71  | total loss: [1m[32m0.09983[0m[0m | time: 60.391s
[2K
| Adam | epoch: 012 | loss: 0.09983 - acc: 0.9738 -- iter: 160/167
[A[ATraining Step: 72  | total loss: [1m[32m0.09592[0m[0m | time: 85.440s
[2K
| Adam | epoch: 012 | loss: 0.09592 - acc: 0.9768 | val_loss: 1.12154 - val_acc: 0.7358 -- iter: 167/167
--
Training Step: 73  | total loss: [1m[32m0.08981[0m[0m | time: 16.008s
[2K
| Adam | epoch: 013 | loss: 0.08981 - acc: 0.9794 -- iter: 032/167
[A[ATraining Step: 74  | total loss: [1m[32m0.08375[0m[0m | time: 51.906s
[2K
| Adam | epoch: 013 | loss: 0.08375 - acc: 0.9816 -- iter: 064/167
[A[ATraining Step: 75  | total loss: [1m[32m0.08304[0m[0m | time: 62.697s
[2K
| Adam | epoch: 013 | loss: 0.08304 - acc: 0.9802 -- iter: 096/167
[A[ATraining Step: 76  | total loss: [1m[32m0.07508[0m[0m | time: 66.447s
[2K
| Adam | epoch: 013 | loss: 0.07508 - acc: 0.9823 -- iter: 128/167
[A[ATraining Step: 77  | total loss: [1m[32m0.06740[0m[0m | time: 68.947s
[2K
| Adam | epoch: 013 | loss: 0.06740 - acc: 0.9842 -- iter: 160/167
[A[ATraining Step: 78  | total loss: [1m[32m0.06066[0m[0m | time: 80.337s
[2K
| Adam | epoch: 013 | loss: 0.06066 - acc: 0.9859 | val_loss: 0.79134 - val_acc: 0.7925 -- iter: 167/167
--
Training Step: 79  | total loss: [1m[32m0.09270[0m[0m | time: 17.612s
[2K
| Adam | epoch: 014 | loss: 0.09270 - acc: 0.9776 -- iter: 032/167
[A[ATraining Step: 80  | total loss: [1m[32m0.08423[0m[0m | time: 29.929s
[2K
| Adam | epoch: 014 | loss: 0.08423 - acc: 0.9799 -- iter: 064/167
[A[ATraining Step: 81  | total loss: [1m[32m0.09094[0m[0m | time: 41.924s
[2K
| Adam | epoch: 014 | loss: 0.09094 - acc: 0.9756 -- iter: 096/167
[A[ATraining Step: 82  | total loss: [1m[32m0.08272[0m[0m | time: 53.668s
[2K
| Adam | epoch: 014 | loss: 0.08272 - acc: 0.9781 -- iter: 128/167
[A[ATraining Step: 83  | total loss: [1m[32m0.07494[0m[0m | time: 57.556s
[2K
| Adam | epoch: 014 | loss: 0.07494 - acc: 0.9803 -- iter: 160/167
[A[ATraining Step: 84  | total loss: [1m[32m0.06936[0m[0m | time: 65.101s
[2K
| Adam | epoch: 014 | loss: 0.06936 - acc: 0.9822 | val_loss: 1.33884 - val_acc: 0.6038 -- iter: 167/167
--
Training Step: 85  | total loss: [1m[32m0.06312[0m[0m | time: 12.084s
[2K
| Adam | epoch: 015 | loss: 0.06312 - acc: 0.9840 -- iter: 032/167
[A[ATraining Step: 86  | total loss: [1m[32m0.09899[0m[0m | time: 23.944s
[2K
| Adam | epoch: 015 | loss: 0.09899 - acc: 0.9669 -- iter: 064/167
[A[ATraining Step: 87  | total loss: [1m[32m0.11361[0m[0m | time: 36.344s
[2K
| Adam | epoch: 015 | loss: 0.11361 - acc: 0.9670 -- iter: 096/167
[A[ATraining Step: 88  | total loss: [1m[32m0.10249[0m[0m | time: 48.888s
[2K
| Adam | epoch: 015 | loss: 0.10249 - acc: 0.9703 -- iter: 128/167
[A[ATraining Step: 89  | total loss: [1m[32m0.09361[0m[0m | time: 60.930s
[2K
| Adam | epoch: 015 | loss: 0.09361 - acc: 0.9733 -- iter: 160/167
[A[ATraining Step: 90  | total loss: [1m[32m0.08454[0m[0m | time: 68.530s
[2K
| Adam | epoch: 015 | loss: 0.08454 - acc: 0.9760 | val_loss: 0.96530 - val_acc: 0.6792 -- iter: 167/167
--
Validation AUC:0.88
Validation AUPRC:0.8592855008741331
Test AUC:0.9585714285714286
Test AUPRC:0.958905822777236
BestTestF1Score	0.93	0.85	0.92	0.9	0.96	27	3	22	1	0.02
BestTestMCCScore	0.93	0.85	0.92	0.9	0.96	27	3	22	1	0.02
BestTestAccuracyScore	0.93	0.85	0.92	0.9	0.96	27	3	22	1	0.02
BestValidationF1Score	0.83	0.67	0.83	0.79	0.88	22	6	22	3	0.02
BestValidationMCC	0.83	0.67	0.83	0.79	0.88	22	6	22	3	0.02
BestValidationAccuracy	0.83	0.67	0.83	0.79	0.88	22	6	22	3	0.02
TestPredictions (Threshold:0.02)
CHEMBL3617988,TP,ACT,0.28999999165534973	CHEMBL337251,TN,INACT,0.0	CHEMBL2147091,TP,ACT,0.8600000143051147	CHEMBL444068,TN,INACT,0.0	CHEMBL1915167,TN,INACT,0.009999999776482582	CHEMBL1203655,FP,INACT,0.8999999761581421	CHEMBL2146978,TP,ACT,0.9700000286102295	CHEMBL330452,TN,INACT,0.0	CHEMBL517904,TP,ACT,0.9200000166893005	CHEMBL179398,TN,INACT,0.0	CHEMBL3398410,TP,ACT,0.3799999952316284	CHEMBL1629801,TN,INACT,0.0	CHEMBL3645516,TN,INACT,0.0	CHEMBL1831087,TP,ACT,0.9900000095367432	CHEMBL362489,TP,ACT,1.0	CHEMBL112908,TN,INACT,0.0	CHEMBL1766001,TP,ACT,0.9300000071525574	CHEMBL1915401,TN,INACT,0.019999999552965164	CHEMBL2011181,TN,INACT,0.0	CHEMBL389433,TP,ACT,0.10999999940395355	CHEMBL323626,TP,ACT,1.0	CHEMBL3664715,TN,INACT,0.0	CHEMBL3617991,TP,ACT,0.15000000596046448	CHEMBL443530,TN,INACT,0.0	CHEMBL367357,TP,ACT,0.9399999976158142	CHEMBL359627,TP,ACT,0.6000000238418579	CHEMBL2146982,TP,ACT,0.8799999952316284	CHEMBL157346,TN,INACT,0.0	CHEMBL15594,TN,INACT,0.0	CHEMBL3398413,TP,ACT,0.11999999731779099	CHEMBL1831083,TP,ACT,0.9900000095367432	CHEMBL359657,TN,INACT,0.0	CHEMBL1215665,TN,INACT,0.0	CHEMBL3398412,TP,ACT,0.10000000149011612	CHEMBL426789,TP,ACT,0.9700000286102295	CHEMBL3786184,TP,ACT,0.8899999856948853	CHEMBL26485,TN,INACT,0.0	CHEMBL459505,TP,ACT,0.9900000095367432	CHEMBL1784790,FP,INACT,0.10000000149011612	CHEMBL2011183,TN,INACT,0.0	CHEMBL1831086,TP,ACT,0.9900000095367432	CHEMBL3398416,TP,ACT,0.03999999910593033	CHEMBL1831094,TP,ACT,0.9900000095367432	CHEMBL1831090,TP,ACT,1.0	CHEMBL228985,FP,INACT,0.2199999988079071	CHEMBL3398401,TP,ACT,0.029999999329447746	CHEMBL345586,TN,INACT,0.0	CHEMBL495574,TN,INACT,0.0	CHEMBL1766008,TP,ACT,0.9900000095367432	CHEMBL3398414,TP,ACT,0.029999999329447746	CHEMBL3664674,TN,INACT,0.0	CHEMBL3702789,TN,INACT,0.0	CHEMBL3398421,FN,ACT,0.0	

