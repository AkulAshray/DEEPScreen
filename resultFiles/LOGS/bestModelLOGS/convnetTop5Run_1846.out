CNNModel CHEMBL3710 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	480
Number of inactive compounds :	480
---------------------------------
Run id: CNNModel_CHEMBL3710_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3710_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 508
Validation samples: 160
--
Training Step: 1  | time: 0.775s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/508
[A[ATraining Step: 2  | total loss: [1m[32m0.62413[0m[0m | time: 1.368s
[2K
| Adam | epoch: 001 | loss: 0.62413 - acc: 0.3656 -- iter: 064/508
[A[ATraining Step: 3  | total loss: [1m[32m0.68139[0m[0m | time: 1.967s
[2K
| Adam | epoch: 001 | loss: 0.68139 - acc: 0.3477 -- iter: 096/508
[A[ATraining Step: 4  | total loss: [1m[32m0.69029[0m[0m | time: 2.601s
[2K
| Adam | epoch: 001 | loss: 0.69029 - acc: 0.4619 -- iter: 128/508
[A[ATraining Step: 5  | total loss: [1m[32m0.69223[0m[0m | time: 3.212s
[2K
| Adam | epoch: 001 | loss: 0.69223 - acc: 0.5099 -- iter: 160/508
[A[ATraining Step: 6  | total loss: [1m[32m0.69190[0m[0m | time: 3.872s
[2K
| Adam | epoch: 001 | loss: 0.69190 - acc: 0.5437 -- iter: 192/508
[A[ATraining Step: 7  | total loss: [1m[32m0.68784[0m[0m | time: 4.491s
[2K
| Adam | epoch: 001 | loss: 0.68784 - acc: 0.6300 -- iter: 224/508
[A[ATraining Step: 8  | total loss: [1m[32m0.68832[0m[0m | time: 5.113s
[2K
| Adam | epoch: 001 | loss: 0.68832 - acc: 0.5920 -- iter: 256/508
[A[ATraining Step: 9  | total loss: [1m[32m0.69319[0m[0m | time: 5.729s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5433 -- iter: 288/508
[A[ATraining Step: 10  | total loss: [1m[32m0.68348[0m[0m | time: 6.335s
[2K
| Adam | epoch: 001 | loss: 0.68348 - acc: 0.5842 -- iter: 320/508
[A[ATraining Step: 11  | total loss: [1m[32m0.68524[0m[0m | time: 6.953s
[2K
| Adam | epoch: 001 | loss: 0.68524 - acc: 0.5739 -- iter: 352/508
[A[ATraining Step: 12  | total loss: [1m[32m0.68595[0m[0m | time: 7.563s
[2K
| Adam | epoch: 001 | loss: 0.68595 - acc: 0.5688 -- iter: 384/508
[A[ATraining Step: 13  | total loss: [1m[32m0.66762[0m[0m | time: 8.171s
[2K
| Adam | epoch: 001 | loss: 0.66762 - acc: 0.6197 -- iter: 416/508
[A[ATraining Step: 14  | total loss: [1m[32m0.64575[0m[0m | time: 8.807s
[2K
| Adam | epoch: 001 | loss: 0.64575 - acc: 0.6602 -- iter: 448/508
[A[ATraining Step: 15  | total loss: [1m[32m0.65377[0m[0m | time: 9.406s
[2K
| Adam | epoch: 001 | loss: 0.65377 - acc: 0.6464 -- iter: 480/508
[A[ATraining Step: 16  | total loss: [1m[32m0.61915[0m[0m | time: 10.971s
[2K
| Adam | epoch: 001 | loss: 0.61915 - acc: 0.6853 | val_loss: 0.74970 - val_acc: 0.5437 -- iter: 508/508
--
Training Step: 17  | total loss: [1m[32m0.69885[0m[0m | time: 0.565s
[2K
| Adam | epoch: 002 | loss: 0.69885 - acc: 0.6186 -- iter: 032/508
[A[ATraining Step: 18  | total loss: [1m[32m0.73034[0m[0m | time: 1.178s
[2K
| Adam | epoch: 002 | loss: 0.73034 - acc: 0.5775 -- iter: 064/508
[A[ATraining Step: 19  | total loss: [1m[32m0.71968[0m[0m | time: 1.795s
[2K
| Adam | epoch: 002 | loss: 0.71968 - acc: 0.5725 -- iter: 096/508
[A[ATraining Step: 20  | total loss: [1m[32m0.71791[0m[0m | time: 2.392s
[2K
| Adam | epoch: 002 | loss: 0.71791 - acc: 0.5492 -- iter: 128/508
[A[ATraining Step: 21  | total loss: [1m[32m0.70475[0m[0m | time: 3.000s
[2K
| Adam | epoch: 002 | loss: 0.70475 - acc: 0.5630 -- iter: 160/508
[A[ATraining Step: 22  | total loss: [1m[32m0.69408[0m[0m | time: 3.609s
[2K
| Adam | epoch: 002 | loss: 0.69408 - acc: 0.5816 -- iter: 192/508
[A[ATraining Step: 23  | total loss: [1m[32m0.68991[0m[0m | time: 4.217s
[2K
| Adam | epoch: 002 | loss: 0.68991 - acc: 0.5851 -- iter: 224/508
[A[ATraining Step: 24  | total loss: [1m[32m0.68787[0m[0m | time: 4.831s
[2K
| Adam | epoch: 002 | loss: 0.68787 - acc: 0.5876 -- iter: 256/508
[A[ATraining Step: 25  | total loss: [1m[32m0.68357[0m[0m | time: 5.421s
[2K
| Adam | epoch: 002 | loss: 0.68357 - acc: 0.6233 -- iter: 288/508
[A[ATraining Step: 26  | total loss: [1m[32m0.68141[0m[0m | time: 6.034s
[2K
| Adam | epoch: 002 | loss: 0.68141 - acc: 0.6486 -- iter: 320/508
[A[ATraining Step: 27  | total loss: [1m[32m0.68384[0m[0m | time: 6.646s
[2K
| Adam | epoch: 002 | loss: 0.68384 - acc: 0.6184 -- iter: 352/508
[A[ATraining Step: 28  | total loss: [1m[32m0.68498[0m[0m | time: 7.254s
[2K
| Adam | epoch: 002 | loss: 0.68498 - acc: 0.6044 -- iter: 384/508
[A[ATraining Step: 29  | total loss: [1m[32m0.68535[0m[0m | time: 7.873s
[2K
| Adam | epoch: 002 | loss: 0.68535 - acc: 0.6018 -- iter: 416/508
[A[ATraining Step: 30  | total loss: [1m[32m0.68521[0m[0m | time: 8.488s
[2K
| Adam | epoch: 002 | loss: 0.68521 - acc: 0.6073 -- iter: 448/508
[A[ATraining Step: 31  | total loss: [1m[32m0.68720[0m[0m | time: 9.104s
[2K
| Adam | epoch: 002 | loss: 0.68720 - acc: 0.5826 -- iter: 480/508
[A[ATraining Step: 32  | total loss: [1m[32m0.68814[0m[0m | time: 10.721s
[2K
| Adam | epoch: 002 | loss: 0.68814 - acc: 0.5710 | val_loss: 0.69029 - val_acc: 0.5437 -- iter: 508/508
--
Training Step: 33  | total loss: [1m[32m0.68627[0m[0m | time: 0.548s
[2K
| Adam | epoch: 003 | loss: 0.68627 - acc: 0.5966 -- iter: 032/508
[A[ATraining Step: 34  | total loss: [1m[32m0.68648[0m[0m | time: 1.074s
[2K
| Adam | epoch: 003 | loss: 0.68648 - acc: 0.5912 -- iter: 064/508
[A[ATraining Step: 35  | total loss: [1m[32m0.68682[0m[0m | time: 1.689s
[2K
| Adam | epoch: 003 | loss: 0.68682 - acc: 0.5871 -- iter: 096/508
[A[ATraining Step: 36  | total loss: [1m[32m0.68553[0m[0m | time: 2.296s
[2K
| Adam | epoch: 003 | loss: 0.68553 - acc: 0.6012 -- iter: 128/508
[A[ATraining Step: 37  | total loss: [1m[32m0.68497[0m[0m | time: 2.929s
[2K
| Adam | epoch: 003 | loss: 0.68497 - acc: 0.6060 -- iter: 160/508
[A[ATraining Step: 38  | total loss: [1m[32m0.68432[0m[0m | time: 3.556s
[2K
| Adam | epoch: 003 | loss: 0.68432 - acc: 0.6097 -- iter: 192/508
[A[ATraining Step: 39  | total loss: [1m[32m0.68295[0m[0m | time: 4.175s
[2K
| Adam | epoch: 003 | loss: 0.68295 - acc: 0.6186 -- iter: 224/508
[A[ATraining Step: 40  | total loss: [1m[32m0.68150[0m[0m | time: 4.795s
[2K
| Adam | epoch: 003 | loss: 0.68150 - acc: 0.6257 -- iter: 256/508
[A[ATraining Step: 41  | total loss: [1m[32m0.67928[0m[0m | time: 5.396s
[2K
| Adam | epoch: 003 | loss: 0.67928 - acc: 0.6370 -- iter: 288/508
[A[ATraining Step: 42  | total loss: [1m[32m0.68051[0m[0m | time: 6.021s
[2K
| Adam | epoch: 003 | loss: 0.68051 - acc: 0.6236 -- iter: 320/508
[A[ATraining Step: 43  | total loss: [1m[32m0.68340[0m[0m | time: 6.624s
[2K
| Adam | epoch: 003 | loss: 0.68340 - acc: 0.6018 -- iter: 352/508
[A[ATraining Step: 44  | total loss: [1m[32m0.68843[0m[0m | time: 7.239s
[2K
| Adam | epoch: 003 | loss: 0.68843 - acc: 0.5734 -- iter: 384/508
[A[ATraining Step: 45  | total loss: [1m[32m0.68774[0m[0m | time: 7.837s
[2K
| Adam | epoch: 003 | loss: 0.68774 - acc: 0.5715 -- iter: 416/508
[A[ATraining Step: 46  | total loss: [1m[32m0.68132[0m[0m | time: 8.444s
[2K
| Adam | epoch: 003 | loss: 0.68132 - acc: 0.5961 -- iter: 448/508
[A[ATraining Step: 47  | total loss: [1m[32m0.68819[0m[0m | time: 9.053s
[2K
| Adam | epoch: 003 | loss: 0.68819 - acc: 0.5650 -- iter: 480/508
[A[ATraining Step: 48  | total loss: [1m[32m0.68494[0m[0m | time: 10.664s
[2K
| Adam | epoch: 003 | loss: 0.68494 - acc: 0.5746 | val_loss: 0.68933 - val_acc: 0.5437 -- iter: 508/508
--
Training Step: 49  | total loss: [1m[32m0.68249[0m[0m | time: 0.611s
[2K
| Adam | epoch: 004 | loss: 0.68249 - acc: 0.5826 -- iter: 032/508
[A[ATraining Step: 50  | total loss: [1m[32m0.68140[0m[0m | time: 1.166s
[2K
| Adam | epoch: 004 | loss: 0.68140 - acc: 0.5843 -- iter: 064/508
[A[ATraining Step: 51  | total loss: [1m[32m0.68142[0m[0m | time: 1.701s
[2K
| Adam | epoch: 004 | loss: 0.68142 - acc: 0.5824 -- iter: 096/508
[A[ATraining Step: 52  | total loss: [1m[32m0.68152[0m[0m | time: 2.311s
[2K
| Adam | epoch: 004 | loss: 0.68152 - acc: 0.5807 -- iter: 128/508
[A[ATraining Step: 53  | total loss: [1m[32m0.67869[0m[0m | time: 2.910s
[2K
| Adam | epoch: 004 | loss: 0.67869 - acc: 0.5873 -- iter: 160/508
[A[ATraining Step: 54  | total loss: [1m[32m0.67934[0m[0m | time: 3.512s
[2K
| Adam | epoch: 004 | loss: 0.67934 - acc: 0.5837 -- iter: 192/508
[A[ATraining Step: 55  | total loss: [1m[32m0.67686[0m[0m | time: 4.136s
[2K
| Adam | epoch: 004 | loss: 0.67686 - acc: 0.5896 -- iter: 224/508
[A[ATraining Step: 56  | total loss: [1m[32m0.68565[0m[0m | time: 4.746s
[2K
| Adam | epoch: 004 | loss: 0.68565 - acc: 0.5682 -- iter: 256/508
[A[ATraining Step: 57  | total loss: [1m[32m0.67713[0m[0m | time: 5.364s
[2K
| Adam | epoch: 004 | loss: 0.67713 - acc: 0.5890 -- iter: 288/508
[A[ATraining Step: 58  | total loss: [1m[32m0.67658[0m[0m | time: 5.975s
[2K
| Adam | epoch: 004 | loss: 0.67658 - acc: 0.5897 -- iter: 320/508
[A[ATraining Step: 59  | total loss: [1m[32m0.66556[0m[0m | time: 6.591s
[2K
| Adam | epoch: 004 | loss: 0.66556 - acc: 0.6154 -- iter: 352/508
[A[ATraining Step: 60  | total loss: [1m[32m0.66887[0m[0m | time: 7.207s
[2K
| Adam | epoch: 004 | loss: 0.66887 - acc: 0.6084 -- iter: 384/508
[A[ATraining Step: 61  | total loss: [1m[32m0.67788[0m[0m | time: 7.823s
[2K
| Adam | epoch: 004 | loss: 0.67788 - acc: 0.5902 -- iter: 416/508
[A[ATraining Step: 62  | total loss: [1m[32m0.66964[0m[0m | time: 8.431s
[2K
| Adam | epoch: 004 | loss: 0.66964 - acc: 0.6067 -- iter: 448/508
[A[ATraining Step: 63  | total loss: [1m[32m0.67222[0m[0m | time: 9.046s
[2K
| Adam | epoch: 004 | loss: 0.67222 - acc: 0.6011 -- iter: 480/508
[A[ATraining Step: 64  | total loss: [1m[32m0.67638[0m[0m | time: 10.664s
[2K
| Adam | epoch: 004 | loss: 0.67638 - acc: 0.5924 | val_loss: 0.69240 - val_acc: 0.5437 -- iter: 508/508
--
Training Step: 65  | total loss: [1m[32m0.68464[0m[0m | time: 0.607s
[2K
| Adam | epoch: 005 | loss: 0.68464 - acc: 0.5733 -- iter: 032/508
[A[ATraining Step: 66  | total loss: [1m[32m0.68621[0m[0m | time: 1.210s
[2K
| Adam | epoch: 005 | loss: 0.68621 - acc: 0.5682 -- iter: 064/508
[A[ATraining Step: 67  | total loss: [1m[32m0.67775[0m[0m | time: 1.743s
[2K
| Adam | epoch: 005 | loss: 0.67775 - acc: 0.5900 -- iter: 096/508
[A[ATraining Step: 68  | total loss: [1m[32m0.67667[0m[0m | time: 2.280s
[2K
| Adam | epoch: 005 | loss: 0.67667 - acc: 0.5920 -- iter: 128/508
[A[ATraining Step: 69  | total loss: [1m[32m0.67575[0m[0m | time: 2.885s
[2K
| Adam | epoch: 005 | loss: 0.67575 - acc: 0.5938 -- iter: 160/508
[A[ATraining Step: 70  | total loss: [1m[32m0.67113[0m[0m | time: 3.488s
[2K
| Adam | epoch: 005 | loss: 0.67113 - acc: 0.6082 -- iter: 192/508
[A[ATraining Step: 71  | total loss: [1m[32m0.66804[0m[0m | time: 4.095s
[2K
| Adam | epoch: 005 | loss: 0.66804 - acc: 0.6172 -- iter: 224/508
[A[ATraining Step: 72  | total loss: [1m[32m0.66990[0m[0m | time: 4.700s
[2K
| Adam | epoch: 005 | loss: 0.66990 - acc: 0.6111 -- iter: 256/508
[A[ATraining Step: 73  | total loss: [1m[32m0.67368[0m[0m | time: 5.306s
[2K
| Adam | epoch: 005 | loss: 0.67368 - acc: 0.5987 -- iter: 288/508
[A[ATraining Step: 74  | total loss: [1m[32m0.67242[0m[0m | time: 5.916s
[2K
| Adam | epoch: 005 | loss: 0.67242 - acc: 0.6016 -- iter: 320/508
[A[ATraining Step: 75  | total loss: [1m[32m0.67453[0m[0m | time: 6.525s
[2K
| Adam | epoch: 005 | loss: 0.67453 - acc: 0.5940 -- iter: 352/508
[A[ATraining Step: 76  | total loss: [1m[32m0.67283[0m[0m | time: 7.134s
[2K
| Adam | epoch: 005 | loss: 0.67283 - acc: 0.5973 -- iter: 384/508
[A[ATraining Step: 77  | total loss: [1m[32m0.67510[0m[0m | time: 7.732s
[2K
| Adam | epoch: 005 | loss: 0.67510 - acc: 0.5903 -- iter: 416/508
[A[ATraining Step: 78  | total loss: [1m[32m0.67337[0m[0m | time: 8.336s
[2K
| Adam | epoch: 005 | loss: 0.67337 - acc: 0.5939 -- iter: 448/508
[A[ATraining Step: 79  | total loss: [1m[32m0.67664[0m[0m | time: 8.944s
[2K
| Adam | epoch: 005 | loss: 0.67664 - acc: 0.5842 -- iter: 480/508
[A[ATraining Step: 80  | total loss: [1m[32m0.67669[0m[0m | time: 10.560s
[2K
| Adam | epoch: 005 | loss: 0.67669 - acc: 0.5820 | val_loss: 0.68644 - val_acc: 0.5437 -- iter: 508/508
--
Training Step: 81  | total loss: [1m[32m0.67115[0m[0m | time: 0.620s
[2K
| Adam | epoch: 006 | loss: 0.67115 - acc: 0.5958 -- iter: 032/508
[A[ATraining Step: 82  | total loss: [1m[32m0.67465[0m[0m | time: 1.230s
[2K
| Adam | epoch: 006 | loss: 0.67465 - acc: 0.5863 -- iter: 064/508
[A[ATraining Step: 83  | total loss: [1m[32m0.67388[0m[0m | time: 1.839s
[2K
| Adam | epoch: 006 | loss: 0.67388 - acc: 0.5870 -- iter: 096/508
[A[ATraining Step: 84  | total loss: [1m[32m0.66942[0m[0m | time: 2.391s
[2K
| Adam | epoch: 006 | loss: 0.66942 - acc: 0.5971 -- iter: 128/508
[A[ATraining Step: 85  | total loss: [1m[32m0.67149[0m[0m | time: 2.926s
[2K
| Adam | epoch: 006 | loss: 0.67149 - acc: 0.5909 -- iter: 160/508
[A[ATraining Step: 86  | total loss: [1m[32m0.67333[0m[0m | time: 3.541s
[2K
| Adam | epoch: 006 | loss: 0.67333 - acc: 0.5854 -- iter: 192/508
[A[ATraining Step: 87  | total loss: [1m[32m0.66713[0m[0m | time: 4.152s
[2K
| Adam | epoch: 006 | loss: 0.66713 - acc: 0.5987 -- iter: 224/508
[A[ATraining Step: 88  | total loss: [1m[32m0.67239[0m[0m | time: 4.756s
[2K
| Adam | epoch: 006 | loss: 0.67239 - acc: 0.5857 -- iter: 256/508
[A[ATraining Step: 89  | total loss: [1m[32m0.66290[0m[0m | time: 5.351s
[2K
| Adam | epoch: 006 | loss: 0.66290 - acc: 0.6053 -- iter: 288/508
[A[ATraining Step: 90  | total loss: [1m[32m0.66442[0m[0m | time: 5.958s
[2K
| Adam | epoch: 006 | loss: 0.66442 - acc: 0.6010 -- iter: 320/508
[A[ATraining Step: 91  | total loss: [1m[32m0.66471[0m[0m | time: 6.575s
[2K
| Adam | epoch: 006 | loss: 0.66471 - acc: 0.6003 -- iter: 352/508
[A[ATraining Step: 92  | total loss: [1m[32m0.66612[0m[0m | time: 7.179s
[2K
| Adam | epoch: 006 | loss: 0.66612 - acc: 0.5965 -- iter: 384/508
[A[ATraining Step: 93  | total loss: [1m[32m0.66136[0m[0m | time: 7.789s
[2K
| Adam | epoch: 006 | loss: 0.66136 - acc: 0.6025 -- iter: 416/508
[A[ATraining Step: 94  | total loss: [1m[32m0.65747[0m[0m | time: 8.397s
[2K
| Adam | epoch: 006 | loss: 0.65747 - acc: 0.6079 -- iter: 448/508
[A[ATraining Step: 95  | total loss: [1m[32m0.66601[0m[0m | time: 8.998s
[2K
| Adam | epoch: 006 | loss: 0.66601 - acc: 0.5939 -- iter: 480/508
[A[ATraining Step: 96  | total loss: [1m[32m0.66607[0m[0m | time: 10.632s
[2K
| Adam | epoch: 006 | loss: 0.66607 - acc: 0.5908 | val_loss: 0.67348 - val_acc: 0.5437 -- iter: 508/508
--
Training Step: 97  | total loss: [1m[32m0.66971[0m[0m | time: 0.600s
[2K
| Adam | epoch: 007 | loss: 0.66971 - acc: 0.5817 -- iter: 032/508
[A[ATraining Step: 98  | total loss: [1m[32m0.67062[0m[0m | time: 1.216s
[2K
| Adam | epoch: 007 | loss: 0.67062 - acc: 0.5767 -- iter: 064/508
[A[ATraining Step: 99  | total loss: [1m[32m0.66120[0m[0m | time: 1.831s
[2K
| Adam | epoch: 007 | loss: 0.66120 - acc: 0.6003 -- iter: 096/508
[A[ATraining Step: 100  | total loss: [1m[32m0.66081[0m[0m | time: 2.434s
[2K
| Adam | epoch: 007 | loss: 0.66081 - acc: 0.5965 -- iter: 128/508
[A[ATraining Step: 101  | total loss: [1m[32m0.66213[0m[0m | time: 2.990s
[2K
| Adam | epoch: 007 | loss: 0.66213 - acc: 0.5900 -- iter: 160/508
[A[ATraining Step: 102  | total loss: [1m[32m0.66296[0m[0m | time: 3.514s
[2K
| Adam | epoch: 007 | loss: 0.66296 - acc: 0.5845 -- iter: 192/508
[A[ATraining Step: 103  | total loss: [1m[32m0.66383[0m[0m | time: 4.106s
[2K
| Adam | epoch: 007 | loss: 0.66383 - acc: 0.5797 -- iter: 224/508
[A[ATraining Step: 104  | total loss: [1m[32m0.66127[0m[0m | time: 4.733s
[2K
| Adam | epoch: 007 | loss: 0.66127 - acc: 0.5842 -- iter: 256/508
[A[ATraining Step: 105  | total loss: [1m[32m0.65717[0m[0m | time: 5.345s
[2K
| Adam | epoch: 007 | loss: 0.65717 - acc: 0.5914 -- iter: 288/508
[A[ATraining Step: 106  | total loss: [1m[32m0.65703[0m[0m | time: 5.965s
[2K
| Adam | epoch: 007 | loss: 0.65703 - acc: 0.5885 -- iter: 320/508
[A[ATraining Step: 107  | total loss: [1m[32m0.65365[0m[0m | time: 6.576s
[2K
| Adam | epoch: 007 | loss: 0.65365 - acc: 0.5922 -- iter: 352/508
[A[ATraining Step: 108  | total loss: [1m[32m0.65510[0m[0m | time: 7.190s
[2K
| Adam | epoch: 007 | loss: 0.65510 - acc: 0.5861 -- iter: 384/508
[A[ATraining Step: 109  | total loss: [1m[32m0.65412[0m[0m | time: 7.828s
[2K
| Adam | epoch: 007 | loss: 0.65412 - acc: 0.5837 -- iter: 416/508
[A[ATraining Step: 110  | total loss: [1m[32m0.64821[0m[0m | time: 8.434s
[2K
| Adam | epoch: 007 | loss: 0.64821 - acc: 0.5910 -- iter: 448/508
[A[ATraining Step: 111  | total loss: [1m[32m0.64685[0m[0m | time: 9.043s
[2K
| Adam | epoch: 007 | loss: 0.64685 - acc: 0.5881 -- iter: 480/508
[A[ATraining Step: 112  | total loss: [1m[32m0.63985[0m[0m | time: 10.658s
[2K
| Adam | epoch: 007 | loss: 0.63985 - acc: 0.5949 | val_loss: 0.63597 - val_acc: 0.5437 -- iter: 508/508
--
Training Step: 113  | total loss: [1m[32m0.63103[0m[0m | time: 0.607s
[2K
| Adam | epoch: 008 | loss: 0.63103 - acc: 0.6011 -- iter: 032/508
[A[ATraining Step: 114  | total loss: [1m[32m0.62325[0m[0m | time: 1.224s
[2K
| Adam | epoch: 008 | loss: 0.62325 - acc: 0.6035 -- iter: 064/508
[A[ATraining Step: 115  | total loss: [1m[32m0.62238[0m[0m | time: 1.851s
[2K
| Adam | epoch: 008 | loss: 0.62238 - acc: 0.6025 -- iter: 096/508
[A[ATraining Step: 116  | total loss: [1m[32m0.62024[0m[0m | time: 2.453s
[2K
| Adam | epoch: 008 | loss: 0.62024 - acc: 0.6016 -- iter: 128/508
[A[ATraining Step: 117  | total loss: [1m[32m0.62616[0m[0m | time: 3.057s
[2K
| Adam | epoch: 008 | loss: 0.62616 - acc: 0.5821 -- iter: 160/508
[A[ATraining Step: 118  | total loss: [1m[32m0.61661[0m[0m | time: 3.601s
[2K
| Adam | epoch: 008 | loss: 0.61661 - acc: 0.5895 -- iter: 192/508
[A[ATraining Step: 119  | total loss: [1m[32m0.61389[0m[0m | time: 4.141s
[2K
| Adam | epoch: 008 | loss: 0.61389 - acc: 0.5841 -- iter: 224/508
[A[ATraining Step: 120  | total loss: [1m[32m0.60985[0m[0m | time: 4.753s
[2K
| Adam | epoch: 008 | loss: 0.60985 - acc: 0.5793 -- iter: 256/508
[A[ATraining Step: 121  | total loss: [1m[32m0.60415[0m[0m | time: 5.349s
[2K
| Adam | epoch: 008 | loss: 0.60415 - acc: 0.5807 -- iter: 288/508
[A[ATraining Step: 122  | total loss: [1m[32m0.58709[0m[0m | time: 5.947s
[2K
| Adam | epoch: 008 | loss: 0.58709 - acc: 0.5883 -- iter: 320/508
[A[ATraining Step: 123  | total loss: [1m[32m0.58221[0m[0m | time: 6.584s
[2K
| Adam | epoch: 008 | loss: 0.58221 - acc: 0.5857 -- iter: 352/508
[A[ATraining Step: 124  | total loss: [1m[32m0.57802[0m[0m | time: 7.189s
[2K
| Adam | epoch: 008 | loss: 0.57802 - acc: 0.5896 -- iter: 384/508
[A[ATraining Step: 125  | total loss: [1m[32m0.57025[0m[0m | time: 7.792s
[2K
| Adam | epoch: 008 | loss: 0.57025 - acc: 0.5963 -- iter: 416/508
[A[ATraining Step: 126  | total loss: [1m[32m0.56024[0m[0m | time: 8.402s
[2K
| Adam | epoch: 008 | loss: 0.56024 - acc: 0.6304 -- iter: 448/508
[A[ATraining Step: 127  | total loss: [1m[32m0.56077[0m[0m | time: 8.998s
[2K
| Adam | epoch: 008 | loss: 0.56077 - acc: 0.6392 -- iter: 480/508
[A[ATraining Step: 128  | total loss: [1m[32m0.56693[0m[0m | time: 10.612s
[2K
| Adam | epoch: 008 | loss: 0.56693 - acc: 0.6503 | val_loss: 0.52885 - val_acc: 0.6687 -- iter: 508/508
--
Training Step: 129  | total loss: [1m[32m0.55495[0m[0m | time: 0.621s
[2K
| Adam | epoch: 009 | loss: 0.55495 - acc: 0.6665 -- iter: 032/508
[A[ATraining Step: 130  | total loss: [1m[32m0.56211[0m[0m | time: 1.232s
[2K
| Adam | epoch: 009 | loss: 0.56211 - acc: 0.6561 -- iter: 064/508
[A[ATraining Step: 131  | total loss: [1m[32m0.54996[0m[0m | time: 1.844s
[2K
| Adam | epoch: 009 | loss: 0.54996 - acc: 0.6780 -- iter: 096/508
[A[ATraining Step: 132  | total loss: [1m[32m0.54262[0m[0m | time: 2.462s
[2K
| Adam | epoch: 009 | loss: 0.54262 - acc: 0.6852 -- iter: 128/508
[A[ATraining Step: 133  | total loss: [1m[32m0.53385[0m[0m | time: 3.096s
[2K
| Adam | epoch: 009 | loss: 0.53385 - acc: 0.6917 -- iter: 160/508
[A[ATraining Step: 134  | total loss: [1m[32m0.53119[0m[0m | time: 3.694s
[2K
| Adam | epoch: 009 | loss: 0.53119 - acc: 0.7038 -- iter: 192/508
[A[ATraining Step: 135  | total loss: [1m[32m0.50966[0m[0m | time: 4.243s
[2K
| Adam | epoch: 009 | loss: 0.50966 - acc: 0.7303 -- iter: 224/508
[A[ATraining Step: 136  | total loss: [1m[32m0.48548[0m[0m | time: 4.785s
[2K
| Adam | epoch: 009 | loss: 0.48548 - acc: 0.7537 -- iter: 256/508
[A[ATraining Step: 137  | total loss: [1m[32m0.46184[0m[0m | time: 5.413s
[2K
| Adam | epoch: 009 | loss: 0.46184 - acc: 0.7676 -- iter: 288/508
[A[ATraining Step: 138  | total loss: [1m[32m0.45975[0m[0m | time: 6.031s
[2K
| Adam | epoch: 009 | loss: 0.45975 - acc: 0.7690 -- iter: 320/508
[A[ATraining Step: 139  | total loss: [1m[32m0.46922[0m[0m | time: 6.656s
[2K
| Adam | epoch: 009 | loss: 0.46922 - acc: 0.7702 -- iter: 352/508
[A[ATraining Step: 140  | total loss: [1m[32m0.46386[0m[0m | time: 7.257s
[2K
| Adam | epoch: 009 | loss: 0.46386 - acc: 0.7775 -- iter: 384/508
[A[ATraining Step: 141  | total loss: [1m[32m0.46286[0m[0m | time: 7.877s
[2K
| Adam | epoch: 009 | loss: 0.46286 - acc: 0.7810 -- iter: 416/508
[A[ATraining Step: 142  | total loss: [1m[32m0.45058[0m[0m | time: 8.501s
[2K
| Adam | epoch: 009 | loss: 0.45058 - acc: 0.7936 -- iter: 448/508
[A[ATraining Step: 143  | total loss: [1m[32m0.44568[0m[0m | time: 9.099s
[2K
| Adam | epoch: 009 | loss: 0.44568 - acc: 0.7986 -- iter: 480/508
[A[ATraining Step: 144  | total loss: [1m[32m0.42862[0m[0m | time: 10.706s
[2K
| Adam | epoch: 009 | loss: 0.42862 - acc: 0.8093 | val_loss: 0.50248 - val_acc: 0.8313 -- iter: 508/508
--
Training Step: 145  | total loss: [1m[32m0.43822[0m[0m | time: 0.614s
[2K
| Adam | epoch: 010 | loss: 0.43822 - acc: 0.8034 -- iter: 032/508
[A[ATraining Step: 146  | total loss: [1m[32m0.43593[0m[0m | time: 1.214s
[2K
| Adam | epoch: 010 | loss: 0.43593 - acc: 0.8106 -- iter: 064/508
[A[ATraining Step: 147  | total loss: [1m[32m0.41003[0m[0m | time: 1.825s
[2K
| Adam | epoch: 010 | loss: 0.41003 - acc: 0.8264 -- iter: 096/508
[A[ATraining Step: 148  | total loss: [1m[32m0.42228[0m[0m | time: 2.468s
[2K
| Adam | epoch: 010 | loss: 0.42228 - acc: 0.8188 -- iter: 128/508
[A[ATraining Step: 149  | total loss: [1m[32m0.39792[0m[0m | time: 3.078s
[2K
| Adam | epoch: 010 | loss: 0.39792 - acc: 0.8275 -- iter: 160/508
[A[ATraining Step: 150  | total loss: [1m[32m0.40624[0m[0m | time: 3.675s
[2K
| Adam | epoch: 010 | loss: 0.40624 - acc: 0.8198 -- iter: 192/508
[A[ATraining Step: 151  | total loss: [1m[32m0.38734[0m[0m | time: 4.275s
[2K
| Adam | epoch: 010 | loss: 0.38734 - acc: 0.8222 -- iter: 224/508
[A[ATraining Step: 152  | total loss: [1m[32m0.39003[0m[0m | time: 4.799s
[2K
| Adam | epoch: 010 | loss: 0.39003 - acc: 0.8212 -- iter: 256/508
[A[ATraining Step: 153  | total loss: [1m[32m0.38796[0m[0m | time: 5.337s
[2K
| Adam | epoch: 010 | loss: 0.38796 - acc: 0.8248 -- iter: 288/508
[A[ATraining Step: 154  | total loss: [1m[32m0.38313[0m[0m | time: 5.936s
[2K
| Adam | epoch: 010 | loss: 0.38313 - acc: 0.8316 -- iter: 320/508
[A[ATraining Step: 155  | total loss: [1m[32m0.37486[0m[0m | time: 6.543s
[2K
| Adam | epoch: 010 | loss: 0.37486 - acc: 0.8359 -- iter: 352/508
[A[ATraining Step: 156  | total loss: [1m[32m0.37636[0m[0m | time: 7.151s
[2K
| Adam | epoch: 010 | loss: 0.37636 - acc: 0.8336 -- iter: 384/508
[A[ATraining Step: 157  | total loss: [1m[32m0.37518[0m[0m | time: 7.752s
[2K
| Adam | epoch: 010 | loss: 0.37518 - acc: 0.8377 -- iter: 416/508
[A[ATraining Step: 158  | total loss: [1m[32m0.36004[0m[0m | time: 8.355s
[2K
| Adam | epoch: 010 | loss: 0.36004 - acc: 0.8446 -- iter: 448/508
[A[ATraining Step: 159  | total loss: [1m[32m0.35372[0m[0m | time: 8.968s
[2K
| Adam | epoch: 010 | loss: 0.35372 - acc: 0.8507 -- iter: 480/508
[A[ATraining Step: 160  | total loss: [1m[32m0.34515[0m[0m | time: 10.576s
[2K
| Adam | epoch: 010 | loss: 0.34515 - acc: 0.8563 | val_loss: 0.31452 - val_acc: 0.8938 -- iter: 508/508
--
Training Step: 161  | total loss: [1m[32m0.34397[0m[0m | time: 0.614s
[2K
| Adam | epoch: 011 | loss: 0.34397 - acc: 0.8488 -- iter: 032/508
[A[ATraining Step: 162  | total loss: [1m[32m0.33600[0m[0m | time: 1.214s
[2K
| Adam | epoch: 011 | loss: 0.33600 - acc: 0.8545 -- iter: 064/508
[A[ATraining Step: 163  | total loss: [1m[32m0.32420[0m[0m | time: 1.810s
[2K
| Adam | epoch: 011 | loss: 0.32420 - acc: 0.8628 -- iter: 096/508
[A[ATraining Step: 164  | total loss: [1m[32m0.33086[0m[0m | time: 2.432s
[2K
| Adam | epoch: 011 | loss: 0.33086 - acc: 0.8578 -- iter: 128/508
[A[ATraining Step: 165  | total loss: [1m[32m0.32766[0m[0m | time: 3.039s
[2K
| Adam | epoch: 011 | loss: 0.32766 - acc: 0.8626 -- iter: 160/508
[A[ATraining Step: 166  | total loss: [1m[32m0.30984[0m[0m | time: 3.651s
[2K
| Adam | epoch: 011 | loss: 0.30984 - acc: 0.8733 -- iter: 192/508
[A[ATraining Step: 167  | total loss: [1m[32m0.30760[0m[0m | time: 4.253s
[2K
| Adam | epoch: 011 | loss: 0.30760 - acc: 0.8703 -- iter: 224/508
[A[ATraining Step: 168  | total loss: [1m[32m0.32341[0m[0m | time: 4.851s
[2K
| Adam | epoch: 011 | loss: 0.32341 - acc: 0.8614 -- iter: 256/508
[A[ATraining Step: 169  | total loss: [1m[32m0.32777[0m[0m | time: 5.370s
[2K
| Adam | epoch: 011 | loss: 0.32777 - acc: 0.8596 -- iter: 288/508
[A[ATraining Step: 170  | total loss: [1m[32m0.32263[0m[0m | time: 5.896s
[2K
| Adam | epoch: 011 | loss: 0.32263 - acc: 0.8558 -- iter: 320/508
[A[ATraining Step: 171  | total loss: [1m[32m0.31203[0m[0m | time: 6.504s
[2K
| Adam | epoch: 011 | loss: 0.31203 - acc: 0.8631 -- iter: 352/508
[A[ATraining Step: 172  | total loss: [1m[32m0.33529[0m[0m | time: 7.096s
[2K
| Adam | epoch: 011 | loss: 0.33529 - acc: 0.8549 -- iter: 384/508
[A[ATraining Step: 173  | total loss: [1m[32m0.32460[0m[0m | time: 7.722s
[2K
| Adam | epoch: 011 | loss: 0.32460 - acc: 0.8600 -- iter: 416/508
[A[ATraining Step: 174  | total loss: [1m[32m0.33171[0m[0m | time: 8.317s
[2K
| Adam | epoch: 011 | loss: 0.33171 - acc: 0.8584 -- iter: 448/508
[A[ATraining Step: 175  | total loss: [1m[32m0.32928[0m[0m | time: 8.922s
[2K
| Adam | epoch: 011 | loss: 0.32928 - acc: 0.8569 -- iter: 480/508
[A[ATraining Step: 176  | total loss: [1m[32m0.32972[0m[0m | time: 10.526s
[2K
| Adam | epoch: 011 | loss: 0.32972 - acc: 0.8588 | val_loss: 0.56247 - val_acc: 0.7812 -- iter: 508/508
--
Training Step: 177  | total loss: [1m[32m0.33005[0m[0m | time: 0.601s
[2K
| Adam | epoch: 012 | loss: 0.33005 - acc: 0.8604 -- iter: 032/508
[A[ATraining Step: 178  | total loss: [1m[32m0.33182[0m[0m | time: 1.225s
[2K
| Adam | epoch: 012 | loss: 0.33182 - acc: 0.8618 -- iter: 064/508
[A[ATraining Step: 179  | total loss: [1m[32m0.34010[0m[0m | time: 1.824s
[2K
| Adam | epoch: 012 | loss: 0.34010 - acc: 0.8538 -- iter: 096/508
[A[ATraining Step: 180  | total loss: [1m[32m0.33725[0m[0m | time: 2.434s
[2K
| Adam | epoch: 012 | loss: 0.33725 - acc: 0.8590 -- iter: 128/508
[A[ATraining Step: 181  | total loss: [1m[32m0.33487[0m[0m | time: 3.061s
[2K
| Adam | epoch: 012 | loss: 0.33487 - acc: 0.8575 -- iter: 160/508
[A[ATraining Step: 182  | total loss: [1m[32m0.34278[0m[0m | time: 3.674s
[2K
| Adam | epoch: 012 | loss: 0.34278 - acc: 0.8561 -- iter: 192/508
[A[ATraining Step: 183  | total loss: [1m[32m0.34699[0m[0m | time: 4.295s
[2K
| Adam | epoch: 012 | loss: 0.34699 - acc: 0.8518 -- iter: 224/508
[A[ATraining Step: 184  | total loss: [1m[32m0.36314[0m[0m | time: 4.899s
[2K
| Adam | epoch: 012 | loss: 0.36314 - acc: 0.8447 -- iter: 256/508
[A[ATraining Step: 185  | total loss: [1m[32m0.36041[0m[0m | time: 5.504s
[2K
| Adam | epoch: 012 | loss: 0.36041 - acc: 0.8477 -- iter: 288/508
[A[ATraining Step: 186  | total loss: [1m[32m0.35055[0m[0m | time: 6.051s
[2K
| Adam | epoch: 012 | loss: 0.35055 - acc: 0.8536 -- iter: 320/508
[A[ATraining Step: 187  | total loss: [1m[32m0.33298[0m[0m | time: 6.581s
[2K
| Adam | epoch: 012 | loss: 0.33298 - acc: 0.8682 -- iter: 352/508
[A[ATraining Step: 188  | total loss: [1m[32m0.31743[0m[0m | time: 7.183s
[2K
| Adam | epoch: 012 | loss: 0.31743 - acc: 0.8707 -- iter: 384/508
[A[ATraining Step: 189  | total loss: [1m[32m0.30704[0m[0m | time: 7.799s
[2K
| Adam | epoch: 012 | loss: 0.30704 - acc: 0.8680 -- iter: 416/508
[A[ATraining Step: 190  | total loss: [1m[32m0.31397[0m[0m | time: 8.409s
[2K
| Adam | epoch: 012 | loss: 0.31397 - acc: 0.8624 -- iter: 448/508
[A[ATraining Step: 191  | total loss: [1m[32m0.29961[0m[0m | time: 9.022s
[2K
| Adam | epoch: 012 | loss: 0.29961 - acc: 0.8700 -- iter: 480/508
[A[ATraining Step: 192  | total loss: [1m[32m0.28978[0m[0m | time: 10.629s
[2K
| Adam | epoch: 012 | loss: 0.28978 - acc: 0.8767 | val_loss: 0.29678 - val_acc: 0.8875 -- iter: 508/508
--
Training Step: 193  | total loss: [1m[32m0.28025[0m[0m | time: 0.626s
[2K
| Adam | epoch: 013 | loss: 0.28025 - acc: 0.8828 -- iter: 032/508
[A[ATraining Step: 194  | total loss: [1m[32m0.28237[0m[0m | time: 1.240s
[2K
| Adam | epoch: 013 | loss: 0.28237 - acc: 0.8789 -- iter: 064/508
[A[ATraining Step: 195  | total loss: [1m[32m0.27097[0m[0m | time: 1.847s
[2K
| Adam | epoch: 013 | loss: 0.27097 - acc: 0.8879 -- iter: 096/508
[A[ATraining Step: 196  | total loss: [1m[32m0.27642[0m[0m | time: 2.455s
[2K
| Adam | epoch: 013 | loss: 0.27642 - acc: 0.8866 -- iter: 128/508
[A[ATraining Step: 197  | total loss: [1m[32m0.28250[0m[0m | time: 3.059s
[2K
| Adam | epoch: 013 | loss: 0.28250 - acc: 0.8823 -- iter: 160/508
[A[ATraining Step: 198  | total loss: [1m[32m0.28805[0m[0m | time: 3.680s
[2K
| Adam | epoch: 013 | loss: 0.28805 - acc: 0.8816 -- iter: 192/508
[A[ATraining Step: 199  | total loss: [1m[32m0.27769[0m[0m | time: 4.284s
[2K
| Adam | epoch: 013 | loss: 0.27769 - acc: 0.8903 -- iter: 224/508
[A[ATraining Step: 200  | total loss: [1m[32m0.25936[0m[0m | time: 5.901s
[2K
| Adam | epoch: 013 | loss: 0.25936 - acc: 0.9013 | val_loss: 0.37973 - val_acc: 0.8688 -- iter: 256/508
--
Training Step: 201  | total loss: [1m[32m0.25984[0m[0m | time: 6.529s
[2K
| Adam | epoch: 013 | loss: 0.25984 - acc: 0.8986 -- iter: 288/508
[A[ATraining Step: 202  | total loss: [1m[32m0.26221[0m[0m | time: 7.131s
[2K
| Adam | epoch: 013 | loss: 0.26221 - acc: 0.8931 -- iter: 320/508
[A[ATraining Step: 203  | total loss: [1m[32m0.26492[0m[0m | time: 7.678s
[2K
| Adam | epoch: 013 | loss: 0.26492 - acc: 0.8882 -- iter: 352/508
[A[ATraining Step: 204  | total loss: [1m[32m0.26018[0m[0m | time: 8.214s
[2K
| Adam | epoch: 013 | loss: 0.26018 - acc: 0.8922 -- iter: 384/508
[A[ATraining Step: 205  | total loss: [1m[32m0.25710[0m[0m | time: 8.829s
[2K
| Adam | epoch: 013 | loss: 0.25710 - acc: 0.8923 -- iter: 416/508
[A[ATraining Step: 206  | total loss: [1m[32m0.25231[0m[0m | time: 9.442s
[2K
| Adam | epoch: 013 | loss: 0.25231 - acc: 0.8937 -- iter: 448/508
[A[ATraining Step: 207  | total loss: [1m[32m0.24259[0m[0m | time: 10.049s
[2K
| Adam | epoch: 013 | loss: 0.24259 - acc: 0.9012 -- iter: 480/508
[A[ATraining Step: 208  | total loss: [1m[32m0.23399[0m[0m | time: 11.656s
[2K
| Adam | epoch: 013 | loss: 0.23399 - acc: 0.9048 | val_loss: 0.36724 - val_acc: 0.8812 -- iter: 508/508
--
Training Step: 209  | total loss: [1m[32m0.22834[0m[0m | time: 0.611s
[2K
| Adam | epoch: 014 | loss: 0.22834 - acc: 0.9081 -- iter: 032/508
[A[ATraining Step: 210  | total loss: [1m[32m0.21672[0m[0m | time: 1.217s
[2K
| Adam | epoch: 014 | loss: 0.21672 - acc: 0.9142 -- iter: 064/508
[A[ATraining Step: 211  | total loss: [1m[32m0.22070[0m[0m | time: 1.850s
[2K
| Adam | epoch: 014 | loss: 0.22070 - acc: 0.9102 -- iter: 096/508
[A[ATraining Step: 212  | total loss: [1m[32m0.20509[0m[0m | time: 2.459s
[2K
| Adam | epoch: 014 | loss: 0.20509 - acc: 0.9192 -- iter: 128/508
[A[ATraining Step: 213  | total loss: [1m[32m0.20246[0m[0m | time: 3.063s
[2K
| Adam | epoch: 014 | loss: 0.20246 - acc: 0.9179 -- iter: 160/508
[A[ATraining Step: 214  | total loss: [1m[32m0.20670[0m[0m | time: 3.662s
[2K
| Adam | epoch: 014 | loss: 0.20670 - acc: 0.9136 -- iter: 192/508
[A[ATraining Step: 215  | total loss: [1m[32m0.20274[0m[0m | time: 4.265s
[2K
| Adam | epoch: 014 | loss: 0.20274 - acc: 0.9191 -- iter: 224/508
[A[ATraining Step: 216  | total loss: [1m[32m0.21109[0m[0m | time: 4.875s
[2K
| Adam | epoch: 014 | loss: 0.21109 - acc: 0.9147 -- iter: 256/508
[A[ATraining Step: 217  | total loss: [1m[32m0.20003[0m[0m | time: 5.500s
[2K
| Adam | epoch: 014 | loss: 0.20003 - acc: 0.9201 -- iter: 288/508
[A[ATraining Step: 218  | total loss: [1m[32m0.20083[0m[0m | time: 6.105s
[2K
| Adam | epoch: 014 | loss: 0.20083 - acc: 0.9219 -- iter: 320/508
[A[ATraining Step: 219  | total loss: [1m[32m0.20913[0m[0m | time: 6.729s
[2K
| Adam | epoch: 014 | loss: 0.20913 - acc: 0.9172 -- iter: 352/508
[A[ATraining Step: 220  | total loss: [1m[32m0.20049[0m[0m | time: 7.260s
[2K
| Adam | epoch: 014 | loss: 0.20049 - acc: 0.9161 -- iter: 384/508
[A[ATraining Step: 221  | total loss: [1m[32m0.21201[0m[0m | time: 7.788s
[2K
| Adam | epoch: 014 | loss: 0.21201 - acc: 0.9138 -- iter: 416/508
[A[ATraining Step: 222  | total loss: [1m[32m0.22092[0m[0m | time: 8.404s
[2K
| Adam | epoch: 014 | loss: 0.22092 - acc: 0.9117 -- iter: 448/508
[A[ATraining Step: 223  | total loss: [1m[32m0.21590[0m[0m | time: 9.030s
[2K
| Adam | epoch: 014 | loss: 0.21590 - acc: 0.9111 -- iter: 480/508
[A[ATraining Step: 224  | total loss: [1m[32m0.20467[0m[0m | time: 10.646s
[2K
| Adam | epoch: 014 | loss: 0.20467 - acc: 0.9200 | val_loss: 0.43019 - val_acc: 0.8562 -- iter: 508/508
--
Training Step: 225  | total loss: [1m[32m0.21215[0m[0m | time: 0.603s
[2K
| Adam | epoch: 015 | loss: 0.21215 - acc: 0.9155 -- iter: 032/508
[A[ATraining Step: 226  | total loss: [1m[32m0.20646[0m[0m | time: 1.208s
[2K
| Adam | epoch: 015 | loss: 0.20646 - acc: 0.9177 -- iter: 064/508
[A[ATraining Step: 227  | total loss: [1m[32m0.20523[0m[0m | time: 1.811s
[2K
| Adam | epoch: 015 | loss: 0.20523 - acc: 0.9197 -- iter: 096/508
[A[ATraining Step: 228  | total loss: [1m[32m0.19778[0m[0m | time: 2.445s
[2K
| Adam | epoch: 015 | loss: 0.19778 - acc: 0.9215 -- iter: 128/508
[A[ATraining Step: 229  | total loss: [1m[32m0.18399[0m[0m | time: 3.051s
[2K
| Adam | epoch: 015 | loss: 0.18399 - acc: 0.9293 -- iter: 160/508
[A[ATraining Step: 230  | total loss: [1m[32m0.17567[0m[0m | time: 3.663s
[2K
| Adam | epoch: 015 | loss: 0.17567 - acc: 0.9333 -- iter: 192/508
[A[ATraining Step: 231  | total loss: [1m[32m0.16447[0m[0m | time: 4.264s
[2K
| Adam | epoch: 015 | loss: 0.16447 - acc: 0.9399 -- iter: 224/508
[A[ATraining Step: 232  | total loss: [1m[32m0.16781[0m[0m | time: 4.890s
[2K
| Adam | epoch: 015 | loss: 0.16781 - acc: 0.9397 -- iter: 256/508
[A[ATraining Step: 233  | total loss: [1m[32m0.16467[0m[0m | time: 5.508s
[2K
| Adam | epoch: 015 | loss: 0.16467 - acc: 0.9426 -- iter: 288/508
[A[ATraining Step: 234  | total loss: [1m[32m0.15787[0m[0m | time: 6.115s
[2K
| Adam | epoch: 015 | loss: 0.15787 - acc: 0.9452 -- iter: 320/508
[A[ATraining Step: 235  | total loss: [1m[32m0.14912[0m[0m | time: 6.722s
[2K
| Adam | epoch: 015 | loss: 0.14912 - acc: 0.9476 -- iter: 352/508
[A[ATraining Step: 236  | total loss: [1m[32m0.15750[0m[0m | time: 7.340s
[2K
| Adam | epoch: 015 | loss: 0.15750 - acc: 0.9434 -- iter: 384/508
[A[ATraining Step: 237  | total loss: [1m[32m0.15704[0m[0m | time: 7.876s
[2K
| Adam | epoch: 015 | loss: 0.15704 - acc: 0.9428 -- iter: 416/508
[A[ATraining Step: 238  | total loss: [1m[32m0.14782[0m[0m | time: 8.406s
[2K
| Adam | epoch: 015 | loss: 0.14782 - acc: 0.9486 -- iter: 448/508
[A[ATraining Step: 239  | total loss: [1m[32m0.13980[0m[0m | time: 9.010s
[2K
| Adam | epoch: 015 | loss: 0.13980 - acc: 0.9501 -- iter: 480/508
[A[ATraining Step: 240  | total loss: [1m[32m0.15742[0m[0m | time: 10.617s
[2K
| Adam | epoch: 015 | loss: 0.15742 - acc: 0.9489 | val_loss: 0.33166 - val_acc: 0.9000 -- iter: 508/508
--
Validation AUC:0.956542276806802
Validation AUPRC:0.9628959719135264
Test AUC:0.9538655329869312
Test AUPRC:0.9655580019628731
BestTestF1Score	0.91	0.79	0.89	0.87	0.94	82	12	61	5	0.46
BestTestMCCScore	0.91	0.79	0.89	0.87	0.94	82	12	61	5	0.46
BestTestAccuracyScore	0.9	0.79	0.89	0.91	0.9	78	8	65	9	0.79
BestValidationF1Score	0.92	0.81	0.91	0.88	0.95	83	11	62	4	0.46
BestValidationMCC	0.92	0.81	0.91	0.88	0.95	83	11	62	4	0.46
BestValidationAccuracy	0.91	0.81	0.91	0.91	0.92	80	8	65	7	0.79
TestPredictions (Threshold:0.46)
CHEMBL464906,TP,ACT,1.0	CHEMBL473242,TP,ACT,1.0	CHEMBL314812,FN,ACT,0.07999999821186066	CHEMBL479657,TP,ACT,1.0	CHEMBL1079732,TP,ACT,1.0	CHEMBL404199,TP,ACT,1.0	CHEMBL472754,TP,ACT,1.0	CHEMBL75169,TN,INACT,0.10999999940395355	CHEMBL284855,TN,INACT,0.03999999910593033	CHEMBL2113685,TN,INACT,0.05999999865889549	CHEMBL460325,TP,ACT,1.0	CHEMBL42129,TN,INACT,0.10000000149011612	CHEMBL465923,TP,ACT,1.0	CHEMBL412070,FN,ACT,0.019999999552965164	CHEMBL321579,TN,INACT,0.07000000029802322	CHEMBL480609,TP,ACT,1.0	CHEMBL1093124,TP,ACT,1.0	CHEMBL306907,TN,INACT,0.03999999910593033	CHEMBL1091893,TP,ACT,1.0	CHEMBL418375,TN,INACT,0.009999999776482582	CHEMBL1237302,TP,ACT,1.0	CHEMBL3589084,FN,ACT,0.09000000357627869	CHEMBL2370768,TN,INACT,0.4399999976158142	CHEMBL465947,TP,ACT,1.0	CHEMBL141291,TN,INACT,0.1899999976158142	CHEMBL399000,FP,INACT,0.8399999737739563	CHEMBL1916708,TN,INACT,0.12999999523162842	CHEMBL461807,TP,ACT,1.0	CHEMBL520290,TP,ACT,1.0	CHEMBL566005,TP,ACT,1.0	CHEMBL293232,TN,INACT,0.07000000029802322	CHEMBL3799257,TP,ACT,0.49000000953674316	CHEMBL490896,TP,ACT,1.0	CHEMBL3114151,TN,INACT,0.029999999329447746	CHEMBL585507,TP,ACT,1.0	CHEMBL3794245,TN,INACT,0.3799999952316284	CHEMBL90491,TP,ACT,0.9800000190734863	CHEMBL461390,TP,ACT,1.0	CHEMBL64239,TN,INACT,0.009999999776482582	CHEMBL257684,TN,INACT,0.019999999552965164	CHEMBL179638,TN,INACT,0.11999999731779099	CHEMBL3410305,TN,INACT,0.41999998688697815	CHEMBL517282,TP,ACT,1.0	CHEMBL392115,TN,INACT,0.009999999776482582	CHEMBL86799,TP,ACT,1.0	CHEMBL321178,FP,INACT,0.5199999809265137	CHEMBL347423,TN,INACT,0.03999999910593033	CHEMBL1086634,TP,ACT,1.0	CHEMBL1237299,TP,ACT,1.0	CHEMBL3798872,TP,ACT,0.8799999952316284	CHEMBL89358,TN,INACT,0.019999999552965164	CHEMBL2164609,TP,ACT,0.9800000190734863	CHEMBL551813,TN,INACT,0.3799999952316284	CHEMBL48031,TN,INACT,0.11999999731779099	CHEMBL2112320,TN,INACT,0.009999999776482582	CHEMBL520918,TP,ACT,1.0	CHEMBL518110,TP,ACT,1.0	CHEMBL576509,TP,ACT,0.49000000953674316	CHEMBL520425,TP,ACT,0.9900000095367432	CHEMBL424975,TP,ACT,1.0	CHEMBL89494,TN,INACT,0.019999999552965164	CHEMBL3586309,TN,INACT,0.07999999821186066	CHEMBL520741,TP,ACT,1.0	CHEMBL319356,TN,INACT,0.019999999552965164	CHEMBL170335,TN,INACT,0.41999998688697815	CHEMBL125110,TP,ACT,1.0	CHEMBL26455,TN,INACT,0.019999999552965164	CHEMBL506888,TN,INACT,0.009999999776482582	CHEMBL1088846,TP,ACT,1.0	CHEMBL2204336,TP,ACT,0.9599999785423279	CHEMBL218123,TP,ACT,0.8100000023841858	CHEMBL1088284,TN,INACT,0.10000000149011612	CHEMBL1092229,TP,ACT,1.0	CHEMBL289568,TP,ACT,1.0	CHEMBL283057,TN,INACT,0.03999999910593033	CHEMBL28626,TN,INACT,0.03999999910593033	CHEMBL585483,TP,ACT,1.0	CHEMBL314533,TP,ACT,0.9900000095367432	CHEMBL2371240,FP,INACT,1.0	CHEMBL1765671,TN,INACT,0.05000000074505806	CHEMBL282310,TN,INACT,0.009999999776482582	CHEMBL337552,TN,INACT,0.019999999552965164	CHEMBL3753853,TP,ACT,0.8199999928474426	CHEMBL441145,TN,INACT,0.03999999910593033	CHEMBL516789,TP,ACT,1.0	CHEMBL36041,TP,ACT,1.0	CHEMBL132222,TN,INACT,0.0	CHEMBL445895,TP,ACT,1.0	CHEMBL1916686,FP,INACT,0.9200000166893005	CHEMBL123855,TP,ACT,0.9900000095367432	CHEMBL2373410,TP,ACT,0.9399999976158142	CHEMBL3752377,TP,ACT,0.8700000047683716	CHEMBL608462,TN,INACT,0.009999999776482582	CHEMBL67228,TN,INACT,0.03999999910593033	CHEMBL29782,TN,INACT,0.009999999776482582	CHEMBL130596,TN,INACT,0.029999999329447746	CHEMBL348766,TN,INACT,0.03999999910593033	CHEMBL1082084,TP,ACT,1.0	CHEMBL127482,TP,ACT,1.0	CHEMBL1237315,TP,ACT,0.800000011920929	CHEMBL3797362,FN,ACT,0.3400000035762787	CHEMBL484778,FN,ACT,0.05999999865889549	CHEMBL103433,TN,INACT,0.07000000029802322	CHEMBL1091621,TP,ACT,1.0	CHEMBL464618,TP,ACT,1.0	CHEMBL567265,TP,ACT,1.0	CHEMBL78830,TN,INACT,0.029999999329447746	CHEMBL218071,TP,ACT,0.6800000071525574	CHEMBL86886,TP,ACT,0.9800000190734863	CHEMBL1084009,TP,ACT,0.9900000095367432	CHEMBL566014,FP,INACT,0.9700000286102295	CHEMBL262690,TP,ACT,0.9800000190734863	CHEMBL336033,FP,INACT,0.8700000047683716	CHEMBL64784,TN,INACT,0.009999999776482582	CHEMBL414605,FP,INACT,0.6600000262260437	CHEMBL97770,TN,INACT,0.019999999552965164	CHEMBL3753221,TP,ACT,0.8600000143051147	CHEMBL76779,TN,INACT,0.029999999329447746	CHEMBL565797,TP,ACT,0.9800000190734863	CHEMBL73933,TN,INACT,0.029999999329447746	CHEMBL100071,TN,INACT,0.009999999776482582	CHEMBL10801,TN,INACT,0.07999999821186066	CHEMBL251505,TP,ACT,0.8399999737739563	CHEMBL39986,TN,INACT,0.009999999776482582	CHEMBL280442,TP,ACT,0.8700000047683716	CHEMBL464271,TP,ACT,1.0	CHEMBL517994,TP,ACT,1.0	CHEMBL465915,TP,ACT,1.0	CHEMBL521777,TP,ACT,1.0	CHEMBL251294,TP,ACT,0.46000000834465027	CHEMBL481183,TP,ACT,1.0	CHEMBL1090889,TP,ACT,1.0	CHEMBL91786,TN,INACT,0.009999999776482582	CHEMBL108705,TN,INACT,0.12999999523162842	CHEMBL210457,FP,INACT,0.8600000143051147	CHEMBL464031,TP,ACT,1.0	CHEMBL1081185,TP,ACT,0.9900000095367432	CHEMBL585582,TP,ACT,1.0	CHEMBL2112561,TN,INACT,0.029999999329447746	CHEMBL490692,TP,ACT,1.0	CHEMBL75002,TN,INACT,0.009999999776482582	CHEMBL120278,TN,INACT,0.18000000715255737	CHEMBL74328,FP,INACT,0.7599999904632568	CHEMBL481228,TP,ACT,1.0	CHEMBL114886,FP,INACT,0.8600000143051147	CHEMBL566013,TP,ACT,0.9900000095367432	CHEMBL218263,TP,ACT,0.9700000286102295	CHEMBL565992,TP,ACT,1.0	CHEMBL80945,TN,INACT,0.20999999344348907	CHEMBL417358,FP,INACT,0.8500000238418579	CHEMBL3799530,TP,ACT,0.8399999737739563	CHEMBL1092871,TP,ACT,1.0	CHEMBL463816,TP,ACT,1.0	CHEMBL24289,TN,INACT,0.019999999552965164	CHEMBL1086633,TP,ACT,0.9900000095367432	CHEMBL104848,TN,INACT,0.3100000023841858	CHEMBL280367,TN,INACT,0.009999999776482582	CHEMBL283535,FP,INACT,0.6000000238418579	CHEMBL480992,TP,ACT,1.0	CHEMBL421523,TN,INACT,0.09000000357627869	

