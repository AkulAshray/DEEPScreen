ImageNetInceptionV2 CHEMBL3912 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	191
Number of inactive compounds :	191
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3912_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3912_adam_0.0001_15_0.6/
---------------------------------
Training samples: 242
Validation samples: 76
--
Training Step: 1  | time: 85.383s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/242
[A[ATraining Step: 2  | total loss: [1m[32m0.62079[0m[0m | time: 107.885s
[2K
| Adam | epoch: 001 | loss: 0.62079 - acc: 0.5344 -- iter: 064/242
[A[ATraining Step: 3  | total loss: [1m[32m0.62411[0m[0m | time: 120.751s
[2K
| Adam | epoch: 001 | loss: 0.62411 - acc: 0.6341 -- iter: 096/242
[A[ATraining Step: 4  | total loss: [1m[32m0.66772[0m[0m | time: 176.806s
[2K
| Adam | epoch: 001 | loss: 0.66772 - acc: 0.6038 -- iter: 128/242
[A[ATraining Step: 5  | total loss: [1m[32m0.64102[0m[0m | time: 222.608s
[2K
| Adam | epoch: 001 | loss: 0.64102 - acc: 0.6401 -- iter: 160/242
[A[ATraining Step: 6  | total loss: [1m[32m0.67473[0m[0m | time: 258.976s
[2K
| Adam | epoch: 001 | loss: 0.67473 - acc: 0.5701 -- iter: 192/242
[A[ATraining Step: 7  | total loss: [1m[32m0.62518[0m[0m | time: 303.042s
[2K
| Adam | epoch: 001 | loss: 0.62518 - acc: 0.6406 -- iter: 224/242
[A[ATraining Step: 8  | total loss: [1m[32m0.60137[0m[0m | time: 372.963s
[2K
| Adam | epoch: 001 | loss: 0.60137 - acc: 0.6494 | val_loss: 0.81074 - val_acc: 0.4737 -- iter: 242/242
--
Training Step: 9  | total loss: [1m[32m0.63842[0m[0m | time: 7.534s
[2K
| Adam | epoch: 002 | loss: 0.63842 - acc: 0.5997 -- iter: 032/242
[A[ATraining Step: 10  | total loss: [1m[32m0.58222[0m[0m | time: 19.977s
[2K
| Adam | epoch: 002 | loss: 0.58222 - acc: 0.6332 -- iter: 064/242
[A[ATraining Step: 11  | total loss: [1m[32m0.67365[0m[0m | time: 46.325s
[2K
| Adam | epoch: 002 | loss: 0.67365 - acc: 0.5997 -- iter: 096/242
[A[ATraining Step: 12  | total loss: [1m[32m0.59977[0m[0m | time: 83.094s
[2K
| Adam | epoch: 002 | loss: 0.59977 - acc: 0.6814 -- iter: 128/242
[A[ATraining Step: 13  | total loss: [1m[32m0.53157[0m[0m | time: 101.187s
[2K
| Adam | epoch: 002 | loss: 0.53157 - acc: 0.7778 -- iter: 160/242
[A[ATraining Step: 14  | total loss: [1m[32m0.50214[0m[0m | time: 133.395s
[2K
| Adam | epoch: 002 | loss: 0.50214 - acc: 0.8303 -- iter: 192/242
[A[ATraining Step: 15  | total loss: [1m[32m0.50624[0m[0m | time: 162.210s
[2K
| Adam | epoch: 002 | loss: 0.50624 - acc: 0.8234 -- iter: 224/242
[A[ATraining Step: 16  | total loss: [1m[32m0.47538[0m[0m | time: 221.174s
[2K
| Adam | epoch: 002 | loss: 0.47538 - acc: 0.8544 | val_loss: 0.74036 - val_acc: 0.5263 -- iter: 242/242
--
Training Step: 17  | total loss: [1m[32m0.43562[0m[0m | time: 7.547s
[2K
| Adam | epoch: 003 | loss: 0.43562 - acc: 0.8956 -- iter: 032/242
[A[ATraining Step: 18  | total loss: [1m[32m0.41195[0m[0m | time: 15.295s
[2K
| Adam | epoch: 003 | loss: 0.41195 - acc: 0.8933 -- iter: 064/242
[A[ATraining Step: 19  | total loss: [1m[32m0.37553[0m[0m | time: 31.249s
[2K
| Adam | epoch: 003 | loss: 0.37553 - acc: 0.9103 -- iter: 096/242
[A[ATraining Step: 20  | total loss: [1m[32m0.37354[0m[0m | time: 49.937s
[2K
| Adam | epoch: 003 | loss: 0.37354 - acc: 0.9090 -- iter: 128/242
[A[ATraining Step: 21  | total loss: [1m[32m0.36695[0m[0m | time: 68.450s
[2K
| Adam | epoch: 003 | loss: 0.36695 - acc: 0.8985 -- iter: 160/242
[A[ATraining Step: 22  | total loss: [1m[32m0.34130[0m[0m | time: 87.123s
[2K
| Adam | epoch: 003 | loss: 0.34130 - acc: 0.9008 -- iter: 192/242
[A[ATraining Step: 23  | total loss: [1m[32m0.29786[0m[0m | time: 105.955s
[2K
| Adam | epoch: 003 | loss: 0.29786 - acc: 0.9296 -- iter: 224/242
[A[ATraining Step: 24  | total loss: [1m[32m0.26601[0m[0m | time: 131.319s
[2K
| Adam | epoch: 003 | loss: 0.26601 - acc: 0.9494 | val_loss: 0.68920 - val_acc: 0.5658 -- iter: 242/242
--
Training Step: 25  | total loss: [1m[32m0.23835[0m[0m | time: 13.235s
[2K
| Adam | epoch: 004 | loss: 0.23835 - acc: 0.9547 -- iter: 032/242
[A[ATraining Step: 26  | total loss: [1m[32m0.23032[0m[0m | time: 20.664s
[2K
| Adam | epoch: 004 | loss: 0.23032 - acc: 0.9419 -- iter: 064/242
[A[ATraining Step: 27  | total loss: [1m[32m0.23323[0m[0m | time: 28.303s
[2K
| Adam | epoch: 004 | loss: 0.23323 - acc: 0.9425 -- iter: 096/242
[A[ATraining Step: 28  | total loss: [1m[32m0.21036[0m[0m | time: 47.740s
[2K
| Adam | epoch: 004 | loss: 0.21036 - acc: 0.9569 -- iter: 128/242
[A[ATraining Step: 29  | total loss: [1m[32m0.18363[0m[0m | time: 65.553s
[2K
| Adam | epoch: 004 | loss: 0.18363 - acc: 0.9674 -- iter: 160/242
[A[ATraining Step: 30  | total loss: [1m[32m0.16061[0m[0m | time: 84.030s
[2K
| Adam | epoch: 004 | loss: 0.16061 - acc: 0.9751 -- iter: 192/242
[A[ATraining Step: 31  | total loss: [1m[32m0.34516[0m[0m | time: 100.289s
[2K
| Adam | epoch: 004 | loss: 0.34516 - acc: 0.9159 -- iter: 224/242
[A[ATraining Step: 32  | total loss: [1m[32m0.27834[0m[0m | time: 124.560s
[2K
| Adam | epoch: 004 | loss: 0.27834 - acc: 0.9349 | val_loss: 0.72061 - val_acc: 0.5263 -- iter: 242/242
--
Training Step: 33  | total loss: [1m[32m0.22380[0m[0m | time: 19.071s
[2K
| Adam | epoch: 005 | loss: 0.22380 - acc: 0.9492 -- iter: 032/242
[A[ATraining Step: 34  | total loss: [1m[32m0.18444[0m[0m | time: 36.488s
[2K
| Adam | epoch: 005 | loss: 0.18444 - acc: 0.9601 -- iter: 064/242
[A[ATraining Step: 35  | total loss: [1m[32m0.15864[0m[0m | time: 45.204s
[2K
| Adam | epoch: 005 | loss: 0.15864 - acc: 0.9684 -- iter: 096/242
[A[ATraining Step: 36  | total loss: [1m[32m0.13672[0m[0m | time: 52.635s
[2K
| Adam | epoch: 005 | loss: 0.13672 - acc: 0.9749 -- iter: 128/242
[A[ATraining Step: 37  | total loss: [1m[32m0.11350[0m[0m | time: 65.513s
[2K
| Adam | epoch: 005 | loss: 0.11350 - acc: 0.9799 -- iter: 160/242
[A[ATraining Step: 38  | total loss: [1m[32m0.09474[0m[0m | time: 97.242s
[2K
| Adam | epoch: 005 | loss: 0.09474 - acc: 0.9838 -- iter: 192/242
[A[ATraining Step: 39  | total loss: [1m[32m0.12340[0m[0m | time: 114.560s
[2K
| Adam | epoch: 005 | loss: 0.12340 - acc: 0.9750 -- iter: 224/242
[A[ATraining Step: 40  | total loss: [1m[32m0.10410[0m[0m | time: 146.160s
[2K
| Adam | epoch: 005 | loss: 0.10410 - acc: 0.9797 | val_loss: 0.67958 - val_acc: 0.5921 -- iter: 242/242
--
Training Step: 41  | total loss: [1m[32m0.09861[0m[0m | time: 14.528s
[2K
| Adam | epoch: 006 | loss: 0.09861 - acc: 0.9777 -- iter: 032/242
[A[ATraining Step: 42  | total loss: [1m[32m0.08713[0m[0m | time: 35.130s
[2K
| Adam | epoch: 006 | loss: 0.08713 - acc: 0.9760 -- iter: 064/242
[A[ATraining Step: 43  | total loss: [1m[32m0.07394[0m[0m | time: 47.203s
[2K
| Adam | epoch: 006 | loss: 0.07394 - acc: 0.9803 -- iter: 096/242
[A[ATraining Step: 44  | total loss: [1m[32m0.06438[0m[0m | time: 54.662s
[2K
| Adam | epoch: 006 | loss: 0.06438 - acc: 0.9837 -- iter: 128/242
[A[ATraining Step: 45  | total loss: [1m[32m0.06037[0m[0m | time: 62.667s
[2K
| Adam | epoch: 006 | loss: 0.06037 - acc: 0.9865 -- iter: 160/242
[A[ATraining Step: 46  | total loss: [1m[32m0.05412[0m[0m | time: 75.314s
[2K
| Adam | epoch: 006 | loss: 0.05412 - acc: 0.9887 -- iter: 192/242
[A[ATraining Step: 47  | total loss: [1m[32m0.05071[0m[0m | time: 113.756s
[2K
| Adam | epoch: 006 | loss: 0.05071 - acc: 0.9906 -- iter: 224/242
[A[ATraining Step: 48  | total loss: [1m[32m0.04930[0m[0m | time: 153.186s
[2K
| Adam | epoch: 006 | loss: 0.04930 - acc: 0.9871 | val_loss: 1.21842 - val_acc: 0.5263 -- iter: 242/242
--
Training Step: 49  | total loss: [1m[32m0.04268[0m[0m | time: 16.719s
[2K
| Adam | epoch: 007 | loss: 0.04268 - acc: 0.9891 -- iter: 032/242
[A[ATraining Step: 50  | total loss: [1m[32m0.03705[0m[0m | time: 32.979s
[2K
| Adam | epoch: 007 | loss: 0.03705 - acc: 0.9908 -- iter: 064/242
[A[ATraining Step: 51  | total loss: [1m[32m0.03484[0m[0m | time: 50.935s
[2K
| Adam | epoch: 007 | loss: 0.03484 - acc: 0.9922 -- iter: 096/242
[A[ATraining Step: 52  | total loss: [1m[32m0.03119[0m[0m | time: 65.672s
[2K
| Adam | epoch: 007 | loss: 0.03119 - acc: 0.9934 -- iter: 128/242
[A[ATraining Step: 53  | total loss: [1m[32m0.02746[0m[0m | time: 76.303s
[2K
| Adam | epoch: 007 | loss: 0.02746 - acc: 0.9943 -- iter: 160/242
[A[ATraining Step: 54  | total loss: [1m[32m0.02465[0m[0m | time: 84.524s
[2K
| Adam | epoch: 007 | loss: 0.02465 - acc: 0.9952 -- iter: 192/242
[A[ATraining Step: 55  | total loss: [1m[32m0.02205[0m[0m | time: 96.219s
[2K
| Adam | epoch: 007 | loss: 0.02205 - acc: 0.9959 -- iter: 224/242
[A[ATraining Step: 56  | total loss: [1m[32m0.01950[0m[0m | time: 119.453s
[2K
| Adam | epoch: 007 | loss: 0.01950 - acc: 0.9964 | val_loss: 1.01262 - val_acc: 0.5789 -- iter: 242/242
--
Training Step: 57  | total loss: [1m[32m0.01788[0m[0m | time: 60.764s
[2K
| Adam | epoch: 008 | loss: 0.01788 - acc: 0.9969 -- iter: 032/242
[A[ATraining Step: 58  | total loss: [1m[32m0.01610[0m[0m | time: 121.616s
[2K
| Adam | epoch: 008 | loss: 0.01610 - acc: 0.9974 -- iter: 064/242
[A[ATraining Step: 59  | total loss: [1m[32m0.01512[0m[0m | time: 186.625s
[2K
| Adam | epoch: 008 | loss: 0.01512 - acc: 0.9977 -- iter: 096/242
[A[ATraining Step: 60  | total loss: [1m[32m0.01345[0m[0m | time: 223.938s
[2K
| Adam | epoch: 008 | loss: 0.01345 - acc: 0.9980 -- iter: 128/242
[A[ATraining Step: 61  | total loss: [1m[32m0.01532[0m[0m | time: 236.112s
[2K
| Adam | epoch: 008 | loss: 0.01532 - acc: 0.9983 -- iter: 160/242
[A[ATraining Step: 62  | total loss: [1m[32m0.01393[0m[0m | time: 243.977s
[2K
| Adam | epoch: 008 | loss: 0.01393 - acc: 0.9985 -- iter: 192/242
[A[ATraining Step: 63  | total loss: [1m[32m0.01283[0m[0m | time: 251.498s
[2K
| Adam | epoch: 008 | loss: 0.01283 - acc: 0.9987 -- iter: 224/242
[A[ATraining Step: 64  | total loss: [1m[32m0.01155[0m[0m | time: 270.387s
[2K
| Adam | epoch: 008 | loss: 0.01155 - acc: 0.9988 | val_loss: 0.80574 - val_acc: 0.6974 -- iter: 242/242
--
Training Step: 65  | total loss: [1m[32m0.01076[0m[0m | time: 17.147s
[2K
| Adam | epoch: 009 | loss: 0.01076 - acc: 0.9990 -- iter: 032/242
[A[ATraining Step: 66  | total loss: [1m[32m0.00960[0m[0m | time: 33.499s
[2K
| Adam | epoch: 009 | loss: 0.00960 - acc: 0.9991 -- iter: 064/242
[A[ATraining Step: 67  | total loss: [1m[32m0.05596[0m[0m | time: 49.733s
[2K
| Adam | epoch: 009 | loss: 0.05596 - acc: 0.9917 -- iter: 096/242
[A[ATraining Step: 68  | total loss: [1m[32m0.05343[0m[0m | time: 66.311s
[2K
| Adam | epoch: 009 | loss: 0.05343 - acc: 0.9927 -- iter: 128/242
[A[ATraining Step: 69  | total loss: [1m[32m0.04746[0m[0m | time: 86.490s
[2K
| Adam | epoch: 009 | loss: 0.04746 - acc: 0.9936 -- iter: 160/242
[A[ATraining Step: 70  | total loss: [1m[32m0.04258[0m[0m | time: 103.058s
[2K
| Adam | epoch: 009 | loss: 0.04258 - acc: 0.9943 -- iter: 192/242
[A[ATraining Step: 71  | total loss: [1m[32m0.03820[0m[0m | time: 113.452s
[2K
| Adam | epoch: 009 | loss: 0.03820 - acc: 0.9949 -- iter: 224/242
[A[ATraining Step: 72  | total loss: [1m[32m0.03419[0m[0m | time: 132.252s
[2K
| Adam | epoch: 009 | loss: 0.03419 - acc: 0.9955 | val_loss: 1.94201 - val_acc: 0.5789 -- iter: 242/242
--
Training Step: 73  | total loss: [1m[32m0.03062[0m[0m | time: 12.501s
[2K
| Adam | epoch: 010 | loss: 0.03062 - acc: 0.9960 -- iter: 032/242
[A[ATraining Step: 74  | total loss: [1m[32m0.02746[0m[0m | time: 27.775s
[2K
| Adam | epoch: 010 | loss: 0.02746 - acc: 0.9965 -- iter: 064/242
[A[ATraining Step: 75  | total loss: [1m[32m0.02603[0m[0m | time: 44.300s
[2K
| Adam | epoch: 010 | loss: 0.02603 - acc: 0.9968 -- iter: 096/242
[A[ATraining Step: 76  | total loss: [1m[32m0.08427[0m[0m | time: 60.914s
[2K
| Adam | epoch: 010 | loss: 0.08427 - acc: 0.9871 -- iter: 128/242
[A[ATraining Step: 77  | total loss: [1m[32m0.07552[0m[0m | time: 77.104s
[2K
| Adam | epoch: 010 | loss: 0.07552 - acc: 0.9885 -- iter: 160/242
[A[ATraining Step: 78  | total loss: [1m[32m0.07024[0m[0m | time: 93.163s
[2K
| Adam | epoch: 010 | loss: 0.07024 - acc: 0.9897 -- iter: 192/242
[A[ATraining Step: 79  | total loss: [1m[32m0.06349[0m[0m | time: 109.912s
[2K
| Adam | epoch: 010 | loss: 0.06349 - acc: 0.9908 -- iter: 224/242
[A[ATraining Step: 80  | total loss: [1m[32m0.05729[0m[0m | time: 128.360s
[2K
| Adam | epoch: 010 | loss: 0.05729 - acc: 0.9917 | val_loss: 2.11785 - val_acc: 0.5789 -- iter: 242/242
--
Training Step: 81  | total loss: [1m[32m0.05175[0m[0m | time: 8.143s
[2K
| Adam | epoch: 011 | loss: 0.05175 - acc: 0.9925 -- iter: 032/242
[A[ATraining Step: 82  | total loss: [1m[32m0.04698[0m[0m | time: 20.558s
[2K
| Adam | epoch: 011 | loss: 0.04698 - acc: 0.9933 -- iter: 064/242
[A[ATraining Step: 83  | total loss: [1m[32m0.05966[0m[0m | time: 34.747s
[2K
| Adam | epoch: 011 | loss: 0.05966 - acc: 0.9908 -- iter: 096/242
[A[ATraining Step: 84  | total loss: [1m[32m0.09324[0m[0m | time: 50.243s
[2K
| Adam | epoch: 011 | loss: 0.09324 - acc: 0.9855 -- iter: 128/242
[A[ATraining Step: 85  | total loss: [1m[32m0.10560[0m[0m | time: 66.445s
[2K
| Adam | epoch: 011 | loss: 0.10560 - acc: 0.9807 -- iter: 160/242
[A[ATraining Step: 86  | total loss: [1m[32m0.09643[0m[0m | time: 84.004s
[2K
| Adam | epoch: 011 | loss: 0.09643 - acc: 0.9826 -- iter: 192/242
[A[ATraining Step: 87  | total loss: [1m[32m0.08786[0m[0m | time: 101.658s
[2K
| Adam | epoch: 011 | loss: 0.08786 - acc: 0.9844 -- iter: 224/242
[A[ATraining Step: 88  | total loss: [1m[32m0.10262[0m[0m | time: 125.891s
[2K
| Adam | epoch: 011 | loss: 0.10262 - acc: 0.9797 | val_loss: 1.54211 - val_acc: 0.6053 -- iter: 242/242
--
Training Step: 89  | total loss: [1m[32m0.09325[0m[0m | time: 10.695s
[2K
| Adam | epoch: 012 | loss: 0.09325 - acc: 0.9817 -- iter: 032/242
[A[ATraining Step: 90  | total loss: [1m[32m0.08462[0m[0m | time: 21.145s
[2K
| Adam | epoch: 012 | loss: 0.08462 - acc: 0.9835 -- iter: 064/242
[A[ATraining Step: 91  | total loss: [1m[32m0.07679[0m[0m | time: 33.490s
[2K
| Adam | epoch: 012 | loss: 0.07679 - acc: 0.9852 -- iter: 096/242
[A[ATraining Step: 92  | total loss: [1m[32m0.07059[0m[0m | time: 46.341s
[2K
| Adam | epoch: 012 | loss: 0.07059 - acc: 0.9867 -- iter: 128/242
[A[ATraining Step: 93  | total loss: [1m[32m0.06743[0m[0m | time: 65.453s
[2K
| Adam | epoch: 012 | loss: 0.06743 - acc: 0.9880 -- iter: 160/242
[A[ATraining Step: 94  | total loss: [1m[32m0.10643[0m[0m | time: 85.850s
[2K
| Adam | epoch: 012 | loss: 0.10643 - acc: 0.9830 -- iter: 192/242
[A[ATraining Step: 95  | total loss: [1m[32m0.09835[0m[0m | time: 101.218s
[2K
| Adam | epoch: 012 | loss: 0.09835 - acc: 0.9847 -- iter: 224/242
[A[ATraining Step: 96  | total loss: [1m[32m0.08924[0m[0m | time: 125.324s
[2K
| Adam | epoch: 012 | loss: 0.08924 - acc: 0.9862 | val_loss: 1.39270 - val_acc: 0.6579 -- iter: 242/242
--
Training Step: 97  | total loss: [1m[32m0.08118[0m[0m | time: 16.792s
[2K
| Adam | epoch: 013 | loss: 0.08118 - acc: 0.9876 -- iter: 032/242
[A[ATraining Step: 98  | total loss: [1m[32m0.07486[0m[0m | time: 27.228s
[2K
| Adam | epoch: 013 | loss: 0.07486 - acc: 0.9888 -- iter: 064/242
[A[ATraining Step: 99  | total loss: [1m[32m0.07252[0m[0m | time: 37.129s
[2K
| Adam | epoch: 013 | loss: 0.07252 - acc: 0.9844 -- iter: 096/242
[A[ATraining Step: 100  | total loss: [1m[32m0.06622[0m[0m | time: 52.000s
[2K
| Adam | epoch: 013 | loss: 0.06622 - acc: 0.9859 -- iter: 128/242
[A[ATraining Step: 101  | total loss: [1m[32m0.07022[0m[0m | time: 63.840s
[2K
| Adam | epoch: 013 | loss: 0.07022 - acc: 0.9842 -- iter: 160/242
[A[ATraining Step: 102  | total loss: [1m[32m0.06461[0m[0m | time: 77.923s
[2K
| Adam | epoch: 013 | loss: 0.06461 - acc: 0.9858 -- iter: 192/242
[A[ATraining Step: 103  | total loss: [1m[32m0.07694[0m[0m | time: 94.453s
[2K
| Adam | epoch: 013 | loss: 0.07694 - acc: 0.9841 -- iter: 224/242
[A[ATraining Step: 104  | total loss: [1m[32m0.07293[0m[0m | time: 118.494s
[2K
| Adam | epoch: 013 | loss: 0.07293 - acc: 0.9857 | val_loss: 0.95886 - val_acc: 0.7105 -- iter: 242/242
--
Training Step: 105  | total loss: [1m[32m0.06631[0m[0m | time: 29.975s
[2K
| Adam | epoch: 014 | loss: 0.06631 - acc: 0.9871 -- iter: 032/242
[A[ATraining Step: 106  | total loss: [1m[32m0.06210[0m[0m | time: 51.943s
[2K
| Adam | epoch: 014 | loss: 0.06210 - acc: 0.9884 -- iter: 064/242
[A[ATraining Step: 107  | total loss: [1m[32m0.05663[0m[0m | time: 62.055s
[2K
| Adam | epoch: 014 | loss: 0.05663 - acc: 0.9896 -- iter: 096/242
[A[ATraining Step: 108  | total loss: [1m[32m0.05353[0m[0m | time: 72.560s
[2K
| Adam | epoch: 014 | loss: 0.05353 - acc: 0.9906 -- iter: 128/242
[A[ATraining Step: 109  | total loss: [1m[32m0.04908[0m[0m | time: 86.571s
[2K
| Adam | epoch: 014 | loss: 0.04908 - acc: 0.9915 -- iter: 160/242
[A[ATraining Step: 110  | total loss: [1m[32m0.04749[0m[0m | time: 98.335s
[2K
| Adam | epoch: 014 | loss: 0.04749 - acc: 0.9924 -- iter: 192/242
[A[ATraining Step: 111  | total loss: [1m[32m0.07467[0m[0m | time: 112.833s
[2K
| Adam | epoch: 014 | loss: 0.07467 - acc: 0.9900 -- iter: 224/242
[A[ATraining Step: 112  | total loss: [1m[32m0.11189[0m[0m | time: 137.464s
[2K
| Adam | epoch: 014 | loss: 0.11189 - acc: 0.9848 | val_loss: 1.11763 - val_acc: 0.6316 -- iter: 242/242
--
Training Step: 113  | total loss: [1m[32m0.10149[0m[0m | time: 15.106s
[2K
| Adam | epoch: 015 | loss: 0.10149 - acc: 0.9863 -- iter: 032/242
[A[ATraining Step: 114  | total loss: [1m[32m0.09189[0m[0m | time: 31.739s
[2K
| Adam | epoch: 015 | loss: 0.09189 - acc: 0.9877 -- iter: 064/242
[A[ATraining Step: 115  | total loss: [1m[32m0.09902[0m[0m | time: 48.646s
[2K
| Adam | epoch: 015 | loss: 0.09902 - acc: 0.9858 -- iter: 096/242
[A[ATraining Step: 116  | total loss: [1m[32m0.09017[0m[0m | time: 59.040s
[2K
| Adam | epoch: 015 | loss: 0.09017 - acc: 0.9872 -- iter: 128/242
[A[ATraining Step: 117  | total loss: [1m[32m0.08195[0m[0m | time: 69.801s
[2K
| Adam | epoch: 015 | loss: 0.08195 - acc: 0.9885 -- iter: 160/242
[A[ATraining Step: 118  | total loss: [1m[32m0.07453[0m[0m | time: 87.148s
[2K
| Adam | epoch: 015 | loss: 0.07453 - acc: 0.9896 -- iter: 192/242
[A[ATraining Step: 119  | total loss: [1m[32m0.06826[0m[0m | time: 99.849s
[2K
| Adam | epoch: 015 | loss: 0.06826 - acc: 0.9907 -- iter: 224/242
[A[ATraining Step: 120  | total loss: [1m[32m0.06208[0m[0m | time: 121.702s
[2K
| Adam | epoch: 015 | loss: 0.06208 - acc: 0.9916 | val_loss: 0.67690 - val_acc: 0.7500 -- iter: 242/242
--
Validation AUC:0.7965277777777777
Validation AUPRC:0.7973404103001537
Test AUC:0.8433818433818434
Test AUPRC:0.877352862508274
BestTestF1Score	0.74	0.53	0.76	0.79	0.7	26	7	32	11	0.51
BestTestMCCScore	0.77	0.66	0.82	0.96	0.65	24	1	38	13	0.77
BestTestAccuracyScore	0.77	0.66	0.82	0.96	0.65	24	1	38	13	0.77
BestValidationF1Score	0.72	0.5	0.75	0.77	0.67	24	7	33	12	0.51
BestValidationMCC	0.68	0.52	0.75	0.87	0.56	20	3	37	16	0.77
BestValidationAccuracy	0.68	0.52	0.75	0.87	0.56	20	3	37	16	0.77
TestPredictions (Threshold:0.77)
CHEMBL865,FN,ACT,0.12999999523162842	CHEMBL3799296,FN,ACT,0.28999999165534973	CHEMBL1232443,FN,ACT,0.6299999952316284	CHEMBL19,FN,ACT,0.20999999344348907	CHEMBL2010998,TP,ACT,0.9800000190734863	CHEMBL2443190,TP,ACT,0.9399999976158142	CHEMBL1161632,TN,INACT,0.0	CHEMBL3356279,TN,INACT,0.5799999833106995	CHEMBL2443207,TP,ACT,0.8199999928474426	CHEMBL1885780,TN,INACT,0.07999999821186066	CHEMBL2069541,TN,INACT,0.18000000715255737	CHEMBL235471,TN,INACT,0.49000000953674316	CHEMBL1272298,FN,ACT,0.2199999988079071	CHEMBL2333402,TP,ACT,0.9300000071525574	CHEMBL3137798,TN,INACT,0.09000000357627869	CHEMBL3138422,TN,INACT,0.10999999940395355	CHEMBL100580,TN,INACT,0.14000000059604645	CHEMBL20,FN,ACT,0.28999999165534973	CHEMBL13766,TN,INACT,0.0	CHEMBL3138364,TN,INACT,0.10999999940395355	CHEMBL189526,FN,ACT,0.25	CHEMBL3137759,TN,INACT,0.0	CHEMBL568417,TN,INACT,0.3700000047683716	CHEMBL123982,TN,INACT,0.11999999731779099	CHEMBL251680,FN,ACT,0.10999999940395355	CHEMBL2443198,TP,ACT,0.9399999976158142	CHEMBL116438,FN,ACT,0.10000000149011612	CHEMBL568416,TN,INACT,0.5600000023841858	CHEMBL2443206,TP,ACT,0.949999988079071	CHEMBL258230,TN,INACT,0.6100000143051147	CHEMBL6648,TN,INACT,0.0	CHEMBL1272242,FN,ACT,0.0	CHEMBL3110149,TN,INACT,0.15000000596046448	CHEMBL1822701,FN,ACT,0.23000000417232513	CHEMBL3797385,TP,ACT,0.9300000071525574	CHEMBL3798473,TP,ACT,0.9200000166893005	CHEMBL2334351,TN,INACT,0.03999999910593033	CHEMBL99958,TN,INACT,0.25999999046325684	CHEMBL2326507,TN,INACT,0.6399999856948853	CHEMBL2443205,TP,ACT,0.9800000190734863	CHEMBL253551,FN,ACT,0.5400000214576721	CHEMBL344237,TN,INACT,0.2800000011920929	CHEMBL1461,TN,INACT,0.03999999910593033	CHEMBL385073,TN,INACT,0.4300000071525574	CHEMBL1209039,FN,ACT,0.30000001192092896	CHEMBL2443196,TP,ACT,1.0	CHEMBL2443197,TP,ACT,0.9800000190734863	CHEMBL148680,TN,INACT,0.009999999776482582	CHEMBL139023,FP,INACT,0.8999999761581421	CHEMBL171095,TN,INACT,0.0	CHEMBL2443194,TP,ACT,0.8100000023841858	CHEMBL2333407,TP,ACT,0.949999988079071	CHEMBL571514,TN,INACT,0.44999998807907104	CHEMBL466517,TN,INACT,0.05000000074505806	CHEMBL2010993,TP,ACT,0.8600000143051147	CHEMBL2333410,TP,ACT,0.9599999785423279	CHEMBL235505,TN,INACT,0.36000001430511475	CHEMBL235473,TN,INACT,0.18000000715255737	CHEMBL308819,TN,INACT,0.6100000143051147	CHEMBL1233725,TP,ACT,0.9800000190734863	CHEMBL6852,TN,INACT,0.18000000715255737	CHEMBL2334357,TP,ACT,0.9700000286102295	CHEMBL2019137,TN,INACT,0.029999999329447746	CHEMBL351692,TN,INACT,0.49000000953674316	CHEMBL2010997,TP,ACT,0.9800000190734863	CHEMBL2443199,TP,ACT,0.9300000071525574	CHEMBL2333411,TP,ACT,0.8600000143051147	CHEMBL186716,TP,ACT,0.7799999713897705	CHEMBL568348,TN,INACT,0.46000000834465027	CHEMBL2010988,TP,ACT,0.9700000286102295	CHEMBL36017,TN,INACT,0.5899999737739563	CHEMBL7204,TN,INACT,0.0	CHEMBL2333398,TP,ACT,0.9100000262260437	CHEMBL122950,TN,INACT,0.019999999552965164	CHEMBL98253,TN,INACT,0.07000000029802322	CHEMBL406,TP,ACT,0.9800000190734863	

