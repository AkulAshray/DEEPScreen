CNNModel CHEMBL3890 adam 0.0005 30 128 0 0.6 False True
Number of active compounds :	130
Number of inactive compounds :	130
---------------------------------
Run id: CNNModel_CHEMBL3890_adam_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3890_adam_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 166
Validation samples: 52
--
Training Step: 1  | time: 1.479s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/166
[A[ATraining Step: 2  | total loss: [1m[32m0.62390[0m[0m | time: 2.411s
[2K
| Adam | epoch: 001 | loss: 0.62390 - acc: 0.3656 -- iter: 064/166
[A[ATraining Step: 3  | total loss: [1m[32m0.67807[0m[0m | time: 3.627s
[2K
| Adam | epoch: 001 | loss: 0.67807 - acc: 0.6034 -- iter: 096/166
[A[ATraining Step: 4  | total loss: [1m[32m0.68699[0m[0m | time: 4.957s
[2K
| Adam | epoch: 001 | loss: 0.68699 - acc: 0.5727 -- iter: 128/166
[A[ATraining Step: 5  | total loss: [1m[32m0.68999[0m[0m | time: 6.225s
[2K
| Adam | epoch: 001 | loss: 0.68999 - acc: 0.5440 -- iter: 160/166
[A[ATraining Step: 6  | total loss: [1m[32m0.70288[0m[0m | time: 7.577s
[2K
| Adam | epoch: 001 | loss: 0.70288 - acc: 0.4755 | val_loss: 0.70401 - val_acc: 0.4038 -- iter: 166/166
--
Training Step: 7  | total loss: [1m[32m0.69535[0m[0m | time: 0.246s
[2K
| Adam | epoch: 002 | loss: 0.69535 - acc: 0.4902 -- iter: 032/166
[A[ATraining Step: 8  | total loss: [1m[32m0.69484[0m[0m | time: 1.355s
[2K
| Adam | epoch: 002 | loss: 0.69484 - acc: 0.4957 -- iter: 064/166
[A[ATraining Step: 9  | total loss: [1m[32m0.69334[0m[0m | time: 2.448s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.5145 -- iter: 096/166
[A[ATraining Step: 10  | total loss: [1m[32m0.69036[0m[0m | time: 3.581s
[2K
| Adam | epoch: 002 | loss: 0.69036 - acc: 0.5541 -- iter: 128/166
[A[ATraining Step: 11  | total loss: [1m[32m0.68709[0m[0m | time: 4.692s
[2K
| Adam | epoch: 002 | loss: 0.68709 - acc: 0.6025 -- iter: 160/166
[A[ATraining Step: 12  | total loss: [1m[32m0.69172[0m[0m | time: 6.816s
[2K
| Adam | epoch: 002 | loss: 0.69172 - acc: 0.5283 | val_loss: 0.69998 - val_acc: 0.4038 -- iter: 166/166
--
Training Step: 13  | total loss: [1m[32m0.69491[0m[0m | time: 0.324s
[2K
| Adam | epoch: 003 | loss: 0.69491 - acc: 0.4894 -- iter: 032/166
[A[ATraining Step: 14  | total loss: [1m[32m0.69286[0m[0m | time: 0.610s
[2K
| Adam | epoch: 003 | loss: 0.69286 - acc: 0.4937 -- iter: 064/166
[A[ATraining Step: 15  | total loss: [1m[32m0.69289[0m[0m | time: 1.725s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.4962 -- iter: 096/166
[A[ATraining Step: 16  | total loss: [1m[32m0.69105[0m[0m | time: 2.647s
[2K
| Adam | epoch: 003 | loss: 0.69105 - acc: 0.5328 -- iter: 128/166
[A[ATraining Step: 17  | total loss: [1m[32m0.68983[0m[0m | time: 3.843s
[2K
| Adam | epoch: 003 | loss: 0.68983 - acc: 0.5547 -- iter: 160/166
[A[ATraining Step: 18  | total loss: [1m[32m0.68894[0m[0m | time: 6.128s
[2K
| Adam | epoch: 003 | loss: 0.68894 - acc: 0.5682 | val_loss: 0.70067 - val_acc: 0.4038 -- iter: 166/166
--
Training Step: 19  | total loss: [1m[32m0.69212[0m[0m | time: 0.824s
[2K
| Adam | epoch: 004 | loss: 0.69212 - acc: 0.5247 -- iter: 032/166
[A[ATraining Step: 20  | total loss: [1m[32m0.69046[0m[0m | time: 1.034s
[2K
| Adam | epoch: 004 | loss: 0.69046 - acc: 0.5368 -- iter: 064/166
[A[ATraining Step: 21  | total loss: [1m[32m0.69536[0m[0m | time: 1.278s
[2K
| Adam | epoch: 004 | loss: 0.69536 - acc: 0.4737 -- iter: 096/166
[A[ATraining Step: 22  | total loss: [1m[32m0.69846[0m[0m | time: 2.386s
[2K
| Adam | epoch: 004 | loss: 0.69846 - acc: 0.4316 -- iter: 128/166
[A[ATraining Step: 23  | total loss: [1m[32m0.69549[0m[0m | time: 3.524s
[2K
| Adam | epoch: 004 | loss: 0.69549 - acc: 0.4696 -- iter: 160/166
[A[ATraining Step: 24  | total loss: [1m[32m0.69329[0m[0m | time: 5.602s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.5133 | val_loss: 0.69492 - val_acc: 0.4038 -- iter: 166/166
--
Training Step: 25  | total loss: [1m[32m0.69286[0m[0m | time: 1.226s
[2K
| Adam | epoch: 005 | loss: 0.69286 - acc: 0.5097 -- iter: 032/166
[A[ATraining Step: 26  | total loss: [1m[32m0.69224[0m[0m | time: 2.349s
[2K
| Adam | epoch: 005 | loss: 0.69224 - acc: 0.5071 -- iter: 064/166
[A[ATraining Step: 27  | total loss: [1m[32m0.69201[0m[0m | time: 2.647s
[2K
| Adam | epoch: 005 | loss: 0.69201 - acc: 0.5053 -- iter: 096/166
[A[ATraining Step: 28  | total loss: [1m[32m0.68982[0m[0m | time: 2.935s
[2K
| Adam | epoch: 005 | loss: 0.68982 - acc: 0.5456 -- iter: 128/166
[A[ATraining Step: 29  | total loss: [1m[32m0.68832[0m[0m | time: 4.102s
[2K
| Adam | epoch: 005 | loss: 0.68832 - acc: 0.5751 -- iter: 160/166
[A[ATraining Step: 30  | total loss: [1m[32m0.68800[0m[0m | time: 6.287s
[2K
| Adam | epoch: 005 | loss: 0.68800 - acc: 0.5721 | val_loss: 0.69877 - val_acc: 0.4038 -- iter: 166/166
--
Training Step: 31  | total loss: [1m[32m0.68762[0m[0m | time: 1.172s
[2K
| Adam | epoch: 006 | loss: 0.68762 - acc: 0.5627 -- iter: 032/166
[A[ATraining Step: 32  | total loss: [1m[32m0.68684[0m[0m | time: 2.229s
[2K
| Adam | epoch: 006 | loss: 0.68684 - acc: 0.5626 -- iter: 064/166
[A[ATraining Step: 33  | total loss: [1m[32m0.68556[0m[0m | time: 3.166s
[2K
| Adam | epoch: 006 | loss: 0.68556 - acc: 0.5626 -- iter: 096/166
[A[ATraining Step: 34  | total loss: [1m[32m0.68317[0m[0m | time: 3.405s
[2K
| Adam | epoch: 006 | loss: 0.68317 - acc: 0.5626 -- iter: 128/166
[A[ATraining Step: 35  | total loss: [1m[32m0.68373[0m[0m | time: 3.639s
[2K
| Adam | epoch: 006 | loss: 0.68373 - acc: 0.5495 -- iter: 160/166
[A[ATraining Step: 36  | total loss: [1m[32m0.68030[0m[0m | time: 5.674s
[2K
| Adam | epoch: 006 | loss: 0.68030 - acc: 0.5394 | val_loss: 0.67068 - val_acc: 0.7115 -- iter: 166/166
--
Training Step: 37  | total loss: [1m[32m0.67907[0m[0m | time: 1.226s
[2K
| Adam | epoch: 007 | loss: 0.67907 - acc: 0.5315 -- iter: 032/166
[A[ATraining Step: 38  | total loss: [1m[32m0.67938[0m[0m | time: 2.299s
[2K
| Adam | epoch: 007 | loss: 0.67938 - acc: 0.5314 -- iter: 064/166
[A[ATraining Step: 39  | total loss: [1m[32m0.67476[0m[0m | time: 3.452s
[2K
| Adam | epoch: 007 | loss: 0.67476 - acc: 0.5853 -- iter: 096/166
[A[ATraining Step: 40  | total loss: [1m[32m0.67115[0m[0m | time: 4.621s
[2K
| Adam | epoch: 007 | loss: 0.67115 - acc: 0.6044 -- iter: 128/166
[A[ATraining Step: 41  | total loss: [1m[32m0.67126[0m[0m | time: 4.867s
[2K
| Adam | epoch: 007 | loss: 0.67126 - acc: 0.5738 -- iter: 160/166
[A[ATraining Step: 42  | total loss: [1m[32m0.65288[0m[0m | time: 6.125s
[2K
| Adam | epoch: 007 | loss: 0.65288 - acc: 0.6505 | val_loss: 0.76217 - val_acc: 0.4038 -- iter: 166/166
--
Training Step: 43  | total loss: [1m[32m0.62220[0m[0m | time: 1.184s
[2K
| Adam | epoch: 008 | loss: 0.62220 - acc: 0.6828 -- iter: 032/166
[A[ATraining Step: 44  | total loss: [1m[32m0.61336[0m[0m | time: 2.431s
[2K
| Adam | epoch: 008 | loss: 0.61336 - acc: 0.6728 -- iter: 064/166
[A[ATraining Step: 45  | total loss: [1m[32m0.66042[0m[0m | time: 3.558s
[2K
| Adam | epoch: 008 | loss: 0.66042 - acc: 0.6381 -- iter: 096/166
[A[ATraining Step: 46  | total loss: [1m[32m0.66708[0m[0m | time: 4.634s
[2K
| Adam | epoch: 008 | loss: 0.66708 - acc: 0.6203 -- iter: 128/166
[A[ATraining Step: 47  | total loss: [1m[32m0.65608[0m[0m | time: 5.586s
[2K
| Adam | epoch: 008 | loss: 0.65608 - acc: 0.6160 -- iter: 160/166
[A[ATraining Step: 48  | total loss: [1m[32m0.63750[0m[0m | time: 6.839s
[2K
| Adam | epoch: 008 | loss: 0.63750 - acc: 0.6425 | val_loss: 0.56070 - val_acc: 0.8462 -- iter: 166/166
--
Training Step: 49  | total loss: [1m[32m0.61903[0m[0m | time: 0.259s
[2K
| Adam | epoch: 009 | loss: 0.61903 - acc: 0.6990 -- iter: 032/166
[A[ATraining Step: 50  | total loss: [1m[32m0.60360[0m[0m | time: 1.384s
[2K
| Adam | epoch: 009 | loss: 0.60360 - acc: 0.7457 -- iter: 064/166
[A[ATraining Step: 51  | total loss: [1m[32m0.60378[0m[0m | time: 2.580s
[2K
| Adam | epoch: 009 | loss: 0.60378 - acc: 0.7463 -- iter: 096/166
[A[ATraining Step: 52  | total loss: [1m[32m0.59773[0m[0m | time: 3.695s
[2K
| Adam | epoch: 009 | loss: 0.59773 - acc: 0.7563 -- iter: 128/166
[A[ATraining Step: 53  | total loss: [1m[32m0.59513[0m[0m | time: 4.814s
[2K
| Adam | epoch: 009 | loss: 0.59513 - acc: 0.7415 -- iter: 160/166
[A[ATraining Step: 54  | total loss: [1m[32m0.57684[0m[0m | time: 6.834s
[2K
| Adam | epoch: 009 | loss: 0.57684 - acc: 0.7563 | val_loss: 0.47586 - val_acc: 0.7692 -- iter: 166/166
--
Training Step: 55  | total loss: [1m[32m0.56290[0m[0m | time: 0.299s
[2K
| Adam | epoch: 010 | loss: 0.56290 - acc: 0.7599 -- iter: 032/166
[A[ATraining Step: 56  | total loss: [1m[32m0.52269[0m[0m | time: 0.596s
[2K
| Adam | epoch: 010 | loss: 0.52269 - acc: 0.7937 -- iter: 064/166
[A[ATraining Step: 57  | total loss: [1m[32m0.47626[0m[0m | time: 1.775s
[2K
| Adam | epoch: 010 | loss: 0.47626 - acc: 0.8222 -- iter: 096/166
[A[ATraining Step: 58  | total loss: [1m[32m0.46969[0m[0m | time: 2.864s
[2K
| Adam | epoch: 010 | loss: 0.46969 - acc: 0.8252 -- iter: 128/166
[A[ATraining Step: 59  | total loss: [1m[32m0.46454[0m[0m | time: 3.983s
[2K
| Adam | epoch: 010 | loss: 0.46454 - acc: 0.8235 -- iter: 160/166
[A[ATraining Step: 60  | total loss: [1m[32m0.49101[0m[0m | time: 6.027s
[2K
| Adam | epoch: 010 | loss: 0.49101 - acc: 0.8013 | val_loss: 0.38291 - val_acc: 0.8462 -- iter: 166/166
--
Training Step: 61  | total loss: [1m[32m0.45785[0m[0m | time: 1.146s
[2K
| Adam | epoch: 011 | loss: 0.45785 - acc: 0.8109 -- iter: 032/166
[A[ATraining Step: 62  | total loss: [1m[32m0.45131[0m[0m | time: 1.401s
[2K
| Adam | epoch: 011 | loss: 0.45131 - acc: 0.8071 -- iter: 064/166
[A[ATraining Step: 63  | total loss: [1m[32m0.42712[0m[0m | time: 1.649s
[2K
| Adam | epoch: 011 | loss: 0.42712 - acc: 0.8104 -- iter: 096/166
[A[ATraining Step: 64  | total loss: [1m[32m0.38592[0m[0m | time: 2.769s
[2K
| Adam | epoch: 011 | loss: 0.38592 - acc: 0.8341 -- iter: 128/166
[A[ATraining Step: 65  | total loss: [1m[32m0.51525[0m[0m | time: 3.899s
[2K
| Adam | epoch: 011 | loss: 0.51525 - acc: 0.7852 -- iter: 160/166
[A[ATraining Step: 66  | total loss: [1m[32m0.66264[0m[0m | time: 6.050s
[2K
| Adam | epoch: 011 | loss: 0.66264 - acc: 0.7506 | val_loss: 0.36909 - val_acc: 0.8462 -- iter: 166/166
--
Training Step: 67  | total loss: [1m[32m0.67662[0m[0m | time: 1.264s
[2K
| Adam | epoch: 012 | loss: 0.67662 - acc: 0.6980 -- iter: 032/166
[A[ATraining Step: 68  | total loss: [1m[32m0.66421[0m[0m | time: 2.379s
[2K
| Adam | epoch: 012 | loss: 0.66421 - acc: 0.7041 -- iter: 064/166
[A[ATraining Step: 69  | total loss: [1m[32m0.62212[0m[0m | time: 2.700s
[2K
| Adam | epoch: 012 | loss: 0.62212 - acc: 0.7241 -- iter: 096/166
[A[ATraining Step: 70  | total loss: [1m[32m0.63560[0m[0m | time: 3.007s
[2K
| Adam | epoch: 012 | loss: 0.63560 - acc: 0.7175 -- iter: 128/166
[A[ATraining Step: 71  | total loss: [1m[32m0.64204[0m[0m | time: 4.122s
[2K
| Adam | epoch: 012 | loss: 0.64204 - acc: 0.7117 -- iter: 160/166
[A[ATraining Step: 72  | total loss: [1m[32m0.65583[0m[0m | time: 6.237s
[2K
| Adam | epoch: 012 | loss: 0.65583 - acc: 0.6949 | val_loss: 0.58926 - val_acc: 0.6731 -- iter: 166/166
--
Training Step: 73  | total loss: [1m[32m0.64463[0m[0m | time: 1.010s
[2K
| Adam | epoch: 013 | loss: 0.64463 - acc: 0.7045 -- iter: 032/166
[A[ATraining Step: 74  | total loss: [1m[32m0.64231[0m[0m | time: 2.115s
[2K
| Adam | epoch: 013 | loss: 0.64231 - acc: 0.6889 -- iter: 064/166
[A[ATraining Step: 75  | total loss: [1m[32m0.61429[0m[0m | time: 3.124s
[2K
| Adam | epoch: 013 | loss: 0.61429 - acc: 0.7091 -- iter: 096/166
[A[ATraining Step: 76  | total loss: [1m[32m0.59284[0m[0m | time: 3.392s
[2K
| Adam | epoch: 013 | loss: 0.59284 - acc: 0.7269 -- iter: 128/166
[A[ATraining Step: 77  | total loss: [1m[32m0.57497[0m[0m | time: 3.648s
[2K
| Adam | epoch: 013 | loss: 0.57497 - acc: 0.7381 -- iter: 160/166
[A[ATraining Step: 78  | total loss: [1m[32m0.56330[0m[0m | time: 5.768s
[2K
| Adam | epoch: 013 | loss: 0.56330 - acc: 0.7481 | val_loss: 0.41361 - val_acc: 0.8846 -- iter: 166/166
--
Training Step: 79  | total loss: [1m[32m0.55967[0m[0m | time: 1.094s
[2K
| Adam | epoch: 014 | loss: 0.55967 - acc: 0.7483 -- iter: 032/166
[A[ATraining Step: 80  | total loss: [1m[32m0.58015[0m[0m | time: 2.338s
[2K
| Adam | epoch: 014 | loss: 0.58015 - acc: 0.7293 -- iter: 064/166
[A[ATraining Step: 81  | total loss: [1m[32m0.56771[0m[0m | time: 3.514s
[2K
| Adam | epoch: 014 | loss: 0.56771 - acc: 0.7440 -- iter: 096/166
[A[ATraining Step: 82  | total loss: [1m[32m0.55899[0m[0m | time: 4.705s
[2K
| Adam | epoch: 014 | loss: 0.55899 - acc: 0.7540 -- iter: 128/166
[A[ATraining Step: 83  | total loss: [1m[32m0.54397[0m[0m | time: 4.951s
[2K
| Adam | epoch: 014 | loss: 0.54397 - acc: 0.7630 -- iter: 160/166
[A[ATraining Step: 84  | total loss: [1m[32m0.55773[0m[0m | time: 6.192s
[2K
| Adam | epoch: 014 | loss: 0.55773 - acc: 0.7367 | val_loss: 0.39004 - val_acc: 0.9038 -- iter: 166/166
--
Training Step: 85  | total loss: [1m[32m0.56257[0m[0m | time: 0.946s
[2K
| Adam | epoch: 015 | loss: 0.56257 - acc: 0.7130 -- iter: 032/166
[A[ATraining Step: 86  | total loss: [1m[32m0.54268[0m[0m | time: 1.979s
[2K
| Adam | epoch: 015 | loss: 0.54268 - acc: 0.7292 -- iter: 064/166
[A[ATraining Step: 87  | total loss: [1m[32m0.53111[0m[0m | time: 3.066s
[2K
| Adam | epoch: 015 | loss: 0.53111 - acc: 0.7344 -- iter: 096/166
[A[ATraining Step: 88  | total loss: [1m[32m0.51198[0m[0m | time: 4.128s
[2K
| Adam | epoch: 015 | loss: 0.51198 - acc: 0.7453 -- iter: 128/166
[A[ATraining Step: 89  | total loss: [1m[32m0.50150[0m[0m | time: 5.198s
[2K
| Adam | epoch: 015 | loss: 0.50150 - acc: 0.7521 -- iter: 160/166
[A[ATraining Step: 90  | total loss: [1m[32m0.49722[0m[0m | time: 6.469s
[2K
| Adam | epoch: 015 | loss: 0.49722 - acc: 0.7519 | val_loss: 0.37113 - val_acc: 0.8846 -- iter: 166/166
--
Training Step: 91  | total loss: [1m[32m0.46933[0m[0m | time: 0.283s
[2K
| Adam | epoch: 016 | loss: 0.46933 - acc: 0.7767 -- iter: 032/166
[A[ATraining Step: 92  | total loss: [1m[32m0.43934[0m[0m | time: 1.383s
[2K
| Adam | epoch: 016 | loss: 0.43934 - acc: 0.7990 -- iter: 064/166
[A[ATraining Step: 93  | total loss: [1m[32m0.43429[0m[0m | time: 2.479s
[2K
| Adam | epoch: 016 | loss: 0.43429 - acc: 0.8035 -- iter: 096/166
[A[ATraining Step: 94  | total loss: [1m[32m0.46397[0m[0m | time: 3.677s
[2K
| Adam | epoch: 016 | loss: 0.46397 - acc: 0.7888 -- iter: 128/166
[A[ATraining Step: 95  | total loss: [1m[32m0.46609[0m[0m | time: 4.836s
[2K
| Adam | epoch: 016 | loss: 0.46609 - acc: 0.7880 -- iter: 160/166
[A[ATraining Step: 96  | total loss: [1m[32m0.45403[0m[0m | time: 6.972s
[2K
| Adam | epoch: 016 | loss: 0.45403 - acc: 0.7936 | val_loss: 0.28658 - val_acc: 0.9038 -- iter: 166/166
--
Training Step: 97  | total loss: [1m[32m0.44324[0m[0m | time: 0.210s
[2K
| Adam | epoch: 017 | loss: 0.44324 - acc: 0.8017 -- iter: 032/166
[A[ATraining Step: 98  | total loss: [1m[32m0.41575[0m[0m | time: 0.415s
[2K
| Adam | epoch: 017 | loss: 0.41575 - acc: 0.8215 -- iter: 064/166
[A[ATraining Step: 99  | total loss: [1m[32m0.38820[0m[0m | time: 1.402s
[2K
| Adam | epoch: 017 | loss: 0.38820 - acc: 0.8394 -- iter: 096/166
[A[ATraining Step: 100  | total loss: [1m[32m0.39186[0m[0m | time: 2.468s
[2K
| Adam | epoch: 017 | loss: 0.39186 - acc: 0.8367 -- iter: 128/166
[A[ATraining Step: 101  | total loss: [1m[32m0.39617[0m[0m | time: 3.543s
[2K
| Adam | epoch: 017 | loss: 0.39617 - acc: 0.8343 -- iter: 160/166
[A[ATraining Step: 102  | total loss: [1m[32m0.38121[0m[0m | time: 5.643s
[2K
| Adam | epoch: 017 | loss: 0.38121 - acc: 0.8415 | val_loss: 0.38905 - val_acc: 0.8846 -- iter: 166/166
--
Training Step: 103  | total loss: [1m[32m0.37076[0m[0m | time: 1.085s
[2K
| Adam | epoch: 018 | loss: 0.37076 - acc: 0.8417 -- iter: 032/166
[A[ATraining Step: 104  | total loss: [1m[32m0.35329[0m[0m | time: 1.316s
[2K
| Adam | epoch: 018 | loss: 0.35329 - acc: 0.8544 -- iter: 064/166
[A[ATraining Step: 105  | total loss: [1m[32m0.33756[0m[0m | time: 1.549s
[2K
| Adam | epoch: 018 | loss: 0.33756 - acc: 0.8690 -- iter: 096/166
[A[ATraining Step: 106  | total loss: [1m[32m0.31925[0m[0m | time: 2.665s
[2K
| Adam | epoch: 018 | loss: 0.31925 - acc: 0.8821 -- iter: 128/166
[A[ATraining Step: 107  | total loss: [1m[32m0.36534[0m[0m | time: 3.869s
[2K
| Adam | epoch: 018 | loss: 0.36534 - acc: 0.8657 -- iter: 160/166
[A[ATraining Step: 108  | total loss: [1m[32m0.36282[0m[0m | time: 6.064s
[2K
| Adam | epoch: 018 | loss: 0.36282 - acc: 0.8635 | val_loss: 0.30971 - val_acc: 0.9231 -- iter: 166/166
--
Training Step: 109  | total loss: [1m[32m0.34894[0m[0m | time: 1.142s
[2K
| Adam | epoch: 019 | loss: 0.34894 - acc: 0.8678 -- iter: 032/166
[A[ATraining Step: 110  | total loss: [1m[32m0.33711[0m[0m | time: 2.240s
[2K
| Adam | epoch: 019 | loss: 0.33711 - acc: 0.8654 -- iter: 064/166
[A[ATraining Step: 111  | total loss: [1m[32m0.34062[0m[0m | time: 2.456s
[2K
| Adam | epoch: 019 | loss: 0.34062 - acc: 0.8570 -- iter: 096/166
[A[ATraining Step: 112  | total loss: [1m[32m0.37667[0m[0m | time: 2.641s
[2K
| Adam | epoch: 019 | loss: 0.37667 - acc: 0.8380 -- iter: 128/166
[A[ATraining Step: 113  | total loss: [1m[32m0.40820[0m[0m | time: 3.587s
[2K
| Adam | epoch: 019 | loss: 0.40820 - acc: 0.8208 -- iter: 160/166
[A[ATraining Step: 114  | total loss: [1m[32m0.40472[0m[0m | time: 5.699s
[2K
| Adam | epoch: 019 | loss: 0.40472 - acc: 0.8231 | val_loss: 0.30141 - val_acc: 0.8846 -- iter: 166/166
--
Training Step: 115  | total loss: [1m[32m0.40572[0m[0m | time: 1.104s
[2K
| Adam | epoch: 020 | loss: 0.40572 - acc: 0.8189 -- iter: 032/166
[A[ATraining Step: 116  | total loss: [1m[32m0.38890[0m[0m | time: 2.226s
[2K
| Adam | epoch: 020 | loss: 0.38890 - acc: 0.8308 -- iter: 064/166
[A[ATraining Step: 117  | total loss: [1m[32m0.37949[0m[0m | time: 3.276s
[2K
| Adam | epoch: 020 | loss: 0.37949 - acc: 0.8352 -- iter: 096/166
[A[ATraining Step: 118  | total loss: [1m[32m0.37098[0m[0m | time: 3.609s
[2K
| Adam | epoch: 020 | loss: 0.37098 - acc: 0.8454 -- iter: 128/166
[A[ATraining Step: 119  | total loss: [1m[32m0.38012[0m[0m | time: 3.890s
[2K
| Adam | epoch: 020 | loss: 0.38012 - acc: 0.8276 -- iter: 160/166
[A[ATraining Step: 120  | total loss: [1m[32m0.38279[0m[0m | time: 6.046s
[2K
| Adam | epoch: 020 | loss: 0.38279 - acc: 0.8281 | val_loss: 0.42436 - val_acc: 0.8654 -- iter: 166/166
--
Training Step: 121  | total loss: [1m[32m0.37790[0m[0m | time: 0.870s
[2K
| Adam | epoch: 021 | loss: 0.37790 - acc: 0.8328 -- iter: 032/166
[A[ATraining Step: 122  | total loss: [1m[32m0.38597[0m[0m | time: 2.018s
[2K
| Adam | epoch: 021 | loss: 0.38597 - acc: 0.8339 -- iter: 064/166
[A[ATraining Step: 123  | total loss: [1m[32m0.38491[0m[0m | time: 3.222s
[2K
| Adam | epoch: 021 | loss: 0.38491 - acc: 0.8318 -- iter: 096/166
[A[ATraining Step: 124  | total loss: [1m[32m0.36705[0m[0m | time: 4.338s
[2K
| Adam | epoch: 021 | loss: 0.36705 - acc: 0.8455 -- iter: 128/166
[A[ATraining Step: 125  | total loss: [1m[32m0.35967[0m[0m | time: 4.541s
[2K
| Adam | epoch: 021 | loss: 0.35967 - acc: 0.8484 -- iter: 160/166
[A[ATraining Step: 126  | total loss: [1m[32m0.33983[0m[0m | time: 5.745s
[2K
| Adam | epoch: 021 | loss: 0.33983 - acc: 0.8636 | val_loss: 0.33345 - val_acc: 0.9038 -- iter: 166/166
--
Training Step: 127  | total loss: [1m[32m0.32084[0m[0m | time: 1.101s
[2K
| Adam | epoch: 022 | loss: 0.32084 - acc: 0.8772 -- iter: 032/166
[A[ATraining Step: 128  | total loss: [1m[32m0.32333[0m[0m | time: 2.166s
[2K
| Adam | epoch: 022 | loss: 0.32333 - acc: 0.8708 -- iter: 064/166
[A[ATraining Step: 129  | total loss: [1m[32m0.37479[0m[0m | time: 3.218s
[2K
| Adam | epoch: 022 | loss: 0.37479 - acc: 0.8556 -- iter: 096/166
[A[ATraining Step: 130  | total loss: [1m[32m0.36775[0m[0m | time: 4.295s
[2K
| Adam | epoch: 022 | loss: 0.36775 - acc: 0.8544 -- iter: 128/166
[A[ATraining Step: 131  | total loss: [1m[32m0.35439[0m[0m | time: 5.423s
[2K
| Adam | epoch: 022 | loss: 0.35439 - acc: 0.8596 -- iter: 160/166
[A[ATraining Step: 132  | total loss: [1m[32m0.33593[0m[0m | time: 6.710s
[2K
| Adam | epoch: 022 | loss: 0.33593 - acc: 0.8674 | val_loss: 0.25616 - val_acc: 0.9038 -- iter: 166/166
--
Training Step: 133  | total loss: [1m[32m0.33117[0m[0m | time: 0.323s
[2K
| Adam | epoch: 023 | loss: 0.33117 - acc: 0.8640 -- iter: 032/166
[A[ATraining Step: 134  | total loss: [1m[32m0.31869[0m[0m | time: 1.433s
[2K
| Adam | epoch: 023 | loss: 0.31869 - acc: 0.8609 -- iter: 064/166
[A[ATraining Step: 135  | total loss: [1m[32m0.31499[0m[0m | time: 2.369s
[2K
| Adam | epoch: 023 | loss: 0.31499 - acc: 0.8592 -- iter: 096/166
[A[ATraining Step: 136  | total loss: [1m[32m0.31064[0m[0m | time: 3.555s
[2K
| Adam | epoch: 023 | loss: 0.31064 - acc: 0.8608 -- iter: 128/166
[A[ATraining Step: 137  | total loss: [1m[32m0.32572[0m[0m | time: 4.813s
[2K
| Adam | epoch: 023 | loss: 0.32572 - acc: 0.8559 -- iter: 160/166
[A[ATraining Step: 138  | total loss: [1m[32m0.31398[0m[0m | time: 6.943s
[2K
| Adam | epoch: 023 | loss: 0.31398 - acc: 0.8610 | val_loss: 0.24610 - val_acc: 0.8654 -- iter: 166/166
--
Training Step: 139  | total loss: [1m[32m0.29574[0m[0m | time: 0.274s
[2K
| Adam | epoch: 024 | loss: 0.29574 - acc: 0.8717 -- iter: 032/166
[A[ATraining Step: 140  | total loss: [1m[32m0.28756[0m[0m | time: 0.521s
[2K
| Adam | epoch: 024 | loss: 0.28756 - acc: 0.8679 -- iter: 064/166
[A[ATraining Step: 141  | total loss: [1m[32m0.27938[0m[0m | time: 1.561s
[2K
| Adam | epoch: 024 | loss: 0.27938 - acc: 0.8644 -- iter: 096/166
[A[ATraining Step: 142  | total loss: [1m[32m0.27592[0m[0m | time: 2.675s
[2K
| Adam | epoch: 024 | loss: 0.27592 - acc: 0.8686 -- iter: 128/166
[A[ATraining Step: 143  | total loss: [1m[32m0.26884[0m[0m | time: 3.814s
[2K
| Adam | epoch: 024 | loss: 0.26884 - acc: 0.8693 -- iter: 160/166
[A[ATraining Step: 144  | total loss: [1m[32m0.25474[0m[0m | time: 5.992s
[2K
| Adam | epoch: 024 | loss: 0.25474 - acc: 0.8761 | val_loss: 0.27138 - val_acc: 0.9231 -- iter: 166/166
--
Training Step: 145  | total loss: [1m[32m0.23641[0m[0m | time: 1.225s
[2K
| Adam | epoch: 025 | loss: 0.23641 - acc: 0.8885 -- iter: 032/166
[A[ATraining Step: 146  | total loss: [1m[32m0.24040[0m[0m | time: 1.511s
[2K
| Adam | epoch: 025 | loss: 0.24040 - acc: 0.8903 -- iter: 064/166
[A[ATraining Step: 147  | total loss: [1m[32m0.24133[0m[0m | time: 1.744s
[2K
| Adam | epoch: 025 | loss: 0.24133 - acc: 0.8846 -- iter: 096/166
[A[ATraining Step: 148  | total loss: [1m[32m0.23329[0m[0m | time: 2.605s
[2K
| Adam | epoch: 025 | loss: 0.23329 - acc: 0.8961 -- iter: 128/166
[A[ATraining Step: 149  | total loss: [1m[32m0.23929[0m[0m | time: 3.722s
[2K
| Adam | epoch: 025 | loss: 0.23929 - acc: 0.8940 -- iter: 160/166
[A[ATraining Step: 150  | total loss: [1m[32m0.25469[0m[0m | time: 6.032s
[2K
| Adam | epoch: 025 | loss: 0.25469 - acc: 0.8858 | val_loss: 0.39006 - val_acc: 0.8654 -- iter: 166/166
--
Training Step: 151  | total loss: [1m[32m0.28464[0m[0m | time: 0.928s
[2K
| Adam | epoch: 026 | loss: 0.28464 - acc: 0.8629 -- iter: 032/166
[A[ATraining Step: 152  | total loss: [1m[32m0.26894[0m[0m | time: 2.019s
[2K
| Adam | epoch: 026 | loss: 0.26894 - acc: 0.8735 -- iter: 064/166
[A[ATraining Step: 153  | total loss: [1m[32m0.25934[0m[0m | time: 2.281s
[2K
| Adam | epoch: 026 | loss: 0.25934 - acc: 0.8799 -- iter: 096/166
[A[ATraining Step: 154  | total loss: [1m[32m0.23702[0m[0m | time: 2.550s
[2K
| Adam | epoch: 026 | loss: 0.23702 - acc: 0.8919 -- iter: 128/166
[A[ATraining Step: 155  | total loss: [1m[32m0.21669[0m[0m | time: 3.645s
[2K
| Adam | epoch: 026 | loss: 0.21669 - acc: 0.9027 -- iter: 160/166
[A[ATraining Step: 156  | total loss: [1m[32m0.20916[0m[0m | time: 5.777s
[2K
| Adam | epoch: 026 | loss: 0.20916 - acc: 0.9062 | val_loss: 0.23365 - val_acc: 0.8846 -- iter: 166/166
--
Training Step: 157  | total loss: [1m[32m0.24979[0m[0m | time: 1.155s
[2K
| Adam | epoch: 027 | loss: 0.24979 - acc: 0.8968 -- iter: 032/166
[A[ATraining Step: 158  | total loss: [1m[32m0.23878[0m[0m | time: 2.382s
[2K
| Adam | epoch: 027 | loss: 0.23878 - acc: 0.8978 -- iter: 064/166
[A[ATraining Step: 159  | total loss: [1m[32m0.22459[0m[0m | time: 3.526s
[2K
| Adam | epoch: 027 | loss: 0.22459 - acc: 0.9017 -- iter: 096/166
[A[ATraining Step: 160  | total loss: [1m[32m0.22161[0m[0m | time: 3.722s
[2K
| Adam | epoch: 027 | loss: 0.22161 - acc: 0.9053 -- iter: 128/166
[A[ATraining Step: 161  | total loss: [1m[32m0.21568[0m[0m | time: 3.950s
[2K
| Adam | epoch: 027 | loss: 0.21568 - acc: 0.9148 -- iter: 160/166
[A[ATraining Step: 162  | total loss: [1m[32m0.20995[0m[0m | time: 5.996s
[2K
| Adam | epoch: 027 | loss: 0.20995 - acc: 0.9233 | val_loss: 0.31969 - val_acc: 0.8846 -- iter: 166/166
--
Training Step: 163  | total loss: [1m[32m0.20047[0m[0m | time: 1.137s
[2K
| Adam | epoch: 028 | loss: 0.20047 - acc: 0.9278 -- iter: 032/166
[A[ATraining Step: 164  | total loss: [1m[32m0.21210[0m[0m | time: 2.217s
[2K
| Adam | epoch: 028 | loss: 0.21210 - acc: 0.9288 -- iter: 064/166
[A[ATraining Step: 165  | total loss: [1m[32m0.20197[0m[0m | time: 3.366s
[2K
| Adam | epoch: 028 | loss: 0.20197 - acc: 0.9328 -- iter: 096/166
[A[ATraining Step: 166  | total loss: [1m[32m0.20220[0m[0m | time: 4.574s
[2K
| Adam | epoch: 028 | loss: 0.20220 - acc: 0.9301 -- iter: 128/166
[A[ATraining Step: 167  | total loss: [1m[32m0.19503[0m[0m | time: 4.864s
[2K
| Adam | epoch: 028 | loss: 0.19503 - acc: 0.9340 -- iter: 160/166
[A[ATraining Step: 168  | total loss: [1m[32m0.17799[0m[0m | time: 6.155s
[2K
| Adam | epoch: 028 | loss: 0.17799 - acc: 0.9406 | val_loss: 0.23516 - val_acc: 0.9231 -- iter: 166/166
--
Training Step: 169  | total loss: [1m[32m0.16224[0m[0m | time: 1.139s
[2K
| Adam | epoch: 029 | loss: 0.16224 - acc: 0.9465 -- iter: 032/166
[A[ATraining Step: 170  | total loss: [1m[32m0.15583[0m[0m | time: 2.388s
[2K
| Adam | epoch: 029 | loss: 0.15583 - acc: 0.9488 -- iter: 064/166
[A[ATraining Step: 171  | total loss: [1m[32m0.17684[0m[0m | time: 3.602s
[2K
| Adam | epoch: 029 | loss: 0.17684 - acc: 0.9476 -- iter: 096/166
[A[ATraining Step: 172  | total loss: [1m[32m0.17339[0m[0m | time: 4.817s
[2K
| Adam | epoch: 029 | loss: 0.17339 - acc: 0.9435 -- iter: 128/166
[A[ATraining Step: 173  | total loss: [1m[32m0.17937[0m[0m | time: 5.905s
[2K
| Adam | epoch: 029 | loss: 0.17937 - acc: 0.9367 -- iter: 160/166
[A[ATraining Step: 174  | total loss: [1m[32m0.16806[0m[0m | time: 7.176s
[2K
| Adam | epoch: 029 | loss: 0.16806 - acc: 0.9430 | val_loss: 0.31617 - val_acc: 0.8654 -- iter: 166/166
--
Training Step: 175  | total loss: [1m[32m0.15443[0m[0m | time: 0.273s
[2K
| Adam | epoch: 030 | loss: 0.15443 - acc: 0.9487 -- iter: 032/166
[A[ATraining Step: 176  | total loss: [1m[32m0.14166[0m[0m | time: 1.365s
[2K
| Adam | epoch: 030 | loss: 0.14166 - acc: 0.9538 -- iter: 064/166
[A[ATraining Step: 177  | total loss: [1m[32m0.13498[0m[0m | time: 2.602s
[2K
| Adam | epoch: 030 | loss: 0.13498 - acc: 0.9553 -- iter: 096/166
[A[ATraining Step: 178  | total loss: [1m[32m0.21281[0m[0m | time: 3.758s
[2K
| Adam | epoch: 030 | loss: 0.21281 - acc: 0.9410 -- iter: 128/166
[A[ATraining Step: 179  | total loss: [1m[32m0.20309[0m[0m | time: 4.910s
[2K
| Adam | epoch: 030 | loss: 0.20309 - acc: 0.9469 -- iter: 160/166
[A[ATraining Step: 180  | total loss: [1m[32m0.19216[0m[0m | time: 7.045s
[2K
| Adam | epoch: 030 | loss: 0.19216 - acc: 0.9491 | val_loss: 0.24249 - val_acc: 0.9038 -- iter: 166/166
--
Validation AUC:0.978494623655914
Validation AUPRC:0.9738525606946662
Test AUC:0.9370314842578711
Test AUPRC:0.9248549883275282
BestTestF1Score	0.86	0.77	0.88	0.9	0.83	19	2	27	4	0.7
BestTestMCCScore	0.86	0.77	0.88	0.9	0.83	19	2	27	4	0.7
BestTestAccuracyScore	0.86	0.77	0.88	0.9	0.83	19	2	27	4	0.87
BestValidationF1Score	0.93	0.88	0.94	0.91	0.95	20	2	29	1	0.7
BestValidationMCC	0.93	0.88	0.94	0.91	0.95	20	2	29	1	0.7
BestValidationAccuracy	0.93	0.88	0.94	0.95	0.9	19	1	30	2	0.87
TestPredictions (Threshold:0.7)
CHEMBL317271,TN,INACT,0.05000000074505806	CHEMBL3215449,FN,ACT,0.05999999865889549	CHEMBL288114,TN,INACT,0.05000000074505806	CHEMBL221111,FN,ACT,0.28999999165534973	CHEMBL117093,TP,ACT,0.9900000095367432	CHEMBL117279,TP,ACT,0.9800000190734863	CHEMBL6430,TN,INACT,0.20000000298023224	CHEMBL117668,TP,ACT,0.9900000095367432	CHEMBL117198,TP,ACT,1.0	CHEMBL269056,TN,INACT,0.25	CHEMBL119711,TP,ACT,0.9700000286102295	CHEMBL1160648,TN,INACT,0.03999999910593033	CHEMBL2370864,TN,INACT,0.05000000074505806	CHEMBL220721,FN,ACT,0.3100000023841858	CHEMBL325651,TP,ACT,0.9700000286102295	CHEMBL6523,FP,INACT,0.9900000095367432	CHEMBL104241,TN,INACT,0.009999999776482582	CHEMBL139490,TN,INACT,0.05000000074505806	CHEMBL2029056,TN,INACT,0.23000000417232513	CHEMBL267678,TP,ACT,1.0	CHEMBL3350406,FN,ACT,0.4399999976158142	CHEMBL561209,TN,INACT,0.44999998807907104	CHEMBL1767035,TN,INACT,0.05999999865889549	CHEMBL325184,TP,ACT,0.9900000095367432	CHEMBL107188,TN,INACT,0.009999999776482582	CHEMBL2111731,TN,INACT,0.07999999821186066	CHEMBL3215408,TN,INACT,0.029999999329447746	CHEMBL331584,TP,ACT,0.9900000095367432	CHEMBL262570,TP,ACT,0.9900000095367432	CHEMBL37284,TN,INACT,0.5699999928474426	CHEMBL119886,TP,ACT,0.9900000095367432	CHEMBL2381517,TN,INACT,0.019999999552965164	CHEMBL3423031,TN,INACT,0.019999999552965164	CHEMBL3085443,TN,INACT,0.17000000178813934	CHEMBL323304,TN,INACT,0.009999999776482582	CHEMBL325893,TP,ACT,0.9800000190734863	CHEMBL331662,TP,ACT,0.9900000095367432	CHEMBL266799,TP,ACT,0.9599999785423279	CHEMBL450936,TN,INACT,0.009999999776482582	CHEMBL221161,TN,INACT,0.07000000029802322	CHEMBL117292,TP,ACT,0.9800000190734863	CHEMBL175597,TN,INACT,0.07000000029802322	CHEMBL268567,TP,ACT,1.0	CHEMBL326120,TP,ACT,0.9900000095367432	CHEMBL348443,TN,INACT,0.019999999552965164	CHEMBL221041,TN,INACT,0.029999999329447746	CHEMBL153334,TN,INACT,0.27000001072883606	CHEMBL266198,TP,ACT,1.0	CHEMBL220340,TN,INACT,0.019999999552965164	CHEMBL608739,TN,INACT,0.6899999976158142	CHEMBL6369,TP,ACT,0.9900000095367432	CHEMBL269495,FP,INACT,0.9800000190734863	

