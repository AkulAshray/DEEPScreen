ImageNetInceptionV2 CHEMBL1075319 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	288
Number of inactive compounds :	192
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1075319_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1075319_adam_0.001_15_0.8/
---------------------------------
Training samples: 307
Validation samples: 96
--
Training Step: 1  | time: 325.667s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/307
[A[ATraining Step: 2  | total loss: [1m[32m0.60228[0m[0m | time: 536.621s
[2K
| Adam | epoch: 001 | loss: 0.60228 - acc: 0.5062 -- iter: 064/307
[A[ATraining Step: 3  | total loss: [1m[32m0.44874[0m[0m | time: 612.476s
[2K
| Adam | epoch: 001 | loss: 0.44874 - acc: 0.7312 -- iter: 096/307
[A[ATraining Step: 4  | total loss: [1m[32m0.62919[0m[0m | time: 721.910s
[2K
| Adam | epoch: 001 | loss: 0.62919 - acc: 0.7922 -- iter: 128/307
[A[ATraining Step: 5  | total loss: [1m[32m0.74705[0m[0m | time: 916.246s
[2K
| Adam | epoch: 001 | loss: 0.74705 - acc: 0.7846 -- iter: 160/307
[A[ATraining Step: 6  | total loss: [1m[32m0.64414[0m[0m | time: 1101.700s
[2K
| Adam | epoch: 001 | loss: 0.64414 - acc: 0.7825 -- iter: 192/307
[A[ATraining Step: 7  | total loss: [1m[32m0.71748[0m[0m | time: 1213.824s
[2K
| Adam | epoch: 001 | loss: 0.71748 - acc: 0.6505 -- iter: 224/307
[A[ATraining Step: 8  | total loss: [1m[32m0.46954[0m[0m | time: 1358.856s
[2K
| Adam | epoch: 001 | loss: 0.46954 - acc: 0.7944 -- iter: 256/307
[A[ATraining Step: 9  | total loss: [1m[32m0.39212[0m[0m | time: 1597.611s
[2K
| Adam | epoch: 001 | loss: 0.39212 - acc: 0.8205 -- iter: 288/307
[A[ATraining Step: 10  | total loss: [1m[32m0.42623[0m[0m | time: 1798.406s
[2K
| Adam | epoch: 001 | loss: 0.42623 - acc: 0.7853 | val_loss: 0.88357 - val_acc: 0.5312 -- iter: 307/307
--
Training Step: 11  | total loss: [1m[32m0.49372[0m[0m | time: 76.922s
[2K
| Adam | epoch: 002 | loss: 0.49372 - acc: 0.7623 -- iter: 032/307
[A[ATraining Step: 12  | total loss: [1m[32m0.42399[0m[0m | time: 247.842s
[2K
| Adam | epoch: 002 | loss: 0.42399 - acc: 0.8456 -- iter: 064/307
[A[ATraining Step: 13  | total loss: [1m[32m0.33084[0m[0m | time: 468.116s
[2K
| Adam | epoch: 002 | loss: 0.33084 - acc: 0.8582 -- iter: 096/307
[A[ATraining Step: 14  | total loss: [1m[32m0.35576[0m[0m | time: 563.192s
[2K
| Adam | epoch: 002 | loss: 0.35576 - acc: 0.8779 -- iter: 128/307
[A[ATraining Step: 15  | total loss: [1m[32m0.43532[0m[0m | time: 636.043s
[2K
| Adam | epoch: 002 | loss: 0.43532 - acc: 0.8156 -- iter: 160/307
[A[ATraining Step: 16  | total loss: [1m[32m0.35559[0m[0m | time: 671.817s
[2K
| Adam | epoch: 002 | loss: 0.35559 - acc: 0.8496 -- iter: 192/307
[A[ATraining Step: 17  | total loss: [1m[32m0.36462[0m[0m | time: 709.073s
[2K
| Adam | epoch: 002 | loss: 0.36462 - acc: 0.8137 -- iter: 224/307
[A[ATraining Step: 18  | total loss: [1m[32m0.31047[0m[0m | time: 743.067s
[2K
| Adam | epoch: 002 | loss: 0.31047 - acc: 0.8674 -- iter: 256/307
[A[ATraining Step: 19  | total loss: [1m[32m0.28516[0m[0m | time: 762.201s
[2K
| Adam | epoch: 002 | loss: 0.28516 - acc: 0.9012 -- iter: 288/307
[A[ATraining Step: 20  | total loss: [1m[32m0.26532[0m[0m | time: 795.086s
[2K
| Adam | epoch: 002 | loss: 0.26532 - acc: 0.9028 | val_loss: 0.83172 - val_acc: 0.4688 -- iter: 307/307
--
Training Step: 21  | total loss: [1m[32m0.23155[0m[0m | time: 8.337s
[2K
| Adam | epoch: 003 | loss: 0.23155 - acc: 0.9233 -- iter: 032/307
[A[ATraining Step: 22  | total loss: [1m[32m0.18681[0m[0m | time: 15.343s
[2K
| Adam | epoch: 003 | loss: 0.18681 - acc: 0.9463 -- iter: 064/307
[A[ATraining Step: 23  | total loss: [1m[32m0.18971[0m[0m | time: 30.433s
[2K
| Adam | epoch: 003 | loss: 0.18971 - acc: 0.9313 -- iter: 096/307
[A[ATraining Step: 24  | total loss: [1m[32m0.16062[0m[0m | time: 61.953s
[2K
| Adam | epoch: 003 | loss: 0.16062 - acc: 0.9506 -- iter: 128/307
[A[ATraining Step: 25  | total loss: [1m[32m0.15108[0m[0m | time: 117.033s
[2K
| Adam | epoch: 003 | loss: 0.15108 - acc: 0.9471 -- iter: 160/307
[A[ATraining Step: 26  | total loss: [1m[32m0.18657[0m[0m | time: 156.704s
[2K
| Adam | epoch: 003 | loss: 0.18657 - acc: 0.9363 -- iter: 192/307
[A[ATraining Step: 27  | total loss: [1m[32m0.21513[0m[0m | time: 221.068s
[2K
| Adam | epoch: 003 | loss: 0.21513 - acc: 0.9285 -- iter: 224/307
[A[ATraining Step: 28  | total loss: [1m[32m0.20553[0m[0m | time: 248.610s
[2K
| Adam | epoch: 003 | loss: 0.20553 - acc: 0.9308 -- iter: 256/307
[A[ATraining Step: 29  | total loss: [1m[32m0.17920[0m[0m | time: 294.497s
[2K
| Adam | epoch: 003 | loss: 0.17920 - acc: 0.9400 -- iter: 288/307
[A[ATraining Step: 30  | total loss: [1m[32m0.14606[0m[0m | time: 356.083s
[2K
| Adam | epoch: 003 | loss: 0.14606 - acc: 0.9542 | val_loss: 1.62178 - val_acc: 0.4688 -- iter: 307/307
--
Training Step: 31  | total loss: [1m[32m0.13653[0m[0m | time: 27.152s
[2K
| Adam | epoch: 004 | loss: 0.13653 - acc: 0.9576 -- iter: 032/307
[A[ATraining Step: 32  | total loss: [1m[32m0.17526[0m[0m | time: 36.373s
[2K
| Adam | epoch: 004 | loss: 0.17526 - acc: 0.9390 -- iter: 064/307
[A[ATraining Step: 33  | total loss: [1m[32m0.16031[0m[0m | time: 45.362s
[2K
| Adam | epoch: 004 | loss: 0.16031 - acc: 0.9524 -- iter: 096/307
[A[ATraining Step: 34  | total loss: [1m[32m0.21095[0m[0m | time: 67.682s
[2K
| Adam | epoch: 004 | loss: 0.21095 - acc: 0.9288 -- iter: 128/307
[A[ATraining Step: 35  | total loss: [1m[32m0.19839[0m[0m | time: 86.057s
[2K
| Adam | epoch: 004 | loss: 0.19839 - acc: 0.9371 -- iter: 160/307
[A[ATraining Step: 36  | total loss: [1m[32m0.18018[0m[0m | time: 107.450s
[2K
| Adam | epoch: 004 | loss: 0.18018 - acc: 0.9372 -- iter: 192/307
[A[ATraining Step: 37  | total loss: [1m[32m0.17229[0m[0m | time: 126.437s
[2K
| Adam | epoch: 004 | loss: 0.17229 - acc: 0.9435 -- iter: 224/307
[A[ATraining Step: 38  | total loss: [1m[32m0.15582[0m[0m | time: 142.071s
[2K
| Adam | epoch: 004 | loss: 0.15582 - acc: 0.9484 -- iter: 256/307
[A[ATraining Step: 39  | total loss: [1m[32m0.13928[0m[0m | time: 154.303s
[2K
| Adam | epoch: 004 | loss: 0.13928 - acc: 0.9523 -- iter: 288/307
[A[ATraining Step: 40  | total loss: [1m[32m0.15314[0m[0m | time: 173.357s
[2K
| Adam | epoch: 004 | loss: 0.15314 - acc: 0.9437 | val_loss: 2.18897 - val_acc: 0.4688 -- iter: 307/307
--
Training Step: 41  | total loss: [1m[32m0.14305[0m[0m | time: 63.171s
[2K
| Adam | epoch: 005 | loss: 0.14305 - acc: 0.9483 -- iter: 032/307
[A[ATraining Step: 42  | total loss: [1m[32m0.12382[0m[0m | time: 86.966s
[2K
| Adam | epoch: 005 | loss: 0.12382 - acc: 0.9576 -- iter: 064/307
[A[ATraining Step: 43  | total loss: [1m[32m0.14893[0m[0m | time: 98.533s
[2K
| Adam | epoch: 005 | loss: 0.14893 - acc: 0.9485 -- iter: 096/307
[A[ATraining Step: 44  | total loss: [1m[32m0.13253[0m[0m | time: 124.136s
[2K
| Adam | epoch: 005 | loss: 0.13253 - acc: 0.9574 -- iter: 128/307
[A[ATraining Step: 45  | total loss: [1m[32m0.12466[0m[0m | time: 146.608s
[2K
| Adam | epoch: 005 | loss: 0.12466 - acc: 0.9557 -- iter: 160/307
[A[ATraining Step: 46  | total loss: [1m[32m0.10699[0m[0m | time: 160.660s
[2K
| Adam | epoch: 005 | loss: 0.10699 - acc: 0.9631 -- iter: 192/307
[A[ATraining Step: 47  | total loss: [1m[32m0.10070[0m[0m | time: 173.617s
[2K
| Adam | epoch: 005 | loss: 0.10070 - acc: 0.9640 -- iter: 224/307
[A[ATraining Step: 48  | total loss: [1m[32m0.08934[0m[0m | time: 188.694s
[2K
| Adam | epoch: 005 | loss: 0.08934 - acc: 0.9698 -- iter: 256/307
[A[ATraining Step: 49  | total loss: [1m[32m0.09164[0m[0m | time: 217.524s
[2K
| Adam | epoch: 005 | loss: 0.09164 - acc: 0.9696 -- iter: 288/307
[A[ATraining Step: 50  | total loss: [1m[32m0.09539[0m[0m | time: 260.008s
[2K
| Adam | epoch: 005 | loss: 0.09539 - acc: 0.9598 | val_loss: 0.72798 - val_acc: 0.8021 -- iter: 307/307
--
Training Step: 51  | total loss: [1m[32m0.08275[0m[0m | time: 9.416s
[2K
| Adam | epoch: 006 | loss: 0.08275 - acc: 0.9659 -- iter: 032/307
[A[ATraining Step: 52  | total loss: [1m[32m0.09266[0m[0m | time: 17.925s
[2K
| Adam | epoch: 006 | loss: 0.09266 - acc: 0.9664 -- iter: 064/307
[A[ATraining Step: 53  | total loss: [1m[32m0.08926[0m[0m | time: 28.656s
[2K
| Adam | epoch: 006 | loss: 0.08926 - acc: 0.9667 -- iter: 096/307
[A[ATraining Step: 54  | total loss: [1m[32m0.08728[0m[0m | time: 39.436s
[2K
| Adam | epoch: 006 | loss: 0.08728 - acc: 0.9670 -- iter: 128/307
[A[ATraining Step: 55  | total loss: [1m[32m0.07731[0m[0m | time: 50.159s
[2K
| Adam | epoch: 006 | loss: 0.07731 - acc: 0.9717 -- iter: 160/307
[A[ATraining Step: 56  | total loss: [1m[32m0.11073[0m[0m | time: 78.999s
[2K
| Adam | epoch: 006 | loss: 0.11073 - acc: 0.9683 -- iter: 192/307
[A[ATraining Step: 57  | total loss: [1m[32m0.11857[0m[0m | time: 103.205s
[2K
| Adam | epoch: 006 | loss: 0.11857 - acc: 0.9640 -- iter: 224/307
[A[ATraining Step: 58  | total loss: [1m[32m0.11995[0m[0m | time: 120.620s
[2K
| Adam | epoch: 006 | loss: 0.11995 - acc: 0.9647 -- iter: 256/307
[A[ATraining Step: 59  | total loss: [1m[32m0.10742[0m[0m | time: 140.651s
[2K
| Adam | epoch: 006 | loss: 0.10742 - acc: 0.9694 -- iter: 288/307
[A[ATraining Step: 60  | total loss: [1m[32m0.09538[0m[0m | time: 160.974s
[2K
| Adam | epoch: 006 | loss: 0.09538 - acc: 0.9735 | val_loss: 0.57959 - val_acc: 0.8542 -- iter: 307/307
--
Training Step: 61  | total loss: [1m[32m0.08397[0m[0m | time: 22.264s
[2K
| Adam | epoch: 007 | loss: 0.08397 - acc: 0.9769 -- iter: 032/307
[A[ATraining Step: 62  | total loss: [1m[32m0.07482[0m[0m | time: 42.783s
[2K
| Adam | epoch: 007 | loss: 0.07482 - acc: 0.9799 -- iter: 064/307
[A[ATraining Step: 63  | total loss: [1m[32m0.07194[0m[0m | time: 60.511s
[2K
| Adam | epoch: 007 | loss: 0.07194 - acc: 0.9824 -- iter: 096/307
[A[ATraining Step: 64  | total loss: [1m[32m0.07078[0m[0m | time: 74.313s
[2K
| Adam | epoch: 007 | loss: 0.07078 - acc: 0.9807 -- iter: 128/307
[A[ATraining Step: 65  | total loss: [1m[32m0.06417[0m[0m | time: 82.288s
[2K
| Adam | epoch: 007 | loss: 0.06417 - acc: 0.9831 -- iter: 160/307
[A[ATraining Step: 66  | total loss: [1m[32m0.07806[0m[0m | time: 92.031s
[2K
| Adam | epoch: 007 | loss: 0.07806 - acc: 0.9788 -- iter: 192/307
[A[ATraining Step: 67  | total loss: [1m[32m0.11738[0m[0m | time: 106.816s
[2K
| Adam | epoch: 007 | loss: 0.11738 - acc: 0.9750 -- iter: 224/307
[A[ATraining Step: 68  | total loss: [1m[32m0.13331[0m[0m | time: 122.552s
[2K
| Adam | epoch: 007 | loss: 0.13331 - acc: 0.9632 -- iter: 256/307
[A[ATraining Step: 69  | total loss: [1m[32m0.13018[0m[0m | time: 135.365s
[2K
| Adam | epoch: 007 | loss: 0.13018 - acc: 0.9638 -- iter: 288/307
[A[ATraining Step: 70  | total loss: [1m[32m0.14690[0m[0m | time: 170.266s
[2K
| Adam | epoch: 007 | loss: 0.14690 - acc: 0.9572 | val_loss: 0.49920 - val_acc: 0.8125 -- iter: 307/307
--
Training Step: 71  | total loss: [1m[32m0.13547[0m[0m | time: 19.162s
[2K
| Adam | epoch: 008 | loss: 0.13547 - acc: 0.9620 -- iter: 032/307
[A[ATraining Step: 72  | total loss: [1m[32m0.13363[0m[0m | time: 37.090s
[2K
| Adam | epoch: 008 | loss: 0.13363 - acc: 0.9628 -- iter: 064/307
[A[ATraining Step: 73  | total loss: [1m[32m0.13379[0m[0m | time: 55.418s
[2K
| Adam | epoch: 008 | loss: 0.13379 - acc: 0.9565 -- iter: 096/307
[A[ATraining Step: 74  | total loss: [1m[32m0.13601[0m[0m | time: 72.983s
[2K
| Adam | epoch: 008 | loss: 0.13601 - acc: 0.9579 -- iter: 128/307
[A[ATraining Step: 75  | total loss: [1m[32m0.13007[0m[0m | time: 89.658s
[2K
| Adam | epoch: 008 | loss: 0.13007 - acc: 0.9590 -- iter: 160/307
[A[ATraining Step: 76  | total loss: [1m[32m0.13665[0m[0m | time: 98.202s
[2K
| Adam | epoch: 008 | loss: 0.13665 - acc: 0.9534 -- iter: 192/307
[A[ATraining Step: 77  | total loss: [1m[32m0.15984[0m[0m | time: 106.559s
[2K
| Adam | epoch: 008 | loss: 0.15984 - acc: 0.9416 -- iter: 224/307
[A[ATraining Step: 78  | total loss: [1m[32m0.16819[0m[0m | time: 125.551s
[2K
| Adam | epoch: 008 | loss: 0.16819 - acc: 0.9422 -- iter: 256/307
[A[ATraining Step: 79  | total loss: [1m[32m0.17701[0m[0m | time: 144.598s
[2K
| Adam | epoch: 008 | loss: 0.17701 - acc: 0.9385 -- iter: 288/307
[A[ATraining Step: 80  | total loss: [1m[32m0.16480[0m[0m | time: 173.716s
[2K
| Adam | epoch: 008 | loss: 0.16480 - acc: 0.9448 | val_loss: 0.36782 - val_acc: 0.9062 -- iter: 307/307
--
Training Step: 81  | total loss: [1m[32m0.15700[0m[0m | time: 8.428s
[2K
| Adam | epoch: 009 | loss: 0.15700 - acc: 0.9504 -- iter: 032/307
[A[ATraining Step: 82  | total loss: [1m[32m0.14886[0m[0m | time: 18.293s
[2K
| Adam | epoch: 009 | loss: 0.14886 - acc: 0.9522 -- iter: 064/307
[A[ATraining Step: 83  | total loss: [1m[32m0.13646[0m[0m | time: 28.424s
[2K
| Adam | epoch: 009 | loss: 0.13646 - acc: 0.9570 -- iter: 096/307
[A[ATraining Step: 84  | total loss: [1m[32m0.12860[0m[0m | time: 42.257s
[2K
| Adam | epoch: 009 | loss: 0.12860 - acc: 0.9613 -- iter: 128/307
[A[ATraining Step: 85  | total loss: [1m[32m0.13713[0m[0m | time: 58.035s
[2K
| Adam | epoch: 009 | loss: 0.13713 - acc: 0.9589 -- iter: 160/307
[A[ATraining Step: 86  | total loss: [1m[32m0.12867[0m[0m | time: 70.478s
[2K
| Adam | epoch: 009 | loss: 0.12867 - acc: 0.9630 -- iter: 192/307
[A[ATraining Step: 87  | total loss: [1m[32m0.12092[0m[0m | time: 78.562s
[2K
| Adam | epoch: 009 | loss: 0.12092 - acc: 0.9636 -- iter: 224/307
[A[ATraining Step: 88  | total loss: [1m[32m0.11143[0m[0m | time: 87.053s
[2K
| Adam | epoch: 009 | loss: 0.11143 - acc: 0.9672 -- iter: 256/307
[A[ATraining Step: 89  | total loss: [1m[32m0.14245[0m[0m | time: 99.738s
[2K
| Adam | epoch: 009 | loss: 0.14245 - acc: 0.9652 -- iter: 288/307
[A[ATraining Step: 90  | total loss: [1m[32m0.13057[0m[0m | time: 118.744s
[2K
| Adam | epoch: 009 | loss: 0.13057 - acc: 0.9687 | val_loss: 0.37143 - val_acc: 0.8438 -- iter: 307/307
--
Training Step: 91  | total loss: [1m[32m0.12504[0m[0m | time: 13.259s
[2K
| Adam | epoch: 010 | loss: 0.12504 - acc: 0.9687 -- iter: 032/307
[A[ATraining Step: 92  | total loss: [1m[32m0.11503[0m[0m | time: 26.438s
[2K
| Adam | epoch: 010 | loss: 0.11503 - acc: 0.9718 -- iter: 064/307
[A[ATraining Step: 93  | total loss: [1m[32m0.10767[0m[0m | time: 39.318s
[2K
| Adam | epoch: 010 | loss: 0.10767 - acc: 0.9747 -- iter: 096/307
[A[ATraining Step: 94  | total loss: [1m[32m0.10199[0m[0m | time: 51.989s
[2K
| Adam | epoch: 010 | loss: 0.10199 - acc: 0.9741 -- iter: 128/307
[A[ATraining Step: 95  | total loss: [1m[32m0.09782[0m[0m | time: 65.237s
[2K
| Adam | epoch: 010 | loss: 0.09782 - acc: 0.9735 -- iter: 160/307
[A[ATraining Step: 96  | total loss: [1m[32m0.09010[0m[0m | time: 76.067s
[2K
| Adam | epoch: 010 | loss: 0.09010 - acc: 0.9762 -- iter: 192/307
[A[ATraining Step: 97  | total loss: [1m[32m0.08435[0m[0m | time: 84.354s
[2K
| Adam | epoch: 010 | loss: 0.08435 - acc: 0.9786 -- iter: 224/307
[A[ATraining Step: 98  | total loss: [1m[32m0.08039[0m[0m | time: 89.771s
[2K
| Adam | epoch: 010 | loss: 0.08039 - acc: 0.9807 -- iter: 256/307
[A[ATraining Step: 99  | total loss: [1m[32m0.07302[0m[0m | time: 97.191s
[2K
| Adam | epoch: 010 | loss: 0.07302 - acc: 0.9826 -- iter: 288/307
[A[ATraining Step: 100  | total loss: [1m[32m0.09051[0m[0m | time: 117.352s
[2K
| Adam | epoch: 010 | loss: 0.09051 - acc: 0.9791 | val_loss: 0.49384 - val_acc: 0.8646 -- iter: 307/307
--
Training Step: 101  | total loss: [1m[32m0.08231[0m[0m | time: 12.997s
[2K
| Adam | epoch: 011 | loss: 0.08231 - acc: 0.9812 -- iter: 032/307
[A[ATraining Step: 102  | total loss: [1m[32m0.07829[0m[0m | time: 26.065s
[2K
| Adam | epoch: 011 | loss: 0.07829 - acc: 0.9831 -- iter: 064/307
[A[ATraining Step: 103  | total loss: [1m[32m0.07190[0m[0m | time: 38.767s
[2K
| Adam | epoch: 011 | loss: 0.07190 - acc: 0.9848 -- iter: 096/307
[A[ATraining Step: 104  | total loss: [1m[32m0.07236[0m[0m | time: 51.669s
[2K
| Adam | epoch: 011 | loss: 0.07236 - acc: 0.9863 -- iter: 128/307
[A[ATraining Step: 105  | total loss: [1m[32m0.06715[0m[0m | time: 64.232s
[2K
| Adam | epoch: 011 | loss: 0.06715 - acc: 0.9877 -- iter: 160/307
[A[ATraining Step: 106  | total loss: [1m[32m0.06134[0m[0m | time: 77.153s
[2K
| Adam | epoch: 011 | loss: 0.06134 - acc: 0.9889 -- iter: 192/307
[A[ATraining Step: 107  | total loss: [1m[32m0.05599[0m[0m | time: 89.290s
[2K
| Adam | epoch: 011 | loss: 0.05599 - acc: 0.9900 -- iter: 224/307
[A[ATraining Step: 108  | total loss: [1m[32m0.05239[0m[0m | time: 101.766s
[2K
| Adam | epoch: 011 | loss: 0.05239 - acc: 0.9910 -- iter: 256/307
[A[ATraining Step: 109  | total loss: [1m[32m0.04897[0m[0m | time: 111.826s
[2K
| Adam | epoch: 011 | loss: 0.04897 - acc: 0.9919 -- iter: 288/307
[A[ATraining Step: 110  | total loss: [1m[32m0.04445[0m[0m | time: 127.152s
[2K
| Adam | epoch: 011 | loss: 0.04445 - acc: 0.9927 | val_loss: 1.50877 - val_acc: 0.6771 -- iter: 307/307
--
Training Step: 111  | total loss: [1m[32m0.05567[0m[0m | time: 8.825s
[2K
| Adam | epoch: 012 | loss: 0.05567 - acc: 0.9882 -- iter: 032/307
[A[ATraining Step: 112  | total loss: [1m[32m0.06105[0m[0m | time: 17.282s
[2K
| Adam | epoch: 012 | loss: 0.06105 - acc: 0.9831 -- iter: 064/307
[A[ATraining Step: 113  | total loss: [1m[32m0.05564[0m[0m | time: 30.213s
[2K
| Adam | epoch: 012 | loss: 0.05564 - acc: 0.9848 -- iter: 096/307
[A[ATraining Step: 114  | total loss: [1m[32m0.05178[0m[0m | time: 51.346s
[2K
| Adam | epoch: 012 | loss: 0.05178 - acc: 0.9863 -- iter: 128/307
[A[ATraining Step: 115  | total loss: [1m[32m0.04760[0m[0m | time: 64.253s
[2K
| Adam | epoch: 012 | loss: 0.04760 - acc: 0.9877 -- iter: 160/307
[A[ATraining Step: 116  | total loss: [1m[32m0.04316[0m[0m | time: 81.485s
[2K
| Adam | epoch: 012 | loss: 0.04316 - acc: 0.9889 -- iter: 192/307
[A[ATraining Step: 117  | total loss: [1m[32m0.04058[0m[0m | time: 103.276s
[2K
| Adam | epoch: 012 | loss: 0.04058 - acc: 0.9900 -- iter: 224/307
[A[ATraining Step: 118  | total loss: [1m[32m0.03685[0m[0m | time: 115.333s
[2K
| Adam | epoch: 012 | loss: 0.03685 - acc: 0.9910 -- iter: 256/307
[A[ATraining Step: 119  | total loss: [1m[32m0.10426[0m[0m | time: 127.600s
[2K
| Adam | epoch: 012 | loss: 0.10426 - acc: 0.9732 -- iter: 288/307
[A[ATraining Step: 120  | total loss: [1m[32m0.09492[0m[0m | time: 142.667s
[2K
| Adam | epoch: 012 | loss: 0.09492 - acc: 0.9759 | val_loss: 0.50812 - val_acc: 0.8646 -- iter: 307/307
--
Training Step: 121  | total loss: [1m[32m0.08712[0m[0m | time: 8.337s
[2K
| Adam | epoch: 013 | loss: 0.08712 - acc: 0.9783 -- iter: 032/307
[A[ATraining Step: 122  | total loss: [1m[32m0.11513[0m[0m | time: 20.839s
[2K
| Adam | epoch: 013 | loss: 0.11513 - acc: 0.9752 -- iter: 064/307
[A[ATraining Step: 123  | total loss: [1m[32m0.10628[0m[0m | time: 33.981s
[2K
| Adam | epoch: 013 | loss: 0.10628 - acc: 0.9777 -- iter: 096/307
[A[ATraining Step: 124  | total loss: [1m[32m0.10365[0m[0m | time: 46.593s
[2K
| Adam | epoch: 013 | loss: 0.10365 - acc: 0.9799 -- iter: 128/307
[A[ATraining Step: 125  | total loss: [1m[32m0.10526[0m[0m | time: 60.131s
[2K
| Adam | epoch: 013 | loss: 0.10526 - acc: 0.9788 -- iter: 160/307
[A[ATraining Step: 126  | total loss: [1m[32m0.11365[0m[0m | time: 68.821s
[2K
| Adam | epoch: 013 | loss: 0.11365 - acc: 0.9747 -- iter: 192/307
[A[ATraining Step: 127  | total loss: [1m[32m0.10339[0m[0m | time: 77.359s
[2K
| Adam | epoch: 013 | loss: 0.10339 - acc: 0.9772 -- iter: 224/307
[A[ATraining Step: 128  | total loss: [1m[32m0.09632[0m[0m | time: 87.564s
[2K
| Adam | epoch: 013 | loss: 0.09632 - acc: 0.9763 -- iter: 256/307
[A[ATraining Step: 129  | total loss: [1m[32m0.08948[0m[0m | time: 99.759s
[2K
| Adam | epoch: 013 | loss: 0.08948 - acc: 0.9787 -- iter: 288/307
[A[ATraining Step: 130  | total loss: [1m[32m0.08216[0m[0m | time: 119.465s
[2K
| Adam | epoch: 013 | loss: 0.08216 - acc: 0.9808 | val_loss: 1.05372 - val_acc: 0.6979 -- iter: 307/307
--
Training Step: 131  | total loss: [1m[32m0.07941[0m[0m | time: 8.005s
[2K
| Adam | epoch: 014 | loss: 0.07941 - acc: 0.9796 -- iter: 032/307
[A[ATraining Step: 132  | total loss: [1m[32m0.07360[0m[0m | time: 15.858s
[2K
| Adam | epoch: 014 | loss: 0.07360 - acc: 0.9817 -- iter: 064/307
[A[ATraining Step: 133  | total loss: [1m[32m0.14883[0m[0m | time: 28.478s
[2K
| Adam | epoch: 014 | loss: 0.14883 - acc: 0.9677 -- iter: 096/307
[A[ATraining Step: 134  | total loss: [1m[32m0.13745[0m[0m | time: 41.330s
[2K
| Adam | epoch: 014 | loss: 0.13745 - acc: 0.9709 -- iter: 128/307
[A[ATraining Step: 135  | total loss: [1m[32m0.12665[0m[0m | time: 53.676s
[2K
| Adam | epoch: 014 | loss: 0.12665 - acc: 0.9738 -- iter: 160/307
[A[ATraining Step: 136  | total loss: [1m[32m0.11725[0m[0m | time: 66.668s
[2K
| Adam | epoch: 014 | loss: 0.11725 - acc: 0.9765 -- iter: 192/307
[A[ATraining Step: 137  | total loss: [1m[32m0.11700[0m[0m | time: 79.142s
[2K
| Adam | epoch: 014 | loss: 0.11700 - acc: 0.9694 -- iter: 224/307
[A[ATraining Step: 138  | total loss: [1m[32m0.11800[0m[0m | time: 92.948s
[2K
| Adam | epoch: 014 | loss: 0.11800 - acc: 0.9694 -- iter: 256/307
[A[ATraining Step: 139  | total loss: [1m[32m0.12382[0m[0m | time: 107.203s
[2K
| Adam | epoch: 014 | loss: 0.12382 - acc: 0.9662 -- iter: 288/307
[A[ATraining Step: 140  | total loss: [1m[32m0.11496[0m[0m | time: 126.920s
[2K
| Adam | epoch: 014 | loss: 0.11496 - acc: 0.9696 | val_loss: 1.11609 - val_acc: 0.6667 -- iter: 307/307
--
Training Step: 141  | total loss: [1m[32m0.10822[0m[0m | time: 14.207s
[2K
| Adam | epoch: 015 | loss: 0.10822 - acc: 0.9726 -- iter: 032/307
[A[ATraining Step: 142  | total loss: [1m[32m0.10200[0m[0m | time: 22.331s
[2K
| Adam | epoch: 015 | loss: 0.10200 - acc: 0.9753 -- iter: 064/307
[A[ATraining Step: 143  | total loss: [1m[32m0.09523[0m[0m | time: 30.696s
[2K
| Adam | epoch: 015 | loss: 0.09523 - acc: 0.9778 -- iter: 096/307
[A[ATraining Step: 144  | total loss: [1m[32m0.08859[0m[0m | time: 43.533s
[2K
| Adam | epoch: 015 | loss: 0.08859 - acc: 0.9800 -- iter: 128/307
[A[ATraining Step: 145  | total loss: [1m[32m0.08268[0m[0m | time: 58.603s
[2K
| Adam | epoch: 015 | loss: 0.08268 - acc: 0.9820 -- iter: 160/307
[A[ATraining Step: 146  | total loss: [1m[32m0.07825[0m[0m | time: 71.711s
[2K
| Adam | epoch: 015 | loss: 0.07825 - acc: 0.9807 -- iter: 192/307
[A[ATraining Step: 147  | total loss: [1m[32m0.07359[0m[0m | time: 84.664s
[2K
| Adam | epoch: 015 | loss: 0.07359 - acc: 0.9826 -- iter: 224/307
[A[ATraining Step: 148  | total loss: [1m[32m0.06731[0m[0m | time: 97.622s
[2K
| Adam | epoch: 015 | loss: 0.06731 - acc: 0.9844 -- iter: 256/307
[A[ATraining Step: 149  | total loss: [1m[32m0.06263[0m[0m | time: 109.731s
[2K
| Adam | epoch: 015 | loss: 0.06263 - acc: 0.9859 -- iter: 288/307
[A[ATraining Step: 150  | total loss: [1m[32m0.06684[0m[0m | time: 129.800s
[2K
| Adam | epoch: 015 | loss: 0.06684 - acc: 0.9811 | val_loss: 0.58365 - val_acc: 0.8125 -- iter: 307/307
--
Validation AUC:0.9403050108932461
Validation AUPRC:0.9228203206555968
Test AUC:0.9894179894179893
Test AUPRC:0.9949809023710927
BestTestF1Score	0.97	0.91	0.96	0.98	0.95	60	1	32	3	0.98
BestTestMCCScore	0.97	0.91	0.96	0.98	0.95	60	1	32	3	0.98
BestTestAccuracyScore	0.97	0.91	0.96	0.98	0.95	60	1	32	3	0.98
BestValidationF1Score	0.93	0.86	0.93	0.96	0.9	46	2	43	5	0.98
BestValidationMCC	0.93	0.86	0.93	0.96	0.9	46	2	43	5	0.98
BestValidationAccuracy	0.93	0.86	0.93	0.96	0.9	46	2	43	5	0.98
TestPredictions (Threshold:0.98)
CHEMBL3687322,TP,ACT,1.0	CHEMBL3687356,TP,ACT,1.0	CHEMBL463866,TN,INACT,0.0	CHEMBL254384,TN,INACT,0.36000001430511475	CHEMBL304786,TN,INACT,0.5199999809265137	CHEMBL741,TN,INACT,0.0	CHEMBL3353574,TP,ACT,1.0	CHEMBL2376864,TN,INACT,0.6000000238418579	CHEMBL2386173,TN,INACT,0.9700000286102295	CHEMBL3682617,TP,ACT,1.0	CHEMBL3687385,TP,ACT,1.0	CHEMBL3687400,TP,ACT,1.0	CHEMBL3353605,TP,ACT,1.0	CHEMBL2087051,FP,INACT,1.0	CHEMBL3682544,TP,ACT,1.0	CHEMBL259208,TN,INACT,0.0	CHEMBL3577882,TP,ACT,1.0	CHEMBL468913,TN,INACT,0.3199999928474426	CHEMBL924,TN,INACT,0.0	CHEMBL3353581,TP,ACT,1.0	CHEMBL3687369,TP,ACT,1.0	CHEMBL2386175,TN,INACT,0.4399999976158142	CHEMBL3687404,TP,ACT,1.0	CHEMBL3682580,TP,ACT,1.0	CHEMBL2443089,TP,ACT,0.9900000095367432	CHEMBL505222,TN,INACT,0.0	CHEMBL2442015,TP,ACT,1.0	CHEMBL3682608,TP,ACT,1.0	CHEMBL2443073,TP,ACT,1.0	CHEMBL3687352,TP,ACT,1.0	CHEMBL3682611,TP,ACT,1.0	CHEMBL3682552,TP,ACT,1.0	CHEMBL2153704,TN,INACT,0.019999999552965164	CHEMBL3687349,TP,ACT,1.0	CHEMBL3735230,TN,INACT,0.029999999329447746	CHEMBL3687407,TP,ACT,1.0	CHEMBL3697711,TN,INACT,0.33000001311302185	CHEMBL3687393,TP,ACT,1.0	CHEMBL3687333,TP,ACT,1.0	CHEMBL3353579,TP,ACT,1.0	CHEMBL3687323,TP,ACT,1.0	CHEMBL3682613,TP,ACT,1.0	CHEMBL2087072,TN,INACT,0.3400000035762787	CHEMBL3682586,TP,ACT,1.0	CHEMBL3687392,TP,ACT,1.0	CHEMBL2440148,FN,ACT,0.8500000238418579	CHEMBL3589911,TN,INACT,0.8100000023841858	CHEMBL3682560,TP,ACT,1.0	CHEMBL3593946,TN,INACT,0.019999999552965164	CHEMBL3577905,TP,ACT,1.0	CHEMBL2442021,TP,ACT,1.0	CHEMBL3682602,TP,ACT,1.0	CHEMBL3687391,TP,ACT,1.0	CHEMBL261097,TN,INACT,0.0	CHEMBL3687345,TP,ACT,1.0	CHEMBL2443083,TP,ACT,0.9900000095367432	CHEMBL3687331,TP,ACT,1.0	CHEMBL23479,TN,INACT,0.029999999329447746	CHEMBL3687332,TP,ACT,1.0	CHEMBL466000,TN,INACT,0.1899999976158142	CHEMBL97266,TN,INACT,0.009999999776482582	CHEMBL3353582,TP,ACT,1.0	CHEMBL3235974,TP,ACT,1.0	CHEMBL3682589,TP,ACT,1.0	CHEMBL3687347,TP,ACT,1.0	CHEMBL1650511,FN,ACT,0.9700000286102295	CHEMBL3687395,TP,ACT,1.0	CHEMBL3687339,TP,ACT,1.0	CHEMBL277580,TN,INACT,0.0	CHEMBL3687361,TP,ACT,1.0	CHEMBL3682567,TP,ACT,1.0	CHEMBL3682609,TP,ACT,1.0	CHEMBL3687413,TP,ACT,1.0	CHEMBL1084643,TN,INACT,0.009999999776482582	CHEMBL27768,TN,INACT,0.25	CHEMBL3589892,TN,INACT,0.25	CHEMBL3353610,TP,ACT,1.0	CHEMBL2443061,TP,ACT,1.0	CHEMBL3682572,TP,ACT,1.0	CHEMBL3682585,TP,ACT,1.0	CHEMBL182120,TN,INACT,0.029999999329447746	CHEMBL2376852,TN,INACT,0.8100000023841858	CHEMBL2443085,TP,ACT,0.9900000095367432	CHEMBL3218118,FN,ACT,0.28999999165534973	CHEMBL3353595,TP,ACT,1.0	CHEMBL3682570,TP,ACT,1.0	CHEMBL3577903,TP,ACT,0.9900000095367432	CHEMBL3682594,TP,ACT,1.0	CHEMBL3355290,TN,INACT,0.3400000035762787	CHEMBL2376854,TN,INACT,0.10999999940395355	CHEMBL3682584,TP,ACT,1.0	CHEMBL213470,TN,INACT,0.0	CHEMBL517023,TN,INACT,0.9200000166893005	CHEMBL2442031,TP,ACT,1.0	CHEMBL316720,TN,INACT,0.17000000178813934	CHEMBL2443074,TP,ACT,1.0	

