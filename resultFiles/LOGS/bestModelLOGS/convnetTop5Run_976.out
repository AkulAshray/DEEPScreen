ImageNetInceptionV2 CHEMBL4489 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	131
Number of inactive compounds :	131
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4489_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4489_adam_0.0001_15_0.8/
---------------------------------
Training samples: 158
Validation samples: 50
--
Training Step: 1  | time: 59.679s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/158
[A[ATraining Step: 2  | total loss: [1m[32m0.68628[0m[0m | time: 72.550s
[2K
| Adam | epoch: 001 | loss: 0.68628 - acc: 0.3094 -- iter: 064/158
[A[ATraining Step: 3  | total loss: [1m[32m0.55222[0m[0m | time: 87.383s
[2K
| Adam | epoch: 001 | loss: 0.55222 - acc: 0.6699 -- iter: 096/158
[A[ATraining Step: 4  | total loss: [1m[32m0.52437[0m[0m | time: 100.604s
[2K
| Adam | epoch: 001 | loss: 0.52437 - acc: 0.7534 -- iter: 128/158
[A[ATraining Step: 5  | total loss: [1m[32m0.78196[0m[0m | time: 128.688s
[2K
| Adam | epoch: 001 | loss: 0.78196 - acc: 0.5780 | val_loss: 1.36976 - val_acc: 0.6000 -- iter: 158/158
--
Training Step: 6  | total loss: [1m[32m0.47526[0m[0m | time: 11.494s
[2K
| Adam | epoch: 002 | loss: 0.47526 - acc: 0.8064 -- iter: 032/158
[A[ATraining Step: 7  | total loss: [1m[32m0.32294[0m[0m | time: 24.075s
[2K
| Adam | epoch: 002 | loss: 0.32294 - acc: 0.9026 -- iter: 064/158
[A[ATraining Step: 8  | total loss: [1m[32m0.29754[0m[0m | time: 36.628s
[2K
| Adam | epoch: 002 | loss: 0.29754 - acc: 0.9046 -- iter: 096/158
[A[ATraining Step: 9  | total loss: [1m[32m0.30239[0m[0m | time: 49.020s
[2K
| Adam | epoch: 002 | loss: 0.30239 - acc: 0.9055 -- iter: 128/158
[A[ATraining Step: 10  | total loss: [1m[32m0.24064[0m[0m | time: 65.896s
[2K
| Adam | epoch: 002 | loss: 0.24064 - acc: 0.9527 | val_loss: 2.44492 - val_acc: 0.6000 -- iter: 158/158
--
Training Step: 11  | total loss: [1m[32m0.24932[0m[0m | time: 13.704s
[2K
| Adam | epoch: 003 | loss: 0.24932 - acc: 0.9455 -- iter: 032/158
[A[ATraining Step: 12  | total loss: [1m[32m0.25993[0m[0m | time: 40.908s
[2K
| Adam | epoch: 003 | loss: 0.25993 - acc: 0.9400 -- iter: 064/158
[A[ATraining Step: 13  | total loss: [1m[32m0.23074[0m[0m | time: 52.686s
[2K
| Adam | epoch: 003 | loss: 0.23074 - acc: 0.9372 -- iter: 096/158
[A[ATraining Step: 14  | total loss: [1m[32m0.18036[0m[0m | time: 64.556s
[2K
| Adam | epoch: 003 | loss: 0.18036 - acc: 0.9501 -- iter: 128/158
[A[ATraining Step: 15  | total loss: [1m[32m0.15180[0m[0m | time: 80.429s
[2K
| Adam | epoch: 003 | loss: 0.15180 - acc: 0.9452 | val_loss: 3.14593 - val_acc: 0.6000 -- iter: 158/158
--
Training Step: 16  | total loss: [1m[32m0.21582[0m[0m | time: 12.243s
[2K
| Adam | epoch: 004 | loss: 0.21582 - acc: 0.9189 -- iter: 032/158
[A[ATraining Step: 17  | total loss: [1m[32m0.16662[0m[0m | time: 23.736s
[2K
| Adam | epoch: 004 | loss: 0.16662 - acc: 0.9481 -- iter: 064/158
[A[ATraining Step: 18  | total loss: [1m[32m0.15273[0m[0m | time: 51.871s
[2K
| Adam | epoch: 004 | loss: 0.15273 - acc: 0.9430 -- iter: 096/158
[A[ATraining Step: 19  | total loss: [1m[32m0.12694[0m[0m | time: 63.546s
[2K
| Adam | epoch: 004 | loss: 0.12694 - acc: 0.9620 -- iter: 128/158
[A[ATraining Step: 20  | total loss: [1m[32m0.11398[0m[0m | time: 79.287s
[2K
| Adam | epoch: 004 | loss: 0.11398 - acc: 0.9642 | val_loss: 3.40105 - val_acc: 0.6000 -- iter: 158/158
--
Training Step: 21  | total loss: [1m[32m0.08434[0m[0m | time: 12.476s
[2K
| Adam | epoch: 005 | loss: 0.08434 - acc: 0.9753 -- iter: 032/158
[A[ATraining Step: 22  | total loss: [1m[32m0.07056[0m[0m | time: 25.130s
[2K
| Adam | epoch: 005 | loss: 0.07056 - acc: 0.9827 -- iter: 064/158
[A[ATraining Step: 23  | total loss: [1m[32m0.06694[0m[0m | time: 37.119s
[2K
| Adam | epoch: 005 | loss: 0.06694 - acc: 0.9786 -- iter: 096/158
[A[ATraining Step: 24  | total loss: [1m[32m0.09386[0m[0m | time: 49.264s
[2K
| Adam | epoch: 005 | loss: 0.09386 - acc: 0.9753 -- iter: 128/158
[A[ATraining Step: 25  | total loss: [1m[32m0.09325[0m[0m | time: 61.556s
[2K
| Adam | epoch: 005 | loss: 0.09325 - acc: 0.9729 | val_loss: 3.33469 - val_acc: 0.6000 -- iter: 158/158
--
Training Step: 26  | total loss: [1m[32m0.07400[0m[0m | time: 14.779s
[2K
| Adam | epoch: 006 | loss: 0.07400 - acc: 0.9801 -- iter: 032/158
[A[ATraining Step: 27  | total loss: [1m[32m0.05911[0m[0m | time: 47.570s
[2K
| Adam | epoch: 006 | loss: 0.05911 - acc: 0.9852 -- iter: 064/158
[A[ATraining Step: 28  | total loss: [1m[32m0.09906[0m[0m | time: 65.072s
[2K
| Adam | epoch: 006 | loss: 0.09906 - acc: 0.9811 -- iter: 096/158
[A[ATraining Step: 29  | total loss: [1m[32m0.07757[0m[0m | time: 76.382s
[2K
| Adam | epoch: 006 | loss: 0.07757 - acc: 0.9857 -- iter: 128/158
[A[ATraining Step: 30  | total loss: [1m[32m0.06566[0m[0m | time: 90.527s
[2K
| Adam | epoch: 006 | loss: 0.06566 - acc: 0.9891 | val_loss: 2.83407 - val_acc: 0.6000 -- iter: 158/158
--
Training Step: 31  | total loss: [1m[32m0.05498[0m[0m | time: 12.121s
[2K
| Adam | epoch: 007 | loss: 0.05498 - acc: 0.9916 -- iter: 032/158
[A[ATraining Step: 32  | total loss: [1m[32m0.04479[0m[0m | time: 26.216s
[2K
| Adam | epoch: 007 | loss: 0.04479 - acc: 0.9935 -- iter: 064/158
[A[ATraining Step: 33  | total loss: [1m[32m0.06564[0m[0m | time: 51.655s
[2K
| Adam | epoch: 007 | loss: 0.06564 - acc: 0.9881 -- iter: 096/158
[A[ATraining Step: 34  | total loss: [1m[32m0.05412[0m[0m | time: 63.395s
[2K
| Adam | epoch: 007 | loss: 0.05412 - acc: 0.9906 -- iter: 128/158
[A[ATraining Step: 35  | total loss: [1m[32m0.06617[0m[0m | time: 78.515s
[2K
| Adam | epoch: 007 | loss: 0.06617 - acc: 0.9860 | val_loss: 1.55145 - val_acc: 0.6000 -- iter: 158/158
--
Training Step: 36  | total loss: [1m[32m0.05339[0m[0m | time: 11.342s
[2K
| Adam | epoch: 008 | loss: 0.05339 - acc: 0.9889 -- iter: 032/158
[A[ATraining Step: 37  | total loss: [1m[32m0.04352[0m[0m | time: 23.345s
[2K
| Adam | epoch: 008 | loss: 0.04352 - acc: 0.9911 -- iter: 064/158
[A[ATraining Step: 38  | total loss: [1m[32m0.03837[0m[0m | time: 35.520s
[2K
| Adam | epoch: 008 | loss: 0.03837 - acc: 0.9929 -- iter: 096/158
[A[ATraining Step: 39  | total loss: [1m[32m0.03305[0m[0m | time: 47.984s
[2K
| Adam | epoch: 008 | loss: 0.03305 - acc: 0.9942 -- iter: 128/158
[A[ATraining Step: 40  | total loss: [1m[32m0.07193[0m[0m | time: 67.598s
[2K
| Adam | epoch: 008 | loss: 0.07193 - acc: 0.9894 | val_loss: 0.63677 - val_acc: 0.6600 -- iter: 158/158
--
Training Step: 41  | total loss: [1m[32m0.08112[0m[0m | time: 11.699s
[2K
| Adam | epoch: 009 | loss: 0.08112 - acc: 0.9856 -- iter: 032/158
[A[ATraining Step: 42  | total loss: [1m[32m0.07010[0m[0m | time: 23.238s
[2K
| Adam | epoch: 009 | loss: 0.07010 - acc: 0.9882 -- iter: 064/158
[A[ATraining Step: 43  | total loss: [1m[32m0.06028[0m[0m | time: 43.313s
[2K
| Adam | epoch: 009 | loss: 0.06028 - acc: 0.9903 -- iter: 096/158
[A[ATraining Step: 44  | total loss: [1m[32m0.05870[0m[0m | time: 55.095s
[2K
| Adam | epoch: 009 | loss: 0.05870 - acc: 0.9920 -- iter: 128/158
[A[ATraining Step: 45  | total loss: [1m[32m0.06392[0m[0m | time: 70.199s
[2K
| Adam | epoch: 009 | loss: 0.06392 - acc: 0.9880 | val_loss: 0.60921 - val_acc: 0.7400 -- iter: 158/158
--
Training Step: 46  | total loss: [1m[32m0.06083[0m[0m | time: 11.862s
[2K
| Adam | epoch: 010 | loss: 0.06083 - acc: 0.9848 -- iter: 032/158
[A[ATraining Step: 47  | total loss: [1m[32m0.05149[0m[0m | time: 23.025s
[2K
| Adam | epoch: 010 | loss: 0.05149 - acc: 0.9873 -- iter: 064/158
[A[ATraining Step: 48  | total loss: [1m[32m0.04453[0m[0m | time: 34.423s
[2K
| Adam | epoch: 010 | loss: 0.04453 - acc: 0.9893 -- iter: 096/158
[A[ATraining Step: 49  | total loss: [1m[32m0.03852[0m[0m | time: 46.677s
[2K
| Adam | epoch: 010 | loss: 0.03852 - acc: 0.9910 -- iter: 128/158
[A[ATraining Step: 50  | total loss: [1m[32m0.03486[0m[0m | time: 61.991s
[2K
| Adam | epoch: 010 | loss: 0.03486 - acc: 0.9924 | val_loss: 0.52437 - val_acc: 0.7600 -- iter: 158/158
--
Training Step: 51  | total loss: [1m[32m0.04762[0m[0m | time: 12.406s
[2K
| Adam | epoch: 011 | loss: 0.04762 - acc: 0.9888 -- iter: 032/158
[A[ATraining Step: 52  | total loss: [1m[32m0.08605[0m[0m | time: 24.682s
[2K
| Adam | epoch: 011 | loss: 0.08605 - acc: 0.9764 -- iter: 064/158
[A[ATraining Step: 53  | total loss: [1m[32m0.07483[0m[0m | time: 36.896s
[2K
| Adam | epoch: 011 | loss: 0.07483 - acc: 0.9799 -- iter: 096/158
[A[ATraining Step: 54  | total loss: [1m[32m0.07002[0m[0m | time: 48.900s
[2K
| Adam | epoch: 011 | loss: 0.07002 - acc: 0.9780 -- iter: 128/158
[A[ATraining Step: 55  | total loss: [1m[32m0.06427[0m[0m | time: 62.060s
[2K
| Adam | epoch: 011 | loss: 0.06427 - acc: 0.9811 | val_loss: 0.28775 - val_acc: 0.8800 -- iter: 158/158
--
Training Step: 56  | total loss: [1m[32m0.05648[0m[0m | time: 21.027s
[2K
| Adam | epoch: 012 | loss: 0.05648 - acc: 0.9838 -- iter: 032/158
[A[ATraining Step: 57  | total loss: [1m[32m0.04945[0m[0m | time: 32.978s
[2K
| Adam | epoch: 012 | loss: 0.04945 - acc: 0.9860 -- iter: 064/158
[A[ATraining Step: 58  | total loss: [1m[32m0.04381[0m[0m | time: 44.918s
[2K
| Adam | epoch: 012 | loss: 0.04381 - acc: 0.9879 -- iter: 096/158
[A[ATraining Step: 59  | total loss: [1m[32m0.03936[0m[0m | time: 56.172s
[2K
| Adam | epoch: 012 | loss: 0.03936 - acc: 0.9896 -- iter: 128/158
[A[ATraining Step: 60  | total loss: [1m[32m0.03801[0m[0m | time: 70.986s
[2K
| Adam | epoch: 012 | loss: 0.03801 - acc: 0.9909 | val_loss: 0.34673 - val_acc: 0.9000 -- iter: 158/158
--
Training Step: 61  | total loss: [1m[32m0.03576[0m[0m | time: 11.704s
[2K
| Adam | epoch: 013 | loss: 0.03576 - acc: 0.9921 -- iter: 032/158
[A[ATraining Step: 62  | total loss: [1m[32m0.03295[0m[0m | time: 24.023s
[2K
| Adam | epoch: 013 | loss: 0.03295 - acc: 0.9931 -- iter: 064/158
[A[ATraining Step: 63  | total loss: [1m[32m0.03329[0m[0m | time: 36.335s
[2K
| Adam | epoch: 013 | loss: 0.03329 - acc: 0.9900 -- iter: 096/158
[A[ATraining Step: 64  | total loss: [1m[32m0.02965[0m[0m | time: 48.079s
[2K
| Adam | epoch: 013 | loss: 0.02965 - acc: 0.9913 -- iter: 128/158
[A[ATraining Step: 65  | total loss: [1m[32m0.02660[0m[0m | time: 63.303s
[2K
| Adam | epoch: 013 | loss: 0.02660 - acc: 0.9924 | val_loss: 0.48651 - val_acc: 0.8400 -- iter: 158/158
--
Training Step: 66  | total loss: [1m[32m0.02412[0m[0m | time: 11.665s
[2K
| Adam | epoch: 014 | loss: 0.02412 - acc: 0.9933 -- iter: 032/158
[A[ATraining Step: 67  | total loss: [1m[32m0.02191[0m[0m | time: 23.520s
[2K
| Adam | epoch: 014 | loss: 0.02191 - acc: 0.9941 -- iter: 064/158
[A[ATraining Step: 68  | total loss: [1m[32m0.02806[0m[0m | time: 35.580s
[2K
| Adam | epoch: 014 | loss: 0.02806 - acc: 0.9911 -- iter: 096/158
[A[ATraining Step: 69  | total loss: [1m[32m0.02625[0m[0m | time: 48.026s
[2K
| Adam | epoch: 014 | loss: 0.02625 - acc: 0.9921 -- iter: 128/158
[A[ATraining Step: 70  | total loss: [1m[32m0.04448[0m[0m | time: 63.388s
[2K
| Adam | epoch: 014 | loss: 0.04448 - acc: 0.9858 | val_loss: 0.30511 - val_acc: 0.9000 -- iter: 158/158
--
Training Step: 71  | total loss: [1m[32m0.03987[0m[0m | time: 12.522s
[2K
| Adam | epoch: 015 | loss: 0.03987 - acc: 0.9874 -- iter: 032/158
[A[ATraining Step: 72  | total loss: [1m[32m0.03575[0m[0m | time: 23.577s
[2K
| Adam | epoch: 015 | loss: 0.03575 - acc: 0.9889 -- iter: 064/158
[A[ATraining Step: 73  | total loss: [1m[32m0.03216[0m[0m | time: 35.174s
[2K
| Adam | epoch: 015 | loss: 0.03216 - acc: 0.9901 -- iter: 096/158
[A[ATraining Step: 74  | total loss: [1m[32m0.02960[0m[0m | time: 47.161s
[2K
| Adam | epoch: 015 | loss: 0.02960 - acc: 0.9912 -- iter: 128/158
[A[ATraining Step: 75  | total loss: [1m[32m0.03516[0m[0m | time: 62.404s
[2K
| Adam | epoch: 015 | loss: 0.03516 - acc: 0.9888 | val_loss: 0.23592 - val_acc: 0.8800 -- iter: 158/158
--
Validation AUC:0.9650000000000001
Validation AUPRC:0.9382717605732985
Test AUC:0.9935897435897436
Test AUPRC:0.9948717948717947
BestTestF1Score	0.98	0.96	0.98	1.0	0.96	25	0	24	1	0.76
BestTestMCCScore	0.98	0.96	0.98	1.0	0.96	25	0	24	1	0.76
BestTestAccuracyScore	0.98	0.96	0.98	1.0	0.96	25	0	24	1	0.76
BestValidationF1Score	0.92	0.87	0.94	0.95	0.9	18	1	29	2	0.76
BestValidationMCC	0.92	0.87	0.94	0.95	0.9	18	1	29	2	0.76
BestValidationAccuracy	0.92	0.87	0.94	0.95	0.9	18	1	29	2	0.76
TestPredictions (Threshold:0.76)
CHEMBL9666,TN,INACT,0.0	CHEMBL2323791,TP,ACT,1.0	CHEMBL2370509,TN,INACT,0.7099999785423279	CHEMBL3287326,TP,ACT,0.9800000190734863	CHEMBL59,TN,INACT,0.0	CHEMBL94369,TP,ACT,1.0	CHEMBL99331,TN,INACT,0.009999999776482582	CHEMBL451335,TN,INACT,0.0	CHEMBL432027,TP,ACT,0.9900000095367432	CHEMBL2093084,TN,INACT,0.0	CHEMBL1983100,TN,INACT,0.0	CHEMBL96531,TP,ACT,0.8899999856948853	CHEMBL2323785,TP,ACT,1.0	CHEMBL190080,TP,ACT,0.949999988079071	CHEMBL3287323,TP,ACT,0.9900000095367432	CHEMBL2369975,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.03999999910593033	CHEMBL553155,TN,INACT,0.0	CHEMBL168632,TN,INACT,0.009999999776482582	CHEMBL190732,TP,ACT,0.9399999976158142	CHEMBL3287329,TP,ACT,0.9599999785423279	CHEMBL2042401,TN,INACT,0.0	CHEMBL330674,TN,INACT,0.019999999552965164	CHEMBL295651,TN,INACT,0.0	CHEMBL320763,TN,INACT,0.0	CHEMBL227429,TN,INACT,0.0	CHEMBL186970,TP,ACT,0.9599999785423279	CHEMBL3798421,TP,ACT,0.9599999785423279	CHEMBL298612,TN,INACT,0.009999999776482582	CHEMBL40986,TN,INACT,0.0	CHEMBL154153,TP,ACT,0.9800000190734863	CHEMBL2323792,TP,ACT,0.9900000095367432	CHEMBL441988,TP,ACT,0.7799999713897705	CHEMBL358833,TP,ACT,0.9800000190734863	CHEMBL460470,TN,INACT,0.0	CHEMBL2369977,TP,ACT,1.0	CHEMBL373344,TP,ACT,0.9700000286102295	CHEMBL2371832,TP,ACT,0.8999999761581421	CHEMBL3798768,TP,ACT,0.9399999976158142	CHEMBL188459,TP,ACT,0.9700000286102295	CHEMBL78830,TN,INACT,0.0	CHEMBL2111789,TN,INACT,0.6399999856948853	CHEMBL1916635,TN,INACT,0.5099999904632568	CHEMBL327479,TP,ACT,1.0	CHEMBL191120,TP,ACT,0.9800000190734863	CHEMBL297215,TN,INACT,0.05000000074505806	CHEMBL228144,TN,INACT,0.0	CHEMBL3799955,FN,ACT,0.12999999523162842	CHEMBL317968,TP,ACT,1.0	CHEMBL2112592,TN,INACT,0.6899999976158142	

