CNNModel CHEMBL1983 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	1106
Number of inactive compounds :	1106
---------------------------------
Run id: CNNModel_CHEMBL1983_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1983_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 1386
Validation samples: 434
--
Training Step: 1  | time: 1.123s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1386
[A[ATraining Step: 2  | total loss: [1m[32m0.62402[0m[0m | time: 2.167s
[2K
| Adam | epoch: 001 | loss: 0.62402 - acc: 0.3937 -- iter: 0064/1386
[A[ATraining Step: 3  | total loss: [1m[32m0.68194[0m[0m | time: 3.186s
[2K
| Adam | epoch: 001 | loss: 0.68194 - acc: 0.3784 -- iter: 0096/1386
[A[ATraining Step: 4  | total loss: [1m[32m0.69032[0m[0m | time: 4.084s
[2K
| Adam | epoch: 001 | loss: 0.69032 - acc: 0.4696 -- iter: 0128/1386
[A[ATraining Step: 5  | total loss: [1m[32m0.69196[0m[0m | time: 4.983s
[2K
| Adam | epoch: 001 | loss: 0.69196 - acc: 0.5123 -- iter: 0160/1386
[A[ATraining Step: 6  | total loss: [1m[32m0.69154[0m[0m | time: 5.900s
[2K
| Adam | epoch: 001 | loss: 0.69154 - acc: 0.5446 -- iter: 0192/1386
[A[ATraining Step: 7  | total loss: [1m[32m0.69317[0m[0m | time: 6.863s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.5178 -- iter: 0224/1386
[A[ATraining Step: 8  | total loss: [1m[32m0.69214[0m[0m | time: 7.747s
[2K
| Adam | epoch: 001 | loss: 0.69214 - acc: 0.5254 -- iter: 0256/1386
[A[ATraining Step: 9  | total loss: [1m[32m0.69064[0m[0m | time: 8.796s
[2K
| Adam | epoch: 001 | loss: 0.69064 - acc: 0.5450 -- iter: 0288/1386
[A[ATraining Step: 10  | total loss: [1m[32m0.69313[0m[0m | time: 9.785s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.5225 -- iter: 0320/1386
[A[ATraining Step: 11  | total loss: [1m[32m0.69587[0m[0m | time: 10.645s
[2K
| Adam | epoch: 001 | loss: 0.69587 - acc: 0.4970 -- iter: 0352/1386
[A[ATraining Step: 12  | total loss: [1m[32m0.68954[0m[0m | time: 11.641s
[2K
| Adam | epoch: 001 | loss: 0.68954 - acc: 0.5546 -- iter: 0384/1386
[A[ATraining Step: 13  | total loss: [1m[32m0.69666[0m[0m | time: 12.690s
[2K
| Adam | epoch: 001 | loss: 0.69666 - acc: 0.4910 -- iter: 0416/1386
[A[ATraining Step: 14  | total loss: [1m[32m0.69188[0m[0m | time: 13.693s
[2K
| Adam | epoch: 001 | loss: 0.69188 - acc: 0.5331 -- iter: 0448/1386
[A[ATraining Step: 15  | total loss: [1m[32m0.68380[0m[0m | time: 14.466s
[2K
| Adam | epoch: 001 | loss: 0.68380 - acc: 0.6179 -- iter: 0480/1386
[A[ATraining Step: 16  | total loss: [1m[32m0.69056[0m[0m | time: 15.358s
[2K
| Adam | epoch: 001 | loss: 0.69056 - acc: 0.5503 -- iter: 0512/1386
[A[ATraining Step: 17  | total loss: [1m[32m0.69365[0m[0m | time: 16.231s
[2K
| Adam | epoch: 001 | loss: 0.69365 - acc: 0.5209 -- iter: 0544/1386
[A[ATraining Step: 18  | total loss: [1m[32m0.70200[0m[0m | time: 17.127s
[2K
| Adam | epoch: 001 | loss: 0.70200 - acc: 0.4488 -- iter: 0576/1386
[A[ATraining Step: 19  | total loss: [1m[32m0.69717[0m[0m | time: 18.068s
[2K
| Adam | epoch: 001 | loss: 0.69717 - acc: 0.4867 -- iter: 0608/1386
[A[ATraining Step: 20  | total loss: [1m[32m0.69457[0m[0m | time: 19.099s
[2K
| Adam | epoch: 001 | loss: 0.69457 - acc: 0.5111 -- iter: 0640/1386
[A[ATraining Step: 21  | total loss: [1m[32m0.69381[0m[0m | time: 20.036s
[2K
| Adam | epoch: 001 | loss: 0.69381 - acc: 0.5173 -- iter: 0672/1386
[A[ATraining Step: 22  | total loss: [1m[32m0.69199[0m[0m | time: 20.935s
[2K
| Adam | epoch: 001 | loss: 0.69199 - acc: 0.5403 -- iter: 0704/1386
[A[ATraining Step: 23  | total loss: [1m[32m0.69344[0m[0m | time: 21.961s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.5104 -- iter: 0736/1386
[A[ATraining Step: 24  | total loss: [1m[32m0.69432[0m[0m | time: 23.006s
[2K
| Adam | epoch: 001 | loss: 0.69432 - acc: 0.4899 -- iter: 0768/1386
[A[ATraining Step: 25  | total loss: [1m[32m0.69358[0m[0m | time: 23.871s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.5012 -- iter: 0800/1386
[A[ATraining Step: 26  | total loss: [1m[32m0.69174[0m[0m | time: 24.716s
[2K
| Adam | epoch: 001 | loss: 0.69174 - acc: 0.5422 -- iter: 0832/1386
[A[ATraining Step: 27  | total loss: [1m[32m0.69280[0m[0m | time: 25.613s
[2K
| Adam | epoch: 001 | loss: 0.69280 - acc: 0.5153 -- iter: 0864/1386
[A[ATraining Step: 28  | total loss: [1m[32m0.69304[0m[0m | time: 26.506s
[2K
| Adam | epoch: 001 | loss: 0.69304 - acc: 0.5115 -- iter: 0896/1386
[A[ATraining Step: 29  | total loss: [1m[32m0.69356[0m[0m | time: 27.420s
[2K
| Adam | epoch: 001 | loss: 0.69356 - acc: 0.4935 -- iter: 0928/1386
[A[ATraining Step: 30  | total loss: [1m[32m0.69173[0m[0m | time: 28.389s
[2K
| Adam | epoch: 001 | loss: 0.69173 - acc: 0.5394 -- iter: 0960/1386
[A[ATraining Step: 31  | total loss: [1m[32m0.69175[0m[0m | time: 29.375s
[2K
| Adam | epoch: 001 | loss: 0.69175 - acc: 0.5375 -- iter: 0992/1386
[A[ATraining Step: 32  | total loss: [1m[32m0.69241[0m[0m | time: 30.219s
[2K
| Adam | epoch: 001 | loss: 0.69241 - acc: 0.5221 -- iter: 1024/1386
[A[ATraining Step: 33  | total loss: [1m[32m0.69197[0m[0m | time: 31.191s
[2K
| Adam | epoch: 001 | loss: 0.69197 - acc: 0.5309 -- iter: 1056/1386
[A[ATraining Step: 34  | total loss: [1m[32m0.69135[0m[0m | time: 32.228s
[2K
| Adam | epoch: 001 | loss: 0.69135 - acc: 0.5444 -- iter: 1088/1386
[A[ATraining Step: 35  | total loss: [1m[32m0.69167[0m[0m | time: 33.202s
[2K
| Adam | epoch: 001 | loss: 0.69167 - acc: 0.5351 -- iter: 1120/1386
[A[ATraining Step: 36  | total loss: [1m[32m0.69204[0m[0m | time: 33.950s
[2K
| Adam | epoch: 001 | loss: 0.69204 - acc: 0.5279 -- iter: 1152/1386
[A[ATraining Step: 37  | total loss: [1m[32m0.69127[0m[0m | time: 34.830s
[2K
| Adam | epoch: 001 | loss: 0.69127 - acc: 0.5411 -- iter: 1184/1386
[A[ATraining Step: 38  | total loss: [1m[32m0.69184[0m[0m | time: 35.755s
[2K
| Adam | epoch: 001 | loss: 0.69184 - acc: 0.5331 -- iter: 1216/1386
[A[ATraining Step: 39  | total loss: [1m[32m0.69360[0m[0m | time: 36.678s
[2K
| Adam | epoch: 001 | loss: 0.69360 - acc: 0.5028 -- iter: 1248/1386
[A[ATraining Step: 40  | total loss: [1m[32m0.69319[0m[0m | time: 37.572s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5081 -- iter: 1280/1386
[A[ATraining Step: 41  | total loss: [1m[32m0.69219[0m[0m | time: 38.545s
[2K
| Adam | epoch: 001 | loss: 0.69219 - acc: 0.5239 -- iter: 1312/1386
[A[ATraining Step: 42  | total loss: [1m[32m0.69103[0m[0m | time: 39.517s
[2K
| Adam | epoch: 001 | loss: 0.69103 - acc: 0.5421 -- iter: 1344/1386
[A[ATraining Step: 43  | total loss: [1m[32m0.69253[0m[0m | time: 40.355s
[2K
| Adam | epoch: 001 | loss: 0.69253 - acc: 0.5181 -- iter: 1376/1386
[A[ATraining Step: 44  | total loss: [1m[32m0.69188[0m[0m | time: 42.989s
[2K
| Adam | epoch: 001 | loss: 0.69188 - acc: 0.5258 | val_loss: 0.69461 - val_acc: 0.4862 -- iter: 1386/1386
--
Training Step: 45  | total loss: [1m[32m0.68973[0m[0m | time: 0.279s
[2K
| Adam | epoch: 002 | loss: 0.68973 - acc: 0.5554 -- iter: 0032/1386
[A[ATraining Step: 46  | total loss: [1m[32m0.68746[0m[0m | time: 1.081s
[2K
| Adam | epoch: 002 | loss: 0.68746 - acc: 0.5795 -- iter: 0064/1386
[A[ATraining Step: 47  | total loss: [1m[32m0.68796[0m[0m | time: 1.951s
[2K
| Adam | epoch: 002 | loss: 0.68796 - acc: 0.5716 -- iter: 0096/1386
[A[ATraining Step: 48  | total loss: [1m[32m0.68654[0m[0m | time: 2.831s
[2K
| Adam | epoch: 002 | loss: 0.68654 - acc: 0.5802 -- iter: 0128/1386
[A[ATraining Step: 49  | total loss: [1m[32m0.68736[0m[0m | time: 3.687s
[2K
| Adam | epoch: 002 | loss: 0.68736 - acc: 0.5724 -- iter: 0160/1386
[A[ATraining Step: 50  | total loss: [1m[32m0.68807[0m[0m | time: 4.613s
[2K
| Adam | epoch: 002 | loss: 0.68807 - acc: 0.5660 -- iter: 0192/1386
[A[ATraining Step: 51  | total loss: [1m[32m0.68757[0m[0m | time: 5.580s
[2K
| Adam | epoch: 002 | loss: 0.68757 - acc: 0.5655 -- iter: 0224/1386
[A[ATraining Step: 52  | total loss: [1m[32m0.69545[0m[0m | time: 6.502s
[2K
| Adam | epoch: 002 | loss: 0.69545 - acc: 0.5369 -- iter: 0256/1386
[A[ATraining Step: 53  | total loss: [1m[32m0.69599[0m[0m | time: 7.367s
[2K
| Adam | epoch: 002 | loss: 0.69599 - acc: 0.5315 -- iter: 0288/1386
[A[ATraining Step: 54  | total loss: [1m[32m0.69871[0m[0m | time: 8.393s
[2K
| Adam | epoch: 002 | loss: 0.69871 - acc: 0.5133 -- iter: 0320/1386
[A[ATraining Step: 55  | total loss: [1m[32m0.69639[0m[0m | time: 9.421s
[2K
| Adam | epoch: 002 | loss: 0.69639 - acc: 0.5248 -- iter: 0352/1386
[A[ATraining Step: 56  | total loss: [1m[32m0.69789[0m[0m | time: 10.285s
[2K
| Adam | epoch: 002 | loss: 0.69789 - acc: 0.5037 -- iter: 0384/1386
[A[ATraining Step: 57  | total loss: [1m[32m0.69726[0m[0m | time: 11.093s
[2K
| Adam | epoch: 002 | loss: 0.69726 - acc: 0.5032 -- iter: 0416/1386
[A[ATraining Step: 58  | total loss: [1m[32m0.69698[0m[0m | time: 12.071s
[2K
| Adam | epoch: 002 | loss: 0.69698 - acc: 0.4985 -- iter: 0448/1386
[A[ATraining Step: 59  | total loss: [1m[32m0.69703[0m[0m | time: 13.003s
[2K
| Adam | epoch: 002 | loss: 0.69703 - acc: 0.4861 -- iter: 0480/1386
[A[ATraining Step: 60  | total loss: [1m[32m0.69635[0m[0m | time: 13.884s
[2K
| Adam | epoch: 002 | loss: 0.69635 - acc: 0.4921 -- iter: 0512/1386
[A[ATraining Step: 61  | total loss: [1m[32m0.69566[0m[0m | time: 14.918s
[2K
| Adam | epoch: 002 | loss: 0.69566 - acc: 0.5013 -- iter: 0544/1386
[A[ATraining Step: 62  | total loss: [1m[32m0.69498[0m[0m | time: 15.842s
[2K
| Adam | epoch: 002 | loss: 0.69498 - acc: 0.5132 -- iter: 0576/1386
[A[ATraining Step: 63  | total loss: [1m[32m0.69485[0m[0m | time: 16.692s
[2K
| Adam | epoch: 002 | loss: 0.69485 - acc: 0.5075 -- iter: 0608/1386
[A[ATraining Step: 64  | total loss: [1m[32m0.69432[0m[0m | time: 17.783s
[2K
| Adam | epoch: 002 | loss: 0.69432 - acc: 0.5183 -- iter: 0640/1386
[A[ATraining Step: 65  | total loss: [1m[32m0.69476[0m[0m | time: 18.847s
[2K
| Adam | epoch: 002 | loss: 0.69476 - acc: 0.4968 -- iter: 0672/1386
[A[ATraining Step: 66  | total loss: [1m[32m0.69374[0m[0m | time: 19.739s
[2K
| Adam | epoch: 002 | loss: 0.69374 - acc: 0.5276 -- iter: 0704/1386
[A[ATraining Step: 67  | total loss: [1m[32m0.69356[0m[0m | time: 20.590s
[2K
| Adam | epoch: 002 | loss: 0.69356 - acc: 0.5280 -- iter: 0736/1386
[A[ATraining Step: 68  | total loss: [1m[32m0.69316[0m[0m | time: 21.480s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5358 -- iter: 0768/1386
[A[ATraining Step: 69  | total loss: [1m[32m0.69316[0m[0m | time: 22.428s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5316 -- iter: 0800/1386
[A[ATraining Step: 70  | total loss: [1m[32m0.69290[0m[0m | time: 23.298s
[2K
| Adam | epoch: 002 | loss: 0.69290 - acc: 0.5352 -- iter: 0832/1386
[A[ATraining Step: 71  | total loss: [1m[32m0.69255[0m[0m | time: 24.307s
[2K
| Adam | epoch: 002 | loss: 0.69255 - acc: 0.5419 -- iter: 0864/1386
[A[ATraining Step: 72  | total loss: [1m[32m0.69289[0m[0m | time: 25.297s
[2K
| Adam | epoch: 002 | loss: 0.69289 - acc: 0.5301 -- iter: 0896/1386
[A[ATraining Step: 73  | total loss: [1m[32m0.69318[0m[0m | time: 26.153s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5198 -- iter: 0928/1386
[A[ATraining Step: 74  | total loss: [1m[32m0.69288[0m[0m | time: 27.146s
[2K
| Adam | epoch: 002 | loss: 0.69288 - acc: 0.5245 -- iter: 0960/1386
[A[ATraining Step: 75  | total loss: [1m[32m0.69289[0m[0m | time: 28.191s
[2K
| Adam | epoch: 002 | loss: 0.69289 - acc: 0.5219 -- iter: 0992/1386
[A[ATraining Step: 76  | total loss: [1m[32m0.69303[0m[0m | time: 29.173s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5162 -- iter: 1024/1386
[A[ATraining Step: 77  | total loss: [1m[32m0.69328[0m[0m | time: 29.921s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.5078 -- iter: 1056/1386
[A[ATraining Step: 78  | total loss: [1m[32m0.69299[0m[0m | time: 30.799s
[2K
| Adam | epoch: 002 | loss: 0.69299 - acc: 0.5136 -- iter: 1088/1386
[A[ATraining Step: 79  | total loss: [1m[32m0.69299[0m[0m | time: 31.684s
[2K
| Adam | epoch: 002 | loss: 0.69299 - acc: 0.5122 -- iter: 1120/1386
[A[ATraining Step: 80  | total loss: [1m[32m0.69265[0m[0m | time: 32.592s
[2K
| Adam | epoch: 002 | loss: 0.69265 - acc: 0.5205 -- iter: 1152/1386
[A[ATraining Step: 81  | total loss: [1m[32m0.69219[0m[0m | time: 33.550s
[2K
| Adam | epoch: 002 | loss: 0.69219 - acc: 0.5311 -- iter: 1184/1386
[A[ATraining Step: 82  | total loss: [1m[32m0.69259[0m[0m | time: 34.510s
[2K
| Adam | epoch: 002 | loss: 0.69259 - acc: 0.5186 -- iter: 1216/1386
[A[ATraining Step: 83  | total loss: [1m[32m0.69329[0m[0m | time: 35.529s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.5011 -- iter: 1248/1386
[A[ATraining Step: 84  | total loss: [1m[32m0.69281[0m[0m | time: 36.409s
[2K
| Adam | epoch: 002 | loss: 0.69281 - acc: 0.5104 -- iter: 1280/1386
[A[ATraining Step: 85  | total loss: [1m[32m0.69279[0m[0m | time: 37.510s
[2K
| Adam | epoch: 002 | loss: 0.69279 - acc: 0.5093 -- iter: 1312/1386
[A[ATraining Step: 86  | total loss: [1m[32m0.69251[0m[0m | time: 38.573s
[2K
| Adam | epoch: 002 | loss: 0.69251 - acc: 0.5146 -- iter: 1344/1386
[A[ATraining Step: 87  | total loss: [1m[32m0.69253[0m[0m | time: 39.458s
[2K
| Adam | epoch: 002 | loss: 0.69253 - acc: 0.5069 -- iter: 1376/1386
[A[ATraining Step: 88  | total loss: [1m[32m0.69264[0m[0m | time: 42.165s
[2K
| Adam | epoch: 002 | loss: 0.69264 - acc: 0.5031 | val_loss: 0.69071 - val_acc: 0.4954 -- iter: 1386/1386
--
Training Step: 89  | total loss: [1m[32m0.69240[0m[0m | time: 0.323s
[2K
| Adam | epoch: 003 | loss: 0.69240 - acc: 0.5091 -- iter: 0032/1386
[A[ATraining Step: 90  | total loss: [1m[32m0.69135[0m[0m | time: 0.648s
[2K
| Adam | epoch: 003 | loss: 0.69135 - acc: 0.5481 -- iter: 0064/1386
[A[ATraining Step: 91  | total loss: [1m[32m0.68931[0m[0m | time: 1.637s
[2K
| Adam | epoch: 003 | loss: 0.68931 - acc: 0.5833 -- iter: 0096/1386
[A[ATraining Step: 92  | total loss: [1m[32m0.68956[0m[0m | time: 2.611s
[2K
| Adam | epoch: 003 | loss: 0.68956 - acc: 0.5750 -- iter: 0128/1386
[A[ATraining Step: 93  | total loss: [1m[32m0.68896[0m[0m | time: 3.490s
[2K
| Adam | epoch: 003 | loss: 0.68896 - acc: 0.5769 -- iter: 0160/1386
[A[ATraining Step: 94  | total loss: [1m[32m0.68856[0m[0m | time: 4.394s
[2K
| Adam | epoch: 003 | loss: 0.68856 - acc: 0.5754 -- iter: 0192/1386
[A[ATraining Step: 95  | total loss: [1m[32m0.68954[0m[0m | time: 5.472s
[2K
| Adam | epoch: 003 | loss: 0.68954 - acc: 0.5648 -- iter: 0224/1386
[A[ATraining Step: 96  | total loss: [1m[32m0.68812[0m[0m | time: 6.471s
[2K
| Adam | epoch: 003 | loss: 0.68812 - acc: 0.5677 -- iter: 0256/1386
[A[ATraining Step: 97  | total loss: [1m[32m0.68788[0m[0m | time: 7.252s
[2K
| Adam | epoch: 003 | loss: 0.68788 - acc: 0.5640 -- iter: 0288/1386
[A[ATraining Step: 98  | total loss: [1m[32m0.68768[0m[0m | time: 8.124s
[2K
| Adam | epoch: 003 | loss: 0.68768 - acc: 0.5607 -- iter: 0320/1386
[A[ATraining Step: 99  | total loss: [1m[32m0.68960[0m[0m | time: 9.044s
[2K
| Adam | epoch: 003 | loss: 0.68960 - acc: 0.5515 -- iter: 0352/1386
[A[ATraining Step: 100  | total loss: [1m[32m0.69166[0m[0m | time: 9.934s
[2K
| Adam | epoch: 003 | loss: 0.69166 - acc: 0.5401 -- iter: 0384/1386
[A[ATraining Step: 101  | total loss: [1m[32m0.69129[0m[0m | time: 10.800s
[2K
| Adam | epoch: 003 | loss: 0.69129 - acc: 0.5393 -- iter: 0416/1386
[A[ATraining Step: 102  | total loss: [1m[32m0.69192[0m[0m | time: 11.816s
[2K
| Adam | epoch: 003 | loss: 0.69192 - acc: 0.5291 -- iter: 0448/1386
[A[ATraining Step: 103  | total loss: [1m[32m0.69194[0m[0m | time: 12.756s
[2K
| Adam | epoch: 003 | loss: 0.69194 - acc: 0.5199 -- iter: 0480/1386
[A[ATraining Step: 104  | total loss: [1m[32m0.69265[0m[0m | time: 13.629s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5054 -- iter: 0512/1386
[A[ATraining Step: 105  | total loss: [1m[32m0.69307[0m[0m | time: 14.596s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.4924 -- iter: 0544/1386
[A[ATraining Step: 106  | total loss: [1m[32m0.69238[0m[0m | time: 15.586s
[2K
| Adam | epoch: 003 | loss: 0.69238 - acc: 0.4994 -- iter: 0576/1386
[A[ATraining Step: 107  | total loss: [1m[32m0.69187[0m[0m | time: 16.586s
[2K
| Adam | epoch: 003 | loss: 0.69187 - acc: 0.5026 -- iter: 0608/1386
[A[ATraining Step: 108  | total loss: [1m[32m0.69113[0m[0m | time: 17.331s
[2K
| Adam | epoch: 003 | loss: 0.69113 - acc: 0.5054 -- iter: 0640/1386
[A[ATraining Step: 109  | total loss: [1m[32m0.68999[0m[0m | time: 18.208s
[2K
| Adam | epoch: 003 | loss: 0.68999 - acc: 0.5174 -- iter: 0672/1386
[A[ATraining Step: 110  | total loss: [1m[32m0.68964[0m[0m | time: 19.063s
[2K
| Adam | epoch: 003 | loss: 0.68964 - acc: 0.5157 -- iter: 0704/1386
[A[ATraining Step: 111  | total loss: [1m[32m0.68945[0m[0m | time: 19.919s
[2K
| Adam | epoch: 003 | loss: 0.68945 - acc: 0.5110 -- iter: 0736/1386
[A[ATraining Step: 112  | total loss: [1m[32m0.69061[0m[0m | time: 20.800s
[2K
| Adam | epoch: 003 | loss: 0.69061 - acc: 0.5068 -- iter: 0768/1386
[A[ATraining Step: 113  | total loss: [1m[32m0.68494[0m[0m | time: 21.716s
[2K
| Adam | epoch: 003 | loss: 0.68494 - acc: 0.5280 -- iter: 0800/1386
[A[ATraining Step: 114  | total loss: [1m[32m0.68135[0m[0m | time: 22.705s
[2K
| Adam | epoch: 003 | loss: 0.68135 - acc: 0.5377 -- iter: 0832/1386
[A[ATraining Step: 115  | total loss: [1m[32m0.68253[0m[0m | time: 23.567s
[2K
| Adam | epoch: 003 | loss: 0.68253 - acc: 0.5339 -- iter: 0864/1386
[A[ATraining Step: 116  | total loss: [1m[32m0.68364[0m[0m | time: 24.545s
[2K
| Adam | epoch: 003 | loss: 0.68364 - acc: 0.5336 -- iter: 0896/1386
[A[ATraining Step: 117  | total loss: [1m[32m0.67900[0m[0m | time: 25.545s
[2K
| Adam | epoch: 003 | loss: 0.67900 - acc: 0.5428 -- iter: 0928/1386
[A[ATraining Step: 118  | total loss: [1m[32m0.68119[0m[0m | time: 26.624s
[2K
| Adam | epoch: 003 | loss: 0.68119 - acc: 0.5416 -- iter: 0960/1386
[A[ATraining Step: 119  | total loss: [1m[32m0.67695[0m[0m | time: 27.361s
[2K
| Adam | epoch: 003 | loss: 0.67695 - acc: 0.5531 -- iter: 0992/1386
[A[ATraining Step: 120  | total loss: [1m[32m0.67290[0m[0m | time: 28.207s
[2K
| Adam | epoch: 003 | loss: 0.67290 - acc: 0.5696 -- iter: 1024/1386
[A[ATraining Step: 121  | total loss: [1m[32m0.66593[0m[0m | time: 29.118s
[2K
| Adam | epoch: 003 | loss: 0.66593 - acc: 0.5939 -- iter: 1056/1386
[A[ATraining Step: 122  | total loss: [1m[32m0.65487[0m[0m | time: 29.974s
[2K
| Adam | epoch: 003 | loss: 0.65487 - acc: 0.6158 -- iter: 1088/1386
[A[ATraining Step: 123  | total loss: [1m[32m0.65782[0m[0m | time: 30.915s
[2K
| Adam | epoch: 003 | loss: 0.65782 - acc: 0.6167 -- iter: 1120/1386
[A[ATraining Step: 124  | total loss: [1m[32m0.67146[0m[0m | time: 31.846s
[2K
| Adam | epoch: 003 | loss: 0.67146 - acc: 0.6050 -- iter: 1152/1386
[A[ATraining Step: 125  | total loss: [1m[32m0.66892[0m[0m | time: 32.755s
[2K
| Adam | epoch: 003 | loss: 0.66892 - acc: 0.6070 -- iter: 1184/1386
[A[ATraining Step: 126  | total loss: [1m[32m0.65726[0m[0m | time: 33.640s
[2K
| Adam | epoch: 003 | loss: 0.65726 - acc: 0.6151 -- iter: 1216/1386
[A[ATraining Step: 127  | total loss: [1m[32m0.65851[0m[0m | time: 34.668s
[2K
| Adam | epoch: 003 | loss: 0.65851 - acc: 0.6161 -- iter: 1248/1386
[A[ATraining Step: 128  | total loss: [1m[32m0.66494[0m[0m | time: 35.707s
[2K
| Adam | epoch: 003 | loss: 0.66494 - acc: 0.6076 -- iter: 1280/1386
[A[ATraining Step: 129  | total loss: [1m[32m0.65671[0m[0m | time: 36.697s
[2K
| Adam | epoch: 003 | loss: 0.65671 - acc: 0.6187 -- iter: 1312/1386
[A[ATraining Step: 130  | total loss: [1m[32m0.65624[0m[0m | time: 37.487s
[2K
| Adam | epoch: 003 | loss: 0.65624 - acc: 0.6131 -- iter: 1344/1386
[A[ATraining Step: 131  | total loss: [1m[32m0.66069[0m[0m | time: 38.344s
[2K
| Adam | epoch: 003 | loss: 0.66069 - acc: 0.6080 -- iter: 1376/1386
[A[ATraining Step: 132  | total loss: [1m[32m0.65245[0m[0m | time: 41.151s
[2K
| Adam | epoch: 003 | loss: 0.65245 - acc: 0.6160 | val_loss: 0.61242 - val_acc: 0.6820 -- iter: 1386/1386
--
Training Step: 133  | total loss: [1m[32m0.64671[0m[0m | time: 1.033s
[2K
| Adam | epoch: 004 | loss: 0.64671 - acc: 0.6231 -- iter: 0032/1386
[A[ATraining Step: 134  | total loss: [1m[32m0.64311[0m[0m | time: 1.350s
[2K
| Adam | epoch: 004 | loss: 0.64311 - acc: 0.6296 -- iter: 0064/1386
[A[ATraining Step: 135  | total loss: [1m[32m0.63557[0m[0m | time: 1.677s
[2K
| Adam | epoch: 004 | loss: 0.63557 - acc: 0.6566 -- iter: 0096/1386
[A[ATraining Step: 136  | total loss: [1m[32m0.62761[0m[0m | time: 2.516s
[2K
| Adam | epoch: 004 | loss: 0.62761 - acc: 0.6709 -- iter: 0128/1386
[A[ATraining Step: 137  | total loss: [1m[32m0.63148[0m[0m | time: 3.574s
[2K
| Adam | epoch: 004 | loss: 0.63148 - acc: 0.6601 -- iter: 0160/1386
[A[ATraining Step: 138  | total loss: [1m[32m0.63007[0m[0m | time: 4.593s
[2K
| Adam | epoch: 004 | loss: 0.63007 - acc: 0.6628 -- iter: 0192/1386
[A[ATraining Step: 139  | total loss: [1m[32m0.62487[0m[0m | time: 5.483s
[2K
| Adam | epoch: 004 | loss: 0.62487 - acc: 0.6622 -- iter: 0224/1386
[A[ATraining Step: 140  | total loss: [1m[32m0.62308[0m[0m | time: 6.291s
[2K
| Adam | epoch: 004 | loss: 0.62308 - acc: 0.6616 -- iter: 0256/1386
[A[ATraining Step: 141  | total loss: [1m[32m0.61609[0m[0m | time: 7.211s
[2K
| Adam | epoch: 004 | loss: 0.61609 - acc: 0.6642 -- iter: 0288/1386
[A[ATraining Step: 142  | total loss: [1m[32m0.61248[0m[0m | time: 8.093s
[2K
| Adam | epoch: 004 | loss: 0.61248 - acc: 0.6603 -- iter: 0320/1386
[A[ATraining Step: 143  | total loss: [1m[32m0.60664[0m[0m | time: 8.951s
[2K
| Adam | epoch: 004 | loss: 0.60664 - acc: 0.6630 -- iter: 0352/1386
[A[ATraining Step: 144  | total loss: [1m[32m0.60569[0m[0m | time: 9.896s
[2K
| Adam | epoch: 004 | loss: 0.60569 - acc: 0.6717 -- iter: 0384/1386
[A[ATraining Step: 145  | total loss: [1m[32m0.60168[0m[0m | time: 10.908s
[2K
| Adam | epoch: 004 | loss: 0.60168 - acc: 0.6764 -- iter: 0416/1386
[A[ATraining Step: 146  | total loss: [1m[32m0.60373[0m[0m | time: 11.776s
[2K
| Adam | epoch: 004 | loss: 0.60373 - acc: 0.6713 -- iter: 0448/1386
[A[ATraining Step: 147  | total loss: [1m[32m0.59982[0m[0m | time: 12.697s
[2K
| Adam | epoch: 004 | loss: 0.59982 - acc: 0.6760 -- iter: 0480/1386
[A[ATraining Step: 148  | total loss: [1m[32m0.59451[0m[0m | time: 13.692s
[2K
| Adam | epoch: 004 | loss: 0.59451 - acc: 0.6740 -- iter: 0512/1386
[A[ATraining Step: 149  | total loss: [1m[32m0.59384[0m[0m | time: 14.738s
[2K
| Adam | epoch: 004 | loss: 0.59384 - acc: 0.6723 -- iter: 0544/1386
[A[ATraining Step: 150  | total loss: [1m[32m0.59798[0m[0m | time: 15.611s
[2K
| Adam | epoch: 004 | loss: 0.59798 - acc: 0.6738 -- iter: 0576/1386
[A[ATraining Step: 151  | total loss: [1m[32m0.59063[0m[0m | time: 16.470s
[2K
| Adam | epoch: 004 | loss: 0.59063 - acc: 0.6783 -- iter: 0608/1386
[A[ATraining Step: 152  | total loss: [1m[32m0.58739[0m[0m | time: 17.336s
[2K
| Adam | epoch: 004 | loss: 0.58739 - acc: 0.6823 -- iter: 0640/1386
[A[ATraining Step: 153  | total loss: [1m[32m0.59621[0m[0m | time: 18.255s
[2K
| Adam | epoch: 004 | loss: 0.59621 - acc: 0.6703 -- iter: 0672/1386
[A[ATraining Step: 154  | total loss: [1m[32m0.58052[0m[0m | time: 19.187s
[2K
| Adam | epoch: 004 | loss: 0.58052 - acc: 0.6908 -- iter: 0704/1386
[A[ATraining Step: 155  | total loss: [1m[32m0.58920[0m[0m | time: 20.200s
[2K
| Adam | epoch: 004 | loss: 0.58920 - acc: 0.6780 -- iter: 0736/1386
[A[ATraining Step: 156  | total loss: [1m[32m0.58697[0m[0m | time: 21.186s
[2K
| Adam | epoch: 004 | loss: 0.58697 - acc: 0.6852 -- iter: 0768/1386
[A[ATraining Step: 157  | total loss: [1m[32m0.60343[0m[0m | time: 22.024s
[2K
| Adam | epoch: 004 | loss: 0.60343 - acc: 0.6635 -- iter: 0800/1386
[A[ATraining Step: 158  | total loss: [1m[32m0.60903[0m[0m | time: 23.089s
[2K
| Adam | epoch: 004 | loss: 0.60903 - acc: 0.6597 -- iter: 0832/1386
[A[ATraining Step: 159  | total loss: [1m[32m0.59673[0m[0m | time: 24.143s
[2K
| Adam | epoch: 004 | loss: 0.59673 - acc: 0.6750 -- iter: 0864/1386
[A[ATraining Step: 160  | total loss: [1m[32m0.59274[0m[0m | time: 25.020s
[2K
| Adam | epoch: 004 | loss: 0.59274 - acc: 0.6762 -- iter: 0896/1386
[A[ATraining Step: 161  | total loss: [1m[32m0.58979[0m[0m | time: 25.864s
[2K
| Adam | epoch: 004 | loss: 0.58979 - acc: 0.6773 -- iter: 0928/1386
[A[ATraining Step: 162  | total loss: [1m[32m0.59289[0m[0m | time: 26.744s
[2K
| Adam | epoch: 004 | loss: 0.59289 - acc: 0.6752 -- iter: 0960/1386
[A[ATraining Step: 163  | total loss: [1m[32m0.58471[0m[0m | time: 27.642s
[2K
| Adam | epoch: 004 | loss: 0.58471 - acc: 0.6921 -- iter: 0992/1386
[A[ATraining Step: 164  | total loss: [1m[32m0.57397[0m[0m | time: 28.515s
[2K
| Adam | epoch: 004 | loss: 0.57397 - acc: 0.7041 -- iter: 1024/1386
[A[ATraining Step: 165  | total loss: [1m[32m0.56261[0m[0m | time: 29.477s
[2K
| Adam | epoch: 004 | loss: 0.56261 - acc: 0.7212 -- iter: 1056/1386
[A[ATraining Step: 166  | total loss: [1m[32m0.56568[0m[0m | time: 30.512s
[2K
| Adam | epoch: 004 | loss: 0.56568 - acc: 0.7178 -- iter: 1088/1386
[A[ATraining Step: 167  | total loss: [1m[32m0.56598[0m[0m | time: 31.402s
[2K
| Adam | epoch: 004 | loss: 0.56598 - acc: 0.7117 -- iter: 1120/1386
[A[ATraining Step: 168  | total loss: [1m[32m0.55969[0m[0m | time: 32.421s
[2K
| Adam | epoch: 004 | loss: 0.55969 - acc: 0.7155 -- iter: 1152/1386
[A[ATraining Step: 169  | total loss: [1m[32m0.56424[0m[0m | time: 33.434s
[2K
| Adam | epoch: 004 | loss: 0.56424 - acc: 0.7033 -- iter: 1184/1386
[A[ATraining Step: 170  | total loss: [1m[32m0.56256[0m[0m | time: 34.416s
[2K
| Adam | epoch: 004 | loss: 0.56256 - acc: 0.7049 -- iter: 1216/1386
[A[ATraining Step: 171  | total loss: [1m[32m0.56328[0m[0m | time: 35.177s
[2K
| Adam | epoch: 004 | loss: 0.56328 - acc: 0.7063 -- iter: 1248/1386
[A[ATraining Step: 172  | total loss: [1m[32m0.55013[0m[0m | time: 36.017s
[2K
| Adam | epoch: 004 | loss: 0.55013 - acc: 0.7200 -- iter: 1280/1386
[A[ATraining Step: 173  | total loss: [1m[32m0.54601[0m[0m | time: 36.902s
[2K
| Adam | epoch: 004 | loss: 0.54601 - acc: 0.7230 -- iter: 1312/1386
[A[ATraining Step: 174  | total loss: [1m[32m0.53745[0m[0m | time: 37.842s
[2K
| Adam | epoch: 004 | loss: 0.53745 - acc: 0.7320 -- iter: 1344/1386
[A[ATraining Step: 175  | total loss: [1m[32m0.52913[0m[0m | time: 38.755s
[2K
| Adam | epoch: 004 | loss: 0.52913 - acc: 0.7369 -- iter: 1376/1386
[A[ATraining Step: 176  | total loss: [1m[32m0.52627[0m[0m | time: 41.754s
[2K
| Adam | epoch: 004 | loss: 0.52627 - acc: 0.7382 | val_loss: 0.54038 - val_acc: 0.7373 -- iter: 1386/1386
--
Training Step: 177  | total loss: [1m[32m0.53180[0m[0m | time: 1.129s
[2K
| Adam | epoch: 005 | loss: 0.53180 - acc: 0.7425 -- iter: 0032/1386
[A[ATraining Step: 178  | total loss: [1m[32m0.52032[0m[0m | time: 2.077s
[2K
| Adam | epoch: 005 | loss: 0.52032 - acc: 0.7495 -- iter: 0064/1386
[A[ATraining Step: 179  | total loss: [1m[32m0.54222[0m[0m | time: 2.377s
[2K
| Adam | epoch: 005 | loss: 0.54222 - acc: 0.7433 -- iter: 0096/1386
[A[ATraining Step: 180  | total loss: [1m[32m0.54284[0m[0m | time: 2.685s
[2K
| Adam | epoch: 005 | loss: 0.54284 - acc: 0.7590 -- iter: 0128/1386
[A[ATraining Step: 181  | total loss: [1m[32m0.53774[0m[0m | time: 3.625s
[2K
| Adam | epoch: 005 | loss: 0.53774 - acc: 0.7731 -- iter: 0160/1386
[A[ATraining Step: 182  | total loss: [1m[32m0.55326[0m[0m | time: 4.578s
[2K
| Adam | epoch: 005 | loss: 0.55326 - acc: 0.7551 -- iter: 0192/1386
[A[ATraining Step: 183  | total loss: [1m[32m0.58197[0m[0m | time: 5.475s
[2K
| Adam | epoch: 005 | loss: 0.58197 - acc: 0.7390 -- iter: 0224/1386
[A[ATraining Step: 184  | total loss: [1m[32m0.56913[0m[0m | time: 6.439s
[2K
| Adam | epoch: 005 | loss: 0.56913 - acc: 0.7401 -- iter: 0256/1386
[A[ATraining Step: 185  | total loss: [1m[32m0.56431[0m[0m | time: 7.463s
[2K
| Adam | epoch: 005 | loss: 0.56431 - acc: 0.7473 -- iter: 0288/1386
[A[ATraining Step: 186  | total loss: [1m[32m0.58424[0m[0m | time: 8.448s
[2K
| Adam | epoch: 005 | loss: 0.58424 - acc: 0.7257 -- iter: 0320/1386
[A[ATraining Step: 187  | total loss: [1m[32m0.59644[0m[0m | time: 9.334s
[2K
| Adam | epoch: 005 | loss: 0.59644 - acc: 0.7032 -- iter: 0352/1386
[A[ATraining Step: 188  | total loss: [1m[32m0.58979[0m[0m | time: 10.363s
[2K
| Adam | epoch: 005 | loss: 0.58979 - acc: 0.7110 -- iter: 0384/1386
[A[ATraining Step: 189  | total loss: [1m[32m0.57856[0m[0m | time: 11.427s
[2K
| Adam | epoch: 005 | loss: 0.57856 - acc: 0.7274 -- iter: 0416/1386
[A[ATraining Step: 190  | total loss: [1m[32m0.57295[0m[0m | time: 12.204s
[2K
| Adam | epoch: 005 | loss: 0.57295 - acc: 0.7234 -- iter: 0448/1386
[A[ATraining Step: 191  | total loss: [1m[32m0.56113[0m[0m | time: 13.027s
[2K
| Adam | epoch: 005 | loss: 0.56113 - acc: 0.7323 -- iter: 0480/1386
[A[ATraining Step: 192  | total loss: [1m[32m0.57029[0m[0m | time: 13.895s
[2K
| Adam | epoch: 005 | loss: 0.57029 - acc: 0.7247 -- iter: 0512/1386
[A[ATraining Step: 193  | total loss: [1m[32m0.59251[0m[0m | time: 14.771s
[2K
| Adam | epoch: 005 | loss: 0.59251 - acc: 0.6960 -- iter: 0544/1386
[A[ATraining Step: 194  | total loss: [1m[32m0.60331[0m[0m | time: 15.660s
[2K
| Adam | epoch: 005 | loss: 0.60331 - acc: 0.6733 -- iter: 0576/1386
[A[ATraining Step: 195  | total loss: [1m[32m0.59618[0m[0m | time: 16.626s
[2K
| Adam | epoch: 005 | loss: 0.59618 - acc: 0.6778 -- iter: 0608/1386
[A[ATraining Step: 196  | total loss: [1m[32m0.59804[0m[0m | time: 17.683s
[2K
| Adam | epoch: 005 | loss: 0.59804 - acc: 0.6756 -- iter: 0640/1386
[A[ATraining Step: 197  | total loss: [1m[32m0.60389[0m[0m | time: 18.551s
[2K
| Adam | epoch: 005 | loss: 0.60389 - acc: 0.6706 -- iter: 0672/1386
[A[ATraining Step: 198  | total loss: [1m[32m0.60305[0m[0m | time: 19.492s
[2K
| Adam | epoch: 005 | loss: 0.60305 - acc: 0.6785 -- iter: 0704/1386
[A[ATraining Step: 199  | total loss: [1m[32m0.59549[0m[0m | time: 20.618s
[2K
| Adam | epoch: 005 | loss: 0.59549 - acc: 0.7044 -- iter: 0736/1386
[A[ATraining Step: 200  | total loss: [1m[32m0.58969[0m[0m | time: 23.356s
[2K
| Adam | epoch: 005 | loss: 0.58969 - acc: 0.7184 | val_loss: 0.57693 - val_acc: 0.7581 -- iter: 0768/1386
--
Training Step: 201  | total loss: [1m[32m0.59125[0m[0m | time: 24.232s
[2K
| Adam | epoch: 005 | loss: 0.59125 - acc: 0.7184 -- iter: 0800/1386
[A[ATraining Step: 202  | total loss: [1m[32m0.58770[0m[0m | time: 25.082s
[2K
| Adam | epoch: 005 | loss: 0.58770 - acc: 0.7278 -- iter: 0832/1386
[A[ATraining Step: 203  | total loss: [1m[32m0.58735[0m[0m | time: 25.951s
[2K
| Adam | epoch: 005 | loss: 0.58735 - acc: 0.7269 -- iter: 0864/1386
[A[ATraining Step: 204  | total loss: [1m[32m0.57966[0m[0m | time: 26.956s
[2K
| Adam | epoch: 005 | loss: 0.57966 - acc: 0.7355 -- iter: 0896/1386
[A[ATraining Step: 205  | total loss: [1m[32m0.57841[0m[0m | time: 27.950s
[2K
| Adam | epoch: 005 | loss: 0.57841 - acc: 0.7275 -- iter: 0928/1386
[A[ATraining Step: 206  | total loss: [1m[32m0.57291[0m[0m | time: 28.818s
[2K
| Adam | epoch: 005 | loss: 0.57291 - acc: 0.7267 -- iter: 0960/1386
[A[ATraining Step: 207  | total loss: [1m[32m0.56686[0m[0m | time: 29.656s
[2K
| Adam | epoch: 005 | loss: 0.56686 - acc: 0.7259 -- iter: 0992/1386
[A[ATraining Step: 208  | total loss: [1m[32m0.54883[0m[0m | time: 30.765s
[2K
| Adam | epoch: 005 | loss: 0.54883 - acc: 0.7408 -- iter: 1024/1386
[A[ATraining Step: 209  | total loss: [1m[32m0.55256[0m[0m | time: 31.801s
[2K
| Adam | epoch: 005 | loss: 0.55256 - acc: 0.7386 -- iter: 1056/1386
[A[ATraining Step: 210  | total loss: [1m[32m0.53628[0m[0m | time: 32.657s
[2K
| Adam | epoch: 005 | loss: 0.53628 - acc: 0.7522 -- iter: 1088/1386
[A[ATraining Step: 211  | total loss: [1m[32m0.52799[0m[0m | time: 33.548s
[2K
| Adam | epoch: 005 | loss: 0.52799 - acc: 0.7614 -- iter: 1120/1386
[A[ATraining Step: 212  | total loss: [1m[32m0.53703[0m[0m | time: 34.450s
[2K
| Adam | epoch: 005 | loss: 0.53703 - acc: 0.7540 -- iter: 1152/1386
[A[ATraining Step: 213  | total loss: [1m[32m0.55167[0m[0m | time: 35.340s
[2K
| Adam | epoch: 005 | loss: 0.55167 - acc: 0.7411 -- iter: 1184/1386
[A[ATraining Step: 214  | total loss: [1m[32m0.55233[0m[0m | time: 36.179s
[2K
| Adam | epoch: 005 | loss: 0.55233 - acc: 0.7389 -- iter: 1216/1386
[A[ATraining Step: 215  | total loss: [1m[32m0.55798[0m[0m | time: 37.178s
[2K
| Adam | epoch: 005 | loss: 0.55798 - acc: 0.7337 -- iter: 1248/1386
[A[ATraining Step: 216  | total loss: [1m[32m0.55211[0m[0m | time: 38.190s
[2K
| Adam | epoch: 005 | loss: 0.55211 - acc: 0.7353 -- iter: 1280/1386
[A[ATraining Step: 217  | total loss: [1m[32m0.56490[0m[0m | time: 39.088s
[2K
| Adam | epoch: 005 | loss: 0.56490 - acc: 0.7306 -- iter: 1312/1386
[A[ATraining Step: 218  | total loss: [1m[32m0.56665[0m[0m | time: 40.118s
[2K
| Adam | epoch: 005 | loss: 0.56665 - acc: 0.7200 -- iter: 1344/1386
[A[ATraining Step: 219  | total loss: [1m[32m0.55666[0m[0m | time: 41.161s
[2K
| Adam | epoch: 005 | loss: 0.55666 - acc: 0.7199 -- iter: 1376/1386
[A[ATraining Step: 220  | total loss: [1m[32m0.55391[0m[0m | time: 43.806s
[2K
| Adam | epoch: 005 | loss: 0.55391 - acc: 0.7198 | val_loss: 0.49446 - val_acc: 0.7811 -- iter: 1386/1386
--
Training Step: 221  | total loss: [1m[32m0.54629[0m[0m | time: 0.853s
[2K
| Adam | epoch: 006 | loss: 0.54629 - acc: 0.7259 -- iter: 0032/1386
[A[ATraining Step: 222  | total loss: [1m[32m0.53945[0m[0m | time: 1.725s
[2K
| Adam | epoch: 006 | loss: 0.53945 - acc: 0.7314 -- iter: 0064/1386
[A[ATraining Step: 223  | total loss: [1m[32m0.53003[0m[0m | time: 2.638s
[2K
| Adam | epoch: 006 | loss: 0.53003 - acc: 0.7396 -- iter: 0096/1386
[A[ATraining Step: 224  | total loss: [1m[32m0.52978[0m[0m | time: 3.005s
[2K
| Adam | epoch: 006 | loss: 0.52978 - acc: 0.7406 -- iter: 0128/1386
[A[ATraining Step: 225  | total loss: [1m[32m0.53263[0m[0m | time: 3.368s
[2K
| Adam | epoch: 006 | loss: 0.53263 - acc: 0.7365 -- iter: 0160/1386
[A[ATraining Step: 226  | total loss: [1m[32m0.52777[0m[0m | time: 4.326s
[2K
| Adam | epoch: 006 | loss: 0.52777 - acc: 0.7329 -- iter: 0192/1386
[A[ATraining Step: 227  | total loss: [1m[32m0.52012[0m[0m | time: 5.187s
[2K
| Adam | epoch: 006 | loss: 0.52012 - acc: 0.7440 -- iter: 0224/1386
[A[ATraining Step: 228  | total loss: [1m[32m0.51165[0m[0m | time: 6.159s
[2K
| Adam | epoch: 006 | loss: 0.51165 - acc: 0.7508 -- iter: 0256/1386
[A[ATraining Step: 229  | total loss: [1m[32m0.50245[0m[0m | time: 7.176s
[2K
| Adam | epoch: 006 | loss: 0.50245 - acc: 0.7539 -- iter: 0288/1386
[A[ATraining Step: 230  | total loss: [1m[32m0.51303[0m[0m | time: 8.194s
[2K
| Adam | epoch: 006 | loss: 0.51303 - acc: 0.7472 -- iter: 0320/1386
[A[ATraining Step: 231  | total loss: [1m[32m0.51674[0m[0m | time: 8.947s
[2K
| Adam | epoch: 006 | loss: 0.51674 - acc: 0.7350 -- iter: 0352/1386
[A[ATraining Step: 232  | total loss: [1m[32m0.51115[0m[0m | time: 9.804s
[2K
| Adam | epoch: 006 | loss: 0.51115 - acc: 0.7396 -- iter: 0384/1386
[A[ATraining Step: 233  | total loss: [1m[32m0.51304[0m[0m | time: 10.656s
[2K
| Adam | epoch: 006 | loss: 0.51304 - acc: 0.7407 -- iter: 0416/1386
[A[ATraining Step: 234  | total loss: [1m[32m0.51096[0m[0m | time: 11.549s
[2K
| Adam | epoch: 006 | loss: 0.51096 - acc: 0.7479 -- iter: 0448/1386
[A[ATraining Step: 235  | total loss: [1m[32m0.51209[0m[0m | time: 12.435s
[2K
| Adam | epoch: 006 | loss: 0.51209 - acc: 0.7481 -- iter: 0480/1386
[A[ATraining Step: 236  | total loss: [1m[32m0.51470[0m[0m | time: 13.376s
[2K
| Adam | epoch: 006 | loss: 0.51470 - acc: 0.7514 -- iter: 0512/1386
[A[ATraining Step: 237  | total loss: [1m[32m0.50326[0m[0m | time: 14.302s
[2K
| Adam | epoch: 006 | loss: 0.50326 - acc: 0.7606 -- iter: 0544/1386
[A[ATraining Step: 238  | total loss: [1m[32m0.52095[0m[0m | time: 15.127s
[2K
| Adam | epoch: 006 | loss: 0.52095 - acc: 0.7408 -- iter: 0576/1386
[A[ATraining Step: 239  | total loss: [1m[32m0.51489[0m[0m | time: 16.099s
[2K
| Adam | epoch: 006 | loss: 0.51489 - acc: 0.7449 -- iter: 0608/1386
[A[ATraining Step: 240  | total loss: [1m[32m0.53515[0m[0m | time: 17.159s
[2K
| Adam | epoch: 006 | loss: 0.53515 - acc: 0.7360 -- iter: 0640/1386
[A[ATraining Step: 241  | total loss: [1m[32m0.54149[0m[0m | time: 18.135s
[2K
| Adam | epoch: 006 | loss: 0.54149 - acc: 0.7249 -- iter: 0672/1386
[A[ATraining Step: 242  | total loss: [1m[32m0.53200[0m[0m | time: 18.935s
[2K
| Adam | epoch: 006 | loss: 0.53200 - acc: 0.7337 -- iter: 0704/1386
[A[ATraining Step: 243  | total loss: [1m[32m0.54518[0m[0m | time: 19.812s
[2K
| Adam | epoch: 006 | loss: 0.54518 - acc: 0.7259 -- iter: 0736/1386
[A[ATraining Step: 244  | total loss: [1m[32m0.54163[0m[0m | time: 20.674s
[2K
| Adam | epoch: 006 | loss: 0.54163 - acc: 0.7314 -- iter: 0768/1386
[A[ATraining Step: 245  | total loss: [1m[32m0.53369[0m[0m | time: 21.545s
[2K
| Adam | epoch: 006 | loss: 0.53369 - acc: 0.7364 -- iter: 0800/1386
[A[ATraining Step: 246  | total loss: [1m[32m0.52425[0m[0m | time: 22.449s
[2K
| Adam | epoch: 006 | loss: 0.52425 - acc: 0.7503 -- iter: 0832/1386
[A[ATraining Step: 247  | total loss: [1m[32m0.51228[0m[0m | time: 23.351s
[2K
| Adam | epoch: 006 | loss: 0.51228 - acc: 0.7659 -- iter: 0864/1386
[A[ATraining Step: 248  | total loss: [1m[32m0.50896[0m[0m | time: 24.276s
[2K
| Adam | epoch: 006 | loss: 0.50896 - acc: 0.7674 -- iter: 0896/1386
[A[ATraining Step: 249  | total loss: [1m[32m0.51096[0m[0m | time: 25.139s
[2K
| Adam | epoch: 006 | loss: 0.51096 - acc: 0.7626 -- iter: 0928/1386
[A[ATraining Step: 250  | total loss: [1m[32m0.51709[0m[0m | time: 26.225s
[2K
| Adam | epoch: 006 | loss: 0.51709 - acc: 0.7613 -- iter: 0960/1386
[A[ATraining Step: 251  | total loss: [1m[32m0.49862[0m[0m | time: 27.278s
[2K
| Adam | epoch: 006 | loss: 0.49862 - acc: 0.7727 -- iter: 0992/1386
[A[ATraining Step: 252  | total loss: [1m[32m0.49707[0m[0m | time: 28.159s
[2K
| Adam | epoch: 006 | loss: 0.49707 - acc: 0.7673 -- iter: 1024/1386
[A[ATraining Step: 253  | total loss: [1m[32m0.48245[0m[0m | time: 28.964s
[2K
| Adam | epoch: 006 | loss: 0.48245 - acc: 0.7718 -- iter: 1056/1386
[A[ATraining Step: 254  | total loss: [1m[32m0.46980[0m[0m | time: 29.836s
[2K
| Adam | epoch: 006 | loss: 0.46980 - acc: 0.7790 -- iter: 1088/1386
[A[ATraining Step: 255  | total loss: [1m[32m0.49406[0m[0m | time: 30.724s
[2K
| Adam | epoch: 006 | loss: 0.49406 - acc: 0.7511 -- iter: 1120/1386
[A[ATraining Step: 256  | total loss: [1m[32m0.48537[0m[0m | time: 31.637s
[2K
| Adam | epoch: 006 | loss: 0.48537 - acc: 0.7635 -- iter: 1152/1386
[A[ATraining Step: 257  | total loss: [1m[32m0.49715[0m[0m | time: 32.553s
[2K
| Adam | epoch: 006 | loss: 0.49715 - acc: 0.7559 -- iter: 1184/1386
[A[ATraining Step: 258  | total loss: [1m[32m0.51577[0m[0m | time: 33.470s
[2K
| Adam | epoch: 006 | loss: 0.51577 - acc: 0.7397 -- iter: 1216/1386
[A[ATraining Step: 259  | total loss: [1m[32m0.51032[0m[0m | time: 34.417s
[2K
| Adam | epoch: 006 | loss: 0.51032 - acc: 0.7438 -- iter: 1248/1386
[A[ATraining Step: 260  | total loss: [1m[32m0.50362[0m[0m | time: 35.279s
[2K
| Adam | epoch: 006 | loss: 0.50362 - acc: 0.7507 -- iter: 1280/1386
[A[ATraining Step: 261  | total loss: [1m[32m0.49610[0m[0m | time: 36.290s
[2K
| Adam | epoch: 006 | loss: 0.49610 - acc: 0.7569 -- iter: 1312/1386
[A[ATraining Step: 262  | total loss: [1m[32m0.48345[0m[0m | time: 37.348s
[2K
| Adam | epoch: 006 | loss: 0.48345 - acc: 0.7624 -- iter: 1344/1386
[A[ATraining Step: 263  | total loss: [1m[32m0.47521[0m[0m | time: 38.159s
[2K
| Adam | epoch: 006 | loss: 0.47521 - acc: 0.7612 -- iter: 1376/1386
[A[ATraining Step: 264  | total loss: [1m[32m0.49295[0m[0m | time: 40.950s
[2K
| Adam | epoch: 006 | loss: 0.49295 - acc: 0.7476 | val_loss: 0.47822 - val_acc: 0.7903 -- iter: 1386/1386
--
Training Step: 265  | total loss: [1m[32m0.51336[0m[0m | time: 0.938s
[2K
| Adam | epoch: 007 | loss: 0.51336 - acc: 0.7322 -- iter: 0032/1386
[A[ATraining Step: 266  | total loss: [1m[32m0.50413[0m[0m | time: 1.973s
[2K
| Adam | epoch: 007 | loss: 0.50413 - acc: 0.7465 -- iter: 0064/1386
[A[ATraining Step: 267  | total loss: [1m[32m0.48079[0m[0m | time: 2.938s
[2K
| Adam | epoch: 007 | loss: 0.48079 - acc: 0.7656 -- iter: 0096/1386
[A[ATraining Step: 268  | total loss: [1m[32m0.47858[0m[0m | time: 3.810s
[2K
| Adam | epoch: 007 | loss: 0.47858 - acc: 0.7734 -- iter: 0128/1386
[A[ATraining Step: 269  | total loss: [1m[32m0.48245[0m[0m | time: 4.228s
[2K
| Adam | epoch: 007 | loss: 0.48245 - acc: 0.7679 -- iter: 0160/1386
[A[ATraining Step: 270  | total loss: [1m[32m0.49400[0m[0m | time: 4.603s
[2K
| Adam | epoch: 007 | loss: 0.49400 - acc: 0.7611 -- iter: 0192/1386
[A[ATraining Step: 271  | total loss: [1m[32m0.50177[0m[0m | time: 5.628s
[2K
| Adam | epoch: 007 | loss: 0.50177 - acc: 0.7550 -- iter: 0224/1386
[A[ATraining Step: 272  | total loss: [1m[32m0.48325[0m[0m | time: 6.519s
[2K
| Adam | epoch: 007 | loss: 0.48325 - acc: 0.7701 -- iter: 0256/1386
[A[ATraining Step: 273  | total loss: [1m[32m0.48062[0m[0m | time: 7.317s
[2K
| Adam | epoch: 007 | loss: 0.48062 - acc: 0.7744 -- iter: 0288/1386
[A[ATraining Step: 274  | total loss: [1m[32m0.47897[0m[0m | time: 8.167s
[2K
| Adam | epoch: 007 | loss: 0.47897 - acc: 0.7813 -- iter: 0320/1386
[A[ATraining Step: 275  | total loss: [1m[32m0.47271[0m[0m | time: 9.097s
[2K
| Adam | epoch: 007 | loss: 0.47271 - acc: 0.7813 -- iter: 0352/1386
[A[ATraining Step: 276  | total loss: [1m[32m0.46864[0m[0m | time: 9.963s
[2K
| Adam | epoch: 007 | loss: 0.46864 - acc: 0.7844 -- iter: 0384/1386
[A[ATraining Step: 277  | total loss: [1m[32m0.46865[0m[0m | time: 10.915s
[2K
| Adam | epoch: 007 | loss: 0.46865 - acc: 0.7841 -- iter: 0416/1386
[A[ATraining Step: 278  | total loss: [1m[32m0.47601[0m[0m | time: 11.917s
[2K
| Adam | epoch: 007 | loss: 0.47601 - acc: 0.7745 -- iter: 0448/1386
[A[ATraining Step: 279  | total loss: [1m[32m0.46860[0m[0m | time: 12.834s
[2K
| Adam | epoch: 007 | loss: 0.46860 - acc: 0.7814 -- iter: 0480/1386
[A[ATraining Step: 280  | total loss: [1m[32m0.44836[0m[0m | time: 13.762s
[2K
| Adam | epoch: 007 | loss: 0.44836 - acc: 0.8001 -- iter: 0512/1386
[A[ATraining Step: 281  | total loss: [1m[32m0.45830[0m[0m | time: 14.801s
[2K
| Adam | epoch: 007 | loss: 0.45830 - acc: 0.7920 -- iter: 0544/1386
[A[ATraining Step: 282  | total loss: [1m[32m0.45398[0m[0m | time: 15.842s
[2K
| Adam | epoch: 007 | loss: 0.45398 - acc: 0.7972 -- iter: 0576/1386
[A[ATraining Step: 283  | total loss: [1m[32m0.44728[0m[0m | time: 16.632s
[2K
| Adam | epoch: 007 | loss: 0.44728 - acc: 0.8018 -- iter: 0608/1386
[A[ATraining Step: 284  | total loss: [1m[32m0.44783[0m[0m | time: 17.513s
[2K
| Adam | epoch: 007 | loss: 0.44783 - acc: 0.7998 -- iter: 0640/1386
[A[ATraining Step: 285  | total loss: [1m[32m0.45636[0m[0m | time: 18.405s
[2K
| Adam | epoch: 007 | loss: 0.45636 - acc: 0.7885 -- iter: 0672/1386
[A[ATraining Step: 286  | total loss: [1m[32m0.47116[0m[0m | time: 19.287s
[2K
| Adam | epoch: 007 | loss: 0.47116 - acc: 0.7784 -- iter: 0704/1386
[A[ATraining Step: 287  | total loss: [1m[32m0.46427[0m[0m | time: 20.239s
[2K
| Adam | epoch: 007 | loss: 0.46427 - acc: 0.7881 -- iter: 0736/1386
[A[ATraining Step: 288  | total loss: [1m[32m0.46057[0m[0m | time: 21.252s
[2K
| Adam | epoch: 007 | loss: 0.46057 - acc: 0.7905 -- iter: 0768/1386
[A[ATraining Step: 289  | total loss: [1m[32m0.46501[0m[0m | time: 22.206s
[2K
| Adam | epoch: 007 | loss: 0.46501 - acc: 0.7834 -- iter: 0800/1386
[A[ATraining Step: 290  | total loss: [1m[32m0.46851[0m[0m | time: 23.053s
[2K
| Adam | epoch: 007 | loss: 0.46851 - acc: 0.7706 -- iter: 0832/1386
[A[ATraining Step: 291  | total loss: [1m[32m0.45451[0m[0m | time: 24.053s
[2K
| Adam | epoch: 007 | loss: 0.45451 - acc: 0.7811 -- iter: 0864/1386
[A[ATraining Step: 292  | total loss: [1m[32m0.43670[0m[0m | time: 25.086s
[2K
| Adam | epoch: 007 | loss: 0.43670 - acc: 0.7967 -- iter: 0896/1386
[A[ATraining Step: 293  | total loss: [1m[32m0.44034[0m[0m | time: 25.914s
[2K
| Adam | epoch: 007 | loss: 0.44034 - acc: 0.7952 -- iter: 0928/1386
[A[ATraining Step: 294  | total loss: [1m[32m0.44528[0m[0m | time: 26.728s
[2K
| Adam | epoch: 007 | loss: 0.44528 - acc: 0.7938 -- iter: 0960/1386
[A[ATraining Step: 295  | total loss: [1m[32m0.45195[0m[0m | time: 27.665s
[2K
| Adam | epoch: 007 | loss: 0.45195 - acc: 0.7925 -- iter: 0992/1386
[A[ATraining Step: 296  | total loss: [1m[32m0.43950[0m[0m | time: 28.541s
[2K
| Adam | epoch: 007 | loss: 0.43950 - acc: 0.8008 -- iter: 1024/1386
[A[ATraining Step: 297  | total loss: [1m[32m0.42652[0m[0m | time: 29.413s
[2K
| Adam | epoch: 007 | loss: 0.42652 - acc: 0.8113 -- iter: 1056/1386
[A[ATraining Step: 298  | total loss: [1m[32m0.42491[0m[0m | time: 30.381s
[2K
| Adam | epoch: 007 | loss: 0.42491 - acc: 0.8114 -- iter: 1088/1386
[A[ATraining Step: 299  | total loss: [1m[32m0.40675[0m[0m | time: 31.452s
[2K
| Adam | epoch: 007 | loss: 0.40675 - acc: 0.8240 -- iter: 1120/1386
[A[ATraining Step: 300  | total loss: [1m[32m0.39171[0m[0m | time: 32.332s
[2K
| Adam | epoch: 007 | loss: 0.39171 - acc: 0.8354 -- iter: 1152/1386
[A[ATraining Step: 301  | total loss: [1m[32m0.40298[0m[0m | time: 33.278s
[2K
| Adam | epoch: 007 | loss: 0.40298 - acc: 0.8300 -- iter: 1184/1386
[A[ATraining Step: 302  | total loss: [1m[32m0.38616[0m[0m | time: 34.287s
[2K
| Adam | epoch: 007 | loss: 0.38616 - acc: 0.8439 -- iter: 1216/1386
[A[ATraining Step: 303  | total loss: [1m[32m0.37776[0m[0m | time: 35.305s
[2K
| Adam | epoch: 007 | loss: 0.37776 - acc: 0.8470 -- iter: 1248/1386
[A[ATraining Step: 304  | total loss: [1m[32m0.38266[0m[0m | time: 36.043s
[2K
| Adam | epoch: 007 | loss: 0.38266 - acc: 0.8404 -- iter: 1280/1386
[A[ATraining Step: 305  | total loss: [1m[32m0.38060[0m[0m | time: 36.881s
[2K
| Adam | epoch: 007 | loss: 0.38060 - acc: 0.8407 -- iter: 1312/1386
[A[ATraining Step: 306  | total loss: [1m[32m0.40600[0m[0m | time: 37.726s
[2K
| Adam | epoch: 007 | loss: 0.40600 - acc: 0.8254 -- iter: 1344/1386
[A[ATraining Step: 307  | total loss: [1m[32m0.40161[0m[0m | time: 38.588s
[2K
| Adam | epoch: 007 | loss: 0.40161 - acc: 0.8272 -- iter: 1376/1386
[A[ATraining Step: 308  | total loss: [1m[32m0.38724[0m[0m | time: 41.526s
[2K
| Adam | epoch: 007 | loss: 0.38724 - acc: 0.8414 | val_loss: 0.43724 - val_acc: 0.7995 -- iter: 1386/1386
--
Training Step: 309  | total loss: [1m[32m0.39970[0m[0m | time: 0.854s
[2K
| Adam | epoch: 008 | loss: 0.39970 - acc: 0.8354 -- iter: 0032/1386
[A[ATraining Step: 310  | total loss: [1m[32m0.40250[0m[0m | time: 1.855s
[2K
| Adam | epoch: 008 | loss: 0.40250 - acc: 0.8300 -- iter: 0064/1386
[A[ATraining Step: 311  | total loss: [1m[32m0.40259[0m[0m | time: 2.899s
[2K
| Adam | epoch: 008 | loss: 0.40259 - acc: 0.8251 -- iter: 0096/1386
[A[ATraining Step: 312  | total loss: [1m[32m0.39763[0m[0m | time: 3.860s
[2K
| Adam | epoch: 008 | loss: 0.39763 - acc: 0.8238 -- iter: 0128/1386
[A[ATraining Step: 313  | total loss: [1m[32m0.42203[0m[0m | time: 4.624s
[2K
| Adam | epoch: 008 | loss: 0.42203 - acc: 0.8040 -- iter: 0160/1386
[A[ATraining Step: 314  | total loss: [1m[32m0.42263[0m[0m | time: 4.947s
[2K
| Adam | epoch: 008 | loss: 0.42263 - acc: 0.7986 -- iter: 0192/1386
[A[ATraining Step: 315  | total loss: [1m[32m0.47301[0m[0m | time: 5.274s
[2K
| Adam | epoch: 008 | loss: 0.47301 - acc: 0.7787 -- iter: 0224/1386
[A[ATraining Step: 316  | total loss: [1m[32m0.49054[0m[0m | time: 6.167s
[2K
| Adam | epoch: 008 | loss: 0.49054 - acc: 0.7708 -- iter: 0256/1386
[A[ATraining Step: 317  | total loss: [1m[32m0.47798[0m[0m | time: 7.042s
[2K
| Adam | epoch: 008 | loss: 0.47798 - acc: 0.7750 -- iter: 0288/1386
[A[ATraining Step: 318  | total loss: [1m[32m0.48999[0m[0m | time: 7.945s
[2K
| Adam | epoch: 008 | loss: 0.48999 - acc: 0.7662 -- iter: 0320/1386
[A[ATraining Step: 319  | total loss: [1m[32m0.49070[0m[0m | time: 8.949s
[2K
| Adam | epoch: 008 | loss: 0.49070 - acc: 0.7646 -- iter: 0352/1386
[A[ATraining Step: 320  | total loss: [1m[32m0.48909[0m[0m | time: 9.894s
[2K
| Adam | epoch: 008 | loss: 0.48909 - acc: 0.7694 -- iter: 0384/1386
[A[ATraining Step: 321  | total loss: [1m[32m0.48534[0m[0m | time: 10.690s
[2K
| Adam | epoch: 008 | loss: 0.48534 - acc: 0.7675 -- iter: 0416/1386
[A[ATraining Step: 322  | total loss: [1m[32m0.46806[0m[0m | time: 11.695s
[2K
| Adam | epoch: 008 | loss: 0.46806 - acc: 0.7813 -- iter: 0448/1386
[A[ATraining Step: 323  | total loss: [1m[32m0.48264[0m[0m | time: 12.736s
[2K
| Adam | epoch: 008 | loss: 0.48264 - acc: 0.7720 -- iter: 0480/1386
[A[ATraining Step: 324  | total loss: [1m[32m0.46273[0m[0m | time: 13.607s
[2K
| Adam | epoch: 008 | loss: 0.46273 - acc: 0.7823 -- iter: 0512/1386
[A[ATraining Step: 325  | total loss: [1m[32m0.45681[0m[0m | time: 14.359s
[2K
| Adam | epoch: 008 | loss: 0.45681 - acc: 0.7853 -- iter: 0544/1386
[A[ATraining Step: 326  | total loss: [1m[32m0.44526[0m[0m | time: 15.277s
[2K
| Adam | epoch: 008 | loss: 0.44526 - acc: 0.7943 -- iter: 0576/1386
[A[ATraining Step: 327  | total loss: [1m[32m0.43719[0m[0m | time: 16.137s
[2K
| Adam | epoch: 008 | loss: 0.43719 - acc: 0.8023 -- iter: 0608/1386
[A[ATraining Step: 328  | total loss: [1m[32m0.42807[0m[0m | time: 17.020s
[2K
| Adam | epoch: 008 | loss: 0.42807 - acc: 0.8065 -- iter: 0640/1386
[A[ATraining Step: 329  | total loss: [1m[32m0.42416[0m[0m | time: 17.930s
[2K
| Adam | epoch: 008 | loss: 0.42416 - acc: 0.8133 -- iter: 0672/1386
[A[ATraining Step: 330  | total loss: [1m[32m0.41730[0m[0m | time: 18.920s
[2K
| Adam | epoch: 008 | loss: 0.41730 - acc: 0.8257 -- iter: 0704/1386
[A[ATraining Step: 331  | total loss: [1m[32m0.40858[0m[0m | time: 19.818s
[2K
| Adam | epoch: 008 | loss: 0.40858 - acc: 0.8338 -- iter: 0736/1386
[A[ATraining Step: 332  | total loss: [1m[32m0.41518[0m[0m | time: 20.704s
[2K
| Adam | epoch: 008 | loss: 0.41518 - acc: 0.8317 -- iter: 0768/1386
[A[ATraining Step: 333  | total loss: [1m[32m0.39931[0m[0m | time: 21.715s
[2K
| Adam | epoch: 008 | loss: 0.39931 - acc: 0.8423 -- iter: 0800/1386
[A[ATraining Step: 334  | total loss: [1m[32m0.39735[0m[0m | time: 22.753s
[2K
| Adam | epoch: 008 | loss: 0.39735 - acc: 0.8455 -- iter: 0832/1386
[A[ATraining Step: 335  | total loss: [1m[32m0.39790[0m[0m | time: 23.573s
[2K
| Adam | epoch: 008 | loss: 0.39790 - acc: 0.8485 -- iter: 0864/1386
[A[ATraining Step: 336  | total loss: [1m[32m0.39856[0m[0m | time: 24.478s
[2K
| Adam | epoch: 008 | loss: 0.39856 - acc: 0.8480 -- iter: 0896/1386
[A[ATraining Step: 337  | total loss: [1m[32m0.38443[0m[0m | time: 25.367s
[2K
| Adam | epoch: 008 | loss: 0.38443 - acc: 0.8507 -- iter: 0928/1386
[A[ATraining Step: 338  | total loss: [1m[32m0.37505[0m[0m | time: 26.264s
[2K
| Adam | epoch: 008 | loss: 0.37505 - acc: 0.8563 -- iter: 0960/1386
[A[ATraining Step: 339  | total loss: [1m[32m0.37246[0m[0m | time: 27.128s
[2K
| Adam | epoch: 008 | loss: 0.37246 - acc: 0.8581 -- iter: 0992/1386
[A[ATraining Step: 340  | total loss: [1m[32m0.39404[0m[0m | time: 28.100s
[2K
| Adam | epoch: 008 | loss: 0.39404 - acc: 0.8348 -- iter: 1024/1386
[A[ATraining Step: 341  | total loss: [1m[32m0.37253[0m[0m | time: 29.038s
[2K
| Adam | epoch: 008 | loss: 0.37253 - acc: 0.8482 -- iter: 1056/1386
[A[ATraining Step: 342  | total loss: [1m[32m0.35810[0m[0m | time: 29.880s
[2K
| Adam | epoch: 008 | loss: 0.35810 - acc: 0.8571 -- iter: 1088/1386
[A[ATraining Step: 343  | total loss: [1m[32m0.35560[0m[0m | time: 30.934s
[2K
| Adam | epoch: 008 | loss: 0.35560 - acc: 0.8527 -- iter: 1120/1386
[A[ATraining Step: 344  | total loss: [1m[32m0.37554[0m[0m | time: 31.969s
[2K
| Adam | epoch: 008 | loss: 0.37554 - acc: 0.8455 -- iter: 1152/1386
[A[ATraining Step: 345  | total loss: [1m[32m0.37701[0m[0m | time: 32.919s
[2K
| Adam | epoch: 008 | loss: 0.37701 - acc: 0.8422 -- iter: 1184/1386
[A[ATraining Step: 346  | total loss: [1m[32m0.36757[0m[0m | time: 33.757s
[2K
| Adam | epoch: 008 | loss: 0.36757 - acc: 0.8455 -- iter: 1216/1386
[A[ATraining Step: 347  | total loss: [1m[32m0.36414[0m[0m | time: 34.650s
[2K
| Adam | epoch: 008 | loss: 0.36414 - acc: 0.8453 -- iter: 1248/1386
[A[ATraining Step: 348  | total loss: [1m[32m0.35852[0m[0m | time: 35.542s
[2K
| Adam | epoch: 008 | loss: 0.35852 - acc: 0.8420 -- iter: 1280/1386
[A[ATraining Step: 349  | total loss: [1m[32m0.36024[0m[0m | time: 36.410s
[2K
| Adam | epoch: 008 | loss: 0.36024 - acc: 0.8422 -- iter: 1312/1386
[A[ATraining Step: 350  | total loss: [1m[32m0.35507[0m[0m | time: 37.362s
[2K
| Adam | epoch: 008 | loss: 0.35507 - acc: 0.8392 -- iter: 1344/1386
[A[ATraining Step: 351  | total loss: [1m[32m0.35189[0m[0m | time: 38.353s
[2K
| Adam | epoch: 008 | loss: 0.35189 - acc: 0.8366 -- iter: 1376/1386
[A[ATraining Step: 352  | total loss: [1m[32m0.33592[0m[0m | time: 41.219s
[2K
| Adam | epoch: 008 | loss: 0.33592 - acc: 0.8435 | val_loss: 0.44591 - val_acc: 0.8111 -- iter: 1386/1386
--
Training Step: 353  | total loss: [1m[32m0.34314[0m[0m | time: 0.978s
[2K
| Adam | epoch: 009 | loss: 0.34314 - acc: 0.8342 -- iter: 0032/1386
[A[ATraining Step: 354  | total loss: [1m[32m0.33732[0m[0m | time: 1.755s
[2K
| Adam | epoch: 009 | loss: 0.33732 - acc: 0.8414 -- iter: 0064/1386
[A[ATraining Step: 355  | total loss: [1m[32m0.33937[0m[0m | time: 2.603s
[2K
| Adam | epoch: 009 | loss: 0.33937 - acc: 0.8479 -- iter: 0096/1386
[A[ATraining Step: 356  | total loss: [1m[32m0.33763[0m[0m | time: 3.449s
[2K
| Adam | epoch: 009 | loss: 0.33763 - acc: 0.8443 -- iter: 0128/1386
[A[ATraining Step: 357  | total loss: [1m[32m0.34670[0m[0m | time: 4.297s
[2K
| Adam | epoch: 009 | loss: 0.34670 - acc: 0.8380 -- iter: 0160/1386
[A[ATraining Step: 358  | total loss: [1m[32m0.35169[0m[0m | time: 5.161s
[2K
| Adam | epoch: 009 | loss: 0.35169 - acc: 0.8324 -- iter: 0192/1386
[A[ATraining Step: 359  | total loss: [1m[32m0.35901[0m[0m | time: 5.507s
[2K
| Adam | epoch: 009 | loss: 0.35901 - acc: 0.8335 -- iter: 0224/1386
[A[ATraining Step: 360  | total loss: [1m[32m0.36602[0m[0m | time: 5.873s
[2K
| Adam | epoch: 009 | loss: 0.36602 - acc: 0.8301 -- iter: 0256/1386
[A[ATraining Step: 361  | total loss: [1m[32m0.35564[0m[0m | time: 6.831s
[2K
| Adam | epoch: 009 | loss: 0.35564 - acc: 0.8271 -- iter: 0288/1386
[A[ATraining Step: 362  | total loss: [1m[32m0.37278[0m[0m | time: 7.726s
[2K
| Adam | epoch: 009 | loss: 0.37278 - acc: 0.8194 -- iter: 0320/1386
[A[ATraining Step: 363  | total loss: [1m[32m0.38439[0m[0m | time: 8.708s
[2K
| Adam | epoch: 009 | loss: 0.38439 - acc: 0.8156 -- iter: 0352/1386
[A[ATraining Step: 364  | total loss: [1m[32m0.39153[0m[0m | time: 9.745s
[2K
| Adam | epoch: 009 | loss: 0.39153 - acc: 0.8090 -- iter: 0384/1386
[A[ATraining Step: 365  | total loss: [1m[32m0.39888[0m[0m | time: 10.718s
[2K
| Adam | epoch: 009 | loss: 0.39888 - acc: 0.8063 -- iter: 0416/1386
[A[ATraining Step: 366  | total loss: [1m[32m0.39272[0m[0m | time: 11.503s
[2K
| Adam | epoch: 009 | loss: 0.39272 - acc: 0.8100 -- iter: 0448/1386
[A[ATraining Step: 367  | total loss: [1m[32m0.37807[0m[0m | time: 12.391s
[2K
| Adam | epoch: 009 | loss: 0.37807 - acc: 0.8196 -- iter: 0480/1386
[A[ATraining Step: 368  | total loss: [1m[32m0.37686[0m[0m | time: 13.261s
[2K
| Adam | epoch: 009 | loss: 0.37686 - acc: 0.8220 -- iter: 0512/1386
[A[ATraining Step: 369  | total loss: [1m[32m0.40555[0m[0m | time: 14.157s
[2K
| Adam | epoch: 009 | loss: 0.40555 - acc: 0.8055 -- iter: 0544/1386
[A[ATraining Step: 370  | total loss: [1m[32m0.42641[0m[0m | time: 15.042s
[2K
| Adam | epoch: 009 | loss: 0.42641 - acc: 0.7843 -- iter: 0576/1386
[A[ATraining Step: 371  | total loss: [1m[32m0.43012[0m[0m | time: 16.011s
[2K
| Adam | epoch: 009 | loss: 0.43012 - acc: 0.7871 -- iter: 0608/1386
[A[ATraining Step: 372  | total loss: [1m[32m0.41161[0m[0m | time: 16.917s
[2K
| Adam | epoch: 009 | loss: 0.41161 - acc: 0.8053 -- iter: 0640/1386
[A[ATraining Step: 373  | total loss: [1m[32m0.46595[0m[0m | time: 17.748s
[2K
| Adam | epoch: 009 | loss: 0.46595 - acc: 0.7873 -- iter: 0672/1386
[A[ATraining Step: 374  | total loss: [1m[32m0.46717[0m[0m | time: 18.758s
[2K
| Adam | epoch: 009 | loss: 0.46717 - acc: 0.7898 -- iter: 0704/1386
[A[ATraining Step: 375  | total loss: [1m[32m0.45666[0m[0m | time: 19.780s
[2K
| Adam | epoch: 009 | loss: 0.45666 - acc: 0.7889 -- iter: 0736/1386
[A[ATraining Step: 376  | total loss: [1m[32m0.43981[0m[0m | time: 20.733s
[2K
| Adam | epoch: 009 | loss: 0.43981 - acc: 0.8007 -- iter: 0768/1386
[A[ATraining Step: 377  | total loss: [1m[32m0.42954[0m[0m | time: 21.500s
[2K
| Adam | epoch: 009 | loss: 0.42954 - acc: 0.8081 -- iter: 0800/1386
[A[ATraining Step: 378  | total loss: [1m[32m0.41829[0m[0m | time: 22.396s
[2K
| Adam | epoch: 009 | loss: 0.41829 - acc: 0.8179 -- iter: 0832/1386
[A[ATraining Step: 379  | total loss: [1m[32m0.41115[0m[0m | time: 23.298s
[2K
| Adam | epoch: 009 | loss: 0.41115 - acc: 0.8299 -- iter: 0864/1386
[A[ATraining Step: 380  | total loss: [1m[32m0.39777[0m[0m | time: 24.199s
[2K
| Adam | epoch: 009 | loss: 0.39777 - acc: 0.8406 -- iter: 0896/1386
[A[ATraining Step: 381  | total loss: [1m[32m0.38508[0m[0m | time: 25.131s
[2K
| Adam | epoch: 009 | loss: 0.38508 - acc: 0.8503 -- iter: 0928/1386
[A[ATraining Step: 382  | total loss: [1m[32m0.39217[0m[0m | time: 26.134s
[2K
| Adam | epoch: 009 | loss: 0.39217 - acc: 0.8497 -- iter: 0960/1386
[A[ATraining Step: 383  | total loss: [1m[32m0.39115[0m[0m | time: 27.054s
[2K
| Adam | epoch: 009 | loss: 0.39115 - acc: 0.8491 -- iter: 0992/1386
[A[ATraining Step: 384  | total loss: [1m[32m0.38148[0m[0m | time: 27.901s
[2K
| Adam | epoch: 009 | loss: 0.38148 - acc: 0.8548 -- iter: 1024/1386
[A[ATraining Step: 385  | total loss: [1m[32m0.36861[0m[0m | time: 28.961s
[2K
| Adam | epoch: 009 | loss: 0.36861 - acc: 0.8631 -- iter: 1056/1386
[A[ATraining Step: 386  | total loss: [1m[32m0.36641[0m[0m | time: 29.956s
[2K
| Adam | epoch: 009 | loss: 0.36641 - acc: 0.8580 -- iter: 1088/1386
[A[ATraining Step: 387  | total loss: [1m[32m0.35686[0m[0m | time: 30.864s
[2K
| Adam | epoch: 009 | loss: 0.35686 - acc: 0.8660 -- iter: 1120/1386
[A[ATraining Step: 388  | total loss: [1m[32m0.36241[0m[0m | time: 31.682s
[2K
| Adam | epoch: 009 | loss: 0.36241 - acc: 0.8606 -- iter: 1152/1386
[A[ATraining Step: 389  | total loss: [1m[32m0.34286[0m[0m | time: 32.554s
[2K
| Adam | epoch: 009 | loss: 0.34286 - acc: 0.8714 -- iter: 1184/1386
[A[ATraining Step: 390  | total loss: [1m[32m0.33316[0m[0m | time: 33.416s
[2K
| Adam | epoch: 009 | loss: 0.33316 - acc: 0.8718 -- iter: 1216/1386
[A[ATraining Step: 391  | total loss: [1m[32m0.33899[0m[0m | time: 34.349s
[2K
| Adam | epoch: 009 | loss: 0.33899 - acc: 0.8659 -- iter: 1248/1386
[A[ATraining Step: 392  | total loss: [1m[32m0.32823[0m[0m | time: 35.271s
[2K
| Adam | epoch: 009 | loss: 0.32823 - acc: 0.8699 -- iter: 1280/1386
[A[ATraining Step: 393  | total loss: [1m[32m0.32906[0m[0m | time: 36.222s
[2K
| Adam | epoch: 009 | loss: 0.32906 - acc: 0.8673 -- iter: 1312/1386
[A[ATraining Step: 394  | total loss: [1m[32m0.30662[0m[0m | time: 37.107s
[2K
| Adam | epoch: 009 | loss: 0.30662 - acc: 0.8805 -- iter: 1344/1386
[A[ATraining Step: 395  | total loss: [1m[32m0.29069[0m[0m | time: 37.988s
[2K
| Adam | epoch: 009 | loss: 0.29069 - acc: 0.8894 -- iter: 1376/1386
[A[ATraining Step: 396  | total loss: [1m[32m0.27622[0m[0m | time: 41.071s
[2K
| Adam | epoch: 009 | loss: 0.27622 - acc: 0.8973 | val_loss: 0.35321 - val_acc: 0.8571 -- iter: 1386/1386
--
Training Step: 397  | total loss: [1m[32m0.27996[0m[0m | time: 0.871s
[2K
| Adam | epoch: 010 | loss: 0.27996 - acc: 0.8951 -- iter: 0032/1386
[A[ATraining Step: 398  | total loss: [1m[32m0.28779[0m[0m | time: 1.770s
[2K
| Adam | epoch: 010 | loss: 0.28779 - acc: 0.8868 -- iter: 0064/1386
[A[ATraining Step: 399  | total loss: [1m[32m0.28620[0m[0m | time: 2.663s
[2K
| Adam | epoch: 010 | loss: 0.28620 - acc: 0.8856 -- iter: 0096/1386
[A[ATraining Step: 400  | total loss: [1m[32m0.29547[0m[0m | time: 5.686s
[2K
| Adam | epoch: 010 | loss: 0.29547 - acc: 0.8877 | val_loss: 0.51569 - val_acc: 0.8088 -- iter: 0128/1386
--
Training Step: 401  | total loss: [1m[32m0.29440[0m[0m | time: 6.505s
[2K
| Adam | epoch: 010 | loss: 0.29440 - acc: 0.8896 -- iter: 0160/1386
[A[ATraining Step: 402  | total loss: [1m[32m0.31722[0m[0m | time: 7.533s
[2K
| Adam | epoch: 010 | loss: 0.31722 - acc: 0.8881 -- iter: 0192/1386
[A[ATraining Step: 403  | total loss: [1m[32m0.31105[0m[0m | time: 8.581s
[2K
| Adam | epoch: 010 | loss: 0.31105 - acc: 0.8868 -- iter: 0224/1386
[A[ATraining Step: 404  | total loss: [1m[32m0.30674[0m[0m | time: 8.903s
[2K
| Adam | epoch: 010 | loss: 0.30674 - acc: 0.8856 -- iter: 0256/1386
[A[ATraining Step: 405  | total loss: [1m[32m0.28971[0m[0m | time: 9.254s
[2K
| Adam | epoch: 010 | loss: 0.28971 - acc: 0.8970 -- iter: 0288/1386
[A[ATraining Step: 406  | total loss: [1m[32m0.27432[0m[0m | time: 10.045s
[2K
| Adam | epoch: 010 | loss: 0.27432 - acc: 0.9073 -- iter: 0320/1386
[A[ATraining Step: 407  | total loss: [1m[32m0.26945[0m[0m | time: 10.968s
[2K
| Adam | epoch: 010 | loss: 0.26945 - acc: 0.9041 -- iter: 0352/1386
[A[ATraining Step: 408  | total loss: [1m[32m0.27067[0m[0m | time: 11.877s
[2K
| Adam | epoch: 010 | loss: 0.27067 - acc: 0.9074 -- iter: 0384/1386
[A[ATraining Step: 409  | total loss: [1m[32m0.26086[0m[0m | time: 12.770s
[2K
| Adam | epoch: 010 | loss: 0.26086 - acc: 0.9136 -- iter: 0416/1386
[A[ATraining Step: 410  | total loss: [1m[32m0.26405[0m[0m | time: 13.762s
[2K
| Adam | epoch: 010 | loss: 0.26405 - acc: 0.9160 -- iter: 0448/1386
[A[ATraining Step: 411  | total loss: [1m[32m0.25812[0m[0m | time: 14.691s
[2K
| Adam | epoch: 010 | loss: 0.25812 - acc: 0.9181 -- iter: 0480/1386
[A[ATraining Step: 412  | total loss: [1m[32m0.26682[0m[0m | time: 15.474s
[2K
| Adam | epoch: 010 | loss: 0.26682 - acc: 0.9076 -- iter: 0512/1386
[A[ATraining Step: 413  | total loss: [1m[32m0.25891[0m[0m | time: 16.390s
[2K
| Adam | epoch: 010 | loss: 0.25891 - acc: 0.9074 -- iter: 0544/1386
[A[ATraining Step: 414  | total loss: [1m[32m0.28632[0m[0m | time: 17.386s
[2K
| Adam | epoch: 010 | loss: 0.28632 - acc: 0.8948 -- iter: 0576/1386
[A[ATraining Step: 415  | total loss: [1m[32m0.29186[0m[0m | time: 18.410s
[2K
| Adam | epoch: 010 | loss: 0.29186 - acc: 0.8928 -- iter: 0608/1386
[A[ATraining Step: 416  | total loss: [1m[32m0.28533[0m[0m | time: 19.163s
[2K
| Adam | epoch: 010 | loss: 0.28533 - acc: 0.8910 -- iter: 0640/1386
[A[ATraining Step: 417  | total loss: [1m[32m0.27641[0m[0m | time: 20.041s
[2K
| Adam | epoch: 010 | loss: 0.27641 - acc: 0.8926 -- iter: 0672/1386
[A[ATraining Step: 418  | total loss: [1m[32m0.40906[0m[0m | time: 20.915s
[2K
| Adam | epoch: 010 | loss: 0.40906 - acc: 0.8627 -- iter: 0704/1386
[A[ATraining Step: 419  | total loss: [1m[32m0.37604[0m[0m | time: 21.783s
[2K
| Adam | epoch: 010 | loss: 0.37604 - acc: 0.8764 -- iter: 0736/1386
[A[ATraining Step: 420  | total loss: [1m[32m0.35736[0m[0m | time: 22.675s
[2K
| Adam | epoch: 010 | loss: 0.35736 - acc: 0.8794 -- iter: 0768/1386
[A[ATraining Step: 421  | total loss: [1m[32m0.34216[0m[0m | time: 23.689s
[2K
| Adam | epoch: 010 | loss: 0.34216 - acc: 0.8852 -- iter: 0800/1386
[A[ATraining Step: 422  | total loss: [1m[32m0.33841[0m[0m | time: 24.648s
[2K
| Adam | epoch: 010 | loss: 0.33841 - acc: 0.8873 -- iter: 0832/1386
[A[ATraining Step: 423  | total loss: [1m[32m0.32906[0m[0m | time: 25.481s
[2K
| Adam | epoch: 010 | loss: 0.32906 - acc: 0.8892 -- iter: 0864/1386
[A[ATraining Step: 424  | total loss: [1m[32m0.31854[0m[0m | time: 26.447s
[2K
| Adam | epoch: 010 | loss: 0.31854 - acc: 0.8940 -- iter: 0896/1386
[A[ATraining Step: 425  | total loss: [1m[32m0.31194[0m[0m | time: 27.564s
[2K
| Adam | epoch: 010 | loss: 0.31194 - acc: 0.8953 -- iter: 0928/1386
[A[ATraining Step: 426  | total loss: [1m[32m0.30296[0m[0m | time: 28.438s
[2K
| Adam | epoch: 010 | loss: 0.30296 - acc: 0.8964 -- iter: 0960/1386
[A[ATraining Step: 427  | total loss: [1m[32m0.28720[0m[0m | time: 29.237s
[2K
| Adam | epoch: 010 | loss: 0.28720 - acc: 0.9036 -- iter: 0992/1386
[A[ATraining Step: 428  | total loss: [1m[32m0.27534[0m[0m | time: 30.137s
[2K
| Adam | epoch: 010 | loss: 0.27534 - acc: 0.9101 -- iter: 1024/1386
[A[ATraining Step: 429  | total loss: [1m[32m0.27062[0m[0m | time: 30.977s
[2K
| Adam | epoch: 010 | loss: 0.27062 - acc: 0.9066 -- iter: 1056/1386
[A[ATraining Step: 430  | total loss: [1m[32m0.26220[0m[0m | time: 31.837s
[2K
| Adam | epoch: 010 | loss: 0.26220 - acc: 0.9128 -- iter: 1088/1386
[A[ATraining Step: 431  | total loss: [1m[32m0.25846[0m[0m | time: 32.751s
[2K
| Adam | epoch: 010 | loss: 0.25846 - acc: 0.9090 -- iter: 1120/1386
[A[ATraining Step: 432  | total loss: [1m[32m0.26893[0m[0m | time: 33.718s
[2K
| Adam | epoch: 010 | loss: 0.26893 - acc: 0.9056 -- iter: 1152/1386
[A[ATraining Step: 433  | total loss: [1m[32m0.26875[0m[0m | time: 34.647s
[2K
| Adam | epoch: 010 | loss: 0.26875 - acc: 0.9057 -- iter: 1184/1386
[A[ATraining Step: 434  | total loss: [1m[32m0.25849[0m[0m | time: 35.509s
[2K
| Adam | epoch: 010 | loss: 0.25849 - acc: 0.9120 -- iter: 1216/1386
[A[ATraining Step: 435  | total loss: [1m[32m0.25005[0m[0m | time: 36.546s
[2K
| Adam | epoch: 010 | loss: 0.25005 - acc: 0.9177 -- iter: 1248/1386
[A[ATraining Step: 436  | total loss: [1m[32m0.23853[0m[0m | time: 37.570s
[2K
| Adam | epoch: 010 | loss: 0.23853 - acc: 0.9197 -- iter: 1280/1386
[A[ATraining Step: 437  | total loss: [1m[32m0.23372[0m[0m | time: 38.465s
[2K
| Adam | epoch: 010 | loss: 0.23372 - acc: 0.9152 -- iter: 1312/1386
[A[ATraining Step: 438  | total loss: [1m[32m0.21711[0m[0m | time: 39.242s
[2K
| Adam | epoch: 010 | loss: 0.21711 - acc: 0.9237 -- iter: 1344/1386
[A[ATraining Step: 439  | total loss: [1m[32m0.22895[0m[0m | time: 40.194s
[2K
| Adam | epoch: 010 | loss: 0.22895 - acc: 0.9219 -- iter: 1376/1386
[A[ATraining Step: 440  | total loss: [1m[32m0.22413[0m[0m | time: 43.031s
[2K
| Adam | epoch: 010 | loss: 0.22413 - acc: 0.9266 | val_loss: 0.30471 - val_acc: 0.8871 -- iter: 1386/1386
--
Training Step: 441  | total loss: [1m[32m0.23638[0m[0m | time: 0.961s
[2K
| Adam | epoch: 011 | loss: 0.23638 - acc: 0.9215 -- iter: 0032/1386
[A[ATraining Step: 442  | total loss: [1m[32m0.22649[0m[0m | time: 1.891s
[2K
| Adam | epoch: 011 | loss: 0.22649 - acc: 0.9231 -- iter: 0064/1386
[A[ATraining Step: 443  | total loss: [1m[32m0.23224[0m[0m | time: 2.776s
[2K
| Adam | epoch: 011 | loss: 0.23224 - acc: 0.9214 -- iter: 0096/1386
[A[ATraining Step: 444  | total loss: [1m[32m0.22654[0m[0m | time: 3.875s
[2K
| Adam | epoch: 011 | loss: 0.22654 - acc: 0.9230 -- iter: 0128/1386
[A[ATraining Step: 445  | total loss: [1m[32m0.22046[0m[0m | time: 4.884s
[2K
| Adam | epoch: 011 | loss: 0.22046 - acc: 0.9276 -- iter: 0160/1386
[A[ATraining Step: 446  | total loss: [1m[32m0.21328[0m[0m | time: 5.709s
[2K
| Adam | epoch: 011 | loss: 0.21328 - acc: 0.9317 -- iter: 0192/1386
[A[ATraining Step: 447  | total loss: [1m[32m0.20751[0m[0m | time: 6.555s
[2K
| Adam | epoch: 011 | loss: 0.20751 - acc: 0.9323 -- iter: 0224/1386
[A[ATraining Step: 448  | total loss: [1m[32m0.20974[0m[0m | time: 7.454s
[2K
| Adam | epoch: 011 | loss: 0.20974 - acc: 0.9265 -- iter: 0256/1386
[A[ATraining Step: 449  | total loss: [1m[32m0.20716[0m[0m | time: 7.769s
[2K
| Adam | epoch: 011 | loss: 0.20716 - acc: 0.9308 -- iter: 0288/1386
[A[ATraining Step: 450  | total loss: [1m[32m0.19330[0m[0m | time: 8.098s
[2K
| Adam | epoch: 011 | loss: 0.19330 - acc: 0.9377 -- iter: 0320/1386
[A[ATraining Step: 451  | total loss: [1m[32m0.17841[0m[0m | time: 9.048s
[2K
| Adam | epoch: 011 | loss: 0.17841 - acc: 0.9439 -- iter: 0352/1386
[A[ATraining Step: 452  | total loss: [1m[32m0.17760[0m[0m | time: 10.091s
[2K
| Adam | epoch: 011 | loss: 0.17760 - acc: 0.9433 -- iter: 0384/1386
[A[ATraining Step: 453  | total loss: [1m[32m0.17615[0m[0m | time: 11.125s
[2K
| Adam | epoch: 011 | loss: 0.17615 - acc: 0.9427 -- iter: 0416/1386
[A[ATraining Step: 454  | total loss: [1m[32m0.16946[0m[0m | time: 11.898s
[2K
| Adam | epoch: 011 | loss: 0.16946 - acc: 0.9453 -- iter: 0448/1386
[A[ATraining Step: 455  | total loss: [1m[32m0.17340[0m[0m | time: 12.963s
[2K
| Adam | epoch: 011 | loss: 0.17340 - acc: 0.9414 -- iter: 0480/1386
[A[ATraining Step: 456  | total loss: [1m[32m0.19617[0m[0m | time: 14.053s
[2K
| Adam | epoch: 011 | loss: 0.19617 - acc: 0.9348 -- iter: 0512/1386
[A[ATraining Step: 457  | total loss: [1m[32m0.21495[0m[0m | time: 14.955s
[2K
| Adam | epoch: 011 | loss: 0.21495 - acc: 0.9194 -- iter: 0544/1386
[A[ATraining Step: 458  | total loss: [1m[32m0.22614[0m[0m | time: 15.778s
[2K
| Adam | epoch: 011 | loss: 0.22614 - acc: 0.9150 -- iter: 0576/1386
[A[ATraining Step: 459  | total loss: [1m[32m0.21716[0m[0m | time: 16.788s
[2K
| Adam | epoch: 011 | loss: 0.21716 - acc: 0.9172 -- iter: 0608/1386
[A[ATraining Step: 460  | total loss: [1m[32m0.21653[0m[0m | time: 17.681s
[2K
| Adam | epoch: 011 | loss: 0.21653 - acc: 0.9161 -- iter: 0640/1386
[A[ATraining Step: 461  | total loss: [1m[32m0.20899[0m[0m | time: 18.552s
[2K
| Adam | epoch: 011 | loss: 0.20899 - acc: 0.9183 -- iter: 0672/1386
[A[ATraining Step: 462  | total loss: [1m[32m0.20737[0m[0m | time: 19.515s
[2K
| Adam | epoch: 011 | loss: 0.20737 - acc: 0.9139 -- iter: 0704/1386
[A[ATraining Step: 463  | total loss: [1m[32m0.21956[0m[0m | time: 20.484s
[2K
| Adam | epoch: 011 | loss: 0.21956 - acc: 0.9100 -- iter: 0736/1386
[A[ATraining Step: 464  | total loss: [1m[32m0.21459[0m[0m | time: 21.337s
[2K
| Adam | epoch: 011 | loss: 0.21459 - acc: 0.9128 -- iter: 0768/1386
[A[ATraining Step: 465  | total loss: [1m[32m0.20262[0m[0m | time: 22.323s
[2K
| Adam | epoch: 011 | loss: 0.20262 - acc: 0.9184 -- iter: 0800/1386
[A[ATraining Step: 466  | total loss: [1m[32m0.19489[0m[0m | time: 23.367s
[2K
| Adam | epoch: 011 | loss: 0.19489 - acc: 0.9234 -- iter: 0832/1386
[A[ATraining Step: 467  | total loss: [1m[32m0.18119[0m[0m | time: 24.352s
[2K
| Adam | epoch: 011 | loss: 0.18119 - acc: 0.9311 -- iter: 0864/1386
[A[ATraining Step: 468  | total loss: [1m[32m0.17057[0m[0m | time: 25.153s
[2K
| Adam | epoch: 011 | loss: 0.17057 - acc: 0.9348 -- iter: 0896/1386
[A[ATraining Step: 469  | total loss: [1m[32m0.18095[0m[0m | time: 26.058s
[2K
| Adam | epoch: 011 | loss: 0.18095 - acc: 0.9351 -- iter: 0928/1386
[A[ATraining Step: 470  | total loss: [1m[32m0.18869[0m[0m | time: 26.939s
[2K
| Adam | epoch: 011 | loss: 0.18869 - acc: 0.9291 -- iter: 0960/1386
[A[ATraining Step: 471  | total loss: [1m[32m0.17955[0m[0m | time: 27.834s
[2K
| Adam | epoch: 011 | loss: 0.17955 - acc: 0.9331 -- iter: 0992/1386
[A[ATraining Step: 472  | total loss: [1m[32m0.17411[0m[0m | time: 28.721s
[2K
| Adam | epoch: 011 | loss: 0.17411 - acc: 0.9335 -- iter: 1024/1386
[A[ATraining Step: 473  | total loss: [1m[32m0.19857[0m[0m | time: 29.681s
[2K
| Adam | epoch: 011 | loss: 0.19857 - acc: 0.9214 -- iter: 1056/1386
[A[ATraining Step: 474  | total loss: [1m[32m0.20055[0m[0m | time: 30.630s
[2K
| Adam | epoch: 011 | loss: 0.20055 - acc: 0.9199 -- iter: 1088/1386
[A[ATraining Step: 475  | total loss: [1m[32m0.19677[0m[0m | time: 31.421s
[2K
| Adam | epoch: 011 | loss: 0.19677 - acc: 0.9248 -- iter: 1120/1386
[A[ATraining Step: 476  | total loss: [1m[32m0.19391[0m[0m | time: 32.460s
[2K
| Adam | epoch: 011 | loss: 0.19391 - acc: 0.9260 -- iter: 1152/1386
[A[ATraining Step: 477  | total loss: [1m[32m0.18214[0m[0m | time: 33.518s
[2K
| Adam | epoch: 011 | loss: 0.18214 - acc: 0.9334 -- iter: 1184/1386
[A[ATraining Step: 478  | total loss: [1m[32m0.18678[0m[0m | time: 34.391s
[2K
| Adam | epoch: 011 | loss: 0.18678 - acc: 0.9276 -- iter: 1216/1386
[A[ATraining Step: 479  | total loss: [1m[32m0.18094[0m[0m | time: 35.281s
[2K
| Adam | epoch: 011 | loss: 0.18094 - acc: 0.9286 -- iter: 1248/1386
[A[ATraining Step: 480  | total loss: [1m[32m0.16921[0m[0m | time: 36.121s
[2K
| Adam | epoch: 011 | loss: 0.16921 - acc: 0.9326 -- iter: 1280/1386
[A[ATraining Step: 481  | total loss: [1m[32m0.18056[0m[0m | time: 37.012s
[2K
| Adam | epoch: 011 | loss: 0.18056 - acc: 0.9237 -- iter: 1312/1386
[A[ATraining Step: 482  | total loss: [1m[32m0.17814[0m[0m | time: 37.941s
[2K
| Adam | epoch: 011 | loss: 0.17814 - acc: 0.9220 -- iter: 1344/1386
[A[ATraining Step: 483  | total loss: [1m[32m0.17001[0m[0m | time: 38.864s
[2K
| Adam | epoch: 011 | loss: 0.17001 - acc: 0.9298 -- iter: 1376/1386
[A[ATraining Step: 484  | total loss: [1m[32m0.17494[0m[0m | time: 41.796s
[2K
| Adam | epoch: 011 | loss: 0.17494 - acc: 0.9305 | val_loss: 0.39357 - val_acc: 0.8410 -- iter: 1386/1386
--
Training Step: 485  | total loss: [1m[32m0.19865[0m[0m | time: 1.001s
[2K
| Adam | epoch: 012 | loss: 0.19865 - acc: 0.9219 -- iter: 0032/1386
[A[ATraining Step: 486  | total loss: [1m[32m0.18697[0m[0m | time: 2.066s
[2K
| Adam | epoch: 012 | loss: 0.18697 - acc: 0.9266 -- iter: 0064/1386
[A[ATraining Step: 487  | total loss: [1m[32m0.17655[0m[0m | time: 2.898s
[2K
| Adam | epoch: 012 | loss: 0.17655 - acc: 0.9339 -- iter: 0096/1386
[A[ATraining Step: 488  | total loss: [1m[32m0.16687[0m[0m | time: 3.771s
[2K
| Adam | epoch: 012 | loss: 0.16687 - acc: 0.9405 -- iter: 0128/1386
[A[ATraining Step: 489  | total loss: [1m[32m0.15754[0m[0m | time: 4.673s
[2K
| Adam | epoch: 012 | loss: 0.15754 - acc: 0.9465 -- iter: 0160/1386
[A[ATraining Step: 490  | total loss: [1m[32m0.15250[0m[0m | time: 5.558s
[2K
| Adam | epoch: 012 | loss: 0.15250 - acc: 0.9487 -- iter: 0192/1386
[A[ATraining Step: 491  | total loss: [1m[32m0.16736[0m[0m | time: 6.507s
[2K
| Adam | epoch: 012 | loss: 0.16736 - acc: 0.9413 -- iter: 0224/1386
[A[ATraining Step: 492  | total loss: [1m[32m0.16216[0m[0m | time: 7.485s
[2K
| Adam | epoch: 012 | loss: 0.16216 - acc: 0.9441 -- iter: 0256/1386
[A[ATraining Step: 493  | total loss: [1m[32m0.15877[0m[0m | time: 8.458s
[2K
| Adam | epoch: 012 | loss: 0.15877 - acc: 0.9465 -- iter: 0288/1386
[A[ATraining Step: 494  | total loss: [1m[32m0.16600[0m[0m | time: 8.749s
[2K
| Adam | epoch: 012 | loss: 0.16600 - acc: 0.9394 -- iter: 0320/1386
[A[ATraining Step: 495  | total loss: [1m[32m0.15241[0m[0m | time: 9.042s
[2K
| Adam | epoch: 012 | loss: 0.15241 - acc: 0.9454 -- iter: 0352/1386
[A[ATraining Step: 496  | total loss: [1m[32m0.13992[0m[0m | time: 10.012s
[2K
| Adam | epoch: 012 | loss: 0.13992 - acc: 0.9509 -- iter: 0384/1386
[A[ATraining Step: 497  | total loss: [1m[32m0.13304[0m[0m | time: 11.031s
[2K
| Adam | epoch: 012 | loss: 0.13304 - acc: 0.9558 -- iter: 0416/1386
[A[ATraining Step: 498  | total loss: [1m[32m0.13445[0m[0m | time: 12.005s
[2K
| Adam | epoch: 012 | loss: 0.13445 - acc: 0.9540 -- iter: 0448/1386
[A[ATraining Step: 499  | total loss: [1m[32m0.14387[0m[0m | time: 12.756s
[2K
| Adam | epoch: 012 | loss: 0.14387 - acc: 0.9523 -- iter: 0480/1386
[A[ATraining Step: 500  | total loss: [1m[32m0.14133[0m[0m | time: 13.653s
[2K
| Adam | epoch: 012 | loss: 0.14133 - acc: 0.9540 -- iter: 0512/1386
[A[ATraining Step: 501  | total loss: [1m[32m0.13023[0m[0m | time: 14.537s
[2K
| Adam | epoch: 012 | loss: 0.13023 - acc: 0.9586 -- iter: 0544/1386
[A[ATraining Step: 502  | total loss: [1m[32m0.13213[0m[0m | time: 15.401s
[2K
| Adam | epoch: 012 | loss: 0.13213 - acc: 0.9596 -- iter: 0576/1386
[A[ATraining Step: 503  | total loss: [1m[32m0.12607[0m[0m | time: 16.329s
[2K
| Adam | epoch: 012 | loss: 0.12607 - acc: 0.9605 -- iter: 0608/1386
[A[ATraining Step: 504  | total loss: [1m[32m0.13709[0m[0m | time: 17.302s
[2K
| Adam | epoch: 012 | loss: 0.13709 - acc: 0.9582 -- iter: 0640/1386
[A[ATraining Step: 505  | total loss: [1m[32m0.14442[0m[0m | time: 18.261s
[2K
| Adam | epoch: 012 | loss: 0.14442 - acc: 0.9561 -- iter: 0672/1386
[A[ATraining Step: 506  | total loss: [1m[32m0.14167[0m[0m | time: 19.068s
[2K
| Adam | epoch: 012 | loss: 0.14167 - acc: 0.9574 -- iter: 0704/1386
[A[ATraining Step: 507  | total loss: [1m[32m0.13535[0m[0m | time: 20.040s
[2K
| Adam | epoch: 012 | loss: 0.13535 - acc: 0.9585 -- iter: 0736/1386
[A[ATraining Step: 508  | total loss: [1m[32m0.14410[0m[0m | time: 21.047s
[2K
| Adam | epoch: 012 | loss: 0.14410 - acc: 0.9471 -- iter: 0768/1386
[A[ATraining Step: 509  | total loss: [1m[32m0.13762[0m[0m | time: 22.024s
[2K
| Adam | epoch: 012 | loss: 0.13762 - acc: 0.9492 -- iter: 0800/1386
[A[ATraining Step: 510  | total loss: [1m[32m0.12837[0m[0m | time: 22.994s
[2K
| Adam | epoch: 012 | loss: 0.12837 - acc: 0.9543 -- iter: 0832/1386
[A[ATraining Step: 511  | total loss: [1m[32m0.14666[0m[0m | time: 23.919s
[2K
| Adam | epoch: 012 | loss: 0.14666 - acc: 0.9526 -- iter: 0864/1386
[A[ATraining Step: 512  | total loss: [1m[32m0.14026[0m[0m | time: 24.886s
[2K
| Adam | epoch: 012 | loss: 0.14026 - acc: 0.9542 -- iter: 0896/1386
[A[ATraining Step: 513  | total loss: [1m[32m0.13277[0m[0m | time: 25.899s
[2K
| Adam | epoch: 012 | loss: 0.13277 - acc: 0.9588 -- iter: 0928/1386
[A[ATraining Step: 514  | total loss: [1m[32m0.12741[0m[0m | time: 26.851s
[2K
| Adam | epoch: 012 | loss: 0.12741 - acc: 0.9598 -- iter: 0960/1386
[A[ATraining Step: 515  | total loss: [1m[32m0.12784[0m[0m | time: 27.800s
[2K
| Adam | epoch: 012 | loss: 0.12784 - acc: 0.9576 -- iter: 0992/1386
[A[ATraining Step: 516  | total loss: [1m[32m0.11827[0m[0m | time: 28.720s
[2K
| Adam | epoch: 012 | loss: 0.11827 - acc: 0.9618 -- iter: 1024/1386
[A[ATraining Step: 517  | total loss: [1m[32m0.11146[0m[0m | time: 29.665s
[2K
| Adam | epoch: 012 | loss: 0.11146 - acc: 0.9625 -- iter: 1056/1386
[A[ATraining Step: 518  | total loss: [1m[32m0.11236[0m[0m | time: 30.674s
[2K
| Adam | epoch: 012 | loss: 0.11236 - acc: 0.9569 -- iter: 1088/1386
[A[ATraining Step: 519  | total loss: [1m[32m0.10957[0m[0m | time: 31.583s
[2K
| Adam | epoch: 012 | loss: 0.10957 - acc: 0.9612 -- iter: 1120/1386
[A[ATraining Step: 520  | total loss: [1m[32m0.10099[0m[0m | time: 32.569s
[2K
| Adam | epoch: 012 | loss: 0.10099 - acc: 0.9651 -- iter: 1152/1386
[A[ATraining Step: 521  | total loss: [1m[32m0.09869[0m[0m | time: 33.570s
[2K
| Adam | epoch: 012 | loss: 0.09869 - acc: 0.9654 -- iter: 1184/1386
[A[ATraining Step: 522  | total loss: [1m[32m0.11006[0m[0m | time: 34.522s
[2K
| Adam | epoch: 012 | loss: 0.11006 - acc: 0.9595 -- iter: 1216/1386
[A[ATraining Step: 523  | total loss: [1m[32m0.10254[0m[0m | time: 35.531s
[2K
| Adam | epoch: 012 | loss: 0.10254 - acc: 0.9636 -- iter: 1248/1386
[A[ATraining Step: 524  | total loss: [1m[32m0.09712[0m[0m | time: 36.532s
[2K
| Adam | epoch: 012 | loss: 0.09712 - acc: 0.9641 -- iter: 1280/1386
[A[ATraining Step: 525  | total loss: [1m[32m0.10075[0m[0m | time: 37.521s
[2K
| Adam | epoch: 012 | loss: 0.10075 - acc: 0.9614 -- iter: 1312/1386
[A[ATraining Step: 526  | total loss: [1m[32m0.10318[0m[0m | time: 38.529s
[2K
| Adam | epoch: 012 | loss: 0.10318 - acc: 0.9590 -- iter: 1344/1386
[A[ATraining Step: 527  | total loss: [1m[32m0.09705[0m[0m | time: 39.556s
[2K
| Adam | epoch: 012 | loss: 0.09705 - acc: 0.9631 -- iter: 1376/1386
[A[ATraining Step: 528  | total loss: [1m[32m0.09596[0m[0m | time: 42.607s
[2K
| Adam | epoch: 012 | loss: 0.09596 - acc: 0.9637 | val_loss: 0.47719 - val_acc: 0.8571 -- iter: 1386/1386
--
Training Step: 529  | total loss: [1m[32m0.09703[0m[0m | time: 0.922s
[2K
| Adam | epoch: 013 | loss: 0.09703 - acc: 0.9611 -- iter: 0032/1386
[A[ATraining Step: 530  | total loss: [1m[32m0.09770[0m[0m | time: 1.857s
[2K
| Adam | epoch: 013 | loss: 0.09770 - acc: 0.9618 -- iter: 0064/1386
[A[ATraining Step: 531  | total loss: [1m[32m0.09117[0m[0m | time: 2.802s
[2K
| Adam | epoch: 013 | loss: 0.09117 - acc: 0.9657 -- iter: 0096/1386
[A[ATraining Step: 532  | total loss: [1m[32m0.08654[0m[0m | time: 3.729s
[2K
| Adam | epoch: 013 | loss: 0.08654 - acc: 0.9691 -- iter: 0128/1386
[A[ATraining Step: 533  | total loss: [1m[32m0.09048[0m[0m | time: 4.679s
[2K
| Adam | epoch: 013 | loss: 0.09048 - acc: 0.9691 -- iter: 0160/1386
[A[ATraining Step: 534  | total loss: [1m[32m0.09147[0m[0m | time: 5.634s
[2K
| Adam | epoch: 013 | loss: 0.09147 - acc: 0.9690 -- iter: 0192/1386
[A[ATraining Step: 535  | total loss: [1m[32m0.12040[0m[0m | time: 6.595s
[2K
| Adam | epoch: 013 | loss: 0.12040 - acc: 0.9565 -- iter: 0224/1386
[A[ATraining Step: 536  | total loss: [1m[32m0.12116[0m[0m | time: 7.599s
[2K
| Adam | epoch: 013 | loss: 0.12116 - acc: 0.9577 -- iter: 0256/1386
[A[ATraining Step: 537  | total loss: [1m[32m0.12525[0m[0m | time: 8.556s
[2K
| Adam | epoch: 013 | loss: 0.12525 - acc: 0.9557 -- iter: 0288/1386
[A[ATraining Step: 538  | total loss: [1m[32m0.12053[0m[0m | time: 9.526s
[2K
| Adam | epoch: 013 | loss: 0.12053 - acc: 0.9570 -- iter: 0320/1386
[A[ATraining Step: 539  | total loss: [1m[32m0.12999[0m[0m | time: 9.886s
[2K
| Adam | epoch: 013 | loss: 0.12999 - acc: 0.9551 -- iter: 0352/1386
[A[ATraining Step: 540  | total loss: [1m[32m0.11995[0m[0m | time: 10.236s
[2K
| Adam | epoch: 013 | loss: 0.11995 - acc: 0.9596 -- iter: 0384/1386
[A[ATraining Step: 541  | total loss: [1m[32m0.11001[0m[0m | time: 11.200s
[2K
| Adam | epoch: 013 | loss: 0.11001 - acc: 0.9636 -- iter: 0416/1386
[A[ATraining Step: 542  | total loss: [1m[32m0.11458[0m[0m | time: 12.266s
[2K
| Adam | epoch: 013 | loss: 0.11458 - acc: 0.9610 -- iter: 0448/1386
[A[ATraining Step: 543  | total loss: [1m[32m0.11982[0m[0m | time: 13.264s
[2K
| Adam | epoch: 013 | loss: 0.11982 - acc: 0.9586 -- iter: 0480/1386
[A[ATraining Step: 544  | total loss: [1m[32m0.12413[0m[0m | time: 14.246s
[2K
| Adam | epoch: 013 | loss: 0.12413 - acc: 0.9565 -- iter: 0512/1386
[A[ATraining Step: 545  | total loss: [1m[32m0.11939[0m[0m | time: 15.199s
[2K
| Adam | epoch: 013 | loss: 0.11939 - acc: 0.9546 -- iter: 0544/1386
[A[ATraining Step: 546  | total loss: [1m[32m0.11740[0m[0m | time: 15.880s
[2K
| Adam | epoch: 013 | loss: 0.11740 - acc: 0.9560 -- iter: 0576/1386
[A[ATraining Step: 547  | total loss: [1m[32m0.12016[0m[0m | time: 16.499s
[2K
| Adam | epoch: 013 | loss: 0.12016 - acc: 0.9542 -- iter: 0608/1386
[A[ATraining Step: 548  | total loss: [1m[32m0.11105[0m[0m | time: 17.119s
[2K
| Adam | epoch: 013 | loss: 0.11105 - acc: 0.9588 -- iter: 0640/1386
[A[ATraining Step: 549  | total loss: [1m[32m0.11741[0m[0m | time: 17.758s
[2K
| Adam | epoch: 013 | loss: 0.11741 - acc: 0.9535 -- iter: 0672/1386
[A[ATraining Step: 550  | total loss: [1m[32m0.11515[0m[0m | time: 18.539s
[2K
| Adam | epoch: 013 | loss: 0.11515 - acc: 0.9582 -- iter: 0704/1386
[A[ATraining Step: 551  | total loss: [1m[32m0.11561[0m[0m | time: 19.317s
[2K
| Adam | epoch: 013 | loss: 0.11561 - acc: 0.9592 -- iter: 0736/1386
[A[ATraining Step: 552  | total loss: [1m[32m0.10653[0m[0m | time: 20.033s
[2K
| Adam | epoch: 013 | loss: 0.10653 - acc: 0.9633 -- iter: 0768/1386
[A[ATraining Step: 553  | total loss: [1m[32m0.09910[0m[0m | time: 20.683s
[2K
| Adam | epoch: 013 | loss: 0.09910 - acc: 0.9670 -- iter: 0800/1386
[A[ATraining Step: 554  | total loss: [1m[32m0.09138[0m[0m | time: 21.307s
[2K
| Adam | epoch: 013 | loss: 0.09138 - acc: 0.9703 -- iter: 0832/1386
[A[ATraining Step: 555  | total loss: [1m[32m0.08607[0m[0m | time: 21.906s
[2K
| Adam | epoch: 013 | loss: 0.08607 - acc: 0.9732 -- iter: 0864/1386
[A[ATraining Step: 556  | total loss: [1m[32m0.08511[0m[0m | time: 22.513s
[2K
| Adam | epoch: 013 | loss: 0.08511 - acc: 0.9728 -- iter: 0896/1386
[A[ATraining Step: 557  | total loss: [1m[32m0.08691[0m[0m | time: 23.118s
[2K
| Adam | epoch: 013 | loss: 0.08691 - acc: 0.9693 -- iter: 0928/1386
[A[ATraining Step: 558  | total loss: [1m[32m0.08436[0m[0m | time: 23.720s
[2K
| Adam | epoch: 013 | loss: 0.08436 - acc: 0.9692 -- iter: 0960/1386
[A[ATraining Step: 559  | total loss: [1m[32m0.08372[0m[0m | time: 24.330s
[2K
| Adam | epoch: 013 | loss: 0.08372 - acc: 0.9723 -- iter: 0992/1386
[A[ATraining Step: 560  | total loss: [1m[32m0.07804[0m[0m | time: 24.926s
[2K
| Adam | epoch: 013 | loss: 0.07804 - acc: 0.9751 -- iter: 1024/1386
[A[ATraining Step: 561  | total loss: [1m[32m0.07214[0m[0m | time: 25.544s
[2K
| Adam | epoch: 013 | loss: 0.07214 - acc: 0.9776 -- iter: 1056/1386
[A[ATraining Step: 562  | total loss: [1m[32m0.06656[0m[0m | time: 26.147s
[2K
| Adam | epoch: 013 | loss: 0.06656 - acc: 0.9798 -- iter: 1088/1386
[A[ATraining Step: 563  | total loss: [1m[32m0.06189[0m[0m | time: 26.759s
[2K
| Adam | epoch: 013 | loss: 0.06189 - acc: 0.9818 -- iter: 1120/1386
[A[ATraining Step: 564  | total loss: [1m[32m0.05713[0m[0m | time: 27.396s
[2K
| Adam | epoch: 013 | loss: 0.05713 - acc: 0.9836 -- iter: 1152/1386
[A[ATraining Step: 565  | total loss: [1m[32m0.06795[0m[0m | time: 28.014s
[2K
| Adam | epoch: 013 | loss: 0.06795 - acc: 0.9790 -- iter: 1184/1386
[A[ATraining Step: 566  | total loss: [1m[32m0.06261[0m[0m | time: 28.639s
[2K
| Adam | epoch: 013 | loss: 0.06261 - acc: 0.9811 -- iter: 1216/1386
[A[ATraining Step: 567  | total loss: [1m[32m0.05792[0m[0m | time: 29.258s
[2K
| Adam | epoch: 013 | loss: 0.05792 - acc: 0.9830 -- iter: 1248/1386
[A[ATraining Step: 568  | total loss: [1m[32m0.05744[0m[0m | time: 29.870s
[2K
| Adam | epoch: 013 | loss: 0.05744 - acc: 0.9816 -- iter: 1280/1386
[A[ATraining Step: 569  | total loss: [1m[32m0.05278[0m[0m | time: 30.459s
[2K
| Adam | epoch: 013 | loss: 0.05278 - acc: 0.9834 -- iter: 1312/1386
[A[ATraining Step: 570  | total loss: [1m[32m0.05035[0m[0m | time: 31.079s
[2K
| Adam | epoch: 013 | loss: 0.05035 - acc: 0.9851 -- iter: 1344/1386
[A[ATraining Step: 571  | total loss: [1m[32m0.07002[0m[0m | time: 31.697s
[2K
| Adam | epoch: 013 | loss: 0.07002 - acc: 0.9834 -- iter: 1376/1386
[A[ATraining Step: 572  | total loss: [1m[32m0.07837[0m[0m | time: 33.682s
[2K
| Adam | epoch: 013 | loss: 0.07837 - acc: 0.9789 | val_loss: 0.40992 - val_acc: 0.8802 -- iter: 1386/1386
--
Training Step: 573  | total loss: [1m[32m0.08546[0m[0m | time: 0.611s
[2K
| Adam | epoch: 014 | loss: 0.08546 - acc: 0.9747 -- iter: 0032/1386
[A[ATraining Step: 574  | total loss: [1m[32m0.07834[0m[0m | time: 1.233s
[2K
| Adam | epoch: 014 | loss: 0.07834 - acc: 0.9772 -- iter: 0064/1386
[A[ATraining Step: 575  | total loss: [1m[32m0.07305[0m[0m | time: 1.881s
[2K
| Adam | epoch: 014 | loss: 0.07305 - acc: 0.9795 -- iter: 0096/1386
[A[ATraining Step: 576  | total loss: [1m[32m0.06634[0m[0m | time: 2.494s
[2K
| Adam | epoch: 014 | loss: 0.06634 - acc: 0.9816 -- iter: 0128/1386
[A[ATraining Step: 577  | total loss: [1m[32m0.06711[0m[0m | time: 3.108s
[2K
| Adam | epoch: 014 | loss: 0.06711 - acc: 0.9803 -- iter: 0160/1386
[A[ATraining Step: 578  | total loss: [1m[32m0.06384[0m[0m | time: 3.723s
[2K
| Adam | epoch: 014 | loss: 0.06384 - acc: 0.9823 -- iter: 0192/1386
[A[ATraining Step: 579  | total loss: [1m[32m0.05945[0m[0m | time: 4.330s
[2K
| Adam | epoch: 014 | loss: 0.05945 - acc: 0.9840 -- iter: 0224/1386
[A[ATraining Step: 580  | total loss: [1m[32m0.05452[0m[0m | time: 4.939s
[2K
| Adam | epoch: 014 | loss: 0.05452 - acc: 0.9856 -- iter: 0256/1386
[A[ATraining Step: 581  | total loss: [1m[32m0.05203[0m[0m | time: 5.532s
[2K
| Adam | epoch: 014 | loss: 0.05203 - acc: 0.9871 -- iter: 0288/1386
[A[ATraining Step: 582  | total loss: [1m[32m0.04815[0m[0m | time: 6.138s
[2K
| Adam | epoch: 014 | loss: 0.04815 - acc: 0.9884 -- iter: 0320/1386
[A[ATraining Step: 583  | total loss: [1m[32m0.04629[0m[0m | time: 6.762s
[2K
| Adam | epoch: 014 | loss: 0.04629 - acc: 0.9895 -- iter: 0352/1386
[A[ATraining Step: 584  | total loss: [1m[32m0.05044[0m[0m | time: 6.975s
[2K
| Adam | epoch: 014 | loss: 0.05044 - acc: 0.9874 -- iter: 0384/1386
[A[ATraining Step: 585  | total loss: [1m[32m0.04762[0m[0m | time: 7.207s
[2K
| Adam | epoch: 014 | loss: 0.04762 - acc: 0.9887 -- iter: 0416/1386
[A[ATraining Step: 586  | total loss: [1m[32m0.04346[0m[0m | time: 8.293s
[2K
| Adam | epoch: 014 | loss: 0.04346 - acc: 0.9898 -- iter: 0448/1386
[A[ATraining Step: 587  | total loss: [1m[32m0.04079[0m[0m | time: 9.329s
[2K
| Adam | epoch: 014 | loss: 0.04079 - acc: 0.9908 -- iter: 0480/1386
[A[ATraining Step: 588  | total loss: [1m[32m0.03909[0m[0m | time: 10.263s
[2K
| Adam | epoch: 014 | loss: 0.03909 - acc: 0.9918 -- iter: 0512/1386
[A[ATraining Step: 589  | total loss: [1m[32m0.03742[0m[0m | time: 11.011s
[2K
| Adam | epoch: 014 | loss: 0.03742 - acc: 0.9926 -- iter: 0544/1386
[A[ATraining Step: 590  | total loss: [1m[32m0.03585[0m[0m | time: 11.855s
[2K
| Adam | epoch: 014 | loss: 0.03585 - acc: 0.9933 -- iter: 0576/1386
[A[ATraining Step: 591  | total loss: [1m[32m0.03671[0m[0m | time: 12.754s
[2K
| Adam | epoch: 014 | loss: 0.03671 - acc: 0.9909 -- iter: 0608/1386
[A[ATraining Step: 592  | total loss: [1m[32m0.03699[0m[0m | time: 13.633s
[2K
| Adam | epoch: 014 | loss: 0.03699 - acc: 0.9918 -- iter: 0640/1386
[A[ATraining Step: 593  | total loss: [1m[32m0.03843[0m[0m | time: 14.527s
[2K
| Adam | epoch: 014 | loss: 0.03843 - acc: 0.9926 -- iter: 0672/1386
[A[ATraining Step: 594  | total loss: [1m[32m0.03764[0m[0m | time: 15.505s
[2K
| Adam | epoch: 014 | loss: 0.03764 - acc: 0.9933 -- iter: 0704/1386
[A[ATraining Step: 595  | total loss: [1m[32m0.03565[0m[0m | time: 16.462s
[2K
| Adam | epoch: 014 | loss: 0.03565 - acc: 0.9940 -- iter: 0736/1386
[A[ATraining Step: 596  | total loss: [1m[32m0.03560[0m[0m | time: 17.316s
[2K
| Adam | epoch: 014 | loss: 0.03560 - acc: 0.9946 -- iter: 0768/1386
[A[ATraining Step: 597  | total loss: [1m[32m0.03323[0m[0m | time: 18.347s
[2K
| Adam | epoch: 014 | loss: 0.03323 - acc: 0.9951 -- iter: 0800/1386
[A[ATraining Step: 598  | total loss: [1m[32m0.05338[0m[0m | time: 19.390s
[2K
| Adam | epoch: 014 | loss: 0.05338 - acc: 0.9925 -- iter: 0832/1386
[A[ATraining Step: 599  | total loss: [1m[32m0.04828[0m[0m | time: 20.436s
[2K
| Adam | epoch: 014 | loss: 0.04828 - acc: 0.9933 -- iter: 0864/1386
[A[ATraining Step: 600  | total loss: [1m[32m0.04492[0m[0m | time: 23.032s
[2K
| Adam | epoch: 014 | loss: 0.04492 - acc: 0.9939 | val_loss: 0.40692 - val_acc: 0.8871 -- iter: 0896/1386
--
Training Step: 601  | total loss: [1m[32m0.04153[0m[0m | time: 23.920s
[2K
| Adam | epoch: 014 | loss: 0.04153 - acc: 0.9945 -- iter: 0928/1386
[A[ATraining Step: 602  | total loss: [1m[32m0.03883[0m[0m | time: 24.835s
[2K
| Adam | epoch: 014 | loss: 0.03883 - acc: 0.9951 -- iter: 0960/1386
[A[ATraining Step: 603  | total loss: [1m[32m0.03564[0m[0m | time: 25.820s
[2K
| Adam | epoch: 014 | loss: 0.03564 - acc: 0.9956 -- iter: 0992/1386
[A[ATraining Step: 604  | total loss: [1m[32m0.03291[0m[0m | time: 26.753s
[2K
| Adam | epoch: 014 | loss: 0.03291 - acc: 0.9960 -- iter: 1024/1386
[A[ATraining Step: 605  | total loss: [1m[32m0.03028[0m[0m | time: 27.597s
[2K
| Adam | epoch: 014 | loss: 0.03028 - acc: 0.9964 -- iter: 1056/1386
[A[ATraining Step: 606  | total loss: [1m[32m0.02802[0m[0m | time: 28.575s
[2K
| Adam | epoch: 014 | loss: 0.02802 - acc: 0.9968 -- iter: 1088/1386
[A[ATraining Step: 607  | total loss: [1m[32m0.02673[0m[0m | time: 29.611s
[2K
| Adam | epoch: 014 | loss: 0.02673 - acc: 0.9971 -- iter: 1120/1386
[A[ATraining Step: 608  | total loss: [1m[32m0.02484[0m[0m | time: 30.589s
[2K
| Adam | epoch: 014 | loss: 0.02484 - acc: 0.9974 -- iter: 1152/1386
[A[ATraining Step: 609  | total loss: [1m[32m0.02299[0m[0m | time: 31.423s
[2K
| Adam | epoch: 014 | loss: 0.02299 - acc: 0.9976 -- iter: 1184/1386
[A[ATraining Step: 610  | total loss: [1m[32m0.02233[0m[0m | time: 32.240s
[2K
| Adam | epoch: 014 | loss: 0.02233 - acc: 0.9979 -- iter: 1216/1386
[A[ATraining Step: 611  | total loss: [1m[32m0.02089[0m[0m | time: 33.094s
[2K
| Adam | epoch: 014 | loss: 0.02089 - acc: 0.9981 -- iter: 1248/1386
[A[ATraining Step: 612  | total loss: [1m[32m0.01953[0m[0m | time: 33.940s
[2K
| Adam | epoch: 014 | loss: 0.01953 - acc: 0.9983 -- iter: 1280/1386
[A[ATraining Step: 613  | total loss: [1m[32m0.01799[0m[0m | time: 34.824s
[2K
| Adam | epoch: 014 | loss: 0.01799 - acc: 0.9985 -- iter: 1312/1386
[A[ATraining Step: 614  | total loss: [1m[32m0.02065[0m[0m | time: 35.805s
[2K
| Adam | epoch: 014 | loss: 0.02065 - acc: 0.9955 -- iter: 1344/1386
[A[ATraining Step: 615  | total loss: [1m[32m0.02043[0m[0m | time: 36.776s
[2K
| Adam | epoch: 014 | loss: 0.02043 - acc: 0.9959 -- iter: 1376/1386
[A[ATraining Step: 616  | total loss: [1m[32m0.02784[0m[0m | time: 39.727s
[2K
| Adam | epoch: 014 | loss: 0.02784 - acc: 0.9932 | val_loss: 0.44301 - val_acc: 0.9009 -- iter: 1386/1386
--
Training Step: 617  | total loss: [1m[32m0.02719[0m[0m | time: 0.864s
[2K
| Adam | epoch: 015 | loss: 0.02719 - acc: 0.9939 -- iter: 0032/1386
[A[ATraining Step: 618  | total loss: [1m[32m0.02544[0m[0m | time: 1.740s
[2K
| Adam | epoch: 015 | loss: 0.02544 - acc: 0.9945 -- iter: 0064/1386
[A[ATraining Step: 619  | total loss: [1m[32m0.02710[0m[0m | time: 2.609s
[2K
| Adam | epoch: 015 | loss: 0.02710 - acc: 0.9919 -- iter: 0096/1386
[A[ATraining Step: 620  | total loss: [1m[32m0.02558[0m[0m | time: 3.514s
[2K
| Adam | epoch: 015 | loss: 0.02558 - acc: 0.9927 -- iter: 0128/1386
[A[ATraining Step: 621  | total loss: [1m[32m0.02377[0m[0m | time: 4.370s
[2K
| Adam | epoch: 015 | loss: 0.02377 - acc: 0.9935 -- iter: 0160/1386
[A[ATraining Step: 622  | total loss: [1m[32m0.02203[0m[0m | time: 5.315s
[2K
| Adam | epoch: 015 | loss: 0.02203 - acc: 0.9941 -- iter: 0192/1386
[A[ATraining Step: 623  | total loss: [1m[32m0.02289[0m[0m | time: 6.292s
[2K
| Adam | epoch: 015 | loss: 0.02289 - acc: 0.9947 -- iter: 0224/1386
[A[ATraining Step: 624  | total loss: [1m[32m0.02090[0m[0m | time: 7.188s
[2K
| Adam | epoch: 015 | loss: 0.02090 - acc: 0.9952 -- iter: 0256/1386
[A[ATraining Step: 625  | total loss: [1m[32m0.02045[0m[0m | time: 8.209s
[2K
| Adam | epoch: 015 | loss: 0.02045 - acc: 0.9957 -- iter: 0288/1386
[A[ATraining Step: 626  | total loss: [1m[32m0.01947[0m[0m | time: 9.200s
[2K
| Adam | epoch: 015 | loss: 0.01947 - acc: 0.9961 -- iter: 0320/1386
[A[ATraining Step: 627  | total loss: [1m[32m0.01939[0m[0m | time: 10.133s
[2K
| Adam | epoch: 015 | loss: 0.01939 - acc: 0.9965 -- iter: 0352/1386
[A[ATraining Step: 628  | total loss: [1m[32m0.01759[0m[0m | time: 10.945s
[2K
| Adam | epoch: 015 | loss: 0.01759 - acc: 0.9969 -- iter: 0384/1386
[A[ATraining Step: 629  | total loss: [1m[32m0.01701[0m[0m | time: 11.256s
[2K
| Adam | epoch: 015 | loss: 0.01701 - acc: 0.9972 -- iter: 0416/1386
[A[ATraining Step: 630  | total loss: [1m[32m0.01563[0m[0m | time: 11.592s
[2K
| Adam | epoch: 015 | loss: 0.01563 - acc: 0.9975 -- iter: 0448/1386
[A[ATraining Step: 631  | total loss: [1m[32m0.01437[0m[0m | time: 12.506s
[2K
| Adam | epoch: 015 | loss: 0.01437 - acc: 0.9977 -- iter: 0480/1386
[A[ATraining Step: 632  | total loss: [1m[32m0.01797[0m[0m | time: 13.416s
[2K
| Adam | epoch: 015 | loss: 0.01797 - acc: 0.9948 -- iter: 0512/1386
[A[ATraining Step: 633  | total loss: [1m[32m0.01635[0m[0m | time: 14.346s
[2K
| Adam | epoch: 015 | loss: 0.01635 - acc: 0.9953 -- iter: 0544/1386
[A[ATraining Step: 634  | total loss: [1m[32m0.01523[0m[0m | time: 15.330s
[2K
| Adam | epoch: 015 | loss: 0.01523 - acc: 0.9958 -- iter: 0576/1386
[A[ATraining Step: 635  | total loss: [1m[32m0.01841[0m[0m | time: 16.264s
[2K
| Adam | epoch: 015 | loss: 0.01841 - acc: 0.9931 -- iter: 0608/1386
[A[ATraining Step: 636  | total loss: [1m[32m0.01742[0m[0m | time: 17.104s
[2K
| Adam | epoch: 015 | loss: 0.01742 - acc: 0.9938 -- iter: 0640/1386
[A[ATraining Step: 637  | total loss: [1m[32m0.01867[0m[0m | time: 18.211s
[2K
| Adam | epoch: 015 | loss: 0.01867 - acc: 0.9944 -- iter: 0672/1386
[A[ATraining Step: 638  | total loss: [1m[32m0.01796[0m[0m | time: 19.240s
[2K
| Adam | epoch: 015 | loss: 0.01796 - acc: 0.9950 -- iter: 0704/1386
[A[ATraining Step: 639  | total loss: [1m[32m0.01639[0m[0m | time: 20.083s
[2K
| Adam | epoch: 015 | loss: 0.01639 - acc: 0.9955 -- iter: 0736/1386
[A[ATraining Step: 640  | total loss: [1m[32m0.01946[0m[0m | time: 20.902s
[2K
| Adam | epoch: 015 | loss: 0.01946 - acc: 0.9928 -- iter: 0768/1386
[A[ATraining Step: 641  | total loss: [1m[32m0.01890[0m[0m | time: 21.790s
[2K
| Adam | epoch: 015 | loss: 0.01890 - acc: 0.9935 -- iter: 0800/1386
[A[ATraining Step: 642  | total loss: [1m[32m0.01724[0m[0m | time: 22.670s
[2K
| Adam | epoch: 015 | loss: 0.01724 - acc: 0.9942 -- iter: 0832/1386
[A[ATraining Step: 643  | total loss: [1m[32m0.01599[0m[0m | time: 23.530s
[2K
| Adam | epoch: 015 | loss: 0.01599 - acc: 0.9948 -- iter: 0864/1386
[A[ATraining Step: 644  | total loss: [1m[32m0.01486[0m[0m | time: 24.493s
[2K
| Adam | epoch: 015 | loss: 0.01486 - acc: 0.9953 -- iter: 0896/1386
[A[ATraining Step: 645  | total loss: [1m[32m0.01360[0m[0m | time: 25.474s
[2K
| Adam | epoch: 015 | loss: 0.01360 - acc: 0.9957 -- iter: 0928/1386
[A[ATraining Step: 646  | total loss: [1m[32m0.01290[0m[0m | time: 26.340s
[2K
| Adam | epoch: 015 | loss: 0.01290 - acc: 0.9962 -- iter: 0960/1386
[A[ATraining Step: 647  | total loss: [1m[32m0.01199[0m[0m | time: 27.238s
[2K
| Adam | epoch: 015 | loss: 0.01199 - acc: 0.9966 -- iter: 0992/1386
[A[ATraining Step: 648  | total loss: [1m[32m0.01102[0m[0m | time: 28.259s
[2K
| Adam | epoch: 015 | loss: 0.01102 - acc: 0.9969 -- iter: 1024/1386
[A[ATraining Step: 649  | total loss: [1m[32m0.01019[0m[0m | time: 29.291s
[2K
| Adam | epoch: 015 | loss: 0.01019 - acc: 0.9972 -- iter: 1056/1386
[A[ATraining Step: 650  | total loss: [1m[32m0.01105[0m[0m | time: 30.116s
[2K
| Adam | epoch: 015 | loss: 0.01105 - acc: 0.9975 -- iter: 1088/1386
[A[ATraining Step: 651  | total loss: [1m[32m0.01012[0m[0m | time: 30.947s
[2K
| Adam | epoch: 015 | loss: 0.01012 - acc: 0.9977 -- iter: 1120/1386
[A[ATraining Step: 652  | total loss: [1m[32m0.00958[0m[0m | time: 31.836s
[2K
| Adam | epoch: 015 | loss: 0.00958 - acc: 0.9980 -- iter: 1152/1386
[A[ATraining Step: 653  | total loss: [1m[32m0.00890[0m[0m | time: 32.755s
[2K
| Adam | epoch: 015 | loss: 0.00890 - acc: 0.9982 -- iter: 1184/1386
[A[ATraining Step: 654  | total loss: [1m[32m0.00824[0m[0m | time: 33.642s
[2K
| Adam | epoch: 015 | loss: 0.00824 - acc: 0.9984 -- iter: 1216/1386
[A[ATraining Step: 655  | total loss: [1m[32m0.00765[0m[0m | time: 34.574s
[2K
| Adam | epoch: 015 | loss: 0.00765 - acc: 0.9985 -- iter: 1248/1386
[A[ATraining Step: 656  | total loss: [1m[32m0.00712[0m[0m | time: 35.513s
[2K
| Adam | epoch: 015 | loss: 0.00712 - acc: 0.9987 -- iter: 1280/1386
[A[ATraining Step: 657  | total loss: [1m[32m0.00791[0m[0m | time: 36.367s
[2K
| Adam | epoch: 015 | loss: 0.00791 - acc: 0.9988 -- iter: 1312/1386
[A[ATraining Step: 658  | total loss: [1m[32m0.00734[0m[0m | time: 37.355s
[2K
| Adam | epoch: 015 | loss: 0.00734 - acc: 0.9989 -- iter: 1344/1386
[A[ATraining Step: 659  | total loss: [1m[32m0.00770[0m[0m | time: 38.448s
[2K
| Adam | epoch: 015 | loss: 0.00770 - acc: 0.9990 -- iter: 1376/1386
[A[ATraining Step: 660  | total loss: [1m[32m0.00742[0m[0m | time: 41.110s
[2K
| Adam | epoch: 015 | loss: 0.00742 - acc: 0.9991 | val_loss: 0.55202 - val_acc: 0.8825 -- iter: 1386/1386
--
Validation AUC:0.9535630034216733
Validation AUPRC:0.9524482031706797
Test AUC:0.9536370393968354
Test AUPRC:0.9582544728682107
BestTestF1Score	0.88	0.78	0.89	0.92	0.85	183	16	203	32	0.99
BestTestMCCScore	0.88	0.78	0.89	0.92	0.85	183	16	203	32	0.99
BestTestAccuracyScore	0.88	0.78	0.89	0.92	0.85	183	16	203	32	0.99
BestValidationF1Score	0.91	0.83	0.91	0.93	0.9	189	15	208	22	0.99
BestValidationMCC	0.91	0.83	0.91	0.93	0.9	189	15	208	22	0.99
BestValidationAccuracy	0.91	0.83	0.91	0.93	0.9	189	15	208	22	0.99
TestPredictions (Threshold:0.99)
CHEMBL67109,TN,INACT,0.0	CHEMBL431172,TN,INACT,0.0	CHEMBL2370509,TN,INACT,0.0	CHEMBL101239,TN,INACT,0.0	CHEMBL128360,TN,INACT,0.0	CHEMBL312958,TN,INACT,0.0	CHEMBL64000,TN,INACT,0.9800000190734863	CHEMBL513955,TP,ACT,1.0	CHEMBL401745,FN,ACT,0.009999999776482582	CHEMBL143341,TN,INACT,0.0	CHEMBL192176,TP,ACT,1.0	CHEMBL104223,TN,INACT,0.0	CHEMBL123099,TN,INACT,0.7799999713897705	CHEMBL69943,FN,ACT,0.8600000143051147	CHEMBL2312346,TN,INACT,0.10000000149011612	CHEMBL114478,TN,INACT,0.0	CHEMBL2112307,TP,ACT,1.0	CHEMBL3234454,TN,INACT,0.0	CHEMBL285402,TP,ACT,1.0	CHEMBL191971,TP,ACT,1.0	CHEMBL393675,TN,INACT,0.05000000074505806	CHEMBL594802,TN,INACT,0.10000000149011612	CHEMBL519037,TP,ACT,1.0	CHEMBL414570,TN,INACT,0.0	CHEMBL2368256,TP,ACT,1.0	CHEMBL1788198,TP,ACT,1.0	CHEMBL425919,TP,ACT,1.0	CHEMBL386152,TN,INACT,0.0	CHEMBL421064,TP,ACT,1.0	CHEMBL187952,TP,ACT,1.0	CHEMBL424214,TN,INACT,0.8299999833106995	CHEMBL234448,TP,ACT,1.0	CHEMBL2113072,TN,INACT,0.009999999776482582	CHEMBL327103,TP,ACT,1.0	CHEMBL22960,FN,ACT,0.9700000286102295	CHEMBL282950,FN,ACT,0.0	CHEMBL156851,TN,INACT,0.0	CHEMBL196600,TP,ACT,1.0	CHEMBL324751,TP,ACT,1.0	CHEMBL2079546,FP,INACT,1.0	CHEMBL402473,TN,INACT,0.0	CHEMBL1631541,TP,ACT,1.0	CHEMBL63760,TN,INACT,0.05999999865889549	CHEMBL117579,TP,ACT,1.0	CHEMBL24781,TN,INACT,0.18000000715255737	CHEMBL166736,TN,INACT,0.009999999776482582	CHEMBL80945,TN,INACT,0.009999999776482582	CHEMBL348864,TP,ACT,1.0	CHEMBL89445,FP,INACT,0.9900000095367432	CHEMBL1548,FN,ACT,0.009999999776482582	CHEMBL187928,FN,ACT,0.0	CHEMBL121901,TP,ACT,1.0	CHEMBL2436720,TN,INACT,0.0	CHEMBL3770342,FN,ACT,0.0	CHEMBL81593,TN,INACT,0.0	CHEMBL343667,TP,ACT,1.0	CHEMBL50993,TN,INACT,0.0	CHEMBL60189,TN,INACT,0.0	CHEMBL64321,TN,INACT,0.0	CHEMBL139438,TP,ACT,1.0	CHEMBL76360,TN,INACT,0.0	CHEMBL123654,TN,INACT,0.0	CHEMBL1632212,TP,ACT,1.0	CHEMBL357034,TP,ACT,1.0	CHEMBL18928,TP,ACT,1.0	CHEMBL62948,TN,INACT,0.0	CHEMBL351036,TP,ACT,1.0	CHEMBL2093084,TN,INACT,0.029999999329447746	CHEMBL2368612,FN,ACT,0.8299999833106995	CHEMBL115750,TP,ACT,1.0	CHEMBL440961,TN,INACT,0.009999999776482582	CHEMBL60509,TN,INACT,0.0	CHEMBL314364,TN,INACT,0.0	CHEMBL279520,TN,INACT,0.009999999776482582	CHEMBL319910,TN,INACT,0.0	CHEMBL353304,TN,INACT,0.8899999856948853	CHEMBL297660,TP,ACT,1.0	CHEMBL3734955,TN,INACT,0.0	CHEMBL300686,TP,ACT,1.0	CHEMBL527880,TN,INACT,0.0	CHEMBL149592,TN,INACT,0.0	CHEMBL2021524,TP,ACT,1.0	CHEMBL162722,TP,ACT,1.0	CHEMBL64727,TN,INACT,0.03999999910593033	CHEMBL199175,TP,ACT,1.0	CHEMBL22961,TP,ACT,1.0	CHEMBL47404,TN,INACT,0.0	CHEMBL434,TN,INACT,0.9800000190734863	CHEMBL147148,TP,ACT,1.0	CHEMBL1744040,TP,ACT,1.0	CHEMBL495160,TP,ACT,1.0	CHEMBL88893,TP,ACT,1.0	CHEMBL62527,TN,INACT,0.0	CHEMBL42359,TN,INACT,0.0	CHEMBL146024,TP,ACT,1.0	CHEMBL143304,TN,INACT,0.0	CHEMBL514965,TN,INACT,0.0	CHEMBL3143394,TN,INACT,0.0	CHEMBL326723,TP,ACT,1.0	CHEMBL1910139,TP,ACT,1.0	CHEMBL2324200,TN,INACT,0.019999999552965164	CHEMBL149263,TP,ACT,1.0	CHEMBL190,TN,INACT,0.0	CHEMBL349528,TP,ACT,1.0	CHEMBL79915,TN,INACT,0.0	CHEMBL329207,TP,ACT,1.0	CHEMBL1076554,TN,INACT,0.0	CHEMBL83112,TP,ACT,1.0	CHEMBL302829,TN,INACT,0.0	CHEMBL170335,FP,INACT,1.0	CHEMBL334159,TP,ACT,1.0	CHEMBL603858,TN,INACT,0.8600000143051147	CHEMBL57908,TN,INACT,0.0	CHEMBL1279,TP,ACT,1.0	CHEMBL70985,FN,ACT,0.8299999833106995	CHEMBL443060,TP,ACT,1.0	CHEMBL65669,TN,INACT,0.0	CHEMBL541993,TP,ACT,1.0	CHEMBL606547,TP,ACT,1.0	CHEMBL422192,TP,ACT,1.0	CHEMBL71635,TP,ACT,1.0	CHEMBL125925,TN,INACT,0.09000000357627869	CHEMBL3290994,FP,INACT,0.9900000095367432	CHEMBL1765671,TN,INACT,0.0	CHEMBL369359,TN,INACT,0.17000000178813934	CHEMBL67367,TP,ACT,1.0	CHEMBL441259,TP,ACT,1.0	CHEMBL358406,TP,ACT,0.9900000095367432	CHEMBL65824,TP,ACT,1.0	CHEMBL197947,TP,ACT,1.0	CHEMBL104848,TN,INACT,0.0	CHEMBL2367888,TN,INACT,0.0	CHEMBL417215,TN,INACT,0.0	CHEMBL75358,TN,INACT,0.7599999904632568	CHEMBL161970,TP,ACT,1.0	CHEMBL302468,TN,INACT,0.0	CHEMBL28437,TP,ACT,1.0	CHEMBL105118,TP,ACT,1.0	CHEMBL399719,TP,ACT,1.0	CHEMBL274001,TP,ACT,1.0	CHEMBL420748,TP,ACT,1.0	CHEMBL3764335,FN,ACT,0.09000000357627869	CHEMBL316247,TN,INACT,0.0	CHEMBL100086,TP,ACT,1.0	CHEMBL417550,FP,INACT,1.0	CHEMBL210457,FP,INACT,1.0	CHEMBL2058429,FN,ACT,0.9399999976158142	CHEMBL48024,FP,INACT,1.0	CHEMBL100624,TN,INACT,0.0	CHEMBL451335,TN,INACT,0.019999999552965164	CHEMBL83732,TP,ACT,1.0	CHEMBL83426,TP,ACT,1.0	CHEMBL135878,TP,ACT,1.0	CHEMBL31781,TN,INACT,0.029999999329447746	CHEMBL3403334,TN,INACT,0.0	CHEMBL2110300,TP,ACT,1.0	CHEMBL291394,TN,INACT,0.0	CHEMBL444307,TN,INACT,0.0	CHEMBL541424,TN,INACT,0.05999999865889549	CHEMBL162011,TP,ACT,1.0	CHEMBL116161,TP,ACT,1.0	CHEMBL1983100,TN,INACT,0.14000000059604645	CHEMBL160581,TP,ACT,1.0	CHEMBL78830,TN,INACT,0.019999999552965164	CHEMBL45160,TN,INACT,0.9800000190734863	CHEMBL352925,TN,INACT,0.0	CHEMBL359141,TN,INACT,0.0	CHEMBL2436721,TN,INACT,0.09000000357627869	CHEMBL148087,TP,ACT,1.0	CHEMBL44054,FN,ACT,0.949999988079071	CHEMBL404557,TN,INACT,0.0	CHEMBL272853,TN,INACT,0.6700000166893005	CHEMBL349185,TP,ACT,0.9900000095367432	CHEMBL258075,FN,ACT,0.1599999964237213	CHEMBL148110,TP,ACT,1.0	CHEMBL71176,TP,ACT,1.0	CHEMBL162899,TP,ACT,1.0	CHEMBL42799,TN,INACT,0.0	CHEMBL452150,TN,INACT,0.6899999976158142	CHEMBL321967,TP,ACT,1.0	CHEMBL88152,TP,ACT,1.0	CHEMBL79030,TN,INACT,0.009999999776482582	CHEMBL197169,TP,ACT,1.0	CHEMBL2436555,FN,ACT,0.05000000074505806	CHEMBL308087,TN,INACT,0.0	CHEMBL412876,TP,ACT,1.0	CHEMBL444843,TP,ACT,1.0	CHEMBL91534,TP,ACT,1.0	CHEMBL193268,TP,ACT,1.0	CHEMBL416019,TN,INACT,0.0	CHEMBL63167,TP,ACT,1.0	CHEMBL108337,FN,ACT,0.18000000715255737	CHEMBL190190,TP,ACT,1.0	CHEMBL117046,TP,ACT,1.0	CHEMBL535602,TN,INACT,0.9399999976158142	CHEMBL494093,TN,INACT,0.0	CHEMBL1091790,TN,INACT,0.05999999865889549	CHEMBL323986,TP,ACT,1.0	CHEMBL297215,TN,INACT,0.0	CHEMBL101690,TP,ACT,1.0	CHEMBL537834,TN,INACT,0.0	CHEMBL441305,TN,INACT,0.009999999776482582	CHEMBL90443,TP,ACT,1.0	CHEMBL2436717,TN,INACT,0.009999999776482582	CHEMBL422243,TP,ACT,1.0	CHEMBL2062854,TN,INACT,0.0	CHEMBL319036,TN,INACT,0.0	CHEMBL147838,TP,ACT,1.0	CHEMBL2114039,TP,ACT,1.0	CHEMBL2443002,TN,INACT,0.18000000715255737	CHEMBL400190,TN,INACT,0.0	CHEMBL288967,TN,INACT,0.0	CHEMBL514606,TN,INACT,0.009999999776482582	CHEMBL425190,TP,ACT,1.0	CHEMBL332063,TP,ACT,1.0	CHEMBL102250,TP,ACT,1.0	CHEMBL10801,TN,INACT,0.0	CHEMBL148194,TP,ACT,1.0	CHEMBL506888,TN,INACT,0.0	CHEMBL273921,TP,ACT,1.0	CHEMBL223686,TN,INACT,0.0	CHEMBL1258452,FN,ACT,0.0	CHEMBL438915,TN,INACT,0.0	CHEMBL267014,TN,INACT,0.019999999552965164	CHEMBL65321,TP,ACT,1.0	CHEMBL351311,TP,ACT,1.0	CHEMBL2163920,TN,INACT,0.0	CHEMBL505750,TP,ACT,1.0	CHEMBL114877,TP,ACT,1.0	CHEMBL54125,TN,INACT,0.0	CHEMBL194701,TP,ACT,0.9900000095367432	CHEMBL2042403,TN,INACT,0.8799999952316284	CHEMBL593443,TN,INACT,0.009999999776482582	CHEMBL1632218,TP,ACT,1.0	CHEMBL556506,TN,INACT,0.0	CHEMBL828,TN,INACT,0.3499999940395355	CHEMBL418823,FN,ACT,0.9800000190734863	CHEMBL294849,TN,INACT,0.5	CHEMBL495705,TP,ACT,1.0	CHEMBL3604302,TN,INACT,0.0	CHEMBL146285,TP,ACT,1.0	CHEMBL3393993,TN,INACT,0.0	CHEMBL314616,TN,INACT,0.23000000417232513	CHEMBL146891,TP,ACT,1.0	CHEMBL234447,TP,ACT,1.0	CHEMBL88937,TN,INACT,0.07999999821186066	CHEMBL316589,FP,INACT,0.9900000095367432	CHEMBL357983,TN,INACT,0.0	CHEMBL484260,TP,ACT,1.0	CHEMBL414165,TN,INACT,0.0	CHEMBL393971,TN,INACT,0.0	CHEMBL1631542,TP,ACT,1.0	CHEMBL294649,TN,INACT,0.14000000059604645	CHEMBL2436819,TN,INACT,0.0	CHEMBL302373,FN,ACT,0.8999999761581421	CHEMBL456675,FP,INACT,1.0	CHEMBL25800,FN,ACT,0.33000001311302185	CHEMBL146023,TP,ACT,1.0	CHEMBL484742,TP,ACT,1.0	CHEMBL173059,FP,INACT,1.0	CHEMBL151045,FN,ACT,0.029999999329447746	CHEMBL195897,TP,ACT,1.0	CHEMBL161694,TP,ACT,1.0	CHEMBL42586,TN,INACT,0.0	CHEMBL495854,TN,INACT,0.0	CHEMBL84305,TP,ACT,1.0	CHEMBL76933,TN,INACT,0.0	CHEMBL64124,TN,INACT,0.0	CHEMBL319231,TN,INACT,0.0	CHEMBL162930,TP,ACT,1.0	CHEMBL304008,FN,ACT,0.47999998927116394	CHEMBL159278,TP,ACT,1.0	CHEMBL3290986,FP,INACT,1.0	CHEMBL312266,TN,INACT,0.0	CHEMBL42360,TN,INACT,0.0	CHEMBL331241,FN,ACT,0.05999999865889549	CHEMBL72172,TN,INACT,0.0	CHEMBL92139,FN,ACT,0.7799999713897705	CHEMBL320254,TN,INACT,0.0	CHEMBL160396,TN,INACT,0.009999999776482582	CHEMBL456458,TP,ACT,1.0	CHEMBL142629,TP,ACT,1.0	CHEMBL393539,TP,ACT,1.0	CHEMBL3604310,TN,INACT,0.009999999776482582	CHEMBL104210,TN,INACT,0.009999999776482582	CHEMBL323517,TN,INACT,0.0	CHEMBL2260933,FN,ACT,0.47999998927116394	CHEMBL421523,TN,INACT,0.009999999776482582	CHEMBL146735,TP,ACT,1.0	CHEMBL303386,TN,INACT,0.0	CHEMBL197408,TP,ACT,1.0	CHEMBL302196,TN,INACT,0.0	CHEMBL121207,TP,ACT,1.0	CHEMBL91123,TP,ACT,1.0	CHEMBL247428,TP,ACT,1.0	CHEMBL3114145,TN,INACT,0.0	CHEMBL80180,TN,INACT,0.05999999865889549	CHEMBL146976,TP,ACT,1.0	CHEMBL269576,TN,INACT,0.25999999046325684	CHEMBL76576,TN,INACT,0.0	CHEMBL321080,TP,ACT,1.0	CHEMBL114074,TN,INACT,0.0	CHEMBL71640,FN,ACT,0.14000000059604645	CHEMBL459282,TP,ACT,1.0	CHEMBL284311,FP,INACT,1.0	CHEMBL1185,TP,ACT,1.0	CHEMBL80438,TN,INACT,0.0	CHEMBL377542,TN,INACT,0.0	CHEMBL162012,TP,ACT,1.0	CHEMBL1290716,TP,ACT,1.0	CHEMBL62716,TN,INACT,0.0	CHEMBL1093044,TN,INACT,0.0	CHEMBL312670,TN,INACT,0.0	CHEMBL151825,FN,ACT,0.2800000011920929	CHEMBL31524,TN,INACT,0.0	CHEMBL3290984,FP,INACT,1.0	CHEMBL297139,FP,INACT,1.0	CHEMBL3218123,TN,INACT,0.0	CHEMBL161723,TP,ACT,1.0	CHEMBL28313,TP,ACT,0.9900000095367432	CHEMBL146729,TP,ACT,1.0	CHEMBL62601,TN,INACT,0.09000000357627869	CHEMBL342330,TP,ACT,1.0	CHEMBL1085672,FN,ACT,0.05000000074505806	CHEMBL519010,TP,ACT,1.0	CHEMBL104692,TP,ACT,1.0	CHEMBL41844,TP,ACT,1.0	CHEMBL159627,TP,ACT,1.0	CHEMBL116031,TP,ACT,1.0	CHEMBL99331,TN,INACT,0.0	CHEMBL3586317,TN,INACT,0.11999999731779099	CHEMBL98965,TP,ACT,1.0	CHEMBL3633665,TN,INACT,0.0	CHEMBL71726,TN,INACT,0.0	CHEMBL40796,TN,INACT,0.3799999952316284	CHEMBL462650,TN,INACT,0.07000000029802322	CHEMBL326667,TP,ACT,1.0	CHEMBL475497,TN,INACT,0.03999999910593033	CHEMBL74066,TN,INACT,0.14000000059604645	CHEMBL107680,TN,INACT,0.0	CHEMBL542877,TN,INACT,0.0	CHEMBL167335,TN,INACT,0.009999999776482582	CHEMBL355517,TP,ACT,1.0	CHEMBL312268,TN,INACT,0.0	CHEMBL422411,TN,INACT,0.0	CHEMBL106359,TN,INACT,0.0	CHEMBL53662,TN,INACT,0.0	CHEMBL79725,TP,ACT,1.0	CHEMBL1910141,FN,ACT,0.8500000238418579	CHEMBL328285,TN,INACT,0.0	CHEMBL63289,TN,INACT,0.0	CHEMBL523095,TP,ACT,1.0	CHEMBL184994,TP,ACT,1.0	CHEMBL491839,TP,ACT,1.0	CHEMBL1762308,TN,INACT,0.0	CHEMBL196666,TP,ACT,1.0	CHEMBL311694,TP,ACT,1.0	CHEMBL441256,TP,ACT,1.0	CHEMBL497963,TP,ACT,1.0	CHEMBL73096,TN,INACT,0.019999999552965164	CHEMBL404248,FN,ACT,0.009999999776482582	CHEMBL357061,FN,ACT,0.9700000286102295	CHEMBL51,FN,ACT,0.0	CHEMBL3752900,TP,ACT,1.0	CHEMBL117397,TP,ACT,1.0	CHEMBL557840,TN,INACT,0.0	CHEMBL80189,TP,ACT,1.0	CHEMBL432897,TN,INACT,0.0	CHEMBL404372,TP,ACT,0.9900000095367432	CHEMBL191980,TP,ACT,1.0	CHEMBL64235,TN,INACT,0.0	CHEMBL241082,FP,INACT,1.0	CHEMBL71033,TP,ACT,1.0	CHEMBL173708,TN,INACT,0.0	CHEMBL191921,TP,ACT,1.0	CHEMBL3633650,TN,INACT,0.0	CHEMBL349041,TP,ACT,0.9900000095367432	CHEMBL294087,TN,INACT,0.0	CHEMBL344154,TN,INACT,0.0	CHEMBL356829,TP,ACT,1.0	CHEMBL162724,TP,ACT,1.0	CHEMBL1263,TN,INACT,0.0	CHEMBL141706,TP,ACT,1.0	CHEMBL106483,TN,INACT,0.0	CHEMBL175698,TN,INACT,0.0	CHEMBL77962,TN,INACT,0.0	CHEMBL275854,TP,ACT,1.0	CHEMBL264027,TN,INACT,0.019999999552965164	CHEMBL196848,TP,ACT,1.0	CHEMBL111283,TP,ACT,1.0	CHEMBL78601,TN,INACT,0.0	CHEMBL320577,TN,INACT,0.9700000286102295	CHEMBL331394,TN,INACT,0.0	CHEMBL70431,TP,ACT,1.0	CHEMBL91596,TP,ACT,1.0	CHEMBL7505,TN,INACT,0.07000000029802322	CHEMBL72738,TN,INACT,0.0	CHEMBL148095,TP,ACT,1.0	CHEMBL320804,TN,INACT,0.0	CHEMBL233957,TN,INACT,0.14000000059604645	CHEMBL400404,TN,INACT,0.09000000357627869	CHEMBL349505,TN,INACT,0.0	CHEMBL322537,TN,INACT,0.0	CHEMBL429136,TP,ACT,1.0	CHEMBL241503,TP,ACT,1.0	CHEMBL246597,TP,ACT,1.0	CHEMBL354126,TN,INACT,0.0	CHEMBL1631544,TP,ACT,1.0	CHEMBL65413,TN,INACT,0.0	CHEMBL105483,TN,INACT,0.0	CHEMBL83617,TP,ACT,1.0	CHEMBL85668,TP,ACT,1.0	CHEMBL536800,FP,INACT,1.0	CHEMBL444341,TP,ACT,1.0	CHEMBL294732,TP,ACT,1.0	CHEMBL311455,TN,INACT,0.0	CHEMBL44134,TN,INACT,0.0	CHEMBL307034,TN,INACT,0.0	CHEMBL161176,TP,ACT,1.0	CHEMBL267094,TN,INACT,0.0	CHEMBL344866,TN,INACT,0.0	CHEMBL146628,TP,ACT,1.0	CHEMBL2111789,TN,INACT,0.0	CHEMBL143951,TP,ACT,1.0	CHEMBL197796,TP,ACT,1.0	CHEMBL95104,FN,ACT,0.0	CHEMBL82523,TP,ACT,1.0	CHEMBL424154,TP,ACT,1.0	CHEMBL142324,TN,INACT,0.009999999776482582	CHEMBL2079597,TN,INACT,0.9800000190734863	CHEMBL105556,TP,ACT,1.0	CHEMBL198488,TP,ACT,1.0	CHEMBL137781,TP,ACT,1.0	CHEMBL352181,TP,ACT,1.0	

