CNNModel CHEMBL257 adam 0.0005 15 32 0 0.8 False True
Number of active compounds :	501
Number of inactive compounds :	501
---------------------------------
Run id: CNNModel_CHEMBL257_adam_0.0005_15_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL257_adam_0.0005_15_32_0.8_True/
---------------------------------
Training samples: 608
Validation samples: 191
--
Training Step: 1  | time: 1.110s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/608
[A[ATraining Step: 2  | total loss: [1m[32m0.62387[0m[0m | time: 2.018s
[2K
| Adam | epoch: 001 | loss: 0.62387 - acc: 0.4781 -- iter: 064/608
[A[ATraining Step: 3  | total loss: [1m[32m0.68158[0m[0m | time: 2.898s
[2K
| Adam | epoch: 001 | loss: 0.68158 - acc: 0.4193 -- iter: 096/608
[A[ATraining Step: 4  | total loss: [1m[32m0.69032[0m[0m | time: 3.748s
[2K
| Adam | epoch: 001 | loss: 0.69032 - acc: 0.4564 -- iter: 128/608
[A[ATraining Step: 5  | total loss: [1m[32m0.69216[0m[0m | time: 4.644s
[2K
| Adam | epoch: 001 | loss: 0.69216 - acc: 0.5082 -- iter: 160/608
[A[ATraining Step: 6  | total loss: [1m[32m0.69277[0m[0m | time: 5.635s
[2K
| Adam | epoch: 001 | loss: 0.69277 - acc: 0.5029 -- iter: 192/608
[A[ATraining Step: 7  | total loss: [1m[32m0.69282[0m[0m | time: 6.377s
[2K
| Adam | epoch: 001 | loss: 0.69282 - acc: 0.5199 -- iter: 224/608
[A[ATraining Step: 8  | total loss: [1m[32m0.69234[0m[0m | time: 7.187s
[2K
| Adam | epoch: 001 | loss: 0.69234 - acc: 0.5439 -- iter: 256/608
[A[ATraining Step: 9  | total loss: [1m[32m0.69391[0m[0m | time: 7.983s
[2K
| Adam | epoch: 001 | loss: 0.69391 - acc: 0.4876 -- iter: 288/608
[A[ATraining Step: 10  | total loss: [1m[32m0.69317[0m[0m | time: 8.917s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.4938 -- iter: 320/608
[A[ATraining Step: 11  | total loss: [1m[32m0.69188[0m[0m | time: 9.667s
[2K
| Adam | epoch: 001 | loss: 0.69188 - acc: 0.5263 -- iter: 352/608
[A[ATraining Step: 12  | total loss: [1m[32m0.69275[0m[0m | time: 10.438s
[2K
| Adam | epoch: 001 | loss: 0.69275 - acc: 0.5004 -- iter: 384/608
[A[ATraining Step: 13  | total loss: [1m[32m0.69129[0m[0m | time: 11.194s
[2K
| Adam | epoch: 001 | loss: 0.69129 - acc: 0.5270 -- iter: 416/608
[A[ATraining Step: 14  | total loss: [1m[32m0.69560[0m[0m | time: 11.949s
[2K
| Adam | epoch: 001 | loss: 0.69560 - acc: 0.4776 -- iter: 448/608
[A[ATraining Step: 15  | total loss: [1m[32m0.69569[0m[0m | time: 12.766s
[2K
| Adam | epoch: 001 | loss: 0.69569 - acc: 0.4741 -- iter: 480/608
[A[ATraining Step: 16  | total loss: [1m[32m0.69458[0m[0m | time: 13.504s
[2K
| Adam | epoch: 001 | loss: 0.69458 - acc: 0.4838 -- iter: 512/608
[A[ATraining Step: 17  | total loss: [1m[32m0.69585[0m[0m | time: 14.285s
[2K
| Adam | epoch: 001 | loss: 0.69585 - acc: 0.4447 -- iter: 544/608
[A[ATraining Step: 18  | total loss: [1m[32m0.69457[0m[0m | time: 15.110s
[2K
| Adam | epoch: 001 | loss: 0.69457 - acc: 0.4746 -- iter: 576/608
[A[ATraining Step: 19  | total loss: [1m[32m0.69345[0m[0m | time: 16.745s
[2K
| Adam | epoch: 001 | loss: 0.69345 - acc: 0.5248 | val_loss: 0.69298 - val_acc: 0.5026 -- iter: 608/608
--
Training Step: 20  | total loss: [1m[32m0.69306[0m[0m | time: 0.786s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5469 -- iter: 032/608
[A[ATraining Step: 21  | total loss: [1m[32m0.69272[0m[0m | time: 1.675s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5615 -- iter: 064/608
[A[ATraining Step: 22  | total loss: [1m[32m0.69309[0m[0m | time: 3.434s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5243 -- iter: 096/608
[A[ATraining Step: 23  | total loss: [1m[32m0.69237[0m[0m | time: 4.777s
[2K
| Adam | epoch: 002 | loss: 0.69237 - acc: 0.5535 -- iter: 128/608
[A[ATraining Step: 24  | total loss: [1m[32m0.69355[0m[0m | time: 6.115s
[2K
| Adam | epoch: 002 | loss: 0.69355 - acc: 0.4945 -- iter: 160/608
[A[ATraining Step: 25  | total loss: [1m[32m0.69364[0m[0m | time: 7.641s
[2K
| Adam | epoch: 002 | loss: 0.69364 - acc: 0.4790 -- iter: 192/608
[A[ATraining Step: 26  | total loss: [1m[32m0.69296[0m[0m | time: 8.981s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5176 -- iter: 224/608
[A[ATraining Step: 27  | total loss: [1m[32m0.69213[0m[0m | time: 10.462s
[2K
| Adam | epoch: 002 | loss: 0.69213 - acc: 0.5613 -- iter: 256/608
[A[ATraining Step: 28  | total loss: [1m[32m0.69173[0m[0m | time: 11.857s
[2K
| Adam | epoch: 002 | loss: 0.69173 - acc: 0.5694 -- iter: 288/608
[A[ATraining Step: 29  | total loss: [1m[32m0.69084[0m[0m | time: 13.201s
[2K
| Adam | epoch: 002 | loss: 0.69084 - acc: 0.5905 -- iter: 320/608
[A[ATraining Step: 30  | total loss: [1m[32m0.69060[0m[0m | time: 14.579s
[2K
| Adam | epoch: 002 | loss: 0.69060 - acc: 0.5839 -- iter: 352/608
[A[ATraining Step: 31  | total loss: [1m[32m0.68916[0m[0m | time: 15.963s
[2K
| Adam | epoch: 002 | loss: 0.68916 - acc: 0.5934 -- iter: 384/608
[A[ATraining Step: 32  | total loss: [1m[32m0.69197[0m[0m | time: 17.700s
[2K
| Adam | epoch: 002 | loss: 0.69197 - acc: 0.5583 -- iter: 416/608
[A[ATraining Step: 33  | total loss: [1m[32m0.69344[0m[0m | time: 18.913s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.5386 -- iter: 448/608
[A[ATraining Step: 34  | total loss: [1m[32m0.69403[0m[0m | time: 20.195s
[2K
| Adam | epoch: 002 | loss: 0.69403 - acc: 0.5237 -- iter: 480/608
[A[ATraining Step: 35  | total loss: [1m[32m0.69457[0m[0m | time: 21.838s
[2K
| Adam | epoch: 002 | loss: 0.69457 - acc: 0.5122 -- iter: 512/608
[A[ATraining Step: 36  | total loss: [1m[32m0.69608[0m[0m | time: 22.967s
[2K
| Adam | epoch: 002 | loss: 0.69608 - acc: 0.4905 -- iter: 544/608
[A[ATraining Step: 37  | total loss: [1m[32m0.69719[0m[0m | time: 24.183s
[2K
| Adam | epoch: 002 | loss: 0.69719 - acc: 0.4674 -- iter: 576/608
[A[ATraining Step: 38  | total loss: [1m[32m0.69501[0m[0m | time: 26.832s
[2K
| Adam | epoch: 002 | loss: 0.69501 - acc: 0.4982 | val_loss: 0.69210 - val_acc: 0.5026 -- iter: 608/608
--
Training Step: 39  | total loss: [1m[32m0.69404[0m[0m | time: 0.762s
[2K
| Adam | epoch: 003 | loss: 0.69404 - acc: 0.5105 -- iter: 032/608
[A[ATraining Step: 40  | total loss: [1m[32m0.69284[0m[0m | time: 1.536s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5320 -- iter: 064/608
[A[ATraining Step: 41  | total loss: [1m[32m0.69190[0m[0m | time: 2.284s
[2K
| Adam | epoch: 003 | loss: 0.69190 - acc: 0.5491 -- iter: 096/608
[A[ATraining Step: 42  | total loss: [1m[32m0.69177[0m[0m | time: 2.995s
[2K
| Adam | epoch: 003 | loss: 0.69177 - acc: 0.5459 -- iter: 128/608
[A[ATraining Step: 43  | total loss: [1m[32m0.69199[0m[0m | time: 3.731s
[2K
| Adam | epoch: 003 | loss: 0.69199 - acc: 0.5323 -- iter: 160/608
[A[ATraining Step: 44  | total loss: [1m[32m0.69285[0m[0m | time: 4.491s
[2K
| Adam | epoch: 003 | loss: 0.69285 - acc: 0.5105 -- iter: 192/608
[A[ATraining Step: 45  | total loss: [1m[32m0.69317[0m[0m | time: 5.208s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4981 -- iter: 224/608
[A[ATraining Step: 46  | total loss: [1m[32m0.69307[0m[0m | time: 5.922s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.4932 -- iter: 256/608
[A[ATraining Step: 47  | total loss: [1m[32m0.69234[0m[0m | time: 6.684s
[2K
| Adam | epoch: 003 | loss: 0.69234 - acc: 0.5045 -- iter: 288/608
[A[ATraining Step: 48  | total loss: [1m[32m0.69255[0m[0m | time: 7.431s
[2K
| Adam | epoch: 003 | loss: 0.69255 - acc: 0.4938 -- iter: 320/608
[A[ATraining Step: 49  | total loss: [1m[32m0.69256[0m[0m | time: 8.186s
[2K
| Adam | epoch: 003 | loss: 0.69256 - acc: 0.4898 -- iter: 352/608
[A[ATraining Step: 50  | total loss: [1m[32m0.69135[0m[0m | time: 8.937s
[2K
| Adam | epoch: 003 | loss: 0.69135 - acc: 0.5108 -- iter: 384/608
[A[ATraining Step: 51  | total loss: [1m[32m0.69104[0m[0m | time: 9.658s
[2K
| Adam | epoch: 003 | loss: 0.69104 - acc: 0.5091 -- iter: 416/608
[A[ATraining Step: 52  | total loss: [1m[32m0.69139[0m[0m | time: 10.401s
[2K
| Adam | epoch: 003 | loss: 0.69139 - acc: 0.5031 -- iter: 448/608
[A[ATraining Step: 53  | total loss: [1m[32m0.68991[0m[0m | time: 11.282s
[2K
| Adam | epoch: 003 | loss: 0.68991 - acc: 0.5165 -- iter: 480/608
[A[ATraining Step: 54  | total loss: [1m[32m0.68999[0m[0m | time: 11.884s
[2K
| Adam | epoch: 003 | loss: 0.68999 - acc: 0.5095 -- iter: 512/608
[A[ATraining Step: 55  | total loss: [1m[32m0.69161[0m[0m | time: 12.495s
[2K
| Adam | epoch: 003 | loss: 0.69161 - acc: 0.4858 -- iter: 544/608
[A[ATraining Step: 56  | total loss: [1m[32m0.68996[0m[0m | time: 13.116s
[2K
| Adam | epoch: 003 | loss: 0.68996 - acc: 0.4922 -- iter: 576/608
[A[ATraining Step: 57  | total loss: [1m[32m0.68906[0m[0m | time: 14.764s
[2K
| Adam | epoch: 003 | loss: 0.68906 - acc: 0.4976 | val_loss: 0.67530 - val_acc: 0.5026 -- iter: 608/608
--
Training Step: 58  | total loss: [1m[32m0.68672[0m[0m | time: 0.755s
[2K
| Adam | epoch: 004 | loss: 0.68672 - acc: 0.5150 -- iter: 032/608
[A[ATraining Step: 59  | total loss: [1m[32m0.68466[0m[0m | time: 1.480s
[2K
| Adam | epoch: 004 | loss: 0.68466 - acc: 0.5298 -- iter: 064/608
[A[ATraining Step: 60  | total loss: [1m[32m0.68537[0m[0m | time: 2.193s
[2K
| Adam | epoch: 004 | loss: 0.68537 - acc: 0.5176 -- iter: 096/608
[A[ATraining Step: 61  | total loss: [1m[32m0.68589[0m[0m | time: 2.932s
[2K
| Adam | epoch: 004 | loss: 0.68589 - acc: 0.5071 -- iter: 128/608
[A[ATraining Step: 62  | total loss: [1m[32m0.68435[0m[0m | time: 3.635s
[2K
| Adam | epoch: 004 | loss: 0.68435 - acc: 0.5102 -- iter: 160/608
[A[ATraining Step: 63  | total loss: [1m[32m0.68375[0m[0m | time: 4.397s
[2K
| Adam | epoch: 004 | loss: 0.68375 - acc: 0.4970 -- iter: 192/608
[A[ATraining Step: 64  | total loss: [1m[32m0.67933[0m[0m | time: 5.121s
[2K
| Adam | epoch: 004 | loss: 0.67933 - acc: 0.5013 -- iter: 224/608
[A[ATraining Step: 65  | total loss: [1m[32m0.67436[0m[0m | time: 5.831s
[2K
| Adam | epoch: 004 | loss: 0.67436 - acc: 0.5166 -- iter: 256/608
[A[ATraining Step: 66  | total loss: [1m[32m0.67465[0m[0m | time: 6.580s
[2K
| Adam | epoch: 004 | loss: 0.67465 - acc: 0.5032 -- iter: 288/608
[A[ATraining Step: 67  | total loss: [1m[32m0.66870[0m[0m | time: 7.335s
[2K
| Adam | epoch: 004 | loss: 0.66870 - acc: 0.5140 -- iter: 320/608
[A[ATraining Step: 68  | total loss: [1m[32m0.66640[0m[0m | time: 8.066s
[2K
| Adam | epoch: 004 | loss: 0.66640 - acc: 0.5124 -- iter: 352/608
[A[ATraining Step: 69  | total loss: [1m[32m0.65902[0m[0m | time: 8.786s
[2K
| Adam | epoch: 004 | loss: 0.65902 - acc: 0.5255 -- iter: 384/608
[A[ATraining Step: 70  | total loss: [1m[32m0.65889[0m[0m | time: 9.500s
[2K
| Adam | epoch: 004 | loss: 0.65889 - acc: 0.5118 -- iter: 416/608
[A[ATraining Step: 71  | total loss: [1m[32m0.64803[0m[0m | time: 10.244s
[2K
| Adam | epoch: 004 | loss: 0.64803 - acc: 0.5460 -- iter: 448/608
[A[ATraining Step: 72  | total loss: [1m[32m0.64419[0m[0m | time: 11.019s
[2K
| Adam | epoch: 004 | loss: 0.64419 - acc: 0.5584 -- iter: 480/608
[A[ATraining Step: 73  | total loss: [1m[32m0.63073[0m[0m | time: 11.617s
[2K
| Adam | epoch: 004 | loss: 0.63073 - acc: 0.5867 -- iter: 512/608
[A[ATraining Step: 74  | total loss: [1m[32m0.62353[0m[0m | time: 12.225s
[2K
| Adam | epoch: 004 | loss: 0.62353 - acc: 0.5943 -- iter: 544/608
[A[ATraining Step: 75  | total loss: [1m[32m0.62909[0m[0m | time: 12.851s
[2K
| Adam | epoch: 004 | loss: 0.62909 - acc: 0.5875 -- iter: 576/608
[A[ATraining Step: 76  | total loss: [1m[32m0.62011[0m[0m | time: 14.460s
[2K
| Adam | epoch: 004 | loss: 0.62011 - acc: 0.5982 | val_loss: 0.58967 - val_acc: 0.7853 -- iter: 608/608
--
Training Step: 77  | total loss: [1m[32m0.61721[0m[0m | time: 0.703s
[2K
| Adam | epoch: 005 | loss: 0.61721 - acc: 0.6242 -- iter: 032/608
[A[ATraining Step: 78  | total loss: [1m[32m0.61572[0m[0m | time: 1.446s
[2K
| Adam | epoch: 005 | loss: 0.61572 - acc: 0.6341 -- iter: 064/608
[A[ATraining Step: 79  | total loss: [1m[32m0.61487[0m[0m | time: 2.191s
[2K
| Adam | epoch: 005 | loss: 0.61487 - acc: 0.6461 -- iter: 096/608
[A[ATraining Step: 80  | total loss: [1m[32m0.60593[0m[0m | time: 2.931s
[2K
| Adam | epoch: 005 | loss: 0.60593 - acc: 0.6695 -- iter: 128/608
[A[ATraining Step: 81  | total loss: [1m[32m0.59847[0m[0m | time: 3.675s
[2K
| Adam | epoch: 005 | loss: 0.59847 - acc: 0.6713 -- iter: 160/608
[A[ATraining Step: 82  | total loss: [1m[32m0.59825[0m[0m | time: 4.408s
[2K
| Adam | epoch: 005 | loss: 0.59825 - acc: 0.6823 -- iter: 192/608
[A[ATraining Step: 83  | total loss: [1m[32m0.60348[0m[0m | time: 5.129s
[2K
| Adam | epoch: 005 | loss: 0.60348 - acc: 0.6828 -- iter: 224/608
[A[ATraining Step: 84  | total loss: [1m[32m0.60012[0m[0m | time: 5.886s
[2K
| Adam | epoch: 005 | loss: 0.60012 - acc: 0.6958 -- iter: 256/608
[A[ATraining Step: 85  | total loss: [1m[32m0.60189[0m[0m | time: 6.622s
[2K
| Adam | epoch: 005 | loss: 0.60189 - acc: 0.6950 -- iter: 288/608
[A[ATraining Step: 86  | total loss: [1m[32m0.59521[0m[0m | time: 7.363s
[2K
| Adam | epoch: 005 | loss: 0.59521 - acc: 0.7005 -- iter: 320/608
[A[ATraining Step: 87  | total loss: [1m[32m0.58762[0m[0m | time: 8.088s
[2K
| Adam | epoch: 005 | loss: 0.58762 - acc: 0.7148 -- iter: 352/608
[A[ATraining Step: 88  | total loss: [1m[32m0.58430[0m[0m | time: 8.880s
[2K
| Adam | epoch: 005 | loss: 0.58430 - acc: 0.7183 -- iter: 384/608
[A[ATraining Step: 89  | total loss: [1m[32m0.58232[0m[0m | time: 9.655s
[2K
| Adam | epoch: 005 | loss: 0.58232 - acc: 0.7277 -- iter: 416/608
[A[ATraining Step: 90  | total loss: [1m[32m0.56171[0m[0m | time: 10.285s
[2K
| Adam | epoch: 005 | loss: 0.56171 - acc: 0.7425 -- iter: 448/608
[A[ATraining Step: 91  | total loss: [1m[32m0.55157[0m[0m | time: 10.877s
[2K
| Adam | epoch: 005 | loss: 0.55157 - acc: 0.7463 -- iter: 480/608
[A[ATraining Step: 92  | total loss: [1m[32m0.53732[0m[0m | time: 11.626s
[2K
| Adam | epoch: 005 | loss: 0.53732 - acc: 0.7530 -- iter: 512/608
[A[ATraining Step: 93  | total loss: [1m[32m0.53024[0m[0m | time: 12.352s
[2K
| Adam | epoch: 005 | loss: 0.53024 - acc: 0.7589 -- iter: 544/608
[A[ATraining Step: 94  | total loss: [1m[32m0.51940[0m[0m | time: 13.077s
[2K
| Adam | epoch: 005 | loss: 0.51940 - acc: 0.7674 -- iter: 576/608
[A[ATraining Step: 95  | total loss: [1m[32m0.50719[0m[0m | time: 14.830s
[2K
| Adam | epoch: 005 | loss: 0.50719 - acc: 0.7750 | val_loss: 0.37864 - val_acc: 0.8272 -- iter: 608/608
--
Training Step: 96  | total loss: [1m[32m0.50707[0m[0m | time: 0.694s
[2K
| Adam | epoch: 006 | loss: 0.50707 - acc: 0.7725 -- iter: 032/608
[A[ATraining Step: 97  | total loss: [1m[32m0.48961[0m[0m | time: 1.478s
[2K
| Adam | epoch: 006 | loss: 0.48961 - acc: 0.7859 -- iter: 064/608
[A[ATraining Step: 98  | total loss: [1m[32m0.48636[0m[0m | time: 2.246s
[2K
| Adam | epoch: 006 | loss: 0.48636 - acc: 0.7854 -- iter: 096/608
[A[ATraining Step: 99  | total loss: [1m[32m0.48998[0m[0m | time: 2.990s
[2K
| Adam | epoch: 006 | loss: 0.48998 - acc: 0.7788 -- iter: 128/608
[A[ATraining Step: 100  | total loss: [1m[32m0.48536[0m[0m | time: 3.774s
[2K
| Adam | epoch: 006 | loss: 0.48536 - acc: 0.7790 -- iter: 160/608
[A[ATraining Step: 101  | total loss: [1m[32m0.47644[0m[0m | time: 4.522s
[2K
| Adam | epoch: 006 | loss: 0.47644 - acc: 0.7824 -- iter: 192/608
[A[ATraining Step: 102  | total loss: [1m[32m0.48020[0m[0m | time: 5.441s
[2K
| Adam | epoch: 006 | loss: 0.48020 - acc: 0.7729 -- iter: 224/608
[A[ATraining Step: 103  | total loss: [1m[32m0.45860[0m[0m | time: 6.053s
[2K
| Adam | epoch: 006 | loss: 0.45860 - acc: 0.7800 -- iter: 256/608
[A[ATraining Step: 104  | total loss: [1m[32m0.45089[0m[0m | time: 6.677s
[2K
| Adam | epoch: 006 | loss: 0.45089 - acc: 0.7832 -- iter: 288/608
[A[ATraining Step: 105  | total loss: [1m[32m0.43254[0m[0m | time: 7.287s
[2K
| Adam | epoch: 006 | loss: 0.43254 - acc: 0.8018 -- iter: 320/608
[A[ATraining Step: 106  | total loss: [1m[32m0.40892[0m[0m | time: 7.907s
[2K
| Adam | epoch: 006 | loss: 0.40892 - acc: 0.8185 -- iter: 352/608
[A[ATraining Step: 107  | total loss: [1m[32m0.39709[0m[0m | time: 8.494s
[2K
| Adam | epoch: 006 | loss: 0.39709 - acc: 0.8210 -- iter: 384/608
[A[ATraining Step: 108  | total loss: [1m[32m0.38470[0m[0m | time: 9.131s
[2K
| Adam | epoch: 006 | loss: 0.38470 - acc: 0.8358 -- iter: 416/608
[A[ATraining Step: 109  | total loss: [1m[32m0.38785[0m[0m | time: 9.729s
[2K
| Adam | epoch: 006 | loss: 0.38785 - acc: 0.8241 -- iter: 448/608
[A[ATraining Step: 110  | total loss: [1m[32m0.36580[0m[0m | time: 10.327s
[2K
| Adam | epoch: 006 | loss: 0.36580 - acc: 0.8354 -- iter: 480/608
[A[ATraining Step: 111  | total loss: [1m[32m0.35487[0m[0m | time: 10.929s
[2K
| Adam | epoch: 006 | loss: 0.35487 - acc: 0.8425 -- iter: 512/608
[A[ATraining Step: 112  | total loss: [1m[32m0.33371[0m[0m | time: 11.709s
[2K
| Adam | epoch: 006 | loss: 0.33371 - acc: 0.8520 -- iter: 544/608
[A[ATraining Step: 113  | total loss: [1m[32m0.32824[0m[0m | time: 12.453s
[2K
| Adam | epoch: 006 | loss: 0.32824 - acc: 0.8605 -- iter: 576/608
[A[ATraining Step: 114  | total loss: [1m[32m0.35270[0m[0m | time: 14.207s
[2K
| Adam | epoch: 006 | loss: 0.35270 - acc: 0.8495 | val_loss: 0.31417 - val_acc: 0.8796 -- iter: 608/608
--
Training Step: 115  | total loss: [1m[32m0.34488[0m[0m | time: 0.960s
[2K
| Adam | epoch: 007 | loss: 0.34488 - acc: 0.8520 -- iter: 032/608
[A[ATraining Step: 116  | total loss: [1m[32m0.32974[0m[0m | time: 1.697s
[2K
| Adam | epoch: 007 | loss: 0.32974 - acc: 0.8637 -- iter: 064/608
[A[ATraining Step: 117  | total loss: [1m[32m0.33415[0m[0m | time: 2.410s
[2K
| Adam | epoch: 007 | loss: 0.33415 - acc: 0.8617 -- iter: 096/608
[A[ATraining Step: 118  | total loss: [1m[32m0.32702[0m[0m | time: 3.121s
[2K
| Adam | epoch: 007 | loss: 0.32702 - acc: 0.8568 -- iter: 128/608
[A[ATraining Step: 119  | total loss: [1m[32m0.31578[0m[0m | time: 3.854s
[2K
| Adam | epoch: 007 | loss: 0.31578 - acc: 0.8680 -- iter: 160/608
[A[ATraining Step: 120  | total loss: [1m[32m0.30058[0m[0m | time: 4.584s
[2K
| Adam | epoch: 007 | loss: 0.30058 - acc: 0.8749 -- iter: 192/608
[A[ATraining Step: 121  | total loss: [1m[32m0.28407[0m[0m | time: 5.323s
[2K
| Adam | epoch: 007 | loss: 0.28407 - acc: 0.8812 -- iter: 224/608
[A[ATraining Step: 122  | total loss: [1m[32m0.26395[0m[0m | time: 6.171s
[2K
| Adam | epoch: 007 | loss: 0.26395 - acc: 0.8900 -- iter: 256/608
[A[ATraining Step: 123  | total loss: [1m[32m0.25559[0m[0m | time: 6.780s
[2K
| Adam | epoch: 007 | loss: 0.25559 - acc: 0.8885 -- iter: 288/608
[A[ATraining Step: 124  | total loss: [1m[32m0.25132[0m[0m | time: 7.379s
[2K
| Adam | epoch: 007 | loss: 0.25132 - acc: 0.8871 -- iter: 320/608
[A[ATraining Step: 125  | total loss: [1m[32m0.26520[0m[0m | time: 7.978s
[2K
| Adam | epoch: 007 | loss: 0.26520 - acc: 0.8859 -- iter: 352/608
[A[ATraining Step: 126  | total loss: [1m[32m0.25892[0m[0m | time: 8.607s
[2K
| Adam | epoch: 007 | loss: 0.25892 - acc: 0.8848 -- iter: 384/608
[A[ATraining Step: 127  | total loss: [1m[32m0.25333[0m[0m | time: 9.217s
[2K
| Adam | epoch: 007 | loss: 0.25333 - acc: 0.8901 -- iter: 416/608
[A[ATraining Step: 128  | total loss: [1m[32m0.26076[0m[0m | time: 9.837s
[2K
| Adam | epoch: 007 | loss: 0.26076 - acc: 0.8948 -- iter: 448/608
[A[ATraining Step: 129  | total loss: [1m[32m0.25158[0m[0m | time: 10.495s
[2K
| Adam | epoch: 007 | loss: 0.25158 - acc: 0.9022 -- iter: 480/608
[A[ATraining Step: 130  | total loss: [1m[32m0.24597[0m[0m | time: 11.149s
[2K
| Adam | epoch: 007 | loss: 0.24597 - acc: 0.9026 -- iter: 512/608
[A[ATraining Step: 131  | total loss: [1m[32m0.25277[0m[0m | time: 11.957s
[2K
| Adam | epoch: 007 | loss: 0.25277 - acc: 0.9030 -- iter: 544/608
[A[ATraining Step: 132  | total loss: [1m[32m0.24096[0m[0m | time: 12.694s
[2K
| Adam | epoch: 007 | loss: 0.24096 - acc: 0.9064 -- iter: 576/608
[A[ATraining Step: 133  | total loss: [1m[32m0.26399[0m[0m | time: 14.492s
[2K
| Adam | epoch: 007 | loss: 0.26399 - acc: 0.8939 | val_loss: 0.24217 - val_acc: 0.9162 -- iter: 608/608
--
Training Step: 134  | total loss: [1m[32m0.26426[0m[0m | time: 0.745s
[2K
| Adam | epoch: 008 | loss: 0.26426 - acc: 0.8951 -- iter: 032/608
[A[ATraining Step: 135  | total loss: [1m[32m0.24758[0m[0m | time: 1.510s
[2K
| Adam | epoch: 008 | loss: 0.24758 - acc: 0.9025 -- iter: 064/608
[A[ATraining Step: 136  | total loss: [1m[32m0.23429[0m[0m | time: 2.349s
[2K
| Adam | epoch: 008 | loss: 0.23429 - acc: 0.9091 -- iter: 096/608
[A[ATraining Step: 137  | total loss: [1m[32m0.23437[0m[0m | time: 2.956s
[2K
| Adam | epoch: 008 | loss: 0.23437 - acc: 0.9088 -- iter: 128/608
[A[ATraining Step: 138  | total loss: [1m[32m0.22595[0m[0m | time: 3.577s
[2K
| Adam | epoch: 008 | loss: 0.22595 - acc: 0.9117 -- iter: 160/608
[A[ATraining Step: 139  | total loss: [1m[32m0.23411[0m[0m | time: 4.327s
[2K
| Adam | epoch: 008 | loss: 0.23411 - acc: 0.9112 -- iter: 192/608
[A[ATraining Step: 140  | total loss: [1m[32m0.22906[0m[0m | time: 5.059s
[2K
| Adam | epoch: 008 | loss: 0.22906 - acc: 0.9138 -- iter: 224/608
[A[ATraining Step: 141  | total loss: [1m[32m0.21760[0m[0m | time: 5.774s
[2K
| Adam | epoch: 008 | loss: 0.21760 - acc: 0.9193 -- iter: 256/608
[A[ATraining Step: 142  | total loss: [1m[32m0.20887[0m[0m | time: 6.527s
[2K
| Adam | epoch: 008 | loss: 0.20887 - acc: 0.9211 -- iter: 288/608
[A[ATraining Step: 143  | total loss: [1m[32m0.20163[0m[0m | time: 7.347s
[2K
| Adam | epoch: 008 | loss: 0.20163 - acc: 0.9259 -- iter: 320/608
[A[ATraining Step: 144  | total loss: [1m[32m0.19006[0m[0m | time: 8.060s
[2K
| Adam | epoch: 008 | loss: 0.19006 - acc: 0.9333 -- iter: 352/608
[A[ATraining Step: 145  | total loss: [1m[32m0.18218[0m[0m | time: 8.687s
[2K
| Adam | epoch: 008 | loss: 0.18218 - acc: 0.9368 -- iter: 384/608
[A[ATraining Step: 146  | total loss: [1m[32m0.18170[0m[0m | time: 9.296s
[2K
| Adam | epoch: 008 | loss: 0.18170 - acc: 0.9369 -- iter: 416/608
[A[ATraining Step: 147  | total loss: [1m[32m0.17142[0m[0m | time: 9.895s
[2K
| Adam | epoch: 008 | loss: 0.17142 - acc: 0.9401 -- iter: 448/608
[A[ATraining Step: 148  | total loss: [1m[32m0.16106[0m[0m | time: 10.497s
[2K
| Adam | epoch: 008 | loss: 0.16106 - acc: 0.9461 -- iter: 480/608
[A[ATraining Step: 149  | total loss: [1m[32m0.15252[0m[0m | time: 11.105s
[2K
| Adam | epoch: 008 | loss: 0.15252 - acc: 0.9515 -- iter: 512/608
[A[ATraining Step: 150  | total loss: [1m[32m0.14299[0m[0m | time: 11.797s
[2K
| Adam | epoch: 008 | loss: 0.14299 - acc: 0.9563 -- iter: 544/608
[A[ATraining Step: 151  | total loss: [1m[32m0.13393[0m[0m | time: 12.555s
[2K
| Adam | epoch: 008 | loss: 0.13393 - acc: 0.9607 -- iter: 576/608
[A[ATraining Step: 152  | total loss: [1m[32m0.12782[0m[0m | time: 14.291s
[2K
| Adam | epoch: 008 | loss: 0.12782 - acc: 0.9646 | val_loss: 0.16764 - val_acc: 0.9267 -- iter: 608/608
--
Training Step: 153  | total loss: [1m[32m0.11790[0m[0m | time: 0.728s
[2K
| Adam | epoch: 009 | loss: 0.11790 - acc: 0.9682 -- iter: 032/608
[A[ATraining Step: 154  | total loss: [1m[32m0.11165[0m[0m | time: 1.478s
[2K
| Adam | epoch: 009 | loss: 0.11165 - acc: 0.9713 -- iter: 064/608
[A[ATraining Step: 155  | total loss: [1m[32m0.10712[0m[0m | time: 2.155s
[2K
| Adam | epoch: 009 | loss: 0.10712 - acc: 0.9711 -- iter: 096/608
[A[ATraining Step: 156  | total loss: [1m[32m0.10013[0m[0m | time: 2.915s
[2K
| Adam | epoch: 009 | loss: 0.10013 - acc: 0.9740 -- iter: 128/608
[A[ATraining Step: 157  | total loss: [1m[32m0.09443[0m[0m | time: 3.833s
[2K
| Adam | epoch: 009 | loss: 0.09443 - acc: 0.9766 -- iter: 160/608
[A[ATraining Step: 158  | total loss: [1m[32m0.08940[0m[0m | time: 4.438s
[2K
| Adam | epoch: 009 | loss: 0.08940 - acc: 0.9758 -- iter: 192/608
[A[ATraining Step: 159  | total loss: [1m[32m0.09091[0m[0m | time: 5.039s
[2K
| Adam | epoch: 009 | loss: 0.09091 - acc: 0.9751 -- iter: 224/608
[A[ATraining Step: 160  | total loss: [1m[32m0.11577[0m[0m | time: 5.649s
[2K
| Adam | epoch: 009 | loss: 0.11577 - acc: 0.9620 -- iter: 256/608
[A[ATraining Step: 161  | total loss: [1m[32m0.12804[0m[0m | time: 6.249s
[2K
| Adam | epoch: 009 | loss: 0.12804 - acc: 0.9595 -- iter: 288/608
[A[ATraining Step: 162  | total loss: [1m[32m0.12188[0m[0m | time: 6.857s
[2K
| Adam | epoch: 009 | loss: 0.12188 - acc: 0.9604 -- iter: 320/608
[A[ATraining Step: 163  | total loss: [1m[32m0.12482[0m[0m | time: 7.481s
[2K
| Adam | epoch: 009 | loss: 0.12482 - acc: 0.9581 -- iter: 352/608
[A[ATraining Step: 164  | total loss: [1m[32m0.11985[0m[0m | time: 8.167s
[2K
| Adam | epoch: 009 | loss: 0.11985 - acc: 0.9592 -- iter: 384/608
[A[ATraining Step: 165  | total loss: [1m[32m0.11493[0m[0m | time: 8.947s
[2K
| Adam | epoch: 009 | loss: 0.11493 - acc: 0.9602 -- iter: 416/608
[A[ATraining Step: 166  | total loss: [1m[32m0.10583[0m[0m | time: 9.704s
[2K
| Adam | epoch: 009 | loss: 0.10583 - acc: 0.9641 -- iter: 448/608
[A[ATraining Step: 167  | total loss: [1m[32m0.09879[0m[0m | time: 10.451s
[2K
| Adam | epoch: 009 | loss: 0.09879 - acc: 0.9677 -- iter: 480/608
[A[ATraining Step: 168  | total loss: [1m[32m0.40440[0m[0m | time: 11.151s
[2K
| Adam | epoch: 009 | loss: 0.40440 - acc: 0.9085 -- iter: 512/608
[A[ATraining Step: 169  | total loss: [1m[32m0.36723[0m[0m | time: 11.917s
[2K
| Adam | epoch: 009 | loss: 0.36723 - acc: 0.9176 -- iter: 544/608
[A[ATraining Step: 170  | total loss: [1m[32m0.33186[0m[0m | time: 12.695s
[2K
| Adam | epoch: 009 | loss: 0.33186 - acc: 0.9258 -- iter: 576/608
[A[ATraining Step: 171  | total loss: [1m[32m0.30303[0m[0m | time: 14.462s
[2K
| Adam | epoch: 009 | loss: 0.30303 - acc: 0.9333 | val_loss: 0.19379 - val_acc: 0.9215 -- iter: 608/608
--
Training Step: 172  | total loss: [1m[32m0.27598[0m[0m | time: 0.733s
[2K
| Adam | epoch: 010 | loss: 0.27598 - acc: 0.9399 -- iter: 032/608
[A[ATraining Step: 173  | total loss: [1m[32m0.25103[0m[0m | time: 1.461s
[2K
| Adam | epoch: 010 | loss: 0.25103 - acc: 0.9459 -- iter: 064/608
[A[ATraining Step: 174  | total loss: [1m[32m0.23208[0m[0m | time: 2.214s
[2K
| Adam | epoch: 010 | loss: 0.23208 - acc: 0.9513 -- iter: 096/608
[A[ATraining Step: 175  | total loss: [1m[32m0.21057[0m[0m | time: 2.915s
[2K
| Adam | epoch: 010 | loss: 0.21057 - acc: 0.9562 -- iter: 128/608
[A[ATraining Step: 176  | total loss: [1m[32m0.19345[0m[0m | time: 3.767s
[2K
| Adam | epoch: 010 | loss: 0.19345 - acc: 0.9606 -- iter: 160/608
[A[ATraining Step: 177  | total loss: [1m[32m0.17604[0m[0m | time: 4.428s
[2K
| Adam | epoch: 010 | loss: 0.17604 - acc: 0.9645 -- iter: 192/608
[A[ATraining Step: 178  | total loss: [1m[32m0.16048[0m[0m | time: 5.040s
[2K
| Adam | epoch: 010 | loss: 0.16048 - acc: 0.9681 -- iter: 224/608
[A[ATraining Step: 179  | total loss: [1m[32m0.14646[0m[0m | time: 5.647s
[2K
| Adam | epoch: 010 | loss: 0.14646 - acc: 0.9713 -- iter: 256/608
[A[ATraining Step: 180  | total loss: [1m[32m0.13666[0m[0m | time: 6.244s
[2K
| Adam | epoch: 010 | loss: 0.13666 - acc: 0.9741 -- iter: 288/608
[A[ATraining Step: 181  | total loss: [1m[32m0.12698[0m[0m | time: 6.839s
[2K
| Adam | epoch: 010 | loss: 0.12698 - acc: 0.9767 -- iter: 320/608
[A[ATraining Step: 182  | total loss: [1m[32m0.11884[0m[0m | time: 7.469s
[2K
| Adam | epoch: 010 | loss: 0.11884 - acc: 0.9791 -- iter: 352/608
[A[ATraining Step: 183  | total loss: [1m[32m0.10791[0m[0m | time: 8.076s
[2K
| Adam | epoch: 010 | loss: 0.10791 - acc: 0.9812 -- iter: 384/608
[A[ATraining Step: 184  | total loss: [1m[32m0.10066[0m[0m | time: 8.678s
[2K
| Adam | epoch: 010 | loss: 0.10066 - acc: 0.9830 -- iter: 416/608
[A[ATraining Step: 185  | total loss: [1m[32m0.09283[0m[0m | time: 9.289s
[2K
| Adam | epoch: 010 | loss: 0.09283 - acc: 0.9847 -- iter: 448/608
[A[ATraining Step: 186  | total loss: [1m[32m0.08501[0m[0m | time: 9.892s
[2K
| Adam | epoch: 010 | loss: 0.08501 - acc: 0.9863 -- iter: 480/608
[A[ATraining Step: 187  | total loss: [1m[32m0.08061[0m[0m | time: 10.485s
[2K
| Adam | epoch: 010 | loss: 0.08061 - acc: 0.9845 -- iter: 512/608
[A[ATraining Step: 188  | total loss: [1m[32m0.07621[0m[0m | time: 11.202s
[2K
| Adam | epoch: 010 | loss: 0.07621 - acc: 0.9861 -- iter: 544/608
[A[ATraining Step: 189  | total loss: [1m[32m0.07039[0m[0m | time: 11.945s
[2K
| Adam | epoch: 010 | loss: 0.07039 - acc: 0.9875 -- iter: 576/608
[A[ATraining Step: 190  | total loss: [1m[32m0.06482[0m[0m | time: 13.659s
[2K
| Adam | epoch: 010 | loss: 0.06482 - acc: 0.9887 | val_loss: 0.22001 - val_acc: 0.9162 -- iter: 608/608
--
Training Step: 191  | total loss: [1m[32m0.05946[0m[0m | time: 0.721s
[2K
| Adam | epoch: 011 | loss: 0.05946 - acc: 0.9898 -- iter: 032/608
[A[ATraining Step: 192  | total loss: [1m[32m0.05410[0m[0m | time: 1.451s
[2K
| Adam | epoch: 011 | loss: 0.05410 - acc: 0.9909 -- iter: 064/608
[A[ATraining Step: 193  | total loss: [1m[32m0.05032[0m[0m | time: 2.180s
[2K
| Adam | epoch: 011 | loss: 0.05032 - acc: 0.9918 -- iter: 096/608
[A[ATraining Step: 194  | total loss: [1m[32m0.04559[0m[0m | time: 2.919s
[2K
| Adam | epoch: 011 | loss: 0.04559 - acc: 0.9926 -- iter: 128/608
[A[ATraining Step: 195  | total loss: [1m[32m0.04465[0m[0m | time: 3.671s
[2K
| Adam | epoch: 011 | loss: 0.04465 - acc: 0.9933 -- iter: 160/608
[A[ATraining Step: 196  | total loss: [1m[32m0.04087[0m[0m | time: 4.576s
[2K
| Adam | epoch: 011 | loss: 0.04087 - acc: 0.9940 -- iter: 192/608
[A[ATraining Step: 197  | total loss: [1m[32m0.03696[0m[0m | time: 5.170s
[2K
| Adam | epoch: 011 | loss: 0.03696 - acc: 0.9946 -- iter: 224/608
[A[ATraining Step: 198  | total loss: [1m[32m0.04595[0m[0m | time: 5.768s
[2K
| Adam | epoch: 011 | loss: 0.04595 - acc: 0.9889 -- iter: 256/608
[A[ATraining Step: 199  | total loss: [1m[32m0.04234[0m[0m | time: 6.383s
[2K
| Adam | epoch: 011 | loss: 0.04234 - acc: 0.9900 -- iter: 288/608
[A[ATraining Step: 200  | total loss: [1m[32m0.03973[0m[0m | time: 8.000s
[2K
| Adam | epoch: 011 | loss: 0.03973 - acc: 0.9910 | val_loss: 0.21485 - val_acc: 0.9267 -- iter: 320/608
--
Training Step: 201  | total loss: [1m[32m0.03851[0m[0m | time: 8.610s
[2K
| Adam | epoch: 011 | loss: 0.03851 - acc: 0.9919 -- iter: 352/608
[A[ATraining Step: 202  | total loss: [1m[32m0.03489[0m[0m | time: 9.213s
[2K
| Adam | epoch: 011 | loss: 0.03489 - acc: 0.9927 -- iter: 384/608
[A[ATraining Step: 203  | total loss: [1m[32m0.03253[0m[0m | time: 9.815s
[2K
| Adam | epoch: 011 | loss: 0.03253 - acc: 0.9934 -- iter: 416/608
[A[ATraining Step: 204  | total loss: [1m[32m0.03151[0m[0m | time: 10.440s
[2K
| Adam | epoch: 011 | loss: 0.03151 - acc: 0.9941 -- iter: 448/608
[A[ATraining Step: 205  | total loss: [1m[32m0.02884[0m[0m | time: 11.076s
[2K
| Adam | epoch: 011 | loss: 0.02884 - acc: 0.9947 -- iter: 480/608
[A[ATraining Step: 206  | total loss: [1m[32m0.02642[0m[0m | time: 11.687s
[2K
| Adam | epoch: 011 | loss: 0.02642 - acc: 0.9952 -- iter: 512/608
[A[ATraining Step: 207  | total loss: [1m[32m0.02494[0m[0m | time: 12.294s
[2K
| Adam | epoch: 011 | loss: 0.02494 - acc: 0.9957 -- iter: 544/608
[A[ATraining Step: 208  | total loss: [1m[32m0.05957[0m[0m | time: 12.890s
[2K
| Adam | epoch: 011 | loss: 0.05957 - acc: 0.9899 -- iter: 576/608
[A[ATraining Step: 209  | total loss: [1m[32m0.05421[0m[0m | time: 14.517s
[2K
| Adam | epoch: 011 | loss: 0.05421 - acc: 0.9909 | val_loss: 0.19475 - val_acc: 0.9162 -- iter: 608/608
--
Training Step: 210  | total loss: [1m[32m0.04904[0m[0m | time: 0.623s
[2K
| Adam | epoch: 012 | loss: 0.04904 - acc: 0.9918 -- iter: 032/608
[A[ATraining Step: 211  | total loss: [1m[32m0.04433[0m[0m | time: 1.230s
[2K
| Adam | epoch: 012 | loss: 0.04433 - acc: 0.9926 -- iter: 064/608
[A[ATraining Step: 212  | total loss: [1m[32m0.04015[0m[0m | time: 1.844s
[2K
| Adam | epoch: 012 | loss: 0.04015 - acc: 0.9934 -- iter: 096/608
[A[ATraining Step: 213  | total loss: [1m[32m0.04102[0m[0m | time: 2.458s
[2K
| Adam | epoch: 012 | loss: 0.04102 - acc: 0.9940 -- iter: 128/608
[A[ATraining Step: 214  | total loss: [1m[32m0.03926[0m[0m | time: 3.063s
[2K
| Adam | epoch: 012 | loss: 0.03926 - acc: 0.9946 -- iter: 160/608
[A[ATraining Step: 215  | total loss: [1m[32m0.06039[0m[0m | time: 3.663s
[2K
| Adam | epoch: 012 | loss: 0.06039 - acc: 0.9920 -- iter: 192/608
[A[ATraining Step: 216  | total loss: [1m[32m0.06240[0m[0m | time: 4.263s
[2K
| Adam | epoch: 012 | loss: 0.06240 - acc: 0.9897 -- iter: 224/608
[A[ATraining Step: 217  | total loss: [1m[32m0.05723[0m[0m | time: 4.890s
[2K
| Adam | epoch: 012 | loss: 0.05723 - acc: 0.9907 -- iter: 256/608
[A[ATraining Step: 218  | total loss: [1m[32m0.05183[0m[0m | time: 5.494s
[2K
| Adam | epoch: 012 | loss: 0.05183 - acc: 0.9917 -- iter: 288/608
[A[ATraining Step: 219  | total loss: [1m[32m0.05129[0m[0m | time: 6.120s
[2K
| Adam | epoch: 012 | loss: 0.05129 - acc: 0.9925 -- iter: 320/608
[A[ATraining Step: 220  | total loss: [1m[32m0.04873[0m[0m | time: 6.745s
[2K
| Adam | epoch: 012 | loss: 0.04873 - acc: 0.9932 -- iter: 352/608
[A[ATraining Step: 221  | total loss: [1m[32m0.04430[0m[0m | time: 7.343s
[2K
| Adam | epoch: 012 | loss: 0.04430 - acc: 0.9939 -- iter: 384/608
[A[ATraining Step: 222  | total loss: [1m[32m0.04099[0m[0m | time: 7.943s
[2K
| Adam | epoch: 012 | loss: 0.04099 - acc: 0.9945 -- iter: 416/608
[A[ATraining Step: 223  | total loss: [1m[32m0.04291[0m[0m | time: 8.537s
[2K
| Adam | epoch: 012 | loss: 0.04291 - acc: 0.9920 -- iter: 448/608
[A[ATraining Step: 224  | total loss: [1m[32m0.03998[0m[0m | time: 9.134s
[2K
| Adam | epoch: 012 | loss: 0.03998 - acc: 0.9928 -- iter: 480/608
[A[ATraining Step: 225  | total loss: [1m[32m0.03741[0m[0m | time: 9.753s
[2K
| Adam | epoch: 012 | loss: 0.03741 - acc: 0.9935 -- iter: 512/608
[A[ATraining Step: 226  | total loss: [1m[32m0.03537[0m[0m | time: 10.341s
[2K
| Adam | epoch: 012 | loss: 0.03537 - acc: 0.9941 -- iter: 544/608
[A[ATraining Step: 227  | total loss: [1m[32m0.03304[0m[0m | time: 10.948s
[2K
| Adam | epoch: 012 | loss: 0.03304 - acc: 0.9947 -- iter: 576/608
[A[ATraining Step: 228  | total loss: [1m[32m0.03049[0m[0m | time: 12.574s
[2K
| Adam | epoch: 012 | loss: 0.03049 - acc: 0.9952 | val_loss: 0.24677 - val_acc: 0.9215 -- iter: 608/608
--
Training Step: 229  | total loss: [1m[32m0.02776[0m[0m | time: 0.610s
[2K
| Adam | epoch: 013 | loss: 0.02776 - acc: 0.9957 -- iter: 032/608
[A[ATraining Step: 230  | total loss: [1m[32m0.02534[0m[0m | time: 1.215s
[2K
| Adam | epoch: 013 | loss: 0.02534 - acc: 0.9961 -- iter: 064/608
[A[ATraining Step: 231  | total loss: [1m[32m0.02367[0m[0m | time: 1.806s
[2K
| Adam | epoch: 013 | loss: 0.02367 - acc: 0.9965 -- iter: 096/608
[A[ATraining Step: 232  | total loss: [1m[32m0.02172[0m[0m | time: 2.408s
[2K
| Adam | epoch: 013 | loss: 0.02172 - acc: 0.9969 -- iter: 128/608
[A[ATraining Step: 233  | total loss: [1m[32m0.02004[0m[0m | time: 3.022s
[2K
| Adam | epoch: 013 | loss: 0.02004 - acc: 0.9972 -- iter: 160/608
[A[ATraining Step: 234  | total loss: [1m[32m0.01980[0m[0m | time: 3.754s
[2K
| Adam | epoch: 013 | loss: 0.01980 - acc: 0.9975 -- iter: 192/608
[A[ATraining Step: 235  | total loss: [1m[32m0.01810[0m[0m | time: 4.358s
[2K
| Adam | epoch: 013 | loss: 0.01810 - acc: 0.9977 -- iter: 224/608
[A[ATraining Step: 236  | total loss: [1m[32m0.01809[0m[0m | time: 4.958s
[2K
| Adam | epoch: 013 | loss: 0.01809 - acc: 0.9980 -- iter: 256/608
[A[ATraining Step: 237  | total loss: [1m[32m0.01697[0m[0m | time: 5.557s
[2K
| Adam | epoch: 013 | loss: 0.01697 - acc: 0.9982 -- iter: 288/608
[A[ATraining Step: 238  | total loss: [1m[32m0.01553[0m[0m | time: 6.191s
[2K
| Adam | epoch: 013 | loss: 0.01553 - acc: 0.9983 -- iter: 320/608
[A[ATraining Step: 239  | total loss: [1m[32m0.01430[0m[0m | time: 6.779s
[2K
| Adam | epoch: 013 | loss: 0.01430 - acc: 0.9985 -- iter: 352/608
[A[ATraining Step: 240  | total loss: [1m[32m0.01307[0m[0m | time: 7.380s
[2K
| Adam | epoch: 013 | loss: 0.01307 - acc: 0.9987 -- iter: 384/608
[A[ATraining Step: 241  | total loss: [1m[32m0.01194[0m[0m | time: 7.973s
[2K
| Adam | epoch: 013 | loss: 0.01194 - acc: 0.9988 -- iter: 416/608
[A[ATraining Step: 242  | total loss: [1m[32m0.01107[0m[0m | time: 8.569s
[2K
| Adam | epoch: 013 | loss: 0.01107 - acc: 0.9989 -- iter: 448/608
[A[ATraining Step: 243  | total loss: [1m[32m0.01014[0m[0m | time: 9.170s
[2K
| Adam | epoch: 013 | loss: 0.01014 - acc: 0.9990 -- iter: 480/608
[A[ATraining Step: 244  | total loss: [1m[32m0.00943[0m[0m | time: 9.766s
[2K
| Adam | epoch: 013 | loss: 0.00943 - acc: 0.9991 -- iter: 512/608
[A[ATraining Step: 245  | total loss: [1m[32m0.00862[0m[0m | time: 10.375s
[2K
| Adam | epoch: 013 | loss: 0.00862 - acc: 0.9992 -- iter: 544/608
[A[ATraining Step: 246  | total loss: [1m[32m0.00780[0m[0m | time: 10.989s
[2K
| Adam | epoch: 013 | loss: 0.00780 - acc: 0.9993 -- iter: 576/608
[A[ATraining Step: 247  | total loss: [1m[32m0.00898[0m[0m | time: 12.587s
[2K
| Adam | epoch: 013 | loss: 0.00898 - acc: 0.9994 | val_loss: 0.23741 - val_acc: 0.9110 -- iter: 608/608
--
Training Step: 248  | total loss: [1m[32m0.06701[0m[0m | time: 0.615s
[2K
| Adam | epoch: 014 | loss: 0.06701 - acc: 0.9932 -- iter: 032/608
[A[ATraining Step: 249  | total loss: [1m[32m0.06071[0m[0m | time: 1.224s
[2K
| Adam | epoch: 014 | loss: 0.06071 - acc: 0.9939 -- iter: 064/608
[A[ATraining Step: 250  | total loss: [1m[32m0.05882[0m[0m | time: 1.825s
[2K
| Adam | epoch: 014 | loss: 0.05882 - acc: 0.9913 -- iter: 096/608
[A[ATraining Step: 251  | total loss: [1m[32m0.05368[0m[0m | time: 2.431s
[2K
| Adam | epoch: 014 | loss: 0.05368 - acc: 0.9922 -- iter: 128/608
[A[ATraining Step: 252  | total loss: [1m[32m0.04846[0m[0m | time: 3.029s
[2K
| Adam | epoch: 014 | loss: 0.04846 - acc: 0.9930 -- iter: 160/608
[A[ATraining Step: 253  | total loss: [1m[32m0.04412[0m[0m | time: 3.630s
[2K
| Adam | epoch: 014 | loss: 0.04412 - acc: 0.9937 -- iter: 192/608
[A[ATraining Step: 254  | total loss: [1m[32m0.04096[0m[0m | time: 4.230s
[2K
| Adam | epoch: 014 | loss: 0.04096 - acc: 0.9943 -- iter: 224/608
[A[ATraining Step: 255  | total loss: [1m[32m0.03767[0m[0m | time: 4.826s
[2K
| Adam | epoch: 014 | loss: 0.03767 - acc: 0.9949 -- iter: 256/608
[A[ATraining Step: 256  | total loss: [1m[32m0.03445[0m[0m | time: 5.428s
[2K
| Adam | epoch: 014 | loss: 0.03445 - acc: 0.9954 -- iter: 288/608
[A[ATraining Step: 257  | total loss: [1m[32m0.03214[0m[0m | time: 6.035s
[2K
| Adam | epoch: 014 | loss: 0.03214 - acc: 0.9959 -- iter: 320/608
[A[ATraining Step: 258  | total loss: [1m[32m0.02930[0m[0m | time: 6.639s
[2K
| Adam | epoch: 014 | loss: 0.02930 - acc: 0.9963 -- iter: 352/608
[A[ATraining Step: 259  | total loss: [1m[32m0.02924[0m[0m | time: 7.258s
[2K
| Adam | epoch: 014 | loss: 0.02924 - acc: 0.9966 -- iter: 384/608
[A[ATraining Step: 260  | total loss: [1m[32m0.02946[0m[0m | time: 7.852s
[2K
| Adam | epoch: 014 | loss: 0.02946 - acc: 0.9970 -- iter: 416/608
[A[ATraining Step: 261  | total loss: [1m[32m0.02914[0m[0m | time: 8.458s
[2K
| Adam | epoch: 014 | loss: 0.02914 - acc: 0.9973 -- iter: 448/608
[A[ATraining Step: 262  | total loss: [1m[32m0.02776[0m[0m | time: 9.094s
[2K
| Adam | epoch: 014 | loss: 0.02776 - acc: 0.9976 -- iter: 480/608
[A[ATraining Step: 263  | total loss: [1m[32m0.02603[0m[0m | time: 9.698s
[2K
| Adam | epoch: 014 | loss: 0.02603 - acc: 0.9978 -- iter: 512/608
[A[ATraining Step: 264  | total loss: [1m[32m0.02385[0m[0m | time: 10.299s
[2K
| Adam | epoch: 014 | loss: 0.02385 - acc: 0.9980 -- iter: 544/608
[A[ATraining Step: 265  | total loss: [1m[32m0.03187[0m[0m | time: 10.904s
[2K
| Adam | epoch: 014 | loss: 0.03187 - acc: 0.9920 -- iter: 576/608
[A[ATraining Step: 266  | total loss: [1m[32m0.03013[0m[0m | time: 12.515s
[2K
| Adam | epoch: 014 | loss: 0.03013 - acc: 0.9928 | val_loss: 0.27554 - val_acc: 0.9005 -- iter: 608/608
--
Training Step: 267  | total loss: [1m[32m0.02747[0m[0m | time: 0.621s
[2K
| Adam | epoch: 015 | loss: 0.02747 - acc: 0.9935 -- iter: 032/608
[A[ATraining Step: 268  | total loss: [1m[32m0.06326[0m[0m | time: 1.241s
[2K
| Adam | epoch: 015 | loss: 0.06326 - acc: 0.9879 -- iter: 064/608
[A[ATraining Step: 269  | total loss: [1m[32m0.07062[0m[0m | time: 1.865s
[2K
| Adam | epoch: 015 | loss: 0.07062 - acc: 0.9829 -- iter: 096/608
[A[ATraining Step: 270  | total loss: [1m[32m0.07589[0m[0m | time: 2.487s
[2K
| Adam | epoch: 015 | loss: 0.07589 - acc: 0.9783 -- iter: 128/608
[A[ATraining Step: 271  | total loss: [1m[32m0.07015[0m[0m | time: 3.082s
[2K
| Adam | epoch: 015 | loss: 0.07015 - acc: 0.9805 -- iter: 160/608
[A[ATraining Step: 272  | total loss: [1m[32m0.06345[0m[0m | time: 3.710s
[2K
| Adam | epoch: 015 | loss: 0.06345 - acc: 0.9824 -- iter: 192/608
[A[ATraining Step: 273  | total loss: [1m[32m0.05924[0m[0m | time: 4.309s
[2K
| Adam | epoch: 015 | loss: 0.05924 - acc: 0.9842 -- iter: 224/608
[A[ATraining Step: 274  | total loss: [1m[32m0.06445[0m[0m | time: 4.941s
[2K
| Adam | epoch: 015 | loss: 0.06445 - acc: 0.9764 -- iter: 256/608
[A[ATraining Step: 275  | total loss: [1m[32m0.06208[0m[0m | time: 5.542s
[2K
| Adam | epoch: 015 | loss: 0.06208 - acc: 0.9788 -- iter: 288/608
[A[ATraining Step: 276  | total loss: [1m[32m0.05679[0m[0m | time: 6.150s
[2K
| Adam | epoch: 015 | loss: 0.05679 - acc: 0.9809 -- iter: 320/608
[A[ATraining Step: 277  | total loss: [1m[32m0.05335[0m[0m | time: 6.764s
[2K
| Adam | epoch: 015 | loss: 0.05335 - acc: 0.9828 -- iter: 352/608
[A[ATraining Step: 278  | total loss: [1m[32m0.05267[0m[0m | time: 7.367s
[2K
| Adam | epoch: 015 | loss: 0.05267 - acc: 0.9814 -- iter: 384/608
[A[ATraining Step: 279  | total loss: [1m[32m0.05045[0m[0m | time: 7.988s
[2K
| Adam | epoch: 015 | loss: 0.05045 - acc: 0.9833 -- iter: 416/608
[A[ATraining Step: 280  | total loss: [1m[32m0.04607[0m[0m | time: 8.612s
[2K
| Adam | epoch: 015 | loss: 0.04607 - acc: 0.9849 -- iter: 448/608
[A[ATraining Step: 281  | total loss: [1m[32m0.04190[0m[0m | time: 9.214s
[2K
| Adam | epoch: 015 | loss: 0.04190 - acc: 0.9864 -- iter: 480/608
[A[ATraining Step: 282  | total loss: [1m[32m0.03820[0m[0m | time: 9.805s
[2K
| Adam | epoch: 015 | loss: 0.03820 - acc: 0.9878 -- iter: 512/608
[A[ATraining Step: 283  | total loss: [1m[32m0.04117[0m[0m | time: 10.403s
[2K
| Adam | epoch: 015 | loss: 0.04117 - acc: 0.9859 -- iter: 544/608
[A[ATraining Step: 284  | total loss: [1m[32m0.03819[0m[0m | time: 11.005s
[2K
| Adam | epoch: 015 | loss: 0.03819 - acc: 0.9873 -- iter: 576/608
[A[ATraining Step: 285  | total loss: [1m[32m0.03483[0m[0m | time: 12.607s
[2K
| Adam | epoch: 015 | loss: 0.03483 - acc: 0.9886 | val_loss: 0.24243 - val_acc: 0.9215 -- iter: 608/608
--
Validation AUC:0.9794956140350877
Validation AUPRC:0.9804448285933339
Test AUC:0.9931703018285967
Test AUPRC:0.9941661588828673
BestTestF1Score	0.94	0.87	0.93	0.89	0.99	101	12	77	1	0.05
BestTestMCCScore	0.94	0.87	0.93	0.89	0.99	101	12	77	1	0.05
BestTestAccuracyScore	0.95	0.9	0.95	0.96	0.94	96	4	85	6	0.66
BestValidationF1Score	0.93	0.86	0.93	0.88	0.99	95	13	82	1	0.05
BestValidationMCC	0.93	0.86	0.93	0.88	0.99	95	13	82	1	0.05
BestValidationAccuracy	0.93	0.85	0.93	0.94	0.92	88	6	89	8	0.66
TestPredictions (Threshold:0.05)
CHEMBL165354,TP,ACT,0.9700000286102295	CHEMBL308237,TP,ACT,0.8700000047683716	CHEMBL353980,TP,ACT,1.0	CHEMBL297578,TN,INACT,0.009999999776482582	CHEMBL318605,TP,ACT,0.9800000190734863	CHEMBL174448,TN,INACT,0.0	CHEMBL304950,TN,INACT,0.0	CHEMBL302027,TN,INACT,0.009999999776482582	CHEMBL907,FP,INACT,0.9900000095367432	CHEMBL125231,TP,ACT,1.0	CHEMBL39959,TP,ACT,1.0	CHEMBL289284,TN,INACT,0.009999999776482582	CHEMBL168771,TP,ACT,1.0	CHEMBL132179,FP,INACT,0.14000000059604645	CHEMBL169009,TP,ACT,1.0	CHEMBL124903,TP,ACT,1.0	CHEMBL419974,TP,ACT,0.9900000095367432	CHEMBL309194,TN,INACT,0.03999999910593033	CHEMBL407818,TN,INACT,0.0	CHEMBL422411,TN,INACT,0.0	CHEMBL340367,FN,ACT,0.019999999552965164	CHEMBL339256,TP,ACT,1.0	CHEMBL73164,TN,INACT,0.009999999776482582	CHEMBL352502,TP,ACT,1.0	CHEMBL338027,TP,ACT,1.0	CHEMBL329679,TP,ACT,0.5899999737739563	CHEMBL299887,TP,ACT,1.0	CHEMBL416069,TN,INACT,0.0	CHEMBL319910,TN,INACT,0.009999999776482582	CHEMBL307290,TP,ACT,0.9800000190734863	CHEMBL431619,TP,ACT,1.0	CHEMBL72295,FP,INACT,0.8500000238418579	CHEMBL274710,TP,ACT,1.0	CHEMBL25528,FP,INACT,0.12999999523162842	CHEMBL404888,TN,INACT,0.0	CHEMBL245319,TN,INACT,0.0	CHEMBL421478,TP,ACT,1.0	CHEMBL553082,TN,INACT,0.0	CHEMBL45456,TN,INACT,0.0	CHEMBL251541,TN,INACT,0.0	CHEMBL343158,TN,INACT,0.009999999776482582	CHEMBL98453,TP,ACT,1.0	CHEMBL24781,TN,INACT,0.009999999776482582	CHEMBL307757,TP,ACT,0.699999988079071	CHEMBL411487,TP,ACT,1.0	CHEMBL352639,TP,ACT,1.0	CHEMBL72710,TN,INACT,0.0	CHEMBL352629,TP,ACT,1.0	CHEMBL344752,TN,INACT,0.0	CHEMBL344597,TP,ACT,0.6200000047683716	CHEMBL17487,TP,ACT,1.0	CHEMBL233552,TN,INACT,0.009999999776482582	CHEMBL2062852,FP,INACT,0.2800000011920929	CHEMBL110064,TN,INACT,0.0	CHEMBL350554,TP,ACT,1.0	CHEMBL140619,TP,ACT,1.0	CHEMBL98665,TP,ACT,1.0	CHEMBL432334,FP,INACT,0.05000000074505806	CHEMBL332239,TP,ACT,0.5699999928474426	CHEMBL435784,FP,INACT,0.17000000178813934	CHEMBL262296,TP,ACT,1.0	CHEMBL157946,TP,ACT,0.09000000357627869	CHEMBL287250,TP,ACT,1.0	CHEMBL125008,TP,ACT,1.0	CHEMBL98047,TP,ACT,0.949999988079071	CHEMBL324586,TN,INACT,0.0	CHEMBL329858,TP,ACT,1.0	CHEMBL195893,TN,INACT,0.0	CHEMBL109478,TN,INACT,0.0	CHEMBL122401,TP,ACT,0.9900000095367432	CHEMBL166338,TP,ACT,1.0	CHEMBL44463,TN,INACT,0.0	CHEMBL323854,TN,INACT,0.0	CHEMBL333224,TP,ACT,1.0	CHEMBL813,TP,ACT,1.0	CHEMBL15606,TP,ACT,0.9900000095367432	CHEMBL160396,TN,INACT,0.0	CHEMBL172788,TN,INACT,0.0	CHEMBL352925,TN,INACT,0.009999999776482582	CHEMBL97465,TP,ACT,1.0	CHEMBL316706,TP,ACT,1.0	CHEMBL392888,TN,INACT,0.0	CHEMBL15816,TP,ACT,1.0	CHEMBL141354,TN,INACT,0.009999999776482582	CHEMBL321367,TP,ACT,1.0	CHEMBL76860,TN,INACT,0.0	CHEMBL355708,TP,ACT,1.0	CHEMBL303538,TN,INACT,0.0	CHEMBL408799,TP,ACT,1.0	CHEMBL319924,TN,INACT,0.0	CHEMBL97271,TP,ACT,1.0	CHEMBL97500,TP,ACT,1.0	CHEMBL169488,TP,ACT,1.0	CHEMBL39879,FP,INACT,0.05000000074505806	CHEMBL291818,TP,ACT,1.0	CHEMBL299538,TN,INACT,0.009999999776482582	CHEMBL100119,TP,ACT,0.9399999976158142	CHEMBL602474,TN,INACT,0.0	CHEMBL73272,TN,INACT,0.009999999776482582	CHEMBL423260,TN,INACT,0.0	CHEMBL142295,TN,INACT,0.0	CHEMBL408493,FP,INACT,0.25999999046325684	CHEMBL160494,TP,ACT,1.0	CHEMBL339806,TP,ACT,1.0	CHEMBL414165,TN,INACT,0.009999999776482582	CHEMBL169827,TP,ACT,1.0	CHEMBL350121,TP,ACT,0.9399999976158142	CHEMBL353088,TN,INACT,0.0	CHEMBL369359,TN,INACT,0.0	CHEMBL3218123,TN,INACT,0.0	CHEMBL338687,TP,ACT,1.0	CHEMBL342256,FP,INACT,0.6299999952316284	CHEMBL280290,TP,ACT,0.9200000166893005	CHEMBL377542,TN,INACT,0.0	CHEMBL32301,TN,INACT,0.0	CHEMBL367095,TP,ACT,0.9100000262260437	CHEMBL446693,TN,INACT,0.0	CHEMBL2113072,TN,INACT,0.0	CHEMBL351550,FP,INACT,0.8299999833106995	CHEMBL320254,TN,INACT,0.0	CHEMBL338889,TP,ACT,1.0	CHEMBL274260,TP,ACT,1.0	CHEMBL304946,TP,ACT,1.0	CHEMBL355443,TP,ACT,1.0	CHEMBL48120,TN,INACT,0.0	CHEMBL350851,TP,ACT,0.9900000095367432	CHEMBL329693,TP,ACT,1.0	CHEMBL279103,TP,ACT,0.9900000095367432	CHEMBL3586317,TN,INACT,0.0	CHEMBL339113,TP,ACT,1.0	CHEMBL62744,TP,ACT,1.0	CHEMBL456675,TN,INACT,0.0	CHEMBL139452,TP,ACT,1.0	CHEMBL34082,TP,ACT,1.0	CHEMBL316655,TP,ACT,1.0	CHEMBL352458,TP,ACT,1.0	CHEMBL42360,TN,INACT,0.0	CHEMBL311386,TP,ACT,1.0	CHEMBL278955,TP,ACT,1.0	CHEMBL444128,TN,INACT,0.0	CHEMBL94355,TP,ACT,1.0	CHEMBL431162,TP,ACT,1.0	CHEMBL124771,TP,ACT,1.0	CHEMBL1765668,TN,INACT,0.009999999776482582	CHEMBL341934,TP,ACT,1.0	CHEMBL292150,TP,ACT,1.0	CHEMBL435792,TP,ACT,1.0	CHEMBL421523,TN,INACT,0.009999999776482582	CHEMBL305647,TP,ACT,1.0	CHEMBL275481,TN,INACT,0.009999999776482582	CHEMBL80532,TN,INACT,0.009999999776482582	CHEMBL10801,TN,INACT,0.029999999329447746	CHEMBL97539,TP,ACT,1.0	CHEMBL80807,TN,INACT,0.0	CHEMBL94176,TP,ACT,0.8199999928474426	CHEMBL339605,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.009999999776482582	CHEMBL40986,TN,INACT,0.009999999776482582	CHEMBL89688,TN,INACT,0.0	CHEMBL97897,TP,ACT,1.0	CHEMBL330533,TP,ACT,1.0	CHEMBL316273,TP,ACT,1.0	CHEMBL314812,TP,ACT,1.0	CHEMBL352947,TP,ACT,1.0	CHEMBL309397,TN,INACT,0.009999999776482582	CHEMBL76360,TN,INACT,0.0	CHEMBL298612,TN,INACT,0.0	CHEMBL110695,TN,INACT,0.0	CHEMBL80180,TN,INACT,0.009999999776482582	CHEMBL35638,TP,ACT,1.0	CHEMBL303204,TN,INACT,0.0	CHEMBL110904,TN,INACT,0.0	CHEMBL407919,TP,ACT,1.0	CHEMBL164395,TP,ACT,1.0	CHEMBL430683,TN,INACT,0.0	CHEMBL343719,TP,ACT,1.0	CHEMBL317962,TP,ACT,1.0	CHEMBL316482,TP,ACT,1.0	CHEMBL2443003,TN,INACT,0.0	CHEMBL2158005,TN,INACT,0.0	CHEMBL291803,TP,ACT,0.38999998569488525	CHEMBL1076625,FP,INACT,0.8399999737739563	CHEMBL271488,TN,INACT,0.0	CHEMBL88663,TP,ACT,1.0	CHEMBL339004,TP,ACT,1.0	CHEMBL342605,TP,ACT,1.0	CHEMBL140006,TN,INACT,0.0	CHEMBL302282,TN,INACT,0.0	CHEMBL169798,TP,ACT,1.0	CHEMBL353087,TN,INACT,0.0	CHEMBL354298,TP,ACT,1.0	

