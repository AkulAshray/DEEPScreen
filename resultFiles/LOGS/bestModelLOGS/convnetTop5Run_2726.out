ImageNetInceptionV2 CHEMBL4828 adam 0.001 30 0 0 0.6 False True
Number of active compounds :	168
Number of inactive compounds :	112
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4828_adam_0.001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4828_adam_0.001_30_0.6/
---------------------------------
Training samples: 179
Validation samples: 56
--
Training Step: 1  | time: 105.190s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/179
[A[ATraining Step: 2  | total loss: [1m[32m0.70941[0m[0m | time: 124.670s
[2K
| Adam | epoch: 001 | loss: 0.70941 - acc: 0.3937 -- iter: 064/179
[A[ATraining Step: 3  | total loss: [1m[32m0.63554[0m[0m | time: 142.330s
[2K
| Adam | epoch: 001 | loss: 0.63554 - acc: 0.6597 -- iter: 096/179
[A[ATraining Step: 4  | total loss: [1m[32m0.73539[0m[0m | time: 157.913s
[2K
| Adam | epoch: 001 | loss: 0.73539 - acc: 0.5868 -- iter: 128/179
[A[ATraining Step: 5  | total loss: [1m[32m0.64698[0m[0m | time: 177.227s
[2K
| Adam | epoch: 001 | loss: 0.64698 - acc: 0.6781 -- iter: 160/179
[A[ATraining Step: 6  | total loss: [1m[32m0.55938[0m[0m | time: 204.380s
[2K
| Adam | epoch: 001 | loss: 0.55938 - acc: 0.7042 | val_loss: 2.33113 - val_acc: 0.5536 -- iter: 179/179
--
Training Step: 7  | total loss: [1m[32m0.49161[0m[0m | time: 13.523s
[2K
| Adam | epoch: 002 | loss: 0.49161 - acc: 0.7870 -- iter: 032/179
[A[ATraining Step: 8  | total loss: [1m[32m0.36291[0m[0m | time: 42.173s
[2K
| Adam | epoch: 002 | loss: 0.36291 - acc: 0.8772 -- iter: 064/179
[A[ATraining Step: 9  | total loss: [1m[32m0.37966[0m[0m | time: 57.650s
[2K
| Adam | epoch: 002 | loss: 0.37966 - acc: 0.8595 -- iter: 096/179
[A[ATraining Step: 10  | total loss: [1m[32m0.36022[0m[0m | time: 77.353s
[2K
| Adam | epoch: 002 | loss: 0.36022 - acc: 0.8516 -- iter: 128/179
[A[ATraining Step: 11  | total loss: [1m[32m0.32357[0m[0m | time: 100.547s
[2K
| Adam | epoch: 002 | loss: 0.32357 - acc: 0.8627 -- iter: 160/179
[A[ATraining Step: 12  | total loss: [1m[32m0.32116[0m[0m | time: 125.589s
[2K
| Adam | epoch: 002 | loss: 0.32116 - acc: 0.8682 | val_loss: 2.83550 - val_acc: 0.5536 -- iter: 179/179
--
Training Step: 13  | total loss: [1m[32m0.38387[0m[0m | time: 10.690s
[2K
| Adam | epoch: 003 | loss: 0.38387 - acc: 0.8443 -- iter: 032/179
[A[ATraining Step: 14  | total loss: [1m[32m0.35415[0m[0m | time: 20.399s
[2K
| Adam | epoch: 003 | loss: 0.35415 - acc: 0.8434 -- iter: 064/179
[A[ATraining Step: 15  | total loss: [1m[32m0.25237[0m[0m | time: 80.192s
[2K
| Adam | epoch: 003 | loss: 0.25237 - acc: 0.9047 -- iter: 096/179
[A[ATraining Step: 16  | total loss: [1m[32m0.22752[0m[0m | time: 162.352s
[2K
| Adam | epoch: 003 | loss: 0.22752 - acc: 0.9170 -- iter: 128/179
[A[ATraining Step: 17  | total loss: [1m[32m0.18896[0m[0m | time: 177.920s
[2K
| Adam | epoch: 003 | loss: 0.18896 - acc: 0.9356 -- iter: 160/179
[A[ATraining Step: 18  | total loss: [1m[32m0.16479[0m[0m | time: 192.755s
[2K
| Adam | epoch: 003 | loss: 0.16479 - acc: 0.9363 | val_loss: 1.38015 - val_acc: 0.5536 -- iter: 179/179
--
Training Step: 19  | total loss: [1m[32m0.14666[0m[0m | time: 10.643s
[2K
| Adam | epoch: 004 | loss: 0.14666 - acc: 0.9471 -- iter: 032/179
[A[ATraining Step: 20  | total loss: [1m[32m0.16667[0m[0m | time: 19.173s
[2K
| Adam | epoch: 004 | loss: 0.16667 - acc: 0.9541 -- iter: 064/179
[A[ATraining Step: 21  | total loss: [1m[32m0.22219[0m[0m | time: 28.991s
[2K
| Adam | epoch: 004 | loss: 0.22219 - acc: 0.9520 -- iter: 096/179
[A[ATraining Step: 22  | total loss: [1m[32m0.18808[0m[0m | time: 43.604s
[2K
| Adam | epoch: 004 | loss: 0.18808 - acc: 0.9506 -- iter: 128/179
[A[ATraining Step: 23  | total loss: [1m[32m0.26279[0m[0m | time: 58.102s
[2K
| Adam | epoch: 004 | loss: 0.26279 - acc: 0.9105 -- iter: 160/179
[A[ATraining Step: 24  | total loss: [1m[32m0.29569[0m[0m | time: 77.020s
[2K
| Adam | epoch: 004 | loss: 0.29569 - acc: 0.9005 | val_loss: 1.11874 - val_acc: 0.4464 -- iter: 179/179
--
Training Step: 25  | total loss: [1m[32m0.29104[0m[0m | time: 16.089s
[2K
| Adam | epoch: 005 | loss: 0.29104 - acc: 0.8936 -- iter: 032/179
[A[ATraining Step: 26  | total loss: [1m[32m0.26387[0m[0m | time: 31.146s
[2K
| Adam | epoch: 005 | loss: 0.26387 - acc: 0.8969 -- iter: 064/179
[A[ATraining Step: 27  | total loss: [1m[32m0.23227[0m[0m | time: 41.629s
[2K
| Adam | epoch: 005 | loss: 0.23227 - acc: 0.9154 -- iter: 096/179
[A[ATraining Step: 28  | total loss: [1m[32m0.25452[0m[0m | time: 51.177s
[2K
| Adam | epoch: 005 | loss: 0.25452 - acc: 0.8839 -- iter: 128/179
[A[ATraining Step: 29  | total loss: [1m[32m0.23935[0m[0m | time: 76.066s
[2K
| Adam | epoch: 005 | loss: 0.23935 - acc: 0.8737 -- iter: 160/179
[A[ATraining Step: 30  | total loss: [1m[32m0.21311[0m[0m | time: 95.466s
[2K
| Adam | epoch: 005 | loss: 0.21311 - acc: 0.8888 | val_loss: 0.92114 - val_acc: 0.4464 -- iter: 179/179
--
Training Step: 31  | total loss: [1m[32m0.18298[0m[0m | time: 14.770s
[2K
| Adam | epoch: 006 | loss: 0.18298 - acc: 0.9145 -- iter: 032/179
[A[ATraining Step: 32  | total loss: [1m[32m0.16502[0m[0m | time: 29.157s
[2K
| Adam | epoch: 006 | loss: 0.16502 - acc: 0.9267 -- iter: 064/179
[A[ATraining Step: 33  | total loss: [1m[32m0.14641[0m[0m | time: 46.504s
[2K
| Adam | epoch: 006 | loss: 0.14641 - acc: 0.9428 -- iter: 096/179
[A[ATraining Step: 34  | total loss: [1m[32m0.12837[0m[0m | time: 56.754s
[2K
| Adam | epoch: 006 | loss: 0.12837 - acc: 0.9551 -- iter: 128/179
[A[ATraining Step: 35  | total loss: [1m[32m0.11837[0m[0m | time: 66.080s
[2K
| Adam | epoch: 006 | loss: 0.11837 - acc: 0.9645 -- iter: 160/179
[A[ATraining Step: 36  | total loss: [1m[32m0.09948[0m[0m | time: 138.336s
[2K
| Adam | epoch: 006 | loss: 0.09948 - acc: 0.9717 | val_loss: 0.73203 - val_acc: 0.4821 -- iter: 179/179
--
Training Step: 37  | total loss: [1m[32m0.13876[0m[0m | time: 41.353s
[2K
| Adam | epoch: 007 | loss: 0.13876 - acc: 0.9649 -- iter: 032/179
[A[ATraining Step: 38  | total loss: [1m[32m0.11552[0m[0m | time: 141.519s
[2K
| Adam | epoch: 007 | loss: 0.11552 - acc: 0.9718 -- iter: 064/179
[A[ATraining Step: 39  | total loss: [1m[32m0.09630[0m[0m | time: 156.979s
[2K
| Adam | epoch: 007 | loss: 0.09630 - acc: 0.9772 -- iter: 096/179
[A[ATraining Step: 40  | total loss: [1m[32m0.09556[0m[0m | time: 168.844s
[2K
| Adam | epoch: 007 | loss: 0.09556 - acc: 0.9756 -- iter: 128/179
[A[ATraining Step: 41  | total loss: [1m[32m0.09405[0m[0m | time: 174.691s
[2K
| Adam | epoch: 007 | loss: 0.09405 - acc: 0.9743 -- iter: 160/179
[A[ATraining Step: 42  | total loss: [1m[32m0.09233[0m[0m | time: 183.420s
[2K
| Adam | epoch: 007 | loss: 0.09233 - acc: 0.9695 | val_loss: 2.71436 - val_acc: 0.4464 -- iter: 179/179
--
Training Step: 43  | total loss: [1m[32m0.07852[0m[0m | time: 13.965s
[2K
| Adam | epoch: 008 | loss: 0.07852 - acc: 0.9749 -- iter: 032/179
[A[ATraining Step: 44  | total loss: [1m[32m0.07695[0m[0m | time: 28.076s
[2K
| Adam | epoch: 008 | loss: 0.07695 - acc: 0.9684 -- iter: 064/179
[A[ATraining Step: 45  | total loss: [1m[32m0.17154[0m[0m | time: 41.728s
[2K
| Adam | epoch: 008 | loss: 0.17154 - acc: 0.9525 -- iter: 096/179
[A[ATraining Step: 46  | total loss: [1m[32m0.14549[0m[0m | time: 55.855s
[2K
| Adam | epoch: 008 | loss: 0.14549 - acc: 0.9604 -- iter: 128/179
[A[ATraining Step: 47  | total loss: [1m[32m0.15629[0m[0m | time: 70.102s
[2K
| Adam | epoch: 008 | loss: 0.15629 - acc: 0.9567 -- iter: 160/179
[A[ATraining Step: 48  | total loss: [1m[32m0.14458[0m[0m | time: 84.920s
[2K
| Adam | epoch: 008 | loss: 0.14458 - acc: 0.9536 | val_loss: 1.49914 - val_acc: 0.4821 -- iter: 179/179
--
Training Step: 49  | total loss: [1m[32m0.12445[0m[0m | time: 10.275s
[2K
| Adam | epoch: 009 | loss: 0.12445 - acc: 0.9609 -- iter: 032/179
[A[ATraining Step: 50  | total loss: [1m[32m0.10927[0m[0m | time: 31.258s
[2K
| Adam | epoch: 009 | loss: 0.10927 - acc: 0.9670 -- iter: 064/179
[A[ATraining Step: 51  | total loss: [1m[32m0.10098[0m[0m | time: 45.299s
[2K
| Adam | epoch: 009 | loss: 0.10098 - acc: 0.9673 -- iter: 096/179
[A[ATraining Step: 52  | total loss: [1m[32m0.08809[0m[0m | time: 62.141s
[2K
| Adam | epoch: 009 | loss: 0.08809 - acc: 0.9722 -- iter: 128/179
[A[ATraining Step: 53  | total loss: [1m[32m0.09772[0m[0m | time: 76.589s
[2K
| Adam | epoch: 009 | loss: 0.09772 - acc: 0.9671 -- iter: 160/179
[A[ATraining Step: 54  | total loss: [1m[32m0.08515[0m[0m | time: 95.791s
[2K
| Adam | epoch: 009 | loss: 0.08515 - acc: 0.9718 | val_loss: 1.85076 - val_acc: 0.4643 -- iter: 179/179
--
Training Step: 55  | total loss: [1m[32m0.07569[0m[0m | time: 9.976s
[2K
| Adam | epoch: 010 | loss: 0.07569 - acc: 0.9759 -- iter: 032/179
[A[ATraining Step: 56  | total loss: [1m[32m0.07222[0m[0m | time: 20.035s
[2K
| Adam | epoch: 010 | loss: 0.07222 - acc: 0.9793 -- iter: 064/179
[A[ATraining Step: 57  | total loss: [1m[32m0.06422[0m[0m | time: 69.248s
[2K
| Adam | epoch: 010 | loss: 0.06422 - acc: 0.9821 -- iter: 096/179
[A[ATraining Step: 58  | total loss: [1m[32m0.07183[0m[0m | time: 84.634s
[2K
| Adam | epoch: 010 | loss: 0.07183 - acc: 0.9803 -- iter: 128/179
[A[ATraining Step: 59  | total loss: [1m[32m0.10744[0m[0m | time: 121.162s
[2K
| Adam | epoch: 010 | loss: 0.10744 - acc: 0.9788 -- iter: 160/179
[A[ATraining Step: 60  | total loss: [1m[32m0.09437[0m[0m | time: 228.552s
[2K
| Adam | epoch: 010 | loss: 0.09437 - acc: 0.9816 | val_loss: 0.78118 - val_acc: 0.7679 -- iter: 179/179
--
Training Step: 61  | total loss: [1m[32m0.09440[0m[0m | time: 89.194s
[2K
| Adam | epoch: 011 | loss: 0.09440 - acc: 0.9799 -- iter: 032/179
[A[ATraining Step: 62  | total loss: [1m[32m0.10361[0m[0m | time: 110.826s
[2K
| Adam | epoch: 011 | loss: 0.10361 - acc: 0.9704 -- iter: 064/179
[A[ATraining Step: 63  | total loss: [1m[32m0.09294[0m[0m | time: 124.308s
[2K
| Adam | epoch: 011 | loss: 0.09294 - acc: 0.9742 -- iter: 096/179
[A[ATraining Step: 64  | total loss: [1m[32m0.08356[0m[0m | time: 168.630s
[2K
| Adam | epoch: 011 | loss: 0.08356 - acc: 0.9774 -- iter: 128/179
[A[ATraining Step: 65  | total loss: [1m[32m0.07606[0m[0m | time: 187.122s
[2K
| Adam | epoch: 011 | loss: 0.07606 - acc: 0.9802 -- iter: 160/179
[A[ATraining Step: 66  | total loss: [1m[32m0.07178[0m[0m | time: 237.168s
[2K
| Adam | epoch: 011 | loss: 0.07178 - acc: 0.9826 | val_loss: 0.55947 - val_acc: 0.8929 -- iter: 179/179
--
Training Step: 67  | total loss: [1m[32m0.06814[0m[0m | time: 26.504s
[2K
| Adam | epoch: 012 | loss: 0.06814 - acc: 0.9847 -- iter: 032/179
[A[ATraining Step: 68  | total loss: [1m[32m0.08196[0m[0m | time: 54.097s
[2K
| Adam | epoch: 012 | loss: 0.08196 - acc: 0.9717 -- iter: 064/179
[A[ATraining Step: 69  | total loss: [1m[32m0.07443[0m[0m | time: 73.772s
[2K
| Adam | epoch: 012 | loss: 0.07443 - acc: 0.9750 -- iter: 096/179
[A[ATraining Step: 70  | total loss: [1m[32m0.06749[0m[0m | time: 88.655s
[2K
| Adam | epoch: 012 | loss: 0.06749 - acc: 0.9779 -- iter: 128/179
[A[ATraining Step: 71  | total loss: [1m[32m0.06438[0m[0m | time: 123.699s
[2K
| Adam | epoch: 012 | loss: 0.06438 - acc: 0.9804 -- iter: 160/179
[A[ATraining Step: 72  | total loss: [1m[32m0.06453[0m[0m | time: 154.679s
[2K
| Adam | epoch: 012 | loss: 0.06453 - acc: 0.9791 | val_loss: 0.50974 - val_acc: 0.8571 -- iter: 179/179
--
Training Step: 73  | total loss: [1m[32m0.06125[0m[0m | time: 20.236s
[2K
| Adam | epoch: 013 | loss: 0.06125 - acc: 0.9814 -- iter: 032/179
[A[ATraining Step: 74  | total loss: [1m[32m0.08063[0m[0m | time: 41.319s
[2K
| Adam | epoch: 013 | loss: 0.08063 - acc: 0.9766 -- iter: 064/179
[A[ATraining Step: 75  | total loss: [1m[32m0.07773[0m[0m | time: 64.148s
[2K
| Adam | epoch: 013 | loss: 0.07773 - acc: 0.9791 -- iter: 096/179
[A[ATraining Step: 76  | total loss: [1m[32m0.07037[0m[0m | time: 77.562s
[2K
| Adam | epoch: 013 | loss: 0.07037 - acc: 0.9814 -- iter: 128/179
[A[ATraining Step: 77  | total loss: [1m[32m0.06348[0m[0m | time: 101.343s
[2K
| Adam | epoch: 013 | loss: 0.06348 - acc: 0.9833 -- iter: 160/179
[A[ATraining Step: 78  | total loss: [1m[32m0.05729[0m[0m | time: 133.199s
[2K
| Adam | epoch: 013 | loss: 0.05729 - acc: 0.9851 | val_loss: 2.03619 - val_acc: 0.6964 -- iter: 179/179
--
Training Step: 79  | total loss: [1m[32m0.05337[0m[0m | time: 18.840s
[2K
| Adam | epoch: 014 | loss: 0.05337 - acc: 0.9866 -- iter: 032/179
[A[ATraining Step: 80  | total loss: [1m[32m0.07449[0m[0m | time: 46.358s
[2K
| Adam | epoch: 014 | loss: 0.07449 - acc: 0.9848 -- iter: 064/179
[A[ATraining Step: 81  | total loss: [1m[32m0.07133[0m[0m | time: 61.475s
[2K
| Adam | epoch: 014 | loss: 0.07133 - acc: 0.9863 -- iter: 096/179
[A[ATraining Step: 82  | total loss: [1m[32m0.06701[0m[0m | time: 94.426s
[2K
| Adam | epoch: 014 | loss: 0.06701 - acc: 0.9877 -- iter: 128/179
[A[ATraining Step: 83  | total loss: [1m[32m0.08202[0m[0m | time: 107.561s
[2K
| Adam | epoch: 014 | loss: 0.08202 - acc: 0.9796 -- iter: 160/179
[A[ATraining Step: 84  | total loss: [1m[32m0.09696[0m[0m | time: 120.503s
[2K
| Adam | epoch: 014 | loss: 0.09696 - acc: 0.9711 | val_loss: 1.47868 - val_acc: 0.6607 -- iter: 179/179
--
Training Step: 85  | total loss: [1m[32m0.09813[0m[0m | time: 36.241s
[2K
| Adam | epoch: 015 | loss: 0.09813 - acc: 0.9687 -- iter: 032/179
[A[ATraining Step: 86  | total loss: [1m[32m0.10305[0m[0m | time: 99.327s
[2K
| Adam | epoch: 015 | loss: 0.10305 - acc: 0.9656 -- iter: 064/179
[A[ATraining Step: 87  | total loss: [1m[32m0.24884[0m[0m | time: 155.837s
[2K
| Adam | epoch: 015 | loss: 0.24884 - acc: 0.9503 -- iter: 096/179
[A[ATraining Step: 88  | total loss: [1m[32m0.22546[0m[0m | time: 177.795s
[2K
| Adam | epoch: 015 | loss: 0.22546 - acc: 0.9552 -- iter: 128/179
[A[ATraining Step: 89  | total loss: [1m[32m0.23141[0m[0m | time: 199.695s
[2K
| Adam | epoch: 015 | loss: 0.23141 - acc: 0.9535 -- iter: 160/179
[A[ATraining Step: 90  | total loss: [1m[32m0.21516[0m[0m | time: 259.449s
[2K
| Adam | epoch: 015 | loss: 0.21516 - acc: 0.9550 | val_loss: 0.57621 - val_acc: 0.7500 -- iter: 179/179
--
Training Step: 91  | total loss: [1m[32m0.21739[0m[0m | time: 12.680s
[2K
| Adam | epoch: 016 | loss: 0.21739 - acc: 0.9490 -- iter: 032/179
[A[ATraining Step: 92  | total loss: [1m[32m0.21412[0m[0m | time: 31.048s
[2K
| Adam | epoch: 016 | loss: 0.21412 - acc: 0.9436 -- iter: 064/179
[A[ATraining Step: 93  | total loss: [1m[32m0.21937[0m[0m | time: 49.696s
[2K
| Adam | epoch: 016 | loss: 0.21937 - acc: 0.9336 -- iter: 096/179
[A[ATraining Step: 94  | total loss: [1m[32m0.33238[0m[0m | time: 68.140s
[2K
| Adam | epoch: 016 | loss: 0.33238 - acc: 0.8996 -- iter: 128/179
[A[ATraining Step: 95  | total loss: [1m[32m0.33513[0m[0m | time: 87.373s
[2K
| Adam | epoch: 016 | loss: 0.33513 - acc: 0.9003 -- iter: 160/179
[A[ATraining Step: 96  | total loss: [1m[32m0.37634[0m[0m | time: 112.279s
[2K
| Adam | epoch: 016 | loss: 0.37634 - acc: 0.8727 | val_loss: 2.04656 - val_acc: 0.5714 -- iter: 179/179
--
Training Step: 97  | total loss: [1m[32m0.40258[0m[0m | time: 12.360s
[2K
| Adam | epoch: 017 | loss: 0.40258 - acc: 0.8605 -- iter: 032/179
[A[ATraining Step: 98  | total loss: [1m[32m0.39061[0m[0m | time: 25.495s
[2K
| Adam | epoch: 017 | loss: 0.39061 - acc: 0.8691 -- iter: 064/179
[A[ATraining Step: 99  | total loss: [1m[32m0.37691[0m[0m | time: 44.224s
[2K
| Adam | epoch: 017 | loss: 0.37691 - acc: 0.8717 -- iter: 096/179
[A[ATraining Step: 100  | total loss: [1m[32m0.37215[0m[0m | time: 64.767s
[2K
| Adam | epoch: 017 | loss: 0.37215 - acc: 0.8720 -- iter: 128/179
[A[ATraining Step: 101  | total loss: [1m[32m0.40061[0m[0m | time: 84.088s
[2K
| Adam | epoch: 017 | loss: 0.40061 - acc: 0.8630 -- iter: 160/179
[A[ATraining Step: 102  | total loss: [1m[32m0.38293[0m[0m | time: 110.476s
[2K
| Adam | epoch: 017 | loss: 0.38293 - acc: 0.8735 | val_loss: 4.36773 - val_acc: 0.5536 -- iter: 179/179
--
Training Step: 103  | total loss: [1m[32m0.37080[0m[0m | time: 21.504s
[2K
| Adam | epoch: 018 | loss: 0.37080 - acc: 0.8737 -- iter: 032/179
[A[ATraining Step: 104  | total loss: [1m[32m0.34813[0m[0m | time: 33.741s
[2K
| Adam | epoch: 018 | loss: 0.34813 - acc: 0.8863 -- iter: 064/179
[A[ATraining Step: 105  | total loss: [1m[32m0.33883[0m[0m | time: 50.728s
[2K
| Adam | epoch: 018 | loss: 0.33883 - acc: 0.8819 -- iter: 096/179
[A[ATraining Step: 106  | total loss: [1m[32m0.32051[0m[0m | time: 69.350s
[2K
| Adam | epoch: 018 | loss: 0.32051 - acc: 0.8937 -- iter: 128/179
[A[ATraining Step: 107  | total loss: [1m[32m0.30744[0m[0m | time: 89.695s
[2K
| Adam | epoch: 018 | loss: 0.30744 - acc: 0.9012 -- iter: 160/179
[A[ATraining Step: 108  | total loss: [1m[32m0.31349[0m[0m | time: 120.284s
[2K
| Adam | epoch: 018 | loss: 0.31349 - acc: 0.9017 | val_loss: 0.38619 - val_acc: 0.8393 -- iter: 179/179
--
Training Step: 109  | total loss: [1m[32m0.28737[0m[0m | time: 15.120s
[2K
| Adam | epoch: 019 | loss: 0.28737 - acc: 0.9115 -- iter: 032/179
[A[ATraining Step: 110  | total loss: [1m[32m0.26556[0m[0m | time: 27.825s
[2K
| Adam | epoch: 019 | loss: 0.26556 - acc: 0.9204 -- iter: 064/179
[A[ATraining Step: 111  | total loss: [1m[32m0.24552[0m[0m | time: 37.016s
[2K
| Adam | epoch: 019 | loss: 0.24552 - acc: 0.9283 -- iter: 096/179
[A[ATraining Step: 112  | total loss: [1m[32m0.23043[0m[0m | time: 47.582s
[2K
| Adam | epoch: 019 | loss: 0.23043 - acc: 0.9355 -- iter: 128/179
[A[ATraining Step: 113  | total loss: [1m[32m0.21218[0m[0m | time: 65.320s
[2K
| Adam | epoch: 019 | loss: 0.21218 - acc: 0.9420 -- iter: 160/179
[A[ATraining Step: 114  | total loss: [1m[32m0.19488[0m[0m | time: 89.675s
[2K
| Adam | epoch: 019 | loss: 0.19488 - acc: 0.9478 | val_loss: 0.33695 - val_acc: 0.8214 -- iter: 179/179
--
Training Step: 115  | total loss: [1m[32m0.17718[0m[0m | time: 31.503s
[2K
| Adam | epoch: 020 | loss: 0.17718 - acc: 0.9530 -- iter: 032/179
[A[ATraining Step: 116  | total loss: [1m[32m0.16133[0m[0m | time: 50.413s
[2K
| Adam | epoch: 020 | loss: 0.16133 - acc: 0.9577 -- iter: 064/179
[A[ATraining Step: 117  | total loss: [1m[32m0.15017[0m[0m | time: 69.413s
[2K
| Adam | epoch: 020 | loss: 0.15017 - acc: 0.9588 -- iter: 096/179
[A[ATraining Step: 118  | total loss: [1m[32m0.13691[0m[0m | time: 81.538s
[2K
| Adam | epoch: 020 | loss: 0.13691 - acc: 0.9629 -- iter: 128/179
[A[ATraining Step: 119  | total loss: [1m[32m0.12472[0m[0m | time: 93.688s
[2K
| Adam | epoch: 020 | loss: 0.12472 - acc: 0.9666 -- iter: 160/179
[A[ATraining Step: 120  | total loss: [1m[32m0.11325[0m[0m | time: 119.346s
[2K
| Adam | epoch: 020 | loss: 0.11325 - acc: 0.9700 | val_loss: 0.37306 - val_acc: 0.8214 -- iter: 179/179
--
Training Step: 121  | total loss: [1m[32m0.10304[0m[0m | time: 19.383s
[2K
| Adam | epoch: 021 | loss: 0.10304 - acc: 0.9730 -- iter: 032/179
[A[ATraining Step: 122  | total loss: [1m[32m0.11258[0m[0m | time: 37.973s
[2K
| Adam | epoch: 021 | loss: 0.11258 - acc: 0.9725 -- iter: 064/179
[A[ATraining Step: 123  | total loss: [1m[32m0.10220[0m[0m | time: 56.849s
[2K
| Adam | epoch: 021 | loss: 0.10220 - acc: 0.9753 -- iter: 096/179
[A[ATraining Step: 124  | total loss: [1m[32m0.09463[0m[0m | time: 76.239s
[2K
| Adam | epoch: 021 | loss: 0.09463 - acc: 0.9778 -- iter: 128/179
[A[ATraining Step: 125  | total loss: [1m[32m0.08651[0m[0m | time: 88.278s
[2K
| Adam | epoch: 021 | loss: 0.08651 - acc: 0.9800 -- iter: 160/179
[A[ATraining Step: 126  | total loss: [1m[32m0.07919[0m[0m | time: 106.744s
[2K
| Adam | epoch: 021 | loss: 0.07919 - acc: 0.9820 | val_loss: 0.54051 - val_acc: 0.7857 -- iter: 179/179
--
Training Step: 127  | total loss: [1m[32m0.07211[0m[0m | time: 18.880s
[2K
| Adam | epoch: 022 | loss: 0.07211 - acc: 0.9838 -- iter: 032/179
[A[ATraining Step: 128  | total loss: [1m[32m0.06791[0m[0m | time: 38.487s
[2K
| Adam | epoch: 022 | loss: 0.06791 - acc: 0.9854 -- iter: 064/179
[A[ATraining Step: 129  | total loss: [1m[32m0.06181[0m[0m | time: 61.899s
[2K
| Adam | epoch: 022 | loss: 0.06181 - acc: 0.9869 -- iter: 096/179
[A[ATraining Step: 130  | total loss: [1m[32m0.05605[0m[0m | time: 83.106s
[2K
| Adam | epoch: 022 | loss: 0.05605 - acc: 0.9882 -- iter: 128/179
[A[ATraining Step: 131  | total loss: [1m[32m0.05110[0m[0m | time: 102.783s
[2K
| Adam | epoch: 022 | loss: 0.05110 - acc: 0.9894 -- iter: 160/179
[A[ATraining Step: 132  | total loss: [1m[32m0.04985[0m[0m | time: 116.449s
[2K
| Adam | epoch: 022 | loss: 0.04985 - acc: 0.9873 | val_loss: 0.58031 - val_acc: 0.8036 -- iter: 179/179
--
Training Step: 133  | total loss: [1m[32m0.04573[0m[0m | time: 12.353s
[2K
| Adam | epoch: 023 | loss: 0.04573 - acc: 0.9886 -- iter: 032/179
[A[ATraining Step: 134  | total loss: [1m[32m0.04218[0m[0m | time: 32.272s
[2K
| Adam | epoch: 023 | loss: 0.04218 - acc: 0.9897 -- iter: 064/179
[A[ATraining Step: 135  | total loss: [1m[32m0.04606[0m[0m | time: 50.157s
[2K
| Adam | epoch: 023 | loss: 0.04606 - acc: 0.9845 -- iter: 096/179
[A[ATraining Step: 136  | total loss: [1m[32m0.08968[0m[0m | time: 64.223s
[2K
| Adam | epoch: 023 | loss: 0.08968 - acc: 0.9798 -- iter: 128/179
[A[ATraining Step: 137  | total loss: [1m[32m0.08398[0m[0m | time: 77.490s
[2K
| Adam | epoch: 023 | loss: 0.08398 - acc: 0.9818 -- iter: 160/179
[A[ATraining Step: 138  | total loss: [1m[32m0.08204[0m[0m | time: 100.029s
[2K
| Adam | epoch: 023 | loss: 0.08204 - acc: 0.9805 | val_loss: 1.11008 - val_acc: 0.7857 -- iter: 179/179
--
Training Step: 139  | total loss: [1m[32m0.07555[0m[0m | time: 12.519s
[2K
| Adam | epoch: 024 | loss: 0.07555 - acc: 0.9825 -- iter: 032/179
[A[ATraining Step: 140  | total loss: [1m[32m0.06849[0m[0m | time: 24.962s
[2K
| Adam | epoch: 024 | loss: 0.06849 - acc: 0.9842 -- iter: 064/179
[A[ATraining Step: 141  | total loss: [1m[32m0.06207[0m[0m | time: 44.220s
[2K
| Adam | epoch: 024 | loss: 0.06207 - acc: 0.9858 -- iter: 096/179
[A[ATraining Step: 142  | total loss: [1m[32m0.05647[0m[0m | time: 60.550s
[2K
| Adam | epoch: 024 | loss: 0.05647 - acc: 0.9872 -- iter: 128/179
[A[ATraining Step: 143  | total loss: [1m[32m0.28512[0m[0m | time: 77.255s
[2K
| Adam | epoch: 024 | loss: 0.28512 - acc: 0.9604 -- iter: 160/179
[A[ATraining Step: 144  | total loss: [1m[32m0.25868[0m[0m | time: 102.583s
[2K
| Adam | epoch: 024 | loss: 0.25868 - acc: 0.9643 | val_loss: 4.99123 - val_acc: 0.4286 -- iter: 179/179
--
Training Step: 145  | total loss: [1m[32m0.24509[0m[0m | time: 18.453s
[2K
| Adam | epoch: 025 | loss: 0.24509 - acc: 0.9648 -- iter: 032/179
[A[ATraining Step: 146  | total loss: [1m[32m0.22496[0m[0m | time: 30.787s
[2K
| Adam | epoch: 025 | loss: 0.22496 - acc: 0.9683 -- iter: 064/179
[A[ATraining Step: 147  | total loss: [1m[32m0.21271[0m[0m | time: 43.139s
[2K
| Adam | epoch: 025 | loss: 0.21271 - acc: 0.9662 -- iter: 096/179
[A[ATraining Step: 148  | total loss: [1m[32m0.19798[0m[0m | time: 61.186s
[2K
| Adam | epoch: 025 | loss: 0.19798 - acc: 0.9696 -- iter: 128/179
[A[ATraining Step: 149  | total loss: [1m[32m0.18856[0m[0m | time: 79.893s
[2K
| Adam | epoch: 025 | loss: 0.18856 - acc: 0.9664 -- iter: 160/179
[A[ATraining Step: 150  | total loss: [1m[32m0.21826[0m[0m | time: 105.092s
[2K
| Adam | epoch: 025 | loss: 0.21826 - acc: 0.9604 | val_loss: 0.47885 - val_acc: 0.8393 -- iter: 179/179
--
Training Step: 151  | total loss: [1m[32m0.19871[0m[0m | time: 19.075s
[2K
| Adam | epoch: 026 | loss: 0.19871 - acc: 0.9643 -- iter: 032/179
[A[ATraining Step: 152  | total loss: [1m[32m0.18558[0m[0m | time: 37.226s
[2K
| Adam | epoch: 026 | loss: 0.18558 - acc: 0.9679 -- iter: 064/179
[A[ATraining Step: 153  | total loss: [1m[32m0.17354[0m[0m | time: 49.498s
[2K
| Adam | epoch: 026 | loss: 0.17354 - acc: 0.9680 -- iter: 096/179
[A[ATraining Step: 154  | total loss: [1m[32m0.16690[0m[0m | time: 62.345s
[2K
| Adam | epoch: 026 | loss: 0.16690 - acc: 0.9659 -- iter: 128/179
[A[ATraining Step: 155  | total loss: [1m[32m0.15881[0m[0m | time: 80.666s
[2K
| Adam | epoch: 026 | loss: 0.15881 - acc: 0.9693 -- iter: 160/179
[A[ATraining Step: 156  | total loss: [1m[32m0.15424[0m[0m | time: 105.569s
[2K
| Adam | epoch: 026 | loss: 0.15424 - acc: 0.9693 | val_loss: 0.61762 - val_acc: 0.6786 -- iter: 179/179
--
Training Step: 157  | total loss: [1m[32m0.32654[0m[0m | time: 15.494s
[2K
| Adam | epoch: 027 | loss: 0.32654 - acc: 0.9317 -- iter: 032/179
[A[ATraining Step: 158  | total loss: [1m[32m0.30028[0m[0m | time: 33.998s
[2K
| Adam | epoch: 027 | loss: 0.30028 - acc: 0.9385 -- iter: 064/179
[A[ATraining Step: 159  | total loss: [1m[32m0.27548[0m[0m | time: 52.658s
[2K
| Adam | epoch: 027 | loss: 0.27548 - acc: 0.9447 -- iter: 096/179
[A[ATraining Step: 160  | total loss: [1m[32m0.25412[0m[0m | time: 65.472s
[2K
| Adam | epoch: 027 | loss: 0.25412 - acc: 0.9502 -- iter: 128/179
[A[ATraining Step: 161  | total loss: [1m[32m0.24227[0m[0m | time: 75.072s
[2K
| Adam | epoch: 027 | loss: 0.24227 - acc: 0.9499 -- iter: 160/179
[A[ATraining Step: 162  | total loss: [1m[32m0.22847[0m[0m | time: 93.944s
[2K
| Adam | epoch: 027 | loss: 0.22847 - acc: 0.9549 | val_loss: 0.45800 - val_acc: 0.7857 -- iter: 179/179
--
Training Step: 163  | total loss: [1m[32m0.21157[0m[0m | time: 18.357s
[2K
| Adam | epoch: 028 | loss: 0.21157 - acc: 0.9594 -- iter: 032/179
[A[ATraining Step: 164  | total loss: [1m[32m0.22621[0m[0m | time: 36.967s
[2K
| Adam | epoch: 028 | loss: 0.22621 - acc: 0.9573 -- iter: 064/179
[A[ATraining Step: 165  | total loss: [1m[32m0.21211[0m[0m | time: 55.750s
[2K
| Adam | epoch: 028 | loss: 0.21211 - acc: 0.9615 -- iter: 096/179
[A[ATraining Step: 166  | total loss: [1m[32m0.19884[0m[0m | time: 74.613s
[2K
| Adam | epoch: 028 | loss: 0.19884 - acc: 0.9654 -- iter: 128/179
[A[ATraining Step: 167  | total loss: [1m[32m0.18601[0m[0m | time: 87.437s
[2K
| Adam | epoch: 028 | loss: 0.18601 - acc: 0.9688 -- iter: 160/179
[A[ATraining Step: 168  | total loss: [1m[32m0.17405[0m[0m | time: 106.366s
[2K
| Adam | epoch: 028 | loss: 0.17405 - acc: 0.9720 | val_loss: 0.34948 - val_acc: 0.8393 -- iter: 179/179
--
Training Step: 169  | total loss: [1m[32m0.16186[0m[0m | time: 18.854s
[2K
| Adam | epoch: 029 | loss: 0.16186 - acc: 0.9748 -- iter: 032/179
[A[ATraining Step: 170  | total loss: [1m[32m0.15083[0m[0m | time: 37.543s
[2K
| Adam | epoch: 029 | loss: 0.15083 - acc: 0.9773 -- iter: 064/179
[A[ATraining Step: 171  | total loss: [1m[32m0.15350[0m[0m | time: 56.610s
[2K
| Adam | epoch: 029 | loss: 0.15350 - acc: 0.9764 -- iter: 096/179
[A[ATraining Step: 172  | total loss: [1m[32m0.14194[0m[0m | time: 75.493s
[2K
| Adam | epoch: 029 | loss: 0.14194 - acc: 0.9788 -- iter: 128/179
[A[ATraining Step: 173  | total loss: [1m[32m0.13044[0m[0m | time: 94.506s
[2K
| Adam | epoch: 029 | loss: 0.13044 - acc: 0.9809 -- iter: 160/179
[A[ATraining Step: 174  | total loss: [1m[32m0.11982[0m[0m | time: 112.724s
[2K
| Adam | epoch: 029 | loss: 0.11982 - acc: 0.9828 | val_loss: 0.39889 - val_acc: 0.8571 -- iter: 179/179
--
Training Step: 175  | total loss: [1m[32m0.11016[0m[0m | time: 12.254s
[2K
| Adam | epoch: 030 | loss: 0.11016 - acc: 0.9845 -- iter: 032/179
[A[ATraining Step: 176  | total loss: [1m[32m0.10129[0m[0m | time: 31.123s
[2K
| Adam | epoch: 030 | loss: 0.10129 - acc: 0.9861 -- iter: 064/179
[A[ATraining Step: 177  | total loss: [1m[32m0.09319[0m[0m | time: 50.316s
[2K
| Adam | epoch: 030 | loss: 0.09319 - acc: 0.9875 -- iter: 096/179
[A[ATraining Step: 178  | total loss: [1m[32m0.09984[0m[0m | time: 70.139s
[2K
| Adam | epoch: 030 | loss: 0.09984 - acc: 0.9856 -- iter: 128/179
[A[ATraining Step: 179  | total loss: [1m[32m0.09201[0m[0m | time: 88.945s
[2K
| Adam | epoch: 030 | loss: 0.09201 - acc: 0.9870 -- iter: 160/179
[A[ATraining Step: 180  | total loss: [1m[32m0.08396[0m[0m | time: 108.020s
[2K
| Adam | epoch: 030 | loss: 0.08396 - acc: 0.9883 | val_loss: 0.32456 - val_acc: 0.8929 -- iter: 179/179
--
Validation AUC:0.9535483870967743
Validation AUPRC:0.9627003652131101
Test AUC:0.889795918367347
Test AUPRC:0.9058143696668919
BestTestF1Score	0.92	0.77	0.89	0.89	0.94	33	4	17	2	0.49
BestTestMCCScore	0.92	0.77	0.89	0.89	0.94	33	4	17	2	0.49
BestTestAccuracyScore	0.92	0.77	0.89	0.89	0.94	33	4	17	2	0.49
BestValidationF1Score	0.92	0.82	0.91	0.93	0.9	28	2	23	3	0.49
BestValidationMCC	0.92	0.82	0.91	0.93	0.9	28	2	23	3	0.49
BestValidationAccuracy	0.92	0.82	0.91	0.93	0.9	28	2	23	3	0.49
TestPredictions (Threshold:0.49)
CHEMBL372435,TP,ACT,1.0	CHEMBL597270,TP,ACT,0.6000000238418579	CHEMBL3133797,TP,ACT,0.9700000286102295	CHEMBL611,TN,INACT,0.33000001311302185	CHEMBL494865,TN,INACT,0.009999999776482582	CHEMBL3809513,TP,ACT,0.9700000286102295	CHEMBL89233,TN,INACT,0.009999999776482582	CHEMBL425617,TP,ACT,0.9900000095367432	CHEMBL370014,FN,ACT,0.05000000074505806	CHEMBL1237044,TN,INACT,0.029999999329447746	CHEMBL3810004,TP,ACT,1.0	CHEMBL500548,TP,ACT,1.0	CHEMBL454769,TP,ACT,1.0	CHEMBL55,FP,INACT,1.0	CHEMBL567232,TP,ACT,1.0	CHEMBL3133799,TP,ACT,0.9700000286102295	CHEMBL461,TN,INACT,0.009999999776482582	CHEMBL3809875,TP,ACT,0.9200000166893005	CHEMBL168464,TN,INACT,0.009999999776482582	CHEMBL3133783,TP,ACT,1.0	CHEMBL3809090,TP,ACT,0.9900000095367432	CHEMBL597067,TP,ACT,0.9200000166893005	CHEMBL86,TN,INACT,0.3499999940395355	CHEMBL2442144,TP,ACT,1.0	CHEMBL3133792,FP,INACT,1.0	CHEMBL496752,TN,INACT,0.23999999463558197	CHEMBL273074,TN,INACT,0.019999999552965164	CHEMBL599081,TP,ACT,1.0	CHEMBL2391615,TN,INACT,0.05000000074505806	CHEMBL27,TN,INACT,0.03999999910593033	CHEMBL213148,TP,ACT,0.9900000095367432	CHEMBL3793720,TP,ACT,1.0	CHEMBL2381727,TP,ACT,0.8899999856948853	CHEMBL3133786,TP,ACT,1.0	CHEMBL190319,TP,ACT,0.6600000262260437	CHEMBL757,TN,INACT,0.019999999552965164	CHEMBL1201201,FN,ACT,0.009999999776482582	CHEMBL3809073,TP,ACT,0.949999988079071	CHEMBL597297,TP,ACT,0.9900000095367432	CHEMBL217815,TP,ACT,1.0	CHEMBL596683,TP,ACT,1.0	CHEMBL841,FP,INACT,0.699999988079071	CHEMBL84,FP,INACT,0.75	CHEMBL3793365,TP,ACT,1.0	CHEMBL3133700,TP,ACT,1.0	CHEMBL2442146,TP,ACT,1.0	CHEMBL3133790,TP,ACT,1.0	CHEMBL271567,TN,INACT,0.009999999776482582	CHEMBL496543,TN,INACT,0.3799999952316284	CHEMBL536788,TN,INACT,0.009999999776482582	CHEMBL517956,TN,INACT,0.25999999046325684	CHEMBL2391621,TN,INACT,0.0	CHEMBL569075,TP,ACT,0.75	CHEMBL509644,TP,ACT,1.0	CHEMBL2381723,TP,ACT,1.0	CHEMBL599268,TP,ACT,0.9399999976158142	

