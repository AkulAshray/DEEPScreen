CNNModel CHEMBL2034 adam 0.001 15 128 0 0.8 False True
Number of active compounds :	1149
Number of inactive compounds :	766
---------------------------------
Run id: CNNModel_CHEMBL2034_adam_0.001_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2034_adam_0.001_15_128_0.8_True/
---------------------------------
Training samples: 1170
Validation samples: 366
--
Training Step: 1  | time: 1.481s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1170
[A[ATraining Step: 2  | total loss: [1m[32m0.62365[0m[0m | time: 2.361s
[2K
| Adam | epoch: 001 | loss: 0.62365 - acc: 0.5062 -- iter: 0064/1170
[A[ATraining Step: 3  | total loss: [1m[32m0.67806[0m[0m | time: 3.387s
[2K
| Adam | epoch: 001 | loss: 0.67806 - acc: 0.5523 -- iter: 0096/1170
[A[ATraining Step: 4  | total loss: [1m[32m0.68762[0m[0m | time: 4.573s
[2K
| Adam | epoch: 001 | loss: 0.68762 - acc: 0.5365 -- iter: 0128/1170
[A[ATraining Step: 5  | total loss: [1m[32m0.67518[0m[0m | time: 5.897s
[2K
| Adam | epoch: 001 | loss: 0.67518 - acc: 0.5978 -- iter: 0160/1170
[A[ATraining Step: 6  | total loss: [1m[32m0.70605[0m[0m | time: 6.761s
[2K
| Adam | epoch: 001 | loss: 0.70605 - acc: 0.5148 -- iter: 0192/1170
[A[ATraining Step: 7  | total loss: [1m[32m0.68840[0m[0m | time: 7.700s
[2K
| Adam | epoch: 001 | loss: 0.68840 - acc: 0.5622 -- iter: 0224/1170
[A[ATraining Step: 8  | total loss: [1m[32m0.69100[0m[0m | time: 8.646s
[2K
| Adam | epoch: 001 | loss: 0.69100 - acc: 0.5448 -- iter: 0256/1170
[A[ATraining Step: 9  | total loss: [1m[32m0.68661[0m[0m | time: 9.574s
[2K
| Adam | epoch: 001 | loss: 0.68661 - acc: 0.5707 -- iter: 0288/1170
[A[ATraining Step: 10  | total loss: [1m[32m0.69931[0m[0m | time: 10.583s
[2K
| Adam | epoch: 001 | loss: 0.69931 - acc: 0.4572 -- iter: 0320/1170
[A[ATraining Step: 11  | total loss: [1m[32m0.68789[0m[0m | time: 11.668s
[2K
| Adam | epoch: 001 | loss: 0.68789 - acc: 0.5959 -- iter: 0352/1170
[A[ATraining Step: 12  | total loss: [1m[32m0.68952[0m[0m | time: 12.500s
[2K
| Adam | epoch: 001 | loss: 0.68952 - acc: 0.5668 -- iter: 0384/1170
[A[ATraining Step: 13  | total loss: [1m[32m0.68953[0m[0m | time: 13.516s
[2K
| Adam | epoch: 001 | loss: 0.68953 - acc: 0.5650 -- iter: 0416/1170
[A[ATraining Step: 14  | total loss: [1m[32m0.68600[0m[0m | time: 14.604s
[2K
| Adam | epoch: 001 | loss: 0.68600 - acc: 0.6151 -- iter: 0448/1170
[A[ATraining Step: 15  | total loss: [1m[32m0.68263[0m[0m | time: 15.908s
[2K
| Adam | epoch: 001 | loss: 0.68263 - acc: 0.6434 -- iter: 0480/1170
[A[ATraining Step: 16  | total loss: [1m[32m0.68459[0m[0m | time: 16.760s
[2K
| Adam | epoch: 001 | loss: 0.68459 - acc: 0.6131 -- iter: 0512/1170
[A[ATraining Step: 17  | total loss: [1m[32m0.68470[0m[0m | time: 17.695s
[2K
| Adam | epoch: 001 | loss: 0.68470 - acc: 0.5949 -- iter: 0544/1170
[A[ATraining Step: 18  | total loss: [1m[32m0.68223[0m[0m | time: 18.657s
[2K
| Adam | epoch: 001 | loss: 0.68223 - acc: 0.5945 -- iter: 0576/1170
[A[ATraining Step: 19  | total loss: [1m[32m0.68323[0m[0m | time: 19.612s
[2K
| Adam | epoch: 001 | loss: 0.68323 - acc: 0.5838 -- iter: 0608/1170
[A[ATraining Step: 20  | total loss: [1m[32m0.69358[0m[0m | time: 20.671s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.5468 -- iter: 0640/1170
[A[ATraining Step: 21  | total loss: [1m[32m0.70448[0m[0m | time: 21.733s
[2K
| Adam | epoch: 001 | loss: 0.70448 - acc: 0.5129 -- iter: 0672/1170
[A[ATraining Step: 22  | total loss: [1m[32m0.69121[0m[0m | time: 22.601s
[2K
| Adam | epoch: 001 | loss: 0.69121 - acc: 0.5559 -- iter: 0704/1170
[A[ATraining Step: 23  | total loss: [1m[32m0.69726[0m[0m | time: 23.594s
[2K
| Adam | epoch: 001 | loss: 0.69726 - acc: 0.5215 -- iter: 0736/1170
[A[ATraining Step: 24  | total loss: [1m[32m0.69036[0m[0m | time: 24.685s
[2K
| Adam | epoch: 001 | loss: 0.69036 - acc: 0.5506 -- iter: 0768/1170
[A[ATraining Step: 25  | total loss: [1m[32m0.68908[0m[0m | time: 25.962s
[2K
| Adam | epoch: 001 | loss: 0.68908 - acc: 0.5539 -- iter: 0800/1170
[A[ATraining Step: 26  | total loss: [1m[32m0.68325[0m[0m | time: 26.893s
[2K
| Adam | epoch: 001 | loss: 0.68325 - acc: 0.5892 -- iter: 0832/1170
[A[ATraining Step: 27  | total loss: [1m[32m0.68144[0m[0m | time: 27.789s
[2K
| Adam | epoch: 001 | loss: 0.68144 - acc: 0.5984 -- iter: 0864/1170
[A[ATraining Step: 28  | total loss: [1m[32m0.68762[0m[0m | time: 28.719s
[2K
| Adam | epoch: 001 | loss: 0.68762 - acc: 0.5582 -- iter: 0896/1170
[A[ATraining Step: 29  | total loss: [1m[32m0.68448[0m[0m | time: 29.685s
[2K
| Adam | epoch: 001 | loss: 0.68448 - acc: 0.5745 -- iter: 0928/1170
[A[ATraining Step: 30  | total loss: [1m[32m0.68314[0m[0m | time: 30.723s
[2K
| Adam | epoch: 001 | loss: 0.68314 - acc: 0.5790 -- iter: 0960/1170
[A[ATraining Step: 31  | total loss: [1m[32m0.69413[0m[0m | time: 31.740s
[2K
| Adam | epoch: 001 | loss: 0.69413 - acc: 0.5247 -- iter: 0992/1170
[A[ATraining Step: 32  | total loss: [1m[32m0.68932[0m[0m | time: 32.676s
[2K
| Adam | epoch: 001 | loss: 0.68932 - acc: 0.5473 -- iter: 1024/1170
[A[ATraining Step: 33  | total loss: [1m[32m0.69101[0m[0m | time: 33.710s
[2K
| Adam | epoch: 001 | loss: 0.69101 - acc: 0.5369 -- iter: 1056/1170
[A[ATraining Step: 34  | total loss: [1m[32m0.69087[0m[0m | time: 34.848s
[2K
| Adam | epoch: 001 | loss: 0.69087 - acc: 0.5357 -- iter: 1088/1170
[A[ATraining Step: 35  | total loss: [1m[32m0.68109[0m[0m | time: 36.148s
[2K
| Adam | epoch: 001 | loss: 0.68109 - acc: 0.5871 -- iter: 1120/1170
[A[ATraining Step: 36  | total loss: [1m[32m0.68084[0m[0m | time: 37.022s
[2K
| Adam | epoch: 001 | loss: 0.68084 - acc: 0.5885 -- iter: 1152/1170
[A[ATraining Step: 37  | total loss: [1m[32m0.67956[0m[0m | time: 39.462s
[2K
| Adam | epoch: 001 | loss: 0.67956 - acc: 0.5895 | val_loss: 0.67081 - val_acc: 0.5984 -- iter: 1170/1170
--
Training Step: 38  | total loss: [1m[32m0.67386[0m[0m | time: 0.522s
[2K
| Adam | epoch: 002 | loss: 0.67386 - acc: 0.6046 -- iter: 0032/1170
[A[ATraining Step: 39  | total loss: [1m[32m0.66878[0m[0m | time: 1.534s
[2K
| Adam | epoch: 002 | loss: 0.66878 - acc: 0.6165 -- iter: 0064/1170
[A[ATraining Step: 40  | total loss: [1m[32m0.66011[0m[0m | time: 2.548s
[2K
| Adam | epoch: 002 | loss: 0.66011 - acc: 0.6298 -- iter: 0096/1170
[A[ATraining Step: 41  | total loss: [1m[32m0.67339[0m[0m | time: 3.621s
[2K
| Adam | epoch: 002 | loss: 0.67339 - acc: 0.6174 -- iter: 0128/1170
[A[ATraining Step: 42  | total loss: [1m[32m0.68121[0m[0m | time: 4.661s
[2K
| Adam | epoch: 002 | loss: 0.68121 - acc: 0.6076 -- iter: 0160/1170
[A[ATraining Step: 43  | total loss: [1m[32m0.68008[0m[0m | time: 5.724s
[2K
| Adam | epoch: 002 | loss: 0.68008 - acc: 0.6051 -- iter: 0192/1170
[A[ATraining Step: 44  | total loss: [1m[32m0.68566[0m[0m | time: 6.798s
[2K
| Adam | epoch: 002 | loss: 0.68566 - acc: 0.5869 -- iter: 0224/1170
[A[ATraining Step: 45  | total loss: [1m[32m0.68496[0m[0m | time: 7.772s
[2K
| Adam | epoch: 002 | loss: 0.68496 - acc: 0.5828 -- iter: 0256/1170
[A[ATraining Step: 46  | total loss: [1m[32m0.68163[0m[0m | time: 8.847s
[2K
| Adam | epoch: 002 | loss: 0.68163 - acc: 0.5950 -- iter: 0288/1170
[A[ATraining Step: 47  | total loss: [1m[32m0.68380[0m[0m | time: 9.791s
[2K
| Adam | epoch: 002 | loss: 0.68380 - acc: 0.5795 -- iter: 0320/1170
[A[ATraining Step: 48  | total loss: [1m[32m0.68208[0m[0m | time: 10.716s
[2K
| Adam | epoch: 002 | loss: 0.68208 - acc: 0.5918 -- iter: 0352/1170
[A[ATraining Step: 49  | total loss: [1m[32m0.68032[0m[0m | time: 11.389s
[2K
| Adam | epoch: 002 | loss: 0.68032 - acc: 0.6069 -- iter: 0384/1170
[A[ATraining Step: 50  | total loss: [1m[32m0.68362[0m[0m | time: 12.001s
[2K
| Adam | epoch: 002 | loss: 0.68362 - acc: 0.5806 -- iter: 0416/1170
[A[ATraining Step: 51  | total loss: [1m[32m0.68580[0m[0m | time: 12.622s
[2K
| Adam | epoch: 002 | loss: 0.68580 - acc: 0.5636 -- iter: 0448/1170
[A[ATraining Step: 52  | total loss: [1m[32m0.68717[0m[0m | time: 13.248s
[2K
| Adam | epoch: 002 | loss: 0.68717 - acc: 0.5540 -- iter: 0480/1170
[A[ATraining Step: 53  | total loss: [1m[32m0.68818[0m[0m | time: 13.872s
[2K
| Adam | epoch: 002 | loss: 0.68818 - acc: 0.5461 -- iter: 0512/1170
[A[ATraining Step: 54  | total loss: [1m[32m0.68710[0m[0m | time: 14.483s
[2K
| Adam | epoch: 002 | loss: 0.68710 - acc: 0.5575 -- iter: 0544/1170
[A[ATraining Step: 55  | total loss: [1m[32m0.68588[0m[0m | time: 15.083s
[2K
| Adam | epoch: 002 | loss: 0.68588 - acc: 0.5716 -- iter: 0576/1170
[A[ATraining Step: 56  | total loss: [1m[32m0.68565[0m[0m | time: 15.688s
[2K
| Adam | epoch: 002 | loss: 0.68565 - acc: 0.5747 -- iter: 0608/1170
[A[ATraining Step: 57  | total loss: [1m[32m0.68595[0m[0m | time: 16.324s
[2K
| Adam | epoch: 002 | loss: 0.68595 - acc: 0.5730 -- iter: 0640/1170
[A[ATraining Step: 58  | total loss: [1m[32m0.68761[0m[0m | time: 16.946s
[2K
| Adam | epoch: 002 | loss: 0.68761 - acc: 0.5588 -- iter: 0672/1170
[A[ATraining Step: 59  | total loss: [1m[32m0.68422[0m[0m | time: 17.558s
[2K
| Adam | epoch: 002 | loss: 0.68422 - acc: 0.5887 -- iter: 0704/1170
[A[ATraining Step: 60  | total loss: [1m[32m0.68359[0m[0m | time: 18.214s
[2K
| Adam | epoch: 002 | loss: 0.68359 - acc: 0.5935 -- iter: 0736/1170
[A[ATraining Step: 61  | total loss: [1m[32m0.68340[0m[0m | time: 18.843s
[2K
| Adam | epoch: 002 | loss: 0.68340 - acc: 0.5935 -- iter: 0768/1170
[A[ATraining Step: 62  | total loss: [1m[32m0.68600[0m[0m | time: 19.464s
[2K
| Adam | epoch: 002 | loss: 0.68600 - acc: 0.5735 -- iter: 0800/1170
[A[ATraining Step: 63  | total loss: [1m[32m0.68305[0m[0m | time: 20.085s
[2K
| Adam | epoch: 002 | loss: 0.68305 - acc: 0.5919 -- iter: 0832/1170
[A[ATraining Step: 64  | total loss: [1m[32m0.68411[0m[0m | time: 20.711s
[2K
| Adam | epoch: 002 | loss: 0.68411 - acc: 0.5843 -- iter: 0864/1170
[A[ATraining Step: 65  | total loss: [1m[32m0.68361[0m[0m | time: 21.327s
[2K
| Adam | epoch: 002 | loss: 0.68361 - acc: 0.5855 -- iter: 0896/1170
[A[ATraining Step: 66  | total loss: [1m[32m0.68534[0m[0m | time: 21.944s
[2K
| Adam | epoch: 002 | loss: 0.68534 - acc: 0.5751 -- iter: 0928/1170
[A[ATraining Step: 67  | total loss: [1m[32m0.68975[0m[0m | time: 22.548s
[2K
| Adam | epoch: 002 | loss: 0.68975 - acc: 0.5511 -- iter: 0960/1170
[A[ATraining Step: 68  | total loss: [1m[32m0.68898[0m[0m | time: 23.160s
[2K
| Adam | epoch: 002 | loss: 0.68898 - acc: 0.5524 -- iter: 0992/1170
[A[ATraining Step: 69  | total loss: [1m[32m0.68624[0m[0m | time: 23.769s
[2K
| Adam | epoch: 002 | loss: 0.68624 - acc: 0.5646 -- iter: 1024/1170
[A[ATraining Step: 70  | total loss: [1m[32m0.68527[0m[0m | time: 24.422s
[2K
| Adam | epoch: 002 | loss: 0.68527 - acc: 0.5679 -- iter: 1056/1170
[A[ATraining Step: 71  | total loss: [1m[32m0.68368[0m[0m | time: 25.028s
[2K
| Adam | epoch: 002 | loss: 0.68368 - acc: 0.5744 -- iter: 1088/1170
[A[ATraining Step: 72  | total loss: [1m[32m0.68341[0m[0m | time: 25.640s
[2K
| Adam | epoch: 002 | loss: 0.68341 - acc: 0.5731 -- iter: 1120/1170
[A[ATraining Step: 73  | total loss: [1m[32m0.67909[0m[0m | time: 26.243s
[2K
| Adam | epoch: 002 | loss: 0.67909 - acc: 0.5858 -- iter: 1152/1170
[A[ATraining Step: 74  | total loss: [1m[32m0.68116[0m[0m | time: 28.016s
[2K
| Adam | epoch: 002 | loss: 0.68116 - acc: 0.5798 | val_loss: 0.66774 - val_acc: 0.5984 -- iter: 1170/1170
--
Training Step: 75  | total loss: [1m[32m0.68338[0m[0m | time: 0.387s
[2K
| Adam | epoch: 003 | loss: 0.68338 - acc: 0.5712 -- iter: 0032/1170
[A[ATraining Step: 76  | total loss: [1m[32m0.68169[0m[0m | time: 0.767s
[2K
| Adam | epoch: 003 | loss: 0.68169 - acc: 0.5754 -- iter: 0064/1170
[A[ATraining Step: 77  | total loss: [1m[32m0.67993[0m[0m | time: 1.379s
[2K
| Adam | epoch: 003 | loss: 0.67993 - acc: 0.5792 -- iter: 0096/1170
[A[ATraining Step: 78  | total loss: [1m[32m0.67812[0m[0m | time: 1.987s
[2K
| Adam | epoch: 003 | loss: 0.67812 - acc: 0.5807 -- iter: 0128/1170
[A[ATraining Step: 79  | total loss: [1m[32m0.67094[0m[0m | time: 2.592s
[2K
| Adam | epoch: 003 | loss: 0.67094 - acc: 0.5950 -- iter: 0160/1170
[A[ATraining Step: 80  | total loss: [1m[32m0.68030[0m[0m | time: 3.231s
[2K
| Adam | epoch: 003 | loss: 0.68030 - acc: 0.5821 -- iter: 0192/1170
[A[ATraining Step: 81  | total loss: [1m[32m0.68080[0m[0m | time: 3.853s
[2K
| Adam | epoch: 003 | loss: 0.68080 - acc: 0.5801 -- iter: 0224/1170
[A[ATraining Step: 82  | total loss: [1m[32m0.68174[0m[0m | time: 4.481s
[2K
| Adam | epoch: 003 | loss: 0.68174 - acc: 0.5752 -- iter: 0256/1170
[A[ATraining Step: 83  | total loss: [1m[32m0.67825[0m[0m | time: 5.094s
[2K
| Adam | epoch: 003 | loss: 0.67825 - acc: 0.5833 -- iter: 0288/1170
[A[ATraining Step: 84  | total loss: [1m[32m0.67999[0m[0m | time: 5.747s
[2K
| Adam | epoch: 003 | loss: 0.67999 - acc: 0.5750 -- iter: 0320/1170
[A[ATraining Step: 85  | total loss: [1m[32m0.68070[0m[0m | time: 6.376s
[2K
| Adam | epoch: 003 | loss: 0.68070 - acc: 0.5706 -- iter: 0352/1170
[A[ATraining Step: 86  | total loss: [1m[32m0.68210[0m[0m | time: 6.994s
[2K
| Adam | epoch: 003 | loss: 0.68210 - acc: 0.5636 -- iter: 0384/1170
[A[ATraining Step: 87  | total loss: [1m[32m0.68068[0m[0m | time: 7.601s
[2K
| Adam | epoch: 003 | loss: 0.68068 - acc: 0.5697 -- iter: 0416/1170
[A[ATraining Step: 88  | total loss: [1m[32m0.68147[0m[0m | time: 8.209s
[2K
| Adam | epoch: 003 | loss: 0.68147 - acc: 0.5659 -- iter: 0448/1170
[A[ATraining Step: 89  | total loss: [1m[32m0.67924[0m[0m | time: 8.818s
[2K
| Adam | epoch: 003 | loss: 0.67924 - acc: 0.5780 -- iter: 0480/1170
[A[ATraining Step: 90  | total loss: [1m[32m0.67823[0m[0m | time: 9.424s
[2K
| Adam | epoch: 003 | loss: 0.67823 - acc: 0.5827 -- iter: 0512/1170
[A[ATraining Step: 91  | total loss: [1m[32m0.67882[0m[0m | time: 10.039s
[2K
| Adam | epoch: 003 | loss: 0.67882 - acc: 0.5776 -- iter: 0544/1170
[A[ATraining Step: 92  | total loss: [1m[32m0.67599[0m[0m | time: 10.912s
[2K
| Adam | epoch: 003 | loss: 0.67599 - acc: 0.5854 -- iter: 0576/1170
[A[ATraining Step: 93  | total loss: [1m[32m0.67447[0m[0m | time: 11.938s
[2K
| Adam | epoch: 003 | loss: 0.67447 - acc: 0.5863 -- iter: 0608/1170
[A[ATraining Step: 94  | total loss: [1m[32m0.67367[0m[0m | time: 13.239s
[2K
| Adam | epoch: 003 | loss: 0.67367 - acc: 0.5870 -- iter: 0640/1170
[A[ATraining Step: 95  | total loss: [1m[32m0.67005[0m[0m | time: 14.320s
[2K
| Adam | epoch: 003 | loss: 0.67005 - acc: 0.5908 -- iter: 0672/1170
[A[ATraining Step: 96  | total loss: [1m[32m0.66746[0m[0m | time: 15.167s
[2K
| Adam | epoch: 003 | loss: 0.66746 - acc: 0.5942 -- iter: 0704/1170
[A[ATraining Step: 97  | total loss: [1m[32m0.66775[0m[0m | time: 16.120s
[2K
| Adam | epoch: 003 | loss: 0.66775 - acc: 0.5911 -- iter: 0736/1170
[A[ATraining Step: 98  | total loss: [1m[32m0.67712[0m[0m | time: 17.126s
[2K
| Adam | epoch: 003 | loss: 0.67712 - acc: 0.5820 -- iter: 0768/1170
[A[ATraining Step: 99  | total loss: [1m[32m0.66924[0m[0m | time: 18.081s
[2K
| Adam | epoch: 003 | loss: 0.66924 - acc: 0.5894 -- iter: 0800/1170
[A[ATraining Step: 100  | total loss: [1m[32m0.66569[0m[0m | time: 19.087s
[2K
| Adam | epoch: 003 | loss: 0.66569 - acc: 0.5961 -- iter: 0832/1170
[A[ATraining Step: 101  | total loss: [1m[32m0.66406[0m[0m | time: 20.025s
[2K
| Adam | epoch: 003 | loss: 0.66406 - acc: 0.5990 -- iter: 0864/1170
[A[ATraining Step: 102  | total loss: [1m[32m0.66615[0m[0m | time: 21.046s
[2K
| Adam | epoch: 003 | loss: 0.66615 - acc: 0.5891 -- iter: 0896/1170
[A[ATraining Step: 103  | total loss: [1m[32m0.66680[0m[0m | time: 22.175s
[2K
| Adam | epoch: 003 | loss: 0.66680 - acc: 0.5864 -- iter: 0928/1170
[A[ATraining Step: 104  | total loss: [1m[32m0.66570[0m[0m | time: 23.378s
[2K
| Adam | epoch: 003 | loss: 0.66570 - acc: 0.5871 -- iter: 0960/1170
[A[ATraining Step: 105  | total loss: [1m[32m0.66635[0m[0m | time: 24.328s
[2K
| Adam | epoch: 003 | loss: 0.66635 - acc: 0.5784 -- iter: 0992/1170
[A[ATraining Step: 106  | total loss: [1m[32m0.67068[0m[0m | time: 25.223s
[2K
| Adam | epoch: 003 | loss: 0.67068 - acc: 0.5612 -- iter: 1024/1170
[A[ATraining Step: 107  | total loss: [1m[32m0.67057[0m[0m | time: 26.187s
[2K
| Adam | epoch: 003 | loss: 0.67057 - acc: 0.5645 -- iter: 1056/1170
[A[ATraining Step: 108  | total loss: [1m[32m0.67320[0m[0m | time: 27.125s
[2K
| Adam | epoch: 003 | loss: 0.67320 - acc: 0.5486 -- iter: 1088/1170
[A[ATraining Step: 109  | total loss: [1m[32m0.67231[0m[0m | time: 28.144s
[2K
| Adam | epoch: 003 | loss: 0.67231 - acc: 0.5500 -- iter: 1120/1170
[A[ATraining Step: 110  | total loss: [1m[32m0.67201[0m[0m | time: 29.174s
[2K
| Adam | epoch: 003 | loss: 0.67201 - acc: 0.5513 -- iter: 1152/1170
[A[ATraining Step: 111  | total loss: [1m[32m0.67018[0m[0m | time: 31.721s
[2K
| Adam | epoch: 003 | loss: 0.67018 - acc: 0.5586 | val_loss: 0.63145 - val_acc: 0.6585 -- iter: 1170/1170
--
Training Step: 112  | total loss: [1m[32m0.66951[0m[0m | time: 0.932s
[2K
| Adam | epoch: 004 | loss: 0.66951 - acc: 0.5528 -- iter: 0032/1170
[A[ATraining Step: 113  | total loss: [1m[32m0.66771[0m[0m | time: 1.561s
[2K
| Adam | epoch: 004 | loss: 0.66771 - acc: 0.5663 -- iter: 0064/1170
[A[ATraining Step: 114  | total loss: [1m[32m0.66802[0m[0m | time: 2.195s
[2K
| Adam | epoch: 004 | loss: 0.66802 - acc: 0.5707 -- iter: 0096/1170
[A[ATraining Step: 115  | total loss: [1m[32m0.66708[0m[0m | time: 3.490s
[2K
| Adam | epoch: 004 | loss: 0.66708 - acc: 0.5748 -- iter: 0128/1170
[A[ATraining Step: 116  | total loss: [1m[32m0.66451[0m[0m | time: 4.570s
[2K
| Adam | epoch: 004 | loss: 0.66451 - acc: 0.5798 -- iter: 0160/1170
[A[ATraining Step: 117  | total loss: [1m[32m0.65899[0m[0m | time: 5.413s
[2K
| Adam | epoch: 004 | loss: 0.65899 - acc: 0.5968 -- iter: 0192/1170
[A[ATraining Step: 118  | total loss: [1m[32m0.65314[0m[0m | time: 6.390s
[2K
| Adam | epoch: 004 | loss: 0.65314 - acc: 0.5965 -- iter: 0224/1170
[A[ATraining Step: 119  | total loss: [1m[32m0.66356[0m[0m | time: 7.317s
[2K
| Adam | epoch: 004 | loss: 0.66356 - acc: 0.5931 -- iter: 0256/1170
[A[ATraining Step: 120  | total loss: [1m[32m0.66287[0m[0m | time: 8.255s
[2K
| Adam | epoch: 004 | loss: 0.66287 - acc: 0.5932 -- iter: 0288/1170
[A[ATraining Step: 121  | total loss: [1m[32m0.66455[0m[0m | time: 9.306s
[2K
| Adam | epoch: 004 | loss: 0.66455 - acc: 0.5839 -- iter: 0320/1170
[A[ATraining Step: 122  | total loss: [1m[32m0.66312[0m[0m | time: 10.368s
[2K
| Adam | epoch: 004 | loss: 0.66312 - acc: 0.5848 -- iter: 0352/1170
[A[ATraining Step: 123  | total loss: [1m[32m0.66803[0m[0m | time: 11.194s
[2K
| Adam | epoch: 004 | loss: 0.66803 - acc: 0.5732 -- iter: 0384/1170
[A[ATraining Step: 124  | total loss: [1m[32m0.66489[0m[0m | time: 12.314s
[2K
| Adam | epoch: 004 | loss: 0.66489 - acc: 0.5784 -- iter: 0416/1170
[A[ATraining Step: 125  | total loss: [1m[32m0.66900[0m[0m | time: 13.540s
[2K
| Adam | epoch: 004 | loss: 0.66900 - acc: 0.5799 -- iter: 0448/1170
[A[ATraining Step: 126  | total loss: [1m[32m0.67276[0m[0m | time: 14.814s
[2K
| Adam | epoch: 004 | loss: 0.67276 - acc: 0.5688 -- iter: 0480/1170
[A[ATraining Step: 127  | total loss: [1m[32m0.67151[0m[0m | time: 15.635s
[2K
| Adam | epoch: 004 | loss: 0.67151 - acc: 0.5713 -- iter: 0512/1170
[A[ATraining Step: 128  | total loss: [1m[32m0.66680[0m[0m | time: 16.526s
[2K
| Adam | epoch: 004 | loss: 0.66680 - acc: 0.5861 -- iter: 0544/1170
[A[ATraining Step: 129  | total loss: [1m[32m0.66025[0m[0m | time: 17.433s
[2K
| Adam | epoch: 004 | loss: 0.66025 - acc: 0.6025 -- iter: 0576/1170
[A[ATraining Step: 130  | total loss: [1m[32m0.65260[0m[0m | time: 18.397s
[2K
| Adam | epoch: 004 | loss: 0.65260 - acc: 0.6235 -- iter: 0608/1170
[A[ATraining Step: 131  | total loss: [1m[32m0.65168[0m[0m | time: 19.370s
[2K
| Adam | epoch: 004 | loss: 0.65168 - acc: 0.6267 -- iter: 0640/1170
[A[ATraining Step: 132  | total loss: [1m[32m0.64458[0m[0m | time: 20.459s
[2K
| Adam | epoch: 004 | loss: 0.64458 - acc: 0.6391 -- iter: 0672/1170
[A[ATraining Step: 133  | total loss: [1m[32m0.63850[0m[0m | time: 21.319s
[2K
| Adam | epoch: 004 | loss: 0.63850 - acc: 0.6439 -- iter: 0704/1170
[A[ATraining Step: 134  | total loss: [1m[32m0.62939[0m[0m | time: 22.308s
[2K
| Adam | epoch: 004 | loss: 0.62939 - acc: 0.6608 -- iter: 0736/1170
[A[ATraining Step: 135  | total loss: [1m[32m0.63825[0m[0m | time: 23.414s
[2K
| Adam | epoch: 004 | loss: 0.63825 - acc: 0.6509 -- iter: 0768/1170
[A[ATraining Step: 136  | total loss: [1m[32m0.63889[0m[0m | time: 24.670s
[2K
| Adam | epoch: 004 | loss: 0.63889 - acc: 0.6483 -- iter: 0800/1170
[A[ATraining Step: 137  | total loss: [1m[32m0.62192[0m[0m | time: 25.553s
[2K
| Adam | epoch: 004 | loss: 0.62192 - acc: 0.6679 -- iter: 0832/1170
[A[ATraining Step: 138  | total loss: [1m[32m0.60723[0m[0m | time: 26.436s
[2K
| Adam | epoch: 004 | loss: 0.60723 - acc: 0.6761 -- iter: 0864/1170
[A[ATraining Step: 139  | total loss: [1m[32m0.59547[0m[0m | time: 27.396s
[2K
| Adam | epoch: 004 | loss: 0.59547 - acc: 0.6804 -- iter: 0896/1170
[A[ATraining Step: 140  | total loss: [1m[32m0.58471[0m[0m | time: 28.333s
[2K
| Adam | epoch: 004 | loss: 0.58471 - acc: 0.6936 -- iter: 0928/1170
[A[ATraining Step: 141  | total loss: [1m[32m0.57532[0m[0m | time: 29.343s
[2K
| Adam | epoch: 004 | loss: 0.57532 - acc: 0.7023 -- iter: 0960/1170
[A[ATraining Step: 142  | total loss: [1m[32m0.59273[0m[0m | time: 30.438s
[2K
| Adam | epoch: 004 | loss: 0.59273 - acc: 0.6884 -- iter: 0992/1170
[A[ATraining Step: 143  | total loss: [1m[32m0.57195[0m[0m | time: 31.297s
[2K
| Adam | epoch: 004 | loss: 0.57195 - acc: 0.7039 -- iter: 1024/1170
[A[ATraining Step: 144  | total loss: [1m[32m0.55585[0m[0m | time: 32.174s
[2K
| Adam | epoch: 004 | loss: 0.55585 - acc: 0.7116 -- iter: 1056/1170
[A[ATraining Step: 145  | total loss: [1m[32m0.55404[0m[0m | time: 33.345s
[2K
| Adam | epoch: 004 | loss: 0.55404 - acc: 0.7217 -- iter: 1088/1170
[A[ATraining Step: 146  | total loss: [1m[32m0.58020[0m[0m | time: 34.600s
[2K
| Adam | epoch: 004 | loss: 0.58020 - acc: 0.7027 -- iter: 1120/1170
[A[ATraining Step: 147  | total loss: [1m[32m0.58284[0m[0m | time: 35.509s
[2K
| Adam | epoch: 004 | loss: 0.58284 - acc: 0.6949 -- iter: 1152/1170
[A[ATraining Step: 148  | total loss: [1m[32m0.57341[0m[0m | time: 38.226s
[2K
| Adam | epoch: 004 | loss: 0.57341 - acc: 0.7067 | val_loss: 0.56302 - val_acc: 0.7077 -- iter: 1170/1170
--
Training Step: 149  | total loss: [1m[32m0.58346[0m[0m | time: 1.261s
[2K
| Adam | epoch: 005 | loss: 0.58346 - acc: 0.7016 -- iter: 0032/1170
[A[ATraining Step: 150  | total loss: [1m[32m0.58036[0m[0m | time: 2.143s
[2K
| Adam | epoch: 005 | loss: 0.58036 - acc: 0.7065 -- iter: 0064/1170
[A[ATraining Step: 151  | total loss: [1m[32m0.57617[0m[0m | time: 2.662s
[2K
| Adam | epoch: 005 | loss: 0.57617 - acc: 0.7108 -- iter: 0096/1170
[A[ATraining Step: 152  | total loss: [1m[32m0.56522[0m[0m | time: 3.202s
[2K
| Adam | epoch: 005 | loss: 0.56522 - acc: 0.7286 -- iter: 0128/1170
[A[ATraining Step: 153  | total loss: [1m[32m0.55411[0m[0m | time: 4.130s
[2K
| Adam | epoch: 005 | loss: 0.55411 - acc: 0.7446 -- iter: 0160/1170
[A[ATraining Step: 154  | total loss: [1m[32m0.55668[0m[0m | time: 5.058s
[2K
| Adam | epoch: 005 | loss: 0.55668 - acc: 0.7421 -- iter: 0192/1170
[A[ATraining Step: 155  | total loss: [1m[32m0.55023[0m[0m | time: 6.112s
[2K
| Adam | epoch: 005 | loss: 0.55023 - acc: 0.7429 -- iter: 0224/1170
[A[ATraining Step: 156  | total loss: [1m[32m0.54701[0m[0m | time: 7.069s
[2K
| Adam | epoch: 005 | loss: 0.54701 - acc: 0.7436 -- iter: 0256/1170
[A[ATraining Step: 157  | total loss: [1m[32m0.55985[0m[0m | time: 7.994s
[2K
| Adam | epoch: 005 | loss: 0.55985 - acc: 0.7348 -- iter: 0288/1170
[A[ATraining Step: 158  | total loss: [1m[32m0.54626[0m[0m | time: 9.119s
[2K
| Adam | epoch: 005 | loss: 0.54626 - acc: 0.7426 -- iter: 0320/1170
[A[ATraining Step: 159  | total loss: [1m[32m0.54273[0m[0m | time: 10.491s
[2K
| Adam | epoch: 005 | loss: 0.54273 - acc: 0.7558 -- iter: 0352/1170
[A[ATraining Step: 160  | total loss: [1m[32m0.55682[0m[0m | time: 11.457s
[2K
| Adam | epoch: 005 | loss: 0.55682 - acc: 0.7490 -- iter: 0384/1170
[A[ATraining Step: 161  | total loss: [1m[32m0.56674[0m[0m | time: 12.323s
[2K
| Adam | epoch: 005 | loss: 0.56674 - acc: 0.7429 -- iter: 0416/1170
[A[ATraining Step: 162  | total loss: [1m[32m0.56962[0m[0m | time: 13.278s
[2K
| Adam | epoch: 005 | loss: 0.56962 - acc: 0.7311 -- iter: 0448/1170
[A[ATraining Step: 163  | total loss: [1m[32m0.56214[0m[0m | time: 14.207s
[2K
| Adam | epoch: 005 | loss: 0.56214 - acc: 0.7423 -- iter: 0480/1170
[A[ATraining Step: 164  | total loss: [1m[32m0.55125[0m[0m | time: 15.207s
[2K
| Adam | epoch: 005 | loss: 0.55125 - acc: 0.7525 -- iter: 0512/1170
[A[ATraining Step: 165  | total loss: [1m[32m0.55575[0m[0m | time: 16.325s
[2K
| Adam | epoch: 005 | loss: 0.55575 - acc: 0.7429 -- iter: 0544/1170
[A[ATraining Step: 166  | total loss: [1m[32m0.56881[0m[0m | time: 17.199s
[2K
| Adam | epoch: 005 | loss: 0.56881 - acc: 0.7154 -- iter: 0576/1170
[A[ATraining Step: 167  | total loss: [1m[32m0.55797[0m[0m | time: 18.158s
[2K
| Adam | epoch: 005 | loss: 0.55797 - acc: 0.7252 -- iter: 0608/1170
[A[ATraining Step: 168  | total loss: [1m[32m0.55501[0m[0m | time: 19.278s
[2K
| Adam | epoch: 005 | loss: 0.55501 - acc: 0.7339 -- iter: 0640/1170
[A[ATraining Step: 169  | total loss: [1m[32m0.54326[0m[0m | time: 20.519s
[2K
| Adam | epoch: 005 | loss: 0.54326 - acc: 0.7480 -- iter: 0672/1170
[A[ATraining Step: 170  | total loss: [1m[32m0.53147[0m[0m | time: 21.526s
[2K
| Adam | epoch: 005 | loss: 0.53147 - acc: 0.7576 -- iter: 0704/1170
[A[ATraining Step: 171  | total loss: [1m[32m0.53739[0m[0m | time: 22.389s
[2K
| Adam | epoch: 005 | loss: 0.53739 - acc: 0.7537 -- iter: 0736/1170
[A[ATraining Step: 172  | total loss: [1m[32m0.55122[0m[0m | time: 23.372s
[2K
| Adam | epoch: 005 | loss: 0.55122 - acc: 0.7439 -- iter: 0768/1170
[A[ATraining Step: 173  | total loss: [1m[32m0.54891[0m[0m | time: 24.308s
[2K
| Adam | epoch: 005 | loss: 0.54891 - acc: 0.7414 -- iter: 0800/1170
[A[ATraining Step: 174  | total loss: [1m[32m0.52586[0m[0m | time: 25.282s
[2K
| Adam | epoch: 005 | loss: 0.52586 - acc: 0.7548 -- iter: 0832/1170
[A[ATraining Step: 175  | total loss: [1m[32m0.51422[0m[0m | time: 26.344s
[2K
| Adam | epoch: 005 | loss: 0.51422 - acc: 0.7637 -- iter: 0864/1170
[A[ATraining Step: 176  | total loss: [1m[32m0.52160[0m[0m | time: 27.304s
[2K
| Adam | epoch: 005 | loss: 0.52160 - acc: 0.7623 -- iter: 0896/1170
[A[ATraining Step: 177  | total loss: [1m[32m0.51413[0m[0m | time: 28.148s
[2K
| Adam | epoch: 005 | loss: 0.51413 - acc: 0.7611 -- iter: 0928/1170
[A[ATraining Step: 178  | total loss: [1m[32m0.50227[0m[0m | time: 29.230s
[2K
| Adam | epoch: 005 | loss: 0.50227 - acc: 0.7693 -- iter: 0960/1170
[A[ATraining Step: 179  | total loss: [1m[32m0.48715[0m[0m | time: 30.509s
[2K
| Adam | epoch: 005 | loss: 0.48715 - acc: 0.7830 -- iter: 0992/1170
[A[ATraining Step: 180  | total loss: [1m[32m0.47030[0m[0m | time: 31.621s
[2K
| Adam | epoch: 005 | loss: 0.47030 - acc: 0.7985 -- iter: 1024/1170
[A[ATraining Step: 181  | total loss: [1m[32m0.46711[0m[0m | time: 32.488s
[2K
| Adam | epoch: 005 | loss: 0.46711 - acc: 0.7999 -- iter: 1056/1170
[A[ATraining Step: 182  | total loss: [1m[32m0.46159[0m[0m | time: 33.453s
[2K
| Adam | epoch: 005 | loss: 0.46159 - acc: 0.8043 -- iter: 1088/1170
[A[ATraining Step: 183  | total loss: [1m[32m0.45953[0m[0m | time: 34.412s
[2K
| Adam | epoch: 005 | loss: 0.45953 - acc: 0.8020 -- iter: 1120/1170
[A[ATraining Step: 184  | total loss: [1m[32m0.46392[0m[0m | time: 35.355s
[2K
| Adam | epoch: 005 | loss: 0.46392 - acc: 0.7936 -- iter: 1152/1170
[A[ATraining Step: 185  | total loss: [1m[32m0.46760[0m[0m | time: 38.103s
[2K
| Adam | epoch: 005 | loss: 0.46760 - acc: 0.7987 | val_loss: 0.48003 - val_acc: 0.7923 -- iter: 1170/1170
--
Training Step: 186  | total loss: [1m[32m0.46663[0m[0m | time: 0.921s
[2K
| Adam | epoch: 006 | loss: 0.46663 - acc: 0.7969 -- iter: 0032/1170
[A[ATraining Step: 187  | total loss: [1m[32m0.46122[0m[0m | time: 1.881s
[2K
| Adam | epoch: 006 | loss: 0.46122 - acc: 0.7954 -- iter: 0064/1170
[A[ATraining Step: 188  | total loss: [1m[32m0.47829[0m[0m | time: 2.970s
[2K
| Adam | epoch: 006 | loss: 0.47829 - acc: 0.7877 -- iter: 0096/1170
[A[ATraining Step: 189  | total loss: [1m[32m0.47523[0m[0m | time: 3.523s
[2K
| Adam | epoch: 006 | loss: 0.47523 - acc: 0.7902 -- iter: 0128/1170
[A[ATraining Step: 190  | total loss: [1m[32m0.46634[0m[0m | time: 3.991s
[2K
| Adam | epoch: 006 | loss: 0.46634 - acc: 0.7945 -- iter: 0160/1170
[A[ATraining Step: 191  | total loss: [1m[32m0.46260[0m[0m | time: 5.029s
[2K
| Adam | epoch: 006 | loss: 0.46260 - acc: 0.7984 -- iter: 0192/1170
[A[ATraining Step: 192  | total loss: [1m[32m0.48604[0m[0m | time: 6.218s
[2K
| Adam | epoch: 006 | loss: 0.48604 - acc: 0.7779 -- iter: 0224/1170
[A[ATraining Step: 193  | total loss: [1m[32m0.48858[0m[0m | time: 7.562s
[2K
| Adam | epoch: 006 | loss: 0.48858 - acc: 0.7782 -- iter: 0256/1170
[A[ATraining Step: 194  | total loss: [1m[32m0.49277[0m[0m | time: 8.482s
[2K
| Adam | epoch: 006 | loss: 0.49277 - acc: 0.7723 -- iter: 0288/1170
[A[ATraining Step: 195  | total loss: [1m[32m0.48372[0m[0m | time: 9.404s
[2K
| Adam | epoch: 006 | loss: 0.48372 - acc: 0.7794 -- iter: 0320/1170
[A[ATraining Step: 196  | total loss: [1m[32m0.50207[0m[0m | time: 10.323s
[2K
| Adam | epoch: 006 | loss: 0.50207 - acc: 0.7765 -- iter: 0352/1170
[A[ATraining Step: 197  | total loss: [1m[32m0.49731[0m[0m | time: 11.275s
[2K
| Adam | epoch: 006 | loss: 0.49731 - acc: 0.7832 -- iter: 0384/1170
[A[ATraining Step: 198  | total loss: [1m[32m0.51167[0m[0m | time: 12.267s
[2K
| Adam | epoch: 006 | loss: 0.51167 - acc: 0.7611 -- iter: 0416/1170
[A[ATraining Step: 199  | total loss: [1m[32m0.50231[0m[0m | time: 13.350s
[2K
| Adam | epoch: 006 | loss: 0.50231 - acc: 0.7694 -- iter: 0448/1170
[A[ATraining Step: 200  | total loss: [1m[32m0.49166[0m[0m | time: 15.965s
[2K
| Adam | epoch: 006 | loss: 0.49166 - acc: 0.7800 | val_loss: 0.49415 - val_acc: 0.7650 -- iter: 0480/1170
--
Training Step: 201  | total loss: [1m[32m0.47749[0m[0m | time: 16.838s
[2K
| Adam | epoch: 006 | loss: 0.47749 - acc: 0.7895 -- iter: 0512/1170
[A[ATraining Step: 202  | total loss: [1m[32m0.46626[0m[0m | time: 17.766s
[2K
| Adam | epoch: 006 | loss: 0.46626 - acc: 0.8011 -- iter: 0544/1170
[A[ATraining Step: 203  | total loss: [1m[32m0.47059[0m[0m | time: 18.697s
[2K
| Adam | epoch: 006 | loss: 0.47059 - acc: 0.7929 -- iter: 0576/1170
[A[ATraining Step: 204  | total loss: [1m[32m0.47202[0m[0m | time: 19.610s
[2K
| Adam | epoch: 006 | loss: 0.47202 - acc: 0.7980 -- iter: 0608/1170
[A[ATraining Step: 205  | total loss: [1m[32m0.46472[0m[0m | time: 20.658s
[2K
| Adam | epoch: 006 | loss: 0.46472 - acc: 0.7963 -- iter: 0640/1170
[A[ATraining Step: 206  | total loss: [1m[32m0.44949[0m[0m | time: 21.661s
[2K
| Adam | epoch: 006 | loss: 0.44949 - acc: 0.8011 -- iter: 0672/1170
[A[ATraining Step: 207  | total loss: [1m[32m0.45872[0m[0m | time: 22.521s
[2K
| Adam | epoch: 006 | loss: 0.45872 - acc: 0.7897 -- iter: 0704/1170
[A[ATraining Step: 208  | total loss: [1m[32m0.44001[0m[0m | time: 23.518s
[2K
| Adam | epoch: 006 | loss: 0.44001 - acc: 0.7951 -- iter: 0736/1170
[A[ATraining Step: 209  | total loss: [1m[32m0.44256[0m[0m | time: 24.643s
[2K
| Adam | epoch: 006 | loss: 0.44256 - acc: 0.7937 -- iter: 0768/1170
[A[ATraining Step: 210  | total loss: [1m[32m0.43431[0m[0m | time: 25.932s
[2K
| Adam | epoch: 006 | loss: 0.43431 - acc: 0.7956 -- iter: 0800/1170
[A[ATraining Step: 211  | total loss: [1m[32m0.43522[0m[0m | time: 26.855s
[2K
| Adam | epoch: 006 | loss: 0.43522 - acc: 0.7973 -- iter: 0832/1170
[A[ATraining Step: 212  | total loss: [1m[32m0.44855[0m[0m | time: 27.773s
[2K
| Adam | epoch: 006 | loss: 0.44855 - acc: 0.7926 -- iter: 0864/1170
[A[ATraining Step: 213  | total loss: [1m[32m0.45136[0m[0m | time: 28.723s
[2K
| Adam | epoch: 006 | loss: 0.45136 - acc: 0.7946 -- iter: 0896/1170
[A[ATraining Step: 214  | total loss: [1m[32m0.44836[0m[0m | time: 29.686s
[2K
| Adam | epoch: 006 | loss: 0.44836 - acc: 0.7995 -- iter: 0928/1170
[A[ATraining Step: 215  | total loss: [1m[32m0.43682[0m[0m | time: 30.712s
[2K
| Adam | epoch: 006 | loss: 0.43682 - acc: 0.7977 -- iter: 0960/1170
[A[ATraining Step: 216  | total loss: [1m[32m0.44454[0m[0m | time: 31.753s
[2K
| Adam | epoch: 006 | loss: 0.44454 - acc: 0.7866 -- iter: 0992/1170
[A[ATraining Step: 217  | total loss: [1m[32m0.45598[0m[0m | time: 32.647s
[2K
| Adam | epoch: 006 | loss: 0.45598 - acc: 0.7736 -- iter: 1024/1170
[A[ATraining Step: 218  | total loss: [1m[32m0.44538[0m[0m | time: 33.673s
[2K
| Adam | epoch: 006 | loss: 0.44538 - acc: 0.7806 -- iter: 1056/1170
[A[ATraining Step: 219  | total loss: [1m[32m0.45460[0m[0m | time: 34.836s
[2K
| Adam | epoch: 006 | loss: 0.45460 - acc: 0.7713 -- iter: 1088/1170
[A[ATraining Step: 220  | total loss: [1m[32m0.45884[0m[0m | time: 36.128s
[2K
| Adam | epoch: 006 | loss: 0.45884 - acc: 0.7692 -- iter: 1120/1170
[A[ATraining Step: 221  | total loss: [1m[32m0.45848[0m[0m | time: 37.070s
[2K
| Adam | epoch: 006 | loss: 0.45848 - acc: 0.7673 -- iter: 1152/1170
[A[ATraining Step: 222  | total loss: [1m[32m0.46776[0m[0m | time: 39.654s
[2K
| Adam | epoch: 006 | loss: 0.46776 - acc: 0.7624 | val_loss: 0.49032 - val_acc: 0.7514 -- iter: 1170/1170
--
Training Step: 223  | total loss: [1m[32m0.48523[0m[0m | time: 1.152s
[2K
| Adam | epoch: 007 | loss: 0.48523 - acc: 0.7518 -- iter: 0032/1170
[A[ATraining Step: 224  | total loss: [1m[32m0.48398[0m[0m | time: 2.464s
[2K
| Adam | epoch: 007 | loss: 0.48398 - acc: 0.7547 -- iter: 0064/1170
[A[ATraining Step: 225  | total loss: [1m[32m0.48304[0m[0m | time: 3.580s
[2K
| Adam | epoch: 007 | loss: 0.48304 - acc: 0.7574 -- iter: 0096/1170
[A[ATraining Step: 226  | total loss: [1m[32m0.47744[0m[0m | time: 4.485s
[2K
| Adam | epoch: 007 | loss: 0.47744 - acc: 0.7629 -- iter: 0128/1170
[A[ATraining Step: 227  | total loss: [1m[32m0.47326[0m[0m | time: 5.032s
[2K
| Adam | epoch: 007 | loss: 0.47326 - acc: 0.7679 -- iter: 0160/1170
[A[ATraining Step: 228  | total loss: [1m[32m0.47758[0m[0m | time: 5.587s
[2K
| Adam | epoch: 007 | loss: 0.47758 - acc: 0.7633 -- iter: 0192/1170
[A[ATraining Step: 229  | total loss: [1m[32m0.48182[0m[0m | time: 6.558s
[2K
| Adam | epoch: 007 | loss: 0.48182 - acc: 0.7536 -- iter: 0224/1170
[A[ATraining Step: 230  | total loss: [1m[32m0.46806[0m[0m | time: 7.482s
[2K
| Adam | epoch: 007 | loss: 0.46806 - acc: 0.7658 -- iter: 0256/1170
[A[ATraining Step: 231  | total loss: [1m[32m0.45672[0m[0m | time: 8.486s
[2K
| Adam | epoch: 007 | loss: 0.45672 - acc: 0.7704 -- iter: 0288/1170
[A[ATraining Step: 232  | total loss: [1m[32m0.44433[0m[0m | time: 9.472s
[2K
| Adam | epoch: 007 | loss: 0.44433 - acc: 0.7840 -- iter: 0320/1170
[A[ATraining Step: 233  | total loss: [1m[32m0.42998[0m[0m | time: 10.380s
[2K
| Adam | epoch: 007 | loss: 0.42998 - acc: 0.7962 -- iter: 0352/1170
[A[ATraining Step: 234  | total loss: [1m[32m0.41719[0m[0m | time: 11.557s
[2K
| Adam | epoch: 007 | loss: 0.41719 - acc: 0.8041 -- iter: 0384/1170
[A[ATraining Step: 235  | total loss: [1m[32m0.42557[0m[0m | time: 12.889s
[2K
| Adam | epoch: 007 | loss: 0.42557 - acc: 0.8018 -- iter: 0416/1170
[A[ATraining Step: 236  | total loss: [1m[32m0.43331[0m[0m | time: 13.973s
[2K
| Adam | epoch: 007 | loss: 0.43331 - acc: 0.8060 -- iter: 0448/1170
[A[ATraining Step: 237  | total loss: [1m[32m0.41316[0m[0m | time: 14.852s
[2K
| Adam | epoch: 007 | loss: 0.41316 - acc: 0.8160 -- iter: 0480/1170
[A[ATraining Step: 238  | total loss: [1m[32m0.39889[0m[0m | time: 15.823s
[2K
| Adam | epoch: 007 | loss: 0.39889 - acc: 0.8188 -- iter: 0512/1170
[A[ATraining Step: 239  | total loss: [1m[32m0.38864[0m[0m | time: 16.733s
[2K
| Adam | epoch: 007 | loss: 0.38864 - acc: 0.8276 -- iter: 0544/1170
[A[ATraining Step: 240  | total loss: [1m[32m0.38743[0m[0m | time: 17.674s
[2K
| Adam | epoch: 007 | loss: 0.38743 - acc: 0.8292 -- iter: 0576/1170
[A[ATraining Step: 241  | total loss: [1m[32m0.38727[0m[0m | time: 18.714s
[2K
| Adam | epoch: 007 | loss: 0.38727 - acc: 0.8275 -- iter: 0608/1170
[A[ATraining Step: 242  | total loss: [1m[32m0.39879[0m[0m | time: 19.714s
[2K
| Adam | epoch: 007 | loss: 0.39879 - acc: 0.8229 -- iter: 0640/1170
[A[ATraining Step: 243  | total loss: [1m[32m0.40208[0m[0m | time: 20.591s
[2K
| Adam | epoch: 007 | loss: 0.40208 - acc: 0.8218 -- iter: 0672/1170
[A[ATraining Step: 244  | total loss: [1m[32m0.39768[0m[0m | time: 21.577s
[2K
| Adam | epoch: 007 | loss: 0.39768 - acc: 0.8178 -- iter: 0704/1170
[A[ATraining Step: 245  | total loss: [1m[32m0.38550[0m[0m | time: 22.602s
[2K
| Adam | epoch: 007 | loss: 0.38550 - acc: 0.8266 -- iter: 0736/1170
[A[ATraining Step: 246  | total loss: [1m[32m0.36794[0m[0m | time: 23.618s
[2K
| Adam | epoch: 007 | loss: 0.36794 - acc: 0.8346 -- iter: 0768/1170
[A[ATraining Step: 247  | total loss: [1m[32m0.35904[0m[0m | time: 24.665s
[2K
| Adam | epoch: 007 | loss: 0.35904 - acc: 0.8355 -- iter: 0800/1170
[A[ATraining Step: 248  | total loss: [1m[32m0.35704[0m[0m | time: 25.637s
[2K
| Adam | epoch: 007 | loss: 0.35704 - acc: 0.8332 -- iter: 0832/1170
[A[ATraining Step: 249  | total loss: [1m[32m0.36885[0m[0m | time: 26.703s
[2K
| Adam | epoch: 007 | loss: 0.36885 - acc: 0.8311 -- iter: 0864/1170
[A[ATraining Step: 250  | total loss: [1m[32m0.35694[0m[0m | time: 27.696s
[2K
| Adam | epoch: 007 | loss: 0.35694 - acc: 0.8324 -- iter: 0896/1170
[A[ATraining Step: 251  | total loss: [1m[32m0.36045[0m[0m | time: 28.818s
[2K
| Adam | epoch: 007 | loss: 0.36045 - acc: 0.8335 -- iter: 0928/1170
[A[ATraining Step: 252  | total loss: [1m[32m0.36570[0m[0m | time: 29.845s
[2K
| Adam | epoch: 007 | loss: 0.36570 - acc: 0.8377 -- iter: 0960/1170
[A[ATraining Step: 253  | total loss: [1m[32m0.35453[0m[0m | time: 30.650s
[2K
| Adam | epoch: 007 | loss: 0.35453 - acc: 0.8477 -- iter: 0992/1170
[A[ATraining Step: 254  | total loss: [1m[32m0.34809[0m[0m | time: 31.298s
[2K
| Adam | epoch: 007 | loss: 0.34809 - acc: 0.8535 -- iter: 1024/1170
[A[ATraining Step: 255  | total loss: [1m[32m0.34748[0m[0m | time: 31.906s
[2K
| Adam | epoch: 007 | loss: 0.34748 - acc: 0.8494 -- iter: 1056/1170
[A[ATraining Step: 256  | total loss: [1m[32m0.34541[0m[0m | time: 32.525s
[2K
| Adam | epoch: 007 | loss: 0.34541 - acc: 0.8489 -- iter: 1088/1170
[A[ATraining Step: 257  | total loss: [1m[32m0.35376[0m[0m | time: 33.131s
[2K
| Adam | epoch: 007 | loss: 0.35376 - acc: 0.8483 -- iter: 1120/1170
[A[ATraining Step: 258  | total loss: [1m[32m0.35713[0m[0m | time: 33.735s
[2K
| Adam | epoch: 007 | loss: 0.35713 - acc: 0.8510 -- iter: 1152/1170
[A[ATraining Step: 259  | total loss: [1m[32m0.36502[0m[0m | time: 35.529s
[2K
| Adam | epoch: 007 | loss: 0.36502 - acc: 0.8472 | val_loss: 0.38430 - val_acc: 0.8361 -- iter: 1170/1170
--
Training Step: 260  | total loss: [1m[32m0.35775[0m[0m | time: 0.625s
[2K
| Adam | epoch: 008 | loss: 0.35775 - acc: 0.8499 -- iter: 0032/1170
[A[ATraining Step: 261  | total loss: [1m[32m0.34922[0m[0m | time: 1.232s
[2K
| Adam | epoch: 008 | loss: 0.34922 - acc: 0.8524 -- iter: 0064/1170
[A[ATraining Step: 262  | total loss: [1m[32m0.33490[0m[0m | time: 1.849s
[2K
| Adam | epoch: 008 | loss: 0.33490 - acc: 0.8578 -- iter: 0096/1170
[A[ATraining Step: 263  | total loss: [1m[32m0.33316[0m[0m | time: 2.467s
[2K
| Adam | epoch: 008 | loss: 0.33316 - acc: 0.8595 -- iter: 0128/1170
[A[ATraining Step: 264  | total loss: [1m[32m0.33504[0m[0m | time: 3.106s
[2K
| Adam | epoch: 008 | loss: 0.33504 - acc: 0.8517 -- iter: 0160/1170
[A[ATraining Step: 265  | total loss: [1m[32m0.32591[0m[0m | time: 3.460s
[2K
| Adam | epoch: 008 | loss: 0.32591 - acc: 0.8540 -- iter: 0192/1170
[A[ATraining Step: 266  | total loss: [1m[32m0.31823[0m[0m | time: 3.826s
[2K
| Adam | epoch: 008 | loss: 0.31823 - acc: 0.8631 -- iter: 0224/1170
[A[ATraining Step: 267  | total loss: [1m[32m0.30631[0m[0m | time: 4.462s
[2K
| Adam | epoch: 008 | loss: 0.30631 - acc: 0.8657 -- iter: 0256/1170
[A[ATraining Step: 268  | total loss: [1m[32m0.29777[0m[0m | time: 5.075s
[2K
| Adam | epoch: 008 | loss: 0.29777 - acc: 0.8728 -- iter: 0288/1170
[A[ATraining Step: 269  | total loss: [1m[32m0.29993[0m[0m | time: 5.713s
[2K
| Adam | epoch: 008 | loss: 0.29993 - acc: 0.8637 -- iter: 0320/1170
[A[ATraining Step: 270  | total loss: [1m[32m0.30281[0m[0m | time: 6.339s
[2K
| Adam | epoch: 008 | loss: 0.30281 - acc: 0.8648 -- iter: 0352/1170
[A[ATraining Step: 271  | total loss: [1m[32m0.31675[0m[0m | time: 6.935s
[2K
| Adam | epoch: 008 | loss: 0.31675 - acc: 0.8627 -- iter: 0384/1170
[A[ATraining Step: 272  | total loss: [1m[32m0.43424[0m[0m | time: 7.541s
[2K
| Adam | epoch: 008 | loss: 0.43424 - acc: 0.8358 -- iter: 0416/1170
[A[ATraining Step: 273  | total loss: [1m[32m0.45053[0m[0m | time: 8.177s
[2K
| Adam | epoch: 008 | loss: 0.45053 - acc: 0.8272 -- iter: 0448/1170
[A[ATraining Step: 274  | total loss: [1m[32m0.43507[0m[0m | time: 8.786s
[2K
| Adam | epoch: 008 | loss: 0.43507 - acc: 0.8351 -- iter: 0480/1170
[A[ATraining Step: 275  | total loss: [1m[32m0.41608[0m[0m | time: 9.415s
[2K
| Adam | epoch: 008 | loss: 0.41608 - acc: 0.8391 -- iter: 0512/1170
[A[ATraining Step: 276  | total loss: [1m[32m0.40002[0m[0m | time: 10.499s
[2K
| Adam | epoch: 008 | loss: 0.40002 - acc: 0.8490 -- iter: 0544/1170
[A[ATraining Step: 277  | total loss: [1m[32m0.40502[0m[0m | time: 11.636s
[2K
| Adam | epoch: 008 | loss: 0.40502 - acc: 0.8453 -- iter: 0576/1170
[A[ATraining Step: 278  | total loss: [1m[32m0.39419[0m[0m | time: 12.961s
[2K
| Adam | epoch: 008 | loss: 0.39419 - acc: 0.8514 -- iter: 0608/1170
[A[ATraining Step: 279  | total loss: [1m[32m0.37939[0m[0m | time: 13.963s
[2K
| Adam | epoch: 008 | loss: 0.37939 - acc: 0.8569 -- iter: 0640/1170
[A[ATraining Step: 280  | total loss: [1m[32m0.36722[0m[0m | time: 14.864s
[2K
| Adam | epoch: 008 | loss: 0.36722 - acc: 0.8618 -- iter: 0672/1170
[A[ATraining Step: 281  | total loss: [1m[32m0.37540[0m[0m | time: 15.846s
[2K
| Adam | epoch: 008 | loss: 0.37540 - acc: 0.8600 -- iter: 0704/1170
[A[ATraining Step: 282  | total loss: [1m[32m0.38233[0m[0m | time: 16.823s
[2K
| Adam | epoch: 008 | loss: 0.38233 - acc: 0.8521 -- iter: 0736/1170
[A[ATraining Step: 283  | total loss: [1m[32m0.38241[0m[0m | time: 17.876s
[2K
| Adam | epoch: 008 | loss: 0.38241 - acc: 0.8544 -- iter: 0768/1170
[A[ATraining Step: 284  | total loss: [1m[32m0.38070[0m[0m | time: 19.000s
[2K
| Adam | epoch: 008 | loss: 0.38070 - acc: 0.8440 -- iter: 0800/1170
[A[ATraining Step: 285  | total loss: [1m[32m0.37197[0m[0m | time: 19.822s
[2K
| Adam | epoch: 008 | loss: 0.37197 - acc: 0.8440 -- iter: 0832/1170
[A[ATraining Step: 286  | total loss: [1m[32m0.36750[0m[0m | time: 20.926s
[2K
| Adam | epoch: 008 | loss: 0.36750 - acc: 0.8471 -- iter: 0864/1170
[A[ATraining Step: 287  | total loss: [1m[32m0.35159[0m[0m | time: 22.198s
[2K
| Adam | epoch: 008 | loss: 0.35159 - acc: 0.8592 -- iter: 0896/1170
[A[ATraining Step: 288  | total loss: [1m[32m0.33451[0m[0m | time: 23.374s
[2K
| Adam | epoch: 008 | loss: 0.33451 - acc: 0.8702 -- iter: 0928/1170
[A[ATraining Step: 289  | total loss: [1m[32m0.32417[0m[0m | time: 24.194s
[2K
| Adam | epoch: 008 | loss: 0.32417 - acc: 0.8707 -- iter: 0960/1170
[A[ATraining Step: 290  | total loss: [1m[32m0.33758[0m[0m | time: 25.107s
[2K
| Adam | epoch: 008 | loss: 0.33758 - acc: 0.8617 -- iter: 0992/1170
[A[ATraining Step: 291  | total loss: [1m[32m0.32763[0m[0m | time: 25.994s
[2K
| Adam | epoch: 008 | loss: 0.32763 - acc: 0.8631 -- iter: 1024/1170
[A[ATraining Step: 292  | total loss: [1m[32m0.33173[0m[0m | time: 26.914s
[2K
| Adam | epoch: 008 | loss: 0.33173 - acc: 0.8642 -- iter: 1056/1170
[A[ATraining Step: 293  | total loss: [1m[32m0.33164[0m[0m | time: 27.913s
[2K
| Adam | epoch: 008 | loss: 0.33164 - acc: 0.8622 -- iter: 1088/1170
[A[ATraining Step: 294  | total loss: [1m[32m0.33954[0m[0m | time: 28.970s
[2K
| Adam | epoch: 008 | loss: 0.33954 - acc: 0.8541 -- iter: 1120/1170
[A[ATraining Step: 295  | total loss: [1m[32m0.32802[0m[0m | time: 29.879s
[2K
| Adam | epoch: 008 | loss: 0.32802 - acc: 0.8593 -- iter: 1152/1170
[A[ATraining Step: 296  | total loss: [1m[32m0.33081[0m[0m | time: 32.970s
[2K
| Adam | epoch: 008 | loss: 0.33081 - acc: 0.8640 | val_loss: 0.36740 - val_acc: 0.8443 -- iter: 1170/1170
--
Training Step: 297  | total loss: [1m[32m0.31677[0m[0m | time: 0.950s
[2K
| Adam | epoch: 009 | loss: 0.31677 - acc: 0.8682 -- iter: 0032/1170
[A[ATraining Step: 298  | total loss: [1m[32m0.30112[0m[0m | time: 1.925s
[2K
| Adam | epoch: 009 | loss: 0.30112 - acc: 0.8752 -- iter: 0064/1170
[A[ATraining Step: 299  | total loss: [1m[32m0.32218[0m[0m | time: 2.990s
[2K
| Adam | epoch: 009 | loss: 0.32218 - acc: 0.8751 -- iter: 0096/1170
[A[ATraining Step: 300  | total loss: [1m[32m0.30641[0m[0m | time: 3.857s
[2K
| Adam | epoch: 009 | loss: 0.30641 - acc: 0.8814 -- iter: 0128/1170
[A[ATraining Step: 301  | total loss: [1m[32m0.30648[0m[0m | time: 4.906s
[2K
| Adam | epoch: 009 | loss: 0.30648 - acc: 0.8714 -- iter: 0160/1170
[A[ATraining Step: 302  | total loss: [1m[32m0.29160[0m[0m | time: 6.069s
[2K
| Adam | epoch: 009 | loss: 0.29160 - acc: 0.8780 -- iter: 0192/1170
[A[ATraining Step: 303  | total loss: [1m[32m0.29934[0m[0m | time: 6.832s
[2K
| Adam | epoch: 009 | loss: 0.29934 - acc: 0.8746 -- iter: 0224/1170
[A[ATraining Step: 304  | total loss: [1m[32m0.27597[0m[0m | time: 7.537s
[2K
| Adam | epoch: 009 | loss: 0.27597 - acc: 0.8871 -- iter: 0256/1170
[A[ATraining Step: 305  | total loss: [1m[32m0.25669[0m[0m | time: 8.403s
[2K
| Adam | epoch: 009 | loss: 0.25669 - acc: 0.8984 -- iter: 0288/1170
[A[ATraining Step: 306  | total loss: [1m[32m0.25135[0m[0m | time: 9.372s
[2K
| Adam | epoch: 009 | loss: 0.25135 - acc: 0.9023 -- iter: 0320/1170
[A[ATraining Step: 307  | total loss: [1m[32m0.25634[0m[0m | time: 10.281s
[2K
| Adam | epoch: 009 | loss: 0.25634 - acc: 0.9058 -- iter: 0352/1170
[A[ATraining Step: 308  | total loss: [1m[32m0.25656[0m[0m | time: 11.218s
[2K
| Adam | epoch: 009 | loss: 0.25656 - acc: 0.9059 -- iter: 0384/1170
[A[ATraining Step: 309  | total loss: [1m[32m0.25500[0m[0m | time: 12.268s
[2K
| Adam | epoch: 009 | loss: 0.25500 - acc: 0.9090 -- iter: 0416/1170
[A[ATraining Step: 310  | total loss: [1m[32m0.24880[0m[0m | time: 13.245s
[2K
| Adam | epoch: 009 | loss: 0.24880 - acc: 0.9088 -- iter: 0448/1170
[A[ATraining Step: 311  | total loss: [1m[32m0.23571[0m[0m | time: 14.099s
[2K
| Adam | epoch: 009 | loss: 0.23571 - acc: 0.9116 -- iter: 0480/1170
[A[ATraining Step: 312  | total loss: [1m[32m0.21905[0m[0m | time: 15.088s
[2K
| Adam | epoch: 009 | loss: 0.21905 - acc: 0.9205 -- iter: 0512/1170
[A[ATraining Step: 313  | total loss: [1m[32m0.22125[0m[0m | time: 16.307s
[2K
| Adam | epoch: 009 | loss: 0.22125 - acc: 0.9190 -- iter: 0544/1170
[A[ATraining Step: 314  | total loss: [1m[32m0.25350[0m[0m | time: 17.528s
[2K
| Adam | epoch: 009 | loss: 0.25350 - acc: 0.9146 -- iter: 0576/1170
[A[ATraining Step: 315  | total loss: [1m[32m0.25069[0m[0m | time: 18.430s
[2K
| Adam | epoch: 009 | loss: 0.25069 - acc: 0.9107 -- iter: 0608/1170
[A[ATraining Step: 316  | total loss: [1m[32m0.25361[0m[0m | time: 19.322s
[2K
| Adam | epoch: 009 | loss: 0.25361 - acc: 0.9134 -- iter: 0640/1170
[A[ATraining Step: 317  | total loss: [1m[32m0.24488[0m[0m | time: 20.256s
[2K
| Adam | epoch: 009 | loss: 0.24488 - acc: 0.9126 -- iter: 0672/1170
[A[ATraining Step: 318  | total loss: [1m[32m0.23325[0m[0m | time: 21.166s
[2K
| Adam | epoch: 009 | loss: 0.23325 - acc: 0.9183 -- iter: 0704/1170
[A[ATraining Step: 319  | total loss: [1m[32m0.25161[0m[0m | time: 22.147s
[2K
| Adam | epoch: 009 | loss: 0.25161 - acc: 0.9046 -- iter: 0736/1170
[A[ATraining Step: 320  | total loss: [1m[32m0.24490[0m[0m | time: 23.247s
[2K
| Adam | epoch: 009 | loss: 0.24490 - acc: 0.9047 -- iter: 0768/1170
[A[ATraining Step: 321  | total loss: [1m[32m0.22811[0m[0m | time: 24.162s
[2K
| Adam | epoch: 009 | loss: 0.22811 - acc: 0.9143 -- iter: 0800/1170
[A[ATraining Step: 322  | total loss: [1m[32m0.22340[0m[0m | time: 25.063s
[2K
| Adam | epoch: 009 | loss: 0.22340 - acc: 0.9197 -- iter: 0832/1170
[A[ATraining Step: 323  | total loss: [1m[32m0.24812[0m[0m | time: 26.122s
[2K
| Adam | epoch: 009 | loss: 0.24812 - acc: 0.9027 -- iter: 0864/1170
[A[ATraining Step: 324  | total loss: [1m[32m0.23565[0m[0m | time: 27.243s
[2K
| Adam | epoch: 009 | loss: 0.23565 - acc: 0.9093 -- iter: 0896/1170
[A[ATraining Step: 325  | total loss: [1m[32m0.22611[0m[0m | time: 28.303s
[2K
| Adam | epoch: 009 | loss: 0.22611 - acc: 0.9122 -- iter: 0928/1170
[A[ATraining Step: 326  | total loss: [1m[32m0.21877[0m[0m | time: 29.179s
[2K
| Adam | epoch: 009 | loss: 0.21877 - acc: 0.9178 -- iter: 0960/1170
[A[ATraining Step: 327  | total loss: [1m[32m0.22946[0m[0m | time: 30.128s
[2K
| Adam | epoch: 009 | loss: 0.22946 - acc: 0.9167 -- iter: 0992/1170
[A[ATraining Step: 328  | total loss: [1m[32m0.23901[0m[0m | time: 31.053s
[2K
| Adam | epoch: 009 | loss: 0.23901 - acc: 0.9094 -- iter: 1024/1170
[A[ATraining Step: 329  | total loss: [1m[32m0.23491[0m[0m | time: 31.964s
[2K
| Adam | epoch: 009 | loss: 0.23491 - acc: 0.9122 -- iter: 1056/1170
[A[ATraining Step: 330  | total loss: [1m[32m0.22891[0m[0m | time: 33.044s
[2K
| Adam | epoch: 009 | loss: 0.22891 - acc: 0.9085 -- iter: 1088/1170
[A[ATraining Step: 331  | total loss: [1m[32m0.22665[0m[0m | time: 34.034s
[2K
| Adam | epoch: 009 | loss: 0.22665 - acc: 0.9082 -- iter: 1120/1170
[A[ATraining Step: 332  | total loss: [1m[32m0.21855[0m[0m | time: 34.882s
[2K
| Adam | epoch: 009 | loss: 0.21855 - acc: 0.9112 -- iter: 1152/1170
[A[ATraining Step: 333  | total loss: [1m[32m0.21261[0m[0m | time: 38.160s
[2K
| Adam | epoch: 009 | loss: 0.21261 - acc: 0.9169 | val_loss: 0.49784 - val_acc: 0.7978 -- iter: 1170/1170
--
Training Step: 334  | total loss: [1m[32m0.21368[0m[0m | time: 0.946s
[2K
| Adam | epoch: 010 | loss: 0.21368 - acc: 0.9096 -- iter: 0032/1170
[A[ATraining Step: 335  | total loss: [1m[32m0.21350[0m[0m | time: 1.986s
[2K
| Adam | epoch: 010 | loss: 0.21350 - acc: 0.9093 -- iter: 0064/1170
[A[ATraining Step: 336  | total loss: [1m[32m0.21140[0m[0m | time: 3.045s
[2K
| Adam | epoch: 010 | loss: 0.21140 - acc: 0.9121 -- iter: 0096/1170
[A[ATraining Step: 337  | total loss: [1m[32m0.21066[0m[0m | time: 3.919s
[2K
| Adam | epoch: 010 | loss: 0.21066 - acc: 0.9115 -- iter: 0128/1170
[A[ATraining Step: 338  | total loss: [1m[32m0.20872[0m[0m | time: 4.976s
[2K
| Adam | epoch: 010 | loss: 0.20872 - acc: 0.9110 -- iter: 0160/1170
[A[ATraining Step: 339  | total loss: [1m[32m0.20335[0m[0m | time: 6.031s
[2K
| Adam | epoch: 010 | loss: 0.20335 - acc: 0.9168 -- iter: 0192/1170
[A[ATraining Step: 340  | total loss: [1m[32m0.23129[0m[0m | time: 7.154s
[2K
| Adam | epoch: 010 | loss: 0.23129 - acc: 0.9001 -- iter: 0224/1170
[A[ATraining Step: 341  | total loss: [1m[32m0.23389[0m[0m | time: 7.636s
[2K
| Adam | epoch: 010 | loss: 0.23389 - acc: 0.8945 -- iter: 0256/1170
[A[ATraining Step: 342  | total loss: [1m[32m0.21971[0m[0m | time: 8.199s
[2K
| Adam | epoch: 010 | loss: 0.21971 - acc: 0.9050 -- iter: 0288/1170
[A[ATraining Step: 343  | total loss: [1m[32m0.20145[0m[0m | time: 9.114s
[2K
| Adam | epoch: 010 | loss: 0.20145 - acc: 0.9145 -- iter: 0320/1170
[A[ATraining Step: 344  | total loss: [1m[32m0.21307[0m[0m | time: 10.009s
[2K
| Adam | epoch: 010 | loss: 0.21307 - acc: 0.9074 -- iter: 0352/1170
[A[ATraining Step: 345  | total loss: [1m[32m0.19667[0m[0m | time: 10.943s
[2K
| Adam | epoch: 010 | loss: 0.19667 - acc: 0.9167 -- iter: 0384/1170
[A[ATraining Step: 346  | total loss: [1m[32m0.19044[0m[0m | time: 12.065s
[2K
| Adam | epoch: 010 | loss: 0.19044 - acc: 0.9219 -- iter: 0416/1170
[A[ATraining Step: 347  | total loss: [1m[32m0.20649[0m[0m | time: 12.988s
[2K
| Adam | epoch: 010 | loss: 0.20649 - acc: 0.9172 -- iter: 0448/1170
[A[ATraining Step: 348  | total loss: [1m[32m0.21412[0m[0m | time: 14.066s
[2K
| Adam | epoch: 010 | loss: 0.21412 - acc: 0.9192 -- iter: 0480/1170
[A[ATraining Step: 349  | total loss: [1m[32m0.21093[0m[0m | time: 15.184s
[2K
| Adam | epoch: 010 | loss: 0.21093 - acc: 0.9179 -- iter: 0512/1170
[A[ATraining Step: 350  | total loss: [1m[32m0.19721[0m[0m | time: 16.284s
[2K
| Adam | epoch: 010 | loss: 0.19721 - acc: 0.9261 -- iter: 0544/1170
[A[ATraining Step: 351  | total loss: [1m[32m0.19478[0m[0m | time: 17.093s
[2K
| Adam | epoch: 010 | loss: 0.19478 - acc: 0.9273 -- iter: 0576/1170
[A[ATraining Step: 352  | total loss: [1m[32m0.18158[0m[0m | time: 17.976s
[2K
| Adam | epoch: 010 | loss: 0.18158 - acc: 0.9345 -- iter: 0608/1170
[A[ATraining Step: 353  | total loss: [1m[32m0.19041[0m[0m | time: 18.918s
[2K
| Adam | epoch: 010 | loss: 0.19041 - acc: 0.9348 -- iter: 0640/1170
[A[ATraining Step: 354  | total loss: [1m[32m0.19791[0m[0m | time: 19.847s
[2K
| Adam | epoch: 010 | loss: 0.19791 - acc: 0.9382 -- iter: 0672/1170
[A[ATraining Step: 355  | total loss: [1m[32m0.22452[0m[0m | time: 20.896s
[2K
| Adam | epoch: 010 | loss: 0.22452 - acc: 0.9225 -- iter: 0704/1170
[A[ATraining Step: 356  | total loss: [1m[32m0.22876[0m[0m | time: 21.833s
[2K
| Adam | epoch: 010 | loss: 0.22876 - acc: 0.9178 -- iter: 0736/1170
[A[ATraining Step: 357  | total loss: [1m[32m0.21839[0m[0m | time: 22.819s
[2K
| Adam | epoch: 010 | loss: 0.21839 - acc: 0.9260 -- iter: 0768/1170
[A[ATraining Step: 358  | total loss: [1m[32m0.20323[0m[0m | time: 23.938s
[2K
| Adam | epoch: 010 | loss: 0.20323 - acc: 0.9334 -- iter: 0800/1170
[A[ATraining Step: 359  | total loss: [1m[32m0.21399[0m[0m | time: 25.240s
[2K
| Adam | epoch: 010 | loss: 0.21399 - acc: 0.9307 -- iter: 0832/1170
[A[ATraining Step: 360  | total loss: [1m[32m0.20197[0m[0m | time: 26.241s
[2K
| Adam | epoch: 010 | loss: 0.20197 - acc: 0.9345 -- iter: 0864/1170
[A[ATraining Step: 361  | total loss: [1m[32m0.19397[0m[0m | time: 27.177s
[2K
| Adam | epoch: 010 | loss: 0.19397 - acc: 0.9379 -- iter: 0896/1170
[A[ATraining Step: 362  | total loss: [1m[32m0.20193[0m[0m | time: 28.151s
[2K
| Adam | epoch: 010 | loss: 0.20193 - acc: 0.9348 -- iter: 0928/1170
[A[ATraining Step: 363  | total loss: [1m[32m0.19085[0m[0m | time: 29.085s
[2K
| Adam | epoch: 010 | loss: 0.19085 - acc: 0.9382 -- iter: 0960/1170
[A[ATraining Step: 364  | total loss: [1m[32m0.17851[0m[0m | time: 30.178s
[2K
| Adam | epoch: 010 | loss: 0.17851 - acc: 0.9443 -- iter: 0992/1170
[A[ATraining Step: 365  | total loss: [1m[32m0.16991[0m[0m | time: 31.182s
[2K
| Adam | epoch: 010 | loss: 0.16991 - acc: 0.9468 -- iter: 1024/1170
[A[ATraining Step: 366  | total loss: [1m[32m0.16638[0m[0m | time: 32.049s
[2K
| Adam | epoch: 010 | loss: 0.16638 - acc: 0.9459 -- iter: 1056/1170
[A[ATraining Step: 367  | total loss: [1m[32m0.15955[0m[0m | time: 33.171s
[2K
| Adam | epoch: 010 | loss: 0.15955 - acc: 0.9481 -- iter: 1088/1170
[A[ATraining Step: 368  | total loss: [1m[32m0.16783[0m[0m | time: 34.248s
[2K
| Adam | epoch: 010 | loss: 0.16783 - acc: 0.9471 -- iter: 1120/1170
[A[ATraining Step: 369  | total loss: [1m[32m0.15497[0m[0m | time: 35.460s
[2K
| Adam | epoch: 010 | loss: 0.15497 - acc: 0.9492 -- iter: 1152/1170
[A[ATraining Step: 370  | total loss: [1m[32m0.14395[0m[0m | time: 38.010s
[2K
| Adam | epoch: 010 | loss: 0.14395 - acc: 0.9543 | val_loss: 0.43832 - val_acc: 0.8443 -- iter: 1170/1170
--
Training Step: 371  | total loss: [1m[32m0.14363[0m[0m | time: 1.170s
[2K
| Adam | epoch: 011 | loss: 0.14363 - acc: 0.9558 -- iter: 0032/1170
[A[ATraining Step: 372  | total loss: [1m[32m0.14643[0m[0m | time: 2.290s
[2K
| Adam | epoch: 011 | loss: 0.14643 - acc: 0.9508 -- iter: 0064/1170
[A[ATraining Step: 373  | total loss: [1m[32m0.18174[0m[0m | time: 3.140s
[2K
| Adam | epoch: 011 | loss: 0.18174 - acc: 0.9339 -- iter: 0096/1170
[A[ATraining Step: 374  | total loss: [1m[32m0.18456[0m[0m | time: 4.067s
[2K
| Adam | epoch: 011 | loss: 0.18456 - acc: 0.9311 -- iter: 0128/1170
[A[ATraining Step: 375  | total loss: [1m[32m0.17567[0m[0m | time: 4.984s
[2K
| Adam | epoch: 011 | loss: 0.17567 - acc: 0.9286 -- iter: 0160/1170
[A[ATraining Step: 376  | total loss: [1m[32m0.22103[0m[0m | time: 5.877s
[2K
| Adam | epoch: 011 | loss: 0.22103 - acc: 0.9107 -- iter: 0192/1170
[A[ATraining Step: 377  | total loss: [1m[32m0.23091[0m[0m | time: 6.878s
[2K
| Adam | epoch: 011 | loss: 0.23091 - acc: 0.9072 -- iter: 0224/1170
[A[ATraining Step: 378  | total loss: [1m[32m0.23708[0m[0m | time: 7.883s
[2K
| Adam | epoch: 011 | loss: 0.23708 - acc: 0.9040 -- iter: 0256/1170
[A[ATraining Step: 379  | total loss: [1m[32m0.22834[0m[0m | time: 8.398s
[2K
| Adam | epoch: 011 | loss: 0.22834 - acc: 0.9073 -- iter: 0288/1170
[A[ATraining Step: 380  | total loss: [1m[32m0.23201[0m[0m | time: 8.974s
[2K
| Adam | epoch: 011 | loss: 0.23201 - acc: 0.9110 -- iter: 0320/1170
[A[ATraining Step: 381  | total loss: [1m[32m0.21736[0m[0m | time: 10.075s
[2K
| Adam | epoch: 011 | loss: 0.21736 - acc: 0.9144 -- iter: 0352/1170
[A[ATraining Step: 382  | total loss: [1m[32m0.20188[0m[0m | time: 11.239s
[2K
| Adam | epoch: 011 | loss: 0.20188 - acc: 0.9229 -- iter: 0384/1170
[A[ATraining Step: 383  | total loss: [1m[32m0.20971[0m[0m | time: 12.358s
[2K
| Adam | epoch: 011 | loss: 0.20971 - acc: 0.9181 -- iter: 0416/1170
[A[ATraining Step: 384  | total loss: [1m[32m0.23178[0m[0m | time: 13.185s
[2K
| Adam | epoch: 011 | loss: 0.23178 - acc: 0.9107 -- iter: 0448/1170
[A[ATraining Step: 385  | total loss: [1m[32m0.21816[0m[0m | time: 14.060s
[2K
| Adam | epoch: 011 | loss: 0.21816 - acc: 0.9134 -- iter: 0480/1170
[A[ATraining Step: 386  | total loss: [1m[32m0.21218[0m[0m | time: 14.996s
[2K
| Adam | epoch: 011 | loss: 0.21218 - acc: 0.9158 -- iter: 0512/1170
[A[ATraining Step: 387  | total loss: [1m[32m0.21670[0m[0m | time: 15.928s
[2K
| Adam | epoch: 011 | loss: 0.21670 - acc: 0.9180 -- iter: 0544/1170
[A[ATraining Step: 388  | total loss: [1m[32m0.19787[0m[0m | time: 16.963s
[2K
| Adam | epoch: 011 | loss: 0.19787 - acc: 0.9262 -- iter: 0576/1170
[A[ATraining Step: 389  | total loss: [1m[32m0.18576[0m[0m | time: 17.986s
[2K
| Adam | epoch: 011 | loss: 0.18576 - acc: 0.9304 -- iter: 0608/1170
[A[ATraining Step: 390  | total loss: [1m[32m0.17673[0m[0m | time: 18.857s
[2K
| Adam | epoch: 011 | loss: 0.17673 - acc: 0.9374 -- iter: 0640/1170
[A[ATraining Step: 391  | total loss: [1m[32m0.17723[0m[0m | time: 19.866s
[2K
| Adam | epoch: 011 | loss: 0.17723 - acc: 0.9374 -- iter: 0672/1170
[A[ATraining Step: 392  | total loss: [1m[32m0.17780[0m[0m | time: 20.984s
[2K
| Adam | epoch: 011 | loss: 0.17780 - acc: 0.9374 -- iter: 0704/1170
[A[ATraining Step: 393  | total loss: [1m[32m0.16979[0m[0m | time: 22.266s
[2K
| Adam | epoch: 011 | loss: 0.16979 - acc: 0.9405 -- iter: 0736/1170
[A[ATraining Step: 394  | total loss: [1m[32m0.17789[0m[0m | time: 23.181s
[2K
| Adam | epoch: 011 | loss: 0.17789 - acc: 0.9340 -- iter: 0768/1170
[A[ATraining Step: 395  | total loss: [1m[32m0.17223[0m[0m | time: 24.144s
[2K
| Adam | epoch: 011 | loss: 0.17223 - acc: 0.9375 -- iter: 0800/1170
[A[ATraining Step: 396  | total loss: [1m[32m0.17560[0m[0m | time: 25.098s
[2K
| Adam | epoch: 011 | loss: 0.17560 - acc: 0.9343 -- iter: 0832/1170
[A[ATraining Step: 397  | total loss: [1m[32m0.17024[0m[0m | time: 26.057s
[2K
| Adam | epoch: 011 | loss: 0.17024 - acc: 0.9378 -- iter: 0864/1170
[A[ATraining Step: 398  | total loss: [1m[32m0.18346[0m[0m | time: 27.029s
[2K
| Adam | epoch: 011 | loss: 0.18346 - acc: 0.9315 -- iter: 0896/1170
[A[ATraining Step: 399  | total loss: [1m[32m0.19826[0m[0m | time: 28.122s
[2K
| Adam | epoch: 011 | loss: 0.19826 - acc: 0.9321 -- iter: 0928/1170
[A[ATraining Step: 400  | total loss: [1m[32m0.19385[0m[0m | time: 30.703s
[2K
| Adam | epoch: 011 | loss: 0.19385 - acc: 0.9326 | val_loss: 0.61047 - val_acc: 0.7760 -- iter: 0960/1170
--
Training Step: 401  | total loss: [1m[32m0.18214[0m[0m | time: 31.813s
[2K
| Adam | epoch: 011 | loss: 0.18214 - acc: 0.9363 -- iter: 0992/1170
[A[ATraining Step: 402  | total loss: [1m[32m0.21351[0m[0m | time: 32.707s
[2K
| Adam | epoch: 011 | loss: 0.21351 - acc: 0.9270 -- iter: 1024/1170
[A[ATraining Step: 403  | total loss: [1m[32m0.23069[0m[0m | time: 33.653s
[2K
| Adam | epoch: 011 | loss: 0.23069 - acc: 0.9187 -- iter: 1056/1170
[A[ATraining Step: 404  | total loss: [1m[32m0.22975[0m[0m | time: 34.637s
[2K
| Adam | epoch: 011 | loss: 0.22975 - acc: 0.9112 -- iter: 1088/1170
[A[ATraining Step: 405  | total loss: [1m[32m0.22253[0m[0m | time: 35.647s
[2K
| Adam | epoch: 011 | loss: 0.22253 - acc: 0.9107 -- iter: 1120/1170
[A[ATraining Step: 406  | total loss: [1m[32m0.21037[0m[0m | time: 36.687s
[2K
| Adam | epoch: 011 | loss: 0.21037 - acc: 0.9165 -- iter: 1152/1170
[A[ATraining Step: 407  | total loss: [1m[32m0.26910[0m[0m | time: 39.331s
[2K
| Adam | epoch: 011 | loss: 0.26910 - acc: 0.8873 | val_loss: 0.64213 - val_acc: 0.7486 -- iter: 1170/1170
--
Training Step: 408  | total loss: [1m[32m0.27731[0m[0m | time: 0.972s
[2K
| Adam | epoch: 012 | loss: 0.27731 - acc: 0.8736 -- iter: 0032/1170
[A[ATraining Step: 409  | total loss: [1m[32m0.26356[0m[0m | time: 1.879s
[2K
| Adam | epoch: 012 | loss: 0.26356 - acc: 0.8800 -- iter: 0064/1170
[A[ATraining Step: 410  | total loss: [1m[32m0.24256[0m[0m | time: 2.810s
[2K
| Adam | epoch: 012 | loss: 0.24256 - acc: 0.8920 -- iter: 0096/1170
[A[ATraining Step: 411  | total loss: [1m[32m0.22814[0m[0m | time: 3.867s
[2K
| Adam | epoch: 012 | loss: 0.22814 - acc: 0.8997 -- iter: 0128/1170
[A[ATraining Step: 412  | total loss: [1m[32m0.22157[0m[0m | time: 4.913s
[2K
| Adam | epoch: 012 | loss: 0.22157 - acc: 0.9035 -- iter: 0160/1170
[A[ATraining Step: 413  | total loss: [1m[32m0.24437[0m[0m | time: 5.839s
[2K
| Adam | epoch: 012 | loss: 0.24437 - acc: 0.8944 -- iter: 0192/1170
[A[ATraining Step: 414  | total loss: [1m[32m0.23202[0m[0m | time: 6.914s
[2K
| Adam | epoch: 012 | loss: 0.23202 - acc: 0.8987 -- iter: 0224/1170
[A[ATraining Step: 415  | total loss: [1m[32m0.21187[0m[0m | time: 8.036s
[2K
| Adam | epoch: 012 | loss: 0.21187 - acc: 0.9088 -- iter: 0256/1170
[A[ATraining Step: 416  | total loss: [1m[32m0.20630[0m[0m | time: 9.042s
[2K
| Adam | epoch: 012 | loss: 0.20630 - acc: 0.9054 -- iter: 0288/1170
[A[ATraining Step: 417  | total loss: [1m[32m0.20759[0m[0m | time: 9.515s
[2K
| Adam | epoch: 012 | loss: 0.20759 - acc: 0.9055 -- iter: 0320/1170
[A[ATraining Step: 418  | total loss: [1m[32m0.20939[0m[0m | time: 10.050s
[2K
| Adam | epoch: 012 | loss: 0.20939 - acc: 0.9094 -- iter: 0352/1170
[A[ATraining Step: 419  | total loss: [1m[32m0.19189[0m[0m | time: 11.012s
[2K
| Adam | epoch: 012 | loss: 0.19189 - acc: 0.9185 -- iter: 0384/1170
[A[ATraining Step: 420  | total loss: [1m[32m0.17802[0m[0m | time: 11.982s
[2K
| Adam | epoch: 012 | loss: 0.17802 - acc: 0.9235 -- iter: 0416/1170
[A[ATraining Step: 421  | total loss: [1m[32m0.18953[0m[0m | time: 12.929s
[2K
| Adam | epoch: 012 | loss: 0.18953 - acc: 0.9155 -- iter: 0448/1170
[A[ATraining Step: 422  | total loss: [1m[32m0.21961[0m[0m | time: 13.992s
[2K
| Adam | epoch: 012 | loss: 0.21961 - acc: 0.9021 -- iter: 0480/1170
[A[ATraining Step: 423  | total loss: [1m[32m0.23012[0m[0m | time: 14.988s
[2K
| Adam | epoch: 012 | loss: 0.23012 - acc: 0.8931 -- iter: 0512/1170
[A[ATraining Step: 424  | total loss: [1m[32m0.28582[0m[0m | time: 15.865s
[2K
| Adam | epoch: 012 | loss: 0.28582 - acc: 0.8882 -- iter: 0544/1170
[A[ATraining Step: 425  | total loss: [1m[32m0.27715[0m[0m | time: 16.970s
[2K
| Adam | epoch: 012 | loss: 0.27715 - acc: 0.8931 -- iter: 0576/1170
[A[ATraining Step: 426  | total loss: [1m[32m0.31787[0m[0m | time: 18.072s
[2K
| Adam | epoch: 012 | loss: 0.31787 - acc: 0.8726 -- iter: 0608/1170
[A[ATraining Step: 427  | total loss: [1m[32m0.31964[0m[0m | time: 19.137s
[2K
| Adam | epoch: 012 | loss: 0.31964 - acc: 0.8697 -- iter: 0640/1170
[A[ATraining Step: 428  | total loss: [1m[32m0.31431[0m[0m | time: 20.004s
[2K
| Adam | epoch: 012 | loss: 0.31431 - acc: 0.8733 -- iter: 0672/1170
[A[ATraining Step: 429  | total loss: [1m[32m0.29242[0m[0m | time: 20.943s
[2K
| Adam | epoch: 012 | loss: 0.29242 - acc: 0.8829 -- iter: 0704/1170
[A[ATraining Step: 430  | total loss: [1m[32m0.27604[0m[0m | time: 21.846s
[2K
| Adam | epoch: 012 | loss: 0.27604 - acc: 0.8915 -- iter: 0736/1170
[A[ATraining Step: 431  | total loss: [1m[32m0.25407[0m[0m | time: 22.834s
[2K
| Adam | epoch: 012 | loss: 0.25407 - acc: 0.9023 -- iter: 0768/1170
[A[ATraining Step: 432  | total loss: [1m[32m0.24898[0m[0m | time: 23.810s
[2K
| Adam | epoch: 012 | loss: 0.24898 - acc: 0.9090 -- iter: 0800/1170
[A[ATraining Step: 433  | total loss: [1m[32m0.24596[0m[0m | time: 24.861s
[2K
| Adam | epoch: 012 | loss: 0.24596 - acc: 0.9087 -- iter: 0832/1170
[A[ATraining Step: 434  | total loss: [1m[32m0.22975[0m[0m | time: 25.750s
[2K
| Adam | epoch: 012 | loss: 0.22975 - acc: 0.9178 -- iter: 0864/1170
[A[ATraining Step: 435  | total loss: [1m[32m0.21953[0m[0m | time: 26.740s
[2K
| Adam | epoch: 012 | loss: 0.21953 - acc: 0.9229 -- iter: 0896/1170
[A[ATraining Step: 436  | total loss: [1m[32m0.21157[0m[0m | time: 27.762s
[2K
| Adam | epoch: 012 | loss: 0.21157 - acc: 0.9275 -- iter: 0928/1170
[A[ATraining Step: 437  | total loss: [1m[32m0.20225[0m[0m | time: 28.796s
[2K
| Adam | epoch: 012 | loss: 0.20225 - acc: 0.9316 -- iter: 0960/1170
[A[ATraining Step: 438  | total loss: [1m[32m0.19031[0m[0m | time: 29.842s
[2K
| Adam | epoch: 012 | loss: 0.19031 - acc: 0.9385 -- iter: 0992/1170
[A[ATraining Step: 439  | total loss: [1m[32m0.17889[0m[0m | time: 30.885s
[2K
| Adam | epoch: 012 | loss: 0.17889 - acc: 0.9446 -- iter: 1024/1170
[A[ATraining Step: 440  | total loss: [1m[32m0.17985[0m[0m | time: 31.954s
[2K
| Adam | epoch: 012 | loss: 0.17985 - acc: 0.9439 -- iter: 1056/1170
[A[ATraining Step: 441  | total loss: [1m[32m0.17491[0m[0m | time: 32.962s
[2K
| Adam | epoch: 012 | loss: 0.17491 - acc: 0.9433 -- iter: 1088/1170
[A[ATraining Step: 442  | total loss: [1m[32m0.16309[0m[0m | time: 34.039s
[2K
| Adam | epoch: 012 | loss: 0.16309 - acc: 0.9489 -- iter: 1120/1170
[A[ATraining Step: 443  | total loss: [1m[32m0.15797[0m[0m | time: 35.025s
[2K
| Adam | epoch: 012 | loss: 0.15797 - acc: 0.9509 -- iter: 1152/1170
[A[ATraining Step: 444  | total loss: [1m[32m0.14961[0m[0m | time: 37.118s
[2K
| Adam | epoch: 012 | loss: 0.14961 - acc: 0.9527 | val_loss: 0.34656 - val_acc: 0.8770 -- iter: 1170/1170
--
Training Step: 445  | total loss: [1m[32m0.13897[0m[0m | time: 0.631s
[2K
| Adam | epoch: 013 | loss: 0.13897 - acc: 0.9543 -- iter: 0032/1170
[A[ATraining Step: 446  | total loss: [1m[32m0.12738[0m[0m | time: 1.246s
[2K
| Adam | epoch: 013 | loss: 0.12738 - acc: 0.9589 -- iter: 0064/1170
[A[ATraining Step: 447  | total loss: [1m[32m0.13062[0m[0m | time: 1.870s
[2K
| Adam | epoch: 013 | loss: 0.13062 - acc: 0.9536 -- iter: 0096/1170
[A[ATraining Step: 448  | total loss: [1m[32m0.14429[0m[0m | time: 2.501s
[2K
| Adam | epoch: 013 | loss: 0.14429 - acc: 0.9458 -- iter: 0128/1170
[A[ATraining Step: 449  | total loss: [1m[32m0.13736[0m[0m | time: 3.130s
[2K
| Adam | epoch: 013 | loss: 0.13736 - acc: 0.9481 -- iter: 0160/1170
[A[ATraining Step: 450  | total loss: [1m[32m0.12730[0m[0m | time: 3.735s
[2K
| Adam | epoch: 013 | loss: 0.12730 - acc: 0.9532 -- iter: 0192/1170
[A[ATraining Step: 451  | total loss: [1m[32m0.11641[0m[0m | time: 4.356s
[2K
| Adam | epoch: 013 | loss: 0.11641 - acc: 0.9579 -- iter: 0224/1170
[A[ATraining Step: 452  | total loss: [1m[32m0.10844[0m[0m | time: 4.976s
[2K
| Adam | epoch: 013 | loss: 0.10844 - acc: 0.9621 -- iter: 0256/1170
[A[ATraining Step: 453  | total loss: [1m[32m0.10033[0m[0m | time: 5.599s
[2K
| Adam | epoch: 013 | loss: 0.10033 - acc: 0.9659 -- iter: 0288/1170
[A[ATraining Step: 454  | total loss: [1m[32m0.10024[0m[0m | time: 6.226s
[2K
| Adam | epoch: 013 | loss: 0.10024 - acc: 0.9662 -- iter: 0320/1170
[A[ATraining Step: 455  | total loss: [1m[32m0.09425[0m[0m | time: 6.583s
[2K
| Adam | epoch: 013 | loss: 0.09425 - acc: 0.9696 -- iter: 0352/1170
[A[ATraining Step: 456  | total loss: [1m[32m0.08533[0m[0m | time: 6.951s
[2K
| Adam | epoch: 013 | loss: 0.08533 - acc: 0.9726 -- iter: 0384/1170
[A[ATraining Step: 457  | total loss: [1m[32m0.07742[0m[0m | time: 7.558s
[2K
| Adam | epoch: 013 | loss: 0.07742 - acc: 0.9754 -- iter: 0416/1170
[A[ATraining Step: 458  | total loss: [1m[32m0.09048[0m[0m | time: 8.170s
[2K
| Adam | epoch: 013 | loss: 0.09048 - acc: 0.9747 -- iter: 0448/1170
[A[ATraining Step: 459  | total loss: [1m[32m0.10120[0m[0m | time: 8.789s
[2K
| Adam | epoch: 013 | loss: 0.10120 - acc: 0.9710 -- iter: 0480/1170
[A[ATraining Step: 460  | total loss: [1m[32m0.09186[0m[0m | time: 9.410s
[2K
| Adam | epoch: 013 | loss: 0.09186 - acc: 0.9739 -- iter: 0512/1170
[A[ATraining Step: 461  | total loss: [1m[32m0.09286[0m[0m | time: 10.022s
[2K
| Adam | epoch: 013 | loss: 0.09286 - acc: 0.9734 -- iter: 0544/1170
[A[ATraining Step: 462  | total loss: [1m[32m0.10509[0m[0m | time: 10.632s
[2K
| Adam | epoch: 013 | loss: 0.10509 - acc: 0.9729 -- iter: 0576/1170
[A[ATraining Step: 463  | total loss: [1m[32m0.09531[0m[0m | time: 11.238s
[2K
| Adam | epoch: 013 | loss: 0.09531 - acc: 0.9756 -- iter: 0608/1170
[A[ATraining Step: 464  | total loss: [1m[32m0.08640[0m[0m | time: 11.857s
[2K
| Adam | epoch: 013 | loss: 0.08640 - acc: 0.9781 -- iter: 0640/1170
[A[ATraining Step: 465  | total loss: [1m[32m0.08934[0m[0m | time: 12.509s
[2K
| Adam | epoch: 013 | loss: 0.08934 - acc: 0.9771 -- iter: 0672/1170
[A[ATraining Step: 466  | total loss: [1m[32m0.08159[0m[0m | time: 13.124s
[2K
| Adam | epoch: 013 | loss: 0.08159 - acc: 0.9794 -- iter: 0704/1170
[A[ATraining Step: 467  | total loss: [1m[32m0.08687[0m[0m | time: 13.740s
[2K
| Adam | epoch: 013 | loss: 0.08687 - acc: 0.9783 -- iter: 0736/1170
[A[ATraining Step: 468  | total loss: [1m[32m0.08402[0m[0m | time: 14.538s
[2K
| Adam | epoch: 013 | loss: 0.08402 - acc: 0.9774 -- iter: 0768/1170
[A[ATraining Step: 469  | total loss: [1m[32m0.07637[0m[0m | time: 15.579s
[2K
| Adam | epoch: 013 | loss: 0.07637 - acc: 0.9796 -- iter: 0800/1170
[A[ATraining Step: 470  | total loss: [1m[32m0.06948[0m[0m | time: 16.756s
[2K
| Adam | epoch: 013 | loss: 0.06948 - acc: 0.9817 -- iter: 0832/1170
[A[ATraining Step: 471  | total loss: [1m[32m0.07586[0m[0m | time: 17.833s
[2K
| Adam | epoch: 013 | loss: 0.07586 - acc: 0.9773 -- iter: 0864/1170
[A[ATraining Step: 472  | total loss: [1m[32m0.07843[0m[0m | time: 18.808s
[2K
| Adam | epoch: 013 | loss: 0.07843 - acc: 0.9764 -- iter: 0896/1170
[A[ATraining Step: 473  | total loss: [1m[32m0.10072[0m[0m | time: 19.796s
[2K
| Adam | epoch: 013 | loss: 0.10072 - acc: 0.9756 -- iter: 0928/1170
[A[ATraining Step: 474  | total loss: [1m[32m0.10757[0m[0m | time: 20.715s
[2K
| Adam | epoch: 013 | loss: 0.10757 - acc: 0.9687 -- iter: 0960/1170
[A[ATraining Step: 475  | total loss: [1m[32m0.10997[0m[0m | time: 21.666s
[2K
| Adam | epoch: 013 | loss: 0.10997 - acc: 0.9687 -- iter: 0992/1170
[A[ATraining Step: 476  | total loss: [1m[32m0.10290[0m[0m | time: 22.753s
[2K
| Adam | epoch: 013 | loss: 0.10290 - acc: 0.9718 -- iter: 1024/1170
[A[ATraining Step: 477  | total loss: [1m[32m0.09840[0m[0m | time: 23.725s
[2K
| Adam | epoch: 013 | loss: 0.09840 - acc: 0.9715 -- iter: 1056/1170
[A[ATraining Step: 478  | total loss: [1m[32m0.09279[0m[0m | time: 24.633s
[2K
| Adam | epoch: 013 | loss: 0.09279 - acc: 0.9744 -- iter: 1088/1170
[A[ATraining Step: 479  | total loss: [1m[32m0.10026[0m[0m | time: 25.692s
[2K
| Adam | epoch: 013 | loss: 0.10026 - acc: 0.9707 -- iter: 1120/1170
[A[ATraining Step: 480  | total loss: [1m[32m0.09540[0m[0m | time: 26.861s
[2K
| Adam | epoch: 013 | loss: 0.09540 - acc: 0.9705 -- iter: 1152/1170
[A[ATraining Step: 481  | total loss: [1m[32m0.08860[0m[0m | time: 29.538s
[2K
| Adam | epoch: 013 | loss: 0.08860 - acc: 0.9734 | val_loss: 0.39224 - val_acc: 0.8497 -- iter: 1170/1170
--
Training Step: 482  | total loss: [1m[32m0.08246[0m[0m | time: 0.998s
[2K
| Adam | epoch: 014 | loss: 0.08246 - acc: 0.9761 -- iter: 0032/1170
[A[ATraining Step: 483  | total loss: [1m[32m0.08941[0m[0m | time: 1.930s
[2K
| Adam | epoch: 014 | loss: 0.08941 - acc: 0.9754 -- iter: 0064/1170
[A[ATraining Step: 484  | total loss: [1m[32m0.08771[0m[0m | time: 3.010s
[2K
| Adam | epoch: 014 | loss: 0.08771 - acc: 0.9747 -- iter: 0096/1170
[A[ATraining Step: 485  | total loss: [1m[32m0.08134[0m[0m | time: 4.167s
[2K
| Adam | epoch: 014 | loss: 0.08134 - acc: 0.9772 -- iter: 0128/1170
[A[ATraining Step: 486  | total loss: [1m[32m0.08366[0m[0m | time: 5.225s
[2K
| Adam | epoch: 014 | loss: 0.08366 - acc: 0.9764 -- iter: 0160/1170
[A[ATraining Step: 487  | total loss: [1m[32m0.07761[0m[0m | time: 6.088s
[2K
| Adam | epoch: 014 | loss: 0.07761 - acc: 0.9787 -- iter: 0192/1170
[A[ATraining Step: 488  | total loss: [1m[32m0.07581[0m[0m | time: 7.103s
[2K
| Adam | epoch: 014 | loss: 0.07581 - acc: 0.9777 -- iter: 0224/1170
[A[ATraining Step: 489  | total loss: [1m[32m0.06994[0m[0m | time: 8.108s
[2K
| Adam | epoch: 014 | loss: 0.06994 - acc: 0.9800 -- iter: 0256/1170
[A[ATraining Step: 490  | total loss: [1m[32m0.06691[0m[0m | time: 9.073s
[2K
| Adam | epoch: 014 | loss: 0.06691 - acc: 0.9820 -- iter: 0288/1170
[A[ATraining Step: 491  | total loss: [1m[32m0.06528[0m[0m | time: 10.157s
[2K
| Adam | epoch: 014 | loss: 0.06528 - acc: 0.9807 -- iter: 0320/1170
[A[ATraining Step: 492  | total loss: [1m[32m0.06400[0m[0m | time: 11.083s
[2K
| Adam | epoch: 014 | loss: 0.06400 - acc: 0.9795 -- iter: 0352/1170
[A[ATraining Step: 493  | total loss: [1m[32m0.06389[0m[0m | time: 11.523s
[2K
| Adam | epoch: 014 | loss: 0.06389 - acc: 0.9784 -- iter: 0384/1170
[A[ATraining Step: 494  | total loss: [1m[32m0.07594[0m[0m | time: 12.158s
[2K
| Adam | epoch: 014 | loss: 0.07594 - acc: 0.9694 -- iter: 0416/1170
[A[ATraining Step: 495  | total loss: [1m[32m0.07692[0m[0m | time: 13.302s
[2K
| Adam | epoch: 014 | loss: 0.07692 - acc: 0.9725 -- iter: 0448/1170
[A[ATraining Step: 496  | total loss: [1m[32m0.07079[0m[0m | time: 14.588s
[2K
| Adam | epoch: 014 | loss: 0.07079 - acc: 0.9752 -- iter: 0480/1170
[A[ATraining Step: 497  | total loss: [1m[32m0.07982[0m[0m | time: 15.491s
[2K
| Adam | epoch: 014 | loss: 0.07982 - acc: 0.9715 -- iter: 0512/1170
[A[ATraining Step: 498  | total loss: [1m[32m0.07323[0m[0m | time: 16.412s
[2K
| Adam | epoch: 014 | loss: 0.07323 - acc: 0.9743 -- iter: 0544/1170
[A[ATraining Step: 499  | total loss: [1m[32m0.08005[0m[0m | time: 17.399s
[2K
| Adam | epoch: 014 | loss: 0.08005 - acc: 0.9738 -- iter: 0576/1170
[A[ATraining Step: 500  | total loss: [1m[32m0.10662[0m[0m | time: 18.450s
[2K
| Adam | epoch: 014 | loss: 0.10662 - acc: 0.9670 -- iter: 0608/1170
[A[ATraining Step: 501  | total loss: [1m[32m0.09660[0m[0m | time: 19.509s
[2K
| Adam | epoch: 014 | loss: 0.09660 - acc: 0.9703 -- iter: 0640/1170
[A[ATraining Step: 502  | total loss: [1m[32m0.12453[0m[0m | time: 20.544s
[2K
| Adam | epoch: 014 | loss: 0.12453 - acc: 0.9608 -- iter: 0672/1170
[A[ATraining Step: 503  | total loss: [1m[32m0.14511[0m[0m | time: 21.426s
[2K
| Adam | epoch: 014 | loss: 0.14511 - acc: 0.9553 -- iter: 0704/1170
[A[ATraining Step: 504  | total loss: [1m[32m0.15022[0m[0m | time: 22.518s
[2K
| Adam | epoch: 014 | loss: 0.15022 - acc: 0.9504 -- iter: 0736/1170
[A[ATraining Step: 505  | total loss: [1m[32m0.13715[0m[0m | time: 23.627s
[2K
| Adam | epoch: 014 | loss: 0.13715 - acc: 0.9554 -- iter: 0768/1170
[A[ATraining Step: 506  | total loss: [1m[32m0.14518[0m[0m | time: 24.878s
[2K
| Adam | epoch: 014 | loss: 0.14518 - acc: 0.9442 -- iter: 0800/1170
[A[ATraining Step: 507  | total loss: [1m[32m0.16833[0m[0m | time: 25.684s
[2K
| Adam | epoch: 014 | loss: 0.16833 - acc: 0.9310 -- iter: 0832/1170
[A[ATraining Step: 508  | total loss: [1m[32m0.17749[0m[0m | time: 26.605s
[2K
| Adam | epoch: 014 | loss: 0.17749 - acc: 0.9192 -- iter: 0864/1170
[A[ATraining Step: 509  | total loss: [1m[32m0.16367[0m[0m | time: 27.559s
[2K
| Adam | epoch: 014 | loss: 0.16367 - acc: 0.9273 -- iter: 0896/1170
[A[ATraining Step: 510  | total loss: [1m[32m0.15093[0m[0m | time: 28.523s
[2K
| Adam | epoch: 014 | loss: 0.15093 - acc: 0.9345 -- iter: 0928/1170
[A[ATraining Step: 511  | total loss: [1m[32m0.16839[0m[0m | time: 29.580s
[2K
| Adam | epoch: 014 | loss: 0.16839 - acc: 0.9255 -- iter: 0960/1170
[A[ATraining Step: 512  | total loss: [1m[32m0.17035[0m[0m | time: 30.638s
[2K
| Adam | epoch: 014 | loss: 0.17035 - acc: 0.9267 -- iter: 0992/1170
[A[ATraining Step: 513  | total loss: [1m[32m0.15917[0m[0m | time: 31.526s
[2K
| Adam | epoch: 014 | loss: 0.15917 - acc: 0.9340 -- iter: 1024/1170
[A[ATraining Step: 514  | total loss: [1m[32m0.14652[0m[0m | time: 32.550s
[2K
| Adam | epoch: 014 | loss: 0.14652 - acc: 0.9406 -- iter: 1056/1170
[A[ATraining Step: 515  | total loss: [1m[32m0.13816[0m[0m | time: 33.686s
[2K
| Adam | epoch: 014 | loss: 0.13816 - acc: 0.9434 -- iter: 1088/1170
[A[ATraining Step: 516  | total loss: [1m[32m0.13814[0m[0m | time: 34.910s
[2K
| Adam | epoch: 014 | loss: 0.13814 - acc: 0.9428 -- iter: 1120/1170
[A[ATraining Step: 517  | total loss: [1m[32m0.12738[0m[0m | time: 35.708s
[2K
| Adam | epoch: 014 | loss: 0.12738 - acc: 0.9485 -- iter: 1152/1170
[A[ATraining Step: 518  | total loss: [1m[32m0.11717[0m[0m | time: 38.375s
[2K
| Adam | epoch: 014 | loss: 0.11717 - acc: 0.9537 | val_loss: 0.43308 - val_acc: 0.8689 -- iter: 1170/1170
--
Training Step: 519  | total loss: [1m[32m0.10755[0m[0m | time: 1.149s
[2K
| Adam | epoch: 015 | loss: 0.10755 - acc: 0.9583 -- iter: 0032/1170
[A[ATraining Step: 520  | total loss: [1m[32m0.10127[0m[0m | time: 2.305s
[2K
| Adam | epoch: 015 | loss: 0.10127 - acc: 0.9625 -- iter: 0064/1170
[A[ATraining Step: 521  | total loss: [1m[32m0.09214[0m[0m | time: 3.460s
[2K
| Adam | epoch: 015 | loss: 0.09214 - acc: 0.9662 -- iter: 0096/1170
[A[ATraining Step: 522  | total loss: [1m[32m0.09366[0m[0m | time: 4.328s
[2K
| Adam | epoch: 015 | loss: 0.09366 - acc: 0.9665 -- iter: 0128/1170
[A[ATraining Step: 523  | total loss: [1m[32m0.08596[0m[0m | time: 5.242s
[2K
| Adam | epoch: 015 | loss: 0.08596 - acc: 0.9698 -- iter: 0160/1170
[A[ATraining Step: 524  | total loss: [1m[32m0.08009[0m[0m | time: 6.185s
[2K
| Adam | epoch: 015 | loss: 0.08009 - acc: 0.9729 -- iter: 0192/1170
[A[ATraining Step: 525  | total loss: [1m[32m0.07290[0m[0m | time: 7.147s
[2K
| Adam | epoch: 015 | loss: 0.07290 - acc: 0.9756 -- iter: 0224/1170
[A[ATraining Step: 526  | total loss: [1m[32m0.06808[0m[0m | time: 8.171s
[2K
| Adam | epoch: 015 | loss: 0.06808 - acc: 0.9780 -- iter: 0256/1170
[A[ATraining Step: 527  | total loss: [1m[32m0.06178[0m[0m | time: 9.157s
[2K
| Adam | epoch: 015 | loss: 0.06178 - acc: 0.9802 -- iter: 0288/1170
[A[ATraining Step: 528  | total loss: [1m[32m0.05705[0m[0m | time: 10.018s
[2K
| Adam | epoch: 015 | loss: 0.05705 - acc: 0.9822 -- iter: 0320/1170
[A[ATraining Step: 529  | total loss: [1m[32m0.05488[0m[0m | time: 11.115s
[2K
| Adam | epoch: 015 | loss: 0.05488 - acc: 0.9840 -- iter: 0352/1170
[A[ATraining Step: 530  | total loss: [1m[32m0.05366[0m[0m | time: 12.193s
[2K
| Adam | epoch: 015 | loss: 0.05366 - acc: 0.9824 -- iter: 0384/1170
[A[ATraining Step: 531  | total loss: [1m[32m0.04947[0m[0m | time: 12.886s
[2K
| Adam | epoch: 015 | loss: 0.04947 - acc: 0.9842 -- iter: 0416/1170
[A[ATraining Step: 532  | total loss: [1m[32m0.04492[0m[0m | time: 13.612s
[2K
| Adam | epoch: 015 | loss: 0.04492 - acc: 0.9858 -- iter: 0448/1170
[A[ATraining Step: 533  | total loss: [1m[32m0.04083[0m[0m | time: 14.443s
[2K
| Adam | epoch: 015 | loss: 0.04083 - acc: 0.9872 -- iter: 0480/1170
[A[ATraining Step: 534  | total loss: [1m[32m0.04016[0m[0m | time: 15.300s
[2K
| Adam | epoch: 015 | loss: 0.04016 - acc: 0.9885 -- iter: 0512/1170
[A[ATraining Step: 535  | total loss: [1m[32m0.05414[0m[0m | time: 16.205s
[2K
| Adam | epoch: 015 | loss: 0.05414 - acc: 0.9803 -- iter: 0544/1170
[A[ATraining Step: 536  | total loss: [1m[32m0.04910[0m[0m | time: 17.069s
[2K
| Adam | epoch: 015 | loss: 0.04910 - acc: 0.9822 -- iter: 0576/1170
[A[ATraining Step: 537  | total loss: [1m[32m0.05402[0m[0m | time: 18.032s
[2K
| Adam | epoch: 015 | loss: 0.05402 - acc: 0.9809 -- iter: 0608/1170
[A[ATraining Step: 538  | total loss: [1m[32m0.08502[0m[0m | time: 19.086s
[2K
| Adam | epoch: 015 | loss: 0.08502 - acc: 0.9640 -- iter: 0640/1170
[A[ATraining Step: 539  | total loss: [1m[32m0.12337[0m[0m | time: 19.995s
[2K
| Adam | epoch: 015 | loss: 0.12337 - acc: 0.9520 -- iter: 0672/1170
[A[ATraining Step: 540  | total loss: [1m[32m0.12249[0m[0m | time: 20.913s
[2K
| Adam | epoch: 015 | loss: 0.12249 - acc: 0.9537 -- iter: 0704/1170
[A[ATraining Step: 541  | total loss: [1m[32m0.11065[0m[0m | time: 21.952s
[2K
| Adam | epoch: 015 | loss: 0.11065 - acc: 0.9583 -- iter: 0736/1170
[A[ATraining Step: 542  | total loss: [1m[32m0.10138[0m[0m | time: 23.014s
[2K
| Adam | epoch: 015 | loss: 0.10138 - acc: 0.9625 -- iter: 0768/1170
[A[ATraining Step: 543  | total loss: [1m[32m0.11715[0m[0m | time: 23.950s
[2K
| Adam | epoch: 015 | loss: 0.11715 - acc: 0.9600 -- iter: 0800/1170
[A[ATraining Step: 544  | total loss: [1m[32m0.10570[0m[0m | time: 24.825s
[2K
| Adam | epoch: 015 | loss: 0.10570 - acc: 0.9640 -- iter: 0832/1170
[A[ATraining Step: 545  | total loss: [1m[32m0.10195[0m[0m | time: 25.703s
[2K
| Adam | epoch: 015 | loss: 0.10195 - acc: 0.9645 -- iter: 0864/1170
[A[ATraining Step: 546  | total loss: [1m[32m0.09656[0m[0m | time: 26.672s
[2K
| Adam | epoch: 015 | loss: 0.09656 - acc: 0.9649 -- iter: 0896/1170
[A[ATraining Step: 547  | total loss: [1m[32m0.09713[0m[0m | time: 27.705s
[2K
| Adam | epoch: 015 | loss: 0.09713 - acc: 0.9622 -- iter: 0928/1170
[A[ATraining Step: 548  | total loss: [1m[32m0.09094[0m[0m | time: 28.697s
[2K
| Adam | epoch: 015 | loss: 0.09094 - acc: 0.9628 -- iter: 0960/1170
[A[ATraining Step: 549  | total loss: [1m[32m0.08429[0m[0m | time: 29.545s
[2K
| Adam | epoch: 015 | loss: 0.08429 - acc: 0.9665 -- iter: 0992/1170
[A[ATraining Step: 550  | total loss: [1m[32m0.08031[0m[0m | time: 30.584s
[2K
| Adam | epoch: 015 | loss: 0.08031 - acc: 0.9668 -- iter: 1024/1170
[A[ATraining Step: 551  | total loss: [1m[32m0.07274[0m[0m | time: 31.678s
[2K
| Adam | epoch: 015 | loss: 0.07274 - acc: 0.9701 -- iter: 1056/1170
[A[ATraining Step: 552  | total loss: [1m[32m0.06706[0m[0m | time: 32.730s
[2K
| Adam | epoch: 015 | loss: 0.06706 - acc: 0.9731 -- iter: 1088/1170
[A[ATraining Step: 553  | total loss: [1m[32m0.06147[0m[0m | time: 33.611s
[2K
| Adam | epoch: 015 | loss: 0.06147 - acc: 0.9758 -- iter: 1120/1170
[A[ATraining Step: 554  | total loss: [1m[32m0.05662[0m[0m | time: 34.528s
[2K
| Adam | epoch: 015 | loss: 0.05662 - acc: 0.9782 -- iter: 1152/1170
[A[ATraining Step: 555  | total loss: [1m[32m0.05214[0m[0m | time: 37.292s
[2K
| Adam | epoch: 015 | loss: 0.05214 - acc: 0.9804 | val_loss: 0.48280 - val_acc: 0.8716 -- iter: 1170/1170
--
Validation AUC:0.9285248345913708
Validation AUPRC:0.9418288819022779
Test AUC:0.9320659770757618
Test AUPRC:0.9478500371343962
BestTestF1Score	0.9	0.75	0.88	0.86	0.95	209	34	113	10	0.51
BestTestMCCScore	0.89	0.73	0.87	0.87	0.92	202	31	116	17	0.77
BestTestAccuracyScore	0.89	0.73	0.87	0.87	0.92	202	31	116	17	0.77
BestValidationF1Score	0.9	0.73	0.87	0.86	0.94	206	34	113	13	0.51
BestValidationMCC	0.9	0.74	0.87	0.88	0.91	199	26	121	20	0.77
BestValidationAccuracy	0.9	0.74	0.87	0.88	0.91	199	26	121	20	0.77
TestPredictions (Threshold:0.77)
CHEMBL541765,FN,ACT,0.019999999552965164	CHEMBL1200545,TP,ACT,1.0	CHEMBL1329230,TN,INACT,0.4000000059604645	CHEMBL235113,TN,INACT,0.0	CHEMBL196509,TP,ACT,0.9700000286102295	CHEMBL1800985,TP,ACT,1.0	CHEMBL459142,TN,INACT,0.0	CHEMBL3706950,TP,ACT,1.0	CHEMBL195953,FP,INACT,0.9599999785423279	CHEMBL63932,TP,ACT,0.9900000095367432	CHEMBL3358935,TP,ACT,1.0	CHEMBL1762203,TP,ACT,1.0	CHEMBL491820,TN,INACT,0.009999999776482582	CHEMBL258818,TN,INACT,0.33000001311302185	CHEMBL1090805,TP,ACT,1.0	CHEMBL71450,TP,ACT,0.9700000286102295	CHEMBL1384049,FP,INACT,1.0	CHEMBL196232,TP,ACT,1.0	CHEMBL325221,TP,ACT,0.9900000095367432	CHEMBL387094,TN,INACT,0.0	CHEMBL309243,TP,ACT,1.0	CHEMBL272788,TP,ACT,1.0	CHEMBL3138046,TN,INACT,0.3499999940395355	CHEMBL50619,TP,ACT,0.9900000095367432	CHEMBL2381195,FP,INACT,0.9900000095367432	CHEMBL53549,FN,ACT,0.7099999785423279	CHEMBL3138035,FP,INACT,0.8999999761581421	CHEMBL461012,TP,ACT,1.0	CHEMBL3315061,TP,ACT,0.9900000095367432	CHEMBL482531,TN,INACT,0.019999999552965164	CHEMBL515181,TN,INACT,0.009999999776482582	CHEMBL250104,TN,INACT,0.0	CHEMBL2426625,TP,ACT,1.0	CHEMBL230885,TP,ACT,0.9800000190734863	CHEMBL236229,TP,ACT,0.9900000095367432	CHEMBL3234032,FP,INACT,0.8299999833106995	CHEMBL337112,TP,ACT,1.0	CHEMBL3093450,TP,ACT,1.0	CHEMBL1668080,TP,ACT,1.0	CHEMBL389794,TP,ACT,1.0	CHEMBL394344,FN,ACT,0.6700000166893005	CHEMBL237595,TP,ACT,1.0	CHEMBL70449,TP,ACT,1.0	CHEMBL1911660,TP,ACT,0.800000011920929	CHEMBL8639,TP,ACT,0.8299999833106995	CHEMBL550441,TN,INACT,0.0	CHEMBL3109606,FP,INACT,1.0	CHEMBL2426644,TP,ACT,1.0	CHEMBL3613431,TN,INACT,0.4000000059604645	CHEMBL3397914,TN,INACT,0.07000000029802322	CHEMBL371988,TP,ACT,0.9800000190734863	CHEMBL474188,TP,ACT,1.0	CHEMBL3261411,TP,ACT,1.0	CHEMBL1083885,TP,ACT,1.0	CHEMBL3109607,FP,INACT,0.8199999928474426	CHEMBL137103,TP,ACT,1.0	CHEMBL2147553,TP,ACT,1.0	CHEMBL1201207,TP,ACT,1.0	CHEMBL3198515,TN,INACT,0.009999999776482582	CHEMBL503957,TP,ACT,1.0	CHEMBL1547376,TN,INACT,0.4699999988079071	CHEMBL1201139,TP,ACT,0.9900000095367432	CHEMBL1911653,TP,ACT,0.8500000238418579	CHEMBL1448466,TN,INACT,0.0	CHEMBL361362,TN,INACT,0.0	CHEMBL3261406,TP,ACT,1.0	CHEMBL3354989,TN,INACT,0.0	CHEMBL3352882,TP,ACT,1.0	CHEMBL558494,TN,INACT,0.0	CHEMBL566391,TP,ACT,0.9800000190734863	CHEMBL3623111,TN,INACT,0.17000000178813934	CHEMBL233660,TP,ACT,1.0	CHEMBL3315067,TP,ACT,0.9900000095367432	CHEMBL1482875,TN,INACT,0.0	CHEMBL228610,TP,ACT,0.9700000286102295	CHEMBL3581693,TP,ACT,1.0	CHEMBL3234274,TN,INACT,0.5199999809265137	CHEMBL1377708,TN,INACT,0.0	CHEMBL1370919,TN,INACT,0.25	CHEMBL1645401,TP,ACT,1.0	CHEMBL1159650,TP,ACT,0.9900000095367432	CHEMBL2023621,TP,ACT,1.0	CHEMBL3126942,TP,ACT,1.0	CHEMBL79807,TP,ACT,1.0	CHEMBL3397549,TN,INACT,0.0	CHEMBL1835918,TN,INACT,0.0	CHEMBL1087884,FP,INACT,0.9599999785423279	CHEMBL83953,TN,INACT,0.3499999940395355	CHEMBL1083149,TP,ACT,1.0	CHEMBL2087297,TP,ACT,1.0	CHEMBL247051,TP,ACT,1.0	CHEMBL1682435,TP,ACT,0.9900000095367432	CHEMBL1505049,TN,INACT,0.019999999552965164	CHEMBL236855,TP,ACT,1.0	CHEMBL2022660,TP,ACT,1.0	CHEMBL94749,TP,ACT,1.0	CHEMBL77779,TP,ACT,1.0	CHEMBL1094208,TP,ACT,1.0	CHEMBL2403356,TN,INACT,0.11999999731779099	CHEMBL1270644,TN,INACT,0.009999999776482582	CHEMBL2022656,TP,ACT,1.0	CHEMBL304839,TP,ACT,1.0	CHEMBL1288322,TN,INACT,0.009999999776482582	CHEMBL552770,FN,ACT,0.5899999737739563	CHEMBL3828422,TN,INACT,0.0	CHEMBL1668075,TP,ACT,1.0	CHEMBL379159,FN,ACT,0.7200000286102295	CHEMBL1501342,TN,INACT,0.009999999776482582	CHEMBL3233272,FN,ACT,0.6899999976158142	CHEMBL352024,TN,INACT,0.009999999776482582	CHEMBL257462,TP,ACT,1.0	CHEMBL397050,TP,ACT,1.0	CHEMBL1359354,TN,INACT,0.0	CHEMBL981,FP,INACT,0.9200000166893005	CHEMBL3093462,TP,ACT,1.0	CHEMBL1466928,TN,INACT,0.05000000074505806	CHEMBL3358924,TP,ACT,1.0	CHEMBL237496,TP,ACT,0.9900000095367432	CHEMBL3358951,TP,ACT,1.0	CHEMBL3421874,TP,ACT,0.9900000095367432	CHEMBL138197,TP,ACT,1.0	CHEMBL2070878,FP,INACT,0.9599999785423279	CHEMBL2381196,FP,INACT,0.8999999761581421	CHEMBL3799245,FP,INACT,1.0	CHEMBL46403,TN,INACT,0.0	CHEMBL62118,TP,ACT,0.9700000286102295	CHEMBL3736000,TP,ACT,1.0	CHEMBL195654,TP,ACT,1.0	CHEMBL1622067,TN,INACT,0.009999999776482582	CHEMBL3421888,TP,ACT,0.9800000190734863	CHEMBL386630,FN,ACT,0.0	CHEMBL2426626,TP,ACT,1.0	CHEMBL1465370,TN,INACT,0.009999999776482582	CHEMBL1505467,TN,INACT,0.5	CHEMBL1372855,TN,INACT,0.009999999776482582	CHEMBL237241,TN,INACT,0.0	CHEMBL83110,TP,ACT,1.0	CHEMBL3132993,FP,INACT,0.9900000095367432	CHEMBL236134,TN,INACT,0.0	CHEMBL50454,TP,ACT,0.9900000095367432	CHEMBL376264,TP,ACT,1.0	CHEMBL1469796,TN,INACT,0.0	CHEMBL222515,TP,ACT,0.8799999952316284	CHEMBL2311179,FN,ACT,0.33000001311302185	CHEMBL470785,TP,ACT,0.9599999785423279	CHEMBL418971,TN,INACT,0.0	CHEMBL2023243,TP,ACT,1.0	CHEMBL1254174,TP,ACT,1.0	CHEMBL1094231,TP,ACT,1.0	CHEMBL1641710,FP,INACT,0.9200000166893005	CHEMBL1940555,TP,ACT,1.0	CHEMBL208996,TP,ACT,1.0	CHEMBL1326483,TN,INACT,0.3700000047683716	CHEMBL3138037,FP,INACT,0.9300000071525574	CHEMBL3736358,TP,ACT,0.9599999785423279	CHEMBL1390963,TN,INACT,0.0	CHEMBL564923,TP,ACT,0.9900000095367432	CHEMBL361245,TP,ACT,1.0	CHEMBL1485005,TN,INACT,0.0	CHEMBL1684351,TP,ACT,1.0	CHEMBL2348881,TN,INACT,0.0	CHEMBL2437301,TN,INACT,0.10000000149011612	CHEMBL118972,TN,INACT,0.5600000023841858	CHEMBL336353,TP,ACT,1.0	CHEMBL3093461,TP,ACT,1.0	CHEMBL3098275,TN,INACT,0.0	CHEMBL184228,FN,ACT,0.0	CHEMBL221686,TP,ACT,1.0	CHEMBL1095542,TP,ACT,0.9900000095367432	CHEMBL70503,TP,ACT,1.0	CHEMBL3706948,TP,ACT,1.0	CHEMBL2087291,TP,ACT,1.0	CHEMBL266673,TP,ACT,1.0	CHEMBL391943,TP,ACT,0.9900000095367432	CHEMBL336169,TP,ACT,1.0	CHEMBL243870,TP,ACT,1.0	CHEMBL362988,TP,ACT,1.0	CHEMBL2426153,TP,ACT,1.0	CHEMBL71405,TP,ACT,1.0	CHEMBL3706956,TP,ACT,1.0	CHEMBL1991885,TN,INACT,0.4399999976158142	CHEMBL1480971,TN,INACT,0.0	CHEMBL396997,TP,ACT,0.9800000190734863	CHEMBL444286,TP,ACT,1.0	CHEMBL3263232,FP,INACT,0.8899999856948853	CHEMBL1668079,TP,ACT,1.0	CHEMBL150924,TN,INACT,0.20000000298023224	CHEMBL2426635,TP,ACT,0.9200000166893005	CHEMBL2070867,FP,INACT,0.8100000023841858	CHEMBL1835807,FN,ACT,0.05999999865889549	CHEMBL1399039,TN,INACT,0.0	CHEMBL3706958,TP,ACT,0.9700000286102295	CHEMBL182610,TP,ACT,0.9900000095367432	CHEMBL1570005,TN,INACT,0.07999999821186066	CHEMBL1911659,TP,ACT,1.0	CHEMBL2316563,FP,INACT,0.9100000262260437	CHEMBL452456,TP,ACT,1.0	CHEMBL195524,TP,ACT,1.0	CHEMBL267231,TP,ACT,0.9700000286102295	CHEMBL1682429,TP,ACT,1.0	CHEMBL1545787,FP,INACT,0.9800000190734863	CHEMBL2426110,TP,ACT,1.0	CHEMBL3109612,TN,INACT,0.0	CHEMBL34015,TP,ACT,1.0	CHEMBL3315063,TP,ACT,1.0	CHEMBL1254419,TP,ACT,1.0	CHEMBL1784260,TN,INACT,0.019999999552965164	CHEMBL2147562,TP,ACT,1.0	CHEMBL1448272,TN,INACT,0.019999999552965164	CHEMBL2147554,TP,ACT,1.0	CHEMBL2426138,TP,ACT,1.0	CHEMBL3315060,TP,ACT,1.0	CHEMBL370039,TN,INACT,0.0	CHEMBL454408,TN,INACT,0.49000000953674316	CHEMBL1468124,FP,INACT,1.0	CHEMBL2070860,TN,INACT,0.0	CHEMBL141030,TN,INACT,0.0	CHEMBL219016,TP,ACT,1.0	CHEMBL2441819,TN,INACT,0.009999999776482582	CHEMBL247418,TP,ACT,0.9900000095367432	CHEMBL255570,TP,ACT,1.0	CHEMBL2070854,TN,INACT,0.27000001072883606	CHEMBL398106,TN,INACT,0.0	CHEMBL2348886,TN,INACT,0.12999999523162842	CHEMBL182647,TP,ACT,1.0	CHEMBL509182,TP,ACT,1.0	CHEMBL3800363,FP,INACT,0.9900000095367432	CHEMBL1491959,TN,INACT,0.28999999165534973	CHEMBL233390,TP,ACT,1.0	CHEMBL489597,TN,INACT,0.009999999776482582	CHEMBL389545,TP,ACT,0.9900000095367432	CHEMBL3736390,TP,ACT,1.0	CHEMBL499630,TP,ACT,1.0	CHEMBL2325060,FP,INACT,1.0	CHEMBL1911547,TP,ACT,1.0	CHEMBL415524,TP,ACT,0.9900000095367432	CHEMBL1608989,FP,INACT,0.9200000166893005	CHEMBL370624,TP,ACT,1.0	CHEMBL237823,TN,INACT,0.0	CHEMBL1956361,TN,INACT,0.05000000074505806	CHEMBL73933,TN,INACT,0.0	CHEMBL2348903,TN,INACT,0.0	CHEMBL2426630,TP,ACT,0.9599999785423279	CHEMBL87285,TN,INACT,0.23999999463558197	CHEMBL3315056,TP,ACT,1.0	CHEMBL2181925,TP,ACT,1.0	CHEMBL1580543,TN,INACT,0.0	CHEMBL1322274,TN,INACT,0.07000000029802322	CHEMBL1299357,FP,INACT,0.7900000214576721	CHEMBL2087287,TP,ACT,0.9599999785423279	CHEMBL1083784,TP,ACT,1.0	CHEMBL194301,TP,ACT,0.8799999952316284	CHEMBL237455,TN,INACT,0.0	CHEMBL1645395,FN,ACT,0.0	CHEMBL52,TN,INACT,0.3799999952316284	CHEMBL577945,TP,ACT,1.0	CHEMBL1672549,TP,ACT,0.9900000095367432	CHEMBL1940696,TP,ACT,1.0	CHEMBL556523,FN,ACT,0.4000000059604645	CHEMBL265125,TP,ACT,1.0	CHEMBL1911143,TP,ACT,0.9900000095367432	CHEMBL95644,TP,ACT,1.0	CHEMBL3358922,TP,ACT,1.0	CHEMBL1271259,FP,INACT,1.0	CHEMBL1200845,FN,ACT,0.75	CHEMBL1911662,TP,ACT,1.0	CHEMBL596544,TN,INACT,0.0	CHEMBL1254820,TP,ACT,1.0	CHEMBL2326697,TN,INACT,0.11999999731779099	CHEMBL2326410,FP,INACT,0.949999988079071	CHEMBL1330946,TN,INACT,0.0	CHEMBL224204,FN,ACT,0.009999999776482582	CHEMBL487611,TN,INACT,0.0	CHEMBL2023620,TP,ACT,1.0	CHEMBL2147556,TP,ACT,0.9900000095367432	CHEMBL191423,TP,ACT,1.0	CHEMBL427080,TN,INACT,0.0	CHEMBL3706961,TP,ACT,1.0	CHEMBL429592,TP,ACT,1.0	CHEMBL308900,TP,ACT,0.9900000095367432	CHEMBL400609,TP,ACT,1.0	CHEMBL1917246,TP,ACT,1.0	CHEMBL206772,TN,INACT,0.0	CHEMBL2070852,TN,INACT,0.0	CHEMBL3605930,TP,ACT,0.9900000095367432	CHEMBL1461683,FP,INACT,0.9900000095367432	CHEMBL3138365,FN,ACT,0.019999999552965164	CHEMBL3126944,TP,ACT,1.0	CHEMBL8055,TP,ACT,0.9900000095367432	CHEMBL575075,TN,INACT,0.0	CHEMBL1956370,TN,INACT,0.0	CHEMBL3622365,TN,INACT,0.14000000059604645	CHEMBL1645392,FN,ACT,0.0	CHEMBL503,TN,INACT,0.009999999776482582	CHEMBL1389163,TN,INACT,0.11999999731779099	CHEMBL1645402,TP,ACT,0.9900000095367432	CHEMBL3647441,TP,ACT,1.0	CHEMBL1098849,TP,ACT,1.0	CHEMBL487116,TP,ACT,1.0	CHEMBL1540767,TN,INACT,0.0	CHEMBL404496,TP,ACT,0.9900000095367432	CHEMBL397919,TP,ACT,1.0	CHEMBL2426125,TP,ACT,1.0	CHEMBL325172,TN,INACT,0.3400000035762787	CHEMBL142221,TN,INACT,0.10000000149011612	CHEMBL1331729,TN,INACT,0.0	CHEMBL219561,TP,ACT,0.9900000095367432	CHEMBL8340,TP,ACT,0.9900000095367432	CHEMBL1412226,TN,INACT,0.0	CHEMBL1585431,TN,INACT,0.0	CHEMBL3666808,TP,ACT,1.0	CHEMBL3233271,TP,ACT,1.0	CHEMBL266488,TP,ACT,0.9900000095367432	CHEMBL214915,TN,INACT,0.12999999523162842	CHEMBL2426657,TP,ACT,0.9900000095367432	CHEMBL63239,TP,ACT,1.0	CHEMBL1531512,TN,INACT,0.4399999976158142	CHEMBL3623110,FP,INACT,1.0	CHEMBL272923,TP,ACT,1.0	CHEMBL3578286,TP,ACT,1.0	CHEMBL218778,TP,ACT,1.0	CHEMBL2011539,TN,INACT,0.019999999552965164	CHEMBL1835834,TN,INACT,0.05999999865889549	CHEMBL1801003,TP,ACT,0.9200000166893005	CHEMBL2070875,TN,INACT,0.07000000029802322	CHEMBL271019,TP,ACT,0.9900000095367432	CHEMBL230247,TP,ACT,0.800000011920929	CHEMBL1389986,FP,INACT,0.9900000095367432	CHEMBL464453,TN,INACT,0.7400000095367432	CHEMBL506844,TP,ACT,0.9900000095367432	CHEMBL1684346,TP,ACT,1.0	CHEMBL1387610,TN,INACT,0.009999999776482582	CHEMBL237611,TN,INACT,0.0	CHEMBL1760023,TP,ACT,0.9900000095367432	CHEMBL1465490,TN,INACT,0.05000000074505806	CHEMBL2382120,TN,INACT,0.07000000029802322	CHEMBL394168,FN,ACT,0.7200000286102295	CHEMBL9352,TN,INACT,0.0	CHEMBL1393548,TN,INACT,0.019999999552965164	CHEMBL247235,TP,ACT,0.9800000190734863	CHEMBL8131,TP,ACT,0.9900000095367432	CHEMBL236496,TN,INACT,0.0	CHEMBL48358,TP,ACT,1.0	CHEMBL2441817,TN,INACT,0.029999999329447746	CHEMBL3358945,TP,ACT,1.0	CHEMBL1510817,TN,INACT,0.03999999910593033	CHEMBL561449,TN,INACT,0.0	CHEMBL197100,TP,ACT,1.0	CHEMBL401013,TP,ACT,1.0	CHEMBL403334,TP,ACT,1.0	CHEMBL553018,TP,ACT,0.9900000095367432	CHEMBL3358929,TP,ACT,0.9800000190734863	CHEMBL1424125,FP,INACT,0.9599999785423279	CHEMBL3647442,TP,ACT,1.0	CHEMBL3623106,TN,INACT,0.25	CHEMBL236543,TN,INACT,0.0	CHEMBL386806,TP,ACT,1.0	CHEMBL2070865,FP,INACT,0.9700000286102295	CHEMBL192346,TN,INACT,0.019999999552965164	CHEMBL286158,TP,ACT,0.9900000095367432	CHEMBL2426115,TP,ACT,1.0	CHEMBL1940695,TP,ACT,1.0	CHEMBL48745,TP,ACT,0.9900000095367432	CHEMBL1096467,TP,ACT,1.0	CHEMBL2087288,TP,ACT,1.0	CHEMBL583859,TP,ACT,1.0	

