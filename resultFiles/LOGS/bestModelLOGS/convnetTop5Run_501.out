CNNModel CHEMBL2966 adam 0.0005 30 32 0 0.8 False True
Number of active compounds :	134
Number of inactive compounds :	134
---------------------------------
Run id: CNNModel_CHEMBL2966_adam_0.0005_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2966_adam_0.0005_30_32_0.8_True/
---------------------------------
Training samples: 171
Validation samples: 54
--
Training Step: 1  | time: 0.805s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/171
[A[ATraining Step: 2  | total loss: [1m[32m0.62406[0m[0m | time: 1.432s
[2K
| Adam | epoch: 001 | loss: 0.62406 - acc: 0.3937 -- iter: 064/171
[A[ATraining Step: 3  | total loss: [1m[32m0.68040[0m[0m | time: 2.032s
[2K
| Adam | epoch: 001 | loss: 0.68040 - acc: 0.4807 -- iter: 096/171
[A[ATraining Step: 4  | total loss: [1m[32m0.69159[0m[0m | time: 2.649s
[2K
| Adam | epoch: 001 | loss: 0.69159 - acc: 0.4014 -- iter: 128/171
[A[ATraining Step: 5  | total loss: [1m[32m0.69219[0m[0m | time: 3.271s
[2K
| Adam | epoch: 001 | loss: 0.69219 - acc: 0.5562 -- iter: 160/171
[A[ATraining Step: 6  | total loss: [1m[32m0.69257[0m[0m | time: 4.532s
[2K
| Adam | epoch: 001 | loss: 0.69257 - acc: 0.5402 | val_loss: 0.69303 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 7  | total loss: [1m[32m0.69236[0m[0m | time: 0.236s
[2K
| Adam | epoch: 002 | loss: 0.69236 - acc: 0.5433 -- iter: 032/171
[A[ATraining Step: 8  | total loss: [1m[32m0.69173[0m[0m | time: 0.839s
[2K
| Adam | epoch: 002 | loss: 0.69173 - acc: 0.5445 -- iter: 064/171
[A[ATraining Step: 9  | total loss: [1m[32m0.69378[0m[0m | time: 1.453s
[2K
| Adam | epoch: 002 | loss: 0.69378 - acc: 0.4879 -- iter: 096/171
[A[ATraining Step: 10  | total loss: [1m[32m0.69380[0m[0m | time: 2.055s
[2K
| Adam | epoch: 002 | loss: 0.69380 - acc: 0.4783 -- iter: 128/171
[A[ATraining Step: 11  | total loss: [1m[32m0.69444[0m[0m | time: 2.682s
[2K
| Adam | epoch: 002 | loss: 0.69444 - acc: 0.4590 -- iter: 160/171
[A[ATraining Step: 12  | total loss: [1m[32m0.69237[0m[0m | time: 4.306s
[2K
| Adam | epoch: 002 | loss: 0.69237 - acc: 0.5196 | val_loss: 0.69287 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 13  | total loss: [1m[32m0.69251[0m[0m | time: 0.245s
[2K
| Adam | epoch: 003 | loss: 0.69251 - acc: 0.5112 -- iter: 032/171
[A[ATraining Step: 14  | total loss: [1m[32m0.69488[0m[0m | time: 0.481s
[2K
| Adam | epoch: 003 | loss: 0.69488 - acc: 0.4508 -- iter: 064/171
[A[ATraining Step: 15  | total loss: [1m[32m0.69576[0m[0m | time: 1.090s
[2K
| Adam | epoch: 003 | loss: 0.69576 - acc: 0.4167 -- iter: 096/171
[A[ATraining Step: 16  | total loss: [1m[32m0.69479[0m[0m | time: 1.712s
[2K
| Adam | epoch: 003 | loss: 0.69479 - acc: 0.4479 -- iter: 128/171
[A[ATraining Step: 17  | total loss: [1m[32m0.69412[0m[0m | time: 2.322s
[2K
| Adam | epoch: 003 | loss: 0.69412 - acc: 0.5004 -- iter: 160/171
[A[ATraining Step: 18  | total loss: [1m[32m0.69412[0m[0m | time: 3.937s
[2K
| Adam | epoch: 003 | loss: 0.69412 - acc: 0.4570 | val_loss: 0.69308 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 19  | total loss: [1m[32m0.69374[0m[0m | time: 0.609s
[2K
| Adam | epoch: 004 | loss: 0.69374 - acc: 0.4505 -- iter: 032/171
[A[ATraining Step: 20  | total loss: [1m[32m0.69357[0m[0m | time: 0.845s
[2K
| Adam | epoch: 004 | loss: 0.69357 - acc: 0.4363 -- iter: 064/171
[A[ATraining Step: 21  | total loss: [1m[32m0.69355[0m[0m | time: 1.108s
[2K
| Adam | epoch: 004 | loss: 0.69355 - acc: 0.4137 -- iter: 096/171
[A[ATraining Step: 22  | total loss: [1m[32m0.69354[0m[0m | time: 1.711s
[2K
| Adam | epoch: 004 | loss: 0.69354 - acc: 0.3987 -- iter: 128/171
[A[ATraining Step: 23  | total loss: [1m[32m0.69347[0m[0m | time: 2.354s
[2K
| Adam | epoch: 004 | loss: 0.69347 - acc: 0.3918 -- iter: 160/171
[A[ATraining Step: 24  | total loss: [1m[32m0.69340[0m[0m | time: 3.985s
[2K
| Adam | epoch: 004 | loss: 0.69340 - acc: 0.4135 | val_loss: 0.69302 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 25  | total loss: [1m[32m0.69328[0m[0m | time: 0.625s
[2K
| Adam | epoch: 005 | loss: 0.69328 - acc: 0.4371 -- iter: 032/171
[A[ATraining Step: 26  | total loss: [1m[32m0.69314[0m[0m | time: 1.235s
[2K
| Adam | epoch: 005 | loss: 0.69314 - acc: 0.4620 -- iter: 064/171
[A[ATraining Step: 27  | total loss: [1m[32m0.69336[0m[0m | time: 1.470s
[2K
| Adam | epoch: 005 | loss: 0.69336 - acc: 0.4396 -- iter: 096/171
[A[ATraining Step: 28  | total loss: [1m[32m0.69360[0m[0m | time: 1.704s
[2K
| Adam | epoch: 005 | loss: 0.69360 - acc: 0.3979 -- iter: 128/171
[A[ATraining Step: 29  | total loss: [1m[32m0.69357[0m[0m | time: 2.308s
[2K
| Adam | epoch: 005 | loss: 0.69357 - acc: 0.4117 -- iter: 160/171
[A[ATraining Step: 30  | total loss: [1m[32m0.69353[0m[0m | time: 3.933s
[2K
| Adam | epoch: 005 | loss: 0.69353 - acc: 0.4030 | val_loss: 0.69275 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 31  | total loss: [1m[32m0.69320[0m[0m | time: 0.609s
[2K
| Adam | epoch: 006 | loss: 0.69320 - acc: 0.4470 -- iter: 032/171
[A[ATraining Step: 32  | total loss: [1m[32m0.69296[0m[0m | time: 1.200s
[2K
| Adam | epoch: 006 | loss: 0.69296 - acc: 0.4730 -- iter: 064/171
[A[ATraining Step: 33  | total loss: [1m[32m0.69338[0m[0m | time: 1.795s
[2K
| Adam | epoch: 006 | loss: 0.69338 - acc: 0.4583 -- iter: 096/171
[A[ATraining Step: 34  | total loss: [1m[32m0.69334[0m[0m | time: 2.048s
[2K
| Adam | epoch: 006 | loss: 0.69334 - acc: 0.4606 -- iter: 128/171
[A[ATraining Step: 35  | total loss: [1m[32m0.69349[0m[0m | time: 2.279s
[2K
| Adam | epoch: 006 | loss: 0.69349 - acc: 0.4593 -- iter: 160/171
[A[ATraining Step: 36  | total loss: [1m[32m0.69361[0m[0m | time: 3.932s
[2K
| Adam | epoch: 006 | loss: 0.69361 - acc: 0.4583 | val_loss: 0.69229 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 37  | total loss: [1m[32m0.69360[0m[0m | time: 0.606s
[2K
| Adam | epoch: 007 | loss: 0.69360 - acc: 0.4542 -- iter: 032/171
[A[ATraining Step: 38  | total loss: [1m[32m0.69318[0m[0m | time: 1.203s
[2K
| Adam | epoch: 007 | loss: 0.69318 - acc: 0.4754 -- iter: 064/171
[A[ATraining Step: 39  | total loss: [1m[32m0.69276[0m[0m | time: 1.805s
[2K
| Adam | epoch: 007 | loss: 0.69276 - acc: 0.4921 -- iter: 096/171
[A[ATraining Step: 40  | total loss: [1m[32m0.69355[0m[0m | time: 2.400s
[2K
| Adam | epoch: 007 | loss: 0.69355 - acc: 0.4584 -- iter: 128/171
[A[ATraining Step: 41  | total loss: [1m[32m0.69372[0m[0m | time: 2.636s
[2K
| Adam | epoch: 007 | loss: 0.69372 - acc: 0.4373 -- iter: 160/171
[A[ATraining Step: 42  | total loss: [1m[32m0.69296[0m[0m | time: 3.870s
[2K
| Adam | epoch: 007 | loss: 0.69296 - acc: 0.4732 | val_loss: 0.69146 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 43  | total loss: [1m[32m0.69226[0m[0m | time: 0.618s
[2K
| Adam | epoch: 008 | loss: 0.69226 - acc: 0.5020 -- iter: 032/171
[A[ATraining Step: 44  | total loss: [1m[32m0.69176[0m[0m | time: 1.241s
[2K
| Adam | epoch: 008 | loss: 0.69176 - acc: 0.5233 -- iter: 064/171
[A[ATraining Step: 45  | total loss: [1m[32m0.69198[0m[0m | time: 1.848s
[2K
| Adam | epoch: 008 | loss: 0.69198 - acc: 0.5087 -- iter: 096/171
[A[ATraining Step: 46  | total loss: [1m[32m0.69072[0m[0m | time: 2.464s
[2K
| Adam | epoch: 008 | loss: 0.69072 - acc: 0.5229 -- iter: 128/171
[A[ATraining Step: 47  | total loss: [1m[32m0.69249[0m[0m | time: 3.069s
[2K
| Adam | epoch: 008 | loss: 0.69249 - acc: 0.4936 -- iter: 160/171
[A[ATraining Step: 48  | total loss: [1m[32m0.69275[0m[0m | time: 4.324s
[2K
| Adam | epoch: 008 | loss: 0.69275 - acc: 0.4845 | val_loss: 0.68818 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 49  | total loss: [1m[32m0.69148[0m[0m | time: 0.246s
[2K
| Adam | epoch: 009 | loss: 0.69148 - acc: 0.4942 -- iter: 032/171
[A[ATraining Step: 50  | total loss: [1m[32m0.69017[0m[0m | time: 0.846s
[2K
| Adam | epoch: 009 | loss: 0.69017 - acc: 0.5021 -- iter: 064/171
[A[ATraining Step: 51  | total loss: [1m[32m0.68822[0m[0m | time: 1.451s
[2K
| Adam | epoch: 009 | loss: 0.68822 - acc: 0.5209 -- iter: 096/171
[A[ATraining Step: 52  | total loss: [1m[32m0.68655[0m[0m | time: 2.055s
[2K
| Adam | epoch: 009 | loss: 0.68655 - acc: 0.5271 -- iter: 128/171
[A[ATraining Step: 53  | total loss: [1m[32m0.68716[0m[0m | time: 2.662s
[2K
| Adam | epoch: 009 | loss: 0.68716 - acc: 0.5185 -- iter: 160/171
[A[ATraining Step: 54  | total loss: [1m[32m0.68775[0m[0m | time: 4.265s
[2K
| Adam | epoch: 009 | loss: 0.68775 - acc: 0.5067 | val_loss: 0.67842 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 55  | total loss: [1m[32m0.68533[0m[0m | time: 0.248s
[2K
| Adam | epoch: 010 | loss: 0.68533 - acc: 0.5102 -- iter: 032/171
[A[ATraining Step: 56  | total loss: [1m[32m0.67274[0m[0m | time: 0.502s
[2K
| Adam | epoch: 010 | loss: 0.67274 - acc: 0.5535 -- iter: 064/171
[A[ATraining Step: 57  | total loss: [1m[32m0.65627[0m[0m | time: 1.114s
[2K
| Adam | epoch: 010 | loss: 0.65627 - acc: 0.5902 -- iter: 096/171
[A[ATraining Step: 58  | total loss: [1m[32m0.67662[0m[0m | time: 1.719s
[2K
| Adam | epoch: 010 | loss: 0.67662 - acc: 0.5566 -- iter: 128/171
[A[ATraining Step: 59  | total loss: [1m[32m0.68863[0m[0m | time: 2.324s
[2K
| Adam | epoch: 010 | loss: 0.68863 - acc: 0.5364 -- iter: 160/171
[A[ATraining Step: 60  | total loss: [1m[32m0.68565[0m[0m | time: 3.934s
[2K
| Adam | epoch: 010 | loss: 0.68565 - acc: 0.5357 | val_loss: 0.67124 - val_acc: 0.5000 -- iter: 171/171
--
Training Step: 61  | total loss: [1m[32m0.68432[0m[0m | time: 0.625s
[2K
| Adam | epoch: 011 | loss: 0.68432 - acc: 0.5311 -- iter: 032/171
[A[ATraining Step: 62  | total loss: [1m[32m0.68046[0m[0m | time: 0.856s
[2K
| Adam | epoch: 011 | loss: 0.68046 - acc: 0.5351 -- iter: 064/171
[A[ATraining Step: 63  | total loss: [1m[32m0.67442[0m[0m | time: 1.088s
[2K
| Adam | epoch: 011 | loss: 0.67442 - acc: 0.5595 -- iter: 096/171
[A[ATraining Step: 64  | total loss: [1m[32m0.66923[0m[0m | time: 1.691s
[2K
| Adam | epoch: 011 | loss: 0.66923 - acc: 0.5804 -- iter: 128/171
[A[ATraining Step: 65  | total loss: [1m[32m0.66907[0m[0m | time: 2.315s
[2K
| Adam | epoch: 011 | loss: 0.66907 - acc: 0.5590 -- iter: 160/171
[A[ATraining Step: 66  | total loss: [1m[32m0.67051[0m[0m | time: 3.953s
[2K
| Adam | epoch: 011 | loss: 0.67051 - acc: 0.5442 | val_loss: 0.66321 - val_acc: 0.6111 -- iter: 171/171
--
Training Step: 67  | total loss: [1m[32m0.66900[0m[0m | time: 0.622s
[2K
| Adam | epoch: 012 | loss: 0.66900 - acc: 0.5389 -- iter: 032/171
[A[ATraining Step: 68  | total loss: [1m[32m0.66930[0m[0m | time: 1.221s
[2K
| Adam | epoch: 012 | loss: 0.66930 - acc: 0.5417 -- iter: 064/171
[A[ATraining Step: 69  | total loss: [1m[32m0.66732[0m[0m | time: 1.478s
[2K
| Adam | epoch: 012 | loss: 0.66732 - acc: 0.5441 -- iter: 096/171
[A[ATraining Step: 70  | total loss: [1m[32m0.66425[0m[0m | time: 1.707s
[2K
| Adam | epoch: 012 | loss: 0.66425 - acc: 0.5862 -- iter: 128/171
[A[ATraining Step: 71  | total loss: [1m[32m0.65940[0m[0m | time: 2.317s
[2K
| Adam | epoch: 012 | loss: 0.65940 - acc: 0.6230 -- iter: 160/171
[A[ATraining Step: 72  | total loss: [1m[32m0.65110[0m[0m | time: 3.935s
[2K
| Adam | epoch: 012 | loss: 0.65110 - acc: 0.6373 | val_loss: 0.68629 - val_acc: 0.5185 -- iter: 171/171
--
Training Step: 73  | total loss: [1m[32m0.65139[0m[0m | time: 0.614s
[2K
| Adam | epoch: 013 | loss: 0.65139 - acc: 0.6290 -- iter: 032/171
[A[ATraining Step: 74  | total loss: [1m[32m0.65500[0m[0m | time: 1.253s
[2K
| Adam | epoch: 013 | loss: 0.65500 - acc: 0.6114 -- iter: 064/171
[A[ATraining Step: 75  | total loss: [1m[32m0.65603[0m[0m | time: 1.859s
[2K
| Adam | epoch: 013 | loss: 0.65603 - acc: 0.6095 -- iter: 096/171
[A[ATraining Step: 76  | total loss: [1m[32m0.65565[0m[0m | time: 2.095s
[2K
| Adam | epoch: 013 | loss: 0.65565 - acc: 0.6078 -- iter: 128/171
[A[ATraining Step: 77  | total loss: [1m[32m0.64841[0m[0m | time: 2.339s
[2K
| Adam | epoch: 013 | loss: 0.64841 - acc: 0.6204 -- iter: 160/171
[A[ATraining Step: 78  | total loss: [1m[32m0.64130[0m[0m | time: 3.944s
[2K
| Adam | epoch: 013 | loss: 0.64130 - acc: 0.6411 | val_loss: 0.62829 - val_acc: 0.6667 -- iter: 171/171
--
Training Step: 79  | total loss: [1m[32m0.63624[0m[0m | time: 0.610s
[2K
| Adam | epoch: 014 | loss: 0.63624 - acc: 0.6621 -- iter: 032/171
[A[ATraining Step: 80  | total loss: [1m[32m0.63462[0m[0m | time: 1.225s
[2K
| Adam | epoch: 014 | loss: 0.63462 - acc: 0.6711 -- iter: 064/171
[A[ATraining Step: 81  | total loss: [1m[32m0.62852[0m[0m | time: 1.835s
[2K
| Adam | epoch: 014 | loss: 0.62852 - acc: 0.6728 -- iter: 096/171
[A[ATraining Step: 82  | total loss: [1m[32m0.62481[0m[0m | time: 2.429s
[2K
| Adam | epoch: 014 | loss: 0.62481 - acc: 0.6774 -- iter: 128/171
[A[ATraining Step: 83  | total loss: [1m[32m0.61388[0m[0m | time: 2.674s
[2K
| Adam | epoch: 014 | loss: 0.61388 - acc: 0.6940 -- iter: 160/171
[A[ATraining Step: 84  | total loss: [1m[32m0.60187[0m[0m | time: 3.912s
[2K
| Adam | epoch: 014 | loss: 0.60187 - acc: 0.6973 | val_loss: 0.55498 - val_acc: 0.7407 -- iter: 171/171
--
Training Step: 85  | total loss: [1m[32m0.58788[0m[0m | time: 0.619s
[2K
| Adam | epoch: 015 | loss: 0.58788 - acc: 0.7094 -- iter: 032/171
[A[ATraining Step: 86  | total loss: [1m[32m0.57775[0m[0m | time: 1.229s
[2K
| Adam | epoch: 015 | loss: 0.57775 - acc: 0.7166 -- iter: 064/171
[A[ATraining Step: 87  | total loss: [1m[32m0.57759[0m[0m | time: 1.843s
[2K
| Adam | epoch: 015 | loss: 0.57759 - acc: 0.7074 -- iter: 096/171
[A[ATraining Step: 88  | total loss: [1m[32m0.55567[0m[0m | time: 2.450s
[2K
| Adam | epoch: 015 | loss: 0.55567 - acc: 0.7242 -- iter: 128/171
[A[ATraining Step: 89  | total loss: [1m[32m0.54055[0m[0m | time: 3.060s
[2K
| Adam | epoch: 015 | loss: 0.54055 - acc: 0.7361 -- iter: 160/171
[A[ATraining Step: 90  | total loss: [1m[32m0.52576[0m[0m | time: 4.297s
[2K
| Adam | epoch: 015 | loss: 0.52576 - acc: 0.7469 | val_loss: 0.92064 - val_acc: 0.6481 -- iter: 171/171
--
Training Step: 91  | total loss: [1m[32m0.48627[0m[0m | time: 0.266s
[2K
| Adam | epoch: 016 | loss: 0.48627 - acc: 0.7722 -- iter: 032/171
[A[ATraining Step: 92  | total loss: [1m[32m0.45147[0m[0m | time: 0.871s
[2K
| Adam | epoch: 016 | loss: 0.45147 - acc: 0.7859 -- iter: 064/171
[A[ATraining Step: 93  | total loss: [1m[32m0.48907[0m[0m | time: 1.500s
[2K
| Adam | epoch: 016 | loss: 0.48907 - acc: 0.7823 -- iter: 096/171
[A[ATraining Step: 94  | total loss: [1m[32m0.50253[0m[0m | time: 2.107s
[2K
| Adam | epoch: 016 | loss: 0.50253 - acc: 0.7760 -- iter: 128/171
[A[ATraining Step: 95  | total loss: [1m[32m0.49775[0m[0m | time: 2.721s
[2K
| Adam | epoch: 016 | loss: 0.49775 - acc: 0.7827 -- iter: 160/171
[A[ATraining Step: 96  | total loss: [1m[32m0.54568[0m[0m | time: 4.336s
[2K
| Adam | epoch: 016 | loss: 0.54568 - acc: 0.7638 | val_loss: 0.52838 - val_acc: 0.7593 -- iter: 171/171
--
Training Step: 97  | total loss: [1m[32m0.53932[0m[0m | time: 0.239s
[2K
| Adam | epoch: 017 | loss: 0.53932 - acc: 0.7656 -- iter: 032/171
[A[ATraining Step: 98  | total loss: [1m[32m0.49758[0m[0m | time: 0.474s
[2K
| Adam | epoch: 017 | loss: 0.49758 - acc: 0.7890 -- iter: 064/171
[A[ATraining Step: 99  | total loss: [1m[32m0.46367[0m[0m | time: 1.083s
[2K
| Adam | epoch: 017 | loss: 0.46367 - acc: 0.8010 -- iter: 096/171
[A[ATraining Step: 100  | total loss: [1m[32m0.43673[0m[0m | time: 1.681s
[2K
| Adam | epoch: 017 | loss: 0.43673 - acc: 0.8147 -- iter: 128/171
[A[ATraining Step: 101  | total loss: [1m[32m0.41696[0m[0m | time: 2.299s
[2K
| Adam | epoch: 017 | loss: 0.41696 - acc: 0.8238 -- iter: 160/171
[A[ATraining Step: 102  | total loss: [1m[32m0.40409[0m[0m | time: 3.897s
[2K
| Adam | epoch: 017 | loss: 0.40409 - acc: 0.8352 | val_loss: 0.50057 - val_acc: 0.7963 -- iter: 171/171
--
Training Step: 103  | total loss: [1m[32m0.40109[0m[0m | time: 0.626s
[2K
| Adam | epoch: 018 | loss: 0.40109 - acc: 0.8361 -- iter: 032/171
[A[ATraining Step: 104  | total loss: [1m[32m0.38623[0m[0m | time: 0.862s
[2K
| Adam | epoch: 018 | loss: 0.38623 - acc: 0.8462 -- iter: 064/171
[A[ATraining Step: 105  | total loss: [1m[32m0.37183[0m[0m | time: 1.108s
[2K
| Adam | epoch: 018 | loss: 0.37183 - acc: 0.8525 -- iter: 096/171
[A[ATraining Step: 106  | total loss: [1m[32m0.35483[0m[0m | time: 1.709s
[2K
| Adam | epoch: 018 | loss: 0.35483 - acc: 0.8581 -- iter: 128/171
[A[ATraining Step: 107  | total loss: [1m[32m0.34318[0m[0m | time: 2.322s
[2K
| Adam | epoch: 018 | loss: 0.34318 - acc: 0.8661 -- iter: 160/171
[A[ATraining Step: 108  | total loss: [1m[32m0.33147[0m[0m | time: 3.927s
[2K
| Adam | epoch: 018 | loss: 0.33147 - acc: 0.8763 | val_loss: 0.49951 - val_acc: 0.7963 -- iter: 171/171
--
Training Step: 109  | total loss: [1m[32m0.32713[0m[0m | time: 0.616s
[2K
| Adam | epoch: 019 | loss: 0.32713 - acc: 0.8825 -- iter: 032/171
[A[ATraining Step: 110  | total loss: [1m[32m0.30471[0m[0m | time: 1.241s
[2K
| Adam | epoch: 019 | loss: 0.30471 - acc: 0.8942 -- iter: 064/171
[A[ATraining Step: 111  | total loss: [1m[32m0.30824[0m[0m | time: 1.472s
[2K
| Adam | epoch: 019 | loss: 0.30824 - acc: 0.8892 -- iter: 096/171
[A[ATraining Step: 112  | total loss: [1m[32m0.28503[0m[0m | time: 1.719s
[2K
| Adam | epoch: 019 | loss: 0.28503 - acc: 0.9003 -- iter: 128/171
[A[ATraining Step: 113  | total loss: [1m[32m0.26449[0m[0m | time: 2.329s
[2K
| Adam | epoch: 019 | loss: 0.26449 - acc: 0.9102 -- iter: 160/171
[A[ATraining Step: 114  | total loss: [1m[32m0.29454[0m[0m | time: 3.932s
[2K
| Adam | epoch: 019 | loss: 0.29454 - acc: 0.8973 | val_loss: 0.53837 - val_acc: 0.7593 -- iter: 171/171
--
Training Step: 115  | total loss: [1m[32m0.28985[0m[0m | time: 0.613s
[2K
| Adam | epoch: 020 | loss: 0.28985 - acc: 0.8982 -- iter: 032/171
[A[ATraining Step: 116  | total loss: [1m[32m0.29067[0m[0m | time: 1.221s
[2K
| Adam | epoch: 020 | loss: 0.29067 - acc: 0.8959 -- iter: 064/171
[A[ATraining Step: 117  | total loss: [1m[32m0.33479[0m[0m | time: 1.850s
[2K
| Adam | epoch: 020 | loss: 0.33479 - acc: 0.8782 -- iter: 096/171
[A[ATraining Step: 118  | total loss: [1m[32m0.33287[0m[0m | time: 2.094s
[2K
| Adam | epoch: 020 | loss: 0.33287 - acc: 0.8747 -- iter: 128/171
[A[ATraining Step: 119  | total loss: [1m[32m0.31295[0m[0m | time: 2.333s
[2K
| Adam | epoch: 020 | loss: 0.31295 - acc: 0.8782 -- iter: 160/171
[A[ATraining Step: 120  | total loss: [1m[32m0.29578[0m[0m | time: 3.973s
[2K
| Adam | epoch: 020 | loss: 0.29578 - acc: 0.8813 | val_loss: 0.45565 - val_acc: 0.7593 -- iter: 171/171
--
Training Step: 121  | total loss: [1m[32m0.28284[0m[0m | time: 0.620s
[2K
| Adam | epoch: 021 | loss: 0.28284 - acc: 0.8838 -- iter: 032/171
[A[ATraining Step: 122  | total loss: [1m[32m0.31642[0m[0m | time: 1.220s
[2K
| Adam | epoch: 021 | loss: 0.31642 - acc: 0.8766 -- iter: 064/171
[A[ATraining Step: 123  | total loss: [1m[32m0.31128[0m[0m | time: 1.816s
[2K
| Adam | epoch: 021 | loss: 0.31128 - acc: 0.8796 -- iter: 096/171
[A[ATraining Step: 124  | total loss: [1m[32m0.29885[0m[0m | time: 2.421s
[2K
| Adam | epoch: 021 | loss: 0.29885 - acc: 0.8854 -- iter: 128/171
[A[ATraining Step: 125  | total loss: [1m[32m0.28145[0m[0m | time: 2.652s
[2K
| Adam | epoch: 021 | loss: 0.28145 - acc: 0.8906 -- iter: 160/171
[A[ATraining Step: 126  | total loss: [1m[32m0.26101[0m[0m | time: 3.887s
[2K
| Adam | epoch: 021 | loss: 0.26101 - acc: 0.9015 | val_loss: 0.32453 - val_acc: 0.9074 -- iter: 171/171
--
Training Step: 127  | total loss: [1m[32m0.24262[0m[0m | time: 0.611s
[2K
| Adam | epoch: 022 | loss: 0.24262 - acc: 0.9114 -- iter: 032/171
[A[ATraining Step: 128  | total loss: [1m[32m0.22778[0m[0m | time: 1.237s
[2K
| Adam | epoch: 022 | loss: 0.22778 - acc: 0.9202 -- iter: 064/171
[A[ATraining Step: 129  | total loss: [1m[32m0.22314[0m[0m | time: 1.836s
[2K
| Adam | epoch: 022 | loss: 0.22314 - acc: 0.9220 -- iter: 096/171
[A[ATraining Step: 130  | total loss: [1m[32m0.22095[0m[0m | time: 2.434s
[2K
| Adam | epoch: 022 | loss: 0.22095 - acc: 0.9204 -- iter: 128/171
[A[ATraining Step: 131  | total loss: [1m[32m0.20705[0m[0m | time: 3.044s
[2K
| Adam | epoch: 022 | loss: 0.20705 - acc: 0.9252 -- iter: 160/171
[A[ATraining Step: 132  | total loss: [1m[32m0.19975[0m[0m | time: 4.302s
[2K
| Adam | epoch: 022 | loss: 0.19975 - acc: 0.9296 | val_loss: 0.35468 - val_acc: 0.9074 -- iter: 171/171
--
Training Step: 133  | total loss: [1m[32m0.19055[0m[0m | time: 0.247s
[2K
| Adam | epoch: 023 | loss: 0.19055 - acc: 0.9366 -- iter: 032/171
[A[ATraining Step: 134  | total loss: [1m[32m0.17884[0m[0m | time: 0.855s
[2K
| Adam | epoch: 023 | loss: 0.17884 - acc: 0.9430 -- iter: 064/171
[A[ATraining Step: 135  | total loss: [1m[32m0.19098[0m[0m | time: 1.457s
[2K
| Adam | epoch: 023 | loss: 0.19098 - acc: 0.9393 -- iter: 096/171
[A[ATraining Step: 136  | total loss: [1m[32m0.20097[0m[0m | time: 2.067s
[2K
| Adam | epoch: 023 | loss: 0.20097 - acc: 0.9391 -- iter: 128/171
[A[ATraining Step: 137  | total loss: [1m[32m0.18417[0m[0m | time: 2.665s
[2K
| Adam | epoch: 023 | loss: 0.18417 - acc: 0.9452 -- iter: 160/171
[A[ATraining Step: 138  | total loss: [1m[32m0.18166[0m[0m | time: 4.295s
[2K
| Adam | epoch: 023 | loss: 0.18166 - acc: 0.9444 | val_loss: 0.52583 - val_acc: 0.8148 -- iter: 171/171
--
Training Step: 139  | total loss: [1m[32m0.18168[0m[0m | time: 0.263s
[2K
| Adam | epoch: 024 | loss: 0.18168 - acc: 0.9406 -- iter: 032/171
[A[ATraining Step: 140  | total loss: [1m[32m0.17000[0m[0m | time: 0.505s
[2K
| Adam | epoch: 024 | loss: 0.17000 - acc: 0.9466 -- iter: 064/171
[A[ATraining Step: 141  | total loss: [1m[32m0.15574[0m[0m | time: 1.126s
[2K
| Adam | epoch: 024 | loss: 0.15574 - acc: 0.9519 -- iter: 096/171
[A[ATraining Step: 142  | total loss: [1m[32m0.15272[0m[0m | time: 1.727s
[2K
| Adam | epoch: 024 | loss: 0.15272 - acc: 0.9536 -- iter: 128/171
[A[ATraining Step: 143  | total loss: [1m[32m0.16667[0m[0m | time: 2.342s
[2K
| Adam | epoch: 024 | loss: 0.16667 - acc: 0.9520 -- iter: 160/171
[A[ATraining Step: 144  | total loss: [1m[32m0.16836[0m[0m | time: 3.955s
[2K
| Adam | epoch: 024 | loss: 0.16836 - acc: 0.9505 | val_loss: 0.38598 - val_acc: 0.8519 -- iter: 171/171
--
Training Step: 145  | total loss: [1m[32m0.16033[0m[0m | time: 0.617s
[2K
| Adam | epoch: 025 | loss: 0.16033 - acc: 0.9523 -- iter: 032/171
[A[ATraining Step: 146  | total loss: [1m[32m0.15740[0m[0m | time: 0.851s
[2K
| Adam | epoch: 025 | loss: 0.15740 - acc: 0.9509 -- iter: 064/171
[A[ATraining Step: 147  | total loss: [1m[32m0.14601[0m[0m | time: 1.078s
[2K
| Adam | epoch: 025 | loss: 0.14601 - acc: 0.9558 -- iter: 096/171
[A[ATraining Step: 148  | total loss: [1m[32m0.13476[0m[0m | time: 1.679s
[2K
| Adam | epoch: 025 | loss: 0.13476 - acc: 0.9602 -- iter: 128/171
[A[ATraining Step: 149  | total loss: [1m[32m0.13331[0m[0m | time: 2.321s
[2K
| Adam | epoch: 025 | loss: 0.13331 - acc: 0.9548 -- iter: 160/171
[A[ATraining Step: 150  | total loss: [1m[32m0.12572[0m[0m | time: 3.949s
[2K
| Adam | epoch: 025 | loss: 0.12572 - acc: 0.9593 | val_loss: 0.29132 - val_acc: 0.9074 -- iter: 171/171
--
Training Step: 151  | total loss: [1m[32m0.12136[0m[0m | time: 0.610s
[2K
| Adam | epoch: 026 | loss: 0.12136 - acc: 0.9571 -- iter: 032/171
[A[ATraining Step: 152  | total loss: [1m[32m0.11811[0m[0m | time: 1.214s
[2K
| Adam | epoch: 026 | loss: 0.11811 - acc: 0.9583 -- iter: 064/171
[A[ATraining Step: 153  | total loss: [1m[32m0.11468[0m[0m | time: 1.462s
[2K
| Adam | epoch: 026 | loss: 0.11468 - acc: 0.9593 -- iter: 096/171
[A[ATraining Step: 154  | total loss: [1m[32m0.11412[0m[0m | time: 1.717s
[2K
| Adam | epoch: 026 | loss: 0.11412 - acc: 0.9634 -- iter: 128/171
[A[ATraining Step: 155  | total loss: [1m[32m0.11285[0m[0m | time: 2.318s
[2K
| Adam | epoch: 026 | loss: 0.11285 - acc: 0.9671 -- iter: 160/171
[A[ATraining Step: 156  | total loss: [1m[32m0.11711[0m[0m | time: 3.936s
[2K
| Adam | epoch: 026 | loss: 0.11711 - acc: 0.9641 | val_loss: 0.40506 - val_acc: 0.8519 -- iter: 171/171
--
Training Step: 157  | total loss: [1m[32m0.15354[0m[0m | time: 0.610s
[2K
| Adam | epoch: 027 | loss: 0.15354 - acc: 0.9615 -- iter: 032/171
[A[ATraining Step: 158  | total loss: [1m[32m0.15329[0m[0m | time: 1.212s
[2K
| Adam | epoch: 027 | loss: 0.15329 - acc: 0.9591 -- iter: 064/171
[A[ATraining Step: 159  | total loss: [1m[32m0.16563[0m[0m | time: 1.821s
[2K
| Adam | epoch: 027 | loss: 0.16563 - acc: 0.9507 -- iter: 096/171
[A[ATraining Step: 160  | total loss: [1m[32m0.18166[0m[0m | time: 2.096s
[2K
| Adam | epoch: 027 | loss: 0.18166 - acc: 0.9462 -- iter: 128/171
[A[ATraining Step: 161  | total loss: [1m[32m0.16649[0m[0m | time: 2.348s
[2K
| Adam | epoch: 027 | loss: 0.16649 - acc: 0.9516 -- iter: 160/171
[A[ATraining Step: 162  | total loss: [1m[32m0.15883[0m[0m | time: 3.953s
[2K
| Adam | epoch: 027 | loss: 0.15883 - acc: 0.9473 | val_loss: 0.38763 - val_acc: 0.8333 -- iter: 171/171
--
Training Step: 163  | total loss: [1m[32m0.15946[0m[0m | time: 0.609s
[2K
| Adam | epoch: 028 | loss: 0.15946 - acc: 0.9432 -- iter: 032/171
[A[ATraining Step: 164  | total loss: [1m[32m0.16862[0m[0m | time: 1.215s
[2K
| Adam | epoch: 028 | loss: 0.16862 - acc: 0.9427 -- iter: 064/171
[A[ATraining Step: 165  | total loss: [1m[32m0.15825[0m[0m | time: 1.813s
[2K
| Adam | epoch: 028 | loss: 0.15825 - acc: 0.9453 -- iter: 096/171
[A[ATraining Step: 166  | total loss: [1m[32m0.15587[0m[0m | time: 2.415s
[2K
| Adam | epoch: 028 | loss: 0.15587 - acc: 0.9476 -- iter: 128/171
[A[ATraining Step: 167  | total loss: [1m[32m0.14550[0m[0m | time: 2.648s
[2K
| Adam | epoch: 028 | loss: 0.14550 - acc: 0.9529 -- iter: 160/171
[A[ATraining Step: 168  | total loss: [1m[32m0.13410[0m[0m | time: 3.894s
[2K
| Adam | epoch: 028 | loss: 0.13410 - acc: 0.9576 | val_loss: 0.33280 - val_acc: 0.8704 -- iter: 171/171
--
Training Step: 169  | total loss: [1m[32m0.12360[0m[0m | time: 0.610s
[2K
| Adam | epoch: 029 | loss: 0.12360 - acc: 0.9618 -- iter: 032/171
[A[ATraining Step: 170  | total loss: [1m[32m0.13510[0m[0m | time: 1.210s
[2K
| Adam | epoch: 029 | loss: 0.13510 - acc: 0.9563 -- iter: 064/171
[A[ATraining Step: 171  | total loss: [1m[32m0.14010[0m[0m | time: 1.823s
[2K
| Adam | epoch: 029 | loss: 0.14010 - acc: 0.9575 -- iter: 096/171
[A[ATraining Step: 172  | total loss: [1m[32m0.14051[0m[0m | time: 2.430s
[2K
| Adam | epoch: 029 | loss: 0.14051 - acc: 0.9586 -- iter: 128/171
[A[ATraining Step: 173  | total loss: [1m[32m0.14651[0m[0m | time: 3.046s
[2K
| Adam | epoch: 029 | loss: 0.14651 - acc: 0.9534 -- iter: 160/171
[A[ATraining Step: 174  | total loss: [1m[32m0.14120[0m[0m | time: 4.285s
[2K
| Adam | epoch: 029 | loss: 0.14120 - acc: 0.9549 | val_loss: 0.30690 - val_acc: 0.9074 -- iter: 171/171
--
Training Step: 175  | total loss: [1m[32m0.13019[0m[0m | time: 0.240s
[2K
| Adam | epoch: 030 | loss: 0.13019 - acc: 0.9594 -- iter: 032/171
[A[ATraining Step: 176  | total loss: [1m[32m0.12119[0m[0m | time: 0.833s
[2K
| Adam | epoch: 030 | loss: 0.12119 - acc: 0.9635 -- iter: 064/171
[A[ATraining Step: 177  | total loss: [1m[32m0.11690[0m[0m | time: 1.452s
[2K
| Adam | epoch: 030 | loss: 0.11690 - acc: 0.9671 -- iter: 096/171
[A[ATraining Step: 178  | total loss: [1m[32m0.11636[0m[0m | time: 2.077s
[2K
| Adam | epoch: 030 | loss: 0.11636 - acc: 0.9673 -- iter: 128/171
[A[ATraining Step: 179  | total loss: [1m[32m0.11289[0m[0m | time: 2.672s
[2K
| Adam | epoch: 030 | loss: 0.11289 - acc: 0.9643 -- iter: 160/171
[A[ATraining Step: 180  | total loss: [1m[32m0.11053[0m[0m | time: 4.291s
[2K
| Adam | epoch: 030 | loss: 0.11053 - acc: 0.9648 | val_loss: 0.41153 - val_acc: 0.8704 -- iter: 171/171
--
Validation AUC:0.9519890260631001
Validation AUPRC:0.9541751367012354
Test AUC:0.8772413793103448
Test AUPRC:0.8130236212840068
BestTestF1Score	0.82	0.67	0.83	0.81	0.84	21	5	24	4	0.02
BestTestMCCScore	0.82	0.67	0.83	0.81	0.84	21	5	24	4	0.02
BestTestAccuracyScore	0.77	0.64	0.81	0.89	0.68	17	2	27	8	0.18
BestValidationF1Score	0.91	0.82	0.91	0.87	0.96	26	4	23	1	0.02
BestValidationMCC	0.91	0.82	0.91	0.87	0.96	26	4	23	1	0.02
BestValidationAccuracy	0.91	0.82	0.91	0.92	0.89	24	2	25	3	0.18
TestPredictions (Threshold:0.02)
CHEMBL1651380,TP,ACT,0.800000011920929	CHEMBL364227,TN,INACT,0.0	CHEMBL1090074,TN,INACT,0.0	CHEMBL290770,TP,ACT,0.28999999165534973	CHEMBL612157,FN,ACT,0.009999999776482582	CHEMBL2407455,TN,INACT,0.0	CHEMBL1651370,TN,INACT,0.009999999776482582	CHEMBL3143085,FN,ACT,0.009999999776482582	CHEMBL38218,TP,ACT,0.9900000095367432	CHEMBL127469,TP,ACT,0.8500000238418579	CHEMBL1093343,TN,INACT,0.0	CHEMBL42063,TP,ACT,0.9900000095367432	CHEMBL156990,TP,ACT,0.9800000190734863	CHEMBL279149,TP,ACT,0.9599999785423279	CHEMBL9234,TN,INACT,0.0	CHEMBL1651367,FN,ACT,0.0	CHEMBL605448,TN,INACT,0.019999999552965164	CHEMBL64503,TP,ACT,0.09000000357627869	CHEMBL290381,TP,ACT,0.9800000190734863	CHEMBL112683,TN,INACT,0.0	CHEMBL3099732,TN,INACT,0.0	CHEMBL1651365,TN,INACT,0.0	CHEMBL36699,FN,ACT,0.019999999552965164	CHEMBL2304163,FP,INACT,0.029999999329447746	CHEMBL1089942,TN,INACT,0.0	CHEMBL2407461,TN,INACT,0.0	CHEMBL132135,TP,ACT,0.9800000190734863	CHEMBL18172,TN,INACT,0.019999999552965164	CHEMBL17822,FP,INACT,1.0	CHEMBL1651363,TN,INACT,0.009999999776482582	CHEMBL3633021,FP,INACT,0.12999999523162842	CHEMBL1784539,TN,INACT,0.009999999776482582	CHEMBL18433,TP,ACT,0.8600000143051147	CHEMBL188485,FP,INACT,0.03999999910593033	CHEMBL267463,TN,INACT,0.019999999552965164	CHEMBL289027,TP,ACT,0.05999999865889549	CHEMBL18838,TP,ACT,1.0	CHEMBL440769,FP,INACT,0.6800000071525574	CHEMBL593178,TN,INACT,0.009999999776482582	CHEMBL37531,TP,ACT,0.9900000095367432	CHEMBL1580,TP,ACT,0.05000000074505806	CHEMBL43261,TP,ACT,0.1899999976158142	CHEMBL3633016,TN,INACT,0.0	CHEMBL3633002,TN,INACT,0.009999999776482582	CHEMBL1090075,TN,INACT,0.009999999776482582	CHEMBL9700,TN,INACT,0.0	CHEMBL17870,TP,ACT,0.6600000262260437	CHEMBL295003,TP,ACT,0.9900000095367432	CHEMBL2407592,TN,INACT,0.0	CHEMBL558539,TN,INACT,0.0	CHEMBL604965,TN,INACT,0.009999999776482582	CHEMBL2112699,TP,ACT,0.1899999976158142	CHEMBL280595,TP,ACT,0.05999999865889549	CHEMBL418074,TP,ACT,0.8899999856948853	

