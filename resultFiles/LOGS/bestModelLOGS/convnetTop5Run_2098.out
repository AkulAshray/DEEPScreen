ImageNetInceptionV2 CHEMBL2336 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	196
Number of inactive compounds :	196
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2336_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2336_adam_0.0001_15_0.8/
---------------------------------
Training samples: 249
Validation samples: 78
--
Training Step: 1  | time: 65.415s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/249
[A[ATraining Step: 2  | total loss: [1m[32m0.64650[0m[0m | time: 77.581s
[2K
| Adam | epoch: 001 | loss: 0.64650 - acc: 0.5062 -- iter: 064/249
[A[ATraining Step: 3  | total loss: [1m[32m0.61661[0m[0m | time: 85.508s
[2K
| Adam | epoch: 001 | loss: 0.61661 - acc: 0.6034 -- iter: 096/249
[A[ATraining Step: 4  | total loss: [1m[32m0.52157[0m[0m | time: 93.542s
[2K
| Adam | epoch: 001 | loss: 0.52157 - acc: 0.7837 -- iter: 128/249
[A[ATraining Step: 5  | total loss: [1m[32m0.54078[0m[0m | time: 101.414s
[2K
| Adam | epoch: 001 | loss: 0.54078 - acc: 0.7387 -- iter: 160/249
[A[ATraining Step: 6  | total loss: [1m[32m0.51984[0m[0m | time: 110.527s
[2K
| Adam | epoch: 001 | loss: 0.51984 - acc: 0.7259 -- iter: 192/249
[A[ATraining Step: 7  | total loss: [1m[32m0.48610[0m[0m | time: 125.539s
[2K
| Adam | epoch: 001 | loss: 0.48610 - acc: 0.7966 -- iter: 224/249
[A[ATraining Step: 8  | total loss: [1m[32m0.53408[0m[0m | time: 151.710s
[2K
| Adam | epoch: 001 | loss: 0.53408 - acc: 0.7352 | val_loss: 2.91784 - val_acc: 0.4487 -- iter: 249/249
--
Training Step: 9  | total loss: [1m[32m0.47563[0m[0m | time: 13.036s
[2K
| Adam | epoch: 002 | loss: 0.47563 - acc: 0.7695 -- iter: 032/249
[A[ATraining Step: 10  | total loss: [1m[32m0.40162[0m[0m | time: 24.909s
[2K
| Adam | epoch: 002 | loss: 0.40162 - acc: 0.8248 -- iter: 064/249
[A[ATraining Step: 11  | total loss: [1m[32m0.48389[0m[0m | time: 32.859s
[2K
| Adam | epoch: 002 | loss: 0.48389 - acc: 0.7597 -- iter: 096/249
[A[ATraining Step: 12  | total loss: [1m[32m0.45093[0m[0m | time: 40.905s
[2K
| Adam | epoch: 002 | loss: 0.45093 - acc: 0.7975 -- iter: 128/249
[A[ATraining Step: 13  | total loss: [1m[32m0.41380[0m[0m | time: 48.788s
[2K
| Adam | epoch: 002 | loss: 0.41380 - acc: 0.8441 -- iter: 160/249
[A[ATraining Step: 14  | total loss: [1m[32m0.37473[0m[0m | time: 59.105s
[2K
| Adam | epoch: 002 | loss: 0.37473 - acc: 0.8695 -- iter: 192/249
[A[ATraining Step: 15  | total loss: [1m[32m0.38433[0m[0m | time: 71.912s
[2K
| Adam | epoch: 002 | loss: 0.38433 - acc: 0.8839 -- iter: 224/249
[A[ATraining Step: 16  | total loss: [1m[32m0.32565[0m[0m | time: 90.821s
[2K
| Adam | epoch: 002 | loss: 0.32565 - acc: 0.9157 | val_loss: 3.80108 - val_acc: 0.4487 -- iter: 249/249
--
Training Step: 17  | total loss: [1m[32m0.30010[0m[0m | time: 6.432s
[2K
| Adam | epoch: 003 | loss: 0.30010 - acc: 0.9123 -- iter: 032/249
[A[ATraining Step: 18  | total loss: [1m[32m0.26955[0m[0m | time: 13.703s
[2K
| Adam | epoch: 003 | loss: 0.26955 - acc: 0.9288 -- iter: 064/249
[A[ATraining Step: 19  | total loss: [1m[32m0.22772[0m[0m | time: 26.078s
[2K
| Adam | epoch: 003 | loss: 0.22772 - acc: 0.9525 -- iter: 096/249
[A[ATraining Step: 20  | total loss: [1m[32m0.21034[0m[0m | time: 39.085s
[2K
| Adam | epoch: 003 | loss: 0.21034 - acc: 0.9678 -- iter: 128/249
[A[ATraining Step: 21  | total loss: [1m[32m0.19785[0m[0m | time: 51.696s
[2K
| Adam | epoch: 003 | loss: 0.19785 - acc: 0.9681 -- iter: 160/249
[A[ATraining Step: 22  | total loss: [1m[32m0.25606[0m[0m | time: 63.981s
[2K
| Adam | epoch: 003 | loss: 0.25606 - acc: 0.9589 -- iter: 192/249
[A[ATraining Step: 23  | total loss: [1m[32m0.20119[0m[0m | time: 72.002s
[2K
| Adam | epoch: 003 | loss: 0.20119 - acc: 0.9708 -- iter: 224/249
[A[ATraining Step: 24  | total loss: [1m[32m0.16422[0m[0m | time: 83.662s
[2K
| Adam | epoch: 003 | loss: 0.16422 - acc: 0.9790 | val_loss: 3.67758 - val_acc: 0.4487 -- iter: 249/249
--
Training Step: 25  | total loss: [1m[32m0.14396[0m[0m | time: 11.238s
[2K
| Adam | epoch: 004 | loss: 0.14396 - acc: 0.9848 -- iter: 032/249
[A[ATraining Step: 26  | total loss: [1m[32m0.11858[0m[0m | time: 17.904s
[2K
| Adam | epoch: 004 | loss: 0.11858 - acc: 0.9888 -- iter: 064/249
[A[ATraining Step: 27  | total loss: [1m[32m0.10211[0m[0m | time: 24.393s
[2K
| Adam | epoch: 004 | loss: 0.10211 - acc: 0.9917 -- iter: 096/249
[A[ATraining Step: 28  | total loss: [1m[32m0.08803[0m[0m | time: 32.411s
[2K
| Adam | epoch: 004 | loss: 0.08803 - acc: 0.9938 -- iter: 128/249
[A[ATraining Step: 29  | total loss: [1m[32m0.07761[0m[0m | time: 44.172s
[2K
| Adam | epoch: 004 | loss: 0.07761 - acc: 0.9953 -- iter: 160/249
[A[ATraining Step: 30  | total loss: [1m[32m0.06762[0m[0m | time: 56.523s
[2K
| Adam | epoch: 004 | loss: 0.06762 - acc: 0.9964 -- iter: 192/249
[A[ATraining Step: 31  | total loss: [1m[32m0.19518[0m[0m | time: 74.498s
[2K
| Adam | epoch: 004 | loss: 0.19518 - acc: 0.9684 -- iter: 224/249
[A[ATraining Step: 32  | total loss: [1m[32m0.15583[0m[0m | time: 304.695s
[2K
| Adam | epoch: 004 | loss: 0.15583 - acc: 0.9755 | val_loss: 2.57676 - val_acc: 0.4487 -- iter: 249/249
--
Training Step: 33  | total loss: [1m[32m0.12518[0m[0m | time: 12.617s
[2K
| Adam | epoch: 005 | loss: 0.12518 - acc: 0.9809 -- iter: 032/249
[A[ATraining Step: 34  | total loss: [1m[32m0.10286[0m[0m | time: 24.562s
[2K
| Adam | epoch: 005 | loss: 0.10286 - acc: 0.9850 -- iter: 064/249
[A[ATraining Step: 35  | total loss: [1m[32m0.08556[0m[0m | time: 34.728s
[2K
| Adam | epoch: 005 | loss: 0.08556 - acc: 0.9881 -- iter: 096/249
[A[ATraining Step: 36  | total loss: [1m[32m0.07778[0m[0m | time: 42.052s
[2K
| Adam | epoch: 005 | loss: 0.07778 - acc: 0.9824 -- iter: 128/249
[A[ATraining Step: 37  | total loss: [1m[32m0.06520[0m[0m | time: 50.070s
[2K
| Adam | epoch: 005 | loss: 0.06520 - acc: 0.9859 -- iter: 160/249
[A[ATraining Step: 38  | total loss: [1m[32m0.05466[0m[0m | time: 58.025s
[2K
| Adam | epoch: 005 | loss: 0.05466 - acc: 0.9887 -- iter: 192/249
[A[ATraining Step: 39  | total loss: [1m[32m0.05598[0m[0m | time: 66.108s
[2K
| Adam | epoch: 005 | loss: 0.05598 - acc: 0.9848 -- iter: 224/249
[A[ATraining Step: 40  | total loss: [1m[32m0.07310[0m[0m | time: 79.523s
[2K
| Adam | epoch: 005 | loss: 0.07310 - acc: 0.9818 | val_loss: 1.61896 - val_acc: 0.4487 -- iter: 249/249
--
Training Step: 41  | total loss: [1m[32m0.06572[0m[0m | time: 9.626s
[2K
| Adam | epoch: 006 | loss: 0.06572 - acc: 0.9794 -- iter: 032/249
[A[ATraining Step: 42  | total loss: [1m[32m0.05579[0m[0m | time: 17.686s
[2K
| Adam | epoch: 006 | loss: 0.05579 - acc: 0.9831 -- iter: 064/249
[A[ATraining Step: 43  | total loss: [1m[32m0.04689[0m[0m | time: 28.124s
[2K
| Adam | epoch: 006 | loss: 0.04689 - acc: 0.9861 -- iter: 096/249
[A[ATraining Step: 44  | total loss: [1m[32m0.04132[0m[0m | time: 55.129s
[2K
| Adam | epoch: 006 | loss: 0.04132 - acc: 0.9885 -- iter: 128/249
[A[ATraining Step: 45  | total loss: [1m[32m0.03538[0m[0m | time: 460.547s
[2K
| Adam | epoch: 006 | loss: 0.03538 - acc: 0.9905 -- iter: 160/249
[A[ATraining Step: 46  | total loss: [1m[32m0.03045[0m[0m | time: 705.847s
[2K
| Adam | epoch: 006 | loss: 0.03045 - acc: 0.9921 -- iter: 192/249
[A[ATraining Step: 47  | total loss: [1m[32m0.02980[0m[0m | time: 845.841s
[2K
| Adam | epoch: 006 | loss: 0.02980 - acc: 0.9882 -- iter: 224/249
[A[ATraining Step: 48  | total loss: [1m[32m0.02588[0m[0m | time: 969.838s
[2K
| Adam | epoch: 006 | loss: 0.02588 - acc: 0.9901 | val_loss: 0.93718 - val_acc: 0.5000 -- iter: 249/249
--
Training Step: 49  | total loss: [1m[32m0.04277[0m[0m | time: 140.526s
[2K
| Adam | epoch: 007 | loss: 0.04277 - acc: 0.9868 -- iter: 032/249
[A[ATraining Step: 50  | total loss: [1m[32m0.03818[0m[0m | time: 236.731s
[2K
| Adam | epoch: 007 | loss: 0.03818 - acc: 0.9888 -- iter: 064/249
[A[ATraining Step: 51  | total loss: [1m[32m0.05909[0m[0m | time: 256.859s
[2K
| Adam | epoch: 007 | loss: 0.05909 - acc: 0.9857 -- iter: 096/249
[A[ATraining Step: 52  | total loss: [1m[32m0.05224[0m[0m | time: 411.850s
[2K
| Adam | epoch: 007 | loss: 0.05224 - acc: 0.9879 -- iter: 128/249
[A[ATraining Step: 53  | total loss: [1m[32m0.08607[0m[0m | time: 430.579s
[2K
| Adam | epoch: 007 | loss: 0.08607 - acc: 0.9851 -- iter: 160/249
[A[ATraining Step: 54  | total loss: [1m[32m0.07616[0m[0m | time: 453.606s
[2K
| Adam | epoch: 007 | loss: 0.07616 - acc: 0.9872 -- iter: 192/249
[A[ATraining Step: 55  | total loss: [1m[32m0.06754[0m[0m | time: 612.159s
[2K
| Adam | epoch: 007 | loss: 0.06754 - acc: 0.9891 -- iter: 224/249
[A[ATraining Step: 56  | total loss: [1m[32m0.06616[0m[0m | time: 637.407s
[2K
| Adam | epoch: 007 | loss: 0.06616 - acc: 0.9862 | val_loss: 0.51205 - val_acc: 0.7564 -- iter: 249/249
--
Training Step: 57  | total loss: [1m[32m0.05889[0m[0m | time: 45.893s
[2K
| Adam | epoch: 008 | loss: 0.05889 - acc: 0.9881 -- iter: 032/249
[A[ATraining Step: 58  | total loss: [1m[32m0.05199[0m[0m | time: 141.785s
[2K
| Adam | epoch: 008 | loss: 0.05199 - acc: 0.9897 -- iter: 064/249
[A[ATraining Step: 59  | total loss: [1m[32m0.04587[0m[0m | time: 242.770s
[2K
| Adam | epoch: 008 | loss: 0.04587 - acc: 0.9911 -- iter: 096/249
[A[ATraining Step: 60  | total loss: [1m[32m0.04040[0m[0m | time: 280.120s
[2K
| Adam | epoch: 008 | loss: 0.04040 - acc: 0.9923 -- iter: 128/249
[A[ATraining Step: 61  | total loss: [1m[32m0.03697[0m[0m | time: 298.604s
[2K
| Adam | epoch: 008 | loss: 0.03697 - acc: 0.9933 -- iter: 160/249
[A[ATraining Step: 62  | total loss: [1m[32m0.03281[0m[0m | time: 313.173s
[2K
| Adam | epoch: 008 | loss: 0.03281 - acc: 0.9942 -- iter: 192/249
[A[ATraining Step: 63  | total loss: [1m[32m0.02965[0m[0m | time: 326.086s
[2K
| Adam | epoch: 008 | loss: 0.02965 - acc: 0.9949 -- iter: 224/249
[A[ATraining Step: 64  | total loss: [1m[32m0.02692[0m[0m | time: 347.022s
[2K
| Adam | epoch: 008 | loss: 0.02692 - acc: 0.9955 | val_loss: 2.47402 - val_acc: 0.4487 -- iter: 249/249
--
Training Step: 65  | total loss: [1m[32m0.02485[0m[0m | time: 18.227s
[2K
| Adam | epoch: 009 | loss: 0.02485 - acc: 0.9961 -- iter: 032/249
[A[ATraining Step: 66  | total loss: [1m[32m0.02294[0m[0m | time: 35.981s
[2K
| Adam | epoch: 009 | loss: 0.02294 - acc: 0.9966 -- iter: 064/249
[A[ATraining Step: 67  | total loss: [1m[32m0.07311[0m[0m | time: 49.021s
[2K
| Adam | epoch: 009 | loss: 0.07311 - acc: 0.9895 -- iter: 096/249
[A[ATraining Step: 68  | total loss: [1m[32m0.06518[0m[0m | time: 63.228s
[2K
| Adam | epoch: 009 | loss: 0.06518 - acc: 0.9907 -- iter: 128/249
[A[ATraining Step: 69  | total loss: [1m[32m0.05797[0m[0m | time: 80.681s
[2K
| Adam | epoch: 009 | loss: 0.05797 - acc: 0.9918 -- iter: 160/249
[A[ATraining Step: 70  | total loss: [1m[32m0.05259[0m[0m | time: 98.081s
[2K
| Adam | epoch: 009 | loss: 0.05259 - acc: 0.9928 -- iter: 192/249
[A[ATraining Step: 71  | total loss: [1m[32m0.04964[0m[0m | time: 112.993s
[2K
| Adam | epoch: 009 | loss: 0.04964 - acc: 0.9936 -- iter: 224/249
[A[ATraining Step: 72  | total loss: [1m[32m0.04550[0m[0m | time: 133.288s
[2K
| Adam | epoch: 009 | loss: 0.04550 - acc: 0.9943 | val_loss: 0.50853 - val_acc: 0.7821 -- iter: 249/249
--
Training Step: 73  | total loss: [1m[32m0.04152[0m[0m | time: 17.315s
[2K
| Adam | epoch: 010 | loss: 0.04152 - acc: 0.9949 -- iter: 032/249
[A[ATraining Step: 74  | total loss: [1m[32m0.05887[0m[0m | time: 34.172s
[2K
| Adam | epoch: 010 | loss: 0.05887 - acc: 0.9886 -- iter: 064/249
[A[ATraining Step: 75  | total loss: [1m[32m0.05613[0m[0m | time: 47.404s
[2K
| Adam | epoch: 010 | loss: 0.05613 - acc: 0.9899 -- iter: 096/249
[A[ATraining Step: 76  | total loss: [1m[32m0.11063[0m[0m | time: 62.849s
[2K
| Adam | epoch: 010 | loss: 0.11063 - acc: 0.9809 -- iter: 128/249
[A[ATraining Step: 77  | total loss: [1m[32m0.09942[0m[0m | time: 80.365s
[2K
| Adam | epoch: 010 | loss: 0.09942 - acc: 0.9829 -- iter: 160/249
[A[ATraining Step: 78  | total loss: [1m[32m0.09441[0m[0m | time: 97.777s
[2K
| Adam | epoch: 010 | loss: 0.09441 - acc: 0.9814 -- iter: 192/249
[A[ATraining Step: 79  | total loss: [1m[32m0.09376[0m[0m | time: 114.683s
[2K
| Adam | epoch: 010 | loss: 0.09376 - acc: 0.9801 -- iter: 224/249
[A[ATraining Step: 80  | total loss: [1m[32m0.08594[0m[0m | time: 132.777s
[2K
| Adam | epoch: 010 | loss: 0.08594 - acc: 0.9822 | val_loss: 2.28551 - val_acc: 0.5513 -- iter: 249/249
--
Training Step: 81  | total loss: [1m[32m0.08061[0m[0m | time: 14.957s
[2K
| Adam | epoch: 011 | loss: 0.08061 - acc: 0.9840 -- iter: 032/249
[A[ATraining Step: 82  | total loss: [1m[32m0.07363[0m[0m | time: 33.386s
[2K
| Adam | epoch: 011 | loss: 0.07363 - acc: 0.9856 -- iter: 064/249
[A[ATraining Step: 83  | total loss: [1m[32m0.06698[0m[0m | time: 51.521s
[2K
| Adam | epoch: 011 | loss: 0.06698 - acc: 0.9870 -- iter: 096/249
[A[ATraining Step: 84  | total loss: [1m[32m0.06087[0m[0m | time: 65.758s
[2K
| Adam | epoch: 011 | loss: 0.06087 - acc: 0.9883 -- iter: 128/249
[A[ATraining Step: 85  | total loss: [1m[32m0.26110[0m[0m | time: 78.751s
[2K
| Adam | epoch: 011 | loss: 0.26110 - acc: 0.9520 -- iter: 160/249
[A[ATraining Step: 86  | total loss: [1m[32m0.23593[0m[0m | time: 96.359s
[2K
| Adam | epoch: 011 | loss: 0.23593 - acc: 0.9568 -- iter: 192/249
[A[ATraining Step: 87  | total loss: [1m[32m0.21372[0m[0m | time: 114.526s
[2K
| Adam | epoch: 011 | loss: 0.21372 - acc: 0.9611 -- iter: 224/249
[A[ATraining Step: 88  | total loss: [1m[32m0.19409[0m[0m | time: 140.683s
[2K
| Adam | epoch: 011 | loss: 0.19409 - acc: 0.9650 | val_loss: 2.45326 - val_acc: 0.5513 -- iter: 249/249
--
Training Step: 89  | total loss: [1m[32m0.17728[0m[0m | time: 11.527s
[2K
| Adam | epoch: 012 | loss: 0.17728 - acc: 0.9685 -- iter: 032/249
[A[ATraining Step: 90  | total loss: [1m[32m0.16909[0m[0m | time: 25.600s
[2K
| Adam | epoch: 012 | loss: 0.16909 - acc: 0.9676 -- iter: 064/249
[A[ATraining Step: 91  | total loss: [1m[32m0.15505[0m[0m | time: 43.077s
[2K
| Adam | epoch: 012 | loss: 0.15505 - acc: 0.9709 -- iter: 096/249
[A[ATraining Step: 92  | total loss: [1m[32m0.14654[0m[0m | time: 60.999s
[2K
| Adam | epoch: 012 | loss: 0.14654 - acc: 0.9707 -- iter: 128/249
[A[ATraining Step: 93  | total loss: [1m[32m0.14587[0m[0m | time: 77.320s
[2K
| Adam | epoch: 012 | loss: 0.14587 - acc: 0.9674 -- iter: 160/249
[A[ATraining Step: 94  | total loss: [1m[32m0.18586[0m[0m | time: 90.457s
[2K
| Adam | epoch: 012 | loss: 0.18586 - acc: 0.9550 -- iter: 192/249
[A[ATraining Step: 95  | total loss: [1m[32m0.17003[0m[0m | time: 106.263s
[2K
| Adam | epoch: 012 | loss: 0.17003 - acc: 0.9595 -- iter: 224/249
[A[ATraining Step: 96  | total loss: [1m[32m0.15634[0m[0m | time: 132.055s
[2K
| Adam | epoch: 012 | loss: 0.15634 - acc: 0.9635 | val_loss: 3.12321 - val_acc: 0.4487 -- iter: 249/249
--
Training Step: 97  | total loss: [1m[32m0.15220[0m[0m | time: 12.712s
[2K
| Adam | epoch: 013 | loss: 0.15220 - acc: 0.9641 -- iter: 032/249
[A[ATraining Step: 98  | total loss: [1m[32m0.14411[0m[0m | time: 25.374s
[2K
| Adam | epoch: 013 | loss: 0.14411 - acc: 0.9677 -- iter: 064/249
[A[ATraining Step: 99  | total loss: [1m[32m0.13311[0m[0m | time: 40.749s
[2K
| Adam | epoch: 013 | loss: 0.13311 - acc: 0.9709 -- iter: 096/249
[A[ATraining Step: 100  | total loss: [1m[32m0.12180[0m[0m | time: 58.642s
[2K
| Adam | epoch: 013 | loss: 0.12180 - acc: 0.9738 -- iter: 128/249
[A[ATraining Step: 101  | total loss: [1m[32m0.11386[0m[0m | time: 75.681s
[2K
| Adam | epoch: 013 | loss: 0.11386 - acc: 0.9764 -- iter: 160/249
[A[ATraining Step: 102  | total loss: [1m[32m0.11064[0m[0m | time: 90.849s
[2K
| Adam | epoch: 013 | loss: 0.11064 - acc: 0.9788 -- iter: 192/249
[A[ATraining Step: 103  | total loss: [1m[32m0.10024[0m[0m | time: 103.914s
[2K
| Adam | epoch: 013 | loss: 0.10024 - acc: 0.9809 -- iter: 224/249
[A[ATraining Step: 104  | total loss: [1m[32m0.09124[0m[0m | time: 125.896s
[2K
| Adam | epoch: 013 | loss: 0.09124 - acc: 0.9828 | val_loss: 0.66928 - val_acc: 0.7179 -- iter: 249/249
--
Training Step: 105  | total loss: [1m[32m0.08359[0m[0m | time: 13.274s
[2K
| Adam | epoch: 014 | loss: 0.08359 - acc: 0.9845 -- iter: 032/249
[A[ATraining Step: 106  | total loss: [1m[32m0.07660[0m[0m | time: 26.767s
[2K
| Adam | epoch: 014 | loss: 0.07660 - acc: 0.9861 -- iter: 064/249
[A[ATraining Step: 107  | total loss: [1m[32m0.07095[0m[0m | time: 36.777s
[2K
| Adam | epoch: 014 | loss: 0.07095 - acc: 0.9875 -- iter: 096/249
[A[ATraining Step: 108  | total loss: [1m[32m0.07499[0m[0m | time: 47.304s
[2K
| Adam | epoch: 014 | loss: 0.07499 - acc: 0.9847 -- iter: 128/249
[A[ATraining Step: 109  | total loss: [1m[32m0.07274[0m[0m | time: 59.796s
[2K
| Adam | epoch: 014 | loss: 0.07274 - acc: 0.9863 -- iter: 160/249
[A[ATraining Step: 110  | total loss: [1m[32m0.06710[0m[0m | time: 73.047s
[2K
| Adam | epoch: 014 | loss: 0.06710 - acc: 0.9876 -- iter: 192/249
[A[ATraining Step: 111  | total loss: [1m[32m0.06074[0m[0m | time: 85.988s
[2K
| Adam | epoch: 014 | loss: 0.06074 - acc: 0.9889 -- iter: 224/249
[A[ATraining Step: 112  | total loss: [1m[32m0.06772[0m[0m | time: 104.461s
[2K
| Adam | epoch: 014 | loss: 0.06772 - acc: 0.9869 | val_loss: 4.31318 - val_acc: 0.5513 -- iter: 249/249
--
Training Step: 113  | total loss: [1m[32m0.06198[0m[0m | time: 12.549s
[2K
| Adam | epoch: 015 | loss: 0.06198 - acc: 0.9882 -- iter: 032/249
[A[ATraining Step: 114  | total loss: [1m[32m0.05648[0m[0m | time: 24.608s
[2K
| Adam | epoch: 015 | loss: 0.05648 - acc: 0.9893 -- iter: 064/249
[A[ATraining Step: 115  | total loss: [1m[32m0.05173[0m[0m | time: 36.868s
[2K
| Adam | epoch: 015 | loss: 0.05173 - acc: 0.9904 -- iter: 096/249
[A[ATraining Step: 116  | total loss: [1m[32m0.04698[0m[0m | time: 47.999s
[2K
| Adam | epoch: 015 | loss: 0.04698 - acc: 0.9914 -- iter: 128/249
[A[ATraining Step: 117  | total loss: [1m[32m0.04275[0m[0m | time: 58.615s
[2K
| Adam | epoch: 015 | loss: 0.04275 - acc: 0.9922 -- iter: 160/249
[A[ATraining Step: 118  | total loss: [1m[32m0.03888[0m[0m | time: 71.238s
[2K
| Adam | epoch: 015 | loss: 0.03888 - acc: 0.9930 -- iter: 192/249
[A[ATraining Step: 119  | total loss: [1m[32m0.03541[0m[0m | time: 84.500s
[2K
| Adam | epoch: 015 | loss: 0.03541 - acc: 0.9937 -- iter: 224/249
[A[ATraining Step: 120  | total loss: [1m[32m0.06253[0m[0m | time: 103.038s
[2K
| Adam | epoch: 015 | loss: 0.06253 - acc: 0.9912 | val_loss: 1.29416 - val_acc: 0.7179 -- iter: 249/249
--
Validation AUC:0.9395348837209303
Validation AUPRC:0.9547480173516574
Test AUC:0.8537146614069692
Test AUPRC:0.8716849858816523
BestTestF1Score	0.84	0.67	0.83	0.81	0.87	34	8	31	5	1.0
BestTestMCCScore	0.84	0.67	0.83	0.81	0.87	34	8	31	5	1.0
BestTestAccuracyScore	0.84	0.67	0.83	0.81	0.87	34	8	31	5	1.0
BestValidationF1Score	0.87	0.69	0.85	0.83	0.91	39	8	27	4	1.0
BestValidationMCC	0.87	0.69	0.85	0.83	0.91	39	8	27	4	1.0
BestValidationAccuracy	0.87	0.69	0.85	0.83	0.91	39	8	27	4	1.0
TestPredictions (Threshold:1.0)
CHEMBL419069,FP,INACT,1.0	CHEMBL2059870,FP,INACT,1.0	CHEMBL272108,TP,ACT,1.0	CHEMBL3086701,TN,INACT,0.8199999928474426	CHEMBL2392237,TN,INACT,0.05999999865889549	CHEMBL333899,TP,ACT,1.0	CHEMBL524820,FP,INACT,1.0	CHEMBL552136,TN,INACT,0.029999999329447746	CHEMBL370156,TP,ACT,1.0	CHEMBL525921,TN,INACT,0.6700000166893005	CHEMBL199853,TP,ACT,1.0	CHEMBL2392388,TN,INACT,0.14000000059604645	CHEMBL3086702,TN,INACT,0.9700000286102295	CHEMBL2392375,TN,INACT,0.25999999046325684	CHEMBL2392240,TN,INACT,0.029999999329447746	CHEMBL2088585,TP,ACT,1.0	CHEMBL22818,TP,ACT,1.0	CHEMBL2152961,TN,INACT,0.9900000095367432	CHEMBL468125,FP,INACT,1.0	CHEMBL2164716,TN,INACT,0.9900000095367432	CHEMBL403737,TP,ACT,1.0	CHEMBL226471,TN,INACT,0.9800000190734863	CHEMBL561136,TN,INACT,0.8999999761581421	CHEMBL3086700,TN,INACT,0.9700000286102295	CHEMBL291427,TP,ACT,1.0	CHEMBL2392239,TN,INACT,0.30000001192092896	CHEMBL123469,TP,ACT,1.0	CHEMBL563948,TN,INACT,0.12999999523162842	CHEMBL364572,TP,ACT,1.0	CHEMBL104749,TP,ACT,1.0	CHEMBL101779,TN,INACT,0.9900000095367432	CHEMBL488646,FP,INACT,1.0	CHEMBL121512,FN,ACT,0.05999999865889549	CHEMBL606245,FP,INACT,1.0	CHEMBL456760,TN,INACT,0.6800000071525574	CHEMBL562198,TN,INACT,0.7200000286102295	CHEMBL3609567,TN,INACT,0.44999998807907104	CHEMBL411291,TP,ACT,1.0	CHEMBL199937,TP,ACT,1.0	CHEMBL1922210,TN,INACT,0.18000000715255737	CHEMBL482919,TN,INACT,0.8500000238418579	CHEMBL343481,FP,INACT,1.0	CHEMBL333923,TP,ACT,1.0	CHEMBL142751,TN,INACT,0.8500000238418579	CHEMBL485460,TN,INACT,0.9900000095367432	CHEMBL485878,TN,INACT,0.8799999952316284	CHEMBL2392238,TN,INACT,0.009999999776482582	CHEMBL432839,TP,ACT,1.0	CHEMBL119385,TP,ACT,1.0	CHEMBL560393,TN,INACT,0.019999999552965164	CHEMBL115509,FN,ACT,0.9800000190734863	CHEMBL331920,TP,ACT,1.0	CHEMBL497454,TN,INACT,0.9900000095367432	CHEMBL141294,TP,ACT,1.0	CHEMBL3669125,FN,ACT,0.019999999552965164	CHEMBL120067,FN,ACT,0.0	CHEMBL199993,TP,ACT,1.0	CHEMBL120160,TP,ACT,1.0	CHEMBL118917,TP,ACT,1.0	CHEMBL2088583,TP,ACT,1.0	CHEMBL498705,TN,INACT,0.7900000214576721	CHEMBL200040,TP,ACT,1.0	CHEMBL2088577,TP,ACT,1.0	CHEMBL192889,TP,ACT,1.0	CHEMBL1077396,TN,INACT,0.8100000023841858	CHEMBL437030,TP,ACT,1.0	CHEMBL284015,TP,ACT,1.0	CHEMBL1767275,TN,INACT,0.23999999463558197	CHEMBL22618,TP,ACT,1.0	CHEMBL272535,TP,ACT,1.0	CHEMBL525530,FP,INACT,1.0	CHEMBL115769,TP,ACT,1.0	CHEMBL456113,TN,INACT,0.800000011920929	CHEMBL334184,TP,ACT,1.0	CHEMBL118651,TP,ACT,1.0	CHEMBL380596,TP,ACT,1.0	CHEMBL371756,TP,ACT,1.0	CHEMBL219804,FN,ACT,0.9300000071525574	

