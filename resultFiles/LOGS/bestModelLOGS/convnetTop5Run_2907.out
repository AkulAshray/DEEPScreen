CNNModel CHEMBL1913 adam 0.0005 30 32 0 0.8 False True
Number of active compounds :	866
Number of inactive compounds :	866
---------------------------------
Run id: CNNModel_CHEMBL1913_adam_0.0005_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1913_adam_0.0005_30_32_0.8_True/
---------------------------------
Training samples: 1094
Validation samples: 343
--
Training Step: 1  | time: 2.244s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1094
[A[ATraining Step: 2  | total loss: [1m[32m0.62388[0m[0m | time: 3.726s
[2K
| Adam | epoch: 001 | loss: 0.62388 - acc: 0.3937 -- iter: 0064/1094
[A[ATraining Step: 3  | total loss: [1m[32m0.67921[0m[0m | time: 5.464s
[2K
| Adam | epoch: 001 | loss: 0.67921 - acc: 0.5574 -- iter: 0096/1094
[A[ATraining Step: 4  | total loss: [1m[32m0.68603[0m[0m | time: 6.766s
[2K
| Adam | epoch: 001 | loss: 0.68603 - acc: 0.5847 -- iter: 0128/1094
[A[ATraining Step: 5  | total loss: [1m[32m0.70602[0m[0m | time: 8.075s
[2K
| Adam | epoch: 001 | loss: 0.70602 - acc: 0.4179 -- iter: 0160/1094
[A[ATraining Step: 6  | total loss: [1m[32m0.69777[0m[0m | time: 9.317s
[2K
| Adam | epoch: 001 | loss: 0.69777 - acc: 0.4707 -- iter: 0192/1094
[A[ATraining Step: 7  | total loss: [1m[32m0.69797[0m[0m | time: 10.720s
[2K
| Adam | epoch: 001 | loss: 0.69797 - acc: 0.4320 -- iter: 0224/1094
[A[ATraining Step: 8  | total loss: [1m[32m0.69382[0m[0m | time: 11.975s
[2K
| Adam | epoch: 001 | loss: 0.69382 - acc: 0.5230 -- iter: 0256/1094
[A[ATraining Step: 9  | total loss: [1m[32m0.69507[0m[0m | time: 13.329s
[2K
| Adam | epoch: 001 | loss: 0.69507 - acc: 0.4446 -- iter: 0288/1094
[A[ATraining Step: 10  | total loss: [1m[32m0.69417[0m[0m | time: 14.903s
[2K
| Adam | epoch: 001 | loss: 0.69417 - acc: 0.4567 -- iter: 0320/1094
[A[ATraining Step: 11  | total loss: [1m[32m0.69387[0m[0m | time: 19.308s
[2K
| Adam | epoch: 001 | loss: 0.69387 - acc: 0.3884 -- iter: 0352/1094
[A[ATraining Step: 12  | total loss: [1m[32m0.69349[0m[0m | time: 24.484s
[2K
| Adam | epoch: 001 | loss: 0.69349 - acc: 0.4386 -- iter: 0384/1094
[A[ATraining Step: 13  | total loss: [1m[32m0.69342[0m[0m | time: 35.585s
[2K
| Adam | epoch: 001 | loss: 0.69342 - acc: 0.4515 -- iter: 0416/1094
[A[ATraining Step: 14  | total loss: [1m[32m0.69389[0m[0m | time: 37.155s
[2K
| Adam | epoch: 001 | loss: 0.69389 - acc: 0.4330 -- iter: 0448/1094
[A[ATraining Step: 15  | total loss: [1m[32m0.69350[0m[0m | time: 39.625s
[2K
| Adam | epoch: 001 | loss: 0.69350 - acc: 0.4714 -- iter: 0480/1094
[A[ATraining Step: 16  | total loss: [1m[32m0.69385[0m[0m | time: 41.252s
[2K
| Adam | epoch: 001 | loss: 0.69385 - acc: 0.4236 -- iter: 0512/1094
[A[ATraining Step: 17  | total loss: [1m[32m0.69386[0m[0m | time: 42.615s
[2K
| Adam | epoch: 001 | loss: 0.69386 - acc: 0.3836 -- iter: 0544/1094
[A[ATraining Step: 18  | total loss: [1m[32m0.69358[0m[0m | time: 44.222s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.4455 -- iter: 0576/1094
[A[ATraining Step: 19  | total loss: [1m[32m0.69335[0m[0m | time: 45.888s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.4949 -- iter: 0608/1094
[A[ATraining Step: 20  | total loss: [1m[32m0.69354[0m[0m | time: 47.515s
[2K
| Adam | epoch: 001 | loss: 0.69354 - acc: 0.4664 -- iter: 0640/1094
[A[ATraining Step: 21  | total loss: [1m[32m0.69393[0m[0m | time: 49.023s
[2K
| Adam | epoch: 001 | loss: 0.69393 - acc: 0.4187 -- iter: 0672/1094
[A[ATraining Step: 22  | total loss: [1m[32m0.69388[0m[0m | time: 50.354s
[2K
| Adam | epoch: 001 | loss: 0.69388 - acc: 0.4243 -- iter: 0704/1094
[A[ATraining Step: 23  | total loss: [1m[32m0.69352[0m[0m | time: 52.019s
[2K
| Adam | epoch: 001 | loss: 0.69352 - acc: 0.4644 -- iter: 0736/1094
[A[ATraining Step: 24  | total loss: [1m[32m0.69366[0m[0m | time: 53.636s
[2K
| Adam | epoch: 001 | loss: 0.69366 - acc: 0.4393 -- iter: 0768/1094
[A[ATraining Step: 25  | total loss: [1m[32m0.69353[0m[0m | time: 55.239s
[2K
| Adam | epoch: 001 | loss: 0.69353 - acc: 0.4558 -- iter: 0800/1094
[A[ATraining Step: 26  | total loss: [1m[32m0.69367[0m[0m | time: 56.561s
[2K
| Adam | epoch: 001 | loss: 0.69367 - acc: 0.4262 -- iter: 0832/1094
[A[ATraining Step: 27  | total loss: [1m[32m0.69336[0m[0m | time: 57.915s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4853 -- iter: 0864/1094
[A[ATraining Step: 28  | total loss: [1m[32m0.69341[0m[0m | time: 59.797s
[2K
| Adam | epoch: 001 | loss: 0.69341 - acc: 0.4577 -- iter: 0896/1094
[A[ATraining Step: 29  | total loss: [1m[32m0.69343[0m[0m | time: 61.231s
[2K
| Adam | epoch: 001 | loss: 0.69343 - acc: 0.4376 -- iter: 0928/1094
[A[ATraining Step: 30  | total loss: [1m[32m0.69335[0m[0m | time: 62.677s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.4672 -- iter: 0960/1094
[A[ATraining Step: 31  | total loss: [1m[32m0.69333[0m[0m | time: 64.316s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.4459 -- iter: 0992/1094
[A[ATraining Step: 32  | total loss: [1m[32m0.69330[0m[0m | time: 65.796s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.4581 -- iter: 1024/1094
[A[ATraining Step: 33  | total loss: [1m[32m0.69323[0m[0m | time: 67.526s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.4810 -- iter: 1056/1094
[A[ATraining Step: 34  | total loss: [1m[32m0.69323[0m[0m | time: 69.190s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.4784 -- iter: 1088/1094
[A[ATraining Step: 35  | total loss: [1m[32m0.69328[0m[0m | time: 73.127s
[2K
| Adam | epoch: 001 | loss: 0.69328 - acc: 0.4502 | val_loss: 0.69314 - val_acc: 0.5044 -- iter: 1094/1094
--
Training Step: 36  | total loss: [1m[32m0.69340[0m[0m | time: 0.433s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.3581 -- iter: 0032/1094
[A[ATraining Step: 37  | total loss: [1m[32m0.69324[0m[0m | time: 2.059s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4865 -- iter: 0064/1094
[A[ATraining Step: 38  | total loss: [1m[32m0.69316[0m[0m | time: 8.176s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5014 -- iter: 0096/1094
[A[ATraining Step: 39  | total loss: [1m[32m0.69299[0m[0m | time: 9.599s
[2K
| Adam | epoch: 002 | loss: 0.69299 - acc: 0.5250 -- iter: 0128/1094
[A[ATraining Step: 40  | total loss: [1m[32m0.69285[0m[0m | time: 10.907s
[2K
| Adam | epoch: 002 | loss: 0.69285 - acc: 0.5379 -- iter: 0160/1094
[A[ATraining Step: 41  | total loss: [1m[32m0.69306[0m[0m | time: 20.446s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5195 -- iter: 0192/1094
[A[ATraining Step: 42  | total loss: [1m[32m0.69308[0m[0m | time: 24.020s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5160 -- iter: 0224/1094
[A[ATraining Step: 43  | total loss: [1m[32m0.69312[0m[0m | time: 25.720s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5132 -- iter: 0256/1094
[A[ATraining Step: 44  | total loss: [1m[32m0.69314[0m[0m | time: 27.489s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5109 -- iter: 0288/1094
[A[ATraining Step: 45  | total loss: [1m[32m0.69334[0m[0m | time: 29.110s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4984 -- iter: 0320/1094
[A[ATraining Step: 46  | total loss: [1m[32m0.69279[0m[0m | time: 30.462s
[2K
| Adam | epoch: 002 | loss: 0.69279 - acc: 0.5247 -- iter: 0352/1094
[A[ATraining Step: 47  | total loss: [1m[32m0.69296[0m[0m | time: 31.966s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5156 -- iter: 0384/1094
[A[ATraining Step: 48  | total loss: [1m[32m0.69360[0m[0m | time: 33.699s
[2K
| Adam | epoch: 002 | loss: 0.69360 - acc: 0.4880 -- iter: 0416/1094
[A[ATraining Step: 49  | total loss: [1m[32m0.69352[0m[0m | time: 39.666s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4899 -- iter: 0448/1094
[A[ATraining Step: 50  | total loss: [1m[32m0.69383[0m[0m | time: 53.722s
[2K
| Adam | epoch: 002 | loss: 0.69383 - acc: 0.4769 -- iter: 0480/1094
[A[ATraining Step: 51  | total loss: [1m[32m0.69318[0m[0m | time: 65.126s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5042 -- iter: 0512/1094
[A[ATraining Step: 52  | total loss: [1m[32m0.69376[0m[0m | time: 75.955s
[2K
| Adam | epoch: 002 | loss: 0.69376 - acc: 0.4802 -- iter: 0544/1094
[A[ATraining Step: 53  | total loss: [1m[32m0.69334[0m[0m | time: 87.833s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4969 -- iter: 0576/1094
[A[ATraining Step: 54  | total loss: [1m[32m0.69332[0m[0m | time: 95.483s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4974 -- iter: 0608/1094
[A[ATraining Step: 55  | total loss: [1m[32m0.69320[0m[0m | time: 103.135s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5022 -- iter: 0640/1094
[A[ATraining Step: 56  | total loss: [1m[32m0.69364[0m[0m | time: 107.765s
[2K
| Adam | epoch: 002 | loss: 0.69364 - acc: 0.4843 -- iter: 0672/1094
[A[ATraining Step: 57  | total loss: [1m[32m0.69357[0m[0m | time: 109.942s
[2K
| Adam | epoch: 002 | loss: 0.69357 - acc: 0.4865 -- iter: 0704/1094
[A[ATraining Step: 58  | total loss: [1m[32m0.69343[0m[0m | time: 111.317s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.4926 -- iter: 0736/1094
[A[ATraining Step: 59  | total loss: [1m[32m0.69320[0m[0m | time: 113.048s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5020 -- iter: 0768/1094
[A[ATraining Step: 60  | total loss: [1m[32m0.69311[0m[0m | time: 114.464s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5059 -- iter: 0800/1094
[A[ATraining Step: 61  | total loss: [1m[32m0.69281[0m[0m | time: 116.083s
[2K
| Adam | epoch: 002 | loss: 0.69281 - acc: 0.5173 -- iter: 0832/1094
[A[ATraining Step: 62  | total loss: [1m[32m0.69287[0m[0m | time: 117.668s
[2K
| Adam | epoch: 002 | loss: 0.69287 - acc: 0.5151 -- iter: 0864/1094
[A[ATraining Step: 63  | total loss: [1m[32m0.69271[0m[0m | time: 119.494s
[2K
| Adam | epoch: 002 | loss: 0.69271 - acc: 0.5211 -- iter: 0896/1094
[A[ATraining Step: 64  | total loss: [1m[32m0.69278[0m[0m | time: 121.147s
[2K
| Adam | epoch: 002 | loss: 0.69278 - acc: 0.5185 -- iter: 0928/1094
[A[ATraining Step: 65  | total loss: [1m[32m0.69271[0m[0m | time: 122.764s
[2K
| Adam | epoch: 002 | loss: 0.69271 - acc: 0.5200 -- iter: 0960/1094
[A[ATraining Step: 66  | total loss: [1m[32m0.69310[0m[0m | time: 124.341s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5062 -- iter: 0992/1094
[A[ATraining Step: 67  | total loss: [1m[32m0.69319[0m[0m | time: 125.780s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5017 -- iter: 1024/1094
[A[ATraining Step: 68  | total loss: [1m[32m0.69338[0m[0m | time: 127.234s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.4941 -- iter: 1056/1094
[A[ATraining Step: 69  | total loss: [1m[32m0.69309[0m[0m | time: 128.833s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5058 -- iter: 1088/1094
[A[ATraining Step: 70  | total loss: [1m[32m0.69311[0m[0m | time: 155.380s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5051 | val_loss: 0.69304 - val_acc: 0.5044 -- iter: 1094/1094
--
Training Step: 71  | total loss: [1m[32m0.69268[0m[0m | time: 0.402s
[2K
| Adam | epoch: 003 | loss: 0.69268 - acc: 0.5223 -- iter: 0032/1094
[A[ATraining Step: 72  | total loss: [1m[32m0.69177[0m[0m | time: 0.812s
[2K
| Adam | epoch: 003 | loss: 0.69177 - acc: 0.5573 -- iter: 0064/1094
[A[ATraining Step: 73  | total loss: [1m[32m0.69086[0m[0m | time: 2.409s
[2K
| Adam | epoch: 003 | loss: 0.69086 - acc: 0.5880 -- iter: 0096/1094
[A[ATraining Step: 74  | total loss: [1m[32m0.69147[0m[0m | time: 3.995s
[2K
| Adam | epoch: 003 | loss: 0.69147 - acc: 0.5680 -- iter: 0128/1094
[A[ATraining Step: 75  | total loss: [1m[32m0.69166[0m[0m | time: 5.551s
[2K
| Adam | epoch: 003 | loss: 0.69166 - acc: 0.5606 -- iter: 0160/1094
[A[ATraining Step: 76  | total loss: [1m[32m0.69128[0m[0m | time: 7.496s
[2K
| Adam | epoch: 003 | loss: 0.69128 - acc: 0.5675 -- iter: 0192/1094
[A[ATraining Step: 77  | total loss: [1m[32m0.69148[0m[0m | time: 9.142s
[2K
| Adam | epoch: 003 | loss: 0.69148 - acc: 0.5604 -- iter: 0224/1094
[A[ATraining Step: 78  | total loss: [1m[32m0.69153[0m[0m | time: 10.649s
[2K
| Adam | epoch: 003 | loss: 0.69153 - acc: 0.5573 -- iter: 0256/1094
[A[ATraining Step: 79  | total loss: [1m[32m0.69172[0m[0m | time: 12.252s
[2K
| Adam | epoch: 003 | loss: 0.69172 - acc: 0.5514 -- iter: 0288/1094
[A[ATraining Step: 80  | total loss: [1m[32m0.69173[0m[0m | time: 13.782s
[2K
| Adam | epoch: 003 | loss: 0.69173 - acc: 0.5493 -- iter: 0320/1094
[A[ATraining Step: 81  | total loss: [1m[32m0.69235[0m[0m | time: 15.242s
[2K
| Adam | epoch: 003 | loss: 0.69235 - acc: 0.5380 -- iter: 0352/1094
[A[ATraining Step: 82  | total loss: [1m[32m0.69229[0m[0m | time: 16.953s
[2K
| Adam | epoch: 003 | loss: 0.69229 - acc: 0.5374 -- iter: 0384/1094
[A[ATraining Step: 83  | total loss: [1m[32m0.69202[0m[0m | time: 33.362s
[2K
| Adam | epoch: 003 | loss: 0.69202 - acc: 0.5399 -- iter: 0416/1094
[A[ATraining Step: 84  | total loss: [1m[32m0.69176[0m[0m | time: 40.876s
[2K
| Adam | epoch: 003 | loss: 0.69176 - acc: 0.5421 -- iter: 0448/1094
[A[ATraining Step: 85  | total loss: [1m[32m0.69190[0m[0m | time: 42.790s
[2K
| Adam | epoch: 003 | loss: 0.69190 - acc: 0.5379 -- iter: 0480/1094
[A[ATraining Step: 86  | total loss: [1m[32m0.69188[0m[0m | time: 44.165s
[2K
| Adam | epoch: 003 | loss: 0.69188 - acc: 0.5373 -- iter: 0512/1094
[A[ATraining Step: 87  | total loss: [1m[32m0.69128[0m[0m | time: 45.625s
[2K
| Adam | epoch: 003 | loss: 0.69128 - acc: 0.5429 -- iter: 0544/1094
[A[ATraining Step: 88  | total loss: [1m[32m0.69159[0m[0m | time: 47.293s
[2K
| Adam | epoch: 003 | loss: 0.69159 - acc: 0.5386 -- iter: 0576/1094
[A[ATraining Step: 89  | total loss: [1m[32m0.69264[0m[0m | time: 48.886s
[2K
| Adam | epoch: 003 | loss: 0.69264 - acc: 0.5285 -- iter: 0608/1094
[A[ATraining Step: 90  | total loss: [1m[32m0.69316[0m[0m | time: 50.505s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.5225 -- iter: 0640/1094
[A[ATraining Step: 91  | total loss: [1m[32m0.69355[0m[0m | time: 52.148s
[2K
| Adam | epoch: 003 | loss: 0.69355 - acc: 0.5171 -- iter: 0672/1094
[A[ATraining Step: 92  | total loss: [1m[32m0.69335[0m[0m | time: 54.137s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.5186 -- iter: 0704/1094
[A[ATraining Step: 93  | total loss: [1m[32m0.69334[0m[0m | time: 55.663s
[2K
| Adam | epoch: 003 | loss: 0.69334 - acc: 0.5167 -- iter: 0736/1094
[A[ATraining Step: 94  | total loss: [1m[32m0.69341[0m[0m | time: 57.144s
[2K
| Adam | epoch: 003 | loss: 0.69341 - acc: 0.5150 -- iter: 0768/1094
[A[ATraining Step: 95  | total loss: [1m[32m0.69301[0m[0m | time: 58.992s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5198 -- iter: 0800/1094
[A[ATraining Step: 96  | total loss: [1m[32m0.69340[0m[0m | time: 70.289s
[2K
| Adam | epoch: 003 | loss: 0.69340 - acc: 0.5116 -- iter: 0832/1094
[A[ATraining Step: 97  | total loss: [1m[32m0.69355[0m[0m | time: 84.408s
[2K
| Adam | epoch: 003 | loss: 0.69355 - acc: 0.5073 -- iter: 0864/1094
[A[ATraining Step: 98  | total loss: [1m[32m0.69300[0m[0m | time: 95.291s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5159 -- iter: 0896/1094
[A[ATraining Step: 99  | total loss: [1m[32m0.69254[0m[0m | time: 98.626s
[2K
| Adam | epoch: 003 | loss: 0.69254 - acc: 0.5237 -- iter: 0928/1094
[A[ATraining Step: 100  | total loss: [1m[32m0.69310[0m[0m | time: 103.172s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5120 -- iter: 0960/1094
[A[ATraining Step: 101  | total loss: [1m[32m0.69292[0m[0m | time: 107.165s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5139 -- iter: 0992/1094
[A[ATraining Step: 102  | total loss: [1m[32m0.69277[0m[0m | time: 108.703s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5156 -- iter: 1024/1094
[A[ATraining Step: 103  | total loss: [1m[32m0.69266[0m[0m | time: 110.310s
[2K
| Adam | epoch: 003 | loss: 0.69266 - acc: 0.5172 -- iter: 1056/1094
[A[ATraining Step: 104  | total loss: [1m[32m0.69342[0m[0m | time: 112.156s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.5030 -- iter: 1088/1094
[A[ATraining Step: 105  | total loss: [1m[32m0.69319[0m[0m | time: 118.110s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5058 | val_loss: 0.69285 - val_acc: 0.5044 -- iter: 1094/1094
--
Training Step: 106  | total loss: [1m[32m0.69353[0m[0m | time: 1.486s
[2K
| Adam | epoch: 004 | loss: 0.69353 - acc: 0.4990 -- iter: 0032/1094
[A[ATraining Step: 107  | total loss: [1m[32m0.69394[0m[0m | time: 1.981s
[2K
| Adam | epoch: 004 | loss: 0.69394 - acc: 0.4897 -- iter: 0064/1094
[A[ATraining Step: 108  | total loss: [1m[32m0.69293[0m[0m | time: 2.399s
[2K
| Adam | epoch: 004 | loss: 0.69293 - acc: 0.5074 -- iter: 0096/1094
[A[ATraining Step: 109  | total loss: [1m[32m0.69192[0m[0m | time: 3.989s
[2K
| Adam | epoch: 004 | loss: 0.69192 - acc: 0.5233 -- iter: 0128/1094
[A[ATraining Step: 110  | total loss: [1m[32m0.69095[0m[0m | time: 5.473s
[2K
| Adam | epoch: 004 | loss: 0.69095 - acc: 0.5397 -- iter: 0160/1094
[A[ATraining Step: 111  | total loss: [1m[32m0.69098[0m[0m | time: 19.555s
[2K
| Adam | epoch: 004 | loss: 0.69098 - acc: 0.5389 -- iter: 0192/1094
[A[ATraining Step: 112  | total loss: [1m[32m0.69218[0m[0m | time: 21.857s
[2K
| Adam | epoch: 004 | loss: 0.69218 - acc: 0.5225 -- iter: 0224/1094
[A[ATraining Step: 113  | total loss: [1m[32m0.69268[0m[0m | time: 23.351s
[2K
| Adam | epoch: 004 | loss: 0.69268 - acc: 0.5140 -- iter: 0256/1094
[A[ATraining Step: 114  | total loss: [1m[32m0.69125[0m[0m | time: 25.018s
[2K
| Adam | epoch: 004 | loss: 0.69125 - acc: 0.5313 -- iter: 0288/1094
[A[ATraining Step: 115  | total loss: [1m[32m0.69160[0m[0m | time: 26.531s
[2K
| Adam | epoch: 004 | loss: 0.69160 - acc: 0.5251 -- iter: 0320/1094
[A[ATraining Step: 116  | total loss: [1m[32m0.69199[0m[0m | time: 28.089s
[2K
| Adam | epoch: 004 | loss: 0.69199 - acc: 0.5195 -- iter: 0352/1094
[A[ATraining Step: 117  | total loss: [1m[32m0.69084[0m[0m | time: 29.942s
[2K
| Adam | epoch: 004 | loss: 0.69084 - acc: 0.5300 -- iter: 0384/1094
[A[ATraining Step: 118  | total loss: [1m[32m0.68984[0m[0m | time: 31.546s
[2K
| Adam | epoch: 004 | loss: 0.68984 - acc: 0.5364 -- iter: 0416/1094
[A[ATraining Step: 119  | total loss: [1m[32m0.68983[0m[0m | time: 32.944s
[2K
| Adam | epoch: 004 | loss: 0.68983 - acc: 0.5359 -- iter: 0448/1094
[A[ATraining Step: 120  | total loss: [1m[32m0.69341[0m[0m | time: 34.116s
[2K
| Adam | epoch: 004 | loss: 0.69341 - acc: 0.5135 -- iter: 0480/1094
[A[ATraining Step: 121  | total loss: [1m[32m0.69201[0m[0m | time: 35.456s
[2K
| Adam | epoch: 004 | loss: 0.69201 - acc: 0.5216 -- iter: 0512/1094
[A[ATraining Step: 122  | total loss: [1m[32m0.69152[0m[0m | time: 36.930s
[2K
| Adam | epoch: 004 | loss: 0.69152 - acc: 0.5194 -- iter: 0544/1094
[A[ATraining Step: 123  | total loss: [1m[32m0.68953[0m[0m | time: 38.341s
[2K
| Adam | epoch: 004 | loss: 0.68953 - acc: 0.5331 -- iter: 0576/1094
[A[ATraining Step: 124  | total loss: [1m[32m0.69223[0m[0m | time: 39.792s
[2K
| Adam | epoch: 004 | loss: 0.69223 - acc: 0.5110 -- iter: 0608/1094
[A[ATraining Step: 125  | total loss: [1m[32m0.69115[0m[0m | time: 41.289s
[2K
| Adam | epoch: 004 | loss: 0.69115 - acc: 0.5130 -- iter: 0640/1094
[A[ATraining Step: 126  | total loss: [1m[32m0.69179[0m[0m | time: 42.749s
[2K
| Adam | epoch: 004 | loss: 0.69179 - acc: 0.5024 -- iter: 0672/1094
[A[ATraining Step: 127  | total loss: [1m[32m0.69191[0m[0m | time: 44.012s
[2K
| Adam | epoch: 004 | loss: 0.69191 - acc: 0.4990 -- iter: 0704/1094
[A[ATraining Step: 128  | total loss: [1m[32m0.69092[0m[0m | time: 45.236s
[2K
| Adam | epoch: 004 | loss: 0.69092 - acc: 0.5054 -- iter: 0736/1094
[A[ATraining Step: 129  | total loss: [1m[32m0.68959[0m[0m | time: 46.474s
[2K
| Adam | epoch: 004 | loss: 0.68959 - acc: 0.5111 -- iter: 0768/1094
[A[ATraining Step: 130  | total loss: [1m[32m0.68959[0m[0m | time: 47.753s
[2K
| Adam | epoch: 004 | loss: 0.68959 - acc: 0.5100 -- iter: 0800/1094
[A[ATraining Step: 131  | total loss: [1m[32m0.68737[0m[0m | time: 49.112s
[2K
| Adam | epoch: 004 | loss: 0.68737 - acc: 0.5246 -- iter: 0832/1094
[A[ATraining Step: 132  | total loss: [1m[32m0.68635[0m[0m | time: 50.384s
[2K
| Adam | epoch: 004 | loss: 0.68635 - acc: 0.5253 -- iter: 0864/1094
[A[ATraining Step: 133  | total loss: [1m[32m0.68199[0m[0m | time: 51.619s
[2K
| Adam | epoch: 004 | loss: 0.68199 - acc: 0.5384 -- iter: 0896/1094
[A[ATraining Step: 134  | total loss: [1m[32m0.68645[0m[0m | time: 52.588s
[2K
| Adam | epoch: 004 | loss: 0.68645 - acc: 0.5283 -- iter: 0928/1094
[A[ATraining Step: 135  | total loss: [1m[32m0.69240[0m[0m | time: 53.525s
[2K
| Adam | epoch: 004 | loss: 0.69240 - acc: 0.5192 -- iter: 0960/1094
[A[ATraining Step: 136  | total loss: [1m[32m0.69192[0m[0m | time: 54.514s
[2K
| Adam | epoch: 004 | loss: 0.69192 - acc: 0.5110 -- iter: 0992/1094
[A[ATraining Step: 137  | total loss: [1m[32m0.68760[0m[0m | time: 55.509s
[2K
| Adam | epoch: 004 | loss: 0.68760 - acc: 0.5193 -- iter: 1024/1094
[A[ATraining Step: 138  | total loss: [1m[32m0.68423[0m[0m | time: 56.583s
[2K
| Adam | epoch: 004 | loss: 0.68423 - acc: 0.5205 -- iter: 1056/1094
[A[ATraining Step: 139  | total loss: [1m[32m0.68316[0m[0m | time: 57.975s
[2K
| Adam | epoch: 004 | loss: 0.68316 - acc: 0.5247 -- iter: 1088/1094
[A[ATraining Step: 140  | total loss: [1m[32m0.68323[0m[0m | time: 61.674s
[2K
| Adam | epoch: 004 | loss: 0.68323 - acc: 0.5222 | val_loss: 0.67039 - val_acc: 0.5044 -- iter: 1094/1094
--
Training Step: 141  | total loss: [1m[32m0.68171[0m[0m | time: 1.353s
[2K
| Adam | epoch: 005 | loss: 0.68171 - acc: 0.5263 -- iter: 0032/1094
[A[ATraining Step: 142  | total loss: [1m[32m0.68420[0m[0m | time: 2.600s
[2K
| Adam | epoch: 005 | loss: 0.68420 - acc: 0.5111 -- iter: 0064/1094
[A[ATraining Step: 143  | total loss: [1m[32m0.68581[0m[0m | time: 2.919s
[2K
| Adam | epoch: 005 | loss: 0.68581 - acc: 0.4975 -- iter: 0096/1094
[A[ATraining Step: 144  | total loss: [1m[32m0.67828[0m[0m | time: 3.260s
[2K
| Adam | epoch: 005 | loss: 0.67828 - acc: 0.4978 -- iter: 0128/1094
[A[ATraining Step: 145  | total loss: [1m[32m0.67029[0m[0m | time: 4.538s
[2K
| Adam | epoch: 005 | loss: 0.67029 - acc: 0.4980 -- iter: 0160/1094
[A[ATraining Step: 146  | total loss: [1m[32m0.66818[0m[0m | time: 5.935s
[2K
| Adam | epoch: 005 | loss: 0.66818 - acc: 0.5076 -- iter: 0192/1094
[A[ATraining Step: 147  | total loss: [1m[32m0.66721[0m[0m | time: 7.267s
[2K
| Adam | epoch: 005 | loss: 0.66721 - acc: 0.5224 -- iter: 0224/1094
[A[ATraining Step: 148  | total loss: [1m[32m0.67236[0m[0m | time: 8.574s
[2K
| Adam | epoch: 005 | loss: 0.67236 - acc: 0.5327 -- iter: 0256/1094
[A[ATraining Step: 149  | total loss: [1m[32m0.67358[0m[0m | time: 9.880s
[2K
| Adam | epoch: 005 | loss: 0.67358 - acc: 0.5450 -- iter: 0288/1094
[A[ATraining Step: 150  | total loss: [1m[32m0.66212[0m[0m | time: 11.178s
[2K
| Adam | epoch: 005 | loss: 0.66212 - acc: 0.5655 -- iter: 0320/1094
[A[ATraining Step: 151  | total loss: [1m[32m0.66285[0m[0m | time: 12.617s
[2K
| Adam | epoch: 005 | loss: 0.66285 - acc: 0.5777 -- iter: 0352/1094
[A[ATraining Step: 152  | total loss: [1m[32m0.66436[0m[0m | time: 14.272s
[2K
| Adam | epoch: 005 | loss: 0.66436 - acc: 0.5762 -- iter: 0384/1094
[A[ATraining Step: 153  | total loss: [1m[32m0.67816[0m[0m | time: 15.451s
[2K
| Adam | epoch: 005 | loss: 0.67816 - acc: 0.5717 -- iter: 0416/1094
[A[ATraining Step: 154  | total loss: [1m[32m0.67643[0m[0m | time: 16.734s
[2K
| Adam | epoch: 005 | loss: 0.67643 - acc: 0.5708 -- iter: 0448/1094
[A[ATraining Step: 155  | total loss: [1m[32m0.67511[0m[0m | time: 18.048s
[2K
| Adam | epoch: 005 | loss: 0.67511 - acc: 0.5700 -- iter: 0480/1094
[A[ATraining Step: 156  | total loss: [1m[32m0.67409[0m[0m | time: 19.251s
[2K
| Adam | epoch: 005 | loss: 0.67409 - acc: 0.5723 -- iter: 0512/1094
[A[ATraining Step: 157  | total loss: [1m[32m0.67384[0m[0m | time: 20.490s
[2K
| Adam | epoch: 005 | loss: 0.67384 - acc: 0.5682 -- iter: 0544/1094
[A[ATraining Step: 158  | total loss: [1m[32m0.67196[0m[0m | time: 21.785s
[2K
| Adam | epoch: 005 | loss: 0.67196 - acc: 0.5802 -- iter: 0576/1094
[A[ATraining Step: 159  | total loss: [1m[32m0.67272[0m[0m | time: 23.378s
[2K
| Adam | epoch: 005 | loss: 0.67272 - acc: 0.5815 -- iter: 0608/1094
[A[ATraining Step: 160  | total loss: [1m[32m0.67000[0m[0m | time: 24.702s
[2K
| Adam | epoch: 005 | loss: 0.67000 - acc: 0.5796 -- iter: 0640/1094
[A[ATraining Step: 161  | total loss: [1m[32m0.66170[0m[0m | time: 26.054s
[2K
| Adam | epoch: 005 | loss: 0.66170 - acc: 0.5967 -- iter: 0672/1094
[A[ATraining Step: 162  | total loss: [1m[32m0.66179[0m[0m | time: 27.653s
[2K
| Adam | epoch: 005 | loss: 0.66179 - acc: 0.5995 -- iter: 0704/1094
[A[ATraining Step: 163  | total loss: [1m[32m0.66031[0m[0m | time: 29.309s
[2K
| Adam | epoch: 005 | loss: 0.66031 - acc: 0.6020 -- iter: 0736/1094
[A[ATraining Step: 164  | total loss: [1m[32m0.65204[0m[0m | time: 30.729s
[2K
| Adam | epoch: 005 | loss: 0.65204 - acc: 0.6137 -- iter: 0768/1094
[A[ATraining Step: 165  | total loss: [1m[32m0.65018[0m[0m | time: 33.853s
[2K
| Adam | epoch: 005 | loss: 0.65018 - acc: 0.6117 -- iter: 0800/1094
[A[ATraining Step: 166  | total loss: [1m[32m0.65241[0m[0m | time: 44.484s
[2K
| Adam | epoch: 005 | loss: 0.65241 - acc: 0.6130 -- iter: 0832/1094
[A[ATraining Step: 167  | total loss: [1m[32m0.65548[0m[0m | time: 45.723s
[2K
| Adam | epoch: 005 | loss: 0.65548 - acc: 0.6080 -- iter: 0864/1094
[A[ATraining Step: 168  | total loss: [1m[32m0.64712[0m[0m | time: 46.911s
[2K
| Adam | epoch: 005 | loss: 0.64712 - acc: 0.6222 -- iter: 0896/1094
[A[ATraining Step: 169  | total loss: [1m[32m0.64099[0m[0m | time: 48.309s
[2K
| Adam | epoch: 005 | loss: 0.64099 - acc: 0.6381 -- iter: 0928/1094
[A[ATraining Step: 170  | total loss: [1m[32m0.63972[0m[0m | time: 49.636s
[2K
| Adam | epoch: 005 | loss: 0.63972 - acc: 0.6399 -- iter: 0960/1094
[A[ATraining Step: 171  | total loss: [1m[32m0.64127[0m[0m | time: 50.937s
[2K
| Adam | epoch: 005 | loss: 0.64127 - acc: 0.6353 -- iter: 0992/1094
[A[ATraining Step: 172  | total loss: [1m[32m0.63390[0m[0m | time: 52.324s
[2K
| Adam | epoch: 005 | loss: 0.63390 - acc: 0.6436 -- iter: 1024/1094
[A[ATraining Step: 173  | total loss: [1m[32m0.64553[0m[0m | time: 53.537s
[2K
| Adam | epoch: 005 | loss: 0.64553 - acc: 0.6262 -- iter: 1056/1094
[A[ATraining Step: 174  | total loss: [1m[32m0.64797[0m[0m | time: 54.836s
[2K
| Adam | epoch: 005 | loss: 0.64797 - acc: 0.6260 -- iter: 1088/1094
[A[ATraining Step: 175  | total loss: [1m[32m0.64586[0m[0m | time: 79.933s
[2K
| Adam | epoch: 005 | loss: 0.64586 - acc: 0.6259 | val_loss: 0.63903 - val_acc: 0.6793 -- iter: 1094/1094
--
Training Step: 176  | total loss: [1m[32m0.63561[0m[0m | time: 1.484s
[2K
| Adam | epoch: 006 | loss: 0.63561 - acc: 0.6446 -- iter: 0032/1094
[A[ATraining Step: 177  | total loss: [1m[32m0.64736[0m[0m | time: 3.110s
[2K
| Adam | epoch: 006 | loss: 0.64736 - acc: 0.6395 -- iter: 0064/1094
[A[ATraining Step: 178  | total loss: [1m[32m0.64356[0m[0m | time: 4.593s
[2K
| Adam | epoch: 006 | loss: 0.64356 - acc: 0.6474 -- iter: 0096/1094
[A[ATraining Step: 179  | total loss: [1m[32m0.64109[0m[0m | time: 5.010s
[2K
| Adam | epoch: 006 | loss: 0.64109 - acc: 0.6546 -- iter: 0128/1094
[A[ATraining Step: 180  | total loss: [1m[32m0.66315[0m[0m | time: 5.384s
[2K
| Adam | epoch: 006 | loss: 0.66315 - acc: 0.6391 -- iter: 0160/1094
[A[ATraining Step: 181  | total loss: [1m[32m0.67122[0m[0m | time: 7.006s
[2K
| Adam | epoch: 006 | loss: 0.67122 - acc: 0.6252 -- iter: 0192/1094
[A[ATraining Step: 182  | total loss: [1m[32m0.66635[0m[0m | time: 8.676s
[2K
| Adam | epoch: 006 | loss: 0.66635 - acc: 0.6314 -- iter: 0224/1094
[A[ATraining Step: 183  | total loss: [1m[32m0.66173[0m[0m | time: 10.287s
[2K
| Adam | epoch: 006 | loss: 0.66173 - acc: 0.6370 -- iter: 0256/1094
[A[ATraining Step: 184  | total loss: [1m[32m0.66464[0m[0m | time: 11.796s
[2K
| Adam | epoch: 006 | loss: 0.66464 - acc: 0.6296 -- iter: 0288/1094
[A[ATraining Step: 185  | total loss: [1m[32m0.66806[0m[0m | time: 13.371s
[2K
| Adam | epoch: 006 | loss: 0.66806 - acc: 0.6229 -- iter: 0320/1094
[A[ATraining Step: 186  | total loss: [1m[32m0.66999[0m[0m | time: 15.044s
[2K
| Adam | epoch: 006 | loss: 0.66999 - acc: 0.6200 -- iter: 0352/1094
[A[ATraining Step: 187  | total loss: [1m[32m0.66926[0m[0m | time: 16.738s
[2K
| Adam | epoch: 006 | loss: 0.66926 - acc: 0.6173 -- iter: 0384/1094
[A[ATraining Step: 188  | total loss: [1m[32m0.67136[0m[0m | time: 31.154s
[2K
| Adam | epoch: 006 | loss: 0.67136 - acc: 0.6119 -- iter: 0416/1094
[A[ATraining Step: 189  | total loss: [1m[32m0.66946[0m[0m | time: 37.181s
[2K
| Adam | epoch: 006 | loss: 0.66946 - acc: 0.6132 -- iter: 0448/1094
[A[ATraining Step: 190  | total loss: [1m[32m0.66847[0m[0m | time: 38.735s
[2K
| Adam | epoch: 006 | loss: 0.66847 - acc: 0.6144 -- iter: 0480/1094
[A[ATraining Step: 191  | total loss: [1m[32m0.67041[0m[0m | time: 40.105s
[2K
| Adam | epoch: 006 | loss: 0.67041 - acc: 0.6060 -- iter: 0512/1094
[A[ATraining Step: 192  | total loss: [1m[32m0.66826[0m[0m | time: 41.359s
[2K
| Adam | epoch: 006 | loss: 0.66826 - acc: 0.6079 -- iter: 0544/1094
[A[ATraining Step: 193  | total loss: [1m[32m0.66520[0m[0m | time: 42.734s
[2K
| Adam | epoch: 006 | loss: 0.66520 - acc: 0.6128 -- iter: 0576/1094
[A[ATraining Step: 194  | total loss: [1m[32m0.66654[0m[0m | time: 44.360s
[2K
| Adam | epoch: 006 | loss: 0.66654 - acc: 0.6077 -- iter: 0608/1094
[A[ATraining Step: 195  | total loss: [1m[32m0.66276[0m[0m | time: 45.798s
[2K
| Adam | epoch: 006 | loss: 0.66276 - acc: 0.6220 -- iter: 0640/1094
[A[ATraining Step: 196  | total loss: [1m[32m0.65918[0m[0m | time: 47.399s
[2K
| Adam | epoch: 006 | loss: 0.65918 - acc: 0.6316 -- iter: 0672/1094
[A[ATraining Step: 197  | total loss: [1m[32m0.65385[0m[0m | time: 48.910s
[2K
| Adam | epoch: 006 | loss: 0.65385 - acc: 0.6466 -- iter: 0704/1094
[A[ATraining Step: 198  | total loss: [1m[32m0.64679[0m[0m | time: 50.629s
[2K
| Adam | epoch: 006 | loss: 0.64679 - acc: 0.6601 -- iter: 0736/1094
[A[ATraining Step: 199  | total loss: [1m[32m0.64370[0m[0m | time: 52.453s
[2K
| Adam | epoch: 006 | loss: 0.64370 - acc: 0.6628 -- iter: 0768/1094
[A[ATraining Step: 200  | total loss: [1m[32m0.63430[0m[0m | time: 57.085s
[2K
| Adam | epoch: 006 | loss: 0.63430 - acc: 0.6778 | val_loss: 0.58464 - val_acc: 0.6822 -- iter: 0800/1094
--
Training Step: 201  | total loss: [1m[32m0.62670[0m[0m | time: 58.818s
[2K
| Adam | epoch: 006 | loss: 0.62670 - acc: 0.6913 -- iter: 0832/1094
[A[ATraining Step: 202  | total loss: [1m[32m0.62093[0m[0m | time: 60.450s
[2K
| Adam | epoch: 006 | loss: 0.62093 - acc: 0.6909 -- iter: 0864/1094
[A[ATraining Step: 203  | total loss: [1m[32m0.62311[0m[0m | time: 61.792s
[2K
| Adam | epoch: 006 | loss: 0.62311 - acc: 0.6905 -- iter: 0896/1094
[A[ATraining Step: 204  | total loss: [1m[32m0.62428[0m[0m | time: 63.325s
[2K
| Adam | epoch: 006 | loss: 0.62428 - acc: 0.6902 -- iter: 0928/1094
[A[ATraining Step: 205  | total loss: [1m[32m0.63127[0m[0m | time: 65.123s
[2K
| Adam | epoch: 006 | loss: 0.63127 - acc: 0.6900 -- iter: 0960/1094
[A[ATraining Step: 206  | total loss: [1m[32m0.63632[0m[0m | time: 66.905s
[2K
| Adam | epoch: 006 | loss: 0.63632 - acc: 0.6835 -- iter: 0992/1094
[A[ATraining Step: 207  | total loss: [1m[32m0.63175[0m[0m | time: 68.330s
[2K
| Adam | epoch: 006 | loss: 0.63175 - acc: 0.6807 -- iter: 1024/1094
[A[ATraining Step: 208  | total loss: [1m[32m0.62382[0m[0m | time: 70.182s
[2K
| Adam | epoch: 006 | loss: 0.62382 - acc: 0.6845 -- iter: 1056/1094
[A[ATraining Step: 209  | total loss: [1m[32m0.62068[0m[0m | time: 75.506s
[2K
| Adam | epoch: 006 | loss: 0.62068 - acc: 0.6817 -- iter: 1088/1094
[A[ATraining Step: 210  | total loss: [1m[32m0.60756[0m[0m | time: 99.916s
[2K
| Adam | epoch: 006 | loss: 0.60756 - acc: 0.6948 | val_loss: 0.59534 - val_acc: 0.6822 -- iter: 1094/1094
--
Training Step: 211  | total loss: [1m[32m0.60906[0m[0m | time: 1.564s
[2K
| Adam | epoch: 007 | loss: 0.60906 - acc: 0.6909 -- iter: 0032/1094
[A[ATraining Step: 212  | total loss: [1m[32m0.61422[0m[0m | time: 4.133s
[2K
| Adam | epoch: 007 | loss: 0.61422 - acc: 0.6812 -- iter: 0064/1094
[A[ATraining Step: 213  | total loss: [1m[32m0.61680[0m[0m | time: 6.965s
[2K
| Adam | epoch: 007 | loss: 0.61680 - acc: 0.6818 -- iter: 0096/1094
[A[ATraining Step: 214  | total loss: [1m[32m0.61317[0m[0m | time: 8.965s
[2K
| Adam | epoch: 007 | loss: 0.61317 - acc: 0.6855 -- iter: 0128/1094
[A[ATraining Step: 215  | total loss: [1m[32m0.60729[0m[0m | time: 9.336s
[2K
| Adam | epoch: 007 | loss: 0.60729 - acc: 0.6982 -- iter: 0160/1094
[A[ATraining Step: 216  | total loss: [1m[32m0.61433[0m[0m | time: 9.993s
[2K
| Adam | epoch: 007 | loss: 0.61433 - acc: 0.6951 -- iter: 0192/1094
[A[ATraining Step: 217  | total loss: [1m[32m0.61651[0m[0m | time: 11.583s
[2K
| Adam | epoch: 007 | loss: 0.61651 - acc: 0.7089 -- iter: 0224/1094
[A[ATraining Step: 218  | total loss: [1m[32m0.61282[0m[0m | time: 13.263s
[2K
| Adam | epoch: 007 | loss: 0.61282 - acc: 0.7099 -- iter: 0256/1094
[A[ATraining Step: 219  | total loss: [1m[32m0.63218[0m[0m | time: 14.686s
[2K
| Adam | epoch: 007 | loss: 0.63218 - acc: 0.6889 -- iter: 0288/1094
[A[ATraining Step: 220  | total loss: [1m[32m0.64509[0m[0m | time: 16.322s
[2K
| Adam | epoch: 007 | loss: 0.64509 - acc: 0.6763 -- iter: 0320/1094
[A[ATraining Step: 221  | total loss: [1m[32m0.63604[0m[0m | time: 17.960s
[2K
| Adam | epoch: 007 | loss: 0.63604 - acc: 0.6805 -- iter: 0352/1094
[A[ATraining Step: 222  | total loss: [1m[32m0.63007[0m[0m | time: 22.545s
[2K
| Adam | epoch: 007 | loss: 0.63007 - acc: 0.6937 -- iter: 0384/1094
[A[ATraining Step: 223  | total loss: [1m[32m0.62007[0m[0m | time: 27.297s
[2K
| Adam | epoch: 007 | loss: 0.62007 - acc: 0.7056 -- iter: 0416/1094
[A[ATraining Step: 224  | total loss: [1m[32m0.62575[0m[0m | time: 34.299s
[2K
| Adam | epoch: 007 | loss: 0.62575 - acc: 0.6913 -- iter: 0448/1094
[A[ATraining Step: 225  | total loss: [1m[32m0.62322[0m[0m | time: 49.578s
[2K
| Adam | epoch: 007 | loss: 0.62322 - acc: 0.6972 -- iter: 0480/1094
[A[ATraining Step: 226  | total loss: [1m[32m0.61971[0m[0m | time: 51.197s
[2K
| Adam | epoch: 007 | loss: 0.61971 - acc: 0.6962 -- iter: 0512/1094
[A[ATraining Step: 227  | total loss: [1m[32m0.62073[0m[0m | time: 60.713s
[2K
| Adam | epoch: 007 | loss: 0.62073 - acc: 0.6953 -- iter: 0544/1094
[A[ATraining Step: 228  | total loss: [1m[32m0.61384[0m[0m | time: 62.777s
[2K
| Adam | epoch: 007 | loss: 0.61384 - acc: 0.7070 -- iter: 0576/1094
[A[ATraining Step: 229  | total loss: [1m[32m0.61442[0m[0m | time: 64.234s
[2K
| Adam | epoch: 007 | loss: 0.61442 - acc: 0.7113 -- iter: 0608/1094
[A[ATraining Step: 230  | total loss: [1m[32m0.61149[0m[0m | time: 65.981s
[2K
| Adam | epoch: 007 | loss: 0.61149 - acc: 0.7121 -- iter: 0640/1094
[A[ATraining Step: 231  | total loss: [1m[32m0.60392[0m[0m | time: 67.662s
[2K
| Adam | epoch: 007 | loss: 0.60392 - acc: 0.7127 -- iter: 0672/1094
[A[ATraining Step: 232  | total loss: [1m[32m0.60095[0m[0m | time: 69.402s
[2K
| Adam | epoch: 007 | loss: 0.60095 - acc: 0.7040 -- iter: 0704/1094
[A[ATraining Step: 233  | total loss: [1m[32m0.59795[0m[0m | time: 71.049s
[2K
| Adam | epoch: 007 | loss: 0.59795 - acc: 0.7023 -- iter: 0736/1094
[A[ATraining Step: 234  | total loss: [1m[32m0.59505[0m[0m | time: 72.725s
[2K
| Adam | epoch: 007 | loss: 0.59505 - acc: 0.7040 -- iter: 0768/1094
[A[ATraining Step: 235  | total loss: [1m[32m0.59842[0m[0m | time: 74.475s
[2K
| Adam | epoch: 007 | loss: 0.59842 - acc: 0.6992 -- iter: 0800/1094
[A[ATraining Step: 236  | total loss: [1m[32m0.58951[0m[0m | time: 83.946s
[2K
| Adam | epoch: 007 | loss: 0.58951 - acc: 0.7043 -- iter: 0832/1094
[A[ATraining Step: 237  | total loss: [1m[32m0.59929[0m[0m | time: 85.349s
[2K
| Adam | epoch: 007 | loss: 0.59929 - acc: 0.6995 -- iter: 0864/1094
[A[ATraining Step: 238  | total loss: [1m[32m0.59759[0m[0m | time: 99.135s
[2K
| Adam | epoch: 007 | loss: 0.59759 - acc: 0.7014 -- iter: 0896/1094
[A[ATraining Step: 239  | total loss: [1m[32m0.59953[0m[0m | time: 108.634s
[2K
| Adam | epoch: 007 | loss: 0.59953 - acc: 0.7000 -- iter: 0928/1094
[A[ATraining Step: 240  | total loss: [1m[32m0.59454[0m[0m | time: 114.802s
[2K
| Adam | epoch: 007 | loss: 0.59454 - acc: 0.7081 -- iter: 0960/1094
[A[ATraining Step: 241  | total loss: [1m[32m0.59263[0m[0m | time: 120.274s
[2K
| Adam | epoch: 007 | loss: 0.59263 - acc: 0.7061 -- iter: 0992/1094
[A[ATraining Step: 242  | total loss: [1m[32m0.59055[0m[0m | time: 126.873s
[2K
| Adam | epoch: 007 | loss: 0.59055 - acc: 0.7042 -- iter: 1024/1094
[A[ATraining Step: 243  | total loss: [1m[32m0.58753[0m[0m | time: 131.477s
[2K
| Adam | epoch: 007 | loss: 0.58753 - acc: 0.7025 -- iter: 1056/1094
[A[ATraining Step: 244  | total loss: [1m[32m0.58358[0m[0m | time: 132.591s
[2K
| Adam | epoch: 007 | loss: 0.58358 - acc: 0.6979 -- iter: 1088/1094
[A[ATraining Step: 245  | total loss: [1m[32m0.59366[0m[0m | time: 137.996s
[2K
| Adam | epoch: 007 | loss: 0.59366 - acc: 0.6937 | val_loss: 0.56159 - val_acc: 0.7143 -- iter: 1094/1094
--
Training Step: 246  | total loss: [1m[32m0.59742[0m[0m | time: 1.842s
[2K
| Adam | epoch: 008 | loss: 0.59742 - acc: 0.6931 -- iter: 0032/1094
[A[ATraining Step: 247  | total loss: [1m[32m0.58605[0m[0m | time: 3.647s
[2K
| Adam | epoch: 008 | loss: 0.58605 - acc: 0.7051 -- iter: 0064/1094
[A[ATraining Step: 248  | total loss: [1m[32m0.58828[0m[0m | time: 5.292s
[2K
| Adam | epoch: 008 | loss: 0.58828 - acc: 0.7002 -- iter: 0096/1094
[A[ATraining Step: 249  | total loss: [1m[32m0.57671[0m[0m | time: 6.878s
[2K
| Adam | epoch: 008 | loss: 0.57671 - acc: 0.7052 -- iter: 0128/1094
[A[ATraining Step: 250  | total loss: [1m[32m0.56286[0m[0m | time: 8.531s
[2K
| Adam | epoch: 008 | loss: 0.56286 - acc: 0.7221 -- iter: 0160/1094
[A[ATraining Step: 251  | total loss: [1m[32m0.57818[0m[0m | time: 8.939s
[2K
| Adam | epoch: 008 | loss: 0.57818 - acc: 0.7093 -- iter: 0192/1094
[A[ATraining Step: 252  | total loss: [1m[32m0.57282[0m[0m | time: 9.324s
[2K
| Adam | epoch: 008 | loss: 0.57282 - acc: 0.7217 -- iter: 0224/1094
[A[ATraining Step: 253  | total loss: [1m[32m0.56484[0m[0m | time: 12.006s
[2K
| Adam | epoch: 008 | loss: 0.56484 - acc: 0.7329 -- iter: 0256/1094
[A[ATraining Step: 254  | total loss: [1m[32m0.57047[0m[0m | time: 21.482s
[2K
| Adam | epoch: 008 | loss: 0.57047 - acc: 0.7221 -- iter: 0288/1094
[A[ATraining Step: 255  | total loss: [1m[32m0.57412[0m[0m | time: 29.812s
[2K
| Adam | epoch: 008 | loss: 0.57412 - acc: 0.7186 -- iter: 0320/1094
[A[ATraining Step: 256  | total loss: [1m[32m0.56653[0m[0m | time: 36.518s
[2K
| Adam | epoch: 008 | loss: 0.56653 - acc: 0.7249 -- iter: 0352/1094
[A[ATraining Step: 257  | total loss: [1m[32m0.55477[0m[0m | time: 40.357s
[2K
| Adam | epoch: 008 | loss: 0.55477 - acc: 0.7368 -- iter: 0384/1094
[A[ATraining Step: 258  | total loss: [1m[32m0.54720[0m[0m | time: 41.853s
[2K
| Adam | epoch: 008 | loss: 0.54720 - acc: 0.7443 -- iter: 0416/1094
[A[ATraining Step: 259  | total loss: [1m[32m0.55066[0m[0m | time: 43.346s
[2K
| Adam | epoch: 008 | loss: 0.55066 - acc: 0.7355 -- iter: 0448/1094
[A[ATraining Step: 260  | total loss: [1m[32m0.54025[0m[0m | time: 45.047s
[2K
| Adam | epoch: 008 | loss: 0.54025 - acc: 0.7464 -- iter: 0480/1094
[A[ATraining Step: 261  | total loss: [1m[32m0.54179[0m[0m | time: 46.587s
[2K
| Adam | epoch: 008 | loss: 0.54179 - acc: 0.7436 -- iter: 0512/1094
[A[ATraining Step: 262  | total loss: [1m[32m0.54557[0m[0m | time: 48.514s
[2K
| Adam | epoch: 008 | loss: 0.54557 - acc: 0.7442 -- iter: 0544/1094
[A[ATraining Step: 263  | total loss: [1m[32m0.54395[0m[0m | time: 50.304s
[2K
| Adam | epoch: 008 | loss: 0.54395 - acc: 0.7448 -- iter: 0576/1094
[A[ATraining Step: 264  | total loss: [1m[32m0.53495[0m[0m | time: 52.081s
[2K
| Adam | epoch: 008 | loss: 0.53495 - acc: 0.7547 -- iter: 0608/1094
[A[ATraining Step: 265  | total loss: [1m[32m0.52671[0m[0m | time: 53.924s
[2K
| Adam | epoch: 008 | loss: 0.52671 - acc: 0.7574 -- iter: 0640/1094
[A[ATraining Step: 266  | total loss: [1m[32m0.51714[0m[0m | time: 55.768s
[2K
| Adam | epoch: 008 | loss: 0.51714 - acc: 0.7660 -- iter: 0672/1094
[A[ATraining Step: 267  | total loss: [1m[32m0.53899[0m[0m | time: 57.376s
[2K
| Adam | epoch: 008 | loss: 0.53899 - acc: 0.7488 -- iter: 0704/1094
[A[ATraining Step: 268  | total loss: [1m[32m0.53962[0m[0m | time: 58.986s
[2K
| Adam | epoch: 008 | loss: 0.53962 - acc: 0.7426 -- iter: 0736/1094
[A[ATraining Step: 269  | total loss: [1m[32m0.53691[0m[0m | time: 68.224s
[2K
| Adam | epoch: 008 | loss: 0.53691 - acc: 0.7465 -- iter: 0768/1094
[A[ATraining Step: 270  | total loss: [1m[32m0.53268[0m[0m | time: 77.756s
[2K
| Adam | epoch: 008 | loss: 0.53268 - acc: 0.7469 -- iter: 0800/1094
[A[ATraining Step: 271  | total loss: [1m[32m0.52118[0m[0m | time: 86.612s
[2K
| Adam | epoch: 008 | loss: 0.52118 - acc: 0.7597 -- iter: 0832/1094
[A[ATraining Step: 272  | total loss: [1m[32m0.52635[0m[0m | time: 91.356s
[2K
| Adam | epoch: 008 | loss: 0.52635 - acc: 0.7556 -- iter: 0864/1094
[A[ATraining Step: 273  | total loss: [1m[32m0.51170[0m[0m | time: 92.801s
[2K
| Adam | epoch: 008 | loss: 0.51170 - acc: 0.7644 -- iter: 0896/1094
[A[ATraining Step: 274  | total loss: [1m[32m0.50069[0m[0m | time: 94.363s
[2K
| Adam | epoch: 008 | loss: 0.50069 - acc: 0.7755 -- iter: 0928/1094
[A[ATraining Step: 275  | total loss: [1m[32m0.49989[0m[0m | time: 95.834s
[2K
| Adam | epoch: 008 | loss: 0.49989 - acc: 0.7667 -- iter: 0960/1094
[A[ATraining Step: 276  | total loss: [1m[32m0.51237[0m[0m | time: 97.281s
[2K
| Adam | epoch: 008 | loss: 0.51237 - acc: 0.7587 -- iter: 0992/1094
[A[ATraining Step: 277  | total loss: [1m[32m0.50201[0m[0m | time: 98.898s
[2K
| Adam | epoch: 008 | loss: 0.50201 - acc: 0.7704 -- iter: 1024/1094
[A[ATraining Step: 278  | total loss: [1m[32m0.49389[0m[0m | time: 100.494s
[2K
| Adam | epoch: 008 | loss: 0.49389 - acc: 0.7840 -- iter: 1056/1094
[A[ATraining Step: 279  | total loss: [1m[32m0.49431[0m[0m | time: 102.054s
[2K
| Adam | epoch: 008 | loss: 0.49431 - acc: 0.7806 -- iter: 1088/1094
[A[ATraining Step: 280  | total loss: [1m[32m0.49424[0m[0m | time: 107.709s
[2K
| Adam | epoch: 008 | loss: 0.49424 - acc: 0.7838 | val_loss: 0.67349 - val_acc: 0.6472 -- iter: 1094/1094
--
Training Step: 281  | total loss: [1m[32m0.50067[0m[0m | time: 1.637s
[2K
| Adam | epoch: 009 | loss: 0.50067 - acc: 0.7773 -- iter: 0032/1094
[A[ATraining Step: 282  | total loss: [1m[32m0.52651[0m[0m | time: 3.900s
[2K
| Adam | epoch: 009 | loss: 0.52651 - acc: 0.7589 -- iter: 0064/1094
[A[ATraining Step: 283  | total loss: [1m[32m0.52422[0m[0m | time: 10.393s
[2K
| Adam | epoch: 009 | loss: 0.52422 - acc: 0.7611 -- iter: 0096/1094
[A[ATraining Step: 284  | total loss: [1m[32m0.51739[0m[0m | time: 17.581s
[2K
| Adam | epoch: 009 | loss: 0.51739 - acc: 0.7694 -- iter: 0128/1094
[A[ATraining Step: 285  | total loss: [1m[32m0.52850[0m[0m | time: 21.768s
[2K
| Adam | epoch: 009 | loss: 0.52850 - acc: 0.7612 -- iter: 0160/1094
[A[ATraining Step: 286  | total loss: [1m[32m0.53085[0m[0m | time: 23.186s
[2K
| Adam | epoch: 009 | loss: 0.53085 - acc: 0.7538 -- iter: 0192/1094
[A[ATraining Step: 287  | total loss: [1m[32m0.54322[0m[0m | time: 23.616s
[2K
| Adam | epoch: 009 | loss: 0.54322 - acc: 0.7378 -- iter: 0224/1094
[A[ATraining Step: 288  | total loss: [1m[32m0.56373[0m[0m | time: 24.063s
[2K
| Adam | epoch: 009 | loss: 0.56373 - acc: 0.7140 -- iter: 0256/1094
[A[ATraining Step: 289  | total loss: [1m[32m0.56507[0m[0m | time: 25.906s
[2K
| Adam | epoch: 009 | loss: 0.56507 - acc: 0.7093 -- iter: 0288/1094
[A[ATraining Step: 290  | total loss: [1m[32m0.56589[0m[0m | time: 27.514s
[2K
| Adam | epoch: 009 | loss: 0.56589 - acc: 0.7165 -- iter: 0320/1094
[A[ATraining Step: 291  | total loss: [1m[32m0.56585[0m[0m | time: 29.400s
[2K
| Adam | epoch: 009 | loss: 0.56585 - acc: 0.7199 -- iter: 0352/1094
[A[ATraining Step: 292  | total loss: [1m[32m0.56899[0m[0m | time: 31.168s
[2K
| Adam | epoch: 009 | loss: 0.56899 - acc: 0.7104 -- iter: 0384/1094
[A[ATraining Step: 293  | total loss: [1m[32m0.57893[0m[0m | time: 32.953s
[2K
| Adam | epoch: 009 | loss: 0.57893 - acc: 0.7050 -- iter: 0416/1094
[A[ATraining Step: 294  | total loss: [1m[32m0.57643[0m[0m | time: 34.569s
[2K
| Adam | epoch: 009 | loss: 0.57643 - acc: 0.7032 -- iter: 0448/1094
[A[ATraining Step: 295  | total loss: [1m[32m0.57801[0m[0m | time: 35.928s
[2K
| Adam | epoch: 009 | loss: 0.57801 - acc: 0.7048 -- iter: 0480/1094
[A[ATraining Step: 296  | total loss: [1m[32m0.58274[0m[0m | time: 37.369s
[2K
| Adam | epoch: 009 | loss: 0.58274 - acc: 0.6937 -- iter: 0512/1094
[A[ATraining Step: 297  | total loss: [1m[32m0.57191[0m[0m | time: 38.551s
[2K
| Adam | epoch: 009 | loss: 0.57191 - acc: 0.7055 -- iter: 0544/1094
[A[ATraining Step: 298  | total loss: [1m[32m0.57477[0m[0m | time: 39.741s
[2K
| Adam | epoch: 009 | loss: 0.57477 - acc: 0.7131 -- iter: 0576/1094
[A[ATraining Step: 299  | total loss: [1m[32m0.57098[0m[0m | time: 41.143s
[2K
| Adam | epoch: 009 | loss: 0.57098 - acc: 0.7231 -- iter: 0608/1094
[A[ATraining Step: 300  | total loss: [1m[32m0.56929[0m[0m | time: 42.425s
[2K
| Adam | epoch: 009 | loss: 0.56929 - acc: 0.7289 -- iter: 0640/1094
[A[ATraining Step: 301  | total loss: [1m[32m0.56176[0m[0m | time: 43.401s
[2K
| Adam | epoch: 009 | loss: 0.56176 - acc: 0.7466 -- iter: 0672/1094
[A[ATraining Step: 302  | total loss: [1m[32m0.56362[0m[0m | time: 44.460s
[2K
| Adam | epoch: 009 | loss: 0.56362 - acc: 0.7470 -- iter: 0704/1094
[A[ATraining Step: 303  | total loss: [1m[32m0.55746[0m[0m | time: 45.847s
[2K
| Adam | epoch: 009 | loss: 0.55746 - acc: 0.7535 -- iter: 0736/1094
[A[ATraining Step: 304  | total loss: [1m[32m0.54863[0m[0m | time: 47.216s
[2K
| Adam | epoch: 009 | loss: 0.54863 - acc: 0.7625 -- iter: 0768/1094
[A[ATraining Step: 305  | total loss: [1m[32m0.54184[0m[0m | time: 48.600s
[2K
| Adam | epoch: 009 | loss: 0.54184 - acc: 0.7644 -- iter: 0800/1094
[A[ATraining Step: 306  | total loss: [1m[32m0.53243[0m[0m | time: 50.042s
[2K
| Adam | epoch: 009 | loss: 0.53243 - acc: 0.7755 -- iter: 0832/1094
[A[ATraining Step: 307  | total loss: [1m[32m0.52618[0m[0m | time: 51.303s
[2K
| Adam | epoch: 009 | loss: 0.52618 - acc: 0.7792 -- iter: 0864/1094
[A[ATraining Step: 308  | total loss: [1m[32m0.52564[0m[0m | time: 52.739s
[2K
| Adam | epoch: 009 | loss: 0.52564 - acc: 0.7762 -- iter: 0896/1094
[A[ATraining Step: 309  | total loss: [1m[32m0.53176[0m[0m | time: 54.186s
[2K
| Adam | epoch: 009 | loss: 0.53176 - acc: 0.7736 -- iter: 0928/1094
[A[ATraining Step: 310  | total loss: [1m[32m0.51418[0m[0m | time: 55.368s
[2K
| Adam | epoch: 009 | loss: 0.51418 - acc: 0.7806 -- iter: 0960/1094
[A[ATraining Step: 311  | total loss: [1m[32m0.51468[0m[0m | time: 56.622s
[2K
| Adam | epoch: 009 | loss: 0.51468 - acc: 0.7776 -- iter: 0992/1094
[A[ATraining Step: 312  | total loss: [1m[32m0.52716[0m[0m | time: 58.112s
[2K
| Adam | epoch: 009 | loss: 0.52716 - acc: 0.7654 -- iter: 1024/1094
[A[ATraining Step: 313  | total loss: [1m[32m0.51234[0m[0m | time: 59.399s
[2K
| Adam | epoch: 009 | loss: 0.51234 - acc: 0.7733 -- iter: 1056/1094
[A[ATraining Step: 314  | total loss: [1m[32m0.50001[0m[0m | time: 61.117s
[2K
| Adam | epoch: 009 | loss: 0.50001 - acc: 0.7803 -- iter: 1088/1094
[A[ATraining Step: 315  | total loss: [1m[32m0.49389[0m[0m | time: 66.500s
[2K
| Adam | epoch: 009 | loss: 0.49389 - acc: 0.7804 | val_loss: 0.61750 - val_acc: 0.7026 -- iter: 1094/1094
--
Training Step: 316  | total loss: [1m[32m0.48294[0m[0m | time: 1.709s
[2K
| Adam | epoch: 010 | loss: 0.48294 - acc: 0.7867 -- iter: 0032/1094
[A[ATraining Step: 317  | total loss: [1m[32m0.47075[0m[0m | time: 3.456s
[2K
| Adam | epoch: 010 | loss: 0.47075 - acc: 0.7924 -- iter: 0064/1094
[A[ATraining Step: 318  | total loss: [1m[32m0.46885[0m[0m | time: 5.367s
[2K
| Adam | epoch: 010 | loss: 0.46885 - acc: 0.7945 -- iter: 0096/1094
[A[ATraining Step: 319  | total loss: [1m[32m0.47621[0m[0m | time: 7.120s
[2K
| Adam | epoch: 010 | loss: 0.47621 - acc: 0.7900 -- iter: 0128/1094
[A[ATraining Step: 320  | total loss: [1m[32m0.47092[0m[0m | time: 9.073s
[2K
| Adam | epoch: 010 | loss: 0.47092 - acc: 0.7923 -- iter: 0160/1094
[A[ATraining Step: 321  | total loss: [1m[32m0.47654[0m[0m | time: 11.365s
[2K
| Adam | epoch: 010 | loss: 0.47654 - acc: 0.7912 -- iter: 0192/1094
[A[ATraining Step: 322  | total loss: [1m[32m0.49194[0m[0m | time: 12.673s
[2K
| Adam | epoch: 010 | loss: 0.49194 - acc: 0.7777 -- iter: 0224/1094
[A[ATraining Step: 323  | total loss: [1m[32m0.51022[0m[0m | time: 13.069s
[2K
| Adam | epoch: 010 | loss: 0.51022 - acc: 0.7561 -- iter: 0256/1094
[A[ATraining Step: 324  | total loss: [1m[32m0.52952[0m[0m | time: 13.440s
[2K
| Adam | epoch: 010 | loss: 0.52952 - acc: 0.7472 -- iter: 0288/1094
[A[ATraining Step: 325  | total loss: [1m[32m0.52720[0m[0m | time: 15.175s
[2K
| Adam | epoch: 010 | loss: 0.52720 - acc: 0.7391 -- iter: 0320/1094
[A[ATraining Step: 326  | total loss: [1m[32m0.52323[0m[0m | time: 16.958s
[2K
| Adam | epoch: 010 | loss: 0.52323 - acc: 0.7371 -- iter: 0352/1094
[A[ATraining Step: 327  | total loss: [1m[32m0.52485[0m[0m | time: 18.299s
[2K
| Adam | epoch: 010 | loss: 0.52485 - acc: 0.7415 -- iter: 0384/1094
[A[ATraining Step: 328  | total loss: [1m[32m0.53650[0m[0m | time: 19.856s
[2K
| Adam | epoch: 010 | loss: 0.53650 - acc: 0.7424 -- iter: 0416/1094
[A[ATraining Step: 329  | total loss: [1m[32m0.52748[0m[0m | time: 21.394s
[2K
| Adam | epoch: 010 | loss: 0.52748 - acc: 0.7431 -- iter: 0448/1094
[A[ATraining Step: 330  | total loss: [1m[32m0.53049[0m[0m | time: 23.070s
[2K
| Adam | epoch: 010 | loss: 0.53049 - acc: 0.7282 -- iter: 0480/1094
[A[ATraining Step: 331  | total loss: [1m[32m0.51242[0m[0m | time: 24.342s
[2K
| Adam | epoch: 010 | loss: 0.51242 - acc: 0.7522 -- iter: 0512/1094
[A[ATraining Step: 332  | total loss: [1m[32m0.51878[0m[0m | time: 26.058s
[2K
| Adam | epoch: 010 | loss: 0.51878 - acc: 0.7458 -- iter: 0544/1094
[A[ATraining Step: 333  | total loss: [1m[32m0.51471[0m[0m | time: 27.857s
[2K
| Adam | epoch: 010 | loss: 0.51471 - acc: 0.7462 -- iter: 0576/1094
[A[ATraining Step: 334  | total loss: [1m[32m0.50709[0m[0m | time: 29.754s
[2K
| Adam | epoch: 010 | loss: 0.50709 - acc: 0.7591 -- iter: 0608/1094
[A[ATraining Step: 335  | total loss: [1m[32m0.51078[0m[0m | time: 32.580s
[2K
| Adam | epoch: 010 | loss: 0.51078 - acc: 0.7582 -- iter: 0640/1094
[A[ATraining Step: 336  | total loss: [1m[32m0.51692[0m[0m | time: 35.820s
[2K
| Adam | epoch: 010 | loss: 0.51692 - acc: 0.7574 -- iter: 0672/1094
[A[ATraining Step: 337  | total loss: [1m[32m0.52009[0m[0m | time: 37.979s
[2K
| Adam | epoch: 010 | loss: 0.52009 - acc: 0.7566 -- iter: 0704/1094
[A[ATraining Step: 338  | total loss: [1m[32m0.51645[0m[0m | time: 41.079s
[2K
| Adam | epoch: 010 | loss: 0.51645 - acc: 0.7685 -- iter: 0736/1094
[A[ATraining Step: 339  | total loss: [1m[32m0.51842[0m[0m | time: 42.795s
[2K
| Adam | epoch: 010 | loss: 0.51842 - acc: 0.7604 -- iter: 0768/1094
[A[ATraining Step: 340  | total loss: [1m[32m0.51772[0m[0m | time: 44.618s
[2K
| Adam | epoch: 010 | loss: 0.51772 - acc: 0.7593 -- iter: 0800/1094
[A[ATraining Step: 341  | total loss: [1m[32m0.52329[0m[0m | time: 47.020s
[2K
| Adam | epoch: 010 | loss: 0.52329 - acc: 0.7490 -- iter: 0832/1094
[A[ATraining Step: 342  | total loss: [1m[32m0.51832[0m[0m | time: 48.539s
[2K
| Adam | epoch: 010 | loss: 0.51832 - acc: 0.7554 -- iter: 0864/1094
[A[ATraining Step: 343  | total loss: [1m[32m0.53302[0m[0m | time: 50.323s
[2K
| Adam | epoch: 010 | loss: 0.53302 - acc: 0.7361 -- iter: 0896/1094
[A[ATraining Step: 344  | total loss: [1m[32m0.53336[0m[0m | time: 51.994s
[2K
| Adam | epoch: 010 | loss: 0.53336 - acc: 0.7406 -- iter: 0928/1094
[A[ATraining Step: 345  | total loss: [1m[32m0.52189[0m[0m | time: 53.705s
[2K
| Adam | epoch: 010 | loss: 0.52189 - acc: 0.7509 -- iter: 0960/1094
[A[ATraining Step: 346  | total loss: [1m[32m0.51609[0m[0m | time: 55.290s
[2K
| Adam | epoch: 010 | loss: 0.51609 - acc: 0.7539 -- iter: 0992/1094
[A[ATraining Step: 347  | total loss: [1m[32m0.51644[0m[0m | time: 57.181s
[2K
| Adam | epoch: 010 | loss: 0.51644 - acc: 0.7567 -- iter: 1024/1094
[A[ATraining Step: 348  | total loss: [1m[32m0.50328[0m[0m | time: 58.853s
[2K
| Adam | epoch: 010 | loss: 0.50328 - acc: 0.7623 -- iter: 1056/1094
[A[ATraining Step: 349  | total loss: [1m[32m0.49042[0m[0m | time: 60.297s
[2K
| Adam | epoch: 010 | loss: 0.49042 - acc: 0.7673 -- iter: 1088/1094
[A[ATraining Step: 350  | total loss: [1m[32m0.49370[0m[0m | time: 68.531s
[2K
| Adam | epoch: 010 | loss: 0.49370 - acc: 0.7718 | val_loss: 0.49962 - val_acc: 0.7755 -- iter: 1094/1094
--
Training Step: 351  | total loss: [1m[32m0.48218[0m[0m | time: 1.513s
[2K
| Adam | epoch: 011 | loss: 0.48218 - acc: 0.7790 -- iter: 0032/1094
[A[ATraining Step: 352  | total loss: [1m[32m0.47762[0m[0m | time: 3.131s
[2K
| Adam | epoch: 011 | loss: 0.47762 - acc: 0.7855 -- iter: 0064/1094
[A[ATraining Step: 353  | total loss: [1m[32m0.46142[0m[0m | time: 4.841s
[2K
| Adam | epoch: 011 | loss: 0.46142 - acc: 0.7944 -- iter: 0096/1094
[A[ATraining Step: 354  | total loss: [1m[32m0.46439[0m[0m | time: 6.516s
[2K
| Adam | epoch: 011 | loss: 0.46439 - acc: 0.7931 -- iter: 0128/1094
[A[ATraining Step: 355  | total loss: [1m[32m0.44469[0m[0m | time: 8.311s
[2K
| Adam | epoch: 011 | loss: 0.44469 - acc: 0.8044 -- iter: 0160/1094
[A[ATraining Step: 356  | total loss: [1m[32m0.44315[0m[0m | time: 10.065s
[2K
| Adam | epoch: 011 | loss: 0.44315 - acc: 0.8052 -- iter: 0192/1094
[A[ATraining Step: 357  | total loss: [1m[32m0.43858[0m[0m | time: 11.546s
[2K
| Adam | epoch: 011 | loss: 0.43858 - acc: 0.8028 -- iter: 0224/1094
[A[ATraining Step: 358  | total loss: [1m[32m0.42452[0m[0m | time: 12.946s
[2K
| Adam | epoch: 011 | loss: 0.42452 - acc: 0.8132 -- iter: 0256/1094
[A[ATraining Step: 359  | total loss: [1m[32m0.42782[0m[0m | time: 13.357s
[2K
| Adam | epoch: 011 | loss: 0.42782 - acc: 0.8162 -- iter: 0288/1094
[A[ATraining Step: 360  | total loss: [1m[32m0.44495[0m[0m | time: 13.783s
[2K
| Adam | epoch: 011 | loss: 0.44495 - acc: 0.8013 -- iter: 0320/1094
[A[ATraining Step: 361  | total loss: [1m[32m0.44503[0m[0m | time: 15.467s
[2K
| Adam | epoch: 011 | loss: 0.44503 - acc: 0.7878 -- iter: 0352/1094
[A[ATraining Step: 362  | total loss: [1m[32m0.45037[0m[0m | time: 22.614s
[2K
| Adam | epoch: 011 | loss: 0.45037 - acc: 0.7903 -- iter: 0384/1094
[A[ATraining Step: 363  | total loss: [1m[32m0.46287[0m[0m | time: 24.142s
[2K
| Adam | epoch: 011 | loss: 0.46287 - acc: 0.7800 -- iter: 0416/1094
[A[ATraining Step: 364  | total loss: [1m[32m0.46206[0m[0m | time: 25.742s
[2K
| Adam | epoch: 011 | loss: 0.46206 - acc: 0.7739 -- iter: 0448/1094
[A[ATraining Step: 365  | total loss: [1m[32m0.45416[0m[0m | time: 27.251s
[2K
| Adam | epoch: 011 | loss: 0.45416 - acc: 0.7840 -- iter: 0480/1094
[A[ATraining Step: 366  | total loss: [1m[32m0.45501[0m[0m | time: 28.636s
[2K
| Adam | epoch: 011 | loss: 0.45501 - acc: 0.7837 -- iter: 0512/1094
[A[ATraining Step: 367  | total loss: [1m[32m0.46030[0m[0m | time: 30.100s
[2K
| Adam | epoch: 011 | loss: 0.46030 - acc: 0.7772 -- iter: 0544/1094
[A[ATraining Step: 368  | total loss: [1m[32m0.46676[0m[0m | time: 31.999s
[2K
| Adam | epoch: 011 | loss: 0.46676 - acc: 0.7745 -- iter: 0576/1094
[A[ATraining Step: 369  | total loss: [1m[32m0.46031[0m[0m | time: 33.754s
[2K
| Adam | epoch: 011 | loss: 0.46031 - acc: 0.7814 -- iter: 0608/1094
[A[ATraining Step: 370  | total loss: [1m[32m0.45225[0m[0m | time: 35.547s
[2K
| Adam | epoch: 011 | loss: 0.45225 - acc: 0.7845 -- iter: 0640/1094
[A[ATraining Step: 371  | total loss: [1m[32m0.43537[0m[0m | time: 37.004s
[2K
| Adam | epoch: 011 | loss: 0.43537 - acc: 0.7967 -- iter: 0672/1094
[A[ATraining Step: 372  | total loss: [1m[32m0.43799[0m[0m | time: 38.845s
[2K
| Adam | epoch: 011 | loss: 0.43799 - acc: 0.7889 -- iter: 0704/1094
[A[ATraining Step: 373  | total loss: [1m[32m0.43707[0m[0m | time: 40.608s
[2K
| Adam | epoch: 011 | loss: 0.43707 - acc: 0.7944 -- iter: 0736/1094
[A[ATraining Step: 374  | total loss: [1m[32m0.45396[0m[0m | time: 42.231s
[2K
| Adam | epoch: 011 | loss: 0.45396 - acc: 0.7900 -- iter: 0768/1094
[A[ATraining Step: 375  | total loss: [1m[32m0.44545[0m[0m | time: 45.942s
[2K
| Adam | epoch: 011 | loss: 0.44545 - acc: 0.7985 -- iter: 0800/1094
[A[ATraining Step: 376  | total loss: [1m[32m0.43138[0m[0m | time: 48.996s
[2K
| Adam | epoch: 011 | loss: 0.43138 - acc: 0.8092 -- iter: 0832/1094
[A[ATraining Step: 377  | total loss: [1m[32m0.42342[0m[0m | time: 50.681s
[2K
| Adam | epoch: 011 | loss: 0.42342 - acc: 0.8189 -- iter: 0864/1094
[A[ATraining Step: 378  | total loss: [1m[32m0.42555[0m[0m | time: 52.145s
[2K
| Adam | epoch: 011 | loss: 0.42555 - acc: 0.8120 -- iter: 0896/1094
[A[ATraining Step: 379  | total loss: [1m[32m0.42024[0m[0m | time: 53.554s
[2K
| Adam | epoch: 011 | loss: 0.42024 - acc: 0.8152 -- iter: 0928/1094
[A[ATraining Step: 380  | total loss: [1m[32m0.41253[0m[0m | time: 55.163s
[2K
| Adam | epoch: 011 | loss: 0.41253 - acc: 0.8149 -- iter: 0960/1094
[A[ATraining Step: 381  | total loss: [1m[32m0.41800[0m[0m | time: 56.878s
[2K
| Adam | epoch: 011 | loss: 0.41800 - acc: 0.8147 -- iter: 0992/1094
[A[ATraining Step: 382  | total loss: [1m[32m0.42958[0m[0m | time: 58.336s
[2K
| Adam | epoch: 011 | loss: 0.42958 - acc: 0.8051 -- iter: 1024/1094
[A[ATraining Step: 383  | total loss: [1m[32m0.43196[0m[0m | time: 59.851s
[2K
| Adam | epoch: 011 | loss: 0.43196 - acc: 0.8058 -- iter: 1056/1094
[A[ATraining Step: 384  | total loss: [1m[32m0.42801[0m[0m | time: 61.703s
[2K
| Adam | epoch: 011 | loss: 0.42801 - acc: 0.8065 -- iter: 1088/1094
[A[ATraining Step: 385  | total loss: [1m[32m0.42698[0m[0m | time: 67.476s
[2K
| Adam | epoch: 011 | loss: 0.42698 - acc: 0.8071 | val_loss: 0.48463 - val_acc: 0.7872 -- iter: 1094/1094
--
Training Step: 386  | total loss: [1m[32m0.42182[0m[0m | time: 1.539s
[2K
| Adam | epoch: 012 | loss: 0.42182 - acc: 0.8108 -- iter: 0032/1094
[A[ATraining Step: 387  | total loss: [1m[32m0.42028[0m[0m | time: 3.078s
[2K
| Adam | epoch: 012 | loss: 0.42028 - acc: 0.8078 -- iter: 0064/1094
[A[ATraining Step: 388  | total loss: [1m[32m0.42251[0m[0m | time: 4.608s
[2K
| Adam | epoch: 012 | loss: 0.42251 - acc: 0.8020 -- iter: 0096/1094
[A[ATraining Step: 389  | total loss: [1m[32m0.41636[0m[0m | time: 6.074s
[2K
| Adam | epoch: 012 | loss: 0.41636 - acc: 0.8062 -- iter: 0128/1094
[A[ATraining Step: 390  | total loss: [1m[32m0.41226[0m[0m | time: 7.807s
[2K
| Adam | epoch: 012 | loss: 0.41226 - acc: 0.8068 -- iter: 0160/1094
[A[ATraining Step: 391  | total loss: [1m[32m0.41056[0m[0m | time: 9.633s
[2K
| Adam | epoch: 012 | loss: 0.41056 - acc: 0.8043 -- iter: 0192/1094
[A[ATraining Step: 392  | total loss: [1m[32m0.39113[0m[0m | time: 10.917s
[2K
| Adam | epoch: 012 | loss: 0.39113 - acc: 0.8207 -- iter: 0224/1094
[A[ATraining Step: 393  | total loss: [1m[32m0.39848[0m[0m | time: 12.507s
[2K
| Adam | epoch: 012 | loss: 0.39848 - acc: 0.8168 -- iter: 0256/1094
[A[ATraining Step: 394  | total loss: [1m[32m0.41272[0m[0m | time: 14.290s
[2K
| Adam | epoch: 012 | loss: 0.41272 - acc: 0.8101 -- iter: 0288/1094
[A[ATraining Step: 395  | total loss: [1m[32m0.39868[0m[0m | time: 14.728s
[2K
| Adam | epoch: 012 | loss: 0.39868 - acc: 0.8197 -- iter: 0320/1094
[A[ATraining Step: 396  | total loss: [1m[32m0.37680[0m[0m | time: 15.142s
[2K
| Adam | epoch: 012 | loss: 0.37680 - acc: 0.8377 -- iter: 0352/1094
[A[ATraining Step: 397  | total loss: [1m[32m0.35226[0m[0m | time: 17.001s
[2K
| Adam | epoch: 012 | loss: 0.35226 - acc: 0.8540 -- iter: 0384/1094
[A[ATraining Step: 398  | total loss: [1m[32m0.34870[0m[0m | time: 18.747s
[2K
| Adam | epoch: 012 | loss: 0.34870 - acc: 0.8498 -- iter: 0416/1094
[A[ATraining Step: 399  | total loss: [1m[32m0.35037[0m[0m | time: 22.500s
[2K
| Adam | epoch: 012 | loss: 0.35037 - acc: 0.8555 -- iter: 0448/1094
[A[ATraining Step: 400  | total loss: [1m[32m0.35617[0m[0m | time: 28.469s
[2K
| Adam | epoch: 012 | loss: 0.35617 - acc: 0.8543 | val_loss: 0.60063 - val_acc: 0.7318 -- iter: 0480/1094
--
Training Step: 401  | total loss: [1m[32m0.34859[0m[0m | time: 30.356s
[2K
| Adam | epoch: 012 | loss: 0.34859 - acc: 0.8564 -- iter: 0512/1094
[A[ATraining Step: 402  | total loss: [1m[32m0.35110[0m[0m | time: 31.793s
[2K
| Adam | epoch: 012 | loss: 0.35110 - acc: 0.8551 -- iter: 0544/1094
[A[ATraining Step: 403  | total loss: [1m[32m0.35915[0m[0m | time: 33.345s
[2K
| Adam | epoch: 012 | loss: 0.35915 - acc: 0.8508 -- iter: 0576/1094
[A[ATraining Step: 404  | total loss: [1m[32m0.35188[0m[0m | time: 34.953s
[2K
| Adam | epoch: 012 | loss: 0.35188 - acc: 0.8564 -- iter: 0608/1094
[A[ATraining Step: 405  | total loss: [1m[32m0.33626[0m[0m | time: 36.595s
[2K
| Adam | epoch: 012 | loss: 0.33626 - acc: 0.8614 -- iter: 0640/1094
[A[ATraining Step: 406  | total loss: [1m[32m0.33812[0m[0m | time: 38.221s
[2K
| Adam | epoch: 012 | loss: 0.33812 - acc: 0.8627 -- iter: 0672/1094
[A[ATraining Step: 407  | total loss: [1m[32m0.35838[0m[0m | time: 39.487s
[2K
| Adam | epoch: 012 | loss: 0.35838 - acc: 0.8452 -- iter: 0704/1094
[A[ATraining Step: 408  | total loss: [1m[32m0.35416[0m[0m | time: 41.023s
[2K
| Adam | epoch: 012 | loss: 0.35416 - acc: 0.8482 -- iter: 0736/1094
[A[ATraining Step: 409  | total loss: [1m[32m0.34814[0m[0m | time: 42.675s
[2K
| Adam | epoch: 012 | loss: 0.34814 - acc: 0.8540 -- iter: 0768/1094
[A[ATraining Step: 410  | total loss: [1m[32m0.34249[0m[0m | time: 44.479s
[2K
| Adam | epoch: 012 | loss: 0.34249 - acc: 0.8530 -- iter: 0800/1094
[A[ATraining Step: 411  | total loss: [1m[32m0.34591[0m[0m | time: 46.080s
[2K
| Adam | epoch: 012 | loss: 0.34591 - acc: 0.8583 -- iter: 0832/1094
[A[ATraining Step: 412  | total loss: [1m[32m0.35740[0m[0m | time: 47.458s
[2K
| Adam | epoch: 012 | loss: 0.35740 - acc: 0.8568 -- iter: 0864/1094
[A[ATraining Step: 413  | total loss: [1m[32m0.35149[0m[0m | time: 49.230s
[2K
| Adam | epoch: 012 | loss: 0.35149 - acc: 0.8587 -- iter: 0896/1094
[A[ATraining Step: 414  | total loss: [1m[32m0.34600[0m[0m | time: 51.048s
[2K
| Adam | epoch: 012 | loss: 0.34600 - acc: 0.8572 -- iter: 0928/1094
[A[ATraining Step: 415  | total loss: [1m[32m0.34230[0m[0m | time: 52.903s
[2K
| Adam | epoch: 012 | loss: 0.34230 - acc: 0.8558 -- iter: 0960/1094
[A[ATraining Step: 416  | total loss: [1m[32m0.35370[0m[0m | time: 54.461s
[2K
| Adam | epoch: 012 | loss: 0.35370 - acc: 0.8452 -- iter: 0992/1094
[A[ATraining Step: 417  | total loss: [1m[32m0.33895[0m[0m | time: 56.040s
[2K
| Adam | epoch: 012 | loss: 0.33895 - acc: 0.8576 -- iter: 1024/1094
[A[ATraining Step: 418  | total loss: [1m[32m0.33799[0m[0m | time: 57.814s
[2K
| Adam | epoch: 012 | loss: 0.33799 - acc: 0.8562 -- iter: 1056/1094
[A[ATraining Step: 419  | total loss: [1m[32m0.32688[0m[0m | time: 59.535s
[2K
| Adam | epoch: 012 | loss: 0.32688 - acc: 0.8643 -- iter: 1088/1094
[A[ATraining Step: 420  | total loss: [1m[32m0.32534[0m[0m | time: 64.428s
[2K
| Adam | epoch: 012 | loss: 0.32534 - acc: 0.8654 | val_loss: 0.48230 - val_acc: 0.7726 -- iter: 1094/1094
--
Training Step: 421  | total loss: [1m[32m0.31252[0m[0m | time: 1.460s
[2K
| Adam | epoch: 013 | loss: 0.31252 - acc: 0.8695 -- iter: 0032/1094
[A[ATraining Step: 422  | total loss: [1m[32m0.31422[0m[0m | time: 2.744s
[2K
| Adam | epoch: 013 | loss: 0.31422 - acc: 0.8700 -- iter: 0064/1094
[A[ATraining Step: 423  | total loss: [1m[32m0.32500[0m[0m | time: 4.096s
[2K
| Adam | epoch: 013 | loss: 0.32500 - acc: 0.8580 -- iter: 0096/1094
[A[ATraining Step: 424  | total loss: [1m[32m0.32328[0m[0m | time: 5.297s
[2K
| Adam | epoch: 013 | loss: 0.32328 - acc: 0.8597 -- iter: 0128/1094
[A[ATraining Step: 425  | total loss: [1m[32m0.32013[0m[0m | time: 6.558s
[2K
| Adam | epoch: 013 | loss: 0.32013 - acc: 0.8644 -- iter: 0160/1094
[A[ATraining Step: 426  | total loss: [1m[32m0.32427[0m[0m | time: 7.549s
[2K
| Adam | epoch: 013 | loss: 0.32427 - acc: 0.8654 -- iter: 0192/1094
[A[ATraining Step: 427  | total loss: [1m[32m0.33974[0m[0m | time: 8.845s
[2K
| Adam | epoch: 013 | loss: 0.33974 - acc: 0.8570 -- iter: 0224/1094
[A[ATraining Step: 428  | total loss: [1m[32m0.33610[0m[0m | time: 10.382s
[2K
| Adam | epoch: 013 | loss: 0.33610 - acc: 0.8588 -- iter: 0256/1094
[A[ATraining Step: 429  | total loss: [1m[32m0.33756[0m[0m | time: 11.807s
[2K
| Adam | epoch: 013 | loss: 0.33756 - acc: 0.8511 -- iter: 0288/1094
[A[ATraining Step: 430  | total loss: [1m[32m0.34309[0m[0m | time: 12.976s
[2K
| Adam | epoch: 013 | loss: 0.34309 - acc: 0.8535 -- iter: 0320/1094
[A[ATraining Step: 431  | total loss: [1m[32m0.34101[0m[0m | time: 13.293s
[2K
| Adam | epoch: 013 | loss: 0.34101 - acc: 0.8556 -- iter: 0352/1094
[A[ATraining Step: 432  | total loss: [1m[32m0.37512[0m[0m | time: 13.592s
[2K
| Adam | epoch: 013 | loss: 0.37512 - acc: 0.8367 -- iter: 0384/1094
[A[ATraining Step: 433  | total loss: [1m[32m0.39227[0m[0m | time: 14.972s
[2K
| Adam | epoch: 013 | loss: 0.39227 - acc: 0.8364 -- iter: 0416/1094
[A[ATraining Step: 434  | total loss: [1m[32m0.37588[0m[0m | time: 16.412s
[2K
| Adam | epoch: 013 | loss: 0.37588 - acc: 0.8465 -- iter: 0448/1094
[A[ATraining Step: 435  | total loss: [1m[32m0.36875[0m[0m | time: 17.640s
[2K
| Adam | epoch: 013 | loss: 0.36875 - acc: 0.8525 -- iter: 0480/1094
[A[ATraining Step: 436  | total loss: [1m[32m0.38732[0m[0m | time: 18.969s
[2K
| Adam | epoch: 013 | loss: 0.38732 - acc: 0.8391 -- iter: 0512/1094
[A[ATraining Step: 437  | total loss: [1m[32m0.37152[0m[0m | time: 20.718s
[2K
| Adam | epoch: 013 | loss: 0.37152 - acc: 0.8521 -- iter: 0544/1094
[A[ATraining Step: 438  | total loss: [1m[32m0.35200[0m[0m | time: 22.905s
[2K
| Adam | epoch: 013 | loss: 0.35200 - acc: 0.8669 -- iter: 0576/1094
[A[ATraining Step: 439  | total loss: [1m[32m0.34418[0m[0m | time: 24.601s
[2K
| Adam | epoch: 013 | loss: 0.34418 - acc: 0.8770 -- iter: 0608/1094
[A[ATraining Step: 440  | total loss: [1m[32m0.34038[0m[0m | time: 26.015s
[2K
| Adam | epoch: 013 | loss: 0.34038 - acc: 0.8706 -- iter: 0640/1094
[A[ATraining Step: 441  | total loss: [1m[32m0.32525[0m[0m | time: 27.650s
[2K
| Adam | epoch: 013 | loss: 0.32525 - acc: 0.8773 -- iter: 0672/1094
[A[ATraining Step: 442  | total loss: [1m[32m0.32671[0m[0m | time: 29.315s
[2K
| Adam | epoch: 013 | loss: 0.32671 - acc: 0.8771 -- iter: 0704/1094
[A[ATraining Step: 443  | total loss: [1m[32m0.32540[0m[0m | time: 31.078s
[2K
| Adam | epoch: 013 | loss: 0.32540 - acc: 0.8737 -- iter: 0736/1094
[A[ATraining Step: 444  | total loss: [1m[32m0.33297[0m[0m | time: 32.525s
[2K
| Adam | epoch: 013 | loss: 0.33297 - acc: 0.8676 -- iter: 0768/1094
[A[ATraining Step: 445  | total loss: [1m[32m0.35124[0m[0m | time: 34.033s
[2K
| Adam | epoch: 013 | loss: 0.35124 - acc: 0.8590 -- iter: 0800/1094
[A[ATraining Step: 446  | total loss: [1m[32m0.33809[0m[0m | time: 35.839s
[2K
| Adam | epoch: 013 | loss: 0.33809 - acc: 0.8637 -- iter: 0832/1094
[A[ATraining Step: 447  | total loss: [1m[32m0.34698[0m[0m | time: 37.811s
[2K
| Adam | epoch: 013 | loss: 0.34698 - acc: 0.8586 -- iter: 0864/1094
[A[ATraining Step: 448  | total loss: [1m[32m0.37185[0m[0m | time: 39.710s
[2K
| Adam | epoch: 013 | loss: 0.37185 - acc: 0.8508 -- iter: 0896/1094
[A[ATraining Step: 449  | total loss: [1m[32m0.36592[0m[0m | time: 41.438s
[2K
| Adam | epoch: 013 | loss: 0.36592 - acc: 0.8533 -- iter: 0928/1094
[A[ATraining Step: 450  | total loss: [1m[32m0.34533[0m[0m | time: 43.236s
[2K
| Adam | epoch: 013 | loss: 0.34533 - acc: 0.8648 -- iter: 0960/1094
[A[ATraining Step: 451  | total loss: [1m[32m0.33422[0m[0m | time: 45.023s
[2K
| Adam | epoch: 013 | loss: 0.33422 - acc: 0.8721 -- iter: 0992/1094
[A[ATraining Step: 452  | total loss: [1m[32m0.33813[0m[0m | time: 48.253s
[2K
| Adam | epoch: 013 | loss: 0.33813 - acc: 0.8661 -- iter: 1024/1094
[A[ATraining Step: 453  | total loss: [1m[32m0.34211[0m[0m | time: 56.458s
[2K
| Adam | epoch: 013 | loss: 0.34211 - acc: 0.8608 -- iter: 1056/1094
[A[ATraining Step: 454  | total loss: [1m[32m0.33825[0m[0m | time: 63.327s
[2K
| Adam | epoch: 013 | loss: 0.33825 - acc: 0.8591 -- iter: 1088/1094
[A[ATraining Step: 455  | total loss: [1m[32m0.33345[0m[0m | time: 142.624s
[2K
| Adam | epoch: 013 | loss: 0.33345 - acc: 0.8638 | val_loss: 0.44583 - val_acc: 0.8105 -- iter: 1094/1094
--
Training Step: 456  | total loss: [1m[32m0.33317[0m[0m | time: 1.728s
[2K
| Adam | epoch: 014 | loss: 0.33317 - acc: 0.8618 -- iter: 0032/1094
[A[ATraining Step: 457  | total loss: [1m[32m0.31340[0m[0m | time: 3.413s
[2K
| Adam | epoch: 014 | loss: 0.31340 - acc: 0.8756 -- iter: 0064/1094
[A[ATraining Step: 458  | total loss: [1m[32m0.30197[0m[0m | time: 5.190s
[2K
| Adam | epoch: 014 | loss: 0.30197 - acc: 0.8849 -- iter: 0096/1094
[A[ATraining Step: 459  | total loss: [1m[32m0.30632[0m[0m | time: 7.072s
[2K
| Adam | epoch: 014 | loss: 0.30632 - acc: 0.8839 -- iter: 0128/1094
[A[ATraining Step: 460  | total loss: [1m[32m0.30971[0m[0m | time: 8.532s
[2K
| Adam | epoch: 014 | loss: 0.30971 - acc: 0.8737 -- iter: 0160/1094
[A[ATraining Step: 461  | total loss: [1m[32m0.29674[0m[0m | time: 9.990s
[2K
| Adam | epoch: 014 | loss: 0.29674 - acc: 0.8800 -- iter: 0192/1094
[A[ATraining Step: 462  | total loss: [1m[32m0.30634[0m[0m | time: 11.390s
[2K
| Adam | epoch: 014 | loss: 0.30634 - acc: 0.8795 -- iter: 0224/1094
[A[ATraining Step: 463  | total loss: [1m[32m0.31120[0m[0m | time: 12.649s
[2K
| Adam | epoch: 014 | loss: 0.31120 - acc: 0.8728 -- iter: 0256/1094
[A[ATraining Step: 464  | total loss: [1m[32m0.32191[0m[0m | time: 13.980s
[2K
| Adam | epoch: 014 | loss: 0.32191 - acc: 0.8699 -- iter: 0288/1094
[A[ATraining Step: 465  | total loss: [1m[32m0.30900[0m[0m | time: 15.593s
[2K
| Adam | epoch: 014 | loss: 0.30900 - acc: 0.8767 -- iter: 0320/1094
[A[ATraining Step: 466  | total loss: [1m[32m0.31049[0m[0m | time: 16.851s
[2K
| Adam | epoch: 014 | loss: 0.31049 - acc: 0.8765 -- iter: 0352/1094
[A[ATraining Step: 467  | total loss: [1m[32m0.32647[0m[0m | time: 17.154s
[2K
| Adam | epoch: 014 | loss: 0.32647 - acc: 0.8701 -- iter: 0384/1094
[A[ATraining Step: 468  | total loss: [1m[32m0.36238[0m[0m | time: 17.410s
[2K
| Adam | epoch: 014 | loss: 0.36238 - acc: 0.8664 -- iter: 0416/1094
[A[ATraining Step: 469  | total loss: [1m[32m0.38767[0m[0m | time: 18.447s
[2K
| Adam | epoch: 014 | loss: 0.38767 - acc: 0.8631 -- iter: 0448/1094
[A[ATraining Step: 470  | total loss: [1m[32m0.38140[0m[0m | time: 19.613s
[2K
| Adam | epoch: 014 | loss: 0.38140 - acc: 0.8643 -- iter: 0480/1094
[A[ATraining Step: 471  | total loss: [1m[32m0.36628[0m[0m | time: 20.944s
[2K
| Adam | epoch: 014 | loss: 0.36628 - acc: 0.8716 -- iter: 0512/1094
[A[ATraining Step: 472  | total loss: [1m[32m0.36285[0m[0m | time: 22.279s
[2K
| Adam | epoch: 014 | loss: 0.36285 - acc: 0.8720 -- iter: 0544/1094
[A[ATraining Step: 473  | total loss: [1m[32m0.35437[0m[0m | time: 23.707s
[2K
| Adam | epoch: 014 | loss: 0.35437 - acc: 0.8723 -- iter: 0576/1094
[A[ATraining Step: 474  | total loss: [1m[32m0.35099[0m[0m | time: 25.037s
[2K
| Adam | epoch: 014 | loss: 0.35099 - acc: 0.8694 -- iter: 0608/1094
[A[ATraining Step: 475  | total loss: [1m[32m0.33537[0m[0m | time: 26.410s
[2K
| Adam | epoch: 014 | loss: 0.33537 - acc: 0.8794 -- iter: 0640/1094
[A[ATraining Step: 476  | total loss: [1m[32m0.32790[0m[0m | time: 27.857s
[2K
| Adam | epoch: 014 | loss: 0.32790 - acc: 0.8820 -- iter: 0672/1094
[A[ATraining Step: 477  | total loss: [1m[32m0.32579[0m[0m | time: 29.005s
[2K
| Adam | epoch: 014 | loss: 0.32579 - acc: 0.8876 -- iter: 0704/1094
[A[ATraining Step: 478  | total loss: [1m[32m0.32209[0m[0m | time: 30.213s
[2K
| Adam | epoch: 014 | loss: 0.32209 - acc: 0.8926 -- iter: 0736/1094
[A[ATraining Step: 479  | total loss: [1m[32m0.32354[0m[0m | time: 31.539s
[2K
| Adam | epoch: 014 | loss: 0.32354 - acc: 0.8877 -- iter: 0768/1094
[A[ATraining Step: 480  | total loss: [1m[32m0.33342[0m[0m | time: 33.056s
[2K
| Adam | epoch: 014 | loss: 0.33342 - acc: 0.8802 -- iter: 0800/1094
[A[ATraining Step: 481  | total loss: [1m[32m0.32505[0m[0m | time: 34.543s
[2K
| Adam | epoch: 014 | loss: 0.32505 - acc: 0.8828 -- iter: 0832/1094
[A[ATraining Step: 482  | total loss: [1m[32m0.31018[0m[0m | time: 36.146s
[2K
| Adam | epoch: 014 | loss: 0.31018 - acc: 0.8883 -- iter: 0864/1094
[A[ATraining Step: 483  | total loss: [1m[32m0.30736[0m[0m | time: 37.561s
[2K
| Adam | epoch: 014 | loss: 0.30736 - acc: 0.8869 -- iter: 0896/1094
[A[ATraining Step: 484  | total loss: [1m[32m0.28860[0m[0m | time: 39.231s
[2K
| Adam | epoch: 014 | loss: 0.28860 - acc: 0.8982 -- iter: 0928/1094
[A[ATraining Step: 485  | total loss: [1m[32m0.29350[0m[0m | time: 40.657s
[2K
| Adam | epoch: 014 | loss: 0.29350 - acc: 0.8959 -- iter: 0960/1094
[A[ATraining Step: 486  | total loss: [1m[32m0.27411[0m[0m | time: 42.585s
[2K
| Adam | epoch: 014 | loss: 0.27411 - acc: 0.9063 -- iter: 0992/1094
[A[ATraining Step: 487  | total loss: [1m[32m0.26527[0m[0m | time: 44.609s
[2K
| Adam | epoch: 014 | loss: 0.26527 - acc: 0.9063 -- iter: 1024/1094
[A[ATraining Step: 488  | total loss: [1m[32m0.26020[0m[0m | time: 46.091s
[2K
| Adam | epoch: 014 | loss: 0.26020 - acc: 0.9126 -- iter: 1056/1094
[A[ATraining Step: 489  | total loss: [1m[32m0.25365[0m[0m | time: 47.859s
[2K
| Adam | epoch: 014 | loss: 0.25365 - acc: 0.9182 -- iter: 1088/1094
[A[ATraining Step: 490  | total loss: [1m[32m0.24142[0m[0m | time: 53.033s
[2K
| Adam | epoch: 014 | loss: 0.24142 - acc: 0.9201 | val_loss: 0.44722 - val_acc: 0.8251 -- iter: 1094/1094
--
Training Step: 491  | total loss: [1m[32m0.22731[0m[0m | time: 1.517s
[2K
| Adam | epoch: 015 | loss: 0.22731 - acc: 0.9250 -- iter: 0032/1094
[A[ATraining Step: 492  | total loss: [1m[32m0.22432[0m[0m | time: 3.124s
[2K
| Adam | epoch: 015 | loss: 0.22432 - acc: 0.9262 -- iter: 0064/1094
[A[ATraining Step: 493  | total loss: [1m[32m0.24288[0m[0m | time: 4.605s
[2K
| Adam | epoch: 015 | loss: 0.24288 - acc: 0.9180 -- iter: 0096/1094
[A[ATraining Step: 494  | total loss: [1m[32m0.22514[0m[0m | time: 6.003s
[2K
| Adam | epoch: 015 | loss: 0.22514 - acc: 0.9262 -- iter: 0128/1094
[A[ATraining Step: 495  | total loss: [1m[32m0.21890[0m[0m | time: 7.601s
[2K
| Adam | epoch: 015 | loss: 0.21890 - acc: 0.9242 -- iter: 0160/1094
[A[ATraining Step: 496  | total loss: [1m[32m0.21322[0m[0m | time: 9.494s
[2K
| Adam | epoch: 015 | loss: 0.21322 - acc: 0.9255 -- iter: 0192/1094
[A[ATraining Step: 497  | total loss: [1m[32m0.20906[0m[0m | time: 11.404s
[2K
| Adam | epoch: 015 | loss: 0.20906 - acc: 0.9205 -- iter: 0224/1094
[A[ATraining Step: 498  | total loss: [1m[32m0.20485[0m[0m | time: 12.885s
[2K
| Adam | epoch: 015 | loss: 0.20485 - acc: 0.9190 -- iter: 0256/1094
[A[ATraining Step: 499  | total loss: [1m[32m0.19531[0m[0m | time: 14.654s
[2K
| Adam | epoch: 015 | loss: 0.19531 - acc: 0.9209 -- iter: 0288/1094
[A[ATraining Step: 500  | total loss: [1m[32m0.18456[0m[0m | time: 16.364s
[2K
| Adam | epoch: 015 | loss: 0.18456 - acc: 0.9288 -- iter: 0320/1094
[A[ATraining Step: 501  | total loss: [1m[32m0.18828[0m[0m | time: 17.998s
[2K
| Adam | epoch: 015 | loss: 0.18828 - acc: 0.9265 -- iter: 0352/1094
[A[ATraining Step: 502  | total loss: [1m[32m0.18782[0m[0m | time: 19.855s
[2K
| Adam | epoch: 015 | loss: 0.18782 - acc: 0.9245 -- iter: 0384/1094
[A[ATraining Step: 503  | total loss: [1m[32m0.19162[0m[0m | time: 20.261s
[2K
| Adam | epoch: 015 | loss: 0.19162 - acc: 0.9227 -- iter: 0416/1094
[A[ATraining Step: 504  | total loss: [1m[32m0.17374[0m[0m | time: 20.703s
[2K
| Adam | epoch: 015 | loss: 0.17374 - acc: 0.9304 -- iter: 0448/1094
[A[ATraining Step: 505  | total loss: [1m[32m0.15722[0m[0m | time: 22.464s
[2K
| Adam | epoch: 015 | loss: 0.15722 - acc: 0.9374 -- iter: 0480/1094
[A[ATraining Step: 506  | total loss: [1m[32m0.17304[0m[0m | time: 24.053s
[2K
| Adam | epoch: 015 | loss: 0.17304 - acc: 0.9343 -- iter: 0512/1094
[A[ATraining Step: 507  | total loss: [1m[32m0.17011[0m[0m | time: 25.433s
[2K
| Adam | epoch: 015 | loss: 0.17011 - acc: 0.9346 -- iter: 0544/1094
[A[ATraining Step: 508  | total loss: [1m[32m0.16360[0m[0m | time: 27.087s
[2K
| Adam | epoch: 015 | loss: 0.16360 - acc: 0.9349 -- iter: 0576/1094
[A[ATraining Step: 509  | total loss: [1m[32m0.15132[0m[0m | time: 28.851s
[2K
| Adam | epoch: 015 | loss: 0.15132 - acc: 0.9414 -- iter: 0608/1094
[A[ATraining Step: 510  | total loss: [1m[32m0.14489[0m[0m | time: 30.668s
[2K
| Adam | epoch: 015 | loss: 0.14489 - acc: 0.9410 -- iter: 0640/1094
[A[ATraining Step: 511  | total loss: [1m[32m0.14259[0m[0m | time: 32.309s
[2K
| Adam | epoch: 015 | loss: 0.14259 - acc: 0.9438 -- iter: 0672/1094
[A[ATraining Step: 512  | total loss: [1m[32m0.13432[0m[0m | time: 34.205s
[2K
| Adam | epoch: 015 | loss: 0.13432 - acc: 0.9494 -- iter: 0704/1094
[A[ATraining Step: 513  | total loss: [1m[32m0.14498[0m[0m | time: 35.495s
[2K
| Adam | epoch: 015 | loss: 0.14498 - acc: 0.9451 -- iter: 0736/1094
[A[ATraining Step: 514  | total loss: [1m[32m0.13917[0m[0m | time: 37.001s
[2K
| Adam | epoch: 015 | loss: 0.13917 - acc: 0.9506 -- iter: 0768/1094
[A[ATraining Step: 515  | total loss: [1m[32m0.14282[0m[0m | time: 38.654s
[2K
| Adam | epoch: 015 | loss: 0.14282 - acc: 0.9461 -- iter: 0800/1094
[A[ATraining Step: 516  | total loss: [1m[32m0.14352[0m[0m | time: 40.289s
[2K
| Adam | epoch: 015 | loss: 0.14352 - acc: 0.9484 -- iter: 0832/1094
[A[ATraining Step: 517  | total loss: [1m[32m0.14523[0m[0m | time: 41.971s
[2K
| Adam | epoch: 015 | loss: 0.14523 - acc: 0.9442 -- iter: 0864/1094
[A[ATraining Step: 518  | total loss: [1m[32m0.14843[0m[0m | time: 43.840s
[2K
| Adam | epoch: 015 | loss: 0.14843 - acc: 0.9435 -- iter: 0896/1094
[A[ATraining Step: 519  | total loss: [1m[32m0.15591[0m[0m | time: 45.601s
[2K
| Adam | epoch: 015 | loss: 0.15591 - acc: 0.9398 -- iter: 0928/1094
[A[ATraining Step: 520  | total loss: [1m[32m0.15187[0m[0m | time: 47.020s
[2K
| Adam | epoch: 015 | loss: 0.15187 - acc: 0.9427 -- iter: 0960/1094
[A[ATraining Step: 521  | total loss: [1m[32m0.14387[0m[0m | time: 48.457s
[2K
| Adam | epoch: 015 | loss: 0.14387 - acc: 0.9453 -- iter: 0992/1094
[A[ATraining Step: 522  | total loss: [1m[32m0.14000[0m[0m | time: 50.192s
[2K
| Adam | epoch: 015 | loss: 0.14000 - acc: 0.9476 -- iter: 1024/1094
[A[ATraining Step: 523  | total loss: [1m[32m0.14339[0m[0m | time: 51.969s
[2K
| Adam | epoch: 015 | loss: 0.14339 - acc: 0.9498 -- iter: 1056/1094
[A[ATraining Step: 524  | total loss: [1m[32m0.13977[0m[0m | time: 53.730s
[2K
| Adam | epoch: 015 | loss: 0.13977 - acc: 0.9517 -- iter: 1088/1094
[A[ATraining Step: 525  | total loss: [1m[32m0.12927[0m[0m | time: 59.378s
[2K
| Adam | epoch: 015 | loss: 0.12927 - acc: 0.9565 | val_loss: 0.56861 - val_acc: 0.8134 -- iter: 1094/1094
--
Training Step: 526  | total loss: [1m[32m0.13270[0m[0m | time: 1.641s
[2K
| Adam | epoch: 016 | loss: 0.13270 - acc: 0.9546 -- iter: 0032/1094
[A[ATraining Step: 527  | total loss: [1m[32m0.13133[0m[0m | time: 3.155s
[2K
| Adam | epoch: 016 | loss: 0.13133 - acc: 0.9560 -- iter: 0064/1094
[A[ATraining Step: 528  | total loss: [1m[32m0.13217[0m[0m | time: 4.954s
[2K
| Adam | epoch: 016 | loss: 0.13217 - acc: 0.9573 -- iter: 0096/1094
[A[ATraining Step: 529  | total loss: [1m[32m0.14860[0m[0m | time: 6.866s
[2K
| Adam | epoch: 016 | loss: 0.14860 - acc: 0.9522 -- iter: 0128/1094
[A[ATraining Step: 530  | total loss: [1m[32m0.15837[0m[0m | time: 8.108s
[2K
| Adam | epoch: 016 | loss: 0.15837 - acc: 0.9507 -- iter: 0160/1094
[A[ATraining Step: 531  | total loss: [1m[32m0.14976[0m[0m | time: 9.574s
[2K
| Adam | epoch: 016 | loss: 0.14976 - acc: 0.9556 -- iter: 0192/1094
[A[ATraining Step: 532  | total loss: [1m[32m0.15053[0m[0m | time: 11.424s
[2K
| Adam | epoch: 016 | loss: 0.15053 - acc: 0.9569 -- iter: 0224/1094
[A[ATraining Step: 533  | total loss: [1m[32m0.15034[0m[0m | time: 13.151s
[2K
| Adam | epoch: 016 | loss: 0.15034 - acc: 0.9550 -- iter: 0256/1094
[A[ATraining Step: 534  | total loss: [1m[32m0.14197[0m[0m | time: 15.040s
[2K
| Adam | epoch: 016 | loss: 0.14197 - acc: 0.9595 -- iter: 0288/1094
[A[ATraining Step: 535  | total loss: [1m[32m0.14361[0m[0m | time: 19.588s
[2K
| Adam | epoch: 016 | loss: 0.14361 - acc: 0.9511 -- iter: 0320/1094
[A[ATraining Step: 536  | total loss: [1m[32m0.16892[0m[0m | time: 21.382s
[2K
| Adam | epoch: 016 | loss: 0.16892 - acc: 0.9466 -- iter: 0352/1094
[A[ATraining Step: 537  | total loss: [1m[32m0.16808[0m[0m | time: 23.052s
[2K
| Adam | epoch: 016 | loss: 0.16808 - acc: 0.9488 -- iter: 0384/1094
[A[ATraining Step: 538  | total loss: [1m[32m0.18016[0m[0m | time: 24.484s
[2K
| Adam | epoch: 016 | loss: 0.18016 - acc: 0.9383 -- iter: 0416/1094
[A[ATraining Step: 539  | total loss: [1m[32m0.17073[0m[0m | time: 24.979s
[2K
| Adam | epoch: 016 | loss: 0.17073 - acc: 0.9445 -- iter: 0448/1094
[A[ATraining Step: 540  | total loss: [1m[32m0.15662[0m[0m | time: 25.463s
[2K
| Adam | epoch: 016 | loss: 0.15662 - acc: 0.9500 -- iter: 0480/1094
[A[ATraining Step: 541  | total loss: [1m[32m0.14474[0m[0m | time: 27.153s
[2K
| Adam | epoch: 016 | loss: 0.14474 - acc: 0.9550 -- iter: 0512/1094
[A[ATraining Step: 542  | total loss: [1m[32m0.14659[0m[0m | time: 28.793s
[2K
| Adam | epoch: 016 | loss: 0.14659 - acc: 0.9533 -- iter: 0544/1094
[A[ATraining Step: 543  | total loss: [1m[32m0.14125[0m[0m | time: 30.041s
[2K
| Adam | epoch: 016 | loss: 0.14125 - acc: 0.9548 -- iter: 0576/1094
[A[ATraining Step: 544  | total loss: [1m[32m0.14866[0m[0m | time: 31.646s
[2K
| Adam | epoch: 016 | loss: 0.14866 - acc: 0.9500 -- iter: 0608/1094
[A[ATraining Step: 545  | total loss: [1m[32m0.14347[0m[0m | time: 33.453s
[2K
| Adam | epoch: 016 | loss: 0.14347 - acc: 0.9518 -- iter: 0640/1094
[A[ATraining Step: 546  | total loss: [1m[32m0.13634[0m[0m | time: 35.414s
[2K
| Adam | epoch: 016 | loss: 0.13634 - acc: 0.9504 -- iter: 0672/1094
[A[ATraining Step: 547  | total loss: [1m[32m0.12657[0m[0m | time: 37.515s
[2K
| Adam | epoch: 016 | loss: 0.12657 - acc: 0.9554 -- iter: 0704/1094
[A[ATraining Step: 548  | total loss: [1m[32m0.12086[0m[0m | time: 39.278s
[2K
| Adam | epoch: 016 | loss: 0.12086 - acc: 0.9567 -- iter: 0736/1094
[A[ATraining Step: 549  | total loss: [1m[32m0.11131[0m[0m | time: 40.825s
[2K
| Adam | epoch: 016 | loss: 0.11131 - acc: 0.9610 -- iter: 0768/1094
[A[ATraining Step: 550  | total loss: [1m[32m0.11102[0m[0m | time: 42.438s
[2K
| Adam | epoch: 016 | loss: 0.11102 - acc: 0.9587 -- iter: 0800/1094
[A[ATraining Step: 551  | total loss: [1m[32m0.10690[0m[0m | time: 44.054s
[2K
| Adam | epoch: 016 | loss: 0.10690 - acc: 0.9597 -- iter: 0832/1094
[A[ATraining Step: 552  | total loss: [1m[32m0.09949[0m[0m | time: 45.418s
[2K
| Adam | epoch: 016 | loss: 0.09949 - acc: 0.9637 -- iter: 0864/1094
[A[ATraining Step: 553  | total loss: [1m[32m0.09731[0m[0m | time: 47.160s
[2K
| Adam | epoch: 016 | loss: 0.09731 - acc: 0.9611 -- iter: 0896/1094
[A[ATraining Step: 554  | total loss: [1m[32m0.09968[0m[0m | time: 48.893s
[2K
| Adam | epoch: 016 | loss: 0.09968 - acc: 0.9587 -- iter: 0928/1094
[A[ATraining Step: 555  | total loss: [1m[32m0.10251[0m[0m | time: 50.590s
[2K
| Adam | epoch: 016 | loss: 0.10251 - acc: 0.9597 -- iter: 0960/1094
[A[ATraining Step: 556  | total loss: [1m[32m0.09431[0m[0m | time: 51.800s
[2K
| Adam | epoch: 016 | loss: 0.09431 - acc: 0.9638 -- iter: 0992/1094
[A[ATraining Step: 557  | total loss: [1m[32m0.09308[0m[0m | time: 53.341s
[2K
| Adam | epoch: 016 | loss: 0.09308 - acc: 0.9611 -- iter: 1024/1094
[A[ATraining Step: 558  | total loss: [1m[32m0.08801[0m[0m | time: 55.004s
[2K
| Adam | epoch: 016 | loss: 0.08801 - acc: 0.9650 -- iter: 1056/1094
[A[ATraining Step: 559  | total loss: [1m[32m0.08786[0m[0m | time: 56.842s
[2K
| Adam | epoch: 016 | loss: 0.08786 - acc: 0.9654 -- iter: 1088/1094
[A[ATraining Step: 560  | total loss: [1m[32m0.08280[0m[0m | time: 65.979s
[2K
| Adam | epoch: 016 | loss: 0.08280 - acc: 0.9689 | val_loss: 0.60063 - val_acc: 0.8047 -- iter: 1094/1094
--
Training Step: 561  | total loss: [1m[32m0.09412[0m[0m | time: 1.377s
[2K
| Adam | epoch: 017 | loss: 0.09412 - acc: 0.9688 -- iter: 0032/1094
[A[ATraining Step: 562  | total loss: [1m[32m0.09984[0m[0m | time: 2.866s
[2K
| Adam | epoch: 017 | loss: 0.09984 - acc: 0.9626 -- iter: 0064/1094
[A[ATraining Step: 563  | total loss: [1m[32m0.11127[0m[0m | time: 4.462s
[2K
| Adam | epoch: 017 | loss: 0.11127 - acc: 0.9601 -- iter: 0096/1094
[A[ATraining Step: 564  | total loss: [1m[32m0.11058[0m[0m | time: 5.871s
[2K
| Adam | epoch: 017 | loss: 0.11058 - acc: 0.9578 -- iter: 0128/1094
[A[ATraining Step: 565  | total loss: [1m[32m0.11582[0m[0m | time: 7.482s
[2K
| Adam | epoch: 017 | loss: 0.11582 - acc: 0.9589 -- iter: 0160/1094
[A[ATraining Step: 566  | total loss: [1m[32m0.11544[0m[0m | time: 8.899s
[2K
| Adam | epoch: 017 | loss: 0.11544 - acc: 0.9599 -- iter: 0192/1094
[A[ATraining Step: 567  | total loss: [1m[32m0.10914[0m[0m | time: 10.441s
[2K
| Adam | epoch: 017 | loss: 0.10914 - acc: 0.9608 -- iter: 0224/1094
[A[ATraining Step: 568  | total loss: [1m[32m0.10368[0m[0m | time: 12.127s
[2K
| Adam | epoch: 017 | loss: 0.10368 - acc: 0.9616 -- iter: 0256/1094
[A[ATraining Step: 569  | total loss: [1m[32m0.10137[0m[0m | time: 13.925s
[2K
| Adam | epoch: 017 | loss: 0.10137 - acc: 0.9654 -- iter: 0288/1094
[A[ATraining Step: 570  | total loss: [1m[32m0.11656[0m[0m | time: 15.820s
[2K
| Adam | epoch: 017 | loss: 0.11656 - acc: 0.9564 -- iter: 0320/1094
[A[ATraining Step: 571  | total loss: [1m[32m0.10595[0m[0m | time: 17.511s
[2K
| Adam | epoch: 017 | loss: 0.10595 - acc: 0.9607 -- iter: 0352/1094
[A[ATraining Step: 572  | total loss: [1m[32m0.10316[0m[0m | time: 18.898s
[2K
| Adam | epoch: 017 | loss: 0.10316 - acc: 0.9615 -- iter: 0384/1094
[A[ATraining Step: 573  | total loss: [1m[32m0.09947[0m[0m | time: 20.295s
[2K
| Adam | epoch: 017 | loss: 0.09947 - acc: 0.9654 -- iter: 0416/1094
[A[ATraining Step: 574  | total loss: [1m[32m0.10703[0m[0m | time: 21.867s
[2K
| Adam | epoch: 017 | loss: 0.10703 - acc: 0.9626 -- iter: 0448/1094
[A[ATraining Step: 575  | total loss: [1m[32m0.14762[0m[0m | time: 22.269s
[2K
| Adam | epoch: 017 | loss: 0.14762 - acc: 0.9507 -- iter: 0480/1094
[A[ATraining Step: 576  | total loss: [1m[32m0.14161[0m[0m | time: 22.700s
[2K
| Adam | epoch: 017 | loss: 0.14161 - acc: 0.9556 -- iter: 0512/1094
[A[ATraining Step: 577  | total loss: [1m[32m0.12821[0m[0m | time: 24.519s
[2K
| Adam | epoch: 017 | loss: 0.12821 - acc: 0.9601 -- iter: 0544/1094
[A[ATraining Step: 578  | total loss: [1m[32m0.15485[0m[0m | time: 26.005s
[2K
| Adam | epoch: 017 | loss: 0.15485 - acc: 0.9484 -- iter: 0576/1094
[A[ATraining Step: 579  | total loss: [1m[32m0.15899[0m[0m | time: 27.533s
[2K
| Adam | epoch: 017 | loss: 0.15899 - acc: 0.9411 -- iter: 0608/1094
[A[ATraining Step: 580  | total loss: [1m[32m0.18506[0m[0m | time: 29.259s
[2K
| Adam | epoch: 017 | loss: 0.18506 - acc: 0.9345 -- iter: 0640/1094
[A[ATraining Step: 581  | total loss: [1m[32m0.17703[0m[0m | time: 31.026s
[2K
| Adam | epoch: 017 | loss: 0.17703 - acc: 0.9379 -- iter: 0672/1094
[A[ATraining Step: 582  | total loss: [1m[32m0.16453[0m[0m | time: 32.623s
[2K
| Adam | epoch: 017 | loss: 0.16453 - acc: 0.9441 -- iter: 0704/1094
[A[ATraining Step: 583  | total loss: [1m[32m0.15462[0m[0m | time: 34.263s
[2K
| Adam | epoch: 017 | loss: 0.15462 - acc: 0.9466 -- iter: 0736/1094
[A[ATraining Step: 584  | total loss: [1m[32m0.19510[0m[0m | time: 35.831s
[2K
| Adam | epoch: 017 | loss: 0.19510 - acc: 0.9269 -- iter: 0768/1094
[A[ATraining Step: 585  | total loss: [1m[32m0.23391[0m[0m | time: 37.568s
[2K
| Adam | epoch: 017 | loss: 0.23391 - acc: 0.9092 -- iter: 0800/1094
[A[ATraining Step: 586  | total loss: [1m[32m0.25683[0m[0m | time: 38.904s
[2K
| Adam | epoch: 017 | loss: 0.25683 - acc: 0.8964 -- iter: 0832/1094
[A[ATraining Step: 587  | total loss: [1m[32m0.24153[0m[0m | time: 40.590s
[2K
| Adam | epoch: 017 | loss: 0.24153 - acc: 0.9037 -- iter: 0864/1094
[A[ATraining Step: 588  | total loss: [1m[32m0.22524[0m[0m | time: 42.092s
[2K
| Adam | epoch: 017 | loss: 0.22524 - acc: 0.9102 -- iter: 0896/1094
[A[ATraining Step: 589  | total loss: [1m[32m0.20940[0m[0m | time: 43.805s
[2K
| Adam | epoch: 017 | loss: 0.20940 - acc: 0.9160 -- iter: 0928/1094
[A[ATraining Step: 590  | total loss: [1m[32m0.20591[0m[0m | time: 45.657s
[2K
| Adam | epoch: 017 | loss: 0.20591 - acc: 0.9182 -- iter: 0960/1094
[A[ATraining Step: 591  | total loss: [1m[32m0.19424[0m[0m | time: 47.124s
[2K
| Adam | epoch: 017 | loss: 0.19424 - acc: 0.9232 -- iter: 0992/1094
[A[ATraining Step: 592  | total loss: [1m[32m0.17921[0m[0m | time: 48.849s
[2K
| Adam | epoch: 017 | loss: 0.17921 - acc: 0.9309 -- iter: 1024/1094
[A[ATraining Step: 593  | total loss: [1m[32m0.16606[0m[0m | time: 50.476s
[2K
| Adam | epoch: 017 | loss: 0.16606 - acc: 0.9378 -- iter: 1056/1094
[A[ATraining Step: 594  | total loss: [1m[32m0.15668[0m[0m | time: 52.082s
[2K
| Adam | epoch: 017 | loss: 0.15668 - acc: 0.9440 -- iter: 1088/1094
[A[ATraining Step: 595  | total loss: [1m[32m0.15177[0m[0m | time: 62.216s
[2K
| Adam | epoch: 017 | loss: 0.15177 - acc: 0.9465 | val_loss: 0.58136 - val_acc: 0.8134 -- iter: 1094/1094
--
Training Step: 596  | total loss: [1m[32m0.13977[0m[0m | time: 1.302s
[2K
| Adam | epoch: 018 | loss: 0.13977 - acc: 0.9519 -- iter: 0032/1094
[A[ATraining Step: 597  | total loss: [1m[32m0.13628[0m[0m | time: 3.106s
[2K
| Adam | epoch: 018 | loss: 0.13628 - acc: 0.9535 -- iter: 0064/1094
[A[ATraining Step: 598  | total loss: [1m[32m0.13232[0m[0m | time: 4.780s
[2K
| Adam | epoch: 018 | loss: 0.13232 - acc: 0.9551 -- iter: 0096/1094
[A[ATraining Step: 599  | total loss: [1m[32m0.12104[0m[0m | time: 6.383s
[2K
| Adam | epoch: 018 | loss: 0.12104 - acc: 0.9596 -- iter: 0128/1094
[A[ATraining Step: 600  | total loss: [1m[32m0.11594[0m[0m | time: 11.779s
[2K
| Adam | epoch: 018 | loss: 0.11594 - acc: 0.9605 | val_loss: 0.55083 - val_acc: 0.8251 -- iter: 0160/1094
--
Training Step: 601  | total loss: [1m[32m0.11136[0m[0m | time: 13.505s
[2K
| Adam | epoch: 018 | loss: 0.11136 - acc: 0.9613 -- iter: 0192/1094
[A[ATraining Step: 602  | total loss: [1m[32m0.11895[0m[0m | time: 15.000s
[2K
| Adam | epoch: 018 | loss: 0.11895 - acc: 0.9589 -- iter: 0224/1094
[A[ATraining Step: 603  | total loss: [1m[32m0.11263[0m[0m | time: 16.709s
[2K
| Adam | epoch: 018 | loss: 0.11263 - acc: 0.9599 -- iter: 0256/1094
[A[ATraining Step: 604  | total loss: [1m[32m0.12226[0m[0m | time: 18.651s
[2K
| Adam | epoch: 018 | loss: 0.12226 - acc: 0.9577 -- iter: 0288/1094
[A[ATraining Step: 605  | total loss: [1m[32m0.11293[0m[0m | time: 26.091s
[2K
| Adam | epoch: 018 | loss: 0.11293 - acc: 0.9619 -- iter: 0320/1094
[A[ATraining Step: 606  | total loss: [1m[32m0.10315[0m[0m | time: 31.684s
[2K
| Adam | epoch: 018 | loss: 0.10315 - acc: 0.9657 -- iter: 0352/1094
[A[ATraining Step: 607  | total loss: [1m[32m0.10105[0m[0m | time: 33.055s
[2K
| Adam | epoch: 018 | loss: 0.10105 - acc: 0.9660 -- iter: 0384/1094
[A[ATraining Step: 608  | total loss: [1m[32m0.09950[0m[0m | time: 34.637s
[2K
| Adam | epoch: 018 | loss: 0.09950 - acc: 0.9663 -- iter: 0416/1094
[A[ATraining Step: 609  | total loss: [1m[32m0.09592[0m[0m | time: 36.536s
[2K
| Adam | epoch: 018 | loss: 0.09592 - acc: 0.9697 -- iter: 0448/1094
[A[ATraining Step: 610  | total loss: [1m[32m0.09476[0m[0m | time: 38.291s
[2K
| Adam | epoch: 018 | loss: 0.09476 - acc: 0.9696 -- iter: 0480/1094
[A[ATraining Step: 611  | total loss: [1m[32m0.09594[0m[0m | time: 38.752s
[2K
| Adam | epoch: 018 | loss: 0.09594 - acc: 0.9695 -- iter: 0512/1094
[A[ATraining Step: 612  | total loss: [1m[32m0.08997[0m[0m | time: 39.168s
[2K
| Adam | epoch: 018 | loss: 0.08997 - acc: 0.9725 -- iter: 0544/1094
[A[ATraining Step: 613  | total loss: [1m[32m0.08351[0m[0m | time: 41.024s
[2K
| Adam | epoch: 018 | loss: 0.08351 - acc: 0.9753 -- iter: 0576/1094
[A[ATraining Step: 614  | total loss: [1m[32m0.09292[0m[0m | time: 42.588s
[2K
| Adam | epoch: 018 | loss: 0.09292 - acc: 0.9715 -- iter: 0608/1094
[A[ATraining Step: 615  | total loss: [1m[32m0.08762[0m[0m | time: 44.351s
[2K
| Adam | epoch: 018 | loss: 0.08762 - acc: 0.9744 -- iter: 0640/1094
[A[ATraining Step: 616  | total loss: [1m[32m0.20661[0m[0m | time: 46.154s
[2K
| Adam | epoch: 018 | loss: 0.20661 - acc: 0.9457 -- iter: 0672/1094
[A[ATraining Step: 617  | total loss: [1m[32m0.19210[0m[0m | time: 47.972s
[2K
| Adam | epoch: 018 | loss: 0.19210 - acc: 0.9480 -- iter: 0704/1094
[A[ATraining Step: 618  | total loss: [1m[32m0.18281[0m[0m | time: 49.736s
[2K
| Adam | epoch: 018 | loss: 0.18281 - acc: 0.9469 -- iter: 0736/1094
[A[ATraining Step: 619  | total loss: [1m[32m0.17306[0m[0m | time: 51.571s
[2K
| Adam | epoch: 018 | loss: 0.17306 - acc: 0.9491 -- iter: 0768/1094
[A[ATraining Step: 620  | total loss: [1m[32m0.15839[0m[0m | time: 53.423s
[2K
| Adam | epoch: 018 | loss: 0.15839 - acc: 0.9542 -- iter: 0800/1094
[A[ATraining Step: 621  | total loss: [1m[32m0.14574[0m[0m | time: 54.770s
[2K
| Adam | epoch: 018 | loss: 0.14574 - acc: 0.9588 -- iter: 0832/1094
[A[ATraining Step: 622  | total loss: [1m[32m0.13865[0m[0m | time: 56.352s
[2K
| Adam | epoch: 018 | loss: 0.13865 - acc: 0.9598 -- iter: 0864/1094
[A[ATraining Step: 623  | total loss: [1m[32m0.12917[0m[0m | time: 58.333s
[2K
| Adam | epoch: 018 | loss: 0.12917 - acc: 0.9638 -- iter: 0896/1094
[A[ATraining Step: 624  | total loss: [1m[32m0.12906[0m[0m | time: 60.004s
[2K
| Adam | epoch: 018 | loss: 0.12906 - acc: 0.9643 -- iter: 0928/1094
[A[ATraining Step: 625  | total loss: [1m[32m0.12396[0m[0m | time: 61.754s
[2K
| Adam | epoch: 018 | loss: 0.12396 - acc: 0.9647 -- iter: 0960/1094
[A[ATraining Step: 626  | total loss: [1m[32m0.12700[0m[0m | time: 63.736s
[2K
| Adam | epoch: 018 | loss: 0.12700 - acc: 0.9651 -- iter: 0992/1094
[A[ATraining Step: 627  | total loss: [1m[32m0.12121[0m[0m | time: 65.067s
[2K
| Adam | epoch: 018 | loss: 0.12121 - acc: 0.9655 -- iter: 1024/1094
[A[ATraining Step: 628  | total loss: [1m[32m0.11142[0m[0m | time: 66.395s
[2K
| Adam | epoch: 018 | loss: 0.11142 - acc: 0.9690 -- iter: 1056/1094
[A[ATraining Step: 629  | total loss: [1m[32m0.11055[0m[0m | time: 67.881s
[2K
| Adam | epoch: 018 | loss: 0.11055 - acc: 0.9658 -- iter: 1088/1094
[A[ATraining Step: 630  | total loss: [1m[32m0.11167[0m[0m | time: 71.866s
[2K
| Adam | epoch: 018 | loss: 0.11167 - acc: 0.9599 | val_loss: 0.59914 - val_acc: 0.8047 -- iter: 1094/1094
--
Training Step: 631  | total loss: [1m[32m0.10266[0m[0m | time: 1.161s
[2K
| Adam | epoch: 019 | loss: 0.10266 - acc: 0.9639 -- iter: 0032/1094
[A[ATraining Step: 632  | total loss: [1m[32m0.09520[0m[0m | time: 2.603s
[2K
| Adam | epoch: 019 | loss: 0.09520 - acc: 0.9675 -- iter: 0064/1094
[A[ATraining Step: 633  | total loss: [1m[32m0.08803[0m[0m | time: 3.874s
[2K
| Adam | epoch: 019 | loss: 0.08803 - acc: 0.9707 -- iter: 0096/1094
[A[ATraining Step: 634  | total loss: [1m[32m0.08067[0m[0m | time: 5.300s
[2K
| Adam | epoch: 019 | loss: 0.08067 - acc: 0.9737 -- iter: 0128/1094
[A[ATraining Step: 635  | total loss: [1m[32m0.07498[0m[0m | time: 6.604s
[2K
| Adam | epoch: 019 | loss: 0.07498 - acc: 0.9763 -- iter: 0160/1094
[A[ATraining Step: 636  | total loss: [1m[32m0.07102[0m[0m | time: 8.090s
[2K
| Adam | epoch: 019 | loss: 0.07102 - acc: 0.9787 -- iter: 0192/1094
[A[ATraining Step: 637  | total loss: [1m[32m0.06608[0m[0m | time: 9.478s
[2K
| Adam | epoch: 019 | loss: 0.06608 - acc: 0.9808 -- iter: 0224/1094
[A[ATraining Step: 638  | total loss: [1m[32m0.06309[0m[0m | time: 10.774s
[2K
| Adam | epoch: 019 | loss: 0.06309 - acc: 0.9827 -- iter: 0256/1094
[A[ATraining Step: 639  | total loss: [1m[32m0.06284[0m[0m | time: 11.919s
[2K
| Adam | epoch: 019 | loss: 0.06284 - acc: 0.9813 -- iter: 0288/1094
[A[ATraining Step: 640  | total loss: [1m[32m0.06154[0m[0m | time: 13.350s
[2K
| Adam | epoch: 019 | loss: 0.06154 - acc: 0.9801 -- iter: 0320/1094
[A[ATraining Step: 641  | total loss: [1m[32m0.06343[0m[0m | time: 14.679s
[2K
| Adam | epoch: 019 | loss: 0.06343 - acc: 0.9789 -- iter: 0352/1094
[A[ATraining Step: 642  | total loss: [1m[32m0.06230[0m[0m | time: 15.743s
[2K
| Adam | epoch: 019 | loss: 0.06230 - acc: 0.9779 -- iter: 0384/1094
[A[ATraining Step: 643  | total loss: [1m[32m0.08065[0m[0m | time: 17.034s
[2K
| Adam | epoch: 019 | loss: 0.08065 - acc: 0.9707 -- iter: 0416/1094
[A[ATraining Step: 644  | total loss: [1m[32m0.10198[0m[0m | time: 18.314s
[2K
| Adam | epoch: 019 | loss: 0.10198 - acc: 0.9612 -- iter: 0448/1094
[A[ATraining Step: 645  | total loss: [1m[32m0.10257[0m[0m | time: 19.828s
[2K
| Adam | epoch: 019 | loss: 0.10257 - acc: 0.9619 -- iter: 0480/1094
[A[ATraining Step: 646  | total loss: [1m[32m0.09362[0m[0m | time: 21.157s
[2K
| Adam | epoch: 019 | loss: 0.09362 - acc: 0.9657 -- iter: 0512/1094
[A[ATraining Step: 647  | total loss: [1m[32m0.09017[0m[0m | time: 21.465s
[2K
| Adam | epoch: 019 | loss: 0.09017 - acc: 0.9660 -- iter: 0544/1094
[A[ATraining Step: 648  | total loss: [1m[32m0.11215[0m[0m | time: 21.790s
[2K
| Adam | epoch: 019 | loss: 0.11215 - acc: 0.9528 -- iter: 0576/1094
[A[ATraining Step: 649  | total loss: [1m[32m0.10740[0m[0m | time: 23.100s
[2K
| Adam | epoch: 019 | loss: 0.10740 - acc: 0.9575 -- iter: 0608/1094
[A[ATraining Step: 650  | total loss: [1m[32m0.10310[0m[0m | time: 24.592s
[2K
| Adam | epoch: 019 | loss: 0.10310 - acc: 0.9586 -- iter: 0640/1094
[A[ATraining Step: 651  | total loss: [1m[32m0.11942[0m[0m | time: 26.077s
[2K
| Adam | epoch: 019 | loss: 0.11942 - acc: 0.9534 -- iter: 0672/1094
[A[ATraining Step: 652  | total loss: [1m[32m0.11476[0m[0m | time: 27.097s
[2K
| Adam | epoch: 019 | loss: 0.11476 - acc: 0.9549 -- iter: 0704/1094
[A[ATraining Step: 653  | total loss: [1m[32m0.10504[0m[0m | time: 28.406s
[2K
| Adam | epoch: 019 | loss: 0.10504 - acc: 0.9594 -- iter: 0736/1094
[A[ATraining Step: 654  | total loss: [1m[32m0.09548[0m[0m | time: 29.853s
[2K
| Adam | epoch: 019 | loss: 0.09548 - acc: 0.9635 -- iter: 0768/1094
[A[ATraining Step: 655  | total loss: [1m[32m0.10368[0m[0m | time: 31.556s
[2K
| Adam | epoch: 019 | loss: 0.10368 - acc: 0.9609 -- iter: 0800/1094
[A[ATraining Step: 656  | total loss: [1m[32m0.09411[0m[0m | time: 33.063s
[2K
| Adam | epoch: 019 | loss: 0.09411 - acc: 0.9648 -- iter: 0832/1094
[A[ATraining Step: 657  | total loss: [1m[32m0.08799[0m[0m | time: 34.654s
[2K
| Adam | epoch: 019 | loss: 0.08799 - acc: 0.9683 -- iter: 0864/1094
[A[ATraining Step: 658  | total loss: [1m[32m0.08423[0m[0m | time: 35.997s
[2K
| Adam | epoch: 019 | loss: 0.08423 - acc: 0.9684 -- iter: 0896/1094
[A[ATraining Step: 659  | total loss: [1m[32m0.07856[0m[0m | time: 37.932s
[2K
| Adam | epoch: 019 | loss: 0.07856 - acc: 0.9715 -- iter: 0928/1094
[A[ATraining Step: 660  | total loss: [1m[32m0.07195[0m[0m | time: 39.601s
[2K
| Adam | epoch: 019 | loss: 0.07195 - acc: 0.9744 -- iter: 0960/1094
[A[ATraining Step: 661  | total loss: [1m[32m0.06534[0m[0m | time: 41.350s
[2K
| Adam | epoch: 019 | loss: 0.06534 - acc: 0.9769 -- iter: 0992/1094
[A[ATraining Step: 662  | total loss: [1m[32m0.06121[0m[0m | time: 42.996s
[2K
| Adam | epoch: 019 | loss: 0.06121 - acc: 0.9792 -- iter: 1024/1094
[A[ATraining Step: 663  | total loss: [1m[32m0.05616[0m[0m | time: 44.903s
[2K
| Adam | epoch: 019 | loss: 0.05616 - acc: 0.9813 -- iter: 1056/1094
[A[ATraining Step: 664  | total loss: [1m[32m0.05659[0m[0m | time: 46.728s
[2K
| Adam | epoch: 019 | loss: 0.05659 - acc: 0.9801 -- iter: 1088/1094
[A[ATraining Step: 665  | total loss: [1m[32m0.05457[0m[0m | time: 52.348s
[2K
| Adam | epoch: 019 | loss: 0.05457 - acc: 0.9789 | val_loss: 0.86862 - val_acc: 0.7668 -- iter: 1094/1094
--
Training Step: 666  | total loss: [1m[32m0.05324[0m[0m | time: 1.776s
[2K
| Adam | epoch: 020 | loss: 0.05324 - acc: 0.9779 -- iter: 0032/1094
[A[ATraining Step: 667  | total loss: [1m[32m0.05117[0m[0m | time: 3.640s
[2K
| Adam | epoch: 020 | loss: 0.05117 - acc: 0.9801 -- iter: 0064/1094
[A[ATraining Step: 668  | total loss: [1m[32m0.05389[0m[0m | time: 5.224s
[2K
| Adam | epoch: 020 | loss: 0.05389 - acc: 0.9790 -- iter: 0096/1094
[A[ATraining Step: 669  | total loss: [1m[32m0.05406[0m[0m | time: 6.963s
[2K
| Adam | epoch: 020 | loss: 0.05406 - acc: 0.9811 -- iter: 0128/1094
[A[ATraining Step: 670  | total loss: [1m[32m0.04962[0m[0m | time: 8.815s
[2K
| Adam | epoch: 020 | loss: 0.04962 - acc: 0.9830 -- iter: 0160/1094
[A[ATraining Step: 671  | total loss: [1m[32m0.04761[0m[0m | time: 10.729s
[2K
| Adam | epoch: 020 | loss: 0.04761 - acc: 0.9847 -- iter: 0192/1094
[A[ATraining Step: 672  | total loss: [1m[32m0.04368[0m[0m | time: 11.984s
[2K
| Adam | epoch: 020 | loss: 0.04368 - acc: 0.9862 -- iter: 0224/1094
[A[ATraining Step: 673  | total loss: [1m[32m0.04183[0m[0m | time: 13.326s
[2K
| Adam | epoch: 020 | loss: 0.04183 - acc: 0.9876 -- iter: 0256/1094
[A[ATraining Step: 674  | total loss: [1m[32m0.06349[0m[0m | time: 14.695s
[2K
| Adam | epoch: 020 | loss: 0.06349 - acc: 0.9857 -- iter: 0288/1094
[A[ATraining Step: 675  | total loss: [1m[32m0.07621[0m[0m | time: 16.080s
[2K
| Adam | epoch: 020 | loss: 0.07621 - acc: 0.9778 -- iter: 0320/1094
[A[ATraining Step: 676  | total loss: [1m[32m0.08373[0m[0m | time: 17.386s
[2K
| Adam | epoch: 020 | loss: 0.08373 - acc: 0.9706 -- iter: 0352/1094
[A[ATraining Step: 677  | total loss: [1m[32m0.07563[0m[0m | time: 18.870s
[2K
| Adam | epoch: 020 | loss: 0.07563 - acc: 0.9735 -- iter: 0384/1094
[A[ATraining Step: 678  | total loss: [1m[32m0.06887[0m[0m | time: 20.286s
[2K
| Adam | epoch: 020 | loss: 0.06887 - acc: 0.9762 -- iter: 0416/1094
[A[ATraining Step: 679  | total loss: [1m[32m0.07916[0m[0m | time: 21.430s
[2K
| Adam | epoch: 020 | loss: 0.07916 - acc: 0.9692 -- iter: 0448/1094
[A[ATraining Step: 680  | total loss: [1m[32m0.09005[0m[0m | time: 22.468s
[2K
| Adam | epoch: 020 | loss: 0.09005 - acc: 0.9692 -- iter: 0480/1094
[A[ATraining Step: 681  | total loss: [1m[32m0.08376[0m[0m | time: 23.827s
[2K
| Adam | epoch: 020 | loss: 0.08376 - acc: 0.9722 -- iter: 0512/1094
[A[ATraining Step: 682  | total loss: [1m[32m0.07686[0m[0m | time: 25.221s
[2K
| Adam | epoch: 020 | loss: 0.07686 - acc: 0.9750 -- iter: 0544/1094
[A[ATraining Step: 683  | total loss: [1m[32m0.07877[0m[0m | time: 25.508s
[2K
| Adam | epoch: 020 | loss: 0.07877 - acc: 0.9744 -- iter: 0576/1094
[A[ATraining Step: 684  | total loss: [1m[32m0.07202[0m[0m | time: 25.834s
[2K
| Adam | epoch: 020 | loss: 0.07202 - acc: 0.9769 -- iter: 0608/1094
[A[ATraining Step: 685  | total loss: [1m[32m0.06664[0m[0m | time: 27.181s
[2K
| Adam | epoch: 020 | loss: 0.06664 - acc: 0.9793 -- iter: 0640/1094
[A[ATraining Step: 686  | total loss: [1m[32m0.06034[0m[0m | time: 28.518s
[2K
| Adam | epoch: 020 | loss: 0.06034 - acc: 0.9813 -- iter: 0672/1094
[A[ATraining Step: 687  | total loss: [1m[32m0.05587[0m[0m | time: 29.817s
[2K
| Adam | epoch: 020 | loss: 0.05587 - acc: 0.9832 -- iter: 0704/1094
[A[ATraining Step: 688  | total loss: [1m[32m0.06290[0m[0m | time: 31.308s
[2K
| Adam | epoch: 020 | loss: 0.06290 - acc: 0.9786 -- iter: 0736/1094
[A[ATraining Step: 689  | total loss: [1m[32m0.07646[0m[0m | time: 32.435s
[2K
| Adam | epoch: 020 | loss: 0.07646 - acc: 0.9745 -- iter: 0768/1094
[A[ATraining Step: 690  | total loss: [1m[32m0.07137[0m[0m | time: 33.708s
[2K
| Adam | epoch: 020 | loss: 0.07137 - acc: 0.9771 -- iter: 0800/1094
[A[ATraining Step: 691  | total loss: [1m[32m0.06575[0m[0m | time: 35.174s
[2K
| Adam | epoch: 020 | loss: 0.06575 - acc: 0.9794 -- iter: 0832/1094
[A[ATraining Step: 692  | total loss: [1m[32m0.05986[0m[0m | time: 36.492s
[2K
| Adam | epoch: 020 | loss: 0.05986 - acc: 0.9814 -- iter: 0864/1094
[A[ATraining Step: 693  | total loss: [1m[32m0.05500[0m[0m | time: 37.489s
[2K
| Adam | epoch: 020 | loss: 0.05500 - acc: 0.9833 -- iter: 0896/1094
[A[ATraining Step: 694  | total loss: [1m[32m0.05093[0m[0m | time: 38.728s
[2K
| Adam | epoch: 020 | loss: 0.05093 - acc: 0.9850 -- iter: 0928/1094
[A[ATraining Step: 695  | total loss: [1m[32m0.05811[0m[0m | time: 40.085s
[2K
| Adam | epoch: 020 | loss: 0.05811 - acc: 0.9833 -- iter: 0960/1094
[A[ATraining Step: 696  | total loss: [1m[32m0.05416[0m[0m | time: 41.414s
[2K
| Adam | epoch: 020 | loss: 0.05416 - acc: 0.9850 -- iter: 0992/1094
[A[ATraining Step: 697  | total loss: [1m[32m0.05062[0m[0m | time: 42.756s
[2K
| Adam | epoch: 020 | loss: 0.05062 - acc: 0.9865 -- iter: 1024/1094
[A[ATraining Step: 698  | total loss: [1m[32m0.04697[0m[0m | time: 44.104s
[2K
| Adam | epoch: 020 | loss: 0.04697 - acc: 0.9878 -- iter: 1056/1094
[A[ATraining Step: 699  | total loss: [1m[32m0.04769[0m[0m | time: 45.485s
[2K
| Adam | epoch: 020 | loss: 0.04769 - acc: 0.9828 -- iter: 1088/1094
[A[ATraining Step: 700  | total loss: [1m[32m0.04368[0m[0m | time: 67.047s
[2K
| Adam | epoch: 020 | loss: 0.04368 - acc: 0.9845 | val_loss: 0.73996 - val_acc: 0.8047 -- iter: 1094/1094
--
Training Step: 701  | total loss: [1m[32m0.03983[0m[0m | time: 1.762s
[2K
| Adam | epoch: 021 | loss: 0.03983 - acc: 0.9861 -- iter: 0032/1094
[A[ATraining Step: 702  | total loss: [1m[32m0.03860[0m[0m | time: 3.476s
[2K
| Adam | epoch: 021 | loss: 0.03860 - acc: 0.9875 -- iter: 0064/1094
[A[ATraining Step: 703  | total loss: [1m[32m0.06994[0m[0m | time: 5.374s
[2K
| Adam | epoch: 021 | loss: 0.06994 - acc: 0.9762 -- iter: 0096/1094
[A[ATraining Step: 704  | total loss: [1m[32m0.06344[0m[0m | time: 7.459s
[2K
| Adam | epoch: 021 | loss: 0.06344 - acc: 0.9786 -- iter: 0128/1094
[A[ATraining Step: 705  | total loss: [1m[32m0.05789[0m[0m | time: 9.552s
[2K
| Adam | epoch: 021 | loss: 0.05789 - acc: 0.9807 -- iter: 0160/1094
[A[ATraining Step: 706  | total loss: [1m[32m0.06929[0m[0m | time: 11.574s
[2K
| Adam | epoch: 021 | loss: 0.06929 - acc: 0.9733 -- iter: 0192/1094
[A[ATraining Step: 707  | total loss: [1m[32m0.06967[0m[0m | time: 13.494s
[2K
| Adam | epoch: 021 | loss: 0.06967 - acc: 0.9728 -- iter: 0224/1094
[A[ATraining Step: 708  | total loss: [1m[32m0.08018[0m[0m | time: 15.365s
[2K
| Adam | epoch: 021 | loss: 0.08018 - acc: 0.9724 -- iter: 0256/1094
[A[ATraining Step: 709  | total loss: [1m[32m0.07310[0m[0m | time: 18.286s
[2K
| Adam | epoch: 021 | loss: 0.07310 - acc: 0.9752 -- iter: 0288/1094
[A[ATraining Step: 710  | total loss: [1m[32m0.06667[0m[0m | time: 19.930s
[2K
| Adam | epoch: 021 | loss: 0.06667 - acc: 0.9777 -- iter: 0320/1094
[A[ATraining Step: 711  | total loss: [1m[32m0.06327[0m[0m | time: 21.848s
[2K
| Adam | epoch: 021 | loss: 0.06327 - acc: 0.9799 -- iter: 0352/1094
[A[ATraining Step: 712  | total loss: [1m[32m0.06939[0m[0m | time: 23.652s
[2K
| Adam | epoch: 021 | loss: 0.06939 - acc: 0.9788 -- iter: 0384/1094
[A[ATraining Step: 713  | total loss: [1m[32m0.06375[0m[0m | time: 25.511s
[2K
| Adam | epoch: 021 | loss: 0.06375 - acc: 0.9809 -- iter: 0416/1094
[A[ATraining Step: 714  | total loss: [1m[32m0.05962[0m[0m | time: 26.953s
[2K
| Adam | epoch: 021 | loss: 0.05962 - acc: 0.9828 -- iter: 0448/1094
[A[ATraining Step: 715  | total loss: [1m[32m0.08145[0m[0m | time: 28.403s
[2K
| Adam | epoch: 021 | loss: 0.08145 - acc: 0.9783 -- iter: 0480/1094
[A[ATraining Step: 716  | total loss: [1m[32m0.07584[0m[0m | time: 29.860s
[2K
| Adam | epoch: 021 | loss: 0.07584 - acc: 0.9805 -- iter: 0512/1094
[A[ATraining Step: 717  | total loss: [1m[32m0.07140[0m[0m | time: 31.470s
[2K
| Adam | epoch: 021 | loss: 0.07140 - acc: 0.9824 -- iter: 0544/1094
[A[ATraining Step: 718  | total loss: [1m[32m0.06745[0m[0m | time: 33.028s
[2K
| Adam | epoch: 021 | loss: 0.06745 - acc: 0.9842 -- iter: 0576/1094
[A[ATraining Step: 719  | total loss: [1m[32m0.06358[0m[0m | time: 33.353s
[2K
| Adam | epoch: 021 | loss: 0.06358 - acc: 0.9858 -- iter: 0608/1094
[A[ATraining Step: 720  | total loss: [1m[32m0.05758[0m[0m | time: 33.725s
[2K
| Adam | epoch: 021 | loss: 0.05758 - acc: 0.9872 -- iter: 0640/1094
[A[ATraining Step: 721  | total loss: [1m[32m0.05219[0m[0m | time: 34.919s
[2K
| Adam | epoch: 021 | loss: 0.05219 - acc: 0.9885 -- iter: 0672/1094
[A[ATraining Step: 722  | total loss: [1m[32m0.05109[0m[0m | time: 35.890s
[2K
| Adam | epoch: 021 | loss: 0.05109 - acc: 0.9865 -- iter: 0704/1094
[A[ATraining Step: 723  | total loss: [1m[32m0.04685[0m[0m | time: 36.832s
[2K
| Adam | epoch: 021 | loss: 0.04685 - acc: 0.9878 -- iter: 0736/1094
[A[ATraining Step: 724  | total loss: [1m[32m0.20888[0m[0m | time: 37.817s
[2K
| Adam | epoch: 021 | loss: 0.20888 - acc: 0.9609 -- iter: 0768/1094
[A[ATraining Step: 725  | total loss: [1m[32m0.18908[0m[0m | time: 38.844s
[2K
| Adam | epoch: 021 | loss: 0.18908 - acc: 0.9648 -- iter: 0800/1094
[A[ATraining Step: 726  | total loss: [1m[32m0.17226[0m[0m | time: 40.031s
[2K
| Adam | epoch: 021 | loss: 0.17226 - acc: 0.9684 -- iter: 0832/1094
[A[ATraining Step: 727  | total loss: [1m[32m0.15767[0m[0m | time: 41.077s
[2K
| Adam | epoch: 021 | loss: 0.15767 - acc: 0.9715 -- iter: 0864/1094
[A[ATraining Step: 728  | total loss: [1m[32m0.14399[0m[0m | time: 41.907s
[2K
| Adam | epoch: 021 | loss: 0.14399 - acc: 0.9744 -- iter: 0896/1094
[A[ATraining Step: 729  | total loss: [1m[32m0.13147[0m[0m | time: 42.853s
[2K
| Adam | epoch: 021 | loss: 0.13147 - acc: 0.9769 -- iter: 0928/1094
[A[ATraining Step: 730  | total loss: [1m[32m0.12074[0m[0m | time: 43.879s
[2K
| Adam | epoch: 021 | loss: 0.12074 - acc: 0.9792 -- iter: 0960/1094
[A[ATraining Step: 731  | total loss: [1m[32m0.11133[0m[0m | time: 44.939s
[2K
| Adam | epoch: 021 | loss: 0.11133 - acc: 0.9813 -- iter: 0992/1094
[A[ATraining Step: 732  | total loss: [1m[32m0.10649[0m[0m | time: 45.918s
[2K
| Adam | epoch: 021 | loss: 0.10649 - acc: 0.9801 -- iter: 1024/1094
[A[ATraining Step: 733  | total loss: [1m[32m0.09951[0m[0m | time: 46.955s
[2K
| Adam | epoch: 021 | loss: 0.09951 - acc: 0.9821 -- iter: 1056/1094
[A[ATraining Step: 734  | total loss: [1m[32m0.10051[0m[0m | time: 47.944s
[2K
| Adam | epoch: 021 | loss: 0.10051 - acc: 0.9807 -- iter: 1088/1094
[A[ATraining Step: 735  | total loss: [1m[32m0.09637[0m[0m | time: 51.093s
[2K
| Adam | epoch: 021 | loss: 0.09637 - acc: 0.9795 | val_loss: 0.56262 - val_acc: 0.8017 -- iter: 1094/1094
--
Training Step: 736  | total loss: [1m[32m0.09197[0m[0m | time: 0.852s
[2K
| Adam | epoch: 022 | loss: 0.09197 - acc: 0.9816 -- iter: 0032/1094
[A[ATraining Step: 737  | total loss: [1m[32m0.08499[0m[0m | time: 1.775s
[2K
| Adam | epoch: 022 | loss: 0.08499 - acc: 0.9834 -- iter: 0064/1094
[A[ATraining Step: 738  | total loss: [1m[32m0.07809[0m[0m | time: 2.668s
[2K
| Adam | epoch: 022 | loss: 0.07809 - acc: 0.9851 -- iter: 0096/1094
[A[ATraining Step: 739  | total loss: [1m[32m0.07187[0m[0m | time: 3.587s
[2K
| Adam | epoch: 022 | loss: 0.07187 - acc: 0.9866 -- iter: 0128/1094
[A[ATraining Step: 740  | total loss: [1m[32m0.07739[0m[0m | time: 4.538s
[2K
| Adam | epoch: 022 | loss: 0.07739 - acc: 0.9848 -- iter: 0160/1094
[A[ATraining Step: 741  | total loss: [1m[32m0.07230[0m[0m | time: 5.947s
[2K
| Adam | epoch: 022 | loss: 0.07230 - acc: 0.9863 -- iter: 0192/1094
[A[ATraining Step: 742  | total loss: [1m[32m0.06810[0m[0m | time: 7.515s
[2K
| Adam | epoch: 022 | loss: 0.06810 - acc: 0.9877 -- iter: 0224/1094
[A[ATraining Step: 743  | total loss: [1m[32m0.06248[0m[0m | time: 8.898s
[2K
| Adam | epoch: 022 | loss: 0.06248 - acc: 0.9889 -- iter: 0256/1094
[A[ATraining Step: 744  | total loss: [1m[32m0.06304[0m[0m | time: 10.284s
[2K
| Adam | epoch: 022 | loss: 0.06304 - acc: 0.9869 -- iter: 0288/1094
[A[ATraining Step: 745  | total loss: [1m[32m0.05786[0m[0m | time: 11.765s
[2K
| Adam | epoch: 022 | loss: 0.05786 - acc: 0.9882 -- iter: 0320/1094
[A[ATraining Step: 746  | total loss: [1m[32m0.05650[0m[0m | time: 13.158s
[2K
| Adam | epoch: 022 | loss: 0.05650 - acc: 0.9863 -- iter: 0352/1094
[A[ATraining Step: 747  | total loss: [1m[32m0.05173[0m[0m | time: 14.448s
[2K
| Adam | epoch: 022 | loss: 0.05173 - acc: 0.9876 -- iter: 0384/1094
[A[ATraining Step: 748  | total loss: [1m[32m0.04784[0m[0m | time: 15.771s
[2K
| Adam | epoch: 022 | loss: 0.04784 - acc: 0.9889 -- iter: 0416/1094
[A[ATraining Step: 749  | total loss: [1m[32m0.05102[0m[0m | time: 17.174s
[2K
| Adam | epoch: 022 | loss: 0.05102 - acc: 0.9869 -- iter: 0448/1094
[A[ATraining Step: 750  | total loss: [1m[32m0.04701[0m[0m | time: 18.700s
[2K
| Adam | epoch: 022 | loss: 0.04701 - acc: 0.9882 -- iter: 0480/1094
[A[ATraining Step: 751  | total loss: [1m[32m0.04874[0m[0m | time: 19.996s
[2K
| Adam | epoch: 022 | loss: 0.04874 - acc: 0.9862 -- iter: 0512/1094
[A[ATraining Step: 752  | total loss: [1m[32m0.04534[0m[0m | time: 21.562s
[2K
| Adam | epoch: 022 | loss: 0.04534 - acc: 0.9876 -- iter: 0544/1094
[A[ATraining Step: 753  | total loss: [1m[32m0.04215[0m[0m | time: 23.065s
[2K
| Adam | epoch: 022 | loss: 0.04215 - acc: 0.9888 -- iter: 0576/1094
[A[ATraining Step: 754  | total loss: [1m[32m0.05110[0m[0m | time: 24.734s
[2K
| Adam | epoch: 022 | loss: 0.05110 - acc: 0.9868 -- iter: 0608/1094
[A[ATraining Step: 755  | total loss: [1m[32m0.05041[0m[0m | time: 25.101s
[2K
| Adam | epoch: 022 | loss: 0.05041 - acc: 0.9850 -- iter: 0640/1094
[A[ATraining Step: 756  | total loss: [1m[32m0.04618[0m[0m | time: 25.485s
[2K
| Adam | epoch: 022 | loss: 0.04618 - acc: 0.9865 -- iter: 0672/1094
[A[ATraining Step: 757  | total loss: [1m[32m0.04206[0m[0m | time: 27.179s
[2K
| Adam | epoch: 022 | loss: 0.04206 - acc: 0.9879 -- iter: 0704/1094
[A[ATraining Step: 758  | total loss: [1m[32m0.03846[0m[0m | time: 28.474s
[2K
| Adam | epoch: 022 | loss: 0.03846 - acc: 0.9891 -- iter: 0736/1094
[A[ATraining Step: 759  | total loss: [1m[32m0.03580[0m[0m | time: 29.847s
[2K
| Adam | epoch: 022 | loss: 0.03580 - acc: 0.9902 -- iter: 0768/1094
[A[ATraining Step: 760  | total loss: [1m[32m0.15357[0m[0m | time: 31.346s
[2K
| Adam | epoch: 022 | loss: 0.15357 - acc: 0.9755 -- iter: 0800/1094
[A[ATraining Step: 761  | total loss: [1m[32m0.13922[0m[0m | time: 32.789s
[2K
| Adam | epoch: 022 | loss: 0.13922 - acc: 0.9780 -- iter: 0832/1094
[A[ATraining Step: 762  | total loss: [1m[32m0.12898[0m[0m | time: 34.426s
[2K
| Adam | epoch: 022 | loss: 0.12898 - acc: 0.9802 -- iter: 0864/1094
[A[ATraining Step: 763  | total loss: [1m[32m0.11718[0m[0m | time: 35.810s
[2K
| Adam | epoch: 022 | loss: 0.11718 - acc: 0.9822 -- iter: 0896/1094
[A[ATraining Step: 764  | total loss: [1m[32m0.10636[0m[0m | time: 36.877s
[2K
| Adam | epoch: 022 | loss: 0.10636 - acc: 0.9839 -- iter: 0928/1094
[A[ATraining Step: 765  | total loss: [1m[32m0.10006[0m[0m | time: 37.916s
[2K
| Adam | epoch: 022 | loss: 0.10006 - acc: 0.9824 -- iter: 0960/1094
[A[ATraining Step: 766  | total loss: [1m[32m0.09134[0m[0m | time: 38.909s
[2K
| Adam | epoch: 022 | loss: 0.09134 - acc: 0.9842 -- iter: 0992/1094
[A[ATraining Step: 767  | total loss: [1m[32m0.08554[0m[0m | time: 39.903s
[2K
| Adam | epoch: 022 | loss: 0.08554 - acc: 0.9858 -- iter: 1024/1094
[A[ATraining Step: 768  | total loss: [1m[32m0.07789[0m[0m | time: 40.984s
[2K
| Adam | epoch: 022 | loss: 0.07789 - acc: 0.9872 -- iter: 1056/1094
[A[ATraining Step: 769  | total loss: [1m[32m0.07120[0m[0m | time: 42.050s
[2K
| Adam | epoch: 022 | loss: 0.07120 - acc: 0.9885 -- iter: 1088/1094
[A[ATraining Step: 770  | total loss: [1m[32m0.06579[0m[0m | time: 44.920s
[2K
| Adam | epoch: 022 | loss: 0.06579 - acc: 0.9896 | val_loss: 0.59929 - val_acc: 0.8163 -- iter: 1094/1094
--
Training Step: 771  | total loss: [1m[32m0.06096[0m[0m | time: 1.034s
[2K
| Adam | epoch: 023 | loss: 0.06096 - acc: 0.9907 -- iter: 0032/1094
[A[ATraining Step: 772  | total loss: [1m[32m0.05983[0m[0m | time: 1.982s
[2K
| Adam | epoch: 023 | loss: 0.05983 - acc: 0.9885 -- iter: 0064/1094
[A[ATraining Step: 773  | total loss: [1m[32m0.05534[0m[0m | time: 2.938s
[2K
| Adam | epoch: 023 | loss: 0.05534 - acc: 0.9896 -- iter: 0096/1094
[A[ATraining Step: 774  | total loss: [1m[32m0.05281[0m[0m | time: 3.872s
[2K
| Adam | epoch: 023 | loss: 0.05281 - acc: 0.9907 -- iter: 0128/1094
[A[ATraining Step: 775  | total loss: [1m[32m0.05075[0m[0m | time: 4.876s
[2K
| Adam | epoch: 023 | loss: 0.05075 - acc: 0.9885 -- iter: 0160/1094
[A[ATraining Step: 776  | total loss: [1m[32m0.04705[0m[0m | time: 5.922s
[2K
| Adam | epoch: 023 | loss: 0.04705 - acc: 0.9896 -- iter: 0192/1094
[A[ATraining Step: 777  | total loss: [1m[32m0.05655[0m[0m | time: 6.875s
[2K
| Adam | epoch: 023 | loss: 0.05655 - acc: 0.9875 -- iter: 0224/1094
[A[ATraining Step: 778  | total loss: [1m[32m0.05231[0m[0m | time: 7.686s
[2K
| Adam | epoch: 023 | loss: 0.05231 - acc: 0.9888 -- iter: 0256/1094
[A[ATraining Step: 779  | total loss: [1m[32m0.04825[0m[0m | time: 8.655s
[2K
| Adam | epoch: 023 | loss: 0.04825 - acc: 0.9899 -- iter: 0288/1094
[A[ATraining Step: 780  | total loss: [1m[32m0.04466[0m[0m | time: 9.622s
[2K
| Adam | epoch: 023 | loss: 0.04466 - acc: 0.9909 -- iter: 0320/1094
[A[ATraining Step: 781  | total loss: [1m[32m0.06296[0m[0m | time: 10.593s
[2K
| Adam | epoch: 023 | loss: 0.06296 - acc: 0.9856 -- iter: 0352/1094
[A[ATraining Step: 782  | total loss: [1m[32m0.05772[0m[0m | time: 11.597s
[2K
| Adam | epoch: 023 | loss: 0.05772 - acc: 0.9870 -- iter: 0384/1094
[A[ATraining Step: 783  | total loss: [1m[32m0.05712[0m[0m | time: 12.641s
[2K
| Adam | epoch: 023 | loss: 0.05712 - acc: 0.9852 -- iter: 0416/1094
[A[ATraining Step: 784  | total loss: [1m[32m0.06729[0m[0m | time: 13.632s
[2K
| Adam | epoch: 023 | loss: 0.06729 - acc: 0.9835 -- iter: 0448/1094
[A[ATraining Step: 785  | total loss: [1m[32m0.07165[0m[0m | time: 14.608s
[2K
| Adam | epoch: 023 | loss: 0.07165 - acc: 0.9821 -- iter: 0480/1094
[A[ATraining Step: 786  | total loss: [1m[32m0.06564[0m[0m | time: 15.577s
[2K
| Adam | epoch: 023 | loss: 0.06564 - acc: 0.9839 -- iter: 0512/1094
[A[ATraining Step: 787  | total loss: [1m[32m0.06079[0m[0m | time: 16.618s
[2K
| Adam | epoch: 023 | loss: 0.06079 - acc: 0.9855 -- iter: 0544/1094
[A[ATraining Step: 788  | total loss: [1m[32m0.05668[0m[0m | time: 17.733s
[2K
| Adam | epoch: 023 | loss: 0.05668 - acc: 0.9869 -- iter: 0576/1094
[A[ATraining Step: 789  | total loss: [1m[32m0.05350[0m[0m | time: 18.786s
[2K
| Adam | epoch: 023 | loss: 0.05350 - acc: 0.9882 -- iter: 0608/1094
[A[ATraining Step: 790  | total loss: [1m[32m0.04897[0m[0m | time: 19.830s
[2K
| Adam | epoch: 023 | loss: 0.04897 - acc: 0.9894 -- iter: 0640/1094
[A[ATraining Step: 791  | total loss: [1m[32m0.04492[0m[0m | time: 20.083s
[2K
| Adam | epoch: 023 | loss: 0.04492 - acc: 0.9905 -- iter: 0672/1094
[A[ATraining Step: 792  | total loss: [1m[32m0.04104[0m[0m | time: 20.337s
[2K
| Adam | epoch: 023 | loss: 0.04104 - acc: 0.9914 -- iter: 0704/1094
[A[ATraining Step: 793  | total loss: [1m[32m0.03753[0m[0m | time: 21.424s
[2K
| Adam | epoch: 023 | loss: 0.03753 - acc: 0.9923 -- iter: 0736/1094
[A[ATraining Step: 794  | total loss: [1m[32m0.03468[0m[0m | time: 22.430s
[2K
| Adam | epoch: 023 | loss: 0.03468 - acc: 0.9931 -- iter: 0768/1094
[A[ATraining Step: 795  | total loss: [1m[32m0.03180[0m[0m | time: 23.140s
[2K
| Adam | epoch: 023 | loss: 0.03180 - acc: 0.9937 -- iter: 0800/1094
[A[ATraining Step: 796  | total loss: [1m[32m0.20209[0m[0m | time: 23.831s
[2K
| Adam | epoch: 023 | loss: 0.20209 - acc: 0.9631 -- iter: 0832/1094
[A[ATraining Step: 797  | total loss: [1m[32m0.18781[0m[0m | time: 24.530s
[2K
| Adam | epoch: 023 | loss: 0.18781 - acc: 0.9637 -- iter: 0864/1094
[A[ATraining Step: 798  | total loss: [1m[32m0.17067[0m[0m | time: 25.225s
[2K
| Adam | epoch: 023 | loss: 0.17067 - acc: 0.9673 -- iter: 0896/1094
[A[ATraining Step: 799  | total loss: [1m[32m0.15567[0m[0m | time: 25.915s
[2K
| Adam | epoch: 023 | loss: 0.15567 - acc: 0.9706 -- iter: 0928/1094
[A[ATraining Step: 800  | total loss: [1m[32m0.14214[0m[0m | time: 28.146s
[2K
| Adam | epoch: 023 | loss: 0.14214 - acc: 0.9735 | val_loss: 0.70353 - val_acc: 0.7697 -- iter: 0960/1094
--
Training Step: 801  | total loss: [1m[32m0.13023[0m[0m | time: 28.863s
[2K
| Adam | epoch: 023 | loss: 0.13023 - acc: 0.9762 -- iter: 0992/1094
[A[ATraining Step: 802  | total loss: [1m[32m0.12790[0m[0m | time: 29.547s
[2K
| Adam | epoch: 023 | loss: 0.12790 - acc: 0.9754 -- iter: 1024/1094
[A[ATraining Step: 803  | total loss: [1m[32m0.12920[0m[0m | time: 30.212s
[2K
| Adam | epoch: 023 | loss: 0.12920 - acc: 0.9748 -- iter: 1056/1094
[A[ATraining Step: 804  | total loss: [1m[32m0.11840[0m[0m | time: 30.901s
[2K
| Adam | epoch: 023 | loss: 0.11840 - acc: 0.9773 -- iter: 1088/1094
[A[ATraining Step: 805  | total loss: [1m[32m0.10808[0m[0m | time: 33.038s
[2K
| Adam | epoch: 023 | loss: 0.10808 - acc: 0.9796 | val_loss: 0.57228 - val_acc: 0.8105 -- iter: 1094/1094
--
Training Step: 806  | total loss: [1m[32m0.10800[0m[0m | time: 0.691s
[2K
| Adam | epoch: 024 | loss: 0.10800 - acc: 0.9785 -- iter: 0032/1094
[A[ATraining Step: 807  | total loss: [1m[32m0.09918[0m[0m | time: 1.406s
[2K
| Adam | epoch: 024 | loss: 0.09918 - acc: 0.9806 -- iter: 0064/1094
[A[ATraining Step: 808  | total loss: [1m[32m0.09169[0m[0m | time: 2.059s
[2K
| Adam | epoch: 024 | loss: 0.09169 - acc: 0.9826 -- iter: 0096/1094
[A[ATraining Step: 809  | total loss: [1m[32m0.08452[0m[0m | time: 2.751s
[2K
| Adam | epoch: 024 | loss: 0.08452 - acc: 0.9843 -- iter: 0128/1094
[A[ATraining Step: 810  | total loss: [1m[32m0.07777[0m[0m | time: 3.402s
[2K
| Adam | epoch: 024 | loss: 0.07777 - acc: 0.9859 -- iter: 0160/1094
[A[ATraining Step: 811  | total loss: [1m[32m0.08389[0m[0m | time: 4.096s
[2K
| Adam | epoch: 024 | loss: 0.08389 - acc: 0.9842 -- iter: 0192/1094
[A[ATraining Step: 812  | total loss: [1m[32m0.07810[0m[0m | time: 4.786s
[2K
| Adam | epoch: 024 | loss: 0.07810 - acc: 0.9857 -- iter: 0224/1094
[A[ATraining Step: 813  | total loss: [1m[32m0.07702[0m[0m | time: 5.537s
[2K
| Adam | epoch: 024 | loss: 0.07702 - acc: 0.9840 -- iter: 0256/1094
[A[ATraining Step: 814  | total loss: [1m[32m0.07075[0m[0m | time: 6.244s
[2K
| Adam | epoch: 024 | loss: 0.07075 - acc: 0.9856 -- iter: 0288/1094
[A[ATraining Step: 815  | total loss: [1m[32m0.06512[0m[0m | time: 7.005s
[2K
| Adam | epoch: 024 | loss: 0.06512 - acc: 0.9871 -- iter: 0320/1094
[A[ATraining Step: 816  | total loss: [1m[32m0.06569[0m[0m | time: 8.155s
[2K
| Adam | epoch: 024 | loss: 0.06569 - acc: 0.9852 -- iter: 0352/1094
[A[ATraining Step: 817  | total loss: [1m[32m0.06051[0m[0m | time: 9.287s
[2K
| Adam | epoch: 024 | loss: 0.06051 - acc: 0.9867 -- iter: 0384/1094
[A[ATraining Step: 818  | total loss: [1m[32m0.05756[0m[0m | time: 10.056s
[2K
| Adam | epoch: 024 | loss: 0.05756 - acc: 0.9881 -- iter: 0416/1094
[A[ATraining Step: 819  | total loss: [1m[32m0.05452[0m[0m | time: 10.990s
[2K
| Adam | epoch: 024 | loss: 0.05452 - acc: 0.9892 -- iter: 0448/1094
[A[ATraining Step: 820  | total loss: [1m[32m0.05055[0m[0m | time: 11.983s
[2K
| Adam | epoch: 024 | loss: 0.05055 - acc: 0.9903 -- iter: 0480/1094
[A[ATraining Step: 821  | total loss: [1m[32m0.04667[0m[0m | time: 12.869s
[2K
| Adam | epoch: 024 | loss: 0.04667 - acc: 0.9913 -- iter: 0512/1094
[A[ATraining Step: 822  | total loss: [1m[32m0.04340[0m[0m | time: 13.871s
[2K
| Adam | epoch: 024 | loss: 0.04340 - acc: 0.9922 -- iter: 0544/1094
[A[ATraining Step: 823  | total loss: [1m[32m0.04031[0m[0m | time: 14.879s
[2K
| Adam | epoch: 024 | loss: 0.04031 - acc: 0.9929 -- iter: 0576/1094
[A[ATraining Step: 824  | total loss: [1m[32m0.03695[0m[0m | time: 15.901s
[2K
| Adam | epoch: 024 | loss: 0.03695 - acc: 0.9936 -- iter: 0608/1094
[A[ATraining Step: 825  | total loss: [1m[32m0.03562[0m[0m | time: 16.798s
[2K
| Adam | epoch: 024 | loss: 0.03562 - acc: 0.9943 -- iter: 0640/1094
[A[ATraining Step: 826  | total loss: [1m[32m0.03311[0m[0m | time: 17.755s
[2K
| Adam | epoch: 024 | loss: 0.03311 - acc: 0.9949 -- iter: 0672/1094
[A[ATraining Step: 827  | total loss: [1m[32m0.03049[0m[0m | time: 17.961s
[2K
| Adam | epoch: 024 | loss: 0.03049 - acc: 0.9954 -- iter: 0704/1094
[A[ATraining Step: 828  | total loss: [1m[32m0.02794[0m[0m | time: 18.179s
[2K
| Adam | epoch: 024 | loss: 0.02794 - acc: 0.9958 -- iter: 0736/1094
[A[ATraining Step: 829  | total loss: [1m[32m0.02558[0m[0m | time: 19.317s
[2K
| Adam | epoch: 024 | loss: 0.02558 - acc: 0.9963 -- iter: 0768/1094
[A[ATraining Step: 830  | total loss: [1m[32m0.02932[0m[0m | time: 20.394s
[2K
| Adam | epoch: 024 | loss: 0.02932 - acc: 0.9935 -- iter: 0800/1094
[A[ATraining Step: 831  | total loss: [1m[32m0.02745[0m[0m | time: 21.229s
[2K
| Adam | epoch: 024 | loss: 0.02745 - acc: 0.9942 -- iter: 0832/1094
[A[ATraining Step: 832  | total loss: [1m[32m0.02547[0m[0m | time: 22.183s
[2K
| Adam | epoch: 024 | loss: 0.02547 - acc: 0.9947 -- iter: 0864/1094
[A[ATraining Step: 833  | total loss: [1m[32m0.02452[0m[0m | time: 23.154s
[2K
| Adam | epoch: 024 | loss: 0.02452 - acc: 0.9953 -- iter: 0896/1094
[A[ATraining Step: 834  | total loss: [1m[32m0.02271[0m[0m | time: 24.183s
[2K
| Adam | epoch: 024 | loss: 0.02271 - acc: 0.9957 -- iter: 0928/1094
[A[ATraining Step: 835  | total loss: [1m[32m0.02090[0m[0m | time: 25.178s
[2K
| Adam | epoch: 024 | loss: 0.02090 - acc: 0.9962 -- iter: 0960/1094
[A[ATraining Step: 836  | total loss: [1m[32m0.01910[0m[0m | time: 26.221s
[2K
| Adam | epoch: 024 | loss: 0.01910 - acc: 0.9965 -- iter: 0992/1094
[A[ATraining Step: 837  | total loss: [1m[32m0.01749[0m[0m | time: 27.170s
[2K
| Adam | epoch: 024 | loss: 0.01749 - acc: 0.9969 -- iter: 1024/1094
[A[ATraining Step: 838  | total loss: [1m[32m0.01672[0m[0m | time: 28.166s
[2K
| Adam | epoch: 024 | loss: 0.01672 - acc: 0.9972 -- iter: 1056/1094
[A[ATraining Step: 839  | total loss: [1m[32m0.01554[0m[0m | time: 29.121s
[2K
| Adam | epoch: 024 | loss: 0.01554 - acc: 0.9975 -- iter: 1088/1094
[A[ATraining Step: 840  | total loss: [1m[32m0.01527[0m[0m | time: 32.219s
[2K
| Adam | epoch: 024 | loss: 0.01527 - acc: 0.9977 | val_loss: 0.73090 - val_acc: 0.8251 -- iter: 1094/1094
--
Training Step: 841  | total loss: [1m[32m0.01439[0m[0m | time: 0.971s
[2K
| Adam | epoch: 025 | loss: 0.01439 - acc: 0.9980 -- iter: 0032/1094
[A[ATraining Step: 842  | total loss: [1m[32m0.01324[0m[0m | time: 1.958s
[2K
| Adam | epoch: 025 | loss: 0.01324 - acc: 0.9982 -- iter: 0064/1094
[A[ATraining Step: 843  | total loss: [1m[32m0.01277[0m[0m | time: 2.944s
[2K
| Adam | epoch: 025 | loss: 0.01277 - acc: 0.9983 -- iter: 0096/1094
[A[ATraining Step: 844  | total loss: [1m[32m0.01173[0m[0m | time: 4.011s
[2K
| Adam | epoch: 025 | loss: 0.01173 - acc: 0.9985 -- iter: 0128/1094
[A[ATraining Step: 845  | total loss: [1m[32m0.01080[0m[0m | time: 5.012s
[2K
| Adam | epoch: 025 | loss: 0.01080 - acc: 0.9987 -- iter: 0160/1094
[A[ATraining Step: 846  | total loss: [1m[32m0.01001[0m[0m | time: 6.052s
[2K
| Adam | epoch: 025 | loss: 0.01001 - acc: 0.9988 -- iter: 0192/1094
[A[ATraining Step: 847  | total loss: [1m[32m0.00919[0m[0m | time: 6.959s
[2K
| Adam | epoch: 025 | loss: 0.00919 - acc: 0.9989 -- iter: 0224/1094
[A[ATraining Step: 848  | total loss: [1m[32m0.01367[0m[0m | time: 8.120s
[2K
| Adam | epoch: 025 | loss: 0.01367 - acc: 0.9959 -- iter: 0256/1094
[A[ATraining Step: 849  | total loss: [1m[32m0.01271[0m[0m | time: 9.163s
[2K
| Adam | epoch: 025 | loss: 0.01271 - acc: 0.9963 -- iter: 0288/1094
[A[ATraining Step: 850  | total loss: [1m[32m0.02469[0m[0m | time: 9.902s
[2K
| Adam | epoch: 025 | loss: 0.02469 - acc: 0.9936 -- iter: 0320/1094
[A[ATraining Step: 851  | total loss: [1m[32m0.02252[0m[0m | time: 10.808s
[2K
| Adam | epoch: 025 | loss: 0.02252 - acc: 0.9942 -- iter: 0352/1094
[A[ATraining Step: 852  | total loss: [1m[32m0.02059[0m[0m | time: 11.810s
[2K
| Adam | epoch: 025 | loss: 0.02059 - acc: 0.9948 -- iter: 0384/1094
[A[ATraining Step: 853  | total loss: [1m[32m0.01897[0m[0m | time: 12.778s
[2K
| Adam | epoch: 025 | loss: 0.01897 - acc: 0.9953 -- iter: 0416/1094
[A[ATraining Step: 854  | total loss: [1m[32m0.01746[0m[0m | time: 13.747s
[2K
| Adam | epoch: 025 | loss: 0.01746 - acc: 0.9958 -- iter: 0448/1094
[A[ATraining Step: 855  | total loss: [1m[32m0.01596[0m[0m | time: 14.753s
[2K
| Adam | epoch: 025 | loss: 0.01596 - acc: 0.9962 -- iter: 0480/1094
[A[ATraining Step: 856  | total loss: [1m[32m0.01463[0m[0m | time: 15.744s
[2K
| Adam | epoch: 025 | loss: 0.01463 - acc: 0.9966 -- iter: 0512/1094
[A[ATraining Step: 857  | total loss: [1m[32m0.01353[0m[0m | time: 16.773s
[2K
| Adam | epoch: 025 | loss: 0.01353 - acc: 0.9969 -- iter: 0544/1094
[A[ATraining Step: 858  | total loss: [1m[32m0.01237[0m[0m | time: 17.768s
[2K
| Adam | epoch: 025 | loss: 0.01237 - acc: 0.9972 -- iter: 0576/1094
[A[ATraining Step: 859  | total loss: [1m[32m0.04686[0m[0m | time: 18.684s
[2K
| Adam | epoch: 025 | loss: 0.04686 - acc: 0.9913 -- iter: 0608/1094
[A[ATraining Step: 860  | total loss: [1m[32m0.05363[0m[0m | time: 19.786s
[2K
| Adam | epoch: 025 | loss: 0.05363 - acc: 0.9890 -- iter: 0640/1094
[A[ATraining Step: 861  | total loss: [1m[32m0.06136[0m[0m | time: 20.848s
[2K
| Adam | epoch: 025 | loss: 0.06136 - acc: 0.9870 -- iter: 0672/1094
[A[ATraining Step: 862  | total loss: [1m[32m0.05562[0m[0m | time: 21.637s
[2K
| Adam | epoch: 025 | loss: 0.05562 - acc: 0.9883 -- iter: 0704/1094
[A[ATraining Step: 863  | total loss: [1m[32m0.05083[0m[0m | time: 21.869s
[2K
| Adam | epoch: 025 | loss: 0.05083 - acc: 0.9895 -- iter: 0736/1094
[A[ATraining Step: 864  | total loss: [1m[32m0.04624[0m[0m | time: 22.096s
[2K
| Adam | epoch: 025 | loss: 0.04624 - acc: 0.9905 -- iter: 0768/1094
[A[ATraining Step: 865  | total loss: [1m[32m0.04217[0m[0m | time: 23.174s
[2K
| Adam | epoch: 025 | loss: 0.04217 - acc: 0.9915 -- iter: 0800/1094
[A[ATraining Step: 866  | total loss: [1m[32m0.04260[0m[0m | time: 24.131s
[2K
| Adam | epoch: 025 | loss: 0.04260 - acc: 0.9923 -- iter: 0832/1094
[A[ATraining Step: 867  | total loss: [1m[32m0.05072[0m[0m | time: 25.145s
[2K
| Adam | epoch: 025 | loss: 0.05072 - acc: 0.9900 -- iter: 0864/1094
[A[ATraining Step: 868  | total loss: [1m[32m0.07431[0m[0m | time: 26.191s
[2K
| Adam | epoch: 025 | loss: 0.07431 - acc: 0.9878 -- iter: 0896/1094
[A[ATraining Step: 869  | total loss: [1m[32m0.06729[0m[0m | time: 27.214s
[2K
| Adam | epoch: 025 | loss: 0.06729 - acc: 0.9891 -- iter: 0928/1094
[A[ATraining Step: 870  | total loss: [1m[32m0.06113[0m[0m | time: 28.224s
[2K
| Adam | epoch: 025 | loss: 0.06113 - acc: 0.9901 -- iter: 0960/1094
[A[ATraining Step: 871  | total loss: [1m[32m0.05537[0m[0m | time: 29.156s
[2K
| Adam | epoch: 025 | loss: 0.05537 - acc: 0.9911 -- iter: 0992/1094
[A[ATraining Step: 872  | total loss: [1m[32m0.05067[0m[0m | time: 30.341s
[2K
| Adam | epoch: 025 | loss: 0.05067 - acc: 0.9920 -- iter: 1024/1094
[A[ATraining Step: 873  | total loss: [1m[32m0.04918[0m[0m | time: 31.418s
[2K
| Adam | epoch: 025 | loss: 0.04918 - acc: 0.9928 -- iter: 1056/1094
[A[ATraining Step: 874  | total loss: [1m[32m0.05534[0m[0m | time: 32.222s
[2K
| Adam | epoch: 025 | loss: 0.05534 - acc: 0.9904 -- iter: 1088/1094
[A[ATraining Step: 875  | total loss: [1m[32m0.05169[0m[0m | time: 35.299s
[2K
| Adam | epoch: 025 | loss: 0.05169 - acc: 0.9914 | val_loss: 0.70707 - val_acc: 0.7959 -- iter: 1094/1094
--
Training Step: 876  | total loss: [1m[32m0.04766[0m[0m | time: 1.024s
[2K
| Adam | epoch: 026 | loss: 0.04766 - acc: 0.9922 -- iter: 0032/1094
[A[ATraining Step: 877  | total loss: [1m[32m0.04334[0m[0m | time: 1.992s
[2K
| Adam | epoch: 026 | loss: 0.04334 - acc: 0.9930 -- iter: 0064/1094
[A[ATraining Step: 878  | total loss: [1m[32m0.05185[0m[0m | time: 2.973s
[2K
| Adam | epoch: 026 | loss: 0.05185 - acc: 0.9906 -- iter: 0096/1094
[A[ATraining Step: 879  | total loss: [1m[32m0.05355[0m[0m | time: 3.887s
[2K
| Adam | epoch: 026 | loss: 0.05355 - acc: 0.9884 -- iter: 0128/1094
[A[ATraining Step: 880  | total loss: [1m[32m0.04890[0m[0m | time: 5.029s
[2K
| Adam | epoch: 026 | loss: 0.04890 - acc: 0.9896 -- iter: 0160/1094
[A[ATraining Step: 881  | total loss: [1m[32m0.04509[0m[0m | time: 6.115s
[2K
| Adam | epoch: 026 | loss: 0.04509 - acc: 0.9906 -- iter: 0192/1094
[A[ATraining Step: 882  | total loss: [1m[32m0.04135[0m[0m | time: 6.894s
[2K
| Adam | epoch: 026 | loss: 0.04135 - acc: 0.9915 -- iter: 0224/1094
[A[ATraining Step: 883  | total loss: [1m[32m0.03882[0m[0m | time: 7.873s
[2K
| Adam | epoch: 026 | loss: 0.03882 - acc: 0.9924 -- iter: 0256/1094
[A[ATraining Step: 884  | total loss: [1m[32m0.03557[0m[0m | time: 8.866s
[2K
| Adam | epoch: 026 | loss: 0.03557 - acc: 0.9931 -- iter: 0288/1094
[A[ATraining Step: 885  | total loss: [1m[32m0.03320[0m[0m | time: 9.865s
[2K
| Adam | epoch: 026 | loss: 0.03320 - acc: 0.9938 -- iter: 0320/1094
[A[ATraining Step: 886  | total loss: [1m[32m0.03044[0m[0m | time: 10.816s
[2K
| Adam | epoch: 026 | loss: 0.03044 - acc: 0.9945 -- iter: 0352/1094
[A[ATraining Step: 887  | total loss: [1m[32m0.02808[0m[0m | time: 11.828s
[2K
| Adam | epoch: 026 | loss: 0.02808 - acc: 0.9950 -- iter: 0384/1094
[A[ATraining Step: 888  | total loss: [1m[32m0.02626[0m[0m | time: 12.817s
[2K
| Adam | epoch: 026 | loss: 0.02626 - acc: 0.9955 -- iter: 0416/1094
[A[ATraining Step: 889  | total loss: [1m[32m0.02428[0m[0m | time: 13.811s
[2K
| Adam | epoch: 026 | loss: 0.02428 - acc: 0.9960 -- iter: 0448/1094
[A[ATraining Step: 890  | total loss: [1m[32m0.02327[0m[0m | time: 14.779s
[2K
| Adam | epoch: 026 | loss: 0.02327 - acc: 0.9964 -- iter: 0480/1094
[A[ATraining Step: 891  | total loss: [1m[32m0.03590[0m[0m | time: 15.963s
[2K
| Adam | epoch: 026 | loss: 0.03590 - acc: 0.9936 -- iter: 0512/1094
[A[ATraining Step: 892  | total loss: [1m[32m0.03314[0m[0m | time: 17.030s
[2K
| Adam | epoch: 026 | loss: 0.03314 - acc: 0.9942 -- iter: 0544/1094
[A[ATraining Step: 893  | total loss: [1m[32m0.03102[0m[0m | time: 17.814s
[2K
| Adam | epoch: 026 | loss: 0.03102 - acc: 0.9948 -- iter: 0576/1094
[A[ATraining Step: 894  | total loss: [1m[32m0.03659[0m[0m | time: 18.814s
[2K
| Adam | epoch: 026 | loss: 0.03659 - acc: 0.9922 -- iter: 0608/1094
[A[ATraining Step: 895  | total loss: [1m[32m0.03732[0m[0m | time: 19.841s
[2K
| Adam | epoch: 026 | loss: 0.03732 - acc: 0.9899 -- iter: 0640/1094
[A[ATraining Step: 896  | total loss: [1m[32m0.03420[0m[0m | time: 20.853s
[2K
| Adam | epoch: 026 | loss: 0.03420 - acc: 0.9909 -- iter: 0672/1094
[A[ATraining Step: 897  | total loss: [1m[32m0.03122[0m[0m | time: 21.846s
[2K
| Adam | epoch: 026 | loss: 0.03122 - acc: 0.9918 -- iter: 0704/1094
[A[ATraining Step: 898  | total loss: [1m[32m0.02905[0m[0m | time: 22.832s
[2K
| Adam | epoch: 026 | loss: 0.02905 - acc: 0.9926 -- iter: 0736/1094
[A[ATraining Step: 899  | total loss: [1m[32m0.02870[0m[0m | time: 23.106s
[2K
| Adam | epoch: 026 | loss: 0.02870 - acc: 0.9933 -- iter: 0768/1094
[A[ATraining Step: 900  | total loss: [1m[32m0.02622[0m[0m | time: 23.343s
[2K
| Adam | epoch: 026 | loss: 0.02622 - acc: 0.9940 -- iter: 0800/1094
[A[ATraining Step: 901  | total loss: [1m[32m0.02392[0m[0m | time: 24.385s
[2K
| Adam | epoch: 026 | loss: 0.02392 - acc: 0.9946 -- iter: 0832/1094
[A[ATraining Step: 902  | total loss: [1m[32m0.02369[0m[0m | time: 25.328s
[2K
| Adam | epoch: 026 | loss: 0.02369 - acc: 0.9952 -- iter: 0864/1094
[A[ATraining Step: 903  | total loss: [1m[32m0.02189[0m[0m | time: 26.501s
[2K
| Adam | epoch: 026 | loss: 0.02189 - acc: 0.9956 -- iter: 0896/1094
[A[ATraining Step: 904  | total loss: [1m[32m0.05961[0m[0m | time: 27.587s
[2K
| Adam | epoch: 026 | loss: 0.05961 - acc: 0.9898 -- iter: 0928/1094
[A[ATraining Step: 905  | total loss: [1m[32m0.05411[0m[0m | time: 28.383s
[2K
| Adam | epoch: 026 | loss: 0.05411 - acc: 0.9908 -- iter: 0960/1094
[A[ATraining Step: 906  | total loss: [1m[32m0.04920[0m[0m | time: 29.325s
[2K
| Adam | epoch: 026 | loss: 0.04920 - acc: 0.9918 -- iter: 0992/1094
[A[ATraining Step: 907  | total loss: [1m[32m0.04467[0m[0m | time: 30.231s
[2K
| Adam | epoch: 026 | loss: 0.04467 - acc: 0.9926 -- iter: 1024/1094
[A[ATraining Step: 908  | total loss: [1m[32m0.04180[0m[0m | time: 31.204s
[2K
| Adam | epoch: 026 | loss: 0.04180 - acc: 0.9933 -- iter: 1056/1094
[A[ATraining Step: 909  | total loss: [1m[32m0.03817[0m[0m | time: 32.100s
[2K
| Adam | epoch: 026 | loss: 0.03817 - acc: 0.9940 -- iter: 1088/1094
[A[ATraining Step: 910  | total loss: [1m[32m0.03516[0m[0m | time: 35.174s
[2K
| Adam | epoch: 026 | loss: 0.03516 - acc: 0.9946 | val_loss: 0.70580 - val_acc: 0.8163 -- iter: 1094/1094
--
Training Step: 911  | total loss: [1m[32m0.03200[0m[0m | time: 0.926s
[2K
| Adam | epoch: 027 | loss: 0.03200 - acc: 0.9951 -- iter: 0032/1094
[A[ATraining Step: 912  | total loss: [1m[32m0.03207[0m[0m | time: 1.749s
[2K
| Adam | epoch: 027 | loss: 0.03207 - acc: 0.9956 -- iter: 0064/1094
[A[ATraining Step: 913  | total loss: [1m[32m0.02978[0m[0m | time: 2.673s
[2K
| Adam | epoch: 027 | loss: 0.02978 - acc: 0.9961 -- iter: 0096/1094
[A[ATraining Step: 914  | total loss: [1m[32m0.02724[0m[0m | time: 3.623s
[2K
| Adam | epoch: 027 | loss: 0.02724 - acc: 0.9965 -- iter: 0128/1094
[A[ATraining Step: 915  | total loss: [1m[32m0.02518[0m[0m | time: 4.454s
[2K
| Adam | epoch: 027 | loss: 0.02518 - acc: 0.9968 -- iter: 0160/1094
[A[ATraining Step: 916  | total loss: [1m[32m0.02310[0m[0m | time: 5.403s
[2K
| Adam | epoch: 027 | loss: 0.02310 - acc: 0.9971 -- iter: 0192/1094
[A[ATraining Step: 917  | total loss: [1m[32m0.02112[0m[0m | time: 6.291s
[2K
| Adam | epoch: 027 | loss: 0.02112 - acc: 0.9974 -- iter: 0224/1094
[A[ATraining Step: 918  | total loss: [1m[32m0.02041[0m[0m | time: 7.377s
[2K
| Adam | epoch: 027 | loss: 0.02041 - acc: 0.9977 -- iter: 0256/1094
[A[ATraining Step: 919  | total loss: [1m[32m0.01925[0m[0m | time: 8.414s
[2K
| Adam | epoch: 027 | loss: 0.01925 - acc: 0.9979 -- iter: 0288/1094
[A[ATraining Step: 920  | total loss: [1m[32m0.01798[0m[0m | time: 9.144s
[2K
| Adam | epoch: 027 | loss: 0.01798 - acc: 0.9981 -- iter: 0320/1094
[A[ATraining Step: 921  | total loss: [1m[32m0.02766[0m[0m | time: 10.058s
[2K
| Adam | epoch: 027 | loss: 0.02766 - acc: 0.9952 -- iter: 0352/1094
[A[ATraining Step: 922  | total loss: [1m[32m0.02525[0m[0m | time: 11.057s
[2K
| Adam | epoch: 027 | loss: 0.02525 - acc: 0.9957 -- iter: 0384/1094
[A[ATraining Step: 923  | total loss: [1m[32m0.02360[0m[0m | time: 12.032s
[2K
| Adam | epoch: 027 | loss: 0.02360 - acc: 0.9961 -- iter: 0416/1094
[A[ATraining Step: 924  | total loss: [1m[32m0.03416[0m[0m | time: 13.020s
[2K
| Adam | epoch: 027 | loss: 0.03416 - acc: 0.9934 -- iter: 0448/1094
[A[ATraining Step: 925  | total loss: [1m[32m0.03099[0m[0m | time: 14.021s
[2K
| Adam | epoch: 027 | loss: 0.03099 - acc: 0.9940 -- iter: 0480/1094
[A[ATraining Step: 926  | total loss: [1m[32m0.02861[0m[0m | time: 14.940s
[2K
| Adam | epoch: 027 | loss: 0.02861 - acc: 0.9946 -- iter: 0512/1094
[A[ATraining Step: 927  | total loss: [1m[32m0.02756[0m[0m | time: 15.936s
[2K
| Adam | epoch: 027 | loss: 0.02756 - acc: 0.9952 -- iter: 0544/1094
[A[ATraining Step: 928  | total loss: [1m[32m0.02817[0m[0m | time: 16.934s
[2K
| Adam | epoch: 027 | loss: 0.02817 - acc: 0.9956 -- iter: 0576/1094
[A[ATraining Step: 929  | total loss: [1m[32m0.02641[0m[0m | time: 18.079s
[2K
| Adam | epoch: 027 | loss: 0.02641 - acc: 0.9961 -- iter: 0608/1094
[A[ATraining Step: 930  | total loss: [1m[32m0.02409[0m[0m | time: 19.140s
[2K
| Adam | epoch: 027 | loss: 0.02409 - acc: 0.9965 -- iter: 0640/1094
[A[ATraining Step: 931  | total loss: [1m[32m0.02220[0m[0m | time: 19.888s
[2K
| Adam | epoch: 027 | loss: 0.02220 - acc: 0.9968 -- iter: 0672/1094
[A[ATraining Step: 932  | total loss: [1m[32m0.02033[0m[0m | time: 20.821s
[2K
| Adam | epoch: 027 | loss: 0.02033 - acc: 0.9971 -- iter: 0704/1094
[A[ATraining Step: 933  | total loss: [1m[32m0.01861[0m[0m | time: 21.872s
[2K
| Adam | epoch: 027 | loss: 0.01861 - acc: 0.9974 -- iter: 0736/1094
[A[ATraining Step: 934  | total loss: [1m[32m0.01728[0m[0m | time: 22.761s
[2K
| Adam | epoch: 027 | loss: 0.01728 - acc: 0.9977 -- iter: 0768/1094
[A[ATraining Step: 935  | total loss: [1m[32m0.01575[0m[0m | time: 22.996s
[2K
| Adam | epoch: 027 | loss: 0.01575 - acc: 0.9979 -- iter: 0800/1094
[A[ATraining Step: 936  | total loss: [1m[32m0.08066[0m[0m | time: 23.234s
[2K
| Adam | epoch: 027 | loss: 0.08066 - acc: 0.9815 -- iter: 0832/1094
[A[ATraining Step: 937  | total loss: [1m[32m0.10476[0m[0m | time: 24.251s
[2K
| Adam | epoch: 027 | loss: 0.10476 - acc: 0.9666 -- iter: 0864/1094
[A[ATraining Step: 938  | total loss: [1m[32m0.10006[0m[0m | time: 25.277s
[2K
| Adam | epoch: 027 | loss: 0.10006 - acc: 0.9669 -- iter: 0896/1094
[A[ATraining Step: 939  | total loss: [1m[32m0.09051[0m[0m | time: 26.240s
[2K
| Adam | epoch: 027 | loss: 0.09051 - acc: 0.9702 -- iter: 0928/1094
[A[ATraining Step: 940  | total loss: [1m[32m0.09794[0m[0m | time: 27.269s
[2K
| Adam | epoch: 027 | loss: 0.09794 - acc: 0.9700 -- iter: 0960/1094
[A[ATraining Step: 941  | total loss: [1m[32m0.09251[0m[0m | time: 28.175s
[2K
| Adam | epoch: 027 | loss: 0.09251 - acc: 0.9699 -- iter: 0992/1094
[A[ATraining Step: 942  | total loss: [1m[32m0.08854[0m[0m | time: 29.271s
[2K
| Adam | epoch: 027 | loss: 0.08854 - acc: 0.9698 -- iter: 1024/1094
[A[ATraining Step: 943  | total loss: [1m[32m0.09234[0m[0m | time: 30.291s
[2K
| Adam | epoch: 027 | loss: 0.09234 - acc: 0.9697 -- iter: 1056/1094
[A[ATraining Step: 944  | total loss: [1m[32m0.08354[0m[0m | time: 31.382s
[2K
| Adam | epoch: 027 | loss: 0.08354 - acc: 0.9727 -- iter: 1088/1094
[A[ATraining Step: 945  | total loss: [1m[32m0.07660[0m[0m | time: 34.564s
[2K
| Adam | epoch: 027 | loss: 0.07660 - acc: 0.9754 | val_loss: 0.81543 - val_acc: 0.7930 -- iter: 1094/1094
--
Training Step: 946  | total loss: [1m[32m0.07007[0m[0m | time: 0.728s
[2K
| Adam | epoch: 028 | loss: 0.07007 - acc: 0.9779 -- iter: 0032/1094
[A[ATraining Step: 947  | total loss: [1m[32m0.06442[0m[0m | time: 1.426s
[2K
| Adam | epoch: 028 | loss: 0.06442 - acc: 0.9801 -- iter: 0064/1094
[A[ATraining Step: 948  | total loss: [1m[32m0.05867[0m[0m | time: 2.124s
[2K
| Adam | epoch: 028 | loss: 0.05867 - acc: 0.9821 -- iter: 0096/1094
[A[ATraining Step: 949  | total loss: [1m[32m0.05494[0m[0m | time: 2.846s
[2K
| Adam | epoch: 028 | loss: 0.05494 - acc: 0.9839 -- iter: 0128/1094
[A[ATraining Step: 950  | total loss: [1m[32m0.05467[0m[0m | time: 3.565s
[2K
| Adam | epoch: 028 | loss: 0.05467 - acc: 0.9824 -- iter: 0160/1094
[A[ATraining Step: 951  | total loss: [1m[32m0.05061[0m[0m | time: 4.246s
[2K
| Adam | epoch: 028 | loss: 0.05061 - acc: 0.9841 -- iter: 0192/1094
[A[ATraining Step: 952  | total loss: [1m[32m0.04601[0m[0m | time: 4.943s
[2K
| Adam | epoch: 028 | loss: 0.04601 - acc: 0.9857 -- iter: 0224/1094
[A[ATraining Step: 953  | total loss: [1m[32m0.04204[0m[0m | time: 5.629s
[2K
| Adam | epoch: 028 | loss: 0.04204 - acc: 0.9872 -- iter: 0256/1094
[A[ATraining Step: 954  | total loss: [1m[32m0.03836[0m[0m | time: 6.361s
[2K
| Adam | epoch: 028 | loss: 0.03836 - acc: 0.9884 -- iter: 0288/1094
[A[ATraining Step: 955  | total loss: [1m[32m0.03731[0m[0m | time: 7.088s
[2K
| Adam | epoch: 028 | loss: 0.03731 - acc: 0.9896 -- iter: 0320/1094
[A[ATraining Step: 956  | total loss: [1m[32m0.03429[0m[0m | time: 7.754s
[2K
| Adam | epoch: 028 | loss: 0.03429 - acc: 0.9906 -- iter: 0352/1094
[A[ATraining Step: 957  | total loss: [1m[32m0.03299[0m[0m | time: 8.503s
[2K
| Adam | epoch: 028 | loss: 0.03299 - acc: 0.9916 -- iter: 0384/1094
[A[ATraining Step: 958  | total loss: [1m[32m0.03610[0m[0m | time: 9.210s
[2K
| Adam | epoch: 028 | loss: 0.03610 - acc: 0.9862 -- iter: 0416/1094
[A[ATraining Step: 959  | total loss: [1m[32m0.04893[0m[0m | time: 9.928s
[2K
| Adam | epoch: 028 | loss: 0.04893 - acc: 0.9844 -- iter: 0448/1094
[A[ATraining Step: 960  | total loss: [1m[32m0.04698[0m[0m | time: 10.582s
[2K
| Adam | epoch: 028 | loss: 0.04698 - acc: 0.9829 -- iter: 0480/1094
[A[ATraining Step: 961  | total loss: [1m[32m0.05168[0m[0m | time: 11.223s
[2K
| Adam | epoch: 028 | loss: 0.05168 - acc: 0.9814 -- iter: 0512/1094
[A[ATraining Step: 962  | total loss: [1m[32m0.04934[0m[0m | time: 11.883s
[2K
| Adam | epoch: 028 | loss: 0.04934 - acc: 0.9833 -- iter: 0544/1094
[A[ATraining Step: 963  | total loss: [1m[32m0.06092[0m[0m | time: 12.594s
[2K
| Adam | epoch: 028 | loss: 0.06092 - acc: 0.9818 -- iter: 0576/1094
[A[ATraining Step: 964  | total loss: [1m[32m0.08717[0m[0m | time: 13.248s
[2K
| Adam | epoch: 028 | loss: 0.08717 - acc: 0.9712 -- iter: 0608/1094
[A[ATraining Step: 965  | total loss: [1m[32m0.08075[0m[0m | time: 13.898s
[2K
| Adam | epoch: 028 | loss: 0.08075 - acc: 0.9740 -- iter: 0640/1094
[A[ATraining Step: 966  | total loss: [1m[32m0.07383[0m[0m | time: 14.549s
[2K
| Adam | epoch: 028 | loss: 0.07383 - acc: 0.9766 -- iter: 0672/1094
[A[ATraining Step: 967  | total loss: [1m[32m0.06694[0m[0m | time: 15.236s
[2K
| Adam | epoch: 028 | loss: 0.06694 - acc: 0.9790 -- iter: 0704/1094
[A[ATraining Step: 968  | total loss: [1m[32m0.06128[0m[0m | time: 15.942s
[2K
| Adam | epoch: 028 | loss: 0.06128 - acc: 0.9811 -- iter: 0736/1094
[A[ATraining Step: 969  | total loss: [1m[32m0.06370[0m[0m | time: 16.668s
[2K
| Adam | epoch: 028 | loss: 0.06370 - acc: 0.9798 -- iter: 0768/1094
[A[ATraining Step: 970  | total loss: [1m[32m0.05835[0m[0m | time: 17.368s
[2K
| Adam | epoch: 028 | loss: 0.05835 - acc: 0.9819 -- iter: 0800/1094
[A[ATraining Step: 971  | total loss: [1m[32m0.05533[0m[0m | time: 17.530s
[2K
| Adam | epoch: 028 | loss: 0.05533 - acc: 0.9837 -- iter: 0832/1094
[A[ATraining Step: 972  | total loss: [1m[32m0.05077[0m[0m | time: 17.695s
[2K
| Adam | epoch: 028 | loss: 0.05077 - acc: 0.9853 -- iter: 0864/1094
[A[ATraining Step: 973  | total loss: [1m[32m0.04657[0m[0m | time: 18.391s
[2K
| Adam | epoch: 028 | loss: 0.04657 - acc: 0.9868 -- iter: 0896/1094
[A[ATraining Step: 974  | total loss: [1m[32m0.05173[0m[0m | time: 19.559s
[2K
| Adam | epoch: 028 | loss: 0.05173 - acc: 0.9850 -- iter: 0928/1094
[A[ATraining Step: 975  | total loss: [1m[32m0.06031[0m[0m | time: 20.655s
[2K
| Adam | epoch: 028 | loss: 0.06031 - acc: 0.9834 -- iter: 0960/1094
[A[ATraining Step: 976  | total loss: [1m[32m0.07848[0m[0m | time: 21.425s
[2K
| Adam | epoch: 028 | loss: 0.07848 - acc: 0.9819 -- iter: 0992/1094
[A[ATraining Step: 977  | total loss: [1m[32m0.07190[0m[0m | time: 22.307s
[2K
| Adam | epoch: 028 | loss: 0.07190 - acc: 0.9837 -- iter: 1024/1094
[A[ATraining Step: 978  | total loss: [1m[32m0.06552[0m[0m | time: 23.299s
[2K
| Adam | epoch: 028 | loss: 0.06552 - acc: 0.9853 -- iter: 1056/1094
[A[ATraining Step: 979  | total loss: [1m[32m0.06074[0m[0m | time: 24.245s
[2K
| Adam | epoch: 028 | loss: 0.06074 - acc: 0.9868 -- iter: 1088/1094
[A[ATraining Step: 980  | total loss: [1m[32m0.05946[0m[0m | time: 27.347s
[2K
| Adam | epoch: 028 | loss: 0.05946 - acc: 0.9850 | val_loss: 0.72780 - val_acc: 0.7843 -- iter: 1094/1094
--
Training Step: 981  | total loss: [1m[32m0.05474[0m[0m | time: 1.057s
[2K
| Adam | epoch: 029 | loss: 0.05474 - acc: 0.9865 -- iter: 0032/1094
[A[ATraining Step: 982  | total loss: [1m[32m0.06950[0m[0m | time: 1.824s
[2K
| Adam | epoch: 029 | loss: 0.06950 - acc: 0.9785 -- iter: 0064/1094
[A[ATraining Step: 983  | total loss: [1m[32m0.06586[0m[0m | time: 2.769s
[2K
| Adam | epoch: 029 | loss: 0.06586 - acc: 0.9806 -- iter: 0096/1094
[A[ATraining Step: 984  | total loss: [1m[32m0.06044[0m[0m | time: 3.775s
[2K
| Adam | epoch: 029 | loss: 0.06044 - acc: 0.9826 -- iter: 0128/1094
[A[ATraining Step: 985  | total loss: [1m[32m0.06114[0m[0m | time: 4.759s
[2K
| Adam | epoch: 029 | loss: 0.06114 - acc: 0.9812 -- iter: 0160/1094
[A[ATraining Step: 986  | total loss: [1m[32m0.05585[0m[0m | time: 5.739s
[2K
| Adam | epoch: 029 | loss: 0.05585 - acc: 0.9831 -- iter: 0192/1094
[A[ATraining Step: 987  | total loss: [1m[32m0.05121[0m[0m | time: 6.739s
[2K
| Adam | epoch: 029 | loss: 0.05121 - acc: 0.9848 -- iter: 0224/1094
[A[ATraining Step: 988  | total loss: [1m[32m0.04663[0m[0m | time: 7.766s
[2K
| Adam | epoch: 029 | loss: 0.04663 - acc: 0.9863 -- iter: 0256/1094
[A[ATraining Step: 989  | total loss: [1m[32m0.04376[0m[0m | time: 8.743s
[2K
| Adam | epoch: 029 | loss: 0.04376 - acc: 0.9877 -- iter: 0288/1094
[A[ATraining Step: 990  | total loss: [1m[32m0.04160[0m[0m | time: 9.654s
[2K
| Adam | epoch: 029 | loss: 0.04160 - acc: 0.9889 -- iter: 0320/1094
[A[ATraining Step: 991  | total loss: [1m[32m0.03894[0m[0m | time: 10.732s
[2K
| Adam | epoch: 029 | loss: 0.03894 - acc: 0.9900 -- iter: 0352/1094
[A[ATraining Step: 992  | total loss: [1m[32m0.03619[0m[0m | time: 11.831s
[2K
| Adam | epoch: 029 | loss: 0.03619 - acc: 0.9910 -- iter: 0384/1094
[A[ATraining Step: 993  | total loss: [1m[32m0.03316[0m[0m | time: 12.590s
[2K
| Adam | epoch: 029 | loss: 0.03316 - acc: 0.9919 -- iter: 0416/1094
[A[ATraining Step: 994  | total loss: [1m[32m0.03177[0m[0m | time: 13.528s
[2K
| Adam | epoch: 029 | loss: 0.03177 - acc: 0.9927 -- iter: 0448/1094
[A[ATraining Step: 995  | total loss: [1m[32m0.02963[0m[0m | time: 14.594s
[2K
| Adam | epoch: 029 | loss: 0.02963 - acc: 0.9934 -- iter: 0480/1094
[A[ATraining Step: 996  | total loss: [1m[32m0.04352[0m[0m | time: 15.537s
[2K
| Adam | epoch: 029 | loss: 0.04352 - acc: 0.9878 -- iter: 0512/1094
[A[ATraining Step: 997  | total loss: [1m[32m0.03961[0m[0m | time: 16.507s
[2K
| Adam | epoch: 029 | loss: 0.03961 - acc: 0.9891 -- iter: 0544/1094
[A[ATraining Step: 998  | total loss: [1m[32m0.03605[0m[0m | time: 17.519s
[2K
| Adam | epoch: 029 | loss: 0.03605 - acc: 0.9902 -- iter: 0576/1094
[A[ATraining Step: 999  | total loss: [1m[32m0.04200[0m[0m | time: 18.429s
[2K
| Adam | epoch: 029 | loss: 0.04200 - acc: 0.9880 -- iter: 0608/1094
[A[ATraining Step: 1000  | total loss: [1m[32m0.03852[0m[0m | time: 21.465s
[2K
| Adam | epoch: 029 | loss: 0.03852 - acc: 0.9892 | val_loss: 0.71963 - val_acc: 0.8105 -- iter: 0640/1094
--
Training Step: 1001  | total loss: [1m[32m0.03531[0m[0m | time: 22.394s
[2K
| Adam | epoch: 029 | loss: 0.03531 - acc: 0.9903 -- iter: 0672/1094
[A[ATraining Step: 1002  | total loss: [1m[32m0.03233[0m[0m | time: 23.335s
[2K
| Adam | epoch: 029 | loss: 0.03233 - acc: 0.9913 -- iter: 0704/1094
[A[ATraining Step: 1003  | total loss: [1m[32m0.02948[0m[0m | time: 24.273s
[2K
| Adam | epoch: 029 | loss: 0.02948 - acc: 0.9921 -- iter: 0736/1094
[A[ATraining Step: 1004  | total loss: [1m[32m0.02699[0m[0m | time: 25.279s
[2K
| Adam | epoch: 029 | loss: 0.02699 - acc: 0.9929 -- iter: 0768/1094
[A[ATraining Step: 1005  | total loss: [1m[32m0.02460[0m[0m | time: 26.332s
[2K
| Adam | epoch: 029 | loss: 0.02460 - acc: 0.9936 -- iter: 0800/1094
[A[ATraining Step: 1006  | total loss: [1m[32m0.02287[0m[0m | time: 27.358s
[2K
| Adam | epoch: 029 | loss: 0.02287 - acc: 0.9943 -- iter: 0832/1094
[A[ATraining Step: 1007  | total loss: [1m[32m0.02102[0m[0m | time: 27.595s
[2K
| Adam | epoch: 029 | loss: 0.02102 - acc: 0.9948 -- iter: 0864/1094
[A[ATraining Step: 1008  | total loss: [1m[32m0.01935[0m[0m | time: 27.832s
[2K
| Adam | epoch: 029 | loss: 0.01935 - acc: 0.9954 -- iter: 0896/1094
[A[ATraining Step: 1009  | total loss: [1m[32m0.01794[0m[0m | time: 28.755s
[2K
| Adam | epoch: 029 | loss: 0.01794 - acc: 0.9958 -- iter: 0928/1094
[A[ATraining Step: 1010  | total loss: [1m[32m0.01656[0m[0m | time: 29.759s
[2K
| Adam | epoch: 029 | loss: 0.01656 - acc: 0.9962 -- iter: 0960/1094
[A[ATraining Step: 1011  | total loss: [1m[32m0.01520[0m[0m | time: 30.881s
[2K
| Adam | epoch: 029 | loss: 0.01520 - acc: 0.9966 -- iter: 0992/1094
[A[ATraining Step: 1012  | total loss: [1m[32m0.01393[0m[0m | time: 31.758s
[2K
| Adam | epoch: 029 | loss: 0.01393 - acc: 0.9970 -- iter: 1024/1094
[A[ATraining Step: 1013  | total loss: [1m[32m0.01275[0m[0m | time: 32.679s
[2K
| Adam | epoch: 029 | loss: 0.01275 - acc: 0.9973 -- iter: 1056/1094
[A[ATraining Step: 1014  | total loss: [1m[32m0.01180[0m[0m | time: 33.639s
[2K
| Adam | epoch: 029 | loss: 0.01180 - acc: 0.9975 -- iter: 1088/1094
[A[ATraining Step: 1015  | total loss: [1m[32m0.01263[0m[0m | time: 36.625s
[2K
| Adam | epoch: 029 | loss: 0.01263 - acc: 0.9978 | val_loss: 0.77494 - val_acc: 0.8134 -- iter: 1094/1094
--
Training Step: 1016  | total loss: [1m[32m0.01178[0m[0m | time: 1.089s
[2K
| Adam | epoch: 030 | loss: 0.01178 - acc: 0.9980 -- iter: 0032/1094
[A[ATraining Step: 1017  | total loss: [1m[32m0.01113[0m[0m | time: 2.147s
[2K
| Adam | epoch: 030 | loss: 0.01113 - acc: 0.9982 -- iter: 0064/1094
[A[ATraining Step: 1018  | total loss: [1m[32m0.01022[0m[0m | time: 2.946s
[2K
| Adam | epoch: 030 | loss: 0.01022 - acc: 0.9984 -- iter: 0096/1094
[A[ATraining Step: 1019  | total loss: [1m[32m0.02548[0m[0m | time: 3.910s
[2K
| Adam | epoch: 030 | loss: 0.02548 - acc: 0.9954 -- iter: 0128/1094
[A[ATraining Step: 1020  | total loss: [1m[32m0.02316[0m[0m | time: 4.865s
[2K
| Adam | epoch: 030 | loss: 0.02316 - acc: 0.9959 -- iter: 0160/1094
[A[ATraining Step: 1021  | total loss: [1m[32m0.02103[0m[0m | time: 5.822s
[2K
| Adam | epoch: 030 | loss: 0.02103 - acc: 0.9963 -- iter: 0192/1094
[A[ATraining Step: 1022  | total loss: [1m[32m0.01910[0m[0m | time: 6.760s
[2K
| Adam | epoch: 030 | loss: 0.01910 - acc: 0.9967 -- iter: 0224/1094
[A[ATraining Step: 1023  | total loss: [1m[32m0.01750[0m[0m | time: 7.717s
[2K
| Adam | epoch: 030 | loss: 0.01750 - acc: 0.9970 -- iter: 0256/1094
[A[ATraining Step: 1024  | total loss: [1m[32m0.01601[0m[0m | time: 8.710s
[2K
| Adam | epoch: 030 | loss: 0.01601 - acc: 0.9973 -- iter: 0288/1094
[A[ATraining Step: 1025  | total loss: [1m[32m0.01594[0m[0m | time: 9.687s
[2K
| Adam | epoch: 030 | loss: 0.01594 - acc: 0.9976 -- iter: 0320/1094
[A[ATraining Step: 1026  | total loss: [1m[32m0.01462[0m[0m | time: 10.700s
[2K
| Adam | epoch: 030 | loss: 0.01462 - acc: 0.9978 -- iter: 0352/1094
[A[ATraining Step: 1027  | total loss: [1m[32m0.01366[0m[0m | time: 11.776s
[2K
| Adam | epoch: 030 | loss: 0.01366 - acc: 0.9980 -- iter: 0384/1094
[A[ATraining Step: 1028  | total loss: [1m[32m0.01297[0m[0m | time: 12.778s
[2K
| Adam | epoch: 030 | loss: 0.01297 - acc: 0.9982 -- iter: 0416/1094
[A[ATraining Step: 1029  | total loss: [1m[32m0.01781[0m[0m | time: 13.555s
[2K
| Adam | epoch: 030 | loss: 0.01781 - acc: 0.9953 -- iter: 0448/1094
[A[ATraining Step: 1030  | total loss: [1m[32m0.01767[0m[0m | time: 14.480s
[2K
| Adam | epoch: 030 | loss: 0.01767 - acc: 0.9957 -- iter: 0480/1094
[A[ATraining Step: 1031  | total loss: [1m[32m0.01630[0m[0m | time: 15.499s
[2K
| Adam | epoch: 030 | loss: 0.01630 - acc: 0.9962 -- iter: 0512/1094
[A[ATraining Step: 1032  | total loss: [1m[32m0.01589[0m[0m | time: 16.483s
[2K
| Adam | epoch: 030 | loss: 0.01589 - acc: 0.9966 -- iter: 0544/1094
[A[ATraining Step: 1033  | total loss: [1m[32m0.01480[0m[0m | time: 17.506s
[2K
| Adam | epoch: 030 | loss: 0.01480 - acc: 0.9969 -- iter: 0576/1094
[A[ATraining Step: 1034  | total loss: [1m[32m0.01426[0m[0m | time: 18.488s
[2K
| Adam | epoch: 030 | loss: 0.01426 - acc: 0.9972 -- iter: 0608/1094
[A[ATraining Step: 1035  | total loss: [1m[32m0.01321[0m[0m | time: 19.479s
[2K
| Adam | epoch: 030 | loss: 0.01321 - acc: 0.9975 -- iter: 0640/1094
[A[ATraining Step: 1036  | total loss: [1m[32m0.01239[0m[0m | time: 20.439s
[2K
| Adam | epoch: 030 | loss: 0.01239 - acc: 0.9977 -- iter: 0672/1094
[A[ATraining Step: 1037  | total loss: [1m[32m0.01169[0m[0m | time: 21.413s
[2K
| Adam | epoch: 030 | loss: 0.01169 - acc: 0.9980 -- iter: 0704/1094
[A[ATraining Step: 1038  | total loss: [1m[32m0.01068[0m[0m | time: 22.423s
[2K
| Adam | epoch: 030 | loss: 0.01068 - acc: 0.9982 -- iter: 0736/1094
[A[ATraining Step: 1039  | total loss: [1m[32m0.01800[0m[0m | time: 23.401s
[2K
| Adam | epoch: 030 | loss: 0.01800 - acc: 0.9952 -- iter: 0768/1094
[A[ATraining Step: 1040  | total loss: [1m[32m0.03273[0m[0m | time: 24.177s
[2K
| Adam | epoch: 030 | loss: 0.03273 - acc: 0.9926 -- iter: 0800/1094
[A[ATraining Step: 1041  | total loss: [1m[32m0.02960[0m[0m | time: 25.094s
[2K
| Adam | epoch: 030 | loss: 0.02960 - acc: 0.9933 -- iter: 0832/1094
[A[ATraining Step: 1042  | total loss: [1m[32m0.04699[0m[0m | time: 26.072s
[2K
| Adam | epoch: 030 | loss: 0.04699 - acc: 0.9909 -- iter: 0864/1094
[A[ATraining Step: 1043  | total loss: [1m[32m0.04250[0m[0m | time: 26.309s
[2K
| Adam | epoch: 030 | loss: 0.04250 - acc: 0.9918 -- iter: 0896/1094
[A[ATraining Step: 1044  | total loss: [1m[32m0.05330[0m[0m | time: 26.533s
[2K
| Adam | epoch: 030 | loss: 0.05330 - acc: 0.9926 -- iter: 0928/1094
[A[ATraining Step: 1045  | total loss: [1m[32m0.04873[0m[0m | time: 27.543s
[2K
| Adam | epoch: 030 | loss: 0.04873 - acc: 0.9933 -- iter: 0960/1094
[A[ATraining Step: 1046  | total loss: [1m[32m0.04411[0m[0m | time: 28.572s
[2K
| Adam | epoch: 030 | loss: 0.04411 - acc: 0.9940 -- iter: 0992/1094
[A[ATraining Step: 1047  | total loss: [1m[32m0.04042[0m[0m | time: 29.540s
[2K
| Adam | epoch: 030 | loss: 0.04042 - acc: 0.9946 -- iter: 1024/1094
[A[ATraining Step: 1048  | total loss: [1m[32m0.11641[0m[0m | time: 30.540s
[2K
| Adam | epoch: 030 | loss: 0.11641 - acc: 0.9826 -- iter: 1056/1094
[A[ATraining Step: 1049  | total loss: [1m[32m0.10501[0m[0m | time: 31.482s
[2K
| Adam | epoch: 030 | loss: 0.10501 - acc: 0.9844 -- iter: 1088/1094
[A[ATraining Step: 1050  | total loss: [1m[32m0.09652[0m[0m | time: 34.568s
[2K
| Adam | epoch: 030 | loss: 0.09652 - acc: 0.9859 | val_loss: 0.74499 - val_acc: 0.8076 -- iter: 1094/1094
--
2018-08-02 03:23:42.416558: W tensorflow/core/framework/allocator.cc:101] Allocation of 3106471424 exceeds 10% of system memory.
2018-08-02 03:23:43.666548: W tensorflow/core/framework/allocator.cc:101] Allocation of 3106471424 exceeds 10% of system memory.
Validation AUC:0.8701122067324039
Validation AUPRC:0.8907776309086927
Test AUC:0.8892742977623613
Test AUPRC:0.8916145847025422
BestTestF1Score	0.84	0.68	0.84	0.87	0.81	141	22	147	33	0.55
BestTestMCCScore	0.79	0.63	0.81	0.9	0.7	122	14	155	52	0.93
BestTestAccuracyScore	0.79	0.63	0.81	0.9	0.7	122	14	155	52	0.93
BestValidationF1Score	0.81	0.63	0.81	0.82	0.81	137	31	142	33	0.55
BestValidationMCC	0.8	0.65	0.82	0.88	0.74	126	18	155	44	0.93
BestValidationAccuracy	0.8	0.65	0.82	0.88	0.74	126	18	155	44	0.93
TestPredictions (Threshold:0.93)
CHEMBL3648058,TP,ACT,1.0	CHEMBL57143,TP,ACT,0.9900000095367432	CHEMBL279481,TN,INACT,0.009999999776482582	CHEMBL200735,TP,ACT,1.0	CHEMBL3628816,TN,INACT,0.019999999552965164	CHEMBL2180604,TP,ACT,0.9700000286102295	CHEMBL1258603,TP,ACT,0.9900000095367432	CHEMBL275117,FN,ACT,0.5699999928474426	CHEMBL3098319,TN,INACT,0.0	CHEMBL2392234,TN,INACT,0.0	CHEMBL184753,TP,ACT,1.0	CHEMBL309331,FN,ACT,0.0	CHEMBL1171273,TN,INACT,0.019999999552965164	CHEMBL125277,TP,ACT,0.9900000095367432	CHEMBL3651228,FN,ACT,0.5699999928474426	CHEMBL1830260,TN,INACT,0.0	CHEMBL514499,TP,ACT,0.9800000190734863	CHEMBL440213,TN,INACT,0.0	CHEMBL100542,TP,ACT,0.9900000095367432	CHEMBL185597,TP,ACT,1.0	CHEMBL1922120,TN,INACT,0.0	CHEMBL100736,TP,ACT,1.0	CHEMBL1241679,TN,INACT,0.009999999776482582	CHEMBL556874,FP,INACT,0.9900000095367432	CHEMBL343209,TP,ACT,1.0	CHEMBL517154,TN,INACT,0.0	CHEMBL2203434,TP,ACT,1.0	CHEMBL406375,FN,ACT,0.019999999552965164	CHEMBL67655,FP,INACT,0.9800000190734863	CHEMBL488811,TN,INACT,0.0	CHEMBL3237855,FP,INACT,0.9800000190734863	CHEMBL522732,TP,ACT,1.0	CHEMBL1276890,TP,ACT,0.9900000095367432	CHEMBL2430259,TP,ACT,1.0	CHEMBL55993,TN,INACT,0.0	CHEMBL492809,TP,ACT,0.9399999976158142	CHEMBL565084,TN,INACT,0.0	CHEMBL524820,TN,INACT,0.009999999776482582	CHEMBL184913,TP,ACT,1.0	CHEMBL2208034,TP,ACT,0.9599999785423279	CHEMBL1908394,TP,ACT,0.9900000095367432	CHEMBL3690080,TP,ACT,0.9700000286102295	CHEMBL519590,TN,INACT,0.07999999821186066	CHEMBL322659,TP,ACT,1.0	CHEMBL1241582,TN,INACT,0.0	CHEMBL105227,TP,ACT,1.0	CHEMBL360756,TP,ACT,1.0	CHEMBL2023488,FN,ACT,0.30000001192092896	CHEMBL259381,TN,INACT,0.0	CHEMBL1630114,TP,ACT,0.9900000095367432	CHEMBL594228,TP,ACT,1.0	CHEMBL485878,TN,INACT,0.8899999856948853	CHEMBL1242290,TN,INACT,0.0	CHEMBL432396,TN,INACT,0.029999999329447746	CHEMBL3702618,FN,ACT,0.019999999552965164	CHEMBL1762119,TN,INACT,0.0	CHEMBL477772,TP,ACT,0.9399999976158142	CHEMBL75232,TP,ACT,0.949999988079071	CHEMBL1668412,TN,INACT,0.0	CHEMBL125811,TP,ACT,0.9900000095367432	CHEMBL435831,TN,INACT,0.0	CHEMBL3809935,FN,ACT,0.0	CHEMBL3623375,TP,ACT,1.0	CHEMBL183923,TP,ACT,1.0	CHEMBL322464,FP,INACT,1.0	CHEMBL456378,TN,INACT,0.0	CHEMBL103870,TP,ACT,1.0	CHEMBL445636,TP,ACT,1.0	CHEMBL1944928,TN,INACT,0.0	CHEMBL1080580,FN,ACT,0.009999999776482582	CHEMBL3702605,FN,ACT,0.019999999552965164	CHEMBL2023118,TP,ACT,1.0	CHEMBL1956896,TN,INACT,0.009999999776482582	CHEMBL2430249,TP,ACT,0.9700000286102295	CHEMBL363901,TP,ACT,1.0	CHEMBL482715,TN,INACT,0.0	CHEMBL2047251,TN,INACT,0.009999999776482582	CHEMBL184231,FP,INACT,0.9900000095367432	CHEMBL157304,TN,INACT,0.0	CHEMBL75637,TN,INACT,0.14000000059604645	CHEMBL125028,TP,ACT,1.0	CHEMBL1241301,TN,INACT,0.029999999329447746	CHEMBL1172147,TN,INACT,0.0	CHEMBL1241588,TN,INACT,0.0	CHEMBL116012,TN,INACT,0.009999999776482582	CHEMBL431006,FN,ACT,0.4399999976158142	CHEMBL3798556,TN,INACT,0.0	CHEMBL293749,TN,INACT,0.0	CHEMBL1242034,TN,INACT,0.0	CHEMBL576982,TP,ACT,1.0	CHEMBL338619,TP,ACT,1.0	CHEMBL3217993,TN,INACT,0.6600000262260437	CHEMBL495735,FN,ACT,0.8799999952316284	CHEMBL200976,FN,ACT,0.8399999737739563	CHEMBL1945804,TP,ACT,0.9900000095367432	CHEMBL1087055,TN,INACT,0.0	CHEMBL1241482,TN,INACT,0.0	CHEMBL89697,TN,INACT,0.10000000149011612	CHEMBL1721885,FN,ACT,0.8700000047683716	CHEMBL3403513,FN,ACT,0.05999999865889549	CHEMBL1221633,TN,INACT,0.0	CHEMBL3358992,TP,ACT,0.9700000286102295	CHEMBL1929314,TN,INACT,0.0	CHEMBL146993,TP,ACT,1.0	CHEMBL62701,TN,INACT,0.0	CHEMBL87208,FN,ACT,0.0	CHEMBL559069,TN,INACT,0.3400000035762787	CHEMBL2023802,TP,ACT,1.0	CHEMBL102330,TP,ACT,1.0	CHEMBL1082940,TN,INACT,0.03999999910593033	CHEMBL603469,FN,ACT,0.0	CHEMBL119385,FN,ACT,0.9100000262260437	CHEMBL395666,TN,INACT,0.38999998569488525	CHEMBL591457,TN,INACT,0.0	CHEMBL3353407,TN,INACT,0.0	CHEMBL529663,TN,INACT,0.09000000357627869	CHEMBL551936,TN,INACT,0.0	CHEMBL1630110,TP,ACT,1.0	CHEMBL2036728,TN,INACT,0.6700000166893005	CHEMBL3403512,FN,ACT,0.029999999329447746	CHEMBL557321,TN,INACT,0.0	CHEMBL363057,FN,ACT,0.9200000166893005	CHEMBL591706,TN,INACT,0.0	CHEMBL1828876,TN,INACT,0.0	CHEMBL134354,TN,INACT,0.0	CHEMBL100735,TP,ACT,1.0	CHEMBL541988,TN,INACT,0.14000000059604645	CHEMBL493315,FN,ACT,0.4399999976158142	CHEMBL2430258,TP,ACT,1.0	CHEMBL589165,TN,INACT,0.0	CHEMBL184118,TP,ACT,1.0	CHEMBL2335379,TN,INACT,0.0	CHEMBL3361128,TN,INACT,0.3100000023841858	CHEMBL1929555,FN,ACT,0.009999999776482582	CHEMBL2437301,TN,INACT,0.019999999552965164	CHEMBL557050,TN,INACT,0.0	CHEMBL104325,TP,ACT,1.0	CHEMBL102427,TP,ACT,1.0	CHEMBL318358,TP,ACT,1.0	CHEMBL127753,TP,ACT,0.9800000190734863	CHEMBL1172419,TN,INACT,0.0	CHEMBL3403516,TP,ACT,0.9800000190734863	CHEMBL595143,TP,ACT,1.0	CHEMBL390156,TN,INACT,0.009999999776482582	CHEMBL488646,TN,INACT,0.05000000074505806	CHEMBL3702603,TP,ACT,0.949999988079071	CHEMBL2029690,TN,INACT,0.029999999329447746	CHEMBL200774,TP,ACT,0.9599999785423279	CHEMBL344091,TP,ACT,1.0	CHEMBL104896,FN,ACT,0.9100000262260437	CHEMBL449593,TP,ACT,1.0	CHEMBL324399,TN,INACT,0.07000000029802322	CHEMBL3358967,TP,ACT,0.9900000095367432	CHEMBL526507,TP,ACT,0.9900000095367432	CHEMBL74645,TN,INACT,0.05999999865889549	CHEMBL199865,TN,INACT,0.009999999776482582	CHEMBL3621299,FN,ACT,0.6200000047683716	CHEMBL521201,TN,INACT,0.3400000035762787	CHEMBL105183,TP,ACT,1.0	CHEMBL59812,TN,INACT,0.0	CHEMBL288441,FN,ACT,0.9200000166893005	CHEMBL1161234,TN,INACT,0.009999999776482582	CHEMBL2392236,TN,INACT,0.0	CHEMBL483298,FP,INACT,0.9900000095367432	CHEMBL189059,TN,INACT,0.0	CHEMBL486487,FP,INACT,0.9700000286102295	CHEMBL209511,TN,INACT,0.0	CHEMBL125445,TP,ACT,1.0	CHEMBL2023119,FN,ACT,0.7099999785423279	CHEMBL1241950,TN,INACT,0.0	CHEMBL2337368,TN,INACT,0.8600000143051147	CHEMBL113985,TN,INACT,0.05000000074505806	CHEMBL55496,FN,ACT,0.6399999856948853	CHEMBL509435,TN,INACT,0.28999999165534973	CHEMBL525065,TN,INACT,0.009999999776482582	CHEMBL480356,TP,ACT,0.9900000095367432	CHEMBL395664,TN,INACT,0.09000000357627869	CHEMBL1084117,TN,INACT,0.029999999329447746	CHEMBL592224,TN,INACT,0.019999999552965164	CHEMBL1829274,TN,INACT,0.0	CHEMBL154822,TN,INACT,0.0	CHEMBL57229,TN,INACT,0.009999999776482582	CHEMBL3702662,FN,ACT,0.0	CHEMBL1940104,TP,ACT,1.0	CHEMBL1241863,TN,INACT,0.0	CHEMBL147761,TP,ACT,0.9900000095367432	CHEMBL405059,FP,INACT,0.9800000190734863	CHEMBL1277071,FN,ACT,0.07999999821186066	CHEMBL1829272,TN,INACT,0.0	CHEMBL408565,FN,ACT,0.27000001072883606	CHEMBL3358995,TP,ACT,0.9900000095367432	CHEMBL387300,TN,INACT,0.8500000238418579	CHEMBL1940116,TP,ACT,1.0	CHEMBL2430248,TP,ACT,0.949999988079071	CHEMBL3358976,TN,INACT,0.019999999552965164	CHEMBL1242380,TN,INACT,0.10000000149011612	CHEMBL2335376,TN,INACT,0.0	CHEMBL154260,TN,INACT,0.0	CHEMBL1242032,TN,INACT,0.0	CHEMBL3651249,FN,ACT,0.03999999910593033	CHEMBL1278234,TP,ACT,0.9900000095367432	CHEMBL324371,TN,INACT,0.0	CHEMBL148225,TP,ACT,0.9900000095367432	CHEMBL3133834,TN,INACT,0.0	CHEMBL59099,TN,INACT,0.009999999776482582	CHEMBL3358969,FN,ACT,0.18000000715255737	CHEMBL1933806,FP,INACT,0.9900000095367432	CHEMBL267118,TN,INACT,0.009999999776482582	CHEMBL345862,TN,INACT,0.0	CHEMBL320645,TP,ACT,0.9900000095367432	CHEMBL358243,TN,INACT,0.0	CHEMBL75034,FN,ACT,0.7300000190734863	CHEMBL318461,TN,INACT,0.03999999910593033	CHEMBL1242207,TN,INACT,0.0	CHEMBL313578,FN,ACT,0.18000000715255737	CHEMBL50,TN,INACT,0.019999999552965164	CHEMBL1945498,TP,ACT,0.9800000190734863	CHEMBL2023487,FN,ACT,0.5400000214576721	CHEMBL76985,TN,INACT,0.0	CHEMBL1240703,TP,ACT,0.9700000286102295	CHEMBL6246,FN,ACT,0.0	CHEMBL144687,TP,ACT,1.0	CHEMBL258694,FN,ACT,0.5099999904632568	CHEMBL3806189,TP,ACT,0.9900000095367432	CHEMBL1276308,TN,INACT,0.0	CHEMBL20926,TN,INACT,0.009999999776482582	CHEMBL2429872,TP,ACT,1.0	CHEMBL125898,TP,ACT,1.0	CHEMBL3358978,TP,ACT,0.9900000095367432	CHEMBL3644547,TP,ACT,0.9900000095367432	CHEMBL1094423,FN,ACT,0.0	CHEMBL371910,FN,ACT,0.0	CHEMBL498348,TP,ACT,0.9900000095367432	CHEMBL231526,TP,ACT,1.0	CHEMBL132089,TN,INACT,0.0	CHEMBL109625,TN,INACT,0.009999999776482582	CHEMBL3690083,TP,ACT,0.9900000095367432	CHEMBL340157,TP,ACT,0.9900000095367432	CHEMBL511337,FN,ACT,0.0	CHEMBL77085,TN,INACT,0.0	CHEMBL147277,TP,ACT,0.9900000095367432	CHEMBL226131,FP,INACT,1.0	CHEMBL1172697,TN,INACT,0.0	CHEMBL318485,TN,INACT,0.019999999552965164	CHEMBL1277072,FN,ACT,0.07999999821186066	CHEMBL521155,TN,INACT,0.019999999552965164	CHEMBL200726,TP,ACT,0.9599999785423279	CHEMBL382735,TP,ACT,0.9700000286102295	CHEMBL2430262,FN,ACT,0.6899999976158142	CHEMBL404939,TN,INACT,0.05000000074505806	CHEMBL152995,TN,INACT,0.0	CHEMBL3628799,FN,ACT,0.9200000166893005	CHEMBL2011301,TN,INACT,0.019999999552965164	CHEMBL1221415,TN,INACT,0.05999999865889549	CHEMBL1956068,FN,ACT,0.9100000262260437	CHEMBL485321,TN,INACT,0.10000000149011612	CHEMBL318188,TN,INACT,0.019999999552965164	CHEMBL75196,TP,ACT,1.0	CHEMBL3696097,TP,ACT,1.0	CHEMBL91,TN,INACT,0.0	CHEMBL589259,TN,INACT,0.6899999976158142	CHEMBL501368,TN,INACT,0.0	CHEMBL2430251,TP,ACT,0.9599999785423279	CHEMBL183929,TP,ACT,1.0	CHEMBL339974,TP,ACT,1.0	CHEMBL347074,FN,ACT,0.6000000238418579	CHEMBL549303,TN,INACT,0.0	CHEMBL86531,FP,INACT,0.9800000190734863	CHEMBL300138,TP,ACT,0.9700000286102295	CHEMBL469346,TN,INACT,0.019999999552965164	CHEMBL593292,TP,ACT,1.0	CHEMBL3633276,FP,INACT,0.9900000095367432	CHEMBL414013,TN,INACT,0.25999999046325684	CHEMBL1242665,TN,INACT,0.0	CHEMBL2023117,TP,ACT,1.0	CHEMBL2023475,FN,ACT,0.009999999776482582	CHEMBL592240,TN,INACT,0.009999999776482582	CHEMBL498013,TP,ACT,1.0	CHEMBL2164696,TN,INACT,0.0	CHEMBL610512,TN,INACT,0.009999999776482582	CHEMBL127429,TP,ACT,0.9900000095367432	CHEMBL102136,TN,INACT,0.11999999731779099	CHEMBL76905,TN,INACT,0.0	CHEMBL3651298,TP,ACT,0.9700000286102295	CHEMBL103487,TP,ACT,1.0	CHEMBL1241864,TN,INACT,0.10000000149011612	CHEMBL3690075,TP,ACT,0.9599999785423279	CHEMBL3297899,TP,ACT,0.9900000095367432	CHEMBL515258,TP,ACT,0.9700000286102295	CHEMBL453336,TN,INACT,0.009999999776482582	CHEMBL444654,TN,INACT,0.0	CHEMBL232542,FP,INACT,1.0	CHEMBL543600,TN,INACT,0.009999999776482582	CHEMBL30432,FP,INACT,0.9900000095367432	CHEMBL1161235,TN,INACT,0.0	CHEMBL1940269,TP,ACT,1.0	CHEMBL554,TP,ACT,1.0	CHEMBL496762,TP,ACT,0.9900000095367432	CHEMBL515432,FN,ACT,0.4399999976158142	CHEMBL1221822,TN,INACT,0.0	CHEMBL3644550,TP,ACT,0.9900000095367432	CHEMBL1945501,TP,ACT,0.9599999785423279	CHEMBL509499,TN,INACT,0.0	CHEMBL3633690,TN,INACT,0.009999999776482582	CHEMBL374248,FN,ACT,0.1599999964237213	CHEMBL495530,FN,ACT,0.75	CHEMBL435227,FN,ACT,0.20999999344348907	CHEMBL154080,TN,INACT,0.0	CHEMBL1668418,FN,ACT,0.7699999809265137	CHEMBL3343366,TP,ACT,1.0	CHEMBL590083,TN,INACT,0.9100000262260437	CHEMBL352308,TP,ACT,1.0	CHEMBL153843,FN,ACT,0.009999999776482582	CHEMBL184078,TP,ACT,1.0	CHEMBL127748,TP,ACT,1.0	CHEMBL593245,TP,ACT,0.9900000095367432	CHEMBL332497,TN,INACT,0.07000000029802322	CHEMBL143986,TP,ACT,1.0	CHEMBL319894,TP,ACT,1.0	CHEMBL184244,TP,ACT,1.0	CHEMBL1821886,TN,INACT,0.0	CHEMBL340235,TP,ACT,1.0	CHEMBL460746,FN,ACT,0.0	CHEMBL125721,TP,ACT,1.0	CHEMBL1940108,TP,ACT,1.0	CHEMBL55683,TN,INACT,0.0	CHEMBL3297999,TP,ACT,0.9900000095367432	CHEMBL457180,TN,INACT,0.11999999731779099	CHEMBL3353355,TN,INACT,0.4699999988079071	CHEMBL1241948,TN,INACT,0.0	CHEMBL91250,TP,ACT,0.9700000286102295	CHEMBL336330,TN,INACT,0.05999999865889549	CHEMBL1097743,TN,INACT,0.0	CHEMBL3133906,TN,INACT,0.019999999552965164	CHEMBL3805409,TN,INACT,0.0	CHEMBL395665,TN,INACT,0.1899999976158142	CHEMBL500153,TN,INACT,0.0	CHEMBL419785,TP,ACT,0.9900000095367432	CHEMBL2337362,TN,INACT,0.8600000143051147	CHEMBL182515,TP,ACT,1.0	CHEMBL275575,TN,INACT,0.11999999731779099	CHEMBL1830258,TN,INACT,0.0	CHEMBL340439,TP,ACT,1.0	

