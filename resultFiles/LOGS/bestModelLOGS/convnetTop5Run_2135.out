CNNModel CHEMBL4080 adam 0.001 30 128 0 0.8 False True
Number of active compounds :	158
Number of inactive compounds :	158
---------------------------------
Run id: CNNModel_CHEMBL4080_adam_0.001_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4080_adam_0.001_30_128_0.8_True/
---------------------------------
Training samples: 182
Validation samples: 57
--
Training Step: 1  | time: 0.773s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/182
[A[ATraining Step: 2  | total loss: [1m[32m0.62421[0m[0m | time: 1.392s
[2K
| Adam | epoch: 001 | loss: 0.62421 - acc: 0.2812 -- iter: 064/182
[A[ATraining Step: 3  | total loss: [1m[32m0.67804[0m[0m | time: 2.029s
[2K
| Adam | epoch: 001 | loss: 0.67804 - acc: 0.5881 -- iter: 096/182
[A[ATraining Step: 4  | total loss: [1m[32m0.70301[0m[0m | time: 2.660s
[2K
| Adam | epoch: 001 | loss: 0.70301 - acc: 0.4283 -- iter: 128/182
[A[ATraining Step: 5  | total loss: [1m[32m0.69632[0m[0m | time: 3.290s
[2K
| Adam | epoch: 001 | loss: 0.69632 - acc: 0.4779 -- iter: 160/182
[A[ATraining Step: 6  | total loss: [1m[32m0.69185[0m[0m | time: 4.760s
[2K
| Adam | epoch: 001 | loss: 0.69185 - acc: 0.5524 | val_loss: 0.69166 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 7  | total loss: [1m[32m0.69272[0m[0m | time: 0.438s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5210 -- iter: 032/182
[A[ATraining Step: 8  | total loss: [1m[32m0.69282[0m[0m | time: 1.051s
[2K
| Adam | epoch: 002 | loss: 0.69282 - acc: 0.5092 -- iter: 064/182
[A[ATraining Step: 9  | total loss: [1m[32m0.69123[0m[0m | time: 1.675s
[2K
| Adam | epoch: 002 | loss: 0.69123 - acc: 0.5539 -- iter: 096/182
[A[ATraining Step: 10  | total loss: [1m[32m0.69095[0m[0m | time: 2.306s
[2K
| Adam | epoch: 002 | loss: 0.69095 - acc: 0.5582 -- iter: 128/182
[A[ATraining Step: 11  | total loss: [1m[32m0.69487[0m[0m | time: 2.936s
[2K
| Adam | epoch: 002 | loss: 0.69487 - acc: 0.4714 -- iter: 160/182
[A[ATraining Step: 12  | total loss: [1m[32m0.69300[0m[0m | time: 4.560s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5124 | val_loss: 0.69132 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 13  | total loss: [1m[32m0.69271[0m[0m | time: 0.432s
[2K
| Adam | epoch: 003 | loss: 0.69271 - acc: 0.5205 -- iter: 032/182
[A[ATraining Step: 14  | total loss: [1m[32m0.68926[0m[0m | time: 0.876s
[2K
| Adam | epoch: 003 | loss: 0.68926 - acc: 0.5865 -- iter: 064/182
[A[ATraining Step: 15  | total loss: [1m[32m0.68690[0m[0m | time: 1.528s
[2K
| Adam | epoch: 003 | loss: 0.68690 - acc: 0.6238 -- iter: 096/182
[A[ATraining Step: 16  | total loss: [1m[32m0.68774[0m[0m | time: 2.146s
[2K
| Adam | epoch: 003 | loss: 0.68774 - acc: 0.6008 -- iter: 128/182
[A[ATraining Step: 17  | total loss: [1m[32m0.68887[0m[0m | time: 2.773s
[2K
| Adam | epoch: 003 | loss: 0.68887 - acc: 0.5758 -- iter: 160/182
[A[ATraining Step: 18  | total loss: [1m[32m0.69075[0m[0m | time: 4.438s
[2K
| Adam | epoch: 003 | loss: 0.69075 - acc: 0.5495 | val_loss: 0.68963 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 19  | total loss: [1m[32m0.69481[0m[0m | time: 20.438s
[2K
| Adam | epoch: 004 | loss: 0.69481 - acc: 0.5122 -- iter: 032/182
[A[ATraining Step: 20  | total loss: [1m[32m0.68385[0m[0m | time: 37.670s
[2K
| Adam | epoch: 004 | loss: 0.68385 - acc: 0.5987 -- iter: 064/182
[A[ATraining Step: 21  | total loss: [1m[32m0.69182[0m[0m | time: 38.610s
[2K
| Adam | epoch: 004 | loss: 0.69182 - acc: 0.5398 -- iter: 096/182
[A[ATraining Step: 22  | total loss: [1m[32m0.69750[0m[0m | time: 45.128s
[2K
| Adam | epoch: 004 | loss: 0.69750 - acc: 0.5006 -- iter: 128/182
[A[ATraining Step: 23  | total loss: [1m[32m0.69562[0m[0m | time: 46.310s
[2K
| Adam | epoch: 004 | loss: 0.69562 - acc: 0.5095 -- iter: 160/182
[A[ATraining Step: 24  | total loss: [1m[32m0.69223[0m[0m | time: 48.478s
[2K
| Adam | epoch: 004 | loss: 0.69223 - acc: 0.5332 | val_loss: 0.68956 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 25  | total loss: [1m[32m0.69300[0m[0m | time: 1.236s
[2K
| Adam | epoch: 005 | loss: 0.69300 - acc: 0.5241 -- iter: 032/182
[A[ATraining Step: 26  | total loss: [1m[32m0.69340[0m[0m | time: 2.386s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.5178 -- iter: 064/182
[A[ATraining Step: 27  | total loss: [1m[32m0.69378[0m[0m | time: 14.594s
[2K
| Adam | epoch: 005 | loss: 0.69378 - acc: 0.5132 -- iter: 096/182
[A[ATraining Step: 28  | total loss: [1m[32m0.69019[0m[0m | time: 30.014s
[2K
| Adam | epoch: 005 | loss: 0.69019 - acc: 0.5440 -- iter: 128/182
[A[ATraining Step: 29  | total loss: [1m[32m0.68759[0m[0m | time: 39.624s
[2K
| Adam | epoch: 005 | loss: 0.68759 - acc: 0.5665 -- iter: 160/182
[A[ATraining Step: 30  | total loss: [1m[32m0.68834[0m[0m | time: 41.777s
[2K
| Adam | epoch: 005 | loss: 0.68834 - acc: 0.5581 | val_loss: 0.68933 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 31  | total loss: [1m[32m0.68899[0m[0m | time: 1.294s
[2K
| Adam | epoch: 006 | loss: 0.68899 - acc: 0.5519 -- iter: 032/182
[A[ATraining Step: 32  | total loss: [1m[32m0.69214[0m[0m | time: 2.566s
[2K
| Adam | epoch: 006 | loss: 0.69214 - acc: 0.5262 -- iter: 064/182
[A[ATraining Step: 33  | total loss: [1m[32m0.69275[0m[0m | time: 3.734s
[2K
| Adam | epoch: 006 | loss: 0.69275 - acc: 0.5204 -- iter: 096/182
[A[ATraining Step: 34  | total loss: [1m[32m0.69238[0m[0m | time: 4.537s
[2K
| Adam | epoch: 006 | loss: 0.69238 - acc: 0.5227 -- iter: 128/182
[A[ATraining Step: 35  | total loss: [1m[32m0.68951[0m[0m | time: 5.340s
[2K
| Adam | epoch: 006 | loss: 0.68951 - acc: 0.5465 -- iter: 160/182
[A[ATraining Step: 36  | total loss: [1m[32m0.68710[0m[0m | time: 6.978s
[2K
| Adam | epoch: 006 | loss: 0.68710 - acc: 0.5649 | val_loss: 0.68865 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 37  | total loss: [1m[32m0.68520[0m[0m | time: 0.604s
[2K
| Adam | epoch: 007 | loss: 0.68520 - acc: 0.5769 -- iter: 032/182
[A[ATraining Step: 38  | total loss: [1m[32m0.69137[0m[0m | time: 1.219s
[2K
| Adam | epoch: 007 | loss: 0.69137 - acc: 0.5374 -- iter: 064/182
[A[ATraining Step: 39  | total loss: [1m[32m0.69519[0m[0m | time: 1.817s
[2K
| Adam | epoch: 007 | loss: 0.69519 - acc: 0.5123 -- iter: 096/182
[A[ATraining Step: 40  | total loss: [1m[32m0.69076[0m[0m | time: 2.456s
[2K
| Adam | epoch: 007 | loss: 0.69076 - acc: 0.5393 -- iter: 128/182
[A[ATraining Step: 41  | total loss: [1m[32m0.68897[0m[0m | time: 2.932s
[2K
| Adam | epoch: 007 | loss: 0.68897 - acc: 0.5493 -- iter: 160/182
[A[ATraining Step: 42  | total loss: [1m[32m0.69009[0m[0m | time: 4.420s
[2K
| Adam | epoch: 007 | loss: 0.69009 - acc: 0.5404 | val_loss: 0.68836 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 43  | total loss: [1m[32m0.69113[0m[0m | time: 0.614s
[2K
| Adam | epoch: 008 | loss: 0.69113 - acc: 0.5333 -- iter: 032/182
[A[ATraining Step: 44  | total loss: [1m[32m0.68686[0m[0m | time: 1.216s
[2K
| Adam | epoch: 008 | loss: 0.68686 - acc: 0.5600 -- iter: 064/182
[A[ATraining Step: 45  | total loss: [1m[32m0.68453[0m[0m | time: 1.841s
[2K
| Adam | epoch: 008 | loss: 0.68453 - acc: 0.5710 -- iter: 096/182
[A[ATraining Step: 46  | total loss: [1m[32m0.68536[0m[0m | time: 2.445s
[2K
| Adam | epoch: 008 | loss: 0.68536 - acc: 0.5644 -- iter: 128/182
[A[ATraining Step: 47  | total loss: [1m[32m0.68143[0m[0m | time: 3.061s
[2K
| Adam | epoch: 008 | loss: 0.68143 - acc: 0.5794 -- iter: 160/182
[A[ATraining Step: 48  | total loss: [1m[32m0.68737[0m[0m | time: 4.506s
[2K
| Adam | epoch: 008 | loss: 0.68737 - acc: 0.5566 | val_loss: 0.68693 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 49  | total loss: [1m[32m0.68911[0m[0m | time: 0.455s
[2K
| Adam | epoch: 009 | loss: 0.68911 - acc: 0.5477 -- iter: 032/182
[A[ATraining Step: 50  | total loss: [1m[32m0.69096[0m[0m | time: 1.078s
[2K
| Adam | epoch: 009 | loss: 0.69096 - acc: 0.5403 -- iter: 064/182
[A[ATraining Step: 51  | total loss: [1m[32m0.69308[0m[0m | time: 1.697s
[2K
| Adam | epoch: 009 | loss: 0.69308 - acc: 0.5294 -- iter: 096/182
[A[ATraining Step: 52  | total loss: [1m[32m0.69052[0m[0m | time: 2.334s
[2K
| Adam | epoch: 009 | loss: 0.69052 - acc: 0.5390 -- iter: 128/182
[A[ATraining Step: 53  | total loss: [1m[32m0.69315[0m[0m | time: 2.951s
[2K
| Adam | epoch: 009 | loss: 0.69315 - acc: 0.5194 -- iter: 160/182
[A[ATraining Step: 54  | total loss: [1m[32m0.69316[0m[0m | time: 4.563s
[2K
| Adam | epoch: 009 | loss: 0.69316 - acc: 0.5166 | val_loss: 0.68705 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 55  | total loss: [1m[32m0.69139[0m[0m | time: 0.482s
[2K
| Adam | epoch: 010 | loss: 0.69139 - acc: 0.5276 -- iter: 032/182
[A[ATraining Step: 56  | total loss: [1m[32m0.69229[0m[0m | time: 0.909s
[2K
| Adam | epoch: 010 | loss: 0.69229 - acc: 0.5174 -- iter: 064/182
[A[ATraining Step: 57  | total loss: [1m[32m0.69294[0m[0m | time: 1.520s
[2K
| Adam | epoch: 010 | loss: 0.69294 - acc: 0.5087 -- iter: 096/182
[A[ATraining Step: 58  | total loss: [1m[32m0.69012[0m[0m | time: 2.134s
[2K
| Adam | epoch: 010 | loss: 0.69012 - acc: 0.5288 -- iter: 128/182
[A[ATraining Step: 59  | total loss: [1m[32m0.68870[0m[0m | time: 2.746s
[2K
| Adam | epoch: 010 | loss: 0.68870 - acc: 0.5375 -- iter: 160/182
[A[ATraining Step: 60  | total loss: [1m[32m0.68884[0m[0m | time: 4.367s
[2K
| Adam | epoch: 010 | loss: 0.68884 - acc: 0.5325 | val_loss: 0.68210 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 61  | total loss: [1m[32m0.68859[0m[0m | time: 0.647s
[2K
| Adam | epoch: 011 | loss: 0.68859 - acc: 0.5283 -- iter: 032/182
[A[ATraining Step: 62  | total loss: [1m[32m0.68485[0m[0m | time: 1.078s
[2K
| Adam | epoch: 011 | loss: 0.68485 - acc: 0.5448 -- iter: 064/182
[A[ATraining Step: 63  | total loss: [1m[32m0.68472[0m[0m | time: 1.508s
[2K
| Adam | epoch: 011 | loss: 0.68472 - acc: 0.5391 -- iter: 096/182
[A[ATraining Step: 64  | total loss: [1m[32m0.68445[0m[0m | time: 2.140s
[2K
| Adam | epoch: 011 | loss: 0.68445 - acc: 0.5342 -- iter: 128/182
[A[ATraining Step: 65  | total loss: [1m[32m0.68467[0m[0m | time: 2.750s
[2K
| Adam | epoch: 011 | loss: 0.68467 - acc: 0.5261 -- iter: 160/182
[A[ATraining Step: 66  | total loss: [1m[32m0.68097[0m[0m | time: 4.404s
[2K
| Adam | epoch: 011 | loss: 0.68097 - acc: 0.5305 | val_loss: 0.65344 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 67  | total loss: [1m[32m0.67746[0m[0m | time: 0.633s
[2K
| Adam | epoch: 012 | loss: 0.67746 - acc: 0.5269 -- iter: 032/182
[A[ATraining Step: 68  | total loss: [1m[32m0.67183[0m[0m | time: 1.261s
[2K
| Adam | epoch: 012 | loss: 0.67183 - acc: 0.5348 -- iter: 064/182
[A[ATraining Step: 69  | total loss: [1m[32m0.66739[0m[0m | time: 1.721s
[2K
| Adam | epoch: 012 | loss: 0.66739 - acc: 0.5344 -- iter: 096/182
[A[ATraining Step: 70  | total loss: [1m[32m0.66738[0m[0m | time: 2.168s
[2K
| Adam | epoch: 012 | loss: 0.66738 - acc: 0.5252 -- iter: 128/182
[A[ATraining Step: 71  | total loss: [1m[32m0.66871[0m[0m | time: 2.788s
[2K
| Adam | epoch: 012 | loss: 0.66871 - acc: 0.5171 -- iter: 160/182
[A[ATraining Step: 72  | total loss: [1m[32m0.65703[0m[0m | time: 4.404s
[2K
| Adam | epoch: 012 | loss: 0.65703 - acc: 0.5222 | val_loss: 0.65450 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 73  | total loss: [1m[32m0.65425[0m[0m | time: 0.634s
[2K
| Adam | epoch: 013 | loss: 0.65425 - acc: 0.5337 -- iter: 032/182
[A[ATraining Step: 74  | total loss: [1m[32m0.64567[0m[0m | time: 1.252s
[2K
| Adam | epoch: 013 | loss: 0.64567 - acc: 0.5334 -- iter: 064/182
[A[ATraining Step: 75  | total loss: [1m[32m0.63269[0m[0m | time: 1.882s
[2K
| Adam | epoch: 013 | loss: 0.63269 - acc: 0.5569 -- iter: 096/182
[A[ATraining Step: 76  | total loss: [1m[32m0.62738[0m[0m | time: 2.336s
[2K
| Adam | epoch: 013 | loss: 0.62738 - acc: 0.5809 -- iter: 128/182
[A[ATraining Step: 77  | total loss: [1m[32m0.62131[0m[0m | time: 2.769s
[2K
| Adam | epoch: 013 | loss: 0.62131 - acc: 0.6157 -- iter: 160/182
[A[ATraining Step: 78  | total loss: [1m[32m0.61022[0m[0m | time: 4.389s
[2K
| Adam | epoch: 013 | loss: 0.61022 - acc: 0.6273 | val_loss: 0.54026 - val_acc: 0.6842 -- iter: 182/182
--
Training Step: 79  | total loss: [1m[32m0.60001[0m[0m | time: 0.611s
[2K
| Adam | epoch: 014 | loss: 0.60001 - acc: 0.6336 -- iter: 032/182
[A[ATraining Step: 80  | total loss: [1m[32m0.59302[0m[0m | time: 1.254s
[2K
| Adam | epoch: 014 | loss: 0.59302 - acc: 0.6615 -- iter: 064/182
[A[ATraining Step: 81  | total loss: [1m[32m0.58580[0m[0m | time: 1.868s
[2K
| Adam | epoch: 014 | loss: 0.58580 - acc: 0.6704 -- iter: 096/182
[A[ATraining Step: 82  | total loss: [1m[32m0.57481[0m[0m | time: 2.490s
[2K
| Adam | epoch: 014 | loss: 0.57481 - acc: 0.6877 -- iter: 128/182
[A[ATraining Step: 83  | total loss: [1m[32m0.55671[0m[0m | time: 2.917s
[2K
| Adam | epoch: 014 | loss: 0.55671 - acc: 0.7158 -- iter: 160/182
[A[ATraining Step: 84  | total loss: [1m[32m0.58233[0m[0m | time: 4.383s
[2K
| Adam | epoch: 014 | loss: 0.58233 - acc: 0.7079 | val_loss: 0.53901 - val_acc: 0.7193 -- iter: 182/182
--
Training Step: 85  | total loss: [1m[32m0.58135[0m[0m | time: 0.609s
[2K
| Adam | epoch: 015 | loss: 0.58135 - acc: 0.7053 -- iter: 032/182
[A[ATraining Step: 86  | total loss: [1m[32m0.57161[0m[0m | time: 1.218s
[2K
| Adam | epoch: 015 | loss: 0.57161 - acc: 0.7098 -- iter: 064/182
[A[ATraining Step: 87  | total loss: [1m[32m0.56749[0m[0m | time: 1.848s
[2K
| Adam | epoch: 015 | loss: 0.56749 - acc: 0.7138 -- iter: 096/182
[A[ATraining Step: 88  | total loss: [1m[32m0.55063[0m[0m | time: 2.491s
[2K
| Adam | epoch: 015 | loss: 0.55063 - acc: 0.7237 -- iter: 128/182
[A[ATraining Step: 89  | total loss: [1m[32m0.54012[0m[0m | time: 3.106s
[2K
| Adam | epoch: 015 | loss: 0.54012 - acc: 0.7294 -- iter: 160/182
[A[ATraining Step: 90  | total loss: [1m[32m0.51950[0m[0m | time: 4.534s
[2K
| Adam | epoch: 015 | loss: 0.51950 - acc: 0.7502 | val_loss: 0.45925 - val_acc: 0.8070 -- iter: 182/182
--
Training Step: 91  | total loss: [1m[32m0.50519[0m[0m | time: 0.442s
[2K
| Adam | epoch: 016 | loss: 0.50519 - acc: 0.7661 -- iter: 032/182
[A[ATraining Step: 92  | total loss: [1m[32m0.49302[0m[0m | time: 1.060s
[2K
| Adam | epoch: 016 | loss: 0.49302 - acc: 0.7759 -- iter: 064/182
[A[ATraining Step: 93  | total loss: [1m[32m0.48705[0m[0m | time: 1.678s
[2K
| Adam | epoch: 016 | loss: 0.48705 - acc: 0.7795 -- iter: 096/182
[A[ATraining Step: 94  | total loss: [1m[32m0.47868[0m[0m | time: 2.282s
[2K
| Adam | epoch: 016 | loss: 0.47868 - acc: 0.7891 -- iter: 128/182
[A[ATraining Step: 95  | total loss: [1m[32m0.45268[0m[0m | time: 2.919s
[2K
| Adam | epoch: 016 | loss: 0.45268 - acc: 0.8102 -- iter: 160/182
[A[ATraining Step: 96  | total loss: [1m[32m0.43703[0m[0m | time: 4.528s
[2K
| Adam | epoch: 016 | loss: 0.43703 - acc: 0.8166 | val_loss: 0.35834 - val_acc: 0.8421 -- iter: 182/182
--
Training Step: 97  | total loss: [1m[32m0.43171[0m[0m | time: 0.440s
[2K
| Adam | epoch: 017 | loss: 0.43171 - acc: 0.8162 -- iter: 032/182
[A[ATraining Step: 98  | total loss: [1m[32m0.40261[0m[0m | time: 0.882s
[2K
| Adam | epoch: 017 | loss: 0.40261 - acc: 0.8301 -- iter: 064/182
[A[ATraining Step: 99  | total loss: [1m[32m0.37349[0m[0m | time: 1.506s
[2K
| Adam | epoch: 017 | loss: 0.37349 - acc: 0.8471 -- iter: 096/182
[A[ATraining Step: 100  | total loss: [1m[32m0.35615[0m[0m | time: 2.136s
[2K
| Adam | epoch: 017 | loss: 0.35615 - acc: 0.8530 -- iter: 128/182
[A[ATraining Step: 101  | total loss: [1m[32m0.34940[0m[0m | time: 2.749s
[2K
| Adam | epoch: 017 | loss: 0.34940 - acc: 0.8552 -- iter: 160/182
[A[ATraining Step: 102  | total loss: [1m[32m0.32590[0m[0m | time: 4.394s
[2K
| Adam | epoch: 017 | loss: 0.32590 - acc: 0.8665 | val_loss: 0.33636 - val_acc: 0.8596 -- iter: 182/182
--
Training Step: 103  | total loss: [1m[32m0.30457[0m[0m | time: 0.633s
[2K
| Adam | epoch: 018 | loss: 0.30457 - acc: 0.8768 -- iter: 032/182
[A[ATraining Step: 104  | total loss: [1m[32m0.29287[0m[0m | time: 1.074s
[2K
| Adam | epoch: 018 | loss: 0.29287 - acc: 0.8735 -- iter: 064/182
[A[ATraining Step: 105  | total loss: [1m[32m0.28256[0m[0m | time: 1.529s
[2K
| Adam | epoch: 018 | loss: 0.28256 - acc: 0.8770 -- iter: 096/182
[A[ATraining Step: 106  | total loss: [1m[32m0.26331[0m[0m | time: 2.143s
[2K
| Adam | epoch: 018 | loss: 0.26331 - acc: 0.8848 -- iter: 128/182
[A[ATraining Step: 107  | total loss: [1m[32m0.25033[0m[0m | time: 2.765s
[2K
| Adam | epoch: 018 | loss: 0.25033 - acc: 0.8900 -- iter: 160/182
[A[ATraining Step: 108  | total loss: [1m[32m0.26443[0m[0m | time: 4.407s
[2K
| Adam | epoch: 018 | loss: 0.26443 - acc: 0.8948 | val_loss: 0.35979 - val_acc: 0.8246 -- iter: 182/182
--
Training Step: 109  | total loss: [1m[32m0.24701[0m[0m | time: 0.643s
[2K
| Adam | epoch: 019 | loss: 0.24701 - acc: 0.9022 -- iter: 032/182
[A[ATraining Step: 110  | total loss: [1m[32m0.23185[0m[0m | time: 1.256s
[2K
| Adam | epoch: 019 | loss: 0.23185 - acc: 0.9057 -- iter: 064/182
[A[ATraining Step: 111  | total loss: [1m[32m0.22049[0m[0m | time: 1.680s
[2K
| Adam | epoch: 019 | loss: 0.22049 - acc: 0.9120 -- iter: 096/182
[A[ATraining Step: 112  | total loss: [1m[32m0.20315[0m[0m | time: 2.129s
[2K
| Adam | epoch: 019 | loss: 0.20315 - acc: 0.9208 -- iter: 128/182
[A[ATraining Step: 113  | total loss: [1m[32m0.18740[0m[0m | time: 2.728s
[2K
| Adam | epoch: 019 | loss: 0.18740 - acc: 0.9287 -- iter: 160/182
[A[ATraining Step: 114  | total loss: [1m[32m0.18161[0m[0m | time: 4.329s
[2K
| Adam | epoch: 019 | loss: 0.18161 - acc: 0.9327 | val_loss: 0.57261 - val_acc: 0.8070 -- iter: 182/182
--
Training Step: 115  | total loss: [1m[32m0.18345[0m[0m | time: 0.604s
[2K
| Adam | epoch: 020 | loss: 0.18345 - acc: 0.9332 -- iter: 032/182
[A[ATraining Step: 116  | total loss: [1m[32m0.17747[0m[0m | time: 1.205s
[2K
| Adam | epoch: 020 | loss: 0.17747 - acc: 0.9368 -- iter: 064/182
[A[ATraining Step: 117  | total loss: [1m[32m0.17031[0m[0m | time: 1.840s
[2K
| Adam | epoch: 020 | loss: 0.17031 - acc: 0.9368 -- iter: 096/182
[A[ATraining Step: 118  | total loss: [1m[32m0.16400[0m[0m | time: 2.273s
[2K
| Adam | epoch: 020 | loss: 0.16400 - acc: 0.9400 -- iter: 128/182
[A[ATraining Step: 119  | total loss: [1m[32m0.16526[0m[0m | time: 2.708s
[2K
| Adam | epoch: 020 | loss: 0.16526 - acc: 0.9369 -- iter: 160/182
[A[ATraining Step: 120  | total loss: [1m[32m0.15261[0m[0m | time: 4.332s
[2K
| Adam | epoch: 020 | loss: 0.15261 - acc: 0.9432 | val_loss: 0.32615 - val_acc: 0.8947 -- iter: 182/182
--
Training Step: 121  | total loss: [1m[32m0.14769[0m[0m | time: 0.615s
[2K
| Adam | epoch: 021 | loss: 0.14769 - acc: 0.9458 -- iter: 032/182
[A[ATraining Step: 122  | total loss: [1m[32m0.18268[0m[0m | time: 1.259s
[2K
| Adam | epoch: 021 | loss: 0.18268 - acc: 0.9450 -- iter: 064/182
[A[ATraining Step: 123  | total loss: [1m[32m0.17027[0m[0m | time: 1.876s
[2K
| Adam | epoch: 021 | loss: 0.17027 - acc: 0.9505 -- iter: 096/182
[A[ATraining Step: 124  | total loss: [1m[32m0.15664[0m[0m | time: 2.506s
[2K
| Adam | epoch: 021 | loss: 0.15664 - acc: 0.9554 -- iter: 128/182
[A[ATraining Step: 125  | total loss: [1m[32m0.14725[0m[0m | time: 2.959s
[2K
| Adam | epoch: 021 | loss: 0.14725 - acc: 0.9568 -- iter: 160/182
[A[ATraining Step: 126  | total loss: [1m[32m0.13880[0m[0m | time: 4.391s
[2K
| Adam | epoch: 021 | loss: 0.13880 - acc: 0.9565 | val_loss: 0.32516 - val_acc: 0.9123 -- iter: 182/182
--
Training Step: 127  | total loss: [1m[32m0.12875[0m[0m | time: 0.620s
[2K
| Adam | epoch: 022 | loss: 0.12875 - acc: 0.9609 -- iter: 032/182
[A[ATraining Step: 128  | total loss: [1m[32m0.12425[0m[0m | time: 1.414s
[2K
| Adam | epoch: 022 | loss: 0.12425 - acc: 0.9585 -- iter: 064/182
[A[ATraining Step: 129  | total loss: [1m[32m0.11415[0m[0m | time: 2.028s
[2K
| Adam | epoch: 022 | loss: 0.11415 - acc: 0.9627 -- iter: 096/182
[A[ATraining Step: 130  | total loss: [1m[32m0.10647[0m[0m | time: 2.640s
[2K
| Adam | epoch: 022 | loss: 0.10647 - acc: 0.9664 -- iter: 128/182
[A[ATraining Step: 131  | total loss: [1m[32m0.10044[0m[0m | time: 3.254s
[2K
| Adam | epoch: 022 | loss: 0.10044 - acc: 0.9698 -- iter: 160/182
[A[ATraining Step: 132  | total loss: [1m[32m0.09281[0m[0m | time: 4.698s
[2K
| Adam | epoch: 022 | loss: 0.09281 - acc: 0.9728 | val_loss: 0.33402 - val_acc: 0.8772 -- iter: 182/182
--
Training Step: 133  | total loss: [1m[32m0.08546[0m[0m | time: 0.431s
[2K
| Adam | epoch: 023 | loss: 0.08546 - acc: 0.9755 -- iter: 032/182
[A[ATraining Step: 134  | total loss: [1m[32m0.07934[0m[0m | time: 1.071s
[2K
| Adam | epoch: 023 | loss: 0.07934 - acc: 0.9780 -- iter: 064/182
[A[ATraining Step: 135  | total loss: [1m[32m0.07286[0m[0m | time: 1.670s
[2K
| Adam | epoch: 023 | loss: 0.07286 - acc: 0.9802 -- iter: 096/182
[A[ATraining Step: 136  | total loss: [1m[32m0.09271[0m[0m | time: 2.275s
[2K
| Adam | epoch: 023 | loss: 0.09271 - acc: 0.9790 -- iter: 128/182
[A[ATraining Step: 137  | total loss: [1m[32m0.08696[0m[0m | time: 2.905s
[2K
| Adam | epoch: 023 | loss: 0.08696 - acc: 0.9811 -- iter: 160/182
[A[ATraining Step: 138  | total loss: [1m[32m0.08041[0m[0m | time: 4.506s
[2K
| Adam | epoch: 023 | loss: 0.08041 - acc: 0.9830 | val_loss: 0.41269 - val_acc: 0.8596 -- iter: 182/182
--
Training Step: 139  | total loss: [1m[32m0.07344[0m[0m | time: 0.479s
[2K
| Adam | epoch: 024 | loss: 0.07344 - acc: 0.9847 -- iter: 032/182
[A[ATraining Step: 140  | total loss: [1m[32m0.06708[0m[0m | time: 0.912s
[2K
| Adam | epoch: 024 | loss: 0.06708 - acc: 0.9862 -- iter: 064/182
[A[ATraining Step: 141  | total loss: [1m[32m0.06195[0m[0m | time: 1.518s
[2K
| Adam | epoch: 024 | loss: 0.06195 - acc: 0.9876 -- iter: 096/182
[A[ATraining Step: 142  | total loss: [1m[32m0.05729[0m[0m | time: 2.130s
[2K
| Adam | epoch: 024 | loss: 0.05729 - acc: 0.9889 -- iter: 128/182
[A[ATraining Step: 143  | total loss: [1m[32m0.07187[0m[0m | time: 2.747s
[2K
| Adam | epoch: 024 | loss: 0.07187 - acc: 0.9868 -- iter: 160/182
[A[ATraining Step: 144  | total loss: [1m[32m0.06547[0m[0m | time: 4.354s
[2K
| Adam | epoch: 024 | loss: 0.06547 - acc: 0.9882 | val_loss: 0.32787 - val_acc: 0.9123 -- iter: 182/182
--
Training Step: 145  | total loss: [1m[32m0.05938[0m[0m | time: 0.616s
[2K
| Adam | epoch: 025 | loss: 0.05938 - acc: 0.9893 -- iter: 032/182
[A[ATraining Step: 146  | total loss: [1m[32m0.05548[0m[0m | time: 1.059s
[2K
| Adam | epoch: 025 | loss: 0.05548 - acc: 0.9904 -- iter: 064/182
[A[ATraining Step: 147  | total loss: [1m[32m0.05082[0m[0m | time: 1.494s
[2K
| Adam | epoch: 025 | loss: 0.05082 - acc: 0.9914 -- iter: 096/182
[A[ATraining Step: 148  | total loss: [1m[32m0.04655[0m[0m | time: 2.106s
[2K
| Adam | epoch: 025 | loss: 0.04655 - acc: 0.9922 -- iter: 128/182
[A[ATraining Step: 149  | total loss: [1m[32m0.04289[0m[0m | time: 2.737s
[2K
| Adam | epoch: 025 | loss: 0.04289 - acc: 0.9930 -- iter: 160/182
[A[ATraining Step: 150  | total loss: [1m[32m0.03939[0m[0m | time: 4.350s
[2K
| Adam | epoch: 025 | loss: 0.03939 - acc: 0.9937 | val_loss: 0.37423 - val_acc: 0.8772 -- iter: 182/182
--
Training Step: 151  | total loss: [1m[32m0.03628[0m[0m | time: 0.609s
[2K
| Adam | epoch: 026 | loss: 0.03628 - acc: 0.9943 -- iter: 032/182
[A[ATraining Step: 152  | total loss: [1m[32m0.03442[0m[0m | time: 1.225s
[2K
| Adam | epoch: 026 | loss: 0.03442 - acc: 0.9949 -- iter: 064/182
[A[ATraining Step: 153  | total loss: [1m[32m0.03145[0m[0m | time: 1.655s
[2K
| Adam | epoch: 026 | loss: 0.03145 - acc: 0.9954 -- iter: 096/182
[A[ATraining Step: 154  | total loss: [1m[32m0.02865[0m[0m | time: 2.092s
[2K
| Adam | epoch: 026 | loss: 0.02865 - acc: 0.9959 -- iter: 128/182
[A[ATraining Step: 155  | total loss: [1m[32m0.02618[0m[0m | time: 2.717s
[2K
| Adam | epoch: 026 | loss: 0.02618 - acc: 0.9963 -- iter: 160/182
[A[ATraining Step: 156  | total loss: [1m[32m0.02458[0m[0m | time: 4.324s
[2K
| Adam | epoch: 026 | loss: 0.02458 - acc: 0.9967 | val_loss: 0.33758 - val_acc: 0.9123 -- iter: 182/182
--
Training Step: 157  | total loss: [1m[32m0.04342[0m[0m | time: 0.614s
[2K
| Adam | epoch: 027 | loss: 0.04342 - acc: 0.9939 -- iter: 032/182
[A[ATraining Step: 158  | total loss: [1m[32m0.03947[0m[0m | time: 1.269s
[2K
| Adam | epoch: 027 | loss: 0.03947 - acc: 0.9945 -- iter: 064/182
[A[ATraining Step: 159  | total loss: [1m[32m0.03586[0m[0m | time: 1.899s
[2K
| Adam | epoch: 027 | loss: 0.03586 - acc: 0.9950 -- iter: 096/182
[A[ATraining Step: 160  | total loss: [1m[32m0.03289[0m[0m | time: 2.328s
[2K
| Adam | epoch: 027 | loss: 0.03289 - acc: 0.9955 -- iter: 128/182
[A[ATraining Step: 161  | total loss: [1m[32m0.03030[0m[0m | time: 2.776s
[2K
| Adam | epoch: 027 | loss: 0.03030 - acc: 0.9960 -- iter: 160/182
[A[ATraining Step: 162  | total loss: [1m[32m0.02799[0m[0m | time: 4.401s
[2K
| Adam | epoch: 027 | loss: 0.02799 - acc: 0.9964 | val_loss: 0.42635 - val_acc: 0.8772 -- iter: 182/182
--
Training Step: 163  | total loss: [1m[32m0.02588[0m[0m | time: 0.631s
[2K
| Adam | epoch: 028 | loss: 0.02588 - acc: 0.9967 -- iter: 032/182
[A[ATraining Step: 164  | total loss: [1m[32m0.02358[0m[0m | time: 1.227s
[2K
| Adam | epoch: 028 | loss: 0.02358 - acc: 0.9971 -- iter: 064/182
[A[ATraining Step: 165  | total loss: [1m[32m0.02146[0m[0m | time: 1.879s
[2K
| Adam | epoch: 028 | loss: 0.02146 - acc: 0.9974 -- iter: 096/182
[A[ATraining Step: 166  | total loss: [1m[32m0.01962[0m[0m | time: 2.487s
[2K
| Adam | epoch: 028 | loss: 0.01962 - acc: 0.9976 -- iter: 128/182
[A[ATraining Step: 167  | total loss: [1m[32m0.01794[0m[0m | time: 2.920s
[2K
| Adam | epoch: 028 | loss: 0.01794 - acc: 0.9979 -- iter: 160/182
[A[ATraining Step: 168  | total loss: [1m[32m0.01643[0m[0m | time: 4.369s
[2K
| Adam | epoch: 028 | loss: 0.01643 - acc: 0.9981 | val_loss: 0.34174 - val_acc: 0.8772 -- iter: 182/182
--
Training Step: 169  | total loss: [1m[32m0.01509[0m[0m | time: 0.656s
[2K
| Adam | epoch: 029 | loss: 0.01509 - acc: 0.9983 -- iter: 032/182
[A[ATraining Step: 170  | total loss: [1m[32m0.01489[0m[0m | time: 1.279s
[2K
| Adam | epoch: 029 | loss: 0.01489 - acc: 0.9984 -- iter: 064/182
[A[ATraining Step: 171  | total loss: [1m[32m0.03899[0m[0m | time: 1.883s
[2K
| Adam | epoch: 029 | loss: 0.03899 - acc: 0.9955 -- iter: 096/182
[A[ATraining Step: 172  | total loss: [1m[32m0.03561[0m[0m | time: 2.487s
[2K
| Adam | epoch: 029 | loss: 0.03561 - acc: 0.9959 -- iter: 128/182
[A[ATraining Step: 173  | total loss: [1m[32m0.03278[0m[0m | time: 3.101s
[2K
| Adam | epoch: 029 | loss: 0.03278 - acc: 0.9963 -- iter: 160/182
[A[ATraining Step: 174  | total loss: [1m[32m0.02973[0m[0m | time: 4.561s
[2K
| Adam | epoch: 029 | loss: 0.02973 - acc: 0.9967 | val_loss: 0.34202 - val_acc: 0.8596 -- iter: 182/182
--
Training Step: 175  | total loss: [1m[32m0.02711[0m[0m | time: 0.428s
[2K
| Adam | epoch: 030 | loss: 0.02711 - acc: 0.9970 -- iter: 032/182
[A[ATraining Step: 176  | total loss: [1m[32m0.02473[0m[0m | time: 1.046s
[2K
| Adam | epoch: 030 | loss: 0.02473 - acc: 0.9973 -- iter: 064/182
[A[ATraining Step: 177  | total loss: [1m[32m0.02295[0m[0m | time: 1.653s
[2K
| Adam | epoch: 030 | loss: 0.02295 - acc: 0.9976 -- iter: 096/182
[A[ATraining Step: 178  | total loss: [1m[32m0.03995[0m[0m | time: 2.280s
[2K
| Adam | epoch: 030 | loss: 0.03995 - acc: 0.9947 -- iter: 128/182
[A[ATraining Step: 179  | total loss: [1m[32m0.03614[0m[0m | time: 2.899s
[2K
| Adam | epoch: 030 | loss: 0.03614 - acc: 0.9952 -- iter: 160/182
[A[ATraining Step: 180  | total loss: [1m[32m0.03281[0m[0m | time: 4.506s
[2K
| Adam | epoch: 030 | loss: 0.03281 - acc: 0.9957 | val_loss: 0.51775 - val_acc: 0.8772 -- iter: 182/182
--
Validation AUC:0.9516129032258064
Validation AUPRC:0.9722583107251224
Test AUC:0.9556650246305418
Test AUPRC:0.9610087392342335
BestTestF1Score	0.88	0.8	0.89	0.96	0.82	23	1	28	5	0.99
BestTestMCCScore	0.88	0.8	0.89	0.96	0.82	23	1	28	5	0.99
BestTestAccuracyScore	0.88	0.8	0.89	0.96	0.82	23	1	28	5	0.99
BestValidationF1Score	0.92	0.82	0.91	0.93	0.9	28	2	24	3	0.99
BestValidationMCC	0.92	0.82	0.91	0.93	0.9	28	2	24	3	0.99
BestValidationAccuracy	0.92	0.82	0.91	0.93	0.9	28	2	24	3	0.99
TestPredictions (Threshold:0.99)
CHEMBL404557,TN,INACT,0.009999999776482582	CHEMBL191915,TN,INACT,0.009999999776482582	CHEMBL3115383,TP,ACT,1.0	CHEMBL42411,TN,INACT,0.019999999552965164	CHEMBL1762251,FN,ACT,0.1899999976158142	CHEMBL40796,TN,INACT,0.0	CHEMBL245319,FP,INACT,1.0	CHEMBL595022,TN,INACT,0.009999999776482582	CHEMBL95727,TN,INACT,0.3499999940395355	CHEMBL293232,TN,INACT,0.6399999856948853	CHEMBL2023111,TP,ACT,1.0	CHEMBL2179476,TP,ACT,1.0	CHEMBL1087442,TP,ACT,1.0	CHEMBL59597,TN,INACT,0.009999999776482582	CHEMBL1762258,FN,ACT,0.07000000029802322	CHEMBL298612,TN,INACT,0.8100000023841858	CHEMBL321644,TN,INACT,0.029999999329447746	CHEMBL1762266,FN,ACT,0.6200000047683716	CHEMBL424214,TN,INACT,0.009999999776482582	CHEMBL217002,TN,INACT,0.0	CHEMBL302038,TN,INACT,0.05000000074505806	CHEMBL3356413,TP,ACT,1.0	CHEMBL63937,TN,INACT,0.009999999776482582	CHEMBL525577,FN,ACT,0.3700000047683716	CHEMBL2164577,TP,ACT,1.0	CHEMBL2164226,TP,ACT,1.0	CHEMBL21937,TN,INACT,0.009999999776482582	CHEMBL2179907,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.0	CHEMBL2093084,TN,INACT,0.009999999776482582	CHEMBL3115388,TP,ACT,1.0	CHEMBL435810,TN,INACT,0.10000000149011612	CHEMBL3115399,TP,ACT,1.0	CHEMBL123099,TN,INACT,0.019999999552965164	CHEMBL2023110,TP,ACT,1.0	CHEMBL2179482,FN,ACT,0.5299999713897705	CHEMBL2179910,TP,ACT,1.0	CHEMBL2113072,TN,INACT,0.03999999910593033	CHEMBL3115372,TP,ACT,1.0	CHEMBL3356412,TP,ACT,1.0	CHEMBL3115386,TP,ACT,1.0	CHEMBL1086673,TP,ACT,1.0	CHEMBL44262,TN,INACT,0.0	CHEMBL21509,TN,INACT,0.8600000143051147	CHEMBL3356404,TP,ACT,1.0	CHEMBL40986,TN,INACT,0.07999999821186066	CHEMBL3115374,TP,ACT,0.9900000095367432	CHEMBL2179917,TP,ACT,1.0	CHEMBL99331,TN,INACT,0.800000011920929	CHEMBL297215,TN,INACT,0.009999999776482582	CHEMBL21508,TN,INACT,0.8100000023841858	CHEMBL308924,TN,INACT,0.009999999776482582	CHEMBL1762271,TP,ACT,1.0	CHEMBL2179478,TP,ACT,1.0	CHEMBL1170027,TN,INACT,0.11999999731779099	CHEMBL1086674,TP,ACT,1.0	CHEMBL1091985,TP,ACT,1.0	

