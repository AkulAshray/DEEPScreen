CNNModel CHEMBL204 RMSprop 0.0005 30 128 0 0.8 False True
Number of active compounds :	2112
Number of inactive compounds :	1408
---------------------------------
Run id: CNNModel_CHEMBL204_RMSprop_0.0005_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL204_RMSprop_0.0005_30_128_0.8_True/
---------------------------------
Training samples: 2235
Validation samples: 699
--
Training Step: 1  | time: 1.737s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2235
[A[ATraining Step: 2  | total loss: [1m[32m0.62427[0m[0m | time: 2.852s
[2K
| RMSProp | epoch: 001 | loss: 0.62427 - acc: 0.3375 -- iter: 0064/2235
[A[ATraining Step: 3  | total loss: [1m[32m0.68060[0m[0m | time: 4.046s
[2K
| RMSProp | epoch: 001 | loss: 0.68060 - acc: 0.4960 -- iter: 0096/2235
[A[ATraining Step: 4  | total loss: [1m[32m0.68999[0m[0m | time: 5.347s
[2K
| RMSProp | epoch: 001 | loss: 0.68999 - acc: 0.4990 -- iter: 0128/2235
[A[ATraining Step: 5  | total loss: [1m[32m0.69263[0m[0m | time: 6.540s
[2K
| RMSProp | epoch: 001 | loss: 0.69263 - acc: 0.3699 -- iter: 0160/2235
[A[ATraining Step: 6  | total loss: [1m[32m0.69302[0m[0m | time: 7.666s
[2K
| RMSProp | epoch: 001 | loss: 0.69302 - acc: 0.4134 -- iter: 0192/2235
[A[ATraining Step: 7  | total loss: [1m[32m0.69299[0m[0m | time: 8.776s
[2K
| RMSProp | epoch: 001 | loss: 0.69299 - acc: 0.5028 -- iter: 0224/2235
[A[ATraining Step: 8  | total loss: [1m[32m0.69325[0m[0m | time: 9.993s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4661 -- iter: 0256/2235
[A[ATraining Step: 9  | total loss: [1m[32m0.69322[0m[0m | time: 11.186s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4510 -- iter: 0288/2235
[A[ATraining Step: 10  | total loss: [1m[32m0.69340[0m[0m | time: 12.214s
[2K
| RMSProp | epoch: 001 | loss: 0.69340 - acc: 0.3974 -- iter: 0320/2235
[A[ATraining Step: 11  | total loss: [1m[32m0.69361[0m[0m | time: 13.340s
[2K
| RMSProp | epoch: 001 | loss: 0.69361 - acc: 0.3276 -- iter: 0352/2235
[A[ATraining Step: 12  | total loss: [1m[32m0.69349[0m[0m | time: 14.550s
[2K
| RMSProp | epoch: 001 | loss: 0.69349 - acc: 0.4052 -- iter: 0384/2235
[A[ATraining Step: 13  | total loss: [1m[32m0.69332[0m[0m | time: 15.663s
[2K
| RMSProp | epoch: 001 | loss: 0.69332 - acc: 0.4458 -- iter: 0416/2235
[A[ATraining Step: 14  | total loss: [1m[32m0.69328[0m[0m | time: 16.882s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4935 -- iter: 0448/2235
[A[ATraining Step: 15  | total loss: [1m[32m0.69319[0m[0m | time: 18.032s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.5205 -- iter: 0480/2235
[A[ATraining Step: 16  | total loss: [1m[32m0.69314[0m[0m | time: 19.096s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5363 -- iter: 0512/2235
[A[ATraining Step: 17  | total loss: [1m[32m0.69319[0m[0m | time: 20.302s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4895 -- iter: 0544/2235
[A[ATraining Step: 18  | total loss: [1m[32m0.69324[0m[0m | time: 21.554s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4715 -- iter: 0576/2235
[A[ATraining Step: 19  | total loss: [1m[32m0.69316[0m[0m | time: 22.721s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4914 -- iter: 0608/2235
[A[ATraining Step: 20  | total loss: [1m[32m0.69318[0m[0m | time: 23.790s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4942 -- iter: 0640/2235
[A[ATraining Step: 21  | total loss: [1m[32m0.69325[0m[0m | time: 24.817s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4669 -- iter: 0672/2235
[A[ATraining Step: 22  | total loss: [1m[32m0.69318[0m[0m | time: 32.180s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5143 -- iter: 0704/2235
[A[ATraining Step: 23  | total loss: [1m[32m0.69322[0m[0m | time: 35.877s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4920 -- iter: 0736/2235
[A[ATraining Step: 24  | total loss: [1m[32m0.69324[0m[0m | time: 40.319s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4943 -- iter: 0768/2235
[A[ATraining Step: 25  | total loss: [1m[32m0.69320[0m[0m | time: 41.434s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.5214 -- iter: 0800/2235
[A[ATraining Step: 26  | total loss: [1m[32m0.69322[0m[0m | time: 42.640s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.5157 -- iter: 0832/2235
[A[ATraining Step: 27  | total loss: [1m[32m0.69314[0m[0m | time: 43.860s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5438 -- iter: 0864/2235
[A[ATraining Step: 28  | total loss: [1m[32m0.69320[0m[0m | time: 44.955s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.5251 -- iter: 0896/2235
[A[ATraining Step: 29  | total loss: [1m[32m0.69319[0m[0m | time: 46.079s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.5038 -- iter: 0928/2235
[A[ATraining Step: 30  | total loss: [1m[32m0.69320[0m[0m | time: 47.320s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.5177 -- iter: 0960/2235
[A[ATraining Step: 31  | total loss: [1m[32m0.69318[0m[0m | time: 48.696s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5136 -- iter: 0992/2235
[A[ATraining Step: 32  | total loss: [1m[32m0.69314[0m[0m | time: 49.845s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5457 -- iter: 1024/2235
[A[ATraining Step: 33  | total loss: [1m[32m0.69303[0m[0m | time: 50.882s
[2K
| RMSProp | epoch: 001 | loss: 0.69303 - acc: 0.5562 -- iter: 1056/2235
[A[ATraining Step: 34  | total loss: [1m[32m0.69301[0m[0m | time: 52.003s
[2K
| RMSProp | epoch: 001 | loss: 0.69301 - acc: 0.5509 -- iter: 1088/2235
[A[ATraining Step: 35  | total loss: [1m[32m0.69286[0m[0m | time: 53.250s
[2K
| RMSProp | epoch: 001 | loss: 0.69286 - acc: 0.5795 -- iter: 1120/2235
[A[ATraining Step: 36  | total loss: [1m[32m0.69284[0m[0m | time: 54.433s
[2K
| RMSProp | epoch: 001 | loss: 0.69284 - acc: 0.5824 -- iter: 1152/2235
[A[ATraining Step: 37  | total loss: [1m[32m0.69270[0m[0m | time: 55.622s
[2K
| RMSProp | epoch: 001 | loss: 0.69270 - acc: 0.6034 -- iter: 1184/2235
[A[ATraining Step: 38  | total loss: [1m[32m0.69282[0m[0m | time: 56.866s
[2K
| RMSProp | epoch: 001 | loss: 0.69282 - acc: 0.5954 -- iter: 1216/2235
[A[ATraining Step: 39  | total loss: [1m[32m0.69270[0m[0m | time: 58.116s
[2K
| RMSProp | epoch: 001 | loss: 0.69270 - acc: 0.5951 -- iter: 1248/2235
[A[ATraining Step: 40  | total loss: [1m[32m0.69252[0m[0m | time: 59.308s
[2K
| RMSProp | epoch: 001 | loss: 0.69252 - acc: 0.6183 -- iter: 1280/2235
[A[ATraining Step: 41  | total loss: [1m[32m0.69234[0m[0m | time: 60.481s
[2K
| RMSProp | epoch: 001 | loss: 0.69234 - acc: 0.6253 -- iter: 1312/2235
[A[ATraining Step: 42  | total loss: [1m[32m0.69253[0m[0m | time: 61.806s
[2K
| RMSProp | epoch: 001 | loss: 0.69253 - acc: 0.6027 -- iter: 1344/2235
[A[ATraining Step: 43  | total loss: [1m[32m0.69276[0m[0m | time: 62.921s
[2K
| RMSProp | epoch: 001 | loss: 0.69276 - acc: 0.5736 -- iter: 1376/2235
[A[ATraining Step: 44  | total loss: [1m[32m0.69253[0m[0m | time: 64.219s
[2K
| RMSProp | epoch: 001 | loss: 0.69253 - acc: 0.5933 -- iter: 1408/2235
[A[ATraining Step: 45  | total loss: [1m[32m0.69256[0m[0m | time: 65.301s
[2K
| RMSProp | epoch: 001 | loss: 0.69256 - acc: 0.5827 -- iter: 1440/2235
[A[ATraining Step: 46  | total loss: [1m[32m0.69234[0m[0m | time: 66.120s
[2K
| RMSProp | epoch: 001 | loss: 0.69234 - acc: 0.5950 -- iter: 1472/2235
[A[ATraining Step: 47  | total loss: [1m[32m0.69249[0m[0m | time: 66.876s
[2K
| RMSProp | epoch: 001 | loss: 0.69249 - acc: 0.5794 -- iter: 1504/2235
[A[ATraining Step: 48  | total loss: [1m[32m0.69242[0m[0m | time: 67.740s
[2K
| RMSProp | epoch: 001 | loss: 0.69242 - acc: 0.5817 -- iter: 1536/2235
[A[ATraining Step: 49  | total loss: [1m[32m0.69227[0m[0m | time: 68.690s
[2K
| RMSProp | epoch: 001 | loss: 0.69227 - acc: 0.5886 -- iter: 1568/2235
[A[ATraining Step: 50  | total loss: [1m[32m0.69201[0m[0m | time: 69.535s
[2K
| RMSProp | epoch: 001 | loss: 0.69201 - acc: 0.5991 -- iter: 1600/2235
[A[ATraining Step: 51  | total loss: [1m[32m0.69230[0m[0m | time: 70.428s
[2K
| RMSProp | epoch: 001 | loss: 0.69230 - acc: 0.5792 -- iter: 1632/2235
[A[ATraining Step: 52  | total loss: [1m[32m0.69234[0m[0m | time: 71.329s
[2K
| RMSProp | epoch: 001 | loss: 0.69234 - acc: 0.5720 -- iter: 1664/2235
[A[ATraining Step: 53  | total loss: [1m[32m0.69228[0m[0m | time: 72.296s
[2K
| RMSProp | epoch: 001 | loss: 0.69228 - acc: 0.5706 -- iter: 1696/2235
[A[ATraining Step: 54  | total loss: [1m[32m0.69249[0m[0m | time: 73.102s
[2K
| RMSProp | epoch: 001 | loss: 0.69249 - acc: 0.5558 -- iter: 1728/2235
[A[ATraining Step: 55  | total loss: [1m[32m0.69232[0m[0m | time: 73.887s
[2K
| RMSProp | epoch: 001 | loss: 0.69232 - acc: 0.5612 -- iter: 1760/2235
[A[ATraining Step: 56  | total loss: [1m[32m0.69238[0m[0m | time: 74.903s
[2K
| RMSProp | epoch: 001 | loss: 0.69238 - acc: 0.5570 -- iter: 1792/2235
[A[ATraining Step: 57  | total loss: [1m[32m0.69282[0m[0m | time: 75.869s
[2K
| RMSProp | epoch: 001 | loss: 0.69282 - acc: 0.5318 -- iter: 1824/2235
[A[ATraining Step: 58  | total loss: [1m[32m0.69273[0m[0m | time: 76.665s
[2K
| RMSProp | epoch: 001 | loss: 0.69273 - acc: 0.5360 -- iter: 1856/2235
[A[ATraining Step: 59  | total loss: [1m[32m0.69279[0m[0m | time: 77.382s
[2K
| RMSProp | epoch: 001 | loss: 0.69279 - acc: 0.5312 -- iter: 1888/2235
[A[ATraining Step: 60  | total loss: [1m[32m0.69229[0m[0m | time: 78.229s
[2K
| RMSProp | epoch: 001 | loss: 0.69229 - acc: 0.5601 -- iter: 1920/2235
[A[ATraining Step: 61  | total loss: [1m[32m0.69189[0m[0m | time: 79.072s
[2K
| RMSProp | epoch: 001 | loss: 0.69189 - acc: 0.5767 -- iter: 1952/2235
[A[ATraining Step: 62  | total loss: [1m[32m0.69210[0m[0m | time: 79.915s
[2K
| RMSProp | epoch: 001 | loss: 0.69210 - acc: 0.5669 -- iter: 1984/2235
[A[ATraining Step: 63  | total loss: [1m[32m0.69188[0m[0m | time: 80.867s
[2K
| RMSProp | epoch: 001 | loss: 0.69188 - acc: 0.5742 -- iter: 2016/2235
[A[ATraining Step: 64  | total loss: [1m[32m0.69194[0m[0m | time: 81.734s
[2K
| RMSProp | epoch: 001 | loss: 0.69194 - acc: 0.5689 -- iter: 2048/2235
[A[ATraining Step: 65  | total loss: [1m[32m0.69131[0m[0m | time: 82.582s
[2K
| RMSProp | epoch: 001 | loss: 0.69131 - acc: 0.5912 -- iter: 2080/2235
[A[ATraining Step: 66  | total loss: [1m[32m0.69077[0m[0m | time: 83.451s
[2K
| RMSProp | epoch: 001 | loss: 0.69077 - acc: 0.6067 -- iter: 2112/2235
[A[ATraining Step: 67  | total loss: [1m[32m0.69072[0m[0m | time: 84.296s
[2K
| RMSProp | epoch: 001 | loss: 0.69072 - acc: 0.6052 -- iter: 2144/2235
[A[ATraining Step: 68  | total loss: [1m[32m0.69067[0m[0m | time: 85.232s
[2K
| RMSProp | epoch: 001 | loss: 0.69067 - acc: 0.6038 -- iter: 2176/2235
[A[ATraining Step: 69  | total loss: [1m[32m0.69099[0m[0m | time: 86.209s
[2K
| RMSProp | epoch: 001 | loss: 0.69099 - acc: 0.5917 -- iter: 2208/2235
[A[ATraining Step: 70  | total loss: [1m[32m0.69077[0m[0m | time: 89.787s
[2K
| RMSProp | epoch: 001 | loss: 0.69077 - acc: 0.5955 | val_loss: 0.68873 - val_acc: 0.6280 -- iter: 2235/2235
--
Training Step: 71  | total loss: [1m[32m0.69082[0m[0m | time: 1.036s
[2K
| RMSProp | epoch: 002 | loss: 0.69082 - acc: 0.5910 -- iter: 0032/2235
[A[ATraining Step: 72  | total loss: [1m[32m0.69087[0m[0m | time: 2.409s
[2K
| RMSProp | epoch: 002 | loss: 0.69087 - acc: 0.5870 -- iter: 0064/2235
[A[ATraining Step: 73  | total loss: [1m[32m0.69114[0m[0m | time: 3.703s
[2K
| RMSProp | epoch: 002 | loss: 0.69114 - acc: 0.5773 -- iter: 0096/2235
[A[ATraining Step: 74  | total loss: [1m[32m0.69123[0m[0m | time: 4.706s
[2K
| RMSProp | epoch: 002 | loss: 0.69123 - acc: 0.5723 -- iter: 0128/2235
[A[ATraining Step: 75  | total loss: [1m[32m0.69071[0m[0m | time: 5.885s
[2K
| RMSProp | epoch: 002 | loss: 0.69071 - acc: 0.5848 -- iter: 0160/2235
[A[ATraining Step: 76  | total loss: [1m[32m0.69019[0m[0m | time: 6.942s
[2K
| RMSProp | epoch: 002 | loss: 0.69019 - acc: 0.5958 -- iter: 0192/2235
[A[ATraining Step: 77  | total loss: [1m[32m0.68964[0m[0m | time: 8.223s
[2K
| RMSProp | epoch: 002 | loss: 0.68964 - acc: 0.6055 -- iter: 0224/2235
[A[ATraining Step: 78  | total loss: [1m[32m0.69004[0m[0m | time: 9.394s
[2K
| RMSProp | epoch: 002 | loss: 0.69004 - acc: 0.5944 -- iter: 0256/2235
[A[ATraining Step: 79  | total loss: [1m[32m0.68997[0m[0m | time: 10.588s
[2K
| RMSProp | epoch: 002 | loss: 0.68997 - acc: 0.5944 -- iter: 0288/2235
[A[ATraining Step: 80  | total loss: [1m[32m0.68984[0m[0m | time: 11.646s
[2K
| RMSProp | epoch: 002 | loss: 0.68984 - acc: 0.5943 -- iter: 0320/2235
[A[ATraining Step: 81  | total loss: [1m[32m0.68914[0m[0m | time: 12.826s
[2K
| RMSProp | epoch: 002 | loss: 0.68914 - acc: 0.6069 -- iter: 0352/2235
[A[ATraining Step: 82  | total loss: [1m[32m0.68972[0m[0m | time: 13.953s
[2K
| RMSProp | epoch: 002 | loss: 0.68972 - acc: 0.5931 -- iter: 0384/2235
[A[ATraining Step: 83  | total loss: [1m[32m0.68960[0m[0m | time: 15.049s
[2K
| RMSProp | epoch: 002 | loss: 0.68960 - acc: 0.5931 -- iter: 0416/2235
[A[ATraining Step: 84  | total loss: [1m[32m0.68877[0m[0m | time: 16.253s
[2K
| RMSProp | epoch: 002 | loss: 0.68877 - acc: 0.6057 -- iter: 0448/2235
[A[ATraining Step: 85  | total loss: [1m[32m0.68779[0m[0m | time: 17.465s
[2K
| RMSProp | epoch: 002 | loss: 0.68779 - acc: 0.6201 -- iter: 0480/2235
[A[ATraining Step: 86  | total loss: [1m[32m0.68756[0m[0m | time: 18.664s
[2K
| RMSProp | epoch: 002 | loss: 0.68756 - acc: 0.6206 -- iter: 0512/2235
[A[ATraining Step: 87  | total loss: [1m[32m0.68773[0m[0m | time: 19.634s
[2K
| RMSProp | epoch: 002 | loss: 0.68773 - acc: 0.6148 -- iter: 0544/2235
[A[ATraining Step: 88  | total loss: [1m[32m0.68873[0m[0m | time: 20.738s
[2K
| RMSProp | epoch: 002 | loss: 0.68873 - acc: 0.5971 -- iter: 0576/2235
[A[ATraining Step: 89  | total loss: [1m[32m0.68883[0m[0m | time: 21.821s
[2K
| RMSProp | epoch: 002 | loss: 0.68883 - acc: 0.5936 -- iter: 0608/2235
[A[ATraining Step: 90  | total loss: [1m[32m0.68929[0m[0m | time: 22.933s
[2K
| RMSProp | epoch: 002 | loss: 0.68929 - acc: 0.5843 -- iter: 0640/2235
[A[ATraining Step: 91  | total loss: [1m[32m0.68889[0m[0m | time: 24.126s
[2K
| RMSProp | epoch: 002 | loss: 0.68889 - acc: 0.5883 -- iter: 0672/2235
[A[ATraining Step: 92  | total loss: [1m[32m0.68851[0m[0m | time: 25.453s
[2K
| RMSProp | epoch: 002 | loss: 0.68851 - acc: 0.5920 -- iter: 0704/2235
[A[ATraining Step: 93  | total loss: [1m[32m0.68884[0m[0m | time: 26.527s
[2K
| RMSProp | epoch: 002 | loss: 0.68884 - acc: 0.5859 -- iter: 0736/2235
[A[ATraining Step: 94  | total loss: [1m[32m0.68820[0m[0m | time: 27.710s
[2K
| RMSProp | epoch: 002 | loss: 0.68820 - acc: 0.5930 -- iter: 0768/2235
[A[ATraining Step: 95  | total loss: [1m[32m0.68833[0m[0m | time: 28.875s
[2K
| RMSProp | epoch: 002 | loss: 0.68833 - acc: 0.5899 -- iter: 0800/2235
[A[ATraining Step: 96  | total loss: [1m[32m0.68740[0m[0m | time: 30.017s
[2K
| RMSProp | epoch: 002 | loss: 0.68740 - acc: 0.5997 -- iter: 0832/2235
[A[ATraining Step: 97  | total loss: [1m[32m0.68778[0m[0m | time: 31.291s
[2K
| RMSProp | epoch: 002 | loss: 0.68778 - acc: 0.5928 -- iter: 0864/2235
[A[ATraining Step: 98  | total loss: [1m[32m0.68730[0m[0m | time: 32.677s
[2K
| RMSProp | epoch: 002 | loss: 0.68730 - acc: 0.5960 -- iter: 0896/2235
[A[ATraining Step: 99  | total loss: [1m[32m0.68771[0m[0m | time: 34.276s
[2K
| RMSProp | epoch: 002 | loss: 0.68771 - acc: 0.5896 -- iter: 0928/2235
[A[ATraining Step: 100  | total loss: [1m[32m0.68809[0m[0m | time: 35.395s
[2K
| RMSProp | epoch: 002 | loss: 0.68809 - acc: 0.5837 -- iter: 0960/2235
[A[ATraining Step: 101  | total loss: [1m[32m0.68958[0m[0m | time: 36.555s
[2K
| RMSProp | epoch: 002 | loss: 0.68958 - acc: 0.5660 -- iter: 0992/2235
[A[ATraining Step: 102  | total loss: [1m[32m0.69082[0m[0m | time: 37.683s
[2K
| RMSProp | epoch: 002 | loss: 0.69082 - acc: 0.5500 -- iter: 1024/2235
[A[ATraining Step: 103  | total loss: [1m[32m0.68991[0m[0m | time: 38.805s
[2K
| RMSProp | epoch: 002 | loss: 0.68991 - acc: 0.5606 -- iter: 1056/2235
[A[ATraining Step: 104  | total loss: [1m[32m0.68948[0m[0m | time: 40.043s
[2K
| RMSProp | epoch: 002 | loss: 0.68948 - acc: 0.5639 -- iter: 1088/2235
[A[ATraining Step: 105  | total loss: [1m[32m0.68996[0m[0m | time: 41.270s
[2K
| RMSProp | epoch: 002 | loss: 0.68996 - acc: 0.5576 -- iter: 1120/2235
[A[ATraining Step: 106  | total loss: [1m[32m0.68902[0m[0m | time: 42.453s
[2K
| RMSProp | epoch: 002 | loss: 0.68902 - acc: 0.5674 -- iter: 1152/2235
[A[ATraining Step: 107  | total loss: [1m[32m0.68750[0m[0m | time: 43.516s
[2K
| RMSProp | epoch: 002 | loss: 0.68750 - acc: 0.5826 -- iter: 1184/2235
[A[ATraining Step: 108  | total loss: [1m[32m0.68556[0m[0m | time: 44.614s
[2K
| RMSProp | epoch: 002 | loss: 0.68556 - acc: 0.5993 -- iter: 1216/2235
[A[ATraining Step: 109  | total loss: [1m[32m0.68684[0m[0m | time: 45.797s
[2K
| RMSProp | epoch: 002 | loss: 0.68684 - acc: 0.5862 -- iter: 1248/2235
[A[ATraining Step: 110  | total loss: [1m[32m0.68614[0m[0m | time: 46.994s
[2K
| RMSProp | epoch: 002 | loss: 0.68614 - acc: 0.5901 -- iter: 1280/2235
[A[ATraining Step: 111  | total loss: [1m[32m0.68706[0m[0m | time: 48.133s
[2K
| RMSProp | epoch: 002 | loss: 0.68706 - acc: 0.5811 -- iter: 1312/2235
[A[ATraining Step: 112  | total loss: [1m[32m0.68634[0m[0m | time: 49.178s
[2K
| RMSProp | epoch: 002 | loss: 0.68634 - acc: 0.5855 -- iter: 1344/2235
[A[ATraining Step: 113  | total loss: [1m[32m0.68725[0m[0m | time: 50.170s
[2K
| RMSProp | epoch: 002 | loss: 0.68725 - acc: 0.5769 -- iter: 1376/2235
[A[ATraining Step: 114  | total loss: [1m[32m0.68689[0m[0m | time: 51.266s
[2K
| RMSProp | epoch: 002 | loss: 0.68689 - acc: 0.5786 -- iter: 1408/2235
[A[ATraining Step: 115  | total loss: [1m[32m0.68817[0m[0m | time: 52.456s
[2K
| RMSProp | epoch: 002 | loss: 0.68817 - acc: 0.5676 -- iter: 1440/2235
[A[ATraining Step: 116  | total loss: [1m[32m0.68618[0m[0m | time: 53.577s
[2K
| RMSProp | epoch: 002 | loss: 0.68618 - acc: 0.5828 -- iter: 1472/2235
[A[ATraining Step: 117  | total loss: [1m[32m0.68582[0m[0m | time: 54.701s
[2K
| RMSProp | epoch: 002 | loss: 0.68582 - acc: 0.5839 -- iter: 1504/2235
[A[ATraining Step: 118  | total loss: [1m[32m0.68640[0m[0m | time: 55.989s
[2K
| RMSProp | epoch: 002 | loss: 0.68640 - acc: 0.5786 -- iter: 1536/2235
[A[ATraining Step: 119  | total loss: [1m[32m0.68591[0m[0m | time: 57.337s
[2K
| RMSProp | epoch: 002 | loss: 0.68591 - acc: 0.5801 -- iter: 1568/2235
[A[ATraining Step: 120  | total loss: [1m[32m0.68438[0m[0m | time: 58.377s
[2K
| RMSProp | epoch: 002 | loss: 0.68438 - acc: 0.5877 -- iter: 1600/2235
[A[ATraining Step: 121  | total loss: [1m[32m0.68231[0m[0m | time: 59.275s
[2K
| RMSProp | epoch: 002 | loss: 0.68231 - acc: 0.5977 -- iter: 1632/2235
[A[ATraining Step: 122  | total loss: [1m[32m0.68329[0m[0m | time: 60.285s
[2K
| RMSProp | epoch: 002 | loss: 0.68329 - acc: 0.5911 -- iter: 1664/2235
[A[ATraining Step: 123  | total loss: [1m[32m0.68281[0m[0m | time: 61.478s
[2K
| RMSProp | epoch: 002 | loss: 0.68281 - acc: 0.5913 -- iter: 1696/2235
[A[ATraining Step: 124  | total loss: [1m[32m0.68308[0m[0m | time: 62.708s
[2K
| RMSProp | epoch: 002 | loss: 0.68308 - acc: 0.5884 -- iter: 1728/2235
[A[ATraining Step: 125  | total loss: [1m[32m0.68478[0m[0m | time: 63.967s
[2K
| RMSProp | epoch: 002 | loss: 0.68478 - acc: 0.5796 -- iter: 1760/2235
[A[ATraining Step: 126  | total loss: [1m[32m0.68165[0m[0m | time: 64.981s
[2K
| RMSProp | epoch: 002 | loss: 0.68165 - acc: 0.5935 -- iter: 1792/2235
[A[ATraining Step: 127  | total loss: [1m[32m0.68026[0m[0m | time: 66.093s
[2K
| RMSProp | epoch: 002 | loss: 0.68026 - acc: 0.5967 -- iter: 1824/2235
[A[ATraining Step: 128  | total loss: [1m[32m0.67978[0m[0m | time: 67.334s
[2K
| RMSProp | epoch: 002 | loss: 0.67978 - acc: 0.5964 -- iter: 1856/2235
[A[ATraining Step: 129  | total loss: [1m[32m0.68156[0m[0m | time: 68.461s
[2K
| RMSProp | epoch: 002 | loss: 0.68156 - acc: 0.5899 -- iter: 1888/2235
[A[ATraining Step: 130  | total loss: [1m[32m0.68299[0m[0m | time: 69.616s
[2K
| RMSProp | epoch: 002 | loss: 0.68299 - acc: 0.5840 -- iter: 1920/2235
[A[ATraining Step: 131  | total loss: [1m[32m0.68392[0m[0m | time: 70.823s
[2K
| RMSProp | epoch: 002 | loss: 0.68392 - acc: 0.5787 -- iter: 1952/2235
[A[ATraining Step: 132  | total loss: [1m[32m0.68273[0m[0m | time: 72.104s
[2K
| RMSProp | epoch: 002 | loss: 0.68273 - acc: 0.5834 -- iter: 1984/2235
[A[ATraining Step: 133  | total loss: [1m[32m0.68461[0m[0m | time: 73.333s
[2K
| RMSProp | epoch: 002 | loss: 0.68461 - acc: 0.5750 -- iter: 2016/2235
[A[ATraining Step: 134  | total loss: [1m[32m0.68408[0m[0m | time: 74.435s
[2K
| RMSProp | epoch: 002 | loss: 0.68408 - acc: 0.5769 -- iter: 2048/2235
[A[ATraining Step: 135  | total loss: [1m[32m0.67833[0m[0m | time: 75.590s
[2K
| RMSProp | epoch: 002 | loss: 0.67833 - acc: 0.6004 -- iter: 2080/2235
[A[ATraining Step: 136  | total loss: [1m[32m0.68133[0m[0m | time: 76.853s
[2K
| RMSProp | epoch: 002 | loss: 0.68133 - acc: 0.5935 -- iter: 2112/2235
[A[ATraining Step: 137  | total loss: [1m[32m0.68091[0m[0m | time: 81.392s
[2K
| RMSProp | epoch: 002 | loss: 0.68091 - acc: 0.5936 -- iter: 2144/2235
[A[ATraining Step: 138  | total loss: [1m[32m0.67763[0m[0m | time: 84.396s
[2K
| RMSProp | epoch: 002 | loss: 0.67763 - acc: 0.6029 -- iter: 2176/2235
[A[ATraining Step: 139  | total loss: [1m[32m0.68322[0m[0m | time: 86.825s
[2K
| RMSProp | epoch: 002 | loss: 0.68322 - acc: 0.5895 -- iter: 2208/2235
[A[ATraining Step: 140  | total loss: [1m[32m0.68622[0m[0m | time: 92.162s
[2K
| RMSProp | epoch: 002 | loss: 0.68622 - acc: 0.5743 | val_loss: 0.67485 - val_acc: 0.6280 -- iter: 2235/2235
--
Training Step: 141  | total loss: [1m[32m0.68726[0m[0m | time: 0.853s
[2K
| RMSProp | epoch: 003 | loss: 0.68726 - acc: 0.5669 -- iter: 0032/2235
[A[ATraining Step: 142  | total loss: [1m[32m0.68469[0m[0m | time: 1.761s
[2K
| RMSProp | epoch: 003 | loss: 0.68469 - acc: 0.5806 -- iter: 0064/2235
[A[ATraining Step: 143  | total loss: [1m[32m0.68163[0m[0m | time: 2.969s
[2K
| RMSProp | epoch: 003 | loss: 0.68163 - acc: 0.5929 -- iter: 0096/2235
[A[ATraining Step: 144  | total loss: [1m[32m0.68101[0m[0m | time: 4.173s
[2K
| RMSProp | epoch: 003 | loss: 0.68101 - acc: 0.5930 -- iter: 0128/2235
[A[ATraining Step: 145  | total loss: [1m[32m0.67751[0m[0m | time: 5.497s
[2K
| RMSProp | epoch: 003 | loss: 0.67751 - acc: 0.6024 -- iter: 0160/2235
[A[ATraining Step: 146  | total loss: [1m[32m0.67589[0m[0m | time: 6.707s
[2K
| RMSProp | epoch: 003 | loss: 0.67589 - acc: 0.6047 -- iter: 0192/2235
[A[ATraining Step: 147  | total loss: [1m[32m0.68213[0m[0m | time: 7.768s
[2K
| RMSProp | epoch: 003 | loss: 0.68213 - acc: 0.5911 -- iter: 0224/2235
[A[ATraining Step: 148  | total loss: [1m[32m0.68030[0m[0m | time: 8.853s
[2K
| RMSProp | epoch: 003 | loss: 0.68030 - acc: 0.5976 -- iter: 0256/2235
[A[ATraining Step: 149  | total loss: [1m[32m0.68087[0m[0m | time: 10.097s
[2K
| RMSProp | epoch: 003 | loss: 0.68087 - acc: 0.5941 -- iter: 0288/2235
[A[ATraining Step: 150  | total loss: [1m[32m0.67703[0m[0m | time: 11.225s
[2K
| RMSProp | epoch: 003 | loss: 0.67703 - acc: 0.6066 -- iter: 0320/2235
[A[ATraining Step: 151  | total loss: [1m[32m0.67690[0m[0m | time: 12.335s
[2K
| RMSProp | epoch: 003 | loss: 0.67690 - acc: 0.6053 -- iter: 0352/2235
[A[ATraining Step: 152  | total loss: [1m[32m0.67880[0m[0m | time: 13.663s
[2K
| RMSProp | epoch: 003 | loss: 0.67880 - acc: 0.5979 -- iter: 0384/2235
[A[ATraining Step: 153  | total loss: [1m[32m0.68432[0m[0m | time: 14.992s
[2K
| RMSProp | epoch: 003 | loss: 0.68432 - acc: 0.5787 -- iter: 0416/2235
[A[ATraining Step: 154  | total loss: [1m[32m0.68271[0m[0m | time: 16.225s
[2K
| RMSProp | epoch: 003 | loss: 0.68271 - acc: 0.5865 -- iter: 0448/2235
[A[ATraining Step: 155  | total loss: [1m[32m0.68565[0m[0m | time: 17.154s
[2K
| RMSProp | epoch: 003 | loss: 0.68565 - acc: 0.5716 -- iter: 0480/2235
[A[ATraining Step: 156  | total loss: [1m[32m0.68335[0m[0m | time: 18.249s
[2K
| RMSProp | epoch: 003 | loss: 0.68335 - acc: 0.5832 -- iter: 0512/2235
[A[ATraining Step: 157  | total loss: [1m[32m0.68214[0m[0m | time: 19.444s
[2K
| RMSProp | epoch: 003 | loss: 0.68214 - acc: 0.5873 -- iter: 0544/2235
[A[ATraining Step: 158  | total loss: [1m[32m0.67920[0m[0m | time: 20.802s
[2K
| RMSProp | epoch: 003 | loss: 0.67920 - acc: 0.5974 -- iter: 0576/2235
[A[ATraining Step: 159  | total loss: [1m[32m0.68099[0m[0m | time: 22.457s
[2K
| RMSProp | epoch: 003 | loss: 0.68099 - acc: 0.5908 -- iter: 0608/2235
[A[ATraining Step: 160  | total loss: [1m[32m0.67610[0m[0m | time: 33.176s
[2K
| RMSProp | epoch: 003 | loss: 0.67610 - acc: 0.6067 -- iter: 0640/2235
[A[ATraining Step: 161  | total loss: [1m[32m0.67475[0m[0m | time: 34.173s
[2K
| RMSProp | epoch: 003 | loss: 0.67475 - acc: 0.6085 -- iter: 0672/2235
[A[ATraining Step: 162  | total loss: [1m[32m0.67945[0m[0m | time: 35.332s
[2K
| RMSProp | epoch: 003 | loss: 0.67945 - acc: 0.5977 -- iter: 0704/2235
[A[ATraining Step: 163  | total loss: [1m[32m0.67448[0m[0m | time: 36.452s
[2K
| RMSProp | epoch: 003 | loss: 0.67448 - acc: 0.6160 -- iter: 0736/2235
[A[ATraining Step: 164  | total loss: [1m[32m0.67692[0m[0m | time: 37.623s
[2K
| RMSProp | epoch: 003 | loss: 0.67692 - acc: 0.6075 -- iter: 0768/2235
[A[ATraining Step: 165  | total loss: [1m[32m0.68160[0m[0m | time: 38.920s
[2K
| RMSProp | epoch: 003 | loss: 0.68160 - acc: 0.5905 -- iter: 0800/2235
[A[ATraining Step: 166  | total loss: [1m[32m0.68326[0m[0m | time: 40.189s
[2K
| RMSProp | epoch: 003 | loss: 0.68326 - acc: 0.5815 -- iter: 0832/2235
[A[ATraining Step: 167  | total loss: [1m[32m0.68288[0m[0m | time: 41.536s
[2K
| RMSProp | epoch: 003 | loss: 0.68288 - acc: 0.5827 -- iter: 0864/2235
[A[ATraining Step: 168  | total loss: [1m[32m0.68525[0m[0m | time: 42.544s
[2K
| RMSProp | epoch: 003 | loss: 0.68525 - acc: 0.5713 -- iter: 0896/2235
[A[ATraining Step: 169  | total loss: [1m[32m0.68480[0m[0m | time: 43.611s
[2K
| RMSProp | epoch: 003 | loss: 0.68480 - acc: 0.5736 -- iter: 0928/2235
[A[ATraining Step: 170  | total loss: [1m[32m0.68476[0m[0m | time: 45.016s
[2K
| RMSProp | epoch: 003 | loss: 0.68476 - acc: 0.5725 -- iter: 0960/2235
[A[ATraining Step: 171  | total loss: [1m[32m0.68483[0m[0m | time: 46.239s
[2K
| RMSProp | epoch: 003 | loss: 0.68483 - acc: 0.5715 -- iter: 0992/2235
[A[ATraining Step: 172  | total loss: [1m[32m0.68418[0m[0m | time: 48.825s
[2K
| RMSProp | epoch: 003 | loss: 0.68418 - acc: 0.5737 -- iter: 1024/2235
[A[ATraining Step: 173  | total loss: [1m[32m0.68359[0m[0m | time: 49.903s
[2K
| RMSProp | epoch: 003 | loss: 0.68359 - acc: 0.5757 -- iter: 1056/2235
[A[ATraining Step: 174  | total loss: [1m[32m0.68604[0m[0m | time: 51.085s
[2K
| RMSProp | epoch: 003 | loss: 0.68604 - acc: 0.5650 -- iter: 1088/2235
[A[ATraining Step: 175  | total loss: [1m[32m0.68535[0m[0m | time: 52.160s
[2K
| RMSProp | epoch: 003 | loss: 0.68535 - acc: 0.5679 -- iter: 1120/2235
[A[ATraining Step: 176  | total loss: [1m[32m0.68663[0m[0m | time: 53.356s
[2K
| RMSProp | epoch: 003 | loss: 0.68663 - acc: 0.5611 -- iter: 1152/2235
[A[ATraining Step: 177  | total loss: [1m[32m0.68648[0m[0m | time: 54.533s
[2K
| RMSProp | epoch: 003 | loss: 0.68648 - acc: 0.5612 -- iter: 1184/2235
[A[ATraining Step: 178  | total loss: [1m[32m0.68441[0m[0m | time: 55.866s
[2K
| RMSProp | epoch: 003 | loss: 0.68441 - acc: 0.5707 -- iter: 1216/2235
[A[ATraining Step: 179  | total loss: [1m[32m0.68051[0m[0m | time: 57.187s
[2K
| RMSProp | epoch: 003 | loss: 0.68051 - acc: 0.5855 -- iter: 1248/2235
[A[ATraining Step: 180  | total loss: [1m[32m0.67695[0m[0m | time: 58.474s
[2K
| RMSProp | epoch: 003 | loss: 0.67695 - acc: 0.5926 -- iter: 1280/2235
[A[ATraining Step: 181  | total loss: [1m[32m0.67372[0m[0m | time: 59.783s
[2K
| RMSProp | epoch: 003 | loss: 0.67372 - acc: 0.5990 -- iter: 1312/2235
[A[ATraining Step: 182  | total loss: [1m[32m0.67666[0m[0m | time: 61.074s
[2K
| RMSProp | epoch: 003 | loss: 0.67666 - acc: 0.5922 -- iter: 1344/2235
[A[ATraining Step: 183  | total loss: [1m[32m0.67835[0m[0m | time: 62.554s
[2K
| RMSProp | epoch: 003 | loss: 0.67835 - acc: 0.5861 -- iter: 1376/2235
[A[ATraining Step: 184  | total loss: [1m[32m0.67837[0m[0m | time: 63.831s
[2K
| RMSProp | epoch: 003 | loss: 0.67837 - acc: 0.5869 -- iter: 1408/2235
[A[ATraining Step: 185  | total loss: [1m[32m0.68381[0m[0m | time: 64.955s
[2K
| RMSProp | epoch: 003 | loss: 0.68381 - acc: 0.5657 -- iter: 1440/2235
[A[ATraining Step: 186  | total loss: [1m[32m0.68303[0m[0m | time: 66.089s
[2K
| RMSProp | epoch: 003 | loss: 0.68303 - acc: 0.5716 -- iter: 1472/2235
[A[ATraining Step: 187  | total loss: [1m[32m0.68262[0m[0m | time: 67.320s
[2K
| RMSProp | epoch: 003 | loss: 0.68262 - acc: 0.5738 -- iter: 1504/2235
[A[ATraining Step: 188  | total loss: [1m[32m0.68081[0m[0m | time: 68.576s
[2K
| RMSProp | epoch: 003 | loss: 0.68081 - acc: 0.5821 -- iter: 1536/2235
[A[ATraining Step: 189  | total loss: [1m[32m0.68112[0m[0m | time: 69.720s
[2K
| RMSProp | epoch: 003 | loss: 0.68112 - acc: 0.5801 -- iter: 1568/2235
[A[ATraining Step: 190  | total loss: [1m[32m0.67909[0m[0m | time: 70.956s
[2K
| RMSProp | epoch: 003 | loss: 0.67909 - acc: 0.5877 -- iter: 1600/2235
[A[ATraining Step: 191  | total loss: [1m[32m0.68258[0m[0m | time: 72.209s
[2K
| RMSProp | epoch: 003 | loss: 0.68258 - acc: 0.5790 -- iter: 1632/2235
[A[ATraining Step: 192  | total loss: [1m[32m0.67856[0m[0m | time: 73.384s
[2K
| RMSProp | epoch: 003 | loss: 0.67856 - acc: 0.5961 -- iter: 1664/2235
[A[ATraining Step: 193  | total loss: [1m[32m0.67826[0m[0m | time: 74.721s
[2K
| RMSProp | epoch: 003 | loss: 0.67826 - acc: 0.5958 -- iter: 1696/2235
[A[ATraining Step: 194  | total loss: [1m[32m0.67811[0m[0m | time: 75.859s
[2K
| RMSProp | epoch: 003 | loss: 0.67811 - acc: 0.5956 -- iter: 1728/2235
[A[ATraining Step: 195  | total loss: [1m[32m0.67788[0m[0m | time: 77.112s
[2K
| RMSProp | epoch: 003 | loss: 0.67788 - acc: 0.5954 -- iter: 1760/2235
[A[ATraining Step: 196  | total loss: [1m[32m0.67756[0m[0m | time: 78.392s
[2K
| RMSProp | epoch: 003 | loss: 0.67756 - acc: 0.5953 -- iter: 1792/2235
[A[ATraining Step: 197  | total loss: [1m[32m0.67502[0m[0m | time: 79.645s
[2K
| RMSProp | epoch: 003 | loss: 0.67502 - acc: 0.6014 -- iter: 1824/2235
[A[ATraining Step: 198  | total loss: [1m[32m0.68313[0m[0m | time: 102.783s
[2K
| RMSProp | epoch: 003 | loss: 0.68313 - acc: 0.5881 -- iter: 1856/2235
[A[ATraining Step: 199  | total loss: [1m[32m0.68476[0m[0m | time: 110.089s
[2K
| RMSProp | epoch: 003 | loss: 0.68476 - acc: 0.5793 -- iter: 1888/2235
[A[ATraining Step: 200  | total loss: [1m[32m0.68768[0m[0m | time: 116.122s
[2K
| RMSProp | epoch: 003 | loss: 0.68768 - acc: 0.5651 | val_loss: 0.67546 - val_acc: 0.6280 -- iter: 1920/2235
--
Training Step: 201  | total loss: [1m[32m0.69115[0m[0m | time: 117.418s
[2K
| RMSProp | epoch: 003 | loss: 0.69115 - acc: 0.5461 -- iter: 1952/2235
[A[ATraining Step: 202  | total loss: [1m[32m0.68860[0m[0m | time: 118.648s
[2K
| RMSProp | epoch: 003 | loss: 0.68860 - acc: 0.5602 -- iter: 1984/2235
[A[ATraining Step: 203  | total loss: [1m[32m0.69186[0m[0m | time: 119.928s
[2K
| RMSProp | epoch: 003 | loss: 0.69186 - acc: 0.5417 -- iter: 2016/2235
[A[ATraining Step: 204  | total loss: [1m[32m0.68723[0m[0m | time: 121.291s
[2K
| RMSProp | epoch: 003 | loss: 0.68723 - acc: 0.5688 -- iter: 2048/2235
[A[ATraining Step: 205  | total loss: [1m[32m0.68711[0m[0m | time: 122.561s
[2K
| RMSProp | epoch: 003 | loss: 0.68711 - acc: 0.5682 -- iter: 2080/2235
[A[ATraining Step: 206  | total loss: [1m[32m0.68758[0m[0m | time: 123.919s
[2K
| RMSProp | epoch: 003 | loss: 0.68758 - acc: 0.5645 -- iter: 2112/2235
[A[ATraining Step: 207  | total loss: [1m[32m0.68555[0m[0m | time: 125.045s
[2K
| RMSProp | epoch: 003 | loss: 0.68555 - acc: 0.5737 -- iter: 2144/2235
[A[ATraining Step: 208  | total loss: [1m[32m0.68208[0m[0m | time: 126.219s
[2K
| RMSProp | epoch: 003 | loss: 0.68208 - acc: 0.5882 -- iter: 2176/2235
[A[ATraining Step: 209  | total loss: [1m[32m0.68500[0m[0m | time: 127.421s
[2K
| RMSProp | epoch: 003 | loss: 0.68500 - acc: 0.5762 -- iter: 2208/2235
[A[ATraining Step: 210  | total loss: [1m[32m0.68281[0m[0m | time: 134.058s
[2K
| RMSProp | epoch: 003 | loss: 0.68281 - acc: 0.5842 | val_loss: 0.66807 - val_acc: 0.6280 -- iter: 2235/2235
--
Training Step: 211  | total loss: [1m[32m0.68291[0m[0m | time: 1.409s
[2K
| RMSProp | epoch: 004 | loss: 0.68291 - acc: 0.5821 -- iter: 0032/2235
[A[ATraining Step: 212  | total loss: [1m[32m0.68308[0m[0m | time: 12.553s
[2K
| RMSProp | epoch: 004 | loss: 0.68308 - acc: 0.5801 -- iter: 0064/2235
[A[ATraining Step: 213  | total loss: [1m[32m0.67961[0m[0m | time: 38.383s
[2K
| RMSProp | epoch: 004 | loss: 0.67961 - acc: 0.5925 -- iter: 0096/2235
[A[ATraining Step: 214  | total loss: [1m[32m0.67535[0m[0m | time: 47.482s
[2K
| RMSProp | epoch: 004 | loss: 0.67535 - acc: 0.6036 -- iter: 0128/2235
[A[ATraining Step: 215  | total loss: [1m[32m0.67194[0m[0m | time: 48.673s
[2K
| RMSProp | epoch: 004 | loss: 0.67194 - acc: 0.6088 -- iter: 0160/2235
[A[ATraining Step: 216  | total loss: [1m[32m0.67137[0m[0m | time: 49.987s
[2K
| RMSProp | epoch: 004 | loss: 0.67137 - acc: 0.6105 -- iter: 0192/2235
[A[ATraining Step: 217  | total loss: [1m[32m0.67198[0m[0m | time: 51.231s
[2K
| RMSProp | epoch: 004 | loss: 0.67198 - acc: 0.6088 -- iter: 0224/2235
[A[ATraining Step: 218  | total loss: [1m[32m0.67337[0m[0m | time: 52.411s
[2K
| RMSProp | epoch: 004 | loss: 0.67337 - acc: 0.6042 -- iter: 0256/2235
[A[ATraining Step: 219  | total loss: [1m[32m0.67032[0m[0m | time: 53.588s
[2K
| RMSProp | epoch: 004 | loss: 0.67032 - acc: 0.6125 -- iter: 0288/2235
[A[ATraining Step: 220  | total loss: [1m[32m0.67220[0m[0m | time: 54.859s
[2K
| RMSProp | epoch: 004 | loss: 0.67220 - acc: 0.6075 -- iter: 0320/2235
[A[ATraining Step: 221  | total loss: [1m[32m0.67000[0m[0m | time: 56.148s
[2K
| RMSProp | epoch: 004 | loss: 0.67000 - acc: 0.6124 -- iter: 0352/2235
[A[ATraining Step: 222  | total loss: [1m[32m0.67688[0m[0m | time: 57.374s
[2K
| RMSProp | epoch: 004 | loss: 0.67688 - acc: 0.5980 -- iter: 0384/2235
[A[ATraining Step: 223  | total loss: [1m[32m0.67609[0m[0m | time: 58.563s
[2K
| RMSProp | epoch: 004 | loss: 0.67609 - acc: 0.6007 -- iter: 0416/2235
[A[ATraining Step: 224  | total loss: [1m[32m0.67610[0m[0m | time: 59.854s
[2K
| RMSProp | epoch: 004 | loss: 0.67610 - acc: 0.6000 -- iter: 0448/2235
[A[ATraining Step: 225  | total loss: [1m[32m0.67250[0m[0m | time: 61.101s
[2K
| RMSProp | epoch: 004 | loss: 0.67250 - acc: 0.6119 -- iter: 0480/2235
[A[ATraining Step: 226  | total loss: [1m[32m0.67158[0m[0m | time: 62.289s
[2K
| RMSProp | epoch: 004 | loss: 0.67158 - acc: 0.6132 -- iter: 0512/2235
[A[ATraining Step: 227  | total loss: [1m[32m0.66666[0m[0m | time: 63.428s
[2K
| RMSProp | epoch: 004 | loss: 0.66666 - acc: 0.6238 -- iter: 0544/2235
[A[ATraining Step: 228  | total loss: [1m[32m0.67670[0m[0m | time: 64.671s
[2K
| RMSProp | epoch: 004 | loss: 0.67670 - acc: 0.6083 -- iter: 0576/2235
[A[ATraining Step: 229  | total loss: [1m[32m0.67567[0m[0m | time: 65.886s
[2K
| RMSProp | epoch: 004 | loss: 0.67567 - acc: 0.6099 -- iter: 0608/2235
[A[ATraining Step: 230  | total loss: [1m[32m0.67765[0m[0m | time: 67.135s
[2K
| RMSProp | epoch: 004 | loss: 0.67765 - acc: 0.6021 -- iter: 0640/2235
[A[ATraining Step: 231  | total loss: [1m[32m0.67835[0m[0m | time: 68.416s
[2K
| RMSProp | epoch: 004 | loss: 0.67835 - acc: 0.5981 -- iter: 0672/2235
[A[ATraining Step: 232  | total loss: [1m[32m0.67619[0m[0m | time: 69.763s
[2K
| RMSProp | epoch: 004 | loss: 0.67619 - acc: 0.6039 -- iter: 0704/2235
[A[ATraining Step: 233  | total loss: [1m[32m0.67716[0m[0m | time: 71.124s
[2K
| RMSProp | epoch: 004 | loss: 0.67716 - acc: 0.5998 -- iter: 0736/2235
[A[ATraining Step: 234  | total loss: [1m[32m0.67796[0m[0m | time: 72.446s
[2K
| RMSProp | epoch: 004 | loss: 0.67796 - acc: 0.5960 -- iter: 0768/2235
[A[ATraining Step: 235  | total loss: [1m[32m0.67867[0m[0m | time: 73.672s
[2K
| RMSProp | epoch: 004 | loss: 0.67867 - acc: 0.5927 -- iter: 0800/2235
[A[ATraining Step: 236  | total loss: [1m[32m0.68210[0m[0m | time: 74.959s
[2K
| RMSProp | epoch: 004 | loss: 0.68210 - acc: 0.5803 -- iter: 0832/2235
[A[ATraining Step: 237  | total loss: [1m[32m0.67918[0m[0m | time: 76.172s
[2K
| RMSProp | epoch: 004 | loss: 0.67918 - acc: 0.5910 -- iter: 0864/2235
[A[ATraining Step: 238  | total loss: [1m[32m0.68367[0m[0m | time: 77.286s
[2K
| RMSProp | epoch: 004 | loss: 0.68367 - acc: 0.5757 -- iter: 0896/2235
[A[ATraining Step: 239  | total loss: [1m[32m0.68373[0m[0m | time: 78.431s
[2K
| RMSProp | epoch: 004 | loss: 0.68373 - acc: 0.5744 -- iter: 0928/2235
[A[ATraining Step: 240  | total loss: [1m[32m0.68689[0m[0m | time: 79.641s
[2K
| RMSProp | epoch: 004 | loss: 0.68689 - acc: 0.5607 -- iter: 0960/2235
[A[ATraining Step: 241  | total loss: [1m[32m0.68670[0m[0m | time: 80.944s
[2K
| RMSProp | epoch: 004 | loss: 0.68670 - acc: 0.5608 -- iter: 0992/2235
[A[ATraining Step: 242  | total loss: [1m[32m0.68720[0m[0m | time: 82.257s
[2K
| RMSProp | epoch: 004 | loss: 0.68720 - acc: 0.5579 -- iter: 1024/2235
[A[ATraining Step: 243  | total loss: [1m[32m0.68624[0m[0m | time: 83.424s
[2K
| RMSProp | epoch: 004 | loss: 0.68624 - acc: 0.5615 -- iter: 1056/2235
[A[ATraining Step: 244  | total loss: [1m[32m0.68906[0m[0m | time: 84.961s
[2K
| RMSProp | epoch: 004 | loss: 0.68906 - acc: 0.5491 -- iter: 1088/2235
[A[ATraining Step: 245  | total loss: [1m[32m0.69045[0m[0m | time: 86.078s
[2K
| RMSProp | epoch: 004 | loss: 0.69045 - acc: 0.5410 -- iter: 1120/2235
[A[ATraining Step: 246  | total loss: [1m[32m0.68563[0m[0m | time: 87.177s
[2K
| RMSProp | epoch: 004 | loss: 0.68563 - acc: 0.5682 -- iter: 1152/2235
[A[ATraining Step: 247  | total loss: [1m[32m0.68330[0m[0m | time: 88.401s
[2K
| RMSProp | epoch: 004 | loss: 0.68330 - acc: 0.5770 -- iter: 1184/2235
[A[ATraining Step: 248  | total loss: [1m[32m0.67985[0m[0m | time: 89.560s
[2K
| RMSProp | epoch: 004 | loss: 0.67985 - acc: 0.5880 -- iter: 1216/2235
[A[ATraining Step: 249  | total loss: [1m[32m0.67269[0m[0m | time: 90.815s
[2K
| RMSProp | epoch: 004 | loss: 0.67269 - acc: 0.6042 -- iter: 1248/2235
[A[ATraining Step: 250  | total loss: [1m[32m0.68748[0m[0m | time: 92.060s
[2K
| RMSProp | epoch: 004 | loss: 0.68748 - acc: 0.5938 -- iter: 1280/2235
[A[ATraining Step: 251  | total loss: [1m[32m0.68523[0m[0m | time: 93.315s
[2K
| RMSProp | epoch: 004 | loss: 0.68523 - acc: 0.5969 -- iter: 1312/2235
[A[ATraining Step: 252  | total loss: [1m[32m0.68199[0m[0m | time: 94.766s
[2K
| RMSProp | epoch: 004 | loss: 0.68199 - acc: 0.6029 -- iter: 1344/2235
[A[ATraining Step: 253  | total loss: [1m[32m0.68218[0m[0m | time: 96.271s
[2K
| RMSProp | epoch: 004 | loss: 0.68218 - acc: 0.5988 -- iter: 1376/2235
[A[ATraining Step: 254  | total loss: [1m[32m0.68001[0m[0m | time: 97.617s
[2K
| RMSProp | epoch: 004 | loss: 0.68001 - acc: 0.6014 -- iter: 1408/2235
[A[ATraining Step: 255  | total loss: [1m[32m0.68062[0m[0m | time: 98.922s
[2K
| RMSProp | epoch: 004 | loss: 0.68062 - acc: 0.5976 -- iter: 1440/2235
[A[ATraining Step: 256  | total loss: [1m[32m0.68791[0m[0m | time: 100.216s
[2K
| RMSProp | epoch: 004 | loss: 0.68791 - acc: 0.5753 -- iter: 1472/2235
[A[ATraining Step: 257  | total loss: [1m[32m0.68923[0m[0m | time: 101.652s
[2K
| RMSProp | epoch: 004 | loss: 0.68923 - acc: 0.5678 -- iter: 1504/2235
[A[ATraining Step: 258  | total loss: [1m[32m0.68801[0m[0m | time: 103.022s
[2K
| RMSProp | epoch: 004 | loss: 0.68801 - acc: 0.5704 -- iter: 1536/2235
[A[ATraining Step: 259  | total loss: [1m[32m0.68596[0m[0m | time: 104.393s
[2K
| RMSProp | epoch: 004 | loss: 0.68596 - acc: 0.5758 -- iter: 1568/2235
[A[ATraining Step: 260  | total loss: [1m[32m0.68946[0m[0m | time: 105.939s
[2K
| RMSProp | epoch: 004 | loss: 0.68946 - acc: 0.5620 -- iter: 1600/2235
[A[ATraining Step: 261  | total loss: [1m[32m0.69128[0m[0m | time: 107.477s
[2K
| RMSProp | epoch: 004 | loss: 0.69128 - acc: 0.5527 -- iter: 1632/2235
[A[ATraining Step: 262  | total loss: [1m[32m0.68729[0m[0m | time: 109.096s
[2K
| RMSProp | epoch: 004 | loss: 0.68729 - acc: 0.5693 -- iter: 1664/2235
[A[ATraining Step: 263  | total loss: [1m[32m0.68711[0m[0m | time: 110.445s
[2K
| RMSProp | epoch: 004 | loss: 0.68711 - acc: 0.5686 -- iter: 1696/2235
[A[ATraining Step: 264  | total loss: [1m[32m0.68573[0m[0m | time: 111.823s
[2K
| RMSProp | epoch: 004 | loss: 0.68573 - acc: 0.5711 -- iter: 1728/2235
[A[ATraining Step: 265  | total loss: [1m[32m0.68394[0m[0m | time: 113.304s
[2K
| RMSProp | epoch: 004 | loss: 0.68394 - acc: 0.5765 -- iter: 1760/2235
[A[ATraining Step: 266  | total loss: [1m[32m0.68867[0m[0m | time: 114.785s
[2K
| RMSProp | epoch: 004 | loss: 0.68867 - acc: 0.5595 -- iter: 1792/2235
[A[ATraining Step: 267  | total loss: [1m[32m0.69119[0m[0m | time: 119.691s
[2K
| RMSProp | epoch: 004 | loss: 0.69119 - acc: 0.5473 -- iter: 1824/2235
[A[ATraining Step: 268  | total loss: [1m[32m0.68801[0m[0m | time: 128.535s
[2K
| RMSProp | epoch: 004 | loss: 0.68801 - acc: 0.5613 -- iter: 1856/2235
[A[ATraining Step: 269  | total loss: [1m[32m0.68618[0m[0m | time: 137.955s
[2K
| RMSProp | epoch: 004 | loss: 0.68618 - acc: 0.5677 -- iter: 1888/2235
[A[ATraining Step: 270  | total loss: [1m[32m0.68334[0m[0m | time: 152.921s
[2K
| RMSProp | epoch: 004 | loss: 0.68334 - acc: 0.5765 -- iter: 1920/2235
[A[ATraining Step: 271  | total loss: [1m[32m0.67878[0m[0m | time: 157.632s
[2K
| RMSProp | epoch: 004 | loss: 0.67878 - acc: 0.5908 -- iter: 1952/2235
[A[ATraining Step: 272  | total loss: [1m[32m0.67693[0m[0m | time: 159.177s
[2K
| RMSProp | epoch: 004 | loss: 0.67693 - acc: 0.5942 -- iter: 1984/2235
[A[ATraining Step: 273  | total loss: [1m[32m0.67521[0m[0m | time: 160.714s
[2K
| RMSProp | epoch: 004 | loss: 0.67521 - acc: 0.5973 -- iter: 2016/2235
[A[ATraining Step: 274  | total loss: [1m[32m0.67810[0m[0m | time: 162.271s
[2K
| RMSProp | epoch: 004 | loss: 0.67810 - acc: 0.5907 -- iter: 2048/2235
[A[ATraining Step: 275  | total loss: [1m[32m0.67673[0m[0m | time: 163.760s
[2K
| RMSProp | epoch: 004 | loss: 0.67673 - acc: 0.5941 -- iter: 2080/2235
[A[ATraining Step: 276  | total loss: [1m[32m0.67478[0m[0m | time: 165.338s
[2K
| RMSProp | epoch: 004 | loss: 0.67478 - acc: 0.5972 -- iter: 2112/2235
[A[ATraining Step: 277  | total loss: [1m[32m0.68159[0m[0m | time: 166.766s
[2K
| RMSProp | epoch: 004 | loss: 0.68159 - acc: 0.5812 -- iter: 2144/2235
[A[ATraining Step: 278  | total loss: [1m[32m0.67867[0m[0m | time: 168.269s
[2K
| RMSProp | epoch: 004 | loss: 0.67867 - acc: 0.5918 -- iter: 2176/2235
[A[ATraining Step: 279  | total loss: [1m[32m0.67357[0m[0m | time: 169.650s
[2K
| RMSProp | epoch: 004 | loss: 0.67357 - acc: 0.6077 -- iter: 2208/2235
[A[ATraining Step: 280  | total loss: [1m[32m0.67609[0m[0m | time: 176.408s
[2K
| RMSProp | epoch: 004 | loss: 0.67609 - acc: 0.6000 | val_loss: 0.66439 - val_acc: 0.6280 -- iter: 2235/2235
--
Training Step: 281  | total loss: [1m[32m0.67902[0m[0m | time: 1.130s
[2K
| RMSProp | epoch: 005 | loss: 0.67902 - acc: 0.5900 -- iter: 0032/2235
[A[ATraining Step: 282  | total loss: [1m[32m0.67843[0m[0m | time: 2.511s
[2K
| RMSProp | epoch: 005 | loss: 0.67843 - acc: 0.5904 -- iter: 0064/2235
[A[ATraining Step: 283  | total loss: [1m[32m0.68090[0m[0m | time: 3.684s
[2K
| RMSProp | epoch: 005 | loss: 0.68090 - acc: 0.5814 -- iter: 0096/2235
[A[ATraining Step: 284  | total loss: [1m[32m0.68061[0m[0m | time: 4.705s
[2K
| RMSProp | epoch: 005 | loss: 0.68061 - acc: 0.5825 -- iter: 0128/2235
[A[ATraining Step: 285  | total loss: [1m[32m0.68012[0m[0m | time: 5.920s
[2K
| RMSProp | epoch: 005 | loss: 0.68012 - acc: 0.5835 -- iter: 0160/2235
[A[ATraining Step: 286  | total loss: [1m[32m0.67939[0m[0m | time: 7.253s
[2K
| RMSProp | epoch: 005 | loss: 0.67939 - acc: 0.5845 -- iter: 0192/2235
[A[ATraining Step: 287  | total loss: [1m[32m0.67701[0m[0m | time: 8.147s
[2K
| RMSProp | epoch: 005 | loss: 0.67701 - acc: 0.5917 -- iter: 0224/2235
[A[ATraining Step: 288  | total loss: [1m[32m0.67752[0m[0m | time: 8.903s
[2K
| RMSProp | epoch: 005 | loss: 0.67752 - acc: 0.5888 -- iter: 0256/2235
[A[ATraining Step: 289  | total loss: [1m[32m0.67470[0m[0m | time: 9.706s
[2K
| RMSProp | epoch: 005 | loss: 0.67470 - acc: 0.5955 -- iter: 0288/2235
[A[ATraining Step: 290  | total loss: [1m[32m0.67289[0m[0m | time: 10.457s
[2K
| RMSProp | epoch: 005 | loss: 0.67289 - acc: 0.5985 -- iter: 0320/2235
[A[ATraining Step: 291  | total loss: [1m[32m0.66790[0m[0m | time: 11.275s
[2K
| RMSProp | epoch: 005 | loss: 0.66790 - acc: 0.6074 -- iter: 0352/2235
[A[ATraining Step: 292  | total loss: [1m[32m0.68120[0m[0m | time: 12.121s
[2K
| RMSProp | epoch: 005 | loss: 0.68120 - acc: 0.5935 -- iter: 0384/2235
[A[ATraining Step: 293  | total loss: [1m[32m0.68200[0m[0m | time: 12.870s
[2K
| RMSProp | epoch: 005 | loss: 0.68200 - acc: 0.5873 -- iter: 0416/2235
[A[ATraining Step: 294  | total loss: [1m[32m0.68338[0m[0m | time: 13.646s
[2K
| RMSProp | epoch: 005 | loss: 0.68338 - acc: 0.5817 -- iter: 0448/2235
[A[ATraining Step: 295  | total loss: [1m[32m0.68506[0m[0m | time: 14.465s
[2K
| RMSProp | epoch: 005 | loss: 0.68506 - acc: 0.5735 -- iter: 0480/2235
[A[ATraining Step: 296  | total loss: [1m[32m0.68015[0m[0m | time: 15.247s
[2K
| RMSProp | epoch: 005 | loss: 0.68015 - acc: 0.5912 -- iter: 0512/2235
[A[ATraining Step: 297  | total loss: [1m[32m0.68027[0m[0m | time: 15.979s
[2K
| RMSProp | epoch: 005 | loss: 0.68027 - acc: 0.5883 -- iter: 0544/2235
[A[ATraining Step: 298  | total loss: [1m[32m0.67887[0m[0m | time: 16.747s
[2K
| RMSProp | epoch: 005 | loss: 0.67887 - acc: 0.5888 -- iter: 0576/2235
[A[ATraining Step: 299  | total loss: [1m[32m0.67971[0m[0m | time: 17.559s
[2K
| RMSProp | epoch: 005 | loss: 0.67971 - acc: 0.5862 -- iter: 0608/2235
[A[ATraining Step: 300  | total loss: [1m[32m0.67567[0m[0m | time: 18.321s
[2K
| RMSProp | epoch: 005 | loss: 0.67567 - acc: 0.5963 -- iter: 0640/2235
[A[ATraining Step: 301  | total loss: [1m[32m0.67011[0m[0m | time: 19.333s
[2K
| RMSProp | epoch: 005 | loss: 0.67011 - acc: 0.6086 -- iter: 0672/2235
[A[ATraining Step: 302  | total loss: [1m[32m0.66604[0m[0m | time: 20.491s
[2K
| RMSProp | epoch: 005 | loss: 0.66604 - acc: 0.6165 -- iter: 0704/2235
[A[ATraining Step: 303  | total loss: [1m[32m0.67586[0m[0m | time: 21.599s
[2K
| RMSProp | epoch: 005 | loss: 0.67586 - acc: 0.6017 -- iter: 0736/2235
[A[ATraining Step: 304  | total loss: [1m[32m0.68308[0m[0m | time: 22.471s
[2K
| RMSProp | epoch: 005 | loss: 0.68308 - acc: 0.5790 -- iter: 0768/2235
[A[ATraining Step: 305  | total loss: [1m[32m0.67853[0m[0m | time: 23.406s
[2K
| RMSProp | epoch: 005 | loss: 0.67853 - acc: 0.5961 -- iter: 0800/2235
[A[ATraining Step: 306  | total loss: [1m[32m0.67963[0m[0m | time: 24.451s
[2K
| RMSProp | epoch: 005 | loss: 0.67963 - acc: 0.5896 -- iter: 0832/2235
[A[ATraining Step: 307  | total loss: [1m[32m0.67963[0m[0m | time: 25.538s
[2K
| RMSProp | epoch: 005 | loss: 0.67963 - acc: 0.5869 -- iter: 0864/2235
[A[ATraining Step: 308  | total loss: [1m[32m0.68068[0m[0m | time: 26.596s
[2K
| RMSProp | epoch: 005 | loss: 0.68068 - acc: 0.5814 -- iter: 0896/2235
[A[ATraining Step: 309  | total loss: [1m[32m0.68295[0m[0m | time: 27.680s
[2K
| RMSProp | epoch: 005 | loss: 0.68295 - acc: 0.5732 -- iter: 0928/2235
[A[ATraining Step: 310  | total loss: [1m[32m0.68621[0m[0m | time: 28.894s
[2K
| RMSProp | epoch: 005 | loss: 0.68621 - acc: 0.5596 -- iter: 0960/2235
[A[ATraining Step: 311  | total loss: [1m[32m0.68436[0m[0m | time: 30.256s
[2K
| RMSProp | epoch: 005 | loss: 0.68436 - acc: 0.5662 -- iter: 0992/2235
[A[ATraining Step: 312  | total loss: [1m[32m0.67904[0m[0m | time: 31.731s
[2K
| RMSProp | epoch: 005 | loss: 0.67904 - acc: 0.5846 -- iter: 1024/2235
[A[ATraining Step: 313  | total loss: [1m[32m0.67729[0m[0m | time: 33.260s
[2K
| RMSProp | epoch: 005 | loss: 0.67729 - acc: 0.5886 -- iter: 1056/2235
[A[ATraining Step: 314  | total loss: [1m[32m0.68396[0m[0m | time: 43.026s
[2K
| RMSProp | epoch: 005 | loss: 0.68396 - acc: 0.5704 -- iter: 1088/2235
[A[ATraining Step: 315  | total loss: [1m[32m0.68508[0m[0m | time: 58.325s
[2K
| RMSProp | epoch: 005 | loss: 0.68508 - acc: 0.5633 -- iter: 1120/2235
[A[ATraining Step: 316  | total loss: [1m[32m0.68521[0m[0m | time: 66.392s
[2K
| RMSProp | epoch: 005 | loss: 0.68521 - acc: 0.5601 -- iter: 1152/2235
[A[ATraining Step: 317  | total loss: [1m[32m0.68040[0m[0m | time: 67.604s
[2K
| RMSProp | epoch: 005 | loss: 0.68040 - acc: 0.5760 -- iter: 1184/2235
[A[ATraining Step: 318  | total loss: [1m[32m0.67651[0m[0m | time: 68.998s
[2K
| RMSProp | epoch: 005 | loss: 0.67651 - acc: 0.5840 -- iter: 1216/2235
[A[ATraining Step: 319  | total loss: [1m[32m0.67165[0m[0m | time: 72.573s
[2K
| RMSProp | epoch: 005 | loss: 0.67165 - acc: 0.5912 -- iter: 1248/2235
[A[ATraining Step: 320  | total loss: [1m[32m0.67287[0m[0m | time: 75.820s
[2K
| RMSProp | epoch: 005 | loss: 0.67287 - acc: 0.5884 -- iter: 1280/2235
[A[ATraining Step: 321  | total loss: [1m[32m0.67282[0m[0m | time: 77.038s
[2K
| RMSProp | epoch: 005 | loss: 0.67282 - acc: 0.5858 -- iter: 1312/2235
[A[ATraining Step: 322  | total loss: [1m[32m0.66444[0m[0m | time: 78.385s
[2K
| RMSProp | epoch: 005 | loss: 0.66444 - acc: 0.6053 -- iter: 1344/2235
[A[ATraining Step: 323  | total loss: [1m[32m0.68218[0m[0m | time: 79.821s
[2K
| RMSProp | epoch: 005 | loss: 0.68218 - acc: 0.5885 -- iter: 1376/2235
[A[ATraining Step: 324  | total loss: [1m[32m0.67827[0m[0m | time: 81.211s
[2K
| RMSProp | epoch: 005 | loss: 0.67827 - acc: 0.5984 -- iter: 1408/2235
[A[ATraining Step: 325  | total loss: [1m[32m0.67869[0m[0m | time: 82.654s
[2K
| RMSProp | epoch: 005 | loss: 0.67869 - acc: 0.5917 -- iter: 1440/2235
[A[ATraining Step: 326  | total loss: [1m[32m0.66999[0m[0m | time: 84.009s
[2K
| RMSProp | epoch: 005 | loss: 0.66999 - acc: 0.6107 -- iter: 1472/2235
[A[ATraining Step: 327  | total loss: [1m[32m0.66912[0m[0m | time: 85.413s
[2K
| RMSProp | epoch: 005 | loss: 0.66912 - acc: 0.6090 -- iter: 1504/2235
[A[ATraining Step: 328  | total loss: [1m[32m0.67419[0m[0m | time: 86.951s
[2K
| RMSProp | epoch: 005 | loss: 0.67419 - acc: 0.5981 -- iter: 1536/2235
[A[ATraining Step: 329  | total loss: [1m[32m0.67696[0m[0m | time: 88.741s
[2K
| RMSProp | epoch: 005 | loss: 0.67696 - acc: 0.5883 -- iter: 1568/2235
[A[ATraining Step: 330  | total loss: [1m[32m0.67924[0m[0m | time: 105.357s
[2K
| RMSProp | epoch: 005 | loss: 0.67924 - acc: 0.5794 -- iter: 1600/2235
[A[ATraining Step: 331  | total loss: [1m[32m0.67941[0m[0m | time: 117.036s
[2K
| RMSProp | epoch: 005 | loss: 0.67941 - acc: 0.5746 -- iter: 1632/2235
[A[ATraining Step: 332  | total loss: [1m[32m0.67862[0m[0m | time: 124.584s
[2K
| RMSProp | epoch: 005 | loss: 0.67862 - acc: 0.5765 -- iter: 1664/2235
[A[ATraining Step: 333  | total loss: [1m[32m0.67404[0m[0m | time: 125.919s
[2K
| RMSProp | epoch: 005 | loss: 0.67404 - acc: 0.5876 -- iter: 1696/2235
[A[ATraining Step: 334  | total loss: [1m[32m0.67713[0m[0m | time: 127.330s
[2K
| RMSProp | epoch: 005 | loss: 0.67713 - acc: 0.5789 -- iter: 1728/2235
[A[ATraining Step: 335  | total loss: [1m[32m0.67487[0m[0m | time: 128.565s
[2K
| RMSProp | epoch: 005 | loss: 0.67487 - acc: 0.5835 -- iter: 1760/2235
[A[ATraining Step: 336  | total loss: [1m[32m0.67485[0m[0m | time: 129.992s
[2K
| RMSProp | epoch: 005 | loss: 0.67485 - acc: 0.5814 -- iter: 1792/2235
[A[ATraining Step: 337  | total loss: [1m[32m0.67646[0m[0m | time: 131.491s
[2K
| RMSProp | epoch: 005 | loss: 0.67646 - acc: 0.5764 -- iter: 1824/2235
[A[ATraining Step: 338  | total loss: [1m[32m0.67639[0m[0m | time: 132.912s
[2K
| RMSProp | epoch: 005 | loss: 0.67639 - acc: 0.5719 -- iter: 1856/2235
[A[ATraining Step: 339  | total loss: [1m[32m0.67676[0m[0m | time: 134.349s
[2K
| RMSProp | epoch: 005 | loss: 0.67676 - acc: 0.5740 -- iter: 1888/2235
[A[ATraining Step: 340  | total loss: [1m[32m0.66881[0m[0m | time: 135.785s
[2K
| RMSProp | epoch: 005 | loss: 0.66881 - acc: 0.5979 -- iter: 1920/2235
[A[ATraining Step: 341  | total loss: [1m[32m0.68129[0m[0m | time: 137.487s
[2K
| RMSProp | epoch: 005 | loss: 0.68129 - acc: 0.5756 -- iter: 1952/2235
[A[ATraining Step: 342  | total loss: [1m[32m0.68127[0m[0m | time: 138.897s
[2K
| RMSProp | epoch: 005 | loss: 0.68127 - acc: 0.5712 -- iter: 1984/2235
[A[ATraining Step: 343  | total loss: [1m[32m0.67784[0m[0m | time: 140.346s
[2K
| RMSProp | epoch: 005 | loss: 0.67784 - acc: 0.5766 -- iter: 2016/2235
[A[ATraining Step: 344  | total loss: [1m[32m0.67753[0m[0m | time: 150.151s
[2K
| RMSProp | epoch: 005 | loss: 0.67753 - acc: 0.5720 -- iter: 2048/2235
[A[ATraining Step: 345  | total loss: [1m[32m0.67971[0m[0m | time: 158.544s
[2K
| RMSProp | epoch: 005 | loss: 0.67971 - acc: 0.5617 -- iter: 2080/2235
[A[ATraining Step: 346  | total loss: [1m[32m0.67713[0m[0m | time: 162.848s
[2K
| RMSProp | epoch: 005 | loss: 0.67713 - acc: 0.5743 -- iter: 2112/2235
[A[ATraining Step: 347  | total loss: [1m[32m0.67936[0m[0m | time: 164.565s
[2K
| RMSProp | epoch: 005 | loss: 0.67936 - acc: 0.5668 -- iter: 2144/2235
[A[ATraining Step: 348  | total loss: [1m[32m0.67646[0m[0m | time: 170.582s
[2K
| RMSProp | epoch: 005 | loss: 0.67646 - acc: 0.5727 -- iter: 2176/2235
[A[ATraining Step: 349  | total loss: [1m[32m0.67537[0m[0m | time: 172.994s
[2K
| RMSProp | epoch: 005 | loss: 0.67537 - acc: 0.5716 -- iter: 2208/2235
[A[ATraining Step: 350  | total loss: [1m[32m0.67730[0m[0m | time: 180.900s
[2K
| RMSProp | epoch: 005 | loss: 0.67730 - acc: 0.5676 | val_loss: 0.66385 - val_acc: 0.6280 -- iter: 2235/2235
--
Training Step: 351  | total loss: [1m[32m0.68245[0m[0m | time: 1.434s
[2K
| RMSProp | epoch: 006 | loss: 0.68245 - acc: 0.5577 -- iter: 0032/2235
[A[ATraining Step: 352  | total loss: [1m[32m0.68195[0m[0m | time: 2.916s
[2K
| RMSProp | epoch: 006 | loss: 0.68195 - acc: 0.5551 -- iter: 0064/2235
[A[ATraining Step: 353  | total loss: [1m[32m0.68048[0m[0m | time: 4.357s
[2K
| RMSProp | epoch: 006 | loss: 0.68048 - acc: 0.5589 -- iter: 0096/2235
[A[ATraining Step: 354  | total loss: [1m[32m0.67981[0m[0m | time: 5.407s
[2K
| RMSProp | epoch: 006 | loss: 0.67981 - acc: 0.5624 -- iter: 0128/2235
[A[ATraining Step: 355  | total loss: [1m[32m0.68180[0m[0m | time: 6.478s
[2K
| RMSProp | epoch: 006 | loss: 0.68180 - acc: 0.5543 -- iter: 0160/2235
[A[ATraining Step: 356  | total loss: [1m[32m0.68288[0m[0m | time: 7.889s
[2K
| RMSProp | epoch: 006 | loss: 0.68288 - acc: 0.5470 -- iter: 0192/2235
[A[ATraining Step: 357  | total loss: [1m[32m0.68101[0m[0m | time: 9.364s
[2K
| RMSProp | epoch: 006 | loss: 0.68101 - acc: 0.5548 -- iter: 0224/2235
[A[ATraining Step: 358  | total loss: [1m[32m0.67658[0m[0m | time: 10.659s
[2K
| RMSProp | epoch: 006 | loss: 0.67658 - acc: 0.5681 -- iter: 0256/2235
[A[ATraining Step: 359  | total loss: [1m[32m0.67092[0m[0m | time: 12.257s
[2K
| RMSProp | epoch: 006 | loss: 0.67092 - acc: 0.5769 -- iter: 0288/2235
[A[ATraining Step: 360  | total loss: [1m[32m0.67004[0m[0m | time: 13.614s
[2K
| RMSProp | epoch: 006 | loss: 0.67004 - acc: 0.5786 -- iter: 0320/2235
[A[ATraining Step: 361  | total loss: [1m[32m0.67298[0m[0m | time: 15.037s
[2K
| RMSProp | epoch: 006 | loss: 0.67298 - acc: 0.5707 -- iter: 0352/2235
[A[ATraining Step: 362  | total loss: [1m[32m0.67181[0m[0m | time: 16.602s
[2K
| RMSProp | epoch: 006 | loss: 0.67181 - acc: 0.5668 -- iter: 0384/2235
[A[ATraining Step: 363  | total loss: [1m[32m0.66147[0m[0m | time: 18.047s
[2K
| RMSProp | epoch: 006 | loss: 0.66147 - acc: 0.5882 -- iter: 0416/2235
[A[ATraining Step: 364  | total loss: [1m[32m0.66686[0m[0m | time: 19.473s
[2K
| RMSProp | epoch: 006 | loss: 0.66686 - acc: 0.5794 -- iter: 0448/2235
[A[ATraining Step: 365  | total loss: [1m[32m0.66539[0m[0m | time: 20.890s
[2K
| RMSProp | epoch: 006 | loss: 0.66539 - acc: 0.5808 -- iter: 0480/2235
[A[ATraining Step: 366  | total loss: [1m[32m0.66622[0m[0m | time: 22.422s
[2K
| RMSProp | epoch: 006 | loss: 0.66622 - acc: 0.5790 -- iter: 0512/2235
[A[ATraining Step: 367  | total loss: [1m[32m0.66734[0m[0m | time: 23.887s
[2K
| RMSProp | epoch: 006 | loss: 0.66734 - acc: 0.5711 -- iter: 0544/2235
[A[ATraining Step: 368  | total loss: [1m[32m0.66412[0m[0m | time: 25.245s
[2K
| RMSProp | epoch: 006 | loss: 0.66412 - acc: 0.5859 -- iter: 0576/2235
[A[ATraining Step: 369  | total loss: [1m[32m0.65943[0m[0m | time: 26.579s
[2K
| RMSProp | epoch: 006 | loss: 0.65943 - acc: 0.5867 -- iter: 0608/2235
[A[ATraining Step: 370  | total loss: [1m[32m0.66928[0m[0m | time: 28.168s
[2K
| RMSProp | epoch: 006 | loss: 0.66928 - acc: 0.5749 -- iter: 0640/2235
[A[ATraining Step: 371  | total loss: [1m[32m0.66595[0m[0m | time: 29.640s
[2K
| RMSProp | epoch: 006 | loss: 0.66595 - acc: 0.5768 -- iter: 0672/2235
[A[ATraining Step: 372  | total loss: [1m[32m0.65766[0m[0m | time: 30.861s
[2K
| RMSProp | epoch: 006 | loss: 0.65766 - acc: 0.6003 -- iter: 0704/2235
[A[ATraining Step: 373  | total loss: [1m[32m0.65519[0m[0m | time: 32.290s
[2K
| RMSProp | epoch: 006 | loss: 0.65519 - acc: 0.5903 -- iter: 0736/2235
[A[ATraining Step: 374  | total loss: [1m[32m0.65812[0m[0m | time: 33.964s
[2K
| RMSProp | epoch: 006 | loss: 0.65812 - acc: 0.5844 -- iter: 0768/2235
[A[ATraining Step: 375  | total loss: [1m[32m0.65797[0m[0m | time: 35.619s
[2K
| RMSProp | epoch: 006 | loss: 0.65797 - acc: 0.5947 -- iter: 0800/2235
[A[ATraining Step: 376  | total loss: [1m[32m0.65227[0m[0m | time: 37.027s
[2K
| RMSProp | epoch: 006 | loss: 0.65227 - acc: 0.6009 -- iter: 0832/2235
[A[ATraining Step: 377  | total loss: [1m[32m0.65003[0m[0m | time: 38.602s
[2K
| RMSProp | epoch: 006 | loss: 0.65003 - acc: 0.6064 -- iter: 0864/2235
[A[ATraining Step: 378  | total loss: [1m[32m0.65191[0m[0m | time: 40.134s
[2K
| RMSProp | epoch: 006 | loss: 0.65191 - acc: 0.6114 -- iter: 0896/2235
[A[ATraining Step: 379  | total loss: [1m[32m0.64681[0m[0m | time: 41.980s
[2K
| RMSProp | epoch: 006 | loss: 0.64681 - acc: 0.6252 -- iter: 0928/2235
[A[ATraining Step: 380  | total loss: [1m[32m0.64084[0m[0m | time: 48.232s
[2K
| RMSProp | epoch: 006 | loss: 0.64084 - acc: 0.6346 -- iter: 0960/2235
[A[ATraining Step: 381  | total loss: [1m[32m0.64158[0m[0m | time: 57.154s
[2K
| RMSProp | epoch: 006 | loss: 0.64158 - acc: 0.6305 -- iter: 0992/2235
[A[ATraining Step: 382  | total loss: [1m[32m0.64248[0m[0m | time: 61.085s
[2K
| RMSProp | epoch: 006 | loss: 0.64248 - acc: 0.6300 -- iter: 1024/2235
[A[ATraining Step: 383  | total loss: [1m[32m0.65653[0m[0m | time: 62.678s
[2K
| RMSProp | epoch: 006 | loss: 0.65653 - acc: 0.6045 -- iter: 1056/2235
[A[ATraining Step: 384  | total loss: [1m[32m0.65726[0m[0m | time: 64.237s
[2K
| RMSProp | epoch: 006 | loss: 0.65726 - acc: 0.5971 -- iter: 1088/2235
[A[ATraining Step: 385  | total loss: [1m[32m0.65776[0m[0m | time: 65.402s
[2K
| RMSProp | epoch: 006 | loss: 0.65776 - acc: 0.5999 -- iter: 1120/2235
[A[ATraining Step: 386  | total loss: [1m[32m0.64792[0m[0m | time: 66.711s
[2K
| RMSProp | epoch: 006 | loss: 0.64792 - acc: 0.6212 -- iter: 1152/2235
[A[ATraining Step: 387  | total loss: [1m[32m0.64106[0m[0m | time: 67.962s
[2K
| RMSProp | epoch: 006 | loss: 0.64106 - acc: 0.6278 -- iter: 1184/2235
[A[ATraining Step: 388  | total loss: [1m[32m0.64341[0m[0m | time: 69.565s
[2K
| RMSProp | epoch: 006 | loss: 0.64341 - acc: 0.6213 -- iter: 1216/2235
[A[ATraining Step: 389  | total loss: [1m[32m0.63840[0m[0m | time: 71.102s
[2K
| RMSProp | epoch: 006 | loss: 0.63840 - acc: 0.6310 -- iter: 1248/2235
[A[ATraining Step: 390  | total loss: [1m[32m0.63370[0m[0m | time: 72.613s
[2K
| RMSProp | epoch: 006 | loss: 0.63370 - acc: 0.6429 -- iter: 1280/2235
[A[ATraining Step: 391  | total loss: [1m[32m0.62073[0m[0m | time: 74.132s
[2K
| RMSProp | epoch: 006 | loss: 0.62073 - acc: 0.6568 -- iter: 1312/2235
[A[ATraining Step: 392  | total loss: [1m[32m0.64675[0m[0m | time: 75.581s
[2K
| RMSProp | epoch: 006 | loss: 0.64675 - acc: 0.6380 -- iter: 1344/2235
[A[ATraining Step: 393  | total loss: [1m[32m0.64513[0m[0m | time: 77.147s
[2K
| RMSProp | epoch: 006 | loss: 0.64513 - acc: 0.6429 -- iter: 1376/2235
[A[ATraining Step: 394  | total loss: [1m[32m0.65061[0m[0m | time: 78.367s
[2K
| RMSProp | epoch: 006 | loss: 0.65061 - acc: 0.6317 -- iter: 1408/2235
[A[ATraining Step: 395  | total loss: [1m[32m0.64465[0m[0m | time: 79.730s
[2K
| RMSProp | epoch: 006 | loss: 0.64465 - acc: 0.6373 -- iter: 1440/2235
[A[ATraining Step: 396  | total loss: [1m[32m0.64176[0m[0m | time: 81.303s
[2K
| RMSProp | epoch: 006 | loss: 0.64176 - acc: 0.6392 -- iter: 1472/2235
[A[ATraining Step: 397  | total loss: [1m[32m0.63639[0m[0m | time: 82.842s
[2K
| RMSProp | epoch: 006 | loss: 0.63639 - acc: 0.6472 -- iter: 1504/2235
[A[ATraining Step: 398  | total loss: [1m[32m0.63601[0m[0m | time: 85.757s
[2K
| RMSProp | epoch: 006 | loss: 0.63601 - acc: 0.6418 -- iter: 1536/2235
[A[ATraining Step: 399  | total loss: [1m[32m0.63813[0m[0m | time: 91.182s
[2K
| RMSProp | epoch: 006 | loss: 0.63813 - acc: 0.6401 -- iter: 1568/2235
[A[ATraining Step: 400  | total loss: [1m[32m0.63747[0m[0m | time: 98.915s
[2K
| RMSProp | epoch: 006 | loss: 0.63747 - acc: 0.6418 | val_loss: 0.61568 - val_acc: 0.6624 -- iter: 1600/2235
--
Training Step: 401  | total loss: [1m[32m0.63029[0m[0m | time: 102.122s
[2K
| RMSProp | epoch: 006 | loss: 0.63029 - acc: 0.6526 -- iter: 1632/2235
[A[ATraining Step: 402  | total loss: [1m[32m0.63735[0m[0m | time: 110.093s
[2K
| RMSProp | epoch: 006 | loss: 0.63735 - acc: 0.6404 -- iter: 1664/2235
[A[ATraining Step: 403  | total loss: [1m[32m0.63835[0m[0m | time: 112.553s
[2K
| RMSProp | epoch: 006 | loss: 0.63835 - acc: 0.6389 -- iter: 1696/2235
[A[ATraining Step: 404  | total loss: [1m[32m0.63510[0m[0m | time: 116.004s
[2K
| RMSProp | epoch: 006 | loss: 0.63510 - acc: 0.6469 -- iter: 1728/2235
[A[ATraining Step: 405  | total loss: [1m[32m0.62666[0m[0m | time: 124.572s
[2K
| RMSProp | epoch: 006 | loss: 0.62666 - acc: 0.6634 -- iter: 1760/2235
[A[ATraining Step: 406  | total loss: [1m[32m0.62474[0m[0m | time: 132.106s
[2K
| RMSProp | epoch: 006 | loss: 0.62474 - acc: 0.6659 -- iter: 1792/2235
[A[ATraining Step: 407  | total loss: [1m[32m0.62192[0m[0m | time: 133.504s
[2K
| RMSProp | epoch: 006 | loss: 0.62192 - acc: 0.6743 -- iter: 1824/2235
[A[ATraining Step: 408  | total loss: [1m[32m0.61724[0m[0m | time: 134.861s
[2K
| RMSProp | epoch: 006 | loss: 0.61724 - acc: 0.6818 -- iter: 1856/2235
[A[ATraining Step: 409  | total loss: [1m[32m0.60826[0m[0m | time: 143.397s
[2K
| RMSProp | epoch: 006 | loss: 0.60826 - acc: 0.6887 -- iter: 1888/2235
[A[ATraining Step: 410  | total loss: [1m[32m0.60536[0m[0m | time: 144.735s
[2K
| RMSProp | epoch: 006 | loss: 0.60536 - acc: 0.6885 -- iter: 1920/2235
[A[ATraining Step: 411  | total loss: [1m[32m0.60317[0m[0m | time: 146.108s
[2K
| RMSProp | epoch: 006 | loss: 0.60317 - acc: 0.6916 -- iter: 1952/2235
[A[ATraining Step: 412  | total loss: [1m[32m0.60245[0m[0m | time: 147.616s
[2K
| RMSProp | epoch: 006 | loss: 0.60245 - acc: 0.6912 -- iter: 1984/2235
[A[ATraining Step: 413  | total loss: [1m[32m0.61577[0m[0m | time: 149.068s
[2K
| RMSProp | epoch: 006 | loss: 0.61577 - acc: 0.6814 -- iter: 2016/2235
[A[ATraining Step: 414  | total loss: [1m[32m0.62328[0m[0m | time: 150.490s
[2K
| RMSProp | epoch: 006 | loss: 0.62328 - acc: 0.6664 -- iter: 2048/2235
[A[ATraining Step: 415  | total loss: [1m[32m0.62550[0m[0m | time: 151.897s
[2K
| RMSProp | epoch: 006 | loss: 0.62550 - acc: 0.6685 -- iter: 2080/2235
[A[ATraining Step: 416  | total loss: [1m[32m0.63204[0m[0m | time: 153.339s
[2K
| RMSProp | epoch: 006 | loss: 0.63204 - acc: 0.6548 -- iter: 2112/2235
[A[ATraining Step: 417  | total loss: [1m[32m0.62892[0m[0m | time: 154.918s
[2K
| RMSProp | epoch: 006 | loss: 0.62892 - acc: 0.6674 -- iter: 2144/2235
[A[ATraining Step: 418  | total loss: [1m[32m0.61116[0m[0m | time: 156.289s
[2K
| RMSProp | epoch: 006 | loss: 0.61116 - acc: 0.6851 -- iter: 2176/2235
[A[ATraining Step: 419  | total loss: [1m[32m0.61910[0m[0m | time: 157.548s
[2K
| RMSProp | epoch: 006 | loss: 0.61910 - acc: 0.6791 -- iter: 2208/2235
[A[ATraining Step: 420  | total loss: [1m[32m0.61335[0m[0m | time: 166.495s
[2K
| RMSProp | epoch: 006 | loss: 0.61335 - acc: 0.6893 | val_loss: 0.68997 - val_acc: 0.5508 -- iter: 2235/2235
--
Training Step: 421  | total loss: [1m[32m0.62289[0m[0m | time: 1.493s
[2K
| RMSProp | epoch: 007 | loss: 0.62289 - acc: 0.6797 -- iter: 0032/2235
[A[ATraining Step: 422  | total loss: [1m[32m0.63397[0m[0m | time: 2.853s
[2K
| RMSProp | epoch: 007 | loss: 0.63397 - acc: 0.6586 -- iter: 0064/2235
[A[ATraining Step: 423  | total loss: [1m[32m0.64089[0m[0m | time: 4.223s
[2K
| RMSProp | epoch: 007 | loss: 0.64089 - acc: 0.6459 -- iter: 0096/2235
[A[ATraining Step: 424  | total loss: [1m[32m0.63877[0m[0m | time: 5.790s
[2K
| RMSProp | epoch: 007 | loss: 0.63877 - acc: 0.6469 -- iter: 0128/2235
[A[ATraining Step: 425  | total loss: [1m[32m0.63806[0m[0m | time: 7.756s
[2K
| RMSProp | epoch: 007 | loss: 0.63806 - acc: 0.6510 -- iter: 0160/2235
[A[ATraining Step: 426  | total loss: [1m[32m0.62747[0m[0m | time: 9.075s
[2K
| RMSProp | epoch: 007 | loss: 0.62747 - acc: 0.6637 -- iter: 0192/2235
[A[ATraining Step: 427  | total loss: [1m[32m0.61465[0m[0m | time: 10.179s
[2K
| RMSProp | epoch: 007 | loss: 0.61465 - acc: 0.6751 -- iter: 0224/2235
[A[ATraining Step: 428  | total loss: [1m[32m0.60937[0m[0m | time: 11.609s
[2K
| RMSProp | epoch: 007 | loss: 0.60937 - acc: 0.6826 -- iter: 0256/2235
[A[ATraining Step: 429  | total loss: [1m[32m0.60396[0m[0m | time: 13.026s
[2K
| RMSProp | epoch: 007 | loss: 0.60396 - acc: 0.6924 -- iter: 0288/2235
[A[ATraining Step: 430  | total loss: [1m[32m0.60466[0m[0m | time: 14.376s
[2K
| RMSProp | epoch: 007 | loss: 0.60466 - acc: 0.6857 -- iter: 0320/2235
[A[ATraining Step: 431  | total loss: [1m[32m0.62545[0m[0m | time: 15.836s
[2K
| RMSProp | epoch: 007 | loss: 0.62545 - acc: 0.6734 -- iter: 0352/2235
[A[ATraining Step: 432  | total loss: [1m[32m0.62537[0m[0m | time: 17.205s
[2K
| RMSProp | epoch: 007 | loss: 0.62537 - acc: 0.6717 -- iter: 0384/2235
[A[ATraining Step: 433  | total loss: [1m[32m0.62645[0m[0m | time: 18.480s
[2K
| RMSProp | epoch: 007 | loss: 0.62645 - acc: 0.6670 -- iter: 0416/2235
[A[ATraining Step: 434  | total loss: [1m[32m0.62075[0m[0m | time: 19.953s
[2K
| RMSProp | epoch: 007 | loss: 0.62075 - acc: 0.6690 -- iter: 0448/2235
[A[ATraining Step: 435  | total loss: [1m[32m0.61662[0m[0m | time: 21.367s
[2K
| RMSProp | epoch: 007 | loss: 0.61662 - acc: 0.6740 -- iter: 0480/2235
[A[ATraining Step: 436  | total loss: [1m[32m0.62774[0m[0m | time: 22.651s
[2K
| RMSProp | epoch: 007 | loss: 0.62774 - acc: 0.6597 -- iter: 0512/2235
[A[ATraining Step: 437  | total loss: [1m[32m0.62571[0m[0m | time: 24.185s
[2K
| RMSProp | epoch: 007 | loss: 0.62571 - acc: 0.6594 -- iter: 0544/2235
[A[ATraining Step: 438  | total loss: [1m[32m0.62312[0m[0m | time: 25.755s
[2K
| RMSProp | epoch: 007 | loss: 0.62312 - acc: 0.6653 -- iter: 0576/2235
[A[ATraining Step: 439  | total loss: [1m[32m0.61836[0m[0m | time: 28.251s
[2K
| RMSProp | epoch: 007 | loss: 0.61836 - acc: 0.6800 -- iter: 0608/2235
[A[ATraining Step: 440  | total loss: [1m[32m0.62130[0m[0m | time: 31.279s
[2K
| RMSProp | epoch: 007 | loss: 0.62130 - acc: 0.6745 -- iter: 0640/2235
[A[ATraining Step: 441  | total loss: [1m[32m0.62362[0m[0m | time: 32.450s
[2K
| RMSProp | epoch: 007 | loss: 0.62362 - acc: 0.6727 -- iter: 0672/2235
[A[ATraining Step: 442  | total loss: [1m[32m0.63073[0m[0m | time: 33.899s
[2K
| RMSProp | epoch: 007 | loss: 0.63073 - acc: 0.6711 -- iter: 0704/2235
[A[ATraining Step: 443  | total loss: [1m[32m0.62859[0m[0m | time: 35.377s
[2K
| RMSProp | epoch: 007 | loss: 0.62859 - acc: 0.6758 -- iter: 0736/2235
[A[ATraining Step: 444  | total loss: [1m[32m0.62649[0m[0m | time: 36.906s
[2K
| RMSProp | epoch: 007 | loss: 0.62649 - acc: 0.6707 -- iter: 0768/2235
[A[ATraining Step: 445  | total loss: [1m[32m0.62522[0m[0m | time: 38.195s
[2K
| RMSProp | epoch: 007 | loss: 0.62522 - acc: 0.6755 -- iter: 0800/2235
[A[ATraining Step: 446  | total loss: [1m[32m0.61574[0m[0m | time: 39.624s
[2K
| RMSProp | epoch: 007 | loss: 0.61574 - acc: 0.6830 -- iter: 0832/2235
[A[ATraining Step: 447  | total loss: [1m[32m0.61223[0m[0m | time: 41.185s
[2K
| RMSProp | epoch: 007 | loss: 0.61223 - acc: 0.6834 -- iter: 0864/2235
[A[ATraining Step: 448  | total loss: [1m[32m0.62159[0m[0m | time: 42.926s
[2K
| RMSProp | epoch: 007 | loss: 0.62159 - acc: 0.6682 -- iter: 0896/2235
[A[ATraining Step: 449  | total loss: [1m[32m0.62096[0m[0m | time: 44.267s
[2K
| RMSProp | epoch: 007 | loss: 0.62096 - acc: 0.6702 -- iter: 0928/2235
[A[ATraining Step: 450  | total loss: [1m[32m0.62283[0m[0m | time: 45.881s
[2K
| RMSProp | epoch: 007 | loss: 0.62283 - acc: 0.6625 -- iter: 0960/2235
[A[ATraining Step: 451  | total loss: [1m[32m0.62443[0m[0m | time: 47.419s
[2K
| RMSProp | epoch: 007 | loss: 0.62443 - acc: 0.6619 -- iter: 0992/2235
[A[ATraining Step: 452  | total loss: [1m[32m0.61615[0m[0m | time: 48.891s
[2K
| RMSProp | epoch: 007 | loss: 0.61615 - acc: 0.6769 -- iter: 1024/2235
[A[ATraining Step: 453  | total loss: [1m[32m0.62140[0m[0m | time: 50.180s
[2K
| RMSProp | epoch: 007 | loss: 0.62140 - acc: 0.6686 -- iter: 1056/2235
[A[ATraining Step: 454  | total loss: [1m[32m0.62279[0m[0m | time: 51.430s
[2K
| RMSProp | epoch: 007 | loss: 0.62279 - acc: 0.6643 -- iter: 1088/2235
[A[ATraining Step: 455  | total loss: [1m[32m0.62125[0m[0m | time: 52.911s
[2K
| RMSProp | epoch: 007 | loss: 0.62125 - acc: 0.6603 -- iter: 1120/2235
[A[ATraining Step: 456  | total loss: [1m[32m0.62668[0m[0m | time: 54.308s
[2K
| RMSProp | epoch: 007 | loss: 0.62668 - acc: 0.6537 -- iter: 1152/2235
[A[ATraining Step: 457  | total loss: [1m[32m0.62360[0m[0m | time: 55.725s
[2K
| RMSProp | epoch: 007 | loss: 0.62360 - acc: 0.6539 -- iter: 1184/2235
[A[ATraining Step: 458  | total loss: [1m[32m0.62148[0m[0m | time: 57.005s
[2K
| RMSProp | epoch: 007 | loss: 0.62148 - acc: 0.6573 -- iter: 1216/2235
[A[ATraining Step: 459  | total loss: [1m[32m0.61356[0m[0m | time: 58.557s
[2K
| RMSProp | epoch: 007 | loss: 0.61356 - acc: 0.6634 -- iter: 1248/2235
[A[ATraining Step: 460  | total loss: [1m[32m0.60558[0m[0m | time: 59.961s
[2K
| RMSProp | epoch: 007 | loss: 0.60558 - acc: 0.6690 -- iter: 1280/2235
[A[ATraining Step: 461  | total loss: [1m[32m0.59814[0m[0m | time: 61.352s
[2K
| RMSProp | epoch: 007 | loss: 0.59814 - acc: 0.6739 -- iter: 1312/2235
[A[ATraining Step: 462  | total loss: [1m[32m0.59294[0m[0m | time: 62.745s
[2K
| RMSProp | epoch: 007 | loss: 0.59294 - acc: 0.6784 -- iter: 1344/2235
[A[ATraining Step: 463  | total loss: [1m[32m0.58153[0m[0m | time: 64.238s
[2K
| RMSProp | epoch: 007 | loss: 0.58153 - acc: 0.6918 -- iter: 1376/2235
[A[ATraining Step: 464  | total loss: [1m[32m0.58982[0m[0m | time: 65.706s
[2K
| RMSProp | epoch: 007 | loss: 0.58982 - acc: 0.6820 -- iter: 1408/2235
[A[ATraining Step: 465  | total loss: [1m[32m0.60719[0m[0m | time: 73.158s
[2K
| RMSProp | epoch: 007 | loss: 0.60719 - acc: 0.6607 -- iter: 1440/2235
[A[ATraining Step: 466  | total loss: [1m[32m0.60250[0m[0m | time: 74.421s
[2K
| RMSProp | epoch: 007 | loss: 0.60250 - acc: 0.6634 -- iter: 1472/2235
[A[ATraining Step: 467  | total loss: [1m[32m0.60308[0m[0m | time: 75.971s
[2K
| RMSProp | epoch: 007 | loss: 0.60308 - acc: 0.6658 -- iter: 1504/2235
[A[ATraining Step: 468  | total loss: [1m[32m0.60402[0m[0m | time: 77.260s
[2K
| RMSProp | epoch: 007 | loss: 0.60402 - acc: 0.6648 -- iter: 1536/2235
[A[ATraining Step: 469  | total loss: [1m[32m0.61936[0m[0m | time: 78.777s
[2K
| RMSProp | epoch: 007 | loss: 0.61936 - acc: 0.6515 -- iter: 1568/2235
[A[ATraining Step: 470  | total loss: [1m[32m0.61319[0m[0m | time: 79.963s
[2K
| RMSProp | epoch: 007 | loss: 0.61319 - acc: 0.6613 -- iter: 1600/2235
[A[ATraining Step: 471  | total loss: [1m[32m0.61017[0m[0m | time: 81.278s
[2K
| RMSProp | epoch: 007 | loss: 0.61017 - acc: 0.6671 -- iter: 1632/2235
[A[ATraining Step: 472  | total loss: [1m[32m0.61730[0m[0m | time: 82.846s
[2K
| RMSProp | epoch: 007 | loss: 0.61730 - acc: 0.6629 -- iter: 1664/2235
[A[ATraining Step: 473  | total loss: [1m[32m0.60874[0m[0m | time: 84.212s
[2K
| RMSProp | epoch: 007 | loss: 0.60874 - acc: 0.6747 -- iter: 1696/2235
[A[ATraining Step: 474  | total loss: [1m[32m0.61373[0m[0m | time: 85.610s
[2K
| RMSProp | epoch: 007 | loss: 0.61373 - acc: 0.6729 -- iter: 1728/2235
[A[ATraining Step: 475  | total loss: [1m[32m0.61246[0m[0m | time: 87.127s
[2K
| RMSProp | epoch: 007 | loss: 0.61246 - acc: 0.6806 -- iter: 1760/2235
[A[ATraining Step: 476  | total loss: [1m[32m0.61094[0m[0m | time: 88.636s
[2K
| RMSProp | epoch: 007 | loss: 0.61094 - acc: 0.6844 -- iter: 1792/2235
[A[ATraining Step: 477  | total loss: [1m[32m0.61065[0m[0m | time: 90.130s
[2K
| RMSProp | epoch: 007 | loss: 0.61065 - acc: 0.6910 -- iter: 1824/2235
[A[ATraining Step: 478  | total loss: [1m[32m0.60163[0m[0m | time: 91.376s
[2K
| RMSProp | epoch: 007 | loss: 0.60163 - acc: 0.6969 -- iter: 1856/2235
[A[ATraining Step: 479  | total loss: [1m[32m0.58645[0m[0m | time: 92.632s
[2K
| RMSProp | epoch: 007 | loss: 0.58645 - acc: 0.7084 -- iter: 1888/2235
[A[ATraining Step: 480  | total loss: [1m[32m0.57599[0m[0m | time: 94.112s
[2K
| RMSProp | epoch: 007 | loss: 0.57599 - acc: 0.7157 -- iter: 1920/2235
[A[ATraining Step: 481  | total loss: [1m[32m0.58082[0m[0m | time: 95.584s
[2K
| RMSProp | epoch: 007 | loss: 0.58082 - acc: 0.7191 -- iter: 1952/2235
[A[ATraining Step: 482  | total loss: [1m[32m0.57929[0m[0m | time: 97.149s
[2K
| RMSProp | epoch: 007 | loss: 0.57929 - acc: 0.7222 -- iter: 1984/2235
[A[ATraining Step: 483  | total loss: [1m[32m0.57745[0m[0m | time: 98.458s
[2K
| RMSProp | epoch: 007 | loss: 0.57745 - acc: 0.7156 -- iter: 2016/2235
[A[ATraining Step: 484  | total loss: [1m[32m0.58482[0m[0m | time: 99.821s
[2K
| RMSProp | epoch: 007 | loss: 0.58482 - acc: 0.7066 -- iter: 2048/2235
[A[ATraining Step: 485  | total loss: [1m[32m0.57911[0m[0m | time: 101.308s
[2K
| RMSProp | epoch: 007 | loss: 0.57911 - acc: 0.7078 -- iter: 2080/2235
[A[ATraining Step: 486  | total loss: [1m[32m0.56682[0m[0m | time: 102.784s
[2K
| RMSProp | epoch: 007 | loss: 0.56682 - acc: 0.7151 -- iter: 2112/2235
[A[ATraining Step: 487  | total loss: [1m[32m0.58640[0m[0m | time: 104.219s
[2K
| RMSProp | epoch: 007 | loss: 0.58640 - acc: 0.7061 -- iter: 2144/2235
[A[ATraining Step: 488  | total loss: [1m[32m0.58933[0m[0m | time: 105.885s
[2K
| RMSProp | epoch: 007 | loss: 0.58933 - acc: 0.7011 -- iter: 2176/2235
[A[ATraining Step: 489  | total loss: [1m[32m0.59556[0m[0m | time: 107.472s
[2K
| RMSProp | epoch: 007 | loss: 0.59556 - acc: 0.6904 -- iter: 2208/2235
[A[ATraining Step: 490  | total loss: [1m[32m0.59228[0m[0m | time: 116.250s
[2K
| RMSProp | epoch: 007 | loss: 0.59228 - acc: 0.6964 | val_loss: 0.58706 - val_acc: 0.6924 -- iter: 2235/2235
--
Training Step: 491  | total loss: [1m[32m0.60135[0m[0m | time: 1.366s
[2K
| RMSProp | epoch: 008 | loss: 0.60135 - acc: 0.6798 -- iter: 0032/2235
[A[ATraining Step: 492  | total loss: [1m[32m0.60003[0m[0m | time: 2.947s
[2K
| RMSProp | epoch: 008 | loss: 0.60003 - acc: 0.6806 -- iter: 0064/2235
[A[ATraining Step: 493  | total loss: [1m[32m0.59714[0m[0m | time: 4.459s
[2K
| RMSProp | epoch: 008 | loss: 0.59714 - acc: 0.6875 -- iter: 0096/2235
[A[ATraining Step: 494  | total loss: [1m[32m0.58410[0m[0m | time: 6.024s
[2K
| RMSProp | epoch: 008 | loss: 0.58410 - acc: 0.7000 -- iter: 0128/2235
[A[ATraining Step: 495  | total loss: [1m[32m0.57972[0m[0m | time: 7.494s
[2K
| RMSProp | epoch: 008 | loss: 0.57972 - acc: 0.6988 -- iter: 0160/2235
[A[ATraining Step: 496  | total loss: [1m[32m0.56835[0m[0m | time: 8.702s
[2K
| RMSProp | epoch: 008 | loss: 0.56835 - acc: 0.7164 -- iter: 0192/2235
[A[ATraining Step: 497  | total loss: [1m[32m0.55915[0m[0m | time: 9.744s
[2K
| RMSProp | epoch: 008 | loss: 0.55915 - acc: 0.7225 -- iter: 0224/2235
[A[ATraining Step: 498  | total loss: [1m[32m0.54772[0m[0m | time: 11.057s
[2K
| RMSProp | epoch: 008 | loss: 0.54772 - acc: 0.7392 -- iter: 0256/2235
[A[ATraining Step: 499  | total loss: [1m[32m0.59312[0m[0m | time: 12.475s
[2K
| RMSProp | epoch: 008 | loss: 0.59312 - acc: 0.7121 -- iter: 0288/2235
[A[ATraining Step: 500  | total loss: [1m[32m0.60610[0m[0m | time: 13.866s
[2K
| RMSProp | epoch: 008 | loss: 0.60610 - acc: 0.6972 -- iter: 0320/2235
[A[ATraining Step: 501  | total loss: [1m[32m0.60083[0m[0m | time: 15.182s
[2K
| RMSProp | epoch: 008 | loss: 0.60083 - acc: 0.6993 -- iter: 0352/2235
[A[ATraining Step: 502  | total loss: [1m[32m0.59926[0m[0m | time: 16.463s
[2K
| RMSProp | epoch: 008 | loss: 0.59926 - acc: 0.6950 -- iter: 0384/2235
[A[ATraining Step: 503  | total loss: [1m[32m0.59941[0m[0m | time: 18.003s
[2K
| RMSProp | epoch: 008 | loss: 0.59941 - acc: 0.6943 -- iter: 0416/2235
[A[ATraining Step: 504  | total loss: [1m[32m0.61059[0m[0m | time: 19.488s
[2K
| RMSProp | epoch: 008 | loss: 0.61059 - acc: 0.6936 -- iter: 0448/2235
[A[ATraining Step: 505  | total loss: [1m[32m0.60704[0m[0m | time: 20.663s
[2K
| RMSProp | epoch: 008 | loss: 0.60704 - acc: 0.6930 -- iter: 0480/2235
[A[ATraining Step: 506  | total loss: [1m[32m0.60314[0m[0m | time: 21.924s
[2K
| RMSProp | epoch: 008 | loss: 0.60314 - acc: 0.6924 -- iter: 0512/2235
[A[ATraining Step: 507  | total loss: [1m[32m0.60928[0m[0m | time: 23.389s
[2K
| RMSProp | epoch: 008 | loss: 0.60928 - acc: 0.6919 -- iter: 0544/2235
[A[ATraining Step: 508  | total loss: [1m[32m0.60109[0m[0m | time: 24.760s
[2K
| RMSProp | epoch: 008 | loss: 0.60109 - acc: 0.6977 -- iter: 0576/2235
[A[ATraining Step: 509  | total loss: [1m[32m0.58518[0m[0m | time: 26.321s
[2K
| RMSProp | epoch: 008 | loss: 0.58518 - acc: 0.7155 -- iter: 0608/2235
[A[ATraining Step: 510  | total loss: [1m[32m0.58430[0m[0m | time: 27.619s
[2K
| RMSProp | epoch: 008 | loss: 0.58430 - acc: 0.7064 -- iter: 0640/2235
[A[ATraining Step: 511  | total loss: [1m[32m0.58260[0m[0m | time: 29.029s
[2K
| RMSProp | epoch: 008 | loss: 0.58260 - acc: 0.7077 -- iter: 0672/2235
[A[ATraining Step: 512  | total loss: [1m[32m0.57034[0m[0m | time: 30.613s
[2K
| RMSProp | epoch: 008 | loss: 0.57034 - acc: 0.7181 -- iter: 0704/2235
[A[ATraining Step: 513  | total loss: [1m[32m0.56690[0m[0m | time: 32.331s
[2K
| RMSProp | epoch: 008 | loss: 0.56690 - acc: 0.7151 -- iter: 0736/2235
[A[ATraining Step: 514  | total loss: [1m[32m0.55688[0m[0m | time: 38.644s
[2K
| RMSProp | epoch: 008 | loss: 0.55688 - acc: 0.7248 -- iter: 0768/2235
[A[ATraining Step: 515  | total loss: [1m[32m0.54304[0m[0m | time: 42.032s
[2K
| RMSProp | epoch: 008 | loss: 0.54304 - acc: 0.7398 -- iter: 0800/2235
[A[ATraining Step: 516  | total loss: [1m[32m0.56579[0m[0m | time: 43.618s
[2K
| RMSProp | epoch: 008 | loss: 0.56579 - acc: 0.7096 -- iter: 0832/2235
[A[ATraining Step: 517  | total loss: [1m[32m0.58217[0m[0m | time: 45.062s
[2K
| RMSProp | epoch: 008 | loss: 0.58217 - acc: 0.6980 -- iter: 0864/2235
[A[ATraining Step: 518  | total loss: [1m[32m0.57866[0m[0m | time: 46.347s
[2K
| RMSProp | epoch: 008 | loss: 0.57866 - acc: 0.7001 -- iter: 0896/2235
[A[ATraining Step: 519  | total loss: [1m[32m0.57717[0m[0m | time: 47.872s
[2K
| RMSProp | epoch: 008 | loss: 0.57717 - acc: 0.7051 -- iter: 0928/2235
[A[ATraining Step: 520  | total loss: [1m[32m0.58053[0m[0m | time: 49.409s
[2K
| RMSProp | epoch: 008 | loss: 0.58053 - acc: 0.7002 -- iter: 0960/2235
[A[ATraining Step: 521  | total loss: [1m[32m0.58577[0m[0m | time: 50.997s
[2K
| RMSProp | epoch: 008 | loss: 0.58577 - acc: 0.6958 -- iter: 0992/2235
[A[ATraining Step: 522  | total loss: [1m[32m0.57980[0m[0m | time: 52.450s
[2K
| RMSProp | epoch: 008 | loss: 0.57980 - acc: 0.7012 -- iter: 1024/2235
[A[ATraining Step: 523  | total loss: [1m[32m0.57853[0m[0m | time: 53.815s
[2K
| RMSProp | epoch: 008 | loss: 0.57853 - acc: 0.7030 -- iter: 1056/2235
[A[ATraining Step: 524  | total loss: [1m[32m0.57353[0m[0m | time: 55.245s
[2K
| RMSProp | epoch: 008 | loss: 0.57353 - acc: 0.6983 -- iter: 1088/2235
[A[ATraining Step: 525  | total loss: [1m[32m0.56091[0m[0m | time: 56.724s
[2K
| RMSProp | epoch: 008 | loss: 0.56091 - acc: 0.7097 -- iter: 1120/2235
[A[ATraining Step: 526  | total loss: [1m[32m0.56165[0m[0m | time: 58.489s
[2K
| RMSProp | epoch: 008 | loss: 0.56165 - acc: 0.7106 -- iter: 1152/2235
[A[ATraining Step: 527  | total loss: [1m[32m0.56877[0m[0m | time: 60.002s
[2K
| RMSProp | epoch: 008 | loss: 0.56877 - acc: 0.7114 -- iter: 1184/2235
[A[ATraining Step: 528  | total loss: [1m[32m0.56712[0m[0m | time: 61.576s
[2K
| RMSProp | epoch: 008 | loss: 0.56712 - acc: 0.7090 -- iter: 1216/2235
[A[ATraining Step: 529  | total loss: [1m[32m0.57319[0m[0m | time: 63.093s
[2K
| RMSProp | epoch: 008 | loss: 0.57319 - acc: 0.7100 -- iter: 1248/2235
[A[ATraining Step: 530  | total loss: [1m[32m0.57565[0m[0m | time: 64.545s
[2K
| RMSProp | epoch: 008 | loss: 0.57565 - acc: 0.6984 -- iter: 1280/2235
[A[ATraining Step: 531  | total loss: [1m[32m0.56425[0m[0m | time: 65.850s
[2K
| RMSProp | epoch: 008 | loss: 0.56425 - acc: 0.7160 -- iter: 1312/2235
[A[ATraining Step: 532  | total loss: [1m[32m0.57218[0m[0m | time: 67.240s
[2K
| RMSProp | epoch: 008 | loss: 0.57218 - acc: 0.7163 -- iter: 1344/2235
[A[ATraining Step: 533  | total loss: [1m[32m0.56978[0m[0m | time: 68.738s
[2K
| RMSProp | epoch: 008 | loss: 0.56978 - acc: 0.7197 -- iter: 1376/2235
[A[ATraining Step: 534  | total loss: [1m[32m0.56509[0m[0m | time: 70.202s
[2K
| RMSProp | epoch: 008 | loss: 0.56509 - acc: 0.7196 -- iter: 1408/2235
[A[ATraining Step: 535  | total loss: [1m[32m0.55890[0m[0m | time: 71.699s
[2K
| RMSProp | epoch: 008 | loss: 0.55890 - acc: 0.7289 -- iter: 1440/2235
[A[ATraining Step: 536  | total loss: [1m[32m0.55582[0m[0m | time: 72.979s
[2K
| RMSProp | epoch: 008 | loss: 0.55582 - acc: 0.7372 -- iter: 1472/2235
[A[ATraining Step: 537  | total loss: [1m[32m0.55970[0m[0m | time: 74.143s
[2K
| RMSProp | epoch: 008 | loss: 0.55970 - acc: 0.7260 -- iter: 1504/2235
[A[ATraining Step: 538  | total loss: [1m[32m0.55155[0m[0m | time: 75.258s
[2K
| RMSProp | epoch: 008 | loss: 0.55155 - acc: 0.7315 -- iter: 1536/2235
[A[ATraining Step: 539  | total loss: [1m[32m0.54482[0m[0m | time: 76.374s
[2K
| RMSProp | epoch: 008 | loss: 0.54482 - acc: 0.7365 -- iter: 1568/2235
[A[ATraining Step: 540  | total loss: [1m[32m0.54170[0m[0m | time: 77.480s
[2K
| RMSProp | epoch: 008 | loss: 0.54170 - acc: 0.7441 -- iter: 1600/2235
[A[ATraining Step: 541  | total loss: [1m[32m0.60239[0m[0m | time: 78.682s
[2K
| RMSProp | epoch: 008 | loss: 0.60239 - acc: 0.7041 -- iter: 1632/2235
[A[ATraining Step: 542  | total loss: [1m[32m0.59483[0m[0m | time: 79.847s
[2K
| RMSProp | epoch: 008 | loss: 0.59483 - acc: 0.7118 -- iter: 1664/2235
[A[ATraining Step: 543  | total loss: [1m[32m0.58584[0m[0m | time: 80.774s
[2K
| RMSProp | epoch: 008 | loss: 0.58584 - acc: 0.7156 -- iter: 1696/2235
[A[ATraining Step: 544  | total loss: [1m[32m0.59043[0m[0m | time: 81.816s
[2K
| RMSProp | epoch: 008 | loss: 0.59043 - acc: 0.7159 -- iter: 1728/2235
[A[ATraining Step: 545  | total loss: [1m[32m0.57568[0m[0m | time: 82.954s
[2K
| RMSProp | epoch: 008 | loss: 0.57568 - acc: 0.7287 -- iter: 1760/2235
[A[ATraining Step: 546  | total loss: [1m[32m0.56813[0m[0m | time: 83.998s
[2K
| RMSProp | epoch: 008 | loss: 0.56813 - acc: 0.7277 -- iter: 1792/2235
[A[ATraining Step: 547  | total loss: [1m[32m0.55566[0m[0m | time: 85.065s
[2K
| RMSProp | epoch: 008 | loss: 0.55566 - acc: 0.7362 -- iter: 1824/2235
[A[ATraining Step: 548  | total loss: [1m[32m0.56152[0m[0m | time: 86.113s
[2K
| RMSProp | epoch: 008 | loss: 0.56152 - acc: 0.7219 -- iter: 1856/2235
[A[ATraining Step: 549  | total loss: [1m[32m0.55791[0m[0m | time: 87.313s
[2K
| RMSProp | epoch: 008 | loss: 0.55791 - acc: 0.7185 -- iter: 1888/2235
[A[ATraining Step: 550  | total loss: [1m[32m0.54837[0m[0m | time: 88.515s
[2K
| RMSProp | epoch: 008 | loss: 0.54837 - acc: 0.7217 -- iter: 1920/2235
[A[ATraining Step: 551  | total loss: [1m[32m0.53267[0m[0m | time: 89.600s
[2K
| RMSProp | epoch: 008 | loss: 0.53267 - acc: 0.7339 -- iter: 1952/2235
[A[ATraining Step: 552  | total loss: [1m[32m0.52057[0m[0m | time: 90.830s
[2K
| RMSProp | epoch: 008 | loss: 0.52057 - acc: 0.7386 -- iter: 1984/2235
[A[ATraining Step: 553  | total loss: [1m[32m0.50051[0m[0m | time: 92.170s
[2K
| RMSProp | epoch: 008 | loss: 0.50051 - acc: 0.7554 -- iter: 2016/2235
[A[ATraining Step: 554  | total loss: [1m[32m0.51358[0m[0m | time: 93.273s
[2K
| RMSProp | epoch: 008 | loss: 0.51358 - acc: 0.7517 -- iter: 2048/2235
[A[ATraining Step: 555  | total loss: [1m[32m0.51217[0m[0m | time: 94.270s
[2K
| RMSProp | epoch: 008 | loss: 0.51217 - acc: 0.7547 -- iter: 2080/2235
[A[ATraining Step: 556  | total loss: [1m[32m0.53473[0m[0m | time: 95.451s
[2K
| RMSProp | epoch: 008 | loss: 0.53473 - acc: 0.7511 -- iter: 2112/2235
[A[ATraining Step: 557  | total loss: [1m[32m0.53059[0m[0m | time: 96.618s
[2K
| RMSProp | epoch: 008 | loss: 0.53059 - acc: 0.7572 -- iter: 2144/2235
[A[ATraining Step: 558  | total loss: [1m[32m0.51290[0m[0m | time: 98.327s
[2K
| RMSProp | epoch: 008 | loss: 0.51290 - acc: 0.7659 -- iter: 2176/2235
[A[ATraining Step: 559  | total loss: [1m[32m0.50038[0m[0m | time: 99.727s
[2K
| RMSProp | epoch: 008 | loss: 0.50038 - acc: 0.7705 -- iter: 2208/2235
[A[ATraining Step: 560  | total loss: [1m[32m0.51416[0m[0m | time: 107.327s
[2K
| RMSProp | epoch: 008 | loss: 0.51416 - acc: 0.7591 | val_loss: 0.63428 - val_acc: 0.6924 -- iter: 2235/2235
--
Training Step: 561  | total loss: [1m[32m0.50090[0m[0m | time: 1.558s
[2K
| RMSProp | epoch: 009 | loss: 0.50090 - acc: 0.7644 -- iter: 0032/2235
[A[ATraining Step: 562  | total loss: [1m[32m0.50625[0m[0m | time: 3.055s
[2K
| RMSProp | epoch: 009 | loss: 0.50625 - acc: 0.7599 -- iter: 0064/2235
[A[ATraining Step: 563  | total loss: [1m[32m0.50301[0m[0m | time: 4.350s
[2K
| RMSProp | epoch: 009 | loss: 0.50301 - acc: 0.7683 -- iter: 0096/2235
[A[ATraining Step: 564  | total loss: [1m[32m0.51445[0m[0m | time: 5.781s
[2K
| RMSProp | epoch: 009 | loss: 0.51445 - acc: 0.7602 -- iter: 0128/2235
[A[ATraining Step: 565  | total loss: [1m[32m0.51978[0m[0m | time: 7.084s
[2K
| RMSProp | epoch: 009 | loss: 0.51978 - acc: 0.7592 -- iter: 0160/2235
[A[ATraining Step: 566  | total loss: [1m[32m0.51989[0m[0m | time: 8.336s
[2K
| RMSProp | epoch: 009 | loss: 0.51989 - acc: 0.7614 -- iter: 0192/2235
[A[ATraining Step: 567  | total loss: [1m[32m0.51734[0m[0m | time: 9.586s
[2K
| RMSProp | epoch: 009 | loss: 0.51734 - acc: 0.7602 -- iter: 0224/2235
[A[ATraining Step: 568  | total loss: [1m[32m0.51327[0m[0m | time: 10.933s
[2K
| RMSProp | epoch: 009 | loss: 0.51327 - acc: 0.7620 -- iter: 0256/2235
[A[ATraining Step: 569  | total loss: [1m[32m0.50099[0m[0m | time: 12.436s
[2K
| RMSProp | epoch: 009 | loss: 0.50099 - acc: 0.7747 -- iter: 0288/2235
[A[ATraining Step: 570  | total loss: [1m[32m0.51575[0m[0m | time: 13.644s
[2K
| RMSProp | epoch: 009 | loss: 0.51575 - acc: 0.7628 -- iter: 0320/2235
[A[ATraining Step: 571  | total loss: [1m[32m0.54922[0m[0m | time: 15.107s
[2K
| RMSProp | epoch: 009 | loss: 0.54922 - acc: 0.7397 -- iter: 0352/2235
[A[ATraining Step: 572  | total loss: [1m[32m0.54622[0m[0m | time: 16.691s
[2K
| RMSProp | epoch: 009 | loss: 0.54622 - acc: 0.7345 -- iter: 0384/2235
[A[ATraining Step: 573  | total loss: [1m[32m0.55637[0m[0m | time: 18.015s
[2K
| RMSProp | epoch: 009 | loss: 0.55637 - acc: 0.7204 -- iter: 0416/2235
[A[ATraining Step: 574  | total loss: [1m[32m0.55162[0m[0m | time: 19.464s
[2K
| RMSProp | epoch: 009 | loss: 0.55162 - acc: 0.7265 -- iter: 0448/2235
[A[ATraining Step: 575  | total loss: [1m[32m0.54992[0m[0m | time: 21.115s
[2K
| RMSProp | epoch: 009 | loss: 0.54992 - acc: 0.7288 -- iter: 0480/2235
[A[ATraining Step: 576  | total loss: [1m[32m0.55280[0m[0m | time: 22.668s
[2K
| RMSProp | epoch: 009 | loss: 0.55280 - acc: 0.7278 -- iter: 0512/2235
[A[ATraining Step: 577  | total loss: [1m[32m0.54533[0m[0m | time: 23.911s
[2K
| RMSProp | epoch: 009 | loss: 0.54533 - acc: 0.7394 -- iter: 0544/2235
[A[ATraining Step: 578  | total loss: [1m[32m0.53974[0m[0m | time: 25.296s
[2K
| RMSProp | epoch: 009 | loss: 0.53974 - acc: 0.7436 -- iter: 0576/2235
[A[ATraining Step: 579  | total loss: [1m[32m0.52909[0m[0m | time: 26.891s
[2K
| RMSProp | epoch: 009 | loss: 0.52909 - acc: 0.7567 -- iter: 0608/2235
[A[ATraining Step: 580  | total loss: [1m[32m0.54120[0m[0m | time: 28.337s
[2K
| RMSProp | epoch: 009 | loss: 0.54120 - acc: 0.7467 -- iter: 0640/2235
[A[ATraining Step: 581  | total loss: [1m[32m0.53407[0m[0m | time: 31.344s
[2K
| RMSProp | epoch: 009 | loss: 0.53407 - acc: 0.7501 -- iter: 0672/2235
[A[ATraining Step: 582  | total loss: [1m[32m0.53186[0m[0m | time: 34.224s
[2K
| RMSProp | epoch: 009 | loss: 0.53186 - acc: 0.7501 -- iter: 0704/2235
[A[ATraining Step: 583  | total loss: [1m[32m0.54121[0m[0m | time: 37.587s
[2K
| RMSProp | epoch: 009 | loss: 0.54121 - acc: 0.7439 -- iter: 0736/2235
[A[ATraining Step: 584  | total loss: [1m[32m0.53807[0m[0m | time: 39.026s
[2K
| RMSProp | epoch: 009 | loss: 0.53807 - acc: 0.7476 -- iter: 0768/2235
[A[ATraining Step: 585  | total loss: [1m[32m0.55147[0m[0m | time: 40.429s
[2K
| RMSProp | epoch: 009 | loss: 0.55147 - acc: 0.7291 -- iter: 0800/2235
[A[ATraining Step: 586  | total loss: [1m[32m0.54756[0m[0m | time: 42.063s
[2K
| RMSProp | epoch: 009 | loss: 0.54756 - acc: 0.7343 -- iter: 0832/2235
[A[ATraining Step: 587  | total loss: [1m[32m0.55799[0m[0m | time: 43.472s
[2K
| RMSProp | epoch: 009 | loss: 0.55799 - acc: 0.7265 -- iter: 0864/2235
[A[ATraining Step: 588  | total loss: [1m[32m0.54472[0m[0m | time: 44.883s
[2K
| RMSProp | epoch: 009 | loss: 0.54472 - acc: 0.7289 -- iter: 0896/2235
[A[ATraining Step: 589  | total loss: [1m[32m0.54545[0m[0m | time: 46.468s
[2K
| RMSProp | epoch: 009 | loss: 0.54545 - acc: 0.7278 -- iter: 0928/2235
[A[ATraining Step: 590  | total loss: [1m[32m0.53918[0m[0m | time: 47.900s
[2K
| RMSProp | epoch: 009 | loss: 0.53918 - acc: 0.7301 -- iter: 0960/2235
[A[ATraining Step: 591  | total loss: [1m[32m0.54039[0m[0m | time: 49.167s
[2K
| RMSProp | epoch: 009 | loss: 0.54039 - acc: 0.7352 -- iter: 0992/2235
[A[ATraining Step: 592  | total loss: [1m[32m0.53842[0m[0m | time: 50.583s
[2K
| RMSProp | epoch: 009 | loss: 0.53842 - acc: 0.7367 -- iter: 1024/2235
[A[ATraining Step: 593  | total loss: [1m[32m0.54102[0m[0m | time: 52.097s
[2K
| RMSProp | epoch: 009 | loss: 0.54102 - acc: 0.7411 -- iter: 1056/2235
[A[ATraining Step: 594  | total loss: [1m[32m0.54903[0m[0m | time: 53.663s
[2K
| RMSProp | epoch: 009 | loss: 0.54903 - acc: 0.7326 -- iter: 1088/2235
[A[ATraining Step: 595  | total loss: [1m[32m0.53603[0m[0m | time: 55.304s
[2K
| RMSProp | epoch: 009 | loss: 0.53603 - acc: 0.7437 -- iter: 1120/2235
[A[ATraining Step: 596  | total loss: [1m[32m0.54184[0m[0m | time: 59.765s
[2K
| RMSProp | epoch: 009 | loss: 0.54184 - acc: 0.7381 -- iter: 1152/2235
[A[ATraining Step: 597  | total loss: [1m[32m0.54880[0m[0m | time: 62.372s
[2K
| RMSProp | epoch: 009 | loss: 0.54880 - acc: 0.7362 -- iter: 1184/2235
[A[ATraining Step: 598  | total loss: [1m[32m0.53854[0m[0m | time: 63.704s
[2K
| RMSProp | epoch: 009 | loss: 0.53854 - acc: 0.7438 -- iter: 1216/2235
[A[ATraining Step: 599  | total loss: [1m[32m0.53402[0m[0m | time: 65.085s
[2K
| RMSProp | epoch: 009 | loss: 0.53402 - acc: 0.7538 -- iter: 1248/2235
[A[ATraining Step: 600  | total loss: [1m[32m0.52601[0m[0m | time: 72.836s
[2K
| RMSProp | epoch: 009 | loss: 0.52601 - acc: 0.7597 | val_loss: 0.69527 - val_acc: 0.5937 -- iter: 1280/2235
--
Training Step: 601  | total loss: [1m[32m0.52827[0m[0m | time: 74.244s
[2K
| RMSProp | epoch: 009 | loss: 0.52827 - acc: 0.7587 -- iter: 1312/2235
[A[ATraining Step: 602  | total loss: [1m[32m0.53532[0m[0m | time: 75.573s
[2K
| RMSProp | epoch: 009 | loss: 0.53532 - acc: 0.7547 -- iter: 1344/2235
[A[ATraining Step: 603  | total loss: [1m[32m0.53904[0m[0m | time: 76.890s
[2K
| RMSProp | epoch: 009 | loss: 0.53904 - acc: 0.7542 -- iter: 1376/2235
[A[ATraining Step: 604  | total loss: [1m[32m0.53187[0m[0m | time: 78.407s
[2K
| RMSProp | epoch: 009 | loss: 0.53187 - acc: 0.7569 -- iter: 1408/2235
[A[ATraining Step: 605  | total loss: [1m[32m0.52040[0m[0m | time: 80.042s
[2K
| RMSProp | epoch: 009 | loss: 0.52040 - acc: 0.7656 -- iter: 1440/2235
[A[ATraining Step: 606  | total loss: [1m[32m0.53912[0m[0m | time: 82.462s
[2K
| RMSProp | epoch: 009 | loss: 0.53912 - acc: 0.7516 -- iter: 1472/2235
[A[ATraining Step: 607  | total loss: [1m[32m0.56896[0m[0m | time: 87.622s
[2K
| RMSProp | epoch: 009 | loss: 0.56896 - acc: 0.7327 -- iter: 1504/2235
[A[ATraining Step: 608  | total loss: [1m[32m0.55737[0m[0m | time: 90.612s
[2K
| RMSProp | epoch: 009 | loss: 0.55737 - acc: 0.7406 -- iter: 1536/2235
[A[ATraining Step: 609  | total loss: [1m[32m0.54323[0m[0m | time: 92.108s
[2K
| RMSProp | epoch: 009 | loss: 0.54323 - acc: 0.7478 -- iter: 1568/2235
[A[ATraining Step: 610  | total loss: [1m[32m0.53741[0m[0m | time: 93.631s
[2K
| RMSProp | epoch: 009 | loss: 0.53741 - acc: 0.7512 -- iter: 1600/2235
[A[ATraining Step: 611  | total loss: [1m[32m0.52504[0m[0m | time: 95.097s
[2K
| RMSProp | epoch: 009 | loss: 0.52504 - acc: 0.7573 -- iter: 1632/2235
[A[ATraining Step: 612  | total loss: [1m[32m0.51731[0m[0m | time: 96.714s
[2K
| RMSProp | epoch: 009 | loss: 0.51731 - acc: 0.7534 -- iter: 1664/2235
[A[ATraining Step: 613  | total loss: [1m[32m0.52623[0m[0m | time: 98.017s
[2K
| RMSProp | epoch: 009 | loss: 0.52623 - acc: 0.7437 -- iter: 1696/2235
[A[ATraining Step: 614  | total loss: [1m[32m0.52591[0m[0m | time: 99.489s
[2K
| RMSProp | epoch: 009 | loss: 0.52591 - acc: 0.7412 -- iter: 1728/2235
[A[ATraining Step: 615  | total loss: [1m[32m0.52335[0m[0m | time: 101.229s
[2K
| RMSProp | epoch: 009 | loss: 0.52335 - acc: 0.7421 -- iter: 1760/2235
[A[ATraining Step: 616  | total loss: [1m[32m0.51879[0m[0m | time: 102.647s
[2K
| RMSProp | epoch: 009 | loss: 0.51879 - acc: 0.7491 -- iter: 1792/2235
[A[ATraining Step: 617  | total loss: [1m[32m0.50157[0m[0m | time: 104.183s
[2K
| RMSProp | epoch: 009 | loss: 0.50157 - acc: 0.7617 -- iter: 1824/2235
[A[ATraining Step: 618  | total loss: [1m[32m0.50330[0m[0m | time: 105.634s
[2K
| RMSProp | epoch: 009 | loss: 0.50330 - acc: 0.7574 -- iter: 1856/2235
[A[ATraining Step: 619  | total loss: [1m[32m0.50884[0m[0m | time: 107.165s
[2K
| RMSProp | epoch: 009 | loss: 0.50884 - acc: 0.7473 -- iter: 1888/2235
[A[ATraining Step: 620  | total loss: [1m[32m0.52667[0m[0m | time: 108.631s
[2K
| RMSProp | epoch: 009 | loss: 0.52667 - acc: 0.7382 -- iter: 1920/2235
[A[ATraining Step: 621  | total loss: [1m[32m0.52857[0m[0m | time: 110.107s
[2K
| RMSProp | epoch: 009 | loss: 0.52857 - acc: 0.7363 -- iter: 1952/2235
[A[ATraining Step: 622  | total loss: [1m[32m0.52498[0m[0m | time: 111.501s
[2K
| RMSProp | epoch: 009 | loss: 0.52498 - acc: 0.7439 -- iter: 1984/2235
[A[ATraining Step: 623  | total loss: [1m[32m0.52144[0m[0m | time: 112.998s
[2K
| RMSProp | epoch: 009 | loss: 0.52144 - acc: 0.7507 -- iter: 2016/2235
[A[ATraining Step: 624  | total loss: [1m[32m0.51989[0m[0m | time: 114.525s
[2K
| RMSProp | epoch: 009 | loss: 0.51989 - acc: 0.7507 -- iter: 2048/2235
[A[ATraining Step: 625  | total loss: [1m[32m0.50890[0m[0m | time: 116.041s
[2K
| RMSProp | epoch: 009 | loss: 0.50890 - acc: 0.7537 -- iter: 2080/2235
[A[ATraining Step: 626  | total loss: [1m[32m0.50132[0m[0m | time: 117.337s
[2K
| RMSProp | epoch: 009 | loss: 0.50132 - acc: 0.7565 -- iter: 2112/2235
[A[ATraining Step: 627  | total loss: [1m[32m0.50225[0m[0m | time: 118.730s
[2K
| RMSProp | epoch: 009 | loss: 0.50225 - acc: 0.7527 -- iter: 2144/2235
[A[ATraining Step: 628  | total loss: [1m[32m0.50131[0m[0m | time: 120.283s
[2K
| RMSProp | epoch: 009 | loss: 0.50131 - acc: 0.7618 -- iter: 2176/2235
[A[ATraining Step: 629  | total loss: [1m[32m0.50642[0m[0m | time: 121.783s
[2K
| RMSProp | epoch: 009 | loss: 0.50642 - acc: 0.7606 -- iter: 2208/2235
[A[ATraining Step: 630  | total loss: [1m[32m0.49199[0m[0m | time: 129.762s
[2K
| RMSProp | epoch: 009 | loss: 0.49199 - acc: 0.7658 | val_loss: 0.78118 - val_acc: 0.5722 -- iter: 2235/2235
--
Training Step: 631  | total loss: [1m[32m0.49080[0m[0m | time: 1.400s
[2K
| RMSProp | epoch: 010 | loss: 0.49080 - acc: 0.7705 -- iter: 0032/2235
[A[ATraining Step: 632  | total loss: [1m[32m0.48590[0m[0m | time: 2.930s
[2K
| RMSProp | epoch: 010 | loss: 0.48590 - acc: 0.7778 -- iter: 0064/2235
[A[ATraining Step: 633  | total loss: [1m[32m0.47392[0m[0m | time: 4.359s
[2K
| RMSProp | epoch: 010 | loss: 0.47392 - acc: 0.7844 -- iter: 0096/2235
[A[ATraining Step: 634  | total loss: [1m[32m0.48996[0m[0m | time: 5.889s
[2K
| RMSProp | epoch: 010 | loss: 0.48996 - acc: 0.7747 -- iter: 0128/2235
[A[ATraining Step: 635  | total loss: [1m[32m0.52885[0m[0m | time: 7.079s
[2K
| RMSProp | epoch: 010 | loss: 0.52885 - acc: 0.7472 -- iter: 0160/2235
[A[ATraining Step: 636  | total loss: [1m[32m0.51916[0m[0m | time: 8.578s
[2K
| RMSProp | epoch: 010 | loss: 0.51916 - acc: 0.7569 -- iter: 0192/2235
[A[ATraining Step: 637  | total loss: [1m[32m0.53760[0m[0m | time: 10.200s
[2K
| RMSProp | epoch: 010 | loss: 0.53760 - acc: 0.7437 -- iter: 0224/2235
[A[ATraining Step: 638  | total loss: [1m[32m0.52736[0m[0m | time: 11.574s
[2K
| RMSProp | epoch: 010 | loss: 0.52736 - acc: 0.7537 -- iter: 0256/2235
[A[ATraining Step: 639  | total loss: [1m[32m0.55775[0m[0m | time: 13.425s
[2K
| RMSProp | epoch: 010 | loss: 0.55775 - acc: 0.7302 -- iter: 0288/2235
[A[ATraining Step: 640  | total loss: [1m[32m0.54274[0m[0m | time: 15.712s
[2K
| RMSProp | epoch: 010 | loss: 0.54274 - acc: 0.7461 -- iter: 0320/2235
[A[ATraining Step: 641  | total loss: [1m[32m0.52849[0m[0m | time: 17.275s
[2K
| RMSProp | epoch: 010 | loss: 0.52849 - acc: 0.7527 -- iter: 0352/2235
[A[ATraining Step: 642  | total loss: [1m[32m0.51307[0m[0m | time: 18.656s
[2K
| RMSProp | epoch: 010 | loss: 0.51307 - acc: 0.7681 -- iter: 0384/2235
[A[ATraining Step: 643  | total loss: [1m[32m0.50007[0m[0m | time: 20.240s
[2K
| RMSProp | epoch: 010 | loss: 0.50007 - acc: 0.7756 -- iter: 0416/2235
[A[ATraining Step: 644  | total loss: [1m[32m0.50101[0m[0m | time: 21.681s
[2K
| RMSProp | epoch: 010 | loss: 0.50101 - acc: 0.7731 -- iter: 0448/2235
[A[ATraining Step: 645  | total loss: [1m[32m0.50354[0m[0m | time: 23.353s
[2K
| RMSProp | epoch: 010 | loss: 0.50354 - acc: 0.7739 -- iter: 0480/2235
[A[ATraining Step: 646  | total loss: [1m[32m0.50349[0m[0m | time: 25.023s
[2K
| RMSProp | epoch: 010 | loss: 0.50349 - acc: 0.7746 -- iter: 0512/2235
[A[ATraining Step: 647  | total loss: [1m[32m0.49782[0m[0m | time: 26.574s
[2K
| RMSProp | epoch: 010 | loss: 0.49782 - acc: 0.7753 -- iter: 0544/2235
[A[ATraining Step: 648  | total loss: [1m[32m0.49073[0m[0m | time: 27.703s
[2K
| RMSProp | epoch: 010 | loss: 0.49073 - acc: 0.7821 -- iter: 0576/2235
[A[ATraining Step: 649  | total loss: [1m[32m0.47444[0m[0m | time: 29.278s
[2K
| RMSProp | epoch: 010 | loss: 0.47444 - acc: 0.7945 -- iter: 0608/2235
[A[ATraining Step: 650  | total loss: [1m[32m0.45962[0m[0m | time: 30.781s
[2K
| RMSProp | epoch: 010 | loss: 0.45962 - acc: 0.8057 -- iter: 0640/2235
[A[ATraining Step: 651  | total loss: [1m[32m0.45798[0m[0m | time: 37.969s
[2K
| RMSProp | epoch: 010 | loss: 0.45798 - acc: 0.8033 -- iter: 0672/2235
[A[ATraining Step: 652  | total loss: [1m[32m0.47849[0m[0m | time: 40.031s
[2K
| RMSProp | epoch: 010 | loss: 0.47849 - acc: 0.7792 -- iter: 0704/2235
[A[ATraining Step: 653  | total loss: [1m[32m0.48489[0m[0m | time: 43.194s
[2K
| RMSProp | epoch: 010 | loss: 0.48489 - acc: 0.7763 -- iter: 0736/2235
[A[ATraining Step: 654  | total loss: [1m[32m0.48484[0m[0m | time: 47.224s
[2K
| RMSProp | epoch: 010 | loss: 0.48484 - acc: 0.7799 -- iter: 0768/2235
[A[ATraining Step: 655  | total loss: [1m[32m0.47952[0m[0m | time: 48.662s
[2K
| RMSProp | epoch: 010 | loss: 0.47952 - acc: 0.7863 -- iter: 0800/2235
[A[ATraining Step: 656  | total loss: [1m[32m0.48097[0m[0m | time: 50.139s
[2K
| RMSProp | epoch: 010 | loss: 0.48097 - acc: 0.7889 -- iter: 0832/2235
[A[ATraining Step: 657  | total loss: [1m[32m0.47526[0m[0m | time: 51.603s
[2K
| RMSProp | epoch: 010 | loss: 0.47526 - acc: 0.7944 -- iter: 0864/2235
[A[ATraining Step: 658  | total loss: [1m[32m0.45307[0m[0m | time: 53.111s
[2K
| RMSProp | epoch: 010 | loss: 0.45307 - acc: 0.8118 -- iter: 0896/2235
[A[ATraining Step: 659  | total loss: [1m[32m0.45518[0m[0m | time: 54.735s
[2K
| RMSProp | epoch: 010 | loss: 0.45518 - acc: 0.8088 -- iter: 0928/2235
[A[ATraining Step: 660  | total loss: [1m[32m0.43449[0m[0m | time: 56.085s
[2K
| RMSProp | epoch: 010 | loss: 0.43449 - acc: 0.8185 -- iter: 0960/2235
[A[ATraining Step: 661  | total loss: [1m[32m0.45916[0m[0m | time: 57.609s
[2K
| RMSProp | epoch: 010 | loss: 0.45916 - acc: 0.8085 -- iter: 0992/2235
[A[ATraining Step: 662  | total loss: [1m[32m0.47724[0m[0m | time: 58.996s
[2K
| RMSProp | epoch: 010 | loss: 0.47724 - acc: 0.7996 -- iter: 1024/2235
[A[ATraining Step: 663  | total loss: [1m[32m0.49341[0m[0m | time: 60.444s
[2K
| RMSProp | epoch: 010 | loss: 0.49341 - acc: 0.7790 -- iter: 1056/2235
[A[ATraining Step: 664  | total loss: [1m[32m0.47761[0m[0m | time: 62.034s
[2K
| RMSProp | epoch: 010 | loss: 0.47761 - acc: 0.7823 -- iter: 1088/2235
[A[ATraining Step: 665  | total loss: [1m[32m0.47659[0m[0m | time: 63.407s
[2K
| RMSProp | epoch: 010 | loss: 0.47659 - acc: 0.7916 -- iter: 1120/2235
[A[ATraining Step: 666  | total loss: [1m[32m0.47526[0m[0m | time: 64.820s
[2K
| RMSProp | epoch: 010 | loss: 0.47526 - acc: 0.7874 -- iter: 1152/2235
[A[ATraining Step: 667  | total loss: [1m[32m0.46596[0m[0m | time: 66.269s
[2K
| RMSProp | epoch: 010 | loss: 0.46596 - acc: 0.7931 -- iter: 1184/2235
[A[ATraining Step: 668  | total loss: [1m[32m0.46216[0m[0m | time: 67.665s
[2K
| RMSProp | epoch: 010 | loss: 0.46216 - acc: 0.7981 -- iter: 1216/2235
[A[ATraining Step: 669  | total loss: [1m[32m0.46051[0m[0m | time: 69.094s
[2K
| RMSProp | epoch: 010 | loss: 0.46051 - acc: 0.8027 -- iter: 1248/2235
[A[ATraining Step: 670  | total loss: [1m[32m0.47064[0m[0m | time: 70.728s
[2K
| RMSProp | epoch: 010 | loss: 0.47064 - acc: 0.7974 -- iter: 1280/2235
[A[ATraining Step: 671  | total loss: [1m[32m0.47054[0m[0m | time: 72.189s
[2K
| RMSProp | epoch: 010 | loss: 0.47054 - acc: 0.7896 -- iter: 1312/2235
[A[ATraining Step: 672  | total loss: [1m[32m0.46453[0m[0m | time: 73.724s
[2K
| RMSProp | epoch: 010 | loss: 0.46453 - acc: 0.7919 -- iter: 1344/2235
[A[ATraining Step: 673  | total loss: [1m[32m0.46315[0m[0m | time: 75.009s
[2K
| RMSProp | epoch: 010 | loss: 0.46315 - acc: 0.7939 -- iter: 1376/2235
[A[ATraining Step: 674  | total loss: [1m[32m0.45595[0m[0m | time: 76.358s
[2K
| RMSProp | epoch: 010 | loss: 0.45595 - acc: 0.7989 -- iter: 1408/2235
[A[ATraining Step: 675  | total loss: [1m[32m0.46115[0m[0m | time: 77.857s
[2K
| RMSProp | epoch: 010 | loss: 0.46115 - acc: 0.7971 -- iter: 1440/2235
[A[ATraining Step: 676  | total loss: [1m[32m0.46989[0m[0m | time: 79.382s
[2K
| RMSProp | epoch: 010 | loss: 0.46989 - acc: 0.7862 -- iter: 1472/2235
[A[ATraining Step: 677  | total loss: [1m[32m0.47348[0m[0m | time: 81.012s
[2K
| RMSProp | epoch: 010 | loss: 0.47348 - acc: 0.7794 -- iter: 1504/2235
[A[ATraining Step: 678  | total loss: [1m[32m0.46545[0m[0m | time: 85.413s
[2K
| RMSProp | epoch: 010 | loss: 0.46545 - acc: 0.7921 -- iter: 1536/2235
[A[ATraining Step: 679  | total loss: [1m[32m0.45193[0m[0m | time: 86.903s
[2K
| RMSProp | epoch: 010 | loss: 0.45193 - acc: 0.8035 -- iter: 1568/2235
[A[ATraining Step: 680  | total loss: [1m[32m0.45961[0m[0m | time: 88.296s
[2K
| RMSProp | epoch: 010 | loss: 0.45961 - acc: 0.8013 -- iter: 1600/2235
[A[ATraining Step: 681  | total loss: [1m[32m0.45018[0m[0m | time: 89.744s
[2K
| RMSProp | epoch: 010 | loss: 0.45018 - acc: 0.8055 -- iter: 1632/2235
[A[ATraining Step: 682  | total loss: [1m[32m0.44151[0m[0m | time: 91.214s
[2K
| RMSProp | epoch: 010 | loss: 0.44151 - acc: 0.8125 -- iter: 1664/2235
[A[ATraining Step: 683  | total loss: [1m[32m0.42572[0m[0m | time: 92.702s
[2K
| RMSProp | epoch: 010 | loss: 0.42572 - acc: 0.8281 -- iter: 1696/2235
[A[ATraining Step: 684  | total loss: [1m[32m0.44245[0m[0m | time: 94.388s
[2K
| RMSProp | epoch: 010 | loss: 0.44245 - acc: 0.8078 -- iter: 1728/2235
[A[ATraining Step: 685  | total loss: [1m[32m0.45034[0m[0m | time: 96.087s
[2K
| RMSProp | epoch: 010 | loss: 0.45034 - acc: 0.8020 -- iter: 1760/2235
[A[ATraining Step: 686  | total loss: [1m[32m0.44590[0m[0m | time: 97.485s
[2K
| RMSProp | epoch: 010 | loss: 0.44590 - acc: 0.8062 -- iter: 1792/2235
[A[ATraining Step: 687  | total loss: [1m[32m0.43875[0m[0m | time: 98.705s
[2K
| RMSProp | epoch: 010 | loss: 0.43875 - acc: 0.8100 -- iter: 1824/2235
[A[ATraining Step: 688  | total loss: [1m[32m0.42967[0m[0m | time: 100.272s
[2K
| RMSProp | epoch: 010 | loss: 0.42967 - acc: 0.8133 -- iter: 1856/2235
[A[ATraining Step: 689  | total loss: [1m[32m0.42373[0m[0m | time: 101.782s
[2K
| RMSProp | epoch: 010 | loss: 0.42373 - acc: 0.8226 -- iter: 1888/2235
[A[ATraining Step: 690  | total loss: [1m[32m0.42662[0m[0m | time: 103.127s
[2K
| RMSProp | epoch: 010 | loss: 0.42662 - acc: 0.8247 -- iter: 1920/2235
[A[ATraining Step: 691  | total loss: [1m[32m0.44846[0m[0m | time: 107.579s
[2K
| RMSProp | epoch: 010 | loss: 0.44846 - acc: 0.8110 -- iter: 1952/2235
[A[ATraining Step: 692  | total loss: [1m[32m0.44999[0m[0m | time: 108.861s
[2K
| RMSProp | epoch: 010 | loss: 0.44999 - acc: 0.8112 -- iter: 1984/2235
[A[ATraining Step: 693  | total loss: [1m[32m0.43483[0m[0m | time: 110.242s
[2K
| RMSProp | epoch: 010 | loss: 0.43483 - acc: 0.8207 -- iter: 2016/2235
[A[ATraining Step: 694  | total loss: [1m[32m0.42198[0m[0m | time: 111.721s
[2K
| RMSProp | epoch: 010 | loss: 0.42198 - acc: 0.8261 -- iter: 2048/2235
[A[ATraining Step: 695  | total loss: [1m[32m0.42191[0m[0m | time: 112.997s
[2K
| RMSProp | epoch: 010 | loss: 0.42191 - acc: 0.8310 -- iter: 2080/2235
[A[ATraining Step: 696  | total loss: [1m[32m0.40558[0m[0m | time: 114.438s
[2K
| RMSProp | epoch: 010 | loss: 0.40558 - acc: 0.8385 -- iter: 2112/2235
[A[ATraining Step: 697  | total loss: [1m[32m0.40540[0m[0m | time: 116.019s
[2K
| RMSProp | epoch: 010 | loss: 0.40540 - acc: 0.8359 -- iter: 2144/2235
[A[ATraining Step: 698  | total loss: [1m[32m0.41625[0m[0m | time: 117.608s
[2K
| RMSProp | epoch: 010 | loss: 0.41625 - acc: 0.8179 -- iter: 2176/2235
[A[ATraining Step: 699  | total loss: [1m[32m0.44364[0m[0m | time: 118.790s
[2K
| RMSProp | epoch: 010 | loss: 0.44364 - acc: 0.8018 -- iter: 2208/2235
[A[ATraining Step: 700  | total loss: [1m[32m0.43213[0m[0m | time: 126.484s
[2K
| RMSProp | epoch: 010 | loss: 0.43213 - acc: 0.8091 | val_loss: 0.56789 - val_acc: 0.7139 -- iter: 2235/2235
--
Training Step: 701  | total loss: [1m[32m0.44051[0m[0m | time: 1.503s
[2K
| RMSProp | epoch: 011 | loss: 0.44051 - acc: 0.7969 -- iter: 0032/2235
[A[ATraining Step: 702  | total loss: [1m[32m0.43836[0m[0m | time: 2.937s
[2K
| RMSProp | epoch: 011 | loss: 0.43836 - acc: 0.8047 -- iter: 0064/2235
[A[ATraining Step: 703  | total loss: [1m[32m0.42922[0m[0m | time: 4.305s
[2K
| RMSProp | epoch: 011 | loss: 0.42922 - acc: 0.8055 -- iter: 0096/2235
[A[ATraining Step: 704  | total loss: [1m[32m0.42623[0m[0m | time: 5.672s
[2K
| RMSProp | epoch: 011 | loss: 0.42623 - acc: 0.8093 -- iter: 0128/2235
[A[ATraining Step: 705  | total loss: [1m[32m0.41566[0m[0m | time: 7.163s
[2K
| RMSProp | epoch: 011 | loss: 0.41566 - acc: 0.8190 -- iter: 0160/2235
[A[ATraining Step: 706  | total loss: [1m[32m0.40333[0m[0m | time: 9.076s
[2K
| RMSProp | epoch: 011 | loss: 0.40333 - acc: 0.8278 -- iter: 0192/2235
[A[ATraining Step: 707  | total loss: [1m[32m0.41439[0m[0m | time: 10.326s
[2K
| RMSProp | epoch: 011 | loss: 0.41439 - acc: 0.8294 -- iter: 0224/2235
[A[ATraining Step: 708  | total loss: [1m[32m0.43761[0m[0m | time: 13.354s
[2K
| RMSProp | epoch: 011 | loss: 0.43761 - acc: 0.8183 -- iter: 0256/2235
[A[ATraining Step: 709  | total loss: [1m[32m0.42252[0m[0m | time: 17.674s
[2K
| RMSProp | epoch: 011 | loss: 0.42252 - acc: 0.8302 -- iter: 0288/2235
[A[ATraining Step: 710  | total loss: [1m[32m0.42075[0m[0m | time: 20.320s
[2K
| RMSProp | epoch: 011 | loss: 0.42075 - acc: 0.8250 -- iter: 0320/2235
[A[ATraining Step: 711  | total loss: [1m[32m0.40007[0m[0m | time: 24.359s
[2K
| RMSProp | epoch: 011 | loss: 0.40007 - acc: 0.8425 -- iter: 0352/2235
[A[ATraining Step: 712  | total loss: [1m[32m0.40736[0m[0m | time: 25.614s
[2K
| RMSProp | epoch: 011 | loss: 0.40736 - acc: 0.8364 -- iter: 0384/2235
[A[ATraining Step: 713  | total loss: [1m[32m0.41212[0m[0m | time: 26.880s
[2K
| RMSProp | epoch: 011 | loss: 0.41212 - acc: 0.8340 -- iter: 0416/2235
[A[ATraining Step: 714  | total loss: [1m[32m0.42854[0m[0m | time: 28.070s
[2K
| RMSProp | epoch: 011 | loss: 0.42854 - acc: 0.8162 -- iter: 0448/2235
[A[ATraining Step: 715  | total loss: [1m[32m0.43767[0m[0m | time: 29.408s
[2K
| RMSProp | epoch: 011 | loss: 0.43767 - acc: 0.8065 -- iter: 0480/2235
[A[ATraining Step: 716  | total loss: [1m[32m0.42527[0m[0m | time: 30.613s
[2K
| RMSProp | epoch: 011 | loss: 0.42527 - acc: 0.8196 -- iter: 0512/2235
[A[ATraining Step: 717  | total loss: [1m[32m0.43371[0m[0m | time: 31.880s
[2K
| RMSProp | epoch: 011 | loss: 0.43371 - acc: 0.8064 -- iter: 0544/2235
[A[ATraining Step: 718  | total loss: [1m[32m0.44484[0m[0m | time: 33.287s
[2K
| RMSProp | epoch: 011 | loss: 0.44484 - acc: 0.8007 -- iter: 0576/2235
[A[ATraining Step: 719  | total loss: [1m[32m0.45172[0m[0m | time: 34.643s
[2K
| RMSProp | epoch: 011 | loss: 0.45172 - acc: 0.7988 -- iter: 0608/2235
[A[ATraining Step: 720  | total loss: [1m[32m0.45402[0m[0m | time: 35.631s
[2K
| RMSProp | epoch: 011 | loss: 0.45402 - acc: 0.7970 -- iter: 0640/2235
[A[ATraining Step: 721  | total loss: [1m[32m0.45040[0m[0m | time: 37.009s
[2K
| RMSProp | epoch: 011 | loss: 0.45040 - acc: 0.7954 -- iter: 0672/2235
[A[ATraining Step: 722  | total loss: [1m[32m0.45489[0m[0m | time: 38.381s
[2K
| RMSProp | epoch: 011 | loss: 0.45489 - acc: 0.7971 -- iter: 0704/2235
[A[ATraining Step: 723  | total loss: [1m[32m0.47240[0m[0m | time: 39.629s
[2K
| RMSProp | epoch: 011 | loss: 0.47240 - acc: 0.7831 -- iter: 0736/2235
[A[ATraining Step: 724  | total loss: [1m[32m0.46631[0m[0m | time: 40.728s
[2K
| RMSProp | epoch: 011 | loss: 0.46631 - acc: 0.7829 -- iter: 0768/2235
[A[ATraining Step: 725  | total loss: [1m[32m0.46530[0m[0m | time: 42.058s
[2K
| RMSProp | epoch: 011 | loss: 0.46530 - acc: 0.7796 -- iter: 0800/2235
[A[ATraining Step: 726  | total loss: [1m[32m0.46781[0m[0m | time: 43.363s
[2K
| RMSProp | epoch: 011 | loss: 0.46781 - acc: 0.7735 -- iter: 0832/2235
[A[ATraining Step: 727  | total loss: [1m[32m0.46341[0m[0m | time: 44.598s
[2K
| RMSProp | epoch: 011 | loss: 0.46341 - acc: 0.7743 -- iter: 0864/2235
[A[ATraining Step: 728  | total loss: [1m[32m0.45997[0m[0m | time: 45.905s
[2K
| RMSProp | epoch: 011 | loss: 0.45997 - acc: 0.7781 -- iter: 0896/2235
[A[ATraining Step: 729  | total loss: [1m[32m0.44425[0m[0m | time: 47.261s
[2K
| RMSProp | epoch: 011 | loss: 0.44425 - acc: 0.7909 -- iter: 0928/2235
[A[ATraining Step: 730  | total loss: [1m[32m0.41847[0m[0m | time: 48.680s
[2K
| RMSProp | epoch: 011 | loss: 0.41847 - acc: 0.8118 -- iter: 0960/2235
[A[ATraining Step: 731  | total loss: [1m[32m0.40373[0m[0m | time: 49.930s
[2K
| RMSProp | epoch: 011 | loss: 0.40373 - acc: 0.8213 -- iter: 0992/2235
[A[ATraining Step: 732  | total loss: [1m[32m0.40314[0m[0m | time: 51.235s
[2K
| RMSProp | epoch: 011 | loss: 0.40314 - acc: 0.8204 -- iter: 1024/2235
[A[ATraining Step: 733  | total loss: [1m[32m0.42358[0m[0m | time: 52.473s
[2K
| RMSProp | epoch: 011 | loss: 0.42358 - acc: 0.8102 -- iter: 1056/2235
[A[ATraining Step: 734  | total loss: [1m[32m0.41114[0m[0m | time: 53.738s
[2K
| RMSProp | epoch: 011 | loss: 0.41114 - acc: 0.8167 -- iter: 1088/2235
[A[ATraining Step: 735  | total loss: [1m[32m0.39640[0m[0m | time: 54.889s
[2K
| RMSProp | epoch: 011 | loss: 0.39640 - acc: 0.8288 -- iter: 1120/2235
[A[ATraining Step: 736  | total loss: [1m[32m0.39138[0m[0m | time: 56.072s
[2K
| RMSProp | epoch: 011 | loss: 0.39138 - acc: 0.8303 -- iter: 1152/2235
[A[ATraining Step: 737  | total loss: [1m[32m0.38151[0m[0m | time: 57.342s
[2K
| RMSProp | epoch: 011 | loss: 0.38151 - acc: 0.8316 -- iter: 1184/2235
[A[ATraining Step: 738  | total loss: [1m[32m0.41500[0m[0m | time: 58.575s
[2K
| RMSProp | epoch: 011 | loss: 0.41500 - acc: 0.8141 -- iter: 1216/2235
[A[ATraining Step: 739  | total loss: [1m[32m0.43619[0m[0m | time: 59.941s
[2K
| RMSProp | epoch: 011 | loss: 0.43619 - acc: 0.7952 -- iter: 1248/2235
[A[ATraining Step: 740  | total loss: [1m[32m0.43380[0m[0m | time: 61.262s
[2K
| RMSProp | epoch: 011 | loss: 0.43380 - acc: 0.7907 -- iter: 1280/2235
[A[ATraining Step: 741  | total loss: [1m[32m0.43056[0m[0m | time: 62.521s
[2K
| RMSProp | epoch: 011 | loss: 0.43056 - acc: 0.7991 -- iter: 1312/2235
[A[ATraining Step: 742  | total loss: [1m[32m0.41894[0m[0m | time: 63.858s
[2K
| RMSProp | epoch: 011 | loss: 0.41894 - acc: 0.8098 -- iter: 1344/2235
[A[ATraining Step: 743  | total loss: [1m[32m0.42549[0m[0m | time: 65.051s
[2K
| RMSProp | epoch: 011 | loss: 0.42549 - acc: 0.8070 -- iter: 1376/2235
[A[ATraining Step: 744  | total loss: [1m[32m0.46586[0m[0m | time: 66.230s
[2K
| RMSProp | epoch: 011 | loss: 0.46586 - acc: 0.7888 -- iter: 1408/2235
[A[ATraining Step: 745  | total loss: [1m[32m0.44559[0m[0m | time: 67.295s
[2K
| RMSProp | epoch: 011 | loss: 0.44559 - acc: 0.8068 -- iter: 1440/2235
[A[ATraining Step: 746  | total loss: [1m[32m0.42174[0m[0m | time: 68.501s
[2K
| RMSProp | epoch: 011 | loss: 0.42174 - acc: 0.8230 -- iter: 1472/2235
[A[ATraining Step: 747  | total loss: [1m[32m0.41846[0m[0m | time: 69.721s
[2K
| RMSProp | epoch: 011 | loss: 0.41846 - acc: 0.8219 -- iter: 1504/2235
[A[ATraining Step: 748  | total loss: [1m[32m0.40911[0m[0m | time: 70.953s
[2K
| RMSProp | epoch: 011 | loss: 0.40911 - acc: 0.8303 -- iter: 1536/2235
[A[ATraining Step: 749  | total loss: [1m[32m0.39784[0m[0m | time: 72.180s
[2K
| RMSProp | epoch: 011 | loss: 0.39784 - acc: 0.8411 -- iter: 1568/2235
[A[ATraining Step: 750  | total loss: [1m[32m0.39610[0m[0m | time: 73.459s
[2K
| RMSProp | epoch: 011 | loss: 0.39610 - acc: 0.8445 -- iter: 1600/2235
[A[ATraining Step: 751  | total loss: [1m[32m0.38329[0m[0m | time: 74.834s
[2K
| RMSProp | epoch: 011 | loss: 0.38329 - acc: 0.8506 -- iter: 1632/2235
[A[ATraining Step: 752  | total loss: [1m[32m0.36956[0m[0m | time: 76.089s
[2K
| RMSProp | epoch: 011 | loss: 0.36956 - acc: 0.8562 -- iter: 1664/2235
[A[ATraining Step: 753  | total loss: [1m[32m0.36467[0m[0m | time: 77.159s
[2K
| RMSProp | epoch: 011 | loss: 0.36467 - acc: 0.8550 -- iter: 1696/2235
[A[ATraining Step: 754  | total loss: [1m[32m0.35026[0m[0m | time: 78.477s
[2K
| RMSProp | epoch: 011 | loss: 0.35026 - acc: 0.8601 -- iter: 1728/2235
[A[ATraining Step: 755  | total loss: [1m[32m0.35272[0m[0m | time: 79.739s
[2K
| RMSProp | epoch: 011 | loss: 0.35272 - acc: 0.8584 -- iter: 1760/2235
[A[ATraining Step: 756  | total loss: [1m[32m0.34445[0m[0m | time: 80.881s
[2K
| RMSProp | epoch: 011 | loss: 0.34445 - acc: 0.8601 -- iter: 1792/2235
[A[ATraining Step: 757  | total loss: [1m[32m0.32977[0m[0m | time: 82.126s
[2K
| RMSProp | epoch: 011 | loss: 0.32977 - acc: 0.8678 -- iter: 1824/2235
[A[ATraining Step: 758  | total loss: [1m[32m0.33646[0m[0m | time: 83.367s
[2K
| RMSProp | epoch: 011 | loss: 0.33646 - acc: 0.8686 -- iter: 1856/2235
[A[ATraining Step: 759  | total loss: [1m[32m0.35899[0m[0m | time: 84.593s
[2K
| RMSProp | epoch: 011 | loss: 0.35899 - acc: 0.8567 -- iter: 1888/2235
[A[ATraining Step: 760  | total loss: [1m[32m0.36681[0m[0m | time: 85.867s
[2K
| RMSProp | epoch: 011 | loss: 0.36681 - acc: 0.8554 -- iter: 1920/2235
[A[ATraining Step: 761  | total loss: [1m[32m0.36900[0m[0m | time: 87.201s
[2K
| RMSProp | epoch: 011 | loss: 0.36900 - acc: 0.8542 -- iter: 1952/2235
[A[ATraining Step: 762  | total loss: [1m[32m0.35762[0m[0m | time: 88.509s
[2K
| RMSProp | epoch: 011 | loss: 0.35762 - acc: 0.8594 -- iter: 1984/2235
[A[ATraining Step: 763  | total loss: [1m[32m0.36239[0m[0m | time: 89.854s
[2K
| RMSProp | epoch: 011 | loss: 0.36239 - acc: 0.8516 -- iter: 2016/2235
[A[ATraining Step: 764  | total loss: [1m[32m0.35973[0m[0m | time: 91.237s
[2K
| RMSProp | epoch: 011 | loss: 0.35973 - acc: 0.8540 -- iter: 2048/2235
[A[ATraining Step: 765  | total loss: [1m[32m0.35182[0m[0m | time: 92.663s
[2K
| RMSProp | epoch: 011 | loss: 0.35182 - acc: 0.8592 -- iter: 2080/2235
[A[ATraining Step: 766  | total loss: [1m[32m0.33836[0m[0m | time: 93.962s
[2K
| RMSProp | epoch: 011 | loss: 0.33836 - acc: 0.8670 -- iter: 2112/2235
[A[ATraining Step: 767  | total loss: [1m[32m0.33388[0m[0m | time: 95.345s
[2K
| RMSProp | epoch: 011 | loss: 0.33388 - acc: 0.8709 -- iter: 2144/2235
[A[ATraining Step: 768  | total loss: [1m[32m0.32916[0m[0m | time: 96.723s
[2K
| RMSProp | epoch: 011 | loss: 0.32916 - acc: 0.8745 -- iter: 2176/2235
[A[ATraining Step: 769  | total loss: [1m[32m0.32243[0m[0m | time: 97.836s
[2K
| RMSProp | epoch: 011 | loss: 0.32243 - acc: 0.8745 -- iter: 2208/2235
[A[ATraining Step: 770  | total loss: [1m[32m0.32435[0m[0m | time: 102.690s
[2K
| RMSProp | epoch: 011 | loss: 0.32435 - acc: 0.8746 | val_loss: 0.58541 - val_acc: 0.7382 -- iter: 2235/2235
--
Training Step: 771  | total loss: [1m[32m0.33863[0m[0m | time: 1.007s
[2K
| RMSProp | epoch: 012 | loss: 0.33863 - acc: 0.8652 -- iter: 0032/2235
[A[ATraining Step: 772  | total loss: [1m[32m0.36226[0m[0m | time: 1.878s
[2K
| RMSProp | epoch: 012 | loss: 0.36226 - acc: 0.8568 -- iter: 0064/2235
[A[ATraining Step: 773  | total loss: [1m[32m0.34796[0m[0m | time: 2.830s
[2K
| RMSProp | epoch: 012 | loss: 0.34796 - acc: 0.8680 -- iter: 0096/2235
[A[ATraining Step: 774  | total loss: [1m[32m0.33518[0m[0m | time: 3.949s
[2K
| RMSProp | epoch: 012 | loss: 0.33518 - acc: 0.8750 -- iter: 0128/2235
[A[ATraining Step: 775  | total loss: [1m[32m0.32511[0m[0m | time: 5.014s
[2K
| RMSProp | epoch: 012 | loss: 0.32511 - acc: 0.8812 -- iter: 0160/2235
[A[ATraining Step: 776  | total loss: [1m[32m0.31604[0m[0m | time: 5.869s
[2K
| RMSProp | epoch: 012 | loss: 0.31604 - acc: 0.8869 -- iter: 0192/2235
[A[ATraining Step: 777  | total loss: [1m[32m0.30448[0m[0m | time: 6.783s
[2K
| RMSProp | epoch: 012 | loss: 0.30448 - acc: 0.8919 -- iter: 0224/2235
[A[ATraining Step: 778  | total loss: [1m[32m0.30081[0m[0m | time: 7.778s
[2K
| RMSProp | epoch: 012 | loss: 0.30081 - acc: 0.8934 -- iter: 0256/2235
[A[ATraining Step: 779  | total loss: [1m[32m0.30128[0m[0m | time: 8.771s
[2K
| RMSProp | epoch: 012 | loss: 0.30128 - acc: 0.8884 -- iter: 0288/2235
[A[ATraining Step: 780  | total loss: [1m[32m0.32037[0m[0m | time: 9.615s
[2K
| RMSProp | epoch: 012 | loss: 0.32037 - acc: 0.8777 -- iter: 0320/2235
[A[ATraining Step: 781  | total loss: [1m[32m0.33549[0m[0m | time: 10.461s
[2K
| RMSProp | epoch: 012 | loss: 0.33549 - acc: 0.8677 -- iter: 0352/2235
[A[ATraining Step: 782  | total loss: [1m[32m0.33884[0m[0m | time: 11.443s
[2K
| RMSProp | epoch: 012 | loss: 0.33884 - acc: 0.8624 -- iter: 0384/2235
[A[ATraining Step: 783  | total loss: [1m[32m0.32866[0m[0m | time: 12.486s
[2K
| RMSProp | epoch: 012 | loss: 0.32866 - acc: 0.8699 -- iter: 0416/2235
[A[ATraining Step: 784  | total loss: [1m[32m0.33001[0m[0m | time: 13.449s
[2K
| RMSProp | epoch: 012 | loss: 0.33001 - acc: 0.8642 -- iter: 0448/2235
[A[ATraining Step: 785  | total loss: [1m[32m0.33752[0m[0m | time: 14.535s
[2K
| RMSProp | epoch: 012 | loss: 0.33752 - acc: 0.8559 -- iter: 0480/2235
[A[ATraining Step: 786  | total loss: [1m[32m0.32282[0m[0m | time: 15.666s
[2K
| RMSProp | epoch: 012 | loss: 0.32282 - acc: 0.8640 -- iter: 0512/2235
[A[ATraining Step: 787  | total loss: [1m[32m0.31177[0m[0m | time: 16.467s
[2K
| RMSProp | epoch: 012 | loss: 0.31177 - acc: 0.8714 -- iter: 0544/2235
[A[ATraining Step: 788  | total loss: [1m[32m0.29141[0m[0m | time: 17.383s
[2K
| RMSProp | epoch: 012 | loss: 0.29141 - acc: 0.8811 -- iter: 0576/2235
[A[ATraining Step: 789  | total loss: [1m[32m0.29261[0m[0m | time: 18.464s
[2K
| RMSProp | epoch: 012 | loss: 0.29261 - acc: 0.8836 -- iter: 0608/2235
[A[ATraining Step: 790  | total loss: [1m[32m0.34607[0m[0m | time: 19.753s
[2K
| RMSProp | epoch: 012 | loss: 0.34607 - acc: 0.8578 -- iter: 0640/2235
[A[ATraining Step: 791  | total loss: [1m[32m0.34348[0m[0m | time: 21.027s
[2K
| RMSProp | epoch: 012 | loss: 0.34348 - acc: 0.8564 -- iter: 0672/2235
[A[ATraining Step: 792  | total loss: [1m[32m0.37042[0m[0m | time: 22.171s
[2K
| RMSProp | epoch: 012 | loss: 0.37042 - acc: 0.8457 -- iter: 0704/2235
[A[ATraining Step: 793  | total loss: [1m[32m0.36368[0m[0m | time: 23.382s
[2K
| RMSProp | epoch: 012 | loss: 0.36368 - acc: 0.8518 -- iter: 0736/2235
[A[ATraining Step: 794  | total loss: [1m[32m0.35951[0m[0m | time: 24.616s
[2K
| RMSProp | epoch: 012 | loss: 0.35951 - acc: 0.8541 -- iter: 0768/2235
[A[ATraining Step: 795  | total loss: [1m[32m0.34687[0m[0m | time: 25.822s
[2K
| RMSProp | epoch: 012 | loss: 0.34687 - acc: 0.8593 -- iter: 0800/2235
[A[ATraining Step: 796  | total loss: [1m[32m0.33602[0m[0m | time: 26.985s
[2K
| RMSProp | epoch: 012 | loss: 0.33602 - acc: 0.8609 -- iter: 0832/2235
[A[ATraining Step: 797  | total loss: [1m[32m0.33282[0m[0m | time: 28.372s
[2K
| RMSProp | epoch: 012 | loss: 0.33282 - acc: 0.8560 -- iter: 0864/2235
[A[ATraining Step: 798  | total loss: [1m[32m0.31879[0m[0m | time: 29.743s
[2K
| RMSProp | epoch: 012 | loss: 0.31879 - acc: 0.8642 -- iter: 0896/2235
[A[ATraining Step: 799  | total loss: [1m[32m0.32889[0m[0m | time: 31.110s
[2K
| RMSProp | epoch: 012 | loss: 0.32889 - acc: 0.8622 -- iter: 0928/2235
[A[ATraining Step: 800  | total loss: [1m[32m0.37354[0m[0m | time: 37.653s
[2K
| RMSProp | epoch: 012 | loss: 0.37354 - acc: 0.8384 | val_loss: 0.57408 - val_acc: 0.7382 -- iter: 0960/2235
--
Training Step: 801  | total loss: [1m[32m0.35539[0m[0m | time: 38.892s
[2K
| RMSProp | epoch: 012 | loss: 0.35539 - acc: 0.8483 -- iter: 0992/2235
[A[ATraining Step: 802  | total loss: [1m[32m0.37108[0m[0m | time: 40.157s
[2K
| RMSProp | epoch: 012 | loss: 0.37108 - acc: 0.8416 -- iter: 1024/2235
[A[ATraining Step: 803  | total loss: [1m[32m0.39956[0m[0m | time: 41.357s
[2K
| RMSProp | epoch: 012 | loss: 0.39956 - acc: 0.8168 -- iter: 1056/2235
[A[ATraining Step: 804  | total loss: [1m[32m0.38176[0m[0m | time: 42.595s
[2K
| RMSProp | epoch: 012 | loss: 0.38176 - acc: 0.8320 -- iter: 1088/2235
[A[ATraining Step: 805  | total loss: [1m[32m0.38394[0m[0m | time: 43.879s
[2K
| RMSProp | epoch: 012 | loss: 0.38394 - acc: 0.8332 -- iter: 1120/2235
[A[ATraining Step: 806  | total loss: [1m[32m0.37391[0m[0m | time: 45.239s
[2K
| RMSProp | epoch: 012 | loss: 0.37391 - acc: 0.8405 -- iter: 1152/2235
[A[ATraining Step: 807  | total loss: [1m[32m0.36836[0m[0m | time: 46.631s
[2K
| RMSProp | epoch: 012 | loss: 0.36836 - acc: 0.8440 -- iter: 1184/2235
[A[ATraining Step: 808  | total loss: [1m[32m0.36040[0m[0m | time: 47.727s
[2K
| RMSProp | epoch: 012 | loss: 0.36040 - acc: 0.8502 -- iter: 1216/2235
[A[ATraining Step: 809  | total loss: [1m[32m0.35777[0m[0m | time: 48.953s
[2K
| RMSProp | epoch: 012 | loss: 0.35777 - acc: 0.8527 -- iter: 1248/2235
[A[ATraining Step: 810  | total loss: [1m[32m0.36254[0m[0m | time: 50.229s
[2K
| RMSProp | epoch: 012 | loss: 0.36254 - acc: 0.8487 -- iter: 1280/2235
[A[ATraining Step: 811  | total loss: [1m[32m0.37624[0m[0m | time: 51.434s
[2K
| RMSProp | epoch: 012 | loss: 0.37624 - acc: 0.8450 -- iter: 1312/2235
[A[ATraining Step: 812  | total loss: [1m[32m0.37617[0m[0m | time: 52.491s
[2K
| RMSProp | epoch: 012 | loss: 0.37617 - acc: 0.8449 -- iter: 1344/2235
[A[ATraining Step: 813  | total loss: [1m[32m0.36916[0m[0m | time: 53.741s
[2K
| RMSProp | epoch: 012 | loss: 0.36916 - acc: 0.8510 -- iter: 1376/2235
[A[ATraining Step: 814  | total loss: [1m[32m0.37296[0m[0m | time: 55.029s
[2K
| RMSProp | epoch: 012 | loss: 0.37296 - acc: 0.8472 -- iter: 1408/2235
[A[ATraining Step: 815  | total loss: [1m[32m0.37608[0m[0m | time: 56.347s
[2K
| RMSProp | epoch: 012 | loss: 0.37608 - acc: 0.8437 -- iter: 1440/2235
[A[ATraining Step: 816  | total loss: [1m[32m0.35419[0m[0m | time: 57.510s
[2K
| RMSProp | epoch: 012 | loss: 0.35419 - acc: 0.8531 -- iter: 1472/2235
[A[ATraining Step: 817  | total loss: [1m[32m0.35489[0m[0m | time: 58.976s
[2K
| RMSProp | epoch: 012 | loss: 0.35489 - acc: 0.8553 -- iter: 1504/2235
[A[ATraining Step: 818  | total loss: [1m[32m0.35229[0m[0m | time: 60.301s
[2K
| RMSProp | epoch: 012 | loss: 0.35229 - acc: 0.8510 -- iter: 1536/2235
[A[ATraining Step: 819  | total loss: [1m[32m0.34330[0m[0m | time: 61.752s
[2K
| RMSProp | epoch: 012 | loss: 0.34330 - acc: 0.8534 -- iter: 1568/2235
[A[ATraining Step: 820  | total loss: [1m[32m0.38036[0m[0m | time: 63.187s
[2K
| RMSProp | epoch: 012 | loss: 0.38036 - acc: 0.8462 -- iter: 1600/2235
[A[ATraining Step: 821  | total loss: [1m[32m0.38353[0m[0m | time: 64.386s
[2K
| RMSProp | epoch: 012 | loss: 0.38353 - acc: 0.8397 -- iter: 1632/2235
[A[ATraining Step: 822  | total loss: [1m[32m0.37224[0m[0m | time: 65.513s
[2K
| RMSProp | epoch: 012 | loss: 0.37224 - acc: 0.8464 -- iter: 1664/2235
[A[ATraining Step: 823  | total loss: [1m[32m0.35529[0m[0m | time: 66.655s
[2K
| RMSProp | epoch: 012 | loss: 0.35529 - acc: 0.8523 -- iter: 1696/2235
[A[ATraining Step: 824  | total loss: [1m[32m0.33407[0m[0m | time: 67.921s
[2K
| RMSProp | epoch: 012 | loss: 0.33407 - acc: 0.8640 -- iter: 1728/2235
[A[ATraining Step: 825  | total loss: [1m[32m0.32854[0m[0m | time: 69.129s
[2K
| RMSProp | epoch: 012 | loss: 0.32854 - acc: 0.8713 -- iter: 1760/2235
[A[ATraining Step: 826  | total loss: [1m[32m0.32493[0m[0m | time: 70.348s
[2K
| RMSProp | epoch: 012 | loss: 0.32493 - acc: 0.8717 -- iter: 1792/2235
[A[ATraining Step: 827  | total loss: [1m[32m0.34862[0m[0m | time: 71.727s
[2K
| RMSProp | epoch: 012 | loss: 0.34862 - acc: 0.8595 -- iter: 1824/2235
[A[ATraining Step: 828  | total loss: [1m[32m0.33074[0m[0m | time: 73.101s
[2K
| RMSProp | epoch: 012 | loss: 0.33074 - acc: 0.8705 -- iter: 1856/2235
[A[ATraining Step: 829  | total loss: [1m[32m0.32188[0m[0m | time: 74.478s
[2K
| RMSProp | epoch: 012 | loss: 0.32188 - acc: 0.8709 -- iter: 1888/2235
[A[ATraining Step: 830  | total loss: [1m[32m0.30160[0m[0m | time: 75.466s
[2K
| RMSProp | epoch: 012 | loss: 0.30160 - acc: 0.8838 -- iter: 1920/2235
[A[ATraining Step: 831  | total loss: [1m[32m0.28855[0m[0m | time: 76.800s
[2K
| RMSProp | epoch: 012 | loss: 0.28855 - acc: 0.8892 -- iter: 1952/2235
[A[ATraining Step: 832  | total loss: [1m[32m0.28087[0m[0m | time: 78.186s
[2K
| RMSProp | epoch: 012 | loss: 0.28087 - acc: 0.8909 -- iter: 1984/2235
[A[ATraining Step: 833  | total loss: [1m[32m0.28722[0m[0m | time: 79.503s
[2K
| RMSProp | epoch: 012 | loss: 0.28722 - acc: 0.8862 -- iter: 2016/2235
[A[ATraining Step: 834  | total loss: [1m[32m0.30657[0m[0m | time: 80.405s
[2K
| RMSProp | epoch: 012 | loss: 0.30657 - acc: 0.8788 -- iter: 2048/2235
[A[ATraining Step: 835  | total loss: [1m[32m0.30110[0m[0m | time: 81.563s
[2K
| RMSProp | epoch: 012 | loss: 0.30110 - acc: 0.8816 -- iter: 2080/2235
[A[ATraining Step: 836  | total loss: [1m[32m0.30554[0m[0m | time: 82.786s
[2K
| RMSProp | epoch: 012 | loss: 0.30554 - acc: 0.8809 -- iter: 2112/2235
[A[ATraining Step: 837  | total loss: [1m[32m0.29308[0m[0m | time: 84.040s
[2K
| RMSProp | epoch: 012 | loss: 0.29308 - acc: 0.8897 -- iter: 2144/2235
[A[ATraining Step: 838  | total loss: [1m[32m0.27942[0m[0m | time: 85.350s
[2K
| RMSProp | epoch: 012 | loss: 0.27942 - acc: 0.8976 -- iter: 2176/2235
[A[ATraining Step: 839  | total loss: [1m[32m0.26130[0m[0m | time: 86.595s
[2K
| RMSProp | epoch: 012 | loss: 0.26130 - acc: 0.9047 -- iter: 2208/2235
[A[ATraining Step: 840  | total loss: [1m[32m0.26212[0m[0m | time: 93.555s
[2K
| RMSProp | epoch: 012 | loss: 0.26212 - acc: 0.9049 | val_loss: 0.66856 - val_acc: 0.7167 -- iter: 2235/2235
--
Training Step: 841  | total loss: [1m[32m0.25088[0m[0m | time: 1.142s
[2K
| RMSProp | epoch: 013 | loss: 0.25088 - acc: 0.9112 -- iter: 0032/2235
[A[ATraining Step: 842  | total loss: [1m[32m0.25780[0m[0m | time: 2.260s
[2K
| RMSProp | epoch: 013 | loss: 0.25780 - acc: 0.9076 -- iter: 0064/2235
[A[ATraining Step: 843  | total loss: [1m[32m0.26173[0m[0m | time: 3.414s
[2K
| RMSProp | epoch: 013 | loss: 0.26173 - acc: 0.9012 -- iter: 0096/2235
[A[ATraining Step: 844  | total loss: [1m[32m0.27858[0m[0m | time: 4.627s
[2K
| RMSProp | epoch: 013 | loss: 0.27858 - acc: 0.8892 -- iter: 0128/2235
[A[ATraining Step: 845  | total loss: [1m[32m0.27027[0m[0m | time: 5.871s
[2K
| RMSProp | epoch: 013 | loss: 0.27027 - acc: 0.8909 -- iter: 0160/2235
[A[ATraining Step: 846  | total loss: [1m[32m0.28117[0m[0m | time: 7.128s
[2K
| RMSProp | epoch: 013 | loss: 0.28117 - acc: 0.8800 -- iter: 0192/2235
[A[ATraining Step: 847  | total loss: [1m[32m0.27313[0m[0m | time: 8.383s
[2K
| RMSProp | epoch: 013 | loss: 0.27313 - acc: 0.8888 -- iter: 0224/2235
[A[ATraining Step: 848  | total loss: [1m[32m0.26423[0m[0m | time: 9.670s
[2K
| RMSProp | epoch: 013 | loss: 0.26423 - acc: 0.8937 -- iter: 0256/2235
[A[ATraining Step: 849  | total loss: [1m[32m0.24869[0m[0m | time: 10.935s
[2K
| RMSProp | epoch: 013 | loss: 0.24869 - acc: 0.9043 -- iter: 0288/2235
[A[ATraining Step: 850  | total loss: [1m[32m0.24657[0m[0m | time: 12.401s
[2K
| RMSProp | epoch: 013 | loss: 0.24657 - acc: 0.9045 -- iter: 0320/2235
[A[ATraining Step: 851  | total loss: [1m[32m0.23656[0m[0m | time: 13.545s
[2K
| RMSProp | epoch: 013 | loss: 0.23656 - acc: 0.9110 -- iter: 0352/2235
[A[ATraining Step: 852  | total loss: [1m[32m0.23820[0m[0m | time: 14.442s
[2K
| RMSProp | epoch: 013 | loss: 0.23820 - acc: 0.9050 -- iter: 0384/2235
[A[ATraining Step: 853  | total loss: [1m[32m0.23815[0m[0m | time: 15.679s
[2K
| RMSProp | epoch: 013 | loss: 0.23815 - acc: 0.9034 -- iter: 0416/2235
[A[ATraining Step: 854  | total loss: [1m[32m0.25767[0m[0m | time: 17.077s
[2K
| RMSProp | epoch: 013 | loss: 0.25767 - acc: 0.9006 -- iter: 0448/2235
[A[ATraining Step: 855  | total loss: [1m[32m0.24937[0m[0m | time: 18.193s
[2K
| RMSProp | epoch: 013 | loss: 0.24937 - acc: 0.9043 -- iter: 0480/2235
[A[ATraining Step: 856  | total loss: [1m[32m0.26022[0m[0m | time: 19.250s
[2K
| RMSProp | epoch: 013 | loss: 0.26022 - acc: 0.9013 -- iter: 0512/2235
[A[ATraining Step: 857  | total loss: [1m[32m0.27367[0m[0m | time: 20.558s
[2K
| RMSProp | epoch: 013 | loss: 0.27367 - acc: 0.8987 -- iter: 0544/2235
[A[ATraining Step: 858  | total loss: [1m[32m0.28040[0m[0m | time: 21.760s
[2K
| RMSProp | epoch: 013 | loss: 0.28040 - acc: 0.8901 -- iter: 0576/2235
[A[ATraining Step: 859  | total loss: [1m[32m0.28081[0m[0m | time: 23.090s
[2K
| RMSProp | epoch: 013 | loss: 0.28081 - acc: 0.8886 -- iter: 0608/2235
[A[ATraining Step: 860  | total loss: [1m[32m0.26802[0m[0m | time: 24.430s
[2K
| RMSProp | epoch: 013 | loss: 0.26802 - acc: 0.8904 -- iter: 0640/2235
[A[ATraining Step: 861  | total loss: [1m[32m0.27483[0m[0m | time: 25.624s
[2K
| RMSProp | epoch: 013 | loss: 0.27483 - acc: 0.8826 -- iter: 0672/2235
[A[ATraining Step: 862  | total loss: [1m[32m0.26433[0m[0m | time: 26.975s
[2K
| RMSProp | epoch: 013 | loss: 0.26433 - acc: 0.8849 -- iter: 0704/2235
[A[ATraining Step: 863  | total loss: [1m[32m0.25236[0m[0m | time: 28.326s
[2K
| RMSProp | epoch: 013 | loss: 0.25236 - acc: 0.8964 -- iter: 0736/2235
[A[ATraining Step: 864  | total loss: [1m[32m0.27848[0m[0m | time: 29.308s
[2K
| RMSProp | epoch: 013 | loss: 0.27848 - acc: 0.8818 -- iter: 0768/2235
[A[ATraining Step: 865  | total loss: [1m[32m0.28492[0m[0m | time: 30.531s
[2K
| RMSProp | epoch: 013 | loss: 0.28492 - acc: 0.8780 -- iter: 0800/2235
[A[ATraining Step: 866  | total loss: [1m[32m0.28099[0m[0m | time: 31.825s
[2K
| RMSProp | epoch: 013 | loss: 0.28099 - acc: 0.8777 -- iter: 0832/2235
[A[ATraining Step: 867  | total loss: [1m[32m0.29810[0m[0m | time: 33.142s
[2K
| RMSProp | epoch: 013 | loss: 0.29810 - acc: 0.8743 -- iter: 0864/2235
[A[ATraining Step: 868  | total loss: [1m[32m0.28722[0m[0m | time: 34.218s
[2K
| RMSProp | epoch: 013 | loss: 0.28722 - acc: 0.8775 -- iter: 0896/2235
[A[ATraining Step: 869  | total loss: [1m[32m0.26609[0m[0m | time: 35.442s
[2K
| RMSProp | epoch: 013 | loss: 0.26609 - acc: 0.8897 -- iter: 0928/2235
[A[ATraining Step: 870  | total loss: [1m[32m0.25228[0m[0m | time: 36.743s
[2K
| RMSProp | epoch: 013 | loss: 0.25228 - acc: 0.8976 -- iter: 0960/2235
[A[ATraining Step: 871  | total loss: [1m[32m0.24923[0m[0m | time: 38.050s
[2K
| RMSProp | epoch: 013 | loss: 0.24923 - acc: 0.9016 -- iter: 0992/2235
[A[ATraining Step: 872  | total loss: [1m[32m0.25716[0m[0m | time: 39.251s
[2K
| RMSProp | epoch: 013 | loss: 0.25716 - acc: 0.8990 -- iter: 1024/2235
[A[ATraining Step: 873  | total loss: [1m[32m0.28497[0m[0m | time: 40.607s
[2K
| RMSProp | epoch: 013 | loss: 0.28497 - acc: 0.8872 -- iter: 1056/2235
[A[ATraining Step: 874  | total loss: [1m[32m0.30581[0m[0m | time: 41.961s
[2K
| RMSProp | epoch: 013 | loss: 0.30581 - acc: 0.8641 -- iter: 1088/2235
[A[ATraining Step: 875  | total loss: [1m[32m0.29170[0m[0m | time: 43.141s
[2K
| RMSProp | epoch: 013 | loss: 0.29170 - acc: 0.8714 -- iter: 1120/2235
[A[ATraining Step: 876  | total loss: [1m[32m0.29000[0m[0m | time: 44.352s
[2K
| RMSProp | epoch: 013 | loss: 0.29000 - acc: 0.8749 -- iter: 1152/2235
[A[ATraining Step: 877  | total loss: [1m[32m0.27828[0m[0m | time: 45.570s
[2K
| RMSProp | epoch: 013 | loss: 0.27828 - acc: 0.8812 -- iter: 1184/2235
[A[ATraining Step: 878  | total loss: [1m[32m0.28340[0m[0m | time: 46.843s
[2K
| RMSProp | epoch: 013 | loss: 0.28340 - acc: 0.8774 -- iter: 1216/2235
[A[ATraining Step: 879  | total loss: [1m[32m0.30504[0m[0m | time: 48.118s
[2K
| RMSProp | epoch: 013 | loss: 0.30504 - acc: 0.8741 -- iter: 1248/2235
[A[ATraining Step: 880  | total loss: [1m[32m0.34111[0m[0m | time: 49.360s
[2K
| RMSProp | epoch: 013 | loss: 0.34111 - acc: 0.8617 -- iter: 1280/2235
[A[ATraining Step: 881  | total loss: [1m[32m0.33459[0m[0m | time: 50.588s
[2K
| RMSProp | epoch: 013 | loss: 0.33459 - acc: 0.8630 -- iter: 1312/2235
[A[ATraining Step: 882  | total loss: [1m[32m0.31905[0m[0m | time: 51.879s
[2K
| RMSProp | epoch: 013 | loss: 0.31905 - acc: 0.8704 -- iter: 1344/2235
[A[ATraining Step: 883  | total loss: [1m[32m0.31729[0m[0m | time: 53.048s
[2K
| RMSProp | epoch: 013 | loss: 0.31729 - acc: 0.8709 -- iter: 1376/2235
[A[ATraining Step: 884  | total loss: [1m[32m0.31552[0m[0m | time: 54.374s
[2K
| RMSProp | epoch: 013 | loss: 0.31552 - acc: 0.8744 -- iter: 1408/2235
[A[ATraining Step: 885  | total loss: [1m[32m0.29327[0m[0m | time: 55.724s
[2K
| RMSProp | epoch: 013 | loss: 0.29327 - acc: 0.8839 -- iter: 1440/2235
[A[ATraining Step: 886  | total loss: [1m[32m0.28877[0m[0m | time: 56.967s
[2K
| RMSProp | epoch: 013 | loss: 0.28877 - acc: 0.8830 -- iter: 1472/2235
[A[ATraining Step: 887  | total loss: [1m[32m0.28558[0m[0m | time: 58.160s
[2K
| RMSProp | epoch: 013 | loss: 0.28558 - acc: 0.8884 -- iter: 1504/2235
[A[ATraining Step: 888  | total loss: [1m[32m0.27642[0m[0m | time: 59.409s
[2K
| RMSProp | epoch: 013 | loss: 0.27642 - acc: 0.8902 -- iter: 1536/2235
[A[ATraining Step: 889  | total loss: [1m[32m0.27010[0m[0m | time: 60.590s
[2K
| RMSProp | epoch: 013 | loss: 0.27010 - acc: 0.8981 -- iter: 1568/2235
[A[ATraining Step: 890  | total loss: [1m[32m0.27916[0m[0m | time: 61.762s
[2K
| RMSProp | epoch: 013 | loss: 0.27916 - acc: 0.8895 -- iter: 1600/2235
[A[ATraining Step: 891  | total loss: [1m[32m0.29673[0m[0m | time: 63.206s
[2K
| RMSProp | epoch: 013 | loss: 0.29673 - acc: 0.8756 -- iter: 1632/2235
[A[ATraining Step: 892  | total loss: [1m[32m0.27843[0m[0m | time: 64.771s
[2K
| RMSProp | epoch: 013 | loss: 0.27843 - acc: 0.8849 -- iter: 1664/2235
[A[ATraining Step: 893  | total loss: [1m[32m0.26496[0m[0m | time: 66.051s
[2K
| RMSProp | epoch: 013 | loss: 0.26496 - acc: 0.8870 -- iter: 1696/2235
[A[ATraining Step: 894  | total loss: [1m[32m0.25458[0m[0m | time: 67.208s
[2K
| RMSProp | epoch: 013 | loss: 0.25458 - acc: 0.8921 -- iter: 1728/2235
[A[ATraining Step: 895  | total loss: [1m[32m0.25848[0m[0m | time: 68.549s
[2K
| RMSProp | epoch: 013 | loss: 0.25848 - acc: 0.8935 -- iter: 1760/2235
[A[ATraining Step: 896  | total loss: [1m[32m0.24134[0m[0m | time: 69.916s
[2K
| RMSProp | epoch: 013 | loss: 0.24134 - acc: 0.9041 -- iter: 1792/2235
[A[ATraining Step: 897  | total loss: [1m[32m0.24301[0m[0m | time: 70.985s
[2K
| RMSProp | epoch: 013 | loss: 0.24301 - acc: 0.9075 -- iter: 1824/2235
[A[ATraining Step: 898  | total loss: [1m[32m0.25236[0m[0m | time: 72.202s
[2K
| RMSProp | epoch: 013 | loss: 0.25236 - acc: 0.9011 -- iter: 1856/2235
[A[ATraining Step: 899  | total loss: [1m[32m0.29564[0m[0m | time: 73.531s
[2K
| RMSProp | epoch: 013 | loss: 0.29564 - acc: 0.8797 -- iter: 1888/2235
[A[ATraining Step: 900  | total loss: [1m[32m0.27945[0m[0m | time: 74.817s
[2K
| RMSProp | epoch: 013 | loss: 0.27945 - acc: 0.8886 -- iter: 1920/2235
[A[ATraining Step: 901  | total loss: [1m[32m0.26240[0m[0m | time: 76.103s
[2K
| RMSProp | epoch: 013 | loss: 0.26240 - acc: 0.8998 -- iter: 1952/2235
[A[ATraining Step: 902  | total loss: [1m[32m0.24668[0m[0m | time: 77.416s
[2K
| RMSProp | epoch: 013 | loss: 0.24668 - acc: 0.9067 -- iter: 1984/2235
[A[ATraining Step: 903  | total loss: [1m[32m0.23921[0m[0m | time: 78.796s
[2K
| RMSProp | epoch: 013 | loss: 0.23921 - acc: 0.9098 -- iter: 2016/2235
[A[ATraining Step: 904  | total loss: [1m[32m0.22572[0m[0m | time: 80.231s
[2K
| RMSProp | epoch: 013 | loss: 0.22572 - acc: 0.9125 -- iter: 2048/2235
[A[ATraining Step: 905  | total loss: [1m[32m0.22848[0m[0m | time: 81.322s
[2K
| RMSProp | epoch: 013 | loss: 0.22848 - acc: 0.9119 -- iter: 2080/2235
[A[ATraining Step: 906  | total loss: [1m[32m0.24980[0m[0m | time: 82.596s
[2K
| RMSProp | epoch: 013 | loss: 0.24980 - acc: 0.8957 -- iter: 2112/2235
[A[ATraining Step: 907  | total loss: [1m[32m0.25459[0m[0m | time: 83.893s
[2K
| RMSProp | epoch: 013 | loss: 0.25459 - acc: 0.8968 -- iter: 2144/2235
[A[ATraining Step: 908  | total loss: [1m[32m0.25538[0m[0m | time: 85.230s
[2K
| RMSProp | epoch: 013 | loss: 0.25538 - acc: 0.8915 -- iter: 2176/2235
[A[ATraining Step: 909  | total loss: [1m[32m0.26941[0m[0m | time: 86.330s
[2K
| RMSProp | epoch: 013 | loss: 0.26941 - acc: 0.8867 -- iter: 2208/2235
[A[ATraining Step: 910  | total loss: [1m[32m0.27342[0m[0m | time: 93.237s
[2K
| RMSProp | epoch: 013 | loss: 0.27342 - acc: 0.8824 | val_loss: 0.67175 - val_acc: 0.7310 -- iter: 2235/2235
--
Training Step: 911  | total loss: [1m[32m0.26651[0m[0m | time: 1.384s
[2K
| RMSProp | epoch: 014 | loss: 0.26651 - acc: 0.8848 -- iter: 0032/2235
[A[ATraining Step: 912  | total loss: [1m[32m0.26158[0m[0m | time: 2.735s
[2K
| RMSProp | epoch: 014 | loss: 0.26158 - acc: 0.8838 -- iter: 0064/2235
[A[ATraining Step: 913  | total loss: [1m[32m0.24907[0m[0m | time: 4.095s
[2K
| RMSProp | epoch: 014 | loss: 0.24907 - acc: 0.8923 -- iter: 0096/2235
[A[ATraining Step: 914  | total loss: [1m[32m0.24760[0m[0m | time: 5.414s
[2K
| RMSProp | epoch: 014 | loss: 0.24760 - acc: 0.8999 -- iter: 0128/2235
[A[ATraining Step: 915  | total loss: [1m[32m0.24919[0m[0m | time: 6.607s
[2K
| RMSProp | epoch: 014 | loss: 0.24919 - acc: 0.8975 -- iter: 0160/2235
[A[ATraining Step: 916  | total loss: [1m[32m0.24297[0m[0m | time: 7.822s
[2K
| RMSProp | epoch: 014 | loss: 0.24297 - acc: 0.9046 -- iter: 0192/2235
[A[ATraining Step: 917  | total loss: [1m[32m0.23858[0m[0m | time: 9.057s
[2K
| RMSProp | epoch: 014 | loss: 0.23858 - acc: 0.9047 -- iter: 0224/2235
[A[ATraining Step: 918  | total loss: [1m[32m0.23244[0m[0m | time: 10.349s
[2K
| RMSProp | epoch: 014 | loss: 0.23244 - acc: 0.9080 -- iter: 0256/2235
[A[ATraining Step: 919  | total loss: [1m[32m0.23587[0m[0m | time: 11.553s
[2K
| RMSProp | epoch: 014 | loss: 0.23587 - acc: 0.9078 -- iter: 0288/2235
[A[ATraining Step: 920  | total loss: [1m[32m0.23404[0m[0m | time: 12.831s
[2K
| RMSProp | epoch: 014 | loss: 0.23404 - acc: 0.9077 -- iter: 0320/2235
[A[ATraining Step: 921  | total loss: [1m[32m0.22924[0m[0m | time: 14.248s
[2K
| RMSProp | epoch: 014 | loss: 0.22924 - acc: 0.9138 -- iter: 0352/2235
[A[ATraining Step: 922  | total loss: [1m[32m0.22192[0m[0m | time: 15.231s
[2K
| RMSProp | epoch: 014 | loss: 0.22192 - acc: 0.9162 -- iter: 0384/2235
[A[ATraining Step: 923  | total loss: [1m[32m0.20599[0m[0m | time: 16.355s
[2K
| RMSProp | epoch: 014 | loss: 0.20599 - acc: 0.9245 -- iter: 0416/2235
[A[ATraining Step: 924  | total loss: [1m[32m0.18749[0m[0m | time: 17.740s
[2K
| RMSProp | epoch: 014 | loss: 0.18749 - acc: 0.9321 -- iter: 0448/2235
[A[ATraining Step: 925  | total loss: [1m[32m0.17467[0m[0m | time: 19.155s
[2K
| RMSProp | epoch: 014 | loss: 0.17467 - acc: 0.9389 -- iter: 0480/2235
[A[ATraining Step: 926  | total loss: [1m[32m0.17033[0m[0m | time: 20.344s
[2K
| RMSProp | epoch: 014 | loss: 0.17033 - acc: 0.9419 -- iter: 0512/2235
[A[ATraining Step: 927  | total loss: [1m[32m0.17217[0m[0m | time: 21.353s
[2K
| RMSProp | epoch: 014 | loss: 0.17217 - acc: 0.9383 -- iter: 0544/2235
[A[ATraining Step: 928  | total loss: [1m[32m0.16300[0m[0m | time: 22.571s
[2K
| RMSProp | epoch: 014 | loss: 0.16300 - acc: 0.9445 -- iter: 0576/2235
[A[ATraining Step: 929  | total loss: [1m[32m0.16641[0m[0m | time: 23.730s
[2K
| RMSProp | epoch: 014 | loss: 0.16641 - acc: 0.9407 -- iter: 0608/2235
[A[ATraining Step: 930  | total loss: [1m[32m0.19260[0m[0m | time: 24.934s
[2K
| RMSProp | epoch: 014 | loss: 0.19260 - acc: 0.9372 -- iter: 0640/2235
[A[ATraining Step: 931  | total loss: [1m[32m0.22448[0m[0m | time: 26.183s
[2K
| RMSProp | epoch: 014 | loss: 0.22448 - acc: 0.9185 -- iter: 0672/2235
[A[ATraining Step: 932  | total loss: [1m[32m0.21701[0m[0m | time: 27.441s
[2K
| RMSProp | epoch: 014 | loss: 0.21701 - acc: 0.9204 -- iter: 0704/2235
[A[ATraining Step: 933  | total loss: [1m[32m0.21280[0m[0m | time: 28.693s
[2K
| RMSProp | epoch: 014 | loss: 0.21280 - acc: 0.9190 -- iter: 0736/2235
[A[ATraining Step: 934  | total loss: [1m[32m0.21324[0m[0m | time: 29.980s
[2K
| RMSProp | epoch: 014 | loss: 0.21324 - acc: 0.9208 -- iter: 0768/2235
[A[ATraining Step: 935  | total loss: [1m[32m0.23631[0m[0m | time: 31.126s
[2K
| RMSProp | epoch: 014 | loss: 0.23631 - acc: 0.9131 -- iter: 0800/2235
[A[ATraining Step: 936  | total loss: [1m[32m0.26117[0m[0m | time: 32.484s
[2K
| RMSProp | epoch: 014 | loss: 0.26117 - acc: 0.8999 -- iter: 0832/2235
[A[ATraining Step: 937  | total loss: [1m[32m0.27060[0m[0m | time: 33.984s
[2K
| RMSProp | epoch: 014 | loss: 0.27060 - acc: 0.8912 -- iter: 0864/2235
[A[ATraining Step: 938  | total loss: [1m[32m0.27514[0m[0m | time: 35.261s
[2K
| RMSProp | epoch: 014 | loss: 0.27514 - acc: 0.8864 -- iter: 0896/2235
[A[ATraining Step: 939  | total loss: [1m[32m0.27219[0m[0m | time: 36.267s
[2K
| RMSProp | epoch: 014 | loss: 0.27219 - acc: 0.8884 -- iter: 0928/2235
[A[ATraining Step: 940  | total loss: [1m[32m0.26404[0m[0m | time: 37.327s
[2K
| RMSProp | epoch: 014 | loss: 0.26404 - acc: 0.8902 -- iter: 0960/2235
[A[ATraining Step: 941  | total loss: [1m[32m0.26281[0m[0m | time: 38.589s
[2K
| RMSProp | epoch: 014 | loss: 0.26281 - acc: 0.8918 -- iter: 0992/2235
[A[ATraining Step: 942  | total loss: [1m[32m0.25160[0m[0m | time: 39.829s
[2K
| RMSProp | epoch: 014 | loss: 0.25160 - acc: 0.8964 -- iter: 1024/2235
[A[ATraining Step: 943  | total loss: [1m[32m0.26067[0m[0m | time: 41.045s
[2K
| RMSProp | epoch: 014 | loss: 0.26067 - acc: 0.8911 -- iter: 1056/2235
[A[ATraining Step: 944  | total loss: [1m[32m0.26445[0m[0m | time: 42.390s
[2K
| RMSProp | epoch: 014 | loss: 0.26445 - acc: 0.8895 -- iter: 1088/2235
[A[ATraining Step: 945  | total loss: [1m[32m0.25309[0m[0m | time: 43.692s
[2K
| RMSProp | epoch: 014 | loss: 0.25309 - acc: 0.8912 -- iter: 1120/2235
[A[ATraining Step: 946  | total loss: [1m[32m0.26458[0m[0m | time: 44.991s
[2K
| RMSProp | epoch: 014 | loss: 0.26458 - acc: 0.8927 -- iter: 1152/2235
[A[ATraining Step: 947  | total loss: [1m[32m0.25357[0m[0m | time: 46.171s
[2K
| RMSProp | epoch: 014 | loss: 0.25357 - acc: 0.9003 -- iter: 1184/2235
[A[ATraining Step: 948  | total loss: [1m[32m0.24382[0m[0m | time: 47.643s
[2K
| RMSProp | epoch: 014 | loss: 0.24382 - acc: 0.9040 -- iter: 1216/2235
[A[ATraining Step: 949  | total loss: [1m[32m0.29137[0m[0m | time: 49.011s
[2K
| RMSProp | epoch: 014 | loss: 0.29137 - acc: 0.8886 -- iter: 1248/2235
[A[ATraining Step: 950  | total loss: [1m[32m0.28700[0m[0m | time: 50.294s
[2K
| RMSProp | epoch: 014 | loss: 0.28700 - acc: 0.8935 -- iter: 1280/2235
[A[ATraining Step: 951  | total loss: [1m[32m0.26782[0m[0m | time: 55.525s
[2K
| RMSProp | epoch: 014 | loss: 0.26782 - acc: 0.9010 -- iter: 1312/2235
[A[ATraining Step: 952  | total loss: [1m[32m0.25687[0m[0m | time: 56.505s
[2K
| RMSProp | epoch: 014 | loss: 0.25687 - acc: 0.9078 -- iter: 1344/2235
[A[ATraining Step: 953  | total loss: [1m[32m0.25354[0m[0m | time: 57.762s
[2K
| RMSProp | epoch: 014 | loss: 0.25354 - acc: 0.9108 -- iter: 1376/2235
[A[ATraining Step: 954  | total loss: [1m[32m0.25332[0m[0m | time: 59.003s
[2K
| RMSProp | epoch: 014 | loss: 0.25332 - acc: 0.9072 -- iter: 1408/2235
[A[ATraining Step: 955  | total loss: [1m[32m0.25363[0m[0m | time: 60.244s
[2K
| RMSProp | epoch: 014 | loss: 0.25363 - acc: 0.9040 -- iter: 1440/2235
[A[ATraining Step: 956  | total loss: [1m[32m0.25349[0m[0m | time: 61.468s
[2K
| RMSProp | epoch: 014 | loss: 0.25349 - acc: 0.9011 -- iter: 1472/2235
[A[ATraining Step: 957  | total loss: [1m[32m0.25169[0m[0m | time: 62.876s
[2K
| RMSProp | epoch: 014 | loss: 0.25169 - acc: 0.9078 -- iter: 1504/2235
[A[ATraining Step: 958  | total loss: [1m[32m0.25021[0m[0m | time: 64.125s
[2K
| RMSProp | epoch: 014 | loss: 0.25021 - acc: 0.9077 -- iter: 1536/2235
[A[ATraining Step: 959  | total loss: [1m[32m0.28046[0m[0m | time: 65.360s
[2K
| RMSProp | epoch: 014 | loss: 0.28046 - acc: 0.8888 -- iter: 1568/2235
[A[ATraining Step: 960  | total loss: [1m[32m0.28088[0m[0m | time: 66.689s
[2K
| RMSProp | epoch: 014 | loss: 0.28088 - acc: 0.8874 -- iter: 1600/2235
[A[ATraining Step: 961  | total loss: [1m[32m0.27611[0m[0m | time: 68.094s
[2K
| RMSProp | epoch: 014 | loss: 0.27611 - acc: 0.8893 -- iter: 1632/2235
[A[ATraining Step: 962  | total loss: [1m[32m0.25958[0m[0m | time: 69.323s
[2K
| RMSProp | epoch: 014 | loss: 0.25958 - acc: 0.8972 -- iter: 1664/2235
[A[ATraining Step: 963  | total loss: [1m[32m0.24521[0m[0m | time: 70.584s
[2K
| RMSProp | epoch: 014 | loss: 0.24521 - acc: 0.9013 -- iter: 1696/2235
[A[ATraining Step: 964  | total loss: [1m[32m0.23778[0m[0m | time: 71.758s
[2K
| RMSProp | epoch: 014 | loss: 0.23778 - acc: 0.9049 -- iter: 1728/2235
[A[ATraining Step: 965  | total loss: [1m[32m0.22508[0m[0m | time: 72.969s
[2K
| RMSProp | epoch: 014 | loss: 0.22508 - acc: 0.9082 -- iter: 1760/2235
[A[ATraining Step: 966  | total loss: [1m[32m0.24580[0m[0m | time: 74.142s
[2K
| RMSProp | epoch: 014 | loss: 0.24580 - acc: 0.9048 -- iter: 1792/2235
[A[ATraining Step: 967  | total loss: [1m[32m0.26717[0m[0m | time: 75.434s
[2K
| RMSProp | epoch: 014 | loss: 0.26717 - acc: 0.8925 -- iter: 1824/2235
[A[ATraining Step: 968  | total loss: [1m[32m0.25244[0m[0m | time: 76.782s
[2K
| RMSProp | epoch: 014 | loss: 0.25244 - acc: 0.8970 -- iter: 1856/2235
[A[ATraining Step: 969  | total loss: [1m[32m0.25069[0m[0m | time: 78.083s
[2K
| RMSProp | epoch: 014 | loss: 0.25069 - acc: 0.8948 -- iter: 1888/2235
[A[ATraining Step: 970  | total loss: [1m[32m0.24575[0m[0m | time: 79.311s
[2K
| RMSProp | epoch: 014 | loss: 0.24575 - acc: 0.8959 -- iter: 1920/2235
[A[ATraining Step: 971  | total loss: [1m[32m0.24018[0m[0m | time: 80.661s
[2K
| RMSProp | epoch: 014 | loss: 0.24018 - acc: 0.9001 -- iter: 1952/2235
[A[ATraining Step: 972  | total loss: [1m[32m0.23075[0m[0m | time: 81.794s
[2K
| RMSProp | epoch: 014 | loss: 0.23075 - acc: 0.9038 -- iter: 1984/2235
[A[ATraining Step: 973  | total loss: [1m[32m0.22501[0m[0m | time: 82.881s
[2K
| RMSProp | epoch: 014 | loss: 0.22501 - acc: 0.9041 -- iter: 2016/2235
[A[ATraining Step: 974  | total loss: [1m[32m0.22367[0m[0m | time: 84.116s
[2K
| RMSProp | epoch: 014 | loss: 0.22367 - acc: 0.9074 -- iter: 2048/2235
[A[ATraining Step: 975  | total loss: [1m[32m0.22145[0m[0m | time: 85.443s
[2K
| RMSProp | epoch: 014 | loss: 0.22145 - acc: 0.9042 -- iter: 2080/2235
[A[ATraining Step: 976  | total loss: [1m[32m0.23538[0m[0m | time: 86.781s
[2K
| RMSProp | epoch: 014 | loss: 0.23538 - acc: 0.9044 -- iter: 2112/2235
[A[ATraining Step: 977  | total loss: [1m[32m0.22774[0m[0m | time: 87.759s
[2K
| RMSProp | epoch: 014 | loss: 0.22774 - acc: 0.9046 -- iter: 2144/2235
[A[ATraining Step: 978  | total loss: [1m[32m0.23072[0m[0m | time: 88.872s
[2K
| RMSProp | epoch: 014 | loss: 0.23072 - acc: 0.9079 -- iter: 2176/2235
[A[ATraining Step: 979  | total loss: [1m[32m0.22799[0m[0m | time: 90.175s
[2K
| RMSProp | epoch: 014 | loss: 0.22799 - acc: 0.9108 -- iter: 2208/2235
[A[ATraining Step: 980  | total loss: [1m[32m0.21812[0m[0m | time: 96.937s
[2K
| RMSProp | epoch: 014 | loss: 0.21812 - acc: 0.9135 | val_loss: 0.71662 - val_acc: 0.7482 -- iter: 2235/2235
--
Training Step: 981  | total loss: [1m[32m0.19996[0m[0m | time: 1.332s
[2K
| RMSProp | epoch: 015 | loss: 0.19996 - acc: 0.9221 -- iter: 0032/2235
[A[ATraining Step: 982  | total loss: [1m[32m0.20410[0m[0m | time: 2.793s
[2K
| RMSProp | epoch: 015 | loss: 0.20410 - acc: 0.9206 -- iter: 0064/2235
[A[ATraining Step: 983  | total loss: [1m[32m0.20397[0m[0m | time: 4.203s
[2K
| RMSProp | epoch: 015 | loss: 0.20397 - acc: 0.9191 -- iter: 0096/2235
[A[ATraining Step: 984  | total loss: [1m[32m0.19141[0m[0m | time: 5.319s
[2K
| RMSProp | epoch: 015 | loss: 0.19141 - acc: 0.9241 -- iter: 0128/2235
[A[ATraining Step: 985  | total loss: [1m[32m0.17999[0m[0m | time: 6.144s
[2K
| RMSProp | epoch: 015 | loss: 0.17999 - acc: 0.9286 -- iter: 0160/2235
[A[ATraining Step: 986  | total loss: [1m[32m0.16919[0m[0m | time: 7.157s
[2K
| RMSProp | epoch: 015 | loss: 0.16919 - acc: 0.9326 -- iter: 0192/2235
[A[ATraining Step: 987  | total loss: [1m[32m0.16527[0m[0m | time: 8.132s
[2K
| RMSProp | epoch: 015 | loss: 0.16527 - acc: 0.9331 -- iter: 0224/2235
[A[ATraining Step: 988  | total loss: [1m[32m0.16256[0m[0m | time: 9.099s
[2K
| RMSProp | epoch: 015 | loss: 0.16256 - acc: 0.9335 -- iter: 0256/2235
[A[ATraining Step: 989  | total loss: [1m[32m0.16797[0m[0m | time: 10.013s
[2K
| RMSProp | epoch: 015 | loss: 0.16797 - acc: 0.9339 -- iter: 0288/2235
[A[ATraining Step: 990  | total loss: [1m[32m0.15836[0m[0m | time: 11.044s
[2K
| RMSProp | epoch: 015 | loss: 0.15836 - acc: 0.9405 -- iter: 0320/2235
[A[ATraining Step: 991  | total loss: [1m[32m0.15104[0m[0m | time: 11.982s
[2K
| RMSProp | epoch: 015 | loss: 0.15104 - acc: 0.9433 -- iter: 0352/2235
[A[ATraining Step: 992  | total loss: [1m[32m0.16393[0m[0m | time: 12.932s
[2K
| RMSProp | epoch: 015 | loss: 0.16393 - acc: 0.9396 -- iter: 0384/2235
[A[ATraining Step: 993  | total loss: [1m[32m0.17826[0m[0m | time: 13.732s
[2K
| RMSProp | epoch: 015 | loss: 0.17826 - acc: 0.9332 -- iter: 0416/2235
[A[ATraining Step: 994  | total loss: [1m[32m0.19412[0m[0m | time: 14.717s
[2K
| RMSProp | epoch: 015 | loss: 0.19412 - acc: 0.9287 -- iter: 0448/2235
[A[ATraining Step: 995  | total loss: [1m[32m0.18261[0m[0m | time: 15.776s
[2K
| RMSProp | epoch: 015 | loss: 0.18261 - acc: 0.9322 -- iter: 0480/2235
[A[ATraining Step: 996  | total loss: [1m[32m0.17229[0m[0m | time: 16.488s
[2K
| RMSProp | epoch: 015 | loss: 0.17229 - acc: 0.9358 -- iter: 0512/2235
[A[ATraining Step: 997  | total loss: [1m[32m0.16877[0m[0m | time: 17.463s
[2K
| RMSProp | epoch: 015 | loss: 0.16877 - acc: 0.9391 -- iter: 0544/2235
[A[ATraining Step: 998  | total loss: [1m[32m0.16514[0m[0m | time: 18.412s
[2K
| RMSProp | epoch: 015 | loss: 0.16514 - acc: 0.9421 -- iter: 0576/2235
[A[ATraining Step: 999  | total loss: [1m[32m0.19556[0m[0m | time: 19.378s
[2K
| RMSProp | epoch: 015 | loss: 0.19556 - acc: 0.9322 -- iter: 0608/2235
[A[ATraining Step: 1000  | total loss: [1m[32m0.21245[0m[0m | time: 24.472s
[2K
| RMSProp | epoch: 015 | loss: 0.21245 - acc: 0.9265 | val_loss: 0.65873 - val_acc: 0.7654 -- iter: 0640/2235
--
Training Step: 1001  | total loss: [1m[32m0.19781[0m[0m | time: 25.535s
[2K
| RMSProp | epoch: 015 | loss: 0.19781 - acc: 0.9307 -- iter: 0672/2235
[A[ATraining Step: 1002  | total loss: [1m[32m0.19008[0m[0m | time: 26.292s
[2K
| RMSProp | epoch: 015 | loss: 0.19008 - acc: 0.9314 -- iter: 0704/2235
[A[ATraining Step: 1003  | total loss: [1m[32m0.18015[0m[0m | time: 27.151s
[2K
| RMSProp | epoch: 015 | loss: 0.18015 - acc: 0.9352 -- iter: 0736/2235
[A[ATraining Step: 1004  | total loss: [1m[32m0.16936[0m[0m | time: 28.134s
[2K
| RMSProp | epoch: 015 | loss: 0.16936 - acc: 0.9416 -- iter: 0768/2235
[A[ATraining Step: 1005  | total loss: [1m[32m0.17366[0m[0m | time: 29.112s
[2K
| RMSProp | epoch: 015 | loss: 0.17366 - acc: 0.9412 -- iter: 0800/2235
[A[ATraining Step: 1006  | total loss: [1m[32m0.17950[0m[0m | time: 30.004s
[2K
| RMSProp | epoch: 015 | loss: 0.17950 - acc: 0.9409 -- iter: 0832/2235
[A[ATraining Step: 1007  | total loss: [1m[32m0.19389[0m[0m | time: 30.947s
[2K
| RMSProp | epoch: 015 | loss: 0.19389 - acc: 0.9374 -- iter: 0864/2235
[A[ATraining Step: 1008  | total loss: [1m[32m0.18996[0m[0m | time: 31.933s
[2K
| RMSProp | epoch: 015 | loss: 0.18996 - acc: 0.9374 -- iter: 0896/2235
[A[ATraining Step: 1009  | total loss: [1m[32m0.17827[0m[0m | time: 32.936s
[2K
| RMSProp | epoch: 015 | loss: 0.17827 - acc: 0.9405 -- iter: 0928/2235
[A[ATraining Step: 1010  | total loss: [1m[32m0.16464[0m[0m | time: 33.915s
[2K
| RMSProp | epoch: 015 | loss: 0.16464 - acc: 0.9465 -- iter: 0960/2235
[A[ATraining Step: 1011  | total loss: [1m[32m0.16483[0m[0m | time: 35.092s
[2K
| RMSProp | epoch: 015 | loss: 0.16483 - acc: 0.9425 -- iter: 0992/2235
[A[ATraining Step: 1012  | total loss: [1m[32m0.19020[0m[0m | time: 36.218s
[2K
| RMSProp | epoch: 015 | loss: 0.19020 - acc: 0.9326 -- iter: 1024/2235
[A[ATraining Step: 1013  | total loss: [1m[32m0.18070[0m[0m | time: 36.987s
[2K
| RMSProp | epoch: 015 | loss: 0.18070 - acc: 0.9362 -- iter: 1056/2235
[A[ATraining Step: 1014  | total loss: [1m[32m0.17776[0m[0m | time: 37.957s
[2K
| RMSProp | epoch: 015 | loss: 0.17776 - acc: 0.9363 -- iter: 1088/2235
[A[ATraining Step: 1015  | total loss: [1m[32m0.18819[0m[0m | time: 38.944s
[2K
| RMSProp | epoch: 015 | loss: 0.18819 - acc: 0.9365 -- iter: 1120/2235
[A[ATraining Step: 1016  | total loss: [1m[32m0.18282[0m[0m | time: 39.961s
[2K
| RMSProp | epoch: 015 | loss: 0.18282 - acc: 0.9397 -- iter: 1152/2235
[A[ATraining Step: 1017  | total loss: [1m[32m0.17178[0m[0m | time: 40.991s
[2K
| RMSProp | epoch: 015 | loss: 0.17178 - acc: 0.9426 -- iter: 1184/2235
[A[ATraining Step: 1018  | total loss: [1m[32m0.15938[0m[0m | time: 42.051s
[2K
| RMSProp | epoch: 015 | loss: 0.15938 - acc: 0.9483 -- iter: 1216/2235
[A[ATraining Step: 1019  | total loss: [1m[32m0.15539[0m[0m | time: 43.454s
[2K
| RMSProp | epoch: 015 | loss: 0.15539 - acc: 0.9472 -- iter: 1248/2235
[A[ATraining Step: 1020  | total loss: [1m[32m0.18104[0m[0m | time: 44.572s
[2K
| RMSProp | epoch: 015 | loss: 0.18104 - acc: 0.9400 -- iter: 1280/2235
[A[ATraining Step: 1021  | total loss: [1m[32m0.16932[0m[0m | time: 45.807s
[2K
| RMSProp | epoch: 015 | loss: 0.16932 - acc: 0.9460 -- iter: 1312/2235
[A[ATraining Step: 1022  | total loss: [1m[32m0.16920[0m[0m | time: 47.110s
[2K
| RMSProp | epoch: 015 | loss: 0.16920 - acc: 0.9452 -- iter: 1344/2235
[A[ATraining Step: 1023  | total loss: [1m[32m0.18302[0m[0m | time: 48.317s
[2K
| RMSProp | epoch: 015 | loss: 0.18302 - acc: 0.9413 -- iter: 1376/2235
[A[ATraining Step: 1024  | total loss: [1m[32m0.19664[0m[0m | time: 49.363s
[2K
| RMSProp | epoch: 015 | loss: 0.19664 - acc: 0.9284 -- iter: 1408/2235
[A[ATraining Step: 1025  | total loss: [1m[32m0.19143[0m[0m | time: 50.540s
[2K
| RMSProp | epoch: 015 | loss: 0.19143 - acc: 0.9324 -- iter: 1440/2235
[A[ATraining Step: 1026  | total loss: [1m[32m0.19288[0m[0m | time: 51.802s
[2K
| RMSProp | epoch: 015 | loss: 0.19288 - acc: 0.9298 -- iter: 1472/2235
[A[ATraining Step: 1027  | total loss: [1m[32m0.17851[0m[0m | time: 53.107s
[2K
| RMSProp | epoch: 015 | loss: 0.17851 - acc: 0.9368 -- iter: 1504/2235
[A[ATraining Step: 1028  | total loss: [1m[32m0.16713[0m[0m | time: 54.391s
[2K
| RMSProp | epoch: 015 | loss: 0.16713 - acc: 0.9400 -- iter: 1536/2235
[A[ATraining Step: 1029  | total loss: [1m[32m0.17479[0m[0m | time: 55.490s
[2K
| RMSProp | epoch: 015 | loss: 0.17479 - acc: 0.9335 -- iter: 1568/2235
[A[ATraining Step: 1030  | total loss: [1m[32m0.17178[0m[0m | time: 56.765s
[2K
| RMSProp | epoch: 015 | loss: 0.17178 - acc: 0.9370 -- iter: 1600/2235
[A[ATraining Step: 1031  | total loss: [1m[32m0.16666[0m[0m | time: 57.979s
[2K
| RMSProp | epoch: 015 | loss: 0.16666 - acc: 0.9340 -- iter: 1632/2235
[A[ATraining Step: 1032  | total loss: [1m[32m0.15269[0m[0m | time: 59.250s
[2K
| RMSProp | epoch: 015 | loss: 0.15269 - acc: 0.9406 -- iter: 1664/2235
[A[ATraining Step: 1033  | total loss: [1m[32m0.13954[0m[0m | time: 60.485s
[2K
| RMSProp | epoch: 015 | loss: 0.13954 - acc: 0.9465 -- iter: 1696/2235
[A[ATraining Step: 1034  | total loss: [1m[32m0.12956[0m[0m | time: 61.838s
[2K
| RMSProp | epoch: 015 | loss: 0.12956 - acc: 0.9519 -- iter: 1728/2235
[A[ATraining Step: 1035  | total loss: [1m[32m0.12469[0m[0m | time: 63.166s
[2K
| RMSProp | epoch: 015 | loss: 0.12469 - acc: 0.9535 -- iter: 1760/2235
[A[ATraining Step: 1036  | total loss: [1m[32m0.12965[0m[0m | time: 64.363s
[2K
| RMSProp | epoch: 015 | loss: 0.12965 - acc: 0.9551 -- iter: 1792/2235
[A[ATraining Step: 1037  | total loss: [1m[32m0.12107[0m[0m | time: 65.512s
[2K
| RMSProp | epoch: 015 | loss: 0.12107 - acc: 0.9596 -- iter: 1824/2235
[A[ATraining Step: 1038  | total loss: [1m[32m0.12443[0m[0m | time: 66.742s
[2K
| RMSProp | epoch: 015 | loss: 0.12443 - acc: 0.9605 -- iter: 1856/2235
[A[ATraining Step: 1039  | total loss: [1m[32m0.11597[0m[0m | time: 68.176s
[2K
| RMSProp | epoch: 015 | loss: 0.11597 - acc: 0.9613 -- iter: 1888/2235
[A[ATraining Step: 1040  | total loss: [1m[32m0.11230[0m[0m | time: 69.280s
[2K
| RMSProp | epoch: 015 | loss: 0.11230 - acc: 0.9621 -- iter: 1920/2235
[A[ATraining Step: 1041  | total loss: [1m[32m0.13130[0m[0m | time: 70.431s
[2K
| RMSProp | epoch: 015 | loss: 0.13130 - acc: 0.9533 -- iter: 1952/2235
[A[ATraining Step: 1042  | total loss: [1m[32m0.13340[0m[0m | time: 71.616s
[2K
| RMSProp | epoch: 015 | loss: 0.13340 - acc: 0.9518 -- iter: 1984/2235
[A[ATraining Step: 1043  | total loss: [1m[32m0.12520[0m[0m | time: 72.865s
[2K
| RMSProp | epoch: 015 | loss: 0.12520 - acc: 0.9566 -- iter: 2016/2235
[A[ATraining Step: 1044  | total loss: [1m[32m0.13711[0m[0m | time: 74.085s
[2K
| RMSProp | epoch: 015 | loss: 0.13711 - acc: 0.9547 -- iter: 2048/2235
[A[ATraining Step: 1045  | total loss: [1m[32m0.13319[0m[0m | time: 75.401s
[2K
| RMSProp | epoch: 015 | loss: 0.13319 - acc: 0.9561 -- iter: 2080/2235
[A[ATraining Step: 1046  | total loss: [1m[32m0.15966[0m[0m | time: 76.723s
[2K
| RMSProp | epoch: 015 | loss: 0.15966 - acc: 0.9480 -- iter: 2112/2235
[A[ATraining Step: 1047  | total loss: [1m[32m0.15135[0m[0m | time: 78.080s
[2K
| RMSProp | epoch: 015 | loss: 0.15135 - acc: 0.9501 -- iter: 2144/2235
[A[ATraining Step: 1048  | total loss: [1m[32m0.16662[0m[0m | time: 79.366s
[2K
| RMSProp | epoch: 015 | loss: 0.16662 - acc: 0.9488 -- iter: 2176/2235
[A[ATraining Step: 1049  | total loss: [1m[32m0.22062[0m[0m | time: 80.510s
[2K
| RMSProp | epoch: 015 | loss: 0.22062 - acc: 0.9258 -- iter: 2208/2235
[A[ATraining Step: 1050  | total loss: [1m[32m0.20981[0m[0m | time: 86.851s
[2K
| RMSProp | epoch: 015 | loss: 0.20981 - acc: 0.9332 | val_loss: 0.84860 - val_acc: 0.7511 -- iter: 2235/2235
--
Training Step: 1051  | total loss: [1m[32m0.20225[0m[0m | time: 1.306s
[2K
| RMSProp | epoch: 016 | loss: 0.20225 - acc: 0.9305 -- iter: 0032/2235
[A[ATraining Step: 1052  | total loss: [1m[32m0.24580[0m[0m | time: 2.611s
[2K
| RMSProp | epoch: 016 | loss: 0.24580 - acc: 0.9187 -- iter: 0064/2235
[A[ATraining Step: 1053  | total loss: [1m[32m0.24446[0m[0m | time: 3.988s
[2K
| RMSProp | epoch: 016 | loss: 0.24446 - acc: 0.9143 -- iter: 0096/2235
[A[ATraining Step: 1054  | total loss: [1m[32m0.23183[0m[0m | time: 5.374s
[2K
| RMSProp | epoch: 016 | loss: 0.23183 - acc: 0.9198 -- iter: 0128/2235
[A[ATraining Step: 1055  | total loss: [1m[32m0.21279[0m[0m | time: 6.739s
[2K
| RMSProp | epoch: 016 | loss: 0.21279 - acc: 0.9278 -- iter: 0160/2235
[A[ATraining Step: 1056  | total loss: [1m[32m0.19523[0m[0m | time: 8.028s
[2K
| RMSProp | epoch: 016 | loss: 0.19523 - acc: 0.9350 -- iter: 0192/2235
[A[ATraining Step: 1057  | total loss: [1m[32m0.19192[0m[0m | time: 9.376s
[2K
| RMSProp | epoch: 016 | loss: 0.19192 - acc: 0.9353 -- iter: 0224/2235
[A[ATraining Step: 1058  | total loss: [1m[32m0.17507[0m[0m | time: 10.459s
[2K
| RMSProp | epoch: 016 | loss: 0.17507 - acc: 0.9417 -- iter: 0256/2235
[A[ATraining Step: 1059  | total loss: [1m[32m0.16825[0m[0m | time: 11.604s
[2K
| RMSProp | epoch: 016 | loss: 0.16825 - acc: 0.9444 -- iter: 0288/2235
[A[ATraining Step: 1060  | total loss: [1m[32m0.16225[0m[0m | time: 12.827s
[2K
| RMSProp | epoch: 016 | loss: 0.16225 - acc: 0.9469 -- iter: 0320/2235
[A[ATraining Step: 1061  | total loss: [1m[32m0.16630[0m[0m | time: 14.058s
[2K
| RMSProp | epoch: 016 | loss: 0.16630 - acc: 0.9459 -- iter: 0352/2235
[A[ATraining Step: 1062  | total loss: [1m[32m0.15346[0m[0m | time: 15.307s
[2K
| RMSProp | epoch: 016 | loss: 0.15346 - acc: 0.9513 -- iter: 0384/2235
[A[ATraining Step: 1063  | total loss: [1m[32m0.14651[0m[0m | time: 16.590s
[2K
| RMSProp | epoch: 016 | loss: 0.14651 - acc: 0.9562 -- iter: 0416/2235
[A[ATraining Step: 1064  | total loss: [1m[32m0.13981[0m[0m | time: 17.744s
[2K
| RMSProp | epoch: 016 | loss: 0.13981 - acc: 0.9606 -- iter: 0448/2235
[A[ATraining Step: 1065  | total loss: [1m[32m0.13331[0m[0m | time: 18.963s
[2K
| RMSProp | epoch: 016 | loss: 0.13331 - acc: 0.9608 -- iter: 0480/2235
[A[ATraining Step: 1066  | total loss: [1m[32m0.12169[0m[0m | time: 20.269s
[2K
| RMSProp | epoch: 016 | loss: 0.12169 - acc: 0.9647 -- iter: 0512/2235
[A[ATraining Step: 1067  | total loss: [1m[32m0.11420[0m[0m | time: 21.563s
[2K
| RMSProp | epoch: 016 | loss: 0.11420 - acc: 0.9683 -- iter: 0544/2235
[A[ATraining Step: 1068  | total loss: [1m[32m0.11036[0m[0m | time: 22.960s
[2K
| RMSProp | epoch: 016 | loss: 0.11036 - acc: 0.9683 -- iter: 0576/2235
[A[ATraining Step: 1069  | total loss: [1m[32m0.13178[0m[0m | time: 24.331s
[2K
| RMSProp | epoch: 016 | loss: 0.13178 - acc: 0.9621 -- iter: 0608/2235
[A[ATraining Step: 1070  | total loss: [1m[32m0.17872[0m[0m | time: 25.434s
[2K
| RMSProp | epoch: 016 | loss: 0.17872 - acc: 0.9503 -- iter: 0640/2235
[A[ATraining Step: 1071  | total loss: [1m[32m0.18185[0m[0m | time: 26.634s
[2K
| RMSProp | epoch: 016 | loss: 0.18185 - acc: 0.9459 -- iter: 0672/2235
[A[ATraining Step: 1072  | total loss: [1m[32m0.16762[0m[0m | time: 27.912s
[2K
| RMSProp | epoch: 016 | loss: 0.16762 - acc: 0.9513 -- iter: 0704/2235
[A[ATraining Step: 1073  | total loss: [1m[32m0.15307[0m[0m | time: 29.195s
[2K
| RMSProp | epoch: 016 | loss: 0.15307 - acc: 0.9562 -- iter: 0736/2235
[A[ATraining Step: 1074  | total loss: [1m[32m0.15187[0m[0m | time: 30.434s
[2K
| RMSProp | epoch: 016 | loss: 0.15187 - acc: 0.9574 -- iter: 0768/2235
[A[ATraining Step: 1075  | total loss: [1m[32m0.18254[0m[0m | time: 31.778s
[2K
| RMSProp | epoch: 016 | loss: 0.18254 - acc: 0.9492 -- iter: 0800/2235
[A[ATraining Step: 1076  | total loss: [1m[32m0.17710[0m[0m | time: 33.177s
[2K
| RMSProp | epoch: 016 | loss: 0.17710 - acc: 0.9511 -- iter: 0832/2235
[A[ATraining Step: 1077  | total loss: [1m[32m0.16429[0m[0m | time: 34.530s
[2K
| RMSProp | epoch: 016 | loss: 0.16429 - acc: 0.9560 -- iter: 0864/2235
[A[ATraining Step: 1078  | total loss: [1m[32m0.15860[0m[0m | time: 35.698s
[2K
| RMSProp | epoch: 016 | loss: 0.15860 - acc: 0.9573 -- iter: 0896/2235
[A[ATraining Step: 1079  | total loss: [1m[32m0.16046[0m[0m | time: 36.986s
[2K
| RMSProp | epoch: 016 | loss: 0.16046 - acc: 0.9553 -- iter: 0928/2235
[A[ATraining Step: 1080  | total loss: [1m[32m0.14666[0m[0m | time: 38.431s
[2K
| RMSProp | epoch: 016 | loss: 0.14666 - acc: 0.9598 -- iter: 0960/2235
[A[ATraining Step: 1081  | total loss: [1m[32m0.15548[0m[0m | time: 39.732s
[2K
| RMSProp | epoch: 016 | loss: 0.15548 - acc: 0.9576 -- iter: 0992/2235
[A[ATraining Step: 1082  | total loss: [1m[32m0.16099[0m[0m | time: 40.661s
[2K
| RMSProp | epoch: 016 | loss: 0.16099 - acc: 0.9524 -- iter: 1024/2235
[A[ATraining Step: 1083  | total loss: [1m[32m0.17022[0m[0m | time: 41.807s
[2K
| RMSProp | epoch: 016 | loss: 0.17022 - acc: 0.9509 -- iter: 1056/2235
[A[ATraining Step: 1084  | total loss: [1m[32m0.16604[0m[0m | time: 43.091s
[2K
| RMSProp | epoch: 016 | loss: 0.16604 - acc: 0.9527 -- iter: 1088/2235
[A[ATraining Step: 1085  | total loss: [1m[32m0.15674[0m[0m | time: 44.235s
[2K
| RMSProp | epoch: 016 | loss: 0.15674 - acc: 0.9543 -- iter: 1120/2235
[A[ATraining Step: 1086  | total loss: [1m[32m0.15146[0m[0m | time: 45.484s
[2K
| RMSProp | epoch: 016 | loss: 0.15146 - acc: 0.9558 -- iter: 1152/2235
[A[ATraining Step: 1087  | total loss: [1m[32m0.15704[0m[0m | time: 46.790s
[2K
| RMSProp | epoch: 016 | loss: 0.15704 - acc: 0.9539 -- iter: 1184/2235
[A[ATraining Step: 1088  | total loss: [1m[32m0.16309[0m[0m | time: 48.208s
[2K
| RMSProp | epoch: 016 | loss: 0.16309 - acc: 0.9492 -- iter: 1216/2235
[A[ATraining Step: 1089  | total loss: [1m[32m0.17046[0m[0m | time: 49.485s
[2K
| RMSProp | epoch: 016 | loss: 0.17046 - acc: 0.9449 -- iter: 1248/2235
[A[ATraining Step: 1090  | total loss: [1m[32m0.17024[0m[0m | time: 50.693s
[2K
| RMSProp | epoch: 016 | loss: 0.17024 - acc: 0.9410 -- iter: 1280/2235
[A[ATraining Step: 1091  | total loss: [1m[32m0.16464[0m[0m | time: 52.078s
[2K
| RMSProp | epoch: 016 | loss: 0.16464 - acc: 0.9438 -- iter: 1312/2235
[A[ATraining Step: 1092  | total loss: [1m[32m0.15667[0m[0m | time: 53.477s
[2K
| RMSProp | epoch: 016 | loss: 0.15667 - acc: 0.9463 -- iter: 1344/2235
[A[ATraining Step: 1093  | total loss: [1m[32m0.14930[0m[0m | time: 54.792s
[2K
| RMSProp | epoch: 016 | loss: 0.14930 - acc: 0.9485 -- iter: 1376/2235
[A[ATraining Step: 1094  | total loss: [1m[32m0.16071[0m[0m | time: 55.767s
[2K
| RMSProp | epoch: 016 | loss: 0.16071 - acc: 0.9443 -- iter: 1408/2235
[A[ATraining Step: 1095  | total loss: [1m[32m0.15571[0m[0m | time: 56.985s
[2K
| RMSProp | epoch: 016 | loss: 0.15571 - acc: 0.9436 -- iter: 1440/2235
[A[ATraining Step: 1096  | total loss: [1m[32m0.16705[0m[0m | time: 58.287s
[2K
| RMSProp | epoch: 016 | loss: 0.16705 - acc: 0.9399 -- iter: 1472/2235
[A[ATraining Step: 1097  | total loss: [1m[32m0.15749[0m[0m | time: 59.488s
[2K
| RMSProp | epoch: 016 | loss: 0.15749 - acc: 0.9428 -- iter: 1504/2235
[A[ATraining Step: 1098  | total loss: [1m[32m0.14975[0m[0m | time: 60.834s
[2K
| RMSProp | epoch: 016 | loss: 0.14975 - acc: 0.9454 -- iter: 1536/2235
[A[ATraining Step: 1099  | total loss: [1m[32m0.14403[0m[0m | time: 62.303s
[2K
| RMSProp | epoch: 016 | loss: 0.14403 - acc: 0.9477 -- iter: 1568/2235
[A[ATraining Step: 1100  | total loss: [1m[32m0.14853[0m[0m | time: 63.688s
[2K
| RMSProp | epoch: 016 | loss: 0.14853 - acc: 0.9436 -- iter: 1600/2235
[A[ATraining Step: 1101  | total loss: [1m[32m0.16720[0m[0m | time: 64.975s
[2K
| RMSProp | epoch: 016 | loss: 0.16720 - acc: 0.9398 -- iter: 1632/2235
[A[ATraining Step: 1102  | total loss: [1m[32m0.15705[0m[0m | time: 66.419s
[2K
| RMSProp | epoch: 016 | loss: 0.15705 - acc: 0.9458 -- iter: 1664/2235
[A[ATraining Step: 1103  | total loss: [1m[32m0.14386[0m[0m | time: 67.837s
[2K
| RMSProp | epoch: 016 | loss: 0.14386 - acc: 0.9513 -- iter: 1696/2235
[A[ATraining Step: 1104  | total loss: [1m[32m0.17596[0m[0m | time: 69.053s
[2K
| RMSProp | epoch: 016 | loss: 0.17596 - acc: 0.9468 -- iter: 1728/2235
[A[ATraining Step: 1105  | total loss: [1m[32m0.16117[0m[0m | time: 70.293s
[2K
| RMSProp | epoch: 016 | loss: 0.16117 - acc: 0.9521 -- iter: 1760/2235
[A[ATraining Step: 1106  | total loss: [1m[32m0.15004[0m[0m | time: 71.352s
[2K
| RMSProp | epoch: 016 | loss: 0.15004 - acc: 0.9538 -- iter: 1792/2235
[A[ATraining Step: 1107  | total loss: [1m[32m0.13810[0m[0m | time: 72.576s
[2K
| RMSProp | epoch: 016 | loss: 0.13810 - acc: 0.9584 -- iter: 1824/2235
[A[ATraining Step: 1108  | total loss: [1m[32m0.12717[0m[0m | time: 73.716s
[2K
| RMSProp | epoch: 016 | loss: 0.12717 - acc: 0.9625 -- iter: 1856/2235
[A[ATraining Step: 1109  | total loss: [1m[32m0.11660[0m[0m | time: 74.919s
[2K
| RMSProp | epoch: 016 | loss: 0.11660 - acc: 0.9663 -- iter: 1888/2235
[A[ATraining Step: 1110  | total loss: [1m[32m0.11111[0m[0m | time: 76.104s
[2K
| RMSProp | epoch: 016 | loss: 0.11111 - acc: 0.9665 -- iter: 1920/2235
[A[ATraining Step: 1111  | total loss: [1m[32m0.12228[0m[0m | time: 77.428s
[2K
| RMSProp | epoch: 016 | loss: 0.12228 - acc: 0.9636 -- iter: 1952/2235
[A[ATraining Step: 1112  | total loss: [1m[32m0.13754[0m[0m | time: 78.635s
[2K
| RMSProp | epoch: 016 | loss: 0.13754 - acc: 0.9516 -- iter: 1984/2235
[A[ATraining Step: 1113  | total loss: [1m[32m0.13860[0m[0m | time: 79.992s
[2K
| RMSProp | epoch: 016 | loss: 0.13860 - acc: 0.9502 -- iter: 2016/2235
[A[ATraining Step: 1114  | total loss: [1m[32m0.13269[0m[0m | time: 81.335s
[2K
| RMSProp | epoch: 016 | loss: 0.13269 - acc: 0.9521 -- iter: 2048/2235
[A[ATraining Step: 1115  | total loss: [1m[32m0.12875[0m[0m | time: 82.602s
[2K
| RMSProp | epoch: 016 | loss: 0.12875 - acc: 0.9537 -- iter: 2080/2235
[A[ATraining Step: 1116  | total loss: [1m[32m0.11840[0m[0m | time: 83.762s
[2K
| RMSProp | epoch: 016 | loss: 0.11840 - acc: 0.9584 -- iter: 2112/2235
[A[ATraining Step: 1117  | total loss: [1m[32m0.10990[0m[0m | time: 84.988s
[2K
| RMSProp | epoch: 016 | loss: 0.10990 - acc: 0.9625 -- iter: 2144/2235
[A[ATraining Step: 1118  | total loss: [1m[32m0.10084[0m[0m | time: 86.345s
[2K
| RMSProp | epoch: 016 | loss: 0.10084 - acc: 0.9663 -- iter: 2176/2235
[A[ATraining Step: 1119  | total loss: [1m[32m0.10286[0m[0m | time: 87.416s
[2K
| RMSProp | epoch: 016 | loss: 0.10286 - acc: 0.9665 -- iter: 2208/2235
[A[ATraining Step: 1120  | total loss: [1m[32m0.09414[0m[0m | time: 93.953s
[2K
| RMSProp | epoch: 016 | loss: 0.09414 - acc: 0.9699 | val_loss: 0.94182 - val_acc: 0.7039 -- iter: 2235/2235
--
Training Step: 1121  | total loss: [1m[32m0.09739[0m[0m | time: 1.356s
[2K
| RMSProp | epoch: 017 | loss: 0.09739 - acc: 0.9698 -- iter: 0032/2235
[A[ATraining Step: 1122  | total loss: [1m[32m0.11310[0m[0m | time: 2.791s
[2K
| RMSProp | epoch: 017 | loss: 0.11310 - acc: 0.9665 -- iter: 0064/2235
[A[ATraining Step: 1123  | total loss: [1m[32m0.11934[0m[0m | time: 3.855s
[2K
| RMSProp | epoch: 017 | loss: 0.11934 - acc: 0.9668 -- iter: 0096/2235
[A[ATraining Step: 1124  | total loss: [1m[32m0.14101[0m[0m | time: 4.938s
[2K
| RMSProp | epoch: 017 | loss: 0.14101 - acc: 0.9607 -- iter: 0128/2235
[A[ATraining Step: 1125  | total loss: [1m[32m0.14496[0m[0m | time: 6.402s
[2K
| RMSProp | epoch: 017 | loss: 0.14496 - acc: 0.9584 -- iter: 0160/2235
[A[ATraining Step: 1126  | total loss: [1m[32m0.13699[0m[0m | time: 7.847s
[2K
| RMSProp | epoch: 017 | loss: 0.13699 - acc: 0.9625 -- iter: 0192/2235
[A[ATraining Step: 1127  | total loss: [1m[32m0.13378[0m[0m | time: 9.094s
[2K
| RMSProp | epoch: 017 | loss: 0.13378 - acc: 0.9600 -- iter: 0224/2235
[A[ATraining Step: 1128  | total loss: [1m[32m0.15050[0m[0m | time: 10.288s
[2K
| RMSProp | epoch: 017 | loss: 0.15050 - acc: 0.9515 -- iter: 0256/2235
[A[ATraining Step: 1129  | total loss: [1m[32m0.14332[0m[0m | time: 11.607s
[2K
| RMSProp | epoch: 017 | loss: 0.14332 - acc: 0.9533 -- iter: 0288/2235
[A[ATraining Step: 1130  | total loss: [1m[32m0.13464[0m[0m | time: 12.888s
[2K
| RMSProp | epoch: 017 | loss: 0.13464 - acc: 0.9548 -- iter: 0320/2235
[A[ATraining Step: 1131  | total loss: [1m[32m0.13007[0m[0m | time: 14.203s
[2K
| RMSProp | epoch: 017 | loss: 0.13007 - acc: 0.9593 -- iter: 0352/2235
[A[ATraining Step: 1132  | total loss: [1m[32m0.12546[0m[0m | time: 15.557s
[2K
| RMSProp | epoch: 017 | loss: 0.12546 - acc: 0.9603 -- iter: 0384/2235
[A[ATraining Step: 1133  | total loss: [1m[32m0.11613[0m[0m | time: 16.965s
[2K
| RMSProp | epoch: 017 | loss: 0.11613 - acc: 0.9611 -- iter: 0416/2235
[A[ATraining Step: 1134  | total loss: [1m[32m0.10791[0m[0m | time: 18.029s
[2K
| RMSProp | epoch: 017 | loss: 0.10791 - acc: 0.9650 -- iter: 0448/2235
[A[ATraining Step: 1135  | total loss: [1m[32m0.09993[0m[0m | time: 19.136s
[2K
| RMSProp | epoch: 017 | loss: 0.09993 - acc: 0.9685 -- iter: 0480/2235
[A[ATraining Step: 1136  | total loss: [1m[32m0.10517[0m[0m | time: 20.202s
[2K
| RMSProp | epoch: 017 | loss: 0.10517 - acc: 0.9680 -- iter: 0512/2235
[A[ATraining Step: 1137  | total loss: [1m[32m0.09593[0m[0m | time: 21.412s
[2K
| RMSProp | epoch: 017 | loss: 0.09593 - acc: 0.9712 -- iter: 0544/2235
[A[ATraining Step: 1138  | total loss: [1m[32m0.08948[0m[0m | time: 22.787s
[2K
| RMSProp | epoch: 017 | loss: 0.08948 - acc: 0.9740 -- iter: 0576/2235
[A[ATraining Step: 1139  | total loss: [1m[32m0.08206[0m[0m | time: 24.147s
[2K
| RMSProp | epoch: 017 | loss: 0.08206 - acc: 0.9766 -- iter: 0608/2235
[A[ATraining Step: 1140  | total loss: [1m[32m0.08799[0m[0m | time: 25.368s
[2K
| RMSProp | epoch: 017 | loss: 0.08799 - acc: 0.9758 -- iter: 0640/2235
[A[ATraining Step: 1141  | total loss: [1m[32m0.09834[0m[0m | time: 26.592s
[2K
| RMSProp | epoch: 017 | loss: 0.09834 - acc: 0.9720 -- iter: 0672/2235
[A[ATraining Step: 1142  | total loss: [1m[32m0.10683[0m[0m | time: 27.919s
[2K
| RMSProp | epoch: 017 | loss: 0.10683 - acc: 0.9717 -- iter: 0704/2235
[A[ATraining Step: 1143  | total loss: [1m[32m0.11243[0m[0m | time: 29.227s
[2K
| RMSProp | epoch: 017 | loss: 0.11243 - acc: 0.9714 -- iter: 0736/2235
[A[ATraining Step: 1144  | total loss: [1m[32m0.10323[0m[0m | time: 30.641s
[2K
| RMSProp | epoch: 017 | loss: 0.10323 - acc: 0.9743 -- iter: 0768/2235
[A[ATraining Step: 1145  | total loss: [1m[32m0.10593[0m[0m | time: 31.745s
[2K
| RMSProp | epoch: 017 | loss: 0.10593 - acc: 0.9706 -- iter: 0800/2235
[A[ATraining Step: 1146  | total loss: [1m[32m0.10454[0m[0m | time: 32.895s
[2K
| RMSProp | epoch: 017 | loss: 0.10454 - acc: 0.9673 -- iter: 0832/2235
[A[ATraining Step: 1147  | total loss: [1m[32m0.10534[0m[0m | time: 34.161s
[2K
| RMSProp | epoch: 017 | loss: 0.10534 - acc: 0.9643 -- iter: 0864/2235
[A[ATraining Step: 1148  | total loss: [1m[32m0.10880[0m[0m | time: 35.256s
[2K
| RMSProp | epoch: 017 | loss: 0.10880 - acc: 0.9647 -- iter: 0896/2235
[A[ATraining Step: 1149  | total loss: [1m[32m0.11797[0m[0m | time: 36.413s
[2K
| RMSProp | epoch: 017 | loss: 0.11797 - acc: 0.9620 -- iter: 0928/2235
[A[ATraining Step: 1150  | total loss: [1m[32m0.12768[0m[0m | time: 37.913s
[2K
| RMSProp | epoch: 017 | loss: 0.12768 - acc: 0.9596 -- iter: 0960/2235
[A[ATraining Step: 1151  | total loss: [1m[32m0.13082[0m[0m | time: 39.307s
[2K
| RMSProp | epoch: 017 | loss: 0.13082 - acc: 0.9574 -- iter: 0992/2235
[A[ATraining Step: 1152  | total loss: [1m[32m0.14516[0m[0m | time: 40.558s
[2K
| RMSProp | epoch: 017 | loss: 0.14516 - acc: 0.9491 -- iter: 1024/2235
[A[ATraining Step: 1153  | total loss: [1m[32m0.14484[0m[0m | time: 41.672s
[2K
| RMSProp | epoch: 017 | loss: 0.14484 - acc: 0.9511 -- iter: 1056/2235
[A[ATraining Step: 1154  | total loss: [1m[32m0.14511[0m[0m | time: 43.037s
[2K
| RMSProp | epoch: 017 | loss: 0.14511 - acc: 0.9529 -- iter: 1088/2235
[A[ATraining Step: 1155  | total loss: [1m[32m0.14339[0m[0m | time: 44.403s
[2K
| RMSProp | epoch: 017 | loss: 0.14339 - acc: 0.9544 -- iter: 1120/2235
[A[ATraining Step: 1156  | total loss: [1m[32m0.13556[0m[0m | time: 45.495s
[2K
| RMSProp | epoch: 017 | loss: 0.13556 - acc: 0.9559 -- iter: 1152/2235
[A[ATraining Step: 1157  | total loss: [1m[32m0.13381[0m[0m | time: 46.570s
[2K
| RMSProp | epoch: 017 | loss: 0.13381 - acc: 0.9572 -- iter: 1184/2235
[A[ATraining Step: 1158  | total loss: [1m[32m0.13607[0m[0m | time: 47.817s
[2K
| RMSProp | epoch: 017 | loss: 0.13607 - acc: 0.9583 -- iter: 1216/2235
[A[ATraining Step: 1159  | total loss: [1m[32m0.13392[0m[0m | time: 49.134s
[2K
| RMSProp | epoch: 017 | loss: 0.13392 - acc: 0.9625 -- iter: 1248/2235
[A[ATraining Step: 1160  | total loss: [1m[32m0.13614[0m[0m | time: 50.381s
[2K
| RMSProp | epoch: 017 | loss: 0.13614 - acc: 0.9631 -- iter: 1280/2235
[A[ATraining Step: 1161  | total loss: [1m[32m0.13778[0m[0m | time: 51.553s
[2K
| RMSProp | epoch: 017 | loss: 0.13778 - acc: 0.9606 -- iter: 1312/2235
[A[ATraining Step: 1162  | total loss: [1m[32m0.14816[0m[0m | time: 52.798s
[2K
| RMSProp | epoch: 017 | loss: 0.14816 - acc: 0.9551 -- iter: 1344/2235
[A[ATraining Step: 1163  | total loss: [1m[32m0.14391[0m[0m | time: 54.150s
[2K
| RMSProp | epoch: 017 | loss: 0.14391 - acc: 0.9534 -- iter: 1376/2235
[A[ATraining Step: 1164  | total loss: [1m[32m0.13381[0m[0m | time: 55.457s
[2K
| RMSProp | epoch: 017 | loss: 0.13381 - acc: 0.9580 -- iter: 1408/2235
[A[ATraining Step: 1165  | total loss: [1m[32m0.12288[0m[0m | time: 56.396s
[2K
| RMSProp | epoch: 017 | loss: 0.12288 - acc: 0.9622 -- iter: 1440/2235
[A[ATraining Step: 1166  | total loss: [1m[32m0.11262[0m[0m | time: 57.694s
[2K
| RMSProp | epoch: 017 | loss: 0.11262 - acc: 0.9660 -- iter: 1472/2235
[A[ATraining Step: 1167  | total loss: [1m[32m0.11041[0m[0m | time: 58.983s
[2K
| RMSProp | epoch: 017 | loss: 0.11041 - acc: 0.9663 -- iter: 1504/2235
[A[ATraining Step: 1168  | total loss: [1m[32m0.11673[0m[0m | time: 60.202s
[2K
| RMSProp | epoch: 017 | loss: 0.11673 - acc: 0.9665 -- iter: 1536/2235
[A[ATraining Step: 1169  | total loss: [1m[32m0.11583[0m[0m | time: 61.473s
[2K
| RMSProp | epoch: 017 | loss: 0.11583 - acc: 0.9605 -- iter: 1568/2235
[A[ATraining Step: 1170  | total loss: [1m[32m0.12052[0m[0m | time: 62.643s
[2K
| RMSProp | epoch: 017 | loss: 0.12052 - acc: 0.9519 -- iter: 1600/2235
[A[ATraining Step: 1171  | total loss: [1m[32m0.16253[0m[0m | time: 63.877s
[2K
| RMSProp | epoch: 017 | loss: 0.16253 - acc: 0.9349 -- iter: 1632/2235
[A[ATraining Step: 1172  | total loss: [1m[32m0.17476[0m[0m | time: 65.240s
[2K
| RMSProp | epoch: 017 | loss: 0.17476 - acc: 0.9351 -- iter: 1664/2235
[A[ATraining Step: 1173  | total loss: [1m[32m0.16961[0m[0m | time: 66.609s
[2K
| RMSProp | epoch: 017 | loss: 0.16961 - acc: 0.9354 -- iter: 1696/2235
[A[ATraining Step: 1174  | total loss: [1m[32m0.16512[0m[0m | time: 67.944s
[2K
| RMSProp | epoch: 017 | loss: 0.16512 - acc: 0.9387 -- iter: 1728/2235
[A[ATraining Step: 1175  | total loss: [1m[32m0.17582[0m[0m | time: 69.343s
[2K
| RMSProp | epoch: 017 | loss: 0.17582 - acc: 0.9417 -- iter: 1760/2235
[A[ATraining Step: 1176  | total loss: [1m[32m0.16746[0m[0m | time: 70.671s
[2K
| RMSProp | epoch: 017 | loss: 0.16746 - acc: 0.9444 -- iter: 1792/2235
[A[ATraining Step: 1177  | total loss: [1m[32m0.15951[0m[0m | time: 71.962s
[2K
| RMSProp | epoch: 017 | loss: 0.15951 - acc: 0.9469 -- iter: 1824/2235
[A[ATraining Step: 1178  | total loss: [1m[32m0.15740[0m[0m | time: 73.151s
[2K
| RMSProp | epoch: 017 | loss: 0.15740 - acc: 0.9490 -- iter: 1856/2235
[A[ATraining Step: 1179  | total loss: [1m[32m0.14405[0m[0m | time: 74.162s
[2K
| RMSProp | epoch: 017 | loss: 0.14405 - acc: 0.9541 -- iter: 1888/2235
[A[ATraining Step: 1180  | total loss: [1m[32m0.13563[0m[0m | time: 75.347s
[2K
| RMSProp | epoch: 017 | loss: 0.13563 - acc: 0.9587 -- iter: 1920/2235
[A[ATraining Step: 1181  | total loss: [1m[32m0.12379[0m[0m | time: 76.645s
[2K
| RMSProp | epoch: 017 | loss: 0.12379 - acc: 0.9629 -- iter: 1952/2235
[A[ATraining Step: 1182  | total loss: [1m[32m0.11448[0m[0m | time: 77.922s
[2K
| RMSProp | epoch: 017 | loss: 0.11448 - acc: 0.9666 -- iter: 1984/2235
[A[ATraining Step: 1183  | total loss: [1m[32m0.10558[0m[0m | time: 79.342s
[2K
| RMSProp | epoch: 017 | loss: 0.10558 - acc: 0.9699 -- iter: 2016/2235
[A[ATraining Step: 1184  | total loss: [1m[32m0.13053[0m[0m | time: 80.662s
[2K
| RMSProp | epoch: 017 | loss: 0.13053 - acc: 0.9667 -- iter: 2048/2235
[A[ATraining Step: 1185  | total loss: [1m[32m0.12536[0m[0m | time: 82.022s
[2K
| RMSProp | epoch: 017 | loss: 0.12536 - acc: 0.9669 -- iter: 2080/2235
[A[ATraining Step: 1186  | total loss: [1m[32m0.14853[0m[0m | time: 83.401s
[2K
| RMSProp | epoch: 017 | loss: 0.14853 - acc: 0.9514 -- iter: 2112/2235
[A[ATraining Step: 1187  | total loss: [1m[32m0.14050[0m[0m | time: 84.581s
[2K
| RMSProp | epoch: 017 | loss: 0.14050 - acc: 0.9532 -- iter: 2144/2235
[A[ATraining Step: 1188  | total loss: [1m[32m0.14531[0m[0m | time: 85.944s
[2K
| RMSProp | epoch: 017 | loss: 0.14531 - acc: 0.9516 -- iter: 2176/2235
[A[ATraining Step: 1189  | total loss: [1m[32m0.16161[0m[0m | time: 87.323s
[2K
| RMSProp | epoch: 017 | loss: 0.16161 - acc: 0.9408 -- iter: 2208/2235
[A[ATraining Step: 1190  | total loss: [1m[32m0.15137[0m[0m | time: 93.929s
[2K
| RMSProp | epoch: 017 | loss: 0.15137 - acc: 0.9467 | val_loss: 0.81706 - val_acc: 0.7539 -- iter: 2235/2235
--
Training Step: 1191  | total loss: [1m[32m0.13799[0m[0m | time: 1.273s
[2K
| RMSProp | epoch: 018 | loss: 0.13799 - acc: 0.9521 -- iter: 0032/2235
[A[ATraining Step: 1192  | total loss: [1m[32m0.15121[0m[0m | time: 2.656s
[2K
| RMSProp | epoch: 018 | loss: 0.15121 - acc: 0.9506 -- iter: 0064/2235
[A[ATraining Step: 1193  | total loss: [1m[32m0.14895[0m[0m | time: 3.968s
[2K
| RMSProp | epoch: 018 | loss: 0.14895 - acc: 0.9493 -- iter: 0096/2235
[A[ATraining Step: 1194  | total loss: [1m[32m0.14997[0m[0m | time: 5.188s
[2K
| RMSProp | epoch: 018 | loss: 0.14997 - acc: 0.9450 -- iter: 0128/2235
[A[ATraining Step: 1195  | total loss: [1m[32m0.13749[0m[0m | time: 6.368s
[2K
| RMSProp | epoch: 018 | loss: 0.13749 - acc: 0.9505 -- iter: 0160/2235
[A[ATraining Step: 1196  | total loss: [1m[32m0.12746[0m[0m | time: 7.710s
[2K
| RMSProp | epoch: 018 | loss: 0.12746 - acc: 0.9554 -- iter: 0192/2235
[A[ATraining Step: 1197  | total loss: [1m[32m0.11696[0m[0m | time: 9.076s
[2K
| RMSProp | epoch: 018 | loss: 0.11696 - acc: 0.9599 -- iter: 0224/2235
[A[ATraining Step: 1198  | total loss: [1m[32m0.10715[0m[0m | time: 13.820s
[2K
| RMSProp | epoch: 018 | loss: 0.10715 - acc: 0.9639 -- iter: 0256/2235
[A[ATraining Step: 1199  | total loss: [1m[32m0.10020[0m[0m | time: 14.932s
[2K
| RMSProp | epoch: 018 | loss: 0.10020 - acc: 0.9644 -- iter: 0288/2235
[A[ATraining Step: 1200  | total loss: [1m[32m0.09470[0m[0m | time: 21.953s
[2K
| RMSProp | epoch: 018 | loss: 0.09470 - acc: 0.9680 | val_loss: 1.13772 - val_acc: 0.6710 -- iter: 0320/2235
--
Training Step: 1201  | total loss: [1m[32m0.09088[0m[0m | time: 23.258s
[2K
| RMSProp | epoch: 018 | loss: 0.09088 - acc: 0.9680 -- iter: 0352/2235
[A[ATraining Step: 1202  | total loss: [1m[32m0.09335[0m[0m | time: 24.575s
[2K
| RMSProp | epoch: 018 | loss: 0.09335 - acc: 0.9619 -- iter: 0384/2235
[A[ATraining Step: 1203  | total loss: [1m[32m0.09466[0m[0m | time: 25.853s
[2K
| RMSProp | epoch: 018 | loss: 0.09466 - acc: 0.9625 -- iter: 0416/2235
[A[ATraining Step: 1204  | total loss: [1m[32m0.08926[0m[0m | time: 27.198s
[2K
| RMSProp | epoch: 018 | loss: 0.08926 - acc: 0.9632 -- iter: 0448/2235
[A[ATraining Step: 1205  | total loss: [1m[32m0.09357[0m[0m | time: 28.672s
[2K
| RMSProp | epoch: 018 | loss: 0.09357 - acc: 0.9606 -- iter: 0480/2235
[A[ATraining Step: 1206  | total loss: [1m[32m0.09385[0m[0m | time: 29.765s
[2K
| RMSProp | epoch: 018 | loss: 0.09385 - acc: 0.9583 -- iter: 0512/2235
[A[ATraining Step: 1207  | total loss: [1m[32m0.08899[0m[0m | time: 30.729s
[2K
| RMSProp | epoch: 018 | loss: 0.08899 - acc: 0.9625 -- iter: 0544/2235
[A[ATraining Step: 1208  | total loss: [1m[32m0.08104[0m[0m | time: 32.085s
[2K
| RMSProp | epoch: 018 | loss: 0.08104 - acc: 0.9662 -- iter: 0576/2235
[A[ATraining Step: 1209  | total loss: [1m[32m0.07475[0m[0m | time: 33.360s
[2K
| RMSProp | epoch: 018 | loss: 0.07475 - acc: 0.9696 -- iter: 0608/2235
[A[ATraining Step: 1210  | total loss: [1m[32m0.08342[0m[0m | time: 34.687s
[2K
| RMSProp | epoch: 018 | loss: 0.08342 - acc: 0.9664 -- iter: 0640/2235
[A[ATraining Step: 1211  | total loss: [1m[32m0.16551[0m[0m | time: 36.024s
[2K
| RMSProp | epoch: 018 | loss: 0.16551 - acc: 0.9447 -- iter: 0672/2235
[A[ATraining Step: 1212  | total loss: [1m[32m0.16318[0m[0m | time: 37.299s
[2K
| RMSProp | epoch: 018 | loss: 0.16318 - acc: 0.9440 -- iter: 0704/2235
[A[ATraining Step: 1213  | total loss: [1m[32m0.15166[0m[0m | time: 38.421s
[2K
| RMSProp | epoch: 018 | loss: 0.15166 - acc: 0.9496 -- iter: 0736/2235
[A[ATraining Step: 1214  | total loss: [1m[32m0.13802[0m[0m | time: 39.354s
[2K
| RMSProp | epoch: 018 | loss: 0.13802 - acc: 0.9547 -- iter: 0768/2235
[A[ATraining Step: 1215  | total loss: [1m[32m0.12638[0m[0m | time: 40.280s
[2K
| RMSProp | epoch: 018 | loss: 0.12638 - acc: 0.9592 -- iter: 0800/2235
[A[ATraining Step: 1216  | total loss: [1m[32m0.11538[0m[0m | time: 41.238s
[2K
| RMSProp | epoch: 018 | loss: 0.11538 - acc: 0.9633 -- iter: 0832/2235
[A[ATraining Step: 1217  | total loss: [1m[32m0.10666[0m[0m | time: 42.340s
[2K
| RMSProp | epoch: 018 | loss: 0.10666 - acc: 0.9669 -- iter: 0864/2235
[A[ATraining Step: 1218  | total loss: [1m[32m0.09937[0m[0m | time: 43.329s
[2K
| RMSProp | epoch: 018 | loss: 0.09937 - acc: 0.9703 -- iter: 0896/2235
[A[ATraining Step: 1219  | total loss: [1m[32m0.09461[0m[0m | time: 44.155s
[2K
| RMSProp | epoch: 018 | loss: 0.09461 - acc: 0.9701 -- iter: 0928/2235
[A[ATraining Step: 1220  | total loss: [1m[32m0.11404[0m[0m | time: 45.183s
[2K
| RMSProp | epoch: 018 | loss: 0.11404 - acc: 0.9637 -- iter: 0960/2235
[A[ATraining Step: 1221  | total loss: [1m[32m0.12137[0m[0m | time: 46.185s
[2K
| RMSProp | epoch: 018 | loss: 0.12137 - acc: 0.9580 -- iter: 0992/2235
[A[ATraining Step: 1222  | total loss: [1m[32m0.11343[0m[0m | time: 47.179s
[2K
| RMSProp | epoch: 018 | loss: 0.11343 - acc: 0.9622 -- iter: 1024/2235
[A[ATraining Step: 1223  | total loss: [1m[32m0.10294[0m[0m | time: 48.241s
[2K
| RMSProp | epoch: 018 | loss: 0.10294 - acc: 0.9660 -- iter: 1056/2235
[A[ATraining Step: 1224  | total loss: [1m[32m0.09345[0m[0m | time: 49.176s
[2K
| RMSProp | epoch: 018 | loss: 0.09345 - acc: 0.9694 -- iter: 1088/2235
[A[ATraining Step: 1225  | total loss: [1m[32m0.08541[0m[0m | time: 50.249s
[2K
| RMSProp | epoch: 018 | loss: 0.08541 - acc: 0.9724 -- iter: 1120/2235
[A[ATraining Step: 1226  | total loss: [1m[32m0.07923[0m[0m | time: 51.171s
[2K
| RMSProp | epoch: 018 | loss: 0.07923 - acc: 0.9752 -- iter: 1152/2235
[A[ATraining Step: 1227  | total loss: [1m[32m0.07564[0m[0m | time: 52.362s
[2K
| RMSProp | epoch: 018 | loss: 0.07564 - acc: 0.9745 -- iter: 1184/2235
[A[ATraining Step: 1228  | total loss: [1m[32m0.06961[0m[0m | time: 53.437s
[2K
| RMSProp | epoch: 018 | loss: 0.06961 - acc: 0.9771 -- iter: 1216/2235
[A[ATraining Step: 1229  | total loss: [1m[32m0.06328[0m[0m | time: 54.302s
[2K
| RMSProp | epoch: 018 | loss: 0.06328 - acc: 0.9794 -- iter: 1248/2235
[A[ATraining Step: 1230  | total loss: [1m[32m0.08871[0m[0m | time: 55.188s
[2K
| RMSProp | epoch: 018 | loss: 0.08871 - acc: 0.9752 -- iter: 1280/2235
[A[ATraining Step: 1231  | total loss: [1m[32m0.10210[0m[0m | time: 56.148s
[2K
| RMSProp | epoch: 018 | loss: 0.10210 - acc: 0.9652 -- iter: 1312/2235
[A[ATraining Step: 1232  | total loss: [1m[32m0.09752[0m[0m | time: 57.138s
[2K
| RMSProp | epoch: 018 | loss: 0.09752 - acc: 0.9687 -- iter: 1344/2235
[A[ATraining Step: 1233  | total loss: [1m[32m0.12872[0m[0m | time: 58.162s
[2K
| RMSProp | epoch: 018 | loss: 0.12872 - acc: 0.9624 -- iter: 1376/2235
[A[ATraining Step: 1234  | total loss: [1m[32m0.16284[0m[0m | time: 59.511s
[2K
| RMSProp | epoch: 018 | loss: 0.16284 - acc: 0.9505 -- iter: 1408/2235
[A[ATraining Step: 1235  | total loss: [1m[32m0.14968[0m[0m | time: 60.830s
[2K
| RMSProp | epoch: 018 | loss: 0.14968 - acc: 0.9555 -- iter: 1440/2235
[A[ATraining Step: 1236  | total loss: [1m[32m0.15522[0m[0m | time: 61.989s
[2K
| RMSProp | epoch: 018 | loss: 0.15522 - acc: 0.9506 -- iter: 1472/2235
[A[ATraining Step: 1237  | total loss: [1m[32m0.14984[0m[0m | time: 63.231s
[2K
| RMSProp | epoch: 018 | loss: 0.14984 - acc: 0.9524 -- iter: 1504/2235
[A[ATraining Step: 1238  | total loss: [1m[32m0.14164[0m[0m | time: 64.430s
[2K
| RMSProp | epoch: 018 | loss: 0.14164 - acc: 0.9540 -- iter: 1536/2235
[A[ATraining Step: 1239  | total loss: [1m[32m0.13794[0m[0m | time: 65.719s
[2K
| RMSProp | epoch: 018 | loss: 0.13794 - acc: 0.9524 -- iter: 1568/2235
[A[ATraining Step: 1240  | total loss: [1m[32m0.13420[0m[0m | time: 66.708s
[2K
| RMSProp | epoch: 018 | loss: 0.13420 - acc: 0.9540 -- iter: 1600/2235
[A[ATraining Step: 1241  | total loss: [1m[32m0.13294[0m[0m | time: 67.885s
[2K
| RMSProp | epoch: 018 | loss: 0.13294 - acc: 0.9555 -- iter: 1632/2235
[A[ATraining Step: 1242  | total loss: [1m[32m0.12346[0m[0m | time: 69.138s
[2K
| RMSProp | epoch: 018 | loss: 0.12346 - acc: 0.9599 -- iter: 1664/2235
[A[ATraining Step: 1243  | total loss: [1m[32m0.11776[0m[0m | time: 70.244s
[2K
| RMSProp | epoch: 018 | loss: 0.11776 - acc: 0.9608 -- iter: 1696/2235
[A[ATraining Step: 1244  | total loss: [1m[32m0.11665[0m[0m | time: 71.434s
[2K
| RMSProp | epoch: 018 | loss: 0.11665 - acc: 0.9616 -- iter: 1728/2235
[A[ATraining Step: 1245  | total loss: [1m[32m0.11063[0m[0m | time: 72.660s
[2K
| RMSProp | epoch: 018 | loss: 0.11063 - acc: 0.9623 -- iter: 1760/2235
[A[ATraining Step: 1246  | total loss: [1m[32m0.12750[0m[0m | time: 73.912s
[2K
| RMSProp | epoch: 018 | loss: 0.12750 - acc: 0.9630 -- iter: 1792/2235
[A[ATraining Step: 1247  | total loss: [1m[32m0.11567[0m[0m | time: 75.058s
[2K
| RMSProp | epoch: 018 | loss: 0.11567 - acc: 0.9667 -- iter: 1824/2235
[A[ATraining Step: 1248  | total loss: [1m[32m0.10512[0m[0m | time: 76.396s
[2K
| RMSProp | epoch: 018 | loss: 0.10512 - acc: 0.9700 -- iter: 1856/2235
[A[ATraining Step: 1249  | total loss: [1m[32m0.09644[0m[0m | time: 77.692s
[2K
| RMSProp | epoch: 018 | loss: 0.09644 - acc: 0.9730 -- iter: 1888/2235
[A[ATraining Step: 1250  | total loss: [1m[32m0.08934[0m[0m | time: 79.106s
[2K
| RMSProp | epoch: 018 | loss: 0.08934 - acc: 0.9757 -- iter: 1920/2235
[A[ATraining Step: 1251  | total loss: [1m[32m0.08098[0m[0m | time: 80.446s
[2K
| RMSProp | epoch: 018 | loss: 0.08098 - acc: 0.9781 -- iter: 1952/2235
[A[ATraining Step: 1252  | total loss: [1m[32m0.07397[0m[0m | time: 81.617s
[2K
| RMSProp | epoch: 018 | loss: 0.07397 - acc: 0.9803 -- iter: 1984/2235
[A[ATraining Step: 1253  | total loss: [1m[32m0.06963[0m[0m | time: 82.666s
[2K
| RMSProp | epoch: 018 | loss: 0.06963 - acc: 0.9792 -- iter: 2016/2235
[A[ATraining Step: 1254  | total loss: [1m[32m0.06944[0m[0m | time: 83.911s
[2K
| RMSProp | epoch: 018 | loss: 0.06944 - acc: 0.9781 -- iter: 2048/2235
[A[ATraining Step: 1255  | total loss: [1m[32m0.06301[0m[0m | time: 85.060s
[2K
| RMSProp | epoch: 018 | loss: 0.06301 - acc: 0.9803 -- iter: 2080/2235
[A[ATraining Step: 1256  | total loss: [1m[32m0.05777[0m[0m | time: 86.272s
[2K
| RMSProp | epoch: 018 | loss: 0.05777 - acc: 0.9823 -- iter: 2112/2235
[A[ATraining Step: 1257  | total loss: [1m[32m0.05344[0m[0m | time: 87.613s
[2K
| RMSProp | epoch: 018 | loss: 0.05344 - acc: 0.9840 -- iter: 2144/2235
[A[ATraining Step: 1258  | total loss: [1m[32m0.10501[0m[0m | time: 88.945s
[2K
| RMSProp | epoch: 018 | loss: 0.10501 - acc: 0.9731 -- iter: 2176/2235
[A[ATraining Step: 1259  | total loss: [1m[32m0.15800[0m[0m | time: 90.237s
[2K
| RMSProp | epoch: 018 | loss: 0.15800 - acc: 0.9571 -- iter: 2208/2235
[A[ATraining Step: 1260  | total loss: [1m[32m0.15436[0m[0m | time: 97.178s
[2K
| RMSProp | epoch: 018 | loss: 0.15436 - acc: 0.9582 | val_loss: 0.90529 - val_acc: 0.7310 -- iter: 2235/2235
--
Training Step: 1261  | total loss: [1m[32m0.14770[0m[0m | time: 1.050s
[2K
| RMSProp | epoch: 019 | loss: 0.14770 - acc: 0.9562 -- iter: 0032/2235
[A[ATraining Step: 1262  | total loss: [1m[32m0.13642[0m[0m | time: 2.269s
[2K
| RMSProp | epoch: 019 | loss: 0.13642 - acc: 0.9574 -- iter: 0064/2235
[A[ATraining Step: 1263  | total loss: [1m[32m0.13052[0m[0m | time: 3.558s
[2K
| RMSProp | epoch: 019 | loss: 0.13052 - acc: 0.9586 -- iter: 0096/2235
[A[ATraining Step: 1264  | total loss: [1m[32m0.14623[0m[0m | time: 4.966s
[2K
| RMSProp | epoch: 019 | loss: 0.14623 - acc: 0.9533 -- iter: 0128/2235
[A[ATraining Step: 1265  | total loss: [1m[32m0.16142[0m[0m | time: 6.308s
[2K
| RMSProp | epoch: 019 | loss: 0.16142 - acc: 0.9392 -- iter: 0160/2235
[A[ATraining Step: 1266  | total loss: [1m[32m0.16026[0m[0m | time: 7.533s
[2K
| RMSProp | epoch: 019 | loss: 0.16026 - acc: 0.9422 -- iter: 0192/2235
[A[ATraining Step: 1267  | total loss: [1m[32m0.15473[0m[0m | time: 8.973s
[2K
| RMSProp | epoch: 019 | loss: 0.15473 - acc: 0.9417 -- iter: 0224/2235
[A[ATraining Step: 1268  | total loss: [1m[32m0.14204[0m[0m | time: 10.363s
[2K
| RMSProp | epoch: 019 | loss: 0.14204 - acc: 0.9476 -- iter: 0256/2235
[A[ATraining Step: 1269  | total loss: [1m[32m0.13007[0m[0m | time: 11.681s
[2K
| RMSProp | epoch: 019 | loss: 0.13007 - acc: 0.9528 -- iter: 0288/2235
[A[ATraining Step: 1270  | total loss: [1m[32m0.12365[0m[0m | time: 12.916s
[2K
| RMSProp | epoch: 019 | loss: 0.12365 - acc: 0.9544 -- iter: 0320/2235
[A[ATraining Step: 1271  | total loss: [1m[32m0.12287[0m[0m | time: 14.142s
[2K
| RMSProp | epoch: 019 | loss: 0.12287 - acc: 0.9558 -- iter: 0352/2235
[A[ATraining Step: 1272  | total loss: [1m[32m0.11180[0m[0m | time: 15.380s
[2K
| RMSProp | epoch: 019 | loss: 0.11180 - acc: 0.9602 -- iter: 0384/2235
[A[ATraining Step: 1273  | total loss: [1m[32m0.10523[0m[0m | time: 16.470s
[2K
| RMSProp | epoch: 019 | loss: 0.10523 - acc: 0.9611 -- iter: 0416/2235
[A[ATraining Step: 1274  | total loss: [1m[32m0.09753[0m[0m | time: 17.617s
[2K
| RMSProp | epoch: 019 | loss: 0.09753 - acc: 0.9650 -- iter: 0448/2235
[A[ATraining Step: 1275  | total loss: [1m[32m0.09172[0m[0m | time: 18.916s
[2K
| RMSProp | epoch: 019 | loss: 0.09172 - acc: 0.9654 -- iter: 0480/2235
[A[ATraining Step: 1276  | total loss: [1m[32m0.08492[0m[0m | time: 20.380s
[2K
| RMSProp | epoch: 019 | loss: 0.08492 - acc: 0.9688 -- iter: 0512/2235
[A[ATraining Step: 1277  | total loss: [1m[32m0.08685[0m[0m | time: 21.434s
[2K
| RMSProp | epoch: 019 | loss: 0.08685 - acc: 0.9688 -- iter: 0544/2235
[A[ATraining Step: 1278  | total loss: [1m[32m0.08421[0m[0m | time: 22.544s
[2K
| RMSProp | epoch: 019 | loss: 0.08421 - acc: 0.9682 -- iter: 0576/2235
[A[ATraining Step: 1279  | total loss: [1m[32m0.07651[0m[0m | time: 23.902s
[2K
| RMSProp | epoch: 019 | loss: 0.07651 - acc: 0.9714 -- iter: 0608/2235
[A[ATraining Step: 1280  | total loss: [1m[32m0.07784[0m[0m | time: 25.177s
[2K
| RMSProp | epoch: 019 | loss: 0.07784 - acc: 0.9711 -- iter: 0640/2235
[A[ATraining Step: 1281  | total loss: [1m[32m0.10339[0m[0m | time: 26.230s
[2K
| RMSProp | epoch: 019 | loss: 0.10339 - acc: 0.9647 -- iter: 0672/2235
[A[ATraining Step: 1282  | total loss: [1m[32m0.09719[0m[0m | time: 27.386s
[2K
| RMSProp | epoch: 019 | loss: 0.09719 - acc: 0.9651 -- iter: 0704/2235
[A[ATraining Step: 1283  | total loss: [1m[32m0.09096[0m[0m | time: 28.685s
[2K
| RMSProp | epoch: 019 | loss: 0.09096 - acc: 0.9686 -- iter: 0736/2235
[A[ATraining Step: 1284  | total loss: [1m[32m0.09700[0m[0m | time: 30.040s
[2K
| RMSProp | epoch: 019 | loss: 0.09700 - acc: 0.9655 -- iter: 0768/2235
[A[ATraining Step: 1285  | total loss: [1m[32m0.12740[0m[0m | time: 31.169s
[2K
| RMSProp | epoch: 019 | loss: 0.12740 - acc: 0.9595 -- iter: 0800/2235
[A[ATraining Step: 1286  | total loss: [1m[32m0.12919[0m[0m | time: 32.333s
[2K
| RMSProp | epoch: 019 | loss: 0.12919 - acc: 0.9605 -- iter: 0832/2235
[A[ATraining Step: 1287  | total loss: [1m[32m0.13440[0m[0m | time: 33.598s
[2K
| RMSProp | epoch: 019 | loss: 0.13440 - acc: 0.9613 -- iter: 0864/2235
[A[ATraining Step: 1288  | total loss: [1m[32m0.12382[0m[0m | time: 34.943s
[2K
| RMSProp | epoch: 019 | loss: 0.12382 - acc: 0.9652 -- iter: 0896/2235
[A[ATraining Step: 1289  | total loss: [1m[32m0.11427[0m[0m | time: 36.121s
[2K
| RMSProp | epoch: 019 | loss: 0.11427 - acc: 0.9686 -- iter: 0928/2235
[A[ATraining Step: 1290  | total loss: [1m[32m0.10720[0m[0m | time: 37.447s
[2K
| RMSProp | epoch: 019 | loss: 0.10720 - acc: 0.9718 -- iter: 0960/2235
[A[ATraining Step: 1291  | total loss: [1m[32m0.11855[0m[0m | time: 38.846s
[2K
| RMSProp | epoch: 019 | loss: 0.11855 - acc: 0.9683 -- iter: 0992/2235
[A[ATraining Step: 1292  | total loss: [1m[32m0.13047[0m[0m | time: 40.218s
[2K
| RMSProp | epoch: 019 | loss: 0.13047 - acc: 0.9653 -- iter: 1024/2235
[A[ATraining Step: 1293  | total loss: [1m[32m0.12261[0m[0m | time: 41.291s
[2K
| RMSProp | epoch: 019 | loss: 0.12261 - acc: 0.9687 -- iter: 1056/2235
[A[ATraining Step: 1294  | total loss: [1m[32m0.11356[0m[0m | time: 42.453s
[2K
| RMSProp | epoch: 019 | loss: 0.11356 - acc: 0.9719 -- iter: 1088/2235
[A[ATraining Step: 1295  | total loss: [1m[32m0.12242[0m[0m | time: 43.773s
[2K
| RMSProp | epoch: 019 | loss: 0.12242 - acc: 0.9684 -- iter: 1120/2235
[A[ATraining Step: 1296  | total loss: [1m[32m0.13288[0m[0m | time: 45.085s
[2K
| RMSProp | epoch: 019 | loss: 0.13288 - acc: 0.9653 -- iter: 1152/2235
[A[ATraining Step: 1297  | total loss: [1m[32m0.13317[0m[0m | time: 46.370s
[2K
| RMSProp | epoch: 019 | loss: 0.13317 - acc: 0.9626 -- iter: 1184/2235
[A[ATraining Step: 1298  | total loss: [1m[32m0.13449[0m[0m | time: 47.469s
[2K
| RMSProp | epoch: 019 | loss: 0.13449 - acc: 0.9600 -- iter: 1216/2235
[A[ATraining Step: 1299  | total loss: [1m[32m0.12253[0m[0m | time: 48.835s
[2K
| RMSProp | epoch: 019 | loss: 0.12253 - acc: 0.9640 -- iter: 1248/2235
[A[ATraining Step: 1300  | total loss: [1m[32m0.11264[0m[0m | time: 50.040s
[2K
| RMSProp | epoch: 019 | loss: 0.11264 - acc: 0.9676 -- iter: 1280/2235
[A[ATraining Step: 1301  | total loss: [1m[32m0.10410[0m[0m | time: 51.259s
[2K
| RMSProp | epoch: 019 | loss: 0.10410 - acc: 0.9709 -- iter: 1312/2235
[A[ATraining Step: 1302  | total loss: [1m[32m0.10875[0m[0m | time: 52.638s
[2K
| RMSProp | epoch: 019 | loss: 0.10875 - acc: 0.9707 -- iter: 1344/2235
[A[ATraining Step: 1303  | total loss: [1m[32m0.11163[0m[0m | time: 53.921s
[2K
| RMSProp | epoch: 019 | loss: 0.11163 - acc: 0.9673 -- iter: 1376/2235
[A[ATraining Step: 1304  | total loss: [1m[32m0.10736[0m[0m | time: 55.145s
[2K
| RMSProp | epoch: 019 | loss: 0.10736 - acc: 0.9675 -- iter: 1408/2235
[A[ATraining Step: 1305  | total loss: [1m[32m0.11553[0m[0m | time: 56.311s
[2K
| RMSProp | epoch: 019 | loss: 0.11553 - acc: 0.9645 -- iter: 1440/2235
[A[ATraining Step: 1306  | total loss: [1m[32m0.12578[0m[0m | time: 57.615s
[2K
| RMSProp | epoch: 019 | loss: 0.12578 - acc: 0.9649 -- iter: 1472/2235
[A[ATraining Step: 1307  | total loss: [1m[32m0.11408[0m[0m | time: 58.860s
[2K
| RMSProp | epoch: 019 | loss: 0.11408 - acc: 0.9684 -- iter: 1504/2235
[A[ATraining Step: 1308  | total loss: [1m[32m0.12420[0m[0m | time: 60.177s
[2K
| RMSProp | epoch: 019 | loss: 0.12420 - acc: 0.9653 -- iter: 1536/2235
[A[ATraining Step: 1309  | total loss: [1m[32m0.11989[0m[0m | time: 61.545s
[2K
| RMSProp | epoch: 019 | loss: 0.11989 - acc: 0.9657 -- iter: 1568/2235
[A[ATraining Step: 1310  | total loss: [1m[32m0.11311[0m[0m | time: 62.724s
[2K
| RMSProp | epoch: 019 | loss: 0.11311 - acc: 0.9660 -- iter: 1600/2235
[A[ATraining Step: 1311  | total loss: [1m[32m0.11542[0m[0m | time: 63.955s
[2K
| RMSProp | epoch: 019 | loss: 0.11542 - acc: 0.9663 -- iter: 1632/2235
[A[ATraining Step: 1312  | total loss: [1m[32m0.11073[0m[0m | time: 65.190s
[2K
| RMSProp | epoch: 019 | loss: 0.11073 - acc: 0.9665 -- iter: 1664/2235
[A[ATraining Step: 1313  | total loss: [1m[32m0.10761[0m[0m | time: 66.544s
[2K
| RMSProp | epoch: 019 | loss: 0.10761 - acc: 0.9667 -- iter: 1696/2235
[A[ATraining Step: 1314  | total loss: [1m[32m0.10885[0m[0m | time: 67.815s
[2K
| RMSProp | epoch: 019 | loss: 0.10885 - acc: 0.9638 -- iter: 1728/2235
[A[ATraining Step: 1315  | total loss: [1m[32m0.10832[0m[0m | time: 69.141s
[2K
| RMSProp | epoch: 019 | loss: 0.10832 - acc: 0.9643 -- iter: 1760/2235
[A[ATraining Step: 1316  | total loss: [1m[32m0.10024[0m[0m | time: 70.226s
[2K
| RMSProp | epoch: 019 | loss: 0.10024 - acc: 0.9679 -- iter: 1792/2235
[A[ATraining Step: 1317  | total loss: [1m[32m0.13261[0m[0m | time: 71.339s
[2K
| RMSProp | epoch: 019 | loss: 0.13261 - acc: 0.9648 -- iter: 1824/2235
[A[ATraining Step: 1318  | total loss: [1m[32m0.12277[0m[0m | time: 72.702s
[2K
| RMSProp | epoch: 019 | loss: 0.12277 - acc: 0.9684 -- iter: 1856/2235
[A[ATraining Step: 1319  | total loss: [1m[32m0.11288[0m[0m | time: 73.855s
[2K
| RMSProp | epoch: 019 | loss: 0.11288 - acc: 0.9715 -- iter: 1888/2235
[A[ATraining Step: 1320  | total loss: [1m[32m0.10401[0m[0m | time: 75.075s
[2K
| RMSProp | epoch: 019 | loss: 0.10401 - acc: 0.9744 -- iter: 1920/2235
[A[ATraining Step: 1321  | total loss: [1m[32m0.10819[0m[0m | time: 76.420s
[2K
| RMSProp | epoch: 019 | loss: 0.10819 - acc: 0.9707 -- iter: 1952/2235
[A[ATraining Step: 1322  | total loss: [1m[32m0.11384[0m[0m | time: 77.797s
[2K
| RMSProp | epoch: 019 | loss: 0.11384 - acc: 0.9705 -- iter: 1984/2235
[A[ATraining Step: 1323  | total loss: [1m[32m0.11195[0m[0m | time: 78.842s
[2K
| RMSProp | epoch: 019 | loss: 0.11195 - acc: 0.9703 -- iter: 2016/2235
[A[ATraining Step: 1324  | total loss: [1m[32m0.10489[0m[0m | time: 79.989s
[2K
| RMSProp | epoch: 019 | loss: 0.10489 - acc: 0.9733 -- iter: 2048/2235
[A[ATraining Step: 1325  | total loss: [1m[32m0.09538[0m[0m | time: 81.366s
[2K
| RMSProp | epoch: 019 | loss: 0.09538 - acc: 0.9760 -- iter: 2080/2235
[A[ATraining Step: 1326  | total loss: [1m[32m0.10239[0m[0m | time: 82.702s
[2K
| RMSProp | epoch: 019 | loss: 0.10239 - acc: 0.9752 -- iter: 2112/2235
[A[ATraining Step: 1327  | total loss: [1m[32m0.12258[0m[0m | time: 83.916s
[2K
| RMSProp | epoch: 019 | loss: 0.12258 - acc: 0.9652 -- iter: 2144/2235
[A[ATraining Step: 1328  | total loss: [1m[32m0.11216[0m[0m | time: 84.994s
[2K
| RMSProp | epoch: 019 | loss: 0.11216 - acc: 0.9687 -- iter: 2176/2235
[A[ATraining Step: 1329  | total loss: [1m[32m0.10218[0m[0m | time: 86.305s
[2K
| RMSProp | epoch: 019 | loss: 0.10218 - acc: 0.9718 -- iter: 2208/2235
[A[ATraining Step: 1330  | total loss: [1m[32m0.10100[0m[0m | time: 92.910s
[2K
| RMSProp | epoch: 019 | loss: 0.10100 - acc: 0.9715 | val_loss: 0.84057 - val_acc: 0.7639 -- iter: 2235/2235
--
Training Step: 1331  | total loss: [1m[32m0.10590[0m[0m | time: 1.221s
[2K
| RMSProp | epoch: 020 | loss: 0.10590 - acc: 0.9712 -- iter: 0032/2235
[A[ATraining Step: 1332  | total loss: [1m[32m0.09780[0m[0m | time: 2.553s
[2K
| RMSProp | epoch: 020 | loss: 0.09780 - acc: 0.9741 -- iter: 0064/2235
[A[ATraining Step: 1333  | total loss: [1m[32m0.09833[0m[0m | time: 3.918s
[2K
| RMSProp | epoch: 020 | loss: 0.09833 - acc: 0.9705 -- iter: 0096/2235
[A[ATraining Step: 1334  | total loss: [1m[32m0.08993[0m[0m | time: 5.306s
[2K
| RMSProp | epoch: 020 | loss: 0.08993 - acc: 0.9734 -- iter: 0128/2235
[A[ATraining Step: 1335  | total loss: [1m[32m0.08303[0m[0m | time: 6.360s
[2K
| RMSProp | epoch: 020 | loss: 0.08303 - acc: 0.9761 -- iter: 0160/2235
[A[ATraining Step: 1336  | total loss: [1m[32m0.08877[0m[0m | time: 7.617s
[2K
| RMSProp | epoch: 020 | loss: 0.08877 - acc: 0.9722 -- iter: 0192/2235
[A[ATraining Step: 1337  | total loss: [1m[32m0.08391[0m[0m | time: 8.869s
[2K
| RMSProp | epoch: 020 | loss: 0.08391 - acc: 0.9750 -- iter: 0224/2235
[A[ATraining Step: 1338  | total loss: [1m[32m0.07859[0m[0m | time: 10.152s
[2K
| RMSProp | epoch: 020 | loss: 0.07859 - acc: 0.9744 -- iter: 0256/2235
[A[ATraining Step: 1339  | total loss: [1m[32m0.14822[0m[0m | time: 11.377s
[2K
| RMSProp | epoch: 020 | loss: 0.14822 - acc: 0.9488 -- iter: 0288/2235
[A[ATraining Step: 1340  | total loss: [1m[32m0.16483[0m[0m | time: 12.806s
[2K
| RMSProp | epoch: 020 | loss: 0.16483 - acc: 0.9383 -- iter: 0320/2235
[A[ATraining Step: 1341  | total loss: [1m[32m0.15423[0m[0m | time: 14.251s
[2K
| RMSProp | epoch: 020 | loss: 0.15423 - acc: 0.9413 -- iter: 0352/2235
[A[ATraining Step: 1342  | total loss: [1m[32m0.15557[0m[0m | time: 15.718s
[2K
| RMSProp | epoch: 020 | loss: 0.15557 - acc: 0.9410 -- iter: 0384/2235
[A[ATraining Step: 1343  | total loss: [1m[32m0.15706[0m[0m | time: 16.963s
[2K
| RMSProp | epoch: 020 | loss: 0.15706 - acc: 0.9406 -- iter: 0416/2235
[A[ATraining Step: 1344  | total loss: [1m[32m0.15416[0m[0m | time: 18.232s
[2K
| RMSProp | epoch: 020 | loss: 0.15416 - acc: 0.9434 -- iter: 0448/2235
[A[ATraining Step: 1345  | total loss: [1m[32m0.14875[0m[0m | time: 19.536s
[2K
| RMSProp | epoch: 020 | loss: 0.14875 - acc: 0.9460 -- iter: 0480/2235
[A[ATraining Step: 1346  | total loss: [1m[32m0.14071[0m[0m | time: 20.582s
[2K
| RMSProp | epoch: 020 | loss: 0.14071 - acc: 0.9482 -- iter: 0512/2235
[A[ATraining Step: 1347  | total loss: [1m[32m0.14304[0m[0m | time: 21.783s
[2K
| RMSProp | epoch: 020 | loss: 0.14304 - acc: 0.9472 -- iter: 0544/2235
[A[ATraining Step: 1348  | total loss: [1m[32m0.14540[0m[0m | time: 22.866s
[2K
| RMSProp | epoch: 020 | loss: 0.14540 - acc: 0.9462 -- iter: 0576/2235
[A[ATraining Step: 1349  | total loss: [1m[32m0.13206[0m[0m | time: 23.922s
[2K
| RMSProp | epoch: 020 | loss: 0.13206 - acc: 0.9516 -- iter: 0608/2235
[A[ATraining Step: 1350  | total loss: [1m[32m0.11972[0m[0m | time: 25.322s
[2K
| RMSProp | epoch: 020 | loss: 0.11972 - acc: 0.9564 -- iter: 0640/2235
[A[ATraining Step: 1351  | total loss: [1m[32m0.10865[0m[0m | time: 26.670s
[2K
| RMSProp | epoch: 020 | loss: 0.10865 - acc: 0.9608 -- iter: 0672/2235
[A[ATraining Step: 1352  | total loss: [1m[32m0.09999[0m[0m | time: 27.938s
[2K
| RMSProp | epoch: 020 | loss: 0.09999 - acc: 0.9647 -- iter: 0704/2235
[A[ATraining Step: 1353  | total loss: [1m[32m0.11034[0m[0m | time: 29.251s
[2K
| RMSProp | epoch: 020 | loss: 0.11034 - acc: 0.9620 -- iter: 0736/2235
[A[ATraining Step: 1354  | total loss: [1m[32m0.11117[0m[0m | time: 30.643s
[2K
| RMSProp | epoch: 020 | loss: 0.11117 - acc: 0.9627 -- iter: 0768/2235
[A[ATraining Step: 1355  | total loss: [1m[32m0.11470[0m[0m | time: 32.057s
[2K
| RMSProp | epoch: 020 | loss: 0.11470 - acc: 0.9570 -- iter: 0800/2235
[A[ATraining Step: 1356  | total loss: [1m[32m0.10650[0m[0m | time: 33.303s
[2K
| RMSProp | epoch: 020 | loss: 0.10650 - acc: 0.9582 -- iter: 0832/2235
[A[ATraining Step: 1357  | total loss: [1m[32m0.09710[0m[0m | time: 35.194s
[2K
| RMSProp | epoch: 020 | loss: 0.09710 - acc: 0.9624 -- iter: 0864/2235
[A[ATraining Step: 1358  | total loss: [1m[32m0.09229[0m[0m | time: 36.858s
[2K
| RMSProp | epoch: 020 | loss: 0.09229 - acc: 0.9661 -- iter: 0896/2235
[A[ATraining Step: 1359  | total loss: [1m[32m0.08389[0m[0m | time: 38.040s
[2K
| RMSProp | epoch: 020 | loss: 0.08389 - acc: 0.9695 -- iter: 0928/2235
[A[ATraining Step: 1360  | total loss: [1m[32m0.09518[0m[0m | time: 39.267s
[2K
| RMSProp | epoch: 020 | loss: 0.09518 - acc: 0.9694 -- iter: 0960/2235
[A[ATraining Step: 1361  | total loss: [1m[32m0.08822[0m[0m | time: 40.479s
[2K
| RMSProp | epoch: 020 | loss: 0.08822 - acc: 0.9725 -- iter: 0992/2235
[A[ATraining Step: 1362  | total loss: [1m[32m0.08369[0m[0m | time: 41.762s
[2K
| RMSProp | epoch: 020 | loss: 0.08369 - acc: 0.9752 -- iter: 1024/2235
[A[ATraining Step: 1363  | total loss: [1m[32m0.07723[0m[0m | time: 43.076s
[2K
| RMSProp | epoch: 020 | loss: 0.07723 - acc: 0.9777 -- iter: 1056/2235
[A[ATraining Step: 1364  | total loss: [1m[32m0.07051[0m[0m | time: 44.328s
[2K
| RMSProp | epoch: 020 | loss: 0.07051 - acc: 0.9800 -- iter: 1088/2235
[A[ATraining Step: 1365  | total loss: [1m[32m0.07075[0m[0m | time: 45.635s
[2K
| RMSProp | epoch: 020 | loss: 0.07075 - acc: 0.9788 -- iter: 1120/2235
[A[ATraining Step: 1366  | total loss: [1m[32m0.06572[0m[0m | time: 46.839s
[2K
| RMSProp | epoch: 020 | loss: 0.06572 - acc: 0.9809 -- iter: 1152/2235
[A[ATraining Step: 1367  | total loss: [1m[32m0.05974[0m[0m | time: 48.224s
[2K
| RMSProp | epoch: 020 | loss: 0.05974 - acc: 0.9829 -- iter: 1184/2235
[A[ATraining Step: 1368  | total loss: [1m[32m0.05946[0m[0m | time: 49.511s
[2K
| RMSProp | epoch: 020 | loss: 0.05946 - acc: 0.9814 -- iter: 1216/2235
[A[ATraining Step: 1369  | total loss: [1m[32m0.09853[0m[0m | time: 50.767s
[2K
| RMSProp | epoch: 020 | loss: 0.09853 - acc: 0.9614 -- iter: 1248/2235
[A[ATraining Step: 1370  | total loss: [1m[32m0.13143[0m[0m | time: 51.832s
[2K
| RMSProp | epoch: 020 | loss: 0.13143 - acc: 0.9497 -- iter: 1280/2235
[A[ATraining Step: 1371  | total loss: [1m[32m0.14179[0m[0m | time: 53.044s
[2K
| RMSProp | epoch: 020 | loss: 0.14179 - acc: 0.9516 -- iter: 1312/2235
[A[ATraining Step: 1372  | total loss: [1m[32m0.13292[0m[0m | time: 54.245s
[2K
| RMSProp | epoch: 020 | loss: 0.13292 - acc: 0.9533 -- iter: 1344/2235
[A[ATraining Step: 1373  | total loss: [1m[32m0.13024[0m[0m | time: 55.382s
[2K
| RMSProp | epoch: 020 | loss: 0.13024 - acc: 0.9548 -- iter: 1376/2235
[A[ATraining Step: 1374  | total loss: [1m[32m0.11930[0m[0m | time: 56.696s
[2K
| RMSProp | epoch: 020 | loss: 0.11930 - acc: 0.9593 -- iter: 1408/2235
[A[ATraining Step: 1375  | total loss: [1m[32m0.10846[0m[0m | time: 58.010s
[2K
| RMSProp | epoch: 020 | loss: 0.10846 - acc: 0.9634 -- iter: 1440/2235
[A[ATraining Step: 1376  | total loss: [1m[32m0.10890[0m[0m | time: 59.321s
[2K
| RMSProp | epoch: 020 | loss: 0.10890 - acc: 0.9639 -- iter: 1472/2235
[A[ATraining Step: 1377  | total loss: [1m[32m0.10238[0m[0m | time: 60.573s
[2K
| RMSProp | epoch: 020 | loss: 0.10238 - acc: 0.9644 -- iter: 1504/2235
[A[ATraining Step: 1378  | total loss: [1m[32m0.10003[0m[0m | time: 61.838s
[2K
| RMSProp | epoch: 020 | loss: 0.10003 - acc: 0.9649 -- iter: 1536/2235
[A[ATraining Step: 1379  | total loss: [1m[32m0.10047[0m[0m | time: 63.276s
[2K
| RMSProp | epoch: 020 | loss: 0.10047 - acc: 0.9652 -- iter: 1568/2235
[A[ATraining Step: 1380  | total loss: [1m[32m0.09736[0m[0m | time: 64.651s
[2K
| RMSProp | epoch: 020 | loss: 0.09736 - acc: 0.9656 -- iter: 1600/2235
[A[ATraining Step: 1381  | total loss: [1m[32m0.09119[0m[0m | time: 65.734s
[2K
| RMSProp | epoch: 020 | loss: 0.09119 - acc: 0.9690 -- iter: 1632/2235
[A[ATraining Step: 1382  | total loss: [1m[32m0.08328[0m[0m | time: 66.926s
[2K
| RMSProp | epoch: 020 | loss: 0.08328 - acc: 0.9721 -- iter: 1664/2235
[A[ATraining Step: 1383  | total loss: [1m[32m0.07673[0m[0m | time: 68.210s
[2K
| RMSProp | epoch: 020 | loss: 0.07673 - acc: 0.9749 -- iter: 1696/2235
[A[ATraining Step: 1384  | total loss: [1m[32m0.07046[0m[0m | time: 69.534s
[2K
| RMSProp | epoch: 020 | loss: 0.07046 - acc: 0.9774 -- iter: 1728/2235
[A[ATraining Step: 1385  | total loss: [1m[32m0.06737[0m[0m | time: 70.809s
[2K
| RMSProp | epoch: 020 | loss: 0.06737 - acc: 0.9766 -- iter: 1760/2235
[A[ATraining Step: 1386  | total loss: [1m[32m0.07959[0m[0m | time: 72.174s
[2K
| RMSProp | epoch: 020 | loss: 0.07959 - acc: 0.9758 -- iter: 1792/2235
[A[ATraining Step: 1387  | total loss: [1m[32m0.07662[0m[0m | time: 73.559s
[2K
| RMSProp | epoch: 020 | loss: 0.07662 - acc: 0.9782 -- iter: 1824/2235
[A[ATraining Step: 1388  | total loss: [1m[32m0.11479[0m[0m | time: 74.843s
[2K
| RMSProp | epoch: 020 | loss: 0.11479 - acc: 0.9679 -- iter: 1856/2235
[A[ATraining Step: 1389  | total loss: [1m[32m0.11016[0m[0m | time: 76.120s
[2K
| RMSProp | epoch: 020 | loss: 0.11016 - acc: 0.9680 -- iter: 1888/2235
[A[ATraining Step: 1390  | total loss: [1m[32m0.10179[0m[0m | time: 77.296s
[2K
| RMSProp | epoch: 020 | loss: 0.10179 - acc: 0.9712 -- iter: 1920/2235
[A[ATraining Step: 1391  | total loss: [1m[32m0.09494[0m[0m | time: 78.700s
[2K
| RMSProp | epoch: 020 | loss: 0.09494 - acc: 0.9741 -- iter: 1952/2235
[A[ATraining Step: 1392  | total loss: [1m[32m0.08609[0m[0m | time: 80.141s
[2K
| RMSProp | epoch: 020 | loss: 0.08609 - acc: 0.9766 -- iter: 1984/2235
[A[ATraining Step: 1393  | total loss: [1m[32m0.08003[0m[0m | time: 81.197s
[2K
| RMSProp | epoch: 020 | loss: 0.08003 - acc: 0.9790 -- iter: 2016/2235
[A[ATraining Step: 1394  | total loss: [1m[32m0.07481[0m[0m | time: 82.355s
[2K
| RMSProp | epoch: 020 | loss: 0.07481 - acc: 0.9811 -- iter: 2048/2235
[A[ATraining Step: 1395  | total loss: [1m[32m0.06998[0m[0m | time: 83.535s
[2K
| RMSProp | epoch: 020 | loss: 0.06998 - acc: 0.9830 -- iter: 2080/2235
[A[ATraining Step: 1396  | total loss: [1m[32m0.07119[0m[0m | time: 84.806s
[2K
| RMSProp | epoch: 020 | loss: 0.07119 - acc: 0.9816 -- iter: 2112/2235
[A[ATraining Step: 1397  | total loss: [1m[32m0.06573[0m[0m | time: 85.941s
[2K
| RMSProp | epoch: 020 | loss: 0.06573 - acc: 0.9834 -- iter: 2144/2235
[A[ATraining Step: 1398  | total loss: [1m[32m0.06923[0m[0m | time: 87.244s
[2K
| RMSProp | epoch: 020 | loss: 0.06923 - acc: 0.9819 -- iter: 2176/2235
[A[ATraining Step: 1399  | total loss: [1m[32m0.06650[0m[0m | time: 88.635s
[2K
| RMSProp | epoch: 020 | loss: 0.06650 - acc: 0.9806 -- iter: 2208/2235
[A[ATraining Step: 1400  | total loss: [1m[32m0.06269[0m[0m | time: 95.544s
[2K
| RMSProp | epoch: 020 | loss: 0.06269 - acc: 0.9826 | val_loss: 0.99853 - val_acc: 0.7511 -- iter: 2235/2235
--
Training Step: 1401  | total loss: [1m[32m0.05678[0m[0m | time: 1.120s
[2K
| RMSProp | epoch: 021 | loss: 0.05678 - acc: 0.9843 -- iter: 0032/2235
[A[ATraining Step: 1402  | total loss: [1m[32m0.05148[0m[0m | time: 2.346s
[2K
| RMSProp | epoch: 021 | loss: 0.05148 - acc: 0.9859 -- iter: 0064/2235
[A[ATraining Step: 1403  | total loss: [1m[32m0.05968[0m[0m | time: 3.685s
[2K
| RMSProp | epoch: 021 | loss: 0.05968 - acc: 0.9842 -- iter: 0096/2235
[A[ATraining Step: 1404  | total loss: [1m[32m0.08571[0m[0m | time: 5.041s
[2K
| RMSProp | epoch: 021 | loss: 0.08571 - acc: 0.9795 -- iter: 0128/2235
[A[ATraining Step: 1405  | total loss: [1m[32m0.09218[0m[0m | time: 6.395s
[2K
| RMSProp | epoch: 021 | loss: 0.09218 - acc: 0.9784 -- iter: 0160/2235
[A[ATraining Step: 1406  | total loss: [1m[32m0.08379[0m[0m | time: 7.697s
[2K
| RMSProp | epoch: 021 | loss: 0.08379 - acc: 0.9806 -- iter: 0192/2235
[A[ATraining Step: 1407  | total loss: [1m[32m0.08007[0m[0m | time: 8.957s
[2K
| RMSProp | epoch: 021 | loss: 0.08007 - acc: 0.9825 -- iter: 0224/2235
[A[ATraining Step: 1408  | total loss: [1m[32m0.09181[0m[0m | time: 10.293s
[2K
| RMSProp | epoch: 021 | loss: 0.09181 - acc: 0.9780 -- iter: 0256/2235
[A[ATraining Step: 1409  | total loss: [1m[32m0.10790[0m[0m | time: 11.569s
[2K
| RMSProp | epoch: 021 | loss: 0.10790 - acc: 0.9740 -- iter: 0288/2235
[A[ATraining Step: 1410  | total loss: [1m[32m0.10182[0m[0m | time: 12.923s
[2K
| RMSProp | epoch: 021 | loss: 0.10182 - acc: 0.9766 -- iter: 0320/2235
[A[ATraining Step: 1411  | total loss: [1m[32m0.09375[0m[0m | time: 14.123s
[2K
| RMSProp | epoch: 021 | loss: 0.09375 - acc: 0.9789 -- iter: 0352/2235
[A[ATraining Step: 1412  | total loss: [1m[32m0.08511[0m[0m | time: 15.158s
[2K
| RMSProp | epoch: 021 | loss: 0.08511 - acc: 0.9810 -- iter: 0384/2235
[A[ATraining Step: 1413  | total loss: [1m[32m0.08171[0m[0m | time: 16.373s
[2K
| RMSProp | epoch: 021 | loss: 0.08171 - acc: 0.9798 -- iter: 0416/2235
[A[ATraining Step: 1414  | total loss: [1m[32m0.09716[0m[0m | time: 17.608s
[2K
| RMSProp | epoch: 021 | loss: 0.09716 - acc: 0.9724 -- iter: 0448/2235
[A[ATraining Step: 1415  | total loss: [1m[32m0.09311[0m[0m | time: 18.818s
[2K
| RMSProp | epoch: 021 | loss: 0.09311 - acc: 0.9689 -- iter: 0480/2235
[A[ATraining Step: 1416  | total loss: [1m[32m0.08510[0m[0m | time: 20.024s
[2K
| RMSProp | epoch: 021 | loss: 0.08510 - acc: 0.9721 -- iter: 0512/2235
[A[ATraining Step: 1417  | total loss: [1m[32m0.07755[0m[0m | time: 21.379s
[2K
| RMSProp | epoch: 021 | loss: 0.07755 - acc: 0.9748 -- iter: 0544/2235
[A[ATraining Step: 1418  | total loss: [1m[32m0.07058[0m[0m | time: 22.777s
[2K
| RMSProp | epoch: 021 | loss: 0.07058 - acc: 0.9774 -- iter: 0576/2235
[A[ATraining Step: 1419  | total loss: [1m[32m0.06417[0m[0m | time: 23.851s
[2K
| RMSProp | epoch: 021 | loss: 0.06417 - acc: 0.9796 -- iter: 0608/2235
[A[ATraining Step: 1420  | total loss: [1m[32m0.07464[0m[0m | time: 25.034s
[2K
| RMSProp | epoch: 021 | loss: 0.07464 - acc: 0.9780 -- iter: 0640/2235
[A[ATraining Step: 1421  | total loss: [1m[32m0.06949[0m[0m | time: 26.286s
[2K
| RMSProp | epoch: 021 | loss: 0.06949 - acc: 0.9802 -- iter: 0672/2235
[A[ATraining Step: 1422  | total loss: [1m[32m0.06438[0m[0m | time: 27.621s
[2K
| RMSProp | epoch: 021 | loss: 0.06438 - acc: 0.9821 -- iter: 0704/2235
[A[ATraining Step: 1423  | total loss: [1m[32m0.05988[0m[0m | time: 29.047s
[2K
| RMSProp | epoch: 021 | loss: 0.05988 - acc: 0.9839 -- iter: 0736/2235
[A[ATraining Step: 1424  | total loss: [1m[32m0.05598[0m[0m | time: 30.499s
[2K
| RMSProp | epoch: 021 | loss: 0.05598 - acc: 0.9855 -- iter: 0768/2235
[A[ATraining Step: 1425  | total loss: [1m[32m0.07642[0m[0m | time: 31.876s
[2K
| RMSProp | epoch: 021 | loss: 0.07642 - acc: 0.9807 -- iter: 0800/2235
[A[ATraining Step: 1426  | total loss: [1m[32m0.09804[0m[0m | time: 33.276s
[2K
| RMSProp | epoch: 021 | loss: 0.09804 - acc: 0.9733 -- iter: 0832/2235
[A[ATraining Step: 1427  | total loss: [1m[32m0.09872[0m[0m | time: 34.556s
[2K
| RMSProp | epoch: 021 | loss: 0.09872 - acc: 0.9728 -- iter: 0864/2235
[A[ATraining Step: 1428  | total loss: [1m[32m0.09384[0m[0m | time: 36.001s
[2K
| RMSProp | epoch: 021 | loss: 0.09384 - acc: 0.9724 -- iter: 0896/2235
[A[ATraining Step: 1429  | total loss: [1m[32m0.09599[0m[0m | time: 37.444s
[2K
| RMSProp | epoch: 021 | loss: 0.09599 - acc: 0.9689 -- iter: 0928/2235
[A[ATraining Step: 1430  | total loss: [1m[32m0.08964[0m[0m | time: 38.750s
[2K
| RMSProp | epoch: 021 | loss: 0.08964 - acc: 0.9720 -- iter: 0960/2235
[A[ATraining Step: 1431  | total loss: [1m[32m0.08646[0m[0m | time: 39.947s
[2K
| RMSProp | epoch: 021 | loss: 0.08646 - acc: 0.9717 -- iter: 0992/2235
[A[ATraining Step: 1432  | total loss: [1m[32m0.07892[0m[0m | time: 40.982s
[2K
| RMSProp | epoch: 021 | loss: 0.07892 - acc: 0.9745 -- iter: 1024/2235
[A[ATraining Step: 1433  | total loss: [1m[32m0.07201[0m[0m | time: 42.005s
[2K
| RMSProp | epoch: 021 | loss: 0.07201 - acc: 0.9771 -- iter: 1056/2235
[A[ATraining Step: 1434  | total loss: [1m[32m0.07775[0m[0m | time: 43.016s
[2K
| RMSProp | epoch: 021 | loss: 0.07775 - acc: 0.9763 -- iter: 1088/2235
[A[ATraining Step: 1435  | total loss: [1m[32m0.07657[0m[0m | time: 43.977s
[2K
| RMSProp | epoch: 021 | loss: 0.07657 - acc: 0.9755 -- iter: 1120/2235
[A[ATraining Step: 1436  | total loss: [1m[32m0.07875[0m[0m | time: 44.969s
[2K
| RMSProp | epoch: 021 | loss: 0.07875 - acc: 0.9748 -- iter: 1152/2235
[A[ATraining Step: 1437  | total loss: [1m[32m0.07161[0m[0m | time: 46.059s
[2K
| RMSProp | epoch: 021 | loss: 0.07161 - acc: 0.9773 -- iter: 1184/2235
[A[ATraining Step: 1438  | total loss: [1m[32m0.07046[0m[0m | time: 47.157s
[2K
| RMSProp | epoch: 021 | loss: 0.07046 - acc: 0.9765 -- iter: 1216/2235
[A[ATraining Step: 1439  | total loss: [1m[32m0.08301[0m[0m | time: 48.269s
[2K
| RMSProp | epoch: 021 | loss: 0.08301 - acc: 0.9726 -- iter: 1248/2235
[A[ATraining Step: 1440  | total loss: [1m[32m0.07969[0m[0m | time: 49.364s
[2K
| RMSProp | epoch: 021 | loss: 0.07969 - acc: 0.9753 -- iter: 1280/2235
[A[ATraining Step: 1441  | total loss: [1m[32m0.09173[0m[0m | time: 50.467s
[2K
| RMSProp | epoch: 021 | loss: 0.09173 - acc: 0.9747 -- iter: 1312/2235
[A[ATraining Step: 1442  | total loss: [1m[32m0.10203[0m[0m | time: 51.564s
[2K
| RMSProp | epoch: 021 | loss: 0.10203 - acc: 0.9678 -- iter: 1344/2235
[A[ATraining Step: 1443  | total loss: [1m[32m0.11123[0m[0m | time: 52.626s
[2K
| RMSProp | epoch: 021 | loss: 0.11123 - acc: 0.9648 -- iter: 1376/2235
[A[ATraining Step: 1444  | total loss: [1m[32m0.10488[0m[0m | time: 53.670s
[2K
| RMSProp | epoch: 021 | loss: 0.10488 - acc: 0.9683 -- iter: 1408/2235
[A[ATraining Step: 1445  | total loss: [1m[32m0.11172[0m[0m | time: 54.722s
[2K
| RMSProp | epoch: 021 | loss: 0.11172 - acc: 0.9684 -- iter: 1440/2235
[A[ATraining Step: 1446  | total loss: [1m[32m0.10960[0m[0m | time: 55.765s
[2K
| RMSProp | epoch: 021 | loss: 0.10960 - acc: 0.9684 -- iter: 1472/2235
[A[ATraining Step: 1447  | total loss: [1m[32m0.10415[0m[0m | time: 56.813s
[2K
| RMSProp | epoch: 021 | loss: 0.10415 - acc: 0.9684 -- iter: 1504/2235
[A[ATraining Step: 1448  | total loss: [1m[32m0.11576[0m[0m | time: 57.907s
[2K
| RMSProp | epoch: 021 | loss: 0.11576 - acc: 0.9653 -- iter: 1536/2235
[A[ATraining Step: 1449  | total loss: [1m[32m0.10877[0m[0m | time: 58.951s
[2K
| RMSProp | epoch: 021 | loss: 0.10877 - acc: 0.9657 -- iter: 1568/2235
[A[ATraining Step: 1450  | total loss: [1m[32m0.09863[0m[0m | time: 60.009s
[2K
| RMSProp | epoch: 021 | loss: 0.09863 - acc: 0.9691 -- iter: 1600/2235
[A[ATraining Step: 1451  | total loss: [1m[32m0.09778[0m[0m | time: 61.030s
[2K
| RMSProp | epoch: 021 | loss: 0.09778 - acc: 0.9691 -- iter: 1632/2235
[A[ATraining Step: 1452  | total loss: [1m[32m0.10265[0m[0m | time: 62.023s
[2K
| RMSProp | epoch: 021 | loss: 0.10265 - acc: 0.9659 -- iter: 1664/2235
[A[ATraining Step: 1453  | total loss: [1m[32m0.09351[0m[0m | time: 63.080s
[2K
| RMSProp | epoch: 021 | loss: 0.09351 - acc: 0.9693 -- iter: 1696/2235
[A[ATraining Step: 1454  | total loss: [1m[32m0.08485[0m[0m | time: 64.141s
[2K
| RMSProp | epoch: 021 | loss: 0.08485 - acc: 0.9724 -- iter: 1728/2235
[A[ATraining Step: 1455  | total loss: [1m[32m0.07743[0m[0m | time: 65.651s
[2K
| RMSProp | epoch: 021 | loss: 0.07743 - acc: 0.9752 -- iter: 1760/2235
[A[ATraining Step: 1456  | total loss: [1m[32m0.07093[0m[0m | time: 67.014s
[2K
| RMSProp | epoch: 021 | loss: 0.07093 - acc: 0.9776 -- iter: 1792/2235
[A[ATraining Step: 1457  | total loss: [1m[32m0.07102[0m[0m | time: 68.237s
[2K
| RMSProp | epoch: 021 | loss: 0.07102 - acc: 0.9736 -- iter: 1824/2235
[A[ATraining Step: 1458  | total loss: [1m[32m0.07970[0m[0m | time: 69.474s
[2K
| RMSProp | epoch: 021 | loss: 0.07970 - acc: 0.9669 -- iter: 1856/2235
[A[ATraining Step: 1459  | total loss: [1m[32m0.09700[0m[0m | time: 70.778s
[2K
| RMSProp | epoch: 021 | loss: 0.09700 - acc: 0.9608 -- iter: 1888/2235
[A[ATraining Step: 1460  | total loss: [1m[32m0.08989[0m[0m | time: 72.088s
[2K
| RMSProp | epoch: 021 | loss: 0.08989 - acc: 0.9647 -- iter: 1920/2235
[A[ATraining Step: 1461  | total loss: [1m[32m0.08212[0m[0m | time: 73.429s
[2K
| RMSProp | epoch: 021 | loss: 0.08212 - acc: 0.9683 -- iter: 1952/2235
[A[ATraining Step: 1462  | total loss: [1m[32m0.07469[0m[0m | time: 74.786s
[2K
| RMSProp | epoch: 021 | loss: 0.07469 - acc: 0.9714 -- iter: 1984/2235
[A[ATraining Step: 1463  | total loss: [1m[32m0.06858[0m[0m | time: 76.113s
[2K
| RMSProp | epoch: 021 | loss: 0.06858 - acc: 0.9743 -- iter: 2016/2235
[A[ATraining Step: 1464  | total loss: [1m[32m0.06281[0m[0m | time: 77.471s
[2K
| RMSProp | epoch: 021 | loss: 0.06281 - acc: 0.9769 -- iter: 2048/2235
[A[ATraining Step: 1465  | total loss: [1m[32m0.06621[0m[0m | time: 78.666s
[2K
| RMSProp | epoch: 021 | loss: 0.06621 - acc: 0.9761 -- iter: 2080/2235
[A[ATraining Step: 1466  | total loss: [1m[32m0.07945[0m[0m | time: 79.921s
[2K
| RMSProp | epoch: 021 | loss: 0.07945 - acc: 0.9722 -- iter: 2112/2235
[A[ATraining Step: 1467  | total loss: [1m[32m0.08316[0m[0m | time: 81.261s
[2K
| RMSProp | epoch: 021 | loss: 0.08316 - acc: 0.9719 -- iter: 2144/2235
[A[ATraining Step: 1468  | total loss: [1m[32m0.08846[0m[0m | time: 82.514s
[2K
| RMSProp | epoch: 021 | loss: 0.08846 - acc: 0.9715 -- iter: 2176/2235
[A[ATraining Step: 1469  | total loss: [1m[32m0.08221[0m[0m | time: 83.764s
[2K
| RMSProp | epoch: 021 | loss: 0.08221 - acc: 0.9744 -- iter: 2208/2235
[A[ATraining Step: 1470  | total loss: [1m[32m0.07768[0m[0m | time: 90.519s
[2K
| RMSProp | epoch: 021 | loss: 0.07768 - acc: 0.9738 | val_loss: 0.82950 - val_acc: 0.7382 -- iter: 2235/2235
--
Training Step: 1471  | total loss: [1m[32m0.10435[0m[0m | time: 1.342s
[2K
| RMSProp | epoch: 022 | loss: 0.10435 - acc: 0.9733 -- iter: 0032/2235
[A[ATraining Step: 1472  | total loss: [1m[32m0.11911[0m[0m | time: 2.572s
[2K
| RMSProp | epoch: 022 | loss: 0.11911 - acc: 0.9666 -- iter: 0064/2235
[A[ATraining Step: 1473  | total loss: [1m[32m0.10959[0m[0m | time: 3.819s
[2K
| RMSProp | epoch: 022 | loss: 0.10959 - acc: 0.9700 -- iter: 0096/2235
[A[ATraining Step: 1474  | total loss: [1m[32m0.10115[0m[0m | time: 5.013s
[2K
| RMSProp | epoch: 022 | loss: 0.10115 - acc: 0.9730 -- iter: 0128/2235
[A[ATraining Step: 1475  | total loss: [1m[32m0.09531[0m[0m | time: 6.371s
[2K
| RMSProp | epoch: 022 | loss: 0.09531 - acc: 0.9725 -- iter: 0160/2235
[A[ATraining Step: 1476  | total loss: [1m[32m0.09079[0m[0m | time: 7.729s
[2K
| RMSProp | epoch: 022 | loss: 0.09079 - acc: 0.9722 -- iter: 0192/2235
[A[ATraining Step: 1477  | total loss: [1m[32m0.09602[0m[0m | time: 9.010s
[2K
| RMSProp | epoch: 022 | loss: 0.09602 - acc: 0.9718 -- iter: 0224/2235
[A[ATraining Step: 1478  | total loss: [1m[32m0.08872[0m[0m | time: 10.303s
[2K
| RMSProp | epoch: 022 | loss: 0.08872 - acc: 0.9746 -- iter: 0256/2235
[A[ATraining Step: 1479  | total loss: [1m[32m0.08703[0m[0m | time: 11.718s
[2K
| RMSProp | epoch: 022 | loss: 0.08703 - acc: 0.9740 -- iter: 0288/2235
[A[ATraining Step: 1480  | total loss: [1m[32m0.08022[0m[0m | time: 12.864s
[2K
| RMSProp | epoch: 022 | loss: 0.08022 - acc: 0.9766 -- iter: 0320/2235
[A[ATraining Step: 1481  | total loss: [1m[32m0.07988[0m[0m | time: 14.135s
[2K
| RMSProp | epoch: 022 | loss: 0.07988 - acc: 0.9759 -- iter: 0352/2235
[A[ATraining Step: 1482  | total loss: [1m[32m0.07381[0m[0m | time: 15.467s
[2K
| RMSProp | epoch: 022 | loss: 0.07381 - acc: 0.9783 -- iter: 0384/2235
[A[ATraining Step: 1483  | total loss: [1m[32m0.07069[0m[0m | time: 16.734s
[2K
| RMSProp | epoch: 022 | loss: 0.07069 - acc: 0.9804 -- iter: 0416/2235
[A[ATraining Step: 1484  | total loss: [1m[32m0.06865[0m[0m | time: 17.988s
[2K
| RMSProp | epoch: 022 | loss: 0.06865 - acc: 0.9793 -- iter: 0448/2235
[A[ATraining Step: 1485  | total loss: [1m[32m0.06709[0m[0m | time: 19.200s
[2K
| RMSProp | epoch: 022 | loss: 0.06709 - acc: 0.9782 -- iter: 0480/2235
[A[ATraining Step: 1486  | total loss: [1m[32m0.06249[0m[0m | time: 20.608s
[2K
| RMSProp | epoch: 022 | loss: 0.06249 - acc: 0.9804 -- iter: 0512/2235
[A[ATraining Step: 1487  | total loss: [1m[32m0.07153[0m[0m | time: 22.039s
[2K
| RMSProp | epoch: 022 | loss: 0.07153 - acc: 0.9761 -- iter: 0544/2235
[A[ATraining Step: 1488  | total loss: [1m[32m0.10580[0m[0m | time: 23.295s
[2K
| RMSProp | epoch: 022 | loss: 0.10580 - acc: 0.9660 -- iter: 0576/2235
[A[ATraining Step: 1489  | total loss: [1m[32m0.09681[0m[0m | time: 24.592s
[2K
| RMSProp | epoch: 022 | loss: 0.09681 - acc: 0.9694 -- iter: 0608/2235
[A[ATraining Step: 1490  | total loss: [1m[32m0.10099[0m[0m | time: 25.720s
[2K
| RMSProp | epoch: 022 | loss: 0.10099 - acc: 0.9693 -- iter: 0640/2235
[A[ATraining Step: 1491  | total loss: [1m[32m0.10259[0m[0m | time: 26.931s
[2K
| RMSProp | epoch: 022 | loss: 0.10259 - acc: 0.9650 -- iter: 0672/2235
[A[ATraining Step: 1492  | total loss: [1m[32m0.09364[0m[0m | time: 28.290s
[2K
| RMSProp | epoch: 022 | loss: 0.09364 - acc: 0.9685 -- iter: 0704/2235
[A[ATraining Step: 1493  | total loss: [1m[32m0.09034[0m[0m | time: 29.740s
[2K
| RMSProp | epoch: 022 | loss: 0.09034 - acc: 0.9685 -- iter: 0736/2235
[A[ATraining Step: 1494  | total loss: [1m[32m0.09858[0m[0m | time: 31.053s
[2K
| RMSProp | epoch: 022 | loss: 0.09858 - acc: 0.9654 -- iter: 0768/2235
[A[ATraining Step: 1495  | total loss: [1m[32m0.09373[0m[0m | time: 32.506s
[2K
| RMSProp | epoch: 022 | loss: 0.09373 - acc: 0.9689 -- iter: 0800/2235
[A[ATraining Step: 1496  | total loss: [1m[32m0.09557[0m[0m | time: 33.912s
[2K
| RMSProp | epoch: 022 | loss: 0.09557 - acc: 0.9657 -- iter: 0832/2235
[A[ATraining Step: 1497  | total loss: [1m[32m0.09224[0m[0m | time: 35.184s
[2K
| RMSProp | epoch: 022 | loss: 0.09224 - acc: 0.9629 -- iter: 0864/2235
[A[ATraining Step: 1498  | total loss: [1m[32m0.08759[0m[0m | time: 36.587s
[2K
| RMSProp | epoch: 022 | loss: 0.08759 - acc: 0.9635 -- iter: 0896/2235
[A[ATraining Step: 1499  | total loss: [1m[32m0.08479[0m[0m | time: 37.903s
[2K
| RMSProp | epoch: 022 | loss: 0.08479 - acc: 0.9640 -- iter: 0928/2235
[A[ATraining Step: 1500  | total loss: [1m[32m0.08333[0m[0m | time: 39.257s
[2K
| RMSProp | epoch: 022 | loss: 0.08333 - acc: 0.9645 -- iter: 0960/2235
[A[ATraining Step: 1501  | total loss: [1m[32m0.08208[0m[0m | time: 40.455s
[2K
| RMSProp | epoch: 022 | loss: 0.08208 - acc: 0.9649 -- iter: 0992/2235
[A[ATraining Step: 1502  | total loss: [1m[32m0.08253[0m[0m | time: 41.539s
[2K
| RMSProp | epoch: 022 | loss: 0.08253 - acc: 0.9653 -- iter: 1024/2235
[A[ATraining Step: 1503  | total loss: [1m[32m0.07587[0m[0m | time: 42.530s
[2K
| RMSProp | epoch: 022 | loss: 0.07587 - acc: 0.9688 -- iter: 1056/2235
[A[ATraining Step: 1504  | total loss: [1m[32m0.06984[0m[0m | time: 43.560s
[2K
| RMSProp | epoch: 022 | loss: 0.06984 - acc: 0.9719 -- iter: 1088/2235
[A[ATraining Step: 1505  | total loss: [1m[32m0.06343[0m[0m | time: 44.594s
[2K
| RMSProp | epoch: 022 | loss: 0.06343 - acc: 0.9747 -- iter: 1120/2235
[A[ATraining Step: 1506  | total loss: [1m[32m0.05761[0m[0m | time: 45.711s
[2K
| RMSProp | epoch: 022 | loss: 0.05761 - acc: 0.9772 -- iter: 1152/2235
[A[ATraining Step: 1507  | total loss: [1m[32m0.06184[0m[0m | time: 46.759s
[2K
| RMSProp | epoch: 022 | loss: 0.06184 - acc: 0.9764 -- iter: 1184/2235
[A[ATraining Step: 1508  | total loss: [1m[32m0.08135[0m[0m | time: 47.862s
[2K
| RMSProp | epoch: 022 | loss: 0.08135 - acc: 0.9694 -- iter: 1216/2235
[A[ATraining Step: 1509  | total loss: [1m[32m0.12068[0m[0m | time: 48.880s
[2K
| RMSProp | epoch: 022 | loss: 0.12068 - acc: 0.9631 -- iter: 1248/2235
[A[ATraining Step: 1510  | total loss: [1m[32m0.11353[0m[0m | time: 49.935s
[2K
| RMSProp | epoch: 022 | loss: 0.11353 - acc: 0.9636 -- iter: 1280/2235
[A[ATraining Step: 1511  | total loss: [1m[32m0.10681[0m[0m | time: 50.919s
[2K
| RMSProp | epoch: 022 | loss: 0.10681 - acc: 0.9673 -- iter: 1312/2235
[A[ATraining Step: 1512  | total loss: [1m[32m0.09697[0m[0m | time: 51.993s
[2K
| RMSProp | epoch: 022 | loss: 0.09697 - acc: 0.9705 -- iter: 1344/2235
[A[ATraining Step: 1513  | total loss: [1m[32m0.09178[0m[0m | time: 53.053s
[2K
| RMSProp | epoch: 022 | loss: 0.09178 - acc: 0.9704 -- iter: 1376/2235
[A[ATraining Step: 1514  | total loss: [1m[32m0.09189[0m[0m | time: 54.330s
[2K
| RMSProp | epoch: 022 | loss: 0.09189 - acc: 0.9702 -- iter: 1408/2235
[A[ATraining Step: 1515  | total loss: [1m[32m0.11325[0m[0m | time: 55.534s
[2K
| RMSProp | epoch: 022 | loss: 0.11325 - acc: 0.9669 -- iter: 1440/2235
[A[ATraining Step: 1516  | total loss: [1m[32m0.13010[0m[0m | time: 56.662s
[2K
| RMSProp | epoch: 022 | loss: 0.13010 - acc: 0.9609 -- iter: 1472/2235
[A[ATraining Step: 1517  | total loss: [1m[32m0.11919[0m[0m | time: 57.448s
[2K
| RMSProp | epoch: 022 | loss: 0.11919 - acc: 0.9648 -- iter: 1504/2235
[A[ATraining Step: 1518  | total loss: [1m[32m0.11082[0m[0m | time: 58.453s
[2K
| RMSProp | epoch: 022 | loss: 0.11082 - acc: 0.9652 -- iter: 1536/2235
[A[ATraining Step: 1519  | total loss: [1m[32m0.10600[0m[0m | time: 59.483s
[2K
| RMSProp | epoch: 022 | loss: 0.10600 - acc: 0.9655 -- iter: 1568/2235
[A[ATraining Step: 1520  | total loss: [1m[32m0.10043[0m[0m | time: 60.469s
[2K
| RMSProp | epoch: 022 | loss: 0.10043 - acc: 0.9659 -- iter: 1600/2235
[A[ATraining Step: 1521  | total loss: [1m[32m0.09456[0m[0m | time: 61.530s
[2K
| RMSProp | epoch: 022 | loss: 0.09456 - acc: 0.9661 -- iter: 1632/2235
[A[ATraining Step: 1522  | total loss: [1m[32m0.09175[0m[0m | time: 62.584s
[2K
| RMSProp | epoch: 022 | loss: 0.09175 - acc: 0.9664 -- iter: 1664/2235
[A[ATraining Step: 1523  | total loss: [1m[32m0.08406[0m[0m | time: 63.570s
[2K
| RMSProp | epoch: 022 | loss: 0.08406 - acc: 0.9698 -- iter: 1696/2235
[A[ATraining Step: 1524  | total loss: [1m[32m0.07619[0m[0m | time: 64.724s
[2K
| RMSProp | epoch: 022 | loss: 0.07619 - acc: 0.9728 -- iter: 1728/2235
[A[ATraining Step: 1525  | total loss: [1m[32m0.06912[0m[0m | time: 65.807s
[2K
| RMSProp | epoch: 022 | loss: 0.06912 - acc: 0.9755 -- iter: 1760/2235
[A[ATraining Step: 1526  | total loss: [1m[32m0.06375[0m[0m | time: 66.798s
[2K
| RMSProp | epoch: 022 | loss: 0.06375 - acc: 0.9780 -- iter: 1792/2235
[A[ATraining Step: 1527  | total loss: [1m[32m0.05802[0m[0m | time: 67.739s
[2K
| RMSProp | epoch: 022 | loss: 0.05802 - acc: 0.9802 -- iter: 1824/2235
[A[ATraining Step: 1528  | total loss: [1m[32m0.05271[0m[0m | time: 68.700s
[2K
| RMSProp | epoch: 022 | loss: 0.05271 - acc: 0.9821 -- iter: 1856/2235
[A[ATraining Step: 1529  | total loss: [1m[32m0.05131[0m[0m | time: 69.633s
[2K
| RMSProp | epoch: 022 | loss: 0.05131 - acc: 0.9808 -- iter: 1888/2235
[A[ATraining Step: 1530  | total loss: [1m[32m0.05057[0m[0m | time: 70.643s
[2K
| RMSProp | epoch: 022 | loss: 0.05057 - acc: 0.9796 -- iter: 1920/2235
[A[ATraining Step: 1531  | total loss: [1m[32m0.05446[0m[0m | time: 71.703s
[2K
| RMSProp | epoch: 022 | loss: 0.05446 - acc: 0.9754 -- iter: 1952/2235
[A[ATraining Step: 1532  | total loss: [1m[32m0.05862[0m[0m | time: 72.827s
[2K
| RMSProp | epoch: 022 | loss: 0.05862 - acc: 0.9747 -- iter: 1984/2235
[A[ATraining Step: 1533  | total loss: [1m[32m0.05399[0m[0m | time: 73.720s
[2K
| RMSProp | epoch: 022 | loss: 0.05399 - acc: 0.9773 -- iter: 2016/2235
[A[ATraining Step: 1534  | total loss: [1m[32m0.06202[0m[0m | time: 74.807s
[2K
| RMSProp | epoch: 022 | loss: 0.06202 - acc: 0.9733 -- iter: 2048/2235
[A[ATraining Step: 1535  | total loss: [1m[32m0.09324[0m[0m | time: 76.040s
[2K
| RMSProp | epoch: 022 | loss: 0.09324 - acc: 0.9728 -- iter: 2080/2235
[A[ATraining Step: 1536  | total loss: [1m[32m0.08476[0m[0m | time: 76.996s
[2K
| RMSProp | epoch: 022 | loss: 0.08476 - acc: 0.9755 -- iter: 2112/2235
[A[ATraining Step: 1537  | total loss: [1m[32m0.08408[0m[0m | time: 77.984s
[2K
| RMSProp | epoch: 022 | loss: 0.08408 - acc: 0.9749 -- iter: 2144/2235
[A[ATraining Step: 1538  | total loss: [1m[32m0.08984[0m[0m | time: 79.031s
[2K
| RMSProp | epoch: 022 | loss: 0.08984 - acc: 0.9711 -- iter: 2176/2235
[A[ATraining Step: 1539  | total loss: [1m[32m0.08970[0m[0m | time: 80.044s
[2K
| RMSProp | epoch: 022 | loss: 0.08970 - acc: 0.9709 -- iter: 2208/2235
[A[ATraining Step: 1540  | total loss: [1m[32m0.08399[0m[0m | time: 86.598s
[2K
| RMSProp | epoch: 022 | loss: 0.08399 - acc: 0.9707 | val_loss: 0.98829 - val_acc: 0.7525 -- iter: 2235/2235
--
Training Step: 1541  | total loss: [1m[32m0.07640[0m[0m | time: 1.280s
[2K
| RMSProp | epoch: 023 | loss: 0.07640 - acc: 0.9736 -- iter: 0032/2235
[A[ATraining Step: 1542  | total loss: [1m[32m0.06905[0m[0m | time: 2.398s
[2K
| RMSProp | epoch: 023 | loss: 0.06905 - acc: 0.9762 -- iter: 0064/2235
[A[ATraining Step: 1543  | total loss: [1m[32m0.06406[0m[0m | time: 3.568s
[2K
| RMSProp | epoch: 023 | loss: 0.06406 - acc: 0.9786 -- iter: 0096/2235
[A[ATraining Step: 1544  | total loss: [1m[32m0.05839[0m[0m | time: 4.825s
[2K
| RMSProp | epoch: 023 | loss: 0.05839 - acc: 0.9808 -- iter: 0128/2235
[A[ATraining Step: 1545  | total loss: [1m[32m0.05287[0m[0m | time: 5.984s
[2K
| RMSProp | epoch: 023 | loss: 0.05287 - acc: 0.9827 -- iter: 0160/2235
[A[ATraining Step: 1546  | total loss: [1m[32m0.04781[0m[0m | time: 7.243s
[2K
| RMSProp | epoch: 023 | loss: 0.04781 - acc: 0.9844 -- iter: 0192/2235
[A[ATraining Step: 1547  | total loss: [1m[32m0.04346[0m[0m | time: 8.528s
[2K
| RMSProp | epoch: 023 | loss: 0.04346 - acc: 0.9860 -- iter: 0224/2235
[A[ATraining Step: 1548  | total loss: [1m[32m0.04994[0m[0m | time: 9.752s
[2K
| RMSProp | epoch: 023 | loss: 0.04994 - acc: 0.9843 -- iter: 0256/2235
[A[ATraining Step: 1549  | total loss: [1m[32m0.06462[0m[0m | time: 11.305s
[2K
| RMSProp | epoch: 023 | loss: 0.06462 - acc: 0.9765 -- iter: 0288/2235
[A[ATraining Step: 1550  | total loss: [1m[32m0.06267[0m[0m | time: 12.653s
[2K
| RMSProp | epoch: 023 | loss: 0.06267 - acc: 0.9788 -- iter: 0320/2235
[A[ATraining Step: 1551  | total loss: [1m[32m0.07231[0m[0m | time: 13.943s
[2K
| RMSProp | epoch: 023 | loss: 0.07231 - acc: 0.9716 -- iter: 0352/2235
[A[ATraining Step: 1552  | total loss: [1m[32m0.07149[0m[0m | time: 15.196s
[2K
| RMSProp | epoch: 023 | loss: 0.07149 - acc: 0.9713 -- iter: 0384/2235
[A[ATraining Step: 1553  | total loss: [1m[32m0.10226[0m[0m | time: 16.501s
[2K
| RMSProp | epoch: 023 | loss: 0.10226 - acc: 0.9679 -- iter: 0416/2235
[A[ATraining Step: 1554  | total loss: [1m[32m0.09417[0m[0m | time: 17.606s
[2K
| RMSProp | epoch: 023 | loss: 0.09417 - acc: 0.9711 -- iter: 0448/2235
[A[ATraining Step: 1555  | total loss: [1m[32m0.10175[0m[0m | time: 18.774s
[2K
| RMSProp | epoch: 023 | loss: 0.10175 - acc: 0.9709 -- iter: 0480/2235
[A[ATraining Step: 1556  | total loss: [1m[32m0.09240[0m[0m | time: 20.014s
[2K
| RMSProp | epoch: 023 | loss: 0.09240 - acc: 0.9738 -- iter: 0512/2235
[A[ATraining Step: 1557  | total loss: [1m[32m0.08774[0m[0m | time: 21.303s
[2K
| RMSProp | epoch: 023 | loss: 0.08774 - acc: 0.9733 -- iter: 0544/2235
[A[ATraining Step: 1558  | total loss: [1m[32m0.10147[0m[0m | time: 22.622s
[2K
| RMSProp | epoch: 023 | loss: 0.10147 - acc: 0.9666 -- iter: 0576/2235
[A[ATraining Step: 1559  | total loss: [1m[32m0.09696[0m[0m | time: 23.998s
[2K
| RMSProp | epoch: 023 | loss: 0.09696 - acc: 0.9699 -- iter: 0608/2235
[A[ATraining Step: 1560  | total loss: [1m[32m0.08830[0m[0m | time: 25.267s
[2K
| RMSProp | epoch: 023 | loss: 0.08830 - acc: 0.9729 -- iter: 0640/2235
[A[ATraining Step: 1561  | total loss: [1m[32m0.09750[0m[0m | time: 26.298s
[2K
| RMSProp | epoch: 023 | loss: 0.09750 - acc: 0.9725 -- iter: 0672/2235
[A[ATraining Step: 1562  | total loss: [1m[32m0.10095[0m[0m | time: 27.485s
[2K
| RMSProp | epoch: 023 | loss: 0.10095 - acc: 0.9716 -- iter: 0704/2235
[A[ATraining Step: 1563  | total loss: [1m[32m0.09182[0m[0m | time: 28.884s
[2K
| RMSProp | epoch: 023 | loss: 0.09182 - acc: 0.9744 -- iter: 0736/2235
[A[ATraining Step: 1564  | total loss: [1m[32m0.08439[0m[0m | time: 30.265s
[2K
| RMSProp | epoch: 023 | loss: 0.08439 - acc: 0.9770 -- iter: 0768/2235
[A[ATraining Step: 1565  | total loss: [1m[32m0.07922[0m[0m | time: 31.274s
[2K
| RMSProp | epoch: 023 | loss: 0.07922 - acc: 0.9793 -- iter: 0800/2235
[A[ATraining Step: 1566  | total loss: [1m[32m0.07233[0m[0m | time: 32.369s
[2K
| RMSProp | epoch: 023 | loss: 0.07233 - acc: 0.9813 -- iter: 0832/2235
[A[ATraining Step: 1567  | total loss: [1m[32m0.08221[0m[0m | time: 33.608s
[2K
| RMSProp | epoch: 023 | loss: 0.08221 - acc: 0.9801 -- iter: 0864/2235
[A[ATraining Step: 1568  | total loss: [1m[32m0.07644[0m[0m | time: 34.904s
[2K
| RMSProp | epoch: 023 | loss: 0.07644 - acc: 0.9821 -- iter: 0896/2235
[A[ATraining Step: 1569  | total loss: [1m[32m0.07261[0m[0m | time: 36.208s
[2K
| RMSProp | epoch: 023 | loss: 0.07261 - acc: 0.9807 -- iter: 0928/2235
[A[ATraining Step: 1570  | total loss: [1m[32m0.06720[0m[0m | time: 37.502s
[2K
| RMSProp | epoch: 023 | loss: 0.06720 - acc: 0.9827 -- iter: 0960/2235
[A[ATraining Step: 1571  | total loss: [1m[32m0.07742[0m[0m | time: 38.811s
[2K
| RMSProp | epoch: 023 | loss: 0.07742 - acc: 0.9813 -- iter: 0992/2235
[A[ATraining Step: 1572  | total loss: [1m[32m0.07482[0m[0m | time: 40.109s
[2K
| RMSProp | epoch: 023 | loss: 0.07482 - acc: 0.9800 -- iter: 1024/2235
[A[ATraining Step: 1573  | total loss: [1m[32m0.07104[0m[0m | time: 41.256s
[2K
| RMSProp | epoch: 023 | loss: 0.07104 - acc: 0.9820 -- iter: 1056/2235
[A[ATraining Step: 1574  | total loss: [1m[32m0.07253[0m[0m | time: 42.498s
[2K
| RMSProp | epoch: 023 | loss: 0.07253 - acc: 0.9807 -- iter: 1088/2235
[A[ATraining Step: 1575  | total loss: [1m[32m0.06639[0m[0m | time: 43.893s
[2K
| RMSProp | epoch: 023 | loss: 0.06639 - acc: 0.9826 -- iter: 1120/2235
[A[ATraining Step: 1576  | total loss: [1m[32m0.06105[0m[0m | time: 45.250s
[2K
| RMSProp | epoch: 023 | loss: 0.06105 - acc: 0.9844 -- iter: 1152/2235
[A[ATraining Step: 1577  | total loss: [1m[32m0.07362[0m[0m | time: 46.291s
[2K
| RMSProp | epoch: 023 | loss: 0.07362 - acc: 0.9828 -- iter: 1184/2235
[A[ATraining Step: 1578  | total loss: [1m[32m0.07329[0m[0m | time: 47.484s
[2K
| RMSProp | epoch: 023 | loss: 0.07329 - acc: 0.9814 -- iter: 1216/2235
[A[ATraining Step: 1579  | total loss: [1m[32m0.06798[0m[0m | time: 48.761s
[2K
| RMSProp | epoch: 023 | loss: 0.06798 - acc: 0.9833 -- iter: 1248/2235
[A[ATraining Step: 1580  | total loss: [1m[32m0.06716[0m[0m | time: 50.125s
[2K
| RMSProp | epoch: 023 | loss: 0.06716 - acc: 0.9818 -- iter: 1280/2235
[A[ATraining Step: 1581  | total loss: [1m[32m0.09666[0m[0m | time: 51.398s
[2K
| RMSProp | epoch: 023 | loss: 0.09666 - acc: 0.9742 -- iter: 1312/2235
[A[ATraining Step: 1582  | total loss: [1m[32m0.08842[0m[0m | time: 52.617s
[2K
| RMSProp | epoch: 023 | loss: 0.08842 - acc: 0.9768 -- iter: 1344/2235
[A[ATraining Step: 1583  | total loss: [1m[32m0.08291[0m[0m | time: 53.891s
[2K
| RMSProp | epoch: 023 | loss: 0.08291 - acc: 0.9760 -- iter: 1376/2235
[A[ATraining Step: 1584  | total loss: [1m[32m0.07729[0m[0m | time: 55.080s
[2K
| RMSProp | epoch: 023 | loss: 0.07729 - acc: 0.9784 -- iter: 1408/2235
[A[ATraining Step: 1585  | total loss: [1m[32m0.07950[0m[0m | time: 56.307s
[2K
| RMSProp | epoch: 023 | loss: 0.07950 - acc: 0.9743 -- iter: 1440/2235
[A[ATraining Step: 1586  | total loss: [1m[32m0.07354[0m[0m | time: 57.605s
[2K
| RMSProp | epoch: 023 | loss: 0.07354 - acc: 0.9769 -- iter: 1472/2235
[A[ATraining Step: 1587  | total loss: [1m[32m0.06679[0m[0m | time: 59.090s
[2K
| RMSProp | epoch: 023 | loss: 0.06679 - acc: 0.9792 -- iter: 1504/2235
[A[ATraining Step: 1588  | total loss: [1m[32m0.06725[0m[0m | time: 60.349s
[2K
| RMSProp | epoch: 023 | loss: 0.06725 - acc: 0.9782 -- iter: 1536/2235
[A[ATraining Step: 1589  | total loss: [1m[32m0.06706[0m[0m | time: 61.499s
[2K
| RMSProp | epoch: 023 | loss: 0.06706 - acc: 0.9741 -- iter: 1568/2235
[A[ATraining Step: 1590  | total loss: [1m[32m0.06241[0m[0m | time: 62.659s
[2K
| RMSProp | epoch: 023 | loss: 0.06241 - acc: 0.9767 -- iter: 1600/2235
[A[ATraining Step: 1591  | total loss: [1m[32m0.05738[0m[0m | time: 63.912s
[2K
| RMSProp | epoch: 023 | loss: 0.05738 - acc: 0.9790 -- iter: 1632/2235
[A[ATraining Step: 1592  | total loss: [1m[32m0.05303[0m[0m | time: 65.265s
[2K
| RMSProp | epoch: 023 | loss: 0.05303 - acc: 0.9811 -- iter: 1664/2235
[A[ATraining Step: 1593  | total loss: [1m[32m0.05073[0m[0m | time: 66.580s
[2K
| RMSProp | epoch: 023 | loss: 0.05073 - acc: 0.9830 -- iter: 1696/2235
[A[ATraining Step: 1594  | total loss: [1m[32m0.05727[0m[0m | time: 67.934s
[2K
| RMSProp | epoch: 023 | loss: 0.05727 - acc: 0.9785 -- iter: 1728/2235
[A[ATraining Step: 1595  | total loss: [1m[32m0.10029[0m[0m | time: 69.310s
[2K
| RMSProp | epoch: 023 | loss: 0.10029 - acc: 0.9650 -- iter: 1760/2235
[A[ATraining Step: 1596  | total loss: [1m[32m0.09134[0m[0m | time: 70.515s
[2K
| RMSProp | epoch: 023 | loss: 0.09134 - acc: 0.9685 -- iter: 1792/2235
[A[ATraining Step: 1597  | total loss: [1m[32m0.09442[0m[0m | time: 71.931s
[2K
| RMSProp | epoch: 023 | loss: 0.09442 - acc: 0.9685 -- iter: 1824/2235
[A[ATraining Step: 1598  | total loss: [1m[32m0.09218[0m[0m | time: 73.296s
[2K
| RMSProp | epoch: 023 | loss: 0.09218 - acc: 0.9685 -- iter: 1856/2235
[A[ATraining Step: 1599  | total loss: [1m[32m0.11340[0m[0m | time: 74.670s
[2K
| RMSProp | epoch: 023 | loss: 0.11340 - acc: 0.9686 -- iter: 1888/2235
[A[ATraining Step: 1600  | total loss: [1m[32m0.10355[0m[0m | time: 81.149s
[2K
| RMSProp | epoch: 023 | loss: 0.10355 - acc: 0.9717 | val_loss: 1.13372 - val_acc: 0.6938 -- iter: 1920/2235
--
Training Step: 1601  | total loss: [1m[32m0.12067[0m[0m | time: 82.545s
[2K
| RMSProp | epoch: 023 | loss: 0.12067 - acc: 0.9683 -- iter: 1952/2235
[A[ATraining Step: 1602  | total loss: [1m[32m0.12131[0m[0m | time: 83.934s
[2K
| RMSProp | epoch: 023 | loss: 0.12131 - acc: 0.9652 -- iter: 1984/2235
[A[ATraining Step: 1603  | total loss: [1m[32m0.11059[0m[0m | time: 85.219s
[2K
| RMSProp | epoch: 023 | loss: 0.11059 - acc: 0.9687 -- iter: 2016/2235
[A[ATraining Step: 1604  | total loss: [1m[32m0.10454[0m[0m | time: 86.563s
[2K
| RMSProp | epoch: 023 | loss: 0.10454 - acc: 0.9687 -- iter: 2048/2235
[A[ATraining Step: 1605  | total loss: [1m[32m0.11429[0m[0m | time: 87.841s
[2K
| RMSProp | epoch: 023 | loss: 0.11429 - acc: 0.9656 -- iter: 2080/2235
[A[ATraining Step: 1606  | total loss: [1m[32m0.11474[0m[0m | time: 89.140s
[2K
| RMSProp | epoch: 023 | loss: 0.11474 - acc: 0.9628 -- iter: 2112/2235
[A[ATraining Step: 1607  | total loss: [1m[32m0.11570[0m[0m | time: 90.385s
[2K
| RMSProp | epoch: 023 | loss: 0.11570 - acc: 0.9634 -- iter: 2144/2235
[A[ATraining Step: 1608  | total loss: [1m[32m0.10754[0m[0m | time: 91.658s
[2K
| RMSProp | epoch: 023 | loss: 0.10754 - acc: 0.9639 -- iter: 2176/2235
[A[ATraining Step: 1609  | total loss: [1m[32m0.09957[0m[0m | time: 92.886s
[2K
| RMSProp | epoch: 023 | loss: 0.09957 - acc: 0.9644 -- iter: 2208/2235
[A[ATraining Step: 1610  | total loss: [1m[32m0.10860[0m[0m | time: 99.690s
[2K
| RMSProp | epoch: 023 | loss: 0.10860 - acc: 0.9617 | val_loss: 0.90763 - val_acc: 0.7611 -- iter: 2235/2235
--
Training Step: 1611  | total loss: [1m[32m0.10375[0m[0m | time: 1.420s
[2K
| RMSProp | epoch: 024 | loss: 0.10375 - acc: 0.9624 -- iter: 0032/2235
[A[ATraining Step: 1612  | total loss: [1m[32m0.10802[0m[0m | time: 2.806s
[2K
| RMSProp | epoch: 024 | loss: 0.10802 - acc: 0.9630 -- iter: 0064/2235
[A[ATraining Step: 1613  | total loss: [1m[32m0.10729[0m[0m | time: 4.139s
[2K
| RMSProp | epoch: 024 | loss: 0.10729 - acc: 0.9636 -- iter: 0096/2235
[A[ATraining Step: 1614  | total loss: [1m[32m0.09847[0m[0m | time: 5.215s
[2K
| RMSProp | epoch: 024 | loss: 0.09847 - acc: 0.9672 -- iter: 0128/2235
[A[ATraining Step: 1615  | total loss: [1m[32m0.09019[0m[0m | time: 6.471s
[2K
| RMSProp | epoch: 024 | loss: 0.09019 - acc: 0.9705 -- iter: 0160/2235
[A[ATraining Step: 1616  | total loss: [1m[32m0.08661[0m[0m | time: 7.878s
[2K
| RMSProp | epoch: 024 | loss: 0.08661 - acc: 0.9735 -- iter: 0192/2235
[A[ATraining Step: 1617  | total loss: [1m[32m0.07873[0m[0m | time: 9.030s
[2K
| RMSProp | epoch: 024 | loss: 0.07873 - acc: 0.9761 -- iter: 0224/2235
[A[ATraining Step: 1618  | total loss: [1m[32m0.08805[0m[0m | time: 10.249s
[2K
| RMSProp | epoch: 024 | loss: 0.08805 - acc: 0.9723 -- iter: 0256/2235
[A[ATraining Step: 1619  | total loss: [1m[32m0.12896[0m[0m | time: 11.571s
[2K
| RMSProp | epoch: 024 | loss: 0.12896 - acc: 0.9594 -- iter: 0288/2235
[A[ATraining Step: 1620  | total loss: [1m[32m0.11969[0m[0m | time: 12.829s
[2K
| RMSProp | epoch: 024 | loss: 0.11969 - acc: 0.9635 -- iter: 0320/2235
[A[ATraining Step: 1621  | total loss: [1m[32m0.11600[0m[0m | time: 14.122s
[2K
| RMSProp | epoch: 024 | loss: 0.11600 - acc: 0.9640 -- iter: 0352/2235
[A[ATraining Step: 1622  | total loss: [1m[32m0.10683[0m[0m | time: 15.349s
[2K
| RMSProp | epoch: 024 | loss: 0.10683 - acc: 0.9676 -- iter: 0384/2235
[A[ATraining Step: 1623  | total loss: [1m[32m0.09831[0m[0m | time: 16.659s
[2K
| RMSProp | epoch: 024 | loss: 0.09831 - acc: 0.9708 -- iter: 0416/2235
[A[ATraining Step: 1624  | total loss: [1m[32m0.08932[0m[0m | time: 17.984s
[2K
| RMSProp | epoch: 024 | loss: 0.08932 - acc: 0.9738 -- iter: 0448/2235
[A[ATraining Step: 1625  | total loss: [1m[32m0.09442[0m[0m | time: 19.407s
[2K
| RMSProp | epoch: 024 | loss: 0.09442 - acc: 0.9701 -- iter: 0480/2235
[A[ATraining Step: 1626  | total loss: [1m[32m0.09435[0m[0m | time: 20.393s
[2K
| RMSProp | epoch: 024 | loss: 0.09435 - acc: 0.9700 -- iter: 0512/2235
[A[ATraining Step: 1627  | total loss: [1m[32m0.09811[0m[0m | time: 21.735s
[2K
| RMSProp | epoch: 024 | loss: 0.09811 - acc: 0.9699 -- iter: 0544/2235
[A[ATraining Step: 1628  | total loss: [1m[32m0.10009[0m[0m | time: 23.112s
[2K
| RMSProp | epoch: 024 | loss: 0.10009 - acc: 0.9698 -- iter: 0576/2235
[A[ATraining Step: 1629  | total loss: [1m[32m0.09351[0m[0m | time: 24.319s
[2K
| RMSProp | epoch: 024 | loss: 0.09351 - acc: 0.9697 -- iter: 0608/2235
[A[ATraining Step: 1630  | total loss: [1m[32m0.08679[0m[0m | time: 25.397s
[2K
| RMSProp | epoch: 024 | loss: 0.08679 - acc: 0.9727 -- iter: 0640/2235
[A[ATraining Step: 1631  | total loss: [1m[32m0.08048[0m[0m | time: 26.712s
[2K
| RMSProp | epoch: 024 | loss: 0.08048 - acc: 0.9754 -- iter: 0672/2235
[A[ATraining Step: 1632  | total loss: [1m[32m0.07374[0m[0m | time: 27.883s
[2K
| RMSProp | epoch: 024 | loss: 0.07374 - acc: 0.9779 -- iter: 0704/2235
[A[ATraining Step: 1633  | total loss: [1m[32m0.06710[0m[0m | time: 28.980s
[2K
| RMSProp | epoch: 024 | loss: 0.06710 - acc: 0.9801 -- iter: 0736/2235
[A[ATraining Step: 1634  | total loss: [1m[32m0.06080[0m[0m | time: 30.171s
[2K
| RMSProp | epoch: 024 | loss: 0.06080 - acc: 0.9821 -- iter: 0768/2235
[A[ATraining Step: 1635  | total loss: [1m[32m0.05583[0m[0m | time: 31.633s
[2K
| RMSProp | epoch: 024 | loss: 0.05583 - acc: 0.9839 -- iter: 0800/2235
[A[ATraining Step: 1636  | total loss: [1m[32m0.06283[0m[0m | time: 33.005s
[2K
| RMSProp | epoch: 024 | loss: 0.06283 - acc: 0.9824 -- iter: 0832/2235
[A[ATraining Step: 1637  | total loss: [1m[32m0.05777[0m[0m | time: 34.127s
[2K
| RMSProp | epoch: 024 | loss: 0.05777 - acc: 0.9841 -- iter: 0864/2235
[A[ATraining Step: 1638  | total loss: [1m[32m0.05404[0m[0m | time: 35.303s
[2K
| RMSProp | epoch: 024 | loss: 0.05404 - acc: 0.9857 -- iter: 0896/2235
[A[ATraining Step: 1639  | total loss: [1m[32m0.04898[0m[0m | time: 36.542s
[2K
| RMSProp | epoch: 024 | loss: 0.04898 - acc: 0.9871 -- iter: 0928/2235
[A[ATraining Step: 1640  | total loss: [1m[32m0.04570[0m[0m | time: 37.820s
[2K
| RMSProp | epoch: 024 | loss: 0.04570 - acc: 0.9884 -- iter: 0960/2235
[A[ATraining Step: 1641  | total loss: [1m[32m0.04494[0m[0m | time: 39.111s
[2K
| RMSProp | epoch: 024 | loss: 0.04494 - acc: 0.9865 -- iter: 0992/2235
[A[ATraining Step: 1642  | total loss: [1m[32m0.05728[0m[0m | time: 40.121s
[2K
| RMSProp | epoch: 024 | loss: 0.05728 - acc: 0.9816 -- iter: 1024/2235
[A[ATraining Step: 1643  | total loss: [1m[32m0.09149[0m[0m | time: 41.424s
[2K
| RMSProp | epoch: 024 | loss: 0.09149 - acc: 0.9709 -- iter: 1056/2235
[A[ATraining Step: 1644  | total loss: [1m[32m0.10093[0m[0m | time: 42.611s
[2K
| RMSProp | epoch: 024 | loss: 0.10093 - acc: 0.9676 -- iter: 1088/2235
[A[ATraining Step: 1645  | total loss: [1m[32m0.09914[0m[0m | time: 43.848s
[2K
| RMSProp | epoch: 024 | loss: 0.09914 - acc: 0.9677 -- iter: 1120/2235
[A[ATraining Step: 1646  | total loss: [1m[32m0.09480[0m[0m | time: 45.066s
[2K
| RMSProp | epoch: 024 | loss: 0.09480 - acc: 0.9678 -- iter: 1152/2235
[A[ATraining Step: 1647  | total loss: [1m[32m0.08614[0m[0m | time: 46.387s
[2K
| RMSProp | epoch: 024 | loss: 0.08614 - acc: 0.9710 -- iter: 1184/2235
[A[ATraining Step: 1648  | total loss: [1m[32m0.07828[0m[0m | time: 47.765s
[2K
| RMSProp | epoch: 024 | loss: 0.07828 - acc: 0.9739 -- iter: 1216/2235
[A[ATraining Step: 1649  | total loss: [1m[32m0.07223[0m[0m | time: 48.891s
[2K
| RMSProp | epoch: 024 | loss: 0.07223 - acc: 0.9765 -- iter: 1248/2235
[A[ATraining Step: 1650  | total loss: [1m[32m0.06525[0m[0m | time: 50.126s
[2K
| RMSProp | epoch: 024 | loss: 0.06525 - acc: 0.9789 -- iter: 1280/2235
[A[ATraining Step: 1651  | total loss: [1m[32m0.05949[0m[0m | time: 51.356s
[2K
| RMSProp | epoch: 024 | loss: 0.05949 - acc: 0.9810 -- iter: 1312/2235
[A[ATraining Step: 1652  | total loss: [1m[32m0.07215[0m[0m | time: 52.767s
[2K
| RMSProp | epoch: 024 | loss: 0.07215 - acc: 0.9735 -- iter: 1344/2235
[A[ATraining Step: 1653  | total loss: [1m[32m0.08304[0m[0m | time: 54.217s
[2K
| RMSProp | epoch: 024 | loss: 0.08304 - acc: 0.9699 -- iter: 1376/2235
[A[ATraining Step: 1654  | total loss: [1m[32m0.09365[0m[0m | time: 55.631s
[2K
| RMSProp | epoch: 024 | loss: 0.09365 - acc: 0.9667 -- iter: 1408/2235
[A[ATraining Step: 1655  | total loss: [1m[32m0.09027[0m[0m | time: 56.813s
[2K
| RMSProp | epoch: 024 | loss: 0.09027 - acc: 0.9669 -- iter: 1440/2235
[A[ATraining Step: 1656  | total loss: [1m[32m0.09516[0m[0m | time: 58.070s
[2K
| RMSProp | epoch: 024 | loss: 0.09516 - acc: 0.9671 -- iter: 1472/2235
[A[ATraining Step: 1657  | total loss: [1m[32m0.08844[0m[0m | time: 59.268s
[2K
| RMSProp | epoch: 024 | loss: 0.08844 - acc: 0.9704 -- iter: 1504/2235
[A[ATraining Step: 1658  | total loss: [1m[32m0.08081[0m[0m | time: 60.601s
[2K
| RMSProp | epoch: 024 | loss: 0.08081 - acc: 0.9733 -- iter: 1536/2235
[A[ATraining Step: 1659  | total loss: [1m[32m0.07378[0m[0m | time: 61.969s
[2K
| RMSProp | epoch: 024 | loss: 0.07378 - acc: 0.9760 -- iter: 1568/2235
[A[ATraining Step: 1660  | total loss: [1m[32m0.07000[0m[0m | time: 63.298s
[2K
| RMSProp | epoch: 024 | loss: 0.07000 - acc: 0.9753 -- iter: 1600/2235
[A[ATraining Step: 1661  | total loss: [1m[32m0.07438[0m[0m | time: 64.680s
[2K
| RMSProp | epoch: 024 | loss: 0.07438 - acc: 0.9746 -- iter: 1632/2235
[A[ATraining Step: 1662  | total loss: [1m[32m0.07257[0m[0m | time: 66.041s
[2K
| RMSProp | epoch: 024 | loss: 0.07257 - acc: 0.9740 -- iter: 1664/2235
[A[ATraining Step: 1663  | total loss: [1m[32m0.08424[0m[0m | time: 67.272s
[2K
| RMSProp | epoch: 024 | loss: 0.08424 - acc: 0.9735 -- iter: 1696/2235
[A[ATraining Step: 1664  | total loss: [1m[32m0.07994[0m[0m | time: 68.611s
[2K
| RMSProp | epoch: 024 | loss: 0.07994 - acc: 0.9730 -- iter: 1728/2235
[A[ATraining Step: 1665  | total loss: [1m[32m0.07354[0m[0m | time: 70.075s
[2K
| RMSProp | epoch: 024 | loss: 0.07354 - acc: 0.9757 -- iter: 1760/2235
[A[ATraining Step: 1666  | total loss: [1m[32m0.06749[0m[0m | time: 71.474s
[2K
| RMSProp | epoch: 024 | loss: 0.06749 - acc: 0.9781 -- iter: 1792/2235
[A[ATraining Step: 1667  | total loss: [1m[32m0.06934[0m[0m | time: 72.651s
[2K
| RMSProp | epoch: 024 | loss: 0.06934 - acc: 0.9772 -- iter: 1824/2235
[A[ATraining Step: 1668  | total loss: [1m[32m0.06945[0m[0m | time: 73.713s
[2K
| RMSProp | epoch: 024 | loss: 0.06945 - acc: 0.9764 -- iter: 1856/2235
[A[ATraining Step: 1669  | total loss: [1m[32m0.06314[0m[0m | time: 74.663s
[2K
| RMSProp | epoch: 024 | loss: 0.06314 - acc: 0.9787 -- iter: 1888/2235
[A[ATraining Step: 1670  | total loss: [1m[32m0.06109[0m[0m | time: 75.588s
[2K
| RMSProp | epoch: 024 | loss: 0.06109 - acc: 0.9777 -- iter: 1920/2235
[A[ATraining Step: 1671  | total loss: [1m[32m0.06883[0m[0m | time: 76.543s
[2K
| RMSProp | epoch: 024 | loss: 0.06883 - acc: 0.9737 -- iter: 1952/2235
[A[ATraining Step: 1672  | total loss: [1m[32m0.18557[0m[0m | time: 77.532s
[2K
| RMSProp | epoch: 024 | loss: 0.18557 - acc: 0.9576 -- iter: 1984/2235
[A[ATraining Step: 1673  | total loss: [1m[32m0.16906[0m[0m | time: 78.480s
[2K
| RMSProp | epoch: 024 | loss: 0.16906 - acc: 0.9618 -- iter: 2016/2235
[A[ATraining Step: 1674  | total loss: [1m[32m0.15426[0m[0m | time: 79.478s
[2K
| RMSProp | epoch: 024 | loss: 0.15426 - acc: 0.9656 -- iter: 2048/2235
[A[ATraining Step: 1675  | total loss: [1m[32m0.13985[0m[0m | time: 80.389s
[2K
| RMSProp | epoch: 024 | loss: 0.13985 - acc: 0.9691 -- iter: 2080/2235
[A[ATraining Step: 1676  | total loss: [1m[32m0.12673[0m[0m | time: 81.545s
[2K
| RMSProp | epoch: 024 | loss: 0.12673 - acc: 0.9722 -- iter: 2112/2235
[A[ATraining Step: 1677  | total loss: [1m[32m0.11943[0m[0m | time: 82.701s
[2K
| RMSProp | epoch: 024 | loss: 0.11943 - acc: 0.9718 -- iter: 2144/2235
[A[ATraining Step: 1678  | total loss: [1m[32m0.11466[0m[0m | time: 83.590s
[2K
| RMSProp | epoch: 024 | loss: 0.11466 - acc: 0.9715 -- iter: 2176/2235
[A[ATraining Step: 1679  | total loss: [1m[32m0.10572[0m[0m | time: 84.465s
[2K
| RMSProp | epoch: 024 | loss: 0.10572 - acc: 0.9744 -- iter: 2208/2235
[A[ATraining Step: 1680  | total loss: [1m[32m0.09571[0m[0m | time: 89.408s
[2K
| RMSProp | epoch: 024 | loss: 0.09571 - acc: 0.9769 | val_loss: 1.06056 - val_acc: 0.7282 -- iter: 2235/2235
--
Training Step: 1681  | total loss: [1m[32m0.09659[0m[0m | time: 1.040s
[2K
| RMSProp | epoch: 025 | loss: 0.09659 - acc: 0.9761 -- iter: 0032/2235
[A[ATraining Step: 1682  | total loss: [1m[32m0.08874[0m[0m | time: 1.956s
[2K
| RMSProp | epoch: 025 | loss: 0.08874 - acc: 0.9785 -- iter: 0064/2235
[A[ATraining Step: 1683  | total loss: [1m[32m0.08112[0m[0m | time: 2.858s
[2K
| RMSProp | epoch: 025 | loss: 0.08112 - acc: 0.9807 -- iter: 0096/2235
[A[ATraining Step: 1684  | total loss: [1m[32m0.08014[0m[0m | time: 3.957s
[2K
| RMSProp | epoch: 025 | loss: 0.08014 - acc: 0.9795 -- iter: 0128/2235
[A[ATraining Step: 1685  | total loss: [1m[32m0.07767[0m[0m | time: 4.932s
[2K
| RMSProp | epoch: 025 | loss: 0.07767 - acc: 0.9784 -- iter: 0160/2235
[A[ATraining Step: 1686  | total loss: [1m[32m0.07039[0m[0m | time: 5.811s
[2K
| RMSProp | epoch: 025 | loss: 0.07039 - acc: 0.9806 -- iter: 0192/2235
[A[ATraining Step: 1687  | total loss: [1m[32m0.06452[0m[0m | time: 6.792s
[2K
| RMSProp | epoch: 025 | loss: 0.06452 - acc: 0.9825 -- iter: 0224/2235
[A[ATraining Step: 1688  | total loss: [1m[32m0.06841[0m[0m | time: 7.794s
[2K
| RMSProp | epoch: 025 | loss: 0.06841 - acc: 0.9780 -- iter: 0256/2235
[A[ATraining Step: 1689  | total loss: [1m[32m0.06396[0m[0m | time: 8.757s
[2K
| RMSProp | epoch: 025 | loss: 0.06396 - acc: 0.9802 -- iter: 0288/2235
[A[ATraining Step: 1690  | total loss: [1m[32m0.07184[0m[0m | time: 9.751s
[2K
| RMSProp | epoch: 025 | loss: 0.07184 - acc: 0.9791 -- iter: 0320/2235
[A[ATraining Step: 1691  | total loss: [1m[32m0.06868[0m[0m | time: 10.759s
[2K
| RMSProp | epoch: 025 | loss: 0.06868 - acc: 0.9780 -- iter: 0352/2235
[A[ATraining Step: 1692  | total loss: [1m[32m0.07355[0m[0m | time: 11.740s
[2K
| RMSProp | epoch: 025 | loss: 0.07355 - acc: 0.9740 -- iter: 0384/2235
[A[ATraining Step: 1693  | total loss: [1m[32m0.10168[0m[0m | time: 12.675s
[2K
| RMSProp | epoch: 025 | loss: 0.10168 - acc: 0.9672 -- iter: 0416/2235
[A[ATraining Step: 1694  | total loss: [1m[32m0.10204[0m[0m | time: 13.876s
[2K
| RMSProp | epoch: 025 | loss: 0.10204 - acc: 0.9674 -- iter: 0448/2235
[A[ATraining Step: 1695  | total loss: [1m[32m0.10561[0m[0m | time: 15.311s
[2K
| RMSProp | epoch: 025 | loss: 0.10561 - acc: 0.9675 -- iter: 0480/2235
[A[ATraining Step: 1696  | total loss: [1m[32m0.10178[0m[0m | time: 16.694s
[2K
| RMSProp | epoch: 025 | loss: 0.10178 - acc: 0.9676 -- iter: 0512/2235
[A[ATraining Step: 1697  | total loss: [1m[32m0.09329[0m[0m | time: 17.860s
[2K
| RMSProp | epoch: 025 | loss: 0.09329 - acc: 0.9709 -- iter: 0544/2235
[A[ATraining Step: 1698  | total loss: [1m[32m0.08574[0m[0m | time: 18.902s
[2K
| RMSProp | epoch: 025 | loss: 0.08574 - acc: 0.9738 -- iter: 0576/2235
[A[ATraining Step: 1699  | total loss: [1m[32m0.07767[0m[0m | time: 20.163s
[2K
| RMSProp | epoch: 025 | loss: 0.07767 - acc: 0.9764 -- iter: 0608/2235
[A[ATraining Step: 1700  | total loss: [1m[32m0.07071[0m[0m | time: 21.471s
[2K
| RMSProp | epoch: 025 | loss: 0.07071 - acc: 0.9788 -- iter: 0640/2235
[A[ATraining Step: 1701  | total loss: [1m[32m0.06445[0m[0m | time: 22.661s
[2K
| RMSProp | epoch: 025 | loss: 0.06445 - acc: 0.9809 -- iter: 0672/2235
[A[ATraining Step: 1702  | total loss: [1m[32m0.05842[0m[0m | time: 24.031s
[2K
| RMSProp | epoch: 025 | loss: 0.05842 - acc: 0.9828 -- iter: 0704/2235
[A[ATraining Step: 1703  | total loss: [1m[32m0.05347[0m[0m | time: 25.108s
[2K
| RMSProp | epoch: 025 | loss: 0.05347 - acc: 0.9845 -- iter: 0736/2235
[A[ATraining Step: 1704  | total loss: [1m[32m0.04839[0m[0m | time: 26.247s
[2K
| RMSProp | epoch: 025 | loss: 0.04839 - acc: 0.9861 -- iter: 0768/2235
[A[ATraining Step: 1705  | total loss: [1m[32m0.04373[0m[0m | time: 27.545s
[2K
| RMSProp | epoch: 025 | loss: 0.04373 - acc: 0.9875 -- iter: 0800/2235
[A[ATraining Step: 1706  | total loss: [1m[32m0.03973[0m[0m | time: 28.820s
[2K
| RMSProp | epoch: 025 | loss: 0.03973 - acc: 0.9887 -- iter: 0832/2235
[A[ATraining Step: 1707  | total loss: [1m[32m0.03622[0m[0m | time: 30.132s
[2K
| RMSProp | epoch: 025 | loss: 0.03622 - acc: 0.9898 -- iter: 0864/2235
[A[ATraining Step: 1708  | total loss: [1m[32m0.03290[0m[0m | time: 31.530s
[2K
| RMSProp | epoch: 025 | loss: 0.03290 - acc: 0.9909 -- iter: 0896/2235
[A[ATraining Step: 1709  | total loss: [1m[32m0.03835[0m[0m | time: 32.602s
[2K
| RMSProp | epoch: 025 | loss: 0.03835 - acc: 0.9886 -- iter: 0928/2235
[A[ATraining Step: 1710  | total loss: [1m[32m0.05510[0m[0m | time: 33.666s
[2K
| RMSProp | epoch: 025 | loss: 0.05510 - acc: 0.9804 -- iter: 0960/2235
[A[ATraining Step: 1711  | total loss: [1m[32m0.07662[0m[0m | time: 34.937s
[2K
| RMSProp | epoch: 025 | loss: 0.07662 - acc: 0.9730 -- iter: 0992/2235
[A[ATraining Step: 1712  | total loss: [1m[32m0.06971[0m[0m | time: 36.145s
[2K
| RMSProp | epoch: 025 | loss: 0.06971 - acc: 0.9757 -- iter: 1024/2235
[A[ATraining Step: 1713  | total loss: [1m[32m0.06330[0m[0m | time: 37.400s
[2K
| RMSProp | epoch: 025 | loss: 0.06330 - acc: 0.9781 -- iter: 1056/2235
[A[ATraining Step: 1714  | total loss: [1m[32m0.06066[0m[0m | time: 38.724s
[2K
| RMSProp | epoch: 025 | loss: 0.06066 - acc: 0.9803 -- iter: 1088/2235
[A[ATraining Step: 1715  | total loss: [1m[32m0.09811[0m[0m | time: 40.117s
[2K
| RMSProp | epoch: 025 | loss: 0.09811 - acc: 0.9729 -- iter: 1120/2235
[A[ATraining Step: 1716  | total loss: [1m[32m0.09811[0m[0m | time: 41.457s
[2K
| RMSProp | epoch: 025 | loss: 0.09811 - acc: 0.9725 -- iter: 1152/2235
[A[ATraining Step: 1717  | total loss: [1m[32m0.12314[0m[0m | time: 42.659s
[2K
| RMSProp | epoch: 025 | loss: 0.12314 - acc: 0.9659 -- iter: 1184/2235
[A[ATraining Step: 1718  | total loss: [1m[32m0.11182[0m[0m | time: 43.997s
[2K
| RMSProp | epoch: 025 | loss: 0.11182 - acc: 0.9693 -- iter: 1216/2235
[A[ATraining Step: 1719  | total loss: [1m[32m0.10381[0m[0m | time: 45.280s
[2K
| RMSProp | epoch: 025 | loss: 0.10381 - acc: 0.9723 -- iter: 1248/2235
[A[ATraining Step: 1720  | total loss: [1m[32m0.09430[0m[0m | time: 46.566s
[2K
| RMSProp | epoch: 025 | loss: 0.09430 - acc: 0.9751 -- iter: 1280/2235
[A[ATraining Step: 1721  | total loss: [1m[32m0.08537[0m[0m | time: 47.725s
[2K
| RMSProp | epoch: 025 | loss: 0.08537 - acc: 0.9776 -- iter: 1312/2235
[A[ATraining Step: 1722  | total loss: [1m[32m0.07795[0m[0m | time: 48.733s
[2K
| RMSProp | epoch: 025 | loss: 0.07795 - acc: 0.9798 -- iter: 1344/2235
[A[ATraining Step: 1723  | total loss: [1m[32m0.07057[0m[0m | time: 49.977s
[2K
| RMSProp | epoch: 025 | loss: 0.07057 - acc: 0.9819 -- iter: 1376/2235
[A[ATraining Step: 1724  | total loss: [1m[32m0.06419[0m[0m | time: 51.153s
[2K
| RMSProp | epoch: 025 | loss: 0.06419 - acc: 0.9837 -- iter: 1408/2235
[A[ATraining Step: 1725  | total loss: [1m[32m0.05841[0m[0m | time: 52.346s
[2K
| RMSProp | epoch: 025 | loss: 0.05841 - acc: 0.9853 -- iter: 1440/2235
[A[ATraining Step: 1726  | total loss: [1m[32m0.06681[0m[0m | time: 53.669s
[2K
| RMSProp | epoch: 025 | loss: 0.06681 - acc: 0.9837 -- iter: 1472/2235
[A[ATraining Step: 1727  | total loss: [1m[32m0.06331[0m[0m | time: 54.880s
[2K
| RMSProp | epoch: 025 | loss: 0.06331 - acc: 0.9853 -- iter: 1504/2235
[A[ATraining Step: 1728  | total loss: [1m[32m0.08266[0m[0m | time: 56.011s
[2K
| RMSProp | epoch: 025 | loss: 0.08266 - acc: 0.9836 -- iter: 1536/2235
[A[ATraining Step: 1729  | total loss: [1m[32m0.08870[0m[0m | time: 57.190s
[2K
| RMSProp | epoch: 025 | loss: 0.08870 - acc: 0.9821 -- iter: 1568/2235
[A[ATraining Step: 1730  | total loss: [1m[32m0.09133[0m[0m | time: 58.344s
[2K
| RMSProp | epoch: 025 | loss: 0.09133 - acc: 0.9808 -- iter: 1600/2235
[A[ATraining Step: 1731  | total loss: [1m[32m0.14556[0m[0m | time: 59.587s
[2K
| RMSProp | epoch: 025 | loss: 0.14556 - acc: 0.9640 -- iter: 1632/2235
[A[ATraining Step: 1732  | total loss: [1m[32m0.14468[0m[0m | time: 60.967s
[2K
| RMSProp | epoch: 025 | loss: 0.14468 - acc: 0.9645 -- iter: 1664/2235
[A[ATraining Step: 1733  | total loss: [1m[32m0.14448[0m[0m | time: 62.376s
[2K
| RMSProp | epoch: 025 | loss: 0.14448 - acc: 0.9618 -- iter: 1696/2235
[A[ATraining Step: 1734  | total loss: [1m[32m0.13313[0m[0m | time: 63.697s
[2K
| RMSProp | epoch: 025 | loss: 0.13313 - acc: 0.9656 -- iter: 1728/2235
[A[ATraining Step: 1735  | total loss: [1m[32m0.12083[0m[0m | time: 65.049s
[2K
| RMSProp | epoch: 025 | loss: 0.12083 - acc: 0.9690 -- iter: 1760/2235
[A[ATraining Step: 1736  | total loss: [1m[32m0.10961[0m[0m | time: 66.156s
[2K
| RMSProp | epoch: 025 | loss: 0.10961 - acc: 0.9721 -- iter: 1792/2235
[A[ATraining Step: 1737  | total loss: [1m[32m0.12410[0m[0m | time: 67.460s
[2K
| RMSProp | epoch: 025 | loss: 0.12410 - acc: 0.9687 -- iter: 1824/2235
[A[ATraining Step: 1738  | total loss: [1m[32m0.11863[0m[0m | time: 68.683s
[2K
| RMSProp | epoch: 025 | loss: 0.11863 - acc: 0.9687 -- iter: 1856/2235
[A[ATraining Step: 1739  | total loss: [1m[32m0.10830[0m[0m | time: 69.888s
[2K
| RMSProp | epoch: 025 | loss: 0.10830 - acc: 0.9718 -- iter: 1888/2235
[A[ATraining Step: 1740  | total loss: [1m[32m0.09981[0m[0m | time: 71.143s
[2K
| RMSProp | epoch: 025 | loss: 0.09981 - acc: 0.9746 -- iter: 1920/2235
[A[ATraining Step: 1741  | total loss: [1m[32m0.09057[0m[0m | time: 72.568s
[2K
| RMSProp | epoch: 025 | loss: 0.09057 - acc: 0.9772 -- iter: 1952/2235
[A[ATraining Step: 1742  | total loss: [1m[32m0.08244[0m[0m | time: 73.859s
[2K
| RMSProp | epoch: 025 | loss: 0.08244 - acc: 0.9794 -- iter: 1984/2235
[A[ATraining Step: 1743  | total loss: [1m[32m0.16949[0m[0m | time: 75.017s
[2K
| RMSProp | epoch: 025 | loss: 0.16949 - acc: 0.9627 -- iter: 2016/2235
[A[ATraining Step: 1744  | total loss: [1m[32m0.17444[0m[0m | time: 76.376s
[2K
| RMSProp | epoch: 025 | loss: 0.17444 - acc: 0.9602 -- iter: 2048/2235
[A[ATraining Step: 1745  | total loss: [1m[32m0.16284[0m[0m | time: 77.812s
[2K
| RMSProp | epoch: 025 | loss: 0.16284 - acc: 0.9642 -- iter: 2080/2235
[A[ATraining Step: 1746  | total loss: [1m[32m0.16033[0m[0m | time: 79.211s
[2K
| RMSProp | epoch: 025 | loss: 0.16033 - acc: 0.9647 -- iter: 2112/2235
[A[ATraining Step: 1747  | total loss: [1m[32m0.14665[0m[0m | time: 80.178s
[2K
| RMSProp | epoch: 025 | loss: 0.14665 - acc: 0.9682 -- iter: 2144/2235
[A[ATraining Step: 1748  | total loss: [1m[32m0.13529[0m[0m | time: 81.370s
[2K
| RMSProp | epoch: 025 | loss: 0.13529 - acc: 0.9682 -- iter: 2176/2235
[A[ATraining Step: 1749  | total loss: [1m[32m0.12287[0m[0m | time: 82.598s
[2K
| RMSProp | epoch: 025 | loss: 0.12287 - acc: 0.9714 -- iter: 2208/2235
[A[ATraining Step: 1750  | total loss: [1m[32m0.11369[0m[0m | time: 89.766s
[2K
| RMSProp | epoch: 025 | loss: 0.11369 - acc: 0.9743 | val_loss: 0.91673 - val_acc: 0.7582 -- iter: 2235/2235
--
Training Step: 1751  | total loss: [1m[32m0.10548[0m[0m | time: 1.367s
[2K
| RMSProp | epoch: 026 | loss: 0.10548 - acc: 0.9769 -- iter: 0032/2235
[A[ATraining Step: 1752  | total loss: [1m[32m0.09550[0m[0m | time: 2.752s
[2K
| RMSProp | epoch: 026 | loss: 0.09550 - acc: 0.9792 -- iter: 0064/2235
[A[ATraining Step: 1753  | total loss: [1m[32m0.08712[0m[0m | time: 4.142s
[2K
| RMSProp | epoch: 026 | loss: 0.08712 - acc: 0.9812 -- iter: 0096/2235
[A[ATraining Step: 1754  | total loss: [1m[32m0.09079[0m[0m | time: 5.287s
[2K
| RMSProp | epoch: 026 | loss: 0.09079 - acc: 0.9800 -- iter: 0128/2235
[A[ATraining Step: 1755  | total loss: [1m[32m0.08303[0m[0m | time: 6.424s
[2K
| RMSProp | epoch: 026 | loss: 0.08303 - acc: 0.9820 -- iter: 0160/2235
[A[ATraining Step: 1756  | total loss: [1m[32m0.08311[0m[0m | time: 7.675s
[2K
| RMSProp | epoch: 026 | loss: 0.08311 - acc: 0.9807 -- iter: 0192/2235
[A[ATraining Step: 1757  | total loss: [1m[32m0.07625[0m[0m | time: 8.891s
[2K
| RMSProp | epoch: 026 | loss: 0.07625 - acc: 0.9826 -- iter: 0224/2235
[A[ATraining Step: 1758  | total loss: [1m[32m0.07672[0m[0m | time: 10.208s
[2K
| RMSProp | epoch: 026 | loss: 0.07672 - acc: 0.9812 -- iter: 0256/2235
[A[ATraining Step: 1759  | total loss: [1m[32m0.07000[0m[0m | time: 11.460s
[2K
| RMSProp | epoch: 026 | loss: 0.07000 - acc: 0.9831 -- iter: 0288/2235
[A[ATraining Step: 1760  | total loss: [1m[32m0.06823[0m[0m | time: 12.753s
[2K
| RMSProp | epoch: 026 | loss: 0.06823 - acc: 0.9817 -- iter: 0320/2235
[A[ATraining Step: 1761  | total loss: [1m[32m0.06957[0m[0m | time: 13.913s
[2K
| RMSProp | epoch: 026 | loss: 0.06957 - acc: 0.9804 -- iter: 0352/2235
[A[ATraining Step: 1762  | total loss: [1m[32m0.06423[0m[0m | time: 15.278s
[2K
| RMSProp | epoch: 026 | loss: 0.06423 - acc: 0.9823 -- iter: 0384/2235
[A[ATraining Step: 1763  | total loss: [1m[32m0.05915[0m[0m | time: 16.812s
[2K
| RMSProp | epoch: 026 | loss: 0.05915 - acc: 0.9841 -- iter: 0416/2235
[A[ATraining Step: 1764  | total loss: [1m[32m0.05375[0m[0m | time: 18.052s
[2K
| RMSProp | epoch: 026 | loss: 0.05375 - acc: 0.9857 -- iter: 0448/2235
[A[ATraining Step: 1765  | total loss: [1m[32m0.04884[0m[0m | time: 19.229s
[2K
| RMSProp | epoch: 026 | loss: 0.04884 - acc: 0.9871 -- iter: 0480/2235
[A[ATraining Step: 1766  | total loss: [1m[32m0.04560[0m[0m | time: 20.546s
[2K
| RMSProp | epoch: 026 | loss: 0.04560 - acc: 0.9884 -- iter: 0512/2235
[A[ATraining Step: 1767  | total loss: [1m[32m0.04415[0m[0m | time: 21.737s
[2K
| RMSProp | epoch: 026 | loss: 0.04415 - acc: 0.9864 -- iter: 0544/2235
[A[ATraining Step: 1768  | total loss: [1m[32m0.04027[0m[0m | time: 22.864s
[2K
| RMSProp | epoch: 026 | loss: 0.04027 - acc: 0.9878 -- iter: 0576/2235
[A[ATraining Step: 1769  | total loss: [1m[32m0.03819[0m[0m | time: 24.144s
[2K
| RMSProp | epoch: 026 | loss: 0.03819 - acc: 0.9890 -- iter: 0608/2235
[A[ATraining Step: 1770  | total loss: [1m[32m0.06545[0m[0m | time: 25.443s
[2K
| RMSProp | epoch: 026 | loss: 0.06545 - acc: 0.9807 -- iter: 0640/2235
[A[ATraining Step: 1771  | total loss: [1m[32m0.07709[0m[0m | time: 26.781s
[2K
| RMSProp | epoch: 026 | loss: 0.07709 - acc: 0.9733 -- iter: 0672/2235
[A[ATraining Step: 1772  | total loss: [1m[32m0.07018[0m[0m | time: 27.995s
[2K
| RMSProp | epoch: 026 | loss: 0.07018 - acc: 0.9760 -- iter: 0704/2235
[A[ATraining Step: 1773  | total loss: [1m[32m0.07352[0m[0m | time: 29.187s
[2K
| RMSProp | epoch: 026 | loss: 0.07352 - acc: 0.9721 -- iter: 0736/2235
[A[ATraining Step: 1774  | total loss: [1m[32m0.06668[0m[0m | time: 30.379s
[2K
| RMSProp | epoch: 026 | loss: 0.06668 - acc: 0.9749 -- iter: 0768/2235
[A[ATraining Step: 1775  | total loss: [1m[32m0.06055[0m[0m | time: 31.587s
[2K
| RMSProp | epoch: 026 | loss: 0.06055 - acc: 0.9774 -- iter: 0800/2235
[A[ATraining Step: 1776  | total loss: [1m[32m0.05475[0m[0m | time: 32.723s
[2K
| RMSProp | epoch: 026 | loss: 0.05475 - acc: 0.9797 -- iter: 0832/2235
[A[ATraining Step: 1777  | total loss: [1m[32m0.04963[0m[0m | time: 33.905s
[2K
| RMSProp | epoch: 026 | loss: 0.04963 - acc: 0.9817 -- iter: 0864/2235
[A[ATraining Step: 1778  | total loss: [1m[32m0.07759[0m[0m | time: 35.269s
[2K
| RMSProp | epoch: 026 | loss: 0.07759 - acc: 0.9804 -- iter: 0896/2235
[A[ATraining Step: 1779  | total loss: [1m[32m0.07101[0m[0m | time: 36.657s
[2K
| RMSProp | epoch: 026 | loss: 0.07101 - acc: 0.9824 -- iter: 0928/2235
[A[ATraining Step: 1780  | total loss: [1m[32m0.06496[0m[0m | time: 37.759s
[2K
| RMSProp | epoch: 026 | loss: 0.06496 - acc: 0.9841 -- iter: 0960/2235
[A[ATraining Step: 1781  | total loss: [1m[32m0.07051[0m[0m | time: 38.932s
[2K
| RMSProp | epoch: 026 | loss: 0.07051 - acc: 0.9826 -- iter: 0992/2235
[A[ATraining Step: 1782  | total loss: [1m[32m0.06638[0m[0m | time: 40.192s
[2K
| RMSProp | epoch: 026 | loss: 0.06638 - acc: 0.9843 -- iter: 1024/2235
[A[ATraining Step: 1783  | total loss: [1m[32m0.06131[0m[0m | time: 41.484s
[2K
| RMSProp | epoch: 026 | loss: 0.06131 - acc: 0.9859 -- iter: 1056/2235
[A[ATraining Step: 1784  | total loss: [1m[32m0.05563[0m[0m | time: 42.642s
[2K
| RMSProp | epoch: 026 | loss: 0.05563 - acc: 0.9873 -- iter: 1088/2235
[A[ATraining Step: 1785  | total loss: [1m[32m0.05062[0m[0m | time: 44.004s
[2K
| RMSProp | epoch: 026 | loss: 0.05062 - acc: 0.9886 -- iter: 1120/2235
[A[ATraining Step: 1786  | total loss: [1m[32m0.04859[0m[0m | time: 45.378s
[2K
| RMSProp | epoch: 026 | loss: 0.04859 - acc: 0.9866 -- iter: 1152/2235
[A[ATraining Step: 1787  | total loss: [1m[32m0.04947[0m[0m | time: 46.742s
[2K
| RMSProp | epoch: 026 | loss: 0.04947 - acc: 0.9848 -- iter: 1184/2235
[A[ATraining Step: 1788  | total loss: [1m[32m0.05668[0m[0m | time: 47.711s
[2K
| RMSProp | epoch: 026 | loss: 0.05668 - acc: 0.9832 -- iter: 1216/2235
[A[ATraining Step: 1789  | total loss: [1m[32m0.05960[0m[0m | time: 48.844s
[2K
| RMSProp | epoch: 026 | loss: 0.05960 - acc: 0.9818 -- iter: 1248/2235
[A[ATraining Step: 1790  | total loss: [1m[32m0.06743[0m[0m | time: 50.114s
[2K
| RMSProp | epoch: 026 | loss: 0.06743 - acc: 0.9773 -- iter: 1280/2235
[A[ATraining Step: 1791  | total loss: [1m[32m0.07461[0m[0m | time: 51.470s
[2K
| RMSProp | epoch: 026 | loss: 0.07461 - acc: 0.9765 -- iter: 1312/2235
[A[ATraining Step: 1792  | total loss: [1m[32m0.06795[0m[0m | time: 52.711s
[2K
| RMSProp | epoch: 026 | loss: 0.06795 - acc: 0.9788 -- iter: 1344/2235
[A[ATraining Step: 1793  | total loss: [1m[32m0.06517[0m[0m | time: 53.883s
[2K
| RMSProp | epoch: 026 | loss: 0.06517 - acc: 0.9778 -- iter: 1376/2235
[A[ATraining Step: 1794  | total loss: [1m[32m0.05985[0m[0m | time: 55.168s
[2K
| RMSProp | epoch: 026 | loss: 0.05985 - acc: 0.9800 -- iter: 1408/2235
[A[ATraining Step: 1795  | total loss: [1m[32m0.05975[0m[0m | time: 56.436s
[2K
| RMSProp | epoch: 026 | loss: 0.05975 - acc: 0.9789 -- iter: 1440/2235
[A[ATraining Step: 1796  | total loss: [1m[32m0.06466[0m[0m | time: 57.645s
[2K
| RMSProp | epoch: 026 | loss: 0.06466 - acc: 0.9779 -- iter: 1472/2235
[A[ATraining Step: 1797  | total loss: [1m[32m0.06585[0m[0m | time: 58.965s
[2K
| RMSProp | epoch: 026 | loss: 0.06585 - acc: 0.9770 -- iter: 1504/2235
[A[ATraining Step: 1798  | total loss: [1m[32m0.06385[0m[0m | time: 60.306s
[2K
| RMSProp | epoch: 026 | loss: 0.06385 - acc: 0.9762 -- iter: 1536/2235
[A[ATraining Step: 1799  | total loss: [1m[32m0.06896[0m[0m | time: 61.559s
[2K
| RMSProp | epoch: 026 | loss: 0.06896 - acc: 0.9754 -- iter: 1568/2235
[A[ATraining Step: 1800  | total loss: [1m[32m0.06928[0m[0m | time: 68.062s
[2K
| RMSProp | epoch: 026 | loss: 0.06928 - acc: 0.9747 | val_loss: 1.00487 - val_acc: 0.7010 -- iter: 1600/2235
--
Training Step: 1801  | total loss: [1m[32m0.07150[0m[0m | time: 69.425s
[2K
| RMSProp | epoch: 026 | loss: 0.07150 - acc: 0.9741 -- iter: 1632/2235
[A[ATraining Step: 1802  | total loss: [1m[32m0.09771[0m[0m | time: 70.465s
[2K
| RMSProp | epoch: 026 | loss: 0.09771 - acc: 0.9674 -- iter: 1664/2235
[A[ATraining Step: 1803  | total loss: [1m[32m0.10392[0m[0m | time: 71.724s
[2K
| RMSProp | epoch: 026 | loss: 0.10392 - acc: 0.9675 -- iter: 1696/2235
[A[ATraining Step: 1804  | total loss: [1m[32m0.10086[0m[0m | time: 72.944s
[2K
| RMSProp | epoch: 026 | loss: 0.10086 - acc: 0.9676 -- iter: 1728/2235
[A[ATraining Step: 1805  | total loss: [1m[32m0.09519[0m[0m | time: 74.298s
[2K
| RMSProp | epoch: 026 | loss: 0.09519 - acc: 0.9709 -- iter: 1760/2235
[A[ATraining Step: 1806  | total loss: [1m[32m0.09750[0m[0m | time: 75.641s
[2K
| RMSProp | epoch: 026 | loss: 0.09750 - acc: 0.9707 -- iter: 1792/2235
[A[ATraining Step: 1807  | total loss: [1m[32m0.08898[0m[0m | time: 76.643s
[2K
| RMSProp | epoch: 026 | loss: 0.08898 - acc: 0.9736 -- iter: 1824/2235
[A[ATraining Step: 1808  | total loss: [1m[32m0.09486[0m[0m | time: 77.861s
[2K
| RMSProp | epoch: 026 | loss: 0.09486 - acc: 0.9731 -- iter: 1856/2235
[A[ATraining Step: 1809  | total loss: [1m[32m0.08758[0m[0m | time: 79.157s
[2K
| RMSProp | epoch: 026 | loss: 0.08758 - acc: 0.9758 -- iter: 1888/2235
[A[ATraining Step: 1810  | total loss: [1m[32m0.09386[0m[0m | time: 80.369s
[2K
| RMSProp | epoch: 026 | loss: 0.09386 - acc: 0.9720 -- iter: 1920/2235
[A[ATraining Step: 1811  | total loss: [1m[32m0.08644[0m[0m | time: 81.467s
[2K
| RMSProp | epoch: 026 | loss: 0.08644 - acc: 0.9748 -- iter: 1952/2235
[A[ATraining Step: 1812  | total loss: [1m[32m0.08099[0m[0m | time: 82.858s
[2K
| RMSProp | epoch: 026 | loss: 0.08099 - acc: 0.9773 -- iter: 1984/2235
[A[ATraining Step: 1813  | total loss: [1m[32m0.07379[0m[0m | time: 84.256s
[2K
| RMSProp | epoch: 026 | loss: 0.07379 - acc: 0.9796 -- iter: 2016/2235
[A[ATraining Step: 1814  | total loss: [1m[32m0.11969[0m[0m | time: 85.590s
[2K
| RMSProp | epoch: 026 | loss: 0.11969 - acc: 0.9722 -- iter: 2048/2235
[A[ATraining Step: 1815  | total loss: [1m[32m0.11663[0m[0m | time: 86.621s
[2K
| RMSProp | epoch: 026 | loss: 0.11663 - acc: 0.9688 -- iter: 2080/2235
[A[ATraining Step: 1816  | total loss: [1m[32m0.10703[0m[0m | time: 87.914s
[2K
| RMSProp | epoch: 026 | loss: 0.10703 - acc: 0.9719 -- iter: 2112/2235
[A[ATraining Step: 1817  | total loss: [1m[32m0.10882[0m[0m | time: 89.265s
[2K
| RMSProp | epoch: 026 | loss: 0.10882 - acc: 0.9716 -- iter: 2144/2235
[A[ATraining Step: 1818  | total loss: [1m[32m0.09953[0m[0m | time: 90.521s
[2K
| RMSProp | epoch: 026 | loss: 0.09953 - acc: 0.9744 -- iter: 2176/2235
[A[ATraining Step: 1819  | total loss: [1m[32m0.09109[0m[0m | time: 91.591s
[2K
| RMSProp | epoch: 026 | loss: 0.09109 - acc: 0.9770 -- iter: 2208/2235
[A[ATraining Step: 1820  | total loss: [1m[32m0.08348[0m[0m | time: 98.353s
[2K
| RMSProp | epoch: 026 | loss: 0.08348 - acc: 0.9793 | val_loss: 0.88183 - val_acc: 0.7668 -- iter: 2235/2235
--
Training Step: 1821  | total loss: [1m[32m0.07590[0m[0m | time: 1.513s
[2K
| RMSProp | epoch: 027 | loss: 0.07590 - acc: 0.9813 -- iter: 0032/2235
[A[ATraining Step: 1822  | total loss: [1m[32m0.06882[0m[0m | time: 2.818s
[2K
| RMSProp | epoch: 027 | loss: 0.06882 - acc: 0.9832 -- iter: 0064/2235
[A[ATraining Step: 1823  | total loss: [1m[32m0.06253[0m[0m | time: 4.115s
[2K
| RMSProp | epoch: 027 | loss: 0.06253 - acc: 0.9849 -- iter: 0096/2235
[A[ATraining Step: 1824  | total loss: [1m[32m0.05671[0m[0m | time: 5.524s
[2K
| RMSProp | epoch: 027 | loss: 0.05671 - acc: 0.9864 -- iter: 0128/2235
[A[ATraining Step: 1825  | total loss: [1m[32m0.06726[0m[0m | time: 6.700s
[2K
| RMSProp | epoch: 027 | loss: 0.06726 - acc: 0.9846 -- iter: 0160/2235
[A[ATraining Step: 1826  | total loss: [1m[32m0.06134[0m[0m | time: 7.941s
[2K
| RMSProp | epoch: 027 | loss: 0.06134 - acc: 0.9862 -- iter: 0192/2235
[A[ATraining Step: 1827  | total loss: [1m[32m0.07108[0m[0m | time: 9.155s
[2K
| RMSProp | epoch: 027 | loss: 0.07108 - acc: 0.9844 -- iter: 0224/2235
[A[ATraining Step: 1828  | total loss: [1m[32m0.07231[0m[0m | time: 10.449s
[2K
| RMSProp | epoch: 027 | loss: 0.07231 - acc: 0.9829 -- iter: 0256/2235
[A[ATraining Step: 1829  | total loss: [1m[32m0.08031[0m[0m | time: 11.690s
[2K
| RMSProp | epoch: 027 | loss: 0.08031 - acc: 0.9815 -- iter: 0288/2235
[A[ATraining Step: 1830  | total loss: [1m[32m0.07870[0m[0m | time: 13.046s
[2K
| RMSProp | epoch: 027 | loss: 0.07870 - acc: 0.9802 -- iter: 0320/2235
[A[ATraining Step: 1831  | total loss: [1m[32m0.08296[0m[0m | time: 14.292s
[2K
| RMSProp | epoch: 027 | loss: 0.08296 - acc: 0.9759 -- iter: 0352/2235
[A[ATraining Step: 1832  | total loss: [1m[32m0.08006[0m[0m | time: 15.782s
[2K
| RMSProp | epoch: 027 | loss: 0.08006 - acc: 0.9783 -- iter: 0384/2235
[A[ATraining Step: 1833  | total loss: [1m[32m0.08568[0m[0m | time: 17.117s
[2K
| RMSProp | epoch: 027 | loss: 0.08568 - acc: 0.9774 -- iter: 0416/2235
[A[ATraining Step: 1834  | total loss: [1m[32m0.08320[0m[0m | time: 18.455s
[2K
| RMSProp | epoch: 027 | loss: 0.08320 - acc: 0.9765 -- iter: 0448/2235
[A[ATraining Step: 1835  | total loss: [1m[32m0.07574[0m[0m | time: 19.740s
[2K
| RMSProp | epoch: 027 | loss: 0.07574 - acc: 0.9789 -- iter: 0480/2235
[A[ATraining Step: 1836  | total loss: [1m[32m0.07121[0m[0m | time: 21.049s
[2K
| RMSProp | epoch: 027 | loss: 0.07121 - acc: 0.9778 -- iter: 0512/2235
[A[ATraining Step: 1837  | total loss: [1m[32m0.06513[0m[0m | time: 22.293s
[2K
| RMSProp | epoch: 027 | loss: 0.06513 - acc: 0.9801 -- iter: 0544/2235
[A[ATraining Step: 1838  | total loss: [1m[32m0.06184[0m[0m | time: 23.434s
[2K
| RMSProp | epoch: 027 | loss: 0.06184 - acc: 0.9821 -- iter: 0576/2235
[A[ATraining Step: 1839  | total loss: [1m[32m0.05614[0m[0m | time: 24.692s
[2K
| RMSProp | epoch: 027 | loss: 0.05614 - acc: 0.9838 -- iter: 0608/2235
[A[ATraining Step: 1840  | total loss: [1m[32m0.05178[0m[0m | time: 25.938s
[2K
| RMSProp | epoch: 027 | loss: 0.05178 - acc: 0.9855 -- iter: 0640/2235
[A[ATraining Step: 1841  | total loss: [1m[32m0.04710[0m[0m | time: 27.176s
[2K
| RMSProp | epoch: 027 | loss: 0.04710 - acc: 0.9869 -- iter: 0672/2235
[A[ATraining Step: 1842  | total loss: [1m[32m0.04360[0m[0m | time: 28.507s
[2K
| RMSProp | epoch: 027 | loss: 0.04360 - acc: 0.9882 -- iter: 0704/2235
[A[ATraining Step: 1843  | total loss: [1m[32m0.03941[0m[0m | time: 29.765s
[2K
| RMSProp | epoch: 027 | loss: 0.03941 - acc: 0.9894 -- iter: 0736/2235
[A[ATraining Step: 1844  | total loss: [1m[32m0.04787[0m[0m | time: 31.069s
[2K
| RMSProp | epoch: 027 | loss: 0.04787 - acc: 0.9873 -- iter: 0768/2235
[A[ATraining Step: 1845  | total loss: [1m[32m0.04361[0m[0m | time: 32.224s
[2K
| RMSProp | epoch: 027 | loss: 0.04361 - acc: 0.9886 -- iter: 0800/2235
[A[ATraining Step: 1846  | total loss: [1m[32m0.03949[0m[0m | time: 33.312s
[2K
| RMSProp | epoch: 027 | loss: 0.03949 - acc: 0.9897 -- iter: 0832/2235
[A[ATraining Step: 1847  | total loss: [1m[32m0.03572[0m[0m | time: 34.637s
[2K
| RMSProp | epoch: 027 | loss: 0.03572 - acc: 0.9908 -- iter: 0864/2235
[A[ATraining Step: 1848  | total loss: [1m[32m0.03585[0m[0m | time: 35.827s
[2K
| RMSProp | epoch: 027 | loss: 0.03585 - acc: 0.9886 -- iter: 0896/2235
[A[ATraining Step: 1849  | total loss: [1m[32m0.03289[0m[0m | time: 36.892s
[2K
| RMSProp | epoch: 027 | loss: 0.03289 - acc: 0.9897 -- iter: 0928/2235
[A[ATraining Step: 1850  | total loss: [1m[32m0.03030[0m[0m | time: 38.365s
[2K
| RMSProp | epoch: 027 | loss: 0.03030 - acc: 0.9907 -- iter: 0960/2235
[A[ATraining Step: 1851  | total loss: [1m[32m0.02752[0m[0m | time: 39.580s
[2K
| RMSProp | epoch: 027 | loss: 0.02752 - acc: 0.9917 -- iter: 0992/2235
[A[ATraining Step: 1852  | total loss: [1m[32m0.03206[0m[0m | time: 40.770s
[2K
| RMSProp | epoch: 027 | loss: 0.03206 - acc: 0.9894 -- iter: 1024/2235
[A[ATraining Step: 1853  | total loss: [1m[32m0.03549[0m[0m | time: 42.149s
[2K
| RMSProp | epoch: 027 | loss: 0.03549 - acc: 0.9842 -- iter: 1056/2235
[A[ATraining Step: 1854  | total loss: [1m[32m0.05597[0m[0m | time: 43.537s
[2K
| RMSProp | epoch: 027 | loss: 0.05597 - acc: 0.9764 -- iter: 1088/2235
[A[ATraining Step: 1855  | total loss: [1m[32m0.05416[0m[0m | time: 44.977s
[2K
| RMSProp | epoch: 027 | loss: 0.05416 - acc: 0.9788 -- iter: 1120/2235
[A[ATraining Step: 1856  | total loss: [1m[32m0.04959[0m[0m | time: 46.144s
[2K
| RMSProp | epoch: 027 | loss: 0.04959 - acc: 0.9809 -- iter: 1152/2235
[A[ATraining Step: 1857  | total loss: [1m[32m0.05450[0m[0m | time: 47.482s
[2K
| RMSProp | epoch: 027 | loss: 0.05450 - acc: 0.9797 -- iter: 1184/2235
[A[ATraining Step: 1858  | total loss: [1m[32m0.05923[0m[0m | time: 48.969s
[2K
| RMSProp | epoch: 027 | loss: 0.05923 - acc: 0.9786 -- iter: 1216/2235
[A[ATraining Step: 1859  | total loss: [1m[32m0.05547[0m[0m | time: 50.179s
[2K
| RMSProp | epoch: 027 | loss: 0.05547 - acc: 0.9807 -- iter: 1248/2235
[A[ATraining Step: 1860  | total loss: [1m[32m0.05016[0m[0m | time: 51.162s
[2K
| RMSProp | epoch: 027 | loss: 0.05016 - acc: 0.9826 -- iter: 1280/2235
[A[ATraining Step: 1861  | total loss: [1m[32m0.04555[0m[0m | time: 52.434s
[2K
| RMSProp | epoch: 027 | loss: 0.04555 - acc: 0.9844 -- iter: 1312/2235
[A[ATraining Step: 1862  | total loss: [1m[32m0.05223[0m[0m | time: 53.688s
[2K
| RMSProp | epoch: 027 | loss: 0.05223 - acc: 0.9828 -- iter: 1344/2235
[A[ATraining Step: 1863  | total loss: [1m[32m0.04722[0m[0m | time: 54.952s
[2K
| RMSProp | epoch: 027 | loss: 0.04722 - acc: 0.9845 -- iter: 1376/2235
[A[ATraining Step: 1864  | total loss: [1m[32m0.07869[0m[0m | time: 56.288s
[2K
| RMSProp | epoch: 027 | loss: 0.07869 - acc: 0.9767 -- iter: 1408/2235
[A[ATraining Step: 1865  | total loss: [1m[32m0.07464[0m[0m | time: 57.757s
[2K
| RMSProp | epoch: 027 | loss: 0.07464 - acc: 0.9759 -- iter: 1440/2235
[A[ATraining Step: 1866  | total loss: [1m[32m0.06785[0m[0m | time: 59.079s
[2K
| RMSProp | epoch: 027 | loss: 0.06785 - acc: 0.9783 -- iter: 1472/2235
[A[ATraining Step: 1867  | total loss: [1m[32m0.07668[0m[0m | time: 60.282s
[2K
| RMSProp | epoch: 027 | loss: 0.07668 - acc: 0.9774 -- iter: 1504/2235
[A[ATraining Step: 1868  | total loss: [1m[32m0.07068[0m[0m | time: 61.733s
[2K
| RMSProp | epoch: 027 | loss: 0.07068 - acc: 0.9796 -- iter: 1536/2235
[A[ATraining Step: 1869  | total loss: [1m[32m0.06666[0m[0m | time: 63.119s
[2K
| RMSProp | epoch: 027 | loss: 0.06666 - acc: 0.9785 -- iter: 1568/2235
[A[ATraining Step: 1870  | total loss: [1m[32m0.06226[0m[0m | time: 64.474s
[2K
| RMSProp | epoch: 027 | loss: 0.06226 - acc: 0.9807 -- iter: 1600/2235
[A[ATraining Step: 1871  | total loss: [1m[32m0.05676[0m[0m | time: 65.597s
[2K
| RMSProp | epoch: 027 | loss: 0.05676 - acc: 0.9826 -- iter: 1632/2235
[A[ATraining Step: 1872  | total loss: [1m[32m0.05202[0m[0m | time: 66.571s
[2K
| RMSProp | epoch: 027 | loss: 0.05202 - acc: 0.9844 -- iter: 1664/2235
[A[ATraining Step: 1873  | total loss: [1m[32m0.05684[0m[0m | time: 67.855s
[2K
| RMSProp | epoch: 027 | loss: 0.05684 - acc: 0.9828 -- iter: 1696/2235
[A[ATraining Step: 1874  | total loss: [1m[32m0.05160[0m[0m | time: 69.102s
[2K
| RMSProp | epoch: 027 | loss: 0.05160 - acc: 0.9845 -- iter: 1728/2235
[A[ATraining Step: 1875  | total loss: [1m[32m0.04764[0m[0m | time: 70.420s
[2K
| RMSProp | epoch: 027 | loss: 0.04764 - acc: 0.9861 -- iter: 1760/2235
[A[ATraining Step: 1876  | total loss: [1m[32m0.04312[0m[0m | time: 71.817s
[2K
| RMSProp | epoch: 027 | loss: 0.04312 - acc: 0.9875 -- iter: 1792/2235
[A[ATraining Step: 1877  | total loss: [1m[32m0.04986[0m[0m | time: 73.105s
[2K
| RMSProp | epoch: 027 | loss: 0.04986 - acc: 0.9856 -- iter: 1824/2235
[A[ATraining Step: 1878  | total loss: [1m[32m0.08452[0m[0m | time: 74.340s
[2K
| RMSProp | epoch: 027 | loss: 0.08452 - acc: 0.9808 -- iter: 1856/2235
[A[ATraining Step: 1879  | total loss: [1m[32m0.07779[0m[0m | time: 75.591s
[2K
| RMSProp | epoch: 027 | loss: 0.07779 - acc: 0.9827 -- iter: 1888/2235
[A[ATraining Step: 1880  | total loss: [1m[32m0.07219[0m[0m | time: 76.828s
[2K
| RMSProp | epoch: 027 | loss: 0.07219 - acc: 0.9844 -- iter: 1920/2235
[A[ATraining Step: 1881  | total loss: [1m[32m0.06585[0m[0m | time: 77.960s
[2K
| RMSProp | epoch: 027 | loss: 0.06585 - acc: 0.9860 -- iter: 1952/2235
[A[ATraining Step: 1882  | total loss: [1m[32m0.06099[0m[0m | time: 79.419s
[2K
| RMSProp | epoch: 027 | loss: 0.06099 - acc: 0.9874 -- iter: 1984/2235
[A[ATraining Step: 1883  | total loss: [1m[32m0.07023[0m[0m | time: 80.829s
[2K
| RMSProp | epoch: 027 | loss: 0.07023 - acc: 0.9855 -- iter: 2016/2235
[A[ATraining Step: 1884  | total loss: [1m[32m0.07553[0m[0m | time: 82.098s
[2K
| RMSProp | epoch: 027 | loss: 0.07553 - acc: 0.9807 -- iter: 2048/2235
[A[ATraining Step: 1885  | total loss: [1m[32m0.07685[0m[0m | time: 83.258s
[2K
| RMSProp | epoch: 027 | loss: 0.07685 - acc: 0.9795 -- iter: 2080/2235
[A[ATraining Step: 1886  | total loss: [1m[32m0.08247[0m[0m | time: 84.532s
[2K
| RMSProp | epoch: 027 | loss: 0.08247 - acc: 0.9784 -- iter: 2112/2235
[A[ATraining Step: 1887  | total loss: [1m[32m0.07554[0m[0m | time: 85.880s
[2K
| RMSProp | epoch: 027 | loss: 0.07554 - acc: 0.9806 -- iter: 2144/2235
[A[ATraining Step: 1888  | total loss: [1m[32m0.06842[0m[0m | time: 87.219s
[2K
| RMSProp | epoch: 027 | loss: 0.06842 - acc: 0.9825 -- iter: 2176/2235
[A[ATraining Step: 1889  | total loss: [1m[32m0.06229[0m[0m | time: 88.435s
[2K
| RMSProp | epoch: 027 | loss: 0.06229 - acc: 0.9843 -- iter: 2208/2235
[A[ATraining Step: 1890  | total loss: [1m[32m0.05732[0m[0m | time: 93.758s
[2K
| RMSProp | epoch: 027 | loss: 0.05732 - acc: 0.9859 | val_loss: 1.01060 - val_acc: 0.7511 -- iter: 2235/2235
--
Training Step: 1891  | total loss: [1m[32m0.05232[0m[0m | time: 1.149s
[2K
| RMSProp | epoch: 028 | loss: 0.05232 - acc: 0.9873 -- iter: 0032/2235
[A[ATraining Step: 1892  | total loss: [1m[32m0.04753[0m[0m | time: 2.145s
[2K
| RMSProp | epoch: 028 | loss: 0.04753 - acc: 0.9885 -- iter: 0064/2235
[A[ATraining Step: 1893  | total loss: [1m[32m0.04314[0m[0m | time: 2.943s
[2K
| RMSProp | epoch: 028 | loss: 0.04314 - acc: 0.9897 -- iter: 0096/2235
[A[ATraining Step: 1894  | total loss: [1m[32m0.03904[0m[0m | time: 3.879s
[2K
| RMSProp | epoch: 028 | loss: 0.03904 - acc: 0.9907 -- iter: 0128/2235
[A[ATraining Step: 1895  | total loss: [1m[32m0.03547[0m[0m | time: 4.905s
[2K
| RMSProp | epoch: 028 | loss: 0.03547 - acc: 0.9917 -- iter: 0160/2235
[A[ATraining Step: 1896  | total loss: [1m[32m0.03235[0m[0m | time: 5.957s
[2K
| RMSProp | epoch: 028 | loss: 0.03235 - acc: 0.9925 -- iter: 0192/2235
[A[ATraining Step: 1897  | total loss: [1m[32m0.02923[0m[0m | time: 6.890s
[2K
| RMSProp | epoch: 028 | loss: 0.02923 - acc: 0.9932 -- iter: 0224/2235
[A[ATraining Step: 1898  | total loss: [1m[32m0.03321[0m[0m | time: 7.907s
[2K
| RMSProp | epoch: 028 | loss: 0.03321 - acc: 0.9908 -- iter: 0256/2235
[A[ATraining Step: 1899  | total loss: [1m[32m0.07165[0m[0m | time: 8.913s
[2K
| RMSProp | epoch: 028 | loss: 0.07165 - acc: 0.9792 -- iter: 0288/2235
[A[ATraining Step: 1900  | total loss: [1m[32m0.09574[0m[0m | time: 9.843s
[2K
| RMSProp | epoch: 028 | loss: 0.09574 - acc: 0.9719 -- iter: 0320/2235
[A[ATraining Step: 1901  | total loss: [1m[32m0.09138[0m[0m | time: 10.893s
[2K
| RMSProp | epoch: 028 | loss: 0.09138 - acc: 0.9716 -- iter: 0352/2235
[A[ATraining Step: 1902  | total loss: [1m[32m0.08366[0m[0m | time: 12.005s
[2K
| RMSProp | epoch: 028 | loss: 0.08366 - acc: 0.9744 -- iter: 0384/2235
[A[ATraining Step: 1903  | total loss: [1m[32m0.07692[0m[0m | time: 13.006s
[2K
| RMSProp | epoch: 028 | loss: 0.07692 - acc: 0.9770 -- iter: 0416/2235
[A[ATraining Step: 1904  | total loss: [1m[32m0.11641[0m[0m | time: 13.837s
[2K
| RMSProp | epoch: 028 | loss: 0.11641 - acc: 0.9668 -- iter: 0448/2235
[A[ATraining Step: 1905  | total loss: [1m[32m0.10601[0m[0m | time: 14.826s
[2K
| RMSProp | epoch: 028 | loss: 0.10601 - acc: 0.9701 -- iter: 0480/2235
[A[ATraining Step: 1906  | total loss: [1m[32m0.09766[0m[0m | time: 15.845s
[2K
| RMSProp | epoch: 028 | loss: 0.09766 - acc: 0.9731 -- iter: 0512/2235
[A[ATraining Step: 1907  | total loss: [1m[32m0.08978[0m[0m | time: 17.041s
[2K
| RMSProp | epoch: 028 | loss: 0.08978 - acc: 0.9758 -- iter: 0544/2235
[A[ATraining Step: 1908  | total loss: [1m[32m0.08224[0m[0m | time: 18.380s
[2K
| RMSProp | epoch: 028 | loss: 0.08224 - acc: 0.9782 -- iter: 0576/2235
[A[ATraining Step: 1909  | total loss: [1m[32m0.09651[0m[0m | time: 19.721s
[2K
| RMSProp | epoch: 028 | loss: 0.09651 - acc: 0.9773 -- iter: 0608/2235
[A[ATraining Step: 1910  | total loss: [1m[32m0.10114[0m[0m | time: 20.837s
[2K
| RMSProp | epoch: 028 | loss: 0.10114 - acc: 0.9764 -- iter: 0640/2235
[A[ATraining Step: 1911  | total loss: [1m[32m0.09388[0m[0m | time: 22.002s
[2K
| RMSProp | epoch: 028 | loss: 0.09388 - acc: 0.9788 -- iter: 0672/2235
[A[ATraining Step: 1912  | total loss: [1m[32m0.08580[0m[0m | time: 23.199s
[2K
| RMSProp | epoch: 028 | loss: 0.08580 - acc: 0.9809 -- iter: 0704/2235
[A[ATraining Step: 1913  | total loss: [1m[32m0.07815[0m[0m | time: 24.542s
[2K
| RMSProp | epoch: 028 | loss: 0.07815 - acc: 0.9828 -- iter: 0736/2235
[A[ATraining Step: 1914  | total loss: [1m[32m0.07611[0m[0m | time: 25.945s
[2K
| RMSProp | epoch: 028 | loss: 0.07611 - acc: 0.9814 -- iter: 0768/2235
[A[ATraining Step: 1915  | total loss: [1m[32m0.07652[0m[0m | time: 27.273s
[2K
| RMSProp | epoch: 028 | loss: 0.07652 - acc: 0.9801 -- iter: 0800/2235
[A[ATraining Step: 1916  | total loss: [1m[32m0.08062[0m[0m | time: 28.270s
[2K
| RMSProp | epoch: 028 | loss: 0.08062 - acc: 0.9790 -- iter: 0832/2235
[A[ATraining Step: 1917  | total loss: [1m[32m0.07553[0m[0m | time: 29.301s
[2K
| RMSProp | epoch: 028 | loss: 0.07553 - acc: 0.9811 -- iter: 0864/2235
[A[ATraining Step: 1918  | total loss: [1m[32m0.06864[0m[0m | time: 30.510s
[2K
| RMSProp | epoch: 028 | loss: 0.06864 - acc: 0.9830 -- iter: 0896/2235
[A[ATraining Step: 1919  | total loss: [1m[32m0.06427[0m[0m | time: 31.874s
[2K
| RMSProp | epoch: 028 | loss: 0.06427 - acc: 0.9847 -- iter: 0928/2235
[A[ATraining Step: 1920  | total loss: [1m[32m0.05972[0m[0m | time: 33.210s
[2K
| RMSProp | epoch: 028 | loss: 0.05972 - acc: 0.9862 -- iter: 0960/2235
[A[ATraining Step: 1921  | total loss: [1m[32m0.06869[0m[0m | time: 34.371s
[2K
| RMSProp | epoch: 028 | loss: 0.06869 - acc: 0.9845 -- iter: 0992/2235
[A[ATraining Step: 1922  | total loss: [1m[32m0.06215[0m[0m | time: 35.551s
[2K
| RMSProp | epoch: 028 | loss: 0.06215 - acc: 0.9860 -- iter: 1024/2235
[A[ATraining Step: 1923  | total loss: [1m[32m0.05799[0m[0m | time: 36.910s
[2K
| RMSProp | epoch: 028 | loss: 0.05799 - acc: 0.9874 -- iter: 1056/2235
[A[ATraining Step: 1924  | total loss: [1m[32m0.05272[0m[0m | time: 38.191s
[2K
| RMSProp | epoch: 028 | loss: 0.05272 - acc: 0.9887 -- iter: 1088/2235
[A[ATraining Step: 1925  | total loss: [1m[32m0.04799[0m[0m | time: 39.370s
[2K
| RMSProp | epoch: 028 | loss: 0.04799 - acc: 0.9898 -- iter: 1120/2235
[A[ATraining Step: 1926  | total loss: [1m[32m0.04347[0m[0m | time: 40.633s
[2K
| RMSProp | epoch: 028 | loss: 0.04347 - acc: 0.9908 -- iter: 1152/2235
[A[ATraining Step: 1927  | total loss: [1m[32m0.03928[0m[0m | time: 41.944s
[2K
| RMSProp | epoch: 028 | loss: 0.03928 - acc: 0.9917 -- iter: 1184/2235
[A[ATraining Step: 1928  | total loss: [1m[32m0.03559[0m[0m | time: 43.276s
[2K
| RMSProp | epoch: 028 | loss: 0.03559 - acc: 0.9926 -- iter: 1216/2235
[A[ATraining Step: 1929  | total loss: [1m[32m0.03238[0m[0m | time: 44.235s
[2K
| RMSProp | epoch: 028 | loss: 0.03238 - acc: 0.9933 -- iter: 1248/2235
[A[ATraining Step: 1930  | total loss: [1m[32m0.04018[0m[0m | time: 45.544s
[2K
| RMSProp | epoch: 028 | loss: 0.04018 - acc: 0.9909 -- iter: 1280/2235
[A[ATraining Step: 1931  | total loss: [1m[32m0.05278[0m[0m | time: 47.059s
[2K
| RMSProp | epoch: 028 | loss: 0.05278 - acc: 0.9855 -- iter: 1312/2235
[A[ATraining Step: 1932  | total loss: [1m[32m0.06595[0m[0m | time: 48.473s
[2K
| RMSProp | epoch: 028 | loss: 0.06595 - acc: 0.9807 -- iter: 1344/2235
[A[ATraining Step: 1933  | total loss: [1m[32m0.07443[0m[0m | time: 49.561s
[2K
| RMSProp | epoch: 028 | loss: 0.07443 - acc: 0.9764 -- iter: 1376/2235
[A[ATraining Step: 1934  | total loss: [1m[32m0.06767[0m[0m | time: 50.798s
[2K
| RMSProp | epoch: 028 | loss: 0.06767 - acc: 0.9788 -- iter: 1408/2235
[A[ATraining Step: 1935  | total loss: [1m[32m0.06167[0m[0m | time: 51.975s
[2K
| RMSProp | epoch: 028 | loss: 0.06167 - acc: 0.9809 -- iter: 1440/2235
[A[ATraining Step: 1936  | total loss: [1m[32m0.05585[0m[0m | time: 53.316s
[2K
| RMSProp | epoch: 028 | loss: 0.05585 - acc: 0.9828 -- iter: 1472/2235
[A[ATraining Step: 1937  | total loss: [1m[32m0.05106[0m[0m | time: 54.574s
[2K
| RMSProp | epoch: 028 | loss: 0.05106 - acc: 0.9845 -- iter: 1504/2235
[A[ATraining Step: 1938  | total loss: [1m[32m0.04609[0m[0m | time: 55.841s
[2K
| RMSProp | epoch: 028 | loss: 0.04609 - acc: 0.9861 -- iter: 1536/2235
[A[ATraining Step: 1939  | total loss: [1m[32m0.04163[0m[0m | time: 57.270s
[2K
| RMSProp | epoch: 028 | loss: 0.04163 - acc: 0.9875 -- iter: 1568/2235
[A[ATraining Step: 1940  | total loss: [1m[32m0.03773[0m[0m | time: 58.694s
[2K
| RMSProp | epoch: 028 | loss: 0.03773 - acc: 0.9887 -- iter: 1600/2235
[A[ATraining Step: 1941  | total loss: [1m[32m0.03443[0m[0m | time: 59.913s
[2K
| RMSProp | epoch: 028 | loss: 0.03443 - acc: 0.9898 -- iter: 1632/2235
[A[ATraining Step: 1942  | total loss: [1m[32m0.03117[0m[0m | time: 61.095s
[2K
| RMSProp | epoch: 028 | loss: 0.03117 - acc: 0.9909 -- iter: 1664/2235
[A[ATraining Step: 1943  | total loss: [1m[32m0.02821[0m[0m | time: 62.181s
[2K
| RMSProp | epoch: 028 | loss: 0.02821 - acc: 0.9918 -- iter: 1696/2235
[A[ATraining Step: 1944  | total loss: [1m[32m0.02554[0m[0m | time: 63.350s
[2K
| RMSProp | epoch: 028 | loss: 0.02554 - acc: 0.9926 -- iter: 1728/2235
[A[ATraining Step: 1945  | total loss: [1m[32m0.02307[0m[0m | time: 64.545s
[2K
| RMSProp | epoch: 028 | loss: 0.02307 - acc: 0.9933 -- iter: 1760/2235
[A[ATraining Step: 1946  | total loss: [1m[32m0.02081[0m[0m | time: 65.762s
[2K
| RMSProp | epoch: 028 | loss: 0.02081 - acc: 0.9940 -- iter: 1792/2235
[A[ATraining Step: 1947  | total loss: [1m[32m0.02842[0m[0m | time: 67.081s
[2K
| RMSProp | epoch: 028 | loss: 0.02842 - acc: 0.9915 -- iter: 1824/2235
[A[ATraining Step: 1948  | total loss: [1m[32m0.06586[0m[0m | time: 68.252s
[2K
| RMSProp | epoch: 028 | loss: 0.06586 - acc: 0.9798 -- iter: 1856/2235
[A[ATraining Step: 1949  | total loss: [1m[32m0.09937[0m[0m | time: 69.618s
[2K
| RMSProp | epoch: 028 | loss: 0.09937 - acc: 0.9693 -- iter: 1888/2235
[A[ATraining Step: 1950  | total loss: [1m[32m0.10122[0m[0m | time: 70.780s
[2K
| RMSProp | epoch: 028 | loss: 0.10122 - acc: 0.9662 -- iter: 1920/2235
[A[ATraining Step: 1951  | total loss: [1m[32m0.09194[0m[0m | time: 72.008s
[2K
| RMSProp | epoch: 028 | loss: 0.09194 - acc: 0.9695 -- iter: 1952/2235
[A[ATraining Step: 1952  | total loss: [1m[32m0.08337[0m[0m | time: 73.298s
[2K
| RMSProp | epoch: 028 | loss: 0.08337 - acc: 0.9726 -- iter: 1984/2235
[A[ATraining Step: 1953  | total loss: [1m[32m0.07714[0m[0m | time: 74.490s
[2K
| RMSProp | epoch: 028 | loss: 0.07714 - acc: 0.9753 -- iter: 2016/2235
[A[ATraining Step: 1954  | total loss: [1m[32m0.07937[0m[0m | time: 75.614s
[2K
| RMSProp | epoch: 028 | loss: 0.07937 - acc: 0.9747 -- iter: 2048/2235
[A[ATraining Step: 1955  | total loss: [1m[32m0.07362[0m[0m | time: 76.845s
[2K
| RMSProp | epoch: 028 | loss: 0.07362 - acc: 0.9772 -- iter: 2080/2235
[A[ATraining Step: 1956  | total loss: [1m[32m0.07897[0m[0m | time: 78.138s
[2K
| RMSProp | epoch: 028 | loss: 0.07897 - acc: 0.9764 -- iter: 2112/2235
[A[ATraining Step: 1957  | total loss: [1m[32m0.07201[0m[0m | time: 79.468s
[2K
| RMSProp | epoch: 028 | loss: 0.07201 - acc: 0.9787 -- iter: 2144/2235
[A[ATraining Step: 1958  | total loss: [1m[32m0.06685[0m[0m | time: 80.710s
[2K
| RMSProp | epoch: 028 | loss: 0.06685 - acc: 0.9809 -- iter: 2176/2235
[A[ATraining Step: 1959  | total loss: [1m[32m0.06063[0m[0m | time: 81.819s
[2K
| RMSProp | epoch: 028 | loss: 0.06063 - acc: 0.9828 -- iter: 2208/2235
[A[ATraining Step: 1960  | total loss: [1m[32m0.05581[0m[0m | time: 88.606s
[2K
| RMSProp | epoch: 028 | loss: 0.05581 - acc: 0.9845 | val_loss: 1.02254 - val_acc: 0.7868 -- iter: 2235/2235
--
Training Step: 1961  | total loss: [1m[32m0.05101[0m[0m | time: 1.065s
[2K
| RMSProp | epoch: 029 | loss: 0.05101 - acc: 0.9860 -- iter: 0032/2235
[A[ATraining Step: 1962  | total loss: [1m[32m0.04630[0m[0m | time: 2.196s
[2K
| RMSProp | epoch: 029 | loss: 0.04630 - acc: 0.9874 -- iter: 0064/2235
[A[ATraining Step: 1963  | total loss: [1m[32m0.04179[0m[0m | time: 3.595s
[2K
| RMSProp | epoch: 029 | loss: 0.04179 - acc: 0.9887 -- iter: 0096/2235
[A[ATraining Step: 1964  | total loss: [1m[32m0.03772[0m[0m | time: 4.962s
[2K
| RMSProp | epoch: 029 | loss: 0.03772 - acc: 0.9898 -- iter: 0128/2235
[A[ATraining Step: 1965  | total loss: [1m[32m0.03442[0m[0m | time: 6.165s
[2K
| RMSProp | epoch: 029 | loss: 0.03442 - acc: 0.9908 -- iter: 0160/2235
[A[ATraining Step: 1966  | total loss: [1m[32m0.03125[0m[0m | time: 7.334s
[2K
| RMSProp | epoch: 029 | loss: 0.03125 - acc: 0.9918 -- iter: 0192/2235
[A[ATraining Step: 1967  | total loss: [1m[32m0.02832[0m[0m | time: 8.585s
[2K
| RMSProp | epoch: 029 | loss: 0.02832 - acc: 0.9926 -- iter: 0224/2235
[A[ATraining Step: 1968  | total loss: [1m[32m0.06497[0m[0m | time: 9.843s
[2K
| RMSProp | epoch: 029 | loss: 0.06497 - acc: 0.9871 -- iter: 0256/2235
[A[ATraining Step: 1969  | total loss: [1m[32m0.06196[0m[0m | time: 11.130s
[2K
| RMSProp | epoch: 029 | loss: 0.06196 - acc: 0.9884 -- iter: 0288/2235
[A[ATraining Step: 1970  | total loss: [1m[32m0.07821[0m[0m | time: 12.359s
[2K
| RMSProp | epoch: 029 | loss: 0.07821 - acc: 0.9864 -- iter: 0320/2235
[A[ATraining Step: 1971  | total loss: [1m[32m0.07721[0m[0m | time: 13.860s
[2K
| RMSProp | epoch: 029 | loss: 0.07721 - acc: 0.9846 -- iter: 0352/2235
[A[ATraining Step: 1972  | total loss: [1m[32m0.07261[0m[0m | time: 15.191s
[2K
| RMSProp | epoch: 029 | loss: 0.07261 - acc: 0.9862 -- iter: 0384/2235
[A[ATraining Step: 1973  | total loss: [1m[32m0.06591[0m[0m | time: 16.344s
[2K
| RMSProp | epoch: 029 | loss: 0.06591 - acc: 0.9876 -- iter: 0416/2235
[A[ATraining Step: 1974  | total loss: [1m[32m0.06032[0m[0m | time: 17.533s
[2K
| RMSProp | epoch: 029 | loss: 0.06032 - acc: 0.9888 -- iter: 0448/2235
[A[ATraining Step: 1975  | total loss: [1m[32m0.05454[0m[0m | time: 18.880s
[2K
| RMSProp | epoch: 029 | loss: 0.05454 - acc: 0.9899 -- iter: 0480/2235
[A[ATraining Step: 1976  | total loss: [1m[32m0.04937[0m[0m | time: 20.191s
[2K
| RMSProp | epoch: 029 | loss: 0.04937 - acc: 0.9909 -- iter: 0512/2235
[A[ATraining Step: 1977  | total loss: [1m[32m0.04481[0m[0m | time: 21.335s
[2K
| RMSProp | epoch: 029 | loss: 0.04481 - acc: 0.9918 -- iter: 0544/2235
[A[ATraining Step: 1978  | total loss: [1m[32m0.04058[0m[0m | time: 22.577s
[2K
| RMSProp | epoch: 029 | loss: 0.04058 - acc: 0.9927 -- iter: 0576/2235
[A[ATraining Step: 1979  | total loss: [1m[32m0.03692[0m[0m | time: 23.808s
[2K
| RMSProp | epoch: 029 | loss: 0.03692 - acc: 0.9934 -- iter: 0608/2235
[A[ATraining Step: 1980  | total loss: [1m[32m0.03346[0m[0m | time: 25.085s
[2K
| RMSProp | epoch: 029 | loss: 0.03346 - acc: 0.9940 -- iter: 0640/2235
[A[ATraining Step: 1981  | total loss: [1m[32m0.03021[0m[0m | time: 26.257s
[2K
| RMSProp | epoch: 029 | loss: 0.03021 - acc: 0.9946 -- iter: 0672/2235
[A[ATraining Step: 1982  | total loss: [1m[32m0.02731[0m[0m | time: 27.588s
[2K
| RMSProp | epoch: 029 | loss: 0.02731 - acc: 0.9952 -- iter: 0704/2235
[A[ATraining Step: 1983  | total loss: [1m[32m0.03306[0m[0m | time: 28.834s
[2K
| RMSProp | epoch: 029 | loss: 0.03306 - acc: 0.9925 -- iter: 0736/2235
[A[ATraining Step: 1984  | total loss: [1m[32m0.04689[0m[0m | time: 30.146s
[2K
| RMSProp | epoch: 029 | loss: 0.04689 - acc: 0.9870 -- iter: 0768/2235
[A[ATraining Step: 1985  | total loss: [1m[32m0.04806[0m[0m | time: 31.464s
[2K
| RMSProp | epoch: 029 | loss: 0.04806 - acc: 0.9852 -- iter: 0800/2235
[A[ATraining Step: 1986  | total loss: [1m[32m0.05963[0m[0m | time: 32.683s
[2K
| RMSProp | epoch: 029 | loss: 0.05963 - acc: 0.9836 -- iter: 0832/2235
[A[ATraining Step: 1987  | total loss: [1m[32m0.05662[0m[0m | time: 33.859s
[2K
| RMSProp | epoch: 029 | loss: 0.05662 - acc: 0.9852 -- iter: 0864/2235
[A[ATraining Step: 1988  | total loss: [1m[32m0.05306[0m[0m | time: 35.069s
[2K
| RMSProp | epoch: 029 | loss: 0.05306 - acc: 0.9867 -- iter: 0896/2235
[A[ATraining Step: 1989  | total loss: [1m[32m0.04812[0m[0m | time: 36.200s
[2K
| RMSProp | epoch: 029 | loss: 0.04812 - acc: 0.9880 -- iter: 0928/2235
[A[ATraining Step: 1990  | total loss: [1m[32m0.04530[0m[0m | time: 37.490s
[2K
| RMSProp | epoch: 029 | loss: 0.04530 - acc: 0.9892 -- iter: 0960/2235
[A[ATraining Step: 1991  | total loss: [1m[32m0.04125[0m[0m | time: 38.854s
[2K
| RMSProp | epoch: 029 | loss: 0.04125 - acc: 0.9903 -- iter: 0992/2235
[A[ATraining Step: 1992  | total loss: [1m[32m0.03762[0m[0m | time: 40.144s
[2K
| RMSProp | epoch: 029 | loss: 0.03762 - acc: 0.9913 -- iter: 1024/2235
[A[ATraining Step: 1993  | total loss: [1m[32m0.03437[0m[0m | time: 41.306s
[2K
| RMSProp | epoch: 029 | loss: 0.03437 - acc: 0.9921 -- iter: 1056/2235
[A[ATraining Step: 1994  | total loss: [1m[32m0.03110[0m[0m | time: 42.663s
[2K
| RMSProp | epoch: 029 | loss: 0.03110 - acc: 0.9929 -- iter: 1088/2235
[A[ATraining Step: 1995  | total loss: [1m[32m0.02826[0m[0m | time: 43.976s
[2K
| RMSProp | epoch: 029 | loss: 0.02826 - acc: 0.9936 -- iter: 1120/2235
[A[ATraining Step: 1996  | total loss: [1m[32m0.02626[0m[0m | time: 45.321s
[2K
| RMSProp | epoch: 029 | loss: 0.02626 - acc: 0.9943 -- iter: 1152/2235
[A[ATraining Step: 1997  | total loss: [1m[32m0.03923[0m[0m | time: 46.562s
[2K
| RMSProp | epoch: 029 | loss: 0.03923 - acc: 0.9917 -- iter: 1184/2235
[A[ATraining Step: 1998  | total loss: [1m[32m0.04112[0m[0m | time: 48.024s
[2K
| RMSProp | epoch: 029 | loss: 0.04112 - acc: 0.9894 -- iter: 1216/2235
[A[ATraining Step: 1999  | total loss: [1m[32m0.05186[0m[0m | time: 49.258s
[2K
| RMSProp | epoch: 029 | loss: 0.05186 - acc: 0.9874 -- iter: 1248/2235
[A[ATraining Step: 2000  | total loss: [1m[32m0.04725[0m[0m | time: 55.814s
[2K
| RMSProp | epoch: 029 | loss: 0.04725 - acc: 0.9886 | val_loss: 1.08114 - val_acc: 0.7668 -- iter: 1280/2235
--
Training Step: 2001  | total loss: [1m[32m0.04294[0m[0m | time: 57.089s
[2K
| RMSProp | epoch: 029 | loss: 0.04294 - acc: 0.9898 -- iter: 1312/2235
[A[ATraining Step: 2002  | total loss: [1m[32m0.04779[0m[0m | time: 58.400s
[2K
| RMSProp | epoch: 029 | loss: 0.04779 - acc: 0.9877 -- iter: 1344/2235
[A[ATraining Step: 2003  | total loss: [1m[32m0.04395[0m[0m | time: 59.764s
[2K
| RMSProp | epoch: 029 | loss: 0.04395 - acc: 0.9889 -- iter: 1376/2235
[A[ATraining Step: 2004  | total loss: [1m[32m0.06491[0m[0m | time: 60.917s
[2K
| RMSProp | epoch: 029 | loss: 0.06491 - acc: 0.9838 -- iter: 1408/2235
[A[ATraining Step: 2005  | total loss: [1m[32m0.06196[0m[0m | time: 62.266s
[2K
| RMSProp | epoch: 029 | loss: 0.06196 - acc: 0.9854 -- iter: 1440/2235
[A[ATraining Step: 2006  | total loss: [1m[32m0.05690[0m[0m | time: 63.656s
[2K
| RMSProp | epoch: 029 | loss: 0.05690 - acc: 0.9868 -- iter: 1472/2235
[A[ATraining Step: 2007  | total loss: [1m[32m0.05373[0m[0m | time: 65.041s
[2K
| RMSProp | epoch: 029 | loss: 0.05373 - acc: 0.9882 -- iter: 1504/2235
[A[ATraining Step: 2008  | total loss: [1m[32m0.04868[0m[0m | time: 65.996s
[2K
| RMSProp | epoch: 029 | loss: 0.04868 - acc: 0.9893 -- iter: 1536/2235
[A[ATraining Step: 2009  | total loss: [1m[32m0.05034[0m[0m | time: 67.233s
[2K
| RMSProp | epoch: 029 | loss: 0.05034 - acc: 0.9873 -- iter: 1568/2235
[A[ATraining Step: 2010  | total loss: [1m[32m0.06727[0m[0m | time: 68.488s
[2K
| RMSProp | epoch: 029 | loss: 0.06727 - acc: 0.9823 -- iter: 1600/2235
[A[ATraining Step: 2011  | total loss: [1m[32m0.06131[0m[0m | time: 69.717s
[2K
| RMSProp | epoch: 029 | loss: 0.06131 - acc: 0.9841 -- iter: 1632/2235
[A[ATraining Step: 2012  | total loss: [1m[32m0.05966[0m[0m | time: 71.009s
[2K
| RMSProp | epoch: 029 | loss: 0.05966 - acc: 0.9825 -- iter: 1664/2235
[A[ATraining Step: 2013  | total loss: [1m[32m0.06683[0m[0m | time: 72.266s
[2K
| RMSProp | epoch: 029 | loss: 0.06683 - acc: 0.9780 -- iter: 1696/2235
[A[ATraining Step: 2014  | total loss: [1m[32m0.06056[0m[0m | time: 73.665s
[2K
| RMSProp | epoch: 029 | loss: 0.06056 - acc: 0.9802 -- iter: 1728/2235
[A[ATraining Step: 2015  | total loss: [1m[32m0.05577[0m[0m | time: 75.006s
[2K
| RMSProp | epoch: 029 | loss: 0.05577 - acc: 0.9822 -- iter: 1760/2235
[A[ATraining Step: 2016  | total loss: [1m[32m0.05074[0m[0m | time: 76.238s
[2K
| RMSProp | epoch: 029 | loss: 0.05074 - acc: 0.9840 -- iter: 1792/2235
[A[ATraining Step: 2017  | total loss: [1m[32m0.06129[0m[0m | time: 77.600s
[2K
| RMSProp | epoch: 029 | loss: 0.06129 - acc: 0.9793 -- iter: 1824/2235
[A[ATraining Step: 2018  | total loss: [1m[32m0.05693[0m[0m | time: 79.113s
[2K
| RMSProp | epoch: 029 | loss: 0.05693 - acc: 0.9814 -- iter: 1856/2235
[A[ATraining Step: 2019  | total loss: [1m[32m0.05398[0m[0m | time: 80.403s
[2K
| RMSProp | epoch: 029 | loss: 0.05398 - acc: 0.9833 -- iter: 1888/2235
[A[ATraining Step: 2020  | total loss: [1m[32m0.07760[0m[0m | time: 81.481s
[2K
| RMSProp | epoch: 029 | loss: 0.07760 - acc: 0.9756 -- iter: 1920/2235
[A[ATraining Step: 2021  | total loss: [1m[32m0.09004[0m[0m | time: 82.716s
[2K
| RMSProp | epoch: 029 | loss: 0.09004 - acc: 0.9749 -- iter: 1952/2235
[A[ATraining Step: 2022  | total loss: [1m[32m0.09313[0m[0m | time: 84.023s
[2K
| RMSProp | epoch: 029 | loss: 0.09313 - acc: 0.9680 -- iter: 1984/2235
[A[ATraining Step: 2023  | total loss: [1m[32m0.08488[0m[0m | time: 85.258s
[2K
| RMSProp | epoch: 029 | loss: 0.08488 - acc: 0.9712 -- iter: 2016/2235
[A[ATraining Step: 2024  | total loss: [1m[32m0.07762[0m[0m | time: 86.570s
[2K
| RMSProp | epoch: 029 | loss: 0.07762 - acc: 0.9741 -- iter: 2048/2235
[A[ATraining Step: 2025  | total loss: [1m[32m0.07749[0m[0m | time: 87.866s
[2K
| RMSProp | epoch: 029 | loss: 0.07749 - acc: 0.9736 -- iter: 2080/2235
[A[ATraining Step: 2026  | total loss: [1m[32m0.07101[0m[0m | time: 89.139s
[2K
| RMSProp | epoch: 029 | loss: 0.07101 - acc: 0.9762 -- iter: 2112/2235
[A[ATraining Step: 2027  | total loss: [1m[32m0.23624[0m[0m | time: 90.369s
[2K
| RMSProp | epoch: 029 | loss: 0.23624 - acc: 0.9505 -- iter: 2144/2235
[A[ATraining Step: 2028  | total loss: [1m[32m0.21711[0m[0m | time: 91.758s
[2K
| RMSProp | epoch: 029 | loss: 0.21711 - acc: 0.9554 -- iter: 2176/2235
[A[ATraining Step: 2029  | total loss: [1m[32m0.19804[0m[0m | time: 93.045s
[2K
| RMSProp | epoch: 029 | loss: 0.19804 - acc: 0.9599 -- iter: 2208/2235
[A[ATraining Step: 2030  | total loss: [1m[32m0.17976[0m[0m | time: 99.146s
[2K
| RMSProp | epoch: 029 | loss: 0.17976 - acc: 0.9639 | val_loss: 0.79402 - val_acc: 0.7725 -- iter: 2235/2235
--
Training Step: 2031  | total loss: [1m[32m0.16389[0m[0m | time: 1.221s
[2K
| RMSProp | epoch: 030 | loss: 0.16389 - acc: 0.9675 -- iter: 0032/2235
[A[ATraining Step: 2032  | total loss: [1m[32m0.14859[0m[0m | time: 2.582s
[2K
| RMSProp | epoch: 030 | loss: 0.14859 - acc: 0.9707 -- iter: 0064/2235
[A[ATraining Step: 2033  | total loss: [1m[32m0.13705[0m[0m | time: 3.938s
[2K
| RMSProp | epoch: 030 | loss: 0.13705 - acc: 0.9737 -- iter: 0096/2235
[A[ATraining Step: 2034  | total loss: [1m[32m0.13350[0m[0m | time: 5.044s
[2K
| RMSProp | epoch: 030 | loss: 0.13350 - acc: 0.9732 -- iter: 0128/2235
[A[ATraining Step: 2035  | total loss: [1m[32m0.12139[0m[0m | time: 6.394s
[2K
| RMSProp | epoch: 030 | loss: 0.12139 - acc: 0.9759 -- iter: 0160/2235
[A[ATraining Step: 2036  | total loss: [1m[32m0.10967[0m[0m | time: 7.764s
[2K
| RMSProp | epoch: 030 | loss: 0.10967 - acc: 0.9783 -- iter: 0192/2235
[A[ATraining Step: 2037  | total loss: [1m[32m0.09957[0m[0m | time: 9.220s
[2K
| RMSProp | epoch: 030 | loss: 0.09957 - acc: 0.9804 -- iter: 0224/2235
[A[ATraining Step: 2038  | total loss: [1m[32m0.08989[0m[0m | time: 10.267s
[2K
| RMSProp | epoch: 030 | loss: 0.08989 - acc: 0.9824 -- iter: 0256/2235
[A[ATraining Step: 2039  | total loss: [1m[32m0.08123[0m[0m | time: 11.540s
[2K
| RMSProp | epoch: 030 | loss: 0.08123 - acc: 0.9842 -- iter: 0288/2235
[A[ATraining Step: 2040  | total loss: [1m[32m0.08582[0m[0m | time: 12.825s
[2K
| RMSProp | epoch: 030 | loss: 0.08582 - acc: 0.9826 -- iter: 0320/2235
[A[ATraining Step: 2041  | total loss: [1m[32m0.07747[0m[0m | time: 14.038s
[2K
| RMSProp | epoch: 030 | loss: 0.07747 - acc: 0.9844 -- iter: 0352/2235
[A[ATraining Step: 2042  | total loss: [1m[32m0.07627[0m[0m | time: 15.139s
[2K
| RMSProp | epoch: 030 | loss: 0.07627 - acc: 0.9828 -- iter: 0384/2235
[A[ATraining Step: 2043  | total loss: [1m[32m0.07117[0m[0m | time: 16.404s
[2K
| RMSProp | epoch: 030 | loss: 0.07117 - acc: 0.9814 -- iter: 0416/2235
[A[ATraining Step: 2044  | total loss: [1m[32m0.06659[0m[0m | time: 17.619s
[2K
| RMSProp | epoch: 030 | loss: 0.06659 - acc: 0.9833 -- iter: 0448/2235
[A[ATraining Step: 2045  | total loss: [1m[32m0.06040[0m[0m | time: 18.943s
[2K
| RMSProp | epoch: 030 | loss: 0.06040 - acc: 0.9849 -- iter: 0480/2235
[A[ATraining Step: 2046  | total loss: [1m[32m0.05464[0m[0m | time: 20.131s
[2K
| RMSProp | epoch: 030 | loss: 0.05464 - acc: 0.9864 -- iter: 0512/2235
[A[ATraining Step: 2047  | total loss: [1m[32m0.06428[0m[0m | time: 21.422s
[2K
| RMSProp | epoch: 030 | loss: 0.06428 - acc: 0.9847 -- iter: 0544/2235
[A[ATraining Step: 2048  | total loss: [1m[32m0.05988[0m[0m | time: 22.743s
[2K
| RMSProp | epoch: 030 | loss: 0.05988 - acc: 0.9862 -- iter: 0576/2235
[A[ATraining Step: 2049  | total loss: [1m[32m0.05656[0m[0m | time: 24.096s
[2K
| RMSProp | epoch: 030 | loss: 0.05656 - acc: 0.9876 -- iter: 0608/2235
[A[ATraining Step: 2050  | total loss: [1m[32m0.05142[0m[0m | time: 25.117s
[2K
| RMSProp | epoch: 030 | loss: 0.05142 - acc: 0.9888 -- iter: 0640/2235
[A[ATraining Step: 2051  | total loss: [1m[32m0.04652[0m[0m | time: 26.465s
[2K
| RMSProp | epoch: 030 | loss: 0.04652 - acc: 0.9899 -- iter: 0672/2235
[A[ATraining Step: 2052  | total loss: [1m[32m0.04199[0m[0m | time: 27.695s
[2K
| RMSProp | epoch: 030 | loss: 0.04199 - acc: 0.9909 -- iter: 0704/2235
[A[ATraining Step: 2053  | total loss: [1m[32m0.07361[0m[0m | time: 28.901s
[2K
| RMSProp | epoch: 030 | loss: 0.07361 - acc: 0.9856 -- iter: 0736/2235
[A[ATraining Step: 2054  | total loss: [1m[32m0.06806[0m[0m | time: 30.052s
[2K
| RMSProp | epoch: 030 | loss: 0.06806 - acc: 0.9870 -- iter: 0768/2235
[A[ATraining Step: 2055  | total loss: [1m[32m0.06269[0m[0m | time: 31.346s
[2K
| RMSProp | epoch: 030 | loss: 0.06269 - acc: 0.9883 -- iter: 0800/2235
[A[ATraining Step: 2056  | total loss: [1m[32m0.05793[0m[0m | time: 32.698s
[2K
| RMSProp | epoch: 030 | loss: 0.05793 - acc: 0.9895 -- iter: 0832/2235
[A[ATraining Step: 2057  | total loss: [1m[32m0.06262[0m[0m | time: 33.947s
[2K
| RMSProp | epoch: 030 | loss: 0.06262 - acc: 0.9874 -- iter: 0864/2235
[A[ATraining Step: 2058  | total loss: [1m[32m0.06965[0m[0m | time: 34.959s
[2K
| RMSProp | epoch: 030 | loss: 0.06965 - acc: 0.9856 -- iter: 0896/2235
[A[ATraining Step: 2059  | total loss: [1m[32m0.06322[0m[0m | time: 36.173s
[2K
| RMSProp | epoch: 030 | loss: 0.06322 - acc: 0.9870 -- iter: 0928/2235
[A[ATraining Step: 2060  | total loss: [1m[32m0.05727[0m[0m | time: 37.489s
[2K
| RMSProp | epoch: 030 | loss: 0.05727 - acc: 0.9883 -- iter: 0960/2235
[A[ATraining Step: 2061  | total loss: [1m[32m0.05313[0m[0m | time: 38.696s
[2K
| RMSProp | epoch: 030 | loss: 0.05313 - acc: 0.9895 -- iter: 0992/2235
[A[ATraining Step: 2062  | total loss: [1m[32m0.04862[0m[0m | time: 39.761s
[2K
| RMSProp | epoch: 030 | loss: 0.04862 - acc: 0.9905 -- iter: 1024/2235
[A[ATraining Step: 2063  | total loss: [1m[32m0.04456[0m[0m | time: 40.873s
[2K
| RMSProp | epoch: 030 | loss: 0.04456 - acc: 0.9915 -- iter: 1056/2235
[A[ATraining Step: 2064  | total loss: [1m[32m0.04038[0m[0m | time: 42.271s
[2K
| RMSProp | epoch: 030 | loss: 0.04038 - acc: 0.9923 -- iter: 1088/2235
[A[ATraining Step: 2065  | total loss: [1m[32m0.03667[0m[0m | time: 43.561s
[2K
| RMSProp | epoch: 030 | loss: 0.03667 - acc: 0.9931 -- iter: 1120/2235
[A[ATraining Step: 2066  | total loss: [1m[32m0.03338[0m[0m | time: 44.760s
[2K
| RMSProp | epoch: 030 | loss: 0.03338 - acc: 0.9938 -- iter: 1152/2235
[A[ATraining Step: 2067  | total loss: [1m[32m0.04221[0m[0m | time: 45.796s
[2K
| RMSProp | epoch: 030 | loss: 0.04221 - acc: 0.9913 -- iter: 1184/2235
[A[ATraining Step: 2068  | total loss: [1m[32m0.04212[0m[0m | time: 47.094s
[2K
| RMSProp | epoch: 030 | loss: 0.04212 - acc: 0.9890 -- iter: 1216/2235
[A[ATraining Step: 2069  | total loss: [1m[32m0.03936[0m[0m | time: 48.306s
[2K
| RMSProp | epoch: 030 | loss: 0.03936 - acc: 0.9901 -- iter: 1248/2235
[A[ATraining Step: 2070  | total loss: [1m[32m0.03590[0m[0m | time: 49.447s
[2K
| RMSProp | epoch: 030 | loss: 0.03590 - acc: 0.9911 -- iter: 1280/2235
[A[ATraining Step: 2071  | total loss: [1m[32m0.03246[0m[0m | time: 50.801s
[2K
| RMSProp | epoch: 030 | loss: 0.03246 - acc: 0.9920 -- iter: 1312/2235
[A[ATraining Step: 2072  | total loss: [1m[32m0.04750[0m[0m | time: 52.083s
[2K
| RMSProp | epoch: 030 | loss: 0.04750 - acc: 0.9897 -- iter: 1344/2235
[A[ATraining Step: 2073  | total loss: [1m[32m0.04358[0m[0m | time: 53.347s
[2K
| RMSProp | epoch: 030 | loss: 0.04358 - acc: 0.9907 -- iter: 1376/2235
[A[ATraining Step: 2074  | total loss: [1m[32m0.04015[0m[0m | time: 54.452s
[2K
| RMSProp | epoch: 030 | loss: 0.04015 - acc: 0.9916 -- iter: 1408/2235
[A[ATraining Step: 2075  | total loss: [1m[32m0.03639[0m[0m | time: 55.722s
[2K
| RMSProp | epoch: 030 | loss: 0.03639 - acc: 0.9925 -- iter: 1440/2235
[A[ATraining Step: 2076  | total loss: [1m[32m0.03303[0m[0m | time: 56.930s
[2K
| RMSProp | epoch: 030 | loss: 0.03303 - acc: 0.9932 -- iter: 1472/2235
[A[ATraining Step: 2077  | total loss: [1m[32m0.03076[0m[0m | time: 58.358s
[2K
| RMSProp | epoch: 030 | loss: 0.03076 - acc: 0.9939 -- iter: 1504/2235
[A[ATraining Step: 2078  | total loss: [1m[32m0.04690[0m[0m | time: 59.714s
[2K
| RMSProp | epoch: 030 | loss: 0.04690 - acc: 0.9914 -- iter: 1536/2235
[A[ATraining Step: 2079  | total loss: [1m[32m0.05411[0m[0m | time: 61.003s
[2K
| RMSProp | epoch: 030 | loss: 0.05411 - acc: 0.9891 -- iter: 1568/2235
[A[ATraining Step: 2080  | total loss: [1m[32m0.05150[0m[0m | time: 62.264s
[2K
| RMSProp | epoch: 030 | loss: 0.05150 - acc: 0.9902 -- iter: 1600/2235
[A[ATraining Step: 2081  | total loss: [1m[32m0.04790[0m[0m | time: 63.521s
[2K
| RMSProp | epoch: 030 | loss: 0.04790 - acc: 0.9912 -- iter: 1632/2235
[A[ATraining Step: 2082  | total loss: [1m[32m0.04460[0m[0m | time: 64.813s
[2K
| RMSProp | epoch: 030 | loss: 0.04460 - acc: 0.9921 -- iter: 1664/2235
[A[ATraining Step: 2083  | total loss: [1m[32m0.04259[0m[0m | time: 66.220s
[2K
| RMSProp | epoch: 030 | loss: 0.04259 - acc: 0.9929 -- iter: 1696/2235
[A[ATraining Step: 2084  | total loss: [1m[32m0.04569[0m[0m | time: 67.524s
[2K
| RMSProp | epoch: 030 | loss: 0.04569 - acc: 0.9905 -- iter: 1728/2235
[A[ATraining Step: 2085  | total loss: [1m[32m0.04951[0m[0m | time: 68.587s
[2K
| RMSProp | epoch: 030 | loss: 0.04951 - acc: 0.9883 -- iter: 1760/2235
[A[ATraining Step: 2086  | total loss: [1m[32m0.06137[0m[0m | time: 69.777s
[2K
| RMSProp | epoch: 030 | loss: 0.06137 - acc: 0.9832 -- iter: 1792/2235
[A[ATraining Step: 2087  | total loss: [1m[32m0.08335[0m[0m | time: 71.123s
[2K
| RMSProp | epoch: 030 | loss: 0.08335 - acc: 0.9693 -- iter: 1824/2235
[A[ATraining Step: 2088  | total loss: [1m[32m0.08831[0m[0m | time: 72.392s
[2K
| RMSProp | epoch: 030 | loss: 0.08831 - acc: 0.9692 -- iter: 1856/2235
[A[ATraining Step: 2089  | total loss: [1m[32m0.08128[0m[0m | time: 73.678s
[2K
| RMSProp | epoch: 030 | loss: 0.08128 - acc: 0.9723 -- iter: 1888/2235
[A[ATraining Step: 2090  | total loss: [1m[32m0.07507[0m[0m | time: 75.052s
[2K
| RMSProp | epoch: 030 | loss: 0.07507 - acc: 0.9751 -- iter: 1920/2235
[A[ATraining Step: 2091  | total loss: [1m[32m0.06851[0m[0m | time: 76.433s
[2K
| RMSProp | epoch: 030 | loss: 0.06851 - acc: 0.9776 -- iter: 1952/2235
[A[ATraining Step: 2092  | total loss: [1m[32m0.06241[0m[0m | time: 77.446s
[2K
| RMSProp | epoch: 030 | loss: 0.06241 - acc: 0.9798 -- iter: 1984/2235
[A[ATraining Step: 2093  | total loss: [1m[32m0.07496[0m[0m | time: 78.669s
[2K
| RMSProp | epoch: 030 | loss: 0.07496 - acc: 0.9756 -- iter: 2016/2235
[A[ATraining Step: 2094  | total loss: [1m[32m0.08270[0m[0m | time: 80.017s
[2K
| RMSProp | epoch: 030 | loss: 0.08270 - acc: 0.9749 -- iter: 2048/2235
[A[ATraining Step: 2095  | total loss: [1m[32m0.07592[0m[0m | time: 81.398s
[2K
| RMSProp | epoch: 030 | loss: 0.07592 - acc: 0.9774 -- iter: 2080/2235
[A[ATraining Step: 2096  | total loss: [1m[32m0.07264[0m[0m | time: 82.829s
[2K
| RMSProp | epoch: 030 | loss: 0.07264 - acc: 0.9765 -- iter: 2112/2235
[A[ATraining Step: 2097  | total loss: [1m[32m0.06686[0m[0m | time: 84.208s
[2K
| RMSProp | epoch: 030 | loss: 0.06686 - acc: 0.9789 -- iter: 2144/2235
[A[ATraining Step: 2098  | total loss: [1m[32m0.06558[0m[0m | time: 85.648s
[2K
| RMSProp | epoch: 030 | loss: 0.06558 - acc: 0.9779 -- iter: 2176/2235
[A[ATraining Step: 2099  | total loss: [1m[32m0.05932[0m[0m | time: 87.081s
[2K
| RMSProp | epoch: 030 | loss: 0.05932 - acc: 0.9801 -- iter: 2208/2235
[A[ATraining Step: 2100  | total loss: [1m[32m0.05366[0m[0m | time: 94.044s
[2K
| RMSProp | epoch: 030 | loss: 0.05366 - acc: 0.9821 | val_loss: 1.10895 - val_acc: 0.7568 -- iter: 2235/2235
--
2018-08-02 03:05:30.574633: W tensorflow/core/framework/allocator.cc:101] Allocation of 6330680832 exceeds 10% of system memory.
2018-08-02 03:05:36.757869: W tensorflow/core/framework/allocator.cc:101] Allocation of 6330680832 exceeds 10% of system memory.
Validation AUC:0.8172157000175224
Validation AUPRC:0.8641602514002291
Test AUC:0.8287830819578828
Test AUPRC:0.8685285154664806
BestTestF1Score	0.86	0.57	0.81	0.82	0.9	403	91	160	45	0.01
BestTestMCCScore	0.84	0.54	0.79	0.83	0.85	382	81	170	66	0.03
BestTestAccuracyScore	0.84	0.54	0.79	0.83	0.85	382	81	170	66	0.03
BestValidationF1Score	0.83	0.49	0.77	0.77	0.89	392	115	145	47	0.01
BestValidationMCC	0.82	0.5	0.77	0.79	0.86	377	99	161	62	0.03
BestValidationAccuracy	0.82	0.5	0.77	0.79	0.86	377	99	161	62	0.03
TestPredictions (Threshold:0.03)
CHEMBL139810,TP,ACT,1.0	CHEMBL337005,FN,ACT,0.019999999552965164	CHEMBL141834,FP,INACT,1.0	CHEMBL212401,FP,INACT,1.0	CHEMBL289185,FN,ACT,0.019999999552965164	CHEMBL495225,TN,INACT,0.0	CHEMBL96502,TP,ACT,1.0	CHEMBL36943,TP,ACT,0.8700000047683716	CHEMBL317713,TN,INACT,0.0	CHEMBL335491,TP,ACT,1.0	CHEMBL2391191,FP,INACT,0.3499999940395355	CHEMBL2391196,TN,INACT,0.0	CHEMBL352178,TP,ACT,1.0	CHEMBL2334324,TP,ACT,0.9399999976158142	CHEMBL3273012,FP,INACT,0.17000000178813934	CHEMBL230360,TP,ACT,0.8100000023841858	CHEMBL265363,TP,ACT,1.0	CHEMBL1808528,TP,ACT,0.7200000286102295	CHEMBL609702,TN,INACT,0.0	CHEMBL417546,FN,ACT,0.0	CHEMBL1313808,TN,INACT,0.019999999552965164	CHEMBL175398,TP,ACT,1.0	CHEMBL109251,TN,INACT,0.009999999776482582	CHEMBL77911,TN,INACT,0.0	CHEMBL305643,TN,INACT,0.0	CHEMBL317856,TP,ACT,1.0	CHEMBL288862,TP,ACT,0.9700000286102295	CHEMBL3666826,TP,ACT,1.0	CHEMBL91654,TP,ACT,0.699999988079071	CHEMBL3647987,FP,INACT,0.9399999976158142	CHEMBL344825,TP,ACT,1.0	CHEMBL307427,TN,INACT,0.009999999776482582	CHEMBL150138,TP,ACT,0.49000000953674316	CHEMBL406295,TP,ACT,1.0	CHEMBL79442,TP,ACT,1.0	CHEMBL1744051,TN,INACT,0.0	CHEMBL317271,FP,INACT,1.0	CHEMBL17253,TP,ACT,1.0	CHEMBL141043,TP,ACT,0.8399999737739563	CHEMBL53829,TP,ACT,0.9800000190734863	CHEMBL323452,FP,INACT,0.9900000095367432	CHEMBL3143643,FP,INACT,0.7400000095367432	CHEMBL3114836,TP,ACT,0.9700000286102295	CHEMBL42091,TP,ACT,1.0	CHEMBL46666,FP,INACT,0.9100000262260437	CHEMBL558042,TP,ACT,1.0	CHEMBL418050,TP,ACT,1.0	CHEMBL282260,TP,ACT,1.0	CHEMBL463179,FP,INACT,0.9599999785423279	CHEMBL341187,TP,ACT,0.9800000190734863	CHEMBL394724,TN,INACT,0.009999999776482582	CHEMBL395373,TP,ACT,1.0	CHEMBL106869,TN,INACT,0.009999999776482582	CHEMBL431292,TP,ACT,0.75	CHEMBL59690,TN,INACT,0.0	CHEMBL342568,TN,INACT,0.0	CHEMBL64838,TN,INACT,0.009999999776482582	CHEMBL255973,TP,ACT,1.0	CHEMBL416115,TP,ACT,0.9900000095367432	CHEMBL104,TN,INACT,0.009999999776482582	CHEMBL3091507,TP,ACT,1.0	CHEMBL43074,TP,ACT,1.0	CHEMBL47074,TP,ACT,1.0	CHEMBL206335,TP,ACT,0.9800000190734863	CHEMBL328772,TP,ACT,0.9900000095367432	CHEMBL1907917,FN,ACT,0.009999999776482582	CHEMBL599866,TP,ACT,0.8500000238418579	CHEMBL276864,TN,INACT,0.0	CHEMBL3666823,TP,ACT,1.0	CHEMBL290577,TP,ACT,1.0	CHEMBL193745,TP,ACT,0.9800000190734863	CHEMBL314189,TP,ACT,0.9700000286102295	CHEMBL32967,TP,ACT,1.0	CHEMBL412073,FP,INACT,0.36000001430511475	CHEMBL331871,TP,ACT,0.27000001072883606	CHEMBL111745,TN,INACT,0.0	CHEMBL164376,TP,ACT,1.0	CHEMBL101878,FP,INACT,0.28999999165534973	CHEMBL227794,TP,ACT,0.9700000286102295	CHEMBL430545,TP,ACT,0.9900000095367432	CHEMBL288920,TP,ACT,0.9900000095367432	CHEMBL3289300,FN,ACT,0.009999999776482582	CHEMBL597810,TP,ACT,1.0	CHEMBL37637,TP,ACT,1.0	CHEMBL213865,TP,ACT,0.9800000190734863	CHEMBL521570,TN,INACT,0.0	CHEMBL151562,TP,ACT,1.0	CHEMBL3741504,TP,ACT,1.0	CHEMBL567031,TP,ACT,0.8999999761581421	CHEMBL212723,FP,INACT,0.03999999910593033	CHEMBL318526,TN,INACT,0.0	CHEMBL2159294,FP,INACT,0.9599999785423279	CHEMBL333098,FP,INACT,0.9900000095367432	CHEMBL291101,TP,ACT,0.9900000095367432	CHEMBL302387,TN,INACT,0.029999999329447746	CHEMBL299582,TP,ACT,0.9599999785423279	CHEMBL29510,TP,ACT,1.0	CHEMBL3403532,FP,INACT,1.0	CHEMBL239536,FN,ACT,0.009999999776482582	CHEMBL2448367,TP,ACT,0.4399999976158142	CHEMBL513670,TP,ACT,0.10999999940395355	CHEMBL382573,TP,ACT,0.9900000095367432	CHEMBL341885,FP,INACT,0.9900000095367432	CHEMBL107392,TN,INACT,0.0	CHEMBL422803,FN,ACT,0.0	CHEMBL83675,FN,ACT,0.009999999776482582	CHEMBL539815,TP,ACT,0.09000000357627869	CHEMBL3273008,FP,INACT,0.9599999785423279	CHEMBL297220,FP,INACT,0.4000000059604645	CHEMBL46120,TN,INACT,0.009999999776482582	CHEMBL98858,FP,INACT,1.0	CHEMBL158925,TN,INACT,0.0	CHEMBL176221,TN,INACT,0.0	CHEMBL2316070,FP,INACT,1.0	CHEMBL295863,TP,ACT,1.0	CHEMBL3251185,TN,INACT,0.0	CHEMBL23468,TP,ACT,0.7400000095367432	CHEMBL101030,FN,ACT,0.009999999776482582	CHEMBL257889,FP,INACT,0.9300000071525574	CHEMBL62807,FP,INACT,0.3400000035762787	CHEMBL17381,TP,ACT,1.0	CHEMBL1087038,TP,ACT,0.9800000190734863	CHEMBL109050,FP,INACT,0.8500000238418579	CHEMBL3287437,TN,INACT,0.0	CHEMBL282281,TP,ACT,0.05000000074505806	CHEMBL45000,TP,ACT,0.6499999761581421	CHEMBL526504,TN,INACT,0.0	CHEMBL134440,TN,INACT,0.0	CHEMBL51392,TP,ACT,0.05999999865889549	CHEMBL271675,TP,ACT,0.9599999785423279	CHEMBL310289,TN,INACT,0.0	CHEMBL118428,TP,ACT,0.05999999865889549	CHEMBL147707,TN,INACT,0.0	CHEMBL1909808,TN,INACT,0.0	CHEMBL77742,TN,INACT,0.009999999776482582	CHEMBL351312,TP,ACT,0.03999999910593033	CHEMBL107282,TN,INACT,0.0	CHEMBL296941,TN,INACT,0.0	CHEMBL286634,TP,ACT,0.7099999785423279	CHEMBL3330470,TN,INACT,0.0	CHEMBL327093,TP,ACT,1.0	CHEMBL1644912,TN,INACT,0.009999999776482582	CHEMBL493520,TP,ACT,0.07000000029802322	CHEMBL107592,TN,INACT,0.0	CHEMBL103342,TP,ACT,1.0	CHEMBL2159301,TN,INACT,0.0	CHEMBL2370864,TN,INACT,0.009999999776482582	CHEMBL3091501,TP,ACT,0.5899999737739563	CHEMBL3115899,TP,ACT,0.05999999865889549	CHEMBL84442,TN,INACT,0.029999999329447746	CHEMBL418923,FN,ACT,0.009999999776482582	CHEMBL2391203,TN,INACT,0.0	CHEMBL1808497,TN,INACT,0.0	CHEMBL3277931,FP,INACT,0.9900000095367432	CHEMBL498545,TN,INACT,0.0	CHEMBL17365,TP,ACT,1.0	CHEMBL106718,FP,INACT,1.0	CHEMBL324793,TP,ACT,1.0	CHEMBL264626,FN,ACT,0.009999999776482582	CHEMBL3798162,TP,ACT,1.0	CHEMBL207271,TP,ACT,1.0	CHEMBL341920,TP,ACT,1.0	CHEMBL170338,TP,ACT,0.9599999785423279	CHEMBL310722,TP,ACT,0.9900000095367432	CHEMBL308427,TP,ACT,0.9900000095367432	CHEMBL117266,FN,ACT,0.0	CHEMBL32424,TP,ACT,1.0	CHEMBL62490,TN,INACT,0.0	CHEMBL3740693,TN,INACT,0.0	CHEMBL418017,TP,ACT,1.0	CHEMBL554824,FP,INACT,1.0	CHEMBL1788244,FP,INACT,1.0	CHEMBL24508,TP,ACT,1.0	CHEMBL390403,FN,ACT,0.0	CHEMBL2397954,TN,INACT,0.0	CHEMBL48409,TP,ACT,0.10000000149011612	CHEMBL390751,TP,ACT,0.800000011920929	CHEMBL96433,FN,ACT,0.0	CHEMBL107743,FP,INACT,1.0	CHEMBL153607,TP,ACT,1.0	CHEMBL193781,TP,ACT,1.0	CHEMBL231494,TP,ACT,0.9900000095367432	CHEMBL40862,FP,INACT,1.0	CHEMBL164426,TP,ACT,1.0	CHEMBL71513,TP,ACT,0.9399999976158142	CHEMBL497867,TP,ACT,1.0	CHEMBL309710,TN,INACT,0.0	CHEMBL138441,TP,ACT,1.0	CHEMBL54093,TP,ACT,1.0	CHEMBL66348,TP,ACT,0.5699999928474426	CHEMBL416912,TP,ACT,1.0	CHEMBL1159693,TP,ACT,1.0	CHEMBL124834,TP,ACT,1.0	CHEMBL2373341,TP,ACT,1.0	CHEMBL159757,TP,ACT,1.0	CHEMBL341808,TP,ACT,1.0	CHEMBL427978,TP,ACT,0.8700000047683716	CHEMBL2441043,TN,INACT,0.0	CHEMBL1945773,TN,INACT,0.0	CHEMBL180163,TP,ACT,0.9800000190734863	CHEMBL390402,TP,ACT,1.0	CHEMBL43817,TN,INACT,0.019999999552965164	CHEMBL349653,FP,INACT,0.14000000059604645	CHEMBL227250,TP,ACT,1.0	CHEMBL2373302,FN,ACT,0.0	CHEMBL199094,TP,ACT,1.0	CHEMBL195889,FP,INACT,1.0	CHEMBL50103,TP,ACT,0.25999999046325684	CHEMBL151939,TP,ACT,1.0	CHEMBL345435,FN,ACT,0.009999999776482582	CHEMBL416834,TN,INACT,0.0	CHEMBL103102,TN,INACT,0.009999999776482582	CHEMBL281573,FN,ACT,0.019999999552965164	CHEMBL1824558,FP,INACT,1.0	CHEMBL128182,TP,ACT,0.949999988079071	CHEMBL1682779,TP,ACT,1.0	CHEMBL101343,TN,INACT,0.0	CHEMBL2159391,TN,INACT,0.0	CHEMBL424630,FP,INACT,0.41999998688697815	CHEMBL3423008,TN,INACT,0.029999999329447746	CHEMBL2367632,FP,INACT,0.9900000095367432	CHEMBL3134465,FP,INACT,0.05000000074505806	CHEMBL317639,TP,ACT,0.9800000190734863	CHEMBL350114,TN,INACT,0.009999999776482582	CHEMBL22557,TP,ACT,0.9700000286102295	CHEMBL3115906,TP,ACT,0.8700000047683716	CHEMBL310265,TP,ACT,1.0	CHEMBL144707,TP,ACT,0.9900000095367432	CHEMBL1095032,FN,ACT,0.019999999552965164	CHEMBL243841,TP,ACT,1.0	CHEMBL335309,FP,INACT,0.9399999976158142	CHEMBL109535,TP,ACT,0.7300000190734863	CHEMBL50155,TP,ACT,0.6600000262260437	CHEMBL42495,TP,ACT,1.0	CHEMBL2092933,FN,ACT,0.009999999776482582	CHEMBL81887,TP,ACT,0.05999999865889549	CHEMBL3632761,TP,ACT,1.0	CHEMBL526453,TP,ACT,0.9599999785423279	CHEMBL1909804,TN,INACT,0.009999999776482582	CHEMBL103522,TP,ACT,1.0	CHEMBL1568729,TN,INACT,0.0	CHEMBL81846,TP,ACT,0.9399999976158142	CHEMBL431538,FN,ACT,0.0	CHEMBL327986,TP,ACT,1.0	CHEMBL572250,FP,INACT,0.23000000417232513	CHEMBL290212,TP,ACT,0.9399999976158142	CHEMBL179910,TP,ACT,0.07000000029802322	CHEMBL549732,FP,INACT,0.8999999761581421	CHEMBL215295,FP,INACT,0.05000000074505806	CHEMBL1909780,TN,INACT,0.0	CHEMBL160580,TN,INACT,0.0	CHEMBL2370450,TP,ACT,0.05000000074505806	CHEMBL119950,TP,ACT,1.0	CHEMBL402724,TP,ACT,0.9900000095367432	CHEMBL197668,TP,ACT,1.0	CHEMBL350280,FP,INACT,1.0	CHEMBL408300,FP,INACT,0.6800000071525574	CHEMBL3301638,FP,INACT,0.8100000023841858	CHEMBL2337671,TP,ACT,0.3400000035762787	CHEMBL167334,TP,ACT,1.0	CHEMBL432326,TP,ACT,0.6000000238418579	CHEMBL321322,FN,ACT,0.0	CHEMBL92523,TP,ACT,1.0	CHEMBL78562,TN,INACT,0.009999999776482582	CHEMBL66887,FP,INACT,0.03999999910593033	CHEMBL209963,TP,ACT,0.9900000095367432	CHEMBL24460,TP,ACT,0.9900000095367432	CHEMBL153412,TN,INACT,0.0	CHEMBL296177,TP,ACT,0.9800000190734863	CHEMBL295007,TN,INACT,0.0	CHEMBL1945765,TN,INACT,0.0	CHEMBL390969,TP,ACT,1.0	CHEMBL176031,TP,ACT,1.0	CHEMBL213158,TN,INACT,0.0	CHEMBL1952409,TP,ACT,0.8899999856948853	CHEMBL24108,TN,INACT,0.019999999552965164	CHEMBL460144,TP,ACT,0.9900000095367432	CHEMBL3741486,TN,INACT,0.0	CHEMBL446372,TP,ACT,0.05999999865889549	CHEMBL51292,TP,ACT,0.05999999865889549	CHEMBL278453,TN,INACT,0.0	CHEMBL2373062,FP,INACT,0.14000000059604645	CHEMBL109217,FN,ACT,0.019999999552965164	CHEMBL74648,TN,INACT,0.0	CHEMBL120413,TP,ACT,0.6299999952316284	CHEMBL17024,FN,ACT,0.009999999776482582	CHEMBL242998,TN,INACT,0.009999999776482582	CHEMBL102174,TP,ACT,1.0	CHEMBL92609,TP,ACT,0.8899999856948853	CHEMBL426806,TP,ACT,1.0	CHEMBL178777,TN,INACT,0.029999999329447746	CHEMBL321944,TP,ACT,0.9300000071525574	CHEMBL175738,TP,ACT,0.9900000095367432	CHEMBL318175,TN,INACT,0.009999999776482582	CHEMBL505189,FN,ACT,0.0	CHEMBL170457,TP,ACT,1.0	CHEMBL3596557,TN,INACT,0.0	CHEMBL116378,TP,ACT,0.9900000095367432	CHEMBL279270,TN,INACT,0.0	CHEMBL94799,FN,ACT,0.009999999776482582	CHEMBL32549,TP,ACT,0.6299999952316284	CHEMBL113532,FP,INACT,0.9900000095367432	CHEMBL330949,TP,ACT,0.9700000286102295	CHEMBL422722,TP,ACT,1.0	CHEMBL283851,TP,ACT,1.0	CHEMBL1196664,TP,ACT,1.0	CHEMBL3277925,TP,ACT,1.0	CHEMBL538931,TN,INACT,0.0	CHEMBL280158,FN,ACT,0.0	CHEMBL3787587,TP,ACT,0.9900000095367432	CHEMBL440755,TP,ACT,0.8100000023841858	CHEMBL3114556,TP,ACT,0.9900000095367432	CHEMBL3664003,TN,INACT,0.0	CHEMBL424052,FN,ACT,0.029999999329447746	CHEMBL420790,TP,ACT,0.9900000095367432	CHEMBL461629,FP,INACT,1.0	CHEMBL428982,TP,ACT,1.0	CHEMBL322307,TP,ACT,1.0	CHEMBL302913,TN,INACT,0.0	CHEMBL287252,TP,ACT,1.0	CHEMBL3423056,TN,INACT,0.0	CHEMBL404605,TN,INACT,0.009999999776482582	CHEMBL68169,TN,INACT,0.0	CHEMBL279628,TP,ACT,1.0	CHEMBL3423007,TP,ACT,0.9900000095367432	CHEMBL162461,TP,ACT,0.9900000095367432	CHEMBL40162,TP,ACT,0.5600000023841858	CHEMBL3706845,TP,ACT,0.49000000953674316	CHEMBL282568,TP,ACT,1.0	CHEMBL163578,TP,ACT,1.0	CHEMBL289318,FN,ACT,0.029999999329447746	CHEMBL37251,TP,ACT,1.0	CHEMBL597594,TN,INACT,0.0	CHEMBL1814822,TP,ACT,0.5400000214576721	CHEMBL174456,TP,ACT,0.7599999904632568	CHEMBL121608,TP,ACT,0.9900000095367432	CHEMBL115294,TP,ACT,1.0	CHEMBL27805,TP,ACT,0.27000001072883606	CHEMBL102916,TP,ACT,0.9800000190734863	CHEMBL317294,TP,ACT,1.0	CHEMBL3659627,FN,ACT,0.0	CHEMBL337365,TP,ACT,0.23000000417232513	CHEMBL1682695,TP,ACT,1.0	CHEMBL121982,TP,ACT,1.0	CHEMBL589492,TP,ACT,0.11999999731779099	CHEMBL308519,TN,INACT,0.0	CHEMBL1160757,TP,ACT,0.9300000071525574	CHEMBL41862,TP,ACT,1.0	CHEMBL338444,TP,ACT,1.0	CHEMBL288176,TP,ACT,1.0	CHEMBL2159374,TN,INACT,0.0	CHEMBL564165,TN,INACT,0.0	CHEMBL61442,FP,INACT,0.9599999785423279	CHEMBL395773,TP,ACT,0.9599999785423279	CHEMBL380589,TP,ACT,0.23000000417232513	CHEMBL2182017,TN,INACT,0.019999999552965164	CHEMBL485705,FP,INACT,1.0	CHEMBL93681,TP,ACT,0.12999999523162842	CHEMBL330531,TP,ACT,1.0	CHEMBL386463,TP,ACT,0.8399999737739563	CHEMBL421428,TP,ACT,1.0	CHEMBL468812,TP,ACT,0.9700000286102295	CHEMBL445678,TP,ACT,0.4000000059604645	CHEMBL153611,TP,ACT,1.0	CHEMBL37889,TP,ACT,1.0	CHEMBL287918,TP,ACT,1.0	CHEMBL572353,TP,ACT,1.0	CHEMBL367890,TP,ACT,0.9800000190734863	CHEMBL1909785,TN,INACT,0.0	CHEMBL287136,FP,INACT,0.03999999910593033	CHEMBL3277929,TN,INACT,0.0	CHEMBL2040989,TN,INACT,0.009999999776482582	CHEMBL609619,TP,ACT,1.0	CHEMBL279400,FP,INACT,1.0	CHEMBL179207,TP,ACT,0.9900000095367432	CHEMBL139432,TP,ACT,1.0	CHEMBL544760,TP,ACT,1.0	CHEMBL296663,TP,ACT,0.9399999976158142	CHEMBL3142553,TP,ACT,0.9800000190734863	CHEMBL19731,TP,ACT,0.6299999952316284	CHEMBL324349,FN,ACT,0.019999999552965164	CHEMBL121396,TP,ACT,0.10000000149011612	CHEMBL102502,TP,ACT,0.9800000190734863	CHEMBL321130,TP,ACT,1.0	CHEMBL163043,TP,ACT,0.1599999964237213	CHEMBL3084980,TN,INACT,0.0	CHEMBL327254,FP,INACT,0.9900000095367432	CHEMBL1909787,TN,INACT,0.009999999776482582	CHEMBL3287465,TN,INACT,0.0	CHEMBL415375,TP,ACT,0.9300000071525574	CHEMBL3251535,TN,INACT,0.0	CHEMBL226714,TN,INACT,0.0	CHEMBL200134,TP,ACT,1.0	CHEMBL448420,FP,INACT,1.0	CHEMBL308355,TN,INACT,0.0	CHEMBL320750,TN,INACT,0.009999999776482582	CHEMBL1087037,FN,ACT,0.009999999776482582	CHEMBL307727,FN,ACT,0.019999999552965164	CHEMBL172713,TN,INACT,0.0	CHEMBL3408421,FP,INACT,0.6800000071525574	CHEMBL1501309,TN,INACT,0.0	CHEMBL3125571,TN,INACT,0.0	CHEMBL327189,TP,ACT,1.0	CHEMBL84536,TP,ACT,0.9900000095367432	CHEMBL146910,TP,ACT,0.8199999928474426	CHEMBL102115,TP,ACT,0.1899999976158142	CHEMBL107598,TP,ACT,1.0	CHEMBL3608990,FP,INACT,0.3799999952316284	CHEMBL318052,TN,INACT,0.0	CHEMBL418729,FP,INACT,0.05999999865889549	CHEMBL96218,TP,ACT,0.9900000095367432	CHEMBL334257,TP,ACT,0.03999999910593033	CHEMBL7839,TN,INACT,0.0	CHEMBL166859,FP,INACT,0.9800000190734863	CHEMBL22100,TP,ACT,1.0	CHEMBL2159365,TN,INACT,0.009999999776482582	CHEMBL1808535,FN,ACT,0.009999999776482582	CHEMBL3799329,TN,INACT,0.0	CHEMBL159105,TN,INACT,0.0	CHEMBL34614,TP,ACT,0.4300000071525574	CHEMBL254962,TP,ACT,0.4300000071525574	CHEMBL364066,TN,INACT,0.0	CHEMBL468143,TP,ACT,0.9900000095367432	CHEMBL84462,TP,ACT,1.0	CHEMBL3084798,TN,INACT,0.009999999776482582	CHEMBL1160010,FP,INACT,0.23999999463558197	CHEMBL316383,TP,ACT,0.9900000095367432	CHEMBL19594,TN,INACT,0.0	CHEMBL36744,TP,ACT,1.0	CHEMBL1160518,TP,ACT,1.0	CHEMBL138855,TP,ACT,1.0	CHEMBL40292,TN,INACT,0.0	CHEMBL16064,TN,INACT,0.0	CHEMBL322437,TN,INACT,0.0	CHEMBL108670,FN,ACT,0.009999999776482582	CHEMBL1949835,TP,ACT,1.0	CHEMBL3596559,TN,INACT,0.0	CHEMBL402809,TP,ACT,1.0	CHEMBL432209,TP,ACT,1.0	CHEMBL3780548,FP,INACT,0.6000000238418579	CHEMBL2373352,TP,ACT,0.9800000190734863	CHEMBL37894,TP,ACT,0.7799999713897705	CHEMBL111036,TN,INACT,0.0	CHEMBL1682696,TP,ACT,1.0	CHEMBL131473,TP,ACT,0.07999999821186066	CHEMBL359132,TP,ACT,1.0	CHEMBL219354,TP,ACT,1.0	CHEMBL50649,TP,ACT,1.0	CHEMBL43457,TN,INACT,0.0	CHEMBL352197,TP,ACT,1.0	CHEMBL52109,FN,ACT,0.0	CHEMBL168411,TP,ACT,0.9399999976158142	CHEMBL243319,FP,INACT,0.8299999833106995	CHEMBL182124,TP,ACT,1.0	CHEMBL2334311,TP,ACT,1.0	CHEMBL1682766,TP,ACT,1.0	CHEMBL242525,FN,ACT,0.019999999552965164	CHEMBL74482,FP,INACT,0.7099999785423279	CHEMBL268640,TP,ACT,0.699999988079071	CHEMBL537450,TP,ACT,1.0	CHEMBL2409445,FN,ACT,0.019999999552965164	CHEMBL3809352,TP,ACT,1.0	CHEMBL150308,TP,ACT,0.800000011920929	CHEMBL3273013,FP,INACT,0.9800000190734863	CHEMBL215556,TN,INACT,0.009999999776482582	CHEMBL329182,TP,ACT,1.0	CHEMBL141877,TN,INACT,0.0	CHEMBL3808399,TP,ACT,1.0	CHEMBL391986,TP,ACT,0.9800000190734863	CHEMBL332819,TP,ACT,1.0	CHEMBL3415062,TP,ACT,1.0	CHEMBL51151,FN,ACT,0.0	CHEMBL344281,FP,INACT,1.0	CHEMBL556953,TP,ACT,1.0	CHEMBL78053,TN,INACT,0.0	CHEMBL350587,FN,ACT,0.009999999776482582	CHEMBL311067,TP,ACT,1.0	CHEMBL3647999,TN,INACT,0.0	CHEMBL91797,TP,ACT,1.0	CHEMBL107627,TN,INACT,0.0	CHEMBL274021,TN,INACT,0.0	CHEMBL2441048,TN,INACT,0.009999999776482582	CHEMBL295221,TP,ACT,1.0	CHEMBL540119,TP,ACT,1.0	CHEMBL209974,TN,INACT,0.0	CHEMBL10757,TN,INACT,0.0	CHEMBL165195,TN,INACT,0.0	CHEMBL92964,TN,INACT,0.009999999776482582	CHEMBL377627,TP,ACT,1.0	CHEMBL270050,FP,INACT,0.8500000238418579	CHEMBL44980,TP,ACT,1.0	CHEMBL96494,TP,ACT,0.9700000286102295	CHEMBL102552,TP,ACT,0.3199999928474426	CHEMBL2368546,TP,ACT,0.8799999952316284	CHEMBL321141,TP,ACT,1.0	CHEMBL150787,TP,ACT,1.0	CHEMBL423160,TN,INACT,0.0	CHEMBL1468612,TN,INACT,0.009999999776482582	CHEMBL20240,TP,ACT,0.9900000095367432	CHEMBL3093806,TP,ACT,0.07000000029802322	CHEMBL557221,TN,INACT,0.0	CHEMBL3289034,TP,ACT,1.0	CHEMBL305425,FN,ACT,0.009999999776482582	CHEMBL295010,TP,ACT,0.550000011920929	CHEMBL108202,TP,ACT,0.2199999988079071	CHEMBL269393,FN,ACT,0.009999999776482582	CHEMBL1160037,FN,ACT,0.019999999552965164	CHEMBL1335846,TN,INACT,0.009999999776482582	CHEMBL107097,TP,ACT,1.0	CHEMBL2441029,TN,INACT,0.0	CHEMBL330496,TP,ACT,0.8399999737739563	CHEMBL2326345,FP,INACT,0.4099999964237213	CHEMBL76448,FN,ACT,0.019999999552965164	CHEMBL2409219,TP,ACT,0.8899999856948853	CHEMBL26400,TP,ACT,1.0	CHEMBL318518,FN,ACT,0.009999999776482582	CHEMBL350048,FP,INACT,0.9800000190734863	CHEMBL126238,TP,ACT,1.0	CHEMBL379036,TP,ACT,1.0	CHEMBL137945,TP,ACT,1.0	CHEMBL25351,TP,ACT,1.0	CHEMBL2396783,FN,ACT,0.019999999552965164	CHEMBL59998,TN,INACT,0.0	CHEMBL327421,TP,ACT,1.0	CHEMBL349618,TP,ACT,0.9200000166893005	CHEMBL211561,FP,INACT,1.0	CHEMBL2011755,TN,INACT,0.0	CHEMBL1161263,TN,INACT,0.0	CHEMBL3408419,FP,INACT,0.9800000190734863	CHEMBL522532,TN,INACT,0.0	CHEMBL128576,TP,ACT,1.0	CHEMBL2370865,TN,INACT,0.009999999776482582	CHEMBL52932,FP,INACT,0.9800000190734863	CHEMBL2371636,TN,INACT,0.0	CHEMBL3648004,TN,INACT,0.0	CHEMBL19152,TN,INACT,0.009999999776482582	CHEMBL2409570,FN,ACT,0.019999999552965164	CHEMBL226775,TP,ACT,0.9900000095367432	CHEMBL311947,TP,ACT,1.0	CHEMBL605289,TN,INACT,0.009999999776482582	CHEMBL1682756,TP,ACT,0.9700000286102295	CHEMBL62222,TN,INACT,0.0	CHEMBL65273,TP,ACT,1.0	CHEMBL165665,TP,ACT,1.0	CHEMBL171354,FP,INACT,1.0	CHEMBL238902,FP,INACT,0.9800000190734863	CHEMBL289709,TP,ACT,0.4699999988079071	CHEMBL568275,TP,ACT,1.0	CHEMBL317428,TP,ACT,0.03999999910593033	CHEMBL1814696,FN,ACT,0.019999999552965164	CHEMBL298653,TN,INACT,0.009999999776482582	CHEMBL131999,TP,ACT,1.0	CHEMBL557472,TN,INACT,0.0	CHEMBL290378,TP,ACT,0.28999999165534973	CHEMBL431591,TN,INACT,0.0	CHEMBL50656,TN,INACT,0.0	CHEMBL104937,FN,ACT,0.0	CHEMBL377737,FN,ACT,0.0	CHEMBL3114840,TP,ACT,1.0	CHEMBL403735,TP,ACT,0.949999988079071	CHEMBL366697,TP,ACT,1.0	CHEMBL292488,TN,INACT,0.0	CHEMBL180677,TN,INACT,0.0	CHEMBL442766,TP,ACT,1.0	CHEMBL151293,TP,ACT,0.3199999928474426	CHEMBL442292,TP,ACT,0.9900000095367432	CHEMBL147430,TP,ACT,0.9599999785423279	CHEMBL162316,TP,ACT,0.9900000095367432	CHEMBL61059,TN,INACT,0.0	CHEMBL431429,TP,ACT,0.9900000095367432	CHEMBL75348,TP,ACT,0.9900000095367432	CHEMBL25484,FN,ACT,0.019999999552965164	CHEMBL322542,FN,ACT,0.0	CHEMBL94759,TP,ACT,1.0	CHEMBL2315242,TP,ACT,1.0	CHEMBL282837,TP,ACT,1.0	CHEMBL174702,FN,ACT,0.0	CHEMBL44500,TP,ACT,0.8299999833106995	CHEMBL1289648,TP,ACT,1.0	CHEMBL382064,TP,ACT,0.8100000023841858	CHEMBL328307,FP,INACT,1.0	CHEMBL419227,TP,ACT,0.05999999865889549	CHEMBL123757,FN,ACT,0.029999999329447746	CHEMBL122162,TP,ACT,1.0	CHEMBL211659,TP,ACT,1.0	CHEMBL527118,TN,INACT,0.0	CHEMBL190687,TP,ACT,1.0	CHEMBL164481,TP,ACT,0.9800000190734863	CHEMBL432704,TP,ACT,0.8799999952316284	CHEMBL2381492,TN,INACT,0.0	CHEMBL316213,TP,ACT,1.0	CHEMBL29744,TP,ACT,1.0	CHEMBL28922,TP,ACT,1.0	CHEMBL49082,TP,ACT,1.0	CHEMBL2028996,FN,ACT,0.009999999776482582	CHEMBL289734,TN,INACT,0.0	CHEMBL2313088,TN,INACT,0.0	CHEMBL138877,TP,ACT,1.0	CHEMBL92250,TN,INACT,0.019999999552965164	CHEMBL207184,TP,ACT,1.0	CHEMBL3115905,TP,ACT,0.9700000286102295	CHEMBL79545,TN,INACT,0.029999999329447746	CHEMBL3808596,TP,ACT,1.0	CHEMBL3752312,TN,INACT,0.0	CHEMBL256450,TP,ACT,0.10999999940395355	CHEMBL266551,TP,ACT,0.9900000095367432	CHEMBL395371,TP,ACT,1.0	CHEMBL123475,FP,INACT,1.0	CHEMBL179410,TP,ACT,0.9200000166893005	CHEMBL2204324,TP,ACT,1.0	CHEMBL3632873,FN,ACT,0.009999999776482582	CHEMBL356065,TP,ACT,1.0	CHEMBL303367,FN,ACT,0.0	CHEMBL322124,TP,ACT,1.0	CHEMBL1160766,TN,INACT,0.0	CHEMBL250271,TP,ACT,1.0	CHEMBL539559,TP,ACT,1.0	CHEMBL268514,TN,INACT,0.0	CHEMBL368927,TP,ACT,0.3499999940395355	CHEMBL2374242,TP,ACT,1.0	CHEMBL300135,TN,INACT,0.0	CHEMBL494513,TP,ACT,0.05999999865889549	CHEMBL392460,TP,ACT,0.9900000095367432	CHEMBL165875,TN,INACT,0.0	CHEMBL166779,TP,ACT,1.0	CHEMBL3289045,TP,ACT,1.0	CHEMBL1682785,TP,ACT,0.8500000238418579	CHEMBL241920,TP,ACT,1.0	CHEMBL3091502,FN,ACT,0.019999999552965164	CHEMBL116616,FN,ACT,0.009999999776482582	CHEMBL1089577,FP,INACT,1.0	CHEMBL331769,TP,ACT,0.9599999785423279	CHEMBL584260,TP,ACT,1.0	CHEMBL420540,TP,ACT,1.0	CHEMBL336553,TP,ACT,0.6399999856948853	CHEMBL11157,TP,ACT,1.0	CHEMBL50449,TP,ACT,0.8899999856948853	CHEMBL3647982,TN,INACT,0.0	CHEMBL3289015,TP,ACT,0.20000000298023224	CHEMBL163174,TP,ACT,0.7799999713897705	CHEMBL445385,TP,ACT,0.8299999833106995	CHEMBL213180,FP,INACT,0.8500000238418579	CHEMBL354119,TN,INACT,0.0	CHEMBL258286,TP,ACT,0.9800000190734863	CHEMBL24983,TN,INACT,0.0	CHEMBL572226,FP,INACT,1.0	CHEMBL50924,TP,ACT,0.05000000074505806	CHEMBL3289022,TP,ACT,1.0	CHEMBL3114831,TP,ACT,0.9700000286102295	CHEMBL167782,FN,ACT,0.0	CHEMBL3134463,FN,ACT,0.0	CHEMBL334482,TP,ACT,1.0	CHEMBL91999,TP,ACT,1.0	CHEMBL54137,TP,ACT,0.9900000095367432	CHEMBL369234,TN,INACT,0.0	CHEMBL3585735,TN,INACT,0.0	CHEMBL194316,TP,ACT,1.0	CHEMBL332293,TP,ACT,0.8299999833106995	CHEMBL164246,FN,ACT,0.0	CHEMBL3238369,TN,INACT,0.0	CHEMBL75255,TP,ACT,1.0	CHEMBL206205,TP,ACT,1.0	CHEMBL79640,TP,ACT,1.0	CHEMBL338321,TP,ACT,1.0	CHEMBL599649,FN,ACT,0.0	CHEMBL94702,TP,ACT,1.0	CHEMBL502292,TN,INACT,0.0	CHEMBL228173,FP,INACT,0.8999999761581421	CHEMBL418004,TP,ACT,0.9800000190734863	CHEMBL111122,FN,ACT,0.029999999329447746	CHEMBL352188,TP,ACT,1.0	CHEMBL399593,FN,ACT,0.019999999552965164	CHEMBL272394,TN,INACT,0.0	CHEMBL25527,TP,ACT,1.0	CHEMBL44249,FN,ACT,0.009999999776482582	CHEMBL388481,TP,ACT,1.0	CHEMBL100181,TP,ACT,1.0	CHEMBL2391202,TN,INACT,0.0	CHEMBL539557,TP,ACT,0.9599999785423279	CHEMBL55035,TP,ACT,0.9300000071525574	CHEMBL101041,FN,ACT,0.009999999776482582	CHEMBL192268,TP,ACT,1.0	CHEMBL10276,TN,INACT,0.0	CHEMBL427276,TP,ACT,1.0	CHEMBL62414,TN,INACT,0.0	CHEMBL338364,TP,ACT,1.0	CHEMBL3415058,TP,ACT,1.0	CHEMBL428218,TP,ACT,1.0	CHEMBL294776,TN,INACT,0.0	CHEMBL3247191,FP,INACT,0.5099999904632568	CHEMBL1834754,TN,INACT,0.009999999776482582	CHEMBL421944,TP,ACT,1.0	CHEMBL417635,TP,ACT,1.0	CHEMBL2040965,FP,INACT,1.0	CHEMBL116258,TP,ACT,1.0	CHEMBL7213,TP,ACT,0.03999999910593033	CHEMBL3409890,FP,INACT,0.12999999523162842	CHEMBL80128,TP,ACT,0.9599999785423279	CHEMBL1422664,FP,INACT,0.8500000238418579	

