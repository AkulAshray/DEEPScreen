CNNModel CHEMBL2321627 adam 0.001 15 128 0 0.8 False True
Number of active compounds :	153
Number of inactive compounds :	153
---------------------------------
Run id: CNNModel_CHEMBL2321627_adam_0.001_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2321627_adam_0.001_15_128_0.8_True/
---------------------------------
Training samples: 195
Validation samples: 62
--
Training Step: 1  | time: 1.775s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/195
[A[ATraining Step: 2  | total loss: [1m[32m0.62413[0m[0m | time: 8.325s
[2K
| Adam | epoch: 001 | loss: 0.62413 - acc: 0.3656 -- iter: 064/195
[A[ATraining Step: 3  | total loss: [1m[32m0.68053[0m[0m | time: 9.371s
[2K
| Adam | epoch: 001 | loss: 0.68053 - acc: 0.4756 -- iter: 096/195
[A[ATraining Step: 4  | total loss: [1m[32m0.69265[0m[0m | time: 10.599s
[2K
| Adam | epoch: 001 | loss: 0.69265 - acc: 0.4236 -- iter: 128/195
[A[ATraining Step: 5  | total loss: [1m[32m0.69380[0m[0m | time: 11.829s
[2K
| Adam | epoch: 001 | loss: 0.69380 - acc: 0.4332 -- iter: 160/195
[A[ATraining Step: 6  | total loss: [1m[32m0.69321[0m[0m | time: 13.047s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.5163 -- iter: 192/195
[A[ATraining Step: 7  | total loss: [1m[32m0.69335[0m[0m | time: 14.290s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.4690 | val_loss: 0.69354 - val_acc: 0.4677 -- iter: 195/195
--
Training Step: 8  | total loss: [1m[32m0.69275[0m[0m | time: 0.171s
[2K
| Adam | epoch: 002 | loss: 0.69275 - acc: 0.7677 -- iter: 032/195
[A[ATraining Step: 9  | total loss: [1m[32m0.68957[0m[0m | time: 1.041s
[2K
| Adam | epoch: 002 | loss: 0.68957 - acc: 0.8907 -- iter: 064/195
[A[ATraining Step: 10  | total loss: [1m[32m0.69022[0m[0m | time: 1.866s
[2K
| Adam | epoch: 002 | loss: 0.69022 - acc: 0.7422 -- iter: 096/195
[A[ATraining Step: 11  | total loss: [1m[32m0.69206[0m[0m | time: 2.871s
[2K
| Adam | epoch: 002 | loss: 0.69206 - acc: 0.6127 -- iter: 128/195
[A[ATraining Step: 12  | total loss: [1m[32m0.69319[0m[0m | time: 3.952s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5479 -- iter: 160/195
[A[ATraining Step: 13  | total loss: [1m[32m0.69452[0m[0m | time: 4.942s
[2K
| Adam | epoch: 002 | loss: 0.69452 - acc: 0.5006 -- iter: 192/195
[A[ATraining Step: 14  | total loss: [1m[32m0.69398[0m[0m | time: 8.981s
[2K
| Adam | epoch: 002 | loss: 0.69398 - acc: 0.5003 | val_loss: 0.69433 - val_acc: 0.4677 -- iter: 195/195
--
Training Step: 15  | total loss: [1m[32m0.69350[0m[0m | time: 0.159s
[2K
| Adam | epoch: 003 | loss: 0.69350 - acc: 0.5002 -- iter: 032/195
[A[ATraining Step: 16  | total loss: [1m[32m0.69735[0m[0m | time: 0.285s
[2K
| Adam | epoch: 003 | loss: 0.69735 - acc: 0.4376 -- iter: 064/195
[A[ATraining Step: 17  | total loss: [1m[32m0.69911[0m[0m | time: 1.201s
[2K
| Adam | epoch: 003 | loss: 0.69911 - acc: 0.4001 -- iter: 096/195
[A[ATraining Step: 18  | total loss: [1m[32m0.69810[0m[0m | time: 2.147s
[2K
| Adam | epoch: 003 | loss: 0.69810 - acc: 0.4130 -- iter: 128/195
[A[ATraining Step: 19  | total loss: [1m[32m0.69739[0m[0m | time: 3.071s
[2K
| Adam | epoch: 003 | loss: 0.69739 - acc: 0.4212 -- iter: 160/195
[A[ATraining Step: 20  | total loss: [1m[32m0.69682[0m[0m | time: 3.959s
[2K
| Adam | epoch: 003 | loss: 0.69682 - acc: 0.4264 -- iter: 192/195
[A[ATraining Step: 21  | total loss: [1m[32m0.69494[0m[0m | time: 5.886s
[2K
| Adam | epoch: 003 | loss: 0.69494 - acc: 0.4687 | val_loss: 0.69404 - val_acc: 0.4677 -- iter: 195/195
--
Training Step: 22  | total loss: [1m[32m0.69339[0m[0m | time: 0.897s
[2K
| Adam | epoch: 004 | loss: 0.69339 - acc: 0.5062 -- iter: 032/195
[A[ATraining Step: 23  | total loss: [1m[32m0.69257[0m[0m | time: 1.024s
[2K
| Adam | epoch: 004 | loss: 0.69257 - acc: 0.5225 -- iter: 064/195
[A[ATraining Step: 24  | total loss: [1m[32m0.69447[0m[0m | time: 1.164s
[2K
| Adam | epoch: 004 | loss: 0.69447 - acc: 0.4693 -- iter: 096/195
[A[ATraining Step: 25  | total loss: [1m[32m0.69260[0m[0m | time: 2.079s
[2K
| Adam | epoch: 004 | loss: 0.69260 - acc: 0.5231 -- iter: 128/195
[A[ATraining Step: 26  | total loss: [1m[32m0.69257[0m[0m | time: 2.982s
[2K
| Adam | epoch: 004 | loss: 0.69257 - acc: 0.5170 -- iter: 160/195
[A[ATraining Step: 27  | total loss: [1m[32m0.69057[0m[0m | time: 3.904s
[2K
| Adam | epoch: 004 | loss: 0.69057 - acc: 0.5609 -- iter: 192/195
[A[ATraining Step: 28  | total loss: [1m[32m0.68956[0m[0m | time: 5.891s
[2K
| Adam | epoch: 004 | loss: 0.68956 - acc: 0.5769 | val_loss: 0.69144 - val_acc: 0.4677 -- iter: 195/195
--
Training Step: 29  | total loss: [1m[32m0.69130[0m[0m | time: 1.064s
[2K
| Adam | epoch: 005 | loss: 0.69130 - acc: 0.5354 -- iter: 032/195
[A[ATraining Step: 30  | total loss: [1m[32m0.69298[0m[0m | time: 2.051s
[2K
| Adam | epoch: 005 | loss: 0.69298 - acc: 0.4900 -- iter: 064/195
[A[ATraining Step: 31  | total loss: [1m[32m0.69260[0m[0m | time: 2.144s
[2K
| Adam | epoch: 005 | loss: 0.69260 - acc: 0.4779 -- iter: 096/195
[A[ATraining Step: 32  | total loss: [1m[32m0.69009[0m[0m | time: 2.232s
[2K
| Adam | epoch: 005 | loss: 0.69009 - acc: 0.5204 -- iter: 128/195
[A[ATraining Step: 33  | total loss: [1m[32m0.69008[0m[0m | time: 3.076s
[2K
| Adam | epoch: 005 | loss: 0.69008 - acc: 0.5525 -- iter: 160/195
[A[ATraining Step: 34  | total loss: [1m[32m0.68814[0m[0m | time: 3.967s
[2K
| Adam | epoch: 005 | loss: 0.68814 - acc: 0.5412 -- iter: 192/195
[A[ATraining Step: 35  | total loss: [1m[32m0.68627[0m[0m | time: 5.841s
[2K
| Adam | epoch: 005 | loss: 0.68627 - acc: 0.5326 | val_loss: 0.66353 - val_acc: 0.4677 -- iter: 195/195
--
Training Step: 36  | total loss: [1m[32m0.68378[0m[0m | time: 0.890s
[2K
| Adam | epoch: 006 | loss: 0.68378 - acc: 0.5195 -- iter: 032/195
[A[ATraining Step: 37  | total loss: [1m[32m0.67825[0m[0m | time: 1.740s
[2K
| Adam | epoch: 006 | loss: 0.67825 - acc: 0.5281 -- iter: 064/195
[A[ATraining Step: 38  | total loss: [1m[32m0.67279[0m[0m | time: 2.769s
[2K
| Adam | epoch: 006 | loss: 0.67279 - acc: 0.5104 -- iter: 096/195
[A[ATraining Step: 39  | total loss: [1m[32m0.66275[0m[0m | time: 2.925s
[2K
| Adam | epoch: 006 | loss: 0.66275 - acc: 0.5383 -- iter: 128/195
[A[ATraining Step: 40  | total loss: [1m[32m0.64425[0m[0m | time: 3.100s
[2K
| Adam | epoch: 006 | loss: 0.64425 - acc: 0.5624 -- iter: 160/195
[A[ATraining Step: 41  | total loss: [1m[32m0.61112[0m[0m | time: 4.394s
[2K
| Adam | epoch: 006 | loss: 0.61112 - acc: 0.5815 -- iter: 192/195
[A[ATraining Step: 42  | total loss: [1m[32m0.59407[0m[0m | time: 18.982s
[2K
| Adam | epoch: 006 | loss: 0.59407 - acc: 0.5725 | val_loss: 0.44322 - val_acc: 0.9839 -- iter: 195/195
--
Training Step: 43  | total loss: [1m[32m0.58435[0m[0m | time: 11.845s
[2K
| Adam | epoch: 007 | loss: 0.58435 - acc: 0.6479 -- iter: 032/195
[A[ATraining Step: 44  | total loss: [1m[32m0.56299[0m[0m | time: 18.800s
[2K
| Adam | epoch: 007 | loss: 0.56299 - acc: 0.6981 -- iter: 064/195
[A[ATraining Step: 45  | total loss: [1m[32m0.52292[0m[0m | time: 27.705s
[2K
| Adam | epoch: 007 | loss: 0.52292 - acc: 0.7493 -- iter: 096/195
[A[ATraining Step: 46  | total loss: [1m[32m0.48966[0m[0m | time: 31.444s
[2K
| Adam | epoch: 007 | loss: 0.48966 - acc: 0.7703 -- iter: 128/195
[A[ATraining Step: 47  | total loss: [1m[32m0.44919[0m[0m | time: 31.570s
[2K
| Adam | epoch: 007 | loss: 0.44919 - acc: 0.8079 -- iter: 160/195
[A[ATraining Step: 48  | total loss: [1m[32m0.71734[0m[0m | time: 31.682s
[2K
| Adam | epoch: 007 | loss: 0.71734 - acc: 0.7316 -- iter: 192/195
[A[ATraining Step: 49  | total loss: [1m[32m0.74226[0m[0m | time: 33.758s
[2K
| Adam | epoch: 007 | loss: 0.74226 - acc: 0.6687 | val_loss: 0.37817 - val_acc: 0.8065 -- iter: 195/195
--
Training Step: 50  | total loss: [1m[32m0.70413[0m[0m | time: 1.109s
[2K
| Adam | epoch: 008 | loss: 0.70413 - acc: 0.6862 -- iter: 032/195
[A[ATraining Step: 51  | total loss: [1m[32m0.65365[0m[0m | time: 2.268s
[2K
| Adam | epoch: 008 | loss: 0.65365 - acc: 0.7102 -- iter: 064/195
[A[ATraining Step: 52  | total loss: [1m[32m0.59531[0m[0m | time: 3.501s
[2K
| Adam | epoch: 008 | loss: 0.59531 - acc: 0.7443 -- iter: 096/195
[A[ATraining Step: 53  | total loss: [1m[32m0.53324[0m[0m | time: 4.828s
[2K
| Adam | epoch: 008 | loss: 0.53324 - acc: 0.7820 -- iter: 128/195
[A[ATraining Step: 54  | total loss: [1m[32m0.48473[0m[0m | time: 6.119s
[2K
| Adam | epoch: 008 | loss: 0.48473 - acc: 0.8091 -- iter: 160/195
[A[ATraining Step: 55  | total loss: [1m[32m0.45431[0m[0m | time: 6.293s
[2K
| Adam | epoch: 008 | loss: 0.45431 - acc: 0.8230 -- iter: 192/195
[A[ATraining Step: 56  | total loss: [1m[32m0.47155[0m[0m | time: 7.470s
[2K
| Adam | epoch: 008 | loss: 0.47155 - acc: 0.8010 | val_loss: 0.23103 - val_acc: 0.9516 -- iter: 195/195
--
Training Step: 57  | total loss: [1m[32m0.41742[0m[0m | time: 16.778s
[2K
| Adam | epoch: 009 | loss: 0.41742 - acc: 0.8286 -- iter: 032/195
[A[ATraining Step: 58  | total loss: [1m[32m0.38875[0m[0m | time: 23.028s
[2K
| Adam | epoch: 009 | loss: 0.38875 - acc: 0.8434 -- iter: 064/195
[A[ATraining Step: 59  | total loss: [1m[32m0.34690[0m[0m | time: 27.895s
[2K
| Adam | epoch: 009 | loss: 0.34690 - acc: 0.8645 -- iter: 096/195
[A[ATraining Step: 60  | total loss: [1m[32m0.31815[0m[0m | time: 29.999s
[2K
| Adam | epoch: 009 | loss: 0.31815 - acc: 0.8741 -- iter: 128/195
[A[ATraining Step: 61  | total loss: [1m[32m0.28649[0m[0m | time: 31.145s
[2K
| Adam | epoch: 009 | loss: 0.28649 - acc: 0.8905 -- iter: 160/195
[A[ATraining Step: 62  | total loss: [1m[32m0.25766[0m[0m | time: 32.376s
[2K
| Adam | epoch: 009 | loss: 0.25766 - acc: 0.9046 -- iter: 192/195
[A[ATraining Step: 63  | total loss: [1m[32m0.22901[0m[0m | time: 33.574s
[2K
| Adam | epoch: 009 | loss: 0.22901 - acc: 0.9167 | val_loss: 0.03700 - val_acc: 0.9839 -- iter: 195/195
--
Training Step: 64  | total loss: [1m[32m0.20333[0m[0m | time: 0.240s
[2K
| Adam | epoch: 010 | loss: 0.20333 - acc: 0.9271 -- iter: 032/195
[A[ATraining Step: 65  | total loss: [1m[32m0.17999[0m[0m | time: 1.414s
[2K
| Adam | epoch: 010 | loss: 0.17999 - acc: 0.9361 -- iter: 064/195
[A[ATraining Step: 66  | total loss: [1m[32m0.16027[0m[0m | time: 2.739s
[2K
| Adam | epoch: 010 | loss: 0.16027 - acc: 0.9439 -- iter: 096/195
[A[ATraining Step: 67  | total loss: [1m[32m0.14243[0m[0m | time: 4.011s
[2K
| Adam | epoch: 010 | loss: 0.14243 - acc: 0.9506 -- iter: 128/195
[A[ATraining Step: 68  | total loss: [1m[32m0.12825[0m[0m | time: 5.315s
[2K
| Adam | epoch: 010 | loss: 0.12825 - acc: 0.9565 -- iter: 160/195
[A[ATraining Step: 69  | total loss: [1m[32m0.13225[0m[0m | time: 6.653s
[2K
| Adam | epoch: 010 | loss: 0.13225 - acc: 0.9542 -- iter: 192/195
[A[ATraining Step: 70  | total loss: [1m[32m0.11815[0m[0m | time: 19.626s
[2K
| Adam | epoch: 010 | loss: 0.11815 - acc: 0.9595 | val_loss: 0.27940 - val_acc: 0.9516 -- iter: 195/195
--
Training Step: 71  | total loss: [1m[32m0.13798[0m[0m | time: 0.577s
[2K
| Adam | epoch: 011 | loss: 0.13798 - acc: 0.9463 -- iter: 032/195
[A[ATraining Step: 72  | total loss: [1m[32m0.12252[0m[0m | time: 0.711s
[2K
| Adam | epoch: 011 | loss: 0.12252 - acc: 0.9524 -- iter: 064/195
[A[ATraining Step: 73  | total loss: [1m[32m0.10897[0m[0m | time: 1.689s
[2K
| Adam | epoch: 011 | loss: 0.10897 - acc: 0.9577 -- iter: 096/195
[A[ATraining Step: 74  | total loss: [1m[32m0.12946[0m[0m | time: 2.938s
[2K
| Adam | epoch: 011 | loss: 0.12946 - acc: 0.9520 -- iter: 128/195
[A[ATraining Step: 75  | total loss: [1m[32m0.11951[0m[0m | time: 4.181s
[2K
| Adam | epoch: 011 | loss: 0.11951 - acc: 0.9572 -- iter: 160/195
[A[ATraining Step: 76  | total loss: [1m[32m0.10674[0m[0m | time: 5.368s
[2K
| Adam | epoch: 011 | loss: 0.10674 - acc: 0.9618 -- iter: 192/195
[A[ATraining Step: 77  | total loss: [1m[32m0.09605[0m[0m | time: 7.527s
[2K
| Adam | epoch: 011 | loss: 0.09605 - acc: 0.9659 | val_loss: 0.13394 - val_acc: 0.9839 -- iter: 195/195
--
Training Step: 78  | total loss: [1m[32m0.08605[0m[0m | time: 1.332s
[2K
| Adam | epoch: 012 | loss: 0.08605 - acc: 0.9694 -- iter: 032/195
[A[ATraining Step: 79  | total loss: [1m[32m0.11016[0m[0m | time: 1.523s
[2K
| Adam | epoch: 012 | loss: 0.11016 - acc: 0.9661 -- iter: 064/195
[A[ATraining Step: 80  | total loss: [1m[32m0.26727[0m[0m | time: 1.752s
[2K
| Adam | epoch: 012 | loss: 0.26727 - acc: 0.9355 -- iter: 096/195
[A[ATraining Step: 81  | total loss: [1m[32m0.24025[0m[0m | time: 3.484s
[2K
| Adam | epoch: 012 | loss: 0.24025 - acc: 0.9420 -- iter: 128/195
[A[ATraining Step: 82  | total loss: [1m[32m0.21649[0m[0m | time: 4.849s
[2K
| Adam | epoch: 012 | loss: 0.21649 - acc: 0.9478 -- iter: 160/195
[A[ATraining Step: 83  | total loss: [1m[32m0.19492[0m[0m | time: 6.261s
[2K
| Adam | epoch: 012 | loss: 0.19492 - acc: 0.9530 -- iter: 192/195
[A[ATraining Step: 84  | total loss: [1m[32m0.18483[0m[0m | time: 11.876s
[2K
| Adam | epoch: 012 | loss: 0.18483 - acc: 0.9546 | val_loss: 0.08582 - val_acc: 0.9839 -- iter: 195/195
--
Training Step: 85  | total loss: [1m[32m0.16674[0m[0m | time: 1.378s
[2K
| Adam | epoch: 013 | loss: 0.16674 - acc: 0.9591 -- iter: 032/195
[A[ATraining Step: 86  | total loss: [1m[32m0.15082[0m[0m | time: 2.501s
[2K
| Adam | epoch: 013 | loss: 0.15082 - acc: 0.9632 -- iter: 064/195
[A[ATraining Step: 87  | total loss: [1m[32m0.13685[0m[0m | time: 2.733s
[2K
| Adam | epoch: 013 | loss: 0.13685 - acc: 0.9669 -- iter: 096/195
[A[ATraining Step: 88  | total loss: [1m[32m0.12412[0m[0m | time: 2.927s
[2K
| Adam | epoch: 013 | loss: 0.12412 - acc: 0.9702 -- iter: 128/195
[A[ATraining Step: 89  | total loss: [1m[32m0.11453[0m[0m | time: 4.178s
[2K
| Adam | epoch: 013 | loss: 0.11453 - acc: 0.9732 -- iter: 160/195
[A[ATraining Step: 90  | total loss: [1m[32m0.11007[0m[0m | time: 5.402s
[2K
| Adam | epoch: 013 | loss: 0.11007 - acc: 0.9759 -- iter: 192/195
[A[ATraining Step: 91  | total loss: [1m[32m0.09985[0m[0m | time: 7.895s
[2K
| Adam | epoch: 013 | loss: 0.09985 - acc: 0.9783 | val_loss: 0.05277 - val_acc: 0.9839 -- iter: 195/195
--
Training Step: 92  | total loss: [1m[32m0.09079[0m[0m | time: 1.326s
[2K
| Adam | epoch: 014 | loss: 0.09079 - acc: 0.9805 -- iter: 032/195
[A[ATraining Step: 93  | total loss: [1m[32m0.08231[0m[0m | time: 2.564s
[2K
| Adam | epoch: 014 | loss: 0.08231 - acc: 0.9824 -- iter: 064/195
[A[ATraining Step: 94  | total loss: [1m[32m0.07431[0m[0m | time: 3.688s
[2K
| Adam | epoch: 014 | loss: 0.07431 - acc: 0.9842 -- iter: 096/195
[A[ATraining Step: 95  | total loss: [1m[32m0.06707[0m[0m | time: 3.881s
[2K
| Adam | epoch: 014 | loss: 0.06707 - acc: 0.9858 -- iter: 128/195
[A[ATraining Step: 96  | total loss: [1m[32m0.06049[0m[0m | time: 4.088s
[2K
| Adam | epoch: 014 | loss: 0.06049 - acc: 0.9872 -- iter: 160/195
[A[ATraining Step: 97  | total loss: [1m[32m0.05450[0m[0m | time: 5.264s
[2K
| Adam | epoch: 014 | loss: 0.05450 - acc: 0.9885 -- iter: 192/195
[A[ATraining Step: 98  | total loss: [1m[32m0.04931[0m[0m | time: 7.637s
[2K
| Adam | epoch: 014 | loss: 0.04931 - acc: 0.9896 | val_loss: 0.04655 - val_acc: 0.9839 -- iter: 195/195
--
Training Step: 99  | total loss: [1m[32m0.05236[0m[0m | time: 1.181s
[2K
| Adam | epoch: 015 | loss: 0.05236 - acc: 0.9875 -- iter: 032/195
[A[ATraining Step: 100  | total loss: [1m[32m0.04723[0m[0m | time: 2.406s
[2K
| Adam | epoch: 015 | loss: 0.04723 - acc: 0.9888 -- iter: 064/195
[A[ATraining Step: 101  | total loss: [1m[32m0.05069[0m[0m | time: 3.855s
[2K
| Adam | epoch: 015 | loss: 0.05069 - acc: 0.9836 -- iter: 096/195
[A[ATraining Step: 102  | total loss: [1m[32m0.04580[0m[0m | time: 5.153s
[2K
| Adam | epoch: 015 | loss: 0.04580 - acc: 0.9853 -- iter: 128/195
[A[ATraining Step: 103  | total loss: [1m[32m0.04133[0m[0m | time: 5.325s
[2K
| Adam | epoch: 015 | loss: 0.04133 - acc: 0.9868 -- iter: 160/195
[A[ATraining Step: 104  | total loss: [1m[32m0.03725[0m[0m | time: 5.508s
[2K
| Adam | epoch: 015 | loss: 0.03725 - acc: 0.9881 -- iter: 192/195
[A[ATraining Step: 105  | total loss: [1m[32m0.03353[0m[0m | time: 7.646s
[2K
| Adam | epoch: 015 | loss: 0.03353 - acc: 0.9893 | val_loss: 0.16404 - val_acc: 0.9677 -- iter: 195/195
--
Validation AUC:0.9989550679205852
Validation AUPRC:0.999108734402852
Test AUC:1.0
Test AUPRC:0.9999999999999998
BestTestF1Score	1.0	1.0	1.0	1.0	1.0	27	0	35	0	0.38
BestTestMCCScore	1.0	1.0	1.0	1.0	1.0	27	0	35	0	0.38
BestTestAccuracyScore	1.0	1.0	1.0	1.0	1.0	27	0	35	0	0.38
BestValidationF1Score	0.98	0.97	0.98	1.0	0.97	32	0	29	1	0.38
BestValidationMCC	0.98	0.97	0.98	1.0	0.97	32	0	29	1	0.38
BestValidationAccuracy	0.98	0.97	0.98	1.0	0.97	32	0	29	1	0.38
TestPredictions (Threshold:0.38)
CHEMBL177546,TN,INACT,0.0	CHEMBL175228,TN,INACT,0.0	CHEMBL63937,TN,INACT,0.0	CHEMBL3704100,TP,ACT,0.8799999952316284	CHEMBL3704066,TP,ACT,1.0	CHEMBL42411,TN,INACT,0.0	CHEMBL3704089,TP,ACT,1.0	CHEMBL111218,TN,INACT,0.0	CHEMBL3704102,TP,ACT,1.0	CHEMBL149592,TN,INACT,0.0	CHEMBL78080,TN,INACT,0.0	CHEMBL195893,TN,INACT,0.0	CHEMBL45269,TN,INACT,0.0	CHEMBL217002,TN,INACT,0.0	CHEMBL297599,TN,INACT,0.0	CHEMBL462650,TN,INACT,0.0	CHEMBL3704146,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.0	CHEMBL78830,TN,INACT,0.0	CHEMBL3704105,TP,ACT,1.0	CHEMBL336033,TN,INACT,0.0	CHEMBL3659056,TP,ACT,1.0	CHEMBL3659054,TP,ACT,0.9800000190734863	CHEMBL320124,TN,INACT,0.0	CHEMBL3704068,TP,ACT,1.0	CHEMBL39879,TN,INACT,0.0	CHEMBL298203,TN,INACT,0.0	CHEMBL3704076,TP,ACT,1.0	CHEMBL3780248,TN,INACT,0.0	CHEMBL3659049,TP,ACT,0.9900000095367432	CHEMBL3704027,TP,ACT,1.0	CHEMBL3704126,TP,ACT,0.9900000095367432	CHEMBL42586,TN,INACT,0.0	CHEMBL3704083,TP,ACT,1.0	CHEMBL79030,TN,INACT,0.0	CHEMBL3704138,TP,ACT,1.0	CHEMBL3659044,TP,ACT,0.9900000095367432	CHEMBL3704077,TP,ACT,0.9900000095367432	CHEMBL209121,TN,INACT,0.0	CHEMBL3704124,TP,ACT,0.9300000071525574	CHEMBL368629,TN,INACT,0.0	CHEMBL3704091,TP,ACT,1.0	CHEMBL3704123,TP,ACT,0.9900000095367432	CHEMBL297335,TN,INACT,0.0	CHEMBL3704118,TP,ACT,0.9900000095367432	CHEMBL3704046,TP,ACT,0.9900000095367432	CHEMBL3704116,TP,ACT,0.9900000095367432	CHEMBL435810,TN,INACT,0.0	CHEMBL147340,TN,INACT,0.0	CHEMBL58617,TN,INACT,0.0	CHEMBL297215,TN,INACT,0.0	CHEMBL91073,TN,INACT,0.0	CHEMBL3704036,TP,ACT,0.9900000095367432	CHEMBL3704069,TP,ACT,1.0	CHEMBL325935,TN,INACT,0.0	CHEMBL430683,TN,INACT,0.0	CHEMBL104848,TN,INACT,0.0	CHEMBL3704061,TP,ACT,0.9900000095367432	CHEMBL1170027,TN,INACT,0.0	CHEMBL114074,TN,INACT,0.0	CHEMBL3704120,TP,ACT,1.0	CHEMBL296245,TN,INACT,0.0	

