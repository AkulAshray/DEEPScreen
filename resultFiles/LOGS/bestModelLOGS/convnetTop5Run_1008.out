ImageNetInceptionV2 CHEMBL4408 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	128
Number of inactive compounds :	128
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4408_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4408_adam_0.0005_15_0.8/
---------------------------------
Training samples: 163
Validation samples: 52
--
Training Step: 1  | time: 193.805s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/163
[A[ATraining Step: 2  | total loss: [1m[32m0.67351[0m[0m | time: 408.012s
[2K
| Adam | epoch: 001 | loss: 0.67351 - acc: 0.4781 -- iter: 064/163
[A[ATraining Step: 3  | total loss: [1m[32m0.72964[0m[0m | time: 577.789s
[2K
| Adam | epoch: 001 | loss: 0.72964 - acc: 0.7517 -- iter: 096/163
[A[ATraining Step: 4  | total loss: [1m[32m0.50199[0m[0m | time: 804.481s
[2K
| Adam | epoch: 001 | loss: 0.50199 - acc: 0.8207 -- iter: 128/163
[A[ATraining Step: 5  | total loss: [1m[32m0.43139[0m[0m | time: 921.401s
[2K
| Adam | epoch: 001 | loss: 0.43139 - acc: 0.8583 -- iter: 160/163
[A[ATraining Step: 6  | total loss: [1m[32m0.36062[0m[0m | time: 942.808s
[2K
| Adam | epoch: 001 | loss: 0.36062 - acc: 0.8690 | val_loss: 1.15525 - val_acc: 0.4231 -- iter: 163/163
--
Training Step: 7  | total loss: [1m[32m0.52561[0m[0m | time: 3.170s
[2K
| Adam | epoch: 002 | loss: 0.52561 - acc: 0.7476 -- iter: 032/163
[A[ATraining Step: 8  | total loss: [1m[32m0.26950[0m[0m | time: 156.571s
[2K
| Adam | epoch: 002 | loss: 0.26950 - acc: 0.8896 -- iter: 064/163
[A[ATraining Step: 9  | total loss: [1m[32m0.39976[0m[0m | time: 320.948s
[2K
| Adam | epoch: 002 | loss: 0.39976 - acc: 0.8488 -- iter: 096/163
[A[ATraining Step: 10  | total loss: [1m[32m0.45382[0m[0m | time: 607.193s
[2K
| Adam | epoch: 002 | loss: 0.45382 - acc: 0.7994 -- iter: 128/163
[A[ATraining Step: 11  | total loss: [1m[32m0.30929[0m[0m | time: 693.012s
[2K
| Adam | epoch: 002 | loss: 0.30929 - acc: 0.8796 -- iter: 160/163
[A[ATraining Step: 12  | total loss: [1m[32m0.24119[0m[0m | time: 867.635s
[2K
| Adam | epoch: 002 | loss: 0.24119 - acc: 0.9057 | val_loss: 0.88925 - val_acc: 0.4231 -- iter: 163/163
--
Training Step: 13  | total loss: [1m[32m0.19658[0m[0m | time: 19.882s
[2K
| Adam | epoch: 003 | loss: 0.19658 - acc: 0.9327 -- iter: 032/163
[A[ATraining Step: 14  | total loss: [1m[32m0.29624[0m[0m | time: 28.503s
[2K
| Adam | epoch: 003 | loss: 0.29624 - acc: 0.8239 -- iter: 064/163
[A[ATraining Step: 15  | total loss: [1m[32m0.19289[0m[0m | time: 483.463s
[2K
| Adam | epoch: 003 | loss: 0.19289 - acc: 0.8928 -- iter: 096/163
[A[ATraining Step: 16  | total loss: [1m[32m0.23516[0m[0m | time: 740.049s
[2K
| Adam | epoch: 003 | loss: 0.23516 - acc: 0.8978 -- iter: 128/163
[A[ATraining Step: 17  | total loss: [1m[32m0.17586[0m[0m | time: 914.311s
[2K
| Adam | epoch: 003 | loss: 0.17586 - acc: 0.9234 -- iter: 160/163
[A[ATraining Step: 18  | total loss: [1m[32m0.13798[0m[0m | time: 1177.779s
[2K
| Adam | epoch: 003 | loss: 0.13798 - acc: 0.9391 | val_loss: 1.02784 - val_acc: 0.5769 -- iter: 163/163
--
Training Step: 19  | total loss: [1m[32m0.10845[0m[0m | time: 178.942s
[2K
| Adam | epoch: 004 | loss: 0.10845 - acc: 0.9594 -- iter: 032/163
[A[ATraining Step: 20  | total loss: [1m[32m0.08817[0m[0m | time: 183.497s
[2K
| Adam | epoch: 004 | loss: 0.08817 - acc: 0.9724 -- iter: 064/163
[A[ATraining Step: 21  | total loss: [1m[32m0.08627[0m[0m | time: 187.647s
[2K
| Adam | epoch: 004 | loss: 0.08627 - acc: 0.9810 -- iter: 096/163
[A[ATraining Step: 22  | total loss: [1m[32m0.07882[0m[0m | time: 326.381s
[2K
| Adam | epoch: 004 | loss: 0.07882 - acc: 0.9867 -- iter: 128/163
[A[ATraining Step: 23  | total loss: [1m[32m0.06096[0m[0m | time: 396.299s
[2K
| Adam | epoch: 004 | loss: 0.06096 - acc: 0.9906 -- iter: 160/163
[A[ATraining Step: 24  | total loss: [1m[32m0.14559[0m[0m | time: 522.922s
[2K
| Adam | epoch: 004 | loss: 0.14559 - acc: 0.9668 | val_loss: 2.68306 - val_acc: 0.5769 -- iter: 163/163
--
Training Step: 25  | total loss: [1m[32m0.12096[0m[0m | time: 74.341s
[2K
| Adam | epoch: 005 | loss: 0.12096 - acc: 0.9674 -- iter: 032/163
[A[ATraining Step: 26  | total loss: [1m[32m0.10791[0m[0m | time: 131.232s
[2K
| Adam | epoch: 005 | loss: 0.10791 - acc: 0.9677 -- iter: 064/163
[A[ATraining Step: 27  | total loss: [1m[32m0.10317[0m[0m | time: 135.896s
[2K
| Adam | epoch: 005 | loss: 0.10317 - acc: 0.9680 -- iter: 096/163
[A[ATraining Step: 28  | total loss: [1m[32m0.61810[0m[0m | time: 140.488s
[2K
| Adam | epoch: 005 | loss: 0.61810 - acc: 0.8927 -- iter: 128/163
[A[ATraining Step: 29  | total loss: [1m[32m0.74806[0m[0m | time: 199.980s
[2K
| Adam | epoch: 005 | loss: 0.74806 - acc: 0.7566 -- iter: 160/163
[A[ATraining Step: 30  | total loss: [1m[32m0.58193[0m[0m | time: 227.826s
[2K
| Adam | epoch: 005 | loss: 0.58193 - acc: 0.8143 | val_loss: 0.92303 - val_acc: 0.5769 -- iter: 163/163
--
Training Step: 31  | total loss: [1m[32m0.46984[0m[0m | time: 72.485s
[2K
| Adam | epoch: 006 | loss: 0.46984 - acc: 0.8499 -- iter: 032/163
[A[ATraining Step: 32  | total loss: [1m[32m0.37369[0m[0m | time: 118.551s
[2K
| Adam | epoch: 006 | loss: 0.37369 - acc: 0.8837 -- iter: 064/163
[A[ATraining Step: 33  | total loss: [1m[32m0.33835[0m[0m | time: 189.618s
[2K
| Adam | epoch: 006 | loss: 0.33835 - acc: 0.8955 -- iter: 096/163
[A[ATraining Step: 34  | total loss: [1m[32m0.28505[0m[0m | time: 192.468s
[2K
| Adam | epoch: 006 | loss: 0.28505 - acc: 0.9112 -- iter: 128/163
[A[ATraining Step: 35  | total loss: [1m[32m0.24053[0m[0m | time: 195.493s
[2K
| Adam | epoch: 006 | loss: 0.24053 - acc: 0.9298 -- iter: 160/163
[A[ATraining Step: 36  | total loss: [1m[32m0.19711[0m[0m | time: 230.400s
[2K
| Adam | epoch: 006 | loss: 0.19711 - acc: 0.9441 | val_loss: 3.81093 - val_acc: 0.4231 -- iter: 163/163
--
Training Step: 37  | total loss: [1m[32m0.16428[0m[0m | time: 84.220s
[2K
| Adam | epoch: 007 | loss: 0.16428 - acc: 0.9553 -- iter: 032/163
[A[ATraining Step: 38  | total loss: [1m[32m0.14291[0m[0m | time: 200.957s
[2K
| Adam | epoch: 007 | loss: 0.14291 - acc: 0.9641 -- iter: 064/163
[A[ATraining Step: 39  | total loss: [1m[32m0.16751[0m[0m | time: 327.009s
[2K
| Adam | epoch: 007 | loss: 0.16751 - acc: 0.9530 -- iter: 096/163
[A[ATraining Step: 40  | total loss: [1m[32m0.13827[0m[0m | time: 540.359s
[2K
| Adam | epoch: 007 | loss: 0.13827 - acc: 0.9618 -- iter: 128/163
[A[ATraining Step: 41  | total loss: [1m[32m0.11886[0m[0m | time: 554.513s
[2K
| Adam | epoch: 007 | loss: 0.11886 - acc: 0.9688 -- iter: 160/163
[A[ATraining Step: 42  | total loss: [1m[32m0.09929[0m[0m | time: 605.745s
[2K
| Adam | epoch: 007 | loss: 0.09929 - acc: 0.9744 | val_loss: 4.52255 - val_acc: 0.4231 -- iter: 163/163
--
Training Step: 43  | total loss: [1m[32m0.08251[0m[0m | time: 243.709s
[2K
| Adam | epoch: 008 | loss: 0.08251 - acc: 0.9789 -- iter: 032/163
[A[ATraining Step: 44  | total loss: [1m[32m0.07109[0m[0m | time: 336.931s
[2K
| Adam | epoch: 008 | loss: 0.07109 - acc: 0.9826 -- iter: 064/163
[A[ATraining Step: 45  | total loss: [1m[32m0.09059[0m[0m | time: 354.238s
[2K
| Adam | epoch: 008 | loss: 0.09059 - acc: 0.9802 -- iter: 096/163
[A[ATraining Step: 46  | total loss: [1m[32m0.07636[0m[0m | time: 372.473s
[2K
| Adam | epoch: 008 | loss: 0.07636 - acc: 0.9835 -- iter: 128/163
[A[ATraining Step: 47  | total loss: [1m[32m0.06453[0m[0m | time: 390.843s
[2K
| Adam | epoch: 008 | loss: 0.06453 - acc: 0.9862 -- iter: 160/163
[A[ATraining Step: 48  | total loss: [1m[32m0.05784[0m[0m | time: 399.677s
[2K
| Adam | epoch: 008 | loss: 0.05784 - acc: 0.9884 | val_loss: 3.96476 - val_acc: 0.4231 -- iter: 163/163
--
Training Step: 49  | total loss: [1m[32m0.04884[0m[0m | time: 3.814s
[2K
| Adam | epoch: 009 | loss: 0.04884 - acc: 0.9903 -- iter: 032/163
[A[ATraining Step: 50  | total loss: [1m[32m0.04139[0m[0m | time: 21.228s
[2K
| Adam | epoch: 009 | loss: 0.04139 - acc: 0.9918 -- iter: 064/163
[A[ATraining Step: 51  | total loss: [1m[32m0.09631[0m[0m | time: 46.430s
[2K
| Adam | epoch: 009 | loss: 0.09631 - acc: 0.9883 -- iter: 096/163
[A[ATraining Step: 52  | total loss: [1m[32m0.16579[0m[0m | time: 64.128s
[2K
| Adam | epoch: 009 | loss: 0.16579 - acc: 0.9806 -- iter: 128/163
[A[ATraining Step: 53  | total loss: [1m[32m0.14213[0m[0m | time: 81.296s
[2K
| Adam | epoch: 009 | loss: 0.14213 - acc: 0.9835 -- iter: 160/163
[A[ATraining Step: 54  | total loss: [1m[32m0.12222[0m[0m | time: 104.892s
[2K
| Adam | epoch: 009 | loss: 0.12222 - acc: 0.9859 | val_loss: 1.10437 - val_acc: 0.5962 -- iter: 163/163
--
Training Step: 55  | total loss: [1m[32m0.11125[0m[0m | time: 3.817s
[2K
| Adam | epoch: 010 | loss: 0.11125 - acc: 0.9834 -- iter: 032/163
[A[ATraining Step: 56  | total loss: [1m[32m0.09767[0m[0m | time: 6.929s
[2K
| Adam | epoch: 010 | loss: 0.09767 - acc: 0.9858 -- iter: 064/163
[A[ATraining Step: 57  | total loss: [1m[32m0.08494[0m[0m | time: 24.210s
[2K
| Adam | epoch: 010 | loss: 0.08494 - acc: 0.9877 -- iter: 096/163
[A[ATraining Step: 58  | total loss: [1m[32m0.09105[0m[0m | time: 41.863s
[2K
| Adam | epoch: 010 | loss: 0.09105 - acc: 0.9852 -- iter: 128/163
[A[ATraining Step: 59  | total loss: [1m[32m0.26196[0m[0m | time: 59.645s
[2K
| Adam | epoch: 010 | loss: 0.26196 - acc: 0.9536 -- iter: 160/163
[A[ATraining Step: 60  | total loss: [1m[32m0.24146[0m[0m | time: 113.046s
[2K
| Adam | epoch: 010 | loss: 0.24146 - acc: 0.9556 | val_loss: 0.31720 - val_acc: 0.9231 -- iter: 163/163
--
Training Step: 61  | total loss: [1m[32m0.21462[0m[0m | time: 20.171s
[2K
| Adam | epoch: 011 | loss: 0.21462 - acc: 0.9614 -- iter: 032/163
[A[ATraining Step: 62  | total loss: [1m[32m0.20077[0m[0m | time: 23.260s
[2K
| Adam | epoch: 011 | loss: 0.20077 - acc: 0.9623 -- iter: 064/163
[A[ATraining Step: 63  | total loss: [1m[32m0.18610[0m[0m | time: 26.813s
[2K
| Adam | epoch: 011 | loss: 0.18610 - acc: 0.9671 -- iter: 096/163
[A[ATraining Step: 64  | total loss: [1m[32m0.16885[0m[0m | time: 67.195s
[2K
| Adam | epoch: 011 | loss: 0.16885 - acc: 0.9712 -- iter: 128/163
[A[ATraining Step: 65  | total loss: [1m[32m0.15944[0m[0m | time: 88.660s
[2K
| Adam | epoch: 011 | loss: 0.15944 - acc: 0.9709 -- iter: 160/163
[A[ATraining Step: 66  | total loss: [1m[32m0.17837[0m[0m | time: 179.649s
[2K
| Adam | epoch: 011 | loss: 0.17837 - acc: 0.9668 | val_loss: 0.62666 - val_acc: 0.8077 -- iter: 163/163
--
Training Step: 67  | total loss: [1m[32m0.16788[0m[0m | time: 49.074s
[2K
| Adam | epoch: 012 | loss: 0.16788 - acc: 0.9708 -- iter: 032/163
[A[ATraining Step: 68  | total loss: [1m[32m0.15736[0m[0m | time: 66.726s
[2K
| Adam | epoch: 012 | loss: 0.15736 - acc: 0.9743 -- iter: 064/163
[A[ATraining Step: 69  | total loss: [1m[32m0.14691[0m[0m | time: 70.216s
[2K
| Adam | epoch: 012 | loss: 0.14691 - acc: 0.9773 -- iter: 096/163
[A[ATraining Step: 70  | total loss: [1m[32m0.14895[0m[0m | time: 73.501s
[2K
| Adam | epoch: 012 | loss: 0.14895 - acc: 0.9799 -- iter: 128/163
[A[ATraining Step: 71  | total loss: [1m[32m0.13725[0m[0m | time: 91.218s
[2K
| Adam | epoch: 012 | loss: 0.13725 - acc: 0.9822 -- iter: 160/163
[A[ATraining Step: 72  | total loss: [1m[32m0.12443[0m[0m | time: 113.701s
[2K
| Adam | epoch: 012 | loss: 0.12443 - acc: 0.9842 | val_loss: 0.46475 - val_acc: 0.8846 -- iter: 163/163
--
Training Step: 73  | total loss: [1m[32m0.13217[0m[0m | time: 17.894s
[2K
| Adam | epoch: 013 | loss: 0.13217 - acc: 0.9825 -- iter: 032/163
[A[ATraining Step: 74  | total loss: [1m[32m0.12044[0m[0m | time: 35.733s
[2K
| Adam | epoch: 013 | loss: 0.12044 - acc: 0.9844 -- iter: 064/163
[A[ATraining Step: 75  | total loss: [1m[32m0.10970[0m[0m | time: 61.060s
[2K
| Adam | epoch: 013 | loss: 0.10970 - acc: 0.9861 -- iter: 096/163
[A[ATraining Step: 76  | total loss: [1m[32m0.10048[0m[0m | time: 64.349s
[2K
| Adam | epoch: 013 | loss: 0.10048 - acc: 0.9876 -- iter: 128/163
[A[ATraining Step: 77  | total loss: [1m[32m0.13097[0m[0m | time: 67.744s
[2K
| Adam | epoch: 013 | loss: 0.13097 - acc: 0.9536 -- iter: 160/163
[A[ATraining Step: 78  | total loss: [1m[32m0.12138[0m[0m | time: 115.772s
[2K
| Adam | epoch: 013 | loss: 0.12138 - acc: 0.9585 | val_loss: 0.49583 - val_acc: 0.8462 -- iter: 163/163
--
Training Step: 79  | total loss: [1m[32m0.11883[0m[0m | time: 35.560s
[2K
| Adam | epoch: 014 | loss: 0.11883 - acc: 0.9595 -- iter: 032/163
[A[ATraining Step: 80  | total loss: [1m[32m0.11856[0m[0m | time: 55.902s
[2K
| Adam | epoch: 014 | loss: 0.11856 - acc: 0.9605 -- iter: 064/163
[A[ATraining Step: 81  | total loss: [1m[32m0.11401[0m[0m | time: 135.994s
[2K
| Adam | epoch: 014 | loss: 0.11401 - acc: 0.9613 -- iter: 096/163
[A[ATraining Step: 82  | total loss: [1m[32m0.10527[0m[0m | time: 247.456s
[2K
| Adam | epoch: 014 | loss: 0.10527 - acc: 0.9652 -- iter: 128/163
[A[ATraining Step: 83  | total loss: [1m[32m0.10677[0m[0m | time: 251.651s
[2K
| Adam | epoch: 014 | loss: 0.10677 - acc: 0.9624 -- iter: 160/163
[A[ATraining Step: 84  | total loss: [1m[32m0.09978[0m[0m | time: 261.090s
[2K
| Adam | epoch: 014 | loss: 0.09978 - acc: 0.9662 | val_loss: 0.39450 - val_acc: 0.8846 -- iter: 163/163
--
Training Step: 85  | total loss: [1m[32m0.09031[0m[0m | time: 98.020s
[2K
| Adam | epoch: 015 | loss: 0.09031 - acc: 0.9696 -- iter: 032/163
[A[ATraining Step: 86  | total loss: [1m[32m0.09029[0m[0m | time: 136.902s
[2K
| Adam | epoch: 015 | loss: 0.09029 - acc: 0.9695 -- iter: 064/163
[A[ATraining Step: 87  | total loss: [1m[32m0.12178[0m[0m | time: 213.769s
[2K
| Adam | epoch: 015 | loss: 0.12178 - acc: 0.9631 -- iter: 096/163
[A[ATraining Step: 88  | total loss: [1m[32m0.11328[0m[0m | time: 254.482s
[2K
| Adam | epoch: 015 | loss: 0.11328 - acc: 0.9668 -- iter: 128/163
[A[ATraining Step: 89  | total loss: [1m[32m0.10315[0m[0m | time: 273.781s
[2K
| Adam | epoch: 015 | loss: 0.10315 - acc: 0.9701 -- iter: 160/163
[A[ATraining Step: 90  | total loss: [1m[32m0.10358[0m[0m | time: 283.505s
[2K
| Adam | epoch: 015 | loss: 0.10358 - acc: 0.9700 | val_loss: 0.12317 - val_acc: 0.9423 -- iter: 163/163
--
Validation AUC:0.9924242424242424
Validation AUPRC:0.9903148366784731
Test AUC:0.9255952380952381
Test AUPRC:0.9436762866074935
BestTestF1Score	0.89	0.81	0.9	0.91	0.88	21	2	26	3	0.52
BestTestMCCScore	0.89	0.81	0.9	0.91	0.88	21	2	26	3	0.52
BestTestAccuracyScore	0.89	0.81	0.9	0.91	0.88	21	2	26	3	0.52
BestValidationF1Score	0.95	0.92	0.96	0.95	0.95	21	1	29	1	0.52
BestValidationMCC	0.95	0.92	0.96	0.95	0.95	21	1	29	1	0.52
BestValidationAccuracy	0.95	0.92	0.96	0.95	0.95	21	1	29	1	0.52
TestPredictions (Threshold:0.52)
CHEMBL2070772,TP,ACT,0.9599999785423279	CHEMBL150764,TN,INACT,0.0	CHEMBL2070923,FN,ACT,0.03999999910593033	CHEMBL286020,TN,INACT,0.0	CHEMBL329876,TN,INACT,0.0	CHEMBL144978,FP,INACT,0.800000011920929	CHEMBL88525,TN,INACT,0.009999999776482582	CHEMBL2070934,TP,ACT,0.9200000166893005	CHEMBL175958,TN,INACT,0.0	CHEMBL2158066,TN,INACT,0.0	CHEMBL118572,TN,INACT,0.05000000074505806	CHEMBL1094588,TN,INACT,0.0	CHEMBL1780117,TP,ACT,0.8799999952316284	CHEMBL1940057,TN,INACT,0.07999999821186066	CHEMBL2070734,TP,ACT,1.0	CHEMBL2070770,TP,ACT,1.0	CHEMBL1780102,TP,ACT,0.9800000190734863	CHEMBL2070907,TP,ACT,0.9700000286102295	CHEMBL2070595,TP,ACT,0.9399999976158142	CHEMBL1779976,FN,ACT,0.009999999776482582	CHEMBL70951,TN,INACT,0.009999999776482582	CHEMBL2070928,TP,ACT,0.9100000262260437	CHEMBL2070773,TP,ACT,0.9900000095367432	CHEMBL553515,TN,INACT,0.009999999776482582	CHEMBL1780099,TP,ACT,1.0	CHEMBL1780084,TP,ACT,0.9800000190734863	CHEMBL2070729,TP,ACT,0.9900000095367432	CHEMBL344720,TN,INACT,0.49000000953674316	CHEMBL177336,TN,INACT,0.4300000071525574	CHEMBL30908,TN,INACT,0.0	CHEMBL356323,TN,INACT,0.2199999988079071	CHEMBL2070900,TP,ACT,0.9800000190734863	CHEMBL1940056,TN,INACT,0.0	CHEMBL439809,TN,INACT,0.009999999776482582	CHEMBL1780112,TP,ACT,1.0	CHEMBL2070931,FN,ACT,0.0	CHEMBL368322,TN,INACT,0.0	CHEMBL30623,TN,INACT,0.0	CHEMBL359890,TN,INACT,0.05999999865889549	CHEMBL2070732,TP,ACT,1.0	CHEMBL2070735,TP,ACT,1.0	CHEMBL2070920,TP,ACT,0.5299999713897705	CHEMBL2070736,TP,ACT,0.6000000238418579	CHEMBL124539,TN,INACT,0.009999999776482582	CHEMBL3650345,TN,INACT,0.5199999809265137	CHEMBL144047,TN,INACT,0.15000000596046448	CHEMBL366491,TN,INACT,0.009999999776482582	CHEMBL2070768,TP,ACT,0.9900000095367432	CHEMBL357428,TN,INACT,0.019999999552965164	CHEMBL3647460,FP,INACT,0.6800000071525574	CHEMBL183465,TN,INACT,0.0	CHEMBL2070774,TP,ACT,0.9700000286102295	

