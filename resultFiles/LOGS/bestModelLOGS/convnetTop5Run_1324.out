CNNModel CHEMBL3788 adam 0.0005 30 32 0 0.8 False True
Number of active compounds :	133
Number of inactive compounds :	133
---------------------------------
Run id: CNNModel_CHEMBL3788_adam_0.0005_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3788_adam_0.0005_30_32_0.8_True/
---------------------------------
Training samples: 159
Validation samples: 50
--
Training Step: 1  | time: 0.763s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/159
[A[ATraining Step: 2  | total loss: [1m[32m0.62389[0m[0m | time: 1.376s
[2K
| Adam | epoch: 001 | loss: 0.62389 - acc: 0.3937 -- iter: 064/159
[A[ATraining Step: 3  | total loss: [1m[32m0.68110[0m[0m | time: 2.190s
[2K
| Adam | epoch: 001 | loss: 0.68110 - acc: 0.4551 -- iter: 096/159
[A[ATraining Step: 4  | total loss: [1m[32m0.69077[0m[0m | time: 2.804s
[2K
| Adam | epoch: 001 | loss: 0.69077 - acc: 0.4419 -- iter: 128/159
[A[ATraining Step: 5  | total loss: [1m[32m0.69162[0m[0m | time: 4.448s
[2K
| Adam | epoch: 001 | loss: 0.69162 - acc: 0.6552 | val_loss: 0.69148 - val_acc: 0.6200 -- iter: 159/159
--
Training Step: 6  | total loss: [1m[32m0.69316[0m[0m | time: 0.609s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5243 -- iter: 032/159
[A[ATraining Step: 7  | total loss: [1m[32m0.69343[0m[0m | time: 1.244s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.4807 -- iter: 064/159
[A[ATraining Step: 8  | total loss: [1m[32m0.69330[0m[0m | time: 1.870s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4916 -- iter: 096/159
[A[ATraining Step: 9  | total loss: [1m[32m0.69284[0m[0m | time: 2.534s
[2K
| Adam | epoch: 002 | loss: 0.69284 - acc: 0.5291 -- iter: 128/159
[A[ATraining Step: 10  | total loss: [1m[32m0.69333[0m[0m | time: 4.157s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4833 | val_loss: 0.69119 - val_acc: 0.6200 -- iter: 159/159
--
Training Step: 11  | total loss: [1m[32m0.69273[0m[0m | time: 0.606s
[2K
| Adam | epoch: 003 | loss: 0.69273 - acc: 0.5356 -- iter: 032/159
[A[ATraining Step: 12  | total loss: [1m[32m0.69284[0m[0m | time: 1.227s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5123 -- iter: 064/159
[A[ATraining Step: 13  | total loss: [1m[32m0.69302[0m[0m | time: 1.833s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5001 -- iter: 096/159
[A[ATraining Step: 14  | total loss: [1m[32m0.69292[0m[0m | time: 2.466s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5001 -- iter: 128/159
[A[ATraining Step: 15  | total loss: [1m[32m0.69242[0m[0m | time: 4.091s
[2K
| Adam | epoch: 003 | loss: 0.69242 - acc: 0.5245 | val_loss: 0.68830 - val_acc: 0.6200 -- iter: 159/159
--
Training Step: 16  | total loss: [1m[32m0.69287[0m[0m | time: 0.616s
[2K
| Adam | epoch: 004 | loss: 0.69287 - acc: 0.5036 -- iter: 032/159
[A[ATraining Step: 17  | total loss: [1m[32m0.69228[0m[0m | time: 1.223s
[2K
| Adam | epoch: 004 | loss: 0.69228 - acc: 0.5248 -- iter: 064/159
[A[ATraining Step: 18  | total loss: [1m[32m0.69331[0m[0m | time: 1.825s
[2K
| Adam | epoch: 004 | loss: 0.69331 - acc: 0.4995 -- iter: 096/159
[A[ATraining Step: 19  | total loss: [1m[32m0.69375[0m[0m | time: 2.417s
[2K
| Adam | epoch: 004 | loss: 0.69375 - acc: 0.4835 -- iter: 128/159
[A[ATraining Step: 20  | total loss: [1m[32m0.69098[0m[0m | time: 4.033s
[2K
| Adam | epoch: 004 | loss: 0.69098 - acc: 0.5390 | val_loss: 0.68465 - val_acc: 0.6200 -- iter: 159/159
--
Training Step: 21  | total loss: [1m[32m0.69249[0m[0m | time: 0.827s
[2K
| Adam | epoch: 005 | loss: 0.69249 - acc: 0.5075 -- iter: 032/159
[A[ATraining Step: 22  | total loss: [1m[32m0.69322[0m[0m | time: 1.837s
[2K
| Adam | epoch: 005 | loss: 0.69322 - acc: 0.4959 -- iter: 064/159
[A[ATraining Step: 23  | total loss: [1m[32m0.69371[0m[0m | time: 2.874s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.4880 -- iter: 096/159
[A[ATraining Step: 24  | total loss: [1m[32m0.69382[0m[0m | time: 3.768s
[2K
| Adam | epoch: 005 | loss: 0.69382 - acc: 0.4778 -- iter: 128/159
[A[ATraining Step: 25  | total loss: [1m[32m0.69351[0m[0m | time: 5.658s
[2K
| Adam | epoch: 005 | loss: 0.69351 - acc: 0.4706 | val_loss: 0.68936 - val_acc: 0.6200 -- iter: 159/159
--
Training Step: 26  | total loss: [1m[32m0.69304[0m[0m | time: 1.090s
[2K
| Adam | epoch: 006 | loss: 0.69304 - acc: 0.4867 -- iter: 032/159
[A[ATraining Step: 27  | total loss: [1m[32m0.69187[0m[0m | time: 1.928s
[2K
| Adam | epoch: 006 | loss: 0.69187 - acc: 0.5223 -- iter: 064/159
[A[ATraining Step: 28  | total loss: [1m[32m0.69140[0m[0m | time: 2.536s
[2K
| Adam | epoch: 006 | loss: 0.69140 - acc: 0.5245 -- iter: 096/159
[A[ATraining Step: 29  | total loss: [1m[32m0.69069[0m[0m | time: 3.245s
[2K
| Adam | epoch: 006 | loss: 0.69069 - acc: 0.5337 -- iter: 128/159
[A[ATraining Step: 30  | total loss: [1m[32m0.69291[0m[0m | time: 5.308s
[2K
| Adam | epoch: 006 | loss: 0.69291 - acc: 0.4914 | val_loss: 0.68457 - val_acc: 0.6200 -- iter: 159/159
--
Training Step: 31  | total loss: [1m[32m0.69426[0m[0m | time: 0.983s
[2K
| Adam | epoch: 007 | loss: 0.69426 - acc: 0.4599 -- iter: 032/159
[A[ATraining Step: 32  | total loss: [1m[32m0.69289[0m[0m | time: 1.957s
[2K
| Adam | epoch: 007 | loss: 0.69289 - acc: 0.4759 -- iter: 064/159
[A[ATraining Step: 33  | total loss: [1m[32m0.69123[0m[0m | time: 3.083s
[2K
| Adam | epoch: 007 | loss: 0.69123 - acc: 0.5018 -- iter: 096/159
[A[ATraining Step: 34  | total loss: [1m[32m0.69083[0m[0m | time: 4.004s
[2K
| Adam | epoch: 007 | loss: 0.69083 - acc: 0.4947 -- iter: 128/159
[A[ATraining Step: 35  | total loss: [1m[32m0.69011[0m[0m | time: 5.912s
[2K
| Adam | epoch: 007 | loss: 0.69011 - acc: 0.5024 | val_loss: 0.68117 - val_acc: 0.6200 -- iter: 159/159
--
Training Step: 36  | total loss: [1m[32m0.68954[0m[0m | time: 0.962s
[2K
| Adam | epoch: 008 | loss: 0.68954 - acc: 0.4986 -- iter: 032/159
[A[ATraining Step: 37  | total loss: [1m[32m0.68858[0m[0m | time: 1.927s
[2K
| Adam | epoch: 008 | loss: 0.68858 - acc: 0.4956 -- iter: 064/159
[A[ATraining Step: 38  | total loss: [1m[32m0.68665[0m[0m | time: 2.878s
[2K
| Adam | epoch: 008 | loss: 0.68665 - acc: 0.5087 -- iter: 096/159
[A[ATraining Step: 39  | total loss: [1m[32m0.68446[0m[0m | time: 4.054s
[2K
| Adam | epoch: 008 | loss: 0.68446 - acc: 0.5130 -- iter: 128/159
[A[ATraining Step: 40  | total loss: [1m[32m0.68332[0m[0m | time: 6.029s
[2K
| Adam | epoch: 008 | loss: 0.68332 - acc: 0.5106 | val_loss: 0.64965 - val_acc: 0.6200 -- iter: 159/159
--
Training Step: 41  | total loss: [1m[32m0.67704[0m[0m | time: 0.940s
[2K
| Adam | epoch: 009 | loss: 0.67704 - acc: 0.5316 -- iter: 032/159
[A[ATraining Step: 42  | total loss: [1m[32m0.67786[0m[0m | time: 1.972s
[2K
| Adam | epoch: 009 | loss: 0.67786 - acc: 0.5172 -- iter: 064/159
[A[ATraining Step: 43  | total loss: [1m[32m0.67608[0m[0m | time: 2.978s
[2K
| Adam | epoch: 009 | loss: 0.67608 - acc: 0.5056 -- iter: 096/159
[A[ATraining Step: 44  | total loss: [1m[32m0.67363[0m[0m | time: 4.092s
[2K
| Adam | epoch: 009 | loss: 0.67363 - acc: 0.5479 -- iter: 128/159
[A[ATraining Step: 45  | total loss: [1m[32m0.67313[0m[0m | time: 6.214s
[2K
| Adam | epoch: 009 | loss: 0.67313 - acc: 0.5822 | val_loss: 0.62625 - val_acc: 0.6600 -- iter: 159/159
--
Training Step: 46  | total loss: [1m[32m0.66867[0m[0m | time: 0.892s
[2K
| Adam | epoch: 010 | loss: 0.66867 - acc: 0.6206 -- iter: 032/159
[A[ATraining Step: 47  | total loss: [1m[32m0.66173[0m[0m | time: 1.773s
[2K
| Adam | epoch: 010 | loss: 0.66173 - acc: 0.6162 -- iter: 064/159
[A[ATraining Step: 48  | total loss: [1m[32m0.65178[0m[0m | time: 2.700s
[2K
| Adam | epoch: 010 | loss: 0.65178 - acc: 0.6053 -- iter: 096/159
[A[ATraining Step: 49  | total loss: [1m[32m0.64054[0m[0m | time: 3.784s
[2K
| Adam | epoch: 010 | loss: 0.64054 - acc: 0.5963 -- iter: 128/159
[A[ATraining Step: 50  | total loss: [1m[32m0.63386[0m[0m | time: 5.680s
[2K
| Adam | epoch: 010 | loss: 0.63386 - acc: 0.6202 | val_loss: 0.66052 - val_acc: 0.6000 -- iter: 159/159
--
Training Step: 51  | total loss: [1m[32m0.63143[0m[0m | time: 0.647s
[2K
| Adam | epoch: 011 | loss: 0.63143 - acc: 0.6447 -- iter: 032/159
[A[ATraining Step: 52  | total loss: [1m[32m0.62931[0m[0m | time: 1.248s
[2K
| Adam | epoch: 011 | loss: 0.62931 - acc: 0.6512 -- iter: 064/159
[A[ATraining Step: 53  | total loss: [1m[32m0.61831[0m[0m | time: 1.839s
[2K
| Adam | epoch: 011 | loss: 0.61831 - acc: 0.6796 -- iter: 096/159
[A[ATraining Step: 54  | total loss: [1m[32m0.62729[0m[0m | time: 2.442s
[2K
| Adam | epoch: 011 | loss: 0.62729 - acc: 0.6558 -- iter: 128/159
[A[ATraining Step: 55  | total loss: [1m[32m0.61971[0m[0m | time: 4.057s
[2K
| Adam | epoch: 011 | loss: 0.61971 - acc: 0.6681 | val_loss: 0.66585 - val_acc: 0.5400 -- iter: 159/159
--
Training Step: 56  | total loss: [1m[32m0.60524[0m[0m | time: 0.614s
[2K
| Adam | epoch: 012 | loss: 0.60524 - acc: 0.6972 -- iter: 032/159
[A[ATraining Step: 57  | total loss: [1m[32m0.59557[0m[0m | time: 1.216s
[2K
| Adam | epoch: 012 | loss: 0.59557 - acc: 0.7089 -- iter: 064/159
[A[ATraining Step: 58  | total loss: [1m[32m0.60397[0m[0m | time: 1.843s
[2K
| Adam | epoch: 012 | loss: 0.60397 - acc: 0.6804 -- iter: 096/159
[A[ATraining Step: 59  | total loss: [1m[32m0.58978[0m[0m | time: 2.441s
[2K
| Adam | epoch: 012 | loss: 0.58978 - acc: 0.7065 -- iter: 128/159
[A[ATraining Step: 60  | total loss: [1m[32m0.59417[0m[0m | time: 4.096s
[2K
| Adam | epoch: 012 | loss: 0.59417 - acc: 0.7069 | val_loss: 0.50044 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 61  | total loss: [1m[32m0.60192[0m[0m | time: 0.648s
[2K
| Adam | epoch: 013 | loss: 0.60192 - acc: 0.6947 -- iter: 032/159
[A[ATraining Step: 62  | total loss: [1m[32m0.58189[0m[0m | time: 1.250s
[2K
| Adam | epoch: 013 | loss: 0.58189 - acc: 0.7179 -- iter: 064/159
[A[ATraining Step: 63  | total loss: [1m[32m0.56872[0m[0m | time: 1.848s
[2K
| Adam | epoch: 013 | loss: 0.56872 - acc: 0.7378 -- iter: 096/159
[A[ATraining Step: 64  | total loss: [1m[32m0.56422[0m[0m | time: 2.484s
[2K
| Adam | epoch: 013 | loss: 0.56422 - acc: 0.7354 -- iter: 128/159
[A[ATraining Step: 65  | total loss: [1m[32m0.54494[0m[0m | time: 4.155s
[2K
| Adam | epoch: 013 | loss: 0.54494 - acc: 0.7526 | val_loss: 0.45403 - val_acc: 0.7800 -- iter: 159/159
--
Training Step: 66  | total loss: [1m[32m0.52844[0m[0m | time: 0.618s
[2K
| Adam | epoch: 014 | loss: 0.52844 - acc: 0.7670 -- iter: 032/159
[A[ATraining Step: 67  | total loss: [1m[32m0.51115[0m[0m | time: 1.242s
[2K
| Adam | epoch: 014 | loss: 0.51115 - acc: 0.7795 -- iter: 064/159
[A[ATraining Step: 68  | total loss: [1m[32m0.49809[0m[0m | time: 1.848s
[2K
| Adam | epoch: 014 | loss: 0.49809 - acc: 0.7871 -- iter: 096/159
[A[ATraining Step: 69  | total loss: [1m[32m0.49612[0m[0m | time: 2.449s
[2K
| Adam | epoch: 014 | loss: 0.49612 - acc: 0.7864 -- iter: 128/159
[A[ATraining Step: 70  | total loss: [1m[32m0.50388[0m[0m | time: 4.044s
[2K
| Adam | epoch: 014 | loss: 0.50388 - acc: 0.7786 | val_loss: 0.45109 - val_acc: 0.7200 -- iter: 159/159
--
Training Step: 71  | total loss: [1m[32m0.48011[0m[0m | time: 0.612s
[2K
| Adam | epoch: 015 | loss: 0.48011 - acc: 0.7931 -- iter: 032/159
[A[ATraining Step: 72  | total loss: [1m[32m0.46125[0m[0m | time: 1.206s
[2K
| Adam | epoch: 015 | loss: 0.46125 - acc: 0.7983 -- iter: 064/159
[A[ATraining Step: 73  | total loss: [1m[32m0.43874[0m[0m | time: 1.831s
[2K
| Adam | epoch: 015 | loss: 0.43874 - acc: 0.8135 -- iter: 096/159
[A[ATraining Step: 74  | total loss: [1m[32m0.41911[0m[0m | time: 2.446s
[2K
| Adam | epoch: 015 | loss: 0.41911 - acc: 0.8237 -- iter: 128/159
[A[ATraining Step: 75  | total loss: [1m[32m0.42020[0m[0m | time: 4.065s
[2K
| Adam | epoch: 015 | loss: 0.42020 - acc: 0.8191 | val_loss: 0.48391 - val_acc: 0.7600 -- iter: 159/159
--
Training Step: 76  | total loss: [1m[32m0.39401[0m[0m | time: 0.669s
[2K
| Adam | epoch: 016 | loss: 0.39401 - acc: 0.8351 -- iter: 032/159
[A[ATraining Step: 77  | total loss: [1m[32m0.39023[0m[0m | time: 1.273s
[2K
| Adam | epoch: 016 | loss: 0.39023 - acc: 0.8327 -- iter: 064/159
[A[ATraining Step: 78  | total loss: [1m[32m0.38228[0m[0m | time: 2.275s
[2K
| Adam | epoch: 016 | loss: 0.38228 - acc: 0.8401 -- iter: 096/159
[A[ATraining Step: 79  | total loss: [1m[32m0.36271[0m[0m | time: 3.338s
[2K
| Adam | epoch: 016 | loss: 0.36271 - acc: 0.8500 -- iter: 128/159
[A[ATraining Step: 80  | total loss: [1m[32m0.35536[0m[0m | time: 5.296s
[2K
| Adam | epoch: 016 | loss: 0.35536 - acc: 0.8461 | val_loss: 0.38078 - val_acc: 0.8400 -- iter: 159/159
--
Training Step: 81  | total loss: [1m[32m0.34040[0m[0m | time: 1.114s
[2K
| Adam | epoch: 017 | loss: 0.34040 - acc: 0.8554 -- iter: 032/159
[A[ATraining Step: 82  | total loss: [1m[32m0.35602[0m[0m | time: 2.162s
[2K
| Adam | epoch: 017 | loss: 0.35602 - acc: 0.8573 -- iter: 064/159
[A[ATraining Step: 83  | total loss: [1m[32m0.33143[0m[0m | time: 3.008s
[2K
| Adam | epoch: 017 | loss: 0.33143 - acc: 0.8716 -- iter: 096/159
[A[ATraining Step: 84  | total loss: [1m[32m0.30951[0m[0m | time: 3.961s
[2K
| Adam | epoch: 017 | loss: 0.30951 - acc: 0.8812 -- iter: 128/159
[A[ATraining Step: 85  | total loss: [1m[32m0.28838[0m[0m | time: 6.073s
[2K
| Adam | epoch: 017 | loss: 0.28838 - acc: 0.8931 | val_loss: 0.43069 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 86  | total loss: [1m[32m0.27165[0m[0m | time: 1.057s
[2K
| Adam | epoch: 018 | loss: 0.27165 - acc: 0.9007 -- iter: 032/159
[A[ATraining Step: 87  | total loss: [1m[32m0.25629[0m[0m | time: 2.197s
[2K
| Adam | epoch: 018 | loss: 0.25629 - acc: 0.9106 -- iter: 064/159
[A[ATraining Step: 88  | total loss: [1m[32m0.24429[0m[0m | time: 3.151s
[2K
| Adam | epoch: 018 | loss: 0.24429 - acc: 0.9133 -- iter: 096/159
[A[ATraining Step: 89  | total loss: [1m[32m0.23482[0m[0m | time: 4.009s
[2K
| Adam | epoch: 018 | loss: 0.23482 - acc: 0.9157 -- iter: 128/159
[A[ATraining Step: 90  | total loss: [1m[32m0.21726[0m[0m | time: 5.974s
[2K
| Adam | epoch: 018 | loss: 0.21726 - acc: 0.9241 | val_loss: 0.42731 - val_acc: 0.8400 -- iter: 159/159
--
Training Step: 91  | total loss: [1m[32m0.20711[0m[0m | time: 1.014s
[2K
| Adam | epoch: 019 | loss: 0.20711 - acc: 0.9317 -- iter: 032/159
[A[ATraining Step: 92  | total loss: [1m[32m0.19781[0m[0m | time: 2.101s
[2K
| Adam | epoch: 019 | loss: 0.19781 - acc: 0.9354 -- iter: 064/159
[A[ATraining Step: 93  | total loss: [1m[32m0.19748[0m[0m | time: 3.197s
[2K
| Adam | epoch: 019 | loss: 0.19748 - acc: 0.9325 -- iter: 096/159
[A[ATraining Step: 94  | total loss: [1m[32m0.20618[0m[0m | time: 4.009s
[2K
| Adam | epoch: 019 | loss: 0.20618 - acc: 0.9299 -- iter: 128/159
[A[ATraining Step: 95  | total loss: [1m[32m0.19509[0m[0m | time: 5.991s
[2K
| Adam | epoch: 019 | loss: 0.19509 - acc: 0.9338 | val_loss: 0.45400 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 96  | total loss: [1m[32m0.18209[0m[0m | time: 1.080s
[2K
| Adam | epoch: 020 | loss: 0.18209 - acc: 0.9404 -- iter: 032/159
[A[ATraining Step: 97  | total loss: [1m[32m0.17172[0m[0m | time: 2.181s
[2K
| Adam | epoch: 020 | loss: 0.17172 - acc: 0.9464 -- iter: 064/159
[A[ATraining Step: 98  | total loss: [1m[32m0.15848[0m[0m | time: 3.115s
[2K
| Adam | epoch: 020 | loss: 0.15848 - acc: 0.9517 -- iter: 096/159
[A[ATraining Step: 99  | total loss: [1m[32m0.14517[0m[0m | time: 4.042s
[2K
| Adam | epoch: 020 | loss: 0.14517 - acc: 0.9565 -- iter: 128/159
[A[ATraining Step: 100  | total loss: [1m[32m0.18372[0m[0m | time: 6.039s
[2K
| Adam | epoch: 020 | loss: 0.18372 - acc: 0.9421 | val_loss: 0.52352 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 101  | total loss: [1m[32m0.17880[0m[0m | time: 1.009s
[2K
| Adam | epoch: 021 | loss: 0.17880 - acc: 0.9417 -- iter: 032/159
[A[ATraining Step: 102  | total loss: [1m[32m0.16373[0m[0m | time: 1.994s
[2K
| Adam | epoch: 021 | loss: 0.16373 - acc: 0.9475 -- iter: 064/159
[A[ATraining Step: 103  | total loss: [1m[32m0.15816[0m[0m | time: 2.760s
[2K
| Adam | epoch: 021 | loss: 0.15816 - acc: 0.9463 -- iter: 096/159
[A[ATraining Step: 104  | total loss: [1m[32m0.14612[0m[0m | time: 3.387s
[2K
| Adam | epoch: 021 | loss: 0.14612 - acc: 0.9517 -- iter: 128/159
[A[ATraining Step: 105  | total loss: [1m[32m0.13277[0m[0m | time: 5.009s
[2K
| Adam | epoch: 021 | loss: 0.13277 - acc: 0.9565 | val_loss: 0.58124 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 106  | total loss: [1m[32m0.13135[0m[0m | time: 0.641s
[2K
| Adam | epoch: 022 | loss: 0.13135 - acc: 0.9577 -- iter: 032/159
[A[ATraining Step: 107  | total loss: [1m[32m0.12037[0m[0m | time: 1.223s
[2K
| Adam | epoch: 022 | loss: 0.12037 - acc: 0.9620 -- iter: 064/159
[A[ATraining Step: 108  | total loss: [1m[32m0.11009[0m[0m | time: 1.829s
[2K
| Adam | epoch: 022 | loss: 0.11009 - acc: 0.9658 -- iter: 096/159
[A[ATraining Step: 109  | total loss: [1m[32m0.10114[0m[0m | time: 2.483s
[2K
| Adam | epoch: 022 | loss: 0.10114 - acc: 0.9692 -- iter: 128/159
[A[ATraining Step: 110  | total loss: [1m[32m0.09286[0m[0m | time: 4.216s
[2K
| Adam | epoch: 022 | loss: 0.09286 - acc: 0.9723 | val_loss: 0.56805 - val_acc: 0.8200 -- iter: 159/159
--
Training Step: 111  | total loss: [1m[32m0.08514[0m[0m | time: 0.613s
[2K
| Adam | epoch: 023 | loss: 0.08514 - acc: 0.9750 -- iter: 032/159
[A[ATraining Step: 112  | total loss: [1m[32m0.09188[0m[0m | time: 1.234s
[2K
| Adam | epoch: 023 | loss: 0.09188 - acc: 0.9744 -- iter: 064/159
[A[ATraining Step: 113  | total loss: [1m[32m0.08376[0m[0m | time: 1.834s
[2K
| Adam | epoch: 023 | loss: 0.08376 - acc: 0.9770 -- iter: 096/159
[A[ATraining Step: 114  | total loss: [1m[32m0.07960[0m[0m | time: 2.437s
[2K
| Adam | epoch: 023 | loss: 0.07960 - acc: 0.9793 -- iter: 128/159
[A[ATraining Step: 115  | total loss: [1m[32m0.07323[0m[0m | time: 4.046s
[2K
| Adam | epoch: 023 | loss: 0.07323 - acc: 0.9813 | val_loss: 0.46058 - val_acc: 0.8200 -- iter: 159/159
--
Training Step: 116  | total loss: [1m[32m0.06876[0m[0m | time: 0.930s
[2K
| Adam | epoch: 024 | loss: 0.06876 - acc: 0.9832 -- iter: 032/159
[A[ATraining Step: 117  | total loss: [1m[32m0.07254[0m[0m | time: 1.777s
[2K
| Adam | epoch: 024 | loss: 0.07254 - acc: 0.9818 -- iter: 064/159
[A[ATraining Step: 118  | total loss: [1m[32m0.08673[0m[0m | time: 2.722s
[2K
| Adam | epoch: 024 | loss: 0.08673 - acc: 0.9773 -- iter: 096/159
[A[ATraining Step: 119  | total loss: [1m[32m0.07865[0m[0m | time: 3.618s
[2K
| Adam | epoch: 024 | loss: 0.07865 - acc: 0.9796 -- iter: 128/159
[A[ATraining Step: 120  | total loss: [1m[32m0.07165[0m[0m | time: 5.687s
[2K
| Adam | epoch: 024 | loss: 0.07165 - acc: 0.9816 | val_loss: 0.82852 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 121  | total loss: [1m[32m0.06686[0m[0m | time: 0.840s
[2K
| Adam | epoch: 025 | loss: 0.06686 - acc: 0.9835 -- iter: 032/159
[A[ATraining Step: 122  | total loss: [1m[32m0.06952[0m[0m | time: 1.815s
[2K
| Adam | epoch: 025 | loss: 0.06952 - acc: 0.9820 -- iter: 064/159
[A[ATraining Step: 123  | total loss: [1m[32m0.06374[0m[0m | time: 2.761s
[2K
| Adam | epoch: 025 | loss: 0.06374 - acc: 0.9838 -- iter: 096/159
[A[ATraining Step: 124  | total loss: [1m[32m0.06076[0m[0m | time: 3.709s
[2K
| Adam | epoch: 025 | loss: 0.06076 - acc: 0.9854 -- iter: 128/159
[A[ATraining Step: 125  | total loss: [1m[32m0.05704[0m[0m | time: 5.801s
[2K
| Adam | epoch: 025 | loss: 0.05704 - acc: 0.9869 | val_loss: 0.60948 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 126  | total loss: [1m[32m0.05455[0m[0m | time: 0.944s
[2K
| Adam | epoch: 026 | loss: 0.05455 - acc: 0.9882 -- iter: 032/159
[A[ATraining Step: 127  | total loss: [1m[32m0.04976[0m[0m | time: 1.953s
[2K
| Adam | epoch: 026 | loss: 0.04976 - acc: 0.9894 -- iter: 064/159
[A[ATraining Step: 128  | total loss: [1m[32m0.04561[0m[0m | time: 2.944s
[2K
| Adam | epoch: 026 | loss: 0.04561 - acc: 0.9904 -- iter: 096/159
[A[ATraining Step: 129  | total loss: [1m[32m0.04638[0m[0m | time: 4.097s
[2K
| Adam | epoch: 026 | loss: 0.04638 - acc: 0.9914 -- iter: 128/159
[A[ATraining Step: 130  | total loss: [1m[32m0.04760[0m[0m | time: 6.008s
[2K
| Adam | epoch: 026 | loss: 0.04760 - acc: 0.9891 | val_loss: 0.59579 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 131  | total loss: [1m[32m0.04323[0m[0m | time: 0.849s
[2K
| Adam | epoch: 027 | loss: 0.04323 - acc: 0.9902 -- iter: 032/159
[A[ATraining Step: 132  | total loss: [1m[32m0.04618[0m[0m | time: 1.779s
[2K
| Adam | epoch: 027 | loss: 0.04618 - acc: 0.9880 -- iter: 064/159
[A[ATraining Step: 133  | total loss: [1m[32m0.04551[0m[0m | time: 2.788s
[2K
| Adam | epoch: 027 | loss: 0.04551 - acc: 0.9892 -- iter: 096/159
[A[ATraining Step: 134  | total loss: [1m[32m0.04261[0m[0m | time: 3.823s
[2K
| Adam | epoch: 027 | loss: 0.04261 - acc: 0.9903 -- iter: 128/159
[A[ATraining Step: 135  | total loss: [1m[32m0.03956[0m[0m | time: 5.944s
[2K
| Adam | epoch: 027 | loss: 0.03956 - acc: 0.9912 | val_loss: 0.86073 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 136  | total loss: [1m[32m0.06257[0m[0m | time: 0.874s
[2K
| Adam | epoch: 028 | loss: 0.06257 - acc: 0.9859 -- iter: 032/159
[A[ATraining Step: 137  | total loss: [1m[32m0.05912[0m[0m | time: 1.844s
[2K
| Adam | epoch: 028 | loss: 0.05912 - acc: 0.9873 -- iter: 064/159
[A[ATraining Step: 138  | total loss: [1m[32m0.05367[0m[0m | time: 2.809s
[2K
| Adam | epoch: 028 | loss: 0.05367 - acc: 0.9885 -- iter: 096/159
[A[ATraining Step: 139  | total loss: [1m[32m0.04875[0m[0m | time: 3.808s
[2K
| Adam | epoch: 028 | loss: 0.04875 - acc: 0.9897 -- iter: 128/159
[A[ATraining Step: 140  | total loss: [1m[32m0.04630[0m[0m | time: 5.998s
[2K
| Adam | epoch: 028 | loss: 0.04630 - acc: 0.9907 | val_loss: 0.52410 - val_acc: 0.8400 -- iter: 159/159
--
Training Step: 141  | total loss: [1m[32m0.04707[0m[0m | time: 0.652s
[2K
| Adam | epoch: 029 | loss: 0.04707 - acc: 0.9916 -- iter: 032/159
[A[ATraining Step: 142  | total loss: [1m[32m0.04295[0m[0m | time: 1.255s
[2K
| Adam | epoch: 029 | loss: 0.04295 - acc: 0.9925 -- iter: 064/159
[A[ATraining Step: 143  | total loss: [1m[32m0.03951[0m[0m | time: 1.845s
[2K
| Adam | epoch: 029 | loss: 0.03951 - acc: 0.9932 -- iter: 096/159
[A[ATraining Step: 144  | total loss: [1m[32m0.03655[0m[0m | time: 2.447s
[2K
| Adam | epoch: 029 | loss: 0.03655 - acc: 0.9939 -- iter: 128/159
[A[ATraining Step: 145  | total loss: [1m[32m0.03505[0m[0m | time: 4.058s
[2K
| Adam | epoch: 029 | loss: 0.03505 - acc: 0.9945 | val_loss: 0.84661 - val_acc: 0.8000 -- iter: 159/159
--
Training Step: 146  | total loss: [1m[32m0.03332[0m[0m | time: 0.606s
[2K
| Adam | epoch: 030 | loss: 0.03332 - acc: 0.9951 -- iter: 032/159
[A[ATraining Step: 147  | total loss: [1m[32m0.03153[0m[0m | time: 1.210s
[2K
| Adam | epoch: 030 | loss: 0.03153 - acc: 0.9956 -- iter: 064/159
[A[ATraining Step: 148  | total loss: [1m[32m0.02879[0m[0m | time: 1.952s
[2K
| Adam | epoch: 030 | loss: 0.02879 - acc: 0.9960 -- iter: 096/159
[A[ATraining Step: 149  | total loss: [1m[32m0.02621[0m[0m | time: 2.549s
[2K
| Adam | epoch: 030 | loss: 0.02621 - acc: 0.9964 -- iter: 128/159
[A[ATraining Step: 150  | total loss: [1m[32m0.02426[0m[0m | time: 4.156s
[2K
| Adam | epoch: 030 | loss: 0.02426 - acc: 0.9968 | val_loss: 0.58517 - val_acc: 0.8000 -- iter: 159/159
--
Validation AUC:0.896434634974533
Validation AUPRC:0.9456324226516353
Test AUC:0.9535256410256411
Test AUPRC:0.9511942348513813
BestTestF1Score	0.93	0.85	0.92	0.87	1.0	26	4	20	0	0.67
BestTestMCCScore	0.88	0.76	0.88	0.92	0.85	22	2	22	4	0.98
BestTestAccuracyScore	0.88	0.76	0.88	0.92	0.85	22	2	22	4	0.98
BestValidationF1Score	0.86	0.61	0.82	0.84	0.87	27	5	14	4	0.67
BestValidationMCC	0.84	0.67	0.82	0.96	0.74	23	1	18	8	0.98
BestValidationAccuracy	0.84	0.67	0.82	0.96	0.74	23	1	18	8	0.98
TestPredictions (Threshold:0.98)
CHEMBL457180,TN,INACT,0.3199999928474426	CHEMBL2407744,TP,ACT,1.0	CHEMBL1288069,TN,INACT,0.07999999821186066	CHEMBL498520,TN,INACT,0.0	CHEMBL941,FN,ACT,0.9100000262260437	CHEMBL498130,TN,INACT,0.07999999821186066	CHEMBL553,FN,ACT,0.8199999928474426	CHEMBL486487,FP,INACT,1.0	CHEMBL2392390,TN,INACT,0.4300000071525574	CHEMBL1240703,TP,ACT,1.0	CHEMBL485878,TN,INACT,0.17000000178813934	CHEMBL529217,TN,INACT,0.25	CHEMBL521201,FN,ACT,0.9399999976158142	CHEMBL515674,TN,INACT,0.5	CHEMBL558849,TN,INACT,0.0	CHEMBL1721885,TP,ACT,0.9800000190734863	CHEMBL2392388,TN,INACT,0.019999999552965164	CHEMBL524820,TN,INACT,0.8199999928474426	CHEMBL456760,TN,INACT,0.009999999776482582	CHEMBL2407900,TP,ACT,1.0	CHEMBL1725279,TP,ACT,1.0	CHEMBL2420584,TN,INACT,0.9599999785423279	CHEMBL551936,TN,INACT,0.029999999329447746	CHEMBL2407902,TP,ACT,1.0	CHEMBL559882,TN,INACT,0.009999999776482582	CHEMBL3408947,TP,ACT,1.0	CHEMBL3422092,TP,ACT,1.0	CHEMBL223360,TP,ACT,1.0	CHEMBL563948,TN,INACT,0.009999999776482582	CHEMBL1287853,TP,ACT,0.9900000095367432	CHEMBL2407748,TP,ACT,1.0	CHEMBL1336,TP,ACT,1.0	CHEMBL522760,TN,INACT,0.3700000047683716	CHEMBL2407907,TP,ACT,0.9900000095367432	CHEMBL3353347,TP,ACT,1.0	CHEMBL1922121,TN,INACT,0.019999999552965164	CHEMBL2407901,FN,ACT,0.8500000238418579	CHEMBL456965,TN,INACT,0.0	CHEMBL3353345,TP,ACT,1.0	CHEMBL3353352,TP,ACT,1.0	CHEMBL1980391,TP,ACT,0.9800000190734863	CHEMBL3353354,TP,ACT,1.0	CHEMBL3353362,TP,ACT,1.0	CHEMBL488646,TN,INACT,0.5699999928474426	CHEMBL3408956,TP,ACT,1.0	CHEMBL1287914,TN,INACT,0.11999999731779099	CHEMBL475251,TP,ACT,1.0	CHEMBL457390,TN,INACT,0.3700000047683716	CHEMBL3408954,TP,ACT,1.0	CHEMBL504550,FP,INACT,1.0	

