CNNModel CHEMBL5570 adam 0.0005 30 128 0 0.6 False True
Number of active compounds :	209
Number of inactive compounds :	209
---------------------------------
Run id: CNNModel_CHEMBL5570_adam_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5570_adam_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 266
Validation samples: 84
--
Training Step: 1  | time: 1.176s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/266
[A[ATraining Step: 2  | total loss: [1m[32m0.62386[0m[0m | time: 2.099s
[2K
| Adam | epoch: 001 | loss: 0.62386 - acc: 0.4781 -- iter: 064/266
[A[ATraining Step: 3  | total loss: [1m[32m0.68066[0m[0m | time: 2.973s
[2K
| Adam | epoch: 001 | loss: 0.68066 - acc: 0.4705 -- iter: 096/266
[A[ATraining Step: 4  | total loss: [1m[32m0.68965[0m[0m | time: 3.814s
[2K
| Adam | epoch: 001 | loss: 0.68965 - acc: 0.5395 -- iter: 128/266
[A[ATraining Step: 5  | total loss: [1m[32m0.69283[0m[0m | time: 4.832s
[2K
| Adam | epoch: 001 | loss: 0.69283 - acc: 0.4905 -- iter: 160/266
[A[ATraining Step: 6  | total loss: [1m[32m0.69479[0m[0m | time: 5.838s
[2K
| Adam | epoch: 001 | loss: 0.69479 - acc: 0.4363 -- iter: 192/266
[A[ATraining Step: 7  | total loss: [1m[32m0.69366[0m[0m | time: 6.662s
[2K
| Adam | epoch: 001 | loss: 0.69366 - acc: 0.4745 -- iter: 224/266
[A[ATraining Step: 8  | total loss: [1m[32m0.69359[0m[0m | time: 7.462s
[2K
| Adam | epoch: 001 | loss: 0.69359 - acc: 0.4361 -- iter: 256/266
[A[ATraining Step: 9  | total loss: [1m[32m0.69299[0m[0m | time: 8.814s
[2K
| Adam | epoch: 001 | loss: 0.69299 - acc: 0.5030 | val_loss: 0.69329 - val_acc: 0.4643 -- iter: 266/266
--
Training Step: 10  | total loss: [1m[32m0.69388[0m[0m | time: 0.337s
[2K
| Adam | epoch: 002 | loss: 0.69388 - acc: 0.3515 -- iter: 032/266
[A[ATraining Step: 11  | total loss: [1m[32m0.69332[0m[0m | time: 1.268s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4218 -- iter: 064/266
[A[ATraining Step: 12  | total loss: [1m[32m0.69401[0m[0m | time: 2.183s
[2K
| Adam | epoch: 002 | loss: 0.69401 - acc: 0.4148 -- iter: 096/266
[A[ATraining Step: 13  | total loss: [1m[32m0.69363[0m[0m | time: 3.040s
[2K
| Adam | epoch: 002 | loss: 0.69363 - acc: 0.4647 -- iter: 128/266
[A[ATraining Step: 14  | total loss: [1m[32m0.69331[0m[0m | time: 4.056s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4792 -- iter: 160/266
[A[ATraining Step: 15  | total loss: [1m[32m0.69382[0m[0m | time: 5.089s
[2K
| Adam | epoch: 002 | loss: 0.69382 - acc: 0.4751 -- iter: 192/266
[A[ATraining Step: 16  | total loss: [1m[32m0.69420[0m[0m | time: 5.892s
[2K
| Adam | epoch: 002 | loss: 0.69420 - acc: 0.4376 -- iter: 224/266
[A[ATraining Step: 17  | total loss: [1m[32m0.69373[0m[0m | time: 6.684s
[2K
| Adam | epoch: 002 | loss: 0.69373 - acc: 0.4713 -- iter: 256/266
[A[ATraining Step: 18  | total loss: [1m[32m0.69366[0m[0m | time: 8.580s
[2K
| Adam | epoch: 002 | loss: 0.69366 - acc: 0.4812 | val_loss: 0.69317 - val_acc: 0.4643 -- iter: 266/266
--
Training Step: 19  | total loss: [1m[32m0.69344[0m[0m | time: 0.318s
[2K
| Adam | epoch: 003 | loss: 0.69344 - acc: 0.4979 -- iter: 032/266
[A[ATraining Step: 20  | total loss: [1m[32m0.69331[0m[0m | time: 0.652s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.4343 -- iter: 064/266
[A[ATraining Step: 21  | total loss: [1m[32m0.69313[0m[0m | time: 1.519s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.4857 -- iter: 096/266
[A[ATraining Step: 22  | total loss: [1m[32m0.69317[0m[0m | time: 2.433s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4806 -- iter: 128/266
[A[ATraining Step: 23  | total loss: [1m[32m0.69366[0m[0m | time: 3.215s
[2K
| Adam | epoch: 003 | loss: 0.69366 - acc: 0.4590 -- iter: 160/266
[A[ATraining Step: 24  | total loss: [1m[32m0.69324[0m[0m | time: 4.237s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4881 -- iter: 192/266
[A[ATraining Step: 25  | total loss: [1m[32m0.69307[0m[0m | time: 5.252s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.4999 -- iter: 224/266
[A[ATraining Step: 26  | total loss: [1m[32m0.69208[0m[0m | time: 6.072s
[2K
| Adam | epoch: 003 | loss: 0.69208 - acc: 0.5496 -- iter: 256/266
[A[ATraining Step: 27  | total loss: [1m[32m0.69203[0m[0m | time: 7.856s
[2K
| Adam | epoch: 003 | loss: 0.69203 - acc: 0.5448 | val_loss: 0.69193 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 28  | total loss: [1m[32m0.69406[0m[0m | time: 0.902s
[2K
| Adam | epoch: 004 | loss: 0.69406 - acc: 0.4946 -- iter: 032/266
[A[ATraining Step: 29  | total loss: [1m[32m0.69383[0m[0m | time: 1.200s
[2K
| Adam | epoch: 004 | loss: 0.69383 - acc: 0.4959 -- iter: 064/266
[A[ATraining Step: 30  | total loss: [1m[32m0.69190[0m[0m | time: 1.543s
[2K
| Adam | epoch: 004 | loss: 0.69190 - acc: 0.5442 -- iter: 096/266
[A[ATraining Step: 31  | total loss: [1m[32m0.69000[0m[0m | time: 2.384s
[2K
| Adam | epoch: 004 | loss: 0.69000 - acc: 0.5802 -- iter: 128/266
[A[ATraining Step: 32  | total loss: [1m[32m0.68945[0m[0m | time: 3.415s
[2K
| Adam | epoch: 004 | loss: 0.68945 - acc: 0.5832 -- iter: 160/266
[A[ATraining Step: 33  | total loss: [1m[32m0.68765[0m[0m | time: 4.446s
[2K
| Adam | epoch: 004 | loss: 0.68765 - acc: 0.5924 -- iter: 192/266
[A[ATraining Step: 34  | total loss: [1m[32m0.68938[0m[0m | time: 5.209s
[2K
| Adam | epoch: 004 | loss: 0.68938 - acc: 0.5726 -- iter: 224/266
[A[ATraining Step: 35  | total loss: [1m[32m0.69143[0m[0m | time: 6.043s
[2K
| Adam | epoch: 004 | loss: 0.69143 - acc: 0.5574 -- iter: 256/266
[A[ATraining Step: 36  | total loss: [1m[32m0.69428[0m[0m | time: 7.911s
[2K
| Adam | epoch: 004 | loss: 0.69428 - acc: 0.5393 | val_loss: 0.69090 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 37  | total loss: [1m[32m0.69050[0m[0m | time: 0.963s
[2K
| Adam | epoch: 005 | loss: 0.69050 - acc: 0.5564 -- iter: 032/266
[A[ATraining Step: 38  | total loss: [1m[32m0.69419[0m[0m | time: 1.835s
[2K
| Adam | epoch: 005 | loss: 0.69419 - acc: 0.5332 -- iter: 064/266
[A[ATraining Step: 39  | total loss: [1m[32m0.69286[0m[0m | time: 2.113s
[2K
| Adam | epoch: 005 | loss: 0.69286 - acc: 0.5388 -- iter: 096/266
[A[ATraining Step: 40  | total loss: [1m[32m0.69860[0m[0m | time: 2.380s
[2K
| Adam | epoch: 005 | loss: 0.69860 - acc: 0.4940 -- iter: 128/266
[A[ATraining Step: 41  | total loss: [1m[32m0.70192[0m[0m | time: 3.320s
[2K
| Adam | epoch: 005 | loss: 0.70192 - acc: 0.4584 -- iter: 160/266
[A[ATraining Step: 42  | total loss: [1m[32m0.69932[0m[0m | time: 4.266s
[2K
| Adam | epoch: 005 | loss: 0.69932 - acc: 0.4827 -- iter: 192/266
[A[ATraining Step: 43  | total loss: [1m[32m0.69706[0m[0m | time: 5.252s
[2K
| Adam | epoch: 005 | loss: 0.69706 - acc: 0.5078 -- iter: 224/266
[A[ATraining Step: 44  | total loss: [1m[32m0.69663[0m[0m | time: 5.979s
[2K
| Adam | epoch: 005 | loss: 0.69663 - acc: 0.5011 -- iter: 256/266
[A[ATraining Step: 45  | total loss: [1m[32m0.69626[0m[0m | time: 7.806s
[2K
| Adam | epoch: 005 | loss: 0.69626 - acc: 0.4956 | val_loss: 0.69213 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 46  | total loss: [1m[32m0.69560[0m[0m | time: 0.919s
[2K
| Adam | epoch: 006 | loss: 0.69560 - acc: 0.5015 -- iter: 032/266
[A[ATraining Step: 47  | total loss: [1m[32m0.69473[0m[0m | time: 1.715s
[2K
| Adam | epoch: 006 | loss: 0.69473 - acc: 0.5166 -- iter: 064/266
[A[ATraining Step: 48  | total loss: [1m[32m0.69415[0m[0m | time: 2.778s
[2K
| Adam | epoch: 006 | loss: 0.69415 - acc: 0.5240 -- iter: 096/266
[A[ATraining Step: 49  | total loss: [1m[32m0.69325[0m[0m | time: 3.153s
[2K
| Adam | epoch: 006 | loss: 0.69325 - acc: 0.5449 -- iter: 128/266
[A[ATraining Step: 50  | total loss: [1m[32m0.69418[0m[0m | time: 3.513s
[2K
| Adam | epoch: 006 | loss: 0.69418 - acc: 0.5069 -- iter: 160/266
[A[ATraining Step: 51  | total loss: [1m[32m0.69497[0m[0m | time: 4.398s
[2K
| Adam | epoch: 006 | loss: 0.69497 - acc: 0.4753 -- iter: 192/266
[A[ATraining Step: 52  | total loss: [1m[32m0.69474[0m[0m | time: 5.119s
[2K
| Adam | epoch: 006 | loss: 0.69474 - acc: 0.4790 -- iter: 224/266
[A[ATraining Step: 53  | total loss: [1m[32m0.69461[0m[0m | time: 5.959s
[2K
| Adam | epoch: 006 | loss: 0.69461 - acc: 0.4775 -- iter: 256/266
[A[ATraining Step: 54  | total loss: [1m[32m0.69410[0m[0m | time: 7.803s
[2K
| Adam | epoch: 006 | loss: 0.69410 - acc: 0.4944 | val_loss: 0.69253 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 55  | total loss: [1m[32m0.69426[0m[0m | time: 0.912s
[2K
| Adam | epoch: 007 | loss: 0.69426 - acc: 0.4818 -- iter: 032/266
[A[ATraining Step: 56  | total loss: [1m[32m0.69395[0m[0m | time: 1.699s
[2K
| Adam | epoch: 007 | loss: 0.69395 - acc: 0.4931 -- iter: 064/266
[A[ATraining Step: 57  | total loss: [1m[32m0.69377[0m[0m | time: 2.685s
[2K
| Adam | epoch: 007 | loss: 0.69377 - acc: 0.4984 -- iter: 096/266
[A[ATraining Step: 58  | total loss: [1m[32m0.69425[0m[0m | time: 3.713s
[2K
| Adam | epoch: 007 | loss: 0.69425 - acc: 0.4645 -- iter: 128/266
[A[ATraining Step: 59  | total loss: [1m[32m0.69387[0m[0m | time: 4.102s
[2K
| Adam | epoch: 007 | loss: 0.69387 - acc: 0.4861 -- iter: 160/266
[A[ATraining Step: 60  | total loss: [1m[32m0.69377[0m[0m | time: 4.386s
[2K
| Adam | epoch: 007 | loss: 0.69377 - acc: 0.4879 -- iter: 192/266
[A[ATraining Step: 61  | total loss: [1m[32m0.69369[0m[0m | time: 5.128s
[2K
| Adam | epoch: 007 | loss: 0.69369 - acc: 0.4895 -- iter: 224/266
[A[ATraining Step: 62  | total loss: [1m[32m0.69376[0m[0m | time: 5.962s
[2K
| Adam | epoch: 007 | loss: 0.69376 - acc: 0.4748 -- iter: 256/266
[A[ATraining Step: 63  | total loss: [1m[32m0.69372[0m[0m | time: 7.826s
[2K
| Adam | epoch: 007 | loss: 0.69372 - acc: 0.4701 | val_loss: 0.69315 - val_acc: 0.4643 -- iter: 266/266
--
Training Step: 64  | total loss: [1m[32m0.69365[0m[0m | time: 0.828s
[2K
| Adam | epoch: 008 | loss: 0.69365 - acc: 0.4699 -- iter: 032/266
[A[ATraining Step: 65  | total loss: [1m[32m0.69359[0m[0m | time: 1.797s
[2K
| Adam | epoch: 008 | loss: 0.69359 - acc: 0.4621 -- iter: 064/266
[A[ATraining Step: 66  | total loss: [1m[32m0.69350[0m[0m | time: 2.770s
[2K
| Adam | epoch: 008 | loss: 0.69350 - acc: 0.4857 -- iter: 096/266
[A[ATraining Step: 67  | total loss: [1m[32m0.69336[0m[0m | time: 3.683s
[2K
| Adam | epoch: 008 | loss: 0.69336 - acc: 0.5061 -- iter: 128/266
[A[ATraining Step: 68  | total loss: [1m[32m0.69356[0m[0m | time: 4.424s
[2K
| Adam | epoch: 008 | loss: 0.69356 - acc: 0.4758 -- iter: 160/266
[A[ATraining Step: 69  | total loss: [1m[32m0.69336[0m[0m | time: 4.710s
[2K
| Adam | epoch: 008 | loss: 0.69336 - acc: 0.4932 -- iter: 192/266
[A[ATraining Step: 70  | total loss: [1m[32m0.69360[0m[0m | time: 4.993s
[2K
| Adam | epoch: 008 | loss: 0.69360 - acc: 0.4709 -- iter: 224/266
[A[ATraining Step: 71  | total loss: [1m[32m0.69376[0m[0m | time: 5.853s
[2K
| Adam | epoch: 008 | loss: 0.69376 - acc: 0.4515 -- iter: 256/266
[A[ATraining Step: 72  | total loss: [1m[32m0.69361[0m[0m | time: 7.663s
[2K
| Adam | epoch: 008 | loss: 0.69361 - acc: 0.4675 | val_loss: 0.69286 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 73  | total loss: [1m[32m0.69347[0m[0m | time: 0.801s
[2K
| Adam | epoch: 009 | loss: 0.69347 - acc: 0.4815 -- iter: 032/266
[A[ATraining Step: 74  | total loss: [1m[32m0.69347[0m[0m | time: 1.718s
[2K
| Adam | epoch: 009 | loss: 0.69347 - acc: 0.4801 -- iter: 064/266
[A[ATraining Step: 75  | total loss: [1m[32m0.69347[0m[0m | time: 2.725s
[2K
| Adam | epoch: 009 | loss: 0.69347 - acc: 0.4789 -- iter: 096/266
[A[ATraining Step: 76  | total loss: [1m[32m0.69347[0m[0m | time: 3.597s
[2K
| Adam | epoch: 009 | loss: 0.69347 - acc: 0.4744 -- iter: 128/266
[A[ATraining Step: 77  | total loss: [1m[32m0.69346[0m[0m | time: 4.311s
[2K
| Adam | epoch: 009 | loss: 0.69346 - acc: 0.4738 -- iter: 160/266
[A[ATraining Step: 78  | total loss: [1m[32m0.69341[0m[0m | time: 5.146s
[2K
| Adam | epoch: 009 | loss: 0.69341 - acc: 0.4798 -- iter: 192/266
[A[ATraining Step: 79  | total loss: [1m[32m0.69342[0m[0m | time: 5.432s
[2K
| Adam | epoch: 009 | loss: 0.69342 - acc: 0.4755 -- iter: 224/266
[A[ATraining Step: 80  | total loss: [1m[32m0.69326[0m[0m | time: 5.762s
[2K
| Adam | epoch: 009 | loss: 0.69326 - acc: 0.5189 -- iter: 256/266
[A[ATraining Step: 81  | total loss: [1m[32m0.69303[0m[0m | time: 7.605s
[2K
| Adam | epoch: 009 | loss: 0.69303 - acc: 0.5574 | val_loss: 0.69273 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 82  | total loss: [1m[32m0.69294[0m[0m | time: 0.901s
[2K
| Adam | epoch: 010 | loss: 0.69294 - acc: 0.5642 -- iter: 032/266
[A[ATraining Step: 83  | total loss: [1m[32m0.69289[0m[0m | time: 1.869s
[2K
| Adam | epoch: 010 | loss: 0.69289 - acc: 0.5640 -- iter: 064/266
[A[ATraining Step: 84  | total loss: [1m[32m0.69317[0m[0m | time: 2.825s
[2K
| Adam | epoch: 010 | loss: 0.69317 - acc: 0.5420 -- iter: 096/266
[A[ATraining Step: 85  | total loss: [1m[32m0.69322[0m[0m | time: 3.527s
[2K
| Adam | epoch: 010 | loss: 0.69322 - acc: 0.5347 -- iter: 128/266
[A[ATraining Step: 86  | total loss: [1m[32m0.69303[0m[0m | time: 4.339s
[2K
| Adam | epoch: 010 | loss: 0.69303 - acc: 0.5406 -- iter: 160/266
[A[ATraining Step: 87  | total loss: [1m[32m0.69299[0m[0m | time: 5.217s
[2K
| Adam | epoch: 010 | loss: 0.69299 - acc: 0.5396 -- iter: 192/266
[A[ATraining Step: 88  | total loss: [1m[32m0.69300[0m[0m | time: 6.040s
[2K
| Adam | epoch: 010 | loss: 0.69300 - acc: 0.5357 -- iter: 224/266
[A[ATraining Step: 89  | total loss: [1m[32m0.69295[0m[0m | time: 6.350s
[2K
| Adam | epoch: 010 | loss: 0.69295 - acc: 0.5352 -- iter: 256/266
[A[ATraining Step: 90  | total loss: [1m[32m0.69343[0m[0m | time: 7.651s
[2K
| Adam | epoch: 010 | loss: 0.69343 - acc: 0.5117 | val_loss: 0.69237 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 91  | total loss: [1m[32m0.69390[0m[0m | time: 0.916s
[2K
| Adam | epoch: 011 | loss: 0.69390 - acc: 0.4905 -- iter: 032/266
[A[ATraining Step: 92  | total loss: [1m[32m0.69374[0m[0m | time: 1.865s
[2K
| Adam | epoch: 011 | loss: 0.69374 - acc: 0.4946 -- iter: 064/266
[A[ATraining Step: 93  | total loss: [1m[32m0.69369[0m[0m | time: 2.841s
[2K
| Adam | epoch: 011 | loss: 0.69369 - acc: 0.4951 -- iter: 096/266
[A[ATraining Step: 94  | total loss: [1m[32m0.69357[0m[0m | time: 3.543s
[2K
| Adam | epoch: 011 | loss: 0.69357 - acc: 0.4988 -- iter: 128/266
[A[ATraining Step: 95  | total loss: [1m[32m0.69339[0m[0m | time: 4.309s
[2K
| Adam | epoch: 011 | loss: 0.69339 - acc: 0.5051 -- iter: 160/266
[A[ATraining Step: 96  | total loss: [1m[32m0.69310[0m[0m | time: 5.141s
[2K
| Adam | epoch: 011 | loss: 0.69310 - acc: 0.5171 -- iter: 192/266
[A[ATraining Step: 97  | total loss: [1m[32m0.69312[0m[0m | time: 5.976s
[2K
| Adam | epoch: 011 | loss: 0.69312 - acc: 0.5154 -- iter: 224/266
[A[ATraining Step: 98  | total loss: [1m[32m0.69313[0m[0m | time: 6.805s
[2K
| Adam | epoch: 011 | loss: 0.69313 - acc: 0.5139 -- iter: 256/266
[A[ATraining Step: 99  | total loss: [1m[32m0.69270[0m[0m | time: 8.139s
[2K
| Adam | epoch: 011 | loss: 0.69270 - acc: 0.5312 | val_loss: 0.69228 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 100  | total loss: [1m[32m0.69299[0m[0m | time: 0.409s
[2K
| Adam | epoch: 012 | loss: 0.69299 - acc: 0.5181 -- iter: 032/266
[A[ATraining Step: 101  | total loss: [1m[32m0.69326[0m[0m | time: 1.386s
[2K
| Adam | epoch: 012 | loss: 0.69326 - acc: 0.5063 -- iter: 064/266
[A[ATraining Step: 102  | total loss: [1m[32m0.69310[0m[0m | time: 2.305s
[2K
| Adam | epoch: 012 | loss: 0.69310 - acc: 0.5119 -- iter: 096/266
[A[ATraining Step: 103  | total loss: [1m[32m0.69311[0m[0m | time: 2.994s
[2K
| Adam | epoch: 012 | loss: 0.69311 - acc: 0.5107 -- iter: 128/266
[A[ATraining Step: 104  | total loss: [1m[32m0.69312[0m[0m | time: 3.821s
[2K
| Adam | epoch: 012 | loss: 0.69312 - acc: 0.5097 -- iter: 160/266
[A[ATraining Step: 105  | total loss: [1m[32m0.69311[0m[0m | time: 4.681s
[2K
| Adam | epoch: 012 | loss: 0.69311 - acc: 0.5087 -- iter: 192/266
[A[ATraining Step: 106  | total loss: [1m[32m0.69312[0m[0m | time: 5.504s
[2K
| Adam | epoch: 012 | loss: 0.69312 - acc: 0.5078 -- iter: 224/266
[A[ATraining Step: 107  | total loss: [1m[32m0.69312[0m[0m | time: 6.317s
[2K
| Adam | epoch: 012 | loss: 0.69312 - acc: 0.5070 -- iter: 256/266
[A[ATraining Step: 108  | total loss: [1m[32m0.69310[0m[0m | time: 8.178s
[2K
| Adam | epoch: 012 | loss: 0.69310 - acc: 0.5063 | val_loss: 0.69209 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 109  | total loss: [1m[32m0.69260[0m[0m | time: 0.409s
[2K
| Adam | epoch: 013 | loss: 0.69260 - acc: 0.5244 -- iter: 032/266
[A[ATraining Step: 110  | total loss: [1m[32m0.69293[0m[0m | time: 0.751s
[2K
| Adam | epoch: 013 | loss: 0.69293 - acc: 0.5120 -- iter: 064/266
[A[ATraining Step: 111  | total loss: [1m[32m0.69325[0m[0m | time: 1.767s
[2K
| Adam | epoch: 013 | loss: 0.69325 - acc: 0.5008 -- iter: 096/266
[A[ATraining Step: 112  | total loss: [1m[32m0.69341[0m[0m | time: 2.463s
[2K
| Adam | epoch: 013 | loss: 0.69341 - acc: 0.4945 -- iter: 128/266
[A[ATraining Step: 113  | total loss: [1m[32m0.69355[0m[0m | time: 3.328s
[2K
| Adam | epoch: 013 | loss: 0.69355 - acc: 0.4888 -- iter: 160/266
[A[ATraining Step: 114  | total loss: [1m[32m0.69349[0m[0m | time: 4.196s
[2K
| Adam | epoch: 013 | loss: 0.69349 - acc: 0.4899 -- iter: 192/266
[A[ATraining Step: 115  | total loss: [1m[32m0.69358[0m[0m | time: 5.047s
[2K
| Adam | epoch: 013 | loss: 0.69358 - acc: 0.4847 -- iter: 224/266
[A[ATraining Step: 116  | total loss: [1m[32m0.69326[0m[0m | time: 5.874s
[2K
| Adam | epoch: 013 | loss: 0.69326 - acc: 0.4956 -- iter: 256/266
[A[ATraining Step: 117  | total loss: [1m[32m0.69282[0m[0m | time: 7.762s
[2K
| Adam | epoch: 013 | loss: 0.69282 - acc: 0.5116 | val_loss: 0.69153 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 118  | total loss: [1m[32m0.69262[0m[0m | time: 1.049s
[2K
| Adam | epoch: 014 | loss: 0.69262 - acc: 0.5167 -- iter: 032/266
[A[ATraining Step: 119  | total loss: [1m[32m0.69263[0m[0m | time: 1.404s
[2K
| Adam | epoch: 014 | loss: 0.69263 - acc: 0.5151 -- iter: 064/266
[A[ATraining Step: 120  | total loss: [1m[32m0.69294[0m[0m | time: 1.738s
[2K
| Adam | epoch: 014 | loss: 0.69294 - acc: 0.5035 -- iter: 096/266
[A[ATraining Step: 121  | total loss: [1m[32m0.69319[0m[0m | time: 2.447s
[2K
| Adam | epoch: 014 | loss: 0.69319 - acc: 0.4932 -- iter: 128/266
[A[ATraining Step: 122  | total loss: [1m[32m0.69251[0m[0m | time: 3.273s
[2K
| Adam | epoch: 014 | loss: 0.69251 - acc: 0.5126 -- iter: 160/266
[A[ATraining Step: 123  | total loss: [1m[32m0.69187[0m[0m | time: 4.100s
[2K
| Adam | epoch: 014 | loss: 0.69187 - acc: 0.5301 -- iter: 192/266
[A[ATraining Step: 124  | total loss: [1m[32m0.69247[0m[0m | time: 4.924s
[2K
| Adam | epoch: 014 | loss: 0.69247 - acc: 0.5115 -- iter: 224/266
[A[ATraining Step: 125  | total loss: [1m[32m0.69201[0m[0m | time: 5.765s
[2K
| Adam | epoch: 014 | loss: 0.69201 - acc: 0.5197 -- iter: 256/266
[A[ATraining Step: 126  | total loss: [1m[32m0.69254[0m[0m | time: 7.638s
[2K
| Adam | epoch: 014 | loss: 0.69254 - acc: 0.5021 | val_loss: 0.68933 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 127  | total loss: [1m[32m0.69228[0m[0m | time: 0.981s
[2K
| Adam | epoch: 015 | loss: 0.69228 - acc: 0.5050 -- iter: 032/266
[A[ATraining Step: 128  | total loss: [1m[32m0.69207[0m[0m | time: 1.984s
[2K
| Adam | epoch: 015 | loss: 0.69207 - acc: 0.5045 -- iter: 064/266
[A[ATraining Step: 129  | total loss: [1m[32m0.69167[0m[0m | time: 2.294s
[2K
| Adam | epoch: 015 | loss: 0.69167 - acc: 0.5072 -- iter: 096/266
[A[ATraining Step: 130  | total loss: [1m[32m0.69143[0m[0m | time: 2.505s
[2K
| Adam | epoch: 015 | loss: 0.69143 - acc: 0.5065 -- iter: 128/266
[A[ATraining Step: 131  | total loss: [1m[32m0.69103[0m[0m | time: 3.344s
[2K
| Adam | epoch: 015 | loss: 0.69103 - acc: 0.5058 -- iter: 160/266
[A[ATraining Step: 132  | total loss: [1m[32m0.68989[0m[0m | time: 4.179s
[2K
| Adam | epoch: 015 | loss: 0.68989 - acc: 0.5146 -- iter: 192/266
[A[ATraining Step: 133  | total loss: [1m[32m0.68996[0m[0m | time: 5.013s
[2K
| Adam | epoch: 015 | loss: 0.68996 - acc: 0.4975 -- iter: 224/266
[A[ATraining Step: 134  | total loss: [1m[32m0.68935[0m[0m | time: 5.864s
[2K
| Adam | epoch: 015 | loss: 0.68935 - acc: 0.4947 -- iter: 256/266
[A[ATraining Step: 135  | total loss: [1m[32m0.68737[0m[0m | time: 7.699s
[2K
| Adam | epoch: 015 | loss: 0.68737 - acc: 0.5171 | val_loss: 0.67144 - val_acc: 0.5357 -- iter: 266/266
--
Training Step: 136  | total loss: [1m[32m0.68677[0m[0m | time: 0.972s
[2K
| Adam | epoch: 016 | loss: 0.68677 - acc: 0.5154 -- iter: 032/266
[A[ATraining Step: 137  | total loss: [1m[32m0.68440[0m[0m | time: 1.965s
[2K
| Adam | epoch: 016 | loss: 0.68440 - acc: 0.5201 -- iter: 064/266
[A[ATraining Step: 138  | total loss: [1m[32m0.68227[0m[0m | time: 2.903s
[2K
| Adam | epoch: 016 | loss: 0.68227 - acc: 0.5212 -- iter: 096/266
[A[ATraining Step: 139  | total loss: [1m[32m0.67870[0m[0m | time: 3.122s
[2K
| Adam | epoch: 016 | loss: 0.67870 - acc: 0.5253 -- iter: 128/266
[A[ATraining Step: 140  | total loss: [1m[32m0.67672[0m[0m | time: 3.383s
[2K
| Adam | epoch: 016 | loss: 0.67672 - acc: 0.5228 -- iter: 160/266
[A[ATraining Step: 141  | total loss: [1m[32m0.67414[0m[0m | time: 4.186s
[2K
| Adam | epoch: 016 | loss: 0.67414 - acc: 0.5605 -- iter: 192/266
[A[ATraining Step: 142  | total loss: [1m[32m0.66475[0m[0m | time: 5.046s
[2K
| Adam | epoch: 016 | loss: 0.66475 - acc: 0.5888 -- iter: 224/266
[A[ATraining Step: 143  | total loss: [1m[32m0.65871[0m[0m | time: 5.902s
[2K
| Adam | epoch: 016 | loss: 0.65871 - acc: 0.5862 -- iter: 256/266
[A[ATraining Step: 144  | total loss: [1m[32m0.65205[0m[0m | time: 7.747s
[2K
| Adam | epoch: 016 | loss: 0.65205 - acc: 0.5870 | val_loss: 0.60451 - val_acc: 0.8452 -- iter: 266/266
--
Training Step: 145  | total loss: [1m[32m0.64857[0m[0m | time: 0.914s
[2K
| Adam | epoch: 017 | loss: 0.64857 - acc: 0.5845 -- iter: 032/266
[A[ATraining Step: 146  | total loss: [1m[32m0.64567[0m[0m | time: 1.661s
[2K
| Adam | epoch: 017 | loss: 0.64567 - acc: 0.6167 -- iter: 064/266
[A[ATraining Step: 147  | total loss: [1m[32m0.64582[0m[0m | time: 2.504s
[2K
| Adam | epoch: 017 | loss: 0.64582 - acc: 0.6269 -- iter: 096/266
[A[ATraining Step: 148  | total loss: [1m[32m0.64378[0m[0m | time: 3.389s
[2K
| Adam | epoch: 017 | loss: 0.64378 - acc: 0.6330 -- iter: 128/266
[A[ATraining Step: 149  | total loss: [1m[32m0.62503[0m[0m | time: 3.701s
[2K
| Adam | epoch: 017 | loss: 0.62503 - acc: 0.6665 -- iter: 160/266
[A[ATraining Step: 150  | total loss: [1m[32m0.61103[0m[0m | time: 4.005s
[2K
| Adam | epoch: 017 | loss: 0.61103 - acc: 0.6499 -- iter: 192/266
[A[ATraining Step: 151  | total loss: [1m[32m0.58761[0m[0m | time: 4.879s
[2K
| Adam | epoch: 017 | loss: 0.58761 - acc: 0.6749 -- iter: 224/266
[A[ATraining Step: 152  | total loss: [1m[32m0.57279[0m[0m | time: 5.759s
[2K
| Adam | epoch: 017 | loss: 0.57279 - acc: 0.6887 -- iter: 256/266
[A[ATraining Step: 153  | total loss: [1m[32m0.57908[0m[0m | time: 7.634s
[2K
| Adam | epoch: 017 | loss: 0.57908 - acc: 0.6792 | val_loss: 0.39414 - val_acc: 0.8333 -- iter: 266/266
--
Training Step: 154  | total loss: [1m[32m0.56536[0m[0m | time: 0.936s
[2K
| Adam | epoch: 018 | loss: 0.56536 - acc: 0.6956 -- iter: 032/266
[A[ATraining Step: 155  | total loss: [1m[32m0.54464[0m[0m | time: 1.673s
[2K
| Adam | epoch: 018 | loss: 0.54464 - acc: 0.7136 -- iter: 064/266
[A[ATraining Step: 156  | total loss: [1m[32m0.52282[0m[0m | time: 2.510s
[2K
| Adam | epoch: 018 | loss: 0.52282 - acc: 0.7328 -- iter: 096/266
[A[ATraining Step: 157  | total loss: [1m[32m0.51059[0m[0m | time: 3.331s
[2K
| Adam | epoch: 018 | loss: 0.51059 - acc: 0.7408 -- iter: 128/266
[A[ATraining Step: 158  | total loss: [1m[32m0.51356[0m[0m | time: 4.166s
[2K
| Adam | epoch: 018 | loss: 0.51356 - acc: 0.7448 -- iter: 160/266
[A[ATraining Step: 159  | total loss: [1m[32m0.49385[0m[0m | time: 4.470s
[2K
| Adam | epoch: 018 | loss: 0.49385 - acc: 0.7610 -- iter: 192/266
[A[ATraining Step: 160  | total loss: [1m[32m0.46142[0m[0m | time: 4.775s
[2K
| Adam | epoch: 018 | loss: 0.46142 - acc: 0.7749 -- iter: 224/266
[A[ATraining Step: 161  | total loss: [1m[32m0.42934[0m[0m | time: 5.639s
[2K
| Adam | epoch: 018 | loss: 0.42934 - acc: 0.7974 -- iter: 256/266
[A[ATraining Step: 162  | total loss: [1m[32m0.40858[0m[0m | time: 7.542s
[2K
| Adam | epoch: 018 | loss: 0.40858 - acc: 0.8083 | val_loss: 0.46166 - val_acc: 0.7976 -- iter: 266/266
--
Training Step: 163  | total loss: [1m[32m0.40619[0m[0m | time: 0.941s
[2K
| Adam | epoch: 019 | loss: 0.40619 - acc: 0.8118 -- iter: 032/266
[A[ATraining Step: 164  | total loss: [1m[32m0.42924[0m[0m | time: 1.643s
[2K
| Adam | epoch: 019 | loss: 0.42924 - acc: 0.8025 -- iter: 064/266
[A[ATraining Step: 165  | total loss: [1m[32m0.45051[0m[0m | time: 2.524s
[2K
| Adam | epoch: 019 | loss: 0.45051 - acc: 0.7973 -- iter: 096/266
[A[ATraining Step: 166  | total loss: [1m[32m0.43882[0m[0m | time: 3.367s
[2K
| Adam | epoch: 019 | loss: 0.43882 - acc: 0.8050 -- iter: 128/266
[A[ATraining Step: 167  | total loss: [1m[32m0.42872[0m[0m | time: 4.222s
[2K
| Adam | epoch: 019 | loss: 0.42872 - acc: 0.8120 -- iter: 160/266
[A[ATraining Step: 168  | total loss: [1m[32m0.43151[0m[0m | time: 5.091s
[2K
| Adam | epoch: 019 | loss: 0.43151 - acc: 0.8090 -- iter: 192/266
[A[ATraining Step: 169  | total loss: [1m[32m0.41886[0m[0m | time: 5.423s
[2K
| Adam | epoch: 019 | loss: 0.41886 - acc: 0.8156 -- iter: 224/266
[A[ATraining Step: 170  | total loss: [1m[32m0.39740[0m[0m | time: 5.784s
[2K
| Adam | epoch: 019 | loss: 0.39740 - acc: 0.8240 -- iter: 256/266
[A[ATraining Step: 171  | total loss: [1m[32m0.39487[0m[0m | time: 7.685s
[2K
| Adam | epoch: 019 | loss: 0.39487 - acc: 0.8216 | val_loss: 0.29028 - val_acc: 0.8571 -- iter: 266/266
--
Training Step: 172  | total loss: [1m[32m0.38879[0m[0m | time: 0.779s
[2K
| Adam | epoch: 020 | loss: 0.38879 - acc: 0.8269 -- iter: 032/266
[A[ATraining Step: 173  | total loss: [1m[32m0.38727[0m[0m | time: 1.624s
[2K
| Adam | epoch: 020 | loss: 0.38727 - acc: 0.8286 -- iter: 064/266
[A[ATraining Step: 174  | total loss: [1m[32m0.38499[0m[0m | time: 2.464s
[2K
| Adam | epoch: 020 | loss: 0.38499 - acc: 0.8333 -- iter: 096/266
[A[ATraining Step: 175  | total loss: [1m[32m0.38798[0m[0m | time: 3.349s
[2K
| Adam | epoch: 020 | loss: 0.38798 - acc: 0.8281 -- iter: 128/266
[A[ATraining Step: 176  | total loss: [1m[32m0.36769[0m[0m | time: 4.171s
[2K
| Adam | epoch: 020 | loss: 0.36769 - acc: 0.8390 -- iter: 160/266
[A[ATraining Step: 177  | total loss: [1m[32m0.35918[0m[0m | time: 5.023s
[2K
| Adam | epoch: 020 | loss: 0.35918 - acc: 0.8426 -- iter: 192/266
[A[ATraining Step: 178  | total loss: [1m[32m0.34403[0m[0m | time: 5.995s
[2K
| Adam | epoch: 020 | loss: 0.34403 - acc: 0.8521 -- iter: 224/266
[A[ATraining Step: 179  | total loss: [1m[32m0.33558[0m[0m | time: 6.298s
[2K
| Adam | epoch: 020 | loss: 0.33558 - acc: 0.8544 -- iter: 256/266
[A[ATraining Step: 180  | total loss: [1m[32m0.31575[0m[0m | time: 7.626s
[2K
| Adam | epoch: 020 | loss: 0.31575 - acc: 0.8689 | val_loss: 0.29720 - val_acc: 0.9048 -- iter: 266/266
--
Training Step: 181  | total loss: [1m[32m0.29867[0m[0m | time: 0.829s
[2K
| Adam | epoch: 021 | loss: 0.29867 - acc: 0.8821 -- iter: 032/266
[A[ATraining Step: 182  | total loss: [1m[32m0.28260[0m[0m | time: 1.674s
[2K
| Adam | epoch: 021 | loss: 0.28260 - acc: 0.8876 -- iter: 064/266
[A[ATraining Step: 183  | total loss: [1m[32m0.26706[0m[0m | time: 2.553s
[2K
| Adam | epoch: 021 | loss: 0.26706 - acc: 0.8926 -- iter: 096/266
[A[ATraining Step: 184  | total loss: [1m[32m0.26990[0m[0m | time: 3.443s
[2K
| Adam | epoch: 021 | loss: 0.26990 - acc: 0.8940 -- iter: 128/266
[A[ATraining Step: 185  | total loss: [1m[32m0.25958[0m[0m | time: 4.294s
[2K
| Adam | epoch: 021 | loss: 0.25958 - acc: 0.8952 -- iter: 160/266
[A[ATraining Step: 186  | total loss: [1m[32m0.26040[0m[0m | time: 5.160s
[2K
| Adam | epoch: 021 | loss: 0.26040 - acc: 0.8994 -- iter: 192/266
[A[ATraining Step: 187  | total loss: [1m[32m0.25704[0m[0m | time: 5.940s
[2K
| Adam | epoch: 021 | loss: 0.25704 - acc: 0.9001 -- iter: 224/266
[A[ATraining Step: 188  | total loss: [1m[32m0.25501[0m[0m | time: 6.973s
[2K
| Adam | epoch: 021 | loss: 0.25501 - acc: 0.9007 -- iter: 256/266
[A[ATraining Step: 189  | total loss: [1m[32m0.24882[0m[0m | time: 8.356s
[2K
| Adam | epoch: 021 | loss: 0.24882 - acc: 0.9044 | val_loss: 0.24724 - val_acc: 0.8929 -- iter: 266/266
--
Training Step: 190  | total loss: [1m[32m0.23061[0m[0m | time: 0.302s
[2K
| Adam | epoch: 022 | loss: 0.23061 - acc: 0.9140 -- iter: 032/266
[A[ATraining Step: 191  | total loss: [1m[32m0.21383[0m[0m | time: 1.142s
[2K
| Adam | epoch: 022 | loss: 0.21383 - acc: 0.9226 -- iter: 064/266
[A[ATraining Step: 192  | total loss: [1m[32m0.22423[0m[0m | time: 2.002s
[2K
| Adam | epoch: 022 | loss: 0.22423 - acc: 0.9209 -- iter: 096/266
[A[ATraining Step: 193  | total loss: [1m[32m0.20796[0m[0m | time: 2.899s
[2K
| Adam | epoch: 022 | loss: 0.20796 - acc: 0.9288 -- iter: 128/266
[A[ATraining Step: 194  | total loss: [1m[32m0.19602[0m[0m | time: 3.818s
[2K
| Adam | epoch: 022 | loss: 0.19602 - acc: 0.9328 -- iter: 160/266
[A[ATraining Step: 195  | total loss: [1m[32m0.21393[0m[0m | time: 4.643s
[2K
| Adam | epoch: 022 | loss: 0.21393 - acc: 0.9239 -- iter: 192/266
[A[ATraining Step: 196  | total loss: [1m[32m0.21654[0m[0m | time: 5.570s
[2K
| Adam | epoch: 022 | loss: 0.21654 - acc: 0.9222 -- iter: 224/266
[A[ATraining Step: 197  | total loss: [1m[32m0.20017[0m[0m | time: 6.580s
[2K
| Adam | epoch: 022 | loss: 0.20017 - acc: 0.9299 -- iter: 256/266
[A[ATraining Step: 198  | total loss: [1m[32m0.19943[0m[0m | time: 8.589s
[2K
| Adam | epoch: 022 | loss: 0.19943 - acc: 0.9338 | val_loss: 0.25246 - val_acc: 0.8929 -- iter: 266/266
--
Training Step: 199  | total loss: [1m[32m0.19805[0m[0m | time: 0.294s
[2K
| Adam | epoch: 023 | loss: 0.19805 - acc: 0.9342 -- iter: 032/266
[A[ATraining Step: 200  | total loss: [1m[32m0.21461[0m[0m | time: 1.622s
[2K
| Adam | epoch: 023 | loss: 0.21461 - acc: 0.9308 | val_loss: 0.30453 - val_acc: 0.8929 -- iter: 064/266
--
Training Step: 201  | total loss: [1m[32m0.21137[0m[0m | time: 2.540s
[2K
| Adam | epoch: 023 | loss: 0.21137 - acc: 0.9277 -- iter: 096/266
[A[ATraining Step: 202  | total loss: [1m[32m0.21100[0m[0m | time: 3.550s
[2K
| Adam | epoch: 023 | loss: 0.21100 - acc: 0.9255 -- iter: 128/266
[A[ATraining Step: 203  | total loss: [1m[32m0.21624[0m[0m | time: 4.539s
[2K
| Adam | epoch: 023 | loss: 0.21624 - acc: 0.9236 -- iter: 160/266
[A[ATraining Step: 204  | total loss: [1m[32m0.22202[0m[0m | time: 5.336s
[2K
| Adam | epoch: 023 | loss: 0.22202 - acc: 0.9250 -- iter: 192/266
[A[ATraining Step: 205  | total loss: [1m[32m0.21588[0m[0m | time: 6.136s
[2K
| Adam | epoch: 023 | loss: 0.21588 - acc: 0.9294 -- iter: 224/266
[A[ATraining Step: 206  | total loss: [1m[32m0.20179[0m[0m | time: 6.982s
[2K
| Adam | epoch: 023 | loss: 0.20179 - acc: 0.9364 -- iter: 256/266
[A[ATraining Step: 207  | total loss: [1m[32m0.20334[0m[0m | time: 8.869s
[2K
| Adam | epoch: 023 | loss: 0.20334 - acc: 0.9334 | val_loss: 0.25390 - val_acc: 0.8810 -- iter: 266/266
--
Training Step: 208  | total loss: [1m[32m0.19057[0m[0m | time: 0.951s
[2K
| Adam | epoch: 024 | loss: 0.19057 - acc: 0.9401 -- iter: 032/266
[A[ATraining Step: 209  | total loss: [1m[32m0.18946[0m[0m | time: 1.270s
[2K
| Adam | epoch: 024 | loss: 0.18946 - acc: 0.9398 -- iter: 064/266
[A[ATraining Step: 210  | total loss: [1m[32m0.17897[0m[0m | time: 1.626s
[2K
| Adam | epoch: 024 | loss: 0.17897 - acc: 0.9458 -- iter: 096/266
[A[ATraining Step: 211  | total loss: [1m[32m0.16712[0m[0m | time: 2.607s
[2K
| Adam | epoch: 024 | loss: 0.16712 - acc: 0.9513 -- iter: 128/266
[A[ATraining Step: 212  | total loss: [1m[32m0.17492[0m[0m | time: 3.584s
[2K
| Adam | epoch: 024 | loss: 0.17492 - acc: 0.9468 -- iter: 160/266
[A[ATraining Step: 213  | total loss: [1m[32m0.16091[0m[0m | time: 4.499s
[2K
| Adam | epoch: 024 | loss: 0.16091 - acc: 0.9521 -- iter: 192/266
[A[ATraining Step: 214  | total loss: [1m[32m0.15209[0m[0m | time: 5.468s
[2K
| Adam | epoch: 024 | loss: 0.15209 - acc: 0.9537 -- iter: 224/266
[A[ATraining Step: 215  | total loss: [1m[32m0.14857[0m[0m | time: 6.431s
[2K
| Adam | epoch: 024 | loss: 0.14857 - acc: 0.9552 -- iter: 256/266
[A[ATraining Step: 216  | total loss: [1m[32m0.15049[0m[0m | time: 8.395s
[2K
| Adam | epoch: 024 | loss: 0.15049 - acc: 0.9566 | val_loss: 0.21089 - val_acc: 0.8929 -- iter: 266/266
--
Training Step: 217  | total loss: [1m[32m0.14641[0m[0m | time: 0.915s
[2K
| Adam | epoch: 025 | loss: 0.14641 - acc: 0.9578 -- iter: 032/266
[A[ATraining Step: 218  | total loss: [1m[32m0.13785[0m[0m | time: 1.853s
[2K
| Adam | epoch: 025 | loss: 0.13785 - acc: 0.9589 -- iter: 064/266
[A[ATraining Step: 219  | total loss: [1m[32m0.13120[0m[0m | time: 2.177s
[2K
| Adam | epoch: 025 | loss: 0.13120 - acc: 0.9599 -- iter: 096/266
[A[ATraining Step: 220  | total loss: [1m[32m0.11951[0m[0m | time: 2.504s
[2K
| Adam | epoch: 025 | loss: 0.11951 - acc: 0.9639 -- iter: 128/266
[A[ATraining Step: 221  | total loss: [1m[32m0.10850[0m[0m | time: 3.447s
[2K
| Adam | epoch: 025 | loss: 0.10850 - acc: 0.9675 -- iter: 160/266
[A[ATraining Step: 222  | total loss: [1m[32m0.10046[0m[0m | time: 4.429s
[2K
| Adam | epoch: 025 | loss: 0.10046 - acc: 0.9708 -- iter: 192/266
[A[ATraining Step: 223  | total loss: [1m[32m0.09708[0m[0m | time: 5.386s
[2K
| Adam | epoch: 025 | loss: 0.09708 - acc: 0.9706 -- iter: 224/266
[A[ATraining Step: 224  | total loss: [1m[32m0.09224[0m[0m | time: 6.307s
[2K
| Adam | epoch: 025 | loss: 0.09224 - acc: 0.9735 -- iter: 256/266
[A[ATraining Step: 225  | total loss: [1m[32m0.08610[0m[0m | time: 8.230s
[2K
| Adam | epoch: 025 | loss: 0.08610 - acc: 0.9762 | val_loss: 0.26759 - val_acc: 0.9048 -- iter: 266/266
--
Training Step: 226  | total loss: [1m[32m0.10084[0m[0m | time: 0.944s
[2K
| Adam | epoch: 026 | loss: 0.10084 - acc: 0.9692 -- iter: 032/266
[A[ATraining Step: 227  | total loss: [1m[32m0.10407[0m[0m | time: 1.864s
[2K
| Adam | epoch: 026 | loss: 0.10407 - acc: 0.9691 -- iter: 064/266
[A[ATraining Step: 228  | total loss: [1m[32m0.12071[0m[0m | time: 2.822s
[2K
| Adam | epoch: 026 | loss: 0.12071 - acc: 0.9660 -- iter: 096/266
[A[ATraining Step: 229  | total loss: [1m[32m0.11746[0m[0m | time: 3.157s
[2K
| Adam | epoch: 026 | loss: 0.11746 - acc: 0.9662 -- iter: 128/266
[A[ATraining Step: 230  | total loss: [1m[32m0.10788[0m[0m | time: 3.508s
[2K
| Adam | epoch: 026 | loss: 0.10788 - acc: 0.9696 -- iter: 160/266
[A[ATraining Step: 231  | total loss: [1m[32m0.09898[0m[0m | time: 4.466s
[2K
| Adam | epoch: 026 | loss: 0.09898 - acc: 0.9727 -- iter: 192/266
[A[ATraining Step: 232  | total loss: [1m[32m0.09673[0m[0m | time: 5.381s
[2K
| Adam | epoch: 026 | loss: 0.09673 - acc: 0.9723 -- iter: 224/266
[A[ATraining Step: 233  | total loss: [1m[32m0.09093[0m[0m | time: 6.316s
[2K
| Adam | epoch: 026 | loss: 0.09093 - acc: 0.9750 -- iter: 256/266
[A[ATraining Step: 234  | total loss: [1m[32m0.08376[0m[0m | time: 8.261s
[2K
| Adam | epoch: 026 | loss: 0.08376 - acc: 0.9775 | val_loss: 0.25767 - val_acc: 0.8929 -- iter: 266/266
--
Training Step: 235  | total loss: [1m[32m0.08863[0m[0m | time: 0.964s
[2K
| Adam | epoch: 027 | loss: 0.08863 - acc: 0.9735 -- iter: 032/266
[A[ATraining Step: 236  | total loss: [1m[32m0.08560[0m[0m | time: 1.935s
[2K
| Adam | epoch: 027 | loss: 0.08560 - acc: 0.9762 -- iter: 064/266
[A[ATraining Step: 237  | total loss: [1m[32m0.08673[0m[0m | time: 2.983s
[2K
| Adam | epoch: 027 | loss: 0.08673 - acc: 0.9754 -- iter: 096/266
[A[ATraining Step: 238  | total loss: [1m[32m0.10392[0m[0m | time: 3.954s
[2K
| Adam | epoch: 027 | loss: 0.10392 - acc: 0.9716 -- iter: 128/266
[A[ATraining Step: 239  | total loss: [1m[32m0.09588[0m[0m | time: 4.275s
[2K
| Adam | epoch: 027 | loss: 0.09588 - acc: 0.9745 -- iter: 160/266
[A[ATraining Step: 240  | total loss: [1m[32m0.08846[0m[0m | time: 4.600s
[2K
| Adam | epoch: 027 | loss: 0.08846 - acc: 0.9770 -- iter: 192/266
[A[ATraining Step: 241  | total loss: [1m[32m0.08136[0m[0m | time: 5.536s
[2K
| Adam | epoch: 027 | loss: 0.08136 - acc: 0.9793 -- iter: 224/266
[A[ATraining Step: 242  | total loss: [1m[32m0.08137[0m[0m | time: 6.493s
[2K
| Adam | epoch: 027 | loss: 0.08137 - acc: 0.9783 -- iter: 256/266
[A[ATraining Step: 243  | total loss: [1m[32m0.08630[0m[0m | time: 8.427s
[2K
| Adam | epoch: 027 | loss: 0.08630 - acc: 0.9773 | val_loss: 0.23106 - val_acc: 0.8929 -- iter: 266/266
--
Training Step: 244  | total loss: [1m[32m0.08659[0m[0m | time: 0.960s
[2K
| Adam | epoch: 028 | loss: 0.08659 - acc: 0.9765 -- iter: 032/266
[A[ATraining Step: 245  | total loss: [1m[32m0.08214[0m[0m | time: 1.906s
[2K
| Adam | epoch: 028 | loss: 0.08214 - acc: 0.9788 -- iter: 064/266
[A[ATraining Step: 246  | total loss: [1m[32m0.07574[0m[0m | time: 2.857s
[2K
| Adam | epoch: 028 | loss: 0.07574 - acc: 0.9809 -- iter: 096/266
[A[ATraining Step: 247  | total loss: [1m[32m0.06906[0m[0m | time: 3.783s
[2K
| Adam | epoch: 028 | loss: 0.06906 - acc: 0.9828 -- iter: 128/266
[A[ATraining Step: 248  | total loss: [1m[32m0.16504[0m[0m | time: 4.760s
[2K
| Adam | epoch: 028 | loss: 0.16504 - acc: 0.9658 -- iter: 160/266
[A[ATraining Step: 249  | total loss: [1m[32m0.15217[0m[0m | time: 5.103s
[2K
| Adam | epoch: 028 | loss: 0.15217 - acc: 0.9692 -- iter: 192/266
[A[ATraining Step: 250  | total loss: [1m[32m0.14575[0m[0m | time: 5.492s
[2K
| Adam | epoch: 028 | loss: 0.14575 - acc: 0.9623 -- iter: 224/266
[A[ATraining Step: 251  | total loss: [1m[32m0.13412[0m[0m | time: 6.448s
[2K
| Adam | epoch: 028 | loss: 0.13412 - acc: 0.9661 -- iter: 256/266
[A[ATraining Step: 252  | total loss: [1m[32m0.12445[0m[0m | time: 8.440s
[2K
| Adam | epoch: 028 | loss: 0.12445 - acc: 0.9695 | val_loss: 0.20228 - val_acc: 0.9048 -- iter: 266/266
--
Training Step: 253  | total loss: [1m[32m0.11430[0m[0m | time: 0.933s
[2K
| Adam | epoch: 029 | loss: 0.11430 - acc: 0.9725 -- iter: 032/266
[A[ATraining Step: 254  | total loss: [1m[32m0.10590[0m[0m | time: 1.845s
[2K
| Adam | epoch: 029 | loss: 0.10590 - acc: 0.9753 -- iter: 064/266
[A[ATraining Step: 255  | total loss: [1m[32m0.09819[0m[0m | time: 2.794s
[2K
| Adam | epoch: 029 | loss: 0.09819 - acc: 0.9777 -- iter: 096/266
[A[ATraining Step: 256  | total loss: [1m[32m0.08985[0m[0m | time: 3.808s
[2K
| Adam | epoch: 029 | loss: 0.08985 - acc: 0.9800 -- iter: 128/266
[A[ATraining Step: 257  | total loss: [1m[32m0.08439[0m[0m | time: 4.759s
[2K
| Adam | epoch: 029 | loss: 0.08439 - acc: 0.9820 -- iter: 160/266
[A[ATraining Step: 258  | total loss: [1m[32m0.07951[0m[0m | time: 5.698s
[2K
| Adam | epoch: 029 | loss: 0.07951 - acc: 0.9838 -- iter: 192/266
[A[ATraining Step: 259  | total loss: [1m[32m0.07434[0m[0m | time: 6.026s
[2K
| Adam | epoch: 029 | loss: 0.07434 - acc: 0.9854 -- iter: 224/266
[A[ATraining Step: 260  | total loss: [1m[32m0.06762[0m[0m | time: 6.377s
[2K
| Adam | epoch: 029 | loss: 0.06762 - acc: 0.9869 -- iter: 256/266
[A[ATraining Step: 261  | total loss: [1m[32m0.06180[0m[0m | time: 8.328s
[2K
| Adam | epoch: 029 | loss: 0.06180 - acc: 0.9882 | val_loss: 0.39503 - val_acc: 0.8810 -- iter: 266/266
--
Training Step: 262  | total loss: [1m[32m0.05829[0m[0m | time: 0.956s
[2K
| Adam | epoch: 030 | loss: 0.05829 - acc: 0.9894 -- iter: 032/266
[A[ATraining Step: 263  | total loss: [1m[32m0.06014[0m[0m | time: 1.963s
[2K
| Adam | epoch: 030 | loss: 0.06014 - acc: 0.9873 -- iter: 064/266
[A[ATraining Step: 264  | total loss: [1m[32m0.05540[0m[0m | time: 2.932s
[2K
| Adam | epoch: 030 | loss: 0.05540 - acc: 0.9886 -- iter: 096/266
[A[ATraining Step: 265  | total loss: [1m[32m0.05154[0m[0m | time: 3.871s
[2K
| Adam | epoch: 030 | loss: 0.05154 - acc: 0.9897 -- iter: 128/266
[A[ATraining Step: 266  | total loss: [1m[32m0.05145[0m[0m | time: 4.827s
[2K
| Adam | epoch: 030 | loss: 0.05145 - acc: 0.9907 -- iter: 160/266
[A[ATraining Step: 267  | total loss: [1m[32m0.04804[0m[0m | time: 5.801s
[2K
| Adam | epoch: 030 | loss: 0.04804 - acc: 0.9917 -- iter: 192/266
[A[ATraining Step: 268  | total loss: [1m[32m0.04597[0m[0m | time: 6.786s
[2K
| Adam | epoch: 030 | loss: 0.04597 - acc: 0.9925 -- iter: 224/266
[A[ATraining Step: 269  | total loss: [1m[32m0.04405[0m[0m | time: 7.144s
[2K
| Adam | epoch: 030 | loss: 0.04405 - acc: 0.9932 -- iter: 256/266
[A[ATraining Step: 270  | total loss: [1m[32m0.04069[0m[0m | time: 8.491s
[2K
| Adam | epoch: 030 | loss: 0.04069 - acc: 0.9939 | val_loss: 0.34775 - val_acc: 0.8810 -- iter: 266/266
--
Validation AUC:0.9749287749287749
Validation AUPRC:0.9802369805427565
Test AUC:0.983529411764706
Test AUPRC:0.9800157225790668
BestTestF1Score	0.84	0.73	0.86	0.76	0.94	32	10	40	2	0.05
BestTestMCCScore	0.94	0.9	0.95	0.94	0.94	32	2	48	2	0.37
BestTestAccuracyScore	0.94	0.9	0.95	0.94	0.94	32	2	48	2	0.37
BestValidationF1Score	0.91	0.81	0.9	0.91	0.91	41	4	35	4	0.05
BestValidationMCC	0.9	0.82	0.9	0.97	0.84	38	1	38	7	0.37
BestValidationAccuracy	0.9	0.82	0.9	0.97	0.84	38	1	38	7	0.37
TestPredictions (Threshold:0.37)
CHEMBL3660790,TP,ACT,0.9599999785423279	CHEMBL15887,TN,INACT,0.009999999776482582	CHEMBL209511,TN,INACT,0.0	CHEMBL3085971,TP,ACT,0.9900000095367432	CHEMBL1242468,TN,INACT,0.11999999731779099	CHEMBL141238,TN,INACT,0.0	CHEMBL3674561,TP,ACT,0.9900000095367432	CHEMBL3133826,FP,INACT,0.9100000262260437	CHEMBL2029690,TN,INACT,0.009999999776482582	CHEMBL1683957,TN,INACT,0.0	CHEMBL1828884,TN,INACT,0.009999999776482582	CHEMBL1242845,TN,INACT,0.0	CHEMBL201865,TN,INACT,0.03999999910593033	CHEMBL451575,TP,ACT,1.0	CHEMBL3085832,TP,ACT,0.9900000095367432	CHEMBL267118,TN,INACT,0.0	CHEMBL27085,TN,INACT,0.0	CHEMBL1172947,TN,INACT,0.0	CHEMBL55360,TN,INACT,0.0	CHEMBL414001,FN,ACT,0.019999999552965164	CHEMBL3660763,TP,ACT,1.0	CHEMBL1828883,TN,INACT,0.009999999776482582	CHEMBL3745929,TN,INACT,0.23000000417232513	CHEMBL291986,TN,INACT,0.0	CHEMBL1276308,TN,INACT,0.20000000298023224	CHEMBL3660772,TP,ACT,1.0	CHEMBL590083,TN,INACT,0.11999999731779099	CHEMBL3660759,TP,ACT,0.7400000095367432	CHEMBL3660787,TP,ACT,0.8600000143051147	CHEMBL3660755,TP,ACT,1.0	CHEMBL2037209,TP,ACT,0.7799999713897705	CHEMBL1095445,TN,INACT,0.0	CHEMBL3660791,TP,ACT,0.9300000071525574	CHEMBL3674574,TP,ACT,1.0	CHEMBL3660786,TP,ACT,0.9900000095367432	CHEMBL1077069,TN,INACT,0.18000000715255737	CHEMBL324439,TN,INACT,0.0	CHEMBL282575,TN,INACT,0.0	CHEMBL1161236,FP,INACT,0.8100000023841858	CHEMBL336330,TN,INACT,0.009999999776482582	CHEMBL3085984,TP,ACT,0.9900000095367432	CHEMBL3085830,TP,ACT,1.0	CHEMBL14326,TN,INACT,0.009999999776482582	CHEMBL602471,TN,INACT,0.009999999776482582	CHEMBL1221822,TN,INACT,0.0	CHEMBL440213,TN,INACT,0.25999999046325684	CHEMBL1241390,TN,INACT,0.009999999776482582	CHEMBL113996,TN,INACT,0.009999999776482582	CHEMBL3643701,TP,ACT,1.0	CHEMBL1738705,TN,INACT,0.009999999776482582	CHEMBL3098319,TN,INACT,0.0	CHEMBL55993,TN,INACT,0.0	CHEMBL3628818,TN,INACT,0.009999999776482582	CHEMBL3674580,TP,ACT,1.0	CHEMBL86771,TN,INACT,0.0	CHEMBL3660768,TP,ACT,1.0	CHEMBL492809,TP,ACT,1.0	CHEMBL3086177,TP,ACT,1.0	CHEMBL1944928,TN,INACT,0.019999999552965164	CHEMBL3086320,TP,ACT,0.8899999856948853	CHEMBL1080271,TN,INACT,0.07000000029802322	CHEMBL71884,TN,INACT,0.0	CHEMBL113690,TN,INACT,0.009999999776482582	CHEMBL315701,TN,INACT,0.0	CHEMBL90277,TN,INACT,0.0	CHEMBL3674560,TP,ACT,1.0	CHEMBL314021,TN,INACT,0.009999999776482582	CHEMBL3086178,TP,ACT,1.0	CHEMBL1683951,TN,INACT,0.0	CHEMBL428647,TN,INACT,0.0	CHEMBL293986,TN,INACT,0.0	CHEMBL2158297,TP,ACT,0.9900000095367432	CHEMBL1241300,TN,INACT,0.0	CHEMBL3660757,TP,ACT,0.9800000190734863	CHEMBL448117,TP,ACT,1.0	CHEMBL3660775,TP,ACT,0.9900000095367432	CHEMBL3674576,TP,ACT,1.0	CHEMBL2158299,TP,ACT,1.0	CHEMBL104,TN,INACT,0.0	CHEMBL592224,TN,INACT,0.009999999776482582	CHEMBL3660784,TP,ACT,0.9399999976158142	CHEMBL3085972,TP,ACT,0.9599999785423279	CHEMBL491078,FN,ACT,0.019999999552965164	CHEMBL2426377,TN,INACT,0.28999999165534973	

