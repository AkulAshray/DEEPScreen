CNNModel CHEMBL2274 adam 0.001 30 256 0 0.8 False True
Number of active compounds :	193
Number of inactive compounds :	193
---------------------------------
Run id: CNNModel_CHEMBL2274_adam_0.001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2274_adam_0.001_30_256_0.8_True/
---------------------------------
Training samples: 240
Validation samples: 76
--
Training Step: 1  | time: 1.027s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/240
[A[ATraining Step: 2  | total loss: [1m[32m0.62393[0m[0m | time: 1.959s
[2K
| Adam | epoch: 001 | loss: 0.62393 - acc: 0.3937 -- iter: 064/240
[A[ATraining Step: 3  | total loss: [1m[32m0.67903[0m[0m | time: 2.846s
[2K
| Adam | epoch: 001 | loss: 0.67903 - acc: 0.5574 -- iter: 096/240
[A[ATraining Step: 4  | total loss: [1m[32m0.69218[0m[0m | time: 3.699s
[2K
| Adam | epoch: 001 | loss: 0.69218 - acc: 0.4909 -- iter: 128/240
[A[ATraining Step: 5  | total loss: [1m[32m0.68518[0m[0m | time: 4.540s
[2K
| Adam | epoch: 001 | loss: 0.68518 - acc: 0.5621 -- iter: 160/240
[A[ATraining Step: 6  | total loss: [1m[32m0.67827[0m[0m | time: 5.414s
[2K
| Adam | epoch: 001 | loss: 0.67827 - acc: 0.5824 -- iter: 192/240
[A[ATraining Step: 7  | total loss: [1m[32m0.70126[0m[0m | time: 6.344s
[2K
| Adam | epoch: 001 | loss: 0.70126 - acc: 0.5330 -- iter: 224/240
[A[ATraining Step: 8  | total loss: [1m[32m0.68285[0m[0m | time: 7.930s
[2K
| Adam | epoch: 001 | loss: 0.68285 - acc: 0.5672 | val_loss: 0.71191 - val_acc: 0.4474 -- iter: 240/240
--
Training Step: 9  | total loss: [1m[32m0.66818[0m[0m | time: 0.463s
[2K
| Adam | epoch: 002 | loss: 0.66818 - acc: 0.5978 -- iter: 032/240
[A[ATraining Step: 10  | total loss: [1m[32m0.65968[0m[0m | time: 1.220s
[2K
| Adam | epoch: 002 | loss: 0.65968 - acc: 0.6114 -- iter: 064/240
[A[ATraining Step: 11  | total loss: [1m[32m0.67432[0m[0m | time: 2.067s
[2K
| Adam | epoch: 002 | loss: 0.67432 - acc: 0.5586 -- iter: 096/240
[A[ATraining Step: 12  | total loss: [1m[32m0.70247[0m[0m | time: 2.909s
[2K
| Adam | epoch: 002 | loss: 0.70247 - acc: 0.5041 -- iter: 128/240
[A[ATraining Step: 13  | total loss: [1m[32m0.68040[0m[0m | time: 3.759s
[2K
| Adam | epoch: 002 | loss: 0.68040 - acc: 0.5693 -- iter: 160/240
[A[ATraining Step: 14  | total loss: [1m[32m0.66946[0m[0m | time: 4.593s
[2K
| Adam | epoch: 002 | loss: 0.66946 - acc: 0.5793 -- iter: 192/240
[A[ATraining Step: 15  | total loss: [1m[32m0.67385[0m[0m | time: 5.516s
[2K
| Adam | epoch: 002 | loss: 0.67385 - acc: 0.5360 -- iter: 224/240
[A[ATraining Step: 16  | total loss: [1m[32m0.67397[0m[0m | time: 7.408s
[2K
| Adam | epoch: 002 | loss: 0.67397 - acc: 0.5225 | val_loss: 0.67825 - val_acc: 0.4474 -- iter: 240/240
--
Training Step: 17  | total loss: [1m[32m0.68845[0m[0m | time: 0.327s
[2K
| Adam | epoch: 003 | loss: 0.68845 - acc: 0.4469 -- iter: 032/240
[A[ATraining Step: 18  | total loss: [1m[32m0.68208[0m[0m | time: 0.740s
[2K
| Adam | epoch: 003 | loss: 0.68208 - acc: 0.4653 -- iter: 064/240
[A[ATraining Step: 19  | total loss: [1m[32m0.67707[0m[0m | time: 1.557s
[2K
| Adam | epoch: 003 | loss: 0.67707 - acc: 0.4769 -- iter: 096/240
[A[ATraining Step: 20  | total loss: [1m[32m0.66220[0m[0m | time: 2.457s
[2K
| Adam | epoch: 003 | loss: 0.66220 - acc: 0.5446 -- iter: 128/240
[A[ATraining Step: 21  | total loss: [1m[32m0.64983[0m[0m | time: 3.282s
[2K
| Adam | epoch: 003 | loss: 0.64983 - acc: 0.5404 -- iter: 160/240
[A[ATraining Step: 22  | total loss: [1m[32m0.63701[0m[0m | time: 4.119s
[2K
| Adam | epoch: 003 | loss: 0.63701 - acc: 0.5471 -- iter: 192/240
[A[ATraining Step: 23  | total loss: [1m[32m0.64082[0m[0m | time: 4.969s
[2K
| Adam | epoch: 003 | loss: 0.64082 - acc: 0.5334 -- iter: 224/240
[A[ATraining Step: 24  | total loss: [1m[32m0.63089[0m[0m | time: 6.892s
[2K
| Adam | epoch: 003 | loss: 0.63089 - acc: 0.5064 | val_loss: 0.60007 - val_acc: 0.8553 -- iter: 240/240
--
Training Step: 25  | total loss: [1m[32m0.62044[0m[0m | time: 0.882s
[2K
| Adam | epoch: 004 | loss: 0.62044 - acc: 0.5729 -- iter: 032/240
[A[ATraining Step: 26  | total loss: [1m[32m0.61177[0m[0m | time: 1.347s
[2K
| Adam | epoch: 004 | loss: 0.61177 - acc: 0.6528 -- iter: 064/240
[A[ATraining Step: 27  | total loss: [1m[32m0.59326[0m[0m | time: 1.838s
[2K
| Adam | epoch: 004 | loss: 0.59326 - acc: 0.6778 -- iter: 096/240
[A[ATraining Step: 28  | total loss: [1m[32m0.57210[0m[0m | time: 2.738s
[2K
| Adam | epoch: 004 | loss: 0.57210 - acc: 0.7115 -- iter: 128/240
[A[ATraining Step: 29  | total loss: [1m[32m0.55552[0m[0m | time: 3.644s
[2K
| Adam | epoch: 004 | loss: 0.55552 - acc: 0.7361 -- iter: 160/240
[A[ATraining Step: 30  | total loss: [1m[32m0.51094[0m[0m | time: 4.572s
[2K
| Adam | epoch: 004 | loss: 0.51094 - acc: 0.7690 -- iter: 192/240
[A[ATraining Step: 31  | total loss: [1m[32m0.49155[0m[0m | time: 5.482s
[2K
| Adam | epoch: 004 | loss: 0.49155 - acc: 0.7718 -- iter: 224/240
[A[ATraining Step: 32  | total loss: [1m[32m0.52692[0m[0m | time: 7.307s
[2K
| Adam | epoch: 004 | loss: 0.52692 - acc: 0.7810 | val_loss: 0.35754 - val_acc: 0.8816 -- iter: 240/240
--
Training Step: 33  | total loss: [1m[32m0.48800[0m[0m | time: 0.885s
[2K
| Adam | epoch: 005 | loss: 0.48800 - acc: 0.7947 -- iter: 032/240
[A[ATraining Step: 34  | total loss: [1m[32m0.46727[0m[0m | time: 1.744s
[2K
| Adam | epoch: 005 | loss: 0.46727 - acc: 0.8052 -- iter: 064/240
[A[ATraining Step: 35  | total loss: [1m[32m0.43267[0m[0m | time: 2.204s
[2K
| Adam | epoch: 005 | loss: 0.43267 - acc: 0.8198 -- iter: 096/240
[A[ATraining Step: 36  | total loss: [1m[32m0.39340[0m[0m | time: 2.662s
[2K
| Adam | epoch: 005 | loss: 0.39340 - acc: 0.8183 -- iter: 128/240
[A[ATraining Step: 37  | total loss: [1m[32m0.34831[0m[0m | time: 3.561s
[2K
| Adam | epoch: 005 | loss: 0.34831 - acc: 0.8422 -- iter: 160/240
[A[ATraining Step: 38  | total loss: [1m[32m0.34475[0m[0m | time: 4.449s
[2K
| Adam | epoch: 005 | loss: 0.34475 - acc: 0.8425 -- iter: 192/240
[A[ATraining Step: 39  | total loss: [1m[32m0.36146[0m[0m | time: 5.318s
[2K
| Adam | epoch: 005 | loss: 0.36146 - acc: 0.8308 -- iter: 224/240
[A[ATraining Step: 40  | total loss: [1m[32m0.36955[0m[0m | time: 7.312s
[2K
| Adam | epoch: 005 | loss: 0.36955 - acc: 0.8332 | val_loss: 0.44469 - val_acc: 0.8026 -- iter: 240/240
--
Training Step: 41  | total loss: [1m[32m0.38948[0m[0m | time: 0.837s
[2K
| Adam | epoch: 006 | loss: 0.38948 - acc: 0.8351 -- iter: 032/240
[A[ATraining Step: 42  | total loss: [1m[32m0.39203[0m[0m | time: 1.780s
[2K
| Adam | epoch: 006 | loss: 0.39203 - acc: 0.8311 -- iter: 064/240
[A[ATraining Step: 43  | total loss: [1m[32m0.36744[0m[0m | time: 2.640s
[2K
| Adam | epoch: 006 | loss: 0.36744 - acc: 0.8443 -- iter: 096/240
[A[ATraining Step: 44  | total loss: [1m[32m0.34332[0m[0m | time: 3.093s
[2K
| Adam | epoch: 006 | loss: 0.34332 - acc: 0.8496 -- iter: 128/240
[A[ATraining Step: 45  | total loss: [1m[32m0.30849[0m[0m | time: 3.557s
[2K
| Adam | epoch: 006 | loss: 0.30849 - acc: 0.8752 -- iter: 160/240
[A[ATraining Step: 46  | total loss: [1m[32m0.27768[0m[0m | time: 4.481s
[2K
| Adam | epoch: 006 | loss: 0.27768 - acc: 0.8960 -- iter: 192/240
[A[ATraining Step: 47  | total loss: [1m[32m0.27429[0m[0m | time: 5.373s
[2K
| Adam | epoch: 006 | loss: 0.27429 - acc: 0.8925 -- iter: 224/240
[A[ATraining Step: 48  | total loss: [1m[32m0.27337[0m[0m | time: 7.230s
[2K
| Adam | epoch: 006 | loss: 0.27337 - acc: 0.8998 | val_loss: 0.48676 - val_acc: 0.7763 -- iter: 240/240
--
Training Step: 49  | total loss: [1m[32m0.27312[0m[0m | time: 0.834s
[2K
| Adam | epoch: 007 | loss: 0.27312 - acc: 0.9008 -- iter: 032/240
[A[ATraining Step: 50  | total loss: [1m[32m0.28294[0m[0m | time: 1.727s
[2K
| Adam | epoch: 007 | loss: 0.28294 - acc: 0.8871 -- iter: 064/240
[A[ATraining Step: 51  | total loss: [1m[32m0.27477[0m[0m | time: 2.538s
[2K
| Adam | epoch: 007 | loss: 0.27477 - acc: 0.8948 -- iter: 096/240
[A[ATraining Step: 52  | total loss: [1m[32m0.26187[0m[0m | time: 3.390s
[2K
| Adam | epoch: 007 | loss: 0.26187 - acc: 0.8965 -- iter: 128/240
[A[ATraining Step: 53  | total loss: [1m[32m0.25096[0m[0m | time: 3.842s
[2K
| Adam | epoch: 007 | loss: 0.25096 - acc: 0.9025 -- iter: 160/240
[A[ATraining Step: 54  | total loss: [1m[32m0.23388[0m[0m | time: 4.351s
[2K
| Adam | epoch: 007 | loss: 0.23388 - acc: 0.9076 -- iter: 192/240
[A[ATraining Step: 55  | total loss: [1m[32m0.21085[0m[0m | time: 5.256s
[2K
| Adam | epoch: 007 | loss: 0.21085 - acc: 0.9208 -- iter: 224/240
[A[ATraining Step: 56  | total loss: [1m[32m0.22730[0m[0m | time: 7.214s
[2K
| Adam | epoch: 007 | loss: 0.22730 - acc: 0.9100 | val_loss: 0.32909 - val_acc: 0.8421 -- iter: 240/240
--
Training Step: 57  | total loss: [1m[32m0.27611[0m[0m | time: 0.842s
[2K
| Adam | epoch: 008 | loss: 0.27611 - acc: 0.8878 -- iter: 032/240
[A[ATraining Step: 58  | total loss: [1m[32m0.26501[0m[0m | time: 1.639s
[2K
| Adam | epoch: 008 | loss: 0.26501 - acc: 0.8903 -- iter: 064/240
[A[ATraining Step: 59  | total loss: [1m[32m0.25870[0m[0m | time: 2.477s
[2K
| Adam | epoch: 008 | loss: 0.25870 - acc: 0.8883 -- iter: 096/240
[A[ATraining Step: 60  | total loss: [1m[32m0.24567[0m[0m | time: 3.360s
[2K
| Adam | epoch: 008 | loss: 0.24567 - acc: 0.8948 -- iter: 128/240
[A[ATraining Step: 61  | total loss: [1m[32m0.24033[0m[0m | time: 4.199s
[2K
| Adam | epoch: 008 | loss: 0.24033 - acc: 0.9004 -- iter: 160/240
[A[ATraining Step: 62  | total loss: [1m[32m0.22862[0m[0m | time: 4.674s
[2K
| Adam | epoch: 008 | loss: 0.22862 - acc: 0.9051 -- iter: 192/240
[A[ATraining Step: 63  | total loss: [1m[32m0.21671[0m[0m | time: 5.127s
[2K
| Adam | epoch: 008 | loss: 0.21671 - acc: 0.9092 -- iter: 224/240
[A[ATraining Step: 64  | total loss: [1m[32m0.20407[0m[0m | time: 7.052s
[2K
| Adam | epoch: 008 | loss: 0.20407 - acc: 0.9128 | val_loss: 0.33509 - val_acc: 0.8684 -- iter: 240/240
--
Training Step: 65  | total loss: [1m[32m0.20924[0m[0m | time: 1.038s
[2K
| Adam | epoch: 009 | loss: 0.20924 - acc: 0.9158 -- iter: 032/240
[A[ATraining Step: 66  | total loss: [1m[32m0.22671[0m[0m | time: 1.784s
[2K
| Adam | epoch: 009 | loss: 0.22671 - acc: 0.9071 -- iter: 064/240
[A[ATraining Step: 67  | total loss: [1m[32m0.21206[0m[0m | time: 2.641s
[2K
| Adam | epoch: 009 | loss: 0.21206 - acc: 0.9145 -- iter: 096/240
[A[ATraining Step: 68  | total loss: [1m[32m0.24421[0m[0m | time: 3.487s
[2K
| Adam | epoch: 009 | loss: 0.24421 - acc: 0.8987 -- iter: 128/240
[A[ATraining Step: 69  | total loss: [1m[32m0.23593[0m[0m | time: 4.354s
[2K
| Adam | epoch: 009 | loss: 0.23593 - acc: 0.8996 -- iter: 160/240
[A[ATraining Step: 70  | total loss: [1m[32m0.22781[0m[0m | time: 5.204s
[2K
| Adam | epoch: 009 | loss: 0.22781 - acc: 0.9076 -- iter: 192/240
[A[ATraining Step: 71  | total loss: [1m[32m0.22052[0m[0m | time: 5.693s
[2K
| Adam | epoch: 009 | loss: 0.22052 - acc: 0.9074 -- iter: 224/240
[A[ATraining Step: 72  | total loss: [1m[32m0.22102[0m[0m | time: 7.244s
[2K
| Adam | epoch: 009 | loss: 0.22102 - acc: 0.9038 | val_loss: 0.24832 - val_acc: 0.9211 -- iter: 240/240
--
Training Step: 73  | total loss: [1m[32m0.21115[0m[0m | time: 0.845s
[2K
| Adam | epoch: 010 | loss: 0.21115 - acc: 0.9075 -- iter: 032/240
[A[ATraining Step: 74  | total loss: [1m[32m0.19604[0m[0m | time: 1.683s
[2K
| Adam | epoch: 010 | loss: 0.19604 - acc: 0.9177 -- iter: 064/240
[A[ATraining Step: 75  | total loss: [1m[32m0.20255[0m[0m | time: 2.541s
[2K
| Adam | epoch: 010 | loss: 0.20255 - acc: 0.9130 -- iter: 096/240
[A[ATraining Step: 76  | total loss: [1m[32m0.20680[0m[0m | time: 3.468s
[2K
| Adam | epoch: 010 | loss: 0.20680 - acc: 0.9123 -- iter: 128/240
[A[ATraining Step: 77  | total loss: [1m[32m0.20114[0m[0m | time: 4.331s
[2K
| Adam | epoch: 010 | loss: 0.20114 - acc: 0.9150 -- iter: 160/240
[A[ATraining Step: 78  | total loss: [1m[32m0.18890[0m[0m | time: 5.217s
[2K
| Adam | epoch: 010 | loss: 0.18890 - acc: 0.9173 -- iter: 192/240
[A[ATraining Step: 79  | total loss: [1m[32m0.18885[0m[0m | time: 6.035s
[2K
| Adam | epoch: 010 | loss: 0.18885 - acc: 0.9194 -- iter: 224/240
[A[ATraining Step: 80  | total loss: [1m[32m0.17392[0m[0m | time: 7.607s
[2K
| Adam | epoch: 010 | loss: 0.17392 - acc: 0.9245 | val_loss: 0.22690 - val_acc: 0.9079 -- iter: 240/240
--
Training Step: 81  | total loss: [1m[32m0.17523[0m[0m | time: 0.512s
[2K
| Adam | epoch: 011 | loss: 0.17523 - acc: 0.9195 -- iter: 032/240
[A[ATraining Step: 82  | total loss: [1m[32m0.16213[0m[0m | time: 1.372s
[2K
| Adam | epoch: 011 | loss: 0.16213 - acc: 0.9275 -- iter: 064/240
[A[ATraining Step: 83  | total loss: [1m[32m0.15101[0m[0m | time: 2.283s
[2K
| Adam | epoch: 011 | loss: 0.15101 - acc: 0.9348 -- iter: 096/240
[A[ATraining Step: 84  | total loss: [1m[32m0.16130[0m[0m | time: 3.205s
[2K
| Adam | epoch: 011 | loss: 0.16130 - acc: 0.9319 -- iter: 128/240
[A[ATraining Step: 85  | total loss: [1m[32m0.17929[0m[0m | time: 4.084s
[2K
| Adam | epoch: 011 | loss: 0.17929 - acc: 0.9293 -- iter: 160/240
[A[ATraining Step: 86  | total loss: [1m[32m0.17081[0m[0m | time: 4.910s
[2K
| Adam | epoch: 011 | loss: 0.17081 - acc: 0.9302 -- iter: 192/240
[A[ATraining Step: 87  | total loss: [1m[32m0.15780[0m[0m | time: 5.873s
[2K
| Adam | epoch: 011 | loss: 0.15780 - acc: 0.9340 -- iter: 224/240
[A[ATraining Step: 88  | total loss: [1m[32m0.15874[0m[0m | time: 7.893s
[2K
| Adam | epoch: 011 | loss: 0.15874 - acc: 0.9281 | val_loss: 0.38685 - val_acc: 0.8421 -- iter: 240/240
--
Training Step: 89  | total loss: [1m[32m0.17596[0m[0m | time: 0.510s
[2K
| Adam | epoch: 012 | loss: 0.17596 - acc: 0.9197 -- iter: 032/240
[A[ATraining Step: 90  | total loss: [1m[32m0.16794[0m[0m | time: 0.983s
[2K
| Adam | epoch: 012 | loss: 0.16794 - acc: 0.9215 -- iter: 064/240
[A[ATraining Step: 91  | total loss: [1m[32m0.16060[0m[0m | time: 1.855s
[2K
| Adam | epoch: 012 | loss: 0.16060 - acc: 0.9231 -- iter: 096/240
[A[ATraining Step: 92  | total loss: [1m[32m0.17272[0m[0m | time: 2.634s
[2K
| Adam | epoch: 012 | loss: 0.17272 - acc: 0.9214 -- iter: 128/240
[A[ATraining Step: 93  | total loss: [1m[32m0.16237[0m[0m | time: 3.661s
[2K
| Adam | epoch: 012 | loss: 0.16237 - acc: 0.9261 -- iter: 160/240
[A[ATraining Step: 94  | total loss: [1m[32m0.15287[0m[0m | time: 4.704s
[2K
| Adam | epoch: 012 | loss: 0.15287 - acc: 0.9335 -- iter: 192/240
[A[ATraining Step: 95  | total loss: [1m[32m0.14131[0m[0m | time: 5.597s
[2K
| Adam | epoch: 012 | loss: 0.14131 - acc: 0.9402 -- iter: 224/240
[A[ATraining Step: 96  | total loss: [1m[32m0.13995[0m[0m | time: 7.409s
[2K
| Adam | epoch: 012 | loss: 0.13995 - acc: 0.9430 | val_loss: 0.24402 - val_acc: 0.9079 -- iter: 240/240
--
Training Step: 97  | total loss: [1m[32m0.14213[0m[0m | time: 0.834s
[2K
| Adam | epoch: 013 | loss: 0.14213 - acc: 0.9425 -- iter: 032/240
[A[ATraining Step: 98  | total loss: [1m[32m0.14703[0m[0m | time: 1.273s
[2K
| Adam | epoch: 013 | loss: 0.14703 - acc: 0.9420 -- iter: 064/240
[A[ATraining Step: 99  | total loss: [1m[32m0.14167[0m[0m | time: 1.823s
[2K
| Adam | epoch: 013 | loss: 0.14167 - acc: 0.9415 -- iter: 096/240
[A[ATraining Step: 100  | total loss: [1m[32m0.13395[0m[0m | time: 2.871s
[2K
| Adam | epoch: 013 | loss: 0.13395 - acc: 0.9474 -- iter: 128/240
[A[ATraining Step: 101  | total loss: [1m[32m0.13147[0m[0m | time: 3.892s
[2K
| Adam | epoch: 013 | loss: 0.13147 - acc: 0.9464 -- iter: 160/240
[A[ATraining Step: 102  | total loss: [1m[32m0.12171[0m[0m | time: 4.615s
[2K
| Adam | epoch: 013 | loss: 0.12171 - acc: 0.9517 -- iter: 192/240
[A[ATraining Step: 103  | total loss: [1m[32m0.15488[0m[0m | time: 5.419s
[2K
| Adam | epoch: 013 | loss: 0.15488 - acc: 0.9472 -- iter: 224/240
[A[ATraining Step: 104  | total loss: [1m[32m0.14743[0m[0m | time: 7.250s
[2K
| Adam | epoch: 013 | loss: 0.14743 - acc: 0.9494 | val_loss: 0.21169 - val_acc: 0.9211 -- iter: 240/240
--
Training Step: 105  | total loss: [1m[32m0.13583[0m[0m | time: 0.801s
[2K
| Adam | epoch: 014 | loss: 0.13583 - acc: 0.9544 -- iter: 032/240
[A[ATraining Step: 106  | total loss: [1m[32m0.12615[0m[0m | time: 1.863s
[2K
| Adam | epoch: 014 | loss: 0.12615 - acc: 0.9590 -- iter: 064/240
[A[ATraining Step: 107  | total loss: [1m[32m0.12287[0m[0m | time: 2.387s
[2K
| Adam | epoch: 014 | loss: 0.12287 - acc: 0.9600 -- iter: 096/240
[A[ATraining Step: 108  | total loss: [1m[32m0.13111[0m[0m | time: 2.910s
[2K
| Adam | epoch: 014 | loss: 0.13111 - acc: 0.9515 -- iter: 128/240
[A[ATraining Step: 109  | total loss: [1m[32m0.12775[0m[0m | time: 3.640s
[2K
| Adam | epoch: 014 | loss: 0.12775 - acc: 0.9563 -- iter: 160/240
[A[ATraining Step: 110  | total loss: [1m[32m0.11728[0m[0m | time: 4.490s
[2K
| Adam | epoch: 014 | loss: 0.11728 - acc: 0.9607 -- iter: 192/240
[A[ATraining Step: 111  | total loss: [1m[32m0.11415[0m[0m | time: 5.367s
[2K
| Adam | epoch: 014 | loss: 0.11415 - acc: 0.9615 -- iter: 224/240
[A[ATraining Step: 112  | total loss: [1m[32m0.13866[0m[0m | time: 7.222s
[2K
| Adam | epoch: 014 | loss: 0.13866 - acc: 0.9528 | val_loss: 0.22297 - val_acc: 0.9079 -- iter: 240/240
--
Training Step: 113  | total loss: [1m[32m0.13008[0m[0m | time: 1.037s
[2K
| Adam | epoch: 015 | loss: 0.13008 - acc: 0.9544 -- iter: 032/240
[A[ATraining Step: 114  | total loss: [1m[32m0.11880[0m[0m | time: 2.007s
[2K
| Adam | epoch: 015 | loss: 0.11880 - acc: 0.9590 -- iter: 064/240
[A[ATraining Step: 115  | total loss: [1m[32m0.11216[0m[0m | time: 2.824s
[2K
| Adam | epoch: 015 | loss: 0.11216 - acc: 0.9600 -- iter: 096/240
[A[ATraining Step: 116  | total loss: [1m[32m0.10820[0m[0m | time: 3.220s
[2K
| Adam | epoch: 015 | loss: 0.10820 - acc: 0.9608 -- iter: 128/240
[A[ATraining Step: 117  | total loss: [1m[32m0.10035[0m[0m | time: 3.662s
[2K
| Adam | epoch: 015 | loss: 0.10035 - acc: 0.9648 -- iter: 160/240
[A[ATraining Step: 118  | total loss: [1m[32m0.09222[0m[0m | time: 4.500s
[2K
| Adam | epoch: 015 | loss: 0.09222 - acc: 0.9683 -- iter: 192/240
[A[ATraining Step: 119  | total loss: [1m[32m0.08552[0m[0m | time: 5.381s
[2K
| Adam | epoch: 015 | loss: 0.08552 - acc: 0.9715 -- iter: 224/240
[A[ATraining Step: 120  | total loss: [1m[32m0.07832[0m[0m | time: 7.242s
[2K
| Adam | epoch: 015 | loss: 0.07832 - acc: 0.9743 | val_loss: 0.24264 - val_acc: 0.9342 -- iter: 240/240
--
Training Step: 121  | total loss: [1m[32m0.08877[0m[0m | time: 0.832s
[2K
| Adam | epoch: 016 | loss: 0.08877 - acc: 0.9738 -- iter: 032/240
[A[ATraining Step: 122  | total loss: [1m[32m0.08205[0m[0m | time: 1.728s
[2K
| Adam | epoch: 016 | loss: 0.08205 - acc: 0.9764 -- iter: 064/240
[A[ATraining Step: 123  | total loss: [1m[32m0.08353[0m[0m | time: 2.573s
[2K
| Adam | epoch: 016 | loss: 0.08353 - acc: 0.9756 -- iter: 096/240
[A[ATraining Step: 124  | total loss: [1m[32m0.07666[0m[0m | time: 3.409s
[2K
| Adam | epoch: 016 | loss: 0.07666 - acc: 0.9781 -- iter: 128/240
[A[ATraining Step: 125  | total loss: [1m[32m0.06978[0m[0m | time: 3.864s
[2K
| Adam | epoch: 016 | loss: 0.06978 - acc: 0.9802 -- iter: 160/240
[A[ATraining Step: 126  | total loss: [1m[32m0.06314[0m[0m | time: 4.303s
[2K
| Adam | epoch: 016 | loss: 0.06314 - acc: 0.9822 -- iter: 192/240
[A[ATraining Step: 127  | total loss: [1m[32m0.05723[0m[0m | time: 5.249s
[2K
| Adam | epoch: 016 | loss: 0.05723 - acc: 0.9840 -- iter: 224/240
[A[ATraining Step: 128  | total loss: [1m[32m0.05233[0m[0m | time: 7.085s
[2K
| Adam | epoch: 016 | loss: 0.05233 - acc: 0.9856 | val_loss: 0.27687 - val_acc: 0.9474 -- iter: 240/240
--
Training Step: 129  | total loss: [1m[32m0.05567[0m[0m | time: 0.948s
[2K
| Adam | epoch: 017 | loss: 0.05567 - acc: 0.9839 -- iter: 032/240
[A[ATraining Step: 130  | total loss: [1m[32m0.07765[0m[0m | time: 1.861s
[2K
| Adam | epoch: 017 | loss: 0.07765 - acc: 0.9793 -- iter: 064/240
[A[ATraining Step: 131  | total loss: [1m[32m0.07025[0m[0m | time: 2.720s
[2K
| Adam | epoch: 017 | loss: 0.07025 - acc: 0.9813 -- iter: 096/240
[A[ATraining Step: 132  | total loss: [1m[32m0.06466[0m[0m | time: 3.711s
[2K
| Adam | epoch: 017 | loss: 0.06466 - acc: 0.9832 -- iter: 128/240
[A[ATraining Step: 133  | total loss: [1m[32m0.06728[0m[0m | time: 4.767s
[2K
| Adam | epoch: 017 | loss: 0.06728 - acc: 0.9818 -- iter: 160/240
[A[ATraining Step: 134  | total loss: [1m[32m0.06394[0m[0m | time: 5.273s
[2K
| Adam | epoch: 017 | loss: 0.06394 - acc: 0.9836 -- iter: 192/240
[A[ATraining Step: 135  | total loss: [1m[32m0.05888[0m[0m | time: 5.635s
[2K
| Adam | epoch: 017 | loss: 0.05888 - acc: 0.9852 -- iter: 224/240
[A[ATraining Step: 136  | total loss: [1m[32m0.05352[0m[0m | time: 7.445s
[2K
| Adam | epoch: 017 | loss: 0.05352 - acc: 0.9867 | val_loss: 0.28368 - val_acc: 0.9079 -- iter: 240/240
--
Training Step: 137  | total loss: [1m[32m0.04923[0m[0m | time: 0.939s
[2K
| Adam | epoch: 018 | loss: 0.04923 - acc: 0.9880 -- iter: 032/240
[A[ATraining Step: 138  | total loss: [1m[32m0.05086[0m[0m | time: 1.737s
[2K
| Adam | epoch: 018 | loss: 0.05086 - acc: 0.9830 -- iter: 064/240
[A[ATraining Step: 139  | total loss: [1m[32m0.08113[0m[0m | time: 2.754s
[2K
| Adam | epoch: 018 | loss: 0.08113 - acc: 0.9816 -- iter: 096/240
[A[ATraining Step: 140  | total loss: [1m[32m0.07848[0m[0m | time: 3.775s
[2K
| Adam | epoch: 018 | loss: 0.07848 - acc: 0.9834 -- iter: 128/240
[A[ATraining Step: 141  | total loss: [1m[32m0.07283[0m[0m | time: 4.619s
[2K
| Adam | epoch: 018 | loss: 0.07283 - acc: 0.9851 -- iter: 160/240
[A[ATraining Step: 142  | total loss: [1m[32m0.06682[0m[0m | time: 5.375s
[2K
| Adam | epoch: 018 | loss: 0.06682 - acc: 0.9866 -- iter: 192/240
[A[ATraining Step: 143  | total loss: [1m[32m0.06100[0m[0m | time: 5.820s
[2K
| Adam | epoch: 018 | loss: 0.06100 - acc: 0.9879 -- iter: 224/240
[A[ATraining Step: 144  | total loss: [1m[32m0.05606[0m[0m | time: 7.298s
[2K
| Adam | epoch: 018 | loss: 0.05606 - acc: 0.9891 | val_loss: 0.21731 - val_acc: 0.9342 -- iter: 240/240
--
Training Step: 145  | total loss: [1m[32m0.05211[0m[0m | time: 0.847s
[2K
| Adam | epoch: 019 | loss: 0.05211 - acc: 0.9902 -- iter: 032/240
[A[ATraining Step: 146  | total loss: [1m[32m0.04887[0m[0m | time: 1.893s
[2K
| Adam | epoch: 019 | loss: 0.04887 - acc: 0.9912 -- iter: 064/240
[A[ATraining Step: 147  | total loss: [1m[32m0.04495[0m[0m | time: 2.902s
[2K
| Adam | epoch: 019 | loss: 0.04495 - acc: 0.9921 -- iter: 096/240
[A[ATraining Step: 148  | total loss: [1m[32m0.10430[0m[0m | time: 3.733s
[2K
| Adam | epoch: 019 | loss: 0.10430 - acc: 0.9835 -- iter: 128/240
[A[ATraining Step: 149  | total loss: [1m[32m0.09639[0m[0m | time: 4.528s
[2K
| Adam | epoch: 019 | loss: 0.09639 - acc: 0.9851 -- iter: 160/240
[A[ATraining Step: 150  | total loss: [1m[32m0.08826[0m[0m | time: 5.385s
[2K
| Adam | epoch: 019 | loss: 0.08826 - acc: 0.9866 -- iter: 192/240
[A[ATraining Step: 151  | total loss: [1m[32m0.08151[0m[0m | time: 6.356s
[2K
| Adam | epoch: 019 | loss: 0.08151 - acc: 0.9880 -- iter: 224/240
[A[ATraining Step: 152  | total loss: [1m[32m0.07624[0m[0m | time: 7.819s
[2K
| Adam | epoch: 019 | loss: 0.07624 - acc: 0.9892 | val_loss: 0.18763 - val_acc: 0.9474 -- iter: 240/240
--
Training Step: 153  | total loss: [1m[32m0.07044[0m[0m | time: 0.524s
[2K
| Adam | epoch: 020 | loss: 0.07044 - acc: 0.9902 -- iter: 032/240
[A[ATraining Step: 154  | total loss: [1m[32m0.06509[0m[0m | time: 1.484s
[2K
| Adam | epoch: 020 | loss: 0.06509 - acc: 0.9912 -- iter: 064/240
[A[ATraining Step: 155  | total loss: [1m[32m0.06138[0m[0m | time: 2.429s
[2K
| Adam | epoch: 020 | loss: 0.06138 - acc: 0.9921 -- iter: 096/240
[A[ATraining Step: 156  | total loss: [1m[32m0.05669[0m[0m | time: 3.377s
[2K
| Adam | epoch: 020 | loss: 0.05669 - acc: 0.9929 -- iter: 128/240
[A[ATraining Step: 157  | total loss: [1m[32m0.28666[0m[0m | time: 4.358s
[2K
| Adam | epoch: 020 | loss: 0.28666 - acc: 0.9499 -- iter: 160/240
[A[ATraining Step: 158  | total loss: [1m[32m0.26014[0m[0m | time: 5.353s
[2K
| Adam | epoch: 020 | loss: 0.26014 - acc: 0.9549 -- iter: 192/240
[A[ATraining Step: 159  | total loss: [1m[32m0.23773[0m[0m | time: 6.287s
[2K
| Adam | epoch: 020 | loss: 0.23773 - acc: 0.9594 -- iter: 224/240
[A[ATraining Step: 160  | total loss: [1m[32m0.22038[0m[0m | time: 8.264s
[2K
| Adam | epoch: 020 | loss: 0.22038 - acc: 0.9634 | val_loss: 0.18715 - val_acc: 0.9342 -- iter: 240/240
--
Training Step: 161  | total loss: [1m[32m0.20450[0m[0m | time: 0.507s
[2K
| Adam | epoch: 021 | loss: 0.20450 - acc: 0.9671 -- iter: 032/240
[A[ATraining Step: 162  | total loss: [1m[32m0.18900[0m[0m | time: 0.939s
[2K
| Adam | epoch: 021 | loss: 0.18900 - acc: 0.9704 -- iter: 064/240
[A[ATraining Step: 163  | total loss: [1m[32m0.17419[0m[0m | time: 1.593s
[2K
| Adam | epoch: 021 | loss: 0.17419 - acc: 0.9733 -- iter: 096/240
[A[ATraining Step: 164  | total loss: [1m[32m0.16122[0m[0m | time: 2.254s
[2K
| Adam | epoch: 021 | loss: 0.16122 - acc: 0.9760 -- iter: 128/240
[A[ATraining Step: 165  | total loss: [1m[32m0.14905[0m[0m | time: 2.888s
[2K
| Adam | epoch: 021 | loss: 0.14905 - acc: 0.9784 -- iter: 160/240
[A[ATraining Step: 166  | total loss: [1m[32m0.15452[0m[0m | time: 3.505s
[2K
| Adam | epoch: 021 | loss: 0.15452 - acc: 0.9774 -- iter: 192/240
[A[ATraining Step: 167  | total loss: [1m[32m0.14122[0m[0m | time: 4.097s
[2K
| Adam | epoch: 021 | loss: 0.14122 - acc: 0.9797 -- iter: 224/240
[A[ATraining Step: 168  | total loss: [1m[32m0.12869[0m[0m | time: 5.725s
[2K
| Adam | epoch: 021 | loss: 0.12869 - acc: 0.9817 | val_loss: 0.20662 - val_acc: 0.9342 -- iter: 240/240
--
Training Step: 169  | total loss: [1m[32m0.11700[0m[0m | time: 0.608s
[2K
| Adam | epoch: 022 | loss: 0.11700 - acc: 0.9836 -- iter: 032/240
[A[ATraining Step: 170  | total loss: [1m[32m0.10601[0m[0m | time: 0.922s
[2K
| Adam | epoch: 022 | loss: 0.10601 - acc: 0.9852 -- iter: 064/240
[A[ATraining Step: 171  | total loss: [1m[32m0.09646[0m[0m | time: 1.246s
[2K
| Adam | epoch: 022 | loss: 0.09646 - acc: 0.9867 -- iter: 096/240
[A[ATraining Step: 172  | total loss: [1m[32m0.08761[0m[0m | time: 1.869s
[2K
| Adam | epoch: 022 | loss: 0.08761 - acc: 0.9880 -- iter: 128/240
[A[ATraining Step: 173  | total loss: [1m[32m0.07926[0m[0m | time: 2.489s
[2K
| Adam | epoch: 022 | loss: 0.07926 - acc: 0.9892 -- iter: 160/240
[A[ATraining Step: 174  | total loss: [1m[32m0.07200[0m[0m | time: 3.093s
[2K
| Adam | epoch: 022 | loss: 0.07200 - acc: 0.9903 -- iter: 192/240
[A[ATraining Step: 175  | total loss: [1m[32m0.15800[0m[0m | time: 3.721s
[2K
| Adam | epoch: 022 | loss: 0.15800 - acc: 0.9788 -- iter: 224/240
[A[ATraining Step: 176  | total loss: [1m[32m0.14277[0m[0m | time: 5.339s
[2K
| Adam | epoch: 022 | loss: 0.14277 - acc: 0.9809 | val_loss: 0.29896 - val_acc: 0.9211 -- iter: 240/240
--
Training Step: 177  | total loss: [1m[32m0.13009[0m[0m | time: 0.626s
[2K
| Adam | epoch: 023 | loss: 0.13009 - acc: 0.9828 -- iter: 032/240
[A[ATraining Step: 178  | total loss: [1m[32m0.12081[0m[0m | time: 1.256s
[2K
| Adam | epoch: 023 | loss: 0.12081 - acc: 0.9845 -- iter: 064/240
[A[ATraining Step: 179  | total loss: [1m[32m0.11289[0m[0m | time: 1.577s
[2K
| Adam | epoch: 023 | loss: 0.11289 - acc: 0.9861 -- iter: 096/240
[A[ATraining Step: 180  | total loss: [1m[32m0.10462[0m[0m | time: 1.919s
[2K
| Adam | epoch: 023 | loss: 0.10462 - acc: 0.9875 -- iter: 128/240
[A[ATraining Step: 181  | total loss: [1m[32m0.09621[0m[0m | time: 2.538s
[2K
| Adam | epoch: 023 | loss: 0.09621 - acc: 0.9887 -- iter: 160/240
[A[ATraining Step: 182  | total loss: [1m[32m0.08774[0m[0m | time: 3.232s
[2K
| Adam | epoch: 023 | loss: 0.08774 - acc: 0.9898 -- iter: 192/240
[A[ATraining Step: 183  | total loss: [1m[32m0.08074[0m[0m | time: 4.298s
[2K
| Adam | epoch: 023 | loss: 0.08074 - acc: 0.9909 -- iter: 224/240
[A[ATraining Step: 184  | total loss: [1m[32m0.13763[0m[0m | time: 6.244s
[2K
| Adam | epoch: 023 | loss: 0.13763 - acc: 0.9793 | val_loss: 0.21641 - val_acc: 0.9079 -- iter: 240/240
--
Training Step: 185  | total loss: [1m[32m0.12616[0m[0m | time: 0.945s
[2K
| Adam | epoch: 024 | loss: 0.12616 - acc: 0.9813 -- iter: 032/240
[A[ATraining Step: 186  | total loss: [1m[32m0.11609[0m[0m | time: 1.816s
[2K
| Adam | epoch: 024 | loss: 0.11609 - acc: 0.9832 -- iter: 064/240
[A[ATraining Step: 187  | total loss: [1m[32m0.11109[0m[0m | time: 2.641s
[2K
| Adam | epoch: 024 | loss: 0.11109 - acc: 0.9849 -- iter: 096/240
[A[ATraining Step: 188  | total loss: [1m[32m0.10360[0m[0m | time: 3.153s
[2K
| Adam | epoch: 024 | loss: 0.10360 - acc: 0.9864 -- iter: 128/240
[A[ATraining Step: 189  | total loss: [1m[32m0.09686[0m[0m | time: 3.741s
[2K
| Adam | epoch: 024 | loss: 0.09686 - acc: 0.9878 -- iter: 160/240
[A[ATraining Step: 190  | total loss: [1m[32m0.09034[0m[0m | time: 4.773s
[2K
| Adam | epoch: 024 | loss: 0.09034 - acc: 0.9890 -- iter: 192/240
[A[ATraining Step: 191  | total loss: [1m[32m0.08548[0m[0m | time: 5.591s
[2K
| Adam | epoch: 024 | loss: 0.08548 - acc: 0.9901 -- iter: 224/240
[A[ATraining Step: 192  | total loss: [1m[32m0.08086[0m[0m | time: 7.399s
[2K
| Adam | epoch: 024 | loss: 0.08086 - acc: 0.9911 | val_loss: 0.22479 - val_acc: 0.9211 -- iter: 240/240
--
Training Step: 193  | total loss: [1m[32m0.12961[0m[0m | time: 0.839s
[2K
| Adam | epoch: 025 | loss: 0.12961 - acc: 0.9795 -- iter: 032/240
[A[ATraining Step: 194  | total loss: [1m[32m0.12231[0m[0m | time: 1.860s
[2K
| Adam | epoch: 025 | loss: 0.12231 - acc: 0.9815 -- iter: 064/240
[A[ATraining Step: 195  | total loss: [1m[32m0.11500[0m[0m | time: 2.870s
[2K
| Adam | epoch: 025 | loss: 0.11500 - acc: 0.9834 -- iter: 096/240
[A[ATraining Step: 196  | total loss: [1m[32m0.10668[0m[0m | time: 3.660s
[2K
| Adam | epoch: 025 | loss: 0.10668 - acc: 0.9850 -- iter: 128/240
[A[ATraining Step: 197  | total loss: [1m[32m0.09821[0m[0m | time: 4.107s
[2K
| Adam | epoch: 025 | loss: 0.09821 - acc: 0.9865 -- iter: 160/240
[A[ATraining Step: 198  | total loss: [1m[32m0.08928[0m[0m | time: 4.546s
[2K
| Adam | epoch: 025 | loss: 0.08928 - acc: 0.9879 -- iter: 192/240
[A[ATraining Step: 199  | total loss: [1m[32m0.08105[0m[0m | time: 5.401s
[2K
| Adam | epoch: 025 | loss: 0.08105 - acc: 0.9891 -- iter: 224/240
[A[ATraining Step: 200  | total loss: [1m[32m0.07388[0m[0m | time: 7.243s
[2K
| Adam | epoch: 025 | loss: 0.07388 - acc: 0.9902 | val_loss: 0.25756 - val_acc: 0.9211 -- iter: 240/240
--
Training Step: 201  | total loss: [1m[32m0.06716[0m[0m | time: 1.037s
[2K
| Adam | epoch: 026 | loss: 0.06716 - acc: 0.9912 -- iter: 032/240
[A[ATraining Step: 202  | total loss: [1m[32m0.07798[0m[0m | time: 1.847s
[2K
| Adam | epoch: 026 | loss: 0.07798 - acc: 0.9889 -- iter: 064/240
[A[ATraining Step: 203  | total loss: [1m[32m0.07111[0m[0m | time: 2.688s
[2K
| Adam | epoch: 026 | loss: 0.07111 - acc: 0.9900 -- iter: 096/240
[A[ATraining Step: 204  | total loss: [1m[32m0.06616[0m[0m | time: 3.549s
[2K
| Adam | epoch: 026 | loss: 0.06616 - acc: 0.9910 -- iter: 128/240
[A[ATraining Step: 205  | total loss: [1m[32m0.06027[0m[0m | time: 4.420s
[2K
| Adam | epoch: 026 | loss: 0.06027 - acc: 0.9919 -- iter: 160/240
[A[ATraining Step: 206  | total loss: [1m[32m0.05466[0m[0m | time: 4.862s
[2K
| Adam | epoch: 026 | loss: 0.05466 - acc: 0.9927 -- iter: 192/240
[A[ATraining Step: 207  | total loss: [1m[32m0.04951[0m[0m | time: 5.304s
[2K
| Adam | epoch: 026 | loss: 0.04951 - acc: 0.9935 -- iter: 224/240
[A[ATraining Step: 208  | total loss: [1m[32m0.04483[0m[0m | time: 7.216s
[2K
| Adam | epoch: 026 | loss: 0.04483 - acc: 0.9941 | val_loss: 0.27275 - val_acc: 0.9342 -- iter: 240/240
--
Training Step: 209  | total loss: [1m[32m0.04050[0m[0m | time: 0.825s
[2K
| Adam | epoch: 027 | loss: 0.04050 - acc: 0.9947 -- iter: 032/240
[A[ATraining Step: 210  | total loss: [1m[32m0.03657[0m[0m | time: 1.686s
[2K
| Adam | epoch: 027 | loss: 0.03657 - acc: 0.9952 -- iter: 064/240
[A[ATraining Step: 211  | total loss: [1m[32m0.05806[0m[0m | time: 2.559s
[2K
| Adam | epoch: 027 | loss: 0.05806 - acc: 0.9926 -- iter: 096/240
[A[ATraining Step: 212  | total loss: [1m[32m0.05265[0m[0m | time: 3.416s
[2K
| Adam | epoch: 027 | loss: 0.05265 - acc: 0.9933 -- iter: 128/240
[A[ATraining Step: 213  | total loss: [1m[32m0.04774[0m[0m | time: 4.354s
[2K
| Adam | epoch: 027 | loss: 0.04774 - acc: 0.9940 -- iter: 160/240
[A[ATraining Step: 214  | total loss: [1m[32m0.04324[0m[0m | time: 5.290s
[2K
| Adam | epoch: 027 | loss: 0.04324 - acc: 0.9946 -- iter: 192/240
[A[ATraining Step: 215  | total loss: [1m[32m0.03929[0m[0m | time: 5.733s
[2K
| Adam | epoch: 027 | loss: 0.03929 - acc: 0.9951 -- iter: 224/240
[A[ATraining Step: 216  | total loss: [1m[32m0.03780[0m[0m | time: 7.184s
[2K
| Adam | epoch: 027 | loss: 0.03780 - acc: 0.9956 | val_loss: 0.25230 - val_acc: 0.9342 -- iter: 240/240
--
Training Step: 217  | total loss: [1m[32m0.03488[0m[0m | time: 0.876s
[2K
| Adam | epoch: 028 | loss: 0.03488 - acc: 0.9961 -- iter: 032/240
[A[ATraining Step: 218  | total loss: [1m[32m0.03163[0m[0m | time: 1.748s
[2K
| Adam | epoch: 028 | loss: 0.03163 - acc: 0.9965 -- iter: 064/240
[A[ATraining Step: 219  | total loss: [1m[32m0.02881[0m[0m | time: 2.682s
[2K
| Adam | epoch: 028 | loss: 0.02881 - acc: 0.9968 -- iter: 096/240
[A[ATraining Step: 220  | total loss: [1m[32m0.02620[0m[0m | time: 3.598s
[2K
| Adam | epoch: 028 | loss: 0.02620 - acc: 0.9971 -- iter: 128/240
[A[ATraining Step: 221  | total loss: [1m[32m0.02391[0m[0m | time: 4.420s
[2K
| Adam | epoch: 028 | loss: 0.02391 - acc: 0.9974 -- iter: 160/240
[A[ATraining Step: 222  | total loss: [1m[32m0.02181[0m[0m | time: 5.412s
[2K
| Adam | epoch: 028 | loss: 0.02181 - acc: 0.9977 -- iter: 192/240
[A[ATraining Step: 223  | total loss: [1m[32m0.01985[0m[0m | time: 6.468s
[2K
| Adam | epoch: 028 | loss: 0.01985 - acc: 0.9979 -- iter: 224/240
[A[ATraining Step: 224  | total loss: [1m[32m0.01802[0m[0m | time: 7.976s
[2K
| Adam | epoch: 028 | loss: 0.01802 - acc: 0.9981 | val_loss: 0.28366 - val_acc: 0.9342 -- iter: 240/240
--
Training Step: 225  | total loss: [1m[32m0.01638[0m[0m | time: 0.471s
[2K
| Adam | epoch: 029 | loss: 0.01638 - acc: 0.9983 -- iter: 032/240
[A[ATraining Step: 226  | total loss: [1m[32m0.01492[0m[0m | time: 1.313s
[2K
| Adam | epoch: 029 | loss: 0.01492 - acc: 0.9985 -- iter: 064/240
[A[ATraining Step: 227  | total loss: [1m[32m0.01375[0m[0m | time: 2.233s
[2K
| Adam | epoch: 029 | loss: 0.01375 - acc: 0.9986 -- iter: 096/240
[A[ATraining Step: 228  | total loss: [1m[32m0.01288[0m[0m | time: 3.298s
[2K
| Adam | epoch: 029 | loss: 0.01288 - acc: 0.9988 -- iter: 128/240
[A[ATraining Step: 229  | total loss: [1m[32m0.22281[0m[0m | time: 4.249s
[2K
| Adam | epoch: 029 | loss: 0.22281 - acc: 0.9708 -- iter: 160/240
[A[ATraining Step: 230  | total loss: [1m[32m0.20089[0m[0m | time: 5.008s
[2K
| Adam | epoch: 029 | loss: 0.20089 - acc: 0.9737 -- iter: 192/240
[A[ATraining Step: 231  | total loss: [1m[32m0.18168[0m[0m | time: 5.945s
[2K
| Adam | epoch: 029 | loss: 0.18168 - acc: 0.9763 -- iter: 224/240
[A[ATraining Step: 232  | total loss: [1m[32m0.16503[0m[0m | time: 7.772s
[2K
| Adam | epoch: 029 | loss: 0.16503 - acc: 0.9787 | val_loss: 0.18040 - val_acc: 0.9474 -- iter: 240/240
--
Training Step: 233  | total loss: [1m[32m0.15112[0m[0m | time: 0.414s
[2K
| Adam | epoch: 030 | loss: 0.15112 - acc: 0.9808 -- iter: 032/240
[A[ATraining Step: 234  | total loss: [1m[32m0.13899[0m[0m | time: 0.906s
[2K
| Adam | epoch: 030 | loss: 0.13899 - acc: 0.9827 -- iter: 064/240
[A[ATraining Step: 235  | total loss: [1m[32m0.12934[0m[0m | time: 1.882s
[2K
| Adam | epoch: 030 | loss: 0.12934 - acc: 0.9845 -- iter: 096/240
[A[ATraining Step: 236  | total loss: [1m[32m0.12237[0m[0m | time: 2.928s
[2K
| Adam | epoch: 030 | loss: 0.12237 - acc: 0.9860 -- iter: 128/240
[A[ATraining Step: 237  | total loss: [1m[32m0.11665[0m[0m | time: 3.666s
[2K
| Adam | epoch: 030 | loss: 0.11665 - acc: 0.9874 -- iter: 160/240
[A[ATraining Step: 238  | total loss: [1m[32m0.12435[0m[0m | time: 4.508s
[2K
| Adam | epoch: 030 | loss: 0.12435 - acc: 0.9855 -- iter: 192/240
[A[ATraining Step: 239  | total loss: [1m[32m0.11524[0m[0m | time: 5.332s
[2K
| Adam | epoch: 030 | loss: 0.11524 - acc: 0.9870 -- iter: 224/240
[A[ATraining Step: 240  | total loss: [1m[32m0.10734[0m[0m | time: 7.208s
[2K
| Adam | epoch: 030 | loss: 0.10734 - acc: 0.9883 | val_loss: 0.19862 - val_acc: 0.9342 -- iter: 240/240
--
Validation AUC:0.984593837535014
Validation AUPRC:0.9878362179139435
Test AUC:0.9913978494623656
Test AUPRC:0.9939592819096151
BestTestF1Score	0.98	0.95	0.97	0.96	1.0	45	2	29	0	0.14
BestTestMCCScore	0.98	0.95	0.97	0.96	1.0	45	2	29	0	0.14
BestTestAccuracyScore	0.98	0.95	0.97	0.96	1.0	45	2	29	0	0.14
BestValidationF1Score	0.96	0.92	0.96	0.95	0.98	41	2	32	1	0.14
BestValidationMCC	0.96	0.92	0.96	0.95	0.98	41	2	32	1	0.14
BestValidationAccuracy	0.96	0.92	0.96	0.95	0.98	41	2	32	1	0.14
TestPredictions (Threshold:0.14)
CHEMBL378300,TP,ACT,0.9800000190734863	CHEMBL237290,TN,INACT,0.0	CHEMBL3741364,TP,ACT,0.33000001311302185	CHEMBL475405,TP,ACT,0.9900000095367432	CHEMBL371743,TP,ACT,0.9900000095367432	CHEMBL3739977,TP,ACT,0.9700000286102295	CHEMBL1968913,TN,INACT,0.019999999552965164	CHEMBL2181550,TN,INACT,0.12999999523162842	CHEMBL237688,TN,INACT,0.0	CHEMBL2179773,TN,INACT,0.029999999329447746	CHEMBL438672,TN,INACT,0.009999999776482582	CHEMBL3740359,TP,ACT,0.949999988079071	CHEMBL1976353,TN,INACT,0.009999999776482582	CHEMBL194898,TP,ACT,0.9900000095367432	CHEMBL3742107,TP,ACT,0.9700000286102295	CHEMBL83,TN,INACT,0.029999999329447746	CHEMBL3403619,TP,ACT,0.8600000143051147	CHEMBL238367,TN,INACT,0.0	CHEMBL3741743,TP,ACT,0.9800000190734863	CHEMBL1968499,TP,ACT,0.9900000095367432	CHEMBL381872,TP,ACT,0.9900000095367432	CHEMBL361915,TP,ACT,0.8399999737739563	CHEMBL225155,TP,ACT,0.9800000190734863	CHEMBL235815,TN,INACT,0.009999999776482582	CHEMBL8201,TN,INACT,0.05000000074505806	CHEMBL8418,TN,INACT,0.019999999552965164	CHEMBL3359520,TP,ACT,0.9399999976158142	CHEMBL235162,TN,INACT,0.009999999776482582	CHEMBL1086170,TP,ACT,0.9800000190734863	CHEMBL1971132,TP,ACT,0.9800000190734863	CHEMBL1214376,TN,INACT,0.009999999776482582	CHEMBL2371150,TN,INACT,0.009999999776482582	CHEMBL1085191,TP,ACT,0.949999988079071	CHEMBL393918,TN,INACT,0.019999999552965164	CHEMBL184237,TP,ACT,0.9700000286102295	CHEMBL269776,TN,INACT,0.009999999776482582	CHEMBL3740090,TP,ACT,0.9900000095367432	CHEMBL2180219,TN,INACT,0.009999999776482582	CHEMBL115344,TP,ACT,0.8299999833106995	CHEMBL515603,TP,ACT,0.9900000095367432	CHEMBL224623,TP,ACT,0.9900000095367432	CHEMBL3739887,TP,ACT,0.9900000095367432	CHEMBL238342,TN,INACT,0.019999999552965164	CHEMBL181597,TP,ACT,0.9900000095367432	CHEMBL236847,TN,INACT,0.029999999329447746	CHEMBL3740739,TP,ACT,0.9700000286102295	CHEMBL196534,TP,ACT,0.9900000095367432	CHEMBL195025,TP,ACT,0.9900000095367432	CHEMBL3605522,FP,INACT,0.8399999737739563	CHEMBL356213,TN,INACT,0.019999999552965164	CHEMBL473562,TP,ACT,0.9700000286102295	CHEMBL426191,TP,ACT,0.9700000286102295	CHEMBL473238,TP,ACT,0.9599999785423279	CHEMBL425563,TP,ACT,0.9900000095367432	CHEMBL334213,TP,ACT,0.9700000286102295	CHEMBL363076,TP,ACT,0.8700000047683716	CHEMBL3741988,TP,ACT,0.9900000095367432	CHEMBL3739759,TP,ACT,0.9900000095367432	CHEMBL537632,TP,ACT,0.9900000095367432	CHEMBL114606,TP,ACT,0.9900000095367432	CHEMBL224800,TP,ACT,0.7400000095367432	CHEMBL3741775,TP,ACT,0.9700000286102295	CHEMBL2093089,TN,INACT,0.009999999776482582	CHEMBL1090796,TP,ACT,1.0	CHEMBL188881,TP,ACT,0.9800000190734863	CHEMBL393753,TN,INACT,0.009999999776482582	CHEMBL1159698,TN,INACT,0.11999999731779099	CHEMBL808,TN,INACT,0.029999999329447746	CHEMBL235616,TN,INACT,0.009999999776482582	CHEMBL3769933,TP,ACT,0.6899999976158142	CHEMBL362010,TN,INACT,0.009999999776482582	CHEMBL187588,TP,ACT,0.9599999785423279	CHEMBL371670,TP,ACT,0.9900000095367432	CHEMBL3314942,FP,INACT,0.8799999952316284	CHEMBL238158,TN,INACT,0.009999999776482582	CHEMBL2386558,TN,INACT,0.05000000074505806	

