CNNModel CHEMBL3952 RMSprop 0.0005 15 128 0 0.6 False True
Number of active compounds :	1796
Number of inactive compounds :	1796
---------------------------------
Run id: CNNModel_CHEMBL3952_RMSprop_0.0005_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3952_RMSprop_0.0005_15_128_0.6_True/
---------------------------------
Training samples: 2147
Validation samples: 672
--
Training Step: 1  | time: 0.938s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2147
[A[ATraining Step: 2  | total loss: [1m[32m0.62427[0m[0m | time: 1.708s
[2K
| RMSProp | epoch: 001 | loss: 0.62427 - acc: 0.3656 -- iter: 0064/2147
[A[ATraining Step: 3  | total loss: [1m[32m0.68083[0m[0m | time: 2.500s
[2K
| RMSProp | epoch: 001 | loss: 0.68083 - acc: 0.4500 -- iter: 0096/2147
[A[ATraining Step: 4  | total loss: [1m[32m0.69014[0m[0m | time: 3.330s
[2K
| RMSProp | epoch: 001 | loss: 0.69014 - acc: 0.4875 -- iter: 0128/2147
[A[ATraining Step: 5  | total loss: [1m[32m0.69256[0m[0m | time: 4.100s
[2K
| RMSProp | epoch: 001 | loss: 0.69256 - acc: 0.4529 -- iter: 0160/2147
[A[ATraining Step: 6  | total loss: [1m[32m0.69249[0m[0m | time: 4.954s
[2K
| RMSProp | epoch: 001 | loss: 0.69249 - acc: 0.6037 -- iter: 0192/2147
[A[ATraining Step: 7  | total loss: [1m[32m0.69316[0m[0m | time: 5.564s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4665 -- iter: 0224/2147
[A[ATraining Step: 8  | total loss: [1m[32m0.69331[0m[0m | time: 6.205s
[2K
| RMSProp | epoch: 001 | loss: 0.69331 - acc: 0.4853 -- iter: 0256/2147
[A[ATraining Step: 9  | total loss: [1m[32m0.69277[0m[0m | time: 6.796s
[2K
| RMSProp | epoch: 001 | loss: 0.69277 - acc: 0.5758 -- iter: 0288/2147
[A[ATraining Step: 10  | total loss: [1m[32m0.69286[0m[0m | time: 7.501s
[2K
| RMSProp | epoch: 001 | loss: 0.69286 - acc: 0.6004 -- iter: 0320/2147
[A[ATraining Step: 11  | total loss: [1m[32m0.69299[0m[0m | time: 8.217s
[2K
| RMSProp | epoch: 001 | loss: 0.69299 - acc: 0.5825 -- iter: 0352/2147
[A[ATraining Step: 12  | total loss: [1m[32m0.69276[0m[0m | time: 8.952s
[2K
| RMSProp | epoch: 001 | loss: 0.69276 - acc: 0.6016 -- iter: 0384/2147
[A[ATraining Step: 13  | total loss: [1m[32m0.69279[0m[0m | time: 9.724s
[2K
| RMSProp | epoch: 001 | loss: 0.69279 - acc: 0.5982 -- iter: 0416/2147
[A[ATraining Step: 14  | total loss: [1m[32m0.69302[0m[0m | time: 10.468s
[2K
| RMSProp | epoch: 001 | loss: 0.69302 - acc: 0.5453 -- iter: 0448/2147
[A[ATraining Step: 15  | total loss: [1m[32m0.69323[0m[0m | time: 11.222s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.5398 -- iter: 0480/2147
[A[ATraining Step: 16  | total loss: [1m[32m0.69366[0m[0m | time: 11.926s
[2K
| RMSProp | epoch: 001 | loss: 0.69366 - acc: 0.4428 -- iter: 0512/2147
[A[ATraining Step: 17  | total loss: [1m[32m0.69365[0m[0m | time: 12.720s
[2K
| RMSProp | epoch: 001 | loss: 0.69365 - acc: 0.4072 -- iter: 0544/2147
[A[ATraining Step: 18  | total loss: [1m[32m0.69367[0m[0m | time: 13.499s
[2K
| RMSProp | epoch: 001 | loss: 0.69367 - acc: 0.4285 -- iter: 0576/2147
[A[ATraining Step: 19  | total loss: [1m[32m0.69344[0m[0m | time: 14.262s
[2K
| RMSProp | epoch: 001 | loss: 0.69344 - acc: 0.4419 -- iter: 0608/2147
[A[ATraining Step: 20  | total loss: [1m[32m0.69347[0m[0m | time: 14.996s
[2K
| RMSProp | epoch: 001 | loss: 0.69347 - acc: 0.4505 -- iter: 0640/2147
[A[ATraining Step: 21  | total loss: [1m[32m0.69352[0m[0m | time: 15.758s
[2K
| RMSProp | epoch: 001 | loss: 0.69352 - acc: 0.4562 -- iter: 0672/2147
[A[ATraining Step: 22  | total loss: [1m[32m0.69344[0m[0m | time: 16.489s
[2K
| RMSProp | epoch: 001 | loss: 0.69344 - acc: 0.4318 -- iter: 0704/2147
[A[ATraining Step: 23  | total loss: [1m[32m0.69344[0m[0m | time: 17.272s
[2K
| RMSProp | epoch: 001 | loss: 0.69344 - acc: 0.4153 -- iter: 0736/2147
[A[ATraining Step: 24  | total loss: [1m[32m0.69328[0m[0m | time: 18.026s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4743 -- iter: 0768/2147
[A[ATraining Step: 25  | total loss: [1m[32m0.69345[0m[0m | time: 18.644s
[2K
| RMSProp | epoch: 001 | loss: 0.69345 - acc: 0.4302 -- iter: 0800/2147
[A[ATraining Step: 26  | total loss: [1m[32m0.69341[0m[0m | time: 19.264s
[2K
| RMSProp | epoch: 001 | loss: 0.69341 - acc: 0.4404 -- iter: 0832/2147
[A[ATraining Step: 27  | total loss: [1m[32m0.69334[0m[0m | time: 19.873s
[2K
| RMSProp | epoch: 001 | loss: 0.69334 - acc: 0.4557 -- iter: 0864/2147
[A[ATraining Step: 28  | total loss: [1m[32m0.69348[0m[0m | time: 20.549s
[2K
| RMSProp | epoch: 001 | loss: 0.69348 - acc: 0.4277 -- iter: 0896/2147
[A[ATraining Step: 29  | total loss: [1m[32m0.69338[0m[0m | time: 21.328s
[2K
| RMSProp | epoch: 001 | loss: 0.69338 - acc: 0.4681 -- iter: 0928/2147
[A[ATraining Step: 30  | total loss: [1m[32m0.69330[0m[0m | time: 22.053s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4757 -- iter: 0960/2147
[A[ATraining Step: 31  | total loss: [1m[32m0.69344[0m[0m | time: 22.856s
[2K
| RMSProp | epoch: 001 | loss: 0.69344 - acc: 0.4380 -- iter: 0992/2147
[A[ATraining Step: 32  | total loss: [1m[32m0.69333[0m[0m | time: 23.628s
[2K
| RMSProp | epoch: 001 | loss: 0.69333 - acc: 0.4590 -- iter: 1024/2147
[A[ATraining Step: 33  | total loss: [1m[32m0.69330[0m[0m | time: 24.351s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4749 -- iter: 1056/2147
[A[ATraining Step: 34  | total loss: [1m[32m0.69330[0m[0m | time: 25.077s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4802 -- iter: 1088/2147
[A[ATraining Step: 35  | total loss: [1m[32m0.69316[0m[0m | time: 25.821s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5236 -- iter: 1120/2147
[A[ATraining Step: 36  | total loss: [1m[32m0.69315[0m[0m | time: 26.537s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.5316 -- iter: 1152/2147
[A[ATraining Step: 37  | total loss: [1m[32m0.69314[0m[0m | time: 27.333s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5315 -- iter: 1184/2147
[A[ATraining Step: 38  | total loss: [1m[32m0.69312[0m[0m | time: 28.087s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5253 -- iter: 1216/2147
[A[ATraining Step: 39  | total loss: [1m[32m0.69310[0m[0m | time: 28.884s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5325 -- iter: 1248/2147
[A[ATraining Step: 40  | total loss: [1m[32m0.69311[0m[0m | time: 29.677s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5205 -- iter: 1280/2147
[A[ATraining Step: 41  | total loss: [1m[32m0.69311[0m[0m | time: 30.432s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5110 -- iter: 1312/2147
[A[ATraining Step: 42  | total loss: [1m[32m0.69309[0m[0m | time: 31.304s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5146 -- iter: 1344/2147
[A[ATraining Step: 43  | total loss: [1m[32m0.69307[0m[0m | time: 31.925s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5176 -- iter: 1376/2147
[A[ATraining Step: 44  | total loss: [1m[32m0.69309[0m[0m | time: 32.553s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5145 -- iter: 1408/2147
[A[ATraining Step: 45  | total loss: [1m[32m0.69306[0m[0m | time: 33.172s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5227 -- iter: 1440/2147
[A[ATraining Step: 46  | total loss: [1m[32m0.69305[0m[0m | time: 33.853s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5449 -- iter: 1472/2147
[A[ATraining Step: 47  | total loss: [1m[32m0.69305[0m[0m | time: 34.646s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5325 -- iter: 1504/2147
[A[ATraining Step: 48  | total loss: [1m[32m0.69310[0m[0m | time: 35.364s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5122 -- iter: 1536/2147
[A[ATraining Step: 49  | total loss: [1m[32m0.69310[0m[0m | time: 36.089s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5201 -- iter: 1568/2147
[A[ATraining Step: 50  | total loss: [1m[32m0.69307[0m[0m | time: 36.821s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5316 -- iter: 1600/2147
[A[ATraining Step: 51  | total loss: [1m[32m0.69301[0m[0m | time: 37.582s
[2K
| RMSProp | epoch: 001 | loss: 0.69301 - acc: 0.5506 -- iter: 1632/2147
[A[ATraining Step: 52  | total loss: [1m[32m0.69302[0m[0m | time: 38.359s
[2K
| RMSProp | epoch: 001 | loss: 0.69302 - acc: 0.5477 -- iter: 1664/2147
[A[ATraining Step: 53  | total loss: [1m[32m0.69305[0m[0m | time: 39.069s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5268 -- iter: 1696/2147
[A[ATraining Step: 54  | total loss: [1m[32m0.69304[0m[0m | time: 39.831s
[2K
| RMSProp | epoch: 001 | loss: 0.69304 - acc: 0.5275 -- iter: 1728/2147
[A[ATraining Step: 55  | total loss: [1m[32m0.69300[0m[0m | time: 40.536s
[2K
| RMSProp | epoch: 001 | loss: 0.69300 - acc: 0.5459 -- iter: 1760/2147
[A[ATraining Step: 56  | total loss: [1m[32m0.69308[0m[0m | time: 41.275s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.5306 -- iter: 1792/2147
[A[ATraining Step: 57  | total loss: [1m[32m0.69329[0m[0m | time: 42.003s
[2K
| RMSProp | epoch: 001 | loss: 0.69329 - acc: 0.5004 -- iter: 1824/2147
[A[ATraining Step: 58  | total loss: [1m[32m0.69329[0m[0m | time: 42.755s
[2K
| RMSProp | epoch: 001 | loss: 0.69329 - acc: 0.4876 -- iter: 1856/2147
[A[ATraining Step: 59  | total loss: [1m[32m0.69335[0m[0m | time: 43.494s
[2K
| RMSProp | epoch: 001 | loss: 0.69335 - acc: 0.4725 -- iter: 1888/2147
[A[ATraining Step: 60  | total loss: [1m[32m0.69338[0m[0m | time: 44.319s
[2K
| RMSProp | epoch: 001 | loss: 0.69338 - acc: 0.4678 -- iter: 1920/2147
[A[ATraining Step: 61  | total loss: [1m[32m0.69335[0m[0m | time: 44.952s
[2K
| RMSProp | epoch: 001 | loss: 0.69335 - acc: 0.4679 -- iter: 1952/2147
[A[ATraining Step: 62  | total loss: [1m[32m0.69332[0m[0m | time: 45.595s
[2K
| RMSProp | epoch: 001 | loss: 0.69332 - acc: 0.4841 -- iter: 1984/2147
[A[ATraining Step: 63  | total loss: [1m[32m0.69330[0m[0m | time: 46.200s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4822 -- iter: 2016/2147
[A[ATraining Step: 64  | total loss: [1m[32m0.69327[0m[0m | time: 46.815s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.4805 -- iter: 2048/2147
[A[ATraining Step: 65  | total loss: [1m[32m0.69324[0m[0m | time: 47.473s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4868 -- iter: 2080/2147
[A[ATraining Step: 66  | total loss: [1m[32m0.69328[0m[0m | time: 48.242s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4884 -- iter: 2112/2147
[A[ATraining Step: 67  | total loss: [1m[32m0.69320[0m[0m | time: 48.981s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.5010 -- iter: 2144/2147
[A[ATraining Step: 68  | total loss: [1m[32m0.69316[0m[0m | time: 51.712s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5046 | val_loss: 0.69247 - val_acc: 0.5461 -- iter: 2147/2147
--
Training Step: 69  | total loss: [1m[32m0.69272[0m[0m | time: 0.092s
[2K
| RMSProp | epoch: 002 | loss: 0.69272 - acc: 0.5625 -- iter: 0032/2147
[A[ATraining Step: 70  | total loss: [1m[32m0.69182[0m[0m | time: 0.848s
[2K
| RMSProp | epoch: 002 | loss: 0.69182 - acc: 0.6130 -- iter: 0064/2147
[A[ATraining Step: 71  | total loss: [1m[32m0.69167[0m[0m | time: 1.635s
[2K
| RMSProp | epoch: 002 | loss: 0.69167 - acc: 0.6143 -- iter: 0096/2147
[A[ATraining Step: 72  | total loss: [1m[32m0.69226[0m[0m | time: 2.404s
[2K
| RMSProp | epoch: 002 | loss: 0.69226 - acc: 0.5874 -- iter: 0128/2147
[A[ATraining Step: 73  | total loss: [1m[32m0.69234[0m[0m | time: 3.185s
[2K
| RMSProp | epoch: 002 | loss: 0.69234 - acc: 0.5777 -- iter: 0160/2147
[A[ATraining Step: 74  | total loss: [1m[32m0.69218[0m[0m | time: 3.897s
[2K
| RMSProp | epoch: 002 | loss: 0.69218 - acc: 0.5795 -- iter: 0192/2147
[A[ATraining Step: 75  | total loss: [1m[32m0.69228[0m[0m | time: 4.656s
[2K
| RMSProp | epoch: 002 | loss: 0.69228 - acc: 0.5709 -- iter: 0224/2147
[A[ATraining Step: 76  | total loss: [1m[32m0.69185[0m[0m | time: 5.531s
[2K
| RMSProp | epoch: 002 | loss: 0.69185 - acc: 0.5867 -- iter: 0256/2147
[A[ATraining Step: 77  | total loss: [1m[32m0.69238[0m[0m | time: 6.151s
[2K
| RMSProp | epoch: 002 | loss: 0.69238 - acc: 0.5643 -- iter: 0288/2147
[A[ATraining Step: 78  | total loss: [1m[32m0.69260[0m[0m | time: 6.773s
[2K
| RMSProp | epoch: 002 | loss: 0.69260 - acc: 0.5510 -- iter: 0320/2147
[A[ATraining Step: 79  | total loss: [1m[32m0.69254[0m[0m | time: 7.406s
[2K
| RMSProp | epoch: 002 | loss: 0.69254 - acc: 0.5490 -- iter: 0352/2147
[A[ATraining Step: 80  | total loss: [1m[32m0.69251[0m[0m | time: 7.999s
[2K
| RMSProp | epoch: 002 | loss: 0.69251 - acc: 0.5472 -- iter: 0384/2147
[A[ATraining Step: 81  | total loss: [1m[32m0.69261[0m[0m | time: 8.730s
[2K
| RMSProp | epoch: 002 | loss: 0.69261 - acc: 0.5424 -- iter: 0416/2147
[A[ATraining Step: 82  | total loss: [1m[32m0.69245[0m[0m | time: 9.462s
[2K
| RMSProp | epoch: 002 | loss: 0.69245 - acc: 0.5475 -- iter: 0448/2147
[A[ATraining Step: 83  | total loss: [1m[32m0.69200[0m[0m | time: 10.173s
[2K
| RMSProp | epoch: 002 | loss: 0.69200 - acc: 0.5615 -- iter: 0480/2147
[A[ATraining Step: 84  | total loss: [1m[32m0.69190[0m[0m | time: 10.896s
[2K
| RMSProp | epoch: 002 | loss: 0.69190 - acc: 0.5616 -- iter: 0512/2147
[A[ATraining Step: 85  | total loss: [1m[32m0.69236[0m[0m | time: 11.611s
[2K
| RMSProp | epoch: 002 | loss: 0.69236 - acc: 0.5461 -- iter: 0544/2147
[A[ATraining Step: 86  | total loss: [1m[32m0.69208[0m[0m | time: 12.341s
[2K
| RMSProp | epoch: 002 | loss: 0.69208 - acc: 0.5540 -- iter: 0576/2147
[A[ATraining Step: 87  | total loss: [1m[32m0.69208[0m[0m | time: 13.094s
[2K
| RMSProp | epoch: 002 | loss: 0.69208 - acc: 0.5517 -- iter: 0608/2147
[A[ATraining Step: 88  | total loss: [1m[32m0.69256[0m[0m | time: 13.786s
[2K
| RMSProp | epoch: 002 | loss: 0.69256 - acc: 0.5372 -- iter: 0640/2147
[A[ATraining Step: 89  | total loss: [1m[32m0.69240[0m[0m | time: 14.496s
[2K
| RMSProp | epoch: 002 | loss: 0.69240 - acc: 0.5397 -- iter: 0672/2147
[A[ATraining Step: 90  | total loss: [1m[32m0.69197[0m[0m | time: 15.236s
[2K
| RMSProp | epoch: 002 | loss: 0.69197 - acc: 0.5513 -- iter: 0704/2147
[A[ATraining Step: 91  | total loss: [1m[32m0.69210[0m[0m | time: 15.956s
[2K
| RMSProp | epoch: 002 | loss: 0.69210 - acc: 0.5462 -- iter: 0736/2147
[A[ATraining Step: 92  | total loss: [1m[32m0.69174[0m[0m | time: 16.655s
[2K
| RMSProp | epoch: 002 | loss: 0.69174 - acc: 0.5541 -- iter: 0768/2147
[A[ATraining Step: 93  | total loss: [1m[32m0.69188[0m[0m | time: 17.428s
[2K
| RMSProp | epoch: 002 | loss: 0.69188 - acc: 0.5487 -- iter: 0800/2147
[A[ATraining Step: 94  | total loss: [1m[32m0.69197[0m[0m | time: 18.257s
[2K
| RMSProp | epoch: 002 | loss: 0.69197 - acc: 0.5438 -- iter: 0832/2147
[A[ATraining Step: 95  | total loss: [1m[32m0.69197[0m[0m | time: 19.161s
[2K
| RMSProp | epoch: 002 | loss: 0.69197 - acc: 0.5426 -- iter: 0864/2147
[A[ATraining Step: 96  | total loss: [1m[32m0.69264[0m[0m | time: 19.801s
[2K
| RMSProp | epoch: 002 | loss: 0.69264 - acc: 0.5258 -- iter: 0896/2147
[A[ATraining Step: 97  | total loss: [1m[32m0.69343[0m[0m | time: 20.405s
[2K
| RMSProp | epoch: 002 | loss: 0.69343 - acc: 0.5045 -- iter: 0928/2147
[A[ATraining Step: 98  | total loss: [1m[32m0.69332[0m[0m | time: 21.009s
[2K
| RMSProp | epoch: 002 | loss: 0.69332 - acc: 0.5071 -- iter: 0960/2147
[A[ATraining Step: 99  | total loss: [1m[32m0.69312[0m[0m | time: 21.610s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5127 -- iter: 0992/2147
[A[ATraining Step: 100  | total loss: [1m[32m0.69294[0m[0m | time: 22.393s
[2K
| RMSProp | epoch: 002 | loss: 0.69294 - acc: 0.5177 -- iter: 1024/2147
[A[ATraining Step: 101  | total loss: [1m[32m0.69315[0m[0m | time: 23.257s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5096 -- iter: 1056/2147
[A[ATraining Step: 102  | total loss: [1m[32m0.69296[0m[0m | time: 24.014s
[2K
| RMSProp | epoch: 002 | loss: 0.69296 - acc: 0.5149 -- iter: 1088/2147
[A[ATraining Step: 103  | total loss: [1m[32m0.69264[0m[0m | time: 24.795s
[2K
| RMSProp | epoch: 002 | loss: 0.69264 - acc: 0.5228 -- iter: 1120/2147
[A[ATraining Step: 104  | total loss: [1m[32m0.69237[0m[0m | time: 25.479s
[2K
| RMSProp | epoch: 002 | loss: 0.69237 - acc: 0.5299 -- iter: 1152/2147
[A[ATraining Step: 105  | total loss: [1m[32m0.69178[0m[0m | time: 26.271s
[2K
| RMSProp | epoch: 002 | loss: 0.69178 - acc: 0.5425 -- iter: 1184/2147
[A[ATraining Step: 106  | total loss: [1m[32m0.69209[0m[0m | time: 27.033s
[2K
| RMSProp | epoch: 002 | loss: 0.69209 - acc: 0.5352 -- iter: 1216/2147
[A[ATraining Step: 107  | total loss: [1m[32m0.69203[0m[0m | time: 27.828s
[2K
| RMSProp | epoch: 002 | loss: 0.69203 - acc: 0.5348 -- iter: 1248/2147
[A[ATraining Step: 108  | total loss: [1m[32m0.69220[0m[0m | time: 28.603s
[2K
| RMSProp | epoch: 002 | loss: 0.69220 - acc: 0.5313 -- iter: 1280/2147
[A[ATraining Step: 109  | total loss: [1m[32m0.69215[0m[0m | time: 29.446s
[2K
| RMSProp | epoch: 002 | loss: 0.69215 - acc: 0.5313 -- iter: 1312/2147
[A[ATraining Step: 110  | total loss: [1m[32m0.69190[0m[0m | time: 30.215s
[2K
| RMSProp | epoch: 002 | loss: 0.69190 - acc: 0.5344 -- iter: 1344/2147
[A[ATraining Step: 111  | total loss: [1m[32m0.69226[0m[0m | time: 30.942s
[2K
| RMSProp | epoch: 002 | loss: 0.69226 - acc: 0.5278 -- iter: 1376/2147
[A[ATraining Step: 112  | total loss: [1m[32m0.69147[0m[0m | time: 31.715s
[2K
| RMSProp | epoch: 002 | loss: 0.69147 - acc: 0.5407 -- iter: 1408/2147
[A[ATraining Step: 113  | total loss: [1m[32m0.69140[0m[0m | time: 32.526s
[2K
| RMSProp | epoch: 002 | loss: 0.69140 - acc: 0.5397 -- iter: 1440/2147
[A[ATraining Step: 114  | total loss: [1m[32m0.69116[0m[0m | time: 33.162s
[2K
| RMSProp | epoch: 002 | loss: 0.69116 - acc: 0.5420 -- iter: 1472/2147
[A[ATraining Step: 115  | total loss: [1m[32m0.69192[0m[0m | time: 33.766s
[2K
| RMSProp | epoch: 002 | loss: 0.69192 - acc: 0.5316 -- iter: 1504/2147
[A[ATraining Step: 116  | total loss: [1m[32m0.69083[0m[0m | time: 34.378s
[2K
| RMSProp | epoch: 002 | loss: 0.69083 - acc: 0.5472 -- iter: 1536/2147
[A[ATraining Step: 117  | total loss: [1m[32m0.69020[0m[0m | time: 34.992s
[2K
| RMSProp | epoch: 002 | loss: 0.69020 - acc: 0.5518 -- iter: 1568/2147
[A[ATraining Step: 118  | total loss: [1m[32m0.69099[0m[0m | time: 35.594s
[2K
| RMSProp | epoch: 002 | loss: 0.69099 - acc: 0.5435 -- iter: 1600/2147
[A[ATraining Step: 119  | total loss: [1m[32m0.69254[0m[0m | time: 36.309s
[2K
| RMSProp | epoch: 002 | loss: 0.69254 - acc: 0.5267 -- iter: 1632/2147
[A[ATraining Step: 120  | total loss: [1m[32m0.69269[0m[0m | time: 37.013s
[2K
| RMSProp | epoch: 002 | loss: 0.69269 - acc: 0.5240 -- iter: 1664/2147
[A[ATraining Step: 121  | total loss: [1m[32m0.69226[0m[0m | time: 37.740s
[2K
| RMSProp | epoch: 002 | loss: 0.69226 - acc: 0.5310 -- iter: 1696/2147
[A[ATraining Step: 122  | total loss: [1m[32m0.69260[0m[0m | time: 38.469s
[2K
| RMSProp | epoch: 002 | loss: 0.69260 - acc: 0.5247 -- iter: 1728/2147
[A[ATraining Step: 123  | total loss: [1m[32m0.69253[0m[0m | time: 39.274s
[2K
| RMSProp | epoch: 002 | loss: 0.69253 - acc: 0.5254 -- iter: 1760/2147
[A[ATraining Step: 124  | total loss: [1m[32m0.69284[0m[0m | time: 39.876s
[2K
| RMSProp | epoch: 002 | loss: 0.69284 - acc: 0.5197 -- iter: 1792/2147
[A[ATraining Step: 125  | total loss: [1m[32m0.69311[0m[0m | time: 40.502s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5146 -- iter: 1824/2147
[A[ATraining Step: 126  | total loss: [1m[32m0.69297[0m[0m | time: 41.136s
[2K
| RMSProp | epoch: 002 | loss: 0.69297 - acc: 0.5163 -- iter: 1856/2147
[A[ATraining Step: 127  | total loss: [1m[32m0.69323[0m[0m | time: 41.857s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.5115 -- iter: 1888/2147
[A[ATraining Step: 128  | total loss: [1m[32m0.69381[0m[0m | time: 42.631s
[2K
| RMSProp | epoch: 002 | loss: 0.69381 - acc: 0.5010 -- iter: 1920/2147
[A[ATraining Step: 129  | total loss: [1m[32m0.69300[0m[0m | time: 43.353s
[2K
| RMSProp | epoch: 002 | loss: 0.69300 - acc: 0.5228 -- iter: 1952/2147
[A[ATraining Step: 130  | total loss: [1m[32m0.69269[0m[0m | time: 44.073s
[2K
| RMSProp | epoch: 002 | loss: 0.69269 - acc: 0.5268 -- iter: 1984/2147
[A[ATraining Step: 131  | total loss: [1m[32m0.69238[0m[0m | time: 44.796s
[2K
| RMSProp | epoch: 002 | loss: 0.69238 - acc: 0.5303 -- iter: 2016/2147
[A[ATraining Step: 132  | total loss: [1m[32m0.69303[0m[0m | time: 45.541s
[2K
| RMSProp | epoch: 002 | loss: 0.69303 - acc: 0.5210 -- iter: 2048/2147
[A[ATraining Step: 133  | total loss: [1m[32m0.69307[0m[0m | time: 46.294s
[2K
| RMSProp | epoch: 002 | loss: 0.69307 - acc: 0.5189 -- iter: 2080/2147
[A[ATraining Step: 134  | total loss: [1m[32m0.69291[0m[0m | time: 47.028s
[2K
| RMSProp | epoch: 002 | loss: 0.69291 - acc: 0.5202 -- iter: 2112/2147
[A[ATraining Step: 135  | total loss: [1m[32m0.69237[0m[0m | time: 47.738s
[2K
| RMSProp | epoch: 002 | loss: 0.69237 - acc: 0.5275 -- iter: 2144/2147
[A[ATraining Step: 136  | total loss: [1m[32m0.69207[0m[0m | time: 50.913s
[2K
| RMSProp | epoch: 002 | loss: 0.69207 - acc: 0.5310 | val_loss: 0.68884 - val_acc: 0.5461 -- iter: 2147/2147
--
Training Step: 137  | total loss: [1m[32m0.69083[0m[0m | time: 0.157s
[2K
| RMSProp | epoch: 003 | loss: 0.69083 - acc: 0.5436 -- iter: 0032/2147
[A[ATraining Step: 138  | total loss: [1m[32m0.69321[0m[0m | time: 0.267s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.5225 -- iter: 0064/2147
[A[ATraining Step: 139  | total loss: [1m[32m0.69437[0m[0m | time: 1.017s
[2K
| RMSProp | epoch: 003 | loss: 0.69437 - acc: 0.5036 -- iter: 0096/2147
[A[ATraining Step: 140  | total loss: [1m[32m0.69352[0m[0m | time: 1.758s
[2K
| RMSProp | epoch: 003 | loss: 0.69352 - acc: 0.5189 -- iter: 0128/2147
[A[ATraining Step: 141  | total loss: [1m[32m0.69330[0m[0m | time: 2.500s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.5201 -- iter: 0160/2147
[A[ATraining Step: 142  | total loss: [1m[32m0.69272[0m[0m | time: 3.220s
[2K
| RMSProp | epoch: 003 | loss: 0.69272 - acc: 0.5275 -- iter: 0192/2147
[A[ATraining Step: 143  | total loss: [1m[32m0.69334[0m[0m | time: 3.980s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.5185 -- iter: 0224/2147
[A[ATraining Step: 144  | total loss: [1m[32m0.69337[0m[0m | time: 4.700s
[2K
| RMSProp | epoch: 003 | loss: 0.69337 - acc: 0.5166 -- iter: 0256/2147
[A[ATraining Step: 145  | total loss: [1m[32m0.69301[0m[0m | time: 5.453s
[2K
| RMSProp | epoch: 003 | loss: 0.69301 - acc: 0.5212 -- iter: 0288/2147
[A[ATraining Step: 146  | total loss: [1m[32m0.69328[0m[0m | time: 6.195s
[2K
| RMSProp | epoch: 003 | loss: 0.69328 - acc: 0.5160 -- iter: 0320/2147
[A[ATraining Step: 147  | total loss: [1m[32m0.69253[0m[0m | time: 6.911s
[2K
| RMSProp | epoch: 003 | loss: 0.69253 - acc: 0.5269 -- iter: 0352/2147
[A[ATraining Step: 148  | total loss: [1m[32m0.69301[0m[0m | time: 7.635s
[2K
| RMSProp | epoch: 003 | loss: 0.69301 - acc: 0.5211 -- iter: 0384/2147
[A[ATraining Step: 149  | total loss: [1m[32m0.69389[0m[0m | time: 8.322s
[2K
| RMSProp | epoch: 003 | loss: 0.69389 - acc: 0.5065 -- iter: 0416/2147
[A[ATraining Step: 150  | total loss: [1m[32m0.69396[0m[0m | time: 9.037s
[2K
| RMSProp | epoch: 003 | loss: 0.69396 - acc: 0.5027 -- iter: 0448/2147
[A[ATraining Step: 151  | total loss: [1m[32m0.69412[0m[0m | time: 9.870s
[2K
| RMSProp | epoch: 003 | loss: 0.69412 - acc: 0.4962 -- iter: 0480/2147
[A[ATraining Step: 152  | total loss: [1m[32m0.69406[0m[0m | time: 10.472s
[2K
| RMSProp | epoch: 003 | loss: 0.69406 - acc: 0.4965 -- iter: 0512/2147
[A[ATraining Step: 153  | total loss: [1m[32m0.69385[0m[0m | time: 11.106s
[2K
| RMSProp | epoch: 003 | loss: 0.69385 - acc: 0.5000 -- iter: 0544/2147
[A[ATraining Step: 154  | total loss: [1m[32m0.69337[0m[0m | time: 11.737s
[2K
| RMSProp | epoch: 003 | loss: 0.69337 - acc: 0.5125 -- iter: 0576/2147
[A[ATraining Step: 155  | total loss: [1m[32m0.69276[0m[0m | time: 12.350s
[2K
| RMSProp | epoch: 003 | loss: 0.69276 - acc: 0.5238 -- iter: 0608/2147
[A[ATraining Step: 156  | total loss: [1m[32m0.69355[0m[0m | time: 12.992s
[2K
| RMSProp | epoch: 003 | loss: 0.69355 - acc: 0.5120 -- iter: 0640/2147
[A[ATraining Step: 157  | total loss: [1m[32m0.69324[0m[0m | time: 13.650s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.5171 -- iter: 0672/2147
[A[ATraining Step: 158  | total loss: [1m[32m0.69308[0m[0m | time: 14.427s
[2K
| RMSProp | epoch: 003 | loss: 0.69308 - acc: 0.5185 -- iter: 0704/2147
[A[ATraining Step: 159  | total loss: [1m[32m0.69349[0m[0m | time: 15.180s
[2K
| RMSProp | epoch: 003 | loss: 0.69349 - acc: 0.5104 -- iter: 0736/2147
[A[ATraining Step: 160  | total loss: [1m[32m0.69289[0m[0m | time: 15.914s
[2K
| RMSProp | epoch: 003 | loss: 0.69289 - acc: 0.5218 -- iter: 0768/2147
[A[ATraining Step: 161  | total loss: [1m[32m0.69352[0m[0m | time: 16.681s
[2K
| RMSProp | epoch: 003 | loss: 0.69352 - acc: 0.5103 -- iter: 0800/2147
[A[ATraining Step: 162  | total loss: [1m[32m0.69405[0m[0m | time: 17.423s
[2K
| RMSProp | epoch: 003 | loss: 0.69405 - acc: 0.4968 -- iter: 0832/2147
[A[ATraining Step: 163  | total loss: [1m[32m0.69359[0m[0m | time: 18.189s
[2K
| RMSProp | epoch: 003 | loss: 0.69359 - acc: 0.5096 -- iter: 0864/2147
[A[ATraining Step: 164  | total loss: [1m[32m0.69345[0m[0m | time: 18.931s
[2K
| RMSProp | epoch: 003 | loss: 0.69345 - acc: 0.5117 -- iter: 0896/2147
[A[ATraining Step: 165  | total loss: [1m[32m0.69306[0m[0m | time: 19.673s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5199 -- iter: 0928/2147
[A[ATraining Step: 166  | total loss: [1m[32m0.69342[0m[0m | time: 20.390s
[2K
| RMSProp | epoch: 003 | loss: 0.69342 - acc: 0.5117 -- iter: 0960/2147
[A[ATraining Step: 167  | total loss: [1m[32m0.69393[0m[0m | time: 21.143s
[2K
| RMSProp | epoch: 003 | loss: 0.69393 - acc: 0.4980 -- iter: 0992/2147
[A[ATraining Step: 168  | total loss: [1m[32m0.69395[0m[0m | time: 21.877s
[2K
| RMSProp | epoch: 003 | loss: 0.69395 - acc: 0.4951 -- iter: 1024/2147
[A[ATraining Step: 169  | total loss: [1m[32m0.69378[0m[0m | time: 22.580s
[2K
| RMSProp | epoch: 003 | loss: 0.69378 - acc: 0.4987 -- iter: 1056/2147
[A[ATraining Step: 170  | total loss: [1m[32m0.69436[0m[0m | time: 23.284s
[2K
| RMSProp | epoch: 003 | loss: 0.69436 - acc: 0.4770 -- iter: 1088/2147
[A[ATraining Step: 171  | total loss: [1m[32m0.69414[0m[0m | time: 24.120s
[2K
| RMSProp | epoch: 003 | loss: 0.69414 - acc: 0.4855 -- iter: 1120/2147
[A[ATraining Step: 172  | total loss: [1m[32m0.69412[0m[0m | time: 24.726s
[2K
| RMSProp | epoch: 003 | loss: 0.69412 - acc: 0.4838 -- iter: 1152/2147
[A[ATraining Step: 173  | total loss: [1m[32m0.69378[0m[0m | time: 25.336s
[2K
| RMSProp | epoch: 003 | loss: 0.69378 - acc: 0.4980 -- iter: 1184/2147
[A[ATraining Step: 174  | total loss: [1m[32m0.69353[0m[0m | time: 26.041s
[2K
| RMSProp | epoch: 003 | loss: 0.69353 - acc: 0.5044 -- iter: 1216/2147
[A[ATraining Step: 175  | total loss: [1m[32m0.69364[0m[0m | time: 26.729s
[2K
| RMSProp | epoch: 003 | loss: 0.69364 - acc: 0.5008 -- iter: 1248/2147
[A[ATraining Step: 176  | total loss: [1m[32m0.69311[0m[0m | time: 27.434s
[2K
| RMSProp | epoch: 003 | loss: 0.69311 - acc: 0.5164 -- iter: 1280/2147
[A[ATraining Step: 177  | total loss: [1m[32m0.69282[0m[0m | time: 28.134s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5210 -- iter: 1312/2147
[A[ATraining Step: 178  | total loss: [1m[32m0.69268[0m[0m | time: 28.842s
[2K
| RMSProp | epoch: 003 | loss: 0.69268 - acc: 0.5220 -- iter: 1344/2147
[A[ATraining Step: 179  | total loss: [1m[32m0.69306[0m[0m | time: 29.553s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5167 -- iter: 1376/2147
[A[ATraining Step: 180  | total loss: [1m[32m0.69322[0m[0m | time: 30.282s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.5119 -- iter: 1408/2147
[A[ATraining Step: 181  | total loss: [1m[32m0.69278[0m[0m | time: 31.058s
[2K
| RMSProp | epoch: 003 | loss: 0.69278 - acc: 0.5232 -- iter: 1440/2147
[A[ATraining Step: 182  | total loss: [1m[32m0.69379[0m[0m | time: 31.809s
[2K
| RMSProp | epoch: 003 | loss: 0.69379 - acc: 0.5053 -- iter: 1472/2147
[A[ATraining Step: 183  | total loss: [1m[32m0.69346[0m[0m | time: 32.565s
[2K
| RMSProp | epoch: 003 | loss: 0.69346 - acc: 0.5141 -- iter: 1504/2147
[A[ATraining Step: 184  | total loss: [1m[32m0.69356[0m[0m | time: 33.269s
[2K
| RMSProp | epoch: 003 | loss: 0.69356 - acc: 0.5096 -- iter: 1536/2147
[A[ATraining Step: 185  | total loss: [1m[32m0.69343[0m[0m | time: 33.995s
[2K
| RMSProp | epoch: 003 | loss: 0.69343 - acc: 0.5117 -- iter: 1568/2147
[A[ATraining Step: 186  | total loss: [1m[32m0.69311[0m[0m | time: 34.710s
[2K
| RMSProp | epoch: 003 | loss: 0.69311 - acc: 0.5199 -- iter: 1600/2147
[A[ATraining Step: 187  | total loss: [1m[32m0.69329[0m[0m | time: 35.444s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.5148 -- iter: 1632/2147
[A[ATraining Step: 188  | total loss: [1m[32m0.69294[0m[0m | time: 36.237s
[2K
| RMSProp | epoch: 003 | loss: 0.69294 - acc: 0.5227 -- iter: 1664/2147
[A[ATraining Step: 189  | total loss: [1m[32m0.69256[0m[0m | time: 36.856s
[2K
| RMSProp | epoch: 003 | loss: 0.69256 - acc: 0.5298 -- iter: 1696/2147
[A[ATraining Step: 190  | total loss: [1m[32m0.69246[0m[0m | time: 37.469s
[2K
| RMSProp | epoch: 003 | loss: 0.69246 - acc: 0.5300 -- iter: 1728/2147
[A[ATraining Step: 191  | total loss: [1m[32m0.69294[0m[0m | time: 38.073s
[2K
| RMSProp | epoch: 003 | loss: 0.69294 - acc: 0.5207 -- iter: 1760/2147
[A[ATraining Step: 192  | total loss: [1m[32m0.69298[0m[0m | time: 38.675s
[2K
| RMSProp | epoch: 003 | loss: 0.69298 - acc: 0.5186 -- iter: 1792/2147
[A[ATraining Step: 193  | total loss: [1m[32m0.69288[0m[0m | time: 39.308s
[2K
| RMSProp | epoch: 003 | loss: 0.69288 - acc: 0.5199 -- iter: 1824/2147
[A[ATraining Step: 194  | total loss: [1m[32m0.69235[0m[0m | time: 40.009s
[2K
| RMSProp | epoch: 003 | loss: 0.69235 - acc: 0.5304 -- iter: 1856/2147
[A[ATraining Step: 195  | total loss: [1m[32m0.69227[0m[0m | time: 40.697s
[2K
| RMSProp | epoch: 003 | loss: 0.69227 - acc: 0.5305 -- iter: 1888/2147
[A[ATraining Step: 196  | total loss: [1m[32m0.69199[0m[0m | time: 41.395s
[2K
| RMSProp | epoch: 003 | loss: 0.69199 - acc: 0.5337 -- iter: 1920/2147
[A[ATraining Step: 197  | total loss: [1m[32m0.69271[0m[0m | time: 42.152s
[2K
| RMSProp | epoch: 003 | loss: 0.69271 - acc: 0.5241 -- iter: 1952/2147
[A[ATraining Step: 198  | total loss: [1m[32m0.69264[0m[0m | time: 42.925s
[2K
| RMSProp | epoch: 003 | loss: 0.69264 - acc: 0.5248 -- iter: 1984/2147
[A[ATraining Step: 199  | total loss: [1m[32m0.69272[0m[0m | time: 43.689s
[2K
| RMSProp | epoch: 003 | loss: 0.69272 - acc: 0.5223 -- iter: 2016/2147
[A[ATraining Step: 200  | total loss: [1m[32m0.69281[0m[0m | time: 47.014s
[2K
| RMSProp | epoch: 003 | loss: 0.69281 - acc: 0.5201 | val_loss: 0.69104 - val_acc: 0.5461 -- iter: 2048/2147
--
Training Step: 201  | total loss: [1m[32m0.69288[0m[0m | time: 47.738s
[2K
| RMSProp | epoch: 003 | loss: 0.69288 - acc: 0.5181 -- iter: 2080/2147
[A[ATraining Step: 202  | total loss: [1m[32m0.69391[0m[0m | time: 48.457s
[2K
| RMSProp | epoch: 003 | loss: 0.69391 - acc: 0.4975 -- iter: 2112/2147
[A[ATraining Step: 203  | total loss: [1m[32m0.69363[0m[0m | time: 49.218s
[2K
| RMSProp | epoch: 003 | loss: 0.69363 - acc: 0.5040 -- iter: 2144/2147
[A[ATraining Step: 204  | total loss: [1m[32m0.69372[0m[0m | time: 52.147s
[2K
| RMSProp | epoch: 003 | loss: 0.69372 - acc: 0.5005 | val_loss: 0.69158 - val_acc: 0.5461 -- iter: 2147/2147
--
Training Step: 205  | total loss: [1m[32m0.69356[0m[0m | time: 0.699s
[2K
| RMSProp | epoch: 004 | loss: 0.69356 - acc: 0.5036 -- iter: 0032/2147
[A[ATraining Step: 206  | total loss: [1m[32m0.69377[0m[0m | time: 0.805s
[2K
| RMSProp | epoch: 004 | loss: 0.69377 - acc: 0.4970 -- iter: 0064/2147
[A[ATraining Step: 207  | total loss: [1m[32m0.69426[0m[0m | time: 0.890s
[2K
| RMSProp | epoch: 004 | loss: 0.69426 - acc: 0.4806 -- iter: 0096/2147
[A[ATraining Step: 208  | total loss: [1m[32m0.69451[0m[0m | time: 1.702s
[2K
| RMSProp | epoch: 004 | loss: 0.69451 - acc: 0.4659 -- iter: 0128/2147
[A[ATraining Step: 209  | total loss: [1m[32m0.69432[0m[0m | time: 2.460s
[2K
| RMSProp | epoch: 004 | loss: 0.69432 - acc: 0.4787 -- iter: 0160/2147
[A[ATraining Step: 210  | total loss: [1m[32m0.69407[0m[0m | time: 3.196s
[2K
| RMSProp | epoch: 004 | loss: 0.69407 - acc: 0.4870 -- iter: 0192/2147
[A[ATraining Step: 211  | total loss: [1m[32m0.69386[0m[0m | time: 3.948s
[2K
| RMSProp | epoch: 004 | loss: 0.69386 - acc: 0.4915 -- iter: 0224/2147
[A[ATraining Step: 212  | total loss: [1m[32m0.69402[0m[0m | time: 4.735s
[2K
| RMSProp | epoch: 004 | loss: 0.69402 - acc: 0.4892 -- iter: 0256/2147
[A[ATraining Step: 213  | total loss: [1m[32m0.69401[0m[0m | time: 5.504s
[2K
| RMSProp | epoch: 004 | loss: 0.69401 - acc: 0.4871 -- iter: 0288/2147
[A[ATraining Step: 214  | total loss: [1m[32m0.69372[0m[0m | time: 6.211s
[2K
| RMSProp | epoch: 004 | loss: 0.69372 - acc: 0.4978 -- iter: 0320/2147
[A[ATraining Step: 215  | total loss: [1m[32m0.69336[0m[0m | time: 6.945s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.5074 -- iter: 0352/2147
[A[ATraining Step: 216  | total loss: [1m[32m0.69320[0m[0m | time: 7.684s
[2K
| RMSProp | epoch: 004 | loss: 0.69320 - acc: 0.5098 -- iter: 0384/2147
[A[ATraining Step: 217  | total loss: [1m[32m0.69240[0m[0m | time: 8.433s
[2K
| RMSProp | epoch: 004 | loss: 0.69240 - acc: 0.5213 -- iter: 0416/2147
[A[ATraining Step: 218  | total loss: [1m[32m0.68866[0m[0m | time: 9.271s
[2K
| RMSProp | epoch: 004 | loss: 0.68866 - acc: 0.5379 -- iter: 0448/2147
[A[ATraining Step: 219  | total loss: [1m[32m0.70645[0m[0m | time: 9.889s
[2K
| RMSProp | epoch: 004 | loss: 0.70645 - acc: 0.5341 -- iter: 0480/2147
[A[ATraining Step: 220  | total loss: [1m[32m0.70431[0m[0m | time: 10.503s
[2K
| RMSProp | epoch: 004 | loss: 0.70431 - acc: 0.5370 -- iter: 0512/2147
[A[ATraining Step: 221  | total loss: [1m[32m0.70293[0m[0m | time: 11.211s
[2K
| RMSProp | epoch: 004 | loss: 0.70293 - acc: 0.5364 -- iter: 0544/2147
[A[ATraining Step: 222  | total loss: [1m[32m0.70184[0m[0m | time: 11.968s
[2K
| RMSProp | epoch: 004 | loss: 0.70184 - acc: 0.5359 -- iter: 0576/2147
[A[ATraining Step: 223  | total loss: [1m[32m0.69882[0m[0m | time: 12.733s
[2K
| RMSProp | epoch: 004 | loss: 0.69882 - acc: 0.5448 -- iter: 0608/2147
[A[ATraining Step: 224  | total loss: [1m[32m0.69804[0m[0m | time: 13.457s
[2K
| RMSProp | epoch: 004 | loss: 0.69804 - acc: 0.5434 -- iter: 0640/2147
[A[ATraining Step: 225  | total loss: [1m[32m0.69719[0m[0m | time: 14.168s
[2K
| RMSProp | epoch: 004 | loss: 0.69719 - acc: 0.5422 -- iter: 0672/2147
[A[ATraining Step: 226  | total loss: [1m[32m0.69660[0m[0m | time: 14.892s
[2K
| RMSProp | epoch: 004 | loss: 0.69660 - acc: 0.5411 -- iter: 0704/2147
[A[ATraining Step: 227  | total loss: [1m[32m0.69929[0m[0m | time: 15.629s
[2K
| RMSProp | epoch: 004 | loss: 0.69929 - acc: 0.5245 -- iter: 0736/2147
[A[ATraining Step: 228  | total loss: [1m[32m0.70072[0m[0m | time: 16.339s
[2K
| RMSProp | epoch: 004 | loss: 0.70072 - acc: 0.5064 -- iter: 0768/2147
[A[ATraining Step: 229  | total loss: [1m[32m0.70054[0m[0m | time: 17.068s
[2K
| RMSProp | epoch: 004 | loss: 0.70054 - acc: 0.4995 -- iter: 0800/2147
[A[ATraining Step: 230  | total loss: [1m[32m0.70044[0m[0m | time: 17.784s
[2K
| RMSProp | epoch: 004 | loss: 0.70044 - acc: 0.4871 -- iter: 0832/2147
[A[ATraining Step: 231  | total loss: [1m[32m0.69968[0m[0m | time: 18.495s
[2K
| RMSProp | epoch: 004 | loss: 0.69968 - acc: 0.5071 -- iter: 0864/2147
[A[ATraining Step: 232  | total loss: [1m[32m0.69892[0m[0m | time: 19.205s
[2K
| RMSProp | epoch: 004 | loss: 0.69892 - acc: 0.5095 -- iter: 0896/2147
[A[ATraining Step: 233  | total loss: [1m[32m0.69849[0m[0m | time: 19.937s
[2K
| RMSProp | epoch: 004 | loss: 0.69849 - acc: 0.5055 -- iter: 0928/2147
[A[ATraining Step: 234  | total loss: [1m[32m0.69777[0m[0m | time: 20.658s
[2K
| RMSProp | epoch: 004 | loss: 0.69777 - acc: 0.5143 -- iter: 0960/2147
[A[ATraining Step: 235  | total loss: [1m[32m0.69737[0m[0m | time: 21.512s
[2K
| RMSProp | epoch: 004 | loss: 0.69737 - acc: 0.5129 -- iter: 0992/2147
[A[ATraining Step: 236  | total loss: [1m[32m0.69663[0m[0m | time: 22.113s
[2K
| RMSProp | epoch: 004 | loss: 0.69663 - acc: 0.5178 -- iter: 1024/2147
[A[ATraining Step: 237  | total loss: [1m[32m0.69650[0m[0m | time: 22.728s
[2K
| RMSProp | epoch: 004 | loss: 0.69650 - acc: 0.5129 -- iter: 1056/2147
[A[ATraining Step: 238  | total loss: [1m[32m0.69600[0m[0m | time: 23.361s
[2K
| RMSProp | epoch: 004 | loss: 0.69600 - acc: 0.5148 -- iter: 1088/2147
[A[ATraining Step: 239  | total loss: [1m[32m0.69702[0m[0m | time: 24.036s
[2K
| RMSProp | epoch: 004 | loss: 0.69702 - acc: 0.4945 -- iter: 1120/2147
[A[ATraining Step: 240  | total loss: [1m[32m0.69661[0m[0m | time: 24.765s
[2K
| RMSProp | epoch: 004 | loss: 0.69661 - acc: 0.4982 -- iter: 1152/2147
[A[ATraining Step: 241  | total loss: [1m[32m0.69623[0m[0m | time: 25.482s
[2K
| RMSProp | epoch: 004 | loss: 0.69623 - acc: 0.5015 -- iter: 1184/2147
[A[ATraining Step: 242  | total loss: [1m[32m0.69555[0m[0m | time: 26.225s
[2K
| RMSProp | epoch: 004 | loss: 0.69555 - acc: 0.5170 -- iter: 1216/2147
[A[ATraining Step: 243  | total loss: [1m[32m0.69521[0m[0m | time: 26.995s
[2K
| RMSProp | epoch: 004 | loss: 0.69521 - acc: 0.5184 -- iter: 1248/2147
[A[ATraining Step: 244  | total loss: [1m[32m0.69483[0m[0m | time: 27.721s
[2K
| RMSProp | epoch: 004 | loss: 0.69483 - acc: 0.5197 -- iter: 1280/2147
[A[ATraining Step: 245  | total loss: [1m[32m0.69370[0m[0m | time: 28.447s
[2K
| RMSProp | epoch: 004 | loss: 0.69370 - acc: 0.5333 -- iter: 1312/2147
[A[ATraining Step: 246  | total loss: [1m[32m0.69339[0m[0m | time: 29.203s
[2K
| RMSProp | epoch: 004 | loss: 0.69339 - acc: 0.5331 -- iter: 1344/2147
[A[ATraining Step: 247  | total loss: [1m[32m0.69308[0m[0m | time: 29.926s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5329 -- iter: 1376/2147
[A[ATraining Step: 248  | total loss: [1m[32m0.69544[0m[0m | time: 30.656s
[2K
| RMSProp | epoch: 004 | loss: 0.69544 - acc: 0.5140 -- iter: 1408/2147
[A[ATraining Step: 249  | total loss: [1m[32m0.69556[0m[0m | time: 31.406s
[2K
| RMSProp | epoch: 004 | loss: 0.69556 - acc: 0.5033 -- iter: 1440/2147
[A[ATraining Step: 250  | total loss: [1m[32m0.69574[0m[0m | time: 32.172s
[2K
| RMSProp | epoch: 004 | loss: 0.69574 - acc: 0.4873 -- iter: 1472/2147
[A[ATraining Step: 251  | total loss: [1m[32m0.69536[0m[0m | time: 32.944s
[2K
| RMSProp | epoch: 004 | loss: 0.69536 - acc: 0.4979 -- iter: 1504/2147
[A[ATraining Step: 252  | total loss: [1m[32m0.69513[0m[0m | time: 33.665s
[2K
| RMSProp | epoch: 004 | loss: 0.69513 - acc: 0.4982 -- iter: 1536/2147
[A[ATraining Step: 253  | total loss: [1m[32m0.69502[0m[0m | time: 34.466s
[2K
| RMSProp | epoch: 004 | loss: 0.69502 - acc: 0.4921 -- iter: 1568/2147
[A[ATraining Step: 254  | total loss: [1m[32m0.69493[0m[0m | time: 35.065s
[2K
| RMSProp | epoch: 004 | loss: 0.69493 - acc: 0.4835 -- iter: 1600/2147
[A[ATraining Step: 255  | total loss: [1m[32m0.69474[0m[0m | time: 35.662s
[2K
| RMSProp | epoch: 004 | loss: 0.69474 - acc: 0.4789 -- iter: 1632/2147
[A[ATraining Step: 256  | total loss: [1m[32m0.69456[0m[0m | time: 36.288s
[2K
| RMSProp | epoch: 004 | loss: 0.69456 - acc: 0.4841 -- iter: 1664/2147
[A[ATraining Step: 257  | total loss: [1m[32m0.69443[0m[0m | time: 36.934s
[2K
| RMSProp | epoch: 004 | loss: 0.69443 - acc: 0.4826 -- iter: 1696/2147
[A[ATraining Step: 258  | total loss: [1m[32m0.69428[0m[0m | time: 37.619s
[2K
| RMSProp | epoch: 004 | loss: 0.69428 - acc: 0.4906 -- iter: 1728/2147
[A[ATraining Step: 259  | total loss: [1m[32m0.69390[0m[0m | time: 38.370s
[2K
| RMSProp | epoch: 004 | loss: 0.69390 - acc: 0.5197 -- iter: 1760/2147
[A[ATraining Step: 260  | total loss: [1m[32m0.69412[0m[0m | time: 39.097s
[2K
| RMSProp | epoch: 004 | loss: 0.69412 - acc: 0.5114 -- iter: 1792/2147
[A[ATraining Step: 261  | total loss: [1m[32m0.69366[0m[0m | time: 39.864s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.5228 -- iter: 1824/2147
[A[ATraining Step: 262  | total loss: [1m[32m0.69359[0m[0m | time: 40.640s
[2K
| RMSProp | epoch: 004 | loss: 0.69359 - acc: 0.5205 -- iter: 1856/2147
[A[ATraining Step: 263  | total loss: [1m[32m0.69216[0m[0m | time: 41.369s
[2K
| RMSProp | epoch: 004 | loss: 0.69216 - acc: 0.5435 -- iter: 1888/2147
[A[ATraining Step: 264  | total loss: [1m[32m0.69084[0m[0m | time: 42.062s
[2K
| RMSProp | epoch: 004 | loss: 0.69084 - acc: 0.5485 -- iter: 1920/2147
[A[ATraining Step: 265  | total loss: [1m[32m0.69531[0m[0m | time: 42.842s
[2K
| RMSProp | epoch: 004 | loss: 0.69531 - acc: 0.5343 -- iter: 1952/2147
[A[ATraining Step: 266  | total loss: [1m[32m0.69508[0m[0m | time: 43.616s
[2K
| RMSProp | epoch: 004 | loss: 0.69508 - acc: 0.5308 -- iter: 1984/2147
[A[ATraining Step: 267  | total loss: [1m[32m0.69472[0m[0m | time: 44.405s
[2K
| RMSProp | epoch: 004 | loss: 0.69472 - acc: 0.5309 -- iter: 2016/2147
[A[ATraining Step: 268  | total loss: [1m[32m0.69455[0m[0m | time: 45.151s
[2K
| RMSProp | epoch: 004 | loss: 0.69455 - acc: 0.5278 -- iter: 2048/2147
[A[ATraining Step: 269  | total loss: [1m[32m0.69364[0m[0m | time: 45.962s
[2K
| RMSProp | epoch: 004 | loss: 0.69364 - acc: 0.5375 -- iter: 2080/2147
[A[ATraining Step: 270  | total loss: [1m[32m0.69421[0m[0m | time: 46.740s
[2K
| RMSProp | epoch: 004 | loss: 0.69421 - acc: 0.5275 -- iter: 2112/2147
[A[ATraining Step: 271  | total loss: [1m[32m0.69464[0m[0m | time: 47.542s
[2K
| RMSProp | epoch: 004 | loss: 0.69464 - acc: 0.5154 -- iter: 2144/2147
[A[ATraining Step: 272  | total loss: [1m[32m0.69447[0m[0m | time: 50.509s
[2K
| RMSProp | epoch: 004 | loss: 0.69447 - acc: 0.5138 | val_loss: 0.69064 - val_acc: 0.5461 -- iter: 2147/2147
--
Training Step: 273  | total loss: [1m[32m0.69417[0m[0m | time: 0.820s
[2K
| RMSProp | epoch: 005 | loss: 0.69417 - acc: 0.5156 -- iter: 0032/2147
[A[ATraining Step: 274  | total loss: [1m[32m0.69454[0m[0m | time: 1.588s
[2K
| RMSProp | epoch: 005 | loss: 0.69454 - acc: 0.5047 -- iter: 0064/2147
[A[ATraining Step: 275  | total loss: [1m[32m0.69446[0m[0m | time: 1.733s
[2K
| RMSProp | epoch: 005 | loss: 0.69446 - acc: 0.5011 -- iter: 0096/2147
[A[ATraining Step: 276  | total loss: [1m[32m0.69466[0m[0m | time: 1.857s
[2K
| RMSProp | epoch: 005 | loss: 0.69466 - acc: 0.4843 -- iter: 0128/2147
[A[ATraining Step: 277  | total loss: [1m[32m0.69458[0m[0m | time: 2.592s
[2K
| RMSProp | epoch: 005 | loss: 0.69458 - acc: 0.4692 -- iter: 0160/2147
[A[ATraining Step: 278  | total loss: [1m[32m0.69439[0m[0m | time: 3.293s
[2K
| RMSProp | epoch: 005 | loss: 0.69439 - acc: 0.4817 -- iter: 0192/2147
[A[ATraining Step: 279  | total loss: [1m[32m0.69437[0m[0m | time: 3.987s
[2K
| RMSProp | epoch: 005 | loss: 0.69437 - acc: 0.4710 -- iter: 0224/2147
[A[ATraining Step: 280  | total loss: [1m[32m0.69421[0m[0m | time: 4.714s
[2K
| RMSProp | epoch: 005 | loss: 0.69421 - acc: 0.4958 -- iter: 0256/2147
[A[ATraining Step: 281  | total loss: [1m[32m0.69424[0m[0m | time: 5.452s
[2K
| RMSProp | epoch: 005 | loss: 0.69424 - acc: 0.4712 -- iter: 0288/2147
[A[ATraining Step: 282  | total loss: [1m[32m0.69411[0m[0m | time: 6.177s
[2K
| RMSProp | epoch: 005 | loss: 0.69411 - acc: 0.4741 -- iter: 0320/2147
[A[ATraining Step: 283  | total loss: [1m[32m0.69389[0m[0m | time: 6.921s
[2K
| RMSProp | epoch: 005 | loss: 0.69389 - acc: 0.4829 -- iter: 0352/2147
[A[ATraining Step: 284  | total loss: [1m[32m0.69378[0m[0m | time: 7.689s
[2K
| RMSProp | epoch: 005 | loss: 0.69378 - acc: 0.4815 -- iter: 0384/2147
[A[ATraining Step: 285  | total loss: [1m[32m0.69363[0m[0m | time: 8.462s
[2K
| RMSProp | epoch: 005 | loss: 0.69363 - acc: 0.4833 -- iter: 0416/2147
[A[ATraining Step: 286  | total loss: [1m[32m0.69332[0m[0m | time: 9.280s
[2K
| RMSProp | epoch: 005 | loss: 0.69332 - acc: 0.4913 -- iter: 0448/2147
[A[ATraining Step: 287  | total loss: [1m[32m0.69357[0m[0m | time: 9.899s
[2K
| RMSProp | epoch: 005 | loss: 0.69357 - acc: 0.4859 -- iter: 0480/2147
[A[ATraining Step: 288  | total loss: [1m[32m0.69353[0m[0m | time: 10.544s
[2K
| RMSProp | epoch: 005 | loss: 0.69353 - acc: 0.4842 -- iter: 0512/2147
[A[ATraining Step: 289  | total loss: [1m[32m0.69321[0m[0m | time: 11.263s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.4983 -- iter: 0544/2147
[A[ATraining Step: 290  | total loss: [1m[32m0.69308[0m[0m | time: 11.987s
[2K
| RMSProp | epoch: 005 | loss: 0.69308 - acc: 0.4984 -- iter: 0576/2147
[A[ATraining Step: 291  | total loss: [1m[32m0.69244[0m[0m | time: 12.764s
[2K
| RMSProp | epoch: 005 | loss: 0.69244 - acc: 0.5080 -- iter: 0608/2147
[A[ATraining Step: 292  | total loss: [1m[32m0.69470[0m[0m | time: 13.522s
[2K
| RMSProp | epoch: 005 | loss: 0.69470 - acc: 0.4915 -- iter: 0640/2147
[A[ATraining Step: 293  | total loss: [1m[32m0.69439[0m[0m | time: 14.299s
[2K
| RMSProp | epoch: 005 | loss: 0.69439 - acc: 0.4986 -- iter: 0672/2147
[A[ATraining Step: 294  | total loss: [1m[32m0.69421[0m[0m | time: 15.108s
[2K
| RMSProp | epoch: 005 | loss: 0.69421 - acc: 0.4988 -- iter: 0704/2147
[A[ATraining Step: 295  | total loss: [1m[32m0.69367[0m[0m | time: 15.880s
[2K
| RMSProp | epoch: 005 | loss: 0.69367 - acc: 0.5145 -- iter: 0736/2147
[A[ATraining Step: 296  | total loss: [1m[32m0.69348[0m[0m | time: 16.624s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.5131 -- iter: 0768/2147
[A[ATraining Step: 297  | total loss: [1m[32m0.69308[0m[0m | time: 17.373s
[2K
| RMSProp | epoch: 005 | loss: 0.69308 - acc: 0.5180 -- iter: 0800/2147
[A[ATraining Step: 298  | total loss: [1m[32m0.69179[0m[0m | time: 18.122s
[2K
| RMSProp | epoch: 005 | loss: 0.69179 - acc: 0.5350 -- iter: 0832/2147
[A[ATraining Step: 299  | total loss: [1m[32m0.69250[0m[0m | time: 18.861s
[2K
| RMSProp | epoch: 005 | loss: 0.69250 - acc: 0.5283 -- iter: 0864/2147
[A[ATraining Step: 300  | total loss: [1m[32m0.69104[0m[0m | time: 19.589s
[2K
| RMSProp | epoch: 005 | loss: 0.69104 - acc: 0.5411 -- iter: 0896/2147
[A[ATraining Step: 301  | total loss: [1m[32m0.69215[0m[0m | time: 20.353s
[2K
| RMSProp | epoch: 005 | loss: 0.69215 - acc: 0.5339 -- iter: 0928/2147
[A[ATraining Step: 302  | total loss: [1m[32m0.69229[0m[0m | time: 21.107s
[2K
| RMSProp | epoch: 005 | loss: 0.69229 - acc: 0.5305 -- iter: 0960/2147
[A[ATraining Step: 303  | total loss: [1m[32m0.69175[0m[0m | time: 21.967s
[2K
| RMSProp | epoch: 005 | loss: 0.69175 - acc: 0.5337 -- iter: 0992/2147
[A[ATraining Step: 304  | total loss: [1m[32m0.69339[0m[0m | time: 22.591s
[2K
| RMSProp | epoch: 005 | loss: 0.69339 - acc: 0.5178 -- iter: 1024/2147
[A[ATraining Step: 305  | total loss: [1m[32m0.69276[0m[0m | time: 23.286s
[2K
| RMSProp | epoch: 005 | loss: 0.69276 - acc: 0.5254 -- iter: 1056/2147
[A[ATraining Step: 306  | total loss: [1m[32m0.69265[0m[0m | time: 24.052s
[2K
| RMSProp | epoch: 005 | loss: 0.69265 - acc: 0.5229 -- iter: 1088/2147
[A[ATraining Step: 307  | total loss: [1m[32m0.69218[0m[0m | time: 24.834s
[2K
| RMSProp | epoch: 005 | loss: 0.69218 - acc: 0.5268 -- iter: 1120/2147
[A[ATraining Step: 308  | total loss: [1m[32m0.69360[0m[0m | time: 25.614s
[2K
| RMSProp | epoch: 005 | loss: 0.69360 - acc: 0.5085 -- iter: 1152/2147
[A[ATraining Step: 309  | total loss: [1m[32m0.69312[0m[0m | time: 26.359s
[2K
| RMSProp | epoch: 005 | loss: 0.69312 - acc: 0.5171 -- iter: 1184/2147
[A[ATraining Step: 310  | total loss: [1m[32m0.69209[0m[0m | time: 27.090s
[2K
| RMSProp | epoch: 005 | loss: 0.69209 - acc: 0.5341 -- iter: 1216/2147
[A[ATraining Step: 311  | total loss: [1m[32m0.69120[0m[0m | time: 27.855s
[2K
| RMSProp | epoch: 005 | loss: 0.69120 - acc: 0.5369 -- iter: 1248/2147
[A[ATraining Step: 312  | total loss: [1m[32m0.69299[0m[0m | time: 28.600s
[2K
| RMSProp | epoch: 005 | loss: 0.69299 - acc: 0.5239 -- iter: 1280/2147
[A[ATraining Step: 313  | total loss: [1m[32m0.69311[0m[0m | time: 29.335s
[2K
| RMSProp | epoch: 005 | loss: 0.69311 - acc: 0.5152 -- iter: 1312/2147
[A[ATraining Step: 314  | total loss: [1m[32m0.69292[0m[0m | time: 30.054s
[2K
| RMSProp | epoch: 005 | loss: 0.69292 - acc: 0.5137 -- iter: 1344/2147
[A[ATraining Step: 315  | total loss: [1m[32m0.69268[0m[0m | time: 30.835s
[2K
| RMSProp | epoch: 005 | loss: 0.69268 - acc: 0.5123 -- iter: 1376/2147
[A[ATraining Step: 316  | total loss: [1m[32m0.69319[0m[0m | time: 31.604s
[2K
| RMSProp | epoch: 005 | loss: 0.69319 - acc: 0.4955 -- iter: 1408/2147
[A[ATraining Step: 317  | total loss: [1m[32m0.69314[0m[0m | time: 32.379s
[2K
| RMSProp | epoch: 005 | loss: 0.69314 - acc: 0.4991 -- iter: 1440/2147
[A[ATraining Step: 318  | total loss: [1m[32m0.69299[0m[0m | time: 33.166s
[2K
| RMSProp | epoch: 005 | loss: 0.69299 - acc: 0.4992 -- iter: 1472/2147
[A[ATraining Step: 319  | total loss: [1m[32m0.69290[0m[0m | time: 34.061s
[2K
| RMSProp | epoch: 005 | loss: 0.69290 - acc: 0.4930 -- iter: 1504/2147
[A[ATraining Step: 320  | total loss: [1m[32m0.69269[0m[0m | time: 34.668s
[2K
| RMSProp | epoch: 005 | loss: 0.69269 - acc: 0.5187 -- iter: 1536/2147
[A[ATraining Step: 321  | total loss: [1m[32m0.69258[0m[0m | time: 35.291s
[2K
| RMSProp | epoch: 005 | loss: 0.69258 - acc: 0.5137 -- iter: 1568/2147
[A[ATraining Step: 322  | total loss: [1m[32m0.69210[0m[0m | time: 35.993s
[2K
| RMSProp | epoch: 005 | loss: 0.69210 - acc: 0.5154 -- iter: 1600/2147
[A[ATraining Step: 323  | total loss: [1m[32m0.69155[0m[0m | time: 36.722s
[2K
| RMSProp | epoch: 005 | loss: 0.69155 - acc: 0.5170 -- iter: 1632/2147
[A[ATraining Step: 324  | total loss: [1m[32m0.69125[0m[0m | time: 37.430s
[2K
| RMSProp | epoch: 005 | loss: 0.69125 - acc: 0.5153 -- iter: 1664/2147
[A[ATraining Step: 325  | total loss: [1m[32m0.69141[0m[0m | time: 38.208s
[2K
| RMSProp | epoch: 005 | loss: 0.69141 - acc: 0.5044 -- iter: 1696/2147
[A[ATraining Step: 326  | total loss: [1m[32m0.69112[0m[0m | time: 38.926s
[2K
| RMSProp | epoch: 005 | loss: 0.69112 - acc: 0.5384 -- iter: 1728/2147
[A[ATraining Step: 327  | total loss: [1m[32m0.69083[0m[0m | time: 39.668s
[2K
| RMSProp | epoch: 005 | loss: 0.69083 - acc: 0.5408 -- iter: 1760/2147
[A[ATraining Step: 328  | total loss: [1m[32m0.69022[0m[0m | time: 40.452s
[2K
| RMSProp | epoch: 005 | loss: 0.69022 - acc: 0.5367 -- iter: 1792/2147
[A[ATraining Step: 329  | total loss: [1m[32m0.68884[0m[0m | time: 41.196s
[2K
| RMSProp | epoch: 005 | loss: 0.68884 - acc: 0.5486 -- iter: 1824/2147
[A[ATraining Step: 330  | total loss: [1m[32m0.68854[0m[0m | time: 41.940s
[2K
| RMSProp | epoch: 005 | loss: 0.68854 - acc: 0.5469 -- iter: 1856/2147
[A[ATraining Step: 331  | total loss: [1m[32m0.68900[0m[0m | time: 42.648s
[2K
| RMSProp | epoch: 005 | loss: 0.68900 - acc: 0.5360 -- iter: 1888/2147
[A[ATraining Step: 332  | total loss: [1m[32m0.68747[0m[0m | time: 43.422s
[2K
| RMSProp | epoch: 005 | loss: 0.68747 - acc: 0.5511 -- iter: 1920/2147
[A[ATraining Step: 333  | total loss: [1m[32m0.68852[0m[0m | time: 44.189s
[2K
| RMSProp | epoch: 005 | loss: 0.68852 - acc: 0.5366 -- iter: 1952/2147
[A[ATraining Step: 334  | total loss: [1m[32m0.68777[0m[0m | time: 44.927s
[2K
| RMSProp | epoch: 005 | loss: 0.68777 - acc: 0.5455 -- iter: 1984/2147
[A[ATraining Step: 335  | total loss: [1m[32m0.68614[0m[0m | time: 45.703s
[2K
| RMSProp | epoch: 005 | loss: 0.68614 - acc: 0.5659 -- iter: 2016/2147
[A[ATraining Step: 336  | total loss: [1m[32m0.68556[0m[0m | time: 46.591s
[2K
| RMSProp | epoch: 005 | loss: 0.68556 - acc: 0.5593 -- iter: 2048/2147
[A[ATraining Step: 337  | total loss: [1m[32m0.68351[0m[0m | time: 47.198s
[2K
| RMSProp | epoch: 005 | loss: 0.68351 - acc: 0.5628 -- iter: 2080/2147
[A[ATraining Step: 338  | total loss: [1m[32m0.67436[0m[0m | time: 47.881s
[2K
| RMSProp | epoch: 005 | loss: 0.67436 - acc: 0.5752 -- iter: 2112/2147
[A[ATraining Step: 339  | total loss: [1m[32m0.69504[0m[0m | time: 48.680s
[2K
| RMSProp | epoch: 005 | loss: 0.69504 - acc: 0.5615 -- iter: 2144/2147
[A[ATraining Step: 340  | total loss: [1m[32m0.69281[0m[0m | time: 52.015s
[2K
| RMSProp | epoch: 005 | loss: 0.69281 - acc: 0.5709 | val_loss: 0.65915 - val_acc: 0.5521 -- iter: 2147/2147
--
Training Step: 341  | total loss: [1m[32m0.69013[0m[0m | time: 0.794s
[2K
| RMSProp | epoch: 006 | loss: 0.69013 - acc: 0.5639 -- iter: 0032/2147
[A[ATraining Step: 342  | total loss: [1m[32m0.68845[0m[0m | time: 1.549s
[2K
| RMSProp | epoch: 006 | loss: 0.68845 - acc: 0.5512 -- iter: 0064/2147
[A[ATraining Step: 343  | total loss: [1m[32m0.68571[0m[0m | time: 2.290s
[2K
| RMSProp | epoch: 006 | loss: 0.68571 - acc: 0.5523 -- iter: 0096/2147
[A[ATraining Step: 344  | total loss: [1m[32m0.68184[0m[0m | time: 2.376s
[2K
| RMSProp | epoch: 006 | loss: 0.68184 - acc: 0.5784 -- iter: 0128/2147
[A[ATraining Step: 345  | total loss: [1m[32m0.68092[0m[0m | time: 2.535s
[2K
| RMSProp | epoch: 006 | loss: 0.68092 - acc: 0.5872 -- iter: 0160/2147
[A[ATraining Step: 346  | total loss: [1m[32m0.67629[0m[0m | time: 3.304s
[2K
| RMSProp | epoch: 006 | loss: 0.67629 - acc: 0.5951 -- iter: 0192/2147
[A[ATraining Step: 347  | total loss: [1m[32m0.67613[0m[0m | time: 4.058s
[2K
| RMSProp | epoch: 006 | loss: 0.67613 - acc: 0.5856 -- iter: 0224/2147
[A[ATraining Step: 348  | total loss: [1m[32m0.67716[0m[0m | time: 4.821s
[2K
| RMSProp | epoch: 006 | loss: 0.67716 - acc: 0.5677 -- iter: 0256/2147
[A[ATraining Step: 349  | total loss: [1m[32m0.67541[0m[0m | time: 5.688s
[2K
| RMSProp | epoch: 006 | loss: 0.67541 - acc: 0.5890 -- iter: 0288/2147
[A[ATraining Step: 350  | total loss: [1m[32m0.67253[0m[0m | time: 6.330s
[2K
| RMSProp | epoch: 006 | loss: 0.67253 - acc: 0.5895 -- iter: 0320/2147
[A[ATraining Step: 351  | total loss: [1m[32m0.66971[0m[0m | time: 6.937s
[2K
| RMSProp | epoch: 006 | loss: 0.66971 - acc: 0.5899 -- iter: 0352/2147
[A[ATraining Step: 352  | total loss: [1m[32m0.67087[0m[0m | time: 7.674s
[2K
| RMSProp | epoch: 006 | loss: 0.67087 - acc: 0.5872 -- iter: 0384/2147
[A[ATraining Step: 353  | total loss: [1m[32m0.66859[0m[0m | time: 8.387s
[2K
| RMSProp | epoch: 006 | loss: 0.66859 - acc: 0.5847 -- iter: 0416/2147
[A[ATraining Step: 354  | total loss: [1m[32m0.66381[0m[0m | time: 9.158s
[2K
| RMSProp | epoch: 006 | loss: 0.66381 - acc: 0.6044 -- iter: 0448/2147
[A[ATraining Step: 355  | total loss: [1m[32m0.65773[0m[0m | time: 9.869s
[2K
| RMSProp | epoch: 006 | loss: 0.65773 - acc: 0.6033 -- iter: 0480/2147
[A[ATraining Step: 356  | total loss: [1m[32m0.66066[0m[0m | time: 10.589s
[2K
| RMSProp | epoch: 006 | loss: 0.66066 - acc: 0.5961 -- iter: 0512/2147
[A[ATraining Step: 357  | total loss: [1m[32m0.66047[0m[0m | time: 11.319s
[2K
| RMSProp | epoch: 006 | loss: 0.66047 - acc: 0.6052 -- iter: 0544/2147
[A[ATraining Step: 358  | total loss: [1m[32m0.65653[0m[0m | time: 12.083s
[2K
| RMSProp | epoch: 006 | loss: 0.65653 - acc: 0.6197 -- iter: 0576/2147
[A[ATraining Step: 359  | total loss: [1m[32m0.65122[0m[0m | time: 13.052s
[2K
| RMSProp | epoch: 006 | loss: 0.65122 - acc: 0.6140 -- iter: 0608/2147
[A[ATraining Step: 360  | total loss: [1m[32m0.64750[0m[0m | time: 14.133s
[2K
| RMSProp | epoch: 006 | loss: 0.64750 - acc: 0.6339 -- iter: 0640/2147
[A[ATraining Step: 361  | total loss: [1m[32m0.64578[0m[0m | time: 15.156s
[2K
| RMSProp | epoch: 006 | loss: 0.64578 - acc: 0.6455 -- iter: 0672/2147
[A[ATraining Step: 362  | total loss: [1m[32m0.63312[0m[0m | time: 16.413s
[2K
| RMSProp | epoch: 006 | loss: 0.63312 - acc: 0.6653 -- iter: 0704/2147
[A[ATraining Step: 363  | total loss: [1m[32m0.64585[0m[0m | time: 17.455s
[2K
| RMSProp | epoch: 006 | loss: 0.64585 - acc: 0.6363 -- iter: 0736/2147
[A[ATraining Step: 364  | total loss: [1m[32m0.67132[0m[0m | time: 18.524s
[2K
| RMSProp | epoch: 006 | loss: 0.67132 - acc: 0.6195 -- iter: 0768/2147
[A[ATraining Step: 365  | total loss: [1m[32m0.67421[0m[0m | time: 19.705s
[2K
| RMSProp | epoch: 006 | loss: 0.67421 - acc: 0.6107 -- iter: 0800/2147
[A[ATraining Step: 366  | total loss: [1m[32m0.66685[0m[0m | time: 20.892s
[2K
| RMSProp | epoch: 006 | loss: 0.66685 - acc: 0.6246 -- iter: 0832/2147
[A[ATraining Step: 367  | total loss: [1m[32m0.66147[0m[0m | time: 22.126s
[2K
| RMSProp | epoch: 006 | loss: 0.66147 - acc: 0.6278 -- iter: 0864/2147
[A[ATraining Step: 368  | total loss: [1m[32m0.66174[0m[0m | time: 23.228s
[2K
| RMSProp | epoch: 006 | loss: 0.66174 - acc: 0.6275 -- iter: 0896/2147
[A[ATraining Step: 369  | total loss: [1m[32m0.65351[0m[0m | time: 24.141s
[2K
| RMSProp | epoch: 006 | loss: 0.65351 - acc: 0.6366 -- iter: 0928/2147
[A[ATraining Step: 370  | total loss: [1m[32m0.64811[0m[0m | time: 24.899s
[2K
| RMSProp | epoch: 006 | loss: 0.64811 - acc: 0.6386 -- iter: 0960/2147
[A[ATraining Step: 371  | total loss: [1m[32m0.64394[0m[0m | time: 25.662s
[2K
| RMSProp | epoch: 006 | loss: 0.64394 - acc: 0.6435 -- iter: 0992/2147
[A[ATraining Step: 372  | total loss: [1m[32m0.63969[0m[0m | time: 26.783s
[2K
| RMSProp | epoch: 006 | loss: 0.63969 - acc: 0.6385 -- iter: 1024/2147
[A[ATraining Step: 373  | total loss: [1m[32m0.63352[0m[0m | time: 28.016s
[2K
| RMSProp | epoch: 006 | loss: 0.63352 - acc: 0.6465 -- iter: 1056/2147
[A[ATraining Step: 374  | total loss: [1m[32m0.63849[0m[0m | time: 29.201s
[2K
| RMSProp | epoch: 006 | loss: 0.63849 - acc: 0.6288 -- iter: 1088/2147
[A[ATraining Step: 375  | total loss: [1m[32m0.63331[0m[0m | time: 30.294s
[2K
| RMSProp | epoch: 006 | loss: 0.63331 - acc: 0.6378 -- iter: 1120/2147
[A[ATraining Step: 376  | total loss: [1m[32m0.62139[0m[0m | time: 31.320s
[2K
| RMSProp | epoch: 006 | loss: 0.62139 - acc: 0.6521 -- iter: 1152/2147
[A[ATraining Step: 377  | total loss: [1m[32m0.62737[0m[0m | time: 32.464s
[2K
| RMSProp | epoch: 006 | loss: 0.62737 - acc: 0.6306 -- iter: 1184/2147
[A[ATraining Step: 378  | total loss: [1m[32m0.62730[0m[0m | time: 33.599s
[2K
| RMSProp | epoch: 006 | loss: 0.62730 - acc: 0.6270 -- iter: 1216/2147
[A[ATraining Step: 379  | total loss: [1m[32m0.63639[0m[0m | time: 34.730s
[2K
| RMSProp | epoch: 006 | loss: 0.63639 - acc: 0.6143 -- iter: 1248/2147
[A[ATraining Step: 380  | total loss: [1m[32m0.63045[0m[0m | time: 36.002s
[2K
| RMSProp | epoch: 006 | loss: 0.63045 - acc: 0.6372 -- iter: 1280/2147
[A[ATraining Step: 381  | total loss: [1m[32m0.62838[0m[0m | time: 37.158s
[2K
| RMSProp | epoch: 006 | loss: 0.62838 - acc: 0.6329 -- iter: 1312/2147
[A[ATraining Step: 382  | total loss: [1m[32m0.61796[0m[0m | time: 38.110s
[2K
| RMSProp | epoch: 006 | loss: 0.61796 - acc: 0.6571 -- iter: 1344/2147
[A[ATraining Step: 383  | total loss: [1m[32m0.61389[0m[0m | time: 39.284s
[2K
| RMSProp | epoch: 006 | loss: 0.61389 - acc: 0.6664 -- iter: 1376/2147
[A[ATraining Step: 384  | total loss: [1m[32m0.60585[0m[0m | time: 40.547s
[2K
| RMSProp | epoch: 006 | loss: 0.60585 - acc: 0.6747 -- iter: 1408/2147
[A[ATraining Step: 385  | total loss: [1m[32m0.59996[0m[0m | time: 41.749s
[2K
| RMSProp | epoch: 006 | loss: 0.59996 - acc: 0.6885 -- iter: 1440/2147
[A[ATraining Step: 386  | total loss: [1m[32m0.60992[0m[0m | time: 43.093s
[2K
| RMSProp | epoch: 006 | loss: 0.60992 - acc: 0.6697 -- iter: 1472/2147
[A[ATraining Step: 387  | total loss: [1m[32m0.60701[0m[0m | time: 44.001s
[2K
| RMSProp | epoch: 006 | loss: 0.60701 - acc: 0.6777 -- iter: 1504/2147
[A[ATraining Step: 388  | total loss: [1m[32m0.60392[0m[0m | time: 44.947s
[2K
| RMSProp | epoch: 006 | loss: 0.60392 - acc: 0.6787 -- iter: 1536/2147
[A[ATraining Step: 389  | total loss: [1m[32m0.58510[0m[0m | time: 45.897s
[2K
| RMSProp | epoch: 006 | loss: 0.58510 - acc: 0.6889 -- iter: 1568/2147
[A[ATraining Step: 390  | total loss: [1m[32m0.57795[0m[0m | time: 46.889s
[2K
| RMSProp | epoch: 006 | loss: 0.57795 - acc: 0.7013 -- iter: 1600/2147
[A[ATraining Step: 391  | total loss: [1m[32m0.58377[0m[0m | time: 48.049s
[2K
| RMSProp | epoch: 006 | loss: 0.58377 - acc: 0.6937 -- iter: 1632/2147
[A[ATraining Step: 392  | total loss: [1m[32m0.60692[0m[0m | time: 48.949s
[2K
| RMSProp | epoch: 006 | loss: 0.60692 - acc: 0.6712 -- iter: 1664/2147
[A[ATraining Step: 393  | total loss: [1m[32m0.61272[0m[0m | time: 49.842s
[2K
| RMSProp | epoch: 006 | loss: 0.61272 - acc: 0.6666 -- iter: 1696/2147
[A[ATraining Step: 394  | total loss: [1m[32m0.60817[0m[0m | time: 50.902s
[2K
| RMSProp | epoch: 006 | loss: 0.60817 - acc: 0.6686 -- iter: 1728/2147
[A[ATraining Step: 395  | total loss: [1m[32m0.59448[0m[0m | time: 51.930s
[2K
| RMSProp | epoch: 006 | loss: 0.59448 - acc: 0.6768 -- iter: 1760/2147
[A[ATraining Step: 396  | total loss: [1m[32m0.58491[0m[0m | time: 52.871s
[2K
| RMSProp | epoch: 006 | loss: 0.58491 - acc: 0.6841 -- iter: 1792/2147
[A[ATraining Step: 397  | total loss: [1m[32m0.57688[0m[0m | time: 53.754s
[2K
| RMSProp | epoch: 006 | loss: 0.57688 - acc: 0.7001 -- iter: 1824/2147
[A[ATraining Step: 398  | total loss: [1m[32m0.56785[0m[0m | time: 54.789s
[2K
| RMSProp | epoch: 006 | loss: 0.56785 - acc: 0.7144 -- iter: 1856/2147
[A[ATraining Step: 399  | total loss: [1m[32m0.56267[0m[0m | time: 55.801s
[2K
| RMSProp | epoch: 006 | loss: 0.56267 - acc: 0.7149 -- iter: 1888/2147
[A[ATraining Step: 400  | total loss: [1m[32m0.54832[0m[0m | time: 60.049s
[2K
| RMSProp | epoch: 006 | loss: 0.54832 - acc: 0.7278 | val_loss: 0.98539 - val_acc: 0.5179 -- iter: 1920/2147
--
Training Step: 401  | total loss: [1m[32m0.54431[0m[0m | time: 61.202s
[2K
| RMSProp | epoch: 006 | loss: 0.54431 - acc: 0.7175 -- iter: 1952/2147
[A[ATraining Step: 402  | total loss: [1m[32m0.57751[0m[0m | time: 62.266s
[2K
| RMSProp | epoch: 006 | loss: 0.57751 - acc: 0.7020 -- iter: 1984/2147
[A[ATraining Step: 403  | total loss: [1m[32m0.57656[0m[0m | time: 63.270s
[2K
| RMSProp | epoch: 006 | loss: 0.57656 - acc: 0.7037 -- iter: 2016/2147
[A[ATraining Step: 404  | total loss: [1m[32m0.57228[0m[0m | time: 64.155s
[2K
| RMSProp | epoch: 006 | loss: 0.57228 - acc: 0.7052 -- iter: 2048/2147
[A[ATraining Step: 405  | total loss: [1m[32m0.57448[0m[0m | time: 65.112s
[2K
| RMSProp | epoch: 006 | loss: 0.57448 - acc: 0.6972 -- iter: 2080/2147
[A[ATraining Step: 406  | total loss: [1m[32m0.56053[0m[0m | time: 66.151s
[2K
| RMSProp | epoch: 006 | loss: 0.56053 - acc: 0.7087 -- iter: 2112/2147
[A[ATraining Step: 407  | total loss: [1m[32m0.54944[0m[0m | time: 67.106s
[2K
| RMSProp | epoch: 006 | loss: 0.54944 - acc: 0.7159 -- iter: 2144/2147
[A[ATraining Step: 408  | total loss: [1m[32m0.54036[0m[0m | time: 71.433s
[2K
| RMSProp | epoch: 006 | loss: 0.54036 - acc: 0.7256 | val_loss: 0.49885 - val_acc: 0.7545 -- iter: 2147/2147
--
Training Step: 409  | total loss: [1m[32m0.53400[0m[0m | time: 1.014s
[2K
| RMSProp | epoch: 007 | loss: 0.53400 - acc: 0.7343 -- iter: 0032/2147
[A[ATraining Step: 410  | total loss: [1m[32m0.52351[0m[0m | time: 1.879s
[2K
| RMSProp | epoch: 007 | loss: 0.52351 - acc: 0.7452 -- iter: 0064/2147
[A[ATraining Step: 411  | total loss: [1m[32m0.51879[0m[0m | time: 2.859s
[2K
| RMSProp | epoch: 007 | loss: 0.51879 - acc: 0.7488 -- iter: 0096/2147
[A[ATraining Step: 412  | total loss: [1m[32m0.52454[0m[0m | time: 3.852s
[2K
| RMSProp | epoch: 007 | loss: 0.52454 - acc: 0.7396 -- iter: 0128/2147
[A[ATraining Step: 413  | total loss: [1m[32m0.52262[0m[0m | time: 4.009s
[2K
| RMSProp | epoch: 007 | loss: 0.52262 - acc: 0.7437 -- iter: 0160/2147
[A[ATraining Step: 414  | total loss: [1m[32m0.55774[0m[0m | time: 4.164s
[2K
| RMSProp | epoch: 007 | loss: 0.55774 - acc: 0.7360 -- iter: 0192/2147
[A[ATraining Step: 415  | total loss: [1m[32m0.55856[0m[0m | time: 5.216s
[2K
| RMSProp | epoch: 007 | loss: 0.55856 - acc: 0.7624 -- iter: 0224/2147
[A[ATraining Step: 416  | total loss: [1m[32m0.61016[0m[0m | time: 6.252s
[2K
| RMSProp | epoch: 007 | loss: 0.61016 - acc: 0.7299 -- iter: 0256/2147
[A[ATraining Step: 417  | total loss: [1m[32m0.59974[0m[0m | time: 7.095s
[2K
| RMSProp | epoch: 007 | loss: 0.59974 - acc: 0.7351 -- iter: 0288/2147
[A[ATraining Step: 418  | total loss: [1m[32m0.59071[0m[0m | time: 8.114s
[2K
| RMSProp | epoch: 007 | loss: 0.59071 - acc: 0.7491 -- iter: 0320/2147
[A[ATraining Step: 419  | total loss: [1m[32m0.59561[0m[0m | time: 9.121s
[2K
| RMSProp | epoch: 007 | loss: 0.59561 - acc: 0.7335 -- iter: 0352/2147
[A[ATraining Step: 420  | total loss: [1m[32m0.58638[0m[0m | time: 10.203s
[2K
| RMSProp | epoch: 007 | loss: 0.58638 - acc: 0.7383 -- iter: 0384/2147
[A[ATraining Step: 421  | total loss: [1m[32m0.56324[0m[0m | time: 11.132s
[2K
| RMSProp | epoch: 007 | loss: 0.56324 - acc: 0.7520 -- iter: 0416/2147
[A[ATraining Step: 422  | total loss: [1m[32m0.54527[0m[0m | time: 12.070s
[2K
| RMSProp | epoch: 007 | loss: 0.54527 - acc: 0.7549 -- iter: 0448/2147
[A[ATraining Step: 423  | total loss: [1m[32m0.52265[0m[0m | time: 13.039s
[2K
| RMSProp | epoch: 007 | loss: 0.52265 - acc: 0.7700 -- iter: 0480/2147
[A[ATraining Step: 424  | total loss: [1m[32m0.51917[0m[0m | time: 14.002s
[2K
| RMSProp | epoch: 007 | loss: 0.51917 - acc: 0.7805 -- iter: 0512/2147
[A[ATraining Step: 425  | total loss: [1m[32m0.53922[0m[0m | time: 15.075s
[2K
| RMSProp | epoch: 007 | loss: 0.53922 - acc: 0.7587 -- iter: 0544/2147
[A[ATraining Step: 426  | total loss: [1m[32m0.53410[0m[0m | time: 16.094s
[2K
| RMSProp | epoch: 007 | loss: 0.53410 - acc: 0.7641 -- iter: 0576/2147
[A[ATraining Step: 427  | total loss: [1m[32m0.53084[0m[0m | time: 16.938s
[2K
| RMSProp | epoch: 007 | loss: 0.53084 - acc: 0.7658 -- iter: 0608/2147
[A[ATraining Step: 428  | total loss: [1m[32m0.52612[0m[0m | time: 18.046s
[2K
| RMSProp | epoch: 007 | loss: 0.52612 - acc: 0.7705 -- iter: 0640/2147
[A[ATraining Step: 429  | total loss: [1m[32m0.52070[0m[0m | time: 19.102s
[2K
| RMSProp | epoch: 007 | loss: 0.52070 - acc: 0.7747 -- iter: 0672/2147
[A[ATraining Step: 430  | total loss: [1m[32m0.52111[0m[0m | time: 20.175s
[2K
| RMSProp | epoch: 007 | loss: 0.52111 - acc: 0.7691 -- iter: 0704/2147
[A[ATraining Step: 431  | total loss: [1m[32m0.51562[0m[0m | time: 21.048s
[2K
| RMSProp | epoch: 007 | loss: 0.51562 - acc: 0.7672 -- iter: 0736/2147
[A[ATraining Step: 432  | total loss: [1m[32m0.50782[0m[0m | time: 21.960s
[2K
| RMSProp | epoch: 007 | loss: 0.50782 - acc: 0.7717 -- iter: 0768/2147
[A[ATraining Step: 433  | total loss: [1m[32m0.50266[0m[0m | time: 22.931s
[2K
| RMSProp | epoch: 007 | loss: 0.50266 - acc: 0.7789 -- iter: 0800/2147
[A[ATraining Step: 434  | total loss: [1m[32m0.49156[0m[0m | time: 23.884s
[2K
| RMSProp | epoch: 007 | loss: 0.49156 - acc: 0.7854 -- iter: 0832/2147
[A[ATraining Step: 435  | total loss: [1m[32m0.51069[0m[0m | time: 24.989s
[2K
| RMSProp | epoch: 007 | loss: 0.51069 - acc: 0.7787 -- iter: 0864/2147
[A[ATraining Step: 436  | total loss: [1m[32m0.51931[0m[0m | time: 26.045s
[2K
| RMSProp | epoch: 007 | loss: 0.51931 - acc: 0.7696 -- iter: 0896/2147
[A[ATraining Step: 437  | total loss: [1m[32m0.52395[0m[0m | time: 26.873s
[2K
| RMSProp | epoch: 007 | loss: 0.52395 - acc: 0.7645 -- iter: 0928/2147
[A[ATraining Step: 438  | total loss: [1m[32m0.51732[0m[0m | time: 27.976s
[2K
| RMSProp | epoch: 007 | loss: 0.51732 - acc: 0.7756 -- iter: 0960/2147
[A[ATraining Step: 439  | total loss: [1m[32m0.51164[0m[0m | time: 29.055s
[2K
| RMSProp | epoch: 007 | loss: 0.51164 - acc: 0.7761 -- iter: 0992/2147
[A[ATraining Step: 440  | total loss: [1m[32m0.50446[0m[0m | time: 30.101s
[2K
| RMSProp | epoch: 007 | loss: 0.50446 - acc: 0.7798 -- iter: 1024/2147
[A[ATraining Step: 441  | total loss: [1m[32m0.52347[0m[0m | time: 30.968s
[2K
| RMSProp | epoch: 007 | loss: 0.52347 - acc: 0.7612 -- iter: 1056/2147
[A[ATraining Step: 442  | total loss: [1m[32m0.52288[0m[0m | time: 31.912s
[2K
| RMSProp | epoch: 007 | loss: 0.52288 - acc: 0.7632 -- iter: 1088/2147
[A[ATraining Step: 443  | total loss: [1m[32m0.54387[0m[0m | time: 32.925s
[2K
| RMSProp | epoch: 007 | loss: 0.54387 - acc: 0.7650 -- iter: 1120/2147
[A[ATraining Step: 444  | total loss: [1m[32m0.55491[0m[0m | time: 34.177s
[2K
| RMSProp | epoch: 007 | loss: 0.55491 - acc: 0.7416 -- iter: 1152/2147
[A[ATraining Step: 445  | total loss: [1m[32m0.55198[0m[0m | time: 35.527s
[2K
| RMSProp | epoch: 007 | loss: 0.55198 - acc: 0.7393 -- iter: 1184/2147
[A[ATraining Step: 446  | total loss: [1m[32m0.54926[0m[0m | time: 36.822s
[2K
| RMSProp | epoch: 007 | loss: 0.54926 - acc: 0.7279 -- iter: 1216/2147
[A[ATraining Step: 447  | total loss: [1m[32m0.54872[0m[0m | time: 38.148s
[2K
| RMSProp | epoch: 007 | loss: 0.54872 - acc: 0.7301 -- iter: 1248/2147
[A[ATraining Step: 448  | total loss: [1m[32m0.55112[0m[0m | time: 39.340s
[2K
| RMSProp | epoch: 007 | loss: 0.55112 - acc: 0.7321 -- iter: 1280/2147
[A[ATraining Step: 449  | total loss: [1m[32m0.55529[0m[0m | time: 40.577s
[2K
| RMSProp | epoch: 007 | loss: 0.55529 - acc: 0.7276 -- iter: 1312/2147
[A[ATraining Step: 450  | total loss: [1m[32m0.55666[0m[0m | time: 42.000s
[2K
| RMSProp | epoch: 007 | loss: 0.55666 - acc: 0.7299 -- iter: 1344/2147
[A[ATraining Step: 451  | total loss: [1m[32m0.54558[0m[0m | time: 43.331s
[2K
| RMSProp | epoch: 007 | loss: 0.54558 - acc: 0.7413 -- iter: 1376/2147
[A[ATraining Step: 452  | total loss: [1m[32m0.53423[0m[0m | time: 44.623s
[2K
| RMSProp | epoch: 007 | loss: 0.53423 - acc: 0.7609 -- iter: 1408/2147
[A[ATraining Step: 453  | total loss: [1m[32m0.53786[0m[0m | time: 45.723s
[2K
| RMSProp | epoch: 007 | loss: 0.53786 - acc: 0.7504 -- iter: 1440/2147
[A[ATraining Step: 454  | total loss: [1m[32m0.51769[0m[0m | time: 46.948s
[2K
| RMSProp | epoch: 007 | loss: 0.51769 - acc: 0.7660 -- iter: 1472/2147
[A[ATraining Step: 455  | total loss: [1m[32m0.51587[0m[0m | time: 48.281s
[2K
| RMSProp | epoch: 007 | loss: 0.51587 - acc: 0.7613 -- iter: 1504/2147
[A[ATraining Step: 456  | total loss: [1m[32m0.50199[0m[0m | time: 49.598s
[2K
| RMSProp | epoch: 007 | loss: 0.50199 - acc: 0.7664 -- iter: 1536/2147
[A[ATraining Step: 457  | total loss: [1m[32m0.55132[0m[0m | time: 50.772s
[2K
| RMSProp | epoch: 007 | loss: 0.55132 - acc: 0.7429 -- iter: 1568/2147
[A[ATraining Step: 458  | total loss: [1m[32m0.54444[0m[0m | time: 51.871s
[2K
| RMSProp | epoch: 007 | loss: 0.54444 - acc: 0.7436 -- iter: 1600/2147
[A[ATraining Step: 459  | total loss: [1m[32m0.53849[0m[0m | time: 52.970s
[2K
| RMSProp | epoch: 007 | loss: 0.53849 - acc: 0.7442 -- iter: 1632/2147
[A[ATraining Step: 460  | total loss: [1m[32m0.53281[0m[0m | time: 54.141s
[2K
| RMSProp | epoch: 007 | loss: 0.53281 - acc: 0.7479 -- iter: 1664/2147
[A[ATraining Step: 461  | total loss: [1m[32m0.53391[0m[0m | time: 55.636s
[2K
| RMSProp | epoch: 007 | loss: 0.53391 - acc: 0.7450 -- iter: 1696/2147
[A[ATraining Step: 462  | total loss: [1m[32m0.52990[0m[0m | time: 56.958s
[2K
| RMSProp | epoch: 007 | loss: 0.52990 - acc: 0.7424 -- iter: 1728/2147
[A[ATraining Step: 463  | total loss: [1m[32m0.52565[0m[0m | time: 58.173s
[2K
| RMSProp | epoch: 007 | loss: 0.52565 - acc: 0.7400 -- iter: 1760/2147
[A[ATraining Step: 464  | total loss: [1m[32m0.52241[0m[0m | time: 59.476s
[2K
| RMSProp | epoch: 007 | loss: 0.52241 - acc: 0.7473 -- iter: 1792/2147
[A[ATraining Step: 465  | total loss: [1m[32m0.49551[0m[0m | time: 60.636s
[2K
| RMSProp | epoch: 007 | loss: 0.49551 - acc: 0.7694 -- iter: 1824/2147
[A[ATraining Step: 466  | total loss: [1m[32m0.48818[0m[0m | time: 61.925s
[2K
| RMSProp | epoch: 007 | loss: 0.48818 - acc: 0.7644 -- iter: 1856/2147
[A[ATraining Step: 467  | total loss: [1m[32m0.57559[0m[0m | time: 63.186s
[2K
| RMSProp | epoch: 007 | loss: 0.57559 - acc: 0.7317 -- iter: 1888/2147
[A[ATraining Step: 468  | total loss: [1m[32m0.56119[0m[0m | time: 64.508s
[2K
| RMSProp | epoch: 007 | loss: 0.56119 - acc: 0.7523 -- iter: 1920/2147
[A[ATraining Step: 469  | total loss: [1m[32m0.54881[0m[0m | time: 65.939s
[2K
| RMSProp | epoch: 007 | loss: 0.54881 - acc: 0.7583 -- iter: 1952/2147
[A[ATraining Step: 470  | total loss: [1m[32m0.56951[0m[0m | time: 67.464s
[2K
| RMSProp | epoch: 007 | loss: 0.56951 - acc: 0.7293 -- iter: 1984/2147
[A[ATraining Step: 471  | total loss: [1m[32m0.55524[0m[0m | time: 68.661s
[2K
| RMSProp | epoch: 007 | loss: 0.55524 - acc: 0.7376 -- iter: 2016/2147
[A[ATraining Step: 472  | total loss: [1m[32m0.53364[0m[0m | time: 69.886s
[2K
| RMSProp | epoch: 007 | loss: 0.53364 - acc: 0.7514 -- iter: 2048/2147
[A[ATraining Step: 473  | total loss: [1m[32m0.52485[0m[0m | time: 71.186s
[2K
| RMSProp | epoch: 007 | loss: 0.52485 - acc: 0.7606 -- iter: 2080/2147
[A[ATraining Step: 474  | total loss: [1m[32m0.52301[0m[0m | time: 72.755s
[2K
| RMSProp | epoch: 007 | loss: 0.52301 - acc: 0.7533 -- iter: 2112/2147
[A[ATraining Step: 475  | total loss: [1m[32m0.51253[0m[0m | time: 74.052s
[2K
| RMSProp | epoch: 007 | loss: 0.51253 - acc: 0.7623 -- iter: 2144/2147
[A[ATraining Step: 476  | total loss: [1m[32m0.51623[0m[0m | time: 79.454s
[2K
| RMSProp | epoch: 007 | loss: 0.51623 - acc: 0.7549 | val_loss: 0.47122 - val_acc: 0.7842 -- iter: 2147/2147
--
Training Step: 477  | total loss: [1m[32m0.52774[0m[0m | time: 1.249s
[2K
| RMSProp | epoch: 008 | loss: 0.52774 - acc: 0.7388 -- iter: 0032/2147
[A[ATraining Step: 478  | total loss: [1m[32m0.52274[0m[0m | time: 2.667s
[2K
| RMSProp | epoch: 008 | loss: 0.52274 - acc: 0.7399 -- iter: 0064/2147
[A[ATraining Step: 479  | total loss: [1m[32m0.53281[0m[0m | time: 4.115s
[2K
| RMSProp | epoch: 008 | loss: 0.53281 - acc: 0.7346 -- iter: 0096/2147
[A[ATraining Step: 480  | total loss: [1m[32m0.53542[0m[0m | time: 5.432s
[2K
| RMSProp | epoch: 008 | loss: 0.53542 - acc: 0.7331 -- iter: 0128/2147
[A[ATraining Step: 481  | total loss: [1m[32m0.52659[0m[0m | time: 6.542s
[2K
| RMSProp | epoch: 008 | loss: 0.52659 - acc: 0.7410 -- iter: 0160/2147
[A[ATraining Step: 482  | total loss: [1m[32m0.52789[0m[0m | time: 6.798s
[2K
| RMSProp | epoch: 008 | loss: 0.52789 - acc: 0.7419 -- iter: 0192/2147
[A[ATraining Step: 483  | total loss: [1m[32m0.51869[0m[0m | time: 7.004s
[2K
| RMSProp | epoch: 008 | loss: 0.51869 - acc: 0.7344 -- iter: 0224/2147
[A[ATraining Step: 484  | total loss: [1m[32m0.48804[0m[0m | time: 8.324s
[2K
| RMSProp | epoch: 008 | loss: 0.48804 - acc: 0.7609 -- iter: 0256/2147
[A[ATraining Step: 485  | total loss: [1m[32m0.51282[0m[0m | time: 9.998s
[2K
| RMSProp | epoch: 008 | loss: 0.51282 - acc: 0.7473 -- iter: 0288/2147
[A[ATraining Step: 486  | total loss: [1m[32m0.50220[0m[0m | time: 11.215s
[2K
| RMSProp | epoch: 008 | loss: 0.50220 - acc: 0.7507 -- iter: 0320/2147
[A[ATraining Step: 487  | total loss: [1m[32m0.51551[0m[0m | time: 14.800s
[2K
| RMSProp | epoch: 008 | loss: 0.51551 - acc: 0.7413 -- iter: 0352/2147
[A[ATraining Step: 488  | total loss: [1m[32m0.51369[0m[0m | time: 15.819s
[2K
| RMSProp | epoch: 008 | loss: 0.51369 - acc: 0.7484 -- iter: 0384/2147
[A[ATraining Step: 489  | total loss: [1m[32m0.50027[0m[0m | time: 17.035s
[2K
| RMSProp | epoch: 008 | loss: 0.50027 - acc: 0.7579 -- iter: 0416/2147
[A[ATraining Step: 490  | total loss: [1m[32m0.50744[0m[0m | time: 18.257s
[2K
| RMSProp | epoch: 008 | loss: 0.50744 - acc: 0.7603 -- iter: 0448/2147
[A[ATraining Step: 491  | total loss: [1m[32m0.52486[0m[0m | time: 19.559s
[2K
| RMSProp | epoch: 008 | loss: 0.52486 - acc: 0.7499 -- iter: 0480/2147
[A[ATraining Step: 492  | total loss: [1m[32m0.51968[0m[0m | time: 20.890s
[2K
| RMSProp | epoch: 008 | loss: 0.51968 - acc: 0.7530 -- iter: 0512/2147
[A[ATraining Step: 493  | total loss: [1m[32m0.51237[0m[0m | time: 22.411s
[2K
| RMSProp | epoch: 008 | loss: 0.51237 - acc: 0.7621 -- iter: 0544/2147
[A[ATraining Step: 494  | total loss: [1m[32m0.50016[0m[0m | time: 23.927s
[2K
| RMSProp | epoch: 008 | loss: 0.50016 - acc: 0.7671 -- iter: 0576/2147
[A[ATraining Step: 495  | total loss: [1m[32m0.49082[0m[0m | time: 25.030s
[2K
| RMSProp | epoch: 008 | loss: 0.49082 - acc: 0.7779 -- iter: 0608/2147
[A[ATraining Step: 496  | total loss: [1m[32m0.48805[0m[0m | time: 26.293s
[2K
| RMSProp | epoch: 008 | loss: 0.48805 - acc: 0.7814 -- iter: 0640/2147
[A[ATraining Step: 497  | total loss: [1m[32m0.50462[0m[0m | time: 27.598s
[2K
| RMSProp | epoch: 008 | loss: 0.50462 - acc: 0.7657 -- iter: 0672/2147
[A[ATraining Step: 498  | total loss: [1m[32m0.52495[0m[0m | time: 29.142s
[2K
| RMSProp | epoch: 008 | loss: 0.52495 - acc: 0.7454 -- iter: 0704/2147
[A[ATraining Step: 499  | total loss: [1m[32m0.51339[0m[0m | time: 30.320s
[2K
| RMSProp | epoch: 008 | loss: 0.51339 - acc: 0.7490 -- iter: 0736/2147
[A[ATraining Step: 500  | total loss: [1m[32m0.52004[0m[0m | time: 31.429s
[2K
| RMSProp | epoch: 008 | loss: 0.52004 - acc: 0.7366 -- iter: 0768/2147
[A[ATraining Step: 501  | total loss: [1m[32m0.50732[0m[0m | time: 32.687s
[2K
| RMSProp | epoch: 008 | loss: 0.50732 - acc: 0.7504 -- iter: 0800/2147
[A[ATraining Step: 502  | total loss: [1m[32m0.49576[0m[0m | time: 33.931s
[2K
| RMSProp | epoch: 008 | loss: 0.49576 - acc: 0.7598 -- iter: 0832/2147
[A[ATraining Step: 503  | total loss: [1m[32m0.48780[0m[0m | time: 35.208s
[2K
| RMSProp | epoch: 008 | loss: 0.48780 - acc: 0.7682 -- iter: 0864/2147
[A[ATraining Step: 504  | total loss: [1m[32m0.48319[0m[0m | time: 36.596s
[2K
| RMSProp | epoch: 008 | loss: 0.48319 - acc: 0.7726 -- iter: 0896/2147
[A[ATraining Step: 505  | total loss: [1m[32m0.48326[0m[0m | time: 38.112s
[2K
| RMSProp | epoch: 008 | loss: 0.48326 - acc: 0.7735 -- iter: 0928/2147
[A[ATraining Step: 506  | total loss: [1m[32m0.48464[0m[0m | time: 39.311s
[2K
| RMSProp | epoch: 008 | loss: 0.48464 - acc: 0.7742 -- iter: 0960/2147
[A[ATraining Step: 507  | total loss: [1m[32m0.48346[0m[0m | time: 40.345s
[2K
| RMSProp | epoch: 008 | loss: 0.48346 - acc: 0.7749 -- iter: 0992/2147
[A[ATraining Step: 508  | total loss: [1m[32m0.49117[0m[0m | time: 41.515s
[2K
| RMSProp | epoch: 008 | loss: 0.49117 - acc: 0.7662 -- iter: 1024/2147
[A[ATraining Step: 509  | total loss: [1m[32m0.48519[0m[0m | time: 42.576s
[2K
| RMSProp | epoch: 008 | loss: 0.48519 - acc: 0.7677 -- iter: 1056/2147
[A[ATraining Step: 510  | total loss: [1m[32m0.47134[0m[0m | time: 43.400s
[2K
| RMSProp | epoch: 008 | loss: 0.47134 - acc: 0.7784 -- iter: 1088/2147
[A[ATraining Step: 511  | total loss: [1m[32m0.46766[0m[0m | time: 44.354s
[2K
| RMSProp | epoch: 008 | loss: 0.46766 - acc: 0.7787 -- iter: 1120/2147
[A[ATraining Step: 512  | total loss: [1m[32m0.46078[0m[0m | time: 45.336s
[2K
| RMSProp | epoch: 008 | loss: 0.46078 - acc: 0.7852 -- iter: 1152/2147
[A[ATraining Step: 513  | total loss: [1m[32m0.45037[0m[0m | time: 46.299s
[2K
| RMSProp | epoch: 008 | loss: 0.45037 - acc: 0.7911 -- iter: 1184/2147
[A[ATraining Step: 514  | total loss: [1m[32m0.47362[0m[0m | time: 47.381s
[2K
| RMSProp | epoch: 008 | loss: 0.47362 - acc: 0.7651 -- iter: 1216/2147
[A[ATraining Step: 515  | total loss: [1m[32m0.47471[0m[0m | time: 48.493s
[2K
| RMSProp | epoch: 008 | loss: 0.47471 - acc: 0.7636 -- iter: 1248/2147
[A[ATraining Step: 516  | total loss: [1m[32m0.47456[0m[0m | time: 49.347s
[2K
| RMSProp | epoch: 008 | loss: 0.47456 - acc: 0.7685 -- iter: 1280/2147
[A[ATraining Step: 517  | total loss: [1m[32m0.46261[0m[0m | time: 50.473s
[2K
| RMSProp | epoch: 008 | loss: 0.46261 - acc: 0.7791 -- iter: 1312/2147
[A[ATraining Step: 518  | total loss: [1m[32m0.46733[0m[0m | time: 51.575s
[2K
| RMSProp | epoch: 008 | loss: 0.46733 - acc: 0.7762 -- iter: 1344/2147
[A[ATraining Step: 519  | total loss: [1m[32m0.48145[0m[0m | time: 52.913s
[2K
| RMSProp | epoch: 008 | loss: 0.48145 - acc: 0.7861 -- iter: 1376/2147
[A[ATraining Step: 520  | total loss: [1m[32m0.55359[0m[0m | time: 54.102s
[2K
| RMSProp | epoch: 008 | loss: 0.55359 - acc: 0.7544 -- iter: 1408/2147
[A[ATraining Step: 521  | total loss: [1m[32m0.54768[0m[0m | time: 55.382s
[2K
| RMSProp | epoch: 008 | loss: 0.54768 - acc: 0.7633 -- iter: 1440/2147
[A[ATraining Step: 522  | total loss: [1m[32m0.54471[0m[0m | time: 56.645s
[2K
| RMSProp | epoch: 008 | loss: 0.54471 - acc: 0.7557 -- iter: 1472/2147
[A[ATraining Step: 523  | total loss: [1m[32m0.53584[0m[0m | time: 58.027s
[2K
| RMSProp | epoch: 008 | loss: 0.53584 - acc: 0.7583 -- iter: 1504/2147
[A[ATraining Step: 524  | total loss: [1m[32m0.53051[0m[0m | time: 59.344s
[2K
| RMSProp | epoch: 008 | loss: 0.53051 - acc: 0.7543 -- iter: 1536/2147
[A[ATraining Step: 525  | total loss: [1m[32m0.52778[0m[0m | time: 60.764s
[2K
| RMSProp | epoch: 008 | loss: 0.52778 - acc: 0.7570 -- iter: 1568/2147
[A[ATraining Step: 526  | total loss: [1m[32m0.51014[0m[0m | time: 62.127s
[2K
| RMSProp | epoch: 008 | loss: 0.51014 - acc: 0.7688 -- iter: 1600/2147
[A[ATraining Step: 527  | total loss: [1m[32m0.51542[0m[0m | time: 63.296s
[2K
| RMSProp | epoch: 008 | loss: 0.51542 - acc: 0.7607 -- iter: 1632/2147
[A[ATraining Step: 528  | total loss: [1m[32m0.50663[0m[0m | time: 64.461s
[2K
| RMSProp | epoch: 008 | loss: 0.50663 - acc: 0.7627 -- iter: 1664/2147
[A[ATraining Step: 529  | total loss: [1m[32m0.52253[0m[0m | time: 65.573s
[2K
| RMSProp | epoch: 008 | loss: 0.52253 - acc: 0.7490 -- iter: 1696/2147
[A[ATraining Step: 530  | total loss: [1m[32m0.51577[0m[0m | time: 66.650s
[2K
| RMSProp | epoch: 008 | loss: 0.51577 - acc: 0.7491 -- iter: 1728/2147
[A[ATraining Step: 531  | total loss: [1m[32m0.52729[0m[0m | time: 67.737s
[2K
| RMSProp | epoch: 008 | loss: 0.52729 - acc: 0.7398 -- iter: 1760/2147
[A[ATraining Step: 532  | total loss: [1m[32m0.52451[0m[0m | time: 68.664s
[2K
| RMSProp | epoch: 008 | loss: 0.52451 - acc: 0.7439 -- iter: 1792/2147
[A[ATraining Step: 533  | total loss: [1m[32m0.51419[0m[0m | time: 69.685s
[2K
| RMSProp | epoch: 008 | loss: 0.51419 - acc: 0.7570 -- iter: 1824/2147
[A[ATraining Step: 534  | total loss: [1m[32m0.49061[0m[0m | time: 70.642s
[2K
| RMSProp | epoch: 008 | loss: 0.49061 - acc: 0.7720 -- iter: 1856/2147
[A[ATraining Step: 535  | total loss: [1m[32m0.47389[0m[0m | time: 71.753s
[2K
| RMSProp | epoch: 008 | loss: 0.47389 - acc: 0.7854 -- iter: 1888/2147
[A[ATraining Step: 536  | total loss: [1m[32m0.50363[0m[0m | time: 72.817s
[2K
| RMSProp | epoch: 008 | loss: 0.50363 - acc: 0.7850 -- iter: 1920/2147
[A[ATraining Step: 537  | total loss: [1m[32m0.48123[0m[0m | time: 73.688s
[2K
| RMSProp | epoch: 008 | loss: 0.48123 - acc: 0.7971 -- iter: 1952/2147
[A[ATraining Step: 538  | total loss: [1m[32m0.47002[0m[0m | time: 74.703s
[2K
| RMSProp | epoch: 008 | loss: 0.47002 - acc: 0.8049 -- iter: 1984/2147
[A[ATraining Step: 539  | total loss: [1m[32m0.47134[0m[0m | time: 75.816s
[2K
| RMSProp | epoch: 008 | loss: 0.47134 - acc: 0.7932 -- iter: 2016/2147
[A[ATraining Step: 540  | total loss: [1m[32m0.46360[0m[0m | time: 76.972s
[2K
| RMSProp | epoch: 008 | loss: 0.46360 - acc: 0.7982 -- iter: 2048/2147
[A[ATraining Step: 541  | total loss: [1m[32m0.46181[0m[0m | time: 77.844s
[2K
| RMSProp | epoch: 008 | loss: 0.46181 - acc: 0.7965 -- iter: 2080/2147
[A[ATraining Step: 542  | total loss: [1m[32m0.47925[0m[0m | time: 78.820s
[2K
| RMSProp | epoch: 008 | loss: 0.47925 - acc: 0.7825 -- iter: 2112/2147
[A[ATraining Step: 543  | total loss: [1m[32m0.47877[0m[0m | time: 79.798s
[2K
| RMSProp | epoch: 008 | loss: 0.47877 - acc: 0.7792 -- iter: 2144/2147
[A[ATraining Step: 544  | total loss: [1m[32m0.48560[0m[0m | time: 84.293s
[2K
| RMSProp | epoch: 008 | loss: 0.48560 - acc: 0.7701 | val_loss: 0.46612 - val_acc: 0.7768 -- iter: 2147/2147
--
Training Step: 545  | total loss: [1m[32m0.48201[0m[0m | time: 0.921s
[2K
| RMSProp | epoch: 009 | loss: 0.48201 - acc: 0.7774 -- iter: 0032/2147
[A[ATraining Step: 546  | total loss: [1m[32m0.46865[0m[0m | time: 1.964s
[2K
| RMSProp | epoch: 009 | loss: 0.46865 - acc: 0.7841 -- iter: 0064/2147
[A[ATraining Step: 547  | total loss: [1m[32m0.46183[0m[0m | time: 3.106s
[2K
| RMSProp | epoch: 009 | loss: 0.46183 - acc: 0.7838 -- iter: 0096/2147
[A[ATraining Step: 548  | total loss: [1m[32m0.45358[0m[0m | time: 4.125s
[2K
| RMSProp | epoch: 009 | loss: 0.45358 - acc: 0.7898 -- iter: 0128/2147
[A[ATraining Step: 549  | total loss: [1m[32m0.45222[0m[0m | time: 5.097s
[2K
| RMSProp | epoch: 009 | loss: 0.45222 - acc: 0.7921 -- iter: 0160/2147
[A[ATraining Step: 550  | total loss: [1m[32m0.44612[0m[0m | time: 6.125s
[2K
| RMSProp | epoch: 009 | loss: 0.44612 - acc: 0.7910 -- iter: 0192/2147
[A[ATraining Step: 551  | total loss: [1m[32m0.48502[0m[0m | time: 6.273s
[2K
| RMSProp | epoch: 009 | loss: 0.48502 - acc: 0.7556 -- iter: 0224/2147
[A[ATraining Step: 552  | total loss: [1m[32m0.45421[0m[0m | time: 6.428s
[2K
| RMSProp | epoch: 009 | loss: 0.45421 - acc: 0.7801 -- iter: 0256/2147
[A[ATraining Step: 553  | total loss: [1m[32m0.41382[0m[0m | time: 7.444s
[2K
| RMSProp | epoch: 009 | loss: 0.41382 - acc: 0.8021 -- iter: 0288/2147
[A[ATraining Step: 554  | total loss: [1m[32m0.49778[0m[0m | time: 8.652s
[2K
| RMSProp | epoch: 009 | loss: 0.49778 - acc: 0.7781 -- iter: 0320/2147
[A[ATraining Step: 555  | total loss: [1m[32m0.50094[0m[0m | time: 9.577s
[2K
| RMSProp | epoch: 009 | loss: 0.50094 - acc: 0.7784 -- iter: 0352/2147
[A[ATraining Step: 556  | total loss: [1m[32m0.49649[0m[0m | time: 10.548s
[2K
| RMSProp | epoch: 009 | loss: 0.49649 - acc: 0.7756 -- iter: 0384/2147
[A[ATraining Step: 557  | total loss: [1m[32m0.50576[0m[0m | time: 11.701s
[2K
| RMSProp | epoch: 009 | loss: 0.50576 - acc: 0.7668 -- iter: 0416/2147
[A[ATraining Step: 558  | total loss: [1m[32m0.51635[0m[0m | time: 12.852s
[2K
| RMSProp | epoch: 009 | loss: 0.51635 - acc: 0.7620 -- iter: 0448/2147
[A[ATraining Step: 559  | total loss: [1m[32m0.49569[0m[0m | time: 13.824s
[2K
| RMSProp | epoch: 009 | loss: 0.49569 - acc: 0.7795 -- iter: 0480/2147
[A[ATraining Step: 560  | total loss: [1m[32m0.50095[0m[0m | time: 14.845s
[2K
| RMSProp | epoch: 009 | loss: 0.50095 - acc: 0.7672 -- iter: 0512/2147
[A[ATraining Step: 561  | total loss: [1m[32m0.49495[0m[0m | time: 15.836s
[2K
| RMSProp | epoch: 009 | loss: 0.49495 - acc: 0.7717 -- iter: 0544/2147
[A[ATraining Step: 562  | total loss: [1m[32m0.48669[0m[0m | time: 16.792s
[2K
| RMSProp | epoch: 009 | loss: 0.48669 - acc: 0.7727 -- iter: 0576/2147
[A[ATraining Step: 563  | total loss: [1m[32m0.50067[0m[0m | time: 17.963s
[2K
| RMSProp | epoch: 009 | loss: 0.50067 - acc: 0.7610 -- iter: 0608/2147
[A[ATraining Step: 564  | total loss: [1m[32m0.48243[0m[0m | time: 19.089s
[2K
| RMSProp | epoch: 009 | loss: 0.48243 - acc: 0.7787 -- iter: 0640/2147
[A[ATraining Step: 565  | total loss: [1m[32m0.47059[0m[0m | time: 20.282s
[2K
| RMSProp | epoch: 009 | loss: 0.47059 - acc: 0.7883 -- iter: 0672/2147
[A[ATraining Step: 566  | total loss: [1m[32m0.45748[0m[0m | time: 21.483s
[2K
| RMSProp | epoch: 009 | loss: 0.45748 - acc: 0.7939 -- iter: 0704/2147
[A[ATraining Step: 567  | total loss: [1m[32m0.45372[0m[0m | time: 22.965s
[2K
| RMSProp | epoch: 009 | loss: 0.45372 - acc: 0.8020 -- iter: 0736/2147
[A[ATraining Step: 568  | total loss: [1m[32m0.44826[0m[0m | time: 24.265s
[2K
| RMSProp | epoch: 009 | loss: 0.44826 - acc: 0.8061 -- iter: 0768/2147
[A[ATraining Step: 569  | total loss: [1m[32m0.43962[0m[0m | time: 25.732s
[2K
| RMSProp | epoch: 009 | loss: 0.43962 - acc: 0.8099 -- iter: 0800/2147
[A[ATraining Step: 570  | total loss: [1m[32m0.42616[0m[0m | time: 26.840s
[2K
| RMSProp | epoch: 009 | loss: 0.42616 - acc: 0.8133 -- iter: 0832/2147
[A[ATraining Step: 571  | total loss: [1m[32m0.41678[0m[0m | time: 28.068s
[2K
| RMSProp | epoch: 009 | loss: 0.41678 - acc: 0.8195 -- iter: 0864/2147
[A[ATraining Step: 572  | total loss: [1m[32m0.41385[0m[0m | time: 29.280s
[2K
| RMSProp | epoch: 009 | loss: 0.41385 - acc: 0.8188 -- iter: 0896/2147
[A[ATraining Step: 573  | total loss: [1m[32m0.42180[0m[0m | time: 30.665s
[2K
| RMSProp | epoch: 009 | loss: 0.42180 - acc: 0.8150 -- iter: 0928/2147
[A[ATraining Step: 574  | total loss: [1m[32m0.44333[0m[0m | time: 31.972s
[2K
| RMSProp | epoch: 009 | loss: 0.44333 - acc: 0.7929 -- iter: 0960/2147
[A[ATraining Step: 575  | total loss: [1m[32m0.44662[0m[0m | time: 33.170s
[2K
| RMSProp | epoch: 009 | loss: 0.44662 - acc: 0.7886 -- iter: 0992/2147
[A[ATraining Step: 576  | total loss: [1m[32m0.45033[0m[0m | time: 34.546s
[2K
| RMSProp | epoch: 009 | loss: 0.45033 - acc: 0.7910 -- iter: 1024/2147
[A[ATraining Step: 577  | total loss: [1m[32m0.43558[0m[0m | time: 35.833s
[2K
| RMSProp | epoch: 009 | loss: 0.43558 - acc: 0.8056 -- iter: 1056/2147
[A[ATraining Step: 578  | total loss: [1m[32m0.41993[0m[0m | time: 37.145s
[2K
| RMSProp | epoch: 009 | loss: 0.41993 - acc: 0.8157 -- iter: 1088/2147
[A[ATraining Step: 579  | total loss: [1m[32m0.43720[0m[0m | time: 38.596s
[2K
| RMSProp | epoch: 009 | loss: 0.43720 - acc: 0.7998 -- iter: 1120/2147
[A[ATraining Step: 580  | total loss: [1m[32m0.43969[0m[0m | time: 39.782s
[2K
| RMSProp | epoch: 009 | loss: 0.43969 - acc: 0.7979 -- iter: 1152/2147
[A[ATraining Step: 581  | total loss: [1m[32m0.44218[0m[0m | time: 41.159s
[2K
| RMSProp | epoch: 009 | loss: 0.44218 - acc: 0.7869 -- iter: 1184/2147
[A[ATraining Step: 582  | total loss: [1m[32m0.43493[0m[0m | time: 42.509s
[2K
| RMSProp | epoch: 009 | loss: 0.43493 - acc: 0.7957 -- iter: 1216/2147
[A[ATraining Step: 583  | total loss: [1m[32m0.42986[0m[0m | time: 43.677s
[2K
| RMSProp | epoch: 009 | loss: 0.42986 - acc: 0.8005 -- iter: 1248/2147
[A[ATraining Step: 584  | total loss: [1m[32m0.42082[0m[0m | time: 45.037s
[2K
| RMSProp | epoch: 009 | loss: 0.42082 - acc: 0.8111 -- iter: 1280/2147
[A[ATraining Step: 585  | total loss: [1m[32m0.40673[0m[0m | time: 46.411s
[2K
| RMSProp | epoch: 009 | loss: 0.40673 - acc: 0.8175 -- iter: 1312/2147
[A[ATraining Step: 586  | total loss: [1m[32m0.40159[0m[0m | time: 47.645s
[2K
| RMSProp | epoch: 009 | loss: 0.40159 - acc: 0.8170 -- iter: 1344/2147
[A[ATraining Step: 587  | total loss: [1m[32m0.40045[0m[0m | time: 48.850s
[2K
| RMSProp | epoch: 009 | loss: 0.40045 - acc: 0.8196 -- iter: 1376/2147
[A[ATraining Step: 588  | total loss: [1m[32m0.40975[0m[0m | time: 50.149s
[2K
| RMSProp | epoch: 009 | loss: 0.40975 - acc: 0.8096 -- iter: 1408/2147
[A[ATraining Step: 589  | total loss: [1m[32m0.42182[0m[0m | time: 51.617s
[2K
| RMSProp | epoch: 009 | loss: 0.42182 - acc: 0.8098 -- iter: 1440/2147
[A[ATraining Step: 590  | total loss: [1m[32m0.41458[0m[0m | time: 52.852s
[2K
| RMSProp | epoch: 009 | loss: 0.41458 - acc: 0.8164 -- iter: 1472/2147
[A[ATraining Step: 591  | total loss: [1m[32m0.40045[0m[0m | time: 54.181s
[2K
| RMSProp | epoch: 009 | loss: 0.40045 - acc: 0.8285 -- iter: 1504/2147
[A[ATraining Step: 592  | total loss: [1m[32m0.38546[0m[0m | time: 55.481s
[2K
| RMSProp | epoch: 009 | loss: 0.38546 - acc: 0.8331 -- iter: 1536/2147
[A[ATraining Step: 593  | total loss: [1m[32m0.37092[0m[0m | time: 56.957s
[2K
| RMSProp | epoch: 009 | loss: 0.37092 - acc: 0.8436 -- iter: 1568/2147
[A[ATraining Step: 594  | total loss: [1m[32m0.38219[0m[0m | time: 58.316s
[2K
| RMSProp | epoch: 009 | loss: 0.38219 - acc: 0.8373 -- iter: 1600/2147
[A[ATraining Step: 595  | total loss: [1m[32m0.42745[0m[0m | time: 59.405s
[2K
| RMSProp | epoch: 009 | loss: 0.42745 - acc: 0.8223 -- iter: 1632/2147
[A[ATraining Step: 596  | total loss: [1m[32m0.42109[0m[0m | time: 60.663s
[2K
| RMSProp | epoch: 009 | loss: 0.42109 - acc: 0.8245 -- iter: 1664/2147
[A[ATraining Step: 597  | total loss: [1m[32m0.41976[0m[0m | time: 62.179s
[2K
| RMSProp | epoch: 009 | loss: 0.41976 - acc: 0.8202 -- iter: 1696/2147
[A[ATraining Step: 598  | total loss: [1m[32m0.41704[0m[0m | time: 63.434s
[2K
| RMSProp | epoch: 009 | loss: 0.41704 - acc: 0.8163 -- iter: 1728/2147
[A[ATraining Step: 599  | total loss: [1m[32m0.45384[0m[0m | time: 64.515s
[2K
| RMSProp | epoch: 009 | loss: 0.45384 - acc: 0.8128 -- iter: 1760/2147
[A[ATraining Step: 600  | total loss: [1m[32m0.46884[0m[0m | time: 70.861s
[2K
| RMSProp | epoch: 009 | loss: 0.46884 - acc: 0.8034 | val_loss: 0.43173 - val_acc: 0.8095 -- iter: 1792/2147
--
Training Step: 601  | total loss: [1m[32m0.46437[0m[0m | time: 72.400s
[2K
| RMSProp | epoch: 009 | loss: 0.46437 - acc: 0.8012 -- iter: 1824/2147
[A[ATraining Step: 602  | total loss: [1m[32m0.45261[0m[0m | time: 73.769s
[2K
| RMSProp | epoch: 009 | loss: 0.45261 - acc: 0.8148 -- iter: 1856/2147
[A[ATraining Step: 603  | total loss: [1m[32m0.43553[0m[0m | time: 74.907s
[2K
| RMSProp | epoch: 009 | loss: 0.43553 - acc: 0.8271 -- iter: 1888/2147
[A[ATraining Step: 604  | total loss: [1m[32m0.42482[0m[0m | time: 76.214s
[2K
| RMSProp | epoch: 009 | loss: 0.42482 - acc: 0.8350 -- iter: 1920/2147
[A[ATraining Step: 605  | total loss: [1m[32m0.42003[0m[0m | time: 77.641s
[2K
| RMSProp | epoch: 009 | loss: 0.42003 - acc: 0.8359 -- iter: 1952/2147
[A[ATraining Step: 606  | total loss: [1m[32m0.42048[0m[0m | time: 78.887s
[2K
| RMSProp | epoch: 009 | loss: 0.42048 - acc: 0.8304 -- iter: 1984/2147
[A[ATraining Step: 607  | total loss: [1m[32m0.44182[0m[0m | time: 80.168s
[2K
| RMSProp | epoch: 009 | loss: 0.44182 - acc: 0.8130 -- iter: 2016/2147
[A[ATraining Step: 608  | total loss: [1m[32m0.42435[0m[0m | time: 81.490s
[2K
| RMSProp | epoch: 009 | loss: 0.42435 - acc: 0.8254 -- iter: 2048/2147
[A[ATraining Step: 609  | total loss: [1m[32m0.40734[0m[0m | time: 82.790s
[2K
| RMSProp | epoch: 009 | loss: 0.40734 - acc: 0.8366 -- iter: 2080/2147
[A[ATraining Step: 610  | total loss: [1m[32m0.40003[0m[0m | time: 84.068s
[2K
| RMSProp | epoch: 009 | loss: 0.40003 - acc: 0.8374 -- iter: 2112/2147
[A[ATraining Step: 611  | total loss: [1m[32m0.40791[0m[0m | time: 85.315s
[2K
| RMSProp | epoch: 009 | loss: 0.40791 - acc: 0.8349 -- iter: 2144/2147
[A[ATraining Step: 612  | total loss: [1m[32m0.39407[0m[0m | time: 91.328s
[2K
| RMSProp | epoch: 009 | loss: 0.39407 - acc: 0.8389 | val_loss: 0.41488 - val_acc: 0.8244 -- iter: 2147/2147
--
Training Step: 613  | total loss: [1m[32m0.39452[0m[0m | time: 1.392s
[2K
| RMSProp | epoch: 010 | loss: 0.39452 - acc: 0.8394 -- iter: 0032/2147
[A[ATraining Step: 614  | total loss: [1m[32m0.38303[0m[0m | time: 2.751s
[2K
| RMSProp | epoch: 010 | loss: 0.38303 - acc: 0.8492 -- iter: 0064/2147
[A[ATraining Step: 615  | total loss: [1m[32m0.39666[0m[0m | time: 3.942s
[2K
| RMSProp | epoch: 010 | loss: 0.39666 - acc: 0.8424 -- iter: 0096/2147
[A[ATraining Step: 616  | total loss: [1m[32m0.39504[0m[0m | time: 5.413s
[2K
| RMSProp | epoch: 010 | loss: 0.39504 - acc: 0.8394 -- iter: 0128/2147
[A[ATraining Step: 617  | total loss: [1m[32m0.39319[0m[0m | time: 6.803s
[2K
| RMSProp | epoch: 010 | loss: 0.39319 - acc: 0.8336 -- iter: 0160/2147
[A[ATraining Step: 618  | total loss: [1m[32m0.37562[0m[0m | time: 8.214s
[2K
| RMSProp | epoch: 010 | loss: 0.37562 - acc: 0.8409 -- iter: 0192/2147
[A[ATraining Step: 619  | total loss: [1m[32m0.36724[0m[0m | time: 9.353s
[2K
| RMSProp | epoch: 010 | loss: 0.36724 - acc: 0.8443 -- iter: 0224/2147
[A[ATraining Step: 620  | total loss: [1m[32m0.36852[0m[0m | time: 9.519s
[2K
| RMSProp | epoch: 010 | loss: 0.36852 - acc: 0.8473 -- iter: 0256/2147
[A[ATraining Step: 621  | total loss: [1m[32m0.41090[0m[0m | time: 9.680s
[2K
| RMSProp | epoch: 010 | loss: 0.41090 - acc: 0.8293 -- iter: 0288/2147
[A[ATraining Step: 622  | total loss: [1m[32m0.38523[0m[0m | time: 11.020s
[2K
| RMSProp | epoch: 010 | loss: 0.38523 - acc: 0.8463 -- iter: 0320/2147
[A[ATraining Step: 623  | total loss: [1m[32m0.39394[0m[0m | time: 12.480s
[2K
| RMSProp | epoch: 010 | loss: 0.39394 - acc: 0.8398 -- iter: 0352/2147
[A[ATraining Step: 624  | total loss: [1m[32m0.39455[0m[0m | time: 13.938s
[2K
| RMSProp | epoch: 010 | loss: 0.39455 - acc: 0.8371 -- iter: 0384/2147
[A[ATraining Step: 625  | total loss: [1m[32m0.39546[0m[0m | time: 15.213s
[2K
| RMSProp | epoch: 010 | loss: 0.39546 - acc: 0.8378 -- iter: 0416/2147
[A[ATraining Step: 626  | total loss: [1m[32m0.39903[0m[0m | time: 16.498s
[2K
| RMSProp | epoch: 010 | loss: 0.39903 - acc: 0.8384 -- iter: 0448/2147
[A[ATraining Step: 627  | total loss: [1m[32m0.39063[0m[0m | time: 17.838s
[2K
| RMSProp | epoch: 010 | loss: 0.39063 - acc: 0.8389 -- iter: 0480/2147
[A[ATraining Step: 628  | total loss: [1m[32m0.38133[0m[0m | time: 19.193s
[2K
| RMSProp | epoch: 010 | loss: 0.38133 - acc: 0.8425 -- iter: 0512/2147
[A[ATraining Step: 629  | total loss: [1m[32m0.37392[0m[0m | time: 20.370s
[2K
| RMSProp | epoch: 010 | loss: 0.37392 - acc: 0.8426 -- iter: 0544/2147
[A[ATraining Step: 630  | total loss: [1m[32m0.38362[0m[0m | time: 21.567s
[2K
| RMSProp | epoch: 010 | loss: 0.38362 - acc: 0.8365 -- iter: 0576/2147
[A[ATraining Step: 631  | total loss: [1m[32m0.40926[0m[0m | time: 23.004s
[2K
| RMSProp | epoch: 010 | loss: 0.40926 - acc: 0.8247 -- iter: 0608/2147
[A[ATraining Step: 632  | total loss: [1m[32m0.41070[0m[0m | time: 24.405s
[2K
| RMSProp | epoch: 010 | loss: 0.41070 - acc: 0.8204 -- iter: 0640/2147
[A[ATraining Step: 633  | total loss: [1m[32m0.42242[0m[0m | time: 25.560s
[2K
| RMSProp | epoch: 010 | loss: 0.42242 - acc: 0.8196 -- iter: 0672/2147
[A[ATraining Step: 634  | total loss: [1m[32m0.43349[0m[0m | time: 26.843s
[2K
| RMSProp | epoch: 010 | loss: 0.43349 - acc: 0.8126 -- iter: 0704/2147
[A[ATraining Step: 635  | total loss: [1m[32m0.45263[0m[0m | time: 28.414s
[2K
| RMSProp | epoch: 010 | loss: 0.45263 - acc: 0.7970 -- iter: 0736/2147
[A[ATraining Step: 636  | total loss: [1m[32m0.44966[0m[0m | time: 29.820s
[2K
| RMSProp | epoch: 010 | loss: 0.44966 - acc: 0.7985 -- iter: 0768/2147
[A[ATraining Step: 637  | total loss: [1m[32m0.44599[0m[0m | time: 31.064s
[2K
| RMSProp | epoch: 010 | loss: 0.44599 - acc: 0.8062 -- iter: 0800/2147
[A[ATraining Step: 638  | total loss: [1m[32m0.44112[0m[0m | time: 32.244s
[2K
| RMSProp | epoch: 010 | loss: 0.44112 - acc: 0.8068 -- iter: 0832/2147
[A[ATraining Step: 639  | total loss: [1m[32m0.44418[0m[0m | time: 33.565s
[2K
| RMSProp | epoch: 010 | loss: 0.44418 - acc: 0.7980 -- iter: 0864/2147
[A[ATraining Step: 640  | total loss: [1m[32m0.42925[0m[0m | time: 34.988s
[2K
| RMSProp | epoch: 010 | loss: 0.42925 - acc: 0.8088 -- iter: 0896/2147
[A[ATraining Step: 641  | total loss: [1m[32m0.45035[0m[0m | time: 36.192s
[2K
| RMSProp | epoch: 010 | loss: 0.45035 - acc: 0.7967 -- iter: 0928/2147
[A[ATraining Step: 642  | total loss: [1m[32m0.44348[0m[0m | time: 37.467s
[2K
| RMSProp | epoch: 010 | loss: 0.44348 - acc: 0.8045 -- iter: 0960/2147
[A[ATraining Step: 643  | total loss: [1m[32m0.42934[0m[0m | time: 39.018s
[2K
| RMSProp | epoch: 010 | loss: 0.42934 - acc: 0.8147 -- iter: 0992/2147
[A[ATraining Step: 644  | total loss: [1m[32m0.41657[0m[0m | time: 40.552s
[2K
| RMSProp | epoch: 010 | loss: 0.41657 - acc: 0.8239 -- iter: 1024/2147
[A[ATraining Step: 645  | total loss: [1m[32m0.41415[0m[0m | time: 41.796s
[2K
| RMSProp | epoch: 010 | loss: 0.41415 - acc: 0.8196 -- iter: 1056/2147
[A[ATraining Step: 646  | total loss: [1m[32m0.39627[0m[0m | time: 42.966s
[2K
| RMSProp | epoch: 010 | loss: 0.39627 - acc: 0.8283 -- iter: 1088/2147
[A[ATraining Step: 647  | total loss: [1m[32m0.38857[0m[0m | time: 44.328s
[2K
| RMSProp | epoch: 010 | loss: 0.38857 - acc: 0.8361 -- iter: 1120/2147
[A[ATraining Step: 648  | total loss: [1m[32m0.36325[0m[0m | time: 45.721s
[2K
| RMSProp | epoch: 010 | loss: 0.36325 - acc: 0.8525 -- iter: 1152/2147
[A[ATraining Step: 649  | total loss: [1m[32m0.35391[0m[0m | time: 47.114s
[2K
| RMSProp | epoch: 010 | loss: 0.35391 - acc: 0.8578 -- iter: 1184/2147
[A[ATraining Step: 650  | total loss: [1m[32m0.36150[0m[0m | time: 48.501s
[2K
| RMSProp | epoch: 010 | loss: 0.36150 - acc: 0.8502 -- iter: 1216/2147
[A[ATraining Step: 651  | total loss: [1m[32m0.36644[0m[0m | time: 49.808s
[2K
| RMSProp | epoch: 010 | loss: 0.36644 - acc: 0.8495 -- iter: 1248/2147
[A[ATraining Step: 652  | total loss: [1m[32m0.38064[0m[0m | time: 51.075s
[2K
| RMSProp | epoch: 010 | loss: 0.38064 - acc: 0.8396 -- iter: 1280/2147
[A[ATraining Step: 653  | total loss: [1m[32m0.41782[0m[0m | time: 52.262s
[2K
| RMSProp | epoch: 010 | loss: 0.41782 - acc: 0.8212 -- iter: 1312/2147
[A[ATraining Step: 654  | total loss: [1m[32m0.43820[0m[0m | time: 53.579s
[2K
| RMSProp | epoch: 010 | loss: 0.43820 - acc: 0.8016 -- iter: 1344/2147
[A[ATraining Step: 655  | total loss: [1m[32m0.43053[0m[0m | time: 55.061s
[2K
| RMSProp | epoch: 010 | loss: 0.43053 - acc: 0.8058 -- iter: 1376/2147
[A[ATraining Step: 656  | total loss: [1m[32m0.41737[0m[0m | time: 56.788s
[2K
| RMSProp | epoch: 010 | loss: 0.41737 - acc: 0.8096 -- iter: 1408/2147
[A[ATraining Step: 657  | total loss: [1m[32m0.40564[0m[0m | time: 57.966s
[2K
| RMSProp | epoch: 010 | loss: 0.40564 - acc: 0.8162 -- iter: 1440/2147
[A[ATraining Step: 658  | total loss: [1m[32m0.40845[0m[0m | time: 59.104s
[2K
| RMSProp | epoch: 010 | loss: 0.40845 - acc: 0.8252 -- iter: 1472/2147
[A[ATraining Step: 659  | total loss: [1m[32m0.38655[0m[0m | time: 60.388s
[2K
| RMSProp | epoch: 010 | loss: 0.38655 - acc: 0.8395 -- iter: 1504/2147
[A[ATraining Step: 660  | total loss: [1m[32m0.38378[0m[0m | time: 61.741s
[2K
| RMSProp | epoch: 010 | loss: 0.38378 - acc: 0.8400 -- iter: 1536/2147
[A[ATraining Step: 661  | total loss: [1m[32m0.40724[0m[0m | time: 62.953s
[2K
| RMSProp | epoch: 010 | loss: 0.40724 - acc: 0.8310 -- iter: 1568/2147
[A[ATraining Step: 662  | total loss: [1m[32m0.40132[0m[0m | time: 64.209s
[2K
| RMSProp | epoch: 010 | loss: 0.40132 - acc: 0.8322 -- iter: 1600/2147
[A[ATraining Step: 663  | total loss: [1m[32m0.39053[0m[0m | time: 65.495s
[2K
| RMSProp | epoch: 010 | loss: 0.39053 - acc: 0.8428 -- iter: 1632/2147
[A[ATraining Step: 664  | total loss: [1m[32m0.37514[0m[0m | time: 66.579s
[2K
| RMSProp | epoch: 010 | loss: 0.37514 - acc: 0.8522 -- iter: 1664/2147
[A[ATraining Step: 665  | total loss: [1m[32m0.36694[0m[0m | time: 67.846s
[2K
| RMSProp | epoch: 010 | loss: 0.36694 - acc: 0.8545 -- iter: 1696/2147
[A[ATraining Step: 666  | total loss: [1m[32m0.35371[0m[0m | time: 69.176s
[2K
| RMSProp | epoch: 010 | loss: 0.35371 - acc: 0.8566 -- iter: 1728/2147
[A[ATraining Step: 667  | total loss: [1m[32m0.36509[0m[0m | time: 70.430s
[2K
| RMSProp | epoch: 010 | loss: 0.36509 - acc: 0.8522 -- iter: 1760/2147
[A[ATraining Step: 668  | total loss: [1m[32m0.36723[0m[0m | time: 71.487s
[2K
| RMSProp | epoch: 010 | loss: 0.36723 - acc: 0.8357 -- iter: 1792/2147
[A[ATraining Step: 669  | total loss: [1m[32m0.37093[0m[0m | time: 72.408s
[2K
| RMSProp | epoch: 010 | loss: 0.37093 - acc: 0.8334 -- iter: 1824/2147
[A[ATraining Step: 670  | total loss: [1m[32m0.35678[0m[0m | time: 73.319s
[2K
| RMSProp | epoch: 010 | loss: 0.35678 - acc: 0.8469 -- iter: 1856/2147
[A[ATraining Step: 671  | total loss: [1m[32m0.36789[0m[0m | time: 74.273s
[2K
| RMSProp | epoch: 010 | loss: 0.36789 - acc: 0.8435 -- iter: 1888/2147
[A[ATraining Step: 672  | total loss: [1m[32m0.36320[0m[0m | time: 75.314s
[2K
| RMSProp | epoch: 010 | loss: 0.36320 - acc: 0.8529 -- iter: 1920/2147
[A[ATraining Step: 673  | total loss: [1m[32m0.36107[0m[0m | time: 76.422s
[2K
| RMSProp | epoch: 010 | loss: 0.36107 - acc: 0.8520 -- iter: 1952/2147
[A[ATraining Step: 674  | total loss: [1m[32m0.34819[0m[0m | time: 77.354s
[2K
| RMSProp | epoch: 010 | loss: 0.34819 - acc: 0.8605 -- iter: 1984/2147
[A[ATraining Step: 675  | total loss: [1m[32m0.34627[0m[0m | time: 78.332s
[2K
| RMSProp | epoch: 010 | loss: 0.34627 - acc: 0.8651 -- iter: 2016/2147
[A[ATraining Step: 676  | total loss: [1m[32m0.35689[0m[0m | time: 79.411s
[2K
| RMSProp | epoch: 010 | loss: 0.35689 - acc: 0.8598 -- iter: 2048/2147
[A[ATraining Step: 677  | total loss: [1m[32m0.36146[0m[0m | time: 80.608s
[2K
| RMSProp | epoch: 010 | loss: 0.36146 - acc: 0.8645 -- iter: 2080/2147
[A[ATraining Step: 678  | total loss: [1m[32m0.37750[0m[0m | time: 81.929s
[2K
| RMSProp | epoch: 010 | loss: 0.37750 - acc: 0.8499 -- iter: 2112/2147
[A[ATraining Step: 679  | total loss: [1m[32m0.38198[0m[0m | time: 83.178s
[2K
| RMSProp | epoch: 010 | loss: 0.38198 - acc: 0.8368 -- iter: 2144/2147
[A[ATraining Step: 680  | total loss: [1m[32m0.37613[0m[0m | time: 89.255s
[2K
| RMSProp | epoch: 010 | loss: 0.37613 - acc: 0.8406 | val_loss: 0.39513 - val_acc: 0.8408 -- iter: 2147/2147
--
Training Step: 681  | total loss: [1m[32m0.35940[0m[0m | time: 1.223s
[2K
| RMSProp | epoch: 011 | loss: 0.35940 - acc: 0.8534 -- iter: 0032/2147
[A[ATraining Step: 682  | total loss: [1m[32m0.35838[0m[0m | time: 2.478s
[2K
| RMSProp | epoch: 011 | loss: 0.35838 - acc: 0.8556 -- iter: 0064/2147
[A[ATraining Step: 683  | total loss: [1m[32m0.35537[0m[0m | time: 3.788s
[2K
| RMSProp | epoch: 011 | loss: 0.35537 - acc: 0.8575 -- iter: 0096/2147
[A[ATraining Step: 684  | total loss: [1m[32m0.35769[0m[0m | time: 5.097s
[2K
| RMSProp | epoch: 011 | loss: 0.35769 - acc: 0.8561 -- iter: 0128/2147
[A[ATraining Step: 685  | total loss: [1m[32m0.34500[0m[0m | time: 6.461s
[2K
| RMSProp | epoch: 011 | loss: 0.34500 - acc: 0.8643 -- iter: 0160/2147
[A[ATraining Step: 686  | total loss: [1m[32m0.35360[0m[0m | time: 7.686s
[2K
| RMSProp | epoch: 011 | loss: 0.35360 - acc: 0.8591 -- iter: 0192/2147
[A[ATraining Step: 687  | total loss: [1m[32m0.34196[0m[0m | time: 8.886s
[2K
| RMSProp | epoch: 011 | loss: 0.34196 - acc: 0.8638 -- iter: 0224/2147
[A[ATraining Step: 688  | total loss: [1m[32m0.34294[0m[0m | time: 9.975s
[2K
| RMSProp | epoch: 011 | loss: 0.34294 - acc: 0.8649 -- iter: 0256/2147
[A[ATraining Step: 689  | total loss: [1m[32m0.34702[0m[0m | time: 10.110s
[2K
| RMSProp | epoch: 011 | loss: 0.34702 - acc: 0.8597 -- iter: 0288/2147
[A[ATraining Step: 690  | total loss: [1m[32m0.37616[0m[0m | time: 10.250s
[2K
| RMSProp | epoch: 011 | loss: 0.37616 - acc: 0.8404 -- iter: 0320/2147
[A[ATraining Step: 691  | total loss: [1m[32m0.36702[0m[0m | time: 11.195s
[2K
| RMSProp | epoch: 011 | loss: 0.36702 - acc: 0.8563 -- iter: 0352/2147
[A[ATraining Step: 692  | total loss: [1m[32m0.38869[0m[0m | time: 12.219s
[2K
| RMSProp | epoch: 011 | loss: 0.38869 - acc: 0.8363 -- iter: 0384/2147
[A[ATraining Step: 693  | total loss: [1m[32m0.40056[0m[0m | time: 13.330s
[2K
| RMSProp | epoch: 011 | loss: 0.40056 - acc: 0.8308 -- iter: 0416/2147
[A[ATraining Step: 694  | total loss: [1m[32m0.38976[0m[0m | time: 14.241s
[2K
| RMSProp | epoch: 011 | loss: 0.38976 - acc: 0.8352 -- iter: 0448/2147
[A[ATraining Step: 695  | total loss: [1m[32m0.37604[0m[0m | time: 15.268s
[2K
| RMSProp | epoch: 011 | loss: 0.37604 - acc: 0.8423 -- iter: 0480/2147
[A[ATraining Step: 696  | total loss: [1m[32m0.36884[0m[0m | time: 16.318s
[2K
| RMSProp | epoch: 011 | loss: 0.36884 - acc: 0.8487 -- iter: 0512/2147
[A[ATraining Step: 697  | total loss: [1m[32m0.38443[0m[0m | time: 17.571s
[2K
| RMSProp | epoch: 011 | loss: 0.38443 - acc: 0.8420 -- iter: 0544/2147
[A[ATraining Step: 698  | total loss: [1m[32m0.38471[0m[0m | time: 18.579s
[2K
| RMSProp | epoch: 011 | loss: 0.38471 - acc: 0.8453 -- iter: 0576/2147
[A[ATraining Step: 699  | total loss: [1m[32m0.37932[0m[0m | time: 19.529s
[2K
| RMSProp | epoch: 011 | loss: 0.37932 - acc: 0.8451 -- iter: 0608/2147
[A[ATraining Step: 700  | total loss: [1m[32m0.37591[0m[0m | time: 20.517s
[2K
| RMSProp | epoch: 011 | loss: 0.37591 - acc: 0.8481 -- iter: 0640/2147
[A[ATraining Step: 701  | total loss: [1m[32m0.38088[0m[0m | time: 21.501s
[2K
| RMSProp | epoch: 011 | loss: 0.38088 - acc: 0.8477 -- iter: 0672/2147
[A[ATraining Step: 702  | total loss: [1m[32m0.38416[0m[0m | time: 22.564s
[2K
| RMSProp | epoch: 011 | loss: 0.38416 - acc: 0.8442 -- iter: 0704/2147
[A[ATraining Step: 703  | total loss: [1m[32m0.38310[0m[0m | time: 23.720s
[2K
| RMSProp | epoch: 011 | loss: 0.38310 - acc: 0.8441 -- iter: 0736/2147
[A[ATraining Step: 704  | total loss: [1m[32m0.38116[0m[0m | time: 24.633s
[2K
| RMSProp | epoch: 011 | loss: 0.38116 - acc: 0.8410 -- iter: 0768/2147
[A[ATraining Step: 705  | total loss: [1m[32m0.39497[0m[0m | time: 25.782s
[2K
| RMSProp | epoch: 011 | loss: 0.39497 - acc: 0.8444 -- iter: 0800/2147
[A[ATraining Step: 706  | total loss: [1m[32m0.41350[0m[0m | time: 26.913s
[2K
| RMSProp | epoch: 011 | loss: 0.41350 - acc: 0.8318 -- iter: 0832/2147
[A[ATraining Step: 707  | total loss: [1m[32m0.42208[0m[0m | time: 28.072s
[2K
| RMSProp | epoch: 011 | loss: 0.42208 - acc: 0.8174 -- iter: 0864/2147
[A[ATraining Step: 708  | total loss: [1m[32m0.42291[0m[0m | time: 28.975s
[2K
| RMSProp | epoch: 011 | loss: 0.42291 - acc: 0.8169 -- iter: 0896/2147
[A[ATraining Step: 709  | total loss: [1m[32m0.40597[0m[0m | time: 30.013s
[2K
| RMSProp | epoch: 011 | loss: 0.40597 - acc: 0.8289 -- iter: 0928/2147
[A[ATraining Step: 710  | total loss: [1m[32m0.39273[0m[0m | time: 31.008s
[2K
| RMSProp | epoch: 011 | loss: 0.39273 - acc: 0.8336 -- iter: 0960/2147
[A[ATraining Step: 711  | total loss: [1m[32m0.37460[0m[0m | time: 32.034s
[2K
| RMSProp | epoch: 011 | loss: 0.37460 - acc: 0.8439 -- iter: 0992/2147
[A[ATraining Step: 712  | total loss: [1m[32m0.42311[0m[0m | time: 33.226s
[2K
| RMSProp | epoch: 011 | loss: 0.42311 - acc: 0.8252 -- iter: 1024/2147
[A[ATraining Step: 713  | total loss: [1m[32m0.41000[0m[0m | time: 34.211s
[2K
| RMSProp | epoch: 011 | loss: 0.41000 - acc: 0.8302 -- iter: 1056/2147
[A[ATraining Step: 714  | total loss: [1m[32m0.39918[0m[0m | time: 35.265s
[2K
| RMSProp | epoch: 011 | loss: 0.39918 - acc: 0.8315 -- iter: 1088/2147
[A[ATraining Step: 715  | total loss: [1m[32m0.39098[0m[0m | time: 36.288s
[2K
| RMSProp | epoch: 011 | loss: 0.39098 - acc: 0.8390 -- iter: 1120/2147
[A[ATraining Step: 716  | total loss: [1m[32m0.37453[0m[0m | time: 37.390s
[2K
| RMSProp | epoch: 011 | loss: 0.37453 - acc: 0.8488 -- iter: 1152/2147
[A[ATraining Step: 717  | total loss: [1m[32m0.35722[0m[0m | time: 38.457s
[2K
| RMSProp | epoch: 011 | loss: 0.35722 - acc: 0.8608 -- iter: 1184/2147
[A[ATraining Step: 718  | total loss: [1m[32m0.33673[0m[0m | time: 39.498s
[2K
| RMSProp | epoch: 011 | loss: 0.33673 - acc: 0.8685 -- iter: 1216/2147
[A[ATraining Step: 719  | total loss: [1m[32m0.32020[0m[0m | time: 40.554s
[2K
| RMSProp | epoch: 011 | loss: 0.32020 - acc: 0.8754 -- iter: 1248/2147
[A[ATraining Step: 720  | total loss: [1m[32m0.31713[0m[0m | time: 41.469s
[2K
| RMSProp | epoch: 011 | loss: 0.31713 - acc: 0.8722 -- iter: 1280/2147
[A[ATraining Step: 721  | total loss: [1m[32m0.35724[0m[0m | time: 42.394s
[2K
| RMSProp | epoch: 011 | loss: 0.35724 - acc: 0.8538 -- iter: 1312/2147
[A[ATraining Step: 722  | total loss: [1m[32m0.34610[0m[0m | time: 43.023s
[2K
| RMSProp | epoch: 011 | loss: 0.34610 - acc: 0.8621 -- iter: 1344/2147
[A[ATraining Step: 723  | total loss: [1m[32m0.34473[0m[0m | time: 43.623s
[2K
| RMSProp | epoch: 011 | loss: 0.34473 - acc: 0.8572 -- iter: 1376/2147
[A[ATraining Step: 724  | total loss: [1m[32m0.33105[0m[0m | time: 44.241s
[2K
| RMSProp | epoch: 011 | loss: 0.33105 - acc: 0.8683 -- iter: 1408/2147
[A[ATraining Step: 725  | total loss: [1m[32m0.32579[0m[0m | time: 44.867s
[2K
| RMSProp | epoch: 011 | loss: 0.32579 - acc: 0.8721 -- iter: 1440/2147
[A[ATraining Step: 726  | total loss: [1m[32m0.30979[0m[0m | time: 45.476s
[2K
| RMSProp | epoch: 011 | loss: 0.30979 - acc: 0.8818 -- iter: 1472/2147
[A[ATraining Step: 727  | total loss: [1m[32m0.40392[0m[0m | time: 46.398s
[2K
| RMSProp | epoch: 011 | loss: 0.40392 - acc: 0.8467 -- iter: 1504/2147
[A[ATraining Step: 728  | total loss: [1m[32m0.39066[0m[0m | time: 47.374s
[2K
| RMSProp | epoch: 011 | loss: 0.39066 - acc: 0.8496 -- iter: 1536/2147
[A[ATraining Step: 729  | total loss: [1m[32m0.37133[0m[0m | time: 48.327s
[2K
| RMSProp | epoch: 011 | loss: 0.37133 - acc: 0.8615 -- iter: 1568/2147
[A[ATraining Step: 730  | total loss: [1m[32m0.35989[0m[0m | time: 49.220s
[2K
| RMSProp | epoch: 011 | loss: 0.35989 - acc: 0.8722 -- iter: 1600/2147
[A[ATraining Step: 731  | total loss: [1m[32m0.35224[0m[0m | time: 50.174s
[2K
| RMSProp | epoch: 011 | loss: 0.35224 - acc: 0.8725 -- iter: 1632/2147
[A[ATraining Step: 732  | total loss: [1m[32m0.34794[0m[0m | time: 51.212s
[2K
| RMSProp | epoch: 011 | loss: 0.34794 - acc: 0.8696 -- iter: 1664/2147
[A[ATraining Step: 733  | total loss: [1m[32m0.35803[0m[0m | time: 52.172s
[2K
| RMSProp | epoch: 011 | loss: 0.35803 - acc: 0.8639 -- iter: 1696/2147
[A[ATraining Step: 734  | total loss: [1m[32m0.35873[0m[0m | time: 53.158s
[2K
| RMSProp | epoch: 011 | loss: 0.35873 - acc: 0.8588 -- iter: 1728/2147
[A[ATraining Step: 735  | total loss: [1m[32m0.34864[0m[0m | time: 54.210s
[2K
| RMSProp | epoch: 011 | loss: 0.34864 - acc: 0.8604 -- iter: 1760/2147
[A[ATraining Step: 736  | total loss: [1m[32m0.33787[0m[0m | time: 55.468s
[2K
| RMSProp | epoch: 011 | loss: 0.33787 - acc: 0.8681 -- iter: 1792/2147
[A[ATraining Step: 737  | total loss: [1m[32m0.33798[0m[0m | time: 56.511s
[2K
| RMSProp | epoch: 011 | loss: 0.33798 - acc: 0.8625 -- iter: 1824/2147
[A[ATraining Step: 738  | total loss: [1m[32m0.34668[0m[0m | time: 57.447s
[2K
| RMSProp | epoch: 011 | loss: 0.34668 - acc: 0.8575 -- iter: 1856/2147
[A[ATraining Step: 739  | total loss: [1m[32m0.33671[0m[0m | time: 58.361s
[2K
| RMSProp | epoch: 011 | loss: 0.33671 - acc: 0.8624 -- iter: 1888/2147
[A[ATraining Step: 740  | total loss: [1m[32m0.32954[0m[0m | time: 59.293s
[2K
| RMSProp | epoch: 011 | loss: 0.32954 - acc: 0.8668 -- iter: 1920/2147
[A[ATraining Step: 741  | total loss: [1m[32m0.32123[0m[0m | time: 60.208s
[2K
| RMSProp | epoch: 011 | loss: 0.32123 - acc: 0.8739 -- iter: 1952/2147
[A[ATraining Step: 742  | total loss: [1m[32m0.33172[0m[0m | time: 61.330s
[2K
| RMSProp | epoch: 011 | loss: 0.33172 - acc: 0.8646 -- iter: 1984/2147
[A[ATraining Step: 743  | total loss: [1m[32m0.33830[0m[0m | time: 62.339s
[2K
| RMSProp | epoch: 011 | loss: 0.33830 - acc: 0.8500 -- iter: 2016/2147
[A[ATraining Step: 744  | total loss: [1m[32m0.33350[0m[0m | time: 63.225s
[2K
| RMSProp | epoch: 011 | loss: 0.33350 - acc: 0.8556 -- iter: 2048/2147
[A[ATraining Step: 745  | total loss: [1m[32m0.34558[0m[0m | time: 64.350s
[2K
| RMSProp | epoch: 011 | loss: 0.34558 - acc: 0.8544 -- iter: 2080/2147
[A[ATraining Step: 746  | total loss: [1m[32m0.33867[0m[0m | time: 65.477s
[2K
| RMSProp | epoch: 011 | loss: 0.33867 - acc: 0.8596 -- iter: 2112/2147
[A[ATraining Step: 747  | total loss: [1m[32m0.33809[0m[0m | time: 66.502s
[2K
| RMSProp | epoch: 011 | loss: 0.33809 - acc: 0.8612 -- iter: 2144/2147
[A[ATraining Step: 748  | total loss: [1m[32m0.32519[0m[0m | time: 70.839s
[2K
| RMSProp | epoch: 011 | loss: 0.32519 - acc: 0.8688 | val_loss: 0.36640 - val_acc: 0.8467 -- iter: 2147/2147
--
Training Step: 749  | total loss: [1m[32m0.30500[0m[0m | time: 1.409s
[2K
| RMSProp | epoch: 012 | loss: 0.30500 - acc: 0.8788 -- iter: 0032/2147
[A[ATraining Step: 750  | total loss: [1m[32m0.30445[0m[0m | time: 2.647s
[2K
| RMSProp | epoch: 012 | loss: 0.30445 - acc: 0.8753 -- iter: 0064/2147
[A[ATraining Step: 751  | total loss: [1m[32m0.31113[0m[0m | time: 3.784s
[2K
| RMSProp | epoch: 012 | loss: 0.31113 - acc: 0.8690 -- iter: 0096/2147
[A[ATraining Step: 752  | total loss: [1m[32m0.31931[0m[0m | time: 5.077s
[2K
| RMSProp | epoch: 012 | loss: 0.31931 - acc: 0.8634 -- iter: 0128/2147
[A[ATraining Step: 753  | total loss: [1m[32m0.30324[0m[0m | time: 6.532s
[2K
| RMSProp | epoch: 012 | loss: 0.30324 - acc: 0.8739 -- iter: 0160/2147
[A[ATraining Step: 754  | total loss: [1m[32m0.30232[0m[0m | time: 7.961s
[2K
| RMSProp | epoch: 012 | loss: 0.30232 - acc: 0.8740 -- iter: 0192/2147
[A[ATraining Step: 755  | total loss: [1m[32m0.30001[0m[0m | time: 9.122s
[2K
| RMSProp | epoch: 012 | loss: 0.30001 - acc: 0.8741 -- iter: 0224/2147
[A[ATraining Step: 756  | total loss: [1m[32m0.29313[0m[0m | time: 10.457s
[2K
| RMSProp | epoch: 012 | loss: 0.29313 - acc: 0.8804 -- iter: 0256/2147
[A[ATraining Step: 757  | total loss: [1m[32m0.30474[0m[0m | time: 11.800s
[2K
| RMSProp | epoch: 012 | loss: 0.30474 - acc: 0.8737 -- iter: 0288/2147
[A[ATraining Step: 758  | total loss: [1m[32m0.32842[0m[0m | time: 11.992s
[2K
| RMSProp | epoch: 012 | loss: 0.32842 - acc: 0.8644 -- iter: 0320/2147
[A[ATraining Step: 759  | total loss: [1m[32m0.33897[0m[0m | time: 12.191s
[2K
| RMSProp | epoch: 012 | loss: 0.33897 - acc: 0.8446 -- iter: 0352/2147
[A[ATraining Step: 760  | total loss: [1m[32m0.33573[0m[0m | time: 13.359s
[2K
| RMSProp | epoch: 012 | loss: 0.33573 - acc: 0.8268 -- iter: 0384/2147
[A[ATraining Step: 761  | total loss: [1m[32m0.33378[0m[0m | time: 14.645s
[2K
| RMSProp | epoch: 012 | loss: 0.33378 - acc: 0.8317 -- iter: 0416/2147
[A[ATraining Step: 762  | total loss: [1m[32m0.34196[0m[0m | time: 16.039s
[2K
| RMSProp | epoch: 012 | loss: 0.34196 - acc: 0.8329 -- iter: 0448/2147
[A[ATraining Step: 763  | total loss: [1m[32m0.33199[0m[0m | time: 17.581s
[2K
| RMSProp | epoch: 012 | loss: 0.33199 - acc: 0.8433 -- iter: 0480/2147
[A[ATraining Step: 764  | total loss: [1m[32m0.30625[0m[0m | time: 18.810s
[2K
| RMSProp | epoch: 012 | loss: 0.30625 - acc: 0.8590 -- iter: 0512/2147
[A[ATraining Step: 765  | total loss: [1m[32m0.31970[0m[0m | time: 19.987s
[2K
| RMSProp | epoch: 012 | loss: 0.31970 - acc: 0.8575 -- iter: 0544/2147
[A[ATraining Step: 766  | total loss: [1m[32m0.31885[0m[0m | time: 21.332s
[2K
| RMSProp | epoch: 012 | loss: 0.31885 - acc: 0.8623 -- iter: 0576/2147
[A[ATraining Step: 767  | total loss: [1m[32m0.32045[0m[0m | time: 22.621s
[2K
| RMSProp | epoch: 012 | loss: 0.32045 - acc: 0.8636 -- iter: 0608/2147
[A[ATraining Step: 768  | total loss: [1m[32m0.30493[0m[0m | time: 24.067s
[2K
| RMSProp | epoch: 012 | loss: 0.30493 - acc: 0.8741 -- iter: 0640/2147
[A[ATraining Step: 769  | total loss: [1m[32m0.30034[0m[0m | time: 25.329s
[2K
| RMSProp | epoch: 012 | loss: 0.30034 - acc: 0.8773 -- iter: 0672/2147
[A[ATraining Step: 770  | total loss: [1m[32m0.29171[0m[0m | time: 26.537s
[2K
| RMSProp | epoch: 012 | loss: 0.29171 - acc: 0.8771 -- iter: 0704/2147
[A[ATraining Step: 771  | total loss: [1m[32m0.29774[0m[0m | time: 27.704s
[2K
| RMSProp | epoch: 012 | loss: 0.29774 - acc: 0.8738 -- iter: 0736/2147
[A[ATraining Step: 772  | total loss: [1m[32m0.30220[0m[0m | time: 29.093s
[2K
| RMSProp | epoch: 012 | loss: 0.30220 - acc: 0.8708 -- iter: 0768/2147
[A[ATraining Step: 773  | total loss: [1m[32m0.30250[0m[0m | time: 30.475s
[2K
| RMSProp | epoch: 012 | loss: 0.30250 - acc: 0.8681 -- iter: 0800/2147
[A[ATraining Step: 774  | total loss: [1m[32m0.29430[0m[0m | time: 31.998s
[2K
| RMSProp | epoch: 012 | loss: 0.29430 - acc: 0.8750 -- iter: 0832/2147
[A[ATraining Step: 775  | total loss: [1m[32m0.28778[0m[0m | time: 33.341s
[2K
| RMSProp | epoch: 012 | loss: 0.28778 - acc: 0.8813 -- iter: 0864/2147
[A[ATraining Step: 776  | total loss: [1m[32m0.29318[0m[0m | time: 34.489s
[2K
| RMSProp | epoch: 012 | loss: 0.29318 - acc: 0.8806 -- iter: 0896/2147
[A[ATraining Step: 777  | total loss: [1m[32m0.27804[0m[0m | time: 35.650s
[2K
| RMSProp | epoch: 012 | loss: 0.27804 - acc: 0.8894 -- iter: 0928/2147
[A[ATraining Step: 778  | total loss: [1m[32m0.28477[0m[0m | time: 36.952s
[2K
| RMSProp | epoch: 012 | loss: 0.28477 - acc: 0.8880 -- iter: 0960/2147
[A[ATraining Step: 779  | total loss: [1m[32m0.27966[0m[0m | time: 38.352s
[2K
| RMSProp | epoch: 012 | loss: 0.27966 - acc: 0.8898 -- iter: 0992/2147
[A[ATraining Step: 780  | total loss: [1m[32m0.29719[0m[0m | time: 39.901s
[2K
| RMSProp | epoch: 012 | loss: 0.29719 - acc: 0.8821 -- iter: 1024/2147
[A[ATraining Step: 781  | total loss: [1m[32m0.29212[0m[0m | time: 41.254s
[2K
| RMSProp | epoch: 012 | loss: 0.29212 - acc: 0.8845 -- iter: 1056/2147
[A[ATraining Step: 782  | total loss: [1m[32m0.28562[0m[0m | time: 42.408s
[2K
| RMSProp | epoch: 012 | loss: 0.28562 - acc: 0.8867 -- iter: 1088/2147
[A[ATraining Step: 783  | total loss: [1m[32m0.27896[0m[0m | time: 43.491s
[2K
| RMSProp | epoch: 012 | loss: 0.27896 - acc: 0.8886 -- iter: 1120/2147
[A[ATraining Step: 784  | total loss: [1m[32m0.26899[0m[0m | time: 44.817s
[2K
| RMSProp | epoch: 012 | loss: 0.26899 - acc: 0.8935 -- iter: 1152/2147
[A[ATraining Step: 785  | total loss: [1m[32m0.27510[0m[0m | time: 46.225s
[2K
| RMSProp | epoch: 012 | loss: 0.27510 - acc: 0.8885 -- iter: 1184/2147
[A[ATraining Step: 786  | total loss: [1m[32m0.29030[0m[0m | time: 47.604s
[2K
| RMSProp | epoch: 012 | loss: 0.29030 - acc: 0.8809 -- iter: 1216/2147
[A[ATraining Step: 787  | total loss: [1m[32m0.30175[0m[0m | time: 49.143s
[2K
| RMSProp | epoch: 012 | loss: 0.30175 - acc: 0.8803 -- iter: 1248/2147
[A[ATraining Step: 788  | total loss: [1m[32m0.30388[0m[0m | time: 50.406s
[2K
| RMSProp | epoch: 012 | loss: 0.30388 - acc: 0.8798 -- iter: 1280/2147
[A[ATraining Step: 789  | total loss: [1m[32m0.30234[0m[0m | time: 51.735s
[2K
| RMSProp | epoch: 012 | loss: 0.30234 - acc: 0.8825 -- iter: 1312/2147
[A[ATraining Step: 790  | total loss: [1m[32m0.29752[0m[0m | time: 53.040s
[2K
| RMSProp | epoch: 012 | loss: 0.29752 - acc: 0.8817 -- iter: 1344/2147
[A[ATraining Step: 791  | total loss: [1m[32m0.29516[0m[0m | time: 54.444s
[2K
| RMSProp | epoch: 012 | loss: 0.29516 - acc: 0.8873 -- iter: 1376/2147
[A[ATraining Step: 792  | total loss: [1m[32m0.29378[0m[0m | time: 56.024s
[2K
| RMSProp | epoch: 012 | loss: 0.29378 - acc: 0.8798 -- iter: 1408/2147
[A[ATraining Step: 793  | total loss: [1m[32m0.28341[0m[0m | time: 57.441s
[2K
| RMSProp | epoch: 012 | loss: 0.28341 - acc: 0.8887 -- iter: 1440/2147
[A[ATraining Step: 794  | total loss: [1m[32m0.28098[0m[0m | time: 58.654s
[2K
| RMSProp | epoch: 012 | loss: 0.28098 - acc: 0.8905 -- iter: 1472/2147
[A[ATraining Step: 795  | total loss: [1m[32m0.28633[0m[0m | time: 59.894s
[2K
| RMSProp | epoch: 012 | loss: 0.28633 - acc: 0.8858 -- iter: 1504/2147
[A[ATraining Step: 796  | total loss: [1m[32m0.31476[0m[0m | time: 61.232s
[2K
| RMSProp | epoch: 012 | loss: 0.31476 - acc: 0.8753 -- iter: 1536/2147
[A[ATraining Step: 797  | total loss: [1m[32m0.31220[0m[0m | time: 62.779s
[2K
| RMSProp | epoch: 012 | loss: 0.31220 - acc: 0.8691 -- iter: 1568/2147
[A[ATraining Step: 798  | total loss: [1m[32m0.32210[0m[0m | time: 64.404s
[2K
| RMSProp | epoch: 012 | loss: 0.32210 - acc: 0.8665 -- iter: 1600/2147
[A[ATraining Step: 799  | total loss: [1m[32m0.32485[0m[0m | time: 65.727s
[2K
| RMSProp | epoch: 012 | loss: 0.32485 - acc: 0.8611 -- iter: 1632/2147
[A[ATraining Step: 800  | total loss: [1m[32m0.30477[0m[0m | time: 71.591s
[2K
| RMSProp | epoch: 012 | loss: 0.30477 - acc: 0.8719 | val_loss: 0.40590 - val_acc: 0.8244 -- iter: 1664/2147
--
Training Step: 801  | total loss: [1m[32m0.28907[0m[0m | time: 73.310s
[2K
| RMSProp | epoch: 012 | loss: 0.28907 - acc: 0.8816 -- iter: 1696/2147
[A[ATraining Step: 802  | total loss: [1m[32m0.28535[0m[0m | time: 74.806s
[2K
| RMSProp | epoch: 012 | loss: 0.28535 - acc: 0.8840 -- iter: 1728/2147
[A[ATraining Step: 803  | total loss: [1m[32m0.28265[0m[0m | time: 75.899s
[2K
| RMSProp | epoch: 012 | loss: 0.28265 - acc: 0.8831 -- iter: 1760/2147
[A[ATraining Step: 804  | total loss: [1m[32m0.30340[0m[0m | time: 77.091s
[2K
| RMSProp | epoch: 012 | loss: 0.30340 - acc: 0.8698 -- iter: 1792/2147
[A[ATraining Step: 805  | total loss: [1m[32m0.32735[0m[0m | time: 78.408s
[2K
| RMSProp | epoch: 012 | loss: 0.32735 - acc: 0.8547 -- iter: 1824/2147
[A[ATraining Step: 806  | total loss: [1m[32m0.30786[0m[0m | time: 79.821s
[2K
| RMSProp | epoch: 012 | loss: 0.30786 - acc: 0.8661 -- iter: 1856/2147
[A[ATraining Step: 807  | total loss: [1m[32m0.29824[0m[0m | time: 81.373s
[2K
| RMSProp | epoch: 012 | loss: 0.29824 - acc: 0.8701 -- iter: 1888/2147
[A[ATraining Step: 808  | total loss: [1m[32m0.29737[0m[0m | time: 82.647s
[2K
| RMSProp | epoch: 012 | loss: 0.29737 - acc: 0.8675 -- iter: 1920/2147
[A[ATraining Step: 809  | total loss: [1m[32m0.28360[0m[0m | time: 83.981s
[2K
| RMSProp | epoch: 012 | loss: 0.28360 - acc: 0.8776 -- iter: 1952/2147
[A[ATraining Step: 810  | total loss: [1m[32m0.28040[0m[0m | time: 85.207s
[2K
| RMSProp | epoch: 012 | loss: 0.28040 - acc: 0.8805 -- iter: 1984/2147
[A[ATraining Step: 811  | total loss: [1m[32m0.28059[0m[0m | time: 86.497s
[2K
| RMSProp | epoch: 012 | loss: 0.28059 - acc: 0.8737 -- iter: 2016/2147
[A[ATraining Step: 812  | total loss: [1m[32m0.27008[0m[0m | time: 87.797s
[2K
| RMSProp | epoch: 012 | loss: 0.27008 - acc: 0.8801 -- iter: 2048/2147
[A[ATraining Step: 813  | total loss: [1m[32m0.26704[0m[0m | time: 89.421s
[2K
| RMSProp | epoch: 012 | loss: 0.26704 - acc: 0.8827 -- iter: 2080/2147
[A[ATraining Step: 814  | total loss: [1m[32m0.27473[0m[0m | time: 90.916s
[2K
| RMSProp | epoch: 012 | loss: 0.27473 - acc: 0.8819 -- iter: 2112/2147
[A[ATraining Step: 815  | total loss: [1m[32m0.26503[0m[0m | time: 92.008s
[2K
| RMSProp | epoch: 012 | loss: 0.26503 - acc: 0.8875 -- iter: 2144/2147
[A[ATraining Step: 816  | total loss: [1m[32m0.24931[0m[0m | time: 98.368s
[2K
| RMSProp | epoch: 012 | loss: 0.24931 - acc: 0.8987 | val_loss: 0.32101 - val_acc: 0.8720 -- iter: 2147/2147
--
Training Step: 817  | total loss: [1m[32m0.26079[0m[0m | time: 1.286s
[2K
| RMSProp | epoch: 013 | loss: 0.26079 - acc: 0.8964 -- iter: 0032/2147
[A[ATraining Step: 818  | total loss: [1m[32m0.24663[0m[0m | time: 2.462s
[2K
| RMSProp | epoch: 013 | loss: 0.24663 - acc: 0.9036 -- iter: 0064/2147
[A[ATraining Step: 819  | total loss: [1m[32m0.27558[0m[0m | time: 3.767s
[2K
| RMSProp | epoch: 013 | loss: 0.27558 - acc: 0.8882 -- iter: 0096/2147
[A[ATraining Step: 820  | total loss: [1m[32m0.27284[0m[0m | time: 5.144s
[2K
| RMSProp | epoch: 013 | loss: 0.27284 - acc: 0.8932 -- iter: 0128/2147
[A[ATraining Step: 821  | total loss: [1m[32m0.28636[0m[0m | time: 6.842s
[2K
| RMSProp | epoch: 013 | loss: 0.28636 - acc: 0.8882 -- iter: 0160/2147
[A[ATraining Step: 822  | total loss: [1m[32m0.27721[0m[0m | time: 8.241s
[2K
| RMSProp | epoch: 013 | loss: 0.27721 - acc: 0.8931 -- iter: 0192/2147
[A[ATraining Step: 823  | total loss: [1m[32m0.27672[0m[0m | time: 9.359s
[2K
| RMSProp | epoch: 013 | loss: 0.27672 - acc: 0.8913 -- iter: 0224/2147
[A[ATraining Step: 824  | total loss: [1m[32m0.26740[0m[0m | time: 10.516s
[2K
| RMSProp | epoch: 013 | loss: 0.26740 - acc: 0.8991 -- iter: 0256/2147
[A[ATraining Step: 825  | total loss: [1m[32m0.25125[0m[0m | time: 11.885s
[2K
| RMSProp | epoch: 013 | loss: 0.25125 - acc: 0.9060 -- iter: 0288/2147
[A[ATraining Step: 826  | total loss: [1m[32m0.23827[0m[0m | time: 13.309s
[2K
| RMSProp | epoch: 013 | loss: 0.23827 - acc: 0.9123 -- iter: 0320/2147
[A[ATraining Step: 827  | total loss: [1m[32m0.23407[0m[0m | time: 13.539s
[2K
| RMSProp | epoch: 013 | loss: 0.23407 - acc: 0.9148 -- iter: 0352/2147
[A[ATraining Step: 828  | total loss: [1m[32m0.21469[0m[0m | time: 13.779s
[2K
| RMSProp | epoch: 013 | loss: 0.21469 - acc: 0.9233 -- iter: 0384/2147
[A[ATraining Step: 829  | total loss: [1m[32m0.19386[0m[0m | time: 15.304s
[2K
| RMSProp | epoch: 013 | loss: 0.19386 - acc: 0.9310 -- iter: 0416/2147
[A[ATraining Step: 830  | total loss: [1m[32m0.21212[0m[0m | time: 16.569s
[2K
| RMSProp | epoch: 013 | loss: 0.21212 - acc: 0.9192 -- iter: 0448/2147
[A[ATraining Step: 831  | total loss: [1m[32m0.22469[0m[0m | time: 17.802s
[2K
| RMSProp | epoch: 013 | loss: 0.22469 - acc: 0.9054 -- iter: 0480/2147
[A[ATraining Step: 832  | total loss: [1m[32m0.21706[0m[0m | time: 18.904s
[2K
| RMSProp | epoch: 013 | loss: 0.21706 - acc: 0.9086 -- iter: 0512/2147
[A[ATraining Step: 833  | total loss: [1m[32m0.21249[0m[0m | time: 20.209s
[2K
| RMSProp | epoch: 013 | loss: 0.21249 - acc: 0.9115 -- iter: 0544/2147
[A[ATraining Step: 834  | total loss: [1m[32m0.20740[0m[0m | time: 21.516s
[2K
| RMSProp | epoch: 013 | loss: 0.20740 - acc: 0.9110 -- iter: 0576/2147
[A[ATraining Step: 835  | total loss: [1m[32m0.22854[0m[0m | time: 23.165s
[2K
| RMSProp | epoch: 013 | loss: 0.22854 - acc: 0.9011 -- iter: 0608/2147
[A[ATraining Step: 836  | total loss: [1m[32m0.22017[0m[0m | time: 24.726s
[2K
| RMSProp | epoch: 013 | loss: 0.22017 - acc: 0.9079 -- iter: 0640/2147
[A[ATraining Step: 837  | total loss: [1m[32m0.22603[0m[0m | time: 25.790s
[2K
| RMSProp | epoch: 013 | loss: 0.22603 - acc: 0.9015 -- iter: 0672/2147
[A[ATraining Step: 838  | total loss: [1m[32m0.22330[0m[0m | time: 26.978s
[2K
| RMSProp | epoch: 013 | loss: 0.22330 - acc: 0.8988 -- iter: 0704/2147
[A[ATraining Step: 839  | total loss: [1m[32m0.24777[0m[0m | time: 28.334s
[2K
| RMSProp | epoch: 013 | loss: 0.24777 - acc: 0.8871 -- iter: 0736/2147
[A[ATraining Step: 840  | total loss: [1m[32m0.26449[0m[0m | time: 29.755s
[2K
| RMSProp | epoch: 013 | loss: 0.26449 - acc: 0.8796 -- iter: 0768/2147
[A[ATraining Step: 841  | total loss: [1m[32m0.25397[0m[0m | time: 31.238s
[2K
| RMSProp | epoch: 013 | loss: 0.25397 - acc: 0.8885 -- iter: 0800/2147
[A[ATraining Step: 842  | total loss: [1m[32m0.25901[0m[0m | time: 32.606s
[2K
| RMSProp | epoch: 013 | loss: 0.25901 - acc: 0.8840 -- iter: 0832/2147
[A[ATraining Step: 843  | total loss: [1m[32m0.26457[0m[0m | time: 33.957s
[2K
| RMSProp | epoch: 013 | loss: 0.26457 - acc: 0.8800 -- iter: 0864/2147
[A[ATraining Step: 844  | total loss: [1m[32m0.27077[0m[0m | time: 35.059s
[2K
| RMSProp | epoch: 013 | loss: 0.27077 - acc: 0.8795 -- iter: 0896/2147
[A[ATraining Step: 845  | total loss: [1m[32m0.25751[0m[0m | time: 36.349s
[2K
| RMSProp | epoch: 013 | loss: 0.25751 - acc: 0.8884 -- iter: 0928/2147
[A[ATraining Step: 846  | total loss: [1m[32m0.24010[0m[0m | time: 37.722s
[2K
| RMSProp | epoch: 013 | loss: 0.24010 - acc: 0.8996 -- iter: 0960/2147
[A[ATraining Step: 847  | total loss: [1m[32m0.22697[0m[0m | time: 39.293s
[2K
| RMSProp | epoch: 013 | loss: 0.22697 - acc: 0.9065 -- iter: 0992/2147
[A[ATraining Step: 848  | total loss: [1m[32m0.22113[0m[0m | time: 40.752s
[2K
| RMSProp | epoch: 013 | loss: 0.22113 - acc: 0.9096 -- iter: 1024/2147
[A[ATraining Step: 849  | total loss: [1m[32m0.21368[0m[0m | time: 41.967s
[2K
| RMSProp | epoch: 013 | loss: 0.21368 - acc: 0.9124 -- iter: 1056/2147
[A[ATraining Step: 850  | total loss: [1m[32m0.22190[0m[0m | time: 43.148s
[2K
| RMSProp | epoch: 013 | loss: 0.22190 - acc: 0.9087 -- iter: 1088/2147
[A[ATraining Step: 851  | total loss: [1m[32m0.26866[0m[0m | time: 44.479s
[2K
| RMSProp | epoch: 013 | loss: 0.26866 - acc: 0.8897 -- iter: 1120/2147
[A[ATraining Step: 852  | total loss: [1m[32m0.26007[0m[0m | time: 46.030s
[2K
| RMSProp | epoch: 013 | loss: 0.26007 - acc: 0.8913 -- iter: 1152/2147
[A[ATraining Step: 853  | total loss: [1m[32m0.26878[0m[0m | time: 47.492s
[2K
| RMSProp | epoch: 013 | loss: 0.26878 - acc: 0.8866 -- iter: 1184/2147
[A[ATraining Step: 854  | total loss: [1m[32m0.26654[0m[0m | time: 48.924s
[2K
| RMSProp | epoch: 013 | loss: 0.26654 - acc: 0.8885 -- iter: 1216/2147
[A[ATraining Step: 855  | total loss: [1m[32m0.27902[0m[0m | time: 50.166s
[2K
| RMSProp | epoch: 013 | loss: 0.27902 - acc: 0.8903 -- iter: 1248/2147
[A[ATraining Step: 856  | total loss: [1m[32m0.33096[0m[0m | time: 51.290s
[2K
| RMSProp | epoch: 013 | loss: 0.33096 - acc: 0.8700 -- iter: 1280/2147
[A[ATraining Step: 857  | total loss: [1m[32m0.30847[0m[0m | time: 52.483s
[2K
| RMSProp | epoch: 013 | loss: 0.30847 - acc: 0.8830 -- iter: 1312/2147
[A[ATraining Step: 858  | total loss: [1m[32m0.29312[0m[0m | time: 53.759s
[2K
| RMSProp | epoch: 013 | loss: 0.29312 - acc: 0.8885 -- iter: 1344/2147
[A[ATraining Step: 859  | total loss: [1m[32m0.30710[0m[0m | time: 55.340s
[2K
| RMSProp | epoch: 013 | loss: 0.30710 - acc: 0.8809 -- iter: 1376/2147
[A[ATraining Step: 860  | total loss: [1m[32m0.29824[0m[0m | time: 56.985s
[2K
| RMSProp | epoch: 013 | loss: 0.29824 - acc: 0.8865 -- iter: 1408/2147
[A[ATraining Step: 861  | total loss: [1m[32m0.28745[0m[0m | time: 58.201s
[2K
| RMSProp | epoch: 013 | loss: 0.28745 - acc: 0.8885 -- iter: 1440/2147
[A[ATraining Step: 862  | total loss: [1m[32m0.27041[0m[0m | time: 59.329s
[2K
| RMSProp | epoch: 013 | loss: 0.27041 - acc: 0.8997 -- iter: 1472/2147
[A[ATraining Step: 863  | total loss: [1m[32m0.25681[0m[0m | time: 60.629s
[2K
| RMSProp | epoch: 013 | loss: 0.25681 - acc: 0.9066 -- iter: 1504/2147
[A[ATraining Step: 864  | total loss: [1m[32m0.24014[0m[0m | time: 62.009s
[2K
| RMSProp | epoch: 013 | loss: 0.24014 - acc: 0.9128 -- iter: 1536/2147
[A[ATraining Step: 865  | total loss: [1m[32m0.28029[0m[0m | time: 63.466s
[2K
| RMSProp | epoch: 013 | loss: 0.28029 - acc: 0.8996 -- iter: 1568/2147
[A[ATraining Step: 866  | total loss: [1m[32m0.26675[0m[0m | time: 64.858s
[2K
| RMSProp | epoch: 013 | loss: 0.26675 - acc: 0.9034 -- iter: 1600/2147
[A[ATraining Step: 867  | total loss: [1m[32m0.25868[0m[0m | time: 66.194s
[2K
| RMSProp | epoch: 013 | loss: 0.25868 - acc: 0.9037 -- iter: 1632/2147
[A[ATraining Step: 868  | total loss: [1m[32m0.24801[0m[0m | time: 67.407s
[2K
| RMSProp | epoch: 013 | loss: 0.24801 - acc: 0.9102 -- iter: 1664/2147
[A[ATraining Step: 869  | total loss: [1m[32m0.23258[0m[0m | time: 68.558s
[2K
| RMSProp | epoch: 013 | loss: 0.23258 - acc: 0.9161 -- iter: 1696/2147
[A[ATraining Step: 870  | total loss: [1m[32m0.24260[0m[0m | time: 69.825s
[2K
| RMSProp | epoch: 013 | loss: 0.24260 - acc: 0.9120 -- iter: 1728/2147
[A[ATraining Step: 871  | total loss: [1m[32m0.29491[0m[0m | time: 71.185s
[2K
| RMSProp | epoch: 013 | loss: 0.29491 - acc: 0.8864 -- iter: 1760/2147
[A[ATraining Step: 872  | total loss: [1m[32m0.27844[0m[0m | time: 72.858s
[2K
| RMSProp | epoch: 013 | loss: 0.27844 - acc: 0.8915 -- iter: 1792/2147
[A[ATraining Step: 873  | total loss: [1m[32m0.27355[0m[0m | time: 74.185s
[2K
| RMSProp | epoch: 013 | loss: 0.27355 - acc: 0.8930 -- iter: 1824/2147
[A[ATraining Step: 874  | total loss: [1m[32m0.28592[0m[0m | time: 75.308s
[2K
| RMSProp | epoch: 013 | loss: 0.28592 - acc: 0.8880 -- iter: 1856/2147
[A[ATraining Step: 875  | total loss: [1m[32m0.27182[0m[0m | time: 76.479s
[2K
| RMSProp | epoch: 013 | loss: 0.27182 - acc: 0.8961 -- iter: 1888/2147
[A[ATraining Step: 876  | total loss: [1m[32m0.25449[0m[0m | time: 77.721s
[2K
| RMSProp | epoch: 013 | loss: 0.25449 - acc: 0.9034 -- iter: 1920/2147
[A[ATraining Step: 877  | total loss: [1m[32m0.23710[0m[0m | time: 79.257s
[2K
| RMSProp | epoch: 013 | loss: 0.23710 - acc: 0.9130 -- iter: 1952/2147
[A[ATraining Step: 878  | total loss: [1m[32m0.24092[0m[0m | time: 80.599s
[2K
| RMSProp | epoch: 013 | loss: 0.24092 - acc: 0.9124 -- iter: 1984/2147
[A[ATraining Step: 879  | total loss: [1m[32m0.23383[0m[0m | time: 81.981s
[2K
| RMSProp | epoch: 013 | loss: 0.23383 - acc: 0.9149 -- iter: 2016/2147
[A[ATraining Step: 880  | total loss: [1m[32m0.22993[0m[0m | time: 83.239s
[2K
| RMSProp | epoch: 013 | loss: 0.22993 - acc: 0.9140 -- iter: 2048/2147
[A[ATraining Step: 881  | total loss: [1m[32m0.24597[0m[0m | time: 84.384s
[2K
| RMSProp | epoch: 013 | loss: 0.24597 - acc: 0.9101 -- iter: 2080/2147
[A[ATraining Step: 882  | total loss: [1m[32m0.23353[0m[0m | time: 85.707s
[2K
| RMSProp | epoch: 013 | loss: 0.23353 - acc: 0.9160 -- iter: 2112/2147
[A[ATraining Step: 883  | total loss: [1m[32m0.22544[0m[0m | time: 87.039s
[2K
| RMSProp | epoch: 013 | loss: 0.22544 - acc: 0.9181 -- iter: 2144/2147
[A[ATraining Step: 884  | total loss: [1m[32m0.22122[0m[0m | time: 93.142s
[2K
| RMSProp | epoch: 013 | loss: 0.22122 - acc: 0.9232 | val_loss: 0.43758 - val_acc: 0.8229 -- iter: 2147/2147
--
Training Step: 885  | total loss: [1m[32m0.24736[0m[0m | time: 1.470s
[2K
| RMSProp | epoch: 014 | loss: 0.24736 - acc: 0.9090 -- iter: 0032/2147
[A[ATraining Step: 886  | total loss: [1m[32m0.24637[0m[0m | time: 2.986s
[2K
| RMSProp | epoch: 014 | loss: 0.24637 - acc: 0.9056 -- iter: 0064/2147
[A[ATraining Step: 887  | total loss: [1m[32m0.25181[0m[0m | time: 4.391s
[2K
| RMSProp | epoch: 014 | loss: 0.25181 - acc: 0.9057 -- iter: 0096/2147
[A[ATraining Step: 888  | total loss: [1m[32m0.25944[0m[0m | time: 5.724s
[2K
| RMSProp | epoch: 014 | loss: 0.25944 - acc: 0.8995 -- iter: 0128/2147
[A[ATraining Step: 889  | total loss: [1m[32m0.24509[0m[0m | time: 6.950s
[2K
| RMSProp | epoch: 014 | loss: 0.24509 - acc: 0.9095 -- iter: 0160/2147
[A[ATraining Step: 890  | total loss: [1m[32m0.23667[0m[0m | time: 8.078s
[2K
| RMSProp | epoch: 014 | loss: 0.23667 - acc: 0.9123 -- iter: 0192/2147
[A[ATraining Step: 891  | total loss: [1m[32m0.24312[0m[0m | time: 9.349s
[2K
| RMSProp | epoch: 014 | loss: 0.24312 - acc: 0.9086 -- iter: 0224/2147
[A[ATraining Step: 892  | total loss: [1m[32m0.23276[0m[0m | time: 10.827s
[2K
| RMSProp | epoch: 014 | loss: 0.23276 - acc: 0.9115 -- iter: 0256/2147
[A[ATraining Step: 893  | total loss: [1m[32m0.22352[0m[0m | time: 12.305s
[2K
| RMSProp | epoch: 014 | loss: 0.22352 - acc: 0.9172 -- iter: 0288/2147
[A[ATraining Step: 894  | total loss: [1m[32m0.22046[0m[0m | time: 13.826s
[2K
| RMSProp | epoch: 014 | loss: 0.22046 - acc: 0.9161 -- iter: 0320/2147
[A[ATraining Step: 895  | total loss: [1m[32m0.25378[0m[0m | time: 15.003s
[2K
| RMSProp | epoch: 014 | loss: 0.25378 - acc: 0.8995 -- iter: 0352/2147
[A[ATraining Step: 896  | total loss: [1m[32m0.25289[0m[0m | time: 15.148s
[2K
| RMSProp | epoch: 014 | loss: 0.25289 - acc: 0.9002 -- iter: 0384/2147
[A[ATraining Step: 897  | total loss: [1m[32m0.33492[0m[0m | time: 15.352s
[2K
| RMSProp | epoch: 014 | loss: 0.33492 - acc: 0.8768 -- iter: 0416/2147
[A[ATraining Step: 898  | total loss: [1m[32m0.31672[0m[0m | time: 16.554s
[2K
| RMSProp | epoch: 014 | loss: 0.31672 - acc: 0.8891 -- iter: 0448/2147
[A[ATraining Step: 899  | total loss: [1m[32m0.32538[0m[0m | time: 17.986s
[2K
| RMSProp | epoch: 014 | loss: 0.32538 - acc: 0.8846 -- iter: 0480/2147
[A[ATraining Step: 900  | total loss: [1m[32m0.31123[0m[0m | time: 19.384s
[2K
| RMSProp | epoch: 014 | loss: 0.31123 - acc: 0.8899 -- iter: 0512/2147
[A[ATraining Step: 901  | total loss: [1m[32m0.30049[0m[0m | time: 20.886s
[2K
| RMSProp | epoch: 014 | loss: 0.30049 - acc: 0.8947 -- iter: 0544/2147
[A[ATraining Step: 902  | total loss: [1m[32m0.29968[0m[0m | time: 22.231s
[2K
| RMSProp | epoch: 014 | loss: 0.29968 - acc: 0.8958 -- iter: 0576/2147
[A[ATraining Step: 903  | total loss: [1m[32m0.27913[0m[0m | time: 23.466s
[2K
| RMSProp | epoch: 014 | loss: 0.27913 - acc: 0.9031 -- iter: 0608/2147
[A[ATraining Step: 904  | total loss: [1m[32m0.26251[0m[0m | time: 24.567s
[2K
| RMSProp | epoch: 014 | loss: 0.26251 - acc: 0.9065 -- iter: 0640/2147
[A[ATraining Step: 905  | total loss: [1m[32m0.24456[0m[0m | time: 25.886s
[2K
| RMSProp | epoch: 014 | loss: 0.24456 - acc: 0.9159 -- iter: 0672/2147
[A[ATraining Step: 906  | total loss: [1m[32m0.25330[0m[0m | time: 27.244s
[2K
| RMSProp | epoch: 014 | loss: 0.25330 - acc: 0.9087 -- iter: 0704/2147
[A[ATraining Step: 907  | total loss: [1m[32m0.26388[0m[0m | time: 28.836s
[2K
| RMSProp | epoch: 014 | loss: 0.26388 - acc: 0.8991 -- iter: 0736/2147
[A[ATraining Step: 908  | total loss: [1m[32m0.25803[0m[0m | time: 30.389s
[2K
| RMSProp | epoch: 014 | loss: 0.25803 - acc: 0.8998 -- iter: 0768/2147
[A[ATraining Step: 909  | total loss: [1m[32m0.24336[0m[0m | time: 31.584s
[2K
| RMSProp | epoch: 014 | loss: 0.24336 - acc: 0.9067 -- iter: 0800/2147
[A[ATraining Step: 910  | total loss: [1m[32m0.23418[0m[0m | time: 32.719s
[2K
| RMSProp | epoch: 014 | loss: 0.23418 - acc: 0.9098 -- iter: 0832/2147
[A[ATraining Step: 911  | total loss: [1m[32m0.25398[0m[0m | time: 33.962s
[2K
| RMSProp | epoch: 014 | loss: 0.25398 - acc: 0.8969 -- iter: 0864/2147
[A[ATraining Step: 912  | total loss: [1m[32m0.24036[0m[0m | time: 35.321s
[2K
| RMSProp | epoch: 014 | loss: 0.24036 - acc: 0.9041 -- iter: 0896/2147
[A[ATraining Step: 913  | total loss: [1m[32m0.22209[0m[0m | time: 36.616s
[2K
| RMSProp | epoch: 014 | loss: 0.22209 - acc: 0.9137 -- iter: 0928/2147
[A[ATraining Step: 914  | total loss: [1m[32m0.21575[0m[0m | time: 37.963s
[2K
| RMSProp | epoch: 014 | loss: 0.21575 - acc: 0.9098 -- iter: 0960/2147
[A[ATraining Step: 915  | total loss: [1m[32m0.22239[0m[0m | time: 39.492s
[2K
| RMSProp | epoch: 014 | loss: 0.22239 - acc: 0.9126 -- iter: 0992/2147
[A[ATraining Step: 916  | total loss: [1m[32m0.22074[0m[0m | time: 40.689s
[2K
| RMSProp | epoch: 014 | loss: 0.22074 - acc: 0.9119 -- iter: 1024/2147
[A[ATraining Step: 917  | total loss: [1m[32m0.20596[0m[0m | time: 41.936s
[2K
| RMSProp | epoch: 014 | loss: 0.20596 - acc: 0.9208 -- iter: 1056/2147
[A[ATraining Step: 918  | total loss: [1m[32m0.19169[0m[0m | time: 43.228s
[2K
| RMSProp | epoch: 014 | loss: 0.19169 - acc: 0.9256 -- iter: 1088/2147
[A[ATraining Step: 919  | total loss: [1m[32m0.20626[0m[0m | time: 44.634s
[2K
| RMSProp | epoch: 014 | loss: 0.20626 - acc: 0.9174 -- iter: 1120/2147
[A[ATraining Step: 920  | total loss: [1m[32m0.19714[0m[0m | time: 45.916s
[2K
| RMSProp | epoch: 014 | loss: 0.19714 - acc: 0.9225 -- iter: 1152/2147
[A[ATraining Step: 921  | total loss: [1m[32m0.18863[0m[0m | time: 46.772s
[2K
| RMSProp | epoch: 014 | loss: 0.18863 - acc: 0.9271 -- iter: 1184/2147
[A[ATraining Step: 922  | total loss: [1m[32m0.18242[0m[0m | time: 47.722s
[2K
| RMSProp | epoch: 014 | loss: 0.18242 - acc: 0.9282 -- iter: 1216/2147
[A[ATraining Step: 923  | total loss: [1m[32m0.18381[0m[0m | time: 48.652s
[2K
| RMSProp | epoch: 014 | loss: 0.18381 - acc: 0.9260 -- iter: 1248/2147
[A[ATraining Step: 924  | total loss: [1m[32m0.17659[0m[0m | time: 49.662s
[2K
| RMSProp | epoch: 014 | loss: 0.17659 - acc: 0.9303 -- iter: 1280/2147
[A[ATraining Step: 925  | total loss: [1m[32m0.17562[0m[0m | time: 50.681s
[2K
| RMSProp | epoch: 014 | loss: 0.17562 - acc: 0.9310 -- iter: 1312/2147
[A[ATraining Step: 926  | total loss: [1m[32m0.17405[0m[0m | time: 51.746s
[2K
| RMSProp | epoch: 014 | loss: 0.17405 - acc: 0.9285 -- iter: 1344/2147
[A[ATraining Step: 927  | total loss: [1m[32m0.16194[0m[0m | time: 52.618s
[2K
| RMSProp | epoch: 014 | loss: 0.16194 - acc: 0.9357 -- iter: 1376/2147
[A[ATraining Step: 928  | total loss: [1m[32m0.16257[0m[0m | time: 53.698s
[2K
| RMSProp | epoch: 014 | loss: 0.16257 - acc: 0.9358 -- iter: 1408/2147
[A[ATraining Step: 929  | total loss: [1m[32m0.15992[0m[0m | time: 54.975s
[2K
| RMSProp | epoch: 014 | loss: 0.15992 - acc: 0.9360 -- iter: 1440/2147
[A[ATraining Step: 930  | total loss: [1m[32m0.16151[0m[0m | time: 56.178s
[2K
| RMSProp | epoch: 014 | loss: 0.16151 - acc: 0.9299 -- iter: 1472/2147
[A[ATraining Step: 931  | total loss: [1m[32m0.16846[0m[0m | time: 57.057s
[2K
| RMSProp | epoch: 014 | loss: 0.16846 - acc: 0.9244 -- iter: 1504/2147
[A[ATraining Step: 932  | total loss: [1m[32m0.16864[0m[0m | time: 57.943s
[2K
| RMSProp | epoch: 014 | loss: 0.16864 - acc: 0.9226 -- iter: 1536/2147
[A[ATraining Step: 933  | total loss: [1m[32m0.18749[0m[0m | time: 58.887s
[2K
| RMSProp | epoch: 014 | loss: 0.18749 - acc: 0.9147 -- iter: 1568/2147
[A[ATraining Step: 934  | total loss: [1m[32m0.22424[0m[0m | time: 59.877s
[2K
| RMSProp | epoch: 014 | loss: 0.22424 - acc: 0.9014 -- iter: 1600/2147
[A[ATraining Step: 935  | total loss: [1m[32m0.21791[0m[0m | time: 60.877s
[2K
| RMSProp | epoch: 014 | loss: 0.21791 - acc: 0.9050 -- iter: 1632/2147
[A[ATraining Step: 936  | total loss: [1m[32m0.21058[0m[0m | time: 62.012s
[2K
| RMSProp | epoch: 014 | loss: 0.21058 - acc: 0.9051 -- iter: 1664/2147
[A[ATraining Step: 937  | total loss: [1m[32m0.19369[0m[0m | time: 62.989s
[2K
| RMSProp | epoch: 014 | loss: 0.19369 - acc: 0.9146 -- iter: 1696/2147
[A[ATraining Step: 938  | total loss: [1m[32m0.18299[0m[0m | time: 63.972s
[2K
| RMSProp | epoch: 014 | loss: 0.18299 - acc: 0.9200 -- iter: 1728/2147
[A[ATraining Step: 939  | total loss: [1m[32m0.18511[0m[0m | time: 65.195s
[2K
| RMSProp | epoch: 014 | loss: 0.18511 - acc: 0.9218 -- iter: 1760/2147
[A[ATraining Step: 940  | total loss: [1m[32m0.17640[0m[0m | time: 66.560s
[2K
| RMSProp | epoch: 014 | loss: 0.17640 - acc: 0.9265 -- iter: 1792/2147
[A[ATraining Step: 941  | total loss: [1m[32m0.17157[0m[0m | time: 67.492s
[2K
| RMSProp | epoch: 014 | loss: 0.17157 - acc: 0.9307 -- iter: 1824/2147
[A[ATraining Step: 942  | total loss: [1m[32m0.17418[0m[0m | time: 68.410s
[2K
| RMSProp | epoch: 014 | loss: 0.17418 - acc: 0.9314 -- iter: 1856/2147
[A[ATraining Step: 943  | total loss: [1m[32m0.16171[0m[0m | time: 69.474s
[2K
| RMSProp | epoch: 014 | loss: 0.16171 - acc: 0.9382 -- iter: 1888/2147
[A[ATraining Step: 944  | total loss: [1m[32m0.15007[0m[0m | time: 70.800s
[2K
| RMSProp | epoch: 014 | loss: 0.15007 - acc: 0.9444 -- iter: 1920/2147
[A[ATraining Step: 945  | total loss: [1m[32m0.14044[0m[0m | time: 72.275s
[2K
| RMSProp | epoch: 014 | loss: 0.14044 - acc: 0.9500 -- iter: 1952/2147
[A[ATraining Step: 946  | total loss: [1m[32m0.13174[0m[0m | time: 73.802s
[2K
| RMSProp | epoch: 014 | loss: 0.13174 - acc: 0.9550 -- iter: 1984/2147
[A[ATraining Step: 947  | total loss: [1m[32m0.14142[0m[0m | time: 75.147s
[2K
| RMSProp | epoch: 014 | loss: 0.14142 - acc: 0.9563 -- iter: 2016/2147
[A[ATraining Step: 948  | total loss: [1m[32m0.13489[0m[0m | time: 76.289s
[2K
| RMSProp | epoch: 014 | loss: 0.13489 - acc: 0.9576 -- iter: 2048/2147
[A[ATraining Step: 949  | total loss: [1m[32m0.14335[0m[0m | time: 77.650s
[2K
| RMSProp | epoch: 014 | loss: 0.14335 - acc: 0.9525 -- iter: 2080/2147
[A[ATraining Step: 950  | total loss: [1m[32m0.14863[0m[0m | time: 78.887s
[2K
| RMSProp | epoch: 014 | loss: 0.14863 - acc: 0.9510 -- iter: 2112/2147
[A[ATraining Step: 951  | total loss: [1m[32m0.15118[0m[0m | time: 80.199s
[2K
| RMSProp | epoch: 014 | loss: 0.15118 - acc: 0.9527 -- iter: 2144/2147
[A[ATraining Step: 952  | total loss: [1m[32m0.14487[0m[0m | time: 86.198s
[2K
| RMSProp | epoch: 014 | loss: 0.14487 - acc: 0.9543 | val_loss: 0.45720 - val_acc: 0.8363 -- iter: 2147/2147
--
Training Step: 953  | total loss: [1m[32m0.15014[0m[0m | time: 1.397s
[2K
| RMSProp | epoch: 015 | loss: 0.15014 - acc: 0.9495 -- iter: 0032/2147
[A[ATraining Step: 954  | total loss: [1m[32m0.15160[0m[0m | time: 2.976s
[2K
| RMSProp | epoch: 015 | loss: 0.15160 - acc: 0.9452 -- iter: 0064/2147
[A[ATraining Step: 955  | total loss: [1m[32m0.15472[0m[0m | time: 4.180s
[2K
| RMSProp | epoch: 015 | loss: 0.15472 - acc: 0.9413 -- iter: 0096/2147
[A[ATraining Step: 956  | total loss: [1m[32m0.19387[0m[0m | time: 5.412s
[2K
| RMSProp | epoch: 015 | loss: 0.19387 - acc: 0.9284 -- iter: 0128/2147
[A[ATraining Step: 957  | total loss: [1m[32m0.18158[0m[0m | time: 6.684s
[2K
| RMSProp | epoch: 015 | loss: 0.18158 - acc: 0.9356 -- iter: 0160/2147
[A[ATraining Step: 958  | total loss: [1m[32m0.16991[0m[0m | time: 7.915s
[2K
| RMSProp | epoch: 015 | loss: 0.16991 - acc: 0.9420 -- iter: 0192/2147
[A[ATraining Step: 959  | total loss: [1m[32m0.17494[0m[0m | time: 8.862s
[2K
| RMSProp | epoch: 015 | loss: 0.17494 - acc: 0.9384 -- iter: 0224/2147
[A[ATraining Step: 960  | total loss: [1m[32m0.16920[0m[0m | time: 9.966s
[2K
| RMSProp | epoch: 015 | loss: 0.16920 - acc: 0.9415 -- iter: 0256/2147
[A[ATraining Step: 961  | total loss: [1m[32m0.16204[0m[0m | time: 10.919s
[2K
| RMSProp | epoch: 015 | loss: 0.16204 - acc: 0.9473 -- iter: 0288/2147
[A[ATraining Step: 962  | total loss: [1m[32m0.15280[0m[0m | time: 11.980s
[2K
| RMSProp | epoch: 015 | loss: 0.15280 - acc: 0.9526 -- iter: 0320/2147
[A[ATraining Step: 963  | total loss: [1m[32m0.15527[0m[0m | time: 13.090s
[2K
| RMSProp | epoch: 015 | loss: 0.15527 - acc: 0.9480 -- iter: 0352/2147
[A[ATraining Step: 964  | total loss: [1m[32m0.14894[0m[0m | time: 14.328s
[2K
| RMSProp | epoch: 015 | loss: 0.14894 - acc: 0.9500 -- iter: 0384/2147
[A[ATraining Step: 965  | total loss: [1m[32m0.14062[0m[0m | time: 14.433s
[2K
| RMSProp | epoch: 015 | loss: 0.14062 - acc: 0.9519 -- iter: 0416/2147
[A[ATraining Step: 966  | total loss: [1m[32m0.13365[0m[0m | time: 14.553s
[2K
| RMSProp | epoch: 015 | loss: 0.13365 - acc: 0.9567 -- iter: 0448/2147
[A[ATraining Step: 967  | total loss: [1m[32m0.15749[0m[0m | time: 15.421s
[2K
| RMSProp | epoch: 015 | loss: 0.15749 - acc: 0.9277 -- iter: 0480/2147
[A[ATraining Step: 968  | total loss: [1m[32m0.17530[0m[0m | time: 16.367s
[2K
| RMSProp | epoch: 015 | loss: 0.17530 - acc: 0.9256 -- iter: 0512/2147
[A[ATraining Step: 969  | total loss: [1m[32m0.18639[0m[0m | time: 17.316s
[2K
| RMSProp | epoch: 015 | loss: 0.18639 - acc: 0.9174 -- iter: 0544/2147
[A[ATraining Step: 970  | total loss: [1m[32m0.19099[0m[0m | time: 18.378s
[2K
| RMSProp | epoch: 015 | loss: 0.19099 - acc: 0.9163 -- iter: 0576/2147
[A[ATraining Step: 971  | total loss: [1m[32m0.17847[0m[0m | time: 19.439s
[2K
| RMSProp | epoch: 015 | loss: 0.17847 - acc: 0.9246 -- iter: 0608/2147
[A[ATraining Step: 972  | total loss: [1m[32m0.19001[0m[0m | time: 20.307s
[2K
| RMSProp | epoch: 015 | loss: 0.19001 - acc: 0.9197 -- iter: 0640/2147
[A[ATraining Step: 973  | total loss: [1m[32m0.17763[0m[0m | time: 21.410s
[2K
| RMSProp | epoch: 015 | loss: 0.17763 - acc: 0.9246 -- iter: 0672/2147
[A[ATraining Step: 974  | total loss: [1m[32m0.16893[0m[0m | time: 22.487s
[2K
| RMSProp | epoch: 015 | loss: 0.16893 - acc: 0.9259 -- iter: 0704/2147
[A[ATraining Step: 975  | total loss: [1m[32m0.16380[0m[0m | time: 23.845s
[2K
| RMSProp | epoch: 015 | loss: 0.16380 - acc: 0.9302 -- iter: 0736/2147
[A[ATraining Step: 976  | total loss: [1m[32m0.15362[0m[0m | time: 24.759s
[2K
| RMSProp | epoch: 015 | loss: 0.15362 - acc: 0.9340 -- iter: 0768/2147
[A[ATraining Step: 977  | total loss: [1m[32m0.15026[0m[0m | time: 25.766s
[2K
| RMSProp | epoch: 015 | loss: 0.15026 - acc: 0.9344 -- iter: 0800/2147
[A[ATraining Step: 978  | total loss: [1m[32m0.16053[0m[0m | time: 26.786s
[2K
| RMSProp | epoch: 015 | loss: 0.16053 - acc: 0.9347 -- iter: 0832/2147
[A[ATraining Step: 979  | total loss: [1m[32m0.15600[0m[0m | time: 27.733s
[2K
| RMSProp | epoch: 015 | loss: 0.15600 - acc: 0.9381 -- iter: 0864/2147
[A[ATraining Step: 980  | total loss: [1m[32m0.14704[0m[0m | time: 28.862s
[2K
| RMSProp | epoch: 015 | loss: 0.14704 - acc: 0.9412 -- iter: 0896/2147
[A[ATraining Step: 981  | total loss: [1m[32m0.13953[0m[0m | time: 29.961s
[2K
| RMSProp | epoch: 015 | loss: 0.13953 - acc: 0.9470 -- iter: 0928/2147
[A[ATraining Step: 982  | total loss: [1m[32m0.14152[0m[0m | time: 30.780s
[2K
| RMSProp | epoch: 015 | loss: 0.14152 - acc: 0.9461 -- iter: 0960/2147
[A[ATraining Step: 983  | total loss: [1m[32m0.14536[0m[0m | time: 31.907s
[2K
| RMSProp | epoch: 015 | loss: 0.14536 - acc: 0.9452 -- iter: 0992/2147
[A[ATraining Step: 984  | total loss: [1m[32m0.17044[0m[0m | time: 33.086s
[2K
| RMSProp | epoch: 015 | loss: 0.17044 - acc: 0.9320 -- iter: 1024/2147
[A[ATraining Step: 985  | total loss: [1m[32m0.16991[0m[0m | time: 34.353s
[2K
| RMSProp | epoch: 015 | loss: 0.16991 - acc: 0.9356 -- iter: 1056/2147
[A[ATraining Step: 986  | total loss: [1m[32m0.15604[0m[0m | time: 35.550s
[2K
| RMSProp | epoch: 015 | loss: 0.15604 - acc: 0.9421 -- iter: 1088/2147
[A[ATraining Step: 987  | total loss: [1m[32m0.14635[0m[0m | time: 36.765s
[2K
| RMSProp | epoch: 015 | loss: 0.14635 - acc: 0.9479 -- iter: 1120/2147
[A[ATraining Step: 988  | total loss: [1m[32m0.15643[0m[0m | time: 37.998s
[2K
| RMSProp | epoch: 015 | loss: 0.15643 - acc: 0.9468 -- iter: 1152/2147
[A[ATraining Step: 989  | total loss: [1m[32m0.15357[0m[0m | time: 39.132s
[2K
| RMSProp | epoch: 015 | loss: 0.15357 - acc: 0.9428 -- iter: 1184/2147
[A[ATraining Step: 990  | total loss: [1m[32m0.14109[0m[0m | time: 40.338s
[2K
| RMSProp | epoch: 015 | loss: 0.14109 - acc: 0.9485 -- iter: 1216/2147
[A[ATraining Step: 991  | total loss: [1m[32m0.12868[0m[0m | time: 41.644s
[2K
| RMSProp | epoch: 015 | loss: 0.12868 - acc: 0.9536 -- iter: 1248/2147
[A[ATraining Step: 992  | total loss: [1m[32m0.11872[0m[0m | time: 43.083s
[2K
| RMSProp | epoch: 015 | loss: 0.11872 - acc: 0.9583 -- iter: 1280/2147
[A[ATraining Step: 993  | total loss: [1m[32m0.12759[0m[0m | time: 44.366s
[2K
| RMSProp | epoch: 015 | loss: 0.12759 - acc: 0.9500 -- iter: 1312/2147
[A[ATraining Step: 994  | total loss: [1m[32m0.12713[0m[0m | time: 45.479s
[2K
| RMSProp | epoch: 015 | loss: 0.12713 - acc: 0.9518 -- iter: 1344/2147
[A[ATraining Step: 995  | total loss: [1m[32m0.11917[0m[0m | time: 46.848s
[2K
| RMSProp | epoch: 015 | loss: 0.11917 - acc: 0.9535 -- iter: 1376/2147
[A[ATraining Step: 996  | total loss: [1m[32m0.11795[0m[0m | time: 48.336s
[2K
| RMSProp | epoch: 015 | loss: 0.11795 - acc: 0.9550 -- iter: 1408/2147
[A[ATraining Step: 997  | total loss: [1m[32m0.18550[0m[0m | time: 49.816s
[2K
| RMSProp | epoch: 015 | loss: 0.18550 - acc: 0.9314 -- iter: 1440/2147
[A[ATraining Step: 998  | total loss: [1m[32m0.18716[0m[0m | time: 52.297s
[2K
| RMSProp | epoch: 015 | loss: 0.18716 - acc: 0.9258 -- iter: 1472/2147
[A[ATraining Step: 999  | total loss: [1m[32m0.18775[0m[0m | time: 53.511s
[2K
| RMSProp | epoch: 015 | loss: 0.18775 - acc: 0.9207 -- iter: 1504/2147
[A[ATraining Step: 1000  | total loss: [1m[32m0.17162[0m[0m | time: 59.514s
[2K
| RMSProp | epoch: 015 | loss: 0.17162 - acc: 0.9286 | val_loss: 0.36309 - val_acc: 0.8497 -- iter: 1536/2147
--
Training Step: 1001  | total loss: [1m[32m0.18107[0m[0m | time: 60.840s
[2K
| RMSProp | epoch: 015 | loss: 0.18107 - acc: 0.9264 -- iter: 1568/2147
[A[ATraining Step: 1002  | total loss: [1m[32m0.18472[0m[0m | time: 62.216s
[2K
| RMSProp | epoch: 015 | loss: 0.18472 - acc: 0.9244 -- iter: 1600/2147
[A[ATraining Step: 1003  | total loss: [1m[32m0.18916[0m[0m | time: 63.725s
[2K
| RMSProp | epoch: 015 | loss: 0.18916 - acc: 0.9226 -- iter: 1632/2147
[A[ATraining Step: 1004  | total loss: [1m[32m0.17450[0m[0m | time: 64.915s
[2K
| RMSProp | epoch: 015 | loss: 0.17450 - acc: 0.9303 -- iter: 1664/2147
[A[ATraining Step: 1005  | total loss: [1m[32m0.16134[0m[0m | time: 66.365s
[2K
| RMSProp | epoch: 015 | loss: 0.16134 - acc: 0.9373 -- iter: 1696/2147
[A[ATraining Step: 1006  | total loss: [1m[32m0.16150[0m[0m | time: 68.140s
[2K
| RMSProp | epoch: 015 | loss: 0.16150 - acc: 0.9404 -- iter: 1728/2147
[A[ATraining Step: 1007  | total loss: [1m[32m0.14821[0m[0m | time: 69.287s
[2K
| RMSProp | epoch: 015 | loss: 0.14821 - acc: 0.9464 -- iter: 1760/2147
[A[ATraining Step: 1008  | total loss: [1m[32m0.13933[0m[0m | time: 70.654s
[2K
| RMSProp | epoch: 015 | loss: 0.13933 - acc: 0.9517 -- iter: 1792/2147
[A[ATraining Step: 1009  | total loss: [1m[32m0.13799[0m[0m | time: 71.932s
[2K
| RMSProp | epoch: 015 | loss: 0.13799 - acc: 0.9534 -- iter: 1824/2147
[A[ATraining Step: 1010  | total loss: [1m[32m0.14635[0m[0m | time: 73.471s
[2K
| RMSProp | epoch: 015 | loss: 0.14635 - acc: 0.9456 -- iter: 1856/2147
[A[ATraining Step: 1011  | total loss: [1m[32m0.15547[0m[0m | time: 74.799s
[2K
| RMSProp | epoch: 015 | loss: 0.15547 - acc: 0.9417 -- iter: 1888/2147
[A[ATraining Step: 1012  | total loss: [1m[32m0.14436[0m[0m | time: 76.189s
[2K
| RMSProp | epoch: 015 | loss: 0.14436 - acc: 0.9475 -- iter: 1920/2147
[A[ATraining Step: 1013  | total loss: [1m[32m0.13341[0m[0m | time: 77.575s
[2K
| RMSProp | epoch: 015 | loss: 0.13341 - acc: 0.9527 -- iter: 1952/2147
[A[ATraining Step: 1014  | total loss: [1m[32m0.12125[0m[0m | time: 78.916s
[2K
| RMSProp | epoch: 015 | loss: 0.12125 - acc: 0.9575 -- iter: 1984/2147
[A[ATraining Step: 1015  | total loss: [1m[32m0.12124[0m[0m | time: 80.475s
[2K
| RMSProp | epoch: 015 | loss: 0.12124 - acc: 0.9586 -- iter: 2016/2147
[A[ATraining Step: 1016  | total loss: [1m[32m0.11624[0m[0m | time: 81.712s
[2K
| RMSProp | epoch: 015 | loss: 0.11624 - acc: 0.9596 -- iter: 2048/2147
[A[ATraining Step: 1017  | total loss: [1m[32m0.11734[0m[0m | time: 83.115s
[2K
| RMSProp | epoch: 015 | loss: 0.11734 - acc: 0.9605 -- iter: 2080/2147
[A[ATraining Step: 1018  | total loss: [1m[32m0.13283[0m[0m | time: 84.366s
[2K
| RMSProp | epoch: 015 | loss: 0.13283 - acc: 0.9551 -- iter: 2112/2147
[A[ATraining Step: 1019  | total loss: [1m[32m0.13332[0m[0m | time: 85.541s
[2K
| RMSProp | epoch: 015 | loss: 0.13332 - acc: 0.9533 -- iter: 2144/2147
[A[ATraining Step: 1020  | total loss: [1m[32m0.14406[0m[0m | time: 91.772s
[2K
| RMSProp | epoch: 015 | loss: 0.14406 - acc: 0.9486 | val_loss: 0.41965 - val_acc: 0.8586 -- iter: 2147/2147
--
Validation AUC:0.9537499441640238
Validation AUPRC:0.9592828364239978
Test AUC:0.9432778546249609
Test AUPRC:0.9467630110638737
BestTestF1Score	0.89	0.75	0.88	0.85	0.93	339	58	249	26	0.72
BestTestMCCScore	0.89	0.76	0.88	0.91	0.87	319	33	274	46	0.91
BestTestAccuracyScore	0.89	0.76	0.88	0.91	0.87	319	33	274	46	0.91
BestValidationF1Score	0.9	0.78	0.89	0.85	0.96	351	60	245	16	0.72
BestValidationMCC	0.9	0.78	0.89	0.9	0.9	330	36	269	37	0.91
BestValidationAccuracy	0.9	0.78	0.89	0.9	0.9	330	36	269	37	0.91
TestPredictions (Threshold:0.91)
CHEMBL2017151,TP,ACT,1.0	CHEMBL606673,TP,ACT,1.0	CHEMBL458409,TN,INACT,0.05999999865889549	CHEMBL95091,TN,INACT,0.09000000357627869	CHEMBL308243,FP,INACT,0.9700000286102295	CHEMBL58228,TN,INACT,0.28999999165534973	CHEMBL130005,TN,INACT,0.05999999865889549	CHEMBL299114,TP,ACT,1.0	CHEMBL3143394,FP,INACT,0.9800000190734863	CHEMBL368421,TP,ACT,1.0	CHEMBL6568,TN,INACT,0.15000000596046448	CHEMBL461709,TN,INACT,0.17000000178813934	CHEMBL2112320,TN,INACT,0.3400000035762787	CHEMBL123099,TN,INACT,0.8700000047683716	CHEMBL611428,TP,ACT,1.0	CHEMBL1784539,FP,INACT,1.0	CHEMBL62948,TN,INACT,0.009999999776482582	CHEMBL600610,TN,INACT,0.3100000023841858	CHEMBL25386,TP,ACT,0.9800000190734863	CHEMBL244449,FN,ACT,0.800000011920929	CHEMBL316615,TP,ACT,1.0	CHEMBL294849,TN,INACT,0.05999999865889549	CHEMBL2370622,TP,ACT,1.0	CHEMBL11154,TN,INACT,0.20999999344348907	CHEMBL542149,TP,ACT,0.9800000190734863	CHEMBL300877,TP,ACT,0.9900000095367432	CHEMBL2147915,TP,ACT,1.0	CHEMBL432956,TP,ACT,0.9900000095367432	CHEMBL2338754,TP,ACT,1.0	CHEMBL150430,FN,ACT,0.46000000834465027	CHEMBL3218121,TN,INACT,0.3499999940395355	CHEMBL169675,TN,INACT,0.33000001311302185	CHEMBL3589794,FN,ACT,0.20000000298023224	CHEMBL72057,TN,INACT,0.15000000596046448	CHEMBL461229,TP,ACT,0.9800000190734863	CHEMBL458947,TN,INACT,0.05999999865889549	CHEMBL2114058,TN,INACT,0.12999999523162842	CHEMBL2367758,TP,ACT,1.0	CHEMBL1672490,TP,ACT,1.0	CHEMBL334898,TP,ACT,1.0	CHEMBL38576,TP,ACT,0.9700000286102295	CHEMBL3634395,TP,ACT,1.0	CHEMBL506821,TP,ACT,1.0	CHEMBL336968,TN,INACT,0.2199999988079071	CHEMBL3735797,TN,INACT,0.6800000071525574	CHEMBL3350135,TP,ACT,1.0	CHEMBL57628,TP,ACT,1.0	CHEMBL2205419,TP,ACT,1.0	CHEMBL2387739,TP,ACT,0.9900000095367432	CHEMBL2204029,TP,ACT,0.9700000286102295	CHEMBL290095,TP,ACT,0.9399999976158142	CHEMBL280223,TN,INACT,0.6100000143051147	CHEMBL154255,TP,ACT,1.0	CHEMBL410531,TN,INACT,0.2800000011920929	CHEMBL3326659,FN,ACT,0.8100000023841858	CHEMBL1223055,TN,INACT,0.5699999928474426	CHEMBL98568,TP,ACT,1.0	CHEMBL56744,TP,ACT,0.9300000071525574	CHEMBL195411,TP,ACT,1.0	CHEMBL56653,TP,ACT,0.9800000190734863	CHEMBL3410297,TN,INACT,0.20000000298023224	CHEMBL305371,TN,INACT,0.029999999329447746	CHEMBL60837,TN,INACT,0.019999999552965164	CHEMBL324652,TN,INACT,0.7099999785423279	CHEMBL556802,TP,ACT,0.9800000190734863	CHEMBL3264744,TP,ACT,1.0	CHEMBL2364529,TP,ACT,0.9900000095367432	CHEMBL127619,TP,ACT,0.9300000071525574	CHEMBL612075,FN,ACT,0.8500000238418579	CHEMBL477154,TP,ACT,1.0	CHEMBL2147910,TP,ACT,1.0	CHEMBL384497,TP,ACT,1.0	CHEMBL408096,TP,ACT,1.0	CHEMBL2204731,TP,ACT,1.0	CHEMBL97223,TP,ACT,1.0	CHEMBL370735,TP,ACT,1.0	CHEMBL333321,FN,ACT,0.8999999761581421	CHEMBL444048,TP,ACT,1.0	CHEMBL104198,TN,INACT,0.05999999865889549	CHEMBL3409762,TP,ACT,0.9200000166893005	CHEMBL323723,TN,INACT,0.12999999523162842	CHEMBL1744389,TP,ACT,1.0	CHEMBL422567,TP,ACT,1.0	CHEMBL107780,TP,ACT,0.9300000071525574	CHEMBL307034,TN,INACT,0.6899999976158142	CHEMBL118553,TN,INACT,0.1599999964237213	CHEMBL358208,TP,ACT,1.0	CHEMBL98133,TP,ACT,1.0	CHEMBL2436822,TN,INACT,0.029999999329447746	CHEMBL234543,TN,INACT,0.5099999904632568	CHEMBL431185,TN,INACT,0.3199999928474426	CHEMBL322195,TP,ACT,1.0	CHEMBL195316,TP,ACT,0.9900000095367432	CHEMBL3323521,TP,ACT,0.9599999785423279	CHEMBL443068,TP,ACT,1.0	CHEMBL59314,TP,ACT,1.0	CHEMBL2370629,TP,ACT,1.0	CHEMBL22569,TP,ACT,1.0	CHEMBL283941,TN,INACT,0.4099999964237213	CHEMBL1096474,TP,ACT,1.0	CHEMBL2112573,TP,ACT,1.0	CHEMBL290429,TP,ACT,0.9300000071525574	CHEMBL291293,TN,INACT,0.029999999329447746	CHEMBL97111,TP,ACT,1.0	CHEMBL318723,TP,ACT,1.0	CHEMBL416019,TN,INACT,0.3400000035762787	CHEMBL75514,TN,INACT,0.2199999988079071	CHEMBL168372,TN,INACT,0.09000000357627869	CHEMBL220334,TN,INACT,0.23999999463558197	CHEMBL1254769,TP,ACT,1.0	CHEMBL328812,TN,INACT,0.6100000143051147	CHEMBL3338874,TP,ACT,0.9800000190734863	CHEMBL246585,TN,INACT,0.6399999856948853	CHEMBL366737,TN,INACT,0.41999998688697815	CHEMBL558539,FP,INACT,0.9800000190734863	CHEMBL452150,TN,INACT,0.05000000074505806	CHEMBL1162517,TP,ACT,0.9700000286102295	CHEMBL1161429,TP,ACT,1.0	CHEMBL1089543,FN,ACT,0.07000000029802322	CHEMBL447178,TN,INACT,0.8100000023841858	CHEMBL321644,TN,INACT,0.8999999761581421	CHEMBL126688,TP,ACT,0.9900000095367432	CHEMBL2112674,TN,INACT,0.7799999713897705	CHEMBL103404,TN,INACT,0.07000000029802322	CHEMBL75200,TN,INACT,0.6299999952316284	CHEMBL593861,TN,INACT,0.10999999940395355	CHEMBL3740042,TN,INACT,0.18000000715255737	CHEMBL412580,TP,ACT,1.0	CHEMBL291394,TN,INACT,0.009999999776482582	CHEMBL90305,TP,ACT,1.0	CHEMBL2147913,TP,ACT,1.0	CHEMBL321178,TN,INACT,0.23000000417232513	CHEMBL504916,TP,ACT,1.0	CHEMBL2112597,TN,INACT,0.029999999329447746	CHEMBL274989,TN,INACT,0.12999999523162842	CHEMBL3217264,TP,ACT,1.0	CHEMBL233552,TN,INACT,0.2199999988079071	CHEMBL3215947,TP,ACT,1.0	CHEMBL386722,FN,ACT,0.4699999988079071	CHEMBL1089873,TP,ACT,0.9300000071525574	CHEMBL611496,TN,INACT,0.10999999940395355	CHEMBL16373,TN,INACT,0.20000000298023224	CHEMBL3216837,TP,ACT,1.0	CHEMBL1161428,TP,ACT,1.0	CHEMBL54246,TN,INACT,0.10999999940395355	CHEMBL174958,TN,INACT,0.6200000047683716	CHEMBL48816,TP,ACT,1.0	CHEMBL239260,TP,ACT,1.0	CHEMBL135361,TN,INACT,0.05999999865889549	CHEMBL607047,TP,ACT,0.9700000286102295	CHEMBL2062852,FP,INACT,0.9900000095367432	CHEMBL1162074,FP,INACT,1.0	CHEMBL392888,TN,INACT,0.03999999910593033	CHEMBL227429,TN,INACT,0.03999999910593033	CHEMBL59931,TN,INACT,0.009999999776482582	CHEMBL3323512,FN,ACT,0.5799999833106995	CHEMBL1782798,TN,INACT,0.029999999329447746	CHEMBL312268,TN,INACT,0.03999999910593033	CHEMBL338134,TN,INACT,0.3700000047683716	CHEMBL331325,TP,ACT,0.9800000190734863	CHEMBL29541,TN,INACT,0.33000001311302185	CHEMBL317398,TN,INACT,0.09000000357627869	CHEMBL74010,TP,ACT,0.9399999976158142	CHEMBL288495,TP,ACT,0.9900000095367432	CHEMBL576340,FN,ACT,0.7300000190734863	CHEMBL124764,TN,INACT,0.14000000059604645	CHEMBL371565,TP,ACT,0.9900000095367432	CHEMBL2204027,TP,ACT,1.0	CHEMBL391718,TN,INACT,0.12999999523162842	CHEMBL316589,TN,INACT,0.10999999940395355	CHEMBL312150,FP,INACT,0.9200000166893005	CHEMBL633,TN,INACT,0.7400000095367432	CHEMBL3121474,TN,INACT,0.07000000029802322	CHEMBL1272191,TN,INACT,0.11999999731779099	CHEMBL115853,TN,INACT,0.17000000178813934	CHEMBL153538,TP,ACT,1.0	CHEMBL3326771,FN,ACT,0.5	CHEMBL45305,TN,INACT,0.3199999928474426	CHEMBL407303,TP,ACT,1.0	CHEMBL1237302,TN,INACT,0.6200000047683716	CHEMBL367024,TN,INACT,0.3799999952316284	CHEMBL421432,TP,ACT,1.0	CHEMBL1797688,TP,ACT,1.0	CHEMBL3092395,TP,ACT,1.0	CHEMBL114891,TN,INACT,0.029999999329447746	CHEMBL1271976,TN,INACT,0.07999999821186066	CHEMBL202861,TN,INACT,0.41999998688697815	CHEMBL300689,TP,ACT,0.9200000166893005	CHEMBL542544,TN,INACT,0.33000001311302185	CHEMBL275433,TN,INACT,0.1599999964237213	CHEMBL94856,TP,ACT,1.0	CHEMBL3665435,TN,INACT,0.14000000059604645	CHEMBL1834903,TP,ACT,1.0	CHEMBL408336,FP,INACT,0.9300000071525574	CHEMBL3099732,FP,INACT,0.949999988079071	CHEMBL51280,TN,INACT,0.7599999904632568	CHEMBL2436716,TN,INACT,0.11999999731779099	CHEMBL44490,TP,ACT,1.0	CHEMBL1917701,FN,ACT,0.03999999910593033	CHEMBL160396,TN,INACT,0.8500000238418579	CHEMBL2016674,TP,ACT,1.0	CHEMBL2062854,FP,INACT,0.9700000286102295	CHEMBL299189,TP,ACT,1.0	CHEMBL469856,TN,INACT,0.28999999165534973	CHEMBL75773,TN,INACT,0.6499999761581421	CHEMBL103419,TN,INACT,0.28999999165534973	CHEMBL118479,TP,ACT,1.0	CHEMBL305512,TN,INACT,0.14000000059604645	CHEMBL150743,TN,INACT,0.6000000238418579	CHEMBL110601,TN,INACT,0.6399999856948853	CHEMBL389949,TP,ACT,0.9900000095367432	CHEMBL392116,TN,INACT,0.25999999046325684	CHEMBL283535,TN,INACT,0.03999999910593033	CHEMBL537169,TP,ACT,0.9800000190734863	CHEMBL121935,FN,ACT,0.8600000143051147	CHEMBL107398,TP,ACT,0.9900000095367432	CHEMBL1790738,TN,INACT,0.03999999910593033	CHEMBL269776,TN,INACT,0.44999998807907104	CHEMBL122005,TN,INACT,0.7799999713897705	CHEMBL97363,FN,ACT,0.6299999952316284	CHEMBL291649,TP,ACT,0.9900000095367432	CHEMBL1672476,TP,ACT,1.0	CHEMBL106211,FN,ACT,0.27000001072883606	CHEMBL192443,TP,ACT,0.9900000095367432	CHEMBL97731,TP,ACT,1.0	CHEMBL3323517,TP,ACT,0.949999988079071	CHEMBL214122,TN,INACT,0.4300000071525574	CHEMBL110273,TP,ACT,0.9700000286102295	CHEMBL1237299,FP,INACT,0.9599999785423279	CHEMBL2112578,TP,ACT,1.0	CHEMBL67384,FN,ACT,0.5699999928474426	CHEMBL297756,TP,ACT,1.0	CHEMBL60294,TP,ACT,1.0	CHEMBL2115154,TP,ACT,0.9599999785423279	CHEMBL556957,TP,ACT,0.9900000095367432	CHEMBL573566,FN,ACT,0.10999999940395355	CHEMBL343969,TN,INACT,0.09000000357627869	CHEMBL603858,TN,INACT,0.8500000238418579	CHEMBL16565,TN,INACT,0.7099999785423279	CHEMBL241080,TN,INACT,0.6600000262260437	CHEMBL16231,TN,INACT,0.14000000059604645	CHEMBL178829,TP,ACT,1.0	CHEMBL1418,TP,ACT,1.0	CHEMBL576975,FN,ACT,0.5699999928474426	CHEMBL320064,FN,ACT,0.18000000715255737	CHEMBL512035,TN,INACT,0.14000000059604645	CHEMBL95596,TP,ACT,1.0	CHEMBL413644,FP,INACT,0.9900000095367432	CHEMBL3577345,TN,INACT,0.46000000834465027	CHEMBL105268,TN,INACT,0.019999999552965164	CHEMBL2113654,TP,ACT,1.0	CHEMBL436180,TN,INACT,0.11999999731779099	CHEMBL541349,FN,ACT,0.8500000238418579	CHEMBL74342,TN,INACT,0.20999999344348907	CHEMBL2017141,TP,ACT,0.9900000095367432	CHEMBL536937,TP,ACT,0.9200000166893005	CHEMBL3339380,TP,ACT,1.0	CHEMBL1258999,TN,INACT,0.029999999329447746	CHEMBL2181201,TP,ACT,0.9599999785423279	CHEMBL286680,TN,INACT,0.07000000029802322	CHEMBL543329,FN,ACT,0.8600000143051147	CHEMBL227378,TN,INACT,0.07000000029802322	CHEMBL1834900,TP,ACT,1.0	CHEMBL572396,FN,ACT,0.25999999046325684	CHEMBL1907786,TP,ACT,0.9900000095367432	CHEMBL288967,TN,INACT,0.3199999928474426	CHEMBL3335537,TN,INACT,0.3499999940395355	CHEMBL572868,TP,ACT,0.9700000286102295	CHEMBL298688,TP,ACT,1.0	CHEMBL3589708,FN,ACT,0.6600000262260437	CHEMBL40796,TN,INACT,0.12999999523162842	CHEMBL293033,TN,INACT,0.009999999776482582	CHEMBL3236672,TP,ACT,0.9599999785423279	CHEMBL216899,TP,ACT,1.0	CHEMBL299772,TP,ACT,1.0	CHEMBL3577342,TN,INACT,0.029999999329447746	CHEMBL434867,TP,ACT,1.0	CHEMBL297292,TP,ACT,1.0	CHEMBL381108,TN,INACT,0.46000000834465027	CHEMBL1270474,TP,ACT,1.0	CHEMBL1270185,TP,ACT,1.0	CHEMBL72786,TP,ACT,0.9900000095367432	CHEMBL84331,TN,INACT,0.03999999910593033	CHEMBL314209,TP,ACT,0.9599999785423279	CHEMBL291751,TP,ACT,1.0	CHEMBL2114295,TP,ACT,0.9900000095367432	CHEMBL2338735,TP,ACT,1.0	CHEMBL1791272,FP,INACT,0.9100000262260437	CHEMBL354363,TN,INACT,0.1599999964237213	CHEMBL175698,TN,INACT,0.7699999809265137	CHEMBL611144,TP,ACT,1.0	CHEMBL3589798,TP,ACT,0.9300000071525574	CHEMBL42411,FP,INACT,1.0	CHEMBL74300,TN,INACT,0.75	CHEMBL2112730,TP,ACT,1.0	CHEMBL610015,TP,ACT,1.0	CHEMBL2147909,TP,ACT,1.0	CHEMBL8287,TN,INACT,0.10999999940395355	CHEMBL2367645,TP,ACT,1.0	CHEMBL408360,TP,ACT,1.0	CHEMBL2205414,TP,ACT,1.0	CHEMBL32409,TN,INACT,0.03999999910593033	CHEMBL2436824,TN,INACT,0.1899999976158142	CHEMBL386043,TP,ACT,1.0	CHEMBL2113652,TP,ACT,1.0	CHEMBL1269226,TN,INACT,0.03999999910593033	CHEMBL506888,TN,INACT,0.3499999940395355	CHEMBL106602,TN,INACT,0.019999999552965164	CHEMBL301867,TP,ACT,0.9100000262260437	CHEMBL313379,TN,INACT,0.20000000298023224	CHEMBL2163917,FP,INACT,0.949999988079071	CHEMBL386170,TP,ACT,0.9800000190734863	CHEMBL430833,TP,ACT,1.0	CHEMBL310785,TP,ACT,1.0	CHEMBL237079,TN,INACT,0.07999999821186066	CHEMBL578850,FN,ACT,0.8299999833106995	CHEMBL296328,TP,ACT,1.0	CHEMBL1161416,TP,ACT,1.0	CHEMBL346165,TP,ACT,1.0	CHEMBL540896,TN,INACT,0.41999998688697815	CHEMBL1089942,TN,INACT,0.029999999329447746	CHEMBL611437,TP,ACT,1.0	CHEMBL3409755,TP,ACT,0.9900000095367432	CHEMBL439335,TN,INACT,0.23999999463558197	CHEMBL151243,FN,ACT,0.7400000095367432	CHEMBL317610,TP,ACT,1.0	CHEMBL438741,TP,ACT,1.0	CHEMBL169030,TP,ACT,1.0	CHEMBL349940,TP,ACT,0.9900000095367432	CHEMBL611165,TP,ACT,0.9900000095367432	CHEMBL317661,TP,ACT,1.0	CHEMBL272853,TN,INACT,0.019999999552965164	CHEMBL3403336,FP,INACT,0.9399999976158142	CHEMBL150052,TP,ACT,1.0	CHEMBL302038,TN,INACT,0.7699999809265137	CHEMBL3087713,TN,INACT,0.03999999910593033	CHEMBL118282,TP,ACT,0.9700000286102295	CHEMBL475534,TN,INACT,0.6100000143051147	CHEMBL421421,TP,ACT,0.9900000095367432	CHEMBL425064,TN,INACT,0.029999999329447746	CHEMBL2114292,TP,ACT,0.9700000286102295	CHEMBL608816,FP,INACT,0.9900000095367432	CHEMBL364845,TN,INACT,0.10000000149011612	CHEMBL3216131,TP,ACT,1.0	CHEMBL331764,TP,ACT,0.9700000286102295	CHEMBL80180,TN,INACT,0.05999999865889549	CHEMBL594802,TN,INACT,0.07000000029802322	CHEMBL392115,TN,INACT,0.6100000143051147	CHEMBL28443,FN,ACT,0.44999998807907104	CHEMBL405897,TN,INACT,0.17000000178813934	CHEMBL2367762,TP,ACT,0.9900000095367432	CHEMBL559010,FN,ACT,0.6800000071525574	CHEMBL3215715,TP,ACT,1.0	CHEMBL434674,TN,INACT,0.49000000953674316	CHEMBL39843,FP,INACT,0.949999988079071	CHEMBL539317,FN,ACT,0.4399999976158142	CHEMBL422258,TP,ACT,0.9900000095367432	CHEMBL3323522,FN,ACT,0.8700000047683716	CHEMBL296291,TN,INACT,0.07000000029802322	CHEMBL432974,TN,INACT,0.2800000011920929	CHEMBL537615,TP,ACT,0.9900000095367432	CHEMBL78601,TN,INACT,0.18000000715255737	CHEMBL414773,TP,ACT,1.0	CHEMBL46395,TN,INACT,0.25	CHEMBL97360,TP,ACT,1.0	CHEMBL386152,FP,INACT,0.9300000071525574	CHEMBL2312346,TN,INACT,0.5099999904632568	CHEMBL409026,FN,ACT,0.7699999809265137	CHEMBL1162507,TP,ACT,0.949999988079071	CHEMBL29471,TN,INACT,0.27000001072883606	CHEMBL3339378,TP,ACT,1.0	CHEMBL474708,TN,INACT,0.4000000059604645	CHEMBL79915,TN,INACT,0.009999999776482582	CHEMBL74170,TN,INACT,0.05000000074505806	CHEMBL99955,TP,ACT,1.0	CHEMBL3326665,TP,ACT,0.9900000095367432	CHEMBL44910,TP,ACT,1.0	CHEMBL296927,TN,INACT,0.03999999910593033	CHEMBL543236,TP,ACT,0.9800000190734863	CHEMBL1223274,TN,INACT,0.05000000074505806	CHEMBL430683,TN,INACT,0.019999999552965164	CHEMBL170399,TP,ACT,1.0	CHEMBL2368317,TP,ACT,1.0	CHEMBL3339372,TP,ACT,1.0	CHEMBL438223,TP,ACT,1.0	CHEMBL2093082,TN,INACT,0.05999999865889549	CHEMBL3038181,TP,ACT,0.9800000190734863	CHEMBL173749,TP,ACT,1.0	CHEMBL168632,TN,INACT,0.3100000023841858	CHEMBL8234,TP,ACT,0.9900000095367432	CHEMBL280698,TP,ACT,0.9900000095367432	CHEMBL330371,TP,ACT,1.0	CHEMBL267027,TP,ACT,1.0	CHEMBL2147926,TP,ACT,1.0	CHEMBL262787,TN,INACT,0.07999999821186066	CHEMBL193586,TP,ACT,1.0	CHEMBL3786545,TP,ACT,0.9599999785423279	CHEMBL3775378,TN,INACT,0.6100000143051147	CHEMBL127604,TN,INACT,0.5699999928474426	CHEMBL330586,TN,INACT,0.05000000074505806	CHEMBL241514,TN,INACT,0.07999999821186066	CHEMBL294226,TP,ACT,0.9900000095367432	CHEMBL48974,TP,ACT,1.0	CHEMBL142641,TN,INACT,0.07999999821186066	CHEMBL1091790,TN,INACT,0.5299999713897705	CHEMBL413855,FP,INACT,0.9700000286102295	CHEMBL319536,TP,ACT,1.0	CHEMBL595022,FP,INACT,0.9399999976158142	CHEMBL290855,TP,ACT,0.9700000286102295	CHEMBL611701,TP,ACT,1.0	CHEMBL1192069,TN,INACT,0.03999999910593033	CHEMBL275025,TP,ACT,0.9300000071525574	CHEMBL370966,TP,ACT,1.0	CHEMBL170335,FP,INACT,0.9700000286102295	CHEMBL105457,TN,INACT,0.09000000357627869	CHEMBL1161419,FP,INACT,0.9800000190734863	CHEMBL25373,TN,INACT,0.11999999731779099	CHEMBL388800,TP,ACT,0.9800000190734863	CHEMBL90667,TP,ACT,1.0	CHEMBL2443002,FP,INACT,0.9399999976158142	CHEMBL419306,TN,INACT,0.3700000047683716	CHEMBL76023,TP,ACT,1.0	CHEMBL137483,TN,INACT,0.029999999329447746	CHEMBL1162502,TP,ACT,1.0	CHEMBL109478,TN,INACT,0.019999999552965164	CHEMBL105665,TP,ACT,1.0	CHEMBL474091,TN,INACT,0.550000011920929	CHEMBL144894,TN,INACT,0.5600000023841858	CHEMBL1223834,TP,ACT,1.0	CHEMBL575160,TN,INACT,0.8500000238418579	CHEMBL2436713,TN,INACT,0.5600000023841858	CHEMBL387159,TP,ACT,1.0	CHEMBL610260,TP,ACT,1.0	CHEMBL316760,TP,ACT,1.0	CHEMBL60533,FN,ACT,0.3799999952316284	CHEMBL332405,TN,INACT,0.1899999976158142	CHEMBL76128,TN,INACT,0.4099999964237213	CHEMBL2369870,TP,ACT,1.0	CHEMBL273642,TN,INACT,0.47999998927116394	CHEMBL469855,FP,INACT,0.9200000166893005	CHEMBL607048,TP,ACT,1.0	CHEMBL16109,TN,INACT,0.10000000149011612	CHEMBL75358,TN,INACT,0.10000000149011612	CHEMBL2147919,TP,ACT,0.9800000190734863	CHEMBL439898,TP,ACT,0.9900000095367432	CHEMBL237478,TN,INACT,0.019999999552965164	CHEMBL481245,TN,INACT,0.2800000011920929	CHEMBL1929364,TP,ACT,1.0	CHEMBL228503,TP,ACT,0.9300000071525574	CHEMBL339278,FN,ACT,0.8899999856948853	CHEMBL1080485,FN,ACT,0.7400000095367432	CHEMBL101239,TN,INACT,0.5299999713897705	CHEMBL91231,TP,ACT,1.0	CHEMBL425735,TP,ACT,0.9900000095367432	CHEMBL2114223,FN,ACT,0.5799999833106995	CHEMBL3314885,TN,INACT,0.4000000059604645	CHEMBL63760,TN,INACT,0.12999999523162842	CHEMBL2113646,TP,ACT,1.0	CHEMBL553084,TP,ACT,0.9599999785423279	CHEMBL501939,TP,ACT,1.0	CHEMBL3264748,TP,ACT,1.0	CHEMBL110319,FN,ACT,0.6299999952316284	CHEMBL2237158,TN,INACT,0.46000000834465027	CHEMBL2371015,TP,ACT,1.0	CHEMBL244652,TP,ACT,0.9100000262260437	CHEMBL103497,TN,INACT,0.3499999940395355	CHEMBL125874,TN,INACT,0.7200000286102295	CHEMBL70586,TP,ACT,1.0	CHEMBL561262,TN,INACT,0.25	CHEMBL328236,TP,ACT,0.9900000095367432	CHEMBL195082,TP,ACT,1.0	CHEMBL2093084,TN,INACT,0.20000000298023224	CHEMBL263366,TP,ACT,0.9900000095367432	CHEMBL318636,TP,ACT,1.0	CHEMBL367962,TP,ACT,1.0	CHEMBL191915,TN,INACT,0.03999999910593033	CHEMBL216406,TN,INACT,0.019999999552965164	CHEMBL2203713,TN,INACT,0.7900000214576721	CHEMBL590953,FN,ACT,0.07999999821186066	CHEMBL2011441,TN,INACT,0.2800000011920929	CHEMBL1223054,TN,INACT,0.019999999552965164	CHEMBL3403731,TN,INACT,0.029999999329447746	CHEMBL2113697,TN,INACT,0.1899999976158142	CHEMBL510130,TN,INACT,0.6499999761581421	CHEMBL519367,TP,ACT,1.0	CHEMBL2387737,TP,ACT,1.0	CHEMBL239153,FP,INACT,0.9399999976158142	CHEMBL293633,TP,ACT,1.0	CHEMBL343158,TN,INACT,0.6899999976158142	CHEMBL2111766,TN,INACT,0.3400000035762787	CHEMBL607449,FN,ACT,0.1899999976158142	CHEMBL95589,TN,INACT,0.10000000149011612	CHEMBL3350137,TP,ACT,1.0	CHEMBL3109772,TN,INACT,0.10999999940395355	CHEMBL426537,TN,INACT,0.20000000298023224	CHEMBL3323508,TP,ACT,0.9599999785423279	CHEMBL1672480,TP,ACT,1.0	CHEMBL410115,TN,INACT,0.03999999910593033	CHEMBL2111857,TP,ACT,0.9900000095367432	CHEMBL611703,TP,ACT,1.0	CHEMBL238136,FP,INACT,0.949999988079071	CHEMBL404097,FP,INACT,1.0	CHEMBL610268,TP,ACT,1.0	CHEMBL80438,TN,INACT,0.05000000074505806	CHEMBL421349,TN,INACT,0.8600000143051147	CHEMBL51675,TN,INACT,0.800000011920929	CHEMBL1797687,TP,ACT,1.0	CHEMBL3114164,TN,INACT,0.05000000074505806	CHEMBL1478530,TN,INACT,0.8600000143051147	CHEMBL228409,FN,ACT,0.8799999952316284	CHEMBL2204026,TP,ACT,1.0	CHEMBL108393,FN,ACT,0.8100000023841858	CHEMBL2111681,TP,ACT,0.9900000095367432	CHEMBL573557,FN,ACT,0.6200000047683716	CHEMBL2391356,TN,INACT,0.029999999329447746	CHEMBL1094879,TP,ACT,0.9800000190734863	CHEMBL133815,TP,ACT,1.0	CHEMBL330674,TN,INACT,0.7699999809265137	CHEMBL117999,TN,INACT,0.05999999865889549	CHEMBL572633,TP,ACT,0.9700000286102295	CHEMBL66011,TN,INACT,0.15000000596046448	CHEMBL302454,FN,ACT,0.07000000029802322	CHEMBL473206,TP,ACT,1.0	CHEMBL97767,TP,ACT,1.0	CHEMBL610009,TP,ACT,1.0	CHEMBL11262,TN,INACT,0.17000000178813934	CHEMBL2181191,TP,ACT,0.9900000095367432	CHEMBL3589710,FN,ACT,0.7200000286102295	CHEMBL520212,TN,INACT,0.30000001192092896	CHEMBL205768,TN,INACT,0.8399999737739563	CHEMBL610893,TP,ACT,1.0	CHEMBL159623,TN,INACT,0.10999999940395355	CHEMBL60547,TP,ACT,1.0	CHEMBL2387335,TN,INACT,0.7900000214576721	CHEMBL2163921,TN,INACT,0.8700000047683716	CHEMBL233957,TN,INACT,0.5	CHEMBL611702,TP,ACT,1.0	CHEMBL3409759,TP,ACT,0.9800000190734863	CHEMBL610002,TP,ACT,1.0	CHEMBL3234454,FP,INACT,1.0	CHEMBL217049,TP,ACT,0.9900000095367432	CHEMBL118487,TP,ACT,0.9900000095367432	CHEMBL26061,TN,INACT,0.07000000029802322	CHEMBL100358,TP,ACT,1.0	CHEMBL2436816,TN,INACT,0.15000000596046448	CHEMBL95986,TN,INACT,0.07000000029802322	CHEMBL94515,TP,ACT,1.0	CHEMBL1237297,FP,INACT,0.9399999976158142	CHEMBL444626,TP,ACT,0.9100000262260437	CHEMBL2017146,TP,ACT,0.9900000095367432	CHEMBL269119,TP,ACT,1.0	CHEMBL1774786,TN,INACT,0.7099999785423279	CHEMBL1230284,TN,INACT,0.07999999821186066	CHEMBL25976,TN,INACT,0.019999999552965164	CHEMBL244650,TP,ACT,0.9100000262260437	CHEMBL319534,TN,INACT,0.12999999523162842	CHEMBL266717,TP,ACT,1.0	CHEMBL543947,TP,ACT,0.9800000190734863	CHEMBL411196,TP,ACT,1.0	CHEMBL292521,FN,ACT,0.550000011920929	CHEMBL311781,TN,INACT,0.07000000029802322	CHEMBL215040,FP,INACT,0.9800000190734863	CHEMBL298571,TP,ACT,0.9900000095367432	CHEMBL339115,TN,INACT,0.36000001430511475	CHEMBL258905,TN,INACT,0.14000000059604645	CHEMBL410909,TP,ACT,1.0	CHEMBL490665,TP,ACT,1.0	CHEMBL56357,TP,ACT,1.0	CHEMBL418426,TN,INACT,0.05999999865889549	CHEMBL124015,TP,ACT,0.9900000095367432	CHEMBL216821,TN,INACT,0.019999999552965164	CHEMBL345208,TP,ACT,1.0	CHEMBL301804,TP,ACT,1.0	CHEMBL3323524,TP,ACT,0.9300000071525574	CHEMBL2112576,TP,ACT,1.0	CHEMBL95620,TP,ACT,1.0	CHEMBL20844,TN,INACT,0.03999999910593033	CHEMBL296282,TP,ACT,1.0	CHEMBL297335,TN,INACT,0.8899999856948853	CHEMBL608814,FP,INACT,0.9900000095367432	CHEMBL3114165,TN,INACT,0.07999999821186066	CHEMBL3314921,TN,INACT,0.5	CHEMBL154510,TP,ACT,1.0	CHEMBL30057,TN,INACT,0.07999999821186066	CHEMBL332645,TN,INACT,0.2800000011920929	CHEMBL449278,FP,INACT,1.0	CHEMBL2113395,TN,INACT,0.8799999952316284	CHEMBL399203,TN,INACT,0.07000000029802322	CHEMBL7441,TN,INACT,0.5299999713897705	CHEMBL72766,TN,INACT,0.1899999976158142	CHEMBL105942,TP,ACT,0.949999988079071	CHEMBL240895,TN,INACT,0.07000000029802322	CHEMBL2373014,TP,ACT,1.0	CHEMBL2062848,TN,INACT,0.28999999165534973	CHEMBL558766,TN,INACT,0.05999999865889549	CHEMBL3409744,TP,ACT,1.0	CHEMBL322838,TP,ACT,1.0	CHEMBL414068,TP,ACT,1.0	CHEMBL344602,TN,INACT,0.07999999821186066	CHEMBL611804,FN,ACT,0.8299999833106995	CHEMBL3327375,TN,INACT,0.23999999463558197	CHEMBL340501,TN,INACT,0.30000001192092896	CHEMBL89093,TN,INACT,0.5699999928474426	CHEMBL422959,TN,INACT,0.029999999329447746	CHEMBL432144,TN,INACT,0.009999999776482582	CHEMBL3326360,TP,ACT,0.9599999785423279	CHEMBL63937,TN,INACT,0.3100000023841858	CHEMBL422560,TP,ACT,0.9900000095367432	CHEMBL2368318,TP,ACT,1.0	CHEMBL316988,TP,ACT,0.949999988079071	CHEMBL140044,TP,ACT,1.0	CHEMBL474497,TP,ACT,1.0	CHEMBL404976,TP,ACT,1.0	CHEMBL67700,TN,INACT,0.029999999329447746	CHEMBL329719,TP,ACT,1.0	CHEMBL205813,TN,INACT,0.6200000047683716	CHEMBL3326354,TP,ACT,0.9900000095367432	CHEMBL384248,TN,INACT,0.5699999928474426	CHEMBL361274,TP,ACT,0.9800000190734863	CHEMBL320218,TP,ACT,1.0	CHEMBL964,TN,INACT,0.03999999910593033	CHEMBL3215686,TP,ACT,1.0	CHEMBL436608,TP,ACT,1.0	CHEMBL1161423,TP,ACT,1.0	CHEMBL38874,TP,ACT,0.9700000286102295	CHEMBL169367,TP,ACT,0.9900000095367432	CHEMBL216940,TP,ACT,1.0	CHEMBL96776,TP,ACT,1.0	CHEMBL434063,TN,INACT,0.1899999976158142	CHEMBL213228,TP,ACT,1.0	CHEMBL3409751,TP,ACT,1.0	CHEMBL1093716,TN,INACT,0.15000000596046448	CHEMBL60444,TP,ACT,0.9399999976158142	CHEMBL2016679,TP,ACT,1.0	CHEMBL370544,TP,ACT,1.0	CHEMBL267014,TN,INACT,0.17000000178813934	CHEMBL299538,TN,INACT,0.1599999964237213	CHEMBL336256,TN,INACT,0.3100000023841858	CHEMBL2113655,TP,ACT,1.0	CHEMBL1255022,TP,ACT,1.0	CHEMBL274501,TN,INACT,0.1599999964237213	CHEMBL322512,TN,INACT,0.10999999940395355	CHEMBL2181199,TP,ACT,0.9599999785423279	CHEMBL262690,TN,INACT,0.6700000166893005	CHEMBL3323525,FN,ACT,0.8299999833106995	CHEMBL541164,TN,INACT,0.38999998569488525	CHEMBL3236676,TP,ACT,0.9399999976158142	CHEMBL283320,TN,INACT,0.07999999821186066	CHEMBL2338736,TP,ACT,1.0	CHEMBL296245,TN,INACT,0.03999999910593033	CHEMBL352365,TP,ACT,0.9900000095367432	CHEMBL594801,TN,INACT,0.38999998569488525	CHEMBL10808,TN,INACT,0.5299999713897705	CHEMBL484778,TN,INACT,0.28999999165534973	CHEMBL143416,TP,ACT,0.949999988079071	CHEMBL430732,TP,ACT,0.9900000095367432	CHEMBL2147927,TP,ACT,1.0	CHEMBL1082971,TP,ACT,1.0	CHEMBL341529,TP,ACT,0.9900000095367432	CHEMBL577999,TP,ACT,0.9300000071525574	CHEMBL296304,TP,ACT,1.0	CHEMBL3350140,TP,ACT,1.0	CHEMBL2147929,TP,ACT,1.0	CHEMBL297467,TP,ACT,1.0	CHEMBL606606,TP,ACT,1.0	CHEMBL423260,TN,INACT,0.8999999761581421	CHEMBL1263,TN,INACT,0.4000000059604645	CHEMBL286139,TN,INACT,0.019999999552965164	CHEMBL1672471,TP,ACT,1.0	CHEMBL344284,TN,INACT,0.30000001192092896	CHEMBL432045,FN,ACT,0.8500000238418579	CHEMBL317097,TP,ACT,1.0	

