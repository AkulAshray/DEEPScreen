ImageNetInceptionV2 CHEMBL211 RMSprop 0.0001 5 0 0 0.6 False True
Number of active compounds :	1210
Number of inactive compounds :	1210
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL211_RMSprop_0.0001_5_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL211_RMSprop_0.0001_5_0.6/
---------------------------------
Training samples: 1416
Validation samples: 443
--
Training Step: 1  | time: 175.975s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1416
[A[ATraining Step: 2  | total loss: [1m[32m0.66495[0m[0m | time: 255.072s
[2K
| RMSProp | epoch: 001 | loss: 0.66495 - acc: 0.3656 -- iter: 0064/1416
[A[ATraining Step: 3  | total loss: [1m[32m0.74966[0m[0m | time: 354.988s
[2K
| RMSProp | epoch: 001 | loss: 0.74966 - acc: 0.4244 -- iter: 0096/1416
[A[ATraining Step: 4  | total loss: [1m[32m0.77989[0m[0m | time: 437.813s
[2K
| RMSProp | epoch: 001 | loss: 0.77989 - acc: 0.4811 -- iter: 0128/1416
[A[ATraining Step: 5  | total loss: [1m[32m0.78082[0m[0m | time: 496.268s
[2K
| RMSProp | epoch: 001 | loss: 0.78082 - acc: 0.4293 -- iter: 0160/1416
[A[ATraining Step: 6  | total loss: [1m[32m0.74207[0m[0m | time: 526.030s
[2K
| RMSProp | epoch: 001 | loss: 0.74207 - acc: 0.4747 -- iter: 0192/1416
[A[ATraining Step: 7  | total loss: [1m[32m0.72314[0m[0m | time: 564.457s
[2K
| RMSProp | epoch: 001 | loss: 0.72314 - acc: 0.5461 -- iter: 0224/1416
[A[ATraining Step: 8  | total loss: [1m[32m0.72493[0m[0m | time: 600.573s
[2K
| RMSProp | epoch: 001 | loss: 0.72493 - acc: 0.5378 -- iter: 0256/1416
[A[ATraining Step: 9  | total loss: [1m[32m0.71417[0m[0m | time: 632.105s
[2K
| RMSProp | epoch: 001 | loss: 0.71417 - acc: 0.5509 -- iter: 0288/1416
[A[ATraining Step: 10  | total loss: [1m[32m0.74416[0m[0m | time: 648.062s
[2K
| RMSProp | epoch: 001 | loss: 0.74416 - acc: 0.4629 -- iter: 0320/1416
[A[ATraining Step: 11  | total loss: [1m[32m0.73894[0m[0m | time: 665.925s
[2K
| RMSProp | epoch: 001 | loss: 0.73894 - acc: 0.4509 -- iter: 0352/1416
[A[ATraining Step: 12  | total loss: [1m[32m0.73575[0m[0m | time: 679.154s
[2K
| RMSProp | epoch: 001 | loss: 0.73575 - acc: 0.4589 -- iter: 0384/1416
[A[ATraining Step: 13  | total loss: [1m[32m0.72372[0m[0m | time: 693.771s
[2K
| RMSProp | epoch: 001 | loss: 0.72372 - acc: 0.4497 -- iter: 0416/1416
[A[ATraining Step: 14  | total loss: [1m[32m0.71707[0m[0m | time: 707.056s
[2K
| RMSProp | epoch: 001 | loss: 0.71707 - acc: 0.4575 -- iter: 0448/1416
[A[ATraining Step: 15  | total loss: [1m[32m0.72949[0m[0m | time: 733.771s
[2K
| RMSProp | epoch: 001 | loss: 0.72949 - acc: 0.4619 -- iter: 0480/1416
[A[ATraining Step: 16  | total loss: [1m[32m0.75087[0m[0m | time: 758.278s
[2K
| RMSProp | epoch: 001 | loss: 0.75087 - acc: 0.4176 -- iter: 0512/1416
[A[ATraining Step: 17  | total loss: [1m[32m0.74021[0m[0m | time: 774.169s
[2K
| RMSProp | epoch: 001 | loss: 0.74021 - acc: 0.4360 -- iter: 0544/1416
[A[ATraining Step: 18  | total loss: [1m[32m0.72639[0m[0m | time: 788.693s
[2K
| RMSProp | epoch: 001 | loss: 0.72639 - acc: 0.4906 -- iter: 0576/1416
[A[ATraining Step: 19  | total loss: [1m[32m0.74125[0m[0m | time: 805.118s
[2K
| RMSProp | epoch: 001 | loss: 0.74125 - acc: 0.4625 -- iter: 0608/1416
[A[ATraining Step: 20  | total loss: [1m[32m0.75433[0m[0m | time: 817.956s
[2K
| RMSProp | epoch: 001 | loss: 0.75433 - acc: 0.4243 -- iter: 0640/1416
[A[ATraining Step: 21  | total loss: [1m[32m0.73013[0m[0m | time: 832.602s
[2K
| RMSProp | epoch: 001 | loss: 0.73013 - acc: 0.4963 -- iter: 0672/1416
[A[ATraining Step: 22  | total loss: [1m[32m0.73926[0m[0m | time: 847.239s
[2K
| RMSProp | epoch: 001 | loss: 0.73926 - acc: 0.4787 -- iter: 0704/1416
[A[ATraining Step: 23  | total loss: [1m[32m0.73365[0m[0m | time: 859.531s
[2K
| RMSProp | epoch: 001 | loss: 0.73365 - acc: 0.4758 -- iter: 0736/1416
[A[ATraining Step: 24  | total loss: [1m[32m0.72847[0m[0m | time: 873.686s
[2K
| RMSProp | epoch: 001 | loss: 0.72847 - acc: 0.4738 -- iter: 0768/1416
[A[ATraining Step: 25  | total loss: [1m[32m0.72013[0m[0m | time: 887.194s
[2K
| RMSProp | epoch: 001 | loss: 0.72013 - acc: 0.4809 -- iter: 0800/1416
[A[ATraining Step: 26  | total loss: [1m[32m0.71657[0m[0m | time: 907.098s
[2K
| RMSProp | epoch: 001 | loss: 0.71657 - acc: 0.5025 -- iter: 0832/1416
[A[ATraining Step: 27  | total loss: [1m[32m0.71031[0m[0m | time: 923.344s
[2K
| RMSProp | epoch: 001 | loss: 0.71031 - acc: 0.5099 -- iter: 0864/1416
[A[ATraining Step: 28  | total loss: [1m[32m0.70616[0m[0m | time: 937.490s
[2K
| RMSProp | epoch: 001 | loss: 0.70616 - acc: 0.5153 -- iter: 0896/1416
[A[ATraining Step: 29  | total loss: [1m[32m0.70137[0m[0m | time: 951.451s
[2K
| RMSProp | epoch: 001 | loss: 0.70137 - acc: 0.5419 -- iter: 0928/1416
[A[ATraining Step: 30  | total loss: [1m[32m0.69708[0m[0m | time: 964.029s
[2K
| RMSProp | epoch: 001 | loss: 0.69708 - acc: 0.5542 -- iter: 0960/1416
[A[ATraining Step: 31  | total loss: [1m[32m0.70023[0m[0m | time: 978.754s
[2K
| RMSProp | epoch: 001 | loss: 0.70023 - acc: 0.5489 -- iter: 0992/1416
[A[ATraining Step: 32  | total loss: [1m[32m0.71553[0m[0m | time: 992.606s
[2K
| RMSProp | epoch: 001 | loss: 0.71553 - acc: 0.5238 -- iter: 1024/1416
[A[ATraining Step: 33  | total loss: [1m[32m0.72492[0m[0m | time: 1005.428s
[2K
| RMSProp | epoch: 001 | loss: 0.72492 - acc: 0.5118 -- iter: 1056/1416
[A[ATraining Step: 34  | total loss: [1m[32m0.72986[0m[0m | time: 1014.025s
[2K
| RMSProp | epoch: 001 | loss: 0.72986 - acc: 0.4758 -- iter: 1088/1416
[A[ATraining Step: 35  | total loss: [1m[32m0.73141[0m[0m | time: 1025.157s
[2K
| RMSProp | epoch: 001 | loss: 0.73141 - acc: 0.4612 -- iter: 1120/1416
[A[ATraining Step: 36  | total loss: [1m[32m0.72585[0m[0m | time: 1033.955s
[2K
| RMSProp | epoch: 001 | loss: 0.72585 - acc: 0.4883 -- iter: 1152/1416
[A[ATraining Step: 37  | total loss: [1m[32m0.71469[0m[0m | time: 1043.554s
[2K
| RMSProp | epoch: 001 | loss: 0.71469 - acc: 0.5094 -- iter: 1184/1416
[A[ATraining Step: 38  | total loss: [1m[32m0.71224[0m[0m | time: 1060.509s
[2K
| RMSProp | epoch: 001 | loss: 0.71224 - acc: 0.5137 -- iter: 1216/1416
[A[ATraining Step: 39  | total loss: [1m[32m0.71359[0m[0m | time: 1081.191s
[2K
| RMSProp | epoch: 001 | loss: 0.71359 - acc: 0.5111 -- iter: 1248/1416
[A[ATraining Step: 40  | total loss: [1m[32m0.71110[0m[0m | time: 1094.510s
[2K
| RMSProp | epoch: 001 | loss: 0.71110 - acc: 0.5266 -- iter: 1280/1416
[A[ATraining Step: 41  | total loss: [1m[32m0.70578[0m[0m | time: 1109.902s
[2K
| RMSProp | epoch: 001 | loss: 0.70578 - acc: 0.5389 -- iter: 1312/1416
[A[ATraining Step: 42  | total loss: [1m[32m0.70425[0m[0m | time: 1122.516s
[2K
| RMSProp | epoch: 001 | loss: 0.70425 - acc: 0.5432 -- iter: 1344/1416
[A[ATraining Step: 43  | total loss: [1m[32m0.70196[0m[0m | time: 1136.552s
[2K
| RMSProp | epoch: 001 | loss: 0.70196 - acc: 0.5576 -- iter: 1376/1416
[A[ATraining Step: 44  | total loss: [1m[32m0.69172[0m[0m | time: 1150.225s
[2K
| RMSProp | epoch: 001 | loss: 0.69172 - acc: 0.5801 -- iter: 1408/1416
[A[ATraining Step: 45  | total loss: [1m[32m0.69549[0m[0m | time: 1196.607s
[2K
| RMSProp | epoch: 001 | loss: 0.69549 - acc: 0.5665 | val_loss: 0.71556 - val_acc: 0.4470 -- iter: 1416/1416
--
Training Step: 46  | total loss: [1m[32m0.70537[0m[0m | time: 4.289s
[2K
| RMSProp | epoch: 002 | loss: 0.70537 - acc: 0.5346 -- iter: 0032/1416
[A[ATraining Step: 47  | total loss: [1m[32m0.70741[0m[0m | time: 17.749s
[2K
| RMSProp | epoch: 002 | loss: 0.70741 - acc: 0.5289 -- iter: 0064/1416
[A[ATraining Step: 48  | total loss: [1m[32m0.70499[0m[0m | time: 32.009s
[2K
| RMSProp | epoch: 002 | loss: 0.70499 - acc: 0.5243 -- iter: 0096/1416
[A[ATraining Step: 49  | total loss: [1m[32m0.70768[0m[0m | time: 44.805s
[2K
| RMSProp | epoch: 002 | loss: 0.70768 - acc: 0.5007 -- iter: 0128/1416
[A[ATraining Step: 50  | total loss: [1m[32m0.70671[0m[0m | time: 58.481s
[2K
| RMSProp | epoch: 002 | loss: 0.70671 - acc: 0.5006 -- iter: 0160/1416
[A[ATraining Step: 51  | total loss: [1m[32m0.70510[0m[0m | time: 70.983s
[2K
| RMSProp | epoch: 002 | loss: 0.70510 - acc: 0.4957 -- iter: 0192/1416
[A[ATraining Step: 52  | total loss: [1m[32m0.69930[0m[0m | time: 83.853s
[2K
| RMSProp | epoch: 002 | loss: 0.69930 - acc: 0.5151 -- iter: 0224/1416
[A[ATraining Step: 53  | total loss: [1m[32m0.70190[0m[0m | time: 96.987s
[2K
| RMSProp | epoch: 002 | loss: 0.70190 - acc: 0.5083 -- iter: 0256/1416
[A[ATraining Step: 54  | total loss: [1m[32m0.71417[0m[0m | time: 110.052s
[2K
| RMSProp | epoch: 002 | loss: 0.71417 - acc: 0.4708 -- iter: 0288/1416
[A[ATraining Step: 55  | total loss: [1m[32m0.71426[0m[0m | time: 124.779s
[2K
| RMSProp | epoch: 002 | loss: 0.71426 - acc: 0.4705 -- iter: 0320/1416
[A[ATraining Step: 56  | total loss: [1m[32m0.70905[0m[0m | time: 137.914s
[2K
| RMSProp | epoch: 002 | loss: 0.70905 - acc: 0.4922 -- iter: 0352/1416
[A[ATraining Step: 57  | total loss: [1m[32m0.71074[0m[0m | time: 146.207s
[2K
| RMSProp | epoch: 002 | loss: 0.71074 - acc: 0.4933 -- iter: 0384/1416
[A[ATraining Step: 58  | total loss: [1m[32m0.71351[0m[0m | time: 154.546s
[2K
| RMSProp | epoch: 002 | loss: 0.71351 - acc: 0.4857 -- iter: 0416/1416
[A[ATraining Step: 59  | total loss: [1m[32m0.71388[0m[0m | time: 162.905s
[2K
| RMSProp | epoch: 002 | loss: 0.71388 - acc: 0.4876 -- iter: 0448/1416
[A[ATraining Step: 60  | total loss: [1m[32m0.71189[0m[0m | time: 172.422s
[2K
| RMSProp | epoch: 002 | loss: 0.71189 - acc: 0.4893 -- iter: 0480/1416
[A[ATraining Step: 61  | total loss: [1m[32m0.71346[0m[0m | time: 185.177s
[2K
| RMSProp | epoch: 002 | loss: 0.71346 - acc: 0.4825 -- iter: 0512/1416
[A[ATraining Step: 62  | total loss: [1m[32m0.71243[0m[0m | time: 197.571s
[2K
| RMSProp | epoch: 002 | loss: 0.71243 - acc: 0.4767 -- iter: 0544/1416
[A[ATraining Step: 63  | total loss: [1m[32m0.70960[0m[0m | time: 209.797s
[2K
| RMSProp | epoch: 002 | loss: 0.70960 - acc: 0.4797 -- iter: 0576/1416
[A[ATraining Step: 64  | total loss: [1m[32m0.71184[0m[0m | time: 223.983s
[2K
| RMSProp | epoch: 002 | loss: 0.71184 - acc: 0.4744 -- iter: 0608/1416
[A[ATraining Step: 65  | total loss: [1m[32m0.70980[0m[0m | time: 236.802s
[2K
| RMSProp | epoch: 002 | loss: 0.70980 - acc: 0.4930 -- iter: 0640/1416
[A[ATraining Step: 66  | total loss: [1m[32m0.70525[0m[0m | time: 249.915s
[2K
| RMSProp | epoch: 002 | loss: 0.70525 - acc: 0.4938 -- iter: 0672/1416
[A[ATraining Step: 67  | total loss: [1m[32m0.69974[0m[0m | time: 263.370s
[2K
| RMSProp | epoch: 002 | loss: 0.69974 - acc: 0.4946 -- iter: 0704/1416
[A[ATraining Step: 68  | total loss: [1m[32m0.70161[0m[0m | time: 276.134s
[2K
| RMSProp | epoch: 002 | loss: 0.70161 - acc: 0.4989 -- iter: 0736/1416
[A[ATraining Step: 69  | total loss: [1m[32m0.69986[0m[0m | time: 288.810s
[2K
| RMSProp | epoch: 002 | loss: 0.69986 - acc: 0.5063 -- iter: 0768/1416
[A[ATraining Step: 70  | total loss: [1m[32m0.70292[0m[0m | time: 301.360s
[2K
| RMSProp | epoch: 002 | loss: 0.70292 - acc: 0.5128 -- iter: 0800/1416
[A[ATraining Step: 71  | total loss: [1m[32m0.69828[0m[0m | time: 314.647s
[2K
| RMSProp | epoch: 002 | loss: 0.69828 - acc: 0.5220 -- iter: 0832/1416
[A[ATraining Step: 72  | total loss: [1m[32m0.70601[0m[0m | time: 328.585s
[2K
| RMSProp | epoch: 002 | loss: 0.70601 - acc: 0.5090 -- iter: 0864/1416
[A[ATraining Step: 73  | total loss: [1m[32m0.70209[0m[0m | time: 341.038s
[2K
| RMSProp | epoch: 002 | loss: 0.70209 - acc: 0.5219 -- iter: 0896/1416
[A[ATraining Step: 74  | total loss: [1m[32m0.70243[0m[0m | time: 356.747s
[2K
| RMSProp | epoch: 002 | loss: 0.70243 - acc: 0.5161 -- iter: 0928/1416
[A[ATraining Step: 75  | total loss: [1m[32m0.70006[0m[0m | time: 369.312s
[2K
| RMSProp | epoch: 002 | loss: 0.70006 - acc: 0.5143 -- iter: 0960/1416
[A[ATraining Step: 76  | total loss: [1m[32m0.69560[0m[0m | time: 382.200s
[2K
| RMSProp | epoch: 002 | loss: 0.69560 - acc: 0.5262 -- iter: 0992/1416
[A[ATraining Step: 77  | total loss: [1m[32m0.69992[0m[0m | time: 395.983s
[2K
| RMSProp | epoch: 002 | loss: 0.69992 - acc: 0.5168 -- iter: 1024/1416
[A[ATraining Step: 78  | total loss: [1m[32m0.69808[0m[0m | time: 408.804s
[2K
| RMSProp | epoch: 002 | loss: 0.69808 - acc: 0.5150 -- iter: 1056/1416
[A[ATraining Step: 79  | total loss: [1m[32m0.70181[0m[0m | time: 423.879s
[2K
| RMSProp | epoch: 002 | loss: 0.70181 - acc: 0.5005 -- iter: 1088/1416
[A[ATraining Step: 80  | total loss: [1m[32m0.70227[0m[0m | time: 436.124s
[2K
| RMSProp | epoch: 002 | loss: 0.70227 - acc: 0.5037 -- iter: 1120/1416
[A[ATraining Step: 81  | total loss: [1m[32m0.70664[0m[0m | time: 448.690s
[2K
| RMSProp | epoch: 002 | loss: 0.70664 - acc: 0.5065 -- iter: 1152/1416
[A[ATraining Step: 82  | total loss: [1m[32m0.70509[0m[0m | time: 462.605s
[2K
| RMSProp | epoch: 002 | loss: 0.70509 - acc: 0.5121 -- iter: 1184/1416
[A[ATraining Step: 83  | total loss: [1m[32m0.70026[0m[0m | time: 476.859s
[2K
| RMSProp | epoch: 002 | loss: 0.70026 - acc: 0.5296 -- iter: 1216/1416
[A[ATraining Step: 84  | total loss: [1m[32m0.70010[0m[0m | time: 489.009s
[2K
| RMSProp | epoch: 002 | loss: 0.70010 - acc: 0.5267 -- iter: 1248/1416
[A[ATraining Step: 85  | total loss: [1m[32m0.69577[0m[0m | time: 502.924s
[2K
| RMSProp | epoch: 002 | loss: 0.69577 - acc: 0.5365 -- iter: 1280/1416
[A[ATraining Step: 86  | total loss: [1m[32m0.69479[0m[0m | time: 511.944s
[2K
| RMSProp | epoch: 002 | loss: 0.69479 - acc: 0.5422 -- iter: 1312/1416
[A[ATraining Step: 87  | total loss: [1m[32m0.69336[0m[0m | time: 520.347s
[2K
| RMSProp | epoch: 002 | loss: 0.69336 - acc: 0.5505 -- iter: 1344/1416
[A[ATraining Step: 88  | total loss: [1m[32m0.69029[0m[0m | time: 528.629s
[2K
| RMSProp | epoch: 002 | loss: 0.69029 - acc: 0.5579 -- iter: 1376/1416
[A[ATraining Step: 89  | total loss: [1m[32m0.69087[0m[0m | time: 537.750s
[2K
| RMSProp | epoch: 002 | loss: 0.69087 - acc: 0.5522 -- iter: 1408/1416
[A[ATraining Step: 90  | total loss: [1m[32m0.69462[0m[0m | time: 582.252s
[2K
| RMSProp | epoch: 002 | loss: 0.69462 - acc: 0.5469 | val_loss: 0.76609 - val_acc: 0.4447 -- iter: 1416/1416
--
Training Step: 91  | total loss: [1m[32m0.68860[0m[0m | time: 4.391s
[2K
| RMSProp | epoch: 003 | loss: 0.68860 - acc: 0.5579 -- iter: 0032/1416
[A[ATraining Step: 92  | total loss: [1m[32m0.69924[0m[0m | time: 8.774s
[2K
| RMSProp | epoch: 003 | loss: 0.69924 - acc: 0.5521 -- iter: 0064/1416
[A[ATraining Step: 93  | total loss: [1m[32m0.68707[0m[0m | time: 21.242s
[2K
| RMSProp | epoch: 003 | loss: 0.68707 - acc: 0.5719 -- iter: 0096/1416
[A[ATraining Step: 94  | total loss: [1m[32m0.68687[0m[0m | time: 37.557s
[2K
| RMSProp | epoch: 003 | loss: 0.68687 - acc: 0.5678 -- iter: 0128/1416
[A[ATraining Step: 95  | total loss: [1m[32m0.68268[0m[0m | time: 50.083s
[2K
| RMSProp | epoch: 003 | loss: 0.68268 - acc: 0.5704 -- iter: 0160/1416
[A[ATraining Step: 96  | total loss: [1m[32m0.67706[0m[0m | time: 62.430s
[2K
| RMSProp | epoch: 003 | loss: 0.67706 - acc: 0.5821 -- iter: 0192/1416
[A[ATraining Step: 97  | total loss: [1m[32m0.67609[0m[0m | time: 75.038s
[2K
| RMSProp | epoch: 003 | loss: 0.67609 - acc: 0.5802 -- iter: 0224/1416
[A[ATraining Step: 98  | total loss: [1m[32m0.68258[0m[0m | time: 87.290s
[2K
| RMSProp | epoch: 003 | loss: 0.68258 - acc: 0.5690 -- iter: 0256/1416
[A[ATraining Step: 99  | total loss: [1m[32m0.69323[0m[0m | time: 99.781s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.5434 -- iter: 0288/1416
[A[ATraining Step: 100  | total loss: [1m[32m0.69750[0m[0m | time: 112.481s
[2K
| RMSProp | epoch: 003 | loss: 0.69750 - acc: 0.5265 -- iter: 0320/1416
[A[ATraining Step: 101  | total loss: [1m[32m0.69022[0m[0m | time: 125.123s
[2K
| RMSProp | epoch: 003 | loss: 0.69022 - acc: 0.5332 -- iter: 0352/1416
[A[ATraining Step: 102  | total loss: [1m[32m0.69393[0m[0m | time: 137.716s
[2K
| RMSProp | epoch: 003 | loss: 0.69393 - acc: 0.5299 -- iter: 0384/1416
[A[ATraining Step: 103  | total loss: [1m[32m0.69107[0m[0m | time: 150.464s
[2K
| RMSProp | epoch: 003 | loss: 0.69107 - acc: 0.5394 -- iter: 0416/1416
[A[ATraining Step: 104  | total loss: [1m[32m0.69373[0m[0m | time: 162.990s
[2K
| RMSProp | epoch: 003 | loss: 0.69373 - acc: 0.5292 -- iter: 0448/1416
[A[ATraining Step: 105  | total loss: [1m[32m0.69138[0m[0m | time: 175.135s
[2K
| RMSProp | epoch: 003 | loss: 0.69138 - acc: 0.5294 -- iter: 0480/1416
[A[ATraining Step: 106  | total loss: [1m[32m0.69384[0m[0m | time: 187.672s
[2K
| RMSProp | epoch: 003 | loss: 0.69384 - acc: 0.5296 -- iter: 0512/1416
[A[ATraining Step: 107  | total loss: [1m[32m0.68483[0m[0m | time: 199.815s
[2K
| RMSProp | epoch: 003 | loss: 0.68483 - acc: 0.5485 -- iter: 0544/1416
[A[ATraining Step: 108  | total loss: [1m[32m0.68656[0m[0m | time: 212.277s
[2K
| RMSProp | epoch: 003 | loss: 0.68656 - acc: 0.5499 -- iter: 0576/1416
[A[ATraining Step: 109  | total loss: [1m[32m0.68769[0m[0m | time: 224.003s
[2K
| RMSProp | epoch: 003 | loss: 0.68769 - acc: 0.5543 -- iter: 0608/1416
[A[ATraining Step: 110  | total loss: [1m[32m0.68916[0m[0m | time: 236.931s
[2K
| RMSProp | epoch: 003 | loss: 0.68916 - acc: 0.5551 -- iter: 0640/1416
[A[ATraining Step: 111  | total loss: [1m[32m0.68692[0m[0m | time: 249.909s
[2K
| RMSProp | epoch: 003 | loss: 0.68692 - acc: 0.5559 -- iter: 0672/1416
[A[ATraining Step: 112  | total loss: [1m[32m0.68138[0m[0m | time: 258.508s
[2K
| RMSProp | epoch: 003 | loss: 0.68138 - acc: 0.5565 -- iter: 0704/1416
[A[ATraining Step: 113  | total loss: [1m[32m0.68125[0m[0m | time: 266.876s
[2K
| RMSProp | epoch: 003 | loss: 0.68125 - acc: 0.5634 -- iter: 0736/1416
[A[ATraining Step: 114  | total loss: [1m[32m0.68315[0m[0m | time: 277.110s
[2K
| RMSProp | epoch: 003 | loss: 0.68315 - acc: 0.5633 -- iter: 0768/1416
[A[ATraining Step: 115  | total loss: [1m[32m0.68865[0m[0m | time: 289.743s
[2K
| RMSProp | epoch: 003 | loss: 0.68865 - acc: 0.5601 -- iter: 0800/1416
[A[ATraining Step: 116  | total loss: [1m[32m0.69297[0m[0m | time: 302.366s
[2K
| RMSProp | epoch: 003 | loss: 0.69297 - acc: 0.5572 -- iter: 0832/1416
[A[ATraining Step: 117  | total loss: [1m[32m0.69635[0m[0m | time: 315.329s
[2K
| RMSProp | epoch: 003 | loss: 0.69635 - acc: 0.5484 -- iter: 0864/1416
[A[ATraining Step: 118  | total loss: [1m[32m0.68772[0m[0m | time: 327.454s
[2K
| RMSProp | epoch: 003 | loss: 0.68772 - acc: 0.5654 -- iter: 0896/1416
[A[ATraining Step: 119  | total loss: [1m[32m0.68598[0m[0m | time: 339.395s
[2K
| RMSProp | epoch: 003 | loss: 0.68598 - acc: 0.5651 -- iter: 0928/1416
[A[ATraining Step: 120  | total loss: [1m[32m0.68347[0m[0m | time: 351.911s
[2K
| RMSProp | epoch: 003 | loss: 0.68347 - acc: 0.5648 -- iter: 0960/1416
[A[ATraining Step: 121  | total loss: [1m[32m0.68254[0m[0m | time: 364.103s
[2K
| RMSProp | epoch: 003 | loss: 0.68254 - acc: 0.5584 -- iter: 0992/1416
[A[ATraining Step: 122  | total loss: [1m[32m0.67952[0m[0m | time: 376.433s
[2K
| RMSProp | epoch: 003 | loss: 0.67952 - acc: 0.5650 -- iter: 1024/1416
[A[ATraining Step: 123  | total loss: [1m[32m0.68059[0m[0m | time: 389.067s
[2K
| RMSProp | epoch: 003 | loss: 0.68059 - acc: 0.5616 -- iter: 1056/1416
[A[ATraining Step: 124  | total loss: [1m[32m0.67594[0m[0m | time: 401.836s
[2K
| RMSProp | epoch: 003 | loss: 0.67594 - acc: 0.5617 -- iter: 1088/1416
[A[ATraining Step: 125  | total loss: [1m[32m0.68396[0m[0m | time: 414.313s
[2K
| RMSProp | epoch: 003 | loss: 0.68396 - acc: 0.5493 -- iter: 1120/1416
[A[ATraining Step: 126  | total loss: [1m[32m0.67935[0m[0m | time: 427.087s
[2K
| RMSProp | epoch: 003 | loss: 0.67935 - acc: 0.5631 -- iter: 1152/1416
[A[ATraining Step: 127  | total loss: [1m[32m0.68038[0m[0m | time: 439.737s
[2K
| RMSProp | epoch: 003 | loss: 0.68038 - acc: 0.5568 -- iter: 1184/1416
[A[ATraining Step: 128  | total loss: [1m[32m0.67788[0m[0m | time: 452.434s
[2K
| RMSProp | epoch: 003 | loss: 0.67788 - acc: 0.5574 -- iter: 1216/1416
[A[ATraining Step: 129  | total loss: [1m[32m0.67027[0m[0m | time: 464.722s
[2K
| RMSProp | epoch: 003 | loss: 0.67027 - acc: 0.5704 -- iter: 1248/1416
[A[ATraining Step: 130  | total loss: [1m[32m0.66205[0m[0m | time: 477.184s
[2K
| RMSProp | epoch: 003 | loss: 0.66205 - acc: 0.5852 -- iter: 1280/1416
[A[ATraining Step: 131  | total loss: [1m[32m0.66650[0m[0m | time: 490.015s
[2K
| RMSProp | epoch: 003 | loss: 0.66650 - acc: 0.5830 -- iter: 1312/1416
[A[ATraining Step: 132  | total loss: [1m[32m0.66305[0m[0m | time: 502.636s
[2K
| RMSProp | epoch: 003 | loss: 0.66305 - acc: 0.5965 -- iter: 1344/1416
[A[ATraining Step: 133  | total loss: [1m[32m0.65588[0m[0m | time: 522.840s
[2K
| RMSProp | epoch: 003 | loss: 0.65588 - acc: 0.6119 -- iter: 1376/1416
[A[ATraining Step: 134  | total loss: [1m[32m0.65319[0m[0m | time: 538.758s
[2K
| RMSProp | epoch: 003 | loss: 0.65319 - acc: 0.6132 -- iter: 1408/1416
[A[ATraining Step: 135  | total loss: [1m[32m0.65549[0m[0m | time: 583.167s
[2K
| RMSProp | epoch: 003 | loss: 0.65549 - acc: 0.6113 | val_loss: 0.65274 - val_acc: 0.6163 -- iter: 1416/1416
--
Training Step: 136  | total loss: [1m[32m0.65762[0m[0m | time: 11.149s
[2K
| RMSProp | epoch: 004 | loss: 0.65762 - acc: 0.6064 -- iter: 0032/1416
[A[ATraining Step: 137  | total loss: [1m[32m0.65399[0m[0m | time: 15.422s
[2K
| RMSProp | epoch: 004 | loss: 0.65399 - acc: 0.6145 -- iter: 0064/1416
[A[ATraining Step: 138  | total loss: [1m[32m0.65498[0m[0m | time: 19.410s
[2K
| RMSProp | epoch: 004 | loss: 0.65498 - acc: 0.6155 -- iter: 0096/1416
[A[ATraining Step: 139  | total loss: [1m[32m0.61681[0m[0m | time: 32.054s
[2K
| RMSProp | epoch: 004 | loss: 0.61681 - acc: 0.6540 -- iter: 0128/1416
[A[ATraining Step: 140  | total loss: [1m[32m0.61103[0m[0m | time: 44.718s
[2K
| RMSProp | epoch: 004 | loss: 0.61103 - acc: 0.6636 -- iter: 0160/1416
[A[ATraining Step: 141  | total loss: [1m[32m0.62514[0m[0m | time: 57.752s
[2K
| RMSProp | epoch: 004 | loss: 0.62514 - acc: 0.6504 -- iter: 0192/1416
[A[ATraining Step: 142  | total loss: [1m[32m0.63529[0m[0m | time: 70.334s
[2K
| RMSProp | epoch: 004 | loss: 0.63529 - acc: 0.6447 -- iter: 0224/1416
[A[ATraining Step: 143  | total loss: [1m[32m0.62538[0m[0m | time: 81.554s
[2K
| RMSProp | epoch: 004 | loss: 0.62538 - acc: 0.6521 -- iter: 0256/1416
[A[ATraining Step: 144  | total loss: [1m[32m0.62019[0m[0m | time: 93.893s
[2K
| RMSProp | epoch: 004 | loss: 0.62019 - acc: 0.6556 -- iter: 0288/1416
[A[ATraining Step: 145  | total loss: [1m[32m0.62510[0m[0m | time: 106.539s
[2K
| RMSProp | epoch: 004 | loss: 0.62510 - acc: 0.6588 -- iter: 0320/1416
[A[ATraining Step: 146  | total loss: [1m[32m0.61673[0m[0m | time: 118.734s
[2K
| RMSProp | epoch: 004 | loss: 0.61673 - acc: 0.6711 -- iter: 0352/1416
[A[ATraining Step: 147  | total loss: [1m[32m0.60969[0m[0m | time: 131.022s
[2K
| RMSProp | epoch: 004 | loss: 0.60969 - acc: 0.6727 -- iter: 0384/1416
[A[ATraining Step: 148  | total loss: [1m[32m0.61392[0m[0m | time: 148.403s
[2K
| RMSProp | epoch: 004 | loss: 0.61392 - acc: 0.6711 -- iter: 0416/1416
[A[ATraining Step: 149  | total loss: [1m[32m0.64414[0m[0m | time: 161.231s
[2K
| RMSProp | epoch: 004 | loss: 0.64414 - acc: 0.6540 -- iter: 0448/1416
[A[ATraining Step: 150  | total loss: [1m[32m0.64192[0m[0m | time: 179.090s
[2K
| RMSProp | epoch: 004 | loss: 0.64192 - acc: 0.6636 -- iter: 0480/1416
[A[ATraining Step: 151  | total loss: [1m[32m0.63973[0m[0m | time: 191.435s
[2K
| RMSProp | epoch: 004 | loss: 0.63973 - acc: 0.6597 -- iter: 0512/1416
[A[ATraining Step: 152  | total loss: [1m[32m0.64951[0m[0m | time: 203.640s
[2K
| RMSProp | epoch: 004 | loss: 0.64951 - acc: 0.6437 -- iter: 0544/1416
[A[ATraining Step: 153  | total loss: [1m[32m0.63631[0m[0m | time: 216.339s
[2K
| RMSProp | epoch: 004 | loss: 0.63631 - acc: 0.6606 -- iter: 0576/1416
[A[ATraining Step: 154  | total loss: [1m[32m0.62316[0m[0m | time: 228.505s
[2K
| RMSProp | epoch: 004 | loss: 0.62316 - acc: 0.6758 -- iter: 0608/1416
[A[ATraining Step: 155  | total loss: [1m[32m0.62222[0m[0m | time: 241.220s
[2K
| RMSProp | epoch: 004 | loss: 0.62222 - acc: 0.6738 -- iter: 0640/1416
[A[ATraining Step: 156  | total loss: [1m[32m0.61439[0m[0m | time: 253.424s
[2K
| RMSProp | epoch: 004 | loss: 0.61439 - acc: 0.6908 -- iter: 0672/1416
[A[ATraining Step: 157  | total loss: [1m[32m0.60027[0m[0m | time: 265.605s
[2K
| RMSProp | epoch: 004 | loss: 0.60027 - acc: 0.7030 -- iter: 0704/1416
[A[ATraining Step: 158  | total loss: [1m[32m0.60227[0m[0m | time: 278.150s
[2K
| RMSProp | epoch: 004 | loss: 0.60227 - acc: 0.6952 -- iter: 0736/1416
[A[ATraining Step: 159  | total loss: [1m[32m0.60041[0m[0m | time: 290.808s
[2K
| RMSProp | epoch: 004 | loss: 0.60041 - acc: 0.6944 -- iter: 0768/1416
[A[ATraining Step: 160  | total loss: [1m[32m0.58450[0m[0m | time: 303.018s
[2K
| RMSProp | epoch: 004 | loss: 0.58450 - acc: 0.7094 -- iter: 0800/1416
[A[ATraining Step: 161  | total loss: [1m[32m0.57891[0m[0m | time: 315.471s
[2K
| RMSProp | epoch: 004 | loss: 0.57891 - acc: 0.7197 -- iter: 0832/1416
[A[ATraining Step: 162  | total loss: [1m[32m0.57693[0m[0m | time: 329.036s
[2K
| RMSProp | epoch: 004 | loss: 0.57693 - acc: 0.7227 -- iter: 0864/1416
[A[ATraining Step: 163  | total loss: [1m[32m0.57352[0m[0m | time: 342.352s
[2K
| RMSProp | epoch: 004 | loss: 0.57352 - acc: 0.7192 -- iter: 0896/1416
[A[ATraining Step: 164  | total loss: [1m[32m0.56652[0m[0m | time: 350.943s
[2K
| RMSProp | epoch: 004 | loss: 0.56652 - acc: 0.7129 -- iter: 0928/1416
[A[ATraining Step: 165  | total loss: [1m[32m0.55642[0m[0m | time: 359.494s
[2K
| RMSProp | epoch: 004 | loss: 0.55642 - acc: 0.7166 -- iter: 0960/1416
[A[ATraining Step: 166  | total loss: [1m[32m0.54484[0m[0m | time: 370.361s
[2K
| RMSProp | epoch: 004 | loss: 0.54484 - acc: 0.7231 -- iter: 0992/1416
[A[ATraining Step: 167  | total loss: [1m[32m0.53988[0m[0m | time: 382.369s
[2K
| RMSProp | epoch: 004 | loss: 0.53988 - acc: 0.7289 -- iter: 1024/1416
[A[ATraining Step: 168  | total loss: [1m[32m0.52856[0m[0m | time: 395.075s
[2K
| RMSProp | epoch: 004 | loss: 0.52856 - acc: 0.7372 -- iter: 1056/1416
[A[ATraining Step: 169  | total loss: [1m[32m0.51088[0m[0m | time: 407.606s
[2K
| RMSProp | epoch: 004 | loss: 0.51088 - acc: 0.7448 -- iter: 1088/1416
[A[ATraining Step: 170  | total loss: [1m[32m0.50956[0m[0m | time: 420.542s
[2K
| RMSProp | epoch: 004 | loss: 0.50956 - acc: 0.7453 -- iter: 1120/1416
[A[ATraining Step: 171  | total loss: [1m[32m0.52995[0m[0m | time: 432.831s
[2K
| RMSProp | epoch: 004 | loss: 0.52995 - acc: 0.7270 -- iter: 1152/1416
[A[ATraining Step: 172  | total loss: [1m[32m0.51764[0m[0m | time: 444.954s
[2K
| RMSProp | epoch: 004 | loss: 0.51764 - acc: 0.7356 -- iter: 1184/1416
[A[ATraining Step: 173  | total loss: [1m[32m0.51844[0m[0m | time: 457.092s
[2K
| RMSProp | epoch: 004 | loss: 0.51844 - acc: 0.7276 -- iter: 1216/1416
[A[ATraining Step: 174  | total loss: [1m[32m0.52078[0m[0m | time: 469.598s
[2K
| RMSProp | epoch: 004 | loss: 0.52078 - acc: 0.7299 -- iter: 1248/1416
[A[ATraining Step: 175  | total loss: [1m[32m0.51491[0m[0m | time: 481.817s
[2K
| RMSProp | epoch: 004 | loss: 0.51491 - acc: 0.7381 -- iter: 1280/1416
[A[ATraining Step: 176  | total loss: [1m[32m0.50590[0m[0m | time: 494.650s
[2K
| RMSProp | epoch: 004 | loss: 0.50590 - acc: 0.7456 -- iter: 1312/1416
[A[ATraining Step: 177  | total loss: [1m[32m0.51941[0m[0m | time: 507.077s
[2K
| RMSProp | epoch: 004 | loss: 0.51941 - acc: 0.7398 -- iter: 1344/1416
[A[ATraining Step: 178  | total loss: [1m[32m0.51555[0m[0m | time: 519.905s
[2K
| RMSProp | epoch: 004 | loss: 0.51555 - acc: 0.7408 -- iter: 1376/1416
[A[ATraining Step: 179  | total loss: [1m[32m0.50637[0m[0m | time: 532.279s
[2K
| RMSProp | epoch: 004 | loss: 0.50637 - acc: 0.7480 -- iter: 1408/1416
[A[ATraining Step: 180  | total loss: [1m[32m0.49858[0m[0m | time: 575.978s
[2K
| RMSProp | epoch: 004 | loss: 0.49858 - acc: 0.7544 | val_loss: 3.43639 - val_acc: 0.4447 -- iter: 1416/1416
--
Training Step: 181  | total loss: [1m[32m0.48137[0m[0m | time: 12.661s
[2K
| RMSProp | epoch: 005 | loss: 0.48137 - acc: 0.7665 -- iter: 0032/1416
[A[ATraining Step: 182  | total loss: [1m[32m0.48957[0m[0m | time: 25.147s
[2K
| RMSProp | epoch: 005 | loss: 0.48957 - acc: 0.7554 -- iter: 0064/1416
[A[ATraining Step: 183  | total loss: [1m[32m0.50010[0m[0m | time: 29.386s
[2K
| RMSProp | epoch: 005 | loss: 0.50010 - acc: 0.7518 -- iter: 0096/1416
[A[ATraining Step: 184  | total loss: [1m[32m0.49976[0m[0m | time: 33.665s
[2K
| RMSProp | epoch: 005 | loss: 0.49976 - acc: 0.7516 -- iter: 0128/1416
[A[ATraining Step: 185  | total loss: [1m[32m0.45523[0m[0m | time: 46.052s
[2K
| RMSProp | epoch: 005 | loss: 0.45523 - acc: 0.7764 -- iter: 0160/1416
[A[ATraining Step: 186  | total loss: [1m[32m0.46734[0m[0m | time: 58.404s
[2K
| RMSProp | epoch: 005 | loss: 0.46734 - acc: 0.7613 -- iter: 0192/1416
[A[ATraining Step: 187  | total loss: [1m[32m0.46690[0m[0m | time: 70.993s
[2K
| RMSProp | epoch: 005 | loss: 0.46690 - acc: 0.7664 -- iter: 0224/1416
[A[ATraining Step: 188  | total loss: [1m[32m0.47097[0m[0m | time: 84.784s
[2K
| RMSProp | epoch: 005 | loss: 0.47097 - acc: 0.7648 -- iter: 0256/1416
[A[ATraining Step: 189  | total loss: [1m[32m0.46716[0m[0m | time: 93.347s
[2K
| RMSProp | epoch: 005 | loss: 0.46716 - acc: 0.7727 -- iter: 0288/1416
[A[ATraining Step: 190  | total loss: [1m[32m0.47368[0m[0m | time: 101.681s
[2K
| RMSProp | epoch: 005 | loss: 0.47368 - acc: 0.7704 -- iter: 0320/1416
[A[ATraining Step: 191  | total loss: [1m[32m0.47888[0m[0m | time: 112.385s
[2K
| RMSProp | epoch: 005 | loss: 0.47888 - acc: 0.7684 -- iter: 0352/1416
[A[ATraining Step: 192  | total loss: [1m[32m0.49552[0m[0m | time: 124.838s
[2K
| RMSProp | epoch: 005 | loss: 0.49552 - acc: 0.7728 -- iter: 0384/1416
[A[ATraining Step: 193  | total loss: [1m[32m0.48992[0m[0m | time: 137.361s
[2K
| RMSProp | epoch: 005 | loss: 0.48992 - acc: 0.7768 -- iter: 0416/1416
[A[ATraining Step: 194  | total loss: [1m[32m0.48552[0m[0m | time: 149.737s
[2K
| RMSProp | epoch: 005 | loss: 0.48552 - acc: 0.7772 -- iter: 0448/1416
[A[ATraining Step: 195  | total loss: [1m[32m0.49029[0m[0m | time: 162.180s
[2K
| RMSProp | epoch: 005 | loss: 0.49029 - acc: 0.7745 -- iter: 0480/1416
[A[ATraining Step: 196  | total loss: [1m[32m0.48732[0m[0m | time: 174.765s
[2K
| RMSProp | epoch: 005 | loss: 0.48732 - acc: 0.7720 -- iter: 0512/1416
[A[ATraining Step: 197  | total loss: [1m[32m0.49925[0m[0m | time: 186.978s
[2K
| RMSProp | epoch: 005 | loss: 0.49925 - acc: 0.7636 -- iter: 0544/1416
[A[ATraining Step: 198  | total loss: [1m[32m0.49015[0m[0m | time: 199.011s
[2K
| RMSProp | epoch: 005 | loss: 0.49015 - acc: 0.7716 -- iter: 0576/1416
[A[ATraining Step: 199  | total loss: [1m[32m0.47125[0m[0m | time: 210.974s
[2K
| RMSProp | epoch: 005 | loss: 0.47125 - acc: 0.7757 -- iter: 0608/1416
[A[ATraining Step: 200  | total loss: [1m[32m0.45095[0m[0m | time: 255.240s
[2K
| RMSProp | epoch: 005 | loss: 0.45095 - acc: 0.7887 | val_loss: 0.51612 - val_acc: 0.7540 -- iter: 0640/1416
--
Training Step: 201  | total loss: [1m[32m0.42121[0m[0m | time: 276.002s
[2K
| RMSProp | epoch: 005 | loss: 0.42121 - acc: 0.8099 -- iter: 0672/1416
[A[ATraining Step: 202  | total loss: [1m[32m0.40071[0m[0m | time: 288.665s
[2K
| RMSProp | epoch: 005 | loss: 0.40071 - acc: 0.8226 -- iter: 0704/1416
[A[ATraining Step: 203  | total loss: [1m[32m0.37610[0m[0m | time: 301.260s
[2K
| RMSProp | epoch: 005 | loss: 0.37610 - acc: 0.8372 -- iter: 0736/1416
[A[ATraining Step: 204  | total loss: [1m[32m0.35409[0m[0m | time: 314.125s
[2K
| RMSProp | epoch: 005 | loss: 0.35409 - acc: 0.8473 -- iter: 0768/1416
[A[ATraining Step: 205  | total loss: [1m[32m0.34689[0m[0m | time: 327.034s
[2K
| RMSProp | epoch: 005 | loss: 0.34689 - acc: 0.8500 -- iter: 0800/1416
[A[ATraining Step: 206  | total loss: [1m[32m0.33335[0m[0m | time: 339.509s
[2K
| RMSProp | epoch: 005 | loss: 0.33335 - acc: 0.8619 -- iter: 0832/1416
[A[ATraining Step: 207  | total loss: [1m[32m0.31641[0m[0m | time: 351.855s
[2K
| RMSProp | epoch: 005 | loss: 0.31641 - acc: 0.8726 -- iter: 0864/1416
[A[ATraining Step: 208  | total loss: [1m[32m0.30729[0m[0m | time: 364.542s
[2K
| RMSProp | epoch: 005 | loss: 0.30729 - acc: 0.8791 -- iter: 0896/1416
[A[ATraining Step: 209  | total loss: [1m[32m0.29682[0m[0m | time: 377.002s
[2K
| RMSProp | epoch: 005 | loss: 0.29682 - acc: 0.8881 -- iter: 0928/1416
[A[ATraining Step: 210  | total loss: [1m[32m0.31131[0m[0m | time: 389.392s
[2K
| RMSProp | epoch: 005 | loss: 0.31131 - acc: 0.8836 -- iter: 0960/1416
[A[ATraining Step: 211  | total loss: [1m[32m0.31913[0m[0m | time: 402.394s
[2K
| RMSProp | epoch: 005 | loss: 0.31913 - acc: 0.8796 -- iter: 0992/1416
[A[ATraining Step: 212  | total loss: [1m[32m0.32500[0m[0m | time: 414.645s
[2K
| RMSProp | epoch: 005 | loss: 0.32500 - acc: 0.8729 -- iter: 1024/1416
[A[ATraining Step: 213  | total loss: [1m[32m0.31827[0m[0m | time: 422.959s
[2K
| RMSProp | epoch: 005 | loss: 0.31827 - acc: 0.8763 -- iter: 1056/1416
[A[ATraining Step: 214  | total loss: [1m[32m0.29904[0m[0m | time: 431.185s
[2K
| RMSProp | epoch: 005 | loss: 0.29904 - acc: 0.8824 -- iter: 1088/1416
[A[ATraining Step: 215  | total loss: [1m[32m0.29793[0m[0m | time: 441.024s
[2K
| RMSProp | epoch: 005 | loss: 0.29793 - acc: 0.8816 -- iter: 1120/1416
[A[ATraining Step: 216  | total loss: [1m[32m0.28291[0m[0m | time: 453.757s
[2K
| RMSProp | epoch: 005 | loss: 0.28291 - acc: 0.8872 -- iter: 1152/1416
[A[ATraining Step: 217  | total loss: [1m[32m0.27212[0m[0m | time: 466.419s
[2K
| RMSProp | epoch: 005 | loss: 0.27212 - acc: 0.8891 -- iter: 1184/1416
[A[ATraining Step: 218  | total loss: [1m[32m0.28314[0m[0m | time: 479.414s
[2K
| RMSProp | epoch: 005 | loss: 0.28314 - acc: 0.8877 -- iter: 1216/1416
[A[ATraining Step: 219  | total loss: [1m[32m0.28599[0m[0m | time: 491.957s
[2K
| RMSProp | epoch: 005 | loss: 0.28599 - acc: 0.8896 -- iter: 1248/1416
[A[ATraining Step: 220  | total loss: [1m[32m0.30872[0m[0m | time: 504.905s
[2K
| RMSProp | epoch: 005 | loss: 0.30872 - acc: 0.8725 -- iter: 1280/1416
[A[ATraining Step: 221  | total loss: [1m[32m0.32148[0m[0m | time: 518.030s
[2K
| RMSProp | epoch: 005 | loss: 0.32148 - acc: 0.8727 -- iter: 1312/1416
[A[ATraining Step: 222  | total loss: [1m[32m0.30872[0m[0m | time: 531.126s
[2K
| RMSProp | epoch: 005 | loss: 0.30872 - acc: 0.8761 -- iter: 1344/1416
[A[ATraining Step: 223  | total loss: [1m[32m0.30509[0m[0m | time: 543.545s
[2K
| RMSProp | epoch: 005 | loss: 0.30509 - acc: 0.8760 -- iter: 1376/1416
[A[ATraining Step: 224  | total loss: [1m[32m0.30045[0m[0m | time: 555.623s
[2K
| RMSProp | epoch: 005 | loss: 0.30045 - acc: 0.8790 -- iter: 1408/1416
[A[ATraining Step: 225  | total loss: [1m[32m0.28480[0m[0m | time: 600.007s
[2K
| RMSProp | epoch: 005 | loss: 0.28480 - acc: 0.8849 | val_loss: 0.71638 - val_acc: 0.6885 -- iter: 1416/1416
--
Validation AUC:0.8693615616359209
Validation AUPRC:0.8430079321771932
Test AUC:0.8940232996964476
Test AUPRC:0.8840803547383728
BestTestF1Score	0.81	0.65	0.82	0.82	0.8	163	37	202	41	0.85
BestTestMCCScore	0.78	0.64	0.82	0.87	0.72	146	22	217	58	0.92
BestTestAccuracyScore	0.78	0.64	0.82	0.87	0.72	146	22	217	58	0.92
BestValidationF1Score	0.77	0.57	0.79	0.75	0.79	156	53	193	41	0.85
BestValidationMCC	0.75	0.58	0.79	0.81	0.7	138	32	214	59	0.92
BestValidationAccuracy	0.75	0.58	0.79	0.81	0.7	138	32	214	59	0.92
TestPredictions (Threshold:0.92)
CHEMBL283013,TN,INACT,0.38999998569488525	CHEMBL3335535,TN,INACT,0.6800000071525574	CHEMBL294349,TN,INACT,0.7400000095367432	CHEMBL6568,TN,INACT,0.8500000238418579	CHEMBL72738,TN,INACT,0.4000000059604645	CHEMBL205768,TN,INACT,0.5199999809265137	CHEMBL123654,TN,INACT,0.5799999833106995	CHEMBL64239,TN,INACT,0.07999999821186066	CHEMBL143761,TN,INACT,0.8799999952316284	CHEMBL51096,FN,ACT,0.8999999761581421	CHEMBL62660,TN,INACT,0.6100000143051147	CHEMBL1083787,FP,INACT,0.9700000286102295	CHEMBL417369,FN,ACT,0.7799999713897705	CHEMBL404557,FP,INACT,0.9300000071525574	CHEMBL145301,TP,ACT,0.9900000095367432	CHEMBL3218121,TN,INACT,0.7099999785423279	CHEMBL3410301,TN,INACT,0.33000001311302185	CHEMBL3545181,FN,ACT,0.8999999761581421	CHEMBL42359,TN,INACT,0.15000000596046448	CHEMBL61774,FN,ACT,0.5099999904632568	CHEMBL359220,TP,ACT,0.9800000190734863	CHEMBL319910,TN,INACT,0.2800000011920929	CHEMBL2432054,TP,ACT,1.0	CHEMBL291516,TN,INACT,0.44999998807907104	CHEMBL60142,FN,ACT,0.6600000262260437	CHEMBL2112955,TP,ACT,0.9700000286102295	CHEMBL147105,FN,ACT,0.1899999976158142	CHEMBL410890,TP,ACT,0.9900000095367432	CHEMBL3577342,TN,INACT,0.5	CHEMBL1200803,TP,ACT,0.9800000190734863	CHEMBL549784,TP,ACT,1.0	CHEMBL320820,TP,ACT,0.9900000095367432	CHEMBL92152,TN,INACT,0.09000000357627869	CHEMBL540316,FN,ACT,0.5899999737739563	CHEMBL96365,TN,INACT,0.009999999776482582	CHEMBL12291,TP,ACT,0.9399999976158142	CHEMBL419912,TN,INACT,0.17000000178813934	CHEMBL426393,FN,ACT,0.6700000166893005	CHEMBL138746,TN,INACT,0.18000000715255737	CHEMBL353689,TP,ACT,0.9700000286102295	CHEMBL1464005,TP,ACT,0.9399999976158142	CHEMBL439648,TN,INACT,0.5400000214576721	CHEMBL2205825,TP,ACT,0.9800000190734863	CHEMBL611476,FN,ACT,0.5	CHEMBL29782,TN,INACT,0.38999998569488525	CHEMBL355475,TP,ACT,0.9700000286102295	CHEMBL102452,TN,INACT,0.1599999964237213	CHEMBL344602,TN,INACT,0.4300000071525574	CHEMBL3736248,TN,INACT,0.5099999904632568	CHEMBL72084,TN,INACT,0.14000000059604645	CHEMBL2062848,TN,INACT,0.019999999552965164	CHEMBL477542,FN,ACT,0.8899999856948853	CHEMBL233201,TP,ACT,1.0	CHEMBL21508,TN,INACT,0.5199999809265137	CHEMBL3314886,TN,INACT,0.07000000029802322	CHEMBL3618436,FN,ACT,0.8700000047683716	CHEMBL352607,TP,ACT,0.9900000095367432	CHEMBL3393999,TN,INACT,0.18000000715255737	CHEMBL564765,TP,ACT,1.0	CHEMBL240773,TN,INACT,0.7599999904632568	CHEMBL73893,TP,ACT,1.0	CHEMBL55,TP,ACT,0.9800000190734863	CHEMBL415879,TN,INACT,0.6600000262260437	CHEMBL333125,TP,ACT,0.9800000190734863	CHEMBL27809,TN,INACT,0.2199999988079071	CHEMBL2391352,TN,INACT,0.7300000190734863	CHEMBL12150,TP,ACT,1.0	CHEMBL320465,TP,ACT,0.9399999976158142	CHEMBL356181,FN,ACT,0.4399999976158142	CHEMBL2163919,TN,INACT,0.09000000357627869	CHEMBL258907,TP,ACT,1.0	CHEMBL102613,TN,INACT,0.4300000071525574	CHEMBL223055,TP,ACT,0.9900000095367432	CHEMBL422701,TN,INACT,0.05000000074505806	CHEMBL75002,TN,INACT,0.4099999964237213	CHEMBL63631,TN,INACT,0.38999998569488525	CHEMBL234440,TP,ACT,0.9800000190734863	CHEMBL131428,FN,ACT,0.699999988079071	CHEMBL295698,TN,INACT,0.75	CHEMBL108705,FP,INACT,0.9200000166893005	CHEMBL2114064,TP,ACT,1.0	CHEMBL542877,TN,INACT,0.12999999523162842	CHEMBL2113695,FP,INACT,0.9200000166893005	CHEMBL63114,TN,INACT,0.7099999785423279	CHEMBL70728,TN,INACT,0.05999999865889549	CHEMBL105594,TN,INACT,0.4300000071525574	CHEMBL441305,TN,INACT,0.05999999865889549	CHEMBL325043,TN,INACT,0.3700000047683716	CHEMBL657,TP,ACT,0.9900000095367432	CHEMBL1779128,TP,ACT,1.0	CHEMBL166736,FP,INACT,0.9599999785423279	CHEMBL25373,TN,INACT,0.5899999737739563	CHEMBL216741,TN,INACT,0.009999999776482582	CHEMBL2042553,FN,ACT,0.8399999737739563	CHEMBL2011441,TN,INACT,0.699999988079071	CHEMBL410531,TN,INACT,0.8899999856948853	CHEMBL60620,TN,INACT,0.46000000834465027	CHEMBL556426,TP,ACT,0.9599999785423279	CHEMBL2062861,TN,INACT,0.10999999940395355	CHEMBL608814,TN,INACT,0.49000000953674316	CHEMBL29541,TN,INACT,0.8399999737739563	CHEMBL1085507,FN,ACT,0.8100000023841858	CHEMBL2387335,TN,INACT,0.41999998688697815	CHEMBL412421,TP,ACT,0.9599999785423279	CHEMBL2107687,TP,ACT,0.9800000190734863	CHEMBL440601,TP,ACT,1.0	CHEMBL73410,FN,ACT,0.23000000417232513	CHEMBL51675,TN,INACT,0.07999999821186066	CHEMBL179638,TN,INACT,0.2199999988079071	CHEMBL7505,TN,INACT,0.47999998927116394	CHEMBL164385,TP,ACT,1.0	CHEMBL170298,TP,ACT,0.9900000095367432	CHEMBL1779037,TP,ACT,1.0	CHEMBL72166,FP,INACT,0.949999988079071	CHEMBL330999,FN,ACT,0.8799999952316284	CHEMBL22923,FN,ACT,0.27000001072883606	CHEMBL170221,FN,ACT,0.23000000417232513	CHEMBL307810,TP,ACT,1.0	CHEMBL146983,TN,INACT,0.6100000143051147	CHEMBL234438,TP,ACT,1.0	CHEMBL422959,TN,INACT,0.8100000023841858	CHEMBL342137,TP,ACT,1.0	CHEMBL23957,FN,ACT,0.9100000262260437	CHEMBL54246,FP,INACT,0.9900000095367432	CHEMBL1829335,FN,ACT,0.27000001072883606	CHEMBL202701,TN,INACT,0.019999999552965164	CHEMBL143304,TN,INACT,0.4399999976158142	CHEMBL31599,TP,ACT,0.9800000190734863	CHEMBL3735036,TN,INACT,0.029999999329447746	CHEMBL281633,TN,INACT,0.07000000029802322	CHEMBL128360,TN,INACT,0.019999999552965164	CHEMBL2205823,TP,ACT,0.9900000095367432	CHEMBL282776,TN,INACT,0.5400000214576721	CHEMBL441873,FN,ACT,0.8700000047683716	CHEMBL608831,FP,INACT,0.949999988079071	CHEMBL1779138,TP,ACT,1.0	CHEMBL1084993,FN,ACT,0.5799999833106995	CHEMBL3618450,TP,ACT,1.0	CHEMBL100071,TN,INACT,0.550000011920929	CHEMBL3764246,FP,INACT,0.9300000071525574	CHEMBL83982,TP,ACT,0.9800000190734863	CHEMBL302359,TN,INACT,0.09000000357627869	CHEMBL419306,TN,INACT,0.46000000834465027	CHEMBL264747,TP,ACT,0.9800000190734863	CHEMBL609240,TN,INACT,0.10999999940395355	CHEMBL74342,TN,INACT,0.10000000149011612	CHEMBL381623,TP,ACT,1.0	CHEMBL70531,TP,ACT,0.9399999976158142	CHEMBL99331,TN,INACT,0.5699999928474426	CHEMBL254500,TN,INACT,0.3799999952316284	CHEMBL1162116,FN,ACT,0.8299999833106995	CHEMBL241100,TN,INACT,0.03999999910593033	CHEMBL432897,TN,INACT,0.7900000214576721	CHEMBL355455,TP,ACT,0.9900000095367432	CHEMBL374336,TN,INACT,0.30000001192092896	CHEMBL381108,TN,INACT,0.10999999940395355	CHEMBL26505,TP,ACT,0.9800000190734863	CHEMBL145488,TP,ACT,1.0	CHEMBL355299,TP,ACT,1.0	CHEMBL1490,TP,ACT,0.9900000095367432	CHEMBL2436721,TN,INACT,0.3499999940395355	CHEMBL144751,TP,ACT,1.0	CHEMBL1306,FN,ACT,0.3400000035762787	CHEMBL612034,TP,ACT,0.9700000286102295	CHEMBL284137,TP,ACT,1.0	CHEMBL451335,TN,INACT,0.8999999761581421	CHEMBL1098359,TN,INACT,0.5799999833106995	CHEMBL282310,TN,INACT,0.38999998569488525	CHEMBL3604300,TN,INACT,0.15000000596046448	CHEMBL73245,TP,ACT,0.9800000190734863	CHEMBL169594,TP,ACT,0.9700000286102295	CHEMBL167027,FN,ACT,0.9100000262260437	CHEMBL104222,FP,INACT,0.9700000286102295	CHEMBL606031,TN,INACT,0.03999999910593033	CHEMBL66322,TP,ACT,0.9700000286102295	CHEMBL551327,TP,ACT,1.0	CHEMBL1621896,FP,INACT,0.9599999785423279	CHEMBL2113395,TN,INACT,0.15000000596046448	CHEMBL120472,TP,ACT,0.9900000095367432	CHEMBL527880,FP,INACT,1.0	CHEMBL332335,FN,ACT,0.2800000011920929	CHEMBL344752,TN,INACT,0.75	CHEMBL114484,TP,ACT,0.9300000071525574	CHEMBL378859,TP,ACT,0.9800000190734863	CHEMBL1289314,TP,ACT,1.0	CHEMBL569212,TP,ACT,1.0	CHEMBL3618448,TP,ACT,0.9700000286102295	CHEMBL217699,TN,INACT,0.7300000190734863	CHEMBL168707,TP,ACT,1.0	CHEMBL263040,TP,ACT,0.9900000095367432	CHEMBL62115,TN,INACT,0.5600000023841858	CHEMBL83363,FN,ACT,0.7900000214576721	CHEMBL2164434,TN,INACT,0.4699999988079071	CHEMBL74117,TP,ACT,1.0	CHEMBL354636,TP,ACT,0.9599999785423279	CHEMBL435810,TN,INACT,0.07999999821186066	CHEMBL2023764,TP,ACT,0.9900000095367432	CHEMBL283057,TN,INACT,0.07999999821186066	CHEMBL37512,TN,INACT,0.8799999952316284	CHEMBL75773,TN,INACT,0.8799999952316284	CHEMBL85460,TN,INACT,0.49000000953674316	CHEMBL61494,FN,ACT,0.8299999833106995	CHEMBL174958,TN,INACT,0.47999998927116394	CHEMBL100810,TN,INACT,0.14000000059604645	CHEMBL228144,TP,ACT,0.9800000190734863	CHEMBL9746,FP,INACT,0.9900000095367432	CHEMBL438297,TN,INACT,0.1599999964237213	CHEMBL3354067,TP,ACT,0.9900000095367432	CHEMBL85892,TP,ACT,0.9800000190734863	CHEMBL73341,TP,ACT,1.0	CHEMBL177040,TP,ACT,0.9900000095367432	CHEMBL222916,FN,ACT,0.800000011920929	CHEMBL321178,TN,INACT,0.15000000596046448	CHEMBL73392,TN,INACT,0.03999999910593033	CHEMBL1223346,TN,INACT,0.550000011920929	CHEMBL2062849,TN,INACT,0.20000000298023224	CHEMBL163,TN,INACT,0.029999999329447746	CHEMBL562655,TP,ACT,1.0	CHEMBL31524,TN,INACT,0.36000001430511475	CHEMBL3618444,FN,ACT,0.9100000262260437	CHEMBL496235,TN,INACT,0.5899999737739563	CHEMBL164968,FP,INACT,0.9599999785423279	CHEMBL168541,TN,INACT,0.6499999761581421	CHEMBL417215,TN,INACT,0.7900000214576721	CHEMBL1222983,FP,INACT,0.9900000095367432	CHEMBL163777,TP,ACT,1.0	CHEMBL1192069,TN,INACT,0.5899999737739563	CHEMBL313749,FP,INACT,0.9900000095367432	CHEMBL3798018,TN,INACT,0.44999998807907104	CHEMBL2391353,TN,INACT,0.7300000190734863	CHEMBL147695,TP,ACT,0.9399999976158142	CHEMBL238825,TP,ACT,0.9900000095367432	CHEMBL515170,TN,INACT,0.8999999761581421	CHEMBL461089,FN,ACT,0.23000000417232513	CHEMBL589,FP,INACT,0.9800000190734863	CHEMBL118241,TP,ACT,0.9900000095367432	CHEMBL11794,TP,ACT,1.0	CHEMBL100832,TN,INACT,0.029999999329447746	CHEMBL438822,TP,ACT,1.0	CHEMBL114891,TN,INACT,0.6499999761581421	CHEMBL3218122,TN,INACT,0.8700000047683716	CHEMBL146567,TP,ACT,1.0	CHEMBL555146,FN,ACT,0.75	CHEMBL7568,FN,ACT,0.07999999821186066	CHEMBL356505,TP,ACT,0.949999988079071	CHEMBL2153720,TN,INACT,0.3100000023841858	CHEMBL302886,TN,INACT,0.4300000071525574	CHEMBL195437,TP,ACT,1.0	CHEMBL2370509,TN,INACT,0.07999999821186066	CHEMBL170739,TP,ACT,0.9700000286102295	CHEMBL423260,TN,INACT,0.019999999552965164	CHEMBL3604302,TN,INACT,0.0	CHEMBL307659,TN,INACT,0.6899999976158142	CHEMBL716,TP,ACT,0.9700000286102295	CHEMBL113,TN,INACT,0.029999999329447746	CHEMBL2331793,FP,INACT,0.9800000190734863	CHEMBL3393993,TN,INACT,0.1599999964237213	CHEMBL127273,TP,ACT,0.9399999976158142	CHEMBL83074,FN,ACT,0.5	CHEMBL40796,TN,INACT,0.07999999821186066	CHEMBL3238446,TN,INACT,0.30000001192092896	CHEMBL162706,TN,INACT,0.7599999904632568	CHEMBL105457,TP,ACT,0.9200000166893005	CHEMBL223686,TN,INACT,0.8899999856948853	CHEMBL3410305,TN,INACT,0.03999999910593033	CHEMBL352966,TP,ACT,1.0	CHEMBL76933,TN,INACT,0.4699999988079071	CHEMBL304950,TN,INACT,0.3100000023841858	CHEMBL2158005,TN,INACT,0.11999999731779099	CHEMBL434284,TN,INACT,0.8399999737739563	CHEMBL1289545,FN,ACT,0.8199999928474426	CHEMBL344154,TN,INACT,0.20999999344348907	CHEMBL331516,TP,ACT,0.9399999976158142	CHEMBL330586,TN,INACT,0.4399999976158142	CHEMBL1834624,TN,INACT,0.4399999976158142	CHEMBL70828,TP,ACT,1.0	CHEMBL12085,TP,ACT,1.0	CHEMBL241083,TN,INACT,0.8199999928474426	CHEMBL496376,TP,ACT,0.9399999976158142	CHEMBL404097,FP,INACT,1.0	CHEMBL328093,TP,ACT,0.9900000095367432	CHEMBL103643,TN,INACT,0.8600000143051147	CHEMBL53662,TN,INACT,0.8700000047683716	CHEMBL214342,FN,ACT,0.3700000047683716	CHEMBL330892,TP,ACT,0.9900000095367432	CHEMBL569760,TP,ACT,0.9599999785423279	CHEMBL3740969,TN,INACT,0.8399999737739563	CHEMBL1493369,FN,ACT,0.5299999713897705	CHEMBL285334,TN,INACT,0.8399999737739563	CHEMBL167629,TP,ACT,1.0	CHEMBL555475,TP,ACT,0.9900000095367432	CHEMBL418375,TN,INACT,0.019999999552965164	CHEMBL1076554,TN,INACT,0.11999999731779099	CHEMBL561870,TP,ACT,1.0	CHEMBL393971,TN,INACT,0.41999998688697815	CHEMBL355851,TN,INACT,0.2199999988079071	CHEMBL315676,TP,ACT,0.9599999785423279	CHEMBL333065,FN,ACT,0.8199999928474426	CHEMBL3423408,TN,INACT,0.8899999856948853	CHEMBL261623,TN,INACT,0.15000000596046448	CHEMBL322512,TN,INACT,0.03999999910593033	CHEMBL2426678,TP,ACT,1.0	CHEMBL214642,TP,ACT,0.9700000286102295	CHEMBL305607,TP,ACT,1.0	CHEMBL46195,TN,INACT,0.6899999976158142	CHEMBL303369,TN,INACT,0.4099999964237213	CHEMBL422411,TN,INACT,0.30000001192092896	CHEMBL2312347,TN,INACT,0.8100000023841858	CHEMBL345357,TN,INACT,0.20999999344348907	CHEMBL2391356,TN,INACT,0.6100000143051147	CHEMBL223186,FN,ACT,0.6600000262260437	CHEMBL1221512,FN,ACT,0.11999999731779099	CHEMBL359027,TP,ACT,1.0	CHEMBL169889,TN,INACT,0.09000000357627869	CHEMBL556506,TN,INACT,0.3400000035762787	CHEMBL461088,TN,INACT,0.3400000035762787	CHEMBL74902,TN,INACT,0.5199999809265137	CHEMBL352925,TN,INACT,0.699999988079071	CHEMBL12542,TP,ACT,1.0	CHEMBL2048820,FN,ACT,0.8799999952316284	CHEMBL370232,TP,ACT,1.0	CHEMBL381878,TP,ACT,1.0	CHEMBL214122,TN,INACT,0.7599999904632568	CHEMBL80504,TN,INACT,0.44999998807907104	CHEMBL20844,TN,INACT,0.6399999856948853	CHEMBL2042552,TP,ACT,0.949999988079071	CHEMBL1910845,FN,ACT,0.9100000262260437	CHEMBL353088,TN,INACT,0.17000000178813934	CHEMBL1197177,TP,ACT,0.9800000190734863	CHEMBL84583,TN,INACT,0.8399999737739563	CHEMBL69642,TP,ACT,1.0	CHEMBL221753,TP,ACT,0.9599999785423279	CHEMBL144693,TP,ACT,0.9900000095367432	CHEMBL2426671,TP,ACT,0.9800000190734863	CHEMBL3354068,TP,ACT,0.9399999976158142	CHEMBL2377388,TP,ACT,0.9900000095367432	CHEMBL3739799,TN,INACT,0.36000001430511475	CHEMBL1779133,TP,ACT,1.0	CHEMBL3323005,TN,INACT,0.23999999463558197	CHEMBL1702620,TN,INACT,0.8700000047683716	CHEMBL88937,TN,INACT,0.12999999523162842	CHEMBL3618447,TP,ACT,1.0	CHEMBL3410309,TN,INACT,0.03999999910593033	CHEMBL481153,FN,ACT,0.7799999713897705	CHEMBL291394,TN,INACT,0.6299999952316284	CHEMBL148450,TP,ACT,0.949999988079071	CHEMBL382213,TP,ACT,0.9900000095367432	CHEMBL3665433,TN,INACT,0.27000001072883606	CHEMBL552615,TN,INACT,0.8299999833106995	CHEMBL2153622,TN,INACT,0.38999998569488525	CHEMBL223017,FN,ACT,0.800000011920929	CHEMBL313184,TN,INACT,0.019999999552965164	CHEMBL351550,TN,INACT,0.6600000262260437	CHEMBL538793,TP,ACT,0.9900000095367432	CHEMBL395110,FN,ACT,0.8100000023841858	CHEMBL219118,TP,ACT,0.9900000095367432	CHEMBL62421,TN,INACT,0.11999999731779099	CHEMBL316968,TN,INACT,0.07000000029802322	CHEMBL95986,TN,INACT,0.019999999552965164	CHEMBL337309,TN,INACT,0.5199999809265137	CHEMBL222976,TP,ACT,1.0	CHEMBL74330,TN,INACT,0.7900000214576721	CHEMBL106219,FN,ACT,0.8500000238418579	CHEMBL328812,TN,INACT,0.11999999731779099	CHEMBL105764,FP,INACT,0.9599999785423279	CHEMBL3323283,TP,ACT,0.9200000166893005	CHEMBL40554,FN,ACT,0.8899999856948853	CHEMBL169313,TP,ACT,1.0	CHEMBL452150,FP,INACT,0.9399999976158142	CHEMBL135645,FN,ACT,0.4399999976158142	CHEMBL95589,TN,INACT,0.10000000149011612	CHEMBL390667,TN,INACT,0.800000011920929	CHEMBL140620,TN,INACT,0.6200000047683716	CHEMBL342256,FP,INACT,0.9599999785423279	CHEMBL2436720,TN,INACT,0.7699999809265137	CHEMBL284969,TN,INACT,0.07999999821186066	CHEMBL51256,TP,ACT,0.9900000095367432	CHEMBL75590,TN,INACT,0.3400000035762787	CHEMBL539334,TN,INACT,0.5	CHEMBL1082036,TN,INACT,0.5400000214576721	CHEMBL52800,TN,INACT,0.7200000286102295	CHEMBL557840,TN,INACT,0.5099999904632568	CHEMBL542622,TP,ACT,0.949999988079071	CHEMBL2373213,TN,INACT,0.10999999940395355	CHEMBL334933,TN,INACT,0.1899999976158142	CHEMBL91404,TP,ACT,1.0	CHEMBL2021477,FN,ACT,0.75	CHEMBL64788,FN,ACT,0.7599999904632568	CHEMBL1170027,TN,INACT,0.009999999776482582	CHEMBL556221,TP,ACT,1.0	CHEMBL1777827,TP,ACT,1.0	CHEMBL392401,TN,INACT,0.25	CHEMBL212645,TP,ACT,0.9700000286102295	CHEMBL2323445,TN,INACT,0.20999999344348907	CHEMBL354126,TN,INACT,0.20999999344348907	CHEMBL345971,TN,INACT,0.8700000047683716	CHEMBL324125,TN,INACT,0.15000000596046448	CHEMBL200401,TP,ACT,1.0	CHEMBL432144,TN,INACT,0.8299999833106995	CHEMBL124330,TP,ACT,0.9900000095367432	CHEMBL3325705,TN,INACT,0.3799999952316284	CHEMBL140984,TN,INACT,0.05999999865889549	CHEMBL2369493,TN,INACT,0.05999999865889549	CHEMBL37372,TP,ACT,0.9200000166893005	CHEMBL275104,TP,ACT,0.9900000095367432	CHEMBL71,TP,ACT,0.9900000095367432	CHEMBL3741290,TN,INACT,0.800000011920929	CHEMBL493677,TP,ACT,0.9599999785423279	CHEMBL1223631,TN,INACT,0.07000000029802322	CHEMBL73272,TN,INACT,0.25	CHEMBL257643,FN,ACT,0.8600000143051147	CHEMBL3618445,FN,ACT,0.3199999928474426	CHEMBL72408,TP,ACT,1.0	CHEMBL519609,TP,ACT,0.9399999976158142	CHEMBL1319362,FN,ACT,0.7900000214576721	CHEMBL76874,TN,INACT,0.6899999976158142	CHEMBL171411,TP,ACT,1.0	CHEMBL2436824,TN,INACT,0.019999999552965164	CHEMBL357983,TN,INACT,0.38999998569488525	CHEMBL140495,TN,INACT,0.38999998569488525	CHEMBL305313,TN,INACT,0.05000000074505806	CHEMBL3735797,TN,INACT,0.5	CHEMBL1779130,FN,ACT,0.8500000238418579	CHEMBL2426675,TP,ACT,1.0	CHEMBL421304,TP,ACT,1.0	CHEMBL222689,FN,ACT,0.6399999856948853	CHEMBL73234,TP,ACT,1.0	CHEMBL319231,TN,INACT,0.5899999737739563	CHEMBL1275791,TN,INACT,0.3199999928474426	CHEMBL106247,FN,ACT,0.8799999952316284	CHEMBL242345,TP,ACT,0.9900000095367432	CHEMBL106483,TN,INACT,0.4699999988079071	CHEMBL384248,TN,INACT,0.14000000059604645	CHEMBL600610,TN,INACT,0.2199999988079071	CHEMBL1223345,TN,INACT,0.6000000238418579	CHEMBL95032,TN,INACT,0.5099999904632568	CHEMBL355854,TP,ACT,1.0	CHEMBL85190,TP,ACT,1.0	CHEMBL1289758,FN,ACT,0.8999999761581421	CHEMBL334813,TN,INACT,0.5600000023841858	CHEMBL595265,TN,INACT,0.8899999856948853	CHEMBL380352,TP,ACT,0.9800000190734863	CHEMBL87302,TP,ACT,0.9900000095367432	

