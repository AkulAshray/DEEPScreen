ImageNetInceptionV2 CHEMBL2176813 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	207
Number of inactive compounds :	207
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2176813_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2176813_adam_0.0005_15_0.8/
---------------------------------
Training samples: 262
Validation samples: 83
--
Training Step: 1  | time: 76.478s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/262
[A[ATraining Step: 2  | total loss: [1m[32m0.74559[0m[0m | time: 92.305s
[2K
| Adam | epoch: 001 | loss: 0.74559 - acc: 0.3375 -- iter: 064/262
[A[ATraining Step: 3  | total loss: [1m[32m0.58041[0m[0m | time: 107.432s
[2K
| Adam | epoch: 001 | loss: 0.58041 - acc: 0.6750 -- iter: 096/262
[A[ATraining Step: 4  | total loss: [1m[32m0.56819[0m[0m | time: 122.944s
[2K
| Adam | epoch: 001 | loss: 0.56819 - acc: 0.7078 -- iter: 128/262
[A[ATraining Step: 5  | total loss: [1m[32m0.66768[0m[0m | time: 138.172s
[2K
| Adam | epoch: 001 | loss: 0.66768 - acc: 0.6938 -- iter: 160/262
[A[ATraining Step: 6  | total loss: [1m[32m0.43446[0m[0m | time: 155.177s
[2K
| Adam | epoch: 001 | loss: 0.43446 - acc: 0.8504 -- iter: 192/262
[A[ATraining Step: 7  | total loss: [1m[32m0.26730[0m[0m | time: 171.285s
[2K
| Adam | epoch: 001 | loss: 0.26730 - acc: 0.9214 -- iter: 224/262
[A[ATraining Step: 8  | total loss: [1m[32m0.23242[0m[0m | time: 187.110s
[2K
| Adam | epoch: 001 | loss: 0.23242 - acc: 0.9305 -- iter: 256/262
[A[ATraining Step: 9  | total loss: [1m[32m0.16603[0m[0m | time: 215.710s
[2K
| Adam | epoch: 001 | loss: 0.16603 - acc: 0.9507 | val_loss: 2.39090 - val_acc: 0.4578 -- iter: 262/262
--
Training Step: 10  | total loss: [1m[32m0.09253[0m[0m | time: 7.774s
[2K
| Adam | epoch: 002 | loss: 0.09253 - acc: 0.9754 -- iter: 032/262
[A[ATraining Step: 11  | total loss: [1m[32m0.05156[0m[0m | time: 50.128s
[2K
| Adam | epoch: 002 | loss: 0.05156 - acc: 0.9870 -- iter: 064/262
[A[ATraining Step: 12  | total loss: [1m[32m0.10204[0m[0m | time: 104.963s
[2K
| Adam | epoch: 002 | loss: 0.10204 - acc: 0.9788 -- iter: 096/262
[A[ATraining Step: 13  | total loss: [1m[32m0.26594[0m[0m | time: 163.515s
[2K
| Adam | epoch: 002 | loss: 0.26594 - acc: 0.9075 -- iter: 128/262
[A[ATraining Step: 14  | total loss: [1m[32m0.25797[0m[0m | time: 203.066s
[2K
| Adam | epoch: 002 | loss: 0.25797 - acc: 0.8942 -- iter: 160/262
[A[ATraining Step: 15  | total loss: [1m[32m0.18864[0m[0m | time: 223.725s
[2K
| Adam | epoch: 002 | loss: 0.18864 - acc: 0.9234 -- iter: 192/262
[A[ATraining Step: 16  | total loss: [1m[32m0.24036[0m[0m | time: 240.544s
[2K
| Adam | epoch: 002 | loss: 0.24036 - acc: 0.9170 -- iter: 224/262
[A[ATraining Step: 17  | total loss: [1m[32m0.21239[0m[0m | time: 258.354s
[2K
| Adam | epoch: 002 | loss: 0.21239 - acc: 0.9244 -- iter: 256/262
[A[ATraining Step: 18  | total loss: [1m[32m0.16642[0m[0m | time: 279.879s
[2K
| Adam | epoch: 002 | loss: 0.16642 - acc: 0.9505 | val_loss: 4.03847 - val_acc: 0.4578 -- iter: 262/262
--
Training Step: 19  | total loss: [1m[32m0.11790[0m[0m | time: 7.117s
[2K
| Adam | epoch: 003 | loss: 0.11790 - acc: 0.9670 -- iter: 032/262
[A[ATraining Step: 20  | total loss: [1m[32m0.10278[0m[0m | time: 13.476s
[2K
| Adam | epoch: 003 | loss: 0.10278 - acc: 0.9776 -- iter: 064/262
[A[ATraining Step: 21  | total loss: [1m[32m0.08327[0m[0m | time: 49.522s
[2K
| Adam | epoch: 003 | loss: 0.08327 - acc: 0.9846 -- iter: 096/262
[A[ATraining Step: 22  | total loss: [1m[32m0.06011[0m[0m | time: 74.373s
[2K
| Adam | epoch: 003 | loss: 0.06011 - acc: 0.9892 -- iter: 128/262
[A[ATraining Step: 23  | total loss: [1m[32m0.06916[0m[0m | time: 97.946s
[2K
| Adam | epoch: 003 | loss: 0.06916 - acc: 0.9742 -- iter: 160/262
[A[ATraining Step: 24  | total loss: [1m[32m0.05561[0m[0m | time: 118.051s
[2K
| Adam | epoch: 003 | loss: 0.05561 - acc: 0.9814 -- iter: 192/262
[A[ATraining Step: 25  | total loss: [1m[32m0.04284[0m[0m | time: 139.843s
[2K
| Adam | epoch: 003 | loss: 0.04284 - acc: 0.9865 -- iter: 224/262
[A[ATraining Step: 26  | total loss: [1m[32m0.03262[0m[0m | time: 160.119s
[2K
| Adam | epoch: 003 | loss: 0.03262 - acc: 0.9901 -- iter: 256/262
[A[ATraining Step: 27  | total loss: [1m[32m0.02874[0m[0m | time: 187.434s
[2K
| Adam | epoch: 003 | loss: 0.02874 - acc: 0.9926 | val_loss: 3.86764 - val_acc: 0.4578 -- iter: 262/262
--
Training Step: 28  | total loss: [1m[32m0.06984[0m[0m | time: 43.771s
[2K
| Adam | epoch: 004 | loss: 0.06984 - acc: 0.9867 -- iter: 032/262
[A[ATraining Step: 29  | total loss: [1m[32m0.05479[0m[0m | time: 50.311s
[2K
| Adam | epoch: 004 | loss: 0.05479 - acc: 0.9899 -- iter: 064/262
[A[ATraining Step: 30  | total loss: [1m[32m0.04963[0m[0m | time: 56.569s
[2K
| Adam | epoch: 004 | loss: 0.04963 - acc: 0.9923 -- iter: 096/262
[A[ATraining Step: 31  | total loss: [1m[32m0.03856[0m[0m | time: 91.656s
[2K
| Adam | epoch: 004 | loss: 0.03856 - acc: 0.9941 -- iter: 128/262
[A[ATraining Step: 32  | total loss: [1m[32m0.03272[0m[0m | time: 111.725s
[2K
| Adam | epoch: 004 | loss: 0.03272 - acc: 0.9954 -- iter: 160/262
[A[ATraining Step: 33  | total loss: [1m[32m0.03091[0m[0m | time: 136.039s
[2K
| Adam | epoch: 004 | loss: 0.03091 - acc: 0.9964 -- iter: 192/262
[A[ATraining Step: 34  | total loss: [1m[32m0.03185[0m[0m | time: 155.775s
[2K
| Adam | epoch: 004 | loss: 0.03185 - acc: 0.9905 -- iter: 224/262
[A[ATraining Step: 35  | total loss: [1m[32m0.04023[0m[0m | time: 175.585s
[2K
| Adam | epoch: 004 | loss: 0.04023 - acc: 0.9859 -- iter: 256/262
[A[ATraining Step: 36  | total loss: [1m[32m0.05494[0m[0m | time: 201.176s
[2K
| Adam | epoch: 004 | loss: 0.05494 - acc: 0.9824 | val_loss: 0.60314 - val_acc: 0.7590 -- iter: 262/262
--
Training Step: 37  | total loss: [1m[32m0.04566[0m[0m | time: 29.475s
[2K
| Adam | epoch: 005 | loss: 0.04566 - acc: 0.9859 -- iter: 032/262
[A[ATraining Step: 38  | total loss: [1m[32m0.37712[0m[0m | time: 67.955s
[2K
| Adam | epoch: 005 | loss: 0.37712 - acc: 0.9459 -- iter: 064/262
[A[ATraining Step: 39  | total loss: [1m[32m0.31031[0m[0m | time: 79.858s
[2K
| Adam | epoch: 005 | loss: 0.31031 - acc: 0.9563 -- iter: 096/262
[A[ATraining Step: 40  | total loss: [1m[32m0.33412[0m[0m | time: 86.436s
[2K
| Adam | epoch: 005 | loss: 0.33412 - acc: 0.9332 -- iter: 128/262
[A[ATraining Step: 41  | total loss: [1m[32m0.28254[0m[0m | time: 117.205s
[2K
| Adam | epoch: 005 | loss: 0.28254 - acc: 0.9455 -- iter: 160/262
[A[ATraining Step: 42  | total loss: [1m[32m0.29933[0m[0m | time: 149.729s
[2K
| Adam | epoch: 005 | loss: 0.29933 - acc: 0.9384 -- iter: 192/262
[A[ATraining Step: 43  | total loss: [1m[32m0.29977[0m[0m | time: 175.645s
[2K
| Adam | epoch: 005 | loss: 0.29977 - acc: 0.9327 -- iter: 224/262
[A[ATraining Step: 44  | total loss: [1m[32m0.26852[0m[0m | time: 192.010s
[2K
| Adam | epoch: 005 | loss: 0.26852 - acc: 0.9336 -- iter: 256/262
[A[ATraining Step: 45  | total loss: [1m[32m0.25019[0m[0m | time: 212.936s
[2K
| Adam | epoch: 005 | loss: 0.25019 - acc: 0.9342 | val_loss: 1.64918 - val_acc: 0.5422 -- iter: 262/262
--
Training Step: 46  | total loss: [1m[32m0.23716[0m[0m | time: 55.105s
[2K
| Adam | epoch: 006 | loss: 0.23716 - acc: 0.9400 -- iter: 032/262
[A[ATraining Step: 47  | total loss: [1m[32m0.22788[0m[0m | time: 115.271s
[2K
| Adam | epoch: 006 | loss: 0.22788 - acc: 0.9345 -- iter: 064/262
[A[ATraining Step: 48  | total loss: [1m[32m0.26573[0m[0m | time: 165.979s
[2K
| Adam | epoch: 006 | loss: 0.26573 - acc: 0.9249 -- iter: 096/262
[A[ATraining Step: 49  | total loss: [1m[32m0.23987[0m[0m | time: 171.757s
[2K
| Adam | epoch: 006 | loss: 0.23987 - acc: 0.9368 -- iter: 128/262
[A[ATraining Step: 50  | total loss: [1m[32m0.20801[0m[0m | time: 177.929s
[2K
| Adam | epoch: 006 | loss: 0.20801 - acc: 0.9466 -- iter: 160/262
[A[ATraining Step: 51  | total loss: [1m[32m0.18153[0m[0m | time: 213.550s
[2K
| Adam | epoch: 006 | loss: 0.18153 - acc: 0.9547 -- iter: 192/262
[A[ATraining Step: 52  | total loss: [1m[32m0.17436[0m[0m | time: 240.741s
[2K
| Adam | epoch: 006 | loss: 0.17436 - acc: 0.9568 -- iter: 224/262
[A[ATraining Step: 53  | total loss: [1m[32m0.15813[0m[0m | time: 258.050s
[2K
| Adam | epoch: 006 | loss: 0.15813 - acc: 0.9632 -- iter: 256/262
[A[ATraining Step: 54  | total loss: [1m[32m0.16243[0m[0m | time: 287.524s
[2K
| Adam | epoch: 006 | loss: 0.16243 - acc: 0.9504 | val_loss: 0.23242 - val_acc: 0.9157 -- iter: 262/262
--
Training Step: 55  | total loss: [1m[32m0.15148[0m[0m | time: 18.277s
[2K
| Adam | epoch: 007 | loss: 0.15148 - acc: 0.9530 -- iter: 032/262
[A[ATraining Step: 56  | total loss: [1m[32m0.14499[0m[0m | time: 37.337s
[2K
| Adam | epoch: 007 | loss: 0.14499 - acc: 0.9508 -- iter: 064/262
[A[ATraining Step: 57  | total loss: [1m[32m0.13787[0m[0m | time: 56.589s
[2K
| Adam | epoch: 007 | loss: 0.13787 - acc: 0.9576 -- iter: 096/262
[A[ATraining Step: 58  | total loss: [1m[32m0.19949[0m[0m | time: 77.484s
[2K
| Adam | epoch: 007 | loss: 0.19949 - acc: 0.9464 -- iter: 128/262
[A[ATraining Step: 59  | total loss: [1m[32m0.17616[0m[0m | time: 81.114s
[2K
| Adam | epoch: 007 | loss: 0.17616 - acc: 0.9536 -- iter: 160/262
[A[ATraining Step: 60  | total loss: [1m[32m0.16272[0m[0m | time: 85.167s
[2K
| Adam | epoch: 007 | loss: 0.16272 - acc: 0.9597 -- iter: 192/262
[A[ATraining Step: 61  | total loss: [1m[32m0.14695[0m[0m | time: 100.163s
[2K
| Adam | epoch: 007 | loss: 0.14695 - acc: 0.9650 -- iter: 224/262
[A[ATraining Step: 62  | total loss: [1m[32m0.15417[0m[0m | time: 114.865s
[2K
| Adam | epoch: 007 | loss: 0.15417 - acc: 0.9574 -- iter: 256/262
[A[ATraining Step: 63  | total loss: [1m[32m0.15566[0m[0m | time: 144.417s
[2K
| Adam | epoch: 007 | loss: 0.15566 - acc: 0.9509 | val_loss: 0.76034 - val_acc: 0.7108 -- iter: 262/262
--
Training Step: 64  | total loss: [1m[32m0.14342[0m[0m | time: 17.440s
[2K
| Adam | epoch: 008 | loss: 0.14342 - acc: 0.9532 -- iter: 032/262
[A[ATraining Step: 65  | total loss: [1m[32m0.13163[0m[0m | time: 32.073s
[2K
| Adam | epoch: 008 | loss: 0.13163 - acc: 0.9589 -- iter: 064/262
[A[ATraining Step: 66  | total loss: [1m[32m0.11835[0m[0m | time: 46.555s
[2K
| Adam | epoch: 008 | loss: 0.11835 - acc: 0.9639 -- iter: 096/262
[A[ATraining Step: 67  | total loss: [1m[32m0.10651[0m[0m | time: 64.486s
[2K
| Adam | epoch: 008 | loss: 0.10651 - acc: 0.9683 -- iter: 128/262
[A[ATraining Step: 68  | total loss: [1m[32m0.11205[0m[0m | time: 82.105s
[2K
| Adam | epoch: 008 | loss: 0.11205 - acc: 0.9683 -- iter: 160/262
[A[ATraining Step: 69  | total loss: [1m[32m0.10274[0m[0m | time: 86.314s
[2K
| Adam | epoch: 008 | loss: 0.10274 - acc: 0.9720 -- iter: 192/262
[A[ATraining Step: 70  | total loss: [1m[32m0.09146[0m[0m | time: 90.261s
[2K
| Adam | epoch: 008 | loss: 0.09146 - acc: 0.9752 -- iter: 224/262
[A[ATraining Step: 71  | total loss: [1m[32m0.08157[0m[0m | time: 104.434s
[2K
| Adam | epoch: 008 | loss: 0.08157 - acc: 0.9781 -- iter: 256/262
[A[ATraining Step: 72  | total loss: [1m[32m0.07655[0m[0m | time: 134.453s
[2K
| Adam | epoch: 008 | loss: 0.07655 - acc: 0.9805 | val_loss: 0.11065 - val_acc: 0.9518 -- iter: 262/262
--
Training Step: 73  | total loss: [1m[32m0.06979[0m[0m | time: 24.589s
[2K
| Adam | epoch: 009 | loss: 0.06979 - acc: 0.9827 -- iter: 032/262
[A[ATraining Step: 74  | total loss: [1m[32m0.06451[0m[0m | time: 47.699s
[2K
| Adam | epoch: 009 | loss: 0.06451 - acc: 0.9846 -- iter: 064/262
[A[ATraining Step: 75  | total loss: [1m[32m0.05999[0m[0m | time: 105.558s
[2K
| Adam | epoch: 009 | loss: 0.05999 - acc: 0.9863 -- iter: 096/262
[A[ATraining Step: 76  | total loss: [1m[32m0.05619[0m[0m | time: 129.486s
[2K
| Adam | epoch: 009 | loss: 0.05619 - acc: 0.9877 -- iter: 128/262
[A[ATraining Step: 77  | total loss: [1m[32m0.05344[0m[0m | time: 144.204s
[2K
| Adam | epoch: 009 | loss: 0.05344 - acc: 0.9890 -- iter: 160/262
[A[ATraining Step: 78  | total loss: [1m[32m0.06808[0m[0m | time: 158.692s
[2K
| Adam | epoch: 009 | loss: 0.06808 - acc: 0.9869 -- iter: 192/262
[A[ATraining Step: 79  | total loss: [1m[32m0.06161[0m[0m | time: 164.866s
[2K
| Adam | epoch: 009 | loss: 0.06161 - acc: 0.9883 -- iter: 224/262
[A[ATraining Step: 80  | total loss: [1m[32m0.05570[0m[0m | time: 170.498s
[2K
| Adam | epoch: 009 | loss: 0.05570 - acc: 0.9895 -- iter: 256/262
[A[ATraining Step: 81  | total loss: [1m[32m0.05037[0m[0m | time: 199.234s
[2K
| Adam | epoch: 009 | loss: 0.05037 - acc: 0.9905 | val_loss: 0.23852 - val_acc: 0.9036 -- iter: 262/262
--
Training Step: 82  | total loss: [1m[32m0.04567[0m[0m | time: 18.931s
[2K
| Adam | epoch: 010 | loss: 0.04567 - acc: 0.9915 -- iter: 032/262
[A[ATraining Step: 83  | total loss: [1m[32m0.04227[0m[0m | time: 37.814s
[2K
| Adam | epoch: 010 | loss: 0.04227 - acc: 0.9923 -- iter: 064/262
[A[ATraining Step: 84  | total loss: [1m[32m0.04823[0m[0m | time: 56.426s
[2K
| Adam | epoch: 010 | loss: 0.04823 - acc: 0.9868 -- iter: 096/262
[A[ATraining Step: 85  | total loss: [1m[32m0.04393[0m[0m | time: 76.469s
[2K
| Adam | epoch: 010 | loss: 0.04393 - acc: 0.9882 -- iter: 128/262
[A[ATraining Step: 86  | total loss: [1m[32m0.04015[0m[0m | time: 90.494s
[2K
| Adam | epoch: 010 | loss: 0.04015 - acc: 0.9893 -- iter: 160/262
[A[ATraining Step: 87  | total loss: [1m[32m0.03743[0m[0m | time: 106.032s
[2K
| Adam | epoch: 010 | loss: 0.03743 - acc: 0.9904 -- iter: 192/262
[A[ATraining Step: 88  | total loss: [1m[32m0.07058[0m[0m | time: 125.245s
[2K
| Adam | epoch: 010 | loss: 0.07058 - acc: 0.9851 -- iter: 224/262
[A[ATraining Step: 89  | total loss: [1m[32m0.06406[0m[0m | time: 130.917s
[2K
| Adam | epoch: 010 | loss: 0.06406 - acc: 0.9866 -- iter: 256/262
[A[ATraining Step: 90  | total loss: [1m[32m0.06062[0m[0m | time: 146.677s
[2K
| Adam | epoch: 010 | loss: 0.06062 - acc: 0.9879 | val_loss: 0.23051 - val_acc: 0.9036 -- iter: 262/262
--
Training Step: 91  | total loss: [1m[32m0.05564[0m[0m | time: 24.239s
[2K
| Adam | epoch: 011 | loss: 0.05564 - acc: 0.9892 -- iter: 032/262
[A[ATraining Step: 92  | total loss: [1m[32m0.05067[0m[0m | time: 45.474s
[2K
| Adam | epoch: 011 | loss: 0.05067 - acc: 0.9902 -- iter: 064/262
[A[ATraining Step: 93  | total loss: [1m[32m0.04725[0m[0m | time: 67.944s
[2K
| Adam | epoch: 011 | loss: 0.04725 - acc: 0.9912 -- iter: 096/262
[A[ATraining Step: 94  | total loss: [1m[32m0.04290[0m[0m | time: 88.994s
[2K
| Adam | epoch: 011 | loss: 0.04290 - acc: 0.9921 -- iter: 128/262
[A[ATraining Step: 95  | total loss: [1m[32m0.03883[0m[0m | time: 103.284s
[2K
| Adam | epoch: 011 | loss: 0.03883 - acc: 0.9929 -- iter: 160/262
[A[ATraining Step: 96  | total loss: [1m[32m0.03517[0m[0m | time: 118.248s
[2K
| Adam | epoch: 011 | loss: 0.03517 - acc: 0.9936 -- iter: 192/262
[A[ATraining Step: 97  | total loss: [1m[32m0.04525[0m[0m | time: 142.115s
[2K
| Adam | epoch: 011 | loss: 0.04525 - acc: 0.9911 -- iter: 224/262
[A[ATraining Step: 98  | total loss: [1m[32m0.04432[0m[0m | time: 164.875s
[2K
| Adam | epoch: 011 | loss: 0.04432 - acc: 0.9920 -- iter: 256/262
[A[ATraining Step: 99  | total loss: [1m[32m0.04046[0m[0m | time: 180.197s
[2K
| Adam | epoch: 011 | loss: 0.04046 - acc: 0.9928 | val_loss: 0.09127 - val_acc: 0.9639 -- iter: 262/262
--
Training Step: 100  | total loss: [1m[32m0.18652[0m[0m | time: 5.978s
[2K
| Adam | epoch: 012 | loss: 0.18652 - acc: 0.9435 -- iter: 032/262
[A[ATraining Step: 101  | total loss: [1m[32m0.21922[0m[0m | time: 24.750s
[2K
| Adam | epoch: 012 | loss: 0.21922 - acc: 0.9325 -- iter: 064/262
[A[ATraining Step: 102  | total loss: [1m[32m0.19804[0m[0m | time: 43.545s
[2K
| Adam | epoch: 012 | loss: 0.19804 - acc: 0.9393 -- iter: 096/262
[A[ATraining Step: 103  | total loss: [1m[32m0.17881[0m[0m | time: 57.840s
[2K
| Adam | epoch: 012 | loss: 0.17881 - acc: 0.9453 -- iter: 128/262
[A[ATraining Step: 104  | total loss: [1m[32m0.16546[0m[0m | time: 71.970s
[2K
| Adam | epoch: 012 | loss: 0.16546 - acc: 0.9508 -- iter: 160/262
[A[ATraining Step: 105  | total loss: [1m[32m0.15052[0m[0m | time: 94.503s
[2K
| Adam | epoch: 012 | loss: 0.15052 - acc: 0.9557 -- iter: 192/262
[A[ATraining Step: 106  | total loss: [1m[32m0.15428[0m[0m | time: 116.311s
[2K
| Adam | epoch: 012 | loss: 0.15428 - acc: 0.9539 -- iter: 224/262
[A[ATraining Step: 107  | total loss: [1m[32m0.14147[0m[0m | time: 138.577s
[2K
| Adam | epoch: 012 | loss: 0.14147 - acc: 0.9585 -- iter: 256/262
[A[ATraining Step: 108  | total loss: [1m[32m0.13897[0m[0m | time: 167.023s
[2K
| Adam | epoch: 012 | loss: 0.13897 - acc: 0.9595 | val_loss: 0.45020 - val_acc: 0.8554 -- iter: 262/262
--
Training Step: 109  | total loss: [1m[32m0.12554[0m[0m | time: 6.288s
[2K
| Adam | epoch: 013 | loss: 0.12554 - acc: 0.9636 -- iter: 032/262
[A[ATraining Step: 110  | total loss: [1m[32m0.14371[0m[0m | time: 11.996s
[2K
| Adam | epoch: 013 | loss: 0.14371 - acc: 0.9506 -- iter: 064/262
[A[ATraining Step: 111  | total loss: [1m[32m0.13651[0m[0m | time: 31.051s
[2K
| Adam | epoch: 013 | loss: 0.13651 - acc: 0.9555 -- iter: 096/262
[A[ATraining Step: 112  | total loss: [1m[32m0.13307[0m[0m | time: 44.705s
[2K
| Adam | epoch: 013 | loss: 0.13307 - acc: 0.9568 -- iter: 128/262
[A[ATraining Step: 113  | total loss: [1m[32m0.12320[0m[0m | time: 58.241s
[2K
| Adam | epoch: 013 | loss: 0.12320 - acc: 0.9580 -- iter: 160/262
[A[ATraining Step: 114  | total loss: [1m[32m0.11661[0m[0m | time: 95.904s
[2K
| Adam | epoch: 013 | loss: 0.11661 - acc: 0.9591 -- iter: 192/262
[A[ATraining Step: 115  | total loss: [1m[32m0.10672[0m[0m | time: 124.909s
[2K
| Adam | epoch: 013 | loss: 0.10672 - acc: 0.9632 -- iter: 224/262
[A[ATraining Step: 116  | total loss: [1m[32m0.09688[0m[0m | time: 143.400s
[2K
| Adam | epoch: 013 | loss: 0.09688 - acc: 0.9669 -- iter: 256/262
[A[ATraining Step: 117  | total loss: [1m[32m0.08930[0m[0m | time: 180.812s
[2K
| Adam | epoch: 013 | loss: 0.08930 - acc: 0.9702 | val_loss: 0.07929 - val_acc: 0.9759 -- iter: 262/262
--
Training Step: 118  | total loss: [1m[32m0.33995[0m[0m | time: 18.090s
[2K
| Adam | epoch: 014 | loss: 0.33995 - acc: 0.9388 -- iter: 032/262
[A[ATraining Step: 119  | total loss: [1m[32m0.30701[0m[0m | time: 22.157s
[2K
| Adam | epoch: 014 | loss: 0.30701 - acc: 0.9449 -- iter: 064/262
[A[ATraining Step: 120  | total loss: [1m[32m0.41052[0m[0m | time: 25.818s
[2K
| Adam | epoch: 014 | loss: 0.41052 - acc: 0.9004 -- iter: 096/262
[A[ATraining Step: 121  | total loss: [1m[32m0.43566[0m[0m | time: 39.934s
[2K
| Adam | epoch: 014 | loss: 0.43566 - acc: 0.8937 -- iter: 128/262
[A[ATraining Step: 122  | total loss: [1m[32m0.39367[0m[0m | time: 61.322s
[2K
| Adam | epoch: 014 | loss: 0.39367 - acc: 0.9043 -- iter: 160/262
[A[ATraining Step: 123  | total loss: [1m[32m0.35985[0m[0m | time: 80.538s
[2K
| Adam | epoch: 014 | loss: 0.35985 - acc: 0.9108 -- iter: 192/262
[A[ATraining Step: 124  | total loss: [1m[32m0.33915[0m[0m | time: 99.883s
[2K
| Adam | epoch: 014 | loss: 0.33915 - acc: 0.9103 -- iter: 224/262
[A[ATraining Step: 125  | total loss: [1m[32m0.32249[0m[0m | time: 118.826s
[2K
| Adam | epoch: 014 | loss: 0.32249 - acc: 0.9099 -- iter: 256/262
[A[ATraining Step: 126  | total loss: [1m[32m0.30506[0m[0m | time: 146.921s
[2K
| Adam | epoch: 014 | loss: 0.30506 - acc: 0.9127 | val_loss: 0.08937 - val_acc: 0.9759 -- iter: 262/262
--
Training Step: 127  | total loss: [1m[32m0.30899[0m[0m | time: 23.035s
[2K
| Adam | epoch: 015 | loss: 0.30899 - acc: 0.9058 -- iter: 032/262
[A[ATraining Step: 128  | total loss: [1m[32m0.31718[0m[0m | time: 36.341s
[2K
| Adam | epoch: 015 | loss: 0.31718 - acc: 0.9090 -- iter: 064/262
[A[ATraining Step: 129  | total loss: [1m[32m0.29153[0m[0m | time: 40.467s
[2K
| Adam | epoch: 015 | loss: 0.29153 - acc: 0.9181 -- iter: 096/262
[A[ATraining Step: 130  | total loss: [1m[32m0.27034[0m[0m | time: 45.501s
[2K
| Adam | epoch: 015 | loss: 0.27034 - acc: 0.9263 -- iter: 128/262
[A[ATraining Step: 131  | total loss: [1m[32m0.24844[0m[0m | time: 63.786s
[2K
| Adam | epoch: 015 | loss: 0.24844 - acc: 0.9336 -- iter: 160/262
[A[ATraining Step: 132  | total loss: [1m[32m0.23982[0m[0m | time: 83.064s
[2K
| Adam | epoch: 015 | loss: 0.23982 - acc: 0.9340 -- iter: 192/262
[A[ATraining Step: 133  | total loss: [1m[32m0.21922[0m[0m | time: 101.692s
[2K
| Adam | epoch: 015 | loss: 0.21922 - acc: 0.9406 -- iter: 224/262
[A[ATraining Step: 134  | total loss: [1m[32m0.20186[0m[0m | time: 119.829s
[2K
| Adam | epoch: 015 | loss: 0.20186 - acc: 0.9434 -- iter: 256/262
[A[ATraining Step: 135  | total loss: [1m[32m0.19024[0m[0m | time: 147.197s
[2K
| Adam | epoch: 015 | loss: 0.19024 - acc: 0.9460 | val_loss: 0.11381 - val_acc: 0.9639 -- iter: 262/262
--
Validation AUC:0.9929824561403509
Validation AUPRC:0.9931680161943319
Test AUC:1.0
Test AUPRC:1.0
BestTestF1Score	0.98	0.97	0.99	1.0	0.97	31	0	51	1	0.82
BestTestMCCScore	0.98	0.97	0.99	1.0	0.97	31	0	51	1	0.82
BestTestAccuracyScore	0.98	0.97	0.99	1.0	0.97	31	0	51	1	0.82
BestValidationF1Score	0.97	0.95	0.98	1.0	0.95	36	0	45	2	0.82
BestValidationMCC	0.97	0.95	0.98	1.0	0.95	36	0	45	2	0.82
BestValidationAccuracy	0.97	0.95	0.98	1.0	0.95	36	0	45	2	0.82
TestPredictions (Threshold:0.82)
CHEMBL172788,TN,INACT,0.03999999910593033	CHEMBL3641692,TP,ACT,0.9800000190734863	CHEMBL3702027,TP,ACT,0.9900000095367432	CHEMBL353502,TN,INACT,0.07999999821186066	CHEMBL296245,TN,INACT,0.029999999329447746	CHEMBL3109772,TN,INACT,0.019999999552965164	CHEMBL3641695,TP,ACT,0.9700000286102295	CHEMBL3701923,TP,ACT,0.949999988079071	CHEMBL3701979,TP,ACT,0.9900000095367432	CHEMBL3701985,TP,ACT,0.9700000286102295	CHEMBL298203,TN,INACT,0.4300000071525574	CHEMBL3701957,TP,ACT,1.0	CHEMBL322537,TN,INACT,0.019999999552965164	CHEMBL3702019,TP,ACT,0.9900000095367432	CHEMBL99331,TN,INACT,0.6499999761581421	CHEMBL297173,TN,INACT,0.20000000298023224	CHEMBL3701903,TP,ACT,0.9599999785423279	CHEMBL460470,TN,INACT,0.009999999776482582	CHEMBL462650,TN,INACT,0.4300000071525574	CHEMBL312266,TN,INACT,0.019999999552965164	CHEMBL3633656,TN,INACT,0.0	CHEMBL2113072,TN,INACT,0.33000001311302185	CHEMBL3701983,TP,ACT,0.9800000190734863	CHEMBL3639405,TP,ACT,0.9900000095367432	CHEMBL394642,TN,INACT,0.550000011920929	CHEMBL3641699,TP,ACT,0.9300000071525574	CHEMBL2042401,TN,INACT,0.029999999329447746	CHEMBL3633665,TN,INACT,0.019999999552965164	CHEMBL325935,TN,INACT,0.05000000074505806	CHEMBL148967,TN,INACT,0.019999999552965164	CHEMBL2111789,TN,INACT,0.009999999776482582	CHEMBL3641746,TP,ACT,0.9700000286102295	CHEMBL450463,TN,INACT,0.029999999329447746	CHEMBL112877,TN,INACT,0.009999999776482582	CHEMBL42360,TN,INACT,0.019999999552965164	CHEMBL3701920,TP,ACT,1.0	CHEMBL40986,TN,INACT,0.009999999776482582	CHEMBL3701918,TP,ACT,0.9900000095367432	CHEMBL3702011,TP,ACT,0.9900000095367432	CHEMBL1259241,TN,INACT,0.5	CHEMBL545363,TN,INACT,0.23999999463558197	CHEMBL3701944,TP,ACT,0.9900000095367432	CHEMBL408492,TN,INACT,0.009999999776482582	CHEMBL174463,TN,INACT,0.4000000059604645	CHEMBL461709,TN,INACT,0.009999999776482582	CHEMBL417358,TN,INACT,0.5699999928474426	CHEMBL3701972,TP,ACT,0.9900000095367432	CHEMBL435810,TN,INACT,0.07999999821186066	CHEMBL450729,TN,INACT,0.05000000074505806	CHEMBL3701960,TP,ACT,1.0	CHEMBL417712,TN,INACT,0.019999999552965164	CHEMBL3702014,TP,ACT,0.9900000095367432	CHEMBL322547,TN,INACT,0.019999999552965164	CHEMBL3701943,TP,ACT,0.9399999976158142	CHEMBL3701930,TP,ACT,0.9900000095367432	CHEMBL3641757,FN,ACT,0.6700000166893005	CHEMBL3641688,TP,ACT,1.0	CHEMBL3702003,TP,ACT,1.0	CHEMBL461088,TN,INACT,0.14000000059604645	CHEMBL319910,TN,INACT,0.0	CHEMBL429238,TN,INACT,0.23999999463558197	CHEMBL3701996,TP,ACT,0.9800000190734863	CHEMBL3701999,TP,ACT,0.9900000095367432	CHEMBL415879,TN,INACT,0.0	CHEMBL3702002,TP,ACT,1.0	CHEMBL293232,TN,INACT,0.019999999552965164	CHEMBL513277,TN,INACT,0.0	CHEMBL246585,TN,INACT,0.09000000357627869	CHEMBL1258999,TN,INACT,0.49000000953674316	CHEMBL593861,TN,INACT,0.0	CHEMBL3702016,TP,ACT,0.9900000095367432	CHEMBL536800,TN,INACT,0.2800000011920929	CHEMBL420359,TN,INACT,0.0	CHEMBL227378,TN,INACT,0.05999999865889549	CHEMBL320763,TN,INACT,0.019999999552965164	CHEMBL330003,TN,INACT,0.009999999776482582	CHEMBL44134,TN,INACT,0.009999999776482582	CHEMBL1076,TN,INACT,0.07999999821186066	CHEMBL3702010,TP,ACT,0.9900000095367432	CHEMBL40796,TN,INACT,0.009999999776482582	CHEMBL3641696,TP,ACT,0.9700000286102295	CHEMBL3701952,TP,ACT,1.0	CHEMBL21508,TN,INACT,0.019999999552965164	

