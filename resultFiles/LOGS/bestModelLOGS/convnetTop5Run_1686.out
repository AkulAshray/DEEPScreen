CNNModel CHEMBL4306 RMSprop 0.001 30 128 0 0.8 False True
Number of active compounds :	484
Number of inactive compounds :	323
---------------------------------
Run id: CNNModel_CHEMBL4306_RMSprop_0.001_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4306_RMSprop_0.001_30_128_0.8_True/
---------------------------------
Training samples: 461
Validation samples: 145
--
Training Step: 1  | time: 0.807s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/461
[A[ATraining Step: 2  | total loss: [1m[32m0.62386[0m[0m | time: 1.417s
[2K
| RMSProp | epoch: 001 | loss: 0.62386 - acc: 0.3937 -- iter: 064/461
[A[ATraining Step: 3  | total loss: [1m[32m0.68056[0m[0m | time: 2.019s
[2K
| RMSProp | epoch: 001 | loss: 0.68056 - acc: 0.4807 -- iter: 096/461
[A[ATraining Step: 4  | total loss: [1m[32m0.69025[0m[0m | time: 2.642s
[2K
| RMSProp | epoch: 001 | loss: 0.69025 - acc: 0.4014 -- iter: 128/461
[A[ATraining Step: 5  | total loss: [1m[32m0.69224[0m[0m | time: 3.245s
[2K
| RMSProp | epoch: 001 | loss: 0.69224 - acc: 0.3831 -- iter: 160/461
[A[ATraining Step: 6  | total loss: [1m[32m0.69275[0m[0m | time: 3.855s
[2K
| RMSProp | epoch: 001 | loss: 0.69275 - acc: 0.4783 -- iter: 192/461
[A[ATraining Step: 7  | total loss: [1m[32m0.69319[0m[0m | time: 4.448s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.3976 -- iter: 224/461
[A[ATraining Step: 8  | total loss: [1m[32m0.69299[0m[0m | time: 5.081s
[2K
| RMSProp | epoch: 001 | loss: 0.69299 - acc: 0.5431 -- iter: 256/461
[A[ATraining Step: 9  | total loss: [1m[32m0.69309[0m[0m | time: 5.699s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.4541 -- iter: 288/461
[A[ATraining Step: 10  | total loss: [1m[32m0.69307[0m[0m | time: 6.305s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5239 -- iter: 320/461
[A[ATraining Step: 11  | total loss: [1m[32m0.69291[0m[0m | time: 7.194s
[2K
| RMSProp | epoch: 001 | loss: 0.69291 - acc: 0.6014 -- iter: 352/461
[A[ATraining Step: 12  | total loss: [1m[32m0.69306[0m[0m | time: 8.067s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5276 -- iter: 384/461
[A[ATraining Step: 13  | total loss: [1m[32m0.69305[0m[0m | time: 8.678s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5560 -- iter: 416/461
[A[ATraining Step: 14  | total loss: [1m[32m0.69296[0m[0m | time: 9.292s
[2K
| RMSProp | epoch: 001 | loss: 0.69296 - acc: 0.6226 -- iter: 448/461
[A[ATraining Step: 15  | total loss: [1m[32m0.69311[0m[0m | time: 10.594s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5379 | val_loss: 0.69304 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 16  | total loss: [1m[32m0.69297[0m[0m | time: 0.291s
[2K
| RMSProp | epoch: 002 | loss: 0.69297 - acc: 0.5958 -- iter: 032/461
[A[ATraining Step: 17  | total loss: [1m[32m0.69279[0m[0m | time: 0.906s
[2K
| RMSProp | epoch: 002 | loss: 0.69279 - acc: 0.5752 -- iter: 064/461
[A[ATraining Step: 18  | total loss: [1m[32m0.69297[0m[0m | time: 1.517s
[2K
| RMSProp | epoch: 002 | loss: 0.69297 - acc: 0.5491 -- iter: 096/461
[A[ATraining Step: 19  | total loss: [1m[32m0.69293[0m[0m | time: 2.119s
[2K
| RMSProp | epoch: 002 | loss: 0.69293 - acc: 0.5744 -- iter: 128/461
[A[ATraining Step: 20  | total loss: [1m[32m0.69293[0m[0m | time: 2.759s
[2K
| RMSProp | epoch: 002 | loss: 0.69293 - acc: 0.5606 -- iter: 160/461
[A[ATraining Step: 21  | total loss: [1m[32m0.69285[0m[0m | time: 3.364s
[2K
| RMSProp | epoch: 002 | loss: 0.69285 - acc: 0.5709 -- iter: 192/461
[A[ATraining Step: 22  | total loss: [1m[32m0.69290[0m[0m | time: 3.969s
[2K
| RMSProp | epoch: 002 | loss: 0.69290 - acc: 0.5590 -- iter: 224/461
[A[ATraining Step: 23  | total loss: [1m[32m0.69296[0m[0m | time: 4.586s
[2K
| RMSProp | epoch: 002 | loss: 0.69296 - acc: 0.5691 -- iter: 256/461
[A[ATraining Step: 24  | total loss: [1m[32m0.69276[0m[0m | time: 5.194s
[2K
| RMSProp | epoch: 002 | loss: 0.69276 - acc: 0.5848 -- iter: 288/461
[A[ATraining Step: 25  | total loss: [1m[32m0.69296[0m[0m | time: 5.966s
[2K
| RMSProp | epoch: 002 | loss: 0.69296 - acc: 0.5446 -- iter: 320/461
[A[ATraining Step: 26  | total loss: [1m[32m0.69255[0m[0m | time: 6.598s
[2K
| RMSProp | epoch: 002 | loss: 0.69255 - acc: 0.5907 -- iter: 352/461
[A[ATraining Step: 27  | total loss: [1m[32m0.69280[0m[0m | time: 7.201s
[2K
| RMSProp | epoch: 002 | loss: 0.69280 - acc: 0.5513 -- iter: 384/461
[A[ATraining Step: 28  | total loss: [1m[32m0.69271[0m[0m | time: 7.812s
[2K
| RMSProp | epoch: 002 | loss: 0.69271 - acc: 0.5619 -- iter: 416/461
[A[ATraining Step: 29  | total loss: [1m[32m0.69274[0m[0m | time: 8.421s
[2K
| RMSProp | epoch: 002 | loss: 0.69274 - acc: 0.5621 -- iter: 448/461
[A[ATraining Step: 30  | total loss: [1m[32m0.69273[0m[0m | time: 10.030s
[2K
| RMSProp | epoch: 002 | loss: 0.69273 - acc: 0.5622 | val_loss: 0.69275 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 31  | total loss: [1m[32m0.69274[0m[0m | time: 0.278s
[2K
| RMSProp | epoch: 003 | loss: 0.69274 - acc: 0.5550 -- iter: 032/461
[A[ATraining Step: 32  | total loss: [1m[32m0.69224[0m[0m | time: 0.567s
[2K
| RMSProp | epoch: 003 | loss: 0.69224 - acc: 0.6032 -- iter: 064/461
[A[ATraining Step: 33  | total loss: [1m[32m0.69167[0m[0m | time: 1.165s
[2K
| RMSProp | epoch: 003 | loss: 0.69167 - acc: 0.6397 -- iter: 096/461
[A[ATraining Step: 34  | total loss: [1m[32m0.69195[0m[0m | time: 1.746s
[2K
| RMSProp | epoch: 003 | loss: 0.69195 - acc: 0.6097 -- iter: 128/461
[A[ATraining Step: 35  | total loss: [1m[32m0.69200[0m[0m | time: 2.369s
[2K
| RMSProp | epoch: 003 | loss: 0.69200 - acc: 0.5999 -- iter: 160/461
[A[ATraining Step: 36  | total loss: [1m[32m0.69243[0m[0m | time: 2.986s
[2K
| RMSProp | epoch: 003 | loss: 0.69243 - acc: 0.5666 -- iter: 192/461
[A[ATraining Step: 37  | total loss: [1m[32m0.69215[0m[0m | time: 3.612s
[2K
| RMSProp | epoch: 003 | loss: 0.69215 - acc: 0.5783 -- iter: 224/461
[A[ATraining Step: 38  | total loss: [1m[32m0.69170[0m[0m | time: 4.224s
[2K
| RMSProp | epoch: 003 | loss: 0.69170 - acc: 0.5997 -- iter: 256/461
[A[ATraining Step: 39  | total loss: [1m[32m0.69203[0m[0m | time: 4.840s
[2K
| RMSProp | epoch: 003 | loss: 0.69203 - acc: 0.5806 -- iter: 288/461
[A[ATraining Step: 40  | total loss: [1m[32m0.69253[0m[0m | time: 5.451s
[2K
| RMSProp | epoch: 003 | loss: 0.69253 - acc: 0.5538 -- iter: 320/461
[A[ATraining Step: 41  | total loss: [1m[32m0.69258[0m[0m | time: 6.076s
[2K
| RMSProp | epoch: 003 | loss: 0.69258 - acc: 0.5496 -- iter: 352/461
[A[ATraining Step: 42  | total loss: [1m[32m0.69223[0m[0m | time: 6.671s
[2K
| RMSProp | epoch: 003 | loss: 0.69223 - acc: 0.5632 -- iter: 384/461
[A[ATraining Step: 43  | total loss: [1m[32m0.69215[0m[0m | time: 7.285s
[2K
| RMSProp | epoch: 003 | loss: 0.69215 - acc: 0.5631 -- iter: 416/461
[A[ATraining Step: 44  | total loss: [1m[32m0.69152[0m[0m | time: 7.928s
[2K
| RMSProp | epoch: 003 | loss: 0.69152 - acc: 0.5900 -- iter: 448/461
[A[ATraining Step: 45  | total loss: [1m[32m0.69128[0m[0m | time: 9.528s
[2K
| RMSProp | epoch: 003 | loss: 0.69128 - acc: 0.5960 | val_loss: 0.69213 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 46  | total loss: [1m[32m0.69148[0m[0m | time: 0.626s
[2K
| RMSProp | epoch: 004 | loss: 0.69148 - acc: 0.5852 -- iter: 032/461
[A[ATraining Step: 47  | total loss: [1m[32m0.69187[0m[0m | time: 0.929s
[2K
| RMSProp | epoch: 004 | loss: 0.69187 - acc: 0.5661 -- iter: 064/461
[A[ATraining Step: 48  | total loss: [1m[32m0.69260[0m[0m | time: 1.203s
[2K
| RMSProp | epoch: 004 | loss: 0.69260 - acc: 0.5370 -- iter: 096/461
[A[ATraining Step: 49  | total loss: [1m[32m0.69315[0m[0m | time: 1.787s
[2K
| RMSProp | epoch: 004 | loss: 0.69315 - acc: 0.5129 -- iter: 128/461
[A[ATraining Step: 50  | total loss: [1m[32m0.69314[0m[0m | time: 2.449s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.5109 -- iter: 160/461
[A[ATraining Step: 51  | total loss: [1m[32m0.69275[0m[0m | time: 3.082s
[2K
| RMSProp | epoch: 004 | loss: 0.69275 - acc: 0.5283 -- iter: 192/461
[A[ATraining Step: 52  | total loss: [1m[32m0.69301[0m[0m | time: 3.675s
[2K
| RMSProp | epoch: 004 | loss: 0.69301 - acc: 0.5147 -- iter: 224/461
[A[ATraining Step: 53  | total loss: [1m[32m0.69251[0m[0m | time: 4.324s
[2K
| RMSProp | epoch: 004 | loss: 0.69251 - acc: 0.5356 -- iter: 256/461
[A[ATraining Step: 54  | total loss: [1m[32m0.69246[0m[0m | time: 4.937s
[2K
| RMSProp | epoch: 004 | loss: 0.69246 - acc: 0.5349 -- iter: 288/461
[A[ATraining Step: 55  | total loss: [1m[32m0.69244[0m[0m | time: 5.550s
[2K
| RMSProp | epoch: 004 | loss: 0.69244 - acc: 0.5344 -- iter: 320/461
[A[ATraining Step: 56  | total loss: [1m[32m0.69257[0m[0m | time: 6.154s
[2K
| RMSProp | epoch: 004 | loss: 0.69257 - acc: 0.5296 -- iter: 352/461
[A[ATraining Step: 57  | total loss: [1m[32m0.69238[0m[0m | time: 6.758s
[2K
| RMSProp | epoch: 004 | loss: 0.69238 - acc: 0.5341 -- iter: 384/461
[A[ATraining Step: 58  | total loss: [1m[32m0.69214[0m[0m | time: 7.372s
[2K
| RMSProp | epoch: 004 | loss: 0.69214 - acc: 0.5423 -- iter: 416/461
[A[ATraining Step: 59  | total loss: [1m[32m0.69117[0m[0m | time: 7.972s
[2K
| RMSProp | epoch: 004 | loss: 0.69117 - acc: 0.5702 -- iter: 448/461
[A[ATraining Step: 60  | total loss: [1m[32m0.69115[0m[0m | time: 9.584s
[2K
| RMSProp | epoch: 004 | loss: 0.69115 - acc: 0.5692 | val_loss: 0.69177 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 61  | total loss: [1m[32m0.69130[0m[0m | time: 0.644s
[2K
| RMSProp | epoch: 005 | loss: 0.69130 - acc: 0.5642 -- iter: 032/461
[A[ATraining Step: 62  | total loss: [1m[32m0.69124[0m[0m | time: 1.252s
[2K
| RMSProp | epoch: 005 | loss: 0.69124 - acc: 0.5640 -- iter: 064/461
[A[ATraining Step: 63  | total loss: [1m[32m0.69081[0m[0m | time: 1.527s
[2K
| RMSProp | epoch: 005 | loss: 0.69081 - acc: 0.5717 -- iter: 096/461
[A[ATraining Step: 64  | total loss: [1m[32m0.69090[0m[0m | time: 1.799s
[2K
| RMSProp | epoch: 005 | loss: 0.69090 - acc: 0.5676 -- iter: 128/461
[A[ATraining Step: 65  | total loss: [1m[32m0.69104[0m[0m | time: 2.406s
[2K
| RMSProp | epoch: 005 | loss: 0.69104 - acc: 0.5640 -- iter: 160/461
[A[ATraining Step: 66  | total loss: [1m[32m0.69119[0m[0m | time: 3.313s
[2K
| RMSProp | epoch: 005 | loss: 0.69119 - acc: 0.5600 -- iter: 192/461
[A[ATraining Step: 67  | total loss: [1m[32m0.69004[0m[0m | time: 3.923s
[2K
| RMSProp | epoch: 005 | loss: 0.69004 - acc: 0.5828 -- iter: 224/461
[A[ATraining Step: 68  | total loss: [1m[32m0.69047[0m[0m | time: 4.535s
[2K
| RMSProp | epoch: 005 | loss: 0.69047 - acc: 0.5730 -- iter: 256/461
[A[ATraining Step: 69  | total loss: [1m[32m0.69142[0m[0m | time: 5.146s
[2K
| RMSProp | epoch: 005 | loss: 0.69142 - acc: 0.5535 -- iter: 288/461
[A[ATraining Step: 70  | total loss: [1m[32m0.69111[0m[0m | time: 5.784s
[2K
| RMSProp | epoch: 005 | loss: 0.69111 - acc: 0.5581 -- iter: 320/461
[A[ATraining Step: 71  | total loss: [1m[32m0.69099[0m[0m | time: 6.420s
[2K
| RMSProp | epoch: 005 | loss: 0.69099 - acc: 0.5586 -- iter: 352/461
[A[ATraining Step: 72  | total loss: [1m[32m0.69008[0m[0m | time: 7.008s
[2K
| RMSProp | epoch: 005 | loss: 0.69008 - acc: 0.5731 -- iter: 384/461
[A[ATraining Step: 73  | total loss: [1m[32m0.69062[0m[0m | time: 7.633s
[2K
| RMSProp | epoch: 005 | loss: 0.69062 - acc: 0.5615 -- iter: 416/461
[A[ATraining Step: 74  | total loss: [1m[32m0.69056[0m[0m | time: 8.243s
[2K
| RMSProp | epoch: 005 | loss: 0.69056 - acc: 0.5616 -- iter: 448/461
[A[ATraining Step: 75  | total loss: [1m[32m0.69196[0m[0m | time: 9.851s
[2K
| RMSProp | epoch: 005 | loss: 0.69196 - acc: 0.5380 | val_loss: 0.69128 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 76  | total loss: [1m[32m0.69156[0m[0m | time: 0.630s
[2K
| RMSProp | epoch: 006 | loss: 0.69156 - acc: 0.5440 -- iter: 032/461
[A[ATraining Step: 77  | total loss: [1m[32m0.69059[0m[0m | time: 1.227s
[2K
| RMSProp | epoch: 006 | loss: 0.69059 - acc: 0.5592 -- iter: 064/461
[A[ATraining Step: 78  | total loss: [1m[32m0.69027[0m[0m | time: 1.850s
[2K
| RMSProp | epoch: 006 | loss: 0.69027 - acc: 0.5628 -- iter: 096/461
[A[ATraining Step: 79  | total loss: [1m[32m0.68973[0m[0m | time: 2.131s
[2K
| RMSProp | epoch: 006 | loss: 0.68973 - acc: 0.5692 -- iter: 128/461
[A[ATraining Step: 80  | total loss: [1m[32m0.69046[0m[0m | time: 2.407s
[2K
| RMSProp | epoch: 006 | loss: 0.69046 - acc: 0.5582 -- iter: 160/461
[A[ATraining Step: 81  | total loss: [1m[32m0.69104[0m[0m | time: 3.007s
[2K
| RMSProp | epoch: 006 | loss: 0.69104 - acc: 0.5484 -- iter: 192/461
[A[ATraining Step: 82  | total loss: [1m[32m0.69067[0m[0m | time: 3.629s
[2K
| RMSProp | epoch: 006 | loss: 0.69067 - acc: 0.5530 -- iter: 224/461
[A[ATraining Step: 83  | total loss: [1m[32m0.69077[0m[0m | time: 4.255s
[2K
| RMSProp | epoch: 006 | loss: 0.69077 - acc: 0.5508 -- iter: 256/461
[A[ATraining Step: 84  | total loss: [1m[32m0.69037[0m[0m | time: 4.851s
[2K
| RMSProp | epoch: 006 | loss: 0.69037 - acc: 0.5551 -- iter: 288/461
[A[ATraining Step: 85  | total loss: [1m[32m0.69117[0m[0m | time: 5.484s
[2K
| RMSProp | epoch: 006 | loss: 0.69117 - acc: 0.5433 -- iter: 320/461
[A[ATraining Step: 86  | total loss: [1m[32m0.69072[0m[0m | time: 6.094s
[2K
| RMSProp | epoch: 006 | loss: 0.69072 - acc: 0.5484 -- iter: 352/461
[A[ATraining Step: 87  | total loss: [1m[32m0.68982[0m[0m | time: 6.698s
[2K
| RMSProp | epoch: 006 | loss: 0.68982 - acc: 0.5592 -- iter: 384/461
[A[ATraining Step: 88  | total loss: [1m[32m0.68890[0m[0m | time: 7.308s
[2K
| RMSProp | epoch: 006 | loss: 0.68890 - acc: 0.5689 -- iter: 416/461
[A[ATraining Step: 89  | total loss: [1m[32m0.68852[0m[0m | time: 7.925s
[2K
| RMSProp | epoch: 006 | loss: 0.68852 - acc: 0.5714 -- iter: 448/461
[A[ATraining Step: 90  | total loss: [1m[32m0.68756[0m[0m | time: 9.648s
[2K
| RMSProp | epoch: 006 | loss: 0.68756 - acc: 0.5799 | val_loss: 0.69051 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 91  | total loss: [1m[32m0.68928[0m[0m | time: 0.597s
[2K
| RMSProp | epoch: 007 | loss: 0.68928 - acc: 0.5625 -- iter: 032/461
[A[ATraining Step: 92  | total loss: [1m[32m0.68856[0m[0m | time: 1.198s
[2K
| RMSProp | epoch: 007 | loss: 0.68856 - acc: 0.5687 -- iter: 064/461
[A[ATraining Step: 93  | total loss: [1m[32m0.68986[0m[0m | time: 1.817s
[2K
| RMSProp | epoch: 007 | loss: 0.68986 - acc: 0.5556 -- iter: 096/461
[A[ATraining Step: 94  | total loss: [1m[32m0.68999[0m[0m | time: 2.428s
[2K
| RMSProp | epoch: 007 | loss: 0.68999 - acc: 0.5532 -- iter: 128/461
[A[ATraining Step: 95  | total loss: [1m[32m0.68917[0m[0m | time: 2.714s
[2K
| RMSProp | epoch: 007 | loss: 0.68917 - acc: 0.5604 -- iter: 160/461
[A[ATraining Step: 96  | total loss: [1m[32m0.68847[0m[0m | time: 3.002s
[2K
| RMSProp | epoch: 007 | loss: 0.68847 - acc: 0.5659 -- iter: 192/461
[A[ATraining Step: 97  | total loss: [1m[32m0.68773[0m[0m | time: 3.609s
[2K
| RMSProp | epoch: 007 | loss: 0.68773 - acc: 0.5708 -- iter: 224/461
[A[ATraining Step: 98  | total loss: [1m[32m0.68647[0m[0m | time: 4.224s
[2K
| RMSProp | epoch: 007 | loss: 0.68647 - acc: 0.5794 -- iter: 256/461
[A[ATraining Step: 99  | total loss: [1m[32m0.68654[0m[0m | time: 4.833s
[2K
| RMSProp | epoch: 007 | loss: 0.68654 - acc: 0.5777 -- iter: 288/461
[A[ATraining Step: 100  | total loss: [1m[32m0.68739[0m[0m | time: 5.467s
[2K
| RMSProp | epoch: 007 | loss: 0.68739 - acc: 0.5699 -- iter: 320/461
[A[ATraining Step: 101  | total loss: [1m[32m0.68908[0m[0m | time: 6.101s
[2K
| RMSProp | epoch: 007 | loss: 0.68908 - acc: 0.5567 -- iter: 352/461
[A[ATraining Step: 102  | total loss: [1m[32m0.68929[0m[0m | time: 6.709s
[2K
| RMSProp | epoch: 007 | loss: 0.68929 - acc: 0.5541 -- iter: 384/461
[A[ATraining Step: 103  | total loss: [1m[32m0.68944[0m[0m | time: 7.325s
[2K
| RMSProp | epoch: 007 | loss: 0.68944 - acc: 0.5518 -- iter: 416/461
[A[ATraining Step: 104  | total loss: [1m[32m0.68921[0m[0m | time: 8.093s
[2K
| RMSProp | epoch: 007 | loss: 0.68921 - acc: 0.5529 -- iter: 448/461
[A[ATraining Step: 105  | total loss: [1m[32m0.68811[0m[0m | time: 9.732s
[2K
| RMSProp | epoch: 007 | loss: 0.68811 - acc: 0.5601 | val_loss: 0.69008 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 106  | total loss: [1m[32m0.68656[0m[0m | time: 0.604s
[2K
| RMSProp | epoch: 008 | loss: 0.68656 - acc: 0.5697 -- iter: 032/461
[A[ATraining Step: 107  | total loss: [1m[32m0.68648[0m[0m | time: 1.233s
[2K
| RMSProp | epoch: 008 | loss: 0.68648 - acc: 0.5690 -- iter: 064/461
[A[ATraining Step: 108  | total loss: [1m[32m0.68465[0m[0m | time: 1.840s
[2K
| RMSProp | epoch: 008 | loss: 0.68465 - acc: 0.5777 -- iter: 096/461
[A[ATraining Step: 109  | total loss: [1m[32m0.68468[0m[0m | time: 2.468s
[2K
| RMSProp | epoch: 008 | loss: 0.68468 - acc: 0.5762 -- iter: 128/461
[A[ATraining Step: 110  | total loss: [1m[32m0.68617[0m[0m | time: 3.086s
[2K
| RMSProp | epoch: 008 | loss: 0.68617 - acc: 0.5686 -- iter: 160/461
[A[ATraining Step: 111  | total loss: [1m[32m0.68673[0m[0m | time: 3.355s
[2K
| RMSProp | epoch: 008 | loss: 0.68673 - acc: 0.5649 -- iter: 192/461
[A[ATraining Step: 112  | total loss: [1m[32m0.68547[0m[0m | time: 3.631s
[2K
| RMSProp | epoch: 008 | loss: 0.68547 - acc: 0.5699 -- iter: 224/461
[A[ATraining Step: 113  | total loss: [1m[32m0.68409[0m[0m | time: 4.223s
[2K
| RMSProp | epoch: 008 | loss: 0.68409 - acc: 0.5745 -- iter: 256/461
[A[ATraining Step: 114  | total loss: [1m[32m0.67979[0m[0m | time: 4.830s
[2K
| RMSProp | epoch: 008 | loss: 0.67979 - acc: 0.5889 -- iter: 288/461
[A[ATraining Step: 115  | total loss: [1m[32m0.68572[0m[0m | time: 5.432s
[2K
| RMSProp | epoch: 008 | loss: 0.68572 - acc: 0.5769 -- iter: 320/461
[A[ATraining Step: 116  | total loss: [1m[32m0.68499[0m[0m | time: 6.039s
[2K
| RMSProp | epoch: 008 | loss: 0.68499 - acc: 0.5786 -- iter: 352/461
[A[ATraining Step: 117  | total loss: [1m[32m0.68580[0m[0m | time: 6.650s
[2K
| RMSProp | epoch: 008 | loss: 0.68580 - acc: 0.5738 -- iter: 384/461
[A[ATraining Step: 118  | total loss: [1m[32m0.68632[0m[0m | time: 7.242s
[2K
| RMSProp | epoch: 008 | loss: 0.68632 - acc: 0.5696 -- iter: 416/461
[A[ATraining Step: 119  | total loss: [1m[32m0.68499[0m[0m | time: 7.839s
[2K
| RMSProp | epoch: 008 | loss: 0.68499 - acc: 0.5751 -- iter: 448/461
[A[ATraining Step: 120  | total loss: [1m[32m0.68342[0m[0m | time: 9.544s
[2K
| RMSProp | epoch: 008 | loss: 0.68342 - acc: 0.5801 | val_loss: 0.69108 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 121  | total loss: [1m[32m0.68431[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 009 | loss: 0.68431 - acc: 0.5752 -- iter: 032/461
[A[ATraining Step: 122  | total loss: [1m[32m0.68417[0m[0m | time: 1.221s
[2K
| RMSProp | epoch: 009 | loss: 0.68417 - acc: 0.5739 -- iter: 064/461
[A[ATraining Step: 123  | total loss: [1m[32m0.68841[0m[0m | time: 1.823s
[2K
| RMSProp | epoch: 009 | loss: 0.68841 - acc: 0.5572 -- iter: 096/461
[A[ATraining Step: 124  | total loss: [1m[32m0.68732[0m[0m | time: 2.428s
[2K
| RMSProp | epoch: 009 | loss: 0.68732 - acc: 0.5640 -- iter: 128/461
[A[ATraining Step: 125  | total loss: [1m[32m0.68823[0m[0m | time: 3.037s
[2K
| RMSProp | epoch: 009 | loss: 0.68823 - acc: 0.5576 -- iter: 160/461
[A[ATraining Step: 126  | total loss: [1m[32m0.68649[0m[0m | time: 3.657s
[2K
| RMSProp | epoch: 009 | loss: 0.68649 - acc: 0.5674 -- iter: 192/461
[A[ATraining Step: 127  | total loss: [1m[32m0.68761[0m[0m | time: 3.931s
[2K
| RMSProp | epoch: 009 | loss: 0.68761 - acc: 0.5607 -- iter: 224/461
[A[ATraining Step: 128  | total loss: [1m[32m0.68926[0m[0m | time: 4.201s
[2K
| RMSProp | epoch: 009 | loss: 0.68926 - acc: 0.5508 -- iter: 256/461
[A[ATraining Step: 129  | total loss: [1m[32m0.69058[0m[0m | time: 4.857s
[2K
| RMSProp | epoch: 009 | loss: 0.69058 - acc: 0.5418 -- iter: 288/461
[A[ATraining Step: 130  | total loss: [1m[32m0.68985[0m[0m | time: 5.513s
[2K
| RMSProp | epoch: 009 | loss: 0.68985 - acc: 0.5470 -- iter: 320/461
[A[ATraining Step: 131  | total loss: [1m[32m0.68949[0m[0m | time: 6.117s
[2K
| RMSProp | epoch: 009 | loss: 0.68949 - acc: 0.5486 -- iter: 352/461
[A[ATraining Step: 132  | total loss: [1m[32m0.69100[0m[0m | time: 6.717s
[2K
| RMSProp | epoch: 009 | loss: 0.69100 - acc: 0.5375 -- iter: 384/461
[A[ATraining Step: 133  | total loss: [1m[32m0.69105[0m[0m | time: 7.318s
[2K
| RMSProp | epoch: 009 | loss: 0.69105 - acc: 0.5369 -- iter: 416/461
[A[ATraining Step: 134  | total loss: [1m[32m0.69029[0m[0m | time: 7.912s
[2K
| RMSProp | epoch: 009 | loss: 0.69029 - acc: 0.5425 -- iter: 448/461
[A[ATraining Step: 135  | total loss: [1m[32m0.68992[0m[0m | time: 9.714s
[2K
| RMSProp | epoch: 009 | loss: 0.68992 - acc: 0.5445 | val_loss: 0.68990 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 136  | total loss: [1m[32m0.69041[0m[0m | time: 0.635s
[2K
| RMSProp | epoch: 010 | loss: 0.69041 - acc: 0.5401 -- iter: 032/461
[A[ATraining Step: 137  | total loss: [1m[32m0.69046[0m[0m | time: 1.255s
[2K
| RMSProp | epoch: 010 | loss: 0.69046 - acc: 0.5392 -- iter: 064/461
[A[ATraining Step: 138  | total loss: [1m[32m0.68870[0m[0m | time: 1.867s
[2K
| RMSProp | epoch: 010 | loss: 0.68870 - acc: 0.5509 -- iter: 096/461
[A[ATraining Step: 139  | total loss: [1m[32m0.69161[0m[0m | time: 2.493s
[2K
| RMSProp | epoch: 010 | loss: 0.69161 - acc: 0.5364 -- iter: 128/461
[A[ATraining Step: 140  | total loss: [1m[32m0.69119[0m[0m | time: 3.099s
[2K
| RMSProp | epoch: 010 | loss: 0.69119 - acc: 0.5390 -- iter: 160/461
[A[ATraining Step: 141  | total loss: [1m[32m0.68912[0m[0m | time: 3.707s
[2K
| RMSProp | epoch: 010 | loss: 0.68912 - acc: 0.5539 -- iter: 192/461
[A[ATraining Step: 142  | total loss: [1m[32m0.68568[0m[0m | time: 4.303s
[2K
| RMSProp | epoch: 010 | loss: 0.68568 - acc: 0.5735 -- iter: 224/461
[A[ATraining Step: 143  | total loss: [1m[32m0.68567[0m[0m | time: 4.573s
[2K
| RMSProp | epoch: 010 | loss: 0.68567 - acc: 0.5724 -- iter: 256/461
[A[ATraining Step: 144  | total loss: [1m[32m0.69037[0m[0m | time: 4.858s
[2K
| RMSProp | epoch: 010 | loss: 0.69037 - acc: 0.5536 -- iter: 288/461
[A[ATraining Step: 145  | total loss: [1m[32m0.69250[0m[0m | time: 5.447s
[2K
| RMSProp | epoch: 010 | loss: 0.69250 - acc: 0.5367 -- iter: 320/461
[A[ATraining Step: 146  | total loss: [1m[32m0.69162[0m[0m | time: 6.045s
[2K
| RMSProp | epoch: 010 | loss: 0.69162 - acc: 0.5424 -- iter: 352/461
[A[ATraining Step: 147  | total loss: [1m[32m0.69041[0m[0m | time: 6.635s
[2K
| RMSProp | epoch: 010 | loss: 0.69041 - acc: 0.5507 -- iter: 384/461
[A[ATraining Step: 148  | total loss: [1m[32m0.69087[0m[0m | time: 7.293s
[2K
| RMSProp | epoch: 010 | loss: 0.69087 - acc: 0.5456 -- iter: 416/461
[A[ATraining Step: 149  | total loss: [1m[32m0.69084[0m[0m | time: 7.887s
[2K
| RMSProp | epoch: 010 | loss: 0.69084 - acc: 0.5442 -- iter: 448/461
[A[ATraining Step: 150  | total loss: [1m[32m0.69045[0m[0m | time: 9.505s
[2K
| RMSProp | epoch: 010 | loss: 0.69045 - acc: 0.5460 | val_loss: 0.69009 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 151  | total loss: [1m[32m0.69140[0m[0m | time: 0.637s
[2K
| RMSProp | epoch: 011 | loss: 0.69140 - acc: 0.5383 -- iter: 032/461
[A[ATraining Step: 152  | total loss: [1m[32m0.69099[0m[0m | time: 1.248s
[2K
| RMSProp | epoch: 011 | loss: 0.69099 - acc: 0.5407 -- iter: 064/461
[A[ATraining Step: 153  | total loss: [1m[32m0.69186[0m[0m | time: 1.856s
[2K
| RMSProp | epoch: 011 | loss: 0.69186 - acc: 0.5335 -- iter: 096/461
[A[ATraining Step: 154  | total loss: [1m[32m0.68995[0m[0m | time: 2.459s
[2K
| RMSProp | epoch: 011 | loss: 0.68995 - acc: 0.5489 -- iter: 128/461
[A[ATraining Step: 155  | total loss: [1m[32m0.69143[0m[0m | time: 3.055s
[2K
| RMSProp | epoch: 011 | loss: 0.69143 - acc: 0.5378 -- iter: 160/461
[A[ATraining Step: 156  | total loss: [1m[32m0.68939[0m[0m | time: 3.661s
[2K
| RMSProp | epoch: 011 | loss: 0.68939 - acc: 0.5527 -- iter: 192/461
[A[ATraining Step: 157  | total loss: [1m[32m0.68806[0m[0m | time: 4.258s
[2K
| RMSProp | epoch: 011 | loss: 0.68806 - acc: 0.5600 -- iter: 224/461
[A[ATraining Step: 158  | total loss: [1m[32m0.68671[0m[0m | time: 4.878s
[2K
| RMSProp | epoch: 011 | loss: 0.68671 - acc: 0.5665 -- iter: 256/461
[A[ATraining Step: 159  | total loss: [1m[32m0.68585[0m[0m | time: 5.155s
[2K
| RMSProp | epoch: 011 | loss: 0.68585 - acc: 0.5692 -- iter: 288/461
[A[ATraining Step: 160  | total loss: [1m[32m0.68630[0m[0m | time: 5.431s
[2K
| RMSProp | epoch: 011 | loss: 0.68630 - acc: 0.5661 -- iter: 320/461
[A[ATraining Step: 161  | total loss: [1m[32m0.68664[0m[0m | time: 6.030s
[2K
| RMSProp | epoch: 011 | loss: 0.68664 - acc: 0.5634 -- iter: 352/461
[A[ATraining Step: 162  | total loss: [1m[32m0.68583[0m[0m | time: 6.638s
[2K
| RMSProp | epoch: 011 | loss: 0.68583 - acc: 0.5664 -- iter: 384/461
[A[ATraining Step: 163  | total loss: [1m[32m0.68482[0m[0m | time: 7.241s
[2K
| RMSProp | epoch: 011 | loss: 0.68482 - acc: 0.5691 -- iter: 416/461
[A[ATraining Step: 164  | total loss: [1m[32m0.68234[0m[0m | time: 7.851s
[2K
| RMSProp | epoch: 011 | loss: 0.68234 - acc: 0.5747 -- iter: 448/461
[A[ATraining Step: 165  | total loss: [1m[32m0.69885[0m[0m | time: 9.469s
[2K
| RMSProp | epoch: 011 | loss: 0.69885 - acc: 0.5610 | val_loss: 0.69024 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 166  | total loss: [1m[32m0.69678[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 012 | loss: 0.69678 - acc: 0.5674 -- iter: 032/461
[A[ATraining Step: 167  | total loss: [1m[32m0.69825[0m[0m | time: 1.241s
[2K
| RMSProp | epoch: 012 | loss: 0.69825 - acc: 0.5513 -- iter: 064/461
[A[ATraining Step: 168  | total loss: [1m[32m0.69882[0m[0m | time: 1.841s
[2K
| RMSProp | epoch: 012 | loss: 0.69882 - acc: 0.5399 -- iter: 096/461
[A[ATraining Step: 169  | total loss: [1m[32m0.69766[0m[0m | time: 2.441s
[2K
| RMSProp | epoch: 012 | loss: 0.69766 - acc: 0.5422 -- iter: 128/461
[A[ATraining Step: 170  | total loss: [1m[32m0.69622[0m[0m | time: 3.037s
[2K
| RMSProp | epoch: 012 | loss: 0.69622 - acc: 0.5473 -- iter: 160/461
[A[ATraining Step: 171  | total loss: [1m[32m0.69488[0m[0m | time: 3.631s
[2K
| RMSProp | epoch: 012 | loss: 0.69488 - acc: 0.5520 -- iter: 192/461
[A[ATraining Step: 172  | total loss: [1m[32m0.69306[0m[0m | time: 4.238s
[2K
| RMSProp | epoch: 012 | loss: 0.69306 - acc: 0.5593 -- iter: 224/461
[A[ATraining Step: 173  | total loss: [1m[32m0.69032[0m[0m | time: 4.828s
[2K
| RMSProp | epoch: 012 | loss: 0.69032 - acc: 0.5721 -- iter: 256/461
[A[ATraining Step: 174  | total loss: [1m[32m0.69044[0m[0m | time: 5.415s
[2K
| RMSProp | epoch: 012 | loss: 0.69044 - acc: 0.5680 -- iter: 288/461
[A[ATraining Step: 175  | total loss: [1m[32m0.68935[0m[0m | time: 5.684s
[2K
| RMSProp | epoch: 012 | loss: 0.68935 - acc: 0.5706 -- iter: 320/461
[A[ATraining Step: 176  | total loss: [1m[32m0.68951[0m[0m | time: 5.954s
[2K
| RMSProp | epoch: 012 | loss: 0.68951 - acc: 0.5674 -- iter: 352/461
[A[ATraining Step: 177  | total loss: [1m[32m0.68961[0m[0m | time: 6.561s
[2K
| RMSProp | epoch: 012 | loss: 0.68961 - acc: 0.5645 -- iter: 384/461
[A[ATraining Step: 178  | total loss: [1m[32m0.68554[0m[0m | time: 7.162s
[2K
| RMSProp | epoch: 012 | loss: 0.68554 - acc: 0.5830 -- iter: 416/461
[A[ATraining Step: 179  | total loss: [1m[32m0.68675[0m[0m | time: 7.768s
[2K
| RMSProp | epoch: 012 | loss: 0.68675 - acc: 0.5779 -- iter: 448/461
[A[ATraining Step: 180  | total loss: [1m[32m0.68866[0m[0m | time: 9.381s
[2K
| RMSProp | epoch: 012 | loss: 0.68866 - acc: 0.5669 | val_loss: 0.69037 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 181  | total loss: [1m[32m0.68836[0m[0m | time: 0.601s
[2K
| RMSProp | epoch: 013 | loss: 0.68836 - acc: 0.5665 -- iter: 032/461
[A[ATraining Step: 182  | total loss: [1m[32m0.68820[0m[0m | time: 1.207s
[2K
| RMSProp | epoch: 013 | loss: 0.68820 - acc: 0.5661 -- iter: 064/461
[A[ATraining Step: 183  | total loss: [1m[32m0.68606[0m[0m | time: 1.806s
[2K
| RMSProp | epoch: 013 | loss: 0.68606 - acc: 0.5751 -- iter: 096/461
[A[ATraining Step: 184  | total loss: [1m[32m0.68377[0m[0m | time: 2.407s
[2K
| RMSProp | epoch: 013 | loss: 0.68377 - acc: 0.5832 -- iter: 128/461
[A[ATraining Step: 185  | total loss: [1m[32m0.68293[0m[0m | time: 3.009s
[2K
| RMSProp | epoch: 013 | loss: 0.68293 - acc: 0.5843 -- iter: 160/461
[A[ATraining Step: 186  | total loss: [1m[32m0.67754[0m[0m | time: 3.612s
[2K
| RMSProp | epoch: 013 | loss: 0.67754 - acc: 0.5977 -- iter: 192/461
[A[ATraining Step: 187  | total loss: [1m[32m0.70986[0m[0m | time: 4.210s
[2K
| RMSProp | epoch: 013 | loss: 0.70986 - acc: 0.5911 -- iter: 224/461
[A[ATraining Step: 188  | total loss: [1m[32m0.70821[0m[0m | time: 4.810s
[2K
| RMSProp | epoch: 013 | loss: 0.70821 - acc: 0.5851 -- iter: 256/461
[A[ATraining Step: 189  | total loss: [1m[32m0.71083[0m[0m | time: 5.418s
[2K
| RMSProp | epoch: 013 | loss: 0.71083 - acc: 0.5610 -- iter: 288/461
[A[ATraining Step: 190  | total loss: [1m[32m0.70942[0m[0m | time: 6.060s
[2K
| RMSProp | epoch: 013 | loss: 0.70942 - acc: 0.5549 -- iter: 320/461
[A[ATraining Step: 191  | total loss: [1m[32m0.70823[0m[0m | time: 6.359s
[2K
| RMSProp | epoch: 013 | loss: 0.70823 - acc: 0.5494 -- iter: 352/461
[A[ATraining Step: 192  | total loss: [1m[32m0.70528[0m[0m | time: 6.633s
[2K
| RMSProp | epoch: 013 | loss: 0.70528 - acc: 0.5560 -- iter: 384/461
[A[ATraining Step: 193  | total loss: [1m[32m0.70226[0m[0m | time: 7.230s
[2K
| RMSProp | epoch: 013 | loss: 0.70226 - acc: 0.5619 -- iter: 416/461
[A[ATraining Step: 194  | total loss: [1m[32m0.69984[0m[0m | time: 7.834s
[2K
| RMSProp | epoch: 013 | loss: 0.69984 - acc: 0.5651 -- iter: 448/461
[A[ATraining Step: 195  | total loss: [1m[32m0.70275[0m[0m | time: 9.455s
[2K
| RMSProp | epoch: 013 | loss: 0.70275 - acc: 0.5492 | val_loss: 0.69050 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 196  | total loss: [1m[32m0.69941[0m[0m | time: 0.607s
[2K
| RMSProp | epoch: 014 | loss: 0.69941 - acc: 0.5599 -- iter: 032/461
[A[ATraining Step: 197  | total loss: [1m[32m0.69876[0m[0m | time: 1.233s
[2K
| RMSProp | epoch: 014 | loss: 0.69876 - acc: 0.5571 -- iter: 064/461
[A[ATraining Step: 198  | total loss: [1m[32m0.69809[0m[0m | time: 1.851s
[2K
| RMSProp | epoch: 014 | loss: 0.69809 - acc: 0.5545 -- iter: 096/461
[A[ATraining Step: 199  | total loss: [1m[32m0.69459[0m[0m | time: 2.481s
[2K
| RMSProp | epoch: 014 | loss: 0.69459 - acc: 0.5678 -- iter: 128/461
[A[ATraining Step: 200  | total loss: [1m[32m0.69238[0m[0m | time: 4.086s
[2K
| RMSProp | epoch: 014 | loss: 0.69238 - acc: 0.5735 | val_loss: 0.69086 - val_acc: 0.5379 -- iter: 160/461
--
Training Step: 201  | total loss: [1m[32m0.69247[0m[0m | time: 4.693s
[2K
| RMSProp | epoch: 014 | loss: 0.69247 - acc: 0.5693 -- iter: 192/461
[A[ATraining Step: 202  | total loss: [1m[32m0.69377[0m[0m | time: 5.306s
[2K
| RMSProp | epoch: 014 | loss: 0.69377 - acc: 0.5592 -- iter: 224/461
[A[ATraining Step: 203  | total loss: [1m[32m0.69227[0m[0m | time: 5.996s
[2K
| RMSProp | epoch: 014 | loss: 0.69227 - acc: 0.5627 -- iter: 256/461
[A[ATraining Step: 204  | total loss: [1m[32m0.69293[0m[0m | time: 6.593s
[2K
| RMSProp | epoch: 014 | loss: 0.69293 - acc: 0.5564 -- iter: 288/461
[A[ATraining Step: 205  | total loss: [1m[32m0.69346[0m[0m | time: 7.208s
[2K
| RMSProp | epoch: 014 | loss: 0.69346 - acc: 0.5508 -- iter: 320/461
[A[ATraining Step: 206  | total loss: [1m[32m0.69149[0m[0m | time: 7.834s
[2K
| RMSProp | epoch: 014 | loss: 0.69149 - acc: 0.5582 -- iter: 352/461
[A[ATraining Step: 207  | total loss: [1m[32m0.68963[0m[0m | time: 8.106s
[2K
| RMSProp | epoch: 014 | loss: 0.68963 - acc: 0.5649 -- iter: 384/461
[A[ATraining Step: 208  | total loss: [1m[32m0.68429[0m[0m | time: 8.388s
[2K
| RMSProp | epoch: 014 | loss: 0.68429 - acc: 0.5853 -- iter: 416/461
[A[ATraining Step: 209  | total loss: [1m[32m0.67838[0m[0m | time: 8.996s
[2K
| RMSProp | epoch: 014 | loss: 0.67838 - acc: 0.6037 -- iter: 448/461
[A[ATraining Step: 210  | total loss: [1m[32m0.68373[0m[0m | time: 10.620s
[2K
| RMSProp | epoch: 014 | loss: 0.68373 - acc: 0.5902 | val_loss: 0.69261 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 211  | total loss: [1m[32m0.68211[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 015 | loss: 0.68211 - acc: 0.5937 -- iter: 032/461
[A[ATraining Step: 212  | total loss: [1m[32m0.68240[0m[0m | time: 1.215s
[2K
| RMSProp | epoch: 015 | loss: 0.68240 - acc: 0.5906 -- iter: 064/461
[A[ATraining Step: 213  | total loss: [1m[32m0.68729[0m[0m | time: 1.835s
[2K
| RMSProp | epoch: 015 | loss: 0.68729 - acc: 0.5721 -- iter: 096/461
[A[ATraining Step: 214  | total loss: [1m[32m0.68561[0m[0m | time: 2.416s
[2K
| RMSProp | epoch: 015 | loss: 0.68561 - acc: 0.5774 -- iter: 128/461
[A[ATraining Step: 215  | total loss: [1m[32m0.68391[0m[0m | time: 3.012s
[2K
| RMSProp | epoch: 015 | loss: 0.68391 - acc: 0.5822 -- iter: 160/461
[A[ATraining Step: 216  | total loss: [1m[32m0.68669[0m[0m | time: 3.614s
[2K
| RMSProp | epoch: 015 | loss: 0.68669 - acc: 0.5708 -- iter: 192/461
[A[ATraining Step: 217  | total loss: [1m[32m0.68659[0m[0m | time: 4.223s
[2K
| RMSProp | epoch: 015 | loss: 0.68659 - acc: 0.5700 -- iter: 224/461
[A[ATraining Step: 218  | total loss: [1m[32m0.68633[0m[0m | time: 4.829s
[2K
| RMSProp | epoch: 015 | loss: 0.68633 - acc: 0.5693 -- iter: 256/461
[A[ATraining Step: 219  | total loss: [1m[32m0.68771[0m[0m | time: 5.435s
[2K
| RMSProp | epoch: 015 | loss: 0.68771 - acc: 0.5623 -- iter: 288/461
[A[ATraining Step: 220  | total loss: [1m[32m0.68457[0m[0m | time: 6.091s
[2K
| RMSProp | epoch: 015 | loss: 0.68457 - acc: 0.5748 -- iter: 320/461
[A[ATraining Step: 221  | total loss: [1m[32m0.68375[0m[0m | time: 6.712s
[2K
| RMSProp | epoch: 015 | loss: 0.68375 - acc: 0.5767 -- iter: 352/461
[A[ATraining Step: 222  | total loss: [1m[32m0.68472[0m[0m | time: 7.322s
[2K
| RMSProp | epoch: 015 | loss: 0.68472 - acc: 0.5722 -- iter: 384/461
[A[ATraining Step: 223  | total loss: [1m[32m0.68395[0m[0m | time: 7.619s
[2K
| RMSProp | epoch: 015 | loss: 0.68395 - acc: 0.5743 -- iter: 416/461
[A[ATraining Step: 224  | total loss: [1m[32m0.67829[0m[0m | time: 7.895s
[2K
| RMSProp | epoch: 015 | loss: 0.67829 - acc: 0.5938 -- iter: 448/461
[A[ATraining Step: 225  | total loss: [1m[32m0.67096[0m[0m | time: 9.509s
[2K
| RMSProp | epoch: 015 | loss: 0.67096 - acc: 0.6114 | val_loss: 0.69385 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 226  | total loss: [1m[32m0.67368[0m[0m | time: 0.625s
[2K
| RMSProp | epoch: 016 | loss: 0.67368 - acc: 0.6096 -- iter: 032/461
[A[ATraining Step: 227  | total loss: [1m[32m0.67797[0m[0m | time: 1.232s
[2K
| RMSProp | epoch: 016 | loss: 0.67797 - acc: 0.5955 -- iter: 064/461
[A[ATraining Step: 228  | total loss: [1m[32m0.68144[0m[0m | time: 1.837s
[2K
| RMSProp | epoch: 016 | loss: 0.68144 - acc: 0.5828 -- iter: 096/461
[A[ATraining Step: 229  | total loss: [1m[32m0.67551[0m[0m | time: 2.454s
[2K
| RMSProp | epoch: 016 | loss: 0.67551 - acc: 0.6058 -- iter: 128/461
[A[ATraining Step: 230  | total loss: [1m[32m0.67645[0m[0m | time: 3.058s
[2K
| RMSProp | epoch: 016 | loss: 0.67645 - acc: 0.6015 -- iter: 160/461
[A[ATraining Step: 231  | total loss: [1m[32m0.67927[0m[0m | time: 3.665s
[2K
| RMSProp | epoch: 016 | loss: 0.67927 - acc: 0.5913 -- iter: 192/461
[A[ATraining Step: 232  | total loss: [1m[32m0.68084[0m[0m | time: 4.269s
[2K
| RMSProp | epoch: 016 | loss: 0.68084 - acc: 0.5853 -- iter: 224/461
[A[ATraining Step: 233  | total loss: [1m[32m0.68033[0m[0m | time: 5.066s
[2K
| RMSProp | epoch: 016 | loss: 0.68033 - acc: 0.5862 -- iter: 256/461
[A[ATraining Step: 234  | total loss: [1m[32m0.68624[0m[0m | time: 5.670s
[2K
| RMSProp | epoch: 016 | loss: 0.68624 - acc: 0.5650 -- iter: 288/461
[A[ATraining Step: 235  | total loss: [1m[32m0.68393[0m[0m | time: 6.279s
[2K
| RMSProp | epoch: 016 | loss: 0.68393 - acc: 0.5742 -- iter: 320/461
[A[ATraining Step: 236  | total loss: [1m[32m0.68477[0m[0m | time: 6.900s
[2K
| RMSProp | epoch: 016 | loss: 0.68477 - acc: 0.5699 -- iter: 352/461
[A[ATraining Step: 237  | total loss: [1m[32m0.68707[0m[0m | time: 7.504s
[2K
| RMSProp | epoch: 016 | loss: 0.68707 - acc: 0.5598 -- iter: 384/461
[A[ATraining Step: 238  | total loss: [1m[32m0.68478[0m[0m | time: 8.301s
[2K
| RMSProp | epoch: 016 | loss: 0.68478 - acc: 0.5694 -- iter: 416/461
[A[ATraining Step: 239  | total loss: [1m[32m0.68403[0m[0m | time: 8.579s
[2K
| RMSProp | epoch: 016 | loss: 0.68403 - acc: 0.5718 -- iter: 448/461
[A[ATraining Step: 240  | total loss: [1m[32m0.69068[0m[0m | time: 9.864s
[2K
| RMSProp | epoch: 016 | loss: 0.69068 - acc: 0.5454 | val_loss: 0.69021 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 241  | total loss: [1m[32m0.69541[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 017 | loss: 0.69541 - acc: 0.5217 -- iter: 032/461
[A[ATraining Step: 242  | total loss: [1m[32m0.69335[0m[0m | time: 1.234s
[2K
| RMSProp | epoch: 017 | loss: 0.69335 - acc: 0.5320 -- iter: 064/461
[A[ATraining Step: 243  | total loss: [1m[32m0.69261[0m[0m | time: 1.841s
[2K
| RMSProp | epoch: 017 | loss: 0.69261 - acc: 0.5350 -- iter: 096/461
[A[ATraining Step: 244  | total loss: [1m[32m0.69251[0m[0m | time: 2.439s
[2K
| RMSProp | epoch: 017 | loss: 0.69251 - acc: 0.5347 -- iter: 128/461
[A[ATraining Step: 245  | total loss: [1m[32m0.69296[0m[0m | time: 3.039s
[2K
| RMSProp | epoch: 017 | loss: 0.69296 - acc: 0.5312 -- iter: 160/461
[A[ATraining Step: 246  | total loss: [1m[32m0.69169[0m[0m | time: 3.643s
[2K
| RMSProp | epoch: 017 | loss: 0.69169 - acc: 0.5375 -- iter: 192/461
[A[ATraining Step: 247  | total loss: [1m[32m0.69226[0m[0m | time: 4.246s
[2K
| RMSProp | epoch: 017 | loss: 0.69226 - acc: 0.5337 -- iter: 224/461
[A[ATraining Step: 248  | total loss: [1m[32m0.69042[0m[0m | time: 4.855s
[2K
| RMSProp | epoch: 017 | loss: 0.69042 - acc: 0.5428 -- iter: 256/461
[A[ATraining Step: 249  | total loss: [1m[32m0.68858[0m[0m | time: 5.464s
[2K
| RMSProp | epoch: 017 | loss: 0.68858 - acc: 0.5511 -- iter: 288/461
[A[ATraining Step: 250  | total loss: [1m[32m0.68823[0m[0m | time: 6.071s
[2K
| RMSProp | epoch: 017 | loss: 0.68823 - acc: 0.5522 -- iter: 320/461
[A[ATraining Step: 251  | total loss: [1m[32m0.68787[0m[0m | time: 6.661s
[2K
| RMSProp | epoch: 017 | loss: 0.68787 - acc: 0.5532 -- iter: 352/461
[A[ATraining Step: 252  | total loss: [1m[32m0.68811[0m[0m | time: 7.263s
[2K
| RMSProp | epoch: 017 | loss: 0.68811 - acc: 0.5510 -- iter: 384/461
[A[ATraining Step: 253  | total loss: [1m[32m0.68764[0m[0m | time: 7.869s
[2K
| RMSProp | epoch: 017 | loss: 0.68764 - acc: 0.5522 -- iter: 416/461
[A[ATraining Step: 254  | total loss: [1m[32m0.68312[0m[0m | time: 8.502s
[2K
| RMSProp | epoch: 017 | loss: 0.68312 - acc: 0.5688 -- iter: 448/461
[A[ATraining Step: 255  | total loss: [1m[32m0.68885[0m[0m | time: 9.799s
[2K
| RMSProp | epoch: 017 | loss: 0.68885 - acc: 0.5620 | val_loss: 0.69004 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 256  | total loss: [1m[32m0.68578[0m[0m | time: 0.397s
[2K
| RMSProp | epoch: 018 | loss: 0.68578 - acc: 0.5750 -- iter: 032/461
[A[ATraining Step: 257  | total loss: [1m[32m0.68232[0m[0m | time: 0.997s
[2K
| RMSProp | epoch: 018 | loss: 0.68232 - acc: 0.5867 -- iter: 064/461
[A[ATraining Step: 258  | total loss: [1m[32m0.68709[0m[0m | time: 1.602s
[2K
| RMSProp | epoch: 018 | loss: 0.68709 - acc: 0.5687 -- iter: 096/461
[A[ATraining Step: 259  | total loss: [1m[32m0.68281[0m[0m | time: 2.207s
[2K
| RMSProp | epoch: 018 | loss: 0.68281 - acc: 0.5868 -- iter: 128/461
[A[ATraining Step: 260  | total loss: [1m[32m0.68113[0m[0m | time: 2.889s
[2K
| RMSProp | epoch: 018 | loss: 0.68113 - acc: 0.5906 -- iter: 160/461
[A[ATraining Step: 261  | total loss: [1m[32m0.68724[0m[0m | time: 3.482s
[2K
| RMSProp | epoch: 018 | loss: 0.68724 - acc: 0.5691 -- iter: 192/461
[A[ATraining Step: 262  | total loss: [1m[32m0.68398[0m[0m | time: 4.092s
[2K
| RMSProp | epoch: 018 | loss: 0.68398 - acc: 0.5809 -- iter: 224/461
[A[ATraining Step: 263  | total loss: [1m[32m0.68474[0m[0m | time: 4.728s
[2K
| RMSProp | epoch: 018 | loss: 0.68474 - acc: 0.5759 -- iter: 256/461
[A[ATraining Step: 264  | total loss: [1m[32m0.68218[0m[0m | time: 5.333s
[2K
| RMSProp | epoch: 018 | loss: 0.68218 - acc: 0.5840 -- iter: 288/461
[A[ATraining Step: 265  | total loss: [1m[32m0.68132[0m[0m | time: 5.950s
[2K
| RMSProp | epoch: 018 | loss: 0.68132 - acc: 0.5849 -- iter: 320/461
[A[ATraining Step: 266  | total loss: [1m[32m0.68035[0m[0m | time: 6.546s
[2K
| RMSProp | epoch: 018 | loss: 0.68035 - acc: 0.5858 -- iter: 352/461
[A[ATraining Step: 267  | total loss: [1m[32m0.67923[0m[0m | time: 7.151s
[2K
| RMSProp | epoch: 018 | loss: 0.67923 - acc: 0.5866 -- iter: 384/461
[A[ATraining Step: 268  | total loss: [1m[32m0.68234[0m[0m | time: 7.842s
[2K
| RMSProp | epoch: 018 | loss: 0.68234 - acc: 0.5748 -- iter: 416/461
[A[ATraining Step: 269  | total loss: [1m[32m0.68257[0m[0m | time: 8.454s
[2K
| RMSProp | epoch: 018 | loss: 0.68257 - acc: 0.5736 -- iter: 448/461
[A[ATraining Step: 270  | total loss: [1m[32m0.68447[0m[0m | time: 10.067s
[2K
| RMSProp | epoch: 018 | loss: 0.68447 - acc: 0.5631 | val_loss: 0.67972 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 271  | total loss: [1m[32m0.68428[0m[0m | time: 0.294s
[2K
| RMSProp | epoch: 019 | loss: 0.68428 - acc: 0.5599 -- iter: 032/461
[A[ATraining Step: 272  | total loss: [1m[32m0.68602[0m[0m | time: 0.567s
[2K
| RMSProp | epoch: 019 | loss: 0.68602 - acc: 0.5424 -- iter: 064/461
[A[ATraining Step: 273  | total loss: [1m[32m0.68596[0m[0m | time: 1.179s
[2K
| RMSProp | epoch: 019 | loss: 0.68596 - acc: 0.5728 -- iter: 096/461
[A[ATraining Step: 274  | total loss: [1m[32m0.68783[0m[0m | time: 1.782s
[2K
| RMSProp | epoch: 019 | loss: 0.68783 - acc: 0.5655 -- iter: 128/461
[A[ATraining Step: 275  | total loss: [1m[32m0.68424[0m[0m | time: 2.395s
[2K
| RMSProp | epoch: 019 | loss: 0.68424 - acc: 0.5777 -- iter: 160/461
[A[ATraining Step: 276  | total loss: [1m[32m0.68696[0m[0m | time: 3.012s
[2K
| RMSProp | epoch: 019 | loss: 0.68696 - acc: 0.5731 -- iter: 192/461
[A[ATraining Step: 277  | total loss: [1m[32m0.68515[0m[0m | time: 3.621s
[2K
| RMSProp | epoch: 019 | loss: 0.68515 - acc: 0.5751 -- iter: 224/461
[A[ATraining Step: 278  | total loss: [1m[32m0.68447[0m[0m | time: 4.224s
[2K
| RMSProp | epoch: 019 | loss: 0.68447 - acc: 0.5676 -- iter: 256/461
[A[ATraining Step: 279  | total loss: [1m[32m0.68034[0m[0m | time: 4.833s
[2K
| RMSProp | epoch: 019 | loss: 0.68034 - acc: 0.5858 -- iter: 288/461
[A[ATraining Step: 280  | total loss: [1m[32m0.69456[0m[0m | time: 5.428s
[2K
| RMSProp | epoch: 019 | loss: 0.69456 - acc: 0.5616 -- iter: 320/461
[A[ATraining Step: 281  | total loss: [1m[32m0.68849[0m[0m | time: 6.033s
[2K
| RMSProp | epoch: 019 | loss: 0.68849 - acc: 0.5680 -- iter: 352/461
[A[ATraining Step: 282  | total loss: [1m[32m0.69295[0m[0m | time: 6.632s
[2K
| RMSProp | epoch: 019 | loss: 0.69295 - acc: 0.5549 -- iter: 384/461
[A[ATraining Step: 283  | total loss: [1m[32m0.69197[0m[0m | time: 7.228s
[2K
| RMSProp | epoch: 019 | loss: 0.69197 - acc: 0.5557 -- iter: 416/461
[A[ATraining Step: 284  | total loss: [1m[32m0.68992[0m[0m | time: 7.827s
[2K
| RMSProp | epoch: 019 | loss: 0.68992 - acc: 0.5751 -- iter: 448/461
[A[ATraining Step: 285  | total loss: [1m[32m0.69025[0m[0m | time: 9.447s
[2K
| RMSProp | epoch: 019 | loss: 0.69025 - acc: 0.5676 | val_loss: 0.66163 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 286  | total loss: [1m[32m0.68715[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 020 | loss: 0.68715 - acc: 0.5733 -- iter: 032/461
[A[ATraining Step: 287  | total loss: [1m[32m0.68342[0m[0m | time: 0.895s
[2K
| RMSProp | epoch: 020 | loss: 0.68342 - acc: 0.5754 -- iter: 064/461
[A[ATraining Step: 288  | total loss: [1m[32m0.67774[0m[0m | time: 1.261s
[2K
| RMSProp | epoch: 020 | loss: 0.67774 - acc: 0.5871 -- iter: 096/461
[A[ATraining Step: 289  | total loss: [1m[32m0.66991[0m[0m | time: 1.862s
[2K
| RMSProp | epoch: 020 | loss: 0.66991 - acc: 0.5976 -- iter: 128/461
[A[ATraining Step: 290  | total loss: [1m[32m0.65753[0m[0m | time: 2.459s
[2K
| RMSProp | epoch: 020 | loss: 0.65753 - acc: 0.6128 -- iter: 160/461
[A[ATraining Step: 291  | total loss: [1m[32m0.68750[0m[0m | time: 3.061s
[2K
| RMSProp | epoch: 020 | loss: 0.68750 - acc: 0.5953 -- iter: 192/461
[A[ATraining Step: 292  | total loss: [1m[32m0.68407[0m[0m | time: 3.692s
[2K
| RMSProp | epoch: 020 | loss: 0.68407 - acc: 0.6014 -- iter: 224/461
[A[ATraining Step: 293  | total loss: [1m[32m0.68147[0m[0m | time: 4.290s
[2K
| RMSProp | epoch: 020 | loss: 0.68147 - acc: 0.5975 -- iter: 256/461
[A[ATraining Step: 294  | total loss: [1m[32m0.67714[0m[0m | time: 4.894s
[2K
| RMSProp | epoch: 020 | loss: 0.67714 - acc: 0.6096 -- iter: 288/461
[A[ATraining Step: 295  | total loss: [1m[32m0.67358[0m[0m | time: 5.495s
[2K
| RMSProp | epoch: 020 | loss: 0.67358 - acc: 0.6174 -- iter: 320/461
[A[ATraining Step: 296  | total loss: [1m[32m0.67289[0m[0m | time: 6.121s
[2K
| RMSProp | epoch: 020 | loss: 0.67289 - acc: 0.6151 -- iter: 352/461
[A[ATraining Step: 297  | total loss: [1m[32m0.67183[0m[0m | time: 6.724s
[2K
| RMSProp | epoch: 020 | loss: 0.67183 - acc: 0.6098 -- iter: 384/461
[A[ATraining Step: 298  | total loss: [1m[32m0.66734[0m[0m | time: 7.326s
[2K
| RMSProp | epoch: 020 | loss: 0.66734 - acc: 0.6176 -- iter: 416/461
[A[ATraining Step: 299  | total loss: [1m[32m0.66512[0m[0m | time: 7.931s
[2K
| RMSProp | epoch: 020 | loss: 0.66512 - acc: 0.6121 -- iter: 448/461
[A[ATraining Step: 300  | total loss: [1m[32m0.66217[0m[0m | time: 9.561s
[2K
| RMSProp | epoch: 020 | loss: 0.66217 - acc: 0.6196 | val_loss: 0.80161 - val_acc: 0.5379 -- iter: 461/461
--
Training Step: 301  | total loss: [1m[32m0.65150[0m[0m | time: 0.606s
[2K
| RMSProp | epoch: 021 | loss: 0.65150 - acc: 0.6358 -- iter: 032/461
[A[ATraining Step: 302  | total loss: [1m[32m0.66500[0m[0m | time: 1.220s
[2K
| RMSProp | epoch: 021 | loss: 0.66500 - acc: 0.6316 -- iter: 064/461
[A[ATraining Step: 303  | total loss: [1m[32m0.66468[0m[0m | time: 1.496s
[2K
| RMSProp | epoch: 021 | loss: 0.66468 - acc: 0.6340 -- iter: 096/461
[A[ATraining Step: 304  | total loss: [1m[32m0.66352[0m[0m | time: 1.768s
[2K
| RMSProp | epoch: 021 | loss: 0.66352 - acc: 0.6322 -- iter: 128/461
[A[ATraining Step: 305  | total loss: [1m[32m0.65661[0m[0m | time: 2.369s
[2K
| RMSProp | epoch: 021 | loss: 0.65661 - acc: 0.6382 -- iter: 160/461
[A[ATraining Step: 306  | total loss: [1m[32m0.65054[0m[0m | time: 2.974s
[2K
| RMSProp | epoch: 021 | loss: 0.65054 - acc: 0.6462 -- iter: 192/461
[A[ATraining Step: 307  | total loss: [1m[32m0.64863[0m[0m | time: 3.578s
[2K
| RMSProp | epoch: 021 | loss: 0.64863 - acc: 0.6441 -- iter: 224/461
[A[ATraining Step: 308  | total loss: [1m[32m0.65378[0m[0m | time: 4.190s
[2K
| RMSProp | epoch: 021 | loss: 0.65378 - acc: 0.6328 -- iter: 256/461
[A[ATraining Step: 309  | total loss: [1m[32m0.64734[0m[0m | time: 4.824s
[2K
| RMSProp | epoch: 021 | loss: 0.64734 - acc: 0.6570 -- iter: 288/461
[A[ATraining Step: 310  | total loss: [1m[32m0.64682[0m[0m | time: 5.418s
[2K
| RMSProp | epoch: 021 | loss: 0.64682 - acc: 0.6601 -- iter: 320/461
[A[ATraining Step: 311  | total loss: [1m[32m0.63874[0m[0m | time: 6.021s
[2K
| RMSProp | epoch: 021 | loss: 0.63874 - acc: 0.6691 -- iter: 352/461
[A[ATraining Step: 312  | total loss: [1m[32m0.63060[0m[0m | time: 6.639s
[2K
| RMSProp | epoch: 021 | loss: 0.63060 - acc: 0.6772 -- iter: 384/461
[A[ATraining Step: 313  | total loss: [1m[32m0.63316[0m[0m | time: 7.230s
[2K
| RMSProp | epoch: 021 | loss: 0.63316 - acc: 0.6688 -- iter: 416/461
[A[ATraining Step: 314  | total loss: [1m[32m0.64614[0m[0m | time: 7.837s
[2K
| RMSProp | epoch: 021 | loss: 0.64614 - acc: 0.6488 -- iter: 448/461
[A[ATraining Step: 315  | total loss: [1m[32m0.64696[0m[0m | time: 9.456s
[2K
| RMSProp | epoch: 021 | loss: 0.64696 - acc: 0.6371 | val_loss: 0.65785 - val_acc: 0.5862 -- iter: 461/461
--
Training Step: 316  | total loss: [1m[32m0.63781[0m[0m | time: 0.595s
[2K
| RMSProp | epoch: 022 | loss: 0.63781 - acc: 0.6546 -- iter: 032/461
[A[ATraining Step: 317  | total loss: [1m[32m0.63782[0m[0m | time: 1.188s
[2K
| RMSProp | epoch: 022 | loss: 0.63782 - acc: 0.6516 -- iter: 064/461
[A[ATraining Step: 318  | total loss: [1m[32m0.62823[0m[0m | time: 1.791s
[2K
| RMSProp | epoch: 022 | loss: 0.62823 - acc: 0.6646 -- iter: 096/461
[A[ATraining Step: 319  | total loss: [1m[32m0.63312[0m[0m | time: 2.086s
[2K
| RMSProp | epoch: 022 | loss: 0.63312 - acc: 0.6638 -- iter: 128/461
[A[ATraining Step: 320  | total loss: [1m[32m0.62844[0m[0m | time: 2.353s
[2K
| RMSProp | epoch: 022 | loss: 0.62844 - acc: 0.6666 -- iter: 160/461
[A[ATraining Step: 321  | total loss: [1m[32m0.61876[0m[0m | time: 3.087s
[2K
| RMSProp | epoch: 022 | loss: 0.61876 - acc: 0.6692 -- iter: 192/461
[A[ATraining Step: 322  | total loss: [1m[32m0.60914[0m[0m | time: 3.684s
[2K
| RMSProp | epoch: 022 | loss: 0.60914 - acc: 0.6773 -- iter: 224/461
[A[ATraining Step: 323  | total loss: [1m[32m0.60953[0m[0m | time: 4.297s
[2K
| RMSProp | epoch: 022 | loss: 0.60953 - acc: 0.6783 -- iter: 256/461
[A[ATraining Step: 324  | total loss: [1m[32m0.60824[0m[0m | time: 4.901s
[2K
| RMSProp | epoch: 022 | loss: 0.60824 - acc: 0.6792 -- iter: 288/461
[A[ATraining Step: 325  | total loss: [1m[32m0.60942[0m[0m | time: 5.503s
[2K
| RMSProp | epoch: 022 | loss: 0.60942 - acc: 0.6769 -- iter: 320/461
[A[ATraining Step: 326  | total loss: [1m[32m0.61078[0m[0m | time: 6.114s
[2K
| RMSProp | epoch: 022 | loss: 0.61078 - acc: 0.6780 -- iter: 352/461
[A[ATraining Step: 327  | total loss: [1m[32m0.60767[0m[0m | time: 6.789s
[2K
| RMSProp | epoch: 022 | loss: 0.60767 - acc: 0.6789 -- iter: 384/461
[A[ATraining Step: 328  | total loss: [1m[32m0.60103[0m[0m | time: 7.387s
[2K
| RMSProp | epoch: 022 | loss: 0.60103 - acc: 0.6829 -- iter: 416/461
[A[ATraining Step: 329  | total loss: [1m[32m0.60887[0m[0m | time: 8.010s
[2K
| RMSProp | epoch: 022 | loss: 0.60887 - acc: 0.6802 -- iter: 448/461
[A[ATraining Step: 330  | total loss: [1m[32m0.60242[0m[0m | time: 9.618s
[2K
| RMSProp | epoch: 022 | loss: 0.60242 - acc: 0.6810 | val_loss: 0.62636 - val_acc: 0.6276 -- iter: 461/461
--
Training Step: 331  | total loss: [1m[32m0.61243[0m[0m | time: 0.615s
[2K
| RMSProp | epoch: 023 | loss: 0.61243 - acc: 0.6754 -- iter: 032/461
[A[ATraining Step: 332  | total loss: [1m[32m0.61155[0m[0m | time: 1.218s
[2K
| RMSProp | epoch: 023 | loss: 0.61155 - acc: 0.6735 -- iter: 064/461
[A[ATraining Step: 333  | total loss: [1m[32m0.60383[0m[0m | time: 1.824s
[2K
| RMSProp | epoch: 023 | loss: 0.60383 - acc: 0.6874 -- iter: 096/461
[A[ATraining Step: 334  | total loss: [1m[32m0.58588[0m[0m | time: 2.431s
[2K
| RMSProp | epoch: 023 | loss: 0.58588 - acc: 0.7030 -- iter: 128/461
[A[ATraining Step: 335  | total loss: [1m[32m0.58633[0m[0m | time: 2.707s
[2K
| RMSProp | epoch: 023 | loss: 0.58633 - acc: 0.7046 -- iter: 160/461
[A[ATraining Step: 336  | total loss: [1m[32m0.61282[0m[0m | time: 2.995s
[2K
| RMSProp | epoch: 023 | loss: 0.61282 - acc: 0.6880 -- iter: 192/461
[A[ATraining Step: 337  | total loss: [1m[32m0.60491[0m[0m | time: 3.616s
[2K
| RMSProp | epoch: 023 | loss: 0.60491 - acc: 0.6961 -- iter: 224/461
[A[ATraining Step: 338  | total loss: [1m[32m0.59705[0m[0m | time: 4.214s
[2K
| RMSProp | epoch: 023 | loss: 0.59705 - acc: 0.7015 -- iter: 256/461
[A[ATraining Step: 339  | total loss: [1m[32m0.59375[0m[0m | time: 4.810s
[2K
| RMSProp | epoch: 023 | loss: 0.59375 - acc: 0.7001 -- iter: 288/461
[A[ATraining Step: 340  | total loss: [1m[32m0.59338[0m[0m | time: 5.436s
[2K
| RMSProp | epoch: 023 | loss: 0.59338 - acc: 0.6957 -- iter: 320/461
[A[ATraining Step: 341  | total loss: [1m[32m0.58629[0m[0m | time: 6.046s
[2K
| RMSProp | epoch: 023 | loss: 0.58629 - acc: 0.7011 -- iter: 352/461
[A[ATraining Step: 342  | total loss: [1m[32m0.59598[0m[0m | time: 6.818s
[2K
| RMSProp | epoch: 023 | loss: 0.59598 - acc: 0.6935 -- iter: 384/461
[A[ATraining Step: 343  | total loss: [1m[32m0.59025[0m[0m | time: 7.429s
[2K
| RMSProp | epoch: 023 | loss: 0.59025 - acc: 0.6992 -- iter: 416/461
[A[ATraining Step: 344  | total loss: [1m[32m0.58177[0m[0m | time: 8.027s
[2K
| RMSProp | epoch: 023 | loss: 0.58177 - acc: 0.7074 -- iter: 448/461
[A[ATraining Step: 345  | total loss: [1m[32m0.57360[0m[0m | time: 9.648s
[2K
| RMSProp | epoch: 023 | loss: 0.57360 - acc: 0.7179 | val_loss: 0.50051 - val_acc: 0.7655 -- iter: 461/461
--
Training Step: 346  | total loss: [1m[32m0.56724[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 024 | loss: 0.56724 - acc: 0.7180 -- iter: 032/461
[A[ATraining Step: 347  | total loss: [1m[32m0.55692[0m[0m | time: 1.236s
[2K
| RMSProp | epoch: 024 | loss: 0.55692 - acc: 0.7212 -- iter: 064/461
[A[ATraining Step: 348  | total loss: [1m[32m0.55533[0m[0m | time: 1.848s
[2K
| RMSProp | epoch: 024 | loss: 0.55533 - acc: 0.7178 -- iter: 096/461
[A[ATraining Step: 349  | total loss: [1m[32m0.55812[0m[0m | time: 2.474s
[2K
| RMSProp | epoch: 024 | loss: 0.55812 - acc: 0.7117 -- iter: 128/461
[A[ATraining Step: 350  | total loss: [1m[32m0.56578[0m[0m | time: 3.074s
[2K
| RMSProp | epoch: 024 | loss: 0.56578 - acc: 0.7030 -- iter: 160/461
[A[ATraining Step: 351  | total loss: [1m[32m0.55227[0m[0m | time: 3.343s
[2K
| RMSProp | epoch: 024 | loss: 0.55227 - acc: 0.7202 -- iter: 192/461
[A[ATraining Step: 352  | total loss: [1m[32m0.53621[0m[0m | time: 3.612s
[2K
| RMSProp | epoch: 024 | loss: 0.53621 - acc: 0.7328 -- iter: 224/461
[A[ATraining Step: 353  | total loss: [1m[32m0.51822[0m[0m | time: 4.235s
[2K
| RMSProp | epoch: 024 | loss: 0.51822 - acc: 0.7441 -- iter: 256/461
[A[ATraining Step: 354  | total loss: [1m[32m0.55743[0m[0m | time: 4.848s
[2K
| RMSProp | epoch: 024 | loss: 0.55743 - acc: 0.7166 -- iter: 288/461
[A[ATraining Step: 355  | total loss: [1m[32m0.55344[0m[0m | time: 5.453s
[2K
| RMSProp | epoch: 024 | loss: 0.55344 - acc: 0.7199 -- iter: 320/461
[A[ATraining Step: 356  | total loss: [1m[32m0.54510[0m[0m | time: 6.063s
[2K
| RMSProp | epoch: 024 | loss: 0.54510 - acc: 0.7323 -- iter: 352/461
[A[ATraining Step: 357  | total loss: [1m[32m0.52764[0m[0m | time: 6.677s
[2K
| RMSProp | epoch: 024 | loss: 0.52764 - acc: 0.7497 -- iter: 384/461
[A[ATraining Step: 358  | total loss: [1m[32m0.52753[0m[0m | time: 7.306s
[2K
| RMSProp | epoch: 024 | loss: 0.52753 - acc: 0.7497 -- iter: 416/461
[A[ATraining Step: 359  | total loss: [1m[32m0.53117[0m[0m | time: 7.908s
[2K
| RMSProp | epoch: 024 | loss: 0.53117 - acc: 0.7404 -- iter: 448/461
[A[ATraining Step: 360  | total loss: [1m[32m0.53709[0m[0m | time: 9.527s
[2K
| RMSProp | epoch: 024 | loss: 0.53709 - acc: 0.7382 | val_loss: 0.48777 - val_acc: 0.7724 -- iter: 461/461
--
Training Step: 361  | total loss: [1m[32m0.53911[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 025 | loss: 0.53911 - acc: 0.7394 -- iter: 032/461
[A[ATraining Step: 362  | total loss: [1m[32m0.53426[0m[0m | time: 1.249s
[2K
| RMSProp | epoch: 025 | loss: 0.53426 - acc: 0.7467 -- iter: 064/461
[A[ATraining Step: 363  | total loss: [1m[32m0.52444[0m[0m | time: 1.852s
[2K
| RMSProp | epoch: 025 | loss: 0.52444 - acc: 0.7502 -- iter: 096/461
[A[ATraining Step: 364  | total loss: [1m[32m0.52329[0m[0m | time: 2.479s
[2K
| RMSProp | epoch: 025 | loss: 0.52329 - acc: 0.7533 -- iter: 128/461
[A[ATraining Step: 365  | total loss: [1m[32m0.50200[0m[0m | time: 3.076s
[2K
| RMSProp | epoch: 025 | loss: 0.50200 - acc: 0.7717 -- iter: 160/461
[A[ATraining Step: 366  | total loss: [1m[32m0.52186[0m[0m | time: 3.703s
[2K
| RMSProp | epoch: 025 | loss: 0.52186 - acc: 0.7664 -- iter: 192/461
[A[ATraining Step: 367  | total loss: [1m[32m0.54488[0m[0m | time: 3.993s
[2K
| RMSProp | epoch: 025 | loss: 0.54488 - acc: 0.7429 -- iter: 224/461
[A[ATraining Step: 368  | total loss: [1m[32m0.55031[0m[0m | time: 4.276s
[2K
| RMSProp | epoch: 025 | loss: 0.55031 - acc: 0.7301 -- iter: 256/461
[A[ATraining Step: 369  | total loss: [1m[32m0.54844[0m[0m | time: 4.896s
[2K
| RMSProp | epoch: 025 | loss: 0.54844 - acc: 0.7340 -- iter: 288/461
[A[ATraining Step: 370  | total loss: [1m[32m0.54492[0m[0m | time: 5.687s
[2K
| RMSProp | epoch: 025 | loss: 0.54492 - acc: 0.7388 -- iter: 320/461
[A[ATraining Step: 371  | total loss: [1m[32m0.52978[0m[0m | time: 6.293s
[2K
| RMSProp | epoch: 025 | loss: 0.52978 - acc: 0.7524 -- iter: 352/461
[A[ATraining Step: 372  | total loss: [1m[32m0.51250[0m[0m | time: 7.063s
[2K
| RMSProp | epoch: 025 | loss: 0.51250 - acc: 0.7615 -- iter: 384/461
[A[ATraining Step: 373  | total loss: [1m[32m0.49654[0m[0m | time: 7.672s
[2K
| RMSProp | epoch: 025 | loss: 0.49654 - acc: 0.7697 -- iter: 416/461
[A[ATraining Step: 374  | total loss: [1m[32m0.48759[0m[0m | time: 8.297s
[2K
| RMSProp | epoch: 025 | loss: 0.48759 - acc: 0.7771 -- iter: 448/461
[A[ATraining Step: 375  | total loss: [1m[32m0.50962[0m[0m | time: 9.922s
[2K
| RMSProp | epoch: 025 | loss: 0.50962 - acc: 0.7619 | val_loss: 0.62027 - val_acc: 0.7034 -- iter: 461/461
--
Training Step: 376  | total loss: [1m[32m0.55385[0m[0m | time: 0.610s
[2K
| RMSProp | epoch: 026 | loss: 0.55385 - acc: 0.7232 -- iter: 032/461
[A[ATraining Step: 377  | total loss: [1m[32m0.55901[0m[0m | time: 1.231s
[2K
| RMSProp | epoch: 026 | loss: 0.55901 - acc: 0.7134 -- iter: 064/461
[A[ATraining Step: 378  | total loss: [1m[32m0.55021[0m[0m | time: 1.839s
[2K
| RMSProp | epoch: 026 | loss: 0.55021 - acc: 0.7296 -- iter: 096/461
[A[ATraining Step: 379  | total loss: [1m[32m0.53439[0m[0m | time: 2.453s
[2K
| RMSProp | epoch: 026 | loss: 0.53439 - acc: 0.7441 -- iter: 128/461
[A[ATraining Step: 380  | total loss: [1m[32m0.51166[0m[0m | time: 3.058s
[2K
| RMSProp | epoch: 026 | loss: 0.51166 - acc: 0.7603 -- iter: 160/461
[A[ATraining Step: 381  | total loss: [1m[32m0.48714[0m[0m | time: 3.657s
[2K
| RMSProp | epoch: 026 | loss: 0.48714 - acc: 0.7749 -- iter: 192/461
[A[ATraining Step: 382  | total loss: [1m[32m0.46497[0m[0m | time: 4.258s
[2K
| RMSProp | epoch: 026 | loss: 0.46497 - acc: 0.7849 -- iter: 224/461
[A[ATraining Step: 383  | total loss: [1m[32m0.46007[0m[0m | time: 4.535s
[2K
| RMSProp | epoch: 026 | loss: 0.46007 - acc: 0.7908 -- iter: 256/461
[A[ATraining Step: 384  | total loss: [1m[32m0.48547[0m[0m | time: 4.806s
[2K
| RMSProp | epoch: 026 | loss: 0.48547 - acc: 0.7733 -- iter: 288/461
[A[ATraining Step: 385  | total loss: [1m[32m0.47280[0m[0m | time: 5.404s
[2K
| RMSProp | epoch: 026 | loss: 0.47280 - acc: 0.7882 -- iter: 320/461
[A[ATraining Step: 386  | total loss: [1m[32m0.45974[0m[0m | time: 6.001s
[2K
| RMSProp | epoch: 026 | loss: 0.45974 - acc: 0.8000 -- iter: 352/461
[A[ATraining Step: 387  | total loss: [1m[32m0.44133[0m[0m | time: 6.616s
[2K
| RMSProp | epoch: 026 | loss: 0.44133 - acc: 0.8107 -- iter: 384/461
[A[ATraining Step: 388  | total loss: [1m[32m0.42665[0m[0m | time: 7.317s
[2K
| RMSProp | epoch: 026 | loss: 0.42665 - acc: 0.8109 -- iter: 416/461
[A[ATraining Step: 389  | total loss: [1m[32m0.44106[0m[0m | time: 7.946s
[2K
| RMSProp | epoch: 026 | loss: 0.44106 - acc: 0.8016 -- iter: 448/461
[A[ATraining Step: 390  | total loss: [1m[32m0.42573[0m[0m | time: 9.556s
[2K
| RMSProp | epoch: 026 | loss: 0.42573 - acc: 0.8152 | val_loss: 0.41574 - val_acc: 0.8276 -- iter: 461/461
--
Training Step: 391  | total loss: [1m[32m0.41903[0m[0m | time: 0.639s
[2K
| RMSProp | epoch: 027 | loss: 0.41903 - acc: 0.8181 -- iter: 032/461
[A[ATraining Step: 392  | total loss: [1m[32m0.40754[0m[0m | time: 1.250s
[2K
| RMSProp | epoch: 027 | loss: 0.40754 - acc: 0.8269 -- iter: 064/461
[A[ATraining Step: 393  | total loss: [1m[32m0.38743[0m[0m | time: 1.852s
[2K
| RMSProp | epoch: 027 | loss: 0.38743 - acc: 0.8348 -- iter: 096/461
[A[ATraining Step: 394  | total loss: [1m[32m0.37478[0m[0m | time: 2.460s
[2K
| RMSProp | epoch: 027 | loss: 0.37478 - acc: 0.8451 -- iter: 128/461
[A[ATraining Step: 395  | total loss: [1m[32m0.37281[0m[0m | time: 3.065s
[2K
| RMSProp | epoch: 027 | loss: 0.37281 - acc: 0.8481 -- iter: 160/461
[A[ATraining Step: 396  | total loss: [1m[32m0.36334[0m[0m | time: 3.670s
[2K
| RMSProp | epoch: 027 | loss: 0.36334 - acc: 0.8539 -- iter: 192/461
[A[ATraining Step: 397  | total loss: [1m[32m0.35310[0m[0m | time: 4.263s
[2K
| RMSProp | epoch: 027 | loss: 0.35310 - acc: 0.8591 -- iter: 224/461
[A[ATraining Step: 398  | total loss: [1m[32m0.34987[0m[0m | time: 4.869s
[2K
| RMSProp | epoch: 027 | loss: 0.34987 - acc: 0.8639 -- iter: 256/461
[A[ATraining Step: 399  | total loss: [1m[32m0.33747[0m[0m | time: 5.140s
[2K
| RMSProp | epoch: 027 | loss: 0.33747 - acc: 0.8681 -- iter: 288/461
[A[ATraining Step: 400  | total loss: [1m[32m0.30859[0m[0m | time: 6.421s
[2K
| RMSProp | epoch: 027 | loss: 0.30859 - acc: 0.8813 | val_loss: 0.46067 - val_acc: 0.8345 -- iter: 320/461
--
Training Step: 401  | total loss: [1m[32m0.27987[0m[0m | time: 7.063s
[2K
| RMSProp | epoch: 027 | loss: 0.27987 - acc: 0.8932 -- iter: 352/461
[A[ATraining Step: 402  | total loss: [1m[32m0.26705[0m[0m | time: 7.668s
[2K
| RMSProp | epoch: 027 | loss: 0.26705 - acc: 0.8976 -- iter: 384/461
[A[ATraining Step: 403  | total loss: [1m[32m0.26845[0m[0m | time: 8.280s
[2K
| RMSProp | epoch: 027 | loss: 0.26845 - acc: 0.8985 -- iter: 416/461
[A[ATraining Step: 404  | total loss: [1m[32m0.35876[0m[0m | time: 8.914s
[2K
| RMSProp | epoch: 027 | loss: 0.35876 - acc: 0.8586 -- iter: 448/461
[A[ATraining Step: 405  | total loss: [1m[32m0.35108[0m[0m | time: 10.531s
[2K
| RMSProp | epoch: 027 | loss: 0.35108 - acc: 0.8696 | val_loss: 0.56786 - val_acc: 0.7448 -- iter: 461/461
--
Training Step: 406  | total loss: [1m[32m0.35050[0m[0m | time: 0.611s
[2K
| RMSProp | epoch: 028 | loss: 0.35050 - acc: 0.8670 -- iter: 032/461
[A[ATraining Step: 407  | total loss: [1m[32m0.35144[0m[0m | time: 1.255s
[2K
| RMSProp | epoch: 028 | loss: 0.35144 - acc: 0.8647 -- iter: 064/461
[A[ATraining Step: 408  | total loss: [1m[32m0.35093[0m[0m | time: 1.862s
[2K
| RMSProp | epoch: 028 | loss: 0.35093 - acc: 0.8595 -- iter: 096/461
[A[ATraining Step: 409  | total loss: [1m[32m0.34147[0m[0m | time: 2.482s
[2K
| RMSProp | epoch: 028 | loss: 0.34147 - acc: 0.8673 -- iter: 128/461
[A[ATraining Step: 410  | total loss: [1m[32m0.32936[0m[0m | time: 3.113s
[2K
| RMSProp | epoch: 028 | loss: 0.32936 - acc: 0.8712 -- iter: 160/461
[A[ATraining Step: 411  | total loss: [1m[32m0.30383[0m[0m | time: 3.726s
[2K
| RMSProp | epoch: 028 | loss: 0.30383 - acc: 0.8841 -- iter: 192/461
[A[ATraining Step: 412  | total loss: [1m[32m0.28791[0m[0m | time: 4.330s
[2K
| RMSProp | epoch: 028 | loss: 0.28791 - acc: 0.8863 -- iter: 224/461
[A[ATraining Step: 413  | total loss: [1m[32m0.37370[0m[0m | time: 4.927s
[2K
| RMSProp | epoch: 028 | loss: 0.37370 - acc: 0.8539 -- iter: 256/461
[A[ATraining Step: 414  | total loss: [1m[32m0.36934[0m[0m | time: 5.550s
[2K
| RMSProp | epoch: 028 | loss: 0.36934 - acc: 0.8623 -- iter: 288/461
[A[ATraining Step: 415  | total loss: [1m[32m0.35641[0m[0m | time: 5.838s
[2K
| RMSProp | epoch: 028 | loss: 0.35641 - acc: 0.8698 -- iter: 320/461
[A[ATraining Step: 416  | total loss: [1m[32m0.35778[0m[0m | time: 6.111s
[2K
| RMSProp | epoch: 028 | loss: 0.35778 - acc: 0.8674 -- iter: 352/461
[A[ATraining Step: 417  | total loss: [1m[32m0.34613[0m[0m | time: 6.713s
[2K
| RMSProp | epoch: 028 | loss: 0.34613 - acc: 0.8730 -- iter: 384/461
[A[ATraining Step: 418  | total loss: [1m[32m0.34227[0m[0m | time: 7.317s
[2K
| RMSProp | epoch: 028 | loss: 0.34227 - acc: 0.8732 -- iter: 416/461
[A[ATraining Step: 419  | total loss: [1m[32m0.35456[0m[0m | time: 7.926s
[2K
| RMSProp | epoch: 028 | loss: 0.35456 - acc: 0.8577 -- iter: 448/461
[A[ATraining Step: 420  | total loss: [1m[32m0.37546[0m[0m | time: 9.524s
[2K
| RMSProp | epoch: 028 | loss: 0.37546 - acc: 0.8438 | val_loss: 0.42569 - val_acc: 0.8345 -- iter: 461/461
--
Training Step: 421  | total loss: [1m[32m0.35419[0m[0m | time: 0.635s
[2K
| RMSProp | epoch: 029 | loss: 0.35419 - acc: 0.8595 -- iter: 032/461
[A[ATraining Step: 422  | total loss: [1m[32m0.33584[0m[0m | time: 1.238s
[2K
| RMSProp | epoch: 029 | loss: 0.33584 - acc: 0.8673 -- iter: 064/461
[A[ATraining Step: 423  | total loss: [1m[32m0.31283[0m[0m | time: 1.840s
[2K
| RMSProp | epoch: 029 | loss: 0.31283 - acc: 0.8774 -- iter: 096/461
[A[ATraining Step: 424  | total loss: [1m[32m0.31286[0m[0m | time: 2.470s
[2K
| RMSProp | epoch: 029 | loss: 0.31286 - acc: 0.8803 -- iter: 128/461
[A[ATraining Step: 425  | total loss: [1m[32m0.30301[0m[0m | time: 3.069s
[2K
| RMSProp | epoch: 029 | loss: 0.30301 - acc: 0.8798 -- iter: 160/461
[A[ATraining Step: 426  | total loss: [1m[32m0.30277[0m[0m | time: 3.674s
[2K
| RMSProp | epoch: 029 | loss: 0.30277 - acc: 0.8793 -- iter: 192/461
[A[ATraining Step: 427  | total loss: [1m[32m0.28506[0m[0m | time: 4.267s
[2K
| RMSProp | epoch: 029 | loss: 0.28506 - acc: 0.8882 -- iter: 224/461
[A[ATraining Step: 428  | total loss: [1m[32m0.26849[0m[0m | time: 5.033s
[2K
| RMSProp | epoch: 029 | loss: 0.26849 - acc: 0.8963 -- iter: 256/461
[A[ATraining Step: 429  | total loss: [1m[32m0.26543[0m[0m | time: 5.633s
[2K
| RMSProp | epoch: 029 | loss: 0.26543 - acc: 0.8973 -- iter: 288/461
[A[ATraining Step: 430  | total loss: [1m[32m0.25644[0m[0m | time: 6.247s
[2K
| RMSProp | epoch: 029 | loss: 0.25644 - acc: 0.9013 -- iter: 320/461
[A[ATraining Step: 431  | total loss: [1m[32m0.25819[0m[0m | time: 6.520s
[2K
| RMSProp | epoch: 029 | loss: 0.25819 - acc: 0.8987 -- iter: 352/461
[A[ATraining Step: 432  | total loss: [1m[32m0.23931[0m[0m | time: 6.819s
[2K
| RMSProp | epoch: 029 | loss: 0.23931 - acc: 0.9088 -- iter: 384/461
[A[ATraining Step: 433  | total loss: [1m[32m0.21709[0m[0m | time: 7.423s
[2K
| RMSProp | epoch: 029 | loss: 0.21709 - acc: 0.9179 -- iter: 416/461
[A[ATraining Step: 434  | total loss: [1m[32m0.19956[0m[0m | time: 8.042s
[2K
| RMSProp | epoch: 029 | loss: 0.19956 - acc: 0.9261 -- iter: 448/461
[A[ATraining Step: 435  | total loss: [1m[32m0.19728[0m[0m | time: 9.641s
[2K
| RMSProp | epoch: 029 | loss: 0.19728 - acc: 0.9241 | val_loss: 0.50643 - val_acc: 0.7241 -- iter: 461/461
--
Training Step: 436  | total loss: [1m[32m0.20280[0m[0m | time: 0.652s
[2K
| RMSProp | epoch: 030 | loss: 0.20280 - acc: 0.9224 -- iter: 032/461
[A[ATraining Step: 437  | total loss: [1m[32m0.19840[0m[0m | time: 1.257s
[2K
| RMSProp | epoch: 030 | loss: 0.19840 - acc: 0.9270 -- iter: 064/461
[A[ATraining Step: 438  | total loss: [1m[32m0.18286[0m[0m | time: 1.862s
[2K
| RMSProp | epoch: 030 | loss: 0.18286 - acc: 0.9343 -- iter: 096/461
[A[ATraining Step: 439  | total loss: [1m[32m0.17805[0m[0m | time: 2.465s
[2K
| RMSProp | epoch: 030 | loss: 0.17805 - acc: 0.9346 -- iter: 128/461
[A[ATraining Step: 440  | total loss: [1m[32m0.18442[0m[0m | time: 3.085s
[2K
| RMSProp | epoch: 030 | loss: 0.18442 - acc: 0.9349 -- iter: 160/461
[A[ATraining Step: 441  | total loss: [1m[32m0.17012[0m[0m | time: 3.687s
[2K
| RMSProp | epoch: 030 | loss: 0.17012 - acc: 0.9414 -- iter: 192/461
[A[ATraining Step: 442  | total loss: [1m[32m0.17370[0m[0m | time: 4.311s
[2K
| RMSProp | epoch: 030 | loss: 0.17370 - acc: 0.9379 -- iter: 224/461
[A[ATraining Step: 443  | total loss: [1m[32m0.17017[0m[0m | time: 4.917s
[2K
| RMSProp | epoch: 030 | loss: 0.17017 - acc: 0.9347 -- iter: 256/461
[A[ATraining Step: 444  | total loss: [1m[32m0.20322[0m[0m | time: 5.509s
[2K
| RMSProp | epoch: 030 | loss: 0.20322 - acc: 0.9163 -- iter: 288/461
[A[ATraining Step: 445  | total loss: [1m[32m0.21567[0m[0m | time: 6.113s
[2K
| RMSProp | epoch: 030 | loss: 0.21567 - acc: 0.9121 -- iter: 320/461
[A[ATraining Step: 446  | total loss: [1m[32m0.22424[0m[0m | time: 6.720s
[2K
| RMSProp | epoch: 030 | loss: 0.22424 - acc: 0.9053 -- iter: 352/461
[A[ATraining Step: 447  | total loss: [1m[32m0.22024[0m[0m | time: 6.994s
[2K
| RMSProp | epoch: 030 | loss: 0.22024 - acc: 0.9085 -- iter: 384/461
[A[ATraining Step: 448  | total loss: [1m[32m0.20449[0m[0m | time: 7.267s
[2K
| RMSProp | epoch: 030 | loss: 0.20449 - acc: 0.9177 -- iter: 416/461
[A[ATraining Step: 449  | total loss: [1m[32m0.18710[0m[0m | time: 7.871s
[2K
| RMSProp | epoch: 030 | loss: 0.18710 - acc: 0.9259 -- iter: 448/461
[A[ATraining Step: 450  | total loss: [1m[32m0.16894[0m[0m | time: 9.482s
[2K
| RMSProp | epoch: 030 | loss: 0.16894 - acc: 0.9333 | val_loss: 0.45631 - val_acc: 0.8414 -- iter: 461/461
--
Validation AUC:0.9223115193264447
Validation AUPRC:0.9366347883673277
Test AUC:0.955
Test AUPRC:0.9673780865754751
BestTestF1Score	0.89	0.77	0.88	0.92	0.86	69	6	59	11	0.7
BestTestMCCScore	0.89	0.77	0.88	0.92	0.86	69	6	59	11	0.7
BestTestAccuracyScore	0.89	0.77	0.88	0.92	0.86	69	6	59	11	0.7
BestValidationF1Score	0.87	0.73	0.86	0.9	0.83	65	7	60	13	0.7
BestValidationMCC	0.87	0.73	0.86	0.9	0.83	65	7	60	13	0.7
BestValidationAccuracy	0.87	0.73	0.86	0.9	0.83	65	7	60	13	0.7
TestPredictions (Threshold:0.7)
CHEMBL569493,TP,ACT,1.0	CHEMBL2324979,TN,INACT,0.009999999776482582	CHEMBL167975,TN,INACT,0.009999999776482582	CHEMBL1290510,TP,ACT,1.0	CHEMBL3260895,TN,INACT,0.0	CHEMBL3785621,TP,ACT,0.9399999976158142	CHEMBL3221243,TN,INACT,0.10000000149011612	CHEMBL3785810,FN,ACT,0.009999999776482582	CHEMBL3687606,TN,INACT,0.009999999776482582	CHEMBL3731879,TP,ACT,0.9900000095367432	CHEMBL125829,TN,INACT,0.03999999910593033	CHEMBL2398403,FP,INACT,0.9200000166893005	CHEMBL2331985,TP,ACT,1.0	CHEMBL3113247,TN,INACT,0.0	CHEMBL465276,TP,ACT,0.9900000095367432	CHEMBL124751,TN,INACT,0.009999999776482582	CHEMBL2440410,TP,ACT,0.9700000286102295	CHEMBL466204,TN,INACT,0.019999999552965164	CHEMBL2325259,TN,INACT,0.019999999552965164	CHEMBL3262812,TN,INACT,0.009999999776482582	CHEMBL95335,TP,ACT,0.8100000023841858	CHEMBL1091880,TP,ACT,0.8700000047683716	CHEMBL3298141,FN,ACT,0.029999999329447746	CHEMBL2380882,TN,INACT,0.009999999776482582	CHEMBL3786562,TN,INACT,0.5199999809265137	CHEMBL2332448,TP,ACT,0.9900000095367432	CHEMBL513656,FN,ACT,0.019999999552965164	CHEMBL467479,TP,ACT,0.9399999976158142	CHEMBL2380915,TN,INACT,0.0	CHEMBL3127395,FN,ACT,0.6399999856948853	CHEMBL2381016,TN,INACT,0.0	CHEMBL552193,TN,INACT,0.009999999776482582	CHEMBL2331989,TP,ACT,0.9900000095367432	CHEMBL2332453,TP,ACT,0.7900000214576721	CHEMBL386226,FN,ACT,0.5	CHEMBL520917,TP,ACT,1.0	CHEMBL3732734,TP,ACT,0.9900000095367432	CHEMBL1290738,TP,ACT,1.0	CHEMBL373704,TP,ACT,0.9900000095367432	CHEMBL564372,TN,INACT,0.11999999731779099	CHEMBL2332461,TP,ACT,0.8299999833106995	CHEMBL3799790,TN,INACT,0.009999999776482582	CHEMBL2325256,TN,INACT,0.0	CHEMBL569628,TP,ACT,1.0	CHEMBL391455,TP,ACT,0.9399999976158142	CHEMBL3729707,TP,ACT,1.0	CHEMBL512242,FN,ACT,0.6200000047683716	CHEMBL1290064,TP,ACT,0.8999999761581421	CHEMBL2325262,TN,INACT,0.0	CHEMBL2332451,TP,ACT,0.9900000095367432	CHEMBL217921,TP,ACT,0.9900000095367432	CHEMBL3113246,TN,INACT,0.0	CHEMBL1289744,TP,ACT,1.0	CHEMBL230238,TP,ACT,1.0	CHEMBL144106,TP,ACT,1.0	CHEMBL433220,TP,ACT,1.0	CHEMBL1088803,TP,ACT,0.9599999785423279	CHEMBL40078,TN,INACT,0.009999999776482582	CHEMBL517078,TP,ACT,0.9800000190734863	CHEMBL3127408,TP,ACT,1.0	CHEMBL217222,TP,ACT,0.9800000190734863	CHEMBL127604,TN,INACT,0.029999999329447746	CHEMBL228330,TP,ACT,0.9300000071525574	CHEMBL385809,TP,ACT,0.9900000095367432	CHEMBL3221241,TN,INACT,0.009999999776482582	CHEMBL3260892,TN,INACT,0.0	CHEMBL2298877,TN,INACT,0.009999999776482582	CHEMBL2152522,TP,ACT,0.9900000095367432	CHEMBL556623,TN,INACT,0.019999999552965164	CHEMBL517023,TN,INACT,0.019999999552965164	CHEMBL3298225,TP,ACT,1.0	CHEMBL3126834,FP,INACT,0.9300000071525574	CHEMBL258934,TP,ACT,0.9800000190734863	CHEMBL3127396,TP,ACT,1.0	CHEMBL227432,TN,INACT,0.009999999776482582	CHEMBL3677853,TN,INACT,0.009999999776482582	CHEMBL373955,TN,INACT,0.03999999910593033	CHEMBL2381005,TN,INACT,0.0	CHEMBL3799379,TN,INACT,0.009999999776482582	CHEMBL3687605,TN,INACT,0.0	CHEMBL37379,FP,INACT,0.9700000286102295	CHEMBL228808,TP,ACT,0.9800000190734863	CHEMBL1090160,TP,ACT,0.9900000095367432	CHEMBL475723,TN,INACT,0.009999999776482582	CHEMBL2298875,TN,INACT,0.0	CHEMBL1289417,TP,ACT,1.0	CHEMBL1290737,TP,ACT,1.0	CHEMBL3113255,TN,INACT,0.09000000357627869	CHEMBL258718,TP,ACT,0.9900000095367432	CHEMBL2440403,FN,ACT,0.009999999776482582	CHEMBL288131,TP,ACT,0.9700000286102295	CHEMBL2331999,TP,ACT,0.9800000190734863	CHEMBL338607,TN,INACT,0.1899999976158142	CHEMBL562547,TN,INACT,0.0	CHEMBL2381037,FP,INACT,0.7599999904632568	CHEMBL124802,TN,INACT,0.019999999552965164	CHEMBL568957,TP,ACT,1.0	CHEMBL3221240,TN,INACT,0.0	CHEMBL144170,TP,ACT,1.0	CHEMBL387671,FN,ACT,0.019999999552965164	CHEMBL567234,TP,ACT,0.9599999785423279	CHEMBL42934,FN,ACT,0.1599999964237213	CHEMBL2325232,TN,INACT,0.0	CHEMBL3677856,TN,INACT,0.0	CHEMBL3127411,TP,ACT,1.0	CHEMBL389096,TP,ACT,0.9800000190734863	CHEMBL3786460,TP,ACT,0.9900000095367432	CHEMBL467041,TP,ACT,0.9900000095367432	CHEMBL2443262,FP,INACT,0.9700000286102295	CHEMBL3113250,TN,INACT,0.009999999776482582	CHEMBL1684585,TN,INACT,0.0	CHEMBL569185,TP,ACT,1.0	CHEMBL466838,FN,ACT,0.20000000298023224	CHEMBL217291,TP,ACT,1.0	CHEMBL2381017,TN,INACT,0.09000000357627869	CHEMBL2440409,TP,ACT,0.9800000190734863	CHEMBL385662,TP,ACT,0.9900000095367432	CHEMBL2380918,TN,INACT,0.019999999552965164	CHEMBL511864,TN,INACT,0.0	CHEMBL220492,TN,INACT,0.17000000178813934	CHEMBL572153,TP,ACT,1.0	CHEMBL466517,TN,INACT,0.009999999776482582	CHEMBL594891,TN,INACT,0.12999999523162842	CHEMBL3298228,TP,ACT,0.9700000286102295	CHEMBL585353,TP,ACT,1.0	CHEMBL3113251,TN,INACT,0.0	CHEMBL465085,TP,ACT,0.9300000071525574	CHEMBL3113256,TN,INACT,0.0	CHEMBL2332457,TP,ACT,0.8199999928474426	CHEMBL111861,TN,INACT,0.07000000029802322	CHEMBL3127419,TP,ACT,1.0	CHEMBL217473,TP,ACT,1.0	CHEMBL567024,TP,ACT,1.0	CHEMBL78968,TN,INACT,0.15000000596046448	CHEMBL426096,FP,INACT,0.9399999976158142	CHEMBL1090818,TP,ACT,1.0	CHEMBL3262829,TN,INACT,0.20999999344348907	CHEMBL2332446,TP,ACT,1.0	CHEMBL2312928,TP,ACT,0.9900000095367432	CHEMBL23720,TN,INACT,0.05999999865889549	CHEMBL1972820,TN,INACT,0.009999999776482582	CHEMBL2111829,TN,INACT,0.009999999776482582	CHEMBL2042151,TP,ACT,1.0	CHEMBL1091162,TP,ACT,1.0	CHEMBL218128,FN,ACT,0.6000000238418579	

