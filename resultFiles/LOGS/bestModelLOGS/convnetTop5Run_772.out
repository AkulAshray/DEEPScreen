ImageNetInceptionV2 CHEMBL4816 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	203
Number of inactive compounds :	203
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4816_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4816_adam_0.0005_15_0.8/
---------------------------------
Training samples: 252
Validation samples: 79
--
Training Step: 1  | time: 49.036s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/252
[A[ATraining Step: 2  | total loss: [1m[32m0.64777[0m[0m | time: 57.040s
[2K
| Adam | epoch: 001 | loss: 0.64777 - acc: 0.3937 -- iter: 064/252
[A[ATraining Step: 3  | total loss: [1m[32m0.66036[0m[0m | time: 65.052s
[2K
| Adam | epoch: 001 | loss: 0.66036 - acc: 0.5574 -- iter: 096/252
[A[ATraining Step: 4  | total loss: [1m[32m0.62385[0m[0m | time: 94.091s
[2K
| Adam | epoch: 001 | loss: 0.62385 - acc: 0.6784 -- iter: 128/252
[A[ATraining Step: 5  | total loss: [1m[32m0.39086[0m[0m | time: 112.311s
[2K
| Adam | epoch: 001 | loss: 0.39086 - acc: 0.8794 -- iter: 160/252
[A[ATraining Step: 6  | total loss: [1m[32m0.57706[0m[0m | time: 122.621s
[2K
| Adam | epoch: 001 | loss: 0.57706 - acc: 0.8163 -- iter: 192/252
[A[ATraining Step: 7  | total loss: [1m[32m0.57066[0m[0m | time: 134.882s
[2K
| Adam | epoch: 001 | loss: 0.57066 - acc: 0.8140 -- iter: 224/252
[A[ATraining Step: 8  | total loss: [1m[32m0.54127[0m[0m | time: 151.994s
[2K
| Adam | epoch: 001 | loss: 0.54127 - acc: 0.7956 | val_loss: 1.82592 - val_acc: 0.5063 -- iter: 252/252
--
Training Step: 9  | total loss: [1m[32m0.51195[0m[0m | time: 7.415s
[2K
| Adam | epoch: 002 | loss: 0.51195 - acc: 0.7525 -- iter: 032/252
[A[ATraining Step: 10  | total loss: [1m[32m0.35091[0m[0m | time: 15.773s
[2K
| Adam | epoch: 002 | loss: 0.35091 - acc: 0.8406 -- iter: 064/252
[A[ATraining Step: 11  | total loss: [1m[32m0.38974[0m[0m | time: 23.934s
[2K
| Adam | epoch: 002 | loss: 0.38974 - acc: 0.8273 -- iter: 096/252
[A[ATraining Step: 12  | total loss: [1m[32m0.39141[0m[0m | time: 32.366s
[2K
| Adam | epoch: 002 | loss: 0.39141 - acc: 0.8066 -- iter: 128/252
[A[ATraining Step: 13  | total loss: [1m[32m0.34633[0m[0m | time: 44.613s
[2K
| Adam | epoch: 002 | loss: 0.34633 - acc: 0.8091 -- iter: 160/252
[A[ATraining Step: 14  | total loss: [1m[32m0.23226[0m[0m | time: 57.373s
[2K
| Adam | epoch: 002 | loss: 0.23226 - acc: 0.8872 -- iter: 192/252
[A[ATraining Step: 15  | total loss: [1m[32m0.24863[0m[0m | time: 85.118s
[2K
| Adam | epoch: 002 | loss: 0.24863 - acc: 0.9069 -- iter: 224/252
[A[ATraining Step: 16  | total loss: [1m[32m0.20617[0m[0m | time: 111.884s
[2K
| Adam | epoch: 002 | loss: 0.20617 - acc: 0.9301 | val_loss: 4.68687 - val_acc: 0.5063 -- iter: 252/252
--
Training Step: 17  | total loss: [1m[32m0.16462[0m[0m | time: 18.457s
[2K
| Adam | epoch: 003 | loss: 0.16462 - acc: 0.9440 -- iter: 032/252
[A[ATraining Step: 18  | total loss: [1m[32m0.12664[0m[0m | time: 35.481s
[2K
| Adam | epoch: 003 | loss: 0.12664 - acc: 0.9634 -- iter: 064/252
[A[ATraining Step: 19  | total loss: [1m[32m0.09093[0m[0m | time: 54.111s
[2K
| Adam | epoch: 003 | loss: 0.09093 - acc: 0.9756 -- iter: 096/252
[A[ATraining Step: 20  | total loss: [1m[32m0.14852[0m[0m | time: 73.093s
[2K
| Adam | epoch: 003 | loss: 0.14852 - acc: 0.9533 -- iter: 128/252
[A[ATraining Step: 21  | total loss: [1m[32m0.14671[0m[0m | time: 86.762s
[2K
| Adam | epoch: 003 | loss: 0.14671 - acc: 0.9387 -- iter: 160/252
[A[ATraining Step: 22  | total loss: [1m[32m0.13703[0m[0m | time: 98.105s
[2K
| Adam | epoch: 003 | loss: 0.13703 - acc: 0.9477 -- iter: 192/252
[A[ATraining Step: 23  | total loss: [1m[32m0.10581[0m[0m | time: 106.309s
[2K
| Adam | epoch: 003 | loss: 0.10581 - acc: 0.9629 -- iter: 224/252
[A[ATraining Step: 24  | total loss: [1m[32m0.11394[0m[0m | time: 121.511s
[2K
| Adam | epoch: 003 | loss: 0.11394 - acc: 0.9470 | val_loss: 5.82033 - val_acc: 0.5063 -- iter: 252/252
--
Training Step: 25  | total loss: [1m[32m0.11416[0m[0m | time: 15.432s
[2K
| Adam | epoch: 004 | loss: 0.11416 - acc: 0.9529 -- iter: 032/252
[A[ATraining Step: 26  | total loss: [1m[32m0.10010[0m[0m | time: 27.095s
[2K
| Adam | epoch: 004 | loss: 0.10010 - acc: 0.9571 -- iter: 064/252
[A[ATraining Step: 27  | total loss: [1m[32m0.07999[0m[0m | time: 39.314s
[2K
| Adam | epoch: 004 | loss: 0.07999 - acc: 0.9681 -- iter: 096/252
[A[ATraining Step: 28  | total loss: [1m[32m0.06445[0m[0m | time: 54.873s
[2K
| Adam | epoch: 004 | loss: 0.06445 - acc: 0.9761 -- iter: 128/252
[A[ATraining Step: 29  | total loss: [1m[32m0.09451[0m[0m | time: 68.995s
[2K
| Adam | epoch: 004 | loss: 0.09451 - acc: 0.9667 -- iter: 160/252
[A[ATraining Step: 30  | total loss: [1m[32m0.08915[0m[0m | time: 82.072s
[2K
| Adam | epoch: 004 | loss: 0.08915 - acc: 0.9672 -- iter: 192/252
[A[ATraining Step: 31  | total loss: [1m[32m0.08222[0m[0m | time: 95.811s
[2K
| Adam | epoch: 004 | loss: 0.08222 - acc: 0.9748 -- iter: 224/252
[A[ATraining Step: 32  | total loss: [1m[32m0.06998[0m[0m | time: 112.830s
[2K
| Adam | epoch: 004 | loss: 0.06998 - acc: 0.9804 | val_loss: 6.29047 - val_acc: 0.5063 -- iter: 252/252
--
Training Step: 33  | total loss: [1m[32m0.06805[0m[0m | time: 12.433s
[2K
| Adam | epoch: 005 | loss: 0.06805 - acc: 0.9779 -- iter: 032/252
[A[ATraining Step: 34  | total loss: [1m[32m0.07603[0m[0m | time: 25.287s
[2K
| Adam | epoch: 005 | loss: 0.07603 - acc: 0.9692 -- iter: 064/252
[A[ATraining Step: 35  | total loss: [1m[32m0.08034[0m[0m | time: 37.330s
[2K
| Adam | epoch: 005 | loss: 0.08034 - acc: 0.9626 -- iter: 096/252
[A[ATraining Step: 36  | total loss: [1m[32m0.06782[0m[0m | time: 49.267s
[2K
| Adam | epoch: 005 | loss: 0.06782 - acc: 0.9702 -- iter: 128/252
[A[ATraining Step: 37  | total loss: [1m[32m0.05783[0m[0m | time: 62.376s
[2K
| Adam | epoch: 005 | loss: 0.05783 - acc: 0.9762 -- iter: 160/252
[A[ATraining Step: 38  | total loss: [1m[32m0.05448[0m[0m | time: 76.138s
[2K
| Adam | epoch: 005 | loss: 0.05448 - acc: 0.9747 -- iter: 192/252
[A[ATraining Step: 39  | total loss: [1m[32m0.04773[0m[0m | time: 89.545s
[2K
| Adam | epoch: 005 | loss: 0.04773 - acc: 0.9796 -- iter: 224/252
[A[ATraining Step: 40  | total loss: [1m[32m0.11452[0m[0m | time: 106.619s
[2K
| Adam | epoch: 005 | loss: 0.11452 - acc: 0.9717 | val_loss: 1.10395 - val_acc: 0.4937 -- iter: 252/252
--
Training Step: 41  | total loss: [1m[32m0.09529[0m[0m | time: 12.401s
[2K
| Adam | epoch: 006 | loss: 0.09529 - acc: 0.9769 -- iter: 032/252
[A[ATraining Step: 42  | total loss: [1m[32m0.09104[0m[0m | time: 29.647s
[2K
| Adam | epoch: 006 | loss: 0.09104 - acc: 0.9754 -- iter: 064/252
[A[ATraining Step: 43  | total loss: [1m[32m0.08364[0m[0m | time: 42.590s
[2K
| Adam | epoch: 006 | loss: 0.08364 - acc: 0.9798 -- iter: 096/252
[A[ATraining Step: 44  | total loss: [1m[32m0.08322[0m[0m | time: 53.854s
[2K
| Adam | epoch: 006 | loss: 0.08322 - acc: 0.9779 -- iter: 128/252
[A[ATraining Step: 45  | total loss: [1m[32m0.09509[0m[0m | time: 107.283s
[2K
| Adam | epoch: 006 | loss: 0.09509 - acc: 0.9695 -- iter: 160/252
[A[ATraining Step: 46  | total loss: [1m[32m0.08163[0m[0m | time: 213.182s
[2K
| Adam | epoch: 006 | loss: 0.08163 - acc: 0.9746 -- iter: 192/252
[A[ATraining Step: 47  | total loss: [1m[32m0.07131[0m[0m | time: 293.854s
[2K
| Adam | epoch: 006 | loss: 0.07131 - acc: 0.9787 -- iter: 224/252
[A[ATraining Step: 48  | total loss: [1m[32m0.06502[0m[0m | time: 325.786s
[2K
| Adam | epoch: 006 | loss: 0.06502 - acc: 0.9821 | val_loss: 3.29992 - val_acc: 0.4937 -- iter: 252/252
--
Training Step: 49  | total loss: [1m[32m0.10326[0m[0m | time: 11.926s
[2K
| Adam | epoch: 007 | loss: 0.10326 - acc: 0.9800 -- iter: 032/252
[A[ATraining Step: 50  | total loss: [1m[32m0.09042[0m[0m | time: 24.892s
[2K
| Adam | epoch: 007 | loss: 0.09042 - acc: 0.9831 -- iter: 064/252
[A[ATraining Step: 51  | total loss: [1m[32m0.08108[0m[0m | time: 37.696s
[2K
| Adam | epoch: 007 | loss: 0.08108 - acc: 0.9857 -- iter: 096/252
[A[ATraining Step: 52  | total loss: [1m[32m0.07061[0m[0m | time: 49.805s
[2K
| Adam | epoch: 007 | loss: 0.07061 - acc: 0.9878 -- iter: 128/252
[A[ATraining Step: 53  | total loss: [1m[32m0.06564[0m[0m | time: 61.241s
[2K
| Adam | epoch: 007 | loss: 0.06564 - acc: 0.9850 -- iter: 160/252
[A[ATraining Step: 54  | total loss: [1m[32m0.06323[0m[0m | time: 73.033s
[2K
| Adam | epoch: 007 | loss: 0.06323 - acc: 0.9872 -- iter: 192/252
[A[ATraining Step: 55  | total loss: [1m[32m0.05570[0m[0m | time: 85.582s
[2K
| Adam | epoch: 007 | loss: 0.05570 - acc: 0.9890 -- iter: 224/252
[A[ATraining Step: 56  | total loss: [1m[32m0.08211[0m[0m | time: 103.452s
[2K
| Adam | epoch: 007 | loss: 0.08211 - acc: 0.9862 | val_loss: 1.48362 - val_acc: 0.6329 -- iter: 252/252
--
Training Step: 57  | total loss: [1m[32m0.07508[0m[0m | time: 12.420s
[2K
| Adam | epoch: 008 | loss: 0.07508 - acc: 0.9881 -- iter: 032/252
[A[ATraining Step: 58  | total loss: [1m[32m0.08050[0m[0m | time: 24.753s
[2K
| Adam | epoch: 008 | loss: 0.08050 - acc: 0.9855 -- iter: 064/252
[A[ATraining Step: 59  | total loss: [1m[32m0.07408[0m[0m | time: 37.585s
[2K
| Adam | epoch: 008 | loss: 0.07408 - acc: 0.9874 -- iter: 096/252
[A[ATraining Step: 60  | total loss: [1m[32m0.06458[0m[0m | time: 49.834s
[2K
| Adam | epoch: 008 | loss: 0.06458 - acc: 0.9891 -- iter: 128/252
[A[ATraining Step: 61  | total loss: [1m[32m0.05888[0m[0m | time: 62.239s
[2K
| Adam | epoch: 008 | loss: 0.05888 - acc: 0.9905 -- iter: 160/252
[A[ATraining Step: 62  | total loss: [1m[32m0.05234[0m[0m | time: 73.779s
[2K
| Adam | epoch: 008 | loss: 0.05234 - acc: 0.9917 -- iter: 192/252
[A[ATraining Step: 63  | total loss: [1m[32m0.09001[0m[0m | time: 97.121s
[2K
| Adam | epoch: 008 | loss: 0.09001 - acc: 0.9792 -- iter: 224/252
[A[ATraining Step: 64  | total loss: [1m[32m0.09321[0m[0m | time: 159.238s
[2K
| Adam | epoch: 008 | loss: 0.09321 - acc: 0.9773 | val_loss: 1.20847 - val_acc: 0.6203 -- iter: 252/252
--
Training Step: 65  | total loss: [1m[32m0.08278[0m[0m | time: 44.935s
[2K
| Adam | epoch: 009 | loss: 0.08278 - acc: 0.9801 -- iter: 032/252
[A[ATraining Step: 66  | total loss: [1m[32m0.07811[0m[0m | time: 71.533s
[2K
| Adam | epoch: 009 | loss: 0.07811 - acc: 0.9787 -- iter: 064/252
[A[ATraining Step: 67  | total loss: [1m[32m0.10559[0m[0m | time: 100.106s
[2K
| Adam | epoch: 009 | loss: 0.10559 - acc: 0.9775 -- iter: 096/252
[A[ATraining Step: 68  | total loss: [1m[32m0.09565[0m[0m | time: 135.118s
[2K
| Adam | epoch: 009 | loss: 0.09565 - acc: 0.9802 -- iter: 128/252
[A[ATraining Step: 69  | total loss: [1m[32m0.08873[0m[0m | time: 146.798s
[2K
| Adam | epoch: 009 | loss: 0.08873 - acc: 0.9825 -- iter: 160/252
[A[ATraining Step: 70  | total loss: [1m[32m0.08019[0m[0m | time: 159.021s
[2K
| Adam | epoch: 009 | loss: 0.08019 - acc: 0.9845 -- iter: 192/252
[A[ATraining Step: 71  | total loss: [1m[32m0.07728[0m[0m | time: 170.555s
[2K
| Adam | epoch: 009 | loss: 0.07728 - acc: 0.9827 -- iter: 224/252
[A[ATraining Step: 72  | total loss: [1m[32m0.10214[0m[0m | time: 188.402s
[2K
| Adam | epoch: 009 | loss: 0.10214 - acc: 0.9807 | val_loss: 1.67811 - val_acc: 0.5443 -- iter: 252/252
--
Training Step: 73  | total loss: [1m[32m0.09798[0m[0m | time: 8.043s
[2K
| Adam | epoch: 010 | loss: 0.09798 - acc: 0.9788 -- iter: 032/252
[A[ATraining Step: 74  | total loss: [1m[32m0.11887[0m[0m | time: 16.053s
[2K
| Adam | epoch: 010 | loss: 0.11887 - acc: 0.9743 -- iter: 064/252
[A[ATraining Step: 75  | total loss: [1m[32m0.12530[0m[0m | time: 25.756s
[2K
| Adam | epoch: 010 | loss: 0.12530 - acc: 0.9703 -- iter: 096/252
[A[ATraining Step: 76  | total loss: [1m[32m0.15059[0m[0m | time: 38.248s
[2K
| Adam | epoch: 010 | loss: 0.15059 - acc: 0.9701 -- iter: 128/252
[A[ATraining Step: 77  | total loss: [1m[32m0.13615[0m[0m | time: 50.542s
[2K
| Adam | epoch: 010 | loss: 0.13615 - acc: 0.9733 -- iter: 160/252
[A[ATraining Step: 78  | total loss: [1m[32m0.12622[0m[0m | time: 63.289s
[2K
| Adam | epoch: 010 | loss: 0.12622 - acc: 0.9761 -- iter: 192/252
[A[ATraining Step: 79  | total loss: [1m[32m0.13502[0m[0m | time: 75.918s
[2K
| Adam | epoch: 010 | loss: 0.13502 - acc: 0.9689 -- iter: 224/252
[A[ATraining Step: 80  | total loss: [1m[32m0.12836[0m[0m | time: 93.466s
[2K
| Adam | epoch: 010 | loss: 0.12836 - acc: 0.9721 | val_loss: 10.18039 - val_acc: 0.5063 -- iter: 252/252
--
Training Step: 81  | total loss: [1m[32m0.12037[0m[0m | time: 9.040s
[2K
| Adam | epoch: 011 | loss: 0.12037 - acc: 0.9749 -- iter: 032/252
[A[ATraining Step: 82  | total loss: [1m[32m0.10995[0m[0m | time: 17.142s
[2K
| Adam | epoch: 011 | loss: 0.10995 - acc: 0.9774 -- iter: 064/252
[A[ATraining Step: 83  | total loss: [1m[32m0.10210[0m[0m | time: 25.207s
[2K
| Adam | epoch: 011 | loss: 0.10210 - acc: 0.9797 -- iter: 096/252
[A[ATraining Step: 84  | total loss: [1m[32m0.10297[0m[0m | time: 33.166s
[2K
| Adam | epoch: 011 | loss: 0.10297 - acc: 0.9723 -- iter: 128/252
[A[ATraining Step: 85  | total loss: [1m[32m0.09578[0m[0m | time: 43.263s
[2K
| Adam | epoch: 011 | loss: 0.09578 - acc: 0.9751 -- iter: 160/252
[A[ATraining Step: 86  | total loss: [1m[32m0.09010[0m[0m | time: 55.805s
[2K
| Adam | epoch: 011 | loss: 0.09010 - acc: 0.9776 -- iter: 192/252
[A[ATraining Step: 87  | total loss: [1m[32m0.08385[0m[0m | time: 68.498s
[2K
| Adam | epoch: 011 | loss: 0.08385 - acc: 0.9798 -- iter: 224/252
[A[ATraining Step: 88  | total loss: [1m[32m0.07727[0m[0m | time: 87.605s
[2K
| Adam | epoch: 011 | loss: 0.07727 - acc: 0.9818 | val_loss: 1.41112 - val_acc: 0.6709 -- iter: 252/252
--
Training Step: 89  | total loss: [1m[32m0.07197[0m[0m | time: 11.535s
[2K
| Adam | epoch: 012 | loss: 0.07197 - acc: 0.9837 -- iter: 032/252
[A[ATraining Step: 90  | total loss: [1m[32m0.06854[0m[0m | time: 18.972s
[2K
| Adam | epoch: 012 | loss: 0.06854 - acc: 0.9853 -- iter: 064/252
[A[ATraining Step: 91  | total loss: [1m[32m0.06245[0m[0m | time: 26.843s
[2K
| Adam | epoch: 012 | loss: 0.06245 - acc: 0.9868 -- iter: 096/252
[A[ATraining Step: 92  | total loss: [1m[32m0.05904[0m[0m | time: 34.890s
[2K
| Adam | epoch: 012 | loss: 0.05904 - acc: 0.9850 -- iter: 128/252
[A[ATraining Step: 93  | total loss: [1m[32m0.05374[0m[0m | time: 43.665s
[2K
| Adam | epoch: 012 | loss: 0.05374 - acc: 0.9865 -- iter: 160/252
[A[ATraining Step: 94  | total loss: [1m[32m0.06328[0m[0m | time: 56.546s
[2K
| Adam | epoch: 012 | loss: 0.06328 - acc: 0.9816 -- iter: 192/252
[A[ATraining Step: 95  | total loss: [1m[32m0.05965[0m[0m | time: 69.804s
[2K
| Adam | epoch: 012 | loss: 0.05965 - acc: 0.9834 -- iter: 224/252
[A[ATraining Step: 96  | total loss: [1m[32m0.05623[0m[0m | time: 88.030s
[2K
| Adam | epoch: 012 | loss: 0.05623 - acc: 0.9851 | val_loss: 1.07443 - val_acc: 0.6962 -- iter: 252/252
--
Training Step: 97  | total loss: [1m[32m0.05117[0m[0m | time: 12.441s
[2K
| Adam | epoch: 013 | loss: 0.05117 - acc: 0.9866 -- iter: 032/252
[A[ATraining Step: 98  | total loss: [1m[32m0.04874[0m[0m | time: 19.844s
[2K
| Adam | epoch: 013 | loss: 0.04874 - acc: 0.9879 -- iter: 064/252
[A[ATraining Step: 99  | total loss: [1m[32m0.04470[0m[0m | time: 26.977s
[2K
| Adam | epoch: 013 | loss: 0.04470 - acc: 0.9891 -- iter: 096/252
[A[ATraining Step: 100  | total loss: [1m[32m0.04067[0m[0m | time: 35.715s
[2K
| Adam | epoch: 013 | loss: 0.04067 - acc: 0.9902 -- iter: 128/252
[A[ATraining Step: 101  | total loss: [1m[32m0.03703[0m[0m | time: 54.486s
[2K
| Adam | epoch: 013 | loss: 0.03703 - acc: 0.9912 -- iter: 160/252
[A[ATraining Step: 102  | total loss: [1m[32m0.03490[0m[0m | time: 67.422s
[2K
| Adam | epoch: 013 | loss: 0.03490 - acc: 0.9921 -- iter: 192/252
[A[ATraining Step: 103  | total loss: [1m[32m0.06220[0m[0m | time: 80.723s
[2K
| Adam | epoch: 013 | loss: 0.06220 - acc: 0.9897 -- iter: 224/252
[A[ATraining Step: 104  | total loss: [1m[32m0.05831[0m[0m | time: 98.770s
[2K
| Adam | epoch: 013 | loss: 0.05831 - acc: 0.9908 | val_loss: 0.84454 - val_acc: 0.7848 -- iter: 252/252
--
Training Step: 105  | total loss: [1m[32m0.05535[0m[0m | time: 7.957s
[2K
| Adam | epoch: 014 | loss: 0.05535 - acc: 0.9917 -- iter: 032/252
[A[ATraining Step: 106  | total loss: [1m[32m0.05319[0m[0m | time: 16.270s
[2K
| Adam | epoch: 014 | loss: 0.05319 - acc: 0.9894 -- iter: 064/252
[A[ATraining Step: 107  | total loss: [1m[32m0.07485[0m[0m | time: 24.049s
[2K
| Adam | epoch: 014 | loss: 0.07485 - acc: 0.9842 -- iter: 096/252
[A[ATraining Step: 108  | total loss: [1m[32m0.06974[0m[0m | time: 35.293s
[2K
| Adam | epoch: 014 | loss: 0.06974 - acc: 0.9858 -- iter: 128/252
[A[ATraining Step: 109  | total loss: [1m[32m0.06328[0m[0m | time: 48.061s
[2K
| Adam | epoch: 014 | loss: 0.06328 - acc: 0.9872 -- iter: 160/252
[A[ATraining Step: 110  | total loss: [1m[32m0.05723[0m[0m | time: 61.061s
[2K
| Adam | epoch: 014 | loss: 0.05723 - acc: 0.9885 -- iter: 192/252
[A[ATraining Step: 111  | total loss: [1m[32m0.05594[0m[0m | time: 74.064s
[2K
| Adam | epoch: 014 | loss: 0.05594 - acc: 0.9865 -- iter: 224/252
[A[ATraining Step: 112  | total loss: [1m[32m0.05832[0m[0m | time: 92.839s
[2K
| Adam | epoch: 014 | loss: 0.05832 - acc: 0.9847 | val_loss: 2.81689 - val_acc: 0.5570 -- iter: 252/252
--
Training Step: 113  | total loss: [1m[32m0.05268[0m[0m | time: 12.815s
[2K
| Adam | epoch: 015 | loss: 0.05268 - acc: 0.9863 -- iter: 032/252
[A[ATraining Step: 114  | total loss: [1m[32m0.05282[0m[0m | time: 20.750s
[2K
| Adam | epoch: 015 | loss: 0.05282 - acc: 0.9845 -- iter: 064/252
[A[ATraining Step: 115  | total loss: [1m[32m0.07522[0m[0m | time: 28.813s
[2K
| Adam | epoch: 015 | loss: 0.07522 - acc: 0.9829 -- iter: 096/252
[A[ATraining Step: 116  | total loss: [1m[32m0.07437[0m[0m | time: 36.911s
[2K
| Adam | epoch: 015 | loss: 0.07437 - acc: 0.9815 -- iter: 128/252
[A[ATraining Step: 117  | total loss: [1m[32m0.06819[0m[0m | time: 47.356s
[2K
| Adam | epoch: 015 | loss: 0.06819 - acc: 0.9834 -- iter: 160/252
[A[ATraining Step: 118  | total loss: [1m[32m0.06203[0m[0m | time: 59.496s
[2K
| Adam | epoch: 015 | loss: 0.06203 - acc: 0.9850 -- iter: 192/252
[A[ATraining Step: 119  | total loss: [1m[32m0.05968[0m[0m | time: 71.989s
[2K
| Adam | epoch: 015 | loss: 0.05968 - acc: 0.9865 -- iter: 224/252
[A[ATraining Step: 120  | total loss: [1m[32m0.05499[0m[0m | time: 90.658s
[2K
| Adam | epoch: 015 | loss: 0.05499 - acc: 0.9879 | val_loss: 0.55320 - val_acc: 0.8608 -- iter: 252/252
--
Validation AUC:0.9019230769230769
Validation AUPRC:0.8491456904094613
Test AUC:0.9173076923076923
Test AUPRC:0.8643401977750742
BestTestF1Score	0.88	0.76	0.87	0.81	0.97	38	9	31	1	0.46
BestTestMCCScore	0.88	0.76	0.87	0.81	0.97	38	9	31	1	0.46
BestTestAccuracyScore	0.88	0.76	0.87	0.81	0.97	38	9	31	1	0.46
BestValidationF1Score	0.88	0.75	0.87	0.85	0.9	35	6	34	4	0.46
BestValidationMCC	0.88	0.75	0.87	0.85	0.9	35	6	34	4	0.46
BestValidationAccuracy	0.88	0.75	0.87	0.85	0.9	35	6	34	4	0.46
TestPredictions (Threshold:0.46)
CHEMBL1933801,FP,INACT,1.0	CHEMBL2325993,TP,ACT,0.9800000190734863	CHEMBL2177369,TP,ACT,1.0	CHEMBL525385,TP,ACT,1.0	CHEMBL525921,TN,INACT,0.0	CHEMBL564972,TP,ACT,0.9800000190734863	CHEMBL2178597,TP,ACT,1.0	CHEMBL312078,TN,INACT,0.009999999776482582	CHEMBL172973,TN,INACT,0.17000000178813934	CHEMBL2392385,TN,INACT,0.03999999910593033	CHEMBL2325738,TP,ACT,1.0	CHEMBL2177366,TP,ACT,1.0	CHEMBL379300,FN,ACT,0.18000000715255737	CHEMBL1287975,TN,INACT,0.0	CHEMBL2177378,TP,ACT,1.0	CHEMBL521201,FP,INACT,1.0	CHEMBL1910753,FP,INACT,1.0	CHEMBL599519,TN,INACT,0.10999999940395355	CHEMBL378721,TP,ACT,0.9900000095367432	CHEMBL1258778,TP,ACT,1.0	CHEMBL563733,FP,INACT,0.7599999904632568	CHEMBL2177828,TP,ACT,1.0	CHEMBL1767292,TN,INACT,0.05000000074505806	CHEMBL494060,TP,ACT,0.8100000023841858	CHEMBL3746916,FP,INACT,1.0	CHEMBL603197,TP,ACT,1.0	CHEMBL1077376,TP,ACT,1.0	CHEMBL606467,TP,ACT,1.0	CHEMBL509499,TN,INACT,0.0	CHEMBL210071,TP,ACT,1.0	CHEMBL297394,TP,ACT,0.9599999785423279	CHEMBL2325729,TP,ACT,1.0	CHEMBL493067,TP,ACT,1.0	CHEMBL2177387,TP,ACT,1.0	CHEMBL213618,TP,ACT,1.0	CHEMBL560393,TN,INACT,0.009999999776482582	CHEMBL2177372,TP,ACT,1.0	CHEMBL252857,TP,ACT,1.0	CHEMBL1784660,TN,INACT,0.05999999865889549	CHEMBL1258662,TP,ACT,1.0	CHEMBL2392223,TN,INACT,0.0	CHEMBL494662,TP,ACT,1.0	CHEMBL2392234,TN,INACT,0.0	CHEMBL1910757,FP,INACT,0.5799999833106995	CHEMBL377860,TP,ACT,1.0	CHEMBL2177361,TP,ACT,1.0	CHEMBL562198,TN,INACT,0.0	CHEMBL335938,TN,INACT,0.0	CHEMBL178468,FP,INACT,0.49000000953674316	CHEMBL2325997,TP,ACT,1.0	CHEMBL1910762,FP,INACT,0.9100000262260437	CHEMBL1258550,TP,ACT,1.0	CHEMBL213127,TP,ACT,0.9900000095367432	CHEMBL456143,TN,INACT,0.0	CHEMBL120127,TN,INACT,0.05000000074505806	CHEMBL2325990,TP,ACT,1.0	CHEMBL379263,TP,ACT,0.8500000238418579	CHEMBL2392240,TN,INACT,0.0	CHEMBL522760,TN,INACT,0.009999999776482582	CHEMBL469776,TN,INACT,0.0	CHEMBL120703,TN,INACT,0.009999999776482582	CHEMBL487737,TN,INACT,0.03999999910593033	CHEMBL488811,TN,INACT,0.2800000011920929	CHEMBL3609656,TN,INACT,0.009999999776482582	CHEMBL2392390,TN,INACT,0.0	CHEMBL2325996,TP,ACT,1.0	CHEMBL380402,TP,ACT,0.9900000095367432	CHEMBL593375,TP,ACT,1.0	CHEMBL525538,TN,INACT,0.0	CHEMBL1910754,TN,INACT,0.03999999910593033	CHEMBL3691604,FP,INACT,1.0	CHEMBL485878,TN,INACT,0.0	CHEMBL2177377,TP,ACT,0.699999988079071	CHEMBL78223,TN,INACT,0.0	CHEMBL456113,TN,INACT,0.03999999910593033	CHEMBL608533,TP,ACT,0.9200000166893005	CHEMBL463384,TN,INACT,0.0	CHEMBL2177363,TP,ACT,0.9300000071525574	CHEMBL561136,TN,INACT,0.009999999776482582	

