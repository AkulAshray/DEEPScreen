CNNModel CHEMBL3070 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	113
Number of inactive compounds :	111
---------------------------------
Run id: CNNModel_CHEMBL3070_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3070_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 140
Validation samples: 44
--
Training Step: 1  | time: 0.846s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/140
[A[ATraining Step: 2  | total loss: [1m[32m0.62405[0m[0m | time: 1.487s
[2K
| Adam | epoch: 001 | loss: 0.62405 - acc: 0.4219 -- iter: 064/140
[A[ATraining Step: 3  | total loss: [1m[32m0.68050[0m[0m | time: 2.298s
[2K
| Adam | epoch: 001 | loss: 0.68050 - acc: 0.4858 -- iter: 096/140
[A[ATraining Step: 4  | total loss: [1m[32m0.68974[0m[0m | time: 2.949s
[2K
| Adam | epoch: 001 | loss: 0.68974 - acc: 0.4964 -- iter: 128/140
[A[ATraining Step: 5  | total loss: [1m[32m0.68950[0m[0m | time: 4.240s
[2K
| Adam | epoch: 001 | loss: 0.68950 - acc: 0.5638 | val_loss: 0.69728 - val_acc: 0.4318 -- iter: 140/140
--
Training Step: 6  | total loss: [1m[32m0.69147[0m[0m | time: 0.282s
[2K
| Adam | epoch: 002 | loss: 0.69147 - acc: 0.5228 -- iter: 032/140
[A[ATraining Step: 7  | total loss: [1m[32m0.69093[0m[0m | time: 0.946s
[2K
| Adam | epoch: 002 | loss: 0.69093 - acc: 0.5091 -- iter: 064/140
[A[ATraining Step: 8  | total loss: [1m[32m0.69267[0m[0m | time: 1.592s
[2K
| Adam | epoch: 002 | loss: 0.69267 - acc: 0.4864 -- iter: 096/140
[A[ATraining Step: 9  | total loss: [1m[32m0.69128[0m[0m | time: 2.243s
[2K
| Adam | epoch: 002 | loss: 0.69128 - acc: 0.4936 -- iter: 128/140
[A[ATraining Step: 10  | total loss: [1m[32m0.68545[0m[0m | time: 3.914s
[2K
| Adam | epoch: 002 | loss: 0.68545 - acc: 0.5437 | val_loss: 0.69563 - val_acc: 0.4318 -- iter: 140/140
--
Training Step: 11  | total loss: [1m[32m0.68611[0m[0m | time: 0.286s
[2K
| Adam | epoch: 003 | loss: 0.68611 - acc: 0.5230 -- iter: 032/140
[A[ATraining Step: 12  | total loss: [1m[32m0.67634[0m[0m | time: 0.551s
[2K
| Adam | epoch: 003 | loss: 0.67634 - acc: 0.5501 -- iter: 064/140
[A[ATraining Step: 13  | total loss: [1m[32m0.66708[0m[0m | time: 1.268s
[2K
| Adam | epoch: 003 | loss: 0.66708 - acc: 0.5644 -- iter: 096/140
[A[ATraining Step: 14  | total loss: [1m[32m0.67896[0m[0m | time: 1.905s
[2K
| Adam | epoch: 003 | loss: 0.67896 - acc: 0.5253 -- iter: 128/140
[A[ATraining Step: 15  | total loss: [1m[32m0.68085[0m[0m | time: 3.730s
[2K
| Adam | epoch: 003 | loss: 0.68085 - acc: 0.5031 | val_loss: 0.67164 - val_acc: 0.4318 -- iter: 140/140
--
Training Step: 16  | total loss: [1m[32m0.67851[0m[0m | time: 0.672s
[2K
| Adam | epoch: 004 | loss: 0.67851 - acc: 0.4902 -- iter: 032/140
[A[ATraining Step: 17  | total loss: [1m[32m0.67016[0m[0m | time: 0.944s
[2K
| Adam | epoch: 004 | loss: 0.67016 - acc: 0.5050 -- iter: 064/140
[A[ATraining Step: 18  | total loss: [1m[32m0.65430[0m[0m | time: 1.229s
[2K
| Adam | epoch: 004 | loss: 0.65430 - acc: 0.5898 -- iter: 096/140
[A[ATraining Step: 19  | total loss: [1m[32m0.62881[0m[0m | time: 1.873s
[2K
| Adam | epoch: 004 | loss: 0.62881 - acc: 0.6432 -- iter: 128/140
[A[ATraining Step: 20  | total loss: [1m[32m0.65268[0m[0m | time: 3.621s
[2K
| Adam | epoch: 004 | loss: 0.65268 - acc: 0.5771 | val_loss: 0.68965 - val_acc: 0.4318 -- iter: 140/140
--
Training Step: 21  | total loss: [1m[32m0.65696[0m[0m | time: 0.662s
[2K
| Adam | epoch: 005 | loss: 0.65696 - acc: 0.5629 -- iter: 032/140
[A[ATraining Step: 22  | total loss: [1m[32m0.66680[0m[0m | time: 1.347s
[2K
| Adam | epoch: 005 | loss: 0.66680 - acc: 0.5253 -- iter: 064/140
[A[ATraining Step: 23  | total loss: [1m[32m0.63718[0m[0m | time: 1.612s
[2K
| Adam | epoch: 005 | loss: 0.63718 - acc: 0.5633 -- iter: 096/140
[A[ATraining Step: 24  | total loss: [1m[32m0.59934[0m[0m | time: 1.870s
[2K
| Adam | epoch: 005 | loss: 0.59934 - acc: 0.6392 -- iter: 128/140
[A[ATraining Step: 25  | total loss: [1m[32m0.56667[0m[0m | time: 3.517s
[2K
| Adam | epoch: 005 | loss: 0.56667 - acc: 0.6922 | val_loss: 0.61228 - val_acc: 0.4318 -- iter: 140/140
--
Training Step: 26  | total loss: [1m[32m0.57851[0m[0m | time: 0.660s
[2K
| Adam | epoch: 006 | loss: 0.57851 - acc: 0.6248 -- iter: 032/140
[A[ATraining Step: 27  | total loss: [1m[32m0.59468[0m[0m | time: 1.327s
[2K
| Adam | epoch: 006 | loss: 0.59468 - acc: 0.5686 -- iter: 064/140
[A[ATraining Step: 28  | total loss: [1m[32m0.57446[0m[0m | time: 1.982s
[2K
| Adam | epoch: 006 | loss: 0.57446 - acc: 0.5749 -- iter: 096/140
[A[ATraining Step: 29  | total loss: [1m[32m0.55679[0m[0m | time: 2.246s
[2K
| Adam | epoch: 006 | loss: 0.55679 - acc: 0.6403 -- iter: 128/140
[A[ATraining Step: 30  | total loss: [1m[32m0.54079[0m[0m | time: 3.498s
[2K
| Adam | epoch: 006 | loss: 0.54079 - acc: 0.7255 | val_loss: 0.45531 - val_acc: 0.9545 -- iter: 140/140
--
Training Step: 31  | total loss: [1m[32m0.52240[0m[0m | time: 0.681s
[2K
| Adam | epoch: 007 | loss: 0.52240 - acc: 0.7888 -- iter: 032/140
[A[ATraining Step: 32  | total loss: [1m[32m0.51596[0m[0m | time: 1.340s
[2K
| Adam | epoch: 007 | loss: 0.51596 - acc: 0.8152 -- iter: 064/140
[A[ATraining Step: 33  | total loss: [1m[32m0.49124[0m[0m | time: 1.996s
[2K
| Adam | epoch: 007 | loss: 0.49124 - acc: 0.8352 -- iter: 096/140
[A[ATraining Step: 34  | total loss: [1m[32m0.46485[0m[0m | time: 2.655s
[2K
| Adam | epoch: 007 | loss: 0.46485 - acc: 0.8437 -- iter: 128/140
[A[ATraining Step: 35  | total loss: [1m[32m0.57407[0m[0m | time: 3.917s
[2K
| Adam | epoch: 007 | loss: 0.57407 - acc: 0.7980 | val_loss: 0.33966 - val_acc: 0.8864 -- iter: 140/140
--
Training Step: 36  | total loss: [1m[32m0.53761[0m[0m | time: 0.271s
[2K
| Adam | epoch: 008 | loss: 0.53761 - acc: 0.8222 -- iter: 032/140
[A[ATraining Step: 37  | total loss: [1m[32m0.51362[0m[0m | time: 0.914s
[2K
| Adam | epoch: 008 | loss: 0.51362 - acc: 0.8245 -- iter: 064/140
[A[ATraining Step: 38  | total loss: [1m[32m0.48718[0m[0m | time: 1.583s
[2K
| Adam | epoch: 008 | loss: 0.48718 - acc: 0.8221 -- iter: 096/140
[A[ATraining Step: 39  | total loss: [1m[32m0.44237[0m[0m | time: 2.253s
[2K
| Adam | epoch: 008 | loss: 0.44237 - acc: 0.8322 -- iter: 128/140
[A[ATraining Step: 40  | total loss: [1m[32m0.48786[0m[0m | time: 3.948s
[2K
| Adam | epoch: 008 | loss: 0.48786 - acc: 0.8227 | val_loss: 0.22847 - val_acc: 0.9545 -- iter: 140/140
--
Training Step: 41  | total loss: [1m[32m0.45024[0m[0m | time: 0.270s
[2K
| Adam | epoch: 009 | loss: 0.45024 - acc: 0.8438 -- iter: 032/140
[A[ATraining Step: 42  | total loss: [1m[32m0.40937[0m[0m | time: 0.540s
[2K
| Adam | epoch: 009 | loss: 0.40937 - acc: 0.8569 -- iter: 064/140
[A[ATraining Step: 43  | total loss: [1m[32m0.36773[0m[0m | time: 1.194s
[2K
| Adam | epoch: 009 | loss: 0.36773 - acc: 0.8674 -- iter: 096/140
[A[ATraining Step: 44  | total loss: [1m[32m0.34873[0m[0m | time: 1.865s
[2K
| Adam | epoch: 009 | loss: 0.34873 - acc: 0.8796 -- iter: 128/140
[A[ATraining Step: 45  | total loss: [1m[32m0.33783[0m[0m | time: 3.533s
[2K
| Adam | epoch: 009 | loss: 0.33783 - acc: 0.8841 | val_loss: 0.16040 - val_acc: 0.9091 -- iter: 140/140
--
Training Step: 46  | total loss: [1m[32m0.31005[0m[0m | time: 0.673s
[2K
| Adam | epoch: 010 | loss: 0.31005 - acc: 0.8826 -- iter: 032/140
[A[ATraining Step: 47  | total loss: [1m[32m0.30665[0m[0m | time: 0.956s
[2K
| Adam | epoch: 010 | loss: 0.30665 - acc: 0.8813 -- iter: 064/140
[A[ATraining Step: 48  | total loss: [1m[32m0.27681[0m[0m | time: 1.219s
[2K
| Adam | epoch: 010 | loss: 0.27681 - acc: 0.9004 -- iter: 096/140
[A[ATraining Step: 49  | total loss: [1m[32m0.25404[0m[0m | time: 1.918s
[2K
| Adam | epoch: 010 | loss: 0.25404 - acc: 0.9161 -- iter: 128/140
[A[ATraining Step: 50  | total loss: [1m[32m0.26080[0m[0m | time: 3.575s
[2K
| Adam | epoch: 010 | loss: 0.26080 - acc: 0.9098 | val_loss: 0.20153 - val_acc: 0.9545 -- iter: 140/140
--
Training Step: 51  | total loss: [1m[32m0.26277[0m[0m | time: 0.664s
[2K
| Adam | epoch: 011 | loss: 0.26277 - acc: 0.9092 -- iter: 032/140
[A[ATraining Step: 52  | total loss: [1m[32m0.28759[0m[0m | time: 1.332s
[2K
| Adam | epoch: 011 | loss: 0.28759 - acc: 0.9135 -- iter: 064/140
[A[ATraining Step: 53  | total loss: [1m[32m0.28284[0m[0m | time: 1.607s
[2K
| Adam | epoch: 011 | loss: 0.28284 - acc: 0.9078 -- iter: 096/140
[A[ATraining Step: 54  | total loss: [1m[32m0.25012[0m[0m | time: 1.891s
[2K
| Adam | epoch: 011 | loss: 0.25012 - acc: 0.9212 -- iter: 128/140
[A[ATraining Step: 55  | total loss: [1m[32m0.22714[0m[0m | time: 3.578s
[2K
| Adam | epoch: 011 | loss: 0.22714 - acc: 0.9324 | val_loss: 0.24534 - val_acc: 0.8864 -- iter: 140/140
--
Training Step: 56  | total loss: [1m[32m0.23312[0m[0m | time: 0.665s
[2K
| Adam | epoch: 012 | loss: 0.23312 - acc: 0.9331 -- iter: 032/140
[A[ATraining Step: 57  | total loss: [1m[32m0.24470[0m[0m | time: 1.332s
[2K
| Adam | epoch: 012 | loss: 0.24470 - acc: 0.9294 -- iter: 064/140
[A[ATraining Step: 58  | total loss: [1m[32m0.25061[0m[0m | time: 1.983s
[2K
| Adam | epoch: 012 | loss: 0.25061 - acc: 0.9263 -- iter: 096/140
[A[ATraining Step: 59  | total loss: [1m[32m0.24242[0m[0m | time: 2.266s
[2K
| Adam | epoch: 012 | loss: 0.24242 - acc: 0.9278 -- iter: 128/140
[A[ATraining Step: 60  | total loss: [1m[32m0.29021[0m[0m | time: 3.536s
[2K
| Adam | epoch: 012 | loss: 0.29021 - acc: 0.9042 | val_loss: 0.20278 - val_acc: 0.9091 -- iter: 140/140
--
Training Step: 61  | total loss: [1m[32m0.32438[0m[0m | time: 0.667s
[2K
| Adam | epoch: 013 | loss: 0.32438 - acc: 0.8841 -- iter: 032/140
[A[ATraining Step: 62  | total loss: [1m[32m0.30186[0m[0m | time: 1.346s
[2K
| Adam | epoch: 013 | loss: 0.30186 - acc: 0.8910 -- iter: 064/140
[A[ATraining Step: 63  | total loss: [1m[32m0.29596[0m[0m | time: 2.019s
[2K
| Adam | epoch: 013 | loss: 0.29596 - acc: 0.8850 -- iter: 096/140
[A[ATraining Step: 64  | total loss: [1m[32m0.28912[0m[0m | time: 2.706s
[2K
| Adam | epoch: 013 | loss: 0.28912 - acc: 0.8877 -- iter: 128/140
[A[ATraining Step: 65  | total loss: [1m[32m0.26652[0m[0m | time: 3.968s
[2K
| Adam | epoch: 013 | loss: 0.26652 - acc: 0.9015 | val_loss: 0.22815 - val_acc: 0.9091 -- iter: 140/140
--
Training Step: 66  | total loss: [1m[32m0.29338[0m[0m | time: 0.272s
[2K
| Adam | epoch: 014 | loss: 0.29338 - acc: 0.8932 -- iter: 032/140
[A[ATraining Step: 67  | total loss: [1m[32m0.31101[0m[0m | time: 0.922s
[2K
| Adam | epoch: 014 | loss: 0.31101 - acc: 0.8860 -- iter: 064/140
[A[ATraining Step: 68  | total loss: [1m[32m0.29987[0m[0m | time: 1.593s
[2K
| Adam | epoch: 014 | loss: 0.29987 - acc: 0.8921 -- iter: 096/140
[A[ATraining Step: 69  | total loss: [1m[32m0.29870[0m[0m | time: 2.249s
[2K
| Adam | epoch: 014 | loss: 0.29870 - acc: 0.8938 -- iter: 128/140
[A[ATraining Step: 70  | total loss: [1m[32m0.31484[0m[0m | time: 3.913s
[2K
| Adam | epoch: 014 | loss: 0.31484 - acc: 0.8916 | val_loss: 0.25019 - val_acc: 0.9318 -- iter: 140/140
--
Training Step: 71  | total loss: [1m[32m0.30882[0m[0m | time: 0.282s
[2K
| Adam | epoch: 015 | loss: 0.30882 - acc: 0.8933 -- iter: 032/140
[A[ATraining Step: 72  | total loss: [1m[32m0.30328[0m[0m | time: 0.547s
[2K
| Adam | epoch: 015 | loss: 0.30328 - acc: 0.8959 -- iter: 064/140
[A[ATraining Step: 73  | total loss: [1m[32m0.29797[0m[0m | time: 1.201s
[2K
| Adam | epoch: 015 | loss: 0.29797 - acc: 0.8982 -- iter: 096/140
[A[ATraining Step: 74  | total loss: [1m[32m0.28259[0m[0m | time: 1.959s
[2K
| Adam | epoch: 015 | loss: 0.28259 - acc: 0.9060 -- iter: 128/140
[A[ATraining Step: 75  | total loss: [1m[32m0.27447[0m[0m | time: 3.664s
[2K
| Adam | epoch: 015 | loss: 0.27447 - acc: 0.9094 | val_loss: 0.20817 - val_acc: 0.9318 -- iter: 140/140
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9873684210526316
Validation AUPRC:0.9914058355437667
Test AUC:0.9557894736842105
Test AUPRC:0.9647034252297408
BestTestF1Score	0.88	0.82	0.91	1.0	0.79	15	0	25	4	0.86
BestTestMCCScore	0.88	0.82	0.91	1.0	0.79	15	0	25	4	0.86
BestTestAccuracyScore	0.88	0.82	0.91	1.0	0.79	15	0	25	4	0.86
BestValidationF1Score	0.96	0.91	0.95	1.0	0.92	23	0	19	2	0.86
BestValidationMCC	0.96	0.91	0.95	1.0	0.92	23	0	19	2	0.86
BestValidationAccuracy	0.96	0.91	0.95	1.0	0.92	23	0	19	2	0.86
TestPredictions (Threshold:0.86)
CHEMBL562342,TN,INACT,0.0	CHEMBL119039,TP,ACT,0.9100000262260437	CHEMBL524322,TN,INACT,0.029999999329447746	CHEMBL268099,TP,ACT,0.8700000047683716	CHEMBL326271,TP,ACT,0.8899999856948853	CHEMBL2372113,TN,INACT,0.0	CHEMBL268530,TP,ACT,0.8600000143051147	CHEMBL119886,TP,ACT,0.8999999761581421	CHEMBL3629608,TN,INACT,0.029999999329447746	CHEMBL325286,FN,ACT,0.009999999776482582	CHEMBL391051,TN,INACT,0.0	CHEMBL118299,TP,ACT,0.8999999761581421	CHEMBL104264,TN,INACT,0.5600000023841858	CHEMBL328452,TN,INACT,0.07000000029802322	CHEMBL117453,TP,ACT,0.8999999761581421	CHEMBL558859,TN,INACT,0.009999999776482582	CHEMBL86921,TN,INACT,0.4099999964237213	CHEMBL2086728,TN,INACT,0.009999999776482582	CHEMBL324133,TP,ACT,0.8799999952316284	CHEMBL326712,TP,ACT,0.9100000262260437	CHEMBL398243,TN,INACT,0.0	CHEMBL6381,FN,ACT,0.8500000238418579	CHEMBL323832,FN,ACT,0.1899999976158142	CHEMBL485320,TN,INACT,0.029999999329447746	CHEMBL442728,TN,INACT,0.009999999776482582	CHEMBL3318026,TN,INACT,0.8399999737739563	CHEMBL1836309,TN,INACT,0.07999999821186066	CHEMBL1684370,TN,INACT,0.0	CHEMBL267127,FN,ACT,0.800000011920929	CHEMBL434222,TP,ACT,0.8999999761581421	CHEMBL1097190,TN,INACT,0.019999999552965164	CHEMBL267678,TP,ACT,0.8999999761581421	CHEMBL399914,TN,INACT,0.0	CHEMBL1668417,TN,INACT,0.009999999776482582	CHEMBL86631,TN,INACT,0.15000000596046448	CHEMBL326771,TP,ACT,0.8999999761581421	CHEMBL118074,TP,ACT,0.8899999856948853	CHEMBL1956888,TN,INACT,0.03999999910593033	CHEMBL1836311,TN,INACT,0.009999999776482582	CHEMBL3629607,TN,INACT,0.019999999552965164	CHEMBL550608,TN,INACT,0.009999999776482582	CHEMBL118113,TP,ACT,0.8999999761581421	CHEMBL558460,TN,INACT,0.009999999776482582	CHEMBL115637,TP,ACT,0.9200000166893005	

