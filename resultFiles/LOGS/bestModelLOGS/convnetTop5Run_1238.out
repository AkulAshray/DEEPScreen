CNNModel CHEMBL2000 adam 0.0005 30 256 0 0.6 False True
Number of active compounds :	238
Number of inactive compounds :	238
---------------------------------
Run id: CNNModel_CHEMBL2000_adam_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2000_adam_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 293
Validation samples: 92
--
Training Step: 1  | time: 1.473s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/293
[A[ATraining Step: 2  | total loss: [1m[32m0.62370[0m[0m | time: 2.337s
[2K
| Adam | epoch: 001 | loss: 0.62370 - acc: 0.4781 -- iter: 064/293
[A[ATraining Step: 3  | total loss: [1m[32m0.68167[0m[0m | time: 3.499s
[2K
| Adam | epoch: 001 | loss: 0.68167 - acc: 0.4449 -- iter: 096/293
[A[ATraining Step: 4  | total loss: [1m[32m0.69070[0m[0m | time: 4.515s
[2K
| Adam | epoch: 001 | loss: 0.69070 - acc: 0.4628 -- iter: 128/293
[A[ATraining Step: 5  | total loss: [1m[32m0.69245[0m[0m | time: 5.431s
[2K
| Adam | epoch: 001 | loss: 0.69245 - acc: 0.4885 -- iter: 160/293
[A[ATraining Step: 6  | total loss: [1m[32m0.69275[0m[0m | time: 6.373s
[2K
| Adam | epoch: 001 | loss: 0.69275 - acc: 0.5763 -- iter: 192/293
[A[ATraining Step: 7  | total loss: [1m[32m0.69266[0m[0m | time: 7.302s
[2K
| Adam | epoch: 001 | loss: 0.69266 - acc: 0.5493 -- iter: 224/293
[A[ATraining Step: 8  | total loss: [1m[32m0.69379[0m[0m | time: 8.400s
[2K
| Adam | epoch: 001 | loss: 0.69379 - acc: 0.4864 -- iter: 256/293
[A[ATraining Step: 9  | total loss: [1m[32m0.69413[0m[0m | time: 9.443s
[2K
| Adam | epoch: 001 | loss: 0.69413 - acc: 0.4605 -- iter: 288/293
[A[ATraining Step: 10  | total loss: [1m[32m0.69398[0m[0m | time: 10.770s
[2K
| Adam | epoch: 001 | loss: 0.69398 - acc: 0.4646 | val_loss: 0.69300 - val_acc: 0.5109 -- iter: 293/293
--
Training Step: 11  | total loss: [1m[32m0.69157[0m[0m | time: 0.262s
[2K
| Adam | epoch: 002 | loss: 0.69157 - acc: 0.6235 -- iter: 032/293
[A[ATraining Step: 12  | total loss: [1m[32m0.69311[0m[0m | time: 1.241s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5229 -- iter: 064/293
[A[ATraining Step: 13  | total loss: [1m[32m0.69277[0m[0m | time: 2.127s
[2K
| Adam | epoch: 002 | loss: 0.69277 - acc: 0.5399 -- iter: 096/293
[A[ATraining Step: 14  | total loss: [1m[32m0.69183[0m[0m | time: 3.101s
[2K
| Adam | epoch: 002 | loss: 0.69183 - acc: 0.5747 -- iter: 128/293
[A[ATraining Step: 15  | total loss: [1m[32m0.69359[0m[0m | time: 4.095s
[2K
| Adam | epoch: 002 | loss: 0.69359 - acc: 0.5088 -- iter: 160/293
[A[ATraining Step: 16  | total loss: [1m[32m0.69427[0m[0m | time: 5.076s
[2K
| Adam | epoch: 002 | loss: 0.69427 - acc: 0.4821 -- iter: 192/293
[A[ATraining Step: 17  | total loss: [1m[32m0.69498[0m[0m | time: 6.179s
[2K
| Adam | epoch: 002 | loss: 0.69498 - acc: 0.4548 -- iter: 224/293
[A[ATraining Step: 18  | total loss: [1m[32m0.69354[0m[0m | time: 7.256s
[2K
| Adam | epoch: 002 | loss: 0.69354 - acc: 0.5029 -- iter: 256/293
[A[ATraining Step: 19  | total loss: [1m[32m0.69395[0m[0m | time: 8.095s
[2K
| Adam | epoch: 002 | loss: 0.69395 - acc: 0.4811 -- iter: 288/293
[A[ATraining Step: 20  | total loss: [1m[32m0.69215[0m[0m | time: 10.250s
[2K
| Adam | epoch: 002 | loss: 0.69215 - acc: 0.5575 | val_loss: 0.69293 - val_acc: 0.5109 -- iter: 293/293
--
Training Step: 21  | total loss: [1m[32m0.69292[0m[0m | time: 0.224s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5202 -- iter: 032/293
[A[ATraining Step: 22  | total loss: [1m[32m0.69370[0m[0m | time: 0.449s
[2K
| Adam | epoch: 003 | loss: 0.69370 - acc: 0.4842 -- iter: 064/293
[A[ATraining Step: 23  | total loss: [1m[32m0.69284[0m[0m | time: 1.430s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5178 -- iter: 096/293
[A[ATraining Step: 24  | total loss: [1m[32m0.69314[0m[0m | time: 2.503s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.5040 -- iter: 128/293
[A[ATraining Step: 25  | total loss: [1m[32m0.69313[0m[0m | time: 3.577s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5029 -- iter: 160/293
[A[ATraining Step: 26  | total loss: [1m[32m0.69238[0m[0m | time: 4.365s
[2K
| Adam | epoch: 003 | loss: 0.69238 - acc: 0.5352 -- iter: 192/293
[A[ATraining Step: 27  | total loss: [1m[32m0.69175[0m[0m | time: 5.474s
[2K
| Adam | epoch: 003 | loss: 0.69175 - acc: 0.5583 -- iter: 224/293
[A[ATraining Step: 28  | total loss: [1m[32m0.69193[0m[0m | time: 6.566s
[2K
| Adam | epoch: 003 | loss: 0.69193 - acc: 0.5515 -- iter: 256/293
[A[ATraining Step: 29  | total loss: [1m[32m0.69247[0m[0m | time: 7.642s
[2K
| Adam | epoch: 003 | loss: 0.69247 - acc: 0.5314 -- iter: 288/293
[A[ATraining Step: 30  | total loss: [1m[32m0.69401[0m[0m | time: 9.644s
[2K
| Adam | epoch: 003 | loss: 0.69401 - acc: 0.4870 | val_loss: 0.69286 - val_acc: 0.5109 -- iter: 293/293
--
Training Step: 31  | total loss: [1m[32m0.69480[0m[0m | time: 0.945s
[2K
| Adam | epoch: 004 | loss: 0.69480 - acc: 0.4611 -- iter: 032/293
[A[ATraining Step: 32  | total loss: [1m[32m0.69338[0m[0m | time: 1.171s
[2K
| Adam | epoch: 004 | loss: 0.69338 - acc: 0.5050 -- iter: 064/293
[A[ATraining Step: 33  | total loss: [1m[32m0.69288[0m[0m | time: 1.419s
[2K
| Adam | epoch: 004 | loss: 0.69288 - acc: 0.5259 -- iter: 096/293
[A[ATraining Step: 34  | total loss: [1m[32m0.69234[0m[0m | time: 2.482s
[2K
| Adam | epoch: 004 | loss: 0.69234 - acc: 0.5418 -- iter: 128/293
[A[ATraining Step: 35  | total loss: [1m[32m0.69292[0m[0m | time: 3.507s
[2K
| Adam | epoch: 004 | loss: 0.69292 - acc: 0.5199 -- iter: 160/293
[A[ATraining Step: 36  | total loss: [1m[32m0.69299[0m[0m | time: 4.150s
[2K
| Adam | epoch: 004 | loss: 0.69299 - acc: 0.5159 -- iter: 192/293
[A[ATraining Step: 37  | total loss: [1m[32m0.69283[0m[0m | time: 4.767s
[2K
| Adam | epoch: 004 | loss: 0.69283 - acc: 0.5189 -- iter: 224/293
[A[ATraining Step: 38  | total loss: [1m[32m0.69306[0m[0m | time: 5.450s
[2K
| Adam | epoch: 004 | loss: 0.69306 - acc: 0.5091 -- iter: 256/293
[A[ATraining Step: 39  | total loss: [1m[32m0.69341[0m[0m | time: 6.074s
[2K
| Adam | epoch: 004 | loss: 0.69341 - acc: 0.4954 -- iter: 288/293
[A[ATraining Step: 40  | total loss: [1m[32m0.69317[0m[0m | time: 7.696s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5021 | val_loss: 0.69269 - val_acc: 0.5109 -- iter: 293/293
--
Training Step: 41  | total loss: [1m[32m0.69330[0m[0m | time: 0.625s
[2K
| Adam | epoch: 005 | loss: 0.69330 - acc: 0.4960 -- iter: 032/293
[A[ATraining Step: 42  | total loss: [1m[32m0.69245[0m[0m | time: 1.233s
[2K
| Adam | epoch: 005 | loss: 0.69245 - acc: 0.5248 -- iter: 064/293
[A[ATraining Step: 43  | total loss: [1m[32m0.69225[0m[0m | time: 1.375s
[2K
| Adam | epoch: 005 | loss: 0.69225 - acc: 0.5315 -- iter: 096/293
[A[ATraining Step: 44  | total loss: [1m[32m0.69189[0m[0m | time: 1.512s
[2K
| Adam | epoch: 005 | loss: 0.69189 - acc: 0.5433 -- iter: 128/293
[A[ATraining Step: 45  | total loss: [1m[32m0.69390[0m[0m | time: 2.151s
[2K
| Adam | epoch: 005 | loss: 0.69390 - acc: 0.4850 -- iter: 160/293
[A[ATraining Step: 46  | total loss: [1m[32m0.69426[0m[0m | time: 2.780s
[2K
| Adam | epoch: 005 | loss: 0.69426 - acc: 0.4719 -- iter: 192/293
[A[ATraining Step: 47  | total loss: [1m[32m0.69356[0m[0m | time: 3.435s
[2K
| Adam | epoch: 005 | loss: 0.69356 - acc: 0.4918 -- iter: 224/293
[A[ATraining Step: 48  | total loss: [1m[32m0.69410[0m[0m | time: 4.049s
[2K
| Adam | epoch: 005 | loss: 0.69410 - acc: 0.4630 -- iter: 256/293
[A[ATraining Step: 49  | total loss: [1m[32m0.69374[0m[0m | time: 4.680s
[2K
| Adam | epoch: 005 | loss: 0.69374 - acc: 0.4738 -- iter: 288/293
[A[ATraining Step: 50  | total loss: [1m[32m0.69329[0m[0m | time: 6.301s
[2K
| Adam | epoch: 005 | loss: 0.69329 - acc: 0.4973 | val_loss: 0.69240 - val_acc: 0.5109 -- iter: 293/293
--
Training Step: 51  | total loss: [1m[32m0.69326[0m[0m | time: 0.673s
[2K
| Adam | epoch: 006 | loss: 0.69326 - acc: 0.4929 -- iter: 032/293
[A[ATraining Step: 52  | total loss: [1m[32m0.69306[0m[0m | time: 1.279s
[2K
| Adam | epoch: 006 | loss: 0.69306 - acc: 0.4987 -- iter: 064/293
[A[ATraining Step: 53  | total loss: [1m[32m0.69304[0m[0m | time: 2.007s
[2K
| Adam | epoch: 006 | loss: 0.69304 - acc: 0.4989 -- iter: 096/293
[A[ATraining Step: 54  | total loss: [1m[32m0.69238[0m[0m | time: 2.148s
[2K
| Adam | epoch: 006 | loss: 0.69238 - acc: 0.5262 -- iter: 128/293
[A[ATraining Step: 55  | total loss: [1m[32m0.69347[0m[0m | time: 2.299s
[2K
| Adam | epoch: 006 | loss: 0.69347 - acc: 0.4796 -- iter: 160/293
[A[ATraining Step: 56  | total loss: [1m[32m0.69223[0m[0m | time: 3.305s
[2K
| Adam | epoch: 006 | loss: 0.69223 - acc: 0.5247 -- iter: 192/293
[A[ATraining Step: 57  | total loss: [1m[32m0.69162[0m[0m | time: 4.402s
[2K
| Adam | epoch: 006 | loss: 0.69162 - acc: 0.5386 -- iter: 224/293
[A[ATraining Step: 58  | total loss: [1m[32m0.69219[0m[0m | time: 5.479s
[2K
| Adam | epoch: 006 | loss: 0.69219 - acc: 0.5205 -- iter: 256/293
[A[ATraining Step: 59  | total loss: [1m[32m0.69296[0m[0m | time: 6.387s
[2K
| Adam | epoch: 006 | loss: 0.69296 - acc: 0.4968 -- iter: 288/293
[A[ATraining Step: 60  | total loss: [1m[32m0.69249[0m[0m | time: 8.331s
[2K
| Adam | epoch: 006 | loss: 0.69249 - acc: 0.4972 | val_loss: 0.69116 - val_acc: 0.5109 -- iter: 293/293
--
Training Step: 61  | total loss: [1m[32m0.69232[0m[0m | time: 0.928s
[2K
| Adam | epoch: 007 | loss: 0.69232 - acc: 0.4976 -- iter: 032/293
[A[ATraining Step: 62  | total loss: [1m[32m0.69176[0m[0m | time: 2.067s
[2K
| Adam | epoch: 007 | loss: 0.69176 - acc: 0.5180 -- iter: 064/293
[A[ATraining Step: 63  | total loss: [1m[32m0.69145[0m[0m | time: 3.123s
[2K
| Adam | epoch: 007 | loss: 0.69145 - acc: 0.5236 -- iter: 096/293
[A[ATraining Step: 64  | total loss: [1m[32m0.69096[0m[0m | time: 4.015s
[2K
| Adam | epoch: 007 | loss: 0.69096 - acc: 0.5246 -- iter: 128/293
[A[ATraining Step: 65  | total loss: [1m[32m0.69136[0m[0m | time: 4.211s
[2K
| Adam | epoch: 007 | loss: 0.69136 - acc: 0.5138 -- iter: 160/293
[A[ATraining Step: 66  | total loss: [1m[32m0.68842[0m[0m | time: 4.407s
[2K
| Adam | epoch: 007 | loss: 0.68842 - acc: 0.5486 -- iter: 192/293
[A[ATraining Step: 67  | total loss: [1m[32m0.68790[0m[0m | time: 5.397s
[2K
| Adam | epoch: 007 | loss: 0.68790 - acc: 0.5548 -- iter: 224/293
[A[ATraining Step: 68  | total loss: [1m[32m0.68821[0m[0m | time: 6.433s
[2K
| Adam | epoch: 007 | loss: 0.68821 - acc: 0.5483 -- iter: 256/293
[A[ATraining Step: 69  | total loss: [1m[32m0.68685[0m[0m | time: 7.454s
[2K
| Adam | epoch: 007 | loss: 0.68685 - acc: 0.5500 -- iter: 288/293
[A[ATraining Step: 70  | total loss: [1m[32m0.68552[0m[0m | time: 9.597s
[2K
| Adam | epoch: 007 | loss: 0.68552 - acc: 0.5478 | val_loss: 0.68116 - val_acc: 0.6087 -- iter: 293/293
--
Training Step: 71  | total loss: [1m[32m0.68593[0m[0m | time: 0.996s
[2K
| Adam | epoch: 008 | loss: 0.68593 - acc: 0.5388 -- iter: 032/293
[A[ATraining Step: 72  | total loss: [1m[32m0.68468[0m[0m | time: 2.061s
[2K
| Adam | epoch: 008 | loss: 0.68468 - acc: 0.5520 -- iter: 064/293
[A[ATraining Step: 73  | total loss: [1m[32m0.68290[0m[0m | time: 3.096s
[2K
| Adam | epoch: 008 | loss: 0.68290 - acc: 0.5740 -- iter: 096/293
[A[ATraining Step: 74  | total loss: [1m[32m0.68250[0m[0m | time: 3.980s
[2K
| Adam | epoch: 008 | loss: 0.68250 - acc: 0.5693 -- iter: 128/293
[A[ATraining Step: 75  | total loss: [1m[32m0.67880[0m[0m | time: 5.013s
[2K
| Adam | epoch: 008 | loss: 0.67880 - acc: 0.5787 -- iter: 160/293
[A[ATraining Step: 76  | total loss: [1m[32m0.69021[0m[0m | time: 5.237s
[2K
| Adam | epoch: 008 | loss: 0.69021 - acc: 0.5569 -- iter: 192/293
[A[ATraining Step: 77  | total loss: [1m[32m0.68031[0m[0m | time: 5.487s
[2K
| Adam | epoch: 008 | loss: 0.68031 - acc: 0.5827 -- iter: 224/293
[A[ATraining Step: 78  | total loss: [1m[32m0.67641[0m[0m | time: 6.592s
[2K
| Adam | epoch: 008 | loss: 0.67641 - acc: 0.5845 -- iter: 256/293
[A[ATraining Step: 79  | total loss: [1m[32m0.67482[0m[0m | time: 7.625s
[2K
| Adam | epoch: 008 | loss: 0.67482 - acc: 0.6016 -- iter: 288/293
[A[ATraining Step: 80  | total loss: [1m[32m0.67436[0m[0m | time: 9.550s
[2K
| Adam | epoch: 008 | loss: 0.67436 - acc: 0.6072 | val_loss: 0.67595 - val_acc: 0.6087 -- iter: 293/293
--
Training Step: 81  | total loss: [1m[32m0.67614[0m[0m | time: 0.915s
[2K
| Adam | epoch: 009 | loss: 0.67614 - acc: 0.5963 -- iter: 032/293
[A[ATraining Step: 82  | total loss: [1m[32m0.67386[0m[0m | time: 1.828s
[2K
| Adam | epoch: 009 | loss: 0.67386 - acc: 0.6055 -- iter: 064/293
[A[ATraining Step: 83  | total loss: [1m[32m0.67538[0m[0m | time: 2.903s
[2K
| Adam | epoch: 009 | loss: 0.67538 - acc: 0.5918 -- iter: 096/293
[A[ATraining Step: 84  | total loss: [1m[32m0.67498[0m[0m | time: 4.017s
[2K
| Adam | epoch: 009 | loss: 0.67498 - acc: 0.5920 -- iter: 128/293
[A[ATraining Step: 85  | total loss: [1m[32m0.66915[0m[0m | time: 4.987s
[2K
| Adam | epoch: 009 | loss: 0.66915 - acc: 0.6047 -- iter: 160/293
[A[ATraining Step: 86  | total loss: [1m[32m0.65775[0m[0m | time: 5.912s
[2K
| Adam | epoch: 009 | loss: 0.65775 - acc: 0.6254 -- iter: 192/293
[A[ATraining Step: 87  | total loss: [1m[32m0.65924[0m[0m | time: 6.114s
[2K
| Adam | epoch: 009 | loss: 0.65924 - acc: 0.6254 -- iter: 224/293
[A[ATraining Step: 88  | total loss: [1m[32m0.65141[0m[0m | time: 6.331s
[2K
| Adam | epoch: 009 | loss: 0.65141 - acc: 0.6229 -- iter: 256/293
[A[ATraining Step: 89  | total loss: [1m[32m0.67125[0m[0m | time: 7.358s
[2K
| Adam | epoch: 009 | loss: 0.67125 - acc: 0.6006 -- iter: 288/293
[A[ATraining Step: 90  | total loss: [1m[32m0.66126[0m[0m | time: 9.450s
[2K
| Adam | epoch: 009 | loss: 0.66126 - acc: 0.6186 | val_loss: 0.65210 - val_acc: 0.5870 -- iter: 293/293
--
Training Step: 91  | total loss: [1m[32m0.65509[0m[0m | time: 0.629s
[2K
| Adam | epoch: 010 | loss: 0.65509 - acc: 0.6287 -- iter: 032/293
[A[ATraining Step: 92  | total loss: [1m[32m0.65254[0m[0m | time: 1.272s
[2K
| Adam | epoch: 010 | loss: 0.65254 - acc: 0.6283 -- iter: 064/293
[A[ATraining Step: 93  | total loss: [1m[32m0.65174[0m[0m | time: 1.888s
[2K
| Adam | epoch: 010 | loss: 0.65174 - acc: 0.6280 -- iter: 096/293
[A[ATraining Step: 94  | total loss: [1m[32m0.65485[0m[0m | time: 2.498s
[2K
| Adam | epoch: 010 | loss: 0.65485 - acc: 0.6214 -- iter: 128/293
[A[ATraining Step: 95  | total loss: [1m[32m0.66433[0m[0m | time: 3.113s
[2K
| Adam | epoch: 010 | loss: 0.66433 - acc: 0.6061 -- iter: 160/293
[A[ATraining Step: 96  | total loss: [1m[32m0.66428[0m[0m | time: 3.752s
[2K
| Adam | epoch: 010 | loss: 0.66428 - acc: 0.6049 -- iter: 192/293
[A[ATraining Step: 97  | total loss: [1m[32m0.66348[0m[0m | time: 4.381s
[2K
| Adam | epoch: 010 | loss: 0.66348 - acc: 0.6069 -- iter: 224/293
[A[ATraining Step: 98  | total loss: [1m[32m0.65718[0m[0m | time: 4.520s
[2K
| Adam | epoch: 010 | loss: 0.65718 - acc: 0.6212 -- iter: 256/293
[A[ATraining Step: 99  | total loss: [1m[32m0.65642[0m[0m | time: 4.665s
[2K
| Adam | epoch: 010 | loss: 0.65642 - acc: 0.6391 -- iter: 288/293
[A[ATraining Step: 100  | total loss: [1m[32m0.66753[0m[0m | time: 6.284s
[2K
| Adam | epoch: 010 | loss: 0.66753 - acc: 0.6152 | val_loss: 0.64070 - val_acc: 0.6196 -- iter: 293/293
--
Training Step: 101  | total loss: [1m[32m0.66474[0m[0m | time: 0.628s
[2K
| Adam | epoch: 011 | loss: 0.66474 - acc: 0.6162 -- iter: 032/293
[A[ATraining Step: 102  | total loss: [1m[32m0.66227[0m[0m | time: 1.244s
[2K
| Adam | epoch: 011 | loss: 0.66227 - acc: 0.6202 -- iter: 064/293
[A[ATraining Step: 103  | total loss: [1m[32m0.65680[0m[0m | time: 1.877s
[2K
| Adam | epoch: 011 | loss: 0.65680 - acc: 0.6332 -- iter: 096/293
[A[ATraining Step: 104  | total loss: [1m[32m0.65277[0m[0m | time: 2.514s
[2K
| Adam | epoch: 011 | loss: 0.65277 - acc: 0.6480 -- iter: 128/293
[A[ATraining Step: 105  | total loss: [1m[32m0.65328[0m[0m | time: 3.170s
[2K
| Adam | epoch: 011 | loss: 0.65328 - acc: 0.6394 -- iter: 160/293
[A[ATraining Step: 106  | total loss: [1m[32m0.64797[0m[0m | time: 3.776s
[2K
| Adam | epoch: 011 | loss: 0.64797 - acc: 0.6474 -- iter: 192/293
[A[ATraining Step: 107  | total loss: [1m[32m0.63917[0m[0m | time: 4.389s
[2K
| Adam | epoch: 011 | loss: 0.63917 - acc: 0.6639 -- iter: 224/293
[A[ATraining Step: 108  | total loss: [1m[32m0.63549[0m[0m | time: 5.005s
[2K
| Adam | epoch: 011 | loss: 0.63549 - acc: 0.6662 -- iter: 256/293
[A[ATraining Step: 109  | total loss: [1m[32m0.62377[0m[0m | time: 5.134s
[2K
| Adam | epoch: 011 | loss: 0.62377 - acc: 0.6840 -- iter: 288/293
[A[ATraining Step: 110  | total loss: [1m[32m0.62497[0m[0m | time: 6.282s
[2K
| Adam | epoch: 011 | loss: 0.62497 - acc: 0.6756 | val_loss: 0.67341 - val_acc: 0.6413 -- iter: 293/293
--
Training Step: 111  | total loss: [1m[32m0.64589[0m[0m | time: 1.081s
[2K
| Adam | epoch: 012 | loss: 0.64589 - acc: 0.6480 -- iter: 032/293
[A[ATraining Step: 112  | total loss: [1m[32m0.64540[0m[0m | time: 2.199s
[2K
| Adam | epoch: 012 | loss: 0.64540 - acc: 0.6489 -- iter: 064/293
[A[ATraining Step: 113  | total loss: [1m[32m0.63912[0m[0m | time: 3.286s
[2K
| Adam | epoch: 012 | loss: 0.63912 - acc: 0.6558 -- iter: 096/293
[A[ATraining Step: 114  | total loss: [1m[32m0.63010[0m[0m | time: 4.126s
[2K
| Adam | epoch: 012 | loss: 0.63010 - acc: 0.6653 -- iter: 128/293
[A[ATraining Step: 115  | total loss: [1m[32m0.62996[0m[0m | time: 5.048s
[2K
| Adam | epoch: 012 | loss: 0.62996 - acc: 0.6644 -- iter: 160/293
[A[ATraining Step: 116  | total loss: [1m[32m0.62309[0m[0m | time: 6.042s
[2K
| Adam | epoch: 012 | loss: 0.62309 - acc: 0.6667 -- iter: 192/293
[A[ATraining Step: 117  | total loss: [1m[32m0.61053[0m[0m | time: 6.999s
[2K
| Adam | epoch: 012 | loss: 0.61053 - acc: 0.6781 -- iter: 224/293
[A[ATraining Step: 118  | total loss: [1m[32m0.60739[0m[0m | time: 8.165s
[2K
| Adam | epoch: 012 | loss: 0.60739 - acc: 0.6853 -- iter: 256/293
[A[ATraining Step: 119  | total loss: [1m[32m0.61713[0m[0m | time: 9.234s
[2K
| Adam | epoch: 012 | loss: 0.61713 - acc: 0.6730 -- iter: 288/293
[A[ATraining Step: 120  | total loss: [1m[32m0.61048[0m[0m | time: 10.404s
[2K
| Adam | epoch: 012 | loss: 0.61048 - acc: 0.6776 | val_loss: 0.59744 - val_acc: 0.6522 -- iter: 293/293
--
Training Step: 121  | total loss: [1m[32m0.61422[0m[0m | time: 0.222s
[2K
| Adam | epoch: 013 | loss: 0.61422 - acc: 0.6698 -- iter: 032/293
[A[ATraining Step: 122  | total loss: [1m[32m0.59725[0m[0m | time: 1.240s
[2K
| Adam | epoch: 013 | loss: 0.59725 - acc: 0.6829 -- iter: 064/293
[A[ATraining Step: 123  | total loss: [1m[32m0.59569[0m[0m | time: 2.264s
[2K
| Adam | epoch: 013 | loss: 0.59569 - acc: 0.6833 -- iter: 096/293
[A[ATraining Step: 124  | total loss: [1m[32m0.58443[0m[0m | time: 3.314s
[2K
| Adam | epoch: 013 | loss: 0.58443 - acc: 0.6994 -- iter: 128/293
[A[ATraining Step: 125  | total loss: [1m[32m0.56798[0m[0m | time: 4.193s
[2K
| Adam | epoch: 013 | loss: 0.56798 - acc: 0.7138 -- iter: 160/293
[A[ATraining Step: 126  | total loss: [1m[32m0.55809[0m[0m | time: 5.332s
[2K
| Adam | epoch: 013 | loss: 0.55809 - acc: 0.7174 -- iter: 192/293
[A[ATraining Step: 127  | total loss: [1m[32m0.54760[0m[0m | time: 6.413s
[2K
| Adam | epoch: 013 | loss: 0.54760 - acc: 0.7269 -- iter: 224/293
[A[ATraining Step: 128  | total loss: [1m[32m0.54911[0m[0m | time: 7.478s
[2K
| Adam | epoch: 013 | loss: 0.54911 - acc: 0.7292 -- iter: 256/293
[A[ATraining Step: 129  | total loss: [1m[32m0.55569[0m[0m | time: 8.363s
[2K
| Adam | epoch: 013 | loss: 0.55569 - acc: 0.7282 -- iter: 288/293
[A[ATraining Step: 130  | total loss: [1m[32m0.55712[0m[0m | time: 10.309s
[2K
| Adam | epoch: 013 | loss: 0.55712 - acc: 0.7210 | val_loss: 0.58524 - val_acc: 0.6848 -- iter: 293/293
--
Training Step: 131  | total loss: [1m[32m0.56061[0m[0m | time: 0.261s
[2K
| Adam | epoch: 014 | loss: 0.56061 - acc: 0.7208 -- iter: 032/293
[A[ATraining Step: 132  | total loss: [1m[32m0.55996[0m[0m | time: 0.489s
[2K
| Adam | epoch: 014 | loss: 0.55996 - acc: 0.7087 -- iter: 064/293
[A[ATraining Step: 133  | total loss: [1m[32m0.59806[0m[0m | time: 1.533s
[2K
| Adam | epoch: 014 | loss: 0.59806 - acc: 0.6778 -- iter: 096/293
[A[ATraining Step: 134  | total loss: [1m[32m0.61301[0m[0m | time: 2.470s
[2K
| Adam | epoch: 014 | loss: 0.61301 - acc: 0.6694 -- iter: 128/293
[A[ATraining Step: 135  | total loss: [1m[32m0.60789[0m[0m | time: 3.503s
[2K
| Adam | epoch: 014 | loss: 0.60789 - acc: 0.6837 -- iter: 160/293
[A[ATraining Step: 136  | total loss: [1m[32m0.59506[0m[0m | time: 4.485s
[2K
| Adam | epoch: 014 | loss: 0.59506 - acc: 0.6904 -- iter: 192/293
[A[ATraining Step: 137  | total loss: [1m[32m0.58510[0m[0m | time: 5.514s
[2K
| Adam | epoch: 014 | loss: 0.58510 - acc: 0.7057 -- iter: 224/293
[A[ATraining Step: 138  | total loss: [1m[32m0.58907[0m[0m | time: 6.697s
[2K
| Adam | epoch: 014 | loss: 0.58907 - acc: 0.7039 -- iter: 256/293
[A[ATraining Step: 139  | total loss: [1m[32m0.58793[0m[0m | time: 7.609s
[2K
| Adam | epoch: 014 | loss: 0.58793 - acc: 0.6960 -- iter: 288/293
[A[ATraining Step: 140  | total loss: [1m[32m0.58014[0m[0m | time: 9.618s
[2K
| Adam | epoch: 014 | loss: 0.58014 - acc: 0.7076 | val_loss: 0.55646 - val_acc: 0.7391 -- iter: 293/293
--
Training Step: 141  | total loss: [1m[32m0.57000[0m[0m | time: 0.947s
[2K
| Adam | epoch: 015 | loss: 0.57000 - acc: 0.7244 -- iter: 032/293
[A[ATraining Step: 142  | total loss: [1m[32m0.56022[0m[0m | time: 1.150s
[2K
| Adam | epoch: 015 | loss: 0.56022 - acc: 0.7363 -- iter: 064/293
[A[ATraining Step: 143  | total loss: [1m[32m0.54684[0m[0m | time: 1.371s
[2K
| Adam | epoch: 015 | loss: 0.54684 - acc: 0.7627 -- iter: 096/293
[A[ATraining Step: 144  | total loss: [1m[32m0.56302[0m[0m | time: 2.358s
[2K
| Adam | epoch: 015 | loss: 0.56302 - acc: 0.7464 -- iter: 128/293
[A[ATraining Step: 145  | total loss: [1m[32m0.55573[0m[0m | time: 3.468s
[2K
| Adam | epoch: 015 | loss: 0.55573 - acc: 0.7530 -- iter: 160/293
[A[ATraining Step: 146  | total loss: [1m[32m0.53706[0m[0m | time: 4.480s
[2K
| Adam | epoch: 015 | loss: 0.53706 - acc: 0.7683 -- iter: 192/293
[A[ATraining Step: 147  | total loss: [1m[32m0.52457[0m[0m | time: 5.454s
[2K
| Adam | epoch: 015 | loss: 0.52457 - acc: 0.7728 -- iter: 224/293
[A[ATraining Step: 148  | total loss: [1m[32m0.51964[0m[0m | time: 6.544s
[2K
| Adam | epoch: 015 | loss: 0.51964 - acc: 0.7736 -- iter: 256/293
[A[ATraining Step: 149  | total loss: [1m[32m0.51278[0m[0m | time: 7.544s
[2K
| Adam | epoch: 015 | loss: 0.51278 - acc: 0.7744 -- iter: 288/293
[A[ATraining Step: 150  | total loss: [1m[32m0.50707[0m[0m | time: 9.272s
[2K
| Adam | epoch: 015 | loss: 0.50707 - acc: 0.7751 | val_loss: 0.64052 - val_acc: 0.7174 -- iter: 293/293
--
Training Step: 151  | total loss: [1m[32m0.51507[0m[0m | time: 0.628s
[2K
| Adam | epoch: 016 | loss: 0.51507 - acc: 0.7663 -- iter: 032/293
[A[ATraining Step: 152  | total loss: [1m[32m0.51232[0m[0m | time: 1.266s
[2K
| Adam | epoch: 016 | loss: 0.51232 - acc: 0.7647 -- iter: 064/293
[A[ATraining Step: 153  | total loss: [1m[32m0.51257[0m[0m | time: 1.396s
[2K
| Adam | epoch: 016 | loss: 0.51257 - acc: 0.7695 -- iter: 096/293
[A[ATraining Step: 154  | total loss: [1m[32m0.48151[0m[0m | time: 1.531s
[2K
| Adam | epoch: 016 | loss: 0.48151 - acc: 0.7925 -- iter: 128/293
[A[ATraining Step: 155  | total loss: [1m[32m0.56113[0m[0m | time: 2.146s
[2K
| Adam | epoch: 016 | loss: 0.56113 - acc: 0.7533 -- iter: 160/293
[A[ATraining Step: 156  | total loss: [1m[32m0.54054[0m[0m | time: 2.788s
[2K
| Adam | epoch: 016 | loss: 0.54054 - acc: 0.7592 -- iter: 192/293
[A[ATraining Step: 157  | total loss: [1m[32m0.53060[0m[0m | time: 3.398s
[2K
| Adam | epoch: 016 | loss: 0.53060 - acc: 0.7645 -- iter: 224/293
[A[ATraining Step: 158  | total loss: [1m[32m0.52008[0m[0m | time: 4.021s
[2K
| Adam | epoch: 016 | loss: 0.52008 - acc: 0.7724 -- iter: 256/293
[A[ATraining Step: 159  | total loss: [1m[32m0.50138[0m[0m | time: 4.623s
[2K
| Adam | epoch: 016 | loss: 0.50138 - acc: 0.7858 -- iter: 288/293
[A[ATraining Step: 160  | total loss: [1m[32m0.48088[0m[0m | time: 6.241s
[2K
| Adam | epoch: 016 | loss: 0.48088 - acc: 0.7979 | val_loss: 0.47941 - val_acc: 0.7609 -- iter: 293/293
--
Training Step: 161  | total loss: [1m[32m0.47486[0m[0m | time: 0.620s
[2K
| Adam | epoch: 017 | loss: 0.47486 - acc: 0.8025 -- iter: 032/293
[A[ATraining Step: 162  | total loss: [1m[32m0.47046[0m[0m | time: 1.230s
[2K
| Adam | epoch: 017 | loss: 0.47046 - acc: 0.8066 -- iter: 064/293
[A[ATraining Step: 163  | total loss: [1m[32m0.45490[0m[0m | time: 1.864s
[2K
| Adam | epoch: 017 | loss: 0.45490 - acc: 0.8072 -- iter: 096/293
[A[ATraining Step: 164  | total loss: [1m[32m0.44612[0m[0m | time: 1.996s
[2K
| Adam | epoch: 017 | loss: 0.44612 - acc: 0.8140 -- iter: 128/293
[A[ATraining Step: 165  | total loss: [1m[32m0.42128[0m[0m | time: 2.149s
[2K
| Adam | epoch: 017 | loss: 0.42128 - acc: 0.8326 -- iter: 160/293
[A[ATraining Step: 166  | total loss: [1m[32m0.39643[0m[0m | time: 2.758s
[2K
| Adam | epoch: 017 | loss: 0.39643 - acc: 0.8493 -- iter: 192/293
[A[ATraining Step: 167  | total loss: [1m[32m0.38419[0m[0m | time: 3.530s
[2K
| Adam | epoch: 017 | loss: 0.38419 - acc: 0.8550 -- iter: 224/293
[A[ATraining Step: 168  | total loss: [1m[32m0.38318[0m[0m | time: 4.165s
[2K
| Adam | epoch: 017 | loss: 0.38318 - acc: 0.8570 -- iter: 256/293
[A[ATraining Step: 169  | total loss: [1m[32m0.37604[0m[0m | time: 4.763s
[2K
| Adam | epoch: 017 | loss: 0.37604 - acc: 0.8588 -- iter: 288/293
[A[ATraining Step: 170  | total loss: [1m[32m0.36006[0m[0m | time: 6.407s
[2K
| Adam | epoch: 017 | loss: 0.36006 - acc: 0.8698 | val_loss: 0.51247 - val_acc: 0.7283 -- iter: 293/293
--
Training Step: 171  | total loss: [1m[32m0.35779[0m[0m | time: 1.110s
[2K
| Adam | epoch: 018 | loss: 0.35779 - acc: 0.8672 -- iter: 032/293
[A[ATraining Step: 172  | total loss: [1m[32m0.35807[0m[0m | time: 1.991s
[2K
| Adam | epoch: 018 | loss: 0.35807 - acc: 0.8680 -- iter: 064/293
[A[ATraining Step: 173  | total loss: [1m[32m0.34749[0m[0m | time: 3.020s
[2K
| Adam | epoch: 018 | loss: 0.34749 - acc: 0.8687 -- iter: 096/293
[A[ATraining Step: 174  | total loss: [1m[32m0.34558[0m[0m | time: 4.054s
[2K
| Adam | epoch: 018 | loss: 0.34558 - acc: 0.8693 -- iter: 128/293
[A[ATraining Step: 175  | total loss: [1m[32m0.33952[0m[0m | time: 4.295s
[2K
| Adam | epoch: 018 | loss: 0.33952 - acc: 0.8699 -- iter: 160/293
[A[ATraining Step: 176  | total loss: [1m[32m0.31040[0m[0m | time: 4.516s
[2K
| Adam | epoch: 018 | loss: 0.31040 - acc: 0.8829 -- iter: 192/293
[A[ATraining Step: 177  | total loss: [1m[32m0.35214[0m[0m | time: 5.551s
[2K
| Adam | epoch: 018 | loss: 0.35214 - acc: 0.8746 -- iter: 224/293
[A[ATraining Step: 178  | total loss: [1m[32m0.33921[0m[0m | time: 6.692s
[2K
| Adam | epoch: 018 | loss: 0.33921 - acc: 0.8809 -- iter: 256/293
[A[ATraining Step: 179  | total loss: [1m[32m0.32756[0m[0m | time: 7.628s
[2K
| Adam | epoch: 018 | loss: 0.32756 - acc: 0.8866 -- iter: 288/293
[A[ATraining Step: 180  | total loss: [1m[32m0.32699[0m[0m | time: 9.576s
[2K
| Adam | epoch: 018 | loss: 0.32699 - acc: 0.8854 | val_loss: 0.46131 - val_acc: 0.8043 -- iter: 293/293
--
Training Step: 181  | total loss: [1m[32m0.32079[0m[0m | time: 1.119s
[2K
| Adam | epoch: 019 | loss: 0.32079 - acc: 0.8875 -- iter: 032/293
[A[ATraining Step: 182  | total loss: [1m[32m0.32182[0m[0m | time: 1.995s
[2K
| Adam | epoch: 019 | loss: 0.32182 - acc: 0.8831 -- iter: 064/293
[A[ATraining Step: 183  | total loss: [1m[32m0.30477[0m[0m | time: 3.068s
[2K
| Adam | epoch: 019 | loss: 0.30477 - acc: 0.8917 -- iter: 096/293
[A[ATraining Step: 184  | total loss: [1m[32m0.31429[0m[0m | time: 4.129s
[2K
| Adam | epoch: 019 | loss: 0.31429 - acc: 0.8838 -- iter: 128/293
[A[ATraining Step: 185  | total loss: [1m[32m0.34620[0m[0m | time: 5.243s
[2K
| Adam | epoch: 019 | loss: 0.34620 - acc: 0.8610 -- iter: 160/293
[A[ATraining Step: 186  | total loss: [1m[32m0.34518[0m[0m | time: 5.442s
[2K
| Adam | epoch: 019 | loss: 0.34518 - acc: 0.8562 -- iter: 192/293
[A[ATraining Step: 187  | total loss: [1m[32m0.34933[0m[0m | time: 5.610s
[2K
| Adam | epoch: 019 | loss: 0.34933 - acc: 0.8505 -- iter: 224/293
[A[ATraining Step: 188  | total loss: [1m[32m0.32860[0m[0m | time: 6.484s
[2K
| Adam | epoch: 019 | loss: 0.32860 - acc: 0.8655 -- iter: 256/293
[A[ATraining Step: 189  | total loss: [1m[32m0.36450[0m[0m | time: 7.588s
[2K
| Adam | epoch: 019 | loss: 0.36450 - acc: 0.8477 -- iter: 288/293
[A[ATraining Step: 190  | total loss: [1m[32m0.37341[0m[0m | time: 9.671s
[2K
| Adam | epoch: 019 | loss: 0.37341 - acc: 0.8348 | val_loss: 0.37587 - val_acc: 0.8478 -- iter: 293/293
--
Training Step: 191  | total loss: [1m[32m0.37055[0m[0m | time: 1.150s
[2K
| Adam | epoch: 020 | loss: 0.37055 - acc: 0.8388 -- iter: 032/293
[A[ATraining Step: 192  | total loss: [1m[32m0.34767[0m[0m | time: 2.071s
[2K
| Adam | epoch: 020 | loss: 0.34767 - acc: 0.8487 -- iter: 064/293
[A[ATraining Step: 193  | total loss: [1m[32m0.34403[0m[0m | time: 3.003s
[2K
| Adam | epoch: 020 | loss: 0.34403 - acc: 0.8482 -- iter: 096/293
[A[ATraining Step: 194  | total loss: [1m[32m0.34537[0m[0m | time: 3.989s
[2K
| Adam | epoch: 020 | loss: 0.34537 - acc: 0.8509 -- iter: 128/293
[A[ATraining Step: 195  | total loss: [1m[32m0.34786[0m[0m | time: 4.983s
[2K
| Adam | epoch: 020 | loss: 0.34786 - acc: 0.8533 -- iter: 160/293
[A[ATraining Step: 196  | total loss: [1m[32m0.34428[0m[0m | time: 5.986s
[2K
| Adam | epoch: 020 | loss: 0.34428 - acc: 0.8555 -- iter: 192/293
[A[ATraining Step: 197  | total loss: [1m[32m0.33495[0m[0m | time: 6.207s
[2K
| Adam | epoch: 020 | loss: 0.33495 - acc: 0.8574 -- iter: 224/293
[A[ATraining Step: 198  | total loss: [1m[32m0.30335[0m[0m | time: 6.456s
[2K
| Adam | epoch: 020 | loss: 0.30335 - acc: 0.8717 -- iter: 256/293
[A[ATraining Step: 199  | total loss: [1m[32m0.41495[0m[0m | time: 7.475s
[2K
| Adam | epoch: 020 | loss: 0.41495 - acc: 0.8445 -- iter: 288/293
[A[ATraining Step: 200  | total loss: [1m[32m0.42277[0m[0m | time: 9.435s
[2K
| Adam | epoch: 020 | loss: 0.42277 - acc: 0.8444 | val_loss: 0.47628 - val_acc: 0.8043 -- iter: 293/293
--
Training Step: 201  | total loss: [1m[32m0.41788[0m[0m | time: 0.884s
[2K
| Adam | epoch: 021 | loss: 0.41788 - acc: 0.8475 -- iter: 032/293
[A[ATraining Step: 202  | total loss: [1m[32m0.39290[0m[0m | time: 1.853s
[2K
| Adam | epoch: 021 | loss: 0.39290 - acc: 0.8565 -- iter: 064/293
[A[ATraining Step: 203  | total loss: [1m[32m0.36734[0m[0m | time: 2.831s
[2K
| Adam | epoch: 021 | loss: 0.36734 - acc: 0.8708 -- iter: 096/293
[A[ATraining Step: 204  | total loss: [1m[32m0.36381[0m[0m | time: 3.940s
[2K
| Adam | epoch: 021 | loss: 0.36381 - acc: 0.8713 -- iter: 128/293
[A[ATraining Step: 205  | total loss: [1m[32m0.36715[0m[0m | time: 5.028s
[2K
| Adam | epoch: 021 | loss: 0.36715 - acc: 0.8716 -- iter: 160/293
[A[ATraining Step: 206  | total loss: [1m[32m0.35569[0m[0m | time: 5.893s
[2K
| Adam | epoch: 021 | loss: 0.35569 - acc: 0.8720 -- iter: 192/293
[A[ATraining Step: 207  | total loss: [1m[32m0.35599[0m[0m | time: 6.963s
[2K
| Adam | epoch: 021 | loss: 0.35599 - acc: 0.8660 -- iter: 224/293
[A[ATraining Step: 208  | total loss: [1m[32m0.34530[0m[0m | time: 7.207s
[2K
| Adam | epoch: 021 | loss: 0.34530 - acc: 0.8700 -- iter: 256/293
[A[ATraining Step: 209  | total loss: [1m[32m0.33099[0m[0m | time: 7.480s
[2K
| Adam | epoch: 021 | loss: 0.33099 - acc: 0.8830 -- iter: 288/293
[A[ATraining Step: 210  | total loss: [1m[32m0.34054[0m[0m | time: 9.547s
[2K
| Adam | epoch: 021 | loss: 0.34054 - acc: 0.8747 | val_loss: 0.67756 - val_acc: 0.6957 -- iter: 293/293
--
Training Step: 211  | total loss: [1m[32m0.32493[0m[0m | time: 0.621s
[2K
| Adam | epoch: 022 | loss: 0.32493 - acc: 0.8841 -- iter: 032/293
[A[ATraining Step: 212  | total loss: [1m[32m0.33881[0m[0m | time: 1.320s
[2K
| Adam | epoch: 022 | loss: 0.33881 - acc: 0.8738 -- iter: 064/293
[A[ATraining Step: 213  | total loss: [1m[32m0.33520[0m[0m | time: 1.932s
[2K
| Adam | epoch: 022 | loss: 0.33520 - acc: 0.8708 -- iter: 096/293
[A[ATraining Step: 214  | total loss: [1m[32m0.32107[0m[0m | time: 2.562s
[2K
| Adam | epoch: 022 | loss: 0.32107 - acc: 0.8775 -- iter: 128/293
[A[ATraining Step: 215  | total loss: [1m[32m0.31121[0m[0m | time: 3.162s
[2K
| Adam | epoch: 022 | loss: 0.31121 - acc: 0.8835 -- iter: 160/293
[A[ATraining Step: 216  | total loss: [1m[32m0.29865[0m[0m | time: 3.911s
[2K
| Adam | epoch: 022 | loss: 0.29865 - acc: 0.8920 -- iter: 192/293
[A[ATraining Step: 217  | total loss: [1m[32m0.29535[0m[0m | time: 4.519s
[2K
| Adam | epoch: 022 | loss: 0.29535 - acc: 0.8935 -- iter: 224/293
[A[ATraining Step: 218  | total loss: [1m[32m0.29284[0m[0m | time: 5.136s
[2K
| Adam | epoch: 022 | loss: 0.29284 - acc: 0.8947 -- iter: 256/293
[A[ATraining Step: 219  | total loss: [1m[32m0.28748[0m[0m | time: 5.284s
[2K
| Adam | epoch: 022 | loss: 0.28748 - acc: 0.8928 -- iter: 288/293
[A[ATraining Step: 220  | total loss: [1m[32m0.28701[0m[0m | time: 6.419s
[2K
| Adam | epoch: 022 | loss: 0.28701 - acc: 0.8835 | val_loss: 0.61620 - val_acc: 0.7283 -- iter: 293/293
--
Training Step: 221  | total loss: [1m[32m0.26619[0m[0m | time: 0.650s
[2K
| Adam | epoch: 023 | loss: 0.26619 - acc: 0.8951 -- iter: 032/293
[A[ATraining Step: 222  | total loss: [1m[32m0.25176[0m[0m | time: 1.269s
[2K
| Adam | epoch: 023 | loss: 0.25176 - acc: 0.8994 -- iter: 064/293
[A[ATraining Step: 223  | total loss: [1m[32m0.29364[0m[0m | time: 1.879s
[2K
| Adam | epoch: 023 | loss: 0.29364 - acc: 0.8688 -- iter: 096/293
[A[ATraining Step: 224  | total loss: [1m[32m0.30790[0m[0m | time: 2.617s
[2K
| Adam | epoch: 023 | loss: 0.30790 - acc: 0.8601 -- iter: 128/293
[A[ATraining Step: 225  | total loss: [1m[32m0.33379[0m[0m | time: 3.228s
[2K
| Adam | epoch: 023 | loss: 0.33379 - acc: 0.8553 -- iter: 160/293
[A[ATraining Step: 226  | total loss: [1m[32m0.31687[0m[0m | time: 3.873s
[2K
| Adam | epoch: 023 | loss: 0.31687 - acc: 0.8666 -- iter: 192/293
[A[ATraining Step: 227  | total loss: [1m[32m0.30118[0m[0m | time: 4.501s
[2K
| Adam | epoch: 023 | loss: 0.30118 - acc: 0.8706 -- iter: 224/293
[A[ATraining Step: 228  | total loss: [1m[32m0.28236[0m[0m | time: 5.113s
[2K
| Adam | epoch: 023 | loss: 0.28236 - acc: 0.8804 -- iter: 256/293
[A[ATraining Step: 229  | total loss: [1m[32m0.28990[0m[0m | time: 5.719s
[2K
| Adam | epoch: 023 | loss: 0.28990 - acc: 0.8768 -- iter: 288/293
[A[ATraining Step: 230  | total loss: [1m[32m0.29184[0m[0m | time: 6.869s
[2K
| Adam | epoch: 023 | loss: 0.29184 - acc: 0.8766 | val_loss: 0.39415 - val_acc: 0.8261 -- iter: 293/293
--
Training Step: 231  | total loss: [1m[32m0.31599[0m[0m | time: 0.237s
[2K
| Adam | epoch: 024 | loss: 0.31599 - acc: 0.8489 -- iter: 032/293
[A[ATraining Step: 232  | total loss: [1m[32m0.37229[0m[0m | time: 1.237s
[2K
| Adam | epoch: 024 | loss: 0.37229 - acc: 0.8240 -- iter: 064/293
[A[ATraining Step: 233  | total loss: [1m[32m0.34833[0m[0m | time: 2.168s
[2K
| Adam | epoch: 024 | loss: 0.34833 - acc: 0.8354 -- iter: 096/293
[A[ATraining Step: 234  | total loss: [1m[32m0.32631[0m[0m | time: 3.230s
[2K
| Adam | epoch: 024 | loss: 0.32631 - acc: 0.8487 -- iter: 128/293
[A[ATraining Step: 235  | total loss: [1m[32m0.30949[0m[0m | time: 4.411s
[2K
| Adam | epoch: 024 | loss: 0.30949 - acc: 0.8576 -- iter: 160/293
[A[ATraining Step: 236  | total loss: [1m[32m0.28642[0m[0m | time: 5.261s
[2K
| Adam | epoch: 024 | loss: 0.28642 - acc: 0.8718 -- iter: 192/293
[A[ATraining Step: 237  | total loss: [1m[32m0.26942[0m[0m | time: 6.349s
[2K
| Adam | epoch: 024 | loss: 0.26942 - acc: 0.8784 -- iter: 224/293
[A[ATraining Step: 238  | total loss: [1m[32m0.25206[0m[0m | time: 7.475s
[2K
| Adam | epoch: 024 | loss: 0.25206 - acc: 0.8874 -- iter: 256/293
[A[ATraining Step: 239  | total loss: [1m[32m0.23470[0m[0m | time: 8.585s
[2K
| Adam | epoch: 024 | loss: 0.23470 - acc: 0.8987 -- iter: 288/293
[A[ATraining Step: 240  | total loss: [1m[32m0.22014[0m[0m | time: 10.427s
[2K
| Adam | epoch: 024 | loss: 0.22014 - acc: 0.9088 | val_loss: 0.41654 - val_acc: 0.8370 -- iter: 293/293
--
Training Step: 241  | total loss: [1m[32m0.22710[0m[0m | time: 0.262s
[2K
| Adam | epoch: 025 | loss: 0.22710 - acc: 0.9023 -- iter: 032/293
[A[ATraining Step: 242  | total loss: [1m[32m0.20758[0m[0m | time: 0.481s
[2K
| Adam | epoch: 025 | loss: 0.20758 - acc: 0.9121 -- iter: 064/293
[A[ATraining Step: 243  | total loss: [1m[32m0.19048[0m[0m | time: 1.304s
[2K
| Adam | epoch: 025 | loss: 0.19048 - acc: 0.9209 -- iter: 096/293
[A[ATraining Step: 244  | total loss: [1m[32m0.19067[0m[0m | time: 2.504s
[2K
| Adam | epoch: 025 | loss: 0.19067 - acc: 0.9225 -- iter: 128/293
[A[ATraining Step: 245  | total loss: [1m[32m0.18655[0m[0m | time: 3.613s
[2K
| Adam | epoch: 025 | loss: 0.18655 - acc: 0.9240 -- iter: 160/293
[A[ATraining Step: 246  | total loss: [1m[32m0.17336[0m[0m | time: 4.684s
[2K
| Adam | epoch: 025 | loss: 0.17336 - acc: 0.9316 -- iter: 192/293
[A[ATraining Step: 247  | total loss: [1m[32m0.16397[0m[0m | time: 5.583s
[2K
| Adam | epoch: 025 | loss: 0.16397 - acc: 0.9353 -- iter: 224/293
[A[ATraining Step: 248  | total loss: [1m[32m0.17338[0m[0m | time: 6.532s
[2K
| Adam | epoch: 025 | loss: 0.17338 - acc: 0.9293 -- iter: 256/293
[A[ATraining Step: 249  | total loss: [1m[32m0.16022[0m[0m | time: 7.548s
[2K
| Adam | epoch: 025 | loss: 0.16022 - acc: 0.9364 -- iter: 288/293
[A[ATraining Step: 250  | total loss: [1m[32m0.15516[0m[0m | time: 9.519s
[2K
| Adam | epoch: 025 | loss: 0.15516 - acc: 0.9365 | val_loss: 0.55016 - val_acc: 0.7935 -- iter: 293/293
--
Training Step: 251  | total loss: [1m[32m0.14907[0m[0m | time: 1.058s
[2K
| Adam | epoch: 026 | loss: 0.14907 - acc: 0.9397 -- iter: 032/293
[A[ATraining Step: 252  | total loss: [1m[32m0.14398[0m[0m | time: 1.281s
[2K
| Adam | epoch: 026 | loss: 0.14398 - acc: 0.9395 -- iter: 064/293
[A[ATraining Step: 253  | total loss: [1m[32m0.13194[0m[0m | time: 1.513s
[2K
| Adam | epoch: 026 | loss: 0.13194 - acc: 0.9455 -- iter: 096/293
[A[ATraining Step: 254  | total loss: [1m[32m0.12023[0m[0m | time: 2.496s
[2K
| Adam | epoch: 026 | loss: 0.12023 - acc: 0.9510 -- iter: 128/293
[A[ATraining Step: 255  | total loss: [1m[32m0.11628[0m[0m | time: 3.428s
[2K
| Adam | epoch: 026 | loss: 0.11628 - acc: 0.9528 -- iter: 160/293
[A[ATraining Step: 256  | total loss: [1m[32m0.10811[0m[0m | time: 4.446s
[2K
| Adam | epoch: 026 | loss: 0.10811 - acc: 0.9575 -- iter: 192/293
[A[ATraining Step: 257  | total loss: [1m[32m0.09988[0m[0m | time: 5.445s
[2K
| Adam | epoch: 026 | loss: 0.09988 - acc: 0.9617 -- iter: 224/293
[A[ATraining Step: 258  | total loss: [1m[32m0.10142[0m[0m | time: 6.550s
[2K
| Adam | epoch: 026 | loss: 0.10142 - acc: 0.9593 -- iter: 256/293
[A[ATraining Step: 259  | total loss: [1m[32m0.09671[0m[0m | time: 7.622s
[2K
| Adam | epoch: 026 | loss: 0.09671 - acc: 0.9634 -- iter: 288/293
[A[ATraining Step: 260  | total loss: [1m[32m0.08966[0m[0m | time: 9.513s
[2K
| Adam | epoch: 026 | loss: 0.08966 - acc: 0.9670 | val_loss: 0.50098 - val_acc: 0.8152 -- iter: 293/293
--
Training Step: 261  | total loss: [1m[32m0.08514[0m[0m | time: 0.981s
[2K
| Adam | epoch: 027 | loss: 0.08514 - acc: 0.9672 -- iter: 032/293
[A[ATraining Step: 262  | total loss: [1m[32m0.08021[0m[0m | time: 1.971s
[2K
| Adam | epoch: 027 | loss: 0.08021 - acc: 0.9705 -- iter: 064/293
[A[ATraining Step: 263  | total loss: [1m[32m0.07612[0m[0m | time: 2.181s
[2K
| Adam | epoch: 027 | loss: 0.07612 - acc: 0.9734 -- iter: 096/293
[A[ATraining Step: 264  | total loss: [1m[32m0.06941[0m[0m | time: 2.426s
[2K
| Adam | epoch: 027 | loss: 0.06941 - acc: 0.9761 -- iter: 128/293
[A[ATraining Step: 265  | total loss: [1m[32m0.06331[0m[0m | time: 3.514s
[2K
| Adam | epoch: 027 | loss: 0.06331 - acc: 0.9785 -- iter: 160/293
[A[ATraining Step: 266  | total loss: [1m[32m0.06034[0m[0m | time: 4.459s
[2K
| Adam | epoch: 027 | loss: 0.06034 - acc: 0.9806 -- iter: 192/293
[A[ATraining Step: 267  | total loss: [1m[32m0.06402[0m[0m | time: 5.410s
[2K
| Adam | epoch: 027 | loss: 0.06402 - acc: 0.9763 -- iter: 224/293
[A[ATraining Step: 268  | total loss: [1m[32m0.05900[0m[0m | time: 6.528s
[2K
| Adam | epoch: 027 | loss: 0.05900 - acc: 0.9787 -- iter: 256/293
[A[ATraining Step: 269  | total loss: [1m[32m0.05517[0m[0m | time: 7.571s
[2K
| Adam | epoch: 027 | loss: 0.05517 - acc: 0.9808 -- iter: 288/293
[A[ATraining Step: 270  | total loss: [1m[32m0.05446[0m[0m | time: 9.277s
[2K
| Adam | epoch: 027 | loss: 0.05446 - acc: 0.9796 | val_loss: 0.50676 - val_acc: 0.8152 -- iter: 293/293
--
Training Step: 271  | total loss: [1m[32m0.06116[0m[0m | time: 0.615s
[2K
| Adam | epoch: 028 | loss: 0.06116 - acc: 0.9785 -- iter: 032/293
[A[ATraining Step: 272  | total loss: [1m[32m0.05595[0m[0m | time: 1.233s
[2K
| Adam | epoch: 028 | loss: 0.05595 - acc: 0.9807 -- iter: 064/293
[A[ATraining Step: 273  | total loss: [1m[32m0.05102[0m[0m | time: 1.870s
[2K
| Adam | epoch: 028 | loss: 0.05102 - acc: 0.9826 -- iter: 096/293
[A[ATraining Step: 274  | total loss: [1m[32m0.05250[0m[0m | time: 2.002s
[2K
| Adam | epoch: 028 | loss: 0.05250 - acc: 0.9812 -- iter: 128/293
[A[ATraining Step: 275  | total loss: [1m[32m0.04815[0m[0m | time: 2.136s
[2K
| Adam | epoch: 028 | loss: 0.04815 - acc: 0.9831 -- iter: 160/293
[A[ATraining Step: 276  | total loss: [1m[32m0.24631[0m[0m | time: 2.774s
[2K
| Adam | epoch: 028 | loss: 0.24631 - acc: 0.9448 -- iter: 192/293
[A[ATraining Step: 277  | total loss: [1m[32m0.23063[0m[0m | time: 3.403s
[2K
| Adam | epoch: 028 | loss: 0.23063 - acc: 0.9472 -- iter: 224/293
[A[ATraining Step: 278  | total loss: [1m[32m0.20954[0m[0m | time: 4.036s
[2K
| Adam | epoch: 028 | loss: 0.20954 - acc: 0.9525 -- iter: 256/293
[A[ATraining Step: 279  | total loss: [1m[32m0.18951[0m[0m | time: 4.650s
[2K
| Adam | epoch: 028 | loss: 0.18951 - acc: 0.9572 -- iter: 288/293
[A[ATraining Step: 280  | total loss: [1m[32m0.17111[0m[0m | time: 6.265s
[2K
| Adam | epoch: 028 | loss: 0.17111 - acc: 0.9615 | val_loss: 0.52054 - val_acc: 0.8152 -- iter: 293/293
--
Training Step: 281  | total loss: [1m[32m0.15486[0m[0m | time: 0.608s
[2K
| Adam | epoch: 029 | loss: 0.15486 - acc: 0.9653 -- iter: 032/293
[A[ATraining Step: 282  | total loss: [1m[32m0.14083[0m[0m | time: 1.220s
[2K
| Adam | epoch: 029 | loss: 0.14083 - acc: 0.9688 -- iter: 064/293
[A[ATraining Step: 283  | total loss: [1m[32m0.13200[0m[0m | time: 1.856s
[2K
| Adam | epoch: 029 | loss: 0.13200 - acc: 0.9688 -- iter: 096/293
[A[ATraining Step: 284  | total loss: [1m[32m0.12198[0m[0m | time: 2.466s
[2K
| Adam | epoch: 029 | loss: 0.12198 - acc: 0.9719 -- iter: 128/293
[A[ATraining Step: 285  | total loss: [1m[32m0.11233[0m[0m | time: 2.601s
[2K
| Adam | epoch: 029 | loss: 0.11233 - acc: 0.9747 -- iter: 160/293
[A[ATraining Step: 286  | total loss: [1m[32m0.10178[0m[0m | time: 2.735s
[2K
| Adam | epoch: 029 | loss: 0.10178 - acc: 0.9773 -- iter: 192/293
[A[ATraining Step: 287  | total loss: [1m[32m0.30458[0m[0m | time: 3.354s
[2K
| Adam | epoch: 029 | loss: 0.30458 - acc: 0.9395 -- iter: 224/293
[A[ATraining Step: 288  | total loss: [1m[32m0.27489[0m[0m | time: 3.972s
[2K
| Adam | epoch: 029 | loss: 0.27489 - acc: 0.9456 -- iter: 256/293
[A[ATraining Step: 289  | total loss: [1m[32m0.24829[0m[0m | time: 4.580s
[2K
| Adam | epoch: 029 | loss: 0.24829 - acc: 0.9510 -- iter: 288/293
[A[ATraining Step: 290  | total loss: [1m[32m0.22453[0m[0m | time: 6.219s
[2K
| Adam | epoch: 029 | loss: 0.22453 - acc: 0.9559 | val_loss: 0.48522 - val_acc: 0.8043 -- iter: 293/293
--
Training Step: 291  | total loss: [1m[32m0.20337[0m[0m | time: 1.107s
[2K
| Adam | epoch: 030 | loss: 0.20337 - acc: 0.9603 -- iter: 032/293
[A[ATraining Step: 292  | total loss: [1m[32m0.18451[0m[0m | time: 2.049s
[2K
| Adam | epoch: 030 | loss: 0.18451 - acc: 0.9643 -- iter: 064/293
[A[ATraining Step: 293  | total loss: [1m[32m0.16701[0m[0m | time: 2.970s
[2K
| Adam | epoch: 030 | loss: 0.16701 - acc: 0.9679 -- iter: 096/293
[A[ATraining Step: 294  | total loss: [1m[32m0.15238[0m[0m | time: 3.909s
[2K
| Adam | epoch: 030 | loss: 0.15238 - acc: 0.9711 -- iter: 128/293
[A[ATraining Step: 295  | total loss: [1m[32m0.13924[0m[0m | time: 4.883s
[2K
| Adam | epoch: 030 | loss: 0.13924 - acc: 0.9740 -- iter: 160/293
[A[ATraining Step: 296  | total loss: [1m[32m0.12780[0m[0m | time: 5.121s
[2K
| Adam | epoch: 030 | loss: 0.12780 - acc: 0.9766 -- iter: 192/293
[A[ATraining Step: 297  | total loss: [1m[32m0.11603[0m[0m | time: 5.327s
[2K
| Adam | epoch: 030 | loss: 0.11603 - acc: 0.9789 -- iter: 224/293
[A[ATraining Step: 298  | total loss: [1m[32m0.29779[0m[0m | time: 6.412s
[2K
| Adam | epoch: 030 | loss: 0.29779 - acc: 0.9410 -- iter: 256/293
[A[ATraining Step: 299  | total loss: [1m[32m0.26916[0m[0m | time: 7.516s
[2K
| Adam | epoch: 030 | loss: 0.26916 - acc: 0.9469 -- iter: 288/293
[A[ATraining Step: 300  | total loss: [1m[32m0.24478[0m[0m | time: 9.438s
[2K
| Adam | epoch: 030 | loss: 0.24478 - acc: 0.9522 | val_loss: 0.39052 - val_acc: 0.7935 -- iter: 293/293
--
Validation AUC:0.9182033096926714
Validation AUPRC:0.9302705355601231
Test AUC:0.9332386363636364
Test AUPRC:0.9314414451633115
BestTestF1Score	0.85	0.71	0.85	0.79	0.93	41	11	37	3	0.28
BestTestMCCScore	0.82	0.71	0.85	0.94	0.73	32	2	46	12	0.79
BestTestAccuracyScore	0.82	0.71	0.85	0.94	0.73	32	2	46	12	0.79
BestValidationF1Score	0.84	0.67	0.83	0.76	0.93	42	13	34	3	0.28
BestValidationMCC	0.83	0.71	0.85	0.92	0.76	34	3	44	11	0.79
BestValidationAccuracy	0.83	0.71	0.85	0.92	0.76	34	3	44	11	0.79
TestPredictions (Threshold:0.79)
CHEMBL191881,TN,INACT,0.019999999552965164	CHEMBL111567,TP,ACT,0.9900000095367432	CHEMBL295786,TN,INACT,0.009999999776482582	CHEMBL3127491,TP,ACT,0.9900000095367432	CHEMBL2315245,FN,ACT,0.6399999856948853	CHEMBL2011840,TP,ACT,0.9599999785423279	CHEMBL3355687,TP,ACT,1.0	CHEMBL3781319,TP,ACT,0.9900000095367432	CHEMBL3752669,TP,ACT,0.9900000095367432	CHEMBL3109168,TN,INACT,0.0	CHEMBL3355669,TP,ACT,0.800000011920929	CHEMBL3580759,FN,ACT,0.5799999833106995	CHEMBL1464645,TN,INACT,0.12999999523162842	CHEMBL1733342,TN,INACT,0.5799999833106995	CHEMBL1468612,TN,INACT,0.019999999552965164	CHEMBL1568729,TN,INACT,0.12999999523162842	CHEMBL3099870,TN,INACT,0.03999999910593033	CHEMBL3355672,TP,ACT,1.0	CHEMBL322165,FN,ACT,0.25999999046325684	CHEMBL3660177,TP,ACT,1.0	CHEMBL383943,TN,INACT,0.15000000596046448	CHEMBL113531,TN,INACT,0.03999999910593033	CHEMBL382418,TP,ACT,0.9800000190734863	CHEMBL1812010,TN,INACT,0.019999999552965164	CHEMBL2011839,FN,ACT,0.38999998569488525	CHEMBL3751935,TP,ACT,0.9900000095367432	CHEMBL369086,TP,ACT,0.9800000190734863	CHEMBL403042,FN,ACT,0.41999998688697815	CHEMBL77742,TN,INACT,0.5600000023841858	CHEMBL3660173,TP,ACT,1.0	CHEMBL211561,TN,INACT,0.009999999776482582	CHEMBL2373044,TN,INACT,0.029999999329447746	CHEMBL379315,TN,INACT,0.28999999165534973	CHEMBL2304334,FN,ACT,0.4699999988079071	CHEMBL3754262,TP,ACT,0.9900000095367432	CHEMBL105171,TN,INACT,0.019999999552965164	CHEMBL320749,TP,ACT,0.9900000095367432	CHEMBL1201881,FN,ACT,0.009999999776482582	CHEMBL203055,TP,ACT,0.9800000190734863	CHEMBL254439,TN,INACT,0.019999999552965164	CHEMBL504657,TN,INACT,0.009999999776482582	CHEMBL203008,TP,ACT,0.9900000095367432	CHEMBL1574542,TN,INACT,0.75	CHEMBL27305,TN,INACT,0.009999999776482582	CHEMBL231087,TN,INACT,0.009999999776482582	CHEMBL217920,TN,INACT,0.25999999046325684	CHEMBL2159388,TN,INACT,0.0	CHEMBL3408419,TN,INACT,0.009999999776482582	CHEMBL1422664,TN,INACT,0.009999999776482582	CHEMBL3277927,TN,INACT,0.10000000149011612	CHEMBL1392593,TN,INACT,0.33000001311302185	CHEMBL2016865,FN,ACT,0.3700000047683716	CHEMBL398380,FN,ACT,0.41999998688697815	CHEMBL3143639,TN,INACT,0.03999999910593033	CHEMBL3143648,TN,INACT,0.05999999865889549	CHEMBL1340840,TN,INACT,0.05999999865889549	CHEMBL2016868,TP,ACT,0.9900000095367432	CHEMBL391804,TN,INACT,0.009999999776482582	CHEMBL1532635,TN,INACT,0.699999988079071	CHEMBL3660189,TP,ACT,0.9900000095367432	CHEMBL554824,TN,INACT,0.019999999552965164	CHEMBL1945236,FN,ACT,0.7200000286102295	CHEMBL3091519,FN,ACT,0.17000000178813934	CHEMBL507020,TN,INACT,0.0	CHEMBL342036,TN,INACT,0.05000000074505806	CHEMBL2372731,TN,INACT,0.029999999329447746	CHEMBL59660,TN,INACT,0.0	CHEMBL107743,FP,INACT,0.9900000095367432	CHEMBL64708,TN,INACT,0.33000001311302185	CHEMBL3660182,TP,ACT,0.9300000071525574	CHEMBL2315238,TP,ACT,1.0	CHEMBL2016866,TP,ACT,0.9900000095367432	CHEMBL292235,TN,INACT,0.28999999165534973	CHEMBL2315236,TP,ACT,0.9900000095367432	CHEMBL211933,FP,INACT,0.8700000047683716	CHEMBL323387,TP,ACT,0.9800000190734863	CHEMBL212723,TN,INACT,0.14000000059604645	CHEMBL244909,TP,ACT,0.9900000095367432	CHEMBL2016871,TP,ACT,1.0	CHEMBL1812021,TN,INACT,0.019999999552965164	CHEMBL3260342,FN,ACT,0.550000011920929	CHEMBL62490,TN,INACT,0.27000001072883606	CHEMBL1833982,TN,INACT,0.20000000298023224	CHEMBL3099882,TN,INACT,0.0	CHEMBL512935,TN,INACT,0.6100000143051147	CHEMBL3109158,TN,INACT,0.03999999910593033	CHEMBL174499,TP,ACT,0.9700000286102295	CHEMBL204614,TP,ACT,0.9599999785423279	CHEMBL2315247,TP,ACT,1.0	CHEMBL2016872,TP,ACT,1.0	CHEMBL442201,TP,ACT,0.9700000286102295	CHEMBL3355666,TP,ACT,1.0	

