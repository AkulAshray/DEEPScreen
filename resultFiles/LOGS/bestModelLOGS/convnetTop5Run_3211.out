ImageNetInceptionV2 CHEMBL3230 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	154
Number of inactive compounds :	154
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3230_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3230_adam_0.0005_15_0.8/
---------------------------------
Training samples: 190
Validation samples: 60
--
Training Step: 1  | time: 58.819s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/190
[A[ATraining Step: 2  | total loss: [1m[32m0.68876[0m[0m | time: 71.673s
[2K
| Adam | epoch: 001 | loss: 0.68876 - acc: 0.5062 -- iter: 064/190
[A[ATraining Step: 3  | total loss: [1m[32m0.52138[0m[0m | time: 88.382s
[2K
| Adam | epoch: 001 | loss: 0.52138 - acc: 0.7312 -- iter: 096/190
[A[ATraining Step: 4  | total loss: [1m[32m0.29458[0m[0m | time: 104.015s
[2K
| Adam | epoch: 001 | loss: 0.29458 - acc: 0.8859 -- iter: 128/190
[A[ATraining Step: 5  | total loss: [1m[32m0.36122[0m[0m | time: 119.804s
[2K
| Adam | epoch: 001 | loss: 0.36122 - acc: 0.8135 -- iter: 160/190
[A[ATraining Step: 6  | total loss: [1m[32m0.30018[0m[0m | time: 152.641s
[2K
| Adam | epoch: 001 | loss: 0.30018 - acc: 0.8932 | val_loss: 4.06662 - val_acc: 0.4500 -- iter: 190/190
--
Training Step: 7  | total loss: [1m[32m0.29480[0m[0m | time: 14.984s
[2K
| Adam | epoch: 002 | loss: 0.29480 - acc: 0.8973 -- iter: 032/190
[A[ATraining Step: 8  | total loss: [1m[32m0.17717[0m[0m | time: 30.607s
[2K
| Adam | epoch: 002 | loss: 0.17717 - acc: 0.9551 -- iter: 064/190
[A[ATraining Step: 9  | total loss: [1m[32m0.23254[0m[0m | time: 51.164s
[2K
| Adam | epoch: 002 | loss: 0.23254 - acc: 0.9292 -- iter: 096/190
[A[ATraining Step: 10  | total loss: [1m[32m0.22090[0m[0m | time: 65.748s
[2K
| Adam | epoch: 002 | loss: 0.22090 - acc: 0.9334 -- iter: 128/190
[A[ATraining Step: 11  | total loss: [1m[32m0.13933[0m[0m | time: 76.241s
[2K
| Adam | epoch: 002 | loss: 0.13933 - acc: 0.9649 -- iter: 160/190
[A[ATraining Step: 12  | total loss: [1m[32m0.10776[0m[0m | time: 88.266s
[2K
| Adam | epoch: 002 | loss: 0.10776 - acc: 0.9666 | val_loss: 4.29475 - val_acc: 0.4500 -- iter: 190/190
--
Training Step: 13  | total loss: [1m[32m0.09614[0m[0m | time: 51.576s
[2K
| Adam | epoch: 003 | loss: 0.09614 - acc: 0.9809 -- iter: 032/190
[A[ATraining Step: 14  | total loss: [1m[32m0.07431[0m[0m | time: 103.566s
[2K
| Adam | epoch: 003 | loss: 0.07431 - acc: 0.9887 -- iter: 064/190
[A[ATraining Step: 15  | total loss: [1m[32m0.05158[0m[0m | time: 171.961s
[2K
| Adam | epoch: 003 | loss: 0.05158 - acc: 0.9931 -- iter: 096/190
[A[ATraining Step: 16  | total loss: [1m[32m0.05526[0m[0m | time: 230.709s
[2K
| Adam | epoch: 003 | loss: 0.05526 - acc: 0.9840 -- iter: 128/190
[A[ATraining Step: 17  | total loss: [1m[32m0.12827[0m[0m | time: 265.109s
[2K
| Adam | epoch: 003 | loss: 0.12827 - acc: 0.9673 -- iter: 160/190
[A[ATraining Step: 18  | total loss: [1m[32m0.09104[0m[0m | time: 298.360s
[2K
| Adam | epoch: 003 | loss: 0.09104 - acc: 0.9786 | val_loss: 4.47265 - val_acc: 0.4500 -- iter: 190/190
--
Training Step: 19  | total loss: [1m[32m0.06263[0m[0m | time: 16.377s
[2K
| Adam | epoch: 004 | loss: 0.06263 - acc: 0.9857 -- iter: 032/190
[A[ATraining Step: 20  | total loss: [1m[32m0.04569[0m[0m | time: 32.415s
[2K
| Adam | epoch: 004 | loss: 0.04569 - acc: 0.9903 -- iter: 064/190
[A[ATraining Step: 21  | total loss: [1m[32m0.03445[0m[0m | time: 51.032s
[2K
| Adam | epoch: 004 | loss: 0.03445 - acc: 0.9933 -- iter: 096/190
[A[ATraining Step: 22  | total loss: [1m[32m0.02501[0m[0m | time: 63.610s
[2K
| Adam | epoch: 004 | loss: 0.02501 - acc: 0.9953 -- iter: 128/190
[A[ATraining Step: 23  | total loss: [1m[32m0.01874[0m[0m | time: 74.207s
[2K
| Adam | epoch: 004 | loss: 0.01874 - acc: 0.9967 -- iter: 160/190
[A[ATraining Step: 24  | total loss: [1m[32m0.48860[0m[0m | time: 91.613s
[2K
| Adam | epoch: 004 | loss: 0.48860 - acc: 0.9361 | val_loss: 5.05415 - val_acc: 0.4500 -- iter: 190/190
--
Training Step: 25  | total loss: [1m[32m0.38425[0m[0m | time: 51.509s
[2K
| Adam | epoch: 005 | loss: 0.38425 - acc: 0.9450 -- iter: 032/190
[A[ATraining Step: 26  | total loss: [1m[32m0.30143[0m[0m | time: 104.380s
[2K
| Adam | epoch: 005 | loss: 0.30143 - acc: 0.9513 -- iter: 064/190
[A[ATraining Step: 27  | total loss: [1m[32m0.23930[0m[0m | time: 125.552s
[2K
| Adam | epoch: 005 | loss: 0.23930 - acc: 0.9558 -- iter: 096/190
[A[ATraining Step: 28  | total loss: [1m[32m0.21365[0m[0m | time: 167.880s
[2K
| Adam | epoch: 005 | loss: 0.21365 - acc: 0.9502 -- iter: 128/190
[A[ATraining Step: 29  | total loss: [1m[32m0.16623[0m[0m | time: 212.171s
[2K
| Adam | epoch: 005 | loss: 0.16623 - acc: 0.9623 -- iter: 160/190
[A[ATraining Step: 30  | total loss: [1m[32m0.18134[0m[0m | time: 239.064s
[2K
| Adam | epoch: 005 | loss: 0.18134 - acc: 0.9416 | val_loss: 4.66851 - val_acc: 0.4500 -- iter: 190/190
--
Training Step: 31  | total loss: [1m[32m0.23803[0m[0m | time: 16.365s
[2K
| Adam | epoch: 006 | loss: 0.23803 - acc: 0.9335 -- iter: 032/190
[A[ATraining Step: 32  | total loss: [1m[32m0.19735[0m[0m | time: 32.880s
[2K
| Adam | epoch: 006 | loss: 0.19735 - acc: 0.9484 -- iter: 064/190
[A[ATraining Step: 33  | total loss: [1m[32m0.19474[0m[0m | time: 49.367s
[2K
| Adam | epoch: 006 | loss: 0.19474 - acc: 0.9460 -- iter: 096/190
[A[ATraining Step: 34  | total loss: [1m[32m0.17410[0m[0m | time: 61.864s
[2K
| Adam | epoch: 006 | loss: 0.17410 - acc: 0.9576 -- iter: 128/190
[A[ATraining Step: 35  | total loss: [1m[32m0.14561[0m[0m | time: 72.232s
[2K
| Adam | epoch: 006 | loss: 0.14561 - acc: 0.9665 -- iter: 160/190
[A[ATraining Step: 36  | total loss: [1m[32m0.12143[0m[0m | time: 86.519s
[2K
| Adam | epoch: 006 | loss: 0.12143 - acc: 0.9733 | val_loss: 5.16441 - val_acc: 0.4500 -- iter: 190/190
--
Training Step: 37  | total loss: [1m[32m0.10482[0m[0m | time: 12.505s
[2K
| Adam | epoch: 007 | loss: 0.10482 - acc: 0.9787 -- iter: 032/190
[A[ATraining Step: 38  | total loss: [1m[32m0.09050[0m[0m | time: 22.647s
[2K
| Adam | epoch: 007 | loss: 0.09050 - acc: 0.9828 -- iter: 064/190
[A[ATraining Step: 39  | total loss: [1m[32m0.08458[0m[0m | time: 32.784s
[2K
| Adam | epoch: 007 | loss: 0.08458 - acc: 0.9801 -- iter: 096/190
[A[ATraining Step: 40  | total loss: [1m[32m0.08162[0m[0m | time: 42.744s
[2K
| Adam | epoch: 007 | loss: 0.08162 - acc: 0.9780 -- iter: 128/190
[A[ATraining Step: 41  | total loss: [1m[32m0.07354[0m[0m | time: 52.421s
[2K
| Adam | epoch: 007 | loss: 0.07354 - acc: 0.9763 -- iter: 160/190
[A[ATraining Step: 42  | total loss: [1m[32m0.06489[0m[0m | time: 65.314s
[2K
| Adam | epoch: 007 | loss: 0.06489 - acc: 0.9806 | val_loss: 5.12278 - val_acc: 0.4500 -- iter: 190/190
--
Training Step: 43  | total loss: [1m[32m0.05613[0m[0m | time: 10.110s
[2K
| Adam | epoch: 008 | loss: 0.05613 - acc: 0.9840 -- iter: 032/190
[A[ATraining Step: 44  | total loss: [1m[32m0.09656[0m[0m | time: 20.300s
[2K
| Adam | epoch: 008 | loss: 0.09656 - acc: 0.9651 -- iter: 064/190
[A[ATraining Step: 45  | total loss: [1m[32m0.11254[0m[0m | time: 30.664s
[2K
| Adam | epoch: 008 | loss: 0.11254 - acc: 0.9657 -- iter: 096/190
[A[ATraining Step: 46  | total loss: [1m[32m0.09465[0m[0m | time: 40.676s
[2K
| Adam | epoch: 008 | loss: 0.09465 - acc: 0.9715 -- iter: 128/190
[A[ATraining Step: 47  | total loss: [1m[32m0.08758[0m[0m | time: 50.391s
[2K
| Adam | epoch: 008 | loss: 0.08758 - acc: 0.9710 -- iter: 160/190
[A[ATraining Step: 48  | total loss: [1m[32m0.08599[0m[0m | time: 63.352s
[2K
| Adam | epoch: 008 | loss: 0.08599 - acc: 0.9706 | val_loss: 2.93361 - val_acc: 0.4667 -- iter: 190/190
--
Training Step: 49  | total loss: [1m[32m0.07635[0m[0m | time: 9.375s
[2K
| Adam | epoch: 009 | loss: 0.07635 - acc: 0.9753 -- iter: 032/190
[A[ATraining Step: 50  | total loss: [1m[32m0.06534[0m[0m | time: 17.530s
[2K
| Adam | epoch: 009 | loss: 0.06534 - acc: 0.9791 -- iter: 064/190
[A[ATraining Step: 51  | total loss: [1m[32m0.05889[0m[0m | time: 25.769s
[2K
| Adam | epoch: 009 | loss: 0.05889 - acc: 0.9823 -- iter: 096/190
[A[ATraining Step: 52  | total loss: [1m[32m0.10958[0m[0m | time: 34.038s
[2K
| Adam | epoch: 009 | loss: 0.10958 - acc: 0.9803 -- iter: 128/190
[A[ATraining Step: 53  | total loss: [1m[32m0.09383[0m[0m | time: 42.272s
[2K
| Adam | epoch: 009 | loss: 0.09383 - acc: 0.9832 -- iter: 160/190
[A[ATraining Step: 54  | total loss: [1m[32m0.08086[0m[0m | time: 53.058s
[2K
| Adam | epoch: 009 | loss: 0.08086 - acc: 0.9856 | val_loss: 3.06360 - val_acc: 0.4500 -- iter: 190/190
--
Training Step: 55  | total loss: [1m[32m0.07030[0m[0m | time: 7.818s
[2K
| Adam | epoch: 010 | loss: 0.07030 - acc: 0.9877 -- iter: 032/190
[A[ATraining Step: 56  | total loss: [1m[32m0.06211[0m[0m | time: 15.769s
[2K
| Adam | epoch: 010 | loss: 0.06211 - acc: 0.9894 -- iter: 064/190
[A[ATraining Step: 57  | total loss: [1m[32m0.05567[0m[0m | time: 23.773s
[2K
| Adam | epoch: 010 | loss: 0.05567 - acc: 0.9909 -- iter: 096/190
[A[ATraining Step: 58  | total loss: [1m[32m0.04888[0m[0m | time: 31.823s
[2K
| Adam | epoch: 010 | loss: 0.04888 - acc: 0.9921 -- iter: 128/190
[A[ATraining Step: 59  | total loss: [1m[32m0.04269[0m[0m | time: 39.902s
[2K
| Adam | epoch: 010 | loss: 0.04269 - acc: 0.9932 -- iter: 160/190
[A[ATraining Step: 60  | total loss: [1m[32m0.03821[0m[0m | time: 50.749s
[2K
| Adam | epoch: 010 | loss: 0.03821 - acc: 0.9941 | val_loss: 1.99490 - val_acc: 0.4667 -- iter: 190/190
--
Training Step: 61  | total loss: [1m[32m0.03381[0m[0m | time: 8.221s
[2K
| Adam | epoch: 011 | loss: 0.03381 - acc: 0.9949 -- iter: 032/190
[A[ATraining Step: 62  | total loss: [1m[32m0.03032[0m[0m | time: 16.248s
[2K
| Adam | epoch: 011 | loss: 0.03032 - acc: 0.9955 -- iter: 064/190
[A[ATraining Step: 63  | total loss: [1m[32m0.02740[0m[0m | time: 24.214s
[2K
| Adam | epoch: 011 | loss: 0.02740 - acc: 0.9961 -- iter: 096/190
[A[ATraining Step: 64  | total loss: [1m[32m0.02494[0m[0m | time: 32.422s
[2K
| Adam | epoch: 011 | loss: 0.02494 - acc: 0.9966 -- iter: 128/190
[A[ATraining Step: 65  | total loss: [1m[32m0.02381[0m[0m | time: 40.887s
[2K
| Adam | epoch: 011 | loss: 0.02381 - acc: 0.9970 -- iter: 160/190
[A[ATraining Step: 66  | total loss: [1m[32m0.27260[0m[0m | time: 52.105s
[2K
| Adam | epoch: 011 | loss: 0.27260 - acc: 0.9632 | val_loss: 0.14648 - val_acc: 0.9333 -- iter: 190/190
--
Training Step: 67  | total loss: [1m[32m0.24109[0m[0m | time: 8.262s
[2K
| Adam | epoch: 012 | loss: 0.24109 - acc: 0.9676 -- iter: 032/190
[A[ATraining Step: 68  | total loss: [1m[32m0.21482[0m[0m | time: 16.623s
[2K
| Adam | epoch: 012 | loss: 0.21482 - acc: 0.9714 -- iter: 064/190
[A[ATraining Step: 69  | total loss: [1m[32m0.19227[0m[0m | time: 24.447s
[2K
| Adam | epoch: 012 | loss: 0.19227 - acc: 0.9748 -- iter: 096/190
[A[ATraining Step: 70  | total loss: [1m[32m0.18196[0m[0m | time: 32.243s
[2K
| Adam | epoch: 012 | loss: 0.18196 - acc: 0.9738 -- iter: 128/190
[A[ATraining Step: 71  | total loss: [1m[32m0.16912[0m[0m | time: 40.585s
[2K
| Adam | epoch: 012 | loss: 0.16912 - acc: 0.9730 -- iter: 160/190
[A[ATraining Step: 72  | total loss: [1m[32m0.15365[0m[0m | time: 51.371s
[2K
| Adam | epoch: 012 | loss: 0.15365 - acc: 0.9760 | val_loss: 0.16921 - val_acc: 0.9500 -- iter: 190/190
--
Training Step: 73  | total loss: [1m[32m0.16418[0m[0m | time: 8.291s
[2K
| Adam | epoch: 013 | loss: 0.16418 - acc: 0.9752 -- iter: 032/190
[A[ATraining Step: 74  | total loss: [1m[32m0.14819[0m[0m | time: 16.414s
[2K
| Adam | epoch: 013 | loss: 0.14819 - acc: 0.9780 -- iter: 064/190
[A[ATraining Step: 75  | total loss: [1m[32m0.13640[0m[0m | time: 24.915s
[2K
| Adam | epoch: 013 | loss: 0.13640 - acc: 0.9803 -- iter: 096/190
[A[ATraining Step: 76  | total loss: [1m[32m0.12325[0m[0m | time: 32.835s
[2K
| Adam | epoch: 013 | loss: 0.12325 - acc: 0.9824 -- iter: 128/190
[A[ATraining Step: 77  | total loss: [1m[32m0.11220[0m[0m | time: 40.976s
[2K
| Adam | epoch: 013 | loss: 0.11220 - acc: 0.9843 -- iter: 160/190
[A[ATraining Step: 78  | total loss: [1m[32m0.10255[0m[0m | time: 52.260s
[2K
| Adam | epoch: 013 | loss: 0.10255 - acc: 0.9859 | val_loss: 0.12965 - val_acc: 0.9500 -- iter: 190/190
--
Training Step: 79  | total loss: [1m[32m0.09480[0m[0m | time: 8.367s
[2K
| Adam | epoch: 014 | loss: 0.09480 - acc: 0.9874 -- iter: 032/190
[A[ATraining Step: 80  | total loss: [1m[32m0.09593[0m[0m | time: 16.744s
[2K
| Adam | epoch: 014 | loss: 0.09593 - acc: 0.9855 -- iter: 064/190
[A[ATraining Step: 81  | total loss: [1m[32m0.08767[0m[0m | time: 25.202s
[2K
| Adam | epoch: 014 | loss: 0.08767 - acc: 0.9870 -- iter: 096/190
[A[ATraining Step: 82  | total loss: [1m[32m0.08029[0m[0m | time: 33.538s
[2K
| Adam | epoch: 014 | loss: 0.08029 - acc: 0.9883 -- iter: 128/190
[A[ATraining Step: 83  | total loss: [1m[32m0.07331[0m[0m | time: 41.445s
[2K
| Adam | epoch: 014 | loss: 0.07331 - acc: 0.9894 -- iter: 160/190
[A[ATraining Step: 84  | total loss: [1m[32m0.06694[0m[0m | time: 52.016s
[2K
| Adam | epoch: 014 | loss: 0.06694 - acc: 0.9905 | val_loss: 0.14616 - val_acc: 0.9667 -- iter: 190/190
--
Training Step: 85  | total loss: [1m[32m0.06106[0m[0m | time: 8.395s
[2K
| Adam | epoch: 015 | loss: 0.06106 - acc: 0.9914 -- iter: 032/190
[A[ATraining Step: 86  | total loss: [1m[32m0.05555[0m[0m | time: 16.913s
[2K
| Adam | epoch: 015 | loss: 0.05555 - acc: 0.9923 -- iter: 064/190
[A[ATraining Step: 87  | total loss: [1m[32m0.05049[0m[0m | time: 25.170s
[2K
| Adam | epoch: 015 | loss: 0.05049 - acc: 0.9931 -- iter: 096/190
[A[ATraining Step: 88  | total loss: [1m[32m0.04641[0m[0m | time: 33.658s
[2K
| Adam | epoch: 015 | loss: 0.04641 - acc: 0.9938 -- iter: 128/190
[A[ATraining Step: 89  | total loss: [1m[32m0.04381[0m[0m | time: 42.052s
[2K
| Adam | epoch: 015 | loss: 0.04381 - acc: 0.9944 -- iter: 160/190
[A[ATraining Step: 90  | total loss: [1m[32m0.04012[0m[0m | time: 52.809s
[2K
| Adam | epoch: 015 | loss: 0.04012 - acc: 0.9949 | val_loss: 0.11035 - val_acc: 0.9833 -- iter: 190/190
--
Validation AUC:0.9876543209876544
Validation AUPRC:0.9892787524366469
Test AUC:1.0
Test AUPRC:1.0
BestTestF1Score	0.98	0.97	0.98	1.0	0.97	31	0	28	1	0.87
BestTestMCCScore	0.98	0.97	0.98	1.0	0.97	31	0	28	1	0.87
BestTestAccuracyScore	0.98	0.97	0.98	1.0	0.97	31	0	28	1	0.87
BestValidationF1Score	0.98	0.97	0.98	1.0	0.96	26	0	33	1	0.87
BestValidationMCC	0.98	0.97	0.98	1.0	0.96	26	0	33	1	0.87
BestValidationAccuracy	0.98	0.97	0.98	1.0	0.96	26	0	33	1	0.87
TestPredictions (Threshold:0.87)
CHEMBL119562,TP,ACT,1.0	CHEMBL209076,TP,ACT,1.0	CHEMBL541890,TP,ACT,1.0	CHEMBL118068,TP,ACT,1.0	CHEMBL296419,TN,INACT,0.0	CHEMBL75200,TN,INACT,0.0	CHEMBL3806205,TP,ACT,0.9900000095367432	CHEMBL421349,TN,INACT,0.0	CHEMBL101239,TN,INACT,0.0	CHEMBL316247,TN,INACT,0.0	CHEMBL1791272,TN,INACT,0.0	CHEMBL437,TN,INACT,0.009999999776482582	CHEMBL224800,TP,ACT,0.9200000166893005	CHEMBL198976,TP,ACT,1.0	CHEMBL574597,TN,INACT,0.0	CHEMBL115714,TP,ACT,1.0	CHEMBL184879,TP,ACT,1.0	CHEMBL74330,TN,INACT,0.10000000149011612	CHEMBL207580,TP,ACT,0.9900000095367432	CHEMBL392149,TN,INACT,0.0	CHEMBL308634,TN,INACT,0.10000000149011612	CHEMBL537849,TP,ACT,1.0	CHEMBL1765670,TN,INACT,0.0	CHEMBL117973,TP,ACT,1.0	CHEMBL389880,TP,ACT,1.0	CHEMBL364950,TP,ACT,1.0	CHEMBL515603,FN,ACT,0.550000011920929	CHEMBL316648,TN,INACT,0.0	CHEMBL119516,TP,ACT,1.0	CHEMBL80945,TN,INACT,0.019999999552965164	CHEMBL377855,TP,ACT,0.9900000095367432	CHEMBL73740,TN,INACT,0.0	CHEMBL377637,TP,ACT,0.9900000095367432	CHEMBL279898,TN,INACT,0.0	CHEMBL183894,TP,ACT,1.0	CHEMBL541164,TN,INACT,0.0	CHEMBL195141,TP,ACT,0.949999988079071	CHEMBL115344,TP,ACT,0.9800000190734863	CHEMBL3114143,TN,INACT,0.0	CHEMBL3736248,TN,INACT,0.0	CHEMBL115554,TP,ACT,1.0	CHEMBL2324200,TN,INACT,0.0	CHEMBL474688,TP,ACT,1.0	CHEMBL296908,TN,INACT,0.0	CHEMBL1093823,TP,ACT,0.8899999856948853	CHEMBL453822,TN,INACT,0.0	CHEMBL210468,TP,ACT,0.9900000095367432	CHEMBL427221,TP,ACT,0.9900000095367432	CHEMBL432809,TP,ACT,1.0	CHEMBL46195,TN,INACT,0.009999999776482582	CHEMBL116140,TP,ACT,1.0	CHEMBL286214,TN,INACT,0.0	CHEMBL315096,TN,INACT,0.0	CHEMBL184349,TP,ACT,1.0	CHEMBL510130,TN,INACT,0.0	CHEMBL515921,TP,ACT,1.0	CHEMBL332471,TN,INACT,0.019999999552965164	CHEMBL210257,TP,ACT,1.0	CHEMBL181597,TP,ACT,1.0	CHEMBL3735151,TN,INACT,0.0	

