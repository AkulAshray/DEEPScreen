ImageNetInceptionV2 CHEMBL2074 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	103
Number of inactive compounds :	103
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2074_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2074_adam_0.0001_15_0.8/
---------------------------------
Training samples: 102
Validation samples: 33
--
Training Step: 1  | time: 146.814s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/102
[A[ATraining Step: 2  | total loss: [1m[32m0.65081[0m[0m | time: 249.728s
[2K
| Adam | epoch: 001 | loss: 0.65081 - acc: 0.4219 -- iter: 064/102
[A[ATraining Step: 3  | total loss: [1m[32m0.62192[0m[0m | time: 358.669s
[2K
| Adam | epoch: 001 | loss: 0.62192 - acc: 0.5881 -- iter: 096/102
[A[ATraining Step: 4  | total loss: [1m[32m0.51977[0m[0m | time: 368.366s
[2K
| Adam | epoch: 001 | loss: 0.51977 - acc: 0.7798 | val_loss: 0.85916 - val_acc: 0.3333 -- iter: 102/102
--
Training Step: 5  | total loss: [1m[32m0.41302[0m[0m | time: 2.789s
[2K
| Adam | epoch: 002 | loss: 0.41302 - acc: 0.9323 -- iter: 032/102
[A[ATraining Step: 6  | total loss: [1m[32m0.22324[0m[0m | time: 184.943s
[2K
| Adam | epoch: 002 | loss: 0.22324 - acc: 0.9758 -- iter: 064/102
[A[ATraining Step: 7  | total loss: [1m[32m0.40147[0m[0m | time: 296.931s
[2K
| Adam | epoch: 002 | loss: 0.40147 - acc: 0.8591 -- iter: 096/102
[A[ATraining Step: 8  | total loss: [1m[32m0.36537[0m[0m | time: 416.800s
[2K
| Adam | epoch: 002 | loss: 0.36537 - acc: 0.8680 | val_loss: 1.45261 - val_acc: 0.3333 -- iter: 102/102
--
Training Step: 9  | total loss: [1m[32m0.29158[0m[0m | time: 2.753s
[2K
| Adam | epoch: 003 | loss: 0.29158 - acc: 0.9048 -- iter: 032/102
[A[ATraining Step: 10  | total loss: [1m[32m0.39807[0m[0m | time: 5.502s
[2K
| Adam | epoch: 003 | loss: 0.39807 - acc: 0.7857 -- iter: 064/102
[A[ATraining Step: 11  | total loss: [1m[32m0.33822[0m[0m | time: 106.512s
[2K
| Adam | epoch: 003 | loss: 0.33822 - acc: 0.8872 -- iter: 096/102
[A[ATraining Step: 12  | total loss: [1m[32m0.36998[0m[0m | time: 124.186s
[2K
| Adam | epoch: 003 | loss: 0.36998 - acc: 0.8255 | val_loss: 1.77202 - val_acc: 0.3333 -- iter: 102/102
--
Training Step: 13  | total loss: [1m[32m0.29896[0m[0m | time: 83.873s
[2K
| Adam | epoch: 004 | loss: 0.29896 - acc: 0.8735 -- iter: 032/102
[A[ATraining Step: 14  | total loss: [1m[32m0.27163[0m[0m | time: 86.938s
[2K
| Adam | epoch: 004 | loss: 0.27163 - acc: 0.8869 -- iter: 064/102
[A[ATraining Step: 15  | total loss: [1m[32m0.21385[0m[0m | time: 89.446s
[2K
| Adam | epoch: 004 | loss: 0.21385 - acc: 0.9312 -- iter: 096/102
[A[ATraining Step: 16  | total loss: [1m[32m0.15799[0m[0m | time: 128.244s
[2K
| Adam | epoch: 004 | loss: 0.15799 - acc: 0.9570 | val_loss: 1.83165 - val_acc: 0.3333 -- iter: 102/102
--
Training Step: 17  | total loss: [1m[32m0.15215[0m[0m | time: 56.744s
[2K
| Adam | epoch: 005 | loss: 0.15215 - acc: 0.9612 -- iter: 032/102
[A[ATraining Step: 18  | total loss: [1m[32m0.14239[0m[0m | time: 126.404s
[2K
| Adam | epoch: 005 | loss: 0.14239 - acc: 0.9638 -- iter: 064/102
[A[ATraining Step: 19  | total loss: [1m[32m0.13786[0m[0m | time: 129.201s
[2K
| Adam | epoch: 005 | loss: 0.13786 - acc: 0.9759 -- iter: 096/102
[A[ATraining Step: 20  | total loss: [1m[32m0.32031[0m[0m | time: 133.811s
[2K
| Adam | epoch: 005 | loss: 0.32031 - acc: 0.8229 | val_loss: 2.49801 - val_acc: 0.3333 -- iter: 102/102
--
Training Step: 21  | total loss: [1m[32m0.38576[0m[0m | time: 19.651s
[2K
| Adam | epoch: 006 | loss: 0.38576 - acc: 0.8262 -- iter: 032/102
[A[ATraining Step: 22  | total loss: [1m[32m0.28102[0m[0m | time: 107.321s
[2K
| Adam | epoch: 006 | loss: 0.28102 - acc: 0.8783 -- iter: 064/102
[A[ATraining Step: 23  | total loss: [1m[32m0.23082[0m[0m | time: 154.039s
[2K
| Adam | epoch: 006 | loss: 0.23082 - acc: 0.9046 -- iter: 096/102
[A[ATraining Step: 24  | total loss: [1m[32m0.18013[0m[0m | time: 157.947s
[2K
| Adam | epoch: 006 | loss: 0.18013 - acc: 0.9314 | val_loss: 2.36932 - val_acc: 0.3333 -- iter: 102/102
--
Training Step: 25  | total loss: [1m[32m0.30290[0m[0m | time: 2.250s
[2K
| Adam | epoch: 007 | loss: 0.30290 - acc: 0.9047 -- iter: 032/102
[A[ATraining Step: 26  | total loss: [1m[32m0.28334[0m[0m | time: 17.447s
[2K
| Adam | epoch: 007 | loss: 0.28334 - acc: 0.8858 -- iter: 064/102
[A[ATraining Step: 27  | total loss: [1m[32m0.23602[0m[0m | time: 41.121s
[2K
| Adam | epoch: 007 | loss: 0.23602 - acc: 0.9071 -- iter: 096/102
[A[ATraining Step: 28  | total loss: [1m[32m0.25322[0m[0m | time: 69.953s
[2K
| Adam | epoch: 007 | loss: 0.25322 - acc: 0.9147 | val_loss: 1.59647 - val_acc: 0.3333 -- iter: 102/102
--
Training Step: 29  | total loss: [1m[32m0.19550[0m[0m | time: 2.239s
[2K
| Adam | epoch: 008 | loss: 0.19550 - acc: 0.9355 -- iter: 032/102
[A[ATraining Step: 30  | total loss: [1m[32m0.15212[0m[0m | time: 4.629s
[2K
| Adam | epoch: 008 | loss: 0.15212 - acc: 0.9507 -- iter: 064/102
[A[ATraining Step: 31  | total loss: [1m[32m0.11933[0m[0m | time: 26.428s
[2K
| Adam | epoch: 008 | loss: 0.11933 - acc: 0.9621 -- iter: 096/102
[A[ATraining Step: 32  | total loss: [1m[32m0.09952[0m[0m | time: 36.588s
[2K
| Adam | epoch: 008 | loss: 0.09952 - acc: 0.9706 | val_loss: 1.04467 - val_acc: 0.3636 -- iter: 102/102
--
Training Step: 33  | total loss: [1m[32m0.09701[0m[0m | time: 34.836s
[2K
| Adam | epoch: 009 | loss: 0.09701 - acc: 0.9702 -- iter: 032/102
[A[ATraining Step: 34  | total loss: [1m[32m0.07969[0m[0m | time: 37.144s
[2K
| Adam | epoch: 009 | loss: 0.07969 - acc: 0.9766 -- iter: 064/102
[A[ATraining Step: 35  | total loss: [1m[32m0.07478[0m[0m | time: 39.407s
[2K
| Adam | epoch: 009 | loss: 0.07478 - acc: 0.9815 -- iter: 096/102
[A[ATraining Step: 36  | total loss: [1m[32m0.06228[0m[0m | time: 72.467s
[2K
| Adam | epoch: 009 | loss: 0.06228 - acc: 0.9853 | val_loss: 0.84731 - val_acc: 0.4545 -- iter: 102/102
--
Training Step: 37  | total loss: [1m[32m0.05640[0m[0m | time: 15.420s
[2K
| Adam | epoch: 010 | loss: 0.05640 - acc: 0.9882 -- iter: 032/102
[A[ATraining Step: 38  | total loss: [1m[32m0.07230[0m[0m | time: 25.623s
[2K
| Adam | epoch: 010 | loss: 0.07230 - acc: 0.9844 -- iter: 064/102
[A[ATraining Step: 39  | total loss: [1m[32m0.06185[0m[0m | time: 27.920s
[2K
| Adam | epoch: 010 | loss: 0.06185 - acc: 0.9874 -- iter: 096/102
[A[ATraining Step: 40  | total loss: [1m[32m0.05366[0m[0m | time: 32.011s
[2K
| Adam | epoch: 010 | loss: 0.05366 - acc: 0.9898 | val_loss: 0.78313 - val_acc: 0.5758 -- iter: 102/102
--
Training Step: 41  | total loss: [1m[32m0.04538[0m[0m | time: 18.435s
[2K
| Adam | epoch: 011 | loss: 0.04538 - acc: 0.9916 -- iter: 032/102
[A[ATraining Step: 42  | total loss: [1m[32m0.04131[0m[0m | time: 41.972s
[2K
| Adam | epoch: 011 | loss: 0.04131 - acc: 0.9931 -- iter: 064/102
[A[ATraining Step: 43  | total loss: [1m[32m0.05183[0m[0m | time: 54.029s
[2K
| Adam | epoch: 011 | loss: 0.05183 - acc: 0.9888 -- iter: 096/102
[A[ATraining Step: 44  | total loss: [1m[32m0.04477[0m[0m | time: 58.188s
[2K
| Adam | epoch: 011 | loss: 0.04477 - acc: 0.9908 | val_loss: 0.74180 - val_acc: 0.6061 -- iter: 102/102
--
Training Step: 45  | total loss: [1m[32m0.03885[0m[0m | time: 2.360s
[2K
| Adam | epoch: 012 | loss: 0.03885 - acc: 0.9923 -- iter: 032/102
[A[ATraining Step: 46  | total loss: [1m[32m0.03389[0m[0m | time: 15.198s
[2K
| Adam | epoch: 012 | loss: 0.03389 - acc: 0.9936 -- iter: 064/102
[A[ATraining Step: 47  | total loss: [1m[32m0.02963[0m[0m | time: 50.541s
[2K
| Adam | epoch: 012 | loss: 0.02963 - acc: 0.9947 -- iter: 096/102
[A[ATraining Step: 48  | total loss: [1m[32m0.02662[0m[0m | time: 78.044s
[2K
| Adam | epoch: 012 | loss: 0.02662 - acc: 0.9955 | val_loss: 0.80398 - val_acc: 0.6970 -- iter: 102/102
--
Training Step: 49  | total loss: [1m[32m0.02423[0m[0m | time: 2.374s
[2K
| Adam | epoch: 013 | loss: 0.02423 - acc: 0.9962 -- iter: 032/102
[A[ATraining Step: 50  | total loss: [1m[32m0.02106[0m[0m | time: 4.893s
[2K
| Adam | epoch: 013 | loss: 0.02106 - acc: 0.9968 -- iter: 064/102
[A[ATraining Step: 51  | total loss: [1m[32m0.01836[0m[0m | time: 30.435s
[2K
| Adam | epoch: 013 | loss: 0.01836 - acc: 0.9973 -- iter: 096/102
[A[ATraining Step: 52  | total loss: [1m[32m0.01705[0m[0m | time: 59.870s
[2K
| Adam | epoch: 013 | loss: 0.01705 - acc: 0.9977 | val_loss: 0.88450 - val_acc: 0.6970 -- iter: 102/102
--
Training Step: 53  | total loss: [1m[32m0.01491[0m[0m | time: 36.801s
[2K
| Adam | epoch: 014 | loss: 0.01491 - acc: 0.9980 -- iter: 032/102
[A[ATraining Step: 54  | total loss: [1m[32m0.01318[0m[0m | time: 39.232s
[2K
| Adam | epoch: 014 | loss: 0.01318 - acc: 0.9983 -- iter: 064/102
[A[ATraining Step: 55  | total loss: [1m[32m0.02450[0m[0m | time: 41.808s
[2K
| Adam | epoch: 014 | loss: 0.02450 - acc: 0.9986 -- iter: 096/102
[A[ATraining Step: 56  | total loss: [1m[32m0.02702[0m[0m | time: 56.921s
[2K
| Adam | epoch: 014 | loss: 0.02702 - acc: 0.9988 | val_loss: 0.85570 - val_acc: 0.6970 -- iter: 102/102
--
Training Step: 57  | total loss: [1m[32m0.02382[0m[0m | time: 29.729s
[2K
| Adam | epoch: 015 | loss: 0.02382 - acc: 0.9989 -- iter: 032/102
[A[ATraining Step: 58  | total loss: [1m[32m0.05264[0m[0m | time: 51.295s
[2K
| Adam | epoch: 015 | loss: 0.05264 - acc: 0.9948 -- iter: 064/102
[A[ATraining Step: 59  | total loss: [1m[32m0.04581[0m[0m | time: 53.666s
[2K
| Adam | epoch: 015 | loss: 0.04581 - acc: 0.9955 -- iter: 096/102
[A[ATraining Step: 60  | total loss: [1m[32m0.04026[0m[0m | time: 57.781s
[2K
| Adam | epoch: 015 | loss: 0.04026 - acc: 0.9961 | val_loss: 1.46553 - val_acc: 0.4848 -- iter: 102/102
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.6611570247933884
Validation AUPRC:0.7189561466757559
Test AUC:0.8373015873015873
Test AUPRC:0.9121101709999229
BestTestF1Score	0.81	0.38	0.73	0.73	0.9	19	7	5	2	0.03
BestTestMCCScore	0.86	0.6	0.82	0.83	0.9	19	4	8	2	0.09
BestTestAccuracyScore	0.86	0.6	0.82	0.83	0.9	19	4	8	2	0.09
BestValidationF1Score	0.83	0.43	0.76	0.79	0.86	19	5	6	3	0.03
BestValidationMCC	0.81	0.48	0.76	0.85	0.77	17	3	8	5	0.09
BestValidationAccuracy	0.81	0.48	0.76	0.85	0.77	17	3	8	5	0.09
TestPredictions (Threshold:0.09)
CHEMBL239249,TP,ACT,0.8100000023841858	CHEMBL1086997,TP,ACT,0.8700000047683716	CHEMBL3354062,TP,ACT,0.4300000071525574	CHEMBL2051979,FP,INACT,0.8100000023841858	CHEMBL2111688,FP,INACT,0.4099999964237213	CHEMBL1208974,TP,ACT,0.8100000023841858	CHEMBL3407632,TP,ACT,0.8899999856948853	CHEMBL2442258,TP,ACT,0.20000000298023224	CHEMBL2374255,TP,ACT,0.8799999952316284	CHEMBL3354621,TP,ACT,0.28999999165534973	CHEMBL2374252,FP,INACT,0.18000000715255737	CHEMBL2347144,TN,INACT,0.03999999910593033	CHEMBL108084,TN,INACT,0.05999999865889549	CHEMBL8260,TN,INACT,0.05999999865889549	CHEMBL3407638,FN,ACT,0.009999999776482582	CHEMBL501355,TP,ACT,0.6499999761581421	CHEMBL3814988,TP,ACT,0.8399999737739563	CHEMBL2181091,TN,INACT,0.029999999329447746	CHEMBL2051760,TP,ACT,0.8999999761581421	CHEMBL108656,FP,INACT,0.25999999046325684	CHEMBL1277241,TP,ACT,0.9200000166893005	CHEMBL1277062,TP,ACT,0.6200000047683716	CHEMBL3354626,TP,ACT,0.6899999976158142	CHEMBL1939428,TN,INACT,0.0	CHEMBL267963,TN,INACT,0.009999999776482582	CHEMBL1258528,TP,ACT,0.7699999809265137	CHEMBL2114210,TP,ACT,0.550000011920929	CHEMBL332802,TP,ACT,0.11999999731779099	CHEMBL3407637,FN,ACT,0.009999999776482582	CHEMBL1892795,TN,INACT,0.009999999776482582	CHEMBL1258529,TP,ACT,0.5600000023841858	CHEMBL120169,TP,ACT,0.09000000357627869	CHEMBL1744444,TN,INACT,0.009999999776482582	

