ImageNetInceptionV2 CHEMBL4564 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	104
Number of inactive compounds :	104
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4564_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4564_adam_0.0001_15_0.6/
---------------------------------
Training samples: 132
Validation samples: 42
--
Training Step: 1  | time: 37.029s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/132
[A[ATraining Step: 2  | total loss: [1m[32m0.60293[0m[0m | time: 45.122s
[2K
| Adam | epoch: 001 | loss: 0.60293 - acc: 0.5344 -- iter: 064/132
[A[ATraining Step: 3  | total loss: [1m[32m0.58233[0m[0m | time: 53.001s
[2K
| Adam | epoch: 001 | loss: 0.58233 - acc: 0.7364 -- iter: 096/132
[A[ATraining Step: 4  | total loss: [1m[32m0.46914[0m[0m | time: 61.083s
[2K
| Adam | epoch: 001 | loss: 0.46914 - acc: 0.8403 -- iter: 128/132
[A[ATraining Step: 5  | total loss: [1m[32m0.46030[0m[0m | time: 71.065s
[2K
| Adam | epoch: 001 | loss: 0.46030 - acc: 0.8643 | val_loss: 0.92118 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 6  | total loss: [1m[32m0.51059[0m[0m | time: 1.846s
[2K
| Adam | epoch: 002 | loss: 0.51059 - acc: 0.7908 -- iter: 032/132
[A[ATraining Step: 7  | total loss: [1m[32m0.33908[0m[0m | time: 9.662s
[2K
| Adam | epoch: 002 | loss: 0.33908 - acc: 0.9163 -- iter: 064/132
[A[ATraining Step: 8  | total loss: [1m[32m0.35987[0m[0m | time: 17.569s
[2K
| Adam | epoch: 002 | loss: 0.35987 - acc: 0.9107 -- iter: 096/132
[A[ATraining Step: 9  | total loss: [1m[32m0.43699[0m[0m | time: 25.475s
[2K
| Adam | epoch: 002 | loss: 0.43699 - acc: 0.8091 -- iter: 128/132
[A[ATraining Step: 10  | total loss: [1m[32m0.41129[0m[0m | time: 35.309s
[2K
| Adam | epoch: 002 | loss: 0.41129 - acc: 0.8108 | val_loss: 1.84466 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 11  | total loss: [1m[32m0.32106[0m[0m | time: 1.863s
[2K
| Adam | epoch: 003 | loss: 0.32106 - acc: 0.8856 -- iter: 032/132
[A[ATraining Step: 12  | total loss: [1m[32m0.22967[0m[0m | time: 3.696s
[2K
| Adam | epoch: 003 | loss: 0.22967 - acc: 0.9371 -- iter: 064/132
[A[ATraining Step: 13  | total loss: [1m[32m0.16934[0m[0m | time: 11.485s
[2K
| Adam | epoch: 003 | loss: 0.16934 - acc: 0.9640 -- iter: 096/132
[A[ATraining Step: 14  | total loss: [1m[32m0.18168[0m[0m | time: 19.370s
[2K
| Adam | epoch: 003 | loss: 0.18168 - acc: 0.9660 -- iter: 128/132
[A[ATraining Step: 15  | total loss: [1m[32m0.20284[0m[0m | time: 29.094s
[2K
| Adam | epoch: 003 | loss: 0.20284 - acc: 0.9304 | val_loss: 2.37936 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 16  | total loss: [1m[32m0.20212[0m[0m | time: 7.871s
[2K
| Adam | epoch: 004 | loss: 0.20212 - acc: 0.9448 -- iter: 032/132
[A[ATraining Step: 17  | total loss: [1m[32m0.17192[0m[0m | time: 9.698s
[2K
| Adam | epoch: 004 | loss: 0.17192 - acc: 0.9534 -- iter: 064/132
[A[ATraining Step: 18  | total loss: [1m[32m0.28533[0m[0m | time: 11.558s
[2K
| Adam | epoch: 004 | loss: 0.28533 - acc: 0.8830 -- iter: 096/132
[A[ATraining Step: 19  | total loss: [1m[32m0.26477[0m[0m | time: 19.271s
[2K
| Adam | epoch: 004 | loss: 0.26477 - acc: 0.9220 -- iter: 128/132
[A[ATraining Step: 20  | total loss: [1m[32m0.19757[0m[0m | time: 29.093s
[2K
| Adam | epoch: 004 | loss: 0.19757 - acc: 0.9471 | val_loss: 2.51166 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 21  | total loss: [1m[32m0.15881[0m[0m | time: 7.778s
[2K
| Adam | epoch: 005 | loss: 0.15881 - acc: 0.9635 -- iter: 032/132
[A[ATraining Step: 22  | total loss: [1m[32m0.12329[0m[0m | time: 15.750s
[2K
| Adam | epoch: 005 | loss: 0.12329 - acc: 0.9744 -- iter: 064/132
[A[ATraining Step: 23  | total loss: [1m[32m0.09632[0m[0m | time: 17.548s
[2K
| Adam | epoch: 005 | loss: 0.09632 - acc: 0.9819 -- iter: 096/132
[A[ATraining Step: 24  | total loss: [1m[32m0.07484[0m[0m | time: 19.397s
[2K
| Adam | epoch: 005 | loss: 0.07484 - acc: 0.9870 -- iter: 128/132
[A[ATraining Step: 25  | total loss: [1m[32m0.05842[0m[0m | time: 29.163s
[2K
| Adam | epoch: 005 | loss: 0.05842 - acc: 0.9905 | val_loss: 2.23614 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 26  | total loss: [1m[32m0.04837[0m[0m | time: 7.988s
[2K
| Adam | epoch: 006 | loss: 0.04837 - acc: 0.9930 -- iter: 032/132
[A[ATraining Step: 27  | total loss: [1m[32m0.04492[0m[0m | time: 15.648s
[2K
| Adam | epoch: 006 | loss: 0.04492 - acc: 0.9948 -- iter: 064/132
[A[ATraining Step: 28  | total loss: [1m[32m0.07165[0m[0m | time: 23.398s
[2K
| Adam | epoch: 006 | loss: 0.07165 - acc: 0.9883 -- iter: 096/132
[A[ATraining Step: 29  | total loss: [1m[32m0.05709[0m[0m | time: 25.204s
[2K
| Adam | epoch: 006 | loss: 0.05709 - acc: 0.9911 -- iter: 128/132
[A[ATraining Step: 30  | total loss: [1m[32m0.05268[0m[0m | time: 28.917s
[2K
| Adam | epoch: 006 | loss: 0.05268 - acc: 0.9932 | val_loss: 1.84195 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 31  | total loss: [1m[32m0.04636[0m[0m | time: 7.907s
[2K
| Adam | epoch: 007 | loss: 0.04636 - acc: 0.9948 -- iter: 032/132
[A[ATraining Step: 32  | total loss: [1m[32m0.03908[0m[0m | time: 15.793s
[2K
| Adam | epoch: 007 | loss: 0.03908 - acc: 0.9960 -- iter: 064/132
[A[ATraining Step: 33  | total loss: [1m[32m0.03782[0m[0m | time: 23.732s
[2K
| Adam | epoch: 007 | loss: 0.03782 - acc: 0.9969 -- iter: 096/132
[A[ATraining Step: 34  | total loss: [1m[32m0.04317[0m[0m | time: 31.472s
[2K
| Adam | epoch: 007 | loss: 0.04317 - acc: 0.9908 -- iter: 128/132
[A[ATraining Step: 35  | total loss: [1m[32m0.03647[0m[0m | time: 35.237s
[2K
| Adam | epoch: 007 | loss: 0.03647 - acc: 0.9928 | val_loss: 1.69061 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 36  | total loss: [1m[32m0.03964[0m[0m | time: 1.779s
[2K
| Adam | epoch: 008 | loss: 0.03964 - acc: 0.9942 -- iter: 032/132
[A[ATraining Step: 37  | total loss: [1m[32m0.03763[0m[0m | time: 9.571s
[2K
| Adam | epoch: 008 | loss: 0.03763 - acc: 0.9954 -- iter: 064/132
[A[ATraining Step: 38  | total loss: [1m[32m0.03215[0m[0m | time: 17.389s
[2K
| Adam | epoch: 008 | loss: 0.03215 - acc: 0.9963 -- iter: 096/132
[A[ATraining Step: 39  | total loss: [1m[32m0.02949[0m[0m | time: 25.323s
[2K
| Adam | epoch: 008 | loss: 0.02949 - acc: 0.9970 -- iter: 128/132
[A[ATraining Step: 40  | total loss: [1m[32m0.08820[0m[0m | time: 35.030s
[2K
| Adam | epoch: 008 | loss: 0.08820 - acc: 0.9858 | val_loss: 1.34277 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 41  | total loss: [1m[32m0.07468[0m[0m | time: 1.792s
[2K
| Adam | epoch: 009 | loss: 0.07468 - acc: 0.9884 -- iter: 032/132
[A[ATraining Step: 42  | total loss: [1m[32m0.06509[0m[0m | time: 3.575s
[2K
| Adam | epoch: 009 | loss: 0.06509 - acc: 0.9905 -- iter: 064/132
[A[ATraining Step: 43  | total loss: [1m[32m0.05551[0m[0m | time: 11.492s
[2K
| Adam | epoch: 009 | loss: 0.05551 - acc: 0.9922 -- iter: 096/132
[A[ATraining Step: 44  | total loss: [1m[32m0.04749[0m[0m | time: 19.482s
[2K
| Adam | epoch: 009 | loss: 0.04749 - acc: 0.9935 -- iter: 128/132
[A[ATraining Step: 45  | total loss: [1m[32m0.04264[0m[0m | time: 29.547s
[2K
| Adam | epoch: 009 | loss: 0.04264 - acc: 0.9946 | val_loss: 1.01269 - val_acc: 0.5714 -- iter: 132/132
--
Training Step: 46  | total loss: [1m[32m0.05230[0m[0m | time: 7.782s
[2K
| Adam | epoch: 010 | loss: 0.05230 - acc: 0.9903 -- iter: 032/132
[A[ATraining Step: 47  | total loss: [1m[32m0.04431[0m[0m | time: 9.565s
[2K
| Adam | epoch: 010 | loss: 0.04431 - acc: 0.9919 -- iter: 064/132
[A[ATraining Step: 48  | total loss: [1m[32m0.04014[0m[0m | time: 11.352s
[2K
| Adam | epoch: 010 | loss: 0.04014 - acc: 0.9932 -- iter: 096/132
[A[ATraining Step: 49  | total loss: [1m[32m0.03426[0m[0m | time: 18.993s
[2K
| Adam | epoch: 010 | loss: 0.03426 - acc: 0.9943 -- iter: 128/132
[A[ATraining Step: 50  | total loss: [1m[32m0.03011[0m[0m | time: 28.760s
[2K
| Adam | epoch: 010 | loss: 0.03011 - acc: 0.9952 | val_loss: 0.59860 - val_acc: 0.6905 -- iter: 132/132
--
Training Step: 51  | total loss: [1m[32m0.05301[0m[0m | time: 7.588s
[2K
| Adam | epoch: 011 | loss: 0.05301 - acc: 0.9864 -- iter: 032/132
[A[ATraining Step: 52  | total loss: [1m[32m0.04559[0m[0m | time: 15.603s
[2K
| Adam | epoch: 011 | loss: 0.04559 - acc: 0.9884 -- iter: 064/132
[A[ATraining Step: 53  | total loss: [1m[32m0.04122[0m[0m | time: 17.348s
[2K
| Adam | epoch: 011 | loss: 0.04122 - acc: 0.9901 -- iter: 096/132
[A[ATraining Step: 54  | total loss: [1m[32m0.03626[0m[0m | time: 19.050s
[2K
| Adam | epoch: 011 | loss: 0.03626 - acc: 0.9916 -- iter: 128/132
[A[ATraining Step: 55  | total loss: [1m[32m0.03157[0m[0m | time: 28.770s
[2K
| Adam | epoch: 011 | loss: 0.03157 - acc: 0.9928 | val_loss: 0.77634 - val_acc: 0.6667 -- iter: 132/132
--
Training Step: 56  | total loss: [1m[32m0.04803[0m[0m | time: 7.718s
[2K
| Adam | epoch: 012 | loss: 0.04803 - acc: 0.9894 -- iter: 032/132
[A[ATraining Step: 57  | total loss: [1m[32m0.04308[0m[0m | time: 15.519s
[2K
| Adam | epoch: 012 | loss: 0.04308 - acc: 0.9909 -- iter: 064/132
[A[ATraining Step: 58  | total loss: [1m[32m0.05401[0m[0m | time: 23.153s
[2K
| Adam | epoch: 012 | loss: 0.05401 - acc: 0.9878 -- iter: 096/132
[A[ATraining Step: 59  | total loss: [1m[32m0.04719[0m[0m | time: 24.885s
[2K
| Adam | epoch: 012 | loss: 0.04719 - acc: 0.9895 -- iter: 128/132
[A[ATraining Step: 60  | total loss: [1m[32m0.04954[0m[0m | time: 28.595s
[2K
| Adam | epoch: 012 | loss: 0.04954 - acc: 0.9909 | val_loss: 1.27662 - val_acc: 0.5952 -- iter: 132/132
--
Training Step: 61  | total loss: [1m[32m0.04401[0m[0m | time: 7.795s
[2K
| Adam | epoch: 013 | loss: 0.04401 - acc: 0.9921 -- iter: 032/132
[A[ATraining Step: 62  | total loss: [1m[32m0.04033[0m[0m | time: 15.702s
[2K
| Adam | epoch: 013 | loss: 0.04033 - acc: 0.9931 -- iter: 064/132
[A[ATraining Step: 63  | total loss: [1m[32m0.03620[0m[0m | time: 23.420s
[2K
| Adam | epoch: 013 | loss: 0.03620 - acc: 0.9940 -- iter: 096/132
[A[ATraining Step: 64  | total loss: [1m[32m0.03222[0m[0m | time: 31.212s
[2K
| Adam | epoch: 013 | loss: 0.03222 - acc: 0.9947 -- iter: 128/132
[A[ATraining Step: 65  | total loss: [1m[32m0.05758[0m[0m | time: 34.890s
[2K
| Adam | epoch: 013 | loss: 0.05758 - acc: 0.9915 | val_loss: 1.12365 - val_acc: 0.5952 -- iter: 132/132
--
Training Step: 66  | total loss: [1m[32m0.24732[0m[0m | time: 1.751s
[2K
| Adam | epoch: 014 | loss: 0.24732 - acc: 0.9317 -- iter: 032/132
[A[ATraining Step: 67  | total loss: [1m[32m0.35338[0m[0m | time: 9.603s
[2K
| Adam | epoch: 014 | loss: 0.35338 - acc: 0.8499 -- iter: 064/132
[A[ATraining Step: 68  | total loss: [1m[32m0.31207[0m[0m | time: 17.460s
[2K
| Adam | epoch: 014 | loss: 0.31207 - acc: 0.8677 -- iter: 096/132
[A[ATraining Step: 69  | total loss: [1m[32m0.27830[0m[0m | time: 25.420s
[2K
| Adam | epoch: 014 | loss: 0.27830 - acc: 0.8832 -- iter: 128/132
[A[ATraining Step: 70  | total loss: [1m[32m0.26739[0m[0m | time: 35.278s
[2K
| Adam | epoch: 014 | loss: 0.26739 - acc: 0.8930 | val_loss: 1.30237 - val_acc: 0.5476 -- iter: 132/132
--
Training Step: 71  | total loss: [1m[32m0.23882[0m[0m | time: 1.765s
[2K
| Adam | epoch: 015 | loss: 0.23882 - acc: 0.9052 -- iter: 032/132
[A[ATraining Step: 72  | total loss: [1m[32m0.22846[0m[0m | time: 3.507s
[2K
| Adam | epoch: 015 | loss: 0.22846 - acc: 0.9159 -- iter: 064/132
[A[ATraining Step: 73  | total loss: [1m[32m0.20387[0m[0m | time: 11.278s
[2K
| Adam | epoch: 015 | loss: 0.20387 - acc: 0.9252 -- iter: 096/132
[A[ATraining Step: 74  | total loss: [1m[32m0.18741[0m[0m | time: 19.045s
[2K
| Adam | epoch: 015 | loss: 0.18741 - acc: 0.9300 -- iter: 128/132
[A[ATraining Step: 75  | total loss: [1m[32m0.18884[0m[0m | time: 28.929s
[2K
| Adam | epoch: 015 | loss: 0.18884 - acc: 0.9342 | val_loss: 0.74476 - val_acc: 0.7381 -- iter: 132/132
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9107551487414187
Validation AUPRC:0.9129460988275506
Test AUC:0.9977324263038548
Test AUPRC:0.9978354978354982
BestTestF1Score	0.95	0.9	0.95	0.95	0.95	20	1	20	1	0.88
BestTestMCCScore	0.95	0.9	0.95	0.95	0.95	20	1	20	1	0.88
BestTestAccuracyScore	0.95	0.9	0.95	0.95	0.95	20	1	20	1	0.88
BestValidationF1Score	0.89	0.76	0.88	0.88	0.91	21	3	16	2	0.88
BestValidationMCC	0.89	0.76	0.88	0.88	0.91	21	3	16	2	0.88
BestValidationAccuracy	0.89	0.76	0.88	0.88	0.91	21	3	16	2	0.88
TestPredictions (Threshold:0.88)
CHEMBL42159,TP,ACT,1.0	CHEMBL412892,TN,INACT,0.1899999976158142	CHEMBL279509,TN,INACT,0.8100000023841858	CHEMBL264245,TP,ACT,1.0	CHEMBL34259,TP,ACT,1.0	CHEMBL276954,TN,INACT,0.4399999976158142	CHEMBL171937,TP,ACT,1.0	CHEMBL290806,TN,INACT,0.75	CHEMBL2051990,TP,ACT,1.0	CHEMBL48203,TN,INACT,0.03999999910593033	CHEMBL57807,TN,INACT,0.800000011920929	CHEMBL431359,TP,ACT,1.0	CHEMBL23447,TN,INACT,0.41999998688697815	CHEMBL562228,TN,INACT,0.15000000596046448	CHEMBL27149,TP,ACT,1.0	CHEMBL162270,TN,INACT,0.7799999713897705	CHEMBL23338,TN,INACT,0.3400000035762787	CHEMBL134110,TP,ACT,0.9599999785423279	CHEMBL23402,TN,INACT,0.3700000047683716	CHEMBL69681,FP,INACT,0.9599999785423279	CHEMBL278345,TN,INACT,0.17000000178813934	CHEMBL3143620,TP,ACT,0.9599999785423279	CHEMBL14201,TN,INACT,0.029999999329447746	CHEMBL306438,TP,ACT,1.0	CHEMBL69016,TP,ACT,1.0	CHEMBL594339,TN,INACT,0.4300000071525574	CHEMBL604090,TN,INACT,0.5099999904632568	CHEMBL28223,TP,ACT,1.0	CHEMBL561644,TN,INACT,0.5600000023841858	CHEMBL42301,TP,ACT,1.0	CHEMBL334198,TN,INACT,0.3199999928474426	CHEMBL60821,TN,INACT,0.3199999928474426	CHEMBL55797,FN,ACT,0.8299999833106995	CHEMBL36393,TP,ACT,1.0	CHEMBL605413,TP,ACT,0.9800000190734863	CHEMBL293263,TP,ACT,1.0	CHEMBL361101,TN,INACT,0.4300000071525574	CHEMBL6552,TN,INACT,0.3199999928474426	CHEMBL44697,TP,ACT,1.0	CHEMBL8210,TP,ACT,1.0	CHEMBL27335,TP,ACT,1.0	CHEMBL414206,TP,ACT,1.0	

