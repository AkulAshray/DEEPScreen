ImageNetInceptionV2 CHEMBL4461 adam 0.0001 30 0 0 0.6 False True
Number of active compounds :	127
Number of inactive compounds :	127
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4461_adam_0.0001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4461_adam_0.0001_30_0.6/
---------------------------------
Training samples: 148
Validation samples: 47
--
Training Step: 1  | time: 87.653s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/148
[A[ATraining Step: 2  | total loss: [1m[32m0.63646[0m[0m | time: 154.370s
[2K
| Adam | epoch: 001 | loss: 0.63646 - acc: 0.5344 -- iter: 064/148
[A[ATraining Step: 3  | total loss: [1m[32m0.77797[0m[0m | time: 196.043s
[2K
| Adam | epoch: 001 | loss: 0.77797 - acc: 0.5063 -- iter: 096/148
[A[ATraining Step: 4  | total loss: [1m[32m0.57389[0m[0m | time: 217.539s
[2K
| Adam | epoch: 001 | loss: 0.57389 - acc: 0.6891 -- iter: 128/148
[A[ATraining Step: 5  | total loss: [1m[32m0.59779[0m[0m | time: 231.984s
[2K
| Adam | epoch: 001 | loss: 0.59779 - acc: 0.7096 | val_loss: 0.69144 - val_acc: 0.5319 -- iter: 148/148
--
Training Step: 6  | total loss: [1m[32m0.47036[0m[0m | time: 6.234s
[2K
| Adam | epoch: 002 | loss: 0.47036 - acc: 0.7999 -- iter: 032/148
[A[ATraining Step: 7  | total loss: [1m[32m0.32704[0m[0m | time: 20.584s
[2K
| Adam | epoch: 002 | loss: 0.32704 - acc: 0.8899 -- iter: 064/148
[A[ATraining Step: 8  | total loss: [1m[32m0.50327[0m[0m | time: 89.654s
[2K
| Adam | epoch: 002 | loss: 0.50327 - acc: 0.7409 -- iter: 096/148
[A[ATraining Step: 9  | total loss: [1m[32m0.48957[0m[0m | time: 136.852s
[2K
| Adam | epoch: 002 | loss: 0.48957 - acc: 0.7788 -- iter: 128/148
[A[ATraining Step: 10  | total loss: [1m[32m0.44802[0m[0m | time: 241.816s
[2K
| Adam | epoch: 002 | loss: 0.44802 - acc: 0.7488 | val_loss: 0.74571 - val_acc: 0.4681 -- iter: 148/148
--
Training Step: 11  | total loss: [1m[32m0.37997[0m[0m | time: 8.842s
[2K
| Adam | epoch: 003 | loss: 0.37997 - acc: 0.8086 -- iter: 032/148
[A[ATraining Step: 12  | total loss: [1m[32m0.30316[0m[0m | time: 15.104s
[2K
| Adam | epoch: 003 | loss: 0.30316 - acc: 0.8947 -- iter: 064/148
[A[ATraining Step: 13  | total loss: [1m[32m0.23972[0m[0m | time: 102.236s
[2K
| Adam | epoch: 003 | loss: 0.23972 - acc: 0.9398 -- iter: 096/148
[A[ATraining Step: 14  | total loss: [1m[32m0.25218[0m[0m | time: 134.026s
[2K
| Adam | epoch: 003 | loss: 0.25218 - acc: 0.9517 -- iter: 128/148
[A[ATraining Step: 15  | total loss: [1m[32m0.23180[0m[0m | time: 261.806s
[2K
| Adam | epoch: 003 | loss: 0.23180 - acc: 0.9461 | val_loss: 0.81690 - val_acc: 0.5319 -- iter: 148/148
--
Training Step: 16  | total loss: [1m[32m0.24059[0m[0m | time: 48.195s
[2K
| Adam | epoch: 004 | loss: 0.24059 - acc: 0.9546 -- iter: 032/148
[A[ATraining Step: 17  | total loss: [1m[32m0.25246[0m[0m | time: 95.627s
[2K
| Adam | epoch: 004 | loss: 0.25246 - acc: 0.9484 -- iter: 064/148
[A[ATraining Step: 18  | total loss: [1m[32m0.18896[0m[0m | time: 148.834s
[2K
| Adam | epoch: 004 | loss: 0.18896 - acc: 0.9663 -- iter: 096/148
[A[ATraining Step: 19  | total loss: [1m[32m0.14718[0m[0m | time: 193.959s
[2K
| Adam | epoch: 004 | loss: 0.14718 - acc: 0.9775 -- iter: 128/148
[A[ATraining Step: 20  | total loss: [1m[32m0.11755[0m[0m | time: 255.057s
[2K
| Adam | epoch: 004 | loss: 0.11755 - acc: 0.9848 | val_loss: 1.31825 - val_acc: 0.5319 -- iter: 148/148
--
Training Step: 21  | total loss: [1m[32m0.11920[0m[0m | time: 59.872s
[2K
| Adam | epoch: 005 | loss: 0.11920 - acc: 0.9798 -- iter: 032/148
[A[ATraining Step: 22  | total loss: [1m[32m0.10336[0m[0m | time: 106.339s
[2K
| Adam | epoch: 005 | loss: 0.10336 - acc: 0.9765 -- iter: 064/148
[A[ATraining Step: 23  | total loss: [1m[32m0.13413[0m[0m | time: 163.376s
[2K
| Adam | epoch: 005 | loss: 0.13413 - acc: 0.9652 -- iter: 096/148
[A[ATraining Step: 24  | total loss: [1m[32m0.10413[0m[0m | time: 185.732s
[2K
| Adam | epoch: 005 | loss: 0.10413 - acc: 0.9750 -- iter: 128/148
[A[ATraining Step: 25  | total loss: [1m[32m0.08187[0m[0m | time: 215.741s
[2K
| Adam | epoch: 005 | loss: 0.08187 - acc: 0.9818 | val_loss: 1.22252 - val_acc: 0.5319 -- iter: 148/148
--
Training Step: 26  | total loss: [1m[32m0.06376[0m[0m | time: 78.236s
[2K
| Adam | epoch: 006 | loss: 0.06376 - acc: 0.9866 -- iter: 032/148
[A[ATraining Step: 27  | total loss: [1m[32m0.05556[0m[0m | time: 124.457s
[2K
| Adam | epoch: 006 | loss: 0.05556 - acc: 0.9901 -- iter: 064/148
[A[ATraining Step: 28  | total loss: [1m[32m0.04641[0m[0m | time: 230.432s
[2K
| Adam | epoch: 006 | loss: 0.04641 - acc: 0.9925 -- iter: 096/148
[A[ATraining Step: 29  | total loss: [1m[32m0.07414[0m[0m | time: 344.420s
[2K
| Adam | epoch: 006 | loss: 0.07414 - acc: 0.9868 -- iter: 128/148
[A[ATraining Step: 30  | total loss: [1m[32m0.07786[0m[0m | time: 390.249s
[2K
| Adam | epoch: 006 | loss: 0.07786 - acc: 0.9780 | val_loss: 0.97319 - val_acc: 0.5319 -- iter: 148/148
--
Training Step: 31  | total loss: [1m[32m0.07244[0m[0m | time: 98.319s
[2K
| Adam | epoch: 007 | loss: 0.07244 - acc: 0.9831 -- iter: 032/148
[A[ATraining Step: 32  | total loss: [1m[32m0.08782[0m[0m | time: 191.525s
[2K
| Adam | epoch: 007 | loss: 0.08782 - acc: 0.9658 -- iter: 064/148
[A[ATraining Step: 33  | total loss: [1m[32m0.08033[0m[0m | time: 283.824s
[2K
| Adam | epoch: 007 | loss: 0.08033 - acc: 0.9665 -- iter: 096/148
[A[ATraining Step: 34  | total loss: [1m[32m0.08442[0m[0m | time: 327.470s
[2K
| Adam | epoch: 007 | loss: 0.08442 - acc: 0.9603 -- iter: 128/148
[A[ATraining Step: 35  | total loss: [1m[32m0.07064[0m[0m | time: 413.005s
[2K
| Adam | epoch: 007 | loss: 0.07064 - acc: 0.9686 | val_loss: 0.95781 - val_acc: 0.4894 -- iter: 148/148
--
Training Step: 36  | total loss: [1m[32m0.06793[0m[0m | time: 45.476s
[2K
| Adam | epoch: 008 | loss: 0.06793 - acc: 0.9648 -- iter: 032/148
[A[ATraining Step: 37  | total loss: [1m[32m0.05603[0m[0m | time: 105.533s
[2K
| Adam | epoch: 008 | loss: 0.05603 - acc: 0.9718 -- iter: 064/148
[A[ATraining Step: 38  | total loss: [1m[32m0.04642[0m[0m | time: 159.466s
[2K
| Adam | epoch: 008 | loss: 0.04642 - acc: 0.9773 -- iter: 096/148
[A[ATraining Step: 39  | total loss: [1m[32m0.06374[0m[0m | time: 207.388s
[2K
| Adam | epoch: 008 | loss: 0.06374 - acc: 0.9757 -- iter: 128/148
[A[ATraining Step: 40  | total loss: [1m[32m0.09658[0m[0m | time: 262.030s
[2K
| Adam | epoch: 008 | loss: 0.09658 - acc: 0.9744 | val_loss: 1.45869 - val_acc: 0.4681 -- iter: 148/148
--
Training Step: 41  | total loss: [1m[32m0.08071[0m[0m | time: 22.622s
[2K
| Adam | epoch: 009 | loss: 0.08071 - acc: 0.9791 -- iter: 032/148
[A[ATraining Step: 42  | total loss: [1m[32m0.14437[0m[0m | time: 57.792s
[2K
| Adam | epoch: 009 | loss: 0.14437 - acc: 0.9649 -- iter: 064/148
[A[ATraining Step: 43  | total loss: [1m[32m0.16728[0m[0m | time: 113.689s
[2K
| Adam | epoch: 009 | loss: 0.16728 - acc: 0.9534 -- iter: 096/148
[A[ATraining Step: 44  | total loss: [1m[32m0.14547[0m[0m | time: 139.680s
[2K
| Adam | epoch: 009 | loss: 0.14547 - acc: 0.9615 -- iter: 128/148
[A[ATraining Step: 45  | total loss: [1m[32m0.12437[0m[0m | time: 162.178s
[2K
| Adam | epoch: 009 | loss: 0.12437 - acc: 0.9680 | val_loss: 1.78541 - val_acc: 0.4894 -- iter: 148/148
--
Training Step: 46  | total loss: [1m[32m0.14903[0m[0m | time: 47.696s
[2K
| Adam | epoch: 010 | loss: 0.14903 - acc: 0.9681 -- iter: 032/148
[A[ATraining Step: 47  | total loss: [1m[32m0.12937[0m[0m | time: 60.709s
[2K
| Adam | epoch: 010 | loss: 0.12937 - acc: 0.9734 -- iter: 064/148
[A[ATraining Step: 48  | total loss: [1m[32m0.11032[0m[0m | time: 88.451s
[2K
| Adam | epoch: 010 | loss: 0.11032 - acc: 0.9776 -- iter: 096/148
[A[ATraining Step: 49  | total loss: [1m[32m0.09469[0m[0m | time: 118.969s
[2K
| Adam | epoch: 010 | loss: 0.09469 - acc: 0.9812 -- iter: 128/148
[A[ATraining Step: 50  | total loss: [1m[32m0.08207[0m[0m | time: 180.578s
[2K
| Adam | epoch: 010 | loss: 0.08207 - acc: 0.9841 | val_loss: 1.78895 - val_acc: 0.4894 -- iter: 148/148
--
Training Step: 51  | total loss: [1m[32m0.10068[0m[0m | time: 75.475s
[2K
| Adam | epoch: 011 | loss: 0.10068 - acc: 0.9770 -- iter: 032/148
[A[ATraining Step: 52  | total loss: [1m[32m0.08884[0m[0m | time: 110.668s
[2K
| Adam | epoch: 011 | loss: 0.08884 - acc: 0.9804 -- iter: 064/148
[A[ATraining Step: 53  | total loss: [1m[32m0.08187[0m[0m | time: 176.003s
[2K
| Adam | epoch: 011 | loss: 0.08187 - acc: 0.9787 -- iter: 096/148
[A[ATraining Step: 54  | total loss: [1m[32m0.08376[0m[0m | time: 196.520s
[2K
| Adam | epoch: 011 | loss: 0.08376 - acc: 0.9745 -- iter: 128/148
[A[ATraining Step: 55  | total loss: [1m[32m0.07629[0m[0m | time: 263.445s
[2K
| Adam | epoch: 011 | loss: 0.07629 - acc: 0.9782 | val_loss: 0.88043 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 56  | total loss: [1m[32m0.07397[0m[0m | time: 34.369s
[2K
| Adam | epoch: 012 | loss: 0.07397 - acc: 0.9769 -- iter: 032/148
[A[ATraining Step: 57  | total loss: [1m[32m0.06576[0m[0m | time: 91.062s
[2K
| Adam | epoch: 012 | loss: 0.06576 - acc: 0.9801 -- iter: 064/148
[A[ATraining Step: 58  | total loss: [1m[32m0.05777[0m[0m | time: 134.549s
[2K
| Adam | epoch: 012 | loss: 0.05777 - acc: 0.9828 -- iter: 096/148
[A[ATraining Step: 59  | total loss: [1m[32m0.05156[0m[0m | time: 148.068s
[2K
| Adam | epoch: 012 | loss: 0.05156 - acc: 0.9851 -- iter: 128/148
[A[ATraining Step: 60  | total loss: [1m[32m0.06335[0m[0m | time: 165.618s
[2K
| Adam | epoch: 012 | loss: 0.06335 - acc: 0.9804 | val_loss: 0.54887 - val_acc: 0.7872 -- iter: 148/148
--
Training Step: 61  | total loss: [1m[32m0.05991[0m[0m | time: 15.264s
[2K
| Adam | epoch: 013 | loss: 0.05991 - acc: 0.9830 -- iter: 032/148
[A[ATraining Step: 62  | total loss: [1m[32m0.05638[0m[0m | time: 28.656s
[2K
| Adam | epoch: 013 | loss: 0.05638 - acc: 0.9852 -- iter: 064/148
[A[ATraining Step: 63  | total loss: [1m[32m0.05025[0m[0m | time: 45.404s
[2K
| Adam | epoch: 013 | loss: 0.05025 - acc: 0.9871 -- iter: 096/148
[A[ATraining Step: 64  | total loss: [1m[32m0.05060[0m[0m | time: 63.221s
[2K
| Adam | epoch: 013 | loss: 0.05060 - acc: 0.9848 -- iter: 128/148
[A[ATraining Step: 65  | total loss: [1m[32m0.06561[0m[0m | time: 84.324s
[2K
| Adam | epoch: 013 | loss: 0.06561 - acc: 0.9828 | val_loss: 0.79371 - val_acc: 0.7447 -- iter: 148/148
--
Training Step: 66  | total loss: [1m[32m0.05927[0m[0m | time: 22.756s
[2K
| Adam | epoch: 014 | loss: 0.05927 - acc: 0.9849 -- iter: 032/148
[A[ATraining Step: 67  | total loss: [1m[32m0.05340[0m[0m | time: 53.929s
[2K
| Adam | epoch: 014 | loss: 0.05340 - acc: 0.9867 -- iter: 064/148
[A[ATraining Step: 68  | total loss: [1m[32m0.05229[0m[0m | time: 72.177s
[2K
| Adam | epoch: 014 | loss: 0.05229 - acc: 0.9883 -- iter: 096/148
[A[ATraining Step: 69  | total loss: [1m[32m0.04703[0m[0m | time: 113.554s
[2K
| Adam | epoch: 014 | loss: 0.04703 - acc: 0.9896 -- iter: 128/148
[A[ATraining Step: 70  | total loss: [1m[32m0.04388[0m[0m | time: 146.843s
[2K
| Adam | epoch: 014 | loss: 0.04388 - acc: 0.9908 | val_loss: 0.86455 - val_acc: 0.6596 -- iter: 148/148
--
Training Step: 71  | total loss: [1m[32m0.04405[0m[0m | time: 11.946s
[2K
| Adam | epoch: 015 | loss: 0.04405 - acc: 0.9883 -- iter: 032/148
[A[ATraining Step: 72  | total loss: [1m[32m0.03999[0m[0m | time: 24.272s
[2K
| Adam | epoch: 015 | loss: 0.03999 - acc: 0.9896 -- iter: 064/148
[A[ATraining Step: 73  | total loss: [1m[32m0.03618[0m[0m | time: 45.959s
[2K
| Adam | epoch: 015 | loss: 0.03618 - acc: 0.9908 -- iter: 096/148
[A[ATraining Step: 74  | total loss: [1m[32m0.03337[0m[0m | time: 63.431s
[2K
| Adam | epoch: 015 | loss: 0.03337 - acc: 0.9918 -- iter: 128/148
[A[ATraining Step: 75  | total loss: [1m[32m0.03024[0m[0m | time: 94.765s
[2K
| Adam | epoch: 015 | loss: 0.03024 - acc: 0.9927 | val_loss: 2.18217 - val_acc: 0.5319 -- iter: 148/148
--
Training Step: 76  | total loss: [1m[32m0.10187[0m[0m | time: 13.145s
[2K
| Adam | epoch: 016 | loss: 0.10187 - acc: 0.9801 -- iter: 032/148
[A[ATraining Step: 77  | total loss: [1m[32m0.09164[0m[0m | time: 21.593s
[2K
| Adam | epoch: 016 | loss: 0.09164 - acc: 0.9822 -- iter: 064/148
[A[ATraining Step: 78  | total loss: [1m[32m0.08257[0m[0m | time: 30.815s
[2K
| Adam | epoch: 016 | loss: 0.08257 - acc: 0.9841 -- iter: 096/148
[A[ATraining Step: 79  | total loss: [1m[32m0.07479[0m[0m | time: 48.888s
[2K
| Adam | epoch: 016 | loss: 0.07479 - acc: 0.9857 -- iter: 128/148
[A[ATraining Step: 80  | total loss: [1m[32m0.07917[0m[0m | time: 71.867s
[2K
| Adam | epoch: 016 | loss: 0.07917 - acc: 0.9776 | val_loss: 1.50069 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 81  | total loss: [1m[32m0.07292[0m[0m | time: 17.452s
[2K
| Adam | epoch: 017 | loss: 0.07292 - acc: 0.9798 -- iter: 032/148
[A[ATraining Step: 82  | total loss: [1m[32m0.09081[0m[0m | time: 35.461s
[2K
| Adam | epoch: 017 | loss: 0.09081 - acc: 0.9787 -- iter: 064/148
[A[ATraining Step: 83  | total loss: [1m[32m0.08310[0m[0m | time: 54.252s
[2K
| Adam | epoch: 017 | loss: 0.08310 - acc: 0.9809 -- iter: 096/148
[A[ATraining Step: 84  | total loss: [1m[32m0.07695[0m[0m | time: 67.549s
[2K
| Adam | epoch: 017 | loss: 0.07695 - acc: 0.9828 -- iter: 128/148
[A[ATraining Step: 85  | total loss: [1m[32m0.07311[0m[0m | time: 91.152s
[2K
| Adam | epoch: 017 | loss: 0.07311 - acc: 0.9845 | val_loss: 0.87716 - val_acc: 0.7447 -- iter: 148/148
--
Training Step: 86  | total loss: [1m[32m0.06817[0m[0m | time: 17.920s
[2K
| Adam | epoch: 018 | loss: 0.06817 - acc: 0.9860 -- iter: 032/148
[A[ATraining Step: 87  | total loss: [1m[32m0.06330[0m[0m | time: 35.776s
[2K
| Adam | epoch: 018 | loss: 0.06330 - acc: 0.9874 -- iter: 064/148
[A[ATraining Step: 88  | total loss: [1m[32m0.09507[0m[0m | time: 54.049s
[2K
| Adam | epoch: 018 | loss: 0.09507 - acc: 0.9824 -- iter: 096/148
[A[ATraining Step: 89  | total loss: [1m[32m0.08775[0m[0m | time: 65.715s
[2K
| Adam | epoch: 018 | loss: 0.08775 - acc: 0.9842 -- iter: 128/148
[A[ATraining Step: 90  | total loss: [1m[32m0.07959[0m[0m | time: 82.950s
[2K
| Adam | epoch: 018 | loss: 0.07959 - acc: 0.9858 | val_loss: 0.96500 - val_acc: 0.7234 -- iter: 148/148
--
Training Step: 91  | total loss: [1m[32m0.07222[0m[0m | time: 13.103s
[2K
| Adam | epoch: 019 | loss: 0.07222 - acc: 0.9872 -- iter: 032/148
[A[ATraining Step: 92  | total loss: [1m[32m0.07034[0m[0m | time: 26.354s
[2K
| Adam | epoch: 019 | loss: 0.07034 - acc: 0.9854 -- iter: 064/148
[A[ATraining Step: 93  | total loss: [1m[32m0.06701[0m[0m | time: 41.074s
[2K
| Adam | epoch: 019 | loss: 0.06701 - acc: 0.9837 -- iter: 096/148
[A[ATraining Step: 94  | total loss: [1m[32m0.06187[0m[0m | time: 58.708s
[2K
| Adam | epoch: 019 | loss: 0.06187 - acc: 0.9853 -- iter: 128/148
[A[ATraining Step: 95  | total loss: [1m[32m0.05666[0m[0m | time: 75.404s
[2K
| Adam | epoch: 019 | loss: 0.05666 - acc: 0.9868 | val_loss: 0.70631 - val_acc: 0.7872 -- iter: 148/148
--
Training Step: 96  | total loss: [1m[32m0.05141[0m[0m | time: 12.574s
[2K
| Adam | epoch: 020 | loss: 0.05141 - acc: 0.9881 -- iter: 032/148
[A[ATraining Step: 97  | total loss: [1m[32m0.04675[0m[0m | time: 29.934s
[2K
| Adam | epoch: 020 | loss: 0.04675 - acc: 0.9893 -- iter: 064/148
[A[ATraining Step: 98  | total loss: [1m[32m0.04324[0m[0m | time: 47.484s
[2K
| Adam | epoch: 020 | loss: 0.04324 - acc: 0.9904 -- iter: 096/148
[A[ATraining Step: 99  | total loss: [1m[32m0.05827[0m[0m | time: 64.780s
[2K
| Adam | epoch: 020 | loss: 0.05827 - acc: 0.9882 -- iter: 128/148
[A[ATraining Step: 100  | total loss: [1m[32m0.08760[0m[0m | time: 86.834s
[2K
| Adam | epoch: 020 | loss: 0.08760 - acc: 0.9831 | val_loss: 1.00619 - val_acc: 0.7447 -- iter: 148/148
--
Training Step: 101  | total loss: [1m[32m0.08130[0m[0m | time: 11.988s
[2K
| Adam | epoch: 021 | loss: 0.08130 - acc: 0.9848 -- iter: 032/148
[A[ATraining Step: 102  | total loss: [1m[32m0.07497[0m[0m | time: 23.809s
[2K
| Adam | epoch: 021 | loss: 0.07497 - acc: 0.9863 -- iter: 064/148
[A[ATraining Step: 103  | total loss: [1m[32m0.06894[0m[0m | time: 42.249s
[2K
| Adam | epoch: 021 | loss: 0.06894 - acc: 0.9877 -- iter: 096/148
[A[ATraining Step: 104  | total loss: [1m[32m0.06537[0m[0m | time: 59.965s
[2K
| Adam | epoch: 021 | loss: 0.06537 - acc: 0.9889 -- iter: 128/148
[A[ATraining Step: 105  | total loss: [1m[32m0.06635[0m[0m | time: 82.894s
[2K
| Adam | epoch: 021 | loss: 0.06635 - acc: 0.9869 | val_loss: 2.45482 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 106  | total loss: [1m[32m0.07808[0m[0m | time: 19.308s
[2K
| Adam | epoch: 022 | loss: 0.07808 - acc: 0.9851 -- iter: 032/148
[A[ATraining Step: 107  | total loss: [1m[32m0.08404[0m[0m | time: 32.415s
[2K
| Adam | epoch: 022 | loss: 0.08404 - acc: 0.9835 -- iter: 064/148
[A[ATraining Step: 108  | total loss: [1m[32m0.07653[0m[0m | time: 40.843s
[2K
| Adam | epoch: 022 | loss: 0.07653 - acc: 0.9851 -- iter: 096/148
[A[ATraining Step: 109  | total loss: [1m[32m0.06988[0m[0m | time: 53.917s
[2K
| Adam | epoch: 022 | loss: 0.06988 - acc: 0.9866 -- iter: 128/148
[A[ATraining Step: 110  | total loss: [1m[32m0.06476[0m[0m | time: 69.981s
[2K
| Adam | epoch: 022 | loss: 0.06476 - acc: 0.9879 | val_loss: 1.72004 - val_acc: 0.6383 -- iter: 148/148
--
Training Step: 111  | total loss: [1m[32m0.06636[0m[0m | time: 12.868s
[2K
| Adam | epoch: 023 | loss: 0.06636 - acc: 0.9860 -- iter: 032/148
[A[ATraining Step: 112  | total loss: [1m[32m0.34866[0m[0m | time: 25.960s
[2K
| Adam | epoch: 023 | loss: 0.34866 - acc: 0.9343 -- iter: 064/148
[A[ATraining Step: 113  | total loss: [1m[32m0.31720[0m[0m | time: 34.807s
[2K
| Adam | epoch: 023 | loss: 0.31720 - acc: 0.9409 -- iter: 096/148
[A[ATraining Step: 114  | total loss: [1m[32m0.28734[0m[0m | time: 43.521s
[2K
| Adam | epoch: 023 | loss: 0.28734 - acc: 0.9468 -- iter: 128/148
[A[ATraining Step: 115  | total loss: [1m[32m0.26088[0m[0m | time: 59.250s
[2K
| Adam | epoch: 023 | loss: 0.26088 - acc: 0.9521 | val_loss: 0.55584 - val_acc: 0.7660 -- iter: 148/148
--
Training Step: 116  | total loss: [1m[32m0.23974[0m[0m | time: 12.637s
[2K
| Adam | epoch: 024 | loss: 0.23974 - acc: 0.9569 -- iter: 032/148
[A[ATraining Step: 117  | total loss: [1m[32m0.22169[0m[0m | time: 25.007s
[2K
| Adam | epoch: 024 | loss: 0.22169 - acc: 0.9612 -- iter: 064/148
[A[ATraining Step: 118  | total loss: [1m[32m0.20539[0m[0m | time: 37.453s
[2K
| Adam | epoch: 024 | loss: 0.20539 - acc: 0.9651 -- iter: 096/148
[A[ATraining Step: 119  | total loss: [1m[32m0.18743[0m[0m | time: 45.948s
[2K
| Adam | epoch: 024 | loss: 0.18743 - acc: 0.9686 -- iter: 128/148
[A[ATraining Step: 120  | total loss: [1m[32m0.17074[0m[0m | time: 57.976s
[2K
| Adam | epoch: 024 | loss: 0.17074 - acc: 0.9717 | val_loss: 0.54982 - val_acc: 0.8085 -- iter: 148/148
--
Training Step: 121  | total loss: [1m[32m0.15535[0m[0m | time: 11.035s
[2K
| Adam | epoch: 025 | loss: 0.15535 - acc: 0.9745 -- iter: 032/148
[A[ATraining Step: 122  | total loss: [1m[32m0.14130[0m[0m | time: 24.934s
[2K
| Adam | epoch: 025 | loss: 0.14130 - acc: 0.9771 -- iter: 064/148
[A[ATraining Step: 123  | total loss: [1m[32m0.12839[0m[0m | time: 38.898s
[2K
| Adam | epoch: 025 | loss: 0.12839 - acc: 0.9794 -- iter: 096/148
[A[ATraining Step: 124  | total loss: [1m[32m0.11692[0m[0m | time: 52.630s
[2K
| Adam | epoch: 025 | loss: 0.11692 - acc: 0.9814 -- iter: 128/148
[A[ATraining Step: 125  | total loss: [1m[32m0.10637[0m[0m | time: 65.890s
[2K
| Adam | epoch: 025 | loss: 0.10637 - acc: 0.9833 | val_loss: 0.61026 - val_acc: 0.8085 -- iter: 148/148
--
Training Step: 126  | total loss: [1m[32m0.09707[0m[0m | time: 7.094s
[2K
| Adam | epoch: 026 | loss: 0.09707 - acc: 0.9850 -- iter: 032/148
[A[ATraining Step: 127  | total loss: [1m[32m0.08842[0m[0m | time: 15.755s
[2K
| Adam | epoch: 026 | loss: 0.08842 - acc: 0.9865 -- iter: 064/148
[A[ATraining Step: 128  | total loss: [1m[32m0.08054[0m[0m | time: 24.395s
[2K
| Adam | epoch: 026 | loss: 0.08054 - acc: 0.9878 -- iter: 096/148
[A[ATraining Step: 129  | total loss: [1m[32m0.07329[0m[0m | time: 32.971s
[2K
| Adam | epoch: 026 | loss: 0.07329 - acc: 0.9890 -- iter: 128/148
[A[ATraining Step: 130  | total loss: [1m[32m0.30043[0m[0m | time: 46.100s
[2K
| Adam | epoch: 026 | loss: 0.30043 - acc: 0.9526 | val_loss: 0.60378 - val_acc: 0.8298 -- iter: 148/148
--
Training Step: 131  | total loss: [1m[32m0.27172[0m[0m | time: 9.246s
[2K
| Adam | epoch: 027 | loss: 0.27172 - acc: 0.9574 -- iter: 032/148
[A[ATraining Step: 132  | total loss: [1m[32m0.24564[0m[0m | time: 18.430s
[2K
| Adam | epoch: 027 | loss: 0.24564 - acc: 0.9616 -- iter: 064/148
[A[ATraining Step: 133  | total loss: [1m[32m0.22231[0m[0m | time: 30.679s
[2K
| Adam | epoch: 027 | loss: 0.22231 - acc: 0.9655 -- iter: 096/148
[A[ATraining Step: 134  | total loss: [1m[32m0.20070[0m[0m | time: 43.215s
[2K
| Adam | epoch: 027 | loss: 0.20070 - acc: 0.9689 -- iter: 128/148
[A[ATraining Step: 135  | total loss: [1m[32m0.18189[0m[0m | time: 59.390s
[2K
| Adam | epoch: 027 | loss: 0.18189 - acc: 0.9720 | val_loss: 0.69087 - val_acc: 0.7872 -- iter: 148/148
--
Training Step: 136  | total loss: [1m[32m0.18487[0m[0m | time: 13.258s
[2K
| Adam | epoch: 028 | loss: 0.18487 - acc: 0.9717 -- iter: 032/148
[A[ATraining Step: 137  | total loss: [1m[32m0.16926[0m[0m | time: 21.762s
[2K
| Adam | epoch: 028 | loss: 0.16926 - acc: 0.9745 -- iter: 064/148
[A[ATraining Step: 138  | total loss: [1m[32m0.15408[0m[0m | time: 30.392s
[2K
| Adam | epoch: 028 | loss: 0.15408 - acc: 0.9771 -- iter: 096/148
[A[ATraining Step: 139  | total loss: [1m[32m0.14076[0m[0m | time: 42.426s
[2K
| Adam | epoch: 028 | loss: 0.14076 - acc: 0.9794 -- iter: 128/148
[A[ATraining Step: 140  | total loss: [1m[32m0.13170[0m[0m | time: 58.789s
[2K
| Adam | epoch: 028 | loss: 0.13170 - acc: 0.9783 | val_loss: 0.60243 - val_acc: 0.8085 -- iter: 148/148
--
Training Step: 141  | total loss: [1m[32m0.12154[0m[0m | time: 12.915s
[2K
| Adam | epoch: 029 | loss: 0.12154 - acc: 0.9805 -- iter: 032/148
[A[ATraining Step: 142  | total loss: [1m[32m0.12611[0m[0m | time: 25.725s
[2K
| Adam | epoch: 029 | loss: 0.12611 - acc: 0.9793 -- iter: 064/148
[A[ATraining Step: 143  | total loss: [1m[32m0.11442[0m[0m | time: 34.736s
[2K
| Adam | epoch: 029 | loss: 0.11442 - acc: 0.9814 -- iter: 096/148
[A[ATraining Step: 144  | total loss: [1m[32m0.10605[0m[0m | time: 43.003s
[2K
| Adam | epoch: 029 | loss: 0.10605 - acc: 0.9832 -- iter: 128/148
[A[ATraining Step: 145  | total loss: [1m[32m0.09687[0m[0m | time: 59.827s
[2K
| Adam | epoch: 029 | loss: 0.09687 - acc: 0.9849 | val_loss: 0.57150 - val_acc: 0.8511 -- iter: 148/148
--
Training Step: 146  | total loss: [1m[32m0.08840[0m[0m | time: 13.093s
[2K
| Adam | epoch: 030 | loss: 0.08840 - acc: 0.9864 -- iter: 032/148
[A[ATraining Step: 147  | total loss: [1m[32m0.08030[0m[0m | time: 25.576s
[2K
| Adam | epoch: 030 | loss: 0.08030 - acc: 0.9878 -- iter: 064/148
[A[ATraining Step: 148  | total loss: [1m[32m0.07767[0m[0m | time: 38.734s
[2K
| Adam | epoch: 030 | loss: 0.07767 - acc: 0.9859 -- iter: 096/148
[A[ATraining Step: 149  | total loss: [1m[32m0.07070[0m[0m | time: 47.074s
[2K
| Adam | epoch: 030 | loss: 0.07070 - acc: 0.9873 -- iter: 128/148
[A[ATraining Step: 150  | total loss: [1m[32m0.06641[0m[0m | time: 59.131s
[2K
| Adam | epoch: 030 | loss: 0.06641 - acc: 0.9886 | val_loss: 0.72953 - val_acc: 0.7872 -- iter: 148/148
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8672727272727274
Validation AUPRC:0.8492202223620067
Test AUC:0.88
Test AUPRC:0.8965917572394354
BestTestF1Score	0.82	0.59	0.79	0.74	0.92	23	8	14	2	0.07
BestTestMCCScore	0.82	0.59	0.79	0.74	0.92	23	8	14	2	0.07
BestTestAccuracyScore	0.82	0.59	0.79	0.74	0.92	23	8	14	2	0.07
BestValidationF1Score	0.84	0.7	0.85	0.83	0.86	19	4	21	3	0.07
BestValidationMCC	0.84	0.7	0.85	0.83	0.86	19	4	21	3	0.07
BestValidationAccuracy	0.84	0.7	0.85	0.83	0.86	19	4	21	3	0.07
TestPredictions (Threshold:0.07)
CHEMBL3805641,TP,ACT,0.9300000071525574	CHEMBL1945264,TN,INACT,0.009999999776482582	CHEMBL3609651,TP,ACT,0.8299999833106995	CHEMBL430574,TN,INACT,0.0	CHEMBL3804908,TP,ACT,0.25	CHEMBL2417685,FP,INACT,0.38999998569488525	CHEMBL3804850,TP,ACT,0.5699999928474426	CHEMBL3609653,TP,ACT,0.8299999833106995	CHEMBL3105181,TN,INACT,0.009999999776482582	CHEMBL3805331,TP,ACT,0.949999988079071	CHEMBL3735899,TN,INACT,0.009999999776482582	CHEMBL2181509,TN,INACT,0.0	CHEMBL3805306,TP,ACT,0.949999988079071	CHEMBL3609648,TP,ACT,0.9700000286102295	CHEMBL34712,TN,INACT,0.0	CHEMBL1945266,TN,INACT,0.0	CHEMBL3805778,TP,ACT,0.8700000047683716	CHEMBL2152611,TN,INACT,0.0	CHEMBL3343532,FN,ACT,0.009999999776482582	CHEMBL1794051,TN,INACT,0.0	CHEMBL3781485,TP,ACT,0.949999988079071	CHEMBL493160,FP,INACT,0.8399999737739563	CHEMBL3806268,TP,ACT,0.949999988079071	CHEMBL2332043,TP,ACT,0.1599999964237213	CHEMBL3805574,TP,ACT,0.9800000190734863	CHEMBL3805070,TP,ACT,0.9800000190734863	CHEMBL2152576,TN,INACT,0.0	CHEMBL3805072,TP,ACT,0.75	CHEMBL3805547,TP,ACT,0.9399999976158142	CHEMBL2203546,TN,INACT,0.0	CHEMBL2338816,TP,ACT,0.8299999833106995	CHEMBL2332040,TP,ACT,0.8500000238418579	CHEMBL1775011,FP,INACT,0.07999999821186066	CHEMBL2171199,TN,INACT,0.009999999776482582	CHEMBL245011,FP,INACT,0.07999999821186066	CHEMBL83278,FP,INACT,0.46000000834465027	CHEMBL3804901,FP,INACT,0.09000000357627869	CHEMBL3806211,TP,ACT,0.9599999785423279	CHEMBL1945670,TN,INACT,0.0	CHEMBL2332044,TP,ACT,0.20000000298023224	CHEMBL3806002,TP,ACT,0.10999999940395355	CHEMBL549853,TN,INACT,0.009999999776482582	CHEMBL3233733,FN,ACT,0.0	CHEMBL3343531,FP,INACT,0.949999988079071	CHEMBL3804859,TP,ACT,0.9399999976158142	CHEMBL1835303,FP,INACT,0.1599999964237213	CHEMBL2332052,TP,ACT,0.9700000286102295	

