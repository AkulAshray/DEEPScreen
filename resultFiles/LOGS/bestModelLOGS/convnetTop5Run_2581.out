CNNModel CHEMBL4685 adam 0.001 30 256 0 0.6 False True
Number of active compounds :	243
Number of inactive compounds :	162
---------------------------------
Run id: CNNModel_CHEMBL4685_adam_0.001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4685_adam_0.001_30_256_0.6_True/
---------------------------------
Training samples: 250
Validation samples: 79
--
Training Step: 1  | time: 1.293s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/250
[A[ATraining Step: 2  | total loss: [1m[32m0.62359[0m[0m | time: 2.478s
[2K
| Adam | epoch: 001 | loss: 0.62359 - acc: 0.5625 -- iter: 064/250
[A[ATraining Step: 3  | total loss: [1m[32m0.67048[0m[0m | time: 3.424s
[2K
| Adam | epoch: 001 | loss: 0.67048 - acc: 0.6903 -- iter: 096/250
[A[ATraining Step: 4  | total loss: [1m[32m0.70011[0m[0m | time: 4.409s
[2K
| Adam | epoch: 001 | loss: 0.70011 - acc: 0.5241 -- iter: 128/250
[A[ATraining Step: 5  | total loss: [1m[32m0.67944[0m[0m | time: 5.475s
[2K
| Adam | epoch: 001 | loss: 0.67944 - acc: 0.6156 -- iter: 160/250
[A[ATraining Step: 6  | total loss: [1m[32m0.67233[0m[0m | time: 6.645s
[2K
| Adam | epoch: 001 | loss: 0.67233 - acc: 0.6216 -- iter: 192/250
[A[ATraining Step: 7  | total loss: [1m[32m0.66018[0m[0m | time: 7.677s
[2K
| Adam | epoch: 001 | loss: 0.66018 - acc: 0.6424 -- iter: 224/250
[A[ATraining Step: 8  | total loss: [1m[32m0.71702[0m[0m | time: 9.536s
[2K
| Adam | epoch: 001 | loss: 0.71702 - acc: 0.5623 | val_loss: 0.68944 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 9  | total loss: [1m[32m0.67954[0m[0m | time: 0.774s
[2K
| Adam | epoch: 002 | loss: 0.67954 - acc: 0.6108 -- iter: 032/250
[A[ATraining Step: 10  | total loss: [1m[32m0.66733[0m[0m | time: 1.869s
[2K
| Adam | epoch: 002 | loss: 0.66733 - acc: 0.6323 -- iter: 064/250
[A[ATraining Step: 11  | total loss: [1m[32m0.66965[0m[0m | time: 3.033s
[2K
| Adam | epoch: 002 | loss: 0.66965 - acc: 0.6140 -- iter: 096/250
[A[ATraining Step: 12  | total loss: [1m[32m0.67745[0m[0m | time: 4.124s
[2K
| Adam | epoch: 002 | loss: 0.67745 - acc: 0.5908 -- iter: 128/250
[A[ATraining Step: 13  | total loss: [1m[32m0.68004[0m[0m | time: 5.103s
[2K
| Adam | epoch: 002 | loss: 0.68004 - acc: 0.5787 -- iter: 160/250
[A[ATraining Step: 14  | total loss: [1m[32m0.67982[0m[0m | time: 6.081s
[2K
| Adam | epoch: 002 | loss: 0.67982 - acc: 0.5849 -- iter: 192/250
[A[ATraining Step: 15  | total loss: [1m[32m0.68476[0m[0m | time: 7.098s
[2K
| Adam | epoch: 002 | loss: 0.68476 - acc: 0.5639 -- iter: 224/250
[A[ATraining Step: 16  | total loss: [1m[32m0.68503[0m[0m | time: 9.283s
[2K
| Adam | epoch: 002 | loss: 0.68503 - acc: 0.5634 | val_loss: 0.68604 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 17  | total loss: [1m[32m0.67299[0m[0m | time: 0.757s
[2K
| Adam | epoch: 003 | loss: 0.67299 - acc: 0.6193 -- iter: 032/250
[A[ATraining Step: 18  | total loss: [1m[32m0.66042[0m[0m | time: 1.566s
[2K
| Adam | epoch: 003 | loss: 0.66042 - acc: 0.6712 -- iter: 064/250
[A[ATraining Step: 19  | total loss: [1m[32m0.64676[0m[0m | time: 2.538s
[2K
| Adam | epoch: 003 | loss: 0.64676 - acc: 0.7039 -- iter: 096/250
[A[ATraining Step: 20  | total loss: [1m[32m0.66656[0m[0m | time: 3.511s
[2K
| Adam | epoch: 003 | loss: 0.66656 - acc: 0.6484 -- iter: 128/250
[A[ATraining Step: 21  | total loss: [1m[32m0.69294[0m[0m | time: 4.526s
[2K
| Adam | epoch: 003 | loss: 0.69294 - acc: 0.5926 -- iter: 160/250
[A[ATraining Step: 22  | total loss: [1m[32m0.68225[0m[0m | time: 5.617s
[2K
| Adam | epoch: 003 | loss: 0.68225 - acc: 0.6023 -- iter: 192/250
[A[ATraining Step: 23  | total loss: [1m[32m0.68140[0m[0m | time: 6.558s
[2K
| Adam | epoch: 003 | loss: 0.68140 - acc: 0.5999 -- iter: 224/250
[A[ATraining Step: 24  | total loss: [1m[32m0.66398[0m[0m | time: 8.603s
[2K
| Adam | epoch: 003 | loss: 0.66398 - acc: 0.6333 | val_loss: 0.69008 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 25  | total loss: [1m[32m0.67085[0m[0m | time: 0.999s
[2K
| Adam | epoch: 004 | loss: 0.67085 - acc: 0.6140 -- iter: 032/250
[A[ATraining Step: 26  | total loss: [1m[32m0.67491[0m[0m | time: 1.836s
[2K
| Adam | epoch: 004 | loss: 0.67491 - acc: 0.6004 -- iter: 064/250
[A[ATraining Step: 27  | total loss: [1m[32m0.69158[0m[0m | time: 2.792s
[2K
| Adam | epoch: 004 | loss: 0.69158 - acc: 0.5548 -- iter: 096/250
[A[ATraining Step: 28  | total loss: [1m[32m0.70060[0m[0m | time: 3.809s
[2K
| Adam | epoch: 004 | loss: 0.70060 - acc: 0.5218 -- iter: 128/250
[A[ATraining Step: 29  | total loss: [1m[32m0.69095[0m[0m | time: 4.678s
[2K
| Adam | epoch: 004 | loss: 0.69095 - acc: 0.5545 -- iter: 160/250
[A[ATraining Step: 30  | total loss: [1m[32m0.69072[0m[0m | time: 5.790s
[2K
| Adam | epoch: 004 | loss: 0.69072 - acc: 0.5490 -- iter: 192/250
[A[ATraining Step: 31  | total loss: [1m[32m0.68701[0m[0m | time: 6.973s
[2K
| Adam | epoch: 004 | loss: 0.68701 - acc: 0.5666 -- iter: 224/250
[A[ATraining Step: 32  | total loss: [1m[32m0.68161[0m[0m | time: 9.038s
[2K
| Adam | epoch: 004 | loss: 0.68161 - acc: 0.6008 | val_loss: 0.68704 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 33  | total loss: [1m[32m0.67986[0m[0m | time: 1.078s
[2K
| Adam | epoch: 005 | loss: 0.67986 - acc: 0.6130 -- iter: 032/250
[A[ATraining Step: 34  | total loss: [1m[32m0.67834[0m[0m | time: 1.926s
[2K
| Adam | epoch: 005 | loss: 0.67834 - acc: 0.6222 -- iter: 064/250
[A[ATraining Step: 35  | total loss: [1m[32m0.67883[0m[0m | time: 2.836s
[2K
| Adam | epoch: 005 | loss: 0.67883 - acc: 0.6163 -- iter: 096/250
[A[ATraining Step: 36  | total loss: [1m[32m0.67973[0m[0m | time: 3.734s
[2K
| Adam | epoch: 005 | loss: 0.67973 - acc: 0.6082 -- iter: 128/250
[A[ATraining Step: 37  | total loss: [1m[32m0.68038[0m[0m | time: 4.976s
[2K
| Adam | epoch: 005 | loss: 0.68038 - acc: 0.6020 -- iter: 160/250
[A[ATraining Step: 38  | total loss: [1m[32m0.68226[0m[0m | time: 5.856s
[2K
| Adam | epoch: 005 | loss: 0.68226 - acc: 0.5881 -- iter: 192/250
[A[ATraining Step: 39  | total loss: [1m[32m0.68377[0m[0m | time: 6.889s
[2K
| Adam | epoch: 005 | loss: 0.68377 - acc: 0.5772 -- iter: 224/250
[A[ATraining Step: 40  | total loss: [1m[32m0.68510[0m[0m | time: 8.944s
[2K
| Adam | epoch: 005 | loss: 0.68510 - acc: 0.5686 | val_loss: 0.68530 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 41  | total loss: [1m[32m0.68356[0m[0m | time: 1.147s
[2K
| Adam | epoch: 006 | loss: 0.68356 - acc: 0.5732 -- iter: 032/250
[A[ATraining Step: 42  | total loss: [1m[32m0.68748[0m[0m | time: 2.179s
[2K
| Adam | epoch: 006 | loss: 0.68748 - acc: 0.5544 -- iter: 064/250
[A[ATraining Step: 43  | total loss: [1m[32m0.68260[0m[0m | time: 3.126s
[2K
| Adam | epoch: 006 | loss: 0.68260 - acc: 0.5724 -- iter: 096/250
[A[ATraining Step: 44  | total loss: [1m[32m0.67734[0m[0m | time: 3.947s
[2K
| Adam | epoch: 006 | loss: 0.67734 - acc: 0.5923 -- iter: 128/250
[A[ATraining Step: 45  | total loss: [1m[32m0.67741[0m[0m | time: 4.820s
[2K
| Adam | epoch: 006 | loss: 0.67741 - acc: 0.5897 -- iter: 160/250
[A[ATraining Step: 46  | total loss: [1m[32m0.67777[0m[0m | time: 5.870s
[2K
| Adam | epoch: 006 | loss: 0.67777 - acc: 0.5876 -- iter: 192/250
[A[ATraining Step: 47  | total loss: [1m[32m0.68047[0m[0m | time: 6.983s
[2K
| Adam | epoch: 006 | loss: 0.68047 - acc: 0.5784 -- iter: 224/250
[A[ATraining Step: 48  | total loss: [1m[32m0.67444[0m[0m | time: 8.988s
[2K
| Adam | epoch: 006 | loss: 0.67444 - acc: 0.5909 | val_loss: 0.68729 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 49  | total loss: [1m[32m0.68131[0m[0m | time: 1.007s
[2K
| Adam | epoch: 007 | loss: 0.68131 - acc: 0.5765 -- iter: 032/250
[A[ATraining Step: 50  | total loss: [1m[32m0.68349[0m[0m | time: 1.979s
[2K
| Adam | epoch: 007 | loss: 0.68349 - acc: 0.5695 -- iter: 064/250
[A[ATraining Step: 51  | total loss: [1m[32m0.67554[0m[0m | time: 3.081s
[2K
| Adam | epoch: 007 | loss: 0.67554 - acc: 0.5875 -- iter: 096/250
[A[ATraining Step: 52  | total loss: [1m[32m0.67546[0m[0m | time: 4.200s
[2K
| Adam | epoch: 007 | loss: 0.67546 - acc: 0.5838 -- iter: 128/250
[A[ATraining Step: 53  | total loss: [1m[32m0.66566[0m[0m | time: 4.933s
[2K
| Adam | epoch: 007 | loss: 0.66566 - acc: 0.6083 -- iter: 160/250
[A[ATraining Step: 54  | total loss: [1m[32m0.66658[0m[0m | time: 5.712s
[2K
| Adam | epoch: 007 | loss: 0.66658 - acc: 0.6037 -- iter: 192/250
[A[ATraining Step: 55  | total loss: [1m[32m0.66783[0m[0m | time: 6.792s
[2K
| Adam | epoch: 007 | loss: 0.66783 - acc: 0.5999 -- iter: 224/250
[A[ATraining Step: 56  | total loss: [1m[32m0.66984[0m[0m | time: 8.961s
[2K
| Adam | epoch: 007 | loss: 0.66984 - acc: 0.5946 | val_loss: 0.67995 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 57  | total loss: [1m[32m0.67488[0m[0m | time: 1.018s
[2K
| Adam | epoch: 008 | loss: 0.67488 - acc: 0.5859 -- iter: 032/250
[A[ATraining Step: 58  | total loss: [1m[32m0.66738[0m[0m | time: 1.798s
[2K
| Adam | epoch: 008 | loss: 0.66738 - acc: 0.5997 -- iter: 064/250
[A[ATraining Step: 59  | total loss: [1m[32m0.66655[0m[0m | time: 2.916s
[2K
| Adam | epoch: 008 | loss: 0.66655 - acc: 0.5989 -- iter: 096/250
[A[ATraining Step: 60  | total loss: [1m[32m0.67358[0m[0m | time: 3.974s
[2K
| Adam | epoch: 008 | loss: 0.67358 - acc: 0.5776 -- iter: 128/250
[A[ATraining Step: 61  | total loss: [1m[32m0.66631[0m[0m | time: 5.312s
[2K
| Adam | epoch: 008 | loss: 0.66631 - acc: 0.5960 -- iter: 160/250
[A[ATraining Step: 62  | total loss: [1m[32m0.65971[0m[0m | time: 6.034s
[2K
| Adam | epoch: 008 | loss: 0.65971 - acc: 0.6077 -- iter: 192/250
[A[ATraining Step: 63  | total loss: [1m[32m0.65968[0m[0m | time: 6.866s
[2K
| Adam | epoch: 008 | loss: 0.65968 - acc: 0.6038 -- iter: 224/250
[A[ATraining Step: 64  | total loss: [1m[32m0.66018[0m[0m | time: 8.916s
[2K
| Adam | epoch: 008 | loss: 0.66018 - acc: 0.6005 | val_loss: 0.66880 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 65  | total loss: [1m[32m0.66833[0m[0m | time: 1.166s
[2K
| Adam | epoch: 009 | loss: 0.66833 - acc: 0.5881 -- iter: 032/250
[A[ATraining Step: 66  | total loss: [1m[32m0.67108[0m[0m | time: 2.342s
[2K
| Adam | epoch: 009 | loss: 0.67108 - acc: 0.5774 -- iter: 064/250
[A[ATraining Step: 67  | total loss: [1m[32m0.66536[0m[0m | time: 3.184s
[2K
| Adam | epoch: 009 | loss: 0.66536 - acc: 0.5943 -- iter: 096/250
[A[ATraining Step: 68  | total loss: [1m[32m0.66687[0m[0m | time: 4.159s
[2K
| Adam | epoch: 009 | loss: 0.66687 - acc: 0.5795 -- iter: 128/250
[A[ATraining Step: 69  | total loss: [1m[32m0.66755[0m[0m | time: 5.196s
[2K
| Adam | epoch: 009 | loss: 0.66755 - acc: 0.5702 -- iter: 160/250
[A[ATraining Step: 70  | total loss: [1m[32m0.66489[0m[0m | time: 6.193s
[2K
| Adam | epoch: 009 | loss: 0.66489 - acc: 0.5801 -- iter: 192/250
[A[ATraining Step: 71  | total loss: [1m[32m0.65966[0m[0m | time: 7.148s
[2K
| Adam | epoch: 009 | loss: 0.65966 - acc: 0.5817 -- iter: 224/250
[A[ATraining Step: 72  | total loss: [1m[32m0.66749[0m[0m | time: 9.080s
[2K
| Adam | epoch: 009 | loss: 0.66749 - acc: 0.5595 | val_loss: 0.65451 - val_acc: 0.5570 -- iter: 250/250
--
Training Step: 73  | total loss: [1m[32m0.67263[0m[0m | time: 0.974s
[2K
| Adam | epoch: 010 | loss: 0.67263 - acc: 0.5401 -- iter: 032/250
[A[ATraining Step: 74  | total loss: [1m[32m0.66743[0m[0m | time: 1.941s
[2K
| Adam | epoch: 010 | loss: 0.66743 - acc: 0.5597 -- iter: 064/250
[A[ATraining Step: 75  | total loss: [1m[32m0.66148[0m[0m | time: 2.928s
[2K
| Adam | epoch: 010 | loss: 0.66148 - acc: 0.5701 -- iter: 096/250
[A[ATraining Step: 76  | total loss: [1m[32m0.66413[0m[0m | time: 4.066s
[2K
| Adam | epoch: 010 | loss: 0.66413 - acc: 0.5760 -- iter: 128/250
[A[ATraining Step: 77  | total loss: [1m[32m0.65043[0m[0m | time: 5.169s
[2K
| Adam | epoch: 010 | loss: 0.65043 - acc: 0.5978 -- iter: 160/250
[A[ATraining Step: 78  | total loss: [1m[32m0.67022[0m[0m | time: 6.049s
[2K
| Adam | epoch: 010 | loss: 0.67022 - acc: 0.5777 -- iter: 192/250
[A[ATraining Step: 79  | total loss: [1m[32m0.67167[0m[0m | time: 7.181s
[2K
| Adam | epoch: 010 | loss: 0.67167 - acc: 0.5761 -- iter: 224/250
[A[ATraining Step: 80  | total loss: [1m[32m0.66894[0m[0m | time: 9.349s
[2K
| Adam | epoch: 010 | loss: 0.66894 - acc: 0.5652 | val_loss: 0.65720 - val_acc: 0.6329 -- iter: 250/250
--
Training Step: 81  | total loss: [1m[32m0.66256[0m[0m | time: 0.956s
[2K
| Adam | epoch: 011 | loss: 0.66256 - acc: 0.5741 -- iter: 032/250
[A[ATraining Step: 82  | total loss: [1m[32m0.65811[0m[0m | time: 2.027s
[2K
| Adam | epoch: 011 | loss: 0.65811 - acc: 0.5936 -- iter: 064/250
[A[ATraining Step: 83  | total loss: [1m[32m0.64977[0m[0m | time: 3.226s
[2K
| Adam | epoch: 011 | loss: 0.64977 - acc: 0.6124 -- iter: 096/250
[A[ATraining Step: 84  | total loss: [1m[32m0.64754[0m[0m | time: 4.116s
[2K
| Adam | epoch: 011 | loss: 0.64754 - acc: 0.6105 -- iter: 128/250
[A[ATraining Step: 85  | total loss: [1m[32m0.65152[0m[0m | time: 5.020s
[2K
| Adam | epoch: 011 | loss: 0.65152 - acc: 0.6057 -- iter: 160/250
[A[ATraining Step: 86  | total loss: [1m[32m0.64674[0m[0m | time: 5.997s
[2K
| Adam | epoch: 011 | loss: 0.64674 - acc: 0.6170 -- iter: 192/250
[A[ATraining Step: 87  | total loss: [1m[32m0.64231[0m[0m | time: 6.998s
[2K
| Adam | epoch: 011 | loss: 0.64231 - acc: 0.6210 -- iter: 224/250
[A[ATraining Step: 88  | total loss: [1m[32m0.64005[0m[0m | time: 9.072s
[2K
| Adam | epoch: 011 | loss: 0.64005 - acc: 0.6245 | val_loss: 0.63383 - val_acc: 0.6456 -- iter: 250/250
--
Training Step: 89  | total loss: [1m[32m0.62170[0m[0m | time: 0.827s
[2K
| Adam | epoch: 012 | loss: 0.62170 - acc: 0.6464 -- iter: 032/250
[A[ATraining Step: 90  | total loss: [1m[32m0.62082[0m[0m | time: 1.449s
[2K
| Adam | epoch: 012 | loss: 0.62082 - acc: 0.6433 -- iter: 064/250
[A[ATraining Step: 91  | total loss: [1m[32m0.61475[0m[0m | time: 2.078s
[2K
| Adam | epoch: 012 | loss: 0.61475 - acc: 0.6521 -- iter: 096/250
[A[ATraining Step: 92  | total loss: [1m[32m0.61331[0m[0m | time: 2.691s
[2K
| Adam | epoch: 012 | loss: 0.61331 - acc: 0.6556 -- iter: 128/250
[A[ATraining Step: 93  | total loss: [1m[32m0.59914[0m[0m | time: 3.318s
[2K
| Adam | epoch: 012 | loss: 0.59914 - acc: 0.6650 -- iter: 160/250
[A[ATraining Step: 94  | total loss: [1m[32m0.65535[0m[0m | time: 3.924s
[2K
| Adam | epoch: 012 | loss: 0.65535 - acc: 0.6423 -- iter: 192/250
[A[ATraining Step: 95  | total loss: [1m[32m0.65358[0m[0m | time: 4.542s
[2K
| Adam | epoch: 012 | loss: 0.65358 - acc: 0.6499 -- iter: 224/250
[A[ATraining Step: 96  | total loss: [1m[32m0.64180[0m[0m | time: 6.171s
[2K
| Adam | epoch: 012 | loss: 0.64180 - acc: 0.6599 | val_loss: 0.63350 - val_acc: 0.6962 -- iter: 250/250
--
Training Step: 97  | total loss: [1m[32m0.63166[0m[0m | time: 1.061s
[2K
| Adam | epoch: 013 | loss: 0.63166 - acc: 0.6752 -- iter: 032/250
[A[ATraining Step: 98  | total loss: [1m[32m0.62218[0m[0m | time: 1.940s
[2K
| Adam | epoch: 013 | loss: 0.62218 - acc: 0.6983 -- iter: 064/250
[A[ATraining Step: 99  | total loss: [1m[32m0.61706[0m[0m | time: 2.816s
[2K
| Adam | epoch: 013 | loss: 0.61706 - acc: 0.7092 -- iter: 096/250
[A[ATraining Step: 100  | total loss: [1m[32m0.61107[0m[0m | time: 3.797s
[2K
| Adam | epoch: 013 | loss: 0.61107 - acc: 0.7191 -- iter: 128/250
[A[ATraining Step: 101  | total loss: [1m[32m0.61090[0m[0m | time: 4.904s
[2K
| Adam | epoch: 013 | loss: 0.61090 - acc: 0.7222 -- iter: 160/250
[A[ATraining Step: 102  | total loss: [1m[32m0.60218[0m[0m | time: 5.962s
[2K
| Adam | epoch: 013 | loss: 0.60218 - acc: 0.7312 -- iter: 192/250
[A[ATraining Step: 103  | total loss: [1m[32m0.60193[0m[0m | time: 7.116s
[2K
| Adam | epoch: 013 | loss: 0.60193 - acc: 0.7237 -- iter: 224/250
[A[ATraining Step: 104  | total loss: [1m[32m0.58549[0m[0m | time: 9.146s
[2K
| Adam | epoch: 013 | loss: 0.58549 - acc: 0.7326 | val_loss: 0.65503 - val_acc: 0.6203 -- iter: 250/250
--
Training Step: 105  | total loss: [1m[32m0.58273[0m[0m | time: 0.631s
[2K
| Adam | epoch: 014 | loss: 0.58273 - acc: 0.7281 -- iter: 032/250
[A[ATraining Step: 106  | total loss: [1m[32m0.56801[0m[0m | time: 1.292s
[2K
| Adam | epoch: 014 | loss: 0.56801 - acc: 0.7365 -- iter: 064/250
[A[ATraining Step: 107  | total loss: [1m[32m0.55528[0m[0m | time: 1.828s
[2K
| Adam | epoch: 014 | loss: 0.55528 - acc: 0.7410 -- iter: 096/250
[A[ATraining Step: 108  | total loss: [1m[32m0.54406[0m[0m | time: 2.405s
[2K
| Adam | epoch: 014 | loss: 0.54406 - acc: 0.7438 -- iter: 128/250
[A[ATraining Step: 109  | total loss: [1m[32m0.53290[0m[0m | time: 3.012s
[2K
| Adam | epoch: 014 | loss: 0.53290 - acc: 0.7541 -- iter: 160/250
[A[ATraining Step: 110  | total loss: [1m[32m0.52804[0m[0m | time: 3.630s
[2K
| Adam | epoch: 014 | loss: 0.52804 - acc: 0.7568 -- iter: 192/250
[A[ATraining Step: 111  | total loss: [1m[32m0.51790[0m[0m | time: 4.258s
[2K
| Adam | epoch: 014 | loss: 0.51790 - acc: 0.7623 -- iter: 224/250
[A[ATraining Step: 112  | total loss: [1m[32m0.52407[0m[0m | time: 5.891s
[2K
| Adam | epoch: 014 | loss: 0.52407 - acc: 0.7549 | val_loss: 0.59087 - val_acc: 0.7089 -- iter: 250/250
--
Training Step: 113  | total loss: [1m[32m0.51563[0m[0m | time: 0.611s
[2K
| Adam | epoch: 015 | loss: 0.51563 - acc: 0.7638 -- iter: 032/250
[A[ATraining Step: 114  | total loss: [1m[32m0.49876[0m[0m | time: 1.247s
[2K
| Adam | epoch: 015 | loss: 0.49876 - acc: 0.7718 -- iter: 064/250
[A[ATraining Step: 115  | total loss: [1m[32m0.48377[0m[0m | time: 1.888s
[2K
| Adam | epoch: 015 | loss: 0.48377 - acc: 0.7790 -- iter: 096/250
[A[ATraining Step: 116  | total loss: [1m[32m0.46223[0m[0m | time: 2.464s
[2K
| Adam | epoch: 015 | loss: 0.46223 - acc: 0.7948 -- iter: 128/250
[A[ATraining Step: 117  | total loss: [1m[32m0.45234[0m[0m | time: 2.977s
[2K
| Adam | epoch: 015 | loss: 0.45234 - acc: 0.8038 -- iter: 160/250
[A[ATraining Step: 118  | total loss: [1m[32m0.44047[0m[0m | time: 3.585s
[2K
| Adam | epoch: 015 | loss: 0.44047 - acc: 0.8157 -- iter: 192/250
[A[ATraining Step: 119  | total loss: [1m[32m0.41706[0m[0m | time: 4.186s
[2K
| Adam | epoch: 015 | loss: 0.41706 - acc: 0.8248 -- iter: 224/250
[A[ATraining Step: 120  | total loss: [1m[32m0.40985[0m[0m | time: 5.799s
[2K
| Adam | epoch: 015 | loss: 0.40985 - acc: 0.8298 | val_loss: 0.69801 - val_acc: 0.6709 -- iter: 250/250
--
Training Step: 121  | total loss: [1m[32m0.40120[0m[0m | time: 0.627s
[2K
| Adam | epoch: 016 | loss: 0.40120 - acc: 0.8312 -- iter: 032/250
[A[ATraining Step: 122  | total loss: [1m[32m0.38289[0m[0m | time: 1.277s
[2K
| Adam | epoch: 016 | loss: 0.38289 - acc: 0.8387 -- iter: 064/250
[A[ATraining Step: 123  | total loss: [1m[32m0.36371[0m[0m | time: 1.895s
[2K
| Adam | epoch: 016 | loss: 0.36371 - acc: 0.8486 -- iter: 096/250
[A[ATraining Step: 124  | total loss: [1m[32m0.36348[0m[0m | time: 2.516s
[2K
| Adam | epoch: 016 | loss: 0.36348 - acc: 0.8481 -- iter: 128/250
[A[ATraining Step: 125  | total loss: [1m[32m0.34527[0m[0m | time: 3.019s
[2K
| Adam | epoch: 016 | loss: 0.34527 - acc: 0.8570 -- iter: 160/250
[A[ATraining Step: 126  | total loss: [1m[32m0.34149[0m[0m | time: 3.531s
[2K
| Adam | epoch: 016 | loss: 0.34149 - acc: 0.8559 -- iter: 192/250
[A[ATraining Step: 127  | total loss: [1m[32m0.32852[0m[0m | time: 4.150s
[2K
| Adam | epoch: 016 | loss: 0.32852 - acc: 0.8511 -- iter: 224/250
[A[ATraining Step: 128  | total loss: [1m[32m0.31472[0m[0m | time: 5.770s
[2K
| Adam | epoch: 016 | loss: 0.31472 - acc: 0.8566 | val_loss: 0.90692 - val_acc: 0.6203 -- iter: 250/250
--
Training Step: 129  | total loss: [1m[32m0.33079[0m[0m | time: 1.079s
[2K
| Adam | epoch: 017 | loss: 0.33079 - acc: 0.8522 -- iter: 032/250
[A[ATraining Step: 130  | total loss: [1m[32m0.31956[0m[0m | time: 2.062s
[2K
| Adam | epoch: 017 | loss: 0.31956 - acc: 0.8576 -- iter: 064/250
[A[ATraining Step: 131  | total loss: [1m[32m0.29322[0m[0m | time: 2.924s
[2K
| Adam | epoch: 017 | loss: 0.29322 - acc: 0.8719 -- iter: 096/250
[A[ATraining Step: 132  | total loss: [1m[32m0.30615[0m[0m | time: 3.852s
[2K
| Adam | epoch: 017 | loss: 0.30615 - acc: 0.8628 -- iter: 128/250
[A[ATraining Step: 133  | total loss: [1m[32m0.29363[0m[0m | time: 4.774s
[2K
| Adam | epoch: 017 | loss: 0.29363 - acc: 0.8703 -- iter: 160/250
[A[ATraining Step: 134  | total loss: [1m[32m0.28508[0m[0m | time: 5.591s
[2K
| Adam | epoch: 017 | loss: 0.28508 - acc: 0.8739 -- iter: 192/250
[A[ATraining Step: 135  | total loss: [1m[32m0.29741[0m[0m | time: 6.376s
[2K
| Adam | epoch: 017 | loss: 0.29741 - acc: 0.8711 -- iter: 224/250
[A[ATraining Step: 136  | total loss: [1m[32m0.29423[0m[0m | time: 8.421s
[2K
| Adam | epoch: 017 | loss: 0.29423 - acc: 0.8763 | val_loss: 0.68524 - val_acc: 0.7089 -- iter: 250/250
--
Training Step: 137  | total loss: [1m[32m0.31062[0m[0m | time: 1.175s
[2K
| Adam | epoch: 018 | loss: 0.31062 - acc: 0.8699 -- iter: 032/250
[A[ATraining Step: 138  | total loss: [1m[32m0.29029[0m[0m | time: 2.201s
[2K
| Adam | epoch: 018 | loss: 0.29029 - acc: 0.8798 -- iter: 064/250
[A[ATraining Step: 139  | total loss: [1m[32m0.27853[0m[0m | time: 3.123s
[2K
| Adam | epoch: 018 | loss: 0.27853 - acc: 0.8887 -- iter: 096/250
[A[ATraining Step: 140  | total loss: [1m[32m0.26485[0m[0m | time: 4.261s
[2K
| Adam | epoch: 018 | loss: 0.26485 - acc: 0.8967 -- iter: 128/250
[A[ATraining Step: 141  | total loss: [1m[32m0.25745[0m[0m | time: 5.317s
[2K
| Adam | epoch: 018 | loss: 0.25745 - acc: 0.9008 -- iter: 160/250
[A[ATraining Step: 142  | total loss: [1m[32m0.24875[0m[0m | time: 6.402s
[2K
| Adam | epoch: 018 | loss: 0.24875 - acc: 0.9045 -- iter: 192/250
[A[ATraining Step: 143  | total loss: [1m[32m0.23729[0m[0m | time: 7.199s
[2K
| Adam | epoch: 018 | loss: 0.23729 - acc: 0.9109 -- iter: 224/250
[A[ATraining Step: 144  | total loss: [1m[32m0.23375[0m[0m | time: 9.103s
[2K
| Adam | epoch: 018 | loss: 0.23375 - acc: 0.9121 | val_loss: 0.67506 - val_acc: 0.7342 -- iter: 250/250
--
Training Step: 145  | total loss: [1m[32m0.21748[0m[0m | time: 0.924s
[2K
| Adam | epoch: 019 | loss: 0.21748 - acc: 0.9209 -- iter: 032/250
[A[ATraining Step: 146  | total loss: [1m[32m0.21187[0m[0m | time: 1.948s
[2K
| Adam | epoch: 019 | loss: 0.21187 - acc: 0.9257 -- iter: 064/250
[A[ATraining Step: 147  | total loss: [1m[32m0.20122[0m[0m | time: 2.916s
[2K
| Adam | epoch: 019 | loss: 0.20122 - acc: 0.9269 -- iter: 096/250
[A[ATraining Step: 148  | total loss: [1m[32m0.20466[0m[0m | time: 3.915s
[2K
| Adam | epoch: 019 | loss: 0.20466 - acc: 0.9248 -- iter: 128/250
[A[ATraining Step: 149  | total loss: [1m[32m0.18781[0m[0m | time: 5.091s
[2K
| Adam | epoch: 019 | loss: 0.18781 - acc: 0.9323 -- iter: 160/250
[A[ATraining Step: 150  | total loss: [1m[32m0.19228[0m[0m | time: 6.017s
[2K
| Adam | epoch: 019 | loss: 0.19228 - acc: 0.9297 -- iter: 192/250
[A[ATraining Step: 151  | total loss: [1m[32m0.18513[0m[0m | time: 7.021s
[2K
| Adam | epoch: 019 | loss: 0.18513 - acc: 0.9336 -- iter: 224/250
[A[ATraining Step: 152  | total loss: [1m[32m0.19061[0m[0m | time: 8.982s
[2K
| Adam | epoch: 019 | loss: 0.19061 - acc: 0.9340 | val_loss: 0.90727 - val_acc: 0.6962 -- iter: 250/250
--
Training Step: 153  | total loss: [1m[32m0.17475[0m[0m | time: 0.910s
[2K
| Adam | epoch: 020 | loss: 0.17475 - acc: 0.9406 -- iter: 032/250
[A[ATraining Step: 154  | total loss: [1m[32m0.16751[0m[0m | time: 2.042s
[2K
| Adam | epoch: 020 | loss: 0.16751 - acc: 0.9427 -- iter: 064/250
[A[ATraining Step: 155  | total loss: [1m[32m0.16292[0m[0m | time: 2.992s
[2K
| Adam | epoch: 020 | loss: 0.16292 - acc: 0.9453 -- iter: 096/250
[A[ATraining Step: 156  | total loss: [1m[32m0.16090[0m[0m | time: 4.004s
[2K
| Adam | epoch: 020 | loss: 0.16090 - acc: 0.9445 -- iter: 128/250
[A[ATraining Step: 157  | total loss: [1m[32m0.15037[0m[0m | time: 5.117s
[2K
| Adam | epoch: 020 | loss: 0.15037 - acc: 0.9469 -- iter: 160/250
[A[ATraining Step: 158  | total loss: [1m[32m0.15501[0m[0m | time: 6.270s
[2K
| Adam | epoch: 020 | loss: 0.15501 - acc: 0.9460 -- iter: 192/250
[A[ATraining Step: 159  | total loss: [1m[32m0.16319[0m[0m | time: 7.209s
[2K
| Adam | epoch: 020 | loss: 0.16319 - acc: 0.9452 -- iter: 224/250
[A[ATraining Step: 160  | total loss: [1m[32m0.16051[0m[0m | time: 9.202s
[2K
| Adam | epoch: 020 | loss: 0.16051 - acc: 0.9381 | val_loss: 0.72555 - val_acc: 0.7595 -- iter: 250/250
--
Training Step: 161  | total loss: [1m[32m0.16426[0m[0m | time: 1.069s
[2K
| Adam | epoch: 021 | loss: 0.16426 - acc: 0.9318 -- iter: 032/250
[A[ATraining Step: 162  | total loss: [1m[32m0.16376[0m[0m | time: 2.034s
[2K
| Adam | epoch: 021 | loss: 0.16376 - acc: 0.9348 -- iter: 064/250
[A[ATraining Step: 163  | total loss: [1m[32m0.16884[0m[0m | time: 3.067s
[2K
| Adam | epoch: 021 | loss: 0.16884 - acc: 0.9336 -- iter: 096/250
[A[ATraining Step: 164  | total loss: [1m[32m0.15452[0m[0m | time: 4.104s
[2K
| Adam | epoch: 021 | loss: 0.15452 - acc: 0.9403 -- iter: 128/250
[A[ATraining Step: 165  | total loss: [1m[32m0.14767[0m[0m | time: 5.132s
[2K
| Adam | epoch: 021 | loss: 0.14767 - acc: 0.9431 -- iter: 160/250
[A[ATraining Step: 166  | total loss: [1m[32m0.14585[0m[0m | time: 6.060s
[2K
| Adam | epoch: 021 | loss: 0.14585 - acc: 0.9457 -- iter: 192/250
[A[ATraining Step: 167  | total loss: [1m[32m0.13423[0m[0m | time: 7.188s
[2K
| Adam | epoch: 021 | loss: 0.13423 - acc: 0.9511 -- iter: 224/250
[A[ATraining Step: 168  | total loss: [1m[32m0.12687[0m[0m | time: 9.297s
[2K
| Adam | epoch: 021 | loss: 0.12687 - acc: 0.9529 | val_loss: 0.66873 - val_acc: 0.7848 -- iter: 250/250
--
Training Step: 169  | total loss: [1m[32m0.11715[0m[0m | time: 1.022s
[2K
| Adam | epoch: 022 | loss: 0.11715 - acc: 0.9576 -- iter: 032/250
[A[ATraining Step: 170  | total loss: [1m[32m0.10751[0m[0m | time: 1.898s
[2K
| Adam | epoch: 022 | loss: 0.10751 - acc: 0.9618 -- iter: 064/250
[A[ATraining Step: 171  | total loss: [1m[32m0.11428[0m[0m | time: 2.867s
[2K
| Adam | epoch: 022 | loss: 0.11428 - acc: 0.9579 -- iter: 096/250
[A[ATraining Step: 172  | total loss: [1m[32m0.11290[0m[0m | time: 3.804s
[2K
| Adam | epoch: 022 | loss: 0.11290 - acc: 0.9545 -- iter: 128/250
[A[ATraining Step: 173  | total loss: [1m[32m0.13465[0m[0m | time: 4.762s
[2K
| Adam | epoch: 022 | loss: 0.13465 - acc: 0.9496 -- iter: 160/250
[A[ATraining Step: 174  | total loss: [1m[32m0.15443[0m[0m | time: 5.835s
[2K
| Adam | epoch: 022 | loss: 0.15443 - acc: 0.9453 -- iter: 192/250
[A[ATraining Step: 175  | total loss: [1m[32m0.15738[0m[0m | time: 7.028s
[2K
| Adam | epoch: 022 | loss: 0.15738 - acc: 0.9445 -- iter: 224/250
[A[ATraining Step: 176  | total loss: [1m[32m0.14764[0m[0m | time: 9.015s
[2K
| Adam | epoch: 022 | loss: 0.14764 - acc: 0.9469 | val_loss: 0.80760 - val_acc: 0.6582 -- iter: 250/250
--
Training Step: 177  | total loss: [1m[32m0.15598[0m[0m | time: 1.118s
[2K
| Adam | epoch: 023 | loss: 0.15598 - acc: 0.9398 -- iter: 032/250
[A[ATraining Step: 178  | total loss: [1m[32m0.15312[0m[0m | time: 2.403s
[2K
| Adam | epoch: 023 | loss: 0.15312 - acc: 0.9395 -- iter: 064/250
[A[ATraining Step: 179  | total loss: [1m[32m0.14906[0m[0m | time: 3.084s
[2K
| Adam | epoch: 023 | loss: 0.14906 - acc: 0.9424 -- iter: 096/250
[A[ATraining Step: 180  | total loss: [1m[32m0.13740[0m[0m | time: 3.848s
[2K
| Adam | epoch: 023 | loss: 0.13740 - acc: 0.9482 -- iter: 128/250
[A[ATraining Step: 181  | total loss: [1m[32m0.12701[0m[0m | time: 4.797s
[2K
| Adam | epoch: 023 | loss: 0.12701 - acc: 0.9534 -- iter: 160/250
[A[ATraining Step: 182  | total loss: [1m[32m0.13667[0m[0m | time: 5.757s
[2K
| Adam | epoch: 023 | loss: 0.13667 - acc: 0.9518 -- iter: 192/250
[A[ATraining Step: 183  | total loss: [1m[32m0.14866[0m[0m | time: 6.799s
[2K
| Adam | epoch: 023 | loss: 0.14866 - acc: 0.9504 -- iter: 224/250
[A[ATraining Step: 184  | total loss: [1m[32m0.15271[0m[0m | time: 8.910s
[2K
| Adam | epoch: 023 | loss: 0.15271 - acc: 0.9491 | val_loss: 0.72913 - val_acc: 0.7468 -- iter: 250/250
--
Training Step: 185  | total loss: [1m[32m0.14098[0m[0m | time: 0.963s
[2K
| Adam | epoch: 024 | loss: 0.14098 - acc: 0.9542 -- iter: 032/250
[A[ATraining Step: 186  | total loss: [1m[32m0.12992[0m[0m | time: 1.919s
[2K
| Adam | epoch: 024 | loss: 0.12992 - acc: 0.9588 -- iter: 064/250
[A[ATraining Step: 187  | total loss: [1m[32m0.12597[0m[0m | time: 2.963s
[2K
| Adam | epoch: 024 | loss: 0.12597 - acc: 0.9598 -- iter: 096/250
[A[ATraining Step: 188  | total loss: [1m[32m0.11665[0m[0m | time: 3.749s
[2K
| Adam | epoch: 024 | loss: 0.11665 - acc: 0.9638 -- iter: 128/250
[A[ATraining Step: 189  | total loss: [1m[32m0.12047[0m[0m | time: 4.738s
[2K
| Adam | epoch: 024 | loss: 0.12047 - acc: 0.9597 -- iter: 160/250
[A[ATraining Step: 190  | total loss: [1m[32m0.11500[0m[0m | time: 5.782s
[2K
| Adam | epoch: 024 | loss: 0.11500 - acc: 0.9599 -- iter: 192/250
[A[ATraining Step: 191  | total loss: [1m[32m0.10721[0m[0m | time: 6.703s
[2K
| Adam | epoch: 024 | loss: 0.10721 - acc: 0.9639 -- iter: 224/250
[A[ATraining Step: 192  | total loss: [1m[32m0.10465[0m[0m | time: 8.810s
[2K
| Adam | epoch: 024 | loss: 0.10465 - acc: 0.9644 | val_loss: 0.75963 - val_acc: 0.7468 -- iter: 250/250
--
Training Step: 193  | total loss: [1m[32m0.10699[0m[0m | time: 1.223s
[2K
| Adam | epoch: 025 | loss: 0.10699 - acc: 0.9648 -- iter: 032/250
[A[ATraining Step: 194  | total loss: [1m[32m0.10443[0m[0m | time: 2.222s
[2K
| Adam | epoch: 025 | loss: 0.10443 - acc: 0.9652 -- iter: 064/250
[A[ATraining Step: 195  | total loss: [1m[32m0.10579[0m[0m | time: 3.169s
[2K
| Adam | epoch: 025 | loss: 0.10579 - acc: 0.9624 -- iter: 096/250
[A[ATraining Step: 196  | total loss: [1m[32m0.09731[0m[0m | time: 4.312s
[2K
| Adam | epoch: 025 | loss: 0.09731 - acc: 0.9662 -- iter: 128/250
[A[ATraining Step: 197  | total loss: [1m[32m0.08941[0m[0m | time: 5.218s
[2K
| Adam | epoch: 025 | loss: 0.08941 - acc: 0.9696 -- iter: 160/250
[A[ATraining Step: 198  | total loss: [1m[32m0.08141[0m[0m | time: 6.140s
[2K
| Adam | epoch: 025 | loss: 0.08141 - acc: 0.9726 -- iter: 192/250
[A[ATraining Step: 199  | total loss: [1m[32m0.07394[0m[0m | time: 6.983s
[2K
| Adam | epoch: 025 | loss: 0.07394 - acc: 0.9754 -- iter: 224/250
[A[ATraining Step: 200  | total loss: [1m[32m0.08226[0m[0m | time: 9.011s
[2K
| Adam | epoch: 025 | loss: 0.08226 - acc: 0.9684 | val_loss: 1.15698 - val_acc: 0.7342 -- iter: 250/250
--
Training Step: 201  | total loss: [1m[32m0.07727[0m[0m | time: 0.940s
[2K
| Adam | epoch: 026 | loss: 0.07727 - acc: 0.9716 -- iter: 032/250
[A[ATraining Step: 202  | total loss: [1m[32m0.07577[0m[0m | time: 2.029s
[2K
| Adam | epoch: 026 | loss: 0.07577 - acc: 0.9713 -- iter: 064/250
[A[ATraining Step: 203  | total loss: [1m[32m0.07193[0m[0m | time: 3.271s
[2K
| Adam | epoch: 026 | loss: 0.07193 - acc: 0.9742 -- iter: 096/250
[A[ATraining Step: 204  | total loss: [1m[32m0.08098[0m[0m | time: 4.202s
[2K
| Adam | epoch: 026 | loss: 0.08098 - acc: 0.9705 -- iter: 128/250
[A[ATraining Step: 205  | total loss: [1m[32m0.07673[0m[0m | time: 5.163s
[2K
| Adam | epoch: 026 | loss: 0.07673 - acc: 0.9703 -- iter: 160/250
[A[ATraining Step: 206  | total loss: [1m[32m0.06983[0m[0m | time: 5.960s
[2K
| Adam | epoch: 026 | loss: 0.06983 - acc: 0.9733 -- iter: 192/250
[A[ATraining Step: 207  | total loss: [1m[32m0.06430[0m[0m | time: 6.780s
[2K
| Adam | epoch: 026 | loss: 0.06430 - acc: 0.9760 -- iter: 224/250
[A[ATraining Step: 208  | total loss: [1m[32m0.06297[0m[0m | time: 8.773s
[2K
| Adam | epoch: 026 | loss: 0.06297 - acc: 0.9784 | val_loss: 1.08933 - val_acc: 0.7215 -- iter: 250/250
--
Training Step: 209  | total loss: [1m[32m0.07576[0m[0m | time: 1.176s
[2K
| Adam | epoch: 027 | loss: 0.07576 - acc: 0.9743 -- iter: 032/250
[A[ATraining Step: 210  | total loss: [1m[32m0.10517[0m[0m | time: 2.126s
[2K
| Adam | epoch: 027 | loss: 0.10517 - acc: 0.9706 -- iter: 064/250
[A[ATraining Step: 211  | total loss: [1m[32m0.19106[0m[0m | time: 3.151s
[2K
| Adam | epoch: 027 | loss: 0.19106 - acc: 0.9548 -- iter: 096/250
[A[ATraining Step: 212  | total loss: [1m[32m0.19020[0m[0m | time: 4.118s
[2K
| Adam | epoch: 027 | loss: 0.19020 - acc: 0.9531 -- iter: 128/250
[A[ATraining Step: 213  | total loss: [1m[32m0.17596[0m[0m | time: 5.212s
[2K
| Adam | epoch: 027 | loss: 0.17596 - acc: 0.9578 -- iter: 160/250
[A[ATraining Step: 214  | total loss: [1m[32m0.17680[0m[0m | time: 6.297s
[2K
| Adam | epoch: 027 | loss: 0.17680 - acc: 0.9589 -- iter: 192/250
[A[ATraining Step: 215  | total loss: [1m[32m0.17681[0m[0m | time: 7.062s
[2K
| Adam | epoch: 027 | loss: 0.17681 - acc: 0.9599 -- iter: 224/250
[A[ATraining Step: 216  | total loss: [1m[32m0.17112[0m[0m | time: 8.822s
[2K
| Adam | epoch: 027 | loss: 0.17112 - acc: 0.9639 | val_loss: 0.57363 - val_acc: 0.7342 -- iter: 250/250
--
Training Step: 217  | total loss: [1m[32m0.16448[0m[0m | time: 0.931s
[2K
| Adam | epoch: 028 | loss: 0.16448 - acc: 0.9675 -- iter: 032/250
[A[ATraining Step: 218  | total loss: [1m[32m0.16044[0m[0m | time: 1.930s
[2K
| Adam | epoch: 028 | loss: 0.16044 - acc: 0.9707 -- iter: 064/250
[A[ATraining Step: 219  | total loss: [1m[32m0.15151[0m[0m | time: 3.105s
[2K
| Adam | epoch: 028 | loss: 0.15151 - acc: 0.9737 -- iter: 096/250
[A[ATraining Step: 220  | total loss: [1m[32m0.14511[0m[0m | time: 4.170s
[2K
| Adam | epoch: 028 | loss: 0.14511 - acc: 0.9763 -- iter: 128/250
[A[ATraining Step: 221  | total loss: [1m[32m0.13944[0m[0m | time: 5.056s
[2K
| Adam | epoch: 028 | loss: 0.13944 - acc: 0.9755 -- iter: 160/250
[A[ATraining Step: 222  | total loss: [1m[32m0.13198[0m[0m | time: 6.055s
[2K
| Adam | epoch: 028 | loss: 0.13198 - acc: 0.9749 -- iter: 192/250
[A[ATraining Step: 223  | total loss: [1m[32m0.12077[0m[0m | time: 7.141s
[2K
| Adam | epoch: 028 | loss: 0.12077 - acc: 0.9774 -- iter: 224/250
[A[ATraining Step: 224  | total loss: [1m[32m0.11987[0m[0m | time: 9.187s
[2K
| Adam | epoch: 028 | loss: 0.11987 - acc: 0.9765 | val_loss: 0.91960 - val_acc: 0.7468 -- iter: 250/250
--
Training Step: 225  | total loss: [1m[32m0.10896[0m[0m | time: 0.939s
[2K
| Adam | epoch: 029 | loss: 0.10896 - acc: 0.9789 -- iter: 032/250
[A[ATraining Step: 226  | total loss: [1m[32m0.09896[0m[0m | time: 1.813s
[2K
| Adam | epoch: 029 | loss: 0.09896 - acc: 0.9810 -- iter: 064/250
[A[ATraining Step: 227  | total loss: [1m[32m0.08951[0m[0m | time: 2.897s
[2K
| Adam | epoch: 029 | loss: 0.08951 - acc: 0.9829 -- iter: 096/250
[A[ATraining Step: 228  | total loss: [1m[32m0.08873[0m[0m | time: 3.990s
[2K
| Adam | epoch: 029 | loss: 0.08873 - acc: 0.9783 -- iter: 128/250
[A[ATraining Step: 229  | total loss: [1m[32m0.10603[0m[0m | time: 5.224s
[2K
| Adam | epoch: 029 | loss: 0.10603 - acc: 0.9774 -- iter: 160/250
[A[ATraining Step: 230  | total loss: [1m[32m0.09649[0m[0m | time: 6.082s
[2K
| Adam | epoch: 029 | loss: 0.09649 - acc: 0.9796 -- iter: 192/250
[A[ATraining Step: 231  | total loss: [1m[32m0.08901[0m[0m | time: 7.010s
[2K
| Adam | epoch: 029 | loss: 0.08901 - acc: 0.9817 -- iter: 224/250
[A[ATraining Step: 232  | total loss: [1m[32m0.08264[0m[0m | time: 9.032s
[2K
| Adam | epoch: 029 | loss: 0.08264 - acc: 0.9835 | val_loss: 1.10082 - val_acc: 0.7468 -- iter: 250/250
--
Training Step: 233  | total loss: [1m[32m0.07459[0m[0m | time: 1.007s
[2K
| Adam | epoch: 030 | loss: 0.07459 - acc: 0.9852 -- iter: 032/250
[A[ATraining Step: 234  | total loss: [1m[32m0.07835[0m[0m | time: 1.820s
[2K
| Adam | epoch: 030 | loss: 0.07835 - acc: 0.9828 -- iter: 064/250
[A[ATraining Step: 235  | total loss: [1m[32m0.07248[0m[0m | time: 2.738s
[2K
| Adam | epoch: 030 | loss: 0.07248 - acc: 0.9845 -- iter: 096/250
[A[ATraining Step: 236  | total loss: [1m[32m0.08384[0m[0m | time: 3.806s
[2K
| Adam | epoch: 030 | loss: 0.08384 - acc: 0.9767 -- iter: 128/250
[A[ATraining Step: 237  | total loss: [1m[32m0.10522[0m[0m | time: 4.786s
[2K
| Adam | epoch: 030 | loss: 0.10522 - acc: 0.9728 -- iter: 160/250
[A[ATraining Step: 238  | total loss: [1m[32m0.09662[0m[0m | time: 5.820s
[2K
| Adam | epoch: 030 | loss: 0.09662 - acc: 0.9755 -- iter: 192/250
[A[ATraining Step: 239  | total loss: [1m[32m0.08722[0m[0m | time: 6.976s
[2K
| Adam | epoch: 030 | loss: 0.08722 - acc: 0.9779 -- iter: 224/250
[A[ATraining Step: 240  | total loss: [1m[32m0.09499[0m[0m | time: 8.820s
[2K
| Adam | epoch: 030 | loss: 0.09499 - acc: 0.9770 | val_loss: 0.91739 - val_acc: 0.7089 -- iter: 250/250
--
Validation AUC:0.8564935064935065
Validation AUPRC:0.88383235920483
Test AUC:0.816551724137931
Test AUPRC:0.8701705398363768
BestTestF1Score	0.84	0.52	0.78	0.8	0.88	44	11	18	6	0.02
BestTestMCCScore	0.84	0.52	0.78	0.8	0.88	44	11	18	6	0.02
BestTestAccuracyScore	0.84	0.52	0.78	0.8	0.88	44	11	18	6	0.02
BestValidationF1Score	0.83	0.59	0.8	0.79	0.86	38	10	25	6	0.02
BestValidationMCC	0.83	0.59	0.8	0.79	0.86	38	10	25	6	0.02
BestValidationAccuracy	0.83	0.59	0.8	0.79	0.86	38	10	25	6	0.02
TestPredictions (Threshold:0.02)
CHEMBL1224487,FP,INACT,0.029999999329447746	CHEMBL573179,TP,ACT,0.949999988079071	CHEMBL571981,TN,INACT,0.0	CHEMBL2147996,TP,ACT,0.9800000190734863	CHEMBL1802300,FP,INACT,0.10999999940395355	CHEMBL1224314,TP,ACT,0.9900000095367432	CHEMBL1229058,TP,ACT,0.9800000190734863	CHEMBL3765405,TP,ACT,0.4300000071525574	CHEMBL226813,TN,INACT,0.0	CHEMBL509435,FP,INACT,0.9599999785423279	CHEMBL3800056,TP,ACT,0.8299999833106995	CHEMBL193664,TN,INACT,0.009999999776482582	CHEMBL1224626,TP,ACT,0.6200000047683716	CHEMBL3310975,TP,ACT,1.0	CHEMBL3764222,FN,ACT,0.0	CHEMBL206816,TP,ACT,1.0	CHEMBL3310849,TP,ACT,1.0	CHEMBL2148075,FN,ACT,0.009999999776482582	CHEMBL1668305,TN,INACT,0.0	CHEMBL202831,FP,INACT,0.05999999865889549	CHEMBL576344,TP,ACT,0.9900000095367432	CHEMBL3765142,TP,ACT,0.9700000286102295	CHEMBL202872,TN,INACT,0.009999999776482582	CHEMBL503606,FP,INACT,0.9900000095367432	CHEMBL3310852,TP,ACT,1.0	CHEMBL602890,TN,INACT,0.0	CHEMBL465623,TP,ACT,0.9700000286102295	CHEMBL3765698,TP,ACT,0.4300000071525574	CHEMBL3765389,TP,ACT,1.0	CHEMBL271826,TP,ACT,0.6299999952316284	CHEMBL3310853,TP,ACT,1.0	CHEMBL3763974,TP,ACT,0.9900000095367432	CHEMBL272253,TP,ACT,0.949999988079071	CHEMBL510240,FN,ACT,0.0	CHEMBL3764760,TP,ACT,0.9900000095367432	CHEMBL262354,TP,ACT,0.8399999737739563	CHEMBL2147995,TP,ACT,0.9700000286102295	CHEMBL196408,FP,INACT,0.03999999910593033	CHEMBL571980,TP,ACT,0.05999999865889549	CHEMBL575331,TP,ACT,0.8100000023841858	CHEMBL3765107,FP,INACT,0.7799999713897705	CHEMBL229522,TN,INACT,0.0	CHEMBL3218002,FP,INACT,0.07999999821186066	CHEMBL2147999,FP,INACT,0.9900000095367432	CHEMBL510926,FP,INACT,0.9300000071525574	CHEMBL3764504,TP,ACT,0.9900000095367432	CHEMBL14145,TN,INACT,0.009999999776482582	CHEMBL3628604,TP,ACT,0.07999999821186066	CHEMBL3799562,FN,ACT,0.009999999776482582	CHEMBL412131,FN,ACT,0.0	CHEMBL577335,TN,INACT,0.0	CHEMBL1229062,TN,INACT,0.0	CHEMBL1081198,TN,INACT,0.0	CHEMBL3764703,TP,ACT,0.949999988079071	CHEMBL572914,TP,ACT,0.9800000190734863	CHEMBL1224310,TP,ACT,0.25	CHEMBL470328,TN,INACT,0.0	CHEMBL443652,TP,ACT,0.029999999329447746	CHEMBL1933308,FP,INACT,0.800000011920929	CHEMBL3342394,TP,ACT,0.9900000095367432	CHEMBL1668310,TN,INACT,0.0	CHEMBL3745728,TP,ACT,0.9200000166893005	CHEMBL1240901,TP,ACT,0.9399999976158142	CHEMBL3799991,TP,ACT,0.9800000190734863	CHEMBL116893,TN,INACT,0.009999999776482582	CHEMBL3628603,TP,ACT,0.25999999046325684	CHEMBL3087010,TP,ACT,0.15000000596046448	CHEMBL576113,TP,ACT,0.09000000357627869	CHEMBL2336696,TN,INACT,0.0	CHEMBL1224560,TP,ACT,0.9700000286102295	CHEMBL1668307,TN,INACT,0.0	CHEMBL3310974,TP,ACT,0.9300000071525574	CHEMBL3310843,TP,ACT,0.6100000143051147	CHEMBL3763210,TP,ACT,0.029999999329447746	CHEMBL3764514,FN,ACT,0.019999999552965164	CHEMBL3628598,TP,ACT,0.029999999329447746	CHEMBL591504,TN,INACT,0.0	CHEMBL1667871,TN,INACT,0.0	CHEMBL3628554,TP,ACT,0.9800000190734863	

