CNNModel CHEMBL4179 adam 0.0001 30 32 0 0.8 False True
Number of active compounds :	513
Number of inactive compounds :	513
---------------------------------
Run id: CNNModel_CHEMBL4179_adam_0.0001_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4179_adam_0.0001_30_32_0.8_True/
---------------------------------
Training samples: 612
Validation samples: 192
--
Training Step: 1  | time: 1.453s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/612
[A[ATraining Step: 2  | total loss: [1m[32m0.62378[0m[0m | time: 2.670s
[2K
| Adam | epoch: 001 | loss: 0.62378 - acc: 0.4219 -- iter: 064/612
[A[ATraining Step: 3  | total loss: [1m[32m0.68010[0m[0m | time: 3.790s
[2K
| Adam | epoch: 001 | loss: 0.68010 - acc: 0.5369 -- iter: 096/612
[A[ATraining Step: 4  | total loss: [1m[32m0.69021[0m[0m | time: 4.876s
[2K
| Adam | epoch: 001 | loss: 0.69021 - acc: 0.5092 -- iter: 128/612
[A[ATraining Step: 5  | total loss: [1m[32m0.69137[0m[0m | time: 6.115s
[2K
| Adam | epoch: 001 | loss: 0.69137 - acc: 0.5677 -- iter: 160/612
[A[ATraining Step: 6  | total loss: [1m[32m0.69398[0m[0m | time: 7.340s
[2K
| Adam | epoch: 001 | loss: 0.69398 - acc: 0.4438 -- iter: 192/612
[A[ATraining Step: 7  | total loss: [1m[32m0.69689[0m[0m | time: 8.461s
[2K
| Adam | epoch: 001 | loss: 0.69689 - acc: 0.3088 -- iter: 224/612
[A[ATraining Step: 8  | total loss: [1m[32m0.69447[0m[0m | time: 9.801s
[2K
| Adam | epoch: 001 | loss: 0.69447 - acc: 0.4515 -- iter: 256/612
[A[ATraining Step: 9  | total loss: [1m[32m0.69513[0m[0m | time: 11.024s
[2K
| Adam | epoch: 001 | loss: 0.69513 - acc: 0.3779 -- iter: 288/612
[A[ATraining Step: 10  | total loss: [1m[32m0.69430[0m[0m | time: 12.282s
[2K
| Adam | epoch: 001 | loss: 0.69430 - acc: 0.4390 -- iter: 320/612
[A[ATraining Step: 11  | total loss: [1m[32m0.69385[0m[0m | time: 13.216s
[2K
| Adam | epoch: 001 | loss: 0.69385 - acc: 0.4531 -- iter: 352/612
[A[ATraining Step: 12  | total loss: [1m[32m0.69335[0m[0m | time: 14.355s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.5164 -- iter: 384/612
[A[ATraining Step: 13  | total loss: [1m[32m0.69324[0m[0m | time: 15.489s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.5094 -- iter: 416/612
[A[ATraining Step: 14  | total loss: [1m[32m0.69316[0m[0m | time: 16.542s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5567 -- iter: 448/612
[A[ATraining Step: 15  | total loss: [1m[32m0.69320[0m[0m | time: 17.617s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5223 -- iter: 480/612
[A[ATraining Step: 16  | total loss: [1m[32m0.69306[0m[0m | time: 18.816s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.5374 -- iter: 512/612
[A[ATraining Step: 17  | total loss: [1m[32m0.69303[0m[0m | time: 19.976s
[2K
| Adam | epoch: 001 | loss: 0.69303 - acc: 0.5577 -- iter: 544/612
[A[ATraining Step: 18  | total loss: [1m[32m0.69317[0m[0m | time: 21.024s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.5269 -- iter: 576/612
[A[ATraining Step: 19  | total loss: [1m[32m0.69320[0m[0m | time: 22.210s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.4763 -- iter: 608/612
[A[ATraining Step: 20  | total loss: [1m[32m0.69316[0m[0m | time: 23.756s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.4738 | val_loss: 0.69334 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 21  | total loss: [1m[32m0.69313[0m[0m | time: 0.234s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.5595 -- iter: 032/612
[A[ATraining Step: 22  | total loss: [1m[32m0.69358[0m[0m | time: 1.391s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.4667 -- iter: 064/612
[A[ATraining Step: 23  | total loss: [1m[32m0.69339[0m[0m | time: 2.469s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.4854 -- iter: 096/612
[A[ATraining Step: 24  | total loss: [1m[32m0.69326[0m[0m | time: 3.677s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4983 -- iter: 128/612
[A[ATraining Step: 25  | total loss: [1m[32m0.69326[0m[0m | time: 4.878s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4988 -- iter: 160/612
[A[ATraining Step: 26  | total loss: [1m[32m0.69347[0m[0m | time: 6.090s
[2K
| Adam | epoch: 002 | loss: 0.69347 - acc: 0.4577 -- iter: 192/612
[A[ATraining Step: 27  | total loss: [1m[32m0.69331[0m[0m | time: 7.217s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4847 -- iter: 224/612
[A[ATraining Step: 28  | total loss: [1m[32m0.69322[0m[0m | time: 8.340s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4963 -- iter: 256/612
[A[ATraining Step: 29  | total loss: [1m[32m0.69311[0m[0m | time: 9.544s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5124 -- iter: 288/612
[A[ATraining Step: 30  | total loss: [1m[32m0.69305[0m[0m | time: 10.715s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5243 -- iter: 320/612
[A[ATraining Step: 31  | total loss: [1m[32m0.69303[0m[0m | time: 12.004s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5187 -- iter: 352/612
[A[ATraining Step: 32  | total loss: [1m[32m0.69326[0m[0m | time: 13.027s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4934 -- iter: 384/612
[A[ATraining Step: 33  | total loss: [1m[32m0.69324[0m[0m | time: 14.223s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4948 -- iter: 416/612
[A[ATraining Step: 34  | total loss: [1m[32m0.69303[0m[0m | time: 15.400s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5160 -- iter: 448/612
[A[ATraining Step: 35  | total loss: [1m[32m0.69306[0m[0m | time: 16.406s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5061 -- iter: 480/612
[A[ATraining Step: 36  | total loss: [1m[32m0.69298[0m[0m | time: 17.563s
[2K
| Adam | epoch: 002 | loss: 0.69298 - acc: 0.5113 -- iter: 512/612
[A[ATraining Step: 37  | total loss: [1m[32m0.69290[0m[0m | time: 18.795s
[2K
| Adam | epoch: 002 | loss: 0.69290 - acc: 0.5153 -- iter: 544/612
[A[ATraining Step: 38  | total loss: [1m[32m0.69293[0m[0m | time: 19.908s
[2K
| Adam | epoch: 002 | loss: 0.69293 - acc: 0.5123 -- iter: 576/612
[A[ATraining Step: 39  | total loss: [1m[32m0.69289[0m[0m | time: 21.039s
[2K
| Adam | epoch: 002 | loss: 0.69289 - acc: 0.5219 -- iter: 608/612
[A[ATraining Step: 40  | total loss: [1m[32m0.69304[0m[0m | time: 23.420s
[2K
| Adam | epoch: 002 | loss: 0.69304 - acc: 0.5119 | val_loss: 0.69416 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 41  | total loss: [1m[32m0.69293[0m[0m | time: 0.192s
[2K
| Adam | epoch: 003 | loss: 0.69293 - acc: 0.5212 -- iter: 032/612
[A[ATraining Step: 42  | total loss: [1m[32m0.69304[0m[0m | time: 0.362s
[2K
| Adam | epoch: 003 | loss: 0.69304 - acc: 0.5174 -- iter: 064/612
[A[ATraining Step: 43  | total loss: [1m[32m0.69307[0m[0m | time: 1.384s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5143 -- iter: 096/612
[A[ATraining Step: 44  | total loss: [1m[32m0.69298[0m[0m | time: 2.736s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5173 -- iter: 128/612
[A[ATraining Step: 45  | total loss: [1m[32m0.69259[0m[0m | time: 3.920s
[2K
| Adam | epoch: 003 | loss: 0.69259 - acc: 0.5409 -- iter: 160/612
[A[ATraining Step: 46  | total loss: [1m[32m0.69287[0m[0m | time: 4.842s
[2K
| Adam | epoch: 003 | loss: 0.69287 - acc: 0.5236 -- iter: 192/612
[A[ATraining Step: 47  | total loss: [1m[32m0.69290[0m[0m | time: 5.967s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5198 -- iter: 224/612
[A[ATraining Step: 48  | total loss: [1m[32m0.69303[0m[0m | time: 7.219s
[2K
| Adam | epoch: 003 | loss: 0.69303 - acc: 0.5116 -- iter: 256/612
[A[ATraining Step: 49  | total loss: [1m[32m0.69274[0m[0m | time: 8.350s
[2K
| Adam | epoch: 003 | loss: 0.69274 - acc: 0.5245 -- iter: 288/612
[A[ATraining Step: 50  | total loss: [1m[32m0.69312[0m[0m | time: 9.479s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.5062 -- iter: 320/612
[A[ATraining Step: 51  | total loss: [1m[32m0.69313[0m[0m | time: 10.635s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5052 -- iter: 352/612
[A[ATraining Step: 52  | total loss: [1m[32m0.69312[0m[0m | time: 11.739s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.5045 -- iter: 384/612
[A[ATraining Step: 53  | total loss: [1m[32m0.69346[0m[0m | time: 12.984s
[2K
| Adam | epoch: 003 | loss: 0.69346 - acc: 0.4854 -- iter: 416/612
[A[ATraining Step: 54  | total loss: [1m[32m0.69343[0m[0m | time: 13.960s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.4875 -- iter: 448/612
[A[ATraining Step: 55  | total loss: [1m[32m0.69322[0m[0m | time: 14.986s
[2K
| Adam | epoch: 003 | loss: 0.69322 - acc: 0.4982 -- iter: 480/612
[A[ATraining Step: 56  | total loss: [1m[32m0.69346[0m[0m | time: 16.061s
[2K
| Adam | epoch: 003 | loss: 0.69346 - acc: 0.4853 -- iter: 512/612
[A[ATraining Step: 57  | total loss: [1m[32m0.69325[0m[0m | time: 17.171s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.5003 -- iter: 544/612
[A[ATraining Step: 58  | total loss: [1m[32m0.69335[0m[0m | time: 18.222s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4917 -- iter: 576/612
[A[ATraining Step: 59  | total loss: [1m[32m0.69308[0m[0m | time: 19.357s
[2K
| Adam | epoch: 003 | loss: 0.69308 - acc: 0.5054 -- iter: 608/612
[A[ATraining Step: 60  | total loss: [1m[32m0.69298[0m[0m | time: 21.689s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5130 | val_loss: 0.69447 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 61  | total loss: [1m[32m0.69298[0m[0m | time: 1.105s
[2K
| Adam | epoch: 004 | loss: 0.69298 - acc: 0.5113 -- iter: 032/612
[A[ATraining Step: 62  | total loss: [1m[32m0.69310[0m[0m | time: 1.308s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.5058 -- iter: 064/612
[A[ATraining Step: 63  | total loss: [1m[32m0.69316[0m[0m | time: 1.482s
[2K
| Adam | epoch: 004 | loss: 0.69316 - acc: 0.5051 -- iter: 096/612
[A[ATraining Step: 64  | total loss: [1m[32m0.69317[0m[0m | time: 2.746s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5044 -- iter: 128/612
[A[ATraining Step: 65  | total loss: [1m[32m0.69307[0m[0m | time: 3.836s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5116 -- iter: 160/612
[A[ATraining Step: 66  | total loss: [1m[32m0.69333[0m[0m | time: 5.017s
[2K
| Adam | epoch: 004 | loss: 0.69333 - acc: 0.4950 -- iter: 192/612
[A[ATraining Step: 67  | total loss: [1m[32m0.69327[0m[0m | time: 6.151s
[2K
| Adam | epoch: 004 | loss: 0.69327 - acc: 0.4993 -- iter: 224/612
[A[ATraining Step: 68  | total loss: [1m[32m0.69337[0m[0m | time: 7.328s
[2K
| Adam | epoch: 004 | loss: 0.69337 - acc: 0.4957 -- iter: 256/612
[A[ATraining Step: 69  | total loss: [1m[32m0.69308[0m[0m | time: 8.559s
[2K
| Adam | epoch: 004 | loss: 0.69308 - acc: 0.5145 -- iter: 288/612
[A[ATraining Step: 70  | total loss: [1m[32m0.69302[0m[0m | time: 9.887s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5164 -- iter: 320/612
[A[ATraining Step: 71  | total loss: [1m[32m0.69281[0m[0m | time: 10.961s
[2K
| Adam | epoch: 004 | loss: 0.69281 - acc: 0.5288 -- iter: 352/612
[A[ATraining Step: 72  | total loss: [1m[32m0.69292[0m[0m | time: 12.188s
[2K
| Adam | epoch: 004 | loss: 0.69292 - acc: 0.5220 -- iter: 384/612
[A[ATraining Step: 73  | total loss: [1m[32m0.69308[0m[0m | time: 13.370s
[2K
| Adam | epoch: 004 | loss: 0.69308 - acc: 0.5161 -- iter: 416/612
[A[ATraining Step: 74  | total loss: [1m[32m0.69327[0m[0m | time: 14.629s
[2K
| Adam | epoch: 004 | loss: 0.69327 - acc: 0.5075 -- iter: 448/612
[A[ATraining Step: 75  | total loss: [1m[32m0.69318[0m[0m | time: 15.641s
[2K
| Adam | epoch: 004 | loss: 0.69318 - acc: 0.5101 -- iter: 480/612
[A[ATraining Step: 76  | total loss: [1m[32m0.69274[0m[0m | time: 16.611s
[2K
| Adam | epoch: 004 | loss: 0.69274 - acc: 0.5291 -- iter: 512/612
[A[ATraining Step: 77  | total loss: [1m[32m0.69294[0m[0m | time: 17.700s
[2K
| Adam | epoch: 004 | loss: 0.69294 - acc: 0.5194 -- iter: 544/612
[A[ATraining Step: 78  | total loss: [1m[32m0.69277[0m[0m | time: 18.752s
[2K
| Adam | epoch: 004 | loss: 0.69277 - acc: 0.5239 -- iter: 576/612
[A[ATraining Step: 79  | total loss: [1m[32m0.69272[0m[0m | time: 19.864s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.5247 -- iter: 608/612
[A[ATraining Step: 80  | total loss: [1m[32m0.69237[0m[0m | time: 22.249s
[2K
| Adam | epoch: 004 | loss: 0.69237 - acc: 0.5349 | val_loss: 0.69588 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 81  | total loss: [1m[32m0.69278[0m[0m | time: 1.172s
[2K
| Adam | epoch: 005 | loss: 0.69278 - acc: 0.5219 -- iter: 032/612
[A[ATraining Step: 82  | total loss: [1m[32m0.69231[0m[0m | time: 2.447s
[2K
| Adam | epoch: 005 | loss: 0.69231 - acc: 0.5353 -- iter: 064/612
[A[ATraining Step: 83  | total loss: [1m[32m0.69227[0m[0m | time: 2.658s
[2K
| Adam | epoch: 005 | loss: 0.69227 - acc: 0.5349 -- iter: 096/612
[A[ATraining Step: 84  | total loss: [1m[32m0.69131[0m[0m | time: 2.854s
[2K
| Adam | epoch: 005 | loss: 0.69131 - acc: 0.5564 -- iter: 128/612
[A[ATraining Step: 85  | total loss: [1m[32m0.69032[0m[0m | time: 4.008s
[2K
| Adam | epoch: 005 | loss: 0.69032 - acc: 0.5758 -- iter: 160/612
[A[ATraining Step: 86  | total loss: [1m[32m0.69040[0m[0m | time: 5.074s
[2K
| Adam | epoch: 005 | loss: 0.69040 - acc: 0.5713 -- iter: 192/612
[A[ATraining Step: 87  | total loss: [1m[32m0.69078[0m[0m | time: 6.163s
[2K
| Adam | epoch: 005 | loss: 0.69078 - acc: 0.5642 -- iter: 224/612
[A[ATraining Step: 88  | total loss: [1m[32m0.69142[0m[0m | time: 7.327s
[2K
| Adam | epoch: 005 | loss: 0.69142 - acc: 0.5547 -- iter: 256/612
[A[ATraining Step: 89  | total loss: [1m[32m0.69215[0m[0m | time: 8.522s
[2K
| Adam | epoch: 005 | loss: 0.69215 - acc: 0.5461 -- iter: 288/612
[A[ATraining Step: 90  | total loss: [1m[32m0.69392[0m[0m | time: 9.875s
[2K
| Adam | epoch: 005 | loss: 0.69392 - acc: 0.5290 -- iter: 320/612
[A[ATraining Step: 91  | total loss: [1m[32m0.69371[0m[0m | time: 11.036s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.5292 -- iter: 352/612
[A[ATraining Step: 92  | total loss: [1m[32m0.69548[0m[0m | time: 12.232s
[2K
| Adam | epoch: 005 | loss: 0.69548 - acc: 0.5075 -- iter: 384/612
[A[ATraining Step: 93  | total loss: [1m[32m0.69430[0m[0m | time: 13.378s
[2K
| Adam | epoch: 005 | loss: 0.69430 - acc: 0.5193 -- iter: 416/612
[A[ATraining Step: 94  | total loss: [1m[32m0.69397[0m[0m | time: 14.896s
[2K
| Adam | epoch: 005 | loss: 0.69397 - acc: 0.5205 -- iter: 448/612
[A[ATraining Step: 95  | total loss: [1m[32m0.69515[0m[0m | time: 16.421s
[2K
| Adam | epoch: 005 | loss: 0.69515 - acc: 0.5028 -- iter: 480/612
[A[ATraining Step: 96  | total loss: [1m[32m0.69455[0m[0m | time: 17.237s
[2K
| Adam | epoch: 005 | loss: 0.69455 - acc: 0.5088 -- iter: 512/612
[A[ATraining Step: 97  | total loss: [1m[32m0.69455[0m[0m | time: 18.195s
[2K
| Adam | epoch: 005 | loss: 0.69455 - acc: 0.5048 -- iter: 544/612
[A[ATraining Step: 98  | total loss: [1m[32m0.69489[0m[0m | time: 19.262s
[2K
| Adam | epoch: 005 | loss: 0.69489 - acc: 0.4949 -- iter: 576/612
[A[ATraining Step: 99  | total loss: [1m[32m0.69460[0m[0m | time: 20.265s
[2K
| Adam | epoch: 005 | loss: 0.69460 - acc: 0.4985 -- iter: 608/612
[A[ATraining Step: 100  | total loss: [1m[32m0.69434[0m[0m | time: 22.652s
[2K
| Adam | epoch: 005 | loss: 0.69434 - acc: 0.5018 | val_loss: 0.69574 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 101  | total loss: [1m[32m0.69410[0m[0m | time: 1.293s
[2K
| Adam | epoch: 006 | loss: 0.69410 - acc: 0.5048 -- iter: 032/612
[A[ATraining Step: 102  | total loss: [1m[32m0.69349[0m[0m | time: 2.506s
[2K
| Adam | epoch: 006 | loss: 0.69349 - acc: 0.5199 -- iter: 064/612
[A[ATraining Step: 103  | total loss: [1m[32m0.69370[0m[0m | time: 3.775s
[2K
| Adam | epoch: 006 | loss: 0.69370 - acc: 0.5117 -- iter: 096/612
[A[ATraining Step: 104  | total loss: [1m[32m0.69353[0m[0m | time: 3.954s
[2K
| Adam | epoch: 006 | loss: 0.69353 - acc: 0.5136 -- iter: 128/612
[A[ATraining Step: 105  | total loss: [1m[32m0.69430[0m[0m | time: 4.175s
[2K
| Adam | epoch: 006 | loss: 0.69430 - acc: 0.4873 -- iter: 160/612
[A[ATraining Step: 106  | total loss: [1m[32m0.69484[0m[0m | time: 5.227s
[2K
| Adam | epoch: 006 | loss: 0.69484 - acc: 0.4635 -- iter: 192/612
[A[ATraining Step: 107  | total loss: [1m[32m0.69465[0m[0m | time: 6.334s
[2K
| Adam | epoch: 006 | loss: 0.69465 - acc: 0.4672 -- iter: 224/612
[A[ATraining Step: 108  | total loss: [1m[32m0.69471[0m[0m | time: 7.483s
[2K
| Adam | epoch: 006 | loss: 0.69471 - acc: 0.4580 -- iter: 256/612
[A[ATraining Step: 109  | total loss: [1m[32m0.69449[0m[0m | time: 8.580s
[2K
| Adam | epoch: 006 | loss: 0.69449 - acc: 0.4653 -- iter: 288/612
[A[ATraining Step: 110  | total loss: [1m[32m0.69439[0m[0m | time: 9.707s
[2K
| Adam | epoch: 006 | loss: 0.69439 - acc: 0.4656 -- iter: 320/612
[A[ATraining Step: 111  | total loss: [1m[32m0.69416[0m[0m | time: 11.023s
[2K
| Adam | epoch: 006 | loss: 0.69416 - acc: 0.4785 -- iter: 352/612
[A[ATraining Step: 112  | total loss: [1m[32m0.69407[0m[0m | time: 12.170s
[2K
| Adam | epoch: 006 | loss: 0.69407 - acc: 0.4806 -- iter: 384/612
[A[ATraining Step: 113  | total loss: [1m[32m0.69373[0m[0m | time: 13.234s
[2K
| Adam | epoch: 006 | loss: 0.69373 - acc: 0.5075 -- iter: 416/612
[A[ATraining Step: 114  | total loss: [1m[32m0.69368[0m[0m | time: 14.487s
[2K
| Adam | epoch: 006 | loss: 0.69368 - acc: 0.5068 -- iter: 448/612
[A[ATraining Step: 115  | total loss: [1m[32m0.69375[0m[0m | time: 15.685s
[2K
| Adam | epoch: 006 | loss: 0.69375 - acc: 0.4936 -- iter: 480/612
[A[ATraining Step: 116  | total loss: [1m[32m0.69365[0m[0m | time: 16.987s
[2K
| Adam | epoch: 006 | loss: 0.69365 - acc: 0.4974 -- iter: 512/612
[A[ATraining Step: 117  | total loss: [1m[32m0.69364[0m[0m | time: 17.973s
[2K
| Adam | epoch: 006 | loss: 0.69364 - acc: 0.4945 -- iter: 544/612
[A[ATraining Step: 118  | total loss: [1m[32m0.69347[0m[0m | time: 19.162s
[2K
| Adam | epoch: 006 | loss: 0.69347 - acc: 0.5076 -- iter: 576/612
[A[ATraining Step: 119  | total loss: [1m[32m0.69351[0m[0m | time: 20.273s
[2K
| Adam | epoch: 006 | loss: 0.69351 - acc: 0.5006 -- iter: 608/612
[A[ATraining Step: 120  | total loss: [1m[32m0.69346[0m[0m | time: 22.502s
[2K
| Adam | epoch: 006 | loss: 0.69346 - acc: 0.5005 | val_loss: 0.69370 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 121  | total loss: [1m[32m0.69345[0m[0m | time: 1.022s
[2K
| Adam | epoch: 007 | loss: 0.69345 - acc: 0.5004 -- iter: 032/612
[A[ATraining Step: 122  | total loss: [1m[32m0.69335[0m[0m | time: 2.286s
[2K
| Adam | epoch: 007 | loss: 0.69335 - acc: 0.5098 -- iter: 064/612
[A[ATraining Step: 123  | total loss: [1m[32m0.69341[0m[0m | time: 3.558s
[2K
| Adam | epoch: 007 | loss: 0.69341 - acc: 0.4994 -- iter: 096/612
[A[ATraining Step: 124  | total loss: [1m[32m0.69331[0m[0m | time: 4.875s
[2K
| Adam | epoch: 007 | loss: 0.69331 - acc: 0.5089 -- iter: 128/612
[A[ATraining Step: 125  | total loss: [1m[32m0.69339[0m[0m | time: 5.058s
[2K
| Adam | epoch: 007 | loss: 0.69339 - acc: 0.4986 -- iter: 160/612
[A[ATraining Step: 126  | total loss: [1m[32m0.69319[0m[0m | time: 5.210s
[2K
| Adam | epoch: 007 | loss: 0.69319 - acc: 0.5237 -- iter: 192/612
[A[ATraining Step: 127  | total loss: [1m[32m0.69295[0m[0m | time: 6.187s
[2K
| Adam | epoch: 007 | loss: 0.69295 - acc: 0.5464 -- iter: 224/612
[A[ATraining Step: 128  | total loss: [1m[32m0.69279[0m[0m | time: 7.330s
[2K
| Adam | epoch: 007 | loss: 0.69279 - acc: 0.5605 -- iter: 256/612
[A[ATraining Step: 129  | total loss: [1m[32m0.69277[0m[0m | time: 8.371s
[2K
| Adam | epoch: 007 | loss: 0.69277 - acc: 0.5576 -- iter: 288/612
[A[ATraining Step: 130  | total loss: [1m[32m0.69279[0m[0m | time: 9.402s
[2K
| Adam | epoch: 007 | loss: 0.69279 - acc: 0.5549 -- iter: 320/612
[A[ATraining Step: 131  | total loss: [1m[32m0.69291[0m[0m | time: 10.459s
[2K
| Adam | epoch: 007 | loss: 0.69291 - acc: 0.5463 -- iter: 352/612
[A[ATraining Step: 132  | total loss: [1m[32m0.69294[0m[0m | time: 11.681s
[2K
| Adam | epoch: 007 | loss: 0.69294 - acc: 0.5417 -- iter: 384/612
[A[ATraining Step: 133  | total loss: [1m[32m0.69293[0m[0m | time: 12.758s
[2K
| Adam | epoch: 007 | loss: 0.69293 - acc: 0.5406 -- iter: 416/612
[A[ATraining Step: 134  | total loss: [1m[32m0.69306[0m[0m | time: 13.762s
[2K
| Adam | epoch: 007 | loss: 0.69306 - acc: 0.5303 -- iter: 448/612
[A[ATraining Step: 135  | total loss: [1m[32m0.69297[0m[0m | time: 14.974s
[2K
| Adam | epoch: 007 | loss: 0.69297 - acc: 0.5335 -- iter: 480/612
[A[ATraining Step: 136  | total loss: [1m[32m0.69318[0m[0m | time: 16.176s
[2K
| Adam | epoch: 007 | loss: 0.69318 - acc: 0.5208 -- iter: 512/612
[A[ATraining Step: 137  | total loss: [1m[32m0.69301[0m[0m | time: 17.316s
[2K
| Adam | epoch: 007 | loss: 0.69301 - acc: 0.5281 -- iter: 544/612
[A[ATraining Step: 138  | total loss: [1m[32m0.69304[0m[0m | time: 18.476s
[2K
| Adam | epoch: 007 | loss: 0.69304 - acc: 0.5253 -- iter: 576/612
[A[ATraining Step: 139  | total loss: [1m[32m0.69285[0m[0m | time: 19.640s
[2K
| Adam | epoch: 007 | loss: 0.69285 - acc: 0.5321 -- iter: 608/612
[A[ATraining Step: 140  | total loss: [1m[32m0.69287[0m[0m | time: 21.941s
[2K
| Adam | epoch: 007 | loss: 0.69287 - acc: 0.5289 | val_loss: 0.69478 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 141  | total loss: [1m[32m0.69302[0m[0m | time: 1.231s
[2K
| Adam | epoch: 008 | loss: 0.69302 - acc: 0.5198 -- iter: 032/612
[A[ATraining Step: 142  | total loss: [1m[32m0.69282[0m[0m | time: 2.554s
[2K
| Adam | epoch: 008 | loss: 0.69282 - acc: 0.5272 -- iter: 064/612
[A[ATraining Step: 143  | total loss: [1m[32m0.69286[0m[0m | time: 3.874s
[2K
| Adam | epoch: 008 | loss: 0.69286 - acc: 0.5245 -- iter: 096/612
[A[ATraining Step: 144  | total loss: [1m[32m0.69283[0m[0m | time: 4.944s
[2K
| Adam | epoch: 008 | loss: 0.69283 - acc: 0.5251 -- iter: 128/612
[A[ATraining Step: 145  | total loss: [1m[32m0.69263[0m[0m | time: 5.991s
[2K
| Adam | epoch: 008 | loss: 0.69263 - acc: 0.5320 -- iter: 160/612
[A[ATraining Step: 146  | total loss: [1m[32m0.69268[0m[0m | time: 6.200s
[2K
| Adam | epoch: 008 | loss: 0.69268 - acc: 0.5288 -- iter: 192/612
[A[ATraining Step: 147  | total loss: [1m[32m0.69341[0m[0m | time: 6.431s
[2K
| Adam | epoch: 008 | loss: 0.69341 - acc: 0.5009 -- iter: 224/612
[A[ATraining Step: 148  | total loss: [1m[32m0.69404[0m[0m | time: 7.642s
[2K
| Adam | epoch: 008 | loss: 0.69404 - acc: 0.4758 -- iter: 256/612
[A[ATraining Step: 149  | total loss: [1m[32m0.69363[0m[0m | time: 8.739s
[2K
| Adam | epoch: 008 | loss: 0.69363 - acc: 0.4907 -- iter: 288/612
[A[ATraining Step: 150  | total loss: [1m[32m0.69372[0m[0m | time: 9.861s
[2K
| Adam | epoch: 008 | loss: 0.69372 - acc: 0.4854 -- iter: 320/612
[A[ATraining Step: 151  | total loss: [1m[32m0.69380[0m[0m | time: 11.235s
[2K
| Adam | epoch: 008 | loss: 0.69380 - acc: 0.4806 -- iter: 352/612
[A[ATraining Step: 152  | total loss: [1m[32m0.69382[0m[0m | time: 12.620s
[2K
| Adam | epoch: 008 | loss: 0.69382 - acc: 0.4794 -- iter: 384/612
[A[ATraining Step: 153  | total loss: [1m[32m0.69388[0m[0m | time: 13.732s
[2K
| Adam | epoch: 008 | loss: 0.69388 - acc: 0.4752 -- iter: 416/612
[A[ATraining Step: 154  | total loss: [1m[32m0.69352[0m[0m | time: 14.928s
[2K
| Adam | epoch: 008 | loss: 0.69352 - acc: 0.4933 -- iter: 448/612
[A[ATraining Step: 155  | total loss: [1m[32m0.69353[0m[0m | time: 16.125s
[2K
| Adam | epoch: 008 | loss: 0.69353 - acc: 0.4909 -- iter: 480/612
[A[ATraining Step: 156  | total loss: [1m[32m0.69353[0m[0m | time: 17.309s
[2K
| Adam | epoch: 008 | loss: 0.69353 - acc: 0.4887 -- iter: 512/612
[A[ATraining Step: 157  | total loss: [1m[32m0.69344[0m[0m | time: 18.559s
[2K
| Adam | epoch: 008 | loss: 0.69344 - acc: 0.4929 -- iter: 544/612
[A[ATraining Step: 158  | total loss: [1m[32m0.69348[0m[0m | time: 19.817s
[2K
| Adam | epoch: 008 | loss: 0.69348 - acc: 0.4905 -- iter: 576/612
[A[ATraining Step: 159  | total loss: [1m[32m0.69327[0m[0m | time: 20.982s
[2K
| Adam | epoch: 008 | loss: 0.69327 - acc: 0.5040 -- iter: 608/612
[A[ATraining Step: 160  | total loss: [1m[32m0.69334[0m[0m | time: 23.325s
[2K
| Adam | epoch: 008 | loss: 0.69334 - acc: 0.4973 | val_loss: 0.69417 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 161  | total loss: [1m[32m0.69317[0m[0m | time: 1.093s
[2K
| Adam | epoch: 009 | loss: 0.69317 - acc: 0.5101 -- iter: 032/612
[A[ATraining Step: 162  | total loss: [1m[32m0.69313[0m[0m | time: 1.942s
[2K
| Adam | epoch: 009 | loss: 0.69313 - acc: 0.5122 -- iter: 064/612
[A[ATraining Step: 163  | total loss: [1m[32m0.69307[0m[0m | time: 2.649s
[2K
| Adam | epoch: 009 | loss: 0.69307 - acc: 0.5141 -- iter: 096/612
[A[ATraining Step: 164  | total loss: [1m[32m0.69292[0m[0m | time: 3.417s
[2K
| Adam | epoch: 009 | loss: 0.69292 - acc: 0.5221 -- iter: 128/612
[A[ATraining Step: 165  | total loss: [1m[32m0.69308[0m[0m | time: 4.185s
[2K
| Adam | epoch: 009 | loss: 0.69308 - acc: 0.5105 -- iter: 160/612
[A[ATraining Step: 166  | total loss: [1m[32m0.69303[0m[0m | time: 4.987s
[2K
| Adam | epoch: 009 | loss: 0.69303 - acc: 0.5126 -- iter: 192/612
[A[ATraining Step: 167  | total loss: [1m[32m0.69308[0m[0m | time: 5.112s
[2K
| Adam | epoch: 009 | loss: 0.69308 - acc: 0.5082 -- iter: 224/612
[A[ATraining Step: 168  | total loss: [1m[32m0.69308[0m[0m | time: 5.229s
[2K
| Adam | epoch: 009 | loss: 0.69308 - acc: 0.5074 -- iter: 256/612
[A[ATraining Step: 169  | total loss: [1m[32m0.69308[0m[0m | time: 5.940s
[2K
| Adam | epoch: 009 | loss: 0.69308 - acc: 0.5066 -- iter: 288/612
[A[ATraining Step: 170  | total loss: [1m[32m0.69306[0m[0m | time: 6.660s
[2K
| Adam | epoch: 009 | loss: 0.69306 - acc: 0.5060 -- iter: 320/612
[A[ATraining Step: 171  | total loss: [1m[32m0.69336[0m[0m | time: 7.390s
[2K
| Adam | epoch: 009 | loss: 0.69336 - acc: 0.4866 -- iter: 352/612
[A[ATraining Step: 172  | total loss: [1m[32m0.69325[0m[0m | time: 8.152s
[2K
| Adam | epoch: 009 | loss: 0.69325 - acc: 0.4942 -- iter: 384/612
[A[ATraining Step: 173  | total loss: [1m[32m0.69322[0m[0m | time: 8.924s
[2K
| Adam | epoch: 009 | loss: 0.69322 - acc: 0.4948 -- iter: 416/612
[A[ATraining Step: 174  | total loss: [1m[32m0.69311[0m[0m | time: 9.671s
[2K
| Adam | epoch: 009 | loss: 0.69311 - acc: 0.5016 -- iter: 448/612
[A[ATraining Step: 175  | total loss: [1m[32m0.69290[0m[0m | time: 10.426s
[2K
| Adam | epoch: 009 | loss: 0.69290 - acc: 0.5170 -- iter: 480/612
[A[ATraining Step: 176  | total loss: [1m[32m0.69291[0m[0m | time: 11.200s
[2K
| Adam | epoch: 009 | loss: 0.69291 - acc: 0.5153 -- iter: 512/612
[A[ATraining Step: 177  | total loss: [1m[32m0.69310[0m[0m | time: 11.931s
[2K
| Adam | epoch: 009 | loss: 0.69310 - acc: 0.5013 -- iter: 544/612
[A[ATraining Step: 178  | total loss: [1m[32m0.69305[0m[0m | time: 12.680s
[2K
| Adam | epoch: 009 | loss: 0.69305 - acc: 0.5043 -- iter: 576/612
[A[ATraining Step: 179  | total loss: [1m[32m0.69296[0m[0m | time: 13.460s
[2K
| Adam | epoch: 009 | loss: 0.69296 - acc: 0.5101 -- iter: 608/612
[A[ATraining Step: 180  | total loss: [1m[32m0.69302[0m[0m | time: 15.214s
[2K
| Adam | epoch: 009 | loss: 0.69302 - acc: 0.5060 | val_loss: 0.69412 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 181  | total loss: [1m[32m0.69304[0m[0m | time: 0.753s
[2K
| Adam | epoch: 010 | loss: 0.69304 - acc: 0.5054 -- iter: 032/612
[A[ATraining Step: 182  | total loss: [1m[32m0.69291[0m[0m | time: 1.500s
[2K
| Adam | epoch: 010 | loss: 0.69291 - acc: 0.5142 -- iter: 064/612
[A[ATraining Step: 183  | total loss: [1m[32m0.69298[0m[0m | time: 2.243s
[2K
| Adam | epoch: 010 | loss: 0.69298 - acc: 0.5097 -- iter: 096/612
[A[ATraining Step: 184  | total loss: [1m[32m0.69309[0m[0m | time: 2.963s
[2K
| Adam | epoch: 010 | loss: 0.69309 - acc: 0.5025 -- iter: 128/612
[A[ATraining Step: 185  | total loss: [1m[32m0.69290[0m[0m | time: 3.751s
[2K
| Adam | epoch: 010 | loss: 0.69290 - acc: 0.5147 -- iter: 160/612
[A[ATraining Step: 186  | total loss: [1m[32m0.69278[0m[0m | time: 4.474s
[2K
| Adam | epoch: 010 | loss: 0.69278 - acc: 0.5226 -- iter: 192/612
[A[ATraining Step: 187  | total loss: [1m[32m0.69281[0m[0m | time: 5.230s
[2K
| Adam | epoch: 010 | loss: 0.69281 - acc: 0.5203 -- iter: 224/612
[A[ATraining Step: 188  | total loss: [1m[32m0.69250[0m[0m | time: 5.339s
[2K
| Adam | epoch: 010 | loss: 0.69250 - acc: 0.5371 -- iter: 256/612
[A[ATraining Step: 189  | total loss: [1m[32m0.69217[0m[0m | time: 5.444s
[2K
| Adam | epoch: 010 | loss: 0.69217 - acc: 0.5584 -- iter: 288/612
[A[ATraining Step: 190  | total loss: [1m[32m0.69177[0m[0m | time: 6.227s
[2K
| Adam | epoch: 010 | loss: 0.69177 - acc: 0.5775 -- iter: 320/612
[A[ATraining Step: 191  | total loss: [1m[32m0.69160[0m[0m | time: 7.409s
[2K
| Adam | epoch: 010 | loss: 0.69160 - acc: 0.5823 -- iter: 352/612
[A[ATraining Step: 192  | total loss: [1m[32m0.69216[0m[0m | time: 8.659s
[2K
| Adam | epoch: 010 | loss: 0.69216 - acc: 0.5584 -- iter: 384/612
[A[ATraining Step: 193  | total loss: [1m[32m0.69187[0m[0m | time: 9.947s
[2K
| Adam | epoch: 010 | loss: 0.69187 - acc: 0.5651 -- iter: 416/612
[A[ATraining Step: 194  | total loss: [1m[32m0.69210[0m[0m | time: 11.082s
[2K
| Adam | epoch: 010 | loss: 0.69210 - acc: 0.5554 -- iter: 448/612
[A[ATraining Step: 195  | total loss: [1m[32m0.69265[0m[0m | time: 12.173s
[2K
| Adam | epoch: 010 | loss: 0.69265 - acc: 0.5374 -- iter: 480/612
[A[ATraining Step: 196  | total loss: [1m[32m0.69304[0m[0m | time: 13.392s
[2K
| Adam | epoch: 010 | loss: 0.69304 - acc: 0.5243 -- iter: 512/612
[A[ATraining Step: 197  | total loss: [1m[32m0.69351[0m[0m | time: 14.866s
[2K
| Adam | epoch: 010 | loss: 0.69351 - acc: 0.5094 -- iter: 544/612
[A[ATraining Step: 198  | total loss: [1m[32m0.69346[0m[0m | time: 15.967s
[2K
| Adam | epoch: 010 | loss: 0.69346 - acc: 0.5084 -- iter: 576/612
[A[ATraining Step: 199  | total loss: [1m[32m0.69322[0m[0m | time: 17.202s
[2K
| Adam | epoch: 010 | loss: 0.69322 - acc: 0.5138 -- iter: 608/612
[A[ATraining Step: 200  | total loss: [1m[32m0.69383[0m[0m | time: 19.530s
[2K
| Adam | epoch: 010 | loss: 0.69383 - acc: 0.4937 | val_loss: 0.69533 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 201  | total loss: [1m[32m0.69376[0m[0m | time: 0.958s
[2K
| Adam | epoch: 011 | loss: 0.69376 - acc: 0.4943 -- iter: 032/612
[A[ATraining Step: 202  | total loss: [1m[32m0.69379[0m[0m | time: 1.906s
[2K
| Adam | epoch: 011 | loss: 0.69379 - acc: 0.4918 -- iter: 064/612
[A[ATraining Step: 203  | total loss: [1m[32m0.69374[0m[0m | time: 2.917s
[2K
| Adam | epoch: 011 | loss: 0.69374 - acc: 0.4926 -- iter: 096/612
[A[ATraining Step: 204  | total loss: [1m[32m0.69371[0m[0m | time: 3.933s
[2K
| Adam | epoch: 011 | loss: 0.69371 - acc: 0.4933 -- iter: 128/612
[A[ATraining Step: 205  | total loss: [1m[32m0.69333[0m[0m | time: 4.959s
[2K
| Adam | epoch: 011 | loss: 0.69333 - acc: 0.5065 -- iter: 160/612
[A[ATraining Step: 206  | total loss: [1m[32m0.69314[0m[0m | time: 5.870s
[2K
| Adam | epoch: 011 | loss: 0.69314 - acc: 0.5121 -- iter: 192/612
[A[ATraining Step: 207  | total loss: [1m[32m0.69315[0m[0m | time: 6.908s
[2K
| Adam | epoch: 011 | loss: 0.69315 - acc: 0.5109 -- iter: 224/612
[A[ATraining Step: 208  | total loss: [1m[32m0.69324[0m[0m | time: 7.854s
[2K
| Adam | epoch: 011 | loss: 0.69324 - acc: 0.5067 -- iter: 256/612
[A[ATraining Step: 209  | total loss: [1m[32m0.69307[0m[0m | time: 8.011s
[2K
| Adam | epoch: 011 | loss: 0.69307 - acc: 0.5123 -- iter: 288/612
[A[ATraining Step: 210  | total loss: [1m[32m0.69374[0m[0m | time: 8.169s
[2K
| Adam | epoch: 011 | loss: 0.69374 - acc: 0.4860 -- iter: 320/612
[A[ATraining Step: 211  | total loss: [1m[32m0.69429[0m[0m | time: 9.250s
[2K
| Adam | epoch: 011 | loss: 0.69429 - acc: 0.4624 -- iter: 352/612
[A[ATraining Step: 212  | total loss: [1m[32m0.69388[0m[0m | time: 10.481s
[2K
| Adam | epoch: 011 | loss: 0.69388 - acc: 0.4787 -- iter: 384/612
[A[ATraining Step: 213  | total loss: [1m[32m0.69357[0m[0m | time: 11.860s
[2K
| Adam | epoch: 011 | loss: 0.69357 - acc: 0.4902 -- iter: 416/612
[A[ATraining Step: 214  | total loss: [1m[32m0.69371[0m[0m | time: 13.317s
[2K
| Adam | epoch: 011 | loss: 0.69371 - acc: 0.4818 -- iter: 448/612
[A[ATraining Step: 215  | total loss: [1m[32m0.69390[0m[0m | time: 14.274s
[2K
| Adam | epoch: 011 | loss: 0.69390 - acc: 0.4711 -- iter: 480/612
[A[ATraining Step: 216  | total loss: [1m[32m0.69393[0m[0m | time: 15.388s
[2K
| Adam | epoch: 011 | loss: 0.69393 - acc: 0.4678 -- iter: 512/612
[A[ATraining Step: 217  | total loss: [1m[32m0.69384[0m[0m | time: 16.617s
[2K
| Adam | epoch: 011 | loss: 0.69384 - acc: 0.4710 -- iter: 544/612
[A[ATraining Step: 218  | total loss: [1m[32m0.69376[0m[0m | time: 17.753s
[2K
| Adam | epoch: 011 | loss: 0.69376 - acc: 0.4739 -- iter: 576/612
[A[ATraining Step: 219  | total loss: [1m[32m0.69329[0m[0m | time: 18.962s
[2K
| Adam | epoch: 011 | loss: 0.69329 - acc: 0.5015 -- iter: 608/612
[A[ATraining Step: 220  | total loss: [1m[32m0.69340[0m[0m | time: 21.386s
[2K
| Adam | epoch: 011 | loss: 0.69340 - acc: 0.4920 | val_loss: 0.69429 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 221  | total loss: [1m[32m0.69322[0m[0m | time: 1.242s
[2K
| Adam | epoch: 012 | loss: 0.69322 - acc: 0.5021 -- iter: 032/612
[A[ATraining Step: 222  | total loss: [1m[32m0.69306[0m[0m | time: 2.653s
[2K
| Adam | epoch: 012 | loss: 0.69306 - acc: 0.5113 -- iter: 064/612
[A[ATraining Step: 223  | total loss: [1m[32m0.69289[0m[0m | time: 3.768s
[2K
| Adam | epoch: 012 | loss: 0.69289 - acc: 0.5196 -- iter: 096/612
[A[ATraining Step: 224  | total loss: [1m[32m0.69308[0m[0m | time: 4.771s
[2K
| Adam | epoch: 012 | loss: 0.69308 - acc: 0.5082 -- iter: 128/612
[A[ATraining Step: 225  | total loss: [1m[32m0.69304[0m[0m | time: 5.837s
[2K
| Adam | epoch: 012 | loss: 0.69304 - acc: 0.5105 -- iter: 160/612
[A[ATraining Step: 226  | total loss: [1m[32m0.69320[0m[0m | time: 6.895s
[2K
| Adam | epoch: 012 | loss: 0.69320 - acc: 0.5001 -- iter: 192/612
[A[ATraining Step: 227  | total loss: [1m[32m0.69342[0m[0m | time: 8.013s
[2K
| Adam | epoch: 012 | loss: 0.69342 - acc: 0.4876 -- iter: 224/612
[A[ATraining Step: 228  | total loss: [1m[32m0.69301[0m[0m | time: 9.186s
[2K
| Adam | epoch: 012 | loss: 0.69301 - acc: 0.5076 -- iter: 256/612
[A[ATraining Step: 229  | total loss: [1m[32m0.69294[0m[0m | time: 10.363s
[2K
| Adam | epoch: 012 | loss: 0.69294 - acc: 0.5099 -- iter: 288/612
[A[ATraining Step: 230  | total loss: [1m[32m0.69294[0m[0m | time: 10.555s
[2K
| Adam | epoch: 012 | loss: 0.69294 - acc: 0.5090 -- iter: 320/612
[A[ATraining Step: 231  | total loss: [1m[32m0.69298[0m[0m | time: 10.713s
[2K
| Adam | epoch: 012 | loss: 0.69298 - acc: 0.5081 -- iter: 352/612
[A[ATraining Step: 232  | total loss: [1m[32m0.69301[0m[0m | time: 11.730s
[2K
| Adam | epoch: 012 | loss: 0.69301 - acc: 0.5073 -- iter: 384/612
[A[ATraining Step: 233  | total loss: [1m[32m0.69293[0m[0m | time: 12.832s
[2K
| Adam | epoch: 012 | loss: 0.69293 - acc: 0.5097 -- iter: 416/612
[A[ATraining Step: 234  | total loss: [1m[32m0.69294[0m[0m | time: 14.093s
[2K
| Adam | epoch: 012 | loss: 0.69294 - acc: 0.5087 -- iter: 448/612
[A[ATraining Step: 235  | total loss: [1m[32m0.69287[0m[0m | time: 15.510s
[2K
| Adam | epoch: 012 | loss: 0.69287 - acc: 0.5109 -- iter: 480/612
[A[ATraining Step: 236  | total loss: [1m[32m0.69279[0m[0m | time: 16.764s
[2K
| Adam | epoch: 012 | loss: 0.69279 - acc: 0.5130 -- iter: 512/612
[A[ATraining Step: 237  | total loss: [1m[32m0.69265[0m[0m | time: 17.742s
[2K
| Adam | epoch: 012 | loss: 0.69265 - acc: 0.5211 -- iter: 544/612
[A[ATraining Step: 238  | total loss: [1m[32m0.69269[0m[0m | time: 18.882s
[2K
| Adam | epoch: 012 | loss: 0.69269 - acc: 0.5189 -- iter: 576/612
[A[ATraining Step: 239  | total loss: [1m[32m0.69295[0m[0m | time: 20.009s
[2K
| Adam | epoch: 012 | loss: 0.69295 - acc: 0.5046 -- iter: 608/612
[A[ATraining Step: 240  | total loss: [1m[32m0.69290[0m[0m | time: 22.204s
[2K
| Adam | epoch: 012 | loss: 0.69290 - acc: 0.5072 | val_loss: 0.69442 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 241  | total loss: [1m[32m0.69285[0m[0m | time: 1.021s
[2K
| Adam | epoch: 013 | loss: 0.69285 - acc: 0.5096 -- iter: 032/612
[A[ATraining Step: 242  | total loss: [1m[32m0.69304[0m[0m | time: 2.265s
[2K
| Adam | epoch: 013 | loss: 0.69304 - acc: 0.4993 -- iter: 064/612
[A[ATraining Step: 243  | total loss: [1m[32m0.69319[0m[0m | time: 3.559s
[2K
| Adam | epoch: 013 | loss: 0.69319 - acc: 0.4900 -- iter: 096/612
[A[ATraining Step: 244  | total loss: [1m[32m0.69312[0m[0m | time: 5.210s
[2K
| Adam | epoch: 013 | loss: 0.69312 - acc: 0.4941 -- iter: 128/612
[A[ATraining Step: 245  | total loss: [1m[32m0.69293[0m[0m | time: 6.695s
[2K
| Adam | epoch: 013 | loss: 0.69293 - acc: 0.5041 -- iter: 160/612
[A[ATraining Step: 246  | total loss: [1m[32m0.69275[0m[0m | time: 7.632s
[2K
| Adam | epoch: 013 | loss: 0.69275 - acc: 0.5130 -- iter: 192/612
[A[ATraining Step: 247  | total loss: [1m[32m0.69280[0m[0m | time: 8.672s
[2K
| Adam | epoch: 013 | loss: 0.69280 - acc: 0.5086 -- iter: 224/612
[A[ATraining Step: 248  | total loss: [1m[32m0.69252[0m[0m | time: 9.805s
[2K
| Adam | epoch: 013 | loss: 0.69252 - acc: 0.5234 -- iter: 256/612
[A[ATraining Step: 249  | total loss: [1m[32m0.69236[0m[0m | time: 10.952s
[2K
| Adam | epoch: 013 | loss: 0.69236 - acc: 0.5304 -- iter: 288/612
[A[ATraining Step: 250  | total loss: [1m[32m0.69254[0m[0m | time: 12.169s
[2K
| Adam | epoch: 013 | loss: 0.69254 - acc: 0.5211 -- iter: 320/612
[A[ATraining Step: 251  | total loss: [1m[32m0.69249[0m[0m | time: 12.405s
[2K
| Adam | epoch: 013 | loss: 0.69249 - acc: 0.5221 -- iter: 352/612
[A[ATraining Step: 252  | total loss: [1m[32m0.69123[0m[0m | time: 12.627s
[2K
| Adam | epoch: 013 | loss: 0.69123 - acc: 0.5699 -- iter: 384/612
[A[ATraining Step: 253  | total loss: [1m[32m0.68985[0m[0m | time: 13.824s
[2K
| Adam | epoch: 013 | loss: 0.68985 - acc: 0.6129 -- iter: 416/612
[A[ATraining Step: 254  | total loss: [1m[32m0.68938[0m[0m | time: 14.795s
[2K
| Adam | epoch: 013 | loss: 0.68938 - acc: 0.6235 -- iter: 448/612
[A[ATraining Step: 255  | total loss: [1m[32m0.69017[0m[0m | time: 15.942s
[2K
| Adam | epoch: 013 | loss: 0.69017 - acc: 0.6018 -- iter: 480/612
[A[ATraining Step: 256  | total loss: [1m[32m0.69029[0m[0m | time: 17.292s
[2K
| Adam | epoch: 013 | loss: 0.69029 - acc: 0.5947 -- iter: 512/612
[A[ATraining Step: 257  | total loss: [1m[32m0.69073[0m[0m | time: 18.609s
[2K
| Adam | epoch: 013 | loss: 0.69073 - acc: 0.5821 -- iter: 544/612
[A[ATraining Step: 258  | total loss: [1m[32m0.69138[0m[0m | time: 19.739s
[2K
| Adam | epoch: 013 | loss: 0.69138 - acc: 0.5677 -- iter: 576/612
[A[ATraining Step: 259  | total loss: [1m[32m0.69307[0m[0m | time: 20.790s
[2K
| Adam | epoch: 013 | loss: 0.69307 - acc: 0.5390 -- iter: 608/612
[A[ATraining Step: 260  | total loss: [1m[32m0.69333[0m[0m | time: 22.910s
[2K
| Adam | epoch: 013 | loss: 0.69333 - acc: 0.5320 | val_loss: 0.69817 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 261  | total loss: [1m[32m0.69271[0m[0m | time: 1.305s
[2K
| Adam | epoch: 014 | loss: 0.69271 - acc: 0.5382 -- iter: 032/612
[A[ATraining Step: 262  | total loss: [1m[32m0.69254[0m[0m | time: 2.442s
[2K
| Adam | epoch: 014 | loss: 0.69254 - acc: 0.5375 -- iter: 064/612
[A[ATraining Step: 263  | total loss: [1m[32m0.69207[0m[0m | time: 3.450s
[2K
| Adam | epoch: 014 | loss: 0.69207 - acc: 0.5431 -- iter: 096/612
[A[ATraining Step: 264  | total loss: [1m[32m0.69175[0m[0m | time: 4.663s
[2K
| Adam | epoch: 014 | loss: 0.69175 - acc: 0.5450 -- iter: 128/612
[A[ATraining Step: 265  | total loss: [1m[32m0.69164[0m[0m | time: 5.938s
[2K
| Adam | epoch: 014 | loss: 0.69164 - acc: 0.5437 -- iter: 160/612
[A[ATraining Step: 266  | total loss: [1m[32m0.69181[0m[0m | time: 7.383s
[2K
| Adam | epoch: 014 | loss: 0.69181 - acc: 0.5393 -- iter: 192/612
[A[ATraining Step: 267  | total loss: [1m[32m0.69215[0m[0m | time: 8.398s
[2K
| Adam | epoch: 014 | loss: 0.69215 - acc: 0.5322 -- iter: 224/612
[A[ATraining Step: 268  | total loss: [1m[32m0.69322[0m[0m | time: 9.497s
[2K
| Adam | epoch: 014 | loss: 0.69322 - acc: 0.5165 -- iter: 256/612
[A[ATraining Step: 269  | total loss: [1m[32m0.69252[0m[0m | time: 10.550s
[2K
| Adam | epoch: 014 | loss: 0.69252 - acc: 0.5242 -- iter: 288/612
[A[ATraining Step: 270  | total loss: [1m[32m0.69258[0m[0m | time: 11.622s
[2K
| Adam | epoch: 014 | loss: 0.69258 - acc: 0.5218 -- iter: 320/612
[A[ATraining Step: 271  | total loss: [1m[32m0.69178[0m[0m | time: 12.673s
[2K
| Adam | epoch: 014 | loss: 0.69178 - acc: 0.5321 -- iter: 352/612
[A[ATraining Step: 272  | total loss: [1m[32m0.69172[0m[0m | time: 12.843s
[2K
| Adam | epoch: 014 | loss: 0.69172 - acc: 0.5320 -- iter: 384/612
[A[ATraining Step: 273  | total loss: [1m[32m0.68806[0m[0m | time: 13.042s
[2K
| Adam | epoch: 014 | loss: 0.68806 - acc: 0.5788 -- iter: 416/612
[A[ATraining Step: 274  | total loss: [1m[32m0.68424[0m[0m | time: 14.392s
[2K
| Adam | epoch: 014 | loss: 0.68424 - acc: 0.6210 -- iter: 448/612
[A[ATraining Step: 275  | total loss: [1m[32m0.68517[0m[0m | time: 15.542s
[2K
| Adam | epoch: 014 | loss: 0.68517 - acc: 0.6089 -- iter: 480/612
[A[ATraining Step: 276  | total loss: [1m[32m0.68527[0m[0m | time: 16.567s
[2K
| Adam | epoch: 014 | loss: 0.68527 - acc: 0.6042 -- iter: 512/612
[A[ATraining Step: 277  | total loss: [1m[32m0.68634[0m[0m | time: 17.865s
[2K
| Adam | epoch: 014 | loss: 0.68634 - acc: 0.5938 -- iter: 544/612
[A[ATraining Step: 278  | total loss: [1m[32m0.68955[0m[0m | time: 19.141s
[2K
| Adam | epoch: 014 | loss: 0.68955 - acc: 0.5719 -- iter: 576/612
[A[ATraining Step: 279  | total loss: [1m[32m0.69147[0m[0m | time: 20.459s
[2K
| Adam | epoch: 014 | loss: 0.69147 - acc: 0.5585 -- iter: 608/612
[A[ATraining Step: 280  | total loss: [1m[32m0.69258[0m[0m | time: 22.540s
[2K
| Adam | epoch: 014 | loss: 0.69258 - acc: 0.5495 | val_loss: 0.70804 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 281  | total loss: [1m[32m0.69285[0m[0m | time: 1.100s
[2K
| Adam | epoch: 015 | loss: 0.69285 - acc: 0.5446 -- iter: 032/612
[A[ATraining Step: 282  | total loss: [1m[32m0.69314[0m[0m | time: 2.264s
[2K
| Adam | epoch: 015 | loss: 0.69314 - acc: 0.5401 -- iter: 064/612
[A[ATraining Step: 283  | total loss: [1m[32m0.69243[0m[0m | time: 3.414s
[2K
| Adam | epoch: 015 | loss: 0.69243 - acc: 0.5423 -- iter: 096/612
[A[ATraining Step: 284  | total loss: [1m[32m0.69185[0m[0m | time: 4.421s
[2K
| Adam | epoch: 015 | loss: 0.69185 - acc: 0.5444 -- iter: 128/612
[A[ATraining Step: 285  | total loss: [1m[32m0.69047[0m[0m | time: 5.462s
[2K
| Adam | epoch: 015 | loss: 0.69047 - acc: 0.5524 -- iter: 160/612
[A[ATraining Step: 286  | total loss: [1m[32m0.68916[0m[0m | time: 6.665s
[2K
| Adam | epoch: 015 | loss: 0.68916 - acc: 0.5597 -- iter: 192/612
[A[ATraining Step: 287  | total loss: [1m[32m0.68922[0m[0m | time: 7.938s
[2K
| Adam | epoch: 015 | loss: 0.68922 - acc: 0.5568 -- iter: 224/612
[A[ATraining Step: 288  | total loss: [1m[32m0.69109[0m[0m | time: 9.248s
[2K
| Adam | epoch: 015 | loss: 0.69109 - acc: 0.5418 -- iter: 256/612
[A[ATraining Step: 289  | total loss: [1m[32m0.69188[0m[0m | time: 10.321s
[2K
| Adam | epoch: 015 | loss: 0.69188 - acc: 0.5345 -- iter: 288/612
[A[ATraining Step: 290  | total loss: [1m[32m0.69301[0m[0m | time: 11.374s
[2K
| Adam | epoch: 015 | loss: 0.69301 - acc: 0.5248 -- iter: 320/612
[A[ATraining Step: 291  | total loss: [1m[32m0.69428[0m[0m | time: 12.435s
[2K
| Adam | epoch: 015 | loss: 0.69428 - acc: 0.5129 -- iter: 352/612
[A[ATraining Step: 292  | total loss: [1m[32m0.69343[0m[0m | time: 13.530s
[2K
| Adam | epoch: 015 | loss: 0.69343 - acc: 0.5179 -- iter: 384/612
[A[ATraining Step: 293  | total loss: [1m[32m0.69290[0m[0m | time: 13.732s
[2K
| Adam | epoch: 015 | loss: 0.69290 - acc: 0.5223 -- iter: 416/612
[A[ATraining Step: 294  | total loss: [1m[32m0.69061[0m[0m | time: 13.926s
[2K
| Adam | epoch: 015 | loss: 0.69061 - acc: 0.5451 -- iter: 448/612
[A[ATraining Step: 295  | total loss: [1m[32m0.68837[0m[0m | time: 15.104s
[2K
| Adam | epoch: 015 | loss: 0.68837 - acc: 0.5656 -- iter: 480/612
[A[ATraining Step: 296  | total loss: [1m[32m0.68944[0m[0m | time: 16.373s
[2K
| Adam | epoch: 015 | loss: 0.68944 - acc: 0.5528 -- iter: 512/612
[A[ATraining Step: 297  | total loss: [1m[32m0.69054[0m[0m | time: 17.780s
[2K
| Adam | epoch: 015 | loss: 0.69054 - acc: 0.5413 -- iter: 544/612
[A[ATraining Step: 298  | total loss: [1m[32m0.69190[0m[0m | time: 19.077s
[2K
| Adam | epoch: 015 | loss: 0.69190 - acc: 0.5278 -- iter: 576/612
[A[ATraining Step: 299  | total loss: [1m[32m0.69099[0m[0m | time: 20.214s
[2K
| Adam | epoch: 015 | loss: 0.69099 - acc: 0.5344 -- iter: 608/612
[A[ATraining Step: 300  | total loss: [1m[32m0.69160[0m[0m | time: 22.901s
[2K
| Adam | epoch: 015 | loss: 0.69160 - acc: 0.5278 | val_loss: 0.70137 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 301  | total loss: [1m[32m0.69138[0m[0m | time: 1.095s
[2K
| Adam | epoch: 016 | loss: 0.69138 - acc: 0.5281 -- iter: 032/612
[A[ATraining Step: 302  | total loss: [1m[32m0.69042[0m[0m | time: 2.142s
[2K
| Adam | epoch: 016 | loss: 0.69042 - acc: 0.5347 -- iter: 064/612
[A[ATraining Step: 303  | total loss: [1m[32m0.69106[0m[0m | time: 3.297s
[2K
| Adam | epoch: 016 | loss: 0.69106 - acc: 0.5281 -- iter: 096/612
[A[ATraining Step: 304  | total loss: [1m[32m0.69139[0m[0m | time: 4.601s
[2K
| Adam | epoch: 016 | loss: 0.69139 - acc: 0.5253 -- iter: 128/612
[A[ATraining Step: 305  | total loss: [1m[32m0.69187[0m[0m | time: 5.633s
[2K
| Adam | epoch: 016 | loss: 0.69187 - acc: 0.5196 -- iter: 160/612
[A[ATraining Step: 306  | total loss: [1m[32m0.69130[0m[0m | time: 6.737s
[2K
| Adam | epoch: 016 | loss: 0.69130 - acc: 0.5239 -- iter: 192/612
[A[ATraining Step: 307  | total loss: [1m[32m0.69113[0m[0m | time: 8.047s
[2K
| Adam | epoch: 016 | loss: 0.69113 - acc: 0.5247 -- iter: 224/612
[A[ATraining Step: 308  | total loss: [1m[32m0.69003[0m[0m | time: 9.429s
[2K
| Adam | epoch: 016 | loss: 0.69003 - acc: 0.5347 -- iter: 256/612
[A[ATraining Step: 309  | total loss: [1m[32m0.68995[0m[0m | time: 10.776s
[2K
| Adam | epoch: 016 | loss: 0.68995 - acc: 0.5343 -- iter: 288/612
[A[ATraining Step: 310  | total loss: [1m[32m0.69103[0m[0m | time: 11.879s
[2K
| Adam | epoch: 016 | loss: 0.69103 - acc: 0.5247 -- iter: 320/612
[A[ATraining Step: 311  | total loss: [1m[32m0.69091[0m[0m | time: 12.966s
[2K
| Adam | epoch: 016 | loss: 0.69091 - acc: 0.5253 -- iter: 352/612
[A[ATraining Step: 312  | total loss: [1m[32m0.69019[0m[0m | time: 14.217s
[2K
| Adam | epoch: 016 | loss: 0.69019 - acc: 0.5322 -- iter: 384/612
[A[ATraining Step: 313  | total loss: [1m[32m0.68943[0m[0m | time: 15.333s
[2K
| Adam | epoch: 016 | loss: 0.68943 - acc: 0.5383 -- iter: 416/612
[A[ATraining Step: 314  | total loss: [1m[32m0.68937[0m[0m | time: 15.567s
[2K
| Adam | epoch: 016 | loss: 0.68937 - acc: 0.5376 -- iter: 448/612
[A[ATraining Step: 315  | total loss: [1m[32m0.69275[0m[0m | time: 15.812s
[2K
| Adam | epoch: 016 | loss: 0.69275 - acc: 0.5089 -- iter: 480/612
[A[ATraining Step: 316  | total loss: [1m[32m0.69568[0m[0m | time: 17.039s
[2K
| Adam | epoch: 016 | loss: 0.69568 - acc: 0.4830 -- iter: 512/612
[A[ATraining Step: 317  | total loss: [1m[32m0.69565[0m[0m | time: 18.199s
[2K
| Adam | epoch: 016 | loss: 0.69565 - acc: 0.4815 -- iter: 544/612
[A[ATraining Step: 318  | total loss: [1m[32m0.69525[0m[0m | time: 19.182s
[2K
| Adam | epoch: 016 | loss: 0.69525 - acc: 0.4834 -- iter: 576/612
[A[ATraining Step: 319  | total loss: [1m[32m0.69494[0m[0m | time: 20.416s
[2K
| Adam | epoch: 016 | loss: 0.69494 - acc: 0.4851 -- iter: 608/612
[A[ATraining Step: 320  | total loss: [1m[32m0.69469[0m[0m | time: 23.121s
[2K
| Adam | epoch: 016 | loss: 0.69469 - acc: 0.4865 | val_loss: 0.69632 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 321  | total loss: [1m[32m0.69483[0m[0m | time: 1.076s
[2K
| Adam | epoch: 017 | loss: 0.69483 - acc: 0.4816 -- iter: 032/612
[A[ATraining Step: 322  | total loss: [1m[32m0.69437[0m[0m | time: 2.186s
[2K
| Adam | epoch: 017 | loss: 0.69437 - acc: 0.4866 -- iter: 064/612
[A[ATraining Step: 323  | total loss: [1m[32m0.69459[0m[0m | time: 3.273s
[2K
| Adam | epoch: 017 | loss: 0.69459 - acc: 0.4786 -- iter: 096/612
[A[ATraining Step: 324  | total loss: [1m[32m0.69432[0m[0m | time: 4.418s
[2K
| Adam | epoch: 017 | loss: 0.69432 - acc: 0.4807 -- iter: 128/612
[A[ATraining Step: 325  | total loss: [1m[32m0.69401[0m[0m | time: 5.630s
[2K
| Adam | epoch: 017 | loss: 0.69401 - acc: 0.4858 -- iter: 160/612
[A[ATraining Step: 326  | total loss: [1m[32m0.69370[0m[0m | time: 6.643s
[2K
| Adam | epoch: 017 | loss: 0.69370 - acc: 0.4903 -- iter: 192/612
[A[ATraining Step: 327  | total loss: [1m[32m0.69376[0m[0m | time: 7.728s
[2K
| Adam | epoch: 017 | loss: 0.69376 - acc: 0.4819 -- iter: 224/612
[A[ATraining Step: 328  | total loss: [1m[32m0.69359[0m[0m | time: 8.936s
[2K
| Adam | epoch: 017 | loss: 0.69359 - acc: 0.4806 -- iter: 256/612
[A[ATraining Step: 329  | total loss: [1m[32m0.69322[0m[0m | time: 10.416s
[2K
| Adam | epoch: 017 | loss: 0.69322 - acc: 0.4888 -- iter: 288/612
[A[ATraining Step: 330  | total loss: [1m[32m0.69297[0m[0m | time: 11.747s
[2K
| Adam | epoch: 017 | loss: 0.69297 - acc: 0.4930 -- iter: 320/612
[A[ATraining Step: 331  | total loss: [1m[32m0.69258[0m[0m | time: 12.824s
[2K
| Adam | epoch: 017 | loss: 0.69258 - acc: 0.5031 -- iter: 352/612
[A[ATraining Step: 332  | total loss: [1m[32m0.69246[0m[0m | time: 13.929s
[2K
| Adam | epoch: 017 | loss: 0.69246 - acc: 0.5028 -- iter: 384/612
[A[ATraining Step: 333  | total loss: [1m[32m0.69188[0m[0m | time: 15.042s
[2K
| Adam | epoch: 017 | loss: 0.69188 - acc: 0.5150 -- iter: 416/612
[A[ATraining Step: 334  | total loss: [1m[32m0.69147[0m[0m | time: 16.112s
[2K
| Adam | epoch: 017 | loss: 0.69147 - acc: 0.5198 -- iter: 448/612
[A[ATraining Step: 335  | total loss: [1m[32m0.69163[0m[0m | time: 16.347s
[2K
| Adam | epoch: 017 | loss: 0.69163 - acc: 0.5147 -- iter: 480/612
[A[ATraining Step: 336  | total loss: [1m[32m0.69040[0m[0m | time: 16.559s
[2K
| Adam | epoch: 017 | loss: 0.69040 - acc: 0.5382 -- iter: 512/612
[A[ATraining Step: 337  | total loss: [1m[32m0.68916[0m[0m | time: 17.868s
[2K
| Adam | epoch: 017 | loss: 0.68916 - acc: 0.5594 -- iter: 544/612
[A[ATraining Step: 338  | total loss: [1m[32m0.68932[0m[0m | time: 19.081s
[2K
| Adam | epoch: 017 | loss: 0.68932 - acc: 0.5566 -- iter: 576/612
[A[ATraining Step: 339  | total loss: [1m[32m0.69003[0m[0m | time: 20.236s
[2K
| Adam | epoch: 017 | loss: 0.69003 - acc: 0.5447 -- iter: 608/612
[A[ATraining Step: 340  | total loss: [1m[32m0.69070[0m[0m | time: 22.829s
[2K
| Adam | epoch: 017 | loss: 0.69070 - acc: 0.5339 | val_loss: 0.69776 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 341  | total loss: [1m[32m0.69193[0m[0m | time: 1.130s
[2K
| Adam | epoch: 018 | loss: 0.69193 - acc: 0.5180 -- iter: 032/612
[A[ATraining Step: 342  | total loss: [1m[32m0.69143[0m[0m | time: 2.171s
[2K
| Adam | epoch: 018 | loss: 0.69143 - acc: 0.5225 -- iter: 064/612
[A[ATraining Step: 343  | total loss: [1m[32m0.69137[0m[0m | time: 3.283s
[2K
| Adam | epoch: 018 | loss: 0.69137 - acc: 0.5202 -- iter: 096/612
[A[ATraining Step: 344  | total loss: [1m[32m0.69145[0m[0m | time: 4.645s
[2K
| Adam | epoch: 018 | loss: 0.69145 - acc: 0.5182 -- iter: 128/612
[A[ATraining Step: 345  | total loss: [1m[32m0.69085[0m[0m | time: 5.959s
[2K
| Adam | epoch: 018 | loss: 0.69085 - acc: 0.5226 -- iter: 160/612
[A[ATraining Step: 346  | total loss: [1m[32m0.69021[0m[0m | time: 6.973s
[2K
| Adam | epoch: 018 | loss: 0.69021 - acc: 0.5298 -- iter: 192/612
[A[ATraining Step: 347  | total loss: [1m[32m0.69108[0m[0m | time: 8.049s
[2K
| Adam | epoch: 018 | loss: 0.69108 - acc: 0.5174 -- iter: 224/612
[A[ATraining Step: 348  | total loss: [1m[32m0.69125[0m[0m | time: 9.150s
[2K
| Adam | epoch: 018 | loss: 0.69125 - acc: 0.5125 -- iter: 256/612
[A[ATraining Step: 349  | total loss: [1m[32m0.68977[0m[0m | time: 10.338s
[2K
| Adam | epoch: 018 | loss: 0.68977 - acc: 0.5332 -- iter: 288/612
[A[ATraining Step: 350  | total loss: [1m[32m0.69067[0m[0m | time: 11.678s
[2K
| Adam | epoch: 018 | loss: 0.69067 - acc: 0.5205 -- iter: 320/612
[A[ATraining Step: 351  | total loss: [1m[32m0.69113[0m[0m | time: 13.104s
[2K
| Adam | epoch: 018 | loss: 0.69113 - acc: 0.5122 -- iter: 352/612
[A[ATraining Step: 352  | total loss: [1m[32m0.69089[0m[0m | time: 14.037s
[2K
| Adam | epoch: 018 | loss: 0.69089 - acc: 0.5141 -- iter: 384/612
[A[ATraining Step: 353  | total loss: [1m[32m0.69017[0m[0m | time: 15.101s
[2K
| Adam | epoch: 018 | loss: 0.69017 - acc: 0.5189 -- iter: 416/612
[A[ATraining Step: 354  | total loss: [1m[32m0.68969[0m[0m | time: 16.226s
[2K
| Adam | epoch: 018 | loss: 0.68969 - acc: 0.5233 -- iter: 448/612
[A[ATraining Step: 355  | total loss: [1m[32m0.68958[0m[0m | time: 17.620s
[2K
| Adam | epoch: 018 | loss: 0.68958 - acc: 0.5210 -- iter: 480/612
[A[ATraining Step: 356  | total loss: [1m[32m0.69016[0m[0m | time: 17.870s
[2K
| Adam | epoch: 018 | loss: 0.69016 - acc: 0.5126 -- iter: 512/612
[A[ATraining Step: 357  | total loss: [1m[32m0.68616[0m[0m | time: 18.109s
[2K
| Adam | epoch: 018 | loss: 0.68616 - acc: 0.5613 -- iter: 544/612
[A[ATraining Step: 358  | total loss: [1m[32m0.68158[0m[0m | time: 19.466s
[2K
| Adam | epoch: 018 | loss: 0.68158 - acc: 0.6052 -- iter: 576/612
[A[ATraining Step: 359  | total loss: [1m[32m0.68118[0m[0m | time: 20.673s
[2K
| Adam | epoch: 018 | loss: 0.68118 - acc: 0.6041 -- iter: 608/612
[A[ATraining Step: 360  | total loss: [1m[32m0.68352[0m[0m | time: 22.851s
[2K
| Adam | epoch: 018 | loss: 0.68352 - acc: 0.5843 | val_loss: 0.70690 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 361  | total loss: [1m[32m0.68451[0m[0m | time: 1.494s
[2K
| Adam | epoch: 019 | loss: 0.68451 - acc: 0.5727 -- iter: 032/612
[A[ATraining Step: 362  | total loss: [1m[32m0.68641[0m[0m | time: 2.826s
[2K
| Adam | epoch: 019 | loss: 0.68641 - acc: 0.5592 -- iter: 064/612
[A[ATraining Step: 363  | total loss: [1m[32m0.68758[0m[0m | time: 3.981s
[2K
| Adam | epoch: 019 | loss: 0.68758 - acc: 0.5502 -- iter: 096/612
[A[ATraining Step: 364  | total loss: [1m[32m0.68588[0m[0m | time: 5.219s
[2K
| Adam | epoch: 019 | loss: 0.68588 - acc: 0.5576 -- iter: 128/612
[A[ATraining Step: 365  | total loss: [1m[32m0.68488[0m[0m | time: 6.536s
[2K
| Adam | epoch: 019 | loss: 0.68488 - acc: 0.5613 -- iter: 160/612
[A[ATraining Step: 366  | total loss: [1m[32m0.68711[0m[0m | time: 7.801s
[2K
| Adam | epoch: 019 | loss: 0.68711 - acc: 0.5489 -- iter: 192/612
[A[ATraining Step: 367  | total loss: [1m[32m0.69028[0m[0m | time: 9.192s
[2K
| Adam | epoch: 019 | loss: 0.69028 - acc: 0.5315 -- iter: 224/612
[A[ATraining Step: 368  | total loss: [1m[32m0.69164[0m[0m | time: 10.577s
[2K
| Adam | epoch: 019 | loss: 0.69164 - acc: 0.5221 -- iter: 256/612
[A[ATraining Step: 369  | total loss: [1m[32m0.69259[0m[0m | time: 11.900s
[2K
| Adam | epoch: 019 | loss: 0.69259 - acc: 0.5136 -- iter: 288/612
[A[ATraining Step: 370  | total loss: [1m[32m0.69192[0m[0m | time: 13.042s
[2K
| Adam | epoch: 019 | loss: 0.69192 - acc: 0.5154 -- iter: 320/612
[A[ATraining Step: 371  | total loss: [1m[32m0.69202[0m[0m | time: 14.346s
[2K
| Adam | epoch: 019 | loss: 0.69202 - acc: 0.5107 -- iter: 352/612
[A[ATraining Step: 372  | total loss: [1m[32m0.69039[0m[0m | time: 15.857s
[2K
| Adam | epoch: 019 | loss: 0.69039 - acc: 0.5222 -- iter: 384/612
[A[ATraining Step: 373  | total loss: [1m[32m0.68962[0m[0m | time: 17.374s
[2K
| Adam | epoch: 019 | loss: 0.68962 - acc: 0.5293 -- iter: 416/612
[A[ATraining Step: 374  | total loss: [1m[32m0.69060[0m[0m | time: 19.029s
[2K
| Adam | epoch: 019 | loss: 0.69060 - acc: 0.5139 -- iter: 448/612
[A[ATraining Step: 375  | total loss: [1m[32m0.69060[0m[0m | time: 20.331s
[2K
| Adam | epoch: 019 | loss: 0.69060 - acc: 0.5062 -- iter: 480/612
[A[ATraining Step: 376  | total loss: [1m[32m0.68984[0m[0m | time: 21.572s
[2K
| Adam | epoch: 019 | loss: 0.68984 - acc: 0.5150 -- iter: 512/612
[A[ATraining Step: 377  | total loss: [1m[32m0.68934[0m[0m | time: 21.837s
[2K
| Adam | epoch: 019 | loss: 0.68934 - acc: 0.5166 -- iter: 544/612
[A[ATraining Step: 378  | total loss: [1m[32m0.68596[0m[0m | time: 22.125s
[2K
| Adam | epoch: 019 | loss: 0.68596 - acc: 0.5650 -- iter: 576/612
[A[ATraining Step: 379  | total loss: [1m[32m0.68179[0m[0m | time: 23.337s
[2K
| Adam | epoch: 019 | loss: 0.68179 - acc: 0.6085 -- iter: 608/612
[A[ATraining Step: 380  | total loss: [1m[32m0.68316[0m[0m | time: 26.075s
[2K
| Adam | epoch: 019 | loss: 0.68316 - acc: 0.5914 | val_loss: 0.70363 - val_acc: 0.4271 -- iter: 612/612
--
Training Step: 381  | total loss: [1m[32m0.68137[0m[0m | time: 1.334s
[2K
| Adam | epoch: 020 | loss: 0.68137 - acc: 0.5979 -- iter: 032/612
[A[ATraining Step: 382  | total loss: [1m[32m0.68217[0m[0m | time: 2.512s
[2K
| Adam | epoch: 020 | loss: 0.68217 - acc: 0.5881 -- iter: 064/612
[A[ATraining Step: 383  | total loss: [1m[32m0.68449[0m[0m | time: 3.763s
[2K
| Adam | epoch: 020 | loss: 0.68449 - acc: 0.5730 -- iter: 096/612
[A[ATraining Step: 384  | total loss: [1m[32m0.68151[0m[0m | time: 5.186s
[2K
| Adam | epoch: 020 | loss: 0.68151 - acc: 0.5813 -- iter: 128/612
[A[ATraining Step: 385  | total loss: [1m[32m0.68266[0m[0m | time: 6.878s
[2K
| Adam | epoch: 020 | loss: 0.68266 - acc: 0.5732 -- iter: 160/612
[A[ATraining Step: 386  | total loss: [1m[32m0.68236[0m[0m | time: 8.465s
[2K
| Adam | epoch: 020 | loss: 0.68236 - acc: 0.5690 -- iter: 192/612
[A[ATraining Step: 387  | total loss: [1m[32m0.68301[0m[0m | time: 9.648s
[2K
| Adam | epoch: 020 | loss: 0.68301 - acc: 0.5652 -- iter: 224/612
[A[ATraining Step: 388  | total loss: [1m[32m0.68771[0m[0m | time: 10.849s
[2K
| Adam | epoch: 020 | loss: 0.68771 - acc: 0.5462 -- iter: 256/612
[A[ATraining Step: 389  | total loss: [1m[32m0.69016[0m[0m | time: 12.208s
[2K
| Adam | epoch: 020 | loss: 0.69016 - acc: 0.5353 -- iter: 288/612
[A[ATraining Step: 390  | total loss: [1m[32m0.69032[0m[0m | time: 13.504s
[2K
| Adam | epoch: 020 | loss: 0.69032 - acc: 0.5318 -- iter: 320/612
[A[ATraining Step: 391  | total loss: [1m[32m0.68766[0m[0m | time: 14.834s
[2K
| Adam | epoch: 020 | loss: 0.68766 - acc: 0.5411 -- iter: 352/612
[A[ATraining Step: 392  | total loss: [1m[32m0.68955[0m[0m | time: 16.414s
[2K
| Adam | epoch: 020 | loss: 0.68955 - acc: 0.5308 -- iter: 384/612
[A[ATraining Step: 393  | total loss: [1m[32m0.68960[0m[0m | time: 17.858s
[2K
| Adam | epoch: 020 | loss: 0.68960 - acc: 0.5246 -- iter: 416/612
[A[ATraining Step: 394  | total loss: [1m[32m0.68985[0m[0m | time: 19.075s
[2K
| Adam | epoch: 020 | loss: 0.68985 - acc: 0.5190 -- iter: 448/612
[A[ATraining Step: 395  | total loss: [1m[32m0.68926[0m[0m | time: 20.293s
[2K
| Adam | epoch: 020 | loss: 0.68926 - acc: 0.5171 -- iter: 480/612
[A[ATraining Step: 396  | total loss: [1m[32m0.68950[0m[0m | time: 21.759s
[2K
| Adam | epoch: 020 | loss: 0.68950 - acc: 0.5091 -- iter: 512/612
[A[ATraining Step: 397  | total loss: [1m[32m0.68839[0m[0m | time: 23.942s
[2K
| Adam | epoch: 020 | loss: 0.68839 - acc: 0.5176 -- iter: 544/612
[A[ATraining Step: 398  | total loss: [1m[32m0.68669[0m[0m | time: 24.222s
[2K
| Adam | epoch: 020 | loss: 0.68669 - acc: 0.5221 -- iter: 576/612
[A[ATraining Step: 399  | total loss: [1m[32m0.68812[0m[0m | time: 24.524s
[2K
| Adam | epoch: 020 | loss: 0.68812 - acc: 0.4949 -- iter: 608/612
[A[ATraining Step: 400  | total loss: [1m[32m0.68906[0m[0m | time: 27.396s
[2K
| Adam | epoch: 020 | loss: 0.68906 - acc: 0.4704 | val_loss: 0.69030 - val_acc: 0.5885 -- iter: 612/612
--
Training Step: 401  | total loss: [1m[32m0.68773[0m[0m | time: 1.216s
[2K
| Adam | epoch: 021 | loss: 0.68773 - acc: 0.4890 -- iter: 032/612
[A[ATraining Step: 402  | total loss: [1m[32m0.68741[0m[0m | time: 2.455s
[2K
| Adam | epoch: 021 | loss: 0.68741 - acc: 0.4994 -- iter: 064/612
[A[ATraining Step: 403  | total loss: [1m[32m0.68629[0m[0m | time: 3.746s
[2K
| Adam | epoch: 021 | loss: 0.68629 - acc: 0.5183 -- iter: 096/612
[A[ATraining Step: 404  | total loss: [1m[32m0.68450[0m[0m | time: 5.137s
[2K
| Adam | epoch: 021 | loss: 0.68450 - acc: 0.5477 -- iter: 128/612
[A[ATraining Step: 405  | total loss: [1m[32m0.68426[0m[0m | time: 6.461s
[2K
| Adam | epoch: 021 | loss: 0.68426 - acc: 0.5648 -- iter: 160/612
[A[ATraining Step: 406  | total loss: [1m[32m0.68379[0m[0m | time: 7.595s
[2K
| Adam | epoch: 021 | loss: 0.68379 - acc: 0.5708 -- iter: 192/612
[A[ATraining Step: 407  | total loss: [1m[32m0.68263[0m[0m | time: 8.975s
[2K
| Adam | epoch: 021 | loss: 0.68263 - acc: 0.5731 -- iter: 224/612
[A[ATraining Step: 408  | total loss: [1m[32m0.68444[0m[0m | time: 10.636s
[2K
| Adam | epoch: 021 | loss: 0.68444 - acc: 0.5533 -- iter: 256/612
[A[ATraining Step: 409  | total loss: [1m[32m0.68434[0m[0m | time: 12.359s
[2K
| Adam | epoch: 021 | loss: 0.68434 - acc: 0.5511 -- iter: 288/612
[A[ATraining Step: 410  | total loss: [1m[32m0.68240[0m[0m | time: 13.737s
[2K
| Adam | epoch: 021 | loss: 0.68240 - acc: 0.5554 -- iter: 320/612
[A[ATraining Step: 411  | total loss: [1m[32m0.68204[0m[0m | time: 14.886s
[2K
| Adam | epoch: 021 | loss: 0.68204 - acc: 0.5529 -- iter: 352/612
[A[ATraining Step: 412  | total loss: [1m[32m0.68204[0m[0m | time: 16.186s
[2K
| Adam | epoch: 021 | loss: 0.68204 - acc: 0.5539 -- iter: 384/612
[A[ATraining Step: 413  | total loss: [1m[32m0.68129[0m[0m | time: 17.563s
[2K
| Adam | epoch: 021 | loss: 0.68129 - acc: 0.5516 -- iter: 416/612
[A[ATraining Step: 414  | total loss: [1m[32m0.68151[0m[0m | time: 18.888s
[2K
| Adam | epoch: 021 | loss: 0.68151 - acc: 0.5496 -- iter: 448/612
[A[ATraining Step: 415  | total loss: [1m[32m0.68096[0m[0m | time: 20.252s
[2K
| Adam | epoch: 021 | loss: 0.68096 - acc: 0.5540 -- iter: 480/612
[A[ATraining Step: 416  | total loss: [1m[32m0.68089[0m[0m | time: 21.767s
[2K
| Adam | epoch: 021 | loss: 0.68089 - acc: 0.5549 -- iter: 512/612
[A[ATraining Step: 417  | total loss: [1m[32m0.67965[0m[0m | time: 23.193s
[2K
| Adam | epoch: 021 | loss: 0.67965 - acc: 0.5712 -- iter: 544/612
[A[ATraining Step: 418  | total loss: [1m[32m0.68009[0m[0m | time: 24.492s
[2K
| Adam | epoch: 021 | loss: 0.68009 - acc: 0.5797 -- iter: 576/612
[A[ATraining Step: 419  | total loss: [1m[32m0.67969[0m[0m | time: 24.822s
[2K
| Adam | epoch: 021 | loss: 0.67969 - acc: 0.5811 -- iter: 608/612
[A[ATraining Step: 420  | total loss: [1m[32m0.68070[0m[0m | time: 26.731s
[2K
| Adam | epoch: 021 | loss: 0.68070 - acc: 0.5980 | val_loss: 0.67619 - val_acc: 0.6406 -- iter: 612/612
--
Training Step: 421  | total loss: [1m[32m0.68097[0m[0m | time: 1.609s
[2K
| Adam | epoch: 022 | loss: 0.68097 - acc: 0.6132 -- iter: 032/612
[A[ATraining Step: 422  | total loss: [1m[32m0.67831[0m[0m | time: 3.036s
[2K
| Adam | epoch: 022 | loss: 0.67831 - acc: 0.6332 -- iter: 064/612
[A[ATraining Step: 423  | total loss: [1m[32m0.67805[0m[0m | time: 4.280s
[2K
| Adam | epoch: 022 | loss: 0.67805 - acc: 0.6386 -- iter: 096/612
[A[ATraining Step: 424  | total loss: [1m[32m0.67643[0m[0m | time: 5.507s
[2K
| Adam | epoch: 022 | loss: 0.67643 - acc: 0.6466 -- iter: 128/612
[A[ATraining Step: 425  | total loss: [1m[32m0.67541[0m[0m | time: 6.867s
[2K
| Adam | epoch: 022 | loss: 0.67541 - acc: 0.6538 -- iter: 160/612
[A[ATraining Step: 426  | total loss: [1m[32m0.67491[0m[0m | time: 8.010s
[2K
| Adam | epoch: 022 | loss: 0.67491 - acc: 0.6447 -- iter: 192/612
[A[ATraining Step: 427  | total loss: [1m[32m0.67135[0m[0m | time: 9.215s
[2K
| Adam | epoch: 022 | loss: 0.67135 - acc: 0.6615 -- iter: 224/612
[A[ATraining Step: 428  | total loss: [1m[32m0.66992[0m[0m | time: 10.621s
[2K
| Adam | epoch: 022 | loss: 0.66992 - acc: 0.6578 -- iter: 256/612
[A[ATraining Step: 429  | total loss: [1m[32m0.66824[0m[0m | time: 12.007s
[2K
| Adam | epoch: 022 | loss: 0.66824 - acc: 0.6639 -- iter: 288/612
[A[ATraining Step: 430  | total loss: [1m[32m0.66935[0m[0m | time: 13.150s
[2K
| Adam | epoch: 022 | loss: 0.66935 - acc: 0.6600 -- iter: 320/612
[A[ATraining Step: 431  | total loss: [1m[32m0.66633[0m[0m | time: 14.861s
[2K
| Adam | epoch: 022 | loss: 0.66633 - acc: 0.6628 -- iter: 352/612
[A[ATraining Step: 432  | total loss: [1m[32m0.66551[0m[0m | time: 16.369s
[2K
| Adam | epoch: 022 | loss: 0.66551 - acc: 0.6590 -- iter: 384/612
[A[ATraining Step: 433  | total loss: [1m[32m0.66414[0m[0m | time: 18.008s
[2K
| Adam | epoch: 022 | loss: 0.66414 - acc: 0.6650 -- iter: 416/612
[A[ATraining Step: 434  | total loss: [1m[32m0.65950[0m[0m | time: 19.446s
[2K
| Adam | epoch: 022 | loss: 0.65950 - acc: 0.6891 -- iter: 448/612
[A[ATraining Step: 435  | total loss: [1m[32m0.65838[0m[0m | time: 20.617s
[2K
| Adam | epoch: 022 | loss: 0.65838 - acc: 0.6858 -- iter: 480/612
[A[ATraining Step: 436  | total loss: [1m[32m0.65643[0m[0m | time: 21.848s
[2K
| Adam | epoch: 022 | loss: 0.65643 - acc: 0.6922 -- iter: 512/612
[A[ATraining Step: 437  | total loss: [1m[32m0.65714[0m[0m | time: 23.074s
[2K
| Adam | epoch: 022 | loss: 0.65714 - acc: 0.6824 -- iter: 544/612
[A[ATraining Step: 438  | total loss: [1m[32m0.65723[0m[0m | time: 24.389s
[2K
| Adam | epoch: 022 | loss: 0.65723 - acc: 0.6735 -- iter: 576/612
[A[ATraining Step: 439  | total loss: [1m[32m0.65481[0m[0m | time: 25.662s
[2K
| Adam | epoch: 022 | loss: 0.65481 - acc: 0.6624 -- iter: 608/612
[A[ATraining Step: 440  | total loss: [1m[32m0.64818[0m[0m | time: 27.421s
[2K
| Adam | epoch: 022 | loss: 0.64818 - acc: 0.6712 | val_loss: 0.63761 - val_acc: 0.6615 -- iter: 612/612
--
Training Step: 441  | total loss: [1m[32m0.65005[0m[0m | time: 0.221s
[2K
| Adam | epoch: 023 | loss: 0.65005 - acc: 0.6791 -- iter: 032/612
[A[ATraining Step: 442  | total loss: [1m[32m0.64966[0m[0m | time: 1.426s
[2K
| Adam | epoch: 023 | loss: 0.64966 - acc: 0.6862 -- iter: 064/612
[A[ATraining Step: 443  | total loss: [1m[32m0.64485[0m[0m | time: 3.096s
[2K
| Adam | epoch: 023 | loss: 0.64485 - acc: 0.6925 -- iter: 096/612
[A[ATraining Step: 444  | total loss: [1m[32m0.63944[0m[0m | time: 4.747s
[2K
| Adam | epoch: 023 | loss: 0.63944 - acc: 0.7045 -- iter: 128/612
[A[ATraining Step: 445  | total loss: [1m[32m0.63193[0m[0m | time: 6.528s
[2K
| Adam | epoch: 023 | loss: 0.63193 - acc: 0.7185 -- iter: 160/612
[A[ATraining Step: 446  | total loss: [1m[32m0.62681[0m[0m | time: 7.898s
[2K
| Adam | epoch: 023 | loss: 0.62681 - acc: 0.7185 -- iter: 192/612
[A[ATraining Step: 447  | total loss: [1m[32m0.61992[0m[0m | time: 9.177s
[2K
| Adam | epoch: 023 | loss: 0.61992 - acc: 0.7216 -- iter: 224/612
[A[ATraining Step: 448  | total loss: [1m[32m0.61896[0m[0m | time: 10.555s
[2K
| Adam | epoch: 023 | loss: 0.61896 - acc: 0.7213 -- iter: 256/612
[A[ATraining Step: 449  | total loss: [1m[32m0.61985[0m[0m | time: 12.005s
[2K
| Adam | epoch: 023 | loss: 0.61985 - acc: 0.7086 -- iter: 288/612
[A[ATraining Step: 450  | total loss: [1m[32m0.61769[0m[0m | time: 13.643s
[2K
| Adam | epoch: 023 | loss: 0.61769 - acc: 0.7065 -- iter: 320/612
[A[ATraining Step: 451  | total loss: [1m[32m0.62215[0m[0m | time: 15.237s
[2K
| Adam | epoch: 023 | loss: 0.62215 - acc: 0.6983 -- iter: 352/612
[A[ATraining Step: 452  | total loss: [1m[32m0.61042[0m[0m | time: 16.625s
[2K
| Adam | epoch: 023 | loss: 0.61042 - acc: 0.7222 -- iter: 384/612
[A[ATraining Step: 453  | total loss: [1m[32m0.61250[0m[0m | time: 18.015s
[2K
| Adam | epoch: 023 | loss: 0.61250 - acc: 0.7000 -- iter: 416/612
[A[ATraining Step: 454  | total loss: [1m[32m0.60619[0m[0m | time: 19.479s
[2K
| Adam | epoch: 023 | loss: 0.60619 - acc: 0.6988 -- iter: 448/612
[A[ATraining Step: 455  | total loss: [1m[32m0.58546[0m[0m | time: 21.151s
[2K
| Adam | epoch: 023 | loss: 0.58546 - acc: 0.7195 -- iter: 480/612
[A[ATraining Step: 456  | total loss: [1m[32m0.59198[0m[0m | time: 22.791s
[2K
| Adam | epoch: 023 | loss: 0.59198 - acc: 0.7069 -- iter: 512/612
[A[ATraining Step: 457  | total loss: [1m[32m0.59079[0m[0m | time: 24.641s
[2K
| Adam | epoch: 023 | loss: 0.59079 - acc: 0.7050 -- iter: 544/612
[A[ATraining Step: 458  | total loss: [1m[32m0.58960[0m[0m | time: 25.808s
[2K
| Adam | epoch: 023 | loss: 0.58960 - acc: 0.7157 -- iter: 576/612
[A[ATraining Step: 459  | total loss: [1m[32m0.59910[0m[0m | time: 27.254s
[2K
| Adam | epoch: 023 | loss: 0.59910 - acc: 0.6973 -- iter: 608/612
[A[ATraining Step: 460  | total loss: [1m[32m0.60504[0m[0m | time: 30.075s
[2K
| Adam | epoch: 023 | loss: 0.60504 - acc: 0.6932 | val_loss: 0.60555 - val_acc: 0.6719 -- iter: 612/612
--
Training Step: 461  | total loss: [1m[32m0.60068[0m[0m | time: 0.239s
[2K
| Adam | epoch: 024 | loss: 0.60068 - acc: 0.6957 -- iter: 032/612
[A[ATraining Step: 462  | total loss: [1m[32m0.59820[0m[0m | time: 0.474s
[2K
| Adam | epoch: 024 | loss: 0.59820 - acc: 0.7012 -- iter: 064/612
[A[ATraining Step: 463  | total loss: [1m[32m0.59467[0m[0m | time: 1.844s
[2K
| Adam | epoch: 024 | loss: 0.59467 - acc: 0.6811 -- iter: 096/612
[A[ATraining Step: 464  | total loss: [1m[32m0.59866[0m[0m | time: 3.310s
[2K
| Adam | epoch: 024 | loss: 0.59866 - acc: 0.6786 -- iter: 128/612
[A[ATraining Step: 465  | total loss: [1m[32m0.59242[0m[0m | time: 4.915s
[2K
| Adam | epoch: 024 | loss: 0.59242 - acc: 0.6795 -- iter: 160/612
[A[ATraining Step: 466  | total loss: [1m[32m0.58805[0m[0m | time: 6.113s
[2K
| Adam | epoch: 024 | loss: 0.58805 - acc: 0.6834 -- iter: 192/612
[A[ATraining Step: 467  | total loss: [1m[32m0.58394[0m[0m | time: 7.762s
[2K
| Adam | epoch: 024 | loss: 0.58394 - acc: 0.6932 -- iter: 224/612
[A[ATraining Step: 468  | total loss: [1m[32m0.58029[0m[0m | time: 9.294s
[2K
| Adam | epoch: 024 | loss: 0.58029 - acc: 0.6926 -- iter: 256/612
[A[ATraining Step: 469  | total loss: [1m[32m0.57687[0m[0m | time: 10.665s
[2K
| Adam | epoch: 024 | loss: 0.57687 - acc: 0.6921 -- iter: 288/612
[A[ATraining Step: 470  | total loss: [1m[32m0.57898[0m[0m | time: 11.840s
[2K
| Adam | epoch: 024 | loss: 0.57898 - acc: 0.6854 -- iter: 320/612
[A[ATraining Step: 471  | total loss: [1m[32m0.56536[0m[0m | time: 13.015s
[2K
| Adam | epoch: 024 | loss: 0.56536 - acc: 0.7012 -- iter: 352/612
[A[ATraining Step: 472  | total loss: [1m[32m0.56835[0m[0m | time: 14.239s
[2K
| Adam | epoch: 024 | loss: 0.56835 - acc: 0.6967 -- iter: 384/612
[A[ATraining Step: 473  | total loss: [1m[32m0.57003[0m[0m | time: 15.569s
[2K
| Adam | epoch: 024 | loss: 0.57003 - acc: 0.7021 -- iter: 416/612
[A[ATraining Step: 474  | total loss: [1m[32m0.56028[0m[0m | time: 16.858s
[2K
| Adam | epoch: 024 | loss: 0.56028 - acc: 0.7100 -- iter: 448/612
[A[ATraining Step: 475  | total loss: [1m[32m0.55691[0m[0m | time: 18.232s
[2K
| Adam | epoch: 024 | loss: 0.55691 - acc: 0.7202 -- iter: 480/612
[A[ATraining Step: 476  | total loss: [1m[32m0.55252[0m[0m | time: 19.657s
[2K
| Adam | epoch: 024 | loss: 0.55252 - acc: 0.7295 -- iter: 512/612
[A[ATraining Step: 477  | total loss: [1m[32m0.55436[0m[0m | time: 20.823s
[2K
| Adam | epoch: 024 | loss: 0.55436 - acc: 0.7253 -- iter: 544/612
[A[ATraining Step: 478  | total loss: [1m[32m0.54555[0m[0m | time: 22.165s
[2K
| Adam | epoch: 024 | loss: 0.54555 - acc: 0.7434 -- iter: 576/612
[A[ATraining Step: 479  | total loss: [1m[32m0.53139[0m[0m | time: 23.652s
[2K
| Adam | epoch: 024 | loss: 0.53139 - acc: 0.7596 -- iter: 608/612
[A[ATraining Step: 480  | total loss: [1m[32m0.52078[0m[0m | time: 26.930s
[2K
| Adam | epoch: 024 | loss: 0.52078 - acc: 0.7681 | val_loss: 0.59042 - val_acc: 0.6979 -- iter: 612/612
--
Training Step: 481  | total loss: [1m[32m0.51746[0m[0m | time: 1.217s
[2K
| Adam | epoch: 025 | loss: 0.51746 - acc: 0.7694 -- iter: 032/612
[A[ATraining Step: 482  | total loss: [1m[32m0.51857[0m[0m | time: 1.421s
[2K
| Adam | epoch: 025 | loss: 0.51857 - acc: 0.7581 -- iter: 064/612
[A[ATraining Step: 483  | total loss: [1m[32m0.51291[0m[0m | time: 1.650s
[2K
| Adam | epoch: 025 | loss: 0.51291 - acc: 0.7573 -- iter: 096/612
[A[ATraining Step: 484  | total loss: [1m[32m0.50038[0m[0m | time: 2.892s
[2K
| Adam | epoch: 025 | loss: 0.50038 - acc: 0.7815 -- iter: 128/612
[A[ATraining Step: 485  | total loss: [1m[32m0.51154[0m[0m | time: 4.154s
[2K
| Adam | epoch: 025 | loss: 0.51154 - acc: 0.7753 -- iter: 160/612
[A[ATraining Step: 486  | total loss: [1m[32m0.50917[0m[0m | time: 5.409s
[2K
| Adam | epoch: 025 | loss: 0.50917 - acc: 0.7759 -- iter: 192/612
[A[ATraining Step: 487  | total loss: [1m[32m0.50340[0m[0m | time: 6.855s
[2K
| Adam | epoch: 025 | loss: 0.50340 - acc: 0.7701 -- iter: 224/612
[A[ATraining Step: 488  | total loss: [1m[32m0.51537[0m[0m | time: 8.207s
[2K
| Adam | epoch: 025 | loss: 0.51537 - acc: 0.7556 -- iter: 256/612
[A[ATraining Step: 489  | total loss: [1m[32m0.51304[0m[0m | time: 9.529s
[2K
| Adam | epoch: 025 | loss: 0.51304 - acc: 0.7582 -- iter: 288/612
[A[ATraining Step: 490  | total loss: [1m[32m0.50397[0m[0m | time: 10.666s
[2K
| Adam | epoch: 025 | loss: 0.50397 - acc: 0.7667 -- iter: 320/612
[A[ATraining Step: 491  | total loss: [1m[32m0.50456[0m[0m | time: 12.210s
[2K
| Adam | epoch: 025 | loss: 0.50456 - acc: 0.7619 -- iter: 352/612
[A[ATraining Step: 492  | total loss: [1m[32m0.50317[0m[0m | time: 13.837s
[2K
| Adam | epoch: 025 | loss: 0.50317 - acc: 0.7608 -- iter: 384/612
[A[ATraining Step: 493  | total loss: [1m[32m0.51868[0m[0m | time: 15.495s
[2K
| Adam | epoch: 025 | loss: 0.51868 - acc: 0.7347 -- iter: 416/612
[A[ATraining Step: 494  | total loss: [1m[32m0.52433[0m[0m | time: 16.926s
[2K
| Adam | epoch: 025 | loss: 0.52433 - acc: 0.7331 -- iter: 448/612
[A[ATraining Step: 495  | total loss: [1m[32m0.53017[0m[0m | time: 18.062s
[2K
| Adam | epoch: 025 | loss: 0.53017 - acc: 0.7317 -- iter: 480/612
[A[ATraining Step: 496  | total loss: [1m[32m0.51617[0m[0m | time: 19.432s
[2K
| Adam | epoch: 025 | loss: 0.51617 - acc: 0.7460 -- iter: 512/612
[A[ATraining Step: 497  | total loss: [1m[32m0.50712[0m[0m | time: 20.677s
[2K
| Adam | epoch: 025 | loss: 0.50712 - acc: 0.7558 -- iter: 544/612
[A[ATraining Step: 498  | total loss: [1m[32m0.50009[0m[0m | time: 22.035s
[2K
| Adam | epoch: 025 | loss: 0.50009 - acc: 0.7552 -- iter: 576/612
[A[ATraining Step: 499  | total loss: [1m[32m0.51589[0m[0m | time: 23.377s
[2K
| Adam | epoch: 025 | loss: 0.51589 - acc: 0.7422 -- iter: 608/612
[A[ATraining Step: 500  | total loss: [1m[32m0.51215[0m[0m | time: 27.160s
[2K
| Adam | epoch: 025 | loss: 0.51215 - acc: 0.7523 | val_loss: 0.56405 - val_acc: 0.7083 -- iter: 612/612
--
Training Step: 501  | total loss: [1m[32m0.52484[0m[0m | time: 1.685s
[2K
| Adam | epoch: 026 | loss: 0.52484 - acc: 0.7333 -- iter: 032/612
[A[ATraining Step: 502  | total loss: [1m[32m0.51497[0m[0m | time: 2.949s
[2K
| Adam | epoch: 026 | loss: 0.51497 - acc: 0.7413 -- iter: 064/612
[A[ATraining Step: 503  | total loss: [1m[32m0.50786[0m[0m | time: 3.179s
[2K
| Adam | epoch: 026 | loss: 0.50786 - acc: 0.7484 -- iter: 096/612
[A[ATraining Step: 504  | total loss: [1m[32m0.47776[0m[0m | time: 3.324s
[2K
| Adam | epoch: 026 | loss: 0.47776 - acc: 0.7735 -- iter: 128/612
[A[ATraining Step: 505  | total loss: [1m[32m0.44460[0m[0m | time: 4.537s
[2K
| Adam | epoch: 026 | loss: 0.44460 - acc: 0.7962 -- iter: 160/612
[A[ATraining Step: 506  | total loss: [1m[32m0.45703[0m[0m | time: 5.840s
[2K
| Adam | epoch: 026 | loss: 0.45703 - acc: 0.7822 -- iter: 192/612
[A[ATraining Step: 507  | total loss: [1m[32m0.49095[0m[0m | time: 7.067s
[2K
| Adam | epoch: 026 | loss: 0.49095 - acc: 0.7602 -- iter: 224/612
[A[ATraining Step: 508  | total loss: [1m[32m0.51678[0m[0m | time: 8.443s
[2K
| Adam | epoch: 026 | loss: 0.51678 - acc: 0.7342 -- iter: 256/612
[A[ATraining Step: 509  | total loss: [1m[32m0.52215[0m[0m | time: 9.810s
[2K
| Adam | epoch: 026 | loss: 0.52215 - acc: 0.7264 -- iter: 288/612
[A[ATraining Step: 510  | total loss: [1m[32m0.50323[0m[0m | time: 11.209s
[2K
| Adam | epoch: 026 | loss: 0.50323 - acc: 0.7381 -- iter: 320/612
[A[ATraining Step: 511  | total loss: [1m[32m0.50525[0m[0m | time: 12.584s
[2K
| Adam | epoch: 026 | loss: 0.50525 - acc: 0.7393 -- iter: 352/612
[A[ATraining Step: 512  | total loss: [1m[32m0.49900[0m[0m | time: 13.761s
[2K
| Adam | epoch: 026 | loss: 0.49900 - acc: 0.7466 -- iter: 384/612
[A[ATraining Step: 513  | total loss: [1m[32m0.48844[0m[0m | time: 15.310s
[2K
| Adam | epoch: 026 | loss: 0.48844 - acc: 0.7470 -- iter: 416/612
[A[ATraining Step: 514  | total loss: [1m[32m0.51908[0m[0m | time: 16.905s
[2K
| Adam | epoch: 026 | loss: 0.51908 - acc: 0.7317 -- iter: 448/612
[A[ATraining Step: 515  | total loss: [1m[32m0.51632[0m[0m | time: 18.546s
[2K
| Adam | epoch: 026 | loss: 0.51632 - acc: 0.7397 -- iter: 480/612
[A[ATraining Step: 516  | total loss: [1m[32m0.51951[0m[0m | time: 19.980s
[2K
| Adam | epoch: 026 | loss: 0.51951 - acc: 0.7314 -- iter: 512/612
[A[ATraining Step: 517  | total loss: [1m[32m0.50992[0m[0m | time: 21.186s
[2K
| Adam | epoch: 026 | loss: 0.50992 - acc: 0.7395 -- iter: 544/612
[A[ATraining Step: 518  | total loss: [1m[32m0.49622[0m[0m | time: 22.413s
[2K
| Adam | epoch: 026 | loss: 0.49622 - acc: 0.7468 -- iter: 576/612
[A[ATraining Step: 519  | total loss: [1m[32m0.48615[0m[0m | time: 23.668s
[2K
| Adam | epoch: 026 | loss: 0.48615 - acc: 0.7565 -- iter: 608/612
[A[ATraining Step: 520  | total loss: [1m[32m0.48342[0m[0m | time: 26.200s
[2K
| Adam | epoch: 026 | loss: 0.48342 - acc: 0.7621 | val_loss: 0.56423 - val_acc: 0.6823 -- iter: 612/612
--
Training Step: 521  | total loss: [1m[32m0.48332[0m[0m | time: 1.375s
[2K
| Adam | epoch: 027 | loss: 0.48332 - acc: 0.7578 -- iter: 032/612
[A[ATraining Step: 522  | total loss: [1m[32m0.49615[0m[0m | time: 2.727s
[2K
| Adam | epoch: 027 | loss: 0.49615 - acc: 0.7539 -- iter: 064/612
[A[ATraining Step: 523  | total loss: [1m[32m0.48688[0m[0m | time: 4.029s
[2K
| Adam | epoch: 027 | loss: 0.48688 - acc: 0.7660 -- iter: 096/612
[A[ATraining Step: 524  | total loss: [1m[32m0.48831[0m[0m | time: 4.341s
[2K
| Adam | epoch: 027 | loss: 0.48831 - acc: 0.7644 -- iter: 128/612
[A[ATraining Step: 525  | total loss: [1m[32m0.48370[0m[0m | time: 4.636s
[2K
| Adam | epoch: 027 | loss: 0.48370 - acc: 0.7629 -- iter: 160/612
[A[ATraining Step: 526  | total loss: [1m[32m0.47494[0m[0m | time: 6.237s
[2K
| Adam | epoch: 027 | loss: 0.47494 - acc: 0.7866 -- iter: 192/612
[A[ATraining Step: 527  | total loss: [1m[32m0.47493[0m[0m | time: 7.814s
[2K
| Adam | epoch: 027 | loss: 0.47493 - acc: 0.7924 -- iter: 224/612
[A[ATraining Step: 528  | total loss: [1m[32m0.47521[0m[0m | time: 9.347s
[2K
| Adam | epoch: 027 | loss: 0.47521 - acc: 0.7850 -- iter: 256/612
[A[ATraining Step: 529  | total loss: [1m[32m0.46915[0m[0m | time: 10.438s
[2K
| Adam | epoch: 027 | loss: 0.46915 - acc: 0.7877 -- iter: 288/612
[A[ATraining Step: 530  | total loss: [1m[32m0.46176[0m[0m | time: 11.742s
[2K
| Adam | epoch: 027 | loss: 0.46176 - acc: 0.7933 -- iter: 320/612
[A[ATraining Step: 531  | total loss: [1m[32m0.45619[0m[0m | time: 13.038s
[2K
| Adam | epoch: 027 | loss: 0.45619 - acc: 0.7984 -- iter: 352/612
[A[ATraining Step: 532  | total loss: [1m[32m0.44311[0m[0m | time: 14.324s
[2K
| Adam | epoch: 027 | loss: 0.44311 - acc: 0.8092 -- iter: 384/612
[A[ATraining Step: 533  | total loss: [1m[32m0.44270[0m[0m | time: 15.683s
[2K
| Adam | epoch: 027 | loss: 0.44270 - acc: 0.8158 -- iter: 416/612
[A[ATraining Step: 534  | total loss: [1m[32m0.44127[0m[0m | time: 16.965s
[2K
| Adam | epoch: 027 | loss: 0.44127 - acc: 0.8154 -- iter: 448/612
[A[ATraining Step: 535  | total loss: [1m[32m0.43265[0m[0m | time: 18.770s
[2K
| Adam | epoch: 027 | loss: 0.43265 - acc: 0.8183 -- iter: 480/612
[A[ATraining Step: 536  | total loss: [1m[32m0.42969[0m[0m | time: 20.130s
[2K
| Adam | epoch: 027 | loss: 0.42969 - acc: 0.8208 -- iter: 512/612
[A[ATraining Step: 537  | total loss: [1m[32m0.42606[0m[0m | time: 21.274s
[2K
| Adam | epoch: 027 | loss: 0.42606 - acc: 0.8231 -- iter: 544/612
[A[ATraining Step: 538  | total loss: [1m[32m0.41720[0m[0m | time: 22.803s
[2K
| Adam | epoch: 027 | loss: 0.41720 - acc: 0.8314 -- iter: 576/612
[A[ATraining Step: 539  | total loss: [1m[32m0.40881[0m[0m | time: 24.360s
[2K
| Adam | epoch: 027 | loss: 0.40881 - acc: 0.8420 -- iter: 608/612
[A[ATraining Step: 540  | total loss: [1m[32m0.40699[0m[0m | time: 27.224s
[2K
| Adam | epoch: 027 | loss: 0.40699 - acc: 0.8422 | val_loss: 0.53734 - val_acc: 0.7135 -- iter: 612/612
--
Training Step: 541  | total loss: [1m[32m0.40607[0m[0m | time: 1.170s
[2K
| Adam | epoch: 028 | loss: 0.40607 - acc: 0.8361 -- iter: 032/612
[A[ATraining Step: 542  | total loss: [1m[32m0.40530[0m[0m | time: 2.428s
[2K
| Adam | epoch: 028 | loss: 0.40530 - acc: 0.8337 -- iter: 064/612
[A[ATraining Step: 543  | total loss: [1m[32m0.40033[0m[0m | time: 3.696s
[2K
| Adam | epoch: 028 | loss: 0.40033 - acc: 0.8379 -- iter: 096/612
[A[ATraining Step: 544  | total loss: [1m[32m0.39599[0m[0m | time: 5.094s
[2K
| Adam | epoch: 028 | loss: 0.39599 - acc: 0.8416 -- iter: 128/612
[A[ATraining Step: 545  | total loss: [1m[32m0.39961[0m[0m | time: 5.305s
[2K
| Adam | epoch: 028 | loss: 0.39961 - acc: 0.8355 -- iter: 160/612
[A[ATraining Step: 546  | total loss: [1m[32m0.41701[0m[0m | time: 5.476s
[2K
| Adam | epoch: 028 | loss: 0.41701 - acc: 0.8270 -- iter: 192/612
[A[ATraining Step: 547  | total loss: [1m[32m0.42491[0m[0m | time: 6.911s
[2K
| Adam | epoch: 028 | loss: 0.42491 - acc: 0.8193 -- iter: 224/612
[A[ATraining Step: 548  | total loss: [1m[32m0.41737[0m[0m | time: 8.135s
[2K
| Adam | epoch: 028 | loss: 0.41737 - acc: 0.8217 -- iter: 256/612
[A[ATraining Step: 549  | total loss: [1m[32m0.41058[0m[0m | time: 9.619s
[2K
| Adam | epoch: 028 | loss: 0.41058 - acc: 0.8302 -- iter: 288/612
[A[ATraining Step: 550  | total loss: [1m[32m0.41127[0m[0m | time: 11.277s
[2K
| Adam | epoch: 028 | loss: 0.41127 - acc: 0.8347 -- iter: 320/612
[A[ATraining Step: 551  | total loss: [1m[32m0.40666[0m[0m | time: 13.158s
[2K
| Adam | epoch: 028 | loss: 0.40666 - acc: 0.8325 -- iter: 352/612
[A[ATraining Step: 552  | total loss: [1m[32m0.39772[0m[0m | time: 14.677s
[2K
| Adam | epoch: 028 | loss: 0.39772 - acc: 0.8398 -- iter: 384/612
[A[ATraining Step: 553  | total loss: [1m[32m0.40628[0m[0m | time: 15.803s
[2K
| Adam | epoch: 028 | loss: 0.40628 - acc: 0.8340 -- iter: 416/612
[A[ATraining Step: 554  | total loss: [1m[32m0.39597[0m[0m | time: 16.973s
[2K
| Adam | epoch: 028 | loss: 0.39597 - acc: 0.8381 -- iter: 448/612
[A[ATraining Step: 555  | total loss: [1m[32m0.39820[0m[0m | time: 18.225s
[2K
| Adam | epoch: 028 | loss: 0.39820 - acc: 0.8386 -- iter: 480/612
[A[ATraining Step: 556  | total loss: [1m[32m0.42166[0m[0m | time: 19.430s
[2K
| Adam | epoch: 028 | loss: 0.42166 - acc: 0.8235 -- iter: 512/612
[A[ATraining Step: 557  | total loss: [1m[32m0.41148[0m[0m | time: 20.718s
[2K
| Adam | epoch: 028 | loss: 0.41148 - acc: 0.8256 -- iter: 544/612
[A[ATraining Step: 558  | total loss: [1m[32m0.39622[0m[0m | time: 22.174s
[2K
| Adam | epoch: 028 | loss: 0.39622 - acc: 0.8399 -- iter: 576/612
[A[ATraining Step: 559  | total loss: [1m[32m0.41178[0m[0m | time: 23.479s
[2K
| Adam | epoch: 028 | loss: 0.41178 - acc: 0.8340 -- iter: 608/612
[A[ATraining Step: 560  | total loss: [1m[32m0.41070[0m[0m | time: 26.091s
[2K
| Adam | epoch: 028 | loss: 0.41070 - acc: 0.8381 | val_loss: 0.51869 - val_acc: 0.7240 -- iter: 612/612
--
Training Step: 561  | total loss: [1m[32m0.40566[0m[0m | time: 1.546s
[2K
| Adam | epoch: 029 | loss: 0.40566 - acc: 0.8387 -- iter: 032/612
[A[ATraining Step: 562  | total loss: [1m[32m0.40734[0m[0m | time: 3.197s
[2K
| Adam | epoch: 029 | loss: 0.40734 - acc: 0.8361 -- iter: 064/612
[A[ATraining Step: 563  | total loss: [1m[32m0.40238[0m[0m | time: 4.411s
[2K
| Adam | epoch: 029 | loss: 0.40238 - acc: 0.8400 -- iter: 096/612
[A[ATraining Step: 564  | total loss: [1m[32m0.39048[0m[0m | time: 5.606s
[2K
| Adam | epoch: 029 | loss: 0.39048 - acc: 0.8435 -- iter: 128/612
[A[ATraining Step: 565  | total loss: [1m[32m0.39479[0m[0m | time: 7.133s
[2K
| Adam | epoch: 029 | loss: 0.39479 - acc: 0.8372 -- iter: 160/612
[A[ATraining Step: 566  | total loss: [1m[32m0.39370[0m[0m | time: 7.409s
[2K
| Adam | epoch: 029 | loss: 0.39370 - acc: 0.8379 -- iter: 192/612
[A[ATraining Step: 567  | total loss: [1m[32m0.42453[0m[0m | time: 7.711s
[2K
| Adam | epoch: 029 | loss: 0.42453 - acc: 0.8291 -- iter: 224/612
[A[ATraining Step: 568  | total loss: [1m[32m0.44742[0m[0m | time: 8.916s
[2K
| Adam | epoch: 029 | loss: 0.44742 - acc: 0.8212 -- iter: 256/612
[A[ATraining Step: 569  | total loss: [1m[32m0.42986[0m[0m | time: 10.055s
[2K
| Adam | epoch: 029 | loss: 0.42986 - acc: 0.8328 -- iter: 288/612
[A[ATraining Step: 570  | total loss: [1m[32m0.41859[0m[0m | time: 11.507s
[2K
| Adam | epoch: 029 | loss: 0.41859 - acc: 0.8370 -- iter: 320/612
[A[ATraining Step: 571  | total loss: [1m[32m0.40844[0m[0m | time: 13.079s
[2K
| Adam | epoch: 029 | loss: 0.40844 - acc: 0.8471 -- iter: 352/612
[A[ATraining Step: 572  | total loss: [1m[32m0.39953[0m[0m | time: 14.308s
[2K
| Adam | epoch: 029 | loss: 0.39953 - acc: 0.8499 -- iter: 384/612
[A[ATraining Step: 573  | total loss: [1m[32m0.39219[0m[0m | time: 15.462s
[2K
| Adam | epoch: 029 | loss: 0.39219 - acc: 0.8493 -- iter: 416/612
[A[ATraining Step: 574  | total loss: [1m[32m0.37383[0m[0m | time: 16.938s
[2K
| Adam | epoch: 029 | loss: 0.37383 - acc: 0.8643 -- iter: 448/612
[A[ATraining Step: 575  | total loss: [1m[32m0.37311[0m[0m | time: 18.845s
[2K
| Adam | epoch: 029 | loss: 0.37311 - acc: 0.8560 -- iter: 480/612
[A[ATraining Step: 576  | total loss: [1m[32m0.35530[0m[0m | time: 20.444s
[2K
| Adam | epoch: 029 | loss: 0.35530 - acc: 0.8673 -- iter: 512/612
[A[ATraining Step: 577  | total loss: [1m[32m0.35598[0m[0m | time: 21.915s
[2K
| Adam | epoch: 029 | loss: 0.35598 - acc: 0.8681 -- iter: 544/612
[A[ATraining Step: 578  | total loss: [1m[32m0.35029[0m[0m | time: 23.113s
[2K
| Adam | epoch: 029 | loss: 0.35029 - acc: 0.8688 -- iter: 576/612
[A[ATraining Step: 579  | total loss: [1m[32m0.34985[0m[0m | time: 24.459s
[2K
| Adam | epoch: 029 | loss: 0.34985 - acc: 0.8663 -- iter: 608/612
[A[ATraining Step: 580  | total loss: [1m[32m0.34134[0m[0m | time: 27.270s
[2K
| Adam | epoch: 029 | loss: 0.34134 - acc: 0.8765 | val_loss: 0.59999 - val_acc: 0.7500 -- iter: 612/612
--
Training Step: 581  | total loss: [1m[32m0.33247[0m[0m | time: 1.497s
[2K
| Adam | epoch: 030 | loss: 0.33247 - acc: 0.8764 -- iter: 032/612
[A[ATraining Step: 582  | total loss: [1m[32m0.34762[0m[0m | time: 2.801s
[2K
| Adam | epoch: 030 | loss: 0.34762 - acc: 0.8668 -- iter: 064/612
[A[ATraining Step: 583  | total loss: [1m[32m0.35196[0m[0m | time: 4.062s
[2K
| Adam | epoch: 030 | loss: 0.35196 - acc: 0.8645 -- iter: 096/612
[A[ATraining Step: 584  | total loss: [1m[32m0.33905[0m[0m | time: 5.444s
[2K
| Adam | epoch: 030 | loss: 0.33905 - acc: 0.8750 -- iter: 128/612
[A[ATraining Step: 585  | total loss: [1m[32m0.32859[0m[0m | time: 7.171s
[2K
| Adam | epoch: 030 | loss: 0.32859 - acc: 0.8781 -- iter: 160/612
[A[ATraining Step: 586  | total loss: [1m[32m0.31739[0m[0m | time: 8.819s
[2K
| Adam | epoch: 030 | loss: 0.31739 - acc: 0.8872 -- iter: 192/612
[A[ATraining Step: 587  | total loss: [1m[32m0.32654[0m[0m | time: 9.168s
[2K
| Adam | epoch: 030 | loss: 0.32654 - acc: 0.8828 -- iter: 224/612
[A[ATraining Step: 588  | total loss: [1m[32m0.33521[0m[0m | time: 9.387s
[2K
| Adam | epoch: 030 | loss: 0.33521 - acc: 0.8695 -- iter: 256/612
[A[ATraining Step: 589  | total loss: [1m[32m0.34012[0m[0m | time: 11.022s
[2K
| Adam | epoch: 030 | loss: 0.34012 - acc: 0.8576 -- iter: 288/612
[A[ATraining Step: 590  | total loss: [1m[32m0.32840[0m[0m | time: 12.370s
[2K
| Adam | epoch: 030 | loss: 0.32840 - acc: 0.8656 -- iter: 320/612
[A[ATraining Step: 591  | total loss: [1m[32m0.32199[0m[0m | time: 13.562s
[2K
| Adam | epoch: 030 | loss: 0.32199 - acc: 0.8665 -- iter: 352/612
[A[ATraining Step: 592  | total loss: [1m[32m0.31117[0m[0m | time: 14.827s
[2K
| Adam | epoch: 030 | loss: 0.31117 - acc: 0.8705 -- iter: 384/612
[A[ATraining Step: 593  | total loss: [1m[32m0.31145[0m[0m | time: 16.096s
[2K
| Adam | epoch: 030 | loss: 0.31145 - acc: 0.8647 -- iter: 416/612
[A[ATraining Step: 594  | total loss: [1m[32m0.32355[0m[0m | time: 17.449s
[2K
| Adam | epoch: 030 | loss: 0.32355 - acc: 0.8626 -- iter: 448/612
[A[ATraining Step: 595  | total loss: [1m[32m0.31214[0m[0m | time: 18.820s
[2K
| Adam | epoch: 030 | loss: 0.31214 - acc: 0.8701 -- iter: 480/612
[A[ATraining Step: 596  | total loss: [1m[32m0.31529[0m[0m | time: 20.318s
[2K
| Adam | epoch: 030 | loss: 0.31529 - acc: 0.8706 -- iter: 512/612
[A[ATraining Step: 597  | total loss: [1m[32m0.32363[0m[0m | time: 21.473s
[2K
| Adam | epoch: 030 | loss: 0.32363 - acc: 0.8679 -- iter: 544/612
[A[ATraining Step: 598  | total loss: [1m[32m0.32855[0m[0m | time: 22.994s
[2K
| Adam | epoch: 030 | loss: 0.32855 - acc: 0.8686 -- iter: 576/612
[A[ATraining Step: 599  | total loss: [1m[32m0.33294[0m[0m | time: 24.594s
[2K
| Adam | epoch: 030 | loss: 0.33294 - acc: 0.8661 -- iter: 608/612
[A[ATraining Step: 600  | total loss: [1m[32m0.33119[0m[0m | time: 27.655s
[2K
| Adam | epoch: 030 | loss: 0.33119 - acc: 0.8608 | val_loss: 0.53011 - val_acc: 0.7083 -- iter: 612/612
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8258314855875832
Validation AUPRC:0.8600451820179089
Test AUC:0.8472056429734129
Test AUPRC:0.863133776710056
BestTestF1Score	0.77	0.48	0.73	0.68	0.88	85	40	55	12	0.46
BestTestMCCScore	0.77	0.59	0.79	0.86	0.69	67	11	84	30	0.87
BestTestAccuracyScore	0.78	0.56	0.78	0.8	0.76	74	19	76	23	0.76
BestValidationF1Score	0.79	0.45	0.73	0.73	0.85	94	35	47	16	0.46
BestValidationMCC	0.73	0.56	0.74	0.94	0.59	65	4	78	45	0.87
BestValidationAccuracy	0.76	0.52	0.75	0.86	0.67	74	12	70	36	0.76
TestPredictions (Threshold:0.87)
CHEMBL485502,TN,INACT,0.1599999964237213	CHEMBL456760,TN,INACT,0.6000000238418579	CHEMBL214212,TP,ACT,0.9900000095367432	CHEMBL525538,TN,INACT,0.44999998807907104	CHEMBL527039,TN,INACT,0.8199999928474426	CHEMBL238617,TN,INACT,0.3700000047683716	CHEMBL1946328,TP,ACT,0.9800000190734863	CHEMBL1801932,FP,INACT,0.949999988079071	CHEMBL494072,TP,ACT,0.9399999976158142	CHEMBL3623844,TN,INACT,0.14000000059604645	CHEMBL1171955,TN,INACT,0.23000000417232513	CHEMBL2204114,TP,ACT,0.8799999952316284	CHEMBL1644626,TP,ACT,0.9800000190734863	CHEMBL245733,TP,ACT,0.9700000286102295	CHEMBL209534,TP,ACT,0.9800000190734863	CHEMBL209299,TP,ACT,0.9800000190734863	CHEMBL2425640,TP,ACT,0.9100000262260437	CHEMBL1946324,TP,ACT,0.9800000190734863	CHEMBL1288895,FP,INACT,0.8799999952316284	CHEMBL1288966,TN,INACT,0.28999999165534973	CHEMBL1767292,TN,INACT,0.6299999952316284	CHEMBL1801374,TP,ACT,0.9599999785423279	CHEMBL2392837,TP,ACT,0.9800000190734863	CHEMBL86771,TN,INACT,0.10999999940395355	CHEMBL3220492,FN,ACT,0.699999988079071	CHEMBL1288159,TP,ACT,0.9100000262260437	CHEMBL1822144,TP,ACT,0.949999988079071	CHEMBL264667,TN,INACT,0.07999999821186066	CHEMBL2348165,TN,INACT,0.009999999776482582	CHEMBL2425631,FN,ACT,0.8399999737739563	CHEMBL1828884,TN,INACT,0.10000000149011612	CHEMBL2204094,TP,ACT,0.9399999976158142	CHEMBL456964,TN,INACT,0.03999999910593033	CHEMBL102622,TN,INACT,0.25	CHEMBL3665670,TN,INACT,0.7699999809265137	CHEMBL498248,TN,INACT,0.3799999952316284	CHEMBL2151191,TP,ACT,0.9200000166893005	CHEMBL3393605,TP,ACT,0.8899999856948853	CHEMBL266540,TN,INACT,0.07999999821186066	CHEMBL1980140,TP,ACT,0.9200000166893005	CHEMBL941,TP,ACT,0.9399999976158142	CHEMBL3691629,TN,INACT,0.7900000214576721	CHEMBL2163623,TN,INACT,0.25999999046325684	CHEMBL1682002,FN,ACT,0.8100000023841858	CHEMBL518732,TN,INACT,0.6600000262260437	CHEMBL100811,TN,INACT,0.17000000178813934	CHEMBL2420551,FN,ACT,0.7900000214576721	CHEMBL176815,TN,INACT,0.25	CHEMBL55979,TN,INACT,0.18000000715255737	CHEMBL1644623,FN,ACT,0.4099999964237213	CHEMBL1287886,FP,INACT,0.9800000190734863	CHEMBL1288216,TP,ACT,0.9800000190734863	CHEMBL599111,FN,ACT,0.1599999964237213	CHEMBL71884,TN,INACT,0.4099999964237213	CHEMBL38380,TN,INACT,0.2800000011920929	CHEMBL1683952,TN,INACT,0.6200000047683716	CHEMBL1682006,FN,ACT,0.3799999952316284	CHEMBL493708,TP,ACT,0.9700000286102295	CHEMBL1688212,TN,INACT,0.09000000357627869	CHEMBL3661093,TN,INACT,0.6499999761581421	CHEMBL1090089,FN,ACT,0.5	CHEMBL560278,TN,INACT,0.10000000149011612	CHEMBL3577870,TP,ACT,0.9200000166893005	CHEMBL203567,FN,ACT,0.14000000059604645	CHEMBL207228,FN,ACT,0.36000001430511475	CHEMBL453336,FP,INACT,0.9200000166893005	CHEMBL535,TP,ACT,0.9200000166893005	CHEMBL208447,TP,ACT,0.9700000286102295	CHEMBL1801089,FN,ACT,0.6200000047683716	CHEMBL1946339,TP,ACT,0.9200000166893005	CHEMBL475251,TP,ACT,0.9100000262260437	CHEMBL2029519,FP,INACT,0.8999999761581421	CHEMBL3355178,TP,ACT,0.9100000262260437	CHEMBL1784650,TP,ACT,0.9700000286102295	CHEMBL1559959,TN,INACT,0.2199999988079071	CHEMBL2029510,TN,INACT,0.07000000029802322	CHEMBL506669,TN,INACT,0.15000000596046448	CHEMBL2177668,FP,INACT,0.8700000047683716	CHEMBL2425633,TP,ACT,0.9599999785423279	CHEMBL1822145,TP,ACT,0.9800000190734863	CHEMBL1822153,TP,ACT,0.9900000095367432	CHEMBL424418,FN,ACT,0.47999998927116394	CHEMBL1681999,FN,ACT,0.8399999737739563	CHEMBL2151193,TN,INACT,0.8100000023841858	CHEMBL1090090,FN,ACT,0.5299999713897705	CHEMBL1644637,TP,ACT,0.9800000190734863	CHEMBL208433,TN,INACT,0.20000000298023224	CHEMBL569943,FN,ACT,0.5099999904632568	CHEMBL1682005,TP,ACT,0.9300000071525574	CHEMBL1822134,FN,ACT,0.75	CHEMBL525921,TN,INACT,0.3700000047683716	CHEMBL488646,FP,INACT,0.8899999856948853	CHEMBL452812,TN,INACT,0.4099999964237213	CHEMBL209148,TN,INACT,0.8299999833106995	CHEMBL2204108,TP,ACT,0.9599999785423279	CHEMBL2392830,TP,ACT,0.9800000190734863	CHEMBL557237,TN,INACT,0.2800000011920929	CHEMBL1644622,TP,ACT,0.8700000047683716	CHEMBL173453,TN,INACT,0.6000000238418579	CHEMBL3655587,TP,ACT,0.949999988079071	CHEMBL2392831,TP,ACT,0.9700000286102295	CHEMBL2392385,TN,INACT,0.6100000143051147	CHEMBL2163609,TN,INACT,0.47999998927116394	CHEMBL1891423,TN,INACT,0.5400000214576721	CHEMBL2163610,TN,INACT,0.36000001430511475	CHEMBL2425632,TP,ACT,0.9100000262260437	CHEMBL517154,TN,INACT,0.8500000238418579	CHEMBL317281,TN,INACT,0.17000000178813934	CHEMBL2392833,TP,ACT,0.9200000166893005	CHEMBL63135,TP,ACT,0.8899999856948853	CHEMBL2163616,FP,INACT,0.9399999976158142	CHEMBL1946338,TP,ACT,0.9700000286102295	CHEMBL446404,FN,ACT,0.7599999904632568	CHEMBL2163608,FP,INACT,0.9399999976158142	CHEMBL489430,TN,INACT,0.4300000071525574	CHEMBL1644617,TN,INACT,0.27000001072883606	CHEMBL550855,TN,INACT,0.75	CHEMBL1822132,FN,ACT,0.5600000023841858	CHEMBL2392840,TP,ACT,0.8999999761581421	CHEMBL3355174,TP,ACT,0.9300000071525574	CHEMBL2425637,TP,ACT,0.949999988079071	CHEMBL574738,FN,ACT,0.36000001430511475	CHEMBL509499,TN,INACT,0.8199999928474426	CHEMBL515356,TN,INACT,0.14000000059604645	CHEMBL3217784,FN,ACT,0.800000011920929	CHEMBL2204099,TP,ACT,0.9800000190734863	CHEMBL1801388,TP,ACT,0.9700000286102295	CHEMBL261143,TN,INACT,0.15000000596046448	CHEMBL563948,TN,INACT,0.10000000149011612	CHEMBL1779261,TN,INACT,0.05000000074505806	CHEMBL2392827,TP,ACT,0.8999999761581421	CHEMBL226471,TN,INACT,0.33000001311302185	CHEMBL2425646,TP,ACT,0.9800000190734863	CHEMBL210618,TP,ACT,0.9900000095367432	CHEMBL3665663,TN,INACT,0.07000000029802322	CHEMBL1088633,FN,ACT,0.30000001192092896	CHEMBL2392375,TN,INACT,0.03999999910593033	CHEMBL209397,FN,ACT,0.09000000357627869	CHEMBL1922122,TN,INACT,0.2199999988079071	CHEMBL246543,TP,ACT,0.9800000190734863	CHEMBL1644624,TP,ACT,0.9800000190734863	CHEMBL2425630,FN,ACT,0.8199999928474426	CHEMBL285527,TN,INACT,0.12999999523162842	CHEMBL2029523,TN,INACT,0.7400000095367432	CHEMBL101557,TN,INACT,0.3700000047683716	CHEMBL378499,TP,ACT,0.9700000286102295	CHEMBL3577871,TP,ACT,0.9399999976158142	CHEMBL323015,TN,INACT,0.7400000095367432	CHEMBL1644620,TP,ACT,0.9800000190734863	CHEMBL470851,TN,INACT,0.6800000071525574	CHEMBL525530,TN,INACT,0.05999999865889549	CHEMBL3577876,TP,ACT,0.9100000262260437	CHEMBL1688206,TN,INACT,0.30000001192092896	CHEMBL1287975,FP,INACT,0.9700000286102295	CHEMBL328164,TN,INACT,0.18000000715255737	CHEMBL1922121,TN,INACT,0.1599999964237213	CHEMBL2425648,TP,ACT,0.9800000190734863	CHEMBL1767126,FP,INACT,0.8700000047683716	CHEMBL1688214,TN,INACT,0.019999999552965164	CHEMBL1801373,TP,ACT,0.9700000286102295	CHEMBL2392832,TP,ACT,0.9200000166893005	CHEMBL1784646,TN,INACT,0.33000001311302185	CHEMBL1081198,TN,INACT,0.44999998807907104	CHEMBL232599,TP,ACT,0.9599999785423279	CHEMBL1612732,TN,INACT,0.4000000059604645	CHEMBL3655578,TP,ACT,0.8799999952316284	CHEMBL209669,FN,ACT,0.05999999865889549	CHEMBL370808,FN,ACT,0.4000000059604645	CHEMBL3577872,TP,ACT,0.8799999952316284	CHEMBL521201,TN,INACT,0.7599999904632568	CHEMBL3672514,TN,INACT,0.6399999856948853	CHEMBL3220475,FN,ACT,0.47999998927116394	CHEMBL2177830,TN,INACT,0.7300000190734863	CHEMBL492265,TP,ACT,0.9700000286102295	CHEMBL2204109,TP,ACT,0.9599999785423279	CHEMBL490241,TN,INACT,0.7200000286102295	CHEMBL570313,TN,INACT,0.029999999329447746	CHEMBL209082,TP,ACT,0.9800000190734863	CHEMBL303144,FN,ACT,0.7900000214576721	CHEMBL317398,TN,INACT,0.3700000047683716	CHEMBL600828,TN,INACT,0.7599999904632568	CHEMBL55360,TN,INACT,0.3799999952316284	CHEMBL456113,TN,INACT,0.8600000143051147	CHEMBL210032,FN,ACT,0.3499999940395355	CHEMBL603469,FN,ACT,0.6100000143051147	CHEMBL563674,TN,INACT,0.5199999809265137	CHEMBL456143,TN,INACT,0.18000000715255737	CHEMBL3393603,TP,ACT,0.9599999785423279	CHEMBL1288067,TN,INACT,0.550000011920929	CHEMBL460472,TN,INACT,0.5099999904632568	CHEMBL220227,FN,ACT,0.27000001072883606	CHEMBL1801375,TP,ACT,0.9700000286102295	

