CNNModel CHEMBL4068 adam 0.001 15 256 0 0.8 False True
Number of active compounds :	433
Number of inactive compounds :	433
---------------------------------
Run id: CNNModel_CHEMBL4068_adam_0.001_15_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4068_adam_0.001_15_256_0.8_True/
---------------------------------
Training samples: 499
Validation samples: 156
--
Training Step: 1  | time: 26.655s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/499
[A[ATraining Step: 2  | total loss: [1m[32m0.62397[0m[0m | time: 27.738s
[2K
| Adam | epoch: 001 | loss: 0.62397 - acc: 0.3937 -- iter: 064/499
[A[ATraining Step: 3  | total loss: [1m[32m0.67984[0m[0m | time: 28.805s
[2K
| Adam | epoch: 001 | loss: 0.67984 - acc: 0.5318 -- iter: 096/499
[A[ATraining Step: 4  | total loss: [1m[32m0.69938[0m[0m | time: 29.901s
[2K
| Adam | epoch: 001 | loss: 0.69938 - acc: 0.4142 -- iter: 128/499
[A[ATraining Step: 5  | total loss: [1m[32m0.69899[0m[0m | time: 30.950s
[2K
| Adam | epoch: 001 | loss: 0.69899 - acc: 0.3438 -- iter: 160/499
[A[ATraining Step: 6  | total loss: [1m[32m0.69534[0m[0m | time: 32.133s
[2K
| Adam | epoch: 001 | loss: 0.69534 - acc: 0.4040 -- iter: 192/499
[A[ATraining Step: 7  | total loss: [1m[32m0.69389[0m[0m | time: 33.346s
[2K
| Adam | epoch: 001 | loss: 0.69389 - acc: 0.4804 -- iter: 224/499
[A[ATraining Step: 8  | total loss: [1m[32m0.69423[0m[0m | time: 34.322s
[2K
| Adam | epoch: 001 | loss: 0.69423 - acc: 0.4387 -- iter: 256/499
[A[ATraining Step: 9  | total loss: [1m[32m0.69405[0m[0m | time: 35.799s
[2K
| Adam | epoch: 001 | loss: 0.69405 - acc: 0.4381 -- iter: 288/499
[A[ATraining Step: 10  | total loss: [1m[32m0.69349[0m[0m | time: 37.157s
[2K
| Adam | epoch: 001 | loss: 0.69349 - acc: 0.4847 -- iter: 320/499
[A[ATraining Step: 11  | total loss: [1m[32m0.69312[0m[0m | time: 38.310s
[2K
| Adam | epoch: 001 | loss: 0.69312 - acc: 0.5067 -- iter: 352/499
[A[ATraining Step: 12  | total loss: [1m[32m0.69254[0m[0m | time: 44.927s
[2K
| Adam | epoch: 001 | loss: 0.69254 - acc: 0.5459 -- iter: 384/499
[A[ATraining Step: 13  | total loss: [1m[32m0.69170[0m[0m | time: 56.815s
[2K
| Adam | epoch: 001 | loss: 0.69170 - acc: 0.5798 -- iter: 416/499
[A[ATraining Step: 14  | total loss: [1m[32m0.69323[0m[0m | time: 72.569s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.5216 -- iter: 448/499
[A[ATraining Step: 15  | total loss: [1m[32m0.69279[0m[0m | time: 84.686s
[2K
| Adam | epoch: 001 | loss: 0.69279 - acc: 0.5254 -- iter: 480/499
[A[ATraining Step: 16  | total loss: [1m[32m0.69394[0m[0m | time: 86.310s
[2K
| Adam | epoch: 001 | loss: 0.69394 - acc: 0.4924 | val_loss: 0.69228 - val_acc: 0.5256 -- iter: 499/499
--
Training Step: 17  | total loss: [1m[32m0.69265[0m[0m | time: 0.756s
[2K
| Adam | epoch: 002 | loss: 0.69265 - acc: 0.5236 -- iter: 032/499
[A[ATraining Step: 18  | total loss: [1m[32m0.69176[0m[0m | time: 1.811s
[2K
| Adam | epoch: 002 | loss: 0.69176 - acc: 0.5427 -- iter: 064/499
[A[ATraining Step: 19  | total loss: [1m[32m0.69085[0m[0m | time: 2.838s
[2K
| Adam | epoch: 002 | loss: 0.69085 - acc: 0.5597 -- iter: 096/499
[A[ATraining Step: 20  | total loss: [1m[32m0.69160[0m[0m | time: 4.349s
[2K
| Adam | epoch: 002 | loss: 0.69160 - acc: 0.5405 -- iter: 128/499
[A[ATraining Step: 21  | total loss: [1m[32m0.69368[0m[0m | time: 5.456s
[2K
| Adam | epoch: 002 | loss: 0.69368 - acc: 0.5086 -- iter: 160/499
[A[ATraining Step: 22  | total loss: [1m[32m0.69091[0m[0m | time: 16.946s
[2K
| Adam | epoch: 002 | loss: 0.69091 - acc: 0.5435 -- iter: 192/499
[A[ATraining Step: 23  | total loss: [1m[32m0.69186[0m[0m | time: 24.232s
[2K
| Adam | epoch: 002 | loss: 0.69186 - acc: 0.5309 -- iter: 224/499
[A[ATraining Step: 24  | total loss: [1m[32m0.69746[0m[0m | time: 40.224s
[2K
| Adam | epoch: 002 | loss: 0.69746 - acc: 0.4695 -- iter: 256/499
[A[ATraining Step: 25  | total loss: [1m[32m0.69453[0m[0m | time: 48.230s
[2K
| Adam | epoch: 002 | loss: 0.69453 - acc: 0.5034 -- iter: 288/499
[A[ATraining Step: 26  | total loss: [1m[32m0.69297[0m[0m | time: 62.546s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5190 -- iter: 320/499
[A[ATraining Step: 27  | total loss: [1m[32m0.69025[0m[0m | time: 75.903s
[2K
| Adam | epoch: 002 | loss: 0.69025 - acc: 0.5543 -- iter: 352/499
[A[ATraining Step: 28  | total loss: [1m[32m0.69048[0m[0m | time: 88.490s
[2K
| Adam | epoch: 002 | loss: 0.69048 - acc: 0.5485 -- iter: 384/499
[A[ATraining Step: 29  | total loss: [1m[32m0.69257[0m[0m | time: 90.456s
[2K
| Adam | epoch: 002 | loss: 0.69257 - acc: 0.5215 -- iter: 416/499
[A[ATraining Step: 30  | total loss: [1m[32m0.69102[0m[0m | time: 91.424s
[2K
| Adam | epoch: 002 | loss: 0.69102 - acc: 0.5386 -- iter: 448/499
[A[ATraining Step: 31  | total loss: [1m[32m0.69107[0m[0m | time: 92.434s
[2K
| Adam | epoch: 002 | loss: 0.69107 - acc: 0.5369 -- iter: 480/499
[A[ATraining Step: 32  | total loss: [1m[32m0.69127[0m[0m | time: 94.487s
[2K
| Adam | epoch: 002 | loss: 0.69127 - acc: 0.5357 | val_loss: 0.69180 - val_acc: 0.5256 -- iter: 499/499
--
Training Step: 33  | total loss: [1m[32m0.69326[0m[0m | time: 0.897s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5141 -- iter: 032/499
[A[ATraining Step: 34  | total loss: [1m[32m0.69177[0m[0m | time: 1.775s
[2K
| Adam | epoch: 003 | loss: 0.69177 - acc: 0.5280 -- iter: 064/499
[A[ATraining Step: 35  | total loss: [1m[32m0.69062[0m[0m | time: 2.975s
[2K
| Adam | epoch: 003 | loss: 0.69062 - acc: 0.5387 -- iter: 096/499
[A[ATraining Step: 36  | total loss: [1m[32m0.69126[0m[0m | time: 9.537s
[2K
| Adam | epoch: 003 | loss: 0.69126 - acc: 0.5308 -- iter: 128/499
[A[ATraining Step: 37  | total loss: [1m[32m0.68990[0m[0m | time: 14.078s
[2K
| Adam | epoch: 003 | loss: 0.68990 - acc: 0.5434 -- iter: 160/499
[A[ATraining Step: 38  | total loss: [1m[32m0.69160[0m[0m | time: 32.958s
[2K
| Adam | epoch: 003 | loss: 0.69160 - acc: 0.5288 -- iter: 192/499
[A[ATraining Step: 39  | total loss: [1m[32m0.69010[0m[0m | time: 37.054s
[2K
| Adam | epoch: 003 | loss: 0.69010 - acc: 0.5412 -- iter: 224/499
[A[ATraining Step: 40  | total loss: [1m[32m0.69178[0m[0m | time: 46.442s
[2K
| Adam | epoch: 003 | loss: 0.69178 - acc: 0.5276 -- iter: 256/499
[A[ATraining Step: 41  | total loss: [1m[32m0.69311[0m[0m | time: 51.957s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5168 -- iter: 288/499
[A[ATraining Step: 42  | total loss: [1m[32m0.69417[0m[0m | time: 59.735s
[2K
| Adam | epoch: 003 | loss: 0.69417 - acc: 0.5082 -- iter: 320/499
[A[ATraining Step: 43  | total loss: [1m[32m0.69302[0m[0m | time: 60.763s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5177 -- iter: 352/499
[A[ATraining Step: 44  | total loss: [1m[32m0.69337[0m[0m | time: 61.833s
[2K
| Adam | epoch: 003 | loss: 0.69337 - acc: 0.5147 -- iter: 384/499
[A[ATraining Step: 45  | total loss: [1m[32m0.69350[0m[0m | time: 62.974s
[2K
| Adam | epoch: 003 | loss: 0.69350 - acc: 0.5122 -- iter: 416/499
[A[ATraining Step: 46  | total loss: [1m[32m0.69209[0m[0m | time: 64.107s
[2K
| Adam | epoch: 003 | loss: 0.69209 - acc: 0.5258 -- iter: 448/499
[A[ATraining Step: 47  | total loss: [1m[32m0.69238[0m[0m | time: 65.378s
[2K
| Adam | epoch: 003 | loss: 0.69238 - acc: 0.5216 -- iter: 480/499
[A[ATraining Step: 48  | total loss: [1m[32m0.68926[0m[0m | time: 67.492s
[2K
| Adam | epoch: 003 | loss: 0.68926 - acc: 0.5533 | val_loss: 0.69175 - val_acc: 0.5256 -- iter: 499/499
--
Training Step: 49  | total loss: [1m[32m0.68904[0m[0m | time: 1.462s
[2K
| Adam | epoch: 004 | loss: 0.68904 - acc: 0.5547 -- iter: 032/499
[A[ATraining Step: 50  | total loss: [1m[32m0.69164[0m[0m | time: 2.002s
[2K
| Adam | epoch: 004 | loss: 0.69164 - acc: 0.5317 -- iter: 064/499
[A[ATraining Step: 51  | total loss: [1m[32m0.69256[0m[0m | time: 2.660s
[2K
| Adam | epoch: 004 | loss: 0.69256 - acc: 0.5228 -- iter: 096/499
[A[ATraining Step: 52  | total loss: [1m[32m0.69319[0m[0m | time: 3.729s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.5155 -- iter: 128/499
[A[ATraining Step: 53  | total loss: [1m[32m0.69337[0m[0m | time: 4.818s
[2K
| Adam | epoch: 004 | loss: 0.69337 - acc: 0.5132 -- iter: 160/499
[A[ATraining Step: 54  | total loss: [1m[32m0.69433[0m[0m | time: 5.990s
[2K
| Adam | epoch: 004 | loss: 0.69433 - acc: 0.5022 -- iter: 192/499
[A[ATraining Step: 55  | total loss: [1m[32m0.69431[0m[0m | time: 7.149s
[2K
| Adam | epoch: 004 | loss: 0.69431 - acc: 0.5019 -- iter: 224/499
[A[ATraining Step: 56  | total loss: [1m[32m0.69434[0m[0m | time: 8.117s
[2K
| Adam | epoch: 004 | loss: 0.69434 - acc: 0.5016 -- iter: 256/499
[A[ATraining Step: 57  | total loss: [1m[32m0.69227[0m[0m | time: 9.375s
[2K
| Adam | epoch: 004 | loss: 0.69227 - acc: 0.5274 -- iter: 288/499
[A[ATraining Step: 58  | total loss: [1m[32m0.69144[0m[0m | time: 10.632s
[2K
| Adam | epoch: 004 | loss: 0.69144 - acc: 0.5364 -- iter: 320/499
[A[ATraining Step: 59  | total loss: [1m[32m0.69213[0m[0m | time: 11.917s
[2K
| Adam | epoch: 004 | loss: 0.69213 - acc: 0.5273 -- iter: 352/499
[A[ATraining Step: 60  | total loss: [1m[32m0.69169[0m[0m | time: 12.912s
[2K
| Adam | epoch: 004 | loss: 0.69169 - acc: 0.5320 -- iter: 384/499
[A[ATraining Step: 61  | total loss: [1m[32m0.69353[0m[0m | time: 13.940s
[2K
| Adam | epoch: 004 | loss: 0.69353 - acc: 0.5074 -- iter: 416/499
[A[ATraining Step: 62  | total loss: [1m[32m0.69204[0m[0m | time: 15.029s
[2K
| Adam | epoch: 004 | loss: 0.69204 - acc: 0.5266 -- iter: 448/499
[A[ATraining Step: 63  | total loss: [1m[32m0.69225[0m[0m | time: 16.154s
[2K
| Adam | epoch: 004 | loss: 0.69225 - acc: 0.5232 -- iter: 480/499
[A[ATraining Step: 64  | total loss: [1m[32m0.69342[0m[0m | time: 18.453s
[2K
| Adam | epoch: 004 | loss: 0.69342 - acc: 0.5086 | val_loss: 0.69186 - val_acc: 0.5256 -- iter: 499/499
--
Training Step: 65  | total loss: [1m[32m0.69316[0m[0m | time: 1.214s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.5114 -- iter: 032/499
[A[ATraining Step: 66  | total loss: [1m[32m0.69405[0m[0m | time: 2.270s
[2K
| Adam | epoch: 005 | loss: 0.69405 - acc: 0.4986 -- iter: 064/499
[A[ATraining Step: 67  | total loss: [1m[32m0.69245[0m[0m | time: 2.671s
[2K
| Adam | epoch: 005 | loss: 0.69245 - acc: 0.5213 -- iter: 096/499
[A[ATraining Step: 68  | total loss: [1m[32m0.69104[0m[0m | time: 3.090s
[2K
| Adam | epoch: 005 | loss: 0.69104 - acc: 0.5406 -- iter: 128/499
[A[ATraining Step: 69  | total loss: [1m[32m0.68976[0m[0m | time: 3.730s
[2K
| Adam | epoch: 005 | loss: 0.68976 - acc: 0.5573 -- iter: 160/499
[A[ATraining Step: 70  | total loss: [1m[32m0.68993[0m[0m | time: 4.428s
[2K
| Adam | epoch: 005 | loss: 0.68993 - acc: 0.5543 -- iter: 192/499
[A[ATraining Step: 71  | total loss: [1m[32m0.69007[0m[0m | time: 5.082s
[2K
| Adam | epoch: 005 | loss: 0.69007 - acc: 0.5517 -- iter: 224/499
[A[ATraining Step: 72  | total loss: [1m[32m0.69149[0m[0m | time: 5.781s
[2K
| Adam | epoch: 005 | loss: 0.69149 - acc: 0.5353 -- iter: 256/499
[A[ATraining Step: 73  | total loss: [1m[32m0.69109[0m[0m | time: 6.424s
[2K
| Adam | epoch: 005 | loss: 0.69109 - acc: 0.5384 -- iter: 288/499
[A[ATraining Step: 74  | total loss: [1m[32m0.69104[0m[0m | time: 7.081s
[2K
| Adam | epoch: 005 | loss: 0.69104 - acc: 0.5376 -- iter: 320/499
[A[ATraining Step: 75  | total loss: [1m[32m0.69068[0m[0m | time: 7.721s
[2K
| Adam | epoch: 005 | loss: 0.69068 - acc: 0.5403 -- iter: 352/499
[A[ATraining Step: 76  | total loss: [1m[32m0.69005[0m[0m | time: 8.394s
[2K
| Adam | epoch: 005 | loss: 0.69005 - acc: 0.5460 -- iter: 384/499
[A[ATraining Step: 77  | total loss: [1m[32m0.69012[0m[0m | time: 9.055s
[2K
| Adam | epoch: 005 | loss: 0.69012 - acc: 0.5444 -- iter: 416/499
[A[ATraining Step: 78  | total loss: [1m[32m0.69212[0m[0m | time: 9.713s
[2K
| Adam | epoch: 005 | loss: 0.69212 - acc: 0.5267 -- iter: 448/499
[A[ATraining Step: 79  | total loss: [1m[32m0.69272[0m[0m | time: 10.406s
[2K
| Adam | epoch: 005 | loss: 0.69272 - acc: 0.5207 -- iter: 480/499
[A[ATraining Step: 80  | total loss: [1m[32m0.69328[0m[0m | time: 12.062s
[2K
| Adam | epoch: 005 | loss: 0.69328 - acc: 0.5154 | val_loss: 0.69162 - val_acc: 0.5256 -- iter: 499/499
--
Training Step: 81  | total loss: [1m[32m0.69269[0m[0m | time: 0.668s
[2K
| Adam | epoch: 006 | loss: 0.69269 - acc: 0.5202 -- iter: 032/499
[A[ATraining Step: 82  | total loss: [1m[32m0.69117[0m[0m | time: 1.324s
[2K
| Adam | epoch: 006 | loss: 0.69117 - acc: 0.5338 -- iter: 064/499
[A[ATraining Step: 83  | total loss: [1m[32m0.69075[0m[0m | time: 1.982s
[2K
| Adam | epoch: 006 | loss: 0.69075 - acc: 0.5366 -- iter: 096/499
[A[ATraining Step: 84  | total loss: [1m[32m0.69007[0m[0m | time: 2.377s
[2K
| Adam | epoch: 006 | loss: 0.69007 - acc: 0.5424 -- iter: 128/499
[A[ATraining Step: 85  | total loss: [1m[32m0.69141[0m[0m | time: 2.771s
[2K
| Adam | epoch: 006 | loss: 0.69141 - acc: 0.5302 -- iter: 160/499
[A[ATraining Step: 86  | total loss: [1m[32m0.69266[0m[0m | time: 3.453s
[2K
| Adam | epoch: 006 | loss: 0.69266 - acc: 0.5193 -- iter: 192/499
[A[ATraining Step: 87  | total loss: [1m[32m0.69322[0m[0m | time: 4.132s
[2K
| Adam | epoch: 006 | loss: 0.69322 - acc: 0.5143 -- iter: 224/499
[A[ATraining Step: 88  | total loss: [1m[32m0.69155[0m[0m | time: 4.788s
[2K
| Adam | epoch: 006 | loss: 0.69155 - acc: 0.5285 -- iter: 256/499
[A[ATraining Step: 89  | total loss: [1m[32m0.69152[0m[0m | time: 5.457s
[2K
| Adam | epoch: 006 | loss: 0.69152 - acc: 0.5287 -- iter: 288/499
[A[ATraining Step: 90  | total loss: [1m[32m0.69137[0m[0m | time: 6.128s
[2K
| Adam | epoch: 006 | loss: 0.69137 - acc: 0.5290 -- iter: 320/499
[A[ATraining Step: 91  | total loss: [1m[32m0.69397[0m[0m | time: 6.794s
[2K
| Adam | epoch: 006 | loss: 0.69397 - acc: 0.5073 -- iter: 352/499
[A[ATraining Step: 92  | total loss: [1m[32m0.69477[0m[0m | time: 7.512s
[2K
| Adam | epoch: 006 | loss: 0.69477 - acc: 0.5004 -- iter: 384/499
[A[ATraining Step: 93  | total loss: [1m[32m0.69470[0m[0m | time: 8.276s
[2K
| Adam | epoch: 006 | loss: 0.69470 - acc: 0.5003 -- iter: 416/499
[A[ATraining Step: 94  | total loss: [1m[32m0.69348[0m[0m | time: 8.943s
[2K
| Adam | epoch: 006 | loss: 0.69348 - acc: 0.5128 -- iter: 448/499
[A[ATraining Step: 95  | total loss: [1m[32m0.69296[0m[0m | time: 9.645s
[2K
| Adam | epoch: 006 | loss: 0.69296 - acc: 0.5178 -- iter: 480/499
[A[ATraining Step: 96  | total loss: [1m[32m0.69216[0m[0m | time: 11.362s
[2K
| Adam | epoch: 006 | loss: 0.69216 - acc: 0.5254 | val_loss: 0.69140 - val_acc: 0.5256 -- iter: 499/499
--
Training Step: 97  | total loss: [1m[32m0.69266[0m[0m | time: 0.673s
[2K
| Adam | epoch: 007 | loss: 0.69266 - acc: 0.5197 -- iter: 032/499
[A[ATraining Step: 98  | total loss: [1m[32m0.69083[0m[0m | time: 1.509s
[2K
| Adam | epoch: 007 | loss: 0.69083 - acc: 0.5396 -- iter: 064/499
[A[ATraining Step: 99  | total loss: [1m[32m0.69230[0m[0m | time: 2.986s
[2K
| Adam | epoch: 007 | loss: 0.69230 - acc: 0.5231 -- iter: 096/499
[A[ATraining Step: 100  | total loss: [1m[32m0.69132[0m[0m | time: 4.262s
[2K
| Adam | epoch: 007 | loss: 0.69132 - acc: 0.5333 -- iter: 128/499
[A[ATraining Step: 101  | total loss: [1m[32m0.69250[0m[0m | time: 4.953s
[2K
| Adam | epoch: 007 | loss: 0.69250 - acc: 0.5206 -- iter: 160/499
[A[ATraining Step: 102  | total loss: [1m[32m0.69127[0m[0m | time: 5.613s
[2K
| Adam | epoch: 007 | loss: 0.69127 - acc: 0.5317 -- iter: 192/499
[A[ATraining Step: 103  | total loss: [1m[32m0.69009[0m[0m | time: 6.565s
[2K
| Adam | epoch: 007 | loss: 0.69009 - acc: 0.5417 -- iter: 224/499
[A[ATraining Step: 104  | total loss: [1m[32m0.68968[0m[0m | time: 7.590s
[2K
| Adam | epoch: 007 | loss: 0.68968 - acc: 0.5438 -- iter: 256/499
[A[ATraining Step: 105  | total loss: [1m[32m0.68873[0m[0m | time: 8.566s
[2K
| Adam | epoch: 007 | loss: 0.68873 - acc: 0.5488 -- iter: 288/499
[A[ATraining Step: 106  | total loss: [1m[32m0.68916[0m[0m | time: 9.628s
[2K
| Adam | epoch: 007 | loss: 0.68916 - acc: 0.5439 -- iter: 320/499
[A[ATraining Step: 107  | total loss: [1m[32m0.69071[0m[0m | time: 10.759s
[2K
| Adam | epoch: 007 | loss: 0.69071 - acc: 0.5301 -- iter: 352/499
[A[ATraining Step: 108  | total loss: [1m[32m0.68995[0m[0m | time: 11.923s
[2K
| Adam | epoch: 007 | loss: 0.68995 - acc: 0.5334 -- iter: 384/499
[A[ATraining Step: 109  | total loss: [1m[32m0.68927[0m[0m | time: 12.909s
[2K
| Adam | epoch: 007 | loss: 0.68927 - acc: 0.5394 -- iter: 416/499
[A[ATraining Step: 110  | total loss: [1m[32m0.68882[0m[0m | time: 14.301s
[2K
| Adam | epoch: 007 | loss: 0.68882 - acc: 0.5448 -- iter: 448/499
[A[ATraining Step: 111  | total loss: [1m[32m0.68961[0m[0m | time: 15.487s
[2K
| Adam | epoch: 007 | loss: 0.68961 - acc: 0.5341 -- iter: 480/499
[A[ATraining Step: 112  | total loss: [1m[32m0.68833[0m[0m | time: 17.453s
[2K
| Adam | epoch: 007 | loss: 0.68833 - acc: 0.5369 | val_loss: 0.68162 - val_acc: 0.5256 -- iter: 499/499
--
Training Step: 113  | total loss: [1m[32m0.68602[0m[0m | time: 0.979s
[2K
| Adam | epoch: 008 | loss: 0.68602 - acc: 0.5426 -- iter: 032/499
[A[ATraining Step: 114  | total loss: [1m[32m0.68563[0m[0m | time: 2.323s
[2K
| Adam | epoch: 008 | loss: 0.68563 - acc: 0.5415 -- iter: 064/499
[A[ATraining Step: 115  | total loss: [1m[32m0.68752[0m[0m | time: 3.579s
[2K
| Adam | epoch: 008 | loss: 0.68752 - acc: 0.5342 -- iter: 096/499
[A[ATraining Step: 116  | total loss: [1m[32m0.68618[0m[0m | time: 4.765s
[2K
| Adam | epoch: 008 | loss: 0.68618 - acc: 0.5464 -- iter: 128/499
[A[ATraining Step: 117  | total loss: [1m[32m0.68597[0m[0m | time: 5.698s
[2K
| Adam | epoch: 008 | loss: 0.68597 - acc: 0.5449 -- iter: 160/499
[A[ATraining Step: 118  | total loss: [1m[32m0.68659[0m[0m | time: 6.357s
[2K
| Adam | epoch: 008 | loss: 0.68659 - acc: 0.5404 -- iter: 192/499
[A[ATraining Step: 119  | total loss: [1m[32m0.68701[0m[0m | time: 7.018s
[2K
| Adam | epoch: 008 | loss: 0.68701 - acc: 0.5337 -- iter: 224/499
[A[ATraining Step: 120  | total loss: [1m[32m0.68730[0m[0m | time: 8.046s
[2K
| Adam | epoch: 008 | loss: 0.68730 - acc: 0.5330 -- iter: 256/499
[A[ATraining Step: 121  | total loss: [1m[32m0.68363[0m[0m | time: 9.227s
[2K
| Adam | epoch: 008 | loss: 0.68363 - acc: 0.5422 -- iter: 288/499
[A[ATraining Step: 122  | total loss: [1m[32m0.68363[0m[0m | time: 10.350s
[2K
| Adam | epoch: 008 | loss: 0.68363 - acc: 0.5380 -- iter: 320/499
[A[ATraining Step: 123  | total loss: [1m[32m0.67976[0m[0m | time: 11.344s
[2K
| Adam | epoch: 008 | loss: 0.67976 - acc: 0.5467 -- iter: 352/499
[A[ATraining Step: 124  | total loss: [1m[32m0.67663[0m[0m | time: 12.766s
[2K
| Adam | epoch: 008 | loss: 0.67663 - acc: 0.5545 -- iter: 384/499
[A[ATraining Step: 125  | total loss: [1m[32m0.67201[0m[0m | time: 14.055s
[2K
| Adam | epoch: 008 | loss: 0.67201 - acc: 0.5678 -- iter: 416/499
[A[ATraining Step: 126  | total loss: [1m[32m0.66551[0m[0m | time: 21.753s
[2K
| Adam | epoch: 008 | loss: 0.66551 - acc: 0.5860 -- iter: 448/499
[A[ATraining Step: 127  | total loss: [1m[32m0.65646[0m[0m | time: 26.985s
[2K
| Adam | epoch: 008 | loss: 0.65646 - acc: 0.6056 -- iter: 480/499
[A[ATraining Step: 128  | total loss: [1m[32m0.65426[0m[0m | time: 51.401s
[2K
| Adam | epoch: 008 | loss: 0.65426 - acc: 0.6169 | val_loss: 0.66594 - val_acc: 0.5833 -- iter: 499/499
--
Training Step: 129  | total loss: [1m[32m0.64810[0m[0m | time: 1.183s
[2K
| Adam | epoch: 009 | loss: 0.64810 - acc: 0.6208 -- iter: 032/499
[A[ATraining Step: 130  | total loss: [1m[32m0.63775[0m[0m | time: 2.129s
[2K
| Adam | epoch: 009 | loss: 0.63775 - acc: 0.6337 -- iter: 064/499
[A[ATraining Step: 131  | total loss: [1m[32m0.62990[0m[0m | time: 3.458s
[2K
| Adam | epoch: 009 | loss: 0.62990 - acc: 0.6360 -- iter: 096/499
[A[ATraining Step: 132  | total loss: [1m[32m0.64395[0m[0m | time: 4.762s
[2K
| Adam | epoch: 009 | loss: 0.64395 - acc: 0.6286 -- iter: 128/499
[A[ATraining Step: 133  | total loss: [1m[32m0.64158[0m[0m | time: 5.948s
[2K
| Adam | epoch: 009 | loss: 0.64158 - acc: 0.6439 -- iter: 160/499
[A[ATraining Step: 134  | total loss: [1m[32m0.63420[0m[0m | time: 7.475s
[2K
| Adam | epoch: 009 | loss: 0.63420 - acc: 0.6576 -- iter: 192/499
[A[ATraining Step: 135  | total loss: [1m[32m0.63936[0m[0m | time: 14.627s
[2K
| Adam | epoch: 009 | loss: 0.63936 - acc: 0.6544 -- iter: 224/499
[A[ATraining Step: 136  | total loss: [1m[32m0.62110[0m[0m | time: 15.221s
[2K
| Adam | epoch: 009 | loss: 0.62110 - acc: 0.6679 -- iter: 256/499
[A[ATraining Step: 137  | total loss: [1m[32m0.61340[0m[0m | time: 16.307s
[2K
| Adam | epoch: 009 | loss: 0.61340 - acc: 0.6748 -- iter: 288/499
[A[ATraining Step: 138  | total loss: [1m[32m0.62473[0m[0m | time: 17.325s
[2K
| Adam | epoch: 009 | loss: 0.62473 - acc: 0.6667 -- iter: 320/499
[A[ATraining Step: 139  | total loss: [1m[32m0.61492[0m[0m | time: 18.341s
[2K
| Adam | epoch: 009 | loss: 0.61492 - acc: 0.6781 -- iter: 352/499
[A[ATraining Step: 140  | total loss: [1m[32m0.60989[0m[0m | time: 19.478s
[2K
| Adam | epoch: 009 | loss: 0.60989 - acc: 0.6791 -- iter: 384/499
[A[ATraining Step: 141  | total loss: [1m[32m0.60781[0m[0m | time: 20.643s
[2K
| Adam | epoch: 009 | loss: 0.60781 - acc: 0.6768 -- iter: 416/499
[A[ATraining Step: 142  | total loss: [1m[32m0.60950[0m[0m | time: 21.620s
[2K
| Adam | epoch: 009 | loss: 0.60950 - acc: 0.6779 -- iter: 448/499
[A[ATraining Step: 143  | total loss: [1m[32m0.60460[0m[0m | time: 23.029s
[2K
| Adam | epoch: 009 | loss: 0.60460 - acc: 0.6819 -- iter: 480/499
[A[ATraining Step: 144  | total loss: [1m[32m0.60284[0m[0m | time: 47.434s
[2K
| Adam | epoch: 009 | loss: 0.60284 - acc: 0.6856 | val_loss: 0.60987 - val_acc: 0.6795 -- iter: 499/499
--
Training Step: 145  | total loss: [1m[32m0.59391[0m[0m | time: 11.496s
[2K
| Adam | epoch: 010 | loss: 0.59391 - acc: 0.6952 -- iter: 032/499
[A[ATraining Step: 146  | total loss: [1m[32m0.58515[0m[0m | time: 22.748s
[2K
| Adam | epoch: 010 | loss: 0.58515 - acc: 0.7069 -- iter: 064/499
[A[ATraining Step: 147  | total loss: [1m[32m0.58684[0m[0m | time: 23.730s
[2K
| Adam | epoch: 010 | loss: 0.58684 - acc: 0.7081 -- iter: 096/499
[A[ATraining Step: 148  | total loss: [1m[32m0.58367[0m[0m | time: 24.869s
[2K
| Adam | epoch: 010 | loss: 0.58367 - acc: 0.7092 -- iter: 128/499
[A[ATraining Step: 149  | total loss: [1m[32m0.57925[0m[0m | time: 25.915s
[2K
| Adam | epoch: 010 | loss: 0.57925 - acc: 0.7101 -- iter: 160/499
[A[ATraining Step: 150  | total loss: [1m[32m0.57457[0m[0m | time: 26.978s
[2K
| Adam | epoch: 010 | loss: 0.57457 - acc: 0.7141 -- iter: 192/499
[A[ATraining Step: 151  | total loss: [1m[32m0.55924[0m[0m | time: 28.057s
[2K
| Adam | epoch: 010 | loss: 0.55924 - acc: 0.7302 -- iter: 224/499
[A[ATraining Step: 152  | total loss: [1m[32m0.56067[0m[0m | time: 28.676s
[2K
| Adam | epoch: 010 | loss: 0.56067 - acc: 0.7322 -- iter: 256/499
[A[ATraining Step: 153  | total loss: [1m[32m0.54214[0m[0m | time: 29.236s
[2K
| Adam | epoch: 010 | loss: 0.54214 - acc: 0.7432 -- iter: 288/499
[A[ATraining Step: 154  | total loss: [1m[32m0.52322[0m[0m | time: 30.497s
[2K
| Adam | epoch: 010 | loss: 0.52322 - acc: 0.7583 -- iter: 320/499
[A[ATraining Step: 155  | total loss: [1m[32m0.50581[0m[0m | time: 31.772s
[2K
| Adam | epoch: 010 | loss: 0.50581 - acc: 0.7700 -- iter: 352/499
[A[ATraining Step: 156  | total loss: [1m[32m0.48635[0m[0m | time: 33.024s
[2K
| Adam | epoch: 010 | loss: 0.48635 - acc: 0.7774 -- iter: 384/499
[A[ATraining Step: 157  | total loss: [1m[32m0.48860[0m[0m | time: 37.518s
[2K
| Adam | epoch: 010 | loss: 0.48860 - acc: 0.7715 -- iter: 416/499
[A[ATraining Step: 158  | total loss: [1m[32m0.46913[0m[0m | time: 43.903s
[2K
| Adam | epoch: 010 | loss: 0.46913 - acc: 0.7850 -- iter: 448/499
[A[ATraining Step: 159  | total loss: [1m[32m0.46964[0m[0m | time: 53.460s
[2K
| Adam | epoch: 010 | loss: 0.46964 - acc: 0.7909 -- iter: 480/499
[A[ATraining Step: 160  | total loss: [1m[32m0.45948[0m[0m | time: 59.995s
[2K
| Adam | epoch: 010 | loss: 0.45948 - acc: 0.7930 | val_loss: 0.65814 - val_acc: 0.7244 -- iter: 499/499
--
Training Step: 161  | total loss: [1m[32m0.48565[0m[0m | time: 1.439s
[2K
| Adam | epoch: 011 | loss: 0.48565 - acc: 0.7825 -- iter: 032/499
[A[ATraining Step: 162  | total loss: [1m[32m0.50054[0m[0m | time: 2.874s
[2K
| Adam | epoch: 011 | loss: 0.50054 - acc: 0.7699 -- iter: 064/499
[A[ATraining Step: 163  | total loss: [1m[32m0.49459[0m[0m | time: 15.802s
[2K
| Adam | epoch: 011 | loss: 0.49459 - acc: 0.7710 -- iter: 096/499
[A[ATraining Step: 164  | total loss: [1m[32m0.48576[0m[0m | time: 22.219s
[2K
| Adam | epoch: 011 | loss: 0.48576 - acc: 0.7751 -- iter: 128/499
[A[ATraining Step: 165  | total loss: [1m[32m0.47252[0m[0m | time: 32.469s
[2K
| Adam | epoch: 011 | loss: 0.47252 - acc: 0.7914 -- iter: 160/499
[A[ATraining Step: 166  | total loss: [1m[32m0.47759[0m[0m | time: 37.528s
[2K
| Adam | epoch: 011 | loss: 0.47759 - acc: 0.7841 -- iter: 192/499
[A[ATraining Step: 167  | total loss: [1m[32m0.50559[0m[0m | time: 39.747s
[2K
| Adam | epoch: 011 | loss: 0.50559 - acc: 0.7682 -- iter: 224/499
[A[ATraining Step: 168  | total loss: [1m[32m0.50050[0m[0m | time: 40.547s
[2K
| Adam | epoch: 011 | loss: 0.50050 - acc: 0.7633 -- iter: 256/499
[A[ATraining Step: 169  | total loss: [1m[32m0.49025[0m[0m | time: 41.117s
[2K
| Adam | epoch: 011 | loss: 0.49025 - acc: 0.7682 -- iter: 288/499
[A[ATraining Step: 170  | total loss: [1m[32m0.48962[0m[0m | time: 41.766s
[2K
| Adam | epoch: 011 | loss: 0.48962 - acc: 0.7650 -- iter: 320/499
[A[ATraining Step: 171  | total loss: [1m[32m0.48327[0m[0m | time: 42.785s
[2K
| Adam | epoch: 011 | loss: 0.48327 - acc: 0.7675 -- iter: 352/499
[A[ATraining Step: 172  | total loss: [1m[32m0.48078[0m[0m | time: 43.885s
[2K
| Adam | epoch: 011 | loss: 0.48078 - acc: 0.7626 -- iter: 384/499
[A[ATraining Step: 173  | total loss: [1m[32m0.47568[0m[0m | time: 45.076s
[2K
| Adam | epoch: 011 | loss: 0.47568 - acc: 0.7582 -- iter: 416/499
[A[ATraining Step: 174  | total loss: [1m[32m0.46198[0m[0m | time: 46.258s
[2K
| Adam | epoch: 011 | loss: 0.46198 - acc: 0.7730 -- iter: 448/499
[A[ATraining Step: 175  | total loss: [1m[32m0.44377[0m[0m | time: 47.120s
[2K
| Adam | epoch: 011 | loss: 0.44377 - acc: 0.7864 -- iter: 480/499
[A[ATraining Step: 176  | total loss: [1m[32m0.43453[0m[0m | time: 49.718s
[2K
| Adam | epoch: 011 | loss: 0.43453 - acc: 0.7952 | val_loss: 0.57332 - val_acc: 0.7179 -- iter: 499/499
--
Training Step: 177  | total loss: [1m[32m0.42574[0m[0m | time: 3.496s
[2K
| Adam | epoch: 012 | loss: 0.42574 - acc: 0.7938 -- iter: 032/499
[A[ATraining Step: 178  | total loss: [1m[32m0.42613[0m[0m | time: 15.585s
[2K
| Adam | epoch: 012 | loss: 0.42613 - acc: 0.7957 -- iter: 064/499
[A[ATraining Step: 179  | total loss: [1m[32m0.41687[0m[0m | time: 18.857s
[2K
| Adam | epoch: 012 | loss: 0.41687 - acc: 0.8005 -- iter: 096/499
[A[ATraining Step: 180  | total loss: [1m[32m0.41249[0m[0m | time: 19.856s
[2K
| Adam | epoch: 012 | loss: 0.41249 - acc: 0.7954 -- iter: 128/499
[A[ATraining Step: 181  | total loss: [1m[32m0.39737[0m[0m | time: 20.958s
[2K
| Adam | epoch: 012 | loss: 0.39737 - acc: 0.8034 -- iter: 160/499
[A[ATraining Step: 182  | total loss: [1m[32m0.39482[0m[0m | time: 21.977s
[2K
| Adam | epoch: 012 | loss: 0.39482 - acc: 0.7981 -- iter: 192/499
[A[ATraining Step: 183  | total loss: [1m[32m0.38348[0m[0m | time: 23.075s
[2K
| Adam | epoch: 012 | loss: 0.38348 - acc: 0.8026 -- iter: 224/499
[A[ATraining Step: 184  | total loss: [1m[32m0.37152[0m[0m | time: 24.196s
[2K
| Adam | epoch: 012 | loss: 0.37152 - acc: 0.8130 -- iter: 256/499
[A[ATraining Step: 185  | total loss: [1m[32m0.35816[0m[0m | time: 25.205s
[2K
| Adam | epoch: 012 | loss: 0.35816 - acc: 0.8254 -- iter: 288/499
[A[ATraining Step: 186  | total loss: [1m[32m0.36812[0m[0m | time: 25.948s
[2K
| Adam | epoch: 012 | loss: 0.36812 - acc: 0.8210 -- iter: 320/499
[A[ATraining Step: 187  | total loss: [1m[32m0.36956[0m[0m | time: 26.703s
[2K
| Adam | epoch: 012 | loss: 0.36956 - acc: 0.8284 -- iter: 352/499
[A[ATraining Step: 188  | total loss: [1m[32m0.36743[0m[0m | time: 27.783s
[2K
| Adam | epoch: 012 | loss: 0.36743 - acc: 0.8298 -- iter: 384/499
[A[ATraining Step: 189  | total loss: [1m[32m0.41026[0m[0m | time: 28.967s
[2K
| Adam | epoch: 012 | loss: 0.41026 - acc: 0.8218 -- iter: 416/499
[A[ATraining Step: 190  | total loss: [1m[32m0.38675[0m[0m | time: 30.042s
[2K
| Adam | epoch: 012 | loss: 0.38675 - acc: 0.8334 -- iter: 448/499
[A[ATraining Step: 191  | total loss: [1m[32m0.36471[0m[0m | time: 30.727s
[2K
| Adam | epoch: 012 | loss: 0.36471 - acc: 0.8438 -- iter: 480/499
[A[ATraining Step: 192  | total loss: [1m[32m0.35198[0m[0m | time: 32.424s
[2K
| Adam | epoch: 012 | loss: 0.35198 - acc: 0.8469 | val_loss: 0.44781 - val_acc: 0.7949 -- iter: 499/499
--
Training Step: 193  | total loss: [1m[32m0.35344[0m[0m | time: 0.673s
[2K
| Adam | epoch: 013 | loss: 0.35344 - acc: 0.8435 -- iter: 032/499
[A[ATraining Step: 194  | total loss: [1m[32m0.34503[0m[0m | time: 1.349s
[2K
| Adam | epoch: 013 | loss: 0.34503 - acc: 0.8466 -- iter: 064/499
[A[ATraining Step: 195  | total loss: [1m[32m0.34755[0m[0m | time: 2.026s
[2K
| Adam | epoch: 013 | loss: 0.34755 - acc: 0.8432 -- iter: 096/499
[A[ATraining Step: 196  | total loss: [1m[32m0.35376[0m[0m | time: 2.695s
[2K
| Adam | epoch: 013 | loss: 0.35376 - acc: 0.8433 -- iter: 128/499
[A[ATraining Step: 197  | total loss: [1m[32m0.34494[0m[0m | time: 3.427s
[2K
| Adam | epoch: 013 | loss: 0.34494 - acc: 0.8527 -- iter: 160/499
[A[ATraining Step: 198  | total loss: [1m[32m0.33452[0m[0m | time: 4.121s
[2K
| Adam | epoch: 013 | loss: 0.33452 - acc: 0.8549 -- iter: 192/499
[A[ATraining Step: 199  | total loss: [1m[32m0.35146[0m[0m | time: 4.825s
[2K
| Adam | epoch: 013 | loss: 0.35146 - acc: 0.8413 -- iter: 224/499
[A[ATraining Step: 200  | total loss: [1m[32m0.35613[0m[0m | time: 6.522s
[2K
| Adam | epoch: 013 | loss: 0.35613 - acc: 0.8384 | val_loss: 0.46447 - val_acc: 0.8141 -- iter: 256/499
--
Training Step: 201  | total loss: [1m[32m0.33595[0m[0m | time: 7.192s
[2K
| Adam | epoch: 013 | loss: 0.33595 - acc: 0.8514 -- iter: 288/499
[A[ATraining Step: 202  | total loss: [1m[32m0.32180[0m[0m | time: 7.902s
[2K
| Adam | epoch: 013 | loss: 0.32180 - acc: 0.8601 -- iter: 320/499
[A[ATraining Step: 203  | total loss: [1m[32m0.30366[0m[0m | time: 8.320s
[2K
| Adam | epoch: 013 | loss: 0.30366 - acc: 0.8709 -- iter: 352/499
[A[ATraining Step: 204  | total loss: [1m[32m0.29614[0m[0m | time: 8.726s
[2K
| Adam | epoch: 013 | loss: 0.29614 - acc: 0.8733 -- iter: 384/499
[A[ATraining Step: 205  | total loss: [1m[32m0.29109[0m[0m | time: 9.414s
[2K
| Adam | epoch: 013 | loss: 0.29109 - acc: 0.8754 -- iter: 416/499
[A[ATraining Step: 206  | total loss: [1m[32m0.34224[0m[0m | time: 10.116s
[2K
| Adam | epoch: 013 | loss: 0.34224 - acc: 0.8567 -- iter: 448/499
[A[ATraining Step: 207  | total loss: [1m[32m0.32653[0m[0m | time: 10.922s
[2K
| Adam | epoch: 013 | loss: 0.32653 - acc: 0.8647 -- iter: 480/499
[A[ATraining Step: 208  | total loss: [1m[32m0.30448[0m[0m | time: 13.390s
[2K
| Adam | epoch: 013 | loss: 0.30448 - acc: 0.8783 | val_loss: 0.51603 - val_acc: 0.7885 -- iter: 499/499
--
Training Step: 209  | total loss: [1m[32m0.30122[0m[0m | time: 5.045s
[2K
| Adam | epoch: 014 | loss: 0.30122 - acc: 0.8811 -- iter: 032/499
[A[ATraining Step: 210  | total loss: [1m[32m0.28593[0m[0m | time: 6.034s
[2K
| Adam | epoch: 014 | loss: 0.28593 - acc: 0.8836 -- iter: 064/499
[A[ATraining Step: 211  | total loss: [1m[32m0.27401[0m[0m | time: 7.110s
[2K
| Adam | epoch: 014 | loss: 0.27401 - acc: 0.8858 -- iter: 096/499
[A[ATraining Step: 212  | total loss: [1m[32m0.25790[0m[0m | time: 8.162s
[2K
| Adam | epoch: 014 | loss: 0.25790 - acc: 0.8973 -- iter: 128/499
[A[ATraining Step: 213  | total loss: [1m[32m0.25149[0m[0m | time: 9.217s
[2K
| Adam | epoch: 014 | loss: 0.25149 - acc: 0.9013 -- iter: 160/499
[A[ATraining Step: 214  | total loss: [1m[32m0.24017[0m[0m | time: 10.315s
[2K
| Adam | epoch: 014 | loss: 0.24017 - acc: 0.9080 -- iter: 192/499
[A[ATraining Step: 215  | total loss: [1m[32m0.24279[0m[0m | time: 11.270s
[2K
| Adam | epoch: 014 | loss: 0.24279 - acc: 0.9047 -- iter: 224/499
[A[ATraining Step: 216  | total loss: [1m[32m0.23242[0m[0m | time: 12.360s
[2K
| Adam | epoch: 014 | loss: 0.23242 - acc: 0.9143 -- iter: 256/499
[A[ATraining Step: 217  | total loss: [1m[32m0.23976[0m[0m | time: 13.675s
[2K
| Adam | epoch: 014 | loss: 0.23976 - acc: 0.9135 -- iter: 288/499
[A[ATraining Step: 218  | total loss: [1m[32m0.24551[0m[0m | time: 14.960s
[2K
| Adam | epoch: 014 | loss: 0.24551 - acc: 0.9096 -- iter: 320/499
[A[ATraining Step: 219  | total loss: [1m[32m0.23555[0m[0m | time: 15.871s
[2K
| Adam | epoch: 014 | loss: 0.23555 - acc: 0.9155 -- iter: 352/499
[A[ATraining Step: 220  | total loss: [1m[32m0.22706[0m[0m | time: 16.496s
[2K
| Adam | epoch: 014 | loss: 0.22706 - acc: 0.9177 -- iter: 384/499
[A[ATraining Step: 221  | total loss: [1m[32m0.22915[0m[0m | time: 17.187s
[2K
| Adam | epoch: 014 | loss: 0.22915 - acc: 0.9154 -- iter: 416/499
[A[ATraining Step: 222  | total loss: [1m[32m0.22669[0m[0m | time: 18.253s
[2K
| Adam | epoch: 014 | loss: 0.22669 - acc: 0.9134 -- iter: 448/499
[A[ATraining Step: 223  | total loss: [1m[32m0.23653[0m[0m | time: 19.326s
[2K
| Adam | epoch: 014 | loss: 0.23653 - acc: 0.9126 -- iter: 480/499
[A[ATraining Step: 224  | total loss: [1m[32m0.22817[0m[0m | time: 21.706s
[2K
| Adam | epoch: 014 | loss: 0.22817 - acc: 0.9151 | val_loss: 0.50948 - val_acc: 0.7821 -- iter: 499/499
--
Training Step: 225  | total loss: [1m[32m0.23387[0m[0m | time: 0.924s
[2K
| Adam | epoch: 015 | loss: 0.23387 - acc: 0.9111 -- iter: 032/499
[A[ATraining Step: 226  | total loss: [1m[32m0.22198[0m[0m | time: 1.951s
[2K
| Adam | epoch: 015 | loss: 0.22198 - acc: 0.9138 -- iter: 064/499
[A[ATraining Step: 227  | total loss: [1m[32m0.20924[0m[0m | time: 2.908s
[2K
| Adam | epoch: 015 | loss: 0.20924 - acc: 0.9193 -- iter: 096/499
[A[ATraining Step: 228  | total loss: [1m[32m0.19940[0m[0m | time: 4.028s
[2K
| Adam | epoch: 015 | loss: 0.19940 - acc: 0.9242 -- iter: 128/499
[A[ATraining Step: 229  | total loss: [1m[32m0.18816[0m[0m | time: 5.019s
[2K
| Adam | epoch: 015 | loss: 0.18816 - acc: 0.9318 -- iter: 160/499
[A[ATraining Step: 230  | total loss: [1m[32m0.18724[0m[0m | time: 6.148s
[2K
| Adam | epoch: 015 | loss: 0.18724 - acc: 0.9324 -- iter: 192/499
[A[ATraining Step: 231  | total loss: [1m[32m0.18518[0m[0m | time: 7.570s
[2K
| Adam | epoch: 015 | loss: 0.18518 - acc: 0.9329 -- iter: 224/499
[A[ATraining Step: 232  | total loss: [1m[32m0.21008[0m[0m | time: 8.674s
[2K
| Adam | epoch: 015 | loss: 0.21008 - acc: 0.9208 -- iter: 256/499
[A[ATraining Step: 233  | total loss: [1m[32m0.23284[0m[0m | time: 9.575s
[2K
| Adam | epoch: 015 | loss: 0.23284 - acc: 0.9069 -- iter: 288/499
[A[ATraining Step: 234  | total loss: [1m[32m0.22197[0m[0m | time: 10.547s
[2K
| Adam | epoch: 015 | loss: 0.22197 - acc: 0.9099 -- iter: 320/499
[A[ATraining Step: 235  | total loss: [1m[32m0.22858[0m[0m | time: 11.480s
[2K
| Adam | epoch: 015 | loss: 0.22858 - acc: 0.9064 -- iter: 352/499
[A[ATraining Step: 236  | total loss: [1m[32m0.24652[0m[0m | time: 12.530s
[2K
| Adam | epoch: 015 | loss: 0.24652 - acc: 0.9002 -- iter: 384/499
[A[ATraining Step: 237  | total loss: [1m[32m0.23665[0m[0m | time: 13.184s
[2K
| Adam | epoch: 015 | loss: 0.23665 - acc: 0.8977 -- iter: 416/499
[A[ATraining Step: 238  | total loss: [1m[32m0.21935[0m[0m | time: 13.823s
[2K
| Adam | epoch: 015 | loss: 0.21935 - acc: 0.9079 -- iter: 448/499
[A[ATraining Step: 239  | total loss: [1m[32m0.20955[0m[0m | time: 14.885s
[2K
| Adam | epoch: 015 | loss: 0.20955 - acc: 0.9171 -- iter: 480/499
[A[ATraining Step: 240  | total loss: [1m[32m0.20065[0m[0m | time: 17.386s
[2K
| Adam | epoch: 015 | loss: 0.20065 - acc: 0.9223 | val_loss: 0.45458 - val_acc: 0.8269 -- iter: 499/499
--
Validation AUC:0.9058998022412657
Validation AUPRC:0.9077592074472145
Test AUC:0.9262566137566138
Test AUPRC:0.9015492166846938
BestTestF1Score	0.86	0.74	0.86	0.78	0.97	70	20	64	2	0.15
BestTestMCCScore	0.86	0.74	0.86	0.78	0.97	70	20	64	2	0.15
BestTestAccuracyScore	0.85	0.71	0.85	0.78	0.93	67	19	65	5	0.28
BestValidationF1Score	0.84	0.67	0.83	0.76	0.93	69	22	60	5	0.15
BestValidationMCC	0.84	0.67	0.83	0.76	0.93	69	22	60	5	0.15
BestValidationAccuracy	0.83	0.67	0.83	0.8	0.86	64	16	66	10	0.28
TestPredictions (Threshold:0.15)
CHEMBL3099882,FP,INACT,0.699999988079071	CHEMBL396302,TP,ACT,0.9700000286102295	CHEMBL245930,TP,ACT,0.9700000286102295	CHEMBL172873,TP,ACT,0.9700000286102295	CHEMBL40764,FP,INACT,0.9700000286102295	CHEMBL391804,TN,INACT,0.019999999552965164	CHEMBL2159286,TN,INACT,0.009999999776482582	CHEMBL3640092,TP,ACT,0.9900000095367432	CHEMBL2159294,TN,INACT,0.019999999552965164	CHEMBL3639389,TP,ACT,0.9900000095367432	CHEMBL507281,TN,INACT,0.0	CHEMBL24734,TP,ACT,0.9900000095367432	CHEMBL312329,TP,ACT,0.9100000262260437	CHEMBL25199,TP,ACT,0.9800000190734863	CHEMBL3640118,TP,ACT,0.9900000095367432	CHEMBL60776,TP,ACT,0.7900000214576721	CHEMBL391543,TP,ACT,0.9800000190734863	CHEMBL222314,TP,ACT,0.9800000190734863	CHEMBL1807526,TP,ACT,0.9900000095367432	CHEMBL350114,TN,INACT,0.07999999821186066	CHEMBL304838,TP,ACT,0.8799999952316284	CHEMBL3653523,TP,ACT,0.6700000166893005	CHEMBL132617,TP,ACT,0.7900000214576721	CHEMBL512935,TN,INACT,0.0	CHEMBL539993,TN,INACT,0.029999999329447746	CHEMBL412452,TP,ACT,0.9200000166893005	CHEMBL247185,TP,ACT,0.9900000095367432	CHEMBL24071,TP,ACT,0.9800000190734863	CHEMBL304753,FP,INACT,0.4300000071525574	CHEMBL3143648,TN,INACT,0.0	CHEMBL291397,TP,ACT,0.9100000262260437	CHEMBL2372514,TN,INACT,0.0	CHEMBL3653515,TP,ACT,0.8500000238418579	CHEMBL305800,TP,ACT,0.7699999809265137	CHEMBL279270,TN,INACT,0.0	CHEMBL1392763,TN,INACT,0.14000000059604645	CHEMBL339878,FP,INACT,0.4099999964237213	CHEMBL96428,TN,INACT,0.009999999776482582	CHEMBL247168,TP,ACT,0.9900000095367432	CHEMBL3651443,TP,ACT,0.23000000417232513	CHEMBL3653525,FN,ACT,0.03999999910593033	CHEMBL1313808,FP,INACT,0.25999999046325684	CHEMBL3640117,TP,ACT,0.9700000286102295	CHEMBL2372455,TN,INACT,0.07000000029802322	CHEMBL3657204,TP,ACT,0.9300000071525574	CHEMBL424453,TP,ACT,1.0	CHEMBL69677,TP,ACT,0.9700000286102295	CHEMBL1462676,FP,INACT,0.9900000095367432	CHEMBL2159302,TN,INACT,0.07999999821186066	CHEMBL599036,TN,INACT,0.0	CHEMBL296941,TN,INACT,0.10999999940395355	CHEMBL567893,TP,ACT,0.1899999976158142	CHEMBL2182018,TN,INACT,0.019999999552965164	CHEMBL2397004,TP,ACT,0.9900000095367432	CHEMBL507020,TN,INACT,0.0	CHEMBL307172,TP,ACT,0.9800000190734863	CHEMBL3099870,FP,INACT,0.9900000095367432	CHEMBL373899,TP,ACT,0.9100000262260437	CHEMBL2372678,TN,INACT,0.009999999776482582	CHEMBL294067,TN,INACT,0.07999999821186066	CHEMBL27305,TN,INACT,0.0	CHEMBL311482,TN,INACT,0.0	CHEMBL25699,FP,INACT,0.9800000190734863	CHEMBL395822,TP,ACT,0.9700000286102295	CHEMBL284495,TP,ACT,1.0	CHEMBL352917,TP,ACT,0.9900000095367432	CHEMBL461629,TN,INACT,0.0	CHEMBL1339887,FP,INACT,0.9200000166893005	CHEMBL263977,TN,INACT,0.0	CHEMBL96493,TN,INACT,0.029999999329447746	CHEMBL395683,TP,ACT,0.9900000095367432	CHEMBL2381492,TN,INACT,0.019999999552965164	CHEMBL111643,TN,INACT,0.0	CHEMBL374027,TP,ACT,0.699999988079071	CHEMBL2381489,TN,INACT,0.03999999910593033	CHEMBL292834,TP,ACT,0.9300000071525574	CHEMBL373439,TP,ACT,0.9800000190734863	CHEMBL296771,TP,ACT,0.75	CHEMBL493118,TN,INACT,0.0	CHEMBL48604,TN,INACT,0.0	CHEMBL3780584,FP,INACT,0.9100000262260437	CHEMBL2381481,TP,ACT,1.0	CHEMBL2159283,TN,INACT,0.0	CHEMBL396333,TP,ACT,0.9300000071525574	CHEMBL212401,TN,INACT,0.0	CHEMBL1160813,TN,INACT,0.0	CHEMBL1160263,FP,INACT,0.9900000095367432	CHEMBL1348562,FP,INACT,0.6499999761581421	CHEMBL379194,TN,INACT,0.0	CHEMBL19594,TN,INACT,0.0	CHEMBL448786,TN,INACT,0.0	CHEMBL3640106,TP,ACT,0.9900000095367432	CHEMBL2087344,FP,INACT,0.5600000023841858	CHEMBL2087345,FP,INACT,0.5	CHEMBL433079,TN,INACT,0.05000000074505806	CHEMBL1834754,FP,INACT,0.3400000035762787	CHEMBL373846,TP,ACT,0.949999988079071	CHEMBL3640119,TP,ACT,0.9700000286102295	CHEMBL303871,TP,ACT,0.9700000286102295	CHEMBL3408419,TN,INACT,0.07000000029802322	CHEMBL3691801,TP,ACT,0.9900000095367432	CHEMBL1451569,FP,INACT,0.33000001311302185	CHEMBL3640115,TP,ACT,0.1599999964237213	CHEMBL1788242,TN,INACT,0.0	CHEMBL3640110,TP,ACT,0.9900000095367432	CHEMBL17712,TN,INACT,0.019999999552965164	CHEMBL1807537,TP,ACT,0.9599999785423279	CHEMBL111400,TN,INACT,0.019999999552965164	CHEMBL3653520,TP,ACT,0.75	CHEMBL23999,TP,ACT,0.9900000095367432	CHEMBL26171,TP,ACT,0.9900000095367432	CHEMBL287318,TP,ACT,1.0	CHEMBL519886,TN,INACT,0.0	CHEMBL171119,TP,ACT,1.0	CHEMBL373916,TP,ACT,0.8600000143051147	CHEMBL26285,TP,ACT,0.9900000095367432	CHEMBL1468612,FP,INACT,0.5099999904632568	CHEMBL498640,TN,INACT,0.019999999552965164	CHEMBL345710,TN,INACT,0.009999999776482582	CHEMBL246964,TP,ACT,0.9900000095367432	CHEMBL3423011,TN,INACT,0.0	CHEMBL25833,TP,ACT,1.0	CHEMBL46148,TN,INACT,0.03999999910593033	CHEMBL3653519,TP,ACT,0.4300000071525574	CHEMBL1571193,FP,INACT,0.28999999165534973	CHEMBL3640109,TP,ACT,0.9900000095367432	CHEMBL302387,TP,ACT,0.9800000190734863	CHEMBL110645,TN,INACT,0.0	CHEMBL131521,TN,INACT,0.0	CHEMBL2397007,TP,ACT,0.9300000071525574	CHEMBL3653521,TP,ACT,0.8999999761581421	CHEMBL2372746,TN,INACT,0.0	CHEMBL1501309,TN,INACT,0.009999999776482582	CHEMBL3099874,FP,INACT,0.949999988079071	CHEMBL3125570,TN,INACT,0.05000000074505806	CHEMBL2381479,FN,ACT,0.0	CHEMBL213216,TN,INACT,0.009999999776482582	CHEMBL2396919,TP,ACT,0.9900000095367432	CHEMBL66504,TP,ACT,0.9200000166893005	CHEMBL134440,TN,INACT,0.10000000149011612	CHEMBL3640094,TP,ACT,0.9800000190734863	CHEMBL427751,TN,INACT,0.0	CHEMBL3653518,TP,ACT,0.9900000095367432	CHEMBL2417904,TN,INACT,0.12999999523162842	CHEMBL265586,TN,INACT,0.05000000074505806	CHEMBL3247193,TN,INACT,0.0	CHEMBL566340,TN,INACT,0.019999999552965164	CHEMBL484615,TN,INACT,0.0	CHEMBL1340445,TN,INACT,0.03999999910593033	CHEMBL423149,FP,INACT,0.44999998807907104	CHEMBL49757,TN,INACT,0.0	CHEMBL214356,TN,INACT,0.009999999776482582	CHEMBL338615,TN,INACT,0.009999999776482582	CHEMBL147013,TP,ACT,0.5600000023841858	CHEMBL424036,TN,INACT,0.12999999523162842	CHEMBL2396996,TP,ACT,0.7599999904632568	

