ImageNetInceptionV2 CHEMBL3746 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	100
Number of inactive compounds :	100
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3746_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3746_adam_0.001_15_0.8/
---------------------------------
Training samples: 128
Validation samples: 40
--
Training Step: 1  | time: 36.430s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/128
[A[ATraining Step: 2  | total loss: [1m[32m0.71545[0m[0m | time: 44.544s
[2K
| Adam | epoch: 001 | loss: 0.71545 - acc: 0.1969 -- iter: 064/128
[A[ATraining Step: 3  | total loss: [1m[32m1.25239[0m[0m | time: 52.451s
[2K
| Adam | epoch: 001 | loss: 1.25239 - acc: 0.4193 -- iter: 096/128
[A[ATraining Step: 4  | total loss: [1m[32m1.11183[0m[0m | time: 67.841s
[2K
| Adam | epoch: 001 | loss: 1.11183 - acc: 0.4564 | val_loss: 1.90166 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 5  | total loss: [1m[32m0.79066[0m[0m | time: 8.020s
[2K
| Adam | epoch: 002 | loss: 0.79066 - acc: 0.5948 -- iter: 032/128
[A[ATraining Step: 6  | total loss: [1m[32m0.48550[0m[0m | time: 15.885s
[2K
| Adam | epoch: 002 | loss: 0.48550 - acc: 0.7950 -- iter: 064/128
[A[ATraining Step: 7  | total loss: [1m[32m0.40998[0m[0m | time: 23.920s
[2K
| Adam | epoch: 002 | loss: 0.40998 - acc: 0.8805 -- iter: 096/128
[A[ATraining Step: 8  | total loss: [1m[32m0.57371[0m[0m | time: 33.584s
[2K
| Adam | epoch: 002 | loss: 0.57371 - acc: 0.8071 | val_loss: 2.09351 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 9  | total loss: [1m[32m0.46162[0m[0m | time: 7.830s
[2K
| Adam | epoch: 003 | loss: 0.46162 - acc: 0.8430 -- iter: 032/128
[A[ATraining Step: 10  | total loss: [1m[32m0.39787[0m[0m | time: 15.635s
[2K
| Adam | epoch: 003 | loss: 0.39787 - acc: 0.8746 -- iter: 064/128
[A[ATraining Step: 11  | total loss: [1m[32m0.31915[0m[0m | time: 23.410s
[2K
| Adam | epoch: 003 | loss: 0.31915 - acc: 0.9044 -- iter: 096/128
[A[ATraining Step: 12  | total loss: [1m[32m0.35779[0m[0m | time: 33.158s
[2K
| Adam | epoch: 003 | loss: 0.35779 - acc: 0.8631 | val_loss: 2.35846 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 13  | total loss: [1m[32m0.26525[0m[0m | time: 7.956s
[2K
| Adam | epoch: 004 | loss: 0.26525 - acc: 0.8816 -- iter: 032/128
[A[ATraining Step: 14  | total loss: [1m[32m0.19579[0m[0m | time: 15.787s
[2K
| Adam | epoch: 004 | loss: 0.19579 - acc: 0.9300 -- iter: 064/128
[A[ATraining Step: 15  | total loss: [1m[32m0.15697[0m[0m | time: 23.601s
[2K
| Adam | epoch: 004 | loss: 0.15697 - acc: 0.9452 -- iter: 096/128
[A[ATraining Step: 16  | total loss: [1m[32m0.11012[0m[0m | time: 33.368s
[2K
| Adam | epoch: 004 | loss: 0.11012 - acc: 0.9657 | val_loss: 2.14258 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 17  | total loss: [1m[32m0.12829[0m[0m | time: 8.226s
[2K
| Adam | epoch: 005 | loss: 0.12829 - acc: 0.9556 -- iter: 032/128
[A[ATraining Step: 18  | total loss: [1m[32m0.09399[0m[0m | time: 16.113s
[2K
| Adam | epoch: 005 | loss: 0.09399 - acc: 0.9709 -- iter: 064/128
[A[ATraining Step: 19  | total loss: [1m[32m0.08570[0m[0m | time: 23.799s
[2K
| Adam | epoch: 005 | loss: 0.08570 - acc: 0.9702 -- iter: 096/128
[A[ATraining Step: 20  | total loss: [1m[32m0.14611[0m[0m | time: 33.489s
[2K
| Adam | epoch: 005 | loss: 0.14611 - acc: 0.9396 | val_loss: 2.97321 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 21  | total loss: [1m[32m0.12302[0m[0m | time: 7.833s
[2K
| Adam | epoch: 006 | loss: 0.12302 - acc: 0.9584 -- iter: 032/128
[A[ATraining Step: 22  | total loss: [1m[32m0.21530[0m[0m | time: 15.591s
[2K
| Adam | epoch: 006 | loss: 0.21530 - acc: 0.9240 -- iter: 064/128
[A[ATraining Step: 23  | total loss: [1m[32m0.21168[0m[0m | time: 23.535s
[2K
| Adam | epoch: 006 | loss: 0.21168 - acc: 0.9279 -- iter: 096/128
[A[ATraining Step: 24  | total loss: [1m[32m0.19338[0m[0m | time: 33.173s
[2K
| Adam | epoch: 006 | loss: 0.19338 - acc: 0.9306 | val_loss: 4.88947 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 25  | total loss: [1m[32m0.22260[0m[0m | time: 7.844s
[2K
| Adam | epoch: 007 | loss: 0.22260 - acc: 0.9069 -- iter: 032/128
[A[ATraining Step: 26  | total loss: [1m[32m0.19137[0m[0m | time: 15.794s
[2K
| Adam | epoch: 007 | loss: 0.19137 - acc: 0.9316 -- iter: 064/128
[A[ATraining Step: 27  | total loss: [1m[32m0.18358[0m[0m | time: 23.804s
[2K
| Adam | epoch: 007 | loss: 0.18358 - acc: 0.9170 -- iter: 096/128
[A[ATraining Step: 28  | total loss: [1m[32m0.14459[0m[0m | time: 33.409s
[2K
| Adam | epoch: 007 | loss: 0.14459 - acc: 0.9378 | val_loss: 6.82520 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 29  | total loss: [1m[32m0.12248[0m[0m | time: 7.895s
[2K
| Adam | epoch: 008 | loss: 0.12248 - acc: 0.9529 -- iter: 032/128
[A[ATraining Step: 30  | total loss: [1m[32m0.10601[0m[0m | time: 15.682s
[2K
| Adam | epoch: 008 | loss: 0.10601 - acc: 0.9641 -- iter: 064/128
[A[ATraining Step: 31  | total loss: [1m[32m0.08276[0m[0m | time: 23.566s
[2K
| Adam | epoch: 008 | loss: 0.08276 - acc: 0.9723 -- iter: 096/128
[A[ATraining Step: 32  | total loss: [1m[32m0.21247[0m[0m | time: 33.210s
[2K
| Adam | epoch: 008 | loss: 0.21247 - acc: 0.9504 | val_loss: 6.88546 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 33  | total loss: [1m[32m0.22240[0m[0m | time: 7.828s
[2K
| Adam | epoch: 009 | loss: 0.22240 - acc: 0.9407 -- iter: 032/128
[A[ATraining Step: 34  | total loss: [1m[32m0.24365[0m[0m | time: 15.677s
[2K
| Adam | epoch: 009 | loss: 0.24365 - acc: 0.9267 -- iter: 064/128
[A[ATraining Step: 35  | total loss: [1m[32m0.23063[0m[0m | time: 23.343s
[2K
| Adam | epoch: 009 | loss: 0.23063 - acc: 0.9289 -- iter: 096/128
[A[ATraining Step: 36  | total loss: [1m[32m0.19424[0m[0m | time: 32.975s
[2K
| Adam | epoch: 009 | loss: 0.19424 - acc: 0.9435 | val_loss: 8.02679 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 37  | total loss: [1m[32m0.16650[0m[0m | time: 7.996s
[2K
| Adam | epoch: 010 | loss: 0.16650 - acc: 0.9485 -- iter: 032/128
[A[ATraining Step: 38  | total loss: [1m[32m0.16427[0m[0m | time: 15.722s
[2K
| Adam | epoch: 010 | loss: 0.16427 - acc: 0.9525 -- iter: 064/128
[A[ATraining Step: 39  | total loss: [1m[32m0.13859[0m[0m | time: 23.440s
[2K
| Adam | epoch: 010 | loss: 0.13859 - acc: 0.9616 -- iter: 096/128
[A[ATraining Step: 40  | total loss: [1m[32m0.12131[0m[0m | time: 33.009s
[2K
| Adam | epoch: 010 | loss: 0.12131 - acc: 0.9688 | val_loss: 7.97928 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 41  | total loss: [1m[32m0.10287[0m[0m | time: 7.857s
[2K
| Adam | epoch: 011 | loss: 0.10287 - acc: 0.9745 -- iter: 032/128
[A[ATraining Step: 42  | total loss: [1m[32m0.08630[0m[0m | time: 15.533s
[2K
| Adam | epoch: 011 | loss: 0.08630 - acc: 0.9791 -- iter: 064/128
[A[ATraining Step: 43  | total loss: [1m[32m0.07598[0m[0m | time: 23.322s
[2K
| Adam | epoch: 011 | loss: 0.07598 - acc: 0.9828 -- iter: 096/128
[A[ATraining Step: 44  | total loss: [1m[32m0.07957[0m[0m | time: 32.852s
[2K
| Adam | epoch: 011 | loss: 0.07957 - acc: 0.9804 | val_loss: 7.58770 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 45  | total loss: [1m[32m0.07995[0m[0m | time: 7.843s
[2K
| Adam | epoch: 012 | loss: 0.07995 - acc: 0.9837 -- iter: 032/128
[A[ATraining Step: 46  | total loss: [1m[32m0.06818[0m[0m | time: 15.490s
[2K
| Adam | epoch: 012 | loss: 0.06818 - acc: 0.9864 -- iter: 064/128
[A[ATraining Step: 47  | total loss: [1m[32m0.06420[0m[0m | time: 23.411s
[2K
| Adam | epoch: 012 | loss: 0.06420 - acc: 0.9835 -- iter: 096/128
[A[ATraining Step: 48  | total loss: [1m[32m0.13130[0m[0m | time: 33.118s
[2K
| Adam | epoch: 012 | loss: 0.13130 - acc: 0.9761 | val_loss: 6.26167 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 49  | total loss: [1m[32m0.11223[0m[0m | time: 7.806s
[2K
| Adam | epoch: 013 | loss: 0.11223 - acc: 0.9799 -- iter: 032/128
[A[ATraining Step: 50  | total loss: [1m[32m0.11844[0m[0m | time: 15.581s
[2K
| Adam | epoch: 013 | loss: 0.11844 - acc: 0.9733 -- iter: 064/128
[A[ATraining Step: 51  | total loss: [1m[32m0.10652[0m[0m | time: 23.543s
[2K
| Adam | epoch: 013 | loss: 0.10652 - acc: 0.9726 -- iter: 096/128
[A[ATraining Step: 52  | total loss: [1m[32m0.12904[0m[0m | time: 33.266s
[2K
| Adam | epoch: 013 | loss: 0.12904 - acc: 0.9720 | val_loss: 2.27715 - val_acc: 0.6500 -- iter: 128/128
--
Training Step: 53  | total loss: [1m[32m0.13691[0m[0m | time: 7.791s
[2K
| Adam | epoch: 014 | loss: 0.13691 - acc: 0.9669 -- iter: 032/128
[A[ATraining Step: 54  | total loss: [1m[32m0.12245[0m[0m | time: 15.519s
[2K
| Adam | epoch: 014 | loss: 0.12245 - acc: 0.9717 -- iter: 064/128
[A[ATraining Step: 55  | total loss: [1m[32m0.12351[0m[0m | time: 23.274s
[2K
| Adam | epoch: 014 | loss: 0.12351 - acc: 0.9669 -- iter: 096/128
[A[ATraining Step: 56  | total loss: [1m[32m0.11189[0m[0m | time: 33.016s
[2K
| Adam | epoch: 014 | loss: 0.11189 - acc: 0.9715 | val_loss: 1.44147 - val_acc: 0.6750 -- iter: 128/128
--
Training Step: 57  | total loss: [1m[32m0.13544[0m[0m | time: 7.792s
[2K
| Adam | epoch: 015 | loss: 0.13544 - acc: 0.9668 -- iter: 032/128
[A[ATraining Step: 58  | total loss: [1m[32m0.12690[0m[0m | time: 15.640s
[2K
| Adam | epoch: 015 | loss: 0.12690 - acc: 0.9671 -- iter: 064/128
[A[ATraining Step: 59  | total loss: [1m[32m0.12120[0m[0m | time: 23.356s
[2K
| Adam | epoch: 015 | loss: 0.12120 - acc: 0.9715 -- iter: 096/128
[A[ATraining Step: 60  | total loss: [1m[32m0.12147[0m[0m | time: 32.916s
[2K
| Adam | epoch: 015 | loss: 0.12147 - acc: 0.9711 | val_loss: 2.43350 - val_acc: 0.5500 -- iter: 128/128
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7095959595959597
Validation AUPRC:0.6576750826483932
Test AUC:0.8644501278772379
Test AUPRC:0.9090422349929743
BestTestF1Score	0.69	0.56	0.72	1.0	0.52	12	0	17	11	0.01
BestTestMCCScore	0.56	0.46	0.65	1.0	0.39	9	0	17	14	0.03
BestTestAccuracyScore	0.56	0.46	0.65	1.0	0.39	9	0	17	14	0.03
BestValidationF1Score	0.56	0.28	0.65	0.64	0.5	9	5	17	9	0.01
BestValidationMCC	0.46	0.3	0.65	0.75	0.33	6	2	20	12	0.03
BestValidationAccuracy	0.46	0.3	0.65	0.75	0.33	6	2	20	12	0.03
TestPredictions (Threshold:0.03)
CHEMBL425022,TN,INACT,0.0	CHEMBL376293,TN,INACT,0.0	CHEMBL219606,TN,INACT,0.0	CHEMBL402552,TP,ACT,0.03999999910593033	CHEMBL1269273,FN,ACT,0.029999999329447746	CHEMBL200513,FN,ACT,0.0	CHEMBL2380648,FN,ACT,0.0	CHEMBL2023587,FN,ACT,0.0	CHEMBL219028,TN,INACT,0.0	CHEMBL380677,FN,ACT,0.0	CHEMBL240504,TN,INACT,0.0	CHEMBL276915,TN,INACT,0.0	CHEMBL1689279,TP,ACT,0.05999999865889549	CHEMBL2023584,FN,ACT,0.019999999552965164	CHEMBL1928171,TN,INACT,0.0	CHEMBL246471,FN,ACT,0.0	CHEMBL552288,FN,ACT,0.0	CHEMBL441370,TN,INACT,0.0	CHEMBL3741097,TN,INACT,0.0	CHEMBL116438,TN,INACT,0.0	CHEMBL256090,TP,ACT,0.38999998569488525	CHEMBL75893,TN,INACT,0.0	CHEMBL239373,TP,ACT,0.05000000074505806	CHEMBL3740853,TN,INACT,0.0	CHEMBL3339186,TN,INACT,0.0	CHEMBL512447,TP,ACT,0.23999999463558197	CHEMBL606420,FN,ACT,0.0	CHEMBL441687,TP,ACT,0.07000000029802322	CHEMBL241711,FN,ACT,0.0	CHEMBL1761138,TP,ACT,0.15000000596046448	CHEMBL3289870,TN,INACT,0.0	CHEMBL219049,TN,INACT,0.0	CHEMBL402387,TP,ACT,0.38999998569488525	CHEMBL404436,TP,ACT,0.1599999964237213	CHEMBL307429,TN,INACT,0.0	CHEMBL1270001,FN,ACT,0.0	CHEMBL217917,TN,INACT,0.0	CHEMBL384650,FN,ACT,0.0	CHEMBL399191,FN,ACT,0.0	CHEMBL1563246,FN,ACT,0.019999999552965164	

