ImageNetInceptionV2 CHEMBL1850 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	196
Number of inactive compounds :	196
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1850_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1850_adam_0.001_15_0.6/
---------------------------------
Training samples: 247
Validation samples: 78
--
Training Step: 1  | time: 36.435s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/247
[A[ATraining Step: 2  | total loss: [1m[32m0.66095[0m[0m | time: 44.458s
[2K
| Adam | epoch: 001 | loss: 0.66095 - acc: 0.3937 -- iter: 064/247
[A[ATraining Step: 3  | total loss: [1m[32m0.91394[0m[0m | time: 52.422s
[2K
| Adam | epoch: 001 | loss: 0.91394 - acc: 0.4295 -- iter: 096/247
[A[ATraining Step: 4  | total loss: [1m[32m0.90615[0m[0m | time: 60.455s
[2K
| Adam | epoch: 001 | loss: 0.90615 - acc: 0.5293 -- iter: 128/247
[A[ATraining Step: 5  | total loss: [1m[32m0.74058[0m[0m | time: 68.558s
[2K
| Adam | epoch: 001 | loss: 0.74058 - acc: 0.6172 -- iter: 160/247
[A[ATraining Step: 6  | total loss: [1m[32m0.65748[0m[0m | time: 76.402s
[2K
| Adam | epoch: 001 | loss: 0.65748 - acc: 0.6423 -- iter: 192/247
[A[ATraining Step: 7  | total loss: [1m[32m0.70627[0m[0m | time: 84.294s
[2K
| Adam | epoch: 001 | loss: 0.70627 - acc: 0.6132 -- iter: 224/247
[A[ATraining Step: 8  | total loss: [1m[32m0.68934[0m[0m | time: 99.474s
[2K
| Adam | epoch: 001 | loss: 0.68934 - acc: 0.6198 | val_loss: 2.23763 - val_acc: 0.4615 -- iter: 247/247
--
Training Step: 9  | total loss: [1m[32m0.78639[0m[0m | time: 6.235s
[2K
| Adam | epoch: 002 | loss: 0.78639 - acc: 0.5219 -- iter: 032/247
[A[ATraining Step: 10  | total loss: [1m[32m0.72982[0m[0m | time: 14.123s
[2K
| Adam | epoch: 002 | loss: 0.72982 - acc: 0.5435 -- iter: 064/247
[A[ATraining Step: 11  | total loss: [1m[32m0.69147[0m[0m | time: 22.049s
[2K
| Adam | epoch: 002 | loss: 0.69147 - acc: 0.6117 -- iter: 096/247
[A[ATraining Step: 12  | total loss: [1m[32m0.68712[0m[0m | time: 29.889s
[2K
| Adam | epoch: 002 | loss: 0.68712 - acc: 0.6458 -- iter: 128/247
[A[ATraining Step: 13  | total loss: [1m[32m0.69400[0m[0m | time: 37.739s
[2K
| Adam | epoch: 002 | loss: 0.69400 - acc: 0.6503 -- iter: 160/247
[A[ATraining Step: 14  | total loss: [1m[32m0.67373[0m[0m | time: 45.673s
[2K
| Adam | epoch: 002 | loss: 0.67373 - acc: 0.6016 -- iter: 192/247
[A[ATraining Step: 15  | total loss: [1m[32m0.60626[0m[0m | time: 53.721s
[2K
| Adam | epoch: 002 | loss: 0.60626 - acc: 0.6474 -- iter: 224/247
[A[ATraining Step: 16  | total loss: [1m[32m0.55502[0m[0m | time: 65.176s
[2K
| Adam | epoch: 002 | loss: 0.55502 - acc: 0.6742 | val_loss: 1.56430 - val_acc: 0.4615 -- iter: 247/247
--
Training Step: 17  | total loss: [1m[32m0.51333[0m[0m | time: 6.073s
[2K
| Adam | epoch: 003 | loss: 0.51333 - acc: 0.7127 -- iter: 032/247
[A[ATraining Step: 18  | total loss: [1m[32m0.52587[0m[0m | time: 12.120s
[2K
| Adam | epoch: 003 | loss: 0.52587 - acc: 0.7068 -- iter: 064/247
[A[ATraining Step: 19  | total loss: [1m[32m0.49450[0m[0m | time: 20.021s
[2K
| Adam | epoch: 003 | loss: 0.49450 - acc: 0.7466 -- iter: 096/247
[A[ATraining Step: 20  | total loss: [1m[32m0.43775[0m[0m | time: 27.981s
[2K
| Adam | epoch: 003 | loss: 0.43775 - acc: 0.7979 -- iter: 128/247
[A[ATraining Step: 21  | total loss: [1m[32m0.44601[0m[0m | time: 35.879s
[2K
| Adam | epoch: 003 | loss: 0.44601 - acc: 0.8024 -- iter: 160/247
[A[ATraining Step: 22  | total loss: [1m[32m0.42236[0m[0m | time: 43.785s
[2K
| Adam | epoch: 003 | loss: 0.42236 - acc: 0.8055 -- iter: 192/247
[A[ATraining Step: 23  | total loss: [1m[32m0.33171[0m[0m | time: 51.658s
[2K
| Adam | epoch: 003 | loss: 0.33171 - acc: 0.8529 -- iter: 224/247
[A[ATraining Step: 24  | total loss: [1m[32m0.27307[0m[0m | time: 63.202s
[2K
| Adam | epoch: 003 | loss: 0.27307 - acc: 0.8855 | val_loss: 2.65554 - val_acc: 0.4615 -- iter: 247/247
--
Training Step: 25  | total loss: [1m[32m0.26848[0m[0m | time: 7.746s
[2K
| Adam | epoch: 004 | loss: 0.26848 - acc: 0.8826 -- iter: 032/247
[A[ATraining Step: 26  | total loss: [1m[32m0.23227[0m[0m | time: 13.849s
[2K
| Adam | epoch: 004 | loss: 0.23227 - acc: 0.9054 -- iter: 064/247
[A[ATraining Step: 27  | total loss: [1m[32m0.23376[0m[0m | time: 19.789s
[2K
| Adam | epoch: 004 | loss: 0.23376 - acc: 0.9074 -- iter: 096/247
[A[ATraining Step: 28  | total loss: [1m[32m0.18684[0m[0m | time: 27.998s
[2K
| Adam | epoch: 004 | loss: 0.18684 - acc: 0.9305 -- iter: 128/247
[A[ATraining Step: 29  | total loss: [1m[32m0.25428[0m[0m | time: 35.806s
[2K
| Adam | epoch: 004 | loss: 0.25428 - acc: 0.9018 -- iter: 160/247
[A[ATraining Step: 30  | total loss: [1m[32m0.23716[0m[0m | time: 43.715s
[2K
| Adam | epoch: 004 | loss: 0.23716 - acc: 0.8955 -- iter: 192/247
[A[ATraining Step: 31  | total loss: [1m[32m0.34810[0m[0m | time: 51.742s
[2K
| Adam | epoch: 004 | loss: 0.34810 - acc: 0.8907 -- iter: 224/247
[A[ATraining Step: 32  | total loss: [1m[32m0.36546[0m[0m | time: 63.028s
[2K
| Adam | epoch: 004 | loss: 0.36546 - acc: 0.8802 | val_loss: 0.90710 - val_acc: 0.4359 -- iter: 247/247
--
Training Step: 33  | total loss: [1m[32m0.36415[0m[0m | time: 23.854s
[2K
| Adam | epoch: 005 | loss: 0.36415 - acc: 0.8653 -- iter: 032/247
[A[ATraining Step: 34  | total loss: [1m[32m0.34325[0m[0m | time: 36.756s
[2K
| Adam | epoch: 005 | loss: 0.34325 - acc: 0.8674 -- iter: 064/247
[A[ATraining Step: 35  | total loss: [1m[32m0.32165[0m[0m | time: 46.624s
[2K
| Adam | epoch: 005 | loss: 0.32165 - acc: 0.8690 -- iter: 096/247
[A[ATraining Step: 36  | total loss: [1m[32m0.31389[0m[0m | time: 57.245s
[2K
| Adam | epoch: 005 | loss: 0.31389 - acc: 0.8780 -- iter: 128/247
[A[ATraining Step: 37  | total loss: [1m[32m0.27088[0m[0m | time: 71.079s
[2K
| Adam | epoch: 005 | loss: 0.27088 - acc: 0.9024 -- iter: 160/247
[A[ATraining Step: 38  | total loss: [1m[32m0.30835[0m[0m | time: 84.657s
[2K
| Adam | epoch: 005 | loss: 0.30835 - acc: 0.8787 -- iter: 192/247
[A[ATraining Step: 39  | total loss: [1m[32m0.29244[0m[0m | time: 98.785s
[2K
| Adam | epoch: 005 | loss: 0.29244 - acc: 0.8780 -- iter: 224/247
[A[ATraining Step: 40  | total loss: [1m[32m0.29976[0m[0m | time: 118.994s
[2K
| Adam | epoch: 005 | loss: 0.29976 - acc: 0.8833 | val_loss: 1.21606 - val_acc: 0.6154 -- iter: 247/247
--
Training Step: 41  | total loss: [1m[32m0.28318[0m[0m | time: 16.869s
[2K
| Adam | epoch: 006 | loss: 0.28318 - acc: 0.8875 -- iter: 032/247
[A[ATraining Step: 42  | total loss: [1m[32m0.28045[0m[0m | time: 31.285s
[2K
| Adam | epoch: 006 | loss: 0.28045 - acc: 0.8853 -- iter: 064/247
[A[ATraining Step: 43  | total loss: [1m[32m0.27906[0m[0m | time: 44.716s
[2K
| Adam | epoch: 006 | loss: 0.27906 - acc: 0.8834 -- iter: 096/247
[A[ATraining Step: 44  | total loss: [1m[32m0.26844[0m[0m | time: 51.681s
[2K
| Adam | epoch: 006 | loss: 0.26844 - acc: 0.8874 -- iter: 128/247
[A[ATraining Step: 45  | total loss: [1m[32m0.24401[0m[0m | time: 58.162s
[2K
| Adam | epoch: 006 | loss: 0.24401 - acc: 0.8991 -- iter: 160/247
[A[ATraining Step: 46  | total loss: [1m[32m0.22400[0m[0m | time: 71.337s
[2K
| Adam | epoch: 006 | loss: 0.22400 - acc: 0.9159 -- iter: 192/247
[A[ATraining Step: 47  | total loss: [1m[32m0.25695[0m[0m | time: 79.709s
[2K
| Adam | epoch: 006 | loss: 0.25695 - acc: 0.9092 -- iter: 224/247
[A[ATraining Step: 48  | total loss: [1m[32m0.26128[0m[0m | time: 91.394s
[2K
| Adam | epoch: 006 | loss: 0.26128 - acc: 0.9088 | val_loss: 0.95713 - val_acc: 0.6410 -- iter: 247/247
--
Training Step: 49  | total loss: [1m[32m0.28443[0m[0m | time: 13.564s
[2K
| Adam | epoch: 007 | loss: 0.28443 - acc: 0.8936 -- iter: 032/247
[A[ATraining Step: 50  | total loss: [1m[32m0.27685[0m[0m | time: 27.354s
[2K
| Adam | epoch: 007 | loss: 0.27685 - acc: 0.9004 -- iter: 064/247
[A[ATraining Step: 51  | total loss: [1m[32m0.25777[0m[0m | time: 41.143s
[2K
| Adam | epoch: 007 | loss: 0.25777 - acc: 0.9108 -- iter: 096/247
[A[ATraining Step: 52  | total loss: [1m[32m0.23186[0m[0m | time: 55.043s
[2K
| Adam | epoch: 007 | loss: 0.23186 - acc: 0.9195 -- iter: 128/247
[A[ATraining Step: 53  | total loss: [1m[32m0.21682[0m[0m | time: 65.699s
[2K
| Adam | epoch: 007 | loss: 0.21682 - acc: 0.9268 -- iter: 160/247
[A[ATraining Step: 54  | total loss: [1m[32m0.19462[0m[0m | time: 76.159s
[2K
| Adam | epoch: 007 | loss: 0.19462 - acc: 0.9374 -- iter: 192/247
[A[ATraining Step: 55  | total loss: [1m[32m0.17379[0m[0m | time: 92.043s
[2K
| Adam | epoch: 007 | loss: 0.17379 - acc: 0.9463 -- iter: 224/247
[A[ATraining Step: 56  | total loss: [1m[32m0.15724[0m[0m | time: 126.170s
[2K
| Adam | epoch: 007 | loss: 0.15724 - acc: 0.9495 | val_loss: 1.16409 - val_acc: 0.6410 -- iter: 247/247
--
Training Step: 57  | total loss: [1m[32m0.14447[0m[0m | time: 13.406s
[2K
| Adam | epoch: 008 | loss: 0.14447 - acc: 0.9565 -- iter: 032/247
[A[ATraining Step: 58  | total loss: [1m[32m0.12895[0m[0m | time: 22.937s
[2K
| Adam | epoch: 008 | loss: 0.12895 - acc: 0.9624 -- iter: 064/247
[A[ATraining Step: 59  | total loss: [1m[32m0.12432[0m[0m | time: 31.411s
[2K
| Adam | epoch: 008 | loss: 0.12432 - acc: 0.9633 -- iter: 096/247
[A[ATraining Step: 60  | total loss: [1m[32m0.11533[0m[0m | time: 39.959s
[2K
| Adam | epoch: 008 | loss: 0.11533 - acc: 0.9681 -- iter: 128/247
[A[ATraining Step: 61  | total loss: [1m[32m0.10444[0m[0m | time: 51.611s
[2K
| Adam | epoch: 008 | loss: 0.10444 - acc: 0.9723 -- iter: 160/247
[A[ATraining Step: 62  | total loss: [1m[32m0.09531[0m[0m | time: 62.030s
[2K
| Adam | epoch: 008 | loss: 0.09531 - acc: 0.9759 -- iter: 192/247
[A[ATraining Step: 63  | total loss: [1m[32m0.08402[0m[0m | time: 72.433s
[2K
| Adam | epoch: 008 | loss: 0.08402 - acc: 0.9789 -- iter: 224/247
[A[ATraining Step: 64  | total loss: [1m[32m0.07448[0m[0m | time: 96.381s
[2K
| Adam | epoch: 008 | loss: 0.07448 - acc: 0.9815 | val_loss: 1.18915 - val_acc: 0.7692 -- iter: 247/247
--
Training Step: 65  | total loss: [1m[32m0.08009[0m[0m | time: 13.776s
[2K
| Adam | epoch: 009 | loss: 0.08009 - acc: 0.9761 -- iter: 032/247
[A[ATraining Step: 66  | total loss: [1m[32m0.07430[0m[0m | time: 27.695s
[2K
| Adam | epoch: 009 | loss: 0.07430 - acc: 0.9752 -- iter: 064/247
[A[ATraining Step: 67  | total loss: [1m[32m0.11806[0m[0m | time: 41.385s
[2K
| Adam | epoch: 009 | loss: 0.11806 - acc: 0.9707 -- iter: 096/247
[A[ATraining Step: 68  | total loss: [1m[32m0.11897[0m[0m | time: 55.423s
[2K
| Adam | epoch: 009 | loss: 0.11897 - acc: 0.9705 -- iter: 128/247
[A[ATraining Step: 69  | total loss: [1m[32m0.13813[0m[0m | time: 69.423s
[2K
| Adam | epoch: 009 | loss: 0.13813 - acc: 0.9630 -- iter: 160/247
[A[ATraining Step: 70  | total loss: [1m[32m0.15820[0m[0m | time: 82.897s
[2K
| Adam | epoch: 009 | loss: 0.15820 - acc: 0.9564 -- iter: 192/247
[A[ATraining Step: 71  | total loss: [1m[32m0.16566[0m[0m | time: 93.952s
[2K
| Adam | epoch: 009 | loss: 0.16566 - acc: 0.9507 -- iter: 224/247
[A[ATraining Step: 72  | total loss: [1m[32m0.15478[0m[0m | time: 110.654s
[2K
| Adam | epoch: 009 | loss: 0.15478 - acc: 0.9514 | val_loss: 1.11914 - val_acc: 0.7051 -- iter: 247/247
--
Training Step: 73  | total loss: [1m[32m0.13970[0m[0m | time: 8.436s
[2K
| Adam | epoch: 010 | loss: 0.13970 - acc: 0.9568 -- iter: 032/247
[A[ATraining Step: 74  | total loss: [1m[32m0.14212[0m[0m | time: 19.579s
[2K
| Adam | epoch: 010 | loss: 0.14212 - acc: 0.9512 -- iter: 064/247
[A[ATraining Step: 75  | total loss: [1m[32m0.13637[0m[0m | time: 33.152s
[2K
| Adam | epoch: 010 | loss: 0.13637 - acc: 0.9531 -- iter: 096/247
[A[ATraining Step: 76  | total loss: [1m[32m0.14581[0m[0m | time: 47.001s
[2K
| Adam | epoch: 010 | loss: 0.14581 - acc: 0.9514 -- iter: 128/247
[A[ATraining Step: 77  | total loss: [1m[32m0.16333[0m[0m | time: 60.947s
[2K
| Adam | epoch: 010 | loss: 0.16333 - acc: 0.9467 -- iter: 160/247
[A[ATraining Step: 78  | total loss: [1m[32m0.18622[0m[0m | time: 74.800s
[2K
| Adam | epoch: 010 | loss: 0.18622 - acc: 0.9392 -- iter: 192/247
[A[ATraining Step: 79  | total loss: [1m[32m0.20005[0m[0m | time: 88.745s
[2K
| Adam | epoch: 010 | loss: 0.20005 - acc: 0.9261 -- iter: 224/247
[A[ATraining Step: 80  | total loss: [1m[32m0.21866[0m[0m | time: 105.603s
[2K
| Adam | epoch: 010 | loss: 0.21866 - acc: 0.9176 | val_loss: 0.62458 - val_acc: 0.7179 -- iter: 247/247
--
Training Step: 81  | total loss: [1m[32m0.21937[0m[0m | time: 10.632s
[2K
| Adam | epoch: 011 | loss: 0.21937 - acc: 0.9128 -- iter: 032/247
[A[ATraining Step: 82  | total loss: [1m[32m0.21289[0m[0m | time: 24.370s
[2K
| Adam | epoch: 011 | loss: 0.21289 - acc: 0.9172 -- iter: 064/247
[A[ATraining Step: 83  | total loss: [1m[32m0.20342[0m[0m | time: 38.418s
[2K
| Adam | epoch: 011 | loss: 0.20342 - acc: 0.9192 -- iter: 096/247
[A[ATraining Step: 84  | total loss: [1m[32m0.19992[0m[0m | time: 52.520s
[2K
| Adam | epoch: 011 | loss: 0.19992 - acc: 0.9148 -- iter: 128/247
[A[ATraining Step: 85  | total loss: [1m[32m0.20810[0m[0m | time: 66.488s
[2K
| Adam | epoch: 011 | loss: 0.20810 - acc: 0.9077 -- iter: 160/247
[A[ATraining Step: 86  | total loss: [1m[32m0.19858[0m[0m | time: 80.439s
[2K
| Adam | epoch: 011 | loss: 0.19858 - acc: 0.9106 -- iter: 192/247
[A[ATraining Step: 87  | total loss: [1m[32m0.18655[0m[0m | time: 94.104s
[2K
| Adam | epoch: 011 | loss: 0.18655 - acc: 0.9165 -- iter: 224/247
[A[ATraining Step: 88  | total loss: [1m[32m0.17406[0m[0m | time: 108.267s
[2K
| Adam | epoch: 011 | loss: 0.17406 - acc: 0.9248 | val_loss: 1.59043 - val_acc: 0.5128 -- iter: 247/247
--
Training Step: 89  | total loss: [1m[32m0.16919[0m[0m | time: 10.995s
[2K
| Adam | epoch: 012 | loss: 0.16919 - acc: 0.9323 -- iter: 032/247
[A[ATraining Step: 90  | total loss: [1m[32m0.15515[0m[0m | time: 20.996s
[2K
| Adam | epoch: 012 | loss: 0.15515 - acc: 0.9391 -- iter: 064/247
[A[ATraining Step: 91  | total loss: [1m[32m0.14219[0m[0m | time: 54.579s
[2K
| Adam | epoch: 012 | loss: 0.14219 - acc: 0.9452 -- iter: 096/247
[A[ATraining Step: 92  | total loss: [1m[32m0.14104[0m[0m | time: 93.846s
[2K
| Adam | epoch: 012 | loss: 0.14104 - acc: 0.9444 -- iter: 128/247
[A[ATraining Step: 93  | total loss: [1m[32m0.14352[0m[0m | time: 106.909s
[2K
| Adam | epoch: 012 | loss: 0.14352 - acc: 0.9469 -- iter: 160/247
[A[ATraining Step: 94  | total loss: [1m[32m0.16294[0m[0m | time: 139.370s
[2K
| Adam | epoch: 012 | loss: 0.16294 - acc: 0.9490 -- iter: 192/247
[A[ATraining Step: 95  | total loss: [1m[32m0.16417[0m[0m | time: 152.565s
[2K
| Adam | epoch: 012 | loss: 0.16417 - acc: 0.9479 -- iter: 224/247
[A[ATraining Step: 96  | total loss: [1m[32m0.16496[0m[0m | time: 174.261s
[2K
| Adam | epoch: 012 | loss: 0.16496 - acc: 0.9468 | val_loss: 0.95856 - val_acc: 0.6923 -- iter: 247/247
--
Training Step: 97  | total loss: [1m[32m0.15138[0m[0m | time: 13.466s
[2K
| Adam | epoch: 013 | loss: 0.15138 - acc: 0.9522 -- iter: 032/247
[A[ATraining Step: 98  | total loss: [1m[32m0.14271[0m[0m | time: 23.613s
[2K
| Adam | epoch: 013 | loss: 0.14271 - acc: 0.9538 -- iter: 064/247
[A[ATraining Step: 99  | total loss: [1m[32m0.15457[0m[0m | time: 34.367s
[2K
| Adam | epoch: 013 | loss: 0.15457 - acc: 0.9454 -- iter: 096/247
[A[ATraining Step: 100  | total loss: [1m[32m0.14578[0m[0m | time: 173.893s
[2K
| Adam | epoch: 013 | loss: 0.14578 - acc: 0.9509 -- iter: 128/247
[A[ATraining Step: 101  | total loss: [1m[32m0.14665[0m[0m | time: 268.751s
[2K
| Adam | epoch: 013 | loss: 0.14665 - acc: 0.9433 -- iter: 160/247
[A[ATraining Step: 102  | total loss: [1m[32m0.14165[0m[0m | time: 284.223s
[2K
| Adam | epoch: 013 | loss: 0.14165 - acc: 0.9458 -- iter: 192/247
[A[ATraining Step: 103  | total loss: [1m[32m0.18835[0m[0m | time: 294.159s
[2K
| Adam | epoch: 013 | loss: 0.18835 - acc: 0.9450 -- iter: 224/247
[A[ATraining Step: 104  | total loss: [1m[32m0.17341[0m[0m | time: 308.692s
[2K
| Adam | epoch: 013 | loss: 0.17341 - acc: 0.9505 | val_loss: 4.93777 - val_acc: 0.4615 -- iter: 247/247
--
Training Step: 105  | total loss: [1m[32m0.16763[0m[0m | time: 16.289s
[2K
| Adam | epoch: 014 | loss: 0.16763 - acc: 0.9523 -- iter: 032/247
[A[ATraining Step: 106  | total loss: [1m[32m0.19907[0m[0m | time: 32.468s
[2K
| Adam | epoch: 014 | loss: 0.19907 - acc: 0.9446 -- iter: 064/247
[A[ATraining Step: 107  | total loss: [1m[32m0.19167[0m[0m | time: 45.820s
[2K
| Adam | epoch: 014 | loss: 0.19167 - acc: 0.9470 -- iter: 096/247
[A[ATraining Step: 108  | total loss: [1m[32m0.18140[0m[0m | time: 58.028s
[2K
| Adam | epoch: 014 | loss: 0.18140 - acc: 0.9523 -- iter: 128/247
[A[ATraining Step: 109  | total loss: [1m[32m0.16582[0m[0m | time: 95.929s
[2K
| Adam | epoch: 014 | loss: 0.16582 - acc: 0.9571 -- iter: 160/247
[A[ATraining Step: 110  | total loss: [1m[32m0.16141[0m[0m | time: 257.874s
[2K
| Adam | epoch: 014 | loss: 0.16141 - acc: 0.9582 -- iter: 192/247
[A[ATraining Step: 111  | total loss: [1m[32m0.16162[0m[0m | time: 354.060s
[2K
| Adam | epoch: 014 | loss: 0.16162 - acc: 0.9593 -- iter: 224/247
[A[ATraining Step: 112  | total loss: [1m[32m0.14820[0m[0m | time: 442.464s
[2K
| Adam | epoch: 014 | loss: 0.14820 - acc: 0.9634 | val_loss: 0.59564 - val_acc: 0.7949 -- iter: 247/247
--
Training Step: 113  | total loss: [1m[32m0.16082[0m[0m | time: 15.240s
[2K
| Adam | epoch: 015 | loss: 0.16082 - acc: 0.9483 -- iter: 032/247
[A[ATraining Step: 114  | total loss: [1m[32m0.15128[0m[0m | time: 30.484s
[2K
| Adam | epoch: 015 | loss: 0.15128 - acc: 0.9534 -- iter: 064/247
[A[ATraining Step: 115  | total loss: [1m[32m0.14135[0m[0m | time: 45.389s
[2K
| Adam | epoch: 015 | loss: 0.14135 - acc: 0.9550 -- iter: 096/247
[A[ATraining Step: 116  | total loss: [1m[32m0.13864[0m[0m | time: 54.821s
[2K
| Adam | epoch: 015 | loss: 0.13864 - acc: 0.9564 -- iter: 128/247
[A[ATraining Step: 117  | total loss: [1m[32m0.13047[0m[0m | time: 62.723s
[2K
| Adam | epoch: 015 | loss: 0.13047 - acc: 0.9607 -- iter: 160/247
[A[ATraining Step: 118  | total loss: [1m[32m0.12016[0m[0m | time: 72.407s
[2K
| Adam | epoch: 015 | loss: 0.12016 - acc: 0.9646 -- iter: 192/247
[A[ATraining Step: 119  | total loss: [1m[32m0.11160[0m[0m | time: 86.484s
[2K
| Adam | epoch: 015 | loss: 0.11160 - acc: 0.9682 -- iter: 224/247
[A[ATraining Step: 120  | total loss: [1m[32m0.10338[0m[0m | time: 109.184s
[2K
| Adam | epoch: 015 | loss: 0.10338 - acc: 0.9714 | val_loss: 0.56161 - val_acc: 0.8333 -- iter: 247/247
--
Validation AUC:0.9464285714285714
Validation AUPRC:0.942048489599152
Test AUC:0.9404761904761905
Test AUPRC:0.9503123840979381
BestTestF1Score	0.88	0.72	0.86	0.82	0.95	40	9	27	2	0.83
BestTestMCCScore	0.88	0.72	0.86	0.82	0.95	40	9	27	2	0.83
BestTestAccuracyScore	0.88	0.72	0.86	0.82	0.95	40	9	27	2	0.83
BestValidationF1Score	0.87	0.75	0.87	0.82	0.92	33	7	35	3	0.83
BestValidationMCC	0.87	0.75	0.87	0.82	0.92	33	7	35	3	0.83
BestValidationAccuracy	0.87	0.75	0.87	0.82	0.92	33	7	35	3	0.83
TestPredictions (Threshold:0.83)
CHEMBL453,TN,INACT,0.009999999776482582	CHEMBL1259241,FP,INACT,1.0	CHEMBL600083,TP,ACT,1.0	CHEMBL114825,FN,ACT,0.03999999910593033	CHEMBL42360,TN,INACT,0.009999999776482582	CHEMBL2113072,TN,INACT,0.6000000238418579	CHEMBL59597,FP,INACT,1.0	CHEMBL2111789,TN,INACT,0.0	CHEMBL59,TP,ACT,1.0	CHEMBL213492,TP,ACT,0.8999999761581421	CHEMBL610449,TP,ACT,1.0	CHEMBL558766,FP,INACT,0.9800000190734863	CHEMBL3622099,TP,ACT,1.0	CHEMBL382010,TP,ACT,1.0	CHEMBL217002,TN,INACT,0.0	CHEMBL534706,TP,ACT,1.0	CHEMBL408492,TN,INACT,0.0	CHEMBL599116,TP,ACT,1.0	CHEMBL1076,FP,INACT,0.949999988079071	CHEMBL2322893,FP,INACT,0.9700000286102295	CHEMBL396561,TP,ACT,0.9200000166893005	CHEMBL227378,TN,INACT,0.0	CHEMBL238916,TP,ACT,1.0	CHEMBL441618,TP,ACT,1.0	CHEMBL535602,FP,INACT,1.0	CHEMBL100624,FP,INACT,0.8799999952316284	CHEMBL231374,FN,ACT,0.7400000095367432	CHEMBL1557,TP,ACT,1.0	CHEMBL2204343,TP,ACT,1.0	CHEMBL245570,TP,ACT,0.9599999785423279	CHEMBL326263,TP,ACT,1.0	CHEMBL594376,TN,INACT,0.0	CHEMBL343755,TP,ACT,1.0	CHEMBL2370511,TN,INACT,0.0	CHEMBL1180343,FP,INACT,0.9100000262260437	CHEMBL2369493,TN,INACT,0.0	CHEMBL1949729,TP,ACT,1.0	CHEMBL394080,TP,ACT,1.0	CHEMBL1940404,TP,ACT,1.0	CHEMBL378669,TP,ACT,1.0	CHEMBL169553,TN,INACT,0.009999999776482582	CHEMBL89203,TN,INACT,0.18000000715255737	CHEMBL2420775,TP,ACT,1.0	CHEMBL1258999,FP,INACT,1.0	CHEMBL80532,TN,INACT,0.0	CHEMBL19808,TN,INACT,0.0	CHEMBL44134,TN,INACT,0.009999999776482582	CHEMBL109206,TN,INACT,0.0	CHEMBL450729,TN,INACT,0.0	CHEMBL268371,TP,ACT,0.949999988079071	CHEMBL116463,TP,ACT,1.0	CHEMBL112877,TN,INACT,0.0	CHEMBL202924,TP,ACT,1.0	CHEMBL58617,TN,INACT,0.0	CHEMBL393492,TP,ACT,0.9700000286102295	CHEMBL71,TP,ACT,1.0	CHEMBL3289647,TP,ACT,1.0	CHEMBL13668,TP,ACT,1.0	CHEMBL1204122,TP,ACT,1.0	CHEMBL201525,TP,ACT,1.0	CHEMBL238915,TP,ACT,1.0	CHEMBL599282,TP,ACT,1.0	CHEMBL600986,TP,ACT,1.0	CHEMBL389559,TP,ACT,1.0	CHEMBL2112592,TN,INACT,0.0	CHEMBL415879,TN,INACT,0.0	CHEMBL3115575,TP,ACT,0.8799999952316284	CHEMBL310427,TN,INACT,0.18000000715255737	CHEMBL554303,TP,ACT,1.0	CHEMBL1940409,TP,ACT,1.0	CHEMBL416069,TN,INACT,0.0	CHEMBL604314,TP,ACT,1.0	CHEMBL3577343,TN,INACT,0.6299999952316284	CHEMBL134807,TP,ACT,0.8399999737739563	CHEMBL435505,TP,ACT,1.0	CHEMBL603858,TN,INACT,0.029999999329447746	CHEMBL1170027,TN,INACT,0.0	CHEMBL320254,TN,INACT,0.0	

