CNNModel CHEMBL1868 adam 0.0005 15 256 0 0.8 False True
Number of active compounds :	668
Number of inactive compounds :	668
---------------------------------
Run id: CNNModel_CHEMBL1868_adam_0.0005_15_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1868_adam_0.0005_15_256_0.8_True/
---------------------------------
Training samples: 847
Validation samples: 265
--
Training Step: 1  | time: 0.793s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/847
[A[ATraining Step: 2  | total loss: [1m[32m0.62326[0m[0m | time: 1.404s
[2K
| Adam | epoch: 001 | loss: 0.62326 - acc: 0.6750 -- iter: 064/847
[A[ATraining Step: 3  | total loss: [1m[32m0.68588[0m[0m | time: 2.029s
[2K
| Adam | epoch: 001 | loss: 0.68588 - acc: 0.3784 -- iter: 096/847
[A[ATraining Step: 4  | total loss: [1m[32m0.69127[0m[0m | time: 2.623s
[2K
| Adam | epoch: 001 | loss: 0.69127 - acc: 0.4930 -- iter: 128/847
[A[ATraining Step: 5  | total loss: [1m[32m0.69385[0m[0m | time: 3.229s
[2K
| Adam | epoch: 001 | loss: 0.69385 - acc: 0.3897 -- iter: 160/847
[A[ATraining Step: 6  | total loss: [1m[32m0.69343[0m[0m | time: 3.836s
[2K
| Adam | epoch: 001 | loss: 0.69343 - acc: 0.4606 -- iter: 192/847
[A[ATraining Step: 7  | total loss: [1m[32m0.69318[0m[0m | time: 4.460s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.5592 -- iter: 224/847
[A[ATraining Step: 8  | total loss: [1m[32m0.69308[0m[0m | time: 5.049s
[2K
| Adam | epoch: 001 | loss: 0.69308 - acc: 0.5611 -- iter: 256/847
[A[ATraining Step: 9  | total loss: [1m[32m0.69317[0m[0m | time: 5.646s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.4957 -- iter: 288/847
[A[ATraining Step: 10  | total loss: [1m[32m0.69327[0m[0m | time: 6.256s
[2K
| Adam | epoch: 001 | loss: 0.69327 - acc: 0.4666 -- iter: 320/847
[A[ATraining Step: 11  | total loss: [1m[32m0.69331[0m[0m | time: 6.848s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4380 -- iter: 352/847
[A[ATraining Step: 12  | total loss: [1m[32m0.69329[0m[0m | time: 7.453s
[2K
| Adam | epoch: 001 | loss: 0.69329 - acc: 0.4097 -- iter: 384/847
[A[ATraining Step: 13  | total loss: [1m[32m0.69333[0m[0m | time: 8.052s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.3814 -- iter: 416/847
[A[ATraining Step: 14  | total loss: [1m[32m0.69325[0m[0m | time: 8.669s
[2K
| Adam | epoch: 001 | loss: 0.69325 - acc: 0.3916 -- iter: 448/847
[A[ATraining Step: 15  | total loss: [1m[32m0.69350[0m[0m | time: 9.267s
[2K
| Adam | epoch: 001 | loss: 0.69350 - acc: 0.3606 -- iter: 480/847
[A[ATraining Step: 16  | total loss: [1m[32m0.69344[0m[0m | time: 9.869s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.3895 -- iter: 512/847
[A[ATraining Step: 17  | total loss: [1m[32m0.69331[0m[0m | time: 10.494s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4180 -- iter: 544/847
[A[ATraining Step: 18  | total loss: [1m[32m0.69322[0m[0m | time: 11.094s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4788 -- iter: 576/847
[A[ATraining Step: 19  | total loss: [1m[32m0.69316[0m[0m | time: 11.717s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5067 -- iter: 608/847
[A[ATraining Step: 20  | total loss: [1m[32m0.69320[0m[0m | time: 12.326s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.4744 -- iter: 640/847
[A[ATraining Step: 21  | total loss: [1m[32m0.69316[0m[0m | time: 12.925s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.4921 -- iter: 672/847
[A[ATraining Step: 22  | total loss: [1m[32m0.69306[0m[0m | time: 13.513s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.5132 -- iter: 704/847
[A[ATraining Step: 23  | total loss: [1m[32m0.69322[0m[0m | time: 14.111s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4912 -- iter: 736/847
[A[ATraining Step: 24  | total loss: [1m[32m0.69309[0m[0m | time: 14.728s
[2K
| Adam | epoch: 001 | loss: 0.69309 - acc: 0.5025 -- iter: 768/847
[A[ATraining Step: 25  | total loss: [1m[32m0.69313[0m[0m | time: 15.367s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.4933 -- iter: 800/847
[A[ATraining Step: 26  | total loss: [1m[32m0.69296[0m[0m | time: 15.980s
[2K
| Adam | epoch: 001 | loss: 0.69296 - acc: 0.5116 -- iter: 832/847
[A[ATraining Step: 27  | total loss: [1m[32m0.69301[0m[0m | time: 17.314s
[2K
| Adam | epoch: 001 | loss: 0.69301 - acc: 0.5086 | val_loss: 0.69329 - val_acc: 0.4906 -- iter: 847/847
--
Training Step: 28  | total loss: [1m[32m0.69350[0m[0m | time: 0.302s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.4815 -- iter: 032/847
[A[ATraining Step: 29  | total loss: [1m[32m0.69377[0m[0m | time: 0.898s
[2K
| Adam | epoch: 002 | loss: 0.69377 - acc: 0.4616 -- iter: 064/847
[A[ATraining Step: 30  | total loss: [1m[32m0.69341[0m[0m | time: 1.507s
[2K
| Adam | epoch: 002 | loss: 0.69341 - acc: 0.4855 -- iter: 096/847
[A[ATraining Step: 31  | total loss: [1m[32m0.69329[0m[0m | time: 2.120s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4961 -- iter: 128/847
[A[ATraining Step: 32  | total loss: [1m[32m0.69318[0m[0m | time: 2.713s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5040 -- iter: 160/847
[A[ATraining Step: 33  | total loss: [1m[32m0.69294[0m[0m | time: 3.359s
[2K
| Adam | epoch: 002 | loss: 0.69294 - acc: 0.5306 -- iter: 192/847
[A[ATraining Step: 34  | total loss: [1m[32m0.69276[0m[0m | time: 3.957s
[2K
| Adam | epoch: 002 | loss: 0.69276 - acc: 0.5441 -- iter: 224/847
[A[ATraining Step: 35  | total loss: [1m[32m0.69233[0m[0m | time: 4.559s
[2K
| Adam | epoch: 002 | loss: 0.69233 - acc: 0.5741 -- iter: 256/847
[A[ATraining Step: 36  | total loss: [1m[32m0.69206[0m[0m | time: 5.147s
[2K
| Adam | epoch: 002 | loss: 0.69206 - acc: 0.5845 -- iter: 288/847
[A[ATraining Step: 37  | total loss: [1m[32m0.69276[0m[0m | time: 5.745s
[2K
| Adam | epoch: 002 | loss: 0.69276 - acc: 0.5489 -- iter: 320/847
[A[ATraining Step: 38  | total loss: [1m[32m0.69319[0m[0m | time: 6.343s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5271 -- iter: 352/847
[A[ATraining Step: 39  | total loss: [1m[32m0.69352[0m[0m | time: 6.958s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.5099 -- iter: 384/847
[A[ATraining Step: 40  | total loss: [1m[32m0.69378[0m[0m | time: 7.550s
[2K
| Adam | epoch: 002 | loss: 0.69378 - acc: 0.4963 -- iter: 416/847
[A[ATraining Step: 41  | total loss: [1m[32m0.69409[0m[0m | time: 8.150s
[2K
| Adam | epoch: 002 | loss: 0.69409 - acc: 0.4798 -- iter: 448/847
[A[ATraining Step: 42  | total loss: [1m[32m0.69449[0m[0m | time: 8.738s
[2K
| Adam | epoch: 002 | loss: 0.69449 - acc: 0.4553 -- iter: 480/847
[A[ATraining Step: 43  | total loss: [1m[32m0.69380[0m[0m | time: 9.335s
[2K
| Adam | epoch: 002 | loss: 0.69380 - acc: 0.4908 -- iter: 512/847
[A[ATraining Step: 44  | total loss: [1m[32m0.69368[0m[0m | time: 9.938s
[2K
| Adam | epoch: 002 | loss: 0.69368 - acc: 0.4924 -- iter: 544/847
[A[ATraining Step: 45  | total loss: [1m[32m0.69333[0m[0m | time: 10.561s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.5096 -- iter: 576/847
[A[ATraining Step: 46  | total loss: [1m[32m0.69313[0m[0m | time: 11.180s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.5184 -- iter: 608/847
[A[ATraining Step: 47  | total loss: [1m[32m0.69272[0m[0m | time: 11.766s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5410 -- iter: 640/847
[A[ATraining Step: 48  | total loss: [1m[32m0.69251[0m[0m | time: 12.330s
[2K
| Adam | epoch: 002 | loss: 0.69251 - acc: 0.5494 -- iter: 672/847
[A[ATraining Step: 49  | total loss: [1m[32m0.69291[0m[0m | time: 12.936s
[2K
| Adam | epoch: 002 | loss: 0.69291 - acc: 0.5268 -- iter: 704/847
[A[ATraining Step: 50  | total loss: [1m[32m0.69316[0m[0m | time: 13.555s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5130 -- iter: 736/847
[A[ATraining Step: 51  | total loss: [1m[32m0.69380[0m[0m | time: 14.151s
[2K
| Adam | epoch: 002 | loss: 0.69380 - acc: 0.4824 -- iter: 768/847
[A[ATraining Step: 52  | total loss: [1m[32m0.69382[0m[0m | time: 14.771s
[2K
| Adam | epoch: 002 | loss: 0.69382 - acc: 0.4803 -- iter: 800/847
[A[ATraining Step: 53  | total loss: [1m[32m0.69383[0m[0m | time: 15.392s
[2K
| Adam | epoch: 002 | loss: 0.69383 - acc: 0.4786 -- iter: 832/847
[A[ATraining Step: 54  | total loss: [1m[32m0.69348[0m[0m | time: 17.004s
[2K
| Adam | epoch: 002 | loss: 0.69348 - acc: 0.4953 | val_loss: 0.69335 - val_acc: 0.4906 -- iter: 847/847
--
Training Step: 55  | total loss: [1m[32m0.69335[0m[0m | time: 0.312s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.5005 -- iter: 032/847
[A[ATraining Step: 56  | total loss: [1m[32m0.69273[0m[0m | time: 0.615s
[2K
| Adam | epoch: 003 | loss: 0.69273 - acc: 0.5332 -- iter: 064/847
[A[ATraining Step: 57  | total loss: [1m[32m0.69217[0m[0m | time: 1.216s
[2K
| Adam | epoch: 003 | loss: 0.69217 - acc: 0.5609 -- iter: 096/847
[A[ATraining Step: 58  | total loss: [1m[32m0.69257[0m[0m | time: 1.813s
[2K
| Adam | epoch: 003 | loss: 0.69257 - acc: 0.5398 -- iter: 128/847
[A[ATraining Step: 59  | total loss: [1m[32m0.69256[0m[0m | time: 2.409s
[2K
| Adam | epoch: 003 | loss: 0.69256 - acc: 0.5387 -- iter: 160/847
[A[ATraining Step: 60  | total loss: [1m[32m0.69265[0m[0m | time: 3.020s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5336 -- iter: 192/847
[A[ATraining Step: 61  | total loss: [1m[32m0.69285[0m[0m | time: 3.618s
[2K
| Adam | epoch: 003 | loss: 0.69285 - acc: 0.5251 -- iter: 224/847
[A[ATraining Step: 62  | total loss: [1m[32m0.69289[0m[0m | time: 4.250s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.5219 -- iter: 256/847
[A[ATraining Step: 63  | total loss: [1m[32m0.69281[0m[0m | time: 4.861s
[2K
| Adam | epoch: 003 | loss: 0.69281 - acc: 0.5231 -- iter: 288/847
[A[ATraining Step: 64  | total loss: [1m[32m0.69287[0m[0m | time: 5.452s
[2K
| Adam | epoch: 003 | loss: 0.69287 - acc: 0.5202 -- iter: 320/847
[A[ATraining Step: 65  | total loss: [1m[32m0.69323[0m[0m | time: 6.078s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.5061 -- iter: 352/847
[A[ATraining Step: 66  | total loss: [1m[32m0.69280[0m[0m | time: 6.684s
[2K
| Adam | epoch: 003 | loss: 0.69280 - acc: 0.5206 -- iter: 384/847
[A[ATraining Step: 67  | total loss: [1m[32m0.69307[0m[0m | time: 7.256s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5106 -- iter: 416/847
[A[ATraining Step: 68  | total loss: [1m[32m0.69298[0m[0m | time: 7.854s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5131 -- iter: 448/847
[A[ATraining Step: 69  | total loss: [1m[32m0.69278[0m[0m | time: 8.429s
[2K
| Adam | epoch: 003 | loss: 0.69278 - acc: 0.5188 -- iter: 480/847
[A[ATraining Step: 70  | total loss: [1m[32m0.69283[0m[0m | time: 9.027s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5167 -- iter: 512/847
[A[ATraining Step: 71  | total loss: [1m[32m0.69299[0m[0m | time: 9.640s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5112 -- iter: 544/847
[A[ATraining Step: 72  | total loss: [1m[32m0.69200[0m[0m | time: 10.242s
[2K
| Adam | epoch: 003 | loss: 0.69200 - acc: 0.5416 -- iter: 576/847
[A[ATraining Step: 73  | total loss: [1m[32m0.69188[0m[0m | time: 10.828s
[2K
| Adam | epoch: 003 | loss: 0.69188 - acc: 0.5439 -- iter: 608/847
[A[ATraining Step: 74  | total loss: [1m[32m0.69204[0m[0m | time: 11.421s
[2K
| Adam | epoch: 003 | loss: 0.69204 - acc: 0.5391 -- iter: 640/847
[A[ATraining Step: 75  | total loss: [1m[32m0.69272[0m[0m | time: 12.013s
[2K
| Adam | epoch: 003 | loss: 0.69272 - acc: 0.5213 -- iter: 672/847
[A[ATraining Step: 76  | total loss: [1m[32m0.69282[0m[0m | time: 12.634s
[2K
| Adam | epoch: 003 | loss: 0.69282 - acc: 0.5190 -- iter: 704/847
[A[ATraining Step: 77  | total loss: [1m[32m0.69315[0m[0m | time: 13.231s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5104 -- iter: 736/847
[A[ATraining Step: 78  | total loss: [1m[32m0.69330[0m[0m | time: 13.822s
[2K
| Adam | epoch: 003 | loss: 0.69330 - acc: 0.5060 -- iter: 768/847
[A[ATraining Step: 79  | total loss: [1m[32m0.69294[0m[0m | time: 14.457s
[2K
| Adam | epoch: 003 | loss: 0.69294 - acc: 0.5151 -- iter: 800/847
[A[ATraining Step: 80  | total loss: [1m[32m0.69326[0m[0m | time: 15.052s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5072 -- iter: 832/847
[A[ATraining Step: 81  | total loss: [1m[32m0.69275[0m[0m | time: 16.670s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5191 | val_loss: 0.69377 - val_acc: 0.4906 -- iter: 847/847
--
Training Step: 82  | total loss: [1m[32m0.69238[0m[0m | time: 0.600s
[2K
| Adam | epoch: 004 | loss: 0.69238 - acc: 0.5265 -- iter: 032/847
[A[ATraining Step: 83  | total loss: [1m[32m0.69221[0m[0m | time: 0.901s
[2K
| Adam | epoch: 004 | loss: 0.69221 - acc: 0.5301 -- iter: 064/847
[A[ATraining Step: 84  | total loss: [1m[32m0.69216[0m[0m | time: 1.201s
[2K
| Adam | epoch: 004 | loss: 0.69216 - acc: 0.5305 -- iter: 096/847
[A[ATraining Step: 85  | total loss: [1m[32m0.69215[0m[0m | time: 1.827s
[2K
| Adam | epoch: 004 | loss: 0.69215 - acc: 0.5308 -- iter: 128/847
[A[ATraining Step: 86  | total loss: [1m[32m0.69227[0m[0m | time: 2.433s
[2K
| Adam | epoch: 004 | loss: 0.69227 - acc: 0.5277 -- iter: 160/847
[A[ATraining Step: 87  | total loss: [1m[32m0.69220[0m[0m | time: 3.028s
[2K
| Adam | epoch: 004 | loss: 0.69220 - acc: 0.5280 -- iter: 192/847
[A[ATraining Step: 88  | total loss: [1m[32m0.69263[0m[0m | time: 3.622s
[2K
| Adam | epoch: 004 | loss: 0.69263 - acc: 0.5190 -- iter: 224/847
[A[ATraining Step: 89  | total loss: [1m[32m0.69289[0m[0m | time: 4.238s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5140 -- iter: 256/847
[A[ATraining Step: 90  | total loss: [1m[32m0.69333[0m[0m | time: 4.831s
[2K
| Adam | epoch: 004 | loss: 0.69333 - acc: 0.5063 -- iter: 288/847
[A[ATraining Step: 91  | total loss: [1m[32m0.69275[0m[0m | time: 5.417s
[2K
| Adam | epoch: 004 | loss: 0.69275 - acc: 0.5182 -- iter: 320/847
[A[ATraining Step: 92  | total loss: [1m[32m0.69312[0m[0m | time: 6.009s
[2K
| Adam | epoch: 004 | loss: 0.69312 - acc: 0.5101 -- iter: 352/847
[A[ATraining Step: 93  | total loss: [1m[32m0.69363[0m[0m | time: 6.623s
[2K
| Adam | epoch: 004 | loss: 0.69363 - acc: 0.4997 -- iter: 384/847
[A[ATraining Step: 94  | total loss: [1m[32m0.69302[0m[0m | time: 7.225s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5123 -- iter: 416/847
[A[ATraining Step: 95  | total loss: [1m[32m0.69319[0m[0m | time: 7.858s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.5079 -- iter: 448/847
[A[ATraining Step: 96  | total loss: [1m[32m0.69318[0m[0m | time: 8.463s
[2K
| Adam | epoch: 004 | loss: 0.69318 - acc: 0.5071 -- iter: 480/847
[A[ATraining Step: 97  | total loss: [1m[32m0.69349[0m[0m | time: 9.079s
[2K
| Adam | epoch: 004 | loss: 0.69349 - acc: 0.5002 -- iter: 512/847
[A[ATraining Step: 98  | total loss: [1m[32m0.69290[0m[0m | time: 9.677s
[2K
| Adam | epoch: 004 | loss: 0.69290 - acc: 0.5126 -- iter: 544/847
[A[ATraining Step: 99  | total loss: [1m[32m0.69225[0m[0m | time: 10.267s
[2K
| Adam | epoch: 004 | loss: 0.69225 - acc: 0.5270 -- iter: 576/847
[A[ATraining Step: 100  | total loss: [1m[32m0.69297[0m[0m | time: 10.854s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5118 -- iter: 608/847
[A[ATraining Step: 101  | total loss: [1m[32m0.69305[0m[0m | time: 11.454s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5106 -- iter: 640/847
[A[ATraining Step: 102  | total loss: [1m[32m0.69263[0m[0m | time: 12.042s
[2K
| Adam | epoch: 004 | loss: 0.69263 - acc: 0.5189 -- iter: 672/847
[A[ATraining Step: 103  | total loss: [1m[32m0.69299[0m[0m | time: 12.641s
[2K
| Adam | epoch: 004 | loss: 0.69299 - acc: 0.5108 -- iter: 704/847
[A[ATraining Step: 104  | total loss: [1m[32m0.69318[0m[0m | time: 13.241s
[2K
| Adam | epoch: 004 | loss: 0.69318 - acc: 0.5066 -- iter: 736/847
[A[ATraining Step: 105  | total loss: [1m[32m0.69391[0m[0m | time: 13.849s
[2K
| Adam | epoch: 004 | loss: 0.69391 - acc: 0.4903 -- iter: 768/847
[A[ATraining Step: 106  | total loss: [1m[32m0.69344[0m[0m | time: 14.449s
[2K
| Adam | epoch: 004 | loss: 0.69344 - acc: 0.5006 -- iter: 800/847
[A[ATraining Step: 107  | total loss: [1m[32m0.69276[0m[0m | time: 15.051s
[2K
| Adam | epoch: 004 | loss: 0.69276 - acc: 0.5162 -- iter: 832/847
[A[ATraining Step: 108  | total loss: [1m[32m0.69243[0m[0m | time: 16.669s
[2K
| Adam | epoch: 004 | loss: 0.69243 - acc: 0.5240 | val_loss: 0.69375 - val_acc: 0.4906 -- iter: 847/847
--
Training Step: 109  | total loss: [1m[32m0.69238[0m[0m | time: 0.618s
[2K
| Adam | epoch: 005 | loss: 0.69238 - acc: 0.5247 -- iter: 032/847
[A[ATraining Step: 110  | total loss: [1m[32m0.69218[0m[0m | time: 1.229s
[2K
| Adam | epoch: 005 | loss: 0.69218 - acc: 0.5285 -- iter: 064/847
[A[ATraining Step: 111  | total loss: [1m[32m0.69274[0m[0m | time: 1.530s
[2K
| Adam | epoch: 005 | loss: 0.69274 - acc: 0.5162 -- iter: 096/847
[A[ATraining Step: 112  | total loss: [1m[32m0.69327[0m[0m | time: 1.845s
[2K
| Adam | epoch: 005 | loss: 0.69327 - acc: 0.5046 -- iter: 128/847
[A[ATraining Step: 113  | total loss: [1m[32m0.69371[0m[0m | time: 2.469s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.4942 -- iter: 160/847
[A[ATraining Step: 114  | total loss: [1m[32m0.69379[0m[0m | time: 3.069s
[2K
| Adam | epoch: 005 | loss: 0.69379 - acc: 0.4916 -- iter: 192/847
[A[ATraining Step: 115  | total loss: [1m[32m0.69336[0m[0m | time: 3.670s
[2K
| Adam | epoch: 005 | loss: 0.69336 - acc: 0.5018 -- iter: 224/847
[A[ATraining Step: 116  | total loss: [1m[32m0.69322[0m[0m | time: 4.270s
[2K
| Adam | epoch: 005 | loss: 0.69322 - acc: 0.5048 -- iter: 256/847
[A[ATraining Step: 117  | total loss: [1m[32m0.69297[0m[0m | time: 4.889s
[2K
| Adam | epoch: 005 | loss: 0.69297 - acc: 0.5105 -- iter: 288/847
[A[ATraining Step: 118  | total loss: [1m[32m0.69274[0m[0m | time: 5.526s
[2K
| Adam | epoch: 005 | loss: 0.69274 - acc: 0.5157 -- iter: 320/847
[A[ATraining Step: 119  | total loss: [1m[32m0.69306[0m[0m | time: 6.122s
[2K
| Adam | epoch: 005 | loss: 0.69306 - acc: 0.5079 -- iter: 352/847
[A[ATraining Step: 120  | total loss: [1m[32m0.69319[0m[0m | time: 6.731s
[2K
| Adam | epoch: 005 | loss: 0.69319 - acc: 0.5040 -- iter: 384/847
[A[ATraining Step: 121  | total loss: [1m[32m0.69266[0m[0m | time: 7.336s
[2K
| Adam | epoch: 005 | loss: 0.69266 - acc: 0.5161 -- iter: 416/847
[A[ATraining Step: 122  | total loss: [1m[32m0.69356[0m[0m | time: 7.927s
[2K
| Adam | epoch: 005 | loss: 0.69356 - acc: 0.4957 -- iter: 448/847
[A[ATraining Step: 123  | total loss: [1m[32m0.69378[0m[0m | time: 8.534s
[2K
| Adam | epoch: 005 | loss: 0.69378 - acc: 0.4899 -- iter: 480/847
[A[ATraining Step: 124  | total loss: [1m[32m0.69335[0m[0m | time: 9.139s
[2K
| Adam | epoch: 005 | loss: 0.69335 - acc: 0.5003 -- iter: 512/847
[A[ATraining Step: 125  | total loss: [1m[32m0.69320[0m[0m | time: 9.739s
[2K
| Adam | epoch: 005 | loss: 0.69320 - acc: 0.5034 -- iter: 544/847
[A[ATraining Step: 126  | total loss: [1m[32m0.69295[0m[0m | time: 10.341s
[2K
| Adam | epoch: 005 | loss: 0.69295 - acc: 0.5093 -- iter: 576/847
[A[ATraining Step: 127  | total loss: [1m[32m0.69298[0m[0m | time: 10.946s
[2K
| Adam | epoch: 005 | loss: 0.69298 - acc: 0.5084 -- iter: 608/847
[A[ATraining Step: 128  | total loss: [1m[32m0.69253[0m[0m | time: 11.543s
[2K
| Adam | epoch: 005 | loss: 0.69253 - acc: 0.5200 -- iter: 640/847
[A[ATraining Step: 129  | total loss: [1m[32m0.69233[0m[0m | time: 12.137s
[2K
| Adam | epoch: 005 | loss: 0.69233 - acc: 0.5243 -- iter: 672/847
[A[ATraining Step: 130  | total loss: [1m[32m0.69285[0m[0m | time: 12.738s
[2K
| Adam | epoch: 005 | loss: 0.69285 - acc: 0.5125 -- iter: 704/847
[A[ATraining Step: 131  | total loss: [1m[32m0.69231[0m[0m | time: 13.342s
[2K
| Adam | epoch: 005 | loss: 0.69231 - acc: 0.5237 -- iter: 736/847
[A[ATraining Step: 132  | total loss: [1m[32m0.69266[0m[0m | time: 13.941s
[2K
| Adam | epoch: 005 | loss: 0.69266 - acc: 0.5151 -- iter: 768/847
[A[ATraining Step: 133  | total loss: [1m[32m0.69282[0m[0m | time: 14.554s
[2K
| Adam | epoch: 005 | loss: 0.69282 - acc: 0.5105 -- iter: 800/847
[A[ATraining Step: 134  | total loss: [1m[32m0.69270[0m[0m | time: 15.120s
[2K
| Adam | epoch: 005 | loss: 0.69270 - acc: 0.5126 -- iter: 832/847
[A[ATraining Step: 135  | total loss: [1m[32m0.69287[0m[0m | time: 16.728s
[2K
| Adam | epoch: 005 | loss: 0.69287 - acc: 0.5082 | val_loss: 0.69317 - val_acc: 0.4906 -- iter: 847/847
--
Training Step: 136  | total loss: [1m[32m0.69259[0m[0m | time: 0.607s
[2K
| Adam | epoch: 006 | loss: 0.69259 - acc: 0.5136 -- iter: 032/847
[A[ATraining Step: 137  | total loss: [1m[32m0.69245[0m[0m | time: 1.194s
[2K
| Adam | epoch: 006 | loss: 0.69245 - acc: 0.5154 -- iter: 064/847
[A[ATraining Step: 138  | total loss: [1m[32m0.69290[0m[0m | time: 1.782s
[2K
| Adam | epoch: 006 | loss: 0.69290 - acc: 0.5045 -- iter: 096/847
[A[ATraining Step: 139  | total loss: [1m[32m0.69293[0m[0m | time: 2.081s
[2K
| Adam | epoch: 006 | loss: 0.69293 - acc: 0.5009 -- iter: 128/847
[A[ATraining Step: 140  | total loss: [1m[32m0.69320[0m[0m | time: 2.378s
[2K
| Adam | epoch: 006 | loss: 0.69320 - acc: 0.4908 -- iter: 160/847
[A[ATraining Step: 141  | total loss: [1m[32m0.69339[0m[0m | time: 2.989s
[2K
| Adam | epoch: 006 | loss: 0.69339 - acc: 0.4817 -- iter: 192/847
[A[ATraining Step: 142  | total loss: [1m[32m0.69311[0m[0m | time: 3.588s
[2K
| Adam | epoch: 006 | loss: 0.69311 - acc: 0.4898 -- iter: 224/847
[A[ATraining Step: 143  | total loss: [1m[32m0.69320[0m[0m | time: 4.182s
[2K
| Adam | epoch: 006 | loss: 0.69320 - acc: 0.4814 -- iter: 256/847
[A[ATraining Step: 144  | total loss: [1m[32m0.69357[0m[0m | time: 4.770s
[2K
| Adam | epoch: 006 | loss: 0.69357 - acc: 0.4583 -- iter: 288/847
[A[ATraining Step: 145  | total loss: [1m[32m0.69330[0m[0m | time: 5.364s
[2K
| Adam | epoch: 006 | loss: 0.69330 - acc: 0.4750 -- iter: 320/847
[A[ATraining Step: 146  | total loss: [1m[32m0.69346[0m[0m | time: 5.974s
[2K
| Adam | epoch: 006 | loss: 0.69346 - acc: 0.4681 -- iter: 352/847
[A[ATraining Step: 147  | total loss: [1m[32m0.69330[0m[0m | time: 6.604s
[2K
| Adam | epoch: 006 | loss: 0.69330 - acc: 0.4713 -- iter: 384/847
[A[ATraining Step: 148  | total loss: [1m[32m0.69331[0m[0m | time: 7.207s
[2K
| Adam | epoch: 006 | loss: 0.69331 - acc: 0.4648 -- iter: 416/847
[A[ATraining Step: 149  | total loss: [1m[32m0.69294[0m[0m | time: 7.803s
[2K
| Adam | epoch: 006 | loss: 0.69294 - acc: 0.4808 -- iter: 448/847
[A[ATraining Step: 150  | total loss: [1m[32m0.69267[0m[0m | time: 8.405s
[2K
| Adam | epoch: 006 | loss: 0.69267 - acc: 0.4890 -- iter: 480/847
[A[ATraining Step: 151  | total loss: [1m[32m0.69216[0m[0m | time: 8.999s
[2K
| Adam | epoch: 006 | loss: 0.69216 - acc: 0.4963 -- iter: 512/847
[A[ATraining Step: 152  | total loss: [1m[32m0.69192[0m[0m | time: 9.595s
[2K
| Adam | epoch: 006 | loss: 0.69192 - acc: 0.5029 -- iter: 544/847
[A[ATraining Step: 153  | total loss: [1m[32m0.69164[0m[0m | time: 10.197s
[2K
| Adam | epoch: 006 | loss: 0.69164 - acc: 0.5026 -- iter: 576/847
[A[ATraining Step: 154  | total loss: [1m[32m0.69094[0m[0m | time: 10.808s
[2K
| Adam | epoch: 006 | loss: 0.69094 - acc: 0.5149 -- iter: 608/847
[A[ATraining Step: 155  | total loss: [1m[32m0.69080[0m[0m | time: 11.407s
[2K
| Adam | epoch: 006 | loss: 0.69080 - acc: 0.5259 -- iter: 640/847
[A[ATraining Step: 156  | total loss: [1m[32m0.68967[0m[0m | time: 12.014s
[2K
| Adam | epoch: 006 | loss: 0.68967 - acc: 0.5327 -- iter: 672/847
[A[ATraining Step: 157  | total loss: [1m[32m0.69015[0m[0m | time: 12.612s
[2K
| Adam | epoch: 006 | loss: 0.69015 - acc: 0.5232 -- iter: 704/847
[A[ATraining Step: 158  | total loss: [1m[32m0.68936[0m[0m | time: 13.226s
[2K
| Adam | epoch: 006 | loss: 0.68936 - acc: 0.5271 -- iter: 736/847
[A[ATraining Step: 159  | total loss: [1m[32m0.68749[0m[0m | time: 13.831s
[2K
| Adam | epoch: 006 | loss: 0.68749 - acc: 0.5494 -- iter: 768/847
[A[ATraining Step: 160  | total loss: [1m[32m0.68591[0m[0m | time: 14.423s
[2K
| Adam | epoch: 006 | loss: 0.68591 - acc: 0.5601 -- iter: 800/847
[A[ATraining Step: 161  | total loss: [1m[32m0.68331[0m[0m | time: 15.023s
[2K
| Adam | epoch: 006 | loss: 0.68331 - acc: 0.5697 -- iter: 832/847
[A[ATraining Step: 162  | total loss: [1m[32m0.67915[0m[0m | time: 16.638s
[2K
| Adam | epoch: 006 | loss: 0.67915 - acc: 0.5846 | val_loss: 0.71067 - val_acc: 0.4906 -- iter: 847/847
--
Training Step: 163  | total loss: [1m[32m0.67466[0m[0m | time: 0.595s
[2K
| Adam | epoch: 007 | loss: 0.67466 - acc: 0.5949 -- iter: 032/847
[A[ATraining Step: 164  | total loss: [1m[32m0.67351[0m[0m | time: 1.179s
[2K
| Adam | epoch: 007 | loss: 0.67351 - acc: 0.5916 -- iter: 064/847
[A[ATraining Step: 165  | total loss: [1m[32m0.68288[0m[0m | time: 1.776s
[2K
| Adam | epoch: 007 | loss: 0.68288 - acc: 0.5700 -- iter: 096/847
[A[ATraining Step: 166  | total loss: [1m[32m0.68004[0m[0m | time: 2.378s
[2K
| Adam | epoch: 007 | loss: 0.68004 - acc: 0.5849 -- iter: 128/847
[A[ATraining Step: 167  | total loss: [1m[32m0.67902[0m[0m | time: 2.690s
[2K
| Adam | epoch: 007 | loss: 0.67902 - acc: 0.5951 -- iter: 160/847
[A[ATraining Step: 168  | total loss: [1m[32m0.67796[0m[0m | time: 2.988s
[2K
| Adam | epoch: 007 | loss: 0.67796 - acc: 0.5889 -- iter: 192/847
[A[ATraining Step: 169  | total loss: [1m[32m0.67695[0m[0m | time: 3.584s
[2K
| Adam | epoch: 007 | loss: 0.67695 - acc: 0.5834 -- iter: 224/847
[A[ATraining Step: 170  | total loss: [1m[32m0.66908[0m[0m | time: 4.186s
[2K
| Adam | epoch: 007 | loss: 0.66908 - acc: 0.5969 -- iter: 256/847
[A[ATraining Step: 171  | total loss: [1m[32m0.66342[0m[0m | time: 4.780s
[2K
| Adam | epoch: 007 | loss: 0.66342 - acc: 0.6154 -- iter: 288/847
[A[ATraining Step: 172  | total loss: [1m[32m0.66004[0m[0m | time: 5.372s
[2K
| Adam | epoch: 007 | loss: 0.66004 - acc: 0.6194 -- iter: 320/847
[A[ATraining Step: 173  | total loss: [1m[32m0.65890[0m[0m | time: 5.954s
[2K
| Adam | epoch: 007 | loss: 0.65890 - acc: 0.6200 -- iter: 352/847
[A[ATraining Step: 174  | total loss: [1m[32m0.65347[0m[0m | time: 6.534s
[2K
| Adam | epoch: 007 | loss: 0.65347 - acc: 0.6330 -- iter: 384/847
[A[ATraining Step: 175  | total loss: [1m[32m0.65434[0m[0m | time: 7.134s
[2K
| Adam | epoch: 007 | loss: 0.65434 - acc: 0.6228 -- iter: 416/847
[A[ATraining Step: 176  | total loss: [1m[32m0.64648[0m[0m | time: 7.733s
[2K
| Adam | epoch: 007 | loss: 0.64648 - acc: 0.6355 -- iter: 448/847
[A[ATraining Step: 177  | total loss: [1m[32m0.64382[0m[0m | time: 8.342s
[2K
| Adam | epoch: 007 | loss: 0.64382 - acc: 0.6407 -- iter: 480/847
[A[ATraining Step: 178  | total loss: [1m[32m0.64357[0m[0m | time: 8.967s
[2K
| Adam | epoch: 007 | loss: 0.64357 - acc: 0.6329 -- iter: 512/847
[A[ATraining Step: 179  | total loss: [1m[32m0.64117[0m[0m | time: 9.568s
[2K
| Adam | epoch: 007 | loss: 0.64117 - acc: 0.6477 -- iter: 544/847
[A[ATraining Step: 180  | total loss: [1m[32m0.64496[0m[0m | time: 10.174s
[2K
| Adam | epoch: 007 | loss: 0.64496 - acc: 0.6392 -- iter: 576/847
[A[ATraining Step: 181  | total loss: [1m[32m0.64176[0m[0m | time: 10.771s
[2K
| Adam | epoch: 007 | loss: 0.64176 - acc: 0.6378 -- iter: 608/847
[A[ATraining Step: 182  | total loss: [1m[32m0.63981[0m[0m | time: 11.367s
[2K
| Adam | epoch: 007 | loss: 0.63981 - acc: 0.6365 -- iter: 640/847
[A[ATraining Step: 183  | total loss: [1m[32m0.63287[0m[0m | time: 12.003s
[2K
| Adam | epoch: 007 | loss: 0.63287 - acc: 0.6447 -- iter: 672/847
[A[ATraining Step: 184  | total loss: [1m[32m0.63026[0m[0m | time: 12.608s
[2K
| Adam | epoch: 007 | loss: 0.63026 - acc: 0.6490 -- iter: 704/847
[A[ATraining Step: 185  | total loss: [1m[32m0.62790[0m[0m | time: 13.225s
[2K
| Adam | epoch: 007 | loss: 0.62790 - acc: 0.6560 -- iter: 736/847
[A[ATraining Step: 186  | total loss: [1m[32m0.62656[0m[0m | time: 13.834s
[2K
| Adam | epoch: 007 | loss: 0.62656 - acc: 0.6623 -- iter: 768/847
[A[ATraining Step: 187  | total loss: [1m[32m0.62178[0m[0m | time: 14.435s
[2K
| Adam | epoch: 007 | loss: 0.62178 - acc: 0.6742 -- iter: 800/847
[A[ATraining Step: 188  | total loss: [1m[32m0.61423[0m[0m | time: 15.039s
[2K
| Adam | epoch: 007 | loss: 0.61423 - acc: 0.6817 -- iter: 832/847
[A[ATraining Step: 189  | total loss: [1m[32m0.60130[0m[0m | time: 16.638s
[2K
| Adam | epoch: 007 | loss: 0.60130 - acc: 0.6917 | val_loss: 0.54718 - val_acc: 0.7434 -- iter: 847/847
--
Training Step: 190  | total loss: [1m[32m0.60198[0m[0m | time: 0.607s
[2K
| Adam | epoch: 008 | loss: 0.60198 - acc: 0.6913 -- iter: 032/847
[A[ATraining Step: 191  | total loss: [1m[32m0.58485[0m[0m | time: 1.217s
[2K
| Adam | epoch: 008 | loss: 0.58485 - acc: 0.7065 -- iter: 064/847
[A[ATraining Step: 192  | total loss: [1m[32m0.57712[0m[0m | time: 1.841s
[2K
| Adam | epoch: 008 | loss: 0.57712 - acc: 0.7109 -- iter: 096/847
[A[ATraining Step: 193  | total loss: [1m[32m0.57021[0m[0m | time: 2.467s
[2K
| Adam | epoch: 008 | loss: 0.57021 - acc: 0.7148 -- iter: 128/847
[A[ATraining Step: 194  | total loss: [1m[32m0.56557[0m[0m | time: 3.078s
[2K
| Adam | epoch: 008 | loss: 0.56557 - acc: 0.7214 -- iter: 160/847
[A[ATraining Step: 195  | total loss: [1m[32m0.58098[0m[0m | time: 3.399s
[2K
| Adam | epoch: 008 | loss: 0.58098 - acc: 0.7180 -- iter: 192/847
[A[ATraining Step: 196  | total loss: [1m[32m0.57979[0m[0m | time: 3.697s
[2K
| Adam | epoch: 008 | loss: 0.57979 - acc: 0.7062 -- iter: 224/847
[A[ATraining Step: 197  | total loss: [1m[32m0.55933[0m[0m | time: 4.320s
[2K
| Adam | epoch: 008 | loss: 0.55933 - acc: 0.7223 -- iter: 256/847
[A[ATraining Step: 198  | total loss: [1m[32m0.56166[0m[0m | time: 4.912s
[2K
| Adam | epoch: 008 | loss: 0.56166 - acc: 0.7282 -- iter: 288/847
[A[ATraining Step: 199  | total loss: [1m[32m0.54869[0m[0m | time: 5.511s
[2K
| Adam | epoch: 008 | loss: 0.54869 - acc: 0.7366 -- iter: 320/847
[A[ATraining Step: 200  | total loss: [1m[32m0.54600[0m[0m | time: 7.110s
[2K
| Adam | epoch: 008 | loss: 0.54600 - acc: 0.7411 | val_loss: 0.55035 - val_acc: 0.7245 -- iter: 352/847
--
Training Step: 201  | total loss: [1m[32m0.56135[0m[0m | time: 7.706s
[2K
| Adam | epoch: 008 | loss: 0.56135 - acc: 0.7388 -- iter: 384/847
[A[ATraining Step: 202  | total loss: [1m[32m0.55676[0m[0m | time: 8.326s
[2K
| Adam | epoch: 008 | loss: 0.55676 - acc: 0.7337 -- iter: 416/847
[A[ATraining Step: 203  | total loss: [1m[32m0.56474[0m[0m | time: 8.913s
[2K
| Adam | epoch: 008 | loss: 0.56474 - acc: 0.7228 -- iter: 448/847
[A[ATraining Step: 204  | total loss: [1m[32m0.55773[0m[0m | time: 9.513s
[2K
| Adam | epoch: 008 | loss: 0.55773 - acc: 0.7256 -- iter: 480/847
[A[ATraining Step: 205  | total loss: [1m[32m0.56799[0m[0m | time: 10.134s
[2K
| Adam | epoch: 008 | loss: 0.56799 - acc: 0.7249 -- iter: 512/847
[A[ATraining Step: 206  | total loss: [1m[32m0.56444[0m[0m | time: 10.731s
[2K
| Adam | epoch: 008 | loss: 0.56444 - acc: 0.7211 -- iter: 544/847
[A[ATraining Step: 207  | total loss: [1m[32m0.55787[0m[0m | time: 11.325s
[2K
| Adam | epoch: 008 | loss: 0.55787 - acc: 0.7271 -- iter: 576/847
[A[ATraining Step: 208  | total loss: [1m[32m0.54089[0m[0m | time: 11.919s
[2K
| Adam | epoch: 008 | loss: 0.54089 - acc: 0.7482 -- iter: 608/847
[A[ATraining Step: 209  | total loss: [1m[32m0.54478[0m[0m | time: 12.527s
[2K
| Adam | epoch: 008 | loss: 0.54478 - acc: 0.7421 -- iter: 640/847
[A[ATraining Step: 210  | total loss: [1m[32m0.53497[0m[0m | time: 13.128s
[2K
| Adam | epoch: 008 | loss: 0.53497 - acc: 0.7460 -- iter: 672/847
[A[ATraining Step: 211  | total loss: [1m[32m0.53572[0m[0m | time: 13.727s
[2K
| Adam | epoch: 008 | loss: 0.53572 - acc: 0.7433 -- iter: 704/847
[A[ATraining Step: 212  | total loss: [1m[32m0.53342[0m[0m | time: 14.341s
[2K
| Adam | epoch: 008 | loss: 0.53342 - acc: 0.7408 -- iter: 736/847
[A[ATraining Step: 213  | total loss: [1m[32m0.52688[0m[0m | time: 14.968s
[2K
| Adam | epoch: 008 | loss: 0.52688 - acc: 0.7449 -- iter: 768/847
[A[ATraining Step: 214  | total loss: [1m[32m0.52426[0m[0m | time: 15.570s
[2K
| Adam | epoch: 008 | loss: 0.52426 - acc: 0.7485 -- iter: 800/847
[A[ATraining Step: 215  | total loss: [1m[32m0.51799[0m[0m | time: 16.167s
[2K
| Adam | epoch: 008 | loss: 0.51799 - acc: 0.7549 -- iter: 832/847
[A[ATraining Step: 216  | total loss: [1m[32m0.51518[0m[0m | time: 17.783s
[2K
| Adam | epoch: 008 | loss: 0.51518 - acc: 0.7513 | val_loss: 0.50876 - val_acc: 0.7547 -- iter: 847/847
--
Training Step: 217  | total loss: [1m[32m0.50920[0m[0m | time: 0.602s
[2K
| Adam | epoch: 009 | loss: 0.50920 - acc: 0.7605 -- iter: 032/847
[A[ATraining Step: 218  | total loss: [1m[32m0.52526[0m[0m | time: 1.203s
[2K
| Adam | epoch: 009 | loss: 0.52526 - acc: 0.7470 -- iter: 064/847
[A[ATraining Step: 219  | total loss: [1m[32m0.51627[0m[0m | time: 1.806s
[2K
| Adam | epoch: 009 | loss: 0.51627 - acc: 0.7535 -- iter: 096/847
[A[ATraining Step: 220  | total loss: [1m[32m0.50601[0m[0m | time: 2.406s
[2K
| Adam | epoch: 009 | loss: 0.50601 - acc: 0.7563 -- iter: 128/847
[A[ATraining Step: 221  | total loss: [1m[32m0.51056[0m[0m | time: 3.002s
[2K
| Adam | epoch: 009 | loss: 0.51056 - acc: 0.7526 -- iter: 160/847
[A[ATraining Step: 222  | total loss: [1m[32m0.51020[0m[0m | time: 3.603s
[2K
| Adam | epoch: 009 | loss: 0.51020 - acc: 0.7617 -- iter: 192/847
[A[ATraining Step: 223  | total loss: [1m[32m0.51325[0m[0m | time: 3.899s
[2K
| Adam | epoch: 009 | loss: 0.51325 - acc: 0.7605 -- iter: 224/847
[A[ATraining Step: 224  | total loss: [1m[32m0.50940[0m[0m | time: 4.212s
[2K
| Adam | epoch: 009 | loss: 0.50940 - acc: 0.7578 -- iter: 256/847
[A[ATraining Step: 225  | total loss: [1m[32m0.50557[0m[0m | time: 4.812s
[2K
| Adam | epoch: 009 | loss: 0.50557 - acc: 0.7620 -- iter: 288/847
[A[ATraining Step: 226  | total loss: [1m[32m0.50023[0m[0m | time: 5.420s
[2K
| Adam | epoch: 009 | loss: 0.50023 - acc: 0.7671 -- iter: 320/847
[A[ATraining Step: 227  | total loss: [1m[32m0.49255[0m[0m | time: 6.045s
[2K
| Adam | epoch: 009 | loss: 0.49255 - acc: 0.7779 -- iter: 352/847
[A[ATraining Step: 228  | total loss: [1m[32m0.49159[0m[0m | time: 6.646s
[2K
| Adam | epoch: 009 | loss: 0.49159 - acc: 0.7688 -- iter: 384/847
[A[ATraining Step: 229  | total loss: [1m[32m0.49885[0m[0m | time: 7.256s
[2K
| Adam | epoch: 009 | loss: 0.49885 - acc: 0.7513 -- iter: 416/847
[A[ATraining Step: 230  | total loss: [1m[32m0.49052[0m[0m | time: 7.846s
[2K
| Adam | epoch: 009 | loss: 0.49052 - acc: 0.7543 -- iter: 448/847
[A[ATraining Step: 231  | total loss: [1m[32m0.50215[0m[0m | time: 8.442s
[2K
| Adam | epoch: 009 | loss: 0.50215 - acc: 0.7445 -- iter: 480/847
[A[ATraining Step: 232  | total loss: [1m[32m0.49730[0m[0m | time: 9.066s
[2K
| Adam | epoch: 009 | loss: 0.49730 - acc: 0.7482 -- iter: 512/847
[A[ATraining Step: 233  | total loss: [1m[32m0.49284[0m[0m | time: 9.662s
[2K
| Adam | epoch: 009 | loss: 0.49284 - acc: 0.7515 -- iter: 544/847
[A[ATraining Step: 234  | total loss: [1m[32m0.49636[0m[0m | time: 10.259s
[2K
| Adam | epoch: 009 | loss: 0.49636 - acc: 0.7513 -- iter: 576/847
[A[ATraining Step: 235  | total loss: [1m[32m0.47492[0m[0m | time: 10.853s
[2K
| Adam | epoch: 009 | loss: 0.47492 - acc: 0.7731 -- iter: 608/847
[A[ATraining Step: 236  | total loss: [1m[32m0.49302[0m[0m | time: 11.482s
[2K
| Adam | epoch: 009 | loss: 0.49302 - acc: 0.7645 -- iter: 640/847
[A[ATraining Step: 237  | total loss: [1m[32m0.49366[0m[0m | time: 12.097s
[2K
| Adam | epoch: 009 | loss: 0.49366 - acc: 0.7631 -- iter: 672/847
[A[ATraining Step: 238  | total loss: [1m[32m0.49390[0m[0m | time: 12.694s
[2K
| Adam | epoch: 009 | loss: 0.49390 - acc: 0.7680 -- iter: 704/847
[A[ATraining Step: 239  | total loss: [1m[32m0.50295[0m[0m | time: 13.299s
[2K
| Adam | epoch: 009 | loss: 0.50295 - acc: 0.7662 -- iter: 736/847
[A[ATraining Step: 240  | total loss: [1m[32m0.49365[0m[0m | time: 13.899s
[2K
| Adam | epoch: 009 | loss: 0.49365 - acc: 0.7708 -- iter: 768/847
[A[ATraining Step: 241  | total loss: [1m[32m0.49657[0m[0m | time: 14.505s
[2K
| Adam | epoch: 009 | loss: 0.49657 - acc: 0.7688 -- iter: 800/847
[A[ATraining Step: 242  | total loss: [1m[32m0.48020[0m[0m | time: 15.111s
[2K
| Adam | epoch: 009 | loss: 0.48020 - acc: 0.7794 -- iter: 832/847
[A[ATraining Step: 243  | total loss: [1m[32m0.47315[0m[0m | time: 16.714s
[2K
| Adam | epoch: 009 | loss: 0.47315 - acc: 0.7764 | val_loss: 0.48682 - val_acc: 0.7547 -- iter: 847/847
--
Training Step: 244  | total loss: [1m[32m0.46286[0m[0m | time: 0.608s
[2K
| Adam | epoch: 010 | loss: 0.46286 - acc: 0.7769 -- iter: 032/847
[A[ATraining Step: 245  | total loss: [1m[32m0.45732[0m[0m | time: 1.245s
[2K
| Adam | epoch: 010 | loss: 0.45732 - acc: 0.7836 -- iter: 064/847
[A[ATraining Step: 246  | total loss: [1m[32m0.45954[0m[0m | time: 1.856s
[2K
| Adam | epoch: 010 | loss: 0.45954 - acc: 0.7802 -- iter: 096/847
[A[ATraining Step: 247  | total loss: [1m[32m0.45721[0m[0m | time: 2.469s
[2K
| Adam | epoch: 010 | loss: 0.45721 - acc: 0.7803 -- iter: 128/847
[A[ATraining Step: 248  | total loss: [1m[32m0.44079[0m[0m | time: 3.073s
[2K
| Adam | epoch: 010 | loss: 0.44079 - acc: 0.7929 -- iter: 160/847
[A[ATraining Step: 249  | total loss: [1m[32m0.44174[0m[0m | time: 3.677s
[2K
| Adam | epoch: 010 | loss: 0.44174 - acc: 0.7949 -- iter: 192/847
[A[ATraining Step: 250  | total loss: [1m[32m0.43150[0m[0m | time: 4.297s
[2K
| Adam | epoch: 010 | loss: 0.43150 - acc: 0.7967 -- iter: 224/847
[A[ATraining Step: 251  | total loss: [1m[32m0.44482[0m[0m | time: 4.609s
[2K
| Adam | epoch: 010 | loss: 0.44482 - acc: 0.7826 -- iter: 256/847
[A[ATraining Step: 252  | total loss: [1m[32m0.43667[0m[0m | time: 4.916s
[2K
| Adam | epoch: 010 | loss: 0.43667 - acc: 0.7844 -- iter: 288/847
[A[ATraining Step: 253  | total loss: [1m[32m0.42647[0m[0m | time: 5.518s
[2K
| Adam | epoch: 010 | loss: 0.42647 - acc: 0.7926 -- iter: 320/847
[A[ATraining Step: 254  | total loss: [1m[32m0.42604[0m[0m | time: 6.120s
[2K
| Adam | epoch: 010 | loss: 0.42604 - acc: 0.7914 -- iter: 352/847
[A[ATraining Step: 255  | total loss: [1m[32m0.42845[0m[0m | time: 6.712s
[2K
| Adam | epoch: 010 | loss: 0.42845 - acc: 0.7936 -- iter: 384/847
[A[ATraining Step: 256  | total loss: [1m[32m0.43023[0m[0m | time: 7.304s
[2K
| Adam | epoch: 010 | loss: 0.43023 - acc: 0.7986 -- iter: 416/847
[A[ATraining Step: 257  | total loss: [1m[32m0.42873[0m[0m | time: 7.897s
[2K
| Adam | epoch: 010 | loss: 0.42873 - acc: 0.8062 -- iter: 448/847
[A[ATraining Step: 258  | total loss: [1m[32m0.43678[0m[0m | time: 8.492s
[2K
| Adam | epoch: 010 | loss: 0.43678 - acc: 0.7975 -- iter: 480/847
[A[ATraining Step: 259  | total loss: [1m[32m0.44918[0m[0m | time: 9.102s
[2K
| Adam | epoch: 010 | loss: 0.44918 - acc: 0.7990 -- iter: 512/847
[A[ATraining Step: 260  | total loss: [1m[32m0.48111[0m[0m | time: 9.701s
[2K
| Adam | epoch: 010 | loss: 0.48111 - acc: 0.7847 -- iter: 544/847
[A[ATraining Step: 261  | total loss: [1m[32m0.48398[0m[0m | time: 10.287s
[2K
| Adam | epoch: 010 | loss: 0.48398 - acc: 0.7812 -- iter: 576/847
[A[ATraining Step: 262  | total loss: [1m[32m0.48342[0m[0m | time: 10.879s
[2K
| Adam | epoch: 010 | loss: 0.48342 - acc: 0.7812 -- iter: 608/847
[A[ATraining Step: 263  | total loss: [1m[32m0.47808[0m[0m | time: 11.468s
[2K
| Adam | epoch: 010 | loss: 0.47808 - acc: 0.7812 -- iter: 640/847
[A[ATraining Step: 264  | total loss: [1m[32m0.47314[0m[0m | time: 12.060s
[2K
| Adam | epoch: 010 | loss: 0.47314 - acc: 0.7844 -- iter: 672/847
[A[ATraining Step: 265  | total loss: [1m[32m0.46018[0m[0m | time: 12.640s
[2K
| Adam | epoch: 010 | loss: 0.46018 - acc: 0.7965 -- iter: 704/847
[A[ATraining Step: 266  | total loss: [1m[32m0.45272[0m[0m | time: 13.244s
[2K
| Adam | epoch: 010 | loss: 0.45272 - acc: 0.8044 -- iter: 736/847
[A[ATraining Step: 267  | total loss: [1m[32m0.45135[0m[0m | time: 13.838s
[2K
| Adam | epoch: 010 | loss: 0.45135 - acc: 0.7990 -- iter: 768/847
[A[ATraining Step: 268  | total loss: [1m[32m0.43864[0m[0m | time: 14.449s
[2K
| Adam | epoch: 010 | loss: 0.43864 - acc: 0.8066 -- iter: 800/847
[A[ATraining Step: 269  | total loss: [1m[32m0.42523[0m[0m | time: 15.070s
[2K
| Adam | epoch: 010 | loss: 0.42523 - acc: 0.8165 -- iter: 832/847
[A[ATraining Step: 270  | total loss: [1m[32m0.43198[0m[0m | time: 16.677s
[2K
| Adam | epoch: 010 | loss: 0.43198 - acc: 0.8099 | val_loss: 0.45421 - val_acc: 0.7698 -- iter: 847/847
--
Training Step: 271  | total loss: [1m[32m0.43467[0m[0m | time: 0.603s
[2K
| Adam | epoch: 011 | loss: 0.43467 - acc: 0.8070 -- iter: 032/847
[A[ATraining Step: 272  | total loss: [1m[32m0.43436[0m[0m | time: 1.187s
[2K
| Adam | epoch: 011 | loss: 0.43436 - acc: 0.8107 -- iter: 064/847
[A[ATraining Step: 273  | total loss: [1m[32m0.42787[0m[0m | time: 1.800s
[2K
| Adam | epoch: 011 | loss: 0.42787 - acc: 0.8140 -- iter: 096/847
[A[ATraining Step: 274  | total loss: [1m[32m0.41671[0m[0m | time: 2.391s
[2K
| Adam | epoch: 011 | loss: 0.41671 - acc: 0.8201 -- iter: 128/847
[A[ATraining Step: 275  | total loss: [1m[32m0.40326[0m[0m | time: 3.012s
[2K
| Adam | epoch: 011 | loss: 0.40326 - acc: 0.8287 -- iter: 160/847
[A[ATraining Step: 276  | total loss: [1m[32m0.40232[0m[0m | time: 3.619s
[2K
| Adam | epoch: 011 | loss: 0.40232 - acc: 0.8302 -- iter: 192/847
[A[ATraining Step: 277  | total loss: [1m[32m0.39831[0m[0m | time: 4.241s
[2K
| Adam | epoch: 011 | loss: 0.39831 - acc: 0.8284 -- iter: 224/847
[A[ATraining Step: 278  | total loss: [1m[32m0.39705[0m[0m | time: 4.830s
[2K
| Adam | epoch: 011 | loss: 0.39705 - acc: 0.8300 -- iter: 256/847
[A[ATraining Step: 279  | total loss: [1m[32m0.38116[0m[0m | time: 5.152s
[2K
| Adam | epoch: 011 | loss: 0.38116 - acc: 0.8376 -- iter: 288/847
[A[ATraining Step: 280  | total loss: [1m[32m0.43528[0m[0m | time: 5.488s
[2K
| Adam | epoch: 011 | loss: 0.43528 - acc: 0.8138 -- iter: 320/847
[A[ATraining Step: 281  | total loss: [1m[32m0.47084[0m[0m | time: 6.085s
[2K
| Adam | epoch: 011 | loss: 0.47084 - acc: 0.7991 -- iter: 352/847
[A[ATraining Step: 282  | total loss: [1m[32m0.45047[0m[0m | time: 6.694s
[2K
| Adam | epoch: 011 | loss: 0.45047 - acc: 0.8130 -- iter: 384/847
[A[ATraining Step: 283  | total loss: [1m[32m0.45679[0m[0m | time: 7.284s
[2K
| Adam | epoch: 011 | loss: 0.45679 - acc: 0.8004 -- iter: 416/847
[A[ATraining Step: 284  | total loss: [1m[32m0.45105[0m[0m | time: 7.897s
[2K
| Adam | epoch: 011 | loss: 0.45105 - acc: 0.8047 -- iter: 448/847
[A[ATraining Step: 285  | total loss: [1m[32m0.43225[0m[0m | time: 8.484s
[2K
| Adam | epoch: 011 | loss: 0.43225 - acc: 0.8149 -- iter: 480/847
[A[ATraining Step: 286  | total loss: [1m[32m0.41279[0m[0m | time: 9.083s
[2K
| Adam | epoch: 011 | loss: 0.41279 - acc: 0.8303 -- iter: 512/847
[A[ATraining Step: 287  | total loss: [1m[32m0.41072[0m[0m | time: 9.683s
[2K
| Adam | epoch: 011 | loss: 0.41072 - acc: 0.8285 -- iter: 544/847
[A[ATraining Step: 288  | total loss: [1m[32m0.41174[0m[0m | time: 10.273s
[2K
| Adam | epoch: 011 | loss: 0.41174 - acc: 0.8238 -- iter: 576/847
[A[ATraining Step: 289  | total loss: [1m[32m0.39824[0m[0m | time: 10.900s
[2K
| Adam | epoch: 011 | loss: 0.39824 - acc: 0.8352 -- iter: 608/847
[A[ATraining Step: 290  | total loss: [1m[32m0.39071[0m[0m | time: 11.495s
[2K
| Adam | epoch: 011 | loss: 0.39071 - acc: 0.8454 -- iter: 640/847
[A[ATraining Step: 291  | total loss: [1m[32m0.38531[0m[0m | time: 12.098s
[2K
| Adam | epoch: 011 | loss: 0.38531 - acc: 0.8483 -- iter: 672/847
[A[ATraining Step: 292  | total loss: [1m[32m0.38779[0m[0m | time: 12.712s
[2K
| Adam | epoch: 011 | loss: 0.38779 - acc: 0.8448 -- iter: 704/847
[A[ATraining Step: 293  | total loss: [1m[32m0.37713[0m[0m | time: 13.309s
[2K
| Adam | epoch: 011 | loss: 0.37713 - acc: 0.8509 -- iter: 736/847
[A[ATraining Step: 294  | total loss: [1m[32m0.36750[0m[0m | time: 13.914s
[2K
| Adam | epoch: 011 | loss: 0.36750 - acc: 0.8596 -- iter: 768/847
[A[ATraining Step: 295  | total loss: [1m[32m0.37290[0m[0m | time: 14.514s
[2K
| Adam | epoch: 011 | loss: 0.37290 - acc: 0.8517 -- iter: 800/847
[A[ATraining Step: 296  | total loss: [1m[32m0.35382[0m[0m | time: 15.111s
[2K
| Adam | epoch: 011 | loss: 0.35382 - acc: 0.8634 -- iter: 832/847
[A[ATraining Step: 297  | total loss: [1m[32m0.34347[0m[0m | time: 16.709s
[2K
| Adam | epoch: 011 | loss: 0.34347 - acc: 0.8708 | val_loss: 0.68941 - val_acc: 0.6830 -- iter: 847/847
--
Training Step: 298  | total loss: [1m[32m0.37410[0m[0m | time: 0.606s
[2K
| Adam | epoch: 012 | loss: 0.37410 - acc: 0.8494 -- iter: 032/847
[A[ATraining Step: 299  | total loss: [1m[32m0.42073[0m[0m | time: 1.225s
[2K
| Adam | epoch: 012 | loss: 0.42073 - acc: 0.8269 -- iter: 064/847
[A[ATraining Step: 300  | total loss: [1m[32m0.43571[0m[0m | time: 1.832s
[2K
| Adam | epoch: 012 | loss: 0.43571 - acc: 0.8224 -- iter: 096/847
[A[ATraining Step: 301  | total loss: [1m[32m0.43427[0m[0m | time: 2.456s
[2K
| Adam | epoch: 012 | loss: 0.43427 - acc: 0.8151 -- iter: 128/847
[A[ATraining Step: 302  | total loss: [1m[32m0.41764[0m[0m | time: 3.038s
[2K
| Adam | epoch: 012 | loss: 0.41764 - acc: 0.8243 -- iter: 160/847
[A[ATraining Step: 303  | total loss: [1m[32m0.42478[0m[0m | time: 3.650s
[2K
| Adam | epoch: 012 | loss: 0.42478 - acc: 0.8200 -- iter: 192/847
[A[ATraining Step: 304  | total loss: [1m[32m0.42153[0m[0m | time: 4.248s
[2K
| Adam | epoch: 012 | loss: 0.42153 - acc: 0.8255 -- iter: 224/847
[A[ATraining Step: 305  | total loss: [1m[32m0.42719[0m[0m | time: 4.856s
[2K
| Adam | epoch: 012 | loss: 0.42719 - acc: 0.8210 -- iter: 256/847
[A[ATraining Step: 306  | total loss: [1m[32m0.41409[0m[0m | time: 5.456s
[2K
| Adam | epoch: 012 | loss: 0.41409 - acc: 0.8264 -- iter: 288/847
[A[ATraining Step: 307  | total loss: [1m[32m0.39678[0m[0m | time: 5.774s
[2K
| Adam | epoch: 012 | loss: 0.39678 - acc: 0.8313 -- iter: 320/847
[A[ATraining Step: 308  | total loss: [1m[32m0.36763[0m[0m | time: 6.074s
[2K
| Adam | epoch: 012 | loss: 0.36763 - acc: 0.8415 -- iter: 352/847
[A[ATraining Step: 309  | total loss: [1m[32m0.34344[0m[0m | time: 6.684s
[2K
| Adam | epoch: 012 | loss: 0.34344 - acc: 0.8507 -- iter: 384/847
[A[ATraining Step: 310  | total loss: [1m[32m0.39208[0m[0m | time: 7.302s
[2K
| Adam | epoch: 012 | loss: 0.39208 - acc: 0.8312 -- iter: 416/847
[A[ATraining Step: 311  | total loss: [1m[32m0.41737[0m[0m | time: 7.907s
[2K
| Adam | epoch: 012 | loss: 0.41737 - acc: 0.8200 -- iter: 448/847
[A[ATraining Step: 312  | total loss: [1m[32m0.40834[0m[0m | time: 8.506s
[2K
| Adam | epoch: 012 | loss: 0.40834 - acc: 0.8255 -- iter: 480/847
[A[ATraining Step: 313  | total loss: [1m[32m0.40969[0m[0m | time: 9.094s
[2K
| Adam | epoch: 012 | loss: 0.40969 - acc: 0.8211 -- iter: 512/847
[A[ATraining Step: 314  | total loss: [1m[32m0.40397[0m[0m | time: 9.704s
[2K
| Adam | epoch: 012 | loss: 0.40397 - acc: 0.8233 -- iter: 544/847
[A[ATraining Step: 315  | total loss: [1m[32m0.42105[0m[0m | time: 10.314s
[2K
| Adam | epoch: 012 | loss: 0.42105 - acc: 0.8004 -- iter: 576/847
[A[ATraining Step: 316  | total loss: [1m[32m0.43892[0m[0m | time: 10.949s
[2K
| Adam | epoch: 012 | loss: 0.43892 - acc: 0.7891 -- iter: 608/847
[A[ATraining Step: 317  | total loss: [1m[32m0.44878[0m[0m | time: 11.572s
[2K
| Adam | epoch: 012 | loss: 0.44878 - acc: 0.7852 -- iter: 640/847
[A[ATraining Step: 318  | total loss: [1m[32m0.42358[0m[0m | time: 12.178s
[2K
| Adam | epoch: 012 | loss: 0.42358 - acc: 0.8035 -- iter: 672/847
[A[ATraining Step: 319  | total loss: [1m[32m0.41167[0m[0m | time: 12.802s
[2K
| Adam | epoch: 012 | loss: 0.41167 - acc: 0.8138 -- iter: 704/847
[A[ATraining Step: 320  | total loss: [1m[32m0.41067[0m[0m | time: 13.393s
[2K
| Adam | epoch: 012 | loss: 0.41067 - acc: 0.8137 -- iter: 736/847
[A[ATraining Step: 321  | total loss: [1m[32m0.39964[0m[0m | time: 14.006s
[2K
| Adam | epoch: 012 | loss: 0.39964 - acc: 0.8198 -- iter: 768/847
[A[ATraining Step: 322  | total loss: [1m[32m0.39083[0m[0m | time: 14.612s
[2K
| Adam | epoch: 012 | loss: 0.39083 - acc: 0.8253 -- iter: 800/847
[A[ATraining Step: 323  | total loss: [1m[32m0.38826[0m[0m | time: 15.205s
[2K
| Adam | epoch: 012 | loss: 0.38826 - acc: 0.8240 -- iter: 832/847
[A[ATraining Step: 324  | total loss: [1m[32m0.39423[0m[0m | time: 16.812s
[2K
| Adam | epoch: 012 | loss: 0.39423 - acc: 0.8166 | val_loss: 0.49026 - val_acc: 0.7736 -- iter: 847/847
--
Training Step: 325  | total loss: [1m[32m0.37661[0m[0m | time: 0.616s
[2K
| Adam | epoch: 013 | loss: 0.37661 - acc: 0.8287 -- iter: 032/847
[A[ATraining Step: 326  | total loss: [1m[32m0.37447[0m[0m | time: 1.213s
[2K
| Adam | epoch: 013 | loss: 0.37447 - acc: 0.8365 -- iter: 064/847
[A[ATraining Step: 327  | total loss: [1m[32m0.37209[0m[0m | time: 1.814s
[2K
| Adam | epoch: 013 | loss: 0.37209 - acc: 0.8341 -- iter: 096/847
[A[ATraining Step: 328  | total loss: [1m[32m0.36476[0m[0m | time: 2.435s
[2K
| Adam | epoch: 013 | loss: 0.36476 - acc: 0.8413 -- iter: 128/847
[A[ATraining Step: 329  | total loss: [1m[32m0.35913[0m[0m | time: 3.056s
[2K
| Adam | epoch: 013 | loss: 0.35913 - acc: 0.8447 -- iter: 160/847
[A[ATraining Step: 330  | total loss: [1m[32m0.36096[0m[0m | time: 3.654s
[2K
| Adam | epoch: 013 | loss: 0.36096 - acc: 0.8446 -- iter: 192/847
[A[ATraining Step: 331  | total loss: [1m[32m0.36553[0m[0m | time: 4.259s
[2K
| Adam | epoch: 013 | loss: 0.36553 - acc: 0.8414 -- iter: 224/847
[A[ATraining Step: 332  | total loss: [1m[32m0.38450[0m[0m | time: 4.855s
[2K
| Adam | epoch: 013 | loss: 0.38450 - acc: 0.8354 -- iter: 256/847
[A[ATraining Step: 333  | total loss: [1m[32m0.38146[0m[0m | time: 5.454s
[2K
| Adam | epoch: 013 | loss: 0.38146 - acc: 0.8331 -- iter: 288/847
[A[ATraining Step: 334  | total loss: [1m[32m0.37665[0m[0m | time: 6.060s
[2K
| Adam | epoch: 013 | loss: 0.37665 - acc: 0.8341 -- iter: 320/847
[A[ATraining Step: 335  | total loss: [1m[32m0.36468[0m[0m | time: 6.363s
[2K
| Adam | epoch: 013 | loss: 0.36468 - acc: 0.8413 -- iter: 352/847
[A[ATraining Step: 336  | total loss: [1m[32m0.36701[0m[0m | time: 6.670s
[2K
| Adam | epoch: 013 | loss: 0.36701 - acc: 0.8505 -- iter: 384/847
[A[ATraining Step: 337  | total loss: [1m[32m0.36645[0m[0m | time: 7.271s
[2K
| Adam | epoch: 013 | loss: 0.36645 - acc: 0.8588 -- iter: 416/847
[A[ATraining Step: 338  | total loss: [1m[32m0.34371[0m[0m | time: 7.859s
[2K
| Adam | epoch: 013 | loss: 0.34371 - acc: 0.8667 -- iter: 448/847
[A[ATraining Step: 339  | total loss: [1m[32m0.32390[0m[0m | time: 8.459s
[2K
| Adam | epoch: 013 | loss: 0.32390 - acc: 0.8769 -- iter: 480/847
[A[ATraining Step: 340  | total loss: [1m[32m0.30787[0m[0m | time: 9.061s
[2K
| Adam | epoch: 013 | loss: 0.30787 - acc: 0.8830 -- iter: 512/847
[A[ATraining Step: 341  | total loss: [1m[32m0.30333[0m[0m | time: 9.690s
[2K
| Adam | epoch: 013 | loss: 0.30333 - acc: 0.8790 -- iter: 544/847
[A[ATraining Step: 342  | total loss: [1m[32m0.29235[0m[0m | time: 10.295s
[2K
| Adam | epoch: 013 | loss: 0.29235 - acc: 0.8818 -- iter: 576/847
[A[ATraining Step: 343  | total loss: [1m[32m0.29087[0m[0m | time: 10.887s
[2K
| Adam | epoch: 013 | loss: 0.29087 - acc: 0.8811 -- iter: 608/847
[A[ATraining Step: 344  | total loss: [1m[32m0.28718[0m[0m | time: 11.487s
[2K
| Adam | epoch: 013 | loss: 0.28718 - acc: 0.8836 -- iter: 640/847
[A[ATraining Step: 345  | total loss: [1m[32m0.26806[0m[0m | time: 12.086s
[2K
| Adam | epoch: 013 | loss: 0.26806 - acc: 0.8952 -- iter: 672/847
[A[ATraining Step: 346  | total loss: [1m[32m0.26619[0m[0m | time: 12.675s
[2K
| Adam | epoch: 013 | loss: 0.26619 - acc: 0.8963 -- iter: 704/847
[A[ATraining Step: 347  | total loss: [1m[32m0.27153[0m[0m | time: 13.273s
[2K
| Adam | epoch: 013 | loss: 0.27153 - acc: 0.8973 -- iter: 736/847
[A[ATraining Step: 348  | total loss: [1m[32m0.28276[0m[0m | time: 13.866s
[2K
| Adam | epoch: 013 | loss: 0.28276 - acc: 0.8920 -- iter: 768/847
[A[ATraining Step: 349  | total loss: [1m[32m0.27293[0m[0m | time: 14.465s
[2K
| Adam | epoch: 013 | loss: 0.27293 - acc: 0.8934 -- iter: 800/847
[A[ATraining Step: 350  | total loss: [1m[32m0.26668[0m[0m | time: 15.059s
[2K
| Adam | epoch: 013 | loss: 0.26668 - acc: 0.8947 -- iter: 832/847
[A[ATraining Step: 351  | total loss: [1m[32m0.27488[0m[0m | time: 16.635s
[2K
| Adam | epoch: 013 | loss: 0.27488 - acc: 0.8896 | val_loss: 0.48953 - val_acc: 0.8000 -- iter: 847/847
--
Training Step: 352  | total loss: [1m[32m0.26309[0m[0m | time: 0.612s
[2K
| Adam | epoch: 014 | loss: 0.26309 - acc: 0.8913 -- iter: 032/847
[A[ATraining Step: 353  | total loss: [1m[32m0.28196[0m[0m | time: 1.221s
[2K
| Adam | epoch: 014 | loss: 0.28196 - acc: 0.8834 -- iter: 064/847
[A[ATraining Step: 354  | total loss: [1m[32m0.30124[0m[0m | time: 1.815s
[2K
| Adam | epoch: 014 | loss: 0.30124 - acc: 0.8700 -- iter: 096/847
[A[ATraining Step: 355  | total loss: [1m[32m0.28631[0m[0m | time: 2.412s
[2K
| Adam | epoch: 014 | loss: 0.28631 - acc: 0.8799 -- iter: 128/847
[A[ATraining Step: 356  | total loss: [1m[32m0.27936[0m[0m | time: 3.002s
[2K
| Adam | epoch: 014 | loss: 0.27936 - acc: 0.8857 -- iter: 160/847
[A[ATraining Step: 357  | total loss: [1m[32m0.27402[0m[0m | time: 3.608s
[2K
| Adam | epoch: 014 | loss: 0.27402 - acc: 0.8846 -- iter: 192/847
[A[ATraining Step: 358  | total loss: [1m[32m0.27646[0m[0m | time: 4.208s
[2K
| Adam | epoch: 014 | loss: 0.27646 - acc: 0.8868 -- iter: 224/847
[A[ATraining Step: 359  | total loss: [1m[32m0.28021[0m[0m | time: 4.801s
[2K
| Adam | epoch: 014 | loss: 0.28021 - acc: 0.8856 -- iter: 256/847
[A[ATraining Step: 360  | total loss: [1m[32m0.28689[0m[0m | time: 5.410s
[2K
| Adam | epoch: 014 | loss: 0.28689 - acc: 0.8877 -- iter: 288/847
[A[ATraining Step: 361  | total loss: [1m[32m0.28133[0m[0m | time: 6.000s
[2K
| Adam | epoch: 014 | loss: 0.28133 - acc: 0.8926 -- iter: 320/847
[A[ATraining Step: 362  | total loss: [1m[32m0.27066[0m[0m | time: 6.602s
[2K
| Adam | epoch: 014 | loss: 0.27066 - acc: 0.9003 -- iter: 352/847
[A[ATraining Step: 363  | total loss: [1m[32m0.26871[0m[0m | time: 6.903s
[2K
| Adam | epoch: 014 | loss: 0.26871 - acc: 0.9040 -- iter: 384/847
[A[ATraining Step: 364  | total loss: [1m[32m0.25593[0m[0m | time: 7.213s
[2K
| Adam | epoch: 014 | loss: 0.25593 - acc: 0.9136 -- iter: 416/847
[A[ATraining Step: 365  | total loss: [1m[32m0.24179[0m[0m | time: 7.847s
[2K
| Adam | epoch: 014 | loss: 0.24179 - acc: 0.9222 -- iter: 448/847
[A[ATraining Step: 366  | total loss: [1m[32m0.23751[0m[0m | time: 8.453s
[2K
| Adam | epoch: 014 | loss: 0.23751 - acc: 0.9269 -- iter: 480/847
[A[ATraining Step: 367  | total loss: [1m[32m0.23906[0m[0m | time: 9.051s
[2K
| Adam | epoch: 014 | loss: 0.23906 - acc: 0.9217 -- iter: 512/847
[A[ATraining Step: 368  | total loss: [1m[32m0.23556[0m[0m | time: 9.645s
[2K
| Adam | epoch: 014 | loss: 0.23556 - acc: 0.9233 -- iter: 544/847
[A[ATraining Step: 369  | total loss: [1m[32m0.22588[0m[0m | time: 10.247s
[2K
| Adam | epoch: 014 | loss: 0.22588 - acc: 0.9247 -- iter: 576/847
[A[ATraining Step: 370  | total loss: [1m[32m0.22559[0m[0m | time: 10.847s
[2K
| Adam | epoch: 014 | loss: 0.22559 - acc: 0.9291 -- iter: 608/847
[A[ATraining Step: 371  | total loss: [1m[32m0.21344[0m[0m | time: 11.472s
[2K
| Adam | epoch: 014 | loss: 0.21344 - acc: 0.9362 -- iter: 640/847
[A[ATraining Step: 372  | total loss: [1m[32m0.20948[0m[0m | time: 12.112s
[2K
| Adam | epoch: 014 | loss: 0.20948 - acc: 0.9332 -- iter: 672/847
[A[ATraining Step: 373  | total loss: [1m[32m0.20861[0m[0m | time: 12.711s
[2K
| Adam | epoch: 014 | loss: 0.20861 - acc: 0.9305 -- iter: 704/847
[A[ATraining Step: 374  | total loss: [1m[32m0.20963[0m[0m | time: 13.309s
[2K
| Adam | epoch: 014 | loss: 0.20963 - acc: 0.9312 -- iter: 736/847
[A[ATraining Step: 375  | total loss: [1m[32m0.20535[0m[0m | time: 13.893s
[2K
| Adam | epoch: 014 | loss: 0.20535 - acc: 0.9287 -- iter: 768/847
[A[ATraining Step: 376  | total loss: [1m[32m0.20837[0m[0m | time: 14.492s
[2K
| Adam | epoch: 014 | loss: 0.20837 - acc: 0.9233 -- iter: 800/847
[A[ATraining Step: 377  | total loss: [1m[32m0.20247[0m[0m | time: 15.078s
[2K
| Adam | epoch: 014 | loss: 0.20247 - acc: 0.9279 -- iter: 832/847
[A[ATraining Step: 378  | total loss: [1m[32m0.20247[0m[0m | time: 16.685s
[2K
| Adam | epoch: 014 | loss: 0.20247 - acc: 0.9226 | val_loss: 0.41798 - val_acc: 0.8226 -- iter: 847/847
--
Training Step: 379  | total loss: [1m[32m0.20755[0m[0m | time: 0.610s
[2K
| Adam | epoch: 015 | loss: 0.20755 - acc: 0.9210 -- iter: 032/847
[A[ATraining Step: 380  | total loss: [1m[32m0.23815[0m[0m | time: 1.225s
[2K
| Adam | epoch: 015 | loss: 0.23815 - acc: 0.9132 -- iter: 064/847
[A[ATraining Step: 381  | total loss: [1m[32m0.23439[0m[0m | time: 1.830s
[2K
| Adam | epoch: 015 | loss: 0.23439 - acc: 0.9157 -- iter: 096/847
[A[ATraining Step: 382  | total loss: [1m[32m0.23655[0m[0m | time: 2.437s
[2K
| Adam | epoch: 015 | loss: 0.23655 - acc: 0.9178 -- iter: 128/847
[A[ATraining Step: 383  | total loss: [1m[32m0.22896[0m[0m | time: 3.028s
[2K
| Adam | epoch: 015 | loss: 0.22896 - acc: 0.9167 -- iter: 160/847
[A[ATraining Step: 384  | total loss: [1m[32m0.21888[0m[0m | time: 3.630s
[2K
| Adam | epoch: 015 | loss: 0.21888 - acc: 0.9188 -- iter: 192/847
[A[ATraining Step: 385  | total loss: [1m[32m0.20590[0m[0m | time: 4.249s
[2K
| Adam | epoch: 015 | loss: 0.20590 - acc: 0.9238 -- iter: 224/847
[A[ATraining Step: 386  | total loss: [1m[32m0.20425[0m[0m | time: 4.851s
[2K
| Adam | epoch: 015 | loss: 0.20425 - acc: 0.9158 -- iter: 256/847
[A[ATraining Step: 387  | total loss: [1m[32m0.20155[0m[0m | time: 5.480s
[2K
| Adam | epoch: 015 | loss: 0.20155 - acc: 0.9148 -- iter: 288/847
[A[ATraining Step: 388  | total loss: [1m[32m0.21162[0m[0m | time: 6.074s
[2K
| Adam | epoch: 015 | loss: 0.21162 - acc: 0.9140 -- iter: 320/847
[A[ATraining Step: 389  | total loss: [1m[32m0.21339[0m[0m | time: 6.676s
[2K
| Adam | epoch: 015 | loss: 0.21339 - acc: 0.9101 -- iter: 352/847
[A[ATraining Step: 390  | total loss: [1m[32m0.23196[0m[0m | time: 7.274s
[2K
| Adam | epoch: 015 | loss: 0.23196 - acc: 0.9066 -- iter: 384/847
[A[ATraining Step: 391  | total loss: [1m[32m0.25597[0m[0m | time: 7.579s
[2K
| Adam | epoch: 015 | loss: 0.25597 - acc: 0.8940 -- iter: 416/847
[A[ATraining Step: 392  | total loss: [1m[32m0.23332[0m[0m | time: 7.880s
[2K
| Adam | epoch: 015 | loss: 0.23332 - acc: 0.9046 -- iter: 448/847
[A[ATraining Step: 393  | total loss: [1m[32m0.21366[0m[0m | time: 8.495s
[2K
| Adam | epoch: 015 | loss: 0.21366 - acc: 0.9142 -- iter: 480/847
[A[ATraining Step: 394  | total loss: [1m[32m0.20313[0m[0m | time: 9.084s
[2K
| Adam | epoch: 015 | loss: 0.20313 - acc: 0.9227 -- iter: 512/847
[A[ATraining Step: 395  | total loss: [1m[32m0.19474[0m[0m | time: 9.692s
[2K
| Adam | epoch: 015 | loss: 0.19474 - acc: 0.9242 -- iter: 544/847
[A[ATraining Step: 396  | total loss: [1m[32m0.18634[0m[0m | time: 10.294s
[2K
| Adam | epoch: 015 | loss: 0.18634 - acc: 0.9287 -- iter: 576/847
[A[ATraining Step: 397  | total loss: [1m[32m0.18125[0m[0m | time: 10.889s
[2K
| Adam | epoch: 015 | loss: 0.18125 - acc: 0.9327 -- iter: 608/847
[A[ATraining Step: 398  | total loss: [1m[32m0.17304[0m[0m | time: 11.491s
[2K
| Adam | epoch: 015 | loss: 0.17304 - acc: 0.9394 -- iter: 640/847
[A[ATraining Step: 399  | total loss: [1m[32m0.16417[0m[0m | time: 12.089s
[2K
| Adam | epoch: 015 | loss: 0.16417 - acc: 0.9423 -- iter: 672/847
[A[ATraining Step: 400  | total loss: [1m[32m0.16276[0m[0m | time: 13.685s
[2K
| Adam | epoch: 015 | loss: 0.16276 - acc: 0.9450 | val_loss: 0.49660 - val_acc: 0.8000 -- iter: 704/847
--
Training Step: 401  | total loss: [1m[32m0.15573[0m[0m | time: 14.289s
[2K
| Adam | epoch: 015 | loss: 0.15573 - acc: 0.9474 -- iter: 736/847
[A[ATraining Step: 402  | total loss: [1m[32m0.16318[0m[0m | time: 14.882s
[2K
| Adam | epoch: 015 | loss: 0.16318 - acc: 0.9433 -- iter: 768/847
[A[ATraining Step: 403  | total loss: [1m[32m0.17137[0m[0m | time: 15.480s
[2K
| Adam | epoch: 015 | loss: 0.17137 - acc: 0.9427 -- iter: 800/847
[A[ATraining Step: 404  | total loss: [1m[32m0.16362[0m[0m | time: 16.076s
[2K
| Adam | epoch: 015 | loss: 0.16362 - acc: 0.9453 -- iter: 832/847
[A[ATraining Step: 405  | total loss: [1m[32m0.16779[0m[0m | time: 17.675s
[2K
| Adam | epoch: 015 | loss: 0.16779 - acc: 0.9414 | val_loss: 0.41481 - val_acc: 0.8302 -- iter: 847/847
--
Validation AUC:0.9182336182336182
Validation AUPRC:0.919130191362616
Test AUC:0.906217794572312
Test AUPRC:0.9059814072772776
BestTestF1Score	0.82	0.64	0.82	0.76	0.89	109	35	107	14	0.14
BestTestMCCScore	0.8	0.67	0.83	0.9	0.72	89	10	132	34	0.7
BestTestAccuracyScore	0.8	0.67	0.83	0.9	0.72	89	10	132	34	0.7
BestValidationF1Score	0.84	0.67	0.83	0.79	0.89	116	30	105	14	0.14
BestValidationMCC	0.81	0.69	0.83	0.94	0.71	92	6	129	38	0.7
BestValidationAccuracy	0.81	0.69	0.83	0.94	0.71	92	6	129	38	0.7
TestPredictions (Threshold:0.7)
CHEMBL1230020,TP,ACT,0.8600000143051147	CHEMBL1821888,TN,INACT,0.009999999776482582	CHEMBL428534,TP,ACT,0.9800000190734863	CHEMBL79206,TP,ACT,1.0	CHEMBL1821881,FP,INACT,0.9200000166893005	CHEMBL76751,FN,ACT,0.5299999713897705	CHEMBL306284,TP,ACT,1.0	CHEMBL2283259,TN,INACT,0.03999999910593033	CHEMBL2086751,TP,ACT,0.9200000166893005	CHEMBL521201,TN,INACT,0.019999999552965164	CHEMBL1744349,TP,ACT,0.8899999856948853	CHEMBL2086733,FN,ACT,0.6000000238418579	CHEMBL214258,TP,ACT,0.9700000286102295	CHEMBL3672514,TN,INACT,0.6399999856948853	CHEMBL454403,TP,ACT,0.9300000071525574	CHEMBL550623,TN,INACT,0.05999999865889549	CHEMBL238529,TP,ACT,0.9900000095367432	CHEMBL1172418,TN,INACT,0.009999999776482582	CHEMBL383990,FN,ACT,0.05000000074505806	CHEMBL246356,TN,INACT,0.03999999910593033	CHEMBL425247,FN,ACT,0.1599999964237213	CHEMBL1241775,TN,INACT,0.009999999776482582	CHEMBL539433,TN,INACT,0.009999999776482582	CHEMBL488811,TN,INACT,0.009999999776482582	CHEMBL214109,FN,ACT,0.07999999821186066	CHEMBL240209,TP,ACT,1.0	CHEMBL456143,TN,INACT,0.2199999988079071	CHEMBL1683951,TN,INACT,0.019999999552965164	CHEMBL591437,TN,INACT,0.009999999776482582	CHEMBL154969,TN,INACT,0.17000000178813934	CHEMBL3805409,TN,INACT,0.009999999776482582	CHEMBL509032,FN,ACT,0.029999999329447746	CHEMBL74391,TP,ACT,1.0	CHEMBL3739732,TP,ACT,0.9200000166893005	CHEMBL204985,TP,ACT,0.9700000286102295	CHEMBL3586175,TN,INACT,0.3199999928474426	CHEMBL592141,TN,INACT,0.009999999776482582	CHEMBL109625,TN,INACT,0.029999999329447746	CHEMBL2337366,TN,INACT,0.009999999776482582	CHEMBL310740,TP,ACT,1.0	CHEMBL1336,FN,ACT,0.41999998688697815	CHEMBL15887,TN,INACT,0.10999999940395355	CHEMBL377345,TP,ACT,0.9700000286102295	CHEMBL1929304,TN,INACT,0.0	CHEMBL204874,TP,ACT,0.9900000095367432	CHEMBL228114,TN,INACT,0.0	CHEMBL382610,TP,ACT,1.0	CHEMBL543600,TN,INACT,0.05000000074505806	CHEMBL2312652,TN,INACT,0.3199999928474426	CHEMBL1907764,TP,ACT,0.9599999785423279	CHEMBL590109,FN,ACT,0.699999988079071	CHEMBL516645,TP,ACT,0.9900000095367432	CHEMBL1830259,TN,INACT,0.009999999776482582	CHEMBL2029690,FP,INACT,0.8500000238418579	CHEMBL1684370,TN,INACT,0.009999999776482582	CHEMBL1161236,TN,INACT,0.07999999821186066	CHEMBL491872,TP,ACT,0.8999999761581421	CHEMBL3735648,TP,ACT,0.9800000190734863	CHEMBL207772,TP,ACT,0.9900000095367432	CHEMBL1287853,FN,ACT,0.029999999329447746	CHEMBL2337371,TN,INACT,0.009999999776482582	CHEMBL74850,TP,ACT,1.0	CHEMBL3628811,TP,ACT,0.9900000095367432	CHEMBL436806,FN,ACT,0.05000000074505806	CHEMBL3098312,TN,INACT,0.07999999821186066	CHEMBL602890,TN,INACT,0.6899999976158142	CHEMBL2337369,TN,INACT,0.009999999776482582	CHEMBL205884,TP,ACT,0.9700000286102295	CHEMBL521155,TN,INACT,0.009999999776482582	CHEMBL515674,TN,INACT,0.009999999776482582	CHEMBL116012,TN,INACT,0.03999999910593033	CHEMBL430845,TN,INACT,0.03999999910593033	CHEMBL2096839,TP,ACT,0.9900000095367432	CHEMBL396107,FN,ACT,0.019999999552965164	CHEMBL522304,TP,ACT,0.9800000190734863	CHEMBL482489,TN,INACT,0.0	CHEMBL19978,TN,INACT,0.009999999776482582	CHEMBL383333,TP,ACT,1.0	CHEMBL379108,TP,ACT,0.949999988079071	CHEMBL77782,TP,ACT,1.0	CHEMBL1910268,TN,INACT,0.03999999910593033	CHEMBL390066,TN,INACT,0.0	CHEMBL2029698,TN,INACT,0.0	CHEMBL328034,TN,INACT,0.6299999952316284	CHEMBL1641991,TN,INACT,0.23000000417232513	CHEMBL262433,TP,ACT,0.9800000190734863	CHEMBL113996,TN,INACT,0.05999999865889549	CHEMBL201014,FN,ACT,0.14000000059604645	CHEMBL589832,TN,INACT,0.4399999976158142	CHEMBL136289,FP,INACT,0.8999999761581421	CHEMBL1241674,FN,ACT,0.029999999329447746	CHEMBL245377,FN,ACT,0.2199999988079071	CHEMBL1242846,TN,INACT,0.019999999552965164	CHEMBL551031,TN,INACT,0.009999999776482582	CHEMBL204621,TP,ACT,0.9599999785423279	CHEMBL74848,TP,ACT,1.0	CHEMBL498105,TP,ACT,0.9599999785423279	CHEMBL474863,TN,INACT,0.05999999865889549	CHEMBL393636,FN,ACT,0.009999999776482582	CHEMBL557050,TN,INACT,0.009999999776482582	CHEMBL2426377,TN,INACT,0.6499999761581421	CHEMBL482919,TN,INACT,0.009999999776482582	CHEMBL1242119,TN,INACT,0.25999999046325684	CHEMBL1821889,TN,INACT,0.10000000149011612	CHEMBL1828876,TN,INACT,0.05999999865889549	CHEMBL1945644,TN,INACT,0.029999999329447746	CHEMBL3660270,TP,ACT,0.949999988079071	CHEMBL207061,TP,ACT,0.9800000190734863	CHEMBL1916949,TN,INACT,0.009999999776482582	CHEMBL78018,TP,ACT,1.0	CHEMBL2047247,TN,INACT,0.0	CHEMBL419458,TP,ACT,1.0	CHEMBL431996,TN,INACT,0.019999999552965164	CHEMBL603469,FN,ACT,0.009999999776482582	CHEMBL2409779,TP,ACT,0.8799999952316284	CHEMBL2086741,FN,ACT,0.07000000029802322	CHEMBL276711,FN,ACT,0.0	CHEMBL556746,TN,INACT,0.009999999776482582	CHEMBL77452,TP,ACT,1.0	CHEMBL357815,TP,ACT,0.9900000095367432	CHEMBL432396,TN,INACT,0.699999988079071	CHEMBL312526,FN,ACT,0.1899999976158142	CHEMBL120564,TN,INACT,0.009999999776482582	CHEMBL279481,TN,INACT,0.07000000029802322	CHEMBL1956891,TN,INACT,0.009999999776482582	CHEMBL515880,TP,ACT,0.9700000286102295	CHEMBL590877,TN,INACT,0.029999999329447746	CHEMBL3696073,TP,ACT,0.9900000095367432	CHEMBL201713,TP,ACT,1.0	CHEMBL383299,TP,ACT,0.9100000262260437	CHEMBL501709,TN,INACT,0.27000001072883606	CHEMBL2437301,TN,INACT,0.029999999329447746	CHEMBL539942,FP,INACT,0.8799999952316284	CHEMBL1242378,TN,INACT,0.009999999776482582	CHEMBL486487,FP,INACT,0.9700000286102295	CHEMBL1087054,TN,INACT,0.0	CHEMBL429743,TP,ACT,0.9900000095367432	CHEMBL529663,TN,INACT,0.03999999910593033	CHEMBL1271480,TP,ACT,1.0	CHEMBL433936,TP,ACT,0.9900000095367432	CHEMBL2086745,FN,ACT,0.49000000953674316	CHEMBL103667,FN,ACT,0.6499999761581421	CHEMBL549303,TN,INACT,0.009999999776482582	CHEMBL591706,TN,INACT,0.009999999776482582	CHEMBL238734,TP,ACT,1.0	CHEMBL1829272,TN,INACT,0.019999999552965164	CHEMBL1202473,TP,ACT,0.9800000190734863	CHEMBL1829273,TN,INACT,0.019999999552965164	CHEMBL310827,TP,ACT,0.9900000095367432	CHEMBL293986,TN,INACT,0.009999999776482582	CHEMBL3098315,TN,INACT,0.07000000029802322	CHEMBL306707,TP,ACT,0.7200000286102295	CHEMBL2086737,FN,ACT,0.3100000023841858	CHEMBL558859,TN,INACT,0.029999999329447746	CHEMBL2086724,TP,ACT,0.9599999785423279	CHEMBL241075,TP,ACT,0.949999988079071	CHEMBL3628808,FN,ACT,0.4099999964237213	CHEMBL312818,TP,ACT,0.800000011920929	CHEMBL77243,TN,INACT,0.019999999552965164	CHEMBL1088348,TN,INACT,0.0	CHEMBL205421,TP,ACT,1.0	CHEMBL430902,TN,INACT,0.009999999776482582	CHEMBL212054,TP,ACT,0.9599999785423279	CHEMBL601719,FN,ACT,0.1599999964237213	CHEMBL203796,TP,ACT,0.9900000095367432	CHEMBL392513,TP,ACT,1.0	CHEMBL3318023,TN,INACT,0.47999998927116394	CHEMBL589503,TN,INACT,0.5	CHEMBL421326,TP,ACT,1.0	CHEMBL3823628,FP,INACT,0.7200000286102295	CHEMBL592210,TN,INACT,0.009999999776482582	CHEMBL269884,TP,ACT,0.9200000166893005	CHEMBL1929555,TN,INACT,0.20999999344348907	CHEMBL589590,TN,INACT,0.009999999776482582	CHEMBL1242753,TN,INACT,0.07000000029802322	CHEMBL78685,TP,ACT,0.9800000190734863	CHEMBL1173023,TN,INACT,0.009999999776482582	CHEMBL3288526,TP,ACT,0.8100000023841858	CHEMBL572878,FN,ACT,0.009999999776482582	CHEMBL475509,TP,ACT,0.7699999809265137	CHEMBL381283,TP,ACT,0.7300000190734863	CHEMBL150825,FP,INACT,0.9900000095367432	CHEMBL205108,TP,ACT,0.800000011920929	CHEMBL1744347,TP,ACT,0.9800000190734863	CHEMBL248221,TP,ACT,0.949999988079071	CHEMBL452812,TN,INACT,0.009999999776482582	CHEMBL293749,TN,INACT,0.03999999910593033	CHEMBL80540,TP,ACT,1.0	CHEMBL527039,FP,INACT,0.9800000190734863	CHEMBL2437484,TN,INACT,0.2199999988079071	CHEMBL318485,TN,INACT,0.009999999776482582	CHEMBL248393,FN,ACT,0.14000000059604645	CHEMBL556874,FP,INACT,0.9700000286102295	CHEMBL324439,TN,INACT,0.009999999776482582	CHEMBL412391,TN,INACT,0.009999999776482582	CHEMBL590083,FP,INACT,0.8399999737739563	CHEMBL392987,TP,ACT,1.0	CHEMBL261592,FN,ACT,0.6899999976158142	CHEMBL345862,TN,INACT,0.6899999976158142	CHEMBL245966,TN,INACT,0.029999999329447746	CHEMBL2086723,TP,ACT,0.9700000286102295	CHEMBL515432,TN,INACT,0.15000000596046448	CHEMBL1828884,TN,INACT,0.019999999552965164	CHEMBL491502,FN,ACT,0.3400000035762787	CHEMBL457390,TN,INACT,0.0	CHEMBL2335019,TN,INACT,0.019999999552965164	CHEMBL148869,TP,ACT,0.7300000190734863	CHEMBL377734,FN,ACT,0.1899999976158142	CHEMBL2086760,FN,ACT,0.4099999964237213	CHEMBL465015,TP,ACT,0.9300000071525574	CHEMBL1922120,TN,INACT,0.03999999910593033	CHEMBL1241583,TN,INACT,0.009999999776482582	CHEMBL2426288,TN,INACT,0.6600000262260437	CHEMBL591050,TN,INACT,0.009999999776482582	CHEMBL456797,TN,INACT,0.029999999329447746	CHEMBL3696072,TP,ACT,0.949999988079071	CHEMBL1907944,TP,ACT,0.949999988079071	CHEMBL311798,FN,ACT,0.10999999940395355	CHEMBL3355065,FN,ACT,0.15000000596046448	CHEMBL241265,TP,ACT,1.0	CHEMBL515356,TN,INACT,0.009999999776482582	CHEMBL2086740,TP,ACT,0.8700000047683716	CHEMBL1202477,TP,ACT,0.9700000286102295	CHEMBL86921,TN,INACT,0.029999999329447746	CHEMBL2063338,TP,ACT,0.9800000190734863	CHEMBL3133911,TN,INACT,0.019999999552965164	CHEMBL1241680,TN,INACT,0.0	CHEMBL208363,TP,ACT,1.0	CHEMBL483108,TN,INACT,0.05000000074505806	CHEMBL324399,TN,INACT,0.12999999523162842	CHEMBL2086755,TP,ACT,0.7400000095367432	CHEMBL279459,TP,ACT,0.9900000095367432	CHEMBL314146,TN,INACT,0.3100000023841858	CHEMBL3237855,TN,INACT,0.38999998569488525	CHEMBL3335244,TN,INACT,0.009999999776482582	CHEMBL391127,TP,ACT,1.0	CHEMBL2337364,TN,INACT,0.0	CHEMBL309937,TN,INACT,0.019999999552965164	CHEMBL77298,TN,INACT,0.009999999776482582	CHEMBL150,TN,INACT,0.019999999552965164	CHEMBL78249,TN,INACT,0.0	CHEMBL2337363,TN,INACT,0.0	CHEMBL2312645,TN,INACT,0.07999999821186066	CHEMBL1241684,TN,INACT,0.009999999776482582	CHEMBL1641990,TN,INACT,0.009999999776482582	CHEMBL564235,TN,INACT,0.009999999776482582	CHEMBL158119,TN,INACT,0.0	CHEMBL377300,FN,ACT,0.5400000214576721	CHEMBL2029691,TN,INACT,0.550000011920929	CHEMBL3799956,TN,INACT,0.009999999776482582	CHEMBL3237858,TN,INACT,0.33000001311302185	CHEMBL380702,FN,ACT,0.07000000029802322	CHEMBL381577,TP,ACT,1.0	CHEMBL116423,TN,INACT,0.0	CHEMBL245768,TP,ACT,1.0	CHEMBL150606,TP,ACT,0.9900000095367432	CHEMBL269528,TN,INACT,0.019999999552965164	CHEMBL307179,TN,INACT,0.0	CHEMBL597492,TP,ACT,0.8399999737739563	CHEMBL460191,TP,ACT,1.0	CHEMBL1221822,TN,INACT,0.3400000035762787	CHEMBL584,TN,INACT,0.019999999552965164	CHEMBL286160,TP,ACT,0.9800000190734863	CHEMBL2437296,TN,INACT,0.05999999865889549	CHEMBL291313,TN,INACT,0.009999999776482582	

