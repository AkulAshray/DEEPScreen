CNNModel CHEMBL3943 adam 0.001 30 128 0 0.6 False True
Number of active compounds :	253
Number of inactive compounds :	253
---------------------------------
Run id: CNNModel_CHEMBL3943_adam_0.001_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3943_adam_0.001_30_128_0.6_True/
---------------------------------
Training samples: 300
Validation samples: 94
--
Training Step: 1  | time: 1.549s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/300
[A[ATraining Step: 2  | total loss: [1m[32m0.62382[0m[0m | time: 2.897s
[2K
| Adam | epoch: 001 | loss: 0.62382 - acc: 0.5062 -- iter: 064/300
[A[ATraining Step: 3  | total loss: [1m[32m0.68221[0m[0m | time: 4.136s
[2K
| Adam | epoch: 001 | loss: 0.68221 - acc: 0.4244 -- iter: 096/300
[A[ATraining Step: 4  | total loss: [1m[32m0.69142[0m[0m | time: 5.331s
[2K
| Adam | epoch: 001 | loss: 0.69142 - acc: 0.3874 -- iter: 128/300
[A[ATraining Step: 5  | total loss: [1m[32m0.69253[0m[0m | time: 6.822s
[2K
| Adam | epoch: 001 | loss: 0.69253 - acc: 0.4870 -- iter: 160/300
[A[ATraining Step: 6  | total loss: [1m[32m0.69338[0m[0m | time: 8.231s
[2K
| Adam | epoch: 001 | loss: 0.69338 - acc: 0.4351 -- iter: 192/300
[A[ATraining Step: 7  | total loss: [1m[32m0.69334[0m[0m | time: 9.570s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.4740 -- iter: 224/300
[A[ATraining Step: 8  | total loss: [1m[32m0.69323[0m[0m | time: 10.734s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.4886 -- iter: 256/300
[A[ATraining Step: 9  | total loss: [1m[32m0.69316[0m[0m | time: 11.911s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.4616 -- iter: 288/300
[A[ATraining Step: 10  | total loss: [1m[32m0.69324[0m[0m | time: 13.443s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.4495 | val_loss: 0.69338 - val_acc: 0.3830 -- iter: 300/300
--
Training Step: 11  | total loss: [1m[32m0.69290[0m[0m | time: 0.551s
[2K
| Adam | epoch: 002 | loss: 0.69290 - acc: 0.6708 -- iter: 032/300
[A[ATraining Step: 12  | total loss: [1m[32m0.69309[0m[0m | time: 2.004s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5939 -- iter: 064/300
[A[ATraining Step: 13  | total loss: [1m[32m0.69315[0m[0m | time: 3.325s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5403 -- iter: 096/300
[A[ATraining Step: 14  | total loss: [1m[32m0.69283[0m[0m | time: 4.483s
[2K
| Adam | epoch: 002 | loss: 0.69283 - acc: 0.5494 -- iter: 128/300
[A[ATraining Step: 15  | total loss: [1m[32m0.69242[0m[0m | time: 6.118s
[2K
| Adam | epoch: 002 | loss: 0.69242 - acc: 0.5423 -- iter: 160/300
[A[ATraining Step: 16  | total loss: [1m[32m0.69134[0m[0m | time: 7.543s
[2K
| Adam | epoch: 002 | loss: 0.69134 - acc: 0.5499 -- iter: 192/300
[A[ATraining Step: 17  | total loss: [1m[32m0.69237[0m[0m | time: 8.971s
[2K
| Adam | epoch: 002 | loss: 0.69237 - acc: 0.5319 -- iter: 224/300
[A[ATraining Step: 18  | total loss: [1m[32m0.70379[0m[0m | time: 10.466s
[2K
| Adam | epoch: 002 | loss: 0.70379 - acc: 0.4560 -- iter: 256/300
[A[ATraining Step: 19  | total loss: [1m[32m0.70238[0m[0m | time: 11.498s
[2K
| Adam | epoch: 002 | loss: 0.70238 - acc: 0.4498 -- iter: 288/300
[A[ATraining Step: 20  | total loss: [1m[32m0.70153[0m[0m | time: 13.581s
[2K
| Adam | epoch: 002 | loss: 0.70153 - acc: 0.4258 | val_loss: 0.69146 - val_acc: 0.6170 -- iter: 300/300
--
Training Step: 21  | total loss: [1m[32m0.69788[0m[0m | time: 0.535s
[2K
| Adam | epoch: 003 | loss: 0.69788 - acc: 0.4876 -- iter: 032/300
[A[ATraining Step: 22  | total loss: [1m[32m0.69536[0m[0m | time: 1.118s
[2K
| Adam | epoch: 003 | loss: 0.69536 - acc: 0.5663 -- iter: 064/300
[A[ATraining Step: 23  | total loss: [1m[32m0.69432[0m[0m | time: 2.473s
[2K
| Adam | epoch: 003 | loss: 0.69432 - acc: 0.5713 -- iter: 096/300
[A[ATraining Step: 24  | total loss: [1m[32m0.69377[0m[0m | time: 3.654s
[2K
| Adam | epoch: 003 | loss: 0.69377 - acc: 0.5688 -- iter: 128/300
[A[ATraining Step: 25  | total loss: [1m[32m0.69386[0m[0m | time: 4.832s
[2K
| Adam | epoch: 003 | loss: 0.69386 - acc: 0.5330 -- iter: 160/300
[A[ATraining Step: 26  | total loss: [1m[32m0.69349[0m[0m | time: 6.235s
[2K
| Adam | epoch: 003 | loss: 0.69349 - acc: 0.5408 -- iter: 192/300
[A[ATraining Step: 27  | total loss: [1m[32m0.69367[0m[0m | time: 7.697s
[2K
| Adam | epoch: 003 | loss: 0.69367 - acc: 0.5142 -- iter: 224/300
[A[ATraining Step: 28  | total loss: [1m[32m0.69380[0m[0m | time: 9.135s
[2K
| Adam | epoch: 003 | loss: 0.69380 - acc: 0.4951 -- iter: 256/300
[A[ATraining Step: 29  | total loss: [1m[32m0.69399[0m[0m | time: 11.880s
[2K
| Adam | epoch: 003 | loss: 0.69399 - acc: 0.4735 -- iter: 288/300
[A[ATraining Step: 30  | total loss: [1m[32m0.69380[0m[0m | time: 14.028s
[2K
| Adam | epoch: 003 | loss: 0.69380 - acc: 0.4797 | val_loss: 0.69151 - val_acc: 0.6170 -- iter: 300/300
--
Training Step: 31  | total loss: [1m[32m0.69367[0m[0m | time: 1.190s
[2K
| Adam | epoch: 004 | loss: 0.69367 - acc: 0.4844 -- iter: 032/300
[A[ATraining Step: 32  | total loss: [1m[32m0.69328[0m[0m | time: 1.692s
[2K
| Adam | epoch: 004 | loss: 0.69328 - acc: 0.5090 -- iter: 064/300
[A[ATraining Step: 33  | total loss: [1m[32m0.69298[0m[0m | time: 2.351s
[2K
| Adam | epoch: 004 | loss: 0.69298 - acc: 0.5253 -- iter: 096/300
[A[ATraining Step: 34  | total loss: [1m[32m0.69274[0m[0m | time: 3.895s
[2K
| Adam | epoch: 004 | loss: 0.69274 - acc: 0.5378 -- iter: 128/300
[A[ATraining Step: 35  | total loss: [1m[32m0.69305[0m[0m | time: 5.047s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5168 -- iter: 160/300
[A[ATraining Step: 36  | total loss: [1m[32m0.69277[0m[0m | time: 6.200s
[2K
| Adam | epoch: 004 | loss: 0.69277 - acc: 0.5325 -- iter: 192/300
[A[ATraining Step: 37  | total loss: [1m[32m0.69299[0m[0m | time: 7.692s
[2K
| Adam | epoch: 004 | loss: 0.69299 - acc: 0.5198 -- iter: 224/300
[A[ATraining Step: 38  | total loss: [1m[32m0.69276[0m[0m | time: 9.167s
[2K
| Adam | epoch: 004 | loss: 0.69276 - acc: 0.5281 -- iter: 256/300
[A[ATraining Step: 39  | total loss: [1m[32m0.69300[0m[0m | time: 10.543s
[2K
| Adam | epoch: 004 | loss: 0.69300 - acc: 0.5168 -- iter: 288/300
[A[ATraining Step: 40  | total loss: [1m[32m0.69329[0m[0m | time: 12.554s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.5019 | val_loss: 0.69077 - val_acc: 0.6170 -- iter: 300/300
--
Training Step: 41  | total loss: [1m[32m0.69364[0m[0m | time: 1.564s
[2K
| Adam | epoch: 005 | loss: 0.69364 - acc: 0.4843 -- iter: 032/300
[A[ATraining Step: 42  | total loss: [1m[32m0.69344[0m[0m | time: 3.011s
[2K
| Adam | epoch: 005 | loss: 0.69344 - acc: 0.4928 -- iter: 064/300
[A[ATraining Step: 43  | total loss: [1m[32m0.69329[0m[0m | time: 3.522s
[2K
| Adam | epoch: 005 | loss: 0.69329 - acc: 0.4996 -- iter: 096/300
[A[ATraining Step: 44  | total loss: [1m[32m0.69295[0m[0m | time: 4.072s
[2K
| Adam | epoch: 005 | loss: 0.69295 - acc: 0.5141 -- iter: 128/300
[A[ATraining Step: 45  | total loss: [1m[32m0.69412[0m[0m | time: 5.278s
[2K
| Adam | epoch: 005 | loss: 0.69412 - acc: 0.4551 -- iter: 160/300
[A[ATraining Step: 46  | total loss: [1m[32m0.69367[0m[0m | time: 6.396s
[2K
| Adam | epoch: 005 | loss: 0.69367 - acc: 0.4782 -- iter: 192/300
[A[ATraining Step: 47  | total loss: [1m[32m0.69351[0m[0m | time: 7.811s
[2K
| Adam | epoch: 005 | loss: 0.69351 - acc: 0.4869 -- iter: 224/300
[A[ATraining Step: 48  | total loss: [1m[32m0.69324[0m[0m | time: 9.214s
[2K
| Adam | epoch: 005 | loss: 0.69324 - acc: 0.5040 -- iter: 256/300
[A[ATraining Step: 49  | total loss: [1m[32m0.69341[0m[0m | time: 10.637s
[2K
| Adam | epoch: 005 | loss: 0.69341 - acc: 0.4935 -- iter: 288/300
[A[ATraining Step: 50  | total loss: [1m[32m0.69325[0m[0m | time: 12.632s
[2K
| Adam | epoch: 005 | loss: 0.69325 - acc: 0.5042 | val_loss: 0.69155 - val_acc: 0.6170 -- iter: 300/300
--
Training Step: 51  | total loss: [1m[32m0.69333[0m[0m | time: 1.258s
[2K
| Adam | epoch: 006 | loss: 0.69333 - acc: 0.4941 -- iter: 032/300
[A[ATraining Step: 52  | total loss: [1m[32m0.69350[0m[0m | time: 2.639s
[2K
| Adam | epoch: 006 | loss: 0.69350 - acc: 0.4809 -- iter: 064/300
[A[ATraining Step: 53  | total loss: [1m[32m0.69344[0m[0m | time: 3.998s
[2K
| Adam | epoch: 006 | loss: 0.69344 - acc: 0.4837 -- iter: 096/300
[A[ATraining Step: 54  | total loss: [1m[32m0.69337[0m[0m | time: 4.579s
[2K
| Adam | epoch: 006 | loss: 0.69337 - acc: 0.4906 -- iter: 128/300
[A[ATraining Step: 55  | total loss: [1m[32m0.69382[0m[0m | time: 5.039s
[2K
| Adam | epoch: 006 | loss: 0.69382 - acc: 0.4443 -- iter: 160/300
[A[ATraining Step: 56  | total loss: [1m[32m0.69394[0m[0m | time: 6.297s
[2K
| Adam | epoch: 006 | loss: 0.69394 - acc: 0.4287 -- iter: 192/300
[A[ATraining Step: 57  | total loss: [1m[32m0.69384[0m[0m | time: 7.707s
[2K
| Adam | epoch: 006 | loss: 0.69384 - acc: 0.4386 -- iter: 224/300
[A[ATraining Step: 58  | total loss: [1m[32m0.69375[0m[0m | time: 9.106s
[2K
| Adam | epoch: 006 | loss: 0.69375 - acc: 0.4427 -- iter: 256/300
[A[ATraining Step: 59  | total loss: [1m[32m0.69364[0m[0m | time: 10.449s
[2K
| Adam | epoch: 006 | loss: 0.69364 - acc: 0.4546 -- iter: 288/300
[A[ATraining Step: 60  | total loss: [1m[32m0.69363[0m[0m | time: 15.248s
[2K
| Adam | epoch: 006 | loss: 0.69363 - acc: 0.4523 | val_loss: 0.69473 - val_acc: 0.3830 -- iter: 300/300
--
Training Step: 61  | total loss: [1m[32m0.69348[0m[0m | time: 1.152s
[2K
| Adam | epoch: 007 | loss: 0.69348 - acc: 0.4708 -- iter: 032/300
[A[ATraining Step: 62  | total loss: [1m[32m0.69331[0m[0m | time: 2.484s
[2K
| Adam | epoch: 007 | loss: 0.69331 - acc: 0.4826 -- iter: 064/300
[A[ATraining Step: 63  | total loss: [1m[32m0.69356[0m[0m | time: 3.876s
[2K
| Adam | epoch: 007 | loss: 0.69356 - acc: 0.4689 -- iter: 096/300
[A[ATraining Step: 64  | total loss: [1m[32m0.69335[0m[0m | time: 5.176s
[2K
| Adam | epoch: 007 | loss: 0.69335 - acc: 0.4806 -- iter: 128/300
[A[ATraining Step: 65  | total loss: [1m[32m0.69355[0m[0m | time: 5.554s
[2K
| Adam | epoch: 007 | loss: 0.69355 - acc: 0.4715 -- iter: 160/300
[A[ATraining Step: 66  | total loss: [1m[32m0.69312[0m[0m | time: 6.071s
[2K
| Adam | epoch: 007 | loss: 0.69312 - acc: 0.4952 -- iter: 192/300
[A[ATraining Step: 67  | total loss: [1m[32m0.69339[0m[0m | time: 7.466s
[2K
| Adam | epoch: 007 | loss: 0.69339 - acc: 0.4858 -- iter: 224/300
[A[ATraining Step: 68  | total loss: [1m[32m0.69306[0m[0m | time: 8.921s
[2K
| Adam | epoch: 007 | loss: 0.69306 - acc: 0.4986 -- iter: 256/300
[A[ATraining Step: 69  | total loss: [1m[32m0.69295[0m[0m | time: 10.316s
[2K
| Adam | epoch: 007 | loss: 0.69295 - acc: 0.5024 -- iter: 288/300
[A[ATraining Step: 70  | total loss: [1m[32m0.69339[0m[0m | time: 21.476s
[2K
| Adam | epoch: 007 | loss: 0.69339 - acc: 0.4877 | val_loss: 0.69666 - val_acc: 0.3830 -- iter: 300/300
--
Training Step: 71  | total loss: [1m[32m0.69338[0m[0m | time: 1.245s
[2K
| Adam | epoch: 008 | loss: 0.69338 - acc: 0.4891 -- iter: 032/300
[A[ATraining Step: 72  | total loss: [1m[32m0.69336[0m[0m | time: 2.536s
[2K
| Adam | epoch: 008 | loss: 0.69336 - acc: 0.4903 -- iter: 064/300
[A[ATraining Step: 73  | total loss: [1m[32m0.69321[0m[0m | time: 3.816s
[2K
| Adam | epoch: 008 | loss: 0.69321 - acc: 0.4949 -- iter: 096/300
[A[ATraining Step: 74  | total loss: [1m[32m0.69321[0m[0m | time: 5.354s
[2K
| Adam | epoch: 008 | loss: 0.69321 - acc: 0.4954 -- iter: 128/300
[A[ATraining Step: 75  | total loss: [1m[32m0.69311[0m[0m | time: 6.686s
[2K
| Adam | epoch: 008 | loss: 0.69311 - acc: 0.4993 -- iter: 160/300
[A[ATraining Step: 76  | total loss: [1m[32m0.69314[0m[0m | time: 7.103s
[2K
| Adam | epoch: 008 | loss: 0.69314 - acc: 0.4994 -- iter: 192/300
[A[ATraining Step: 77  | total loss: [1m[32m0.69340[0m[0m | time: 7.566s
[2K
| Adam | epoch: 008 | loss: 0.69340 - acc: 0.4906 -- iter: 224/300
[A[ATraining Step: 78  | total loss: [1m[32m0.69365[0m[0m | time: 9.085s
[2K
| Adam | epoch: 008 | loss: 0.69365 - acc: 0.4829 -- iter: 256/300
[A[ATraining Step: 79  | total loss: [1m[32m0.69360[0m[0m | time: 10.567s
[2K
| Adam | epoch: 008 | loss: 0.69360 - acc: 0.4847 -- iter: 288/300
[A[ATraining Step: 80  | total loss: [1m[32m0.69364[0m[0m | time: 12.924s
[2K
| Adam | epoch: 008 | loss: 0.69364 - acc: 0.4830 | val_loss: 0.69619 - val_acc: 0.3830 -- iter: 300/300
--
Training Step: 81  | total loss: [1m[32m0.69363[0m[0m | time: 1.259s
[2K
| Adam | epoch: 009 | loss: 0.69363 - acc: 0.4847 -- iter: 032/300
[A[ATraining Step: 82  | total loss: [1m[32m0.69384[0m[0m | time: 2.462s
[2K
| Adam | epoch: 009 | loss: 0.69384 - acc: 0.4769 -- iter: 064/300
[A[ATraining Step: 83  | total loss: [1m[32m0.69372[0m[0m | time: 3.875s
[2K
| Adam | epoch: 009 | loss: 0.69372 - acc: 0.4823 -- iter: 096/300
[A[ATraining Step: 84  | total loss: [1m[32m0.69347[0m[0m | time: 5.283s
[2K
| Adam | epoch: 009 | loss: 0.69347 - acc: 0.4935 -- iter: 128/300
[A[ATraining Step: 85  | total loss: [1m[32m0.69350[0m[0m | time: 6.411s
[2K
| Adam | epoch: 009 | loss: 0.69350 - acc: 0.4910 -- iter: 160/300
[A[ATraining Step: 86  | total loss: [1m[32m0.69340[0m[0m | time: 7.920s
[2K
| Adam | epoch: 009 | loss: 0.69340 - acc: 0.4950 -- iter: 192/300
[A[ATraining Step: 87  | total loss: [1m[32m0.69340[0m[0m | time: 8.529s
[2K
| Adam | epoch: 009 | loss: 0.69340 - acc: 0.4955 -- iter: 224/300
[A[ATraining Step: 88  | total loss: [1m[32m0.69320[0m[0m | time: 9.094s
[2K
| Adam | epoch: 009 | loss: 0.69320 - acc: 0.5043 -- iter: 256/300
[A[ATraining Step: 89  | total loss: [1m[32m0.69340[0m[0m | time: 10.459s
[2K
| Adam | epoch: 009 | loss: 0.69340 - acc: 0.4955 -- iter: 288/300
[A[ATraining Step: 90  | total loss: [1m[32m0.69317[0m[0m | time: 12.568s
[2K
| Adam | epoch: 009 | loss: 0.69317 - acc: 0.5054 | val_loss: 0.69541 - val_acc: 0.3830 -- iter: 300/300
--
Training Step: 91  | total loss: [1m[32m0.69318[0m[0m | time: 1.252s
[2K
| Adam | epoch: 010 | loss: 0.69318 - acc: 0.5048 -- iter: 032/300
[A[ATraining Step: 92  | total loss: [1m[32m0.69313[0m[0m | time: 2.552s
[2K
| Adam | epoch: 010 | loss: 0.69313 - acc: 0.5075 -- iter: 064/300
[A[ATraining Step: 93  | total loss: [1m[32m0.69308[0m[0m | time: 3.833s
[2K
| Adam | epoch: 010 | loss: 0.69308 - acc: 0.5098 -- iter: 096/300
[A[ATraining Step: 94  | total loss: [1m[32m0.69298[0m[0m | time: 5.182s
[2K
| Adam | epoch: 010 | loss: 0.69298 - acc: 0.5151 -- iter: 128/300
[A[ATraining Step: 95  | total loss: [1m[32m0.69327[0m[0m | time: 6.274s
[2K
| Adam | epoch: 010 | loss: 0.69327 - acc: 0.5011 -- iter: 160/300
[A[ATraining Step: 96  | total loss: [1m[32m0.69341[0m[0m | time: 7.703s
[2K
| Adam | epoch: 010 | loss: 0.69341 - acc: 0.4947 -- iter: 192/300
[A[ATraining Step: 97  | total loss: [1m[32m0.69356[0m[0m | time: 9.140s
[2K
| Adam | epoch: 010 | loss: 0.69356 - acc: 0.4859 -- iter: 224/300
[A[ATraining Step: 98  | total loss: [1m[32m0.69329[0m[0m | time: 9.692s
[2K
| Adam | epoch: 010 | loss: 0.69329 - acc: 0.4998 -- iter: 256/300
[A[ATraining Step: 99  | total loss: [1m[32m0.69345[0m[0m | time: 10.286s
[2K
| Adam | epoch: 010 | loss: 0.69345 - acc: 0.4915 -- iter: 288/300
[A[ATraining Step: 100  | total loss: [1m[32m0.69371[0m[0m | time: 12.778s
[2K
| Adam | epoch: 010 | loss: 0.69371 - acc: 0.4757 | val_loss: 0.69473 - val_acc: 0.3830 -- iter: 300/300
--
Training Step: 101  | total loss: [1m[32m0.69363[0m[0m | time: 1.281s
[2K
| Adam | epoch: 011 | loss: 0.69363 - acc: 0.4812 -- iter: 032/300
[A[ATraining Step: 102  | total loss: [1m[32m0.69347[0m[0m | time: 2.292s
[2K
| Adam | epoch: 011 | loss: 0.69347 - acc: 0.4894 -- iter: 064/300
[A[ATraining Step: 103  | total loss: [1m[32m0.69337[0m[0m | time: 3.444s
[2K
| Adam | epoch: 011 | loss: 0.69337 - acc: 0.4967 -- iter: 096/300
[A[ATraining Step: 104  | total loss: [1m[32m0.69330[0m[0m | time: 4.918s
[2K
| Adam | epoch: 011 | loss: 0.69330 - acc: 0.5001 -- iter: 128/300
[A[ATraining Step: 105  | total loss: [1m[32m0.69333[0m[0m | time: 6.204s
[2K
| Adam | epoch: 011 | loss: 0.69333 - acc: 0.4970 -- iter: 160/300
[A[ATraining Step: 106  | total loss: [1m[32m0.69342[0m[0m | time: 7.407s
[2K
| Adam | epoch: 011 | loss: 0.69342 - acc: 0.4879 -- iter: 192/300
[A[ATraining Step: 107  | total loss: [1m[32m0.69347[0m[0m | time: 8.859s
[2K
| Adam | epoch: 011 | loss: 0.69347 - acc: 0.4829 -- iter: 224/300
[A[ATraining Step: 108  | total loss: [1m[32m0.69348[0m[0m | time: 10.139s
[2K
| Adam | epoch: 011 | loss: 0.69348 - acc: 0.4783 -- iter: 256/300
[A[ATraining Step: 109  | total loss: [1m[32m0.69334[0m[0m | time: 10.806s
[2K
| Adam | epoch: 011 | loss: 0.69334 - acc: 0.4961 -- iter: 288/300
[A[ATraining Step: 110  | total loss: [1m[32m0.69340[0m[0m | time: 12.443s
[2K
| Adam | epoch: 011 | loss: 0.69340 - acc: 0.4798 | val_loss: 0.69358 - val_acc: 0.3830 -- iter: 300/300
--
Training Step: 111  | total loss: [1m[32m0.69337[0m[0m | time: 1.182s
[2K
| Adam | epoch: 012 | loss: 0.69337 - acc: 0.4819 -- iter: 032/300
[A[ATraining Step: 112  | total loss: [1m[32m0.69335[0m[0m | time: 2.340s
[2K
| Adam | epoch: 012 | loss: 0.69335 - acc: 0.4837 -- iter: 064/300
[A[ATraining Step: 113  | total loss: [1m[32m0.69334[0m[0m | time: 3.644s
[2K
| Adam | epoch: 012 | loss: 0.69334 - acc: 0.4728 -- iter: 096/300
[A[ATraining Step: 114  | total loss: [1m[32m0.69328[0m[0m | time: 5.035s
[2K
| Adam | epoch: 012 | loss: 0.69328 - acc: 0.4974 -- iter: 128/300
[A[ATraining Step: 115  | total loss: [1m[32m0.69327[0m[0m | time: 6.320s
[2K
| Adam | epoch: 012 | loss: 0.69327 - acc: 0.4945 -- iter: 160/300
[A[ATraining Step: 116  | total loss: [1m[32m0.69326[0m[0m | time: 7.378s
[2K
| Adam | epoch: 012 | loss: 0.69326 - acc: 0.4920 -- iter: 192/300
[A[ATraining Step: 117  | total loss: [1m[32m0.69325[0m[0m | time: 8.898s
[2K
| Adam | epoch: 012 | loss: 0.69325 - acc: 0.4959 -- iter: 224/300
[A[ATraining Step: 118  | total loss: [1m[32m0.69323[0m[0m | time: 10.222s
[2K
| Adam | epoch: 012 | loss: 0.69323 - acc: 0.4994 -- iter: 256/300
[A[ATraining Step: 119  | total loss: [1m[32m0.69321[0m[0m | time: 11.598s
[2K
| Adam | epoch: 012 | loss: 0.69321 - acc: 0.5089 -- iter: 288/300
[A[ATraining Step: 120  | total loss: [1m[32m0.69322[0m[0m | time: 13.014s
[2K
| Adam | epoch: 012 | loss: 0.69322 - acc: 0.5080 | val_loss: 0.69283 - val_acc: 0.6170 -- iter: 300/300
--
Training Step: 121  | total loss: [1m[32m0.69317[0m[0m | time: 0.491s
[2K
| Adam | epoch: 013 | loss: 0.69317 - acc: 0.5072 -- iter: 032/300
[A[ATraining Step: 122  | total loss: [1m[32m0.69318[0m[0m | time: 1.641s
[2K
| Adam | epoch: 013 | loss: 0.69318 - acc: 0.5065 -- iter: 064/300
[A[ATraining Step: 123  | total loss: [1m[32m0.69318[0m[0m | time: 2.806s
[2K
| Adam | epoch: 013 | loss: 0.69318 - acc: 0.5058 -- iter: 096/300
[A[ATraining Step: 124  | total loss: [1m[32m0.69319[0m[0m | time: 4.173s
[2K
| Adam | epoch: 013 | loss: 0.69319 - acc: 0.4990 -- iter: 128/300
[A[ATraining Step: 125  | total loss: [1m[32m0.69317[0m[0m | time: 5.560s
[2K
| Adam | epoch: 013 | loss: 0.69317 - acc: 0.4991 -- iter: 160/300
[A[ATraining Step: 126  | total loss: [1m[32m0.69315[0m[0m | time: 6.731s
[2K
| Adam | epoch: 013 | loss: 0.69315 - acc: 0.5117 -- iter: 192/300
[A[ATraining Step: 127  | total loss: [1m[32m0.69310[0m[0m | time: 8.032s
[2K
| Adam | epoch: 013 | loss: 0.69310 - acc: 0.5355 -- iter: 224/300
[A[ATraining Step: 128  | total loss: [1m[32m0.69307[0m[0m | time: 9.470s
[2K
| Adam | epoch: 013 | loss: 0.69307 - acc: 0.5351 -- iter: 256/300
[A[ATraining Step: 129  | total loss: [1m[32m0.69303[0m[0m | time: 11.010s
[2K
| Adam | epoch: 013 | loss: 0.69303 - acc: 0.5347 -- iter: 288/300
[A[ATraining Step: 130  | total loss: [1m[32m0.69302[0m[0m | time: 13.612s
[2K
| Adam | epoch: 013 | loss: 0.69302 - acc: 0.5219 | val_loss: 0.69281 - val_acc: 0.4681 -- iter: 300/300
--
Training Step: 131  | total loss: [1m[32m0.69294[0m[0m | time: 0.538s
[2K
| Adam | epoch: 014 | loss: 0.69294 - acc: 0.5322 -- iter: 032/300
[A[ATraining Step: 132  | total loss: [1m[32m0.69283[0m[0m | time: 1.013s
[2K
| Adam | epoch: 014 | loss: 0.69283 - acc: 0.5373 -- iter: 064/300
[A[ATraining Step: 133  | total loss: [1m[32m0.69293[0m[0m | time: 2.162s
[2K
| Adam | epoch: 014 | loss: 0.69293 - acc: 0.5169 -- iter: 096/300
[A[ATraining Step: 134  | total loss: [1m[32m0.69302[0m[0m | time: 3.387s
[2K
| Adam | epoch: 014 | loss: 0.69302 - acc: 0.5121 -- iter: 128/300
[A[ATraining Step: 135  | total loss: [1m[32m0.69291[0m[0m | time: 4.761s
[2K
| Adam | epoch: 014 | loss: 0.69291 - acc: 0.5265 -- iter: 160/300
[A[ATraining Step: 136  | total loss: [1m[32m0.69282[0m[0m | time: 6.076s
[2K
| Adam | epoch: 014 | loss: 0.69282 - acc: 0.5363 -- iter: 192/300
[A[ATraining Step: 137  | total loss: [1m[32m0.69273[0m[0m | time: 7.234s
[2K
| Adam | epoch: 014 | loss: 0.69273 - acc: 0.5483 -- iter: 224/300
[A[ATraining Step: 138  | total loss: [1m[32m0.69250[0m[0m | time: 8.553s
[2K
| Adam | epoch: 014 | loss: 0.69250 - acc: 0.5623 -- iter: 256/300
[A[ATraining Step: 139  | total loss: [1m[32m0.69218[0m[0m | time: 10.080s
[2K
| Adam | epoch: 014 | loss: 0.69218 - acc: 0.5560 -- iter: 288/300
[A[ATraining Step: 140  | total loss: [1m[32m0.69209[0m[0m | time: 12.402s
[2K
| Adam | epoch: 014 | loss: 0.69209 - acc: 0.5473 | val_loss: 0.68897 - val_acc: 0.5957 -- iter: 300/300
--
Training Step: 141  | total loss: [1m[32m0.69146[0m[0m | time: 0.989s
[2K
| Adam | epoch: 015 | loss: 0.69146 - acc: 0.5519 -- iter: 032/300
[A[ATraining Step: 142  | total loss: [1m[32m0.69039[0m[0m | time: 1.456s
[2K
| Adam | epoch: 015 | loss: 0.69039 - acc: 0.5624 -- iter: 064/300
[A[ATraining Step: 143  | total loss: [1m[32m0.69131[0m[0m | time: 1.935s
[2K
| Adam | epoch: 015 | loss: 0.69131 - acc: 0.5561 -- iter: 096/300
[A[ATraining Step: 144  | total loss: [1m[32m0.69066[0m[0m | time: 3.135s
[2K
| Adam | epoch: 015 | loss: 0.69066 - acc: 0.5589 -- iter: 128/300
[A[ATraining Step: 145  | total loss: [1m[32m0.69089[0m[0m | time: 4.307s
[2K
| Adam | epoch: 015 | loss: 0.69089 - acc: 0.5467 -- iter: 160/300
[A[ATraining Step: 146  | total loss: [1m[32m0.69045[0m[0m | time: 5.448s
[2K
| Adam | epoch: 015 | loss: 0.69045 - acc: 0.5545 -- iter: 192/300
[A[ATraining Step: 147  | total loss: [1m[32m0.68858[0m[0m | time: 6.709s
[2K
| Adam | epoch: 015 | loss: 0.68858 - acc: 0.5803 -- iter: 224/300
[A[ATraining Step: 148  | total loss: [1m[32m0.68590[0m[0m | time: 8.243s
[2K
| Adam | epoch: 015 | loss: 0.68590 - acc: 0.5973 -- iter: 256/300
[A[ATraining Step: 149  | total loss: [1m[32m0.68395[0m[0m | time: 9.534s
[2K
| Adam | epoch: 015 | loss: 0.68395 - acc: 0.5907 -- iter: 288/300
[A[ATraining Step: 150  | total loss: [1m[32m0.67732[0m[0m | time: 11.754s
[2K
| Adam | epoch: 015 | loss: 0.67732 - acc: 0.5973 | val_loss: 0.67354 - val_acc: 0.6064 -- iter: 300/300
--
Training Step: 151  | total loss: [1m[32m0.67490[0m[0m | time: 1.253s
[2K
| Adam | epoch: 016 | loss: 0.67490 - acc: 0.5938 -- iter: 032/300
[A[ATraining Step: 152  | total loss: [1m[32m0.66870[0m[0m | time: 2.392s
[2K
| Adam | epoch: 016 | loss: 0.66870 - acc: 0.6063 -- iter: 064/300
[A[ATraining Step: 153  | total loss: [1m[32m0.66313[0m[0m | time: 2.958s
[2K
| Adam | epoch: 016 | loss: 0.66313 - acc: 0.6175 -- iter: 096/300
[A[ATraining Step: 154  | total loss: [1m[32m0.65340[0m[0m | time: 3.428s
[2K
| Adam | epoch: 016 | loss: 0.65340 - acc: 0.6391 -- iter: 128/300
[A[ATraining Step: 155  | total loss: [1m[32m0.63984[0m[0m | time: 4.687s
[2K
| Adam | epoch: 016 | loss: 0.63984 - acc: 0.6502 -- iter: 160/300
[A[ATraining Step: 156  | total loss: [1m[32m0.63112[0m[0m | time: 5.869s
[2K
| Adam | epoch: 016 | loss: 0.63112 - acc: 0.6571 -- iter: 192/300
[A[ATraining Step: 157  | total loss: [1m[32m0.63410[0m[0m | time: 7.071s
[2K
| Adam | epoch: 016 | loss: 0.63410 - acc: 0.6570 -- iter: 224/300
[A[ATraining Step: 158  | total loss: [1m[32m0.62828[0m[0m | time: 8.398s
[2K
| Adam | epoch: 016 | loss: 0.62828 - acc: 0.6663 -- iter: 256/300
[A[ATraining Step: 159  | total loss: [1m[32m0.64431[0m[0m | time: 9.849s
[2K
| Adam | epoch: 016 | loss: 0.64431 - acc: 0.6559 -- iter: 288/300
[A[ATraining Step: 160  | total loss: [1m[32m0.62763[0m[0m | time: 12.085s
[2K
| Adam | epoch: 016 | loss: 0.62763 - acc: 0.6716 | val_loss: 0.57772 - val_acc: 0.7660 -- iter: 300/300
--
Training Step: 161  | total loss: [1m[32m0.62724[0m[0m | time: 1.320s
[2K
| Adam | epoch: 017 | loss: 0.62724 - acc: 0.6700 -- iter: 032/300
[A[ATraining Step: 162  | total loss: [1m[32m0.62840[0m[0m | time: 2.745s
[2K
| Adam | epoch: 017 | loss: 0.62840 - acc: 0.6718 -- iter: 064/300
[A[ATraining Step: 163  | total loss: [1m[32m0.61149[0m[0m | time: 4.126s
[2K
| Adam | epoch: 017 | loss: 0.61149 - acc: 0.6921 -- iter: 096/300
[A[ATraining Step: 164  | total loss: [1m[32m0.61271[0m[0m | time: 4.566s
[2K
| Adam | epoch: 017 | loss: 0.61271 - acc: 0.6885 -- iter: 128/300
[A[ATraining Step: 165  | total loss: [1m[32m0.60399[0m[0m | time: 5.008s
[2K
| Adam | epoch: 017 | loss: 0.60399 - acc: 0.6947 -- iter: 160/300
[A[ATraining Step: 166  | total loss: [1m[32m0.60478[0m[0m | time: 5.991s
[2K
| Adam | epoch: 017 | loss: 0.60478 - acc: 0.6919 -- iter: 192/300
[A[ATraining Step: 167  | total loss: [1m[32m0.59849[0m[0m | time: 7.240s
[2K
| Adam | epoch: 017 | loss: 0.59849 - acc: 0.6946 -- iter: 224/300
[A[ATraining Step: 168  | total loss: [1m[32m0.60248[0m[0m | time: 8.671s
[2K
| Adam | epoch: 017 | loss: 0.60248 - acc: 0.6907 -- iter: 256/300
[A[ATraining Step: 169  | total loss: [1m[32m0.59583[0m[0m | time: 9.965s
[2K
| Adam | epoch: 017 | loss: 0.59583 - acc: 0.6873 -- iter: 288/300
[A[ATraining Step: 170  | total loss: [1m[32m0.58751[0m[0m | time: 12.209s
[2K
| Adam | epoch: 017 | loss: 0.58751 - acc: 0.6935 | val_loss: 0.64165 - val_acc: 0.6809 -- iter: 300/300
--
Training Step: 171  | total loss: [1m[32m0.58823[0m[0m | time: 1.310s
[2K
| Adam | epoch: 018 | loss: 0.58823 - acc: 0.6898 -- iter: 032/300
[A[ATraining Step: 172  | total loss: [1m[32m0.58983[0m[0m | time: 2.217s
[2K
| Adam | epoch: 018 | loss: 0.58983 - acc: 0.6958 -- iter: 064/300
[A[ATraining Step: 173  | total loss: [1m[32m0.58535[0m[0m | time: 3.412s
[2K
| Adam | epoch: 018 | loss: 0.58535 - acc: 0.6981 -- iter: 096/300
[A[ATraining Step: 174  | total loss: [1m[32m0.56934[0m[0m | time: 4.588s
[2K
| Adam | epoch: 018 | loss: 0.56934 - acc: 0.7158 -- iter: 128/300
[A[ATraining Step: 175  | total loss: [1m[32m0.55303[0m[0m | time: 5.060s
[2K
| Adam | epoch: 018 | loss: 0.55303 - acc: 0.7349 -- iter: 160/300
[A[ATraining Step: 176  | total loss: [1m[32m0.56458[0m[0m | time: 5.543s
[2K
| Adam | epoch: 018 | loss: 0.56458 - acc: 0.7197 -- iter: 192/300
[A[ATraining Step: 177  | total loss: [1m[32m0.53932[0m[0m | time: 6.755s
[2K
| Adam | epoch: 018 | loss: 0.53932 - acc: 0.7394 -- iter: 224/300
[A[ATraining Step: 178  | total loss: [1m[32m0.53076[0m[0m | time: 8.077s
[2K
| Adam | epoch: 018 | loss: 0.53076 - acc: 0.7436 -- iter: 256/300
[A[ATraining Step: 179  | total loss: [1m[32m0.54966[0m[0m | time: 9.379s
[2K
| Adam | epoch: 018 | loss: 0.54966 - acc: 0.7286 -- iter: 288/300
[A[ATraining Step: 180  | total loss: [1m[32m0.54034[0m[0m | time: 11.875s
[2K
| Adam | epoch: 018 | loss: 0.54034 - acc: 0.7307 | val_loss: 0.52923 - val_acc: 0.7766 -- iter: 300/300
--
Training Step: 181  | total loss: [1m[32m0.54329[0m[0m | time: 0.968s
[2K
| Adam | epoch: 019 | loss: 0.54329 - acc: 0.7264 -- iter: 032/300
[A[ATraining Step: 182  | total loss: [1m[32m0.53261[0m[0m | time: 2.073s
[2K
| Adam | epoch: 019 | loss: 0.53261 - acc: 0.7382 -- iter: 064/300
[A[ATraining Step: 183  | total loss: [1m[32m0.54509[0m[0m | time: 3.231s
[2K
| Adam | epoch: 019 | loss: 0.54509 - acc: 0.7268 -- iter: 096/300
[A[ATraining Step: 184  | total loss: [1m[32m0.53769[0m[0m | time: 4.432s
[2K
| Adam | epoch: 019 | loss: 0.53769 - acc: 0.7323 -- iter: 128/300
[A[ATraining Step: 185  | total loss: [1m[32m0.53453[0m[0m | time: 5.666s
[2K
| Adam | epoch: 019 | loss: 0.53453 - acc: 0.7309 -- iter: 160/300
[A[ATraining Step: 186  | total loss: [1m[32m0.54372[0m[0m | time: 6.179s
[2K
| Adam | epoch: 019 | loss: 0.54372 - acc: 0.7235 -- iter: 192/300
[A[ATraining Step: 187  | total loss: [1m[32m0.51558[0m[0m | time: 6.717s
[2K
| Adam | epoch: 019 | loss: 0.51558 - acc: 0.7428 -- iter: 224/300
[A[ATraining Step: 188  | total loss: [1m[32m0.49402[0m[0m | time: 8.049s
[2K
| Adam | epoch: 019 | loss: 0.49402 - acc: 0.7518 -- iter: 256/300
[A[ATraining Step: 189  | total loss: [1m[32m0.49812[0m[0m | time: 9.175s
[2K
| Adam | epoch: 019 | loss: 0.49812 - acc: 0.7485 -- iter: 288/300
[A[ATraining Step: 190  | total loss: [1m[32m0.50880[0m[0m | time: 11.343s
[2K
| Adam | epoch: 019 | loss: 0.50880 - acc: 0.7393 | val_loss: 0.53122 - val_acc: 0.7766 -- iter: 300/300
--
Training Step: 191  | total loss: [1m[32m0.52578[0m[0m | time: 1.503s
[2K
| Adam | epoch: 020 | loss: 0.52578 - acc: 0.7279 -- iter: 032/300
[A[ATraining Step: 192  | total loss: [1m[32m0.52148[0m[0m | time: 2.625s
[2K
| Adam | epoch: 020 | loss: 0.52148 - acc: 0.7332 -- iter: 064/300
[A[ATraining Step: 193  | total loss: [1m[32m0.50869[0m[0m | time: 3.831s
[2K
| Adam | epoch: 020 | loss: 0.50869 - acc: 0.7474 -- iter: 096/300
[A[ATraining Step: 194  | total loss: [1m[32m0.51285[0m[0m | time: 5.035s
[2K
| Adam | epoch: 020 | loss: 0.51285 - acc: 0.7414 -- iter: 128/300
[A[ATraining Step: 195  | total loss: [1m[32m0.50708[0m[0m | time: 6.177s
[2K
| Adam | epoch: 020 | loss: 0.50708 - acc: 0.7485 -- iter: 160/300
[A[ATraining Step: 196  | total loss: [1m[32m0.50608[0m[0m | time: 7.452s
[2K
| Adam | epoch: 020 | loss: 0.50608 - acc: 0.7518 -- iter: 192/300
[A[ATraining Step: 197  | total loss: [1m[32m0.49581[0m[0m | time: 8.010s
[2K
| Adam | epoch: 020 | loss: 0.49581 - acc: 0.7610 -- iter: 224/300
[A[ATraining Step: 198  | total loss: [1m[32m0.48704[0m[0m | time: 8.582s
[2K
| Adam | epoch: 020 | loss: 0.48704 - acc: 0.7682 -- iter: 256/300
[A[ATraining Step: 199  | total loss: [1m[32m0.48206[0m[0m | time: 9.962s
[2K
| Adam | epoch: 020 | loss: 0.48206 - acc: 0.7747 -- iter: 288/300
[A[ATraining Step: 200  | total loss: [1m[32m0.47630[0m[0m | time: 12.206s
[2K
| Adam | epoch: 020 | loss: 0.47630 - acc: 0.7785 | val_loss: 0.50115 - val_acc: 0.7872 -- iter: 300/300
--
Training Step: 201  | total loss: [1m[32m0.47917[0m[0m | time: 1.145s
[2K
| Adam | epoch: 021 | loss: 0.47917 - acc: 0.7788 -- iter: 032/300
[A[ATraining Step: 202  | total loss: [1m[32m0.50216[0m[0m | time: 2.158s
[2K
| Adam | epoch: 021 | loss: 0.50216 - acc: 0.7634 -- iter: 064/300
[A[ATraining Step: 203  | total loss: [1m[32m0.48338[0m[0m | time: 3.410s
[2K
| Adam | epoch: 021 | loss: 0.48338 - acc: 0.7746 -- iter: 096/300
[A[ATraining Step: 204  | total loss: [1m[32m0.47965[0m[0m | time: 4.578s
[2K
| Adam | epoch: 021 | loss: 0.47965 - acc: 0.7752 -- iter: 128/300
[A[ATraining Step: 205  | total loss: [1m[32m0.46736[0m[0m | time: 5.825s
[2K
| Adam | epoch: 021 | loss: 0.46736 - acc: 0.7790 -- iter: 160/300
[A[ATraining Step: 206  | total loss: [1m[32m0.45201[0m[0m | time: 7.041s
[2K
| Adam | epoch: 021 | loss: 0.45201 - acc: 0.7917 -- iter: 192/300
[A[ATraining Step: 207  | total loss: [1m[32m0.44815[0m[0m | time: 8.540s
[2K
| Adam | epoch: 021 | loss: 0.44815 - acc: 0.7938 -- iter: 224/300
[A[ATraining Step: 208  | total loss: [1m[32m0.42907[0m[0m | time: 9.158s
[2K
| Adam | epoch: 021 | loss: 0.42907 - acc: 0.8050 -- iter: 256/300
[A[ATraining Step: 209  | total loss: [1m[32m0.42794[0m[0m | time: 9.635s
[2K
| Adam | epoch: 021 | loss: 0.42794 - acc: 0.7912 -- iter: 288/300
[A[ATraining Step: 210  | total loss: [1m[32m0.52271[0m[0m | time: 11.769s
[2K
| Adam | epoch: 021 | loss: 0.52271 - acc: 0.7537 | val_loss: 0.55376 - val_acc: 0.7553 -- iter: 300/300
--
Training Step: 211  | total loss: [1m[32m0.52445[0m[0m | time: 1.320s
[2K
| Adam | epoch: 022 | loss: 0.52445 - acc: 0.7534 -- iter: 032/300
[A[ATraining Step: 212  | total loss: [1m[32m0.53724[0m[0m | time: 2.508s
[2K
| Adam | epoch: 022 | loss: 0.53724 - acc: 0.7405 -- iter: 064/300
[A[ATraining Step: 213  | total loss: [1m[32m0.53766[0m[0m | time: 4.571s
[2K
| Adam | epoch: 022 | loss: 0.53766 - acc: 0.7383 -- iter: 096/300
[A[ATraining Step: 214  | total loss: [1m[32m0.53786[0m[0m | time: 5.839s
[2K
| Adam | epoch: 022 | loss: 0.53786 - acc: 0.7426 -- iter: 128/300
[A[ATraining Step: 215  | total loss: [1m[32m0.52342[0m[0m | time: 7.016s
[2K
| Adam | epoch: 022 | loss: 0.52342 - acc: 0.7559 -- iter: 160/300
[A[ATraining Step: 216  | total loss: [1m[32m0.51323[0m[0m | time: 8.175s
[2K
| Adam | epoch: 022 | loss: 0.51323 - acc: 0.7615 -- iter: 192/300
[A[ATraining Step: 217  | total loss: [1m[32m0.50784[0m[0m | time: 9.307s
[2K
| Adam | epoch: 022 | loss: 0.50784 - acc: 0.7666 -- iter: 224/300
[A[ATraining Step: 218  | total loss: [1m[32m0.49390[0m[0m | time: 10.784s
[2K
| Adam | epoch: 022 | loss: 0.49390 - acc: 0.7775 -- iter: 256/300
[A[ATraining Step: 219  | total loss: [1m[32m0.48970[0m[0m | time: 11.409s
[2K
| Adam | epoch: 022 | loss: 0.48970 - acc: 0.7685 -- iter: 288/300
[A[ATraining Step: 220  | total loss: [1m[32m0.48079[0m[0m | time: 13.021s
[2K
| Adam | epoch: 022 | loss: 0.48079 - acc: 0.7750 | val_loss: 0.50765 - val_acc: 0.7872 -- iter: 300/300
--
Training Step: 221  | total loss: [1m[32m0.46168[0m[0m | time: 1.502s
[2K
| Adam | epoch: 023 | loss: 0.46168 - acc: 0.7891 -- iter: 032/300
[A[ATraining Step: 222  | total loss: [1m[32m0.45791[0m[0m | time: 2.668s
[2K
| Adam | epoch: 023 | loss: 0.45791 - acc: 0.7915 -- iter: 064/300
[A[ATraining Step: 223  | total loss: [1m[32m0.45574[0m[0m | time: 3.618s
[2K
| Adam | epoch: 023 | loss: 0.45574 - acc: 0.7936 -- iter: 096/300
[A[ATraining Step: 224  | total loss: [1m[32m0.43483[0m[0m | time: 4.736s
[2K
| Adam | epoch: 023 | loss: 0.43483 - acc: 0.8111 -- iter: 128/300
[A[ATraining Step: 225  | total loss: [1m[32m0.43835[0m[0m | time: 5.923s
[2K
| Adam | epoch: 023 | loss: 0.43835 - acc: 0.8112 -- iter: 160/300
[A[ATraining Step: 226  | total loss: [1m[32m0.43329[0m[0m | time: 7.236s
[2K
| Adam | epoch: 023 | loss: 0.43329 - acc: 0.8145 -- iter: 192/300
[A[ATraining Step: 227  | total loss: [1m[32m0.44064[0m[0m | time: 8.739s
[2K
| Adam | epoch: 023 | loss: 0.44064 - acc: 0.8080 -- iter: 224/300
[A[ATraining Step: 228  | total loss: [1m[32m0.44512[0m[0m | time: 10.284s
[2K
| Adam | epoch: 023 | loss: 0.44512 - acc: 0.7991 -- iter: 256/300
[A[ATraining Step: 229  | total loss: [1m[32m0.43084[0m[0m | time: 11.718s
[2K
| Adam | epoch: 023 | loss: 0.43084 - acc: 0.8036 -- iter: 288/300
[A[ATraining Step: 230  | total loss: [1m[32m0.42720[0m[0m | time: 13.230s
[2K
| Adam | epoch: 023 | loss: 0.42720 - acc: 0.8107 | val_loss: 0.48188 - val_acc: 0.7979 -- iter: 300/300
--
Training Step: 231  | total loss: [1m[32m0.40610[0m[0m | time: 2.158s
[2K
| Adam | epoch: 024 | loss: 0.40610 - acc: 0.8296 -- iter: 032/300
[A[ATraining Step: 232  | total loss: [1m[32m0.40952[0m[0m | time: 3.165s
[2K
| Adam | epoch: 024 | loss: 0.40952 - acc: 0.8217 -- iter: 064/300
[A[ATraining Step: 233  | total loss: [1m[32m0.40440[0m[0m | time: 4.334s
[2K
| Adam | epoch: 024 | loss: 0.40440 - acc: 0.8239 -- iter: 096/300
[A[ATraining Step: 234  | total loss: [1m[32m0.40334[0m[0m | time: 5.516s
[2K
| Adam | epoch: 024 | loss: 0.40334 - acc: 0.8259 -- iter: 128/300
[A[ATraining Step: 235  | total loss: [1m[32m0.40551[0m[0m | time: 6.694s
[2K
| Adam | epoch: 024 | loss: 0.40551 - acc: 0.8245 -- iter: 160/300
[A[ATraining Step: 236  | total loss: [1m[32m0.40095[0m[0m | time: 7.999s
[2K
| Adam | epoch: 024 | loss: 0.40095 - acc: 0.8265 -- iter: 192/300
[A[ATraining Step: 237  | total loss: [1m[32m0.39367[0m[0m | time: 9.388s
[2K
| Adam | epoch: 024 | loss: 0.39367 - acc: 0.8251 -- iter: 224/300
[A[ATraining Step: 238  | total loss: [1m[32m0.38150[0m[0m | time: 10.728s
[2K
| Adam | epoch: 024 | loss: 0.38150 - acc: 0.8332 -- iter: 256/300
[A[ATraining Step: 239  | total loss: [1m[32m0.37313[0m[0m | time: 11.921s
[2K
| Adam | epoch: 024 | loss: 0.37313 - acc: 0.8405 -- iter: 288/300
[A[ATraining Step: 240  | total loss: [1m[32m0.35397[0m[0m | time: 14.465s
[2K
| Adam | epoch: 024 | loss: 0.35397 - acc: 0.8564 | val_loss: 0.45455 - val_acc: 0.8191 -- iter: 300/300
--
Training Step: 241  | total loss: [1m[32m0.35696[0m[0m | time: 1.390s
[2K
| Adam | epoch: 025 | loss: 0.35696 - acc: 0.8583 -- iter: 032/300
[A[ATraining Step: 242  | total loss: [1m[32m0.35776[0m[0m | time: 1.846s
[2K
| Adam | epoch: 025 | loss: 0.35776 - acc: 0.8641 -- iter: 064/300
[A[ATraining Step: 243  | total loss: [1m[32m0.35641[0m[0m | time: 3.092s
[2K
| Adam | epoch: 025 | loss: 0.35641 - acc: 0.8694 -- iter: 096/300
[A[ATraining Step: 244  | total loss: [1m[32m0.34284[0m[0m | time: 4.296s
[2K
| Adam | epoch: 025 | loss: 0.34284 - acc: 0.8731 -- iter: 128/300
[A[ATraining Step: 245  | total loss: [1m[32m0.33470[0m[0m | time: 5.514s
[2K
| Adam | epoch: 025 | loss: 0.33470 - acc: 0.8733 -- iter: 160/300
[A[ATraining Step: 246  | total loss: [1m[32m0.34484[0m[0m | time: 6.730s
[2K
| Adam | epoch: 025 | loss: 0.34484 - acc: 0.8641 -- iter: 192/300
[A[ATraining Step: 247  | total loss: [1m[32m0.33784[0m[0m | time: 8.196s
[2K
| Adam | epoch: 025 | loss: 0.33784 - acc: 0.8683 -- iter: 224/300
[A[ATraining Step: 248  | total loss: [1m[32m0.36160[0m[0m | time: 9.534s
[2K
| Adam | epoch: 025 | loss: 0.36160 - acc: 0.8565 -- iter: 256/300
[A[ATraining Step: 249  | total loss: [1m[32m0.35023[0m[0m | time: 10.846s
[2K
| Adam | epoch: 025 | loss: 0.35023 - acc: 0.8614 -- iter: 288/300
[A[ATraining Step: 250  | total loss: [1m[32m0.35121[0m[0m | time: 13.223s
[2K
| Adam | epoch: 025 | loss: 0.35121 - acc: 0.8597 | val_loss: 0.48264 - val_acc: 0.7872 -- iter: 300/300
--
Training Step: 251  | total loss: [1m[32m0.34764[0m[0m | time: 3.355s
[2K
| Adam | epoch: 026 | loss: 0.34764 - acc: 0.8612 -- iter: 032/300
[A[ATraining Step: 252  | total loss: [1m[32m0.33927[0m[0m | time: 3.813s
[2K
| Adam | epoch: 026 | loss: 0.33927 - acc: 0.8657 -- iter: 064/300
[A[ATraining Step: 253  | total loss: [1m[32m0.31971[0m[0m | time: 4.355s
[2K
| Adam | epoch: 026 | loss: 0.31971 - acc: 0.8791 -- iter: 096/300
[A[ATraining Step: 254  | total loss: [1m[32m0.34770[0m[0m | time: 5.509s
[2K
| Adam | epoch: 026 | loss: 0.34770 - acc: 0.8662 -- iter: 128/300
[A[ATraining Step: 255  | total loss: [1m[32m0.34327[0m[0m | time: 6.630s
[2K
| Adam | epoch: 026 | loss: 0.34327 - acc: 0.8640 -- iter: 160/300
[A[ATraining Step: 256  | total loss: [1m[32m0.33199[0m[0m | time: 7.787s
[2K
| Adam | epoch: 026 | loss: 0.33199 - acc: 0.8682 -- iter: 192/300
[A[ATraining Step: 257  | total loss: [1m[32m0.32225[0m[0m | time: 9.124s
[2K
| Adam | epoch: 026 | loss: 0.32225 - acc: 0.8751 -- iter: 224/300
[A[ATraining Step: 258  | total loss: [1m[32m0.31730[0m[0m | time: 10.391s
[2K
| Adam | epoch: 026 | loss: 0.31730 - acc: 0.8782 -- iter: 256/300
[A[ATraining Step: 259  | total loss: [1m[32m0.31137[0m[0m | time: 11.623s
[2K
| Adam | epoch: 026 | loss: 0.31137 - acc: 0.8810 -- iter: 288/300
[A[ATraining Step: 260  | total loss: [1m[32m0.30214[0m[0m | time: 13.779s
[2K
| Adam | epoch: 026 | loss: 0.30214 - acc: 0.8867 | val_loss: 0.44723 - val_acc: 0.8191 -- iter: 300/300
--
Training Step: 261  | total loss: [1m[32m0.29553[0m[0m | time: 0.963s
[2K
| Adam | epoch: 027 | loss: 0.29553 - acc: 0.8918 -- iter: 032/300
[A[ATraining Step: 262  | total loss: [1m[32m0.29770[0m[0m | time: 2.027s
[2K
| Adam | epoch: 027 | loss: 0.29770 - acc: 0.8901 -- iter: 064/300
[A[ATraining Step: 263  | total loss: [1m[32m0.29500[0m[0m | time: 2.471s
[2K
| Adam | epoch: 027 | loss: 0.29500 - acc: 0.8917 -- iter: 096/300
[A[ATraining Step: 264  | total loss: [1m[32m0.30175[0m[0m | time: 2.943s
[2K
| Adam | epoch: 027 | loss: 0.30175 - acc: 0.8859 -- iter: 128/300
[A[ATraining Step: 265  | total loss: [1m[32m0.30484[0m[0m | time: 4.110s
[2K
| Adam | epoch: 027 | loss: 0.30484 - acc: 0.8806 -- iter: 160/300
[A[ATraining Step: 266  | total loss: [1m[32m0.30481[0m[0m | time: 5.227s
[2K
| Adam | epoch: 027 | loss: 0.30481 - acc: 0.8738 -- iter: 192/300
[A[ATraining Step: 267  | total loss: [1m[32m0.29265[0m[0m | time: 6.492s
[2K
| Adam | epoch: 027 | loss: 0.29265 - acc: 0.8833 -- iter: 224/300
[A[ATraining Step: 268  | total loss: [1m[32m0.29410[0m[0m | time: 8.020s
[2K
| Adam | epoch: 027 | loss: 0.29410 - acc: 0.8793 -- iter: 256/300
[A[ATraining Step: 269  | total loss: [1m[32m0.27500[0m[0m | time: 9.299s
[2K
| Adam | epoch: 027 | loss: 0.27500 - acc: 0.8914 -- iter: 288/300
[A[ATraining Step: 270  | total loss: [1m[32m0.27251[0m[0m | time: 11.453s
[2K
| Adam | epoch: 027 | loss: 0.27251 - acc: 0.8960 | val_loss: 0.45316 - val_acc: 0.8191 -- iter: 300/300
--
Training Step: 271  | total loss: [1m[32m0.26951[0m[0m | time: 5.307s
[2K
| Adam | epoch: 028 | loss: 0.26951 - acc: 0.9002 -- iter: 032/300
[A[ATraining Step: 272  | total loss: [1m[32m0.27393[0m[0m | time: 6.366s
[2K
| Adam | epoch: 028 | loss: 0.27393 - acc: 0.8977 -- iter: 064/300
[A[ATraining Step: 273  | total loss: [1m[32m0.26387[0m[0m | time: 7.556s
[2K
| Adam | epoch: 028 | loss: 0.26387 - acc: 0.9016 -- iter: 096/300
[A[ATraining Step: 274  | total loss: [1m[32m0.25702[0m[0m | time: 8.039s
[2K
| Adam | epoch: 028 | loss: 0.25702 - acc: 0.9052 -- iter: 128/300
[A[ATraining Step: 275  | total loss: [1m[32m0.25084[0m[0m | time: 8.575s
[2K
| Adam | epoch: 028 | loss: 0.25084 - acc: 0.9064 -- iter: 160/300
[A[ATraining Step: 276  | total loss: [1m[32m0.45062[0m[0m | time: 9.785s
[2K
| Adam | epoch: 028 | loss: 0.45062 - acc: 0.8824 -- iter: 192/300
[A[ATraining Step: 277  | total loss: [1m[32m0.41517[0m[0m | time: 10.959s
[2K
| Adam | epoch: 028 | loss: 0.41517 - acc: 0.8942 -- iter: 224/300
[A[ATraining Step: 278  | total loss: [1m[32m0.39428[0m[0m | time: 12.400s
[2K
| Adam | epoch: 028 | loss: 0.39428 - acc: 0.8985 -- iter: 256/300
[A[ATraining Step: 279  | total loss: [1m[32m0.38556[0m[0m | time: 13.766s
[2K
| Adam | epoch: 028 | loss: 0.38556 - acc: 0.8961 -- iter: 288/300
[A[ATraining Step: 280  | total loss: [1m[32m0.37429[0m[0m | time: 16.010s
[2K
| Adam | epoch: 028 | loss: 0.37429 - acc: 0.8972 | val_loss: 0.66784 - val_acc: 0.7340 -- iter: 300/300
--
Training Step: 281  | total loss: [1m[32m0.35661[0m[0m | time: 2.638s
[2K
| Adam | epoch: 029 | loss: 0.35661 - acc: 0.9012 -- iter: 032/300
[A[ATraining Step: 282  | total loss: [1m[32m0.34390[0m[0m | time: 3.800s
[2K
| Adam | epoch: 029 | loss: 0.34390 - acc: 0.9048 -- iter: 064/300
[A[ATraining Step: 283  | total loss: [1m[32m0.33434[0m[0m | time: 5.014s
[2K
| Adam | epoch: 029 | loss: 0.33434 - acc: 0.9081 -- iter: 096/300
[A[ATraining Step: 284  | total loss: [1m[32m0.32303[0m[0m | time: 6.219s
[2K
| Adam | epoch: 029 | loss: 0.32303 - acc: 0.9110 -- iter: 128/300
[A[ATraining Step: 285  | total loss: [1m[32m0.31193[0m[0m | time: 6.705s
[2K
| Adam | epoch: 029 | loss: 0.31193 - acc: 0.9137 -- iter: 160/300
[A[ATraining Step: 286  | total loss: [1m[32m0.28847[0m[0m | time: 7.192s
[2K
| Adam | epoch: 029 | loss: 0.28847 - acc: 0.9223 -- iter: 192/300
[A[ATraining Step: 287  | total loss: [1m[32m0.26661[0m[0m | time: 8.468s
[2K
| Adam | epoch: 029 | loss: 0.26661 - acc: 0.9301 -- iter: 224/300
[A[ATraining Step: 288  | total loss: [1m[32m0.25637[0m[0m | time: 10.061s
[2K
| Adam | epoch: 029 | loss: 0.25637 - acc: 0.9308 -- iter: 256/300
[A[ATraining Step: 289  | total loss: [1m[32m0.25022[0m[0m | time: 11.649s
[2K
| Adam | epoch: 029 | loss: 0.25022 - acc: 0.9315 -- iter: 288/300
[A[ATraining Step: 290  | total loss: [1m[32m0.25054[0m[0m | time: 14.013s
[2K
| Adam | epoch: 029 | loss: 0.25054 - acc: 0.9290 | val_loss: 0.71207 - val_acc: 0.7553 -- iter: 300/300
--
Training Step: 291  | total loss: [1m[32m0.25060[0m[0m | time: 1.197s
[2K
| Adam | epoch: 030 | loss: 0.25060 - acc: 0.9267 -- iter: 032/300
[A[ATraining Step: 292  | total loss: [1m[32m0.25168[0m[0m | time: 2.347s
[2K
| Adam | epoch: 030 | loss: 0.25168 - acc: 0.9215 -- iter: 064/300
[A[ATraining Step: 293  | total loss: [1m[32m0.23810[0m[0m | time: 3.485s
[2K
| Adam | epoch: 030 | loss: 0.23810 - acc: 0.9231 -- iter: 096/300
[A[ATraining Step: 294  | total loss: [1m[32m0.22953[0m[0m | time: 4.690s
[2K
| Adam | epoch: 030 | loss: 0.22953 - acc: 0.9277 -- iter: 128/300
[A[ATraining Step: 295  | total loss: [1m[32m0.24904[0m[0m | time: 6.188s
[2K
| Adam | epoch: 030 | loss: 0.24904 - acc: 0.9130 -- iter: 160/300
[A[ATraining Step: 296  | total loss: [1m[32m0.23991[0m[0m | time: 6.826s
[2K
| Adam | epoch: 030 | loss: 0.23991 - acc: 0.9155 -- iter: 192/300
[A[ATraining Step: 297  | total loss: [1m[32m0.21886[0m[0m | time: 7.281s
[2K
| Adam | epoch: 030 | loss: 0.21886 - acc: 0.9239 -- iter: 224/300
[A[ATraining Step: 298  | total loss: [1m[32m0.26234[0m[0m | time: 8.391s
[2K
| Adam | epoch: 030 | loss: 0.26234 - acc: 0.9149 -- iter: 256/300
[A[ATraining Step: 299  | total loss: [1m[32m0.26383[0m[0m | time: 9.926s
[2K
| Adam | epoch: 030 | loss: 0.26383 - acc: 0.9140 -- iter: 288/300
[A[ATraining Step: 300  | total loss: [1m[32m0.25422[0m[0m | time: 12.308s
[2K
| Adam | epoch: 030 | loss: 0.25422 - acc: 0.9164 | val_loss: 0.59678 - val_acc: 0.7553 -- iter: 300/300
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8625478927203065
Validation AUPRC:0.8301693221222429
Test AUC:0.8786231884057971
Test AUPRC:0.8877956132630879
BestTestF1Score	0.77	0.53	0.77	0.75	0.78	36	12	36	10	0.79
BestTestMCCScore	0.77	0.53	0.77	0.75	0.78	36	12	36	10	0.79
BestTestAccuracyScore	0.77	0.53	0.77	0.75	0.78	36	12	36	10	0.79
BestValidationF1Score	0.77	0.62	0.82	0.76	0.78	28	9	49	8	0.79
BestValidationMCC	0.77	0.62	0.82	0.76	0.78	28	9	49	8	0.79
BestValidationAccuracy	0.77	0.62	0.82	0.76	0.78	28	9	49	8	0.79
TestPredictions (Threshold:0.79)
CHEMBL3143394,TN,INACT,0.07999999821186066	CHEMBL416069,TN,INACT,0.11999999731779099	CHEMBL446693,TN,INACT,0.05000000074505806	CHEMBL305929,TP,ACT,0.9800000190734863	CHEMBL135988,TN,INACT,0.20000000298023224	CHEMBL1719,FN,ACT,0.5799999833106995	CHEMBL131495,FN,ACT,0.47999998927116394	CHEMBL1907840,TN,INACT,0.7099999785423279	CHEMBL70811,TP,ACT,0.8999999761581421	CHEMBL21508,TN,INACT,0.7699999809265137	CHEMBL100170,TP,ACT,0.9800000190734863	CHEMBL374869,TP,ACT,0.8399999737739563	CHEMBL353304,TN,INACT,0.18000000715255737	CHEMBL17157,TP,ACT,0.9900000095367432	CHEMBL279907,TP,ACT,0.8299999833106995	CHEMBL1880624,FN,ACT,0.10999999940395355	CHEMBL348656,TP,ACT,1.0	CHEMBL1258999,FP,INACT,0.9100000262260437	CHEMBL336081,TN,INACT,0.10999999940395355	CHEMBL222881,TP,ACT,1.0	CHEMBL221462,TP,ACT,1.0	CHEMBL166089,TN,INACT,0.07999999821186066	CHEMBL2391356,TN,INACT,0.14000000059604645	CHEMBL3220628,TP,ACT,0.9900000095367432	CHEMBL16108,TN,INACT,0.20000000298023224	CHEMBL1259241,FP,INACT,0.9399999976158142	CHEMBL515170,TN,INACT,0.10999999940395355	CHEMBL308717,FN,ACT,0.6399999856948853	CHEMBL336198,TP,ACT,0.9900000095367432	CHEMBL151619,TN,INACT,0.10000000149011612	CHEMBL3220634,TP,ACT,0.9900000095367432	CHEMBL134543,TP,ACT,0.9700000286102295	CHEMBL276676,TN,INACT,0.10999999940395355	CHEMBL294345,FN,ACT,0.33000001311302185	CHEMBL998,FN,ACT,0.6700000166893005	CHEMBL153736,TP,ACT,0.9900000095367432	CHEMBL424336,TP,ACT,0.9800000190734863	CHEMBL134424,TP,ACT,0.9900000095367432	CHEMBL716,FN,ACT,0.7799999713897705	CHEMBL3218121,FP,INACT,0.9900000095367432	CHEMBL173708,TN,INACT,0.6100000143051147	CHEMBL72372,FN,ACT,0.75	CHEMBL361805,TP,ACT,1.0	CHEMBL3780248,TN,INACT,0.11999999731779099	CHEMBL221413,TP,ACT,1.0	CHEMBL35869,FN,ACT,0.5	CHEMBL374675,TP,ACT,0.9900000095367432	CHEMBL324652,TN,INACT,0.6700000166893005	CHEMBL420359,TN,INACT,0.10999999940395355	CHEMBL195893,TN,INACT,0.10999999940395355	CHEMBL375208,TP,ACT,0.9700000286102295	CHEMBL3220633,TP,ACT,0.9900000095367432	CHEMBL21937,TN,INACT,0.2800000011920929	CHEMBL264979,TP,ACT,0.949999988079071	CHEMBL130331,FP,INACT,0.9399999976158142	CHEMBL3350741,TN,INACT,0.10000000149011612	CHEMBL222927,TP,ACT,1.0	CHEMBL183169,TP,ACT,1.0	CHEMBL42065,TN,INACT,0.4099999964237213	CHEMBL3633665,FP,INACT,0.9800000190734863	CHEMBL264491,TP,ACT,1.0	CHEMBL436415,TP,ACT,1.0	CHEMBL16639,FP,INACT,0.8899999856948853	CHEMBL387325,TP,ACT,0.9900000095367432	CHEMBL353088,TN,INACT,0.47999998927116394	CHEMBL277285,TN,INACT,0.6700000166893005	CHEMBL59597,TN,INACT,0.10999999940395355	CHEMBL309106,TP,ACT,0.9599999785423279	CHEMBL221716,TP,ACT,1.0	CHEMBL1170027,FP,INACT,0.8999999761581421	CHEMBL140620,TN,INACT,0.09000000357627869	CHEMBL64067,FN,ACT,0.6700000166893005	CHEMBL2385102,TP,ACT,0.9700000286102295	CHEMBL460470,TN,INACT,0.11999999731779099	CHEMBL593861,TN,INACT,0.07999999821186066	CHEMBL182922,TP,ACT,1.0	CHEMBL228144,TN,INACT,0.1899999976158142	CHEMBL174463,TN,INACT,0.7699999809265137	CHEMBL319910,FP,INACT,0.9300000071525574	CHEMBL323245,FP,INACT,0.9800000190734863	CHEMBL2112488,TN,INACT,0.09000000357627869	CHEMBL140365,TN,INACT,0.09000000357627869	CHEMBL79732,TP,ACT,0.9900000095367432	CHEMBL172788,FP,INACT,0.9300000071525574	CHEMBL336317,TP,ACT,0.7900000214576721	CHEMBL2373213,FP,INACT,0.9700000286102295	CHEMBL308756,TN,INACT,0.05999999865889549	CHEMBL21509,FP,INACT,0.8299999833106995	CHEMBL42411,TN,INACT,0.6299999952316284	CHEMBL221678,TP,ACT,0.9800000190734863	CHEMBL423260,TN,INACT,0.07999999821186066	CHEMBL609131,TP,ACT,0.9800000190734863	CHEMBL536800,TN,INACT,0.5099999904632568	CHEMBL336204,TP,ACT,0.7900000214576721	

