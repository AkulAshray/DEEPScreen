ImageNetInceptionV2 CHEMBL5776 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	128
Number of inactive compounds :	128
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5776_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5776_adam_0.0005_15_0.8/
---------------------------------
Training samples: 148
Validation samples: 47
--
Training Step: 1  | time: 79.837s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/148
[A[ATraining Step: 2  | total loss: [1m[32m0.65129[0m[0m | time: 446.980s
[2K
| Adam | epoch: 001 | loss: 0.65129 - acc: 0.3375 -- iter: 064/148
[A[ATraining Step: 3  | total loss: [1m[32m0.58552[0m[0m | time: 712.436s
[2K
| Adam | epoch: 001 | loss: 0.58552 - acc: 0.6239 -- iter: 096/148
[A[ATraining Step: 4  | total loss: [1m[32m0.51318[0m[0m | time: 864.979s
[2K
| Adam | epoch: 001 | loss: 0.51318 - acc: 0.6716 -- iter: 128/148
[A[ATraining Step: 5  | total loss: [1m[32m0.46862[0m[0m | time: 1061.191s
[2K
| Adam | epoch: 001 | loss: 0.46862 - acc: 0.8124 | val_loss: 0.71544 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 6  | total loss: [1m[32m0.65469[0m[0m | time: 30.920s
[2K
| Adam | epoch: 002 | loss: 0.65469 - acc: 0.7080 -- iter: 032/148
[A[ATraining Step: 7  | total loss: [1m[32m0.46023[0m[0m | time: 126.947s
[2K
| Adam | epoch: 002 | loss: 0.46023 - acc: 0.7932 -- iter: 064/148
[A[ATraining Step: 8  | total loss: [1m[32m0.42904[0m[0m | time: 283.456s
[2K
| Adam | epoch: 002 | loss: 0.42904 - acc: 0.8216 -- iter: 096/148
[A[ATraining Step: 9  | total loss: [1m[32m0.41946[0m[0m | time: 393.012s
[2K
| Adam | epoch: 002 | loss: 0.41946 - acc: 0.7837 -- iter: 128/148
[A[ATraining Step: 10  | total loss: [1m[32m0.30608[0m[0m | time: 470.388s
[2K
| Adam | epoch: 002 | loss: 0.30608 - acc: 0.8762 | val_loss: 1.26561 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 11  | total loss: [1m[32m0.22628[0m[0m | time: 114.079s
[2K
| Adam | epoch: 003 | loss: 0.22628 - acc: 0.9201 -- iter: 032/148
[A[ATraining Step: 12  | total loss: [1m[32m0.16976[0m[0m | time: 160.772s
[2K
| Adam | epoch: 003 | loss: 0.16976 - acc: 0.9335 -- iter: 064/148
[A[ATraining Step: 13  | total loss: [1m[32m0.10570[0m[0m | time: 222.436s
[2K
| Adam | epoch: 003 | loss: 0.10570 - acc: 0.9620 -- iter: 096/148
[A[ATraining Step: 14  | total loss: [1m[32m0.09712[0m[0m | time: 286.098s
[2K
| Adam | epoch: 003 | loss: 0.09712 - acc: 0.9776 -- iter: 128/148
[A[ATraining Step: 15  | total loss: [1m[32m0.09891[0m[0m | time: 331.812s
[2K
| Adam | epoch: 003 | loss: 0.09891 - acc: 0.9619 | val_loss: 0.85329 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 16  | total loss: [1m[32m0.13685[0m[0m | time: 45.308s
[2K
| Adam | epoch: 004 | loss: 0.13685 - acc: 0.9645 -- iter: 032/148
[A[ATraining Step: 17  | total loss: [1m[32m0.12101[0m[0m | time: 58.024s
[2K
| Adam | epoch: 004 | loss: 0.12101 - acc: 0.9660 -- iter: 064/148
[A[ATraining Step: 18  | total loss: [1m[32m0.12021[0m[0m | time: 94.391s
[2K
| Adam | epoch: 004 | loss: 0.12021 - acc: 0.9432 -- iter: 096/148
[A[ATraining Step: 19  | total loss: [1m[32m0.08194[0m[0m | time: 143.984s
[2K
| Adam | epoch: 004 | loss: 0.08194 - acc: 0.9621 -- iter: 128/148
[A[ATraining Step: 20  | total loss: [1m[32m0.06033[0m[0m | time: 175.535s
[2K
| Adam | epoch: 004 | loss: 0.06033 - acc: 0.9743 | val_loss: 2.42437 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 21  | total loss: [1m[32m0.07131[0m[0m | time: 41.899s
[2K
| Adam | epoch: 005 | loss: 0.07131 - acc: 0.9726 -- iter: 032/148
[A[ATraining Step: 22  | total loss: [1m[32m0.10230[0m[0m | time: 108.409s
[2K
| Adam | epoch: 005 | loss: 0.10230 - acc: 0.9620 -- iter: 064/148
[A[ATraining Step: 23  | total loss: [1m[32m0.08490[0m[0m | time: 120.741s
[2K
| Adam | epoch: 005 | loss: 0.08490 - acc: 0.9640 -- iter: 096/148
[A[ATraining Step: 24  | total loss: [1m[32m0.07016[0m[0m | time: 133.153s
[2K
| Adam | epoch: 005 | loss: 0.07016 - acc: 0.9741 -- iter: 128/148
[A[ATraining Step: 25  | total loss: [1m[32m0.05590[0m[0m | time: 153.463s
[2K
| Adam | epoch: 005 | loss: 0.05590 - acc: 0.9812 | val_loss: 2.37413 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 26  | total loss: [1m[32m0.04805[0m[0m | time: 35.789s
[2K
| Adam | epoch: 006 | loss: 0.04805 - acc: 0.9862 -- iter: 032/148
[A[ATraining Step: 27  | total loss: [1m[32m0.10814[0m[0m | time: 159.807s
[2K
| Adam | epoch: 006 | loss: 0.10814 - acc: 0.9736 -- iter: 064/148
[A[ATraining Step: 28  | total loss: [1m[32m0.28255[0m[0m | time: 183.901s
[2K
| Adam | epoch: 006 | loss: 0.28255 - acc: 0.9021 -- iter: 096/148
[A[ATraining Step: 29  | total loss: [1m[32m0.25936[0m[0m | time: 191.513s
[2K
| Adam | epoch: 006 | loss: 0.25936 - acc: 0.9183 -- iter: 128/148
[A[ATraining Step: 30  | total loss: [1m[32m0.19887[0m[0m | time: 209.090s
[2K
| Adam | epoch: 006 | loss: 0.19887 - acc: 0.9377 | val_loss: 2.67683 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 31  | total loss: [1m[32m0.15474[0m[0m | time: 28.474s
[2K
| Adam | epoch: 007 | loss: 0.15474 - acc: 0.9521 -- iter: 032/148
[A[ATraining Step: 32  | total loss: [1m[32m0.13239[0m[0m | time: 45.561s
[2K
| Adam | epoch: 007 | loss: 0.13239 - acc: 0.9558 -- iter: 064/148
[A[ATraining Step: 33  | total loss: [1m[32m0.11487[0m[0m | time: 119.919s
[2K
| Adam | epoch: 007 | loss: 0.11487 - acc: 0.9655 -- iter: 096/148
[A[ATraining Step: 34  | total loss: [1m[32m0.52395[0m[0m | time: 141.956s
[2K
| Adam | epoch: 007 | loss: 0.52395 - acc: 0.8925 -- iter: 128/148
[A[ATraining Step: 35  | total loss: [1m[32m0.43474[0m[0m | time: 154.894s
[2K
| Adam | epoch: 007 | loss: 0.43474 - acc: 0.9085 | val_loss: 2.24274 - val_acc: 0.5745 -- iter: 148/148
--
Training Step: 36  | total loss: [1m[32m0.36480[0m[0m | time: 9.505s
[2K
| Adam | epoch: 008 | loss: 0.36480 - acc: 0.9170 -- iter: 032/148
[A[ATraining Step: 37  | total loss: [1m[32m0.29736[0m[0m | time: 28.654s
[2K
| Adam | epoch: 008 | loss: 0.29736 - acc: 0.9336 -- iter: 064/148
[A[ATraining Step: 38  | total loss: [1m[32m0.26986[0m[0m | time: 51.931s
[2K
| Adam | epoch: 008 | loss: 0.26986 - acc: 0.9344 -- iter: 096/148
[A[ATraining Step: 39  | total loss: [1m[32m0.23374[0m[0m | time: 67.783s
[2K
| Adam | epoch: 008 | loss: 0.23374 - acc: 0.9409 -- iter: 128/148
[A[ATraining Step: 40  | total loss: [1m[32m0.19689[0m[0m | time: 84.615s
[2K
| Adam | epoch: 008 | loss: 0.19689 - acc: 0.9520 | val_loss: 0.67388 - val_acc: 0.5957 -- iter: 148/148
--
Training Step: 41  | total loss: [1m[32m0.17233[0m[0m | time: 78.855s
[2K
| Adam | epoch: 009 | loss: 0.17233 - acc: 0.9551 -- iter: 032/148
[A[ATraining Step: 42  | total loss: [1m[32m0.15886[0m[0m | time: 91.147s
[2K
| Adam | epoch: 009 | loss: 0.15886 - acc: 0.9542 -- iter: 064/148
[A[ATraining Step: 43  | total loss: [1m[32m0.13811[0m[0m | time: 135.227s
[2K
| Adam | epoch: 009 | loss: 0.13811 - acc: 0.9623 -- iter: 096/148
[A[ATraining Step: 44  | total loss: [1m[32m0.12439[0m[0m | time: 147.831s
[2K
| Adam | epoch: 009 | loss: 0.12439 - acc: 0.9688 -- iter: 128/148
[A[ATraining Step: 45  | total loss: [1m[32m0.11598[0m[0m | time: 162.297s
[2K
| Adam | epoch: 009 | loss: 0.11598 - acc: 0.9741 | val_loss: 0.39305 - val_acc: 0.8298 -- iter: 148/148
--
Training Step: 46  | total loss: [1m[32m0.14495[0m[0m | time: 25.797s
[2K
| Adam | epoch: 010 | loss: 0.14495 - acc: 0.9732 -- iter: 032/148
[A[ATraining Step: 47  | total loss: [1m[32m0.12484[0m[0m | time: 37.486s
[2K
| Adam | epoch: 010 | loss: 0.12484 - acc: 0.9776 -- iter: 064/148
[A[ATraining Step: 48  | total loss: [1m[32m0.11088[0m[0m | time: 90.287s
[2K
| Adam | epoch: 010 | loss: 0.11088 - acc: 0.9812 -- iter: 096/148
[A[ATraining Step: 49  | total loss: [1m[32m0.09638[0m[0m | time: 107.521s
[2K
| Adam | epoch: 010 | loss: 0.09638 - acc: 0.9842 -- iter: 128/148
[A[ATraining Step: 50  | total loss: [1m[32m0.08766[0m[0m | time: 123.909s
[2K
| Adam | epoch: 010 | loss: 0.08766 - acc: 0.9866 | val_loss: 0.63754 - val_acc: 0.7660 -- iter: 148/148
--
Training Step: 51  | total loss: [1m[32m0.07565[0m[0m | time: 15.227s
[2K
| Adam | epoch: 011 | loss: 0.07565 - acc: 0.9887 -- iter: 032/148
[A[ATraining Step: 52  | total loss: [1m[32m0.08683[0m[0m | time: 30.651s
[2K
| Adam | epoch: 011 | loss: 0.08683 - acc: 0.9857 -- iter: 064/148
[A[ATraining Step: 53  | total loss: [1m[32m0.07524[0m[0m | time: 39.767s
[2K
| Adam | epoch: 011 | loss: 0.07524 - acc: 0.9878 -- iter: 096/148
[A[ATraining Step: 54  | total loss: [1m[32m0.07694[0m[0m | time: 49.704s
[2K
| Adam | epoch: 011 | loss: 0.07694 - acc: 0.9823 -- iter: 128/148
[A[ATraining Step: 55  | total loss: [1m[32m0.06669[0m[0m | time: 73.280s
[2K
| Adam | epoch: 011 | loss: 0.06669 - acc: 0.9848 | val_loss: 1.02672 - val_acc: 0.6596 -- iter: 148/148
--
Training Step: 56  | total loss: [1m[32m0.05901[0m[0m | time: 15.756s
[2K
| Adam | epoch: 012 | loss: 0.05901 - acc: 0.9870 -- iter: 032/148
[A[ATraining Step: 57  | total loss: [1m[32m0.06053[0m[0m | time: 28.244s
[2K
| Adam | epoch: 012 | loss: 0.06053 - acc: 0.9844 -- iter: 064/148
[A[ATraining Step: 58  | total loss: [1m[32m0.15158[0m[0m | time: 36.986s
[2K
| Adam | epoch: 012 | loss: 0.15158 - acc: 0.9738 -- iter: 096/148
[A[ATraining Step: 59  | total loss: [1m[32m0.14178[0m[0m | time: 46.083s
[2K
| Adam | epoch: 012 | loss: 0.14178 - acc: 0.9731 -- iter: 128/148
[A[ATraining Step: 60  | total loss: [1m[32m0.12444[0m[0m | time: 58.486s
[2K
| Adam | epoch: 012 | loss: 0.12444 - acc: 0.9767 | val_loss: 0.63302 - val_acc: 0.7234 -- iter: 148/148
--
Training Step: 61  | total loss: [1m[32m0.11007[0m[0m | time: 14.930s
[2K
| Adam | epoch: 013 | loss: 0.11007 - acc: 0.9797 -- iter: 032/148
[A[ATraining Step: 62  | total loss: [1m[32m0.10125[0m[0m | time: 28.297s
[2K
| Adam | epoch: 013 | loss: 0.10125 - acc: 0.9823 -- iter: 064/148
[A[ATraining Step: 63  | total loss: [1m[32m0.10638[0m[0m | time: 46.127s
[2K
| Adam | epoch: 013 | loss: 0.10638 - acc: 0.9806 -- iter: 096/148
[A[ATraining Step: 64  | total loss: [1m[32m0.15773[0m[0m | time: 64.244s
[2K
| Adam | epoch: 013 | loss: 0.15773 - acc: 0.9713 -- iter: 128/148
[A[ATraining Step: 65  | total loss: [1m[32m0.14880[0m[0m | time: 81.659s
[2K
| Adam | epoch: 013 | loss: 0.14880 - acc: 0.9710 | val_loss: 0.41053 - val_acc: 0.8936 -- iter: 148/148
--
Training Step: 66  | total loss: [1m[32m0.14039[0m[0m | time: 12.861s
[2K
| Adam | epoch: 014 | loss: 0.14039 - acc: 0.9745 -- iter: 032/148
[A[ATraining Step: 67  | total loss: [1m[32m0.12683[0m[0m | time: 34.489s
[2K
| Adam | epoch: 014 | loss: 0.12683 - acc: 0.9776 -- iter: 064/148
[A[ATraining Step: 68  | total loss: [1m[32m0.11943[0m[0m | time: 51.754s
[2K
| Adam | epoch: 014 | loss: 0.11943 - acc: 0.9802 -- iter: 096/148
[A[ATraining Step: 69  | total loss: [1m[32m0.10997[0m[0m | time: 71.142s
[2K
| Adam | epoch: 014 | loss: 0.10997 - acc: 0.9825 -- iter: 128/148
[A[ATraining Step: 70  | total loss: [1m[32m0.10564[0m[0m | time: 89.874s
[2K
| Adam | epoch: 014 | loss: 0.10564 - acc: 0.9846 | val_loss: 0.83173 - val_acc: 0.7234 -- iter: 148/148
--
Training Step: 71  | total loss: [1m[32m0.09602[0m[0m | time: 9.711s
[2K
| Adam | epoch: 015 | loss: 0.09602 - acc: 0.9863 -- iter: 032/148
[A[ATraining Step: 72  | total loss: [1m[32m0.08667[0m[0m | time: 18.206s
[2K
| Adam | epoch: 015 | loss: 0.08667 - acc: 0.9879 -- iter: 064/148
[A[ATraining Step: 73  | total loss: [1m[32m0.07806[0m[0m | time: 32.886s
[2K
| Adam | epoch: 015 | loss: 0.07806 - acc: 0.9892 -- iter: 096/148
[A[ATraining Step: 74  | total loss: [1m[32m0.07057[0m[0m | time: 51.203s
[2K
| Adam | epoch: 015 | loss: 0.07057 - acc: 0.9904 -- iter: 128/148
[A[ATraining Step: 75  | total loss: [1m[32m0.06403[0m[0m | time: 69.269s
[2K
| Adam | epoch: 015 | loss: 0.06403 - acc: 0.9914 | val_loss: 0.80108 - val_acc: 0.7660 -- iter: 148/148
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9129629629629629
Validation AUPRC:0.8914879667975644
Test AUC:0.9619565217391305
Test AUPRC:0.9706099456099455
BestTestF1Score	0.83	0.74	0.85	1.0	0.71	17	0	23	7	0.03
BestTestMCCScore	0.83	0.74	0.85	1.0	0.71	17	0	23	7	0.03
BestTestAccuracyScore	0.83	0.74	0.85	1.0	0.71	17	0	23	7	0.03
BestValidationF1Score	0.9	0.83	0.91	0.9	0.9	18	2	25	2	0.03
BestValidationMCC	0.9	0.83	0.91	0.9	0.9	18	2	25	2	0.03
BestValidationAccuracy	0.9	0.83	0.91	0.9	0.9	18	2	25	2	0.03
TestPredictions (Threshold:0.03)
CHEMBL558601,TN,INACT,0.0	CHEMBL1784660,TN,INACT,0.0	CHEMBL3609568,TN,INACT,0.0	CHEMBL1801932,TN,INACT,0.009999999776482582	CHEMBL2392392,TN,INACT,0.0	CHEMBL522892,FN,ACT,0.0	CHEMBL572878,FN,ACT,0.029999999329447746	CHEMBL2392237,TN,INACT,0.0	CHEMBL1922120,TN,INACT,0.0	CHEMBL1240703,TP,ACT,0.10999999940395355	CHEMBL457180,TN,INACT,0.0	CHEMBL557456,TN,INACT,0.0	CHEMBL527039,TN,INACT,0.009999999776482582	CHEMBL608533,TP,ACT,0.05000000074505806	CHEMBL1922122,TN,INACT,0.0	CHEMBL2408611,TP,ACT,0.3499999940395355	CHEMBL456797,TN,INACT,0.0	CHEMBL2407762,FN,ACT,0.009999999776482582	CHEMBL3736465,TP,ACT,0.05000000074505806	CHEMBL603469,FN,ACT,0.029999999329447746	CHEMBL3822610,FN,ACT,0.009999999776482582	CHEMBL1287975,TN,INACT,0.0	CHEMBL574738,FN,ACT,0.0	CHEMBL458076,TN,INACT,0.0	CHEMBL457390,TN,INACT,0.0	CHEMBL2407760,TP,ACT,0.5699999928474426	CHEMBL2408613,FN,ACT,0.0	CHEMBL3629246,TP,ACT,0.6299999952316284	CHEMBL557525,TN,INACT,0.0	CHEMBL3822835,TP,ACT,0.44999998807907104	CHEMBL101868,TN,INACT,0.0	CHEMBL3629243,TP,ACT,0.9800000190734863	CHEMBL2407784,TP,ACT,0.09000000357627869	CHEMBL2392235,TN,INACT,0.0	CHEMBL1933802,TN,INACT,0.0	CHEMBL3823892,TP,ACT,0.8500000238418579	CHEMBL471474,TP,ACT,0.8899999856948853	CHEMBL2407957,TP,ACT,0.7200000286102295	CHEMBL525538,TN,INACT,0.0	CHEMBL3823738,TP,ACT,0.03999999910593033	CHEMBL2407768,TP,ACT,0.949999988079071	CHEMBL2407753,TP,ACT,0.9100000262260437	CHEMBL515051,TN,INACT,0.0	CHEMBL1801950,TP,ACT,0.9399999976158142	CHEMBL457191,TN,INACT,0.0	CHEMBL318461,TN,INACT,0.0	CHEMBL3629242,TP,ACT,0.9800000190734863	

