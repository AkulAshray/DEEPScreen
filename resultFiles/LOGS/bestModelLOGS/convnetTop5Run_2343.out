CNNModel CHEMBL4441 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	711
Number of inactive compounds :	711
---------------------------------
Run id: CNNModel_CHEMBL4441_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4441_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 876
Validation samples: 275
--
Training Step: 1  | time: 2.166s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/876
[A[ATraining Step: 2  | total loss: [1m[32m0.62388[0m[0m | time: 3.753s
[2K
| Adam | epoch: 001 | loss: 0.62388 - acc: 0.4781 -- iter: 064/876
[A[ATraining Step: 3  | total loss: [1m[32m0.68083[0m[0m | time: 5.256s
[2K
| Adam | epoch: 001 | loss: 0.68083 - acc: 0.4193 -- iter: 096/876
[A[ATraining Step: 4  | total loss: [1m[32m0.69009[0m[0m | time: 6.561s
[2K
| Adam | epoch: 001 | loss: 0.69009 - acc: 0.3861 -- iter: 128/876
[A[ATraining Step: 5  | total loss: [1m[32m0.69247[0m[0m | time: 8.223s
[2K
| Adam | epoch: 001 | loss: 0.69247 - acc: 0.4217 -- iter: 160/876
[A[ATraining Step: 6  | total loss: [1m[32m0.69269[0m[0m | time: 9.882s
[2K
| Adam | epoch: 001 | loss: 0.69269 - acc: 0.5323 -- iter: 192/876
[A[ATraining Step: 7  | total loss: [1m[32m0.69229[0m[0m | time: 11.741s
[2K
| Adam | epoch: 001 | loss: 0.69229 - acc: 0.5504 -- iter: 224/876
[A[ATraining Step: 8  | total loss: [1m[32m0.69337[0m[0m | time: 13.378s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.5045 -- iter: 256/876
[A[ATraining Step: 9  | total loss: [1m[32m0.69554[0m[0m | time: 14.665s
[2K
| Adam | epoch: 001 | loss: 0.69554 - acc: 0.4525 -- iter: 288/876
[A[ATraining Step: 10  | total loss: [1m[32m0.69718[0m[0m | time: 16.109s
[2K
| Adam | epoch: 001 | loss: 0.69718 - acc: 0.3981 -- iter: 320/876
[A[ATraining Step: 11  | total loss: [1m[32m0.69529[0m[0m | time: 17.674s
[2K
| Adam | epoch: 001 | loss: 0.69529 - acc: 0.4464 -- iter: 352/876
[A[ATraining Step: 12  | total loss: [1m[32m0.69430[0m[0m | time: 19.273s
[2K
| Adam | epoch: 001 | loss: 0.69430 - acc: 0.4705 -- iter: 384/876
[A[ATraining Step: 13  | total loss: [1m[32m0.69362[0m[0m | time: 20.838s
[2K
| Adam | epoch: 001 | loss: 0.69362 - acc: 0.5099 -- iter: 416/876
[A[ATraining Step: 14  | total loss: [1m[32m0.69351[0m[0m | time: 22.241s
[2K
| Adam | epoch: 001 | loss: 0.69351 - acc: 0.4803 -- iter: 448/876
[A[ATraining Step: 15  | total loss: [1m[32m0.69336[0m[0m | time: 23.852s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4758 -- iter: 480/876
[A[ATraining Step: 16  | total loss: [1m[32m0.69325[0m[0m | time: 25.378s
[2K
| Adam | epoch: 001 | loss: 0.69325 - acc: 0.5083 -- iter: 512/876
[A[ATraining Step: 17  | total loss: [1m[32m0.69320[0m[0m | time: 26.778s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5053 -- iter: 544/876
[A[ATraining Step: 18  | total loss: [1m[32m0.69322[0m[0m | time: 28.261s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4818 -- iter: 576/876
[A[ATraining Step: 19  | total loss: [1m[32m0.69320[0m[0m | time: 29.824s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.4879 -- iter: 608/876
[A[ATraining Step: 20  | total loss: [1m[32m0.69316[0m[0m | time: 31.374s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5119 -- iter: 640/876
[A[ATraining Step: 21  | total loss: [1m[32m0.69310[0m[0m | time: 32.737s
[2K
| Adam | epoch: 001 | loss: 0.69310 - acc: 0.5470 -- iter: 672/876
[A[ATraining Step: 22  | total loss: [1m[32m0.69323[0m[0m | time: 34.224s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.5048 -- iter: 704/876
[A[ATraining Step: 23  | total loss: [1m[32m0.69313[0m[0m | time: 35.984s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.5215 -- iter: 736/876
[A[ATraining Step: 24  | total loss: [1m[32m0.69300[0m[0m | time: 37.475s
[2K
| Adam | epoch: 001 | loss: 0.69300 - acc: 0.5418 -- iter: 768/876
[A[ATraining Step: 25  | total loss: [1m[32m0.69278[0m[0m | time: 38.646s
[2K
| Adam | epoch: 001 | loss: 0.69278 - acc: 0.5645 -- iter: 800/876
[A[ATraining Step: 26  | total loss: [1m[32m0.69327[0m[0m | time: 39.519s
[2K
| Adam | epoch: 001 | loss: 0.69327 - acc: 0.5144 -- iter: 832/876
[A[ATraining Step: 27  | total loss: [1m[32m0.69304[0m[0m | time: 40.658s
[2K
| Adam | epoch: 001 | loss: 0.69304 - acc: 0.5267 -- iter: 864/876
[A[ATraining Step: 28  | total loss: [1m[32m0.69295[0m[0m | time: 42.738s
[2K
| Adam | epoch: 001 | loss: 0.69295 - acc: 0.5279 | val_loss: 0.69322 - val_acc: 0.4982 -- iter: 876/876
--
Training Step: 29  | total loss: [1m[32m0.69294[0m[0m | time: 0.516s
[2K
| Adam | epoch: 002 | loss: 0.69294 - acc: 0.5211 -- iter: 032/876
[A[ATraining Step: 30  | total loss: [1m[32m0.69295[0m[0m | time: 1.577s
[2K
| Adam | epoch: 002 | loss: 0.69295 - acc: 0.5161 -- iter: 064/876
[A[ATraining Step: 31  | total loss: [1m[32m0.69330[0m[0m | time: 2.855s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4980 -- iter: 096/876
[A[ATraining Step: 32  | total loss: [1m[32m0.69398[0m[0m | time: 4.221s
[2K
| Adam | epoch: 002 | loss: 0.69398 - acc: 0.4633 -- iter: 128/876
[A[ATraining Step: 33  | total loss: [1m[32m0.69403[0m[0m | time: 5.623s
[2K
| Adam | epoch: 002 | loss: 0.69403 - acc: 0.4576 -- iter: 160/876
[A[ATraining Step: 34  | total loss: [1m[32m0.69364[0m[0m | time: 7.033s
[2K
| Adam | epoch: 002 | loss: 0.69364 - acc: 0.4801 -- iter: 192/876
[A[ATraining Step: 35  | total loss: [1m[32m0.69345[0m[0m | time: 8.288s
[2K
| Adam | epoch: 002 | loss: 0.69345 - acc: 0.4908 -- iter: 224/876
[A[ATraining Step: 36  | total loss: [1m[32m0.69320[0m[0m | time: 9.897s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5055 -- iter: 256/876
[A[ATraining Step: 37  | total loss: [1m[32m0.69295[0m[0m | time: 11.338s
[2K
| Adam | epoch: 002 | loss: 0.69295 - acc: 0.5231 -- iter: 288/876
[A[ATraining Step: 38  | total loss: [1m[32m0.69311[0m[0m | time: 12.859s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5125 -- iter: 320/876
[A[ATraining Step: 39  | total loss: [1m[32m0.69303[0m[0m | time: 14.339s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5161 -- iter: 352/876
[A[ATraining Step: 40  | total loss: [1m[32m0.69289[0m[0m | time: 16.062s
[2K
| Adam | epoch: 002 | loss: 0.69289 - acc: 0.5248 -- iter: 384/876
[A[ATraining Step: 41  | total loss: [1m[32m0.69323[0m[0m | time: 17.636s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.5030 -- iter: 416/876
[A[ATraining Step: 42  | total loss: [1m[32m0.69352[0m[0m | time: 19.096s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4856 -- iter: 448/876
[A[ATraining Step: 43  | total loss: [1m[32m0.69329[0m[0m | time: 20.611s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4992 -- iter: 480/876
[A[ATraining Step: 44  | total loss: [1m[32m0.69326[0m[0m | time: 22.192s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4993 -- iter: 512/876
[A[ATraining Step: 45  | total loss: [1m[32m0.69281[0m[0m | time: 23.822s
[2K
| Adam | epoch: 002 | loss: 0.69281 - acc: 0.5260 -- iter: 544/876
[A[ATraining Step: 46  | total loss: [1m[32m0.69252[0m[0m | time: 25.436s
[2K
| Adam | epoch: 002 | loss: 0.69252 - acc: 0.5425 -- iter: 576/876
[A[ATraining Step: 47  | total loss: [1m[32m0.69283[0m[0m | time: 26.826s
[2K
| Adam | epoch: 002 | loss: 0.69283 - acc: 0.5253 -- iter: 608/876
[A[ATraining Step: 48  | total loss: [1m[32m0.69259[0m[0m | time: 27.950s
[2K
| Adam | epoch: 002 | loss: 0.69259 - acc: 0.5363 -- iter: 640/876
[A[ATraining Step: 49  | total loss: [1m[32m0.69247[0m[0m | time: 29.132s
[2K
| Adam | epoch: 002 | loss: 0.69247 - acc: 0.5404 -- iter: 672/876
[A[ATraining Step: 50  | total loss: [1m[32m0.69247[0m[0m | time: 30.260s
[2K
| Adam | epoch: 002 | loss: 0.69247 - acc: 0.5390 -- iter: 704/876
[A[ATraining Step: 51  | total loss: [1m[32m0.69245[0m[0m | time: 31.373s
[2K
| Adam | epoch: 002 | loss: 0.69245 - acc: 0.5378 -- iter: 736/876
[A[ATraining Step: 52  | total loss: [1m[32m0.69241[0m[0m | time: 32.663s
[2K
| Adam | epoch: 002 | loss: 0.69241 - acc: 0.5368 -- iter: 768/876
[A[ATraining Step: 53  | total loss: [1m[32m0.69237[0m[0m | time: 34.036s
[2K
| Adam | epoch: 002 | loss: 0.69237 - acc: 0.5360 -- iter: 800/876
[A[ATraining Step: 54  | total loss: [1m[32m0.69327[0m[0m | time: 35.090s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.5081 -- iter: 832/876
[A[ATraining Step: 55  | total loss: [1m[32m0.69342[0m[0m | time: 36.439s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.5025 -- iter: 864/876
[A[ATraining Step: 56  | total loss: [1m[32m0.69339[0m[0m | time: 39.577s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.5021 | val_loss: 0.69333 - val_acc: 0.4982 -- iter: 876/876
--
Training Step: 57  | total loss: [1m[32m0.69399[0m[0m | time: 0.440s
[2K
| Adam | epoch: 003 | loss: 0.69399 - acc: 0.4845 -- iter: 032/876
[A[ATraining Step: 58  | total loss: [1m[32m0.69202[0m[0m | time: 0.888s
[2K
| Adam | epoch: 003 | loss: 0.69202 - acc: 0.5435 -- iter: 064/876
[A[ATraining Step: 59  | total loss: [1m[32m0.69026[0m[0m | time: 2.005s
[2K
| Adam | epoch: 003 | loss: 0.69026 - acc: 0.5936 -- iter: 096/876
[A[ATraining Step: 60  | total loss: [1m[32m0.69151[0m[0m | time: 3.115s
[2K
| Adam | epoch: 003 | loss: 0.69151 - acc: 0.5605 -- iter: 128/876
[A[ATraining Step: 61  | total loss: [1m[32m0.69137[0m[0m | time: 4.589s
[2K
| Adam | epoch: 003 | loss: 0.69137 - acc: 0.5608 -- iter: 160/876
[A[ATraining Step: 62  | total loss: [1m[32m0.69105[0m[0m | time: 5.707s
[2K
| Adam | epoch: 003 | loss: 0.69105 - acc: 0.5650 -- iter: 192/876
[A[ATraining Step: 63  | total loss: [1m[32m0.69160[0m[0m | time: 6.955s
[2K
| Adam | epoch: 003 | loss: 0.69160 - acc: 0.5528 -- iter: 224/876
[A[ATraining Step: 64  | total loss: [1m[32m0.69319[0m[0m | time: 8.445s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5228 -- iter: 256/876
[A[ATraining Step: 65  | total loss: [1m[32m0.69236[0m[0m | time: 9.912s
[2K
| Adam | epoch: 003 | loss: 0.69236 - acc: 0.5354 -- iter: 288/876
[A[ATraining Step: 66  | total loss: [1m[32m0.69361[0m[0m | time: 10.947s
[2K
| Adam | epoch: 003 | loss: 0.69361 - acc: 0.5121 -- iter: 320/876
[A[ATraining Step: 67  | total loss: [1m[32m0.69362[0m[0m | time: 11.989s
[2K
| Adam | epoch: 003 | loss: 0.69362 - acc: 0.5106 -- iter: 352/876
[A[ATraining Step: 68  | total loss: [1m[32m0.69361[0m[0m | time: 13.075s
[2K
| Adam | epoch: 003 | loss: 0.69361 - acc: 0.5094 -- iter: 384/876
[A[ATraining Step: 69  | total loss: [1m[32m0.69323[0m[0m | time: 14.167s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.5156 -- iter: 416/876
[A[ATraining Step: 70  | total loss: [1m[32m0.69349[0m[0m | time: 15.415s
[2K
| Adam | epoch: 003 | loss: 0.69349 - acc: 0.5102 -- iter: 448/876
[A[ATraining Step: 71  | total loss: [1m[32m0.69332[0m[0m | time: 16.799s
[2K
| Adam | epoch: 003 | loss: 0.69332 - acc: 0.5126 -- iter: 480/876
[A[ATraining Step: 72  | total loss: [1m[32m0.69298[0m[0m | time: 17.875s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5182 -- iter: 512/876
[A[ATraining Step: 73  | total loss: [1m[32m0.69286[0m[0m | time: 19.136s
[2K
| Adam | epoch: 003 | loss: 0.69286 - acc: 0.5196 -- iter: 544/876
[A[ATraining Step: 74  | total loss: [1m[32m0.69290[0m[0m | time: 20.339s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5175 -- iter: 576/876
[A[ATraining Step: 75  | total loss: [1m[32m0.69313[0m[0m | time: 21.620s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5122 -- iter: 608/876
[A[ATraining Step: 76  | total loss: [1m[32m0.69296[0m[0m | time: 22.875s
[2K
| Adam | epoch: 003 | loss: 0.69296 - acc: 0.5142 -- iter: 640/876
[A[ATraining Step: 77  | total loss: [1m[32m0.69318[0m[0m | time: 24.087s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.5094 -- iter: 672/876
[A[ATraining Step: 78  | total loss: [1m[32m0.69256[0m[0m | time: 25.341s
[2K
| Adam | epoch: 003 | loss: 0.69256 - acc: 0.5215 -- iter: 704/876
[A[ATraining Step: 79  | total loss: [1m[32m0.69233[0m[0m | time: 26.444s
[2K
| Adam | epoch: 003 | loss: 0.69233 - acc: 0.5258 -- iter: 736/876
[A[ATraining Step: 80  | total loss: [1m[32m0.69213[0m[0m | time: 27.694s
[2K
| Adam | epoch: 003 | loss: 0.69213 - acc: 0.5295 -- iter: 768/876
[A[ATraining Step: 81  | total loss: [1m[32m0.69210[0m[0m | time: 28.762s
[2K
| Adam | epoch: 003 | loss: 0.69210 - acc: 0.5297 -- iter: 800/876
[A[ATraining Step: 82  | total loss: [1m[32m0.69205[0m[0m | time: 29.557s
[2K
| Adam | epoch: 003 | loss: 0.69205 - acc: 0.5298 -- iter: 832/876
[A[ATraining Step: 83  | total loss: [1m[32m0.69204[0m[0m | time: 30.245s
[2K
| Adam | epoch: 003 | loss: 0.69204 - acc: 0.5300 -- iter: 864/876
[A[ATraining Step: 84  | total loss: [1m[32m0.69253[0m[0m | time: 31.993s
[2K
| Adam | epoch: 003 | loss: 0.69253 - acc: 0.5207 | val_loss: 0.69363 - val_acc: 0.4982 -- iter: 876/876
--
Training Step: 85  | total loss: [1m[32m0.69261[0m[0m | time: 1.003s
[2K
| Adam | epoch: 004 | loss: 0.69261 - acc: 0.5187 -- iter: 032/876
[A[ATraining Step: 86  | total loss: [1m[32m0.69217[0m[0m | time: 1.429s
[2K
| Adam | epoch: 004 | loss: 0.69217 - acc: 0.5262 -- iter: 064/876
[A[ATraining Step: 87  | total loss: [1m[32m0.69332[0m[0m | time: 1.862s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.5069 -- iter: 096/876
[A[ATraining Step: 88  | total loss: [1m[32m0.69423[0m[0m | time: 3.026s
[2K
| Adam | epoch: 004 | loss: 0.69423 - acc: 0.4895 -- iter: 128/876
[A[ATraining Step: 89  | total loss: [1m[32m0.69298[0m[0m | time: 4.527s
[2K
| Adam | epoch: 004 | loss: 0.69298 - acc: 0.5125 -- iter: 160/876
[A[ATraining Step: 90  | total loss: [1m[32m0.69303[0m[0m | time: 5.896s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5112 -- iter: 192/876
[A[ATraining Step: 91  | total loss: [1m[32m0.69304[0m[0m | time: 7.217s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5101 -- iter: 224/876
[A[ATraining Step: 92  | total loss: [1m[32m0.69339[0m[0m | time: 8.152s
[2K
| Adam | epoch: 004 | loss: 0.69339 - acc: 0.5028 -- iter: 256/876
[A[ATraining Step: 93  | total loss: [1m[32m0.69322[0m[0m | time: 9.243s
[2K
| Adam | epoch: 004 | loss: 0.69322 - acc: 0.5057 -- iter: 288/876
[A[ATraining Step: 94  | total loss: [1m[32m0.69388[0m[0m | time: 10.464s
[2K
| Adam | epoch: 004 | loss: 0.69388 - acc: 0.4926 -- iter: 320/876
[A[ATraining Step: 95  | total loss: [1m[32m0.69368[0m[0m | time: 11.625s
[2K
| Adam | epoch: 004 | loss: 0.69368 - acc: 0.4965 -- iter: 352/876
[A[ATraining Step: 96  | total loss: [1m[32m0.69350[0m[0m | time: 13.082s
[2K
| Adam | epoch: 004 | loss: 0.69350 - acc: 0.4999 -- iter: 384/876
[A[ATraining Step: 97  | total loss: [1m[32m0.69390[0m[0m | time: 14.403s
[2K
| Adam | epoch: 004 | loss: 0.69390 - acc: 0.4906 -- iter: 416/876
[A[ATraining Step: 98  | total loss: [1m[32m0.69410[0m[0m | time: 15.456s
[2K
| Adam | epoch: 004 | loss: 0.69410 - acc: 0.4853 -- iter: 448/876
[A[ATraining Step: 99  | total loss: [1m[32m0.69415[0m[0m | time: 16.910s
[2K
| Adam | epoch: 004 | loss: 0.69415 - acc: 0.4836 -- iter: 480/876
[A[ATraining Step: 100  | total loss: [1m[32m0.69445[0m[0m | time: 18.340s
[2K
| Adam | epoch: 004 | loss: 0.69445 - acc: 0.4759 -- iter: 512/876
[A[ATraining Step: 101  | total loss: [1m[32m0.69388[0m[0m | time: 19.743s
[2K
| Adam | epoch: 004 | loss: 0.69388 - acc: 0.4908 -- iter: 544/876
[A[ATraining Step: 102  | total loss: [1m[32m0.69382[0m[0m | time: 20.763s
[2K
| Adam | epoch: 004 | loss: 0.69382 - acc: 0.4917 -- iter: 576/876
[A[ATraining Step: 103  | total loss: [1m[32m0.69335[0m[0m | time: 21.727s
[2K
| Adam | epoch: 004 | loss: 0.69335 - acc: 0.5050 -- iter: 608/876
[A[ATraining Step: 104  | total loss: [1m[32m0.69355[0m[0m | time: 22.865s
[2K
| Adam | epoch: 004 | loss: 0.69355 - acc: 0.4983 -- iter: 640/876
[A[ATraining Step: 105  | total loss: [1m[32m0.69352[0m[0m | time: 23.997s
[2K
| Adam | epoch: 004 | loss: 0.69352 - acc: 0.4985 -- iter: 672/876
[A[ATraining Step: 106  | total loss: [1m[32m0.69307[0m[0m | time: 25.144s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5111 -- iter: 704/876
[A[ATraining Step: 107  | total loss: [1m[32m0.69307[0m[0m | time: 26.502s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5100 -- iter: 736/876
[A[ATraining Step: 108  | total loss: [1m[32m0.69342[0m[0m | time: 27.801s
[2K
| Adam | epoch: 004 | loss: 0.69342 - acc: 0.4996 -- iter: 768/876
[A[ATraining Step: 109  | total loss: [1m[32m0.69317[0m[0m | time: 29.362s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5059 -- iter: 800/876
[A[ATraining Step: 110  | total loss: [1m[32m0.69267[0m[0m | time: 30.996s
[2K
| Adam | epoch: 004 | loss: 0.69267 - acc: 0.5209 -- iter: 832/876
[A[ATraining Step: 111  | total loss: [1m[32m0.69262[0m[0m | time: 32.549s
[2K
| Adam | epoch: 004 | loss: 0.69262 - acc: 0.5220 -- iter: 864/876
[A[ATraining Step: 112  | total loss: [1m[32m0.69293[0m[0m | time: 46.205s
[2K
| Adam | epoch: 004 | loss: 0.69293 - acc: 0.5135 | val_loss: 0.69337 - val_acc: 0.4982 -- iter: 876/876
--
Training Step: 113  | total loss: [1m[32m0.69311[0m[0m | time: 1.381s
[2K
| Adam | epoch: 005 | loss: 0.69311 - acc: 0.5091 -- iter: 032/876
[A[ATraining Step: 114  | total loss: [1m[32m0.69255[0m[0m | time: 2.786s
[2K
| Adam | epoch: 005 | loss: 0.69255 - acc: 0.5238 -- iter: 064/876
[A[ATraining Step: 115  | total loss: [1m[32m0.69203[0m[0m | time: 3.348s
[2K
| Adam | epoch: 005 | loss: 0.69203 - acc: 0.5370 -- iter: 096/876
[A[ATraining Step: 116  | total loss: [1m[32m0.69180[0m[0m | time: 3.906s
[2K
| Adam | epoch: 005 | loss: 0.69180 - acc: 0.5417 -- iter: 128/876
[A[ATraining Step: 117  | total loss: [1m[32m0.69155[0m[0m | time: 5.507s
[2K
| Adam | epoch: 005 | loss: 0.69155 - acc: 0.5458 -- iter: 160/876
[A[ATraining Step: 118  | total loss: [1m[32m0.69143[0m[0m | time: 7.285s
[2K
| Adam | epoch: 005 | loss: 0.69143 - acc: 0.5475 -- iter: 192/876
[A[ATraining Step: 119  | total loss: [1m[32m0.69135[0m[0m | time: 8.664s
[2K
| Adam | epoch: 005 | loss: 0.69135 - acc: 0.5490 -- iter: 224/876
[A[ATraining Step: 120  | total loss: [1m[32m0.69118[0m[0m | time: 10.193s
[2K
| Adam | epoch: 005 | loss: 0.69118 - acc: 0.5503 -- iter: 256/876
[A[ATraining Step: 121  | total loss: [1m[32m0.69097[0m[0m | time: 11.796s
[2K
| Adam | epoch: 005 | loss: 0.69097 - acc: 0.5516 -- iter: 288/876
[A[ATraining Step: 122  | total loss: [1m[32m0.69237[0m[0m | time: 13.394s
[2K
| Adam | epoch: 005 | loss: 0.69237 - acc: 0.5339 -- iter: 320/876
[A[ATraining Step: 123  | total loss: [1m[32m0.69328[0m[0m | time: 14.928s
[2K
| Adam | epoch: 005 | loss: 0.69328 - acc: 0.5211 -- iter: 352/876
[A[ATraining Step: 124  | total loss: [1m[32m0.69290[0m[0m | time: 24.844s
[2K
| Adam | epoch: 005 | loss: 0.69290 - acc: 0.5253 -- iter: 384/876
[A[ATraining Step: 125  | total loss: [1m[32m0.69190[0m[0m | time: 25.944s
[2K
| Adam | epoch: 005 | loss: 0.69190 - acc: 0.5384 -- iter: 416/876
[A[ATraining Step: 126  | total loss: [1m[32m0.69292[0m[0m | time: 27.254s
[2K
| Adam | epoch: 005 | loss: 0.69292 - acc: 0.5220 -- iter: 448/876
[A[ATraining Step: 127  | total loss: [1m[32m0.69407[0m[0m | time: 28.696s
[2K
| Adam | epoch: 005 | loss: 0.69407 - acc: 0.5042 -- iter: 480/876
[A[ATraining Step: 128  | total loss: [1m[32m0.69442[0m[0m | time: 30.101s
[2K
| Adam | epoch: 005 | loss: 0.69442 - acc: 0.4975 -- iter: 512/876
[A[ATraining Step: 129  | total loss: [1m[32m0.69473[0m[0m | time: 31.591s
[2K
| Adam | epoch: 005 | loss: 0.69473 - acc: 0.4915 -- iter: 544/876
[A[ATraining Step: 130  | total loss: [1m[32m0.69425[0m[0m | time: 33.094s
[2K
| Adam | epoch: 005 | loss: 0.69425 - acc: 0.4986 -- iter: 576/876
[A[ATraining Step: 131  | total loss: [1m[32m0.69450[0m[0m | time: 34.906s
[2K
| Adam | epoch: 005 | loss: 0.69450 - acc: 0.4925 -- iter: 608/876
[A[ATraining Step: 132  | total loss: [1m[32m0.69471[0m[0m | time: 36.530s
[2K
| Adam | epoch: 005 | loss: 0.69471 - acc: 0.4870 -- iter: 640/876
[A[ATraining Step: 133  | total loss: [1m[32m0.69419[0m[0m | time: 38.031s
[2K
| Adam | epoch: 005 | loss: 0.69419 - acc: 0.4977 -- iter: 672/876
[A[ATraining Step: 134  | total loss: [1m[32m0.69371[0m[0m | time: 39.708s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.5073 -- iter: 704/876
[A[ATraining Step: 135  | total loss: [1m[32m0.69404[0m[0m | time: 41.398s
[2K
| Adam | epoch: 005 | loss: 0.69404 - acc: 0.4972 -- iter: 736/876
[A[ATraining Step: 136  | total loss: [1m[32m0.69420[0m[0m | time: 42.940s
[2K
| Adam | epoch: 005 | loss: 0.69420 - acc: 0.4912 -- iter: 768/876
[A[ATraining Step: 137  | total loss: [1m[32m0.69466[0m[0m | time: 44.350s
[2K
| Adam | epoch: 005 | loss: 0.69466 - acc: 0.4765 -- iter: 800/876
[A[ATraining Step: 138  | total loss: [1m[32m0.69440[0m[0m | time: 45.601s
[2K
| Adam | epoch: 005 | loss: 0.69440 - acc: 0.4820 -- iter: 832/876
[A[ATraining Step: 139  | total loss: [1m[32m0.69412[0m[0m | time: 46.969s
[2K
| Adam | epoch: 005 | loss: 0.69412 - acc: 0.4900 -- iter: 864/876
[A[ATraining Step: 140  | total loss: [1m[32m0.69373[0m[0m | time: 50.530s
[2K
| Adam | epoch: 005 | loss: 0.69373 - acc: 0.5035 | val_loss: 0.69321 - val_acc: 0.4982 -- iter: 876/876
--
Training Step: 141  | total loss: [1m[32m0.69358[0m[0m | time: 1.507s
[2K
| Adam | epoch: 006 | loss: 0.69358 - acc: 0.5063 -- iter: 032/876
[A[ATraining Step: 142  | total loss: [1m[32m0.69335[0m[0m | time: 2.797s
[2K
| Adam | epoch: 006 | loss: 0.69335 - acc: 0.5119 -- iter: 064/876
[A[ATraining Step: 143  | total loss: [1m[32m0.69348[0m[0m | time: 4.461s
[2K
| Adam | epoch: 006 | loss: 0.69348 - acc: 0.5045 -- iter: 096/876
[A[ATraining Step: 144  | total loss: [1m[32m0.69379[0m[0m | time: 5.246s
[2K
| Adam | epoch: 006 | loss: 0.69379 - acc: 0.4915 -- iter: 128/876
[A[ATraining Step: 145  | total loss: [1m[32m0.69352[0m[0m | time: 5.993s
[2K
| Adam | epoch: 006 | loss: 0.69352 - acc: 0.5007 -- iter: 160/876
[A[ATraining Step: 146  | total loss: [1m[32m0.69331[0m[0m | time: 7.575s
[2K
| Adam | epoch: 006 | loss: 0.69331 - acc: 0.5090 -- iter: 192/876
[A[ATraining Step: 147  | total loss: [1m[32m0.69319[0m[0m | time: 9.165s
[2K
| Adam | epoch: 006 | loss: 0.69319 - acc: 0.5112 -- iter: 224/876
[A[ATraining Step: 148  | total loss: [1m[32m0.69313[0m[0m | time: 10.448s
[2K
| Adam | epoch: 006 | loss: 0.69313 - acc: 0.5132 -- iter: 256/876
[A[ATraining Step: 149  | total loss: [1m[32m0.69328[0m[0m | time: 11.707s
[2K
| Adam | epoch: 006 | loss: 0.69328 - acc: 0.5056 -- iter: 288/876
[A[ATraining Step: 150  | total loss: [1m[32m0.69361[0m[0m | time: 13.068s
[2K
| Adam | epoch: 006 | loss: 0.69361 - acc: 0.4926 -- iter: 320/876
[A[ATraining Step: 151  | total loss: [1m[32m0.69342[0m[0m | time: 14.509s
[2K
| Adam | epoch: 006 | loss: 0.69342 - acc: 0.4996 -- iter: 352/876
[A[ATraining Step: 152  | total loss: [1m[32m0.69325[0m[0m | time: 16.015s
[2K
| Adam | epoch: 006 | loss: 0.69325 - acc: 0.5059 -- iter: 384/876
[A[ATraining Step: 153  | total loss: [1m[32m0.69309[0m[0m | time: 17.474s
[2K
| Adam | epoch: 006 | loss: 0.69309 - acc: 0.5115 -- iter: 416/876
[A[ATraining Step: 154  | total loss: [1m[32m0.69320[0m[0m | time: 19.299s
[2K
| Adam | epoch: 006 | loss: 0.69320 - acc: 0.5041 -- iter: 448/876
[A[ATraining Step: 155  | total loss: [1m[32m0.69328[0m[0m | time: 20.792s
[2K
| Adam | epoch: 006 | loss: 0.69328 - acc: 0.4975 -- iter: 480/876
[A[ATraining Step: 156  | total loss: [1m[32m0.69342[0m[0m | time: 22.133s
[2K
| Adam | epoch: 006 | loss: 0.69342 - acc: 0.4883 -- iter: 512/876
[A[ATraining Step: 157  | total loss: [1m[32m0.69340[0m[0m | time: 23.542s
[2K
| Adam | epoch: 006 | loss: 0.69340 - acc: 0.4864 -- iter: 544/876
[A[ATraining Step: 158  | total loss: [1m[32m0.69336[0m[0m | time: 25.111s
[2K
| Adam | epoch: 006 | loss: 0.69336 - acc: 0.4877 -- iter: 576/876
[A[ATraining Step: 159  | total loss: [1m[32m0.69328[0m[0m | time: 26.470s
[2K
| Adam | epoch: 006 | loss: 0.69328 - acc: 0.5108 -- iter: 608/876
[A[ATraining Step: 160  | total loss: [1m[32m0.69325[0m[0m | time: 27.943s
[2K
| Adam | epoch: 006 | loss: 0.69325 - acc: 0.5098 -- iter: 640/876
[A[ATraining Step: 161  | total loss: [1m[32m0.69322[0m[0m | time: 29.192s
[2K
| Adam | epoch: 006 | loss: 0.69322 - acc: 0.5057 -- iter: 672/876
[A[ATraining Step: 162  | total loss: [1m[32m0.69319[0m[0m | time: 30.399s
[2K
| Adam | epoch: 006 | loss: 0.69319 - acc: 0.5051 -- iter: 704/876
[A[ATraining Step: 163  | total loss: [1m[32m0.69311[0m[0m | time: 31.869s
[2K
| Adam | epoch: 006 | loss: 0.69311 - acc: 0.5108 -- iter: 736/876
[A[ATraining Step: 164  | total loss: [1m[32m0.69299[0m[0m | time: 33.297s
[2K
| Adam | epoch: 006 | loss: 0.69299 - acc: 0.5160 -- iter: 768/876
[A[ATraining Step: 165  | total loss: [1m[32m0.69288[0m[0m | time: 34.595s
[2K
| Adam | epoch: 006 | loss: 0.69288 - acc: 0.5206 -- iter: 800/876
[A[ATraining Step: 166  | total loss: [1m[32m0.69264[0m[0m | time: 36.213s
[2K
| Adam | epoch: 006 | loss: 0.69264 - acc: 0.5280 -- iter: 832/876
[A[ATraining Step: 167  | total loss: [1m[32m0.69267[0m[0m | time: 37.876s
[2K
| Adam | epoch: 006 | loss: 0.69267 - acc: 0.5252 -- iter: 864/876
[A[ATraining Step: 168  | total loss: [1m[32m0.69279[0m[0m | time: 41.440s
[2K
| Adam | epoch: 006 | loss: 0.69279 - acc: 0.5195 | val_loss: 0.69322 - val_acc: 0.4982 -- iter: 876/876
--
Training Step: 169  | total loss: [1m[32m0.69281[0m[0m | time: 1.368s
[2K
| Adam | epoch: 007 | loss: 0.69281 - acc: 0.5176 -- iter: 032/876
[A[ATraining Step: 170  | total loss: [1m[32m0.69285[0m[0m | time: 2.986s
[2K
| Adam | epoch: 007 | loss: 0.69285 - acc: 0.5158 -- iter: 064/876
[A[ATraining Step: 171  | total loss: [1m[32m0.69298[0m[0m | time: 4.249s
[2K
| Adam | epoch: 007 | loss: 0.69298 - acc: 0.5111 -- iter: 096/876
[A[ATraining Step: 172  | total loss: [1m[32m0.69277[0m[0m | time: 5.751s
[2K
| Adam | epoch: 007 | loss: 0.69277 - acc: 0.5162 -- iter: 128/876
[A[ATraining Step: 173  | total loss: [1m[32m0.69304[0m[0m | time: 6.434s
[2K
| Adam | epoch: 007 | loss: 0.69304 - acc: 0.5084 -- iter: 160/876
[A[ATraining Step: 174  | total loss: [1m[32m0.69333[0m[0m | time: 7.073s
[2K
| Adam | epoch: 007 | loss: 0.69333 - acc: 0.4992 -- iter: 192/876
[A[ATraining Step: 175  | total loss: [1m[32m0.69352[0m[0m | time: 8.560s
[2K
| Adam | epoch: 007 | loss: 0.69352 - acc: 0.4909 -- iter: 224/876
[A[ATraining Step: 176  | total loss: [1m[32m0.69365[0m[0m | time: 10.025s
[2K
| Adam | epoch: 007 | loss: 0.69365 - acc: 0.4825 -- iter: 256/876
[A[ATraining Step: 177  | total loss: [1m[32m0.69352[0m[0m | time: 11.586s
[2K
| Adam | epoch: 007 | loss: 0.69352 - acc: 0.4842 -- iter: 288/876
[A[ATraining Step: 178  | total loss: [1m[32m0.69348[0m[0m | time: 13.170s
[2K
| Adam | epoch: 007 | loss: 0.69348 - acc: 0.4764 -- iter: 320/876
[A[ATraining Step: 179  | total loss: [1m[32m0.69342[0m[0m | time: 14.644s
[2K
| Adam | epoch: 007 | loss: 0.69342 - acc: 0.4757 -- iter: 352/876
[A[ATraining Step: 180  | total loss: [1m[32m0.69331[0m[0m | time: 16.026s
[2K
| Adam | epoch: 007 | loss: 0.69331 - acc: 0.4750 -- iter: 384/876
[A[ATraining Step: 181  | total loss: [1m[32m0.69348[0m[0m | time: 17.708s
[2K
| Adam | epoch: 007 | loss: 0.69348 - acc: 0.4650 -- iter: 416/876
[A[ATraining Step: 182  | total loss: [1m[32m0.69304[0m[0m | time: 19.234s
[2K
| Adam | epoch: 007 | loss: 0.69304 - acc: 0.4810 -- iter: 448/876
[A[ATraining Step: 183  | total loss: [1m[32m0.69342[0m[0m | time: 20.926s
[2K
| Adam | epoch: 007 | loss: 0.69342 - acc: 0.4641 -- iter: 480/876
[A[ATraining Step: 184  | total loss: [1m[32m0.69283[0m[0m | time: 22.388s
[2K
| Adam | epoch: 007 | loss: 0.69283 - acc: 0.4833 -- iter: 512/876
[A[ATraining Step: 185  | total loss: [1m[32m0.69313[0m[0m | time: 23.643s
[2K
| Adam | epoch: 007 | loss: 0.69313 - acc: 0.4694 -- iter: 544/876
[A[ATraining Step: 186  | total loss: [1m[32m0.69322[0m[0m | time: 25.058s
[2K
| Adam | epoch: 007 | loss: 0.69322 - acc: 0.4568 -- iter: 576/876
[A[ATraining Step: 187  | total loss: [1m[32m0.69326[0m[0m | time: 26.562s
[2K
| Adam | epoch: 007 | loss: 0.69326 - acc: 0.4549 -- iter: 608/876
[A[ATraining Step: 188  | total loss: [1m[32m0.69304[0m[0m | time: 28.100s
[2K
| Adam | epoch: 007 | loss: 0.69304 - acc: 0.4750 -- iter: 640/876
[A[ATraining Step: 189  | total loss: [1m[32m0.69292[0m[0m | time: 29.523s
[2K
| Adam | epoch: 007 | loss: 0.69292 - acc: 0.4775 -- iter: 672/876
[A[ATraining Step: 190  | total loss: [1m[32m0.69262[0m[0m | time: 31.106s
[2K
| Adam | epoch: 007 | loss: 0.69262 - acc: 0.4860 -- iter: 704/876
[A[ATraining Step: 191  | total loss: [1m[32m0.69283[0m[0m | time: 32.569s
[2K
| Adam | epoch: 007 | loss: 0.69283 - acc: 0.4780 -- iter: 736/876
[A[ATraining Step: 192  | total loss: [1m[32m0.69249[0m[0m | time: 33.912s
[2K
| Adam | epoch: 007 | loss: 0.69249 - acc: 0.4834 -- iter: 768/876
[A[ATraining Step: 193  | total loss: [1m[32m0.69206[0m[0m | time: 35.369s
[2K
| Adam | epoch: 007 | loss: 0.69206 - acc: 0.4913 -- iter: 800/876
[A[ATraining Step: 194  | total loss: [1m[32m0.69183[0m[0m | time: 36.922s
[2K
| Adam | epoch: 007 | loss: 0.69183 - acc: 0.5015 -- iter: 832/876
[A[ATraining Step: 195  | total loss: [1m[32m0.69180[0m[0m | time: 38.465s
[2K
| Adam | epoch: 007 | loss: 0.69180 - acc: 0.4982 -- iter: 864/876
[A[ATraining Step: 196  | total loss: [1m[32m0.69169[0m[0m | time: 42.371s
[2K
| Adam | epoch: 007 | loss: 0.69169 - acc: 0.5078 | val_loss: 0.68931 - val_acc: 0.6109 -- iter: 876/876
--
Training Step: 197  | total loss: [1m[32m0.69139[0m[0m | time: 1.453s
[2K
| Adam | epoch: 008 | loss: 0.69139 - acc: 0.5289 -- iter: 032/876
[A[ATraining Step: 198  | total loss: [1m[32m0.69108[0m[0m | time: 3.181s
[2K
| Adam | epoch: 008 | loss: 0.69108 - acc: 0.5385 -- iter: 064/876
[A[ATraining Step: 199  | total loss: [1m[32m0.69066[0m[0m | time: 4.575s
[2K
| Adam | epoch: 008 | loss: 0.69066 - acc: 0.5440 -- iter: 096/876
[A[ATraining Step: 200  | total loss: [1m[32m0.69090[0m[0m | time: 8.083s
[2K
| Adam | epoch: 008 | loss: 0.69090 - acc: 0.5427 | val_loss: 0.68603 - val_acc: 0.6655 -- iter: 128/876
--
Training Step: 201  | total loss: [1m[32m0.69057[0m[0m | time: 9.631s
[2K
| Adam | epoch: 008 | loss: 0.69057 - acc: 0.5478 -- iter: 160/876
[A[ATraining Step: 202  | total loss: [1m[32m0.68984[0m[0m | time: 10.315s
[2K
| Adam | epoch: 008 | loss: 0.68984 - acc: 0.5649 -- iter: 192/876
[A[ATraining Step: 203  | total loss: [1m[32m0.68837[0m[0m | time: 10.928s
[2K
| Adam | epoch: 008 | loss: 0.68837 - acc: 0.5751 -- iter: 224/876
[A[ATraining Step: 204  | total loss: [1m[32m0.68652[0m[0m | time: 12.379s
[2K
| Adam | epoch: 008 | loss: 0.68652 - acc: 0.5843 -- iter: 256/876
[A[ATraining Step: 205  | total loss: [1m[32m0.68518[0m[0m | time: 13.770s
[2K
| Adam | epoch: 008 | loss: 0.68518 - acc: 0.5883 -- iter: 288/876
[A[ATraining Step: 206  | total loss: [1m[32m0.68283[0m[0m | time: 15.194s
[2K
| Adam | epoch: 008 | loss: 0.68283 - acc: 0.5983 -- iter: 320/876
[A[ATraining Step: 207  | total loss: [1m[32m0.68065[0m[0m | time: 16.710s
[2K
| Adam | epoch: 008 | loss: 0.68065 - acc: 0.5978 -- iter: 352/876
[A[ATraining Step: 208  | total loss: [1m[32m0.67845[0m[0m | time: 18.419s
[2K
| Adam | epoch: 008 | loss: 0.67845 - acc: 0.6162 -- iter: 384/876
[A[ATraining Step: 209  | total loss: [1m[32m0.67743[0m[0m | time: 19.986s
[2K
| Adam | epoch: 008 | loss: 0.67743 - acc: 0.6108 -- iter: 416/876
[A[ATraining Step: 210  | total loss: [1m[32m0.67619[0m[0m | time: 21.355s
[2K
| Adam | epoch: 008 | loss: 0.67619 - acc: 0.6185 -- iter: 448/876
[A[ATraining Step: 211  | total loss: [1m[32m0.66537[0m[0m | time: 22.496s
[2K
| Adam | epoch: 008 | loss: 0.66537 - acc: 0.6472 -- iter: 480/876
[A[ATraining Step: 212  | total loss: [1m[32m0.67380[0m[0m | time: 24.015s
[2K
| Adam | epoch: 008 | loss: 0.67380 - acc: 0.6231 -- iter: 512/876
[A[ATraining Step: 213  | total loss: [1m[32m0.67228[0m[0m | time: 25.393s
[2K
| Adam | epoch: 008 | loss: 0.67228 - acc: 0.6264 -- iter: 544/876
[A[ATraining Step: 214  | total loss: [1m[32m0.66556[0m[0m | time: 26.954s
[2K
| Adam | epoch: 008 | loss: 0.66556 - acc: 0.6419 -- iter: 576/876
[A[ATraining Step: 215  | total loss: [1m[32m0.66946[0m[0m | time: 28.521s
[2K
| Adam | epoch: 008 | loss: 0.66946 - acc: 0.6309 -- iter: 608/876
[A[ATraining Step: 216  | total loss: [1m[32m0.66381[0m[0m | time: 30.017s
[2K
| Adam | epoch: 008 | loss: 0.66381 - acc: 0.6396 -- iter: 640/876
[A[ATraining Step: 217  | total loss: [1m[32m0.66395[0m[0m | time: 31.460s
[2K
| Adam | epoch: 008 | loss: 0.66395 - acc: 0.6444 -- iter: 672/876
[A[ATraining Step: 218  | total loss: [1m[32m0.65025[0m[0m | time: 33.087s
[2K
| Adam | epoch: 008 | loss: 0.65025 - acc: 0.6612 -- iter: 704/876
[A[ATraining Step: 219  | total loss: [1m[32m0.65138[0m[0m | time: 34.566s
[2K
| Adam | epoch: 008 | loss: 0.65138 - acc: 0.6514 -- iter: 736/876
[A[ATraining Step: 220  | total loss: [1m[32m0.64399[0m[0m | time: 36.143s
[2K
| Adam | epoch: 008 | loss: 0.64399 - acc: 0.6675 -- iter: 768/876
[A[ATraining Step: 221  | total loss: [1m[32m0.63981[0m[0m | time: 37.676s
[2K
| Adam | epoch: 008 | loss: 0.63981 - acc: 0.6726 -- iter: 800/876
[A[ATraining Step: 222  | total loss: [1m[32m0.62854[0m[0m | time: 39.444s
[2K
| Adam | epoch: 008 | loss: 0.62854 - acc: 0.6928 -- iter: 832/876
[A[ATraining Step: 223  | total loss: [1m[32m0.61920[0m[0m | time: 40.952s
[2K
| Adam | epoch: 008 | loss: 0.61920 - acc: 0.7017 -- iter: 864/876
[A[ATraining Step: 224  | total loss: [1m[32m0.63303[0m[0m | time: 44.550s
[2K
| Adam | epoch: 008 | loss: 0.63303 - acc: 0.6846 | val_loss: 0.56465 - val_acc: 0.7200 -- iter: 876/876
--
Training Step: 225  | total loss: [1m[32m0.63833[0m[0m | time: 1.611s
[2K
| Adam | epoch: 009 | loss: 0.63833 - acc: 0.6756 -- iter: 032/876
[A[ATraining Step: 226  | total loss: [1m[32m0.63391[0m[0m | time: 3.046s
[2K
| Adam | epoch: 009 | loss: 0.63391 - acc: 0.6767 -- iter: 064/876
[A[ATraining Step: 227  | total loss: [1m[32m0.64294[0m[0m | time: 4.479s
[2K
| Adam | epoch: 009 | loss: 0.64294 - acc: 0.6591 -- iter: 096/876
[A[ATraining Step: 228  | total loss: [1m[32m0.64184[0m[0m | time: 6.088s
[2K
| Adam | epoch: 009 | loss: 0.64184 - acc: 0.6557 -- iter: 128/876
[A[ATraining Step: 229  | total loss: [1m[32m0.64580[0m[0m | time: 7.891s
[2K
| Adam | epoch: 009 | loss: 0.64580 - acc: 0.6463 -- iter: 160/876
[A[ATraining Step: 230  | total loss: [1m[32m0.63840[0m[0m | time: 9.624s
[2K
| Adam | epoch: 009 | loss: 0.63840 - acc: 0.6567 -- iter: 192/876
[A[ATraining Step: 231  | total loss: [1m[32m0.62474[0m[0m | time: 10.229s
[2K
| Adam | epoch: 009 | loss: 0.62474 - acc: 0.6848 -- iter: 224/876
[A[ATraining Step: 232  | total loss: [1m[32m0.60899[0m[0m | time: 10.754s
[2K
| Adam | epoch: 009 | loss: 0.60899 - acc: 0.6996 -- iter: 256/876
[A[ATraining Step: 233  | total loss: [1m[32m0.59617[0m[0m | time: 11.979s
[2K
| Adam | epoch: 009 | loss: 0.59617 - acc: 0.7130 -- iter: 288/876
[A[ATraining Step: 234  | total loss: [1m[32m0.59589[0m[0m | time: 13.611s
[2K
| Adam | epoch: 009 | loss: 0.59589 - acc: 0.7105 -- iter: 320/876
[A[ATraining Step: 235  | total loss: [1m[32m0.58762[0m[0m | time: 15.148s
[2K
| Adam | epoch: 009 | loss: 0.58762 - acc: 0.7144 -- iter: 352/876
[A[ATraining Step: 236  | total loss: [1m[32m0.58363[0m[0m | time: 16.682s
[2K
| Adam | epoch: 009 | loss: 0.58363 - acc: 0.7149 -- iter: 384/876
[A[ATraining Step: 237  | total loss: [1m[32m0.58000[0m[0m | time: 18.082s
[2K
| Adam | epoch: 009 | loss: 0.58000 - acc: 0.7246 -- iter: 416/876
[A[ATraining Step: 238  | total loss: [1m[32m0.58504[0m[0m | time: 19.509s
[2K
| Adam | epoch: 009 | loss: 0.58504 - acc: 0.7178 -- iter: 448/876
[A[ATraining Step: 239  | total loss: [1m[32m0.58192[0m[0m | time: 21.096s
[2K
| Adam | epoch: 009 | loss: 0.58192 - acc: 0.7148 -- iter: 480/876
[A[ATraining Step: 240  | total loss: [1m[32m0.57046[0m[0m | time: 22.518s
[2K
| Adam | epoch: 009 | loss: 0.57046 - acc: 0.7183 -- iter: 512/876
[A[ATraining Step: 241  | total loss: [1m[32m0.55862[0m[0m | time: 23.966s
[2K
| Adam | epoch: 009 | loss: 0.55862 - acc: 0.7277 -- iter: 544/876
[A[ATraining Step: 242  | total loss: [1m[32m0.57197[0m[0m | time: 25.542s
[2K
| Adam | epoch: 009 | loss: 0.57197 - acc: 0.7206 -- iter: 576/876
[A[ATraining Step: 243  | total loss: [1m[32m0.59737[0m[0m | time: 27.224s
[2K
| Adam | epoch: 009 | loss: 0.59737 - acc: 0.7079 -- iter: 608/876
[A[ATraining Step: 244  | total loss: [1m[32m0.60151[0m[0m | time: 28.927s
[2K
| Adam | epoch: 009 | loss: 0.60151 - acc: 0.6996 -- iter: 640/876
[A[ATraining Step: 245  | total loss: [1m[32m0.58172[0m[0m | time: 30.242s
[2K
| Adam | epoch: 009 | loss: 0.58172 - acc: 0.7140 -- iter: 672/876
[A[ATraining Step: 246  | total loss: [1m[32m0.57144[0m[0m | time: 31.679s
[2K
| Adam | epoch: 009 | loss: 0.57144 - acc: 0.7207 -- iter: 704/876
[A[ATraining Step: 247  | total loss: [1m[32m0.56943[0m[0m | time: 33.262s
[2K
| Adam | epoch: 009 | loss: 0.56943 - acc: 0.7205 -- iter: 736/876
[A[ATraining Step: 248  | total loss: [1m[32m0.58261[0m[0m | time: 34.735s
[2K
| Adam | epoch: 009 | loss: 0.58261 - acc: 0.7172 -- iter: 768/876
[A[ATraining Step: 249  | total loss: [1m[32m0.57169[0m[0m | time: 36.207s
[2K
| Adam | epoch: 009 | loss: 0.57169 - acc: 0.7236 -- iter: 800/876
[A[ATraining Step: 250  | total loss: [1m[32m0.55510[0m[0m | time: 37.588s
[2K
| Adam | epoch: 009 | loss: 0.55510 - acc: 0.7356 -- iter: 832/876
[A[ATraining Step: 251  | total loss: [1m[32m0.53923[0m[0m | time: 39.250s
[2K
| Adam | epoch: 009 | loss: 0.53923 - acc: 0.7496 -- iter: 864/876
[A[ATraining Step: 252  | total loss: [1m[32m0.53442[0m[0m | time: 43.070s
[2K
| Adam | epoch: 009 | loss: 0.53442 - acc: 0.7496 | val_loss: 0.53620 - val_acc: 0.7273 -- iter: 876/876
--
Training Step: 253  | total loss: [1m[32m0.52702[0m[0m | time: 1.714s
[2K
| Adam | epoch: 010 | loss: 0.52702 - acc: 0.7497 -- iter: 032/876
[A[ATraining Step: 254  | total loss: [1m[32m0.51508[0m[0m | time: 3.290s
[2K
| Adam | epoch: 010 | loss: 0.51508 - acc: 0.7622 -- iter: 064/876
[A[ATraining Step: 255  | total loss: [1m[32m0.52787[0m[0m | time: 4.793s
[2K
| Adam | epoch: 010 | loss: 0.52787 - acc: 0.7453 -- iter: 096/876
[A[ATraining Step: 256  | total loss: [1m[32m0.50845[0m[0m | time: 5.949s
[2K
| Adam | epoch: 010 | loss: 0.50845 - acc: 0.7614 -- iter: 128/876
[A[ATraining Step: 257  | total loss: [1m[32m0.49555[0m[0m | time: 7.584s
[2K
| Adam | epoch: 010 | loss: 0.49555 - acc: 0.7697 -- iter: 160/876
[A[ATraining Step: 258  | total loss: [1m[32m0.48481[0m[0m | time: 9.095s
[2K
| Adam | epoch: 010 | loss: 0.48481 - acc: 0.7771 -- iter: 192/876
[A[ATraining Step: 259  | total loss: [1m[32m0.48232[0m[0m | time: 10.677s
[2K
| Adam | epoch: 010 | loss: 0.48232 - acc: 0.7775 -- iter: 224/876
[A[ATraining Step: 260  | total loss: [1m[32m0.47268[0m[0m | time: 11.346s
[2K
| Adam | epoch: 010 | loss: 0.47268 - acc: 0.7841 -- iter: 256/876
[A[ATraining Step: 261  | total loss: [1m[32m0.47740[0m[0m | time: 11.859s
[2K
| Adam | epoch: 010 | loss: 0.47740 - acc: 0.7807 -- iter: 288/876
[A[ATraining Step: 262  | total loss: [1m[32m0.47845[0m[0m | time: 13.467s
[2K
| Adam | epoch: 010 | loss: 0.47845 - acc: 0.7860 -- iter: 320/876
[A[ATraining Step: 263  | total loss: [1m[32m0.45902[0m[0m | time: 15.119s
[2K
| Adam | epoch: 010 | loss: 0.45902 - acc: 0.7949 -- iter: 352/876
[A[ATraining Step: 264  | total loss: [1m[32m0.45127[0m[0m | time: 16.554s
[2K
| Adam | epoch: 010 | loss: 0.45127 - acc: 0.7998 -- iter: 384/876
[A[ATraining Step: 265  | total loss: [1m[32m0.44837[0m[0m | time: 17.943s
[2K
| Adam | epoch: 010 | loss: 0.44837 - acc: 0.8010 -- iter: 416/876
[A[ATraining Step: 266  | total loss: [1m[32m0.46242[0m[0m | time: 19.476s
[2K
| Adam | epoch: 010 | loss: 0.46242 - acc: 0.8022 -- iter: 448/876
[A[ATraining Step: 267  | total loss: [1m[32m0.44601[0m[0m | time: 21.144s
[2K
| Adam | epoch: 010 | loss: 0.44601 - acc: 0.8063 -- iter: 480/876
[A[ATraining Step: 268  | total loss: [1m[32m0.43906[0m[0m | time: 22.972s
[2K
| Adam | epoch: 010 | loss: 0.43906 - acc: 0.8101 -- iter: 512/876
[A[ATraining Step: 269  | total loss: [1m[32m0.43623[0m[0m | time: 24.279s
[2K
| Adam | epoch: 010 | loss: 0.43623 - acc: 0.8166 -- iter: 544/876
[A[ATraining Step: 270  | total loss: [1m[32m0.44922[0m[0m | time: 25.690s
[2K
| Adam | epoch: 010 | loss: 0.44922 - acc: 0.8099 -- iter: 576/876
[A[ATraining Step: 271  | total loss: [1m[32m0.45415[0m[0m | time: 27.315s
[2K
| Adam | epoch: 010 | loss: 0.45415 - acc: 0.8070 -- iter: 608/876
[A[ATraining Step: 272  | total loss: [1m[32m0.45059[0m[0m | time: 28.730s
[2K
| Adam | epoch: 010 | loss: 0.45059 - acc: 0.8107 -- iter: 640/876
[A[ATraining Step: 273  | total loss: [1m[32m0.43451[0m[0m | time: 30.189s
[2K
| Adam | epoch: 010 | loss: 0.43451 - acc: 0.8171 -- iter: 672/876
[A[ATraining Step: 274  | total loss: [1m[32m0.42398[0m[0m | time: 31.535s
[2K
| Adam | epoch: 010 | loss: 0.42398 - acc: 0.8229 -- iter: 704/876
[A[ATraining Step: 275  | total loss: [1m[32m0.42751[0m[0m | time: 33.068s
[2K
| Adam | epoch: 010 | loss: 0.42751 - acc: 0.8125 -- iter: 736/876
[A[ATraining Step: 276  | total loss: [1m[32m0.42287[0m[0m | time: 34.718s
[2K
| Adam | epoch: 010 | loss: 0.42287 - acc: 0.8156 -- iter: 768/876
[A[ATraining Step: 277  | total loss: [1m[32m0.40984[0m[0m | time: 36.100s
[2K
| Adam | epoch: 010 | loss: 0.40984 - acc: 0.8184 -- iter: 800/876
[A[ATraining Step: 278  | total loss: [1m[32m0.40070[0m[0m | time: 37.783s
[2K
| Adam | epoch: 010 | loss: 0.40070 - acc: 0.8272 -- iter: 832/876
[A[ATraining Step: 279  | total loss: [1m[32m0.39836[0m[0m | time: 39.419s
[2K
| Adam | epoch: 010 | loss: 0.39836 - acc: 0.8320 -- iter: 864/876
[A[ATraining Step: 280  | total loss: [1m[32m0.39246[0m[0m | time: 43.508s
[2K
| Adam | epoch: 010 | loss: 0.39246 - acc: 0.8363 | val_loss: 0.42202 - val_acc: 0.7891 -- iter: 876/876
--
Training Step: 281  | total loss: [1m[32m0.37669[0m[0m | time: 1.610s
[2K
| Adam | epoch: 011 | loss: 0.37669 - acc: 0.8402 -- iter: 032/876
[A[ATraining Step: 282  | total loss: [1m[32m0.37722[0m[0m | time: 3.128s
[2K
| Adam | epoch: 011 | loss: 0.37722 - acc: 0.8374 -- iter: 064/876
[A[ATraining Step: 283  | total loss: [1m[32m0.36770[0m[0m | time: 4.677s
[2K
| Adam | epoch: 011 | loss: 0.36770 - acc: 0.8412 -- iter: 096/876
[A[ATraining Step: 284  | total loss: [1m[32m0.37291[0m[0m | time: 6.082s
[2K
| Adam | epoch: 011 | loss: 0.37291 - acc: 0.8414 -- iter: 128/876
[A[ATraining Step: 285  | total loss: [1m[32m0.36196[0m[0m | time: 7.598s
[2K
| Adam | epoch: 011 | loss: 0.36196 - acc: 0.8448 -- iter: 160/876
[A[ATraining Step: 286  | total loss: [1m[32m0.37042[0m[0m | time: 9.156s
[2K
| Adam | epoch: 011 | loss: 0.37042 - acc: 0.8416 -- iter: 192/876
[A[ATraining Step: 287  | total loss: [1m[32m0.36742[0m[0m | time: 10.644s
[2K
| Adam | epoch: 011 | loss: 0.36742 - acc: 0.8449 -- iter: 224/876
[A[ATraining Step: 288  | total loss: [1m[32m0.37507[0m[0m | time: 12.666s
[2K
| Adam | epoch: 011 | loss: 0.37507 - acc: 0.8448 -- iter: 256/876
[A[ATraining Step: 289  | total loss: [1m[32m0.38093[0m[0m | time: 13.507s
[2K
| Adam | epoch: 011 | loss: 0.38093 - acc: 0.8416 -- iter: 288/876
[A[ATraining Step: 290  | total loss: [1m[32m0.37249[0m[0m | time: 14.307s
[2K
| Adam | epoch: 011 | loss: 0.37249 - acc: 0.8491 -- iter: 320/876
[A[ATraining Step: 291  | total loss: [1m[32m0.36597[0m[0m | time: 16.015s
[2K
| Adam | epoch: 011 | loss: 0.36597 - acc: 0.8392 -- iter: 352/876
[A[ATraining Step: 292  | total loss: [1m[32m0.39971[0m[0m | time: 24.432s
[2K
| Adam | epoch: 011 | loss: 0.39971 - acc: 0.8177 -- iter: 384/876
[A[ATraining Step: 293  | total loss: [1m[32m0.40262[0m[0m | time: 37.044s
[2K
| Adam | epoch: 011 | loss: 0.40262 - acc: 0.8141 -- iter: 416/876
[A[ATraining Step: 294  | total loss: [1m[32m0.39501[0m[0m | time: 52.386s
[2K
| Adam | epoch: 011 | loss: 0.39501 - acc: 0.8233 -- iter: 448/876
[A[ATraining Step: 295  | total loss: [1m[32m0.37567[0m[0m | time: 61.841s
[2K
| Adam | epoch: 011 | loss: 0.37567 - acc: 0.8347 -- iter: 480/876
[A[ATraining Step: 296  | total loss: [1m[32m0.35422[0m[0m | time: 63.325s
[2K
| Adam | epoch: 011 | loss: 0.35422 - acc: 0.8513 -- iter: 512/876
[A[ATraining Step: 297  | total loss: [1m[32m0.34887[0m[0m | time: 64.957s
[2K
| Adam | epoch: 011 | loss: 0.34887 - acc: 0.8536 -- iter: 544/876
[A[ATraining Step: 298  | total loss: [1m[32m0.34282[0m[0m | time: 66.671s
[2K
| Adam | epoch: 011 | loss: 0.34282 - acc: 0.8526 -- iter: 576/876
[A[ATraining Step: 299  | total loss: [1m[32m0.35572[0m[0m | time: 69.069s
[2K
| Adam | epoch: 011 | loss: 0.35572 - acc: 0.8455 -- iter: 608/876
[A[ATraining Step: 300  | total loss: [1m[32m0.35124[0m[0m | time: 70.533s
[2K
| Adam | epoch: 011 | loss: 0.35124 - acc: 0.8485 -- iter: 640/876
[A[ATraining Step: 301  | total loss: [1m[32m0.33633[0m[0m | time: 72.040s
[2K
| Adam | epoch: 011 | loss: 0.33633 - acc: 0.8636 -- iter: 672/876
[A[ATraining Step: 302  | total loss: [1m[32m0.32954[0m[0m | time: 73.583s
[2K
| Adam | epoch: 011 | loss: 0.32954 - acc: 0.8710 -- iter: 704/876
[A[ATraining Step: 303  | total loss: [1m[32m0.33514[0m[0m | time: 75.412s
[2K
| Adam | epoch: 011 | loss: 0.33514 - acc: 0.8620 -- iter: 736/876
[A[ATraining Step: 304  | total loss: [1m[32m0.34203[0m[0m | time: 77.273s
[2K
| Adam | epoch: 011 | loss: 0.34203 - acc: 0.8571 -- iter: 768/876
[A[ATraining Step: 305  | total loss: [1m[32m0.32759[0m[0m | time: 79.221s
[2K
| Adam | epoch: 011 | loss: 0.32759 - acc: 0.8620 -- iter: 800/876
[A[ATraining Step: 306  | total loss: [1m[32m0.31843[0m[0m | time: 81.051s
[2K
| Adam | epoch: 011 | loss: 0.31843 - acc: 0.8633 -- iter: 832/876
[A[ATraining Step: 307  | total loss: [1m[32m0.31178[0m[0m | time: 82.692s
[2K
| Adam | epoch: 011 | loss: 0.31178 - acc: 0.8613 -- iter: 864/876
[A[ATraining Step: 308  | total loss: [1m[32m0.32865[0m[0m | time: 87.371s
[2K
| Adam | epoch: 011 | loss: 0.32865 - acc: 0.8565 | val_loss: 0.42051 - val_acc: 0.8218 -- iter: 876/876
--
Training Step: 309  | total loss: [1m[32m0.32352[0m[0m | time: 1.892s
[2K
| Adam | epoch: 012 | loss: 0.32352 - acc: 0.8583 -- iter: 032/876
[A[ATraining Step: 310  | total loss: [1m[32m0.33124[0m[0m | time: 3.706s
[2K
| Adam | epoch: 012 | loss: 0.33124 - acc: 0.8506 -- iter: 064/876
[A[ATraining Step: 311  | total loss: [1m[32m0.31994[0m[0m | time: 5.977s
[2K
| Adam | epoch: 012 | loss: 0.31994 - acc: 0.8593 -- iter: 096/876
[A[ATraining Step: 312  | total loss: [1m[32m0.32787[0m[0m | time: 16.561s
[2K
| Adam | epoch: 012 | loss: 0.32787 - acc: 0.8515 -- iter: 128/876
[A[ATraining Step: 313  | total loss: [1m[32m0.31048[0m[0m | time: 38.548s
[2K
| Adam | epoch: 012 | loss: 0.31048 - acc: 0.8601 -- iter: 160/876
[A[ATraining Step: 314  | total loss: [1m[32m0.31034[0m[0m | time: 44.608s
[2K
| Adam | epoch: 012 | loss: 0.31034 - acc: 0.8616 -- iter: 192/876
[A[ATraining Step: 315  | total loss: [1m[32m0.30912[0m[0m | time: 46.119s
[2K
| Adam | epoch: 012 | loss: 0.30912 - acc: 0.8692 -- iter: 224/876
[A[ATraining Step: 316  | total loss: [1m[32m0.33609[0m[0m | time: 47.571s
[2K
| Adam | epoch: 012 | loss: 0.33609 - acc: 0.8698 -- iter: 256/876
[A[ATraining Step: 317  | total loss: [1m[32m0.33466[0m[0m | time: 49.019s
[2K
| Adam | epoch: 012 | loss: 0.33466 - acc: 0.8672 -- iter: 288/876
[A[ATraining Step: 318  | total loss: [1m[32m0.31781[0m[0m | time: 49.738s
[2K
| Adam | epoch: 012 | loss: 0.31781 - acc: 0.8711 -- iter: 320/876
[A[ATraining Step: 319  | total loss: [1m[32m0.31300[0m[0m | time: 50.330s
[2K
| Adam | epoch: 012 | loss: 0.31300 - acc: 0.8673 -- iter: 352/876
[A[ATraining Step: 320  | total loss: [1m[32m0.30555[0m[0m | time: 51.748s
[2K
| Adam | epoch: 012 | loss: 0.30555 - acc: 0.8722 -- iter: 384/876
[A[ATraining Step: 321  | total loss: [1m[32m0.33912[0m[0m | time: 53.424s
[2K
| Adam | epoch: 012 | loss: 0.33912 - acc: 0.8538 -- iter: 416/876
[A[ATraining Step: 322  | total loss: [1m[32m0.33128[0m[0m | time: 54.939s
[2K
| Adam | epoch: 012 | loss: 0.33128 - acc: 0.8559 -- iter: 448/876
[A[ATraining Step: 323  | total loss: [1m[32m0.33407[0m[0m | time: 56.280s
[2K
| Adam | epoch: 012 | loss: 0.33407 - acc: 0.8547 -- iter: 480/876
[A[ATraining Step: 324  | total loss: [1m[32m0.31595[0m[0m | time: 57.916s
[2K
| Adam | epoch: 012 | loss: 0.31595 - acc: 0.8661 -- iter: 512/876
[A[ATraining Step: 325  | total loss: [1m[32m0.31109[0m[0m | time: 59.561s
[2K
| Adam | epoch: 012 | loss: 0.31109 - acc: 0.8732 -- iter: 544/876
[A[ATraining Step: 326  | total loss: [1m[32m0.31575[0m[0m | time: 61.200s
[2K
| Adam | epoch: 012 | loss: 0.31575 - acc: 0.8765 -- iter: 576/876
[A[ATraining Step: 327  | total loss: [1m[32m0.30104[0m[0m | time: 62.574s
[2K
| Adam | epoch: 012 | loss: 0.30104 - acc: 0.8795 -- iter: 608/876
[A[ATraining Step: 328  | total loss: [1m[32m0.31015[0m[0m | time: 63.851s
[2K
| Adam | epoch: 012 | loss: 0.31015 - acc: 0.8697 -- iter: 640/876
[A[ATraining Step: 329  | total loss: [1m[32m0.31803[0m[0m | time: 65.272s
[2K
| Adam | epoch: 012 | loss: 0.31803 - acc: 0.8671 -- iter: 672/876
[A[ATraining Step: 330  | total loss: [1m[32m0.31938[0m[0m | time: 66.689s
[2K
| Adam | epoch: 012 | loss: 0.31938 - acc: 0.8647 -- iter: 704/876
[A[ATraining Step: 331  | total loss: [1m[32m0.30783[0m[0m | time: 68.194s
[2K
| Adam | epoch: 012 | loss: 0.30783 - acc: 0.8720 -- iter: 736/876
[A[ATraining Step: 332  | total loss: [1m[32m0.30193[0m[0m | time: 69.600s
[2K
| Adam | epoch: 012 | loss: 0.30193 - acc: 0.8754 -- iter: 768/876
[A[ATraining Step: 333  | total loss: [1m[32m0.29099[0m[0m | time: 71.089s
[2K
| Adam | epoch: 012 | loss: 0.29099 - acc: 0.8848 -- iter: 800/876
[A[ATraining Step: 334  | total loss: [1m[32m0.28106[0m[0m | time: 72.594s
[2K
| Adam | epoch: 012 | loss: 0.28106 - acc: 0.8838 -- iter: 832/876
[A[ATraining Step: 335  | total loss: [1m[32m0.26914[0m[0m | time: 73.990s
[2K
| Adam | epoch: 012 | loss: 0.26914 - acc: 0.8892 -- iter: 864/876
[A[ATraining Step: 336  | total loss: [1m[32m0.27319[0m[0m | time: 78.115s
[2K
| Adam | epoch: 012 | loss: 0.27319 - acc: 0.8909 | val_loss: 0.42781 - val_acc: 0.7927 -- iter: 876/876
--
Training Step: 337  | total loss: [1m[32m0.26412[0m[0m | time: 1.815s
[2K
| Adam | epoch: 013 | loss: 0.26412 - acc: 0.8987 -- iter: 032/876
[A[ATraining Step: 338  | total loss: [1m[32m0.27096[0m[0m | time: 3.333s
[2K
| Adam | epoch: 013 | loss: 0.27096 - acc: 0.8932 -- iter: 064/876
[A[ATraining Step: 339  | total loss: [1m[32m0.26707[0m[0m | time: 4.796s
[2K
| Adam | epoch: 013 | loss: 0.26707 - acc: 0.8914 -- iter: 096/876
[A[ATraining Step: 340  | total loss: [1m[32m0.26477[0m[0m | time: 6.314s
[2K
| Adam | epoch: 013 | loss: 0.26477 - acc: 0.8897 -- iter: 128/876
[A[ATraining Step: 341  | total loss: [1m[32m0.26110[0m[0m | time: 7.575s
[2K
| Adam | epoch: 013 | loss: 0.26110 - acc: 0.8914 -- iter: 160/876
[A[ATraining Step: 342  | total loss: [1m[32m0.24706[0m[0m | time: 8.991s
[2K
| Adam | epoch: 013 | loss: 0.24706 - acc: 0.9022 -- iter: 192/876
[A[ATraining Step: 343  | total loss: [1m[32m0.25171[0m[0m | time: 10.519s
[2K
| Adam | epoch: 013 | loss: 0.25171 - acc: 0.9026 -- iter: 224/876
[A[ATraining Step: 344  | total loss: [1m[32m0.26732[0m[0m | time: 12.012s
[2K
| Adam | epoch: 013 | loss: 0.26732 - acc: 0.8936 -- iter: 256/876
[A[ATraining Step: 345  | total loss: [1m[32m0.29355[0m[0m | time: 13.462s
[2K
| Adam | epoch: 013 | loss: 0.29355 - acc: 0.8824 -- iter: 288/876
[A[ATraining Step: 346  | total loss: [1m[32m0.29093[0m[0m | time: 14.828s
[2K
| Adam | epoch: 013 | loss: 0.29093 - acc: 0.8848 -- iter: 320/876
[A[ATraining Step: 347  | total loss: [1m[32m0.28630[0m[0m | time: 15.568s
[2K
| Adam | epoch: 013 | loss: 0.28630 - acc: 0.8900 -- iter: 352/876
[A[ATraining Step: 348  | total loss: [1m[32m0.27154[0m[0m | time: 16.249s
[2K
| Adam | epoch: 013 | loss: 0.27154 - acc: 0.8927 -- iter: 384/876
[A[ATraining Step: 349  | total loss: [1m[32m0.25630[0m[0m | time: 17.886s
[2K
| Adam | epoch: 013 | loss: 0.25630 - acc: 0.8951 -- iter: 416/876
[A[ATraining Step: 350  | total loss: [1m[32m0.24426[0m[0m | time: 19.547s
[2K
| Adam | epoch: 013 | loss: 0.24426 - acc: 0.8993 -- iter: 448/876
[A[ATraining Step: 351  | total loss: [1m[32m0.24199[0m[0m | time: 20.990s
[2K
| Adam | epoch: 013 | loss: 0.24199 - acc: 0.9032 -- iter: 480/876
[A[ATraining Step: 352  | total loss: [1m[32m0.22684[0m[0m | time: 22.451s
[2K
| Adam | epoch: 013 | loss: 0.22684 - acc: 0.9128 -- iter: 512/876
[A[ATraining Step: 353  | total loss: [1m[32m0.22244[0m[0m | time: 23.968s
[2K
| Adam | epoch: 013 | loss: 0.22244 - acc: 0.9184 -- iter: 544/876
[A[ATraining Step: 354  | total loss: [1m[32m0.21988[0m[0m | time: 25.266s
[2K
| Adam | epoch: 013 | loss: 0.21988 - acc: 0.9172 -- iter: 576/876
[A[ATraining Step: 355  | total loss: [1m[32m0.22368[0m[0m | time: 26.578s
[2K
| Adam | epoch: 013 | loss: 0.22368 - acc: 0.9161 -- iter: 608/876
[A[ATraining Step: 356  | total loss: [1m[32m0.21290[0m[0m | time: 27.963s
[2K
| Adam | epoch: 013 | loss: 0.21290 - acc: 0.9183 -- iter: 640/876
[A[ATraining Step: 357  | total loss: [1m[32m0.21389[0m[0m | time: 29.539s
[2K
| Adam | epoch: 013 | loss: 0.21389 - acc: 0.9171 -- iter: 672/876
[A[ATraining Step: 358  | total loss: [1m[32m0.22074[0m[0m | time: 30.965s
[2K
| Adam | epoch: 013 | loss: 0.22074 - acc: 0.9097 -- iter: 704/876
[A[ATraining Step: 359  | total loss: [1m[32m0.23670[0m[0m | time: 32.382s
[2K
| Adam | epoch: 013 | loss: 0.23670 - acc: 0.9063 -- iter: 736/876
[A[ATraining Step: 360  | total loss: [1m[32m0.22671[0m[0m | time: 34.256s
[2K
| Adam | epoch: 013 | loss: 0.22671 - acc: 0.9125 -- iter: 768/876
[A[ATraining Step: 361  | total loss: [1m[32m0.21222[0m[0m | time: 35.941s
[2K
| Adam | epoch: 013 | loss: 0.21222 - acc: 0.9213 -- iter: 800/876
[A[ATraining Step: 362  | total loss: [1m[32m0.21069[0m[0m | time: 37.405s
[2K
| Adam | epoch: 013 | loss: 0.21069 - acc: 0.9198 -- iter: 832/876
[A[ATraining Step: 363  | total loss: [1m[32m0.19860[0m[0m | time: 39.159s
[2K
| Adam | epoch: 013 | loss: 0.19860 - acc: 0.9247 -- iter: 864/876
[A[ATraining Step: 364  | total loss: [1m[32m0.20326[0m[0m | time: 42.874s
[2K
| Adam | epoch: 013 | loss: 0.20326 - acc: 0.9197 | val_loss: 0.45049 - val_acc: 0.7927 -- iter: 876/876
--
Training Step: 365  | total loss: [1m[32m0.20266[0m[0m | time: 1.369s
[2K
| Adam | epoch: 014 | loss: 0.20266 - acc: 0.9215 -- iter: 032/876
[A[ATraining Step: 366  | total loss: [1m[32m0.19960[0m[0m | time: 2.977s
[2K
| Adam | epoch: 014 | loss: 0.19960 - acc: 0.9199 -- iter: 064/876
[A[ATraining Step: 367  | total loss: [1m[32m0.20275[0m[0m | time: 4.823s
[2K
| Adam | epoch: 014 | loss: 0.20275 - acc: 0.9186 -- iter: 096/876
[A[ATraining Step: 368  | total loss: [1m[32m0.19935[0m[0m | time: 6.608s
[2K
| Adam | epoch: 014 | loss: 0.19935 - acc: 0.9173 -- iter: 128/876
[A[ATraining Step: 369  | total loss: [1m[32m0.18849[0m[0m | time: 8.231s
[2K
| Adam | epoch: 014 | loss: 0.18849 - acc: 0.9225 -- iter: 160/876
[A[ATraining Step: 370  | total loss: [1m[32m0.18811[0m[0m | time: 9.943s
[2K
| Adam | epoch: 014 | loss: 0.18811 - acc: 0.9240 -- iter: 192/876
[A[ATraining Step: 371  | total loss: [1m[32m0.18568[0m[0m | time: 11.870s
[2K
| Adam | epoch: 014 | loss: 0.18568 - acc: 0.9191 -- iter: 224/876
[A[ATraining Step: 372  | total loss: [1m[32m0.20479[0m[0m | time: 13.615s
[2K
| Adam | epoch: 014 | loss: 0.20479 - acc: 0.9147 -- iter: 256/876
[A[ATraining Step: 373  | total loss: [1m[32m0.20832[0m[0m | time: 15.490s
[2K
| Adam | epoch: 014 | loss: 0.20832 - acc: 0.9138 -- iter: 288/876
[A[ATraining Step: 374  | total loss: [1m[32m0.25961[0m[0m | time: 17.236s
[2K
| Adam | epoch: 014 | loss: 0.25961 - acc: 0.9006 -- iter: 320/876
[A[ATraining Step: 375  | total loss: [1m[32m0.24717[0m[0m | time: 18.727s
[2K
| Adam | epoch: 014 | loss: 0.24717 - acc: 0.9074 -- iter: 352/876
[A[ATraining Step: 376  | total loss: [1m[32m0.23353[0m[0m | time: 19.306s
[2K
| Adam | epoch: 014 | loss: 0.23353 - acc: 0.9135 -- iter: 384/876
[A[ATraining Step: 377  | total loss: [1m[32m0.21374[0m[0m | time: 19.967s
[2K
| Adam | epoch: 014 | loss: 0.21374 - acc: 0.9222 -- iter: 416/876
[A[ATraining Step: 378  | total loss: [1m[32m0.19530[0m[0m | time: 21.438s
[2K
| Adam | epoch: 014 | loss: 0.19530 - acc: 0.9300 -- iter: 448/876
[A[ATraining Step: 379  | total loss: [1m[32m0.18377[0m[0m | time: 23.029s
[2K
| Adam | epoch: 014 | loss: 0.18377 - acc: 0.9370 -- iter: 480/876
[A[ATraining Step: 380  | total loss: [1m[32m0.17235[0m[0m | time: 24.740s
[2K
| Adam | epoch: 014 | loss: 0.17235 - acc: 0.9433 -- iter: 512/876
[A[ATraining Step: 381  | total loss: [1m[32m0.16571[0m[0m | time: 26.571s
[2K
| Adam | epoch: 014 | loss: 0.16571 - acc: 0.9458 -- iter: 544/876
[A[ATraining Step: 382  | total loss: [1m[32m0.16997[0m[0m | time: 28.665s
[2K
| Adam | epoch: 014 | loss: 0.16997 - acc: 0.9450 -- iter: 576/876
[A[ATraining Step: 383  | total loss: [1m[32m0.17237[0m[0m | time: 30.736s
[2K
| Adam | epoch: 014 | loss: 0.17237 - acc: 0.9442 -- iter: 608/876
[A[ATraining Step: 384  | total loss: [1m[32m0.16579[0m[0m | time: 32.656s
[2K
| Adam | epoch: 014 | loss: 0.16579 - acc: 0.9467 -- iter: 640/876
[A[ATraining Step: 385  | total loss: [1m[32m0.16068[0m[0m | time: 34.534s
[2K
| Adam | epoch: 014 | loss: 0.16068 - acc: 0.9520 -- iter: 672/876
[A[ATraining Step: 386  | total loss: [1m[32m0.14994[0m[0m | time: 36.395s
[2K
| Adam | epoch: 014 | loss: 0.14994 - acc: 0.9568 -- iter: 704/876
[A[ATraining Step: 387  | total loss: [1m[32m0.14912[0m[0m | time: 37.976s
[2K
| Adam | epoch: 014 | loss: 0.14912 - acc: 0.9518 -- iter: 736/876
[A[ATraining Step: 388  | total loss: [1m[32m0.14057[0m[0m | time: 39.818s
[2K
| Adam | epoch: 014 | loss: 0.14057 - acc: 0.9535 -- iter: 768/876
[A[ATraining Step: 389  | total loss: [1m[32m0.13577[0m[0m | time: 41.457s
[2K
| Adam | epoch: 014 | loss: 0.13577 - acc: 0.9550 -- iter: 800/876
[A[ATraining Step: 390  | total loss: [1m[32m0.14073[0m[0m | time: 43.057s
[2K
| Adam | epoch: 014 | loss: 0.14073 - acc: 0.9501 -- iter: 832/876
[A[ATraining Step: 391  | total loss: [1m[32m0.14728[0m[0m | time: 44.629s
[2K
| Adam | epoch: 014 | loss: 0.14728 - acc: 0.9489 -- iter: 864/876
[A[ATraining Step: 392  | total loss: [1m[32m0.14647[0m[0m | time: 48.832s
[2K
| Adam | epoch: 014 | loss: 0.14647 - acc: 0.9508 | val_loss: 0.31905 - val_acc: 0.8618 -- iter: 876/876
--
Training Step: 393  | total loss: [1m[32m0.13925[0m[0m | time: 2.123s
[2K
| Adam | epoch: 015 | loss: 0.13925 - acc: 0.9558 -- iter: 032/876
[A[ATraining Step: 394  | total loss: [1m[32m0.13638[0m[0m | time: 4.203s
[2K
| Adam | epoch: 015 | loss: 0.13638 - acc: 0.9539 -- iter: 064/876
[A[ATraining Step: 395  | total loss: [1m[32m0.13219[0m[0m | time: 6.096s
[2K
| Adam | epoch: 015 | loss: 0.13219 - acc: 0.9523 -- iter: 096/876
[A[ATraining Step: 396  | total loss: [1m[32m0.12486[0m[0m | time: 8.024s
[2K
| Adam | epoch: 015 | loss: 0.12486 - acc: 0.9571 -- iter: 128/876
[A[ATraining Step: 397  | total loss: [1m[32m0.12254[0m[0m | time: 9.773s
[2K
| Adam | epoch: 015 | loss: 0.12254 - acc: 0.9551 -- iter: 160/876
[A[ATraining Step: 398  | total loss: [1m[32m0.12565[0m[0m | time: 11.652s
[2K
| Adam | epoch: 015 | loss: 0.12565 - acc: 0.9502 -- iter: 192/876
[A[ATraining Step: 399  | total loss: [1m[32m0.13156[0m[0m | time: 13.308s
[2K
| Adam | epoch: 015 | loss: 0.13156 - acc: 0.9458 -- iter: 224/876
[A[ATraining Step: 400  | total loss: [1m[32m0.14246[0m[0m | time: 18.462s
[2K
| Adam | epoch: 015 | loss: 0.14246 - acc: 0.9450 | val_loss: 0.34491 - val_acc: 0.8509 -- iter: 256/876
--
Training Step: 401  | total loss: [1m[32m0.15359[0m[0m | time: 20.188s
[2K
| Adam | epoch: 015 | loss: 0.15359 - acc: 0.9411 -- iter: 288/876
[A[ATraining Step: 402  | total loss: [1m[32m0.14239[0m[0m | time: 21.836s
[2K
| Adam | epoch: 015 | loss: 0.14239 - acc: 0.9470 -- iter: 320/876
[A[ATraining Step: 403  | total loss: [1m[32m0.24262[0m[0m | time: 23.466s
[2K
| Adam | epoch: 015 | loss: 0.24262 - acc: 0.9242 -- iter: 352/876
[A[ATraining Step: 404  | total loss: [1m[32m0.22939[0m[0m | time: 25.559s
[2K
| Adam | epoch: 015 | loss: 0.22939 - acc: 0.9286 -- iter: 384/876
[A[ATraining Step: 405  | total loss: [1m[32m0.20888[0m[0m | time: 26.399s
[2K
| Adam | epoch: 015 | loss: 0.20888 - acc: 0.9358 -- iter: 416/876
[A[ATraining Step: 406  | total loss: [1m[32m0.20260[0m[0m | time: 27.146s
[2K
| Adam | epoch: 015 | loss: 0.20260 - acc: 0.9339 -- iter: 448/876
[A[ATraining Step: 407  | total loss: [1m[32m0.19476[0m[0m | time: 29.021s
[2K
| Adam | epoch: 015 | loss: 0.19476 - acc: 0.9405 -- iter: 480/876
[A[ATraining Step: 408  | total loss: [1m[32m0.17941[0m[0m | time: 30.853s
[2K
| Adam | epoch: 015 | loss: 0.17941 - acc: 0.9464 -- iter: 512/876
[A[ATraining Step: 409  | total loss: [1m[32m0.16620[0m[0m | time: 32.719s
[2K
| Adam | epoch: 015 | loss: 0.16620 - acc: 0.9518 -- iter: 544/876
[A[ATraining Step: 410  | total loss: [1m[32m0.16320[0m[0m | time: 34.245s
[2K
| Adam | epoch: 015 | loss: 0.16320 - acc: 0.9504 -- iter: 576/876
[A[ATraining Step: 411  | total loss: [1m[32m0.15441[0m[0m | time: 35.999s
[2K
| Adam | epoch: 015 | loss: 0.15441 - acc: 0.9522 -- iter: 608/876
[A[ATraining Step: 412  | total loss: [1m[32m0.15769[0m[0m | time: 37.762s
[2K
| Adam | epoch: 015 | loss: 0.15769 - acc: 0.9476 -- iter: 640/876
[A[ATraining Step: 413  | total loss: [1m[32m0.16313[0m[0m | time: 39.247s
[2K
| Adam | epoch: 015 | loss: 0.16313 - acc: 0.9435 -- iter: 672/876
[A[ATraining Step: 414  | total loss: [1m[32m0.15182[0m[0m | time: 40.928s
[2K
| Adam | epoch: 015 | loss: 0.15182 - acc: 0.9491 -- iter: 704/876
[A[ATraining Step: 415  | total loss: [1m[32m0.15242[0m[0m | time: 42.777s
[2K
| Adam | epoch: 015 | loss: 0.15242 - acc: 0.9480 -- iter: 736/876
[A[ATraining Step: 416  | total loss: [1m[32m0.14541[0m[0m | time: 44.759s
[2K
| Adam | epoch: 015 | loss: 0.14541 - acc: 0.9500 -- iter: 768/876
[A[ATraining Step: 417  | total loss: [1m[32m0.13997[0m[0m | time: 46.633s
[2K
| Adam | epoch: 015 | loss: 0.13997 - acc: 0.9550 -- iter: 800/876
[A[ATraining Step: 418  | total loss: [1m[32m0.13256[0m[0m | time: 48.419s
[2K
| Adam | epoch: 015 | loss: 0.13256 - acc: 0.9595 -- iter: 832/876
[A[ATraining Step: 419  | total loss: [1m[32m0.12274[0m[0m | time: 50.443s
[2K
| Adam | epoch: 015 | loss: 0.12274 - acc: 0.9636 -- iter: 864/876
[A[ATraining Step: 420  | total loss: [1m[32m0.11834[0m[0m | time: 55.218s
[2K
| Adam | epoch: 015 | loss: 0.11834 - acc: 0.9641 | val_loss: 0.40607 - val_acc: 0.8618 -- iter: 876/876
--
Validation AUC:0.9491695757960436
Validation AUPRC:0.9594002216654928
Test AUC:0.961460983884648
Test AUPRC:0.9634243558640467
BestTestF1Score	0.9	0.82	0.91	0.91	0.89	117	11	133	14	0.15
BestTestMCCScore	0.9	0.82	0.91	0.91	0.89	117	11	133	14	0.15
BestTestAccuracyScore	0.9	0.82	0.91	0.91	0.89	117	11	133	14	0.15
BestValidationF1Score	0.89	0.79	0.89	0.92	0.87	120	11	126	18	0.15
BestValidationMCC	0.89	0.79	0.89	0.92	0.87	120	11	126	18	0.15
BestValidationAccuracy	0.89	0.79	0.89	0.92	0.87	120	11	126	18	0.15
TestPredictions (Threshold:0.15)
CHEMBL320577,FP,INACT,0.5699999928474426	CHEMBL72841,TN,INACT,0.0	CHEMBL2205710,TP,ACT,0.9100000262260437	CHEMBL3697055,TP,ACT,0.9900000095367432	CHEMBL3697144,TP,ACT,0.46000000834465027	CHEMBL311455,TN,INACT,0.0	CHEMBL249612,TP,ACT,0.9800000190734863	CHEMBL303386,TN,INACT,0.029999999329447746	CHEMBL578192,TP,ACT,0.23999999463558197	CHEMBL404898,TP,ACT,0.9599999785423279	CHEMBL271636,FN,ACT,0.009999999776482582	CHEMBL64124,TN,INACT,0.0	CHEMBL571815,TN,INACT,0.05999999865889549	CHEMBL470436,TP,ACT,0.20000000298023224	CHEMBL3700593,TP,ACT,0.9800000190734863	CHEMBL535602,TN,INACT,0.029999999329447746	CHEMBL398941,TP,ACT,0.9900000095367432	CHEMBL565979,TP,ACT,0.7300000190734863	CHEMBL511976,TP,ACT,0.9900000095367432	CHEMBL3218123,TN,INACT,0.11999999731779099	CHEMBL27065,TN,INACT,0.009999999776482582	CHEMBL2205077,TP,ACT,0.18000000715255737	CHEMBL3116469,TP,ACT,0.9900000095367432	CHEMBL302359,TN,INACT,0.0	CHEMBL1085565,FN,ACT,0.03999999910593033	CHEMBL3697145,TP,ACT,0.41999998688697815	CHEMBL583651,TP,ACT,0.9700000286102295	CHEMBL302196,TN,INACT,0.0	CHEMBL89689,TN,INACT,0.05000000074505806	CHEMBL1223696,TN,INACT,0.0	CHEMBL352925,TN,INACT,0.019999999552965164	CHEMBL1077810,TP,ACT,0.949999988079071	CHEMBL3697123,TP,ACT,0.9900000095367432	CHEMBL43661,TN,INACT,0.10999999940395355	CHEMBL3697166,TP,ACT,0.9599999785423279	CHEMBL141365,TN,INACT,0.0	CHEMBL72738,TN,INACT,0.07000000029802322	CHEMBL230018,TP,ACT,0.6000000238418579	CHEMBL80438,TN,INACT,0.0	CHEMBL272282,TP,ACT,0.17000000178813934	CHEMBL423405,TN,INACT,0.009999999776482582	CHEMBL175228,TN,INACT,0.009999999776482582	CHEMBL2181444,TP,ACT,0.9700000286102295	CHEMBL672,FP,INACT,0.2199999988079071	CHEMBL1808996,TP,ACT,0.5199999809265137	CHEMBL112314,TN,INACT,0.009999999776482582	CHEMBL353304,TN,INACT,0.07000000029802322	CHEMBL298612,TN,INACT,0.009999999776482582	CHEMBL1809037,TP,ACT,0.20000000298023224	CHEMBL76949,TN,INACT,0.009999999776482582	CHEMBL1921862,TP,ACT,0.9800000190734863	CHEMBL231486,TP,ACT,0.9900000095367432	CHEMBL1921865,TP,ACT,0.9900000095367432	CHEMBL319036,TN,INACT,0.009999999776482582	CHEMBL2205692,FN,ACT,0.11999999731779099	CHEMBL568676,TP,ACT,0.49000000953674316	CHEMBL256457,TP,ACT,0.8199999928474426	CHEMBL125925,TN,INACT,0.009999999776482582	CHEMBL1809010,TP,ACT,0.9100000262260437	CHEMBL304950,TN,INACT,0.07000000029802322	CHEMBL111023,TN,INACT,0.0	CHEMBL556506,TN,INACT,0.009999999776482582	CHEMBL249014,TP,ACT,0.4099999964237213	CHEMBL2163921,TN,INACT,0.0	CHEMBL288967,TN,INACT,0.0	CHEMBL1075640,TP,ACT,0.8899999856948853	CHEMBL3665436,TN,INACT,0.14000000059604645	CHEMBL106163,FP,INACT,0.44999998807907104	CHEMBL282426,FP,INACT,0.38999998569488525	CHEMBL608814,TN,INACT,0.009999999776482582	CHEMBL73392,TN,INACT,0.0	CHEMBL78137,TN,INACT,0.05999999865889549	CHEMBL3697141,TP,ACT,0.6800000071525574	CHEMBL3697060,TP,ACT,0.9700000286102295	CHEMBL1921872,TP,ACT,0.800000011920929	CHEMBL2324200,TN,INACT,0.05999999865889549	CHEMBL1921884,TP,ACT,0.9800000190734863	CHEMBL1258999,TN,INACT,0.009999999776482582	CHEMBL441305,TN,INACT,0.029999999329447746	CHEMBL248632,TP,ACT,0.33000001311302185	CHEMBL444542,TP,ACT,0.4000000059604645	CHEMBL148967,TN,INACT,0.009999999776482582	CHEMBL269576,FP,INACT,0.18000000715255737	CHEMBL1809002,TP,ACT,0.9900000095367432	CHEMBL270821,TP,ACT,0.9900000095367432	CHEMBL3697057,TP,ACT,0.9700000286102295	CHEMBL395993,FP,INACT,0.8600000143051147	CHEMBL3697109,TP,ACT,0.9800000190734863	CHEMBL271250,TP,ACT,0.9700000286102295	CHEMBL3697076,TP,ACT,0.9599999785423279	CHEMBL2181461,TP,ACT,0.7900000214576721	CHEMBL2062858,TN,INACT,0.029999999329447746	CHEMBL2181442,TP,ACT,0.6700000166893005	CHEMBL2205059,TP,ACT,0.9700000286102295	CHEMBL10309,FN,ACT,0.05999999865889549	CHEMBL3323005,TN,INACT,0.009999999776482582	CHEMBL3697125,TP,ACT,0.9599999785423279	CHEMBL2436717,TN,INACT,0.0	CHEMBL3697075,TP,ACT,0.9800000190734863	CHEMBL45875,TN,INACT,0.0	CHEMBL302038,TN,INACT,0.029999999329447746	CHEMBL2205712,TP,ACT,0.8899999856948853	CHEMBL1939559,TP,ACT,0.5199999809265137	CHEMBL114478,TN,INACT,0.009999999776482582	CHEMBL552615,TN,INACT,0.009999999776482582	CHEMBL3116493,TP,ACT,0.9700000286102295	CHEMBL470390,TP,ACT,0.8399999737739563	CHEMBL1809027,TP,ACT,0.9900000095367432	CHEMBL429238,TN,INACT,0.0	CHEMBL3116488,TP,ACT,0.9100000262260437	CHEMBL2205058,TP,ACT,0.699999988079071	CHEMBL1077823,TP,ACT,0.4399999976158142	CHEMBL1077830,FN,ACT,0.009999999776482582	CHEMBL578188,TP,ACT,0.6700000166893005	CHEMBL231588,TP,ACT,0.5799999833106995	CHEMBL2436719,TN,INACT,0.009999999776482582	CHEMBL172788,TN,INACT,0.05000000074505806	CHEMBL140495,TN,INACT,0.0	CHEMBL2205706,TP,ACT,0.9300000071525574	CHEMBL21937,TN,INACT,0.009999999776482582	CHEMBL1921888,TP,ACT,0.9800000190734863	CHEMBL78668,TN,INACT,0.019999999552965164	CHEMBL1077818,TP,ACT,0.9900000095367432	CHEMBL471654,FN,ACT,0.009999999776482582	CHEMBL453822,FP,INACT,0.38999998569488525	CHEMBL3786144,TP,ACT,0.6399999856948853	CHEMBL374602,TN,INACT,0.009999999776482582	CHEMBL167032,TN,INACT,0.0	CHEMBL88937,TN,INACT,0.0	CHEMBL15675,TN,INACT,0.009999999776482582	CHEMBL91362,TN,INACT,0.019999999552965164	CHEMBL259131,TN,INACT,0.0	CHEMBL3697048,TP,ACT,0.9599999785423279	CHEMBL330674,TN,INACT,0.029999999329447746	CHEMBL421523,TN,INACT,0.009999999776482582	CHEMBL103731,TN,INACT,0.029999999329447746	CHEMBL3786864,FN,ACT,0.009999999776482582	CHEMBL390842,TN,INACT,0.009999999776482582	CHEMBL162095,TN,INACT,0.0	CHEMBL241082,FP,INACT,0.5299999713897705	CHEMBL434674,TN,INACT,0.0	CHEMBL3697152,TP,ACT,0.8899999856948853	CHEMBL565559,TP,ACT,0.2199999988079071	CHEMBL197368,TP,ACT,0.8500000238418579	CHEMBL43788,TN,INACT,0.0	CHEMBL45269,TN,INACT,0.0	CHEMBL40986,TN,INACT,0.0	CHEMBL2181460,TP,ACT,0.8999999761581421	CHEMBL266663,TP,ACT,0.9700000286102295	CHEMBL2205702,FN,ACT,0.07999999821186066	CHEMBL3393993,TN,INACT,0.009999999776482582	CHEMBL109778,TN,INACT,0.0	CHEMBL250483,TP,ACT,0.9900000095367432	CHEMBL270591,TP,ACT,0.9900000095367432	CHEMBL303203,TN,INACT,0.0	CHEMBL1939692,TP,ACT,0.8899999856948853	CHEMBL579195,TP,ACT,0.8899999856948853	CHEMBL3697160,TP,ACT,0.9800000190734863	CHEMBL160932,TN,INACT,0.009999999776482582	CHEMBL149763,TN,INACT,0.0	CHEMBL128360,TN,INACT,0.0	CHEMBL3700584,TP,ACT,0.8999999761581421	CHEMBL7505,TN,INACT,0.009999999776482582	CHEMBL324652,TN,INACT,0.0	CHEMBL295207,TN,INACT,0.0	CHEMBL110695,TN,INACT,0.009999999776482582	CHEMBL2205693,TP,ACT,0.5600000023841858	CHEMBL147238,TN,INACT,0.0	CHEMBL423260,TN,INACT,0.0	CHEMBL233501,TN,INACT,0.009999999776482582	CHEMBL2181441,TP,ACT,0.9900000095367432	CHEMBL3697093,TP,ACT,0.9900000095367432	CHEMBL400719,TP,ACT,0.9900000095367432	CHEMBL3335535,TN,INACT,0.019999999552965164	CHEMBL169553,TN,INACT,0.009999999776482582	CHEMBL48031,TN,INACT,0.0	CHEMBL251039,TP,ACT,0.800000011920929	CHEMBL2205076,TP,ACT,0.30000001192092896	CHEMBL323245,TN,INACT,0.009999999776482582	CHEMBL633,TN,INACT,0.07000000029802322	CHEMBL2205721,TP,ACT,0.9100000262260437	CHEMBL2443003,TN,INACT,0.009999999776482582	CHEMBL331394,TN,INACT,0.029999999329447746	CHEMBL1809013,TP,ACT,0.9800000190734863	CHEMBL1907665,TN,INACT,0.0	CHEMBL472484,TP,ACT,0.3799999952316284	CHEMBL230344,TP,ACT,0.9399999976158142	CHEMBL422701,TN,INACT,0.07000000029802322	CHEMBL3697139,TP,ACT,0.6299999952316284	CHEMBL514606,TN,INACT,0.0	CHEMBL587013,TP,ACT,0.3199999928474426	CHEMBL437776,TP,ACT,0.27000001072883606	CHEMBL230343,TP,ACT,0.9700000286102295	CHEMBL231487,FN,ACT,0.019999999552965164	CHEMBL3697124,TP,ACT,0.9900000095367432	CHEMBL3700582,TP,ACT,0.9900000095367432	CHEMBL3697052,TP,ACT,0.9900000095367432	CHEMBL3350741,TN,INACT,0.07000000029802322	CHEMBL3116492,TP,ACT,0.9599999785423279	CHEMBL78601,TN,INACT,0.009999999776482582	CHEMBL109206,TN,INACT,0.0	CHEMBL19808,TN,INACT,0.019999999552965164	CHEMBL3697089,TP,ACT,0.949999988079071	CHEMBL89953,TN,INACT,0.03999999910593033	CHEMBL1170027,TN,INACT,0.009999999776482582	CHEMBL40796,TN,INACT,0.0	CHEMBL3697080,TP,ACT,0.9900000095367432	CHEMBL166089,TN,INACT,0.0	CHEMBL98014,TN,INACT,0.11999999731779099	CHEMBL104172,TN,INACT,0.0	CHEMBL2062854,TN,INACT,0.009999999776482582	CHEMBL446693,FP,INACT,0.4099999964237213	CHEMBL64043,TN,INACT,0.019999999552965164	CHEMBL1923416,FP,INACT,0.23999999463558197	CHEMBL241514,TN,INACT,0.019999999552965164	CHEMBL39879,TN,INACT,0.0	CHEMBL108417,TN,INACT,0.009999999776482582	CHEMBL272873,TN,INACT,0.0	CHEMBL374820,TP,ACT,0.8100000023841858	CHEMBL62660,TN,INACT,0.0	CHEMBL353502,TN,INACT,0.0	CHEMBL470431,FN,ACT,0.009999999776482582	CHEMBL1091790,TN,INACT,0.0	CHEMBL1809001,TP,ACT,0.9599999785423279	CHEMBL233957,TN,INACT,0.009999999776482582	CHEMBL3697148,FN,ACT,0.019999999552965164	CHEMBL62703,TN,INACT,0.03999999910593033	CHEMBL1765667,TN,INACT,0.009999999776482582	CHEMBL403001,FN,ACT,0.009999999776482582	CHEMBL403254,TP,ACT,0.9599999785423279	CHEMBL422411,TN,INACT,0.019999999552965164	CHEMBL2181463,TP,ACT,0.9300000071525574	CHEMBL2181454,TP,ACT,0.8899999856948853	CHEMBL2205694,TP,ACT,0.8899999856948853	CHEMBL73164,TN,INACT,0.0	CHEMBL169675,TN,INACT,0.0	CHEMBL393675,TN,INACT,0.0	CHEMBL3697165,TP,ACT,0.9800000190734863	CHEMBL168855,TN,INACT,0.009999999776482582	CHEMBL272558,FN,ACT,0.009999999776482582	CHEMBL308414,TN,INACT,0.0	CHEMBL3697112,TP,ACT,0.9900000095367432	CHEMBL452150,TN,INACT,0.019999999552965164	CHEMBL11262,TN,INACT,0.009999999776482582	CHEMBL1939557,TP,ACT,0.9900000095367432	CHEMBL240888,TN,INACT,0.0	CHEMBL3697163,TP,ACT,0.9900000095367432	CHEMBL1078642,TN,INACT,0.0	CHEMBL2163919,TN,INACT,0.009999999776482582	CHEMBL575049,TP,ACT,0.9900000095367432	CHEMBL402855,FN,ACT,0.019999999552965164	CHEMBL143304,TN,INACT,0.009999999776482582	CHEMBL1939553,TP,ACT,0.9900000095367432	CHEMBL60401,TN,INACT,0.0	CHEMBL168632,TN,INACT,0.009999999776482582	CHEMBL595265,TN,INACT,0.0	CHEMBL312670,TN,INACT,0.0	CHEMBL3697100,TP,ACT,0.8999999761581421	CHEMBL315096,TN,INACT,0.07000000029802322	CHEMBL1939554,TP,ACT,0.9599999785423279	CHEMBL320569,TN,INACT,0.0	CHEMBL275481,TN,INACT,0.0	CHEMBL310361,TN,INACT,0.0	CHEMBL3697083,TP,ACT,0.9599999785423279	CHEMBL143539,TN,INACT,0.05999999865889549	CHEMBL374821,TP,ACT,0.800000011920929	CHEMBL3116476,TP,ACT,1.0	CHEMBL402375,TP,ACT,0.27000001072883606	CHEMBL257038,TP,ACT,0.5199999809265137	CHEMBL3116497,TP,ACT,0.9900000095367432	CHEMBL296245,FP,INACT,0.2800000011920929	CHEMBL89445,TN,INACT,0.0	CHEMBL573022,TP,ACT,0.9900000095367432	CHEMBL1809029,TP,ACT,0.9800000190734863	CHEMBL403906,TP,ACT,0.17000000178813934	

