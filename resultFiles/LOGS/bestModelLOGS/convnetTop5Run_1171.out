ImageNetInceptionV2 CHEMBL2938 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	181
Number of inactive compounds :	181
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2938_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2938_adam_0.001_15_0.8/
---------------------------------
Training samples: 184
Validation samples: 58
--
Training Step: 1  | time: 37.143s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/184
[A[ATraining Step: 2  | total loss: [1m[32m0.67893[0m[0m | time: 45.040s
[2K
| Adam | epoch: 001 | loss: 0.67893 - acc: 0.4500 -- iter: 064/184
[A[ATraining Step: 3  | total loss: [1m[32m0.57178[0m[0m | time: 52.934s
[2K
| Adam | epoch: 001 | loss: 0.57178 - acc: 0.6443 -- iter: 096/184
[A[ATraining Step: 4  | total loss: [1m[32m0.93284[0m[0m | time: 61.071s
[2K
| Adam | epoch: 001 | loss: 0.93284 - acc: 0.5830 -- iter: 128/184
[A[ATraining Step: 5  | total loss: [1m[32m0.83594[0m[0m | time: 68.893s
[2K
| Adam | epoch: 001 | loss: 0.83594 - acc: 0.6553 -- iter: 160/184
[A[ATraining Step: 6  | total loss: [1m[32m0.65061[0m[0m | time: 83.636s
[2K
| Adam | epoch: 001 | loss: 0.65061 - acc: 0.6961 | val_loss: 2.32716 - val_acc: 0.6379 -- iter: 184/184
--
Training Step: 7  | total loss: [1m[32m0.63467[0m[0m | time: 6.398s
[2K
| Adam | epoch: 002 | loss: 0.63467 - acc: 0.7534 -- iter: 032/184
[A[ATraining Step: 8  | total loss: [1m[32m0.49896[0m[0m | time: 14.355s
[2K
| Adam | epoch: 002 | loss: 0.49896 - acc: 0.8453 -- iter: 064/184
[A[ATraining Step: 9  | total loss: [1m[32m0.44558[0m[0m | time: 22.244s
[2K
| Adam | epoch: 002 | loss: 0.44558 - acc: 0.8610 -- iter: 096/184
[A[ATraining Step: 10  | total loss: [1m[32m0.38626[0m[0m | time: 30.098s
[2K
| Adam | epoch: 002 | loss: 0.38626 - acc: 0.8680 -- iter: 128/184
[A[ATraining Step: 11  | total loss: [1m[32m0.31767[0m[0m | time: 37.908s
[2K
| Adam | epoch: 002 | loss: 0.31767 - acc: 0.8713 -- iter: 160/184
[A[ATraining Step: 12  | total loss: [1m[32m0.29144[0m[0m | time: 48.344s
[2K
| Adam | epoch: 002 | loss: 0.29144 - acc: 0.8870 | val_loss: 1.93489 - val_acc: 0.6379 -- iter: 184/184
--
Training Step: 13  | total loss: [1m[32m0.26553[0m[0m | time: 6.370s
[2K
| Adam | epoch: 003 | loss: 0.26553 - acc: 0.9087 -- iter: 032/184
[A[ATraining Step: 14  | total loss: [1m[32m0.26967[0m[0m | time: 12.647s
[2K
| Adam | epoch: 003 | loss: 0.26967 - acc: 0.9119 -- iter: 064/184
[A[ATraining Step: 15  | total loss: [1m[32m0.18660[0m[0m | time: 20.637s
[2K
| Adam | epoch: 003 | loss: 0.18660 - acc: 0.9464 -- iter: 096/184
[A[ATraining Step: 16  | total loss: [1m[32m0.33101[0m[0m | time: 28.506s
[2K
| Adam | epoch: 003 | loss: 0.33101 - acc: 0.8962 -- iter: 128/184
[A[ATraining Step: 17  | total loss: [1m[32m0.28161[0m[0m | time: 36.477s
[2K
| Adam | epoch: 003 | loss: 0.28161 - acc: 0.9223 -- iter: 160/184
[A[ATraining Step: 18  | total loss: [1m[32m0.22053[0m[0m | time: 46.867s
[2K
| Adam | epoch: 003 | loss: 0.22053 - acc: 0.9384 | val_loss: 1.28185 - val_acc: 0.6379 -- iter: 184/184
--
Training Step: 19  | total loss: [1m[32m0.22053[0m[0m | time: 8.044s
[2K
| Adam | epoch: 004 | loss: 0.22053 - acc: 0.9068 -- iter: 032/184
[A[ATraining Step: 20  | total loss: [1m[32m0.17995[0m[0m | time: 14.273s
[2K
| Adam | epoch: 004 | loss: 0.17995 - acc: 0.9368 -- iter: 064/184
[A[ATraining Step: 21  | total loss: [1m[32m0.21720[0m[0m | time: 20.599s
[2K
| Adam | epoch: 004 | loss: 0.21720 - acc: 0.9305 -- iter: 096/184
[A[ATraining Step: 22  | total loss: [1m[32m0.18619[0m[0m | time: 28.472s
[2K
| Adam | epoch: 004 | loss: 0.18619 - acc: 0.9389 -- iter: 128/184
[A[ATraining Step: 23  | total loss: [1m[32m0.20988[0m[0m | time: 36.256s
[2K
| Adam | epoch: 004 | loss: 0.20988 - acc: 0.9022 -- iter: 160/184
[A[ATraining Step: 24  | total loss: [1m[32m0.20712[0m[0m | time: 46.758s
[2K
| Adam | epoch: 004 | loss: 0.20712 - acc: 0.9209 | val_loss: 2.23966 - val_acc: 0.6379 -- iter: 184/184
--
Training Step: 25  | total loss: [1m[32m0.20034[0m[0m | time: 7.969s
[2K
| Adam | epoch: 005 | loss: 0.20034 - acc: 0.9254 -- iter: 032/184
[A[ATraining Step: 26  | total loss: [1m[32m0.16451[0m[0m | time: 15.826s
[2K
| Adam | epoch: 005 | loss: 0.16451 - acc: 0.9452 -- iter: 064/184
[A[ATraining Step: 27  | total loss: [1m[32m0.20943[0m[0m | time: 22.087s
[2K
| Adam | epoch: 005 | loss: 0.20943 - acc: 0.9191 -- iter: 096/184
[A[ATraining Step: 28  | total loss: [1m[32m0.17123[0m[0m | time: 28.370s
[2K
| Adam | epoch: 005 | loss: 0.17123 - acc: 0.9393 -- iter: 128/184
[A[ATraining Step: 29  | total loss: [1m[32m0.13630[0m[0m | time: 36.146s
[2K
| Adam | epoch: 005 | loss: 0.13630 - acc: 0.9541 -- iter: 160/184
[A[ATraining Step: 30  | total loss: [1m[32m0.12603[0m[0m | time: 46.590s
[2K
| Adam | epoch: 005 | loss: 0.12603 - acc: 0.9576 | val_loss: 2.07856 - val_acc: 0.6379 -- iter: 184/184
--
Training Step: 31  | total loss: [1m[32m0.11654[0m[0m | time: 7.828s
[2K
| Adam | epoch: 006 | loss: 0.11654 - acc: 0.9601 -- iter: 032/184
[A[ATraining Step: 32  | total loss: [1m[32m0.11001[0m[0m | time: 15.492s
[2K
| Adam | epoch: 006 | loss: 0.11001 - acc: 0.9621 -- iter: 064/184
[A[ATraining Step: 33  | total loss: [1m[32m0.09467[0m[0m | time: 23.342s
[2K
| Adam | epoch: 006 | loss: 0.09467 - acc: 0.9635 -- iter: 096/184
[A[ATraining Step: 34  | total loss: [1m[32m0.07935[0m[0m | time: 29.556s
[2K
| Adam | epoch: 006 | loss: 0.07935 - acc: 0.9714 -- iter: 128/184
[A[ATraining Step: 35  | total loss: [1m[32m0.08930[0m[0m | time: 35.759s
[2K
| Adam | epoch: 006 | loss: 0.08930 - acc: 0.9686 -- iter: 160/184
[A[ATraining Step: 36  | total loss: [1m[32m0.08276[0m[0m | time: 46.162s
[2K
| Adam | epoch: 006 | loss: 0.08276 - acc: 0.9750 | val_loss: 0.70963 - val_acc: 0.6379 -- iter: 184/184
--
Training Step: 37  | total loss: [1m[32m0.08050[0m[0m | time: 7.882s
[2K
| Adam | epoch: 007 | loss: 0.08050 - acc: 0.9738 -- iter: 032/184
[A[ATraining Step: 38  | total loss: [1m[32m0.11952[0m[0m | time: 15.657s
[2K
| Adam | epoch: 007 | loss: 0.11952 - acc: 0.9728 -- iter: 064/184
[A[ATraining Step: 39  | total loss: [1m[32m0.10964[0m[0m | time: 23.392s
[2K
| Adam | epoch: 007 | loss: 0.10964 - acc: 0.9720 -- iter: 096/184
[A[ATraining Step: 40  | total loss: [1m[32m0.09025[0m[0m | time: 31.251s
[2K
| Adam | epoch: 007 | loss: 0.09025 - acc: 0.9773 -- iter: 128/184
[A[ATraining Step: 41  | total loss: [1m[32m0.07751[0m[0m | time: 37.557s
[2K
| Adam | epoch: 007 | loss: 0.07751 - acc: 0.9814 -- iter: 160/184
[A[ATraining Step: 42  | total loss: [1m[32m0.13850[0m[0m | time: 46.476s
[2K
| Adam | epoch: 007 | loss: 0.13850 - acc: 0.9698 | val_loss: 1.30342 - val_acc: 0.5862 -- iter: 184/184
--
Training Step: 43  | total loss: [1m[32m0.13258[0m[0m | time: 8.051s
[2K
| Adam | epoch: 008 | loss: 0.13258 - acc: 0.9678 -- iter: 032/184
[A[ATraining Step: 44  | total loss: [1m[32m0.15428[0m[0m | time: 18.145s
[2K
| Adam | epoch: 008 | loss: 0.15428 - acc: 0.9571 -- iter: 064/184
[A[ATraining Step: 45  | total loss: [1m[32m0.23009[0m[0m | time: 30.084s
[2K
| Adam | epoch: 008 | loss: 0.23009 - acc: 0.9485 -- iter: 096/184
[A[ATraining Step: 46  | total loss: [1m[32m0.21547[0m[0m | time: 42.953s
[2K
| Adam | epoch: 008 | loss: 0.21547 - acc: 0.9519 -- iter: 128/184
[A[ATraining Step: 47  | total loss: [1m[32m0.19703[0m[0m | time: 55.982s
[2K
| Adam | epoch: 008 | loss: 0.19703 - acc: 0.9546 -- iter: 160/184
[A[ATraining Step: 48  | total loss: [1m[32m0.24756[0m[0m | time: 70.537s
[2K
| Adam | epoch: 008 | loss: 0.24756 - acc: 0.9468 | val_loss: 0.90054 - val_acc: 0.7241 -- iter: 184/184
--
Training Step: 49  | total loss: [1m[32m0.26085[0m[0m | time: 10.474s
[2K
| Adam | epoch: 009 | loss: 0.26085 - acc: 0.9289 -- iter: 032/184
[A[ATraining Step: 50  | total loss: [1m[32m0.24343[0m[0m | time: 23.775s
[2K
| Adam | epoch: 009 | loss: 0.24343 - acc: 0.9335 -- iter: 064/184
[A[ATraining Step: 51  | total loss: [1m[32m0.21700[0m[0m | time: 36.676s
[2K
| Adam | epoch: 009 | loss: 0.21700 - acc: 0.9436 -- iter: 096/184
[A[ATraining Step: 52  | total loss: [1m[32m0.21260[0m[0m | time: 48.576s
[2K
| Adam | epoch: 009 | loss: 0.21260 - acc: 0.9474 -- iter: 128/184
[A[ATraining Step: 53  | total loss: [1m[32m0.20007[0m[0m | time: 56.756s
[2K
| Adam | epoch: 009 | loss: 0.20007 - acc: 0.9506 -- iter: 160/184
[A[ATraining Step: 54  | total loss: [1m[32m0.18042[0m[0m | time: 71.144s
[2K
| Adam | epoch: 009 | loss: 0.18042 - acc: 0.9577 | val_loss: 0.46363 - val_acc: 0.8793 -- iter: 184/184
--
Training Step: 55  | total loss: [1m[32m0.17023[0m[0m | time: 9.967s
[2K
| Adam | epoch: 010 | loss: 0.17023 - acc: 0.9593 -- iter: 032/184
[A[ATraining Step: 56  | total loss: [1m[32m0.15168[0m[0m | time: 20.309s
[2K
| Adam | epoch: 010 | loss: 0.15168 - acc: 0.9650 -- iter: 064/184
[A[ATraining Step: 57  | total loss: [1m[32m0.13593[0m[0m | time: 33.345s
[2K
| Adam | epoch: 010 | loss: 0.13593 - acc: 0.9699 -- iter: 096/184
[A[ATraining Step: 58  | total loss: [1m[32m0.14024[0m[0m | time: 46.648s
[2K
| Adam | epoch: 010 | loss: 0.14024 - acc: 0.9697 -- iter: 128/184
[A[ATraining Step: 59  | total loss: [1m[32m0.14343[0m[0m | time: 60.033s
[2K
| Adam | epoch: 010 | loss: 0.14343 - acc: 0.9696 -- iter: 160/184
[A[ATraining Step: 60  | total loss: [1m[32m0.12876[0m[0m | time: 78.395s
[2K
| Adam | epoch: 010 | loss: 0.12876 - acc: 0.9736 | val_loss: 0.74639 - val_acc: 0.6724 -- iter: 184/184
--
Training Step: 61  | total loss: [1m[32m0.12449[0m[0m | time: 38.205s
[2K
| Adam | epoch: 011 | loss: 0.12449 - acc: 0.9730 -- iter: 032/184
[A[ATraining Step: 62  | total loss: [1m[32m0.12185[0m[0m | time: 48.737s
[2K
| Adam | epoch: 011 | loss: 0.12185 - acc: 0.9684 -- iter: 064/184
[A[ATraining Step: 63  | total loss: [1m[32m0.11150[0m[0m | time: 59.118s
[2K
| Adam | epoch: 011 | loss: 0.11150 - acc: 0.9724 -- iter: 096/184
[A[ATraining Step: 64  | total loss: [1m[32m0.10116[0m[0m | time: 72.566s
[2K
| Adam | epoch: 011 | loss: 0.10116 - acc: 0.9759 -- iter: 128/184
[A[ATraining Step: 65  | total loss: [1m[32m0.09075[0m[0m | time: 80.989s
[2K
| Adam | epoch: 011 | loss: 0.09075 - acc: 0.9788 -- iter: 160/184
[A[ATraining Step: 66  | total loss: [1m[32m0.08216[0m[0m | time: 91.466s
[2K
| Adam | epoch: 011 | loss: 0.08216 - acc: 0.9814 | val_loss: 1.23584 - val_acc: 0.4655 -- iter: 184/184
--
Training Step: 67  | total loss: [1m[32m0.07555[0m[0m | time: 13.169s
[2K
| Adam | epoch: 012 | loss: 0.07555 - acc: 0.9836 -- iter: 032/184
[A[ATraining Step: 68  | total loss: [1m[32m0.07384[0m[0m | time: 26.054s
[2K
| Adam | epoch: 012 | loss: 0.07384 - acc: 0.9819 -- iter: 064/184
[A[ATraining Step: 69  | total loss: [1m[32m0.09444[0m[0m | time: 36.519s
[2K
| Adam | epoch: 012 | loss: 0.09444 - acc: 0.9767 -- iter: 096/184
[A[ATraining Step: 70  | total loss: [1m[32m0.08519[0m[0m | time: 46.724s
[2K
| Adam | epoch: 012 | loss: 0.08519 - acc: 0.9794 -- iter: 128/184
[A[ATraining Step: 71  | total loss: [1m[32m0.07682[0m[0m | time: 59.713s
[2K
| Adam | epoch: 012 | loss: 0.07682 - acc: 0.9817 -- iter: 160/184
[A[ATraining Step: 72  | total loss: [1m[32m0.07150[0m[0m | time: 77.023s
[2K
| Adam | epoch: 012 | loss: 0.07150 - acc: 0.9838 | val_loss: 0.43801 - val_acc: 0.8621 -- iter: 184/184
--
Training Step: 73  | total loss: [1m[32m0.13779[0m[0m | time: 14.105s
[2K
| Adam | epoch: 013 | loss: 0.13779 - acc: 0.9717 -- iter: 032/184
[A[ATraining Step: 74  | total loss: [1m[32m0.12766[0m[0m | time: 24.511s
[2K
| Adam | epoch: 013 | loss: 0.12766 - acc: 0.9748 -- iter: 064/184
[A[ATraining Step: 75  | total loss: [1m[32m0.11856[0m[0m | time: 32.474s
[2K
| Adam | epoch: 013 | loss: 0.11856 - acc: 0.9775 -- iter: 096/184
[A[ATraining Step: 76  | total loss: [1m[32m0.11044[0m[0m | time: 38.787s
[2K
| Adam | epoch: 013 | loss: 0.11044 - acc: 0.9799 -- iter: 128/184
[A[ATraining Step: 77  | total loss: [1m[32m0.11917[0m[0m | time: 45.483s
[2K
| Adam | epoch: 013 | loss: 0.11917 - acc: 0.9777 -- iter: 160/184
[A[ATraining Step: 78  | total loss: [1m[32m0.11103[0m[0m | time: 89.304s
[2K
| Adam | epoch: 013 | loss: 0.11103 - acc: 0.9800 | val_loss: 7.89011 - val_acc: 0.3966 -- iter: 184/184
--
Training Step: 79  | total loss: [1m[32m0.10260[0m[0m | time: 13.054s
[2K
| Adam | epoch: 014 | loss: 0.10260 - acc: 0.9821 -- iter: 032/184
[A[ATraining Step: 80  | total loss: [1m[32m0.11757[0m[0m | time: 26.156s
[2K
| Adam | epoch: 014 | loss: 0.11757 - acc: 0.9775 -- iter: 064/184
[A[ATraining Step: 81  | total loss: [1m[32m0.11701[0m[0m | time: 39.030s
[2K
| Adam | epoch: 014 | loss: 0.11701 - acc: 0.9766 -- iter: 096/184
[A[ATraining Step: 82  | total loss: [1m[32m0.10881[0m[0m | time: 52.052s
[2K
| Adam | epoch: 014 | loss: 0.10881 - acc: 0.9790 -- iter: 128/184
[A[ATraining Step: 83  | total loss: [1m[32m0.10215[0m[0m | time: 62.553s
[2K
| Adam | epoch: 014 | loss: 0.10215 - acc: 0.9811 -- iter: 160/184
[A[ATraining Step: 84  | total loss: [1m[32m0.12255[0m[0m | time: 77.719s
[2K
| Adam | epoch: 014 | loss: 0.12255 - acc: 0.9746 | val_loss: 13.52597 - val_acc: 0.3793 -- iter: 184/184
--
Training Step: 85  | total loss: [1m[32m0.13037[0m[0m | time: 8.024s
[2K
| Adam | epoch: 015 | loss: 0.13037 - acc: 0.9688 -- iter: 032/184
[A[ATraining Step: 86  | total loss: [1m[32m0.12129[0m[0m | time: 15.882s
[2K
| Adam | epoch: 015 | loss: 0.12129 - acc: 0.9719 -- iter: 064/184
[A[ATraining Step: 87  | total loss: [1m[32m0.11451[0m[0m | time: 25.476s
[2K
| Adam | epoch: 015 | loss: 0.11451 - acc: 0.9716 -- iter: 096/184
[A[ATraining Step: 88  | total loss: [1m[32m0.10846[0m[0m | time: 38.091s
[2K
| Adam | epoch: 015 | loss: 0.10846 - acc: 0.9713 -- iter: 128/184
[A[ATraining Step: 89  | total loss: [1m[32m0.10141[0m[0m | time: 50.623s
[2K
| Adam | epoch: 015 | loss: 0.10141 - acc: 0.9742 -- iter: 160/184
[A[ATraining Step: 90  | total loss: [1m[32m0.09668[0m[0m | time: 67.109s
[2K
| Adam | epoch: 015 | loss: 0.09668 - acc: 0.9768 | val_loss: 1.44830 - val_acc: 0.7069 -- iter: 184/184
--
Validation AUC:0.9472329472329473
Validation AUPRC:0.9041177012451713
Test AUC:0.9754901960784313
Test AUPRC:0.9666535774147603
BestTestF1Score	0.89	0.81	0.9	0.8	1.0	24	6	28	0	0.99
BestTestMCCScore	0.89	0.81	0.9	0.8	1.0	24	6	28	0	0.99
BestTestAccuracyScore	0.86	0.76	0.88	0.81	0.92	22	5	29	2	1.0
BestValidationF1Score	0.85	0.76	0.88	0.77	0.95	20	6	31	1	0.99
BestValidationMCC	0.85	0.76	0.88	0.77	0.95	20	6	31	1	0.99
BestValidationAccuracy	0.84	0.75	0.88	0.79	0.9	19	5	32	2	1.0
TestPredictions (Threshold:0.99)
CHEMBL1081198,FP,INACT,1.0	CHEMBL53596,TP,ACT,1.0	CHEMBL498248,TN,INACT,0.5600000023841858	CHEMBL1258117,TP,ACT,1.0	CHEMBL512658,TN,INACT,0.07999999821186066	CHEMBL482919,FP,INACT,1.0	CHEMBL359486,TP,ACT,1.0	CHEMBL490053,TN,INACT,0.1599999964237213	CHEMBL562198,TN,INACT,0.6800000071525574	CHEMBL1922122,TN,INACT,0.5899999737739563	CHEMBL422056,TP,ACT,1.0	CHEMBL306883,TP,ACT,1.0	CHEMBL498249,FP,INACT,1.0	CHEMBL360304,TP,ACT,1.0	CHEMBL606245,FP,INACT,0.9900000095367432	CHEMBL456378,TN,INACT,0.9599999785423279	CHEMBL2392236,TN,INACT,0.019999999552965164	CHEMBL458076,TN,INACT,0.9599999785423279	CHEMBL549792,TN,INACT,0.6800000071525574	CHEMBL552136,TN,INACT,0.12999999523162842	CHEMBL301860,TP,ACT,1.0	CHEMBL2392355,TN,INACT,0.009999999776482582	CHEMBL28205,TP,ACT,0.9900000095367432	CHEMBL423323,TP,ACT,1.0	CHEMBL311399,TP,ACT,1.0	CHEMBL456760,TN,INACT,0.20000000298023224	CHEMBL2392235,TN,INACT,0.019999999552965164	CHEMBL421217,TP,ACT,0.9900000095367432	CHEMBL523938,TN,INACT,0.8999999761581421	CHEMBL368193,TP,ACT,1.0	CHEMBL1331525,TN,INACT,0.4099999964237213	CHEMBL2392238,TN,INACT,0.17000000178813934	CHEMBL76537,TP,ACT,1.0	CHEMBL242753,TP,ACT,1.0	CHEMBL67788,TP,ACT,1.0	CHEMBL457390,TN,INACT,0.6800000071525574	CHEMBL2392227,TN,INACT,0.019999999552965164	CHEMBL150264,TP,ACT,1.0	CHEMBL439996,TP,ACT,1.0	CHEMBL2392237,TN,INACT,0.019999999552965164	CHEMBL3421968,FP,INACT,1.0	CHEMBL59677,TP,ACT,1.0	CHEMBL1910753,FP,INACT,1.0	CHEMBL318188,TN,INACT,0.5299999713897705	CHEMBL456964,TN,INACT,0.41999998688697815	CHEMBL48636,TP,ACT,1.0	CHEMBL563733,TN,INACT,0.8100000023841858	CHEMBL3609564,TN,INACT,0.7699999809265137	CHEMBL559882,TN,INACT,0.17000000178813934	CHEMBL441802,TP,ACT,1.0	CHEMBL307747,TP,ACT,1.0	CHEMBL48988,TP,ACT,1.0	CHEMBL294037,TN,INACT,0.9200000166893005	CHEMBL306884,TP,ACT,1.0	CHEMBL2392246,TN,INACT,0.009999999776482582	CHEMBL151731,TP,ACT,1.0	CHEMBL102622,TN,INACT,0.05999999865889549	CHEMBL1436125,TN,INACT,0.10999999940395355	

