ImageNetInceptionV2 CHEMBL302 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	1393
Number of inactive compounds :	1393
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL302_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL302_adam_0.0001_15_0.8/
---------------------------------
Training samples: 1779
Validation samples: 557
--
Training Step: 1  | time: 120.797s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1779
[A[ATraining Step: 2  | total loss: [1m[32m0.66845[0m[0m | time: 458.482s
[2K
| Adam | epoch: 001 | loss: 0.66845 - acc: 0.4500 -- iter: 0064/1779
[A[ATraining Step: 3  | total loss: [1m[32m0.69483[0m[0m | time: 743.296s
[2K
| Adam | epoch: 001 | loss: 0.69483 - acc: 0.5676 -- iter: 0096/1779
[A[ATraining Step: 4  | total loss: [1m[32m0.64900[0m[0m | time: 892.345s
[2K
| Adam | epoch: 001 | loss: 0.64900 - acc: 0.6341 -- iter: 0128/1779
[A[ATraining Step: 5  | total loss: [1m[32m0.64401[0m[0m | time: 1216.013s
[2K
| Adam | epoch: 001 | loss: 0.64401 - acc: 0.6711 -- iter: 0160/1779
[A[ATraining Step: 6  | total loss: [1m[32m0.66650[0m[0m | time: 1227.933s
[2K
| Adam | epoch: 001 | loss: 0.66650 - acc: 0.6615 -- iter: 0192/1779
[A[ATraining Step: 7  | total loss: [1m[32m0.67052[0m[0m | time: 1291.946s
[2K
| Adam | epoch: 001 | loss: 0.67052 - acc: 0.6021 -- iter: 0224/1779
[A[ATraining Step: 8  | total loss: [1m[32m0.65330[0m[0m | time: 1405.843s
[2K
| Adam | epoch: 001 | loss: 0.65330 - acc: 0.6150 -- iter: 0256/1779
[A[ATraining Step: 9  | total loss: [1m[32m0.69337[0m[0m | time: 1484.311s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.5376 -- iter: 0288/1779
[A[ATraining Step: 10  | total loss: [1m[32m0.70414[0m[0m | time: 1757.294s
[2K
| Adam | epoch: 001 | loss: 0.70414 - acc: 0.5344 -- iter: 0320/1779
[A[ATraining Step: 11  | total loss: [1m[32m0.65773[0m[0m | time: 1927.162s
[2K
| Adam | epoch: 001 | loss: 0.65773 - acc: 0.5921 -- iter: 0352/1779
[A[ATraining Step: 12  | total loss: [1m[32m0.60777[0m[0m | time: 2149.941s
[2K
| Adam | epoch: 001 | loss: 0.60777 - acc: 0.6772 -- iter: 0384/1779
[A[ATraining Step: 13  | total loss: [1m[32m0.60148[0m[0m | time: 2161.772s
[2K
| Adam | epoch: 001 | loss: 0.60148 - acc: 0.6950 -- iter: 0416/1779
[A[ATraining Step: 14  | total loss: [1m[32m0.67104[0m[0m | time: 2215.892s
[2K
| Adam | epoch: 001 | loss: 0.67104 - acc: 0.6280 -- iter: 0448/1779
[A[ATraining Step: 15  | total loss: [1m[32m0.63313[0m[0m | time: 2260.591s
[2K
| Adam | epoch: 001 | loss: 0.63313 - acc: 0.6880 -- iter: 0480/1779
[A[ATraining Step: 16  | total loss: [1m[32m0.62110[0m[0m | time: 2342.561s
[2K
| Adam | epoch: 001 | loss: 0.62110 - acc: 0.6878 -- iter: 0512/1779
[A[ATraining Step: 17  | total loss: [1m[32m0.64863[0m[0m | time: 2352.898s
[2K
| Adam | epoch: 001 | loss: 0.64863 - acc: 0.6652 -- iter: 0544/1779
[A[ATraining Step: 18  | total loss: [1m[32m0.64937[0m[0m | time: 2363.215s
[2K
| Adam | epoch: 001 | loss: 0.64937 - acc: 0.6296 -- iter: 0576/1779
[A[ATraining Step: 19  | total loss: [1m[32m0.60986[0m[0m | time: 2373.124s
[2K
| Adam | epoch: 001 | loss: 0.60986 - acc: 0.7010 -- iter: 0608/1779
[A[ATraining Step: 20  | total loss: [1m[32m0.60486[0m[0m | time: 2383.124s
[2K
| Adam | epoch: 001 | loss: 0.60486 - acc: 0.6565 -- iter: 0640/1779
[A[ATraining Step: 21  | total loss: [1m[32m0.60169[0m[0m | time: 2393.293s
[2K
| Adam | epoch: 001 | loss: 0.60169 - acc: 0.6467 -- iter: 0672/1779
[A[ATraining Step: 22  | total loss: [1m[32m0.58893[0m[0m | time: 2403.930s
[2K
| Adam | epoch: 001 | loss: 0.58893 - acc: 0.6871 -- iter: 0704/1779
[A[ATraining Step: 23  | total loss: [1m[32m0.57661[0m[0m | time: 2415.026s
[2K
| Adam | epoch: 001 | loss: 0.57661 - acc: 0.6781 -- iter: 0736/1779
[A[ATraining Step: 24  | total loss: [1m[32m0.58714[0m[0m | time: 2425.138s
[2K
| Adam | epoch: 001 | loss: 0.58714 - acc: 0.6632 -- iter: 0768/1779
[A[ATraining Step: 25  | total loss: [1m[32m0.55337[0m[0m | time: 2435.787s
[2K
| Adam | epoch: 001 | loss: 0.55337 - acc: 0.7295 -- iter: 0800/1779
[A[ATraining Step: 26  | total loss: [1m[32m0.50633[0m[0m | time: 2445.811s
[2K
| Adam | epoch: 001 | loss: 0.50633 - acc: 0.7763 -- iter: 0832/1779
[A[ATraining Step: 27  | total loss: [1m[32m0.51018[0m[0m | time: 2456.071s
[2K
| Adam | epoch: 001 | loss: 0.51018 - acc: 0.7695 -- iter: 0864/1779
[A[ATraining Step: 28  | total loss: [1m[32m0.51641[0m[0m | time: 2466.333s
[2K
| Adam | epoch: 001 | loss: 0.51641 - acc: 0.7646 -- iter: 0896/1779
[A[ATraining Step: 29  | total loss: [1m[32m0.51491[0m[0m | time: 2477.830s
[2K
| Adam | epoch: 001 | loss: 0.51491 - acc: 0.7459 -- iter: 0928/1779
[A[ATraining Step: 30  | total loss: [1m[32m0.51640[0m[0m | time: 2488.156s
[2K
| Adam | epoch: 001 | loss: 0.51640 - acc: 0.7469 -- iter: 0960/1779
[A[ATraining Step: 31  | total loss: [1m[32m0.52053[0m[0m | time: 2498.252s
[2K
| Adam | epoch: 001 | loss: 0.52053 - acc: 0.7259 -- iter: 0992/1779
[A[ATraining Step: 32  | total loss: [1m[32m0.51777[0m[0m | time: 2753.553s
[2K
| Adam | epoch: 001 | loss: 0.51777 - acc: 0.7314 -- iter: 1024/1779
[A[ATraining Step: 33  | total loss: [1m[32m0.50529[0m[0m | time: 2807.053s
[2K
| Adam | epoch: 001 | loss: 0.50529 - acc: 0.7492 -- iter: 1056/1779
[A[ATraining Step: 34  | total loss: [1m[32m0.49714[0m[0m | time: 2850.623s
[2K
| Adam | epoch: 001 | loss: 0.49714 - acc: 0.7560 -- iter: 1088/1779
[A[ATraining Step: 35  | total loss: [1m[32m0.49316[0m[0m | time: 2898.867s
[2K
| Adam | epoch: 001 | loss: 0.49316 - acc: 0.7548 -- iter: 1120/1779
[A[ATraining Step: 36  | total loss: [1m[32m0.46838[0m[0m | time: 2945.140s
[2K
| Adam | epoch: 001 | loss: 0.46838 - acc: 0.7858 -- iter: 1152/1779
[A[ATraining Step: 37  | total loss: [1m[32m0.45160[0m[0m | time: 2999.829s
[2K
| Adam | epoch: 001 | loss: 0.45160 - acc: 0.7974 -- iter: 1184/1779
[A[ATraining Step: 38  | total loss: [1m[32m0.43614[0m[0m | time: 3017.131s
[2K
| Adam | epoch: 001 | loss: 0.43614 - acc: 0.7942 -- iter: 1216/1779
[A[ATraining Step: 39  | total loss: [1m[32m0.43188[0m[0m | time: 3028.184s
[2K
| Adam | epoch: 001 | loss: 0.43188 - acc: 0.7917 -- iter: 1248/1779
[A[ATraining Step: 40  | total loss: [1m[32m0.43201[0m[0m | time: 3040.867s
[2K
| Adam | epoch: 001 | loss: 0.43201 - acc: 0.7956 -- iter: 1280/1779
[A[ATraining Step: 41  | total loss: [1m[32m0.43671[0m[0m | time: 3051.021s
[2K
| Adam | epoch: 001 | loss: 0.43671 - acc: 0.8045 -- iter: 1312/1779
[A[ATraining Step: 42  | total loss: [1m[32m0.42276[0m[0m | time: 3061.696s
[2K
| Adam | epoch: 001 | loss: 0.42276 - acc: 0.8172 -- iter: 1344/1779
[A[ATraining Step: 43  | total loss: [1m[32m0.43691[0m[0m | time: 3074.151s
[2K
| Adam | epoch: 001 | loss: 0.43691 - acc: 0.8053 -- iter: 1376/1779
[A[ATraining Step: 44  | total loss: [1m[32m0.46403[0m[0m | time: 3116.823s
[2K
| Adam | epoch: 001 | loss: 0.46403 - acc: 0.8011 -- iter: 1408/1779
[A[ATraining Step: 45  | total loss: [1m[32m0.46593[0m[0m | time: 3195.282s
[2K
| Adam | epoch: 001 | loss: 0.46593 - acc: 0.7925 -- iter: 1440/1779
[A[ATraining Step: 46  | total loss: [1m[32m0.44733[0m[0m | time: 3273.849s
[2K
| Adam | epoch: 001 | loss: 0.44733 - acc: 0.8010 -- iter: 1472/1779
[A[ATraining Step: 47  | total loss: [1m[32m0.42719[0m[0m | time: 3381.575s
[2K
| Adam | epoch: 001 | loss: 0.42719 - acc: 0.8182 -- iter: 1504/1779
[A[ATraining Step: 48  | total loss: [1m[32m0.42998[0m[0m | time: 3398.301s
[2K
| Adam | epoch: 001 | loss: 0.42998 - acc: 0.8022 -- iter: 1536/1779
[A[ATraining Step: 49  | total loss: [1m[32m0.44595[0m[0m | time: 3434.765s
[2K
| Adam | epoch: 001 | loss: 0.44595 - acc: 0.7891 -- iter: 1568/1779
[A[ATraining Step: 50  | total loss: [1m[32m0.42488[0m[0m | time: 3449.323s
[2K
| Adam | epoch: 001 | loss: 0.42488 - acc: 0.7975 -- iter: 1600/1779
[A[ATraining Step: 51  | total loss: [1m[32m0.42204[0m[0m | time: 3460.320s
[2K
| Adam | epoch: 001 | loss: 0.42204 - acc: 0.8046 -- iter: 1632/1779
[A[ATraining Step: 52  | total loss: [1m[32m0.42047[0m[0m | time: 3471.940s
[2K
| Adam | epoch: 001 | loss: 0.42047 - acc: 0.8105 -- iter: 1664/1779
[A[ATraining Step: 53  | total loss: [1m[32m0.44878[0m[0m | time: 3486.839s
[2K
| Adam | epoch: 001 | loss: 0.44878 - acc: 0.8108 -- iter: 1696/1779
[A[ATraining Step: 54  | total loss: [1m[32m0.41962[0m[0m | time: 3524.746s
[2K
| Adam | epoch: 001 | loss: 0.41962 - acc: 0.8246 -- iter: 1728/1779
[A[ATraining Step: 55  | total loss: [1m[32m0.40331[0m[0m | time: 3577.619s
[2K
| Adam | epoch: 001 | loss: 0.40331 - acc: 0.8274 -- iter: 1760/1779
[A[ATraining Step: 56  | total loss: [1m[32m0.36691[0m[0m | time: 3645.820s
[2K
| Adam | epoch: 001 | loss: 0.36691 - acc: 0.8516 | val_loss: 0.62994 - val_acc: 0.6481 -- iter: 1779/1779
--
Training Step: 57  | total loss: [1m[32m0.38433[0m[0m | time: 11.405s
[2K
| Adam | epoch: 002 | loss: 0.38433 - acc: 0.8212 -- iter: 0032/1779
[A[ATraining Step: 58  | total loss: [1m[32m0.36625[0m[0m | time: 28.327s
[2K
| Adam | epoch: 002 | loss: 0.36625 - acc: 0.8456 -- iter: 0064/1779
[A[ATraining Step: 59  | total loss: [1m[32m0.36755[0m[0m | time: 45.442s
[2K
| Adam | epoch: 002 | loss: 0.36755 - acc: 0.8327 -- iter: 0096/1779
[A[ATraining Step: 60  | total loss: [1m[32m0.41470[0m[0m | time: 58.480s
[2K
| Adam | epoch: 002 | loss: 0.41470 - acc: 0.8052 -- iter: 0128/1779
[A[ATraining Step: 61  | total loss: [1m[32m0.43789[0m[0m | time: 68.933s
[2K
| Adam | epoch: 002 | loss: 0.43789 - acc: 0.7939 -- iter: 0160/1779
[A[ATraining Step: 62  | total loss: [1m[32m0.43040[0m[0m | time: 81.702s
[2K
| Adam | epoch: 002 | loss: 0.43040 - acc: 0.7963 -- iter: 0192/1779
[A[ATraining Step: 63  | total loss: [1m[32m0.42316[0m[0m | time: 98.616s
[2K
| Adam | epoch: 002 | loss: 0.42316 - acc: 0.8023 -- iter: 0224/1779
[A[ATraining Step: 64  | total loss: [1m[32m0.45094[0m[0m | time: 115.689s
[2K
| Adam | epoch: 002 | loss: 0.45094 - acc: 0.7841 -- iter: 0256/1779
[A[ATraining Step: 65  | total loss: [1m[32m0.42006[0m[0m | time: 132.318s
[2K
| Adam | epoch: 002 | loss: 0.42006 - acc: 0.7991 -- iter: 0288/1779
[A[ATraining Step: 66  | total loss: [1m[32m0.42911[0m[0m | time: 149.130s
[2K
| Adam | epoch: 002 | loss: 0.42911 - acc: 0.7932 -- iter: 0320/1779
[A[ATraining Step: 67  | total loss: [1m[32m0.45743[0m[0m | time: 165.289s
[2K
| Adam | epoch: 002 | loss: 0.45743 - acc: 0.7805 -- iter: 0352/1779
[A[ATraining Step: 68  | total loss: [1m[32m0.46039[0m[0m | time: 179.966s
[2K
| Adam | epoch: 002 | loss: 0.46039 - acc: 0.7954 -- iter: 0384/1779
[A[ATraining Step: 69  | total loss: [1m[32m0.47269[0m[0m | time: 191.153s
[2K
| Adam | epoch: 002 | loss: 0.47269 - acc: 0.7974 -- iter: 0416/1779
[A[ATraining Step: 70  | total loss: [1m[32m0.45121[0m[0m | time: 204.945s
[2K
| Adam | epoch: 002 | loss: 0.45121 - acc: 0.7991 -- iter: 0448/1779
[A[ATraining Step: 71  | total loss: [1m[32m0.45878[0m[0m | time: 221.836s
[2K
| Adam | epoch: 002 | loss: 0.45878 - acc: 0.7935 -- iter: 0480/1779
[A[ATraining Step: 72  | total loss: [1m[32m0.45044[0m[0m | time: 242.062s
[2K
| Adam | epoch: 002 | loss: 0.45044 - acc: 0.7992 -- iter: 0512/1779
[A[ATraining Step: 73  | total loss: [1m[32m0.44690[0m[0m | time: 262.431s
[2K
| Adam | epoch: 002 | loss: 0.44690 - acc: 0.7937 -- iter: 0544/1779
[A[ATraining Step: 74  | total loss: [1m[32m0.43027[0m[0m | time: 278.975s
[2K
| Adam | epoch: 002 | loss: 0.43027 - acc: 0.7992 -- iter: 0576/1779
[A[ATraining Step: 75  | total loss: [1m[32m0.42258[0m[0m | time: 295.608s
[2K
| Adam | epoch: 002 | loss: 0.42258 - acc: 0.8108 -- iter: 0608/1779
[A[ATraining Step: 76  | total loss: [1m[32m0.44352[0m[0m | time: 310.173s
[2K
| Adam | epoch: 002 | loss: 0.44352 - acc: 0.7976 -- iter: 0640/1779
[A[ATraining Step: 77  | total loss: [1m[32m0.45318[0m[0m | time: 320.358s
[2K
| Adam | epoch: 002 | loss: 0.45318 - acc: 0.7926 -- iter: 0672/1779
[A[ATraining Step: 78  | total loss: [1m[32m0.45872[0m[0m | time: 332.460s
[2K
| Adam | epoch: 002 | loss: 0.45872 - acc: 0.7914 -- iter: 0704/1779
[A[ATraining Step: 79  | total loss: [1m[32m0.44584[0m[0m | time: 349.325s
[2K
| Adam | epoch: 002 | loss: 0.44584 - acc: 0.7936 -- iter: 0736/1779
[A[ATraining Step: 80  | total loss: [1m[32m0.44350[0m[0m | time: 366.628s
[2K
| Adam | epoch: 002 | loss: 0.44350 - acc: 0.7955 -- iter: 0768/1779
[A[ATraining Step: 81  | total loss: [1m[32m0.46632[0m[0m | time: 382.713s
[2K
| Adam | epoch: 002 | loss: 0.46632 - acc: 0.7941 -- iter: 0800/1779
[A[ATraining Step: 82  | total loss: [1m[32m0.44247[0m[0m | time: 399.080s
[2K
| Adam | epoch: 002 | loss: 0.44247 - acc: 0.8115 -- iter: 0832/1779
[A[ATraining Step: 83  | total loss: [1m[32m0.42317[0m[0m | time: 416.221s
[2K
| Adam | epoch: 002 | loss: 0.42317 - acc: 0.8210 -- iter: 0864/1779
[A[ATraining Step: 84  | total loss: [1m[32m0.40005[0m[0m | time: 430.913s
[2K
| Adam | epoch: 002 | loss: 0.40005 - acc: 0.8358 -- iter: 0896/1779
[A[ATraining Step: 85  | total loss: [1m[32m0.37562[0m[0m | time: 442.043s
[2K
| Adam | epoch: 002 | loss: 0.37562 - acc: 0.8522 -- iter: 0928/1779
[A[ATraining Step: 86  | total loss: [1m[32m0.35304[0m[0m | time: 455.361s
[2K
| Adam | epoch: 002 | loss: 0.35304 - acc: 0.8670 -- iter: 0960/1779
[A[ATraining Step: 87  | total loss: [1m[32m0.33723[0m[0m | time: 471.416s
[2K
| Adam | epoch: 002 | loss: 0.33723 - acc: 0.8772 -- iter: 0992/1779
[A[ATraining Step: 88  | total loss: [1m[32m0.32242[0m[0m | time: 488.001s
[2K
| Adam | epoch: 002 | loss: 0.32242 - acc: 0.8863 -- iter: 1024/1779
[A[ATraining Step: 89  | total loss: [1m[32m0.32081[0m[0m | time: 504.215s
[2K
| Adam | epoch: 002 | loss: 0.32081 - acc: 0.8852 -- iter: 1056/1779
[A[ATraining Step: 90  | total loss: [1m[32m0.30810[0m[0m | time: 537.508s
[2K
| Adam | epoch: 002 | loss: 0.30810 - acc: 0.8873 -- iter: 1088/1779
[A[ATraining Step: 91  | total loss: [1m[32m0.30756[0m[0m | time: 564.164s
[2K
| Adam | epoch: 002 | loss: 0.30756 - acc: 0.8861 -- iter: 1120/1779
[A[ATraining Step: 92  | total loss: [1m[32m0.29213[0m[0m | time: 576.223s
[2K
| Adam | epoch: 002 | loss: 0.29213 - acc: 0.8881 -- iter: 1152/1779
[A[ATraining Step: 93  | total loss: [1m[32m0.28519[0m[0m | time: 584.889s
[2K
| Adam | epoch: 002 | loss: 0.28519 - acc: 0.8930 -- iter: 1184/1779
[A[ATraining Step: 94  | total loss: [1m[32m0.27771[0m[0m | time: 593.521s
[2K
| Adam | epoch: 002 | loss: 0.27771 - acc: 0.8943 -- iter: 1216/1779
[A[ATraining Step: 95  | total loss: [1m[32m0.26359[0m[0m | time: 602.304s
[2K
| Adam | epoch: 002 | loss: 0.26359 - acc: 0.8987 -- iter: 1248/1779
[A[ATraining Step: 96  | total loss: [1m[32m0.24491[0m[0m | time: 613.987s
[2K
| Adam | epoch: 002 | loss: 0.24491 - acc: 0.9088 -- iter: 1280/1779
[A[ATraining Step: 97  | total loss: [1m[32m0.23746[0m[0m | time: 627.666s
[2K
| Adam | epoch: 002 | loss: 0.23746 - acc: 0.9085 -- iter: 1312/1779
[A[ATraining Step: 98  | total loss: [1m[32m0.22795[0m[0m | time: 641.615s
[2K
| Adam | epoch: 002 | loss: 0.22795 - acc: 0.9114 -- iter: 1344/1779
[A[ATraining Step: 99  | total loss: [1m[32m0.21134[0m[0m | time: 655.737s
[2K
| Adam | epoch: 002 | loss: 0.21134 - acc: 0.9203 -- iter: 1376/1779
[A[ATraining Step: 100  | total loss: [1m[32m0.19589[0m[0m | time: 669.575s
[2K
| Adam | epoch: 002 | loss: 0.19589 - acc: 0.9283 -- iter: 1408/1779
[A[ATraining Step: 101  | total loss: [1m[32m0.19609[0m[0m | time: 683.533s
[2K
| Adam | epoch: 002 | loss: 0.19609 - acc: 0.9261 -- iter: 1440/1779
[A[ATraining Step: 102  | total loss: [1m[32m0.18792[0m[0m | time: 694.599s
[2K
| Adam | epoch: 002 | loss: 0.18792 - acc: 0.9303 -- iter: 1472/1779
[A[ATraining Step: 103  | total loss: [1m[32m0.17861[0m[0m | time: 702.875s
[2K
| Adam | epoch: 002 | loss: 0.17861 - acc: 0.9373 -- iter: 1504/1779
[A[ATraining Step: 104  | total loss: [1m[32m0.19269[0m[0m | time: 711.410s
[2K
| Adam | epoch: 002 | loss: 0.19269 - acc: 0.9311 -- iter: 1536/1779
[A[ATraining Step: 105  | total loss: [1m[32m0.19876[0m[0m | time: 719.901s
[2K
| Adam | epoch: 002 | loss: 0.19876 - acc: 0.9317 -- iter: 1568/1779
[A[ATraining Step: 106  | total loss: [1m[32m0.20109[0m[0m | time: 733.481s
[2K
| Adam | epoch: 002 | loss: 0.20109 - acc: 0.9323 -- iter: 1600/1779
[A[ATraining Step: 107  | total loss: [1m[32m0.19896[0m[0m | time: 747.555s
[2K
| Adam | epoch: 002 | loss: 0.19896 - acc: 0.9328 -- iter: 1632/1779
[A[ATraining Step: 108  | total loss: [1m[32m0.18475[0m[0m | time: 761.058s
[2K
| Adam | epoch: 002 | loss: 0.18475 - acc: 0.9395 -- iter: 1664/1779
[A[ATraining Step: 109  | total loss: [1m[32m0.17633[0m[0m | time: 775.076s
[2K
| Adam | epoch: 002 | loss: 0.17633 - acc: 0.9393 -- iter: 1696/1779
[A[ATraining Step: 110  | total loss: [1m[32m0.16281[0m[0m | time: 789.136s
[2K
| Adam | epoch: 002 | loss: 0.16281 - acc: 0.9454 -- iter: 1728/1779
[A[ATraining Step: 111  | total loss: [1m[32m0.15748[0m[0m | time: 803.290s
[2K
| Adam | epoch: 002 | loss: 0.15748 - acc: 0.9477 -- iter: 1760/1779
[A[ATraining Step: 112  | total loss: [1m[32m0.15440[0m[0m | time: 839.733s
[2K
| Adam | epoch: 002 | loss: 0.15440 - acc: 0.9436 | val_loss: 2.28926 - val_acc: 0.5171 -- iter: 1779/1779
--
Training Step: 113  | total loss: [1m[32m0.16467[0m[0m | time: 8.787s
[2K
| Adam | epoch: 003 | loss: 0.16467 - acc: 0.9398 -- iter: 0032/1779
[A[ATraining Step: 114  | total loss: [1m[32m0.15213[0m[0m | time: 17.812s
[2K
| Adam | epoch: 003 | loss: 0.15213 - acc: 0.9459 -- iter: 0064/1779
[A[ATraining Step: 115  | total loss: [1m[32m0.13836[0m[0m | time: 31.174s
[2K
| Adam | epoch: 003 | loss: 0.13836 - acc: 0.9513 -- iter: 0096/1779
[A[ATraining Step: 116  | total loss: [1m[32m0.13044[0m[0m | time: 45.253s
[2K
| Adam | epoch: 003 | loss: 0.13044 - acc: 0.9561 -- iter: 0128/1779
[A[ATraining Step: 117  | total loss: [1m[32m0.12512[0m[0m | time: 56.342s
[2K
| Adam | epoch: 003 | loss: 0.12512 - acc: 0.9574 -- iter: 0160/1779
[A[ATraining Step: 118  | total loss: [1m[32m0.11778[0m[0m | time: 64.873s
[2K
| Adam | epoch: 003 | loss: 0.11778 - acc: 0.9617 -- iter: 0192/1779
[A[ATraining Step: 119  | total loss: [1m[32m0.12718[0m[0m | time: 75.260s
[2K
| Adam | epoch: 003 | loss: 0.12718 - acc: 0.9499 -- iter: 0224/1779
[A[ATraining Step: 120  | total loss: [1m[32m0.13591[0m[0m | time: 88.952s
[2K
| Adam | epoch: 003 | loss: 0.13591 - acc: 0.9518 -- iter: 0256/1779
[A[ATraining Step: 121  | total loss: [1m[32m0.13026[0m[0m | time: 103.274s
[2K
| Adam | epoch: 003 | loss: 0.13026 - acc: 0.9535 -- iter: 0288/1779
[A[ATraining Step: 122  | total loss: [1m[32m0.13546[0m[0m | time: 116.964s
[2K
| Adam | epoch: 003 | loss: 0.13546 - acc: 0.9519 -- iter: 0320/1779
[A[ATraining Step: 123  | total loss: [1m[32m0.17127[0m[0m | time: 130.378s
[2K
| Adam | epoch: 003 | loss: 0.17127 - acc: 0.9442 -- iter: 0352/1779
[A[ATraining Step: 124  | total loss: [1m[32m0.17207[0m[0m | time: 144.244s
[2K
| Adam | epoch: 003 | loss: 0.17207 - acc: 0.9404 -- iter: 0384/1779
[A[ATraining Step: 125  | total loss: [1m[32m0.18661[0m[0m | time: 156.548s
[2K
| Adam | epoch: 003 | loss: 0.18661 - acc: 0.9307 -- iter: 0416/1779
[A[ATraining Step: 126  | total loss: [1m[32m0.21449[0m[0m | time: 165.135s
[2K
| Adam | epoch: 003 | loss: 0.21449 - acc: 0.9345 -- iter: 0448/1779
[A[ATraining Step: 127  | total loss: [1m[32m0.20776[0m[0m | time: 173.992s
[2K
| Adam | epoch: 003 | loss: 0.20776 - acc: 0.9348 -- iter: 0480/1779
[A[ATraining Step: 128  | total loss: [1m[32m0.21994[0m[0m | time: 187.793s
[2K
| Adam | epoch: 003 | loss: 0.21994 - acc: 0.9288 -- iter: 0512/1779
[A[ATraining Step: 129  | total loss: [1m[32m0.22041[0m[0m | time: 201.244s
[2K
| Adam | epoch: 003 | loss: 0.22041 - acc: 0.9297 -- iter: 0544/1779
[A[ATraining Step: 130  | total loss: [1m[32m0.23871[0m[0m | time: 214.615s
[2K
| Adam | epoch: 003 | loss: 0.23871 - acc: 0.9242 -- iter: 0576/1779
[A[ATraining Step: 131  | total loss: [1m[32m0.22649[0m[0m | time: 228.382s
[2K
| Adam | epoch: 003 | loss: 0.22649 - acc: 0.9287 -- iter: 0608/1779
[A[ATraining Step: 132  | total loss: [1m[32m0.21966[0m[0m | time: 242.033s
[2K
| Adam | epoch: 003 | loss: 0.21966 - acc: 0.9327 -- iter: 0640/1779
[A[ATraining Step: 133  | total loss: [1m[32m0.22943[0m[0m | time: 255.353s
[2K
| Adam | epoch: 003 | loss: 0.22943 - acc: 0.9332 -- iter: 0672/1779
[A[ATraining Step: 134  | total loss: [1m[32m0.24074[0m[0m | time: 264.483s
[2K
| Adam | epoch: 003 | loss: 0.24074 - acc: 0.9242 -- iter: 0704/1779
[A[ATraining Step: 135  | total loss: [1m[32m0.27354[0m[0m | time: 273.112s
[2K
| Adam | epoch: 003 | loss: 0.27354 - acc: 0.9131 -- iter: 0736/1779
[A[ATraining Step: 136  | total loss: [1m[32m0.26078[0m[0m | time: 283.197s
[2K
| Adam | epoch: 003 | loss: 0.26078 - acc: 0.9124 -- iter: 0768/1779
[A[ATraining Step: 137  | total loss: [1m[32m0.24239[0m[0m | time: 297.208s
[2K
| Adam | epoch: 003 | loss: 0.24239 - acc: 0.9180 -- iter: 0800/1779
[A[ATraining Step: 138  | total loss: [1m[32m0.23562[0m[0m | time: 311.319s
[2K
| Adam | epoch: 003 | loss: 0.23562 - acc: 0.9200 -- iter: 0832/1779
[A[ATraining Step: 139  | total loss: [1m[32m0.22039[0m[0m | time: 325.614s
[2K
| Adam | epoch: 003 | loss: 0.22039 - acc: 0.9217 -- iter: 0864/1779
[A[ATraining Step: 140  | total loss: [1m[32m0.20141[0m[0m | time: 339.266s
[2K
| Adam | epoch: 003 | loss: 0.20141 - acc: 0.9295 -- iter: 0896/1779
[A[ATraining Step: 141  | total loss: [1m[32m0.19718[0m[0m | time: 352.832s
[2K
| Adam | epoch: 003 | loss: 0.19718 - acc: 0.9272 -- iter: 0928/1779
[A[ATraining Step: 142  | total loss: [1m[32m0.18716[0m[0m | time: 364.593s
[2K
| Adam | epoch: 003 | loss: 0.18716 - acc: 0.9314 -- iter: 0960/1779
[A[ATraining Step: 143  | total loss: [1m[32m0.17605[0m[0m | time: 372.950s
[2K
| Adam | epoch: 003 | loss: 0.17605 - acc: 0.9351 -- iter: 0992/1779
[A[ATraining Step: 144  | total loss: [1m[32m0.16199[0m[0m | time: 381.374s
[2K
| Adam | epoch: 003 | loss: 0.16199 - acc: 0.9416 -- iter: 1024/1779
[A[ATraining Step: 145  | total loss: [1m[32m0.15146[0m[0m | time: 394.283s
[2K
| Adam | epoch: 003 | loss: 0.15146 - acc: 0.9474 -- iter: 1056/1779
[A[ATraining Step: 146  | total loss: [1m[32m0.14557[0m[0m | time: 408.409s
[2K
| Adam | epoch: 003 | loss: 0.14557 - acc: 0.9496 -- iter: 1088/1779
[A[ATraining Step: 147  | total loss: [1m[32m0.16375[0m[0m | time: 422.065s
[2K
| Adam | epoch: 003 | loss: 0.16375 - acc: 0.9421 -- iter: 1120/1779
[A[ATraining Step: 148  | total loss: [1m[32m0.16775[0m[0m | time: 435.605s
[2K
| Adam | epoch: 003 | loss: 0.16775 - acc: 0.9448 -- iter: 1152/1779
[A[ATraining Step: 149  | total loss: [1m[32m0.15797[0m[0m | time: 448.855s
[2K
| Adam | epoch: 003 | loss: 0.15797 - acc: 0.9503 -- iter: 1184/1779
[A[ATraining Step: 150  | total loss: [1m[32m0.15261[0m[0m | time: 463.123s
[2K
| Adam | epoch: 003 | loss: 0.15261 - acc: 0.9521 -- iter: 1216/1779
[A[ATraining Step: 151  | total loss: [1m[32m0.16285[0m[0m | time: 472.071s
[2K
| Adam | epoch: 003 | loss: 0.16285 - acc: 0.9507 -- iter: 1248/1779
[A[ATraining Step: 152  | total loss: [1m[32m0.15825[0m[0m | time: 481.035s
[2K
| Adam | epoch: 003 | loss: 0.15825 - acc: 0.9525 -- iter: 1280/1779
[A[ATraining Step: 153  | total loss: [1m[32m0.14856[0m[0m | time: 492.379s
[2K
| Adam | epoch: 003 | loss: 0.14856 - acc: 0.9541 -- iter: 1312/1779
[A[ATraining Step: 154  | total loss: [1m[32m0.14234[0m[0m | time: 506.187s
[2K
| Adam | epoch: 003 | loss: 0.14234 - acc: 0.9556 -- iter: 1344/1779
[A[ATraining Step: 155  | total loss: [1m[32m0.16668[0m[0m | time: 519.992s
[2K
| Adam | epoch: 003 | loss: 0.16668 - acc: 0.9569 -- iter: 1376/1779
[A[ATraining Step: 156  | total loss: [1m[32m0.15987[0m[0m | time: 533.908s
[2K
| Adam | epoch: 003 | loss: 0.15987 - acc: 0.9581 -- iter: 1408/1779
[A[ATraining Step: 157  | total loss: [1m[32m0.15954[0m[0m | time: 546.842s
[2K
| Adam | epoch: 003 | loss: 0.15954 - acc: 0.9560 -- iter: 1440/1779
[A[ATraining Step: 158  | total loss: [1m[32m0.17475[0m[0m | time: 560.445s
[2K
| Adam | epoch: 003 | loss: 0.17475 - acc: 0.9573 -- iter: 1472/1779
[A[ATraining Step: 159  | total loss: [1m[32m0.16006[0m[0m | time: 571.586s
[2K
| Adam | epoch: 003 | loss: 0.16006 - acc: 0.9616 -- iter: 1504/1779
[A[ATraining Step: 160  | total loss: [1m[32m0.14836[0m[0m | time: 579.870s
[2K
| Adam | epoch: 003 | loss: 0.14836 - acc: 0.9654 -- iter: 1536/1779
[A[ATraining Step: 161  | total loss: [1m[32m0.13937[0m[0m | time: 588.179s
[2K
| Adam | epoch: 003 | loss: 0.13937 - acc: 0.9657 -- iter: 1568/1779
[A[ATraining Step: 162  | total loss: [1m[32m0.13258[0m[0m | time: 601.143s
[2K
| Adam | epoch: 003 | loss: 0.13258 - acc: 0.9660 -- iter: 1600/1779
[A[ATraining Step: 163  | total loss: [1m[32m0.14110[0m[0m | time: 614.907s
[2K
| Adam | epoch: 003 | loss: 0.14110 - acc: 0.9601 -- iter: 1632/1779
[A[ATraining Step: 164  | total loss: [1m[32m0.14882[0m[0m | time: 628.699s
[2K
| Adam | epoch: 003 | loss: 0.14882 - acc: 0.9578 -- iter: 1664/1779
[A[ATraining Step: 165  | total loss: [1m[32m0.14961[0m[0m | time: 642.610s
[2K
| Adam | epoch: 003 | loss: 0.14961 - acc: 0.9558 -- iter: 1696/1779
[A[ATraining Step: 166  | total loss: [1m[32m0.14489[0m[0m | time: 656.212s
[2K
| Adam | epoch: 003 | loss: 0.14489 - acc: 0.9539 -- iter: 1728/1779
[A[ATraining Step: 167  | total loss: [1m[32m0.13316[0m[0m | time: 670.032s
[2K
| Adam | epoch: 003 | loss: 0.13316 - acc: 0.9586 -- iter: 1760/1779
[A[ATraining Step: 168  | total loss: [1m[32m0.15331[0m[0m | time: 715.775s
[2K
| Adam | epoch: 003 | loss: 0.15331 - acc: 0.9564 | val_loss: 0.52164 - val_acc: 0.8115 -- iter: 1779/1779
--
Training Step: 169  | total loss: [1m[32m0.14300[0m[0m | time: 13.744s
[2K
| Adam | epoch: 004 | loss: 0.14300 - acc: 0.9608 -- iter: 0032/1779
[A[ATraining Step: 170  | total loss: [1m[32m0.13306[0m[0m | time: 20.310s
[2K
| Adam | epoch: 004 | loss: 0.13306 - acc: 0.9647 -- iter: 0064/1779
[A[ATraining Step: 171  | total loss: [1m[32m0.13620[0m[0m | time: 25.778s
[2K
| Adam | epoch: 004 | loss: 0.13620 - acc: 0.9630 -- iter: 0096/1779
[A[ATraining Step: 172  | total loss: [1m[32m0.12407[0m[0m | time: 34.377s
[2K
| Adam | epoch: 004 | loss: 0.12407 - acc: 0.9667 -- iter: 0128/1779
[A[ATraining Step: 173  | total loss: [1m[32m0.11835[0m[0m | time: 47.229s
[2K
| Adam | epoch: 004 | loss: 0.11835 - acc: 0.9700 -- iter: 0160/1779
[A[ATraining Step: 174  | total loss: [1m[32m0.11911[0m[0m | time: 60.457s
[2K
| Adam | epoch: 004 | loss: 0.11911 - acc: 0.9699 -- iter: 0192/1779
[A[ATraining Step: 175  | total loss: [1m[32m0.11019[0m[0m | time: 73.922s
[2K
| Adam | epoch: 004 | loss: 0.11019 - acc: 0.9729 -- iter: 0224/1779
[A[ATraining Step: 176  | total loss: [1m[32m0.11466[0m[0m | time: 87.092s
[2K
| Adam | epoch: 004 | loss: 0.11466 - acc: 0.9725 -- iter: 0256/1779
[A[ATraining Step: 177  | total loss: [1m[32m0.11096[0m[0m | time: 100.679s
[2K
| Adam | epoch: 004 | loss: 0.11096 - acc: 0.9752 -- iter: 0288/1779
[A[ATraining Step: 178  | total loss: [1m[32m0.11263[0m[0m | time: 114.023s
[2K
| Adam | epoch: 004 | loss: 0.11263 - acc: 0.9715 -- iter: 0320/1779
[A[ATraining Step: 179  | total loss: [1m[32m0.15151[0m[0m | time: 124.542s
[2K
| Adam | epoch: 004 | loss: 0.15151 - acc: 0.9681 -- iter: 0352/1779
[A[ATraining Step: 180  | total loss: [1m[32m0.14246[0m[0m | time: 133.077s
[2K
| Adam | epoch: 004 | loss: 0.14246 - acc: 0.9713 -- iter: 0384/1779
[A[ATraining Step: 181  | total loss: [1m[32m0.13044[0m[0m | time: 142.323s
[2K
| Adam | epoch: 004 | loss: 0.13044 - acc: 0.9741 -- iter: 0416/1779
[A[ATraining Step: 182  | total loss: [1m[32m0.12369[0m[0m | time: 156.032s
[2K
| Adam | epoch: 004 | loss: 0.12369 - acc: 0.9767 -- iter: 0448/1779
[A[ATraining Step: 183  | total loss: [1m[32m0.11609[0m[0m | time: 169.839s
[2K
| Adam | epoch: 004 | loss: 0.11609 - acc: 0.9759 -- iter: 0480/1779
[A[ATraining Step: 184  | total loss: [1m[32m0.12040[0m[0m | time: 182.854s
[2K
| Adam | epoch: 004 | loss: 0.12040 - acc: 0.9690 -- iter: 0512/1779
[A[ATraining Step: 185  | total loss: [1m[32m0.12513[0m[0m | time: 196.314s
[2K
| Adam | epoch: 004 | loss: 0.12513 - acc: 0.9627 -- iter: 0544/1779
[A[ATraining Step: 186  | total loss: [1m[32m0.11783[0m[0m | time: 209.497s
[2K
| Adam | epoch: 004 | loss: 0.11783 - acc: 0.9664 -- iter: 0576/1779
[A[ATraining Step: 187  | total loss: [1m[32m0.10878[0m[0m | time: 223.025s
[2K
| Adam | epoch: 004 | loss: 0.10878 - acc: 0.9698 -- iter: 0608/1779
[A[ATraining Step: 188  | total loss: [1m[32m0.11740[0m[0m | time: 231.685s
[2K
| Adam | epoch: 004 | loss: 0.11740 - acc: 0.9665 -- iter: 0640/1779
[A[ATraining Step: 189  | total loss: [1m[32m0.11773[0m[0m | time: 240.259s
[2K
| Adam | epoch: 004 | loss: 0.11773 - acc: 0.9636 -- iter: 0672/1779
[A[ATraining Step: 190  | total loss: [1m[32m0.11173[0m[0m | time: 252.993s
[2K
| Adam | epoch: 004 | loss: 0.11173 - acc: 0.9642 -- iter: 0704/1779
[A[ATraining Step: 191  | total loss: [1m[32m0.10620[0m[0m | time: 266.784s
[2K
| Adam | epoch: 004 | loss: 0.10620 - acc: 0.9646 -- iter: 0736/1779
[A[ATraining Step: 192  | total loss: [1m[32m0.11760[0m[0m | time: 279.967s
[2K
| Adam | epoch: 004 | loss: 0.11760 - acc: 0.9650 -- iter: 0768/1779
[A[ATraining Step: 193  | total loss: [1m[32m0.11141[0m[0m | time: 294.001s
[2K
| Adam | epoch: 004 | loss: 0.11141 - acc: 0.9685 -- iter: 0800/1779
[A[ATraining Step: 194  | total loss: [1m[32m0.10339[0m[0m | time: 307.583s
[2K
| Adam | epoch: 004 | loss: 0.10339 - acc: 0.9717 -- iter: 0832/1779
[A[ATraining Step: 195  | total loss: [1m[32m0.13514[0m[0m | time: 321.499s
[2K
| Adam | epoch: 004 | loss: 0.13514 - acc: 0.9589 -- iter: 0864/1779
[A[ATraining Step: 196  | total loss: [1m[32m0.14458[0m[0m | time: 331.007s
[2K
| Adam | epoch: 004 | loss: 0.14458 - acc: 0.9567 -- iter: 0896/1779
[A[ATraining Step: 197  | total loss: [1m[32m0.13807[0m[0m | time: 339.834s
[2K
| Adam | epoch: 004 | loss: 0.13807 - acc: 0.9611 -- iter: 0928/1779
[A[ATraining Step: 198  | total loss: [1m[32m0.12937[0m[0m | time: 350.430s
[2K
| Adam | epoch: 004 | loss: 0.12937 - acc: 0.9618 -- iter: 0960/1779
[A[ATraining Step: 199  | total loss: [1m[32m0.12505[0m[0m | time: 363.461s
[2K
| Adam | epoch: 004 | loss: 0.12505 - acc: 0.9625 -- iter: 0992/1779
[A[ATraining Step: 200  | total loss: [1m[32m0.16073[0m[0m | time: 421.650s
[2K
| Adam | epoch: 004 | loss: 0.16073 - acc: 0.9600 | val_loss: 5.69882 - val_acc: 0.5027 -- iter: 1024/1779
--
Training Step: 201  | total loss: [1m[32m0.16312[0m[0m | time: 430.114s
[2K
| Adam | epoch: 004 | loss: 0.16312 - acc: 0.9609 -- iter: 1056/1779
[A[ATraining Step: 202  | total loss: [1m[32m0.15609[0m[0m | time: 438.602s
[2K
| Adam | epoch: 004 | loss: 0.15609 - acc: 0.9617 -- iter: 1088/1779
[A[ATraining Step: 203  | total loss: [1m[32m0.16908[0m[0m | time: 452.189s
[2K
| Adam | epoch: 004 | loss: 0.16908 - acc: 0.9593 -- iter: 1120/1779
[A[ATraining Step: 204  | total loss: [1m[32m0.15432[0m[0m | time: 465.677s
[2K
| Adam | epoch: 004 | loss: 0.15432 - acc: 0.9633 -- iter: 1152/1779
[A[ATraining Step: 205  | total loss: [1m[32m0.14002[0m[0m | time: 479.268s
[2K
| Adam | epoch: 004 | loss: 0.14002 - acc: 0.9670 -- iter: 1184/1779
[A[ATraining Step: 206  | total loss: [1m[32m0.13097[0m[0m | time: 493.025s
[2K
| Adam | epoch: 004 | loss: 0.13097 - acc: 0.9703 -- iter: 1216/1779
[A[ATraining Step: 207  | total loss: [1m[32m0.12183[0m[0m | time: 506.534s
[2K
| Adam | epoch: 004 | loss: 0.12183 - acc: 0.9701 -- iter: 1248/1779
[A[ATraining Step: 208  | total loss: [1m[32m0.13522[0m[0m | time: 519.759s
[2K
| Adam | epoch: 004 | loss: 0.13522 - acc: 0.9606 -- iter: 1280/1779
[A[ATraining Step: 209  | total loss: [1m[32m0.12752[0m[0m | time: 529.255s
[2K
| Adam | epoch: 004 | loss: 0.12752 - acc: 0.9614 -- iter: 1312/1779
[A[ATraining Step: 210  | total loss: [1m[32m0.12787[0m[0m | time: 537.894s
[2K
| Adam | epoch: 004 | loss: 0.12787 - acc: 0.9591 -- iter: 1344/1779
[A[ATraining Step: 211  | total loss: [1m[32m0.12162[0m[0m | time: 547.808s
[2K
| Adam | epoch: 004 | loss: 0.12162 - acc: 0.9600 -- iter: 1376/1779
[A[ATraining Step: 212  | total loss: [1m[32m0.11624[0m[0m | time: 560.910s
[2K
| Adam | epoch: 004 | loss: 0.11624 - acc: 0.9609 -- iter: 1408/1779
[A[ATraining Step: 213  | total loss: [1m[32m0.14582[0m[0m | time: 574.801s
[2K
| Adam | epoch: 004 | loss: 0.14582 - acc: 0.9586 -- iter: 1440/1779
[A[ATraining Step: 214  | total loss: [1m[32m0.13200[0m[0m | time: 588.561s
[2K
| Adam | epoch: 004 | loss: 0.13200 - acc: 0.9627 -- iter: 1472/1779
[A[ATraining Step: 215  | total loss: [1m[32m0.14281[0m[0m | time: 602.437s
[2K
| Adam | epoch: 004 | loss: 0.14281 - acc: 0.9633 -- iter: 1504/1779
[A[ATraining Step: 216  | total loss: [1m[32m0.13175[0m[0m | time: 615.643s
[2K
| Adam | epoch: 004 | loss: 0.13175 - acc: 0.9670 -- iter: 1536/1779
[A[ATraining Step: 217  | total loss: [1m[32m0.11999[0m[0m | time: 628.589s
[2K
| Adam | epoch: 004 | loss: 0.11999 - acc: 0.9703 -- iter: 1568/1779
[A[ATraining Step: 218  | total loss: [1m[32m0.11782[0m[0m | time: 636.853s
[2K
| Adam | epoch: 004 | loss: 0.11782 - acc: 0.9701 -- iter: 1600/1779
[A[ATraining Step: 219  | total loss: [1m[32m0.13723[0m[0m | time: 645.312s
[2K
| Adam | epoch: 004 | loss: 0.13723 - acc: 0.9606 -- iter: 1632/1779
[A[ATraining Step: 220  | total loss: [1m[32m0.13542[0m[0m | time: 658.074s
[2K
| Adam | epoch: 004 | loss: 0.13542 - acc: 0.9614 -- iter: 1664/1779
[A[ATraining Step: 221  | total loss: [1m[32m0.12780[0m[0m | time: 672.005s
[2K
| Adam | epoch: 004 | loss: 0.12780 - acc: 0.9653 -- iter: 1696/1779
[A[ATraining Step: 222  | total loss: [1m[32m0.13335[0m[0m | time: 685.468s
[2K
| Adam | epoch: 004 | loss: 0.13335 - acc: 0.9656 -- iter: 1728/1779
[A[ATraining Step: 223  | total loss: [1m[32m0.13704[0m[0m | time: 698.753s
[2K
| Adam | epoch: 004 | loss: 0.13704 - acc: 0.9628 -- iter: 1760/1779
[A[ATraining Step: 224  | total loss: [1m[32m0.13382[0m[0m | time: 747.536s
[2K
| Adam | epoch: 004 | loss: 0.13382 - acc: 0.9634 | val_loss: 0.73737 - val_acc: 0.7576 -- iter: 1779/1779
--
Training Step: 225  | total loss: [1m[32m0.12249[0m[0m | time: 13.920s
[2K
| Adam | epoch: 005 | loss: 0.12249 - acc: 0.9671 -- iter: 0032/1779
[A[ATraining Step: 226  | total loss: [1m[32m0.12444[0m[0m | time: 27.216s
[2K
| Adam | epoch: 005 | loss: 0.12444 - acc: 0.9641 -- iter: 0064/1779
[A[ATraining Step: 227  | total loss: [1m[32m0.11585[0m[0m | time: 36.301s
[2K
| Adam | epoch: 005 | loss: 0.11585 - acc: 0.9677 -- iter: 0096/1779
[A[ATraining Step: 228  | total loss: [1m[32m0.14191[0m[0m | time: 45.464s
[2K
| Adam | epoch: 005 | loss: 0.14191 - acc: 0.9499 -- iter: 0128/1779
[A[ATraining Step: 229  | total loss: [1m[32m0.13936[0m[0m | time: 58.838s
[2K
| Adam | epoch: 005 | loss: 0.13936 - acc: 0.9549 -- iter: 0160/1779
[A[ATraining Step: 230  | total loss: [1m[32m0.12845[0m[0m | time: 67.299s
[2K
| Adam | epoch: 005 | loss: 0.12845 - acc: 0.9594 -- iter: 0192/1779
[A[ATraining Step: 231  | total loss: [1m[32m0.12466[0m[0m | time: 75.808s
[2K
| Adam | epoch: 005 | loss: 0.12466 - acc: 0.9603 -- iter: 0224/1779
[A[ATraining Step: 232  | total loss: [1m[32m0.12996[0m[0m | time: 87.677s
[2K
| Adam | epoch: 005 | loss: 0.12996 - acc: 0.9549 -- iter: 0256/1779
[A[ATraining Step: 233  | total loss: [1m[32m0.12986[0m[0m | time: 101.312s
[2K
| Adam | epoch: 005 | loss: 0.12986 - acc: 0.9563 -- iter: 0288/1779
[A[ATraining Step: 234  | total loss: [1m[32m0.11954[0m[0m | time: 115.172s
[2K
| Adam | epoch: 005 | loss: 0.11954 - acc: 0.9607 -- iter: 0320/1779
[A[ATraining Step: 235  | total loss: [1m[32m0.13078[0m[0m | time: 128.368s
[2K
| Adam | epoch: 005 | loss: 0.13078 - acc: 0.9615 -- iter: 0352/1779
[A[ATraining Step: 236  | total loss: [1m[32m0.12388[0m[0m | time: 141.632s
[2K
| Adam | epoch: 005 | loss: 0.12388 - acc: 0.9622 -- iter: 0384/1779
[A[ATraining Step: 237  | total loss: [1m[32m0.11765[0m[0m | time: 155.639s
[2K
| Adam | epoch: 005 | loss: 0.11765 - acc: 0.9660 -- iter: 0416/1779
[A[ATraining Step: 238  | total loss: [1m[32m0.12038[0m[0m | time: 166.852s
[2K
| Adam | epoch: 005 | loss: 0.12038 - acc: 0.9663 -- iter: 0448/1779
[A[ATraining Step: 239  | total loss: [1m[32m0.11079[0m[0m | time: 175.558s
[2K
| Adam | epoch: 005 | loss: 0.11079 - acc: 0.9696 -- iter: 0480/1779
[A[ATraining Step: 240  | total loss: [1m[32m0.11324[0m[0m | time: 185.573s
[2K
| Adam | epoch: 005 | loss: 0.11324 - acc: 0.9696 -- iter: 0512/1779
[A[ATraining Step: 241  | total loss: [1m[32m0.11866[0m[0m | time: 199.358s
[2K
| Adam | epoch: 005 | loss: 0.11866 - acc: 0.9663 -- iter: 0544/1779
[A[ATraining Step: 242  | total loss: [1m[32m0.12894[0m[0m | time: 212.948s
[2K
| Adam | epoch: 005 | loss: 0.12894 - acc: 0.9666 -- iter: 0576/1779
[A[ATraining Step: 243  | total loss: [1m[32m0.12387[0m[0m | time: 227.121s
[2K
| Adam | epoch: 005 | loss: 0.12387 - acc: 0.9668 -- iter: 0608/1779
[A[ATraining Step: 244  | total loss: [1m[32m0.11988[0m[0m | time: 240.686s
[2K
| Adam | epoch: 005 | loss: 0.11988 - acc: 0.9639 -- iter: 0640/1779
[A[ATraining Step: 245  | total loss: [1m[32m0.11298[0m[0m | time: 254.038s
[2K
| Adam | epoch: 005 | loss: 0.11298 - acc: 0.9644 -- iter: 0672/1779
[A[ATraining Step: 246  | total loss: [1m[32m0.11009[0m[0m | time: 266.702s
[2K
| Adam | epoch: 005 | loss: 0.11009 - acc: 0.9617 -- iter: 0704/1779
[A[ATraining Step: 247  | total loss: [1m[32m0.13557[0m[0m | time: 275.254s
[2K
| Adam | epoch: 005 | loss: 0.13557 - acc: 0.9593 -- iter: 0736/1779
[A[ATraining Step: 248  | total loss: [1m[32m0.13774[0m[0m | time: 283.803s
[2K
| Adam | epoch: 005 | loss: 0.13774 - acc: 0.9540 -- iter: 0768/1779
[A[ATraining Step: 249  | total loss: [1m[32m0.12868[0m[0m | time: 296.993s
[2K
| Adam | epoch: 005 | loss: 0.12868 - acc: 0.9554 -- iter: 0800/1779
[A[ATraining Step: 250  | total loss: [1m[32m0.15630[0m[0m | time: 310.730s
[2K
| Adam | epoch: 005 | loss: 0.15630 - acc: 0.9505 -- iter: 0832/1779
[A[ATraining Step: 251  | total loss: [1m[32m0.14329[0m[0m | time: 323.693s
[2K
| Adam | epoch: 005 | loss: 0.14329 - acc: 0.9555 -- iter: 0864/1779
[A[ATraining Step: 252  | total loss: [1m[32m0.15182[0m[0m | time: 335.502s
[2K
| Adam | epoch: 005 | loss: 0.15182 - acc: 0.9537 -- iter: 0896/1779
[A[ATraining Step: 253  | total loss: [1m[32m0.13781[0m[0m | time: 344.025s
[2K
| Adam | epoch: 005 | loss: 0.13781 - acc: 0.9583 -- iter: 0928/1779
[A[ATraining Step: 254  | total loss: [1m[32m0.12792[0m[0m | time: 357.638s
[2K
| Adam | epoch: 005 | loss: 0.12792 - acc: 0.9625 -- iter: 0960/1779
[A[ATraining Step: 255  | total loss: [1m[32m0.14040[0m[0m | time: 371.321s
[2K
| Adam | epoch: 005 | loss: 0.14040 - acc: 0.9600 -- iter: 0992/1779
[A[ATraining Step: 256  | total loss: [1m[32m0.12706[0m[0m | time: 384.864s
[2K
| Adam | epoch: 005 | loss: 0.12706 - acc: 0.9640 -- iter: 1024/1779
[A[ATraining Step: 257  | total loss: [1m[32m0.14645[0m[0m | time: 393.737s
[2K
| Adam | epoch: 005 | loss: 0.14645 - acc: 0.9582 -- iter: 1056/1779
[A[ATraining Step: 258  | total loss: [1m[32m0.14747[0m[0m | time: 402.380s
[2K
| Adam | epoch: 005 | loss: 0.14747 - acc: 0.9593 -- iter: 1088/1779
[A[ATraining Step: 259  | total loss: [1m[32m0.13763[0m[0m | time: 412.316s
[2K
| Adam | epoch: 005 | loss: 0.13763 - acc: 0.9602 -- iter: 1120/1779
[A[ATraining Step: 260  | total loss: [1m[32m0.12974[0m[0m | time: 426.010s
[2K
| Adam | epoch: 005 | loss: 0.12974 - acc: 0.9611 -- iter: 1152/1779
[A[ATraining Step: 261  | total loss: [1m[32m0.11992[0m[0m | time: 440.155s
[2K
| Adam | epoch: 005 | loss: 0.11992 - acc: 0.9650 -- iter: 1184/1779
[A[ATraining Step: 262  | total loss: [1m[32m0.11377[0m[0m | time: 454.496s
[2K
| Adam | epoch: 005 | loss: 0.11377 - acc: 0.9653 -- iter: 1216/1779
[A[ATraining Step: 263  | total loss: [1m[32m0.13188[0m[0m | time: 467.794s
[2K
| Adam | epoch: 005 | loss: 0.13188 - acc: 0.9626 -- iter: 1248/1779
[A[ATraining Step: 264  | total loss: [1m[32m0.13078[0m[0m | time: 481.682s
[2K
| Adam | epoch: 005 | loss: 0.13078 - acc: 0.9600 -- iter: 1280/1779
[A[ATraining Step: 265  | total loss: [1m[32m0.13074[0m[0m | time: 493.659s
[2K
| Adam | epoch: 005 | loss: 0.13074 - acc: 0.9578 -- iter: 1312/1779
[A[ATraining Step: 266  | total loss: [1m[32m0.12128[0m[0m | time: 502.269s
[2K
| Adam | epoch: 005 | loss: 0.12128 - acc: 0.9620 -- iter: 1344/1779
[A[ATraining Step: 267  | total loss: [1m[32m0.13044[0m[0m | time: 510.975s
[2K
| Adam | epoch: 005 | loss: 0.13044 - acc: 0.9627 -- iter: 1376/1779
[A[ATraining Step: 268  | total loss: [1m[32m0.13070[0m[0m | time: 519.795s
[2K
| Adam | epoch: 005 | loss: 0.13070 - acc: 0.9633 -- iter: 1408/1779
[A[ATraining Step: 269  | total loss: [1m[32m0.12516[0m[0m | time: 532.113s
[2K
| Adam | epoch: 005 | loss: 0.12516 - acc: 0.9638 -- iter: 1440/1779
[A[ATraining Step: 270  | total loss: [1m[32m0.13797[0m[0m | time: 540.695s
[2K
| Adam | epoch: 005 | loss: 0.13797 - acc: 0.9643 -- iter: 1472/1779
[A[ATraining Step: 271  | total loss: [1m[32m0.12813[0m[0m | time: 549.177s
[2K
| Adam | epoch: 005 | loss: 0.12813 - acc: 0.9679 -- iter: 1504/1779
[A[ATraining Step: 272  | total loss: [1m[32m0.11951[0m[0m | time: 557.783s
[2K
| Adam | epoch: 005 | loss: 0.11951 - acc: 0.9680 -- iter: 1536/1779
[A[ATraining Step: 273  | total loss: [1m[32m0.11495[0m[0m | time: 566.104s
[2K
| Adam | epoch: 005 | loss: 0.11495 - acc: 0.9681 -- iter: 1568/1779
[A[ATraining Step: 274  | total loss: [1m[32m0.11699[0m[0m | time: 574.709s
[2K
| Adam | epoch: 005 | loss: 0.11699 - acc: 0.9650 -- iter: 1600/1779
[A[ATraining Step: 275  | total loss: [1m[32m0.11579[0m[0m | time: 583.027s
[2K
| Adam | epoch: 005 | loss: 0.11579 - acc: 0.9654 -- iter: 1632/1779
[A[ATraining Step: 276  | total loss: [1m[32m0.11032[0m[0m | time: 591.779s
[2K
| Adam | epoch: 005 | loss: 0.11032 - acc: 0.9688 -- iter: 1664/1779
[A[ATraining Step: 277  | total loss: [1m[32m0.10553[0m[0m | time: 600.165s
[2K
| Adam | epoch: 005 | loss: 0.10553 - acc: 0.9688 -- iter: 1696/1779
[A[ATraining Step: 278  | total loss: [1m[32m0.11802[0m[0m | time: 608.883s
[2K
| Adam | epoch: 005 | loss: 0.11802 - acc: 0.9657 -- iter: 1728/1779
[A[ATraining Step: 279  | total loss: [1m[32m0.10931[0m[0m | time: 617.437s
[2K
| Adam | epoch: 005 | loss: 0.10931 - acc: 0.9691 -- iter: 1760/1779
[A[ATraining Step: 280  | total loss: [1m[32m0.10017[0m[0m | time: 651.889s
[2K
| Adam | epoch: 005 | loss: 0.10017 - acc: 0.9722 | val_loss: 0.66647 - val_acc: 0.7882 -- iter: 1779/1779
--
Training Step: 281  | total loss: [1m[32m0.09795[0m[0m | time: 8.275s
[2K
| Adam | epoch: 006 | loss: 0.09795 - acc: 0.9719 -- iter: 0032/1779
[A[ATraining Step: 282  | total loss: [1m[32m0.09212[0m[0m | time: 16.626s
[2K
| Adam | epoch: 006 | loss: 0.09212 - acc: 0.9747 -- iter: 0064/1779
[A[ATraining Step: 283  | total loss: [1m[32m0.09941[0m[0m | time: 25.244s
[2K
| Adam | epoch: 006 | loss: 0.09941 - acc: 0.9710 -- iter: 0096/1779
[A[ATraining Step: 284  | total loss: [1m[32m0.10433[0m[0m | time: 30.829s
[2K
| Adam | epoch: 006 | loss: 0.10433 - acc: 0.9645 -- iter: 0128/1779
[A[ATraining Step: 285  | total loss: [1m[32m0.10151[0m[0m | time: 36.318s
[2K
| Adam | epoch: 006 | loss: 0.10151 - acc: 0.9628 -- iter: 0160/1779
[A[ATraining Step: 286  | total loss: [1m[32m0.09321[0m[0m | time: 44.875s
[2K
| Adam | epoch: 006 | loss: 0.09321 - acc: 0.9665 -- iter: 0192/1779
[A[ATraining Step: 287  | total loss: [1m[32m0.10176[0m[0m | time: 53.359s
[2K
| Adam | epoch: 006 | loss: 0.10176 - acc: 0.9667 -- iter: 0224/1779
[A[ATraining Step: 288  | total loss: [1m[32m0.09579[0m[0m | time: 61.853s
[2K
| Adam | epoch: 006 | loss: 0.09579 - acc: 0.9701 -- iter: 0256/1779
[A[ATraining Step: 289  | total loss: [1m[32m0.09703[0m[0m | time: 70.566s
[2K
| Adam | epoch: 006 | loss: 0.09703 - acc: 0.9699 -- iter: 0288/1779
[A[ATraining Step: 290  | total loss: [1m[32m0.08921[0m[0m | time: 78.877s
[2K
| Adam | epoch: 006 | loss: 0.08921 - acc: 0.9729 -- iter: 0320/1779
[A[ATraining Step: 291  | total loss: [1m[32m0.08322[0m[0m | time: 87.244s
[2K
| Adam | epoch: 006 | loss: 0.08322 - acc: 0.9756 -- iter: 0352/1779
[A[ATraining Step: 292  | total loss: [1m[32m0.07757[0m[0m | time: 95.801s
[2K
| Adam | epoch: 006 | loss: 0.07757 - acc: 0.9781 -- iter: 0384/1779
[A[ATraining Step: 293  | total loss: [1m[32m0.07152[0m[0m | time: 104.113s
[2K
| Adam | epoch: 006 | loss: 0.07152 - acc: 0.9803 -- iter: 0416/1779
[A[ATraining Step: 294  | total loss: [1m[32m0.06920[0m[0m | time: 112.665s
[2K
| Adam | epoch: 006 | loss: 0.06920 - acc: 0.9822 -- iter: 0448/1779
[A[ATraining Step: 295  | total loss: [1m[32m0.07089[0m[0m | time: 121.048s
[2K
| Adam | epoch: 006 | loss: 0.07089 - acc: 0.9778 -- iter: 0480/1779
[A[ATraining Step: 296  | total loss: [1m[32m0.06667[0m[0m | time: 129.352s
[2K
| Adam | epoch: 006 | loss: 0.06667 - acc: 0.9800 -- iter: 0512/1779
[A[ATraining Step: 297  | total loss: [1m[32m0.06549[0m[0m | time: 137.841s
[2K
| Adam | epoch: 006 | loss: 0.06549 - acc: 0.9820 -- iter: 0544/1779
[A[ATraining Step: 298  | total loss: [1m[32m0.06123[0m[0m | time: 146.172s
[2K
| Adam | epoch: 006 | loss: 0.06123 - acc: 0.9838 -- iter: 0576/1779
[A[ATraining Step: 299  | total loss: [1m[32m0.07736[0m[0m | time: 154.839s
[2K
| Adam | epoch: 006 | loss: 0.07736 - acc: 0.9792 -- iter: 0608/1779
[A[ATraining Step: 300  | total loss: [1m[32m0.07762[0m[0m | time: 163.254s
[2K
| Adam | epoch: 006 | loss: 0.07762 - acc: 0.9781 -- iter: 0640/1779
[A[ATraining Step: 301  | total loss: [1m[32m0.09104[0m[0m | time: 171.461s
[2K
| Adam | epoch: 006 | loss: 0.09104 - acc: 0.9741 -- iter: 0672/1779
[A[ATraining Step: 302  | total loss: [1m[32m0.09106[0m[0m | time: 179.990s
[2K
| Adam | epoch: 006 | loss: 0.09106 - acc: 0.9735 -- iter: 0704/1779
[A[ATraining Step: 303  | total loss: [1m[32m0.10644[0m[0m | time: 188.376s
[2K
| Adam | epoch: 006 | loss: 0.10644 - acc: 0.9731 -- iter: 0736/1779
[A[ATraining Step: 304  | total loss: [1m[32m0.10941[0m[0m | time: 196.906s
[2K
| Adam | epoch: 006 | loss: 0.10941 - acc: 0.9726 -- iter: 0768/1779
[A[ATraining Step: 305  | total loss: [1m[32m0.10064[0m[0m | time: 205.347s
[2K
| Adam | epoch: 006 | loss: 0.10064 - acc: 0.9754 -- iter: 0800/1779
[A[ATraining Step: 306  | total loss: [1m[32m0.13146[0m[0m | time: 213.691s
[2K
| Adam | epoch: 006 | loss: 0.13146 - acc: 0.9684 -- iter: 0832/1779
[A[ATraining Step: 307  | total loss: [1m[32m0.13192[0m[0m | time: 222.333s
[2K
| Adam | epoch: 006 | loss: 0.13192 - acc: 0.9654 -- iter: 0864/1779
[A[ATraining Step: 308  | total loss: [1m[32m0.12600[0m[0m | time: 230.891s
[2K
| Adam | epoch: 006 | loss: 0.12600 - acc: 0.9626 -- iter: 0896/1779
[A[ATraining Step: 309  | total loss: [1m[32m0.11442[0m[0m | time: 239.459s
[2K
| Adam | epoch: 006 | loss: 0.11442 - acc: 0.9663 -- iter: 0928/1779
[A[ATraining Step: 310  | total loss: [1m[32m0.10844[0m[0m | time: 248.116s
[2K
| Adam | epoch: 006 | loss: 0.10844 - acc: 0.9666 -- iter: 0960/1779
[A[ATraining Step: 311  | total loss: [1m[32m0.09830[0m[0m | time: 256.513s
[2K
| Adam | epoch: 006 | loss: 0.09830 - acc: 0.9699 -- iter: 0992/1779
[A[ATraining Step: 312  | total loss: [1m[32m0.08913[0m[0m | time: 265.054s
[2K
| Adam | epoch: 006 | loss: 0.08913 - acc: 0.9729 -- iter: 1024/1779
[A[ATraining Step: 313  | total loss: [1m[32m0.08873[0m[0m | time: 273.584s
[2K
| Adam | epoch: 006 | loss: 0.08873 - acc: 0.9725 -- iter: 1056/1779
[A[ATraining Step: 314  | total loss: [1m[32m0.08479[0m[0m | time: 282.014s
[2K
| Adam | epoch: 006 | loss: 0.08479 - acc: 0.9752 -- iter: 1088/1779
[A[ATraining Step: 315  | total loss: [1m[32m0.07879[0m[0m | time: 290.477s
[2K
| Adam | epoch: 006 | loss: 0.07879 - acc: 0.9777 -- iter: 1120/1779
[A[ATraining Step: 316  | total loss: [1m[32m0.08999[0m[0m | time: 299.038s
[2K
| Adam | epoch: 006 | loss: 0.08999 - acc: 0.9737 -- iter: 1152/1779
[A[ATraining Step: 317  | total loss: [1m[32m0.08885[0m[0m | time: 307.614s
[2K
| Adam | epoch: 006 | loss: 0.08885 - acc: 0.9732 -- iter: 1184/1779
[A[ATraining Step: 318  | total loss: [1m[32m0.08598[0m[0m | time: 315.942s
[2K
| Adam | epoch: 006 | loss: 0.08598 - acc: 0.9728 -- iter: 1216/1779
[A[ATraining Step: 319  | total loss: [1m[32m0.08101[0m[0m | time: 324.467s
[2K
| Adam | epoch: 006 | loss: 0.08101 - acc: 0.9724 -- iter: 1248/1779
[A[ATraining Step: 320  | total loss: [1m[32m0.11493[0m[0m | time: 332.820s
[2K
| Adam | epoch: 006 | loss: 0.11493 - acc: 0.9689 -- iter: 1280/1779
[A[ATraining Step: 321  | total loss: [1m[32m0.10423[0m[0m | time: 341.131s
[2K
| Adam | epoch: 006 | loss: 0.10423 - acc: 0.9720 -- iter: 1312/1779
[A[ATraining Step: 322  | total loss: [1m[32m0.09463[0m[0m | time: 349.543s
[2K
| Adam | epoch: 006 | loss: 0.09463 - acc: 0.9748 -- iter: 1344/1779
[A[ATraining Step: 323  | total loss: [1m[32m0.08881[0m[0m | time: 358.291s
[2K
| Adam | epoch: 006 | loss: 0.08881 - acc: 0.9742 -- iter: 1376/1779
[A[ATraining Step: 324  | total loss: [1m[32m0.08064[0m[0m | time: 366.711s
[2K
| Adam | epoch: 006 | loss: 0.08064 - acc: 0.9768 -- iter: 1408/1779
[A[ATraining Step: 325  | total loss: [1m[32m0.08890[0m[0m | time: 375.400s
[2K
| Adam | epoch: 006 | loss: 0.08890 - acc: 0.9760 -- iter: 1440/1779
[A[ATraining Step: 326  | total loss: [1m[32m0.10546[0m[0m | time: 384.083s
[2K
| Adam | epoch: 006 | loss: 0.10546 - acc: 0.9721 -- iter: 1472/1779
[A[ATraining Step: 327  | total loss: [1m[32m0.09829[0m[0m | time: 392.424s
[2K
| Adam | epoch: 006 | loss: 0.09829 - acc: 0.9749 -- iter: 1504/1779
[A[ATraining Step: 328  | total loss: [1m[32m0.09168[0m[0m | time: 400.915s
[2K
| Adam | epoch: 006 | loss: 0.09168 - acc: 0.9774 -- iter: 1536/1779
[A[ATraining Step: 329  | total loss: [1m[32m0.09067[0m[0m | time: 409.368s
[2K
| Adam | epoch: 006 | loss: 0.09067 - acc: 0.9765 -- iter: 1568/1779
[A[ATraining Step: 330  | total loss: [1m[32m0.10043[0m[0m | time: 417.823s
[2K
| Adam | epoch: 006 | loss: 0.10043 - acc: 0.9758 -- iter: 1600/1779
[A[ATraining Step: 331  | total loss: [1m[32m0.09208[0m[0m | time: 426.305s
[2K
| Adam | epoch: 006 | loss: 0.09208 - acc: 0.9782 -- iter: 1632/1779
[A[ATraining Step: 332  | total loss: [1m[32m0.08478[0m[0m | time: 434.817s
[2K
| Adam | epoch: 006 | loss: 0.08478 - acc: 0.9804 -- iter: 1664/1779
[A[ATraining Step: 333  | total loss: [1m[32m0.09656[0m[0m | time: 443.100s
[2K
| Adam | epoch: 006 | loss: 0.09656 - acc: 0.9761 -- iter: 1696/1779
[A[ATraining Step: 334  | total loss: [1m[32m0.08903[0m[0m | time: 451.535s
[2K
| Adam | epoch: 006 | loss: 0.08903 - acc: 0.9785 -- iter: 1728/1779
[A[ATraining Step: 335  | total loss: [1m[32m0.08202[0m[0m | time: 459.985s
[2K
| Adam | epoch: 006 | loss: 0.08202 - acc: 0.9806 -- iter: 1760/1779
[A[ATraining Step: 336  | total loss: [1m[32m0.11417[0m[0m | time: 494.509s
[2K
| Adam | epoch: 006 | loss: 0.11417 - acc: 0.9763 | val_loss: 4.90899 - val_acc: 0.5081 -- iter: 1779/1779
--
Training Step: 337  | total loss: [1m[32m0.10951[0m[0m | time: 8.722s
[2K
| Adam | epoch: 007 | loss: 0.10951 - acc: 0.9756 -- iter: 0032/1779
[A[ATraining Step: 338  | total loss: [1m[32m0.10027[0m[0m | time: 17.317s
[2K
| Adam | epoch: 007 | loss: 0.10027 - acc: 0.9780 -- iter: 0064/1779
[A[ATraining Step: 339  | total loss: [1m[32m0.09538[0m[0m | time: 25.713s
[2K
| Adam | epoch: 007 | loss: 0.09538 - acc: 0.9771 -- iter: 0096/1779
[A[ATraining Step: 340  | total loss: [1m[32m0.10803[0m[0m | time: 34.076s
[2K
| Adam | epoch: 007 | loss: 0.10803 - acc: 0.9762 -- iter: 0128/1779
[A[ATraining Step: 341  | total loss: [1m[32m0.09887[0m[0m | time: 39.575s
[2K
| Adam | epoch: 007 | loss: 0.09887 - acc: 0.9786 -- iter: 0160/1779
[A[ATraining Step: 342  | total loss: [1m[32m0.10812[0m[0m | time: 45.189s
[2K
| Adam | epoch: 007 | loss: 0.10812 - acc: 0.9755 -- iter: 0192/1779
[A[ATraining Step: 343  | total loss: [1m[32m0.09926[0m[0m | time: 53.668s
[2K
| Adam | epoch: 007 | loss: 0.09926 - acc: 0.9779 -- iter: 0224/1779
[A[ATraining Step: 344  | total loss: [1m[32m0.11441[0m[0m | time: 61.913s
[2K
| Adam | epoch: 007 | loss: 0.11441 - acc: 0.9770 -- iter: 0256/1779
[A[ATraining Step: 345  | total loss: [1m[32m0.10588[0m[0m | time: 70.187s
[2K
| Adam | epoch: 007 | loss: 0.10588 - acc: 0.9762 -- iter: 0288/1779
[A[ATraining Step: 346  | total loss: [1m[32m0.10127[0m[0m | time: 78.548s
[2K
| Adam | epoch: 007 | loss: 0.10127 - acc: 0.9755 -- iter: 0320/1779
[A[ATraining Step: 347  | total loss: [1m[32m0.09283[0m[0m | time: 87.039s
[2K
| Adam | epoch: 007 | loss: 0.09283 - acc: 0.9779 -- iter: 0352/1779
[A[ATraining Step: 348  | total loss: [1m[32m0.08688[0m[0m | time: 95.536s
[2K
| Adam | epoch: 007 | loss: 0.08688 - acc: 0.9770 -- iter: 0384/1779
[A[ATraining Step: 349  | total loss: [1m[32m0.08001[0m[0m | time: 103.812s
[2K
| Adam | epoch: 007 | loss: 0.08001 - acc: 0.9793 -- iter: 0416/1779
[A[ATraining Step: 350  | total loss: [1m[32m0.08903[0m[0m | time: 112.387s
[2K
| Adam | epoch: 007 | loss: 0.08903 - acc: 0.9782 -- iter: 0448/1779
[A[ATraining Step: 351  | total loss: [1m[32m0.08525[0m[0m | time: 121.160s
[2K
| Adam | epoch: 007 | loss: 0.08525 - acc: 0.9773 -- iter: 0480/1779
[A[ATraining Step: 352  | total loss: [1m[32m0.08193[0m[0m | time: 129.649s
[2K
| Adam | epoch: 007 | loss: 0.08193 - acc: 0.9764 -- iter: 0512/1779
[A[ATraining Step: 353  | total loss: [1m[32m0.07442[0m[0m | time: 137.990s
[2K
| Adam | epoch: 007 | loss: 0.07442 - acc: 0.9788 -- iter: 0544/1779
[A[ATraining Step: 354  | total loss: [1m[32m0.07793[0m[0m | time: 146.601s
[2K
| Adam | epoch: 007 | loss: 0.07793 - acc: 0.9747 -- iter: 0576/1779
[A[ATraining Step: 355  | total loss: [1m[32m0.07947[0m[0m | time: 154.870s
[2K
| Adam | epoch: 007 | loss: 0.07947 - acc: 0.9741 -- iter: 0608/1779
[A[ATraining Step: 356  | total loss: [1m[32m0.08471[0m[0m | time: 163.452s
[2K
| Adam | epoch: 007 | loss: 0.08471 - acc: 0.9735 -- iter: 0640/1779
[A[ATraining Step: 357  | total loss: [1m[32m0.08399[0m[0m | time: 171.735s
[2K
| Adam | epoch: 007 | loss: 0.08399 - acc: 0.9731 -- iter: 0672/1779
[A[ATraining Step: 358  | total loss: [1m[32m0.07993[0m[0m | time: 180.244s
[2K
| Adam | epoch: 007 | loss: 0.07993 - acc: 0.9758 -- iter: 0704/1779
[A[ATraining Step: 359  | total loss: [1m[32m0.07295[0m[0m | time: 188.704s
[2K
| Adam | epoch: 007 | loss: 0.07295 - acc: 0.9782 -- iter: 0736/1779
[A[ATraining Step: 360  | total loss: [1m[32m0.06942[0m[0m | time: 196.999s
[2K
| Adam | epoch: 007 | loss: 0.06942 - acc: 0.9804 -- iter: 0768/1779
[A[ATraining Step: 361  | total loss: [1m[32m0.06608[0m[0m | time: 205.554s
[2K
| Adam | epoch: 007 | loss: 0.06608 - acc: 0.9823 -- iter: 0800/1779
[A[ATraining Step: 362  | total loss: [1m[32m0.06938[0m[0m | time: 214.074s
[2K
| Adam | epoch: 007 | loss: 0.06938 - acc: 0.9841 -- iter: 0832/1779
[A[ATraining Step: 363  | total loss: [1m[32m0.06570[0m[0m | time: 222.892s
[2K
| Adam | epoch: 007 | loss: 0.06570 - acc: 0.9857 -- iter: 0864/1779
[A[ATraining Step: 364  | total loss: [1m[32m0.06749[0m[0m | time: 231.342s
[2K
| Adam | epoch: 007 | loss: 0.06749 - acc: 0.9840 -- iter: 0896/1779
[A[ATraining Step: 365  | total loss: [1m[32m0.11968[0m[0m | time: 240.059s
[2K
| Adam | epoch: 007 | loss: 0.11968 - acc: 0.9793 -- iter: 0928/1779
[A[ATraining Step: 366  | total loss: [1m[32m0.12195[0m[0m | time: 248.412s
[2K
| Adam | epoch: 007 | loss: 0.12195 - acc: 0.9720 -- iter: 0960/1779
[A[ATraining Step: 367  | total loss: [1m[32m0.13435[0m[0m | time: 256.807s
[2K
| Adam | epoch: 007 | loss: 0.13435 - acc: 0.9717 -- iter: 0992/1779
[A[ATraining Step: 368  | total loss: [1m[32m0.12312[0m[0m | time: 265.189s
[2K
| Adam | epoch: 007 | loss: 0.12312 - acc: 0.9745 -- iter: 1024/1779
[A[ATraining Step: 369  | total loss: [1m[32m0.11276[0m[0m | time: 273.626s
[2K
| Adam | epoch: 007 | loss: 0.11276 - acc: 0.9771 -- iter: 1056/1779
[A[ATraining Step: 370  | total loss: [1m[32m0.10230[0m[0m | time: 282.297s
[2K
| Adam | epoch: 007 | loss: 0.10230 - acc: 0.9794 -- iter: 1088/1779
[A[ATraining Step: 371  | total loss: [1m[32m0.09289[0m[0m | time: 290.719s
[2K
| Adam | epoch: 007 | loss: 0.09289 - acc: 0.9814 -- iter: 1120/1779
[A[ATraining Step: 372  | total loss: [1m[32m0.09082[0m[0m | time: 299.270s
[2K
| Adam | epoch: 007 | loss: 0.09082 - acc: 0.9802 -- iter: 1152/1779
[A[ATraining Step: 373  | total loss: [1m[32m0.08319[0m[0m | time: 307.520s
[2K
| Adam | epoch: 007 | loss: 0.08319 - acc: 0.9821 -- iter: 1184/1779
[A[ATraining Step: 374  | total loss: [1m[32m0.07711[0m[0m | time: 316.035s
[2K
| Adam | epoch: 007 | loss: 0.07711 - acc: 0.9839 -- iter: 1216/1779
[A[ATraining Step: 375  | total loss: [1m[32m0.08832[0m[0m | time: 324.587s
[2K
| Adam | epoch: 007 | loss: 0.08832 - acc: 0.9793 -- iter: 1248/1779
[A[ATraining Step: 376  | total loss: [1m[32m0.10709[0m[0m | time: 333.232s
[2K
| Adam | epoch: 007 | loss: 0.10709 - acc: 0.9626 -- iter: 1280/1779
[A[ATraining Step: 377  | total loss: [1m[32m0.10222[0m[0m | time: 341.904s
[2K
| Adam | epoch: 007 | loss: 0.10222 - acc: 0.9632 -- iter: 1312/1779
[A[ATraining Step: 378  | total loss: [1m[32m0.09289[0m[0m | time: 350.619s
[2K
| Adam | epoch: 007 | loss: 0.09289 - acc: 0.9669 -- iter: 1344/1779
[A[ATraining Step: 379  | total loss: [1m[32m0.09851[0m[0m | time: 359.121s
[2K
| Adam | epoch: 007 | loss: 0.09851 - acc: 0.9671 -- iter: 1376/1779
[A[ATraining Step: 380  | total loss: [1m[32m0.09092[0m[0m | time: 367.328s
[2K
| Adam | epoch: 007 | loss: 0.09092 - acc: 0.9704 -- iter: 1408/1779
[A[ATraining Step: 381  | total loss: [1m[32m0.11763[0m[0m | time: 376.022s
[2K
| Adam | epoch: 007 | loss: 0.11763 - acc: 0.9702 -- iter: 1440/1779
[A[ATraining Step: 382  | total loss: [1m[32m0.10748[0m[0m | time: 384.335s
[2K
| Adam | epoch: 007 | loss: 0.10748 - acc: 0.9732 -- iter: 1472/1779
[A[ATraining Step: 383  | total loss: [1m[32m0.10200[0m[0m | time: 392.603s
[2K
| Adam | epoch: 007 | loss: 0.10200 - acc: 0.9728 -- iter: 1504/1779
[A[ATraining Step: 384  | total loss: [1m[32m0.09298[0m[0m | time: 400.877s
[2K
| Adam | epoch: 007 | loss: 0.09298 - acc: 0.9755 -- iter: 1536/1779
[A[ATraining Step: 385  | total loss: [1m[32m0.08416[0m[0m | time: 409.183s
[2K
| Adam | epoch: 007 | loss: 0.08416 - acc: 0.9779 -- iter: 1568/1779
[A[ATraining Step: 386  | total loss: [1m[32m0.10193[0m[0m | time: 417.573s
[2K
| Adam | epoch: 007 | loss: 0.10193 - acc: 0.9770 -- iter: 1600/1779
[A[ATraining Step: 387  | total loss: [1m[32m0.09388[0m[0m | time: 426.033s
[2K
| Adam | epoch: 007 | loss: 0.09388 - acc: 0.9793 -- iter: 1632/1779
[A[ATraining Step: 388  | total loss: [1m[32m0.08969[0m[0m | time: 434.579s
[2K
| Adam | epoch: 007 | loss: 0.08969 - acc: 0.9814 -- iter: 1664/1779
[A[ATraining Step: 389  | total loss: [1m[32m0.08374[0m[0m | time: 443.058s
[2K
| Adam | epoch: 007 | loss: 0.08374 - acc: 0.9832 -- iter: 1696/1779
[A[ATraining Step: 390  | total loss: [1m[32m0.07873[0m[0m | time: 451.498s
[2K
| Adam | epoch: 007 | loss: 0.07873 - acc: 0.9849 -- iter: 1728/1779
[A[ATraining Step: 391  | total loss: [1m[32m0.07147[0m[0m | time: 459.868s
[2K
| Adam | epoch: 007 | loss: 0.07147 - acc: 0.9864 -- iter: 1760/1779
[A[ATraining Step: 392  | total loss: [1m[32m0.09825[0m[0m | time: 494.684s
[2K
| Adam | epoch: 007 | loss: 0.09825 - acc: 0.9815 | val_loss: 5.19591 - val_acc: 0.5099 -- iter: 1779/1779
--
Training Step: 393  | total loss: [1m[32m0.09092[0m[0m | time: 8.594s
[2K
| Adam | epoch: 008 | loss: 0.09092 - acc: 0.9834 -- iter: 0032/1779
[A[ATraining Step: 394  | total loss: [1m[32m0.08477[0m[0m | time: 17.180s
[2K
| Adam | epoch: 008 | loss: 0.08477 - acc: 0.9850 -- iter: 0064/1779
[A[ATraining Step: 395  | total loss: [1m[32m0.07880[0m[0m | time: 25.594s
[2K
| Adam | epoch: 008 | loss: 0.07880 - acc: 0.9865 -- iter: 0096/1779
[A[ATraining Step: 396  | total loss: [1m[32m0.09176[0m[0m | time: 34.122s
[2K
| Adam | epoch: 008 | loss: 0.09176 - acc: 0.9816 -- iter: 0128/1779
[A[ATraining Step: 397  | total loss: [1m[32m0.08996[0m[0m | time: 42.638s
[2K
| Adam | epoch: 008 | loss: 0.08996 - acc: 0.9803 -- iter: 0160/1779
[A[ATraining Step: 398  | total loss: [1m[32m0.08175[0m[0m | time: 48.324s
[2K
| Adam | epoch: 008 | loss: 0.08175 - acc: 0.9823 -- iter: 0192/1779
[A[ATraining Step: 399  | total loss: [1m[32m0.08303[0m[0m | time: 53.916s
[2K
| Adam | epoch: 008 | loss: 0.08303 - acc: 0.9788 -- iter: 0224/1779
[A[ATraining Step: 400  | total loss: [1m[32m0.07518[0m[0m | time: 88.371s
[2K
| Adam | epoch: 008 | loss: 0.07518 - acc: 0.9809 | val_loss: 1.26949 - val_acc: 0.6912 -- iter: 0256/1779
--
Training Step: 401  | total loss: [1m[32m0.07039[0m[0m | time: 97.371s
[2K
| Adam | epoch: 008 | loss: 0.07039 - acc: 0.9828 -- iter: 0288/1779
[A[ATraining Step: 402  | total loss: [1m[32m0.06483[0m[0m | time: 105.841s
[2K
| Adam | epoch: 008 | loss: 0.06483 - acc: 0.9846 -- iter: 0320/1779
[A[ATraining Step: 403  | total loss: [1m[32m0.05908[0m[0m | time: 114.915s
[2K
| Adam | epoch: 008 | loss: 0.05908 - acc: 0.9861 -- iter: 0352/1779
[A[ATraining Step: 404  | total loss: [1m[32m0.07261[0m[0m | time: 123.193s
[2K
| Adam | epoch: 008 | loss: 0.07261 - acc: 0.9844 -- iter: 0384/1779
[A[ATraining Step: 405  | total loss: [1m[32m0.06658[0m[0m | time: 131.564s
[2K
| Adam | epoch: 008 | loss: 0.06658 - acc: 0.9859 -- iter: 0416/1779
[A[ATraining Step: 406  | total loss: [1m[32m0.06082[0m[0m | time: 140.043s
[2K
| Adam | epoch: 008 | loss: 0.06082 - acc: 0.9873 -- iter: 0448/1779
[A[ATraining Step: 407  | total loss: [1m[32m0.10771[0m[0m | time: 148.823s
[2K
| Adam | epoch: 008 | loss: 0.10771 - acc: 0.9824 -- iter: 0480/1779
[A[ATraining Step: 408  | total loss: [1m[32m0.10731[0m[0m | time: 157.287s
[2K
| Adam | epoch: 008 | loss: 0.10731 - acc: 0.9779 -- iter: 0512/1779
[A[ATraining Step: 409  | total loss: [1m[32m0.09958[0m[0m | time: 165.707s
[2K
| Adam | epoch: 008 | loss: 0.09958 - acc: 0.9801 -- iter: 0544/1779
[A[ATraining Step: 410  | total loss: [1m[32m0.11044[0m[0m | time: 174.091s
[2K
| Adam | epoch: 008 | loss: 0.11044 - acc: 0.9758 -- iter: 0576/1779
[A[ATraining Step: 411  | total loss: [1m[32m0.11629[0m[0m | time: 182.450s
[2K
| Adam | epoch: 008 | loss: 0.11629 - acc: 0.9751 -- iter: 0608/1779
[A[ATraining Step: 412  | total loss: [1m[32m0.10835[0m[0m | time: 190.736s
[2K
| Adam | epoch: 008 | loss: 0.10835 - acc: 0.9745 -- iter: 0640/1779
[A[ATraining Step: 413  | total loss: [1m[32m0.15570[0m[0m | time: 199.315s
[2K
| Adam | epoch: 008 | loss: 0.15570 - acc: 0.9583 -- iter: 0672/1779
[A[ATraining Step: 414  | total loss: [1m[32m0.16411[0m[0m | time: 207.683s
[2K
| Adam | epoch: 008 | loss: 0.16411 - acc: 0.9593 -- iter: 0704/1779
[A[ATraining Step: 415  | total loss: [1m[32m0.14795[0m[0m | time: 216.268s
[2K
| Adam | epoch: 008 | loss: 0.14795 - acc: 0.9634 -- iter: 0736/1779
[A[ATraining Step: 416  | total loss: [1m[32m0.13459[0m[0m | time: 224.729s
[2K
| Adam | epoch: 008 | loss: 0.13459 - acc: 0.9671 -- iter: 0768/1779
[A[ATraining Step: 417  | total loss: [1m[32m0.12904[0m[0m | time: 233.116s
[2K
| Adam | epoch: 008 | loss: 0.12904 - acc: 0.9672 -- iter: 0800/1779
[A[ATraining Step: 418  | total loss: [1m[32m0.11834[0m[0m | time: 241.589s
[2K
| Adam | epoch: 008 | loss: 0.11834 - acc: 0.9705 -- iter: 0832/1779
[A[ATraining Step: 419  | total loss: [1m[32m0.10717[0m[0m | time: 250.060s
[2K
| Adam | epoch: 008 | loss: 0.10717 - acc: 0.9735 -- iter: 0864/1779
[A[ATraining Step: 420  | total loss: [1m[32m0.14207[0m[0m | time: 258.671s
[2K
| Adam | epoch: 008 | loss: 0.14207 - acc: 0.9636 -- iter: 0896/1779
[A[ATraining Step: 421  | total loss: [1m[32m0.13249[0m[0m | time: 267.021s
[2K
| Adam | epoch: 008 | loss: 0.13249 - acc: 0.9641 -- iter: 0928/1779
[A[ATraining Step: 422  | total loss: [1m[32m0.13288[0m[0m | time: 275.168s
[2K
| Adam | epoch: 008 | loss: 0.13288 - acc: 0.9615 -- iter: 0960/1779
[A[ATraining Step: 423  | total loss: [1m[32m0.12009[0m[0m | time: 283.803s
[2K
| Adam | epoch: 008 | loss: 0.12009 - acc: 0.9653 -- iter: 0992/1779
[A[ATraining Step: 424  | total loss: [1m[32m0.12244[0m[0m | time: 292.445s
[2K
| Adam | epoch: 008 | loss: 0.12244 - acc: 0.9657 -- iter: 1024/1779
[A[ATraining Step: 425  | total loss: [1m[32m0.11284[0m[0m | time: 301.205s
[2K
| Adam | epoch: 008 | loss: 0.11284 - acc: 0.9691 -- iter: 1056/1779
[A[ATraining Step: 426  | total loss: [1m[32m0.10382[0m[0m | time: 309.388s
[2K
| Adam | epoch: 008 | loss: 0.10382 - acc: 0.9722 -- iter: 1088/1779
[A[ATraining Step: 427  | total loss: [1m[32m0.09395[0m[0m | time: 318.009s
[2K
| Adam | epoch: 008 | loss: 0.09395 - acc: 0.9750 -- iter: 1120/1779
[A[ATraining Step: 428  | total loss: [1m[32m0.09725[0m[0m | time: 326.514s
[2K
| Adam | epoch: 008 | loss: 0.09725 - acc: 0.9712 -- iter: 1152/1779
[A[ATraining Step: 429  | total loss: [1m[32m0.09272[0m[0m | time: 334.726s
[2K
| Adam | epoch: 008 | loss: 0.09272 - acc: 0.9710 -- iter: 1184/1779
[A[ATraining Step: 430  | total loss: [1m[32m0.08485[0m[0m | time: 343.160s
[2K
| Adam | epoch: 008 | loss: 0.08485 - acc: 0.9739 -- iter: 1216/1779
[A[ATraining Step: 431  | total loss: [1m[32m0.07824[0m[0m | time: 351.743s
[2K
| Adam | epoch: 008 | loss: 0.07824 - acc: 0.9765 -- iter: 1248/1779
[A[ATraining Step: 432  | total loss: [1m[32m0.07274[0m[0m | time: 360.362s
[2K
| Adam | epoch: 008 | loss: 0.07274 - acc: 0.9788 -- iter: 1280/1779
[A[ATraining Step: 433  | total loss: [1m[32m0.06655[0m[0m | time: 368.539s
[2K
| Adam | epoch: 008 | loss: 0.06655 - acc: 0.9810 -- iter: 1312/1779
[A[ATraining Step: 434  | total loss: [1m[32m0.06463[0m[0m | time: 377.212s
[2K
| Adam | epoch: 008 | loss: 0.06463 - acc: 0.9797 -- iter: 1344/1779
[A[ATraining Step: 435  | total loss: [1m[32m0.06224[0m[0m | time: 385.884s
[2K
| Adam | epoch: 008 | loss: 0.06224 - acc: 0.9786 -- iter: 1376/1779
[A[ATraining Step: 436  | total loss: [1m[32m0.05899[0m[0m | time: 394.444s
[2K
| Adam | epoch: 008 | loss: 0.05899 - acc: 0.9808 -- iter: 1408/1779
[A[ATraining Step: 437  | total loss: [1m[32m0.05967[0m[0m | time: 403.035s
[2K
| Adam | epoch: 008 | loss: 0.05967 - acc: 0.9796 -- iter: 1440/1779
[A[ATraining Step: 438  | total loss: [1m[32m0.07229[0m[0m | time: 411.604s
[2K
| Adam | epoch: 008 | loss: 0.07229 - acc: 0.9722 -- iter: 1472/1779
[A[ATraining Step: 439  | total loss: [1m[32m0.06658[0m[0m | time: 420.226s
[2K
| Adam | epoch: 008 | loss: 0.06658 - acc: 0.9750 -- iter: 1504/1779
[A[ATraining Step: 440  | total loss: [1m[32m0.06063[0m[0m | time: 428.733s
[2K
| Adam | epoch: 008 | loss: 0.06063 - acc: 0.9775 -- iter: 1536/1779
[A[ATraining Step: 441  | total loss: [1m[32m0.06430[0m[0m | time: 437.329s
[2K
| Adam | epoch: 008 | loss: 0.06430 - acc: 0.9766 -- iter: 1568/1779
[A[ATraining Step: 442  | total loss: [1m[32m0.05912[0m[0m | time: 445.665s
[2K
| Adam | epoch: 008 | loss: 0.05912 - acc: 0.9790 -- iter: 1600/1779
[A[ATraining Step: 443  | total loss: [1m[32m0.06213[0m[0m | time: 454.451s
[2K
| Adam | epoch: 008 | loss: 0.06213 - acc: 0.9748 -- iter: 1632/1779
[A[ATraining Step: 444  | total loss: [1m[32m0.07102[0m[0m | time: 462.816s
[2K
| Adam | epoch: 008 | loss: 0.07102 - acc: 0.9742 -- iter: 1664/1779
[A[ATraining Step: 445  | total loss: [1m[32m0.06439[0m[0m | time: 471.363s
[2K
| Adam | epoch: 008 | loss: 0.06439 - acc: 0.9768 -- iter: 1696/1779
[A[ATraining Step: 446  | total loss: [1m[32m0.07177[0m[0m | time: 479.997s
[2K
| Adam | epoch: 008 | loss: 0.07177 - acc: 0.9760 -- iter: 1728/1779
[A[ATraining Step: 447  | total loss: [1m[32m0.06521[0m[0m | time: 488.310s
[2K
| Adam | epoch: 008 | loss: 0.06521 - acc: 0.9784 -- iter: 1760/1779
[A[ATraining Step: 448  | total loss: [1m[32m0.06433[0m[0m | time: 522.762s
[2K
| Adam | epoch: 008 | loss: 0.06433 - acc: 0.9774 | val_loss: 0.85595 - val_acc: 0.7540 -- iter: 1779/1779
--
Training Step: 449  | total loss: [1m[32m0.06574[0m[0m | time: 8.614s
[2K
| Adam | epoch: 009 | loss: 0.06574 - acc: 0.9766 -- iter: 0032/1779
[A[ATraining Step: 450  | total loss: [1m[32m0.05995[0m[0m | time: 17.152s
[2K
| Adam | epoch: 009 | loss: 0.05995 - acc: 0.9789 -- iter: 0064/1779
[A[ATraining Step: 451  | total loss: [1m[32m0.06314[0m[0m | time: 25.394s
[2K
| Adam | epoch: 009 | loss: 0.06314 - acc: 0.9779 -- iter: 0096/1779
[A[ATraining Step: 452  | total loss: [1m[32m0.05857[0m[0m | time: 33.796s
[2K
| Adam | epoch: 009 | loss: 0.05857 - acc: 0.9801 -- iter: 0128/1779
[A[ATraining Step: 453  | total loss: [1m[32m0.05386[0m[0m | time: 42.334s
[2K
| Adam | epoch: 009 | loss: 0.05386 - acc: 0.9821 -- iter: 0160/1779
[A[ATraining Step: 454  | total loss: [1m[32m0.05047[0m[0m | time: 50.820s
[2K
| Adam | epoch: 009 | loss: 0.05047 - acc: 0.9839 -- iter: 0192/1779
[A[ATraining Step: 455  | total loss: [1m[32m0.04643[0m[0m | time: 56.453s
[2K
| Adam | epoch: 009 | loss: 0.04643 - acc: 0.9855 -- iter: 0224/1779
[A[ATraining Step: 456  | total loss: [1m[32m0.07874[0m[0m | time: 62.268s
[2K
| Adam | epoch: 009 | loss: 0.07874 - acc: 0.9817 -- iter: 0256/1779
[A[ATraining Step: 457  | total loss: [1m[32m0.08982[0m[0m | time: 70.683s
[2K
| Adam | epoch: 009 | loss: 0.08982 - acc: 0.9782 -- iter: 0288/1779
[A[ATraining Step: 458  | total loss: [1m[32m0.08176[0m[0m | time: 79.373s
[2K
| Adam | epoch: 009 | loss: 0.08176 - acc: 0.9804 -- iter: 0320/1779
[A[ATraining Step: 459  | total loss: [1m[32m0.08335[0m[0m | time: 87.681s
[2K
| Adam | epoch: 009 | loss: 0.08335 - acc: 0.9793 -- iter: 0352/1779
[A[ATraining Step: 460  | total loss: [1m[32m0.07569[0m[0m | time: 96.217s
[2K
| Adam | epoch: 009 | loss: 0.07569 - acc: 0.9813 -- iter: 0384/1779
[A[ATraining Step: 461  | total loss: [1m[32m0.10122[0m[0m | time: 104.850s
[2K
| Adam | epoch: 009 | loss: 0.10122 - acc: 0.9769 -- iter: 0416/1779
[A[ATraining Step: 462  | total loss: [1m[32m0.09422[0m[0m | time: 113.357s
[2K
| Adam | epoch: 009 | loss: 0.09422 - acc: 0.9793 -- iter: 0448/1779
[A[ATraining Step: 463  | total loss: [1m[32m0.12978[0m[0m | time: 121.704s
[2K
| Adam | epoch: 009 | loss: 0.12978 - acc: 0.9751 -- iter: 0480/1779
[A[ATraining Step: 464  | total loss: [1m[32m0.11777[0m[0m | time: 130.218s
[2K
| Adam | epoch: 009 | loss: 0.11777 - acc: 0.9776 -- iter: 0512/1779
[A[ATraining Step: 465  | total loss: [1m[32m0.11669[0m[0m | time: 138.678s
[2K
| Adam | epoch: 009 | loss: 0.11669 - acc: 0.9767 -- iter: 0544/1779
[A[ATraining Step: 466  | total loss: [1m[32m0.11473[0m[0m | time: 147.114s
[2K
| Adam | epoch: 009 | loss: 0.11473 - acc: 0.9759 -- iter: 0576/1779
[A[ATraining Step: 467  | total loss: [1m[32m0.10640[0m[0m | time: 155.596s
[2K
| Adam | epoch: 009 | loss: 0.10640 - acc: 0.9783 -- iter: 0608/1779
[A[ATraining Step: 468  | total loss: [1m[32m0.11318[0m[0m | time: 163.981s
[2K
| Adam | epoch: 009 | loss: 0.11318 - acc: 0.9742 -- iter: 0640/1779
[A[ATraining Step: 469  | total loss: [1m[32m0.10341[0m[0m | time: 172.306s
[2K
| Adam | epoch: 009 | loss: 0.10341 - acc: 0.9768 -- iter: 0672/1779
[A[ATraining Step: 470  | total loss: [1m[32m0.09399[0m[0m | time: 180.436s
[2K
| Adam | epoch: 009 | loss: 0.09399 - acc: 0.9791 -- iter: 0704/1779
[A[ATraining Step: 471  | total loss: [1m[32m0.08867[0m[0m | time: 188.940s
[2K
| Adam | epoch: 009 | loss: 0.08867 - acc: 0.9781 -- iter: 0736/1779
[A[ATraining Step: 472  | total loss: [1m[32m0.09077[0m[0m | time: 197.159s
[2K
| Adam | epoch: 009 | loss: 0.09077 - acc: 0.9772 -- iter: 0768/1779
[A[ATraining Step: 473  | total loss: [1m[32m0.08212[0m[0m | time: 205.795s
[2K
| Adam | epoch: 009 | loss: 0.08212 - acc: 0.9794 -- iter: 0800/1779
[A[ATraining Step: 474  | total loss: [1m[32m0.08793[0m[0m | time: 214.213s
[2K
| Adam | epoch: 009 | loss: 0.08793 - acc: 0.9752 -- iter: 0832/1779
[A[ATraining Step: 475  | total loss: [1m[32m0.08609[0m[0m | time: 222.645s
[2K
| Adam | epoch: 009 | loss: 0.08609 - acc: 0.9777 -- iter: 0864/1779
[A[ATraining Step: 476  | total loss: [1m[32m0.07867[0m[0m | time: 231.292s
[2K
| Adam | epoch: 009 | loss: 0.07867 - acc: 0.9799 -- iter: 0896/1779
[A[ATraining Step: 477  | total loss: [1m[32m0.08094[0m[0m | time: 239.823s
[2K
| Adam | epoch: 009 | loss: 0.08094 - acc: 0.9788 -- iter: 0928/1779
[A[ATraining Step: 478  | total loss: [1m[32m0.07439[0m[0m | time: 248.218s
[2K
| Adam | epoch: 009 | loss: 0.07439 - acc: 0.9809 -- iter: 0960/1779
[A[ATraining Step: 479  | total loss: [1m[32m0.07828[0m[0m | time: 256.573s
[2K
| Adam | epoch: 009 | loss: 0.07828 - acc: 0.9797 -- iter: 0992/1779
[A[ATraining Step: 480  | total loss: [1m[32m0.07191[0m[0m | time: 264.905s
[2K
| Adam | epoch: 009 | loss: 0.07191 - acc: 0.9818 -- iter: 1024/1779
[A[ATraining Step: 481  | total loss: [1m[32m0.09716[0m[0m | time: 273.194s
[2K
| Adam | epoch: 009 | loss: 0.09716 - acc: 0.9773 -- iter: 1056/1779
[A[ATraining Step: 482  | total loss: [1m[32m0.09130[0m[0m | time: 281.774s
[2K
| Adam | epoch: 009 | loss: 0.09130 - acc: 0.9765 -- iter: 1088/1779
[A[ATraining Step: 483  | total loss: [1m[32m0.08823[0m[0m | time: 290.331s
[2K
| Adam | epoch: 009 | loss: 0.08823 - acc: 0.9757 -- iter: 1120/1779
[A[ATraining Step: 484  | total loss: [1m[32m0.07975[0m[0m | time: 298.600s
[2K
| Adam | epoch: 009 | loss: 0.07975 - acc: 0.9781 -- iter: 1152/1779
[A[ATraining Step: 485  | total loss: [1m[32m0.07253[0m[0m | time: 307.139s
[2K
| Adam | epoch: 009 | loss: 0.07253 - acc: 0.9803 -- iter: 1184/1779
[A[ATraining Step: 486  | total loss: [1m[32m0.06608[0m[0m | time: 315.622s
[2K
| Adam | epoch: 009 | loss: 0.06608 - acc: 0.9823 -- iter: 1216/1779
[A[ATraining Step: 487  | total loss: [1m[32m0.06065[0m[0m | time: 323.895s
[2K
| Adam | epoch: 009 | loss: 0.06065 - acc: 0.9841 -- iter: 1248/1779
[A[ATraining Step: 488  | total loss: [1m[32m0.05804[0m[0m | time: 332.193s
[2K
| Adam | epoch: 009 | loss: 0.05804 - acc: 0.9856 -- iter: 1280/1779
[A[ATraining Step: 489  | total loss: [1m[32m0.05377[0m[0m | time: 340.728s
[2K
| Adam | epoch: 009 | loss: 0.05377 - acc: 0.9871 -- iter: 1312/1779
[A[ATraining Step: 490  | total loss: [1m[32m0.05092[0m[0m | time: 349.195s
[2K
| Adam | epoch: 009 | loss: 0.05092 - acc: 0.9884 -- iter: 1344/1779
[A[ATraining Step: 491  | total loss: [1m[32m0.04645[0m[0m | time: 357.656s
[2K
| Adam | epoch: 009 | loss: 0.04645 - acc: 0.9895 -- iter: 1376/1779
[A[ATraining Step: 492  | total loss: [1m[32m0.04299[0m[0m | time: 366.042s
[2K
| Adam | epoch: 009 | loss: 0.04299 - acc: 0.9906 -- iter: 1408/1779
[A[ATraining Step: 493  | total loss: [1m[32m0.04023[0m[0m | time: 374.574s
[2K
| Adam | epoch: 009 | loss: 0.04023 - acc: 0.9915 -- iter: 1440/1779
[A[ATraining Step: 494  | total loss: [1m[32m0.04417[0m[0m | time: 383.370s
[2K
| Adam | epoch: 009 | loss: 0.04417 - acc: 0.9892 -- iter: 1472/1779
[A[ATraining Step: 495  | total loss: [1m[32m0.04031[0m[0m | time: 391.848s
[2K
| Adam | epoch: 009 | loss: 0.04031 - acc: 0.9903 -- iter: 1504/1779
[A[ATraining Step: 496  | total loss: [1m[32m0.06747[0m[0m | time: 400.400s
[2K
| Adam | epoch: 009 | loss: 0.06747 - acc: 0.9882 -- iter: 1536/1779
[A[ATraining Step: 497  | total loss: [1m[32m0.09353[0m[0m | time: 408.844s
[2K
| Adam | epoch: 009 | loss: 0.09353 - acc: 0.9831 -- iter: 1568/1779
[A[ATraining Step: 498  | total loss: [1m[32m0.08584[0m[0m | time: 417.333s
[2K
| Adam | epoch: 009 | loss: 0.08584 - acc: 0.9848 -- iter: 1600/1779
[A[ATraining Step: 499  | total loss: [1m[32m0.07854[0m[0m | time: 426.175s
[2K
| Adam | epoch: 009 | loss: 0.07854 - acc: 0.9863 -- iter: 1632/1779
[A[ATraining Step: 500  | total loss: [1m[32m0.07143[0m[0m | time: 434.412s
[2K
| Adam | epoch: 009 | loss: 0.07143 - acc: 0.9877 -- iter: 1664/1779
[A[ATraining Step: 501  | total loss: [1m[32m0.08846[0m[0m | time: 443.000s
[2K
| Adam | epoch: 009 | loss: 0.08846 - acc: 0.9827 -- iter: 1696/1779
[A[ATraining Step: 502  | total loss: [1m[32m0.11158[0m[0m | time: 451.596s
[2K
| Adam | epoch: 009 | loss: 0.11158 - acc: 0.9813 -- iter: 1728/1779
[A[ATraining Step: 503  | total loss: [1m[32m0.10138[0m[0m | time: 460.005s
[2K
| Adam | epoch: 009 | loss: 0.10138 - acc: 0.9831 -- iter: 1760/1779
[A[ATraining Step: 504  | total loss: [1m[32m0.09188[0m[0m | time: 494.401s
[2K
| Adam | epoch: 009 | loss: 0.09188 - acc: 0.9848 | val_loss: 1.95860 - val_acc: 0.5871 -- iter: 1779/1779
--
Training Step: 505  | total loss: [1m[32m0.08733[0m[0m | time: 8.520s
[2K
| Adam | epoch: 010 | loss: 0.08733 - acc: 0.9832 -- iter: 0032/1779
[A[ATraining Step: 506  | total loss: [1m[32m0.07966[0m[0m | time: 16.974s
[2K
| Adam | epoch: 010 | loss: 0.07966 - acc: 0.9849 -- iter: 0064/1779
[A[ATraining Step: 507  | total loss: [1m[32m0.07225[0m[0m | time: 25.550s
[2K
| Adam | epoch: 010 | loss: 0.07225 - acc: 0.9864 -- iter: 0096/1779
[A[ATraining Step: 508  | total loss: [1m[32m0.06654[0m[0m | time: 33.930s
[2K
| Adam | epoch: 010 | loss: 0.06654 - acc: 0.9878 -- iter: 0128/1779
[A[ATraining Step: 509  | total loss: [1m[32m0.06656[0m[0m | time: 42.349s
[2K
| Adam | epoch: 010 | loss: 0.06656 - acc: 0.9859 -- iter: 0160/1779
[A[ATraining Step: 510  | total loss: [1m[32m0.06291[0m[0m | time: 50.587s
[2K
| Adam | epoch: 010 | loss: 0.06291 - acc: 0.9873 -- iter: 0192/1779
[A[ATraining Step: 511  | total loss: [1m[32m0.05724[0m[0m | time: 58.988s
[2K
| Adam | epoch: 010 | loss: 0.05724 - acc: 0.9886 -- iter: 0224/1779
[A[ATraining Step: 512  | total loss: [1m[32m0.05226[0m[0m | time: 64.524s
[2K
| Adam | epoch: 010 | loss: 0.05226 - acc: 0.9897 -- iter: 0256/1779
[A[ATraining Step: 513  | total loss: [1m[32m0.04843[0m[0m | time: 70.206s
[2K
| Adam | epoch: 010 | loss: 0.04843 - acc: 0.9907 -- iter: 0288/1779
[A[ATraining Step: 514  | total loss: [1m[32m0.04430[0m[0m | time: 78.920s
[2K
| Adam | epoch: 010 | loss: 0.04430 - acc: 0.9917 -- iter: 0320/1779
[A[ATraining Step: 515  | total loss: [1m[32m0.05000[0m[0m | time: 87.509s
[2K
| Adam | epoch: 010 | loss: 0.05000 - acc: 0.9894 -- iter: 0352/1779
[A[ATraining Step: 516  | total loss: [1m[32m0.04620[0m[0m | time: 96.070s
[2K
| Adam | epoch: 010 | loss: 0.04620 - acc: 0.9904 -- iter: 0384/1779
[A[ATraining Step: 517  | total loss: [1m[32m0.04279[0m[0m | time: 104.669s
[2K
| Adam | epoch: 010 | loss: 0.04279 - acc: 0.9914 -- iter: 0416/1779
[A[ATraining Step: 518  | total loss: [1m[32m0.03948[0m[0m | time: 112.944s
[2K
| Adam | epoch: 010 | loss: 0.03948 - acc: 0.9922 -- iter: 0448/1779
[A[ATraining Step: 519  | total loss: [1m[32m0.03744[0m[0m | time: 121.437s
[2K
| Adam | epoch: 010 | loss: 0.03744 - acc: 0.9930 -- iter: 0480/1779
[A[ATraining Step: 520  | total loss: [1m[32m0.03386[0m[0m | time: 129.612s
[2K
| Adam | epoch: 010 | loss: 0.03386 - acc: 0.9937 -- iter: 0512/1779
[A[ATraining Step: 521  | total loss: [1m[32m0.06812[0m[0m | time: 138.350s
[2K
| Adam | epoch: 010 | loss: 0.06812 - acc: 0.9881 -- iter: 0544/1779
[A[ATraining Step: 522  | total loss: [1m[32m0.06171[0m[0m | time: 146.612s
[2K
| Adam | epoch: 010 | loss: 0.06171 - acc: 0.9893 -- iter: 0576/1779
[A[ATraining Step: 523  | total loss: [1m[32m0.05639[0m[0m | time: 155.333s
[2K
| Adam | epoch: 010 | loss: 0.05639 - acc: 0.9904 -- iter: 0608/1779
[A[ATraining Step: 524  | total loss: [1m[32m0.05915[0m[0m | time: 163.928s
[2K
| Adam | epoch: 010 | loss: 0.05915 - acc: 0.9882 -- iter: 0640/1779
[A[ATraining Step: 525  | total loss: [1m[32m0.05807[0m[0m | time: 172.252s
[2K
| Adam | epoch: 010 | loss: 0.05807 - acc: 0.9863 -- iter: 0672/1779
[A[ATraining Step: 526  | total loss: [1m[32m0.05296[0m[0m | time: 180.911s
[2K
| Adam | epoch: 010 | loss: 0.05296 - acc: 0.9876 -- iter: 0704/1779
[A[ATraining Step: 527  | total loss: [1m[32m0.05182[0m[0m | time: 189.477s
[2K
| Adam | epoch: 010 | loss: 0.05182 - acc: 0.9889 -- iter: 0736/1779
[A[ATraining Step: 528  | total loss: [1m[32m0.04728[0m[0m | time: 197.926s
[2K
| Adam | epoch: 010 | loss: 0.04728 - acc: 0.9900 -- iter: 0768/1779
[A[ATraining Step: 529  | total loss: [1m[32m0.05402[0m[0m | time: 206.563s
[2K
| Adam | epoch: 010 | loss: 0.05402 - acc: 0.9879 -- iter: 0800/1779
[A[ATraining Step: 530  | total loss: [1m[32m0.04907[0m[0m | time: 215.198s
[2K
| Adam | epoch: 010 | loss: 0.04907 - acc: 0.9891 -- iter: 0832/1779
[A[ATraining Step: 531  | total loss: [1m[32m0.04851[0m[0m | time: 223.796s
[2K
| Adam | epoch: 010 | loss: 0.04851 - acc: 0.9902 -- iter: 0864/1779
[A[ATraining Step: 532  | total loss: [1m[32m0.04498[0m[0m | time: 232.296s
[2K
| Adam | epoch: 010 | loss: 0.04498 - acc: 0.9911 -- iter: 0896/1779
[A[ATraining Step: 533  | total loss: [1m[32m0.04147[0m[0m | time: 241.721s
[2K
| Adam | epoch: 010 | loss: 0.04147 - acc: 0.9920 -- iter: 0928/1779
[A[ATraining Step: 534  | total loss: [1m[32m0.03815[0m[0m | time: 251.654s
[2K
| Adam | epoch: 010 | loss: 0.03815 - acc: 0.9928 -- iter: 0960/1779
[A[ATraining Step: 535  | total loss: [1m[32m0.03721[0m[0m | time: 261.382s
[2K
| Adam | epoch: 010 | loss: 0.03721 - acc: 0.9935 -- iter: 0992/1779
[A[ATraining Step: 536  | total loss: [1m[32m0.03483[0m[0m | time: 270.600s
[2K
| Adam | epoch: 010 | loss: 0.03483 - acc: 0.9942 -- iter: 1024/1779
[A[ATraining Step: 537  | total loss: [1m[32m0.03692[0m[0m | time: 279.838s
[2K
| Adam | epoch: 010 | loss: 0.03692 - acc: 0.9916 -- iter: 1056/1779
[A[ATraining Step: 538  | total loss: [1m[32m0.05441[0m[0m | time: 289.609s
[2K
| Adam | epoch: 010 | loss: 0.05441 - acc: 0.9894 -- iter: 1088/1779
[A[ATraining Step: 539  | total loss: [1m[32m0.05519[0m[0m | time: 299.550s
[2K
| Adam | epoch: 010 | loss: 0.05519 - acc: 0.9873 -- iter: 1120/1779
[A[ATraining Step: 540  | total loss: [1m[32m0.05330[0m[0m | time: 309.376s
[2K
| Adam | epoch: 010 | loss: 0.05330 - acc: 0.9854 -- iter: 1152/1779
[A[ATraining Step: 541  | total loss: [1m[32m0.04977[0m[0m | time: 318.923s
[2K
| Adam | epoch: 010 | loss: 0.04977 - acc: 0.9869 -- iter: 1184/1779
[A[ATraining Step: 542  | total loss: [1m[32m0.06171[0m[0m | time: 328.436s
[2K
| Adam | epoch: 010 | loss: 0.06171 - acc: 0.9851 -- iter: 1216/1779
[A[ATraining Step: 543  | total loss: [1m[32m0.05712[0m[0m | time: 338.053s
[2K
| Adam | epoch: 010 | loss: 0.05712 - acc: 0.9866 -- iter: 1248/1779
[A[ATraining Step: 544  | total loss: [1m[32m0.05284[0m[0m | time: 347.918s
[2K
| Adam | epoch: 010 | loss: 0.05284 - acc: 0.9879 -- iter: 1280/1779
[A[ATraining Step: 545  | total loss: [1m[32m0.04808[0m[0m | time: 357.399s
[2K
| Adam | epoch: 010 | loss: 0.04808 - acc: 0.9891 -- iter: 1312/1779
[A[ATraining Step: 546  | total loss: [1m[32m0.06279[0m[0m | time: 366.717s
[2K
| Adam | epoch: 010 | loss: 0.06279 - acc: 0.9871 -- iter: 1344/1779
[A[ATraining Step: 547  | total loss: [1m[32m0.07588[0m[0m | time: 375.300s
[2K
| Adam | epoch: 010 | loss: 0.07588 - acc: 0.9853 -- iter: 1376/1779
[A[ATraining Step: 548  | total loss: [1m[32m0.06932[0m[0m | time: 383.720s
[2K
| Adam | epoch: 010 | loss: 0.06932 - acc: 0.9867 -- iter: 1408/1779
[A[ATraining Step: 549  | total loss: [1m[32m0.08874[0m[0m | time: 392.345s
[2K
| Adam | epoch: 010 | loss: 0.08874 - acc: 0.9818 -- iter: 1440/1779
[A[ATraining Step: 550  | total loss: [1m[32m0.09095[0m[0m | time: 400.874s
[2K
| Adam | epoch: 010 | loss: 0.09095 - acc: 0.9805 -- iter: 1472/1779
[A[ATraining Step: 551  | total loss: [1m[32m0.08706[0m[0m | time: 409.222s
[2K
| Adam | epoch: 010 | loss: 0.08706 - acc: 0.9793 -- iter: 1504/1779
[A[ATraining Step: 552  | total loss: [1m[32m0.08035[0m[0m | time: 417.807s
[2K
| Adam | epoch: 010 | loss: 0.08035 - acc: 0.9814 -- iter: 1536/1779
[A[ATraining Step: 553  | total loss: [1m[32m0.07417[0m[0m | time: 426.448s
[2K
| Adam | epoch: 010 | loss: 0.07417 - acc: 0.9833 -- iter: 1568/1779
[A[ATraining Step: 554  | total loss: [1m[32m0.06737[0m[0m | time: 434.883s
[2K
| Adam | epoch: 010 | loss: 0.06737 - acc: 0.9849 -- iter: 1600/1779
[A[ATraining Step: 555  | total loss: [1m[32m0.06870[0m[0m | time: 443.466s
[2K
| Adam | epoch: 010 | loss: 0.06870 - acc: 0.9833 -- iter: 1632/1779
[A[ATraining Step: 556  | total loss: [1m[32m0.06245[0m[0m | time: 452.146s
[2K
| Adam | epoch: 010 | loss: 0.06245 - acc: 0.9850 -- iter: 1664/1779
[A[ATraining Step: 557  | total loss: [1m[32m0.05685[0m[0m | time: 460.428s
[2K
| Adam | epoch: 010 | loss: 0.05685 - acc: 0.9865 -- iter: 1696/1779
[A[ATraining Step: 558  | total loss: [1m[32m0.05190[0m[0m | time: 468.890s
[2K
| Adam | epoch: 010 | loss: 0.05190 - acc: 0.9878 -- iter: 1728/1779
[A[ATraining Step: 559  | total loss: [1m[32m0.04813[0m[0m | time: 477.412s
[2K
| Adam | epoch: 010 | loss: 0.04813 - acc: 0.9890 -- iter: 1760/1779
[A[ATraining Step: 560  | total loss: [1m[32m0.04861[0m[0m | time: 512.180s
[2K
| Adam | epoch: 010 | loss: 0.04861 - acc: 0.9870 | val_loss: 2.48991 - val_acc: 0.5691 -- iter: 1779/1779
--
Training Step: 561  | total loss: [1m[32m0.04696[0m[0m | time: 8.563s
[2K
| Adam | epoch: 011 | loss: 0.04696 - acc: 0.9883 -- iter: 0032/1779
[A[ATraining Step: 562  | total loss: [1m[32m0.04274[0m[0m | time: 17.185s
[2K
| Adam | epoch: 011 | loss: 0.04274 - acc: 0.9895 -- iter: 0064/1779
[A[ATraining Step: 563  | total loss: [1m[32m0.03946[0m[0m | time: 25.605s
[2K
| Adam | epoch: 011 | loss: 0.03946 - acc: 0.9905 -- iter: 0096/1779
[A[ATraining Step: 564  | total loss: [1m[32m0.05082[0m[0m | time: 34.268s
[2K
| Adam | epoch: 011 | loss: 0.05082 - acc: 0.9884 -- iter: 0128/1779
[A[ATraining Step: 565  | total loss: [1m[32m0.04891[0m[0m | time: 42.666s
[2K
| Adam | epoch: 011 | loss: 0.04891 - acc: 0.9864 -- iter: 0160/1779
[A[ATraining Step: 566  | total loss: [1m[32m0.07882[0m[0m | time: 51.289s
[2K
| Adam | epoch: 011 | loss: 0.07882 - acc: 0.9690 -- iter: 0192/1779
[A[ATraining Step: 567  | total loss: [1m[32m0.07604[0m[0m | time: 59.675s
[2K
| Adam | epoch: 011 | loss: 0.07604 - acc: 0.9690 -- iter: 0224/1779
[A[ATraining Step: 568  | total loss: [1m[32m0.07865[0m[0m | time: 68.251s
[2K
| Adam | epoch: 011 | loss: 0.07865 - acc: 0.9658 -- iter: 0256/1779
[A[ATraining Step: 569  | total loss: [1m[32m0.07352[0m[0m | time: 73.724s
[2K
| Adam | epoch: 011 | loss: 0.07352 - acc: 0.9693 -- iter: 0288/1779
[A[ATraining Step: 570  | total loss: [1m[32m0.06665[0m[0m | time: 79.273s
[2K
| Adam | epoch: 011 | loss: 0.06665 - acc: 0.9723 -- iter: 0320/1779
[A[ATraining Step: 571  | total loss: [1m[32m0.06038[0m[0m | time: 87.882s
[2K
| Adam | epoch: 011 | loss: 0.06038 - acc: 0.9751 -- iter: 0352/1779
[A[ATraining Step: 572  | total loss: [1m[32m0.05536[0m[0m | time: 96.342s
[2K
| Adam | epoch: 011 | loss: 0.05536 - acc: 0.9776 -- iter: 0384/1779
[A[ATraining Step: 573  | total loss: [1m[32m0.05126[0m[0m | time: 104.709s
[2K
| Adam | epoch: 011 | loss: 0.05126 - acc: 0.9798 -- iter: 0416/1779
[A[ATraining Step: 574  | total loss: [1m[32m0.05423[0m[0m | time: 113.065s
[2K
| Adam | epoch: 011 | loss: 0.05423 - acc: 0.9787 -- iter: 0448/1779
[A[ATraining Step: 575  | total loss: [1m[32m0.05093[0m[0m | time: 121.542s
[2K
| Adam | epoch: 011 | loss: 0.05093 - acc: 0.9808 -- iter: 0480/1779
[A[ATraining Step: 576  | total loss: [1m[32m0.04615[0m[0m | time: 129.903s
[2K
| Adam | epoch: 011 | loss: 0.04615 - acc: 0.9828 -- iter: 0512/1779
[A[ATraining Step: 577  | total loss: [1m[32m0.04335[0m[0m | time: 138.500s
[2K
| Adam | epoch: 011 | loss: 0.04335 - acc: 0.9845 -- iter: 0544/1779
[A[ATraining Step: 578  | total loss: [1m[32m0.03940[0m[0m | time: 147.123s
[2K
| Adam | epoch: 011 | loss: 0.03940 - acc: 0.9860 -- iter: 0576/1779
[A[ATraining Step: 579  | total loss: [1m[32m0.03720[0m[0m | time: 155.676s
[2K
| Adam | epoch: 011 | loss: 0.03720 - acc: 0.9874 -- iter: 0608/1779
[A[ATraining Step: 580  | total loss: [1m[32m0.03476[0m[0m | time: 164.167s
[2K
| Adam | epoch: 011 | loss: 0.03476 - acc: 0.9887 -- iter: 0640/1779
[A[ATraining Step: 581  | total loss: [1m[32m0.03201[0m[0m | time: 172.472s
[2K
| Adam | epoch: 011 | loss: 0.03201 - acc: 0.9898 -- iter: 0672/1779
[A[ATraining Step: 582  | total loss: [1m[32m0.03034[0m[0m | time: 180.902s
[2K
| Adam | epoch: 011 | loss: 0.03034 - acc: 0.9908 -- iter: 0704/1779
[A[ATraining Step: 583  | total loss: [1m[32m0.03362[0m[0m | time: 189.636s
[2K
| Adam | epoch: 011 | loss: 0.03362 - acc: 0.9886 -- iter: 0736/1779
[A[ATraining Step: 584  | total loss: [1m[32m0.03241[0m[0m | time: 198.211s
[2K
| Adam | epoch: 011 | loss: 0.03241 - acc: 0.9898 -- iter: 0768/1779
[A[ATraining Step: 585  | total loss: [1m[32m0.03299[0m[0m | time: 206.536s
[2K
| Adam | epoch: 011 | loss: 0.03299 - acc: 0.9877 -- iter: 0800/1779
[A[ATraining Step: 586  | total loss: [1m[32m0.03455[0m[0m | time: 214.946s
[2K
| Adam | epoch: 011 | loss: 0.03455 - acc: 0.9858 -- iter: 0832/1779
[A[ATraining Step: 587  | total loss: [1m[32m0.03288[0m[0m | time: 223.683s
[2K
| Adam | epoch: 011 | loss: 0.03288 - acc: 0.9872 -- iter: 0864/1779
[A[ATraining Step: 588  | total loss: [1m[32m0.03117[0m[0m | time: 232.066s
[2K
| Adam | epoch: 011 | loss: 0.03117 - acc: 0.9885 -- iter: 0896/1779
[A[ATraining Step: 589  | total loss: [1m[32m0.03196[0m[0m | time: 240.538s
[2K
| Adam | epoch: 011 | loss: 0.03196 - acc: 0.9896 -- iter: 0928/1779
[A[ATraining Step: 590  | total loss: [1m[32m0.03067[0m[0m | time: 248.980s
[2K
| Adam | epoch: 011 | loss: 0.03067 - acc: 0.9907 -- iter: 0960/1779
[A[ATraining Step: 591  | total loss: [1m[32m0.02813[0m[0m | time: 257.430s
[2K
| Adam | epoch: 011 | loss: 0.02813 - acc: 0.9916 -- iter: 0992/1779
[A[ATraining Step: 592  | total loss: [1m[32m0.03778[0m[0m | time: 266.050s
[2K
| Adam | epoch: 011 | loss: 0.03778 - acc: 0.9862 -- iter: 1024/1779
[A[ATraining Step: 593  | total loss: [1m[32m0.03736[0m[0m | time: 274.806s
[2K
| Adam | epoch: 011 | loss: 0.03736 - acc: 0.9844 -- iter: 1056/1779
[A[ATraining Step: 594  | total loss: [1m[32m0.03380[0m[0m | time: 283.378s
[2K
| Adam | epoch: 011 | loss: 0.03380 - acc: 0.9860 -- iter: 1088/1779
[A[ATraining Step: 595  | total loss: [1m[32m0.07897[0m[0m | time: 291.788s
[2K
| Adam | epoch: 011 | loss: 0.07897 - acc: 0.9812 -- iter: 1120/1779
[A[ATraining Step: 596  | total loss: [1m[32m0.07137[0m[0m | time: 300.297s
[2K
| Adam | epoch: 011 | loss: 0.07137 - acc: 0.9830 -- iter: 1152/1779
[A[ATraining Step: 597  | total loss: [1m[32m0.06774[0m[0m | time: 308.949s
[2K
| Adam | epoch: 011 | loss: 0.06774 - acc: 0.9816 -- iter: 1184/1779
[A[ATraining Step: 598  | total loss: [1m[32m0.06196[0m[0m | time: 317.649s
[2K
| Adam | epoch: 011 | loss: 0.06196 - acc: 0.9834 -- iter: 1216/1779
[A[ATraining Step: 599  | total loss: [1m[32m0.05598[0m[0m | time: 330.928s
[2K
| Adam | epoch: 011 | loss: 0.05598 - acc: 0.9851 -- iter: 1248/1779
[A[ATraining Step: 600  | total loss: [1m[32m0.05084[0m[0m | time: 390.637s
[2K
| Adam | epoch: 011 | loss: 0.05084 - acc: 0.9866 | val_loss: 3.83666 - val_acc: 0.5081 -- iter: 1280/1779
--
Training Step: 601  | total loss: [1m[32m0.04627[0m[0m | time: 404.807s
[2K
| Adam | epoch: 011 | loss: 0.04627 - acc: 0.9879 -- iter: 1312/1779
[A[ATraining Step: 602  | total loss: [1m[32m0.04288[0m[0m | time: 419.131s
[2K
| Adam | epoch: 011 | loss: 0.04288 - acc: 0.9891 -- iter: 1344/1779
[A[ATraining Step: 603  | total loss: [1m[32m0.03892[0m[0m | time: 432.364s
[2K
| Adam | epoch: 011 | loss: 0.03892 - acc: 0.9902 -- iter: 1376/1779
[A[ATraining Step: 604  | total loss: [1m[32m0.03545[0m[0m | time: 441.086s
[2K
| Adam | epoch: 011 | loss: 0.03545 - acc: 0.9912 -- iter: 1408/1779
[A[ATraining Step: 605  | total loss: [1m[32m0.03222[0m[0m | time: 452.705s
[2K
| Adam | epoch: 011 | loss: 0.03222 - acc: 0.9921 -- iter: 1440/1779
[A[ATraining Step: 606  | total loss: [1m[32m0.02949[0m[0m | time: 460.863s
[2K
| Adam | epoch: 011 | loss: 0.02949 - acc: 0.9929 -- iter: 1472/1779
[A[ATraining Step: 607  | total loss: [1m[32m0.04199[0m[0m | time: 469.407s
[2K
| Adam | epoch: 011 | loss: 0.04199 - acc: 0.9905 -- iter: 1504/1779
[A[ATraining Step: 608  | total loss: [1m[32m0.04174[0m[0m | time: 478.020s
[2K
| Adam | epoch: 011 | loss: 0.04174 - acc: 0.9883 -- iter: 1536/1779
[A[ATraining Step: 609  | total loss: [1m[32m0.03798[0m[0m | time: 489.276s
[2K
| Adam | epoch: 011 | loss: 0.03798 - acc: 0.9895 -- iter: 1568/1779
[A[ATraining Step: 610  | total loss: [1m[32m0.03559[0m[0m | time: 503.430s
[2K
| Adam | epoch: 011 | loss: 0.03559 - acc: 0.9905 -- iter: 1600/1779
[A[ATraining Step: 611  | total loss: [1m[32m0.04598[0m[0m | time: 518.237s
[2K
| Adam | epoch: 011 | loss: 0.04598 - acc: 0.9852 -- iter: 1632/1779
[A[ATraining Step: 612  | total loss: [1m[32m0.04159[0m[0m | time: 532.898s
[2K
| Adam | epoch: 011 | loss: 0.04159 - acc: 0.9867 -- iter: 1664/1779
[A[ATraining Step: 613  | total loss: [1m[32m0.03770[0m[0m | time: 547.445s
[2K
| Adam | epoch: 011 | loss: 0.03770 - acc: 0.9880 -- iter: 1696/1779
[A[ATraining Step: 614  | total loss: [1m[32m0.07181[0m[0m | time: 561.653s
[2K
| Adam | epoch: 011 | loss: 0.07181 - acc: 0.9830 -- iter: 1728/1779
[A[ATraining Step: 615  | total loss: [1m[32m0.06982[0m[0m | time: 575.819s
[2K
| Adam | epoch: 011 | loss: 0.06982 - acc: 0.9815 -- iter: 1760/1779
[A[ATraining Step: 616  | total loss: [1m[32m0.06426[0m[0m | time: 627.790s
[2K
| Adam | epoch: 011 | loss: 0.06426 - acc: 0.9834 | val_loss: 1.31326 - val_acc: 0.7504 -- iter: 1779/1779
--
Training Step: 617  | total loss: [1m[32m0.05828[0m[0m | time: 14.377s
[2K
| Adam | epoch: 012 | loss: 0.05828 - acc: 0.9851 -- iter: 0032/1779
[A[ATraining Step: 618  | total loss: [1m[32m0.05407[0m[0m | time: 28.459s
[2K
| Adam | epoch: 012 | loss: 0.05407 - acc: 0.9865 -- iter: 0064/1779
[A[ATraining Step: 619  | total loss: [1m[32m0.05048[0m[0m | time: 43.153s
[2K
| Adam | epoch: 012 | loss: 0.05048 - acc: 0.9879 -- iter: 0096/1779
[A[ATraining Step: 620  | total loss: [1m[32m0.04591[0m[0m | time: 57.621s
[2K
| Adam | epoch: 012 | loss: 0.04591 - acc: 0.9891 -- iter: 0128/1779
[A[ATraining Step: 621  | total loss: [1m[32m0.04152[0m[0m | time: 72.097s
[2K
| Adam | epoch: 012 | loss: 0.04152 - acc: 0.9902 -- iter: 0160/1779
[A[ATraining Step: 622  | total loss: [1m[32m0.04082[0m[0m | time: 85.885s
[2K
| Adam | epoch: 012 | loss: 0.04082 - acc: 0.9880 -- iter: 0192/1779
[A[ATraining Step: 623  | total loss: [1m[32m0.05644[0m[0m | time: 99.883s
[2K
| Adam | epoch: 012 | loss: 0.05644 - acc: 0.9861 -- iter: 0224/1779
[A[ATraining Step: 624  | total loss: [1m[32m0.05191[0m[0m | time: 113.320s
[2K
| Adam | epoch: 012 | loss: 0.05191 - acc: 0.9875 -- iter: 0256/1779
[A[ATraining Step: 625  | total loss: [1m[32m0.04738[0m[0m | time: 121.742s
[2K
| Adam | epoch: 012 | loss: 0.04738 - acc: 0.9888 -- iter: 0288/1779
[A[ATraining Step: 626  | total loss: [1m[32m0.05246[0m[0m | time: 127.305s
[2K
| Adam | epoch: 012 | loss: 0.05246 - acc: 0.9868 -- iter: 0320/1779
[A[ATraining Step: 627  | total loss: [1m[32m0.04726[0m[0m | time: 133.093s
[2K
| Adam | epoch: 012 | loss: 0.04726 - acc: 0.9881 -- iter: 0352/1779
[A[ATraining Step: 628  | total loss: [1m[32m0.04259[0m[0m | time: 147.457s
[2K
| Adam | epoch: 012 | loss: 0.04259 - acc: 0.9893 -- iter: 0384/1779
[A[ATraining Step: 629  | total loss: [1m[32m0.04039[0m[0m | time: 161.105s
[2K
| Adam | epoch: 012 | loss: 0.04039 - acc: 0.9903 -- iter: 0416/1779
[A[ATraining Step: 630  | total loss: [1m[32m0.03729[0m[0m | time: 175.271s
[2K
| Adam | epoch: 012 | loss: 0.03729 - acc: 0.9913 -- iter: 0448/1779
[A[ATraining Step: 631  | total loss: [1m[32m0.03532[0m[0m | time: 189.758s
[2K
| Adam | epoch: 012 | loss: 0.03532 - acc: 0.9922 -- iter: 0480/1779
[A[ATraining Step: 632  | total loss: [1m[32m0.03223[0m[0m | time: 204.540s
[2K
| Adam | epoch: 012 | loss: 0.03223 - acc: 0.9930 -- iter: 0512/1779
[A[ATraining Step: 633  | total loss: [1m[32m0.02915[0m[0m | time: 218.584s
[2K
| Adam | epoch: 012 | loss: 0.02915 - acc: 0.9937 -- iter: 0544/1779
[A[ATraining Step: 634  | total loss: [1m[32m0.02677[0m[0m | time: 233.693s
[2K
| Adam | epoch: 012 | loss: 0.02677 - acc: 0.9943 -- iter: 0576/1779
[A[ATraining Step: 635  | total loss: [1m[32m0.02468[0m[0m | time: 247.825s
[2K
| Adam | epoch: 012 | loss: 0.02468 - acc: 0.9949 -- iter: 0608/1779
[A[ATraining Step: 636  | total loss: [1m[32m0.02281[0m[0m | time: 261.752s
[2K
| Adam | epoch: 012 | loss: 0.02281 - acc: 0.9954 -- iter: 0640/1779
[A[ATraining Step: 637  | total loss: [1m[32m0.02111[0m[0m | time: 270.254s
[2K
| Adam | epoch: 012 | loss: 0.02111 - acc: 0.9958 -- iter: 0672/1779
[A[ATraining Step: 638  | total loss: [1m[32m0.01985[0m[0m | time: 278.910s
[2K
| Adam | epoch: 012 | loss: 0.01985 - acc: 0.9963 -- iter: 0704/1779
[A[ATraining Step: 639  | total loss: [1m[32m0.02014[0m[0m | time: 289.824s
[2K
| Adam | epoch: 012 | loss: 0.02014 - acc: 0.9966 -- iter: 0736/1779
[A[ATraining Step: 640  | total loss: [1m[32m0.01853[0m[0m | time: 303.776s
[2K
| Adam | epoch: 012 | loss: 0.01853 - acc: 0.9970 -- iter: 0768/1779
[A[ATraining Step: 641  | total loss: [1m[32m0.01731[0m[0m | time: 317.315s
[2K
| Adam | epoch: 012 | loss: 0.01731 - acc: 0.9973 -- iter: 0800/1779
[A[ATraining Step: 642  | total loss: [1m[32m0.01681[0m[0m | time: 331.153s
[2K
| Adam | epoch: 012 | loss: 0.01681 - acc: 0.9975 -- iter: 0832/1779
[A[ATraining Step: 643  | total loss: [1m[32m0.01557[0m[0m | time: 345.080s
[2K
| Adam | epoch: 012 | loss: 0.01557 - acc: 0.9978 -- iter: 0864/1779
[A[ATraining Step: 644  | total loss: [1m[32m0.01445[0m[0m | time: 359.033s
[2K
| Adam | epoch: 012 | loss: 0.01445 - acc: 0.9980 -- iter: 0896/1779
[A[ATraining Step: 645  | total loss: [1m[32m0.01974[0m[0m | time: 373.422s
[2K
| Adam | epoch: 012 | loss: 0.01974 - acc: 0.9951 -- iter: 0928/1779
[A[ATraining Step: 646  | total loss: [1m[32m0.01810[0m[0m | time: 387.856s
[2K
| Adam | epoch: 012 | loss: 0.01810 - acc: 0.9956 -- iter: 0960/1779
[A[ATraining Step: 647  | total loss: [1m[32m0.04685[0m[0m | time: 401.962s
[2K
| Adam | epoch: 012 | loss: 0.04685 - acc: 0.9866 -- iter: 0992/1779
[A[ATraining Step: 648  | total loss: [1m[32m0.05585[0m[0m | time: 415.127s
[2K
| Adam | epoch: 012 | loss: 0.05585 - acc: 0.9817 -- iter: 1024/1779
[A[ATraining Step: 649  | total loss: [1m[32m0.05074[0m[0m | time: 423.620s
[2K
| Adam | epoch: 012 | loss: 0.05074 - acc: 0.9836 -- iter: 1056/1779
[A[ATraining Step: 650  | total loss: [1m[32m0.04674[0m[0m | time: 432.035s
[2K
| Adam | epoch: 012 | loss: 0.04674 - acc: 0.9852 -- iter: 1088/1779
[A[ATraining Step: 651  | total loss: [1m[32m0.04253[0m[0m | time: 443.506s
[2K
| Adam | epoch: 012 | loss: 0.04253 - acc: 0.9867 -- iter: 1120/1779
[A[ATraining Step: 652  | total loss: [1m[32m0.06948[0m[0m | time: 457.680s
[2K
| Adam | epoch: 012 | loss: 0.06948 - acc: 0.9849 -- iter: 1152/1779
[A[ATraining Step: 653  | total loss: [1m[32m0.07205[0m[0m | time: 472.363s
[2K
| Adam | epoch: 012 | loss: 0.07205 - acc: 0.9833 -- iter: 1184/1779
[A[ATraining Step: 654  | total loss: [1m[32m0.06789[0m[0m | time: 485.958s
[2K
| Adam | epoch: 012 | loss: 0.06789 - acc: 0.9849 -- iter: 1216/1779
[A[ATraining Step: 655  | total loss: [1m[32m0.06291[0m[0m | time: 499.894s
[2K
| Adam | epoch: 012 | loss: 0.06291 - acc: 0.9865 -- iter: 1248/1779
[A[ATraining Step: 656  | total loss: [1m[32m0.05825[0m[0m | time: 514.517s
[2K
| Adam | epoch: 012 | loss: 0.05825 - acc: 0.9878 -- iter: 1280/1779
[A[ATraining Step: 657  | total loss: [1m[32m0.05897[0m[0m | time: 529.129s
[2K
| Adam | epoch: 012 | loss: 0.05897 - acc: 0.9859 -- iter: 1312/1779
[A[ATraining Step: 658  | total loss: [1m[32m0.05640[0m[0m | time: 543.510s
[2K
| Adam | epoch: 012 | loss: 0.05640 - acc: 0.9842 -- iter: 1344/1779
[A[ATraining Step: 659  | total loss: [1m[32m0.06829[0m[0m | time: 557.947s
[2K
| Adam | epoch: 012 | loss: 0.06829 - acc: 0.9826 -- iter: 1376/1779
[A[ATraining Step: 660  | total loss: [1m[32m0.06201[0m[0m | time: 569.021s
[2K
| Adam | epoch: 012 | loss: 0.06201 - acc: 0.9844 -- iter: 1408/1779
[A[ATraining Step: 661  | total loss: [1m[32m0.05626[0m[0m | time: 577.404s
[2K
| Adam | epoch: 012 | loss: 0.05626 - acc: 0.9859 -- iter: 1440/1779
[A[ATraining Step: 662  | total loss: [1m[32m0.05157[0m[0m | time: 585.955s
[2K
| Adam | epoch: 012 | loss: 0.05157 - acc: 0.9873 -- iter: 1472/1779
[A[ATraining Step: 663  | total loss: [1m[32m0.04998[0m[0m | time: 594.407s
[2K
| Adam | epoch: 012 | loss: 0.04998 - acc: 0.9886 -- iter: 1504/1779
[A[ATraining Step: 664  | total loss: [1m[32m0.05043[0m[0m | time: 608.756s
[2K
| Adam | epoch: 012 | loss: 0.05043 - acc: 0.9866 -- iter: 1536/1779
[A[ATraining Step: 665  | total loss: [1m[32m0.05318[0m[0m | time: 622.767s
[2K
| Adam | epoch: 012 | loss: 0.05318 - acc: 0.9848 -- iter: 1568/1779
[A[ATraining Step: 666  | total loss: [1m[32m0.04837[0m[0m | time: 637.133s
[2K
| Adam | epoch: 012 | loss: 0.04837 - acc: 0.9864 -- iter: 1600/1779
[A[ATraining Step: 667  | total loss: [1m[32m0.04478[0m[0m | time: 651.597s
[2K
| Adam | epoch: 012 | loss: 0.04478 - acc: 0.9877 -- iter: 1632/1779
[A[ATraining Step: 668  | total loss: [1m[32m0.04082[0m[0m | time: 665.213s
[2K
| Adam | epoch: 012 | loss: 0.04082 - acc: 0.9889 -- iter: 1664/1779
[A[ATraining Step: 669  | total loss: [1m[32m0.03830[0m[0m | time: 679.925s
[2K
| Adam | epoch: 012 | loss: 0.03830 - acc: 0.9901 -- iter: 1696/1779
[A[ATraining Step: 670  | total loss: [1m[32m0.03478[0m[0m | time: 694.683s
[2K
| Adam | epoch: 012 | loss: 0.03478 - acc: 0.9910 -- iter: 1728/1779
[A[ATraining Step: 671  | total loss: [1m[32m0.03143[0m[0m | time: 708.094s
[2K
| Adam | epoch: 012 | loss: 0.03143 - acc: 0.9919 -- iter: 1760/1779
[A[ATraining Step: 672  | total loss: [1m[32m0.03546[0m[0m | time: 757.824s
[2K
| Adam | epoch: 012 | loss: 0.03546 - acc: 0.9896 | val_loss: 1.47344 - val_acc: 0.7487 -- iter: 1779/1779
--
Training Step: 673  | total loss: [1m[32m0.03219[0m[0m | time: 17.650s
[2K
| Adam | epoch: 013 | loss: 0.03219 - acc: 0.9907 -- iter: 0032/1779
[A[ATraining Step: 674  | total loss: [1m[32m0.02928[0m[0m | time: 34.630s
[2K
| Adam | epoch: 013 | loss: 0.02928 - acc: 0.9916 -- iter: 0064/1779
[A[ATraining Step: 675  | total loss: [1m[32m0.02792[0m[0m | time: 51.449s
[2K
| Adam | epoch: 013 | loss: 0.02792 - acc: 0.9924 -- iter: 0096/1779
[A[ATraining Step: 676  | total loss: [1m[32m0.03696[0m[0m | time: 69.018s
[2K
| Adam | epoch: 013 | loss: 0.03696 - acc: 0.9869 -- iter: 0128/1779
[A[ATraining Step: 677  | total loss: [1m[32m0.03460[0m[0m | time: 85.864s
[2K
| Adam | epoch: 013 | loss: 0.03460 - acc: 0.9882 -- iter: 0160/1779
[A[ATraining Step: 678  | total loss: [1m[32m0.03953[0m[0m | time: 106.374s
[2K
| Adam | epoch: 013 | loss: 0.03953 - acc: 0.9832 -- iter: 0192/1779
[A[ATraining Step: 679  | total loss: [1m[32m0.03950[0m[0m | time: 119.293s
[2K
| Adam | epoch: 013 | loss: 0.03950 - acc: 0.9817 -- iter: 0224/1779
[A[ATraining Step: 680  | total loss: [1m[32m0.03833[0m[0m | time: 130.462s
[2K
| Adam | epoch: 013 | loss: 0.03833 - acc: 0.9804 -- iter: 0256/1779
[A[ATraining Step: 681  | total loss: [1m[32m0.03535[0m[0m | time: 141.019s
[2K
| Adam | epoch: 013 | loss: 0.03535 - acc: 0.9824 -- iter: 0288/1779
[A[ATraining Step: 682  | total loss: [1m[32m0.03702[0m[0m | time: 154.810s
[2K
| Adam | epoch: 013 | loss: 0.03702 - acc: 0.9810 -- iter: 0320/1779
[A[ATraining Step: 683  | total loss: [1m[32m0.03437[0m[0m | time: 165.850s
[2K
| Adam | epoch: 013 | loss: 0.03437 - acc: 0.9829 -- iter: 0352/1779
[A[ATraining Step: 684  | total loss: [1m[32m0.03151[0m[0m | time: 177.279s
[2K
| Adam | epoch: 013 | loss: 0.03151 - acc: 0.9846 -- iter: 0384/1779
[A[ATraining Step: 685  | total loss: [1m[32m0.02856[0m[0m | time: 194.210s
[2K
| Adam | epoch: 013 | loss: 0.02856 - acc: 0.9862 -- iter: 0416/1779
[A[ATraining Step: 686  | total loss: [1m[32m0.07104[0m[0m | time: 211.507s
[2K
| Adam | epoch: 013 | loss: 0.07104 - acc: 0.9688 -- iter: 0448/1779
[A[ATraining Step: 687  | total loss: [1m[32m0.06439[0m[0m | time: 229.556s
[2K
| Adam | epoch: 013 | loss: 0.06439 - acc: 0.9719 -- iter: 0480/1779
[A[ATraining Step: 688  | total loss: [1m[32m0.06857[0m[0m | time: 246.225s
[2K
| Adam | epoch: 013 | loss: 0.06857 - acc: 0.9716 -- iter: 0512/1779
[A[ATraining Step: 689  | total loss: [1m[32m0.06237[0m[0m | time: 263.664s
[2K
| Adam | epoch: 013 | loss: 0.06237 - acc: 0.9744 -- iter: 0544/1779
[A[ATraining Step: 690  | total loss: [1m[32m0.05685[0m[0m | time: 280.520s
[2K
| Adam | epoch: 013 | loss: 0.05685 - acc: 0.9770 -- iter: 0576/1779
[A[ATraining Step: 691  | total loss: [1m[32m0.05129[0m[0m | time: 298.287s
[2K
| Adam | epoch: 013 | loss: 0.05129 - acc: 0.9793 -- iter: 0608/1779
[A[ATraining Step: 692  | total loss: [1m[32m0.04686[0m[0m | time: 311.344s
[2K
| Adam | epoch: 013 | loss: 0.04686 - acc: 0.9814 -- iter: 0640/1779
[A[ATraining Step: 693  | total loss: [1m[32m0.06183[0m[0m | time: 321.986s
[2K
| Adam | epoch: 013 | loss: 0.06183 - acc: 0.9770 -- iter: 0672/1779
[A[ATraining Step: 694  | total loss: [1m[32m0.06071[0m[0m | time: 335.475s
[2K
| Adam | epoch: 013 | loss: 0.06071 - acc: 0.9762 -- iter: 0704/1779
[A[ATraining Step: 695  | total loss: [1m[32m0.05689[0m[0m | time: 351.655s
[2K
| Adam | epoch: 013 | loss: 0.05689 - acc: 0.9785 -- iter: 0736/1779
[A[ATraining Step: 696  | total loss: [1m[32m0.05133[0m[0m | time: 369.108s
[2K
| Adam | epoch: 013 | loss: 0.05133 - acc: 0.9807 -- iter: 0768/1779
[A[ATraining Step: 697  | total loss: [1m[32m0.04642[0m[0m | time: 386.300s
[2K
| Adam | epoch: 013 | loss: 0.04642 - acc: 0.9826 -- iter: 0800/1779
[A[ATraining Step: 698  | total loss: [1m[32m0.04213[0m[0m | time: 412.297s
[2K
| Adam | epoch: 013 | loss: 0.04213 - acc: 0.9844 -- iter: 0832/1779
[A[ATraining Step: 699  | total loss: [1m[32m0.04006[0m[0m | time: 429.173s
[2K
| Adam | epoch: 013 | loss: 0.04006 - acc: 0.9859 -- iter: 0864/1779
[A[ATraining Step: 700  | total loss: [1m[32m0.06132[0m[0m | time: 446.115s
[2K
| Adam | epoch: 013 | loss: 0.06132 - acc: 0.9842 -- iter: 0896/1779
[A[ATraining Step: 701  | total loss: [1m[32m0.05768[0m[0m | time: 463.620s
[2K
| Adam | epoch: 013 | loss: 0.05768 - acc: 0.9858 -- iter: 0928/1779
[A[ATraining Step: 702  | total loss: [1m[32m0.05315[0m[0m | time: 481.185s
[2K
| Adam | epoch: 013 | loss: 0.05315 - acc: 0.9872 -- iter: 0960/1779
[A[ATraining Step: 703  | total loss: [1m[32m0.04797[0m[0m | time: 497.952s
[2K
| Adam | epoch: 013 | loss: 0.04797 - acc: 0.9885 -- iter: 0992/1779
[A[ATraining Step: 704  | total loss: [1m[32m0.04370[0m[0m | time: 509.003s
[2K
| Adam | epoch: 013 | loss: 0.04370 - acc: 0.9896 -- iter: 1024/1779
[A[ATraining Step: 705  | total loss: [1m[32m0.04213[0m[0m | time: 521.109s
[2K
| Adam | epoch: 013 | loss: 0.04213 - acc: 0.9907 -- iter: 1056/1779
[A[ATraining Step: 706  | total loss: [1m[32m0.03874[0m[0m | time: 538.359s
[2K
| Adam | epoch: 013 | loss: 0.03874 - acc: 0.9916 -- iter: 1088/1779
[A[ATraining Step: 707  | total loss: [1m[32m0.04399[0m[0m | time: 555.363s
[2K
| Adam | epoch: 013 | loss: 0.04399 - acc: 0.9862 -- iter: 1120/1779
[A[ATraining Step: 708  | total loss: [1m[32m0.04039[0m[0m | time: 572.911s
[2K
| Adam | epoch: 013 | loss: 0.04039 - acc: 0.9876 -- iter: 1152/1779
[A[ATraining Step: 709  | total loss: [1m[32m0.04009[0m[0m | time: 589.479s
[2K
| Adam | epoch: 013 | loss: 0.04009 - acc: 0.9857 -- iter: 1184/1779
[A[ATraining Step: 710  | total loss: [1m[32m0.03680[0m[0m | time: 609.383s
[2K
| Adam | epoch: 013 | loss: 0.03680 - acc: 0.9871 -- iter: 1216/1779
[A[ATraining Step: 711  | total loss: [1m[32m0.04845[0m[0m | time: 626.147s
[2K
| Adam | epoch: 013 | loss: 0.04845 - acc: 0.9790 -- iter: 1248/1779
[A[ATraining Step: 712  | total loss: [1m[32m0.04461[0m[0m | time: 643.484s
[2K
| Adam | epoch: 013 | loss: 0.04461 - acc: 0.9811 -- iter: 1280/1779
[A[ATraining Step: 713  | total loss: [1m[32m0.04049[0m[0m | time: 660.185s
[2K
| Adam | epoch: 013 | loss: 0.04049 - acc: 0.9830 -- iter: 1312/1779
[A[ATraining Step: 714  | total loss: [1m[32m0.03727[0m[0m | time: 677.661s
[2K
| Adam | epoch: 013 | loss: 0.03727 - acc: 0.9847 -- iter: 1344/1779
[A[ATraining Step: 715  | total loss: [1m[32m0.03979[0m[0m | time: 688.705s
[2K
| Adam | epoch: 013 | loss: 0.03979 - acc: 0.9831 -- iter: 1376/1779
[A[ATraining Step: 716  | total loss: [1m[32m0.03616[0m[0m | time: 699.690s
[2K
| Adam | epoch: 013 | loss: 0.03616 - acc: 0.9848 -- iter: 1408/1779
[A[ATraining Step: 717  | total loss: [1m[32m0.03301[0m[0m | time: 716.224s
[2K
| Adam | epoch: 013 | loss: 0.03301 - acc: 0.9863 -- iter: 1440/1779
[A[ATraining Step: 718  | total loss: [1m[32m0.04345[0m[0m | time: 742.354s
[2K
| Adam | epoch: 013 | loss: 0.04345 - acc: 0.9846 -- iter: 1472/1779
[A[ATraining Step: 719  | total loss: [1m[32m0.03942[0m[0m | time: 759.686s
[2K
| Adam | epoch: 013 | loss: 0.03942 - acc: 0.9861 -- iter: 1504/1779
[A[ATraining Step: 720  | total loss: [1m[32m0.03590[0m[0m | time: 777.464s
[2K
| Adam | epoch: 013 | loss: 0.03590 - acc: 0.9875 -- iter: 1536/1779
[A[ATraining Step: 721  | total loss: [1m[32m0.03363[0m[0m | time: 795.044s
[2K
| Adam | epoch: 013 | loss: 0.03363 - acc: 0.9888 -- iter: 1568/1779
[A[ATraining Step: 722  | total loss: [1m[32m0.04070[0m[0m | time: 812.268s
[2K
| Adam | epoch: 013 | loss: 0.04070 - acc: 0.9868 -- iter: 1600/1779
[A[ATraining Step: 723  | total loss: [1m[32m0.04178[0m[0m | time: 828.645s
[2K
| Adam | epoch: 013 | loss: 0.04178 - acc: 0.9850 -- iter: 1632/1779
[A[ATraining Step: 724  | total loss: [1m[32m0.03789[0m[0m | time: 845.524s
[2K
| Adam | epoch: 013 | loss: 0.03789 - acc: 0.9865 -- iter: 1664/1779
[A[ATraining Step: 725  | total loss: [1m[32m0.03454[0m[0m | time: 862.281s
[2K
| Adam | epoch: 013 | loss: 0.03454 - acc: 0.9878 -- iter: 1696/1779
[A[ATraining Step: 726  | total loss: [1m[32m0.03349[0m[0m | time: 875.558s
[2K
| Adam | epoch: 013 | loss: 0.03349 - acc: 0.9890 -- iter: 1728/1779
[A[ATraining Step: 727  | total loss: [1m[32m0.03032[0m[0m | time: 886.407s
[2K
| Adam | epoch: 013 | loss: 0.03032 - acc: 0.9901 -- iter: 1760/1779
[A[ATraining Step: 728  | total loss: [1m[32m0.02835[0m[0m | time: 958.401s
[2K
| Adam | epoch: 013 | loss: 0.02835 - acc: 0.9911 | val_loss: 1.08446 - val_acc: 0.7469 -- iter: 1779/1779
--
Training Step: 729  | total loss: [1m[32m0.02615[0m[0m | time: 16.797s
[2K
| Adam | epoch: 014 | loss: 0.02615 - acc: 0.9920 -- iter: 0032/1779
[A[ATraining Step: 730  | total loss: [1m[32m0.02792[0m[0m | time: 30.704s
[2K
| Adam | epoch: 014 | loss: 0.02792 - acc: 0.9897 -- iter: 0064/1779
[A[ATraining Step: 731  | total loss: [1m[32m0.02581[0m[0m | time: 44.241s
[2K
| Adam | epoch: 014 | loss: 0.02581 - acc: 0.9907 -- iter: 0096/1779
[A[ATraining Step: 732  | total loss: [1m[32m0.02739[0m[0m | time: 56.334s
[2K
| Adam | epoch: 014 | loss: 0.02739 - acc: 0.9885 -- iter: 0128/1779
[A[ATraining Step: 733  | total loss: [1m[32m0.02526[0m[0m | time: 64.804s
[2K
| Adam | epoch: 014 | loss: 0.02526 - acc: 0.9897 -- iter: 0160/1779
[A[ATraining Step: 734  | total loss: [1m[32m0.02319[0m[0m | time: 73.937s
[2K
| Adam | epoch: 014 | loss: 0.02319 - acc: 0.9907 -- iter: 0192/1779
[A[ATraining Step: 735  | total loss: [1m[32m0.02127[0m[0m | time: 87.318s
[2K
| Adam | epoch: 014 | loss: 0.02127 - acc: 0.9916 -- iter: 0224/1779
[A[ATraining Step: 736  | total loss: [1m[32m0.01979[0m[0m | time: 101.790s
[2K
| Adam | epoch: 014 | loss: 0.01979 - acc: 0.9925 -- iter: 0256/1779
[A[ATraining Step: 737  | total loss: [1m[32m0.01917[0m[0m | time: 115.860s
[2K
| Adam | epoch: 014 | loss: 0.01917 - acc: 0.9932 -- iter: 0288/1779
[A[ATraining Step: 738  | total loss: [1m[32m0.01757[0m[0m | time: 130.107s
[2K
| Adam | epoch: 014 | loss: 0.01757 - acc: 0.9939 -- iter: 0320/1779
[A[ATraining Step: 739  | total loss: [1m[32m0.01660[0m[0m | time: 143.904s
[2K
| Adam | epoch: 014 | loss: 0.01660 - acc: 0.9945 -- iter: 0352/1779
[A[ATraining Step: 740  | total loss: [1m[32m0.02447[0m[0m | time: 152.766s
[2K
| Adam | epoch: 014 | loss: 0.02447 - acc: 0.9919 -- iter: 0384/1779
[A[ATraining Step: 741  | total loss: [1m[32m0.02255[0m[0m | time: 161.827s
[2K
| Adam | epoch: 014 | loss: 0.02255 - acc: 0.9927 -- iter: 0416/1779
[A[ATraining Step: 742  | total loss: [1m[32m0.02079[0m[0m | time: 176.186s
[2K
| Adam | epoch: 014 | loss: 0.02079 - acc: 0.9935 -- iter: 0448/1779
[A[ATraining Step: 743  | total loss: [1m[32m0.02023[0m[0m | time: 189.686s
[2K
| Adam | epoch: 014 | loss: 0.02023 - acc: 0.9941 -- iter: 0480/1779
[A[ATraining Step: 744  | total loss: [1m[32m0.03776[0m[0m | time: 203.192s
[2K
| Adam | epoch: 014 | loss: 0.03776 - acc: 0.9916 -- iter: 0512/1779
[A[ATraining Step: 745  | total loss: [1m[32m0.03454[0m[0m | time: 211.670s
[2K
| Adam | epoch: 014 | loss: 0.03454 - acc: 0.9924 -- iter: 0544/1779
[A[ATraining Step: 746  | total loss: [1m[32m0.03128[0m[0m | time: 220.214s
[2K
| Adam | epoch: 014 | loss: 0.03128 - acc: 0.9932 -- iter: 0576/1779
[A[ATraining Step: 747  | total loss: [1m[32m0.02940[0m[0m | time: 231.143s
[2K
| Adam | epoch: 014 | loss: 0.02940 - acc: 0.9939 -- iter: 0608/1779
[A[ATraining Step: 748  | total loss: [1m[32m0.04659[0m[0m | time: 244.887s
[2K
| Adam | epoch: 014 | loss: 0.04659 - acc: 0.9820 -- iter: 0640/1779
[A[ATraining Step: 749  | total loss: [1m[32m0.04229[0m[0m | time: 258.749s
[2K
| Adam | epoch: 014 | loss: 0.04229 - acc: 0.9838 -- iter: 0672/1779
[A[ATraining Step: 750  | total loss: [1m[32m0.03846[0m[0m | time: 272.856s
[2K
| Adam | epoch: 014 | loss: 0.03846 - acc: 0.9854 -- iter: 0704/1779
[A[ATraining Step: 751  | total loss: [1m[32m0.03612[0m[0m | time: 287.303s
[2K
| Adam | epoch: 014 | loss: 0.03612 - acc: 0.9869 -- iter: 0736/1779
[A[ATraining Step: 752  | total loss: [1m[32m0.03275[0m[0m | time: 300.993s
[2K
| Adam | epoch: 014 | loss: 0.03275 - acc: 0.9882 -- iter: 0768/1779
[A[ATraining Step: 753  | total loss: [1m[32m0.03416[0m[0m | time: 314.518s
[2K
| Adam | epoch: 014 | loss: 0.03416 - acc: 0.9862 -- iter: 0800/1779
[A[ATraining Step: 754  | total loss: [1m[32m0.03457[0m[0m | time: 328.665s
[2K
| Adam | epoch: 014 | loss: 0.03457 - acc: 0.9845 -- iter: 0832/1779
[A[ATraining Step: 755  | total loss: [1m[32m0.03911[0m[0m | time: 343.182s
[2K
| Adam | epoch: 014 | loss: 0.03911 - acc: 0.9829 -- iter: 0864/1779
[A[ATraining Step: 756  | total loss: [1m[32m0.03691[0m[0m | time: 355.128s
[2K
| Adam | epoch: 014 | loss: 0.03691 - acc: 0.9846 -- iter: 0896/1779
[A[ATraining Step: 757  | total loss: [1m[32m0.03377[0m[0m | time: 363.755s
[2K
| Adam | epoch: 014 | loss: 0.03377 - acc: 0.9862 -- iter: 0928/1779
[A[ATraining Step: 758  | total loss: [1m[32m0.03071[0m[0m | time: 372.062s
[2K
| Adam | epoch: 014 | loss: 0.03071 - acc: 0.9875 -- iter: 0960/1779
[A[ATraining Step: 759  | total loss: [1m[32m0.04106[0m[0m | time: 380.485s
[2K
| Adam | epoch: 014 | loss: 0.04106 - acc: 0.9857 -- iter: 0992/1779
[A[ATraining Step: 760  | total loss: [1m[32m0.03703[0m[0m | time: 395.490s
[2K
| Adam | epoch: 014 | loss: 0.03703 - acc: 0.9871 -- iter: 1024/1779
[A[ATraining Step: 761  | total loss: [1m[32m0.03406[0m[0m | time: 404.142s
[2K
| Adam | epoch: 014 | loss: 0.03406 - acc: 0.9884 -- iter: 1056/1779
[A[ATraining Step: 762  | total loss: [1m[32m0.03083[0m[0m | time: 412.787s
[2K
| Adam | epoch: 014 | loss: 0.03083 - acc: 0.9895 -- iter: 1088/1779
[A[ATraining Step: 763  | total loss: [1m[32m0.02792[0m[0m | time: 421.324s
[2K
| Adam | epoch: 014 | loss: 0.02792 - acc: 0.9906 -- iter: 1120/1779
[A[ATraining Step: 764  | total loss: [1m[32m0.02601[0m[0m | time: 429.851s
[2K
| Adam | epoch: 014 | loss: 0.02601 - acc: 0.9915 -- iter: 1152/1779
[A[ATraining Step: 765  | total loss: [1m[32m0.02375[0m[0m | time: 438.434s
[2K
| Adam | epoch: 014 | loss: 0.02375 - acc: 0.9924 -- iter: 1184/1779
[A[ATraining Step: 766  | total loss: [1m[32m0.11879[0m[0m | time: 447.316s
[2K
| Adam | epoch: 014 | loss: 0.11879 - acc: 0.9775 -- iter: 1216/1779
[A[ATraining Step: 767  | total loss: [1m[32m0.11407[0m[0m | time: 456.024s
[2K
| Adam | epoch: 014 | loss: 0.11407 - acc: 0.9766 -- iter: 1248/1779
[A[ATraining Step: 768  | total loss: [1m[32m0.10322[0m[0m | time: 464.406s
[2K
| Adam | epoch: 014 | loss: 0.10322 - acc: 0.9790 -- iter: 1280/1779
[A[ATraining Step: 769  | total loss: [1m[32m0.09320[0m[0m | time: 473.000s
[2K
| Adam | epoch: 014 | loss: 0.09320 - acc: 0.9811 -- iter: 1312/1779
[A[ATraining Step: 770  | total loss: [1m[32m0.09843[0m[0m | time: 481.714s
[2K
| Adam | epoch: 014 | loss: 0.09843 - acc: 0.9798 -- iter: 1344/1779
[A[ATraining Step: 771  | total loss: [1m[32m0.08883[0m[0m | time: 490.382s
[2K
| Adam | epoch: 014 | loss: 0.08883 - acc: 0.9819 -- iter: 1376/1779
[A[ATraining Step: 772  | total loss: [1m[32m0.08010[0m[0m | time: 499.155s
[2K
| Adam | epoch: 014 | loss: 0.08010 - acc: 0.9837 -- iter: 1408/1779
[A[ATraining Step: 773  | total loss: [1m[32m0.07228[0m[0m | time: 507.742s
[2K
| Adam | epoch: 014 | loss: 0.07228 - acc: 0.9853 -- iter: 1440/1779
[A[ATraining Step: 774  | total loss: [1m[32m0.06518[0m[0m | time: 516.184s
[2K
| Adam | epoch: 014 | loss: 0.06518 - acc: 0.9868 -- iter: 1472/1779
[A[ATraining Step: 775  | total loss: [1m[32m0.05927[0m[0m | time: 524.803s
[2K
| Adam | epoch: 014 | loss: 0.05927 - acc: 0.9881 -- iter: 1504/1779
[A[ATraining Step: 776  | total loss: [1m[32m0.08733[0m[0m | time: 533.064s
[2K
| Adam | epoch: 014 | loss: 0.08733 - acc: 0.9862 -- iter: 1536/1779
[A[ATraining Step: 777  | total loss: [1m[32m0.07942[0m[0m | time: 541.849s
[2K
| Adam | epoch: 014 | loss: 0.07942 - acc: 0.9875 -- iter: 1568/1779
[A[ATraining Step: 778  | total loss: [1m[32m0.07453[0m[0m | time: 550.272s
[2K
| Adam | epoch: 014 | loss: 0.07453 - acc: 0.9857 -- iter: 1600/1779
[A[ATraining Step: 779  | total loss: [1m[32m0.06736[0m[0m | time: 558.947s
[2K
| Adam | epoch: 014 | loss: 0.06736 - acc: 0.9871 -- iter: 1632/1779
[A[ATraining Step: 780  | total loss: [1m[32m0.06116[0m[0m | time: 567.452s
[2K
| Adam | epoch: 014 | loss: 0.06116 - acc: 0.9884 -- iter: 1664/1779
[A[ATraining Step: 781  | total loss: [1m[32m0.05866[0m[0m | time: 575.865s
[2K
| Adam | epoch: 014 | loss: 0.05866 - acc: 0.9896 -- iter: 1696/1779
[A[ATraining Step: 782  | total loss: [1m[32m0.05298[0m[0m | time: 584.466s
[2K
| Adam | epoch: 014 | loss: 0.05298 - acc: 0.9906 -- iter: 1728/1779
[A[ATraining Step: 783  | total loss: [1m[32m0.04797[0m[0m | time: 592.836s
[2K
| Adam | epoch: 014 | loss: 0.04797 - acc: 0.9915 -- iter: 1760/1779
[A[ATraining Step: 784  | total loss: [1m[32m0.04489[0m[0m | time: 627.671s
[2K
| Adam | epoch: 014 | loss: 0.04489 - acc: 0.9924 | val_loss: 3.80321 - val_acc: 0.5099 -- iter: 1779/1779
--
Training Step: 785  | total loss: [1m[32m0.04561[0m[0m | time: 8.537s
[2K
| Adam | epoch: 015 | loss: 0.04561 - acc: 0.9931 -- iter: 0032/1779
[A[ATraining Step: 786  | total loss: [1m[32m0.04128[0m[0m | time: 17.066s
[2K
| Adam | epoch: 015 | loss: 0.04128 - acc: 0.9938 -- iter: 0064/1779
[A[ATraining Step: 787  | total loss: [1m[32m0.03753[0m[0m | time: 25.591s
[2K
| Adam | epoch: 015 | loss: 0.03753 - acc: 0.9944 -- iter: 0096/1779
[A[ATraining Step: 788  | total loss: [1m[32m0.03763[0m[0m | time: 34.167s
[2K
| Adam | epoch: 015 | loss: 0.03763 - acc: 0.9950 -- iter: 0128/1779
[A[ATraining Step: 789  | total loss: [1m[32m0.03441[0m[0m | time: 42.654s
[2K
| Adam | epoch: 015 | loss: 0.03441 - acc: 0.9955 -- iter: 0160/1779
[A[ATraining Step: 790  | total loss: [1m[32m0.03351[0m[0m | time: 51.339s
[2K
| Adam | epoch: 015 | loss: 0.03351 - acc: 0.9960 -- iter: 0192/1779
[A[ATraining Step: 791  | total loss: [1m[32m0.03259[0m[0m | time: 59.760s
[2K
| Adam | epoch: 015 | loss: 0.03259 - acc: 0.9964 -- iter: 0224/1779
[A[ATraining Step: 792  | total loss: [1m[32m0.04544[0m[0m | time: 68.155s
[2K
| Adam | epoch: 015 | loss: 0.04544 - acc: 0.9873 -- iter: 0256/1779
[A[ATraining Step: 793  | total loss: [1m[32m0.05180[0m[0m | time: 76.667s
[2K
| Adam | epoch: 015 | loss: 0.05180 - acc: 0.9855 -- iter: 0288/1779
[A[ATraining Step: 794  | total loss: [1m[32m0.05806[0m[0m | time: 85.410s
[2K
| Adam | epoch: 015 | loss: 0.05806 - acc: 0.9838 -- iter: 0320/1779
[A[ATraining Step: 795  | total loss: [1m[32m0.05348[0m[0m | time: 93.960s
[2K
| Adam | epoch: 015 | loss: 0.05348 - acc: 0.9854 -- iter: 0352/1779
[A[ATraining Step: 796  | total loss: [1m[32m0.04903[0m[0m | time: 102.457s
[2K
| Adam | epoch: 015 | loss: 0.04903 - acc: 0.9869 -- iter: 0384/1779
[A[ATraining Step: 797  | total loss: [1m[32m0.04525[0m[0m | time: 107.933s
[2K
| Adam | epoch: 015 | loss: 0.04525 - acc: 0.9882 -- iter: 0416/1779
[A[ATraining Step: 798  | total loss: [1m[32m0.04192[0m[0m | time: 113.618s
[2K
| Adam | epoch: 015 | loss: 0.04192 - acc: 0.9894 -- iter: 0448/1779
[A[ATraining Step: 799  | total loss: [1m[32m0.03845[0m[0m | time: 122.004s
[2K
| Adam | epoch: 015 | loss: 0.03845 - acc: 0.9904 -- iter: 0480/1779
[A[ATraining Step: 800  | total loss: [1m[32m0.03802[0m[0m | time: 156.518s
[2K
| Adam | epoch: 015 | loss: 0.03802 - acc: 0.9914 | val_loss: 0.75554 - val_acc: 0.8402 -- iter: 0512/1779
--
Training Step: 801  | total loss: [1m[32m0.03917[0m[0m | time: 165.123s
[2K
| Adam | epoch: 015 | loss: 0.03917 - acc: 0.9923 -- iter: 0544/1779
[A[ATraining Step: 802  | total loss: [1m[32m0.05200[0m[0m | time: 173.387s
[2K
| Adam | epoch: 015 | loss: 0.05200 - acc: 0.9868 -- iter: 0576/1779
[A[ATraining Step: 803  | total loss: [1m[32m0.04753[0m[0m | time: 182.055s
[2K
| Adam | epoch: 015 | loss: 0.04753 - acc: 0.9881 -- iter: 0608/1779
[A[ATraining Step: 804  | total loss: [1m[32m0.05091[0m[0m | time: 190.748s
[2K
| Adam | epoch: 015 | loss: 0.05091 - acc: 0.9862 -- iter: 0640/1779
[A[ATraining Step: 805  | total loss: [1m[32m0.05857[0m[0m | time: 198.975s
[2K
| Adam | epoch: 015 | loss: 0.05857 - acc: 0.9844 -- iter: 0672/1779
[A[ATraining Step: 806  | total loss: [1m[32m0.05389[0m[0m | time: 207.484s
[2K
| Adam | epoch: 015 | loss: 0.05389 - acc: 0.9860 -- iter: 0704/1779
[A[ATraining Step: 807  | total loss: [1m[32m0.05061[0m[0m | time: 215.749s
[2K
| Adam | epoch: 015 | loss: 0.05061 - acc: 0.9874 -- iter: 0736/1779
[A[ATraining Step: 808  | total loss: [1m[32m0.04564[0m[0m | time: 224.221s
[2K
| Adam | epoch: 015 | loss: 0.04564 - acc: 0.9886 -- iter: 0768/1779
[A[ATraining Step: 809  | total loss: [1m[32m0.04208[0m[0m | time: 232.602s
[2K
| Adam | epoch: 015 | loss: 0.04208 - acc: 0.9898 -- iter: 0800/1779
[A[ATraining Step: 810  | total loss: [1m[32m0.04892[0m[0m | time: 241.097s
[2K
| Adam | epoch: 015 | loss: 0.04892 - acc: 0.9877 -- iter: 0832/1779
[A[ATraining Step: 811  | total loss: [1m[32m0.04442[0m[0m | time: 249.337s
[2K
| Adam | epoch: 015 | loss: 0.04442 - acc: 0.9889 -- iter: 0864/1779
[A[ATraining Step: 812  | total loss: [1m[32m0.04023[0m[0m | time: 257.891s
[2K
| Adam | epoch: 015 | loss: 0.04023 - acc: 0.9900 -- iter: 0896/1779
[A[ATraining Step: 813  | total loss: [1m[32m0.03665[0m[0m | time: 266.311s
[2K
| Adam | epoch: 015 | loss: 0.03665 - acc: 0.9910 -- iter: 0928/1779
[A[ATraining Step: 814  | total loss: [1m[32m0.07545[0m[0m | time: 275.026s
[2K
| Adam | epoch: 015 | loss: 0.07545 - acc: 0.9825 -- iter: 0960/1779
[A[ATraining Step: 815  | total loss: [1m[32m0.06994[0m[0m | time: 283.490s
[2K
| Adam | epoch: 015 | loss: 0.06994 - acc: 0.9843 -- iter: 0992/1779
[A[ATraining Step: 816  | total loss: [1m[32m0.06329[0m[0m | time: 292.030s
[2K
| Adam | epoch: 015 | loss: 0.06329 - acc: 0.9859 -- iter: 1024/1779
[A[ATraining Step: 817  | total loss: [1m[32m0.05716[0m[0m | time: 300.586s
[2K
| Adam | epoch: 015 | loss: 0.05716 - acc: 0.9873 -- iter: 1056/1779
[A[ATraining Step: 818  | total loss: [1m[32m0.05186[0m[0m | time: 309.169s
[2K
| Adam | epoch: 015 | loss: 0.05186 - acc: 0.9885 -- iter: 1088/1779
[A[ATraining Step: 819  | total loss: [1m[32m0.05022[0m[0m | time: 317.711s
[2K
| Adam | epoch: 015 | loss: 0.05022 - acc: 0.9897 -- iter: 1120/1779
[A[ATraining Step: 820  | total loss: [1m[32m0.05080[0m[0m | time: 326.354s
[2K
| Adam | epoch: 015 | loss: 0.05080 - acc: 0.9876 -- iter: 1152/1779
[A[ATraining Step: 821  | total loss: [1m[32m0.04591[0m[0m | time: 335.059s
[2K
| Adam | epoch: 015 | loss: 0.04591 - acc: 0.9888 -- iter: 1184/1779
[A[ATraining Step: 822  | total loss: [1m[32m0.04163[0m[0m | time: 343.495s
[2K
| Adam | epoch: 015 | loss: 0.04163 - acc: 0.9900 -- iter: 1216/1779
[A[ATraining Step: 823  | total loss: [1m[32m0.10024[0m[0m | time: 352.467s
[2K
| Adam | epoch: 015 | loss: 0.10024 - acc: 0.9878 -- iter: 1248/1779
[A[ATraining Step: 824  | total loss: [1m[32m0.09088[0m[0m | time: 360.942s
[2K
| Adam | epoch: 015 | loss: 0.09088 - acc: 0.9890 -- iter: 1280/1779
[A[ATraining Step: 825  | total loss: [1m[32m0.08272[0m[0m | time: 369.534s
[2K
| Adam | epoch: 015 | loss: 0.08272 - acc: 0.9901 -- iter: 1312/1779
[A[ATraining Step: 826  | total loss: [1m[32m0.07505[0m[0m | time: 377.949s
[2K
| Adam | epoch: 015 | loss: 0.07505 - acc: 0.9911 -- iter: 1344/1779
[A[ATraining Step: 827  | total loss: [1m[32m0.07009[0m[0m | time: 386.610s
[2K
| Adam | epoch: 015 | loss: 0.07009 - acc: 0.9920 -- iter: 1376/1779
[A[ATraining Step: 828  | total loss: [1m[32m0.06544[0m[0m | time: 395.030s
[2K
| Adam | epoch: 015 | loss: 0.06544 - acc: 0.9928 -- iter: 1408/1779
[A[ATraining Step: 829  | total loss: [1m[32m0.06149[0m[0m | time: 403.504s
[2K
| Adam | epoch: 015 | loss: 0.06149 - acc: 0.9904 -- iter: 1440/1779
[A[ATraining Step: 830  | total loss: [1m[32m0.05762[0m[0m | time: 411.841s
[2K
| Adam | epoch: 015 | loss: 0.05762 - acc: 0.9914 -- iter: 1472/1779
[A[ATraining Step: 831  | total loss: [1m[32m0.06476[0m[0m | time: 420.211s
[2K
| Adam | epoch: 015 | loss: 0.06476 - acc: 0.9891 -- iter: 1504/1779
[A[ATraining Step: 832  | total loss: [1m[32m0.05879[0m[0m | time: 428.820s
[2K
| Adam | epoch: 015 | loss: 0.05879 - acc: 0.9902 -- iter: 1536/1779
[A[ATraining Step: 833  | total loss: [1m[32m0.05317[0m[0m | time: 437.352s
[2K
| Adam | epoch: 015 | loss: 0.05317 - acc: 0.9912 -- iter: 1568/1779
[A[ATraining Step: 834  | total loss: [1m[32m0.05886[0m[0m | time: 445.713s
[2K
| Adam | epoch: 015 | loss: 0.05886 - acc: 0.9889 -- iter: 1600/1779
[A[ATraining Step: 835  | total loss: [1m[32m0.06178[0m[0m | time: 454.277s
[2K
| Adam | epoch: 015 | loss: 0.06178 - acc: 0.9869 -- iter: 1632/1779
[A[ATraining Step: 836  | total loss: [1m[32m0.06552[0m[0m | time: 462.915s
[2K
| Adam | epoch: 015 | loss: 0.06552 - acc: 0.9820 -- iter: 1664/1779
[A[ATraining Step: 837  | total loss: [1m[32m0.05915[0m[0m | time: 471.469s
[2K
| Adam | epoch: 015 | loss: 0.05915 - acc: 0.9838 -- iter: 1696/1779
[A[ATraining Step: 838  | total loss: [1m[32m0.05544[0m[0m | time: 480.067s
[2K
| Adam | epoch: 015 | loss: 0.05544 - acc: 0.9854 -- iter: 1728/1779
[A[ATraining Step: 839  | total loss: [1m[32m0.05013[0m[0m | time: 488.416s
[2K
| Adam | epoch: 015 | loss: 0.05013 - acc: 0.9869 -- iter: 1760/1779
[A[ATraining Step: 840  | total loss: [1m[32m0.04576[0m[0m | time: 522.970s
[2K
| Adam | epoch: 015 | loss: 0.04576 - acc: 0.9882 | val_loss: 1.18781 - val_acc: 0.6427 -- iter: 1779/1779
--
Validation AUC:0.8870967741935484
Validation AUPRC:0.8754080454883914
Test AUC:0.8926904129375048
Test AUPRC:0.9009110869041338
BestTestF1Score	0.8	0.6	0.8	0.78	0.82	224	62	221	50	0.01
BestTestMCCScore	0.81	0.67	0.83	0.89	0.75	205	25	258	69	0.03
BestTestAccuracyScore	0.8	0.6	0.8	0.78	0.82	224	62	221	50	0.01
BestValidationF1Score	0.82	0.65	0.82	0.84	0.79	220	41	238	58	0.01
BestValidationMCC	0.79	0.65	0.82	0.92	0.69	192	16	263	86	0.03
BestValidationAccuracy	0.82	0.65	0.82	0.84	0.79	220	41	238	58	0.01
TestPredictions (Threshold:0.03)
CHEMBL1078642,TN,INACT,0.029999999329447746	CHEMBL133566,TP,ACT,0.9399999976158142	CHEMBL577915,TP,ACT,0.47999998927116394	CHEMBL176071,TP,ACT,0.23000000417232513	CHEMBL1945683,TN,INACT,0.009999999776482582	CHEMBL60509,TN,INACT,0.009999999776482582	CHEMBL85678,TN,INACT,0.009999999776482582	CHEMBL433790,TP,ACT,0.05000000074505806	CHEMBL222086,TP,ACT,0.05999999865889549	CHEMBL361275,TP,ACT,0.9800000190734863	CHEMBL1619,TN,INACT,0.0	CHEMBL2113616,TP,ACT,0.6499999761581421	CHEMBL412569,TN,INACT,0.0	CHEMBL2113504,FN,ACT,0.019999999552965164	CHEMBL177539,TP,ACT,0.12999999523162842	CHEMBL558766,TN,INACT,0.0	CHEMBL2113436,TP,ACT,0.25999999046325684	CHEMBL165012,TN,INACT,0.019999999552965164	CHEMBL77699,TP,ACT,0.18000000715255737	CHEMBL2111766,TP,ACT,0.3100000023841858	CHEMBL21172,TN,INACT,0.029999999329447746	CHEMBL57908,TN,INACT,0.0	CHEMBL286680,TN,INACT,0.0	CHEMBL107574,TN,INACT,0.0	CHEMBL186023,FN,ACT,0.029999999329447746	CHEMBL169675,TN,INACT,0.019999999552965164	CHEMBL417358,TN,INACT,0.009999999776482582	CHEMBL16724,TP,ACT,0.30000001192092896	CHEMBL359661,TP,ACT,0.2199999988079071	CHEMBL339254,TN,INACT,0.0	CHEMBL177609,TP,ACT,0.6499999761581421	CHEMBL320804,TN,INACT,0.0	CHEMBL255791,FP,INACT,0.05999999865889549	CHEMBL337503,FN,ACT,0.0	CHEMBL139000,FN,ACT,0.029999999329447746	CHEMBL25688,TN,INACT,0.0	CHEMBL89383,TP,ACT,0.10000000149011612	CHEMBL489592,TP,ACT,0.14000000059604645	CHEMBL97700,FN,ACT,0.029999999329447746	CHEMBL94968,FN,ACT,0.019999999552965164	CHEMBL96755,TN,INACT,0.0	CHEMBL2113430,TP,ACT,0.17000000178813934	CHEMBL72060,FP,INACT,0.05000000074505806	CHEMBL67323,FP,INACT,0.03999999910593033	CHEMBL369550,TP,ACT,0.7900000214576721	CHEMBL520229,FN,ACT,0.009999999776482582	CHEMBL336968,TN,INACT,0.009999999776482582	CHEMBL240773,TN,INACT,0.0	CHEMBL3093234,FN,ACT,0.009999999776482582	CHEMBL120278,TN,INACT,0.009999999776482582	CHEMBL40796,TN,INACT,0.009999999776482582	CHEMBL359463,TP,ACT,0.6200000047683716	CHEMBL104198,TN,INACT,0.0	CHEMBL328776,TN,INACT,0.0	CHEMBL49758,TP,ACT,0.10999999940395355	CHEMBL2112962,TP,ACT,0.1599999964237213	CHEMBL2153613,TP,ACT,0.49000000953674316	CHEMBL401440,TP,ACT,0.800000011920929	CHEMBL276676,TN,INACT,0.0	CHEMBL140006,TN,INACT,0.009999999776482582	CHEMBL3238446,TN,INACT,0.009999999776482582	CHEMBL26991,TP,ACT,0.05000000074505806	CHEMBL73740,TN,INACT,0.009999999776482582	CHEMBL369359,TN,INACT,0.0	CHEMBL241082,TN,INACT,0.0	CHEMBL2113541,TP,ACT,1.0	CHEMBL370840,TP,ACT,0.6100000143051147	CHEMBL286682,FP,INACT,0.03999999910593033	CHEMBL3590085,TN,INACT,0.019999999552965164	CHEMBL221352,TP,ACT,0.8600000143051147	CHEMBL3577344,TN,INACT,0.009999999776482582	CHEMBL2113488,TP,ACT,0.23000000417232513	CHEMBL437506,TP,ACT,0.03999999910593033	CHEMBL567801,TP,ACT,0.550000011920929	CHEMBL421349,TN,INACT,0.0	CHEMBL283320,TN,INACT,0.0	CHEMBL3752923,FN,ACT,0.009999999776482582	CHEMBL1775009,TN,INACT,0.009999999776482582	CHEMBL481245,TN,INACT,0.009999999776482582	CHEMBL3665441,TN,INACT,0.009999999776482582	CHEMBL293776,FN,ACT,0.009999999776482582	CHEMBL351531,TN,INACT,0.0	CHEMBL195437,TN,INACT,0.009999999776482582	CHEMBL123099,TN,INACT,0.0	CHEMBL3765580,FN,ACT,0.009999999776482582	CHEMBL2413103,TP,ACT,0.03999999910593033	CHEMBL513390,TN,INACT,0.0	CHEMBL360178,TP,ACT,0.9700000286102295	CHEMBL174448,TN,INACT,0.0	CHEMBL53842,TN,INACT,0.009999999776482582	CHEMBL3143394,TN,INACT,0.0	CHEMBL333438,TN,INACT,0.0	CHEMBL2113564,TP,ACT,0.33000001311302185	CHEMBL426782,TP,ACT,0.949999988079071	CHEMBL39986,TN,INACT,0.0	CHEMBL162706,TN,INACT,0.019999999552965164	CHEMBL182612,TP,ACT,0.07000000029802322	CHEMBL1791423,FN,ACT,0.029999999329447746	CHEMBL178589,TP,ACT,0.6100000143051147	CHEMBL3741465,TN,INACT,0.009999999776482582	CHEMBL3394008,FP,INACT,0.03999999910593033	CHEMBL95727,TN,INACT,0.0	CHEMBL1091790,TN,INACT,0.0	CHEMBL419403,TP,ACT,0.09000000357627869	CHEMBL65461,TN,INACT,0.0	CHEMBL2112320,TN,INACT,0.0	CHEMBL98398,FP,INACT,0.03999999910593033	CHEMBL3423407,TN,INACT,0.0	CHEMBL605685,TP,ACT,0.07000000029802322	CHEMBL3403339,TN,INACT,0.0	CHEMBL2113547,TP,ACT,0.3199999928474426	CHEMBL443926,TN,INACT,0.019999999552965164	CHEMBL8789,TP,ACT,0.10999999940395355	CHEMBL327016,TN,INACT,0.009999999776482582	CHEMBL114745,FP,INACT,0.6299999952316284	CHEMBL360619,TP,ACT,0.6299999952316284	CHEMBL71385,FP,INACT,0.03999999910593033	CHEMBL222901,TP,ACT,0.5699999928474426	CHEMBL3736199,FN,ACT,0.009999999776482582	CHEMBL2113560,TP,ACT,0.4399999976158142	CHEMBL288300,TN,INACT,0.0	CHEMBL72861,TN,INACT,0.0	CHEMBL97753,TP,ACT,0.17000000178813934	CHEMBL3291310,FN,ACT,0.029999999329447746	CHEMBL349505,TN,INACT,0.0	CHEMBL64239,TN,INACT,0.009999999776482582	CHEMBL2113394,TP,ACT,0.20999999344348907	CHEMBL3633663,TN,INACT,0.0	CHEMBL345060,TP,ACT,0.9900000095367432	CHEMBL241099,FP,INACT,0.15000000596046448	CHEMBL3423403,TN,INACT,0.0	CHEMBL27508,TP,ACT,0.27000001072883606	CHEMBL2372077,TN,INACT,0.0	CHEMBL344284,TN,INACT,0.0	CHEMBL387327,TP,ACT,0.3100000023841858	CHEMBL25964,TP,ACT,0.8799999952316284	CHEMBL373654,TN,INACT,0.0	CHEMBL74066,TN,INACT,0.0	CHEMBL3735151,TN,INACT,0.0	CHEMBL536800,FP,INACT,0.05000000074505806	CHEMBL173059,TN,INACT,0.0	CHEMBL187586,TP,ACT,0.9800000190734863	CHEMBL228686,TN,INACT,0.0	CHEMBL1983100,FP,INACT,0.05999999865889549	CHEMBL2113595,TP,ACT,0.1599999964237213	CHEMBL193,TN,INACT,0.0	CHEMBL3754167,FN,ACT,0.019999999552965164	CHEMBL306313,TP,ACT,0.6899999976158142	CHEMBL2112411,TN,INACT,0.0	CHEMBL2164609,TN,INACT,0.009999999776482582	CHEMBL605473,FN,ACT,0.009999999776482582	CHEMBL404505,TN,INACT,0.029999999329447746	CHEMBL203812,TP,ACT,1.0	CHEMBL2113530,TP,ACT,0.09000000357627869	CHEMBL88506,TN,INACT,0.0	CHEMBL2043295,FN,ACT,0.0	CHEMBL25373,FP,INACT,0.05000000074505806	CHEMBL38193,TP,ACT,0.6600000262260437	CHEMBL275987,FP,INACT,0.6800000071525574	CHEMBL80504,TN,INACT,0.0	CHEMBL516024,TN,INACT,0.0	CHEMBL223035,TP,ACT,0.28999999165534973	CHEMBL603596,FN,ACT,0.0	CHEMBL398385,TP,ACT,0.18000000715255737	CHEMBL3403731,TN,INACT,0.009999999776482582	CHEMBL607376,FN,ACT,0.0	CHEMBL78317,TP,ACT,0.05999999865889549	CHEMBL86968,TN,INACT,0.0	CHEMBL1956200,TN,INACT,0.009999999776482582	CHEMBL164302,TN,INACT,0.009999999776482582	CHEMBL458242,TP,ACT,0.05000000074505806	CHEMBL425685,TP,ACT,0.05999999865889549	CHEMBL2153624,TP,ACT,0.20999999344348907	CHEMBL278932,FN,ACT,0.009999999776482582	CHEMBL429575,FN,ACT,0.0	CHEMBL282806,FN,ACT,0.009999999776482582	CHEMBL499035,TN,INACT,0.009999999776482582	CHEMBL140495,TN,INACT,0.0	CHEMBL444307,TN,INACT,0.0	CHEMBL324125,TN,INACT,0.0	CHEMBL111545,TP,ACT,0.8299999833106995	CHEMBL368208,TP,ACT,0.23999999463558197	CHEMBL431770,TP,ACT,0.800000011920929	CHEMBL101218,TP,ACT,0.9200000166893005	CHEMBL568009,TP,ACT,0.4099999964237213	CHEMBL114975,FN,ACT,0.0	CHEMBL78211,TP,ACT,0.5199999809265137	CHEMBL95091,TN,INACT,0.029999999329447746	CHEMBL3393993,TN,INACT,0.0	CHEMBL115940,FN,ACT,0.009999999776482582	CHEMBL1093313,TP,ACT,0.9100000262260437	CHEMBL449710,TP,ACT,0.9700000286102295	CHEMBL1161419,TN,INACT,0.0	CHEMBL1788230,TP,ACT,0.23000000417232513	CHEMBL106359,TN,INACT,0.009999999776482582	CHEMBL313543,FN,ACT,0.009999999776482582	CHEMBL451335,TN,INACT,0.0	CHEMBL2153612,TP,ACT,0.05000000074505806	CHEMBL83235,TP,ACT,0.9900000095367432	CHEMBL2112488,TN,INACT,0.0	CHEMBL3093325,TP,ACT,0.7699999809265137	CHEMBL384248,TN,INACT,0.0	CHEMBL325983,FP,INACT,0.03999999910593033	CHEMBL2326844,TP,ACT,0.36000001430511475	CHEMBL2113434,TP,ACT,0.8700000047683716	CHEMBL27403,TN,INACT,0.0	CHEMBL361229,TP,ACT,0.699999988079071	CHEMBL184061,TP,ACT,0.4300000071525574	CHEMBL3093333,TP,ACT,0.09000000357627869	CHEMBL35415,TP,ACT,0.05000000074505806	CHEMBL2113694,FP,INACT,0.949999988079071	CHEMBL309017,TN,INACT,0.0	CHEMBL233535,TN,INACT,0.0	CHEMBL366737,TN,INACT,0.019999999552965164	CHEMBL342281,FN,ACT,0.0	CHEMBL1568,TP,ACT,0.5600000023841858	CHEMBL197159,TN,INACT,0.019999999552965164	CHEMBL3764434,FN,ACT,0.019999999552965164	CHEMBL2369710,TN,INACT,0.0	CHEMBL387328,TP,ACT,0.9300000071525574	CHEMBL328089,TN,INACT,0.0	CHEMBL109206,TN,INACT,0.0	CHEMBL374151,TP,ACT,0.03999999910593033	CHEMBL228738,TN,INACT,0.0	CHEMBL593443,TN,INACT,0.0	CHEMBL182754,TP,ACT,0.8700000047683716	CHEMBL179054,FN,ACT,0.019999999552965164	CHEMBL315984,FN,ACT,0.0	CHEMBL136394,TP,ACT,0.07999999821186066	CHEMBL104377,TN,INACT,0.019999999552965164	CHEMBL474091,TN,INACT,0.0	CHEMBL298612,TN,INACT,0.009999999776482582	CHEMBL2178724,TN,INACT,0.019999999552965164	CHEMBL16894,TP,ACT,0.09000000357627869	CHEMBL603808,FN,ACT,0.009999999776482582	CHEMBL59347,TN,INACT,0.009999999776482582	CHEMBL241101,TN,INACT,0.0	CHEMBL3217760,TN,INACT,0.0	CHEMBL505086,TN,INACT,0.0	CHEMBL193692,FN,ACT,0.009999999776482582	CHEMBL387632,TN,INACT,0.019999999552965164	CHEMBL223846,TP,ACT,0.5299999713897705	CHEMBL330586,TN,INACT,0.0	CHEMBL109894,FP,INACT,0.11999999731779099	CHEMBL158507,FN,ACT,0.0	CHEMBL110064,TN,INACT,0.0	CHEMBL330377,TP,ACT,0.4699999988079071	CHEMBL417654,TN,INACT,0.0	CHEMBL28057,TN,INACT,0.019999999552965164	CHEMBL98038,TN,INACT,0.0	CHEMBL426669,TP,ACT,0.5	CHEMBL12344,FP,INACT,0.03999999910593033	CHEMBL3827583,FN,ACT,0.029999999329447746	CHEMBL419306,TN,INACT,0.0	CHEMBL410531,TN,INACT,0.009999999776482582	CHEMBL234771,TN,INACT,0.0	CHEMBL2391356,TN,INACT,0.029999999329447746	CHEMBL292293,TN,INACT,0.0	CHEMBL167343,FN,ACT,0.0	CHEMBL177859,TP,ACT,0.9200000166893005	CHEMBL607941,TP,ACT,0.9900000095367432	CHEMBL53662,TN,INACT,0.0	CHEMBL413046,TP,ACT,0.18000000715255737	CHEMBL608748,TN,INACT,0.019999999552965164	CHEMBL308087,TN,INACT,0.0	CHEMBL240507,TP,ACT,0.07999999821186066	CHEMBL157655,FN,ACT,0.0	CHEMBL10801,TN,INACT,0.0	CHEMBL2153623,TP,ACT,0.41999998688697815	CHEMBL2391836,TN,INACT,0.019999999552965164	CHEMBL113142,TP,ACT,0.38999998569488525	CHEMBL1923416,TN,INACT,0.009999999776482582	CHEMBL2070507,TP,ACT,0.05999999865889549	CHEMBL606315,FN,ACT,0.009999999776482582	CHEMBL189192,TP,ACT,0.18000000715255737	CHEMBL3735679,FN,ACT,0.009999999776482582	CHEMBL45160,TN,INACT,0.0	CHEMBL2113628,TP,ACT,0.8500000238418579	CHEMBL73933,TN,INACT,0.0	CHEMBL80438,TN,INACT,0.009999999776482582	CHEMBL261176,FN,ACT,0.009999999776482582	CHEMBL1484,TN,INACT,0.0	CHEMBL332446,TN,INACT,0.0	CHEMBL21937,TN,INACT,0.0	CHEMBL240279,TN,INACT,0.009999999776482582	CHEMBL302027,TN,INACT,0.0	CHEMBL2113563,TP,ACT,0.6399999856948853	CHEMBL365303,TP,ACT,0.9700000286102295	CHEMBL422399,TP,ACT,0.07999999821186066	CHEMBL164321,FN,ACT,0.0	CHEMBL251975,TP,ACT,0.8199999928474426	CHEMBL99169,TP,ACT,0.9800000190734863	CHEMBL118553,TN,INACT,0.0	CHEMBL368092,TP,ACT,0.4399999976158142	CHEMBL439335,TN,INACT,0.009999999776482582	CHEMBL2237158,FP,INACT,0.09000000357627869	CHEMBL319036,TN,INACT,0.0	CHEMBL271606,FN,ACT,0.0	CHEMBL187366,TP,ACT,0.8399999737739563	CHEMBL2062854,TN,INACT,0.0	CHEMBL186960,TP,ACT,0.8700000047683716	CHEMBL338723,FN,ACT,0.009999999776482582	CHEMBL179638,FP,INACT,0.33000001311302185	CHEMBL21508,TN,INACT,0.0	CHEMBL294649,TN,INACT,0.0	CHEMBL16867,TP,ACT,0.05999999865889549	CHEMBL294302,FN,ACT,0.0	CHEMBL3736248,TN,INACT,0.0	CHEMBL312374,TN,INACT,0.0	CHEMBL63760,TN,INACT,0.0	CHEMBL285334,TN,INACT,0.0	CHEMBL483469,TP,ACT,0.8600000143051147	CHEMBL112417,TN,INACT,0.0	CHEMBL125588,TN,INACT,0.0	CHEMBL66393,TP,ACT,0.7699999809265137	CHEMBL1765668,TN,INACT,0.0	CHEMBL165783,TP,ACT,0.25999999046325684	CHEMBL3290984,TN,INACT,0.0	CHEMBL184655,TP,ACT,0.9399999976158142	CHEMBL103433,TN,INACT,0.0	CHEMBL2153618,TP,ACT,0.7200000286102295	CHEMBL612215,FN,ACT,0.019999999552965164	CHEMBL222868,TP,ACT,0.25	CHEMBL514965,TN,INACT,0.0	CHEMBL2382439,TP,ACT,0.03999999910593033	CHEMBL421523,TN,INACT,0.009999999776482582	CHEMBL3114163,TN,INACT,0.019999999552965164	CHEMBL3763806,FN,ACT,0.009999999776482582	CHEMBL194272,TP,ACT,0.949999988079071	CHEMBL314533,TN,INACT,0.0	CHEMBL276854,TN,INACT,0.0	CHEMBL520212,TN,INACT,0.019999999552965164	CHEMBL74330,TN,INACT,0.019999999552965164	CHEMBL213878,TP,ACT,0.3100000023841858	CHEMBL20993,FP,INACT,0.12999999523162842	CHEMBL605265,TP,ACT,0.20999999344348907	CHEMBL59673,FN,ACT,0.0	CHEMBL320174,TN,INACT,0.029999999329447746	CHEMBL610993,TP,ACT,0.15000000596046448	CHEMBL100382,TP,ACT,0.6399999856948853	CHEMBL2113533,TP,ACT,0.36000001430511475	CHEMBL3093236,TP,ACT,0.9599999785423279	CHEMBL81593,TN,INACT,0.0	CHEMBL3093221,TP,ACT,0.10999999940395355	CHEMBL62421,TN,INACT,0.019999999552965164	CHEMBL2304158,TP,ACT,0.05999999865889549	CHEMBL432974,TN,INACT,0.0	CHEMBL147365,TN,INACT,0.019999999552965164	CHEMBL222767,TP,ACT,0.7900000214576721	CHEMBL437,TN,INACT,0.019999999552965164	CHEMBL319924,TN,INACT,0.009999999776482582	CHEMBL9034,TP,ACT,0.09000000357627869	CHEMBL440864,TN,INACT,0.009999999776482582	CHEMBL604647,FN,ACT,0.009999999776482582	CHEMBL301826,TN,INACT,0.009999999776482582	CHEMBL121307,TN,INACT,0.029999999329447746	CHEMBL76128,TN,INACT,0.009999999776482582	CHEMBL368620,TP,ACT,0.9599999785423279	CHEMBL411732,TP,ACT,0.18000000715255737	CHEMBL612214,TP,ACT,0.2199999988079071	CHEMBL608464,TP,ACT,0.6800000071525574	CHEMBL175907,FN,ACT,0.0	CHEMBL3735036,TN,INACT,0.0	CHEMBL45305,TN,INACT,0.009999999776482582	CHEMBL76576,TN,INACT,0.009999999776482582	CHEMBL296419,TN,INACT,0.0	CHEMBL3093238,TP,ACT,0.7099999785423279	CHEMBL608181,TP,ACT,0.49000000953674316	CHEMBL2113400,TP,ACT,0.10000000149011612	CHEMBL60962,FN,ACT,0.009999999776482582	CHEMBL423260,TN,INACT,0.0	CHEMBL64235,TN,INACT,0.019999999552965164	CHEMBL320178,TN,INACT,0.009999999776482582	CHEMBL186885,TP,ACT,0.9700000286102295	CHEMBL3093326,TP,ACT,0.7400000095367432	CHEMBL461088,TN,INACT,0.0	CHEMBL104947,TN,INACT,0.009999999776482582	CHEMBL344678,TP,ACT,0.9200000166893005	CHEMBL3618474,TP,ACT,0.9599999785423279	CHEMBL607729,FN,ACT,0.0	CHEMBL3218123,TN,INACT,0.0	CHEMBL2063640,FN,ACT,0.0	CHEMBL2153603,TP,ACT,0.15000000596046448	CHEMBL355370,TP,ACT,0.15000000596046448	CHEMBL521223,FN,ACT,0.009999999776482582	CHEMBL222145,TP,ACT,1.0	CHEMBL199413,TN,INACT,0.009999999776482582	CHEMBL413079,TP,ACT,0.03999999910593033	CHEMBL261177,FN,ACT,0.019999999552965164	CHEMBL3291305,TP,ACT,0.09000000357627869	CHEMBL1907839,TN,INACT,0.0	CHEMBL1788234,TP,ACT,0.9300000071525574	CHEMBL3290994,TN,INACT,0.009999999776482582	CHEMBL17094,TP,ACT,0.9300000071525574	CHEMBL265587,TP,ACT,0.9399999976158142	CHEMBL3754252,FN,ACT,0.009999999776482582	CHEMBL291821,TN,INACT,0.0	CHEMBL345357,TN,INACT,0.009999999776482582	CHEMBL296715,TN,INACT,0.0	CHEMBL17013,TP,ACT,0.07999999821186066	CHEMBL150696,TN,INACT,0.0	CHEMBL2113534,TP,ACT,0.05999999865889549	CHEMBL160932,TN,INACT,0.029999999329447746	CHEMBL280982,TP,ACT,0.38999998569488525	CHEMBL39632,TN,INACT,0.0	CHEMBL608462,TP,ACT,0.2199999988079071	CHEMBL608463,TP,ACT,0.550000011920929	CHEMBL276819,TN,INACT,0.0	CHEMBL3234532,TN,INACT,0.0	CHEMBL97961,TP,ACT,0.9900000095367432	CHEMBL241100,TN,INACT,0.0	CHEMBL608985,TN,INACT,0.009999999776482582	CHEMBL608814,TN,INACT,0.0	CHEMBL1095695,FN,ACT,0.009999999776482582	CHEMBL606031,TN,INACT,0.009999999776482582	CHEMBL610651,TP,ACT,0.23999999463558197	CHEMBL47138,TN,INACT,0.0	CHEMBL104172,FP,INACT,0.10000000149011612	CHEMBL357077,TN,INACT,0.0	CHEMBL3093220,TP,ACT,0.8299999833106995	CHEMBL1201353,TN,INACT,0.0	CHEMBL364048,TP,ACT,0.949999988079071	CHEMBL2112968,TP,ACT,0.15000000596046448	CHEMBL60189,TN,INACT,0.0	CHEMBL156863,FN,ACT,0.009999999776482582	CHEMBL2112665,TN,INACT,0.009999999776482582	CHEMBL3218121,TN,INACT,0.0	CHEMBL97937,TP,ACT,0.05999999865889549	CHEMBL277041,TP,ACT,0.23999999463558197	CHEMBL308756,TN,INACT,0.0	CHEMBL2112163,TN,INACT,0.009999999776482582	CHEMBL578145,TP,ACT,0.15000000596046448	CHEMBL435575,TP,ACT,0.23999999463558197	CHEMBL510130,TN,INACT,0.0	CHEMBL619,TN,INACT,0.0	CHEMBL3618469,TP,ACT,0.05000000074505806	CHEMBL589,TN,INACT,0.0	CHEMBL574602,TN,INACT,0.019999999552965164	CHEMBL282776,TN,INACT,0.0	CHEMBL1907840,TN,INACT,0.0	CHEMBL111218,TN,INACT,0.0	CHEMBL3093224,TP,ACT,0.47999998927116394	CHEMBL73272,FP,INACT,0.10000000149011612	CHEMBL193421,TP,ACT,0.8899999856948853	CHEMBL98570,FN,ACT,0.009999999776482582	CHEMBL3633665,TN,INACT,0.0	CHEMBL167335,TN,INACT,0.029999999329447746	CHEMBL101554,TN,INACT,0.0	CHEMBL1088253,FN,ACT,0.009999999776482582	CHEMBL138396,TP,ACT,0.6600000262260437	CHEMBL62066,TN,INACT,0.009999999776482582	CHEMBL2391353,TN,INACT,0.009999999776482582	CHEMBL3828044,TP,ACT,0.10000000149011612	CHEMBL316792,TN,INACT,0.0	CHEMBL95229,FN,ACT,0.019999999552965164	CHEMBL3093330,TP,ACT,0.9100000262260437	CHEMBL604851,TP,ACT,0.6000000238418579	CHEMBL3828343,FN,ACT,0.029999999329447746	CHEMBL312150,FP,INACT,0.6299999952316284	CHEMBL310728,TN,INACT,0.0	CHEMBL274855,TP,ACT,0.7900000214576721	CHEMBL367257,TP,ACT,0.18000000715255737	CHEMBL2113479,TP,ACT,0.07000000029802322	CHEMBL3291292,FN,ACT,0.019999999552965164	CHEMBL11592,TN,INACT,0.019999999552965164	CHEMBL293478,TN,INACT,0.019999999552965164	CHEMBL423852,TP,ACT,0.03999999910593033	CHEMBL334933,TN,INACT,0.0	CHEMBL2113582,TP,ACT,0.05000000074505806	CHEMBL205768,TN,INACT,0.0	CHEMBL78830,TN,INACT,0.0	CHEMBL2153616,TP,ACT,0.4399999976158142	CHEMBL277079,TN,INACT,0.0	CHEMBL284288,TP,ACT,0.7900000214576721	CHEMBL305516,TN,INACT,0.009999999776482582	CHEMBL2113622,TP,ACT,0.9399999976158142	CHEMBL416963,TP,ACT,0.07000000029802322	CHEMBL453822,TN,INACT,0.0	CHEMBL2153610,TP,ACT,0.03999999910593033	CHEMBL211696,TN,INACT,0.0	CHEMBL78601,TN,INACT,0.009999999776482582	CHEMBL76933,TN,INACT,0.0	CHEMBL3827301,FN,ACT,0.019999999552965164	CHEMBL377246,TP,ACT,0.05000000074505806	CHEMBL3093320,TP,ACT,0.7200000286102295	CHEMBL285819,TP,ACT,0.9399999976158142	CHEMBL303203,TN,INACT,0.0	CHEMBL201706,FN,ACT,0.019999999552965164	CHEMBL609493,FN,ACT,0.009999999776482582	CHEMBL227378,TN,INACT,0.0	CHEMBL474708,TN,INACT,0.0	CHEMBL576883,TP,ACT,0.6299999952316284	CHEMBL297215,TN,INACT,0.009999999776482582	CHEMBL98637,TP,ACT,0.5199999809265137	CHEMBL2079643,TP,ACT,0.9599999785423279	CHEMBL302829,TN,INACT,0.009999999776482582	CHEMBL99983,TP,ACT,0.15000000596046448	CHEMBL3314919,FP,INACT,0.1599999964237213	CHEMBL414605,TN,INACT,0.0	CHEMBL98221,TP,ACT,0.18000000715255737	CHEMBL188982,TP,ACT,0.5600000023841858	CHEMBL1090123,TP,ACT,0.1899999976158142	CHEMBL143761,TN,INACT,0.009999999776482582	CHEMBL312079,TP,ACT,0.20000000298023224	CHEMBL423239,TP,ACT,0.05000000074505806	CHEMBL2312973,FN,ACT,0.009999999776482582	CHEMBL551813,TN,INACT,0.019999999552965164	CHEMBL83574,TP,ACT,0.6299999952316284	CHEMBL160396,TN,INACT,0.0	CHEMBL40986,TN,INACT,0.0	CHEMBL2112484,FN,ACT,0.0	CHEMBL228144,TN,INACT,0.0	CHEMBL450463,TN,INACT,0.009999999776482582	CHEMBL3115577,TN,INACT,0.0	CHEMBL163488,TN,INACT,0.0	CHEMBL257547,TN,INACT,0.019999999552965164	CHEMBL608657,TN,INACT,0.0	CHEMBL3093327,FN,ACT,0.0	CHEMBL313306,TP,ACT,0.28999999165534973	CHEMBL3577343,TN,INACT,0.009999999776482582	CHEMBL103404,FP,INACT,0.10999999940395355	CHEMBL380914,TP,ACT,0.4699999988079071	CHEMBL398593,TP,ACT,0.5899999737739563	CHEMBL2113502,TP,ACT,0.7900000214576721	CHEMBL89457,TN,INACT,0.0	CHEMBL603602,TP,ACT,0.07000000029802322	CHEMBL176155,TP,ACT,0.7099999785423279	CHEMBL103731,TN,INACT,0.0	CHEMBL3403337,TN,INACT,0.019999999552965164	CHEMBL59466,FN,ACT,0.0	CHEMBL105483,TN,INACT,0.009999999776482582	CHEMBL285357,TN,INACT,0.019999999552965164	CHEMBL319539,FN,ACT,0.019999999552965164	CHEMBL302447,TN,INACT,0.0	CHEMBL1250,TN,INACT,0.0	CHEMBL177660,TP,ACT,0.699999988079071	CHEMBL320763,TN,INACT,0.0	CHEMBL403029,TN,INACT,0.0	CHEMBL354126,TN,INACT,0.0	CHEMBL520830,TP,ACT,0.8799999952316284	CHEMBL717,TN,INACT,0.0	CHEMBL87496,FN,ACT,0.0	CHEMBL3291309,TP,ACT,0.5099999904632568	CHEMBL2113397,TP,ACT,0.14000000059604645	CHEMBL177711,TP,ACT,0.9399999976158142	CHEMBL2111571,TP,ACT,0.4099999964237213	CHEMBL611293,TP,ACT,0.14000000059604645	CHEMBL142515,TN,INACT,0.0	CHEMBL3827598,TP,ACT,0.03999999910593033	CHEMBL221615,TP,ACT,0.75	CHEMBL64124,TN,INACT,0.0	CHEMBL97748,TP,ACT,0.49000000953674316	CHEMBL140365,TN,INACT,0.0	CHEMBL57362,TP,ACT,0.20999999344348907	CHEMBL323723,TN,INACT,0.0	CHEMBL2382438,TP,ACT,1.0	CHEMBL316968,TN,INACT,0.029999999329447746	

