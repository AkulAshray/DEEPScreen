CNNModel CHEMBL4625 adam 0.001 30 256 0 0.8 False True
Number of active compounds :	315
Number of inactive compounds :	210
---------------------------------
Run id: CNNModel_CHEMBL4625_adam_0.001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4625_adam_0.001_30_256_0.8_True/
---------------------------------
Training samples: 334
Validation samples: 105
--
Training Step: 1  | time: 1.966s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/334
[A[ATraining Step: 2  | total loss: [1m[32m0.62409[0m[0m | time: 3.358s
[2K
| Adam | epoch: 001 | loss: 0.62409 - acc: 0.3375 -- iter: 064/334
[A[ATraining Step: 3  | total loss: [1m[32m0.67947[0m[0m | time: 4.660s
[2K
| Adam | epoch: 001 | loss: 0.67947 - acc: 0.4960 -- iter: 096/334
[A[ATraining Step: 4  | total loss: [1m[32m0.65528[0m[0m | time: 5.903s
[2K
| Adam | epoch: 001 | loss: 0.65528 - acc: 0.7568 -- iter: 128/334
[A[ATraining Step: 5  | total loss: [1m[32m0.66014[0m[0m | time: 7.096s
[2K
| Adam | epoch: 001 | loss: 0.66014 - acc: 0.6656 -- iter: 160/334
[A[ATraining Step: 6  | total loss: [1m[32m0.74399[0m[0m | time: 8.295s
[2K
| Adam | epoch: 001 | loss: 0.74399 - acc: 0.5792 -- iter: 192/334
[A[ATraining Step: 7  | total loss: [1m[32m0.76352[0m[0m | time: 9.497s
[2K
| Adam | epoch: 001 | loss: 0.76352 - acc: 0.4942 -- iter: 224/334
[A[ATraining Step: 8  | total loss: [1m[32m0.70820[0m[0m | time: 10.629s
[2K
| Adam | epoch: 001 | loss: 0.70820 - acc: 0.5678 -- iter: 256/334
[A[ATraining Step: 9  | total loss: [1m[32m0.68511[0m[0m | time: 11.721s
[2K
| Adam | epoch: 001 | loss: 0.68511 - acc: 0.6477 -- iter: 288/334
[A[ATraining Step: 10  | total loss: [1m[32m0.68207[0m[0m | time: 12.589s
[2K
| Adam | epoch: 001 | loss: 0.68207 - acc: 0.6520 -- iter: 320/334
[A[ATraining Step: 11  | total loss: [1m[32m0.68614[0m[0m | time: 14.156s
[2K
| Adam | epoch: 001 | loss: 0.68614 - acc: 0.5948 | val_loss: 0.69154 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 12  | total loss: [1m[32m0.69409[0m[0m | time: 0.423s
[2K
| Adam | epoch: 002 | loss: 0.69409 - acc: 0.4878 -- iter: 032/334
[A[ATraining Step: 13  | total loss: [1m[32m0.69804[0m[0m | time: 1.324s
[2K
| Adam | epoch: 002 | loss: 0.69804 - acc: 0.4318 -- iter: 064/334
[A[ATraining Step: 14  | total loss: [1m[32m0.69493[0m[0m | time: 2.308s
[2K
| Adam | epoch: 002 | loss: 0.69493 - acc: 0.4853 -- iter: 096/334
[A[ATraining Step: 15  | total loss: [1m[32m0.69092[0m[0m | time: 3.235s
[2K
| Adam | epoch: 002 | loss: 0.69092 - acc: 0.5644 -- iter: 128/334
[A[ATraining Step: 16  | total loss: [1m[32m0.68971[0m[0m | time: 4.362s
[2K
| Adam | epoch: 002 | loss: 0.68971 - acc: 0.5871 -- iter: 160/334
[A[ATraining Step: 17  | total loss: [1m[32m0.69007[0m[0m | time: 5.631s
[2K
| Adam | epoch: 002 | loss: 0.69007 - acc: 0.5783 -- iter: 192/334
[A[ATraining Step: 18  | total loss: [1m[32m0.69217[0m[0m | time: 6.903s
[2K
| Adam | epoch: 002 | loss: 0.69217 - acc: 0.5295 -- iter: 224/334
[A[ATraining Step: 19  | total loss: [1m[32m0.69309[0m[0m | time: 7.747s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5093 -- iter: 256/334
[A[ATraining Step: 20  | total loss: [1m[32m0.69187[0m[0m | time: 8.714s
[2K
| Adam | epoch: 002 | loss: 0.69187 - acc: 0.5364 -- iter: 288/334
[A[ATraining Step: 21  | total loss: [1m[32m0.69024[0m[0m | time: 9.681s
[2K
| Adam | epoch: 002 | loss: 0.69024 - acc: 0.5736 -- iter: 320/334
[A[ATraining Step: 22  | total loss: [1m[32m0.68820[0m[0m | time: 11.672s
[2K
| Adam | epoch: 002 | loss: 0.68820 - acc: 0.6172 | val_loss: 0.69167 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 23  | total loss: [1m[32m0.68841[0m[0m | time: 0.467s
[2K
| Adam | epoch: 003 | loss: 0.68841 - acc: 0.6104 -- iter: 032/334
[A[ATraining Step: 24  | total loss: [1m[32m0.68531[0m[0m | time: 0.906s
[2K
| Adam | epoch: 003 | loss: 0.68531 - acc: 0.6597 -- iter: 064/334
[A[ATraining Step: 25  | total loss: [1m[32m0.68273[0m[0m | time: 1.868s
[2K
| Adam | epoch: 003 | loss: 0.68273 - acc: 0.6941 -- iter: 096/334
[A[ATraining Step: 26  | total loss: [1m[32m0.68333[0m[0m | time: 2.945s
[2K
| Adam | epoch: 003 | loss: 0.68333 - acc: 0.6758 -- iter: 128/334
[A[ATraining Step: 27  | total loss: [1m[32m0.68077[0m[0m | time: 4.273s
[2K
| Adam | epoch: 003 | loss: 0.68077 - acc: 0.6949 -- iter: 160/334
[A[ATraining Step: 28  | total loss: [1m[32m0.68269[0m[0m | time: 5.330s
[2K
| Adam | epoch: 003 | loss: 0.68269 - acc: 0.6618 -- iter: 192/334
[A[ATraining Step: 29  | total loss: [1m[32m0.68213[0m[0m | time: 6.233s
[2K
| Adam | epoch: 003 | loss: 0.68213 - acc: 0.6528 -- iter: 224/334
[A[ATraining Step: 30  | total loss: [1m[32m0.67826[0m[0m | time: 7.177s
[2K
| Adam | epoch: 003 | loss: 0.67826 - acc: 0.6684 -- iter: 256/334
[A[ATraining Step: 31  | total loss: [1m[32m0.67872[0m[0m | time: 8.165s
[2K
| Adam | epoch: 003 | loss: 0.67872 - acc: 0.6512 -- iter: 288/334
[A[ATraining Step: 32  | total loss: [1m[32m0.67607[0m[0m | time: 9.456s
[2K
| Adam | epoch: 003 | loss: 0.67607 - acc: 0.6523 -- iter: 320/334
[A[ATraining Step: 33  | total loss: [1m[32m0.67465[0m[0m | time: 12.044s
[2K
| Adam | epoch: 003 | loss: 0.67465 - acc: 0.6463 | val_loss: 0.70824 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 34  | total loss: [1m[32m0.66235[0m[0m | time: 1.161s
[2K
| Adam | epoch: 004 | loss: 0.66235 - acc: 0.6686 -- iter: 032/334
[A[ATraining Step: 35  | total loss: [1m[32m0.67866[0m[0m | time: 1.698s
[2K
| Adam | epoch: 004 | loss: 0.67866 - acc: 0.6267 -- iter: 064/334
[A[ATraining Step: 36  | total loss: [1m[32m0.68193[0m[0m | time: 2.330s
[2K
| Adam | epoch: 004 | loss: 0.68193 - acc: 0.6154 -- iter: 096/334
[A[ATraining Step: 37  | total loss: [1m[32m0.68458[0m[0m | time: 3.557s
[2K
| Adam | epoch: 004 | loss: 0.68458 - acc: 0.6066 -- iter: 128/334
[A[ATraining Step: 38  | total loss: [1m[32m0.68868[0m[0m | time: 4.718s
[2K
| Adam | epoch: 004 | loss: 0.68868 - acc: 0.5919 -- iter: 160/334
[A[ATraining Step: 39  | total loss: [1m[32m0.68580[0m[0m | time: 5.623s
[2K
| Adam | epoch: 004 | loss: 0.68580 - acc: 0.5922 -- iter: 192/334
[A[ATraining Step: 40  | total loss: [1m[32m0.68779[0m[0m | time: 6.514s
[2K
| Adam | epoch: 004 | loss: 0.68779 - acc: 0.5808 -- iter: 224/334
[A[ATraining Step: 41  | total loss: [1m[32m0.69272[0m[0m | time: 7.482s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.5602 -- iter: 256/334
[A[ATraining Step: 42  | total loss: [1m[32m0.68834[0m[0m | time: 8.412s
[2K
| Adam | epoch: 004 | loss: 0.68834 - acc: 0.5719 -- iter: 288/334
[A[ATraining Step: 43  | total loss: [1m[32m0.68639[0m[0m | time: 9.299s
[2K
| Adam | epoch: 004 | loss: 0.68639 - acc: 0.5757 -- iter: 320/334
[A[ATraining Step: 44  | total loss: [1m[32m0.68636[0m[0m | time: 11.311s
[2K
| Adam | epoch: 004 | loss: 0.68636 - acc: 0.5734 | val_loss: 0.69125 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 45  | total loss: [1m[32m0.68376[0m[0m | time: 0.995s
[2K
| Adam | epoch: 005 | loss: 0.68376 - acc: 0.5822 -- iter: 032/334
[A[ATraining Step: 46  | total loss: [1m[32m0.67951[0m[0m | time: 1.853s
[2K
| Adam | epoch: 005 | loss: 0.67951 - acc: 0.5998 -- iter: 064/334
[A[ATraining Step: 47  | total loss: [1m[32m0.67387[0m[0m | time: 2.303s
[2K
| Adam | epoch: 005 | loss: 0.67387 - acc: 0.6243 -- iter: 096/334
[A[ATraining Step: 48  | total loss: [1m[32m0.66806[0m[0m | time: 2.740s
[2K
| Adam | epoch: 005 | loss: 0.66806 - acc: 0.6503 -- iter: 128/334
[A[ATraining Step: 49  | total loss: [1m[32m0.66267[0m[0m | time: 3.640s
[2K
| Adam | epoch: 005 | loss: 0.66267 - acc: 0.6717 -- iter: 160/334
[A[ATraining Step: 50  | total loss: [1m[32m0.66351[0m[0m | time: 4.553s
[2K
| Adam | epoch: 005 | loss: 0.66351 - acc: 0.6644 -- iter: 192/334
[A[ATraining Step: 51  | total loss: [1m[32m0.66690[0m[0m | time: 5.591s
[2K
| Adam | epoch: 005 | loss: 0.66690 - acc: 0.6489 -- iter: 224/334
[A[ATraining Step: 52  | total loss: [1m[32m0.66247[0m[0m | time: 6.603s
[2K
| Adam | epoch: 005 | loss: 0.66247 - acc: 0.6594 -- iter: 256/334
[A[ATraining Step: 53  | total loss: [1m[32m0.66114[0m[0m | time: 7.426s
[2K
| Adam | epoch: 005 | loss: 0.66114 - acc: 0.6589 -- iter: 288/334
[A[ATraining Step: 54  | total loss: [1m[32m0.66325[0m[0m | time: 8.501s
[2K
| Adam | epoch: 005 | loss: 0.66325 - acc: 0.6494 -- iter: 320/334
[A[ATraining Step: 55  | total loss: [1m[32m0.66243[0m[0m | time: 10.563s
[2K
| Adam | epoch: 005 | loss: 0.66243 - acc: 0.6459 | val_loss: 0.70795 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 56  | total loss: [1m[32m0.67338[0m[0m | time: 0.877s
[2K
| Adam | epoch: 006 | loss: 0.67338 - acc: 0.6210 -- iter: 032/334
[A[ATraining Step: 57  | total loss: [1m[32m0.67377[0m[0m | time: 1.841s
[2K
| Adam | epoch: 006 | loss: 0.67377 - acc: 0.6173 -- iter: 064/334
[A[ATraining Step: 58  | total loss: [1m[32m0.67184[0m[0m | time: 2.747s
[2K
| Adam | epoch: 006 | loss: 0.67184 - acc: 0.6183 -- iter: 096/334
[A[ATraining Step: 59  | total loss: [1m[32m0.67671[0m[0m | time: 3.185s
[2K
| Adam | epoch: 006 | loss: 0.67671 - acc: 0.6066 -- iter: 128/334
[A[ATraining Step: 60  | total loss: [1m[32m0.65952[0m[0m | time: 3.618s
[2K
| Adam | epoch: 006 | loss: 0.65952 - acc: 0.6398 -- iter: 160/334
[A[ATraining Step: 61  | total loss: [1m[32m0.64346[0m[0m | time: 4.579s
[2K
| Adam | epoch: 006 | loss: 0.64346 - acc: 0.6681 -- iter: 192/334
[A[ATraining Step: 62  | total loss: [1m[32m0.64757[0m[0m | time: 5.548s
[2K
| Adam | epoch: 006 | loss: 0.64757 - acc: 0.6586 -- iter: 224/334
[A[ATraining Step: 63  | total loss: [1m[32m0.65196[0m[0m | time: 6.764s
[2K
| Adam | epoch: 006 | loss: 0.65196 - acc: 0.6503 -- iter: 256/334
[A[ATraining Step: 64  | total loss: [1m[32m0.66230[0m[0m | time: 8.115s
[2K
| Adam | epoch: 006 | loss: 0.66230 - acc: 0.6355 -- iter: 288/334
[A[ATraining Step: 65  | total loss: [1m[32m0.67093[0m[0m | time: 9.550s
[2K
| Adam | epoch: 006 | loss: 0.67093 - acc: 0.6226 -- iter: 320/334
[A[ATraining Step: 66  | total loss: [1m[32m0.68099[0m[0m | time: 63.199s
[2K
| Adam | epoch: 006 | loss: 0.68099 - acc: 0.6039 | val_loss: 0.69808 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 67  | total loss: [1m[32m0.67830[0m[0m | time: 30.032s
[2K
| Adam | epoch: 007 | loss: 0.67830 - acc: 0.6064 -- iter: 032/334
[A[ATraining Step: 68  | total loss: [1m[32m0.66815[0m[0m | time: 31.125s
[2K
| Adam | epoch: 007 | loss: 0.66815 - acc: 0.6271 -- iter: 064/334
[A[ATraining Step: 69  | total loss: [1m[32m0.66537[0m[0m | time: 33.067s
[2K
| Adam | epoch: 007 | loss: 0.66537 - acc: 0.6305 -- iter: 096/334
[A[ATraining Step: 70  | total loss: [1m[32m0.66189[0m[0m | time: 34.219s
[2K
| Adam | epoch: 007 | loss: 0.66189 - acc: 0.6371 -- iter: 128/334
[A[ATraining Step: 71  | total loss: [1m[32m0.66396[0m[0m | time: 34.839s
[2K
| Adam | epoch: 007 | loss: 0.66396 - acc: 0.6286 -- iter: 160/334
[A[ATraining Step: 72  | total loss: [1m[32m0.65939[0m[0m | time: 35.419s
[2K
| Adam | epoch: 007 | loss: 0.65939 - acc: 0.6382 -- iter: 192/334
[A[ATraining Step: 73  | total loss: [1m[32m0.65560[0m[0m | time: 36.669s
[2K
| Adam | epoch: 007 | loss: 0.65560 - acc: 0.6467 -- iter: 224/334
[A[ATraining Step: 74  | total loss: [1m[32m0.65353[0m[0m | time: 37.974s
[2K
| Adam | epoch: 007 | loss: 0.65353 - acc: 0.6512 -- iter: 256/334
[A[ATraining Step: 75  | total loss: [1m[32m0.65798[0m[0m | time: 39.268s
[2K
| Adam | epoch: 007 | loss: 0.65798 - acc: 0.6382 -- iter: 288/334
[A[ATraining Step: 76  | total loss: [1m[32m0.66067[0m[0m | time: 40.372s
[2K
| Adam | epoch: 007 | loss: 0.66067 - acc: 0.6301 -- iter: 320/334
[A[ATraining Step: 77  | total loss: [1m[32m0.66002[0m[0m | time: 42.717s
[2K
| Adam | epoch: 007 | loss: 0.66002 - acc: 0.6295 | val_loss: 0.69646 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 78  | total loss: [1m[32m0.66393[0m[0m | time: 1.583s
[2K
| Adam | epoch: 008 | loss: 0.66393 - acc: 0.6192 -- iter: 032/334
[A[ATraining Step: 79  | total loss: [1m[32m0.65494[0m[0m | time: 30.581s
[2K
| Adam | epoch: 008 | loss: 0.65494 - acc: 0.6360 -- iter: 064/334
[A[ATraining Step: 80  | total loss: [1m[32m0.65905[0m[0m | time: 78.313s
[2K
| Adam | epoch: 008 | loss: 0.65905 - acc: 0.6253 -- iter: 096/334
[A[ATraining Step: 81  | total loss: [1m[32m0.66326[0m[0m | time: 98.102s
[2K
| Adam | epoch: 008 | loss: 0.66326 - acc: 0.6158 -- iter: 128/334
[A[ATraining Step: 82  | total loss: [1m[32m0.65818[0m[0m | time: 109.758s
[2K
| Adam | epoch: 008 | loss: 0.65818 - acc: 0.6230 -- iter: 160/334
[A[ATraining Step: 83  | total loss: [1m[32m0.66078[0m[0m | time: 116.589s
[2K
| Adam | epoch: 008 | loss: 0.66078 - acc: 0.6169 -- iter: 192/334
[A[ATraining Step: 84  | total loss: [1m[32m0.66267[0m[0m | time: 127.340s
[2K
| Adam | epoch: 008 | loss: 0.66267 - acc: 0.6124 -- iter: 224/334
[A[ATraining Step: 85  | total loss: [1m[32m0.66419[0m[0m | time: 128.460s
[2K
| Adam | epoch: 008 | loss: 0.66419 - acc: 0.6083 -- iter: 256/334
[A[ATraining Step: 86  | total loss: [1m[32m0.66579[0m[0m | time: 129.658s
[2K
| Adam | epoch: 008 | loss: 0.66579 - acc: 0.6037 -- iter: 288/334
[A[ATraining Step: 87  | total loss: [1m[32m0.65657[0m[0m | time: 131.013s
[2K
| Adam | epoch: 008 | loss: 0.65657 - acc: 0.6183 -- iter: 320/334
[A[ATraining Step: 88  | total loss: [1m[32m0.65513[0m[0m | time: 133.305s
[2K
| Adam | epoch: 008 | loss: 0.65513 - acc: 0.6190 | val_loss: 0.69223 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 89  | total loss: [1m[32m0.64740[0m[0m | time: 1.436s
[2K
| Adam | epoch: 009 | loss: 0.64740 - acc: 0.6290 -- iter: 032/334
[A[ATraining Step: 90  | total loss: [1m[32m0.64904[0m[0m | time: 2.676s
[2K
| Adam | epoch: 009 | loss: 0.64904 - acc: 0.6223 -- iter: 064/334
[A[ATraining Step: 91  | total loss: [1m[32m0.64621[0m[0m | time: 3.855s
[2K
| Adam | epoch: 009 | loss: 0.64621 - acc: 0.6226 -- iter: 096/334
[A[ATraining Step: 92  | total loss: [1m[32m0.64170[0m[0m | time: 5.085s
[2K
| Adam | epoch: 009 | loss: 0.64170 - acc: 0.6260 -- iter: 128/334
[A[ATraining Step: 93  | total loss: [1m[32m0.63625[0m[0m | time: 6.414s
[2K
| Adam | epoch: 009 | loss: 0.63625 - acc: 0.6290 -- iter: 160/334
[A[ATraining Step: 94  | total loss: [1m[32m0.64490[0m[0m | time: 7.791s
[2K
| Adam | epoch: 009 | loss: 0.64490 - acc: 0.6161 -- iter: 192/334
[A[ATraining Step: 95  | total loss: [1m[32m0.63654[0m[0m | time: 8.517s
[2K
| Adam | epoch: 009 | loss: 0.63654 - acc: 0.6232 -- iter: 224/334
[A[ATraining Step: 96  | total loss: [1m[32m0.64666[0m[0m | time: 9.073s
[2K
| Adam | epoch: 009 | loss: 0.64666 - acc: 0.6038 -- iter: 256/334
[A[ATraining Step: 97  | total loss: [1m[32m0.65310[0m[0m | time: 10.210s
[2K
| Adam | epoch: 009 | loss: 0.65310 - acc: 0.5862 -- iter: 288/334
[A[ATraining Step: 98  | total loss: [1m[32m0.64775[0m[0m | time: 11.493s
[2K
| Adam | epoch: 009 | loss: 0.64775 - acc: 0.5932 -- iter: 320/334
[A[ATraining Step: 99  | total loss: [1m[32m0.64910[0m[0m | time: 13.626s
[2K
| Adam | epoch: 009 | loss: 0.64910 - acc: 0.5839 | val_loss: 0.62624 - val_acc: 0.5333 -- iter: 334/334
--
Training Step: 100  | total loss: [1m[32m0.64614[0m[0m | time: 1.283s
[2K
| Adam | epoch: 010 | loss: 0.64614 - acc: 0.5912 -- iter: 032/334
[A[ATraining Step: 101  | total loss: [1m[32m0.64260[0m[0m | time: 2.559s
[2K
| Adam | epoch: 010 | loss: 0.64260 - acc: 0.5883 -- iter: 064/334
[A[ATraining Step: 102  | total loss: [1m[32m0.64005[0m[0m | time: 3.774s
[2K
| Adam | epoch: 010 | loss: 0.64005 - acc: 0.5826 -- iter: 096/334
[A[ATraining Step: 103  | total loss: [1m[32m0.61689[0m[0m | time: 4.989s
[2K
| Adam | epoch: 010 | loss: 0.61689 - acc: 0.5962 -- iter: 128/334
[A[ATraining Step: 104  | total loss: [1m[32m0.61261[0m[0m | time: 6.435s
[2K
| Adam | epoch: 010 | loss: 0.61261 - acc: 0.5991 -- iter: 160/334
[A[ATraining Step: 105  | total loss: [1m[32m0.60086[0m[0m | time: 7.816s
[2K
| Adam | epoch: 010 | loss: 0.60086 - acc: 0.6048 -- iter: 192/334
[A[ATraining Step: 106  | total loss: [1m[32m0.58976[0m[0m | time: 14.360s
[2K
| Adam | epoch: 010 | loss: 0.58976 - acc: 0.6037 -- iter: 224/334
[A[ATraining Step: 107  | total loss: [1m[32m0.58920[0m[0m | time: 15.327s
[2K
| Adam | epoch: 010 | loss: 0.58920 - acc: 0.6246 -- iter: 256/334
[A[ATraining Step: 108  | total loss: [1m[32m0.57014[0m[0m | time: 25.663s
[2K
| Adam | epoch: 010 | loss: 0.57014 - acc: 0.6478 -- iter: 288/334
[A[ATraining Step: 109  | total loss: [1m[32m0.55083[0m[0m | time: 54.281s
[2K
| Adam | epoch: 010 | loss: 0.55083 - acc: 0.6688 -- iter: 320/334
[A[ATraining Step: 110  | total loss: [1m[32m0.53676[0m[0m | time: 75.647s
[2K
| Adam | epoch: 010 | loss: 0.53676 - acc: 0.6863 | val_loss: 0.50888 - val_acc: 0.7810 -- iter: 334/334
--
Training Step: 111  | total loss: [1m[32m0.54978[0m[0m | time: 1.369s
[2K
| Adam | epoch: 011 | loss: 0.54978 - acc: 0.6770 -- iter: 032/334
[A[ATraining Step: 112  | total loss: [1m[32m0.54395[0m[0m | time: 2.540s
[2K
| Adam | epoch: 011 | loss: 0.54395 - acc: 0.6874 -- iter: 064/334
[A[ATraining Step: 113  | total loss: [1m[32m0.52928[0m[0m | time: 3.925s
[2K
| Adam | epoch: 011 | loss: 0.52928 - acc: 0.6999 -- iter: 096/334
[A[ATraining Step: 114  | total loss: [1m[32m0.53404[0m[0m | time: 5.260s
[2K
| Adam | epoch: 011 | loss: 0.53404 - acc: 0.6956 -- iter: 128/334
[A[ATraining Step: 115  | total loss: [1m[32m0.51670[0m[0m | time: 6.579s
[2K
| Adam | epoch: 011 | loss: 0.51670 - acc: 0.7135 -- iter: 160/334
[A[ATraining Step: 116  | total loss: [1m[32m0.50125[0m[0m | time: 7.966s
[2K
| Adam | epoch: 011 | loss: 0.50125 - acc: 0.7234 -- iter: 192/334
[A[ATraining Step: 117  | total loss: [1m[32m0.54953[0m[0m | time: 9.332s
[2K
| Adam | epoch: 011 | loss: 0.54953 - acc: 0.7104 -- iter: 224/334
[A[ATraining Step: 118  | total loss: [1m[32m0.53713[0m[0m | time: 10.543s
[2K
| Adam | epoch: 011 | loss: 0.53713 - acc: 0.7207 -- iter: 256/334
[A[ATraining Step: 119  | total loss: [1m[32m0.52960[0m[0m | time: 11.197s
[2K
| Adam | epoch: 011 | loss: 0.52960 - acc: 0.7236 -- iter: 288/334
[A[ATraining Step: 120  | total loss: [1m[32m0.51844[0m[0m | time: 11.698s
[2K
| Adam | epoch: 011 | loss: 0.51844 - acc: 0.7227 -- iter: 320/334
[A[ATraining Step: 121  | total loss: [1m[32m0.51281[0m[0m | time: 13.930s
[2K
| Adam | epoch: 011 | loss: 0.51281 - acc: 0.7147 | val_loss: 0.52357 - val_acc: 0.7619 -- iter: 334/334
--
Training Step: 122  | total loss: [1m[32m0.50663[0m[0m | time: 0.910s
[2K
| Adam | epoch: 012 | loss: 0.50663 - acc: 0.7213 -- iter: 032/334
[A[ATraining Step: 123  | total loss: [1m[32m0.50785[0m[0m | time: 1.859s
[2K
| Adam | epoch: 012 | loss: 0.50785 - acc: 0.7273 -- iter: 064/334
[A[ATraining Step: 124  | total loss: [1m[32m0.50633[0m[0m | time: 2.891s
[2K
| Adam | epoch: 012 | loss: 0.50633 - acc: 0.7358 -- iter: 096/334
[A[ATraining Step: 125  | total loss: [1m[32m0.49957[0m[0m | time: 3.816s
[2K
| Adam | epoch: 012 | loss: 0.49957 - acc: 0.7466 -- iter: 128/334
[A[ATraining Step: 126  | total loss: [1m[32m0.49157[0m[0m | time: 4.930s
[2K
| Adam | epoch: 012 | loss: 0.49157 - acc: 0.7438 -- iter: 160/334
[A[ATraining Step: 127  | total loss: [1m[32m0.48531[0m[0m | time: 5.794s
[2K
| Adam | epoch: 012 | loss: 0.48531 - acc: 0.7507 -- iter: 192/334
[A[ATraining Step: 128  | total loss: [1m[32m0.48536[0m[0m | time: 6.845s
[2K
| Adam | epoch: 012 | loss: 0.48536 - acc: 0.7569 -- iter: 224/334
[A[ATraining Step: 129  | total loss: [1m[32m0.46885[0m[0m | time: 7.924s
[2K
| Adam | epoch: 012 | loss: 0.46885 - acc: 0.7687 -- iter: 256/334
[A[ATraining Step: 130  | total loss: [1m[32m0.46078[0m[0m | time: 9.081s
[2K
| Adam | epoch: 012 | loss: 0.46078 - acc: 0.7700 -- iter: 288/334
[A[ATraining Step: 131  | total loss: [1m[32m0.45713[0m[0m | time: 9.467s
[2K
| Adam | epoch: 012 | loss: 0.45713 - acc: 0.7742 -- iter: 320/334
[A[ATraining Step: 132  | total loss: [1m[32m0.48695[0m[0m | time: 10.935s
[2K
| Adam | epoch: 012 | loss: 0.48695 - acc: 0.7539 | val_loss: 0.62084 - val_acc: 0.7048 -- iter: 334/334
--
Training Step: 133  | total loss: [1m[32m0.50320[0m[0m | time: 0.952s
[2K
| Adam | epoch: 013 | loss: 0.50320 - acc: 0.7428 -- iter: 032/334
[A[ATraining Step: 134  | total loss: [1m[32m0.51185[0m[0m | time: 1.898s
[2K
| Adam | epoch: 013 | loss: 0.51185 - acc: 0.7467 -- iter: 064/334
[A[ATraining Step: 135  | total loss: [1m[32m0.51134[0m[0m | time: 2.861s
[2K
| Adam | epoch: 013 | loss: 0.51134 - acc: 0.7501 -- iter: 096/334
[A[ATraining Step: 136  | total loss: [1m[32m0.49621[0m[0m | time: 3.796s
[2K
| Adam | epoch: 013 | loss: 0.49621 - acc: 0.7626 -- iter: 128/334
[A[ATraining Step: 137  | total loss: [1m[32m0.48962[0m[0m | time: 4.713s
[2K
| Adam | epoch: 013 | loss: 0.48962 - acc: 0.7645 -- iter: 160/334
[A[ATraining Step: 138  | total loss: [1m[32m0.48483[0m[0m | time: 5.825s
[2K
| Adam | epoch: 013 | loss: 0.48483 - acc: 0.7662 -- iter: 192/334
[A[ATraining Step: 139  | total loss: [1m[32m0.47622[0m[0m | time: 7.278s
[2K
| Adam | epoch: 013 | loss: 0.47622 - acc: 0.7645 -- iter: 224/334
[A[ATraining Step: 140  | total loss: [1m[32m0.46746[0m[0m | time: 8.532s
[2K
| Adam | epoch: 013 | loss: 0.46746 - acc: 0.7756 -- iter: 256/334
[A[ATraining Step: 141  | total loss: [1m[32m0.46850[0m[0m | time: 23.341s
[2K
| Adam | epoch: 013 | loss: 0.46850 - acc: 0.7668 -- iter: 288/334
[A[ATraining Step: 142  | total loss: [1m[32m0.46663[0m[0m | time: 24.402s
[2K
| Adam | epoch: 013 | loss: 0.46663 - acc: 0.7713 -- iter: 320/334
[A[ATraining Step: 143  | total loss: [1m[32m0.45713[0m[0m | time: 49.454s
[2K
| Adam | epoch: 013 | loss: 0.45713 - acc: 0.7817 | val_loss: 0.50763 - val_acc: 0.7714 -- iter: 334/334
--
Training Step: 144  | total loss: [1m[32m0.44914[0m[0m | time: 0.549s
[2K
| Adam | epoch: 014 | loss: 0.44914 - acc: 0.7893 -- iter: 032/334
[A[ATraining Step: 145  | total loss: [1m[32m0.44124[0m[0m | time: 1.791s
[2K
| Adam | epoch: 014 | loss: 0.44124 - acc: 0.7960 -- iter: 064/334
[A[ATraining Step: 146  | total loss: [1m[32m0.43992[0m[0m | time: 3.197s
[2K
| Adam | epoch: 014 | loss: 0.43992 - acc: 0.7914 -- iter: 096/334
[A[ATraining Step: 147  | total loss: [1m[32m0.43685[0m[0m | time: 4.494s
[2K
| Adam | epoch: 014 | loss: 0.43685 - acc: 0.7873 -- iter: 128/334
[A[ATraining Step: 148  | total loss: [1m[32m0.45002[0m[0m | time: 5.712s
[2K
| Adam | epoch: 014 | loss: 0.45002 - acc: 0.7773 -- iter: 160/334
[A[ATraining Step: 149  | total loss: [1m[32m0.44996[0m[0m | time: 7.114s
[2K
| Adam | epoch: 014 | loss: 0.44996 - acc: 0.7777 -- iter: 192/334
[A[ATraining Step: 150  | total loss: [1m[32m0.44890[0m[0m | time: 8.511s
[2K
| Adam | epoch: 014 | loss: 0.44890 - acc: 0.7812 -- iter: 224/334
[A[ATraining Step: 151  | total loss: [1m[32m0.43847[0m[0m | time: 9.812s
[2K
| Adam | epoch: 014 | loss: 0.43847 - acc: 0.7874 -- iter: 256/334
[A[ATraining Step: 152  | total loss: [1m[32m0.42859[0m[0m | time: 11.005s
[2K
| Adam | epoch: 014 | loss: 0.42859 - acc: 0.7962 -- iter: 288/334
[A[ATraining Step: 153  | total loss: [1m[32m0.42169[0m[0m | time: 12.365s
[2K
| Adam | epoch: 014 | loss: 0.42169 - acc: 0.7947 -- iter: 320/334
[A[ATraining Step: 154  | total loss: [1m[32m0.42294[0m[0m | time: 15.479s
[2K
| Adam | epoch: 014 | loss: 0.42294 - acc: 0.7965 | val_loss: 0.43346 - val_acc: 0.8095 -- iter: 334/334
--
Training Step: 155  | total loss: [1m[32m0.41584[0m[0m | time: 0.501s
[2K
| Adam | epoch: 015 | loss: 0.41584 - acc: 0.7981 -- iter: 032/334
[A[ATraining Step: 156  | total loss: [1m[32m0.40772[0m[0m | time: 1.128s
[2K
| Adam | epoch: 015 | loss: 0.40772 - acc: 0.8040 -- iter: 064/334
[A[ATraining Step: 157  | total loss: [1m[32m0.40086[0m[0m | time: 2.353s
[2K
| Adam | epoch: 015 | loss: 0.40086 - acc: 0.8093 -- iter: 096/334
[A[ATraining Step: 158  | total loss: [1m[32m0.41652[0m[0m | time: 3.735s
[2K
| Adam | epoch: 015 | loss: 0.41652 - acc: 0.8034 -- iter: 128/334
[A[ATraining Step: 159  | total loss: [1m[32m0.41630[0m[0m | time: 5.092s
[2K
| Adam | epoch: 015 | loss: 0.41630 - acc: 0.8012 -- iter: 160/334
[A[ATraining Step: 160  | total loss: [1m[32m0.41603[0m[0m | time: 6.347s
[2K
| Adam | epoch: 015 | loss: 0.41603 - acc: 0.8054 -- iter: 192/334
[A[ATraining Step: 161  | total loss: [1m[32m0.41153[0m[0m | time: 7.777s
[2K
| Adam | epoch: 015 | loss: 0.41153 - acc: 0.8093 -- iter: 224/334
[A[ATraining Step: 162  | total loss: [1m[32m0.40529[0m[0m | time: 9.155s
[2K
| Adam | epoch: 015 | loss: 0.40529 - acc: 0.8252 -- iter: 256/334
[A[ATraining Step: 163  | total loss: [1m[32m0.39659[0m[0m | time: 10.550s
[2K
| Adam | epoch: 015 | loss: 0.39659 - acc: 0.8239 -- iter: 288/334
[A[ATraining Step: 164  | total loss: [1m[32m0.40047[0m[0m | time: 11.825s
[2K
| Adam | epoch: 015 | loss: 0.40047 - acc: 0.8165 -- iter: 320/334
[A[ATraining Step: 165  | total loss: [1m[32m0.42521[0m[0m | time: 20.414s
[2K
| Adam | epoch: 015 | loss: 0.42521 - acc: 0.8005 | val_loss: 0.43699 - val_acc: 0.8286 -- iter: 334/334
--
Training Step: 166  | total loss: [1m[32m0.41716[0m[0m | time: 16.599s
[2K
| Adam | epoch: 016 | loss: 0.41716 - acc: 0.8017 -- iter: 032/334
[A[ATraining Step: 167  | total loss: [1m[32m0.40893[0m[0m | time: 17.183s
[2K
| Adam | epoch: 016 | loss: 0.40893 - acc: 0.8028 -- iter: 064/334
[A[ATraining Step: 168  | total loss: [1m[32m0.41336[0m[0m | time: 17.717s
[2K
| Adam | epoch: 016 | loss: 0.41336 - acc: 0.7939 -- iter: 096/334
[A[ATraining Step: 169  | total loss: [1m[32m0.41891[0m[0m | time: 18.905s
[2K
| Adam | epoch: 016 | loss: 0.41891 - acc: 0.7860 -- iter: 128/334
[A[ATraining Step: 170  | total loss: [1m[32m0.41022[0m[0m | time: 20.100s
[2K
| Adam | epoch: 016 | loss: 0.41022 - acc: 0.7949 -- iter: 160/334
[A[ATraining Step: 171  | total loss: [1m[32m0.40755[0m[0m | time: 21.533s
[2K
| Adam | epoch: 016 | loss: 0.40755 - acc: 0.8029 -- iter: 192/334
[A[ATraining Step: 172  | total loss: [1m[32m0.41067[0m[0m | time: 22.922s
[2K
| Adam | epoch: 016 | loss: 0.41067 - acc: 0.8101 -- iter: 224/334
[A[ATraining Step: 173  | total loss: [1m[32m0.40508[0m[0m | time: 24.326s
[2K
| Adam | epoch: 016 | loss: 0.40508 - acc: 0.8135 -- iter: 256/334
[A[ATraining Step: 174  | total loss: [1m[32m0.40070[0m[0m | time: 25.894s
[2K
| Adam | epoch: 016 | loss: 0.40070 - acc: 0.8196 -- iter: 288/334
[A[ATraining Step: 175  | total loss: [1m[32m0.39112[0m[0m | time: 27.399s
[2K
| Adam | epoch: 016 | loss: 0.39112 - acc: 0.8220 -- iter: 320/334
[A[ATraining Step: 176  | total loss: [1m[32m0.40462[0m[0m | time: 29.770s
[2K
| Adam | epoch: 016 | loss: 0.40462 - acc: 0.8086 | val_loss: 0.44335 - val_acc: 0.7810 -- iter: 334/334
--
Training Step: 177  | total loss: [1m[32m0.42544[0m[0m | time: 1.130s
[2K
| Adam | epoch: 017 | loss: 0.42544 - acc: 0.7902 -- iter: 032/334
[A[ATraining Step: 178  | total loss: [1m[32m0.41524[0m[0m | time: 2.391s
[2K
| Adam | epoch: 017 | loss: 0.41524 - acc: 0.8018 -- iter: 064/334
[A[ATraining Step: 179  | total loss: [1m[32m0.40892[0m[0m | time: 3.005s
[2K
| Adam | epoch: 017 | loss: 0.40892 - acc: 0.8060 -- iter: 096/334
[A[ATraining Step: 180  | total loss: [1m[32m0.41201[0m[0m | time: 3.624s
[2K
| Adam | epoch: 017 | loss: 0.41201 - acc: 0.8040 -- iter: 128/334
[A[ATraining Step: 181  | total loss: [1m[32m0.41424[0m[0m | time: 4.908s
[2K
| Adam | epoch: 017 | loss: 0.41424 - acc: 0.8022 -- iter: 160/334
[A[ATraining Step: 182  | total loss: [1m[32m0.39923[0m[0m | time: 6.218s
[2K
| Adam | epoch: 017 | loss: 0.39923 - acc: 0.8094 -- iter: 192/334
[A[ATraining Step: 183  | total loss: [1m[32m0.38105[0m[0m | time: 7.592s
[2K
| Adam | epoch: 017 | loss: 0.38105 - acc: 0.8222 -- iter: 224/334
[A[ATraining Step: 184  | total loss: [1m[32m0.39398[0m[0m | time: 8.799s
[2K
| Adam | epoch: 017 | loss: 0.39398 - acc: 0.8119 -- iter: 256/334
[A[ATraining Step: 185  | total loss: [1m[32m0.39237[0m[0m | time: 10.036s
[2K
| Adam | epoch: 017 | loss: 0.39237 - acc: 0.8151 -- iter: 288/334
[A[ATraining Step: 186  | total loss: [1m[32m0.39327[0m[0m | time: 11.435s
[2K
| Adam | epoch: 017 | loss: 0.39327 - acc: 0.8180 -- iter: 320/334
[A[ATraining Step: 187  | total loss: [1m[32m0.38532[0m[0m | time: 13.804s
[2K
| Adam | epoch: 017 | loss: 0.38532 - acc: 0.8205 | val_loss: 0.41540 - val_acc: 0.8190 -- iter: 334/334
--
Training Step: 188  | total loss: [1m[32m0.38628[0m[0m | time: 1.456s
[2K
| Adam | epoch: 018 | loss: 0.38628 - acc: 0.8166 -- iter: 032/334
[A[ATraining Step: 189  | total loss: [1m[32m0.36992[0m[0m | time: 2.831s
[2K
| Adam | epoch: 018 | loss: 0.36992 - acc: 0.8224 -- iter: 064/334
[A[ATraining Step: 190  | total loss: [1m[32m0.36261[0m[0m | time: 4.058s
[2K
| Adam | epoch: 018 | loss: 0.36261 - acc: 0.8246 -- iter: 096/334
[A[ATraining Step: 191  | total loss: [1m[32m0.34905[0m[0m | time: 4.668s
[2K
| Adam | epoch: 018 | loss: 0.34905 - acc: 0.8327 -- iter: 128/334
[A[ATraining Step: 192  | total loss: [1m[32m0.36040[0m[0m | time: 5.146s
[2K
| Adam | epoch: 018 | loss: 0.36040 - acc: 0.8209 -- iter: 160/334
[A[ATraining Step: 193  | total loss: [1m[32m0.36411[0m[0m | time: 6.207s
[2K
| Adam | epoch: 018 | loss: 0.36411 - acc: 0.8245 -- iter: 192/334
[A[ATraining Step: 194  | total loss: [1m[32m0.35393[0m[0m | time: 7.189s
[2K
| Adam | epoch: 018 | loss: 0.35393 - acc: 0.8327 -- iter: 224/334
[A[ATraining Step: 195  | total loss: [1m[32m0.33862[0m[0m | time: 8.153s
[2K
| Adam | epoch: 018 | loss: 0.33862 - acc: 0.8432 -- iter: 256/334
[A[ATraining Step: 196  | total loss: [1m[32m0.34967[0m[0m | time: 9.240s
[2K
| Adam | epoch: 018 | loss: 0.34967 - acc: 0.8401 -- iter: 288/334
[A[ATraining Step: 197  | total loss: [1m[32m0.33707[0m[0m | time: 10.521s
[2K
| Adam | epoch: 018 | loss: 0.33707 - acc: 0.8436 -- iter: 320/334
[A[ATraining Step: 198  | total loss: [1m[32m0.33417[0m[0m | time: 12.441s
[2K
| Adam | epoch: 018 | loss: 0.33417 - acc: 0.8467 | val_loss: 0.39895 - val_acc: 0.8095 -- iter: 334/334
--
Training Step: 199  | total loss: [1m[32m0.32636[0m[0m | time: 0.952s
[2K
| Adam | epoch: 019 | loss: 0.32636 - acc: 0.8558 -- iter: 032/334
[A[ATraining Step: 200  | total loss: [1m[32m0.32346[0m[0m | time: 3.091s
[2K
| Adam | epoch: 019 | loss: 0.32346 - acc: 0.8577 | val_loss: 0.39769 - val_acc: 0.8095 -- iter: 064/334
--
Training Step: 201  | total loss: [1m[32m0.32499[0m[0m | time: 4.158s
[2K
| Adam | epoch: 019 | loss: 0.32499 - acc: 0.8563 -- iter: 096/334
[A[ATraining Step: 202  | total loss: [1m[32m0.32367[0m[0m | time: 5.338s
[2K
| Adam | epoch: 019 | loss: 0.32367 - acc: 0.8551 -- iter: 128/334
[A[ATraining Step: 203  | total loss: [1m[32m0.30853[0m[0m | time: 5.856s
[2K
| Adam | epoch: 019 | loss: 0.30853 - acc: 0.8664 -- iter: 160/334
[A[ATraining Step: 204  | total loss: [1m[32m0.30470[0m[0m | time: 6.446s
[2K
| Adam | epoch: 019 | loss: 0.30470 - acc: 0.8655 -- iter: 192/334
[A[ATraining Step: 205  | total loss: [1m[32m0.29361[0m[0m | time: 7.307s
[2K
| Adam | epoch: 019 | loss: 0.29361 - acc: 0.8718 -- iter: 224/334
[A[ATraining Step: 206  | total loss: [1m[32m0.37794[0m[0m | time: 8.313s
[2K
| Adam | epoch: 019 | loss: 0.37794 - acc: 0.8534 -- iter: 256/334
[A[ATraining Step: 207  | total loss: [1m[32m0.40520[0m[0m | time: 9.258s
[2K
| Adam | epoch: 019 | loss: 0.40520 - acc: 0.8493 -- iter: 288/334
[A[ATraining Step: 208  | total loss: [1m[32m0.41271[0m[0m | time: 10.235s
[2K
| Adam | epoch: 019 | loss: 0.41271 - acc: 0.8425 -- iter: 320/334
[A[ATraining Step: 209  | total loss: [1m[32m0.39650[0m[0m | time: 12.206s
[2K
| Adam | epoch: 019 | loss: 0.39650 - acc: 0.8489 | val_loss: 0.69049 - val_acc: 0.6667 -- iter: 334/334
--
Training Step: 210  | total loss: [1m[32m0.41581[0m[0m | time: 1.371s
[2K
| Adam | epoch: 020 | loss: 0.41581 - acc: 0.8359 -- iter: 032/334
[A[ATraining Step: 211  | total loss: [1m[32m0.43011[0m[0m | time: 2.849s
[2K
| Adam | epoch: 020 | loss: 0.43011 - acc: 0.8241 -- iter: 064/334
[A[ATraining Step: 212  | total loss: [1m[32m0.42904[0m[0m | time: 4.187s
[2K
| Adam | epoch: 020 | loss: 0.42904 - acc: 0.8230 -- iter: 096/334
[A[ATraining Step: 213  | total loss: [1m[32m0.42366[0m[0m | time: 8.321s
[2K
| Adam | epoch: 020 | loss: 0.42366 - acc: 0.8219 -- iter: 128/334
[A[ATraining Step: 214  | total loss: [1m[32m0.41750[0m[0m | time: 16.251s
[2K
| Adam | epoch: 020 | loss: 0.41750 - acc: 0.8210 -- iter: 160/334
[A[ATraining Step: 215  | total loss: [1m[32m0.41418[0m[0m | time: 26.267s
[2K
| Adam | epoch: 020 | loss: 0.41418 - acc: 0.8233 -- iter: 192/334
[A[ATraining Step: 216  | total loss: [1m[32m0.41001[0m[0m | time: 26.836s
[2K
| Adam | epoch: 020 | loss: 0.41001 - acc: 0.8338 -- iter: 224/334
[A[ATraining Step: 217  | total loss: [1m[32m0.40650[0m[0m | time: 27.876s
[2K
| Adam | epoch: 020 | loss: 0.40650 - acc: 0.8433 -- iter: 256/334
[A[ATraining Step: 218  | total loss: [1m[32m0.40522[0m[0m | time: 29.109s
[2K
| Adam | epoch: 020 | loss: 0.40522 - acc: 0.8496 -- iter: 288/334
[A[ATraining Step: 219  | total loss: [1m[32m0.39140[0m[0m | time: 30.349s
[2K
| Adam | epoch: 020 | loss: 0.39140 - acc: 0.8584 -- iter: 320/334
[A[ATraining Step: 220  | total loss: [1m[32m0.37961[0m[0m | time: 32.548s
[2K
| Adam | epoch: 020 | loss: 0.37961 - acc: 0.8600 | val_loss: 0.41700 - val_acc: 0.7714 -- iter: 334/334
--
Training Step: 221  | total loss: [1m[32m0.37030[0m[0m | time: 1.353s
[2K
| Adam | epoch: 021 | loss: 0.37030 - acc: 0.8584 -- iter: 032/334
[A[ATraining Step: 222  | total loss: [1m[32m0.35778[0m[0m | time: 2.681s
[2K
| Adam | epoch: 021 | loss: 0.35778 - acc: 0.8663 -- iter: 064/334
[A[ATraining Step: 223  | total loss: [1m[32m0.34306[0m[0m | time: 4.132s
[2K
| Adam | epoch: 021 | loss: 0.34306 - acc: 0.8703 -- iter: 096/334
[A[ATraining Step: 224  | total loss: [1m[32m0.33622[0m[0m | time: 5.491s
[2K
| Adam | epoch: 021 | loss: 0.33622 - acc: 0.8739 -- iter: 128/334
[A[ATraining Step: 225  | total loss: [1m[32m0.35427[0m[0m | time: 6.887s
[2K
| Adam | epoch: 021 | loss: 0.35427 - acc: 0.8553 -- iter: 160/334
[A[ATraining Step: 226  | total loss: [1m[32m0.34222[0m[0m | time: 18.642s
[2K
| Adam | epoch: 021 | loss: 0.34222 - acc: 0.8604 -- iter: 192/334
[A[ATraining Step: 227  | total loss: [1m[32m0.32201[0m[0m | time: 22.552s
[2K
| Adam | epoch: 021 | loss: 0.32201 - acc: 0.8681 -- iter: 224/334
[A[ATraining Step: 228  | total loss: [1m[32m0.30703[0m[0m | time: 24.734s
[2K
| Adam | epoch: 021 | loss: 0.30703 - acc: 0.8670 -- iter: 256/334
[A[ATraining Step: 229  | total loss: [1m[32m0.28539[0m[0m | time: 28.567s
[2K
| Adam | epoch: 021 | loss: 0.28539 - acc: 0.8803 -- iter: 288/334
[A[ATraining Step: 230  | total loss: [1m[32m0.29835[0m[0m | time: 29.811s
[2K
| Adam | epoch: 021 | loss: 0.29835 - acc: 0.8735 -- iter: 320/334
[A[ATraining Step: 231  | total loss: [1m[32m0.30812[0m[0m | time: 32.045s
[2K
| Adam | epoch: 021 | loss: 0.30812 - acc: 0.8737 | val_loss: 0.41500 - val_acc: 0.8381 -- iter: 334/334
--
Training Step: 232  | total loss: [1m[32m0.29695[0m[0m | time: 1.354s
[2K
| Adam | epoch: 022 | loss: 0.29695 - acc: 0.8769 -- iter: 032/334
[A[ATraining Step: 233  | total loss: [1m[32m0.30727[0m[0m | time: 2.560s
[2K
| Adam | epoch: 022 | loss: 0.30727 - acc: 0.8705 -- iter: 064/334
[A[ATraining Step: 234  | total loss: [1m[32m0.30465[0m[0m | time: 3.779s
[2K
| Adam | epoch: 022 | loss: 0.30465 - acc: 0.8709 -- iter: 096/334
[A[ATraining Step: 235  | total loss: [1m[32m0.28753[0m[0m | time: 5.251s
[2K
| Adam | epoch: 022 | loss: 0.28753 - acc: 0.8807 -- iter: 128/334
[A[ATraining Step: 236  | total loss: [1m[32m0.27943[0m[0m | time: 6.557s
[2K
| Adam | epoch: 022 | loss: 0.27943 - acc: 0.8864 -- iter: 160/334
[A[ATraining Step: 237  | total loss: [1m[32m0.27221[0m[0m | time: 7.951s
[2K
| Adam | epoch: 022 | loss: 0.27221 - acc: 0.8915 -- iter: 192/334
[A[ATraining Step: 238  | total loss: [1m[32m0.26345[0m[0m | time: 9.525s
[2K
| Adam | epoch: 022 | loss: 0.26345 - acc: 0.8930 -- iter: 224/334
[A[ATraining Step: 239  | total loss: [1m[32m0.27007[0m[0m | time: 11.062s
[2K
| Adam | epoch: 022 | loss: 0.27007 - acc: 0.8881 -- iter: 256/334
[A[ATraining Step: 240  | total loss: [1m[32m0.26019[0m[0m | time: 12.198s
[2K
| Adam | epoch: 022 | loss: 0.26019 - acc: 0.8921 -- iter: 288/334
[A[ATraining Step: 241  | total loss: [1m[32m0.24844[0m[0m | time: 13.428s
[2K
| Adam | epoch: 022 | loss: 0.24844 - acc: 0.8957 -- iter: 320/334
[A[ATraining Step: 242  | total loss: [1m[32m0.26500[0m[0m | time: 15.857s
[2K
| Adam | epoch: 022 | loss: 0.26500 - acc: 0.8905 | val_loss: 0.33847 - val_acc: 0.8286 -- iter: 334/334
--
Training Step: 243  | total loss: [1m[32m0.27765[0m[0m | time: 1.196s
[2K
| Adam | epoch: 023 | loss: 0.27765 - acc: 0.8827 -- iter: 032/334
[A[ATraining Step: 244  | total loss: [1m[32m0.27196[0m[0m | time: 2.645s
[2K
| Adam | epoch: 023 | loss: 0.27196 - acc: 0.8851 -- iter: 064/334
[A[ATraining Step: 245  | total loss: [1m[32m0.26563[0m[0m | time: 4.085s
[2K
| Adam | epoch: 023 | loss: 0.26563 - acc: 0.8841 -- iter: 096/334
[A[ATraining Step: 246  | total loss: [1m[32m0.25524[0m[0m | time: 5.400s
[2K
| Adam | epoch: 023 | loss: 0.25524 - acc: 0.8894 -- iter: 128/334
[A[ATraining Step: 247  | total loss: [1m[32m0.24431[0m[0m | time: 6.711s
[2K
| Adam | epoch: 023 | loss: 0.24431 - acc: 0.8974 -- iter: 160/334
[A[ATraining Step: 248  | total loss: [1m[32m0.24084[0m[0m | time: 8.274s
[2K
| Adam | epoch: 023 | loss: 0.24084 - acc: 0.9045 -- iter: 192/334
[A[ATraining Step: 249  | total loss: [1m[32m0.23965[0m[0m | time: 9.712s
[2K
| Adam | epoch: 023 | loss: 0.23965 - acc: 0.9047 -- iter: 224/334
[A[ATraining Step: 250  | total loss: [1m[32m0.22909[0m[0m | time: 11.160s
[2K
| Adam | epoch: 023 | loss: 0.22909 - acc: 0.9111 -- iter: 256/334
[A[ATraining Step: 251  | total loss: [1m[32m0.21720[0m[0m | time: 11.812s
[2K
| Adam | epoch: 023 | loss: 0.21720 - acc: 0.9200 -- iter: 288/334
[A[ATraining Step: 252  | total loss: [1m[32m0.23224[0m[0m | time: 12.501s
[2K
| Adam | epoch: 023 | loss: 0.23224 - acc: 0.9065 -- iter: 320/334
[A[ATraining Step: 253  | total loss: [1m[32m0.24413[0m[0m | time: 15.040s
[2K
| Adam | epoch: 023 | loss: 0.24413 - acc: 0.9016 | val_loss: 0.32396 - val_acc: 0.8667 -- iter: 334/334
--
Training Step: 254  | total loss: [1m[32m0.25300[0m[0m | time: 1.401s
[2K
| Adam | epoch: 024 | loss: 0.25300 - acc: 0.8989 -- iter: 032/334
[A[ATraining Step: 255  | total loss: [1m[32m0.25105[0m[0m | time: 2.731s
[2K
| Adam | epoch: 024 | loss: 0.25105 - acc: 0.8966 -- iter: 064/334
[A[ATraining Step: 256  | total loss: [1m[32m0.24590[0m[0m | time: 3.953s
[2K
| Adam | epoch: 024 | loss: 0.24590 - acc: 0.9006 -- iter: 096/334
[A[ATraining Step: 257  | total loss: [1m[32m0.25128[0m[0m | time: 5.166s
[2K
| Adam | epoch: 024 | loss: 0.25128 - acc: 0.9012 -- iter: 128/334
[A[ATraining Step: 258  | total loss: [1m[32m0.24472[0m[0m | time: 6.568s
[2K
| Adam | epoch: 024 | loss: 0.24472 - acc: 0.9017 -- iter: 160/334
[A[ATraining Step: 259  | total loss: [1m[32m0.23236[0m[0m | time: 7.885s
[2K
| Adam | epoch: 024 | loss: 0.23236 - acc: 0.9084 -- iter: 192/334
[A[ATraining Step: 260  | total loss: [1m[32m0.21926[0m[0m | time: 9.034s
[2K
| Adam | epoch: 024 | loss: 0.21926 - acc: 0.9176 -- iter: 224/334
[A[ATraining Step: 261  | total loss: [1m[32m0.22014[0m[0m | time: 10.438s
[2K
| Adam | epoch: 024 | loss: 0.22014 - acc: 0.9133 -- iter: 256/334
[A[ATraining Step: 262  | total loss: [1m[32m0.22682[0m[0m | time: 11.842s
[2K
| Adam | epoch: 024 | loss: 0.22682 - acc: 0.9064 -- iter: 288/334
[A[ATraining Step: 263  | total loss: [1m[32m0.21152[0m[0m | time: 12.544s
[2K
| Adam | epoch: 024 | loss: 0.21152 - acc: 0.9126 -- iter: 320/334
[A[ATraining Step: 264  | total loss: [1m[32m0.20789[0m[0m | time: 14.259s
[2K
| Adam | epoch: 024 | loss: 0.20789 - acc: 0.9142 | val_loss: 0.68261 - val_acc: 0.7524 -- iter: 334/334
--
Training Step: 265  | total loss: [1m[32m0.19172[0m[0m | time: 1.319s
[2K
| Adam | epoch: 025 | loss: 0.19172 - acc: 0.9228 -- iter: 032/334
[A[ATraining Step: 266  | total loss: [1m[32m0.19498[0m[0m | time: 2.633s
[2K
| Adam | epoch: 025 | loss: 0.19498 - acc: 0.9180 -- iter: 064/334
[A[ATraining Step: 267  | total loss: [1m[32m0.22981[0m[0m | time: 3.581s
[2K
| Adam | epoch: 025 | loss: 0.22981 - acc: 0.8981 -- iter: 096/334
[A[ATraining Step: 268  | total loss: [1m[32m0.25147[0m[0m | time: 4.527s
[2K
| Adam | epoch: 025 | loss: 0.25147 - acc: 0.8958 -- iter: 128/334
[A[ATraining Step: 269  | total loss: [1m[32m0.24417[0m[0m | time: 5.615s
[2K
| Adam | epoch: 025 | loss: 0.24417 - acc: 0.8999 -- iter: 160/334
[A[ATraining Step: 270  | total loss: [1m[32m0.25763[0m[0m | time: 6.652s
[2K
| Adam | epoch: 025 | loss: 0.25763 - acc: 0.9006 -- iter: 192/334
[A[ATraining Step: 271  | total loss: [1m[32m0.30149[0m[0m | time: 7.601s
[2K
| Adam | epoch: 025 | loss: 0.30149 - acc: 0.8793 -- iter: 224/334
[A[ATraining Step: 272  | total loss: [1m[32m0.31486[0m[0m | time: 8.723s
[2K
| Adam | epoch: 025 | loss: 0.31486 - acc: 0.8695 -- iter: 256/334
[A[ATraining Step: 273  | total loss: [1m[32m0.31675[0m[0m | time: 9.796s
[2K
| Adam | epoch: 025 | loss: 0.31675 - acc: 0.8669 -- iter: 288/334
[A[ATraining Step: 274  | total loss: [1m[32m0.29525[0m[0m | time: 10.875s
[2K
| Adam | epoch: 025 | loss: 0.29525 - acc: 0.8802 -- iter: 320/334
[A[ATraining Step: 275  | total loss: [1m[32m0.28355[0m[0m | time: 12.529s
[2K
| Adam | epoch: 025 | loss: 0.28355 - acc: 0.8891 | val_loss: 0.44206 - val_acc: 0.8095 -- iter: 334/334
--
Training Step: 276  | total loss: [1m[32m0.27253[0m[0m | time: 0.502s
[2K
| Adam | epoch: 026 | loss: 0.27253 - acc: 0.8930 -- iter: 032/334
[A[ATraining Step: 277  | total loss: [1m[32m0.26133[0m[0m | time: 1.575s
[2K
| Adam | epoch: 026 | loss: 0.26133 - acc: 0.8966 -- iter: 064/334
[A[ATraining Step: 278  | total loss: [1m[32m0.24567[0m[0m | time: 2.517s
[2K
| Adam | epoch: 026 | loss: 0.24567 - acc: 0.9038 -- iter: 096/334
[A[ATraining Step: 279  | total loss: [1m[32m0.23410[0m[0m | time: 3.501s
[2K
| Adam | epoch: 026 | loss: 0.23410 - acc: 0.9103 -- iter: 128/334
[A[ATraining Step: 280  | total loss: [1m[32m0.37701[0m[0m | time: 4.608s
[2K
| Adam | epoch: 026 | loss: 0.37701 - acc: 0.8724 -- iter: 160/334
[A[ATraining Step: 281  | total loss: [1m[32m0.35800[0m[0m | time: 5.663s
[2K
| Adam | epoch: 026 | loss: 0.35800 - acc: 0.8789 -- iter: 192/334
[A[ATraining Step: 282  | total loss: [1m[32m0.33743[0m[0m | time: 6.582s
[2K
| Adam | epoch: 026 | loss: 0.33743 - acc: 0.8910 -- iter: 224/334
[A[ATraining Step: 283  | total loss: [1m[32m0.32060[0m[0m | time: 7.257s
[2K
| Adam | epoch: 026 | loss: 0.32060 - acc: 0.8988 -- iter: 256/334
[A[ATraining Step: 284  | total loss: [1m[32m0.30597[0m[0m | time: 7.925s
[2K
| Adam | epoch: 026 | loss: 0.30597 - acc: 0.9058 -- iter: 288/334
[A[ATraining Step: 285  | total loss: [1m[32m0.29592[0m[0m | time: 8.614s
[2K
| Adam | epoch: 026 | loss: 0.29592 - acc: 0.9089 -- iter: 320/334
[A[ATraining Step: 286  | total loss: [1m[32m0.28773[0m[0m | time: 10.332s
[2K
| Adam | epoch: 026 | loss: 0.28773 - acc: 0.9149 | val_loss: 0.33504 - val_acc: 0.8571 -- iter: 334/334
--
Training Step: 287  | total loss: [1m[32m0.28159[0m[0m | time: 0.309s
[2K
| Adam | epoch: 027 | loss: 0.28159 - acc: 0.9172 -- iter: 032/334
[A[ATraining Step: 288  | total loss: [1m[32m0.27996[0m[0m | time: 0.623s
[2K
| Adam | epoch: 027 | loss: 0.27996 - acc: 0.9112 -- iter: 064/334
[A[ATraining Step: 289  | total loss: [1m[32m0.27747[0m[0m | time: 1.621s
[2K
| Adam | epoch: 027 | loss: 0.27747 - acc: 0.9058 -- iter: 096/334
[A[ATraining Step: 290  | total loss: [1m[32m0.26590[0m[0m | time: 2.658s
[2K
| Adam | epoch: 027 | loss: 0.26590 - acc: 0.9121 -- iter: 128/334
[A[ATraining Step: 291  | total loss: [1m[32m0.25825[0m[0m | time: 3.550s
[2K
| Adam | epoch: 027 | loss: 0.25825 - acc: 0.9146 -- iter: 160/334
[A[ATraining Step: 292  | total loss: [1m[32m0.34533[0m[0m | time: 4.455s
[2K
| Adam | epoch: 027 | loss: 0.34533 - acc: 0.8982 -- iter: 192/334
[A[ATraining Step: 293  | total loss: [1m[32m0.32632[0m[0m | time: 5.459s
[2K
| Adam | epoch: 027 | loss: 0.32632 - acc: 0.8990 -- iter: 224/334
[A[ATraining Step: 294  | total loss: [1m[32m0.31340[0m[0m | time: 6.440s
[2K
| Adam | epoch: 027 | loss: 0.31340 - acc: 0.9059 -- iter: 256/334
[A[ATraining Step: 295  | total loss: [1m[32m0.29799[0m[0m | time: 7.666s
[2K
| Adam | epoch: 027 | loss: 0.29799 - acc: 0.9122 -- iter: 288/334
[A[ATraining Step: 296  | total loss: [1m[32m0.28518[0m[0m | time: 8.930s
[2K
| Adam | epoch: 027 | loss: 0.28518 - acc: 0.9179 -- iter: 320/334
[A[ATraining Step: 297  | total loss: [1m[32m0.27387[0m[0m | time: 11.067s
[2K
| Adam | epoch: 027 | loss: 0.27387 - acc: 0.9230 | val_loss: 0.30284 - val_acc: 0.8571 -- iter: 334/334
--
Training Step: 298  | total loss: [1m[32m0.25617[0m[0m | time: 1.061s
[2K
| Adam | epoch: 028 | loss: 0.25617 - acc: 0.9307 -- iter: 032/334
[A[ATraining Step: 299  | total loss: [1m[32m0.24028[0m[0m | time: 1.582s
[2K
| Adam | epoch: 028 | loss: 0.24028 - acc: 0.9376 -- iter: 064/334
[A[ATraining Step: 300  | total loss: [1m[32m0.23351[0m[0m | time: 2.067s
[2K
| Adam | epoch: 028 | loss: 0.23351 - acc: 0.9367 -- iter: 096/334
[A[ATraining Step: 301  | total loss: [1m[32m0.22650[0m[0m | time: 3.277s
[2K
| Adam | epoch: 028 | loss: 0.22650 - acc: 0.9359 -- iter: 128/334
[A[ATraining Step: 302  | total loss: [1m[32m0.21146[0m[0m | time: 4.807s
[2K
| Adam | epoch: 028 | loss: 0.21146 - acc: 0.9423 -- iter: 160/334
[A[ATraining Step: 303  | total loss: [1m[32m0.19796[0m[0m | time: 6.089s
[2K
| Adam | epoch: 028 | loss: 0.19796 - acc: 0.9481 -- iter: 192/334
[A[ATraining Step: 304  | total loss: [1m[32m0.24450[0m[0m | time: 7.630s
[2K
| Adam | epoch: 028 | loss: 0.24450 - acc: 0.9345 -- iter: 224/334
[A[ATraining Step: 305  | total loss: [1m[32m0.22440[0m[0m | time: 8.949s
[2K
| Adam | epoch: 028 | loss: 0.22440 - acc: 0.9411 -- iter: 256/334
[A[ATraining Step: 306  | total loss: [1m[32m0.21286[0m[0m | time: 10.307s
[2K
| Adam | epoch: 028 | loss: 0.21286 - acc: 0.9438 -- iter: 288/334
[A[ATraining Step: 307  | total loss: [1m[32m0.19680[0m[0m | time: 11.773s
[2K
| Adam | epoch: 028 | loss: 0.19680 - acc: 0.9494 -- iter: 320/334
[A[ATraining Step: 308  | total loss: [1m[32m0.18109[0m[0m | time: 14.087s
[2K
| Adam | epoch: 028 | loss: 0.18109 - acc: 0.9545 | val_loss: 0.30523 - val_acc: 0.8381 -- iter: 334/334
--
Training Step: 309  | total loss: [1m[32m0.17006[0m[0m | time: 1.510s
[2K
| Adam | epoch: 029 | loss: 0.17006 - acc: 0.9559 -- iter: 032/334
[A[ATraining Step: 310  | total loss: [1m[32m0.16137[0m[0m | time: 3.105s
[2K
| Adam | epoch: 029 | loss: 0.16137 - acc: 0.9603 -- iter: 064/334
[A[ATraining Step: 311  | total loss: [1m[32m0.15593[0m[0m | time: 3.763s
[2K
| Adam | epoch: 029 | loss: 0.15593 - acc: 0.9612 -- iter: 096/334
[A[ATraining Step: 312  | total loss: [1m[32m0.15291[0m[0m | time: 4.434s
[2K
| Adam | epoch: 029 | loss: 0.15291 - acc: 0.9579 -- iter: 128/334
[A[ATraining Step: 313  | total loss: [1m[32m0.14086[0m[0m | time: 5.739s
[2K
| Adam | epoch: 029 | loss: 0.14086 - acc: 0.9621 -- iter: 160/334
[A[ATraining Step: 314  | total loss: [1m[32m0.18005[0m[0m | time: 7.191s
[2K
| Adam | epoch: 029 | loss: 0.18005 - acc: 0.9440 -- iter: 192/334
[A[ATraining Step: 315  | total loss: [1m[32m0.18240[0m[0m | time: 8.813s
[2K
| Adam | epoch: 029 | loss: 0.18240 - acc: 0.9371 -- iter: 224/334
[A[ATraining Step: 316  | total loss: [1m[32m0.18685[0m[0m | time: 11.912s
[2K
| Adam | epoch: 029 | loss: 0.18685 - acc: 0.9372 -- iter: 256/334
[A[ATraining Step: 317  | total loss: [1m[32m0.17541[0m[0m | time: 18.128s
[2K
| Adam | epoch: 029 | loss: 0.17541 - acc: 0.9403 -- iter: 288/334
[A[ATraining Step: 318  | total loss: [1m[32m0.16933[0m[0m | time: 28.877s
[2K
| Adam | epoch: 029 | loss: 0.16933 - acc: 0.9432 -- iter: 320/334
[A[ATraining Step: 319  | total loss: [1m[32m0.15938[0m[0m | time: 52.584s
[2K
| Adam | epoch: 029 | loss: 0.15938 - acc: 0.9426 | val_loss: 0.41627 - val_acc: 0.8286 -- iter: 334/334
--
Training Step: 320  | total loss: [1m[32m0.15100[0m[0m | time: 1.241s
[2K
| Adam | epoch: 030 | loss: 0.15100 - acc: 0.9452 -- iter: 032/334
[A[ATraining Step: 321  | total loss: [1m[32m0.14850[0m[0m | time: 2.489s
[2K
| Adam | epoch: 030 | loss: 0.14850 - acc: 0.9444 -- iter: 064/334
[A[ATraining Step: 322  | total loss: [1m[32m0.15042[0m[0m | time: 3.789s
[2K
| Adam | epoch: 030 | loss: 0.15042 - acc: 0.9438 -- iter: 096/334
[A[ATraining Step: 323  | total loss: [1m[32m0.13814[0m[0m | time: 4.405s
[2K
| Adam | epoch: 030 | loss: 0.13814 - acc: 0.9494 -- iter: 128/334
[A[ATraining Step: 324  | total loss: [1m[32m0.14705[0m[0m | time: 5.098s
[2K
| Adam | epoch: 030 | loss: 0.14705 - acc: 0.9473 -- iter: 160/334
[A[ATraining Step: 325  | total loss: [1m[32m0.14465[0m[0m | time: 6.644s
[2K
| Adam | epoch: 030 | loss: 0.14465 - acc: 0.9526 -- iter: 192/334
[A[ATraining Step: 326  | total loss: [1m[32m0.13456[0m[0m | time: 7.961s
[2K
| Adam | epoch: 030 | loss: 0.13456 - acc: 0.9573 -- iter: 224/334
[A[ATraining Step: 327  | total loss: [1m[32m0.12704[0m[0m | time: 9.255s
[2K
| Adam | epoch: 030 | loss: 0.12704 - acc: 0.9616 -- iter: 256/334
[A[ATraining Step: 328  | total loss: [1m[32m0.16142[0m[0m | time: 10.677s
[2K
| Adam | epoch: 030 | loss: 0.16142 - acc: 0.9592 -- iter: 288/334
[A[ATraining Step: 329  | total loss: [1m[32m0.14684[0m[0m | time: 12.226s
[2K
| Adam | epoch: 030 | loss: 0.14684 - acc: 0.9633 -- iter: 320/334
[A[ATraining Step: 330  | total loss: [1m[32m0.13815[0m[0m | time: 17.127s
[2K
| Adam | epoch: 030 | loss: 0.13815 - acc: 0.9669 | val_loss: 0.46153 - val_acc: 0.8762 -- iter: 334/334
--
Validation AUC:0.9351311953352771
Validation AUPRC:0.952162608449202
Test AUC:0.9536527886881383
Test AUPRC:0.9760680275833231
BestTestF1Score	0.9	0.74	0.88	0.92	0.88	59	5	33	8	0.37
BestTestMCCScore	0.9	0.74	0.88	0.92	0.88	59	5	33	8	0.37
BestTestAccuracyScore	0.9	0.74	0.88	0.92	0.88	59	5	33	8	0.37
BestValidationF1Score	0.91	0.82	0.9	0.96	0.86	48	2	47	8	0.37
BestValidationMCC	0.91	0.82	0.9	0.96	0.86	48	2	47	8	0.37
BestValidationAccuracy	0.91	0.82	0.9	0.96	0.86	48	2	47	8	0.37
TestPredictions (Threshold:0.37)
CHEMBL3417409,TP,ACT,0.3799999952316284	CHEMBL2030860,TP,ACT,0.9800000190734863	CHEMBL374214,TP,ACT,1.0	CHEMBL469424,TN,INACT,0.0	CHEMBL2314377,TN,INACT,0.019999999552965164	CHEMBL3813743,TN,INACT,0.009999999776482582	CHEMBL135650,TN,INACT,0.0	CHEMBL2312473,TP,ACT,0.9399999976158142	CHEMBL1824831,TP,ACT,0.8899999856948853	CHEMBL2326041,TP,ACT,0.9900000095367432	CHEMBL3703619,TP,ACT,1.0	CHEMBL2159743,TP,ACT,1.0	CHEMBL426535,TP,ACT,1.0	CHEMBL370836,TP,ACT,0.9900000095367432	CHEMBL504810,TP,ACT,0.9900000095367432	CHEMBL1288375,TP,ACT,1.0	CHEMBL2063880,FP,INACT,0.6200000047683716	CHEMBL2326037,TP,ACT,0.9900000095367432	CHEMBL3703602,TP,ACT,1.0	CHEMBL2314369,TN,INACT,0.009999999776482582	CHEMBL1456767,TN,INACT,0.0	CHEMBL387141,FN,ACT,0.25	CHEMBL242339,TN,INACT,0.0	CHEMBL3699071,TP,ACT,0.9700000286102295	CHEMBL443599,FP,INACT,0.6000000238418579	CHEMBL2374449,TN,INACT,0.07999999821186066	CHEMBL3401808,FN,ACT,0.0	CHEMBL1543965,TN,INACT,0.0	CHEMBL1824807,FP,INACT,0.9200000166893005	CHEMBL3699079,TP,ACT,0.9700000286102295	CHEMBL382648,TP,ACT,0.9900000095367432	CHEMBL2325760,TP,ACT,1.0	CHEMBL3401796,FN,ACT,0.14000000059604645	CHEMBL216089,TN,INACT,0.3499999940395355	CHEMBL3265304,TN,INACT,0.009999999776482582	CHEMBL502211,TP,ACT,0.9700000286102295	CHEMBL1465739,TN,INACT,0.0	CHEMBL2398250,FN,ACT,0.10999999940395355	CHEMBL2325767,TP,ACT,0.9900000095367432	CHEMBL2314510,TN,INACT,0.0	CHEMBL1270819,TN,INACT,0.0	CHEMBL3780331,TN,INACT,0.0	CHEMBL2031002,TP,ACT,1.0	CHEMBL1271936,TN,INACT,0.0	CHEMBL3287282,TP,ACT,0.8999999761581421	CHEMBL1288358,TP,ACT,1.0	CHEMBL2030852,TP,ACT,1.0	CHEMBL503642,TP,ACT,0.9800000190734863	CHEMBL2398251,FN,ACT,0.029999999329447746	CHEMBL453437,TN,INACT,0.05000000074505806	CHEMBL2322020,TP,ACT,0.9900000095367432	CHEMBL3311492,TP,ACT,0.9900000095367432	CHEMBL3401817,FN,ACT,0.019999999552965164	CHEMBL3814082,TN,INACT,0.0	CHEMBL3704830,TP,ACT,0.9300000071525574	CHEMBL1824822,FP,INACT,0.7799999713897705	CHEMBL243203,TN,INACT,0.0	CHEMBL1940679,TP,ACT,1.0	CHEMBL2159740,TP,ACT,0.9900000095367432	CHEMBL2398261,TP,ACT,0.6100000143051147	CHEMBL3401799,TP,ACT,0.44999998807907104	CHEMBL1200938,FP,INACT,0.46000000834465027	CHEMBL3265306,TN,INACT,0.009999999776482582	CHEMBL220055,TN,INACT,0.009999999776482582	CHEMBL2325762,TP,ACT,0.9800000190734863	CHEMBL1824815,TP,ACT,0.8999999761581421	CHEMBL2314523,TN,INACT,0.0	CHEMBL3779915,TN,INACT,0.0	CHEMBL2031025,TP,ACT,1.0	CHEMBL395653,TN,INACT,0.019999999552965164	CHEMBL1689140,TP,ACT,1.0	CHEMBL552287,TP,ACT,0.9900000095367432	CHEMBL221856,TP,ACT,1.0	CHEMBL3703623,TP,ACT,1.0	CHEMBL243190,TN,INACT,0.11999999731779099	CHEMBL506024,TP,ACT,1.0	CHEMBL3699070,TP,ACT,0.9800000190734863	CHEMBL201947,TP,ACT,0.9800000190734863	CHEMBL3125476,TP,ACT,0.9599999785423279	CHEMBL2063886,TP,ACT,0.9900000095367432	CHEMBL3309312,TP,ACT,0.9800000190734863	CHEMBL3309310,TP,ACT,1.0	CHEMBL383229,TP,ACT,0.9900000095367432	CHEMBL242969,TN,INACT,0.0	CHEMBL269836,TN,INACT,0.0	CHEMBL1269072,TP,ACT,0.3700000047683716	CHEMBL28478,TP,ACT,0.699999988079071	CHEMBL397906,TN,INACT,0.0	CHEMBL1288347,TP,ACT,0.9900000095367432	CHEMBL2030863,TP,ACT,0.9900000095367432	CHEMBL3704827,TP,ACT,0.9599999785423279	CHEMBL2398172,TP,ACT,0.7900000214576721	CHEMBL51483,FN,ACT,0.0	CHEMBL2314176,FN,ACT,0.019999999552965164	CHEMBL3780355,TN,INACT,0.0	CHEMBL36834,TN,INACT,0.0	CHEMBL3704826,TP,ACT,0.9599999785423279	CHEMBL1269073,TP,ACT,0.6800000071525574	CHEMBL2030270,TN,INACT,0.0	CHEMBL2159738,TP,ACT,0.9900000095367432	CHEMBL2314508,TN,INACT,0.0	CHEMBL2325757,TP,ACT,0.9900000095367432	CHEMBL2326746,TP,ACT,0.9800000190734863	CHEMBL3311487,TP,ACT,1.0	CHEMBL3780614,TN,INACT,0.0	

