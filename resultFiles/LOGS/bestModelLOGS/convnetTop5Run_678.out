CNNModel CHEMBL4224 adam 0.0005 30 32 0 0.8 False True
Number of active compounds :	307
Number of inactive compounds :	307
---------------------------------
Run id: CNNModel_CHEMBL4224_adam_0.0005_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4224_adam_0.0005_30_32_0.8_True/
---------------------------------
Training samples: 365
Validation samples: 115
--
Training Step: 1  | time: 0.823s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/365
[A[ATraining Step: 2  | total loss: [1m[32m0.62380[0m[0m | time: 1.617s
[2K
| Adam | epoch: 001 | loss: 0.62380 - acc: 0.4219 -- iter: 064/365
[A[ATraining Step: 3  | total loss: [1m[32m0.68044[0m[0m | time: 2.426s
[2K
| Adam | epoch: 001 | loss: 0.68044 - acc: 0.4858 -- iter: 096/365
[A[ATraining Step: 4  | total loss: [1m[32m0.69024[0m[0m | time: 3.301s
[2K
| Adam | epoch: 001 | loss: 0.69024 - acc: 0.4730 -- iter: 128/365
[A[ATraining Step: 5  | total loss: [1m[32m0.69225[0m[0m | time: 4.259s
[2K
| Adam | epoch: 001 | loss: 0.69225 - acc: 0.4484 -- iter: 160/365
[A[ATraining Step: 6  | total loss: [1m[32m0.69301[0m[0m | time: 5.136s
[2K
| Adam | epoch: 001 | loss: 0.69301 - acc: 0.4615 -- iter: 192/365
[A[ATraining Step: 7  | total loss: [1m[32m0.69307[0m[0m | time: 6.053s
[2K
| Adam | epoch: 001 | loss: 0.69307 - acc: 0.5033 -- iter: 224/365
[A[ATraining Step: 8  | total loss: [1m[32m0.69320[0m[0m | time: 6.937s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5015 -- iter: 256/365
[A[ATraining Step: 9  | total loss: [1m[32m0.69512[0m[0m | time: 7.619s
[2K
| Adam | epoch: 001 | loss: 0.69512 - acc: 0.4345 -- iter: 288/365
[A[ATraining Step: 10  | total loss: [1m[32m0.69306[0m[0m | time: 8.309s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.5298 -- iter: 320/365
[A[ATraining Step: 11  | total loss: [1m[32m0.69279[0m[0m | time: 8.984s
[2K
| Adam | epoch: 001 | loss: 0.69279 - acc: 0.5305 -- iter: 352/365
[A[ATraining Step: 12  | total loss: [1m[32m0.69229[0m[0m | time: 10.315s
[2K
| Adam | epoch: 001 | loss: 0.69229 - acc: 0.5308 | val_loss: 0.69177 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 13  | total loss: [1m[32m0.69529[0m[0m | time: 0.298s
[2K
| Adam | epoch: 002 | loss: 0.69529 - acc: 0.4682 -- iter: 032/365
[A[ATraining Step: 14  | total loss: [1m[32m0.69589[0m[0m | time: 0.931s
[2K
| Adam | epoch: 002 | loss: 0.69589 - acc: 0.4340 -- iter: 064/365
[A[ATraining Step: 15  | total loss: [1m[32m0.69499[0m[0m | time: 1.589s
[2K
| Adam | epoch: 002 | loss: 0.69499 - acc: 0.4476 -- iter: 096/365
[A[ATraining Step: 16  | total loss: [1m[32m0.69431[0m[0m | time: 2.251s
[2K
| Adam | epoch: 002 | loss: 0.69431 - acc: 0.4555 -- iter: 128/365
[A[ATraining Step: 17  | total loss: [1m[32m0.69377[0m[0m | time: 2.912s
[2K
| Adam | epoch: 002 | loss: 0.69377 - acc: 0.4940 -- iter: 160/365
[A[ATraining Step: 18  | total loss: [1m[32m0.69358[0m[0m | time: 3.575s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.4961 -- iter: 192/365
[A[ATraining Step: 19  | total loss: [1m[32m0.69338[0m[0m | time: 4.217s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.5078 -- iter: 224/365
[A[ATraining Step: 20  | total loss: [1m[32m0.69370[0m[0m | time: 4.879s
[2K
| Adam | epoch: 002 | loss: 0.69370 - acc: 0.4651 -- iter: 256/365
[A[ATraining Step: 21  | total loss: [1m[32m0.69346[0m[0m | time: 5.567s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.4856 -- iter: 288/365
[A[ATraining Step: 22  | total loss: [1m[32m0.69315[0m[0m | time: 6.217s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5181 -- iter: 320/365
[A[ATraining Step: 23  | total loss: [1m[32m0.69318[0m[0m | time: 6.879s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5128 -- iter: 352/365
[A[ATraining Step: 24  | total loss: [1m[32m0.69283[0m[0m | time: 8.536s
[2K
| Adam | epoch: 002 | loss: 0.69283 - acc: 0.5444 | val_loss: 0.69385 - val_acc: 0.4435 -- iter: 365/365
--
Training Step: 25  | total loss: [1m[32m0.69312[0m[0m | time: 0.299s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.5152 -- iter: 032/365
[A[ATraining Step: 26  | total loss: [1m[32m0.69298[0m[0m | time: 0.618s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5214 -- iter: 064/365
[A[ATraining Step: 27  | total loss: [1m[32m0.69291[0m[0m | time: 1.271s
[2K
| Adam | epoch: 003 | loss: 0.69291 - acc: 0.5258 -- iter: 096/365
[A[ATraining Step: 28  | total loss: [1m[32m0.69300[0m[0m | time: 1.934s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5193 -- iter: 128/365
[A[ATraining Step: 29  | total loss: [1m[32m0.69330[0m[0m | time: 2.628s
[2K
| Adam | epoch: 003 | loss: 0.69330 - acc: 0.4994 -- iter: 160/365
[A[ATraining Step: 30  | total loss: [1m[32m0.69337[0m[0m | time: 3.318s
[2K
| Adam | epoch: 003 | loss: 0.69337 - acc: 0.4922 -- iter: 192/365
[A[ATraining Step: 31  | total loss: [1m[32m0.69318[0m[0m | time: 3.987s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.5012 -- iter: 224/365
[A[ATraining Step: 32  | total loss: [1m[32m0.69364[0m[0m | time: 4.647s
[2K
| Adam | epoch: 003 | loss: 0.69364 - acc: 0.4728 -- iter: 256/365
[A[ATraining Step: 33  | total loss: [1m[32m0.69384[0m[0m | time: 5.326s
[2K
| Adam | epoch: 003 | loss: 0.69384 - acc: 0.4582 -- iter: 288/365
[A[ATraining Step: 34  | total loss: [1m[32m0.69378[0m[0m | time: 5.988s
[2K
| Adam | epoch: 003 | loss: 0.69378 - acc: 0.4604 -- iter: 320/365
[A[ATraining Step: 35  | total loss: [1m[32m0.69350[0m[0m | time: 6.670s
[2K
| Adam | epoch: 003 | loss: 0.69350 - acc: 0.4818 -- iter: 352/365
[A[ATraining Step: 36  | total loss: [1m[32m0.69350[0m[0m | time: 8.354s
[2K
| Adam | epoch: 003 | loss: 0.69350 - acc: 0.4791 | val_loss: 0.69360 - val_acc: 0.4435 -- iter: 365/365
--
Training Step: 37  | total loss: [1m[32m0.69343[0m[0m | time: 0.705s
[2K
| Adam | epoch: 004 | loss: 0.69343 - acc: 0.4833 -- iter: 032/365
[A[ATraining Step: 38  | total loss: [1m[32m0.69346[0m[0m | time: 1.014s
[2K
| Adam | epoch: 004 | loss: 0.69346 - acc: 0.4743 -- iter: 064/365
[A[ATraining Step: 39  | total loss: [1m[32m0.69357[0m[0m | time: 1.315s
[2K
| Adam | epoch: 004 | loss: 0.69357 - acc: 0.4572 -- iter: 096/365
[A[ATraining Step: 40  | total loss: [1m[32m0.69361[0m[0m | time: 1.982s
[2K
| Adam | epoch: 004 | loss: 0.69361 - acc: 0.4436 -- iter: 128/365
[A[ATraining Step: 41  | total loss: [1m[32m0.69352[0m[0m | time: 2.639s
[2K
| Adam | epoch: 004 | loss: 0.69352 - acc: 0.4424 -- iter: 160/365
[A[ATraining Step: 42  | total loss: [1m[32m0.69346[0m[0m | time: 3.305s
[2K
| Adam | epoch: 004 | loss: 0.69346 - acc: 0.4584 -- iter: 192/365
[A[ATraining Step: 43  | total loss: [1m[32m0.69343[0m[0m | time: 3.973s
[2K
| Adam | epoch: 004 | loss: 0.69343 - acc: 0.4603 -- iter: 224/365
[A[ATraining Step: 44  | total loss: [1m[32m0.69343[0m[0m | time: 4.624s
[2K
| Adam | epoch: 004 | loss: 0.69343 - acc: 0.4563 -- iter: 256/365
[A[ATraining Step: 45  | total loss: [1m[32m0.69343[0m[0m | time: 5.284s
[2K
| Adam | epoch: 004 | loss: 0.69343 - acc: 0.4584 -- iter: 288/365
[A[ATraining Step: 46  | total loss: [1m[32m0.69343[0m[0m | time: 5.952s
[2K
| Adam | epoch: 004 | loss: 0.69343 - acc: 0.4601 -- iter: 320/365
[A[ATraining Step: 47  | total loss: [1m[32m0.69347[0m[0m | time: 6.665s
[2K
| Adam | epoch: 004 | loss: 0.69347 - acc: 0.4513 -- iter: 352/365
[A[ATraining Step: 48  | total loss: [1m[32m0.69353[0m[0m | time: 8.337s
[2K
| Adam | epoch: 004 | loss: 0.69353 - acc: 0.4391 | val_loss: 0.69307 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 49  | total loss: [1m[32m0.69349[0m[0m | time: 0.685s
[2K
| Adam | epoch: 005 | loss: 0.69349 - acc: 0.4437 -- iter: 032/365
[A[ATraining Step: 50  | total loss: [1m[32m0.69339[0m[0m | time: 1.350s
[2K
| Adam | epoch: 005 | loss: 0.69339 - acc: 0.4767 -- iter: 064/365
[A[ATraining Step: 51  | total loss: [1m[32m0.69330[0m[0m | time: 1.648s
[2K
| Adam | epoch: 005 | loss: 0.69330 - acc: 0.5089 -- iter: 096/365
[A[ATraining Step: 52  | total loss: [1m[32m0.69312[0m[0m | time: 1.944s
[2K
| Adam | epoch: 005 | loss: 0.69312 - acc: 0.5595 -- iter: 128/365
[A[ATraining Step: 53  | total loss: [1m[32m0.69283[0m[0m | time: 2.593s
[2K
| Adam | epoch: 005 | loss: 0.69283 - acc: 0.6018 -- iter: 160/365
[A[ATraining Step: 54  | total loss: [1m[32m0.69279[0m[0m | time: 3.272s
[2K
| Adam | epoch: 005 | loss: 0.69279 - acc: 0.5961 -- iter: 192/365
[A[ATraining Step: 55  | total loss: [1m[32m0.69290[0m[0m | time: 3.953s
[2K
| Adam | epoch: 005 | loss: 0.69290 - acc: 0.5779 -- iter: 224/365
[A[ATraining Step: 56  | total loss: [1m[32m0.69299[0m[0m | time: 4.639s
[2K
| Adam | epoch: 005 | loss: 0.69299 - acc: 0.5625 -- iter: 256/365
[A[ATraining Step: 57  | total loss: [1m[32m0.69301[0m[0m | time: 5.297s
[2K
| Adam | epoch: 005 | loss: 0.69301 - acc: 0.5539 -- iter: 288/365
[A[ATraining Step: 58  | total loss: [1m[32m0.69332[0m[0m | time: 5.949s
[2K
| Adam | epoch: 005 | loss: 0.69332 - acc: 0.5337 -- iter: 320/365
[A[ATraining Step: 59  | total loss: [1m[32m0.69314[0m[0m | time: 6.600s
[2K
| Adam | epoch: 005 | loss: 0.69314 - acc: 0.5376 -- iter: 352/365
[A[ATraining Step: 60  | total loss: [1m[32m0.69267[0m[0m | time: 8.272s
[2K
| Adam | epoch: 005 | loss: 0.69267 - acc: 0.5533 | val_loss: 0.69176 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 61  | total loss: [1m[32m0.69303[0m[0m | time: 0.655s
[2K
| Adam | epoch: 006 | loss: 0.69303 - acc: 0.5341 -- iter: 032/365
[A[ATraining Step: 62  | total loss: [1m[32m0.69253[0m[0m | time: 1.325s
[2K
| Adam | epoch: 006 | loss: 0.69253 - acc: 0.5498 -- iter: 064/365
[A[ATraining Step: 63  | total loss: [1m[32m0.69263[0m[0m | time: 1.989s
[2K
| Adam | epoch: 006 | loss: 0.69263 - acc: 0.5435 -- iter: 096/365
[A[ATraining Step: 64  | total loss: [1m[32m0.69329[0m[0m | time: 2.284s
[2K
| Adam | epoch: 006 | loss: 0.69329 - acc: 0.5185 -- iter: 128/365
[A[ATraining Step: 65  | total loss: [1m[32m0.69313[0m[0m | time: 2.572s
[2K
| Adam | epoch: 006 | loss: 0.69313 - acc: 0.5210 -- iter: 160/365
[A[ATraining Step: 66  | total loss: [1m[32m0.69302[0m[0m | time: 3.225s
[2K
| Adam | epoch: 006 | loss: 0.69302 - acc: 0.5231 -- iter: 192/365
[A[ATraining Step: 67  | total loss: [1m[32m0.69305[0m[0m | time: 3.869s
[2K
| Adam | epoch: 006 | loss: 0.69305 - acc: 0.5203 -- iter: 224/365
[A[ATraining Step: 68  | total loss: [1m[32m0.69318[0m[0m | time: 4.525s
[2K
| Adam | epoch: 006 | loss: 0.69318 - acc: 0.5142 -- iter: 256/365
[A[ATraining Step: 69  | total loss: [1m[32m0.69310[0m[0m | time: 5.170s
[2K
| Adam | epoch: 006 | loss: 0.69310 - acc: 0.5162 -- iter: 288/365
[A[ATraining Step: 70  | total loss: [1m[32m0.69348[0m[0m | time: 5.846s
[2K
| Adam | epoch: 006 | loss: 0.69348 - acc: 0.5035 -- iter: 320/365
[A[ATraining Step: 71  | total loss: [1m[32m0.69321[0m[0m | time: 6.508s
[2K
| Adam | epoch: 006 | loss: 0.69321 - acc: 0.5103 -- iter: 352/365
[A[ATraining Step: 72  | total loss: [1m[32m0.69322[0m[0m | time: 8.173s
[2K
| Adam | epoch: 006 | loss: 0.69322 - acc: 0.5091 | val_loss: 0.69134 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 73  | total loss: [1m[32m0.69265[0m[0m | time: 0.674s
[2K
| Adam | epoch: 007 | loss: 0.69265 - acc: 0.5254 -- iter: 032/365
[A[ATraining Step: 74  | total loss: [1m[32m0.69295[0m[0m | time: 1.338s
[2K
| Adam | epoch: 007 | loss: 0.69295 - acc: 0.5158 -- iter: 064/365
[A[ATraining Step: 75  | total loss: [1m[32m0.69298[0m[0m | time: 2.004s
[2K
| Adam | epoch: 007 | loss: 0.69298 - acc: 0.5141 -- iter: 096/365
[A[ATraining Step: 76  | total loss: [1m[32m0.69281[0m[0m | time: 2.661s
[2K
| Adam | epoch: 007 | loss: 0.69281 - acc: 0.5193 -- iter: 128/365
[A[ATraining Step: 77  | total loss: [1m[32m0.69260[0m[0m | time: 2.958s
[2K
| Adam | epoch: 007 | loss: 0.69260 - acc: 0.5238 -- iter: 160/365
[A[ATraining Step: 78  | total loss: [1m[32m0.69218[0m[0m | time: 3.273s
[2K
| Adam | epoch: 007 | loss: 0.69218 - acc: 0.5334 -- iter: 192/365
[A[ATraining Step: 79  | total loss: [1m[32m0.69183[0m[0m | time: 3.945s
[2K
| Adam | epoch: 007 | loss: 0.69183 - acc: 0.5419 -- iter: 224/365
[A[ATraining Step: 80  | total loss: [1m[32m0.69249[0m[0m | time: 4.627s
[2K
| Adam | epoch: 007 | loss: 0.69249 - acc: 0.5248 -- iter: 256/365
[A[ATraining Step: 81  | total loss: [1m[32m0.69310[0m[0m | time: 5.278s
[2K
| Adam | epoch: 007 | loss: 0.69310 - acc: 0.5097 -- iter: 288/365
[A[ATraining Step: 82  | total loss: [1m[32m0.69312[0m[0m | time: 5.958s
[2K
| Adam | epoch: 007 | loss: 0.69312 - acc: 0.5087 -- iter: 320/365
[A[ATraining Step: 83  | total loss: [1m[32m0.69273[0m[0m | time: 6.632s
[2K
| Adam | epoch: 007 | loss: 0.69273 - acc: 0.5172 -- iter: 352/365
[A[ATraining Step: 84  | total loss: [1m[32m0.69278[0m[0m | time: 8.280s
[2K
| Adam | epoch: 007 | loss: 0.69278 - acc: 0.5155 | val_loss: 0.69086 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 85  | total loss: [1m[32m0.69241[0m[0m | time: 0.646s
[2K
| Adam | epoch: 008 | loss: 0.69241 - acc: 0.5233 -- iter: 032/365
[A[ATraining Step: 86  | total loss: [1m[32m0.69280[0m[0m | time: 1.297s
[2K
| Adam | epoch: 008 | loss: 0.69280 - acc: 0.5147 -- iter: 064/365
[A[ATraining Step: 87  | total loss: [1m[32m0.69299[0m[0m | time: 1.935s
[2K
| Adam | epoch: 008 | loss: 0.69299 - acc: 0.5101 -- iter: 096/365
[A[ATraining Step: 88  | total loss: [1m[32m0.69301[0m[0m | time: 2.572s
[2K
| Adam | epoch: 008 | loss: 0.69301 - acc: 0.5091 -- iter: 128/365
[A[ATraining Step: 89  | total loss: [1m[32m0.69330[0m[0m | time: 3.220s
[2K
| Adam | epoch: 008 | loss: 0.69330 - acc: 0.5020 -- iter: 160/365
[A[ATraining Step: 90  | total loss: [1m[32m0.69385[0m[0m | time: 3.540s
[2K
| Adam | epoch: 008 | loss: 0.69385 - acc: 0.4893 -- iter: 192/365
[A[ATraining Step: 91  | total loss: [1m[32m0.69430[0m[0m | time: 3.834s
[2K
| Adam | epoch: 008 | loss: 0.69430 - acc: 0.4788 -- iter: 224/365
[A[ATraining Step: 92  | total loss: [1m[32m0.69468[0m[0m | time: 4.482s
[2K
| Adam | epoch: 008 | loss: 0.69468 - acc: 0.4694 -- iter: 256/365
[A[ATraining Step: 93  | total loss: [1m[32m0.69431[0m[0m | time: 5.133s
[2K
| Adam | epoch: 008 | loss: 0.69431 - acc: 0.4787 -- iter: 288/365
[A[ATraining Step: 94  | total loss: [1m[32m0.69444[0m[0m | time: 5.787s
[2K
| Adam | epoch: 008 | loss: 0.69444 - acc: 0.4746 -- iter: 320/365
[A[ATraining Step: 95  | total loss: [1m[32m0.69402[0m[0m | time: 6.440s
[2K
| Adam | epoch: 008 | loss: 0.69402 - acc: 0.4865 -- iter: 352/365
[A[ATraining Step: 96  | total loss: [1m[32m0.69354[0m[0m | time: 8.082s
[2K
| Adam | epoch: 008 | loss: 0.69354 - acc: 0.5003 | val_loss: 0.69146 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 97  | total loss: [1m[32m0.69310[0m[0m | time: 0.670s
[2K
| Adam | epoch: 009 | loss: 0.69310 - acc: 0.5128 -- iter: 032/365
[A[ATraining Step: 98  | total loss: [1m[32m0.69343[0m[0m | time: 1.326s
[2K
| Adam | epoch: 009 | loss: 0.69343 - acc: 0.5022 -- iter: 064/365
[A[ATraining Step: 99  | total loss: [1m[32m0.69300[0m[0m | time: 1.979s
[2K
| Adam | epoch: 009 | loss: 0.69300 - acc: 0.5144 -- iter: 096/365
[A[ATraining Step: 100  | total loss: [1m[32m0.69313[0m[0m | time: 2.633s
[2K
| Adam | epoch: 009 | loss: 0.69313 - acc: 0.5099 -- iter: 128/365
[A[ATraining Step: 101  | total loss: [1m[32m0.69265[0m[0m | time: 3.290s
[2K
| Adam | epoch: 009 | loss: 0.69265 - acc: 0.5245 -- iter: 160/365
[A[ATraining Step: 102  | total loss: [1m[32m0.69263[0m[0m | time: 3.945s
[2K
| Adam | epoch: 009 | loss: 0.69263 - acc: 0.5252 -- iter: 192/365
[A[ATraining Step: 103  | total loss: [1m[32m0.69247[0m[0m | time: 4.240s
[2K
| Adam | epoch: 009 | loss: 0.69247 - acc: 0.5289 -- iter: 224/365
[A[ATraining Step: 104  | total loss: [1m[32m0.69268[0m[0m | time: 4.537s
[2K
| Adam | epoch: 009 | loss: 0.69268 - acc: 0.5222 -- iter: 256/365
[A[ATraining Step: 105  | total loss: [1m[32m0.69286[0m[0m | time: 5.185s
[2K
| Adam | epoch: 009 | loss: 0.69286 - acc: 0.5161 -- iter: 288/365
[A[ATraining Step: 106  | total loss: [1m[32m0.69312[0m[0m | time: 5.822s
[2K
| Adam | epoch: 009 | loss: 0.69312 - acc: 0.5083 -- iter: 320/365
[A[ATraining Step: 107  | total loss: [1m[32m0.69312[0m[0m | time: 6.489s
[2K
| Adam | epoch: 009 | loss: 0.69312 - acc: 0.5074 -- iter: 352/365
[A[ATraining Step: 108  | total loss: [1m[32m0.69315[0m[0m | time: 8.175s
[2K
| Adam | epoch: 009 | loss: 0.69315 - acc: 0.5067 | val_loss: 0.69131 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 109  | total loss: [1m[32m0.69328[0m[0m | time: 0.669s
[2K
| Adam | epoch: 010 | loss: 0.69328 - acc: 0.5029 -- iter: 032/365
[A[ATraining Step: 110  | total loss: [1m[32m0.69340[0m[0m | time: 1.336s
[2K
| Adam | epoch: 010 | loss: 0.69340 - acc: 0.4995 -- iter: 064/365
[A[ATraining Step: 111  | total loss: [1m[32m0.69382[0m[0m | time: 1.984s
[2K
| Adam | epoch: 010 | loss: 0.69382 - acc: 0.4870 -- iter: 096/365
[A[ATraining Step: 112  | total loss: [1m[32m0.69376[0m[0m | time: 2.675s
[2K
| Adam | epoch: 010 | loss: 0.69376 - acc: 0.4883 -- iter: 128/365
[A[ATraining Step: 113  | total loss: [1m[32m0.69349[0m[0m | time: 3.341s
[2K
| Adam | epoch: 010 | loss: 0.69349 - acc: 0.4957 -- iter: 160/365
[A[ATraining Step: 114  | total loss: [1m[32m0.69315[0m[0m | time: 4.008s
[2K
| Adam | epoch: 010 | loss: 0.69315 - acc: 0.5055 -- iter: 192/365
[A[ATraining Step: 115  | total loss: [1m[32m0.69345[0m[0m | time: 4.703s
[2K
| Adam | epoch: 010 | loss: 0.69345 - acc: 0.4956 -- iter: 224/365
[A[ATraining Step: 116  | total loss: [1m[32m0.69371[0m[0m | time: 5.005s
[2K
| Adam | epoch: 010 | loss: 0.69371 - acc: 0.4867 -- iter: 256/365
[A[ATraining Step: 117  | total loss: [1m[32m0.69332[0m[0m | time: 5.302s
[2K
| Adam | epoch: 010 | loss: 0.69332 - acc: 0.4995 -- iter: 288/365
[A[ATraining Step: 118  | total loss: [1m[32m0.69300[0m[0m | time: 5.997s
[2K
| Adam | epoch: 010 | loss: 0.69300 - acc: 0.5111 -- iter: 320/365
[A[ATraining Step: 119  | total loss: [1m[32m0.69312[0m[0m | time: 6.683s
[2K
| Adam | epoch: 010 | loss: 0.69312 - acc: 0.5069 -- iter: 352/365
[A[ATraining Step: 120  | total loss: [1m[32m0.69285[0m[0m | time: 8.346s
[2K
| Adam | epoch: 010 | loss: 0.69285 - acc: 0.5156 | val_loss: 0.69151 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 121  | total loss: [1m[32m0.69298[0m[0m | time: 0.695s
[2K
| Adam | epoch: 011 | loss: 0.69298 - acc: 0.5109 -- iter: 032/365
[A[ATraining Step: 122  | total loss: [1m[32m0.69313[0m[0m | time: 1.362s
[2K
| Adam | epoch: 011 | loss: 0.69313 - acc: 0.5067 -- iter: 064/365
[A[ATraining Step: 123  | total loss: [1m[32m0.69246[0m[0m | time: 2.039s
[2K
| Adam | epoch: 011 | loss: 0.69246 - acc: 0.5279 -- iter: 096/365
[A[ATraining Step: 124  | total loss: [1m[32m0.69301[0m[0m | time: 2.712s
[2K
| Adam | epoch: 011 | loss: 0.69301 - acc: 0.5095 -- iter: 128/365
[A[ATraining Step: 125  | total loss: [1m[32m0.69271[0m[0m | time: 3.375s
[2K
| Adam | epoch: 011 | loss: 0.69271 - acc: 0.5179 -- iter: 160/365
[A[ATraining Step: 126  | total loss: [1m[32m0.69267[0m[0m | time: 4.035s
[2K
| Adam | epoch: 011 | loss: 0.69267 - acc: 0.5192 -- iter: 192/365
[A[ATraining Step: 127  | total loss: [1m[32m0.69273[0m[0m | time: 4.691s
[2K
| Adam | epoch: 011 | loss: 0.69273 - acc: 0.5173 -- iter: 224/365
[A[ATraining Step: 128  | total loss: [1m[32m0.69238[0m[0m | time: 5.349s
[2K
| Adam | epoch: 011 | loss: 0.69238 - acc: 0.5281 -- iter: 256/365
[A[ATraining Step: 129  | total loss: [1m[32m0.69257[0m[0m | time: 5.647s
[2K
| Adam | epoch: 011 | loss: 0.69257 - acc: 0.5221 -- iter: 288/365
[A[ATraining Step: 130  | total loss: [1m[32m0.69172[0m[0m | time: 5.947s
[2K
| Adam | epoch: 011 | loss: 0.69172 - acc: 0.5469 -- iter: 320/365
[A[ATraining Step: 131  | total loss: [1m[32m0.69086[0m[0m | time: 6.612s
[2K
| Adam | epoch: 011 | loss: 0.69086 - acc: 0.5691 -- iter: 352/365
[A[ATraining Step: 132  | total loss: [1m[32m0.69022[0m[0m | time: 8.277s
[2K
| Adam | epoch: 011 | loss: 0.69022 - acc: 0.5841 | val_loss: 0.69067 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 133  | total loss: [1m[32m0.69067[0m[0m | time: 1.155s
[2K
| Adam | epoch: 012 | loss: 0.69067 - acc: 0.5725 -- iter: 032/365
[A[ATraining Step: 134  | total loss: [1m[32m0.69140[0m[0m | time: 1.858s
[2K
| Adam | epoch: 012 | loss: 0.69140 - acc: 0.5559 -- iter: 064/365
[A[ATraining Step: 135  | total loss: [1m[32m0.69210[0m[0m | time: 2.541s
[2K
| Adam | epoch: 012 | loss: 0.69210 - acc: 0.5409 -- iter: 096/365
[A[ATraining Step: 136  | total loss: [1m[32m0.69258[0m[0m | time: 3.210s
[2K
| Adam | epoch: 012 | loss: 0.69258 - acc: 0.5306 -- iter: 128/365
[A[ATraining Step: 137  | total loss: [1m[32m0.69229[0m[0m | time: 3.874s
[2K
| Adam | epoch: 012 | loss: 0.69229 - acc: 0.5338 -- iter: 160/365
[A[ATraining Step: 138  | total loss: [1m[32m0.69245[0m[0m | time: 4.537s
[2K
| Adam | epoch: 012 | loss: 0.69245 - acc: 0.5304 -- iter: 192/365
[A[ATraining Step: 139  | total loss: [1m[32m0.69186[0m[0m | time: 5.193s
[2K
| Adam | epoch: 012 | loss: 0.69186 - acc: 0.5399 -- iter: 224/365
[A[ATraining Step: 140  | total loss: [1m[32m0.69185[0m[0m | time: 5.888s
[2K
| Adam | epoch: 012 | loss: 0.69185 - acc: 0.5390 -- iter: 256/365
[A[ATraining Step: 141  | total loss: [1m[32m0.69128[0m[0m | time: 6.545s
[2K
| Adam | epoch: 012 | loss: 0.69128 - acc: 0.5476 -- iter: 288/365
[A[ATraining Step: 142  | total loss: [1m[32m0.69191[0m[0m | time: 6.859s
[2K
| Adam | epoch: 012 | loss: 0.69191 - acc: 0.5366 -- iter: 320/365
[A[ATraining Step: 143  | total loss: [1m[32m0.69190[0m[0m | time: 7.152s
[2K
| Adam | epoch: 012 | loss: 0.69190 - acc: 0.5368 -- iter: 352/365
[A[ATraining Step: 144  | total loss: [1m[32m0.69173[0m[0m | time: 8.842s
[2K
| Adam | epoch: 012 | loss: 0.69173 - acc: 0.5369 | val_loss: 0.68971 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 145  | total loss: [1m[32m0.69149[0m[0m | time: 0.662s
[2K
| Adam | epoch: 013 | loss: 0.69149 - acc: 0.5395 -- iter: 032/365
[A[ATraining Step: 146  | total loss: [1m[32m0.69235[0m[0m | time: 1.322s
[2K
| Adam | epoch: 013 | loss: 0.69235 - acc: 0.5262 -- iter: 064/365
[A[ATraining Step: 147  | total loss: [1m[32m0.69278[0m[0m | time: 1.998s
[2K
| Adam | epoch: 013 | loss: 0.69278 - acc: 0.5204 -- iter: 096/365
[A[ATraining Step: 148  | total loss: [1m[32m0.69398[0m[0m | time: 2.650s
[2K
| Adam | epoch: 013 | loss: 0.69398 - acc: 0.5028 -- iter: 128/365
[A[ATraining Step: 149  | total loss: [1m[32m0.69374[0m[0m | time: 3.338s
[2K
| Adam | epoch: 013 | loss: 0.69374 - acc: 0.5056 -- iter: 160/365
[A[ATraining Step: 150  | total loss: [1m[32m0.69391[0m[0m | time: 4.009s
[2K
| Adam | epoch: 013 | loss: 0.69391 - acc: 0.5019 -- iter: 192/365
[A[ATraining Step: 151  | total loss: [1m[32m0.69347[0m[0m | time: 4.660s
[2K
| Adam | epoch: 013 | loss: 0.69347 - acc: 0.5080 -- iter: 224/365
[A[ATraining Step: 152  | total loss: [1m[32m0.69366[0m[0m | time: 5.305s
[2K
| Adam | epoch: 013 | loss: 0.69366 - acc: 0.5041 -- iter: 256/365
[A[ATraining Step: 153  | total loss: [1m[32m0.69362[0m[0m | time: 5.973s
[2K
| Adam | epoch: 013 | loss: 0.69362 - acc: 0.5037 -- iter: 288/365
[A[ATraining Step: 154  | total loss: [1m[32m0.69358[0m[0m | time: 6.642s
[2K
| Adam | epoch: 013 | loss: 0.69358 - acc: 0.5033 -- iter: 320/365
[A[ATraining Step: 155  | total loss: [1m[32m0.69288[0m[0m | time: 6.953s
[2K
| Adam | epoch: 013 | loss: 0.69288 - acc: 0.5155 -- iter: 352/365
[A[ATraining Step: 156  | total loss: [1m[32m0.69359[0m[0m | time: 8.260s
[2K
| Adam | epoch: 013 | loss: 0.69359 - acc: 0.5024 | val_loss: 0.69039 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 157  | total loss: [1m[32m0.69418[0m[0m | time: 0.663s
[2K
| Adam | epoch: 014 | loss: 0.69418 - acc: 0.4906 -- iter: 032/365
[A[ATraining Step: 158  | total loss: [1m[32m0.69477[0m[0m | time: 1.318s
[2K
| Adam | epoch: 014 | loss: 0.69477 - acc: 0.4790 -- iter: 064/365
[A[ATraining Step: 159  | total loss: [1m[32m0.69395[0m[0m | time: 1.977s
[2K
| Adam | epoch: 014 | loss: 0.69395 - acc: 0.4936 -- iter: 096/365
[A[ATraining Step: 160  | total loss: [1m[32m0.69403[0m[0m | time: 2.637s
[2K
| Adam | epoch: 014 | loss: 0.69403 - acc: 0.4911 -- iter: 128/365
[A[ATraining Step: 161  | total loss: [1m[32m0.69383[0m[0m | time: 3.316s
[2K
| Adam | epoch: 014 | loss: 0.69383 - acc: 0.4952 -- iter: 160/365
[A[ATraining Step: 162  | total loss: [1m[32m0.69363[0m[0m | time: 3.965s
[2K
| Adam | epoch: 014 | loss: 0.69363 - acc: 0.4988 -- iter: 192/365
[A[ATraining Step: 163  | total loss: [1m[32m0.69360[0m[0m | time: 4.614s
[2K
| Adam | epoch: 014 | loss: 0.69360 - acc: 0.4989 -- iter: 224/365
[A[ATraining Step: 164  | total loss: [1m[32m0.69354[0m[0m | time: 5.312s
[2K
| Adam | epoch: 014 | loss: 0.69354 - acc: 0.4990 -- iter: 256/365
[A[ATraining Step: 165  | total loss: [1m[32m0.69350[0m[0m | time: 5.968s
[2K
| Adam | epoch: 014 | loss: 0.69350 - acc: 0.4991 -- iter: 288/365
[A[ATraining Step: 166  | total loss: [1m[32m0.69348[0m[0m | time: 6.618s
[2K
| Adam | epoch: 014 | loss: 0.69348 - acc: 0.4992 -- iter: 320/365
[A[ATraining Step: 167  | total loss: [1m[32m0.69315[0m[0m | time: 7.279s
[2K
| Adam | epoch: 014 | loss: 0.69315 - acc: 0.5055 -- iter: 352/365
[A[ATraining Step: 168  | total loss: [1m[32m0.69300[0m[0m | time: 8.599s
[2K
| Adam | epoch: 014 | loss: 0.69300 - acc: 0.5081 | val_loss: 0.69067 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 169  | total loss: [1m[32m0.69360[0m[0m | time: 0.298s
[2K
| Adam | epoch: 015 | loss: 0.69360 - acc: 0.4957 -- iter: 032/365
[A[ATraining Step: 170  | total loss: [1m[32m0.69411[0m[0m | time: 0.975s
[2K
| Adam | epoch: 015 | loss: 0.69411 - acc: 0.4846 -- iter: 064/365
[A[ATraining Step: 171  | total loss: [1m[32m0.69363[0m[0m | time: 1.627s
[2K
| Adam | epoch: 015 | loss: 0.69363 - acc: 0.4955 -- iter: 096/365
[A[ATraining Step: 172  | total loss: [1m[32m0.69396[0m[0m | time: 2.296s
[2K
| Adam | epoch: 015 | loss: 0.69396 - acc: 0.4866 -- iter: 128/365
[A[ATraining Step: 173  | total loss: [1m[32m0.69387[0m[0m | time: 2.944s
[2K
| Adam | epoch: 015 | loss: 0.69387 - acc: 0.4880 -- iter: 160/365
[A[ATraining Step: 174  | total loss: [1m[32m0.69334[0m[0m | time: 3.623s
[2K
| Adam | epoch: 015 | loss: 0.69334 - acc: 0.5017 -- iter: 192/365
[A[ATraining Step: 175  | total loss: [1m[32m0.69355[0m[0m | time: 4.279s
[2K
| Adam | epoch: 015 | loss: 0.69355 - acc: 0.4952 -- iter: 224/365
[A[ATraining Step: 176  | total loss: [1m[32m0.69322[0m[0m | time: 4.937s
[2K
| Adam | epoch: 015 | loss: 0.69322 - acc: 0.5020 -- iter: 256/365
[A[ATraining Step: 177  | total loss: [1m[32m0.69267[0m[0m | time: 5.607s
[2K
| Adam | epoch: 015 | loss: 0.69267 - acc: 0.5143 -- iter: 288/365
[A[ATraining Step: 178  | total loss: [1m[32m0.69288[0m[0m | time: 6.282s
[2K
| Adam | epoch: 015 | loss: 0.69288 - acc: 0.5097 -- iter: 320/365
[A[ATraining Step: 179  | total loss: [1m[32m0.69304[0m[0m | time: 6.941s
[2K
| Adam | epoch: 015 | loss: 0.69304 - acc: 0.5056 -- iter: 352/365
[A[ATraining Step: 180  | total loss: [1m[32m0.69258[0m[0m | time: 8.615s
[2K
| Adam | epoch: 015 | loss: 0.69258 - acc: 0.5144 | val_loss: 0.69009 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 181  | total loss: [1m[32m0.69230[0m[0m | time: 0.323s
[2K
| Adam | epoch: 016 | loss: 0.69230 - acc: 0.5192 -- iter: 032/365
[A[ATraining Step: 182  | total loss: [1m[32m0.69137[0m[0m | time: 0.627s
[2K
| Adam | epoch: 016 | loss: 0.69137 - acc: 0.5365 -- iter: 064/365
[A[ATraining Step: 183  | total loss: [1m[32m0.69045[0m[0m | time: 1.300s
[2K
| Adam | epoch: 016 | loss: 0.69045 - acc: 0.5521 -- iter: 096/365
[A[ATraining Step: 184  | total loss: [1m[32m0.69131[0m[0m | time: 1.967s
[2K
| Adam | epoch: 016 | loss: 0.69131 - acc: 0.5375 -- iter: 128/365
[A[ATraining Step: 185  | total loss: [1m[32m0.69242[0m[0m | time: 2.622s
[2K
| Adam | epoch: 016 | loss: 0.69242 - acc: 0.5213 -- iter: 160/365
[A[ATraining Step: 186  | total loss: [1m[32m0.69262[0m[0m | time: 3.302s
[2K
| Adam | epoch: 016 | loss: 0.69262 - acc: 0.5160 -- iter: 192/365
[A[ATraining Step: 187  | total loss: [1m[32m0.69233[0m[0m | time: 3.974s
[2K
| Adam | epoch: 016 | loss: 0.69233 - acc: 0.5176 -- iter: 224/365
[A[ATraining Step: 188  | total loss: [1m[32m0.69240[0m[0m | time: 4.644s
[2K
| Adam | epoch: 016 | loss: 0.69240 - acc: 0.5127 -- iter: 256/365
[A[ATraining Step: 189  | total loss: [1m[32m0.69153[0m[0m | time: 5.312s
[2K
| Adam | epoch: 016 | loss: 0.69153 - acc: 0.5270 -- iter: 288/365
[A[ATraining Step: 190  | total loss: [1m[32m0.69148[0m[0m | time: 6.013s
[2K
| Adam | epoch: 016 | loss: 0.69148 - acc: 0.5243 -- iter: 320/365
[A[ATraining Step: 191  | total loss: [1m[32m0.69297[0m[0m | time: 6.688s
[2K
| Adam | epoch: 016 | loss: 0.69297 - acc: 0.5063 -- iter: 352/365
[A[ATraining Step: 192  | total loss: [1m[32m0.69186[0m[0m | time: 8.364s
[2K
| Adam | epoch: 016 | loss: 0.69186 - acc: 0.5119 | val_loss: 0.68693 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 193  | total loss: [1m[32m0.69178[0m[0m | time: 0.688s
[2K
| Adam | epoch: 017 | loss: 0.69178 - acc: 0.5045 -- iter: 032/365
[A[ATraining Step: 194  | total loss: [1m[32m0.69127[0m[0m | time: 0.981s
[2K
| Adam | epoch: 017 | loss: 0.69127 - acc: 0.5040 -- iter: 064/365
[A[ATraining Step: 195  | total loss: [1m[32m0.69099[0m[0m | time: 1.268s
[2K
| Adam | epoch: 017 | loss: 0.69099 - acc: 0.5075 -- iter: 096/365
[A[ATraining Step: 196  | total loss: [1m[32m0.69054[0m[0m | time: 1.934s
[2K
| Adam | epoch: 017 | loss: 0.69054 - acc: 0.5106 -- iter: 128/365
[A[ATraining Step: 197  | total loss: [1m[32m0.68890[0m[0m | time: 2.597s
[2K
| Adam | epoch: 017 | loss: 0.68890 - acc: 0.5189 -- iter: 160/365
[A[ATraining Step: 198  | total loss: [1m[32m0.68748[0m[0m | time: 3.261s
[2K
| Adam | epoch: 017 | loss: 0.68748 - acc: 0.5232 -- iter: 192/365
[A[ATraining Step: 199  | total loss: [1m[32m0.69034[0m[0m | time: 3.919s
[2K
| Adam | epoch: 017 | loss: 0.69034 - acc: 0.5178 -- iter: 224/365
[A[ATraining Step: 200  | total loss: [1m[32m0.69213[0m[0m | time: 5.623s
[2K
| Adam | epoch: 017 | loss: 0.69213 - acc: 0.5098 | val_loss: 0.68120 - val_acc: 0.5565 -- iter: 256/365
--
Training Step: 201  | total loss: [1m[32m0.69081[0m[0m | time: 6.292s
[2K
| Adam | epoch: 017 | loss: 0.69081 - acc: 0.5119 -- iter: 288/365
[A[ATraining Step: 202  | total loss: [1m[32m0.68920[0m[0m | time: 6.957s
[2K
| Adam | epoch: 017 | loss: 0.68920 - acc: 0.5232 -- iter: 320/365
[A[ATraining Step: 203  | total loss: [1m[32m0.68857[0m[0m | time: 7.616s
[2K
| Adam | epoch: 017 | loss: 0.68857 - acc: 0.5146 -- iter: 352/365
[A[ATraining Step: 204  | total loss: [1m[32m0.68771[0m[0m | time: 9.289s
[2K
| Adam | epoch: 017 | loss: 0.68771 - acc: 0.5101 | val_loss: 0.67462 - val_acc: 0.5565 -- iter: 365/365
--
Training Step: 205  | total loss: [1m[32m0.68556[0m[0m | time: 0.656s
[2K
| Adam | epoch: 018 | loss: 0.68556 - acc: 0.5247 -- iter: 032/365
[A[ATraining Step: 206  | total loss: [1m[32m0.68470[0m[0m | time: 1.320s
[2K
| Adam | epoch: 018 | loss: 0.68470 - acc: 0.5191 -- iter: 064/365
[A[ATraining Step: 207  | total loss: [1m[32m0.68351[0m[0m | time: 1.623s
[2K
| Adam | epoch: 018 | loss: 0.68351 - acc: 0.5140 -- iter: 096/365
[A[ATraining Step: 208  | total loss: [1m[32m0.68493[0m[0m | time: 1.913s
[2K
| Adam | epoch: 018 | loss: 0.68493 - acc: 0.4934 -- iter: 128/365
[A[ATraining Step: 209  | total loss: [1m[32m0.68299[0m[0m | time: 2.566s
[2K
| Adam | epoch: 018 | loss: 0.68299 - acc: 0.5133 -- iter: 160/365
[A[ATraining Step: 210  | total loss: [1m[32m0.68185[0m[0m | time: 3.227s
[2K
| Adam | epoch: 018 | loss: 0.68185 - acc: 0.5276 -- iter: 192/365
[A[ATraining Step: 211  | total loss: [1m[32m0.67912[0m[0m | time: 3.883s
[2K
| Adam | epoch: 018 | loss: 0.67912 - acc: 0.5405 -- iter: 224/365
[A[ATraining Step: 212  | total loss: [1m[32m0.67669[0m[0m | time: 4.573s
[2K
| Adam | epoch: 018 | loss: 0.67669 - acc: 0.5614 -- iter: 256/365
[A[ATraining Step: 213  | total loss: [1m[32m0.67563[0m[0m | time: 5.239s
[2K
| Adam | epoch: 018 | loss: 0.67563 - acc: 0.5709 -- iter: 288/365
[A[ATraining Step: 214  | total loss: [1m[32m0.66700[0m[0m | time: 5.911s
[2K
| Adam | epoch: 018 | loss: 0.66700 - acc: 0.5826 -- iter: 320/365
[A[ATraining Step: 215  | total loss: [1m[32m0.66730[0m[0m | time: 6.567s
[2K
| Adam | epoch: 018 | loss: 0.66730 - acc: 0.5806 -- iter: 352/365
[A[ATraining Step: 216  | total loss: [1m[32m0.66130[0m[0m | time: 8.241s
[2K
| Adam | epoch: 018 | loss: 0.66130 - acc: 0.5975 | val_loss: 0.64700 - val_acc: 0.5739 -- iter: 365/365
--
Training Step: 217  | total loss: [1m[32m0.65448[0m[0m | time: 0.690s
[2K
| Adam | epoch: 019 | loss: 0.65448 - acc: 0.6127 -- iter: 032/365
[A[ATraining Step: 218  | total loss: [1m[32m0.64811[0m[0m | time: 1.366s
[2K
| Adam | epoch: 019 | loss: 0.64811 - acc: 0.6171 -- iter: 064/365
[A[ATraining Step: 219  | total loss: [1m[32m0.64555[0m[0m | time: 2.045s
[2K
| Adam | epoch: 019 | loss: 0.64555 - acc: 0.6304 -- iter: 096/365
[A[ATraining Step: 220  | total loss: [1m[32m0.63764[0m[0m | time: 2.343s
[2K
| Adam | epoch: 019 | loss: 0.63764 - acc: 0.6424 -- iter: 128/365
[A[ATraining Step: 221  | total loss: [1m[32m0.63333[0m[0m | time: 2.675s
[2K
| Adam | epoch: 019 | loss: 0.63333 - acc: 0.6473 -- iter: 160/365
[A[ATraining Step: 222  | total loss: [1m[32m0.62942[0m[0m | time: 3.337s
[2K
| Adam | epoch: 019 | loss: 0.62942 - acc: 0.6595 -- iter: 192/365
[A[ATraining Step: 223  | total loss: [1m[32m0.62662[0m[0m | time: 4.000s
[2K
| Adam | epoch: 019 | loss: 0.62662 - acc: 0.6623 -- iter: 224/365
[A[ATraining Step: 224  | total loss: [1m[32m0.62391[0m[0m | time: 4.688s
[2K
| Adam | epoch: 019 | loss: 0.62391 - acc: 0.6617 -- iter: 256/365
[A[ATraining Step: 225  | total loss: [1m[32m0.61949[0m[0m | time: 5.350s
[2K
| Adam | epoch: 019 | loss: 0.61949 - acc: 0.6549 -- iter: 288/365
[A[ATraining Step: 226  | total loss: [1m[32m0.62508[0m[0m | time: 6.010s
[2K
| Adam | epoch: 019 | loss: 0.62508 - acc: 0.6488 -- iter: 320/365
[A[ATraining Step: 227  | total loss: [1m[32m0.62065[0m[0m | time: 6.665s
[2K
| Adam | epoch: 019 | loss: 0.62065 - acc: 0.6589 -- iter: 352/365
[A[ATraining Step: 228  | total loss: [1m[32m0.62001[0m[0m | time: 8.323s
[2K
| Adam | epoch: 019 | loss: 0.62001 - acc: 0.6555 | val_loss: 0.63037 - val_acc: 0.6348 -- iter: 365/365
--
Training Step: 229  | total loss: [1m[32m0.60678[0m[0m | time: 0.663s
[2K
| Adam | epoch: 020 | loss: 0.60678 - acc: 0.6744 -- iter: 032/365
[A[ATraining Step: 230  | total loss: [1m[32m0.59234[0m[0m | time: 1.337s
[2K
| Adam | epoch: 020 | loss: 0.59234 - acc: 0.6882 -- iter: 064/365
[A[ATraining Step: 231  | total loss: [1m[32m0.58940[0m[0m | time: 1.992s
[2K
| Adam | epoch: 020 | loss: 0.58940 - acc: 0.6944 -- iter: 096/365
[A[ATraining Step: 232  | total loss: [1m[32m0.58183[0m[0m | time: 2.673s
[2K
| Adam | epoch: 020 | loss: 0.58183 - acc: 0.6999 -- iter: 128/365
[A[ATraining Step: 233  | total loss: [1m[32m0.57522[0m[0m | time: 2.974s
[2K
| Adam | epoch: 020 | loss: 0.57522 - acc: 0.7018 -- iter: 160/365
[A[ATraining Step: 234  | total loss: [1m[32m0.56167[0m[0m | time: 3.270s
[2K
| Adam | epoch: 020 | loss: 0.56167 - acc: 0.7085 -- iter: 192/365
[A[ATraining Step: 235  | total loss: [1m[32m0.54280[0m[0m | time: 3.958s
[2K
| Adam | epoch: 020 | loss: 0.54280 - acc: 0.7300 -- iter: 224/365
[A[ATraining Step: 236  | total loss: [1m[32m0.53510[0m[0m | time: 4.616s
[2K
| Adam | epoch: 020 | loss: 0.53510 - acc: 0.7320 -- iter: 256/365
[A[ATraining Step: 237  | total loss: [1m[32m0.53213[0m[0m | time: 5.272s
[2K
| Adam | epoch: 020 | loss: 0.53213 - acc: 0.7338 -- iter: 288/365
[A[ATraining Step: 238  | total loss: [1m[32m0.51496[0m[0m | time: 5.962s
[2K
| Adam | epoch: 020 | loss: 0.51496 - acc: 0.7448 -- iter: 320/365
[A[ATraining Step: 239  | total loss: [1m[32m0.49481[0m[0m | time: 6.622s
[2K
| Adam | epoch: 020 | loss: 0.49481 - acc: 0.7609 -- iter: 352/365
[A[ATraining Step: 240  | total loss: [1m[32m0.47782[0m[0m | time: 8.280s
[2K
| Adam | epoch: 020 | loss: 0.47782 - acc: 0.7755 | val_loss: 0.62234 - val_acc: 0.7043 -- iter: 365/365
--
Training Step: 241  | total loss: [1m[32m0.47200[0m[0m | time: 0.684s
[2K
| Adam | epoch: 021 | loss: 0.47200 - acc: 0.7792 -- iter: 032/365
[A[ATraining Step: 242  | total loss: [1m[32m0.44947[0m[0m | time: 1.337s
[2K
| Adam | epoch: 021 | loss: 0.44947 - acc: 0.7888 -- iter: 064/365
[A[ATraining Step: 243  | total loss: [1m[32m0.43296[0m[0m | time: 2.002s
[2K
| Adam | epoch: 021 | loss: 0.43296 - acc: 0.8005 -- iter: 096/365
[A[ATraining Step: 244  | total loss: [1m[32m0.41875[0m[0m | time: 2.691s
[2K
| Adam | epoch: 021 | loss: 0.41875 - acc: 0.8080 -- iter: 128/365
[A[ATraining Step: 245  | total loss: [1m[32m0.40157[0m[0m | time: 3.347s
[2K
| Adam | epoch: 021 | loss: 0.40157 - acc: 0.8178 -- iter: 160/365
[A[ATraining Step: 246  | total loss: [1m[32m0.38443[0m[0m | time: 3.647s
[2K
| Adam | epoch: 021 | loss: 0.38443 - acc: 0.8266 -- iter: 192/365
[A[ATraining Step: 247  | total loss: [1m[32m0.37434[0m[0m | time: 3.953s
[2K
| Adam | epoch: 021 | loss: 0.37434 - acc: 0.8286 -- iter: 224/365
[A[ATraining Step: 248  | total loss: [1m[32m0.34570[0m[0m | time: 4.610s
[2K
| Adam | epoch: 021 | loss: 0.34570 - acc: 0.8457 -- iter: 256/365
[A[ATraining Step: 249  | total loss: [1m[32m0.37432[0m[0m | time: 5.258s
[2K
| Adam | epoch: 021 | loss: 0.37432 - acc: 0.8393 -- iter: 288/365
[A[ATraining Step: 250  | total loss: [1m[32m0.38071[0m[0m | time: 5.939s
[2K
| Adam | epoch: 021 | loss: 0.38071 - acc: 0.8366 -- iter: 320/365
[A[ATraining Step: 251  | total loss: [1m[32m0.38985[0m[0m | time: 6.622s
[2K
| Adam | epoch: 021 | loss: 0.38985 - acc: 0.8311 -- iter: 352/365
[A[ATraining Step: 252  | total loss: [1m[32m0.40957[0m[0m | time: 8.277s
[2K
| Adam | epoch: 021 | loss: 0.40957 - acc: 0.8292 | val_loss: 0.91885 - val_acc: 0.6261 -- iter: 365/365
--
Training Step: 253  | total loss: [1m[32m0.44736[0m[0m | time: 0.690s
[2K
| Adam | epoch: 022 | loss: 0.44736 - acc: 0.8119 -- iter: 032/365
[A[ATraining Step: 254  | total loss: [1m[32m0.45182[0m[0m | time: 1.343s
[2K
| Adam | epoch: 022 | loss: 0.45182 - acc: 0.8026 -- iter: 064/365
[A[ATraining Step: 255  | total loss: [1m[32m0.43438[0m[0m | time: 2.001s
[2K
| Adam | epoch: 022 | loss: 0.43438 - acc: 0.8067 -- iter: 096/365
[A[ATraining Step: 256  | total loss: [1m[32m0.41881[0m[0m | time: 2.666s
[2K
| Adam | epoch: 022 | loss: 0.41881 - acc: 0.8167 -- iter: 128/365
[A[ATraining Step: 257  | total loss: [1m[32m0.41654[0m[0m | time: 3.359s
[2K
| Adam | epoch: 022 | loss: 0.41654 - acc: 0.8194 -- iter: 160/365
[A[ATraining Step: 258  | total loss: [1m[32m0.39414[0m[0m | time: 4.041s
[2K
| Adam | epoch: 022 | loss: 0.39414 - acc: 0.8312 -- iter: 192/365
[A[ATraining Step: 259  | total loss: [1m[32m0.37430[0m[0m | time: 4.343s
[2K
| Adam | epoch: 022 | loss: 0.37430 - acc: 0.8449 -- iter: 224/365
[A[ATraining Step: 260  | total loss: [1m[32m0.36398[0m[0m | time: 4.636s
[2K
| Adam | epoch: 022 | loss: 0.36398 - acc: 0.8451 -- iter: 256/365
[A[ATraining Step: 261  | total loss: [1m[32m0.34190[0m[0m | time: 5.320s
[2K
| Adam | epoch: 022 | loss: 0.34190 - acc: 0.8606 -- iter: 288/365
[A[ATraining Step: 262  | total loss: [1m[32m0.32901[0m[0m | time: 5.982s
[2K
| Adam | epoch: 022 | loss: 0.32901 - acc: 0.8714 -- iter: 320/365
[A[ATraining Step: 263  | total loss: [1m[32m0.32118[0m[0m | time: 6.650s
[2K
| Adam | epoch: 022 | loss: 0.32118 - acc: 0.8686 -- iter: 352/365
[A[ATraining Step: 264  | total loss: [1m[32m0.31561[0m[0m | time: 8.333s
[2K
| Adam | epoch: 022 | loss: 0.31561 - acc: 0.8755 | val_loss: 0.74911 - val_acc: 0.6870 -- iter: 365/365
--
Training Step: 265  | total loss: [1m[32m0.32574[0m[0m | time: 0.657s
[2K
| Adam | epoch: 023 | loss: 0.32574 - acc: 0.8723 -- iter: 032/365
[A[ATraining Step: 266  | total loss: [1m[32m0.32056[0m[0m | time: 1.315s
[2K
| Adam | epoch: 023 | loss: 0.32056 - acc: 0.8788 -- iter: 064/365
[A[ATraining Step: 267  | total loss: [1m[32m0.32366[0m[0m | time: 1.968s
[2K
| Adam | epoch: 023 | loss: 0.32366 - acc: 0.8722 -- iter: 096/365
[A[ATraining Step: 268  | total loss: [1m[32m0.29941[0m[0m | time: 2.649s
[2K
| Adam | epoch: 023 | loss: 0.29941 - acc: 0.8850 -- iter: 128/365
[A[ATraining Step: 269  | total loss: [1m[32m0.28913[0m[0m | time: 3.311s
[2K
| Adam | epoch: 023 | loss: 0.28913 - acc: 0.8902 -- iter: 160/365
[A[ATraining Step: 270  | total loss: [1m[32m0.29170[0m[0m | time: 3.963s
[2K
| Adam | epoch: 023 | loss: 0.29170 - acc: 0.8856 -- iter: 192/365
[A[ATraining Step: 271  | total loss: [1m[32m0.28840[0m[0m | time: 4.615s
[2K
| Adam | epoch: 023 | loss: 0.28840 - acc: 0.8845 -- iter: 224/365
[A[ATraining Step: 272  | total loss: [1m[32m0.26360[0m[0m | time: 4.909s
[2K
| Adam | epoch: 023 | loss: 0.26360 - acc: 0.8961 -- iter: 256/365
[A[ATraining Step: 273  | total loss: [1m[32m0.24221[0m[0m | time: 5.226s
[2K
| Adam | epoch: 023 | loss: 0.24221 - acc: 0.9065 -- iter: 288/365
[A[ATraining Step: 274  | total loss: [1m[32m0.22304[0m[0m | time: 5.894s
[2K
| Adam | epoch: 023 | loss: 0.22304 - acc: 0.9158 -- iter: 320/365
[A[ATraining Step: 275  | total loss: [1m[32m0.21466[0m[0m | time: 6.587s
[2K
| Adam | epoch: 023 | loss: 0.21466 - acc: 0.9180 -- iter: 352/365
[A[ATraining Step: 276  | total loss: [1m[32m0.22614[0m[0m | time: 8.254s
[2K
| Adam | epoch: 023 | loss: 0.22614 - acc: 0.9137 | val_loss: 0.81339 - val_acc: 0.7391 -- iter: 365/365
--
Training Step: 277  | total loss: [1m[32m0.23186[0m[0m | time: 0.656s
[2K
| Adam | epoch: 024 | loss: 0.23186 - acc: 0.9161 -- iter: 032/365
[A[ATraining Step: 278  | total loss: [1m[32m0.23547[0m[0m | time: 1.343s
[2K
| Adam | epoch: 024 | loss: 0.23547 - acc: 0.9151 -- iter: 064/365
[A[ATraining Step: 279  | total loss: [1m[32m0.23542[0m[0m | time: 1.992s
[2K
| Adam | epoch: 024 | loss: 0.23542 - acc: 0.9142 -- iter: 096/365
[A[ATraining Step: 280  | total loss: [1m[32m0.22226[0m[0m | time: 2.646s
[2K
| Adam | epoch: 024 | loss: 0.22226 - acc: 0.9228 -- iter: 128/365
[A[ATraining Step: 281  | total loss: [1m[32m0.21051[0m[0m | time: 3.291s
[2K
| Adam | epoch: 024 | loss: 0.21051 - acc: 0.9274 -- iter: 160/365
[A[ATraining Step: 282  | total loss: [1m[32m0.20064[0m[0m | time: 3.945s
[2K
| Adam | epoch: 024 | loss: 0.20064 - acc: 0.9284 -- iter: 192/365
[A[ATraining Step: 283  | total loss: [1m[32m0.18834[0m[0m | time: 4.614s
[2K
| Adam | epoch: 024 | loss: 0.18834 - acc: 0.9356 -- iter: 224/365
[A[ATraining Step: 284  | total loss: [1m[32m0.18152[0m[0m | time: 5.258s
[2K
| Adam | epoch: 024 | loss: 0.18152 - acc: 0.9389 -- iter: 256/365
[A[ATraining Step: 285  | total loss: [1m[32m0.18422[0m[0m | time: 5.552s
[2K
| Adam | epoch: 024 | loss: 0.18422 - acc: 0.9356 -- iter: 288/365
[A[ATraining Step: 286  | total loss: [1m[32m0.16963[0m[0m | time: 5.844s
[2K
| Adam | epoch: 024 | loss: 0.16963 - acc: 0.9421 -- iter: 320/365
[A[ATraining Step: 287  | total loss: [1m[32m0.15695[0m[0m | time: 6.542s
[2K
| Adam | epoch: 024 | loss: 0.15695 - acc: 0.9478 -- iter: 352/365
[A[ATraining Step: 288  | total loss: [1m[32m0.16708[0m[0m | time: 8.216s
[2K
| Adam | epoch: 024 | loss: 0.16708 - acc: 0.9437 | val_loss: 0.68698 - val_acc: 0.7130 -- iter: 365/365
--
Training Step: 289  | total loss: [1m[32m0.16218[0m[0m | time: 0.678s
[2K
| Adam | epoch: 025 | loss: 0.16218 - acc: 0.9462 -- iter: 032/365
[A[ATraining Step: 290  | total loss: [1m[32m0.15213[0m[0m | time: 1.346s
[2K
| Adam | epoch: 025 | loss: 0.15213 - acc: 0.9516 -- iter: 064/365
[A[ATraining Step: 291  | total loss: [1m[32m0.14042[0m[0m | time: 2.003s
[2K
| Adam | epoch: 025 | loss: 0.14042 - acc: 0.9564 -- iter: 096/365
[A[ATraining Step: 292  | total loss: [1m[32m0.14567[0m[0m | time: 2.689s
[2K
| Adam | epoch: 025 | loss: 0.14567 - acc: 0.9576 -- iter: 128/365
[A[ATraining Step: 293  | total loss: [1m[32m0.14230[0m[0m | time: 3.357s
[2K
| Adam | epoch: 025 | loss: 0.14230 - acc: 0.9588 -- iter: 160/365
[A[ATraining Step: 294  | total loss: [1m[32m0.13090[0m[0m | time: 4.024s
[2K
| Adam | epoch: 025 | loss: 0.13090 - acc: 0.9629 -- iter: 192/365
[A[ATraining Step: 295  | total loss: [1m[32m0.12262[0m[0m | time: 4.685s
[2K
| Adam | epoch: 025 | loss: 0.12262 - acc: 0.9666 -- iter: 224/365
[A[ATraining Step: 296  | total loss: [1m[32m0.11136[0m[0m | time: 5.346s
[2K
| Adam | epoch: 025 | loss: 0.11136 - acc: 0.9699 -- iter: 256/365
[A[ATraining Step: 297  | total loss: [1m[32m0.10932[0m[0m | time: 6.019s
[2K
| Adam | epoch: 025 | loss: 0.10932 - acc: 0.9698 -- iter: 288/365
[A[ATraining Step: 298  | total loss: [1m[32m0.10122[0m[0m | time: 6.323s
[2K
| Adam | epoch: 025 | loss: 0.10122 - acc: 0.9728 -- iter: 320/365
[A[ATraining Step: 299  | total loss: [1m[32m0.09243[0m[0m | time: 6.631s
[2K
| Adam | epoch: 025 | loss: 0.09243 - acc: 0.9756 -- iter: 352/365
[A[ATraining Step: 300  | total loss: [1m[32m0.08419[0m[0m | time: 8.347s
[2K
| Adam | epoch: 025 | loss: 0.08419 - acc: 0.9780 | val_loss: 0.78379 - val_acc: 0.7391 -- iter: 365/365
--
Training Step: 301  | total loss: [1m[32m0.07870[0m[0m | time: 0.659s
[2K
| Adam | epoch: 026 | loss: 0.07870 - acc: 0.9802 -- iter: 032/365
[A[ATraining Step: 302  | total loss: [1m[32m0.07967[0m[0m | time: 1.324s
[2K
| Adam | epoch: 026 | loss: 0.07967 - acc: 0.9791 -- iter: 064/365
[A[ATraining Step: 303  | total loss: [1m[32m0.08172[0m[0m | time: 1.999s
[2K
| Adam | epoch: 026 | loss: 0.08172 - acc: 0.9749 -- iter: 096/365
[A[ATraining Step: 304  | total loss: [1m[32m0.08474[0m[0m | time: 2.651s
[2K
| Adam | epoch: 026 | loss: 0.08474 - acc: 0.9743 -- iter: 128/365
[A[ATraining Step: 305  | total loss: [1m[32m0.07858[0m[0m | time: 3.331s
[2K
| Adam | epoch: 026 | loss: 0.07858 - acc: 0.9769 -- iter: 160/365
[A[ATraining Step: 306  | total loss: [1m[32m0.07339[0m[0m | time: 4.046s
[2K
| Adam | epoch: 026 | loss: 0.07339 - acc: 0.9792 -- iter: 192/365
[A[ATraining Step: 307  | total loss: [1m[32m0.06663[0m[0m | time: 4.732s
[2K
| Adam | epoch: 026 | loss: 0.06663 - acc: 0.9813 -- iter: 224/365
[A[ATraining Step: 308  | total loss: [1m[32m0.06116[0m[0m | time: 5.399s
[2K
| Adam | epoch: 026 | loss: 0.06116 - acc: 0.9831 -- iter: 256/365
[A[ATraining Step: 309  | total loss: [1m[32m0.05724[0m[0m | time: 6.074s
[2K
| Adam | epoch: 026 | loss: 0.05724 - acc: 0.9848 -- iter: 288/365
[A[ATraining Step: 310  | total loss: [1m[32m0.05497[0m[0m | time: 6.741s
[2K
| Adam | epoch: 026 | loss: 0.05497 - acc: 0.9863 -- iter: 320/365
[A[ATraining Step: 311  | total loss: [1m[32m0.06140[0m[0m | time: 7.051s
[2K
| Adam | epoch: 026 | loss: 0.06140 - acc: 0.9846 -- iter: 352/365
[A[ATraining Step: 312  | total loss: [1m[32m0.05578[0m[0m | time: 8.355s
[2K
| Adam | epoch: 026 | loss: 0.05578 - acc: 0.9861 | val_loss: 1.06386 - val_acc: 0.6870 -- iter: 365/365
--
Training Step: 313  | total loss: [1m[32m0.05157[0m[0m | time: 0.648s
[2K
| Adam | epoch: 027 | loss: 0.05157 - acc: 0.9875 -- iter: 032/365
[A[ATraining Step: 314  | total loss: [1m[32m0.08465[0m[0m | time: 1.309s
[2K
| Adam | epoch: 027 | loss: 0.08465 - acc: 0.9794 -- iter: 064/365
[A[ATraining Step: 315  | total loss: [1m[32m0.08233[0m[0m | time: 1.989s
[2K
| Adam | epoch: 027 | loss: 0.08233 - acc: 0.9783 -- iter: 096/365
[A[ATraining Step: 316  | total loss: [1m[32m0.07784[0m[0m | time: 2.638s
[2K
| Adam | epoch: 027 | loss: 0.07784 - acc: 0.9774 -- iter: 128/365
[A[ATraining Step: 317  | total loss: [1m[32m0.07539[0m[0m | time: 3.297s
[2K
| Adam | epoch: 027 | loss: 0.07539 - acc: 0.9765 -- iter: 160/365
[A[ATraining Step: 318  | total loss: [1m[32m0.07687[0m[0m | time: 3.964s
[2K
| Adam | epoch: 027 | loss: 0.07687 - acc: 0.9726 -- iter: 192/365
[A[ATraining Step: 319  | total loss: [1m[32m0.07072[0m[0m | time: 4.649s
[2K
| Adam | epoch: 027 | loss: 0.07072 - acc: 0.9753 -- iter: 224/365
[A[ATraining Step: 320  | total loss: [1m[32m0.06819[0m[0m | time: 5.302s
[2K
| Adam | epoch: 027 | loss: 0.06819 - acc: 0.9747 -- iter: 256/365
[A[ATraining Step: 321  | total loss: [1m[32m0.06405[0m[0m | time: 5.962s
[2K
| Adam | epoch: 027 | loss: 0.06405 - acc: 0.9772 -- iter: 288/365
[A[ATraining Step: 322  | total loss: [1m[32m0.07072[0m[0m | time: 6.610s
[2K
| Adam | epoch: 027 | loss: 0.07072 - acc: 0.9732 -- iter: 320/365
[A[ATraining Step: 323  | total loss: [1m[32m0.06486[0m[0m | time: 7.276s
[2K
| Adam | epoch: 027 | loss: 0.06486 - acc: 0.9759 -- iter: 352/365
[A[ATraining Step: 324  | total loss: [1m[32m0.06368[0m[0m | time: 8.573s
[2K
| Adam | epoch: 027 | loss: 0.06368 - acc: 0.9752 | val_loss: 1.10100 - val_acc: 0.7043 -- iter: 365/365
--
Training Step: 325  | total loss: [1m[32m0.05788[0m[0m | time: 0.306s
[2K
| Adam | epoch: 028 | loss: 0.05788 - acc: 0.9777 -- iter: 032/365
[A[ATraining Step: 326  | total loss: [1m[32m0.05278[0m[0m | time: 0.974s
[2K
| Adam | epoch: 028 | loss: 0.05278 - acc: 0.9799 -- iter: 064/365
[A[ATraining Step: 327  | total loss: [1m[32m0.05071[0m[0m | time: 1.624s
[2K
| Adam | epoch: 028 | loss: 0.05071 - acc: 0.9819 -- iter: 096/365
[A[ATraining Step: 328  | total loss: [1m[32m0.04802[0m[0m | time: 2.286s
[2K
| Adam | epoch: 028 | loss: 0.04802 - acc: 0.9837 -- iter: 128/365
[A[ATraining Step: 329  | total loss: [1m[32m0.04392[0m[0m | time: 2.926s
[2K
| Adam | epoch: 028 | loss: 0.04392 - acc: 0.9854 -- iter: 160/365
[A[ATraining Step: 330  | total loss: [1m[32m0.04215[0m[0m | time: 3.607s
[2K
| Adam | epoch: 028 | loss: 0.04215 - acc: 0.9868 -- iter: 192/365
[A[ATraining Step: 331  | total loss: [1m[32m0.04311[0m[0m | time: 4.265s
[2K
| Adam | epoch: 028 | loss: 0.04311 - acc: 0.9850 -- iter: 224/365
[A[ATraining Step: 332  | total loss: [1m[32m0.05173[0m[0m | time: 4.926s
[2K
| Adam | epoch: 028 | loss: 0.05173 - acc: 0.9834 -- iter: 256/365
[A[ATraining Step: 333  | total loss: [1m[32m0.04716[0m[0m | time: 5.594s
[2K
| Adam | epoch: 028 | loss: 0.04716 - acc: 0.9850 -- iter: 288/365
[A[ATraining Step: 334  | total loss: [1m[32m0.04908[0m[0m | time: 6.253s
[2K
| Adam | epoch: 028 | loss: 0.04908 - acc: 0.9834 -- iter: 320/365
[A[ATraining Step: 335  | total loss: [1m[32m0.05601[0m[0m | time: 6.916s
[2K
| Adam | epoch: 028 | loss: 0.05601 - acc: 0.9788 -- iter: 352/365
[A[ATraining Step: 336  | total loss: [1m[32m0.05097[0m[0m | time: 8.614s
[2K
| Adam | epoch: 028 | loss: 0.05097 - acc: 0.9809 | val_loss: 0.92315 - val_acc: 0.7478 -- iter: 365/365
--
Training Step: 337  | total loss: [1m[32m0.04818[0m[0m | time: 0.318s
[2K
| Adam | epoch: 029 | loss: 0.04818 - acc: 0.9828 -- iter: 032/365
[A[ATraining Step: 338  | total loss: [1m[32m0.04541[0m[0m | time: 0.631s
[2K
| Adam | epoch: 029 | loss: 0.04541 - acc: 0.9846 -- iter: 064/365
[A[ATraining Step: 339  | total loss: [1m[32m0.04396[0m[0m | time: 1.295s
[2K
| Adam | epoch: 029 | loss: 0.04396 - acc: 0.9861 -- iter: 096/365
[A[ATraining Step: 340  | total loss: [1m[32m0.04877[0m[0m | time: 1.974s
[2K
| Adam | epoch: 029 | loss: 0.04877 - acc: 0.9844 -- iter: 128/365
[A[ATraining Step: 341  | total loss: [1m[32m0.04641[0m[0m | time: 2.639s
[2K
| Adam | epoch: 029 | loss: 0.04641 - acc: 0.9859 -- iter: 160/365
[A[ATraining Step: 342  | total loss: [1m[32m0.04246[0m[0m | time: 3.305s
[2K
| Adam | epoch: 029 | loss: 0.04246 - acc: 0.9873 -- iter: 192/365
[A[ATraining Step: 343  | total loss: [1m[32m0.03905[0m[0m | time: 3.972s
[2K
| Adam | epoch: 029 | loss: 0.03905 - acc: 0.9886 -- iter: 224/365
[A[ATraining Step: 344  | total loss: [1m[32m0.03949[0m[0m | time: 4.635s
[2K
| Adam | epoch: 029 | loss: 0.03949 - acc: 0.9897 -- iter: 256/365
[A[ATraining Step: 345  | total loss: [1m[32m0.04131[0m[0m | time: 5.323s
[2K
| Adam | epoch: 029 | loss: 0.04131 - acc: 0.9876 -- iter: 288/365
[A[ATraining Step: 346  | total loss: [1m[32m0.03994[0m[0m | time: 6.020s
[2K
| Adam | epoch: 029 | loss: 0.03994 - acc: 0.9889 -- iter: 320/365
[A[ATraining Step: 347  | total loss: [1m[32m0.03625[0m[0m | time: 6.684s
[2K
| Adam | epoch: 029 | loss: 0.03625 - acc: 0.9900 -- iter: 352/365
[A[ATraining Step: 348  | total loss: [1m[32m0.03315[0m[0m | time: 8.377s
[2K
| Adam | epoch: 029 | loss: 0.03315 - acc: 0.9910 | val_loss: 0.97374 - val_acc: 0.7739 -- iter: 365/365
--
Training Step: 349  | total loss: [1m[32m0.04556[0m[0m | time: 0.664s
[2K
| Adam | epoch: 030 | loss: 0.04556 - acc: 0.9856 -- iter: 032/365
[A[ATraining Step: 350  | total loss: [1m[32m0.04321[0m[0m | time: 0.978s
[2K
| Adam | epoch: 030 | loss: 0.04321 - acc: 0.9871 -- iter: 064/365
[A[ATraining Step: 351  | total loss: [1m[32m0.04007[0m[0m | time: 1.275s
[2K
| Adam | epoch: 030 | loss: 0.04007 - acc: 0.9884 -- iter: 096/365
[A[ATraining Step: 352  | total loss: [1m[32m0.03657[0m[0m | time: 1.953s
[2K
| Adam | epoch: 030 | loss: 0.03657 - acc: 0.9895 -- iter: 128/365
[A[ATraining Step: 353  | total loss: [1m[32m0.03349[0m[0m | time: 2.608s
[2K
| Adam | epoch: 030 | loss: 0.03349 - acc: 0.9906 -- iter: 160/365
[A[ATraining Step: 354  | total loss: [1m[32m0.03149[0m[0m | time: 3.262s
[2K
| Adam | epoch: 030 | loss: 0.03149 - acc: 0.9915 -- iter: 192/365
[A[ATraining Step: 355  | total loss: [1m[32m0.03355[0m[0m | time: 3.936s
[2K
| Adam | epoch: 030 | loss: 0.03355 - acc: 0.9892 -- iter: 224/365
[A[ATraining Step: 356  | total loss: [1m[32m0.03135[0m[0m | time: 4.588s
[2K
| Adam | epoch: 030 | loss: 0.03135 - acc: 0.9903 -- iter: 256/365
[A[ATraining Step: 357  | total loss: [1m[32m0.02945[0m[0m | time: 5.244s
[2K
| Adam | epoch: 030 | loss: 0.02945 - acc: 0.9913 -- iter: 288/365
[A[ATraining Step: 358  | total loss: [1m[32m0.08042[0m[0m | time: 5.911s
[2K
| Adam | epoch: 030 | loss: 0.08042 - acc: 0.9859 -- iter: 320/365
[A[ATraining Step: 359  | total loss: [1m[32m0.10223[0m[0m | time: 6.579s
[2K
| Adam | epoch: 030 | loss: 0.10223 - acc: 0.9748 -- iter: 352/365
[A[ATraining Step: 360  | total loss: [1m[32m0.09460[0m[0m | time: 8.246s
[2K
| Adam | epoch: 030 | loss: 0.09460 - acc: 0.9773 | val_loss: 0.94474 - val_acc: 0.7391 -- iter: 365/365
--
Validation AUC:0.8259803921568627
Validation AUPRC:0.8683120056578408
Test AUC:0.8209090909090909
Test AUPRC:0.8277292361931546
BestTestF1Score	0.77	0.47	0.73	0.69	0.87	52	23	32	8	0.05
BestTestMCCScore	0.7	0.48	0.73	0.82	0.62	37	8	47	23	0.83
BestTestAccuracyScore	0.71	0.48	0.73	0.81	0.63	38	9	46	22	0.73
BestValidationF1Score	0.77	0.45	0.73	0.73	0.81	52	19	32	12	0.05
BestValidationMCC	0.7	0.53	0.73	0.92	0.56	36	3	48	28	0.83
BestValidationAccuracy	0.73	0.51	0.74	0.87	0.62	40	6	45	24	0.73
TestPredictions (Threshold:0.83)
CHEMBL1552755,TP,ACT,1.0	CHEMBL481969,FN,ACT,0.49000000953674316	CHEMBL1898211,FN,ACT,0.6200000047683716	CHEMBL1910755,FP,INACT,0.9900000095367432	CHEMBL1823653,TN,INACT,0.0	CHEMBL509499,TN,INACT,0.0	CHEMBL477064,TN,INACT,0.0	CHEMBL1802966,TP,ACT,0.9700000286102295	CHEMBL2313918,TP,ACT,0.9900000095367432	CHEMBL3609564,TN,INACT,0.09000000357627869	CHEMBL1910760,TN,INACT,0.3400000035762787	CHEMBL1933288,FN,ACT,0.0	CHEMBL3091797,FN,ACT,0.5099999904632568	CHEMBL2392238,TN,INACT,0.009999999776482582	CHEMBL2392365,TP,ACT,0.8999999761581421	CHEMBL77732,FP,INACT,0.9800000190734863	CHEMBL1910602,TN,INACT,0.0	CHEMBL509435,TN,INACT,0.8199999928474426	CHEMBL3775969,TP,ACT,1.0	CHEMBL2042136,TN,INACT,0.6000000238418579	CHEMBL1522508,TP,ACT,0.9100000262260437	CHEMBL557456,TN,INACT,0.0	CHEMBL1802401,TP,ACT,0.9900000095367432	CHEMBL1762116,TN,INACT,0.0	CHEMBL3408797,TP,ACT,0.8700000047683716	CHEMBL521201,TN,INACT,0.18000000715255737	CHEMBL100485,TN,INACT,0.0	CHEMBL1767292,TN,INACT,0.05000000074505806	CHEMBL563733,FP,INACT,0.8500000238418579	CHEMBL1585059,FN,ACT,0.5	CHEMBL574738,FN,ACT,0.019999999552965164	CHEMBL1357975,FN,ACT,0.8100000023841858	CHEMBL485502,TN,INACT,0.0	CHEMBL197077,TN,INACT,0.0	CHEMBL1433465,FN,ACT,0.1899999976158142	CHEMBL1608304,FN,ACT,0.03999999910593033	CHEMBL457180,TN,INACT,0.0	CHEMBL3335351,FN,ACT,0.05999999865889549	CHEMBL120317,TN,INACT,0.009999999776482582	CHEMBL1702086,TP,ACT,0.9599999785423279	CHEMBL132948,TN,INACT,0.0	CHEMBL100675,TN,INACT,0.0	CHEMBL408982,TP,ACT,0.9300000071525574	CHEMBL100670,TN,INACT,0.0	CHEMBL3335354,TP,ACT,1.0	CHEMBL2313891,TP,ACT,0.9900000095367432	CHEMBL3421636,TN,INACT,0.15000000596046448	CHEMBL454973,TN,INACT,0.6499999761581421	CHEMBL3408805,TP,ACT,1.0	CHEMBL1898197,TP,ACT,0.9900000095367432	CHEMBL452812,TN,INACT,0.4399999976158142	CHEMBL489627,TN,INACT,0.03999999910593033	CHEMBL173453,TN,INACT,0.25999999046325684	CHEMBL1440473,FN,ACT,0.6399999856948853	CHEMBL495758,TN,INACT,0.009999999776482582	CHEMBL1476609,TP,ACT,0.9900000095367432	CHEMBL3823532,FN,ACT,0.009999999776482582	CHEMBL3408810,FN,ACT,0.6700000166893005	CHEMBL269538,TP,ACT,1.0	CHEMBL100312,FP,INACT,0.9800000190734863	CHEMBL469770,FP,INACT,0.9100000262260437	CHEMBL513336,TN,INACT,0.0	CHEMBL1611317,FN,ACT,0.6299999952316284	CHEMBL1440984,TP,ACT,0.9800000190734863	CHEMBL2153523,TP,ACT,0.9200000166893005	CHEMBL489430,TN,INACT,0.019999999552965164	CHEMBL1235213,FP,INACT,1.0	CHEMBL3746916,TN,INACT,0.30000001192092896	CHEMBL1802391,TP,ACT,1.0	CHEMBL1802404,TP,ACT,1.0	CHEMBL2313885,TP,ACT,0.9900000095367432	CHEMBL498520,TN,INACT,0.0	CHEMBL1300063,FN,ACT,0.38999998569488525	CHEMBL101868,TN,INACT,0.10000000149011612	CHEMBL1569442,FN,ACT,0.46000000834465027	CHEMBL316887,TN,INACT,0.019999999552965164	CHEMBL560278,TN,INACT,0.0	CHEMBL1802395,TP,ACT,1.0	CHEMBL37139,TP,ACT,0.9399999976158142	CHEMBL1899640,TP,ACT,0.9100000262260437	CHEMBL133214,TN,INACT,0.0	CHEMBL3823505,TP,ACT,1.0	CHEMBL551722,TN,INACT,0.07000000029802322	CHEMBL1910606,FP,INACT,0.9800000190734863	CHEMBL1767275,TN,INACT,0.0	CHEMBL1240703,FN,ACT,0.0	CHEMBL3408801,TP,ACT,1.0	CHEMBL3085242,TN,INACT,0.0	CHEMBL132369,TN,INACT,0.009999999776482582	CHEMBL46440,FN,ACT,0.5299999713897705	CHEMBL3335350,TP,ACT,0.9800000190734863	CHEMBL1396654,TP,ACT,1.0	CHEMBL1508872,TP,ACT,0.8899999856948853	CHEMBL230761,TN,INACT,0.4000000059604645	CHEMBL3609568,TN,INACT,0.0	CHEMBL524820,TN,INACT,0.05999999865889549	CHEMBL1868723,TP,ACT,1.0	CHEMBL608533,FN,ACT,0.0	CHEMBL941,FN,ACT,0.0	CHEMBL2163611,TN,INACT,0.03999999910593033	CHEMBL573578,TN,INACT,0.0	CHEMBL2392362,FN,ACT,0.009999999776482582	CHEMBL1300894,FN,ACT,0.05000000074505806	CHEMBL2314163,TP,ACT,0.9900000095367432	CHEMBL3408795,TP,ACT,1.0	CHEMBL1555138,FN,ACT,0.10999999940395355	CHEMBL1910759,FP,INACT,1.0	CHEMBL504550,TN,INACT,0.0	CHEMBL566722,TP,ACT,0.9100000262260437	CHEMBL1354134,TP,ACT,1.0	CHEMBL1802971,TP,ACT,1.0	CHEMBL1902528,TP,ACT,0.9900000095367432	CHEMBL456113,TN,INACT,0.0	CHEMBL337454,TN,INACT,0.0	CHEMBL450786,TP,ACT,0.9800000190734863	

