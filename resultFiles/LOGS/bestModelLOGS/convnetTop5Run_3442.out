ImageNetInceptionV2 CHEMBL2414 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	261
Number of inactive compounds :	261
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2414_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2414_adam_0.0005_30_0.6/
---------------------------------
Training samples: 317
Validation samples: 100
--
Training Step: 1  | time: 66.096s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/317
[A[ATraining Step: 2  | total loss: [1m[32m0.64367[0m[0m | time: 80.034s
[2K
| Adam | epoch: 001 | loss: 0.64367 - acc: 0.4219 -- iter: 064/317
[A[ATraining Step: 3  | total loss: [1m[32m0.62095[0m[0m | time: 98.683s
[2K
| Adam | epoch: 001 | loss: 0.62095 - acc: 0.6136 -- iter: 096/317
[A[ATraining Step: 4  | total loss: [1m[32m0.75950[0m[0m | time: 124.490s
[2K
| Adam | epoch: 001 | loss: 0.75950 - acc: 0.5050 -- iter: 128/317
[A[ATraining Step: 5  | total loss: [1m[32m0.63213[0m[0m | time: 148.063s
[2K
| Adam | epoch: 001 | loss: 0.63213 - acc: 0.6530 -- iter: 160/317
[A[ATraining Step: 6  | total loss: [1m[32m0.68991[0m[0m | time: 173.567s
[2K
| Adam | epoch: 001 | loss: 0.68991 - acc: 0.5948 -- iter: 192/317
[A[ATraining Step: 7  | total loss: [1m[32m0.62968[0m[0m | time: 206.412s
[2K
| Adam | epoch: 001 | loss: 0.62968 - acc: 0.6129 -- iter: 224/317
[A[ATraining Step: 8  | total loss: [1m[32m0.68394[0m[0m | time: 241.366s
[2K
| Adam | epoch: 001 | loss: 0.68394 - acc: 0.6021 -- iter: 256/317
[A[ATraining Step: 9  | total loss: [1m[32m0.70719[0m[0m | time: 272.035s
[2K
| Adam | epoch: 001 | loss: 0.70719 - acc: 0.5977 -- iter: 288/317
[A[ATraining Step: 10  | total loss: [1m[32m0.71719[0m[0m | time: 298.695s
[2K
| Adam | epoch: 001 | loss: 0.71719 - acc: 0.6113 | val_loss: 0.75336 - val_acc: 0.5400 -- iter: 317/317
--
Training Step: 11  | total loss: [1m[32m0.57645[0m[0m | time: 13.335s
[2K
| Adam | epoch: 002 | loss: 0.57645 - acc: 0.6974 -- iter: 032/317
[A[ATraining Step: 12  | total loss: [1m[32m0.52361[0m[0m | time: 40.184s
[2K
| Adam | epoch: 002 | loss: 0.52361 - acc: 0.7405 -- iter: 064/317
[A[ATraining Step: 13  | total loss: [1m[32m0.49588[0m[0m | time: 61.709s
[2K
| Adam | epoch: 002 | loss: 0.49588 - acc: 0.7446 -- iter: 096/317
[A[ATraining Step: 14  | total loss: [1m[32m0.42473[0m[0m | time: 90.341s
[2K
| Adam | epoch: 002 | loss: 0.42473 - acc: 0.7979 -- iter: 128/317
[A[ATraining Step: 15  | total loss: [1m[32m0.41959[0m[0m | time: 101.952s
[2K
| Adam | epoch: 002 | loss: 0.41959 - acc: 0.7914 -- iter: 160/317
[A[ATraining Step: 16  | total loss: [1m[32m0.44088[0m[0m | time: 113.871s
[2K
| Adam | epoch: 002 | loss: 0.44088 - acc: 0.7524 -- iter: 192/317
[A[ATraining Step: 17  | total loss: [1m[32m0.39416[0m[0m | time: 132.925s
[2K
| Adam | epoch: 002 | loss: 0.39416 - acc: 0.7853 -- iter: 224/317
[A[ATraining Step: 18  | total loss: [1m[32m0.35539[0m[0m | time: 176.857s
[2K
| Adam | epoch: 002 | loss: 0.35539 - acc: 0.8164 -- iter: 256/317
[A[ATraining Step: 19  | total loss: [1m[32m0.37390[0m[0m | time: 193.522s
[2K
| Adam | epoch: 002 | loss: 0.37390 - acc: 0.8047 -- iter: 288/317
[A[ATraining Step: 20  | total loss: [1m[32m0.31831[0m[0m | time: 210.390s
[2K
| Adam | epoch: 002 | loss: 0.31831 - acc: 0.8674 | val_loss: 0.95406 - val_acc: 0.5400 -- iter: 317/317
--
Training Step: 21  | total loss: [1m[32m0.31468[0m[0m | time: 10.836s
[2K
| Adam | epoch: 003 | loss: 0.31468 - acc: 0.8601 -- iter: 032/317
[A[ATraining Step: 22  | total loss: [1m[32m0.30554[0m[0m | time: 18.399s
[2K
| Adam | epoch: 003 | loss: 0.30554 - acc: 0.8503 -- iter: 064/317
[A[ATraining Step: 23  | total loss: [1m[32m0.26494[0m[0m | time: 26.467s
[2K
| Adam | epoch: 003 | loss: 0.26494 - acc: 0.8738 -- iter: 096/317
[A[ATraining Step: 24  | total loss: [1m[32m0.21558[0m[0m | time: 34.381s
[2K
| Adam | epoch: 003 | loss: 0.21558 - acc: 0.9093 -- iter: 128/317
[A[ATraining Step: 25  | total loss: [1m[32m0.18273[0m[0m | time: 42.287s
[2K
| Adam | epoch: 003 | loss: 0.18273 - acc: 0.9340 -- iter: 160/317
[A[ATraining Step: 26  | total loss: [1m[32m0.16690[0m[0m | time: 50.215s
[2K
| Adam | epoch: 003 | loss: 0.16690 - acc: 0.9432 -- iter: 192/317
[A[ATraining Step: 27  | total loss: [1m[32m0.13161[0m[0m | time: 58.289s
[2K
| Adam | epoch: 003 | loss: 0.13161 - acc: 0.9578 -- iter: 224/317
[A[ATraining Step: 28  | total loss: [1m[32m0.13694[0m[0m | time: 66.201s
[2K
| Adam | epoch: 003 | loss: 0.13694 - acc: 0.9527 -- iter: 256/317
[A[ATraining Step: 29  | total loss: [1m[32m0.14060[0m[0m | time: 74.226s
[2K
| Adam | epoch: 003 | loss: 0.14060 - acc: 0.9490 -- iter: 288/317
[A[ATraining Step: 30  | total loss: [1m[32m0.14919[0m[0m | time: 86.836s
[2K
| Adam | epoch: 003 | loss: 0.14919 - acc: 0.9463 | val_loss: 1.59018 - val_acc: 0.5400 -- iter: 317/317
--
Training Step: 31  | total loss: [1m[32m0.19209[0m[0m | time: 8.075s
[2K
| Adam | epoch: 004 | loss: 0.19209 - acc: 0.9298 -- iter: 032/317
[A[ATraining Step: 32  | total loss: [1m[32m0.16113[0m[0m | time: 15.755s
[2K
| Adam | epoch: 004 | loss: 0.16113 - acc: 0.9456 -- iter: 064/317
[A[ATraining Step: 33  | total loss: [1m[32m0.14370[0m[0m | time: 23.246s
[2K
| Adam | epoch: 004 | loss: 0.14370 - acc: 0.9500 -- iter: 096/317
[A[ATraining Step: 34  | total loss: [1m[32m0.15166[0m[0m | time: 31.545s
[2K
| Adam | epoch: 004 | loss: 0.15166 - acc: 0.9385 -- iter: 128/317
[A[ATraining Step: 35  | total loss: [1m[32m0.15002[0m[0m | time: 39.570s
[2K
| Adam | epoch: 004 | loss: 0.15002 - acc: 0.9383 -- iter: 160/317
[A[ATraining Step: 36  | total loss: [1m[32m0.12485[0m[0m | time: 47.816s
[2K
| Adam | epoch: 004 | loss: 0.12485 - acc: 0.9509 -- iter: 192/317
[A[ATraining Step: 37  | total loss: [1m[32m0.11827[0m[0m | time: 55.893s
[2K
| Adam | epoch: 004 | loss: 0.11827 - acc: 0.9483 -- iter: 224/317
[A[ATraining Step: 38  | total loss: [1m[32m0.10948[0m[0m | time: 64.102s
[2K
| Adam | epoch: 004 | loss: 0.10948 - acc: 0.9523 -- iter: 256/317
[A[ATraining Step: 39  | total loss: [1m[32m0.11705[0m[0m | time: 72.210s
[2K
| Adam | epoch: 004 | loss: 0.11705 - acc: 0.9494 -- iter: 288/317
[A[ATraining Step: 40  | total loss: [1m[32m0.14400[0m[0m | time: 84.623s
[2K
| Adam | epoch: 004 | loss: 0.14400 - acc: 0.9472 | val_loss: 1.27126 - val_acc: 0.5400 -- iter: 317/317
--
Training Step: 41  | total loss: [1m[32m0.12571[0m[0m | time: 7.822s
[2K
| Adam | epoch: 005 | loss: 0.12571 - acc: 0.9569 -- iter: 032/317
[A[ATraining Step: 42  | total loss: [1m[32m0.11685[0m[0m | time: 15.751s
[2K
| Adam | epoch: 005 | loss: 0.11685 - acc: 0.9590 -- iter: 064/317
[A[ATraining Step: 43  | total loss: [1m[32m0.11996[0m[0m | time: 23.118s
[2K
| Adam | epoch: 005 | loss: 0.11996 - acc: 0.9552 -- iter: 096/317
[A[ATraining Step: 44  | total loss: [1m[32m0.14971[0m[0m | time: 30.615s
[2K
| Adam | epoch: 005 | loss: 0.14971 - acc: 0.9451 -- iter: 128/317
[A[ATraining Step: 45  | total loss: [1m[32m0.19646[0m[0m | time: 38.424s
[2K
| Adam | epoch: 005 | loss: 0.19646 - acc: 0.9427 -- iter: 160/317
[A[ATraining Step: 46  | total loss: [1m[32m0.20833[0m[0m | time: 46.506s
[2K
| Adam | epoch: 005 | loss: 0.20833 - acc: 0.9366 -- iter: 192/317
[A[ATraining Step: 47  | total loss: [1m[32m0.18484[0m[0m | time: 54.299s
[2K
| Adam | epoch: 005 | loss: 0.18484 - acc: 0.9419 -- iter: 224/317
[A[ATraining Step: 48  | total loss: [1m[32m0.17855[0m[0m | time: 62.353s
[2K
| Adam | epoch: 005 | loss: 0.17855 - acc: 0.9412 -- iter: 256/317
[A[ATraining Step: 49  | total loss: [1m[32m0.16238[0m[0m | time: 70.348s
[2K
| Adam | epoch: 005 | loss: 0.16238 - acc: 0.9455 -- iter: 288/317
[A[ATraining Step: 50  | total loss: [1m[32m0.16437[0m[0m | time: 83.006s
[2K
| Adam | epoch: 005 | loss: 0.16437 - acc: 0.9394 | val_loss: 2.28444 - val_acc: 0.4800 -- iter: 317/317
--
Training Step: 51  | total loss: [1m[32m0.16274[0m[0m | time: 8.169s
[2K
| Adam | epoch: 006 | loss: 0.16274 - acc: 0.9439 -- iter: 032/317
[A[ATraining Step: 52  | total loss: [1m[32m0.16800[0m[0m | time: 16.047s
[2K
| Adam | epoch: 006 | loss: 0.16800 - acc: 0.9383 -- iter: 064/317
[A[ATraining Step: 53  | total loss: [1m[32m0.16141[0m[0m | time: 24.091s
[2K
| Adam | epoch: 006 | loss: 0.16141 - acc: 0.9381 -- iter: 096/317
[A[ATraining Step: 54  | total loss: [1m[32m0.16279[0m[0m | time: 31.616s
[2K
| Adam | epoch: 006 | loss: 0.16279 - acc: 0.9381 -- iter: 128/317
[A[ATraining Step: 55  | total loss: [1m[32m0.16626[0m[0m | time: 39.091s
[2K
| Adam | epoch: 006 | loss: 0.16626 - acc: 0.9321 -- iter: 160/317
[A[ATraining Step: 56  | total loss: [1m[32m0.16893[0m[0m | time: 46.821s
[2K
| Adam | epoch: 006 | loss: 0.16893 - acc: 0.9368 -- iter: 192/317
[A[ATraining Step: 57  | total loss: [1m[32m0.15439[0m[0m | time: 54.857s
[2K
| Adam | epoch: 006 | loss: 0.15439 - acc: 0.9412 -- iter: 224/317
[A[ATraining Step: 58  | total loss: [1m[32m0.17502[0m[0m | time: 62.685s
[2K
| Adam | epoch: 006 | loss: 0.17502 - acc: 0.9365 -- iter: 256/317
[A[ATraining Step: 59  | total loss: [1m[32m0.17549[0m[0m | time: 70.717s
[2K
| Adam | epoch: 006 | loss: 0.17549 - acc: 0.9408 -- iter: 288/317
[A[ATraining Step: 60  | total loss: [1m[32m0.16756[0m[0m | time: 83.104s
[2K
| Adam | epoch: 006 | loss: 0.16756 - acc: 0.9404 | val_loss: 2.51209 - val_acc: 0.5700 -- iter: 317/317
--
Training Step: 61  | total loss: [1m[32m0.15869[0m[0m | time: 8.002s
[2K
| Adam | epoch: 007 | loss: 0.15869 - acc: 0.9441 -- iter: 032/317
[A[ATraining Step: 62  | total loss: [1m[32m0.16528[0m[0m | time: 16.088s
[2K
| Adam | epoch: 007 | loss: 0.16528 - acc: 0.9432 -- iter: 064/317
[A[ATraining Step: 63  | total loss: [1m[32m0.15698[0m[0m | time: 24.148s
[2K
| Adam | epoch: 007 | loss: 0.15698 - acc: 0.9465 -- iter: 096/317
[A[ATraining Step: 64  | total loss: [1m[32m0.14386[0m[0m | time: 32.219s
[2K
| Adam | epoch: 007 | loss: 0.14386 - acc: 0.9492 -- iter: 128/317
[A[ATraining Step: 65  | total loss: [1m[32m0.13686[0m[0m | time: 39.647s
[2K
| Adam | epoch: 007 | loss: 0.13686 - acc: 0.9517 -- iter: 160/317
[A[ATraining Step: 66  | total loss: [1m[32m0.12459[0m[0m | time: 46.930s
[2K
| Adam | epoch: 007 | loss: 0.12459 - acc: 0.9533 -- iter: 192/317
[A[ATraining Step: 67  | total loss: [1m[32m0.11266[0m[0m | time: 55.009s
[2K
| Adam | epoch: 007 | loss: 0.11266 - acc: 0.9589 -- iter: 224/317
[A[ATraining Step: 68  | total loss: [1m[32m0.10580[0m[0m | time: 62.872s
[2K
| Adam | epoch: 007 | loss: 0.10580 - acc: 0.9601 -- iter: 256/317
[A[ATraining Step: 69  | total loss: [1m[32m0.11664[0m[0m | time: 70.817s
[2K
| Adam | epoch: 007 | loss: 0.11664 - acc: 0.9538 -- iter: 288/317
[A[ATraining Step: 70  | total loss: [1m[32m0.10936[0m[0m | time: 83.251s
[2K
| Adam | epoch: 007 | loss: 0.10936 - acc: 0.9555 | val_loss: 2.29076 - val_acc: 0.5800 -- iter: 317/317
--
Training Step: 71  | total loss: [1m[32m0.11583[0m[0m | time: 8.106s
[2K
| Adam | epoch: 008 | loss: 0.11583 - acc: 0.9570 -- iter: 032/317
[A[ATraining Step: 72  | total loss: [1m[32m0.10792[0m[0m | time: 15.927s
[2K
| Adam | epoch: 008 | loss: 0.10792 - acc: 0.9619 -- iter: 064/317
[A[ATraining Step: 73  | total loss: [1m[32m0.10660[0m[0m | time: 23.942s
[2K
| Adam | epoch: 008 | loss: 0.10660 - acc: 0.9592 -- iter: 096/317
[A[ATraining Step: 74  | total loss: [1m[32m0.10415[0m[0m | time: 32.011s
[2K
| Adam | epoch: 008 | loss: 0.10415 - acc: 0.9602 -- iter: 128/317
[A[ATraining Step: 75  | total loss: [1m[32m0.11076[0m[0m | time: 40.102s
[2K
| Adam | epoch: 008 | loss: 0.11076 - acc: 0.9611 -- iter: 160/317
[A[ATraining Step: 76  | total loss: [1m[32m0.10131[0m[0m | time: 47.692s
[2K
| Adam | epoch: 008 | loss: 0.10131 - acc: 0.9653 -- iter: 192/317
[A[ATraining Step: 77  | total loss: [1m[32m0.09362[0m[0m | time: 55.208s
[2K
| Adam | epoch: 008 | loss: 0.09362 - acc: 0.9690 -- iter: 224/317
[A[ATraining Step: 78  | total loss: [1m[32m0.11505[0m[0m | time: 63.096s
[2K
| Adam | epoch: 008 | loss: 0.11505 - acc: 0.9686 -- iter: 256/317
[A[ATraining Step: 79  | total loss: [1m[32m0.11237[0m[0m | time: 71.039s
[2K
| Adam | epoch: 008 | loss: 0.11237 - acc: 0.9686 -- iter: 288/317
[A[ATraining Step: 80  | total loss: [1m[32m0.10253[0m[0m | time: 83.365s
[2K
| Adam | epoch: 008 | loss: 0.10253 - acc: 0.9718 | val_loss: 3.79269 - val_acc: 0.5600 -- iter: 317/317
--
Training Step: 81  | total loss: [1m[32m0.10849[0m[0m | time: 7.768s
[2K
| Adam | epoch: 009 | loss: 0.10849 - acc: 0.9684 -- iter: 032/317
[A[ATraining Step: 82  | total loss: [1m[32m0.11787[0m[0m | time: 15.823s
[2K
| Adam | epoch: 009 | loss: 0.11787 - acc: 0.9622 -- iter: 064/317
[A[ATraining Step: 83  | total loss: [1m[32m0.13305[0m[0m | time: 23.737s
[2K
| Adam | epoch: 009 | loss: 0.13305 - acc: 0.9534 -- iter: 096/317
[A[ATraining Step: 84  | total loss: [1m[32m0.12422[0m[0m | time: 31.592s
[2K
| Adam | epoch: 009 | loss: 0.12422 - acc: 0.9550 -- iter: 128/317
[A[ATraining Step: 85  | total loss: [1m[32m0.11284[0m[0m | time: 39.558s
[2K
| Adam | epoch: 009 | loss: 0.11284 - acc: 0.9595 -- iter: 160/317
[A[ATraining Step: 86  | total loss: [1m[32m0.10520[0m[0m | time: 47.400s
[2K
| Adam | epoch: 009 | loss: 0.10520 - acc: 0.9604 -- iter: 192/317
[A[ATraining Step: 87  | total loss: [1m[32m0.09963[0m[0m | time: 54.782s
[2K
| Adam | epoch: 009 | loss: 0.09963 - acc: 0.9644 -- iter: 224/317
[A[ATraining Step: 88  | total loss: [1m[32m0.09703[0m[0m | time: 62.284s
[2K
| Adam | epoch: 009 | loss: 0.09703 - acc: 0.9645 -- iter: 256/317
[A[ATraining Step: 89  | total loss: [1m[32m0.11272[0m[0m | time: 70.310s
[2K
| Adam | epoch: 009 | loss: 0.11272 - acc: 0.9611 -- iter: 288/317
[A[ATraining Step: 90  | total loss: [1m[32m0.10679[0m[0m | time: 82.800s
[2K
| Adam | epoch: 009 | loss: 0.10679 - acc: 0.9619 | val_loss: 2.56561 - val_acc: 0.6100 -- iter: 317/317
--
Training Step: 91  | total loss: [1m[32m0.11189[0m[0m | time: 8.170s
[2K
| Adam | epoch: 010 | loss: 0.11189 - acc: 0.9626 -- iter: 032/317
[A[ATraining Step: 92  | total loss: [1m[32m0.11475[0m[0m | time: 16.068s
[2K
| Adam | epoch: 010 | loss: 0.11475 - acc: 0.9632 -- iter: 064/317
[A[ATraining Step: 93  | total loss: [1m[32m0.10723[0m[0m | time: 24.025s
[2K
| Adam | epoch: 010 | loss: 0.10723 - acc: 0.9669 -- iter: 096/317
[A[ATraining Step: 94  | total loss: [1m[32m0.11571[0m[0m | time: 31.965s
[2K
| Adam | epoch: 010 | loss: 0.11571 - acc: 0.9608 -- iter: 128/317
[A[ATraining Step: 95  | total loss: [1m[32m0.12165[0m[0m | time: 40.003s
[2K
| Adam | epoch: 010 | loss: 0.12165 - acc: 0.9585 -- iter: 160/317
[A[ATraining Step: 96  | total loss: [1m[32m0.11227[0m[0m | time: 48.058s
[2K
| Adam | epoch: 010 | loss: 0.11227 - acc: 0.9626 -- iter: 192/317
[A[ATraining Step: 97  | total loss: [1m[32m0.10668[0m[0m | time: 55.948s
[2K
| Adam | epoch: 010 | loss: 0.10668 - acc: 0.9632 -- iter: 224/317
[A[ATraining Step: 98  | total loss: [1m[32m0.09994[0m[0m | time: 63.465s
[2K
| Adam | epoch: 010 | loss: 0.09994 - acc: 0.9638 -- iter: 256/317
[A[ATraining Step: 99  | total loss: [1m[32m0.09153[0m[0m | time: 71.095s
[2K
| Adam | epoch: 010 | loss: 0.09153 - acc: 0.9674 -- iter: 288/317
[A[ATraining Step: 100  | total loss: [1m[32m0.09724[0m[0m | time: 83.477s
[2K
| Adam | epoch: 010 | loss: 0.09724 - acc: 0.9672 | val_loss: 1.58911 - val_acc: 0.6500 -- iter: 317/317
--
Training Step: 101  | total loss: [1m[32m0.09988[0m[0m | time: 8.165s
[2K
| Adam | epoch: 011 | loss: 0.09988 - acc: 0.9643 -- iter: 032/317
[A[ATraining Step: 102  | total loss: [1m[32m0.09210[0m[0m | time: 16.163s
[2K
| Adam | epoch: 011 | loss: 0.09210 - acc: 0.9678 -- iter: 064/317
[A[ATraining Step: 103  | total loss: [1m[32m0.09434[0m[0m | time: 24.208s
[2K
| Adam | epoch: 011 | loss: 0.09434 - acc: 0.9679 -- iter: 096/317
[A[ATraining Step: 104  | total loss: [1m[32m0.08599[0m[0m | time: 32.119s
[2K
| Adam | epoch: 011 | loss: 0.08599 - acc: 0.9711 -- iter: 128/317
[A[ATraining Step: 105  | total loss: [1m[32m0.07897[0m[0m | time: 39.960s
[2K
| Adam | epoch: 011 | loss: 0.07897 - acc: 0.9740 -- iter: 160/317
[A[ATraining Step: 106  | total loss: [1m[32m0.07570[0m[0m | time: 47.931s
[2K
| Adam | epoch: 011 | loss: 0.07570 - acc: 0.9766 -- iter: 192/317
[A[ATraining Step: 107  | total loss: [1m[32m0.09837[0m[0m | time: 55.786s
[2K
| Adam | epoch: 011 | loss: 0.09837 - acc: 0.9758 -- iter: 224/317
[A[ATraining Step: 108  | total loss: [1m[32m0.09285[0m[0m | time: 63.737s
[2K
| Adam | epoch: 011 | loss: 0.09285 - acc: 0.9782 -- iter: 256/317
[A[ATraining Step: 109  | total loss: [1m[32m0.08531[0m[0m | time: 71.240s
[2K
| Adam | epoch: 011 | loss: 0.08531 - acc: 0.9804 -- iter: 288/317
[A[ATraining Step: 110  | total loss: [1m[32m0.07836[0m[0m | time: 83.142s
[2K
| Adam | epoch: 011 | loss: 0.07836 - acc: 0.9824 | val_loss: 4.68040 - val_acc: 0.4600 -- iter: 317/317
--
Training Step: 111  | total loss: [1m[32m0.12537[0m[0m | time: 8.139s
[2K
| Adam | epoch: 012 | loss: 0.12537 - acc: 0.9738 -- iter: 032/317
[A[ATraining Step: 112  | total loss: [1m[32m0.11652[0m[0m | time: 16.122s
[2K
| Adam | epoch: 012 | loss: 0.11652 - acc: 0.9764 -- iter: 064/317
[A[ATraining Step: 113  | total loss: [1m[32m0.10910[0m[0m | time: 24.068s
[2K
| Adam | epoch: 012 | loss: 0.10910 - acc: 0.9756 -- iter: 096/317
[A[ATraining Step: 114  | total loss: [1m[32m0.10039[0m[0m | time: 31.972s
[2K
| Adam | epoch: 012 | loss: 0.10039 - acc: 0.9781 -- iter: 128/317
[A[ATraining Step: 115  | total loss: [1m[32m0.11029[0m[0m | time: 39.782s
[2K
| Adam | epoch: 012 | loss: 0.11029 - acc: 0.9709 -- iter: 160/317
[A[ATraining Step: 116  | total loss: [1m[32m0.11281[0m[0m | time: 47.800s
[2K
| Adam | epoch: 012 | loss: 0.11281 - acc: 0.9676 -- iter: 192/317
[A[ATraining Step: 117  | total loss: [1m[32m0.10835[0m[0m | time: 55.653s
[2K
| Adam | epoch: 012 | loss: 0.10835 - acc: 0.9646 -- iter: 224/317
[A[ATraining Step: 118  | total loss: [1m[32m0.10342[0m[0m | time: 63.801s
[2K
| Adam | epoch: 012 | loss: 0.10342 - acc: 0.9650 -- iter: 256/317
[A[ATraining Step: 119  | total loss: [1m[32m0.10192[0m[0m | time: 71.840s
[2K
| Adam | epoch: 012 | loss: 0.10192 - acc: 0.9654 -- iter: 288/317
[A[ATraining Step: 120  | total loss: [1m[32m0.09290[0m[0m | time: 83.949s
[2K
| Adam | epoch: 012 | loss: 0.09290 - acc: 0.9688 | val_loss: 1.07726 - val_acc: 0.6200 -- iter: 317/317
--
Training Step: 121  | total loss: [1m[32m0.08650[0m[0m | time: 7.495s
[2K
| Adam | epoch: 013 | loss: 0.08650 - acc: 0.9719 -- iter: 032/317
[A[ATraining Step: 122  | total loss: [1m[32m0.13823[0m[0m | time: 15.231s
[2K
| Adam | epoch: 013 | loss: 0.13823 - acc: 0.9678 -- iter: 064/317
[A[ATraining Step: 123  | total loss: [1m[32m0.12901[0m[0m | time: 23.292s
[2K
| Adam | epoch: 013 | loss: 0.12901 - acc: 0.9711 -- iter: 096/317
[A[ATraining Step: 124  | total loss: [1m[32m0.12179[0m[0m | time: 31.204s
[2K
| Adam | epoch: 013 | loss: 0.12179 - acc: 0.9708 -- iter: 128/317
[A[ATraining Step: 125  | total loss: [1m[32m0.11341[0m[0m | time: 39.278s
[2K
| Adam | epoch: 013 | loss: 0.11341 - acc: 0.9737 -- iter: 160/317
[A[ATraining Step: 126  | total loss: [1m[32m0.11727[0m[0m | time: 47.418s
[2K
| Adam | epoch: 013 | loss: 0.11727 - acc: 0.9701 -- iter: 192/317
[A[ATraining Step: 127  | total loss: [1m[32m0.12302[0m[0m | time: 55.212s
[2K
| Adam | epoch: 013 | loss: 0.12302 - acc: 0.9669 -- iter: 224/317
[A[ATraining Step: 128  | total loss: [1m[32m0.11928[0m[0m | time: 63.124s
[2K
| Adam | epoch: 013 | loss: 0.11928 - acc: 0.9670 -- iter: 256/317
[A[ATraining Step: 129  | total loss: [1m[32m0.11037[0m[0m | time: 70.844s
[2K
| Adam | epoch: 013 | loss: 0.11037 - acc: 0.9703 -- iter: 288/317
[A[ATraining Step: 130  | total loss: [1m[32m0.10317[0m[0m | time: 83.286s
[2K
| Adam | epoch: 013 | loss: 0.10317 - acc: 0.9733 | val_loss: 1.34149 - val_acc: 0.6100 -- iter: 317/317
--
Training Step: 131  | total loss: [1m[32m0.09531[0m[0m | time: 7.725s
[2K
| Adam | epoch: 014 | loss: 0.09531 - acc: 0.9760 -- iter: 032/317
[A[ATraining Step: 132  | total loss: [1m[32m0.10957[0m[0m | time: 15.147s
[2K
| Adam | epoch: 014 | loss: 0.10957 - acc: 0.9749 -- iter: 064/317
[A[ATraining Step: 133  | total loss: [1m[32m0.14718[0m[0m | time: 23.194s
[2K
| Adam | epoch: 014 | loss: 0.14718 - acc: 0.9636 -- iter: 096/317
[A[ATraining Step: 134  | total loss: [1m[32m0.13937[0m[0m | time: 30.998s
[2K
| Adam | epoch: 014 | loss: 0.13937 - acc: 0.9642 -- iter: 128/317
[A[ATraining Step: 135  | total loss: [1m[32m0.13299[0m[0m | time: 39.019s
[2K
| Adam | epoch: 014 | loss: 0.13299 - acc: 0.9646 -- iter: 160/317
[A[ATraining Step: 136  | total loss: [1m[32m0.14130[0m[0m | time: 46.891s
[2K
| Adam | epoch: 014 | loss: 0.14130 - acc: 0.9650 -- iter: 192/317
[A[ATraining Step: 137  | total loss: [1m[32m0.12794[0m[0m | time: 55.007s
[2K
| Adam | epoch: 014 | loss: 0.12794 - acc: 0.9685 -- iter: 224/317
[A[ATraining Step: 138  | total loss: [1m[32m0.11787[0m[0m | time: 62.990s
[2K
| Adam | epoch: 014 | loss: 0.11787 - acc: 0.9717 -- iter: 256/317
[A[ATraining Step: 139  | total loss: [1m[32m0.11529[0m[0m | time: 70.887s
[2K
| Adam | epoch: 014 | loss: 0.11529 - acc: 0.9714 -- iter: 288/317
[A[ATraining Step: 140  | total loss: [1m[32m0.10783[0m[0m | time: 83.192s
[2K
| Adam | epoch: 014 | loss: 0.10783 - acc: 0.9742 | val_loss: 1.09509 - val_acc: 0.7100 -- iter: 317/317
--
Training Step: 141  | total loss: [1m[32m0.09954[0m[0m | time: 8.189s
[2K
| Adam | epoch: 015 | loss: 0.09954 - acc: 0.9768 -- iter: 032/317
[A[ATraining Step: 142  | total loss: [1m[32m0.09123[0m[0m | time: 15.573s
[2K
| Adam | epoch: 015 | loss: 0.09123 - acc: 0.9791 -- iter: 064/317
[A[ATraining Step: 143  | total loss: [1m[32m0.08532[0m[0m | time: 23.016s
[2K
| Adam | epoch: 015 | loss: 0.08532 - acc: 0.9812 -- iter: 096/317
[A[ATraining Step: 144  | total loss: [1m[32m0.10244[0m[0m | time: 30.990s
[2K
| Adam | epoch: 015 | loss: 0.10244 - acc: 0.9797 -- iter: 128/317
[A[ATraining Step: 145  | total loss: [1m[32m0.09442[0m[0m | time: 38.989s
[2K
| Adam | epoch: 015 | loss: 0.09442 - acc: 0.9817 -- iter: 160/317
[A[ATraining Step: 146  | total loss: [1m[32m0.09937[0m[0m | time: 46.901s
[2K
| Adam | epoch: 015 | loss: 0.09937 - acc: 0.9804 -- iter: 192/317
[A[ATraining Step: 147  | total loss: [1m[32m0.09301[0m[0m | time: 54.741s
[2K
| Adam | epoch: 015 | loss: 0.09301 - acc: 0.9824 -- iter: 224/317
[A[ATraining Step: 148  | total loss: [1m[32m0.08982[0m[0m | time: 62.717s
[2K
| Adam | epoch: 015 | loss: 0.08982 - acc: 0.9779 -- iter: 256/317
[A[ATraining Step: 149  | total loss: [1m[32m0.08241[0m[0m | time: 70.675s
[2K
| Adam | epoch: 015 | loss: 0.08241 - acc: 0.9801 -- iter: 288/317
[A[ATraining Step: 150  | total loss: [1m[32m0.07668[0m[0m | time: 83.254s
[2K
| Adam | epoch: 015 | loss: 0.07668 - acc: 0.9821 | val_loss: 1.63253 - val_acc: 0.6200 -- iter: 317/317
--
Training Step: 151  | total loss: [1m[32m0.07473[0m[0m | time: 7.949s
[2K
| Adam | epoch: 016 | loss: 0.07473 - acc: 0.9807 -- iter: 032/317
[A[ATraining Step: 152  | total loss: [1m[32m0.06845[0m[0m | time: 15.913s
[2K
| Adam | epoch: 016 | loss: 0.06845 - acc: 0.9827 -- iter: 064/317
[A[ATraining Step: 153  | total loss: [1m[32m0.06232[0m[0m | time: 23.504s
[2K
| Adam | epoch: 016 | loss: 0.06232 - acc: 0.9844 -- iter: 096/317
[A[ATraining Step: 154  | total loss: [1m[32m0.05697[0m[0m | time: 30.829s
[2K
| Adam | epoch: 016 | loss: 0.05697 - acc: 0.9860 -- iter: 128/317
[A[ATraining Step: 155  | total loss: [1m[32m0.07409[0m[0m | time: 38.831s
[2K
| Adam | epoch: 016 | loss: 0.07409 - acc: 0.9839 -- iter: 160/317
[A[ATraining Step: 156  | total loss: [1m[32m0.06912[0m[0m | time: 46.815s
[2K
| Adam | epoch: 016 | loss: 0.06912 - acc: 0.9855 -- iter: 192/317
[A[ATraining Step: 157  | total loss: [1m[32m0.06799[0m[0m | time: 55.096s
[2K
| Adam | epoch: 016 | loss: 0.06799 - acc: 0.9838 -- iter: 224/317
[A[ATraining Step: 158  | total loss: [1m[32m0.06169[0m[0m | time: 63.005s
[2K
| Adam | epoch: 016 | loss: 0.06169 - acc: 0.9855 -- iter: 256/317
[A[ATraining Step: 159  | total loss: [1m[32m0.05642[0m[0m | time: 70.969s
[2K
| Adam | epoch: 016 | loss: 0.05642 - acc: 0.9869 -- iter: 288/317
[A[ATraining Step: 160  | total loss: [1m[32m0.05135[0m[0m | time: 83.294s
[2K
| Adam | epoch: 016 | loss: 0.05135 - acc: 0.9882 | val_loss: 1.09218 - val_acc: 0.7200 -- iter: 317/317
--
Training Step: 161  | total loss: [1m[32m0.04654[0m[0m | time: 7.939s
[2K
| Adam | epoch: 017 | loss: 0.04654 - acc: 0.9894 -- iter: 032/317
[A[ATraining Step: 162  | total loss: [1m[32m0.04614[0m[0m | time: 15.934s
[2K
| Adam | epoch: 017 | loss: 0.04614 - acc: 0.9905 -- iter: 064/317
[A[ATraining Step: 163  | total loss: [1m[32m0.04244[0m[0m | time: 23.693s
[2K
| Adam | epoch: 017 | loss: 0.04244 - acc: 0.9914 -- iter: 096/317
[A[ATraining Step: 164  | total loss: [1m[32m0.08991[0m[0m | time: 31.116s
[2K
| Adam | epoch: 017 | loss: 0.08991 - acc: 0.9891 -- iter: 128/317
[A[ATraining Step: 165  | total loss: [1m[32m0.08905[0m[0m | time: 38.522s
[2K
| Adam | epoch: 017 | loss: 0.08905 - acc: 0.9868 -- iter: 160/317
[A[ATraining Step: 166  | total loss: [1m[32m0.10036[0m[0m | time: 46.339s
[2K
| Adam | epoch: 017 | loss: 0.10036 - acc: 0.9847 -- iter: 192/317
[A[ATraining Step: 167  | total loss: [1m[32m0.09203[0m[0m | time: 54.100s
[2K
| Adam | epoch: 017 | loss: 0.09203 - acc: 0.9862 -- iter: 224/317
[A[ATraining Step: 168  | total loss: [1m[32m0.10260[0m[0m | time: 62.155s
[2K
| Adam | epoch: 017 | loss: 0.10260 - acc: 0.9844 -- iter: 256/317
[A[ATraining Step: 169  | total loss: [1m[32m0.09312[0m[0m | time: 69.914s
[2K
| Adam | epoch: 017 | loss: 0.09312 - acc: 0.9860 -- iter: 288/317
[A[ATraining Step: 170  | total loss: [1m[32m0.08679[0m[0m | time: 82.324s
[2K
| Adam | epoch: 017 | loss: 0.08679 - acc: 0.9874 | val_loss: 9.52998 - val_acc: 0.4600 -- iter: 317/317
--
Training Step: 171  | total loss: [1m[32m0.08098[0m[0m | time: 8.160s
[2K
| Adam | epoch: 018 | loss: 0.08098 - acc: 0.9887 -- iter: 032/317
[A[ATraining Step: 172  | total loss: [1m[32m0.07609[0m[0m | time: 15.898s
[2K
| Adam | epoch: 018 | loss: 0.07609 - acc: 0.9898 -- iter: 064/317
[A[ATraining Step: 173  | total loss: [1m[32m0.06914[0m[0m | time: 23.817s
[2K
| Adam | epoch: 018 | loss: 0.06914 - acc: 0.9908 -- iter: 096/317
[A[ATraining Step: 174  | total loss: [1m[32m0.06522[0m[0m | time: 31.855s
[2K
| Adam | epoch: 018 | loss: 0.06522 - acc: 0.9917 -- iter: 128/317
[A[ATraining Step: 175  | total loss: [1m[32m0.06977[0m[0m | time: 39.340s
[2K
| Adam | epoch: 018 | loss: 0.06977 - acc: 0.9863 -- iter: 160/317
[A[ATraining Step: 176  | total loss: [1m[32m0.06506[0m[0m | time: 46.705s
[2K
| Adam | epoch: 018 | loss: 0.06506 - acc: 0.9877 -- iter: 192/317
[A[ATraining Step: 177  | total loss: [1m[32m0.06089[0m[0m | time: 54.728s
[2K
| Adam | epoch: 018 | loss: 0.06089 - acc: 0.9889 -- iter: 224/317
[A[ATraining Step: 178  | total loss: [1m[32m0.05555[0m[0m | time: 62.654s
[2K
| Adam | epoch: 018 | loss: 0.05555 - acc: 0.9900 -- iter: 256/317
[A[ATraining Step: 179  | total loss: [1m[32m0.05143[0m[0m | time: 70.526s
[2K
| Adam | epoch: 018 | loss: 0.05143 - acc: 0.9910 -- iter: 288/317
[A[ATraining Step: 180  | total loss: [1m[32m0.04720[0m[0m | time: 83.043s
[2K
| Adam | epoch: 018 | loss: 0.04720 - acc: 0.9919 | val_loss: 2.67734 - val_acc: 0.5700 -- iter: 317/317
--
Training Step: 181  | total loss: [1m[32m0.05036[0m[0m | time: 7.874s
[2K
| Adam | epoch: 019 | loss: 0.05036 - acc: 0.9896 -- iter: 032/317
[A[ATraining Step: 182  | total loss: [1m[32m0.04618[0m[0m | time: 15.697s
[2K
| Adam | epoch: 019 | loss: 0.04618 - acc: 0.9906 -- iter: 064/317
[A[ATraining Step: 183  | total loss: [1m[32m0.04981[0m[0m | time: 23.633s
[2K
| Adam | epoch: 019 | loss: 0.04981 - acc: 0.9853 -- iter: 096/317
[A[ATraining Step: 184  | total loss: [1m[32m0.04583[0m[0m | time: 31.393s
[2K
| Adam | epoch: 019 | loss: 0.04583 - acc: 0.9868 -- iter: 128/317
[A[ATraining Step: 185  | total loss: [1m[32m0.04193[0m[0m | time: 39.369s
[2K
| Adam | epoch: 019 | loss: 0.04193 - acc: 0.9881 -- iter: 160/317
[A[ATraining Step: 186  | total loss: [1m[32m0.04096[0m[0m | time: 46.558s
[2K
| Adam | epoch: 019 | loss: 0.04096 - acc: 0.9893 -- iter: 192/317
[A[ATraining Step: 187  | total loss: [1m[32m0.03763[0m[0m | time: 54.118s
[2K
| Adam | epoch: 019 | loss: 0.03763 - acc: 0.9904 -- iter: 224/317
[A[ATraining Step: 188  | total loss: [1m[32m0.03458[0m[0m | time: 61.961s
[2K
| Adam | epoch: 019 | loss: 0.03458 - acc: 0.9913 -- iter: 256/317
[A[ATraining Step: 189  | total loss: [1m[32m0.03143[0m[0m | time: 69.964s
[2K
| Adam | epoch: 019 | loss: 0.03143 - acc: 0.9922 -- iter: 288/317
[A[ATraining Step: 190  | total loss: [1m[32m0.03219[0m[0m | time: 82.268s
[2K
| Adam | epoch: 019 | loss: 0.03219 - acc: 0.9930 | val_loss: 0.96529 - val_acc: 0.7900 -- iter: 317/317
--
Training Step: 191  | total loss: [1m[32m0.03003[0m[0m | time: 7.900s
[2K
| Adam | epoch: 020 | loss: 0.03003 - acc: 0.9937 -- iter: 032/317
[A[ATraining Step: 192  | total loss: [1m[32m0.02770[0m[0m | time: 15.845s
[2K
| Adam | epoch: 020 | loss: 0.02770 - acc: 0.9943 -- iter: 064/317
[A[ATraining Step: 193  | total loss: [1m[32m0.02556[0m[0m | time: 23.602s
[2K
| Adam | epoch: 020 | loss: 0.02556 - acc: 0.9949 -- iter: 096/317
[A[ATraining Step: 194  | total loss: [1m[32m0.02318[0m[0m | time: 31.435s
[2K
| Adam | epoch: 020 | loss: 0.02318 - acc: 0.9954 -- iter: 128/317
[A[ATraining Step: 195  | total loss: [1m[32m0.02109[0m[0m | time: 39.442s
[2K
| Adam | epoch: 020 | loss: 0.02109 - acc: 0.9959 -- iter: 160/317
[A[ATraining Step: 196  | total loss: [1m[32m0.02010[0m[0m | time: 47.275s
[2K
| Adam | epoch: 020 | loss: 0.02010 - acc: 0.9963 -- iter: 192/317
[A[ATraining Step: 197  | total loss: [1m[32m0.01832[0m[0m | time: 54.671s
[2K
| Adam | epoch: 020 | loss: 0.01832 - acc: 0.9966 -- iter: 224/317
[A[ATraining Step: 198  | total loss: [1m[32m0.01656[0m[0m | time: 62.123s
[2K
| Adam | epoch: 020 | loss: 0.01656 - acc: 0.9970 -- iter: 256/317
[A[ATraining Step: 199  | total loss: [1m[32m0.03734[0m[0m | time: 70.133s
[2K
| Adam | epoch: 020 | loss: 0.03734 - acc: 0.9938 -- iter: 288/317
[A[ATraining Step: 200  | total loss: [1m[32m0.03380[0m[0m | time: 82.425s
[2K
| Adam | epoch: 020 | loss: 0.03380 - acc: 0.9944 | val_loss: 1.44054 - val_acc: 0.7000 -- iter: 317/317
--
Training Step: 201  | total loss: [1m[32m0.03082[0m[0m | time: 7.966s
[2K
| Adam | epoch: 021 | loss: 0.03082 - acc: 0.9950 -- iter: 032/317
[A[ATraining Step: 202  | total loss: [1m[32m0.02799[0m[0m | time: 15.820s
[2K
| Adam | epoch: 021 | loss: 0.02799 - acc: 0.9955 -- iter: 064/317
[A[ATraining Step: 203  | total loss: [1m[32m0.02563[0m[0m | time: 23.803s
[2K
| Adam | epoch: 021 | loss: 0.02563 - acc: 0.9960 -- iter: 096/317
[A[ATraining Step: 204  | total loss: [1m[32m0.02360[0m[0m | time: 31.850s
[2K
| Adam | epoch: 021 | loss: 0.02360 - acc: 0.9964 -- iter: 128/317
[A[ATraining Step: 205  | total loss: [1m[32m0.02204[0m[0m | time: 39.792s
[2K
| Adam | epoch: 021 | loss: 0.02204 - acc: 0.9967 -- iter: 160/317
[A[ATraining Step: 206  | total loss: [1m[32m0.02026[0m[0m | time: 47.888s
[2K
| Adam | epoch: 021 | loss: 0.02026 - acc: 0.9971 -- iter: 192/317
[A[ATraining Step: 207  | total loss: [1m[32m0.01902[0m[0m | time: 56.080s
[2K
| Adam | epoch: 021 | loss: 0.01902 - acc: 0.9973 -- iter: 224/317
[A[ATraining Step: 208  | total loss: [1m[32m0.05018[0m[0m | time: 63.570s
[2K
| Adam | epoch: 021 | loss: 0.05018 - acc: 0.9945 -- iter: 256/317
[A[ATraining Step: 209  | total loss: [1m[32m0.04997[0m[0m | time: 71.036s
[2K
| Adam | epoch: 021 | loss: 0.04997 - acc: 0.9916 -- iter: 288/317
[A[ATraining Step: 210  | total loss: [1m[32m0.11395[0m[0m | time: 83.411s
[2K
| Adam | epoch: 021 | loss: 0.11395 - acc: 0.9855 | val_loss: 2.49388 - val_acc: 0.5300 -- iter: 317/317
--
Training Step: 211  | total loss: [1m[32m0.10280[0m[0m | time: 8.067s
[2K
| Adam | epoch: 022 | loss: 0.10280 - acc: 0.9870 -- iter: 032/317
[A[ATraining Step: 212  | total loss: [1m[32m0.09568[0m[0m | time: 15.893s
[2K
| Adam | epoch: 022 | loss: 0.09568 - acc: 0.9852 -- iter: 064/317
[A[ATraining Step: 213  | total loss: [1m[32m0.10189[0m[0m | time: 23.826s
[2K
| Adam | epoch: 022 | loss: 0.10189 - acc: 0.9835 -- iter: 096/317
[A[ATraining Step: 214  | total loss: [1m[32m0.09468[0m[0m | time: 31.787s
[2K
| Adam | epoch: 022 | loss: 0.09468 - acc: 0.9852 -- iter: 128/317
[A[ATraining Step: 215  | total loss: [1m[32m0.08746[0m[0m | time: 39.671s
[2K
| Adam | epoch: 022 | loss: 0.08746 - acc: 0.9866 -- iter: 160/317
[A[ATraining Step: 216  | total loss: [1m[32m0.07934[0m[0m | time: 47.600s
[2K
| Adam | epoch: 022 | loss: 0.07934 - acc: 0.9880 -- iter: 192/317
[A[ATraining Step: 217  | total loss: [1m[32m0.07720[0m[0m | time: 55.458s
[2K
| Adam | epoch: 022 | loss: 0.07720 - acc: 0.9861 -- iter: 224/317
[A[ATraining Step: 218  | total loss: [1m[32m0.07112[0m[0m | time: 63.303s
[2K
| Adam | epoch: 022 | loss: 0.07112 - acc: 0.9875 -- iter: 256/317
[A[ATraining Step: 219  | total loss: [1m[32m0.06483[0m[0m | time: 70.826s
[2K
| Adam | epoch: 022 | loss: 0.06483 - acc: 0.9887 -- iter: 288/317
[A[ATraining Step: 220  | total loss: [1m[32m0.07472[0m[0m | time: 82.627s
[2K
| Adam | epoch: 022 | loss: 0.07472 - acc: 0.9864 | val_loss: 0.60666 - val_acc: 0.8200 -- iter: 317/317
--
Training Step: 221  | total loss: [1m[32m0.09481[0m[0m | time: 8.122s
[2K
| Adam | epoch: 023 | loss: 0.09481 - acc: 0.9843 -- iter: 032/317
[A[ATraining Step: 222  | total loss: [1m[32m0.09084[0m[0m | time: 16.023s
[2K
| Adam | epoch: 023 | loss: 0.09084 - acc: 0.9827 -- iter: 064/317
[A[ATraining Step: 223  | total loss: [1m[32m0.08280[0m[0m | time: 23.735s
[2K
| Adam | epoch: 023 | loss: 0.08280 - acc: 0.9845 -- iter: 096/317
[A[ATraining Step: 224  | total loss: [1m[32m0.07912[0m[0m | time: 31.609s
[2K
| Adam | epoch: 023 | loss: 0.07912 - acc: 0.9860 -- iter: 128/317
[A[ATraining Step: 225  | total loss: [1m[32m0.07301[0m[0m | time: 39.645s
[2K
| Adam | epoch: 023 | loss: 0.07301 - acc: 0.9874 -- iter: 160/317
[A[ATraining Step: 226  | total loss: [1m[32m0.06801[0m[0m | time: 47.598s
[2K
| Adam | epoch: 023 | loss: 0.06801 - acc: 0.9887 -- iter: 192/317
[A[ATraining Step: 227  | total loss: [1m[32m0.06277[0m[0m | time: 55.553s
[2K
| Adam | epoch: 023 | loss: 0.06277 - acc: 0.9898 -- iter: 224/317
[A[ATraining Step: 228  | total loss: [1m[32m0.05757[0m[0m | time: 63.440s
[2K
| Adam | epoch: 023 | loss: 0.05757 - acc: 0.9908 -- iter: 256/317
[A[ATraining Step: 229  | total loss: [1m[32m0.09104[0m[0m | time: 71.462s
[2K
| Adam | epoch: 023 | loss: 0.09104 - acc: 0.9824 -- iter: 288/317
[A[ATraining Step: 230  | total loss: [1m[32m0.09073[0m[0m | time: 83.389s
[2K
| Adam | epoch: 023 | loss: 0.09073 - acc: 0.9810 | val_loss: 0.90367 - val_acc: 0.7400 -- iter: 317/317
--
Training Step: 231  | total loss: [1m[32m0.08490[0m[0m | time: 7.445s
[2K
| Adam | epoch: 024 | loss: 0.08490 - acc: 0.9829 -- iter: 032/317
[A[ATraining Step: 232  | total loss: [1m[32m0.09638[0m[0m | time: 15.442s
[2K
| Adam | epoch: 024 | loss: 0.09638 - acc: 0.9812 -- iter: 064/317
[A[ATraining Step: 233  | total loss: [1m[32m0.08904[0m[0m | time: 23.327s
[2K
| Adam | epoch: 024 | loss: 0.08904 - acc: 0.9831 -- iter: 096/317
[A[ATraining Step: 234  | total loss: [1m[32m0.08343[0m[0m | time: 31.404s
[2K
| Adam | epoch: 024 | loss: 0.08343 - acc: 0.9847 -- iter: 128/317
[A[ATraining Step: 235  | total loss: [1m[32m0.09204[0m[0m | time: 39.472s
[2K
| Adam | epoch: 024 | loss: 0.09204 - acc: 0.9831 -- iter: 160/317
[A[ATraining Step: 236  | total loss: [1m[32m0.08489[0m[0m | time: 47.451s
[2K
| Adam | epoch: 024 | loss: 0.08489 - acc: 0.9848 -- iter: 192/317
[A[ATraining Step: 237  | total loss: [1m[32m0.07726[0m[0m | time: 55.427s
[2K
| Adam | epoch: 024 | loss: 0.07726 - acc: 0.9863 -- iter: 224/317
[A[ATraining Step: 238  | total loss: [1m[32m0.07375[0m[0m | time: 63.244s
[2K
| Adam | epoch: 024 | loss: 0.07375 - acc: 0.9846 -- iter: 256/317
[A[ATraining Step: 239  | total loss: [1m[32m0.07320[0m[0m | time: 71.234s
[2K
| Adam | epoch: 024 | loss: 0.07320 - acc: 0.9830 -- iter: 288/317
[A[ATraining Step: 240  | total loss: [1m[32m0.06610[0m[0m | time: 83.734s
[2K
| Adam | epoch: 024 | loss: 0.06610 - acc: 0.9847 | val_loss: 1.32363 - val_acc: 0.6500 -- iter: 317/317
--
Training Step: 241  | total loss: [1m[32m0.06061[0m[0m | time: 7.515s
[2K
| Adam | epoch: 025 | loss: 0.06061 - acc: 0.9862 -- iter: 032/317
[A[ATraining Step: 242  | total loss: [1m[32m0.05585[0m[0m | time: 14.945s
[2K
| Adam | epoch: 025 | loss: 0.05585 - acc: 0.9876 -- iter: 064/317
[A[ATraining Step: 243  | total loss: [1m[32m0.07212[0m[0m | time: 22.815s
[2K
| Adam | epoch: 025 | loss: 0.07212 - acc: 0.9854 -- iter: 096/317
[A[ATraining Step: 244  | total loss: [1m[32m0.06665[0m[0m | time: 30.785s
[2K
| Adam | epoch: 025 | loss: 0.06665 - acc: 0.9869 -- iter: 128/317
[A[ATraining Step: 245  | total loss: [1m[32m0.06666[0m[0m | time: 38.825s
[2K
| Adam | epoch: 025 | loss: 0.06666 - acc: 0.9851 -- iter: 160/317
[A[ATraining Step: 246  | total loss: [1m[32m0.06072[0m[0m | time: 46.767s
[2K
| Adam | epoch: 025 | loss: 0.06072 - acc: 0.9865 -- iter: 192/317
[A[ATraining Step: 247  | total loss: [1m[32m0.05542[0m[0m | time: 54.752s
[2K
| Adam | epoch: 025 | loss: 0.05542 - acc: 0.9879 -- iter: 224/317
[A[ATraining Step: 248  | total loss: [1m[32m0.05101[0m[0m | time: 62.540s
[2K
| Adam | epoch: 025 | loss: 0.05101 - acc: 0.9891 -- iter: 256/317
[A[ATraining Step: 249  | total loss: [1m[32m0.04825[0m[0m | time: 70.456s
[2K
| Adam | epoch: 025 | loss: 0.04825 - acc: 0.9902 -- iter: 288/317
[A[ATraining Step: 250  | total loss: [1m[32m0.04383[0m[0m | time: 82.861s
[2K
| Adam | epoch: 025 | loss: 0.04383 - acc: 0.9912 | val_loss: 1.14734 - val_acc: 0.7600 -- iter: 317/317
--
Training Step: 251  | total loss: [1m[32m0.04683[0m[0m | time: 7.891s
[2K
| Adam | epoch: 026 | loss: 0.04683 - acc: 0.9889 -- iter: 032/317
[A[ATraining Step: 252  | total loss: [1m[32m0.04312[0m[0m | time: 15.211s
[2K
| Adam | epoch: 026 | loss: 0.04312 - acc: 0.9900 -- iter: 064/317
[A[ATraining Step: 253  | total loss: [1m[32m0.04015[0m[0m | time: 22.680s
[2K
| Adam | epoch: 026 | loss: 0.04015 - acc: 0.9910 -- iter: 096/317
[A[ATraining Step: 254  | total loss: [1m[32m0.04957[0m[0m | time: 30.679s
[2K
| Adam | epoch: 026 | loss: 0.04957 - acc: 0.9885 -- iter: 128/317
[A[ATraining Step: 255  | total loss: [1m[32m0.05031[0m[0m | time: 38.751s
[2K
| Adam | epoch: 026 | loss: 0.05031 - acc: 0.9865 -- iter: 160/317
[A[ATraining Step: 256  | total loss: [1m[32m0.04594[0m[0m | time: 46.666s
[2K
| Adam | epoch: 026 | loss: 0.04594 - acc: 0.9879 -- iter: 192/317
[A[ATraining Step: 257  | total loss: [1m[32m0.04995[0m[0m | time: 54.464s
[2K
| Adam | epoch: 026 | loss: 0.04995 - acc: 0.9859 -- iter: 224/317
[A[ATraining Step: 258  | total loss: [1m[32m0.06670[0m[0m | time: 62.415s
[2K
| Adam | epoch: 026 | loss: 0.06670 - acc: 0.9842 -- iter: 256/317
[A[ATraining Step: 259  | total loss: [1m[32m0.06056[0m[0m | time: 70.333s
[2K
| Adam | epoch: 026 | loss: 0.06056 - acc: 0.9858 -- iter: 288/317
[A[ATraining Step: 260  | total loss: [1m[32m0.05626[0m[0m | time: 82.752s
[2K
| Adam | epoch: 026 | loss: 0.05626 - acc: 0.9872 | val_loss: 0.87267 - val_acc: 0.6900 -- iter: 317/317
--
Training Step: 261  | total loss: [1m[32m0.05272[0m[0m | time: 7.984s
[2K
| Adam | epoch: 027 | loss: 0.05272 - acc: 0.9885 -- iter: 032/317
[A[ATraining Step: 262  | total loss: [1m[32m0.05682[0m[0m | time: 16.016s
[2K
| Adam | epoch: 027 | loss: 0.05682 - acc: 0.9865 -- iter: 064/317
[A[ATraining Step: 263  | total loss: [1m[32m0.05188[0m[0m | time: 23.577s
[2K
| Adam | epoch: 027 | loss: 0.05188 - acc: 0.9879 -- iter: 096/317
[A[ATraining Step: 264  | total loss: [1m[32m0.04760[0m[0m | time: 31.101s
[2K
| Adam | epoch: 027 | loss: 0.04760 - acc: 0.9891 -- iter: 128/317
[A[ATraining Step: 265  | total loss: [1m[32m0.07677[0m[0m | time: 38.911s
[2K
| Adam | epoch: 027 | loss: 0.07677 - acc: 0.9867 -- iter: 160/317
[A[ATraining Step: 266  | total loss: [1m[32m0.09332[0m[0m | time: 46.856s
[2K
| Adam | epoch: 027 | loss: 0.09332 - acc: 0.9787 -- iter: 192/317
[A[ATraining Step: 267  | total loss: [1m[32m0.08968[0m[0m | time: 54.712s
[2K
| Adam | epoch: 027 | loss: 0.08968 - acc: 0.9777 -- iter: 224/317
[A[ATraining Step: 268  | total loss: [1m[32m0.08218[0m[0m | time: 62.727s
[2K
| Adam | epoch: 027 | loss: 0.08218 - acc: 0.9799 -- iter: 256/317
[A[ATraining Step: 269  | total loss: [1m[32m0.08277[0m[0m | time: 70.669s
[2K
| Adam | epoch: 027 | loss: 0.08277 - acc: 0.9788 -- iter: 288/317
[A[ATraining Step: 270  | total loss: [1m[32m0.07537[0m[0m | time: 83.096s
[2K
| Adam | epoch: 027 | loss: 0.07537 - acc: 0.9809 | val_loss: 0.68234 - val_acc: 0.8100 -- iter: 317/317
--
Training Step: 271  | total loss: [1m[32m0.06873[0m[0m | time: 7.922s
[2K
| Adam | epoch: 028 | loss: 0.06873 - acc: 0.9828 -- iter: 032/317
[A[ATraining Step: 272  | total loss: [1m[32m0.06356[0m[0m | time: 15.712s
[2K
| Adam | epoch: 028 | loss: 0.06356 - acc: 0.9845 -- iter: 064/317
[A[ATraining Step: 273  | total loss: [1m[32m0.05936[0m[0m | time: 23.729s
[2K
| Adam | epoch: 028 | loss: 0.05936 - acc: 0.9861 -- iter: 096/317
[A[ATraining Step: 274  | total loss: [1m[32m0.06913[0m[0m | time: 30.936s
[2K
| Adam | epoch: 028 | loss: 0.06913 - acc: 0.9781 -- iter: 128/317
[A[ATraining Step: 275  | total loss: [1m[32m0.08759[0m[0m | time: 38.525s
[2K
| Adam | epoch: 028 | loss: 0.08759 - acc: 0.9734 -- iter: 160/317
[A[ATraining Step: 276  | total loss: [1m[32m0.12210[0m[0m | time: 46.323s
[2K
| Adam | epoch: 028 | loss: 0.12210 - acc: 0.9657 -- iter: 192/317
[A[ATraining Step: 277  | total loss: [1m[32m0.11482[0m[0m | time: 54.253s
[2K
| Adam | epoch: 028 | loss: 0.11482 - acc: 0.9691 -- iter: 224/317
[A[ATraining Step: 278  | total loss: [1m[32m0.11274[0m[0m | time: 62.160s
[2K
| Adam | epoch: 028 | loss: 0.11274 - acc: 0.9660 -- iter: 256/317
[A[ATraining Step: 279  | total loss: [1m[32m0.10831[0m[0m | time: 69.993s
[2K
| Adam | epoch: 028 | loss: 0.10831 - acc: 0.9663 -- iter: 288/317
[A[ATraining Step: 280  | total loss: [1m[32m0.10805[0m[0m | time: 82.384s
[2K
| Adam | epoch: 028 | loss: 0.10805 - acc: 0.9665 | val_loss: 1.12742 - val_acc: 0.7300 -- iter: 317/317
--
Training Step: 281  | total loss: [1m[32m0.10346[0m[0m | time: 7.994s
[2K
| Adam | epoch: 029 | loss: 0.10346 - acc: 0.9667 -- iter: 032/317
[A[ATraining Step: 282  | total loss: [1m[32m0.09916[0m[0m | time: 15.790s
[2K
| Adam | epoch: 029 | loss: 0.09916 - acc: 0.9669 -- iter: 064/317
[A[ATraining Step: 283  | total loss: [1m[32m0.09874[0m[0m | time: 23.793s
[2K
| Adam | epoch: 029 | loss: 0.09874 - acc: 0.9671 -- iter: 096/317
[A[ATraining Step: 284  | total loss: [1m[32m0.09045[0m[0m | time: 31.859s
[2K
| Adam | epoch: 029 | loss: 0.09045 - acc: 0.9704 -- iter: 128/317
[A[ATraining Step: 285  | total loss: [1m[32m0.08362[0m[0m | time: 39.356s
[2K
| Adam | epoch: 029 | loss: 0.08362 - acc: 0.9734 -- iter: 160/317
[A[ATraining Step: 286  | total loss: [1m[32m0.07573[0m[0m | time: 46.757s
[2K
| Adam | epoch: 029 | loss: 0.07573 - acc: 0.9760 -- iter: 192/317
[A[ATraining Step: 287  | total loss: [1m[32m0.10875[0m[0m | time: 54.636s
[2K
| Adam | epoch: 029 | loss: 0.10875 - acc: 0.9715 -- iter: 224/317
[A[ATraining Step: 288  | total loss: [1m[32m0.09945[0m[0m | time: 62.754s
[2K
| Adam | epoch: 029 | loss: 0.09945 - acc: 0.9744 -- iter: 256/317
[A[ATraining Step: 289  | total loss: [1m[32m0.09929[0m[0m | time: 70.658s
[2K
| Adam | epoch: 029 | loss: 0.09929 - acc: 0.9738 -- iter: 288/317
[A[ATraining Step: 290  | total loss: [1m[32m0.09182[0m[0m | time: 83.034s
[2K
| Adam | epoch: 029 | loss: 0.09182 - acc: 0.9764 | val_loss: 3.78215 - val_acc: 0.4700 -- iter: 317/317
--
Training Step: 291  | total loss: [1m[32m0.08346[0m[0m | time: 8.067s
[2K
| Adam | epoch: 030 | loss: 0.08346 - acc: 0.9788 -- iter: 032/317
[A[ATraining Step: 292  | total loss: [1m[32m0.07608[0m[0m | time: 15.945s
[2K
| Adam | epoch: 030 | loss: 0.07608 - acc: 0.9809 -- iter: 064/317
[A[ATraining Step: 293  | total loss: [1m[32m0.09008[0m[0m | time: 23.905s
[2K
| Adam | epoch: 030 | loss: 0.09008 - acc: 0.9797 -- iter: 096/317
[A[ATraining Step: 294  | total loss: [1m[32m0.08180[0m[0m | time: 31.999s
[2K
| Adam | epoch: 030 | loss: 0.08180 - acc: 0.9817 -- iter: 128/317
[A[ATraining Step: 295  | total loss: [1m[32m0.07462[0m[0m | time: 39.918s
[2K
| Adam | epoch: 030 | loss: 0.07462 - acc: 0.9836 -- iter: 160/317
[A[ATraining Step: 296  | total loss: [1m[32m0.06811[0m[0m | time: 47.330s
[2K
| Adam | epoch: 030 | loss: 0.06811 - acc: 0.9852 -- iter: 192/317
[A[ATraining Step: 297  | total loss: [1m[32m0.06812[0m[0m | time: 54.829s
[2K
| Adam | epoch: 030 | loss: 0.06812 - acc: 0.9832 -- iter: 224/317
[A[ATraining Step: 298  | total loss: [1m[32m0.11875[0m[0m | time: 62.916s
[2K
| Adam | epoch: 030 | loss: 0.11875 - acc: 0.9746 -- iter: 256/317
[A[ATraining Step: 299  | total loss: [1m[32m0.10756[0m[0m | time: 70.917s
[2K
| Adam | epoch: 030 | loss: 0.10756 - acc: 0.9771 -- iter: 288/317
[A[ATraining Step: 300  | total loss: [1m[32m0.10058[0m[0m | time: 83.152s
[2K
| Adam | epoch: 030 | loss: 0.10058 - acc: 0.9763 | val_loss: 0.61114 - val_acc: 0.8000 -- iter: 317/317
--
Validation AUC:0.8655394524959743
Validation AUPRC:0.9081156725381401
Test AUC:0.8294573643410853
Test AUPRC:0.8574102867670295
BestTestF1Score	0.81	0.53	0.77	0.77	0.86	49	15	28	8	0.15
BestTestMCCScore	0.8	0.59	0.79	0.86	0.75	43	7	36	14	0.47
BestTestAccuracyScore	0.8	0.59	0.79	0.86	0.75	43	7	36	14	0.47
BestValidationF1Score	0.82	0.6	0.8	0.8	0.83	45	11	35	9	0.15
BestValidationMCC	0.82	0.62	0.81	0.86	0.78	42	7	39	12	0.47
BestValidationAccuracy	0.82	0.62	0.81	0.86	0.78	42	7	39	12	0.47
TestPredictions (Threshold:0.47)
CHEMBL3798452,TP,ACT,0.9900000095367432	CHEMBL207320,TP,ACT,0.9599999785423279	CHEMBL57781,TN,INACT,0.009999999776482582	CHEMBL41275,TN,INACT,0.019999999552965164	CHEMBL3394008,TN,INACT,0.11999999731779099	CHEMBL207857,TP,ACT,1.0	CHEMBL2018963,TP,ACT,0.8799999952316284	CHEMBL232640,FN,ACT,0.10999999940395355	CHEMBL40238,TP,ACT,0.5	CHEMBL475496,TN,INACT,0.0	CHEMBL295057,TP,ACT,0.9900000095367432	CHEMBL44143,TP,ACT,0.9700000286102295	CHEMBL404373,TN,INACT,0.2800000011920929	CHEMBL2018960,TP,ACT,0.6499999761581421	CHEMBL184582,TN,INACT,0.28999999165534973	CHEMBL42044,FN,ACT,0.38999998569488525	CHEMBL2205808,TN,INACT,0.25	CHEMBL42046,TP,ACT,0.6000000238418579	CHEMBL42491,TP,ACT,0.5699999928474426	CHEMBL2326619,TP,ACT,0.9800000190734863	CHEMBL372399,TP,ACT,0.8600000143051147	CHEMBL245931,TP,ACT,0.9800000190734863	CHEMBL415902,FN,ACT,0.03999999910593033	CHEMBL63109,TN,INACT,0.029999999329447746	CHEMBL2436713,TN,INACT,0.0	CHEMBL3798539,TP,ACT,0.9700000286102295	CHEMBL336143,TN,INACT,0.2800000011920929	CHEMBL2322893,FP,INACT,0.949999988079071	CHEMBL2207089,FN,ACT,0.46000000834465027	CHEMBL2324200,FN,ACT,0.0	CHEMBL3393993,TN,INACT,0.0	CHEMBL2018966,TP,ACT,0.6100000143051147	CHEMBL245730,TP,ACT,0.9700000286102295	CHEMBL600018,TP,ACT,0.8700000047683716	CHEMBL372493,TN,INACT,0.07999999821186066	CHEMBL1916635,TN,INACT,0.009999999776482582	CHEMBL2436816,TN,INACT,0.0	CHEMBL202085,TP,ACT,0.8199999928474426	CHEMBL208458,FN,ACT,0.3100000023841858	CHEMBL428959,TN,INACT,0.03999999910593033	CHEMBL598070,TP,ACT,0.9700000286102295	CHEMBL336081,TN,INACT,0.03999999910593033	CHEMBL3604299,TN,INACT,0.019999999552965164	CHEMBL233046,TP,ACT,0.49000000953674316	CHEMBL3797462,FN,ACT,0.03999999910593033	CHEMBL557576,TN,INACT,0.07000000029802322	CHEMBL469856,TN,INACT,0.009999999776482582	CHEMBL70239,TN,INACT,0.009999999776482582	CHEMBL25528,TN,INACT,0.1599999964237213	CHEMBL206878,TP,ACT,1.0	CHEMBL297335,FP,INACT,0.9800000190734863	CHEMBL2207100,TP,ACT,0.9900000095367432	CHEMBL195298,TP,ACT,0.9700000286102295	CHEMBL1076625,TN,INACT,0.0	CHEMBL217002,TN,INACT,0.009999999776482582	CHEMBL164968,FP,INACT,0.9800000190734863	CHEMBL200966,TP,ACT,0.9300000071525574	CHEMBL288655,FN,ACT,0.2199999988079071	CHEMBL2207101,TP,ACT,0.6200000047683716	CHEMBL363994,FP,INACT,0.9100000262260437	CHEMBL3109772,TN,INACT,0.009999999776482582	CHEMBL184390,TN,INACT,0.44999998807907104	CHEMBL446178,FP,INACT,0.8999999761581421	CHEMBL82194,TN,INACT,0.10999999940395355	CHEMBL174463,TN,INACT,0.20999999344348907	CHEMBL195484,TP,ACT,0.9900000095367432	CHEMBL42334,FN,ACT,0.029999999329447746	CHEMBL486840,TP,ACT,0.9800000190734863	CHEMBL382244,TP,ACT,0.6499999761581421	CHEMBL207290,TP,ACT,0.7599999904632568	CHEMBL43143,TP,ACT,0.9700000286102295	CHEMBL2018959,TP,ACT,0.9200000166893005	CHEMBL3604305,TN,INACT,0.0	CHEMBL184240,FP,INACT,0.8500000238418579	CHEMBL39879,TN,INACT,0.0	CHEMBL2436721,TN,INACT,0.0	CHEMBL2207082,TP,ACT,0.9700000286102295	CHEMBL514965,TN,INACT,0.0	CHEMBL2326622,TP,ACT,0.9800000190734863	CHEMBL2435852,FN,ACT,0.20000000298023224	CHEMBL126106,TN,INACT,0.05999999865889549	CHEMBL2326623,TP,ACT,0.9900000095367432	CHEMBL535818,TN,INACT,0.2800000011920929	CHEMBL303247,TN,INACT,0.09000000357627869	CHEMBL599995,TP,ACT,0.9399999976158142	CHEMBL441305,FP,INACT,0.8399999737739563	CHEMBL488640,TP,ACT,0.9700000286102295	CHEMBL2105686,FN,ACT,0.019999999552965164	CHEMBL44259,FN,ACT,0.009999999776482582	CHEMBL2018958,TP,ACT,0.7099999785423279	CHEMBL207780,FN,ACT,0.019999999552965164	CHEMBL134652,TN,INACT,0.0	CHEMBL377421,FN,ACT,0.2800000011920929	CHEMBL379460,TP,ACT,1.0	CHEMBL296067,TP,ACT,0.5899999737739563	CHEMBL200465,TP,ACT,0.7699999809265137	CHEMBL2321924,TP,ACT,0.9700000286102295	CHEMBL2018968,TP,ACT,0.9399999976158142	CHEMBL2436818,TN,INACT,0.03999999910593033	CHEMBL397845,TP,ACT,0.9399999976158142	

