ImageNetInceptionV2 CHEMBL4696 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	124
Number of inactive compounds :	124
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4696_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4696_adam_0.001_15_0.6/
---------------------------------
Training samples: 158
Validation samples: 50
--
Training Step: 1  | time: 36.552s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/158
[A[ATraining Step: 2  | total loss: [1m[32m0.67288[0m[0m | time: 44.387s
[2K
| Adam | epoch: 001 | loss: 0.67288 - acc: 0.3937 -- iter: 064/158
[A[ATraining Step: 3  | total loss: [1m[32m0.91006[0m[0m | time: 52.282s
[2K
| Adam | epoch: 001 | loss: 0.91006 - acc: 0.4807 -- iter: 096/158
[A[ATraining Step: 4  | total loss: [1m[32m0.73081[0m[0m | time: 60.243s
[2K
| Adam | epoch: 001 | loss: 0.73081 - acc: 0.5186 -- iter: 128/158
[A[ATraining Step: 5  | total loss: [1m[32m0.77797[0m[0m | time: 75.774s
[2K
| Adam | epoch: 001 | loss: 0.77797 - acc: 0.4625 | val_loss: 1.85245 - val_acc: 0.5400 -- iter: 158/158
--
Training Step: 6  | total loss: [1m[32m0.70327[0m[0m | time: 7.474s
[2K
| Adam | epoch: 002 | loss: 0.70327 - acc: 0.5937 -- iter: 032/158
[A[ATraining Step: 7  | total loss: [1m[32m0.48116[0m[0m | time: 15.289s
[2K
| Adam | epoch: 002 | loss: 0.48116 - acc: 0.7775 -- iter: 064/158
[A[ATraining Step: 8  | total loss: [1m[32m1.28576[0m[0m | time: 23.275s
[2K
| Adam | epoch: 002 | loss: 1.28576 - acc: 0.5159 -- iter: 096/158
[A[ATraining Step: 9  | total loss: [1m[32m1.25645[0m[0m | time: 30.943s
[2K
| Adam | epoch: 002 | loss: 1.25645 - acc: 0.4579 -- iter: 128/158
[A[ATraining Step: 10  | total loss: [1m[32m0.95381[0m[0m | time: 41.006s
[2K
| Adam | epoch: 002 | loss: 0.95381 - acc: 0.5102 | val_loss: 1.12969 - val_acc: 0.5400 -- iter: 158/158
--
Training Step: 11  | total loss: [1m[32m0.81946[0m[0m | time: 7.477s
[2K
| Adam | epoch: 003 | loss: 0.81946 - acc: 0.5202 -- iter: 032/158
[A[ATraining Step: 12  | total loss: [1m[32m0.77810[0m[0m | time: 14.757s
[2K
| Adam | epoch: 003 | loss: 0.77810 - acc: 0.5261 -- iter: 064/158
[A[ATraining Step: 13  | total loss: [1m[32m0.72931[0m[0m | time: 22.626s
[2K
| Adam | epoch: 003 | loss: 0.72931 - acc: 0.5863 -- iter: 096/158
[A[ATraining Step: 14  | total loss: [1m[32m0.76000[0m[0m | time: 30.307s
[2K
| Adam | epoch: 003 | loss: 0.76000 - acc: 0.5127 -- iter: 128/158
[A[ATraining Step: 15  | total loss: [1m[32m0.73396[0m[0m | time: 40.427s
[2K
| Adam | epoch: 003 | loss: 0.73396 - acc: 0.5566 | val_loss: 0.69249 - val_acc: 0.5000 -- iter: 158/158
--
Training Step: 16  | total loss: [1m[32m0.67679[0m[0m | time: 7.750s
[2K
| Adam | epoch: 004 | loss: 0.67679 - acc: 0.6057 -- iter: 032/158
[A[ATraining Step: 17  | total loss: [1m[32m0.66063[0m[0m | time: 15.257s
[2K
| Adam | epoch: 004 | loss: 0.66063 - acc: 0.5901 -- iter: 064/158
[A[ATraining Step: 18  | total loss: [1m[32m0.68970[0m[0m | time: 22.647s
[2K
| Adam | epoch: 004 | loss: 0.68970 - acc: 0.5705 -- iter: 096/158
[A[ATraining Step: 19  | total loss: [1m[32m0.71203[0m[0m | time: 30.439s
[2K
| Adam | epoch: 004 | loss: 0.71203 - acc: 0.5914 -- iter: 128/158
[A[ATraining Step: 20  | total loss: [1m[32m0.69984[0m[0m | time: 40.437s
[2K
| Adam | epoch: 004 | loss: 0.69984 - acc: 0.5821 | val_loss: 0.87908 - val_acc: 0.5400 -- iter: 158/158
--
Training Step: 21  | total loss: [1m[32m0.69461[0m[0m | time: 7.907s
[2K
| Adam | epoch: 005 | loss: 0.69461 - acc: 0.5760 -- iter: 032/158
[A[ATraining Step: 22  | total loss: [1m[32m0.66288[0m[0m | time: 15.746s
[2K
| Adam | epoch: 005 | loss: 0.66288 - acc: 0.6189 -- iter: 064/158
[A[ATraining Step: 23  | total loss: [1m[32m0.63260[0m[0m | time: 23.203s
[2K
| Adam | epoch: 005 | loss: 0.63260 - acc: 0.6751 -- iter: 096/158
[A[ATraining Step: 24  | total loss: [1m[32m0.61710[0m[0m | time: 30.638s
[2K
| Adam | epoch: 005 | loss: 0.61710 - acc: 0.6915 -- iter: 128/158
[A[ATraining Step: 25  | total loss: [1m[32m0.58029[0m[0m | time: 40.620s
[2K
| Adam | epoch: 005 | loss: 0.58029 - acc: 0.7211 | val_loss: 0.76774 - val_acc: 0.4600 -- iter: 158/158
--
Training Step: 26  | total loss: [1m[32m0.57932[0m[0m | time: 7.882s
[2K
| Adam | epoch: 006 | loss: 0.57932 - acc: 0.7287 -- iter: 032/158
[A[ATraining Step: 27  | total loss: [1m[32m0.59584[0m[0m | time: 15.539s
[2K
| Adam | epoch: 006 | loss: 0.59584 - acc: 0.7262 -- iter: 064/158
[A[ATraining Step: 28  | total loss: [1m[32m0.55708[0m[0m | time: 23.178s
[2K
| Adam | epoch: 006 | loss: 0.55708 - acc: 0.7243 -- iter: 096/158
[A[ATraining Step: 29  | total loss: [1m[32m0.56065[0m[0m | time: 30.527s
[2K
| Adam | epoch: 006 | loss: 0.56065 - acc: 0.7078 -- iter: 128/158
[A[ATraining Step: 30  | total loss: [1m[32m0.51216[0m[0m | time: 40.381s
[2K
| Adam | epoch: 006 | loss: 0.51216 - acc: 0.7296 | val_loss: 1.16702 - val_acc: 0.4600 -- iter: 158/158
--
Training Step: 31  | total loss: [1m[32m0.45503[0m[0m | time: 7.820s
[2K
| Adam | epoch: 007 | loss: 0.45503 - acc: 0.7843 -- iter: 032/158
[A[ATraining Step: 32  | total loss: [1m[32m0.42960[0m[0m | time: 15.577s
[2K
| Adam | epoch: 007 | loss: 0.42960 - acc: 0.7977 -- iter: 064/158
[A[ATraining Step: 33  | total loss: [1m[32m0.45637[0m[0m | time: 23.203s
[2K
| Adam | epoch: 007 | loss: 0.45637 - acc: 0.7804 -- iter: 096/158
[A[ATraining Step: 34  | total loss: [1m[32m0.41008[0m[0m | time: 30.957s
[2K
| Adam | epoch: 007 | loss: 0.41008 - acc: 0.8073 -- iter: 128/158
[A[ATraining Step: 35  | total loss: [1m[32m0.36810[0m[0m | time: 40.543s
[2K
| Adam | epoch: 007 | loss: 0.36810 - acc: 0.8346 | val_loss: 1.22293 - val_acc: 0.4600 -- iter: 158/158
--
Training Step: 36  | total loss: [1m[32m0.37898[0m[0m | time: 7.485s
[2K
| Adam | epoch: 008 | loss: 0.37898 - acc: 0.8275 -- iter: 032/158
[A[ATraining Step: 37  | total loss: [1m[32m0.35845[0m[0m | time: 15.123s
[2K
| Adam | epoch: 008 | loss: 0.35845 - acc: 0.8420 -- iter: 064/158
[A[ATraining Step: 38  | total loss: [1m[32m0.34348[0m[0m | time: 23.054s
[2K
| Adam | epoch: 008 | loss: 0.34348 - acc: 0.8485 -- iter: 096/158
[A[ATraining Step: 39  | total loss: [1m[32m0.39010[0m[0m | time: 30.633s
[2K
| Adam | epoch: 008 | loss: 0.39010 - acc: 0.8296 -- iter: 128/158
[A[ATraining Step: 40  | total loss: [1m[32m0.39942[0m[0m | time: 40.699s
[2K
| Adam | epoch: 008 | loss: 0.39942 - acc: 0.8381 | val_loss: 1.72653 - val_acc: 0.4600 -- iter: 158/158
--
Training Step: 41  | total loss: [1m[32m0.39283[0m[0m | time: 7.411s
[2K
| Adam | epoch: 009 | loss: 0.39283 - acc: 0.8449 -- iter: 032/158
[A[ATraining Step: 42  | total loss: [1m[32m0.37446[0m[0m | time: 14.910s
[2K
| Adam | epoch: 009 | loss: 0.37446 - acc: 0.8548 -- iter: 064/158
[A[ATraining Step: 43  | total loss: [1m[32m0.33357[0m[0m | time: 22.484s
[2K
| Adam | epoch: 009 | loss: 0.33357 - acc: 0.8746 -- iter: 096/158
[A[ATraining Step: 44  | total loss: [1m[32m0.30977[0m[0m | time: 30.310s
[2K
| Adam | epoch: 009 | loss: 0.30977 - acc: 0.8854 -- iter: 128/158
[A[ATraining Step: 45  | total loss: [1m[32m0.29488[0m[0m | time: 40.323s
[2K
| Adam | epoch: 009 | loss: 0.29488 - acc: 0.8837 | val_loss: 3.14407 - val_acc: 0.4600 -- iter: 158/158
--
Training Step: 46  | total loss: [1m[32m0.30115[0m[0m | time: 7.610s
[2K
| Adam | epoch: 010 | loss: 0.30115 - acc: 0.8874 -- iter: 032/158
[A[ATraining Step: 47  | total loss: [1m[32m0.29864[0m[0m | time: 14.926s
[2K
| Adam | epoch: 010 | loss: 0.29864 - acc: 0.8854 -- iter: 064/158
[A[ATraining Step: 48  | total loss: [1m[32m0.27855[0m[0m | time: 22.191s
[2K
| Adam | epoch: 010 | loss: 0.27855 - acc: 0.8985 -- iter: 096/158
[A[ATraining Step: 49  | total loss: [1m[32m0.25268[0m[0m | time: 29.851s
[2K
| Adam | epoch: 010 | loss: 0.25268 - acc: 0.9092 -- iter: 128/158
[A[ATraining Step: 50  | total loss: [1m[32m0.24774[0m[0m | time: 39.816s
[2K
| Adam | epoch: 010 | loss: 0.24774 - acc: 0.9039 | val_loss: 1.82592 - val_acc: 0.5600 -- iter: 158/158
--
Training Step: 51  | total loss: [1m[32m0.23960[0m[0m | time: 7.875s
[2K
| Adam | epoch: 011 | loss: 0.23960 - acc: 0.9138 -- iter: 032/158
[A[ATraining Step: 52  | total loss: [1m[32m0.24751[0m[0m | time: 15.358s
[2K
| Adam | epoch: 011 | loss: 0.24751 - acc: 0.9127 -- iter: 064/158
[A[ATraining Step: 53  | total loss: [1m[32m0.22737[0m[0m | time: 22.829s
[2K
| Adam | epoch: 011 | loss: 0.22737 - acc: 0.9209 -- iter: 096/158
[A[ATraining Step: 54  | total loss: [1m[32m0.32090[0m[0m | time: 30.195s
[2K
| Adam | epoch: 011 | loss: 0.32090 - acc: 0.8889 -- iter: 128/158
[A[ATraining Step: 55  | total loss: [1m[32m0.36134[0m[0m | time: 40.095s
[2K
| Adam | epoch: 011 | loss: 0.36134 - acc: 0.8714 | val_loss: 3.60082 - val_acc: 0.5400 -- iter: 158/158
--
Training Step: 56  | total loss: [1m[32m0.35094[0m[0m | time: 7.668s
[2K
| Adam | epoch: 012 | loss: 0.35094 - acc: 0.8675 -- iter: 032/158
[A[ATraining Step: 57  | total loss: [1m[32m0.34417[0m[0m | time: 15.387s
[2K
| Adam | epoch: 012 | loss: 0.34417 - acc: 0.8686 -- iter: 064/158
[A[ATraining Step: 58  | total loss: [1m[32m0.33839[0m[0m | time: 23.110s
[2K
| Adam | epoch: 012 | loss: 0.33839 - acc: 0.8652 -- iter: 096/158
[A[ATraining Step: 59  | total loss: [1m[32m0.31976[0m[0m | time: 30.476s
[2K
| Adam | epoch: 012 | loss: 0.31976 - acc: 0.8707 -- iter: 128/158
[A[ATraining Step: 60  | total loss: [1m[32m0.34720[0m[0m | time: 40.034s
[2K
| Adam | epoch: 012 | loss: 0.34720 - acc: 0.8613 | val_loss: 2.82143 - val_acc: 0.5600 -- iter: 158/158
--
Training Step: 61  | total loss: [1m[32m0.34885[0m[0m | time: 7.752s
[2K
| Adam | epoch: 013 | loss: 0.34885 - acc: 0.8664 -- iter: 032/158
[A[ATraining Step: 62  | total loss: [1m[32m0.32387[0m[0m | time: 15.479s
[2K
| Adam | epoch: 013 | loss: 0.32387 - acc: 0.8755 -- iter: 064/158
[A[ATraining Step: 63  | total loss: [1m[32m0.31734[0m[0m | time: 23.266s
[2K
| Adam | epoch: 013 | loss: 0.31734 - acc: 0.8755 -- iter: 096/158
[A[ATraining Step: 64  | total loss: [1m[32m0.30751[0m[0m | time: 30.981s
[2K
| Adam | epoch: 013 | loss: 0.30751 - acc: 0.8832 -- iter: 128/158
[A[ATraining Step: 65  | total loss: [1m[32m0.29639[0m[0m | time: 40.624s
[2K
| Adam | epoch: 013 | loss: 0.29639 - acc: 0.8861 | val_loss: 1.09285 - val_acc: 0.5600 -- iter: 158/158
--
Training Step: 66  | total loss: [1m[32m0.31221[0m[0m | time: 7.224s
[2K
| Adam | epoch: 014 | loss: 0.31221 - acc: 0.8796 -- iter: 032/158
[A[ATraining Step: 67  | total loss: [1m[32m0.28858[0m[0m | time: 14.772s
[2K
| Adam | epoch: 014 | loss: 0.28858 - acc: 0.8901 -- iter: 064/158
[A[ATraining Step: 68  | total loss: [1m[32m0.29356[0m[0m | time: 22.499s
[2K
| Adam | epoch: 014 | loss: 0.29356 - acc: 0.8846 -- iter: 096/158
[A[ATraining Step: 69  | total loss: [1m[32m0.27012[0m[0m | time: 30.255s
[2K
| Adam | epoch: 014 | loss: 0.27012 - acc: 0.8944 -- iter: 128/158
[A[ATraining Step: 70  | total loss: [1m[32m0.26078[0m[0m | time: 40.256s
[2K
| Adam | epoch: 014 | loss: 0.26078 - acc: 0.9030 | val_loss: 1.97151 - val_acc: 0.5600 -- iter: 158/158
--
Training Step: 71  | total loss: [1m[32m0.27803[0m[0m | time: 7.268s
[2K
| Adam | epoch: 015 | loss: 0.27803 - acc: 0.8998 -- iter: 032/158
[A[ATraining Step: 72  | total loss: [1m[32m0.25361[0m[0m | time: 14.586s
[2K
| Adam | epoch: 015 | loss: 0.25361 - acc: 0.9111 -- iter: 064/158
[A[ATraining Step: 73  | total loss: [1m[32m0.23029[0m[0m | time: 22.445s
[2K
| Adam | epoch: 015 | loss: 0.23029 - acc: 0.9210 -- iter: 096/158
[A[ATraining Step: 74  | total loss: [1m[32m0.22412[0m[0m | time: 30.084s
[2K
| Adam | epoch: 015 | loss: 0.22412 - acc: 0.9262 -- iter: 128/158
[A[ATraining Step: 75  | total loss: [1m[32m0.21914[0m[0m | time: 39.925s
[2K
| Adam | epoch: 015 | loss: 0.21914 - acc: 0.9308 | val_loss: 1.05144 - val_acc: 0.6600 -- iter: 158/158
--
Validation AUC:0.6731078904991947
Validation AUPRC:0.7484494896932663
Test AUC:0.625
Test AUPRC:0.6876559990291826
BestTestF1Score	0.62	0.34	0.66	0.74	0.54	14	5	19	12	0.44
BestTestMCCScore	0.47	0.26	0.6	0.75	0.35	9	3	21	17	0.91
BestTestAccuracyScore	0.62	0.34	0.66	0.74	0.54	14	5	19	12	0.44
BestValidationF1Score	0.73	0.39	0.7	0.71	0.74	20	8	15	7	0.44
BestValidationMCC	0.64	0.41	0.68	0.82	0.52	14	3	20	13	0.91
BestValidationAccuracy	0.73	0.39	0.7	0.71	0.74	20	8	15	7	0.44
TestPredictions (Threshold:0.91)
CHEMBL1797438,TN,INACT,0.17000000178813934	CHEMBL566381,TN,INACT,0.10999999940395355	CHEMBL1796866,FN,ACT,0.019999999552965164	CHEMBL150213,FN,ACT,0.009999999776482582	CHEMBL1096135,FN,ACT,0.20999999344348907	CHEMBL1078407,TP,ACT,0.9900000095367432	CHEMBL1080965,TN,INACT,0.11999999731779099	CHEMBL208693,FN,ACT,0.38999998569488525	CHEMBL2408225,TP,ACT,0.9800000190734863	CHEMBL1814507,TP,ACT,0.9900000095367432	CHEMBL1796871,TN,INACT,0.1899999976158142	CHEMBL1796868,TN,INACT,0.3799999952316284	CHEMBL1797307,TN,INACT,0.12999999523162842	CHEMBL1797014,FN,ACT,0.12999999523162842	CHEMBL1797010,FN,ACT,0.20999999344348907	CHEMBL202392,TN,INACT,0.41999998688697815	CHEMBL3237969,TP,ACT,1.0	CHEMBL3323453,FN,ACT,0.8299999833106995	CHEMBL338902,FN,ACT,0.33000001311302185	CHEMBL3770237,TN,INACT,0.10000000149011612	CHEMBL1738939,TN,INACT,0.009999999776482582	CHEMBL1077649,TN,INACT,0.09000000357627869	CHEMBL3322302,FN,ACT,0.009999999776482582	CHEMBL202579,TN,INACT,0.019999999552965164	CHEMBL1814498,TP,ACT,0.9200000166893005	CHEMBL566671,FN,ACT,0.5600000023841858	CHEMBL1077655,TN,INACT,0.8999999761581421	CHEMBL3237963,TP,ACT,0.9300000071525574	CHEMBL1796861,TN,INACT,0.11999999731779099	CHEMBL1096136,FN,ACT,0.49000000953674316	CHEMBL1229682,TN,INACT,0.2800000011920929	CHEMBL490175,TP,ACT,1.0	CHEMBL490001,FN,ACT,0.18000000715255737	CHEMBL1077658,FN,ACT,0.0	CHEMBL566250,FP,INACT,0.949999988079071	CHEMBL1230224,FP,INACT,0.9599999785423279	CHEMBL595519,FN,ACT,0.8600000143051147	CHEMBL114950,FN,ACT,0.0	CHEMBL1797141,TN,INACT,0.029999999329447746	CHEMBL1644921,FP,INACT,1.0	CHEMBL213661,FN,ACT,0.699999988079071	CHEMBL1797025,TN,INACT,0.8100000023841858	CHEMBL236090,TN,INACT,0.2800000011920929	CHEMBL380025,TN,INACT,0.3400000035762787	CHEMBL1078508,TN,INACT,0.23000000417232513	CHEMBL567035,TN,INACT,0.1899999976158142	CHEMBL1797306,FN,ACT,0.05000000074505806	CHEMBL392670,TP,ACT,0.9900000095367432	CHEMBL1797139,TP,ACT,0.9300000071525574	CHEMBL568431,TN,INACT,0.0	

