CNNModel CHEMBL2285 adam 0.001 30 128 0 0.8 False True
Number of active compounds :	391
Number of inactive compounds :	315
---------------------------------
Run id: CNNModel_CHEMBL2285_adam_0.001_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2285_adam_0.001_30_128_0.8_True/
---------------------------------
Training samples: 431
Validation samples: 135
--
Training Step: 1  | time: 0.771s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/431
[A[ATraining Step: 2  | total loss: [1m[32m0.62389[0m[0m | time: 1.396s
[2K
| Adam | epoch: 001 | loss: 0.62389 - acc: 0.4500 -- iter: 064/431
[A[ATraining Step: 3  | total loss: [1m[32m0.68034[0m[0m | time: 2.021s
[2K
| Adam | epoch: 001 | loss: 0.68034 - acc: 0.5165 -- iter: 096/431
[A[ATraining Step: 4  | total loss: [1m[32m0.68951[0m[0m | time: 2.628s
[2K
| Adam | epoch: 001 | loss: 0.68951 - acc: 0.5041 -- iter: 128/431
[A[ATraining Step: 5  | total loss: [1m[32m0.71264[0m[0m | time: 3.236s
[2K
| Adam | epoch: 001 | loss: 0.71264 - acc: 0.3498 -- iter: 160/431
[A[ATraining Step: 6  | total loss: [1m[32m0.70209[0m[0m | time: 3.843s
[2K
| Adam | epoch: 001 | loss: 0.70209 - acc: 0.3861 -- iter: 192/431
[A[ATraining Step: 7  | total loss: [1m[32m0.69619[0m[0m | time: 4.443s
[2K
| Adam | epoch: 001 | loss: 0.69619 - acc: 0.5482 -- iter: 224/431
[A[ATraining Step: 8  | total loss: [1m[32m0.69175[0m[0m | time: 5.089s
[2K
| Adam | epoch: 001 | loss: 0.69175 - acc: 0.6441 -- iter: 256/431
[A[ATraining Step: 9  | total loss: [1m[32m0.69315[0m[0m | time: 5.697s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.5513 -- iter: 288/431
[A[ATraining Step: 10  | total loss: [1m[32m0.69004[0m[0m | time: 6.293s
[2K
| Adam | epoch: 001 | loss: 0.69004 - acc: 0.5881 -- iter: 320/431
[A[ATraining Step: 11  | total loss: [1m[32m0.69173[0m[0m | time: 6.907s
[2K
| Adam | epoch: 001 | loss: 0.69173 - acc: 0.5464 -- iter: 352/431
[A[ATraining Step: 12  | total loss: [1m[32m0.68486[0m[0m | time: 7.531s
[2K
| Adam | epoch: 001 | loss: 0.68486 - acc: 0.6099 -- iter: 384/431
[A[ATraining Step: 13  | total loss: [1m[32m0.68168[0m[0m | time: 8.156s
[2K
| Adam | epoch: 001 | loss: 0.68168 - acc: 0.6164 -- iter: 416/431
[A[ATraining Step: 14  | total loss: [1m[32m0.67712[0m[0m | time: 9.529s
[2K
| Adam | epoch: 001 | loss: 0.67712 - acc: 0.6199 | val_loss: 0.69944 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 15  | total loss: [1m[32m0.70778[0m[0m | time: 0.330s
[2K
| Adam | epoch: 002 | loss: 0.70778 - acc: 0.5339 -- iter: 032/431
[A[ATraining Step: 16  | total loss: [1m[32m0.72129[0m[0m | time: 0.945s
[2K
| Adam | epoch: 002 | loss: 0.72129 - acc: 0.4837 -- iter: 064/431
[A[ATraining Step: 17  | total loss: [1m[32m0.71098[0m[0m | time: 1.576s
[2K
| Adam | epoch: 002 | loss: 0.71098 - acc: 0.5008 -- iter: 096/431
[A[ATraining Step: 18  | total loss: [1m[32m0.70761[0m[0m | time: 2.170s
[2K
| Adam | epoch: 002 | loss: 0.70761 - acc: 0.4897 -- iter: 128/431
[A[ATraining Step: 19  | total loss: [1m[32m0.69983[0m[0m | time: 2.773s
[2K
| Adam | epoch: 002 | loss: 0.69983 - acc: 0.5244 -- iter: 160/431
[A[ATraining Step: 20  | total loss: [1m[32m0.69440[0m[0m | time: 3.380s
[2K
| Adam | epoch: 002 | loss: 0.69440 - acc: 0.5567 -- iter: 192/431
[A[ATraining Step: 21  | total loss: [1m[32m0.69584[0m[0m | time: 3.995s
[2K
| Adam | epoch: 002 | loss: 0.69584 - acc: 0.5197 -- iter: 224/431
[A[ATraining Step: 22  | total loss: [1m[32m0.69256[0m[0m | time: 4.605s
[2K
| Adam | epoch: 002 | loss: 0.69256 - acc: 0.5513 -- iter: 256/431
[A[ATraining Step: 23  | total loss: [1m[32m0.68922[0m[0m | time: 5.211s
[2K
| Adam | epoch: 002 | loss: 0.68922 - acc: 0.5908 -- iter: 288/431
[A[ATraining Step: 24  | total loss: [1m[32m0.68811[0m[0m | time: 5.830s
[2K
| Adam | epoch: 002 | loss: 0.68811 - acc: 0.6005 -- iter: 320/431
[A[ATraining Step: 25  | total loss: [1m[32m0.68616[0m[0m | time: 6.449s
[2K
| Adam | epoch: 002 | loss: 0.68616 - acc: 0.6242 -- iter: 352/431
[A[ATraining Step: 26  | total loss: [1m[32m0.68577[0m[0m | time: 7.058s
[2K
| Adam | epoch: 002 | loss: 0.68577 - acc: 0.6244 -- iter: 384/431
[A[ATraining Step: 27  | total loss: [1m[32m0.68787[0m[0m | time: 7.675s
[2K
| Adam | epoch: 002 | loss: 0.68787 - acc: 0.5924 -- iter: 416/431
[A[ATraining Step: 28  | total loss: [1m[32m0.68675[0m[0m | time: 9.287s
[2K
| Adam | epoch: 002 | loss: 0.68675 - acc: 0.6006 | val_loss: 0.69179 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 29  | total loss: [1m[32m0.68371[0m[0m | time: 0.329s
[2K
| Adam | epoch: 003 | loss: 0.68371 - acc: 0.6293 -- iter: 032/431
[A[ATraining Step: 30  | total loss: [1m[32m0.68694[0m[0m | time: 0.654s
[2K
| Adam | epoch: 003 | loss: 0.68694 - acc: 0.5908 -- iter: 064/431
[A[ATraining Step: 31  | total loss: [1m[32m0.68944[0m[0m | time: 1.261s
[2K
| Adam | epoch: 003 | loss: 0.68944 - acc: 0.5621 -- iter: 096/431
[A[ATraining Step: 32  | total loss: [1m[32m0.68584[0m[0m | time: 1.870s
[2K
| Adam | epoch: 003 | loss: 0.68584 - acc: 0.5904 -- iter: 128/431
[A[ATraining Step: 33  | total loss: [1m[32m0.68200[0m[0m | time: 2.470s
[2K
| Adam | epoch: 003 | loss: 0.68200 - acc: 0.6185 -- iter: 160/431
[A[ATraining Step: 34  | total loss: [1m[32m0.68595[0m[0m | time: 3.048s
[2K
| Adam | epoch: 003 | loss: 0.68595 - acc: 0.5864 -- iter: 192/431
[A[ATraining Step: 35  | total loss: [1m[32m0.68502[0m[0m | time: 3.642s
[2K
| Adam | epoch: 003 | loss: 0.68502 - acc: 0.5880 -- iter: 224/431
[A[ATraining Step: 36  | total loss: [1m[32m0.68526[0m[0m | time: 4.247s
[2K
| Adam | epoch: 003 | loss: 0.68526 - acc: 0.5828 -- iter: 256/431
[A[ATraining Step: 37  | total loss: [1m[32m0.68538[0m[0m | time: 4.864s
[2K
| Adam | epoch: 003 | loss: 0.68538 - acc: 0.5787 -- iter: 288/431
[A[ATraining Step: 38  | total loss: [1m[32m0.68666[0m[0m | time: 5.494s
[2K
| Adam | epoch: 003 | loss: 0.68666 - acc: 0.5694 -- iter: 320/431
[A[ATraining Step: 39  | total loss: [1m[32m0.69017[0m[0m | time: 6.105s
[2K
| Adam | epoch: 003 | loss: 0.69017 - acc: 0.5501 -- iter: 352/431
[A[ATraining Step: 40  | total loss: [1m[32m0.69061[0m[0m | time: 6.710s
[2K
| Adam | epoch: 003 | loss: 0.69061 - acc: 0.5466 -- iter: 384/431
[A[ATraining Step: 41  | total loss: [1m[32m0.68731[0m[0m | time: 7.332s
[2K
| Adam | epoch: 003 | loss: 0.68731 - acc: 0.5610 -- iter: 416/431
[A[ATraining Step: 42  | total loss: [1m[32m0.68482[0m[0m | time: 8.933s
[2K
| Adam | epoch: 003 | loss: 0.68482 - acc: 0.5725 | val_loss: 0.69440 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 43  | total loss: [1m[32m0.68365[0m[0m | time: 0.603s
[2K
| Adam | epoch: 004 | loss: 0.68365 - acc: 0.5763 -- iter: 032/431
[A[ATraining Step: 44  | total loss: [1m[32m0.68676[0m[0m | time: 0.909s
[2K
| Adam | epoch: 004 | loss: 0.68676 - acc: 0.5631 -- iter: 064/431
[A[ATraining Step: 45  | total loss: [1m[32m0.67899[0m[0m | time: 1.242s
[2K
| Adam | epoch: 004 | loss: 0.67899 - acc: 0.5920 -- iter: 096/431
[A[ATraining Step: 46  | total loss: [1m[32m0.67196[0m[0m | time: 1.845s
[2K
| Adam | epoch: 004 | loss: 0.67196 - acc: 0.6155 -- iter: 128/431
[A[ATraining Step: 47  | total loss: [1m[32m0.67082[0m[0m | time: 2.453s
[2K
| Adam | epoch: 004 | loss: 0.67082 - acc: 0.6171 -- iter: 160/431
[A[ATraining Step: 48  | total loss: [1m[32m0.67632[0m[0m | time: 3.084s
[2K
| Adam | epoch: 004 | loss: 0.67632 - acc: 0.6033 -- iter: 192/431
[A[ATraining Step: 49  | total loss: [1m[32m0.67665[0m[0m | time: 3.699s
[2K
| Adam | epoch: 004 | loss: 0.67665 - acc: 0.6018 -- iter: 224/431
[A[ATraining Step: 50  | total loss: [1m[32m0.69192[0m[0m | time: 4.336s
[2K
| Adam | epoch: 004 | loss: 0.69192 - acc: 0.5714 -- iter: 256/431
[A[ATraining Step: 51  | total loss: [1m[32m0.69521[0m[0m | time: 4.934s
[2K
| Adam | epoch: 004 | loss: 0.69521 - acc: 0.5605 -- iter: 288/431
[A[ATraining Step: 52  | total loss: [1m[32m0.69416[0m[0m | time: 5.531s
[2K
| Adam | epoch: 004 | loss: 0.69416 - acc: 0.5608 -- iter: 320/431
[A[ATraining Step: 53  | total loss: [1m[32m0.69279[0m[0m | time: 6.132s
[2K
| Adam | epoch: 004 | loss: 0.69279 - acc: 0.5611 -- iter: 352/431
[A[ATraining Step: 54  | total loss: [1m[32m0.69507[0m[0m | time: 6.735s
[2K
| Adam | epoch: 004 | loss: 0.69507 - acc: 0.5477 -- iter: 384/431
[A[ATraining Step: 55  | total loss: [1m[32m0.68764[0m[0m | time: 7.349s
[2K
| Adam | epoch: 004 | loss: 0.68764 - acc: 0.5766 -- iter: 416/431
[A[ATraining Step: 56  | total loss: [1m[32m0.68360[0m[0m | time: 8.946s
[2K
| Adam | epoch: 004 | loss: 0.68360 - acc: 0.5922 | val_loss: 0.69298 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 57  | total loss: [1m[32m0.67956[0m[0m | time: 0.612s
[2K
| Adam | epoch: 005 | loss: 0.67956 - acc: 0.6097 -- iter: 032/431
[A[ATraining Step: 58  | total loss: [1m[32m0.68543[0m[0m | time: 1.218s
[2K
| Adam | epoch: 005 | loss: 0.68543 - acc: 0.5777 -- iter: 064/431
[A[ATraining Step: 59  | total loss: [1m[32m0.68630[0m[0m | time: 1.519s
[2K
| Adam | epoch: 005 | loss: 0.68630 - acc: 0.5715 -- iter: 096/431
[A[ATraining Step: 60  | total loss: [1m[32m0.68864[0m[0m | time: 1.823s
[2K
| Adam | epoch: 005 | loss: 0.68864 - acc: 0.5576 -- iter: 128/431
[A[ATraining Step: 61  | total loss: [1m[32m0.69081[0m[0m | time: 2.419s
[2K
| Adam | epoch: 005 | loss: 0.69081 - acc: 0.5457 -- iter: 160/431
[A[ATraining Step: 62  | total loss: [1m[32m0.69157[0m[0m | time: 3.017s
[2K
| Adam | epoch: 005 | loss: 0.69157 - acc: 0.5399 -- iter: 192/431
[A[ATraining Step: 63  | total loss: [1m[32m0.69018[0m[0m | time: 3.641s
[2K
| Adam | epoch: 005 | loss: 0.69018 - acc: 0.5467 -- iter: 224/431
[A[ATraining Step: 64  | total loss: [1m[32m0.68834[0m[0m | time: 4.249s
[2K
| Adam | epoch: 005 | loss: 0.68834 - acc: 0.5565 -- iter: 256/431
[A[ATraining Step: 65  | total loss: [1m[32m0.68874[0m[0m | time: 4.837s
[2K
| Adam | epoch: 005 | loss: 0.68874 - acc: 0.5534 -- iter: 288/431
[A[ATraining Step: 66  | total loss: [1m[32m0.68637[0m[0m | time: 5.441s
[2K
| Adam | epoch: 005 | loss: 0.68637 - acc: 0.5659 -- iter: 320/431
[A[ATraining Step: 67  | total loss: [1m[32m0.68507[0m[0m | time: 6.052s
[2K
| Adam | epoch: 005 | loss: 0.68507 - acc: 0.5730 -- iter: 352/431
[A[ATraining Step: 68  | total loss: [1m[32m0.68442[0m[0m | time: 6.696s
[2K
| Adam | epoch: 005 | loss: 0.68442 - acc: 0.5754 -- iter: 384/431
[A[ATraining Step: 69  | total loss: [1m[32m0.68269[0m[0m | time: 7.305s
[2K
| Adam | epoch: 005 | loss: 0.68269 - acc: 0.5849 -- iter: 416/431
[A[ATraining Step: 70  | total loss: [1m[32m0.67843[0m[0m | time: 8.934s
[2K
| Adam | epoch: 005 | loss: 0.67843 - acc: 0.6075 | val_loss: 0.69286 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 71  | total loss: [1m[32m0.67864[0m[0m | time: 0.622s
[2K
| Adam | epoch: 006 | loss: 0.67864 - acc: 0.6060 -- iter: 032/431
[A[ATraining Step: 72  | total loss: [1m[32m0.67938[0m[0m | time: 1.232s
[2K
| Adam | epoch: 006 | loss: 0.67938 - acc: 0.6011 -- iter: 064/431
[A[ATraining Step: 73  | total loss: [1m[32m0.67937[0m[0m | time: 1.840s
[2K
| Adam | epoch: 006 | loss: 0.67937 - acc: 0.6003 -- iter: 096/431
[A[ATraining Step: 74  | total loss: [1m[32m0.68299[0m[0m | time: 2.142s
[2K
| Adam | epoch: 006 | loss: 0.68299 - acc: 0.5824 -- iter: 128/431
[A[ATraining Step: 75  | total loss: [1m[32m0.68390[0m[0m | time: 2.451s
[2K
| Adam | epoch: 006 | loss: 0.68390 - acc: 0.5771 -- iter: 160/431
[A[ATraining Step: 76  | total loss: [1m[32m0.68470[0m[0m | time: 3.060s
[2K
| Adam | epoch: 006 | loss: 0.68470 - acc: 0.5724 -- iter: 192/431
[A[ATraining Step: 77  | total loss: [1m[32m0.68259[0m[0m | time: 3.666s
[2K
| Adam | epoch: 006 | loss: 0.68259 - acc: 0.5813 -- iter: 224/431
[A[ATraining Step: 78  | total loss: [1m[32m0.68355[0m[0m | time: 4.269s
[2K
| Adam | epoch: 006 | loss: 0.68355 - acc: 0.5760 -- iter: 256/431
[A[ATraining Step: 79  | total loss: [1m[32m0.68301[0m[0m | time: 4.899s
[2K
| Adam | epoch: 006 | loss: 0.68301 - acc: 0.5779 -- iter: 288/431
[A[ATraining Step: 80  | total loss: [1m[32m0.68099[0m[0m | time: 5.526s
[2K
| Adam | epoch: 006 | loss: 0.68099 - acc: 0.5859 -- iter: 320/431
[A[ATraining Step: 81  | total loss: [1m[32m0.68450[0m[0m | time: 6.131s
[2K
| Adam | epoch: 006 | loss: 0.68450 - acc: 0.5709 -- iter: 352/431
[A[ATraining Step: 82  | total loss: [1m[32m0.68612[0m[0m | time: 6.726s
[2K
| Adam | epoch: 006 | loss: 0.68612 - acc: 0.5638 -- iter: 384/431
[A[ATraining Step: 83  | total loss: [1m[32m0.68449[0m[0m | time: 7.331s
[2K
| Adam | epoch: 006 | loss: 0.68449 - acc: 0.5699 -- iter: 416/431
[A[ATraining Step: 84  | total loss: [1m[32m0.68150[0m[0m | time: 8.939s
[2K
| Adam | epoch: 006 | loss: 0.68150 - acc: 0.5817 | val_loss: 0.69467 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 85  | total loss: [1m[32m0.68262[0m[0m | time: 0.644s
[2K
| Adam | epoch: 007 | loss: 0.68262 - acc: 0.5766 -- iter: 032/431
[A[ATraining Step: 86  | total loss: [1m[32m0.67972[0m[0m | time: 1.245s
[2K
| Adam | epoch: 007 | loss: 0.67972 - acc: 0.5877 -- iter: 064/431
[A[ATraining Step: 87  | total loss: [1m[32m0.67784[0m[0m | time: 1.854s
[2K
| Adam | epoch: 007 | loss: 0.67784 - acc: 0.5946 -- iter: 096/431
[A[ATraining Step: 88  | total loss: [1m[32m0.68025[0m[0m | time: 2.447s
[2K
| Adam | epoch: 007 | loss: 0.68025 - acc: 0.5851 -- iter: 128/431
[A[ATraining Step: 89  | total loss: [1m[32m0.67977[0m[0m | time: 2.746s
[2K
| Adam | epoch: 007 | loss: 0.67977 - acc: 0.5860 -- iter: 160/431
[A[ATraining Step: 90  | total loss: [1m[32m0.68313[0m[0m | time: 3.050s
[2K
| Adam | epoch: 007 | loss: 0.68313 - acc: 0.5740 -- iter: 192/431
[A[ATraining Step: 91  | total loss: [1m[32m0.68607[0m[0m | time: 3.679s
[2K
| Adam | epoch: 007 | loss: 0.68607 - acc: 0.5633 -- iter: 224/431
[A[ATraining Step: 92  | total loss: [1m[32m0.68971[0m[0m | time: 4.270s
[2K
| Adam | epoch: 007 | loss: 0.68971 - acc: 0.5507 -- iter: 256/431
[A[ATraining Step: 93  | total loss: [1m[32m0.68315[0m[0m | time: 4.869s
[2K
| Adam | epoch: 007 | loss: 0.68315 - acc: 0.5738 -- iter: 288/431
[A[ATraining Step: 94  | total loss: [1m[32m0.67817[0m[0m | time: 5.481s
[2K
| Adam | epoch: 007 | loss: 0.67817 - acc: 0.5914 -- iter: 320/431
[A[ATraining Step: 95  | total loss: [1m[32m0.67800[0m[0m | time: 6.072s
[2K
| Adam | epoch: 007 | loss: 0.67800 - acc: 0.5916 -- iter: 352/431
[A[ATraining Step: 96  | total loss: [1m[32m0.67768[0m[0m | time: 6.679s
[2K
| Adam | epoch: 007 | loss: 0.67768 - acc: 0.5918 -- iter: 384/431
[A[ATraining Step: 97  | total loss: [1m[32m0.67752[0m[0m | time: 7.286s
[2K
| Adam | epoch: 007 | loss: 0.67752 - acc: 0.5920 -- iter: 416/431
[A[ATraining Step: 98  | total loss: [1m[32m0.67631[0m[0m | time: 8.895s
[2K
| Adam | epoch: 007 | loss: 0.67631 - acc: 0.5953 | val_loss: 0.69783 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 99  | total loss: [1m[32m0.67537[0m[0m | time: 0.608s
[2K
| Adam | epoch: 008 | loss: 0.67537 - acc: 0.5983 -- iter: 032/431
[A[ATraining Step: 100  | total loss: [1m[32m0.67528[0m[0m | time: 1.226s
[2K
| Adam | epoch: 008 | loss: 0.67528 - acc: 0.5978 -- iter: 064/431
[A[ATraining Step: 101  | total loss: [1m[32m0.68045[0m[0m | time: 1.830s
[2K
| Adam | epoch: 008 | loss: 0.68045 - acc: 0.5818 -- iter: 096/431
[A[ATraining Step: 102  | total loss: [1m[32m0.68310[0m[0m | time: 2.427s
[2K
| Adam | epoch: 008 | loss: 0.68310 - acc: 0.5736 -- iter: 128/431
[A[ATraining Step: 103  | total loss: [1m[32m0.68119[0m[0m | time: 3.040s
[2K
| Adam | epoch: 008 | loss: 0.68119 - acc: 0.5788 -- iter: 160/431
[A[ATraining Step: 104  | total loss: [1m[32m0.68281[0m[0m | time: 3.339s
[2K
| Adam | epoch: 008 | loss: 0.68281 - acc: 0.5740 -- iter: 192/431
[A[ATraining Step: 105  | total loss: [1m[32m0.68201[0m[0m | time: 3.657s
[2K
| Adam | epoch: 008 | loss: 0.68201 - acc: 0.5766 -- iter: 224/431
[A[ATraining Step: 106  | total loss: [1m[32m0.68091[0m[0m | time: 4.249s
[2K
| Adam | epoch: 008 | loss: 0.68091 - acc: 0.5790 -- iter: 256/431
[A[ATraining Step: 107  | total loss: [1m[32m0.68352[0m[0m | time: 4.879s
[2K
| Adam | epoch: 008 | loss: 0.68352 - acc: 0.5711 -- iter: 288/431
[A[ATraining Step: 108  | total loss: [1m[32m0.68597[0m[0m | time: 5.474s
[2K
| Adam | epoch: 008 | loss: 0.68597 - acc: 0.5640 -- iter: 320/431
[A[ATraining Step: 109  | total loss: [1m[32m0.68493[0m[0m | time: 6.079s
[2K
| Adam | epoch: 008 | loss: 0.68493 - acc: 0.5669 -- iter: 352/431
[A[ATraining Step: 110  | total loss: [1m[32m0.67991[0m[0m | time: 6.687s
[2K
| Adam | epoch: 008 | loss: 0.67991 - acc: 0.5821 -- iter: 384/431
[A[ATraining Step: 111  | total loss: [1m[32m0.68260[0m[0m | time: 7.291s
[2K
| Adam | epoch: 008 | loss: 0.68260 - acc: 0.5739 -- iter: 416/431
[A[ATraining Step: 112  | total loss: [1m[32m0.67687[0m[0m | time: 8.912s
[2K
| Adam | epoch: 008 | loss: 0.67687 - acc: 0.5915 | val_loss: 0.69815 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 113  | total loss: [1m[32m0.67786[0m[0m | time: 0.636s
[2K
| Adam | epoch: 009 | loss: 0.67786 - acc: 0.5886 -- iter: 032/431
[A[ATraining Step: 114  | total loss: [1m[32m0.67662[0m[0m | time: 1.228s
[2K
| Adam | epoch: 009 | loss: 0.67662 - acc: 0.5922 -- iter: 064/431
[A[ATraining Step: 115  | total loss: [1m[32m0.68085[0m[0m | time: 1.831s
[2K
| Adam | epoch: 009 | loss: 0.68085 - acc: 0.5799 -- iter: 096/431
[A[ATraining Step: 116  | total loss: [1m[32m0.68013[0m[0m | time: 2.429s
[2K
| Adam | epoch: 009 | loss: 0.68013 - acc: 0.5813 -- iter: 128/431
[A[ATraining Step: 117  | total loss: [1m[32m0.67955[0m[0m | time: 3.042s
[2K
| Adam | epoch: 009 | loss: 0.67955 - acc: 0.5825 -- iter: 160/431
[A[ATraining Step: 118  | total loss: [1m[32m0.67599[0m[0m | time: 3.647s
[2K
| Adam | epoch: 009 | loss: 0.67599 - acc: 0.5930 -- iter: 192/431
[A[ATraining Step: 119  | total loss: [1m[32m0.67366[0m[0m | time: 3.963s
[2K
| Adam | epoch: 009 | loss: 0.67366 - acc: 0.5994 -- iter: 224/431
[A[ATraining Step: 120  | total loss: [1m[32m0.68069[0m[0m | time: 4.272s
[2K
| Adam | epoch: 009 | loss: 0.68069 - acc: 0.5794 -- iter: 256/431
[A[ATraining Step: 121  | total loss: [1m[32m0.68672[0m[0m | time: 4.871s
[2K
| Adam | epoch: 009 | loss: 0.68672 - acc: 0.5615 -- iter: 288/431
[A[ATraining Step: 122  | total loss: [1m[32m0.68562[0m[0m | time: 5.506s
[2K
| Adam | epoch: 009 | loss: 0.68562 - acc: 0.5647 -- iter: 320/431
[A[ATraining Step: 123  | total loss: [1m[32m0.68879[0m[0m | time: 6.109s
[2K
| Adam | epoch: 009 | loss: 0.68879 - acc: 0.5551 -- iter: 352/431
[A[ATraining Step: 124  | total loss: [1m[32m0.68434[0m[0m | time: 6.729s
[2K
| Adam | epoch: 009 | loss: 0.68434 - acc: 0.5683 -- iter: 384/431
[A[ATraining Step: 125  | total loss: [1m[32m0.68241[0m[0m | time: 7.331s
[2K
| Adam | epoch: 009 | loss: 0.68241 - acc: 0.5740 -- iter: 416/431
[A[ATraining Step: 126  | total loss: [1m[32m0.68571[0m[0m | time: 8.947s
[2K
| Adam | epoch: 009 | loss: 0.68571 - acc: 0.5635 | val_loss: 0.69690 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 127  | total loss: [1m[32m0.68367[0m[0m | time: 0.784s
[2K
| Adam | epoch: 010 | loss: 0.68367 - acc: 0.5696 -- iter: 032/431
[A[ATraining Step: 128  | total loss: [1m[32m0.68282[0m[0m | time: 1.387s
[2K
| Adam | epoch: 010 | loss: 0.68282 - acc: 0.5720 -- iter: 064/431
[A[ATraining Step: 129  | total loss: [1m[32m0.68598[0m[0m | time: 1.989s
[2K
| Adam | epoch: 010 | loss: 0.68598 - acc: 0.5617 -- iter: 096/431
[A[ATraining Step: 130  | total loss: [1m[32m0.68310[0m[0m | time: 2.582s
[2K
| Adam | epoch: 010 | loss: 0.68310 - acc: 0.5712 -- iter: 128/431
[A[ATraining Step: 131  | total loss: [1m[32m0.68227[0m[0m | time: 3.170s
[2K
| Adam | epoch: 010 | loss: 0.68227 - acc: 0.5734 -- iter: 160/431
[A[ATraining Step: 132  | total loss: [1m[32m0.68358[0m[0m | time: 3.778s
[2K
| Adam | epoch: 010 | loss: 0.68358 - acc: 0.5692 -- iter: 192/431
[A[ATraining Step: 133  | total loss: [1m[32m0.68207[0m[0m | time: 4.395s
[2K
| Adam | epoch: 010 | loss: 0.68207 - acc: 0.5748 -- iter: 224/431
[A[ATraining Step: 134  | total loss: [1m[32m0.67957[0m[0m | time: 4.700s
[2K
| Adam | epoch: 010 | loss: 0.67957 - acc: 0.5829 -- iter: 256/431
[A[ATraining Step: 135  | total loss: [1m[32m0.67308[0m[0m | time: 5.006s
[2K
| Adam | epoch: 010 | loss: 0.67308 - acc: 0.6046 -- iter: 288/431
[A[ATraining Step: 136  | total loss: [1m[32m0.66711[0m[0m | time: 5.626s
[2K
| Adam | epoch: 010 | loss: 0.66711 - acc: 0.6242 -- iter: 320/431
[A[ATraining Step: 137  | total loss: [1m[32m0.66904[0m[0m | time: 6.252s
[2K
| Adam | epoch: 010 | loss: 0.66904 - acc: 0.6180 -- iter: 352/431
[A[ATraining Step: 138  | total loss: [1m[32m0.67069[0m[0m | time: 6.845s
[2K
| Adam | epoch: 010 | loss: 0.67069 - acc: 0.6125 -- iter: 384/431
[A[ATraining Step: 139  | total loss: [1m[32m0.67122[0m[0m | time: 7.435s
[2K
| Adam | epoch: 010 | loss: 0.67122 - acc: 0.6106 -- iter: 416/431
[A[ATraining Step: 140  | total loss: [1m[32m0.67061[0m[0m | time: 9.035s
[2K
| Adam | epoch: 010 | loss: 0.67061 - acc: 0.6120 | val_loss: 0.70073 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 141  | total loss: [1m[32m0.67686[0m[0m | time: 0.657s
[2K
| Adam | epoch: 011 | loss: 0.67686 - acc: 0.5946 -- iter: 032/431
[A[ATraining Step: 142  | total loss: [1m[32m0.67439[0m[0m | time: 1.248s
[2K
| Adam | epoch: 011 | loss: 0.67439 - acc: 0.6007 -- iter: 064/431
[A[ATraining Step: 143  | total loss: [1m[32m0.67211[0m[0m | time: 1.857s
[2K
| Adam | epoch: 011 | loss: 0.67211 - acc: 0.6063 -- iter: 096/431
[A[ATraining Step: 144  | total loss: [1m[32m0.67248[0m[0m | time: 2.451s
[2K
| Adam | epoch: 011 | loss: 0.67248 - acc: 0.6050 -- iter: 128/431
[A[ATraining Step: 145  | total loss: [1m[32m0.67779[0m[0m | time: 3.073s
[2K
| Adam | epoch: 011 | loss: 0.67779 - acc: 0.5914 -- iter: 160/431
[A[ATraining Step: 146  | total loss: [1m[32m0.68270[0m[0m | time: 3.668s
[2K
| Adam | epoch: 011 | loss: 0.68270 - acc: 0.5791 -- iter: 192/431
[A[ATraining Step: 147  | total loss: [1m[32m0.68321[0m[0m | time: 4.266s
[2K
| Adam | epoch: 011 | loss: 0.68321 - acc: 0.5775 -- iter: 224/431
[A[ATraining Step: 148  | total loss: [1m[32m0.68109[0m[0m | time: 4.856s
[2K
| Adam | epoch: 011 | loss: 0.68109 - acc: 0.5822 -- iter: 256/431
[A[ATraining Step: 149  | total loss: [1m[32m0.68513[0m[0m | time: 5.157s
[2K
| Adam | epoch: 011 | loss: 0.68513 - acc: 0.5709 -- iter: 288/431
[A[ATraining Step: 150  | total loss: [1m[32m0.68411[0m[0m | time: 5.464s
[2K
| Adam | epoch: 011 | loss: 0.68411 - acc: 0.5738 -- iter: 320/431
[A[ATraining Step: 151  | total loss: [1m[32m0.68298[0m[0m | time: 6.073s
[2K
| Adam | epoch: 011 | loss: 0.68298 - acc: 0.5764 -- iter: 352/431
[A[ATraining Step: 152  | total loss: [1m[32m0.68213[0m[0m | time: 6.685s
[2K
| Adam | epoch: 011 | loss: 0.68213 - acc: 0.5781 -- iter: 384/431
[A[ATraining Step: 153  | total loss: [1m[32m0.68147[0m[0m | time: 7.293s
[2K
| Adam | epoch: 011 | loss: 0.68147 - acc: 0.5797 -- iter: 416/431
[A[ATraining Step: 154  | total loss: [1m[32m0.68713[0m[0m | time: 8.889s
[2K
| Adam | epoch: 011 | loss: 0.68713 - acc: 0.5624 | val_loss: 0.69721 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 155  | total loss: [1m[32m0.68381[0m[0m | time: 0.601s
[2K
| Adam | epoch: 012 | loss: 0.68381 - acc: 0.5718 -- iter: 032/431
[A[ATraining Step: 156  | total loss: [1m[32m0.68096[0m[0m | time: 1.200s
[2K
| Adam | epoch: 012 | loss: 0.68096 - acc: 0.5802 -- iter: 064/431
[A[ATraining Step: 157  | total loss: [1m[32m0.68038[0m[0m | time: 1.812s
[2K
| Adam | epoch: 012 | loss: 0.68038 - acc: 0.5816 -- iter: 096/431
[A[ATraining Step: 158  | total loss: [1m[32m0.68184[0m[0m | time: 2.404s
[2K
| Adam | epoch: 012 | loss: 0.68184 - acc: 0.5765 -- iter: 128/431
[A[ATraining Step: 159  | total loss: [1m[32m0.68118[0m[0m | time: 3.018s
[2K
| Adam | epoch: 012 | loss: 0.68118 - acc: 0.5782 -- iter: 160/431
[A[ATraining Step: 160  | total loss: [1m[32m0.67961[0m[0m | time: 3.615s
[2K
| Adam | epoch: 012 | loss: 0.67961 - acc: 0.5829 -- iter: 192/431
[A[ATraining Step: 161  | total loss: [1m[32m0.67913[0m[0m | time: 4.235s
[2K
| Adam | epoch: 012 | loss: 0.67913 - acc: 0.5840 -- iter: 224/431
[A[ATraining Step: 162  | total loss: [1m[32m0.67781[0m[0m | time: 4.844s
[2K
| Adam | epoch: 012 | loss: 0.67781 - acc: 0.5881 -- iter: 256/431
[A[ATraining Step: 163  | total loss: [1m[32m0.68380[0m[0m | time: 5.450s
[2K
| Adam | epoch: 012 | loss: 0.68380 - acc: 0.5699 -- iter: 288/431
[A[ATraining Step: 164  | total loss: [1m[32m0.68292[0m[0m | time: 5.776s
[2K
| Adam | epoch: 012 | loss: 0.68292 - acc: 0.5723 -- iter: 320/431
[A[ATraining Step: 165  | total loss: [1m[32m0.67992[0m[0m | time: 6.080s
[2K
| Adam | epoch: 012 | loss: 0.67992 - acc: 0.5817 -- iter: 352/431
[A[ATraining Step: 166  | total loss: [1m[32m0.67725[0m[0m | time: 6.692s
[2K
| Adam | epoch: 012 | loss: 0.67725 - acc: 0.5902 -- iter: 384/431
[A[ATraining Step: 167  | total loss: [1m[32m0.67308[0m[0m | time: 7.287s
[2K
| Adam | epoch: 012 | loss: 0.67308 - acc: 0.6031 -- iter: 416/431
[A[ATraining Step: 168  | total loss: [1m[32m0.67001[0m[0m | time: 8.893s
[2K
| Adam | epoch: 012 | loss: 0.67001 - acc: 0.6115 | val_loss: 0.69967 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 169  | total loss: [1m[32m0.67377[0m[0m | time: 0.616s
[2K
| Adam | epoch: 013 | loss: 0.67377 - acc: 0.6004 -- iter: 032/431
[A[ATraining Step: 170  | total loss: [1m[32m0.67823[0m[0m | time: 1.222s
[2K
| Adam | epoch: 013 | loss: 0.67823 - acc: 0.5872 -- iter: 064/431
[A[ATraining Step: 171  | total loss: [1m[32m0.68149[0m[0m | time: 1.824s
[2K
| Adam | epoch: 013 | loss: 0.68149 - acc: 0.5785 -- iter: 096/431
[A[ATraining Step: 172  | total loss: [1m[32m0.68182[0m[0m | time: 2.432s
[2K
| Adam | epoch: 013 | loss: 0.68182 - acc: 0.5769 -- iter: 128/431
[A[ATraining Step: 173  | total loss: [1m[32m0.67996[0m[0m | time: 3.035s
[2K
| Adam | epoch: 013 | loss: 0.67996 - acc: 0.5817 -- iter: 160/431
[A[ATraining Step: 174  | total loss: [1m[32m0.68133[0m[0m | time: 3.639s
[2K
| Adam | epoch: 013 | loss: 0.68133 - acc: 0.5767 -- iter: 192/431
[A[ATraining Step: 175  | total loss: [1m[32m0.67589[0m[0m | time: 4.242s
[2K
| Adam | epoch: 013 | loss: 0.67589 - acc: 0.5909 -- iter: 224/431
[A[ATraining Step: 176  | total loss: [1m[32m0.67547[0m[0m | time: 4.846s
[2K
| Adam | epoch: 013 | loss: 0.67547 - acc: 0.5912 -- iter: 256/431
[A[ATraining Step: 177  | total loss: [1m[32m0.67396[0m[0m | time: 5.448s
[2K
| Adam | epoch: 013 | loss: 0.67396 - acc: 0.5945 -- iter: 288/431
[A[ATraining Step: 178  | total loss: [1m[32m0.67746[0m[0m | time: 6.055s
[2K
| Adam | epoch: 013 | loss: 0.67746 - acc: 0.5851 -- iter: 320/431
[A[ATraining Step: 179  | total loss: [1m[32m0.67266[0m[0m | time: 6.354s
[2K
| Adam | epoch: 013 | loss: 0.67266 - acc: 0.5953 -- iter: 352/431
[A[ATraining Step: 180  | total loss: [1m[32m0.66920[0m[0m | time: 6.677s
[2K
| Adam | epoch: 013 | loss: 0.66920 - acc: 0.6025 -- iter: 384/431
[A[ATraining Step: 181  | total loss: [1m[32m0.66561[0m[0m | time: 7.293s
[2K
| Adam | epoch: 013 | loss: 0.66561 - acc: 0.6089 -- iter: 416/431
[A[ATraining Step: 182  | total loss: [1m[32m0.66106[0m[0m | time: 8.887s
[2K
| Adam | epoch: 013 | loss: 0.66106 - acc: 0.6167 | val_loss: 0.74647 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 183  | total loss: [1m[32m0.66034[0m[0m | time: 0.645s
[2K
| Adam | epoch: 014 | loss: 0.66034 - acc: 0.6176 -- iter: 032/431
[A[ATraining Step: 184  | total loss: [1m[32m0.67152[0m[0m | time: 1.270s
[2K
| Adam | epoch: 014 | loss: 0.67152 - acc: 0.6027 -- iter: 064/431
[A[ATraining Step: 185  | total loss: [1m[32m0.67092[0m[0m | time: 1.879s
[2K
| Adam | epoch: 014 | loss: 0.67092 - acc: 0.6018 -- iter: 096/431
[A[ATraining Step: 186  | total loss: [1m[32m0.66988[0m[0m | time: 2.483s
[2K
| Adam | epoch: 014 | loss: 0.66988 - acc: 0.6010 -- iter: 128/431
[A[ATraining Step: 187  | total loss: [1m[32m0.66979[0m[0m | time: 3.084s
[2K
| Adam | epoch: 014 | loss: 0.66979 - acc: 0.5971 -- iter: 160/431
[A[ATraining Step: 188  | total loss: [1m[32m0.66863[0m[0m | time: 3.690s
[2K
| Adam | epoch: 014 | loss: 0.66863 - acc: 0.5999 -- iter: 192/431
[A[ATraining Step: 189  | total loss: [1m[32m0.66944[0m[0m | time: 4.326s
[2K
| Adam | epoch: 014 | loss: 0.66944 - acc: 0.5962 -- iter: 224/431
[A[ATraining Step: 190  | total loss: [1m[32m0.67349[0m[0m | time: 4.931s
[2K
| Adam | epoch: 014 | loss: 0.67349 - acc: 0.5834 -- iter: 256/431
[A[ATraining Step: 191  | total loss: [1m[32m0.67525[0m[0m | time: 5.532s
[2K
| Adam | epoch: 014 | loss: 0.67525 - acc: 0.5782 -- iter: 288/431
[A[ATraining Step: 192  | total loss: [1m[32m0.67359[0m[0m | time: 6.158s
[2K
| Adam | epoch: 014 | loss: 0.67359 - acc: 0.5829 -- iter: 320/431
[A[ATraining Step: 193  | total loss: [1m[32m0.67157[0m[0m | time: 6.774s
[2K
| Adam | epoch: 014 | loss: 0.67157 - acc: 0.5902 -- iter: 352/431
[A[ATraining Step: 194  | total loss: [1m[32m0.67412[0m[0m | time: 7.081s
[2K
| Adam | epoch: 014 | loss: 0.67412 - acc: 0.5781 -- iter: 384/431
[A[ATraining Step: 195  | total loss: [1m[32m0.67162[0m[0m | time: 7.397s
[2K
| Adam | epoch: 014 | loss: 0.67162 - acc: 0.5803 -- iter: 416/431
[A[ATraining Step: 196  | total loss: [1m[32m0.66847[0m[0m | time: 8.997s
[2K
| Adam | epoch: 014 | loss: 0.66847 - acc: 0.5822 | val_loss: 0.68061 - val_acc: 0.5259 -- iter: 431/431
--
Training Step: 197  | total loss: [1m[32m0.66727[0m[0m | time: 0.617s
[2K
| Adam | epoch: 015 | loss: 0.66727 - acc: 0.5803 -- iter: 032/431
[A[ATraining Step: 198  | total loss: [1m[32m0.66418[0m[0m | time: 1.221s
[2K
| Adam | epoch: 015 | loss: 0.66418 - acc: 0.5816 -- iter: 064/431
[A[ATraining Step: 199  | total loss: [1m[32m0.66174[0m[0m | time: 1.820s
[2K
| Adam | epoch: 015 | loss: 0.66174 - acc: 0.5891 -- iter: 096/431
[A[ATraining Step: 200  | total loss: [1m[32m0.65313[0m[0m | time: 3.432s
[2K
| Adam | epoch: 015 | loss: 0.65313 - acc: 0.6021 | val_loss: 0.66047 - val_acc: 0.5630 -- iter: 128/431
--
Training Step: 201  | total loss: [1m[32m0.67086[0m[0m | time: 4.034s
[2K
| Adam | epoch: 015 | loss: 0.67086 - acc: 0.5887 -- iter: 160/431
[A[ATraining Step: 202  | total loss: [1m[32m0.66302[0m[0m | time: 4.639s
[2K
| Adam | epoch: 015 | loss: 0.66302 - acc: 0.6017 -- iter: 192/431
[A[ATraining Step: 203  | total loss: [1m[32m0.65861[0m[0m | time: 5.236s
[2K
| Adam | epoch: 015 | loss: 0.65861 - acc: 0.6197 -- iter: 224/431
[A[ATraining Step: 204  | total loss: [1m[32m0.65810[0m[0m | time: 5.841s
[2K
| Adam | epoch: 015 | loss: 0.65810 - acc: 0.6233 -- iter: 256/431
[A[ATraining Step: 205  | total loss: [1m[32m0.65653[0m[0m | time: 6.441s
[2K
| Adam | epoch: 015 | loss: 0.65653 - acc: 0.6173 -- iter: 288/431
[A[ATraining Step: 206  | total loss: [1m[32m0.65312[0m[0m | time: 7.071s
[2K
| Adam | epoch: 015 | loss: 0.65312 - acc: 0.6149 -- iter: 320/431
[A[ATraining Step: 207  | total loss: [1m[32m0.65010[0m[0m | time: 7.670s
[2K
| Adam | epoch: 015 | loss: 0.65010 - acc: 0.6159 -- iter: 352/431
[A[ATraining Step: 208  | total loss: [1m[32m0.65269[0m[0m | time: 8.267s
[2K
| Adam | epoch: 015 | loss: 0.65269 - acc: 0.6043 -- iter: 384/431
[A[ATraining Step: 209  | total loss: [1m[32m0.64417[0m[0m | time: 8.563s
[2K
| Adam | epoch: 015 | loss: 0.64417 - acc: 0.6220 -- iter: 416/431
[A[ATraining Step: 210  | total loss: [1m[32m0.64540[0m[0m | time: 9.869s
[2K
| Adam | epoch: 015 | loss: 0.64540 - acc: 0.6198 | val_loss: 0.68516 - val_acc: 0.5407 -- iter: 431/431
--
Training Step: 211  | total loss: [1m[32m0.64224[0m[0m | time: 0.627s
[2K
| Adam | epoch: 016 | loss: 0.64224 - acc: 0.6245 -- iter: 032/431
[A[ATraining Step: 212  | total loss: [1m[32m0.65154[0m[0m | time: 1.216s
[2K
| Adam | epoch: 016 | loss: 0.65154 - acc: 0.6058 -- iter: 064/431
[A[ATraining Step: 213  | total loss: [1m[32m0.64133[0m[0m | time: 1.843s
[2K
| Adam | epoch: 016 | loss: 0.64133 - acc: 0.6202 -- iter: 096/431
[A[ATraining Step: 214  | total loss: [1m[32m0.62710[0m[0m | time: 2.451s
[2K
| Adam | epoch: 016 | loss: 0.62710 - acc: 0.6394 -- iter: 128/431
[A[ATraining Step: 215  | total loss: [1m[32m0.61322[0m[0m | time: 3.075s
[2K
| Adam | epoch: 016 | loss: 0.61322 - acc: 0.6536 -- iter: 160/431
[A[ATraining Step: 216  | total loss: [1m[32m0.65811[0m[0m | time: 3.672s
[2K
| Adam | epoch: 016 | loss: 0.65811 - acc: 0.6289 -- iter: 192/431
[A[ATraining Step: 217  | total loss: [1m[32m0.65271[0m[0m | time: 4.299s
[2K
| Adam | epoch: 016 | loss: 0.65271 - acc: 0.6316 -- iter: 224/431
[A[ATraining Step: 218  | total loss: [1m[32m0.65071[0m[0m | time: 4.911s
[2K
| Adam | epoch: 016 | loss: 0.65071 - acc: 0.6247 -- iter: 256/431
[A[ATraining Step: 219  | total loss: [1m[32m0.64069[0m[0m | time: 5.518s
[2K
| Adam | epoch: 016 | loss: 0.64069 - acc: 0.6279 -- iter: 288/431
[A[ATraining Step: 220  | total loss: [1m[32m0.63657[0m[0m | time: 6.119s
[2K
| Adam | epoch: 016 | loss: 0.63657 - acc: 0.6401 -- iter: 320/431
[A[ATraining Step: 221  | total loss: [1m[32m0.63347[0m[0m | time: 6.718s
[2K
| Adam | epoch: 016 | loss: 0.63347 - acc: 0.6511 -- iter: 352/431
[A[ATraining Step: 222  | total loss: [1m[32m0.63273[0m[0m | time: 7.329s
[2K
| Adam | epoch: 016 | loss: 0.63273 - acc: 0.6547 -- iter: 384/431
[A[ATraining Step: 223  | total loss: [1m[32m0.63753[0m[0m | time: 7.932s
[2K
| Adam | epoch: 016 | loss: 0.63753 - acc: 0.6424 -- iter: 416/431
[A[ATraining Step: 224  | total loss: [1m[32m0.63593[0m[0m | time: 9.238s
[2K
| Adam | epoch: 016 | loss: 0.63593 - acc: 0.6469 | val_loss: 0.64353 - val_acc: 0.6370 -- iter: 431/431
--
Training Step: 225  | total loss: [1m[32m0.62703[0m[0m | time: 0.314s
[2K
| Adam | epoch: 017 | loss: 0.62703 - acc: 0.6689 -- iter: 032/431
[A[ATraining Step: 226  | total loss: [1m[32m0.61731[0m[0m | time: 0.915s
[2K
| Adam | epoch: 017 | loss: 0.61731 - acc: 0.6820 -- iter: 064/431
[A[ATraining Step: 227  | total loss: [1m[32m0.60684[0m[0m | time: 1.514s
[2K
| Adam | epoch: 017 | loss: 0.60684 - acc: 0.6857 -- iter: 096/431
[A[ATraining Step: 228  | total loss: [1m[32m0.59381[0m[0m | time: 2.119s
[2K
| Adam | epoch: 017 | loss: 0.59381 - acc: 0.6952 -- iter: 128/431
[A[ATraining Step: 229  | total loss: [1m[32m0.59170[0m[0m | time: 2.748s
[2K
| Adam | epoch: 017 | loss: 0.59170 - acc: 0.6944 -- iter: 160/431
[A[ATraining Step: 230  | total loss: [1m[32m0.59573[0m[0m | time: 3.341s
[2K
| Adam | epoch: 017 | loss: 0.59573 - acc: 0.6969 -- iter: 192/431
[A[ATraining Step: 231  | total loss: [1m[32m0.58671[0m[0m | time: 3.959s
[2K
| Adam | epoch: 017 | loss: 0.58671 - acc: 0.7053 -- iter: 224/431
[A[ATraining Step: 232  | total loss: [1m[32m0.58061[0m[0m | time: 4.570s
[2K
| Adam | epoch: 017 | loss: 0.58061 - acc: 0.7098 -- iter: 256/431
[A[ATraining Step: 233  | total loss: [1m[32m0.57263[0m[0m | time: 5.179s
[2K
| Adam | epoch: 017 | loss: 0.57263 - acc: 0.7107 -- iter: 288/431
[A[ATraining Step: 234  | total loss: [1m[32m0.57119[0m[0m | time: 5.794s
[2K
| Adam | epoch: 017 | loss: 0.57119 - acc: 0.7115 -- iter: 320/431
[A[ATraining Step: 235  | total loss: [1m[32m0.57396[0m[0m | time: 6.400s
[2K
| Adam | epoch: 017 | loss: 0.57396 - acc: 0.7122 -- iter: 352/431
[A[ATraining Step: 236  | total loss: [1m[32m0.56904[0m[0m | time: 7.001s
[2K
| Adam | epoch: 017 | loss: 0.56904 - acc: 0.7191 -- iter: 384/431
[A[ATraining Step: 237  | total loss: [1m[32m0.56398[0m[0m | time: 7.617s
[2K
| Adam | epoch: 017 | loss: 0.56398 - acc: 0.7160 -- iter: 416/431
[A[ATraining Step: 238  | total loss: [1m[32m0.56836[0m[0m | time: 9.231s
[2K
| Adam | epoch: 017 | loss: 0.56836 - acc: 0.7006 | val_loss: 0.64979 - val_acc: 0.6296 -- iter: 431/431
--
Training Step: 239  | total loss: [1m[32m0.55190[0m[0m | time: 0.315s
[2K
| Adam | epoch: 018 | loss: 0.55190 - acc: 0.7118 -- iter: 032/431
[A[ATraining Step: 240  | total loss: [1m[32m0.54342[0m[0m | time: 0.615s
[2K
| Adam | epoch: 018 | loss: 0.54342 - acc: 0.7273 -- iter: 064/431
[A[ATraining Step: 241  | total loss: [1m[32m0.53759[0m[0m | time: 1.209s
[2K
| Adam | epoch: 018 | loss: 0.53759 - acc: 0.7346 -- iter: 096/431
[A[ATraining Step: 242  | total loss: [1m[32m0.53160[0m[0m | time: 1.812s
[2K
| Adam | epoch: 018 | loss: 0.53160 - acc: 0.7392 -- iter: 128/431
[A[ATraining Step: 243  | total loss: [1m[32m0.51974[0m[0m | time: 2.410s
[2K
| Adam | epoch: 018 | loss: 0.51974 - acc: 0.7497 -- iter: 160/431
[A[ATraining Step: 244  | total loss: [1m[32m0.54035[0m[0m | time: 3.012s
[2K
| Adam | epoch: 018 | loss: 0.54035 - acc: 0.7310 -- iter: 192/431
[A[ATraining Step: 245  | total loss: [1m[32m0.55243[0m[0m | time: 3.834s
[2K
| Adam | epoch: 018 | loss: 0.55243 - acc: 0.7235 -- iter: 224/431
[A[ATraining Step: 246  | total loss: [1m[32m0.54434[0m[0m | time: 4.442s
[2K
| Adam | epoch: 018 | loss: 0.54434 - acc: 0.7324 -- iter: 256/431
[A[ATraining Step: 247  | total loss: [1m[32m0.54522[0m[0m | time: 5.055s
[2K
| Adam | epoch: 018 | loss: 0.54522 - acc: 0.7373 -- iter: 288/431
[A[ATraining Step: 248  | total loss: [1m[32m0.54257[0m[0m | time: 5.660s
[2K
| Adam | epoch: 018 | loss: 0.54257 - acc: 0.7385 -- iter: 320/431
[A[ATraining Step: 249  | total loss: [1m[32m0.54195[0m[0m | time: 6.255s
[2K
| Adam | epoch: 018 | loss: 0.54195 - acc: 0.7303 -- iter: 352/431
[A[ATraining Step: 250  | total loss: [1m[32m0.53369[0m[0m | time: 6.856s
[2K
| Adam | epoch: 018 | loss: 0.53369 - acc: 0.7354 -- iter: 384/431
[A[ATraining Step: 251  | total loss: [1m[32m0.52232[0m[0m | time: 7.457s
[2K
| Adam | epoch: 018 | loss: 0.52232 - acc: 0.7400 -- iter: 416/431
[A[ATraining Step: 252  | total loss: [1m[32m0.51263[0m[0m | time: 9.108s
[2K
| Adam | epoch: 018 | loss: 0.51263 - acc: 0.7441 | val_loss: 0.57927 - val_acc: 0.7185 -- iter: 431/431
--
Training Step: 253  | total loss: [1m[32m0.51961[0m[0m | time: 0.619s
[2K
| Adam | epoch: 019 | loss: 0.51961 - acc: 0.7385 -- iter: 032/431
[A[ATraining Step: 254  | total loss: [1m[32m0.50319[0m[0m | time: 0.918s
[2K
| Adam | epoch: 019 | loss: 0.50319 - acc: 0.7521 -- iter: 064/431
[A[ATraining Step: 255  | total loss: [1m[32m0.49272[0m[0m | time: 1.225s
[2K
| Adam | epoch: 019 | loss: 0.49272 - acc: 0.7636 -- iter: 096/431
[A[ATraining Step: 256  | total loss: [1m[32m0.47370[0m[0m | time: 1.833s
[2K
| Adam | epoch: 019 | loss: 0.47370 - acc: 0.7739 -- iter: 128/431
[A[ATraining Step: 257  | total loss: [1m[32m0.48752[0m[0m | time: 2.436s
[2K
| Adam | epoch: 019 | loss: 0.48752 - acc: 0.7621 -- iter: 160/431
[A[ATraining Step: 258  | total loss: [1m[32m0.47761[0m[0m | time: 3.039s
[2K
| Adam | epoch: 019 | loss: 0.47761 - acc: 0.7703 -- iter: 192/431
[A[ATraining Step: 259  | total loss: [1m[32m0.46160[0m[0m | time: 3.664s
[2K
| Adam | epoch: 019 | loss: 0.46160 - acc: 0.7776 -- iter: 224/431
[A[ATraining Step: 260  | total loss: [1m[32m0.48716[0m[0m | time: 4.267s
[2K
| Adam | epoch: 019 | loss: 0.48716 - acc: 0.7686 -- iter: 256/431
[A[ATraining Step: 261  | total loss: [1m[32m0.47526[0m[0m | time: 4.856s
[2K
| Adam | epoch: 019 | loss: 0.47526 - acc: 0.7761 -- iter: 288/431
[A[ATraining Step: 262  | total loss: [1m[32m0.46567[0m[0m | time: 5.455s
[2K
| Adam | epoch: 019 | loss: 0.46567 - acc: 0.7860 -- iter: 320/431
[A[ATraining Step: 263  | total loss: [1m[32m0.44629[0m[0m | time: 6.056s
[2K
| Adam | epoch: 019 | loss: 0.44629 - acc: 0.8012 -- iter: 352/431
[A[ATraining Step: 264  | total loss: [1m[32m0.45424[0m[0m | time: 6.666s
[2K
| Adam | epoch: 019 | loss: 0.45424 - acc: 0.7898 -- iter: 384/431
[A[ATraining Step: 265  | total loss: [1m[32m0.45352[0m[0m | time: 7.266s
[2K
| Adam | epoch: 019 | loss: 0.45352 - acc: 0.7952 -- iter: 416/431
[A[ATraining Step: 266  | total loss: [1m[32m0.45179[0m[0m | time: 8.883s
[2K
| Adam | epoch: 019 | loss: 0.45179 - acc: 0.8000 | val_loss: 0.61622 - val_acc: 0.7111 -- iter: 431/431
--
Training Step: 267  | total loss: [1m[32m0.46705[0m[0m | time: 0.631s
[2K
| Adam | epoch: 020 | loss: 0.46705 - acc: 0.7888 -- iter: 032/431
[A[ATraining Step: 268  | total loss: [1m[32m0.45675[0m[0m | time: 1.237s
[2K
| Adam | epoch: 020 | loss: 0.45675 - acc: 0.7912 -- iter: 064/431
[A[ATraining Step: 269  | total loss: [1m[32m0.45126[0m[0m | time: 1.543s
[2K
| Adam | epoch: 020 | loss: 0.45126 - acc: 0.7870 -- iter: 096/431
[A[ATraining Step: 270  | total loss: [1m[32m0.45620[0m[0m | time: 1.858s
[2K
| Adam | epoch: 020 | loss: 0.45620 - acc: 0.7817 -- iter: 128/431
[A[ATraining Step: 271  | total loss: [1m[32m0.44327[0m[0m | time: 2.456s
[2K
| Adam | epoch: 020 | loss: 0.44327 - acc: 0.7902 -- iter: 160/431
[A[ATraining Step: 272  | total loss: [1m[32m0.43734[0m[0m | time: 3.054s
[2K
| Adam | epoch: 020 | loss: 0.43734 - acc: 0.7987 -- iter: 192/431
[A[ATraining Step: 273  | total loss: [1m[32m0.43167[0m[0m | time: 3.677s
[2K
| Adam | epoch: 020 | loss: 0.43167 - acc: 0.8000 -- iter: 224/431
[A[ATraining Step: 274  | total loss: [1m[32m0.43232[0m[0m | time: 4.284s
[2K
| Adam | epoch: 020 | loss: 0.43232 - acc: 0.7950 -- iter: 256/431
[A[ATraining Step: 275  | total loss: [1m[32m0.43606[0m[0m | time: 4.893s
[2K
| Adam | epoch: 020 | loss: 0.43606 - acc: 0.7968 -- iter: 288/431
[A[ATraining Step: 276  | total loss: [1m[32m0.42865[0m[0m | time: 5.500s
[2K
| Adam | epoch: 020 | loss: 0.42865 - acc: 0.8015 -- iter: 320/431
[A[ATraining Step: 277  | total loss: [1m[32m0.43728[0m[0m | time: 6.101s
[2K
| Adam | epoch: 020 | loss: 0.43728 - acc: 0.7963 -- iter: 352/431
[A[ATraining Step: 278  | total loss: [1m[32m0.42396[0m[0m | time: 6.723s
[2K
| Adam | epoch: 020 | loss: 0.42396 - acc: 0.8042 -- iter: 384/431
[A[ATraining Step: 279  | total loss: [1m[32m0.43279[0m[0m | time: 7.330s
[2K
| Adam | epoch: 020 | loss: 0.43279 - acc: 0.7925 -- iter: 416/431
[A[ATraining Step: 280  | total loss: [1m[32m0.42381[0m[0m | time: 8.947s
[2K
| Adam | epoch: 020 | loss: 0.42381 - acc: 0.8008 | val_loss: 0.62957 - val_acc: 0.7259 -- iter: 431/431
--
Training Step: 281  | total loss: [1m[32m0.42369[0m[0m | time: 0.619s
[2K
| Adam | epoch: 021 | loss: 0.42369 - acc: 0.8019 -- iter: 032/431
[A[ATraining Step: 282  | total loss: [1m[32m0.42523[0m[0m | time: 1.220s
[2K
| Adam | epoch: 021 | loss: 0.42523 - acc: 0.7968 -- iter: 064/431
[A[ATraining Step: 283  | total loss: [1m[32m0.41920[0m[0m | time: 1.813s
[2K
| Adam | epoch: 021 | loss: 0.41920 - acc: 0.8077 -- iter: 096/431
[A[ATraining Step: 284  | total loss: [1m[32m0.39697[0m[0m | time: 2.112s
[2K
| Adam | epoch: 021 | loss: 0.39697 - acc: 0.8238 -- iter: 128/431
[A[ATraining Step: 285  | total loss: [1m[32m0.39311[0m[0m | time: 2.413s
[2K
| Adam | epoch: 021 | loss: 0.39311 - acc: 0.8214 -- iter: 160/431
[A[ATraining Step: 286  | total loss: [1m[32m0.38470[0m[0m | time: 3.032s
[2K
| Adam | epoch: 021 | loss: 0.38470 - acc: 0.8260 -- iter: 192/431
[A[ATraining Step: 287  | total loss: [1m[32m0.37438[0m[0m | time: 3.630s
[2K
| Adam | epoch: 021 | loss: 0.37438 - acc: 0.8371 -- iter: 224/431
[A[ATraining Step: 288  | total loss: [1m[32m0.37643[0m[0m | time: 4.238s
[2K
| Adam | epoch: 021 | loss: 0.37643 - acc: 0.8440 -- iter: 256/431
[A[ATraining Step: 289  | total loss: [1m[32m0.36389[0m[0m | time: 4.834s
[2K
| Adam | epoch: 021 | loss: 0.36389 - acc: 0.8534 -- iter: 288/431
[A[ATraining Step: 290  | total loss: [1m[32m0.35065[0m[0m | time: 5.443s
[2K
| Adam | epoch: 021 | loss: 0.35065 - acc: 0.8649 -- iter: 320/431
[A[ATraining Step: 291  | total loss: [1m[32m0.34968[0m[0m | time: 6.061s
[2K
| Adam | epoch: 021 | loss: 0.34968 - acc: 0.8597 -- iter: 352/431
[A[ATraining Step: 292  | total loss: [1m[32m0.34201[0m[0m | time: 6.656s
[2K
| Adam | epoch: 021 | loss: 0.34201 - acc: 0.8674 -- iter: 384/431
[A[ATraining Step: 293  | total loss: [1m[32m0.34594[0m[0m | time: 7.277s
[2K
| Adam | epoch: 021 | loss: 0.34594 - acc: 0.8651 -- iter: 416/431
[A[ATraining Step: 294  | total loss: [1m[32m0.34689[0m[0m | time: 8.892s
[2K
| Adam | epoch: 021 | loss: 0.34689 - acc: 0.8661 | val_loss: 0.61316 - val_acc: 0.7630 -- iter: 431/431
--
Training Step: 295  | total loss: [1m[32m0.32901[0m[0m | time: 0.625s
[2K
| Adam | epoch: 022 | loss: 0.32901 - acc: 0.8701 -- iter: 032/431
[A[ATraining Step: 296  | total loss: [1m[32m0.32779[0m[0m | time: 1.247s
[2K
| Adam | epoch: 022 | loss: 0.32779 - acc: 0.8706 -- iter: 064/431
[A[ATraining Step: 297  | total loss: [1m[32m0.32933[0m[0m | time: 1.883s
[2K
| Adam | epoch: 022 | loss: 0.32933 - acc: 0.8679 -- iter: 096/431
[A[ATraining Step: 298  | total loss: [1m[32m0.32934[0m[0m | time: 2.499s
[2K
| Adam | epoch: 022 | loss: 0.32934 - acc: 0.8717 -- iter: 128/431
[A[ATraining Step: 299  | total loss: [1m[32m0.32373[0m[0m | time: 2.804s
[2K
| Adam | epoch: 022 | loss: 0.32373 - acc: 0.8752 -- iter: 160/431
[A[ATraining Step: 300  | total loss: [1m[32m0.31419[0m[0m | time: 3.106s
[2K
| Adam | epoch: 022 | loss: 0.31419 - acc: 0.8810 -- iter: 192/431
[A[ATraining Step: 301  | total loss: [1m[32m0.30210[0m[0m | time: 3.704s
[2K
| Adam | epoch: 022 | loss: 0.30210 - acc: 0.8862 -- iter: 224/431
[A[ATraining Step: 302  | total loss: [1m[32m0.29403[0m[0m | time: 4.310s
[2K
| Adam | epoch: 022 | loss: 0.29403 - acc: 0.8851 -- iter: 256/431
[A[ATraining Step: 303  | total loss: [1m[32m0.29798[0m[0m | time: 4.936s
[2K
| Adam | epoch: 022 | loss: 0.29798 - acc: 0.8872 -- iter: 288/431
[A[ATraining Step: 304  | total loss: [1m[32m0.28775[0m[0m | time: 5.581s
[2K
| Adam | epoch: 022 | loss: 0.28775 - acc: 0.8923 -- iter: 320/431
[A[ATraining Step: 305  | total loss: [1m[32m0.29042[0m[0m | time: 6.219s
[2K
| Adam | epoch: 022 | loss: 0.29042 - acc: 0.8905 -- iter: 352/431
[A[ATraining Step: 306  | total loss: [1m[32m0.28013[0m[0m | time: 6.856s
[2K
| Adam | epoch: 022 | loss: 0.28013 - acc: 0.8952 -- iter: 384/431
[A[ATraining Step: 307  | total loss: [1m[32m0.27562[0m[0m | time: 7.455s
[2K
| Adam | epoch: 022 | loss: 0.27562 - acc: 0.8995 -- iter: 416/431
[A[ATraining Step: 308  | total loss: [1m[32m0.25715[0m[0m | time: 9.082s
[2K
| Adam | epoch: 022 | loss: 0.25715 - acc: 0.9095 | val_loss: 0.66039 - val_acc: 0.7407 -- iter: 431/431
--
Training Step: 309  | total loss: [1m[32m0.25850[0m[0m | time: 0.620s
[2K
| Adam | epoch: 023 | loss: 0.25850 - acc: 0.9061 -- iter: 032/431
[A[ATraining Step: 310  | total loss: [1m[32m0.25767[0m[0m | time: 1.226s
[2K
| Adam | epoch: 023 | loss: 0.25767 - acc: 0.9029 -- iter: 064/431
[A[ATraining Step: 311  | total loss: [1m[32m0.25924[0m[0m | time: 1.823s
[2K
| Adam | epoch: 023 | loss: 0.25924 - acc: 0.9033 -- iter: 096/431
[A[ATraining Step: 312  | total loss: [1m[32m0.25391[0m[0m | time: 2.423s
[2K
| Adam | epoch: 023 | loss: 0.25391 - acc: 0.9036 -- iter: 128/431
[A[ATraining Step: 313  | total loss: [1m[32m0.23960[0m[0m | time: 3.032s
[2K
| Adam | epoch: 023 | loss: 0.23960 - acc: 0.9101 -- iter: 160/431
[A[ATraining Step: 314  | total loss: [1m[32m0.22454[0m[0m | time: 3.367s
[2K
| Adam | epoch: 023 | loss: 0.22454 - acc: 0.9191 -- iter: 192/431
[A[ATraining Step: 315  | total loss: [1m[32m0.20885[0m[0m | time: 3.669s
[2K
| Adam | epoch: 023 | loss: 0.20885 - acc: 0.9272 -- iter: 224/431
[A[ATraining Step: 316  | total loss: [1m[32m0.19366[0m[0m | time: 4.276s
[2K
| Adam | epoch: 023 | loss: 0.19366 - acc: 0.9345 -- iter: 256/431
[A[ATraining Step: 317  | total loss: [1m[32m0.18246[0m[0m | time: 4.910s
[2K
| Adam | epoch: 023 | loss: 0.18246 - acc: 0.9410 -- iter: 288/431
[A[ATraining Step: 318  | total loss: [1m[32m0.17123[0m[0m | time: 5.533s
[2K
| Adam | epoch: 023 | loss: 0.17123 - acc: 0.9438 -- iter: 320/431
[A[ATraining Step: 319  | total loss: [1m[32m0.21157[0m[0m | time: 6.117s
[2K
| Adam | epoch: 023 | loss: 0.21157 - acc: 0.9244 -- iter: 352/431
[A[ATraining Step: 320  | total loss: [1m[32m0.20863[0m[0m | time: 6.728s
[2K
| Adam | epoch: 023 | loss: 0.20863 - acc: 0.9288 -- iter: 384/431
[A[ATraining Step: 321  | total loss: [1m[32m0.23194[0m[0m | time: 7.338s
[2K
| Adam | epoch: 023 | loss: 0.23194 - acc: 0.9203 -- iter: 416/431
[A[ATraining Step: 322  | total loss: [1m[32m0.22643[0m[0m | time: 8.942s
[2K
| Adam | epoch: 023 | loss: 0.22643 - acc: 0.9158 | val_loss: 0.69550 - val_acc: 0.7556 -- iter: 431/431
--
Training Step: 323  | total loss: [1m[32m0.22572[0m[0m | time: 0.616s
[2K
| Adam | epoch: 024 | loss: 0.22572 - acc: 0.9148 -- iter: 032/431
[A[ATraining Step: 324  | total loss: [1m[32m0.22057[0m[0m | time: 1.227s
[2K
| Adam | epoch: 024 | loss: 0.22057 - acc: 0.9171 -- iter: 064/431
[A[ATraining Step: 325  | total loss: [1m[32m0.20984[0m[0m | time: 1.828s
[2K
| Adam | epoch: 024 | loss: 0.20984 - acc: 0.9254 -- iter: 096/431
[A[ATraining Step: 326  | total loss: [1m[32m0.20270[0m[0m | time: 2.452s
[2K
| Adam | epoch: 024 | loss: 0.20270 - acc: 0.9266 -- iter: 128/431
[A[ATraining Step: 327  | total loss: [1m[32m0.19644[0m[0m | time: 3.059s
[2K
| Adam | epoch: 024 | loss: 0.19644 - acc: 0.9308 -- iter: 160/431
[A[ATraining Step: 328  | total loss: [1m[32m0.18142[0m[0m | time: 3.668s
[2K
| Adam | epoch: 024 | loss: 0.18142 - acc: 0.9377 -- iter: 192/431
[A[ATraining Step: 329  | total loss: [1m[32m0.17985[0m[0m | time: 3.968s
[2K
| Adam | epoch: 024 | loss: 0.17985 - acc: 0.9377 -- iter: 224/431
[A[ATraining Step: 330  | total loss: [1m[32m0.21597[0m[0m | time: 4.276s
[2K
| Adam | epoch: 024 | loss: 0.21597 - acc: 0.9173 -- iter: 256/431
[A[ATraining Step: 331  | total loss: [1m[32m0.22302[0m[0m | time: 4.876s
[2K
| Adam | epoch: 024 | loss: 0.22302 - acc: 0.9122 -- iter: 288/431
[A[ATraining Step: 332  | total loss: [1m[32m0.21640[0m[0m | time: 5.492s
[2K
| Adam | epoch: 024 | loss: 0.21640 - acc: 0.9116 -- iter: 320/431
[A[ATraining Step: 333  | total loss: [1m[32m0.22366[0m[0m | time: 6.091s
[2K
| Adam | epoch: 024 | loss: 0.22366 - acc: 0.9080 -- iter: 352/431
[A[ATraining Step: 334  | total loss: [1m[32m0.21392[0m[0m | time: 6.721s
[2K
| Adam | epoch: 024 | loss: 0.21392 - acc: 0.9078 -- iter: 384/431
[A[ATraining Step: 335  | total loss: [1m[32m0.19863[0m[0m | time: 7.335s
[2K
| Adam | epoch: 024 | loss: 0.19863 - acc: 0.9170 -- iter: 416/431
[A[ATraining Step: 336  | total loss: [1m[32m0.18778[0m[0m | time: 8.954s
[2K
| Adam | epoch: 024 | loss: 0.18778 - acc: 0.9222 | val_loss: 0.49776 - val_acc: 0.8222 -- iter: 431/431
--
Training Step: 337  | total loss: [1m[32m0.18696[0m[0m | time: 0.612s
[2K
| Adam | epoch: 025 | loss: 0.18696 - acc: 0.9206 -- iter: 032/431
[A[ATraining Step: 338  | total loss: [1m[32m0.17800[0m[0m | time: 1.209s
[2K
| Adam | epoch: 025 | loss: 0.17800 - acc: 0.9285 -- iter: 064/431
[A[ATraining Step: 339  | total loss: [1m[32m0.17160[0m[0m | time: 1.848s
[2K
| Adam | epoch: 025 | loss: 0.17160 - acc: 0.9326 -- iter: 096/431
[A[ATraining Step: 340  | total loss: [1m[32m0.17568[0m[0m | time: 2.454s
[2K
| Adam | epoch: 025 | loss: 0.17568 - acc: 0.9299 -- iter: 128/431
[A[ATraining Step: 341  | total loss: [1m[32m0.17068[0m[0m | time: 3.053s
[2K
| Adam | epoch: 025 | loss: 0.17068 - acc: 0.9338 -- iter: 160/431
[A[ATraining Step: 342  | total loss: [1m[32m0.16367[0m[0m | time: 3.655s
[2K
| Adam | epoch: 025 | loss: 0.16367 - acc: 0.9342 -- iter: 192/431
[A[ATraining Step: 343  | total loss: [1m[32m0.17464[0m[0m | time: 4.256s
[2K
| Adam | epoch: 025 | loss: 0.17464 - acc: 0.9376 -- iter: 224/431
[A[ATraining Step: 344  | total loss: [1m[32m0.16190[0m[0m | time: 4.561s
[2K
| Adam | epoch: 025 | loss: 0.16190 - acc: 0.9439 -- iter: 256/431
[A[ATraining Step: 345  | total loss: [1m[32m0.15070[0m[0m | time: 4.888s
[2K
| Adam | epoch: 025 | loss: 0.15070 - acc: 0.9495 -- iter: 288/431
[A[ATraining Step: 346  | total loss: [1m[32m0.13964[0m[0m | time: 5.495s
[2K
| Adam | epoch: 025 | loss: 0.13964 - acc: 0.9545 -- iter: 320/431
[A[ATraining Step: 347  | total loss: [1m[32m0.13185[0m[0m | time: 6.096s
[2K
| Adam | epoch: 025 | loss: 0.13185 - acc: 0.9591 -- iter: 352/431
[A[ATraining Step: 348  | total loss: [1m[32m0.12872[0m[0m | time: 6.702s
[2K
| Adam | epoch: 025 | loss: 0.12872 - acc: 0.9600 -- iter: 384/431
[A[ATraining Step: 349  | total loss: [1m[32m0.14218[0m[0m | time: 7.308s
[2K
| Adam | epoch: 025 | loss: 0.14218 - acc: 0.9547 -- iter: 416/431
[A[ATraining Step: 350  | total loss: [1m[32m0.13791[0m[0m | time: 8.926s
[2K
| Adam | epoch: 025 | loss: 0.13791 - acc: 0.9561 | val_loss: 0.97094 - val_acc: 0.7111 -- iter: 431/431
--
Training Step: 351  | total loss: [1m[32m0.12743[0m[0m | time: 0.615s
[2K
| Adam | epoch: 026 | loss: 0.12743 - acc: 0.9605 -- iter: 032/431
[A[ATraining Step: 352  | total loss: [1m[32m0.11893[0m[0m | time: 1.230s
[2K
| Adam | epoch: 026 | loss: 0.11893 - acc: 0.9644 -- iter: 064/431
[A[ATraining Step: 353  | total loss: [1m[32m0.12986[0m[0m | time: 1.838s
[2K
| Adam | epoch: 026 | loss: 0.12986 - acc: 0.9524 -- iter: 096/431
[A[ATraining Step: 354  | total loss: [1m[32m0.11989[0m[0m | time: 2.451s
[2K
| Adam | epoch: 026 | loss: 0.11989 - acc: 0.9571 -- iter: 128/431
[A[ATraining Step: 355  | total loss: [1m[32m0.11019[0m[0m | time: 3.052s
[2K
| Adam | epoch: 026 | loss: 0.11019 - acc: 0.9614 -- iter: 160/431
[A[ATraining Step: 356  | total loss: [1m[32m0.11164[0m[0m | time: 3.661s
[2K
| Adam | epoch: 026 | loss: 0.11164 - acc: 0.9590 -- iter: 192/431
[A[ATraining Step: 357  | total loss: [1m[32m0.11722[0m[0m | time: 4.287s
[2K
| Adam | epoch: 026 | loss: 0.11722 - acc: 0.9569 -- iter: 224/431
[A[ATraining Step: 358  | total loss: [1m[32m0.11808[0m[0m | time: 4.891s
[2K
| Adam | epoch: 026 | loss: 0.11808 - acc: 0.9581 -- iter: 256/431
[A[ATraining Step: 359  | total loss: [1m[32m0.11502[0m[0m | time: 5.227s
[2K
| Adam | epoch: 026 | loss: 0.11502 - acc: 0.9591 -- iter: 288/431
[A[ATraining Step: 360  | total loss: [1m[32m0.15925[0m[0m | time: 5.535s
[2K
| Adam | epoch: 026 | loss: 0.15925 - acc: 0.9432 -- iter: 320/431
[A[ATraining Step: 361  | total loss: [1m[32m0.20129[0m[0m | time: 6.137s
[2K
| Adam | epoch: 026 | loss: 0.20129 - acc: 0.9222 -- iter: 352/431
[A[ATraining Step: 362  | total loss: [1m[32m0.19838[0m[0m | time: 6.741s
[2K
| Adam | epoch: 026 | loss: 0.19838 - acc: 0.9238 -- iter: 384/431
[A[ATraining Step: 363  | total loss: [1m[32m0.18529[0m[0m | time: 7.338s
[2K
| Adam | epoch: 026 | loss: 0.18529 - acc: 0.9283 -- iter: 416/431
[A[ATraining Step: 364  | total loss: [1m[32m0.17876[0m[0m | time: 9.040s
[2K
| Adam | epoch: 026 | loss: 0.17876 - acc: 0.9292 | val_loss: 0.68163 - val_acc: 0.7111 -- iter: 431/431
--
Training Step: 365  | total loss: [1m[32m0.16808[0m[0m | time: 0.614s
[2K
| Adam | epoch: 027 | loss: 0.16808 - acc: 0.9363 -- iter: 032/431
[A[ATraining Step: 366  | total loss: [1m[32m0.17840[0m[0m | time: 1.220s
[2K
| Adam | epoch: 027 | loss: 0.17840 - acc: 0.9270 -- iter: 064/431
[A[ATraining Step: 367  | total loss: [1m[32m0.16719[0m[0m | time: 1.817s
[2K
| Adam | epoch: 027 | loss: 0.16719 - acc: 0.9312 -- iter: 096/431
[A[ATraining Step: 368  | total loss: [1m[32m0.15191[0m[0m | time: 2.443s
[2K
| Adam | epoch: 027 | loss: 0.15191 - acc: 0.9381 -- iter: 128/431
[A[ATraining Step: 369  | total loss: [1m[32m0.14424[0m[0m | time: 3.041s
[2K
| Adam | epoch: 027 | loss: 0.14424 - acc: 0.9411 -- iter: 160/431
[A[ATraining Step: 370  | total loss: [1m[32m0.13608[0m[0m | time: 3.642s
[2K
| Adam | epoch: 027 | loss: 0.13608 - acc: 0.9470 -- iter: 192/431
[A[ATraining Step: 371  | total loss: [1m[32m0.13539[0m[0m | time: 4.263s
[2K
| Adam | epoch: 027 | loss: 0.13539 - acc: 0.9461 -- iter: 224/431
[A[ATraining Step: 372  | total loss: [1m[32m0.12473[0m[0m | time: 4.865s
[2K
| Adam | epoch: 027 | loss: 0.12473 - acc: 0.9515 -- iter: 256/431
[A[ATraining Step: 373  | total loss: [1m[32m0.14673[0m[0m | time: 5.495s
[2K
| Adam | epoch: 027 | loss: 0.14673 - acc: 0.9501 -- iter: 288/431
[A[ATraining Step: 374  | total loss: [1m[32m0.14924[0m[0m | time: 5.799s
[2K
| Adam | epoch: 027 | loss: 0.14924 - acc: 0.9488 -- iter: 320/431
[A[ATraining Step: 375  | total loss: [1m[32m0.13906[0m[0m | time: 6.113s
[2K
| Adam | epoch: 027 | loss: 0.13906 - acc: 0.9539 -- iter: 352/431
[A[ATraining Step: 376  | total loss: [1m[32m0.12646[0m[0m | time: 6.719s
[2K
| Adam | epoch: 027 | loss: 0.12646 - acc: 0.9585 -- iter: 384/431
[A[ATraining Step: 377  | total loss: [1m[32m0.11858[0m[0m | time: 7.311s
[2K
| Adam | epoch: 027 | loss: 0.11858 - acc: 0.9627 -- iter: 416/431
[A[ATraining Step: 378  | total loss: [1m[32m0.10942[0m[0m | time: 8.938s
[2K
| Adam | epoch: 027 | loss: 0.10942 - acc: 0.9664 | val_loss: 0.77185 - val_acc: 0.7704 -- iter: 431/431
--
Training Step: 379  | total loss: [1m[32m0.10093[0m[0m | time: 0.612s
[2K
| Adam | epoch: 028 | loss: 0.10093 - acc: 0.9698 -- iter: 032/431
[A[ATraining Step: 380  | total loss: [1m[32m0.10447[0m[0m | time: 1.222s
[2K
| Adam | epoch: 028 | loss: 0.10447 - acc: 0.9697 -- iter: 064/431
[A[ATraining Step: 381  | total loss: [1m[32m0.10028[0m[0m | time: 1.824s
[2K
| Adam | epoch: 028 | loss: 0.10028 - acc: 0.9696 -- iter: 096/431
[A[ATraining Step: 382  | total loss: [1m[32m0.09240[0m[0m | time: 2.469s
[2K
| Adam | epoch: 028 | loss: 0.09240 - acc: 0.9726 -- iter: 128/431
[A[ATraining Step: 383  | total loss: [1m[32m0.08752[0m[0m | time: 3.058s
[2K
| Adam | epoch: 028 | loss: 0.08752 - acc: 0.9722 -- iter: 160/431
[A[ATraining Step: 384  | total loss: [1m[32m0.07977[0m[0m | time: 3.669s
[2K
| Adam | epoch: 028 | loss: 0.07977 - acc: 0.9750 -- iter: 192/431
[A[ATraining Step: 385  | total loss: [1m[32m0.07368[0m[0m | time: 4.269s
[2K
| Adam | epoch: 028 | loss: 0.07368 - acc: 0.9775 -- iter: 224/431
[A[ATraining Step: 386  | total loss: [1m[32m0.06721[0m[0m | time: 4.899s
[2K
| Adam | epoch: 028 | loss: 0.06721 - acc: 0.9798 -- iter: 256/431
[A[ATraining Step: 387  | total loss: [1m[32m0.07122[0m[0m | time: 5.520s
[2K
| Adam | epoch: 028 | loss: 0.07122 - acc: 0.9787 -- iter: 288/431
[A[ATraining Step: 388  | total loss: [1m[32m0.07794[0m[0m | time: 6.115s
[2K
| Adam | epoch: 028 | loss: 0.07794 - acc: 0.9777 -- iter: 320/431
[A[ATraining Step: 389  | total loss: [1m[32m0.08306[0m[0m | time: 6.423s
[2K
| Adam | epoch: 028 | loss: 0.08306 - acc: 0.9768 -- iter: 352/431
[A[ATraining Step: 390  | total loss: [1m[32m0.07550[0m[0m | time: 6.744s
[2K
| Adam | epoch: 028 | loss: 0.07550 - acc: 0.9791 -- iter: 384/431
[A[ATraining Step: 391  | total loss: [1m[32m0.06877[0m[0m | time: 7.343s
[2K
| Adam | epoch: 028 | loss: 0.06877 - acc: 0.9812 -- iter: 416/431
[A[ATraining Step: 392  | total loss: [1m[32m0.06342[0m[0m | time: 8.954s
[2K
| Adam | epoch: 028 | loss: 0.06342 - acc: 0.9831 | val_loss: 0.58938 - val_acc: 0.8444 -- iter: 431/431
--
Training Step: 393  | total loss: [1m[32m0.05882[0m[0m | time: 0.620s
[2K
| Adam | epoch: 029 | loss: 0.05882 - acc: 0.9848 -- iter: 032/431
[A[ATraining Step: 394  | total loss: [1m[32m0.05448[0m[0m | time: 1.224s
[2K
| Adam | epoch: 029 | loss: 0.05448 - acc: 0.9863 -- iter: 064/431
[A[ATraining Step: 395  | total loss: [1m[32m0.05089[0m[0m | time: 1.823s
[2K
| Adam | epoch: 029 | loss: 0.05089 - acc: 0.9877 -- iter: 096/431
[A[ATraining Step: 396  | total loss: [1m[32m0.04786[0m[0m | time: 2.422s
[2K
| Adam | epoch: 029 | loss: 0.04786 - acc: 0.9889 -- iter: 128/431
[A[ATraining Step: 397  | total loss: [1m[32m0.04668[0m[0m | time: 3.022s
[2K
| Adam | epoch: 029 | loss: 0.04668 - acc: 0.9869 -- iter: 160/431
[A[ATraining Step: 398  | total loss: [1m[32m0.04428[0m[0m | time: 3.625s
[2K
| Adam | epoch: 029 | loss: 0.04428 - acc: 0.9882 -- iter: 192/431
[A[ATraining Step: 399  | total loss: [1m[32m0.04192[0m[0m | time: 4.222s
[2K
| Adam | epoch: 029 | loss: 0.04192 - acc: 0.9894 -- iter: 224/431
[A[ATraining Step: 400  | total loss: [1m[32m0.03876[0m[0m | time: 5.830s
[2K
| Adam | epoch: 029 | loss: 0.03876 - acc: 0.9904 | val_loss: 0.68760 - val_acc: 0.8296 -- iter: 256/431
--
Training Step: 401  | total loss: [1m[32m0.03600[0m[0m | time: 6.458s
[2K
| Adam | epoch: 029 | loss: 0.03600 - acc: 0.9914 -- iter: 288/431
[A[ATraining Step: 402  | total loss: [1m[32m0.03962[0m[0m | time: 7.063s
[2K
| Adam | epoch: 029 | loss: 0.03962 - acc: 0.9891 -- iter: 320/431
[A[ATraining Step: 403  | total loss: [1m[32m0.05733[0m[0m | time: 7.669s
[2K
| Adam | epoch: 029 | loss: 0.05733 - acc: 0.9871 -- iter: 352/431
[A[ATraining Step: 404  | total loss: [1m[32m0.05236[0m[0m | time: 7.967s
[2K
| Adam | epoch: 029 | loss: 0.05236 - acc: 0.9884 -- iter: 384/431
[A[ATraining Step: 405  | total loss: [1m[32m0.04798[0m[0m | time: 8.271s
[2K
| Adam | epoch: 029 | loss: 0.04798 - acc: 0.9895 -- iter: 416/431
[A[ATraining Step: 406  | total loss: [1m[32m0.04402[0m[0m | time: 9.875s
[2K
| Adam | epoch: 029 | loss: 0.04402 - acc: 0.9906 | val_loss: 0.69874 - val_acc: 0.8074 -- iter: 431/431
--
Training Step: 407  | total loss: [1m[32m0.04023[0m[0m | time: 0.625s
[2K
| Adam | epoch: 030 | loss: 0.04023 - acc: 0.9915 -- iter: 032/431
[A[ATraining Step: 408  | total loss: [1m[32m0.03680[0m[0m | time: 1.246s
[2K
| Adam | epoch: 030 | loss: 0.03680 - acc: 0.9924 -- iter: 064/431
[A[ATraining Step: 409  | total loss: [1m[32m0.03355[0m[0m | time: 1.848s
[2K
| Adam | epoch: 030 | loss: 0.03355 - acc: 0.9931 -- iter: 096/431
[A[ATraining Step: 410  | total loss: [1m[32m0.03243[0m[0m | time: 2.456s
[2K
| Adam | epoch: 030 | loss: 0.03243 - acc: 0.9938 -- iter: 128/431
[A[ATraining Step: 411  | total loss: [1m[32m0.03019[0m[0m | time: 3.076s
[2K
| Adam | epoch: 030 | loss: 0.03019 - acc: 0.9944 -- iter: 160/431
[A[ATraining Step: 412  | total loss: [1m[32m0.02855[0m[0m | time: 3.675s
[2K
| Adam | epoch: 030 | loss: 0.02855 - acc: 0.9950 -- iter: 192/431
[A[ATraining Step: 413  | total loss: [1m[32m0.02626[0m[0m | time: 4.274s
[2K
| Adam | epoch: 030 | loss: 0.02626 - acc: 0.9955 -- iter: 224/431
[A[ATraining Step: 414  | total loss: [1m[32m0.02404[0m[0m | time: 4.883s
[2K
| Adam | epoch: 030 | loss: 0.02404 - acc: 0.9959 -- iter: 256/431
[A[ATraining Step: 415  | total loss: [1m[32m0.02216[0m[0m | time: 5.481s
[2K
| Adam | epoch: 030 | loss: 0.02216 - acc: 0.9964 -- iter: 288/431
[A[ATraining Step: 416  | total loss: [1m[32m0.02094[0m[0m | time: 6.082s
[2K
| Adam | epoch: 030 | loss: 0.02094 - acc: 0.9967 -- iter: 320/431
[A[ATraining Step: 417  | total loss: [1m[32m0.01997[0m[0m | time: 6.700s
[2K
| Adam | epoch: 030 | loss: 0.01997 - acc: 0.9970 -- iter: 352/431
[A[ATraining Step: 418  | total loss: [1m[32m0.03647[0m[0m | time: 7.314s
[2K
| Adam | epoch: 030 | loss: 0.03647 - acc: 0.9942 -- iter: 384/431
[A[ATraining Step: 419  | total loss: [1m[32m0.03343[0m[0m | time: 7.623s
[2K
| Adam | epoch: 030 | loss: 0.03343 - acc: 0.9948 -- iter: 416/431
[A[ATraining Step: 420  | total loss: [1m[32m0.03042[0m[0m | time: 8.950s
[2K
| Adam | epoch: 030 | loss: 0.03042 - acc: 0.9953 | val_loss: 1.14345 - val_acc: 0.7185 -- iter: 431/431
--
Validation AUC:0.8840228873239437
Validation AUPRC:0.885244458976957
Test AUC:0.896180860403863
Test AUPRC:0.8947702687548552
BestTestF1Score	0.85	0.69	0.84	0.83	0.87	58	12	56	9	0.99
BestTestMCCScore	0.85	0.69	0.84	0.83	0.87	58	12	56	9	0.99
BestTestAccuracyScore	0.85	0.69	0.84	0.83	0.87	58	12	56	9	0.99
BestValidationF1Score	0.84	0.65	0.82	0.79	0.9	64	17	47	7	0.99
BestValidationMCC	0.84	0.65	0.82	0.79	0.9	64	17	47	7	0.99
BestValidationAccuracy	0.84	0.65	0.82	0.79	0.9	64	17	47	7	0.99
TestPredictions (Threshold:0.99)
CHEMBL2348089,TP,ACT,1.0	CHEMBL332145,TN,INACT,0.029999999329447746	CHEMBL604328,TN,INACT,0.0	CHEMBL1819450,FP,INACT,1.0	CHEMBL1766901,TP,ACT,1.0	CHEMBL3104662,TP,ACT,0.9900000095367432	CHEMBL1767005,TP,ACT,1.0	CHEMBL1819448,FP,INACT,1.0	CHEMBL516281,TN,INACT,0.09000000357627869	CHEMBL2164079,TP,ACT,1.0	CHEMBL252965,TN,INACT,0.0	CHEMBL102970,TN,INACT,0.6000000238418579	CHEMBL475668,TP,ACT,1.0	CHEMBL3104667,TP,ACT,1.0	CHEMBL1784344,TP,ACT,0.9900000095367432	CHEMBL1270274,TN,INACT,0.07000000029802322	CHEMBL477965,TP,ACT,1.0	CHEMBL232565,FN,ACT,0.0	CHEMBL574274,FP,INACT,1.0	CHEMBL1784371,TP,ACT,1.0	CHEMBL231000,TP,ACT,1.0	CHEMBL79433,TP,ACT,1.0	CHEMBL482319,TN,INACT,0.019999999552965164	CHEMBL324842,TN,INACT,0.1599999964237213	CHEMBL236317,TP,ACT,1.0	CHEMBL2048503,TN,INACT,0.800000011920929	CHEMBL200435,TN,INACT,0.6700000166893005	CHEMBL235890,TP,ACT,1.0	CHEMBL2337698,TP,ACT,1.0	CHEMBL1784369,TP,ACT,1.0	CHEMBL401435,TP,ACT,1.0	CHEMBL2437176,FN,ACT,0.9800000190734863	CHEMBL252523,TN,INACT,0.0	CHEMBL395503,TP,ACT,1.0	CHEMBL474607,TP,ACT,1.0	CHEMBL2437165,TP,ACT,1.0	CHEMBL2151349,TN,INACT,0.9599999785423279	CHEMBL231962,TP,ACT,1.0	CHEMBL489231,TN,INACT,0.029999999329447746	CHEMBL3104674,TP,ACT,1.0	CHEMBL121188,TN,INACT,0.0	CHEMBL2163735,TP,ACT,1.0	CHEMBL115460,TN,INACT,0.009999999776482582	CHEMBL603452,TN,INACT,0.0	CHEMBL1767010,TP,ACT,1.0	CHEMBL1078454,FN,ACT,0.4099999964237213	CHEMBL228229,TN,INACT,0.9700000286102295	CHEMBL1819325,TN,INACT,0.4300000071525574	CHEMBL475598,TP,ACT,1.0	CHEMBL2348090,TP,ACT,0.9900000095367432	CHEMBL1767009,TP,ACT,1.0	CHEMBL250058,TN,INACT,0.9800000190734863	CHEMBL501715,TN,INACT,0.949999988079071	CHEMBL251937,TN,INACT,0.27000001072883606	CHEMBL1766897,FN,ACT,0.949999988079071	CHEMBL392264,TN,INACT,0.9300000071525574	CHEMBL1213795,TN,INACT,0.0	CHEMBL1767017,TP,ACT,1.0	CHEMBL480379,TP,ACT,1.0	CHEMBL1269961,TN,INACT,0.05999999865889549	CHEMBL1433,TN,INACT,0.0	CHEMBL489826,TN,INACT,0.009999999776482582	CHEMBL481712,TN,INACT,0.20999999344348907	CHEMBL103375,FP,INACT,0.9900000095367432	CHEMBL512902,TP,ACT,1.0	CHEMBL482171,TP,ACT,1.0	CHEMBL310555,TN,INACT,0.07000000029802322	CHEMBL482961,TN,INACT,0.4399999976158142	CHEMBL3775221,TN,INACT,0.0	CHEMBL94873,TN,INACT,0.8799999952316284	CHEMBL1766920,TP,ACT,1.0	CHEMBL2164110,TP,ACT,1.0	CHEMBL316884,FP,INACT,1.0	CHEMBL253835,TN,INACT,0.07000000029802322	CHEMBL2348070,TP,ACT,1.0	CHEMBL473638,TP,ACT,1.0	CHEMBL253373,TN,INACT,0.25999999046325684	CHEMBL2164103,TP,ACT,1.0	CHEMBL442073,TP,ACT,0.9900000095367432	CHEMBL2440437,TN,INACT,0.0	CHEMBL1819327,TN,INACT,0.10999999940395355	CHEMBL290632,TN,INACT,0.09000000357627869	CHEMBL451577,FN,ACT,0.18000000715255737	CHEMBL1427458,FP,INACT,1.0	CHEMBL491050,TN,INACT,0.009999999776482582	CHEMBL1927185,TN,INACT,0.7300000190734863	CHEMBL62186,TN,INACT,0.9700000286102295	CHEMBL1160686,TN,INACT,0.03999999910593033	CHEMBL550038,TN,INACT,0.8500000238418579	CHEMBL236942,TP,ACT,1.0	CHEMBL121501,TN,INACT,0.009999999776482582	CHEMBL3358158,TP,ACT,1.0	CHEMBL1784345,TP,ACT,0.9900000095367432	CHEMBL2348078,TP,ACT,1.0	CHEMBL2437167,TP,ACT,1.0	CHEMBL2437173,TP,ACT,1.0	CHEMBL231740,FN,ACT,0.9800000190734863	CHEMBL3104669,TP,ACT,1.0	CHEMBL3593362,TN,INACT,0.9700000286102295	CHEMBL1819447,TN,INACT,0.75	CHEMBL2048511,FP,INACT,1.0	CHEMBL481894,TP,ACT,1.0	CHEMBL448604,FN,ACT,0.28999999165534973	CHEMBL1683463,TN,INACT,0.7200000286102295	CHEMBL1784370,TP,ACT,1.0	CHEMBL1767014,TP,ACT,1.0	CHEMBL3828582,TN,INACT,0.6299999952316284	CHEMBL476638,TN,INACT,0.1599999964237213	CHEMBL1819331,FP,INACT,0.9900000095367432	CHEMBL254039,TN,INACT,0.8399999737739563	CHEMBL1819445,FP,INACT,1.0	CHEMBL435131,TN,INACT,0.8999999761581421	CHEMBL2151353,TN,INACT,0.8700000047683716	CHEMBL1910455,TN,INACT,0.8999999761581421	CHEMBL1939872,TN,INACT,0.009999999776482582	CHEMBL254627,TN,INACT,0.10000000149011612	CHEMBL1784362,TP,ACT,1.0	CHEMBL19611,FN,ACT,0.5199999809265137	CHEMBL575654,TN,INACT,0.019999999552965164	CHEMBL181682,FP,INACT,1.0	CHEMBL1784341,TP,ACT,1.0	CHEMBL2437189,TP,ACT,1.0	CHEMBL1079173,TP,ACT,1.0	CHEMBL1766896,TP,ACT,1.0	CHEMBL2437156,TP,ACT,1.0	CHEMBL392395,TP,ACT,1.0	CHEMBL514669,TP,ACT,1.0	CHEMBL230725,TP,ACT,1.0	CHEMBL324891,FP,INACT,1.0	CHEMBL2437181,TP,ACT,0.9900000095367432	CHEMBL2437186,FN,ACT,0.9700000286102295	CHEMBL567341,FP,INACT,1.0	CHEMBL1767008,TP,ACT,1.0	CHEMBL1939844,TN,INACT,0.0	CHEMBL1770649,TN,INACT,0.8799999952316284	

