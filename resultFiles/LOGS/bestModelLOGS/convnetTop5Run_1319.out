ImageNetInceptionV2 CHEMBL1898 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	934
Number of inactive compounds :	934
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1898_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1898_adam_0.0005_15_0.6/
---------------------------------
Training samples: 1177
Validation samples: 368
--
Training Step: 1  | time: 35.001s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1177
[A[ATraining Step: 2  | total loss: [1m[32m0.67924[0m[0m | time: 43.036s
[2K
| Adam | epoch: 001 | loss: 0.67924 - acc: 0.3937 -- iter: 0064/1177
[A[ATraining Step: 3  | total loss: [1m[32m0.81122[0m[0m | time: 50.977s
[2K
| Adam | epoch: 001 | loss: 0.81122 - acc: 0.4040 -- iter: 0096/1177
[A[ATraining Step: 4  | total loss: [1m[32m0.63946[0m[0m | time: 58.962s
[2K
| Adam | epoch: 001 | loss: 0.63946 - acc: 0.6635 -- iter: 0128/1177
[A[ATraining Step: 5  | total loss: [1m[32m0.66343[0m[0m | time: 66.934s
[2K
| Adam | epoch: 001 | loss: 0.66343 - acc: 0.5719 -- iter: 0160/1177
[A[ATraining Step: 6  | total loss: [1m[32m0.66283[0m[0m | time: 74.862s
[2K
| Adam | epoch: 001 | loss: 0.66283 - acc: 0.5659 -- iter: 0192/1177
[A[ATraining Step: 7  | total loss: [1m[32m0.71169[0m[0m | time: 82.691s
[2K
| Adam | epoch: 001 | loss: 0.71169 - acc: 0.4701 -- iter: 0224/1177
[A[ATraining Step: 8  | total loss: [1m[32m0.64085[0m[0m | time: 90.874s
[2K
| Adam | epoch: 001 | loss: 0.64085 - acc: 0.6100 -- iter: 0256/1177
[A[ATraining Step: 9  | total loss: [1m[32m0.68189[0m[0m | time: 98.814s
[2K
| Adam | epoch: 001 | loss: 0.68189 - acc: 0.5848 -- iter: 0288/1177
[A[ATraining Step: 10  | total loss: [1m[32m0.60613[0m[0m | time: 106.714s
[2K
| Adam | epoch: 001 | loss: 0.60613 - acc: 0.6518 -- iter: 0320/1177
[A[ATraining Step: 11  | total loss: [1m[32m0.64319[0m[0m | time: 114.756s
[2K
| Adam | epoch: 001 | loss: 0.64319 - acc: 0.6391 -- iter: 0352/1177
[A[ATraining Step: 12  | total loss: [1m[32m0.64118[0m[0m | time: 122.635s
[2K
| Adam | epoch: 001 | loss: 0.64118 - acc: 0.6609 -- iter: 0384/1177
[A[ATraining Step: 13  | total loss: [1m[32m0.62637[0m[0m | time: 130.540s
[2K
| Adam | epoch: 001 | loss: 0.62637 - acc: 0.6723 -- iter: 0416/1177
[A[ATraining Step: 14  | total loss: [1m[32m0.62643[0m[0m | time: 138.516s
[2K
| Adam | epoch: 001 | loss: 0.62643 - acc: 0.6402 -- iter: 0448/1177
[A[ATraining Step: 15  | total loss: [1m[32m0.56341[0m[0m | time: 146.473s
[2K
| Adam | epoch: 001 | loss: 0.56341 - acc: 0.7321 -- iter: 0480/1177
[A[ATraining Step: 16  | total loss: [1m[32m0.53241[0m[0m | time: 154.420s
[2K
| Adam | epoch: 001 | loss: 0.53241 - acc: 0.7505 -- iter: 0512/1177
[A[ATraining Step: 17  | total loss: [1m[32m0.58516[0m[0m | time: 162.240s
[2K
| Adam | epoch: 001 | loss: 0.58516 - acc: 0.7391 -- iter: 0544/1177
[A[ATraining Step: 18  | total loss: [1m[32m0.53252[0m[0m | time: 170.145s
[2K
| Adam | epoch: 001 | loss: 0.53252 - acc: 0.7537 -- iter: 0576/1177
[A[ATraining Step: 19  | total loss: [1m[32m0.53678[0m[0m | time: 178.079s
[2K
| Adam | epoch: 001 | loss: 0.53678 - acc: 0.7524 -- iter: 0608/1177
[A[ATraining Step: 20  | total loss: [1m[32m0.53659[0m[0m | time: 186.105s
[2K
| Adam | epoch: 001 | loss: 0.53659 - acc: 0.7517 -- iter: 0640/1177
[A[ATraining Step: 21  | total loss: [1m[32m0.51203[0m[0m | time: 194.070s
[2K
| Adam | epoch: 001 | loss: 0.51203 - acc: 0.7802 -- iter: 0672/1177
[A[ATraining Step: 22  | total loss: [1m[32m0.52719[0m[0m | time: 201.917s
[2K
| Adam | epoch: 001 | loss: 0.52719 - acc: 0.7618 -- iter: 0704/1177
[A[ATraining Step: 23  | total loss: [1m[32m0.49264[0m[0m | time: 209.881s
[2K
| Adam | epoch: 001 | loss: 0.49264 - acc: 0.7674 -- iter: 0736/1177
[A[ATraining Step: 24  | total loss: [1m[32m0.50077[0m[0m | time: 217.813s
[2K
| Adam | epoch: 001 | loss: 0.50077 - acc: 0.7362 -- iter: 0768/1177
[A[ATraining Step: 25  | total loss: [1m[32m0.50498[0m[0m | time: 225.762s
[2K
| Adam | epoch: 001 | loss: 0.50498 - acc: 0.7399 -- iter: 0800/1177
[A[ATraining Step: 26  | total loss: [1m[32m0.54944[0m[0m | time: 233.533s
[2K
| Adam | epoch: 001 | loss: 0.54944 - acc: 0.7178 -- iter: 0832/1177
[A[ATraining Step: 27  | total loss: [1m[32m0.54398[0m[0m | time: 241.424s
[2K
| Adam | epoch: 001 | loss: 0.54398 - acc: 0.7341 -- iter: 0864/1177
[A[ATraining Step: 28  | total loss: [1m[32m0.56872[0m[0m | time: 249.292s
[2K
| Adam | epoch: 001 | loss: 0.56872 - acc: 0.7225 -- iter: 0896/1177
[A[ATraining Step: 29  | total loss: [1m[32m0.55473[0m[0m | time: 257.290s
[2K
| Adam | epoch: 001 | loss: 0.55473 - acc: 0.7140 -- iter: 0928/1177
[A[ATraining Step: 30  | total loss: [1m[32m0.54658[0m[0m | time: 265.197s
[2K
| Adam | epoch: 001 | loss: 0.54658 - acc: 0.7003 -- iter: 0960/1177
[A[ATraining Step: 31  | total loss: [1m[32m0.53677[0m[0m | time: 273.177s
[2K
| Adam | epoch: 001 | loss: 0.53677 - acc: 0.7190 -- iter: 0992/1177
[A[ATraining Step: 32  | total loss: [1m[32m0.49739[0m[0m | time: 281.190s
[2K
| Adam | epoch: 001 | loss: 0.49739 - acc: 0.7541 -- iter: 1024/1177
[A[ATraining Step: 33  | total loss: [1m[32m0.48269[0m[0m | time: 289.133s
[2K
| Adam | epoch: 001 | loss: 0.48269 - acc: 0.7669 -- iter: 1056/1177
[A[ATraining Step: 34  | total loss: [1m[32m0.47120[0m[0m | time: 296.918s
[2K
| Adam | epoch: 001 | loss: 0.47120 - acc: 0.7767 -- iter: 1088/1177
[A[ATraining Step: 35  | total loss: [1m[32m0.51139[0m[0m | time: 304.828s
[2K
| Adam | epoch: 001 | loss: 0.51139 - acc: 0.7645 -- iter: 1120/1177
[A[ATraining Step: 36  | total loss: [1m[32m0.50828[0m[0m | time: 312.706s
[2K
| Adam | epoch: 001 | loss: 0.50828 - acc: 0.7680 -- iter: 1152/1177
[A[ATraining Step: 37  | total loss: [1m[32m0.55695[0m[0m | time: 341.422s
[2K
| Adam | epoch: 001 | loss: 0.55695 - acc: 0.7769 | val_loss: 0.90491 - val_acc: 0.5299 -- iter: 1177/1177
--
Training Step: 38  | total loss: [1m[32m0.54380[0m[0m | time: 6.596s
[2K
| Adam | epoch: 002 | loss: 0.54380 - acc: 0.7892 -- iter: 0032/1177
[A[ATraining Step: 39  | total loss: [1m[32m0.51128[0m[0m | time: 14.559s
[2K
| Adam | epoch: 002 | loss: 0.51128 - acc: 0.8066 -- iter: 0064/1177
[A[ATraining Step: 40  | total loss: [1m[32m0.50759[0m[0m | time: 22.402s
[2K
| Adam | epoch: 002 | loss: 0.50759 - acc: 0.7960 -- iter: 0096/1177
[A[ATraining Step: 41  | total loss: [1m[32m0.55526[0m[0m | time: 30.209s
[2K
| Adam | epoch: 002 | loss: 0.55526 - acc: 0.7818 -- iter: 0128/1177
[A[ATraining Step: 42  | total loss: [1m[32m0.61126[0m[0m | time: 38.075s
[2K
| Adam | epoch: 002 | loss: 0.61126 - acc: 0.7817 -- iter: 0160/1177
[A[ATraining Step: 43  | total loss: [1m[32m0.61610[0m[0m | time: 45.961s
[2K
| Adam | epoch: 002 | loss: 0.61610 - acc: 0.7596 -- iter: 0192/1177
[A[ATraining Step: 44  | total loss: [1m[32m0.61166[0m[0m | time: 54.022s
[2K
| Adam | epoch: 002 | loss: 0.61166 - acc: 0.7633 -- iter: 0224/1177
[A[ATraining Step: 45  | total loss: [1m[32m0.57380[0m[0m | time: 61.906s
[2K
| Adam | epoch: 002 | loss: 0.57380 - acc: 0.7823 -- iter: 0256/1177
[A[ATraining Step: 46  | total loss: [1m[32m0.54961[0m[0m | time: 69.797s
[2K
| Adam | epoch: 002 | loss: 0.54961 - acc: 0.7821 -- iter: 0288/1177
[A[ATraining Step: 47  | total loss: [1m[32m0.50748[0m[0m | time: 77.793s
[2K
| Adam | epoch: 002 | loss: 0.50748 - acc: 0.8024 -- iter: 0320/1177
[A[ATraining Step: 48  | total loss: [1m[32m0.49344[0m[0m | time: 85.651s
[2K
| Adam | epoch: 002 | loss: 0.49344 - acc: 0.7990 -- iter: 0352/1177
[A[ATraining Step: 49  | total loss: [1m[32m0.45101[0m[0m | time: 93.557s
[2K
| Adam | epoch: 002 | loss: 0.45101 - acc: 0.8258 -- iter: 0384/1177
[A[ATraining Step: 50  | total loss: [1m[32m0.45110[0m[0m | time: 101.261s
[2K
| Adam | epoch: 002 | loss: 0.45110 - acc: 0.8286 -- iter: 0416/1177
[A[ATraining Step: 51  | total loss: [1m[32m0.45040[0m[0m | time: 109.048s
[2K
| Adam | epoch: 002 | loss: 0.45040 - acc: 0.8261 -- iter: 0448/1177
[A[ATraining Step: 52  | total loss: [1m[32m0.43853[0m[0m | time: 116.851s
[2K
| Adam | epoch: 002 | loss: 0.43853 - acc: 0.8288 -- iter: 0480/1177
[A[ATraining Step: 53  | total loss: [1m[32m0.44062[0m[0m | time: 124.696s
[2K
| Adam | epoch: 002 | loss: 0.44062 - acc: 0.8172 -- iter: 0512/1177
[A[ATraining Step: 54  | total loss: [1m[32m0.42355[0m[0m | time: 132.705s
[2K
| Adam | epoch: 002 | loss: 0.42355 - acc: 0.8210 -- iter: 0544/1177
[A[ATraining Step: 55  | total loss: [1m[32m0.43544[0m[0m | time: 140.511s
[2K
| Adam | epoch: 002 | loss: 0.43544 - acc: 0.8064 -- iter: 0576/1177
[A[ATraining Step: 56  | total loss: [1m[32m0.41548[0m[0m | time: 148.352s
[2K
| Adam | epoch: 002 | loss: 0.41548 - acc: 0.8161 -- iter: 0608/1177
[A[ATraining Step: 57  | total loss: [1m[32m0.40454[0m[0m | time: 156.240s
[2K
| Adam | epoch: 002 | loss: 0.40454 - acc: 0.8156 -- iter: 0640/1177
[A[ATraining Step: 58  | total loss: [1m[32m0.41278[0m[0m | time: 164.010s
[2K
| Adam | epoch: 002 | loss: 0.41278 - acc: 0.7938 -- iter: 0672/1177
[A[ATraining Step: 59  | total loss: [1m[32m0.40274[0m[0m | time: 171.875s
[2K
| Adam | epoch: 002 | loss: 0.40274 - acc: 0.8005 -- iter: 0704/1177
[A[ATraining Step: 60  | total loss: [1m[32m0.38853[0m[0m | time: 179.789s
[2K
| Adam | epoch: 002 | loss: 0.38853 - acc: 0.8104 -- iter: 0736/1177
[A[ATraining Step: 61  | total loss: [1m[32m0.35782[0m[0m | time: 187.727s
[2K
| Adam | epoch: 002 | loss: 0.35782 - acc: 0.8311 -- iter: 0768/1177
[A[ATraining Step: 62  | total loss: [1m[32m0.41402[0m[0m | time: 195.521s
[2K
| Adam | epoch: 002 | loss: 0.41402 - acc: 0.8126 -- iter: 0800/1177
[A[ATraining Step: 63  | total loss: [1m[32m0.41216[0m[0m | time: 203.525s
[2K
| Adam | epoch: 002 | loss: 0.41216 - acc: 0.8126 -- iter: 0832/1177
[A[ATraining Step: 64  | total loss: [1m[32m0.40310[0m[0m | time: 211.358s
[2K
| Adam | epoch: 002 | loss: 0.40310 - acc: 0.8126 -- iter: 0864/1177
[A[ATraining Step: 65  | total loss: [1m[32m0.38663[0m[0m | time: 219.127s
[2K
| Adam | epoch: 002 | loss: 0.38663 - acc: 0.8203 -- iter: 0896/1177
[A[ATraining Step: 66  | total loss: [1m[32m0.41959[0m[0m | time: 227.082s
[2K
| Adam | epoch: 002 | loss: 0.41959 - acc: 0.8079 -- iter: 0928/1177
[A[ATraining Step: 67  | total loss: [1m[32m0.42038[0m[0m | time: 234.916s
[2K
| Adam | epoch: 002 | loss: 0.42038 - acc: 0.8160 -- iter: 0960/1177
[A[ATraining Step: 68  | total loss: [1m[32m0.41039[0m[0m | time: 242.840s
[2K
| Adam | epoch: 002 | loss: 0.41039 - acc: 0.8156 -- iter: 0992/1177
[A[ATraining Step: 69  | total loss: [1m[32m0.41486[0m[0m | time: 250.711s
[2K
| Adam | epoch: 002 | loss: 0.41486 - acc: 0.8152 -- iter: 1024/1177
[A[ATraining Step: 70  | total loss: [1m[32m0.40496[0m[0m | time: 258.558s
[2K
| Adam | epoch: 002 | loss: 0.40496 - acc: 0.8185 -- iter: 1056/1177
[A[ATraining Step: 71  | total loss: [1m[32m0.39154[0m[0m | time: 266.443s
[2K
| Adam | epoch: 002 | loss: 0.39154 - acc: 0.8249 -- iter: 1088/1177
[A[ATraining Step: 72  | total loss: [1m[32m0.39625[0m[0m | time: 274.299s
[2K
| Adam | epoch: 002 | loss: 0.39625 - acc: 0.8235 -- iter: 1120/1177
[A[ATraining Step: 73  | total loss: [1m[32m0.37806[0m[0m | time: 282.303s
[2K
| Adam | epoch: 002 | loss: 0.37806 - acc: 0.8362 -- iter: 1152/1177
[A[ATraining Step: 74  | total loss: [1m[32m0.38298[0m[0m | time: 306.566s
[2K
| Adam | epoch: 002 | loss: 0.38298 - acc: 0.8302 | val_loss: 0.66834 - val_acc: 0.7092 -- iter: 1177/1177
--
Training Step: 75  | total loss: [1m[32m0.37376[0m[0m | time: 6.459s
[2K
| Adam | epoch: 003 | loss: 0.37376 - acc: 0.8350 -- iter: 0032/1177
[A[ATraining Step: 76  | total loss: [1m[32m0.36763[0m[0m | time: 12.898s
[2K
| Adam | epoch: 003 | loss: 0.36763 - acc: 0.8441 -- iter: 0064/1177
[A[ATraining Step: 77  | total loss: [1m[32m0.35271[0m[0m | time: 20.829s
[2K
| Adam | epoch: 003 | loss: 0.35271 - acc: 0.8564 -- iter: 0096/1177
[A[ATraining Step: 78  | total loss: [1m[32m0.36070[0m[0m | time: 28.721s
[2K
| Adam | epoch: 003 | loss: 0.36070 - acc: 0.8485 -- iter: 0128/1177
[A[ATraining Step: 79  | total loss: [1m[32m0.37790[0m[0m | time: 36.609s
[2K
| Adam | epoch: 003 | loss: 0.37790 - acc: 0.8480 -- iter: 0160/1177
[A[ATraining Step: 80  | total loss: [1m[32m0.40698[0m[0m | time: 44.299s
[2K
| Adam | epoch: 003 | loss: 0.40698 - acc: 0.8316 -- iter: 0192/1177
[A[ATraining Step: 81  | total loss: [1m[32m0.39102[0m[0m | time: 52.149s
[2K
| Adam | epoch: 003 | loss: 0.39102 - acc: 0.8328 -- iter: 0224/1177
[A[ATraining Step: 82  | total loss: [1m[32m0.40728[0m[0m | time: 60.038s
[2K
| Adam | epoch: 003 | loss: 0.40728 - acc: 0.8277 -- iter: 0256/1177
[A[ATraining Step: 83  | total loss: [1m[32m0.39505[0m[0m | time: 67.926s
[2K
| Adam | epoch: 003 | loss: 0.39505 - acc: 0.8355 -- iter: 0288/1177
[A[ATraining Step: 84  | total loss: [1m[32m0.38432[0m[0m | time: 75.774s
[2K
| Adam | epoch: 003 | loss: 0.38432 - acc: 0.8395 -- iter: 0320/1177
[A[ATraining Step: 85  | total loss: [1m[32m0.38992[0m[0m | time: 83.632s
[2K
| Adam | epoch: 003 | loss: 0.38992 - acc: 0.8337 -- iter: 0352/1177
[A[ATraining Step: 86  | total loss: [1m[32m0.37939[0m[0m | time: 91.520s
[2K
| Adam | epoch: 003 | loss: 0.37939 - acc: 0.8409 -- iter: 0384/1177
[A[ATraining Step: 87  | total loss: [1m[32m0.36148[0m[0m | time: 99.377s
[2K
| Adam | epoch: 003 | loss: 0.36148 - acc: 0.8537 -- iter: 0416/1177
[A[ATraining Step: 88  | total loss: [1m[32m0.37298[0m[0m | time: 107.269s
[2K
| Adam | epoch: 003 | loss: 0.37298 - acc: 0.8496 -- iter: 0448/1177
[A[ATraining Step: 89  | total loss: [1m[32m0.35755[0m[0m | time: 115.308s
[2K
| Adam | epoch: 003 | loss: 0.35755 - acc: 0.8584 -- iter: 0480/1177
[A[ATraining Step: 90  | total loss: [1m[32m0.36071[0m[0m | time: 123.204s
[2K
| Adam | epoch: 003 | loss: 0.36071 - acc: 0.8538 -- iter: 0512/1177
[A[ATraining Step: 91  | total loss: [1m[32m0.35107[0m[0m | time: 130.972s
[2K
| Adam | epoch: 003 | loss: 0.35107 - acc: 0.8528 -- iter: 0544/1177
[A[ATraining Step: 92  | total loss: [1m[32m0.34828[0m[0m | time: 138.773s
[2K
| Adam | epoch: 003 | loss: 0.34828 - acc: 0.8581 -- iter: 0576/1177
[A[ATraining Step: 93  | total loss: [1m[32m0.33607[0m[0m | time: 146.588s
[2K
| Adam | epoch: 003 | loss: 0.33607 - acc: 0.8629 -- iter: 0608/1177
[A[ATraining Step: 94  | total loss: [1m[32m0.32940[0m[0m | time: 154.464s
[2K
| Adam | epoch: 003 | loss: 0.32940 - acc: 0.8641 -- iter: 0640/1177
[A[ATraining Step: 95  | total loss: [1m[32m0.30997[0m[0m | time: 162.403s
[2K
| Adam | epoch: 003 | loss: 0.30997 - acc: 0.8715 -- iter: 0672/1177
[A[ATraining Step: 96  | total loss: [1m[32m0.30947[0m[0m | time: 170.218s
[2K
| Adam | epoch: 003 | loss: 0.30947 - acc: 0.8718 -- iter: 0704/1177
[A[ATraining Step: 97  | total loss: [1m[32m0.31427[0m[0m | time: 178.093s
[2K
| Adam | epoch: 003 | loss: 0.31427 - acc: 0.8690 -- iter: 0736/1177
[A[ATraining Step: 98  | total loss: [1m[32m0.30687[0m[0m | time: 185.853s
[2K
| Adam | epoch: 003 | loss: 0.30687 - acc: 0.8727 -- iter: 0768/1177
[A[ATraining Step: 99  | total loss: [1m[32m0.30112[0m[0m | time: 193.643s
[2K
| Adam | epoch: 003 | loss: 0.30112 - acc: 0.8761 -- iter: 0800/1177
[A[ATraining Step: 100  | total loss: [1m[32m0.30303[0m[0m | time: 201.435s
[2K
| Adam | epoch: 003 | loss: 0.30303 - acc: 0.8729 -- iter: 0832/1177
[A[ATraining Step: 101  | total loss: [1m[32m0.31295[0m[0m | time: 209.245s
[2K
| Adam | epoch: 003 | loss: 0.31295 - acc: 0.8793 -- iter: 0864/1177
[A[ATraining Step: 102  | total loss: [1m[32m0.33065[0m[0m | time: 217.057s
[2K
| Adam | epoch: 003 | loss: 0.33065 - acc: 0.8664 -- iter: 0896/1177
[A[ATraining Step: 103  | total loss: [1m[32m0.30929[0m[0m | time: 224.927s
[2K
| Adam | epoch: 003 | loss: 0.30929 - acc: 0.8766 -- iter: 0928/1177
[A[ATraining Step: 104  | total loss: [1m[32m0.29276[0m[0m | time: 232.840s
[2K
| Adam | epoch: 003 | loss: 0.29276 - acc: 0.8858 -- iter: 0960/1177
[A[ATraining Step: 105  | total loss: [1m[32m0.28900[0m[0m | time: 240.612s
[2K
| Adam | epoch: 003 | loss: 0.28900 - acc: 0.8879 -- iter: 0992/1177
[A[ATraining Step: 106  | total loss: [1m[32m0.30074[0m[0m | time: 248.486s
[2K
| Adam | epoch: 003 | loss: 0.30074 - acc: 0.8803 -- iter: 1024/1177
[A[ATraining Step: 107  | total loss: [1m[32m0.29830[0m[0m | time: 256.387s
[2K
| Adam | epoch: 003 | loss: 0.29830 - acc: 0.8861 -- iter: 1056/1177
[A[ATraining Step: 108  | total loss: [1m[32m0.30294[0m[0m | time: 264.227s
[2K
| Adam | epoch: 003 | loss: 0.30294 - acc: 0.8850 -- iter: 1088/1177
[A[ATraining Step: 109  | total loss: [1m[32m0.30437[0m[0m | time: 271.944s
[2K
| Adam | epoch: 003 | loss: 0.30437 - acc: 0.8840 -- iter: 1120/1177
[A[ATraining Step: 110  | total loss: [1m[32m0.32020[0m[0m | time: 279.696s
[2K
| Adam | epoch: 003 | loss: 0.32020 - acc: 0.8768 -- iter: 1152/1177
[A[ATraining Step: 111  | total loss: [1m[32m0.30889[0m[0m | time: 304.033s
[2K
| Adam | epoch: 003 | loss: 0.30889 - acc: 0.8798 | val_loss: 0.50320 - val_acc: 0.7799 -- iter: 1177/1177
--
Training Step: 112  | total loss: [1m[32m0.29494[0m[0m | time: 7.818s
[2K
| Adam | epoch: 004 | loss: 0.29494 - acc: 0.8855 -- iter: 0032/1177
[A[ATraining Step: 113  | total loss: [1m[32m0.28700[0m[0m | time: 14.224s
[2K
| Adam | epoch: 004 | loss: 0.28700 - acc: 0.8907 -- iter: 0064/1177
[A[ATraining Step: 114  | total loss: [1m[32m0.34046[0m[0m | time: 20.613s
[2K
| Adam | epoch: 004 | loss: 0.34046 - acc: 0.8697 -- iter: 0096/1177
[A[ATraining Step: 115  | total loss: [1m[32m0.36736[0m[0m | time: 28.604s
[2K
| Adam | epoch: 004 | loss: 0.36736 - acc: 0.8627 -- iter: 0128/1177
[A[ATraining Step: 116  | total loss: [1m[32m0.35301[0m[0m | time: 36.365s
[2K
| Adam | epoch: 004 | loss: 0.35301 - acc: 0.8670 -- iter: 0160/1177
[A[ATraining Step: 117  | total loss: [1m[32m0.34791[0m[0m | time: 44.249s
[2K
| Adam | epoch: 004 | loss: 0.34791 - acc: 0.8647 -- iter: 0192/1177
[A[ATraining Step: 118  | total loss: [1m[32m0.34141[0m[0m | time: 52.071s
[2K
| Adam | epoch: 004 | loss: 0.34141 - acc: 0.8657 -- iter: 0224/1177
[A[ATraining Step: 119  | total loss: [1m[32m0.33937[0m[0m | time: 60.024s
[2K
| Adam | epoch: 004 | loss: 0.33937 - acc: 0.8635 -- iter: 0256/1177
[A[ATraining Step: 120  | total loss: [1m[32m0.36243[0m[0m | time: 67.825s
[2K
| Adam | epoch: 004 | loss: 0.36243 - acc: 0.8491 -- iter: 0288/1177
[A[ATraining Step: 121  | total loss: [1m[32m0.34029[0m[0m | time: 75.786s
[2K
| Adam | epoch: 004 | loss: 0.34029 - acc: 0.8642 -- iter: 0320/1177
[A[ATraining Step: 122  | total loss: [1m[32m0.33235[0m[0m | time: 83.581s
[2K
| Adam | epoch: 004 | loss: 0.33235 - acc: 0.8684 -- iter: 0352/1177
[A[ATraining Step: 123  | total loss: [1m[32m0.32648[0m[0m | time: 91.461s
[2K
| Adam | epoch: 004 | loss: 0.32648 - acc: 0.8690 -- iter: 0384/1177
[A[ATraining Step: 124  | total loss: [1m[32m0.30817[0m[0m | time: 99.324s
[2K
| Adam | epoch: 004 | loss: 0.30817 - acc: 0.8790 -- iter: 0416/1177
[A[ATraining Step: 125  | total loss: [1m[32m0.30124[0m[0m | time: 107.221s
[2K
| Adam | epoch: 004 | loss: 0.30124 - acc: 0.8786 -- iter: 0448/1177
[A[ATraining Step: 126  | total loss: [1m[32m0.29016[0m[0m | time: 115.058s
[2K
| Adam | epoch: 004 | loss: 0.29016 - acc: 0.8845 -- iter: 0480/1177
[A[ATraining Step: 127  | total loss: [1m[32m0.28273[0m[0m | time: 123.066s
[2K
| Adam | epoch: 004 | loss: 0.28273 - acc: 0.8898 -- iter: 0512/1177
[A[ATraining Step: 128  | total loss: [1m[32m0.28443[0m[0m | time: 130.810s
[2K
| Adam | epoch: 004 | loss: 0.28443 - acc: 0.8821 -- iter: 0544/1177
[A[ATraining Step: 129  | total loss: [1m[32m0.27947[0m[0m | time: 138.639s
[2K
| Adam | epoch: 004 | loss: 0.27947 - acc: 0.8814 -- iter: 0576/1177
[A[ATraining Step: 130  | total loss: [1m[32m0.26837[0m[0m | time: 146.481s
[2K
| Adam | epoch: 004 | loss: 0.26837 - acc: 0.8870 -- iter: 0608/1177
[A[ATraining Step: 131  | total loss: [1m[32m0.28261[0m[0m | time: 154.433s
[2K
| Adam | epoch: 004 | loss: 0.28261 - acc: 0.8795 -- iter: 0640/1177
[A[ATraining Step: 132  | total loss: [1m[32m0.27085[0m[0m | time: 162.342s
[2K
| Adam | epoch: 004 | loss: 0.27085 - acc: 0.8884 -- iter: 0672/1177
[A[ATraining Step: 133  | total loss: [1m[32m0.26898[0m[0m | time: 170.373s
[2K
| Adam | epoch: 004 | loss: 0.26898 - acc: 0.8934 -- iter: 0704/1177
[A[ATraining Step: 134  | total loss: [1m[32m0.25553[0m[0m | time: 178.333s
[2K
| Adam | epoch: 004 | loss: 0.25553 - acc: 0.9009 -- iter: 0736/1177
[A[ATraining Step: 135  | total loss: [1m[32m0.24119[0m[0m | time: 186.222s
[2K
| Adam | epoch: 004 | loss: 0.24119 - acc: 0.9108 -- iter: 0768/1177
[A[ATraining Step: 136  | total loss: [1m[32m0.24509[0m[0m | time: 194.052s
[2K
| Adam | epoch: 004 | loss: 0.24509 - acc: 0.9103 -- iter: 0800/1177
[A[ATraining Step: 137  | total loss: [1m[32m0.23970[0m[0m | time: 202.002s
[2K
| Adam | epoch: 004 | loss: 0.23970 - acc: 0.9099 -- iter: 0832/1177
[A[ATraining Step: 138  | total loss: [1m[32m0.24315[0m[0m | time: 209.844s
[2K
| Adam | epoch: 004 | loss: 0.24315 - acc: 0.9127 -- iter: 0864/1177
[A[ATraining Step: 139  | total loss: [1m[32m0.23987[0m[0m | time: 217.800s
[2K
| Adam | epoch: 004 | loss: 0.23987 - acc: 0.9120 -- iter: 0896/1177
[A[ATraining Step: 140  | total loss: [1m[32m0.23865[0m[0m | time: 225.643s
[2K
| Adam | epoch: 004 | loss: 0.23865 - acc: 0.9083 -- iter: 0928/1177
[A[ATraining Step: 141  | total loss: [1m[32m0.23325[0m[0m | time: 233.616s
[2K
| Adam | epoch: 004 | loss: 0.23325 - acc: 0.9113 -- iter: 0960/1177
[A[ATraining Step: 142  | total loss: [1m[32m0.24383[0m[0m | time: 241.697s
[2K
| Adam | epoch: 004 | loss: 0.24383 - acc: 0.9108 -- iter: 0992/1177
[A[ATraining Step: 143  | total loss: [1m[32m0.23487[0m[0m | time: 249.840s
[2K
| Adam | epoch: 004 | loss: 0.23487 - acc: 0.9134 -- iter: 1024/1177
[A[ATraining Step: 144  | total loss: [1m[32m0.22481[0m[0m | time: 257.766s
[2K
| Adam | epoch: 004 | loss: 0.22481 - acc: 0.9190 -- iter: 1056/1177
[A[ATraining Step: 145  | total loss: [1m[32m0.21866[0m[0m | time: 265.802s
[2K
| Adam | epoch: 004 | loss: 0.21866 - acc: 0.9208 -- iter: 1088/1177
[A[ATraining Step: 146  | total loss: [1m[32m0.23557[0m[0m | time: 273.672s
[2K
| Adam | epoch: 004 | loss: 0.23557 - acc: 0.9194 -- iter: 1120/1177
[A[ATraining Step: 147  | total loss: [1m[32m0.24080[0m[0m | time: 281.774s
[2K
| Adam | epoch: 004 | loss: 0.24080 - acc: 0.9181 -- iter: 1152/1177
[A[ATraining Step: 148  | total loss: [1m[32m0.24209[0m[0m | time: 306.119s
[2K
| Adam | epoch: 004 | loss: 0.24209 - acc: 0.9231 | val_loss: 0.94463 - val_acc: 0.7147 -- iter: 1177/1177
--
Training Step: 149  | total loss: [1m[32m0.24464[0m[0m | time: 7.889s
[2K
| Adam | epoch: 005 | loss: 0.24464 - acc: 0.9183 -- iter: 0032/1177
[A[ATraining Step: 150  | total loss: [1m[32m0.24228[0m[0m | time: 15.827s
[2K
| Adam | epoch: 005 | loss: 0.24228 - acc: 0.9202 -- iter: 0064/1177
[A[ATraining Step: 151  | total loss: [1m[32m0.23277[0m[0m | time: 22.288s
[2K
| Adam | epoch: 005 | loss: 0.23277 - acc: 0.9251 -- iter: 0096/1177
[A[ATraining Step: 152  | total loss: [1m[32m0.21753[0m[0m | time: 28.865s
[2K
| Adam | epoch: 005 | loss: 0.21753 - acc: 0.9286 -- iter: 0128/1177
[A[ATraining Step: 153  | total loss: [1m[32m0.19981[0m[0m | time: 36.854s
[2K
| Adam | epoch: 005 | loss: 0.19981 - acc: 0.9357 -- iter: 0160/1177
[A[ATraining Step: 154  | total loss: [1m[32m0.22062[0m[0m | time: 44.895s
[2K
| Adam | epoch: 005 | loss: 0.22062 - acc: 0.9234 -- iter: 0192/1177
[A[ATraining Step: 155  | total loss: [1m[32m0.21785[0m[0m | time: 52.813s
[2K
| Adam | epoch: 005 | loss: 0.21785 - acc: 0.9217 -- iter: 0224/1177
[A[ATraining Step: 156  | total loss: [1m[32m0.22070[0m[0m | time: 60.947s
[2K
| Adam | epoch: 005 | loss: 0.22070 - acc: 0.9170 -- iter: 0256/1177
[A[ATraining Step: 157  | total loss: [1m[32m0.21851[0m[0m | time: 68.901s
[2K
| Adam | epoch: 005 | loss: 0.21851 - acc: 0.9128 -- iter: 0288/1177
[A[ATraining Step: 158  | total loss: [1m[32m0.23337[0m[0m | time: 76.856s
[2K
| Adam | epoch: 005 | loss: 0.23337 - acc: 0.9122 -- iter: 0320/1177
[A[ATraining Step: 159  | total loss: [1m[32m0.22056[0m[0m | time: 84.911s
[2K
| Adam | epoch: 005 | loss: 0.22056 - acc: 0.9178 -- iter: 0352/1177
[A[ATraining Step: 160  | total loss: [1m[32m0.22490[0m[0m | time: 93.097s
[2K
| Adam | epoch: 005 | loss: 0.22490 - acc: 0.9104 -- iter: 0384/1177
[A[ATraining Step: 161  | total loss: [1m[32m0.22289[0m[0m | time: 101.008s
[2K
| Adam | epoch: 005 | loss: 0.22289 - acc: 0.9162 -- iter: 0416/1177
[A[ATraining Step: 162  | total loss: [1m[32m0.21829[0m[0m | time: 109.140s
[2K
| Adam | epoch: 005 | loss: 0.21829 - acc: 0.9184 -- iter: 0448/1177
[A[ATraining Step: 163  | total loss: [1m[32m0.22349[0m[0m | time: 117.137s
[2K
| Adam | epoch: 005 | loss: 0.22349 - acc: 0.9172 -- iter: 0480/1177
[A[ATraining Step: 164  | total loss: [1m[32m0.20976[0m[0m | time: 125.173s
[2K
| Adam | epoch: 005 | loss: 0.20976 - acc: 0.9254 -- iter: 0512/1177
[A[ATraining Step: 165  | total loss: [1m[32m0.20733[0m[0m | time: 133.111s
[2K
| Adam | epoch: 005 | loss: 0.20733 - acc: 0.9266 -- iter: 0544/1177
[A[ATraining Step: 166  | total loss: [1m[32m0.20348[0m[0m | time: 141.149s
[2K
| Adam | epoch: 005 | loss: 0.20348 - acc: 0.9246 -- iter: 0576/1177
[A[ATraining Step: 167  | total loss: [1m[32m0.19234[0m[0m | time: 149.241s
[2K
| Adam | epoch: 005 | loss: 0.19234 - acc: 0.9321 -- iter: 0608/1177
[A[ATraining Step: 168  | total loss: [1m[32m0.19731[0m[0m | time: 157.239s
[2K
| Adam | epoch: 005 | loss: 0.19731 - acc: 0.9296 -- iter: 0640/1177
[A[ATraining Step: 169  | total loss: [1m[32m0.18447[0m[0m | time: 165.280s
[2K
| Adam | epoch: 005 | loss: 0.18447 - acc: 0.9335 -- iter: 0672/1177
[A[ATraining Step: 170  | total loss: [1m[32m0.17449[0m[0m | time: 173.284s
[2K
| Adam | epoch: 005 | loss: 0.17449 - acc: 0.9339 -- iter: 0704/1177
[A[ATraining Step: 171  | total loss: [1m[32m0.16497[0m[0m | time: 181.134s
[2K
| Adam | epoch: 005 | loss: 0.16497 - acc: 0.9374 -- iter: 0736/1177
[A[ATraining Step: 172  | total loss: [1m[32m0.15921[0m[0m | time: 189.183s
[2K
| Adam | epoch: 005 | loss: 0.15921 - acc: 0.9374 -- iter: 0768/1177
[A[ATraining Step: 173  | total loss: [1m[32m0.17253[0m[0m | time: 197.172s
[2K
| Adam | epoch: 005 | loss: 0.17253 - acc: 0.9374 -- iter: 0800/1177
[A[ATraining Step: 174  | total loss: [1m[32m0.16730[0m[0m | time: 205.233s
[2K
| Adam | epoch: 005 | loss: 0.16730 - acc: 0.9405 -- iter: 0832/1177
[A[ATraining Step: 175  | total loss: [1m[32m0.15821[0m[0m | time: 213.230s
[2K
| Adam | epoch: 005 | loss: 0.15821 - acc: 0.9433 -- iter: 0864/1177
[A[ATraining Step: 176  | total loss: [1m[32m0.17186[0m[0m | time: 221.244s
[2K
| Adam | epoch: 005 | loss: 0.17186 - acc: 0.9365 -- iter: 0896/1177
[A[ATraining Step: 177  | total loss: [1m[32m0.16395[0m[0m | time: 229.181s
[2K
| Adam | epoch: 005 | loss: 0.16395 - acc: 0.9397 -- iter: 0928/1177
[A[ATraining Step: 178  | total loss: [1m[32m0.21446[0m[0m | time: 237.330s
[2K
| Adam | epoch: 005 | loss: 0.21446 - acc: 0.9145 -- iter: 0960/1177
[A[ATraining Step: 179  | total loss: [1m[32m0.20497[0m[0m | time: 245.227s
[2K
| Adam | epoch: 005 | loss: 0.20497 - acc: 0.9199 -- iter: 0992/1177
[A[ATraining Step: 180  | total loss: [1m[32m0.19373[0m[0m | time: 253.197s
[2K
| Adam | epoch: 005 | loss: 0.19373 - acc: 0.9217 -- iter: 1024/1177
[A[ATraining Step: 181  | total loss: [1m[32m0.21268[0m[0m | time: 261.303s
[2K
| Adam | epoch: 005 | loss: 0.21268 - acc: 0.9139 -- iter: 1056/1177
[A[ATraining Step: 182  | total loss: [1m[32m0.19743[0m[0m | time: 269.430s
[2K
| Adam | epoch: 005 | loss: 0.19743 - acc: 0.9194 -- iter: 1088/1177
[A[ATraining Step: 183  | total loss: [1m[32m0.19460[0m[0m | time: 277.371s
[2K
| Adam | epoch: 005 | loss: 0.19460 - acc: 0.9243 -- iter: 1120/1177
[A[ATraining Step: 184  | total loss: [1m[32m0.21178[0m[0m | time: 285.550s
[2K
| Adam | epoch: 005 | loss: 0.21178 - acc: 0.9163 -- iter: 1152/1177
[A[ATraining Step: 185  | total loss: [1m[32m0.20136[0m[0m | time: 309.657s
[2K
| Adam | epoch: 005 | loss: 0.20136 - acc: 0.9184 | val_loss: 1.43438 - val_acc: 0.5978 -- iter: 1177/1177
--
Training Step: 186  | total loss: [1m[32m0.26497[0m[0m | time: 8.263s
[2K
| Adam | epoch: 006 | loss: 0.26497 - acc: 0.8984 -- iter: 0032/1177
[A[ATraining Step: 187  | total loss: [1m[32m0.25256[0m[0m | time: 16.295s
[2K
| Adam | epoch: 006 | loss: 0.25256 - acc: 0.9023 -- iter: 0064/1177
[A[ATraining Step: 188  | total loss: [1m[32m0.24540[0m[0m | time: 24.475s
[2K
| Adam | epoch: 006 | loss: 0.24540 - acc: 0.9027 -- iter: 0096/1177
[A[ATraining Step: 189  | total loss: [1m[32m0.24236[0m[0m | time: 30.881s
[2K
| Adam | epoch: 006 | loss: 0.24236 - acc: 0.9062 -- iter: 0128/1177
[A[ATraining Step: 190  | total loss: [1m[32m0.27595[0m[0m | time: 37.448s
[2K
| Adam | epoch: 006 | loss: 0.27595 - acc: 0.8956 -- iter: 0160/1177
[A[ATraining Step: 191  | total loss: [1m[32m0.27194[0m[0m | time: 45.442s
[2K
| Adam | epoch: 006 | loss: 0.27194 - acc: 0.8940 -- iter: 0192/1177
[A[ATraining Step: 192  | total loss: [1m[32m0.27531[0m[0m | time: 53.609s
[2K
| Adam | epoch: 006 | loss: 0.27531 - acc: 0.8890 -- iter: 0224/1177
[A[ATraining Step: 193  | total loss: [1m[32m0.27738[0m[0m | time: 61.615s
[2K
| Adam | epoch: 006 | loss: 0.27738 - acc: 0.8876 -- iter: 0256/1177
[A[ATraining Step: 194  | total loss: [1m[32m0.26825[0m[0m | time: 69.813s
[2K
| Adam | epoch: 006 | loss: 0.26825 - acc: 0.8926 -- iter: 0288/1177
[A[ATraining Step: 195  | total loss: [1m[32m0.27525[0m[0m | time: 77.965s
[2K
| Adam | epoch: 006 | loss: 0.27525 - acc: 0.8908 -- iter: 0320/1177
[A[ATraining Step: 196  | total loss: [1m[32m0.27252[0m[0m | time: 86.102s
[2K
| Adam | epoch: 006 | loss: 0.27252 - acc: 0.8924 -- iter: 0352/1177
[A[ATraining Step: 197  | total loss: [1m[32m0.27462[0m[0m | time: 94.312s
[2K
| Adam | epoch: 006 | loss: 0.27462 - acc: 0.8938 -- iter: 0384/1177
[A[ATraining Step: 198  | total loss: [1m[32m0.25866[0m[0m | time: 102.295s
[2K
| Adam | epoch: 006 | loss: 0.25866 - acc: 0.9013 -- iter: 0416/1177
[A[ATraining Step: 199  | total loss: [1m[32m0.24753[0m[0m | time: 110.346s
[2K
| Adam | epoch: 006 | loss: 0.24753 - acc: 0.9049 -- iter: 0448/1177
[A[ATraining Step: 200  | total loss: [1m[32m0.23184[0m[0m | time: 135.212s
[2K
| Adam | epoch: 006 | loss: 0.23184 - acc: 0.9113 | val_loss: 1.09660 - val_acc: 0.5788 -- iter: 0480/1177
--
Training Step: 201  | total loss: [1m[32m0.25143[0m[0m | time: 143.430s
[2K
| Adam | epoch: 006 | loss: 0.25143 - acc: 0.9014 -- iter: 0512/1177
[A[ATraining Step: 202  | total loss: [1m[32m0.25094[0m[0m | time: 151.880s
[2K
| Adam | epoch: 006 | loss: 0.25094 - acc: 0.8988 -- iter: 0544/1177
[A[ATraining Step: 203  | total loss: [1m[32m0.23575[0m[0m | time: 160.075s
[2K
| Adam | epoch: 006 | loss: 0.23575 - acc: 0.9058 -- iter: 0576/1177
[A[ATraining Step: 204  | total loss: [1m[32m0.22450[0m[0m | time: 168.235s
[2K
| Adam | epoch: 006 | loss: 0.22450 - acc: 0.9089 -- iter: 0608/1177
[A[ATraining Step: 205  | total loss: [1m[32m0.20926[0m[0m | time: 176.444s
[2K
| Adam | epoch: 006 | loss: 0.20926 - acc: 0.9180 -- iter: 0640/1177
[A[ATraining Step: 206  | total loss: [1m[32m0.20415[0m[0m | time: 184.791s
[2K
| Adam | epoch: 006 | loss: 0.20415 - acc: 0.9200 -- iter: 0672/1177
[A[ATraining Step: 207  | total loss: [1m[32m0.21080[0m[0m | time: 193.034s
[2K
| Adam | epoch: 006 | loss: 0.21080 - acc: 0.9124 -- iter: 0704/1177
[A[ATraining Step: 208  | total loss: [1m[32m0.20564[0m[0m | time: 201.212s
[2K
| Adam | epoch: 006 | loss: 0.20564 - acc: 0.9149 -- iter: 0736/1177
[A[ATraining Step: 209  | total loss: [1m[32m0.20321[0m[0m | time: 209.708s
[2K
| Adam | epoch: 006 | loss: 0.20321 - acc: 0.9171 -- iter: 0768/1177
[A[ATraining Step: 210  | total loss: [1m[32m0.19230[0m[0m | time: 217.782s
[2K
| Adam | epoch: 006 | loss: 0.19230 - acc: 0.9223 -- iter: 0800/1177
[A[ATraining Step: 211  | total loss: [1m[32m0.18515[0m[0m | time: 226.012s
[2K
| Adam | epoch: 006 | loss: 0.18515 - acc: 0.9269 -- iter: 0832/1177
[A[ATraining Step: 212  | total loss: [1m[32m0.20431[0m[0m | time: 234.391s
[2K
| Adam | epoch: 006 | loss: 0.20431 - acc: 0.9280 -- iter: 0864/1177
[A[ATraining Step: 213  | total loss: [1m[32m0.21400[0m[0m | time: 242.681s
[2K
| Adam | epoch: 006 | loss: 0.21400 - acc: 0.9196 -- iter: 0896/1177
[A[ATraining Step: 214  | total loss: [1m[32m0.20662[0m[0m | time: 250.925s
[2K
| Adam | epoch: 006 | loss: 0.20662 - acc: 0.9214 -- iter: 0928/1177
[A[ATraining Step: 215  | total loss: [1m[32m0.19551[0m[0m | time: 259.335s
[2K
| Adam | epoch: 006 | loss: 0.19551 - acc: 0.9261 -- iter: 0960/1177
[A[ATraining Step: 216  | total loss: [1m[32m0.20417[0m[0m | time: 267.563s
[2K
| Adam | epoch: 006 | loss: 0.20417 - acc: 0.9241 -- iter: 0992/1177
[A[ATraining Step: 217  | total loss: [1m[32m0.18819[0m[0m | time: 275.605s
[2K
| Adam | epoch: 006 | loss: 0.18819 - acc: 0.9317 -- iter: 1024/1177
[A[ATraining Step: 218  | total loss: [1m[32m0.21770[0m[0m | time: 283.829s
[2K
| Adam | epoch: 006 | loss: 0.21770 - acc: 0.9167 -- iter: 1056/1177
[A[ATraining Step: 219  | total loss: [1m[32m0.21723[0m[0m | time: 292.082s
[2K
| Adam | epoch: 006 | loss: 0.21723 - acc: 0.9187 -- iter: 1088/1177
[A[ATraining Step: 220  | total loss: [1m[32m0.20209[0m[0m | time: 300.230s
[2K
| Adam | epoch: 006 | loss: 0.20209 - acc: 0.9269 -- iter: 1120/1177
[A[ATraining Step: 221  | total loss: [1m[32m0.19872[0m[0m | time: 308.432s
[2K
| Adam | epoch: 006 | loss: 0.19872 - acc: 0.9311 -- iter: 1152/1177
[A[ATraining Step: 222  | total loss: [1m[32m0.18491[0m[0m | time: 332.822s
[2K
| Adam | epoch: 006 | loss: 0.18491 - acc: 0.9380 | val_loss: 2.97929 - val_acc: 0.4755 -- iter: 1177/1177
--
Training Step: 223  | total loss: [1m[32m0.18004[0m[0m | time: 8.210s
[2K
| Adam | epoch: 007 | loss: 0.18004 - acc: 0.9410 -- iter: 0032/1177
[A[ATraining Step: 224  | total loss: [1m[32m0.16941[0m[0m | time: 16.363s
[2K
| Adam | epoch: 007 | loss: 0.16941 - acc: 0.9438 -- iter: 0064/1177
[A[ATraining Step: 225  | total loss: [1m[32m0.16354[0m[0m | time: 24.623s
[2K
| Adam | epoch: 007 | loss: 0.16354 - acc: 0.9400 -- iter: 0096/1177
[A[ATraining Step: 226  | total loss: [1m[32m0.16620[0m[0m | time: 32.834s
[2K
| Adam | epoch: 007 | loss: 0.16620 - acc: 0.9429 -- iter: 0128/1177
[A[ATraining Step: 227  | total loss: [1m[32m0.16411[0m[0m | time: 39.482s
[2K
| Adam | epoch: 007 | loss: 0.16411 - acc: 0.9424 -- iter: 0160/1177
[A[ATraining Step: 228  | total loss: [1m[32m0.15479[0m[0m | time: 46.172s
[2K
| Adam | epoch: 007 | loss: 0.15479 - acc: 0.9481 -- iter: 0192/1177
[A[ATraining Step: 229  | total loss: [1m[32m0.14309[0m[0m | time: 54.131s
[2K
| Adam | epoch: 007 | loss: 0.14309 - acc: 0.9533 -- iter: 0224/1177
[A[ATraining Step: 230  | total loss: [1m[32m0.14371[0m[0m | time: 62.288s
[2K
| Adam | epoch: 007 | loss: 0.14371 - acc: 0.9549 -- iter: 0256/1177
[A[ATraining Step: 231  | total loss: [1m[32m0.14421[0m[0m | time: 70.493s
[2K
| Adam | epoch: 007 | loss: 0.14421 - acc: 0.9531 -- iter: 0288/1177
[A[ATraining Step: 232  | total loss: [1m[32m0.13454[0m[0m | time: 78.781s
[2K
| Adam | epoch: 007 | loss: 0.13454 - acc: 0.9578 -- iter: 0320/1177
[A[ATraining Step: 233  | total loss: [1m[32m0.13413[0m[0m | time: 86.971s
[2K
| Adam | epoch: 007 | loss: 0.13413 - acc: 0.9589 -- iter: 0352/1177
[A[ATraining Step: 234  | total loss: [1m[32m0.16952[0m[0m | time: 95.183s
[2K
| Adam | epoch: 007 | loss: 0.16952 - acc: 0.9536 -- iter: 0384/1177
[A[ATraining Step: 235  | total loss: [1m[32m0.15833[0m[0m | time: 103.136s
[2K
| Adam | epoch: 007 | loss: 0.15833 - acc: 0.9583 -- iter: 0416/1177
[A[ATraining Step: 236  | total loss: [1m[32m0.14668[0m[0m | time: 111.466s
[2K
| Adam | epoch: 007 | loss: 0.14668 - acc: 0.9625 -- iter: 0448/1177
[A[ATraining Step: 237  | total loss: [1m[32m0.15423[0m[0m | time: 119.590s
[2K
| Adam | epoch: 007 | loss: 0.15423 - acc: 0.9568 -- iter: 0480/1177
[A[ATraining Step: 238  | total loss: [1m[32m0.14205[0m[0m | time: 127.672s
[2K
| Adam | epoch: 007 | loss: 0.14205 - acc: 0.9611 -- iter: 0512/1177
[A[ATraining Step: 239  | total loss: [1m[32m0.13887[0m[0m | time: 135.771s
[2K
| Adam | epoch: 007 | loss: 0.13887 - acc: 0.9619 -- iter: 0544/1177
[A[ATraining Step: 240  | total loss: [1m[32m0.12756[0m[0m | time: 143.958s
[2K
| Adam | epoch: 007 | loss: 0.12756 - acc: 0.9657 -- iter: 0576/1177
[A[ATraining Step: 241  | total loss: [1m[32m0.13819[0m[0m | time: 152.061s
[2K
| Adam | epoch: 007 | loss: 0.13819 - acc: 0.9598 -- iter: 0608/1177
[A[ATraining Step: 242  | total loss: [1m[32m0.12758[0m[0m | time: 160.239s
[2K
| Adam | epoch: 007 | loss: 0.12758 - acc: 0.9638 -- iter: 0640/1177
[A[ATraining Step: 243  | total loss: [1m[32m0.12734[0m[0m | time: 168.312s
[2K
| Adam | epoch: 007 | loss: 0.12734 - acc: 0.9643 -- iter: 0672/1177
[A[ATraining Step: 244  | total loss: [1m[32m0.12361[0m[0m | time: 176.460s
[2K
| Adam | epoch: 007 | loss: 0.12361 - acc: 0.9647 -- iter: 0704/1177
[A[ATraining Step: 245  | total loss: [1m[32m0.11816[0m[0m | time: 184.639s
[2K
| Adam | epoch: 007 | loss: 0.11816 - acc: 0.9651 -- iter: 0736/1177
[A[ATraining Step: 246  | total loss: [1m[32m0.11359[0m[0m | time: 192.683s
[2K
| Adam | epoch: 007 | loss: 0.11359 - acc: 0.9655 -- iter: 0768/1177
[A[ATraining Step: 247  | total loss: [1m[32m0.10904[0m[0m | time: 201.040s
[2K
| Adam | epoch: 007 | loss: 0.10904 - acc: 0.9658 -- iter: 0800/1177
[A[ATraining Step: 248  | total loss: [1m[32m0.10052[0m[0m | time: 209.203s
[2K
| Adam | epoch: 007 | loss: 0.10052 - acc: 0.9692 -- iter: 0832/1177
[A[ATraining Step: 249  | total loss: [1m[32m0.09564[0m[0m | time: 217.580s
[2K
| Adam | epoch: 007 | loss: 0.09564 - acc: 0.9692 -- iter: 0864/1177
[A[ATraining Step: 250  | total loss: [1m[32m0.10950[0m[0m | time: 225.614s
[2K
| Adam | epoch: 007 | loss: 0.10950 - acc: 0.9629 -- iter: 0896/1177
[A[ATraining Step: 251  | total loss: [1m[32m0.10416[0m[0m | time: 233.690s
[2K
| Adam | epoch: 007 | loss: 0.10416 - acc: 0.9635 -- iter: 0928/1177
[A[ATraining Step: 252  | total loss: [1m[32m0.09584[0m[0m | time: 241.826s
[2K
| Adam | epoch: 007 | loss: 0.09584 - acc: 0.9671 -- iter: 0960/1177
[A[ATraining Step: 253  | total loss: [1m[32m0.11045[0m[0m | time: 252.253s
[2K
| Adam | epoch: 007 | loss: 0.11045 - acc: 0.9642 -- iter: 0992/1177
[A[ATraining Step: 254  | total loss: [1m[32m0.10231[0m[0m | time: 260.670s
[2K
| Adam | epoch: 007 | loss: 0.10231 - acc: 0.9678 -- iter: 1024/1177
[A[ATraining Step: 255  | total loss: [1m[32m0.10212[0m[0m | time: 268.961s
[2K
| Adam | epoch: 007 | loss: 0.10212 - acc: 0.9647 -- iter: 1056/1177
[A[ATraining Step: 256  | total loss: [1m[32m0.10319[0m[0m | time: 277.244s
[2K
| Adam | epoch: 007 | loss: 0.10319 - acc: 0.9651 -- iter: 1088/1177
[A[ATraining Step: 257  | total loss: [1m[32m0.11341[0m[0m | time: 285.252s
[2K
| Adam | epoch: 007 | loss: 0.11341 - acc: 0.9592 -- iter: 1120/1177
[A[ATraining Step: 258  | total loss: [1m[32m0.11394[0m[0m | time: 293.291s
[2K
| Adam | epoch: 007 | loss: 0.11394 - acc: 0.9602 -- iter: 1152/1177
[A[ATraining Step: 259  | total loss: [1m[32m0.12781[0m[0m | time: 444.195s
[2K
| Adam | epoch: 007 | loss: 0.12781 - acc: 0.9548 | val_loss: 1.90004 - val_acc: 0.6902 -- iter: 1177/1177
--
Training Step: 260  | total loss: [1m[32m0.12155[0m[0m | time: 18.674s
[2K
| Adam | epoch: 008 | loss: 0.12155 - acc: 0.9562 -- iter: 0032/1177
[A[ATraining Step: 261  | total loss: [1m[32m0.11712[0m[0m | time: 37.281s
[2K
| Adam | epoch: 008 | loss: 0.11712 - acc: 0.9543 -- iter: 0064/1177
[A[ATraining Step: 262  | total loss: [1m[32m0.11344[0m[0m | time: 51.651s
[2K
| Adam | epoch: 008 | loss: 0.11344 - acc: 0.9558 -- iter: 0096/1177
[A[ATraining Step: 263  | total loss: [1m[32m0.10409[0m[0m | time: 60.236s
[2K
| Adam | epoch: 008 | loss: 0.10409 - acc: 0.9602 -- iter: 0128/1177
[A[ATraining Step: 264  | total loss: [1m[32m0.12069[0m[0m | time: 70.713s
[2K
| Adam | epoch: 008 | loss: 0.12069 - acc: 0.9517 -- iter: 0160/1177
[A[ATraining Step: 265  | total loss: [1m[32m0.11949[0m[0m | time: 77.279s
[2K
| Adam | epoch: 008 | loss: 0.11949 - acc: 0.9534 -- iter: 0192/1177
[A[ATraining Step: 266  | total loss: [1m[32m0.13165[0m[0m | time: 84.065s
[2K
| Adam | epoch: 008 | loss: 0.13165 - acc: 0.9500 -- iter: 0224/1177
[A[ATraining Step: 267  | total loss: [1m[32m0.12270[0m[0m | time: 92.219s
[2K
| Adam | epoch: 008 | loss: 0.12270 - acc: 0.9550 -- iter: 0256/1177
[A[ATraining Step: 268  | total loss: [1m[32m0.12352[0m[0m | time: 100.642s
[2K
| Adam | epoch: 008 | loss: 0.12352 - acc: 0.9502 -- iter: 0288/1177
[A[ATraining Step: 269  | total loss: [1m[32m0.13302[0m[0m | time: 110.765s
[2K
| Adam | epoch: 008 | loss: 0.13302 - acc: 0.9426 -- iter: 0320/1177
[A[ATraining Step: 270  | total loss: [1m[32m0.15575[0m[0m | time: 129.474s
[2K
| Adam | epoch: 008 | loss: 0.15575 - acc: 0.9359 -- iter: 0352/1177
[A[ATraining Step: 271  | total loss: [1m[32m0.14576[0m[0m | time: 153.769s
[2K
| Adam | epoch: 008 | loss: 0.14576 - acc: 0.9423 -- iter: 0384/1177
[A[ATraining Step: 272  | total loss: [1m[32m0.15366[0m[0m | time: 168.788s
[2K
| Adam | epoch: 008 | loss: 0.15366 - acc: 0.9449 -- iter: 0416/1177
[A[ATraining Step: 273  | total loss: [1m[32m0.15129[0m[0m | time: 184.605s
[2K
| Adam | epoch: 008 | loss: 0.15129 - acc: 0.9442 -- iter: 0448/1177
[A[ATraining Step: 274  | total loss: [1m[32m0.14144[0m[0m | time: 200.347s
[2K
| Adam | epoch: 008 | loss: 0.14144 - acc: 0.9498 -- iter: 0480/1177
[A[ATraining Step: 275  | total loss: [1m[32m0.13040[0m[0m | time: 214.015s
[2K
| Adam | epoch: 008 | loss: 0.13040 - acc: 0.9548 -- iter: 0512/1177
[A[ATraining Step: 276  | total loss: [1m[32m0.12875[0m[0m | time: 231.000s
[2K
| Adam | epoch: 008 | loss: 0.12875 - acc: 0.9562 -- iter: 0544/1177
[A[ATraining Step: 277  | total loss: [1m[32m0.13088[0m[0m | time: 246.227s
[2K
| Adam | epoch: 008 | loss: 0.13088 - acc: 0.9543 -- iter: 0576/1177
[A[ATraining Step: 278  | total loss: [1m[32m0.12685[0m[0m | time: 254.593s
[2K
| Adam | epoch: 008 | loss: 0.12685 - acc: 0.9526 -- iter: 0608/1177
[A[ATraining Step: 279  | total loss: [1m[32m0.11757[0m[0m | time: 262.893s
[2K
| Adam | epoch: 008 | loss: 0.11757 - acc: 0.9574 -- iter: 0640/1177
[A[ATraining Step: 280  | total loss: [1m[32m0.11213[0m[0m | time: 271.183s
[2K
| Adam | epoch: 008 | loss: 0.11213 - acc: 0.9585 -- iter: 0672/1177
[A[ATraining Step: 281  | total loss: [1m[32m0.12095[0m[0m | time: 279.490s
[2K
| Adam | epoch: 008 | loss: 0.12095 - acc: 0.9564 -- iter: 0704/1177
[A[ATraining Step: 282  | total loss: [1m[32m0.11101[0m[0m | time: 288.461s
[2K
| Adam | epoch: 008 | loss: 0.11101 - acc: 0.9608 -- iter: 0736/1177
[A[ATraining Step: 283  | total loss: [1m[32m0.11509[0m[0m | time: 357.830s
[2K
| Adam | epoch: 008 | loss: 0.11509 - acc: 0.9553 -- iter: 0768/1177
[A[ATraining Step: 284  | total loss: [1m[32m0.10938[0m[0m | time: 459.830s
[2K
| Adam | epoch: 008 | loss: 0.10938 - acc: 0.9567 -- iter: 0800/1177
[A[ATraining Step: 285  | total loss: [1m[32m0.10544[0m[0m | time: 562.727s
[2K
| Adam | epoch: 008 | loss: 0.10544 - acc: 0.9579 -- iter: 0832/1177
[A[ATraining Step: 286  | total loss: [1m[32m0.10074[0m[0m | time: 577.331s
[2K
| Adam | epoch: 008 | loss: 0.10074 - acc: 0.9590 -- iter: 0864/1177
[A[ATraining Step: 287  | total loss: [1m[32m0.09816[0m[0m | time: 649.391s
[2K
| Adam | epoch: 008 | loss: 0.09816 - acc: 0.9599 -- iter: 0896/1177
[A[ATraining Step: 288  | total loss: [1m[32m0.09784[0m[0m | time: 696.793s
[2K
| Adam | epoch: 008 | loss: 0.09784 - acc: 0.9577 -- iter: 0928/1177
[A[ATraining Step: 289  | total loss: [1m[32m0.08997[0m[0m | time: 709.779s
[2K
| Adam | epoch: 008 | loss: 0.08997 - acc: 0.9619 -- iter: 0960/1177
[A[ATraining Step: 290  | total loss: [1m[32m0.08541[0m[0m | time: 719.491s
[2K
| Adam | epoch: 008 | loss: 0.08541 - acc: 0.9657 -- iter: 0992/1177
[A[ATraining Step: 291  | total loss: [1m[32m0.07846[0m[0m | time: 727.738s
[2K
| Adam | epoch: 008 | loss: 0.07846 - acc: 0.9692 -- iter: 1024/1177
[A[ATraining Step: 292  | total loss: [1m[32m0.07214[0m[0m | time: 736.046s
[2K
| Adam | epoch: 008 | loss: 0.07214 - acc: 0.9722 -- iter: 1056/1177
[A[ATraining Step: 293  | total loss: [1m[32m0.07277[0m[0m | time: 750.824s
[2K
| Adam | epoch: 008 | loss: 0.07277 - acc: 0.9719 -- iter: 1088/1177
[A[ATraining Step: 294  | total loss: [1m[32m0.08872[0m[0m | time: 762.612s
[2K
| Adam | epoch: 008 | loss: 0.08872 - acc: 0.9685 -- iter: 1120/1177
[A[ATraining Step: 295  | total loss: [1m[32m0.09808[0m[0m | time: 775.894s
[2K
| Adam | epoch: 008 | loss: 0.09808 - acc: 0.9622 -- iter: 1152/1177
[A[ATraining Step: 296  | total loss: [1m[32m0.08926[0m[0m | time: 817.963s
[2K
| Adam | epoch: 008 | loss: 0.08926 - acc: 0.9660 | val_loss: 2.00888 - val_acc: 0.6277 -- iter: 1177/1177
--
Training Step: 297  | total loss: [1m[32m0.10276[0m[0m | time: 8.079s
[2K
| Adam | epoch: 009 | loss: 0.10276 - acc: 0.9632 -- iter: 0032/1177
[A[ATraining Step: 298  | total loss: [1m[32m0.10566[0m[0m | time: 16.258s
[2K
| Adam | epoch: 009 | loss: 0.10566 - acc: 0.9606 -- iter: 0064/1177
[A[ATraining Step: 299  | total loss: [1m[32m0.11598[0m[0m | time: 26.203s
[2K
| Adam | epoch: 009 | loss: 0.11598 - acc: 0.9614 -- iter: 0096/1177
[A[ATraining Step: 300  | total loss: [1m[32m0.11797[0m[0m | time: 39.468s
[2K
| Adam | epoch: 009 | loss: 0.11797 - acc: 0.9559 -- iter: 0128/1177
[A[ATraining Step: 301  | total loss: [1m[32m0.12126[0m[0m | time: 51.470s
[2K
| Adam | epoch: 009 | loss: 0.12126 - acc: 0.9541 -- iter: 0160/1177
[A[ATraining Step: 302  | total loss: [1m[32m0.11820[0m[0m | time: 72.794s
[2K
| Adam | epoch: 009 | loss: 0.11820 - acc: 0.9555 -- iter: 0192/1177
[A[ATraining Step: 303  | total loss: [1m[32m0.13446[0m[0m | time: 83.874s
[2K
| Adam | epoch: 009 | loss: 0.13446 - acc: 0.9506 -- iter: 0224/1177
[A[ATraining Step: 304  | total loss: [1m[32m0.14378[0m[0m | time: 94.741s
[2K
| Adam | epoch: 009 | loss: 0.14378 - acc: 0.9475 -- iter: 0256/1177
[A[ATraining Step: 305  | total loss: [1m[32m0.13309[0m[0m | time: 107.929s
[2K
| Adam | epoch: 009 | loss: 0.13309 - acc: 0.9528 -- iter: 0288/1177
[A[ATraining Step: 306  | total loss: [1m[32m0.14217[0m[0m | time: 120.924s
[2K
| Adam | epoch: 009 | loss: 0.14217 - acc: 0.9481 -- iter: 0320/1177
[A[ATraining Step: 307  | total loss: [1m[32m0.14196[0m[0m | time: 132.491s
[2K
| Adam | epoch: 009 | loss: 0.14196 - acc: 0.9502 -- iter: 0352/1177
[A[ATraining Step: 308  | total loss: [1m[32m0.13295[0m[0m | time: 140.602s
[2K
| Adam | epoch: 009 | loss: 0.13295 - acc: 0.9552 -- iter: 0384/1177
[A[ATraining Step: 309  | total loss: [1m[32m0.13156[0m[0m | time: 148.721s
[2K
| Adam | epoch: 009 | loss: 0.13156 - acc: 0.9534 -- iter: 0416/1177
[A[ATraining Step: 310  | total loss: [1m[32m0.14759[0m[0m | time: 156.986s
[2K
| Adam | epoch: 009 | loss: 0.14759 - acc: 0.9518 -- iter: 0448/1177
[A[ATraining Step: 311  | total loss: [1m[32m0.13515[0m[0m | time: 165.100s
[2K
| Adam | epoch: 009 | loss: 0.13515 - acc: 0.9566 -- iter: 0480/1177
[A[ATraining Step: 312  | total loss: [1m[32m0.12636[0m[0m | time: 173.300s
[2K
| Adam | epoch: 009 | loss: 0.12636 - acc: 0.9578 -- iter: 0512/1177
[A[ATraining Step: 313  | total loss: [1m[32m0.12117[0m[0m | time: 186.846s
[2K
| Adam | epoch: 009 | loss: 0.12117 - acc: 0.9589 -- iter: 0544/1177
[A[ATraining Step: 314  | total loss: [1m[32m0.12673[0m[0m | time: 194.960s
[2K
| Adam | epoch: 009 | loss: 0.12673 - acc: 0.9568 -- iter: 0576/1177
[A[ATraining Step: 315  | total loss: [1m[32m0.13244[0m[0m | time: 202.970s
[2K
| Adam | epoch: 009 | loss: 0.13244 - acc: 0.9580 -- iter: 0608/1177
[A[ATraining Step: 316  | total loss: [1m[32m0.12082[0m[0m | time: 211.255s
[2K
| Adam | epoch: 009 | loss: 0.12082 - acc: 0.9622 -- iter: 0640/1177
[A[ATraining Step: 317  | total loss: [1m[32m0.12815[0m[0m | time: 219.538s
[2K
| Adam | epoch: 009 | loss: 0.12815 - acc: 0.9566 -- iter: 0672/1177
[A[ATraining Step: 318  | total loss: [1m[32m0.11960[0m[0m | time: 227.568s
[2K
| Adam | epoch: 009 | loss: 0.11960 - acc: 0.9609 -- iter: 0704/1177
[A[ATraining Step: 319  | total loss: [1m[32m0.12517[0m[0m | time: 235.876s
[2K
| Adam | epoch: 009 | loss: 0.12517 - acc: 0.9586 -- iter: 0736/1177
[A[ATraining Step: 320  | total loss: [1m[32m0.13825[0m[0m | time: 244.042s
[2K
| Adam | epoch: 009 | loss: 0.13825 - acc: 0.9534 -- iter: 0768/1177
[A[ATraining Step: 321  | total loss: [1m[32m0.12897[0m[0m | time: 252.273s
[2K
| Adam | epoch: 009 | loss: 0.12897 - acc: 0.9580 -- iter: 0800/1177
[A[ATraining Step: 322  | total loss: [1m[32m0.12899[0m[0m | time: 260.328s
[2K
| Adam | epoch: 009 | loss: 0.12899 - acc: 0.9560 -- iter: 0832/1177
[A[ATraining Step: 323  | total loss: [1m[32m0.12929[0m[0m | time: 268.658s
[2K
| Adam | epoch: 009 | loss: 0.12929 - acc: 0.9541 -- iter: 0864/1177
[A[ATraining Step: 324  | total loss: [1m[32m0.13810[0m[0m | time: 277.019s
[2K
| Adam | epoch: 009 | loss: 0.13810 - acc: 0.9462 -- iter: 0896/1177
[A[ATraining Step: 325  | total loss: [1m[32m0.14239[0m[0m | time: 285.414s
[2K
| Adam | epoch: 009 | loss: 0.14239 - acc: 0.9422 -- iter: 0928/1177
[A[ATraining Step: 326  | total loss: [1m[32m0.13140[0m[0m | time: 293.415s
[2K
| Adam | epoch: 009 | loss: 0.13140 - acc: 0.9480 -- iter: 0960/1177
[A[ATraining Step: 327  | total loss: [1m[32m0.12182[0m[0m | time: 301.757s
[2K
| Adam | epoch: 009 | loss: 0.12182 - acc: 0.9532 -- iter: 0992/1177
[A[ATraining Step: 328  | total loss: [1m[32m0.11527[0m[0m | time: 309.912s
[2K
| Adam | epoch: 009 | loss: 0.11527 - acc: 0.9579 -- iter: 1024/1177
[A[ATraining Step: 329  | total loss: [1m[32m0.11458[0m[0m | time: 318.241s
[2K
| Adam | epoch: 009 | loss: 0.11458 - acc: 0.9558 -- iter: 1056/1177
[A[ATraining Step: 330  | total loss: [1m[32m0.12044[0m[0m | time: 326.460s
[2K
| Adam | epoch: 009 | loss: 0.12044 - acc: 0.9509 -- iter: 1088/1177
[A[ATraining Step: 331  | total loss: [1m[32m0.11312[0m[0m | time: 334.759s
[2K
| Adam | epoch: 009 | loss: 0.11312 - acc: 0.9558 -- iter: 1120/1177
[A[ATraining Step: 332  | total loss: [1m[32m0.11195[0m[0m | time: 342.923s
[2K
| Adam | epoch: 009 | loss: 0.11195 - acc: 0.9571 -- iter: 1152/1177
[A[ATraining Step: 333  | total loss: [1m[32m0.11009[0m[0m | time: 368.218s
[2K
| Adam | epoch: 009 | loss: 0.11009 - acc: 0.9583 | val_loss: 1.68737 - val_acc: 0.6685 -- iter: 1177/1177
--
Training Step: 334  | total loss: [1m[32m0.10334[0m[0m | time: 8.399s
[2K
| Adam | epoch: 010 | loss: 0.10334 - acc: 0.9624 -- iter: 0032/1177
[A[ATraining Step: 335  | total loss: [1m[32m0.10011[0m[0m | time: 16.616s
[2K
| Adam | epoch: 010 | loss: 0.10011 - acc: 0.9631 -- iter: 0064/1177
[A[ATraining Step: 336  | total loss: [1m[32m0.11810[0m[0m | time: 24.868s
[2K
| Adam | epoch: 010 | loss: 0.11810 - acc: 0.9605 -- iter: 0096/1177
[A[ATraining Step: 337  | total loss: [1m[32m0.13064[0m[0m | time: 32.950s
[2K
| Adam | epoch: 010 | loss: 0.13064 - acc: 0.9551 -- iter: 0128/1177
[A[ATraining Step: 338  | total loss: [1m[32m0.12739[0m[0m | time: 40.943s
[2K
| Adam | epoch: 010 | loss: 0.12739 - acc: 0.9596 -- iter: 0160/1177
[A[ATraining Step: 339  | total loss: [1m[32m0.11984[0m[0m | time: 49.028s
[2K
| Adam | epoch: 010 | loss: 0.11984 - acc: 0.9636 -- iter: 0192/1177
[A[ATraining Step: 340  | total loss: [1m[32m0.12266[0m[0m | time: 57.020s
[2K
| Adam | epoch: 010 | loss: 0.12266 - acc: 0.9641 -- iter: 0224/1177
[A[ATraining Step: 341  | total loss: [1m[32m0.11687[0m[0m | time: 63.767s
[2K
| Adam | epoch: 010 | loss: 0.11687 - acc: 0.9646 -- iter: 0256/1177
[A[ATraining Step: 342  | total loss: [1m[32m0.10960[0m[0m | time: 70.481s
[2K
| Adam | epoch: 010 | loss: 0.10960 - acc: 0.9641 -- iter: 0288/1177
[A[ATraining Step: 343  | total loss: [1m[32m0.10002[0m[0m | time: 78.546s
[2K
| Adam | epoch: 010 | loss: 0.10002 - acc: 0.9677 -- iter: 0320/1177
[A[ATraining Step: 344  | total loss: [1m[32m0.09405[0m[0m | time: 86.734s
[2K
| Adam | epoch: 010 | loss: 0.09405 - acc: 0.9709 -- iter: 0352/1177
[A[ATraining Step: 345  | total loss: [1m[32m0.08793[0m[0m | time: 94.913s
[2K
| Adam | epoch: 010 | loss: 0.08793 - acc: 0.9739 -- iter: 0384/1177
[A[ATraining Step: 346  | total loss: [1m[32m0.10457[0m[0m | time: 103.165s
[2K
| Adam | epoch: 010 | loss: 0.10457 - acc: 0.9671 -- iter: 0416/1177
[A[ATraining Step: 347  | total loss: [1m[32m0.09743[0m[0m | time: 111.131s
[2K
| Adam | epoch: 010 | loss: 0.09743 - acc: 0.9704 -- iter: 0448/1177
[A[ATraining Step: 348  | total loss: [1m[32m0.10182[0m[0m | time: 119.377s
[2K
| Adam | epoch: 010 | loss: 0.10182 - acc: 0.9702 -- iter: 0480/1177
[A[ATraining Step: 349  | total loss: [1m[32m0.15557[0m[0m | time: 127.689s
[2K
| Adam | epoch: 010 | loss: 0.15557 - acc: 0.9544 -- iter: 0512/1177
[A[ATraining Step: 350  | total loss: [1m[32m0.16057[0m[0m | time: 136.074s
[2K
| Adam | epoch: 010 | loss: 0.16057 - acc: 0.9559 -- iter: 0544/1177
[A[ATraining Step: 351  | total loss: [1m[32m0.14585[0m[0m | time: 144.170s
[2K
| Adam | epoch: 010 | loss: 0.14585 - acc: 0.9603 -- iter: 0576/1177
[A[ATraining Step: 352  | total loss: [1m[32m0.13322[0m[0m | time: 152.489s
[2K
| Adam | epoch: 010 | loss: 0.13322 - acc: 0.9643 -- iter: 0608/1177
[A[ATraining Step: 353  | total loss: [1m[32m0.13265[0m[0m | time: 160.658s
[2K
| Adam | epoch: 010 | loss: 0.13265 - acc: 0.9616 -- iter: 0640/1177
[A[ATraining Step: 354  | total loss: [1m[32m0.12154[0m[0m | time: 168.850s
[2K
| Adam | epoch: 010 | loss: 0.12154 - acc: 0.9654 -- iter: 0672/1177
[A[ATraining Step: 355  | total loss: [1m[32m0.11757[0m[0m | time: 176.986s
[2K
| Adam | epoch: 010 | loss: 0.11757 - acc: 0.9658 -- iter: 0704/1177
[A[ATraining Step: 356  | total loss: [1m[32m0.10768[0m[0m | time: 185.159s
[2K
| Adam | epoch: 010 | loss: 0.10768 - acc: 0.9692 -- iter: 0736/1177
[A[ATraining Step: 357  | total loss: [1m[32m0.09821[0m[0m | time: 193.336s
[2K
| Adam | epoch: 010 | loss: 0.09821 - acc: 0.9723 -- iter: 0768/1177
[A[ATraining Step: 358  | total loss: [1m[32m0.09846[0m[0m | time: 201.584s
[2K
| Adam | epoch: 010 | loss: 0.09846 - acc: 0.9719 -- iter: 0800/1177
[A[ATraining Step: 359  | total loss: [1m[32m0.09176[0m[0m | time: 209.715s
[2K
| Adam | epoch: 010 | loss: 0.09176 - acc: 0.9716 -- iter: 0832/1177
[A[ATraining Step: 360  | total loss: [1m[32m0.08479[0m[0m | time: 217.755s
[2K
| Adam | epoch: 010 | loss: 0.08479 - acc: 0.9744 -- iter: 0864/1177
[A[ATraining Step: 361  | total loss: [1m[32m0.07796[0m[0m | time: 225.943s
[2K
| Adam | epoch: 010 | loss: 0.07796 - acc: 0.9770 -- iter: 0896/1177
[A[ATraining Step: 362  | total loss: [1m[32m0.07457[0m[0m | time: 234.079s
[2K
| Adam | epoch: 010 | loss: 0.07457 - acc: 0.9762 -- iter: 0928/1177
[A[ATraining Step: 363  | total loss: [1m[32m0.08332[0m[0m | time: 242.334s
[2K
| Adam | epoch: 010 | loss: 0.08332 - acc: 0.9692 -- iter: 0960/1177
[A[ATraining Step: 364  | total loss: [1m[32m0.07991[0m[0m | time: 250.452s
[2K
| Adam | epoch: 010 | loss: 0.07991 - acc: 0.9691 -- iter: 0992/1177
[A[ATraining Step: 365  | total loss: [1m[32m0.07452[0m[0m | time: 258.484s
[2K
| Adam | epoch: 010 | loss: 0.07452 - acc: 0.9722 -- iter: 1024/1177
[A[ATraining Step: 366  | total loss: [1m[32m0.08811[0m[0m | time: 266.622s
[2K
| Adam | epoch: 010 | loss: 0.08811 - acc: 0.9719 -- iter: 1056/1177
[A[ATraining Step: 367  | total loss: [1m[32m0.08343[0m[0m | time: 274.962s
[2K
| Adam | epoch: 010 | loss: 0.08343 - acc: 0.9747 -- iter: 1088/1177
[A[ATraining Step: 368  | total loss: [1m[32m0.07776[0m[0m | time: 283.122s
[2K
| Adam | epoch: 010 | loss: 0.07776 - acc: 0.9772 -- iter: 1120/1177
[A[ATraining Step: 369  | total loss: [1m[32m0.08173[0m[0m | time: 291.292s
[2K
| Adam | epoch: 010 | loss: 0.08173 - acc: 0.9701 -- iter: 1152/1177
[A[ATraining Step: 370  | total loss: [1m[32m0.07604[0m[0m | time: 316.326s
[2K
| Adam | epoch: 010 | loss: 0.07604 - acc: 0.9731 | val_loss: 1.51944 - val_acc: 0.6467 -- iter: 1177/1177
--
Training Step: 371  | total loss: [1m[32m0.07252[0m[0m | time: 8.255s
[2K
| Adam | epoch: 011 | loss: 0.07252 - acc: 0.9727 -- iter: 0032/1177
[A[ATraining Step: 372  | total loss: [1m[32m0.06804[0m[0m | time: 16.268s
[2K
| Adam | epoch: 011 | loss: 0.06804 - acc: 0.9754 -- iter: 0064/1177
[A[ATraining Step: 373  | total loss: [1m[32m0.09137[0m[0m | time: 24.568s
[2K
| Adam | epoch: 011 | loss: 0.09137 - acc: 0.9716 -- iter: 0096/1177
[A[ATraining Step: 374  | total loss: [1m[32m0.08292[0m[0m | time: 32.634s
[2K
| Adam | epoch: 011 | loss: 0.08292 - acc: 0.9745 -- iter: 0128/1177
[A[ATraining Step: 375  | total loss: [1m[32m0.07515[0m[0m | time: 40.829s
[2K
| Adam | epoch: 011 | loss: 0.07515 - acc: 0.9770 -- iter: 0160/1177
[A[ATraining Step: 376  | total loss: [1m[32m0.11534[0m[0m | time: 48.950s
[2K
| Adam | epoch: 011 | loss: 0.11534 - acc: 0.9699 -- iter: 0192/1177
[A[ATraining Step: 377  | total loss: [1m[32m0.11286[0m[0m | time: 56.996s
[2K
| Adam | epoch: 011 | loss: 0.11286 - acc: 0.9698 -- iter: 0224/1177
[A[ATraining Step: 378  | total loss: [1m[32m0.10932[0m[0m | time: 65.211s
[2K
| Adam | epoch: 011 | loss: 0.10932 - acc: 0.9697 -- iter: 0256/1177
[A[ATraining Step: 379  | total loss: [1m[32m0.09945[0m[0m | time: 71.880s
[2K
| Adam | epoch: 011 | loss: 0.09945 - acc: 0.9727 -- iter: 0288/1177
[A[ATraining Step: 380  | total loss: [1m[32m0.11672[0m[0m | time: 78.432s
[2K
| Adam | epoch: 011 | loss: 0.11672 - acc: 0.9715 -- iter: 0320/1177
[A[ATraining Step: 381  | total loss: [1m[32m0.11280[0m[0m | time: 86.512s
[2K
| Adam | epoch: 011 | loss: 0.11280 - acc: 0.9703 -- iter: 0352/1177
[A[ATraining Step: 382  | total loss: [1m[32m0.10562[0m[0m | time: 94.574s
[2K
| Adam | epoch: 011 | loss: 0.10562 - acc: 0.9733 -- iter: 0384/1177
[A[ATraining Step: 383  | total loss: [1m[32m0.09898[0m[0m | time: 102.666s
[2K
| Adam | epoch: 011 | loss: 0.09898 - acc: 0.9760 -- iter: 0416/1177
[A[ATraining Step: 384  | total loss: [1m[32m0.09050[0m[0m | time: 110.941s
[2K
| Adam | epoch: 011 | loss: 0.09050 - acc: 0.9784 -- iter: 0448/1177
[A[ATraining Step: 385  | total loss: [1m[32m0.08607[0m[0m | time: 118.978s
[2K
| Adam | epoch: 011 | loss: 0.08607 - acc: 0.9774 -- iter: 0480/1177
[A[ATraining Step: 386  | total loss: [1m[32m0.10977[0m[0m | time: 126.942s
[2K
| Adam | epoch: 011 | loss: 0.10977 - acc: 0.9765 -- iter: 0512/1177
[A[ATraining Step: 387  | total loss: [1m[32m0.10303[0m[0m | time: 134.910s
[2K
| Adam | epoch: 011 | loss: 0.10303 - acc: 0.9758 -- iter: 0544/1177
[A[ATraining Step: 388  | total loss: [1m[32m0.09914[0m[0m | time: 143.081s
[2K
| Adam | epoch: 011 | loss: 0.09914 - acc: 0.9751 -- iter: 0576/1177
[A[ATraining Step: 389  | total loss: [1m[32m0.09017[0m[0m | time: 151.300s
[2K
| Adam | epoch: 011 | loss: 0.09017 - acc: 0.9776 -- iter: 0608/1177
[A[ATraining Step: 390  | total loss: [1m[32m0.08486[0m[0m | time: 159.383s
[2K
| Adam | epoch: 011 | loss: 0.08486 - acc: 0.9798 -- iter: 0640/1177
[A[ATraining Step: 391  | total loss: [1m[32m0.07803[0m[0m | time: 167.690s
[2K
| Adam | epoch: 011 | loss: 0.07803 - acc: 0.9818 -- iter: 0672/1177
[A[ATraining Step: 392  | total loss: [1m[32m0.08060[0m[0m | time: 176.030s
[2K
| Adam | epoch: 011 | loss: 0.08060 - acc: 0.9805 -- iter: 0704/1177
[A[ATraining Step: 393  | total loss: [1m[32m0.07793[0m[0m | time: 184.255s
[2K
| Adam | epoch: 011 | loss: 0.07793 - acc: 0.9825 -- iter: 0736/1177
[A[ATraining Step: 394  | total loss: [1m[32m0.07915[0m[0m | time: 192.574s
[2K
| Adam | epoch: 011 | loss: 0.07915 - acc: 0.9811 -- iter: 0768/1177
[A[ATraining Step: 395  | total loss: [1m[32m0.07262[0m[0m | time: 200.566s
[2K
| Adam | epoch: 011 | loss: 0.07262 - acc: 0.9830 -- iter: 0800/1177
[A[ATraining Step: 396  | total loss: [1m[32m0.06927[0m[0m | time: 208.841s
[2K
| Adam | epoch: 011 | loss: 0.06927 - acc: 0.9847 -- iter: 0832/1177
[A[ATraining Step: 397  | total loss: [1m[32m0.06418[0m[0m | time: 217.078s
[2K
| Adam | epoch: 011 | loss: 0.06418 - acc: 0.9862 -- iter: 0864/1177
[A[ATraining Step: 398  | total loss: [1m[32m0.05932[0m[0m | time: 225.171s
[2K
| Adam | epoch: 011 | loss: 0.05932 - acc: 0.9876 -- iter: 0896/1177
[A[ATraining Step: 399  | total loss: [1m[32m0.05489[0m[0m | time: 233.419s
[2K
| Adam | epoch: 011 | loss: 0.05489 - acc: 0.9888 -- iter: 0928/1177
[A[ATraining Step: 400  | total loss: [1m[32m0.05936[0m[0m | time: 258.534s
[2K
| Adam | epoch: 011 | loss: 0.05936 - acc: 0.9837 | val_loss: 0.65238 - val_acc: 0.8234 -- iter: 0960/1177
--
Training Step: 401  | total loss: [1m[32m0.05574[0m[0m | time: 266.851s
[2K
| Adam | epoch: 011 | loss: 0.05574 - acc: 0.9853 -- iter: 0992/1177
[A[ATraining Step: 402  | total loss: [1m[32m0.05539[0m[0m | time: 274.972s
[2K
| Adam | epoch: 011 | loss: 0.05539 - acc: 0.9837 -- iter: 1024/1177
[A[ATraining Step: 403  | total loss: [1m[32m0.05085[0m[0m | time: 283.000s
[2K
| Adam | epoch: 011 | loss: 0.05085 - acc: 0.9853 -- iter: 1056/1177
[A[ATraining Step: 404  | total loss: [1m[32m0.04665[0m[0m | time: 291.027s
[2K
| Adam | epoch: 011 | loss: 0.04665 - acc: 0.9868 -- iter: 1088/1177
[A[ATraining Step: 405  | total loss: [1m[32m0.04682[0m[0m | time: 299.281s
[2K
| Adam | epoch: 011 | loss: 0.04682 - acc: 0.9850 -- iter: 1120/1177
[A[ATraining Step: 406  | total loss: [1m[32m0.04453[0m[0m | time: 307.244s
[2K
| Adam | epoch: 011 | loss: 0.04453 - acc: 0.9865 -- iter: 1152/1177
[A[ATraining Step: 407  | total loss: [1m[32m0.07231[0m[0m | time: 332.536s
[2K
| Adam | epoch: 011 | loss: 0.07231 - acc: 0.9847 | val_loss: 0.74115 - val_acc: 0.8207 -- iter: 1177/1177
--
Training Step: 408  | total loss: [1m[32m0.07077[0m[0m | time: 7.935s
[2K
| Adam | epoch: 012 | loss: 0.07077 - acc: 0.9831 -- iter: 0032/1177
[A[ATraining Step: 409  | total loss: [1m[32m0.06506[0m[0m | time: 15.740s
[2K
| Adam | epoch: 012 | loss: 0.06506 - acc: 0.9848 -- iter: 0064/1177
[A[ATraining Step: 410  | total loss: [1m[32m0.05971[0m[0m | time: 23.760s
[2K
| Adam | epoch: 012 | loss: 0.05971 - acc: 0.9863 -- iter: 0096/1177
[A[ATraining Step: 411  | total loss: [1m[32m0.05449[0m[0m | time: 31.873s
[2K
| Adam | epoch: 012 | loss: 0.05449 - acc: 0.9877 -- iter: 0128/1177
[A[ATraining Step: 412  | total loss: [1m[32m0.05007[0m[0m | time: 39.912s
[2K
| Adam | epoch: 012 | loss: 0.05007 - acc: 0.9889 -- iter: 0160/1177
[A[ATraining Step: 413  | total loss: [1m[32m0.05299[0m[0m | time: 47.860s
[2K
| Adam | epoch: 012 | loss: 0.05299 - acc: 0.9869 -- iter: 0192/1177
[A[ATraining Step: 414  | total loss: [1m[32m0.04962[0m[0m | time: 56.035s
[2K
| Adam | epoch: 012 | loss: 0.04962 - acc: 0.9882 -- iter: 0224/1177
[A[ATraining Step: 415  | total loss: [1m[32m0.04670[0m[0m | time: 64.156s
[2K
| Adam | epoch: 012 | loss: 0.04670 - acc: 0.9894 -- iter: 0256/1177
[A[ATraining Step: 416  | total loss: [1m[32m0.04287[0m[0m | time: 72.233s
[2K
| Adam | epoch: 012 | loss: 0.04287 - acc: 0.9904 -- iter: 0288/1177
[A[ATraining Step: 417  | total loss: [1m[32m0.04047[0m[0m | time: 78.870s
[2K
| Adam | epoch: 012 | loss: 0.04047 - acc: 0.9914 -- iter: 0320/1177
[A[ATraining Step: 418  | total loss: [1m[32m0.04930[0m[0m | time: 85.589s
[2K
| Adam | epoch: 012 | loss: 0.04930 - acc: 0.9843 -- iter: 0352/1177
[A[ATraining Step: 419  | total loss: [1m[32m0.04698[0m[0m | time: 93.835s
[2K
| Adam | epoch: 012 | loss: 0.04698 - acc: 0.9858 -- iter: 0384/1177
[A[ATraining Step: 420  | total loss: [1m[32m0.09098[0m[0m | time: 102.327s
[2K
| Adam | epoch: 012 | loss: 0.09098 - acc: 0.9716 -- iter: 0416/1177
[A[ATraining Step: 421  | total loss: [1m[32m0.09393[0m[0m | time: 110.307s
[2K
| Adam | epoch: 012 | loss: 0.09393 - acc: 0.9713 -- iter: 0448/1177
[A[ATraining Step: 422  | total loss: [1m[32m0.08530[0m[0m | time: 118.537s
[2K
| Adam | epoch: 012 | loss: 0.08530 - acc: 0.9742 -- iter: 0480/1177
[A[ATraining Step: 423  | total loss: [1m[32m0.08082[0m[0m | time: 126.738s
[2K
| Adam | epoch: 012 | loss: 0.08082 - acc: 0.9768 -- iter: 0512/1177
[A[ATraining Step: 424  | total loss: [1m[32m0.09523[0m[0m | time: 135.125s
[2K
| Adam | epoch: 012 | loss: 0.09523 - acc: 0.9760 -- iter: 0544/1177
[A[ATraining Step: 425  | total loss: [1m[32m0.08619[0m[0m | time: 143.247s
[2K
| Adam | epoch: 012 | loss: 0.08619 - acc: 0.9784 -- iter: 0576/1177
[A[ATraining Step: 426  | total loss: [1m[32m0.07854[0m[0m | time: 151.360s
[2K
| Adam | epoch: 012 | loss: 0.07854 - acc: 0.9805 -- iter: 0608/1177
[A[ATraining Step: 427  | total loss: [1m[32m0.07235[0m[0m | time: 159.666s
[2K
| Adam | epoch: 012 | loss: 0.07235 - acc: 0.9825 -- iter: 0640/1177
[A[ATraining Step: 428  | total loss: [1m[32m0.06613[0m[0m | time: 167.938s
[2K
| Adam | epoch: 012 | loss: 0.06613 - acc: 0.9842 -- iter: 0672/1177
[A[ATraining Step: 429  | total loss: [1m[32m0.06065[0m[0m | time: 175.982s
[2K
| Adam | epoch: 012 | loss: 0.06065 - acc: 0.9858 -- iter: 0704/1177
[A[ATraining Step: 430  | total loss: [1m[32m0.06518[0m[0m | time: 184.058s
[2K
| Adam | epoch: 012 | loss: 0.06518 - acc: 0.9810 -- iter: 0736/1177
[A[ATraining Step: 431  | total loss: [1m[32m0.06020[0m[0m | time: 192.129s
[2K
| Adam | epoch: 012 | loss: 0.06020 - acc: 0.9829 -- iter: 0768/1177
[A[ATraining Step: 432  | total loss: [1m[32m0.05498[0m[0m | time: 200.314s
[2K
| Adam | epoch: 012 | loss: 0.05498 - acc: 0.9846 -- iter: 0800/1177
[A[ATraining Step: 433  | total loss: [1m[32m0.05118[0m[0m | time: 208.351s
[2K
| Adam | epoch: 012 | loss: 0.05118 - acc: 0.9861 -- iter: 0832/1177
[A[ATraining Step: 434  | total loss: [1m[32m0.05128[0m[0m | time: 216.591s
[2K
| Adam | epoch: 012 | loss: 0.05128 - acc: 0.9844 -- iter: 0864/1177
[A[ATraining Step: 435  | total loss: [1m[32m0.04751[0m[0m | time: 224.830s
[2K
| Adam | epoch: 012 | loss: 0.04751 - acc: 0.9860 -- iter: 0896/1177
[A[ATraining Step: 436  | total loss: [1m[32m0.04488[0m[0m | time: 232.968s
[2K
| Adam | epoch: 012 | loss: 0.04488 - acc: 0.9874 -- iter: 0928/1177
[A[ATraining Step: 437  | total loss: [1m[32m0.04686[0m[0m | time: 241.337s
[2K
| Adam | epoch: 012 | loss: 0.04686 - acc: 0.9855 -- iter: 0960/1177
[A[ATraining Step: 438  | total loss: [1m[32m0.04407[0m[0m | time: 249.537s
[2K
| Adam | epoch: 012 | loss: 0.04407 - acc: 0.9870 -- iter: 0992/1177
[A[ATraining Step: 439  | total loss: [1m[32m0.04229[0m[0m | time: 257.552s
[2K
| Adam | epoch: 012 | loss: 0.04229 - acc: 0.9883 -- iter: 1024/1177
[A[ATraining Step: 440  | total loss: [1m[32m0.04049[0m[0m | time: 265.643s
[2K
| Adam | epoch: 012 | loss: 0.04049 - acc: 0.9894 -- iter: 1056/1177
[A[ATraining Step: 441  | total loss: [1m[32m0.03741[0m[0m | time: 273.935s
[2K
| Adam | epoch: 012 | loss: 0.03741 - acc: 0.9905 -- iter: 1088/1177
[A[ATraining Step: 442  | total loss: [1m[32m0.03557[0m[0m | time: 282.256s
[2K
| Adam | epoch: 012 | loss: 0.03557 - acc: 0.9914 -- iter: 1120/1177
[A[ATraining Step: 443  | total loss: [1m[32m0.03479[0m[0m | time: 290.412s
[2K
| Adam | epoch: 012 | loss: 0.03479 - acc: 0.9892 -- iter: 1152/1177
[A[ATraining Step: 444  | total loss: [1m[32m0.03186[0m[0m | time: 315.614s
[2K
| Adam | epoch: 012 | loss: 0.03186 - acc: 0.9903 | val_loss: 3.73858 - val_acc: 0.5734 -- iter: 1177/1177
--
Training Step: 445  | total loss: [1m[32m0.03026[0m[0m | time: 8.278s
[2K
| Adam | epoch: 013 | loss: 0.03026 - acc: 0.9912 -- iter: 0032/1177
[A[ATraining Step: 446  | total loss: [1m[32m0.02875[0m[0m | time: 16.306s
[2K
| Adam | epoch: 013 | loss: 0.02875 - acc: 0.9921 -- iter: 0064/1177
[A[ATraining Step: 447  | total loss: [1m[32m0.03833[0m[0m | time: 24.400s
[2K
| Adam | epoch: 013 | loss: 0.03833 - acc: 0.9898 -- iter: 0096/1177
[A[ATraining Step: 448  | total loss: [1m[32m0.04811[0m[0m | time: 32.527s
[2K
| Adam | epoch: 013 | loss: 0.04811 - acc: 0.9877 -- iter: 0128/1177
[A[ATraining Step: 449  | total loss: [1m[32m0.10056[0m[0m | time: 40.659s
[2K
| Adam | epoch: 013 | loss: 0.10056 - acc: 0.9733 -- iter: 0160/1177
[A[ATraining Step: 450  | total loss: [1m[32m0.09950[0m[0m | time: 48.819s
[2K
| Adam | epoch: 013 | loss: 0.09950 - acc: 0.9728 -- iter: 0192/1177
[A[ATraining Step: 451  | total loss: [1m[32m0.09904[0m[0m | time: 56.939s
[2K
| Adam | epoch: 013 | loss: 0.09904 - acc: 0.9724 -- iter: 0224/1177
[A[ATraining Step: 452  | total loss: [1m[32m0.09281[0m[0m | time: 65.023s
[2K
| Adam | epoch: 013 | loss: 0.09281 - acc: 0.9720 -- iter: 0256/1177
[A[ATraining Step: 453  | total loss: [1m[32m0.08890[0m[0m | time: 73.167s
[2K
| Adam | epoch: 013 | loss: 0.08890 - acc: 0.9717 -- iter: 0288/1177
[A[ATraining Step: 454  | total loss: [1m[32m0.08126[0m[0m | time: 81.535s
[2K
| Adam | epoch: 013 | loss: 0.08126 - acc: 0.9745 -- iter: 0320/1177
[A[ATraining Step: 455  | total loss: [1m[32m0.07425[0m[0m | time: 88.293s
[2K
| Adam | epoch: 013 | loss: 0.07425 - acc: 0.9771 -- iter: 0352/1177
[A[ATraining Step: 456  | total loss: [1m[32m0.06747[0m[0m | time: 95.071s
[2K
| Adam | epoch: 013 | loss: 0.06747 - acc: 0.9794 -- iter: 0384/1177
[A[ATraining Step: 457  | total loss: [1m[32m0.06144[0m[0m | time: 103.061s
[2K
| Adam | epoch: 013 | loss: 0.06144 - acc: 0.9814 -- iter: 0416/1177
[A[ATraining Step: 458  | total loss: [1m[32m0.05705[0m[0m | time: 111.285s
[2K
| Adam | epoch: 013 | loss: 0.05705 - acc: 0.9833 -- iter: 0448/1177
[A[ATraining Step: 459  | total loss: [1m[32m0.05340[0m[0m | time: 119.656s
[2K
| Adam | epoch: 013 | loss: 0.05340 - acc: 0.9850 -- iter: 0480/1177
[A[ATraining Step: 460  | total loss: [1m[32m0.05149[0m[0m | time: 127.914s
[2K
| Adam | epoch: 013 | loss: 0.05149 - acc: 0.9865 -- iter: 0512/1177
[A[ATraining Step: 461  | total loss: [1m[32m0.04826[0m[0m | time: 136.128s
[2K
| Adam | epoch: 013 | loss: 0.04826 - acc: 0.9878 -- iter: 0544/1177
[A[ATraining Step: 462  | total loss: [1m[32m0.07944[0m[0m | time: 144.352s
[2K
| Adam | epoch: 013 | loss: 0.07944 - acc: 0.9828 -- iter: 0576/1177
[A[ATraining Step: 463  | total loss: [1m[32m0.07198[0m[0m | time: 152.421s
[2K
| Adam | epoch: 013 | loss: 0.07198 - acc: 0.9845 -- iter: 0608/1177
[A[ATraining Step: 464  | total loss: [1m[32m0.07007[0m[0m | time: 160.649s
[2K
| Adam | epoch: 013 | loss: 0.07007 - acc: 0.9861 -- iter: 0640/1177
[A[ATraining Step: 465  | total loss: [1m[32m0.06358[0m[0m | time: 168.842s
[2K
| Adam | epoch: 013 | loss: 0.06358 - acc: 0.9875 -- iter: 0672/1177
[A[ATraining Step: 466  | total loss: [1m[32m0.06477[0m[0m | time: 176.962s
[2K
| Adam | epoch: 013 | loss: 0.06477 - acc: 0.9856 -- iter: 0704/1177
[A[ATraining Step: 467  | total loss: [1m[32m0.06094[0m[0m | time: 185.054s
[2K
| Adam | epoch: 013 | loss: 0.06094 - acc: 0.9870 -- iter: 0736/1177
[A[ATraining Step: 468  | total loss: [1m[32m0.05552[0m[0m | time: 193.293s
[2K
| Adam | epoch: 013 | loss: 0.05552 - acc: 0.9883 -- iter: 0768/1177
[A[ATraining Step: 469  | total loss: [1m[32m0.05828[0m[0m | time: 201.382s
[2K
| Adam | epoch: 013 | loss: 0.05828 - acc: 0.9864 -- iter: 0800/1177
[A[ATraining Step: 470  | total loss: [1m[32m0.05496[0m[0m | time: 209.763s
[2K
| Adam | epoch: 013 | loss: 0.05496 - acc: 0.9877 -- iter: 0832/1177
[A[ATraining Step: 471  | total loss: [1m[32m0.05006[0m[0m | time: 217.919s
[2K
| Adam | epoch: 013 | loss: 0.05006 - acc: 0.9890 -- iter: 0864/1177
[A[ATraining Step: 472  | total loss: [1m[32m0.05535[0m[0m | time: 226.255s
[2K
| Adam | epoch: 013 | loss: 0.05535 - acc: 0.9869 -- iter: 0896/1177
[A[ATraining Step: 473  | total loss: [1m[32m0.05335[0m[0m | time: 234.398s
[2K
| Adam | epoch: 013 | loss: 0.05335 - acc: 0.9851 -- iter: 0928/1177
[A[ATraining Step: 474  | total loss: [1m[32m0.04820[0m[0m | time: 242.663s
[2K
| Adam | epoch: 013 | loss: 0.04820 - acc: 0.9866 -- iter: 0960/1177
[A[ATraining Step: 475  | total loss: [1m[32m0.04422[0m[0m | time: 250.836s
[2K
| Adam | epoch: 013 | loss: 0.04422 - acc: 0.9879 -- iter: 0992/1177
[A[ATraining Step: 476  | total loss: [1m[32m0.04002[0m[0m | time: 259.021s
[2K
| Adam | epoch: 013 | loss: 0.04002 - acc: 0.9892 -- iter: 1024/1177
[A[ATraining Step: 477  | total loss: [1m[32m0.03787[0m[0m | time: 267.144s
[2K
| Adam | epoch: 013 | loss: 0.03787 - acc: 0.9902 -- iter: 1056/1177
[A[ATraining Step: 478  | total loss: [1m[32m0.03594[0m[0m | time: 275.337s
[2K
| Adam | epoch: 013 | loss: 0.03594 - acc: 0.9912 -- iter: 1088/1177
[A[ATraining Step: 479  | total loss: [1m[32m0.04255[0m[0m | time: 283.333s
[2K
| Adam | epoch: 013 | loss: 0.04255 - acc: 0.9858 -- iter: 1120/1177
[A[ATraining Step: 480  | total loss: [1m[32m0.03878[0m[0m | time: 291.467s
[2K
| Adam | epoch: 013 | loss: 0.03878 - acc: 0.9873 -- iter: 1152/1177
[A[ATraining Step: 481  | total loss: [1m[32m0.05206[0m[0m | time: 316.700s
[2K
| Adam | epoch: 013 | loss: 0.05206 - acc: 0.9854 | val_loss: 0.58596 - val_acc: 0.8397 -- iter: 1177/1177
--
Training Step: 482  | total loss: [1m[32m0.04726[0m[0m | time: 8.033s
[2K
| Adam | epoch: 014 | loss: 0.04726 - acc: 0.9869 -- iter: 0032/1177
[A[ATraining Step: 483  | total loss: [1m[32m0.04272[0m[0m | time: 16.105s
[2K
| Adam | epoch: 014 | loss: 0.04272 - acc: 0.9882 -- iter: 0064/1177
[A[ATraining Step: 484  | total loss: [1m[32m0.04139[0m[0m | time: 24.346s
[2K
| Adam | epoch: 014 | loss: 0.04139 - acc: 0.9894 -- iter: 0096/1177
[A[ATraining Step: 485  | total loss: [1m[32m0.03754[0m[0m | time: 32.306s
[2K
| Adam | epoch: 014 | loss: 0.03754 - acc: 0.9904 -- iter: 0128/1177
[A[ATraining Step: 486  | total loss: [1m[32m0.05296[0m[0m | time: 40.383s
[2K
| Adam | epoch: 014 | loss: 0.05296 - acc: 0.9883 -- iter: 0160/1177
[A[ATraining Step: 487  | total loss: [1m[32m0.04911[0m[0m | time: 48.515s
[2K
| Adam | epoch: 014 | loss: 0.04911 - acc: 0.9894 -- iter: 0192/1177
[A[ATraining Step: 488  | total loss: [1m[32m0.04450[0m[0m | time: 56.707s
[2K
| Adam | epoch: 014 | loss: 0.04450 - acc: 0.9905 -- iter: 0224/1177
[A[ATraining Step: 489  | total loss: [1m[32m0.04027[0m[0m | time: 64.782s
[2K
| Adam | epoch: 014 | loss: 0.04027 - acc: 0.9914 -- iter: 0256/1177
[A[ATraining Step: 490  | total loss: [1m[32m0.04204[0m[0m | time: 73.036s
[2K
| Adam | epoch: 014 | loss: 0.04204 - acc: 0.9892 -- iter: 0288/1177
[A[ATraining Step: 491  | total loss: [1m[32m0.03984[0m[0m | time: 81.046s
[2K
| Adam | epoch: 014 | loss: 0.03984 - acc: 0.9903 -- iter: 0320/1177
[A[ATraining Step: 492  | total loss: [1m[32m0.03987[0m[0m | time: 88.999s
[2K
| Adam | epoch: 014 | loss: 0.03987 - acc: 0.9912 -- iter: 0352/1177
[A[ATraining Step: 493  | total loss: [1m[32m0.03702[0m[0m | time: 95.663s
[2K
| Adam | epoch: 014 | loss: 0.03702 - acc: 0.9921 -- iter: 0384/1177
[A[ATraining Step: 494  | total loss: [1m[32m0.03843[0m[0m | time: 102.467s
[2K
| Adam | epoch: 014 | loss: 0.03843 - acc: 0.9929 -- iter: 0416/1177
[A[ATraining Step: 495  | total loss: [1m[32m0.03598[0m[0m | time: 110.628s
[2K
| Adam | epoch: 014 | loss: 0.03598 - acc: 0.9936 -- iter: 0448/1177
[A[ATraining Step: 496  | total loss: [1m[32m0.03271[0m[0m | time: 118.928s
[2K
| Adam | epoch: 014 | loss: 0.03271 - acc: 0.9942 -- iter: 0480/1177
[A[ATraining Step: 497  | total loss: [1m[32m0.03457[0m[0m | time: 127.228s
[2K
| Adam | epoch: 014 | loss: 0.03457 - acc: 0.9917 -- iter: 0512/1177
[A[ATraining Step: 498  | total loss: [1m[32m0.04309[0m[0m | time: 135.386s
[2K
| Adam | epoch: 014 | loss: 0.04309 - acc: 0.9863 -- iter: 0544/1177
[A[ATraining Step: 499  | total loss: [1m[32m0.05400[0m[0m | time: 143.978s
[2K
| Adam | epoch: 014 | loss: 0.05400 - acc: 0.9845 -- iter: 0576/1177
[A[ATraining Step: 500  | total loss: [1m[32m0.11263[0m[0m | time: 154.854s
[2K
| Adam | epoch: 014 | loss: 0.11263 - acc: 0.9798 -- iter: 0608/1177
[A[ATraining Step: 501  | total loss: [1m[32m0.10443[0m[0m | time: 165.657s
[2K
| Adam | epoch: 014 | loss: 0.10443 - acc: 0.9818 -- iter: 0640/1177
[A[ATraining Step: 502  | total loss: [1m[32m0.10429[0m[0m | time: 176.077s
[2K
| Adam | epoch: 014 | loss: 0.10429 - acc: 0.9805 -- iter: 0672/1177
[A[ATraining Step: 503  | total loss: [1m[32m0.10475[0m[0m | time: 186.914s
[2K
| Adam | epoch: 014 | loss: 0.10475 - acc: 0.9762 -- iter: 0704/1177
[A[ATraining Step: 504  | total loss: [1m[32m0.09576[0m[0m | time: 197.643s
[2K
| Adam | epoch: 014 | loss: 0.09576 - acc: 0.9786 -- iter: 0736/1177
[A[ATraining Step: 505  | total loss: [1m[32m0.08742[0m[0m | time: 209.034s
[2K
| Adam | epoch: 014 | loss: 0.08742 - acc: 0.9807 -- iter: 0768/1177
[A[ATraining Step: 506  | total loss: [1m[32m0.08344[0m[0m | time: 219.990s
[2K
| Adam | epoch: 014 | loss: 0.08344 - acc: 0.9795 -- iter: 0800/1177
[A[ATraining Step: 507  | total loss: [1m[32m0.07639[0m[0m | time: 230.483s
[2K
| Adam | epoch: 014 | loss: 0.07639 - acc: 0.9816 -- iter: 0832/1177
[A[ATraining Step: 508  | total loss: [1m[32m0.07021[0m[0m | time: 241.361s
[2K
| Adam | epoch: 014 | loss: 0.07021 - acc: 0.9834 -- iter: 0864/1177
[A[ATraining Step: 509  | total loss: [1m[32m0.08462[0m[0m | time: 251.926s
[2K
| Adam | epoch: 014 | loss: 0.08462 - acc: 0.9788 -- iter: 0896/1177
[A[ATraining Step: 510  | total loss: [1m[32m0.07818[0m[0m | time: 263.103s
[2K
| Adam | epoch: 014 | loss: 0.07818 - acc: 0.9810 -- iter: 0928/1177
[A[ATraining Step: 511  | total loss: [1m[32m0.07331[0m[0m | time: 273.970s
[2K
| Adam | epoch: 014 | loss: 0.07331 - acc: 0.9797 -- iter: 0960/1177
[A[ATraining Step: 512  | total loss: [1m[32m0.06613[0m[0m | time: 284.319s
[2K
| Adam | epoch: 014 | loss: 0.06613 - acc: 0.9818 -- iter: 0992/1177
[A[ATraining Step: 513  | total loss: [1m[32m0.06143[0m[0m | time: 294.822s
[2K
| Adam | epoch: 014 | loss: 0.06143 - acc: 0.9836 -- iter: 1024/1177
[A[ATraining Step: 514  | total loss: [1m[32m0.05609[0m[0m | time: 305.379s
[2K
| Adam | epoch: 014 | loss: 0.05609 - acc: 0.9852 -- iter: 1056/1177
[A[ATraining Step: 515  | total loss: [1m[32m0.05618[0m[0m | time: 316.786s
[2K
| Adam | epoch: 014 | loss: 0.05618 - acc: 0.9836 -- iter: 1088/1177
[A[ATraining Step: 516  | total loss: [1m[32m0.05703[0m[0m | time: 327.497s
[2K
| Adam | epoch: 014 | loss: 0.05703 - acc: 0.9821 -- iter: 1120/1177
[A[ATraining Step: 517  | total loss: [1m[32m0.05257[0m[0m | time: 338.801s
[2K
| Adam | epoch: 014 | loss: 0.05257 - acc: 0.9839 -- iter: 1152/1177
[A[ATraining Step: 518  | total loss: [1m[32m0.05432[0m[0m | time: 371.259s
[2K
| Adam | epoch: 014 | loss: 0.05432 - acc: 0.9824 | val_loss: 0.95549 - val_acc: 0.7826 -- iter: 1177/1177
--
Training Step: 519  | total loss: [1m[32m0.05320[0m[0m | time: 10.415s
[2K
| Adam | epoch: 015 | loss: 0.05320 - acc: 0.9841 -- iter: 0032/1177
[A[ATraining Step: 520  | total loss: [1m[32m0.05198[0m[0m | time: 21.204s
[2K
| Adam | epoch: 015 | loss: 0.05198 - acc: 0.9857 -- iter: 0064/1177
[A[ATraining Step: 521  | total loss: [1m[32m0.06281[0m[0m | time: 31.618s
[2K
| Adam | epoch: 015 | loss: 0.06281 - acc: 0.9809 -- iter: 0096/1177
[A[ATraining Step: 522  | total loss: [1m[32m0.06688[0m[0m | time: 43.435s
[2K
| Adam | epoch: 015 | loss: 0.06688 - acc: 0.9766 -- iter: 0128/1177
[A[ATraining Step: 523  | total loss: [1m[32m0.06071[0m[0m | time: 54.172s
[2K
| Adam | epoch: 015 | loss: 0.06071 - acc: 0.9789 -- iter: 0160/1177
[A[ATraining Step: 524  | total loss: [1m[32m0.06873[0m[0m | time: 65.074s
[2K
| Adam | epoch: 015 | loss: 0.06873 - acc: 0.9748 -- iter: 0192/1177
[A[ATraining Step: 525  | total loss: [1m[32m0.06491[0m[0m | time: 75.531s
[2K
| Adam | epoch: 015 | loss: 0.06491 - acc: 0.9773 -- iter: 0224/1177
[A[ATraining Step: 526  | total loss: [1m[32m0.05978[0m[0m | time: 86.391s
[2K
| Adam | epoch: 015 | loss: 0.05978 - acc: 0.9796 -- iter: 0256/1177
[A[ATraining Step: 527  | total loss: [1m[32m0.05714[0m[0m | time: 98.009s
[2K
| Adam | epoch: 015 | loss: 0.05714 - acc: 0.9785 -- iter: 0288/1177
[A[ATraining Step: 528  | total loss: [1m[32m0.06289[0m[0m | time: 109.734s
[2K
| Adam | epoch: 015 | loss: 0.06289 - acc: 0.9775 -- iter: 0320/1177
[A[ATraining Step: 529  | total loss: [1m[32m0.05843[0m[0m | time: 120.110s
[2K
| Adam | epoch: 015 | loss: 0.05843 - acc: 0.9798 -- iter: 0352/1177
[A[ATraining Step: 530  | total loss: [1m[32m0.05688[0m[0m | time: 131.192s
[2K
| Adam | epoch: 015 | loss: 0.05688 - acc: 0.9787 -- iter: 0384/1177
[A[ATraining Step: 531  | total loss: [1m[32m0.05300[0m[0m | time: 140.149s
[2K
| Adam | epoch: 015 | loss: 0.05300 - acc: 0.9808 -- iter: 0416/1177
[A[ATraining Step: 532  | total loss: [1m[32m0.05008[0m[0m | time: 149.846s
[2K
| Adam | epoch: 015 | loss: 0.05008 - acc: 0.9827 -- iter: 0448/1177
[A[ATraining Step: 533  | total loss: [1m[32m0.04627[0m[0m | time: 161.498s
[2K
| Adam | epoch: 015 | loss: 0.04627 - acc: 0.9844 -- iter: 0480/1177
[A[ATraining Step: 534  | total loss: [1m[32m0.04651[0m[0m | time: 171.606s
[2K
| Adam | epoch: 015 | loss: 0.04651 - acc: 0.9829 -- iter: 0512/1177
[A[ATraining Step: 535  | total loss: [1m[32m0.04304[0m[0m | time: 182.455s
[2K
| Adam | epoch: 015 | loss: 0.04304 - acc: 0.9846 -- iter: 0544/1177
[A[ATraining Step: 536  | total loss: [1m[32m0.05444[0m[0m | time: 193.674s
[2K
| Adam | epoch: 015 | loss: 0.05444 - acc: 0.9830 -- iter: 0576/1177
[A[ATraining Step: 537  | total loss: [1m[32m0.06795[0m[0m | time: 204.395s
[2K
| Adam | epoch: 015 | loss: 0.06795 - acc: 0.9784 -- iter: 0608/1177
[A[ATraining Step: 538  | total loss: [1m[32m0.06139[0m[0m | time: 214.992s
[2K
| Adam | epoch: 015 | loss: 0.06139 - acc: 0.9806 -- iter: 0640/1177
[A[ATraining Step: 539  | total loss: [1m[32m0.05577[0m[0m | time: 227.762s
[2K
| Adam | epoch: 015 | loss: 0.05577 - acc: 0.9825 -- iter: 0672/1177
[A[ATraining Step: 540  | total loss: [1m[32m0.05044[0m[0m | time: 238.392s
[2K
| Adam | epoch: 015 | loss: 0.05044 - acc: 0.9843 -- iter: 0704/1177
[A[ATraining Step: 541  | total loss: [1m[32m0.04663[0m[0m | time: 249.163s
[2K
| Adam | epoch: 015 | loss: 0.04663 - acc: 0.9859 -- iter: 0736/1177
[A[ATraining Step: 542  | total loss: [1m[32m0.04261[0m[0m | time: 259.706s
[2K
| Adam | epoch: 015 | loss: 0.04261 - acc: 0.9873 -- iter: 0768/1177
[A[ATraining Step: 543  | total loss: [1m[32m0.04095[0m[0m | time: 275.195s
[2K
| Adam | epoch: 015 | loss: 0.04095 - acc: 0.9885 -- iter: 0800/1177
[A[ATraining Step: 544  | total loss: [1m[32m0.04524[0m[0m | time: 285.900s
[2K
| Adam | epoch: 015 | loss: 0.04524 - acc: 0.9866 -- iter: 0832/1177
[A[ATraining Step: 545  | total loss: [1m[32m0.04812[0m[0m | time: 296.147s
[2K
| Adam | epoch: 015 | loss: 0.04812 - acc: 0.9848 -- iter: 0864/1177
[A[ATraining Step: 546  | total loss: [1m[32m0.04755[0m[0m | time: 361.008s
[2K
| Adam | epoch: 015 | loss: 0.04755 - acc: 0.9832 -- iter: 0896/1177
[A[ATraining Step: 547  | total loss: [1m[32m0.04799[0m[0m | time: 371.488s
[2K
| Adam | epoch: 015 | loss: 0.04799 - acc: 0.9817 -- iter: 0928/1177
[A[ATraining Step: 548  | total loss: [1m[32m0.04361[0m[0m | time: 381.864s
[2K
| Adam | epoch: 015 | loss: 0.04361 - acc: 0.9836 -- iter: 0960/1177
[A[ATraining Step: 549  | total loss: [1m[32m0.07834[0m[0m | time: 392.453s
[2K
| Adam | epoch: 015 | loss: 0.07834 - acc: 0.9758 -- iter: 0992/1177
[A[ATraining Step: 550  | total loss: [1m[32m0.09431[0m[0m | time: 403.229s
[2K
| Adam | epoch: 015 | loss: 0.09431 - acc: 0.9720 -- iter: 1024/1177
[A[ATraining Step: 551  | total loss: [1m[32m0.09025[0m[0m | time: 414.015s
[2K
| Adam | epoch: 015 | loss: 0.09025 - acc: 0.9717 -- iter: 1056/1177
[A[ATraining Step: 552  | total loss: [1m[32m0.08440[0m[0m | time: 424.770s
[2K
| Adam | epoch: 015 | loss: 0.08440 - acc: 0.9714 -- iter: 1088/1177
[A[ATraining Step: 553  | total loss: [1m[32m0.07911[0m[0m | time: 435.567s
[2K
| Adam | epoch: 015 | loss: 0.07911 - acc: 0.9742 -- iter: 1120/1177
[A[ATraining Step: 554  | total loss: [1m[32m0.07381[0m[0m | time: 446.119s
[2K
| Adam | epoch: 015 | loss: 0.07381 - acc: 0.9768 -- iter: 1152/1177
[A[ATraining Step: 555  | total loss: [1m[32m0.07187[0m[0m | time: 479.149s
[2K
| Adam | epoch: 015 | loss: 0.07187 - acc: 0.9760 | val_loss: 1.13765 - val_acc: 0.7228 -- iter: 1177/1177
--
Validation AUC:0.8973469690232695
Validation AUPRC:0.9201964191085051
Test AUC:0.9307028687919165
Test AUPRC:0.9290400339012043
BestTestF1Score	0.87	0.73	0.87	0.85	0.89	161	29	158	20	0.99
BestTestMCCScore	0.87	0.73	0.87	0.85	0.89	161	29	158	20	0.99
BestTestAccuracyScore	0.87	0.73	0.87	0.85	0.89	161	29	158	20	0.99
BestValidationF1Score	0.84	0.67	0.83	0.84	0.85	166	32	141	29	0.99
BestValidationMCC	0.84	0.67	0.83	0.84	0.85	166	32	141	29	0.99
BestValidationAccuracy	0.84	0.67	0.83	0.84	0.85	166	32	141	29	0.99
TestPredictions (Threshold:0.99)
CHEMBL149488,TP,ACT,1.0	CHEMBL342805,TP,ACT,1.0	CHEMBL327626,TN,INACT,0.0	CHEMBL1259071,TN,INACT,0.0	CHEMBL323264,TP,ACT,1.0	CHEMBL2397476,FP,INACT,1.0	CHEMBL194647,TP,ACT,1.0	CHEMBL225364,TP,ACT,1.0	CHEMBL71907,FP,INACT,1.0	CHEMBL3577342,TN,INACT,0.44999998807907104	CHEMBL2368253,TP,ACT,1.0	CHEMBL1631534,FN,ACT,0.9700000286102295	CHEMBL1289047,TP,ACT,1.0	CHEMBL435784,TN,INACT,0.25	CHEMBL303204,TN,INACT,0.03999999910593033	CHEMBL112558,TP,ACT,1.0	CHEMBL451335,TN,INACT,0.0	CHEMBL190298,TP,ACT,1.0	CHEMBL89689,TN,INACT,0.949999988079071	CHEMBL3763779,TP,ACT,0.9900000095367432	CHEMBL3403339,TN,INACT,0.6499999761581421	CHEMBL161694,TP,ACT,1.0	CHEMBL3126382,TP,ACT,1.0	CHEMBL2111789,FP,INACT,1.0	CHEMBL298649,TN,INACT,0.23999999463558197	CHEMBL3577343,TN,INACT,0.4399999976158142	CHEMBL34328,FP,INACT,0.9900000095367432	CHEMBL553666,TN,INACT,0.05999999865889549	CHEMBL501645,TP,ACT,1.0	CHEMBL3423401,TN,INACT,0.4399999976158142	CHEMBL38562,TN,INACT,0.03999999910593033	CHEMBL441256,TP,ACT,1.0	CHEMBL354748,TN,INACT,0.05000000074505806	CHEMBL74066,TN,INACT,0.3499999940395355	CHEMBL336081,TN,INACT,0.03999999910593033	CHEMBL419547,TP,ACT,1.0	CHEMBL3403334,TN,INACT,0.029999999329447746	CHEMBL199088,FN,ACT,0.9700000286102295	CHEMBL63760,TN,INACT,0.949999988079071	CHEMBL60435,TN,INACT,0.4399999976158142	CHEMBL64120,TN,INACT,0.9700000286102295	CHEMBL274256,TP,ACT,1.0	CHEMBL116876,TP,ACT,1.0	CHEMBL147660,TP,ACT,1.0	CHEMBL197159,TN,INACT,0.05000000074505806	CHEMBL173656,TP,ACT,1.0	CHEMBL196140,FN,ACT,0.949999988079071	CHEMBL293614,TP,ACT,1.0	CHEMBL109839,TP,ACT,1.0	CHEMBL166089,TN,INACT,0.11999999731779099	CHEMBL393539,TP,ACT,1.0	CHEMBL2260926,TP,ACT,1.0	CHEMBL43788,TN,INACT,0.8299999833106995	CHEMBL558364,TN,INACT,0.38999998569488525	CHEMBL328476,TN,INACT,0.009999999776482582	CHEMBL195114,TP,ACT,1.0	CHEMBL81191,TP,ACT,1.0	CHEMBL525362,TP,ACT,1.0	CHEMBL3354069,FP,INACT,1.0	CHEMBL496317,TP,ACT,1.0	CHEMBL3218123,FP,INACT,1.0	CHEMBL71899,FN,ACT,0.9800000190734863	CHEMBL105025,TP,ACT,1.0	CHEMBL302172,TP,ACT,1.0	CHEMBL145584,TN,INACT,0.009999999776482582	CHEMBL345951,TN,INACT,0.3199999928474426	CHEMBL146396,TP,ACT,1.0	CHEMBL254500,FP,INACT,1.0	CHEMBL321190,TP,ACT,1.0	CHEMBL160396,TN,INACT,0.1899999976158142	CHEMBL3633656,FP,INACT,1.0	CHEMBL143512,FN,ACT,0.18000000715255737	CHEMBL164035,TP,ACT,1.0	CHEMBL163639,TP,ACT,0.9900000095367432	CHEMBL322537,TN,INACT,0.7699999809265137	CHEMBL67684,TP,ACT,1.0	CHEMBL342330,TP,ACT,1.0	CHEMBL285010,TN,INACT,0.029999999329447746	CHEMBL430683,TN,INACT,0.6200000047683716	CHEMBL328940,TP,ACT,1.0	CHEMBL3234454,TN,INACT,0.9100000262260437	CHEMBL3423400,TN,INACT,0.949999988079071	CHEMBL320577,TN,INACT,0.27000001072883606	CHEMBL423260,TN,INACT,0.03999999910593033	CHEMBL43661,FP,INACT,1.0	CHEMBL67109,TN,INACT,0.0	CHEMBL421523,TN,INACT,0.0	CHEMBL103479,TP,ACT,1.0	CHEMBL292274,TP,ACT,1.0	CHEMBL2164434,TN,INACT,0.7599999904632568	CHEMBL391033,TP,ACT,1.0	CHEMBL435060,TP,ACT,1.0	CHEMBL128699,TP,ACT,1.0	CHEMBL65765,TP,ACT,1.0	CHEMBL47404,TN,INACT,0.0	CHEMBL3238446,TN,INACT,0.9800000190734863	CHEMBL160070,TP,ACT,1.0	CHEMBL1631536,TP,ACT,1.0	CHEMBL159819,TP,ACT,1.0	CHEMBL173162,TP,ACT,1.0	CHEMBL110904,TN,INACT,0.27000001072883606	CHEMBL344154,TN,INACT,0.23999999463558197	CHEMBL297599,TN,INACT,0.029999999329447746	CHEMBL339980,FN,ACT,0.10000000149011612	CHEMBL81703,TP,ACT,1.0	CHEMBL521235,TP,ACT,1.0	CHEMBL302829,TN,INACT,0.8100000023841858	CHEMBL65824,TP,ACT,1.0	CHEMBL413040,TN,INACT,0.0	CHEMBL161410,TP,ACT,1.0	CHEMBL151668,FP,INACT,1.0	CHEMBL40796,TN,INACT,0.029999999329447746	CHEMBL3335537,TN,INACT,0.30000001192092896	CHEMBL324685,TN,INACT,0.3400000035762787	CHEMBL557840,TN,INACT,0.41999998688697815	CHEMBL304950,TN,INACT,0.0	CHEMBL340786,TP,ACT,1.0	CHEMBL95175,TP,ACT,1.0	CHEMBL67460,TP,ACT,1.0	CHEMBL344127,TP,ACT,1.0	CHEMBL195927,TP,ACT,1.0	CHEMBL146132,TP,ACT,1.0	CHEMBL307659,TN,INACT,0.11999999731779099	CHEMBL248407,TP,ACT,1.0	CHEMBL289284,TN,INACT,0.6200000047683716	CHEMBL495213,TP,ACT,1.0	CHEMBL320763,TN,INACT,0.07000000029802322	CHEMBL294732,TP,ACT,1.0	CHEMBL3104093,TP,ACT,1.0	CHEMBL64003,TP,ACT,1.0	CHEMBL191605,TP,ACT,1.0	CHEMBL316983,TN,INACT,0.0	CHEMBL71625,TP,ACT,1.0	CHEMBL168541,TN,INACT,0.9300000071525574	CHEMBL509314,TP,ACT,1.0	CHEMBL3780248,TN,INACT,0.0	CHEMBL399704,TP,ACT,1.0	CHEMBL71676,FN,ACT,0.11999999731779099	CHEMBL430500,TP,ACT,1.0	CHEMBL103424,TP,ACT,1.0	CHEMBL79853,TP,ACT,1.0	CHEMBL296245,TN,INACT,0.10000000149011612	CHEMBL118553,TN,INACT,0.0	CHEMBL118,TN,INACT,0.3100000023841858	CHEMBL3290971,TN,INACT,0.009999999776482582	CHEMBL42411,FP,INACT,1.0	CHEMBL117046,TP,ACT,1.0	CHEMBL33438,FP,INACT,0.9900000095367432	CHEMBL1923416,TN,INACT,0.019999999552965164	CHEMBL47040,TN,INACT,0.11999999731779099	CHEMBL227429,TN,INACT,0.0	CHEMBL3085215,TN,INACT,0.7699999809265137	CHEMBL343217,TP,ACT,1.0	CHEMBL357077,TN,INACT,0.009999999776482582	CHEMBL246598,TP,ACT,1.0	CHEMBL2048230,TN,INACT,0.009999999776482582	CHEMBL330003,TN,INACT,0.03999999910593033	CHEMBL312670,TN,INACT,0.029999999329447746	CHEMBL163516,TP,ACT,1.0	CHEMBL194610,FN,ACT,0.07999999821186066	CHEMBL27763,TN,INACT,0.9399999976158142	CHEMBL371655,TP,ACT,1.0	CHEMBL8412,TN,INACT,0.07000000029802322	CHEMBL352159,TP,ACT,1.0	CHEMBL147940,TP,ACT,1.0	CHEMBL434125,TP,ACT,1.0	CHEMBL351346,TP,ACT,1.0	CHEMBL432495,TN,INACT,0.009999999776482582	CHEMBL241279,TN,INACT,0.6800000071525574	CHEMBL345657,TP,ACT,1.0	CHEMBL146024,TP,ACT,1.0	CHEMBL104210,FP,INACT,1.0	CHEMBL110053,TN,INACT,0.5400000214576721	CHEMBL519019,TP,ACT,1.0	CHEMBL294547,TP,ACT,1.0	CHEMBL302027,TN,INACT,0.07999999821186066	CHEMBL163151,TP,ACT,1.0	CHEMBL71474,TP,ACT,1.0	CHEMBL11629,TN,INACT,0.7599999904632568	CHEMBL423599,TP,ACT,1.0	CHEMBL59517,TN,INACT,0.03999999910593033	CHEMBL97450,TP,ACT,1.0	CHEMBL168855,TN,INACT,0.9200000166893005	CHEMBL303538,TN,INACT,0.5899999737739563	CHEMBL523095,TP,ACT,0.9900000095367432	CHEMBL370896,FN,ACT,0.38999998569488525	CHEMBL269576,TN,INACT,0.9399999976158142	CHEMBL306645,FP,INACT,1.0	CHEMBL305976,FN,ACT,0.07000000029802322	CHEMBL78929,TN,INACT,0.029999999329447746	CHEMBL376813,TP,ACT,1.0	CHEMBL62902,FP,INACT,1.0	CHEMBL318018,FN,ACT,0.800000011920929	CHEMBL1258723,TP,ACT,1.0	CHEMBL148071,TP,ACT,1.0	CHEMBL192176,TP,ACT,1.0	CHEMBL2205811,TP,ACT,1.0	CHEMBL11409,TP,ACT,1.0	CHEMBL435936,TP,ACT,1.0	CHEMBL324586,TN,INACT,0.3700000047683716	CHEMBL2324200,FP,INACT,1.0	CHEMBL284912,TN,INACT,0.019999999552965164	CHEMBL45456,TN,INACT,0.9599999785423279	CHEMBL80945,TN,INACT,0.0	CHEMBL428991,TP,ACT,1.0	CHEMBL283535,TN,INACT,0.0	CHEMBL273860,TN,INACT,0.6600000262260437	CHEMBL527880,TN,INACT,0.0	CHEMBL252231,FP,INACT,1.0	CHEMBL368629,TN,INACT,0.18000000715255737	CHEMBL148095,TP,ACT,1.0	CHEMBL80317,TN,INACT,0.019999999552965164	CHEMBL6640,TP,ACT,1.0	CHEMBL606556,FN,ACT,0.41999998688697815	CHEMBL451394,FN,ACT,0.9700000286102295	CHEMBL65461,TN,INACT,0.8100000023841858	CHEMBL380054,TN,INACT,0.10999999940395355	CHEMBL1907665,FP,INACT,0.9900000095367432	CHEMBL1765671,TN,INACT,0.009999999776482582	CHEMBL224738,TP,ACT,1.0	CHEMBL275469,TN,INACT,0.8999999761581421	CHEMBL349689,TN,INACT,0.6800000071525574	CHEMBL593685,TN,INACT,0.0	CHEMBL11262,TN,INACT,0.0	CHEMBL404505,TN,INACT,0.9300000071525574	CHEMBL368584,FP,INACT,1.0	CHEMBL239166,TP,ACT,1.0	CHEMBL303921,TP,ACT,1.0	CHEMBL323245,TN,INACT,0.9200000166893005	CHEMBL146338,TP,ACT,1.0	CHEMBL58241,TN,INACT,0.0	CHEMBL150260,TN,INACT,0.1899999976158142	CHEMBL328089,TN,INACT,0.9700000286102295	CHEMBL70728,TN,INACT,0.1899999976158142	CHEMBL140620,TN,INACT,0.75	CHEMBL78669,TN,INACT,0.0	CHEMBL1170027,TN,INACT,0.0	CHEMBL481245,FP,INACT,1.0	CHEMBL2413154,FN,ACT,0.05999999865889549	CHEMBL304857,TP,ACT,1.0	CHEMBL1437,TN,INACT,0.3700000047683716	CHEMBL105556,TP,ACT,1.0	CHEMBL33224,TN,INACT,0.17000000178813934	CHEMBL147238,TN,INACT,0.10000000149011612	CHEMBL352123,TP,ACT,1.0	CHEMBL298203,TN,INACT,0.07000000029802322	CHEMBL348811,TP,ACT,1.0	CHEMBL88629,TN,INACT,0.800000011920929	CHEMBL472289,TP,ACT,1.0	CHEMBL257547,TN,INACT,0.949999988079071	CHEMBL70680,TP,ACT,1.0	CHEMBL450852,TP,ACT,1.0	CHEMBL39,TP,ACT,1.0	CHEMBL3609143,FN,ACT,0.9599999785423279	CHEMBL1744040,FN,ACT,0.6800000071525574	CHEMBL2260933,TP,ACT,1.0	CHEMBL296291,TN,INACT,0.5099999904632568	CHEMBL194701,TP,ACT,1.0	CHEMBL98350,FP,INACT,1.0	CHEMBL341854,TP,ACT,1.0	CHEMBL606547,TP,ACT,1.0	CHEMBL1275709,TP,ACT,1.0	CHEMBL402143,TP,ACT,1.0	CHEMBL305301,TP,ACT,0.9900000095367432	CHEMBL520129,FN,ACT,0.9700000286102295	CHEMBL441259,TP,ACT,1.0	CHEMBL74342,TN,INACT,0.11999999731779099	CHEMBL93868,TP,ACT,1.0	CHEMBL42228,TN,INACT,0.029999999329447746	CHEMBL279520,TN,INACT,0.3199999928474426	CHEMBL194837,FN,ACT,0.8299999833106995	CHEMBL1765667,TN,INACT,0.0	CHEMBL191921,TP,ACT,1.0	CHEMBL163573,TP,ACT,1.0	CHEMBL108337,TP,ACT,0.9900000095367432	CHEMBL245319,FP,INACT,1.0	CHEMBL47688,TN,INACT,0.12999999523162842	CHEMBL241101,TN,INACT,0.699999988079071	CHEMBL12713,TP,ACT,1.0	CHEMBL552615,TN,INACT,0.36000001430511475	CHEMBL562384,TN,INACT,0.3799999952316284	CHEMBL52785,TN,INACT,0.05000000074505806	CHEMBL140365,TN,INACT,0.5799999833106995	CHEMBL362992,TP,ACT,1.0	CHEMBL1381098,FP,INACT,1.0	CHEMBL325359,TP,ACT,1.0	CHEMBL310427,FP,INACT,1.0	CHEMBL330603,TP,ACT,1.0	CHEMBL2391353,TN,INACT,0.0	CHEMBL459061,TP,ACT,1.0	CHEMBL334498,TN,INACT,0.8700000047683716	CHEMBL303203,TN,INACT,0.75	CHEMBL416747,TN,INACT,0.029999999329447746	CHEMBL276819,TN,INACT,0.7400000095367432	CHEMBL309397,TN,INACT,0.009999999776482582	CHEMBL593861,TN,INACT,0.0	CHEMBL59597,TN,INACT,0.05999999865889549	CHEMBL11265,TP,ACT,1.0	CHEMBL29410,TP,ACT,0.9900000095367432	CHEMBL169889,TN,INACT,0.019999999552965164	CHEMBL425064,TN,INACT,0.05999999865889549	CHEMBL416688,TP,ACT,1.0	CHEMBL137483,TN,INACT,0.9100000262260437	CHEMBL251541,TN,INACT,0.8199999928474426	CHEMBL50456,TN,INACT,0.0	CHEMBL293232,TN,INACT,0.029999999329447746	CHEMBL21937,TN,INACT,0.33000001311302185	CHEMBL161176,TP,ACT,1.0	CHEMBL1083787,FP,INACT,1.0	CHEMBL144302,TN,INACT,0.9800000190734863	CHEMBL601013,TP,ACT,1.0	CHEMBL310425,TN,INACT,0.949999988079071	CHEMBL414420,TP,ACT,1.0	CHEMBL489393,TP,ACT,1.0	CHEMBL311781,TN,INACT,0.019999999552965164	CHEMBL450281,TP,ACT,1.0	CHEMBL339308,TP,ACT,1.0	CHEMBL349174,TP,ACT,1.0	CHEMBL208311,FP,INACT,1.0	CHEMBL57908,TN,INACT,0.009999999776482582	CHEMBL69943,FN,ACT,0.9800000190734863	CHEMBL104484,TP,ACT,1.0	CHEMBL164413,TP,ACT,1.0	CHEMBL239598,TP,ACT,1.0	CHEMBL62601,FP,INACT,1.0	CHEMBL51888,TN,INACT,0.03999999910593033	CHEMBL422737,TP,ACT,1.0	CHEMBL79725,TP,ACT,1.0	CHEMBL247609,TP,ACT,1.0	CHEMBL27065,FP,INACT,1.0	CHEMBL304767,TP,ACT,1.0	CHEMBL423610,FN,ACT,0.9800000190734863	CHEMBL104848,TN,INACT,0.5	CHEMBL162724,TP,ACT,1.0	CHEMBL318901,TP,ACT,1.0	CHEMBL7441,TN,INACT,0.5600000023841858	CHEMBL333089,TP,ACT,1.0	CHEMBL432332,TP,ACT,1.0	CHEMBL241099,TN,INACT,0.949999988079071	CHEMBL161970,TP,ACT,1.0	CHEMBL110317,TP,ACT,1.0	CHEMBL1782812,TN,INACT,0.07000000029802322	CHEMBL30831,TP,ACT,1.0	CHEMBL37512,TN,INACT,0.9100000262260437	CHEMBL497979,TP,ACT,1.0	CHEMBL142295,TN,INACT,0.10000000149011612	CHEMBL3323005,TN,INACT,0.03999999910593033	CHEMBL1263,TN,INACT,0.9800000190734863	CHEMBL2093084,TN,INACT,0.0	CHEMBL498354,TP,ACT,1.0	CHEMBL89688,TN,INACT,0.009999999776482582	CHEMBL281232,TN,INACT,0.0	CHEMBL241500,TP,ACT,1.0	CHEMBL162805,TP,ACT,1.0	CHEMBL1632213,TP,ACT,1.0	CHEMBL3290977,FP,INACT,1.0	CHEMBL163462,TP,ACT,1.0	CHEMBL326125,TP,ACT,1.0	CHEMBL440961,TN,INACT,0.8799999952316284	CHEMBL308347,TP,ACT,1.0	CHEMBL212631,TN,INACT,0.019999999552965164	CHEMBL487805,TN,INACT,0.7300000190734863	CHEMBL441296,TP,ACT,1.0	CHEMBL300735,TN,INACT,0.15000000596046448	CHEMBL277467,TP,ACT,1.0	CHEMBL3609140,TP,ACT,0.9900000095367432	CHEMBL320569,TN,INACT,0.12999999523162842	CHEMBL1788198,TP,ACT,1.0	

