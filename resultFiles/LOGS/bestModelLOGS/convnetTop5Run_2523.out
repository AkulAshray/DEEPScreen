CNNModel CHEMBL2815 adam 0.0005 15 32 0 0.8 False True
Number of active compounds :	1160
Number of inactive compounds :	1160
---------------------------------
Run id: CNNModel_CHEMBL2815_adam_0.0005_15_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2815_adam_0.0005_15_32_0.8_True/
---------------------------------
Training samples: 1481
Validation samples: 464
--
Training Step: 1  | time: 1.228s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1481
[A[ATraining Step: 2  | total loss: [1m[32m0.62376[0m[0m | time: 2.142s
[2K
| Adam | epoch: 001 | loss: 0.62376 - acc: 0.4781 -- iter: 0064/1481
[A[ATraining Step: 3  | total loss: [1m[32m0.68103[0m[0m | time: 3.074s
[2K
| Adam | epoch: 001 | loss: 0.68103 - acc: 0.4449 -- iter: 0096/1481
[A[ATraining Step: 4  | total loss: [1m[32m0.68992[0m[0m | time: 3.876s
[2K
| Adam | epoch: 001 | loss: 0.68992 - acc: 0.4393 -- iter: 0128/1481
[A[ATraining Step: 5  | total loss: [1m[32m0.69202[0m[0m | time: 4.931s
[2K
| Adam | epoch: 001 | loss: 0.69202 - acc: 0.5030 -- iter: 0160/1481
[A[ATraining Step: 6  | total loss: [1m[32m0.69232[0m[0m | time: 5.953s
[2K
| Adam | epoch: 001 | loss: 0.69232 - acc: 0.5212 -- iter: 0192/1481
[A[ATraining Step: 7  | total loss: [1m[32m0.68956[0m[0m | time: 6.880s
[2K
| Adam | epoch: 001 | loss: 0.68956 - acc: 0.5835 -- iter: 0224/1481
[A[ATraining Step: 8  | total loss: [1m[32m0.69382[0m[0m | time: 7.692s
[2K
| Adam | epoch: 001 | loss: 0.69382 - acc: 0.5189 -- iter: 0256/1481
[A[ATraining Step: 9  | total loss: [1m[32m0.69300[0m[0m | time: 8.554s
[2K
| Adam | epoch: 001 | loss: 0.69300 - acc: 0.5089 -- iter: 0288/1481
[A[ATraining Step: 10  | total loss: [1m[32m0.69174[0m[0m | time: 9.386s
[2K
| Adam | epoch: 001 | loss: 0.69174 - acc: 0.5201 -- iter: 0320/1481
[A[ATraining Step: 11  | total loss: [1m[32m0.68441[0m[0m | time: 10.217s
[2K
| Adam | epoch: 001 | loss: 0.68441 - acc: 0.5846 -- iter: 0352/1481
[A[ATraining Step: 12  | total loss: [1m[32m0.69290[0m[0m | time: 11.075s
[2K
| Adam | epoch: 001 | loss: 0.69290 - acc: 0.5325 -- iter: 0384/1481
[A[ATraining Step: 13  | total loss: [1m[32m0.69853[0m[0m | time: 11.931s
[2K
| Adam | epoch: 001 | loss: 0.69853 - acc: 0.4918 -- iter: 0416/1481
[A[ATraining Step: 14  | total loss: [1m[32m0.69572[0m[0m | time: 12.816s
[2K
| Adam | epoch: 001 | loss: 0.69572 - acc: 0.5079 -- iter: 0448/1481
[A[ATraining Step: 15  | total loss: [1m[32m0.69149[0m[0m | time: 13.710s
[2K
| Adam | epoch: 001 | loss: 0.69149 - acc: 0.5293 -- iter: 0480/1481
[A[ATraining Step: 16  | total loss: [1m[32m0.68960[0m[0m | time: 14.512s
[2K
| Adam | epoch: 001 | loss: 0.68960 - acc: 0.5417 -- iter: 0512/1481
[A[ATraining Step: 17  | total loss: [1m[32m0.69004[0m[0m | time: 15.569s
[2K
| Adam | epoch: 001 | loss: 0.69004 - acc: 0.5380 -- iter: 0544/1481
[A[ATraining Step: 18  | total loss: [1m[32m0.69295[0m[0m | time: 16.592s
[2K
| Adam | epoch: 001 | loss: 0.69295 - acc: 0.5140 -- iter: 0576/1481
[A[ATraining Step: 19  | total loss: [1m[32m0.69561[0m[0m | time: 17.433s
[2K
| Adam | epoch: 001 | loss: 0.69561 - acc: 0.4885 -- iter: 0608/1481
[A[ATraining Step: 20  | total loss: [1m[32m0.69669[0m[0m | time: 18.208s
[2K
| Adam | epoch: 001 | loss: 0.69669 - acc: 0.4721 -- iter: 0640/1481
[A[ATraining Step: 21  | total loss: [1m[32m0.69548[0m[0m | time: 19.110s
[2K
| Adam | epoch: 001 | loss: 0.69548 - acc: 0.4808 -- iter: 0672/1481
[A[ATraining Step: 22  | total loss: [1m[32m0.69687[0m[0m | time: 19.968s
[2K
| Adam | epoch: 001 | loss: 0.69687 - acc: 0.4397 -- iter: 0704/1481
[A[ATraining Step: 23  | total loss: [1m[32m0.69498[0m[0m | time: 20.898s
[2K
| Adam | epoch: 001 | loss: 0.69498 - acc: 0.4844 -- iter: 0736/1481
[A[ATraining Step: 24  | total loss: [1m[32m0.69403[0m[0m | time: 21.737s
[2K
| Adam | epoch: 001 | loss: 0.69403 - acc: 0.4976 -- iter: 0768/1481
[A[ATraining Step: 25  | total loss: [1m[32m0.69388[0m[0m | time: 22.617s
[2K
| Adam | epoch: 001 | loss: 0.69388 - acc: 0.4897 -- iter: 0800/1481
[A[ATraining Step: 26  | total loss: [1m[32m0.69372[0m[0m | time: 23.476s
[2K
| Adam | epoch: 001 | loss: 0.69372 - acc: 0.4842 -- iter: 0832/1481
[A[ATraining Step: 27  | total loss: [1m[32m0.69355[0m[0m | time: 24.426s
[2K
| Adam | epoch: 001 | loss: 0.69355 - acc: 0.4802 -- iter: 0864/1481
[A[ATraining Step: 28  | total loss: [1m[32m0.69341[0m[0m | time: 25.303s
[2K
| Adam | epoch: 001 | loss: 0.69341 - acc: 0.5008 -- iter: 0896/1481
[A[ATraining Step: 29  | total loss: [1m[32m0.69332[0m[0m | time: 26.303s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.5158 -- iter: 0928/1481
[A[ATraining Step: 30  | total loss: [1m[32m0.69319[0m[0m | time: 27.259s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5417 -- iter: 0960/1481
[A[ATraining Step: 31  | total loss: [1m[32m0.69309[0m[0m | time: 28.048s
[2K
| Adam | epoch: 001 | loss: 0.69309 - acc: 0.5320 -- iter: 0992/1481
[A[ATraining Step: 32  | total loss: [1m[32m0.69309[0m[0m | time: 28.857s
[2K
| Adam | epoch: 001 | loss: 0.69309 - acc: 0.5248 -- iter: 1024/1481
[A[ATraining Step: 33  | total loss: [1m[32m0.69316[0m[0m | time: 29.727s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5125 -- iter: 1056/1481
[A[ATraining Step: 34  | total loss: [1m[32m0.69299[0m[0m | time: 30.597s
[2K
| Adam | epoch: 001 | loss: 0.69299 - acc: 0.5433 -- iter: 1088/1481
[A[ATraining Step: 35  | total loss: [1m[32m0.69292[0m[0m | time: 31.462s
[2K
| Adam | epoch: 001 | loss: 0.69292 - acc: 0.5343 -- iter: 1120/1481
[A[ATraining Step: 36  | total loss: [1m[32m0.69279[0m[0m | time: 32.386s
[2K
| Adam | epoch: 001 | loss: 0.69279 - acc: 0.5336 -- iter: 1152/1481
[A[ATraining Step: 37  | total loss: [1m[32m0.69288[0m[0m | time: 33.303s
[2K
| Adam | epoch: 001 | loss: 0.69288 - acc: 0.5207 -- iter: 1184/1481
[A[ATraining Step: 38  | total loss: [1m[32m0.69300[0m[0m | time: 34.215s
[2K
| Adam | epoch: 001 | loss: 0.69300 - acc: 0.4922 -- iter: 1216/1481
[A[ATraining Step: 39  | total loss: [1m[32m0.69288[0m[0m | time: 35.040s
[2K
| Adam | epoch: 001 | loss: 0.69288 - acc: 0.5056 -- iter: 1248/1481
[A[ATraining Step: 40  | total loss: [1m[32m0.69279[0m[0m | time: 36.027s
[2K
| Adam | epoch: 001 | loss: 0.69279 - acc: 0.5456 -- iter: 1280/1481
[A[ATraining Step: 41  | total loss: [1m[32m0.69279[0m[0m | time: 36.969s
[2K
| Adam | epoch: 001 | loss: 0.69279 - acc: 0.5602 -- iter: 1312/1481
[A[ATraining Step: 42  | total loss: [1m[32m0.69248[0m[0m | time: 37.918s
[2K
| Adam | epoch: 001 | loss: 0.69248 - acc: 0.6000 -- iter: 1344/1481
[A[ATraining Step: 43  | total loss: [1m[32m0.69227[0m[0m | time: 38.858s
[2K
| Adam | epoch: 001 | loss: 0.69227 - acc: 0.6154 -- iter: 1376/1481
[A[ATraining Step: 44  | total loss: [1m[32m0.69189[0m[0m | time: 39.786s
[2K
| Adam | epoch: 001 | loss: 0.69189 - acc: 0.6279 -- iter: 1408/1481
[A[ATraining Step: 45  | total loss: [1m[32m0.69156[0m[0m | time: 40.738s
[2K
| Adam | epoch: 001 | loss: 0.69156 - acc: 0.6433 -- iter: 1440/1481
[A[ATraining Step: 46  | total loss: [1m[32m0.69150[0m[0m | time: 41.719s
[2K
| Adam | epoch: 001 | loss: 0.69150 - acc: 0.6299 -- iter: 1472/1481
[A[ATraining Step: 47  | total loss: [1m[32m0.69131[0m[0m | time: 44.338s
[2K
| Adam | epoch: 001 | loss: 0.69131 - acc: 0.6291 | val_loss: 0.68773 - val_acc: 0.6703 -- iter: 1481/1481
--
Training Step: 48  | total loss: [1m[32m0.69077[0m[0m | time: 0.360s
[2K
| Adam | epoch: 002 | loss: 0.69077 - acc: 0.5994 -- iter: 0032/1481
[A[ATraining Step: 49  | total loss: [1m[32m0.68956[0m[0m | time: 1.331s
[2K
| Adam | epoch: 002 | loss: 0.68956 - acc: 0.6276 -- iter: 0064/1481
[A[ATraining Step: 50  | total loss: [1m[32m0.68841[0m[0m | time: 2.201s
[2K
| Adam | epoch: 002 | loss: 0.68841 - acc: 0.6417 -- iter: 0096/1481
[A[ATraining Step: 51  | total loss: [1m[32m0.68787[0m[0m | time: 2.803s
[2K
| Adam | epoch: 002 | loss: 0.68787 - acc: 0.6630 -- iter: 0128/1481
[A[ATraining Step: 52  | total loss: [1m[32m0.68793[0m[0m | time: 3.414s
[2K
| Adam | epoch: 002 | loss: 0.68793 - acc: 0.6526 -- iter: 0160/1481
[A[ATraining Step: 53  | total loss: [1m[32m0.68607[0m[0m | time: 4.028s
[2K
| Adam | epoch: 002 | loss: 0.68607 - acc: 0.6624 -- iter: 0192/1481
[A[ATraining Step: 54  | total loss: [1m[32m0.68500[0m[0m | time: 4.630s
[2K
| Adam | epoch: 002 | loss: 0.68500 - acc: 0.6660 -- iter: 0224/1481
[A[ATraining Step: 55  | total loss: [1m[32m0.68144[0m[0m | time: 5.226s
[2K
| Adam | epoch: 002 | loss: 0.68144 - acc: 0.6691 -- iter: 0256/1481
[A[ATraining Step: 56  | total loss: [1m[32m0.68551[0m[0m | time: 5.817s
[2K
| Adam | epoch: 002 | loss: 0.68551 - acc: 0.6497 -- iter: 0288/1481
[A[ATraining Step: 57  | total loss: [1m[32m0.68316[0m[0m | time: 6.465s
[2K
| Adam | epoch: 002 | loss: 0.68316 - acc: 0.6506 -- iter: 0320/1481
[A[ATraining Step: 58  | total loss: [1m[32m0.68050[0m[0m | time: 7.083s
[2K
| Adam | epoch: 002 | loss: 0.68050 - acc: 0.6471 -- iter: 0352/1481
[A[ATraining Step: 59  | total loss: [1m[32m0.67428[0m[0m | time: 7.705s
[2K
| Adam | epoch: 002 | loss: 0.67428 - acc: 0.6567 -- iter: 0384/1481
[A[ATraining Step: 60  | total loss: [1m[32m0.67469[0m[0m | time: 8.311s
[2K
| Adam | epoch: 002 | loss: 0.67469 - acc: 0.6360 -- iter: 0416/1481
[A[ATraining Step: 61  | total loss: [1m[32m0.67116[0m[0m | time: 8.920s
[2K
| Adam | epoch: 002 | loss: 0.67116 - acc: 0.6305 -- iter: 0448/1481
[A[ATraining Step: 62  | total loss: [1m[32m0.67188[0m[0m | time: 9.531s
[2K
| Adam | epoch: 002 | loss: 0.67188 - acc: 0.6177 -- iter: 0480/1481
[A[ATraining Step: 63  | total loss: [1m[32m0.65932[0m[0m | time: 10.134s
[2K
| Adam | epoch: 002 | loss: 0.65932 - acc: 0.6424 -- iter: 0512/1481
[A[ATraining Step: 64  | total loss: [1m[32m0.65580[0m[0m | time: 10.757s
[2K
| Adam | epoch: 002 | loss: 0.65580 - acc: 0.6363 -- iter: 0544/1481
[A[ATraining Step: 65  | total loss: [1m[32m0.65939[0m[0m | time: 11.393s
[2K
| Adam | epoch: 002 | loss: 0.65939 - acc: 0.6272 -- iter: 0576/1481
[A[ATraining Step: 66  | total loss: [1m[32m0.65909[0m[0m | time: 12.012s
[2K
| Adam | epoch: 002 | loss: 0.65909 - acc: 0.6194 -- iter: 0608/1481
[A[ATraining Step: 67  | total loss: [1m[32m0.66697[0m[0m | time: 12.623s
[2K
| Adam | epoch: 002 | loss: 0.66697 - acc: 0.6013 -- iter: 0640/1481
[A[ATraining Step: 68  | total loss: [1m[32m0.66443[0m[0m | time: 13.270s
[2K
| Adam | epoch: 002 | loss: 0.66443 - acc: 0.6078 -- iter: 0672/1481
[A[ATraining Step: 69  | total loss: [1m[32m0.66183[0m[0m | time: 13.869s
[2K
| Adam | epoch: 002 | loss: 0.66183 - acc: 0.6171 -- iter: 0704/1481
[A[ATraining Step: 70  | total loss: [1m[32m0.65387[0m[0m | time: 14.488s
[2K
| Adam | epoch: 002 | loss: 0.65387 - acc: 0.6360 -- iter: 0736/1481
[A[ATraining Step: 71  | total loss: [1m[32m0.65189[0m[0m | time: 15.104s
[2K
| Adam | epoch: 002 | loss: 0.65189 - acc: 0.6384 -- iter: 0768/1481
[A[ATraining Step: 72  | total loss: [1m[32m0.64759[0m[0m | time: 15.727s
[2K
| Adam | epoch: 002 | loss: 0.64759 - acc: 0.6509 -- iter: 0800/1481
[A[ATraining Step: 73  | total loss: [1m[32m0.63729[0m[0m | time: 16.324s
[2K
| Adam | epoch: 002 | loss: 0.63729 - acc: 0.6584 -- iter: 0832/1481
[A[ATraining Step: 74  | total loss: [1m[32m0.64470[0m[0m | time: 16.931s
[2K
| Adam | epoch: 002 | loss: 0.64470 - acc: 0.6445 -- iter: 0864/1481
[A[ATraining Step: 75  | total loss: [1m[32m0.64887[0m[0m | time: 17.663s
[2K
| Adam | epoch: 002 | loss: 0.64887 - acc: 0.6322 -- iter: 0896/1481
[A[ATraining Step: 76  | total loss: [1m[32m0.64031[0m[0m | time: 18.268s
[2K
| Adam | epoch: 002 | loss: 0.64031 - acc: 0.6448 -- iter: 0928/1481
[A[ATraining Step: 77  | total loss: [1m[32m0.64112[0m[0m | time: 18.889s
[2K
| Adam | epoch: 002 | loss: 0.64112 - acc: 0.6427 -- iter: 0960/1481
[A[ATraining Step: 78  | total loss: [1m[32m0.63593[0m[0m | time: 19.486s
[2K
| Adam | epoch: 002 | loss: 0.63593 - acc: 0.6474 -- iter: 0992/1481
[A[ATraining Step: 79  | total loss: [1m[32m0.63302[0m[0m | time: 20.086s
[2K
| Adam | epoch: 002 | loss: 0.63302 - acc: 0.6516 -- iter: 1024/1481
[A[ATraining Step: 80  | total loss: [1m[32m0.62772[0m[0m | time: 20.681s
[2K
| Adam | epoch: 002 | loss: 0.62772 - acc: 0.6616 -- iter: 1056/1481
[A[ATraining Step: 81  | total loss: [1m[32m0.62675[0m[0m | time: 21.291s
[2K
| Adam | epoch: 002 | loss: 0.62675 - acc: 0.6611 -- iter: 1088/1481
[A[ATraining Step: 82  | total loss: [1m[32m0.62297[0m[0m | time: 21.917s
[2K
| Adam | epoch: 002 | loss: 0.62297 - acc: 0.6637 -- iter: 1120/1481
[A[ATraining Step: 83  | total loss: [1m[32m0.61252[0m[0m | time: 22.554s
[2K
| Adam | epoch: 002 | loss: 0.61252 - acc: 0.6724 -- iter: 1152/1481
[A[ATraining Step: 84  | total loss: [1m[32m0.60434[0m[0m | time: 23.487s
[2K
| Adam | epoch: 002 | loss: 0.60434 - acc: 0.6739 -- iter: 1184/1481
[A[ATraining Step: 85  | total loss: [1m[32m0.61383[0m[0m | time: 24.582s
[2K
| Adam | epoch: 002 | loss: 0.61383 - acc: 0.6784 -- iter: 1216/1481
[A[ATraining Step: 86  | total loss: [1m[32m0.60278[0m[0m | time: 25.527s
[2K
| Adam | epoch: 002 | loss: 0.60278 - acc: 0.6824 -- iter: 1248/1481
[A[ATraining Step: 87  | total loss: [1m[32m0.59982[0m[0m | time: 26.258s
[2K
| Adam | epoch: 002 | loss: 0.59982 - acc: 0.6860 -- iter: 1280/1481
[A[ATraining Step: 88  | total loss: [1m[32m0.59568[0m[0m | time: 27.097s
[2K
| Adam | epoch: 002 | loss: 0.59568 - acc: 0.6862 -- iter: 1312/1481
[A[ATraining Step: 89  | total loss: [1m[32m0.59234[0m[0m | time: 27.963s
[2K
| Adam | epoch: 002 | loss: 0.59234 - acc: 0.6957 -- iter: 1344/1481
[A[ATraining Step: 90  | total loss: [1m[32m0.59152[0m[0m | time: 28.820s
[2K
| Adam | epoch: 002 | loss: 0.59152 - acc: 0.6949 -- iter: 1376/1481
[A[ATraining Step: 91  | total loss: [1m[32m0.59852[0m[0m | time: 29.667s
[2K
| Adam | epoch: 002 | loss: 0.59852 - acc: 0.6910 -- iter: 1408/1481
[A[ATraining Step: 92  | total loss: [1m[32m0.59005[0m[0m | time: 30.692s
[2K
| Adam | epoch: 002 | loss: 0.59005 - acc: 0.7000 -- iter: 1440/1481
[A[ATraining Step: 93  | total loss: [1m[32m0.59066[0m[0m | time: 31.665s
[2K
| Adam | epoch: 002 | loss: 0.59066 - acc: 0.7050 -- iter: 1472/1481
[A[ATraining Step: 94  | total loss: [1m[32m0.58951[0m[0m | time: 34.583s
[2K
| Adam | epoch: 002 | loss: 0.58951 - acc: 0.7064 | val_loss: 0.54862 - val_acc: 0.7026 -- iter: 1481/1481
--
Training Step: 95  | total loss: [1m[32m0.57749[0m[0m | time: 0.285s
[2K
| Adam | epoch: 003 | loss: 0.57749 - acc: 0.7170 -- iter: 0032/1481
[A[ATraining Step: 96  | total loss: [1m[32m0.58985[0m[0m | time: 0.592s
[2K
| Adam | epoch: 003 | loss: 0.58985 - acc: 0.7120 -- iter: 0064/1481
[A[ATraining Step: 97  | total loss: [1m[32m0.60033[0m[0m | time: 1.447s
[2K
| Adam | epoch: 003 | loss: 0.60033 - acc: 0.7074 -- iter: 0096/1481
[A[ATraining Step: 98  | total loss: [1m[32m0.59978[0m[0m | time: 2.325s
[2K
| Adam | epoch: 003 | loss: 0.59978 - acc: 0.6992 -- iter: 0128/1481
[A[ATraining Step: 99  | total loss: [1m[32m0.59301[0m[0m | time: 3.309s
[2K
| Adam | epoch: 003 | loss: 0.59301 - acc: 0.7074 -- iter: 0160/1481
[A[ATraining Step: 100  | total loss: [1m[32m0.59965[0m[0m | time: 4.208s
[2K
| Adam | epoch: 003 | loss: 0.59965 - acc: 0.6992 -- iter: 0192/1481
[A[ATraining Step: 101  | total loss: [1m[32m0.59844[0m[0m | time: 5.095s
[2K
| Adam | epoch: 003 | loss: 0.59844 - acc: 0.6980 -- iter: 0224/1481
[A[ATraining Step: 102  | total loss: [1m[32m0.60578[0m[0m | time: 5.913s
[2K
| Adam | epoch: 003 | loss: 0.60578 - acc: 0.6844 -- iter: 0256/1481
[A[ATraining Step: 103  | total loss: [1m[32m0.59638[0m[0m | time: 6.910s
[2K
| Adam | epoch: 003 | loss: 0.59638 - acc: 0.6973 -- iter: 0288/1481
[A[ATraining Step: 104  | total loss: [1m[32m0.58451[0m[0m | time: 7.899s
[2K
| Adam | epoch: 003 | loss: 0.58451 - acc: 0.7057 -- iter: 0320/1481
[A[ATraining Step: 105  | total loss: [1m[32m0.58609[0m[0m | time: 8.850s
[2K
| Adam | epoch: 003 | loss: 0.58609 - acc: 0.7070 -- iter: 0352/1481
[A[ATraining Step: 106  | total loss: [1m[32m0.58053[0m[0m | time: 9.616s
[2K
| Adam | epoch: 003 | loss: 0.58053 - acc: 0.7113 -- iter: 0384/1481
[A[ATraining Step: 107  | total loss: [1m[32m0.58018[0m[0m | time: 10.502s
[2K
| Adam | epoch: 003 | loss: 0.58018 - acc: 0.7058 -- iter: 0416/1481
[A[ATraining Step: 108  | total loss: [1m[32m0.57010[0m[0m | time: 11.351s
[2K
| Adam | epoch: 003 | loss: 0.57010 - acc: 0.7133 -- iter: 0448/1481
[A[ATraining Step: 109  | total loss: [1m[32m0.58477[0m[0m | time: 12.189s
[2K
| Adam | epoch: 003 | loss: 0.58477 - acc: 0.6857 -- iter: 0480/1481
[A[ATraining Step: 110  | total loss: [1m[32m0.58818[0m[0m | time: 13.044s
[2K
| Adam | epoch: 003 | loss: 0.58818 - acc: 0.6797 -- iter: 0512/1481
[A[ATraining Step: 111  | total loss: [1m[32m0.58816[0m[0m | time: 13.934s
[2K
| Adam | epoch: 003 | loss: 0.58816 - acc: 0.6773 -- iter: 0544/1481
[A[ATraining Step: 112  | total loss: [1m[32m0.59290[0m[0m | time: 14.828s
[2K
| Adam | epoch: 003 | loss: 0.59290 - acc: 0.6721 -- iter: 0576/1481
[A[ATraining Step: 113  | total loss: [1m[32m0.58666[0m[0m | time: 15.724s
[2K
| Adam | epoch: 003 | loss: 0.58666 - acc: 0.6736 -- iter: 0608/1481
[A[ATraining Step: 114  | total loss: [1m[32m0.58140[0m[0m | time: 16.529s
[2K
| Adam | epoch: 003 | loss: 0.58140 - acc: 0.6844 -- iter: 0640/1481
[A[ATraining Step: 115  | total loss: [1m[32m0.57783[0m[0m | time: 17.629s
[2K
| Adam | epoch: 003 | loss: 0.57783 - acc: 0.6910 -- iter: 0672/1481
[A[ATraining Step: 116  | total loss: [1m[32m0.57923[0m[0m | time: 18.680s
[2K
| Adam | epoch: 003 | loss: 0.57923 - acc: 0.6937 -- iter: 0704/1481
[A[ATraining Step: 117  | total loss: [1m[32m0.57801[0m[0m | time: 19.504s
[2K
| Adam | epoch: 003 | loss: 0.57801 - acc: 0.6931 -- iter: 0736/1481
[A[ATraining Step: 118  | total loss: [1m[32m0.56711[0m[0m | time: 20.371s
[2K
| Adam | epoch: 003 | loss: 0.56711 - acc: 0.7082 -- iter: 0768/1481
[A[ATraining Step: 119  | total loss: [1m[32m0.56545[0m[0m | time: 21.254s
[2K
| Adam | epoch: 003 | loss: 0.56545 - acc: 0.7092 -- iter: 0800/1481
[A[ATraining Step: 120  | total loss: [1m[32m0.56090[0m[0m | time: 22.103s
[2K
| Adam | epoch: 003 | loss: 0.56090 - acc: 0.7071 -- iter: 0832/1481
[A[ATraining Step: 121  | total loss: [1m[32m0.55160[0m[0m | time: 22.995s
[2K
| Adam | epoch: 003 | loss: 0.55160 - acc: 0.7114 -- iter: 0864/1481
[A[ATraining Step: 122  | total loss: [1m[32m0.55401[0m[0m | time: 23.907s
[2K
| Adam | epoch: 003 | loss: 0.55401 - acc: 0.7027 -- iter: 0896/1481
[A[ATraining Step: 123  | total loss: [1m[32m0.55159[0m[0m | time: 24.845s
[2K
| Adam | epoch: 003 | loss: 0.55159 - acc: 0.7043 -- iter: 0928/1481
[A[ATraining Step: 124  | total loss: [1m[32m0.54581[0m[0m | time: 25.828s
[2K
| Adam | epoch: 003 | loss: 0.54581 - acc: 0.7089 -- iter: 0960/1481
[A[ATraining Step: 125  | total loss: [1m[32m0.54328[0m[0m | time: 26.713s
[2K
| Adam | epoch: 003 | loss: 0.54328 - acc: 0.7130 -- iter: 0992/1481
[A[ATraining Step: 126  | total loss: [1m[32m0.55283[0m[0m | time: 27.665s
[2K
| Adam | epoch: 003 | loss: 0.55283 - acc: 0.7011 -- iter: 1024/1481
[A[ATraining Step: 127  | total loss: [1m[32m0.55194[0m[0m | time: 28.689s
[2K
| Adam | epoch: 003 | loss: 0.55194 - acc: 0.7091 -- iter: 1056/1481
[A[ATraining Step: 128  | total loss: [1m[32m0.54492[0m[0m | time: 29.530s
[2K
| Adam | epoch: 003 | loss: 0.54492 - acc: 0.7132 -- iter: 1088/1481
[A[ATraining Step: 129  | total loss: [1m[32m0.55224[0m[0m | time: 30.303s
[2K
| Adam | epoch: 003 | loss: 0.55224 - acc: 0.7106 -- iter: 1120/1481
[A[ATraining Step: 130  | total loss: [1m[32m0.55237[0m[0m | time: 31.143s
[2K
| Adam | epoch: 003 | loss: 0.55237 - acc: 0.7083 -- iter: 1152/1481
[A[ATraining Step: 131  | total loss: [1m[32m0.54951[0m[0m | time: 32.072s
[2K
| Adam | epoch: 003 | loss: 0.54951 - acc: 0.7156 -- iter: 1184/1481
[A[ATraining Step: 132  | total loss: [1m[32m0.54512[0m[0m | time: 32.912s
[2K
| Adam | epoch: 003 | loss: 0.54512 - acc: 0.7159 -- iter: 1216/1481
[A[ATraining Step: 133  | total loss: [1m[32m0.53575[0m[0m | time: 33.828s
[2K
| Adam | epoch: 003 | loss: 0.53575 - acc: 0.7224 -- iter: 1248/1481
[A[ATraining Step: 134  | total loss: [1m[32m0.54325[0m[0m | time: 34.713s
[2K
| Adam | epoch: 003 | loss: 0.54325 - acc: 0.7096 -- iter: 1280/1481
[A[ATraining Step: 135  | total loss: [1m[32m0.53504[0m[0m | time: 35.636s
[2K
| Adam | epoch: 003 | loss: 0.53504 - acc: 0.7136 -- iter: 1312/1481
[A[ATraining Step: 136  | total loss: [1m[32m0.53673[0m[0m | time: 36.479s
[2K
| Adam | epoch: 003 | loss: 0.53673 - acc: 0.7235 -- iter: 1344/1481
[A[ATraining Step: 137  | total loss: [1m[32m0.53745[0m[0m | time: 37.398s
[2K
| Adam | epoch: 003 | loss: 0.53745 - acc: 0.7230 -- iter: 1376/1481
[A[ATraining Step: 138  | total loss: [1m[32m0.52726[0m[0m | time: 38.363s
[2K
| Adam | epoch: 003 | loss: 0.52726 - acc: 0.7289 -- iter: 1408/1481
[A[ATraining Step: 139  | total loss: [1m[32m0.53183[0m[0m | time: 39.383s
[2K
| Adam | epoch: 003 | loss: 0.53183 - acc: 0.7278 -- iter: 1440/1481
[A[ATraining Step: 140  | total loss: [1m[32m0.52130[0m[0m | time: 40.125s
[2K
| Adam | epoch: 003 | loss: 0.52130 - acc: 0.7363 -- iter: 1472/1481
[A[ATraining Step: 141  | total loss: [1m[32m0.52634[0m[0m | time: 42.886s
[2K
| Adam | epoch: 003 | loss: 0.52634 - acc: 0.7408 | val_loss: 0.49514 - val_acc: 0.7478 -- iter: 1481/1481
--
Training Step: 142  | total loss: [1m[32m0.52541[0m[0m | time: 0.918s
[2K
| Adam | epoch: 004 | loss: 0.52541 - acc: 0.7386 -- iter: 0032/1481
[A[ATraining Step: 143  | total loss: [1m[32m0.53144[0m[0m | time: 1.190s
[2K
| Adam | epoch: 004 | loss: 0.53144 - acc: 0.7304 -- iter: 0064/1481
[A[ATraining Step: 144  | total loss: [1m[32m0.50989[0m[0m | time: 1.450s
[2K
| Adam | epoch: 004 | loss: 0.50989 - acc: 0.7462 -- iter: 0096/1481
[A[ATraining Step: 145  | total loss: [1m[32m0.49042[0m[0m | time: 2.467s
[2K
| Adam | epoch: 004 | loss: 0.49042 - acc: 0.7605 -- iter: 0128/1481
[A[ATraining Step: 146  | total loss: [1m[32m0.49559[0m[0m | time: 3.522s
[2K
| Adam | epoch: 004 | loss: 0.49559 - acc: 0.7594 -- iter: 0160/1481
[A[ATraining Step: 147  | total loss: [1m[32m0.50616[0m[0m | time: 4.371s
[2K
| Adam | epoch: 004 | loss: 0.50616 - acc: 0.7522 -- iter: 0192/1481
[A[ATraining Step: 148  | total loss: [1m[32m0.51078[0m[0m | time: 5.161s
[2K
| Adam | epoch: 004 | loss: 0.51078 - acc: 0.7489 -- iter: 0224/1481
[A[ATraining Step: 149  | total loss: [1m[32m0.50339[0m[0m | time: 5.996s
[2K
| Adam | epoch: 004 | loss: 0.50339 - acc: 0.7553 -- iter: 0256/1481
[A[ATraining Step: 150  | total loss: [1m[32m0.51051[0m[0m | time: 6.858s
[2K
| Adam | epoch: 004 | loss: 0.51051 - acc: 0.7454 -- iter: 0288/1481
[A[ATraining Step: 151  | total loss: [1m[32m0.49905[0m[0m | time: 7.710s
[2K
| Adam | epoch: 004 | loss: 0.49905 - acc: 0.7583 -- iter: 0320/1481
[A[ATraining Step: 152  | total loss: [1m[32m0.49732[0m[0m | time: 8.556s
[2K
| Adam | epoch: 004 | loss: 0.49732 - acc: 0.7575 -- iter: 0352/1481
[A[ATraining Step: 153  | total loss: [1m[32m0.50594[0m[0m | time: 9.410s
[2K
| Adam | epoch: 004 | loss: 0.50594 - acc: 0.7474 -- iter: 0384/1481
[A[ATraining Step: 154  | total loss: [1m[32m0.48621[0m[0m | time: 10.289s
[2K
| Adam | epoch: 004 | loss: 0.48621 - acc: 0.7601 -- iter: 0416/1481
[A[ATraining Step: 155  | total loss: [1m[32m0.49426[0m[0m | time: 11.205s
[2K
| Adam | epoch: 004 | loss: 0.49426 - acc: 0.7466 -- iter: 0448/1481
[A[ATraining Step: 156  | total loss: [1m[32m0.50427[0m[0m | time: 12.075s
[2K
| Adam | epoch: 004 | loss: 0.50427 - acc: 0.7407 -- iter: 0480/1481
[A[ATraining Step: 157  | total loss: [1m[32m0.48688[0m[0m | time: 13.119s
[2K
| Adam | epoch: 004 | loss: 0.48688 - acc: 0.7510 -- iter: 0512/1481
[A[ATraining Step: 158  | total loss: [1m[32m0.49229[0m[0m | time: 14.200s
[2K
| Adam | epoch: 004 | loss: 0.49229 - acc: 0.7447 -- iter: 0544/1481
[A[ATraining Step: 159  | total loss: [1m[32m0.48511[0m[0m | time: 14.971s
[2K
| Adam | epoch: 004 | loss: 0.48511 - acc: 0.7514 -- iter: 0576/1481
[A[ATraining Step: 160  | total loss: [1m[32m0.49249[0m[0m | time: 15.824s
[2K
| Adam | epoch: 004 | loss: 0.49249 - acc: 0.7482 -- iter: 0608/1481
[A[ATraining Step: 161  | total loss: [1m[32m0.48362[0m[0m | time: 16.706s
[2K
| Adam | epoch: 004 | loss: 0.48362 - acc: 0.7609 -- iter: 0640/1481
[A[ATraining Step: 162  | total loss: [1m[32m0.48449[0m[0m | time: 17.560s
[2K
| Adam | epoch: 004 | loss: 0.48449 - acc: 0.7598 -- iter: 0672/1481
[A[ATraining Step: 163  | total loss: [1m[32m0.48392[0m[0m | time: 18.415s
[2K
| Adam | epoch: 004 | loss: 0.48392 - acc: 0.7619 -- iter: 0704/1481
[A[ATraining Step: 164  | total loss: [1m[32m0.48584[0m[0m | time: 19.285s
[2K
| Adam | epoch: 004 | loss: 0.48584 - acc: 0.7639 -- iter: 0736/1481
[A[ATraining Step: 165  | total loss: [1m[32m0.48424[0m[0m | time: 20.160s
[2K
| Adam | epoch: 004 | loss: 0.48424 - acc: 0.7687 -- iter: 0768/1481
[A[ATraining Step: 166  | total loss: [1m[32m0.47945[0m[0m | time: 21.111s
[2K
| Adam | epoch: 004 | loss: 0.47945 - acc: 0.7731 -- iter: 0800/1481
[A[ATraining Step: 167  | total loss: [1m[32m0.47539[0m[0m | time: 21.956s
[2K
| Adam | epoch: 004 | loss: 0.47539 - acc: 0.7739 -- iter: 0832/1481
[A[ATraining Step: 168  | total loss: [1m[32m0.47809[0m[0m | time: 22.961s
[2K
| Adam | epoch: 004 | loss: 0.47809 - acc: 0.7715 -- iter: 0864/1481
[A[ATraining Step: 169  | total loss: [1m[32m0.47230[0m[0m | time: 24.019s
[2K
| Adam | epoch: 004 | loss: 0.47230 - acc: 0.7725 -- iter: 0896/1481
[A[ATraining Step: 170  | total loss: [1m[32m0.48624[0m[0m | time: 24.885s
[2K
| Adam | epoch: 004 | loss: 0.48624 - acc: 0.7577 -- iter: 0928/1481
[A[ATraining Step: 171  | total loss: [1m[32m0.48650[0m[0m | time: 25.670s
[2K
| Adam | epoch: 004 | loss: 0.48650 - acc: 0.7570 -- iter: 0960/1481
[A[ATraining Step: 172  | total loss: [1m[32m0.47980[0m[0m | time: 26.506s
[2K
| Adam | epoch: 004 | loss: 0.47980 - acc: 0.7625 -- iter: 0992/1481
[A[ATraining Step: 173  | total loss: [1m[32m0.47678[0m[0m | time: 27.342s
[2K
| Adam | epoch: 004 | loss: 0.47678 - acc: 0.7613 -- iter: 1024/1481
[A[ATraining Step: 174  | total loss: [1m[32m0.48262[0m[0m | time: 28.185s
[2K
| Adam | epoch: 004 | loss: 0.48262 - acc: 0.7508 -- iter: 1056/1481
[A[ATraining Step: 175  | total loss: [1m[32m0.46818[0m[0m | time: 29.027s
[2K
| Adam | epoch: 004 | loss: 0.46818 - acc: 0.7632 -- iter: 1088/1481
[A[ATraining Step: 176  | total loss: [1m[32m0.46498[0m[0m | time: 29.925s
[2K
| Adam | epoch: 004 | loss: 0.46498 - acc: 0.7681 -- iter: 1120/1481
[A[ATraining Step: 177  | total loss: [1m[32m0.46676[0m[0m | time: 30.855s
[2K
| Adam | epoch: 004 | loss: 0.46676 - acc: 0.7694 -- iter: 1152/1481
[A[ATraining Step: 178  | total loss: [1m[32m0.46439[0m[0m | time: 31.725s
[2K
| Adam | epoch: 004 | loss: 0.46439 - acc: 0.7706 -- iter: 1184/1481
[A[ATraining Step: 179  | total loss: [1m[32m0.46278[0m[0m | time: 32.548s
[2K
| Adam | epoch: 004 | loss: 0.46278 - acc: 0.7748 -- iter: 1216/1481
[A[ATraining Step: 180  | total loss: [1m[32m0.47468[0m[0m | time: 33.579s
[2K
| Adam | epoch: 004 | loss: 0.47468 - acc: 0.7661 -- iter: 1248/1481
[A[ATraining Step: 181  | total loss: [1m[32m0.46442[0m[0m | time: 34.547s
[2K
| Adam | epoch: 004 | loss: 0.46442 - acc: 0.7738 -- iter: 1280/1481
[A[ATraining Step: 182  | total loss: [1m[32m0.45290[0m[0m | time: 35.363s
[2K
| Adam | epoch: 004 | loss: 0.45290 - acc: 0.7840 -- iter: 1312/1481
[A[ATraining Step: 183  | total loss: [1m[32m0.45727[0m[0m | time: 36.145s
[2K
| Adam | epoch: 004 | loss: 0.45727 - acc: 0.7774 -- iter: 1344/1481
[A[ATraining Step: 184  | total loss: [1m[32m0.45075[0m[0m | time: 36.983s
[2K
| Adam | epoch: 004 | loss: 0.45075 - acc: 0.7872 -- iter: 1376/1481
[A[ATraining Step: 185  | total loss: [1m[32m0.46133[0m[0m | time: 37.823s
[2K
| Adam | epoch: 004 | loss: 0.46133 - acc: 0.7866 -- iter: 1408/1481
[A[ATraining Step: 186  | total loss: [1m[32m0.46710[0m[0m | time: 38.690s
[2K
| Adam | epoch: 004 | loss: 0.46710 - acc: 0.7861 -- iter: 1440/1481
[A[ATraining Step: 187  | total loss: [1m[32m0.46235[0m[0m | time: 39.552s
[2K
| Adam | epoch: 004 | loss: 0.46235 - acc: 0.7793 -- iter: 1472/1481
[A[ATraining Step: 188  | total loss: [1m[32m0.46872[0m[0m | time: 42.678s
[2K
| Adam | epoch: 004 | loss: 0.46872 - acc: 0.7701 | val_loss: 0.43365 - val_acc: 0.7802 -- iter: 1481/1481
--
Training Step: 189  | total loss: [1m[32m0.45863[0m[0m | time: 0.798s
[2K
| Adam | epoch: 005 | loss: 0.45863 - acc: 0.7775 -- iter: 0032/1481
[A[ATraining Step: 190  | total loss: [1m[32m0.47126[0m[0m | time: 1.617s
[2K
| Adam | epoch: 005 | loss: 0.47126 - acc: 0.7654 -- iter: 0064/1481
[A[ATraining Step: 191  | total loss: [1m[32m0.48301[0m[0m | time: 1.918s
[2K
| Adam | epoch: 005 | loss: 0.48301 - acc: 0.7513 -- iter: 0096/1481
[A[ATraining Step: 192  | total loss: [1m[32m0.47159[0m[0m | time: 2.203s
[2K
| Adam | epoch: 005 | loss: 0.47159 - acc: 0.7651 -- iter: 0128/1481
[A[ATraining Step: 193  | total loss: [1m[32m0.46077[0m[0m | time: 3.078s
[2K
| Adam | epoch: 005 | loss: 0.46077 - acc: 0.7775 -- iter: 0160/1481
[A[ATraining Step: 194  | total loss: [1m[32m0.46199[0m[0m | time: 3.953s
[2K
| Adam | epoch: 005 | loss: 0.46199 - acc: 0.7747 -- iter: 0192/1481
[A[ATraining Step: 195  | total loss: [1m[32m0.46057[0m[0m | time: 4.862s
[2K
| Adam | epoch: 005 | loss: 0.46057 - acc: 0.7723 -- iter: 0224/1481
[A[ATraining Step: 196  | total loss: [1m[32m0.45734[0m[0m | time: 5.749s
[2K
| Adam | epoch: 005 | loss: 0.45734 - acc: 0.7732 -- iter: 0256/1481
[A[ATraining Step: 197  | total loss: [1m[32m0.44297[0m[0m | time: 6.640s
[2K
| Adam | epoch: 005 | loss: 0.44297 - acc: 0.7865 -- iter: 0288/1481
[A[ATraining Step: 198  | total loss: [1m[32m0.44023[0m[0m | time: 7.498s
[2K
| Adam | epoch: 005 | loss: 0.44023 - acc: 0.7859 -- iter: 0320/1481
[A[ATraining Step: 199  | total loss: [1m[32m0.44163[0m[0m | time: 8.425s
[2K
| Adam | epoch: 005 | loss: 0.44163 - acc: 0.7824 -- iter: 0352/1481
[A[ATraining Step: 200  | total loss: [1m[32m0.44836[0m[0m | time: 11.356s
[2K
| Adam | epoch: 005 | loss: 0.44836 - acc: 0.7822 | val_loss: 0.40518 - val_acc: 0.7953 -- iter: 0384/1481
--
Training Step: 201  | total loss: [1m[32m0.43762[0m[0m | time: 12.210s
[2K
| Adam | epoch: 005 | loss: 0.43762 - acc: 0.7915 -- iter: 0416/1481
[A[ATraining Step: 202  | total loss: [1m[32m0.42505[0m[0m | time: 13.062s
[2K
| Adam | epoch: 005 | loss: 0.42505 - acc: 0.7999 -- iter: 0448/1481
[A[ATraining Step: 203  | total loss: [1m[32m0.43132[0m[0m | time: 14.037s
[2K
| Adam | epoch: 005 | loss: 0.43132 - acc: 0.7949 -- iter: 0480/1481
[A[ATraining Step: 204  | total loss: [1m[32m0.43573[0m[0m | time: 15.012s
[2K
| Adam | epoch: 005 | loss: 0.43573 - acc: 0.7935 -- iter: 0512/1481
[A[ATraining Step: 205  | total loss: [1m[32m0.45847[0m[0m | time: 15.885s
[2K
| Adam | epoch: 005 | loss: 0.45847 - acc: 0.7829 -- iter: 0544/1481
[A[ATraining Step: 206  | total loss: [1m[32m0.45267[0m[0m | time: 16.744s
[2K
| Adam | epoch: 005 | loss: 0.45267 - acc: 0.7859 -- iter: 0576/1481
[A[ATraining Step: 207  | total loss: [1m[32m0.44109[0m[0m | time: 17.763s
[2K
| Adam | epoch: 005 | loss: 0.44109 - acc: 0.7948 -- iter: 0608/1481
[A[ATraining Step: 208  | total loss: [1m[32m0.43320[0m[0m | time: 18.823s
[2K
| Adam | epoch: 005 | loss: 0.43320 - acc: 0.8028 -- iter: 0640/1481
[A[ATraining Step: 209  | total loss: [1m[32m0.43106[0m[0m | time: 19.620s
[2K
| Adam | epoch: 005 | loss: 0.43106 - acc: 0.8007 -- iter: 0672/1481
[A[ATraining Step: 210  | total loss: [1m[32m0.43333[0m[0m | time: 20.441s
[2K
| Adam | epoch: 005 | loss: 0.43333 - acc: 0.8018 -- iter: 0704/1481
[A[ATraining Step: 211  | total loss: [1m[32m0.42092[0m[0m | time: 21.292s
[2K
| Adam | epoch: 005 | loss: 0.42092 - acc: 0.8092 -- iter: 0736/1481
[A[ATraining Step: 212  | total loss: [1m[32m0.42011[0m[0m | time: 22.147s
[2K
| Adam | epoch: 005 | loss: 0.42011 - acc: 0.8064 -- iter: 0768/1481
[A[ATraining Step: 213  | total loss: [1m[32m0.40915[0m[0m | time: 23.026s
[2K
| Adam | epoch: 005 | loss: 0.40915 - acc: 0.8132 -- iter: 0800/1481
[A[ATraining Step: 214  | total loss: [1m[32m0.39865[0m[0m | time: 23.949s
[2K
| Adam | epoch: 005 | loss: 0.39865 - acc: 0.8225 -- iter: 0832/1481
[A[ATraining Step: 215  | total loss: [1m[32m0.38446[0m[0m | time: 24.892s
[2K
| Adam | epoch: 005 | loss: 0.38446 - acc: 0.8340 -- iter: 0864/1481
[A[ATraining Step: 216  | total loss: [1m[32m0.37401[0m[0m | time: 25.848s
[2K
| Adam | epoch: 005 | loss: 0.37401 - acc: 0.8381 -- iter: 0896/1481
[A[ATraining Step: 217  | total loss: [1m[32m0.36433[0m[0m | time: 26.624s
[2K
| Adam | epoch: 005 | loss: 0.36433 - acc: 0.8387 -- iter: 0928/1481
[A[ATraining Step: 218  | total loss: [1m[32m0.35929[0m[0m | time: 27.638s
[2K
| Adam | epoch: 005 | loss: 0.35929 - acc: 0.8361 -- iter: 0960/1481
[A[ATraining Step: 219  | total loss: [1m[32m0.35500[0m[0m | time: 28.635s
[2K
| Adam | epoch: 005 | loss: 0.35500 - acc: 0.8368 -- iter: 0992/1481
[A[ATraining Step: 220  | total loss: [1m[32m0.34458[0m[0m | time: 29.544s
[2K
| Adam | epoch: 005 | loss: 0.34458 - acc: 0.8438 -- iter: 1024/1481
[A[ATraining Step: 221  | total loss: [1m[32m0.35285[0m[0m | time: 30.305s
[2K
| Adam | epoch: 005 | loss: 0.35285 - acc: 0.8375 -- iter: 1056/1481
[A[ATraining Step: 222  | total loss: [1m[32m0.35061[0m[0m | time: 31.173s
[2K
| Adam | epoch: 005 | loss: 0.35061 - acc: 0.8413 -- iter: 1088/1481
[A[ATraining Step: 223  | total loss: [1m[32m0.36701[0m[0m | time: 32.033s
[2K
| Adam | epoch: 005 | loss: 0.36701 - acc: 0.8290 -- iter: 1120/1481
[A[ATraining Step: 224  | total loss: [1m[32m0.39342[0m[0m | time: 32.876s
[2K
| Adam | epoch: 005 | loss: 0.39342 - acc: 0.8211 -- iter: 1152/1481
[A[ATraining Step: 225  | total loss: [1m[32m0.38672[0m[0m | time: 33.718s
[2K
| Adam | epoch: 005 | loss: 0.38672 - acc: 0.8234 -- iter: 1184/1481
[A[ATraining Step: 226  | total loss: [1m[32m0.38486[0m[0m | time: 34.661s
[2K
| Adam | epoch: 005 | loss: 0.38486 - acc: 0.8223 -- iter: 1216/1481
[A[ATraining Step: 227  | total loss: [1m[32m0.36945[0m[0m | time: 35.557s
[2K
| Adam | epoch: 005 | loss: 0.36945 - acc: 0.8276 -- iter: 1248/1481
[A[ATraining Step: 228  | total loss: [1m[32m0.37383[0m[0m | time: 36.428s
[2K
| Adam | epoch: 005 | loss: 0.37383 - acc: 0.8261 -- iter: 1280/1481
[A[ATraining Step: 229  | total loss: [1m[32m0.38554[0m[0m | time: 37.298s
[2K
| Adam | epoch: 005 | loss: 0.38554 - acc: 0.8185 -- iter: 1312/1481
[A[ATraining Step: 230  | total loss: [1m[32m0.36789[0m[0m | time: 38.304s
[2K
| Adam | epoch: 005 | loss: 0.36789 - acc: 0.8272 -- iter: 1344/1481
[A[ATraining Step: 231  | total loss: [1m[32m0.36704[0m[0m | time: 39.232s
[2K
| Adam | epoch: 005 | loss: 0.36704 - acc: 0.8258 -- iter: 1376/1481
[A[ATraining Step: 232  | total loss: [1m[32m0.36799[0m[0m | time: 39.961s
[2K
| Adam | epoch: 005 | loss: 0.36799 - acc: 0.8276 -- iter: 1408/1481
[A[ATraining Step: 233  | total loss: [1m[32m0.36697[0m[0m | time: 40.806s
[2K
| Adam | epoch: 005 | loss: 0.36697 - acc: 0.8292 -- iter: 1440/1481
[A[ATraining Step: 234  | total loss: [1m[32m0.36131[0m[0m | time: 41.673s
[2K
| Adam | epoch: 005 | loss: 0.36131 - acc: 0.8338 -- iter: 1472/1481
[A[ATraining Step: 235  | total loss: [1m[32m0.34494[0m[0m | time: 44.570s
[2K
| Adam | epoch: 005 | loss: 0.34494 - acc: 0.8473 | val_loss: 0.42226 - val_acc: 0.8060 -- iter: 1481/1481
--
Training Step: 236  | total loss: [1m[32m0.34201[0m[0m | time: 0.883s
[2K
| Adam | epoch: 006 | loss: 0.34201 - acc: 0.8500 -- iter: 0032/1481
[A[ATraining Step: 237  | total loss: [1m[32m0.34853[0m[0m | time: 1.758s
[2K
| Adam | epoch: 006 | loss: 0.34853 - acc: 0.8432 -- iter: 0064/1481
[A[ATraining Step: 238  | total loss: [1m[32m0.36561[0m[0m | time: 2.658s
[2K
| Adam | epoch: 006 | loss: 0.36561 - acc: 0.8370 -- iter: 0096/1481
[A[ATraining Step: 239  | total loss: [1m[32m0.37577[0m[0m | time: 2.940s
[2K
| Adam | epoch: 006 | loss: 0.37577 - acc: 0.8314 -- iter: 0128/1481
[A[ATraining Step: 240  | total loss: [1m[32m0.37514[0m[0m | time: 3.255s
[2K
| Adam | epoch: 006 | loss: 0.37514 - acc: 0.8371 -- iter: 0160/1481
[A[ATraining Step: 241  | total loss: [1m[32m0.36616[0m[0m | time: 4.105s
[2K
| Adam | epoch: 006 | loss: 0.36616 - acc: 0.8423 -- iter: 0192/1481
[A[ATraining Step: 242  | total loss: [1m[32m0.39020[0m[0m | time: 4.987s
[2K
| Adam | epoch: 006 | loss: 0.39020 - acc: 0.8206 -- iter: 0224/1481
[A[ATraining Step: 243  | total loss: [1m[32m0.39803[0m[0m | time: 6.033s
[2K
| Adam | epoch: 006 | loss: 0.39803 - acc: 0.8167 -- iter: 0256/1481
[A[ATraining Step: 244  | total loss: [1m[32m0.39690[0m[0m | time: 7.065s
[2K
| Adam | epoch: 006 | loss: 0.39690 - acc: 0.8131 -- iter: 0288/1481
[A[ATraining Step: 245  | total loss: [1m[32m0.39989[0m[0m | time: 7.815s
[2K
| Adam | epoch: 006 | loss: 0.39989 - acc: 0.8131 -- iter: 0320/1481
[A[ATraining Step: 246  | total loss: [1m[32m0.38527[0m[0m | time: 8.641s
[2K
| Adam | epoch: 006 | loss: 0.38527 - acc: 0.8224 -- iter: 0352/1481
[A[ATraining Step: 247  | total loss: [1m[32m0.37700[0m[0m | time: 9.534s
[2K
| Adam | epoch: 006 | loss: 0.37700 - acc: 0.8276 -- iter: 0384/1481
[A[ATraining Step: 248  | total loss: [1m[32m0.36631[0m[0m | time: 10.392s
[2K
| Adam | epoch: 006 | loss: 0.36631 - acc: 0.8355 -- iter: 0416/1481
[A[ATraining Step: 249  | total loss: [1m[32m0.38841[0m[0m | time: 11.229s
[2K
| Adam | epoch: 006 | loss: 0.38841 - acc: 0.8176 -- iter: 0448/1481
[A[ATraining Step: 250  | total loss: [1m[32m0.38676[0m[0m | time: 12.144s
[2K
| Adam | epoch: 006 | loss: 0.38676 - acc: 0.8202 -- iter: 0480/1481
[A[ATraining Step: 251  | total loss: [1m[32m0.38638[0m[0m | time: 13.062s
[2K
| Adam | epoch: 006 | loss: 0.38638 - acc: 0.8194 -- iter: 0512/1481
[A[ATraining Step: 252  | total loss: [1m[32m0.37497[0m[0m | time: 14.105s
[2K
| Adam | epoch: 006 | loss: 0.37497 - acc: 0.8250 -- iter: 0544/1481
[A[ATraining Step: 253  | total loss: [1m[32m0.36147[0m[0m | time: 14.980s
[2K
| Adam | epoch: 006 | loss: 0.36147 - acc: 0.8269 -- iter: 0576/1481
[A[ATraining Step: 254  | total loss: [1m[32m0.37133[0m[0m | time: 16.007s
[2K
| Adam | epoch: 006 | loss: 0.37133 - acc: 0.8098 -- iter: 0608/1481
[A[ATraining Step: 255  | total loss: [1m[32m0.38621[0m[0m | time: 17.032s
[2K
| Adam | epoch: 006 | loss: 0.38621 - acc: 0.8038 -- iter: 0640/1481
[A[ATraining Step: 256  | total loss: [1m[32m0.37232[0m[0m | time: 17.846s
[2K
| Adam | epoch: 006 | loss: 0.37232 - acc: 0.8172 -- iter: 0672/1481
[A[ATraining Step: 257  | total loss: [1m[32m0.37181[0m[0m | time: 18.692s
[2K
| Adam | epoch: 006 | loss: 0.37181 - acc: 0.8198 -- iter: 0704/1481
[A[ATraining Step: 258  | total loss: [1m[32m0.36659[0m[0m | time: 19.548s
[2K
| Adam | epoch: 006 | loss: 0.36659 - acc: 0.8254 -- iter: 0736/1481
[A[ATraining Step: 259  | total loss: [1m[32m0.37317[0m[0m | time: 20.476s
[2K
| Adam | epoch: 006 | loss: 0.37317 - acc: 0.8209 -- iter: 0768/1481
[A[ATraining Step: 260  | total loss: [1m[32m0.37199[0m[0m | time: 21.363s
[2K
| Adam | epoch: 006 | loss: 0.37199 - acc: 0.8170 -- iter: 0800/1481
[A[ATraining Step: 261  | total loss: [1m[32m0.37622[0m[0m | time: 22.276s
[2K
| Adam | epoch: 006 | loss: 0.37622 - acc: 0.8103 -- iter: 0832/1481
[A[ATraining Step: 262  | total loss: [1m[32m0.36707[0m[0m | time: 23.201s
[2K
| Adam | epoch: 006 | loss: 0.36707 - acc: 0.8199 -- iter: 0864/1481
[A[ATraining Step: 263  | total loss: [1m[32m0.35716[0m[0m | time: 24.121s
[2K
| Adam | epoch: 006 | loss: 0.35716 - acc: 0.8254 -- iter: 0896/1481
[A[ATraining Step: 264  | total loss: [1m[32m0.35978[0m[0m | time: 24.989s
[2K
| Adam | epoch: 006 | loss: 0.35978 - acc: 0.8272 -- iter: 0928/1481
[A[ATraining Step: 265  | total loss: [1m[32m0.35142[0m[0m | time: 26.009s
[2K
| Adam | epoch: 006 | loss: 0.35142 - acc: 0.8320 -- iter: 0960/1481
[A[ATraining Step: 266  | total loss: [1m[32m0.33867[0m[0m | time: 27.082s
[2K
| Adam | epoch: 006 | loss: 0.33867 - acc: 0.8426 -- iter: 0992/1481
[A[ATraining Step: 267  | total loss: [1m[32m0.32051[0m[0m | time: 27.868s
[2K
| Adam | epoch: 006 | loss: 0.32051 - acc: 0.8552 -- iter: 1024/1481
[A[ATraining Step: 268  | total loss: [1m[32m0.31654[0m[0m | time: 28.686s
[2K
| Adam | epoch: 006 | loss: 0.31654 - acc: 0.8572 -- iter: 1056/1481
[A[ATraining Step: 269  | total loss: [1m[32m0.31357[0m[0m | time: 29.577s
[2K
| Adam | epoch: 006 | loss: 0.31357 - acc: 0.8589 -- iter: 1088/1481
[A[ATraining Step: 270  | total loss: [1m[32m0.30625[0m[0m | time: 30.513s
[2K
| Adam | epoch: 006 | loss: 0.30625 - acc: 0.8668 -- iter: 1120/1481
[A[ATraining Step: 271  | total loss: [1m[32m0.30200[0m[0m | time: 31.442s
[2K
| Adam | epoch: 006 | loss: 0.30200 - acc: 0.8707 -- iter: 1152/1481
[A[ATraining Step: 272  | total loss: [1m[32m0.28471[0m[0m | time: 32.350s
[2K
| Adam | epoch: 006 | loss: 0.28471 - acc: 0.8805 -- iter: 1184/1481
[A[ATraining Step: 273  | total loss: [1m[32m0.28705[0m[0m | time: 33.261s
[2K
| Adam | epoch: 006 | loss: 0.28705 - acc: 0.8800 -- iter: 1216/1481
[A[ATraining Step: 274  | total loss: [1m[32m0.28167[0m[0m | time: 34.180s
[2K
| Adam | epoch: 006 | loss: 0.28167 - acc: 0.8826 -- iter: 1248/1481
[A[ATraining Step: 275  | total loss: [1m[32m0.27852[0m[0m | time: 34.991s
[2K
| Adam | epoch: 006 | loss: 0.27852 - acc: 0.8819 -- iter: 1280/1481
[A[ATraining Step: 276  | total loss: [1m[32m0.26981[0m[0m | time: 36.043s
[2K
| Adam | epoch: 006 | loss: 0.26981 - acc: 0.8874 -- iter: 1312/1481
[A[ATraining Step: 277  | total loss: [1m[32m0.26355[0m[0m | time: 37.066s
[2K
| Adam | epoch: 006 | loss: 0.26355 - acc: 0.8956 -- iter: 1344/1481
[A[ATraining Step: 278  | total loss: [1m[32m0.24902[0m[0m | time: 37.868s
[2K
| Adam | epoch: 006 | loss: 0.24902 - acc: 0.9060 -- iter: 1376/1481
[A[ATraining Step: 279  | total loss: [1m[32m0.24421[0m[0m | time: 38.666s
[2K
| Adam | epoch: 006 | loss: 0.24421 - acc: 0.9060 -- iter: 1408/1481
[A[ATraining Step: 280  | total loss: [1m[32m0.24203[0m[0m | time: 39.538s
[2K
| Adam | epoch: 006 | loss: 0.24203 - acc: 0.9092 -- iter: 1440/1481
[A[ATraining Step: 281  | total loss: [1m[32m0.25144[0m[0m | time: 40.394s
[2K
| Adam | epoch: 006 | loss: 0.25144 - acc: 0.9026 -- iter: 1472/1481
[A[ATraining Step: 282  | total loss: [1m[32m0.24116[0m[0m | time: 43.333s
[2K
| Adam | epoch: 006 | loss: 0.24116 - acc: 0.9030 | val_loss: 0.33754 - val_acc: 0.8427 -- iter: 1481/1481
--
Training Step: 283  | total loss: [1m[32m0.22880[0m[0m | time: 0.855s
[2K
| Adam | epoch: 007 | loss: 0.22880 - acc: 0.9096 -- iter: 0032/1481
[A[ATraining Step: 284  | total loss: [1m[32m0.23102[0m[0m | time: 1.708s
[2K
| Adam | epoch: 007 | loss: 0.23102 - acc: 0.9061 -- iter: 0064/1481
[A[ATraining Step: 285  | total loss: [1m[32m0.25116[0m[0m | time: 2.621s
[2K
| Adam | epoch: 007 | loss: 0.25116 - acc: 0.9030 -- iter: 0096/1481
[A[ATraining Step: 286  | total loss: [1m[32m0.23484[0m[0m | time: 3.518s
[2K
| Adam | epoch: 007 | loss: 0.23484 - acc: 0.9127 -- iter: 0128/1481
[A[ATraining Step: 287  | total loss: [1m[32m0.22797[0m[0m | time: 3.853s
[2K
| Adam | epoch: 007 | loss: 0.22797 - acc: 0.9183 -- iter: 0160/1481
[A[ATraining Step: 288  | total loss: [1m[32m0.24110[0m[0m | time: 4.142s
[2K
| Adam | epoch: 007 | loss: 0.24110 - acc: 0.9154 -- iter: 0192/1481
[A[ATraining Step: 289  | total loss: [1m[32m0.22490[0m[0m | time: 5.086s
[2K
| Adam | epoch: 007 | loss: 0.22490 - acc: 0.9238 -- iter: 0224/1481
[A[ATraining Step: 290  | total loss: [1m[32m0.27652[0m[0m | time: 5.940s
[2K
| Adam | epoch: 007 | loss: 0.27652 - acc: 0.9033 -- iter: 0256/1481
[A[ATraining Step: 291  | total loss: [1m[32m0.28661[0m[0m | time: 6.786s
[2K
| Adam | epoch: 007 | loss: 0.28661 - acc: 0.9005 -- iter: 0288/1481
[A[ATraining Step: 292  | total loss: [1m[32m0.29737[0m[0m | time: 7.822s
[2K
| Adam | epoch: 007 | loss: 0.29737 - acc: 0.8979 -- iter: 0320/1481
[A[ATraining Step: 293  | total loss: [1m[32m0.31011[0m[0m | time: 8.841s
[2K
| Adam | epoch: 007 | loss: 0.31011 - acc: 0.8863 -- iter: 0352/1481
[A[ATraining Step: 294  | total loss: [1m[32m0.29903[0m[0m | time: 9.710s
[2K
| Adam | epoch: 007 | loss: 0.29903 - acc: 0.8914 -- iter: 0384/1481
[A[ATraining Step: 295  | total loss: [1m[32m0.29036[0m[0m | time: 10.553s
[2K
| Adam | epoch: 007 | loss: 0.29036 - acc: 0.8960 -- iter: 0416/1481
[A[ATraining Step: 296  | total loss: [1m[32m0.30927[0m[0m | time: 11.476s
[2K
| Adam | epoch: 007 | loss: 0.30927 - acc: 0.8783 -- iter: 0448/1481
[A[ATraining Step: 297  | total loss: [1m[32m0.32718[0m[0m | time: 12.371s
[2K
| Adam | epoch: 007 | loss: 0.32718 - acc: 0.8654 -- iter: 0480/1481
[A[ATraining Step: 298  | total loss: [1m[32m0.32456[0m[0m | time: 13.220s
[2K
| Adam | epoch: 007 | loss: 0.32456 - acc: 0.8664 -- iter: 0512/1481
[A[ATraining Step: 299  | total loss: [1m[32m0.31872[0m[0m | time: 14.233s
[2K
| Adam | epoch: 007 | loss: 0.31872 - acc: 0.8704 -- iter: 0544/1481
[A[ATraining Step: 300  | total loss: [1m[32m0.31564[0m[0m | time: 15.216s
[2K
| Adam | epoch: 007 | loss: 0.31564 - acc: 0.8740 -- iter: 0576/1481
[A[ATraining Step: 301  | total loss: [1m[32m0.31895[0m[0m | time: 16.116s
[2K
| Adam | epoch: 007 | loss: 0.31895 - acc: 0.8741 -- iter: 0608/1481
[A[ATraining Step: 302  | total loss: [1m[32m0.32755[0m[0m | time: 16.984s
[2K
| Adam | epoch: 007 | loss: 0.32755 - acc: 0.8679 -- iter: 0640/1481
[A[ATraining Step: 303  | total loss: [1m[32m0.33130[0m[0m | time: 18.000s
[2K
| Adam | epoch: 007 | loss: 0.33130 - acc: 0.8686 -- iter: 0672/1481
[A[ATraining Step: 304  | total loss: [1m[32m0.33553[0m[0m | time: 19.006s
[2K
| Adam | epoch: 007 | loss: 0.33553 - acc: 0.8693 -- iter: 0704/1481
[A[ATraining Step: 305  | total loss: [1m[32m0.32576[0m[0m | time: 19.810s
[2K
| Adam | epoch: 007 | loss: 0.32576 - acc: 0.8761 -- iter: 0736/1481
[A[ATraining Step: 306  | total loss: [1m[32m0.31460[0m[0m | time: 20.667s
[2K
| Adam | epoch: 007 | loss: 0.31460 - acc: 0.8854 -- iter: 0768/1481
[A[ATraining Step: 307  | total loss: [1m[32m0.31189[0m[0m | time: 21.607s
[2K
| Adam | epoch: 007 | loss: 0.31189 - acc: 0.8843 -- iter: 0800/1481
[A[ATraining Step: 308  | total loss: [1m[32m0.30410[0m[0m | time: 22.518s
[2K
| Adam | epoch: 007 | loss: 0.30410 - acc: 0.8896 -- iter: 0832/1481
[A[ATraining Step: 309  | total loss: [1m[32m0.29039[0m[0m | time: 23.380s
[2K
| Adam | epoch: 007 | loss: 0.29039 - acc: 0.8913 -- iter: 0864/1481
[A[ATraining Step: 310  | total loss: [1m[32m0.28465[0m[0m | time: 24.318s
[2K
| Adam | epoch: 007 | loss: 0.28465 - acc: 0.8897 -- iter: 0896/1481
[A[ATraining Step: 311  | total loss: [1m[32m0.30381[0m[0m | time: 25.218s
[2K
| Adam | epoch: 007 | loss: 0.30381 - acc: 0.8788 -- iter: 0928/1481
[A[ATraining Step: 312  | total loss: [1m[32m0.29919[0m[0m | time: 26.091s
[2K
| Adam | epoch: 007 | loss: 0.29919 - acc: 0.8784 -- iter: 0960/1481
[A[ATraining Step: 313  | total loss: [1m[32m0.29267[0m[0m | time: 26.861s
[2K
| Adam | epoch: 007 | loss: 0.29267 - acc: 0.8781 -- iter: 0992/1481
[A[ATraining Step: 314  | total loss: [1m[32m0.28118[0m[0m | time: 27.791s
[2K
| Adam | epoch: 007 | loss: 0.28118 - acc: 0.8809 -- iter: 1024/1481
[A[ATraining Step: 315  | total loss: [1m[32m0.26937[0m[0m | time: 28.790s
[2K
| Adam | epoch: 007 | loss: 0.26937 - acc: 0.8834 -- iter: 1056/1481
[A[ATraining Step: 316  | total loss: [1m[32m0.26775[0m[0m | time: 29.739s
[2K
| Adam | epoch: 007 | loss: 0.26775 - acc: 0.8826 -- iter: 1088/1481
[A[ATraining Step: 317  | total loss: [1m[32m0.26064[0m[0m | time: 30.676s
[2K
| Adam | epoch: 007 | loss: 0.26064 - acc: 0.8881 -- iter: 1120/1481
[A[ATraining Step: 318  | total loss: [1m[32m0.25117[0m[0m | time: 31.649s
[2K
| Adam | epoch: 007 | loss: 0.25117 - acc: 0.8962 -- iter: 1152/1481
[A[ATraining Step: 319  | total loss: [1m[32m0.24345[0m[0m | time: 32.590s
[2K
| Adam | epoch: 007 | loss: 0.24345 - acc: 0.9003 -- iter: 1184/1481
[A[ATraining Step: 320  | total loss: [1m[32m0.24898[0m[0m | time: 33.542s
[2K
| Adam | epoch: 007 | loss: 0.24898 - acc: 0.9009 -- iter: 1216/1481
[A[ATraining Step: 321  | total loss: [1m[32m0.23508[0m[0m | time: 34.533s
[2K
| Adam | epoch: 007 | loss: 0.23508 - acc: 0.9045 -- iter: 1248/1481
[A[ATraining Step: 322  | total loss: [1m[32m0.23392[0m[0m | time: 35.508s
[2K
| Adam | epoch: 007 | loss: 0.23392 - acc: 0.9078 -- iter: 1280/1481
[A[ATraining Step: 323  | total loss: [1m[32m0.22563[0m[0m | time: 36.482s
[2K
| Adam | epoch: 007 | loss: 0.22563 - acc: 0.9139 -- iter: 1312/1481
[A[ATraining Step: 324  | total loss: [1m[32m0.21618[0m[0m | time: 37.456s
[2K
| Adam | epoch: 007 | loss: 0.21618 - acc: 0.9163 -- iter: 1344/1481
[A[ATraining Step: 325  | total loss: [1m[32m0.21551[0m[0m | time: 38.467s
[2K
| Adam | epoch: 007 | loss: 0.21551 - acc: 0.9153 -- iter: 1376/1481
[A[ATraining Step: 326  | total loss: [1m[32m0.21166[0m[0m | time: 39.374s
[2K
| Adam | epoch: 007 | loss: 0.21166 - acc: 0.9175 -- iter: 1408/1481
[A[ATraining Step: 327  | total loss: [1m[32m0.23407[0m[0m | time: 40.133s
[2K
| Adam | epoch: 007 | loss: 0.23407 - acc: 0.9133 -- iter: 1440/1481
[A[ATraining Step: 328  | total loss: [1m[32m0.23083[0m[0m | time: 40.768s
[2K
| Adam | epoch: 007 | loss: 0.23083 - acc: 0.9094 -- iter: 1472/1481
[A[ATraining Step: 329  | total loss: [1m[32m0.24631[0m[0m | time: 42.894s
[2K
| Adam | epoch: 007 | loss: 0.24631 - acc: 0.8966 | val_loss: 0.32693 - val_acc: 0.8685 -- iter: 1481/1481
--
Training Step: 330  | total loss: [1m[32m0.23967[0m[0m | time: 0.620s
[2K
| Adam | epoch: 008 | loss: 0.23967 - acc: 0.8976 -- iter: 0032/1481
[A[ATraining Step: 331  | total loss: [1m[32m0.24650[0m[0m | time: 1.223s
[2K
| Adam | epoch: 008 | loss: 0.24650 - acc: 0.8953 -- iter: 0064/1481
[A[ATraining Step: 332  | total loss: [1m[32m0.23455[0m[0m | time: 1.839s
[2K
| Adam | epoch: 008 | loss: 0.23455 - acc: 0.8995 -- iter: 0096/1481
[A[ATraining Step: 333  | total loss: [1m[32m0.22211[0m[0m | time: 2.455s
[2K
| Adam | epoch: 008 | loss: 0.22211 - acc: 0.9096 -- iter: 0128/1481
[A[ATraining Step: 334  | total loss: [1m[32m0.22627[0m[0m | time: 3.077s
[2K
| Adam | epoch: 008 | loss: 0.22627 - acc: 0.9093 -- iter: 0160/1481
[A[ATraining Step: 335  | total loss: [1m[32m0.21074[0m[0m | time: 3.299s
[2K
| Adam | epoch: 008 | loss: 0.21074 - acc: 0.9183 -- iter: 0192/1481
[A[ATraining Step: 336  | total loss: [1m[32m0.19977[0m[0m | time: 3.500s
[2K
| Adam | epoch: 008 | loss: 0.19977 - acc: 0.9265 -- iter: 0224/1481
[A[ATraining Step: 337  | total loss: [1m[32m0.18698[0m[0m | time: 4.123s
[2K
| Adam | epoch: 008 | loss: 0.18698 - acc: 0.9338 -- iter: 0256/1481
[A[ATraining Step: 338  | total loss: [1m[32m0.18717[0m[0m | time: 4.734s
[2K
| Adam | epoch: 008 | loss: 0.18717 - acc: 0.9342 -- iter: 0288/1481
[A[ATraining Step: 339  | total loss: [1m[32m0.18023[0m[0m | time: 5.357s
[2K
| Adam | epoch: 008 | loss: 0.18023 - acc: 0.9377 -- iter: 0320/1481
[A[ATraining Step: 340  | total loss: [1m[32m0.17041[0m[0m | time: 5.978s
[2K
| Adam | epoch: 008 | loss: 0.17041 - acc: 0.9408 -- iter: 0352/1481
[A[ATraining Step: 341  | total loss: [1m[32m0.17079[0m[0m | time: 6.584s
[2K
| Adam | epoch: 008 | loss: 0.17079 - acc: 0.9342 -- iter: 0384/1481
[A[ATraining Step: 342  | total loss: [1m[32m0.16752[0m[0m | time: 7.198s
[2K
| Adam | epoch: 008 | loss: 0.16752 - acc: 0.9345 -- iter: 0416/1481
[A[ATraining Step: 343  | total loss: [1m[32m0.17791[0m[0m | time: 7.811s
[2K
| Adam | epoch: 008 | loss: 0.17791 - acc: 0.9317 -- iter: 0448/1481
[A[ATraining Step: 344  | total loss: [1m[32m0.18024[0m[0m | time: 8.421s
[2K
| Adam | epoch: 008 | loss: 0.18024 - acc: 0.9292 -- iter: 0480/1481
[A[ATraining Step: 345  | total loss: [1m[32m0.19042[0m[0m | time: 9.026s
[2K
| Adam | epoch: 008 | loss: 0.19042 - acc: 0.9300 -- iter: 0512/1481
[A[ATraining Step: 346  | total loss: [1m[32m0.20739[0m[0m | time: 9.655s
[2K
| Adam | epoch: 008 | loss: 0.20739 - acc: 0.9245 -- iter: 0544/1481
[A[ATraining Step: 347  | total loss: [1m[32m0.21705[0m[0m | time: 10.257s
[2K
| Adam | epoch: 008 | loss: 0.21705 - acc: 0.9195 -- iter: 0576/1481
[A[ATraining Step: 348  | total loss: [1m[32m0.20496[0m[0m | time: 10.859s
[2K
| Adam | epoch: 008 | loss: 0.20496 - acc: 0.9276 -- iter: 0608/1481
[A[ATraining Step: 349  | total loss: [1m[32m0.21162[0m[0m | time: 11.477s
[2K
| Adam | epoch: 008 | loss: 0.21162 - acc: 0.9255 -- iter: 0640/1481
[A[ATraining Step: 350  | total loss: [1m[32m0.20336[0m[0m | time: 12.114s
[2K
| Adam | epoch: 008 | loss: 0.20336 - acc: 0.9298 -- iter: 0672/1481
[A[ATraining Step: 351  | total loss: [1m[32m0.20177[0m[0m | time: 12.719s
[2K
| Adam | epoch: 008 | loss: 0.20177 - acc: 0.9243 -- iter: 0704/1481
[A[ATraining Step: 352  | total loss: [1m[32m0.21415[0m[0m | time: 13.717s
[2K
| Adam | epoch: 008 | loss: 0.21415 - acc: 0.9162 -- iter: 0736/1481
[A[ATraining Step: 353  | total loss: [1m[32m0.21968[0m[0m | time: 14.806s
[2K
| Adam | epoch: 008 | loss: 0.21968 - acc: 0.9121 -- iter: 0768/1481
[A[ATraining Step: 354  | total loss: [1m[32m0.20641[0m[0m | time: 15.661s
[2K
| Adam | epoch: 008 | loss: 0.20641 - acc: 0.9209 -- iter: 0800/1481
[A[ATraining Step: 355  | total loss: [1m[32m0.19646[0m[0m | time: 16.448s
[2K
| Adam | epoch: 008 | loss: 0.19646 - acc: 0.9257 -- iter: 0832/1481
[A[ATraining Step: 356  | total loss: [1m[32m0.19573[0m[0m | time: 17.282s
[2K
| Adam | epoch: 008 | loss: 0.19573 - acc: 0.9238 -- iter: 0864/1481
[A[ATraining Step: 357  | total loss: [1m[32m0.21253[0m[0m | time: 18.110s
[2K
| Adam | epoch: 008 | loss: 0.21253 - acc: 0.9126 -- iter: 0896/1481
[A[ATraining Step: 358  | total loss: [1m[32m0.21457[0m[0m | time: 19.015s
[2K
| Adam | epoch: 008 | loss: 0.21457 - acc: 0.9120 -- iter: 0928/1481
[A[ATraining Step: 359  | total loss: [1m[32m0.19899[0m[0m | time: 19.829s
[2K
| Adam | epoch: 008 | loss: 0.19899 - acc: 0.9208 -- iter: 0960/1481
[A[ATraining Step: 360  | total loss: [1m[32m0.19481[0m[0m | time: 20.736s
[2K
| Adam | epoch: 008 | loss: 0.19481 - acc: 0.9193 -- iter: 0992/1481
[A[ATraining Step: 361  | total loss: [1m[32m0.20668[0m[0m | time: 21.634s
[2K
| Adam | epoch: 008 | loss: 0.20668 - acc: 0.9180 -- iter: 1024/1481
[A[ATraining Step: 362  | total loss: [1m[32m0.21606[0m[0m | time: 22.554s
[2K
| Adam | epoch: 008 | loss: 0.21606 - acc: 0.9137 -- iter: 1056/1481
[A[ATraining Step: 363  | total loss: [1m[32m0.19971[0m[0m | time: 23.331s
[2K
| Adam | epoch: 008 | loss: 0.19971 - acc: 0.9224 -- iter: 1088/1481
[A[ATraining Step: 364  | total loss: [1m[32m0.19903[0m[0m | time: 24.359s
[2K
| Adam | epoch: 008 | loss: 0.19903 - acc: 0.9207 -- iter: 1120/1481
[A[ATraining Step: 365  | total loss: [1m[32m0.19630[0m[0m | time: 25.365s
[2K
| Adam | epoch: 008 | loss: 0.19630 - acc: 0.9224 -- iter: 1152/1481
[A[ATraining Step: 366  | total loss: [1m[32m0.19518[0m[0m | time: 26.229s
[2K
| Adam | epoch: 008 | loss: 0.19518 - acc: 0.9239 -- iter: 1184/1481
[A[ATraining Step: 367  | total loss: [1m[32m0.18597[0m[0m | time: 27.064s
[2K
| Adam | epoch: 008 | loss: 0.18597 - acc: 0.9253 -- iter: 1216/1481
[A[ATraining Step: 368  | total loss: [1m[32m0.18695[0m[0m | time: 27.882s
[2K
| Adam | epoch: 008 | loss: 0.18695 - acc: 0.9265 -- iter: 1248/1481
[A[ATraining Step: 369  | total loss: [1m[32m0.18003[0m[0m | time: 28.725s
[2K
| Adam | epoch: 008 | loss: 0.18003 - acc: 0.9307 -- iter: 1280/1481
[A[ATraining Step: 370  | total loss: [1m[32m0.17418[0m[0m | time: 29.612s
[2K
| Adam | epoch: 008 | loss: 0.17418 - acc: 0.9314 -- iter: 1312/1481
[A[ATraining Step: 371  | total loss: [1m[32m0.17311[0m[0m | time: 30.464s
[2K
| Adam | epoch: 008 | loss: 0.17311 - acc: 0.9351 -- iter: 1344/1481
[A[ATraining Step: 372  | total loss: [1m[32m0.17248[0m[0m | time: 31.358s
[2K
| Adam | epoch: 008 | loss: 0.17248 - acc: 0.9354 -- iter: 1376/1481
[A[ATraining Step: 373  | total loss: [1m[32m0.16109[0m[0m | time: 32.297s
[2K
| Adam | epoch: 008 | loss: 0.16109 - acc: 0.9418 -- iter: 1408/1481
[A[ATraining Step: 374  | total loss: [1m[32m0.15804[0m[0m | time: 33.169s
[2K
| Adam | epoch: 008 | loss: 0.15804 - acc: 0.9414 -- iter: 1440/1481
[A[ATraining Step: 375  | total loss: [1m[32m0.16718[0m[0m | time: 34.008s
[2K
| Adam | epoch: 008 | loss: 0.16718 - acc: 0.9379 -- iter: 1472/1481
[A[ATraining Step: 376  | total loss: [1m[32m0.15901[0m[0m | time: 37.239s
[2K
| Adam | epoch: 008 | loss: 0.15901 - acc: 0.9410 | val_loss: 0.34162 - val_acc: 0.8621 -- iter: 1481/1481
--
Training Step: 377  | total loss: [1m[32m0.17385[0m[0m | time: 0.927s
[2K
| Adam | epoch: 009 | loss: 0.17385 - acc: 0.9344 -- iter: 0032/1481
[A[ATraining Step: 378  | total loss: [1m[32m0.16580[0m[0m | time: 1.852s
[2K
| Adam | epoch: 009 | loss: 0.16580 - acc: 0.9378 -- iter: 0064/1481
[A[ATraining Step: 379  | total loss: [1m[32m0.16781[0m[0m | time: 2.769s
[2K
| Adam | epoch: 009 | loss: 0.16781 - acc: 0.9347 -- iter: 0096/1481
[A[ATraining Step: 380  | total loss: [1m[32m0.17021[0m[0m | time: 3.681s
[2K
| Adam | epoch: 009 | loss: 0.17021 - acc: 0.9287 -- iter: 0128/1481
[A[ATraining Step: 381  | total loss: [1m[32m0.16772[0m[0m | time: 4.493s
[2K
| Adam | epoch: 009 | loss: 0.16772 - acc: 0.9296 -- iter: 0160/1481
[A[ATraining Step: 382  | total loss: [1m[32m0.16773[0m[0m | time: 5.554s
[2K
| Adam | epoch: 009 | loss: 0.16773 - acc: 0.9304 -- iter: 0192/1481
[A[ATraining Step: 383  | total loss: [1m[32m0.15496[0m[0m | time: 5.921s
[2K
| Adam | epoch: 009 | loss: 0.15496 - acc: 0.9373 -- iter: 0224/1481
[A[ATraining Step: 384  | total loss: [1m[32m0.14020[0m[0m | time: 6.267s
[2K
| Adam | epoch: 009 | loss: 0.14020 - acc: 0.9436 -- iter: 0256/1481
[A[ATraining Step: 385  | total loss: [1m[32m0.12682[0m[0m | time: 7.214s
[2K
| Adam | epoch: 009 | loss: 0.12682 - acc: 0.9492 -- iter: 0288/1481
[A[ATraining Step: 386  | total loss: [1m[32m0.15741[0m[0m | time: 7.977s
[2K
| Adam | epoch: 009 | loss: 0.15741 - acc: 0.9356 -- iter: 0320/1481
[A[ATraining Step: 387  | total loss: [1m[32m0.16614[0m[0m | time: 8.809s
[2K
| Adam | epoch: 009 | loss: 0.16614 - acc: 0.9326 -- iter: 0352/1481
[A[ATraining Step: 388  | total loss: [1m[32m0.17706[0m[0m | time: 9.635s
[2K
| Adam | epoch: 009 | loss: 0.17706 - acc: 0.9300 -- iter: 0384/1481
[A[ATraining Step: 389  | total loss: [1m[32m0.16363[0m[0m | time: 10.482s
[2K
| Adam | epoch: 009 | loss: 0.16363 - acc: 0.9370 -- iter: 0416/1481
[A[ATraining Step: 390  | total loss: [1m[32m0.15675[0m[0m | time: 11.385s
[2K
| Adam | epoch: 009 | loss: 0.15675 - acc: 0.9370 -- iter: 0448/1481
[A[ATraining Step: 391  | total loss: [1m[32m0.16588[0m[0m | time: 12.292s
[2K
| Adam | epoch: 009 | loss: 0.16588 - acc: 0.9308 -- iter: 0480/1481
[A[ATraining Step: 392  | total loss: [1m[32m0.17204[0m[0m | time: 13.218s
[2K
| Adam | epoch: 009 | loss: 0.17204 - acc: 0.9284 -- iter: 0512/1481
[A[ATraining Step: 393  | total loss: [1m[32m0.16752[0m[0m | time: 14.101s
[2K
| Adam | epoch: 009 | loss: 0.16752 - acc: 0.9324 -- iter: 0544/1481
[A[ATraining Step: 394  | total loss: [1m[32m0.15990[0m[0m | time: 15.020s
[2K
| Adam | epoch: 009 | loss: 0.15990 - acc: 0.9361 -- iter: 0576/1481
[A[ATraining Step: 395  | total loss: [1m[32m0.15477[0m[0m | time: 16.002s
[2K
| Adam | epoch: 009 | loss: 0.15477 - acc: 0.9393 -- iter: 0608/1481
[A[ATraining Step: 396  | total loss: [1m[32m0.16480[0m[0m | time: 17.024s
[2K
| Adam | epoch: 009 | loss: 0.16480 - acc: 0.9391 -- iter: 0640/1481
[A[ATraining Step: 397  | total loss: [1m[32m0.16511[0m[0m | time: 17.754s
[2K
| Adam | epoch: 009 | loss: 0.16511 - acc: 0.9359 -- iter: 0672/1481
[A[ATraining Step: 398  | total loss: [1m[32m0.17628[0m[0m | time: 18.614s
[2K
| Adam | epoch: 009 | loss: 0.17628 - acc: 0.9329 -- iter: 0704/1481
[A[ATraining Step: 399  | total loss: [1m[32m0.17388[0m[0m | time: 19.456s
[2K
| Adam | epoch: 009 | loss: 0.17388 - acc: 0.9365 -- iter: 0736/1481
[A[ATraining Step: 400  | total loss: [1m[32m0.20087[0m[0m | time: 22.462s
[2K
| Adam | epoch: 009 | loss: 0.20087 - acc: 0.9272 | val_loss: 0.29281 - val_acc: 0.8772 -- iter: 0768/1481
--
Training Step: 401  | total loss: [1m[32m0.20262[0m[0m | time: 23.417s
[2K
| Adam | epoch: 009 | loss: 0.20262 - acc: 0.9282 -- iter: 0800/1481
[A[ATraining Step: 402  | total loss: [1m[32m0.18743[0m[0m | time: 24.133s
[2K
| Adam | epoch: 009 | loss: 0.18743 - acc: 0.9354 -- iter: 0832/1481
[A[ATraining Step: 403  | total loss: [1m[32m0.17630[0m[0m | time: 24.980s
[2K
| Adam | epoch: 009 | loss: 0.17630 - acc: 0.9419 -- iter: 0864/1481
[A[ATraining Step: 404  | total loss: [1m[32m0.17253[0m[0m | time: 25.842s
[2K
| Adam | epoch: 009 | loss: 0.17253 - acc: 0.9446 -- iter: 0896/1481
[A[ATraining Step: 405  | total loss: [1m[32m0.16710[0m[0m | time: 26.682s
[2K
| Adam | epoch: 009 | loss: 0.16710 - acc: 0.9470 -- iter: 0928/1481
[A[ATraining Step: 406  | total loss: [1m[32m0.16175[0m[0m | time: 27.553s
[2K
| Adam | epoch: 009 | loss: 0.16175 - acc: 0.9523 -- iter: 0960/1481
[A[ATraining Step: 407  | total loss: [1m[32m0.15432[0m[0m | time: 28.438s
[2K
| Adam | epoch: 009 | loss: 0.15432 - acc: 0.9571 -- iter: 0992/1481
[A[ATraining Step: 408  | total loss: [1m[32m0.14743[0m[0m | time: 29.326s
[2K
| Adam | epoch: 009 | loss: 0.14743 - acc: 0.9613 -- iter: 1024/1481
[A[ATraining Step: 409  | total loss: [1m[32m0.13908[0m[0m | time: 30.250s
[2K
| Adam | epoch: 009 | loss: 0.13908 - acc: 0.9652 -- iter: 1056/1481
[A[ATraining Step: 410  | total loss: [1m[32m0.12876[0m[0m | time: 31.060s
[2K
| Adam | epoch: 009 | loss: 0.12876 - acc: 0.9687 -- iter: 1088/1481
[A[ATraining Step: 411  | total loss: [1m[32m0.12833[0m[0m | time: 32.100s
[2K
| Adam | epoch: 009 | loss: 0.12833 - acc: 0.9687 -- iter: 1120/1481
[A[ATraining Step: 412  | total loss: [1m[32m0.11999[0m[0m | time: 33.109s
[2K
| Adam | epoch: 009 | loss: 0.11999 - acc: 0.9718 -- iter: 1152/1481
[A[ATraining Step: 413  | total loss: [1m[32m0.11359[0m[0m | time: 33.957s
[2K
| Adam | epoch: 009 | loss: 0.11359 - acc: 0.9715 -- iter: 1184/1481
[A[ATraining Step: 414  | total loss: [1m[32m0.11231[0m[0m | time: 34.773s
[2K
| Adam | epoch: 009 | loss: 0.11231 - acc: 0.9712 -- iter: 1216/1481
[A[ATraining Step: 415  | total loss: [1m[32m0.10495[0m[0m | time: 35.604s
[2K
| Adam | epoch: 009 | loss: 0.10495 - acc: 0.9741 -- iter: 1248/1481
[A[ATraining Step: 416  | total loss: [1m[32m0.11173[0m[0m | time: 36.434s
[2K
| Adam | epoch: 009 | loss: 0.11173 - acc: 0.9673 -- iter: 1280/1481
[A[ATraining Step: 417  | total loss: [1m[32m0.11662[0m[0m | time: 37.248s
[2K
| Adam | epoch: 009 | loss: 0.11662 - acc: 0.9675 -- iter: 1312/1481
[A[ATraining Step: 418  | total loss: [1m[32m0.10853[0m[0m | time: 38.134s
[2K
| Adam | epoch: 009 | loss: 0.10853 - acc: 0.9707 -- iter: 1344/1481
[A[ATraining Step: 419  | total loss: [1m[32m0.10255[0m[0m | time: 39.049s
[2K
| Adam | epoch: 009 | loss: 0.10255 - acc: 0.9737 -- iter: 1376/1481
[A[ATraining Step: 420  | total loss: [1m[32m0.10165[0m[0m | time: 39.992s
[2K
| Adam | epoch: 009 | loss: 0.10165 - acc: 0.9732 -- iter: 1408/1481
[A[ATraining Step: 421  | total loss: [1m[32m0.10576[0m[0m | time: 40.849s
[2K
| Adam | epoch: 009 | loss: 0.10576 - acc: 0.9727 -- iter: 1440/1481
[A[ATraining Step: 422  | total loss: [1m[32m0.11151[0m[0m | time: 41.748s
[2K
| Adam | epoch: 009 | loss: 0.11151 - acc: 0.9723 -- iter: 1472/1481
[A[ATraining Step: 423  | total loss: [1m[32m0.12554[0m[0m | time: 44.852s
[2K
| Adam | epoch: 009 | loss: 0.12554 - acc: 0.9595 | val_loss: 0.34330 - val_acc: 0.8772 -- iter: 1481/1481
--
Training Step: 424  | total loss: [1m[32m0.11971[0m[0m | time: 0.876s
[2K
| Adam | epoch: 010 | loss: 0.11971 - acc: 0.9604 -- iter: 0032/1481
[A[ATraining Step: 425  | total loss: [1m[32m0.10902[0m[0m | time: 1.874s
[2K
| Adam | epoch: 010 | loss: 0.10902 - acc: 0.9644 -- iter: 0064/1481
[A[ATraining Step: 426  | total loss: [1m[32m0.09996[0m[0m | time: 2.770s
[2K
| Adam | epoch: 010 | loss: 0.09996 - acc: 0.9679 -- iter: 0096/1481
[A[ATraining Step: 427  | total loss: [1m[32m0.11143[0m[0m | time: 3.619s
[2K
| Adam | epoch: 010 | loss: 0.11143 - acc: 0.9618 -- iter: 0128/1481
[A[ATraining Step: 428  | total loss: [1m[32m0.10809[0m[0m | time: 4.556s
[2K
| Adam | epoch: 010 | loss: 0.10809 - acc: 0.9656 -- iter: 0160/1481
[A[ATraining Step: 429  | total loss: [1m[32m0.10003[0m[0m | time: 5.569s
[2K
| Adam | epoch: 010 | loss: 0.10003 - acc: 0.9690 -- iter: 0192/1481
[A[ATraining Step: 430  | total loss: [1m[32m0.09448[0m[0m | time: 6.569s
[2K
| Adam | epoch: 010 | loss: 0.09448 - acc: 0.9690 -- iter: 0224/1481
[A[ATraining Step: 431  | total loss: [1m[32m0.09157[0m[0m | time: 6.810s
[2K
| Adam | epoch: 010 | loss: 0.09157 - acc: 0.9721 -- iter: 0256/1481
[A[ATraining Step: 432  | total loss: [1m[32m0.08690[0m[0m | time: 7.051s
[2K
| Adam | epoch: 010 | loss: 0.08690 - acc: 0.9749 -- iter: 0288/1481
[A[ATraining Step: 433  | total loss: [1m[32m0.08024[0m[0m | time: 7.854s
[2K
| Adam | epoch: 010 | loss: 0.08024 - acc: 0.9774 -- iter: 0320/1481
[A[ATraining Step: 434  | total loss: [1m[32m0.08257[0m[0m | time: 8.733s
[2K
| Adam | epoch: 010 | loss: 0.08257 - acc: 0.9734 -- iter: 0352/1481
[A[ATraining Step: 435  | total loss: [1m[32m0.07990[0m[0m | time: 9.550s
[2K
| Adam | epoch: 010 | loss: 0.07990 - acc: 0.9761 -- iter: 0384/1481
[A[ATraining Step: 436  | total loss: [1m[32m0.07398[0m[0m | time: 10.433s
[2K
| Adam | epoch: 010 | loss: 0.07398 - acc: 0.9785 -- iter: 0416/1481
[A[ATraining Step: 437  | total loss: [1m[32m0.07881[0m[0m | time: 11.316s
[2K
| Adam | epoch: 010 | loss: 0.07881 - acc: 0.9775 -- iter: 0448/1481
[A[ATraining Step: 438  | total loss: [1m[32m0.07327[0m[0m | time: 12.180s
[2K
| Adam | epoch: 010 | loss: 0.07327 - acc: 0.9797 -- iter: 0480/1481
[A[ATraining Step: 439  | total loss: [1m[32m0.06849[0m[0m | time: 13.095s
[2K
| Adam | epoch: 010 | loss: 0.06849 - acc: 0.9818 -- iter: 0512/1481
[A[ATraining Step: 440  | total loss: [1m[32m0.06857[0m[0m | time: 13.917s
[2K
| Adam | epoch: 010 | loss: 0.06857 - acc: 0.9805 -- iter: 0544/1481
[A[ATraining Step: 441  | total loss: [1m[32m0.07147[0m[0m | time: 14.839s
[2K
| Adam | epoch: 010 | loss: 0.07147 - acc: 0.9793 -- iter: 0576/1481
[A[ATraining Step: 442  | total loss: [1m[32m0.07957[0m[0m | time: 15.791s
[2K
| Adam | epoch: 010 | loss: 0.07957 - acc: 0.9751 -- iter: 0608/1481
[A[ATraining Step: 443  | total loss: [1m[32m0.09148[0m[0m | time: 16.803s
[2K
| Adam | epoch: 010 | loss: 0.09148 - acc: 0.9745 -- iter: 0640/1481
[A[ATraining Step: 444  | total loss: [1m[32m0.09900[0m[0m | time: 17.780s
[2K
| Adam | epoch: 010 | loss: 0.09900 - acc: 0.9708 -- iter: 0672/1481
[A[ATraining Step: 445  | total loss: [1m[32m0.09525[0m[0m | time: 18.790s
[2K
| Adam | epoch: 010 | loss: 0.09525 - acc: 0.9737 -- iter: 0704/1481
[A[ATraining Step: 446  | total loss: [1m[32m0.09324[0m[0m | time: 19.752s
[2K
| Adam | epoch: 010 | loss: 0.09324 - acc: 0.9732 -- iter: 0736/1481
[A[ATraining Step: 447  | total loss: [1m[32m0.08526[0m[0m | time: 20.730s
[2K
| Adam | epoch: 010 | loss: 0.08526 - acc: 0.9759 -- iter: 0768/1481
[A[ATraining Step: 448  | total loss: [1m[32m0.10069[0m[0m | time: 21.706s
[2K
| Adam | epoch: 010 | loss: 0.10069 - acc: 0.9752 -- iter: 0800/1481
[A[ATraining Step: 449  | total loss: [1m[32m0.09527[0m[0m | time: 22.698s
[2K
| Adam | epoch: 010 | loss: 0.09527 - acc: 0.9777 -- iter: 0832/1481
[A[ATraining Step: 450  | total loss: [1m[32m0.08847[0m[0m | time: 23.645s
[2K
| Adam | epoch: 010 | loss: 0.08847 - acc: 0.9799 -- iter: 0864/1481
[A[ATraining Step: 451  | total loss: [1m[32m0.08164[0m[0m | time: 24.562s
[2K
| Adam | epoch: 010 | loss: 0.08164 - acc: 0.9819 -- iter: 0896/1481
[A[ATraining Step: 452  | total loss: [1m[32m0.07842[0m[0m | time: 25.495s
[2K
| Adam | epoch: 010 | loss: 0.07842 - acc: 0.9806 -- iter: 0928/1481
[A[ATraining Step: 453  | total loss: [1m[32m0.07190[0m[0m | time: 26.436s
[2K
| Adam | epoch: 010 | loss: 0.07190 - acc: 0.9825 -- iter: 0960/1481
[A[ATraining Step: 454  | total loss: [1m[32m0.06553[0m[0m | time: 27.331s
[2K
| Adam | epoch: 010 | loss: 0.06553 - acc: 0.9843 -- iter: 0992/1481
[A[ATraining Step: 455  | total loss: [1m[32m0.06243[0m[0m | time: 27.964s
[2K
| Adam | epoch: 010 | loss: 0.06243 - acc: 0.9858 -- iter: 1024/1481
[A[ATraining Step: 456  | total loss: [1m[32m0.06429[0m[0m | time: 28.575s
[2K
| Adam | epoch: 010 | loss: 0.06429 - acc: 0.9841 -- iter: 1056/1481
[A[ATraining Step: 457  | total loss: [1m[32m0.06027[0m[0m | time: 29.183s
[2K
| Adam | epoch: 010 | loss: 0.06027 - acc: 0.9857 -- iter: 1088/1481
[A[ATraining Step: 458  | total loss: [1m[32m0.05684[0m[0m | time: 29.814s
[2K
| Adam | epoch: 010 | loss: 0.05684 - acc: 0.9872 -- iter: 1120/1481
[A[ATraining Step: 459  | total loss: [1m[32m0.06194[0m[0m | time: 30.416s
[2K
| Adam | epoch: 010 | loss: 0.06194 - acc: 0.9853 -- iter: 1152/1481
[A[ATraining Step: 460  | total loss: [1m[32m0.07248[0m[0m | time: 31.025s
[2K
| Adam | epoch: 010 | loss: 0.07248 - acc: 0.9837 -- iter: 1184/1481
[A[ATraining Step: 461  | total loss: [1m[32m0.07500[0m[0m | time: 31.670s
[2K
| Adam | epoch: 010 | loss: 0.07500 - acc: 0.9822 -- iter: 1216/1481
[A[ATraining Step: 462  | total loss: [1m[32m0.06845[0m[0m | time: 32.276s
[2K
| Adam | epoch: 010 | loss: 0.06845 - acc: 0.9839 -- iter: 1248/1481
[A[ATraining Step: 463  | total loss: [1m[32m0.06266[0m[0m | time: 32.901s
[2K
| Adam | epoch: 010 | loss: 0.06266 - acc: 0.9856 -- iter: 1280/1481
[A[ATraining Step: 464  | total loss: [1m[32m0.06203[0m[0m | time: 33.507s
[2K
| Adam | epoch: 010 | loss: 0.06203 - acc: 0.9870 -- iter: 1312/1481
[A[ATraining Step: 465  | total loss: [1m[32m0.05833[0m[0m | time: 34.126s
[2K
| Adam | epoch: 010 | loss: 0.05833 - acc: 0.9883 -- iter: 1344/1481
[A[ATraining Step: 466  | total loss: [1m[32m0.05574[0m[0m | time: 34.731s
[2K
| Adam | epoch: 010 | loss: 0.05574 - acc: 0.9895 -- iter: 1376/1481
[A[ATraining Step: 467  | total loss: [1m[32m0.05074[0m[0m | time: 35.331s
[2K
| Adam | epoch: 010 | loss: 0.05074 - acc: 0.9905 -- iter: 1408/1481
[A[ATraining Step: 468  | total loss: [1m[32m0.05018[0m[0m | time: 35.922s
[2K
| Adam | epoch: 010 | loss: 0.05018 - acc: 0.9915 -- iter: 1440/1481
[A[ATraining Step: 469  | total loss: [1m[32m0.04884[0m[0m | time: 36.524s
[2K
| Adam | epoch: 010 | loss: 0.04884 - acc: 0.9923 -- iter: 1472/1481
[A[ATraining Step: 470  | total loss: [1m[32m0.07373[0m[0m | time: 38.602s
[2K
| Adam | epoch: 010 | loss: 0.07373 - acc: 0.9868 | val_loss: 0.39580 - val_acc: 0.8685 -- iter: 1481/1481
--
Training Step: 471  | total loss: [1m[32m0.06679[0m[0m | time: 0.599s
[2K
| Adam | epoch: 011 | loss: 0.06679 - acc: 0.9882 -- iter: 0032/1481
[A[ATraining Step: 472  | total loss: [1m[32m0.06336[0m[0m | time: 1.195s
[2K
| Adam | epoch: 011 | loss: 0.06336 - acc: 0.9893 -- iter: 0064/1481
[A[ATraining Step: 473  | total loss: [1m[32m0.06187[0m[0m | time: 1.811s
[2K
| Adam | epoch: 011 | loss: 0.06187 - acc: 0.9904 -- iter: 0096/1481
[A[ATraining Step: 474  | total loss: [1m[32m0.05794[0m[0m | time: 2.418s
[2K
| Adam | epoch: 011 | loss: 0.05794 - acc: 0.9914 -- iter: 0128/1481
[A[ATraining Step: 475  | total loss: [1m[32m0.05282[0m[0m | time: 3.035s
[2K
| Adam | epoch: 011 | loss: 0.05282 - acc: 0.9922 -- iter: 0160/1481
[A[ATraining Step: 476  | total loss: [1m[32m0.04797[0m[0m | time: 3.640s
[2K
| Adam | epoch: 011 | loss: 0.04797 - acc: 0.9930 -- iter: 0192/1481
[A[ATraining Step: 477  | total loss: [1m[32m0.04816[0m[0m | time: 4.231s
[2K
| Adam | epoch: 011 | loss: 0.04816 - acc: 0.9937 -- iter: 0224/1481
[A[ATraining Step: 478  | total loss: [1m[32m0.04534[0m[0m | time: 4.864s
[2K
| Adam | epoch: 011 | loss: 0.04534 - acc: 0.9943 -- iter: 0256/1481
[A[ATraining Step: 479  | total loss: [1m[32m0.04454[0m[0m | time: 5.069s
[2K
| Adam | epoch: 011 | loss: 0.04454 - acc: 0.9918 -- iter: 0288/1481
[A[ATraining Step: 480  | total loss: [1m[32m0.04042[0m[0m | time: 5.265s
[2K
| Adam | epoch: 011 | loss: 0.04042 - acc: 0.9926 -- iter: 0320/1481
[A[ATraining Step: 481  | total loss: [1m[32m0.03674[0m[0m | time: 5.867s
[2K
| Adam | epoch: 011 | loss: 0.03674 - acc: 0.9933 -- iter: 0352/1481
[A[ATraining Step: 482  | total loss: [1m[32m0.03486[0m[0m | time: 6.493s
[2K
| Adam | epoch: 011 | loss: 0.03486 - acc: 0.9940 -- iter: 0384/1481
[A[ATraining Step: 483  | total loss: [1m[32m0.03221[0m[0m | time: 7.518s
[2K
| Adam | epoch: 011 | loss: 0.03221 - acc: 0.9946 -- iter: 0416/1481
[A[ATraining Step: 484  | total loss: [1m[32m0.04317[0m[0m | time: 8.498s
[2K
| Adam | epoch: 011 | loss: 0.04317 - acc: 0.9889 -- iter: 0448/1481
[A[ATraining Step: 485  | total loss: [1m[32m0.04309[0m[0m | time: 9.350s
[2K
| Adam | epoch: 011 | loss: 0.04309 - acc: 0.9900 -- iter: 0480/1481
[A[ATraining Step: 486  | total loss: [1m[32m0.04044[0m[0m | time: 10.148s
[2K
| Adam | epoch: 011 | loss: 0.04044 - acc: 0.9910 -- iter: 0512/1481
[A[ATraining Step: 487  | total loss: [1m[32m0.03751[0m[0m | time: 10.992s
[2K
| Adam | epoch: 011 | loss: 0.03751 - acc: 0.9919 -- iter: 0544/1481
[A[ATraining Step: 488  | total loss: [1m[32m0.05119[0m[0m | time: 11.828s
[2K
| Adam | epoch: 011 | loss: 0.05119 - acc: 0.9896 -- iter: 0576/1481
[A[ATraining Step: 489  | total loss: [1m[32m0.04803[0m[0m | time: 12.733s
[2K
| Adam | epoch: 011 | loss: 0.04803 - acc: 0.9906 -- iter: 0608/1481
[A[ATraining Step: 490  | total loss: [1m[32m0.04551[0m[0m | time: 13.549s
[2K
| Adam | epoch: 011 | loss: 0.04551 - acc: 0.9916 -- iter: 0640/1481
[A[ATraining Step: 491  | total loss: [1m[32m0.04458[0m[0m | time: 14.516s
[2K
| Adam | epoch: 011 | loss: 0.04458 - acc: 0.9893 -- iter: 0672/1481
[A[ATraining Step: 492  | total loss: [1m[32m0.04500[0m[0m | time: 15.456s
[2K
| Adam | epoch: 011 | loss: 0.04500 - acc: 0.9872 -- iter: 0704/1481
[A[ATraining Step: 493  | total loss: [1m[32m0.04699[0m[0m | time: 16.310s
[2K
| Adam | epoch: 011 | loss: 0.04699 - acc: 0.9854 -- iter: 0736/1481
[A[ATraining Step: 494  | total loss: [1m[32m0.04843[0m[0m | time: 17.098s
[2K
| Adam | epoch: 011 | loss: 0.04843 - acc: 0.9837 -- iter: 0768/1481
[A[ATraining Step: 495  | total loss: [1m[32m0.04425[0m[0m | time: 18.158s
[2K
| Adam | epoch: 011 | loss: 0.04425 - acc: 0.9853 -- iter: 0800/1481
[A[ATraining Step: 496  | total loss: [1m[32m0.05720[0m[0m | time: 19.244s
[2K
| Adam | epoch: 011 | loss: 0.05720 - acc: 0.9837 -- iter: 0832/1481
[A[ATraining Step: 497  | total loss: [1m[32m0.05351[0m[0m | time: 20.031s
[2K
| Adam | epoch: 011 | loss: 0.05351 - acc: 0.9853 -- iter: 0864/1481
[A[ATraining Step: 498  | total loss: [1m[32m0.04937[0m[0m | time: 20.915s
[2K
| Adam | epoch: 011 | loss: 0.04937 - acc: 0.9868 -- iter: 0896/1481
[A[ATraining Step: 499  | total loss: [1m[32m0.04552[0m[0m | time: 21.789s
[2K
| Adam | epoch: 011 | loss: 0.04552 - acc: 0.9881 -- iter: 0928/1481
[A[ATraining Step: 500  | total loss: [1m[32m0.04174[0m[0m | time: 22.632s
[2K
| Adam | epoch: 011 | loss: 0.04174 - acc: 0.9893 -- iter: 0960/1481
[A[ATraining Step: 501  | total loss: [1m[32m0.04731[0m[0m | time: 23.443s
[2K
| Adam | epoch: 011 | loss: 0.04731 - acc: 0.9872 -- iter: 0992/1481
[A[ATraining Step: 502  | total loss: [1m[32m0.04453[0m[0m | time: 24.317s
[2K
| Adam | epoch: 011 | loss: 0.04453 - acc: 0.9885 -- iter: 1024/1481
[A[ATraining Step: 503  | total loss: [1m[32m0.04142[0m[0m | time: 25.302s
[2K
| Adam | epoch: 011 | loss: 0.04142 - acc: 0.9897 -- iter: 1056/1481
[A[ATraining Step: 504  | total loss: [1m[32m0.03851[0m[0m | time: 26.198s
[2K
| Adam | epoch: 011 | loss: 0.03851 - acc: 0.9907 -- iter: 1088/1481
[A[ATraining Step: 505  | total loss: [1m[32m0.03596[0m[0m | time: 27.043s
[2K
| Adam | epoch: 011 | loss: 0.03596 - acc: 0.9916 -- iter: 1120/1481
[A[ATraining Step: 506  | total loss: [1m[32m0.03366[0m[0m | time: 28.034s
[2K
| Adam | epoch: 011 | loss: 0.03366 - acc: 0.9925 -- iter: 1152/1481
[A[ATraining Step: 507  | total loss: [1m[32m0.03317[0m[0m | time: 29.090s
[2K
| Adam | epoch: 011 | loss: 0.03317 - acc: 0.9932 -- iter: 1184/1481
[A[ATraining Step: 508  | total loss: [1m[32m0.03083[0m[0m | time: 30.060s
[2K
| Adam | epoch: 011 | loss: 0.03083 - acc: 0.9939 -- iter: 1216/1481
[A[ATraining Step: 509  | total loss: [1m[32m0.04152[0m[0m | time: 30.893s
[2K
| Adam | epoch: 011 | loss: 0.04152 - acc: 0.9914 -- iter: 1248/1481
[A[ATraining Step: 510  | total loss: [1m[32m0.03807[0m[0m | time: 31.777s
[2K
| Adam | epoch: 011 | loss: 0.03807 - acc: 0.9922 -- iter: 1280/1481
[A[ATraining Step: 511  | total loss: [1m[32m0.03601[0m[0m | time: 32.613s
[2K
| Adam | epoch: 011 | loss: 0.03601 - acc: 0.9930 -- iter: 1312/1481
[A[ATraining Step: 512  | total loss: [1m[32m0.04014[0m[0m | time: 33.478s
[2K
| Adam | epoch: 011 | loss: 0.04014 - acc: 0.9906 -- iter: 1344/1481
[A[ATraining Step: 513  | total loss: [1m[32m0.04623[0m[0m | time: 34.389s
[2K
| Adam | epoch: 011 | loss: 0.04623 - acc: 0.9884 -- iter: 1376/1481
[A[ATraining Step: 514  | total loss: [1m[32m0.04234[0m[0m | time: 35.296s
[2K
| Adam | epoch: 011 | loss: 0.04234 - acc: 0.9896 -- iter: 1408/1481
[A[ATraining Step: 515  | total loss: [1m[32m0.03906[0m[0m | time: 36.195s
[2K
| Adam | epoch: 011 | loss: 0.03906 - acc: 0.9906 -- iter: 1440/1481
[A[ATraining Step: 516  | total loss: [1m[32m0.03575[0m[0m | time: 37.074s
[2K
| Adam | epoch: 011 | loss: 0.03575 - acc: 0.9916 -- iter: 1472/1481
[A[ATraining Step: 517  | total loss: [1m[32m0.03551[0m[0m | time: 40.311s
[2K
| Adam | epoch: 011 | loss: 0.03551 - acc: 0.9924 | val_loss: 0.43637 - val_acc: 0.8772 -- iter: 1481/1481
--
Training Step: 518  | total loss: [1m[32m0.03295[0m[0m | time: 0.922s
[2K
| Adam | epoch: 012 | loss: 0.03295 - acc: 0.9932 -- iter: 0032/1481
[A[ATraining Step: 519  | total loss: [1m[32m0.03305[0m[0m | time: 1.834s
[2K
| Adam | epoch: 012 | loss: 0.03305 - acc: 0.9907 -- iter: 0064/1481
[A[ATraining Step: 520  | total loss: [1m[32m0.03151[0m[0m | time: 2.806s
[2K
| Adam | epoch: 012 | loss: 0.03151 - acc: 0.9916 -- iter: 0096/1481
[A[ATraining Step: 521  | total loss: [1m[32m0.03128[0m[0m | time: 3.782s
[2K
| Adam | epoch: 012 | loss: 0.03128 - acc: 0.9925 -- iter: 0128/1481
[A[ATraining Step: 522  | total loss: [1m[32m0.02905[0m[0m | time: 4.821s
[2K
| Adam | epoch: 012 | loss: 0.02905 - acc: 0.9932 -- iter: 0160/1481
[A[ATraining Step: 523  | total loss: [1m[32m0.03593[0m[0m | time: 5.537s
[2K
| Adam | epoch: 012 | loss: 0.03593 - acc: 0.9908 -- iter: 0192/1481
[A[ATraining Step: 524  | total loss: [1m[32m0.03268[0m[0m | time: 6.374s
[2K
| Adam | epoch: 012 | loss: 0.03268 - acc: 0.9917 -- iter: 0224/1481
[A[ATraining Step: 525  | total loss: [1m[32m0.05106[0m[0m | time: 7.183s
[2K
| Adam | epoch: 012 | loss: 0.05106 - acc: 0.9863 -- iter: 0256/1481
[A[ATraining Step: 526  | total loss: [1m[32m0.04678[0m[0m | time: 8.019s
[2K
| Adam | epoch: 012 | loss: 0.04678 - acc: 0.9877 -- iter: 0288/1481
[A[ATraining Step: 527  | total loss: [1m[32m0.04369[0m[0m | time: 8.301s
[2K
| Adam | epoch: 012 | loss: 0.04369 - acc: 0.9889 -- iter: 0320/1481
[A[ATraining Step: 528  | total loss: [1m[32m0.04030[0m[0m | time: 8.588s
[2K
| Adam | epoch: 012 | loss: 0.04030 - acc: 0.9900 -- iter: 0352/1481
[A[ATraining Step: 529  | total loss: [1m[32m0.03694[0m[0m | time: 9.414s
[2K
| Adam | epoch: 012 | loss: 0.03694 - acc: 0.9910 -- iter: 0384/1481
[A[ATraining Step: 530  | total loss: [1m[32m0.03365[0m[0m | time: 10.372s
[2K
| Adam | epoch: 012 | loss: 0.03365 - acc: 0.9919 -- iter: 0416/1481
[A[ATraining Step: 531  | total loss: [1m[32m0.03057[0m[0m | time: 11.255s
[2K
| Adam | epoch: 012 | loss: 0.03057 - acc: 0.9927 -- iter: 0448/1481
[A[ATraining Step: 532  | total loss: [1m[32m0.02869[0m[0m | time: 12.102s
[2K
| Adam | epoch: 012 | loss: 0.02869 - acc: 0.9934 -- iter: 0480/1481
[A[ATraining Step: 533  | total loss: [1m[32m0.02645[0m[0m | time: 13.006s
[2K
| Adam | epoch: 012 | loss: 0.02645 - acc: 0.9941 -- iter: 0512/1481
[A[ATraining Step: 534  | total loss: [1m[32m0.02435[0m[0m | time: 14.011s
[2K
| Adam | epoch: 012 | loss: 0.02435 - acc: 0.9947 -- iter: 0544/1481
[A[ATraining Step: 535  | total loss: [1m[32m0.02264[0m[0m | time: 14.992s
[2K
| Adam | epoch: 012 | loss: 0.02264 - acc: 0.9952 -- iter: 0576/1481
[A[ATraining Step: 536  | total loss: [1m[32m0.02091[0m[0m | time: 15.733s
[2K
| Adam | epoch: 012 | loss: 0.02091 - acc: 0.9957 -- iter: 0608/1481
[A[ATraining Step: 537  | total loss: [1m[32m0.01937[0m[0m | time: 16.587s
[2K
| Adam | epoch: 012 | loss: 0.01937 - acc: 0.9961 -- iter: 0640/1481
[A[ATraining Step: 538  | total loss: [1m[32m0.02266[0m[0m | time: 17.454s
[2K
| Adam | epoch: 012 | loss: 0.02266 - acc: 0.9903 -- iter: 0672/1481
[A[ATraining Step: 539  | total loss: [1m[32m0.02057[0m[0m | time: 18.324s
[2K
| Adam | epoch: 012 | loss: 0.02057 - acc: 0.9912 -- iter: 0704/1481
[A[ATraining Step: 540  | total loss: [1m[32m0.02274[0m[0m | time: 19.170s
[2K
| Adam | epoch: 012 | loss: 0.02274 - acc: 0.9890 -- iter: 0736/1481
[A[ATraining Step: 541  | total loss: [1m[32m0.02332[0m[0m | time: 20.060s
[2K
| Adam | epoch: 012 | loss: 0.02332 - acc: 0.9901 -- iter: 0768/1481
[A[ATraining Step: 542  | total loss: [1m[32m0.02169[0m[0m | time: 20.959s
[2K
| Adam | epoch: 012 | loss: 0.02169 - acc: 0.9911 -- iter: 0800/1481
[A[ATraining Step: 543  | total loss: [1m[32m0.02064[0m[0m | time: 21.908s
[2K
| Adam | epoch: 012 | loss: 0.02064 - acc: 0.9920 -- iter: 0832/1481
[A[ATraining Step: 544  | total loss: [1m[32m0.03195[0m[0m | time: 22.753s
[2K
| Adam | epoch: 012 | loss: 0.03195 - acc: 0.9897 -- iter: 0864/1481
[A[ATraining Step: 545  | total loss: [1m[32m0.03070[0m[0m | time: 23.744s
[2K
| Adam | epoch: 012 | loss: 0.03070 - acc: 0.9907 -- iter: 0896/1481
[A[ATraining Step: 546  | total loss: [1m[32m0.02987[0m[0m | time: 24.772s
[2K
| Adam | epoch: 012 | loss: 0.02987 - acc: 0.9916 -- iter: 0928/1481
[A[ATraining Step: 547  | total loss: [1m[32m0.03055[0m[0m | time: 25.489s
[2K
| Adam | epoch: 012 | loss: 0.03055 - acc: 0.9925 -- iter: 0960/1481
[A[ATraining Step: 548  | total loss: [1m[32m0.03110[0m[0m | time: 26.293s
[2K
| Adam | epoch: 012 | loss: 0.03110 - acc: 0.9932 -- iter: 0992/1481
[A[ATraining Step: 549  | total loss: [1m[32m0.02889[0m[0m | time: 27.145s
[2K
| Adam | epoch: 012 | loss: 0.02889 - acc: 0.9939 -- iter: 1024/1481
[A[ATraining Step: 550  | total loss: [1m[32m0.03590[0m[0m | time: 27.993s
[2K
| Adam | epoch: 012 | loss: 0.03590 - acc: 0.9914 -- iter: 1056/1481
[A[ATraining Step: 551  | total loss: [1m[32m0.03750[0m[0m | time: 28.888s
[2K
| Adam | epoch: 012 | loss: 0.03750 - acc: 0.9891 -- iter: 1088/1481
[A[ATraining Step: 552  | total loss: [1m[32m0.03402[0m[0m | time: 29.760s
[2K
| Adam | epoch: 012 | loss: 0.03402 - acc: 0.9902 -- iter: 1120/1481
[A[ATraining Step: 553  | total loss: [1m[32m0.03189[0m[0m | time: 30.680s
[2K
| Adam | epoch: 012 | loss: 0.03189 - acc: 0.9912 -- iter: 1152/1481
[A[ATraining Step: 554  | total loss: [1m[32m0.02902[0m[0m | time: 31.496s
[2K
| Adam | epoch: 012 | loss: 0.02902 - acc: 0.9921 -- iter: 1184/1481
[A[ATraining Step: 555  | total loss: [1m[32m0.02711[0m[0m | time: 32.439s
[2K
| Adam | epoch: 012 | loss: 0.02711 - acc: 0.9929 -- iter: 1216/1481
[A[ATraining Step: 556  | total loss: [1m[32m0.02862[0m[0m | time: 33.422s
[2K
| Adam | epoch: 012 | loss: 0.02862 - acc: 0.9904 -- iter: 1248/1481
[A[ATraining Step: 557  | total loss: [1m[32m0.02640[0m[0m | time: 34.280s
[2K
| Adam | epoch: 012 | loss: 0.02640 - acc: 0.9914 -- iter: 1280/1481
[A[ATraining Step: 558  | total loss: [1m[32m0.02834[0m[0m | time: 35.088s
[2K
| Adam | epoch: 012 | loss: 0.02834 - acc: 0.9923 -- iter: 1312/1481
[A[ATraining Step: 559  | total loss: [1m[32m0.02585[0m[0m | time: 35.895s
[2K
| Adam | epoch: 012 | loss: 0.02585 - acc: 0.9930 -- iter: 1344/1481
[A[ATraining Step: 560  | total loss: [1m[32m0.02502[0m[0m | time: 36.704s
[2K
| Adam | epoch: 012 | loss: 0.02502 - acc: 0.9937 -- iter: 1376/1481
[A[ATraining Step: 561  | total loss: [1m[32m0.03043[0m[0m | time: 37.542s
[2K
| Adam | epoch: 012 | loss: 0.03043 - acc: 0.9912 -- iter: 1408/1481
[A[ATraining Step: 562  | total loss: [1m[32m0.03412[0m[0m | time: 38.439s
[2K
| Adam | epoch: 012 | loss: 0.03412 - acc: 0.9890 -- iter: 1440/1481
[A[ATraining Step: 563  | total loss: [1m[32m0.03118[0m[0m | time: 39.378s
[2K
| Adam | epoch: 012 | loss: 0.03118 - acc: 0.9901 -- iter: 1472/1481
[A[ATraining Step: 564  | total loss: [1m[32m0.04910[0m[0m | time: 42.309s
[2K
| Adam | epoch: 012 | loss: 0.04910 - acc: 0.9880 | val_loss: 0.47197 - val_acc: 0.8685 -- iter: 1481/1481
--
Training Step: 565  | total loss: [1m[32m0.04461[0m[0m | time: 0.908s
[2K
| Adam | epoch: 013 | loss: 0.04461 - acc: 0.9892 -- iter: 0032/1481
[A[ATraining Step: 566  | total loss: [1m[32m0.04058[0m[0m | time: 1.802s
[2K
| Adam | epoch: 013 | loss: 0.04058 - acc: 0.9902 -- iter: 0064/1481
[A[ATraining Step: 567  | total loss: [1m[32m0.03746[0m[0m | time: 2.699s
[2K
| Adam | epoch: 013 | loss: 0.03746 - acc: 0.9912 -- iter: 0096/1481
[A[ATraining Step: 568  | total loss: [1m[32m0.03804[0m[0m | time: 3.603s
[2K
| Adam | epoch: 013 | loss: 0.03804 - acc: 0.9921 -- iter: 0128/1481
[A[ATraining Step: 569  | total loss: [1m[32m0.04016[0m[0m | time: 4.489s
[2K
| Adam | epoch: 013 | loss: 0.04016 - acc: 0.9929 -- iter: 0160/1481
[A[ATraining Step: 570  | total loss: [1m[32m0.03766[0m[0m | time: 5.339s
[2K
| Adam | epoch: 013 | loss: 0.03766 - acc: 0.9936 -- iter: 0192/1481
[A[ATraining Step: 571  | total loss: [1m[32m0.03427[0m[0m | time: 6.334s
[2K
| Adam | epoch: 013 | loss: 0.03427 - acc: 0.9942 -- iter: 0224/1481
[A[ATraining Step: 572  | total loss: [1m[32m0.03344[0m[0m | time: 7.365s
[2K
| Adam | epoch: 013 | loss: 0.03344 - acc: 0.9948 -- iter: 0256/1481
[A[ATraining Step: 573  | total loss: [1m[32m0.03436[0m[0m | time: 8.216s
[2K
| Adam | epoch: 013 | loss: 0.03436 - acc: 0.9922 -- iter: 0288/1481
[A[ATraining Step: 574  | total loss: [1m[32m0.03391[0m[0m | time: 9.009s
[2K
| Adam | epoch: 013 | loss: 0.03391 - acc: 0.9930 -- iter: 0320/1481
[A[ATraining Step: 575  | total loss: [1m[32m0.03093[0m[0m | time: 9.287s
[2K
| Adam | epoch: 013 | loss: 0.03093 - acc: 0.9937 -- iter: 0352/1481
[A[ATraining Step: 576  | total loss: [1m[32m0.02793[0m[0m | time: 9.580s
[2K
| Adam | epoch: 013 | loss: 0.02793 - acc: 0.9943 -- iter: 0384/1481
[A[ATraining Step: 577  | total loss: [1m[32m0.02524[0m[0m | time: 10.445s
[2K
| Adam | epoch: 013 | loss: 0.02524 - acc: 0.9949 -- iter: 0416/1481
[A[ATraining Step: 578  | total loss: [1m[32m0.03264[0m[0m | time: 11.320s
[2K
| Adam | epoch: 013 | loss: 0.03264 - acc: 0.9891 -- iter: 0448/1481
[A[ATraining Step: 579  | total loss: [1m[32m0.03348[0m[0m | time: 12.207s
[2K
| Adam | epoch: 013 | loss: 0.03348 - acc: 0.9902 -- iter: 0480/1481
[A[ATraining Step: 580  | total loss: [1m[32m0.03131[0m[0m | time: 13.112s
[2K
| Adam | epoch: 013 | loss: 0.03131 - acc: 0.9912 -- iter: 0512/1481
[A[ATraining Step: 581  | total loss: [1m[32m0.02932[0m[0m | time: 14.047s
[2K
| Adam | epoch: 013 | loss: 0.02932 - acc: 0.9921 -- iter: 0544/1481
[A[ATraining Step: 582  | total loss: [1m[32m0.03185[0m[0m | time: 14.875s
[2K
| Adam | epoch: 013 | loss: 0.03185 - acc: 0.9898 -- iter: 0576/1481
[A[ATraining Step: 583  | total loss: [1m[32m0.03406[0m[0m | time: 15.724s
[2K
| Adam | epoch: 013 | loss: 0.03406 - acc: 0.9877 -- iter: 0608/1481
[A[ATraining Step: 584  | total loss: [1m[32m0.03710[0m[0m | time: 16.766s
[2K
| Adam | epoch: 013 | loss: 0.03710 - acc: 0.9826 -- iter: 0640/1481
[A[ATraining Step: 585  | total loss: [1m[32m0.03519[0m[0m | time: 17.781s
[2K
| Adam | epoch: 013 | loss: 0.03519 - acc: 0.9844 -- iter: 0672/1481
[A[ATraining Step: 586  | total loss: [1m[32m0.03263[0m[0m | time: 18.512s
[2K
| Adam | epoch: 013 | loss: 0.03263 - acc: 0.9859 -- iter: 0704/1481
[A[ATraining Step: 587  | total loss: [1m[32m0.04335[0m[0m | time: 19.336s
[2K
| Adam | epoch: 013 | loss: 0.04335 - acc: 0.9842 -- iter: 0736/1481
[A[ATraining Step: 588  | total loss: [1m[32m0.04249[0m[0m | time: 20.250s
[2K
| Adam | epoch: 013 | loss: 0.04249 - acc: 0.9858 -- iter: 0768/1481
[A[ATraining Step: 589  | total loss: [1m[32m0.03851[0m[0m | time: 21.136s
[2K
| Adam | epoch: 013 | loss: 0.03851 - acc: 0.9872 -- iter: 0800/1481
[A[ATraining Step: 590  | total loss: [1m[32m0.03841[0m[0m | time: 22.009s
[2K
| Adam | epoch: 013 | loss: 0.03841 - acc: 0.9854 -- iter: 0832/1481
[A[ATraining Step: 591  | total loss: [1m[32m0.03527[0m[0m | time: 22.982s
[2K
| Adam | epoch: 013 | loss: 0.03527 - acc: 0.9868 -- iter: 0864/1481
[A[ATraining Step: 592  | total loss: [1m[32m0.10430[0m[0m | time: 23.863s
[2K
| Adam | epoch: 013 | loss: 0.10430 - acc: 0.9819 -- iter: 0896/1481
[A[ATraining Step: 593  | total loss: [1m[32m0.09446[0m[0m | time: 24.784s
[2K
| Adam | epoch: 013 | loss: 0.09446 - acc: 0.9837 -- iter: 0928/1481
[A[ATraining Step: 594  | total loss: [1m[32m0.08595[0m[0m | time: 25.637s
[2K
| Adam | epoch: 013 | loss: 0.08595 - acc: 0.9853 -- iter: 0960/1481
[A[ATraining Step: 595  | total loss: [1m[32m0.08355[0m[0m | time: 26.656s
[2K
| Adam | epoch: 013 | loss: 0.08355 - acc: 0.9837 -- iter: 0992/1481
[A[ATraining Step: 596  | total loss: [1m[32m0.10443[0m[0m | time: 27.692s
[2K
| Adam | epoch: 013 | loss: 0.10443 - acc: 0.9759 -- iter: 1024/1481
[A[ATraining Step: 597  | total loss: [1m[32m0.11738[0m[0m | time: 28.461s
[2K
| Adam | epoch: 013 | loss: 0.11738 - acc: 0.9690 -- iter: 1056/1481
[A[ATraining Step: 598  | total loss: [1m[32m0.10824[0m[0m | time: 29.344s
[2K
| Adam | epoch: 013 | loss: 0.10824 - acc: 0.9721 -- iter: 1088/1481
[A[ATraining Step: 599  | total loss: [1m[32m0.09950[0m[0m | time: 30.303s
[2K
| Adam | epoch: 013 | loss: 0.09950 - acc: 0.9749 -- iter: 1120/1481
[A[ATraining Step: 600  | total loss: [1m[32m0.09243[0m[0m | time: 33.344s
[2K
| Adam | epoch: 013 | loss: 0.09243 - acc: 0.9774 | val_loss: 0.74613 - val_acc: 0.7845 -- iter: 1152/1481
--
Training Step: 601  | total loss: [1m[32m0.08684[0m[0m | time: 34.232s
[2K
| Adam | epoch: 013 | loss: 0.08684 - acc: 0.9796 -- iter: 1184/1481
[A[ATraining Step: 602  | total loss: [1m[32m0.10616[0m[0m | time: 35.231s
[2K
| Adam | epoch: 013 | loss: 0.10616 - acc: 0.9661 -- iter: 1216/1481
[A[ATraining Step: 603  | total loss: [1m[32m0.09973[0m[0m | time: 36.245s
[2K
| Adam | epoch: 013 | loss: 0.09973 - acc: 0.9694 -- iter: 1248/1481
[A[ATraining Step: 604  | total loss: [1m[32m0.09269[0m[0m | time: 36.976s
[2K
| Adam | epoch: 013 | loss: 0.09269 - acc: 0.9725 -- iter: 1280/1481
[A[ATraining Step: 605  | total loss: [1m[32m0.08544[0m[0m | time: 37.873s
[2K
| Adam | epoch: 013 | loss: 0.08544 - acc: 0.9753 -- iter: 1312/1481
[A[ATraining Step: 606  | total loss: [1m[32m0.07839[0m[0m | time: 38.745s
[2K
| Adam | epoch: 013 | loss: 0.07839 - acc: 0.9777 -- iter: 1344/1481
[A[ATraining Step: 607  | total loss: [1m[32m0.07267[0m[0m | time: 39.597s
[2K
| Adam | epoch: 013 | loss: 0.07267 - acc: 0.9800 -- iter: 1376/1481
[A[ATraining Step: 608  | total loss: [1m[32m0.06940[0m[0m | time: 40.453s
[2K
| Adam | epoch: 013 | loss: 0.06940 - acc: 0.9820 -- iter: 1408/1481
[A[ATraining Step: 609  | total loss: [1m[32m0.07001[0m[0m | time: 41.364s
[2K
| Adam | epoch: 013 | loss: 0.07001 - acc: 0.9775 -- iter: 1440/1481
[A[ATraining Step: 610  | total loss: [1m[32m0.06938[0m[0m | time: 42.273s
[2K
| Adam | epoch: 013 | loss: 0.06938 - acc: 0.9766 -- iter: 1472/1481
[A[ATraining Step: 611  | total loss: [1m[32m0.06361[0m[0m | time: 45.107s
[2K
| Adam | epoch: 013 | loss: 0.06361 - acc: 0.9790 | val_loss: 0.43390 - val_acc: 0.8793 -- iter: 1481/1481
--
Training Step: 612  | total loss: [1m[32m0.05857[0m[0m | time: 0.961s
[2K
| Adam | epoch: 014 | loss: 0.05857 - acc: 0.9811 -- iter: 0032/1481
[A[ATraining Step: 613  | total loss: [1m[32m0.05312[0m[0m | time: 1.889s
[2K
| Adam | epoch: 014 | loss: 0.05312 - acc: 0.9830 -- iter: 0064/1481
[A[ATraining Step: 614  | total loss: [1m[32m0.04814[0m[0m | time: 2.790s
[2K
| Adam | epoch: 014 | loss: 0.04814 - acc: 0.9847 -- iter: 0096/1481
[A[ATraining Step: 615  | total loss: [1m[32m0.04391[0m[0m | time: 3.686s
[2K
| Adam | epoch: 014 | loss: 0.04391 - acc: 0.9862 -- iter: 0128/1481
[A[ATraining Step: 616  | total loss: [1m[32m0.05156[0m[0m | time: 4.649s
[2K
| Adam | epoch: 014 | loss: 0.05156 - acc: 0.9813 -- iter: 0160/1481
[A[ATraining Step: 617  | total loss: [1m[32m0.04935[0m[0m | time: 5.688s
[2K
| Adam | epoch: 014 | loss: 0.04935 - acc: 0.9832 -- iter: 0192/1481
[A[ATraining Step: 618  | total loss: [1m[32m0.04554[0m[0m | time: 6.643s
[2K
| Adam | epoch: 014 | loss: 0.04554 - acc: 0.9849 -- iter: 0224/1481
[A[ATraining Step: 619  | total loss: [1m[32m0.04506[0m[0m | time: 7.573s
[2K
| Adam | epoch: 014 | loss: 0.04506 - acc: 0.9833 -- iter: 0256/1481
[A[ATraining Step: 620  | total loss: [1m[32m0.04336[0m[0m | time: 8.523s
[2K
| Adam | epoch: 014 | loss: 0.04336 - acc: 0.9818 -- iter: 0288/1481
[A[ATraining Step: 621  | total loss: [1m[32m0.04303[0m[0m | time: 9.480s
[2K
| Adam | epoch: 014 | loss: 0.04303 - acc: 0.9836 -- iter: 0320/1481
[A[ATraining Step: 622  | total loss: [1m[32m0.03882[0m[0m | time: 10.459s
[2K
| Adam | epoch: 014 | loss: 0.03882 - acc: 0.9853 -- iter: 0352/1481
[A[ATraining Step: 623  | total loss: [1m[32m0.03538[0m[0m | time: 10.778s
[2K
| Adam | epoch: 014 | loss: 0.03538 - acc: 0.9867 -- iter: 0384/1481
[A[ATraining Step: 624  | total loss: [1m[32m0.03201[0m[0m | time: 11.073s
[2K
| Adam | epoch: 014 | loss: 0.03201 - acc: 0.9881 -- iter: 0416/1481
[A[ATraining Step: 625  | total loss: [1m[32m0.02896[0m[0m | time: 12.097s
[2K
| Adam | epoch: 014 | loss: 0.02896 - acc: 0.9893 -- iter: 0448/1481
[A[ATraining Step: 626  | total loss: [1m[32m0.02642[0m[0m | time: 13.044s
[2K
| Adam | epoch: 014 | loss: 0.02642 - acc: 0.9903 -- iter: 0480/1481
[A[ATraining Step: 627  | total loss: [1m[32m0.02416[0m[0m | time: 14.034s
[2K
| Adam | epoch: 014 | loss: 0.02416 - acc: 0.9913 -- iter: 0512/1481
[A[ATraining Step: 628  | total loss: [1m[32m0.02214[0m[0m | time: 15.013s
[2K
| Adam | epoch: 014 | loss: 0.02214 - acc: 0.9922 -- iter: 0544/1481
[A[ATraining Step: 629  | total loss: [1m[32m0.02023[0m[0m | time: 15.975s
[2K
| Adam | epoch: 014 | loss: 0.02023 - acc: 0.9930 -- iter: 0576/1481
[A[ATraining Step: 630  | total loss: [1m[32m0.01892[0m[0m | time: 16.881s
[2K
| Adam | epoch: 014 | loss: 0.01892 - acc: 0.9937 -- iter: 0608/1481
[A[ATraining Step: 631  | total loss: [1m[32m0.01829[0m[0m | time: 17.501s
[2K
| Adam | epoch: 014 | loss: 0.01829 - acc: 0.9943 -- iter: 0640/1481
[A[ATraining Step: 632  | total loss: [1m[32m0.01696[0m[0m | time: 18.113s
[2K
| Adam | epoch: 014 | loss: 0.01696 - acc: 0.9949 -- iter: 0672/1481
[A[ATraining Step: 633  | total loss: [1m[32m0.01549[0m[0m | time: 18.760s
[2K
| Adam | epoch: 014 | loss: 0.01549 - acc: 0.9954 -- iter: 0704/1481
[A[ATraining Step: 634  | total loss: [1m[32m0.01413[0m[0m | time: 19.361s
[2K
| Adam | epoch: 014 | loss: 0.01413 - acc: 0.9958 -- iter: 0736/1481
[A[ATraining Step: 635  | total loss: [1m[32m0.01292[0m[0m | time: 19.971s
[2K
| Adam | epoch: 014 | loss: 0.01292 - acc: 0.9963 -- iter: 0768/1481
[A[ATraining Step: 636  | total loss: [1m[32m0.01204[0m[0m | time: 20.587s
[2K
| Adam | epoch: 014 | loss: 0.01204 - acc: 0.9966 -- iter: 0800/1481
[A[ATraining Step: 637  | total loss: [1m[32m0.01102[0m[0m | time: 21.198s
[2K
| Adam | epoch: 014 | loss: 0.01102 - acc: 0.9970 -- iter: 0832/1481
[A[ATraining Step: 638  | total loss: [1m[32m0.01041[0m[0m | time: 21.801s
[2K
| Adam | epoch: 014 | loss: 0.01041 - acc: 0.9973 -- iter: 0864/1481
[A[ATraining Step: 639  | total loss: [1m[32m0.00974[0m[0m | time: 22.404s
[2K
| Adam | epoch: 014 | loss: 0.00974 - acc: 0.9975 -- iter: 0896/1481
[A[ATraining Step: 640  | total loss: [1m[32m0.00909[0m[0m | time: 23.013s
[2K
| Adam | epoch: 014 | loss: 0.00909 - acc: 0.9978 -- iter: 0928/1481
[A[ATraining Step: 641  | total loss: [1m[32m0.00920[0m[0m | time: 23.623s
[2K
| Adam | epoch: 014 | loss: 0.00920 - acc: 0.9980 -- iter: 0960/1481
[A[ATraining Step: 642  | total loss: [1m[32m0.00847[0m[0m | time: 24.227s
[2K
| Adam | epoch: 014 | loss: 0.00847 - acc: 0.9982 -- iter: 0992/1481
[A[ATraining Step: 643  | total loss: [1m[32m0.00769[0m[0m | time: 24.834s
[2K
| Adam | epoch: 014 | loss: 0.00769 - acc: 0.9984 -- iter: 1024/1481
[A[ATraining Step: 644  | total loss: [1m[32m0.00773[0m[0m | time: 25.434s
[2K
| Adam | epoch: 014 | loss: 0.00773 - acc: 0.9985 -- iter: 1056/1481
[A[ATraining Step: 645  | total loss: [1m[32m0.00776[0m[0m | time: 26.047s
[2K
| Adam | epoch: 014 | loss: 0.00776 - acc: 0.9987 -- iter: 1088/1481
[A[ATraining Step: 646  | total loss: [1m[32m0.00788[0m[0m | time: 26.652s
[2K
| Adam | epoch: 014 | loss: 0.00788 - acc: 0.9988 -- iter: 1120/1481
[A[ATraining Step: 647  | total loss: [1m[32m0.00727[0m[0m | time: 27.261s
[2K
| Adam | epoch: 014 | loss: 0.00727 - acc: 0.9989 -- iter: 1152/1481
[A[ATraining Step: 648  | total loss: [1m[32m0.00672[0m[0m | time: 27.871s
[2K
| Adam | epoch: 014 | loss: 0.00672 - acc: 0.9990 -- iter: 1184/1481
[A[ATraining Step: 649  | total loss: [1m[32m0.00619[0m[0m | time: 28.473s
[2K
| Adam | epoch: 014 | loss: 0.00619 - acc: 0.9991 -- iter: 1216/1481
[A[ATraining Step: 650  | total loss: [1m[32m0.00572[0m[0m | time: 29.080s
[2K
| Adam | epoch: 014 | loss: 0.00572 - acc: 0.9992 -- iter: 1248/1481
[A[ATraining Step: 651  | total loss: [1m[32m0.00530[0m[0m | time: 29.704s
[2K
| Adam | epoch: 014 | loss: 0.00530 - acc: 0.9993 -- iter: 1280/1481
[A[ATraining Step: 652  | total loss: [1m[32m0.00484[0m[0m | time: 30.315s
[2K
| Adam | epoch: 014 | loss: 0.00484 - acc: 0.9994 -- iter: 1312/1481
[A[ATraining Step: 653  | total loss: [1m[32m0.00465[0m[0m | time: 30.926s
[2K
| Adam | epoch: 014 | loss: 0.00465 - acc: 0.9994 -- iter: 1344/1481
[A[ATraining Step: 654  | total loss: [1m[32m0.00424[0m[0m | time: 31.535s
[2K
| Adam | epoch: 014 | loss: 0.00424 - acc: 0.9995 -- iter: 1376/1481
[A[ATraining Step: 655  | total loss: [1m[32m0.00394[0m[0m | time: 32.147s
[2K
| Adam | epoch: 014 | loss: 0.00394 - acc: 0.9995 -- iter: 1408/1481
[A[ATraining Step: 656  | total loss: [1m[32m0.00374[0m[0m | time: 32.754s
[2K
| Adam | epoch: 014 | loss: 0.00374 - acc: 0.9996 -- iter: 1440/1481
[A[ATraining Step: 657  | total loss: [1m[32m0.00352[0m[0m | time: 33.384s
[2K
| Adam | epoch: 014 | loss: 0.00352 - acc: 0.9996 -- iter: 1472/1481
[A[ATraining Step: 658  | total loss: [1m[32m0.00358[0m[0m | time: 35.455s
[2K
| Adam | epoch: 014 | loss: 0.00358 - acc: 0.9997 | val_loss: 0.51893 - val_acc: 0.8858 -- iter: 1481/1481
--
Training Step: 659  | total loss: [1m[32m0.00340[0m[0m | time: 0.884s
[2K
| Adam | epoch: 015 | loss: 0.00340 - acc: 0.9997 -- iter: 0032/1481
[A[ATraining Step: 660  | total loss: [1m[32m0.00315[0m[0m | time: 1.753s
[2K
| Adam | epoch: 015 | loss: 0.00315 - acc: 0.9997 -- iter: 0064/1481
[A[ATraining Step: 661  | total loss: [1m[32m0.00295[0m[0m | time: 2.629s
[2K
| Adam | epoch: 015 | loss: 0.00295 - acc: 0.9998 -- iter: 0096/1481
[A[ATraining Step: 662  | total loss: [1m[32m0.00432[0m[0m | time: 3.504s
[2K
| Adam | epoch: 015 | loss: 0.00432 - acc: 0.9998 -- iter: 0128/1481
[A[ATraining Step: 663  | total loss: [1m[32m0.00430[0m[0m | time: 4.412s
[2K
| Adam | epoch: 015 | loss: 0.00430 - acc: 0.9998 -- iter: 0160/1481
[A[ATraining Step: 664  | total loss: [1m[32m0.00414[0m[0m | time: 5.350s
[2K
| Adam | epoch: 015 | loss: 0.00414 - acc: 0.9998 -- iter: 0192/1481
[A[ATraining Step: 665  | total loss: [1m[32m0.00386[0m[0m | time: 6.163s
[2K
| Adam | epoch: 015 | loss: 0.00386 - acc: 0.9998 -- iter: 0224/1481
[A[ATraining Step: 666  | total loss: [1m[32m0.00372[0m[0m | time: 7.148s
[2K
| Adam | epoch: 015 | loss: 0.00372 - acc: 0.9999 -- iter: 0256/1481
[A[ATraining Step: 667  | total loss: [1m[32m0.00352[0m[0m | time: 8.183s
[2K
| Adam | epoch: 015 | loss: 0.00352 - acc: 0.9999 -- iter: 0288/1481
[A[ATraining Step: 668  | total loss: [1m[32m0.00351[0m[0m | time: 9.151s
[2K
| Adam | epoch: 015 | loss: 0.00351 - acc: 0.9999 -- iter: 0320/1481
[A[ATraining Step: 669  | total loss: [1m[32m0.00322[0m[0m | time: 9.872s
[2K
| Adam | epoch: 015 | loss: 0.00322 - acc: 0.9999 -- iter: 0352/1481
[A[ATraining Step: 670  | total loss: [1m[32m0.00295[0m[0m | time: 10.762s
[2K
| Adam | epoch: 015 | loss: 0.00295 - acc: 0.9999 -- iter: 0384/1481
[A[ATraining Step: 671  | total loss: [1m[32m0.00575[0m[0m | time: 11.044s
[2K
| Adam | epoch: 015 | loss: 0.00575 - acc: 0.9968 -- iter: 0416/1481
[A[ATraining Step: 672  | total loss: [1m[32m0.00519[0m[0m | time: 11.322s
[2K
| Adam | epoch: 015 | loss: 0.00519 - acc: 0.9971 -- iter: 0448/1481
[A[ATraining Step: 673  | total loss: [1m[32m0.00468[0m[0m | time: 12.176s
[2K
| Adam | epoch: 015 | loss: 0.00468 - acc: 0.9974 -- iter: 0480/1481
[A[ATraining Step: 674  | total loss: [1m[32m0.00441[0m[0m | time: 13.055s
[2K
| Adam | epoch: 015 | loss: 0.00441 - acc: 0.9977 -- iter: 0512/1481
[A[ATraining Step: 675  | total loss: [1m[32m0.00404[0m[0m | time: 13.952s
[2K
| Adam | epoch: 015 | loss: 0.00404 - acc: 0.9979 -- iter: 0544/1481
[A[ATraining Step: 676  | total loss: [1m[32m0.00411[0m[0m | time: 14.871s
[2K
| Adam | epoch: 015 | loss: 0.00411 - acc: 0.9981 -- iter: 0576/1481
[A[ATraining Step: 677  | total loss: [1m[32m0.00447[0m[0m | time: 15.788s
[2K
| Adam | epoch: 015 | loss: 0.00447 - acc: 0.9983 -- iter: 0608/1481
[A[ATraining Step: 678  | total loss: [1m[32m0.00510[0m[0m | time: 16.551s
[2K
| Adam | epoch: 015 | loss: 0.00510 - acc: 0.9985 -- iter: 0640/1481
[A[ATraining Step: 679  | total loss: [1m[32m0.00643[0m[0m | time: 17.641s
[2K
| Adam | epoch: 015 | loss: 0.00643 - acc: 0.9986 -- iter: 0672/1481
[A[ATraining Step: 680  | total loss: [1m[32m0.00605[0m[0m | time: 18.672s
[2K
| Adam | epoch: 015 | loss: 0.00605 - acc: 0.9988 -- iter: 0704/1481
[A[ATraining Step: 681  | total loss: [1m[32m0.00575[0m[0m | time: 19.603s
[2K
| Adam | epoch: 015 | loss: 0.00575 - acc: 0.9989 -- iter: 0736/1481
[A[ATraining Step: 682  | total loss: [1m[32m0.00553[0m[0m | time: 20.391s
[2K
| Adam | epoch: 015 | loss: 0.00553 - acc: 0.9990 -- iter: 0768/1481
[A[ATraining Step: 683  | total loss: [1m[32m0.00505[0m[0m | time: 21.241s
[2K
| Adam | epoch: 015 | loss: 0.00505 - acc: 0.9991 -- iter: 0800/1481
[A[ATraining Step: 684  | total loss: [1m[32m0.00470[0m[0m | time: 22.101s
[2K
| Adam | epoch: 015 | loss: 0.00470 - acc: 0.9992 -- iter: 0832/1481
[A[ATraining Step: 685  | total loss: [1m[32m0.00462[0m[0m | time: 22.970s
[2K
| Adam | epoch: 015 | loss: 0.00462 - acc: 0.9993 -- iter: 0864/1481
[A[ATraining Step: 686  | total loss: [1m[32m0.00429[0m[0m | time: 23.878s
[2K
| Adam | epoch: 015 | loss: 0.00429 - acc: 0.9993 -- iter: 0896/1481
[A[ATraining Step: 687  | total loss: [1m[32m0.01337[0m[0m | time: 24.800s
[2K
| Adam | epoch: 015 | loss: 0.01337 - acc: 0.9900 -- iter: 0928/1481
[A[ATraining Step: 688  | total loss: [1m[32m0.07377[0m[0m | time: 25.691s
[2K
| Adam | epoch: 015 | loss: 0.07377 - acc: 0.9848 -- iter: 0960/1481
[A[ATraining Step: 689  | total loss: [1m[32m0.06668[0m[0m | time: 26.520s
[2K
| Adam | epoch: 015 | loss: 0.06668 - acc: 0.9863 -- iter: 0992/1481
[A[ATraining Step: 690  | total loss: [1m[32m0.06034[0m[0m | time: 27.464s
[2K
| Adam | epoch: 015 | loss: 0.06034 - acc: 0.9877 -- iter: 1024/1481
[A[ATraining Step: 691  | total loss: [1m[32m0.05446[0m[0m | time: 28.539s
[2K
| Adam | epoch: 015 | loss: 0.05446 - acc: 0.9889 -- iter: 1056/1481
[A[ATraining Step: 692  | total loss: [1m[32m0.04963[0m[0m | time: 29.485s
[2K
| Adam | epoch: 015 | loss: 0.04963 - acc: 0.9900 -- iter: 1088/1481
[A[ATraining Step: 693  | total loss: [1m[32m0.04501[0m[0m | time: 30.309s
[2K
| Adam | epoch: 015 | loss: 0.04501 - acc: 0.9910 -- iter: 1120/1481
[A[ATraining Step: 694  | total loss: [1m[32m0.04142[0m[0m | time: 31.184s
[2K
| Adam | epoch: 015 | loss: 0.04142 - acc: 0.9919 -- iter: 1152/1481
[A[ATraining Step: 695  | total loss: [1m[32m0.05426[0m[0m | time: 32.054s
[2K
| Adam | epoch: 015 | loss: 0.05426 - acc: 0.9833 -- iter: 1184/1481
[A[ATraining Step: 696  | total loss: [1m[32m0.04929[0m[0m | time: 32.913s
[2K
| Adam | epoch: 015 | loss: 0.04929 - acc: 0.9850 -- iter: 1216/1481
[A[ATraining Step: 697  | total loss: [1m[32m0.04553[0m[0m | time: 33.867s
[2K
| Adam | epoch: 015 | loss: 0.04553 - acc: 0.9865 -- iter: 1248/1481
[A[ATraining Step: 698  | total loss: [1m[32m0.04179[0m[0m | time: 34.786s
[2K
| Adam | epoch: 015 | loss: 0.04179 - acc: 0.9879 -- iter: 1280/1481
[A[ATraining Step: 699  | total loss: [1m[32m0.03912[0m[0m | time: 35.675s
[2K
| Adam | epoch: 015 | loss: 0.03912 - acc: 0.9891 -- iter: 1312/1481
[A[ATraining Step: 700  | total loss: [1m[32m0.03682[0m[0m | time: 36.532s
[2K
| Adam | epoch: 015 | loss: 0.03682 - acc: 0.9902 -- iter: 1344/1481
[A[ATraining Step: 701  | total loss: [1m[32m0.03663[0m[0m | time: 37.560s
[2K
| Adam | epoch: 015 | loss: 0.03663 - acc: 0.9880 -- iter: 1376/1481
[A[ATraining Step: 702  | total loss: [1m[32m0.03366[0m[0m | time: 38.560s
[2K
| Adam | epoch: 015 | loss: 0.03366 - acc: 0.9892 -- iter: 1408/1481
[A[ATraining Step: 703  | total loss: [1m[32m0.03193[0m[0m | time: 39.481s
[2K
| Adam | epoch: 015 | loss: 0.03193 - acc: 0.9903 -- iter: 1440/1481
[A[ATraining Step: 704  | total loss: [1m[32m0.03125[0m[0m | time: 40.259s
[2K
| Adam | epoch: 015 | loss: 0.03125 - acc: 0.9913 -- iter: 1472/1481
[A[ATraining Step: 705  | total loss: [1m[32m0.02888[0m[0m | time: 43.145s
[2K
| Adam | epoch: 015 | loss: 0.02888 - acc: 0.9921 | val_loss: 0.41966 - val_acc: 0.8772 -- iter: 1481/1481
--
Validation AUC:0.9420575702882236
Validation AUPRC:0.9592936207664378
Test AUC:0.9670200892857144
Test AUPRC:0.9753631345766108
BestTestF1Score	0.92	0.83	0.92	0.92	0.92	221	20	204	19	0.63
BestTestMCCScore	0.9	0.81	0.9	0.97	0.84	201	6	218	39	0.98
BestTestAccuracyScore	0.91	0.83	0.91	0.95	0.88	211	11	213	29	0.91
BestValidationF1Score	0.88	0.77	0.88	0.91	0.86	207	20	203	34	0.63
BestValidationMCC	0.88	0.78	0.88	0.97	0.8	192	5	218	49	0.98
BestValidationAccuracy	0.88	0.78	0.89	0.95	0.82	198	10	213	43	0.91
TestPredictions (Threshold:0.98)
CHEMBL3661549,TP,ACT,1.0	CHEMBL40583,TN,INACT,0.0	CHEMBL215417,TN,INACT,0.009999999776482582	CHEMBL3661529,TP,ACT,1.0	CHEMBL3671153,TP,ACT,1.0	CHEMBL2205390,TN,INACT,0.10000000149011612	CHEMBL3671442,TP,ACT,1.0	CHEMBL3356117,TN,INACT,0.7699999809265137	CHEMBL1241391,TN,INACT,0.0	CHEMBL3661488,TP,ACT,1.0	CHEMBL3676082,TP,ACT,1.0	CHEMBL254690,TP,ACT,0.9900000095367432	CHEMBL3676071,TP,ACT,0.9900000095367432	CHEMBL428647,TN,INACT,0.1599999964237213	CHEMBL76813,TN,INACT,0.0	CHEMBL279481,TN,INACT,0.009999999776482582	CHEMBL3661587,TP,ACT,1.0	CHEMBL77732,TN,INACT,0.03999999910593033	CHEMBL3666245,TP,ACT,1.0	CHEMBL50,TN,INACT,0.0	CHEMBL483081,TN,INACT,0.9599999785423279	CHEMBL3671426,TP,ACT,1.0	CHEMBL3675952,FN,ACT,0.9100000262260437	CHEMBL456996,TP,ACT,0.9900000095367432	CHEMBL2152281,TP,ACT,0.9900000095367432	CHEMBL3678306,TP,ACT,0.9900000095367432	CHEMBL523059,TN,INACT,0.019999999552965164	CHEMBL308134,TN,INACT,0.009999999776482582	CHEMBL316009,FP,INACT,1.0	CHEMBL2029691,TN,INACT,0.009999999776482582	CHEMBL71205,TN,INACT,0.0	CHEMBL497290,TN,INACT,0.0	CHEMBL3673454,TP,ACT,1.0	CHEMBL288817,FN,ACT,0.9599999785423279	CHEMBL211858,FN,ACT,0.5400000214576721	CHEMBL3780971,TP,ACT,1.0	CHEMBL527026,TN,INACT,0.009999999776482582	CHEMBL156555,TN,INACT,0.009999999776482582	CHEMBL457393,TP,ACT,0.9900000095367432	CHEMBL1794056,TP,ACT,1.0	CHEMBL3666277,TP,ACT,1.0	CHEMBL3671367,TP,ACT,1.0	CHEMBL3671451,FN,ACT,0.019999999552965164	CHEMBL1809197,TN,INACT,0.0	CHEMBL498520,TN,INACT,0.019999999552965164	CHEMBL3673461,TP,ACT,1.0	CHEMBL3673458,TP,ACT,1.0	CHEMBL463384,TN,INACT,0.03999999910593033	CHEMBL1242378,TN,INACT,0.0	CHEMBL3676032,TP,ACT,1.0	CHEMBL591440,TN,INACT,0.0	CHEMBL201865,TN,INACT,0.019999999552965164	CHEMBL100312,TN,INACT,0.0	CHEMBL3678283,TP,ACT,1.0	CHEMBL3661497,TP,ACT,1.0	CHEMBL3666280,TP,ACT,1.0	CHEMBL327725,TN,INACT,0.019999999552965164	CHEMBL2283258,TN,INACT,0.8999999761581421	CHEMBL1258913,TP,ACT,1.0	CHEMBL3671393,TP,ACT,1.0	CHEMBL3666404,TP,ACT,1.0	CHEMBL515258,TN,INACT,0.009999999776482582	CHEMBL233958,TN,INACT,0.019999999552965164	CHEMBL253857,FN,ACT,0.5299999713897705	CHEMBL254050,TP,ACT,1.0	CHEMBL1908842,FN,ACT,0.8500000238418579	CHEMBL3671389,TP,ACT,1.0	CHEMBL1095445,TN,INACT,0.0	CHEMBL3661569,TP,ACT,1.0	CHEMBL3639749,TP,ACT,1.0	CHEMBL1081198,TN,INACT,0.17000000178813934	CHEMBL310580,TN,INACT,0.17000000178813934	CHEMBL3661476,TP,ACT,1.0	CHEMBL3676050,TP,ACT,1.0	CHEMBL3639652,TP,ACT,1.0	CHEMBL202831,TN,INACT,0.09000000357627869	CHEMBL561136,TN,INACT,0.0	CHEMBL57553,TN,INACT,0.0	CHEMBL589120,TN,INACT,0.009999999776482582	CHEMBL1222854,FP,INACT,0.9900000095367432	CHEMBL3676080,TP,ACT,1.0	CHEMBL2037213,TP,ACT,1.0	CHEMBL3218000,TN,INACT,0.05000000074505806	CHEMBL245769,TN,INACT,0.0	CHEMBL251796,TP,ACT,1.0	CHEMBL104466,TN,INACT,0.009999999776482582	CHEMBL557525,TN,INACT,0.0	CHEMBL554,TN,INACT,0.019999999552965164	CHEMBL77298,TN,INACT,0.0	CHEMBL3676072,TP,ACT,1.0	CHEMBL467079,TN,INACT,0.0	CHEMBL590568,TN,INACT,0.0	CHEMBL1830266,TN,INACT,0.0	CHEMBL3629604,TN,INACT,0.0	CHEMBL101682,FP,INACT,0.9900000095367432	CHEMBL2086746,TN,INACT,0.0	CHEMBL3661574,TP,ACT,1.0	CHEMBL190201,TN,INACT,0.019999999552965164	CHEMBL1956892,TN,INACT,0.07000000029802322	CHEMBL3675928,TP,ACT,1.0	CHEMBL2047244,TN,INACT,0.0	CHEMBL3666393,TP,ACT,1.0	CHEMBL3661578,TP,ACT,1.0	CHEMBL1956893,TN,INACT,0.0	CHEMBL436817,TN,INACT,0.0	CHEMBL539433,TN,INACT,0.0	CHEMBL3666313,TP,ACT,1.0	CHEMBL316239,FP,INACT,1.0	CHEMBL404561,TP,ACT,1.0	CHEMBL570313,TN,INACT,0.0	CHEMBL3661570,TP,ACT,1.0	CHEMBL440213,TN,INACT,0.029999999329447746	CHEMBL486302,TN,INACT,0.0	CHEMBL144785,TN,INACT,0.009999999776482582	CHEMBL3666268,TP,ACT,1.0	CHEMBL1242756,TN,INACT,0.0	CHEMBL3671155,TP,ACT,1.0	CHEMBL291985,FN,ACT,0.9399999976158142	CHEMBL556874,TN,INACT,0.0	CHEMBL3671129,TP,ACT,1.0	CHEMBL3661567,TP,ACT,1.0	CHEMBL542887,TN,INACT,0.009999999776482582	CHEMBL2163624,TN,INACT,0.0	CHEMBL3582438,TP,ACT,1.0	CHEMBL3237855,TN,INACT,0.009999999776482582	CHEMBL337253,TN,INACT,0.0	CHEMBL3661580,TP,ACT,1.0	CHEMBL516142,TP,ACT,0.9900000095367432	CHEMBL3666344,TP,ACT,1.0	CHEMBL3675914,TP,ACT,1.0	CHEMBL211328,TP,ACT,1.0	CHEMBL89723,TN,INACT,0.0	CHEMBL2382017,TN,INACT,0.550000011920929	CHEMBL3678288,TP,ACT,0.9800000190734863	CHEMBL210933,TP,ACT,1.0	CHEMBL3673452,TP,ACT,1.0	CHEMBL3671462,TP,ACT,1.0	CHEMBL216646,TN,INACT,0.0	CHEMBL3666449,TP,ACT,1.0	CHEMBL414013,TN,INACT,0.009999999776482582	CHEMBL3666263,TP,ACT,1.0	CHEMBL3666337,TP,ACT,1.0	CHEMBL1171638,TN,INACT,0.0	CHEMBL1642298,TN,INACT,0.0	CHEMBL3596859,TP,ACT,1.0	CHEMBL3661462,TP,ACT,1.0	CHEMBL1945444,TN,INACT,0.0	CHEMBL3675942,TP,ACT,1.0	CHEMBL3781538,TN,INACT,0.009999999776482582	CHEMBL1958316,TN,INACT,0.0	CHEMBL3673465,TP,ACT,1.0	CHEMBL592240,TN,INACT,0.0	CHEMBL291986,TN,INACT,0.0	CHEMBL592224,TN,INACT,0.0	CHEMBL3675963,TP,ACT,1.0	CHEMBL3666398,TP,ACT,1.0	CHEMBL1990583,FN,ACT,0.49000000953674316	CHEMBL3666377,TP,ACT,1.0	CHEMBL1684370,TN,INACT,0.03999999910593033	CHEMBL388978,FN,ACT,0.029999999329447746	CHEMBL3676053,TP,ACT,1.0	CHEMBL3661480,TP,ACT,1.0	CHEMBL1908395,FN,ACT,0.05999999865889549	CHEMBL1821889,TN,INACT,0.009999999776482582	CHEMBL3673455,TP,ACT,1.0	CHEMBL3408947,FN,ACT,0.23999999463558197	CHEMBL343050,TN,INACT,0.009999999776482582	CHEMBL71,TN,INACT,0.009999999776482582	CHEMBL3666357,TP,ACT,1.0	CHEMBL2042136,TN,INACT,0.009999999776482582	CHEMBL2346665,TN,INACT,0.0	CHEMBL56671,TN,INACT,0.10000000149011612	CHEMBL3676049,TP,ACT,1.0	CHEMBL1241859,TN,INACT,0.0	CHEMBL2348165,TN,INACT,0.019999999552965164	CHEMBL3666345,TP,ACT,1.0	CHEMBL557238,TN,INACT,0.0	CHEMBL3676027,TP,ACT,1.0	CHEMBL240093,TN,INACT,0.0	CHEMBL3666438,TP,ACT,1.0	CHEMBL3661598,TP,ACT,1.0	CHEMBL456796,TN,INACT,0.009999999776482582	CHEMBL511451,TN,INACT,0.009999999776482582	CHEMBL3298269,FN,ACT,0.25	CHEMBL2088258,TN,INACT,0.38999998569488525	CHEMBL557050,TN,INACT,0.0	CHEMBL8095,TN,INACT,0.18000000715255737	CHEMBL3133826,TN,INACT,0.0	CHEMBL3671461,TP,ACT,1.0	CHEMBL77261,TN,INACT,0.15000000596046448	CHEMBL55994,TN,INACT,0.0	CHEMBL3676023,FN,ACT,0.9300000071525574	CHEMBL3671405,TP,ACT,1.0	CHEMBL457608,TP,ACT,0.9900000095367432	CHEMBL430845,TN,INACT,0.019999999552965164	CHEMBL3666376,TP,ACT,1.0	CHEMBL3671137,TP,ACT,1.0	CHEMBL2151323,TP,ACT,1.0	CHEMBL1956888,TN,INACT,0.0	CHEMBL3666373,TP,ACT,1.0	CHEMBL3661564,TP,ACT,1.0	CHEMBL3666356,TP,ACT,1.0	CHEMBL456976,TP,ACT,1.0	CHEMBL318485,TN,INACT,0.0	CHEMBL3676066,TP,ACT,1.0	CHEMBL3686123,FN,ACT,0.0	CHEMBL2152269,TP,ACT,1.0	CHEMBL3666459,TP,ACT,1.0	CHEMBL306929,TN,INACT,0.0	CHEMBL173478,TN,INACT,0.019999999552965164	CHEMBL3671386,TP,ACT,1.0	CHEMBL150,TN,INACT,0.0	CHEMBL457180,TN,INACT,0.0	CHEMBL3661560,TP,ACT,1.0	CHEMBL1828883,TN,INACT,0.0	CHEMBL3675973,TP,ACT,1.0	CHEMBL3661605,TP,ACT,1.0	CHEMBL3661581,TP,ACT,1.0	CHEMBL573578,TN,INACT,0.0	CHEMBL3661532,TP,ACT,1.0	CHEMBL208881,TP,ACT,1.0	CHEMBL3659508,TP,ACT,0.9800000190734863	CHEMBL254688,TP,ACT,0.9900000095367432	CHEMBL3666389,TP,ACT,1.0	CHEMBL522011,TN,INACT,0.0	CHEMBL3676091,TP,ACT,1.0	CHEMBL3596879,FN,ACT,0.8799999952316284	CHEMBL1668416,TN,INACT,0.0	CHEMBL589165,TN,INACT,0.009999999776482582	CHEMBL576982,FN,ACT,0.6800000071525574	CHEMBL132948,TN,INACT,0.0	CHEMBL427901,TP,ACT,1.0	CHEMBL604748,TN,INACT,0.0	CHEMBL1940253,TP,ACT,1.0	CHEMBL70360,TN,INACT,0.009999999776482582	CHEMBL3666249,TP,ACT,1.0	CHEMBL1082940,TN,INACT,0.7900000214576721	CHEMBL3678285,FN,ACT,0.9399999976158142	CHEMBL398243,TN,INACT,0.009999999776482582	CHEMBL3671145,TP,ACT,1.0	CHEMBL3666264,TP,ACT,1.0	CHEMBL478488,TN,INACT,0.0	CHEMBL3661484,TP,ACT,1.0	CHEMBL3666364,TP,ACT,1.0	CHEMBL208331,TN,INACT,0.0	CHEMBL1929314,TN,INACT,0.009999999776482582	CHEMBL3678298,TP,ACT,1.0	CHEMBL515822,TP,ACT,0.9900000095367432	CHEMBL1683951,TN,INACT,0.009999999776482582	CHEMBL31184,TN,INACT,0.0	CHEMBL3671471,TP,ACT,1.0	CHEMBL3671403,TP,ACT,1.0	CHEMBL3666408,FN,ACT,0.009999999776482582	CHEMBL3666300,TP,ACT,1.0	CHEMBL254893,TP,ACT,0.9900000095367432	CHEMBL1933736,TN,INACT,0.03999999910593033	CHEMBL3666339,TP,ACT,1.0	CHEMBL3676046,TP,ACT,1.0	CHEMBL312078,TN,INACT,0.009999999776482582	CHEMBL3661492,TP,ACT,1.0	CHEMBL3671446,TP,ACT,1.0	CHEMBL3661617,TP,ACT,1.0	CHEMBL3582431,FN,ACT,0.009999999776482582	CHEMBL123046,TN,INACT,0.0	CHEMBL3666270,TP,ACT,1.0	CHEMBL3686124,FN,ACT,0.8199999928474426	CHEMBL3666253,TP,ACT,1.0	CHEMBL3648042,FP,INACT,0.9900000095367432	CHEMBL115519,TN,INACT,0.0	CHEMBL3671138,TP,ACT,1.0	CHEMBL3691660,TN,INACT,0.019999999552965164	CHEMBL2437484,TN,INACT,0.019999999552965164	CHEMBL256835,TN,INACT,0.0	CHEMBL3658032,TN,INACT,0.009999999776482582	CHEMBL3666283,TP,ACT,1.0	CHEMBL520515,TN,INACT,0.0	CHEMBL1254199,TN,INACT,0.0	CHEMBL3629605,TN,INACT,0.0	CHEMBL3666429,TP,ACT,1.0	CHEMBL1831216,TN,INACT,0.0	CHEMBL2372113,TN,INACT,0.029999999329447746	CHEMBL103667,FN,ACT,0.0	CHEMBL1791367,TN,INACT,0.009999999776482582	CHEMBL2152287,TP,ACT,1.0	CHEMBL3666302,TP,ACT,1.0	CHEMBL322464,TN,INACT,0.0	CHEMBL3673443,TP,ACT,1.0	CHEMBL1940251,TP,ACT,1.0	CHEMBL3676007,TP,ACT,1.0	CHEMBL287306,TN,INACT,0.019999999552965164	CHEMBL3675940,TP,ACT,1.0	CHEMBL339077,TN,INACT,0.0	CHEMBL3666387,TP,ACT,1.0	CHEMBL23254,FN,ACT,0.4099999964237213	CHEMBL3666420,TP,ACT,1.0	CHEMBL3671472,TP,ACT,1.0	CHEMBL3676092,TP,ACT,1.0	CHEMBL90277,TN,INACT,0.0	CHEMBL3671421,TP,ACT,1.0	CHEMBL2064388,TN,INACT,0.0	CHEMBL524820,TN,INACT,0.0	CHEMBL2029693,TN,INACT,0.03999999910593033	CHEMBL254060,TP,ACT,1.0	CHEMBL1829273,TN,INACT,0.0	CHEMBL2062563,TN,INACT,0.009999999776482582	CHEMBL3676067,TP,ACT,1.0	CHEMBL3671135,TP,ACT,1.0	CHEMBL1910756,TN,INACT,0.009999999776482582	CHEMBL3639702,TP,ACT,1.0	CHEMBL3666303,TP,ACT,1.0	CHEMBL2437477,TN,INACT,0.0	CHEMBL1933755,TN,INACT,0.009999999776482582	CHEMBL3661542,TP,ACT,1.0	CHEMBL3781939,TN,INACT,0.009999999776482582	CHEMBL3678294,TP,ACT,0.9800000190734863	CHEMBL281957,TN,INACT,0.9300000071525574	CHEMBL2037214,FN,ACT,0.7900000214576721	CHEMBL1253945,TN,INACT,0.0	CHEMBL2152270,TP,ACT,1.0	CHEMBL3706656,TN,INACT,0.14000000059604645	CHEMBL281948,FN,ACT,0.9300000071525574	CHEMBL3358993,TN,INACT,0.6000000238418579	CHEMBL3673482,TP,ACT,1.0	CHEMBL483108,TN,INACT,0.0	CHEMBL70942,TN,INACT,0.0	CHEMBL381932,TN,INACT,0.0	CHEMBL3676075,TP,ACT,0.9900000095367432	CHEMBL1828876,TN,INACT,0.019999999552965164	CHEMBL414001,FN,ACT,0.8299999833106995	CHEMBL495758,TN,INACT,0.0	CHEMBL3666276,TP,ACT,1.0	CHEMBL131944,TN,INACT,0.05999999865889549	CHEMBL209506,FN,ACT,0.9100000262260437	CHEMBL3671394,TP,ACT,1.0	CHEMBL1080271,TN,INACT,0.03999999910593033	CHEMBL498705,TN,INACT,0.4699999988079071	CHEMBL3218001,FP,INACT,0.9800000190734863	CHEMBL1172877,TN,INACT,0.0	CHEMBL3666246,TP,ACT,1.0	CHEMBL3671388,TP,ACT,1.0	CHEMBL3675964,FN,ACT,0.9300000071525574	CHEMBL513953,TP,ACT,0.9900000095367432	CHEMBL521734,TN,INACT,0.8999999761581421	CHEMBL3666396,TP,ACT,1.0	CHEMBL3671433,TP,ACT,1.0	CHEMBL141238,TN,INACT,0.8899999856948853	CHEMBL3675988,TP,ACT,1.0	CHEMBL460990,TP,ACT,1.0	CHEMBL53885,TP,ACT,0.9900000095367432	CHEMBL279035,TN,INACT,0.0	CHEMBL3358984,TN,INACT,0.009999999776482582	CHEMBL3421963,TN,INACT,0.009999999776482582	CHEMBL3666461,TP,ACT,1.0	CHEMBL1738705,TN,INACT,0.8299999833106995	CHEMBL1668413,TN,INACT,0.0	CHEMBL558601,TN,INACT,0.0	CHEMBL1242661,TN,INACT,0.8299999833106995	CHEMBL1910278,TN,INACT,0.009999999776482582	CHEMBL1821881,TN,INACT,0.019999999552965164	CHEMBL589832,TN,INACT,0.4300000071525574	CHEMBL3666383,TP,ACT,1.0	CHEMBL3298162,FN,ACT,0.03999999910593033	CHEMBL498130,TN,INACT,0.029999999329447746	CHEMBL486285,TN,INACT,0.9700000286102295	CHEMBL514571,TP,ACT,0.9900000095367432	CHEMBL1944931,TN,INACT,0.8100000023841858	CHEMBL518051,FN,ACT,0.8399999737739563	CHEMBL3639748,TP,ACT,1.0	CHEMBL3678290,FN,ACT,0.17000000178813934	CHEMBL246356,TN,INACT,0.009999999776482582	CHEMBL3671401,TP,ACT,1.0	CHEMBL77070,TN,INACT,0.009999999776482582	CHEMBL1929555,TN,INACT,0.14000000059604645	CHEMBL3678287,FN,ACT,0.9200000166893005	CHEMBL3661599,TP,ACT,1.0	CHEMBL3421636,TN,INACT,0.6200000047683716	CHEMBL522760,TN,INACT,0.0	CHEMBL3671385,TP,ACT,1.0	CHEMBL3661522,TP,ACT,1.0	CHEMBL1093099,TN,INACT,0.18000000715255737	CHEMBL89040,TN,INACT,0.0	CHEMBL459729,TN,INACT,0.019999999552965164	CHEMBL3673462,TP,ACT,1.0	CHEMBL377444,TP,ACT,1.0	CHEMBL55742,TN,INACT,0.3700000047683716	CHEMBL3596876,TP,ACT,0.9800000190734863	CHEMBL517154,TN,INACT,0.15000000596046448	CHEMBL313746,TN,INACT,0.0	CHEMBL3661471,TP,ACT,1.0	CHEMBL169757,TN,INACT,0.0	CHEMBL3671435,TP,ACT,1.0	CHEMBL3661612,FN,ACT,0.0	CHEMBL3671464,TP,ACT,1.0	CHEMBL3675990,TP,ACT,1.0	CHEMBL1642269,TN,INACT,0.3799999952316284	CHEMBL279003,TN,INACT,0.029999999329447746	CHEMBL69358,TN,INACT,0.0	CHEMBL456760,TN,INACT,0.15000000596046448	CHEMBL1933729,TN,INACT,0.029999999329447746	CHEMBL1242665,TN,INACT,0.009999999776482582	CHEMBL3666462,TP,ACT,1.0	CHEMBL456964,TN,INACT,0.009999999776482582	CHEMBL1094475,TN,INACT,0.0	CHEMBL1084863,TN,INACT,0.0	CHEMBL1301731,TN,INACT,0.0	CHEMBL2163623,TN,INACT,0.009999999776482582	CHEMBL3671400,TP,ACT,1.0	CHEMBL3666401,TP,ACT,1.0	CHEMBL1173398,TN,INACT,0.0	CHEMBL2348176,TN,INACT,0.009999999776482582	CHEMBL3671415,TP,ACT,1.0	CHEMBL99779,TN,INACT,0.8199999928474426	CHEMBL1172697,TN,INACT,0.019999999552965164	CHEMBL314021,TN,INACT,0.009999999776482582	CHEMBL87325,TN,INACT,0.0	CHEMBL3666307,TP,ACT,1.0	CHEMBL3676074,FN,ACT,0.6399999856948853	CHEMBL456153,FN,ACT,0.029999999329447746	CHEMBL3298163,FN,ACT,0.9200000166893005	CHEMBL3661489,TP,ACT,1.0	CHEMBL3745929,TN,INACT,0.9700000286102295	CHEMBL3666297,TP,ACT,1.0	CHEMBL3678305,FN,ACT,0.8700000047683716	CHEMBL3666267,TP,ACT,1.0	CHEMBL450383,TN,INACT,0.0	CHEMBL485320,TN,INACT,0.0	CHEMBL487737,TN,INACT,0.10000000149011612	CHEMBL3661582,TP,ACT,1.0	CHEMBL3678286,TP,ACT,1.0	CHEMBL490053,TN,INACT,0.0	CHEMBL1276446,FN,ACT,0.7599999904632568	CHEMBL3675912,TP,ACT,1.0	CHEMBL3586678,FN,ACT,0.009999999776482582	CHEMBL3661540,TP,ACT,1.0	CHEMBL3666437,TP,ACT,1.0	CHEMBL3666256,TP,ACT,1.0	CHEMBL3676068,TP,ACT,1.0	CHEMBL3666319,TP,ACT,1.0	CHEMBL1077095,TN,INACT,0.25	CHEMBL3676078,TP,ACT,1.0	CHEMBL3671423,TP,ACT,1.0	CHEMBL3671377,TP,ACT,1.0	CHEMBL2348170,TN,INACT,0.009999999776482582	CHEMBL1270331,TN,INACT,0.0	CHEMBL3676033,TP,ACT,1.0	CHEMBL3666380,TP,ACT,1.0	CHEMBL3116050,FN,ACT,0.0	CHEMBL2348180,TN,INACT,0.009999999776482582	CHEMBL3661616,TP,ACT,1.0	CHEMBL1241583,TN,INACT,0.0	CHEMBL603494,TN,INACT,0.019999999552965164	CHEMBL3596862,TP,ACT,1.0	CHEMBL1806525,TN,INACT,0.0	CHEMBL3671450,TP,ACT,1.0	CHEMBL3675978,TP,ACT,1.0	CHEMBL3675976,TP,ACT,1.0	CHEMBL56964,TN,INACT,0.009999999776482582	CHEMBL466496,TN,INACT,0.0	CHEMBL3673441,TP,ACT,1.0	CHEMBL99699,TN,INACT,0.03999999910593033	CHEMBL77085,TN,INACT,0.019999999552965164	CHEMBL499587,TN,INACT,0.9700000286102295	CHEMBL2011302,TN,INACT,0.0	CHEMBL3666257,TP,ACT,1.0	

