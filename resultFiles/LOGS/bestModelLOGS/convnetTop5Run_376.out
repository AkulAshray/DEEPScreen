ImageNetInceptionV2 CHEMBL4781 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	149
Number of inactive compounds :	149
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4781_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4781_adam_0.0005_15_0.6/
---------------------------------
Training samples: 188
Validation samples: 59
--
Training Step: 1  | time: 418.210s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/188
[A[ATraining Step: 2  | total loss: [1m[32m0.77664[0m[0m | time: 646.846s
[2K
| Adam | epoch: 001 | loss: 0.77664 - acc: 0.3375 -- iter: 064/188
[A[ATraining Step: 3  | total loss: [1m[32m0.82646[0m[0m | time: 1052.068s
[2K
| Adam | epoch: 001 | loss: 0.82646 - acc: 0.5472 -- iter: 096/188
[A[ATraining Step: 4  | total loss: [1m[32m0.64550[0m[0m | time: 1563.162s
[2K
| Adam | epoch: 001 | loss: 0.64550 - acc: 0.6759 -- iter: 128/188
[A[ATraining Step: 5  | total loss: [1m[32m0.57649[0m[0m | time: 2016.845s
[2K
| Adam | epoch: 001 | loss: 0.57649 - acc: 0.7056 -- iter: 160/188
[A[ATraining Step: 6  | total loss: [1m[32m0.48178[0m[0m | time: 2328.850s
[2K
| Adam | epoch: 001 | loss: 0.48178 - acc: 0.7944 | val_loss: 2.21169 - val_acc: 0.4746 -- iter: 188/188
--
Training Step: 7  | total loss: [1m[32m0.34749[0m[0m | time: 77.094s
[2K
| Adam | epoch: 002 | loss: 0.34749 - acc: 0.8749 -- iter: 032/188
[A[ATraining Step: 8  | total loss: [1m[32m0.19571[0m[0m | time: 745.341s
[2K
| Adam | epoch: 002 | loss: 0.19571 - acc: 0.9453 -- iter: 064/188
[A[ATraining Step: 9  | total loss: [1m[32m0.29251[0m[0m | time: 846.081s
[2K
| Adam | epoch: 002 | loss: 0.29251 - acc: 0.9081 -- iter: 096/188
[A[ATraining Step: 10  | total loss: [1m[32m0.36990[0m[0m | time: 1108.052s
[2K
| Adam | epoch: 002 | loss: 0.36990 - acc: 0.8915 -- iter: 128/188
[A[ATraining Step: 11  | total loss: [1m[32m0.23458[0m[0m | time: 1202.783s
[2K
| Adam | epoch: 002 | loss: 0.23458 - acc: 0.9429 -- iter: 160/188
[A[ATraining Step: 12  | total loss: [1m[32m0.37470[0m[0m | time: 1388.512s
[2K
| Adam | epoch: 002 | loss: 0.37470 - acc: 0.8983 | val_loss: 4.42639 - val_acc: 0.4746 -- iter: 188/188
--
Training Step: 13  | total loss: [1m[32m0.26888[0m[0m | time: 16.293s
[2K
| Adam | epoch: 003 | loss: 0.26888 - acc: 0.9151 -- iter: 032/188
[A[ATraining Step: 14  | total loss: [1m[32m0.20643[0m[0m | time: 137.426s
[2K
| Adam | epoch: 003 | loss: 0.20643 - acc: 0.9206 -- iter: 064/188
[A[ATraining Step: 15  | total loss: [1m[32m0.14991[0m[0m | time: 338.921s
[2K
| Adam | epoch: 003 | loss: 0.14991 - acc: 0.9517 -- iter: 096/188
[A[ATraining Step: 16  | total loss: [1m[32m0.13960[0m[0m | time: 368.961s
[2K
| Adam | epoch: 003 | loss: 0.13960 - acc: 0.9581 -- iter: 128/188
[A[ATraining Step: 17  | total loss: [1m[32m0.23282[0m[0m | time: 466.376s
[2K
| Adam | epoch: 003 | loss: 0.23282 - acc: 0.9394 -- iter: 160/188
[A[ATraining Step: 18  | total loss: [1m[32m0.17789[0m[0m | time: 507.684s
[2K
| Adam | epoch: 003 | loss: 0.17789 - acc: 0.9496 | val_loss: 4.78270 - val_acc: 0.4746 -- iter: 188/188
--
Training Step: 19  | total loss: [1m[32m0.13591[0m[0m | time: 295.659s
[2K
| Adam | epoch: 004 | loss: 0.13591 - acc: 0.9664 -- iter: 032/188
[A[ATraining Step: 20  | total loss: [1m[32m0.10107[0m[0m | time: 307.681s
[2K
| Adam | epoch: 004 | loss: 0.10107 - acc: 0.9772 -- iter: 064/188
[A[ATraining Step: 21  | total loss: [1m[32m0.07933[0m[0m | time: 329.699s
[2K
| Adam | epoch: 004 | loss: 0.07933 - acc: 0.9843 -- iter: 096/188
[A[ATraining Step: 22  | total loss: [1m[32m0.06044[0m[0m | time: 509.915s
[2K
| Adam | epoch: 004 | loss: 0.06044 - acc: 0.9890 -- iter: 128/188
[A[ATraining Step: 23  | total loss: [1m[32m0.05335[0m[0m | time: 622.233s
[2K
| Adam | epoch: 004 | loss: 0.05335 - acc: 0.9922 -- iter: 160/188
[A[ATraining Step: 24  | total loss: [1m[32m0.05017[0m[0m | time: 821.094s
[2K
| Adam | epoch: 004 | loss: 0.05017 - acc: 0.9856 | val_loss: 6.11225 - val_acc: 0.4746 -- iter: 188/188
--
Training Step: 25  | total loss: [1m[32m0.04815[0m[0m | time: 299.541s
[2K
| Adam | epoch: 005 | loss: 0.04815 - acc: 0.9895 -- iter: 032/188
[A[ATraining Step: 26  | total loss: [1m[32m0.03656[0m[0m | time: 494.044s
[2K
| Adam | epoch: 005 | loss: 0.03656 - acc: 0.9923 -- iter: 064/188
[A[ATraining Step: 27  | total loss: [1m[32m0.02969[0m[0m | time: 506.087s
[2K
| Adam | epoch: 005 | loss: 0.02969 - acc: 0.9943 -- iter: 096/188
[A[ATraining Step: 28  | total loss: [1m[32m0.02566[0m[0m | time: 518.374s
[2K
| Adam | epoch: 005 | loss: 0.02566 - acc: 0.9957 -- iter: 128/188
[A[ATraining Step: 29  | total loss: [1m[32m0.02072[0m[0m | time: 674.472s
[2K
| Adam | epoch: 005 | loss: 0.02072 - acc: 0.9968 -- iter: 160/188
[A[ATraining Step: 30  | total loss: [1m[32m0.01655[0m[0m | time: 790.781s
[2K
| Adam | epoch: 005 | loss: 0.01655 - acc: 0.9975 | val_loss: 5.47415 - val_acc: 0.4746 -- iter: 188/188
--
Training Step: 31  | total loss: [1m[32m0.02565[0m[0m | time: 166.448s
[2K
| Adam | epoch: 006 | loss: 0.02565 - acc: 0.9981 -- iter: 032/188
[A[ATraining Step: 32  | total loss: [1m[32m0.02360[0m[0m | time: 178.512s
[2K
| Adam | epoch: 006 | loss: 0.02360 - acc: 0.9985 -- iter: 064/188
[A[ATraining Step: 33  | total loss: [1m[32m0.01909[0m[0m | time: 190.817s
[2K
| Adam | epoch: 006 | loss: 0.01909 - acc: 0.9988 -- iter: 096/188
[A[ATraining Step: 34  | total loss: [1m[32m0.01572[0m[0m | time: 201.748s
[2K
| Adam | epoch: 006 | loss: 0.01572 - acc: 0.9991 -- iter: 128/188
[A[ATraining Step: 35  | total loss: [1m[32m0.01263[0m[0m | time: 212.588s
[2K
| Adam | epoch: 006 | loss: 0.01263 - acc: 0.9993 -- iter: 160/188
[A[ATraining Step: 36  | total loss: [1m[32m0.01026[0m[0m | time: 228.719s
[2K
| Adam | epoch: 006 | loss: 0.01026 - acc: 0.9994 | val_loss: 3.02119 - val_acc: 0.4746 -- iter: 188/188
--
Training Step: 37  | total loss: [1m[32m0.01718[0m[0m | time: 12.930s
[2K
| Adam | epoch: 007 | loss: 0.01718 - acc: 0.9995 -- iter: 032/188
[A[ATraining Step: 38  | total loss: [1m[32m0.10556[0m[0m | time: 26.392s
[2K
| Adam | epoch: 007 | loss: 0.10556 - acc: 0.9874 -- iter: 064/188
[A[ATraining Step: 39  | total loss: [1m[32m0.08872[0m[0m | time: 34.772s
[2K
| Adam | epoch: 007 | loss: 0.08872 - acc: 0.9898 -- iter: 096/188
[A[ATraining Step: 40  | total loss: [1m[32m0.07825[0m[0m | time: 43.406s
[2K
| Adam | epoch: 007 | loss: 0.07825 - acc: 0.9859 -- iter: 128/188
[A[ATraining Step: 41  | total loss: [1m[32m0.06998[0m[0m | time: 50.989s
[2K
| Adam | epoch: 007 | loss: 0.06998 - acc: 0.9885 -- iter: 160/188
[A[ATraining Step: 42  | total loss: [1m[32m0.07505[0m[0m | time: 62.686s
[2K
| Adam | epoch: 007 | loss: 0.07505 - acc: 0.9841 | val_loss: 0.66081 - val_acc: 0.6441 -- iter: 188/188
--
Training Step: 43  | total loss: [1m[32m0.06443[0m[0m | time: 12.215s
[2K
| Adam | epoch: 008 | loss: 0.06443 - acc: 0.9869 -- iter: 032/188
[A[ATraining Step: 44  | total loss: [1m[32m0.06861[0m[0m | time: 24.352s
[2K
| Adam | epoch: 008 | loss: 0.06861 - acc: 0.9838 -- iter: 064/188
[A[ATraining Step: 45  | total loss: [1m[32m0.05788[0m[0m | time: 36.847s
[2K
| Adam | epoch: 008 | loss: 0.05788 - acc: 0.9865 -- iter: 096/188
[A[ATraining Step: 46  | total loss: [1m[32m0.04966[0m[0m | time: 49.802s
[2K
| Adam | epoch: 008 | loss: 0.04966 - acc: 0.9888 -- iter: 128/188
[A[ATraining Step: 47  | total loss: [1m[32m0.05462[0m[0m | time: 61.730s
[2K
| Adam | epoch: 008 | loss: 0.05462 - acc: 0.9855 -- iter: 160/188
[A[ATraining Step: 48  | total loss: [1m[32m0.05429[0m[0m | time: 77.157s
[2K
| Adam | epoch: 008 | loss: 0.05429 - acc: 0.9778 | val_loss: 0.83208 - val_acc: 0.7797 -- iter: 188/188
--
Training Step: 49  | total loss: [1m[32m0.04693[0m[0m | time: 10.875s
[2K
| Adam | epoch: 009 | loss: 0.04693 - acc: 0.9813 -- iter: 032/188
[A[ATraining Step: 50  | total loss: [1m[32m0.04104[0m[0m | time: 22.878s
[2K
| Adam | epoch: 009 | loss: 0.04104 - acc: 0.9842 -- iter: 064/188
[A[ATraining Step: 51  | total loss: [1m[32m0.03930[0m[0m | time: 34.781s
[2K
| Adam | epoch: 009 | loss: 0.03930 - acc: 0.9866 -- iter: 096/188
[A[ATraining Step: 52  | total loss: [1m[32m0.03933[0m[0m | time: 46.969s
[2K
| Adam | epoch: 009 | loss: 0.03933 - acc: 0.9886 -- iter: 128/188
[A[ATraining Step: 53  | total loss: [1m[32m0.04409[0m[0m | time: 59.194s
[2K
| Adam | epoch: 009 | loss: 0.04409 - acc: 0.9857 -- iter: 160/188
[A[ATraining Step: 54  | total loss: [1m[32m0.05534[0m[0m | time: 75.297s
[2K
| Adam | epoch: 009 | loss: 0.05534 - acc: 0.9832 | val_loss: 0.53960 - val_acc: 0.8814 -- iter: 188/188
--
Training Step: 55  | total loss: [1m[32m0.05133[0m[0m | time: 8.568s
[2K
| Adam | epoch: 010 | loss: 0.05133 - acc: 0.9856 -- iter: 032/188
[A[ATraining Step: 56  | total loss: [1m[32m0.04731[0m[0m | time: 19.663s
[2K
| Adam | epoch: 010 | loss: 0.04731 - acc: 0.9876 -- iter: 064/188
[A[ATraining Step: 57  | total loss: [1m[32m0.04201[0m[0m | time: 31.670s
[2K
| Adam | epoch: 010 | loss: 0.04201 - acc: 0.9894 -- iter: 096/188
[A[ATraining Step: 58  | total loss: [1m[32m0.05334[0m[0m | time: 43.884s
[2K
| Adam | epoch: 010 | loss: 0.05334 - acc: 0.9780 -- iter: 128/188
[A[ATraining Step: 59  | total loss: [1m[32m0.11562[0m[0m | time: 55.885s
[2K
| Adam | epoch: 010 | loss: 0.11562 - acc: 0.9726 -- iter: 160/188
[A[ATraining Step: 60  | total loss: [1m[32m0.10090[0m[0m | time: 72.589s
[2K
| Adam | epoch: 010 | loss: 0.10090 - acc: 0.9762 | val_loss: 0.15396 - val_acc: 0.9322 -- iter: 188/188
--
Training Step: 61  | total loss: [1m[32m0.09419[0m[0m | time: 12.132s
[2K
| Adam | epoch: 011 | loss: 0.09419 - acc: 0.9752 -- iter: 032/188
[A[ATraining Step: 62  | total loss: [1m[32m0.08351[0m[0m | time: 23.102s
[2K
| Adam | epoch: 011 | loss: 0.08351 - acc: 0.9784 -- iter: 064/188
[A[ATraining Step: 63  | total loss: [1m[32m0.08289[0m[0m | time: 34.119s
[2K
| Adam | epoch: 011 | loss: 0.08289 - acc: 0.9766 -- iter: 096/188
[A[ATraining Step: 64  | total loss: [1m[32m0.07450[0m[0m | time: 46.199s
[2K
| Adam | epoch: 011 | loss: 0.07450 - acc: 0.9795 -- iter: 128/188
[A[ATraining Step: 65  | total loss: [1m[32m0.08343[0m[0m | time: 58.864s
[2K
| Adam | epoch: 011 | loss: 0.08343 - acc: 0.9782 -- iter: 160/188
[A[ATraining Step: 66  | total loss: [1m[32m0.07434[0m[0m | time: 75.488s
[2K
| Adam | epoch: 011 | loss: 0.07434 - acc: 0.9809 | val_loss: 0.14144 - val_acc: 0.9492 -- iter: 188/188
--
Training Step: 67  | total loss: [1m[32m0.06639[0m[0m | time: 13.261s
[2K
| Adam | epoch: 012 | loss: 0.06639 - acc: 0.9832 -- iter: 032/188
[A[ATraining Step: 68  | total loss: [1m[32m0.05913[0m[0m | time: 22.261s
[2K
| Adam | epoch: 012 | loss: 0.05913 - acc: 0.9852 -- iter: 064/188
[A[ATraining Step: 69  | total loss: [1m[32m0.05344[0m[0m | time: 29.790s
[2K
| Adam | epoch: 012 | loss: 0.05344 - acc: 0.9869 -- iter: 096/188
[A[ATraining Step: 70  | total loss: [1m[32m0.04929[0m[0m | time: 37.487s
[2K
| Adam | epoch: 012 | loss: 0.04929 - acc: 0.9884 -- iter: 128/188
[A[ATraining Step: 71  | total loss: [1m[32m0.04525[0m[0m | time: 45.665s
[2K
| Adam | epoch: 012 | loss: 0.04525 - acc: 0.9897 -- iter: 160/188
[A[ATraining Step: 72  | total loss: [1m[32m0.04304[0m[0m | time: 60.297s
[2K
| Adam | epoch: 012 | loss: 0.04304 - acc: 0.9909 | val_loss: 0.20480 - val_acc: 0.9492 -- iter: 188/188
--
Training Step: 73  | total loss: [1m[32m0.07434[0m[0m | time: 12.253s
[2K
| Adam | epoch: 013 | loss: 0.07434 - acc: 0.9884 -- iter: 032/188
[A[ATraining Step: 74  | total loss: [1m[32m0.06637[0m[0m | time: 24.089s
[2K
| Adam | epoch: 013 | loss: 0.06637 - acc: 0.9897 -- iter: 064/188
[A[ATraining Step: 75  | total loss: [1m[32m0.06216[0m[0m | time: 36.403s
[2K
| Adam | epoch: 013 | loss: 0.06216 - acc: 0.9908 -- iter: 096/188
[A[ATraining Step: 76  | total loss: [1m[32m0.06251[0m[0m | time: 47.678s
[2K
| Adam | epoch: 013 | loss: 0.06251 - acc: 0.9884 -- iter: 128/188
[A[ATraining Step: 77  | total loss: [1m[32m0.05724[0m[0m | time: 58.648s
[2K
| Adam | epoch: 013 | loss: 0.05724 - acc: 0.9897 -- iter: 160/188
[A[ATraining Step: 78  | total loss: [1m[32m0.05241[0m[0m | time: 74.915s
[2K
| Adam | epoch: 013 | loss: 0.05241 - acc: 0.9908 | val_loss: 0.41136 - val_acc: 0.8475 -- iter: 188/188
--
Training Step: 79  | total loss: [1m[32m0.05019[0m[0m | time: 12.002s
[2K
| Adam | epoch: 014 | loss: 0.05019 - acc: 0.9917 -- iter: 032/188
[A[ATraining Step: 80  | total loss: [1m[32m0.08167[0m[0m | time: 24.360s
[2K
| Adam | epoch: 014 | loss: 0.08167 - acc: 0.9894 -- iter: 064/188
[A[ATraining Step: 81  | total loss: [1m[32m0.07402[0m[0m | time: 36.797s
[2K
| Adam | epoch: 014 | loss: 0.07402 - acc: 0.9904 -- iter: 096/188
[A[ATraining Step: 82  | total loss: [1m[32m0.06741[0m[0m | time: 49.230s
[2K
| Adam | epoch: 014 | loss: 0.06741 - acc: 0.9914 -- iter: 128/188
[A[ATraining Step: 83  | total loss: [1m[32m0.06098[0m[0m | time: 59.984s
[2K
| Adam | epoch: 014 | loss: 0.06098 - acc: 0.9923 -- iter: 160/188
[A[ATraining Step: 84  | total loss: [1m[32m0.05602[0m[0m | time: 75.342s
[2K
| Adam | epoch: 014 | loss: 0.05602 - acc: 0.9930 | val_loss: 0.16838 - val_acc: 0.9492 -- iter: 188/188
--
Training Step: 85  | total loss: [1m[32m0.05191[0m[0m | time: 9.850s
[2K
| Adam | epoch: 015 | loss: 0.05191 - acc: 0.9937 -- iter: 032/188
[A[ATraining Step: 86  | total loss: [1m[32m0.04708[0m[0m | time: 18.266s
[2K
| Adam | epoch: 015 | loss: 0.04708 - acc: 0.9944 -- iter: 064/188
[A[ATraining Step: 87  | total loss: [1m[32m0.06611[0m[0m | time: 27.893s
[2K
| Adam | epoch: 015 | loss: 0.06611 - acc: 0.9918 -- iter: 096/188
[A[ATraining Step: 88  | total loss: [1m[32m0.06027[0m[0m | time: 40.015s
[2K
| Adam | epoch: 015 | loss: 0.06027 - acc: 0.9926 -- iter: 128/188
[A[ATraining Step: 89  | total loss: [1m[32m0.05487[0m[0m | time: 52.281s
[2K
| Adam | epoch: 015 | loss: 0.05487 - acc: 0.9934 -- iter: 160/188
[A[ATraining Step: 90  | total loss: [1m[32m0.05202[0m[0m | time: 67.392s
[2K
| Adam | epoch: 015 | loss: 0.05202 - acc: 0.9940 | val_loss: 0.19438 - val_acc: 0.8983 -- iter: 188/188
--
Validation AUC:0.9827188940092166
Validation AUPRC:0.9785005382511469
Test AUC:0.9666666666666667
Test AUPRC:0.9808080808080807
BestTestF1Score	0.93	0.87	0.93	1.0	0.87	26	0	29	4	0.2
BestTestMCCScore	0.93	0.87	0.93	1.0	0.87	26	0	29	4	0.2
BestTestAccuracyScore	0.93	0.87	0.93	1.0	0.87	26	0	29	4	0.2
BestValidationF1Score	0.97	0.93	0.97	0.93	1.0	28	2	29	0	0.2
BestValidationMCC	0.97	0.93	0.97	0.93	1.0	28	2	29	0	0.2
BestValidationAccuracy	0.97	0.93	0.97	0.93	1.0	28	2	29	0	0.2
TestPredictions (Threshold:0.2)
CHEMBL3633650,TN,INACT,0.0	CHEMBL42359,TN,INACT,0.0	CHEMBL31599,TP,ACT,1.0	CHEMBL3337857,FN,ACT,0.17000000178813934	CHEMBL461502,TN,INACT,0.0	CHEMBL262448,TP,ACT,1.0	CHEMBL269205,TP,ACT,1.0	CHEMBL123099,TN,INACT,0.0	CHEMBL285136,TP,ACT,0.9900000095367432	CHEMBL515170,TN,INACT,0.0	CHEMBL169633,TP,ACT,0.9599999785423279	CHEMBL95,FN,ACT,0.0	CHEMBL609382,TP,ACT,0.8799999952316284	CHEMBL2111789,TN,INACT,0.0	CHEMBL3337866,TP,ACT,1.0	CHEMBL100624,TN,INACT,0.019999999552965164	CHEMBL3337862,TP,ACT,0.9800000190734863	CHEMBL262124,TP,ACT,1.0	CHEMBL450463,TN,INACT,0.0	CHEMBL172788,TN,INACT,0.0	CHEMBL168613,TP,ACT,0.9200000166893005	CHEMBL3218121,TN,INACT,0.0	CHEMBL251541,TN,INACT,0.019999999552965164	CHEMBL31376,TP,ACT,0.9900000095367432	CHEMBL228144,TN,INACT,0.0	CHEMBL3589940,TN,INACT,0.0	CHEMBL168840,TP,ACT,0.9300000071525574	CHEMBL282782,FN,ACT,0.0	CHEMBL540131,TP,ACT,0.8399999737739563	CHEMBL594801,TN,INACT,0.0	CHEMBL21937,TN,INACT,0.0	CHEMBL7902,TP,ACT,1.0	CHEMBL1202148,TP,ACT,0.5699999928474426	CHEMBL381913,TP,ACT,0.9300000071525574	CHEMBL21328,TN,INACT,0.0	CHEMBL168760,TP,ACT,0.3400000035762787	CHEMBL352779,TN,INACT,0.0	CHEMBL351183,TN,INACT,0.0	CHEMBL513277,TN,INACT,0.0	CHEMBL8653,TP,ACT,0.9900000095367432	CHEMBL32609,TP,ACT,0.23999999463558197	CHEMBL2370511,TN,INACT,0.0	CHEMBL380352,FN,ACT,0.07999999821186066	CHEMBL590603,TP,ACT,0.9599999785423279	CHEMBL262449,TP,ACT,1.0	CHEMBL3309718,TN,INACT,0.0	CHEMBL593443,TN,INACT,0.0	CHEMBL168632,TN,INACT,0.0	CHEMBL8898,TP,ACT,0.9399999976158142	CHEMBL33656,TP,ACT,0.5899999737739563	CHEMBL438915,TN,INACT,0.0	CHEMBL2391356,TN,INACT,0.029999999329447746	CHEMBL9071,TP,ACT,0.3499999940395355	CHEMBL3780633,TN,INACT,0.0	CHEMBL3633656,TN,INACT,0.0	CHEMBL382659,TP,ACT,0.9300000071525574	CHEMBL164968,TN,INACT,0.019999999552965164	CHEMBL461709,TN,INACT,0.0	CHEMBL265482,TP,ACT,1.0	

