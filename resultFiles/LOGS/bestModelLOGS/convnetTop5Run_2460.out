ImageNetInceptionV2 CHEMBL5076 adam 0.0001 5 0 0 0.6 False True
Number of active compounds :	395
Number of inactive compounds :	395
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5076_adam_0.0001_5_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5076_adam_0.0001_5_0.6/
---------------------------------
Training samples: 492
Validation samples: 154
--
Training Step: 1  | time: 214.339s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/492
[A[ATraining Step: 2  | total loss: [1m[32m0.62192[0m[0m | time: 310.453s
[2K
| Adam | epoch: 001 | loss: 0.62192 - acc: 0.5062 -- iter: 064/492
[A[ATraining Step: 3  | total loss: [1m[32m0.50796[0m[0m | time: 422.155s
[2K
| Adam | epoch: 001 | loss: 0.50796 - acc: 0.7312 -- iter: 096/492
[A[ATraining Step: 4  | total loss: [1m[32m0.62640[0m[0m | time: 486.617s
[2K
| Adam | epoch: 001 | loss: 0.62640 - acc: 0.6750 -- iter: 128/492
[A[ATraining Step: 5  | total loss: [1m[32m0.52919[0m[0m | time: 553.230s
[2K
| Adam | epoch: 001 | loss: 0.52919 - acc: 0.7269 -- iter: 160/492
[A[ATraining Step: 6  | total loss: [1m[32m0.60560[0m[0m | time: 616.105s
[2K
| Adam | epoch: 001 | loss: 0.60560 - acc: 0.7819 -- iter: 192/492
[A[ATraining Step: 7  | total loss: [1m[32m0.57779[0m[0m | time: 652.357s
[2K
| Adam | epoch: 001 | loss: 0.57779 - acc: 0.8003 -- iter: 224/492
[A[ATraining Step: 8  | total loss: [1m[32m0.45745[0m[0m | time: 770.445s
[2K
| Adam | epoch: 001 | loss: 0.45745 - acc: 0.8423 -- iter: 256/492
[A[ATraining Step: 9  | total loss: [1m[32m0.45071[0m[0m | time: 813.047s
[2K
| Adam | epoch: 001 | loss: 0.45071 - acc: 0.8431 -- iter: 288/492
[A[ATraining Step: 10  | total loss: [1m[32m0.40229[0m[0m | time: 857.657s
[2K
| Adam | epoch: 001 | loss: 0.40229 - acc: 0.8590 -- iter: 320/492
[A[ATraining Step: 11  | total loss: [1m[32m0.48188[0m[0m | time: 927.147s
[2K
| Adam | epoch: 001 | loss: 0.48188 - acc: 0.8074 -- iter: 352/492
[A[ATraining Step: 12  | total loss: [1m[32m0.40302[0m[0m | time: 979.034s
[2K
| Adam | epoch: 001 | loss: 0.40302 - acc: 0.8519 -- iter: 384/492
[A[ATraining Step: 13  | total loss: [1m[32m0.35973[0m[0m | time: 1028.462s
[2K
| Adam | epoch: 001 | loss: 0.35973 - acc: 0.8484 -- iter: 416/492
[A[ATraining Step: 14  | total loss: [1m[32m0.40297[0m[0m | time: 1048.836s
[2K
| Adam | epoch: 001 | loss: 0.40297 - acc: 0.7954 -- iter: 448/492
[A[ATraining Step: 15  | total loss: [1m[32m0.49046[0m[0m | time: 1094.930s
[2K
| Adam | epoch: 001 | loss: 0.49046 - acc: 0.7409 -- iter: 480/492
[A[ATraining Step: 16  | total loss: [1m[32m0.47629[0m[0m | time: 1129.528s
[2K
| Adam | epoch: 001 | loss: 0.47629 - acc: 0.7678 | val_loss: 4.17937 - val_acc: 0.4610 -- iter: 492/492
--
Training Step: 17  | total loss: [1m[32m0.47239[0m[0m | time: 8.174s
[2K
| Adam | epoch: 002 | loss: 0.47239 - acc: 0.7614 -- iter: 032/492
[A[ATraining Step: 18  | total loss: [1m[32m0.40992[0m[0m | time: 51.622s
[2K
| Adam | epoch: 002 | loss: 0.40992 - acc: 0.7863 -- iter: 064/492
[A[ATraining Step: 19  | total loss: [1m[32m0.48482[0m[0m | time: 65.181s
[2K
| Adam | epoch: 002 | loss: 0.48482 - acc: 0.7221 -- iter: 096/492
[A[ATraining Step: 20  | total loss: [1m[32m0.41547[0m[0m | time: 83.424s
[2K
| Adam | epoch: 002 | loss: 0.41547 - acc: 0.7913 -- iter: 128/492
[A[ATraining Step: 21  | total loss: [1m[32m0.37751[0m[0m | time: 118.649s
[2K
| Adam | epoch: 002 | loss: 0.37751 - acc: 0.8270 -- iter: 160/492
[A[ATraining Step: 22  | total loss: [1m[32m0.38194[0m[0m | time: 168.719s
[2K
| Adam | epoch: 002 | loss: 0.38194 - acc: 0.8320 -- iter: 192/492
[A[ATraining Step: 23  | total loss: [1m[32m0.34446[0m[0m | time: 204.273s
[2K
| Adam | epoch: 002 | loss: 0.34446 - acc: 0.8626 -- iter: 224/492
[A[ATraining Step: 24  | total loss: [1m[32m0.32716[0m[0m | time: 238.221s
[2K
| Adam | epoch: 002 | loss: 0.32716 - acc: 0.8749 -- iter: 256/492
[A[ATraining Step: 25  | total loss: [1m[32m0.32871[0m[0m | time: 290.580s
[2K
| Adam | epoch: 002 | loss: 0.32871 - acc: 0.8664 -- iter: 288/492
[A[ATraining Step: 26  | total loss: [1m[32m0.28142[0m[0m | time: 359.810s
[2K
| Adam | epoch: 002 | loss: 0.28142 - acc: 0.8935 -- iter: 320/492
[A[ATraining Step: 27  | total loss: [1m[32m0.33579[0m[0m | time: 448.636s
[2K
| Adam | epoch: 002 | loss: 0.33579 - acc: 0.8646 -- iter: 352/492
[A[ATraining Step: 28  | total loss: [1m[32m0.29747[0m[0m | time: 476.280s
[2K
| Adam | epoch: 002 | loss: 0.29747 - acc: 0.8907 -- iter: 384/492
[A[ATraining Step: 29  | total loss: [1m[32m0.27311[0m[0m | time: 493.407s
[2K
| Adam | epoch: 002 | loss: 0.27311 - acc: 0.8945 -- iter: 416/492
[A[ATraining Step: 30  | total loss: [1m[32m0.26721[0m[0m | time: 530.511s
[2K
| Adam | epoch: 002 | loss: 0.26721 - acc: 0.8972 -- iter: 448/492
[A[ATraining Step: 31  | total loss: [1m[32m0.26838[0m[0m | time: 568.547s
[2K
| Adam | epoch: 002 | loss: 0.26838 - acc: 0.8921 -- iter: 480/492
[A[ATraining Step: 32  | total loss: [1m[32m0.28338[0m[0m | time: 626.530s
[2K
| Adam | epoch: 002 | loss: 0.28338 - acc: 0.8812 | val_loss: 1.71150 - val_acc: 0.4610 -- iter: 492/492
--
Training Step: 33  | total loss: [1m[32m0.25324[0m[0m | time: 6.715s
[2K
| Adam | epoch: 003 | loss: 0.25324 - acc: 0.9073 -- iter: 032/492
[A[ATraining Step: 34  | total loss: [1m[32m0.22688[0m[0m | time: 14.279s
[2K
| Adam | epoch: 003 | loss: 0.22688 - acc: 0.9272 -- iter: 064/492
[A[ATraining Step: 35  | total loss: [1m[32m0.19033[0m[0m | time: 37.615s
[2K
| Adam | epoch: 003 | loss: 0.19033 - acc: 0.9424 -- iter: 096/492
[A[ATraining Step: 36  | total loss: [1m[32m0.18799[0m[0m | time: 56.631s
[2K
| Adam | epoch: 003 | loss: 0.18799 - acc: 0.9414 -- iter: 128/492
[A[ATraining Step: 37  | total loss: [1m[32m0.17386[0m[0m | time: 73.776s
[2K
| Adam | epoch: 003 | loss: 0.17386 - acc: 0.9469 -- iter: 160/492
[A[ATraining Step: 38  | total loss: [1m[32m0.17278[0m[0m | time: 91.115s
[2K
| Adam | epoch: 003 | loss: 0.17278 - acc: 0.9512 -- iter: 192/492
[A[ATraining Step: 39  | total loss: [1m[32m0.14861[0m[0m | time: 113.719s
[2K
| Adam | epoch: 003 | loss: 0.14861 - acc: 0.9605 -- iter: 224/492
[A[ATraining Step: 40  | total loss: [1m[32m0.15678[0m[0m | time: 135.900s
[2K
| Adam | epoch: 003 | loss: 0.15678 - acc: 0.9503 -- iter: 256/492
[A[ATraining Step: 41  | total loss: [1m[32m0.13959[0m[0m | time: 153.476s
[2K
| Adam | epoch: 003 | loss: 0.13959 - acc: 0.9595 -- iter: 288/492
[A[ATraining Step: 42  | total loss: [1m[32m0.13403[0m[0m | time: 171.773s
[2K
| Adam | epoch: 003 | loss: 0.13403 - acc: 0.9611 -- iter: 320/492
[A[ATraining Step: 43  | total loss: [1m[32m0.13369[0m[0m | time: 191.369s
[2K
| Adam | epoch: 003 | loss: 0.13369 - acc: 0.9625 -- iter: 352/492
[A[ATraining Step: 44  | total loss: [1m[32m0.12452[0m[0m | time: 208.240s
[2K
| Adam | epoch: 003 | loss: 0.12452 - acc: 0.9636 -- iter: 384/492
[A[ATraining Step: 45  | total loss: [1m[32m0.11797[0m[0m | time: 225.647s
[2K
| Adam | epoch: 003 | loss: 0.11797 - acc: 0.9697 -- iter: 416/492
[A[ATraining Step: 46  | total loss: [1m[32m0.10493[0m[0m | time: 258.900s
[2K
| Adam | epoch: 003 | loss: 0.10493 - acc: 0.9748 -- iter: 448/492
[A[ATraining Step: 47  | total loss: [1m[32m0.09461[0m[0m | time: 276.984s
[2K
| Adam | epoch: 003 | loss: 0.09461 - acc: 0.9789 -- iter: 480/492
[A[ATraining Step: 48  | total loss: [1m[32m0.08467[0m[0m | time: 301.211s
[2K
| Adam | epoch: 003 | loss: 0.08467 - acc: 0.9823 | val_loss: 0.49536 - val_acc: 0.7273 -- iter: 492/492
--
Training Step: 49  | total loss: [1m[32m0.08150[0m[0m | time: 47.053s
[2K
| Adam | epoch: 004 | loss: 0.08150 - acc: 0.9851 -- iter: 032/492
[A[ATraining Step: 50  | total loss: [1m[32m0.07865[0m[0m | time: 55.335s
[2K
| Adam | epoch: 004 | loss: 0.07865 - acc: 0.9826 -- iter: 064/492
[A[ATraining Step: 51  | total loss: [1m[32m0.08293[0m[0m | time: 63.309s
[2K
| Adam | epoch: 004 | loss: 0.08293 - acc: 0.9725 -- iter: 096/492
[A[ATraining Step: 52  | total loss: [1m[32m0.07326[0m[0m | time: 87.181s
[2K
| Adam | epoch: 004 | loss: 0.07326 - acc: 0.9766 -- iter: 128/492
[A[ATraining Step: 53  | total loss: [1m[32m0.13835[0m[0m | time: 106.737s
[2K
| Adam | epoch: 004 | loss: 0.13835 - acc: 0.9662 -- iter: 160/492
[A[ATraining Step: 54  | total loss: [1m[32m0.12015[0m[0m | time: 123.858s
[2K
| Adam | epoch: 004 | loss: 0.12015 - acc: 0.9711 -- iter: 192/492
[A[ATraining Step: 55  | total loss: [1m[32m0.10439[0m[0m | time: 140.928s
[2K
| Adam | epoch: 004 | loss: 0.10439 - acc: 0.9753 -- iter: 224/492
[A[ATraining Step: 56  | total loss: [1m[32m0.09058[0m[0m | time: 158.180s
[2K
| Adam | epoch: 004 | loss: 0.09058 - acc: 0.9787 -- iter: 256/492
[A[ATraining Step: 57  | total loss: [1m[32m0.08228[0m[0m | time: 175.155s
[2K
| Adam | epoch: 004 | loss: 0.08228 - acc: 0.9817 -- iter: 288/492
[A[ATraining Step: 58  | total loss: [1m[32m0.07397[0m[0m | time: 192.174s
[2K
| Adam | epoch: 004 | loss: 0.07397 - acc: 0.9842 -- iter: 320/492
[A[ATraining Step: 59  | total loss: [1m[32m0.06886[0m[0m | time: 209.264s
[2K
| Adam | epoch: 004 | loss: 0.06886 - acc: 0.9863 -- iter: 352/492
[A[ATraining Step: 60  | total loss: [1m[32m0.06083[0m[0m | time: 230.922s
[2K
| Adam | epoch: 004 | loss: 0.06083 - acc: 0.9881 -- iter: 384/492
[A[ATraining Step: 61  | total loss: [1m[32m0.05437[0m[0m | time: 244.053s
[2K
| Adam | epoch: 004 | loss: 0.05437 - acc: 0.9897 -- iter: 416/492
[A[ATraining Step: 62  | total loss: [1m[32m0.04818[0m[0m | time: 272.743s
[2K
| Adam | epoch: 004 | loss: 0.04818 - acc: 0.9910 -- iter: 448/492
[A[ATraining Step: 63  | total loss: [1m[32m0.04643[0m[0m | time: 347.291s
[2K
| Adam | epoch: 004 | loss: 0.04643 - acc: 0.9882 -- iter: 480/492
[A[ATraining Step: 64  | total loss: [1m[32m0.04441[0m[0m | time: 380.154s
[2K
| Adam | epoch: 004 | loss: 0.04441 - acc: 0.9897 | val_loss: 1.21909 - val_acc: 0.7468 -- iter: 492/492
--
Training Step: 65  | total loss: [1m[32m0.06063[0m[0m | time: 16.796s
[2K
| Adam | epoch: 005 | loss: 0.06063 - acc: 0.9832 -- iter: 032/492
[A[ATraining Step: 66  | total loss: [1m[32m0.05715[0m[0m | time: 35.759s
[2K
| Adam | epoch: 005 | loss: 0.05715 - acc: 0.9853 -- iter: 064/492
[A[ATraining Step: 67  | total loss: [1m[32m0.05713[0m[0m | time: 43.706s
[2K
| Adam | epoch: 005 | loss: 0.05713 - acc: 0.9870 -- iter: 096/492
[A[ATraining Step: 68  | total loss: [1m[32m0.05247[0m[0m | time: 52.129s
[2K
| Adam | epoch: 005 | loss: 0.05247 - acc: 0.9886 -- iter: 128/492
[A[ATraining Step: 69  | total loss: [1m[32m0.04813[0m[0m | time: 76.232s
[2K
| Adam | epoch: 005 | loss: 0.04813 - acc: 0.9899 -- iter: 160/492
[A[ATraining Step: 70  | total loss: [1m[32m0.24025[0m[0m | time: 93.133s
[2K
| Adam | epoch: 005 | loss: 0.24025 - acc: 0.9550 -- iter: 192/492
[A[ATraining Step: 71  | total loss: [1m[32m0.21358[0m[0m | time: 114.024s
[2K
| Adam | epoch: 005 | loss: 0.21358 - acc: 0.9601 -- iter: 224/492
[A[ATraining Step: 72  | total loss: [1m[32m0.19084[0m[0m | time: 131.033s
[2K
| Adam | epoch: 005 | loss: 0.19084 - acc: 0.9646 -- iter: 256/492
[A[ATraining Step: 73  | total loss: [1m[32m0.17511[0m[0m | time: 145.690s
[2K
| Adam | epoch: 005 | loss: 0.17511 - acc: 0.9651 -- iter: 288/492
[A[ATraining Step: 74  | total loss: [1m[32m0.15850[0m[0m | time: 158.736s
[2K
| Adam | epoch: 005 | loss: 0.15850 - acc: 0.9689 -- iter: 320/492
[A[ATraining Step: 75  | total loss: [1m[32m0.14297[0m[0m | time: 176.796s
[2K
| Adam | epoch: 005 | loss: 0.14297 - acc: 0.9723 -- iter: 352/492
[A[ATraining Step: 76  | total loss: [1m[32m0.13087[0m[0m | time: 193.400s
[2K
| Adam | epoch: 005 | loss: 0.13087 - acc: 0.9753 -- iter: 384/492
[A[ATraining Step: 77  | total loss: [1m[32m0.12922[0m[0m | time: 225.387s
[2K
| Adam | epoch: 005 | loss: 0.12922 - acc: 0.9746 -- iter: 416/492
[A[ATraining Step: 78  | total loss: [1m[32m0.11643[0m[0m | time: 243.248s
[2K
| Adam | epoch: 005 | loss: 0.11643 - acc: 0.9772 -- iter: 448/492
[A[ATraining Step: 79  | total loss: [1m[32m0.10815[0m[0m | time: 260.565s
[2K
| Adam | epoch: 005 | loss: 0.10815 - acc: 0.9796 -- iter: 480/492
[A[ATraining Step: 80  | total loss: [1m[32m0.09876[0m[0m | time: 301.986s
[2K
| Adam | epoch: 005 | loss: 0.09876 - acc: 0.9817 | val_loss: 0.42343 - val_acc: 0.8377 -- iter: 492/492
--
Validation AUC:0.9363651790259631
Validation AUPRC:0.9385419176203231
Test AUC:0.9459505541346973
Test AUPRC:0.9620888427882374
BestTestF1Score	0.92	0.82	0.91	0.91	0.93	79	8	61	6	0.64
BestTestMCCScore	0.92	0.82	0.91	0.91	0.93	79	8	61	6	0.64
BestTestAccuracyScore	0.87	0.74	0.86	0.93	0.81	69	5	64	16	0.92
BestValidationF1Score	0.86	0.73	0.86	0.82	0.9	64	14	69	7	0.64
BestValidationMCC	0.86	0.73	0.86	0.82	0.9	64	14	69	7	0.64
BestValidationAccuracy	0.84	0.73	0.86	0.89	0.8	57	7	76	14	0.92
TestPredictions (Threshold:0.64)
CHEMBL45056,TP,ACT,0.7300000190734863	CHEMBL330003,TN,INACT,0.23999999463558197	CHEMBL128635,TP,ACT,1.0	CHEMBL88629,TN,INACT,0.0	CHEMBL75332,TP,ACT,0.8700000047683716	CHEMBL373263,TP,ACT,0.9900000095367432	CHEMBL39951,TP,ACT,0.8999999761581421	CHEMBL453,TN,INACT,0.4099999964237213	CHEMBL77925,TP,ACT,1.0	CHEMBL48024,TN,INACT,0.49000000953674316	CHEMBL75100,TP,ACT,0.9900000095367432	CHEMBL76949,TN,INACT,0.07999999821186066	CHEMBL156814,FP,INACT,0.949999988079071	CHEMBL168632,FP,INACT,0.800000011920929	CHEMBL204193,TP,ACT,1.0	CHEMBL293874,TN,INACT,0.009999999776482582	CHEMBL59347,TN,INACT,0.009999999776482582	CHEMBL77594,TP,ACT,0.9800000190734863	CHEMBL2283101,TP,ACT,1.0	CHEMBL595022,TN,INACT,0.5799999833106995	CHEMBL2373213,TN,INACT,0.009999999776482582	CHEMBL3143400,TN,INACT,0.0	CHEMBL274490,TP,ACT,0.9900000095367432	CHEMBL200540,TP,ACT,1.0	CHEMBL14690,TP,ACT,1.0	CHEMBL200139,TP,ACT,1.0	CHEMBL417719,TN,INACT,0.03999999910593033	CHEMBL352779,TN,INACT,0.029999999329447746	CHEMBL1222650,TP,ACT,0.8899999856948853	CHEMBL69707,TP,ACT,1.0	CHEMBL432334,TN,INACT,0.0	CHEMBL66439,TP,ACT,1.0	CHEMBL80317,TN,INACT,0.029999999329447746	CHEMBL322537,TN,INACT,0.25999999046325684	CHEMBL18735,TP,ACT,0.949999988079071	CHEMBL312670,TN,INACT,0.009999999776482582	CHEMBL408492,TN,INACT,0.009999999776482582	CHEMBL2283088,TP,ACT,1.0	CHEMBL432773,TP,ACT,0.9700000286102295	CHEMBL2112321,TP,ACT,0.9300000071525574	CHEMBL413040,TN,INACT,0.009999999776482582	CHEMBL414570,TN,INACT,0.0	CHEMBL424847,TP,ACT,1.0	CHEMBL128773,TP,ACT,0.9900000095367432	CHEMBL2283093,TP,ACT,1.0	CHEMBL2297887,TP,ACT,1.0	CHEMBL309017,TN,INACT,0.0	CHEMBL199972,TP,ACT,0.9200000166893005	CHEMBL308243,TN,INACT,0.1599999964237213	CHEMBL90,TP,ACT,0.9900000095367432	CHEMBL131366,TP,ACT,1.0	CHEMBL435728,TP,ACT,0.9700000286102295	CHEMBL52080,TP,ACT,0.9900000095367432	CHEMBL104172,TN,INACT,0.029999999329447746	CHEMBL2297877,TP,ACT,0.9900000095367432	CHEMBL203263,TP,ACT,1.0	CHEMBL76360,TN,INACT,0.03999999910593033	CHEMBL66438,TP,ACT,1.0	CHEMBL141365,TN,INACT,0.09000000357627869	CHEMBL2437425,TP,ACT,0.8700000047683716	CHEMBL241514,TN,INACT,0.3700000047683716	CHEMBL2297888,TP,ACT,0.9900000095367432	CHEMBL58973,TP,ACT,0.8899999856948853	CHEMBL1222718,TP,ACT,0.9800000190734863	CHEMBL423320,TP,ACT,1.0	CHEMBL53412,TP,ACT,1.0	CHEMBL421125,TP,ACT,0.9800000190734863	CHEMBL3780248,TN,INACT,0.0	CHEMBL40378,FN,ACT,0.009999999776482582	CHEMBL130005,TP,ACT,1.0	CHEMBL602269,TN,INACT,0.17000000178813934	CHEMBL381070,TP,ACT,0.9599999785423279	CHEMBL294649,TN,INACT,0.0	CHEMBL408395,TN,INACT,0.009999999776482582	CHEMBL200842,TP,ACT,0.9900000095367432	CHEMBL53056,TP,ACT,0.8999999761581421	CHEMBL353502,TN,INACT,0.07999999821186066	CHEMBL52090,TP,ACT,1.0	CHEMBL148967,TN,INACT,0.0	CHEMBL78853,TN,INACT,0.3700000047683716	CHEMBL114074,TN,INACT,0.009999999776482582	CHEMBL217002,TN,INACT,0.2199999988079071	CHEMBL321644,TN,INACT,0.05000000074505806	CHEMBL14364,FN,ACT,0.6399999856948853	CHEMBL166089,TN,INACT,0.07999999821186066	CHEMBL3633665,TN,INACT,0.1899999976158142	CHEMBL75871,TP,ACT,1.0	CHEMBL2283086,TP,ACT,1.0	CHEMBL2437424,TP,ACT,0.9300000071525574	CHEMBL418653,TP,ACT,0.9900000095367432	CHEMBL19808,TN,INACT,0.3400000035762787	CHEMBL2283091,TP,ACT,1.0	CHEMBL332405,TN,INACT,0.07999999821186066	CHEMBL6568,TN,INACT,0.36000001430511475	CHEMBL493091,TP,ACT,1.0	CHEMBL1223502,TP,ACT,0.8999999761581421	CHEMBL288967,TN,INACT,0.4399999976158142	CHEMBL173585,FN,ACT,0.03999999910593033	CHEMBL106342,TP,ACT,1.0	CHEMBL68483,TP,ACT,1.0	CHEMBL131117,TP,ACT,1.0	CHEMBL2437419,FN,ACT,0.03999999910593033	CHEMBL513277,TN,INACT,0.07000000029802322	CHEMBL2283098,TP,ACT,1.0	CHEMBL78601,TN,INACT,0.41999998688697815	CHEMBL430683,TN,INACT,0.5400000214576721	CHEMBL412882,TP,ACT,0.9900000095367432	CHEMBL173126,TP,ACT,0.8700000047683716	CHEMBL83271,TP,ACT,0.9700000286102295	CHEMBL328089,TN,INACT,0.0	CHEMBL3633656,TN,INACT,0.11999999731779099	CHEMBL2042400,TN,INACT,0.0	CHEMBL373000,TP,ACT,1.0	CHEMBL309269,TP,ACT,1.0	CHEMBL14868,TP,ACT,0.9399999976158142	CHEMBL141354,TN,INACT,0.4699999988079071	CHEMBL2283079,TP,ACT,1.0	CHEMBL98473,TP,ACT,0.9900000095367432	CHEMBL593443,FP,INACT,0.9599999785423279	CHEMBL18980,TP,ACT,0.75	CHEMBL78080,TN,INACT,0.009999999776482582	CHEMBL310361,TN,INACT,0.009999999776482582	CHEMBL274041,TP,ACT,0.9800000190734863	CHEMBL2437429,FN,ACT,0.2800000011920929	CHEMBL2283077,TP,ACT,1.0	CHEMBL2437431,TP,ACT,0.9700000286102295	CHEMBL461087,TN,INACT,0.03999999910593033	CHEMBL79271,FN,ACT,0.009999999776482582	CHEMBL1170027,TN,INACT,0.009999999776482582	CHEMBL323854,TN,INACT,0.05000000074505806	CHEMBL3354069,FP,INACT,0.9800000190734863	CHEMBL40796,TN,INACT,0.1899999976158142	CHEMBL377278,TP,ACT,1.0	CHEMBL21508,TN,INACT,0.009999999776482582	CHEMBL112723,TP,ACT,1.0	CHEMBL70148,TP,ACT,1.0	CHEMBL200806,TP,ACT,1.0	CHEMBL2113072,FP,INACT,0.8999999761581421	CHEMBL417358,FP,INACT,0.8299999833106995	CHEMBL593620,TN,INACT,0.009999999776482582	CHEMBL2297873,TP,ACT,0.9800000190734863	CHEMBL11629,FP,INACT,0.9800000190734863	CHEMBL594803,FP,INACT,0.949999988079071	CHEMBL307850,TP,ACT,1.0	CHEMBL99518,TP,ACT,0.9900000095367432	CHEMBL110064,TN,INACT,0.0	CHEMBL298203,TN,INACT,0.0	CHEMBL371730,TP,ACT,1.0	CHEMBL227378,TN,INACT,0.07000000029802322	CHEMBL2437421,TP,ACT,0.9200000166893005	CHEMBL200189,TP,ACT,1.0	CHEMBL48448,TN,INACT,0.03999999910593033	CHEMBL128360,TN,INACT,0.17000000178813934	CHEMBL2297874,TP,ACT,0.9800000190734863	

