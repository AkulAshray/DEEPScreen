CNNModel CHEMBL209 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	1088
Number of inactive compounds :	1088
---------------------------------
Run id: CNNModel_CHEMBL209_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL209_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 1392
Validation samples: 435
--
Training Step: 1  | time: 0.808s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1392
[A[ATraining Step: 2  | total loss: [1m[32m0.62386[0m[0m | time: 1.401s
[2K
| Adam | epoch: 001 | loss: 0.62386 - acc: 0.4219 -- iter: 0064/1392
[A[ATraining Step: 3  | total loss: [1m[32m0.67956[0m[0m | time: 2.003s
[2K
| Adam | epoch: 001 | loss: 0.67956 - acc: 0.5881 -- iter: 0096/1392
[A[ATraining Step: 4  | total loss: [1m[32m0.68999[0m[0m | time: 2.601s
[2K
| Adam | epoch: 001 | loss: 0.68999 - acc: 0.5220 -- iter: 0128/1392
[A[ATraining Step: 5  | total loss: [1m[32m0.70180[0m[0m | time: 3.203s
[2K
| Adam | epoch: 001 | loss: 0.70180 - acc: 0.3986 -- iter: 0160/1392
[A[ATraining Step: 6  | total loss: [1m[32m0.69857[0m[0m | time: 3.856s
[2K
| Adam | epoch: 001 | loss: 0.69857 - acc: 0.4035 -- iter: 0192/1392
[A[ATraining Step: 7  | total loss: [1m[32m0.69562[0m[0m | time: 4.476s
[2K
| Adam | epoch: 001 | loss: 0.69562 - acc: 0.4614 -- iter: 0224/1392
[A[ATraining Step: 8  | total loss: [1m[32m0.69432[0m[0m | time: 5.081s
[2K
| Adam | epoch: 001 | loss: 0.69432 - acc: 0.4480 -- iter: 0256/1392
[A[ATraining Step: 9  | total loss: [1m[32m0.69380[0m[0m | time: 5.697s
[2K
| Adam | epoch: 001 | loss: 0.69380 - acc: 0.4755 -- iter: 0288/1392
[A[ATraining Step: 10  | total loss: [1m[32m0.69381[0m[0m | time: 6.297s
[2K
| Adam | epoch: 001 | loss: 0.69381 - acc: 0.4721 -- iter: 0320/1392
[A[ATraining Step: 11  | total loss: [1m[32m0.69368[0m[0m | time: 6.929s
[2K
| Adam | epoch: 001 | loss: 0.69368 - acc: 0.4705 -- iter: 0352/1392
[A[ATraining Step: 12  | total loss: [1m[32m0.69324[0m[0m | time: 7.540s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.4979 -- iter: 0384/1392
[A[ATraining Step: 13  | total loss: [1m[32m0.69274[0m[0m | time: 8.159s
[2K
| Adam | epoch: 001 | loss: 0.69274 - acc: 0.5256 -- iter: 0416/1392
[A[ATraining Step: 14  | total loss: [1m[32m0.69125[0m[0m | time: 8.766s
[2K
| Adam | epoch: 001 | loss: 0.69125 - acc: 0.5790 -- iter: 0448/1392
[A[ATraining Step: 15  | total loss: [1m[32m0.69105[0m[0m | time: 9.371s
[2K
| Adam | epoch: 001 | loss: 0.69105 - acc: 0.5726 -- iter: 0480/1392
[A[ATraining Step: 16  | total loss: [1m[32m0.69285[0m[0m | time: 9.975s
[2K
| Adam | epoch: 001 | loss: 0.69285 - acc: 0.5336 -- iter: 0512/1392
[A[ATraining Step: 17  | total loss: [1m[32m0.69240[0m[0m | time: 10.585s
[2K
| Adam | epoch: 001 | loss: 0.69240 - acc: 0.5328 -- iter: 0544/1392
[A[ATraining Step: 18  | total loss: [1m[32m0.69328[0m[0m | time: 11.201s
[2K
| Adam | epoch: 001 | loss: 0.69328 - acc: 0.5214 -- iter: 0576/1392
[A[ATraining Step: 19  | total loss: [1m[32m0.69160[0m[0m | time: 11.808s
[2K
| Adam | epoch: 001 | loss: 0.69160 - acc: 0.5351 -- iter: 0608/1392
[A[ATraining Step: 20  | total loss: [1m[32m0.69075[0m[0m | time: 12.427s
[2K
| Adam | epoch: 001 | loss: 0.69075 - acc: 0.5439 -- iter: 0640/1392
[A[ATraining Step: 21  | total loss: [1m[32m0.69086[0m[0m | time: 13.025s
[2K
| Adam | epoch: 001 | loss: 0.69086 - acc: 0.5400 -- iter: 0672/1392
[A[ATraining Step: 22  | total loss: [1m[32m0.69859[0m[0m | time: 13.650s
[2K
| Adam | epoch: 001 | loss: 0.69859 - acc: 0.4905 -- iter: 0704/1392
[A[ATraining Step: 23  | total loss: [1m[32m0.69858[0m[0m | time: 14.257s
[2K
| Adam | epoch: 001 | loss: 0.69858 - acc: 0.4842 -- iter: 0736/1392
[A[ATraining Step: 24  | total loss: [1m[32m0.69488[0m[0m | time: 14.860s
[2K
| Adam | epoch: 001 | loss: 0.69488 - acc: 0.5150 -- iter: 0768/1392
[A[ATraining Step: 25  | total loss: [1m[32m0.69842[0m[0m | time: 15.457s
[2K
| Adam | epoch: 001 | loss: 0.69842 - acc: 0.4598 -- iter: 0800/1392
[A[ATraining Step: 26  | total loss: [1m[32m0.69582[0m[0m | time: 16.063s
[2K
| Adam | epoch: 001 | loss: 0.69582 - acc: 0.4952 -- iter: 0832/1392
[A[ATraining Step: 27  | total loss: [1m[32m0.69586[0m[0m | time: 16.681s
[2K
| Adam | epoch: 001 | loss: 0.69586 - acc: 0.4804 -- iter: 0864/1392
[A[ATraining Step: 28  | total loss: [1m[32m0.69484[0m[0m | time: 17.291s
[2K
| Adam | epoch: 001 | loss: 0.69484 - acc: 0.4931 -- iter: 0896/1392
[A[ATraining Step: 29  | total loss: [1m[32m0.69503[0m[0m | time: 17.893s
[2K
| Adam | epoch: 001 | loss: 0.69503 - acc: 0.4720 -- iter: 0928/1392
[A[ATraining Step: 30  | total loss: [1m[32m0.69488[0m[0m | time: 18.509s
[2K
| Adam | epoch: 001 | loss: 0.69488 - acc: 0.4638 -- iter: 0960/1392
[A[ATraining Step: 31  | total loss: [1m[32m0.69410[0m[0m | time: 19.134s
[2K
| Adam | epoch: 001 | loss: 0.69410 - acc: 0.5010 -- iter: 0992/1392
[A[ATraining Step: 32  | total loss: [1m[32m0.69408[0m[0m | time: 19.747s
[2K
| Adam | epoch: 001 | loss: 0.69408 - acc: 0.4867 -- iter: 1024/1392
[A[ATraining Step: 33  | total loss: [1m[32m0.69369[0m[0m | time: 20.341s
[2K
| Adam | epoch: 001 | loss: 0.69369 - acc: 0.5102 -- iter: 1056/1392
[A[ATraining Step: 34  | total loss: [1m[32m0.69350[0m[0m | time: 20.937s
[2K
| Adam | epoch: 001 | loss: 0.69350 - acc: 0.5147 -- iter: 1088/1392
[A[ATraining Step: 35  | total loss: [1m[32m0.69349[0m[0m | time: 21.510s
[2K
| Adam | epoch: 001 | loss: 0.69349 - acc: 0.5051 -- iter: 1120/1392
[A[ATraining Step: 36  | total loss: [1m[32m0.69324[0m[0m | time: 22.124s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.5232 -- iter: 1152/1392
[A[ATraining Step: 37  | total loss: [1m[32m0.69299[0m[0m | time: 22.738s
[2K
| Adam | epoch: 001 | loss: 0.69299 - acc: 0.5436 -- iter: 1184/1392
[A[ATraining Step: 38  | total loss: [1m[32m0.69289[0m[0m | time: 23.347s
[2K
| Adam | epoch: 001 | loss: 0.69289 - acc: 0.5473 -- iter: 1216/1392
[A[ATraining Step: 39  | total loss: [1m[32m0.69324[0m[0m | time: 23.954s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.5143 -- iter: 1248/1392
[A[ATraining Step: 40  | total loss: [1m[32m0.69315[0m[0m | time: 24.545s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.5175 -- iter: 1280/1392
[A[ATraining Step: 41  | total loss: [1m[32m0.69315[0m[0m | time: 25.146s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.5143 -- iter: 1312/1392
[A[ATraining Step: 42  | total loss: [1m[32m0.69323[0m[0m | time: 25.747s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.5061 -- iter: 1344/1392
[A[ATraining Step: 43  | total loss: [1m[32m0.69273[0m[0m | time: 26.341s
[2K
| Adam | epoch: 001 | loss: 0.69273 - acc: 0.5381 -- iter: 1376/1392
[A[ATraining Step: 44  | total loss: [1m[32m0.69288[0m[0m | time: 28.058s
[2K
| Adam | epoch: 001 | loss: 0.69288 - acc: 0.5261 | val_loss: 0.69299 - val_acc: 0.5103 -- iter: 1392/1392
--
Training Step: 45  | total loss: [1m[32m0.69276[0m[0m | time: 0.316s
[2K
| Adam | epoch: 002 | loss: 0.69276 - acc: 0.5323 -- iter: 0032/1392
[A[ATraining Step: 46  | total loss: [1m[32m0.69260[0m[0m | time: 0.912s
[2K
| Adam | epoch: 002 | loss: 0.69260 - acc: 0.5373 -- iter: 0064/1392
[A[ATraining Step: 47  | total loss: [1m[32m0.69303[0m[0m | time: 1.501s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5159 -- iter: 0096/1392
[A[ATraining Step: 48  | total loss: [1m[32m0.69329[0m[0m | time: 2.113s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.5033 -- iter: 0128/1392
[A[ATraining Step: 49  | total loss: [1m[32m0.69293[0m[0m | time: 2.727s
[2K
| Adam | epoch: 002 | loss: 0.69293 - acc: 0.5176 -- iter: 0160/1392
[A[ATraining Step: 50  | total loss: [1m[32m0.69320[0m[0m | time: 3.320s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5051 -- iter: 0192/1392
[A[ATraining Step: 51  | total loss: [1m[32m0.69275[0m[0m | time: 3.913s
[2K
| Adam | epoch: 002 | loss: 0.69275 - acc: 0.5234 -- iter: 0224/1392
[A[ATraining Step: 52  | total loss: [1m[32m0.69251[0m[0m | time: 4.534s
[2K
| Adam | epoch: 002 | loss: 0.69251 - acc: 0.5340 -- iter: 0256/1392
[A[ATraining Step: 53  | total loss: [1m[32m0.69272[0m[0m | time: 5.164s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5243 -- iter: 0288/1392
[A[ATraining Step: 54  | total loss: [1m[32m0.69339[0m[0m | time: 5.785s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.4981 -- iter: 0320/1392
[A[ATraining Step: 55  | total loss: [1m[32m0.69326[0m[0m | time: 6.401s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.5029 -- iter: 0352/1392
[A[ATraining Step: 56  | total loss: [1m[32m0.69338[0m[0m | time: 7.004s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.4981 -- iter: 0384/1392
[A[ATraining Step: 57  | total loss: [1m[32m0.69403[0m[0m | time: 7.605s
[2K
| Adam | epoch: 002 | loss: 0.69403 - acc: 0.4724 -- iter: 0416/1392
[A[ATraining Step: 58  | total loss: [1m[32m0.69381[0m[0m | time: 8.209s
[2K
| Adam | epoch: 002 | loss: 0.69381 - acc: 0.4804 -- iter: 0448/1392
[A[ATraining Step: 59  | total loss: [1m[32m0.69392[0m[0m | time: 8.813s
[2K
| Adam | epoch: 002 | loss: 0.69392 - acc: 0.4746 -- iter: 0480/1392
[A[ATraining Step: 60  | total loss: [1m[32m0.69349[0m[0m | time: 9.419s
[2K
| Adam | epoch: 002 | loss: 0.69349 - acc: 0.4945 -- iter: 0512/1392
[A[ATraining Step: 61  | total loss: [1m[32m0.69291[0m[0m | time: 10.041s
[2K
| Adam | epoch: 002 | loss: 0.69291 - acc: 0.5238 -- iter: 0544/1392
[A[ATraining Step: 62  | total loss: [1m[32m0.69296[0m[0m | time: 10.647s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5207 -- iter: 0576/1392
[A[ATraining Step: 63  | total loss: [1m[32m0.69297[0m[0m | time: 11.243s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5181 -- iter: 0608/1392
[A[ATraining Step: 64  | total loss: [1m[32m0.69291[0m[0m | time: 11.851s
[2K
| Adam | epoch: 002 | loss: 0.69291 - acc: 0.5197 -- iter: 0640/1392
[A[ATraining Step: 65  | total loss: [1m[32m0.69287[0m[0m | time: 12.447s
[2K
| Adam | epoch: 002 | loss: 0.69287 - acc: 0.5212 -- iter: 0672/1392
[A[ATraining Step: 66  | total loss: [1m[32m0.69272[0m[0m | time: 13.063s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5262 -- iter: 0704/1392
[A[ATraining Step: 67  | total loss: [1m[32m0.69276[0m[0m | time: 13.660s
[2K
| Adam | epoch: 002 | loss: 0.69276 - acc: 0.5230 -- iter: 0736/1392
[A[ATraining Step: 68  | total loss: [1m[32m0.69289[0m[0m | time: 14.271s
[2K
| Adam | epoch: 002 | loss: 0.69289 - acc: 0.5166 -- iter: 0768/1392
[A[ATraining Step: 69  | total loss: [1m[32m0.69285[0m[0m | time: 14.892s
[2K
| Adam | epoch: 002 | loss: 0.69285 - acc: 0.5183 -- iter: 0800/1392
[A[ATraining Step: 70  | total loss: [1m[32m0.69290[0m[0m | time: 15.499s
[2K
| Adam | epoch: 002 | loss: 0.69290 - acc: 0.5162 -- iter: 0832/1392
[A[ATraining Step: 71  | total loss: [1m[32m0.69304[0m[0m | time: 16.091s
[2K
| Adam | epoch: 002 | loss: 0.69304 - acc: 0.5108 -- iter: 0864/1392
[A[ATraining Step: 72  | total loss: [1m[32m0.69337[0m[0m | time: 16.688s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4990 -- iter: 0896/1392
[A[ATraining Step: 73  | total loss: [1m[32m0.69308[0m[0m | time: 17.299s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5096 -- iter: 0928/1392
[A[ATraining Step: 74  | total loss: [1m[32m0.69327[0m[0m | time: 17.922s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.5017 -- iter: 0960/1392
[A[ATraining Step: 75  | total loss: [1m[32m0.69310[0m[0m | time: 18.530s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5083 -- iter: 0992/1392
[A[ATraining Step: 76  | total loss: [1m[32m0.69276[0m[0m | time: 19.129s
[2K
| Adam | epoch: 002 | loss: 0.69276 - acc: 0.5208 -- iter: 1024/1392
[A[ATraining Step: 77  | total loss: [1m[32m0.69309[0m[0m | time: 19.752s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5086 -- iter: 1056/1392
[A[ATraining Step: 78  | total loss: [1m[32m0.69301[0m[0m | time: 20.351s
[2K
| Adam | epoch: 002 | loss: 0.69301 - acc: 0.5110 -- iter: 1088/1392
[A[ATraining Step: 79  | total loss: [1m[32m0.69320[0m[0m | time: 20.968s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5034 -- iter: 1120/1392
[A[ATraining Step: 80  | total loss: [1m[32m0.69373[0m[0m | time: 21.566s
[2K
| Adam | epoch: 002 | loss: 0.69373 - acc: 0.4839 -- iter: 1152/1392
[A[ATraining Step: 81  | total loss: [1m[32m0.69360[0m[0m | time: 22.162s
[2K
| Adam | epoch: 002 | loss: 0.69360 - acc: 0.4887 -- iter: 1184/1392
[A[ATraining Step: 82  | total loss: [1m[32m0.69350[0m[0m | time: 22.760s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.4929 -- iter: 1216/1392
[A[ATraining Step: 83  | total loss: [1m[32m0.69377[0m[0m | time: 23.372s
[2K
| Adam | epoch: 002 | loss: 0.69377 - acc: 0.4811 -- iter: 1248/1392
[A[ATraining Step: 84  | total loss: [1m[32m0.69376[0m[0m | time: 23.989s
[2K
| Adam | epoch: 002 | loss: 0.69376 - acc: 0.4799 -- iter: 1280/1392
[A[ATraining Step: 85  | total loss: [1m[32m0.69369[0m[0m | time: 24.590s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.4819 -- iter: 1312/1392
[A[ATraining Step: 86  | total loss: [1m[32m0.69369[0m[0m | time: 25.186s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.4806 -- iter: 1344/1392
[A[ATraining Step: 87  | total loss: [1m[32m0.69353[0m[0m | time: 25.796s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.4888 -- iter: 1376/1392
[A[ATraining Step: 88  | total loss: [1m[32m0.69359[0m[0m | time: 27.776s
[2K
| Adam | epoch: 002 | loss: 0.69359 - acc: 0.4837 | val_loss: 0.69301 - val_acc: 0.5103 -- iter: 1392/1392
--
Training Step: 89  | total loss: [1m[32m0.69362[0m[0m | time: 0.323s
[2K
| Adam | epoch: 003 | loss: 0.69362 - acc: 0.4790 -- iter: 0032/1392
[A[ATraining Step: 90  | total loss: [1m[32m0.69358[0m[0m | time: 0.661s
[2K
| Adam | epoch: 003 | loss: 0.69358 - acc: 0.4811 -- iter: 0064/1392
[A[ATraining Step: 91  | total loss: [1m[32m0.69353[0m[0m | time: 1.266s
[2K
| Adam | epoch: 003 | loss: 0.69353 - acc: 0.4830 -- iter: 0096/1392
[A[ATraining Step: 92  | total loss: [1m[32m0.69347[0m[0m | time: 1.870s
[2K
| Adam | epoch: 003 | loss: 0.69347 - acc: 0.4878 -- iter: 0128/1392
[A[ATraining Step: 93  | total loss: [1m[32m0.69340[0m[0m | time: 2.476s
[2K
| Adam | epoch: 003 | loss: 0.69340 - acc: 0.4922 -- iter: 0160/1392
[A[ATraining Step: 94  | total loss: [1m[32m0.69335[0m[0m | time: 3.076s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4961 -- iter: 0192/1392
[A[ATraining Step: 95  | total loss: [1m[32m0.69335[0m[0m | time: 3.677s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4934 -- iter: 0224/1392
[A[ATraining Step: 96  | total loss: [1m[32m0.69335[0m[0m | time: 4.281s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4909 -- iter: 0256/1392
[A[ATraining Step: 97  | total loss: [1m[32m0.69335[0m[0m | time: 4.894s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4887 -- iter: 0288/1392
[A[ATraining Step: 98  | total loss: [1m[32m0.69326[0m[0m | time: 5.485s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.4992 -- iter: 0320/1392
[A[ATraining Step: 99  | total loss: [1m[32m0.69314[0m[0m | time: 6.079s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.5180 -- iter: 0352/1392
[A[ATraining Step: 100  | total loss: [1m[32m0.69308[0m[0m | time: 6.672s
[2K
| Adam | epoch: 003 | loss: 0.69308 - acc: 0.5256 -- iter: 0384/1392
[A[ATraining Step: 101  | total loss: [1m[32m0.69315[0m[0m | time: 7.285s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5168 -- iter: 0416/1392
[A[ATraining Step: 102  | total loss: [1m[32m0.69318[0m[0m | time: 7.893s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.5120 -- iter: 0448/1392
[A[ATraining Step: 103  | total loss: [1m[32m0.69324[0m[0m | time: 8.488s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.5045 -- iter: 0480/1392
[A[ATraining Step: 104  | total loss: [1m[32m0.69303[0m[0m | time: 9.085s
[2K
| Adam | epoch: 003 | loss: 0.69303 - acc: 0.5197 -- iter: 0512/1392
[A[ATraining Step: 105  | total loss: [1m[32m0.69288[0m[0m | time: 9.718s
[2K
| Adam | epoch: 003 | loss: 0.69288 - acc: 0.5302 -- iter: 0544/1392
[A[ATraining Step: 106  | total loss: [1m[32m0.69290[0m[0m | time: 10.320s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5272 -- iter: 0576/1392
[A[ATraining Step: 107  | total loss: [1m[32m0.69288[0m[0m | time: 10.927s
[2K
| Adam | epoch: 003 | loss: 0.69288 - acc: 0.5276 -- iter: 0608/1392
[A[ATraining Step: 108  | total loss: [1m[32m0.69290[0m[0m | time: 11.530s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5249 -- iter: 0640/1392
[A[ATraining Step: 109  | total loss: [1m[32m0.69288[0m[0m | time: 12.124s
[2K
| Adam | epoch: 003 | loss: 0.69288 - acc: 0.5255 -- iter: 0672/1392
[A[ATraining Step: 110  | total loss: [1m[32m0.69291[0m[0m | time: 12.717s
[2K
| Adam | epoch: 003 | loss: 0.69291 - acc: 0.5229 -- iter: 0704/1392
[A[ATraining Step: 111  | total loss: [1m[32m0.69266[0m[0m | time: 13.314s
[2K
| Adam | epoch: 003 | loss: 0.69266 - acc: 0.5331 -- iter: 0736/1392
[A[ATraining Step: 112  | total loss: [1m[32m0.69255[0m[0m | time: 13.909s
[2K
| Adam | epoch: 003 | loss: 0.69255 - acc: 0.5361 -- iter: 0768/1392
[A[ATraining Step: 113  | total loss: [1m[32m0.69217[0m[0m | time: 14.531s
[2K
| Adam | epoch: 003 | loss: 0.69217 - acc: 0.5481 -- iter: 0800/1392
[A[ATraining Step: 114  | total loss: [1m[32m0.69262[0m[0m | time: 15.122s
[2K
| Adam | epoch: 003 | loss: 0.69262 - acc: 0.5339 -- iter: 0832/1392
[A[ATraining Step: 115  | total loss: [1m[32m0.69246[0m[0m | time: 15.727s
[2K
| Adam | epoch: 003 | loss: 0.69246 - acc: 0.5368 -- iter: 0864/1392
[A[ATraining Step: 116  | total loss: [1m[32m0.69242[0m[0m | time: 16.323s
[2K
| Adam | epoch: 003 | loss: 0.69242 - acc: 0.5362 -- iter: 0896/1392
[A[ATraining Step: 117  | total loss: [1m[32m0.69205[0m[0m | time: 16.925s
[2K
| Adam | epoch: 003 | loss: 0.69205 - acc: 0.5420 -- iter: 0928/1392
[A[ATraining Step: 118  | total loss: [1m[32m0.69290[0m[0m | time: 17.522s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5253 -- iter: 0960/1392
[A[ATraining Step: 119  | total loss: [1m[32m0.69351[0m[0m | time: 18.149s
[2K
| Adam | epoch: 003 | loss: 0.69351 - acc: 0.5134 -- iter: 0992/1392
[A[ATraining Step: 120  | total loss: [1m[32m0.69351[0m[0m | time: 18.745s
[2K
| Adam | epoch: 003 | loss: 0.69351 - acc: 0.5120 -- iter: 1024/1392
[A[ATraining Step: 121  | total loss: [1m[32m0.69331[0m[0m | time: 19.343s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.5140 -- iter: 1056/1392
[A[ATraining Step: 122  | total loss: [1m[32m0.69346[0m[0m | time: 19.968s
[2K
| Adam | epoch: 003 | loss: 0.69346 - acc: 0.5094 -- iter: 1088/1392
[A[ATraining Step: 123  | total loss: [1m[32m0.69427[0m[0m | time: 20.569s
[2K
| Adam | epoch: 003 | loss: 0.69427 - acc: 0.4897 -- iter: 1120/1392
[A[ATraining Step: 124  | total loss: [1m[32m0.69431[0m[0m | time: 21.174s
[2K
| Adam | epoch: 003 | loss: 0.69431 - acc: 0.4876 -- iter: 1152/1392
[A[ATraining Step: 125  | total loss: [1m[32m0.69409[0m[0m | time: 21.785s
[2K
| Adam | epoch: 003 | loss: 0.69409 - acc: 0.4920 -- iter: 1184/1392
[A[ATraining Step: 126  | total loss: [1m[32m0.69389[0m[0m | time: 22.389s
[2K
| Adam | epoch: 003 | loss: 0.69389 - acc: 0.4959 -- iter: 1216/1392
[A[ATraining Step: 127  | total loss: [1m[32m0.69373[0m[0m | time: 23.023s
[2K
| Adam | epoch: 003 | loss: 0.69373 - acc: 0.4995 -- iter: 1248/1392
[A[ATraining Step: 128  | total loss: [1m[32m0.69406[0m[0m | time: 23.669s
[2K
| Adam | epoch: 003 | loss: 0.69406 - acc: 0.4870 -- iter: 1280/1392
[A[ATraining Step: 129  | total loss: [1m[32m0.69371[0m[0m | time: 24.260s
[2K
| Adam | epoch: 003 | loss: 0.69371 - acc: 0.4977 -- iter: 1312/1392
[A[ATraining Step: 130  | total loss: [1m[32m0.69326[0m[0m | time: 24.885s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5135 -- iter: 1344/1392
[A[ATraining Step: 131  | total loss: [1m[32m0.69310[0m[0m | time: 25.481s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5184 -- iter: 1376/1392
[A[ATraining Step: 132  | total loss: [1m[32m0.69327[0m[0m | time: 27.434s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.5103 | val_loss: 0.69291 - val_acc: 0.5103 -- iter: 1392/1392
--
Training Step: 133  | total loss: [1m[32m0.69307[0m[0m | time: 0.593s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5156 -- iter: 0032/1392
[A[ATraining Step: 134  | total loss: [1m[32m0.69268[0m[0m | time: 0.900s
[2K
| Adam | epoch: 004 | loss: 0.69268 - acc: 0.5296 -- iter: 0064/1392
[A[ATraining Step: 135  | total loss: [1m[32m0.69256[0m[0m | time: 1.207s
[2K
| Adam | epoch: 004 | loss: 0.69256 - acc: 0.5329 -- iter: 0096/1392
[A[ATraining Step: 136  | total loss: [1m[32m0.69244[0m[0m | time: 1.819s
[2K
| Adam | epoch: 004 | loss: 0.69244 - acc: 0.5359 -- iter: 0128/1392
[A[ATraining Step: 137  | total loss: [1m[32m0.69232[0m[0m | time: 2.420s
[2K
| Adam | epoch: 004 | loss: 0.69232 - acc: 0.5385 -- iter: 0160/1392
[A[ATraining Step: 138  | total loss: [1m[32m0.69260[0m[0m | time: 3.042s
[2K
| Adam | epoch: 004 | loss: 0.69260 - acc: 0.5284 -- iter: 0192/1392
[A[ATraining Step: 139  | total loss: [1m[32m0.69300[0m[0m | time: 3.627s
[2K
| Adam | epoch: 004 | loss: 0.69300 - acc: 0.5162 -- iter: 0224/1392
[A[ATraining Step: 140  | total loss: [1m[32m0.69312[0m[0m | time: 4.218s
[2K
| Adam | epoch: 004 | loss: 0.69312 - acc: 0.5115 -- iter: 0256/1392
[A[ATraining Step: 141  | total loss: [1m[32m0.69334[0m[0m | time: 4.822s
[2K
| Adam | epoch: 004 | loss: 0.69334 - acc: 0.5041 -- iter: 0288/1392
[A[ATraining Step: 142  | total loss: [1m[32m0.69388[0m[0m | time: 5.424s
[2K
| Adam | epoch: 004 | loss: 0.69388 - acc: 0.4880 -- iter: 0320/1392
[A[ATraining Step: 143  | total loss: [1m[32m0.69382[0m[0m | time: 6.033s
[2K
| Adam | epoch: 004 | loss: 0.69382 - acc: 0.4892 -- iter: 0352/1392
[A[ATraining Step: 144  | total loss: [1m[32m0.69384[0m[0m | time: 6.629s
[2K
| Adam | epoch: 004 | loss: 0.69384 - acc: 0.4872 -- iter: 0384/1392
[A[ATraining Step: 145  | total loss: [1m[32m0.69386[0m[0m | time: 7.236s
[2K
| Adam | epoch: 004 | loss: 0.69386 - acc: 0.4853 -- iter: 0416/1392
[A[ATraining Step: 146  | total loss: [1m[32m0.69424[0m[0m | time: 7.846s
[2K
| Adam | epoch: 004 | loss: 0.69424 - acc: 0.4712 -- iter: 0448/1392
[A[ATraining Step: 147  | total loss: [1m[32m0.69379[0m[0m | time: 8.458s
[2K
| Adam | epoch: 004 | loss: 0.69379 - acc: 0.4866 -- iter: 0480/1392
[A[ATraining Step: 148  | total loss: [1m[32m0.69350[0m[0m | time: 9.070s
[2K
| Adam | epoch: 004 | loss: 0.69350 - acc: 0.4973 -- iter: 0512/1392
[A[ATraining Step: 149  | total loss: [1m[32m0.69344[0m[0m | time: 9.684s
[2K
| Adam | epoch: 004 | loss: 0.69344 - acc: 0.4976 -- iter: 0544/1392
[A[ATraining Step: 150  | total loss: [1m[32m0.69298[0m[0m | time: 10.299s
[2K
| Adam | epoch: 004 | loss: 0.69298 - acc: 0.5166 -- iter: 0576/1392
[A[ATraining Step: 151  | total loss: [1m[32m0.69302[0m[0m | time: 10.904s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5149 -- iter: 0608/1392
[A[ATraining Step: 152  | total loss: [1m[32m0.69325[0m[0m | time: 11.512s
[2K
| Adam | epoch: 004 | loss: 0.69325 - acc: 0.5040 -- iter: 0640/1392
[A[ATraining Step: 153  | total loss: [1m[32m0.69333[0m[0m | time: 12.164s
[2K
| Adam | epoch: 004 | loss: 0.69333 - acc: 0.5005 -- iter: 0672/1392
[A[ATraining Step: 154  | total loss: [1m[32m0.69303[0m[0m | time: 12.780s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5130 -- iter: 0704/1392
[A[ATraining Step: 155  | total loss: [1m[32m0.69301[0m[0m | time: 13.407s
[2K
| Adam | epoch: 004 | loss: 0.69301 - acc: 0.5117 -- iter: 0736/1392
[A[ATraining Step: 156  | total loss: [1m[32m0.69325[0m[0m | time: 14.007s
[2K
| Adam | epoch: 004 | loss: 0.69325 - acc: 0.5011 -- iter: 0768/1392
[A[ATraining Step: 157  | total loss: [1m[32m0.69354[0m[0m | time: 14.615s
[2K
| Adam | epoch: 004 | loss: 0.69354 - acc: 0.4885 -- iter: 0800/1392
[A[ATraining Step: 158  | total loss: [1m[32m0.69393[0m[0m | time: 15.247s
[2K
| Adam | epoch: 004 | loss: 0.69393 - acc: 0.4709 -- iter: 0832/1392
[A[ATraining Step: 159  | total loss: [1m[32m0.69440[0m[0m | time: 15.851s
[2K
| Adam | epoch: 004 | loss: 0.69440 - acc: 0.4457 -- iter: 0864/1392
[A[ATraining Step: 160  | total loss: [1m[32m0.69420[0m[0m | time: 16.451s
[2K
| Adam | epoch: 004 | loss: 0.69420 - acc: 0.4542 -- iter: 0896/1392
[A[ATraining Step: 161  | total loss: [1m[32m0.69400[0m[0m | time: 17.055s
[2K
| Adam | epoch: 004 | loss: 0.69400 - acc: 0.4651 -- iter: 0928/1392
[A[ATraining Step: 162  | total loss: [1m[32m0.69392[0m[0m | time: 17.650s
[2K
| Adam | epoch: 004 | loss: 0.69392 - acc: 0.4654 -- iter: 0960/1392
[A[ATraining Step: 163  | total loss: [1m[32m0.69387[0m[0m | time: 18.249s
[2K
| Adam | epoch: 004 | loss: 0.69387 - acc: 0.4626 -- iter: 0992/1392
[A[ATraining Step: 164  | total loss: [1m[32m0.69377[0m[0m | time: 18.849s
[2K
| Adam | epoch: 004 | loss: 0.69377 - acc: 0.4695 -- iter: 1024/1392
[A[ATraining Step: 165  | total loss: [1m[32m0.69373[0m[0m | time: 19.451s
[2K
| Adam | epoch: 004 | loss: 0.69373 - acc: 0.4663 -- iter: 1056/1392
[A[ATraining Step: 166  | total loss: [1m[32m0.69363[0m[0m | time: 20.037s
[2K
| Adam | epoch: 004 | loss: 0.69363 - acc: 0.4884 -- iter: 1088/1392
[A[ATraining Step: 167  | total loss: [1m[32m0.69358[0m[0m | time: 20.660s
[2K
| Adam | epoch: 004 | loss: 0.69358 - acc: 0.4958 -- iter: 1120/1392
[A[ATraining Step: 168  | total loss: [1m[32m0.69351[0m[0m | time: 21.252s
[2K
| Adam | epoch: 004 | loss: 0.69351 - acc: 0.5087 -- iter: 1152/1392
[A[ATraining Step: 169  | total loss: [1m[32m0.69341[0m[0m | time: 21.876s
[2K
| Adam | epoch: 004 | loss: 0.69341 - acc: 0.5141 -- iter: 1184/1392
[A[ATraining Step: 170  | total loss: [1m[32m0.69342[0m[0m | time: 22.482s
[2K
| Adam | epoch: 004 | loss: 0.69342 - acc: 0.5002 -- iter: 1216/1392
[A[ATraining Step: 171  | total loss: [1m[32m0.69337[0m[0m | time: 23.072s
[2K
| Adam | epoch: 004 | loss: 0.69337 - acc: 0.5064 -- iter: 1248/1392
[A[ATraining Step: 172  | total loss: [1m[32m0.69327[0m[0m | time: 23.691s
[2K
| Adam | epoch: 004 | loss: 0.69327 - acc: 0.5245 -- iter: 1280/1392
[A[ATraining Step: 173  | total loss: [1m[32m0.69330[0m[0m | time: 24.315s
[2K
| Adam | epoch: 004 | loss: 0.69330 - acc: 0.5127 -- iter: 1312/1392
[A[ATraining Step: 174  | total loss: [1m[32m0.69326[0m[0m | time: 24.924s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.5114 -- iter: 1344/1392
[A[ATraining Step: 175  | total loss: [1m[32m0.69329[0m[0m | time: 25.540s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.5041 -- iter: 1376/1392
[A[ATraining Step: 176  | total loss: [1m[32m0.69320[0m[0m | time: 27.481s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.5099 | val_loss: 0.69273 - val_acc: 0.5310 -- iter: 1392/1392
--
Training Step: 177  | total loss: [1m[32m0.69317[0m[0m | time: 0.600s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.5027 -- iter: 0032/1392
[A[ATraining Step: 178  | total loss: [1m[32m0.69312[0m[0m | time: 1.222s
[2K
| Adam | epoch: 005 | loss: 0.69312 - acc: 0.5024 -- iter: 0064/1392
[A[ATraining Step: 179  | total loss: [1m[32m0.69301[0m[0m | time: 1.538s
[2K
| Adam | epoch: 005 | loss: 0.69301 - acc: 0.5178 -- iter: 0096/1392
[A[ATraining Step: 180  | total loss: [1m[32m0.69289[0m[0m | time: 1.845s
[2K
| Adam | epoch: 005 | loss: 0.69289 - acc: 0.5285 -- iter: 0128/1392
[A[ATraining Step: 181  | total loss: [1m[32m0.69267[0m[0m | time: 2.444s
[2K
| Adam | epoch: 005 | loss: 0.69267 - acc: 0.5506 -- iter: 0160/1392
[A[ATraining Step: 182  | total loss: [1m[32m0.69276[0m[0m | time: 3.026s
[2K
| Adam | epoch: 005 | loss: 0.69276 - acc: 0.5425 -- iter: 0192/1392
[A[ATraining Step: 183  | total loss: [1m[32m0.69258[0m[0m | time: 3.649s
[2K
| Adam | epoch: 005 | loss: 0.69258 - acc: 0.5507 -- iter: 0224/1392
[A[ATraining Step: 184  | total loss: [1m[32m0.69239[0m[0m | time: 4.296s
[2K
| Adam | epoch: 005 | loss: 0.69239 - acc: 0.5581 -- iter: 0256/1392
[A[ATraining Step: 185  | total loss: [1m[32m0.69239[0m[0m | time: 4.883s
[2K
| Adam | epoch: 005 | loss: 0.69239 - acc: 0.5555 -- iter: 0288/1392
[A[ATraining Step: 186  | total loss: [1m[32m0.69233[0m[0m | time: 5.484s
[2K
| Adam | epoch: 005 | loss: 0.69233 - acc: 0.5530 -- iter: 0320/1392
[A[ATraining Step: 187  | total loss: [1m[32m0.69237[0m[0m | time: 6.085s
[2K
| Adam | epoch: 005 | loss: 0.69237 - acc: 0.5477 -- iter: 0352/1392
[A[ATraining Step: 188  | total loss: [1m[32m0.69244[0m[0m | time: 6.679s
[2K
| Adam | epoch: 005 | loss: 0.69244 - acc: 0.5430 -- iter: 0384/1392
[A[ATraining Step: 189  | total loss: [1m[32m0.69217[0m[0m | time: 7.281s
[2K
| Adam | epoch: 005 | loss: 0.69217 - acc: 0.5449 -- iter: 0416/1392
[A[ATraining Step: 190  | total loss: [1m[32m0.69268[0m[0m | time: 7.869s
[2K
| Adam | epoch: 005 | loss: 0.69268 - acc: 0.5342 -- iter: 0448/1392
[A[ATraining Step: 191  | total loss: [1m[32m0.69183[0m[0m | time: 8.464s
[2K
| Adam | epoch: 005 | loss: 0.69183 - acc: 0.5433 -- iter: 0480/1392
[A[ATraining Step: 192  | total loss: [1m[32m0.69281[0m[0m | time: 9.069s
[2K
| Adam | epoch: 005 | loss: 0.69281 - acc: 0.5296 -- iter: 0512/1392
[A[ATraining Step: 193  | total loss: [1m[32m0.69215[0m[0m | time: 9.665s
[2K
| Adam | epoch: 005 | loss: 0.69215 - acc: 0.5360 -- iter: 0544/1392
[A[ATraining Step: 194  | total loss: [1m[32m0.69299[0m[0m | time: 10.267s
[2K
| Adam | epoch: 005 | loss: 0.69299 - acc: 0.5230 -- iter: 0576/1392
[A[ATraining Step: 195  | total loss: [1m[32m0.69346[0m[0m | time: 10.867s
[2K
| Adam | epoch: 005 | loss: 0.69346 - acc: 0.5144 -- iter: 0608/1392
[A[ATraining Step: 196  | total loss: [1m[32m0.69338[0m[0m | time: 11.466s
[2K
| Adam | epoch: 005 | loss: 0.69338 - acc: 0.5130 -- iter: 0640/1392
[A[ATraining Step: 197  | total loss: [1m[32m0.69371[0m[0m | time: 12.066s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.5055 -- iter: 0672/1392
[A[ATraining Step: 198  | total loss: [1m[32m0.69362[0m[0m | time: 12.666s
[2K
| Adam | epoch: 005 | loss: 0.69362 - acc: 0.5049 -- iter: 0704/1392
[A[ATraining Step: 199  | total loss: [1m[32m0.69394[0m[0m | time: 13.284s
[2K
| Adam | epoch: 005 | loss: 0.69394 - acc: 0.4950 -- iter: 0736/1392
[A[ATraining Step: 200  | total loss: [1m[32m0.69370[0m[0m | time: 15.242s
[2K
| Adam | epoch: 005 | loss: 0.69370 - acc: 0.5018 | val_loss: 0.69248 - val_acc: 0.5103 -- iter: 0768/1392
--
Training Step: 201  | total loss: [1m[32m0.69359[0m[0m | time: 15.832s
[2K
| Adam | epoch: 005 | loss: 0.69359 - acc: 0.5016 -- iter: 0800/1392
[A[ATraining Step: 202  | total loss: [1m[32m0.69332[0m[0m | time: 16.428s
[2K
| Adam | epoch: 005 | loss: 0.69332 - acc: 0.5077 -- iter: 0832/1392
[A[ATraining Step: 203  | total loss: [1m[32m0.69303[0m[0m | time: 17.020s
[2K
| Adam | epoch: 005 | loss: 0.69303 - acc: 0.5163 -- iter: 0864/1392
[A[ATraining Step: 204  | total loss: [1m[32m0.69317[0m[0m | time: 17.649s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.5053 -- iter: 0896/1392
[A[ATraining Step: 205  | total loss: [1m[32m0.69307[0m[0m | time: 18.258s
[2K
| Adam | epoch: 005 | loss: 0.69307 - acc: 0.5048 -- iter: 0928/1392
[A[ATraining Step: 206  | total loss: [1m[32m0.69294[0m[0m | time: 18.863s
[2K
| Adam | epoch: 005 | loss: 0.69294 - acc: 0.5074 -- iter: 0960/1392
[A[ATraining Step: 207  | total loss: [1m[32m0.69295[0m[0m | time: 19.461s
[2K
| Adam | epoch: 005 | loss: 0.69295 - acc: 0.5098 -- iter: 0992/1392
[A[ATraining Step: 208  | total loss: [1m[32m0.69290[0m[0m | time: 20.060s
[2K
| Adam | epoch: 005 | loss: 0.69290 - acc: 0.5151 -- iter: 1024/1392
[A[ATraining Step: 209  | total loss: [1m[32m0.69283[0m[0m | time: 20.710s
[2K
| Adam | epoch: 005 | loss: 0.69283 - acc: 0.5229 -- iter: 1056/1392
[A[ATraining Step: 210  | total loss: [1m[32m0.69290[0m[0m | time: 21.310s
[2K
| Adam | epoch: 005 | loss: 0.69290 - acc: 0.5206 -- iter: 1088/1392
[A[ATraining Step: 211  | total loss: [1m[32m0.69259[0m[0m | time: 21.900s
[2K
| Adam | epoch: 005 | loss: 0.69259 - acc: 0.5248 -- iter: 1120/1392
[A[ATraining Step: 212  | total loss: [1m[32m0.69242[0m[0m | time: 22.500s
[2K
| Adam | epoch: 005 | loss: 0.69242 - acc: 0.5255 -- iter: 1152/1392
[A[ATraining Step: 213  | total loss: [1m[32m0.69196[0m[0m | time: 23.127s
[2K
| Adam | epoch: 005 | loss: 0.69196 - acc: 0.5354 -- iter: 1184/1392
[A[ATraining Step: 214  | total loss: [1m[32m0.69205[0m[0m | time: 23.721s
[2K
| Adam | epoch: 005 | loss: 0.69205 - acc: 0.5288 -- iter: 1216/1392
[A[ATraining Step: 215  | total loss: [1m[32m0.69150[0m[0m | time: 24.348s
[2K
| Adam | epoch: 005 | loss: 0.69150 - acc: 0.5415 -- iter: 1248/1392
[A[ATraining Step: 216  | total loss: [1m[32m0.69134[0m[0m | time: 24.953s
[2K
| Adam | epoch: 005 | loss: 0.69134 - acc: 0.5405 -- iter: 1280/1392
[A[ATraining Step: 217  | total loss: [1m[32m0.69115[0m[0m | time: 25.550s
[2K
| Adam | epoch: 005 | loss: 0.69115 - acc: 0.5396 -- iter: 1312/1392
[A[ATraining Step: 218  | total loss: [1m[32m0.69210[0m[0m | time: 26.152s
[2K
| Adam | epoch: 005 | loss: 0.69210 - acc: 0.5262 -- iter: 1344/1392
[A[ATraining Step: 219  | total loss: [1m[32m0.69265[0m[0m | time: 26.745s
[2K
| Adam | epoch: 005 | loss: 0.69265 - acc: 0.5174 -- iter: 1376/1392
[A[ATraining Step: 220  | total loss: [1m[32m0.69218[0m[0m | time: 28.728s
[2K
| Adam | epoch: 005 | loss: 0.69218 - acc: 0.5250 | val_loss: 0.68746 - val_acc: 0.5448 -- iter: 1392/1392
--
Training Step: 221  | total loss: [1m[32m0.69050[0m[0m | time: 0.615s
[2K
| Adam | epoch: 006 | loss: 0.69050 - acc: 0.5506 -- iter: 0032/1392
[A[ATraining Step: 222  | total loss: [1m[32m0.68912[0m[0m | time: 1.209s
[2K
| Adam | epoch: 006 | loss: 0.68912 - acc: 0.5643 -- iter: 0064/1392
[A[ATraining Step: 223  | total loss: [1m[32m0.68908[0m[0m | time: 1.805s
[2K
| Adam | epoch: 006 | loss: 0.68908 - acc: 0.5610 -- iter: 0096/1392
[A[ATraining Step: 224  | total loss: [1m[32m0.68608[0m[0m | time: 2.122s
[2K
| Adam | epoch: 006 | loss: 0.68608 - acc: 0.5799 -- iter: 0128/1392
[A[ATraining Step: 225  | total loss: [1m[32m0.68804[0m[0m | time: 2.447s
[2K
| Adam | epoch: 006 | loss: 0.68804 - acc: 0.5719 -- iter: 0160/1392
[A[ATraining Step: 226  | total loss: [1m[32m0.68970[0m[0m | time: 3.054s
[2K
| Adam | epoch: 006 | loss: 0.68970 - acc: 0.5647 -- iter: 0192/1392
[A[ATraining Step: 227  | total loss: [1m[32m0.68579[0m[0m | time: 3.649s
[2K
| Adam | epoch: 006 | loss: 0.68579 - acc: 0.5770 -- iter: 0224/1392
[A[ATraining Step: 228  | total loss: [1m[32m0.68598[0m[0m | time: 4.256s
[2K
| Adam | epoch: 006 | loss: 0.68598 - acc: 0.5724 -- iter: 0256/1392
[A[ATraining Step: 229  | total loss: [1m[32m0.68704[0m[0m | time: 4.852s
[2K
| Adam | epoch: 006 | loss: 0.68704 - acc: 0.5683 -- iter: 0288/1392
[A[ATraining Step: 230  | total loss: [1m[32m0.68773[0m[0m | time: 5.435s
[2K
| Adam | epoch: 006 | loss: 0.68773 - acc: 0.5677 -- iter: 0320/1392
[A[ATraining Step: 231  | total loss: [1m[32m0.68929[0m[0m | time: 6.051s
[2K
| Adam | epoch: 006 | loss: 0.68929 - acc: 0.5485 -- iter: 0352/1392
[A[ATraining Step: 232  | total loss: [1m[32m0.68736[0m[0m | time: 6.651s
[2K
| Adam | epoch: 006 | loss: 0.68736 - acc: 0.5624 -- iter: 0384/1392
[A[ATraining Step: 233  | total loss: [1m[32m0.68716[0m[0m | time: 7.246s
[2K
| Adam | epoch: 006 | loss: 0.68716 - acc: 0.5592 -- iter: 0416/1392
[A[ATraining Step: 234  | total loss: [1m[32m0.68828[0m[0m | time: 7.855s
[2K
| Adam | epoch: 006 | loss: 0.68828 - acc: 0.5533 -- iter: 0448/1392
[A[ATraining Step: 235  | total loss: [1m[32m0.68598[0m[0m | time: 8.475s
[2K
| Adam | epoch: 006 | loss: 0.68598 - acc: 0.5605 -- iter: 0480/1392
[A[ATraining Step: 236  | total loss: [1m[32m0.68789[0m[0m | time: 9.074s
[2K
| Adam | epoch: 006 | loss: 0.68789 - acc: 0.5544 -- iter: 0512/1392
[A[ATraining Step: 237  | total loss: [1m[32m0.68923[0m[0m | time: 9.668s
[2K
| Adam | epoch: 006 | loss: 0.68923 - acc: 0.5490 -- iter: 0544/1392
[A[ATraining Step: 238  | total loss: [1m[32m0.68541[0m[0m | time: 10.279s
[2K
| Adam | epoch: 006 | loss: 0.68541 - acc: 0.5628 -- iter: 0576/1392
[A[ATraining Step: 239  | total loss: [1m[32m0.68499[0m[0m | time: 10.873s
[2K
| Adam | epoch: 006 | loss: 0.68499 - acc: 0.5628 -- iter: 0608/1392
[A[ATraining Step: 240  | total loss: [1m[32m0.68775[0m[0m | time: 11.467s
[2K
| Adam | epoch: 006 | loss: 0.68775 - acc: 0.5534 -- iter: 0640/1392
[A[ATraining Step: 241  | total loss: [1m[32m0.68641[0m[0m | time: 12.078s
[2K
| Adam | epoch: 006 | loss: 0.68641 - acc: 0.5574 -- iter: 0672/1392
[A[ATraining Step: 242  | total loss: [1m[32m0.68724[0m[0m | time: 12.688s
[2K
| Adam | epoch: 006 | loss: 0.68724 - acc: 0.5517 -- iter: 0704/1392
[A[ATraining Step: 243  | total loss: [1m[32m0.68641[0m[0m | time: 13.278s
[2K
| Adam | epoch: 006 | loss: 0.68641 - acc: 0.5528 -- iter: 0736/1392
[A[ATraining Step: 244  | total loss: [1m[32m0.68682[0m[0m | time: 13.882s
[2K
| Adam | epoch: 006 | loss: 0.68682 - acc: 0.5475 -- iter: 0768/1392
[A[ATraining Step: 245  | total loss: [1m[32m0.68454[0m[0m | time: 14.469s
[2K
| Adam | epoch: 006 | loss: 0.68454 - acc: 0.5584 -- iter: 0800/1392
[A[ATraining Step: 246  | total loss: [1m[32m0.68566[0m[0m | time: 15.075s
[2K
| Adam | epoch: 006 | loss: 0.68566 - acc: 0.5494 -- iter: 0832/1392
[A[ATraining Step: 247  | total loss: [1m[32m0.68711[0m[0m | time: 15.675s
[2K
| Adam | epoch: 006 | loss: 0.68711 - acc: 0.5413 -- iter: 0864/1392
[A[ATraining Step: 248  | total loss: [1m[32m0.68945[0m[0m | time: 16.269s
[2K
| Adam | epoch: 006 | loss: 0.68945 - acc: 0.5247 -- iter: 0896/1392
[A[ATraining Step: 249  | total loss: [1m[32m0.68709[0m[0m | time: 16.882s
[2K
| Adam | epoch: 006 | loss: 0.68709 - acc: 0.5347 -- iter: 0928/1392
[A[ATraining Step: 250  | total loss: [1m[32m0.68346[0m[0m | time: 17.481s
[2K
| Adam | epoch: 006 | loss: 0.68346 - acc: 0.5531 -- iter: 0960/1392
[A[ATraining Step: 251  | total loss: [1m[32m0.68561[0m[0m | time: 18.084s
[2K
| Adam | epoch: 006 | loss: 0.68561 - acc: 0.5353 -- iter: 0992/1392
[A[ATraining Step: 252  | total loss: [1m[32m0.68747[0m[0m | time: 18.684s
[2K
| Adam | epoch: 006 | loss: 0.68747 - acc: 0.5255 -- iter: 1024/1392
[A[ATraining Step: 253  | total loss: [1m[32m0.68765[0m[0m | time: 19.273s
[2K
| Adam | epoch: 006 | loss: 0.68765 - acc: 0.5136 -- iter: 1056/1392
[A[ATraining Step: 254  | total loss: [1m[32m0.68647[0m[0m | time: 19.864s
[2K
| Adam | epoch: 006 | loss: 0.68647 - acc: 0.5216 -- iter: 1088/1392
[A[ATraining Step: 255  | total loss: [1m[32m0.68678[0m[0m | time: 20.460s
[2K
| Adam | epoch: 006 | loss: 0.68678 - acc: 0.5226 -- iter: 1120/1392
[A[ATraining Step: 256  | total loss: [1m[32m0.68421[0m[0m | time: 21.061s
[2K
| Adam | epoch: 006 | loss: 0.68421 - acc: 0.5391 -- iter: 1152/1392
[A[ATraining Step: 257  | total loss: [1m[32m0.68407[0m[0m | time: 21.663s
[2K
| Adam | epoch: 006 | loss: 0.68407 - acc: 0.5289 -- iter: 1184/1392
[A[ATraining Step: 258  | total loss: [1m[32m0.68265[0m[0m | time: 22.258s
[2K
| Adam | epoch: 006 | loss: 0.68265 - acc: 0.5292 -- iter: 1216/1392
[A[ATraining Step: 259  | total loss: [1m[32m0.67982[0m[0m | time: 22.862s
[2K
| Adam | epoch: 006 | loss: 0.67982 - acc: 0.5325 -- iter: 1248/1392
[A[ATraining Step: 260  | total loss: [1m[32m0.68017[0m[0m | time: 23.447s
[2K
| Adam | epoch: 006 | loss: 0.68017 - acc: 0.5449 -- iter: 1280/1392
[A[ATraining Step: 261  | total loss: [1m[32m0.68344[0m[0m | time: 24.051s
[2K
| Adam | epoch: 006 | loss: 0.68344 - acc: 0.5279 -- iter: 1312/1392
[A[ATraining Step: 262  | total loss: [1m[32m0.68169[0m[0m | time: 24.657s
[2K
| Adam | epoch: 006 | loss: 0.68169 - acc: 0.5438 -- iter: 1344/1392
[A[ATraining Step: 263  | total loss: [1m[32m0.68027[0m[0m | time: 25.260s
[2K
| Adam | epoch: 006 | loss: 0.68027 - acc: 0.5426 -- iter: 1376/1392
[A[ATraining Step: 264  | total loss: [1m[32m0.67837[0m[0m | time: 27.205s
[2K
| Adam | epoch: 006 | loss: 0.67837 - acc: 0.5539 | val_loss: 0.67281 - val_acc: 0.5931 -- iter: 1392/1392
--
Training Step: 265  | total loss: [1m[32m0.67500[0m[0m | time: 0.599s
[2K
| Adam | epoch: 007 | loss: 0.67500 - acc: 0.5642 -- iter: 0032/1392
[A[ATraining Step: 266  | total loss: [1m[32m0.67884[0m[0m | time: 1.196s
[2K
| Adam | epoch: 007 | loss: 0.67884 - acc: 0.5578 -- iter: 0064/1392
[A[ATraining Step: 267  | total loss: [1m[32m0.67491[0m[0m | time: 1.797s
[2K
| Adam | epoch: 007 | loss: 0.67491 - acc: 0.5676 -- iter: 0096/1392
[A[ATraining Step: 268  | total loss: [1m[32m0.67166[0m[0m | time: 2.394s
[2K
| Adam | epoch: 007 | loss: 0.67166 - acc: 0.5765 -- iter: 0128/1392
[A[ATraining Step: 269  | total loss: [1m[32m0.67120[0m[0m | time: 2.708s
[2K
| Adam | epoch: 007 | loss: 0.67120 - acc: 0.5813 -- iter: 0160/1392
[A[ATraining Step: 270  | total loss: [1m[32m0.68759[0m[0m | time: 3.014s
[2K
| Adam | epoch: 007 | loss: 0.68759 - acc: 0.5607 -- iter: 0192/1392
[A[ATraining Step: 271  | total loss: [1m[32m0.69676[0m[0m | time: 3.624s
[2K
| Adam | epoch: 007 | loss: 0.69676 - acc: 0.5421 -- iter: 0224/1392
[A[ATraining Step: 272  | total loss: [1m[32m0.69434[0m[0m | time: 4.242s
[2K
| Adam | epoch: 007 | loss: 0.69434 - acc: 0.5473 -- iter: 0256/1392
[A[ATraining Step: 273  | total loss: [1m[32m0.69088[0m[0m | time: 4.851s
[2K
| Adam | epoch: 007 | loss: 0.69088 - acc: 0.5582 -- iter: 0288/1392
[A[ATraining Step: 274  | total loss: [1m[32m0.68968[0m[0m | time: 5.439s
[2K
| Adam | epoch: 007 | loss: 0.68968 - acc: 0.5617 -- iter: 0320/1392
[A[ATraining Step: 275  | total loss: [1m[32m0.68745[0m[0m | time: 6.066s
[2K
| Adam | epoch: 007 | loss: 0.68745 - acc: 0.5743 -- iter: 0352/1392
[A[ATraining Step: 276  | total loss: [1m[32m0.68851[0m[0m | time: 6.663s
[2K
| Adam | epoch: 007 | loss: 0.68851 - acc: 0.5638 -- iter: 0384/1392
[A[ATraining Step: 277  | total loss: [1m[32m0.68896[0m[0m | time: 7.270s
[2K
| Adam | epoch: 007 | loss: 0.68896 - acc: 0.5511 -- iter: 0416/1392
[A[ATraining Step: 278  | total loss: [1m[32m0.68564[0m[0m | time: 7.866s
[2K
| Adam | epoch: 007 | loss: 0.68564 - acc: 0.5554 -- iter: 0448/1392
[A[ATraining Step: 279  | total loss: [1m[32m0.67772[0m[0m | time: 8.458s
[2K
| Adam | epoch: 007 | loss: 0.67772 - acc: 0.5717 -- iter: 0480/1392
[A[ATraining Step: 280  | total loss: [1m[32m0.67716[0m[0m | time: 9.080s
[2K
| Adam | epoch: 007 | loss: 0.67716 - acc: 0.5677 -- iter: 0512/1392
[A[ATraining Step: 281  | total loss: [1m[32m0.67464[0m[0m | time: 9.704s
[2K
| Adam | epoch: 007 | loss: 0.67464 - acc: 0.5672 -- iter: 0544/1392
[A[ATraining Step: 282  | total loss: [1m[32m0.67666[0m[0m | time: 10.312s
[2K
| Adam | epoch: 007 | loss: 0.67666 - acc: 0.5604 -- iter: 0576/1392
[A[ATraining Step: 283  | total loss: [1m[32m0.67677[0m[0m | time: 10.917s
[2K
| Adam | epoch: 007 | loss: 0.67677 - acc: 0.5638 -- iter: 0608/1392
[A[ATraining Step: 284  | total loss: [1m[32m0.67189[0m[0m | time: 11.523s
[2K
| Adam | epoch: 007 | loss: 0.67189 - acc: 0.5637 -- iter: 0640/1392
[A[ATraining Step: 285  | total loss: [1m[32m0.66817[0m[0m | time: 12.132s
[2K
| Adam | epoch: 007 | loss: 0.66817 - acc: 0.5792 -- iter: 0672/1392
[A[ATraining Step: 286  | total loss: [1m[32m0.66465[0m[0m | time: 12.738s
[2K
| Adam | epoch: 007 | loss: 0.66465 - acc: 0.5806 -- iter: 0704/1392
[A[ATraining Step: 287  | total loss: [1m[32m0.66212[0m[0m | time: 13.335s
[2K
| Adam | epoch: 007 | loss: 0.66212 - acc: 0.5976 -- iter: 0736/1392
[A[ATraining Step: 288  | total loss: [1m[32m0.66985[0m[0m | time: 13.950s
[2K
| Adam | epoch: 007 | loss: 0.66985 - acc: 0.6034 -- iter: 0768/1392
[A[ATraining Step: 289  | total loss: [1m[32m0.66918[0m[0m | time: 14.544s
[2K
| Adam | epoch: 007 | loss: 0.66918 - acc: 0.5993 -- iter: 0800/1392
[A[ATraining Step: 290  | total loss: [1m[32m0.66596[0m[0m | time: 15.146s
[2K
| Adam | epoch: 007 | loss: 0.66596 - acc: 0.6082 -- iter: 0832/1392
[A[ATraining Step: 291  | total loss: [1m[32m0.66334[0m[0m | time: 15.745s
[2K
| Adam | epoch: 007 | loss: 0.66334 - acc: 0.6161 -- iter: 0864/1392
[A[ATraining Step: 292  | total loss: [1m[32m0.65881[0m[0m | time: 16.339s
[2K
| Adam | epoch: 007 | loss: 0.65881 - acc: 0.6420 -- iter: 0896/1392
[A[ATraining Step: 293  | total loss: [1m[32m0.65834[0m[0m | time: 16.919s
[2K
| Adam | epoch: 007 | loss: 0.65834 - acc: 0.6403 -- iter: 0928/1392
[A[ATraining Step: 294  | total loss: [1m[32m0.66814[0m[0m | time: 17.530s
[2K
| Adam | epoch: 007 | loss: 0.66814 - acc: 0.6200 -- iter: 0960/1392
[A[ATraining Step: 295  | total loss: [1m[32m0.67974[0m[0m | time: 18.129s
[2K
| Adam | epoch: 007 | loss: 0.67974 - acc: 0.6049 -- iter: 0992/1392
[A[ATraining Step: 296  | total loss: [1m[32m0.67291[0m[0m | time: 18.756s
[2K
| Adam | epoch: 007 | loss: 0.67291 - acc: 0.6225 -- iter: 1024/1392
[A[ATraining Step: 297  | total loss: [1m[32m0.67231[0m[0m | time: 19.350s
[2K
| Adam | epoch: 007 | loss: 0.67231 - acc: 0.6165 -- iter: 1056/1392
[A[ATraining Step: 298  | total loss: [1m[32m0.67372[0m[0m | time: 19.950s
[2K
| Adam | epoch: 007 | loss: 0.67372 - acc: 0.6080 -- iter: 1088/1392
[A[ATraining Step: 299  | total loss: [1m[32m0.67192[0m[0m | time: 20.569s
[2K
| Adam | epoch: 007 | loss: 0.67192 - acc: 0.6066 -- iter: 1120/1392
[A[ATraining Step: 300  | total loss: [1m[32m0.66776[0m[0m | time: 21.203s
[2K
| Adam | epoch: 007 | loss: 0.66776 - acc: 0.6209 -- iter: 1152/1392
[A[ATraining Step: 301  | total loss: [1m[32m0.66884[0m[0m | time: 21.810s
[2K
| Adam | epoch: 007 | loss: 0.66884 - acc: 0.6119 -- iter: 1184/1392
[A[ATraining Step: 302  | total loss: [1m[32m0.67175[0m[0m | time: 22.412s
[2K
| Adam | epoch: 007 | loss: 0.67175 - acc: 0.6007 -- iter: 1216/1392
[A[ATraining Step: 303  | total loss: [1m[32m0.67500[0m[0m | time: 23.006s
[2K
| Adam | epoch: 007 | loss: 0.67500 - acc: 0.5875 -- iter: 1248/1392
[A[ATraining Step: 304  | total loss: [1m[32m0.67856[0m[0m | time: 23.614s
[2K
| Adam | epoch: 007 | loss: 0.67856 - acc: 0.5788 -- iter: 1280/1392
[A[ATraining Step: 305  | total loss: [1m[32m0.67666[0m[0m | time: 24.241s
[2K
| Adam | epoch: 007 | loss: 0.67666 - acc: 0.5803 -- iter: 1312/1392
[A[ATraining Step: 306  | total loss: [1m[32m0.68139[0m[0m | time: 24.842s
[2K
| Adam | epoch: 007 | loss: 0.68139 - acc: 0.5660 -- iter: 1344/1392
[A[ATraining Step: 307  | total loss: [1m[32m0.68403[0m[0m | time: 25.434s
[2K
| Adam | epoch: 007 | loss: 0.68403 - acc: 0.5563 -- iter: 1376/1392
[A[ATraining Step: 308  | total loss: [1m[32m0.68003[0m[0m | time: 27.438s
[2K
| Adam | epoch: 007 | loss: 0.68003 - acc: 0.5569 | val_loss: 0.64784 - val_acc: 0.6184 -- iter: 1392/1392
--
Training Step: 309  | total loss: [1m[32m0.67698[0m[0m | time: 0.604s
[2K
| Adam | epoch: 008 | loss: 0.67698 - acc: 0.5700 -- iter: 0032/1392
[A[ATraining Step: 310  | total loss: [1m[32m0.67018[0m[0m | time: 1.196s
[2K
| Adam | epoch: 008 | loss: 0.67018 - acc: 0.5755 -- iter: 0064/1392
[A[ATraining Step: 311  | total loss: [1m[32m0.65764[0m[0m | time: 1.790s
[2K
| Adam | epoch: 008 | loss: 0.65764 - acc: 0.5929 -- iter: 0096/1392
[A[ATraining Step: 312  | total loss: [1m[32m0.65572[0m[0m | time: 2.376s
[2K
| Adam | epoch: 008 | loss: 0.65572 - acc: 0.5993 -- iter: 0128/1392
[A[ATraining Step: 313  | total loss: [1m[32m0.66251[0m[0m | time: 2.985s
[2K
| Adam | epoch: 008 | loss: 0.66251 - acc: 0.5987 -- iter: 0160/1392
[A[ATraining Step: 314  | total loss: [1m[32m0.66228[0m[0m | time: 3.296s
[2K
| Adam | epoch: 008 | loss: 0.66228 - acc: 0.5951 -- iter: 0192/1392
[A[ATraining Step: 315  | total loss: [1m[32m0.66173[0m[0m | time: 3.616s
[2K
| Adam | epoch: 008 | loss: 0.66173 - acc: 0.6043 -- iter: 0224/1392
[A[ATraining Step: 316  | total loss: [1m[32m0.66067[0m[0m | time: 4.206s
[2K
| Adam | epoch: 008 | loss: 0.66067 - acc: 0.6064 -- iter: 0256/1392
[A[ATraining Step: 317  | total loss: [1m[32m0.65838[0m[0m | time: 4.807s
[2K
| Adam | epoch: 008 | loss: 0.65838 - acc: 0.6114 -- iter: 0288/1392
[A[ATraining Step: 318  | total loss: [1m[32m0.65850[0m[0m | time: 5.424s
[2K
| Adam | epoch: 008 | loss: 0.65850 - acc: 0.6065 -- iter: 0320/1392
[A[ATraining Step: 319  | total loss: [1m[32m0.66095[0m[0m | time: 6.021s
[2K
| Adam | epoch: 008 | loss: 0.66095 - acc: 0.5958 -- iter: 0352/1392
[A[ATraining Step: 320  | total loss: [1m[32m0.66036[0m[0m | time: 6.610s
[2K
| Adam | epoch: 008 | loss: 0.66036 - acc: 0.5863 -- iter: 0384/1392
[A[ATraining Step: 321  | total loss: [1m[32m0.65770[0m[0m | time: 7.203s
[2K
| Adam | epoch: 008 | loss: 0.65770 - acc: 0.6058 -- iter: 0416/1392
[A[ATraining Step: 322  | total loss: [1m[32m0.66201[0m[0m | time: 7.815s
[2K
| Adam | epoch: 008 | loss: 0.66201 - acc: 0.6014 -- iter: 0448/1392
[A[ATraining Step: 323  | total loss: [1m[32m0.65865[0m[0m | time: 8.420s
[2K
| Adam | epoch: 008 | loss: 0.65865 - acc: 0.6132 -- iter: 0480/1392
[A[ATraining Step: 324  | total loss: [1m[32m0.65904[0m[0m | time: 9.016s
[2K
| Adam | epoch: 008 | loss: 0.65904 - acc: 0.6050 -- iter: 0512/1392
[A[ATraining Step: 325  | total loss: [1m[32m0.65797[0m[0m | time: 9.611s
[2K
| Adam | epoch: 008 | loss: 0.65797 - acc: 0.6101 -- iter: 0544/1392
[A[ATraining Step: 326  | total loss: [1m[32m0.65834[0m[0m | time: 10.210s
[2K
| Adam | epoch: 008 | loss: 0.65834 - acc: 0.6053 -- iter: 0576/1392
[A[ATraining Step: 327  | total loss: [1m[32m0.65827[0m[0m | time: 10.803s
[2K
| Adam | epoch: 008 | loss: 0.65827 - acc: 0.6136 -- iter: 0608/1392
[A[ATraining Step: 328  | total loss: [1m[32m0.65917[0m[0m | time: 11.403s
[2K
| Adam | epoch: 008 | loss: 0.65917 - acc: 0.5991 -- iter: 0640/1392
[A[ATraining Step: 329  | total loss: [1m[32m0.65554[0m[0m | time: 12.002s
[2K
| Adam | epoch: 008 | loss: 0.65554 - acc: 0.6048 -- iter: 0672/1392
[A[ATraining Step: 330  | total loss: [1m[32m0.65259[0m[0m | time: 12.600s
[2K
| Adam | epoch: 008 | loss: 0.65259 - acc: 0.6099 -- iter: 0704/1392
[A[ATraining Step: 331  | total loss: [1m[32m0.65552[0m[0m | time: 13.213s
[2K
| Adam | epoch: 008 | loss: 0.65552 - acc: 0.6114 -- iter: 0736/1392
[A[ATraining Step: 332  | total loss: [1m[32m0.66623[0m[0m | time: 13.815s
[2K
| Adam | epoch: 008 | loss: 0.66623 - acc: 0.6097 -- iter: 0768/1392
[A[ATraining Step: 333  | total loss: [1m[32m0.65644[0m[0m | time: 14.419s
[2K
| Adam | epoch: 008 | loss: 0.65644 - acc: 0.6143 -- iter: 0800/1392
[A[ATraining Step: 334  | total loss: [1m[32m0.65696[0m[0m | time: 15.022s
[2K
| Adam | epoch: 008 | loss: 0.65696 - acc: 0.6154 -- iter: 0832/1392
[A[ATraining Step: 335  | total loss: [1m[32m0.65209[0m[0m | time: 15.613s
[2K
| Adam | epoch: 008 | loss: 0.65209 - acc: 0.6226 -- iter: 0864/1392
[A[ATraining Step: 336  | total loss: [1m[32m0.65873[0m[0m | time: 16.213s
[2K
| Adam | epoch: 008 | loss: 0.65873 - acc: 0.6197 -- iter: 0896/1392
[A[ATraining Step: 337  | total loss: [1m[32m0.65660[0m[0m | time: 16.813s
[2K
| Adam | epoch: 008 | loss: 0.65660 - acc: 0.6171 -- iter: 0928/1392
[A[ATraining Step: 338  | total loss: [1m[32m0.65128[0m[0m | time: 17.415s
[2K
| Adam | epoch: 008 | loss: 0.65128 - acc: 0.6210 -- iter: 0960/1392
[A[ATraining Step: 339  | total loss: [1m[32m0.64972[0m[0m | time: 18.015s
[2K
| Adam | epoch: 008 | loss: 0.64972 - acc: 0.6214 -- iter: 0992/1392
[A[ATraining Step: 340  | total loss: [1m[32m0.64373[0m[0m | time: 18.623s
[2K
| Adam | epoch: 008 | loss: 0.64373 - acc: 0.6249 -- iter: 1024/1392
[A[ATraining Step: 341  | total loss: [1m[32m0.64083[0m[0m | time: 19.234s
[2K
| Adam | epoch: 008 | loss: 0.64083 - acc: 0.6312 -- iter: 1056/1392
[A[ATraining Step: 342  | total loss: [1m[32m0.64264[0m[0m | time: 19.852s
[2K
| Adam | epoch: 008 | loss: 0.64264 - acc: 0.6368 -- iter: 1088/1392
[A[ATraining Step: 343  | total loss: [1m[32m0.64135[0m[0m | time: 20.447s
[2K
| Adam | epoch: 008 | loss: 0.64135 - acc: 0.6325 -- iter: 1120/1392
[A[ATraining Step: 344  | total loss: [1m[32m0.64142[0m[0m | time: 21.050s
[2K
| Adam | epoch: 008 | loss: 0.64142 - acc: 0.6318 -- iter: 1152/1392
[A[ATraining Step: 345  | total loss: [1m[32m0.64021[0m[0m | time: 21.659s
[2K
| Adam | epoch: 008 | loss: 0.64021 - acc: 0.6248 -- iter: 1184/1392
[A[ATraining Step: 346  | total loss: [1m[32m0.63561[0m[0m | time: 22.254s
[2K
| Adam | epoch: 008 | loss: 0.63561 - acc: 0.6280 -- iter: 1216/1392
[A[ATraining Step: 347  | total loss: [1m[32m0.62504[0m[0m | time: 22.863s
[2K
| Adam | epoch: 008 | loss: 0.62504 - acc: 0.6402 -- iter: 1248/1392
[A[ATraining Step: 348  | total loss: [1m[32m0.62506[0m[0m | time: 23.470s
[2K
| Adam | epoch: 008 | loss: 0.62506 - acc: 0.6324 -- iter: 1280/1392
[A[ATraining Step: 349  | total loss: [1m[32m0.62019[0m[0m | time: 24.064s
[2K
| Adam | epoch: 008 | loss: 0.62019 - acc: 0.6348 -- iter: 1312/1392
[A[ATraining Step: 350  | total loss: [1m[32m0.62437[0m[0m | time: 24.688s
[2K
| Adam | epoch: 008 | loss: 0.62437 - acc: 0.6338 -- iter: 1344/1392
[A[ATraining Step: 351  | total loss: [1m[32m0.62446[0m[0m | time: 25.294s
[2K
| Adam | epoch: 008 | loss: 0.62446 - acc: 0.6267 -- iter: 1376/1392
[A[ATraining Step: 352  | total loss: [1m[32m0.62695[0m[0m | time: 27.270s
[2K
| Adam | epoch: 008 | loss: 0.62695 - acc: 0.6203 | val_loss: 0.61475 - val_acc: 0.6575 -- iter: 1392/1392
--
Training Step: 353  | total loss: [1m[32m0.61669[0m[0m | time: 0.603s
[2K
| Adam | epoch: 009 | loss: 0.61669 - acc: 0.6426 -- iter: 0032/1392
[A[ATraining Step: 354  | total loss: [1m[32m0.61029[0m[0m | time: 1.216s
[2K
| Adam | epoch: 009 | loss: 0.61029 - acc: 0.6471 -- iter: 0064/1392
[A[ATraining Step: 355  | total loss: [1m[32m0.60356[0m[0m | time: 1.806s
[2K
| Adam | epoch: 009 | loss: 0.60356 - acc: 0.6511 -- iter: 0096/1392
[A[ATraining Step: 356  | total loss: [1m[32m0.60799[0m[0m | time: 2.420s
[2K
| Adam | epoch: 009 | loss: 0.60799 - acc: 0.6579 -- iter: 0128/1392
[A[ATraining Step: 357  | total loss: [1m[32m0.60432[0m[0m | time: 3.022s
[2K
| Adam | epoch: 009 | loss: 0.60432 - acc: 0.6609 -- iter: 0160/1392
[A[ATraining Step: 358  | total loss: [1m[32m0.60965[0m[0m | time: 3.630s
[2K
| Adam | epoch: 009 | loss: 0.60965 - acc: 0.6573 -- iter: 0192/1392
[A[ATraining Step: 359  | total loss: [1m[32m0.61848[0m[0m | time: 3.942s
[2K
| Adam | epoch: 009 | loss: 0.61848 - acc: 0.6478 -- iter: 0224/1392
[A[ATraining Step: 360  | total loss: [1m[32m0.62275[0m[0m | time: 4.260s
[2K
| Adam | epoch: 009 | loss: 0.62275 - acc: 0.6393 -- iter: 0256/1392
[A[ATraining Step: 361  | total loss: [1m[32m0.62367[0m[0m | time: 4.863s
[2K
| Adam | epoch: 009 | loss: 0.62367 - acc: 0.6316 -- iter: 0288/1392
[A[ATraining Step: 362  | total loss: [1m[32m0.61923[0m[0m | time: 5.455s
[2K
| Adam | epoch: 009 | loss: 0.61923 - acc: 0.6372 -- iter: 0320/1392
[A[ATraining Step: 363  | total loss: [1m[32m0.60966[0m[0m | time: 6.047s
[2K
| Adam | epoch: 009 | loss: 0.60966 - acc: 0.6453 -- iter: 0352/1392
[A[ATraining Step: 364  | total loss: [1m[32m0.60609[0m[0m | time: 6.652s
[2K
| Adam | epoch: 009 | loss: 0.60609 - acc: 0.6464 -- iter: 0384/1392
[A[ATraining Step: 365  | total loss: [1m[32m0.60339[0m[0m | time: 7.268s
[2K
| Adam | epoch: 009 | loss: 0.60339 - acc: 0.6537 -- iter: 0416/1392
[A[ATraining Step: 366  | total loss: [1m[32m0.60425[0m[0m | time: 7.878s
[2K
| Adam | epoch: 009 | loss: 0.60425 - acc: 0.6539 -- iter: 0448/1392
[A[ATraining Step: 367  | total loss: [1m[32m0.59655[0m[0m | time: 8.483s
[2K
| Adam | epoch: 009 | loss: 0.59655 - acc: 0.6604 -- iter: 0480/1392
[A[ATraining Step: 368  | total loss: [1m[32m0.59753[0m[0m | time: 9.066s
[2K
| Adam | epoch: 009 | loss: 0.59753 - acc: 0.6569 -- iter: 0512/1392
[A[ATraining Step: 369  | total loss: [1m[32m0.59813[0m[0m | time: 9.669s
[2K
| Adam | epoch: 009 | loss: 0.59813 - acc: 0.6631 -- iter: 0544/1392
[A[ATraining Step: 370  | total loss: [1m[32m0.58667[0m[0m | time: 10.260s
[2K
| Adam | epoch: 009 | loss: 0.58667 - acc: 0.6749 -- iter: 0576/1392
[A[ATraining Step: 371  | total loss: [1m[32m0.59393[0m[0m | time: 10.883s
[2K
| Adam | epoch: 009 | loss: 0.59393 - acc: 0.6761 -- iter: 0608/1392
[A[ATraining Step: 372  | total loss: [1m[32m0.58840[0m[0m | time: 11.511s
[2K
| Adam | epoch: 009 | loss: 0.58840 - acc: 0.6741 -- iter: 0640/1392
[A[ATraining Step: 373  | total loss: [1m[32m0.58599[0m[0m | time: 12.117s
[2K
| Adam | epoch: 009 | loss: 0.58599 - acc: 0.6755 -- iter: 0672/1392
[A[ATraining Step: 374  | total loss: [1m[32m0.58876[0m[0m | time: 12.715s
[2K
| Adam | epoch: 009 | loss: 0.58876 - acc: 0.6767 -- iter: 0704/1392
[A[ATraining Step: 375  | total loss: [1m[32m0.58707[0m[0m | time: 13.318s
[2K
| Adam | epoch: 009 | loss: 0.58707 - acc: 0.6746 -- iter: 0736/1392
[A[ATraining Step: 376  | total loss: [1m[32m0.60052[0m[0m | time: 13.930s
[2K
| Adam | epoch: 009 | loss: 0.60052 - acc: 0.6634 -- iter: 0768/1392
[A[ATraining Step: 377  | total loss: [1m[32m0.60403[0m[0m | time: 14.543s
[2K
| Adam | epoch: 009 | loss: 0.60403 - acc: 0.6533 -- iter: 0800/1392
[A[ATraining Step: 378  | total loss: [1m[32m0.60570[0m[0m | time: 15.143s
[2K
| Adam | epoch: 009 | loss: 0.60570 - acc: 0.6536 -- iter: 0832/1392
[A[ATraining Step: 379  | total loss: [1m[32m0.60367[0m[0m | time: 15.746s
[2K
| Adam | epoch: 009 | loss: 0.60367 - acc: 0.6570 -- iter: 0864/1392
[A[ATraining Step: 380  | total loss: [1m[32m0.61824[0m[0m | time: 16.367s
[2K
| Adam | epoch: 009 | loss: 0.61824 - acc: 0.6444 -- iter: 0896/1392
[A[ATraining Step: 381  | total loss: [1m[32m0.62081[0m[0m | time: 16.973s
[2K
| Adam | epoch: 009 | loss: 0.62081 - acc: 0.6362 -- iter: 0928/1392
[A[ATraining Step: 382  | total loss: [1m[32m0.61239[0m[0m | time: 17.592s
[2K
| Adam | epoch: 009 | loss: 0.61239 - acc: 0.6382 -- iter: 0960/1392
[A[ATraining Step: 383  | total loss: [1m[32m0.60576[0m[0m | time: 18.216s
[2K
| Adam | epoch: 009 | loss: 0.60576 - acc: 0.6463 -- iter: 0992/1392
[A[ATraining Step: 384  | total loss: [1m[32m0.60399[0m[0m | time: 18.823s
[2K
| Adam | epoch: 009 | loss: 0.60399 - acc: 0.6567 -- iter: 1024/1392
[A[ATraining Step: 385  | total loss: [1m[32m0.59461[0m[0m | time: 19.417s
[2K
| Adam | epoch: 009 | loss: 0.59461 - acc: 0.6785 -- iter: 1056/1392
[A[ATraining Step: 386  | total loss: [1m[32m0.59357[0m[0m | time: 20.038s
[2K
| Adam | epoch: 009 | loss: 0.59357 - acc: 0.6794 -- iter: 1088/1392
[A[ATraining Step: 387  | total loss: [1m[32m0.60228[0m[0m | time: 20.650s
[2K
| Adam | epoch: 009 | loss: 0.60228 - acc: 0.6677 -- iter: 1120/1392
[A[ATraining Step: 388  | total loss: [1m[32m0.59772[0m[0m | time: 21.280s
[2K
| Adam | epoch: 009 | loss: 0.59772 - acc: 0.6728 -- iter: 1152/1392
[A[ATraining Step: 389  | total loss: [1m[32m0.58562[0m[0m | time: 21.882s
[2K
| Adam | epoch: 009 | loss: 0.58562 - acc: 0.6899 -- iter: 1184/1392
[A[ATraining Step: 390  | total loss: [1m[32m0.59539[0m[0m | time: 22.490s
[2K
| Adam | epoch: 009 | loss: 0.59539 - acc: 0.6834 -- iter: 1216/1392
[A[ATraining Step: 391  | total loss: [1m[32m0.58767[0m[0m | time: 23.097s
[2K
| Adam | epoch: 009 | loss: 0.58767 - acc: 0.6963 -- iter: 1248/1392
[A[ATraining Step: 392  | total loss: [1m[32m0.57448[0m[0m | time: 23.688s
[2K
| Adam | epoch: 009 | loss: 0.57448 - acc: 0.7111 -- iter: 1280/1392
[A[ATraining Step: 393  | total loss: [1m[32m0.58170[0m[0m | time: 24.298s
[2K
| Adam | epoch: 009 | loss: 0.58170 - acc: 0.7056 -- iter: 1312/1392
[A[ATraining Step: 394  | total loss: [1m[32m0.58041[0m[0m | time: 24.901s
[2K
| Adam | epoch: 009 | loss: 0.58041 - acc: 0.7007 -- iter: 1344/1392
[A[ATraining Step: 395  | total loss: [1m[32m0.57232[0m[0m | time: 25.499s
[2K
| Adam | epoch: 009 | loss: 0.57232 - acc: 0.7056 -- iter: 1376/1392
[A[ATraining Step: 396  | total loss: [1m[32m0.56880[0m[0m | time: 27.477s
[2K
| Adam | epoch: 009 | loss: 0.56880 - acc: 0.7007 | val_loss: 0.59493 - val_acc: 0.6690 -- iter: 1392/1392
--
Training Step: 397  | total loss: [1m[32m0.56255[0m[0m | time: 0.601s
[2K
| Adam | epoch: 010 | loss: 0.56255 - acc: 0.7087 -- iter: 0032/1392
[A[ATraining Step: 398  | total loss: [1m[32m0.55928[0m[0m | time: 1.205s
[2K
| Adam | epoch: 010 | loss: 0.55928 - acc: 0.7097 -- iter: 0064/1392
[A[ATraining Step: 399  | total loss: [1m[32m0.55147[0m[0m | time: 1.802s
[2K
| Adam | epoch: 010 | loss: 0.55147 - acc: 0.7137 -- iter: 0096/1392
[A[ATraining Step: 400  | total loss: [1m[32m0.56193[0m[0m | time: 3.772s
[2K
| Adam | epoch: 010 | loss: 0.56193 - acc: 0.7142 | val_loss: 0.58730 - val_acc: 0.6805 -- iter: 0128/1392
--
Training Step: 401  | total loss: [1m[32m0.55668[0m[0m | time: 4.402s
[2K
| Adam | epoch: 010 | loss: 0.55668 - acc: 0.7241 -- iter: 0160/1392
[A[ATraining Step: 402  | total loss: [1m[32m0.54984[0m[0m | time: 5.001s
[2K
| Adam | epoch: 010 | loss: 0.54984 - acc: 0.7267 -- iter: 0192/1392
[A[ATraining Step: 403  | total loss: [1m[32m0.54026[0m[0m | time: 5.614s
[2K
| Adam | epoch: 010 | loss: 0.54026 - acc: 0.7352 -- iter: 0224/1392
[A[ATraining Step: 404  | total loss: [1m[32m0.53621[0m[0m | time: 5.939s
[2K
| Adam | epoch: 010 | loss: 0.53621 - acc: 0.7367 -- iter: 0256/1392
[A[ATraining Step: 405  | total loss: [1m[32m0.54367[0m[0m | time: 6.255s
[2K
| Adam | epoch: 010 | loss: 0.54367 - acc: 0.7381 -- iter: 0288/1392
[A[ATraining Step: 406  | total loss: [1m[32m0.54572[0m[0m | time: 6.850s
[2K
| Adam | epoch: 010 | loss: 0.54572 - acc: 0.7392 -- iter: 0320/1392
[A[ATraining Step: 407  | total loss: [1m[32m0.55040[0m[0m | time: 7.444s
[2K
| Adam | epoch: 010 | loss: 0.55040 - acc: 0.7341 -- iter: 0352/1392
[A[ATraining Step: 408  | total loss: [1m[32m0.54753[0m[0m | time: 8.058s
[2K
| Adam | epoch: 010 | loss: 0.54753 - acc: 0.7357 -- iter: 0384/1392
[A[ATraining Step: 409  | total loss: [1m[32m0.53353[0m[0m | time: 8.665s
[2K
| Adam | epoch: 010 | loss: 0.53353 - acc: 0.7496 -- iter: 0416/1392
[A[ATraining Step: 410  | total loss: [1m[32m0.53376[0m[0m | time: 9.258s
[2K
| Adam | epoch: 010 | loss: 0.53376 - acc: 0.7434 -- iter: 0448/1392
[A[ATraining Step: 411  | total loss: [1m[32m0.53479[0m[0m | time: 9.861s
[2K
| Adam | epoch: 010 | loss: 0.53479 - acc: 0.7440 -- iter: 0480/1392
[A[ATraining Step: 412  | total loss: [1m[32m0.52390[0m[0m | time: 10.459s
[2K
| Adam | epoch: 010 | loss: 0.52390 - acc: 0.7571 -- iter: 0512/1392
[A[ATraining Step: 413  | total loss: [1m[32m0.53629[0m[0m | time: 11.049s
[2K
| Adam | epoch: 010 | loss: 0.53629 - acc: 0.7377 -- iter: 0544/1392
[A[ATraining Step: 414  | total loss: [1m[32m0.52980[0m[0m | time: 11.666s
[2K
| Adam | epoch: 010 | loss: 0.52980 - acc: 0.7389 -- iter: 0576/1392
[A[ATraining Step: 415  | total loss: [1m[32m0.52699[0m[0m | time: 12.275s
[2K
| Adam | epoch: 010 | loss: 0.52699 - acc: 0.7463 -- iter: 0608/1392
[A[ATraining Step: 416  | total loss: [1m[32m0.52253[0m[0m | time: 12.892s
[2K
| Adam | epoch: 010 | loss: 0.52253 - acc: 0.7466 -- iter: 0640/1392
[A[ATraining Step: 417  | total loss: [1m[32m0.52678[0m[0m | time: 13.483s
[2K
| Adam | epoch: 010 | loss: 0.52678 - acc: 0.7376 -- iter: 0672/1392
[A[ATraining Step: 418  | total loss: [1m[32m0.51710[0m[0m | time: 14.092s
[2K
| Adam | epoch: 010 | loss: 0.51710 - acc: 0.7482 -- iter: 0704/1392
[A[ATraining Step: 419  | total loss: [1m[32m0.51266[0m[0m | time: 14.692s
[2K
| Adam | epoch: 010 | loss: 0.51266 - acc: 0.7421 -- iter: 0736/1392
[A[ATraining Step: 420  | total loss: [1m[32m0.52324[0m[0m | time: 15.295s
[2K
| Adam | epoch: 010 | loss: 0.52324 - acc: 0.7461 -- iter: 0768/1392
[A[ATraining Step: 421  | total loss: [1m[32m0.51149[0m[0m | time: 15.890s
[2K
| Adam | epoch: 010 | loss: 0.51149 - acc: 0.7527 -- iter: 0800/1392
[A[ATraining Step: 422  | total loss: [1m[32m0.50709[0m[0m | time: 16.498s
[2K
| Adam | epoch: 010 | loss: 0.50709 - acc: 0.7556 -- iter: 0832/1392
[A[ATraining Step: 423  | total loss: [1m[32m0.51366[0m[0m | time: 17.098s
[2K
| Adam | epoch: 010 | loss: 0.51366 - acc: 0.7519 -- iter: 0864/1392
[A[ATraining Step: 424  | total loss: [1m[32m0.51827[0m[0m | time: 17.703s
[2K
| Adam | epoch: 010 | loss: 0.51827 - acc: 0.7517 -- iter: 0896/1392
[A[ATraining Step: 425  | total loss: [1m[32m0.49924[0m[0m | time: 18.299s
[2K
| Adam | epoch: 010 | loss: 0.49924 - acc: 0.7703 -- iter: 0928/1392
[A[ATraining Step: 426  | total loss: [1m[32m0.50756[0m[0m | time: 18.902s
[2K
| Adam | epoch: 010 | loss: 0.50756 - acc: 0.7651 -- iter: 0960/1392
[A[ATraining Step: 427  | total loss: [1m[32m0.49070[0m[0m | time: 19.519s
[2K
| Adam | epoch: 010 | loss: 0.49070 - acc: 0.7730 -- iter: 0992/1392
[A[ATraining Step: 428  | total loss: [1m[32m0.49566[0m[0m | time: 20.119s
[2K
| Adam | epoch: 010 | loss: 0.49566 - acc: 0.7738 -- iter: 1024/1392
[A[ATraining Step: 429  | total loss: [1m[32m0.47430[0m[0m | time: 20.716s
[2K
| Adam | epoch: 010 | loss: 0.47430 - acc: 0.7964 -- iter: 1056/1392
[A[ATraining Step: 430  | total loss: [1m[32m0.48690[0m[0m | time: 21.313s
[2K
| Adam | epoch: 010 | loss: 0.48690 - acc: 0.7824 -- iter: 1088/1392
[A[ATraining Step: 431  | total loss: [1m[32m0.48863[0m[0m | time: 21.927s
[2K
| Adam | epoch: 010 | loss: 0.48863 - acc: 0.7729 -- iter: 1120/1392
[A[ATraining Step: 432  | total loss: [1m[32m0.48530[0m[0m | time: 22.525s
[2K
| Adam | epoch: 010 | loss: 0.48530 - acc: 0.7738 -- iter: 1152/1392
[A[ATraining Step: 433  | total loss: [1m[32m0.49702[0m[0m | time: 23.120s
[2K
| Adam | epoch: 010 | loss: 0.49702 - acc: 0.7683 -- iter: 1184/1392
[A[ATraining Step: 434  | total loss: [1m[32m0.50289[0m[0m | time: 23.747s
[2K
| Adam | epoch: 010 | loss: 0.50289 - acc: 0.7664 -- iter: 1216/1392
[A[ATraining Step: 435  | total loss: [1m[32m0.49237[0m[0m | time: 24.346s
[2K
| Adam | epoch: 010 | loss: 0.49237 - acc: 0.7648 -- iter: 1248/1392
[A[ATraining Step: 436  | total loss: [1m[32m0.49406[0m[0m | time: 24.940s
[2K
| Adam | epoch: 010 | loss: 0.49406 - acc: 0.7633 -- iter: 1280/1392
[A[ATraining Step: 437  | total loss: [1m[32m0.50525[0m[0m | time: 25.537s
[2K
| Adam | epoch: 010 | loss: 0.50525 - acc: 0.7432 -- iter: 1312/1392
[A[ATraining Step: 438  | total loss: [1m[32m0.48504[0m[0m | time: 26.140s
[2K
| Adam | epoch: 010 | loss: 0.48504 - acc: 0.7658 -- iter: 1344/1392
[A[ATraining Step: 439  | total loss: [1m[32m0.49352[0m[0m | time: 26.731s
[2K
| Adam | epoch: 010 | loss: 0.49352 - acc: 0.7611 -- iter: 1376/1392
[A[ATraining Step: 440  | total loss: [1m[32m0.50346[0m[0m | time: 28.706s
[2K
| Adam | epoch: 010 | loss: 0.50346 - acc: 0.7600 | val_loss: 0.58332 - val_acc: 0.7126 -- iter: 1392/1392
--
Training Step: 441  | total loss: [1m[32m0.50514[0m[0m | time: 0.604s
[2K
| Adam | epoch: 011 | loss: 0.50514 - acc: 0.7527 -- iter: 0032/1392
[A[ATraining Step: 442  | total loss: [1m[32m0.49884[0m[0m | time: 1.199s
[2K
| Adam | epoch: 011 | loss: 0.49884 - acc: 0.7618 -- iter: 0064/1392
[A[ATraining Step: 443  | total loss: [1m[32m0.49640[0m[0m | time: 1.771s
[2K
| Adam | epoch: 011 | loss: 0.49640 - acc: 0.7638 -- iter: 0096/1392
[A[ATraining Step: 444  | total loss: [1m[32m0.47914[0m[0m | time: 2.364s
[2K
| Adam | epoch: 011 | loss: 0.47914 - acc: 0.7749 -- iter: 0128/1392
[A[ATraining Step: 445  | total loss: [1m[32m0.48701[0m[0m | time: 2.975s
[2K
| Adam | epoch: 011 | loss: 0.48701 - acc: 0.7755 -- iter: 0160/1392
[A[ATraining Step: 446  | total loss: [1m[32m0.48612[0m[0m | time: 3.565s
[2K
| Adam | epoch: 011 | loss: 0.48612 - acc: 0.7730 -- iter: 0192/1392
[A[ATraining Step: 447  | total loss: [1m[32m0.48818[0m[0m | time: 4.160s
[2K
| Adam | epoch: 011 | loss: 0.48818 - acc: 0.7676 -- iter: 0224/1392
[A[ATraining Step: 448  | total loss: [1m[32m0.48918[0m[0m | time: 4.747s
[2K
| Adam | epoch: 011 | loss: 0.48918 - acc: 0.7689 -- iter: 0256/1392
[A[ATraining Step: 449  | total loss: [1m[32m0.49239[0m[0m | time: 5.083s
[2K
| Adam | epoch: 011 | loss: 0.49239 - acc: 0.7670 -- iter: 0288/1392
[A[ATraining Step: 450  | total loss: [1m[32m0.48742[0m[0m | time: 5.412s
[2K
| Adam | epoch: 011 | loss: 0.48742 - acc: 0.7591 -- iter: 0320/1392
[A[ATraining Step: 451  | total loss: [1m[32m0.47727[0m[0m | time: 6.009s
[2K
| Adam | epoch: 011 | loss: 0.47727 - acc: 0.7707 -- iter: 0352/1392
[A[ATraining Step: 452  | total loss: [1m[32m0.47114[0m[0m | time: 6.605s
[2K
| Adam | epoch: 011 | loss: 0.47114 - acc: 0.7749 -- iter: 0384/1392
[A[ATraining Step: 453  | total loss: [1m[32m0.49164[0m[0m | time: 7.210s
[2K
| Adam | epoch: 011 | loss: 0.49164 - acc: 0.7630 -- iter: 0416/1392
[A[ATraining Step: 454  | total loss: [1m[32m0.48915[0m[0m | time: 7.794s
[2K
| Adam | epoch: 011 | loss: 0.48915 - acc: 0.7711 -- iter: 0448/1392
[A[ATraining Step: 455  | total loss: [1m[32m0.48834[0m[0m | time: 8.387s
[2K
| Adam | epoch: 011 | loss: 0.48834 - acc: 0.7721 -- iter: 0480/1392
[A[ATraining Step: 456  | total loss: [1m[32m0.48556[0m[0m | time: 8.988s
[2K
| Adam | epoch: 011 | loss: 0.48556 - acc: 0.7699 -- iter: 0512/1392
[A[ATraining Step: 457  | total loss: [1m[32m0.50250[0m[0m | time: 9.616s
[2K
| Adam | epoch: 011 | loss: 0.50250 - acc: 0.7554 -- iter: 0544/1392
[A[ATraining Step: 458  | total loss: [1m[32m0.53696[0m[0m | time: 10.220s
[2K
| Adam | epoch: 011 | loss: 0.53696 - acc: 0.7330 -- iter: 0576/1392
[A[ATraining Step: 459  | total loss: [1m[32m0.55752[0m[0m | time: 10.840s
[2K
| Adam | epoch: 011 | loss: 0.55752 - acc: 0.7191 -- iter: 0608/1392
[A[ATraining Step: 460  | total loss: [1m[32m0.55197[0m[0m | time: 11.450s
[2K
| Adam | epoch: 011 | loss: 0.55197 - acc: 0.7253 -- iter: 0640/1392
[A[ATraining Step: 461  | total loss: [1m[32m0.54712[0m[0m | time: 12.038s
[2K
| Adam | epoch: 011 | loss: 0.54712 - acc: 0.7277 -- iter: 0672/1392
[A[ATraining Step: 462  | total loss: [1m[32m0.54272[0m[0m | time: 12.628s
[2K
| Adam | epoch: 011 | loss: 0.54272 - acc: 0.7268 -- iter: 0704/1392
[A[ATraining Step: 463  | total loss: [1m[32m0.55097[0m[0m | time: 13.227s
[2K
| Adam | epoch: 011 | loss: 0.55097 - acc: 0.7167 -- iter: 0736/1392
[A[ATraining Step: 464  | total loss: [1m[32m0.54733[0m[0m | time: 13.829s
[2K
| Adam | epoch: 011 | loss: 0.54733 - acc: 0.7294 -- iter: 0768/1392
[A[ATraining Step: 465  | total loss: [1m[32m0.54235[0m[0m | time: 14.471s
[2K
| Adam | epoch: 011 | loss: 0.54235 - acc: 0.7377 -- iter: 0800/1392
[A[ATraining Step: 466  | total loss: [1m[32m0.54345[0m[0m | time: 15.085s
[2K
| Adam | epoch: 011 | loss: 0.54345 - acc: 0.7420 -- iter: 0832/1392
[A[ATraining Step: 467  | total loss: [1m[32m0.53860[0m[0m | time: 15.691s
[2K
| Adam | epoch: 011 | loss: 0.53860 - acc: 0.7522 -- iter: 0864/1392
[A[ATraining Step: 468  | total loss: [1m[32m0.53223[0m[0m | time: 16.315s
[2K
| Adam | epoch: 011 | loss: 0.53223 - acc: 0.7645 -- iter: 0896/1392
[A[ATraining Step: 469  | total loss: [1m[32m0.52648[0m[0m | time: 16.929s
[2K
| Adam | epoch: 011 | loss: 0.52648 - acc: 0.7755 -- iter: 0928/1392
[A[ATraining Step: 470  | total loss: [1m[32m0.51885[0m[0m | time: 17.547s
[2K
| Adam | epoch: 011 | loss: 0.51885 - acc: 0.7886 -- iter: 0960/1392
[A[ATraining Step: 471  | total loss: [1m[32m0.52434[0m[0m | time: 18.156s
[2K
| Adam | epoch: 011 | loss: 0.52434 - acc: 0.7723 -- iter: 0992/1392
[A[ATraining Step: 472  | total loss: [1m[32m0.51843[0m[0m | time: 18.750s
[2K
| Adam | epoch: 011 | loss: 0.51843 - acc: 0.7825 -- iter: 1024/1392
[A[ATraining Step: 473  | total loss: [1m[32m0.51665[0m[0m | time: 19.362s
[2K
| Adam | epoch: 011 | loss: 0.51665 - acc: 0.7918 -- iter: 1056/1392
[A[ATraining Step: 474  | total loss: [1m[32m0.49559[0m[0m | time: 20.012s
[2K
| Adam | epoch: 011 | loss: 0.49559 - acc: 0.8063 -- iter: 1088/1392
[A[ATraining Step: 475  | total loss: [1m[32m0.49724[0m[0m | time: 20.628s
[2K
| Adam | epoch: 011 | loss: 0.49724 - acc: 0.7976 -- iter: 1120/1392
[A[ATraining Step: 476  | total loss: [1m[32m0.47865[0m[0m | time: 21.232s
[2K
| Adam | epoch: 011 | loss: 0.47865 - acc: 0.8022 -- iter: 1152/1392
[A[ATraining Step: 477  | total loss: [1m[32m0.46547[0m[0m | time: 21.827s
[2K
| Adam | epoch: 011 | loss: 0.46547 - acc: 0.8064 -- iter: 1184/1392
[A[ATraining Step: 478  | total loss: [1m[32m0.45363[0m[0m | time: 22.424s
[2K
| Adam | epoch: 011 | loss: 0.45363 - acc: 0.8132 -- iter: 1216/1392
[A[ATraining Step: 479  | total loss: [1m[32m0.43893[0m[0m | time: 23.018s
[2K
| Adam | epoch: 011 | loss: 0.43893 - acc: 0.8163 -- iter: 1248/1392
[A[ATraining Step: 480  | total loss: [1m[32m0.42753[0m[0m | time: 23.610s
[2K
| Adam | epoch: 011 | loss: 0.42753 - acc: 0.8190 -- iter: 1280/1392
[A[ATraining Step: 481  | total loss: [1m[32m0.42203[0m[0m | time: 24.217s
[2K
| Adam | epoch: 011 | loss: 0.42203 - acc: 0.8152 -- iter: 1312/1392
[A[ATraining Step: 482  | total loss: [1m[32m0.42239[0m[0m | time: 24.830s
[2K
| Adam | epoch: 011 | loss: 0.42239 - acc: 0.8150 -- iter: 1344/1392
[A[ATraining Step: 483  | total loss: [1m[32m0.40873[0m[0m | time: 25.441s
[2K
| Adam | epoch: 011 | loss: 0.40873 - acc: 0.8210 -- iter: 1376/1392
[A[ATraining Step: 484  | total loss: [1m[32m0.41501[0m[0m | time: 27.399s
[2K
| Adam | epoch: 011 | loss: 0.41501 - acc: 0.8233 | val_loss: 0.63349 - val_acc: 0.7264 -- iter: 1392/1392
--
Training Step: 485  | total loss: [1m[32m0.41457[0m[0m | time: 0.598s
[2K
| Adam | epoch: 012 | loss: 0.41457 - acc: 0.8191 -- iter: 0032/1392
[A[ATraining Step: 486  | total loss: [1m[32m0.42873[0m[0m | time: 1.212s
[2K
| Adam | epoch: 012 | loss: 0.42873 - acc: 0.8121 -- iter: 0064/1392
[A[ATraining Step: 487  | total loss: [1m[32m0.42205[0m[0m | time: 1.812s
[2K
| Adam | epoch: 012 | loss: 0.42205 - acc: 0.8184 -- iter: 0096/1392
[A[ATraining Step: 488  | total loss: [1m[32m0.42533[0m[0m | time: 2.408s
[2K
| Adam | epoch: 012 | loss: 0.42533 - acc: 0.8210 -- iter: 0128/1392
[A[ATraining Step: 489  | total loss: [1m[32m0.42909[0m[0m | time: 3.005s
[2K
| Adam | epoch: 012 | loss: 0.42909 - acc: 0.8201 -- iter: 0160/1392
[A[ATraining Step: 490  | total loss: [1m[32m0.42791[0m[0m | time: 3.600s
[2K
| Adam | epoch: 012 | loss: 0.42791 - acc: 0.8256 -- iter: 0192/1392
[A[ATraining Step: 491  | total loss: [1m[32m0.41563[0m[0m | time: 4.191s
[2K
| Adam | epoch: 012 | loss: 0.41563 - acc: 0.8337 -- iter: 0224/1392
[A[ATraining Step: 492  | total loss: [1m[32m0.41067[0m[0m | time: 4.790s
[2K
| Adam | epoch: 012 | loss: 0.41067 - acc: 0.8347 -- iter: 0256/1392
[A[ATraining Step: 493  | total loss: [1m[32m0.41203[0m[0m | time: 5.400s
[2K
| Adam | epoch: 012 | loss: 0.41203 - acc: 0.8356 -- iter: 0288/1392
[A[ATraining Step: 494  | total loss: [1m[32m0.41195[0m[0m | time: 5.711s
[2K
| Adam | epoch: 012 | loss: 0.41195 - acc: 0.8395 -- iter: 0320/1392
[A[ATraining Step: 495  | total loss: [1m[32m0.39986[0m[0m | time: 6.042s
[2K
| Adam | epoch: 012 | loss: 0.39986 - acc: 0.8431 -- iter: 0352/1392
[A[ATraining Step: 496  | total loss: [1m[32m0.38662[0m[0m | time: 6.642s
[2K
| Adam | epoch: 012 | loss: 0.38662 - acc: 0.8463 -- iter: 0384/1392
[A[ATraining Step: 497  | total loss: [1m[32m0.38069[0m[0m | time: 7.242s
[2K
| Adam | epoch: 012 | loss: 0.38069 - acc: 0.8491 -- iter: 0416/1392
[A[ATraining Step: 498  | total loss: [1m[32m0.37318[0m[0m | time: 7.850s
[2K
| Adam | epoch: 012 | loss: 0.37318 - acc: 0.8486 -- iter: 0448/1392
[A[ATraining Step: 499  | total loss: [1m[32m0.37603[0m[0m | time: 8.456s
[2K
| Adam | epoch: 012 | loss: 0.37603 - acc: 0.8450 -- iter: 0480/1392
[A[ATraining Step: 500  | total loss: [1m[32m0.37809[0m[0m | time: 9.052s
[2K
| Adam | epoch: 012 | loss: 0.37809 - acc: 0.8449 -- iter: 0512/1392
[A[ATraining Step: 501  | total loss: [1m[32m0.37446[0m[0m | time: 9.648s
[2K
| Adam | epoch: 012 | loss: 0.37446 - acc: 0.8448 -- iter: 0544/1392
[A[ATraining Step: 502  | total loss: [1m[32m0.36101[0m[0m | time: 10.250s
[2K
| Adam | epoch: 012 | loss: 0.36101 - acc: 0.8478 -- iter: 0576/1392
[A[ATraining Step: 503  | total loss: [1m[32m0.37067[0m[0m | time: 10.854s
[2K
| Adam | epoch: 012 | loss: 0.37067 - acc: 0.8443 -- iter: 0608/1392
[A[ATraining Step: 504  | total loss: [1m[32m0.38255[0m[0m | time: 11.448s
[2K
| Adam | epoch: 012 | loss: 0.38255 - acc: 0.8348 -- iter: 0640/1392
[A[ATraining Step: 505  | total loss: [1m[32m0.37586[0m[0m | time: 12.045s
[2K
| Adam | epoch: 012 | loss: 0.37586 - acc: 0.8388 -- iter: 0672/1392
[A[ATraining Step: 506  | total loss: [1m[32m0.38307[0m[0m | time: 12.657s
[2K
| Adam | epoch: 012 | loss: 0.38307 - acc: 0.8362 -- iter: 0704/1392
[A[ATraining Step: 507  | total loss: [1m[32m0.38018[0m[0m | time: 13.282s
[2K
| Adam | epoch: 012 | loss: 0.38018 - acc: 0.8370 -- iter: 0736/1392
[A[ATraining Step: 508  | total loss: [1m[32m0.38600[0m[0m | time: 13.875s
[2K
| Adam | epoch: 012 | loss: 0.38600 - acc: 0.8314 -- iter: 0768/1392
[A[ATraining Step: 509  | total loss: [1m[32m0.38629[0m[0m | time: 14.467s
[2K
| Adam | epoch: 012 | loss: 0.38629 - acc: 0.8295 -- iter: 0800/1392
[A[ATraining Step: 510  | total loss: [1m[32m0.37225[0m[0m | time: 15.091s
[2K
| Adam | epoch: 012 | loss: 0.37225 - acc: 0.8309 -- iter: 0832/1392
[A[ATraining Step: 511  | total loss: [1m[32m0.37604[0m[0m | time: 15.692s
[2K
| Adam | epoch: 012 | loss: 0.37604 - acc: 0.8260 -- iter: 0864/1392
[A[ATraining Step: 512  | total loss: [1m[32m0.37246[0m[0m | time: 16.289s
[2K
| Adam | epoch: 012 | loss: 0.37246 - acc: 0.8309 -- iter: 0896/1392
[A[ATraining Step: 513  | total loss: [1m[32m0.37042[0m[0m | time: 16.892s
[2K
| Adam | epoch: 012 | loss: 0.37042 - acc: 0.8322 -- iter: 0928/1392
[A[ATraining Step: 514  | total loss: [1m[32m0.36440[0m[0m | time: 17.492s
[2K
| Adam | epoch: 012 | loss: 0.36440 - acc: 0.8396 -- iter: 0960/1392
[A[ATraining Step: 515  | total loss: [1m[32m0.35872[0m[0m | time: 18.090s
[2K
| Adam | epoch: 012 | loss: 0.35872 - acc: 0.8431 -- iter: 0992/1392
[A[ATraining Step: 516  | total loss: [1m[32m0.35663[0m[0m | time: 18.698s
[2K
| Adam | epoch: 012 | loss: 0.35663 - acc: 0.8463 -- iter: 1024/1392
[A[ATraining Step: 517  | total loss: [1m[32m0.35830[0m[0m | time: 19.318s
[2K
| Adam | epoch: 012 | loss: 0.35830 - acc: 0.8429 -- iter: 1056/1392
[A[ATraining Step: 518  | total loss: [1m[32m0.35262[0m[0m | time: 19.921s
[2K
| Adam | epoch: 012 | loss: 0.35262 - acc: 0.8430 -- iter: 1088/1392
[A[ATraining Step: 519  | total loss: [1m[32m0.35315[0m[0m | time: 20.517s
[2K
| Adam | epoch: 012 | loss: 0.35315 - acc: 0.8368 -- iter: 1120/1392
[A[ATraining Step: 520  | total loss: [1m[32m0.36812[0m[0m | time: 21.114s
[2K
| Adam | epoch: 012 | loss: 0.36812 - acc: 0.8313 -- iter: 1152/1392
[A[ATraining Step: 521  | total loss: [1m[32m0.37183[0m[0m | time: 21.725s
[2K
| Adam | epoch: 012 | loss: 0.37183 - acc: 0.8263 -- iter: 1184/1392
[A[ATraining Step: 522  | total loss: [1m[32m0.36341[0m[0m | time: 22.325s
[2K
| Adam | epoch: 012 | loss: 0.36341 - acc: 0.8311 -- iter: 1216/1392
[A[ATraining Step: 523  | total loss: [1m[32m0.35722[0m[0m | time: 22.924s
[2K
| Adam | epoch: 012 | loss: 0.35722 - acc: 0.8386 -- iter: 1248/1392
[A[ATraining Step: 524  | total loss: [1m[32m0.34853[0m[0m | time: 23.513s
[2K
| Adam | epoch: 012 | loss: 0.34853 - acc: 0.8454 -- iter: 1280/1392
[A[ATraining Step: 525  | total loss: [1m[32m0.34435[0m[0m | time: 24.117s
[2K
| Adam | epoch: 012 | loss: 0.34435 - acc: 0.8484 -- iter: 1312/1392
[A[ATraining Step: 526  | total loss: [1m[32m0.33982[0m[0m | time: 24.716s
[2K
| Adam | epoch: 012 | loss: 0.33982 - acc: 0.8510 -- iter: 1344/1392
[A[ATraining Step: 527  | total loss: [1m[32m0.34520[0m[0m | time: 25.318s
[2K
| Adam | epoch: 012 | loss: 0.34520 - acc: 0.8503 -- iter: 1376/1392
[A[ATraining Step: 528  | total loss: [1m[32m0.33641[0m[0m | time: 27.336s
[2K
| Adam | epoch: 012 | loss: 0.33641 - acc: 0.8559 | val_loss: 0.60774 - val_acc: 0.7540 -- iter: 1392/1392
--
Training Step: 529  | total loss: [1m[32m0.32266[0m[0m | time: 0.612s
[2K
| Adam | epoch: 013 | loss: 0.32266 - acc: 0.8609 -- iter: 0032/1392
[A[ATraining Step: 530  | total loss: [1m[32m0.31655[0m[0m | time: 1.202s
[2K
| Adam | epoch: 013 | loss: 0.31655 - acc: 0.8686 -- iter: 0064/1392
[A[ATraining Step: 531  | total loss: [1m[32m0.32044[0m[0m | time: 1.806s
[2K
| Adam | epoch: 013 | loss: 0.32044 - acc: 0.8661 -- iter: 0096/1392
[A[ATraining Step: 532  | total loss: [1m[32m0.32495[0m[0m | time: 2.400s
[2K
| Adam | epoch: 013 | loss: 0.32495 - acc: 0.8670 -- iter: 0128/1392
[A[ATraining Step: 533  | total loss: [1m[32m0.32776[0m[0m | time: 3.033s
[2K
| Adam | epoch: 013 | loss: 0.32776 - acc: 0.8647 -- iter: 0160/1392
[A[ATraining Step: 534  | total loss: [1m[32m0.31507[0m[0m | time: 3.631s
[2K
| Adam | epoch: 013 | loss: 0.31507 - acc: 0.8751 -- iter: 0192/1392
[A[ATraining Step: 535  | total loss: [1m[32m0.29509[0m[0m | time: 4.227s
[2K
| Adam | epoch: 013 | loss: 0.29509 - acc: 0.8844 -- iter: 0224/1392
[A[ATraining Step: 536  | total loss: [1m[32m0.29026[0m[0m | time: 4.852s
[2K
| Adam | epoch: 013 | loss: 0.29026 - acc: 0.8835 -- iter: 0256/1392
[A[ATraining Step: 537  | total loss: [1m[32m0.28780[0m[0m | time: 5.469s
[2K
| Adam | epoch: 013 | loss: 0.28780 - acc: 0.8827 -- iter: 0288/1392
[A[ATraining Step: 538  | total loss: [1m[32m0.28814[0m[0m | time: 6.102s
[2K
| Adam | epoch: 013 | loss: 0.28814 - acc: 0.8819 -- iter: 0320/1392
[A[ATraining Step: 539  | total loss: [1m[32m0.28817[0m[0m | time: 6.414s
[2K
| Adam | epoch: 013 | loss: 0.28817 - acc: 0.8874 -- iter: 0352/1392
[A[ATraining Step: 540  | total loss: [1m[32m0.29598[0m[0m | time: 6.731s
[2K
| Adam | epoch: 013 | loss: 0.29598 - acc: 0.8862 -- iter: 0384/1392
[A[ATraining Step: 541  | total loss: [1m[32m0.29400[0m[0m | time: 7.339s
[2K
| Adam | epoch: 013 | loss: 0.29400 - acc: 0.8851 -- iter: 0416/1392
[A[ATraining Step: 542  | total loss: [1m[32m0.29252[0m[0m | time: 7.930s
[2K
| Adam | epoch: 013 | loss: 0.29252 - acc: 0.8841 -- iter: 0448/1392
[A[ATraining Step: 543  | total loss: [1m[32m0.31489[0m[0m | time: 8.527s
[2K
| Adam | epoch: 013 | loss: 0.31489 - acc: 0.8800 -- iter: 0480/1392
[A[ATraining Step: 544  | total loss: [1m[32m0.31839[0m[0m | time: 9.130s
[2K
| Adam | epoch: 013 | loss: 0.31839 - acc: 0.8764 -- iter: 0512/1392
[A[ATraining Step: 545  | total loss: [1m[32m0.30042[0m[0m | time: 9.734s
[2K
| Adam | epoch: 013 | loss: 0.30042 - acc: 0.8825 -- iter: 0544/1392
[A[ATraining Step: 546  | total loss: [1m[32m0.31969[0m[0m | time: 10.338s
[2K
| Adam | epoch: 013 | loss: 0.31969 - acc: 0.8693 -- iter: 0576/1392
[A[ATraining Step: 547  | total loss: [1m[32m0.32405[0m[0m | time: 10.919s
[2K
| Adam | epoch: 013 | loss: 0.32405 - acc: 0.8636 -- iter: 0608/1392
[A[ATraining Step: 548  | total loss: [1m[32m0.32315[0m[0m | time: 11.520s
[2K
| Adam | epoch: 013 | loss: 0.32315 - acc: 0.8585 -- iter: 0640/1392
[A[ATraining Step: 549  | total loss: [1m[32m0.30900[0m[0m | time: 12.116s
[2K
| Adam | epoch: 013 | loss: 0.30900 - acc: 0.8695 -- iter: 0672/1392
[A[ATraining Step: 550  | total loss: [1m[32m0.31061[0m[0m | time: 12.717s
[2K
| Adam | epoch: 013 | loss: 0.31061 - acc: 0.8638 -- iter: 0704/1392
[A[ATraining Step: 551  | total loss: [1m[32m0.30882[0m[0m | time: 13.308s
[2K
| Adam | epoch: 013 | loss: 0.30882 - acc: 0.8649 -- iter: 0736/1392
[A[ATraining Step: 552  | total loss: [1m[32m0.29652[0m[0m | time: 13.902s
[2K
| Adam | epoch: 013 | loss: 0.29652 - acc: 0.8691 -- iter: 0768/1392
[A[ATraining Step: 553  | total loss: [1m[32m0.28394[0m[0m | time: 14.501s
[2K
| Adam | epoch: 013 | loss: 0.28394 - acc: 0.8728 -- iter: 0800/1392
[A[ATraining Step: 554  | total loss: [1m[32m0.27553[0m[0m | time: 15.098s
[2K
| Adam | epoch: 013 | loss: 0.27553 - acc: 0.8824 -- iter: 0832/1392
[A[ATraining Step: 555  | total loss: [1m[32m0.26707[0m[0m | time: 15.695s
[2K
| Adam | epoch: 013 | loss: 0.26707 - acc: 0.8848 -- iter: 0864/1392
[A[ATraining Step: 556  | total loss: [1m[32m0.25091[0m[0m | time: 16.291s
[2K
| Adam | epoch: 013 | loss: 0.25091 - acc: 0.8963 -- iter: 0896/1392
[A[ATraining Step: 557  | total loss: [1m[32m0.23739[0m[0m | time: 16.918s
[2K
| Adam | epoch: 013 | loss: 0.23739 - acc: 0.9035 -- iter: 0928/1392
[A[ATraining Step: 558  | total loss: [1m[32m0.23011[0m[0m | time: 17.528s
[2K
| Adam | epoch: 013 | loss: 0.23011 - acc: 0.9069 -- iter: 0960/1392
[A[ATraining Step: 559  | total loss: [1m[32m0.22033[0m[0m | time: 18.123s
[2K
| Adam | epoch: 013 | loss: 0.22033 - acc: 0.9131 -- iter: 0992/1392
[A[ATraining Step: 560  | total loss: [1m[32m0.23053[0m[0m | time: 18.727s
[2K
| Adam | epoch: 013 | loss: 0.23053 - acc: 0.9031 -- iter: 1024/1392
[A[ATraining Step: 561  | total loss: [1m[32m0.24253[0m[0m | time: 19.331s
[2K
| Adam | epoch: 013 | loss: 0.24253 - acc: 0.9002 -- iter: 1056/1392
[A[ATraining Step: 562  | total loss: [1m[32m0.26870[0m[0m | time: 19.928s
[2K
| Adam | epoch: 013 | loss: 0.26870 - acc: 0.8915 -- iter: 1088/1392
[A[ATraining Step: 563  | total loss: [1m[32m0.27044[0m[0m | time: 20.525s
[2K
| Adam | epoch: 013 | loss: 0.27044 - acc: 0.8867 -- iter: 1120/1392
[A[ATraining Step: 564  | total loss: [1m[32m0.25811[0m[0m | time: 21.123s
[2K
| Adam | epoch: 013 | loss: 0.25811 - acc: 0.8949 -- iter: 1152/1392
[A[ATraining Step: 565  | total loss: [1m[32m0.26601[0m[0m | time: 21.730s
[2K
| Adam | epoch: 013 | loss: 0.26601 - acc: 0.8867 -- iter: 1184/1392
[A[ATraining Step: 566  | total loss: [1m[32m0.29405[0m[0m | time: 22.333s
[2K
| Adam | epoch: 013 | loss: 0.29405 - acc: 0.8792 -- iter: 1216/1392
[A[ATraining Step: 567  | total loss: [1m[32m0.27022[0m[0m | time: 22.934s
[2K
| Adam | epoch: 013 | loss: 0.27022 - acc: 0.8913 -- iter: 1248/1392
[A[ATraining Step: 568  | total loss: [1m[32m0.25249[0m[0m | time: 23.525s
[2K
| Adam | epoch: 013 | loss: 0.25249 - acc: 0.9022 -- iter: 1280/1392
[A[ATraining Step: 569  | total loss: [1m[32m0.24940[0m[0m | time: 24.119s
[2K
| Adam | epoch: 013 | loss: 0.24940 - acc: 0.9057 -- iter: 1312/1392
[A[ATraining Step: 570  | total loss: [1m[32m0.25633[0m[0m | time: 24.715s
[2K
| Adam | epoch: 013 | loss: 0.25633 - acc: 0.9026 -- iter: 1344/1392
[A[ATraining Step: 571  | total loss: [1m[32m0.26707[0m[0m | time: 25.321s
[2K
| Adam | epoch: 013 | loss: 0.26707 - acc: 0.8936 -- iter: 1376/1392
[A[ATraining Step: 572  | total loss: [1m[32m0.25061[0m[0m | time: 27.272s
[2K
| Adam | epoch: 013 | loss: 0.25061 - acc: 0.9011 | val_loss: 0.70223 - val_acc: 0.7264 -- iter: 1392/1392
--
Training Step: 573  | total loss: [1m[32m0.23999[0m[0m | time: 0.606s
[2K
| Adam | epoch: 014 | loss: 0.23999 - acc: 0.9079 -- iter: 0032/1392
[A[ATraining Step: 574  | total loss: [1m[32m0.24493[0m[0m | time: 1.216s
[2K
| Adam | epoch: 014 | loss: 0.24493 - acc: 0.9015 -- iter: 0064/1392
[A[ATraining Step: 575  | total loss: [1m[32m0.23572[0m[0m | time: 1.806s
[2K
| Adam | epoch: 014 | loss: 0.23572 - acc: 0.9082 -- iter: 0096/1392
[A[ATraining Step: 576  | total loss: [1m[32m0.23056[0m[0m | time: 2.407s
[2K
| Adam | epoch: 014 | loss: 0.23056 - acc: 0.9111 -- iter: 0128/1392
[A[ATraining Step: 577  | total loss: [1m[32m0.23488[0m[0m | time: 3.009s
[2K
| Adam | epoch: 014 | loss: 0.23488 - acc: 0.9075 -- iter: 0160/1392
[A[ATraining Step: 578  | total loss: [1m[32m0.22575[0m[0m | time: 3.601s
[2K
| Adam | epoch: 014 | loss: 0.22575 - acc: 0.9105 -- iter: 0192/1392
[A[ATraining Step: 579  | total loss: [1m[32m0.22277[0m[0m | time: 4.195s
[2K
| Adam | epoch: 014 | loss: 0.22277 - acc: 0.9132 -- iter: 0224/1392
[A[ATraining Step: 580  | total loss: [1m[32m0.23627[0m[0m | time: 4.789s
[2K
| Adam | epoch: 014 | loss: 0.23627 - acc: 0.9032 -- iter: 0256/1392
[A[ATraining Step: 581  | total loss: [1m[32m0.23616[0m[0m | time: 5.388s
[2K
| Adam | epoch: 014 | loss: 0.23616 - acc: 0.9003 -- iter: 0288/1392
[A[ATraining Step: 582  | total loss: [1m[32m0.22119[0m[0m | time: 5.980s
[2K
| Adam | epoch: 014 | loss: 0.22119 - acc: 0.9103 -- iter: 0320/1392
[A[ATraining Step: 583  | total loss: [1m[32m0.23673[0m[0m | time: 6.595s
[2K
| Adam | epoch: 014 | loss: 0.23673 - acc: 0.9068 -- iter: 0352/1392
[A[ATraining Step: 584  | total loss: [1m[32m0.22955[0m[0m | time: 6.910s
[2K
| Adam | epoch: 014 | loss: 0.22955 - acc: 0.9130 -- iter: 0384/1392
[A[ATraining Step: 585  | total loss: [1m[32m0.22914[0m[0m | time: 7.223s
[2K
| Adam | epoch: 014 | loss: 0.22914 - acc: 0.9092 -- iter: 0416/1392
[A[ATraining Step: 586  | total loss: [1m[32m0.21682[0m[0m | time: 7.821s
[2K
| Adam | epoch: 014 | loss: 0.21682 - acc: 0.9183 -- iter: 0448/1392
[A[ATraining Step: 587  | total loss: [1m[32m0.22345[0m[0m | time: 8.408s
[2K
| Adam | epoch: 014 | loss: 0.22345 - acc: 0.9202 -- iter: 0480/1392
[A[ATraining Step: 588  | total loss: [1m[32m0.24129[0m[0m | time: 9.007s
[2K
| Adam | epoch: 014 | loss: 0.24129 - acc: 0.9157 -- iter: 0512/1392
[A[ATraining Step: 589  | total loss: [1m[32m0.28085[0m[0m | time: 9.614s
[2K
| Adam | epoch: 014 | loss: 0.28085 - acc: 0.9053 -- iter: 0544/1392
[A[ATraining Step: 590  | total loss: [1m[32m0.26753[0m[0m | time: 10.209s
[2K
| Adam | epoch: 014 | loss: 0.26753 - acc: 0.9117 -- iter: 0576/1392
[A[ATraining Step: 591  | total loss: [1m[32m0.25492[0m[0m | time: 10.804s
[2K
| Adam | epoch: 014 | loss: 0.25492 - acc: 0.9143 -- iter: 0608/1392
[A[ATraining Step: 592  | total loss: [1m[32m0.25699[0m[0m | time: 11.424s
[2K
| Adam | epoch: 014 | loss: 0.25699 - acc: 0.9135 -- iter: 0640/1392
[A[ATraining Step: 593  | total loss: [1m[32m0.24612[0m[0m | time: 12.028s
[2K
| Adam | epoch: 014 | loss: 0.24612 - acc: 0.9190 -- iter: 0672/1392
[A[ATraining Step: 594  | total loss: [1m[32m0.24972[0m[0m | time: 12.639s
[2K
| Adam | epoch: 014 | loss: 0.24972 - acc: 0.9177 -- iter: 0704/1392
[A[ATraining Step: 595  | total loss: [1m[32m0.26772[0m[0m | time: 13.267s
[2K
| Adam | epoch: 014 | loss: 0.26772 - acc: 0.9103 -- iter: 0736/1392
[A[ATraining Step: 596  | total loss: [1m[32m0.27092[0m[0m | time: 13.872s
[2K
| Adam | epoch: 014 | loss: 0.27092 - acc: 0.9068 -- iter: 0768/1392
[A[ATraining Step: 597  | total loss: [1m[32m0.27135[0m[0m | time: 14.496s
[2K
| Adam | epoch: 014 | loss: 0.27135 - acc: 0.9005 -- iter: 0800/1392
[A[ATraining Step: 598  | total loss: [1m[32m0.29387[0m[0m | time: 15.082s
[2K
| Adam | epoch: 014 | loss: 0.29387 - acc: 0.8886 -- iter: 0832/1392
[A[ATraining Step: 599  | total loss: [1m[32m0.27658[0m[0m | time: 15.687s
[2K
| Adam | epoch: 014 | loss: 0.27658 - acc: 0.8966 -- iter: 0864/1392
[A[ATraining Step: 600  | total loss: [1m[32m0.25934[0m[0m | time: 17.674s
[2K
| Adam | epoch: 014 | loss: 0.25934 - acc: 0.9038 | val_loss: 0.69637 - val_acc: 0.7310 -- iter: 0896/1392
--
Training Step: 601  | total loss: [1m[32m0.25092[0m[0m | time: 18.307s
[2K
| Adam | epoch: 014 | loss: 0.25092 - acc: 0.9072 -- iter: 0928/1392
[A[ATraining Step: 602  | total loss: [1m[32m0.23508[0m[0m | time: 18.916s
[2K
| Adam | epoch: 014 | loss: 0.23508 - acc: 0.9165 -- iter: 0960/1392
[A[ATraining Step: 603  | total loss: [1m[32m0.22820[0m[0m | time: 19.520s
[2K
| Adam | epoch: 014 | loss: 0.22820 - acc: 0.9186 -- iter: 0992/1392
[A[ATraining Step: 604  | total loss: [1m[32m0.22062[0m[0m | time: 20.121s
[2K
| Adam | epoch: 014 | loss: 0.22062 - acc: 0.9236 -- iter: 1024/1392
[A[ATraining Step: 605  | total loss: [1m[32m0.21774[0m[0m | time: 20.722s
[2K
| Adam | epoch: 014 | loss: 0.21774 - acc: 0.9250 -- iter: 1056/1392
[A[ATraining Step: 606  | total loss: [1m[32m0.22425[0m[0m | time: 21.320s
[2K
| Adam | epoch: 014 | loss: 0.22425 - acc: 0.9262 -- iter: 1088/1392
[A[ATraining Step: 607  | total loss: [1m[32m0.22840[0m[0m | time: 21.920s
[2K
| Adam | epoch: 014 | loss: 0.22840 - acc: 0.9211 -- iter: 1120/1392
[A[ATraining Step: 608  | total loss: [1m[32m0.22312[0m[0m | time: 22.496s
[2K
| Adam | epoch: 014 | loss: 0.22312 - acc: 0.9227 -- iter: 1152/1392
[A[ATraining Step: 609  | total loss: [1m[32m0.21857[0m[0m | time: 23.086s
[2K
| Adam | epoch: 014 | loss: 0.21857 - acc: 0.9180 -- iter: 1184/1392
[A[ATraining Step: 610  | total loss: [1m[32m0.21199[0m[0m | time: 23.689s
[2K
| Adam | epoch: 014 | loss: 0.21199 - acc: 0.9230 -- iter: 1216/1392
[A[ATraining Step: 611  | total loss: [1m[32m0.21204[0m[0m | time: 24.290s
[2K
| Adam | epoch: 014 | loss: 0.21204 - acc: 0.9214 -- iter: 1248/1392
[A[ATraining Step: 612  | total loss: [1m[32m0.21490[0m[0m | time: 24.898s
[2K
| Adam | epoch: 014 | loss: 0.21490 - acc: 0.9230 -- iter: 1280/1392
[A[ATraining Step: 613  | total loss: [1m[32m0.20684[0m[0m | time: 25.497s
[2K
| Adam | epoch: 014 | loss: 0.20684 - acc: 0.9244 -- iter: 1312/1392
[A[ATraining Step: 614  | total loss: [1m[32m0.19232[0m[0m | time: 26.080s
[2K
| Adam | epoch: 014 | loss: 0.19232 - acc: 0.9320 -- iter: 1344/1392
[A[ATraining Step: 615  | total loss: [1m[32m0.18511[0m[0m | time: 26.675s
[2K
| Adam | epoch: 014 | loss: 0.18511 - acc: 0.9325 -- iter: 1376/1392
[A[ATraining Step: 616  | total loss: [1m[32m0.18613[0m[0m | time: 28.639s
[2K
| Adam | epoch: 014 | loss: 0.18613 - acc: 0.9268 | val_loss: 0.69763 - val_acc: 0.7356 -- iter: 1392/1392
--
Training Step: 617  | total loss: [1m[32m0.18859[0m[0m | time: 0.590s
[2K
| Adam | epoch: 015 | loss: 0.18859 - acc: 0.9247 -- iter: 0032/1392
[A[ATraining Step: 618  | total loss: [1m[32m0.19389[0m[0m | time: 1.165s
[2K
| Adam | epoch: 015 | loss: 0.19389 - acc: 0.9291 -- iter: 0064/1392
[A[ATraining Step: 619  | total loss: [1m[32m0.17959[0m[0m | time: 1.776s
[2K
| Adam | epoch: 015 | loss: 0.17959 - acc: 0.9331 -- iter: 0096/1392
[A[ATraining Step: 620  | total loss: [1m[32m0.17113[0m[0m | time: 2.371s
[2K
| Adam | epoch: 015 | loss: 0.17113 - acc: 0.9367 -- iter: 0128/1392
[A[ATraining Step: 621  | total loss: [1m[32m0.16794[0m[0m | time: 2.987s
[2K
| Adam | epoch: 015 | loss: 0.16794 - acc: 0.9336 -- iter: 0160/1392
[A[ATraining Step: 622  | total loss: [1m[32m0.16926[0m[0m | time: 3.584s
[2K
| Adam | epoch: 015 | loss: 0.16926 - acc: 0.9340 -- iter: 0192/1392
[A[ATraining Step: 623  | total loss: [1m[32m0.16190[0m[0m | time: 4.190s
[2K
| Adam | epoch: 015 | loss: 0.16190 - acc: 0.9375 -- iter: 0224/1392
[A[ATraining Step: 624  | total loss: [1m[32m0.15141[0m[0m | time: 4.794s
[2K
| Adam | epoch: 015 | loss: 0.15141 - acc: 0.9437 -- iter: 0256/1392
[A[ATraining Step: 625  | total loss: [1m[32m0.15926[0m[0m | time: 5.371s
[2K
| Adam | epoch: 015 | loss: 0.15926 - acc: 0.9369 -- iter: 0288/1392
[A[ATraining Step: 626  | total loss: [1m[32m0.16991[0m[0m | time: 5.966s
[2K
| Adam | epoch: 015 | loss: 0.16991 - acc: 0.9307 -- iter: 0320/1392
[A[ATraining Step: 627  | total loss: [1m[32m0.16877[0m[0m | time: 6.573s
[2K
| Adam | epoch: 015 | loss: 0.16877 - acc: 0.9314 -- iter: 0352/1392
[A[ATraining Step: 628  | total loss: [1m[32m0.16036[0m[0m | time: 7.175s
[2K
| Adam | epoch: 015 | loss: 0.16036 - acc: 0.9351 -- iter: 0384/1392
[A[ATraining Step: 629  | total loss: [1m[32m0.15611[0m[0m | time: 7.485s
[2K
| Adam | epoch: 015 | loss: 0.15611 - acc: 0.9353 -- iter: 0416/1392
[A[ATraining Step: 630  | total loss: [1m[32m0.17886[0m[0m | time: 7.818s
[2K
| Adam | epoch: 015 | loss: 0.17886 - acc: 0.9293 -- iter: 0448/1392
[A[ATraining Step: 631  | total loss: [1m[32m0.18639[0m[0m | time: 8.415s
[2K
| Adam | epoch: 015 | loss: 0.18639 - acc: 0.9301 -- iter: 0480/1392
[A[ATraining Step: 632  | total loss: [1m[32m0.21670[0m[0m | time: 9.005s
[2K
| Adam | epoch: 015 | loss: 0.21670 - acc: 0.9246 -- iter: 0512/1392
[A[ATraining Step: 633  | total loss: [1m[32m0.20362[0m[0m | time: 9.592s
[2K
| Adam | epoch: 015 | loss: 0.20362 - acc: 0.9321 -- iter: 0544/1392
[A[ATraining Step: 634  | total loss: [1m[32m0.20706[0m[0m | time: 10.182s
[2K
| Adam | epoch: 015 | loss: 0.20706 - acc: 0.9327 -- iter: 0576/1392
[A[ATraining Step: 635  | total loss: [1m[32m0.20334[0m[0m | time: 10.787s
[2K
| Adam | epoch: 015 | loss: 0.20334 - acc: 0.9300 -- iter: 0608/1392
[A[ATraining Step: 636  | total loss: [1m[32m0.18742[0m[0m | time: 11.390s
[2K
| Adam | epoch: 015 | loss: 0.18742 - acc: 0.9370 -- iter: 0640/1392
[A[ATraining Step: 637  | total loss: [1m[32m0.17354[0m[0m | time: 12.014s
[2K
| Adam | epoch: 015 | loss: 0.17354 - acc: 0.9433 -- iter: 0672/1392
[A[ATraining Step: 638  | total loss: [1m[32m0.18361[0m[0m | time: 12.621s
[2K
| Adam | epoch: 015 | loss: 0.18361 - acc: 0.9365 -- iter: 0704/1392
[A[ATraining Step: 639  | total loss: [1m[32m0.18302[0m[0m | time: 13.225s
[2K
| Adam | epoch: 015 | loss: 0.18302 - acc: 0.9335 -- iter: 0736/1392
[A[ATraining Step: 640  | total loss: [1m[32m0.19836[0m[0m | time: 13.822s
[2K
| Adam | epoch: 015 | loss: 0.19836 - acc: 0.9308 -- iter: 0768/1392
[A[ATraining Step: 641  | total loss: [1m[32m0.19452[0m[0m | time: 14.422s
[2K
| Adam | epoch: 015 | loss: 0.19452 - acc: 0.9346 -- iter: 0800/1392
[A[ATraining Step: 642  | total loss: [1m[32m0.18034[0m[0m | time: 15.025s
[2K
| Adam | epoch: 015 | loss: 0.18034 - acc: 0.9411 -- iter: 0832/1392
[A[ATraining Step: 643  | total loss: [1m[32m0.18223[0m[0m | time: 15.637s
[2K
| Adam | epoch: 015 | loss: 0.18223 - acc: 0.9439 -- iter: 0864/1392
[A[ATraining Step: 644  | total loss: [1m[32m0.17962[0m[0m | time: 16.242s
[2K
| Adam | epoch: 015 | loss: 0.17962 - acc: 0.9401 -- iter: 0896/1392
[A[ATraining Step: 645  | total loss: [1m[32m0.16974[0m[0m | time: 16.842s
[2K
| Adam | epoch: 015 | loss: 0.16974 - acc: 0.9430 -- iter: 0928/1392
[A[ATraining Step: 646  | total loss: [1m[32m0.15939[0m[0m | time: 17.444s
[2K
| Adam | epoch: 015 | loss: 0.15939 - acc: 0.9487 -- iter: 0960/1392
[A[ATraining Step: 647  | total loss: [1m[32m0.16120[0m[0m | time: 18.054s
[2K
| Adam | epoch: 015 | loss: 0.16120 - acc: 0.9476 -- iter: 0992/1392
[A[ATraining Step: 648  | total loss: [1m[32m0.14983[0m[0m | time: 18.646s
[2K
| Adam | epoch: 015 | loss: 0.14983 - acc: 0.9528 -- iter: 1024/1392
[A[ATraining Step: 649  | total loss: [1m[32m0.13858[0m[0m | time: 19.249s
[2K
| Adam | epoch: 015 | loss: 0.13858 - acc: 0.9575 -- iter: 1056/1392
[A[ATraining Step: 650  | total loss: [1m[32m0.13385[0m[0m | time: 19.856s
[2K
| Adam | epoch: 015 | loss: 0.13385 - acc: 0.9586 -- iter: 1088/1392
[A[ATraining Step: 651  | total loss: [1m[32m0.13241[0m[0m | time: 20.478s
[2K
| Adam | epoch: 015 | loss: 0.13241 - acc: 0.9597 -- iter: 1120/1392
[A[ATraining Step: 652  | total loss: [1m[32m0.12873[0m[0m | time: 21.079s
[2K
| Adam | epoch: 015 | loss: 0.12873 - acc: 0.9574 -- iter: 1152/1392
[A[ATraining Step: 653  | total loss: [1m[32m0.12600[0m[0m | time: 21.707s
[2K
| Adam | epoch: 015 | loss: 0.12600 - acc: 0.9617 -- iter: 1184/1392
[A[ATraining Step: 654  | total loss: [1m[32m0.12572[0m[0m | time: 22.306s
[2K
| Adam | epoch: 015 | loss: 0.12572 - acc: 0.9593 -- iter: 1216/1392
[A[ATraining Step: 655  | total loss: [1m[32m0.11985[0m[0m | time: 22.936s
[2K
| Adam | epoch: 015 | loss: 0.11985 - acc: 0.9633 -- iter: 1248/1392
[A[ATraining Step: 656  | total loss: [1m[32m0.11351[0m[0m | time: 23.537s
[2K
| Adam | epoch: 015 | loss: 0.11351 - acc: 0.9670 -- iter: 1280/1392
[A[ATraining Step: 657  | total loss: [1m[32m0.10488[0m[0m | time: 24.132s
[2K
| Adam | epoch: 015 | loss: 0.10488 - acc: 0.9703 -- iter: 1312/1392
[A[ATraining Step: 658  | total loss: [1m[32m0.09696[0m[0m | time: 24.761s
[2K
| Adam | epoch: 015 | loss: 0.09696 - acc: 0.9733 -- iter: 1344/1392
[A[ATraining Step: 659  | total loss: [1m[32m0.10354[0m[0m | time: 25.383s
[2K
| Adam | epoch: 015 | loss: 0.10354 - acc: 0.9666 -- iter: 1376/1392
[A[ATraining Step: 660  | total loss: [1m[32m0.12720[0m[0m | time: 27.361s
[2K
| Adam | epoch: 015 | loss: 0.12720 - acc: 0.9637 | val_loss: 0.83120 - val_acc: 0.7494 -- iter: 1392/1392
--
Training Step: 661  | total loss: [1m[32m0.12249[0m[0m | time: 0.610s
[2K
| Adam | epoch: 016 | loss: 0.12249 - acc: 0.9642 -- iter: 0032/1392
[A[ATraining Step: 662  | total loss: [1m[32m0.12587[0m[0m | time: 1.218s
[2K
| Adam | epoch: 016 | loss: 0.12587 - acc: 0.9615 -- iter: 0064/1392
[A[ATraining Step: 663  | total loss: [1m[32m0.11633[0m[0m | time: 1.843s
[2K
| Adam | epoch: 016 | loss: 0.11633 - acc: 0.9654 -- iter: 0096/1392
[A[ATraining Step: 664  | total loss: [1m[32m0.11244[0m[0m | time: 2.464s
[2K
| Adam | epoch: 016 | loss: 0.11244 - acc: 0.9657 -- iter: 0128/1392
[A[ATraining Step: 665  | total loss: [1m[32m0.10461[0m[0m | time: 3.065s
[2K
| Adam | epoch: 016 | loss: 0.10461 - acc: 0.9691 -- iter: 0160/1392
[A[ATraining Step: 666  | total loss: [1m[32m0.10573[0m[0m | time: 3.659s
[2K
| Adam | epoch: 016 | loss: 0.10573 - acc: 0.9660 -- iter: 0192/1392
[A[ATraining Step: 667  | total loss: [1m[32m0.10689[0m[0m | time: 4.246s
[2K
| Adam | epoch: 016 | loss: 0.10689 - acc: 0.9631 -- iter: 0224/1392
[A[ATraining Step: 668  | total loss: [1m[32m0.09961[0m[0m | time: 4.838s
[2K
| Adam | epoch: 016 | loss: 0.09961 - acc: 0.9668 -- iter: 0256/1392
[A[ATraining Step: 669  | total loss: [1m[32m0.09652[0m[0m | time: 5.448s
[2K
| Adam | epoch: 016 | loss: 0.09652 - acc: 0.9639 -- iter: 0288/1392
[A[ATraining Step: 670  | total loss: [1m[32m0.09809[0m[0m | time: 6.050s
[2K
| Adam | epoch: 016 | loss: 0.09809 - acc: 0.9644 -- iter: 0320/1392
[A[ATraining Step: 671  | total loss: [1m[32m0.14402[0m[0m | time: 6.699s
[2K
| Adam | epoch: 016 | loss: 0.14402 - acc: 0.9429 -- iter: 0352/1392
[A[ATraining Step: 672  | total loss: [1m[32m0.13599[0m[0m | time: 7.290s
[2K
| Adam | epoch: 016 | loss: 0.13599 - acc: 0.9455 -- iter: 0384/1392
[A[ATraining Step: 673  | total loss: [1m[32m0.14858[0m[0m | time: 7.891s
[2K
| Adam | epoch: 016 | loss: 0.14858 - acc: 0.9416 -- iter: 0416/1392
[A[ATraining Step: 674  | total loss: [1m[32m0.15193[0m[0m | time: 8.202s
[2K
| Adam | epoch: 016 | loss: 0.15193 - acc: 0.9412 -- iter: 0448/1392
[A[ATraining Step: 675  | total loss: [1m[32m0.13856[0m[0m | time: 8.515s
[2K
| Adam | epoch: 016 | loss: 0.13856 - acc: 0.9471 -- iter: 0480/1392
[A[ATraining Step: 676  | total loss: [1m[32m0.12693[0m[0m | time: 9.128s
[2K
| Adam | epoch: 016 | loss: 0.12693 - acc: 0.9524 -- iter: 0512/1392
[A[ATraining Step: 677  | total loss: [1m[32m0.12236[0m[0m | time: 9.723s
[2K
| Adam | epoch: 016 | loss: 0.12236 - acc: 0.9540 -- iter: 0544/1392
[A[ATraining Step: 678  | total loss: [1m[32m0.12652[0m[0m | time: 10.316s
[2K
| Adam | epoch: 016 | loss: 0.12652 - acc: 0.9523 -- iter: 0576/1392
[A[ATraining Step: 679  | total loss: [1m[32m0.11985[0m[0m | time: 10.913s
[2K
| Adam | epoch: 016 | loss: 0.11985 - acc: 0.9540 -- iter: 0608/1392
[A[ATraining Step: 680  | total loss: [1m[32m0.11957[0m[0m | time: 11.514s
[2K
| Adam | epoch: 016 | loss: 0.11957 - acc: 0.9555 -- iter: 0640/1392
[A[ATraining Step: 681  | total loss: [1m[32m0.12641[0m[0m | time: 12.108s
[2K
| Adam | epoch: 016 | loss: 0.12641 - acc: 0.9505 -- iter: 0672/1392
[A[ATraining Step: 682  | total loss: [1m[32m0.12495[0m[0m | time: 12.715s
[2K
| Adam | epoch: 016 | loss: 0.12495 - acc: 0.9492 -- iter: 0704/1392
[A[ATraining Step: 683  | total loss: [1m[32m0.12807[0m[0m | time: 13.321s
[2K
| Adam | epoch: 016 | loss: 0.12807 - acc: 0.9481 -- iter: 0736/1392
[A[ATraining Step: 684  | total loss: [1m[32m0.12834[0m[0m | time: 13.926s
[2K
| Adam | epoch: 016 | loss: 0.12834 - acc: 0.9501 -- iter: 0768/1392
[A[ATraining Step: 685  | total loss: [1m[32m0.11980[0m[0m | time: 14.534s
[2K
| Adam | epoch: 016 | loss: 0.11980 - acc: 0.9520 -- iter: 0800/1392
[A[ATraining Step: 686  | total loss: [1m[32m0.12108[0m[0m | time: 15.127s
[2K
| Adam | epoch: 016 | loss: 0.12108 - acc: 0.9505 -- iter: 0832/1392
[A[ATraining Step: 687  | total loss: [1m[32m0.12944[0m[0m | time: 15.731s
[2K
| Adam | epoch: 016 | loss: 0.12944 - acc: 0.9461 -- iter: 0864/1392
[A[ATraining Step: 688  | total loss: [1m[32m0.11960[0m[0m | time: 16.325s
[2K
| Adam | epoch: 016 | loss: 0.11960 - acc: 0.9515 -- iter: 0896/1392
[A[ATraining Step: 689  | total loss: [1m[32m0.11188[0m[0m | time: 16.926s
[2K
| Adam | epoch: 016 | loss: 0.11188 - acc: 0.9564 -- iter: 0928/1392
[A[ATraining Step: 690  | total loss: [1m[32m0.11247[0m[0m | time: 17.521s
[2K
| Adam | epoch: 016 | loss: 0.11247 - acc: 0.9513 -- iter: 0960/1392
[A[ATraining Step: 691  | total loss: [1m[32m0.10947[0m[0m | time: 18.116s
[2K
| Adam | epoch: 016 | loss: 0.10947 - acc: 0.9500 -- iter: 0992/1392
[A[ATraining Step: 692  | total loss: [1m[32m0.11139[0m[0m | time: 18.710s
[2K
| Adam | epoch: 016 | loss: 0.11139 - acc: 0.9487 -- iter: 1024/1392
[A[ATraining Step: 693  | total loss: [1m[32m0.10295[0m[0m | time: 19.314s
[2K
| Adam | epoch: 016 | loss: 0.10295 - acc: 0.9538 -- iter: 1056/1392
[A[ATraining Step: 694  | total loss: [1m[32m0.10003[0m[0m | time: 19.931s
[2K
| Adam | epoch: 016 | loss: 0.10003 - acc: 0.9553 -- iter: 1088/1392
[A[ATraining Step: 695  | total loss: [1m[32m0.10733[0m[0m | time: 20.520s
[2K
| Adam | epoch: 016 | loss: 0.10733 - acc: 0.9567 -- iter: 1120/1392
[A[ATraining Step: 696  | total loss: [1m[32m0.10103[0m[0m | time: 21.157s
[2K
| Adam | epoch: 016 | loss: 0.10103 - acc: 0.9610 -- iter: 1152/1392
[A[ATraining Step: 697  | total loss: [1m[32m0.09779[0m[0m | time: 21.798s
[2K
| Adam | epoch: 016 | loss: 0.09779 - acc: 0.9618 -- iter: 1184/1392
[A[ATraining Step: 698  | total loss: [1m[32m0.09171[0m[0m | time: 22.392s
[2K
| Adam | epoch: 016 | loss: 0.09171 - acc: 0.9656 -- iter: 1216/1392
[A[ATraining Step: 699  | total loss: [1m[32m0.09844[0m[0m | time: 22.990s
[2K
| Adam | epoch: 016 | loss: 0.09844 - acc: 0.9659 -- iter: 1248/1392
[A[ATraining Step: 700  | total loss: [1m[32m0.09052[0m[0m | time: 23.607s
[2K
| Adam | epoch: 016 | loss: 0.09052 - acc: 0.9693 -- iter: 1280/1392
[A[ATraining Step: 701  | total loss: [1m[32m0.10909[0m[0m | time: 24.211s
[2K
| Adam | epoch: 016 | loss: 0.10909 - acc: 0.9630 -- iter: 1312/1392
[A[ATraining Step: 702  | total loss: [1m[32m0.10050[0m[0m | time: 24.816s
[2K
| Adam | epoch: 016 | loss: 0.10050 - acc: 0.9667 -- iter: 1344/1392
[A[ATraining Step: 703  | total loss: [1m[32m0.09462[0m[0m | time: 25.411s
[2K
| Adam | epoch: 016 | loss: 0.09462 - acc: 0.9700 -- iter: 1376/1392
[A[ATraining Step: 704  | total loss: [1m[32m0.08799[0m[0m | time: 27.354s
[2K
| Adam | epoch: 016 | loss: 0.08799 - acc: 0.9730 | val_loss: 0.88066 - val_acc: 0.7333 -- iter: 1392/1392
--
Training Step: 705  | total loss: [1m[32m0.08381[0m[0m | time: 0.598s
[2K
| Adam | epoch: 017 | loss: 0.08381 - acc: 0.9757 -- iter: 0032/1392
[A[ATraining Step: 706  | total loss: [1m[32m0.08074[0m[0m | time: 1.182s
[2K
| Adam | epoch: 017 | loss: 0.08074 - acc: 0.9750 -- iter: 0064/1392
[A[ATraining Step: 707  | total loss: [1m[32m0.07892[0m[0m | time: 1.780s
[2K
| Adam | epoch: 017 | loss: 0.07892 - acc: 0.9775 -- iter: 0096/1392
[A[ATraining Step: 708  | total loss: [1m[32m0.07535[0m[0m | time: 2.378s
[2K
| Adam | epoch: 017 | loss: 0.07535 - acc: 0.9798 -- iter: 0128/1392
[A[ATraining Step: 709  | total loss: [1m[32m0.07610[0m[0m | time: 2.980s
[2K
| Adam | epoch: 017 | loss: 0.07610 - acc: 0.9787 -- iter: 0160/1392
[A[ATraining Step: 710  | total loss: [1m[32m0.07652[0m[0m | time: 3.609s
[2K
| Adam | epoch: 017 | loss: 0.07652 - acc: 0.9746 -- iter: 0192/1392
[A[ATraining Step: 711  | total loss: [1m[32m0.07023[0m[0m | time: 4.210s
[2K
| Adam | epoch: 017 | loss: 0.07023 - acc: 0.9771 -- iter: 0224/1392
[A[ATraining Step: 712  | total loss: [1m[32m0.06823[0m[0m | time: 4.808s
[2K
| Adam | epoch: 017 | loss: 0.06823 - acc: 0.9763 -- iter: 0256/1392
[A[ATraining Step: 713  | total loss: [1m[32m0.07704[0m[0m | time: 5.414s
[2K
| Adam | epoch: 017 | loss: 0.07704 - acc: 0.9724 -- iter: 0288/1392
[A[ATraining Step: 714  | total loss: [1m[32m0.09097[0m[0m | time: 6.011s
[2K
| Adam | epoch: 017 | loss: 0.09097 - acc: 0.9658 -- iter: 0320/1392
[A[ATraining Step: 715  | total loss: [1m[32m0.09692[0m[0m | time: 6.614s
[2K
| Adam | epoch: 017 | loss: 0.09692 - acc: 0.9661 -- iter: 0352/1392
[A[ATraining Step: 716  | total loss: [1m[32m0.09152[0m[0m | time: 7.224s
[2K
| Adam | epoch: 017 | loss: 0.09152 - acc: 0.9695 -- iter: 0384/1392
[A[ATraining Step: 717  | total loss: [1m[32m0.08622[0m[0m | time: 7.830s
[2K
| Adam | epoch: 017 | loss: 0.08622 - acc: 0.9725 -- iter: 0416/1392
[A[ATraining Step: 718  | total loss: [1m[32m0.10380[0m[0m | time: 8.432s
[2K
| Adam | epoch: 017 | loss: 0.10380 - acc: 0.9659 -- iter: 0448/1392
[A[ATraining Step: 719  | total loss: [1m[32m0.11192[0m[0m | time: 8.752s
[2K
| Adam | epoch: 017 | loss: 0.11192 - acc: 0.9631 -- iter: 0480/1392
[A[ATraining Step: 720  | total loss: [1m[32m0.12846[0m[0m | time: 9.058s
[2K
| Adam | epoch: 017 | loss: 0.12846 - acc: 0.9605 -- iter: 0512/1392
[A[ATraining Step: 721  | total loss: [1m[32m0.13545[0m[0m | time: 9.660s
[2K
| Adam | epoch: 017 | loss: 0.13545 - acc: 0.9582 -- iter: 0544/1392
[A[ATraining Step: 722  | total loss: [1m[32m0.13096[0m[0m | time: 10.284s
[2K
| Adam | epoch: 017 | loss: 0.13096 - acc: 0.9593 -- iter: 0576/1392
[A[ATraining Step: 723  | total loss: [1m[32m0.12537[0m[0m | time: 10.878s
[2K
| Adam | epoch: 017 | loss: 0.12537 - acc: 0.9633 -- iter: 0608/1392
[A[ATraining Step: 724  | total loss: [1m[32m0.12676[0m[0m | time: 11.472s
[2K
| Adam | epoch: 017 | loss: 0.12676 - acc: 0.9639 -- iter: 0640/1392
[A[ATraining Step: 725  | total loss: [1m[32m0.12273[0m[0m | time: 12.078s
[2K
| Adam | epoch: 017 | loss: 0.12273 - acc: 0.9612 -- iter: 0672/1392
[A[ATraining Step: 726  | total loss: [1m[32m0.12273[0m[0m | time: 12.688s
[2K
| Adam | epoch: 017 | loss: 0.12273 - acc: 0.9589 -- iter: 0704/1392
[A[ATraining Step: 727  | total loss: [1m[32m0.15260[0m[0m | time: 13.303s
[2K
| Adam | epoch: 017 | loss: 0.15260 - acc: 0.9473 -- iter: 0736/1392
[A[ATraining Step: 728  | total loss: [1m[32m0.15351[0m[0m | time: 13.910s
[2K
| Adam | epoch: 017 | loss: 0.15351 - acc: 0.9464 -- iter: 0768/1392
[A[ATraining Step: 729  | total loss: [1m[32m0.15538[0m[0m | time: 14.515s
[2K
| Adam | epoch: 017 | loss: 0.15538 - acc: 0.9455 -- iter: 0800/1392
[A[ATraining Step: 730  | total loss: [1m[32m0.14691[0m[0m | time: 15.124s
[2K
| Adam | epoch: 017 | loss: 0.14691 - acc: 0.9478 -- iter: 0832/1392
[A[ATraining Step: 731  | total loss: [1m[32m0.13635[0m[0m | time: 15.738s
[2K
| Adam | epoch: 017 | loss: 0.13635 - acc: 0.9530 -- iter: 0864/1392
[A[ATraining Step: 732  | total loss: [1m[32m0.14191[0m[0m | time: 16.331s
[2K
| Adam | epoch: 017 | loss: 0.14191 - acc: 0.9546 -- iter: 0896/1392
[A[ATraining Step: 733  | total loss: [1m[32m0.14754[0m[0m | time: 16.926s
[2K
| Adam | epoch: 017 | loss: 0.14754 - acc: 0.9529 -- iter: 0928/1392
[A[ATraining Step: 734  | total loss: [1m[32m0.14429[0m[0m | time: 17.549s
[2K
| Adam | epoch: 017 | loss: 0.14429 - acc: 0.9513 -- iter: 0960/1392
[A[ATraining Step: 735  | total loss: [1m[32m0.13297[0m[0m | time: 18.148s
[2K
| Adam | epoch: 017 | loss: 0.13297 - acc: 0.9562 -- iter: 0992/1392
[A[ATraining Step: 736  | total loss: [1m[32m0.13277[0m[0m | time: 18.752s
[2K
| Adam | epoch: 017 | loss: 0.13277 - acc: 0.9575 -- iter: 1024/1392
[A[ATraining Step: 737  | total loss: [1m[32m0.12242[0m[0m | time: 19.371s
[2K
| Adam | epoch: 017 | loss: 0.12242 - acc: 0.9617 -- iter: 1056/1392
[A[ATraining Step: 738  | total loss: [1m[32m0.13408[0m[0m | time: 19.974s
[2K
| Adam | epoch: 017 | loss: 0.13408 - acc: 0.9593 -- iter: 1088/1392
[A[ATraining Step: 739  | total loss: [1m[32m0.12380[0m[0m | time: 20.575s
[2K
| Adam | epoch: 017 | loss: 0.12380 - acc: 0.9634 -- iter: 1120/1392
[A[ATraining Step: 740  | total loss: [1m[32m0.12019[0m[0m | time: 21.187s
[2K
| Adam | epoch: 017 | loss: 0.12019 - acc: 0.9639 -- iter: 1152/1392
[A[ATraining Step: 741  | total loss: [1m[32m0.11037[0m[0m | time: 21.792s
[2K
| Adam | epoch: 017 | loss: 0.11037 - acc: 0.9675 -- iter: 1184/1392
[A[ATraining Step: 742  | total loss: [1m[32m0.11316[0m[0m | time: 22.393s
[2K
| Adam | epoch: 017 | loss: 0.11316 - acc: 0.9676 -- iter: 1216/1392
[A[ATraining Step: 743  | total loss: [1m[32m0.11164[0m[0m | time: 22.995s
[2K
| Adam | epoch: 017 | loss: 0.11164 - acc: 0.9678 -- iter: 1248/1392
[A[ATraining Step: 744  | total loss: [1m[32m0.10455[0m[0m | time: 23.592s
[2K
| Adam | epoch: 017 | loss: 0.10455 - acc: 0.9710 -- iter: 1280/1392
[A[ATraining Step: 745  | total loss: [1m[32m0.10174[0m[0m | time: 24.216s
[2K
| Adam | epoch: 017 | loss: 0.10174 - acc: 0.9708 -- iter: 1312/1392
[A[ATraining Step: 746  | total loss: [1m[32m0.10444[0m[0m | time: 24.820s
[2K
| Adam | epoch: 017 | loss: 0.10444 - acc: 0.9706 -- iter: 1344/1392
[A[ATraining Step: 747  | total loss: [1m[32m0.09617[0m[0m | time: 25.418s
[2K
| Adam | epoch: 017 | loss: 0.09617 - acc: 0.9735 -- iter: 1376/1392
[A[ATraining Step: 748  | total loss: [1m[32m0.09274[0m[0m | time: 27.362s
[2K
| Adam | epoch: 017 | loss: 0.09274 - acc: 0.9730 | val_loss: 0.79441 - val_acc: 0.7632 -- iter: 1392/1392
--
Training Step: 749  | total loss: [1m[32m0.09112[0m[0m | time: 0.592s
[2K
| Adam | epoch: 018 | loss: 0.09112 - acc: 0.9726 -- iter: 0032/1392
[A[ATraining Step: 750  | total loss: [1m[32m0.08441[0m[0m | time: 1.193s
[2K
| Adam | epoch: 018 | loss: 0.08441 - acc: 0.9753 -- iter: 0064/1392
[A[ATraining Step: 751  | total loss: [1m[32m0.07892[0m[0m | time: 1.804s
[2K
| Adam | epoch: 018 | loss: 0.07892 - acc: 0.9778 -- iter: 0096/1392
[A[ATraining Step: 752  | total loss: [1m[32m0.08812[0m[0m | time: 2.398s
[2K
| Adam | epoch: 018 | loss: 0.08812 - acc: 0.9738 -- iter: 0128/1392
[A[ATraining Step: 753  | total loss: [1m[32m0.08179[0m[0m | time: 3.015s
[2K
| Adam | epoch: 018 | loss: 0.08179 - acc: 0.9764 -- iter: 0160/1392
[A[ATraining Step: 754  | total loss: [1m[32m0.08694[0m[0m | time: 3.614s
[2K
| Adam | epoch: 018 | loss: 0.08694 - acc: 0.9756 -- iter: 0192/1392
[A[ATraining Step: 755  | total loss: [1m[32m0.08322[0m[0m | time: 4.209s
[2K
| Adam | epoch: 018 | loss: 0.08322 - acc: 0.9781 -- iter: 0224/1392
[A[ATraining Step: 756  | total loss: [1m[32m0.09030[0m[0m | time: 4.803s
[2K
| Adam | epoch: 018 | loss: 0.09030 - acc: 0.9740 -- iter: 0256/1392
[A[ATraining Step: 757  | total loss: [1m[32m0.08306[0m[0m | time: 5.397s
[2K
| Adam | epoch: 018 | loss: 0.08306 - acc: 0.9766 -- iter: 0288/1392
[A[ATraining Step: 758  | total loss: [1m[32m0.07591[0m[0m | time: 5.985s
[2K
| Adam | epoch: 018 | loss: 0.07591 - acc: 0.9789 -- iter: 0320/1392
[A[ATraining Step: 759  | total loss: [1m[32m0.09419[0m[0m | time: 6.584s
[2K
| Adam | epoch: 018 | loss: 0.09419 - acc: 0.9717 -- iter: 0352/1392
[A[ATraining Step: 760  | total loss: [1m[32m0.10439[0m[0m | time: 7.194s
[2K
| Adam | epoch: 018 | loss: 0.10439 - acc: 0.9714 -- iter: 0384/1392
[A[ATraining Step: 761  | total loss: [1m[32m0.10256[0m[0m | time: 7.791s
[2K
| Adam | epoch: 018 | loss: 0.10256 - acc: 0.9742 -- iter: 0416/1392
[A[ATraining Step: 762  | total loss: [1m[32m0.09484[0m[0m | time: 8.387s
[2K
| Adam | epoch: 018 | loss: 0.09484 - acc: 0.9768 -- iter: 0448/1392
[A[ATraining Step: 763  | total loss: [1m[32m0.09390[0m[0m | time: 8.996s
[2K
| Adam | epoch: 018 | loss: 0.09390 - acc: 0.9760 -- iter: 0480/1392
[A[ATraining Step: 764  | total loss: [1m[32m0.08675[0m[0m | time: 9.308s
[2K
| Adam | epoch: 018 | loss: 0.08675 - acc: 0.9784 -- iter: 0512/1392
[A[ATraining Step: 765  | total loss: [1m[32m0.07937[0m[0m | time: 9.620s
[2K
| Adam | epoch: 018 | loss: 0.07937 - acc: 0.9806 -- iter: 0544/1392
[A[ATraining Step: 766  | total loss: [1m[32m0.07292[0m[0m | time: 10.215s
[2K
| Adam | epoch: 018 | loss: 0.07292 - acc: 0.9825 -- iter: 0576/1392
[A[ATraining Step: 767  | total loss: [1m[32m0.06964[0m[0m | time: 10.804s
[2K
| Adam | epoch: 018 | loss: 0.06964 - acc: 0.9843 -- iter: 0608/1392
[A[ATraining Step: 768  | total loss: [1m[32m0.08711[0m[0m | time: 11.396s
[2K
| Adam | epoch: 018 | loss: 0.08711 - acc: 0.9702 -- iter: 0640/1392
[A[ATraining Step: 769  | total loss: [1m[32m0.08838[0m[0m | time: 11.992s
[2K
| Adam | epoch: 018 | loss: 0.08838 - acc: 0.9701 -- iter: 0672/1392
[A[ATraining Step: 770  | total loss: [1m[32m0.08450[0m[0m | time: 12.589s
[2K
| Adam | epoch: 018 | loss: 0.08450 - acc: 0.9699 -- iter: 0704/1392
[A[ATraining Step: 771  | total loss: [1m[32m0.07857[0m[0m | time: 13.186s
[2K
| Adam | epoch: 018 | loss: 0.07857 - acc: 0.9729 -- iter: 0736/1392
[A[ATraining Step: 772  | total loss: [1m[32m0.07614[0m[0m | time: 13.777s
[2K
| Adam | epoch: 018 | loss: 0.07614 - acc: 0.9756 -- iter: 0768/1392
[A[ATraining Step: 773  | total loss: [1m[32m0.08477[0m[0m | time: 14.366s
[2K
| Adam | epoch: 018 | loss: 0.08477 - acc: 0.9687 -- iter: 0800/1392
[A[ATraining Step: 774  | total loss: [1m[32m0.08106[0m[0m | time: 14.958s
[2K
| Adam | epoch: 018 | loss: 0.08106 - acc: 0.9718 -- iter: 0832/1392
[A[ATraining Step: 775  | total loss: [1m[32m0.08353[0m[0m | time: 15.538s
[2K
| Adam | epoch: 018 | loss: 0.08353 - acc: 0.9684 -- iter: 0864/1392
[A[ATraining Step: 776  | total loss: [1m[32m0.08884[0m[0m | time: 16.155s
[2K
| Adam | epoch: 018 | loss: 0.08884 - acc: 0.9684 -- iter: 0896/1392
[A[ATraining Step: 777  | total loss: [1m[32m0.08607[0m[0m | time: 16.785s
[2K
| Adam | epoch: 018 | loss: 0.08607 - acc: 0.9653 -- iter: 0928/1392
[A[ATraining Step: 778  | total loss: [1m[32m0.10029[0m[0m | time: 17.389s
[2K
| Adam | epoch: 018 | loss: 0.10029 - acc: 0.9626 -- iter: 0960/1392
[A[ATraining Step: 779  | total loss: [1m[32m0.09541[0m[0m | time: 17.989s
[2K
| Adam | epoch: 018 | loss: 0.09541 - acc: 0.9632 -- iter: 0992/1392
[A[ATraining Step: 780  | total loss: [1m[32m0.09470[0m[0m | time: 18.592s
[2K
| Adam | epoch: 018 | loss: 0.09470 - acc: 0.9637 -- iter: 1024/1392
[A[ATraining Step: 781  | total loss: [1m[32m0.09046[0m[0m | time: 19.188s
[2K
| Adam | epoch: 018 | loss: 0.09046 - acc: 0.9642 -- iter: 1056/1392
[A[ATraining Step: 782  | total loss: [1m[32m0.08381[0m[0m | time: 19.797s
[2K
| Adam | epoch: 018 | loss: 0.08381 - acc: 0.9678 -- iter: 1088/1392
[A[ATraining Step: 783  | total loss: [1m[32m0.08413[0m[0m | time: 20.404s
[2K
| Adam | epoch: 018 | loss: 0.08413 - acc: 0.9648 -- iter: 1120/1392
[A[ATraining Step: 784  | total loss: [1m[32m0.08259[0m[0m | time: 21.003s
[2K
| Adam | epoch: 018 | loss: 0.08259 - acc: 0.9652 -- iter: 1152/1392
[A[ATraining Step: 785  | total loss: [1m[32m0.08046[0m[0m | time: 21.636s
[2K
| Adam | epoch: 018 | loss: 0.08046 - acc: 0.9655 -- iter: 1184/1392
[A[ATraining Step: 786  | total loss: [1m[32m0.07564[0m[0m | time: 22.254s
[2K
| Adam | epoch: 018 | loss: 0.07564 - acc: 0.9690 -- iter: 1216/1392
[A[ATraining Step: 787  | total loss: [1m[32m0.08595[0m[0m | time: 22.858s
[2K
| Adam | epoch: 018 | loss: 0.08595 - acc: 0.9658 -- iter: 1248/1392
[A[ATraining Step: 788  | total loss: [1m[32m0.08535[0m[0m | time: 23.466s
[2K
| Adam | epoch: 018 | loss: 0.08535 - acc: 0.9661 -- iter: 1280/1392
[A[ATraining Step: 789  | total loss: [1m[32m0.07763[0m[0m | time: 24.088s
[2K
| Adam | epoch: 018 | loss: 0.07763 - acc: 0.9695 -- iter: 1312/1392
[A[ATraining Step: 790  | total loss: [1m[32m0.08188[0m[0m | time: 24.693s
[2K
| Adam | epoch: 018 | loss: 0.08188 - acc: 0.9663 -- iter: 1344/1392
[A[ATraining Step: 791  | total loss: [1m[32m0.07747[0m[0m | time: 25.293s
[2K
| Adam | epoch: 018 | loss: 0.07747 - acc: 0.9697 -- iter: 1376/1392
[A[ATraining Step: 792  | total loss: [1m[32m0.07330[0m[0m | time: 27.264s
[2K
| Adam | epoch: 018 | loss: 0.07330 - acc: 0.9727 | val_loss: 0.95526 - val_acc: 0.7356 -- iter: 1392/1392
--
Training Step: 793  | total loss: [1m[32m0.07523[0m[0m | time: 0.600s
[2K
| Adam | epoch: 019 | loss: 0.07523 - acc: 0.9723 -- iter: 0032/1392
[A[ATraining Step: 794  | total loss: [1m[32m0.07151[0m[0m | time: 1.195s
[2K
| Adam | epoch: 019 | loss: 0.07151 - acc: 0.9720 -- iter: 0064/1392
[A[ATraining Step: 795  | total loss: [1m[32m0.06709[0m[0m | time: 1.787s
[2K
| Adam | epoch: 019 | loss: 0.06709 - acc: 0.9748 -- iter: 0096/1392
[A[ATraining Step: 796  | total loss: [1m[32m0.07134[0m[0m | time: 2.385s
[2K
| Adam | epoch: 019 | loss: 0.07134 - acc: 0.9742 -- iter: 0128/1392
[A[ATraining Step: 797  | total loss: [1m[32m0.06992[0m[0m | time: 2.982s
[2K
| Adam | epoch: 019 | loss: 0.06992 - acc: 0.9736 -- iter: 0160/1392
[A[ATraining Step: 798  | total loss: [1m[32m0.06837[0m[0m | time: 3.586s
[2K
| Adam | epoch: 019 | loss: 0.06837 - acc: 0.9731 -- iter: 0192/1392
[A[ATraining Step: 799  | total loss: [1m[32m0.06295[0m[0m | time: 4.174s
[2K
| Adam | epoch: 019 | loss: 0.06295 - acc: 0.9758 -- iter: 0224/1392
[A[ATraining Step: 800  | total loss: [1m[32m0.05894[0m[0m | time: 6.126s
[2K
| Adam | epoch: 019 | loss: 0.05894 - acc: 0.9782 | val_loss: 0.88530 - val_acc: 0.7517 -- iter: 0256/1392
--
Training Step: 801  | total loss: [1m[32m0.05761[0m[0m | time: 6.722s
[2K
| Adam | epoch: 019 | loss: 0.05761 - acc: 0.9773 -- iter: 0288/1392
[A[ATraining Step: 802  | total loss: [1m[32m0.06677[0m[0m | time: 7.343s
[2K
| Adam | epoch: 019 | loss: 0.06677 - acc: 0.9764 -- iter: 0320/1392
[A[ATraining Step: 803  | total loss: [1m[32m0.06313[0m[0m | time: 7.959s
[2K
| Adam | epoch: 019 | loss: 0.06313 - acc: 0.9788 -- iter: 0352/1392
[A[ATraining Step: 804  | total loss: [1m[32m0.05889[0m[0m | time: 8.555s
[2K
| Adam | epoch: 019 | loss: 0.05889 - acc: 0.9809 -- iter: 0384/1392
[A[ATraining Step: 805  | total loss: [1m[32m0.06792[0m[0m | time: 9.126s
[2K
| Adam | epoch: 019 | loss: 0.06792 - acc: 0.9734 -- iter: 0416/1392
[A[ATraining Step: 806  | total loss: [1m[32m0.06265[0m[0m | time: 9.717s
[2K
| Adam | epoch: 019 | loss: 0.06265 - acc: 0.9761 -- iter: 0448/1392
[A[ATraining Step: 807  | total loss: [1m[32m0.06694[0m[0m | time: 10.307s
[2K
| Adam | epoch: 019 | loss: 0.06694 - acc: 0.9754 -- iter: 0480/1392
[A[ATraining Step: 808  | total loss: [1m[32m0.06409[0m[0m | time: 10.907s
[2K
| Adam | epoch: 019 | loss: 0.06409 - acc: 0.9778 -- iter: 0512/1392
[A[ATraining Step: 809  | total loss: [1m[32m0.07318[0m[0m | time: 11.239s
[2K
| Adam | epoch: 019 | loss: 0.07318 - acc: 0.9738 -- iter: 0544/1392
[A[ATraining Step: 810  | total loss: [1m[32m0.07229[0m[0m | time: 11.547s
[2K
| Adam | epoch: 019 | loss: 0.07229 - acc: 0.9702 -- iter: 0576/1392
[A[ATraining Step: 811  | total loss: [1m[32m0.06718[0m[0m | time: 12.139s
[2K
| Adam | epoch: 019 | loss: 0.06718 - acc: 0.9732 -- iter: 0608/1392
[A[ATraining Step: 812  | total loss: [1m[32m0.07008[0m[0m | time: 12.733s
[2K
| Adam | epoch: 019 | loss: 0.07008 - acc: 0.9696 -- iter: 0640/1392
[A[ATraining Step: 813  | total loss: [1m[32m0.06539[0m[0m | time: 13.333s
[2K
| Adam | epoch: 019 | loss: 0.06539 - acc: 0.9726 -- iter: 0672/1392
[A[ATraining Step: 814  | total loss: [1m[32m0.06106[0m[0m | time: 13.935s
[2K
| Adam | epoch: 019 | loss: 0.06106 - acc: 0.9754 -- iter: 0704/1392
[A[ATraining Step: 815  | total loss: [1m[32m0.05887[0m[0m | time: 14.542s
[2K
| Adam | epoch: 019 | loss: 0.05887 - acc: 0.9778 -- iter: 0736/1392
[A[ATraining Step: 816  | total loss: [1m[32m0.05438[0m[0m | time: 15.144s
[2K
| Adam | epoch: 019 | loss: 0.05438 - acc: 0.9800 -- iter: 0768/1392
[A[ATraining Step: 817  | total loss: [1m[32m0.05084[0m[0m | time: 15.750s
[2K
| Adam | epoch: 019 | loss: 0.05084 - acc: 0.9820 -- iter: 0800/1392
[A[ATraining Step: 818  | total loss: [1m[32m0.04764[0m[0m | time: 16.359s
[2K
| Adam | epoch: 019 | loss: 0.04764 - acc: 0.9838 -- iter: 0832/1392
[A[ATraining Step: 819  | total loss: [1m[32m0.04781[0m[0m | time: 16.954s
[2K
| Adam | epoch: 019 | loss: 0.04781 - acc: 0.9823 -- iter: 0864/1392
[A[ATraining Step: 820  | total loss: [1m[32m0.04486[0m[0m | time: 17.539s
[2K
| Adam | epoch: 019 | loss: 0.04486 - acc: 0.9841 -- iter: 0896/1392
[A[ATraining Step: 821  | total loss: [1m[32m0.04354[0m[0m | time: 18.139s
[2K
| Adam | epoch: 019 | loss: 0.04354 - acc: 0.9857 -- iter: 0928/1392
[A[ATraining Step: 822  | total loss: [1m[32m0.05868[0m[0m | time: 18.735s
[2K
| Adam | epoch: 019 | loss: 0.05868 - acc: 0.9840 -- iter: 0960/1392
[A[ATraining Step: 823  | total loss: [1m[32m0.07371[0m[0m | time: 19.330s
[2K
| Adam | epoch: 019 | loss: 0.07371 - acc: 0.9825 -- iter: 0992/1392
[A[ATraining Step: 824  | total loss: [1m[32m0.08349[0m[0m | time: 19.948s
[2K
| Adam | epoch: 019 | loss: 0.08349 - acc: 0.9811 -- iter: 1024/1392
[A[ATraining Step: 825  | total loss: [1m[32m0.08204[0m[0m | time: 20.551s
[2K
| Adam | epoch: 019 | loss: 0.08204 - acc: 0.9799 -- iter: 1056/1392
[A[ATraining Step: 826  | total loss: [1m[32m0.08576[0m[0m | time: 21.164s
[2K
| Adam | epoch: 019 | loss: 0.08576 - acc: 0.9756 -- iter: 1088/1392
[A[ATraining Step: 827  | total loss: [1m[32m0.07806[0m[0m | time: 21.792s
[2K
| Adam | epoch: 019 | loss: 0.07806 - acc: 0.9781 -- iter: 1120/1392
[A[ATraining Step: 828  | total loss: [1m[32m0.07809[0m[0m | time: 22.415s
[2K
| Adam | epoch: 019 | loss: 0.07809 - acc: 0.9771 -- iter: 1152/1392
[A[ATraining Step: 829  | total loss: [1m[32m0.07220[0m[0m | time: 23.012s
[2K
| Adam | epoch: 019 | loss: 0.07220 - acc: 0.9794 -- iter: 1184/1392
[A[ATraining Step: 830  | total loss: [1m[32m0.07664[0m[0m | time: 23.605s
[2K
| Adam | epoch: 019 | loss: 0.07664 - acc: 0.9752 -- iter: 1216/1392
[A[ATraining Step: 831  | total loss: [1m[32m0.06938[0m[0m | time: 24.202s
[2K
| Adam | epoch: 019 | loss: 0.06938 - acc: 0.9777 -- iter: 1248/1392
[A[ATraining Step: 832  | total loss: [1m[32m0.06981[0m[0m | time: 24.796s
[2K
| Adam | epoch: 019 | loss: 0.06981 - acc: 0.9768 -- iter: 1280/1392
[A[ATraining Step: 833  | total loss: [1m[32m0.06373[0m[0m | time: 25.418s
[2K
| Adam | epoch: 019 | loss: 0.06373 - acc: 0.9791 -- iter: 1312/1392
[A[ATraining Step: 834  | total loss: [1m[32m0.05905[0m[0m | time: 26.017s
[2K
| Adam | epoch: 019 | loss: 0.05905 - acc: 0.9812 -- iter: 1344/1392
[A[ATraining Step: 835  | total loss: [1m[32m0.05739[0m[0m | time: 26.613s
[2K
| Adam | epoch: 019 | loss: 0.05739 - acc: 0.9831 -- iter: 1376/1392
[A[ATraining Step: 836  | total loss: [1m[32m0.05789[0m[0m | time: 28.595s
[2K
| Adam | epoch: 019 | loss: 0.05789 - acc: 0.9785 | val_loss: 0.99699 - val_acc: 0.7655 -- iter: 1392/1392
--
Training Step: 837  | total loss: [1m[32m0.05238[0m[0m | time: 0.596s
[2K
| Adam | epoch: 020 | loss: 0.05238 - acc: 0.9807 -- iter: 0032/1392
[A[ATraining Step: 838  | total loss: [1m[32m0.04914[0m[0m | time: 1.214s
[2K
| Adam | epoch: 020 | loss: 0.04914 - acc: 0.9826 -- iter: 0064/1392
[A[ATraining Step: 839  | total loss: [1m[32m0.04491[0m[0m | time: 1.820s
[2K
| Adam | epoch: 020 | loss: 0.04491 - acc: 0.9844 -- iter: 0096/1392
[A[ATraining Step: 840  | total loss: [1m[32m0.04157[0m[0m | time: 2.418s
[2K
| Adam | epoch: 020 | loss: 0.04157 - acc: 0.9859 -- iter: 0128/1392
[A[ATraining Step: 841  | total loss: [1m[32m0.03981[0m[0m | time: 3.014s
[2K
| Adam | epoch: 020 | loss: 0.03981 - acc: 0.9873 -- iter: 0160/1392
[A[ATraining Step: 842  | total loss: [1m[32m0.03643[0m[0m | time: 3.613s
[2K
| Adam | epoch: 020 | loss: 0.03643 - acc: 0.9886 -- iter: 0192/1392
[A[ATraining Step: 843  | total loss: [1m[32m0.03454[0m[0m | time: 4.223s
[2K
| Adam | epoch: 020 | loss: 0.03454 - acc: 0.9897 -- iter: 0224/1392
[A[ATraining Step: 844  | total loss: [1m[32m0.03142[0m[0m | time: 4.824s
[2K
| Adam | epoch: 020 | loss: 0.03142 - acc: 0.9908 -- iter: 0256/1392
[A[ATraining Step: 845  | total loss: [1m[32m0.04588[0m[0m | time: 5.433s
[2K
| Adam | epoch: 020 | loss: 0.04588 - acc: 0.9886 -- iter: 0288/1392
[A[ATraining Step: 846  | total loss: [1m[32m0.04188[0m[0m | time: 6.056s
[2K
| Adam | epoch: 020 | loss: 0.04188 - acc: 0.9897 -- iter: 0320/1392
[A[ATraining Step: 847  | total loss: [1m[32m0.03843[0m[0m | time: 6.661s
[2K
| Adam | epoch: 020 | loss: 0.03843 - acc: 0.9907 -- iter: 0352/1392
[A[ATraining Step: 848  | total loss: [1m[32m0.03516[0m[0m | time: 7.250s
[2K
| Adam | epoch: 020 | loss: 0.03516 - acc: 0.9917 -- iter: 0384/1392
[A[ATraining Step: 849  | total loss: [1m[32m0.03313[0m[0m | time: 7.855s
[2K
| Adam | epoch: 020 | loss: 0.03313 - acc: 0.9925 -- iter: 0416/1392
[A[ATraining Step: 850  | total loss: [1m[32m0.04222[0m[0m | time: 8.460s
[2K
| Adam | epoch: 020 | loss: 0.04222 - acc: 0.9901 -- iter: 0448/1392
[A[ATraining Step: 851  | total loss: [1m[32m0.04014[0m[0m | time: 9.063s
[2K
| Adam | epoch: 020 | loss: 0.04014 - acc: 0.9911 -- iter: 0480/1392
[A[ATraining Step: 852  | total loss: [1m[32m0.05157[0m[0m | time: 9.697s
[2K
| Adam | epoch: 020 | loss: 0.05157 - acc: 0.9889 -- iter: 0512/1392
[A[ATraining Step: 853  | total loss: [1m[32m0.06184[0m[0m | time: 10.298s
[2K
| Adam | epoch: 020 | loss: 0.06184 - acc: 0.9869 -- iter: 0544/1392
[A[ATraining Step: 854  | total loss: [1m[32m0.05816[0m[0m | time: 10.607s
[2K
| Adam | epoch: 020 | loss: 0.05816 - acc: 0.9882 -- iter: 0576/1392
[A[ATraining Step: 855  | total loss: [1m[32m0.05302[0m[0m | time: 10.930s
[2K
| Adam | epoch: 020 | loss: 0.05302 - acc: 0.9894 -- iter: 0608/1392
[A[ATraining Step: 856  | total loss: [1m[32m0.04828[0m[0m | time: 11.540s
[2K
| Adam | epoch: 020 | loss: 0.04828 - acc: 0.9904 -- iter: 0640/1392
[A[ATraining Step: 857  | total loss: [1m[32m0.07361[0m[0m | time: 12.139s
[2K
| Adam | epoch: 020 | loss: 0.07361 - acc: 0.9789 -- iter: 0672/1392
[A[ATraining Step: 858  | total loss: [1m[32m0.06784[0m[0m | time: 12.752s
[2K
| Adam | epoch: 020 | loss: 0.06784 - acc: 0.9810 -- iter: 0704/1392
[A[ATraining Step: 859  | total loss: [1m[32m0.07083[0m[0m | time: 13.365s
[2K
| Adam | epoch: 020 | loss: 0.07083 - acc: 0.9798 -- iter: 0736/1392
[A[ATraining Step: 860  | total loss: [1m[32m0.07508[0m[0m | time: 13.962s
[2K
| Adam | epoch: 020 | loss: 0.07508 - acc: 0.9787 -- iter: 0768/1392
[A[ATraining Step: 861  | total loss: [1m[32m0.07437[0m[0m | time: 14.561s
[2K
| Adam | epoch: 020 | loss: 0.07437 - acc: 0.9777 -- iter: 0800/1392
[A[ATraining Step: 862  | total loss: [1m[32m0.07223[0m[0m | time: 15.161s
[2K
| Adam | epoch: 020 | loss: 0.07223 - acc: 0.9768 -- iter: 0832/1392
[A[ATraining Step: 863  | total loss: [1m[32m0.07987[0m[0m | time: 15.760s
[2K
| Adam | epoch: 020 | loss: 0.07987 - acc: 0.9760 -- iter: 0864/1392
[A[ATraining Step: 864  | total loss: [1m[32m0.08966[0m[0m | time: 16.364s
[2K
| Adam | epoch: 020 | loss: 0.08966 - acc: 0.9721 -- iter: 0896/1392
[A[ATraining Step: 865  | total loss: [1m[32m0.08242[0m[0m | time: 16.958s
[2K
| Adam | epoch: 020 | loss: 0.08242 - acc: 0.9749 -- iter: 0928/1392
[A[ATraining Step: 866  | total loss: [1m[32m0.08607[0m[0m | time: 17.551s
[2K
| Adam | epoch: 020 | loss: 0.08607 - acc: 0.9743 -- iter: 0960/1392
[A[ATraining Step: 867  | total loss: [1m[32m0.08374[0m[0m | time: 18.159s
[2K
| Adam | epoch: 020 | loss: 0.08374 - acc: 0.9769 -- iter: 0992/1392
[A[ATraining Step: 868  | total loss: [1m[32m0.10957[0m[0m | time: 18.765s
[2K
| Adam | epoch: 020 | loss: 0.10957 - acc: 0.9729 -- iter: 1024/1392
[A[ATraining Step: 869  | total loss: [1m[32m0.10614[0m[0m | time: 19.354s
[2K
| Adam | epoch: 020 | loss: 0.10614 - acc: 0.9694 -- iter: 1056/1392
[A[ATraining Step: 870  | total loss: [1m[32m0.09637[0m[0m | time: 19.957s
[2K
| Adam | epoch: 020 | loss: 0.09637 - acc: 0.9725 -- iter: 1088/1392
[A[ATraining Step: 871  | total loss: [1m[32m0.08757[0m[0m | time: 20.566s
[2K
| Adam | epoch: 020 | loss: 0.08757 - acc: 0.9752 -- iter: 1120/1392
[A[ATraining Step: 872  | total loss: [1m[32m0.07989[0m[0m | time: 21.168s
[2K
| Adam | epoch: 020 | loss: 0.07989 - acc: 0.9777 -- iter: 1152/1392
[A[ATraining Step: 873  | total loss: [1m[32m0.07421[0m[0m | time: 21.752s
[2K
| Adam | epoch: 020 | loss: 0.07421 - acc: 0.9799 -- iter: 1184/1392
[A[ATraining Step: 874  | total loss: [1m[32m0.06844[0m[0m | time: 22.344s
[2K
| Adam | epoch: 020 | loss: 0.06844 - acc: 0.9819 -- iter: 1216/1392
[A[ATraining Step: 875  | total loss: [1m[32m0.06799[0m[0m | time: 22.934s
[2K
| Adam | epoch: 020 | loss: 0.06799 - acc: 0.9806 -- iter: 1248/1392
[A[ATraining Step: 876  | total loss: [1m[32m0.07217[0m[0m | time: 23.523s
[2K
| Adam | epoch: 020 | loss: 0.07217 - acc: 0.9794 -- iter: 1280/1392
[A[ATraining Step: 877  | total loss: [1m[32m0.06906[0m[0m | time: 24.113s
[2K
| Adam | epoch: 020 | loss: 0.06906 - acc: 0.9815 -- iter: 1312/1392
[A[ATraining Step: 878  | total loss: [1m[32m0.06452[0m[0m | time: 24.681s
[2K
| Adam | epoch: 020 | loss: 0.06452 - acc: 0.9833 -- iter: 1344/1392
[A[ATraining Step: 879  | total loss: [1m[32m0.06146[0m[0m | time: 25.283s
[2K
| Adam | epoch: 020 | loss: 0.06146 - acc: 0.9819 -- iter: 1376/1392
[A[ATraining Step: 880  | total loss: [1m[32m0.05741[0m[0m | time: 27.240s
[2K
| Adam | epoch: 020 | loss: 0.05741 - acc: 0.9837 | val_loss: 0.95170 - val_acc: 0.7333 -- iter: 1392/1392
--
Training Step: 881  | total loss: [1m[32m0.05378[0m[0m | time: 0.588s
[2K
| Adam | epoch: 021 | loss: 0.05378 - acc: 0.9853 -- iter: 0032/1392
[A[ATraining Step: 882  | total loss: [1m[32m0.06083[0m[0m | time: 1.205s
[2K
| Adam | epoch: 021 | loss: 0.06083 - acc: 0.9805 -- iter: 0064/1392
[A[ATraining Step: 883  | total loss: [1m[32m0.05630[0m[0m | time: 1.807s
[2K
| Adam | epoch: 021 | loss: 0.05630 - acc: 0.9825 -- iter: 0096/1392
[A[ATraining Step: 884  | total loss: [1m[32m0.05191[0m[0m | time: 2.406s
[2K
| Adam | epoch: 021 | loss: 0.05191 - acc: 0.9842 -- iter: 0128/1392
[A[ATraining Step: 885  | total loss: [1m[32m0.04944[0m[0m | time: 3.000s
[2K
| Adam | epoch: 021 | loss: 0.04944 - acc: 0.9858 -- iter: 0160/1392
[A[ATraining Step: 886  | total loss: [1m[32m0.05986[0m[0m | time: 3.613s
[2K
| Adam | epoch: 021 | loss: 0.05986 - acc: 0.9810 -- iter: 0192/1392
[A[ATraining Step: 887  | total loss: [1m[32m0.05961[0m[0m | time: 4.209s
[2K
| Adam | epoch: 021 | loss: 0.05961 - acc: 0.9798 -- iter: 0224/1392
[A[ATraining Step: 888  | total loss: [1m[32m0.05556[0m[0m | time: 4.777s
[2K
| Adam | epoch: 021 | loss: 0.05556 - acc: 0.9818 -- iter: 0256/1392
[A[ATraining Step: 889  | total loss: [1m[32m0.05067[0m[0m | time: 5.373s
[2K
| Adam | epoch: 021 | loss: 0.05067 - acc: 0.9836 -- iter: 0288/1392
[A[ATraining Step: 890  | total loss: [1m[32m0.04627[0m[0m | time: 5.967s
[2K
| Adam | epoch: 021 | loss: 0.04627 - acc: 0.9852 -- iter: 0320/1392
[A[ATraining Step: 891  | total loss: [1m[32m0.04226[0m[0m | time: 6.567s
[2K
| Adam | epoch: 021 | loss: 0.04226 - acc: 0.9867 -- iter: 0352/1392
[A[ATraining Step: 892  | total loss: [1m[32m0.04136[0m[0m | time: 7.140s
[2K
| Adam | epoch: 021 | loss: 0.04136 - acc: 0.9880 -- iter: 0384/1392
[A[ATraining Step: 893  | total loss: [1m[32m0.04293[0m[0m | time: 7.735s
[2K
| Adam | epoch: 021 | loss: 0.04293 - acc: 0.9861 -- iter: 0416/1392
[A[ATraining Step: 894  | total loss: [1m[32m0.03999[0m[0m | time: 8.368s
[2K
| Adam | epoch: 021 | loss: 0.03999 - acc: 0.9875 -- iter: 0448/1392
[A[ATraining Step: 895  | total loss: [1m[32m0.03771[0m[0m | time: 8.983s
[2K
| Adam | epoch: 021 | loss: 0.03771 - acc: 0.9888 -- iter: 0480/1392
[A[ATraining Step: 896  | total loss: [1m[32m0.05078[0m[0m | time: 9.590s
[2K
| Adam | epoch: 021 | loss: 0.05078 - acc: 0.9868 -- iter: 0512/1392
[A[ATraining Step: 897  | total loss: [1m[32m0.04822[0m[0m | time: 10.182s
[2K
| Adam | epoch: 021 | loss: 0.04822 - acc: 0.9881 -- iter: 0544/1392
[A[ATraining Step: 898  | total loss: [1m[32m0.04622[0m[0m | time: 10.780s
[2K
| Adam | epoch: 021 | loss: 0.04622 - acc: 0.9893 -- iter: 0576/1392
[A[ATraining Step: 899  | total loss: [1m[32m0.04248[0m[0m | time: 11.090s
[2K
| Adam | epoch: 021 | loss: 0.04248 - acc: 0.9903 -- iter: 0608/1392
[A[ATraining Step: 900  | total loss: [1m[32m0.04046[0m[0m | time: 11.400s
[2K
| Adam | epoch: 021 | loss: 0.04046 - acc: 0.9913 -- iter: 0640/1392
[A[ATraining Step: 901  | total loss: [1m[32m0.03727[0m[0m | time: 12.016s
[2K
| Adam | epoch: 021 | loss: 0.03727 - acc: 0.9922 -- iter: 0672/1392
[A[ATraining Step: 902  | total loss: [1m[32m0.03410[0m[0m | time: 12.663s
[2K
| Adam | epoch: 021 | loss: 0.03410 - acc: 0.9930 -- iter: 0704/1392
[A[ATraining Step: 903  | total loss: [1m[32m0.04260[0m[0m | time: 13.286s
[2K
| Adam | epoch: 021 | loss: 0.04260 - acc: 0.9905 -- iter: 0736/1392
[A[ATraining Step: 904  | total loss: [1m[32m0.04479[0m[0m | time: 13.886s
[2K
| Adam | epoch: 021 | loss: 0.04479 - acc: 0.9884 -- iter: 0768/1392
[A[ATraining Step: 905  | total loss: [1m[32m0.04189[0m[0m | time: 14.477s
[2K
| Adam | epoch: 021 | loss: 0.04189 - acc: 0.9895 -- iter: 0800/1392
[A[ATraining Step: 906  | total loss: [1m[32m0.04152[0m[0m | time: 15.085s
[2K
| Adam | epoch: 021 | loss: 0.04152 - acc: 0.9906 -- iter: 0832/1392
[A[ATraining Step: 907  | total loss: [1m[32m0.04376[0m[0m | time: 15.681s
[2K
| Adam | epoch: 021 | loss: 0.04376 - acc: 0.9884 -- iter: 0864/1392
[A[ATraining Step: 908  | total loss: [1m[32m0.05074[0m[0m | time: 16.278s
[2K
| Adam | epoch: 021 | loss: 0.05074 - acc: 0.9864 -- iter: 0896/1392
[A[ATraining Step: 909  | total loss: [1m[32m0.05036[0m[0m | time: 16.881s
[2K
| Adam | epoch: 021 | loss: 0.05036 - acc: 0.9847 -- iter: 0928/1392
[A[ATraining Step: 910  | total loss: [1m[32m0.04654[0m[0m | time: 17.509s
[2K
| Adam | epoch: 021 | loss: 0.04654 - acc: 0.9862 -- iter: 0960/1392
[A[ATraining Step: 911  | total loss: [1m[32m0.04577[0m[0m | time: 18.120s
[2K
| Adam | epoch: 021 | loss: 0.04577 - acc: 0.9844 -- iter: 0992/1392
[A[ATraining Step: 912  | total loss: [1m[32m0.07166[0m[0m | time: 18.759s
[2K
| Adam | epoch: 021 | loss: 0.07166 - acc: 0.9766 -- iter: 1024/1392
[A[ATraining Step: 913  | total loss: [1m[32m0.06516[0m[0m | time: 19.372s
[2K
| Adam | epoch: 021 | loss: 0.06516 - acc: 0.9790 -- iter: 1056/1392
[A[ATraining Step: 914  | total loss: [1m[32m0.06254[0m[0m | time: 20.014s
[2K
| Adam | epoch: 021 | loss: 0.06254 - acc: 0.9779 -- iter: 1088/1392
[A[ATraining Step: 915  | total loss: [1m[32m0.05743[0m[0m | time: 20.620s
[2K
| Adam | epoch: 021 | loss: 0.05743 - acc: 0.9801 -- iter: 1120/1392
[A[ATraining Step: 916  | total loss: [1m[32m0.05218[0m[0m | time: 21.231s
[2K
| Adam | epoch: 021 | loss: 0.05218 - acc: 0.9821 -- iter: 1152/1392
[A[ATraining Step: 917  | total loss: [1m[32m0.06446[0m[0m | time: 21.846s
[2K
| Adam | epoch: 021 | loss: 0.06446 - acc: 0.9777 -- iter: 1184/1392
[A[ATraining Step: 918  | total loss: [1m[32m0.05875[0m[0m | time: 22.448s
[2K
| Adam | epoch: 021 | loss: 0.05875 - acc: 0.9799 -- iter: 1216/1392
[A[ATraining Step: 919  | total loss: [1m[32m0.05454[0m[0m | time: 23.063s
[2K
| Adam | epoch: 021 | loss: 0.05454 - acc: 0.9819 -- iter: 1248/1392
[A[ATraining Step: 920  | total loss: [1m[32m0.05106[0m[0m | time: 23.679s
[2K
| Adam | epoch: 021 | loss: 0.05106 - acc: 0.9837 -- iter: 1280/1392
[A[ATraining Step: 921  | total loss: [1m[32m0.08091[0m[0m | time: 24.276s
[2K
| Adam | epoch: 021 | loss: 0.08091 - acc: 0.9760 -- iter: 1312/1392
[A[ATraining Step: 922  | total loss: [1m[32m0.07420[0m[0m | time: 24.870s
[2K
| Adam | epoch: 021 | loss: 0.07420 - acc: 0.9784 -- iter: 1344/1392
[A[ATraining Step: 923  | total loss: [1m[32m0.06950[0m[0m | time: 25.446s
[2K
| Adam | epoch: 021 | loss: 0.06950 - acc: 0.9805 -- iter: 1376/1392
[A[ATraining Step: 924  | total loss: [1m[32m0.07194[0m[0m | time: 27.382s
[2K
| Adam | epoch: 021 | loss: 0.07194 - acc: 0.9794 | val_loss: 0.98933 - val_acc: 0.7517 -- iter: 1392/1392
--
Training Step: 925  | total loss: [1m[32m0.07205[0m[0m | time: 0.598s
[2K
| Adam | epoch: 022 | loss: 0.07205 - acc: 0.9783 -- iter: 0032/1392
[A[ATraining Step: 926  | total loss: [1m[32m0.06555[0m[0m | time: 1.209s
[2K
| Adam | epoch: 022 | loss: 0.06555 - acc: 0.9805 -- iter: 0064/1392
[A[ATraining Step: 927  | total loss: [1m[32m0.06843[0m[0m | time: 1.804s
[2K
| Adam | epoch: 022 | loss: 0.06843 - acc: 0.9793 -- iter: 0096/1392
[A[ATraining Step: 928  | total loss: [1m[32m0.06462[0m[0m | time: 2.397s
[2K
| Adam | epoch: 022 | loss: 0.06462 - acc: 0.9814 -- iter: 0128/1392
[A[ATraining Step: 929  | total loss: [1m[32m0.05903[0m[0m | time: 2.996s
[2K
| Adam | epoch: 022 | loss: 0.05903 - acc: 0.9832 -- iter: 0160/1392
[A[ATraining Step: 930  | total loss: [1m[32m0.05860[0m[0m | time: 3.605s
[2K
| Adam | epoch: 022 | loss: 0.05860 - acc: 0.9818 -- iter: 0192/1392
[A[ATraining Step: 931  | total loss: [1m[32m0.05366[0m[0m | time: 4.200s
[2K
| Adam | epoch: 022 | loss: 0.05366 - acc: 0.9836 -- iter: 0224/1392
[A[ATraining Step: 932  | total loss: [1m[32m0.05301[0m[0m | time: 4.806s
[2K
| Adam | epoch: 022 | loss: 0.05301 - acc: 0.9821 -- iter: 0256/1392
[A[ATraining Step: 933  | total loss: [1m[32m0.04862[0m[0m | time: 5.399s
[2K
| Adam | epoch: 022 | loss: 0.04862 - acc: 0.9839 -- iter: 0288/1392
[A[ATraining Step: 934  | total loss: [1m[32m0.04851[0m[0m | time: 6.012s
[2K
| Adam | epoch: 022 | loss: 0.04851 - acc: 0.9824 -- iter: 0320/1392
[A[ATraining Step: 935  | total loss: [1m[32m0.04431[0m[0m | time: 6.619s
[2K
| Adam | epoch: 022 | loss: 0.04431 - acc: 0.9842 -- iter: 0352/1392
[A[ATraining Step: 936  | total loss: [1m[32m0.06212[0m[0m | time: 7.217s
[2K
| Adam | epoch: 022 | loss: 0.06212 - acc: 0.9795 -- iter: 0384/1392
[A[ATraining Step: 937  | total loss: [1m[32m0.06793[0m[0m | time: 7.818s
[2K
| Adam | epoch: 022 | loss: 0.06793 - acc: 0.9753 -- iter: 0416/1392
[A[ATraining Step: 938  | total loss: [1m[32m0.06201[0m[0m | time: 8.432s
[2K
| Adam | epoch: 022 | loss: 0.06201 - acc: 0.9778 -- iter: 0448/1392
[A[ATraining Step: 939  | total loss: [1m[32m0.05651[0m[0m | time: 9.031s
[2K
| Adam | epoch: 022 | loss: 0.05651 - acc: 0.9800 -- iter: 0480/1392
[A[ATraining Step: 940  | total loss: [1m[32m0.05369[0m[0m | time: 9.634s
[2K
| Adam | epoch: 022 | loss: 0.05369 - acc: 0.9820 -- iter: 0512/1392
[A[ATraining Step: 941  | total loss: [1m[32m0.04996[0m[0m | time: 10.259s
[2K
| Adam | epoch: 022 | loss: 0.04996 - acc: 0.9838 -- iter: 0544/1392
[A[ATraining Step: 942  | total loss: [1m[32m0.04908[0m[0m | time: 10.861s
[2K
| Adam | epoch: 022 | loss: 0.04908 - acc: 0.9854 -- iter: 0576/1392
[A[ATraining Step: 943  | total loss: [1m[32m0.04640[0m[0m | time: 11.453s
[2K
| Adam | epoch: 022 | loss: 0.04640 - acc: 0.9869 -- iter: 0608/1392
[A[ATraining Step: 944  | total loss: [1m[32m0.04433[0m[0m | time: 11.766s
[2K
| Adam | epoch: 022 | loss: 0.04433 - acc: 0.9882 -- iter: 0640/1392
[A[ATraining Step: 945  | total loss: [1m[32m0.05257[0m[0m | time: 12.094s
[2K
| Adam | epoch: 022 | loss: 0.05257 - acc: 0.9831 -- iter: 0672/1392
[A[ATraining Step: 946  | total loss: [1m[32m0.04917[0m[0m | time: 12.698s
[2K
| Adam | epoch: 022 | loss: 0.04917 - acc: 0.9848 -- iter: 0704/1392
[A[ATraining Step: 947  | total loss: [1m[32m0.05562[0m[0m | time: 13.289s
[2K
| Adam | epoch: 022 | loss: 0.05562 - acc: 0.9832 -- iter: 0736/1392
[A[ATraining Step: 948  | total loss: [1m[32m0.05053[0m[0m | time: 13.913s
[2K
| Adam | epoch: 022 | loss: 0.05053 - acc: 0.9849 -- iter: 0768/1392
[A[ATraining Step: 949  | total loss: [1m[32m0.04656[0m[0m | time: 14.504s
[2K
| Adam | epoch: 022 | loss: 0.04656 - acc: 0.9864 -- iter: 0800/1392
[A[ATraining Step: 950  | total loss: [1m[32m0.04893[0m[0m | time: 15.106s
[2K
| Adam | epoch: 022 | loss: 0.04893 - acc: 0.9846 -- iter: 0832/1392
[A[ATraining Step: 951  | total loss: [1m[32m0.05631[0m[0m | time: 15.712s
[2K
| Adam | epoch: 022 | loss: 0.05631 - acc: 0.9799 -- iter: 0864/1392
[A[ATraining Step: 952  | total loss: [1m[32m0.05145[0m[0m | time: 16.311s
[2K
| Adam | epoch: 022 | loss: 0.05145 - acc: 0.9819 -- iter: 0896/1392
[A[ATraining Step: 953  | total loss: [1m[32m0.05949[0m[0m | time: 16.917s
[2K
| Adam | epoch: 022 | loss: 0.05949 - acc: 0.9806 -- iter: 0928/1392
[A[ATraining Step: 954  | total loss: [1m[32m0.05699[0m[0m | time: 17.517s
[2K
| Adam | epoch: 022 | loss: 0.05699 - acc: 0.9825 -- iter: 0960/1392
[A[ATraining Step: 955  | total loss: [1m[32m0.06231[0m[0m | time: 18.126s
[2K
| Adam | epoch: 022 | loss: 0.06231 - acc: 0.9780 -- iter: 0992/1392
[A[ATraining Step: 956  | total loss: [1m[32m0.07525[0m[0m | time: 18.716s
[2K
| Adam | epoch: 022 | loss: 0.07525 - acc: 0.9740 -- iter: 1024/1392
[A[ATraining Step: 957  | total loss: [1m[32m0.06983[0m[0m | time: 19.303s
[2K
| Adam | epoch: 022 | loss: 0.06983 - acc: 0.9766 -- iter: 1056/1392
[A[ATraining Step: 958  | total loss: [1m[32m0.06407[0m[0m | time: 19.928s
[2K
| Adam | epoch: 022 | loss: 0.06407 - acc: 0.9789 -- iter: 1088/1392
[A[ATraining Step: 959  | total loss: [1m[32m0.05817[0m[0m | time: 20.532s
[2K
| Adam | epoch: 022 | loss: 0.05817 - acc: 0.9810 -- iter: 1120/1392
[A[ATraining Step: 960  | total loss: [1m[32m0.05374[0m[0m | time: 21.139s
[2K
| Adam | epoch: 022 | loss: 0.05374 - acc: 0.9829 -- iter: 1152/1392
[A[ATraining Step: 961  | total loss: [1m[32m0.04908[0m[0m | time: 21.739s
[2K
| Adam | epoch: 022 | loss: 0.04908 - acc: 0.9846 -- iter: 1184/1392
[A[ATraining Step: 962  | total loss: [1m[32m0.04483[0m[0m | time: 22.331s
[2K
| Adam | epoch: 022 | loss: 0.04483 - acc: 0.9862 -- iter: 1216/1392
[A[ATraining Step: 963  | total loss: [1m[32m0.04436[0m[0m | time: 22.932s
[2K
| Adam | epoch: 022 | loss: 0.04436 - acc: 0.9876 -- iter: 1248/1392
[A[ATraining Step: 964  | total loss: [1m[32m0.04082[0m[0m | time: 23.542s
[2K
| Adam | epoch: 022 | loss: 0.04082 - acc: 0.9888 -- iter: 1280/1392
[A[ATraining Step: 965  | total loss: [1m[32m0.03739[0m[0m | time: 24.136s
[2K
| Adam | epoch: 022 | loss: 0.03739 - acc: 0.9899 -- iter: 1312/1392
[A[ATraining Step: 966  | total loss: [1m[32m0.03433[0m[0m | time: 24.745s
[2K
| Adam | epoch: 022 | loss: 0.03433 - acc: 0.9909 -- iter: 1344/1392
[A[ATraining Step: 967  | total loss: [1m[32m0.03136[0m[0m | time: 25.340s
[2K
| Adam | epoch: 022 | loss: 0.03136 - acc: 0.9918 -- iter: 1376/1392
[A[ATraining Step: 968  | total loss: [1m[32m0.03111[0m[0m | time: 27.310s
[2K
| Adam | epoch: 022 | loss: 0.03111 - acc: 0.9927 | val_loss: 1.18305 - val_acc: 0.7632 -- iter: 1392/1392
--
Training Step: 969  | total loss: [1m[32m0.05247[0m[0m | time: 0.605s
[2K
| Adam | epoch: 023 | loss: 0.05247 - acc: 0.9903 -- iter: 0032/1392
[A[ATraining Step: 970  | total loss: [1m[32m0.04856[0m[0m | time: 1.218s
[2K
| Adam | epoch: 023 | loss: 0.04856 - acc: 0.9912 -- iter: 0064/1392
[A[ATraining Step: 971  | total loss: [1m[32m0.04412[0m[0m | time: 1.825s
[2K
| Adam | epoch: 023 | loss: 0.04412 - acc: 0.9921 -- iter: 0096/1392
[A[ATraining Step: 972  | total loss: [1m[32m0.04001[0m[0m | time: 2.438s
[2K
| Adam | epoch: 023 | loss: 0.04001 - acc: 0.9929 -- iter: 0128/1392
[A[ATraining Step: 973  | total loss: [1m[32m0.03622[0m[0m | time: 3.063s
[2K
| Adam | epoch: 023 | loss: 0.03622 - acc: 0.9936 -- iter: 0160/1392
[A[ATraining Step: 974  | total loss: [1m[32m0.03415[0m[0m | time: 3.666s
[2K
| Adam | epoch: 023 | loss: 0.03415 - acc: 0.9943 -- iter: 0192/1392
[A[ATraining Step: 975  | total loss: [1m[32m0.04140[0m[0m | time: 4.274s
[2K
| Adam | epoch: 023 | loss: 0.04140 - acc: 0.9917 -- iter: 0224/1392
[A[ATraining Step: 976  | total loss: [1m[32m0.03754[0m[0m | time: 4.871s
[2K
| Adam | epoch: 023 | loss: 0.03754 - acc: 0.9925 -- iter: 0256/1392
[A[ATraining Step: 977  | total loss: [1m[32m0.04506[0m[0m | time: 5.472s
[2K
| Adam | epoch: 023 | loss: 0.04506 - acc: 0.9902 -- iter: 0288/1392
[A[ATraining Step: 978  | total loss: [1m[32m0.04199[0m[0m | time: 6.074s
[2K
| Adam | epoch: 023 | loss: 0.04199 - acc: 0.9911 -- iter: 0320/1392
[A[ATraining Step: 979  | total loss: [1m[32m0.04975[0m[0m | time: 6.684s
[2K
| Adam | epoch: 023 | loss: 0.04975 - acc: 0.9889 -- iter: 0352/1392
[A[ATraining Step: 980  | total loss: [1m[32m0.04621[0m[0m | time: 7.265s
[2K
| Adam | epoch: 023 | loss: 0.04621 - acc: 0.9900 -- iter: 0384/1392
[A[ATraining Step: 981  | total loss: [1m[32m0.04729[0m[0m | time: 7.880s
[2K
| Adam | epoch: 023 | loss: 0.04729 - acc: 0.9879 -- iter: 0416/1392
[A[ATraining Step: 982  | total loss: [1m[32m0.04319[0m[0m | time: 8.486s
[2K
| Adam | epoch: 023 | loss: 0.04319 - acc: 0.9891 -- iter: 0448/1392
[A[ATraining Step: 983  | total loss: [1m[32m0.03927[0m[0m | time: 9.078s
[2K
| Adam | epoch: 023 | loss: 0.03927 - acc: 0.9902 -- iter: 0480/1392
[A[ATraining Step: 984  | total loss: [1m[32m0.03792[0m[0m | time: 9.678s
[2K
| Adam | epoch: 023 | loss: 0.03792 - acc: 0.9912 -- iter: 0512/1392
[A[ATraining Step: 985  | total loss: [1m[32m0.03512[0m[0m | time: 10.282s
[2K
| Adam | epoch: 023 | loss: 0.03512 - acc: 0.9920 -- iter: 0544/1392
[A[ATraining Step: 986  | total loss: [1m[32m0.03198[0m[0m | time: 10.878s
[2K
| Adam | epoch: 023 | loss: 0.03198 - acc: 0.9928 -- iter: 0576/1392
[A[ATraining Step: 987  | total loss: [1m[32m0.03872[0m[0m | time: 11.471s
[2K
| Adam | epoch: 023 | loss: 0.03872 - acc: 0.9904 -- iter: 0608/1392
[A[ATraining Step: 988  | total loss: [1m[32m0.04753[0m[0m | time: 12.053s
[2K
| Adam | epoch: 023 | loss: 0.04753 - acc: 0.9883 -- iter: 0640/1392
[A[ATraining Step: 989  | total loss: [1m[32m0.04479[0m[0m | time: 12.379s
[2K
| Adam | epoch: 023 | loss: 0.04479 - acc: 0.9894 -- iter: 0672/1392
[A[ATraining Step: 990  | total loss: [1m[32m0.04072[0m[0m | time: 12.694s
[2K
| Adam | epoch: 023 | loss: 0.04072 - acc: 0.9905 -- iter: 0704/1392
[A[ATraining Step: 991  | total loss: [1m[32m0.03709[0m[0m | time: 13.279s
[2K
| Adam | epoch: 023 | loss: 0.03709 - acc: 0.9914 -- iter: 0736/1392
[A[ATraining Step: 992  | total loss: [1m[32m0.03408[0m[0m | time: 13.871s
[2K
| Adam | epoch: 023 | loss: 0.03408 - acc: 0.9923 -- iter: 0768/1392
[A[ATraining Step: 993  | total loss: [1m[32m0.04188[0m[0m | time: 14.478s
[2K
| Adam | epoch: 023 | loss: 0.04188 - acc: 0.9899 -- iter: 0800/1392
[A[ATraining Step: 994  | total loss: [1m[32m0.04793[0m[0m | time: 15.074s
[2K
| Adam | epoch: 023 | loss: 0.04793 - acc: 0.9878 -- iter: 0832/1392
[A[ATraining Step: 995  | total loss: [1m[32m0.04432[0m[0m | time: 15.673s
[2K
| Adam | epoch: 023 | loss: 0.04432 - acc: 0.9890 -- iter: 0864/1392
[A[ATraining Step: 996  | total loss: [1m[32m0.04078[0m[0m | time: 16.271s
[2K
| Adam | epoch: 023 | loss: 0.04078 - acc: 0.9901 -- iter: 0896/1392
[A[ATraining Step: 997  | total loss: [1m[32m0.03904[0m[0m | time: 16.876s
[2K
| Adam | epoch: 023 | loss: 0.03904 - acc: 0.9911 -- iter: 0928/1392
[A[ATraining Step: 998  | total loss: [1m[32m0.03639[0m[0m | time: 17.474s
[2K
| Adam | epoch: 023 | loss: 0.03639 - acc: 0.9920 -- iter: 0960/1392
[A[ATraining Step: 999  | total loss: [1m[32m0.04747[0m[0m | time: 18.078s
[2K
| Adam | epoch: 023 | loss: 0.04747 - acc: 0.9897 -- iter: 0992/1392
[A[ATraining Step: 1000  | total loss: [1m[32m0.04421[0m[0m | time: 20.029s
[2K
| Adam | epoch: 023 | loss: 0.04421 - acc: 0.9907 | val_loss: 1.11532 - val_acc: 0.7356 -- iter: 1024/1392
--
Training Step: 1001  | total loss: [1m[32m0.04060[0m[0m | time: 20.624s
[2K
| Adam | epoch: 023 | loss: 0.04060 - acc: 0.9916 -- iter: 1056/1392
[A[ATraining Step: 1002  | total loss: [1m[32m0.04047[0m[0m | time: 21.245s
[2K
| Adam | epoch: 023 | loss: 0.04047 - acc: 0.9894 -- iter: 1088/1392
[A[ATraining Step: 1003  | total loss: [1m[32m0.04785[0m[0m | time: 21.843s
[2K
| Adam | epoch: 023 | loss: 0.04785 - acc: 0.9873 -- iter: 1120/1392
[A[ATraining Step: 1004  | total loss: [1m[32m0.04555[0m[0m | time: 22.448s
[2K
| Adam | epoch: 023 | loss: 0.04555 - acc: 0.9886 -- iter: 1152/1392
[A[ATraining Step: 1005  | total loss: [1m[32m0.04176[0m[0m | time: 23.045s
[2K
| Adam | epoch: 023 | loss: 0.04176 - acc: 0.9897 -- iter: 1184/1392
[A[ATraining Step: 1006  | total loss: [1m[32m0.05121[0m[0m | time: 23.660s
[2K
| Adam | epoch: 023 | loss: 0.05121 - acc: 0.9876 -- iter: 1216/1392
[A[ATraining Step: 1007  | total loss: [1m[32m0.05124[0m[0m | time: 24.262s
[2K
| Adam | epoch: 023 | loss: 0.05124 - acc: 0.9857 -- iter: 1248/1392
[A[ATraining Step: 1008  | total loss: [1m[32m0.04656[0m[0m | time: 24.868s
[2K
| Adam | epoch: 023 | loss: 0.04656 - acc: 0.9872 -- iter: 1280/1392
[A[ATraining Step: 1009  | total loss: [1m[32m0.05152[0m[0m | time: 25.459s
[2K
| Adam | epoch: 023 | loss: 0.05152 - acc: 0.9853 -- iter: 1312/1392
[A[ATraining Step: 1010  | total loss: [1m[32m0.04811[0m[0m | time: 26.055s
[2K
| Adam | epoch: 023 | loss: 0.04811 - acc: 0.9868 -- iter: 1344/1392
[A[ATraining Step: 1011  | total loss: [1m[32m0.04436[0m[0m | time: 26.653s
[2K
| Adam | epoch: 023 | loss: 0.04436 - acc: 0.9881 -- iter: 1376/1392
[A[ATraining Step: 1012  | total loss: [1m[32m0.04065[0m[0m | time: 28.611s
[2K
| Adam | epoch: 023 | loss: 0.04065 - acc: 0.9893 | val_loss: 1.16220 - val_acc: 0.7333 -- iter: 1392/1392
--
Training Step: 1013  | total loss: [1m[32m0.03885[0m[0m | time: 0.602s
[2K
| Adam | epoch: 024 | loss: 0.03885 - acc: 0.9904 -- iter: 0032/1392
[A[ATraining Step: 1014  | total loss: [1m[32m0.03555[0m[0m | time: 1.198s
[2K
| Adam | epoch: 024 | loss: 0.03555 - acc: 0.9913 -- iter: 0064/1392
[A[ATraining Step: 1015  | total loss: [1m[32m0.04472[0m[0m | time: 1.793s
[2K
| Adam | epoch: 024 | loss: 0.04472 - acc: 0.9891 -- iter: 0096/1392
[A[ATraining Step: 1016  | total loss: [1m[32m0.04127[0m[0m | time: 2.385s
[2K
| Adam | epoch: 024 | loss: 0.04127 - acc: 0.9902 -- iter: 0128/1392
[A[ATraining Step: 1017  | total loss: [1m[32m0.03830[0m[0m | time: 2.992s
[2K
| Adam | epoch: 024 | loss: 0.03830 - acc: 0.9911 -- iter: 0160/1392
[A[ATraining Step: 1018  | total loss: [1m[32m0.03530[0m[0m | time: 3.603s
[2K
| Adam | epoch: 024 | loss: 0.03530 - acc: 0.9920 -- iter: 0192/1392
[A[ATraining Step: 1019  | total loss: [1m[32m0.03285[0m[0m | time: 4.197s
[2K
| Adam | epoch: 024 | loss: 0.03285 - acc: 0.9928 -- iter: 0224/1392
[A[ATraining Step: 1020  | total loss: [1m[32m0.03165[0m[0m | time: 4.801s
[2K
| Adam | epoch: 024 | loss: 0.03165 - acc: 0.9935 -- iter: 0256/1392
[A[ATraining Step: 1021  | total loss: [1m[32m0.03397[0m[0m | time: 5.406s
[2K
| Adam | epoch: 024 | loss: 0.03397 - acc: 0.9911 -- iter: 0288/1392
[A[ATraining Step: 1022  | total loss: [1m[32m0.04104[0m[0m | time: 6.012s
[2K
| Adam | epoch: 024 | loss: 0.04104 - acc: 0.9888 -- iter: 0320/1392
[A[ATraining Step: 1023  | total loss: [1m[32m0.03757[0m[0m | time: 6.613s
[2K
| Adam | epoch: 024 | loss: 0.03757 - acc: 0.9900 -- iter: 0352/1392
[A[ATraining Step: 1024  | total loss: [1m[32m0.03594[0m[0m | time: 7.226s
[2K
| Adam | epoch: 024 | loss: 0.03594 - acc: 0.9910 -- iter: 0384/1392
[A[ATraining Step: 1025  | total loss: [1m[32m0.04155[0m[0m | time: 7.815s
[2K
| Adam | epoch: 024 | loss: 0.04155 - acc: 0.9887 -- iter: 0416/1392
[A[ATraining Step: 1026  | total loss: [1m[32m0.03867[0m[0m | time: 8.405s
[2K
| Adam | epoch: 024 | loss: 0.03867 - acc: 0.9899 -- iter: 0448/1392
[A[ATraining Step: 1027  | total loss: [1m[32m0.03655[0m[0m | time: 9.009s
[2K
| Adam | epoch: 024 | loss: 0.03655 - acc: 0.9909 -- iter: 0480/1392
[A[ATraining Step: 1028  | total loss: [1m[32m0.03858[0m[0m | time: 9.614s
[2K
| Adam | epoch: 024 | loss: 0.03858 - acc: 0.9887 -- iter: 0512/1392
[A[ATraining Step: 1029  | total loss: [1m[32m0.03508[0m[0m | time: 10.213s
[2K
| Adam | epoch: 024 | loss: 0.03508 - acc: 0.9898 -- iter: 0544/1392
[A[ATraining Step: 1030  | total loss: [1m[32m0.03546[0m[0m | time: 10.819s
[2K
| Adam | epoch: 024 | loss: 0.03546 - acc: 0.9877 -- iter: 0576/1392
[A[ATraining Step: 1031  | total loss: [1m[32m0.03236[0m[0m | time: 11.421s
[2K
| Adam | epoch: 024 | loss: 0.03236 - acc: 0.9889 -- iter: 0608/1392
[A[ATraining Step: 1032  | total loss: [1m[32m0.02995[0m[0m | time: 12.024s
[2K
| Adam | epoch: 024 | loss: 0.02995 - acc: 0.9900 -- iter: 0640/1392
[A[ATraining Step: 1033  | total loss: [1m[32m0.04212[0m[0m | time: 12.648s
[2K
| Adam | epoch: 024 | loss: 0.04212 - acc: 0.9848 -- iter: 0672/1392
[A[ATraining Step: 1034  | total loss: [1m[32m0.03904[0m[0m | time: 12.965s
[2K
| Adam | epoch: 024 | loss: 0.03904 - acc: 0.9863 -- iter: 0704/1392
[A[ATraining Step: 1035  | total loss: [1m[32m0.03562[0m[0m | time: 13.303s
[2K
| Adam | epoch: 024 | loss: 0.03562 - acc: 0.9877 -- iter: 0736/1392
[A[ATraining Step: 1036  | total loss: [1m[32m0.03255[0m[0m | time: 13.955s
[2K
| Adam | epoch: 024 | loss: 0.03255 - acc: 0.9889 -- iter: 0768/1392
[A[ATraining Step: 1037  | total loss: [1m[32m0.03074[0m[0m | time: 14.561s
[2K
| Adam | epoch: 024 | loss: 0.03074 - acc: 0.9900 -- iter: 0800/1392
[A[ATraining Step: 1038  | total loss: [1m[32m0.02893[0m[0m | time: 15.157s
[2K
| Adam | epoch: 024 | loss: 0.02893 - acc: 0.9910 -- iter: 0832/1392
[A[ATraining Step: 1039  | total loss: [1m[32m0.02881[0m[0m | time: 15.765s
[2K
| Adam | epoch: 024 | loss: 0.02881 - acc: 0.9919 -- iter: 0864/1392
[A[ATraining Step: 1040  | total loss: [1m[32m0.03794[0m[0m | time: 16.377s
[2K
| Adam | epoch: 024 | loss: 0.03794 - acc: 0.9896 -- iter: 0896/1392
[A[ATraining Step: 1041  | total loss: [1m[32m0.03547[0m[0m | time: 16.988s
[2K
| Adam | epoch: 024 | loss: 0.03547 - acc: 0.9906 -- iter: 0928/1392
[A[ATraining Step: 1042  | total loss: [1m[32m0.03210[0m[0m | time: 17.605s
[2K
| Adam | epoch: 024 | loss: 0.03210 - acc: 0.9916 -- iter: 0960/1392
[A[ATraining Step: 1043  | total loss: [1m[32m0.03094[0m[0m | time: 18.232s
[2K
| Adam | epoch: 024 | loss: 0.03094 - acc: 0.9924 -- iter: 0992/1392
[A[ATraining Step: 1044  | total loss: [1m[32m0.04087[0m[0m | time: 18.846s
[2K
| Adam | epoch: 024 | loss: 0.04087 - acc: 0.9900 -- iter: 1024/1392
[A[ATraining Step: 1045  | total loss: [1m[32m0.03745[0m[0m | time: 19.454s
[2K
| Adam | epoch: 024 | loss: 0.03745 - acc: 0.9910 -- iter: 1056/1392
[A[ATraining Step: 1046  | total loss: [1m[32m0.04890[0m[0m | time: 20.062s
[2K
| Adam | epoch: 024 | loss: 0.04890 - acc: 0.9888 -- iter: 1088/1392
[A[ATraining Step: 1047  | total loss: [1m[32m0.04415[0m[0m | time: 20.674s
[2K
| Adam | epoch: 024 | loss: 0.04415 - acc: 0.9899 -- iter: 1120/1392
[A[ATraining Step: 1048  | total loss: [1m[32m0.05444[0m[0m | time: 21.288s
[2K
| Adam | epoch: 024 | loss: 0.05444 - acc: 0.9847 -- iter: 1152/1392
[A[ATraining Step: 1049  | total loss: [1m[32m0.05138[0m[0m | time: 21.891s
[2K
| Adam | epoch: 024 | loss: 0.05138 - acc: 0.9862 -- iter: 1184/1392
[A[ATraining Step: 1050  | total loss: [1m[32m0.06596[0m[0m | time: 22.491s
[2K
| Adam | epoch: 024 | loss: 0.06596 - acc: 0.9782 -- iter: 1216/1392
[A[ATraining Step: 1051  | total loss: [1m[32m0.06031[0m[0m | time: 23.088s
[2K
| Adam | epoch: 024 | loss: 0.06031 - acc: 0.9804 -- iter: 1248/1392
[A[ATraining Step: 1052  | total loss: [1m[32m0.05845[0m[0m | time: 23.676s
[2K
| Adam | epoch: 024 | loss: 0.05845 - acc: 0.9792 -- iter: 1280/1392
[A[ATraining Step: 1053  | total loss: [1m[32m0.05432[0m[0m | time: 24.273s
[2K
| Adam | epoch: 024 | loss: 0.05432 - acc: 0.9813 -- iter: 1312/1392
[A[ATraining Step: 1054  | total loss: [1m[32m0.07790[0m[0m | time: 24.870s
[2K
| Adam | epoch: 024 | loss: 0.07790 - acc: 0.9738 -- iter: 1344/1392
[A[ATraining Step: 1055  | total loss: [1m[32m0.07198[0m[0m | time: 25.472s
[2K
| Adam | epoch: 024 | loss: 0.07198 - acc: 0.9764 -- iter: 1376/1392
[A[ATraining Step: 1056  | total loss: [1m[32m0.06788[0m[0m | time: 27.428s
[2K
| Adam | epoch: 024 | loss: 0.06788 - acc: 0.9788 | val_loss: 1.26567 - val_acc: 0.7448 -- iter: 1392/1392
--
Training Step: 1057  | total loss: [1m[32m0.06772[0m[0m | time: 0.615s
[2K
| Adam | epoch: 025 | loss: 0.06772 - acc: 0.9747 -- iter: 0032/1392
[A[ATraining Step: 1058  | total loss: [1m[32m0.06243[0m[0m | time: 1.220s
[2K
| Adam | epoch: 025 | loss: 0.06243 - acc: 0.9772 -- iter: 0064/1392
[A[ATraining Step: 1059  | total loss: [1m[32m0.05682[0m[0m | time: 1.813s
[2K
| Adam | epoch: 025 | loss: 0.05682 - acc: 0.9795 -- iter: 0096/1392
[A[ATraining Step: 1060  | total loss: [1m[32m0.05190[0m[0m | time: 2.424s
[2K
| Adam | epoch: 025 | loss: 0.05190 - acc: 0.9815 -- iter: 0128/1392
[A[ATraining Step: 1061  | total loss: [1m[32m0.04707[0m[0m | time: 3.007s
[2K
| Adam | epoch: 025 | loss: 0.04707 - acc: 0.9834 -- iter: 0160/1392
[A[ATraining Step: 1062  | total loss: [1m[32m0.04474[0m[0m | time: 3.603s
[2K
| Adam | epoch: 025 | loss: 0.04474 - acc: 0.9850 -- iter: 0192/1392
[A[ATraining Step: 1063  | total loss: [1m[32m0.04191[0m[0m | time: 4.201s
[2K
| Adam | epoch: 025 | loss: 0.04191 - acc: 0.9865 -- iter: 0224/1392
[A[ATraining Step: 1064  | total loss: [1m[32m0.03887[0m[0m | time: 4.803s
[2K
| Adam | epoch: 025 | loss: 0.03887 - acc: 0.9879 -- iter: 0256/1392
[A[ATraining Step: 1065  | total loss: [1m[32m0.03602[0m[0m | time: 5.391s
[2K
| Adam | epoch: 025 | loss: 0.03602 - acc: 0.9891 -- iter: 0288/1392
[A[ATraining Step: 1066  | total loss: [1m[32m0.03308[0m[0m | time: 5.983s
[2K
| Adam | epoch: 025 | loss: 0.03308 - acc: 0.9902 -- iter: 0320/1392
[A[ATraining Step: 1067  | total loss: [1m[32m0.03034[0m[0m | time: 6.579s
[2K
| Adam | epoch: 025 | loss: 0.03034 - acc: 0.9912 -- iter: 0352/1392
[A[ATraining Step: 1068  | total loss: [1m[32m0.02770[0m[0m | time: 7.180s
[2K
| Adam | epoch: 025 | loss: 0.02770 - acc: 0.9920 -- iter: 0384/1392
[A[ATraining Step: 1069  | total loss: [1m[32m0.02542[0m[0m | time: 7.775s
[2K
| Adam | epoch: 025 | loss: 0.02542 - acc: 0.9928 -- iter: 0416/1392
[A[ATraining Step: 1070  | total loss: [1m[32m0.02330[0m[0m | time: 8.370s
[2K
| Adam | epoch: 025 | loss: 0.02330 - acc: 0.9936 -- iter: 0448/1392
[A[ATraining Step: 1071  | total loss: [1m[32m0.02114[0m[0m | time: 8.963s
[2K
| Adam | epoch: 025 | loss: 0.02114 - acc: 0.9942 -- iter: 0480/1392
[A[ATraining Step: 1072  | total loss: [1m[32m0.01951[0m[0m | time: 9.561s
[2K
| Adam | epoch: 025 | loss: 0.01951 - acc: 0.9948 -- iter: 0512/1392
[A[ATraining Step: 1073  | total loss: [1m[32m0.01862[0m[0m | time: 10.161s
[2K
| Adam | epoch: 025 | loss: 0.01862 - acc: 0.9953 -- iter: 0544/1392
[A[ATraining Step: 1074  | total loss: [1m[32m0.02652[0m[0m | time: 10.752s
[2K
| Adam | epoch: 025 | loss: 0.02652 - acc: 0.9926 -- iter: 0576/1392
[A[ATraining Step: 1075  | total loss: [1m[32m0.03413[0m[0m | time: 11.362s
[2K
| Adam | epoch: 025 | loss: 0.03413 - acc: 0.9903 -- iter: 0608/1392
[A[ATraining Step: 1076  | total loss: [1m[32m0.03125[0m[0m | time: 11.964s
[2K
| Adam | epoch: 025 | loss: 0.03125 - acc: 0.9912 -- iter: 0640/1392
[A[ATraining Step: 1077  | total loss: [1m[32m0.03174[0m[0m | time: 12.576s
[2K
| Adam | epoch: 025 | loss: 0.03174 - acc: 0.9890 -- iter: 0672/1392
[A[ATraining Step: 1078  | total loss: [1m[32m0.02893[0m[0m | time: 13.191s
[2K
| Adam | epoch: 025 | loss: 0.02893 - acc: 0.9901 -- iter: 0704/1392
[A[ATraining Step: 1079  | total loss: [1m[32m0.04030[0m[0m | time: 13.503s
[2K
| Adam | epoch: 025 | loss: 0.04030 - acc: 0.9880 -- iter: 0736/1392
[A[ATraining Step: 1080  | total loss: [1m[32m0.05163[0m[0m | time: 13.809s
[2K
| Adam | epoch: 025 | loss: 0.05163 - acc: 0.9829 -- iter: 0768/1392
[A[ATraining Step: 1081  | total loss: [1m[32m0.04829[0m[0m | time: 14.401s
[2K
| Adam | epoch: 025 | loss: 0.04829 - acc: 0.9846 -- iter: 0800/1392
[A[ATraining Step: 1082  | total loss: [1m[32m0.04374[0m[0m | time: 14.998s
[2K
| Adam | epoch: 025 | loss: 0.04374 - acc: 0.9862 -- iter: 0832/1392
[A[ATraining Step: 1083  | total loss: [1m[32m0.04368[0m[0m | time: 15.618s
[2K
| Adam | epoch: 025 | loss: 0.04368 - acc: 0.9844 -- iter: 0864/1392
[A[ATraining Step: 1084  | total loss: [1m[32m0.04128[0m[0m | time: 16.253s
[2K
| Adam | epoch: 025 | loss: 0.04128 - acc: 0.9860 -- iter: 0896/1392
[A[ATraining Step: 1085  | total loss: [1m[32m0.04183[0m[0m | time: 16.849s
[2K
| Adam | epoch: 025 | loss: 0.04183 - acc: 0.9843 -- iter: 0928/1392
[A[ATraining Step: 1086  | total loss: [1m[32m0.03793[0m[0m | time: 17.447s
[2K
| Adam | epoch: 025 | loss: 0.03793 - acc: 0.9858 -- iter: 0960/1392
[A[ATraining Step: 1087  | total loss: [1m[32m0.03555[0m[0m | time: 18.042s
[2K
| Adam | epoch: 025 | loss: 0.03555 - acc: 0.9872 -- iter: 0992/1392
[A[ATraining Step: 1088  | total loss: [1m[32m0.07051[0m[0m | time: 18.638s
[2K
| Adam | epoch: 025 | loss: 0.07051 - acc: 0.9823 -- iter: 1024/1392
[A[ATraining Step: 1089  | total loss: [1m[32m0.06388[0m[0m | time: 19.246s
[2K
| Adam | epoch: 025 | loss: 0.06388 - acc: 0.9840 -- iter: 1056/1392
[A[ATraining Step: 1090  | total loss: [1m[32m0.06014[0m[0m | time: 19.838s
[2K
| Adam | epoch: 025 | loss: 0.06014 - acc: 0.9856 -- iter: 1088/1392
[A[ATraining Step: 1091  | total loss: [1m[32m0.06247[0m[0m | time: 20.426s
[2K
| Adam | epoch: 025 | loss: 0.06247 - acc: 0.9839 -- iter: 1120/1392
[A[ATraining Step: 1092  | total loss: [1m[32m0.09602[0m[0m | time: 21.019s
[2K
| Adam | epoch: 025 | loss: 0.09602 - acc: 0.9762 -- iter: 1152/1392
[A[ATraining Step: 1093  | total loss: [1m[32m0.12099[0m[0m | time: 21.633s
[2K
| Adam | epoch: 025 | loss: 0.12099 - acc: 0.9723 -- iter: 1184/1392
[A[ATraining Step: 1094  | total loss: [1m[32m0.10919[0m[0m | time: 22.254s
[2K
| Adam | epoch: 025 | loss: 0.10919 - acc: 0.9751 -- iter: 1216/1392
[A[ATraining Step: 1095  | total loss: [1m[32m0.10286[0m[0m | time: 22.850s
[2K
| Adam | epoch: 025 | loss: 0.10286 - acc: 0.9744 -- iter: 1248/1392
[A[ATraining Step: 1096  | total loss: [1m[32m0.09309[0m[0m | time: 23.489s
[2K
| Adam | epoch: 025 | loss: 0.09309 - acc: 0.9770 -- iter: 1280/1392
[A[ATraining Step: 1097  | total loss: [1m[32m0.08479[0m[0m | time: 24.101s
[2K
| Adam | epoch: 025 | loss: 0.08479 - acc: 0.9793 -- iter: 1312/1392
[A[ATraining Step: 1098  | total loss: [1m[32m0.08569[0m[0m | time: 24.693s
[2K
| Adam | epoch: 025 | loss: 0.08569 - acc: 0.9782 -- iter: 1344/1392
[A[ATraining Step: 1099  | total loss: [1m[32m0.07906[0m[0m | time: 25.304s
[2K
| Adam | epoch: 025 | loss: 0.07906 - acc: 0.9804 -- iter: 1376/1392
[A[ATraining Step: 1100  | total loss: [1m[32m0.07189[0m[0m | time: 27.309s
[2K
| Adam | epoch: 025 | loss: 0.07189 - acc: 0.9824 | val_loss: 0.97983 - val_acc: 0.7471 -- iter: 1392/1392
--
Training Step: 1101  | total loss: [1m[32m0.07130[0m[0m | time: 0.618s
[2K
| Adam | epoch: 026 | loss: 0.07130 - acc: 0.9810 -- iter: 0032/1392
[A[ATraining Step: 1102  | total loss: [1m[32m0.06620[0m[0m | time: 1.217s
[2K
| Adam | epoch: 026 | loss: 0.06620 - acc: 0.9829 -- iter: 0064/1392
[A[ATraining Step: 1103  | total loss: [1m[32m0.06054[0m[0m | time: 1.824s
[2K
| Adam | epoch: 026 | loss: 0.06054 - acc: 0.9846 -- iter: 0096/1392
[A[ATraining Step: 1104  | total loss: [1m[32m0.06937[0m[0m | time: 2.439s
[2K
| Adam | epoch: 026 | loss: 0.06937 - acc: 0.9830 -- iter: 0128/1392
[A[ATraining Step: 1105  | total loss: [1m[32m0.06369[0m[0m | time: 3.031s
[2K
| Adam | epoch: 026 | loss: 0.06369 - acc: 0.9847 -- iter: 0160/1392
[A[ATraining Step: 1106  | total loss: [1m[32m0.07288[0m[0m | time: 3.634s
[2K
| Adam | epoch: 026 | loss: 0.07288 - acc: 0.9831 -- iter: 0192/1392
[A[ATraining Step: 1107  | total loss: [1m[32m0.06741[0m[0m | time: 4.238s
[2K
| Adam | epoch: 026 | loss: 0.06741 - acc: 0.9848 -- iter: 0224/1392
[A[ATraining Step: 1108  | total loss: [1m[32m0.06380[0m[0m | time: 4.842s
[2K
| Adam | epoch: 026 | loss: 0.06380 - acc: 0.9863 -- iter: 0256/1392
[A[ATraining Step: 1109  | total loss: [1m[32m0.05861[0m[0m | time: 5.448s
[2K
| Adam | epoch: 026 | loss: 0.05861 - acc: 0.9877 -- iter: 0288/1392
[A[ATraining Step: 1110  | total loss: [1m[32m0.05345[0m[0m | time: 6.078s
[2K
| Adam | epoch: 026 | loss: 0.05345 - acc: 0.9889 -- iter: 0320/1392
[A[ATraining Step: 1111  | total loss: [1m[32m0.05214[0m[0m | time: 6.686s
[2K
| Adam | epoch: 026 | loss: 0.05214 - acc: 0.9900 -- iter: 0352/1392
[A[ATraining Step: 1112  | total loss: [1m[32m0.04842[0m[0m | time: 7.275s
[2K
| Adam | epoch: 026 | loss: 0.04842 - acc: 0.9910 -- iter: 0384/1392
[A[ATraining Step: 1113  | total loss: [1m[32m0.04534[0m[0m | time: 7.887s
[2K
| Adam | epoch: 026 | loss: 0.04534 - acc: 0.9919 -- iter: 0416/1392
[A[ATraining Step: 1114  | total loss: [1m[32m0.04307[0m[0m | time: 8.520s
[2K
| Adam | epoch: 026 | loss: 0.04307 - acc: 0.9927 -- iter: 0448/1392
[A[ATraining Step: 1115  | total loss: [1m[32m0.05056[0m[0m | time: 9.142s
[2K
| Adam | epoch: 026 | loss: 0.05056 - acc: 0.9903 -- iter: 0480/1392
[A[ATraining Step: 1116  | total loss: [1m[32m0.04792[0m[0m | time: 9.732s
[2K
| Adam | epoch: 026 | loss: 0.04792 - acc: 0.9913 -- iter: 0512/1392
[A[ATraining Step: 1117  | total loss: [1m[32m0.04456[0m[0m | time: 10.323s
[2K
| Adam | epoch: 026 | loss: 0.04456 - acc: 0.9922 -- iter: 0544/1392
[A[ATraining Step: 1118  | total loss: [1m[32m0.04073[0m[0m | time: 10.943s
[2K
| Adam | epoch: 026 | loss: 0.04073 - acc: 0.9930 -- iter: 0576/1392
[A[ATraining Step: 1119  | total loss: [1m[32m0.03750[0m[0m | time: 11.537s
[2K
| Adam | epoch: 026 | loss: 0.03750 - acc: 0.9937 -- iter: 0608/1392
[A[ATraining Step: 1120  | total loss: [1m[32m0.03504[0m[0m | time: 12.157s
[2K
| Adam | epoch: 026 | loss: 0.03504 - acc: 0.9943 -- iter: 0640/1392
[A[ATraining Step: 1121  | total loss: [1m[32m0.03435[0m[0m | time: 12.757s
[2K
| Adam | epoch: 026 | loss: 0.03435 - acc: 0.9917 -- iter: 0672/1392
[A[ATraining Step: 1122  | total loss: [1m[32m0.03540[0m[0m | time: 13.371s
[2K
| Adam | epoch: 026 | loss: 0.03540 - acc: 0.9894 -- iter: 0704/1392
[A[ATraining Step: 1123  | total loss: [1m[32m0.03341[0m[0m | time: 14.013s
[2K
| Adam | epoch: 026 | loss: 0.03341 - acc: 0.9905 -- iter: 0736/1392
[A[ATraining Step: 1124  | total loss: [1m[32m0.03086[0m[0m | time: 14.343s
[2K
| Adam | epoch: 026 | loss: 0.03086 - acc: 0.9914 -- iter: 0768/1392
[A[ATraining Step: 1125  | total loss: [1m[32m0.02824[0m[0m | time: 14.674s
[2K
| Adam | epoch: 026 | loss: 0.02824 - acc: 0.9923 -- iter: 0800/1392
[A[ATraining Step: 1126  | total loss: [1m[32m0.02580[0m[0m | time: 15.327s
[2K
| Adam | epoch: 026 | loss: 0.02580 - acc: 0.9931 -- iter: 0832/1392
[A[ATraining Step: 1127  | total loss: [1m[32m0.02358[0m[0m | time: 15.993s
[2K
| Adam | epoch: 026 | loss: 0.02358 - acc: 0.9938 -- iter: 0864/1392
[A[ATraining Step: 1128  | total loss: [1m[32m0.02889[0m[0m | time: 16.596s
[2K
| Adam | epoch: 026 | loss: 0.02889 - acc: 0.9881 -- iter: 0896/1392
[A[ATraining Step: 1129  | total loss: [1m[32m0.02642[0m[0m | time: 17.186s
[2K
| Adam | epoch: 026 | loss: 0.02642 - acc: 0.9893 -- iter: 0928/1392
[A[ATraining Step: 1130  | total loss: [1m[32m0.02433[0m[0m | time: 17.791s
[2K
| Adam | epoch: 026 | loss: 0.02433 - acc: 0.9904 -- iter: 0960/1392
[A[ATraining Step: 1131  | total loss: [1m[32m0.02609[0m[0m | time: 18.400s
[2K
| Adam | epoch: 026 | loss: 0.02609 - acc: 0.9882 -- iter: 0992/1392
[A[ATraining Step: 1132  | total loss: [1m[32m0.02372[0m[0m | time: 19.000s
[2K
| Adam | epoch: 026 | loss: 0.02372 - acc: 0.9894 -- iter: 1024/1392
[A[ATraining Step: 1133  | total loss: [1m[32m0.02299[0m[0m | time: 19.615s
[2K
| Adam | epoch: 026 | loss: 0.02299 - acc: 0.9905 -- iter: 1056/1392
[A[ATraining Step: 1134  | total loss: [1m[32m0.02104[0m[0m | time: 20.198s
[2K
| Adam | epoch: 026 | loss: 0.02104 - acc: 0.9914 -- iter: 1088/1392
[A[ATraining Step: 1135  | total loss: [1m[32m0.01916[0m[0m | time: 20.801s
[2K
| Adam | epoch: 026 | loss: 0.01916 - acc: 0.9923 -- iter: 1120/1392
[A[ATraining Step: 1136  | total loss: [1m[32m0.01760[0m[0m | time: 21.395s
[2K
| Adam | epoch: 026 | loss: 0.01760 - acc: 0.9930 -- iter: 1152/1392
[A[ATraining Step: 1137  | total loss: [1m[32m0.02425[0m[0m | time: 21.982s
[2K
| Adam | epoch: 026 | loss: 0.02425 - acc: 0.9906 -- iter: 1184/1392
[A[ATraining Step: 1138  | total loss: [1m[32m0.03830[0m[0m | time: 22.575s
[2K
| Adam | epoch: 026 | loss: 0.03830 - acc: 0.9884 -- iter: 1216/1392
[A[ATraining Step: 1139  | total loss: [1m[32m0.03582[0m[0m | time: 23.186s
[2K
| Adam | epoch: 026 | loss: 0.03582 - acc: 0.9896 -- iter: 1248/1392
[A[ATraining Step: 1140  | total loss: [1m[32m0.03565[0m[0m | time: 23.788s
[2K
| Adam | epoch: 026 | loss: 0.03565 - acc: 0.9906 -- iter: 1280/1392
[A[ATraining Step: 1141  | total loss: [1m[32m0.03617[0m[0m | time: 24.389s
[2K
| Adam | epoch: 026 | loss: 0.03617 - acc: 0.9916 -- iter: 1312/1392
[A[ATraining Step: 1142  | total loss: [1m[32m0.03379[0m[0m | time: 25.004s
[2K
| Adam | epoch: 026 | loss: 0.03379 - acc: 0.9924 -- iter: 1344/1392
[A[ATraining Step: 1143  | total loss: [1m[32m0.03225[0m[0m | time: 25.595s
[2K
| Adam | epoch: 026 | loss: 0.03225 - acc: 0.9932 -- iter: 1376/1392
[A[ATraining Step: 1144  | total loss: [1m[32m0.03094[0m[0m | time: 27.547s
[2K
| Adam | epoch: 026 | loss: 0.03094 - acc: 0.9939 | val_loss: 1.21349 - val_acc: 0.7425 -- iter: 1392/1392
--
Training Step: 1145  | total loss: [1m[32m0.03573[0m[0m | time: 0.610s
[2K
| Adam | epoch: 027 | loss: 0.03573 - acc: 0.9913 -- iter: 0032/1392
[A[ATraining Step: 1146  | total loss: [1m[32m0.03241[0m[0m | time: 1.225s
[2K
| Adam | epoch: 027 | loss: 0.03241 - acc: 0.9922 -- iter: 0064/1392
[A[ATraining Step: 1147  | total loss: [1m[32m0.02992[0m[0m | time: 1.826s
[2K
| Adam | epoch: 027 | loss: 0.02992 - acc: 0.9930 -- iter: 0096/1392
[A[ATraining Step: 1148  | total loss: [1m[32m0.03409[0m[0m | time: 2.419s
[2K
| Adam | epoch: 027 | loss: 0.03409 - acc: 0.9874 -- iter: 0128/1392
[A[ATraining Step: 1149  | total loss: [1m[32m0.03262[0m[0m | time: 3.024s
[2K
| Adam | epoch: 027 | loss: 0.03262 - acc: 0.9887 -- iter: 0160/1392
[A[ATraining Step: 1150  | total loss: [1m[32m0.03051[0m[0m | time: 3.645s
[2K
| Adam | epoch: 027 | loss: 0.03051 - acc: 0.9898 -- iter: 0192/1392
[A[ATraining Step: 1151  | total loss: [1m[32m0.03742[0m[0m | time: 4.233s
[2K
| Adam | epoch: 027 | loss: 0.03742 - acc: 0.9846 -- iter: 0224/1392
[A[ATraining Step: 1152  | total loss: [1m[32m0.04155[0m[0m | time: 4.830s
[2K
| Adam | epoch: 027 | loss: 0.04155 - acc: 0.9830 -- iter: 0256/1392
[A[ATraining Step: 1153  | total loss: [1m[32m0.05501[0m[0m | time: 5.429s
[2K
| Adam | epoch: 027 | loss: 0.05501 - acc: 0.9816 -- iter: 0288/1392
[A[ATraining Step: 1154  | total loss: [1m[32m0.05438[0m[0m | time: 6.023s
[2K
| Adam | epoch: 027 | loss: 0.05438 - acc: 0.9803 -- iter: 0320/1392
[A[ATraining Step: 1155  | total loss: [1m[32m0.06237[0m[0m | time: 6.641s
[2K
| Adam | epoch: 027 | loss: 0.06237 - acc: 0.9791 -- iter: 0352/1392
[A[ATraining Step: 1156  | total loss: [1m[32m0.06764[0m[0m | time: 7.256s
[2K
| Adam | epoch: 027 | loss: 0.06764 - acc: 0.9781 -- iter: 0384/1392
[A[ATraining Step: 1157  | total loss: [1m[32m0.06227[0m[0m | time: 7.857s
[2K
| Adam | epoch: 027 | loss: 0.06227 - acc: 0.9803 -- iter: 0416/1392
[A[ATraining Step: 1158  | total loss: [1m[32m0.05703[0m[0m | time: 8.456s
[2K
| Adam | epoch: 027 | loss: 0.05703 - acc: 0.9823 -- iter: 0448/1392
[A[ATraining Step: 1159  | total loss: [1m[32m0.06136[0m[0m | time: 9.063s
[2K
| Adam | epoch: 027 | loss: 0.06136 - acc: 0.9809 -- iter: 0480/1392
[A[ATraining Step: 1160  | total loss: [1m[32m0.05890[0m[0m | time: 9.664s
[2K
| Adam | epoch: 027 | loss: 0.05890 - acc: 0.9797 -- iter: 0512/1392
[A[ATraining Step: 1161  | total loss: [1m[32m0.05330[0m[0m | time: 10.264s
[2K
| Adam | epoch: 027 | loss: 0.05330 - acc: 0.9817 -- iter: 0544/1392
[A[ATraining Step: 1162  | total loss: [1m[32m0.04839[0m[0m | time: 10.863s
[2K
| Adam | epoch: 027 | loss: 0.04839 - acc: 0.9836 -- iter: 0576/1392
[A[ATraining Step: 1163  | total loss: [1m[32m0.04413[0m[0m | time: 11.458s
[2K
| Adam | epoch: 027 | loss: 0.04413 - acc: 0.9852 -- iter: 0608/1392
[A[ATraining Step: 1164  | total loss: [1m[32m0.04085[0m[0m | time: 12.052s
[2K
| Adam | epoch: 027 | loss: 0.04085 - acc: 0.9867 -- iter: 0640/1392
[A[ATraining Step: 1165  | total loss: [1m[32m0.03862[0m[0m | time: 12.657s
[2K
| Adam | epoch: 027 | loss: 0.03862 - acc: 0.9880 -- iter: 0672/1392
[A[ATraining Step: 1166  | total loss: [1m[32m0.03521[0m[0m | time: 13.297s
[2K
| Adam | epoch: 027 | loss: 0.03521 - acc: 0.9892 -- iter: 0704/1392
[A[ATraining Step: 1167  | total loss: [1m[32m0.04901[0m[0m | time: 13.918s
[2K
| Adam | epoch: 027 | loss: 0.04901 - acc: 0.9872 -- iter: 0736/1392
[A[ATraining Step: 1168  | total loss: [1m[32m0.04449[0m[0m | time: 14.550s
[2K
| Adam | epoch: 027 | loss: 0.04449 - acc: 0.9884 -- iter: 0768/1392
[A[ATraining Step: 1169  | total loss: [1m[32m0.04060[0m[0m | time: 14.888s
[2K
| Adam | epoch: 027 | loss: 0.04060 - acc: 0.9896 -- iter: 0800/1392
[A[ATraining Step: 1170  | total loss: [1m[32m0.03680[0m[0m | time: 15.214s
[2K
| Adam | epoch: 027 | loss: 0.03680 - acc: 0.9906 -- iter: 0832/1392
[A[ATraining Step: 1171  | total loss: [1m[32m0.03334[0m[0m | time: 15.833s
[2K
| Adam | epoch: 027 | loss: 0.03334 - acc: 0.9916 -- iter: 0864/1392
[A[ATraining Step: 1172  | total loss: [1m[32m0.03955[0m[0m | time: 16.448s
[2K
| Adam | epoch: 027 | loss: 0.03955 - acc: 0.9893 -- iter: 0896/1392
[A[ATraining Step: 1173  | total loss: [1m[32m0.03675[0m[0m | time: 17.041s
[2K
| Adam | epoch: 027 | loss: 0.03675 - acc: 0.9904 -- iter: 0928/1392
[A[ATraining Step: 1174  | total loss: [1m[32m0.03347[0m[0m | time: 17.642s
[2K
| Adam | epoch: 027 | loss: 0.03347 - acc: 0.9913 -- iter: 0960/1392
[A[ATraining Step: 1175  | total loss: [1m[32m0.03424[0m[0m | time: 18.261s
[2K
| Adam | epoch: 027 | loss: 0.03424 - acc: 0.9891 -- iter: 0992/1392
[A[ATraining Step: 1176  | total loss: [1m[32m0.03127[0m[0m | time: 18.861s
[2K
| Adam | epoch: 027 | loss: 0.03127 - acc: 0.9902 -- iter: 1024/1392
[A[ATraining Step: 1177  | total loss: [1m[32m0.02841[0m[0m | time: 19.451s
[2K
| Adam | epoch: 027 | loss: 0.02841 - acc: 0.9911 -- iter: 1056/1392
[A[ATraining Step: 1178  | total loss: [1m[32m0.02584[0m[0m | time: 20.050s
[2K
| Adam | epoch: 027 | loss: 0.02584 - acc: 0.9920 -- iter: 1088/1392
[A[ATraining Step: 1179  | total loss: [1m[32m0.02367[0m[0m | time: 20.644s
[2K
| Adam | epoch: 027 | loss: 0.02367 - acc: 0.9928 -- iter: 1120/1392
[A[ATraining Step: 1180  | total loss: [1m[32m0.02288[0m[0m | time: 21.232s
[2K
| Adam | epoch: 027 | loss: 0.02288 - acc: 0.9935 -- iter: 1152/1392
[A[ATraining Step: 1181  | total loss: [1m[32m0.02383[0m[0m | time: 21.825s
[2K
| Adam | epoch: 027 | loss: 0.02383 - acc: 0.9911 -- iter: 1184/1392
[A[ATraining Step: 1182  | total loss: [1m[32m0.02226[0m[0m | time: 22.430s
[2K
| Adam | epoch: 027 | loss: 0.02226 - acc: 0.9920 -- iter: 1216/1392
[A[ATraining Step: 1183  | total loss: [1m[32m0.04820[0m[0m | time: 23.031s
[2K
| Adam | epoch: 027 | loss: 0.04820 - acc: 0.9896 -- iter: 1248/1392
[A[ATraining Step: 1184  | total loss: [1m[32m0.05419[0m[0m | time: 23.619s
[2K
| Adam | epoch: 027 | loss: 0.05419 - acc: 0.9876 -- iter: 1280/1392
[A[ATraining Step: 1185  | total loss: [1m[32m0.04917[0m[0m | time: 24.217s
[2K
| Adam | epoch: 027 | loss: 0.04917 - acc: 0.9888 -- iter: 1312/1392
[A[ATraining Step: 1186  | total loss: [1m[32m0.04471[0m[0m | time: 24.813s
[2K
| Adam | epoch: 027 | loss: 0.04471 - acc: 0.9899 -- iter: 1344/1392
[A[ATraining Step: 1187  | total loss: [1m[32m0.04048[0m[0m | time: 25.418s
[2K
| Adam | epoch: 027 | loss: 0.04048 - acc: 0.9909 -- iter: 1376/1392
[A[ATraining Step: 1188  | total loss: [1m[32m0.03698[0m[0m | time: 27.362s
[2K
| Adam | epoch: 027 | loss: 0.03698 - acc: 0.9918 | val_loss: 1.09849 - val_acc: 0.7517 -- iter: 1392/1392
--
Training Step: 1189  | total loss: [1m[32m0.03520[0m[0m | time: 0.603s
[2K
| Adam | epoch: 028 | loss: 0.03520 - acc: 0.9926 -- iter: 0032/1392
[A[ATraining Step: 1190  | total loss: [1m[32m0.03294[0m[0m | time: 1.215s
[2K
| Adam | epoch: 028 | loss: 0.03294 - acc: 0.9934 -- iter: 0064/1392
[A[ATraining Step: 1191  | total loss: [1m[32m0.03032[0m[0m | time: 1.823s
[2K
| Adam | epoch: 028 | loss: 0.03032 - acc: 0.9940 -- iter: 0096/1392
[A[ATraining Step: 1192  | total loss: [1m[32m0.02775[0m[0m | time: 2.423s
[2K
| Adam | epoch: 028 | loss: 0.02775 - acc: 0.9946 -- iter: 0128/1392
[A[ATraining Step: 1193  | total loss: [1m[32m0.02664[0m[0m | time: 3.027s
[2K
| Adam | epoch: 028 | loss: 0.02664 - acc: 0.9952 -- iter: 0160/1392
[A[ATraining Step: 1194  | total loss: [1m[32m0.02464[0m[0m | time: 3.671s
[2K
| Adam | epoch: 028 | loss: 0.02464 - acc: 0.9957 -- iter: 0192/1392
[A[ATraining Step: 1195  | total loss: [1m[32m0.02252[0m[0m | time: 4.282s
[2K
| Adam | epoch: 028 | loss: 0.02252 - acc: 0.9961 -- iter: 0224/1392
[A[ATraining Step: 1196  | total loss: [1m[32m0.02890[0m[0m | time: 4.880s
[2K
| Adam | epoch: 028 | loss: 0.02890 - acc: 0.9934 -- iter: 0256/1392
[A[ATraining Step: 1197  | total loss: [1m[32m0.02633[0m[0m | time: 5.471s
[2K
| Adam | epoch: 028 | loss: 0.02633 - acc: 0.9940 -- iter: 0288/1392
[A[ATraining Step: 1198  | total loss: [1m[32m0.02524[0m[0m | time: 6.075s
[2K
| Adam | epoch: 028 | loss: 0.02524 - acc: 0.9946 -- iter: 0320/1392
[A[ATraining Step: 1199  | total loss: [1m[32m0.02402[0m[0m | time: 6.685s
[2K
| Adam | epoch: 028 | loss: 0.02402 - acc: 0.9952 -- iter: 0352/1392
[A[ATraining Step: 1200  | total loss: [1m[32m0.02258[0m[0m | time: 8.649s
[2K
| Adam | epoch: 028 | loss: 0.02258 - acc: 0.9956 | val_loss: 1.12914 - val_acc: 0.7448 -- iter: 0384/1392
--
Training Step: 1201  | total loss: [1m[32m0.02177[0m[0m | time: 9.267s
[2K
| Adam | epoch: 028 | loss: 0.02177 - acc: 0.9961 -- iter: 0416/1392
[A[ATraining Step: 1202  | total loss: [1m[32m0.02032[0m[0m | time: 9.850s
[2K
| Adam | epoch: 028 | loss: 0.02032 - acc: 0.9965 -- iter: 0448/1392
[A[ATraining Step: 1203  | total loss: [1m[32m0.01930[0m[0m | time: 10.446s
[2K
| Adam | epoch: 028 | loss: 0.01930 - acc: 0.9968 -- iter: 0480/1392
[A[ATraining Step: 1204  | total loss: [1m[32m0.01778[0m[0m | time: 11.041s
[2K
| Adam | epoch: 028 | loss: 0.01778 - acc: 0.9971 -- iter: 0512/1392
[A[ATraining Step: 1205  | total loss: [1m[32m0.02698[0m[0m | time: 11.640s
[2K
| Adam | epoch: 028 | loss: 0.02698 - acc: 0.9943 -- iter: 0544/1392
[A[ATraining Step: 1206  | total loss: [1m[32m0.03989[0m[0m | time: 12.238s
[2K
| Adam | epoch: 028 | loss: 0.03989 - acc: 0.9917 -- iter: 0576/1392
[A[ATraining Step: 1207  | total loss: [1m[32m0.05488[0m[0m | time: 12.840s
[2K
| Adam | epoch: 028 | loss: 0.05488 - acc: 0.9894 -- iter: 0608/1392
[A[ATraining Step: 1208  | total loss: [1m[32m0.04972[0m[0m | time: 13.444s
[2K
| Adam | epoch: 028 | loss: 0.04972 - acc: 0.9905 -- iter: 0640/1392
[A[ATraining Step: 1209  | total loss: [1m[32m0.04600[0m[0m | time: 14.039s
[2K
| Adam | epoch: 028 | loss: 0.04600 - acc: 0.9915 -- iter: 0672/1392
[A[ATraining Step: 1210  | total loss: [1m[32m0.04178[0m[0m | time: 14.632s
[2K
| Adam | epoch: 028 | loss: 0.04178 - acc: 0.9923 -- iter: 0704/1392
[A[ATraining Step: 1211  | total loss: [1m[32m0.03817[0m[0m | time: 15.233s
[2K
| Adam | epoch: 028 | loss: 0.03817 - acc: 0.9931 -- iter: 0736/1392
[A[ATraining Step: 1212  | total loss: [1m[32m0.03605[0m[0m | time: 15.830s
[2K
| Adam | epoch: 028 | loss: 0.03605 - acc: 0.9938 -- iter: 0768/1392
[A[ATraining Step: 1213  | total loss: [1m[32m0.03322[0m[0m | time: 16.418s
[2K
| Adam | epoch: 028 | loss: 0.03322 - acc: 0.9944 -- iter: 0800/1392
[A[ATraining Step: 1214  | total loss: [1m[32m0.04016[0m[0m | time: 16.734s
[2K
| Adam | epoch: 028 | loss: 0.04016 - acc: 0.9918 -- iter: 0832/1392
[A[ATraining Step: 1215  | total loss: [1m[32m0.04639[0m[0m | time: 17.074s
[2K
| Adam | epoch: 028 | loss: 0.04639 - acc: 0.9864 -- iter: 0864/1392
[A[ATraining Step: 1216  | total loss: [1m[32m0.04409[0m[0m | time: 17.665s
[2K
| Adam | epoch: 028 | loss: 0.04409 - acc: 0.9878 -- iter: 0896/1392
[A[ATraining Step: 1217  | total loss: [1m[32m0.04200[0m[0m | time: 18.280s
[2K
| Adam | epoch: 028 | loss: 0.04200 - acc: 0.9890 -- iter: 0928/1392
[A[ATraining Step: 1218  | total loss: [1m[32m0.03981[0m[0m | time: 18.880s
[2K
| Adam | epoch: 028 | loss: 0.03981 - acc: 0.9901 -- iter: 0960/1392
[A[ATraining Step: 1219  | total loss: [1m[32m0.03839[0m[0m | time: 19.480s
[2K
| Adam | epoch: 028 | loss: 0.03839 - acc: 0.9911 -- iter: 0992/1392
[A[ATraining Step: 1220  | total loss: [1m[32m0.03559[0m[0m | time: 20.088s
[2K
| Adam | epoch: 028 | loss: 0.03559 - acc: 0.9920 -- iter: 1024/1392
[A[ATraining Step: 1221  | total loss: [1m[32m0.03416[0m[0m | time: 20.692s
[2K
| Adam | epoch: 028 | loss: 0.03416 - acc: 0.9928 -- iter: 1056/1392
[A[ATraining Step: 1222  | total loss: [1m[32m0.03170[0m[0m | time: 21.324s
[2K
| Adam | epoch: 028 | loss: 0.03170 - acc: 0.9935 -- iter: 1088/1392
[A[ATraining Step: 1223  | total loss: [1m[32m0.02964[0m[0m | time: 21.936s
[2K
| Adam | epoch: 028 | loss: 0.02964 - acc: 0.9941 -- iter: 1120/1392
[A[ATraining Step: 1224  | total loss: [1m[32m0.02701[0m[0m | time: 22.551s
[2K
| Adam | epoch: 028 | loss: 0.02701 - acc: 0.9947 -- iter: 1152/1392
[A[ATraining Step: 1225  | total loss: [1m[32m0.02543[0m[0m | time: 23.171s
[2K
| Adam | epoch: 028 | loss: 0.02543 - acc: 0.9953 -- iter: 1184/1392
[A[ATraining Step: 1226  | total loss: [1m[32m0.02467[0m[0m | time: 23.767s
[2K
| Adam | epoch: 028 | loss: 0.02467 - acc: 0.9957 -- iter: 1216/1392
[A[ATraining Step: 1227  | total loss: [1m[32m0.02298[0m[0m | time: 24.376s
[2K
| Adam | epoch: 028 | loss: 0.02298 - acc: 0.9962 -- iter: 1248/1392
[A[ATraining Step: 1228  | total loss: [1m[32m0.05140[0m[0m | time: 24.979s
[2K
| Adam | epoch: 028 | loss: 0.05140 - acc: 0.9934 -- iter: 1280/1392
[A[ATraining Step: 1229  | total loss: [1m[32m0.04790[0m[0m | time: 25.582s
[2K
| Adam | epoch: 028 | loss: 0.04790 - acc: 0.9941 -- iter: 1312/1392
[A[ATraining Step: 1230  | total loss: [1m[32m0.04362[0m[0m | time: 26.173s
[2K
| Adam | epoch: 028 | loss: 0.04362 - acc: 0.9947 -- iter: 1344/1392
[A[ATraining Step: 1231  | total loss: [1m[32m0.04111[0m[0m | time: 26.778s
[2K
| Adam | epoch: 028 | loss: 0.04111 - acc: 0.9952 -- iter: 1376/1392
[A[ATraining Step: 1232  | total loss: [1m[32m0.03735[0m[0m | time: 28.779s
[2K
| Adam | epoch: 028 | loss: 0.03735 - acc: 0.9957 | val_loss: 1.00937 - val_acc: 0.7770 -- iter: 1392/1392
--
Training Step: 1233  | total loss: [1m[32m0.04891[0m[0m | time: 0.594s
[2K
| Adam | epoch: 029 | loss: 0.04891 - acc: 0.9930 -- iter: 0032/1392
[A[ATraining Step: 1234  | total loss: [1m[32m0.05115[0m[0m | time: 1.185s
[2K
| Adam | epoch: 029 | loss: 0.05115 - acc: 0.9906 -- iter: 0064/1392
[A[ATraining Step: 1235  | total loss: [1m[32m0.04744[0m[0m | time: 1.780s
[2K
| Adam | epoch: 029 | loss: 0.04744 - acc: 0.9915 -- iter: 0096/1392
[A[ATraining Step: 1236  | total loss: [1m[32m0.04330[0m[0m | time: 2.384s
[2K
| Adam | epoch: 029 | loss: 0.04330 - acc: 0.9924 -- iter: 0128/1392
[A[ATraining Step: 1237  | total loss: [1m[32m0.03939[0m[0m | time: 2.981s
[2K
| Adam | epoch: 029 | loss: 0.03939 - acc: 0.9931 -- iter: 0160/1392
[A[ATraining Step: 1238  | total loss: [1m[32m0.03598[0m[0m | time: 3.578s
[2K
| Adam | epoch: 029 | loss: 0.03598 - acc: 0.9938 -- iter: 0192/1392
[A[ATraining Step: 1239  | total loss: [1m[32m0.03287[0m[0m | time: 4.205s
[2K
| Adam | epoch: 029 | loss: 0.03287 - acc: 0.9944 -- iter: 0224/1392
[A[ATraining Step: 1240  | total loss: [1m[32m0.02993[0m[0m | time: 4.812s
[2K
| Adam | epoch: 029 | loss: 0.02993 - acc: 0.9950 -- iter: 0256/1392
[A[ATraining Step: 1241  | total loss: [1m[32m0.02764[0m[0m | time: 5.412s
[2K
| Adam | epoch: 029 | loss: 0.02764 - acc: 0.9955 -- iter: 0288/1392
[A[ATraining Step: 1242  | total loss: [1m[32m0.02681[0m[0m | time: 6.025s
[2K
| Adam | epoch: 029 | loss: 0.02681 - acc: 0.9959 -- iter: 0320/1392
[A[ATraining Step: 1243  | total loss: [1m[32m0.02527[0m[0m | time: 6.619s
[2K
| Adam | epoch: 029 | loss: 0.02527 - acc: 0.9963 -- iter: 0352/1392
[A[ATraining Step: 1244  | total loss: [1m[32m0.02300[0m[0m | time: 7.197s
[2K
| Adam | epoch: 029 | loss: 0.02300 - acc: 0.9967 -- iter: 0384/1392
[A[ATraining Step: 1245  | total loss: [1m[32m0.02104[0m[0m | time: 7.794s
[2K
| Adam | epoch: 029 | loss: 0.02104 - acc: 0.9970 -- iter: 0416/1392
[A[ATraining Step: 1246  | total loss: [1m[32m0.01918[0m[0m | time: 8.386s
[2K
| Adam | epoch: 029 | loss: 0.01918 - acc: 0.9973 -- iter: 0448/1392
[A[ATraining Step: 1247  | total loss: [1m[32m0.01857[0m[0m | time: 8.985s
[2K
| Adam | epoch: 029 | loss: 0.01857 - acc: 0.9976 -- iter: 0480/1392
[A[ATraining Step: 1248  | total loss: [1m[32m0.02708[0m[0m | time: 9.598s
[2K
| Adam | epoch: 029 | loss: 0.02708 - acc: 0.9947 -- iter: 0512/1392
[A[ATraining Step: 1249  | total loss: [1m[32m0.02453[0m[0m | time: 10.222s
[2K
| Adam | epoch: 029 | loss: 0.02453 - acc: 0.9952 -- iter: 0544/1392
[A[ATraining Step: 1250  | total loss: [1m[32m0.02296[0m[0m | time: 10.820s
[2K
| Adam | epoch: 029 | loss: 0.02296 - acc: 0.9957 -- iter: 0576/1392
[A[ATraining Step: 1251  | total loss: [1m[32m0.02200[0m[0m | time: 11.403s
[2K
| Adam | epoch: 029 | loss: 0.02200 - acc: 0.9961 -- iter: 0608/1392
[A[ATraining Step: 1252  | total loss: [1m[32m0.02617[0m[0m | time: 11.999s
[2K
| Adam | epoch: 029 | loss: 0.02617 - acc: 0.9934 -- iter: 0640/1392
[A[ATraining Step: 1253  | total loss: [1m[32m0.04383[0m[0m | time: 12.590s
[2K
| Adam | epoch: 029 | loss: 0.04383 - acc: 0.9909 -- iter: 0672/1392
[A[ATraining Step: 1254  | total loss: [1m[32m0.04086[0m[0m | time: 13.186s
[2K
| Adam | epoch: 029 | loss: 0.04086 - acc: 0.9918 -- iter: 0704/1392
[A[ATraining Step: 1255  | total loss: [1m[32m0.03699[0m[0m | time: 13.788s
[2K
| Adam | epoch: 029 | loss: 0.03699 - acc: 0.9927 -- iter: 0736/1392
[A[ATraining Step: 1256  | total loss: [1m[32m0.03494[0m[0m | time: 14.397s
[2K
| Adam | epoch: 029 | loss: 0.03494 - acc: 0.9934 -- iter: 0768/1392
[A[ATraining Step: 1257  | total loss: [1m[32m0.03172[0m[0m | time: 15.020s
[2K
| Adam | epoch: 029 | loss: 0.03172 - acc: 0.9941 -- iter: 0800/1392
[A[ATraining Step: 1258  | total loss: [1m[32m0.02878[0m[0m | time: 15.620s
[2K
| Adam | epoch: 029 | loss: 0.02878 - acc: 0.9947 -- iter: 0832/1392
[A[ATraining Step: 1259  | total loss: [1m[32m0.02626[0m[0m | time: 15.949s
[2K
| Adam | epoch: 029 | loss: 0.02626 - acc: 0.9952 -- iter: 0864/1392
[A[ATraining Step: 1260  | total loss: [1m[32m0.02440[0m[0m | time: 16.278s
[2K
| Adam | epoch: 029 | loss: 0.02440 - acc: 0.9957 -- iter: 0896/1392
[A[ATraining Step: 1261  | total loss: [1m[32m0.02273[0m[0m | time: 16.872s
[2K
| Adam | epoch: 029 | loss: 0.02273 - acc: 0.9961 -- iter: 0928/1392
[A[ATraining Step: 1262  | total loss: [1m[32m0.02093[0m[0m | time: 17.468s
[2K
| Adam | epoch: 029 | loss: 0.02093 - acc: 0.9965 -- iter: 0960/1392
[A[ATraining Step: 1263  | total loss: [1m[32m0.01960[0m[0m | time: 18.059s
[2K
| Adam | epoch: 029 | loss: 0.01960 - acc: 0.9968 -- iter: 0992/1392
[A[ATraining Step: 1264  | total loss: [1m[32m0.01887[0m[0m | time: 18.676s
[2K
| Adam | epoch: 029 | loss: 0.01887 - acc: 0.9972 -- iter: 1024/1392
[A[ATraining Step: 1265  | total loss: [1m[32m0.01751[0m[0m | time: 19.325s
[2K
| Adam | epoch: 029 | loss: 0.01751 - acc: 0.9974 -- iter: 1056/1392
[A[ATraining Step: 1266  | total loss: [1m[32m0.01731[0m[0m | time: 19.931s
[2K
| Adam | epoch: 029 | loss: 0.01731 - acc: 0.9977 -- iter: 1088/1392
[A[ATraining Step: 1267  | total loss: [1m[32m0.02506[0m[0m | time: 20.553s
[2K
| Adam | epoch: 029 | loss: 0.02506 - acc: 0.9948 -- iter: 1120/1392
[A[ATraining Step: 1268  | total loss: [1m[32m0.02302[0m[0m | time: 21.154s
[2K
| Adam | epoch: 029 | loss: 0.02302 - acc: 0.9953 -- iter: 1152/1392
[A[ATraining Step: 1269  | total loss: [1m[32m0.02105[0m[0m | time: 21.752s
[2K
| Adam | epoch: 029 | loss: 0.02105 - acc: 0.9958 -- iter: 1184/1392
[A[ATraining Step: 1270  | total loss: [1m[32m0.01927[0m[0m | time: 22.362s
[2K
| Adam | epoch: 029 | loss: 0.01927 - acc: 0.9962 -- iter: 1216/1392
[A[ATraining Step: 1271  | total loss: [1m[32m0.01767[0m[0m | time: 22.962s
[2K
| Adam | epoch: 029 | loss: 0.01767 - acc: 0.9966 -- iter: 1248/1392
[A[ATraining Step: 1272  | total loss: [1m[32m0.01852[0m[0m | time: 23.566s
[2K
| Adam | epoch: 029 | loss: 0.01852 - acc: 0.9969 -- iter: 1280/1392
[A[ATraining Step: 1273  | total loss: [1m[32m0.04546[0m[0m | time: 24.172s
[2K
| Adam | epoch: 029 | loss: 0.04546 - acc: 0.9910 -- iter: 1312/1392
[A[ATraining Step: 1274  | total loss: [1m[32m0.04132[0m[0m | time: 24.768s
[2K
| Adam | epoch: 029 | loss: 0.04132 - acc: 0.9919 -- iter: 1344/1392
[A[ATraining Step: 1275  | total loss: [1m[32m0.03794[0m[0m | time: 25.366s
[2K
| Adam | epoch: 029 | loss: 0.03794 - acc: 0.9927 -- iter: 1376/1392
[A[ATraining Step: 1276  | total loss: [1m[32m0.03474[0m[0m | time: 27.313s
[2K
| Adam | epoch: 029 | loss: 0.03474 - acc: 0.9934 | val_loss: 1.21078 - val_acc: 0.7701 -- iter: 1392/1392
--
Training Step: 1277  | total loss: [1m[32m0.03157[0m[0m | time: 0.623s
[2K
| Adam | epoch: 030 | loss: 0.03157 - acc: 0.9941 -- iter: 0032/1392
[A[ATraining Step: 1278  | total loss: [1m[32m0.04077[0m[0m | time: 1.224s
[2K
| Adam | epoch: 030 | loss: 0.04077 - acc: 0.9884 -- iter: 0064/1392
[A[ATraining Step: 1279  | total loss: [1m[32m0.04093[0m[0m | time: 1.824s
[2K
| Adam | epoch: 030 | loss: 0.04093 - acc: 0.9865 -- iter: 0096/1392
[A[ATraining Step: 1280  | total loss: [1m[32m0.03714[0m[0m | time: 2.436s
[2K
| Adam | epoch: 030 | loss: 0.03714 - acc: 0.9878 -- iter: 0128/1392
[A[ATraining Step: 1281  | total loss: [1m[32m0.03389[0m[0m | time: 3.041s
[2K
| Adam | epoch: 030 | loss: 0.03389 - acc: 0.9890 -- iter: 0160/1392
[A[ATraining Step: 1282  | total loss: [1m[32m0.03111[0m[0m | time: 3.641s
[2K
| Adam | epoch: 030 | loss: 0.03111 - acc: 0.9901 -- iter: 0192/1392
[A[ATraining Step: 1283  | total loss: [1m[32m0.02850[0m[0m | time: 4.262s
[2K
| Adam | epoch: 030 | loss: 0.02850 - acc: 0.9911 -- iter: 0224/1392
[A[ATraining Step: 1284  | total loss: [1m[32m0.03536[0m[0m | time: 4.854s
[2K
| Adam | epoch: 030 | loss: 0.03536 - acc: 0.9889 -- iter: 0256/1392
[A[ATraining Step: 1285  | total loss: [1m[32m0.03229[0m[0m | time: 5.453s
[2K
| Adam | epoch: 030 | loss: 0.03229 - acc: 0.9900 -- iter: 0288/1392
[A[ATraining Step: 1286  | total loss: [1m[32m0.02959[0m[0m | time: 6.064s
[2K
| Adam | epoch: 030 | loss: 0.02959 - acc: 0.9910 -- iter: 0320/1392
[A[ATraining Step: 1287  | total loss: [1m[32m0.02791[0m[0m | time: 6.673s
[2K
| Adam | epoch: 030 | loss: 0.02791 - acc: 0.9919 -- iter: 0352/1392
[A[ATraining Step: 1288  | total loss: [1m[32m0.02684[0m[0m | time: 7.293s
[2K
| Adam | epoch: 030 | loss: 0.02684 - acc: 0.9927 -- iter: 0384/1392
[A[ATraining Step: 1289  | total loss: [1m[32m0.02484[0m[0m | time: 7.912s
[2K
| Adam | epoch: 030 | loss: 0.02484 - acc: 0.9934 -- iter: 0416/1392
[A[ATraining Step: 1290  | total loss: [1m[32m0.02432[0m[0m | time: 8.543s
[2K
| Adam | epoch: 030 | loss: 0.02432 - acc: 0.9941 -- iter: 0448/1392
[A[ATraining Step: 1291  | total loss: [1m[32m0.02234[0m[0m | time: 9.164s
[2K
| Adam | epoch: 030 | loss: 0.02234 - acc: 0.9947 -- iter: 0480/1392
[A[ATraining Step: 1292  | total loss: [1m[32m0.02186[0m[0m | time: 9.764s
[2K
| Adam | epoch: 030 | loss: 0.02186 - acc: 0.9952 -- iter: 0512/1392
[A[ATraining Step: 1293  | total loss: [1m[32m0.02003[0m[0m | time: 10.379s
[2K
| Adam | epoch: 030 | loss: 0.02003 - acc: 0.9957 -- iter: 0544/1392
[A[ATraining Step: 1294  | total loss: [1m[32m0.01826[0m[0m | time: 10.985s
[2K
| Adam | epoch: 030 | loss: 0.01826 - acc: 0.9961 -- iter: 0576/1392
[A[ATraining Step: 1295  | total loss: [1m[32m0.01669[0m[0m | time: 11.579s
[2K
| Adam | epoch: 030 | loss: 0.01669 - acc: 0.9965 -- iter: 0608/1392
[A[ATraining Step: 1296  | total loss: [1m[32m0.01545[0m[0m | time: 12.191s
[2K
| Adam | epoch: 030 | loss: 0.01545 - acc: 0.9969 -- iter: 0640/1392
[A[ATraining Step: 1297  | total loss: [1m[32m0.02343[0m[0m | time: 12.797s
[2K
| Adam | epoch: 030 | loss: 0.02343 - acc: 0.9940 -- iter: 0672/1392
[A[ATraining Step: 1298  | total loss: [1m[32m0.02492[0m[0m | time: 13.413s
[2K
| Adam | epoch: 030 | loss: 0.02492 - acc: 0.9915 -- iter: 0704/1392
[A[ATraining Step: 1299  | total loss: [1m[32m0.02276[0m[0m | time: 14.028s
[2K
| Adam | epoch: 030 | loss: 0.02276 - acc: 0.9924 -- iter: 0736/1392
[A[ATraining Step: 1300  | total loss: [1m[32m0.02095[0m[0m | time: 14.638s
[2K
| Adam | epoch: 030 | loss: 0.02095 - acc: 0.9931 -- iter: 0768/1392
[A[ATraining Step: 1301  | total loss: [1m[32m0.01915[0m[0m | time: 15.232s
[2K
| Adam | epoch: 030 | loss: 0.01915 - acc: 0.9938 -- iter: 0800/1392
[A[ATraining Step: 1302  | total loss: [1m[32m0.01814[0m[0m | time: 15.823s
[2K
| Adam | epoch: 030 | loss: 0.01814 - acc: 0.9944 -- iter: 0832/1392
[A[ATraining Step: 1303  | total loss: [1m[32m0.01662[0m[0m | time: 16.416s
[2K
| Adam | epoch: 030 | loss: 0.01662 - acc: 0.9950 -- iter: 0864/1392
[A[ATraining Step: 1304  | total loss: [1m[32m0.01558[0m[0m | time: 16.746s
[2K
| Adam | epoch: 030 | loss: 0.01558 - acc: 0.9955 -- iter: 0896/1392
[A[ATraining Step: 1305  | total loss: [1m[32m0.01535[0m[0m | time: 17.064s
[2K
| Adam | epoch: 030 | loss: 0.01535 - acc: 0.9959 -- iter: 0928/1392
[A[ATraining Step: 1306  | total loss: [1m[32m0.01455[0m[0m | time: 17.664s
[2K
| Adam | epoch: 030 | loss: 0.01455 - acc: 0.9963 -- iter: 0960/1392
[A[ATraining Step: 1307  | total loss: [1m[32m0.01340[0m[0m | time: 18.258s
[2K
| Adam | epoch: 030 | loss: 0.01340 - acc: 0.9967 -- iter: 0992/1392
[A[ATraining Step: 1308  | total loss: [1m[32m0.01570[0m[0m | time: 18.853s
[2K
| Adam | epoch: 030 | loss: 0.01570 - acc: 0.9939 -- iter: 1024/1392
[A[ATraining Step: 1309  | total loss: [1m[32m0.01508[0m[0m | time: 19.448s
[2K
| Adam | epoch: 030 | loss: 0.01508 - acc: 0.9945 -- iter: 1056/1392
[A[ATraining Step: 1310  | total loss: [1m[32m0.01459[0m[0m | time: 20.043s
[2K
| Adam | epoch: 030 | loss: 0.01459 - acc: 0.9951 -- iter: 1088/1392
[A[ATraining Step: 1311  | total loss: [1m[32m0.01343[0m[0m | time: 20.647s
[2K
| Adam | epoch: 030 | loss: 0.01343 - acc: 0.9956 -- iter: 1120/1392
[A[ATraining Step: 1312  | total loss: [1m[32m0.01261[0m[0m | time: 21.249s
[2K
| Adam | epoch: 030 | loss: 0.01261 - acc: 0.9960 -- iter: 1152/1392
[A[ATraining Step: 1313  | total loss: [1m[32m0.01387[0m[0m | time: 21.846s
[2K
| Adam | epoch: 030 | loss: 0.01387 - acc: 0.9933 -- iter: 1184/1392
[A[ATraining Step: 1314  | total loss: [1m[32m0.01838[0m[0m | time: 22.448s
[2K
| Adam | epoch: 030 | loss: 0.01838 - acc: 0.9908 -- iter: 1216/1392
[A[ATraining Step: 1315  | total loss: [1m[32m0.01685[0m[0m | time: 23.043s
[2K
| Adam | epoch: 030 | loss: 0.01685 - acc: 0.9917 -- iter: 1248/1392
[A[ATraining Step: 1316  | total loss: [1m[32m0.01974[0m[0m | time: 23.647s
[2K
| Adam | epoch: 030 | loss: 0.01974 - acc: 0.9894 -- iter: 1280/1392
[A[ATraining Step: 1317  | total loss: [1m[32m0.01820[0m[0m | time: 24.238s
[2K
| Adam | epoch: 030 | loss: 0.01820 - acc: 0.9905 -- iter: 1312/1392
[A[ATraining Step: 1318  | total loss: [1m[32m0.07383[0m[0m | time: 24.829s
[2K
| Adam | epoch: 030 | loss: 0.07383 - acc: 0.9821 -- iter: 1344/1392
[A[ATraining Step: 1319  | total loss: [1m[32m0.06665[0m[0m | time: 25.439s
[2K
| Adam | epoch: 030 | loss: 0.06665 - acc: 0.9839 -- iter: 1376/1392
[A[ATraining Step: 1320  | total loss: [1m[32m0.06022[0m[0m | time: 27.401s
[2K
| Adam | epoch: 030 | loss: 0.06022 - acc: 0.9855 | val_loss: 1.14297 - val_acc: 0.7517 -- iter: 1392/1392
--
Validation AUC:0.8308801759505985
Validation AUPRC:0.8255817709703659
Test AUC:0.8624936300322744
Test AUPRC:0.858173464741506
BestTestF1Score	0.82	0.6	0.8	0.77	0.88	205	60	143	27	0.63
BestTestMCCScore	0.82	0.6	0.8	0.79	0.85	198	53	150	34	0.82
BestTestAccuracyScore	0.82	0.6	0.8	0.79	0.85	198	52	151	34	0.83
BestValidationF1Score	0.77	0.52	0.76	0.72	0.82	175	68	154	38	0.63
BestValidationMCC	0.76	0.52	0.76	0.73	0.8	170	62	160	43	0.82
BestValidationAccuracy	0.76	0.52	0.76	0.73	0.79	169	61	161	44	0.83
TestPredictions (Threshold:0.82)
CHEMBL139432,TP,ACT,0.9900000095367432	CHEMBL77142,FP,INACT,1.0	CHEMBL1201881,TP,ACT,0.8899999856948853	CHEMBL81643,TP,ACT,1.0	CHEMBL1824558,TN,INACT,0.0	CHEMBL78562,TN,INACT,0.0	CHEMBL2047998,FP,INACT,1.0	CHEMBL98472,TP,ACT,0.9900000095367432	CHEMBL120012,TN,INACT,0.10999999940395355	CHEMBL104157,TN,INACT,0.0	CHEMBL3585742,TN,INACT,0.0	CHEMBL295221,TP,ACT,0.949999988079071	CHEMBL470520,TN,INACT,0.0	CHEMBL436026,TP,ACT,0.9900000095367432	CHEMBL71058,TP,ACT,1.0	CHEMBL45407,TP,ACT,1.0	CHEMBL24780,FN,ACT,0.2199999988079071	CHEMBL305425,TP,ACT,1.0	CHEMBL433144,TP,ACT,1.0	CHEMBL112931,TP,ACT,0.9900000095367432	CHEMBL47074,TP,ACT,1.0	CHEMBL1563513,TN,INACT,0.0	CHEMBL91796,TP,ACT,1.0	CHEMBL328451,TP,ACT,1.0	CHEMBL238902,FP,INACT,1.0	CHEMBL151747,TP,ACT,1.0	CHEMBL3672877,TP,ACT,0.9900000095367432	CHEMBL160944,TP,ACT,1.0	CHEMBL599036,TN,INACT,0.0	CHEMBL320937,FP,INACT,0.9800000190734863	CHEMBL3423028,TN,INACT,0.019999999552965164	CHEMBL3216660,TP,ACT,1.0	CHEMBL44586,TP,ACT,1.0	CHEMBL41152,TP,ACT,1.0	CHEMBL3115903,TN,INACT,0.009999999776482582	CHEMBL1744048,FP,INACT,0.8700000047683716	CHEMBL41525,TN,INACT,0.0	CHEMBL2418042,TN,INACT,0.009999999776482582	CHEMBL3642881,TP,ACT,1.0	CHEMBL112197,TN,INACT,0.0	CHEMBL3642923,TP,ACT,1.0	CHEMBL211933,TN,INACT,0.1899999976158142	CHEMBL310682,TN,INACT,0.15000000596046448	CHEMBL92964,FP,INACT,1.0	CHEMBL3672850,TP,ACT,1.0	CHEMBL1432215,FP,INACT,0.9900000095367432	CHEMBL322901,TN,INACT,0.0	CHEMBL81844,TP,ACT,1.0	CHEMBL102216,TP,ACT,1.0	CHEMBL572040,FP,INACT,1.0	CHEMBL3667902,TP,ACT,1.0	CHEMBL107132,TN,INACT,0.0	CHEMBL3423011,FP,INACT,0.9599999785423279	CHEMBL438647,TN,INACT,0.0	CHEMBL75749,TN,INACT,0.3199999928474426	CHEMBL26896,TN,INACT,0.0	CHEMBL169291,TP,ACT,0.9700000286102295	CHEMBL466530,TN,INACT,0.0	CHEMBL2159304,FP,INACT,1.0	CHEMBL282260,TP,ACT,0.9700000286102295	CHEMBL557616,FP,INACT,0.9900000095367432	CHEMBL339878,FP,INACT,0.9599999785423279	CHEMBL319035,TN,INACT,0.0	CHEMBL135815,TN,INACT,0.029999999329447746	CHEMBL337799,TN,INACT,0.20000000298023224	CHEMBL143139,TP,ACT,0.9599999785423279	CHEMBL451066,TN,INACT,0.0	CHEMBL49757,FP,INACT,0.9800000190734863	CHEMBL81056,TP,ACT,1.0	CHEMBL37836,FN,ACT,0.14000000059604645	CHEMBL431396,TP,ACT,1.0	CHEMBL72514,TP,ACT,1.0	CHEMBL32280,TP,ACT,1.0	CHEMBL166236,FP,INACT,0.9900000095367432	CHEMBL162596,FN,ACT,0.0	CHEMBL64495,TN,INACT,0.0	CHEMBL415741,FN,ACT,0.05000000074505806	CHEMBL385899,FP,INACT,0.9800000190734863	CHEMBL45480,FN,ACT,0.11999999731779099	CHEMBL137311,TN,INACT,0.0	CHEMBL544222,FN,ACT,0.7699999809265137	CHEMBL3642919,TP,ACT,1.0	CHEMBL354555,TP,ACT,1.0	CHEMBL523865,TN,INACT,0.0	CHEMBL111660,TP,ACT,1.0	CHEMBL3667883,TP,ACT,1.0	CHEMBL172413,TP,ACT,0.9900000095367432	CHEMBL131876,TN,INACT,0.0	CHEMBL329460,TP,ACT,0.9900000095367432	CHEMBL2391039,TN,INACT,0.0	CHEMBL553840,TP,ACT,1.0	CHEMBL318363,TP,ACT,0.9900000095367432	CHEMBL92883,TP,ACT,1.0	CHEMBL155871,TP,ACT,1.0	CHEMBL2159305,TN,INACT,0.17000000178813934	CHEMBL3642863,TP,ACT,0.9900000095367432	CHEMBL3642962,TP,ACT,1.0	CHEMBL25073,TP,ACT,1.0	CHEMBL277905,TN,INACT,0.0	CHEMBL32752,TP,ACT,1.0	CHEMBL133328,TP,ACT,0.8700000047683716	CHEMBL438421,TN,INACT,0.0	CHEMBL318175,TN,INACT,0.3799999952316284	CHEMBL143138,TP,ACT,1.0	CHEMBL156043,TP,ACT,0.9900000095367432	CHEMBL3099871,TN,INACT,0.0	CHEMBL517269,TN,INACT,0.1899999976158142	CHEMBL1366764,TN,INACT,0.009999999776482582	CHEMBL25698,TP,ACT,1.0	CHEMBL157131,TP,ACT,1.0	CHEMBL2159283,TN,INACT,0.3700000047683716	CHEMBL179189,TN,INACT,0.0	CHEMBL262805,TN,INACT,0.0	CHEMBL297220,TN,INACT,0.20000000298023224	CHEMBL302046,TN,INACT,0.0	CHEMBL51173,FN,ACT,0.0	CHEMBL3134465,TN,INACT,0.0	CHEMBL421466,TP,ACT,1.0	CHEMBL406121,TN,INACT,0.0	CHEMBL3642886,TP,ACT,1.0	CHEMBL412487,TN,INACT,0.3700000047683716	CHEMBL46365,FN,ACT,0.009999999776482582	CHEMBL122796,TP,ACT,0.9599999785423279	CHEMBL3642861,TP,ACT,1.0	CHEMBL3642887,TP,ACT,1.0	CHEMBL295786,TN,INACT,0.009999999776482582	CHEMBL64202,TN,INACT,0.0	CHEMBL25351,TP,ACT,1.0	CHEMBL308074,FN,ACT,0.0	CHEMBL1733342,TN,INACT,0.10000000149011612	CHEMBL1256178,TN,INACT,0.0	CHEMBL319930,TP,ACT,1.0	CHEMBL3099874,TN,INACT,0.0	CHEMBL8079,TN,INACT,0.0	CHEMBL171354,FP,INACT,0.8999999761581421	CHEMBL33839,TP,ACT,1.0	CHEMBL315959,FP,INACT,1.0	CHEMBL378916,FP,INACT,0.9900000095367432	CHEMBL209974,TN,INACT,0.019999999552965164	CHEMBL2417910,TN,INACT,0.800000011920929	CHEMBL214356,FP,INACT,0.8799999952316284	CHEMBL523251,TN,INACT,0.0	CHEMBL34712,TN,INACT,0.0	CHEMBL81251,TP,ACT,1.0	CHEMBL167163,TP,ACT,0.9900000095367432	CHEMBL3672890,TP,ACT,1.0	CHEMBL353922,TP,ACT,0.9700000286102295	CHEMBL355466,TP,ACT,1.0	CHEMBL25477,TP,ACT,0.9900000095367432	CHEMBL3642929,TP,ACT,1.0	CHEMBL76796,TN,INACT,0.0	CHEMBL2373402,TP,ACT,1.0	CHEMBL32541,TP,ACT,1.0	CHEMBL159695,FN,ACT,0.3799999952316284	CHEMBL68737,TP,ACT,0.9800000190734863	CHEMBL79640,TP,ACT,1.0	CHEMBL402843,FP,INACT,1.0	CHEMBL227890,TN,INACT,0.0	CHEMBL1910421,TN,INACT,0.019999999552965164	CHEMBL276864,TN,INACT,0.0	CHEMBL422973,TN,INACT,0.1899999976158142	CHEMBL210189,TN,INACT,0.0	CHEMBL143008,TP,ACT,1.0	CHEMBL3642856,TP,ACT,1.0	CHEMBL3585744,TN,INACT,0.0	CHEMBL1744051,FP,INACT,1.0	CHEMBL3642859,TP,ACT,1.0	CHEMBL322345,TN,INACT,0.0	CHEMBL3642961,TP,ACT,1.0	CHEMBL63088,TP,ACT,0.9900000095367432	CHEMBL1392763,TN,INACT,0.0	CHEMBL287807,TN,INACT,0.0	CHEMBL129854,TP,ACT,0.9900000095367432	CHEMBL316311,TP,ACT,1.0	CHEMBL280158,TN,INACT,0.550000011920929	CHEMBL276880,TP,ACT,1.0	CHEMBL2373408,TP,ACT,1.0	CHEMBL163112,TP,ACT,1.0	CHEMBL320988,FN,ACT,0.09000000357627869	CHEMBL3667911,TP,ACT,0.9900000095367432	CHEMBL304219,TN,INACT,0.07000000029802322	CHEMBL350587,TP,ACT,1.0	CHEMBL2372722,TN,INACT,0.0	CHEMBL68431,TN,INACT,0.0	CHEMBL315550,TP,ACT,1.0	CHEMBL3642875,TP,ACT,1.0	CHEMBL286722,TN,INACT,0.8199999928474426	CHEMBL312479,TP,ACT,0.9900000095367432	CHEMBL566340,TN,INACT,0.009999999776482582	CHEMBL158063,FN,ACT,0.7599999904632568	CHEMBL10800,FN,ACT,0.009999999776482582	CHEMBL83549,FP,INACT,0.9100000262260437	CHEMBL553237,FP,INACT,0.9200000166893005	CHEMBL418839,TP,ACT,0.9399999976158142	CHEMBL93227,TP,ACT,1.0	CHEMBL159435,TN,INACT,0.009999999776482582	CHEMBL2371642,TN,INACT,0.0	CHEMBL43938,TN,INACT,0.0	CHEMBL3667889,TP,ACT,1.0	CHEMBL3642857,TP,ACT,0.9800000190734863	CHEMBL331909,TP,ACT,1.0	CHEMBL318112,TP,ACT,1.0	CHEMBL328772,TP,ACT,0.9599999785423279	CHEMBL164419,TP,ACT,1.0	CHEMBL2159374,TN,INACT,0.019999999552965164	CHEMBL147344,TP,ACT,0.9900000095367432	CHEMBL105395,TP,ACT,1.0	CHEMBL374524,TN,INACT,0.0	CHEMBL317590,TP,ACT,1.0	CHEMBL128443,TN,INACT,0.0	CHEMBL303908,TN,INACT,0.0	CHEMBL330206,FN,ACT,0.7200000286102295	CHEMBL3672888,TP,ACT,1.0	CHEMBL84127,FP,INACT,1.0	CHEMBL2159286,TN,INACT,0.0	CHEMBL2373397,TP,ACT,0.9200000166893005	CHEMBL24983,FP,INACT,0.9900000095367432	CHEMBL3238369,TN,INACT,0.0	CHEMBL498545,TN,INACT,0.0	CHEMBL212271,TN,INACT,0.0	CHEMBL606951,FN,ACT,0.0	CHEMBL94952,TP,ACT,1.0	CHEMBL93744,TP,ACT,1.0	CHEMBL331807,TP,ACT,1.0	CHEMBL144079,TN,INACT,0.0	CHEMBL162399,TP,ACT,1.0	CHEMBL2370338,TN,INACT,0.25999999046325684	CHEMBL3642965,TP,ACT,1.0	CHEMBL122435,TP,ACT,0.9900000095367432	CHEMBL500330,TN,INACT,0.009999999776482582	CHEMBL3642979,TP,ACT,1.0	CHEMBL216829,TN,INACT,0.6899999976158142	CHEMBL281719,TN,INACT,0.0	CHEMBL558275,TN,INACT,0.0	CHEMBL328805,TP,ACT,1.0	CHEMBL330572,TP,ACT,1.0	CHEMBL3642903,TP,ACT,1.0	CHEMBL323963,TP,ACT,0.9800000190734863	CHEMBL99262,TP,ACT,1.0	CHEMBL330234,TP,ACT,0.9800000190734863	CHEMBL3780437,FP,INACT,0.9800000190734863	CHEMBL111471,TP,ACT,1.0	CHEMBL50649,TP,ACT,1.0	CHEMBL3672864,FN,ACT,0.0	CHEMBL606957,FN,ACT,0.8100000023841858	CHEMBL24460,TP,ACT,0.949999988079071	CHEMBL3642954,TP,ACT,1.0	CHEMBL44113,TP,ACT,1.0	CHEMBL3667895,TP,ACT,1.0	CHEMBL2040959,TN,INACT,0.0	CHEMBL2373345,FN,ACT,0.029999999329447746	CHEMBL377956,FP,INACT,0.8600000143051147	CHEMBL3642951,FN,ACT,0.5199999809265137	CHEMBL342621,TN,INACT,0.7400000095367432	CHEMBL106718,TN,INACT,0.12999999523162842	CHEMBL32881,TP,ACT,1.0	CHEMBL136215,TP,ACT,1.0	CHEMBL25063,TP,ACT,0.9900000095367432	CHEMBL164138,FN,ACT,0.0	CHEMBL350280,TN,INACT,0.15000000596046448	CHEMBL452174,FP,INACT,1.0	CHEMBL176355,FP,INACT,0.9700000286102295	CHEMBL323544,TP,ACT,0.9900000095367432	CHEMBL41359,TN,INACT,0.2199999988079071	CHEMBL379357,FP,INACT,0.8700000047683716	CHEMBL41267,TP,ACT,1.0	CHEMBL302913,TN,INACT,0.0	CHEMBL212852,TN,INACT,0.0	CHEMBL61933,FP,INACT,0.9300000071525574	CHEMBL158405,TP,ACT,0.9700000286102295	CHEMBL1464645,TN,INACT,0.0	CHEMBL138709,TP,ACT,1.0	CHEMBL2315243,TP,ACT,1.0	CHEMBL27008,TP,ACT,1.0	CHEMBL3216426,TP,ACT,1.0	CHEMBL25699,TN,INACT,0.7900000214576721	CHEMBL3642880,TP,ACT,1.0	CHEMBL1160791,TP,ACT,1.0	CHEMBL3642928,TP,ACT,1.0	CHEMBL308600,FP,INACT,1.0	CHEMBL77742,TN,INACT,0.3100000023841858	CHEMBL153607,FP,INACT,1.0	CHEMBL175333,FN,ACT,0.0	CHEMBL290212,TP,ACT,1.0	CHEMBL308376,TN,INACT,0.75	CHEMBL158814,TP,ACT,0.9900000095367432	CHEMBL372108,FP,INACT,0.9800000190734863	CHEMBL3642860,TP,ACT,1.0	CHEMBL164376,TP,ACT,0.9900000095367432	CHEMBL42039,TN,INACT,0.0	CHEMBL2373559,TP,ACT,1.0	CHEMBL290363,TP,ACT,0.9700000286102295	CHEMBL316820,TN,INACT,0.2199999988079071	CHEMBL104305,TP,ACT,0.9800000190734863	CHEMBL265304,TP,ACT,0.9700000286102295	CHEMBL99622,TP,ACT,0.9900000095367432	CHEMBL215556,TN,INACT,0.7900000214576721	CHEMBL323304,TN,INACT,0.0	CHEMBL3672862,TP,ACT,1.0	CHEMBL148957,TP,ACT,0.9800000190734863	CHEMBL211549,FP,INACT,1.0	CHEMBL2372702,TN,INACT,0.0	CHEMBL424545,TP,ACT,0.9900000095367432	CHEMBL3143639,TN,INACT,0.0	CHEMBL424630,FP,INACT,0.9900000095367432	CHEMBL445678,TP,ACT,1.0	CHEMBL28968,TP,ACT,1.0	CHEMBL3672863,FN,ACT,0.009999999776482582	CHEMBL133326,TP,ACT,0.9800000190734863	CHEMBL122894,TP,ACT,1.0	CHEMBL3672891,TP,ACT,1.0	CHEMBL3423009,TN,INACT,0.0	CHEMBL41876,TN,INACT,0.0	CHEMBL3642947,TP,ACT,1.0	CHEMBL309403,TP,ACT,0.9900000095367432	CHEMBL7124,TN,INACT,0.10999999940395355	CHEMBL1744052,TN,INACT,0.27000001072883606	CHEMBL156765,TP,ACT,1.0	CHEMBL290025,TN,INACT,0.0	CHEMBL3330470,TN,INACT,0.4099999964237213	CHEMBL3642926,TP,ACT,0.9900000095367432	CHEMBL292977,TN,INACT,0.15000000596046448	CHEMBL424260,TP,ACT,0.9900000095367432	CHEMBL296041,TN,INACT,0.009999999776482582	CHEMBL317076,FN,ACT,0.23000000417232513	CHEMBL151939,FN,ACT,0.019999999552965164	CHEMBL421136,TP,ACT,0.9900000095367432	CHEMBL554825,FP,INACT,1.0	CHEMBL289147,TP,ACT,1.0	CHEMBL364422,TN,INACT,0.0	CHEMBL3109162,TN,INACT,0.009999999776482582	CHEMBL3642892,TP,ACT,1.0	CHEMBL314576,TP,ACT,1.0	CHEMBL1812011,TN,INACT,0.009999999776482582	CHEMBL134821,FN,ACT,0.6600000262260437	CHEMBL297536,TP,ACT,0.9900000095367432	CHEMBL320407,FP,INACT,1.0	CHEMBL17712,FP,INACT,0.949999988079071	CHEMBL175779,TN,INACT,0.009999999776482582	CHEMBL3672884,TP,ACT,0.9900000095367432	CHEMBL111567,TP,ACT,1.0	CHEMBL109044,TN,INACT,0.009999999776482582	CHEMBL141106,TP,ACT,1.0	CHEMBL93536,TP,ACT,1.0	CHEMBL47486,FP,INACT,1.0	CHEMBL81846,TP,ACT,1.0	CHEMBL319206,TP,ACT,1.0	CHEMBL104241,TN,INACT,0.0	CHEMBL256396,FN,ACT,0.0	CHEMBL422533,FN,ACT,0.15000000596046448	CHEMBL328298,TP,ACT,1.0	CHEMBL84389,TP,ACT,1.0	CHEMBL293590,TN,INACT,0.0	CHEMBL104211,TP,ACT,0.9700000286102295	CHEMBL416912,TP,ACT,1.0	CHEMBL417409,FP,INACT,0.9800000190734863	CHEMBL2375178,TP,ACT,1.0	CHEMBL319264,FN,ACT,0.0	CHEMBL358387,TN,INACT,0.009999999776482582	CHEMBL62288,TP,ACT,1.0	CHEMBL599626,FP,INACT,0.9900000095367432	CHEMBL2159291,FP,INACT,0.8299999833106995	CHEMBL393873,TN,INACT,0.0	CHEMBL327789,FN,ACT,0.75	CHEMBL3251529,TN,INACT,0.0	CHEMBL320393,TN,INACT,0.0	CHEMBL466529,TN,INACT,0.0	CHEMBL53848,FN,ACT,0.009999999776482582	CHEMBL3238378,TN,INACT,0.029999999329447746	CHEMBL420682,TP,ACT,1.0	CHEMBL24012,TP,ACT,1.0	CHEMBL330460,TN,INACT,0.07000000029802322	CHEMBL312904,FN,ACT,0.0	CHEMBL501749,TN,INACT,0.0	CHEMBL95097,TP,ACT,1.0	CHEMBL312647,TP,ACT,0.9800000190734863	CHEMBL61791,TN,INACT,0.0	CHEMBL3664011,TN,INACT,0.07999999821186066	CHEMBL1612826,TN,INACT,0.019999999552965164	CHEMBL342604,TN,INACT,0.0	CHEMBL3642921,TP,ACT,1.0	CHEMBL3251533,FP,INACT,0.9900000095367432	CHEMBL486112,TN,INACT,0.0	CHEMBL172147,TP,ACT,1.0	CHEMBL219354,FP,INACT,1.0	CHEMBL38054,TN,INACT,0.0	CHEMBL287136,TN,INACT,0.0	CHEMBL138855,TP,ACT,1.0	CHEMBL2441052,TN,INACT,0.0	CHEMBL37318,TP,ACT,0.9399999976158142	CHEMBL3423052,TN,INACT,0.0	CHEMBL322437,TN,INACT,0.0	CHEMBL316349,TP,ACT,1.0	CHEMBL296764,FN,ACT,0.30000001192092896	CHEMBL3642967,TP,ACT,1.0	CHEMBL3642939,TP,ACT,1.0	CHEMBL418965,TP,ACT,1.0	CHEMBL414832,TP,ACT,1.0	CHEMBL3642914,TP,ACT,1.0	CHEMBL507281,TN,INACT,0.0	CHEMBL109535,TP,ACT,1.0	CHEMBL3642901,TP,ACT,1.0	CHEMBL308778,TP,ACT,1.0	CHEMBL298256,TN,INACT,0.009999999776482582	CHEMBL214814,FP,INACT,0.9700000286102295	CHEMBL2159392,FP,INACT,0.9900000095367432	CHEMBL227976,TN,INACT,0.0	CHEMBL283570,TN,INACT,0.009999999776482582	CHEMBL377737,TN,INACT,0.009999999776482582	CHEMBL211939,TN,INACT,0.0	CHEMBL330244,TP,ACT,0.9599999785423279	CHEMBL3244501,FP,INACT,0.9700000286102295	CHEMBL174702,FN,ACT,0.6899999976158142	CHEMBL85154,TP,ACT,1.0	CHEMBL344305,TN,INACT,0.2800000011920929	CHEMBL329568,TP,ACT,1.0	CHEMBL3672873,TP,ACT,0.9900000095367432	CHEMBL155820,TP,ACT,1.0	CHEMBL3668694,TN,INACT,0.03999999910593033	CHEMBL156858,TP,ACT,1.0	CHEMBL191881,TN,INACT,0.2800000011920929	CHEMBL101726,FP,INACT,1.0	CHEMBL3084836,TP,ACT,1.0	CHEMBL99630,TP,ACT,0.9900000095367432	CHEMBL92277,TP,ACT,0.9399999976158142	CHEMBL2425137,FP,INACT,0.9900000095367432	CHEMBL433911,TP,ACT,0.9900000095367432	CHEMBL1335846,FP,INACT,1.0	CHEMBL117266,FP,INACT,0.9900000095367432	CHEMBL543893,TN,INACT,0.0	CHEMBL286915,TP,ACT,1.0	CHEMBL147436,TN,INACT,0.0	CHEMBL3143648,TN,INACT,0.009999999776482582	CHEMBL327254,FP,INACT,0.9700000286102295	CHEMBL433135,FN,ACT,0.0	

