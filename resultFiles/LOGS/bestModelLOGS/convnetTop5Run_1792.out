ImageNetInceptionV2 CHEMBL4835 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	134
Number of inactive compounds :	134
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4835_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4835_adam_0.0005_30_0.8/
---------------------------------
Training samples: 171
Validation samples: 54
--
Training Step: 1  | time: 42.582s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/171
[A[ATraining Step: 2  | total loss: [1m[32m0.65133[0m[0m | time: 51.893s
[2K
| Adam | epoch: 001 | loss: 0.65133 - acc: 0.3656 -- iter: 064/171
[A[ATraining Step: 3  | total loss: [1m[32m0.59173[0m[0m | time: 61.187s
[2K
| Adam | epoch: 001 | loss: 0.59173 - acc: 0.6034 -- iter: 096/171
[A[ATraining Step: 4  | total loss: [1m[32m0.74517[0m[0m | time: 69.275s
[2K
| Adam | epoch: 001 | loss: 0.74517 - acc: 0.6196 -- iter: 128/171
[A[ATraining Step: 5  | total loss: [1m[32m0.71966[0m[0m | time: 76.944s
[2K
| Adam | epoch: 001 | loss: 0.71966 - acc: 0.6233 -- iter: 160/171
[A[ATraining Step: 6  | total loss: [1m[32m0.58713[0m[0m | time: 88.599s
[2K
| Adam | epoch: 001 | loss: 0.58713 - acc: 0.7449 | val_loss: 0.94825 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 7  | total loss: [1m[32m0.70509[0m[0m | time: 3.356s
[2K
| Adam | epoch: 002 | loss: 0.70509 - acc: 0.6798 -- iter: 032/171
[A[ATraining Step: 8  | total loss: [1m[32m0.47082[0m[0m | time: 11.110s
[2K
| Adam | epoch: 002 | loss: 0.47082 - acc: 0.8088 -- iter: 064/171
[A[ATraining Step: 9  | total loss: [1m[32m0.57197[0m[0m | time: 18.868s
[2K
| Adam | epoch: 002 | loss: 0.57197 - acc: 0.6784 -- iter: 096/171
[A[ATraining Step: 10  | total loss: [1m[32m0.51492[0m[0m | time: 26.786s
[2K
| Adam | epoch: 002 | loss: 0.51492 - acc: 0.7611 -- iter: 128/171
[A[ATraining Step: 11  | total loss: [1m[32m0.43907[0m[0m | time: 34.576s
[2K
| Adam | epoch: 002 | loss: 0.43907 - acc: 0.8150 -- iter: 160/171
[A[ATraining Step: 12  | total loss: [1m[32m0.46914[0m[0m | time: 44.898s
[2K
| Adam | epoch: 002 | loss: 0.46914 - acc: 0.7717 | val_loss: 0.89928 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 13  | total loss: [1m[32m0.34906[0m[0m | time: 3.379s
[2K
| Adam | epoch: 003 | loss: 0.34906 - acc: 0.8428 -- iter: 032/171
[A[ATraining Step: 14  | total loss: [1m[32m0.23789[0m[0m | time: 6.744s
[2K
| Adam | epoch: 003 | loss: 0.23789 - acc: 0.9071 -- iter: 064/171
[A[ATraining Step: 15  | total loss: [1m[32m0.15089[0m[0m | time: 14.706s
[2K
| Adam | epoch: 003 | loss: 0.15089 - acc: 0.9434 -- iter: 096/171
[A[ATraining Step: 16  | total loss: [1m[32m0.29724[0m[0m | time: 22.511s
[2K
| Adam | epoch: 003 | loss: 0.29724 - acc: 0.8826 -- iter: 128/171
[A[ATraining Step: 17  | total loss: [1m[32m0.40445[0m[0m | time: 30.360s
[2K
| Adam | epoch: 003 | loss: 0.40445 - acc: 0.8686 -- iter: 160/171
[A[ATraining Step: 18  | total loss: [1m[32m0.36964[0m[0m | time: 40.681s
[2K
| Adam | epoch: 003 | loss: 0.36964 - acc: 0.8708 | val_loss: 1.03115 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 19  | total loss: [1m[32m0.28545[0m[0m | time: 7.890s
[2K
| Adam | epoch: 004 | loss: 0.28545 - acc: 0.9035 -- iter: 032/171
[A[ATraining Step: 20  | total loss: [1m[32m0.23646[0m[0m | time: 11.217s
[2K
| Adam | epoch: 004 | loss: 0.23646 - acc: 0.9044 -- iter: 064/171
[A[ATraining Step: 21  | total loss: [1m[32m0.22322[0m[0m | time: 14.594s
[2K
| Adam | epoch: 004 | loss: 0.22322 - acc: 0.9058 -- iter: 096/171
[A[ATraining Step: 22  | total loss: [1m[32m0.16391[0m[0m | time: 22.543s
[2K
| Adam | epoch: 004 | loss: 0.16391 - acc: 0.9341 -- iter: 128/171
[A[ATraining Step: 23  | total loss: [1m[32m0.26768[0m[0m | time: 30.553s
[2K
| Adam | epoch: 004 | loss: 0.26768 - acc: 0.8897 -- iter: 160/171
[A[ATraining Step: 24  | total loss: [1m[32m0.24857[0m[0m | time: 40.912s
[2K
| Adam | epoch: 004 | loss: 0.24857 - acc: 0.9119 | val_loss: 3.90281 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 25  | total loss: [1m[32m0.24555[0m[0m | time: 7.900s
[2K
| Adam | epoch: 005 | loss: 0.24555 - acc: 0.9104 -- iter: 032/171
[A[ATraining Step: 26  | total loss: [1m[32m0.28079[0m[0m | time: 15.601s
[2K
| Adam | epoch: 005 | loss: 0.28079 - acc: 0.8762 -- iter: 064/171
[A[ATraining Step: 27  | total loss: [1m[32m0.25917[0m[0m | time: 18.915s
[2K
| Adam | epoch: 005 | loss: 0.25917 - acc: 0.9000 -- iter: 096/171
[A[ATraining Step: 28  | total loss: [1m[32m0.25217[0m[0m | time: 22.270s
[2K
| Adam | epoch: 005 | loss: 0.25217 - acc: 0.9023 -- iter: 128/171
[A[ATraining Step: 29  | total loss: [1m[32m0.19737[0m[0m | time: 30.113s
[2K
| Adam | epoch: 005 | loss: 0.19737 - acc: 0.9260 -- iter: 160/171
[A[ATraining Step: 30  | total loss: [1m[32m0.19712[0m[0m | time: 40.422s
[2K
| Adam | epoch: 005 | loss: 0.19712 - acc: 0.9214 | val_loss: 3.09598 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 31  | total loss: [1m[32m0.27395[0m[0m | time: 7.719s
[2K
| Adam | epoch: 006 | loss: 0.27395 - acc: 0.9034 -- iter: 032/171
[A[ATraining Step: 32  | total loss: [1m[32m0.23087[0m[0m | time: 15.624s
[2K
| Adam | epoch: 006 | loss: 0.23087 - acc: 0.9111 -- iter: 064/171
[A[ATraining Step: 33  | total loss: [1m[32m0.21299[0m[0m | time: 23.438s
[2K
| Adam | epoch: 006 | loss: 0.21299 - acc: 0.9100 -- iter: 096/171
[A[ATraining Step: 34  | total loss: [1m[32m0.21518[0m[0m | time: 26.792s
[2K
| Adam | epoch: 006 | loss: 0.21518 - acc: 0.9159 -- iter: 128/171
[A[ATraining Step: 35  | total loss: [1m[32m0.20094[0m[0m | time: 30.062s
[2K
| Adam | epoch: 006 | loss: 0.20094 - acc: 0.9145 -- iter: 160/171
[A[ATraining Step: 36  | total loss: [1m[32m0.16506[0m[0m | time: 40.260s
[2K
| Adam | epoch: 006 | loss: 0.16506 - acc: 0.9320 | val_loss: 3.11442 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 37  | total loss: [1m[32m0.15288[0m[0m | time: 7.932s
[2K
| Adam | epoch: 007 | loss: 0.15288 - acc: 0.9331 -- iter: 032/171
[A[ATraining Step: 38  | total loss: [1m[32m0.17561[0m[0m | time: 15.754s
[2K
| Adam | epoch: 007 | loss: 0.17561 - acc: 0.9401 -- iter: 064/171
[A[ATraining Step: 39  | total loss: [1m[32m0.14762[0m[0m | time: 23.653s
[2K
| Adam | epoch: 007 | loss: 0.14762 - acc: 0.9515 -- iter: 096/171
[A[ATraining Step: 40  | total loss: [1m[32m0.12829[0m[0m | time: 31.386s
[2K
| Adam | epoch: 007 | loss: 0.12829 - acc: 0.9606 -- iter: 128/171
[A[ATraining Step: 41  | total loss: [1m[32m0.10838[0m[0m | time: 34.749s
[2K
| Adam | epoch: 007 | loss: 0.10838 - acc: 0.9679 -- iter: 160/171
[A[ATraining Step: 42  | total loss: [1m[32m0.10142[0m[0m | time: 40.442s
[2K
| Adam | epoch: 007 | loss: 0.10142 - acc: 0.9736 | val_loss: 2.46569 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 43  | total loss: [1m[32m0.08705[0m[0m | time: 7.777s
[2K
| Adam | epoch: 008 | loss: 0.08705 - acc: 0.9783 -- iter: 032/171
[A[ATraining Step: 44  | total loss: [1m[32m0.11573[0m[0m | time: 15.687s
[2K
| Adam | epoch: 008 | loss: 0.11573 - acc: 0.9712 -- iter: 064/171
[A[ATraining Step: 45  | total loss: [1m[32m0.13096[0m[0m | time: 23.491s
[2K
| Adam | epoch: 008 | loss: 0.13096 - acc: 0.9708 -- iter: 096/171
[A[ATraining Step: 46  | total loss: [1m[32m0.11069[0m[0m | time: 31.396s
[2K
| Adam | epoch: 008 | loss: 0.11069 - acc: 0.9757 -- iter: 128/171
[A[ATraining Step: 47  | total loss: [1m[32m0.10456[0m[0m | time: 39.179s
[2K
| Adam | epoch: 008 | loss: 0.10456 - acc: 0.9745 -- iter: 160/171
[A[ATraining Step: 48  | total loss: [1m[32m0.10477[0m[0m | time: 44.777s
[2K
| Adam | epoch: 008 | loss: 0.10477 - acc: 0.9636 | val_loss: 2.73048 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 49  | total loss: [1m[32m0.14488[0m[0m | time: 3.300s
[2K
| Adam | epoch: 009 | loss: 0.14488 - acc: 0.9550 -- iter: 032/171
[A[ATraining Step: 50  | total loss: [1m[32m0.13627[0m[0m | time: 11.081s
[2K
| Adam | epoch: 009 | loss: 0.13627 - acc: 0.9620 -- iter: 064/171
[A[ATraining Step: 51  | total loss: [1m[32m0.14224[0m[0m | time: 18.822s
[2K
| Adam | epoch: 009 | loss: 0.14224 - acc: 0.9582 -- iter: 096/171
[A[ATraining Step: 52  | total loss: [1m[32m0.15462[0m[0m | time: 26.463s
[2K
| Adam | epoch: 009 | loss: 0.15462 - acc: 0.9504 -- iter: 128/171
[A[ATraining Step: 53  | total loss: [1m[32m0.19867[0m[0m | time: 34.360s
[2K
| Adam | epoch: 009 | loss: 0.19867 - acc: 0.9347 -- iter: 160/171
[A[ATraining Step: 54  | total loss: [1m[32m0.17264[0m[0m | time: 44.483s
[2K
| Adam | epoch: 009 | loss: 0.17264 - acc: 0.9442 | val_loss: 0.61785 - val_acc: 0.7222 -- iter: 171/171
--
Training Step: 55  | total loss: [1m[32m0.17296[0m[0m | time: 3.346s
[2K
| Adam | epoch: 010 | loss: 0.17296 - acc: 0.9432 -- iter: 032/171
[A[ATraining Step: 56  | total loss: [1m[32m0.15157[0m[0m | time: 6.629s
[2K
| Adam | epoch: 010 | loss: 0.15157 - acc: 0.9512 -- iter: 064/171
[A[ATraining Step: 57  | total loss: [1m[32m0.13283[0m[0m | time: 14.381s
[2K
| Adam | epoch: 010 | loss: 0.13283 - acc: 0.9580 -- iter: 096/171
[A[ATraining Step: 58  | total loss: [1m[32m0.12462[0m[0m | time: 22.440s
[2K
| Adam | epoch: 010 | loss: 0.12462 - acc: 0.9594 -- iter: 128/171
[A[ATraining Step: 59  | total loss: [1m[32m0.11705[0m[0m | time: 30.487s
[2K
| Adam | epoch: 010 | loss: 0.11705 - acc: 0.9565 -- iter: 160/171
[A[ATraining Step: 60  | total loss: [1m[32m0.12988[0m[0m | time: 40.939s
[2K
| Adam | epoch: 010 | loss: 0.12988 - acc: 0.9540 | val_loss: 0.80574 - val_acc: 0.7222 -- iter: 171/171
--
Training Step: 61  | total loss: [1m[32m0.11925[0m[0m | time: 8.040s
[2K
| Adam | epoch: 011 | loss: 0.11925 - acc: 0.9600 -- iter: 032/171
[A[ATraining Step: 62  | total loss: [1m[32m0.10660[0m[0m | time: 11.271s
[2K
| Adam | epoch: 011 | loss: 0.10660 - acc: 0.9651 -- iter: 064/171
[A[ATraining Step: 63  | total loss: [1m[32m0.09537[0m[0m | time: 14.601s
[2K
| Adam | epoch: 011 | loss: 0.09537 - acc: 0.9695 -- iter: 096/171
[A[ATraining Step: 64  | total loss: [1m[32m0.08468[0m[0m | time: 22.578s
[2K
| Adam | epoch: 011 | loss: 0.08468 - acc: 0.9733 -- iter: 128/171
[A[ATraining Step: 65  | total loss: [1m[32m0.07888[0m[0m | time: 30.557s
[2K
| Adam | epoch: 011 | loss: 0.07888 - acc: 0.9766 -- iter: 160/171
[A[ATraining Step: 66  | total loss: [1m[32m0.10768[0m[0m | time: 41.019s
[2K
| Adam | epoch: 011 | loss: 0.10768 - acc: 0.9719 | val_loss: 0.69019 - val_acc: 0.7778 -- iter: 171/171
--
Training Step: 67  | total loss: [1m[32m0.10075[0m[0m | time: 8.128s
[2K
| Adam | epoch: 012 | loss: 0.10075 - acc: 0.9753 -- iter: 032/171
[A[ATraining Step: 68  | total loss: [1m[32m0.10143[0m[0m | time: 15.962s
[2K
| Adam | epoch: 012 | loss: 0.10143 - acc: 0.9708 -- iter: 064/171
[A[ATraining Step: 69  | total loss: [1m[32m0.09296[0m[0m | time: 19.301s
[2K
| Adam | epoch: 012 | loss: 0.09296 - acc: 0.9742 -- iter: 096/171
[A[ATraining Step: 70  | total loss: [1m[32m0.09463[0m[0m | time: 22.610s
[2K
| Adam | epoch: 012 | loss: 0.09463 - acc: 0.9772 -- iter: 128/171
[A[ATraining Step: 71  | total loss: [1m[32m0.08842[0m[0m | time: 30.668s
[2K
| Adam | epoch: 012 | loss: 0.08842 - acc: 0.9798 -- iter: 160/171
[A[ATraining Step: 72  | total loss: [1m[32m0.09888[0m[0m | time: 41.123s
[2K
| Adam | epoch: 012 | loss: 0.09888 - acc: 0.9785 | val_loss: 0.99515 - val_acc: 0.7593 -- iter: 171/171
--
Training Step: 73  | total loss: [1m[32m0.11476[0m[0m | time: 7.931s
[2K
| Adam | epoch: 013 | loss: 0.11476 - acc: 0.9740 -- iter: 032/171
[A[ATraining Step: 74  | total loss: [1m[32m0.10438[0m[0m | time: 15.559s
[2K
| Adam | epoch: 013 | loss: 0.10438 - acc: 0.9768 -- iter: 064/171
[A[ATraining Step: 75  | total loss: [1m[32m0.09649[0m[0m | time: 23.726s
[2K
| Adam | epoch: 013 | loss: 0.09649 - acc: 0.9793 -- iter: 096/171
[A[ATraining Step: 76  | total loss: [1m[32m0.10546[0m[0m | time: 27.007s
[2K
| Adam | epoch: 013 | loss: 0.10546 - acc: 0.9715 -- iter: 128/171
[A[ATraining Step: 77  | total loss: [1m[32m0.12646[0m[0m | time: 30.270s
[2K
| Adam | epoch: 013 | loss: 0.12646 - acc: 0.9649 -- iter: 160/171
[A[ATraining Step: 78  | total loss: [1m[32m0.12499[0m[0m | time: 40.768s
[2K
| Adam | epoch: 013 | loss: 0.12499 - acc: 0.9686 | val_loss: 0.99687 - val_acc: 0.7407 -- iter: 171/171
--
Training Step: 79  | total loss: [1m[32m0.12187[0m[0m | time: 8.179s
[2K
| Adam | epoch: 014 | loss: 0.12187 - acc: 0.9621 -- iter: 032/171
[A[ATraining Step: 80  | total loss: [1m[32m0.14933[0m[0m | time: 15.978s
[2K
| Adam | epoch: 014 | loss: 0.14933 - acc: 0.9532 -- iter: 064/171
[A[ATraining Step: 81  | total loss: [1m[32m0.13635[0m[0m | time: 24.091s
[2K
| Adam | epoch: 014 | loss: 0.13635 - acc: 0.9579 -- iter: 096/171
[A[ATraining Step: 82  | total loss: [1m[32m0.12679[0m[0m | time: 32.269s
[2K
| Adam | epoch: 014 | loss: 0.12679 - acc: 0.9622 -- iter: 128/171
[A[ATraining Step: 83  | total loss: [1m[32m0.11718[0m[0m | time: 35.543s
[2K
| Adam | epoch: 014 | loss: 0.11718 - acc: 0.9659 -- iter: 160/171
[A[ATraining Step: 84  | total loss: [1m[32m0.10630[0m[0m | time: 41.689s
[2K
| Adam | epoch: 014 | loss: 0.10630 - acc: 0.9693 | val_loss: 5.10547 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 85  | total loss: [1m[32m0.09646[0m[0m | time: 8.122s
[2K
| Adam | epoch: 015 | loss: 0.09646 - acc: 0.9724 -- iter: 032/171
[A[ATraining Step: 86  | total loss: [1m[32m0.09263[0m[0m | time: 16.382s
[2K
| Adam | epoch: 015 | loss: 0.09263 - acc: 0.9752 -- iter: 064/171
[A[ATraining Step: 87  | total loss: [1m[32m0.10070[0m[0m | time: 24.439s
[2K
| Adam | epoch: 015 | loss: 0.10070 - acc: 0.9683 -- iter: 096/171
[A[ATraining Step: 88  | total loss: [1m[32m0.10848[0m[0m | time: 33.328s
[2K
| Adam | epoch: 015 | loss: 0.10848 - acc: 0.9683 -- iter: 128/171
[A[ATraining Step: 89  | total loss: [1m[32m0.09815[0m[0m | time: 43.177s
[2K
| Adam | epoch: 015 | loss: 0.09815 - acc: 0.9715 -- iter: 160/171
[A[ATraining Step: 90  | total loss: [1m[32m0.09206[0m[0m | time: 48.906s
[2K
| Adam | epoch: 015 | loss: 0.09206 - acc: 0.9743 | val_loss: 1.28128 - val_acc: 0.7407 -- iter: 171/171
--
Training Step: 91  | total loss: [1m[32m0.08391[0m[0m | time: 3.393s
[2K
| Adam | epoch: 016 | loss: 0.08391 - acc: 0.9769 -- iter: 032/171
[A[ATraining Step: 92  | total loss: [1m[32m0.07631[0m[0m | time: 162.485s
[2K
| Adam | epoch: 016 | loss: 0.07631 - acc: 0.9792 -- iter: 064/171
[A[ATraining Step: 93  | total loss: [1m[32m0.11797[0m[0m | time: 258.407s
[2K
| Adam | epoch: 016 | loss: 0.11797 - acc: 0.9688 -- iter: 096/171
[A[ATraining Step: 94  | total loss: [1m[32m0.15988[0m[0m | time: 375.970s
[2K
| Adam | epoch: 016 | loss: 0.15988 - acc: 0.9563 -- iter: 128/171
[A[ATraining Step: 95  | total loss: [1m[32m0.15384[0m[0m | time: 574.177s
[2K
| Adam | epoch: 016 | loss: 0.15384 - acc: 0.9544 -- iter: 160/171
[A[ATraining Step: 96  | total loss: [1m[32m0.14612[0m[0m | time: 652.512s
[2K
| Adam | epoch: 016 | loss: 0.14612 - acc: 0.9558 | val_loss: 0.92412 - val_acc: 0.7037 -- iter: 171/171
--
Training Step: 97  | total loss: [1m[32m0.13513[0m[0m | time: 3.610s
[2K
| Adam | epoch: 017 | loss: 0.13513 - acc: 0.9603 -- iter: 032/171
[A[ATraining Step: 98  | total loss: [1m[32m0.16649[0m[0m | time: 7.005s
[2K
| Adam | epoch: 017 | loss: 0.16649 - acc: 0.9461 -- iter: 064/171
[A[ATraining Step: 99  | total loss: [1m[32m0.17872[0m[0m | time: 15.600s
[2K
| Adam | epoch: 017 | loss: 0.17872 - acc: 0.9424 -- iter: 096/171
[A[ATraining Step: 100  | total loss: [1m[32m0.17144[0m[0m | time: 24.124s
[2K
| Adam | epoch: 017 | loss: 0.17144 - acc: 0.9450 -- iter: 128/171
[A[ATraining Step: 101  | total loss: [1m[32m0.16886[0m[0m | time: 32.708s
[2K
| Adam | epoch: 017 | loss: 0.16886 - acc: 0.9474 -- iter: 160/171
[A[ATraining Step: 102  | total loss: [1m[32m0.15477[0m[0m | time: 43.876s
[2K
| Adam | epoch: 017 | loss: 0.15477 - acc: 0.9526 | val_loss: 4.10150 - val_acc: 0.4444 -- iter: 171/171
--
Training Step: 103  | total loss: [1m[32m0.14976[0m[0m | time: 8.382s
[2K
| Adam | epoch: 018 | loss: 0.14976 - acc: 0.9542 -- iter: 032/171
[A[ATraining Step: 104  | total loss: [1m[32m0.13999[0m[0m | time: 11.771s
[2K
| Adam | epoch: 018 | loss: 0.13999 - acc: 0.9588 -- iter: 064/171
[A[ATraining Step: 105  | total loss: [1m[32m0.12976[0m[0m | time: 15.201s
[2K
| Adam | epoch: 018 | loss: 0.12976 - acc: 0.9629 -- iter: 096/171
[A[ATraining Step: 106  | total loss: [1m[32m0.12005[0m[0m | time: 23.555s
[2K
| Adam | epoch: 018 | loss: 0.12005 - acc: 0.9666 -- iter: 128/171
[A[ATraining Step: 107  | total loss: [1m[32m0.12076[0m[0m | time: 32.341s
[2K
| Adam | epoch: 018 | loss: 0.12076 - acc: 0.9637 -- iter: 160/171
[A[ATraining Step: 108  | total loss: [1m[32m0.11435[0m[0m | time: 43.962s
[2K
| Adam | epoch: 018 | loss: 0.11435 - acc: 0.9674 | val_loss: 0.95891 - val_acc: 0.6667 -- iter: 171/171
--
Training Step: 109  | total loss: [1m[32m0.10547[0m[0m | time: 8.356s
[2K
| Adam | epoch: 019 | loss: 0.10547 - acc: 0.9706 -- iter: 032/171
[A[ATraining Step: 110  | total loss: [1m[32m0.10873[0m[0m | time: 151.861s
[2K
| Adam | epoch: 019 | loss: 0.10873 - acc: 0.9673 -- iter: 064/171
[A[ATraining Step: 111  | total loss: [1m[32m0.09963[0m[0m | time: 155.413s
[2K
| Adam | epoch: 019 | loss: 0.09963 - acc: 0.9706 -- iter: 096/171
[A[ATraining Step: 112  | total loss: [1m[32m0.09090[0m[0m | time: 158.794s
[2K
| Adam | epoch: 019 | loss: 0.09090 - acc: 0.9735 -- iter: 128/171
[A[ATraining Step: 113  | total loss: [1m[32m0.08272[0m[0m | time: 224.667s
[2K
| Adam | epoch: 019 | loss: 0.08272 - acc: 0.9762 -- iter: 160/171
[A[ATraining Step: 114  | total loss: [1m[32m0.07571[0m[0m | time: 339.701s
[2K
| Adam | epoch: 019 | loss: 0.07571 - acc: 0.9786 | val_loss: 1.75105 - val_acc: 0.6852 -- iter: 171/171
--
Training Step: 115  | total loss: [1m[32m0.11707[0m[0m | time: 52.130s
[2K
| Adam | epoch: 020 | loss: 0.11707 - acc: 0.9744 -- iter: 032/171
[A[ATraining Step: 116  | total loss: [1m[32m0.10705[0m[0m | time: 61.659s
[2K
| Adam | epoch: 020 | loss: 0.10705 - acc: 0.9770 -- iter: 064/171
[A[ATraining Step: 117  | total loss: [1m[32m0.09883[0m[0m | time: 69.746s
[2K
| Adam | epoch: 020 | loss: 0.09883 - acc: 0.9793 -- iter: 096/171
[A[ATraining Step: 118  | total loss: [1m[32m0.09863[0m[0m | time: 73.291s
[2K
| Adam | epoch: 020 | loss: 0.09863 - acc: 0.9782 -- iter: 128/171
[A[ATraining Step: 119  | total loss: [1m[32m0.09415[0m[0m | time: 76.786s
[2K
| Adam | epoch: 020 | loss: 0.09415 - acc: 0.9804 -- iter: 160/171
[A[ATraining Step: 120  | total loss: [1m[32m0.08578[0m[0m | time: 88.106s
[2K
| Adam | epoch: 020 | loss: 0.08578 - acc: 0.9824 | val_loss: 0.83845 - val_acc: 0.7778 -- iter: 171/171
--
Training Step: 121  | total loss: [1m[32m0.08052[0m[0m | time: 8.619s
[2K
| Adam | epoch: 021 | loss: 0.08052 - acc: 0.9841 -- iter: 032/171
[A[ATraining Step: 122  | total loss: [1m[32m0.09338[0m[0m | time: 55.275s
[2K
| Adam | epoch: 021 | loss: 0.09338 - acc: 0.9826 -- iter: 064/171
[A[ATraining Step: 123  | total loss: [1m[32m0.09056[0m[0m | time: 173.757s
[2K
| Adam | epoch: 021 | loss: 0.09056 - acc: 0.9812 -- iter: 096/171
[A[ATraining Step: 124  | total loss: [1m[32m0.08251[0m[0m | time: 268.267s
[2K
| Adam | epoch: 021 | loss: 0.08251 - acc: 0.9831 -- iter: 128/171
[A[ATraining Step: 125  | total loss: [1m[32m0.08786[0m[0m | time: 271.893s
[2K
| Adam | epoch: 021 | loss: 0.08786 - acc: 0.9754 -- iter: 160/171
[A[ATraining Step: 126  | total loss: [1m[32m0.08379[0m[0m | time: 278.531s
[2K
| Adam | epoch: 021 | loss: 0.08379 - acc: 0.9779 | val_loss: 0.79378 - val_acc: 0.8333 -- iter: 171/171
--
Training Step: 127  | total loss: [1m[32m0.07969[0m[0m | time: 35.724s
[2K
| Adam | epoch: 022 | loss: 0.07969 - acc: 0.9801 -- iter: 032/171
[A[ATraining Step: 128  | total loss: [1m[32m0.07241[0m[0m | time: 71.641s
[2K
| Adam | epoch: 022 | loss: 0.07241 - acc: 0.9821 -- iter: 064/171
[A[ATraining Step: 129  | total loss: [1m[32m0.06636[0m[0m | time: 118.136s
[2K
| Adam | epoch: 022 | loss: 0.06636 - acc: 0.9839 -- iter: 096/171
[A[ATraining Step: 130  | total loss: [1m[32m0.06349[0m[0m | time: 138.316s
[2K
| Adam | epoch: 022 | loss: 0.06349 - acc: 0.9855 -- iter: 128/171
[A[ATraining Step: 131  | total loss: [1m[32m0.05767[0m[0m | time: 210.119s
[2K
| Adam | epoch: 022 | loss: 0.05767 - acc: 0.9869 -- iter: 160/171
[A[ATraining Step: 132  | total loss: [1m[32m0.05369[0m[0m | time: 239.189s
[2K
| Adam | epoch: 022 | loss: 0.05369 - acc: 0.9882 | val_loss: 0.85753 - val_acc: 0.8148 -- iter: 171/171
--
Training Step: 133  | total loss: [1m[32m0.04943[0m[0m | time: 66.252s
[2K
| Adam | epoch: 023 | loss: 0.04943 - acc: 0.9894 -- iter: 032/171
[A[ATraining Step: 134  | total loss: [1m[32m0.04536[0m[0m | time: 75.474s
[2K
| Adam | epoch: 023 | loss: 0.04536 - acc: 0.9905 -- iter: 064/171
[A[ATraining Step: 135  | total loss: [1m[32m0.05517[0m[0m | time: 84.367s
[2K
| Adam | epoch: 023 | loss: 0.05517 - acc: 0.9883 -- iter: 096/171
[A[ATraining Step: 136  | total loss: [1m[32m0.08420[0m[0m | time: 93.642s
[2K
| Adam | epoch: 023 | loss: 0.08420 - acc: 0.9832 -- iter: 128/171
[A[ATraining Step: 137  | total loss: [1m[32m0.07826[0m[0m | time: 102.651s
[2K
| Adam | epoch: 023 | loss: 0.07826 - acc: 0.9849 -- iter: 160/171
[A[ATraining Step: 138  | total loss: [1m[32m0.07099[0m[0m | time: 401.415s
[2K
| Adam | epoch: 023 | loss: 0.07099 - acc: 0.9864 | val_loss: 1.39879 - val_acc: 0.7222 -- iter: 171/171
--
Training Step: 139  | total loss: [1m[32m0.07168[0m[0m | time: 18.639s
[2K
| Adam | epoch: 024 | loss: 0.07168 - acc: 0.9846 -- iter: 032/171
[A[ATraining Step: 140  | total loss: [1m[32m0.06463[0m[0m | time: 35.568s
[2K
| Adam | epoch: 024 | loss: 0.06463 - acc: 0.9862 -- iter: 064/171
[A[ATraining Step: 141  | total loss: [1m[32m0.05829[0m[0m | time: 148.583s
[2K
| Adam | epoch: 024 | loss: 0.05829 - acc: 0.9876 -- iter: 096/171
[A[ATraining Step: 142  | total loss: [1m[32m0.05470[0m[0m | time: 263.899s
[2K
| Adam | epoch: 024 | loss: 0.05470 - acc: 0.9888 -- iter: 128/171
[A[ATraining Step: 143  | total loss: [1m[32m0.08517[0m[0m | time: 385.550s
[2K
| Adam | epoch: 024 | loss: 0.08517 - acc: 0.9837 -- iter: 160/171
[A[ATraining Step: 144  | total loss: [1m[32m0.07716[0m[0m | time: 425.066s
[2K
| Adam | epoch: 024 | loss: 0.07716 - acc: 0.9853 | val_loss: 1.10525 - val_acc: 0.7778 -- iter: 171/171
--
Training Step: 145  | total loss: [1m[32m0.07085[0m[0m | time: 8.884s
[2K
| Adam | epoch: 025 | loss: 0.07085 - acc: 0.9868 -- iter: 032/171
[A[ATraining Step: 146  | total loss: [1m[32m0.06507[0m[0m | time: 12.534s
[2K
| Adam | epoch: 025 | loss: 0.06507 - acc: 0.9881 -- iter: 064/171
[A[ATraining Step: 147  | total loss: [1m[32m0.05930[0m[0m | time: 16.111s
[2K
| Adam | epoch: 025 | loss: 0.05930 - acc: 0.9893 -- iter: 096/171
[A[ATraining Step: 148  | total loss: [1m[32m0.05400[0m[0m | time: 24.798s
[2K
| Adam | epoch: 025 | loss: 0.05400 - acc: 0.9904 -- iter: 128/171
[A[ATraining Step: 149  | total loss: [1m[32m0.07945[0m[0m | time: 33.376s
[2K
| Adam | epoch: 025 | loss: 0.07945 - acc: 0.9851 -- iter: 160/171
[A[ATraining Step: 150  | total loss: [1m[32m0.10954[0m[0m | time: 45.274s
[2K
| Adam | epoch: 025 | loss: 0.10954 - acc: 0.9772 | val_loss: 0.70261 - val_acc: 0.7963 -- iter: 171/171
--
Training Step: 151  | total loss: [1m[32m0.11075[0m[0m | time: 8.581s
[2K
| Adam | epoch: 026 | loss: 0.11075 - acc: 0.9763 -- iter: 032/171
[A[ATraining Step: 152  | total loss: [1m[32m0.12150[0m[0m | time: 17.252s
[2K
| Adam | epoch: 026 | loss: 0.12150 - acc: 0.9693 -- iter: 064/171
[A[ATraining Step: 153  | total loss: [1m[32m0.11230[0m[0m | time: 20.855s
[2K
| Adam | epoch: 026 | loss: 0.11230 - acc: 0.9724 -- iter: 096/171
[A[ATraining Step: 154  | total loss: [1m[32m0.10595[0m[0m | time: 24.305s
[2K
| Adam | epoch: 026 | loss: 0.10595 - acc: 0.9752 -- iter: 128/171
[A[ATraining Step: 155  | total loss: [1m[32m0.09785[0m[0m | time: 62.343s
[2K
| Adam | epoch: 026 | loss: 0.09785 - acc: 0.9776 -- iter: 160/171
[A[ATraining Step: 156  | total loss: [1m[32m0.09960[0m[0m | time: 73.451s
[2K
| Adam | epoch: 026 | loss: 0.09960 - acc: 0.9768 | val_loss: 0.77004 - val_acc: 0.7778 -- iter: 171/171
--
Training Step: 157  | total loss: [1m[32m0.09253[0m[0m | time: 8.918s
[2K
| Adam | epoch: 027 | loss: 0.09253 - acc: 0.9791 -- iter: 032/171
[A[ATraining Step: 158  | total loss: [1m[32m0.08555[0m[0m | time: 32.205s
[2K
| Adam | epoch: 027 | loss: 0.08555 - acc: 0.9812 -- iter: 064/171
[A[ATraining Step: 159  | total loss: [1m[32m0.09821[0m[0m | time: 40.904s
[2K
| Adam | epoch: 027 | loss: 0.09821 - acc: 0.9799 -- iter: 096/171
[A[ATraining Step: 160  | total loss: [1m[32m0.09401[0m[0m | time: 44.603s
[2K
| Adam | epoch: 027 | loss: 0.09401 - acc: 0.9819 -- iter: 128/171
[A[ATraining Step: 161  | total loss: [1m[32m0.09419[0m[0m | time: 48.159s
[2K
| Adam | epoch: 027 | loss: 0.09419 - acc: 0.9747 -- iter: 160/171
[A[ATraining Step: 162  | total loss: [1m[32m0.08963[0m[0m | time: 77.003s
[2K
| Adam | epoch: 027 | loss: 0.08963 - acc: 0.9772 | val_loss: 1.24583 - val_acc: 0.6296 -- iter: 171/171
--
Training Step: 163  | total loss: [1m[32m0.08555[0m[0m | time: 25.676s
[2K
| Adam | epoch: 028 | loss: 0.08555 - acc: 0.9795 -- iter: 032/171
[A[ATraining Step: 164  | total loss: [1m[32m0.08916[0m[0m | time: 34.317s
[2K
| Adam | epoch: 028 | loss: 0.08916 - acc: 0.9753 -- iter: 064/171
[A[ATraining Step: 165  | total loss: [1m[32m0.09641[0m[0m | time: 57.264s
[2K
| Adam | epoch: 028 | loss: 0.09641 - acc: 0.9746 -- iter: 096/171
[A[ATraining Step: 166  | total loss: [1m[32m0.08870[0m[0m | time: 126.555s
[2K
| Adam | epoch: 028 | loss: 0.08870 - acc: 0.9772 -- iter: 128/171
[A[ATraining Step: 167  | total loss: [1m[32m0.08351[0m[0m | time: 130.112s
[2K
| Adam | epoch: 028 | loss: 0.08351 - acc: 0.9763 -- iter: 160/171
[A[ATraining Step: 168  | total loss: [1m[32m0.08082[0m[0m | time: 136.292s
[2K
| Adam | epoch: 028 | loss: 0.08082 - acc: 0.9787 | val_loss: 2.09865 - val_acc: 0.5370 -- iter: 171/171
--
Training Step: 169  | total loss: [1m[32m0.07525[0m[0m | time: 28.187s
[2K
| Adam | epoch: 029 | loss: 0.07525 - acc: 0.9808 -- iter: 032/171
[A[ATraining Step: 170  | total loss: [1m[32m0.06920[0m[0m | time: 74.545s
[2K
| Adam | epoch: 029 | loss: 0.06920 - acc: 0.9827 -- iter: 064/171
[A[ATraining Step: 171  | total loss: [1m[32m0.09793[0m[0m | time: 86.813s
[2K
| Adam | epoch: 029 | loss: 0.09793 - acc: 0.9813 -- iter: 096/171
[A[ATraining Step: 172  | total loss: [1m[32m0.08888[0m[0m | time: 96.004s
[2K
| Adam | epoch: 029 | loss: 0.08888 - acc: 0.9832 -- iter: 128/171
[A[ATraining Step: 173  | total loss: [1m[32m0.08521[0m[0m | time: 105.501s
[2K
| Adam | epoch: 029 | loss: 0.08521 - acc: 0.9818 -- iter: 160/171
[A[ATraining Step: 174  | total loss: [1m[32m0.07733[0m[0m | time: 111.835s
[2K
| Adam | epoch: 029 | loss: 0.07733 - acc: 0.9836 | val_loss: 1.25941 - val_acc: 0.6296 -- iter: 171/171
--
Training Step: 175  | total loss: [1m[32m0.07173[0m[0m | time: 3.693s
[2K
| Adam | epoch: 030 | loss: 0.07173 - acc: 0.9852 -- iter: 032/171
[A[ATraining Step: 176  | total loss: [1m[32m0.06647[0m[0m | time: 26.347s
[2K
| Adam | epoch: 030 | loss: 0.06647 - acc: 0.9867 -- iter: 064/171
[A[ATraining Step: 177  | total loss: [1m[32m0.07546[0m[0m | time: 86.611s
[2K
| Adam | epoch: 030 | loss: 0.07546 - acc: 0.9849 -- iter: 096/171
[A[ATraining Step: 178  | total loss: [1m[32m0.08786[0m[0m | time: 123.046s
[2K
| Adam | epoch: 030 | loss: 0.08786 - acc: 0.9802 -- iter: 128/171
[A[ATraining Step: 179  | total loss: [1m[32m0.07937[0m[0m | time: 131.655s
[2K
| Adam | epoch: 030 | loss: 0.07937 - acc: 0.9821 -- iter: 160/171
[A[ATraining Step: 180  | total loss: [1m[32m0.07194[0m[0m | time: 175.094s
[2K
| Adam | epoch: 030 | loss: 0.07194 - acc: 0.9839 | val_loss: 0.83863 - val_acc: 0.7963 -- iter: 171/171
--
Validation AUC:0.8166666666666668
Validation AUPRC:0.8134295181254585
Test AUC:0.8579545454545454
Test AUPRC:0.7853185169390702
BestTestF1Score	0.79	0.63	0.81	0.73	0.86	19	7	25	3	0.41
BestTestMCCScore	0.79	0.63	0.81	0.73	0.86	19	7	25	3	0.41
BestTestAccuracyScore	0.79	0.63	0.81	0.73	0.86	19	7	25	3	0.41
BestValidationF1Score	0.83	0.62	0.81	0.83	0.83	25	5	19	5	0.41
BestValidationMCC	0.83	0.62	0.81	0.83	0.83	25	5	19	5	0.41
BestValidationAccuracy	0.83	0.62	0.81	0.83	0.83	25	5	19	5	0.41
TestPredictions (Threshold:0.41)
CHEMBL3763517,FP,INACT,0.8999999761581421	CHEMBL557117,FP,INACT,0.5299999713897705	CHEMBL3358870,TP,ACT,0.9900000095367432	CHEMBL3358865,TN,INACT,0.2800000011920929	CHEMBL1910878,TN,INACT,0.009999999776482582	CHEMBL2059003,TN,INACT,0.28999999165534973	CHEMBL3318415,FN,ACT,0.36000001430511475	CHEMBL3581195,TP,ACT,0.9599999785423279	CHEMBL3581174,TP,ACT,0.9399999976158142	CHEMBL3765804,TP,ACT,0.6899999976158142	CHEMBL564845,TN,INACT,0.0	CHEMBL3581173,TP,ACT,1.0	CHEMBL2430729,TN,INACT,0.23000000417232513	CHEMBL2059008,TP,ACT,0.550000011920929	CHEMBL157710,TN,INACT,0.009999999776482582	CHEMBL2364562,TN,INACT,0.019999999552965164	CHEMBL3358871,TP,ACT,1.0	CHEMBL93873,TN,INACT,0.0	CHEMBL3746581,TP,ACT,0.7200000286102295	CHEMBL3221028,TN,INACT,0.1899999976158142	CHEMBL1910877,TN,INACT,0.0	CHEMBL3581203,FN,ACT,0.23000000417232513	CHEMBL2086537,TN,INACT,0.009999999776482582	CHEMBL7942,TN,INACT,0.029999999329447746	CHEMBL3358882,FP,INACT,0.8600000143051147	CHEMBL3318529,TP,ACT,0.949999988079071	CHEMBL2059006,TN,INACT,0.0	CHEMBL3318481,TP,ACT,1.0	CHEMBL2059001,TN,INACT,0.0	CHEMBL3609810,TN,INACT,0.0	CHEMBL435995,TP,ACT,0.9599999785423279	CHEMBL2316881,TP,ACT,0.8999999761581421	CHEMBL3358876,TP,ACT,0.800000011920929	CHEMBL3581185,TP,ACT,1.0	CHEMBL3318456,FP,INACT,0.9800000190734863	CHEMBL3318525,TP,ACT,1.0	CHEMBL3359432,FN,ACT,0.009999999776482582	CHEMBL2059004,TN,INACT,0.0	CHEMBL486329,TN,INACT,0.0	CHEMBL2086502,TN,INACT,0.0	CHEMBL434275,TN,INACT,0.15000000596046448	CHEMBL3765137,TP,ACT,0.9800000190734863	CHEMBL3608328,TN,INACT,0.0	CHEMBL1688789,TN,INACT,0.23999999463558197	CHEMBL3359434,FP,INACT,0.9900000095367432	CHEMBL2430731,TP,ACT,0.41999998688697815	CHEMBL2430741,TN,INACT,0.009999999776482582	CHEMBL3318460,FP,INACT,0.9900000095367432	CHEMBL752,TN,INACT,0.3199999928474426	CHEMBL3318537,TP,ACT,0.9900000095367432	CHEMBL2382396,TN,INACT,0.0	CHEMBL2430733,TP,ACT,0.7900000214576721	CHEMBL3318467,FP,INACT,1.0	CHEMBL3358868,TN,INACT,0.029999999329447746	

