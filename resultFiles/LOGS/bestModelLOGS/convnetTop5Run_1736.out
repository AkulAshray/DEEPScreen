CNNModel CHEMBL4308 adam 0.0005 15 128 0 0.6 False True
Number of active compounds :	520
Number of inactive compounds :	520
---------------------------------
Run id: CNNModel_CHEMBL4308_adam_0.0005_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4308_adam_0.0005_15_128_0.6_True/
---------------------------------
Training samples: 653
Validation samples: 205
--
Training Step: 1  | time: 2.484s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/653
[A[ATraining Step: 2  | total loss: [1m[32m0.62384[0m[0m | time: 5.613s
[2K
| Adam | epoch: 001 | loss: 0.62384 - acc: 0.4219 -- iter: 064/653
[A[ATraining Step: 3  | total loss: [1m[32m0.68027[0m[0m | time: 11.759s
[2K
| Adam | epoch: 001 | loss: 0.68027 - acc: 0.5369 -- iter: 096/653
[A[ATraining Step: 4  | total loss: [1m[32m0.69065[0m[0m | time: 17.000s
[2K
| Adam | epoch: 001 | loss: 0.69065 - acc: 0.4858 -- iter: 128/653
[A[ATraining Step: 5  | total loss: [1m[32m0.69237[0m[0m | time: 20.952s
[2K
| Adam | epoch: 001 | loss: 0.69237 - acc: 0.4956 -- iter: 160/653
[A[ATraining Step: 6  | total loss: [1m[32m0.69237[0m[0m | time: 26.669s
[2K
| Adam | epoch: 001 | loss: 0.69237 - acc: 0.5185 -- iter: 192/653
[A[ATraining Step: 7  | total loss: [1m[32m0.69322[0m[0m | time: 27.995s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4887 -- iter: 224/653
[A[ATraining Step: 8  | total loss: [1m[32m0.69403[0m[0m | time: 29.345s
[2K
| Adam | epoch: 001 | loss: 0.69403 - acc: 0.4599 -- iter: 256/653
[A[ATraining Step: 9  | total loss: [1m[32m0.69315[0m[0m | time: 30.640s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.4977 -- iter: 288/653
[A[ATraining Step: 10  | total loss: [1m[32m0.69261[0m[0m | time: 31.978s
[2K
| Adam | epoch: 001 | loss: 0.69261 - acc: 0.5301 -- iter: 320/653
[A[ATraining Step: 11  | total loss: [1m[32m0.69430[0m[0m | time: 33.382s
[2K
| Adam | epoch: 001 | loss: 0.69430 - acc: 0.4566 -- iter: 352/653
[A[ATraining Step: 12  | total loss: [1m[32m0.69456[0m[0m | time: 35.051s
[2K
| Adam | epoch: 001 | loss: 0.69456 - acc: 0.4058 -- iter: 384/653
[A[ATraining Step: 13  | total loss: [1m[32m0.69392[0m[0m | time: 38.095s
[2K
| Adam | epoch: 001 | loss: 0.69392 - acc: 0.4462 -- iter: 416/653
[A[ATraining Step: 14  | total loss: [1m[32m0.69360[0m[0m | time: 39.268s
[2K
| Adam | epoch: 001 | loss: 0.69360 - acc: 0.4299 -- iter: 448/653
[A[ATraining Step: 15  | total loss: [1m[32m0.69327[0m[0m | time: 40.680s
[2K
| Adam | epoch: 001 | loss: 0.69327 - acc: 0.5062 -- iter: 480/653
[A[ATraining Step: 16  | total loss: [1m[32m0.69303[0m[0m | time: 44.755s
[2K
| Adam | epoch: 001 | loss: 0.69303 - acc: 0.5508 -- iter: 512/653
[A[ATraining Step: 17  | total loss: [1m[32m0.69298[0m[0m | time: 47.698s
[2K
| Adam | epoch: 001 | loss: 0.69298 - acc: 0.5437 -- iter: 544/653
[A[ATraining Step: 18  | total loss: [1m[32m0.69270[0m[0m | time: 50.092s
[2K
| Adam | epoch: 001 | loss: 0.69270 - acc: 0.5502 -- iter: 576/653
[A[ATraining Step: 19  | total loss: [1m[32m0.69236[0m[0m | time: 52.662s
[2K
| Adam | epoch: 001 | loss: 0.69236 - acc: 0.5543 -- iter: 608/653
[A[ATraining Step: 20  | total loss: [1m[32m0.69253[0m[0m | time: 62.805s
[2K
| Adam | epoch: 001 | loss: 0.69253 - acc: 0.5369 -- iter: 640/653
[A[ATraining Step: 21  | total loss: [1m[32m0.69192[0m[0m | time: 69.843s
[2K
| Adam | epoch: 001 | loss: 0.69192 - acc: 0.5448 | val_loss: 0.69797 - val_acc: 0.4293 -- iter: 653/653
--
Training Step: 22  | total loss: [1m[32m0.69054[0m[0m | time: 0.673s
[2K
| Adam | epoch: 002 | loss: 0.69054 - acc: 0.5660 -- iter: 032/653
[A[ATraining Step: 23  | total loss: [1m[32m0.68816[0m[0m | time: 1.868s
[2K
| Adam | epoch: 002 | loss: 0.68816 - acc: 0.5803 -- iter: 064/653
[A[ATraining Step: 24  | total loss: [1m[32m0.69053[0m[0m | time: 3.054s
[2K
| Adam | epoch: 002 | loss: 0.69053 - acc: 0.5489 -- iter: 096/653
[A[ATraining Step: 25  | total loss: [1m[32m0.69646[0m[0m | time: 4.355s
[2K
| Adam | epoch: 002 | loss: 0.69646 - acc: 0.5015 -- iter: 128/653
[A[ATraining Step: 26  | total loss: [1m[32m0.69351[0m[0m | time: 5.720s
[2K
| Adam | epoch: 002 | loss: 0.69351 - acc: 0.5177 -- iter: 160/653
[A[ATraining Step: 27  | total loss: [1m[32m0.69126[0m[0m | time: 6.970s
[2K
| Adam | epoch: 002 | loss: 0.69126 - acc: 0.5292 -- iter: 192/653
[A[ATraining Step: 28  | total loss: [1m[32m0.69037[0m[0m | time: 8.255s
[2K
| Adam | epoch: 002 | loss: 0.69037 - acc: 0.5297 -- iter: 224/653
[A[ATraining Step: 29  | total loss: [1m[32m0.68953[0m[0m | time: 9.685s
[2K
| Adam | epoch: 002 | loss: 0.68953 - acc: 0.5301 -- iter: 256/653
[A[ATraining Step: 30  | total loss: [1m[32m0.68684[0m[0m | time: 11.007s
[2K
| Adam | epoch: 002 | loss: 0.68684 - acc: 0.5526 -- iter: 288/653
[A[ATraining Step: 31  | total loss: [1m[32m0.68591[0m[0m | time: 12.061s
[2K
| Adam | epoch: 002 | loss: 0.68591 - acc: 0.5549 -- iter: 320/653
[A[ATraining Step: 32  | total loss: [1m[32m0.68342[0m[0m | time: 13.075s
[2K
| Adam | epoch: 002 | loss: 0.68342 - acc: 0.5636 -- iter: 352/653
[A[ATraining Step: 33  | total loss: [1m[32m0.68146[0m[0m | time: 13.934s
[2K
| Adam | epoch: 002 | loss: 0.68146 - acc: 0.5634 -- iter: 384/653
[A[ATraining Step: 34  | total loss: [1m[32m0.68242[0m[0m | time: 14.913s
[2K
| Adam | epoch: 002 | loss: 0.68242 - acc: 0.5565 -- iter: 416/653
[A[ATraining Step: 35  | total loss: [1m[32m0.68287[0m[0m | time: 15.981s
[2K
| Adam | epoch: 002 | loss: 0.68287 - acc: 0.5512 -- iter: 448/653
[A[ATraining Step: 36  | total loss: [1m[32m0.67929[0m[0m | time: 16.796s
[2K
| Adam | epoch: 002 | loss: 0.67929 - acc: 0.5599 -- iter: 480/653
[A[ATraining Step: 37  | total loss: [1m[32m0.66996[0m[0m | time: 17.714s
[2K
| Adam | epoch: 002 | loss: 0.66996 - acc: 0.5917 -- iter: 512/653
[A[ATraining Step: 38  | total loss: [1m[32m0.68013[0m[0m | time: 18.659s
[2K
| Adam | epoch: 002 | loss: 0.68013 - acc: 0.5554 -- iter: 544/653
[A[ATraining Step: 39  | total loss: [1m[32m0.68323[0m[0m | time: 19.571s
[2K
| Adam | epoch: 002 | loss: 0.68323 - acc: 0.5388 -- iter: 576/653
[A[ATraining Step: 40  | total loss: [1m[32m0.67686[0m[0m | time: 20.540s
[2K
| Adam | epoch: 002 | loss: 0.67686 - acc: 0.5550 -- iter: 608/653
[A[ATraining Step: 41  | total loss: [1m[32m0.66982[0m[0m | time: 21.455s
[2K
| Adam | epoch: 002 | loss: 0.66982 - acc: 0.5908 -- iter: 640/653
[A[ATraining Step: 42  | total loss: [1m[32m0.66580[0m[0m | time: 23.541s
[2K
| Adam | epoch: 002 | loss: 0.66580 - acc: 0.6026 | val_loss: 0.68715 - val_acc: 0.4488 -- iter: 653/653
--
Training Step: 43  | total loss: [1m[32m0.65688[0m[0m | time: 0.562s
[2K
| Adam | epoch: 003 | loss: 0.65688 - acc: 0.6231 -- iter: 032/653
[A[ATraining Step: 44  | total loss: [1m[32m0.64810[0m[0m | time: 1.074s
[2K
| Adam | epoch: 003 | loss: 0.64810 - acc: 0.6217 -- iter: 064/653
[A[ATraining Step: 45  | total loss: [1m[32m0.63834[0m[0m | time: 1.876s
[2K
| Adam | epoch: 003 | loss: 0.63834 - acc: 0.6207 -- iter: 096/653
[A[ATraining Step: 46  | total loss: [1m[32m0.65096[0m[0m | time: 2.729s
[2K
| Adam | epoch: 003 | loss: 0.65096 - acc: 0.6006 -- iter: 128/653
[A[ATraining Step: 47  | total loss: [1m[32m0.64992[0m[0m | time: 3.705s
[2K
| Adam | epoch: 003 | loss: 0.64992 - acc: 0.5994 -- iter: 160/653
[A[ATraining Step: 48  | total loss: [1m[32m0.64158[0m[0m | time: 4.672s
[2K
| Adam | epoch: 003 | loss: 0.64158 - acc: 0.6186 -- iter: 192/653
[A[ATraining Step: 49  | total loss: [1m[32m0.64166[0m[0m | time: 5.612s
[2K
| Adam | epoch: 003 | loss: 0.64166 - acc: 0.6098 -- iter: 224/653
[A[ATraining Step: 50  | total loss: [1m[32m0.63168[0m[0m | time: 6.588s
[2K
| Adam | epoch: 003 | loss: 0.63168 - acc: 0.6218 -- iter: 256/653
[A[ATraining Step: 51  | total loss: [1m[32m0.62085[0m[0m | time: 7.578s
[2K
| Adam | epoch: 003 | loss: 0.62085 - acc: 0.6461 -- iter: 288/653
[A[ATraining Step: 52  | total loss: [1m[32m0.61849[0m[0m | time: 8.744s
[2K
| Adam | epoch: 003 | loss: 0.61849 - acc: 0.6523 -- iter: 320/653
[A[ATraining Step: 53  | total loss: [1m[32m0.61643[0m[0m | time: 10.121s
[2K
| Adam | epoch: 003 | loss: 0.61643 - acc: 0.6621 -- iter: 352/653
[A[ATraining Step: 54  | total loss: [1m[32m0.60456[0m[0m | time: 11.659s
[2K
| Adam | epoch: 003 | loss: 0.60456 - acc: 0.6749 -- iter: 384/653
[A[ATraining Step: 55  | total loss: [1m[32m0.59593[0m[0m | time: 15.901s
[2K
| Adam | epoch: 003 | loss: 0.59593 - acc: 0.6856 -- iter: 416/653
[A[ATraining Step: 56  | total loss: [1m[32m0.57218[0m[0m | time: 28.196s
[2K
| Adam | epoch: 003 | loss: 0.57218 - acc: 0.7035 -- iter: 448/653
[A[ATraining Step: 57  | total loss: [1m[32m0.55509[0m[0m | time: 35.777s
[2K
| Adam | epoch: 003 | loss: 0.55509 - acc: 0.7142 -- iter: 480/653
[A[ATraining Step: 58  | total loss: [1m[32m0.53236[0m[0m | time: 41.744s
[2K
| Adam | epoch: 003 | loss: 0.53236 - acc: 0.7362 -- iter: 512/653
[A[ATraining Step: 59  | total loss: [1m[32m0.50879[0m[0m | time: 44.104s
[2K
| Adam | epoch: 003 | loss: 0.50879 - acc: 0.7590 -- iter: 544/653
[A[ATraining Step: 60  | total loss: [1m[32m0.52889[0m[0m | time: 45.177s
[2K
| Adam | epoch: 003 | loss: 0.52889 - acc: 0.7578 -- iter: 576/653
[A[ATraining Step: 61  | total loss: [1m[32m0.51998[0m[0m | time: 46.491s
[2K
| Adam | epoch: 003 | loss: 0.51998 - acc: 0.7690 -- iter: 608/653
[A[ATraining Step: 62  | total loss: [1m[32m0.52324[0m[0m | time: 47.839s
[2K
| Adam | epoch: 003 | loss: 0.52324 - acc: 0.7666 -- iter: 640/653
[A[ATraining Step: 63  | total loss: [1m[32m0.53453[0m[0m | time: 50.945s
[2K
| Adam | epoch: 003 | loss: 0.53453 - acc: 0.7566 | val_loss: 0.48108 - val_acc: 0.7610 -- iter: 653/653
--
Training Step: 64  | total loss: [1m[32m0.50609[0m[0m | time: 1.279s
[2K
| Adam | epoch: 004 | loss: 0.50609 - acc: 0.7714 -- iter: 032/653
[A[ATraining Step: 65  | total loss: [1m[32m0.52354[0m[0m | time: 1.690s
[2K
| Adam | epoch: 004 | loss: 0.52354 - acc: 0.7649 -- iter: 064/653
[A[ATraining Step: 66  | total loss: [1m[32m0.50646[0m[0m | time: 2.176s
[2K
| Adam | epoch: 004 | loss: 0.50646 - acc: 0.7654 -- iter: 096/653
[A[ATraining Step: 67  | total loss: [1m[32m0.49073[0m[0m | time: 3.184s
[2K
| Adam | epoch: 004 | loss: 0.49073 - acc: 0.7659 -- iter: 128/653
[A[ATraining Step: 68  | total loss: [1m[32m0.50152[0m[0m | time: 4.145s
[2K
| Adam | epoch: 004 | loss: 0.50152 - acc: 0.7603 -- iter: 160/653
[A[ATraining Step: 69  | total loss: [1m[32m0.49714[0m[0m | time: 5.285s
[2K
| Adam | epoch: 004 | loss: 0.49714 - acc: 0.7627 -- iter: 192/653
[A[ATraining Step: 70  | total loss: [1m[32m0.49206[0m[0m | time: 6.449s
[2K
| Adam | epoch: 004 | loss: 0.49206 - acc: 0.7649 -- iter: 224/653
[A[ATraining Step: 71  | total loss: [1m[32m0.50119[0m[0m | time: 7.838s
[2K
| Adam | epoch: 004 | loss: 0.50119 - acc: 0.7596 -- iter: 256/653
[A[ATraining Step: 72  | total loss: [1m[32m0.50853[0m[0m | time: 9.095s
[2K
| Adam | epoch: 004 | loss: 0.50853 - acc: 0.7515 -- iter: 288/653
[A[ATraining Step: 73  | total loss: [1m[32m0.51145[0m[0m | time: 10.437s
[2K
| Adam | epoch: 004 | loss: 0.51145 - acc: 0.7548 -- iter: 320/653
[A[ATraining Step: 74  | total loss: [1m[32m0.51173[0m[0m | time: 11.695s
[2K
| Adam | epoch: 004 | loss: 0.51173 - acc: 0.7577 -- iter: 352/653
[A[ATraining Step: 75  | total loss: [1m[32m0.52955[0m[0m | time: 12.789s
[2K
| Adam | epoch: 004 | loss: 0.52955 - acc: 0.7433 -- iter: 384/653
[A[ATraining Step: 76  | total loss: [1m[32m0.53877[0m[0m | time: 21.465s
[2K
| Adam | epoch: 004 | loss: 0.53877 - acc: 0.7340 -- iter: 416/653
[A[ATraining Step: 77  | total loss: [1m[32m0.53416[0m[0m | time: 32.257s
[2K
| Adam | epoch: 004 | loss: 0.53416 - acc: 0.7324 -- iter: 448/653
[A[ATraining Step: 78  | total loss: [1m[32m0.55924[0m[0m | time: 34.465s
[2K
| Adam | epoch: 004 | loss: 0.55924 - acc: 0.7048 -- iter: 480/653
[A[ATraining Step: 79  | total loss: [1m[32m0.55477[0m[0m | time: 35.431s
[2K
| Adam | epoch: 004 | loss: 0.55477 - acc: 0.7095 -- iter: 512/653
[A[ATraining Step: 80  | total loss: [1m[32m0.54750[0m[0m | time: 36.425s
[2K
| Adam | epoch: 004 | loss: 0.54750 - acc: 0.7264 -- iter: 544/653
[A[ATraining Step: 81  | total loss: [1m[32m0.54596[0m[0m | time: 37.487s
[2K
| Adam | epoch: 004 | loss: 0.54596 - acc: 0.7351 -- iter: 576/653
[A[ATraining Step: 82  | total loss: [1m[32m0.54269[0m[0m | time: 38.562s
[2K
| Adam | epoch: 004 | loss: 0.54269 - acc: 0.7397 -- iter: 608/653
[A[ATraining Step: 83  | total loss: [1m[32m0.53815[0m[0m | time: 39.781s
[2K
| Adam | epoch: 004 | loss: 0.53815 - acc: 0.7470 -- iter: 640/653
[A[ATraining Step: 84  | total loss: [1m[32m0.53023[0m[0m | time: 42.545s
[2K
| Adam | epoch: 004 | loss: 0.53023 - acc: 0.7504 | val_loss: 0.48309 - val_acc: 0.7854 -- iter: 653/653
--
Training Step: 85  | total loss: [1m[32m0.51931[0m[0m | time: 21.100s
[2K
| Adam | epoch: 005 | loss: 0.51931 - acc: 0.7629 -- iter: 032/653
[A[ATraining Step: 86  | total loss: [1m[32m0.51484[0m[0m | time: 29.842s
[2K
| Adam | epoch: 005 | loss: 0.51484 - acc: 0.7741 -- iter: 064/653
[A[ATraining Step: 87  | total loss: [1m[32m0.50757[0m[0m | time: 32.877s
[2K
| Adam | epoch: 005 | loss: 0.50757 - acc: 0.7779 -- iter: 096/653
[A[ATraining Step: 88  | total loss: [1m[32m0.50342[0m[0m | time: 39.665s
[2K
| Adam | epoch: 005 | loss: 0.50342 - acc: 0.7771 -- iter: 128/653
[A[ATraining Step: 89  | total loss: [1m[32m0.49676[0m[0m | time: 49.870s
[2K
| Adam | epoch: 005 | loss: 0.49676 - acc: 0.7763 -- iter: 160/653
[A[ATraining Step: 90  | total loss: [1m[32m0.49284[0m[0m | time: 60.424s
[2K
| Adam | epoch: 005 | loss: 0.49284 - acc: 0.7737 -- iter: 192/653
[A[ATraining Step: 91  | total loss: [1m[32m0.51368[0m[0m | time: 67.702s
[2K
| Adam | epoch: 005 | loss: 0.51368 - acc: 0.7619 -- iter: 224/653
[A[ATraining Step: 92  | total loss: [1m[32m0.51789[0m[0m | time: 74.260s
[2K
| Adam | epoch: 005 | loss: 0.51789 - acc: 0.7576 -- iter: 256/653
[A[ATraining Step: 93  | total loss: [1m[32m0.52719[0m[0m | time: 79.032s
[2K
| Adam | epoch: 005 | loss: 0.52719 - acc: 0.7537 -- iter: 288/653
[A[ATraining Step: 94  | total loss: [1m[32m0.53822[0m[0m | time: 80.212s
[2K
| Adam | epoch: 005 | loss: 0.53822 - acc: 0.7440 -- iter: 320/653
[A[ATraining Step: 95  | total loss: [1m[32m0.58111[0m[0m | time: 81.569s
[2K
| Adam | epoch: 005 | loss: 0.58111 - acc: 0.7133 -- iter: 352/653
[A[ATraining Step: 96  | total loss: [1m[32m0.60697[0m[0m | time: 82.776s
[2K
| Adam | epoch: 005 | loss: 0.60697 - acc: 0.6951 -- iter: 384/653
[A[ATraining Step: 97  | total loss: [1m[32m0.59815[0m[0m | time: 84.106s
[2K
| Adam | epoch: 005 | loss: 0.59815 - acc: 0.6943 -- iter: 416/653
[A[ATraining Step: 98  | total loss: [1m[32m0.59265[0m[0m | time: 85.319s
[2K
| Adam | epoch: 005 | loss: 0.59265 - acc: 0.6999 -- iter: 448/653
[A[ATraining Step: 99  | total loss: [1m[32m0.57541[0m[0m | time: 86.719s
[2K
| Adam | epoch: 005 | loss: 0.57541 - acc: 0.7049 -- iter: 480/653
[A[ATraining Step: 100  | total loss: [1m[32m0.55761[0m[0m | time: 88.129s
[2K
| Adam | epoch: 005 | loss: 0.55761 - acc: 0.7251 -- iter: 512/653
[A[ATraining Step: 101  | total loss: [1m[32m0.55384[0m[0m | time: 89.308s
[2K
| Adam | epoch: 005 | loss: 0.55384 - acc: 0.7276 -- iter: 544/653
[A[ATraining Step: 102  | total loss: [1m[32m0.55987[0m[0m | time: 90.819s
[2K
| Adam | epoch: 005 | loss: 0.55987 - acc: 0.7235 -- iter: 576/653
[A[ATraining Step: 103  | total loss: [1m[32m0.57462[0m[0m | time: 92.165s
[2K
| Adam | epoch: 005 | loss: 0.57462 - acc: 0.7106 -- iter: 608/653
[A[ATraining Step: 104  | total loss: [1m[32m0.56999[0m[0m | time: 93.479s
[2K
| Adam | epoch: 005 | loss: 0.56999 - acc: 0.7145 -- iter: 640/653
[A[ATraining Step: 105  | total loss: [1m[32m0.56743[0m[0m | time: 95.562s
[2K
| Adam | epoch: 005 | loss: 0.56743 - acc: 0.7118 | val_loss: 0.49250 - val_acc: 0.7610 -- iter: 653/653
--
Training Step: 106  | total loss: [1m[32m0.55936[0m[0m | time: 1.062s
[2K
| Adam | epoch: 006 | loss: 0.55936 - acc: 0.7156 -- iter: 032/653
[A[ATraining Step: 107  | total loss: [1m[32m0.54935[0m[0m | time: 2.108s
[2K
| Adam | epoch: 006 | loss: 0.54935 - acc: 0.7253 -- iter: 064/653
[A[ATraining Step: 108  | total loss: [1m[32m0.53120[0m[0m | time: 3.161s
[2K
| Adam | epoch: 006 | loss: 0.53120 - acc: 0.7497 -- iter: 096/653
[A[ATraining Step: 109  | total loss: [1m[32m0.52395[0m[0m | time: 3.677s
[2K
| Adam | epoch: 006 | loss: 0.52395 - acc: 0.7591 -- iter: 128/653
[A[ATraining Step: 110  | total loss: [1m[32m0.51252[0m[0m | time: 4.134s
[2K
| Adam | epoch: 006 | loss: 0.51252 - acc: 0.7678 -- iter: 160/653
[A[ATraining Step: 111  | total loss: [1m[32m0.49843[0m[0m | time: 5.124s
[2K
| Adam | epoch: 006 | loss: 0.49843 - acc: 0.7679 -- iter: 192/653
[A[ATraining Step: 112  | total loss: [1m[32m0.49477[0m[0m | time: 6.257s
[2K
| Adam | epoch: 006 | loss: 0.49477 - acc: 0.7693 -- iter: 224/653
[A[ATraining Step: 113  | total loss: [1m[32m0.48469[0m[0m | time: 7.486s
[2K
| Adam | epoch: 006 | loss: 0.48469 - acc: 0.7861 -- iter: 256/653
[A[ATraining Step: 114  | total loss: [1m[32m0.47233[0m[0m | time: 8.353s
[2K
| Adam | epoch: 006 | loss: 0.47233 - acc: 0.7918 -- iter: 288/653
[A[ATraining Step: 115  | total loss: [1m[32m0.47482[0m[0m | time: 9.272s
[2K
| Adam | epoch: 006 | loss: 0.47482 - acc: 0.7877 -- iter: 320/653
[A[ATraining Step: 116  | total loss: [1m[32m0.46624[0m[0m | time: 10.240s
[2K
| Adam | epoch: 006 | loss: 0.46624 - acc: 0.7933 -- iter: 352/653
[A[ATraining Step: 117  | total loss: [1m[32m0.45587[0m[0m | time: 11.237s
[2K
| Adam | epoch: 006 | loss: 0.45587 - acc: 0.7983 -- iter: 384/653
[A[ATraining Step: 118  | total loss: [1m[32m0.46623[0m[0m | time: 12.222s
[2K
| Adam | epoch: 006 | loss: 0.46623 - acc: 0.7872 -- iter: 416/653
[A[ATraining Step: 119  | total loss: [1m[32m0.44787[0m[0m | time: 13.214s
[2K
| Adam | epoch: 006 | loss: 0.44787 - acc: 0.7960 -- iter: 448/653
[A[ATraining Step: 120  | total loss: [1m[32m0.44179[0m[0m | time: 14.160s
[2K
| Adam | epoch: 006 | loss: 0.44179 - acc: 0.7977 -- iter: 480/653
[A[ATraining Step: 121  | total loss: [1m[32m0.43860[0m[0m | time: 15.157s
[2K
| Adam | epoch: 006 | loss: 0.43860 - acc: 0.7991 -- iter: 512/653
[A[ATraining Step: 122  | total loss: [1m[32m0.42912[0m[0m | time: 16.136s
[2K
| Adam | epoch: 006 | loss: 0.42912 - acc: 0.8099 -- iter: 544/653
[A[ATraining Step: 123  | total loss: [1m[32m0.41804[0m[0m | time: 17.283s
[2K
| Adam | epoch: 006 | loss: 0.41804 - acc: 0.8132 -- iter: 576/653
[A[ATraining Step: 124  | total loss: [1m[32m0.41112[0m[0m | time: 18.450s
[2K
| Adam | epoch: 006 | loss: 0.41112 - acc: 0.8132 -- iter: 608/653
[A[ATraining Step: 125  | total loss: [1m[32m0.40843[0m[0m | time: 19.253s
[2K
| Adam | epoch: 006 | loss: 0.40843 - acc: 0.8256 -- iter: 640/653
[A[ATraining Step: 126  | total loss: [1m[32m0.40164[0m[0m | time: 21.330s
[2K
| Adam | epoch: 006 | loss: 0.40164 - acc: 0.8305 | val_loss: 0.34931 - val_acc: 0.8439 -- iter: 653/653
--
Training Step: 127  | total loss: [1m[32m0.39758[0m[0m | time: 1.260s
[2K
| Adam | epoch: 007 | loss: 0.39758 - acc: 0.8287 -- iter: 032/653
[A[ATraining Step: 128  | total loss: [1m[32m0.39149[0m[0m | time: 5.489s
[2K
| Adam | epoch: 007 | loss: 0.39149 - acc: 0.8271 -- iter: 064/653
[A[ATraining Step: 129  | total loss: [1m[32m0.39503[0m[0m | time: 9.637s
[2K
| Adam | epoch: 007 | loss: 0.39503 - acc: 0.8257 -- iter: 096/653
[A[ATraining Step: 130  | total loss: [1m[32m0.38399[0m[0m | time: 10.906s
[2K
| Adam | epoch: 007 | loss: 0.38399 - acc: 0.8306 -- iter: 128/653
[A[ATraining Step: 131  | total loss: [1m[32m0.37225[0m[0m | time: 11.516s
[2K
| Adam | epoch: 007 | loss: 0.37225 - acc: 0.8382 -- iter: 160/653
[A[ATraining Step: 132  | total loss: [1m[32m0.38022[0m[0m | time: 12.174s
[2K
| Adam | epoch: 007 | loss: 0.38022 - acc: 0.8390 -- iter: 192/653
[A[ATraining Step: 133  | total loss: [1m[32m0.38470[0m[0m | time: 13.845s
[2K
| Adam | epoch: 007 | loss: 0.38470 - acc: 0.8397 -- iter: 224/653
[A[ATraining Step: 134  | total loss: [1m[32m0.38950[0m[0m | time: 15.183s
[2K
| Adam | epoch: 007 | loss: 0.38950 - acc: 0.8338 -- iter: 256/653
[A[ATraining Step: 135  | total loss: [1m[32m0.37754[0m[0m | time: 17.882s
[2K
| Adam | epoch: 007 | loss: 0.37754 - acc: 0.8411 -- iter: 288/653
[A[ATraining Step: 136  | total loss: [1m[32m0.37857[0m[0m | time: 19.144s
[2K
| Adam | epoch: 007 | loss: 0.37857 - acc: 0.8413 -- iter: 320/653
[A[ATraining Step: 137  | total loss: [1m[32m0.36866[0m[0m | time: 20.382s
[2K
| Adam | epoch: 007 | loss: 0.36866 - acc: 0.8478 -- iter: 352/653
[A[ATraining Step: 138  | total loss: [1m[32m0.35309[0m[0m | time: 21.687s
[2K
| Adam | epoch: 007 | loss: 0.35309 - acc: 0.8537 -- iter: 384/653
[A[ATraining Step: 139  | total loss: [1m[32m0.34226[0m[0m | time: 23.109s
[2K
| Adam | epoch: 007 | loss: 0.34226 - acc: 0.8558 -- iter: 416/653
[A[ATraining Step: 140  | total loss: [1m[32m0.33341[0m[0m | time: 24.533s
[2K
| Adam | epoch: 007 | loss: 0.33341 - acc: 0.8609 -- iter: 448/653
[A[ATraining Step: 141  | total loss: [1m[32m0.33444[0m[0m | time: 28.105s
[2K
| Adam | epoch: 007 | loss: 0.33444 - acc: 0.8591 -- iter: 480/653
[A[ATraining Step: 142  | total loss: [1m[32m0.32413[0m[0m | time: 29.269s
[2K
| Adam | epoch: 007 | loss: 0.32413 - acc: 0.8639 -- iter: 512/653
[A[ATraining Step: 143  | total loss: [1m[32m0.32167[0m[0m | time: 30.610s
[2K
| Adam | epoch: 007 | loss: 0.32167 - acc: 0.8650 -- iter: 544/653
[A[ATraining Step: 144  | total loss: [1m[32m0.31992[0m[0m | time: 31.908s
[2K
| Adam | epoch: 007 | loss: 0.31992 - acc: 0.8628 -- iter: 576/653
[A[ATraining Step: 145  | total loss: [1m[32m0.30894[0m[0m | time: 33.291s
[2K
| Adam | epoch: 007 | loss: 0.30894 - acc: 0.8703 -- iter: 608/653
[A[ATraining Step: 146  | total loss: [1m[32m0.29884[0m[0m | time: 34.655s
[2K
| Adam | epoch: 007 | loss: 0.29884 - acc: 0.8770 -- iter: 640/653
[A[ATraining Step: 147  | total loss: [1m[32m0.29468[0m[0m | time: 37.660s
[2K
| Adam | epoch: 007 | loss: 0.29468 - acc: 0.8768 | val_loss: 0.32936 - val_acc: 0.8683 -- iter: 653/653
--
Training Step: 148  | total loss: [1m[32m0.28532[0m[0m | time: 1.110s
[2K
| Adam | epoch: 008 | loss: 0.28532 - acc: 0.8829 -- iter: 032/653
[A[ATraining Step: 149  | total loss: [1m[32m0.27267[0m[0m | time: 2.241s
[2K
| Adam | epoch: 008 | loss: 0.27267 - acc: 0.8915 -- iter: 064/653
[A[ATraining Step: 150  | total loss: [1m[32m0.27006[0m[0m | time: 3.491s
[2K
| Adam | epoch: 008 | loss: 0.27006 - acc: 0.8961 -- iter: 096/653
[A[ATraining Step: 151  | total loss: [1m[32m0.25969[0m[0m | time: 4.688s
[2K
| Adam | epoch: 008 | loss: 0.25969 - acc: 0.9033 -- iter: 128/653
[A[ATraining Step: 152  | total loss: [1m[32m0.25341[0m[0m | time: 5.982s
[2K
| Adam | epoch: 008 | loss: 0.25341 - acc: 0.9036 -- iter: 160/653
[A[ATraining Step: 153  | total loss: [1m[32m0.24485[0m[0m | time: 6.407s
[2K
| Adam | epoch: 008 | loss: 0.24485 - acc: 0.9039 -- iter: 192/653
[A[ATraining Step: 154  | total loss: [1m[32m0.23577[0m[0m | time: 6.855s
[2K
| Adam | epoch: 008 | loss: 0.23577 - acc: 0.9058 -- iter: 224/653
[A[ATraining Step: 155  | total loss: [1m[32m0.21777[0m[0m | time: 7.946s
[2K
| Adam | epoch: 008 | loss: 0.21777 - acc: 0.9152 -- iter: 256/653
[A[ATraining Step: 156  | total loss: [1m[32m0.24637[0m[0m | time: 9.076s
[2K
| Adam | epoch: 008 | loss: 0.24637 - acc: 0.9112 -- iter: 288/653
[A[ATraining Step: 157  | total loss: [1m[32m0.28897[0m[0m | time: 10.369s
[2K
| Adam | epoch: 008 | loss: 0.28897 - acc: 0.8951 -- iter: 320/653
[A[ATraining Step: 158  | total loss: [1m[32m0.33074[0m[0m | time: 11.743s
[2K
| Adam | epoch: 008 | loss: 0.33074 - acc: 0.8806 -- iter: 352/653
[A[ATraining Step: 159  | total loss: [1m[32m0.32733[0m[0m | time: 13.054s
[2K
| Adam | epoch: 008 | loss: 0.32733 - acc: 0.8800 -- iter: 384/653
[A[ATraining Step: 160  | total loss: [1m[32m0.32381[0m[0m | time: 15.342s
[2K
| Adam | epoch: 008 | loss: 0.32381 - acc: 0.8858 -- iter: 416/653
[A[ATraining Step: 161  | total loss: [1m[32m0.32123[0m[0m | time: 16.883s
[2K
| Adam | epoch: 008 | loss: 0.32123 - acc: 0.8878 -- iter: 448/653
[A[ATraining Step: 162  | total loss: [1m[32m0.33107[0m[0m | time: 20.637s
[2K
| Adam | epoch: 008 | loss: 0.33107 - acc: 0.8803 -- iter: 480/653
[A[ATraining Step: 163  | total loss: [1m[32m0.32091[0m[0m | time: 22.887s
[2K
| Adam | epoch: 008 | loss: 0.32091 - acc: 0.8860 -- iter: 512/653
[A[ATraining Step: 164  | total loss: [1m[32m0.31811[0m[0m | time: 23.894s
[2K
| Adam | epoch: 008 | loss: 0.31811 - acc: 0.8818 -- iter: 544/653
[A[ATraining Step: 165  | total loss: [1m[32m0.30785[0m[0m | time: 24.818s
[2K
| Adam | epoch: 008 | loss: 0.30785 - acc: 0.8905 -- iter: 576/653
[A[ATraining Step: 166  | total loss: [1m[32m0.29830[0m[0m | time: 25.758s
[2K
| Adam | epoch: 008 | loss: 0.29830 - acc: 0.8921 -- iter: 608/653
[A[ATraining Step: 167  | total loss: [1m[32m0.29134[0m[0m | time: 26.794s
[2K
| Adam | epoch: 008 | loss: 0.29134 - acc: 0.8935 -- iter: 640/653
[A[ATraining Step: 168  | total loss: [1m[32m0.27459[0m[0m | time: 29.049s
[2K
| Adam | epoch: 008 | loss: 0.27459 - acc: 0.9041 | val_loss: 0.25649 - val_acc: 0.8976 -- iter: 653/653
--
Training Step: 169  | total loss: [1m[32m0.26946[0m[0m | time: 1.003s
[2K
| Adam | epoch: 009 | loss: 0.26946 - acc: 0.9043 -- iter: 032/653
[A[ATraining Step: 170  | total loss: [1m[32m0.26370[0m[0m | time: 2.015s
[2K
| Adam | epoch: 009 | loss: 0.26370 - acc: 0.9045 -- iter: 064/653
[A[ATraining Step: 171  | total loss: [1m[32m0.25693[0m[0m | time: 2.958s
[2K
| Adam | epoch: 009 | loss: 0.25693 - acc: 0.9078 -- iter: 096/653
[A[ATraining Step: 172  | total loss: [1m[32m0.24666[0m[0m | time: 3.619s
[2K
| Adam | epoch: 009 | loss: 0.24666 - acc: 0.9108 -- iter: 128/653
[A[ATraining Step: 173  | total loss: [1m[32m0.23630[0m[0m | time: 4.335s
[2K
| Adam | epoch: 009 | loss: 0.23630 - acc: 0.9166 -- iter: 160/653
[A[ATraining Step: 174  | total loss: [1m[32m0.22081[0m[0m | time: 5.010s
[2K
| Adam | epoch: 009 | loss: 0.22081 - acc: 0.9218 -- iter: 192/653
[A[ATraining Step: 175  | total loss: [1m[32m0.21863[0m[0m | time: 5.443s
[2K
| Adam | epoch: 009 | loss: 0.21863 - acc: 0.9203 -- iter: 224/653
[A[ATraining Step: 176  | total loss: [1m[32m0.20810[0m[0m | time: 5.826s
[2K
| Adam | epoch: 009 | loss: 0.20810 - acc: 0.9205 -- iter: 256/653
[A[ATraining Step: 177  | total loss: [1m[32m0.19507[0m[0m | time: 6.659s
[2K
| Adam | epoch: 009 | loss: 0.19507 - acc: 0.9285 -- iter: 288/653
[A[ATraining Step: 178  | total loss: [1m[32m0.22343[0m[0m | time: 7.531s
[2K
| Adam | epoch: 009 | loss: 0.22343 - acc: 0.9169 -- iter: 320/653
[A[ATraining Step: 179  | total loss: [1m[32m0.22417[0m[0m | time: 8.306s
[2K
| Adam | epoch: 009 | loss: 0.22417 - acc: 0.9189 -- iter: 352/653
[A[ATraining Step: 180  | total loss: [1m[32m0.21434[0m[0m | time: 9.374s
[2K
| Adam | epoch: 009 | loss: 0.21434 - acc: 0.9208 -- iter: 384/653
[A[ATraining Step: 181  | total loss: [1m[32m0.20409[0m[0m | time: 10.543s
[2K
| Adam | epoch: 009 | loss: 0.20409 - acc: 0.9256 -- iter: 416/653
[A[ATraining Step: 182  | total loss: [1m[32m0.19915[0m[0m | time: 11.561s
[2K
| Adam | epoch: 009 | loss: 0.19915 - acc: 0.9237 -- iter: 448/653
[A[ATraining Step: 183  | total loss: [1m[32m0.18771[0m[0m | time: 12.404s
[2K
| Adam | epoch: 009 | loss: 0.18771 - acc: 0.9282 -- iter: 480/653
[A[ATraining Step: 184  | total loss: [1m[32m0.18487[0m[0m | time: 13.404s
[2K
| Adam | epoch: 009 | loss: 0.18487 - acc: 0.9260 -- iter: 512/653
[A[ATraining Step: 185  | total loss: [1m[32m0.17356[0m[0m | time: 14.329s
[2K
| Adam | epoch: 009 | loss: 0.17356 - acc: 0.9334 -- iter: 544/653
[A[ATraining Step: 186  | total loss: [1m[32m0.17053[0m[0m | time: 15.298s
[2K
| Adam | epoch: 009 | loss: 0.17053 - acc: 0.9369 -- iter: 576/653
[A[ATraining Step: 187  | total loss: [1m[32m0.16704[0m[0m | time: 16.335s
[2K
| Adam | epoch: 009 | loss: 0.16704 - acc: 0.9370 -- iter: 608/653
[A[ATraining Step: 188  | total loss: [1m[32m0.16135[0m[0m | time: 17.384s
[2K
| Adam | epoch: 009 | loss: 0.16135 - acc: 0.9402 -- iter: 640/653
[A[ATraining Step: 189  | total loss: [1m[32m0.15591[0m[0m | time: 19.606s
[2K
| Adam | epoch: 009 | loss: 0.15591 - acc: 0.9430 | val_loss: 0.23594 - val_acc: 0.9366 -- iter: 653/653
--
Training Step: 190  | total loss: [1m[32m0.14976[0m[0m | time: 0.970s
[2K
| Adam | epoch: 010 | loss: 0.14976 - acc: 0.9456 -- iter: 032/653
[A[ATraining Step: 191  | total loss: [1m[32m0.13644[0m[0m | time: 1.848s
[2K
| Adam | epoch: 010 | loss: 0.13644 - acc: 0.9510 -- iter: 064/653
[A[ATraining Step: 192  | total loss: [1m[32m0.13713[0m[0m | time: 3.013s
[2K
| Adam | epoch: 010 | loss: 0.13713 - acc: 0.9465 -- iter: 096/653
[A[ATraining Step: 193  | total loss: [1m[32m0.12951[0m[0m | time: 4.531s
[2K
| Adam | epoch: 010 | loss: 0.12951 - acc: 0.9519 -- iter: 128/653
[A[ATraining Step: 194  | total loss: [1m[32m0.12898[0m[0m | time: 7.347s
[2K
| Adam | epoch: 010 | loss: 0.12898 - acc: 0.9536 -- iter: 160/653
[A[ATraining Step: 195  | total loss: [1m[32m0.13553[0m[0m | time: 9.736s
[2K
| Adam | epoch: 010 | loss: 0.13553 - acc: 0.9520 -- iter: 192/653
[A[ATraining Step: 196  | total loss: [1m[32m0.13461[0m[0m | time: 11.163s
[2K
| Adam | epoch: 010 | loss: 0.13461 - acc: 0.9474 -- iter: 224/653
[A[ATraining Step: 197  | total loss: [1m[32m0.12734[0m[0m | time: 13.406s
[2K
| Adam | epoch: 010 | loss: 0.12734 - acc: 0.9527 -- iter: 256/653
[A[ATraining Step: 198  | total loss: [1m[32m0.13032[0m[0m | time: 16.969s
[2K
| Adam | epoch: 010 | loss: 0.13032 - acc: 0.9497 -- iter: 288/653
[A[ATraining Step: 199  | total loss: [1m[32m0.12309[0m[0m | time: 20.899s
[2K
| Adam | epoch: 010 | loss: 0.12309 - acc: 0.9547 -- iter: 320/653
[A[ATraining Step: 200  | total loss: [1m[32m0.11492[0m[0m | time: 23.689s
[2K
| Adam | epoch: 010 | loss: 0.11492 - acc: 0.9593 | val_loss: 0.24045 - val_acc: 0.9268 -- iter: 352/653
--
Training Step: 201  | total loss: [1m[32m0.10846[0m[0m | time: 25.229s
[2K
| Adam | epoch: 010 | loss: 0.10846 - acc: 0.9633 -- iter: 384/653
[A[ATraining Step: 202  | total loss: [1m[32m0.10557[0m[0m | time: 31.817s
[2K
| Adam | epoch: 010 | loss: 0.10557 - acc: 0.9639 -- iter: 416/653
[A[ATraining Step: 203  | total loss: [1m[32m0.11358[0m[0m | time: 34.978s
[2K
| Adam | epoch: 010 | loss: 0.11358 - acc: 0.9550 -- iter: 448/653
[A[ATraining Step: 204  | total loss: [1m[32m0.12638[0m[0m | time: 37.199s
[2K
| Adam | epoch: 010 | loss: 0.12638 - acc: 0.9501 -- iter: 480/653
[A[ATraining Step: 205  | total loss: [1m[32m0.12446[0m[0m | time: 38.465s
[2K
| Adam | epoch: 010 | loss: 0.12446 - acc: 0.9520 -- iter: 512/653
[A[ATraining Step: 206  | total loss: [1m[32m0.13000[0m[0m | time: 39.826s
[2K
| Adam | epoch: 010 | loss: 0.13000 - acc: 0.9474 -- iter: 544/653
[A[ATraining Step: 207  | total loss: [1m[32m0.12676[0m[0m | time: 41.086s
[2K
| Adam | epoch: 010 | loss: 0.12676 - acc: 0.9495 -- iter: 576/653
[A[ATraining Step: 208  | total loss: [1m[32m0.15309[0m[0m | time: 42.489s
[2K
| Adam | epoch: 010 | loss: 0.15309 - acc: 0.9452 -- iter: 608/653
[A[ATraining Step: 209  | total loss: [1m[32m0.14127[0m[0m | time: 43.916s
[2K
| Adam | epoch: 010 | loss: 0.14127 - acc: 0.9507 -- iter: 640/653
[A[ATraining Step: 210  | total loss: [1m[32m0.14541[0m[0m | time: 56.069s
[2K
| Adam | epoch: 010 | loss: 0.14541 - acc: 0.9462 | val_loss: 0.22189 - val_acc: 0.9317 -- iter: 653/653
--
Training Step: 211  | total loss: [1m[32m0.13587[0m[0m | time: 1.557s
[2K
| Adam | epoch: 011 | loss: 0.13587 - acc: 0.9516 -- iter: 032/653
[A[ATraining Step: 212  | total loss: [1m[32m0.13105[0m[0m | time: 2.940s
[2K
| Adam | epoch: 011 | loss: 0.13105 - acc: 0.9502 -- iter: 064/653
[A[ATraining Step: 213  | total loss: [1m[32m0.12286[0m[0m | time: 6.150s
[2K
| Adam | epoch: 011 | loss: 0.12286 - acc: 0.9521 -- iter: 096/653
[A[ATraining Step: 214  | total loss: [1m[32m0.11454[0m[0m | time: 8.672s
[2K
| Adam | epoch: 011 | loss: 0.11454 - acc: 0.9569 -- iter: 128/653
[A[ATraining Step: 215  | total loss: [1m[32m0.12345[0m[0m | time: 13.486s
[2K
| Adam | epoch: 011 | loss: 0.12345 - acc: 0.9518 -- iter: 160/653
[A[ATraining Step: 216  | total loss: [1m[32m0.12773[0m[0m | time: 14.794s
[2K
| Adam | epoch: 011 | loss: 0.12773 - acc: 0.9504 -- iter: 192/653
[A[ATraining Step: 217  | total loss: [1m[32m0.11948[0m[0m | time: 16.108s
[2K
| Adam | epoch: 011 | loss: 0.11948 - acc: 0.9553 -- iter: 224/653
[A[ATraining Step: 218  | total loss: [1m[32m0.11392[0m[0m | time: 17.421s
[2K
| Adam | epoch: 011 | loss: 0.11392 - acc: 0.9567 -- iter: 256/653
[A[ATraining Step: 219  | total loss: [1m[32m0.10984[0m[0m | time: 17.949s
[2K
| Adam | epoch: 011 | loss: 0.10984 - acc: 0.9579 -- iter: 288/653
[A[ATraining Step: 220  | total loss: [1m[32m0.10011[0m[0m | time: 18.643s
[2K
| Adam | epoch: 011 | loss: 0.10011 - acc: 0.9621 -- iter: 320/653
[A[ATraining Step: 221  | total loss: [1m[32m0.09121[0m[0m | time: 20.221s
[2K
| Adam | epoch: 011 | loss: 0.09121 - acc: 0.9659 -- iter: 352/653
[A[ATraining Step: 222  | total loss: [1m[32m0.09885[0m[0m | time: 21.775s
[2K
| Adam | epoch: 011 | loss: 0.09885 - acc: 0.9630 -- iter: 384/653
[A[ATraining Step: 223  | total loss: [1m[32m0.09178[0m[0m | time: 23.433s
[2K
| Adam | epoch: 011 | loss: 0.09178 - acc: 0.9667 -- iter: 416/653
[A[ATraining Step: 224  | total loss: [1m[32m0.08503[0m[0m | time: 25.458s
[2K
| Adam | epoch: 011 | loss: 0.08503 - acc: 0.9701 -- iter: 448/653
[A[ATraining Step: 225  | total loss: [1m[32m0.08142[0m[0m | time: 29.301s
[2K
| Adam | epoch: 011 | loss: 0.08142 - acc: 0.9731 -- iter: 480/653
[A[ATraining Step: 226  | total loss: [1m[32m0.07586[0m[0m | time: 30.395s
[2K
| Adam | epoch: 011 | loss: 0.07586 - acc: 0.9758 -- iter: 512/653
[A[ATraining Step: 227  | total loss: [1m[32m0.07299[0m[0m | time: 31.759s
[2K
| Adam | epoch: 011 | loss: 0.07299 - acc: 0.9751 -- iter: 544/653
[A[ATraining Step: 228  | total loss: [1m[32m0.07069[0m[0m | time: 33.194s
[2K
| Adam | epoch: 011 | loss: 0.07069 - acc: 0.9744 -- iter: 576/653
[A[ATraining Step: 229  | total loss: [1m[32m0.06674[0m[0m | time: 34.900s
[2K
| Adam | epoch: 011 | loss: 0.06674 - acc: 0.9770 -- iter: 608/653
[A[ATraining Step: 230  | total loss: [1m[32m0.08642[0m[0m | time: 37.189s
[2K
| Adam | epoch: 011 | loss: 0.08642 - acc: 0.9762 -- iter: 640/653
[A[ATraining Step: 231  | total loss: [1m[32m0.07880[0m[0m | time: 41.554s
[2K
| Adam | epoch: 011 | loss: 0.07880 - acc: 0.9785 | val_loss: 0.28247 - val_acc: 0.8976 -- iter: 653/653
--
Training Step: 232  | total loss: [1m[32m0.07287[0m[0m | time: 1.273s
[2K
| Adam | epoch: 012 | loss: 0.07287 - acc: 0.9807 -- iter: 032/653
[A[ATraining Step: 233  | total loss: [1m[32m0.06654[0m[0m | time: 2.400s
[2K
| Adam | epoch: 012 | loss: 0.06654 - acc: 0.9826 -- iter: 064/653
[A[ATraining Step: 234  | total loss: [1m[32m0.06624[0m[0m | time: 3.653s
[2K
| Adam | epoch: 012 | loss: 0.06624 - acc: 0.9812 -- iter: 096/653
[A[ATraining Step: 235  | total loss: [1m[32m0.07496[0m[0m | time: 4.900s
[2K
| Adam | epoch: 012 | loss: 0.07496 - acc: 0.9800 -- iter: 128/653
[A[ATraining Step: 236  | total loss: [1m[32m0.06914[0m[0m | time: 6.211s
[2K
| Adam | epoch: 012 | loss: 0.06914 - acc: 0.9820 -- iter: 160/653
[A[ATraining Step: 237  | total loss: [1m[32m0.06466[0m[0m | time: 7.351s
[2K
| Adam | epoch: 012 | loss: 0.06466 - acc: 0.9838 -- iter: 192/653
[A[ATraining Step: 238  | total loss: [1m[32m0.07591[0m[0m | time: 8.658s
[2K
| Adam | epoch: 012 | loss: 0.07591 - acc: 0.9792 -- iter: 224/653
[A[ATraining Step: 239  | total loss: [1m[32m0.07635[0m[0m | time: 10.037s
[2K
| Adam | epoch: 012 | loss: 0.07635 - acc: 0.9781 -- iter: 256/653
[A[ATraining Step: 240  | total loss: [1m[32m0.07448[0m[0m | time: 11.497s
[2K
| Adam | epoch: 012 | loss: 0.07448 - acc: 0.9772 -- iter: 288/653
[A[ATraining Step: 241  | total loss: [1m[32m0.06895[0m[0m | time: 12.177s
[2K
| Adam | epoch: 012 | loss: 0.06895 - acc: 0.9795 -- iter: 320/653
[A[ATraining Step: 242  | total loss: [1m[32m0.06302[0m[0m | time: 12.790s
[2K
| Adam | epoch: 012 | loss: 0.06302 - acc: 0.9815 -- iter: 352/653
[A[ATraining Step: 243  | total loss: [1m[32m0.05846[0m[0m | time: 13.721s
[2K
| Adam | epoch: 012 | loss: 0.05846 - acc: 0.9834 -- iter: 384/653
[A[ATraining Step: 244  | total loss: [1m[32m0.05512[0m[0m | time: 14.437s
[2K
| Adam | epoch: 012 | loss: 0.05512 - acc: 0.9850 -- iter: 416/653
[A[ATraining Step: 245  | total loss: [1m[32m0.05216[0m[0m | time: 15.131s
[2K
| Adam | epoch: 012 | loss: 0.05216 - acc: 0.9865 -- iter: 448/653
[A[ATraining Step: 246  | total loss: [1m[32m0.04827[0m[0m | time: 15.819s
[2K
| Adam | epoch: 012 | loss: 0.04827 - acc: 0.9879 -- iter: 480/653
[A[ATraining Step: 247  | total loss: [1m[32m0.04611[0m[0m | time: 16.494s
[2K
| Adam | epoch: 012 | loss: 0.04611 - acc: 0.9891 -- iter: 512/653
[A[ATraining Step: 248  | total loss: [1m[32m0.06740[0m[0m | time: 17.167s
[2K
| Adam | epoch: 012 | loss: 0.06740 - acc: 0.9871 -- iter: 544/653
[A[ATraining Step: 249  | total loss: [1m[32m0.06324[0m[0m | time: 17.853s
[2K
| Adam | epoch: 012 | loss: 0.06324 - acc: 0.9883 -- iter: 576/653
[A[ATraining Step: 250  | total loss: [1m[32m0.05971[0m[0m | time: 18.520s
[2K
| Adam | epoch: 012 | loss: 0.05971 - acc: 0.9895 -- iter: 608/653
[A[ATraining Step: 251  | total loss: [1m[32m0.05510[0m[0m | time: 19.203s
[2K
| Adam | epoch: 012 | loss: 0.05510 - acc: 0.9906 -- iter: 640/653
[A[ATraining Step: 252  | total loss: [1m[32m0.05092[0m[0m | time: 20.866s
[2K
| Adam | epoch: 012 | loss: 0.05092 - acc: 0.9915 | val_loss: 0.21848 - val_acc: 0.9366 -- iter: 653/653
--
Training Step: 253  | total loss: [1m[32m0.04657[0m[0m | time: 0.708s
[2K
| Adam | epoch: 013 | loss: 0.04657 - acc: 0.9924 -- iter: 032/653
[A[ATraining Step: 254  | total loss: [1m[32m0.04270[0m[0m | time: 1.372s
[2K
| Adam | epoch: 013 | loss: 0.04270 - acc: 0.9931 -- iter: 064/653
[A[ATraining Step: 255  | total loss: [1m[32m0.04022[0m[0m | time: 2.082s
[2K
| Adam | epoch: 013 | loss: 0.04022 - acc: 0.9938 -- iter: 096/653
[A[ATraining Step: 256  | total loss: [1m[32m0.05364[0m[0m | time: 2.806s
[2K
| Adam | epoch: 013 | loss: 0.05364 - acc: 0.9913 -- iter: 128/653
[A[ATraining Step: 257  | total loss: [1m[32m0.04901[0m[0m | time: 3.512s
[2K
| Adam | epoch: 013 | loss: 0.04901 - acc: 0.9922 -- iter: 160/653
[A[ATraining Step: 258  | total loss: [1m[32m0.04577[0m[0m | time: 4.213s
[2K
| Adam | epoch: 013 | loss: 0.04577 - acc: 0.9930 -- iter: 192/653
[A[ATraining Step: 259  | total loss: [1m[32m0.04159[0m[0m | time: 4.894s
[2K
| Adam | epoch: 013 | loss: 0.04159 - acc: 0.9937 -- iter: 224/653
[A[ATraining Step: 260  | total loss: [1m[32m0.03814[0m[0m | time: 5.622s
[2K
| Adam | epoch: 013 | loss: 0.03814 - acc: 0.9943 -- iter: 256/653
[A[ATraining Step: 261  | total loss: [1m[32m0.03628[0m[0m | time: 6.334s
[2K
| Adam | epoch: 013 | loss: 0.03628 - acc: 0.9949 -- iter: 288/653
[A[ATraining Step: 262  | total loss: [1m[32m0.03367[0m[0m | time: 7.046s
[2K
| Adam | epoch: 013 | loss: 0.03367 - acc: 0.9954 -- iter: 320/653
[A[ATraining Step: 263  | total loss: [1m[32m0.03086[0m[0m | time: 7.370s
[2K
| Adam | epoch: 013 | loss: 0.03086 - acc: 0.9958 -- iter: 352/653
[A[ATraining Step: 264  | total loss: [1m[32m0.03093[0m[0m | time: 7.675s
[2K
| Adam | epoch: 013 | loss: 0.03093 - acc: 0.9963 -- iter: 384/653
[A[ATraining Step: 265  | total loss: [1m[32m0.02949[0m[0m | time: 8.349s
[2K
| Adam | epoch: 013 | loss: 0.02949 - acc: 0.9966 -- iter: 416/653
[A[ATraining Step: 266  | total loss: [1m[32m0.03022[0m[0m | time: 9.057s
[2K
| Adam | epoch: 013 | loss: 0.03022 - acc: 0.9970 -- iter: 448/653
[A[ATraining Step: 267  | total loss: [1m[32m0.02914[0m[0m | time: 10.260s
[2K
| Adam | epoch: 013 | loss: 0.02914 - acc: 0.9973 -- iter: 480/653
[A[ATraining Step: 268  | total loss: [1m[32m0.02687[0m[0m | time: 11.503s
[2K
| Adam | epoch: 013 | loss: 0.02687 - acc: 0.9975 -- iter: 512/653
[A[ATraining Step: 269  | total loss: [1m[32m0.02478[0m[0m | time: 12.869s
[2K
| Adam | epoch: 013 | loss: 0.02478 - acc: 0.9978 -- iter: 544/653
[A[ATraining Step: 270  | total loss: [1m[32m0.02346[0m[0m | time: 20.044s
[2K
| Adam | epoch: 013 | loss: 0.02346 - acc: 0.9980 -- iter: 576/653
[A[ATraining Step: 271  | total loss: [1m[32m0.02254[0m[0m | time: 21.718s
[2K
| Adam | epoch: 013 | loss: 0.02254 - acc: 0.9982 -- iter: 608/653
[A[ATraining Step: 272  | total loss: [1m[32m0.02068[0m[0m | time: 24.670s
[2K
| Adam | epoch: 013 | loss: 0.02068 - acc: 0.9984 -- iter: 640/653
[A[ATraining Step: 273  | total loss: [1m[32m0.02044[0m[0m | time: 32.174s
[2K
| Adam | epoch: 013 | loss: 0.02044 - acc: 0.9985 | val_loss: 0.23073 - val_acc: 0.9512 -- iter: 653/653
--
Training Step: 274  | total loss: [1m[32m0.01888[0m[0m | time: 1.280s
[2K
| Adam | epoch: 014 | loss: 0.01888 - acc: 0.9987 -- iter: 032/653
[A[ATraining Step: 275  | total loss: [1m[32m0.01755[0m[0m | time: 2.443s
[2K
| Adam | epoch: 014 | loss: 0.01755 - acc: 0.9988 -- iter: 064/653
[A[ATraining Step: 276  | total loss: [1m[32m0.06253[0m[0m | time: 3.543s
[2K
| Adam | epoch: 014 | loss: 0.06253 - acc: 0.9927 -- iter: 096/653
[A[ATraining Step: 277  | total loss: [1m[32m0.05665[0m[0m | time: 4.787s
[2K
| Adam | epoch: 014 | loss: 0.05665 - acc: 0.9934 -- iter: 128/653
[A[ATraining Step: 278  | total loss: [1m[32m0.05190[0m[0m | time: 5.879s
[2K
| Adam | epoch: 014 | loss: 0.05190 - acc: 0.9941 -- iter: 160/653
[A[ATraining Step: 279  | total loss: [1m[32m0.04717[0m[0m | time: 7.125s
[2K
| Adam | epoch: 014 | loss: 0.04717 - acc: 0.9947 -- iter: 192/653
[A[ATraining Step: 280  | total loss: [1m[32m0.04336[0m[0m | time: 8.645s
[2K
| Adam | epoch: 014 | loss: 0.04336 - acc: 0.9952 -- iter: 224/653
[A[ATraining Step: 281  | total loss: [1m[32m0.03964[0m[0m | time: 10.230s
[2K
| Adam | epoch: 014 | loss: 0.03964 - acc: 0.9957 -- iter: 256/653
[A[ATraining Step: 282  | total loss: [1m[32m0.03632[0m[0m | time: 17.619s
[2K
| Adam | epoch: 014 | loss: 0.03632 - acc: 0.9961 -- iter: 288/653
[A[ATraining Step: 283  | total loss: [1m[32m0.03329[0m[0m | time: 18.694s
[2K
| Adam | epoch: 014 | loss: 0.03329 - acc: 0.9965 -- iter: 320/653
[A[ATraining Step: 284  | total loss: [1m[32m0.03046[0m[0m | time: 22.818s
[2K
| Adam | epoch: 014 | loss: 0.03046 - acc: 0.9969 -- iter: 352/653
[A[ATraining Step: 285  | total loss: [1m[32m0.02824[0m[0m | time: 23.307s
[2K
| Adam | epoch: 014 | loss: 0.02824 - acc: 0.9972 -- iter: 384/653
[A[ATraining Step: 286  | total loss: [1m[32m0.02609[0m[0m | time: 23.816s
[2K
| Adam | epoch: 014 | loss: 0.02609 - acc: 0.9975 -- iter: 416/653
[A[ATraining Step: 287  | total loss: [1m[32m0.02406[0m[0m | time: 24.994s
[2K
| Adam | epoch: 014 | loss: 0.02406 - acc: 0.9977 -- iter: 448/653
[A[ATraining Step: 288  | total loss: [1m[32m0.02226[0m[0m | time: 26.488s
[2K
| Adam | epoch: 014 | loss: 0.02226 - acc: 0.9979 -- iter: 480/653
[A[ATraining Step: 289  | total loss: [1m[32m0.02065[0m[0m | time: 27.893s
[2K
| Adam | epoch: 014 | loss: 0.02065 - acc: 0.9981 -- iter: 512/653
[A[ATraining Step: 290  | total loss: [1m[32m0.01890[0m[0m | time: 29.135s
[2K
| Adam | epoch: 014 | loss: 0.01890 - acc: 0.9983 -- iter: 544/653
[A[ATraining Step: 291  | total loss: [1m[32m0.01784[0m[0m | time: 30.551s
[2K
| Adam | epoch: 014 | loss: 0.01784 - acc: 0.9985 -- iter: 576/653
[A[ATraining Step: 292  | total loss: [1m[32m0.01636[0m[0m | time: 32.050s
[2K
| Adam | epoch: 014 | loss: 0.01636 - acc: 0.9986 -- iter: 608/653
[A[ATraining Step: 293  | total loss: [1m[32m0.01513[0m[0m | time: 33.508s
[2K
| Adam | epoch: 014 | loss: 0.01513 - acc: 0.9988 -- iter: 640/653
[A[ATraining Step: 294  | total loss: [1m[32m0.01394[0m[0m | time: 46.526s
[2K
| Adam | epoch: 014 | loss: 0.01394 - acc: 0.9989 | val_loss: 0.23766 - val_acc: 0.9171 -- iter: 653/653
--
Training Step: 295  | total loss: [1m[32m0.01328[0m[0m | time: 4.598s
[2K
| Adam | epoch: 015 | loss: 0.01328 - acc: 0.9990 -- iter: 032/653
[A[ATraining Step: 296  | total loss: [1m[32m0.01261[0m[0m | time: 10.141s
[2K
| Adam | epoch: 015 | loss: 0.01261 - acc: 0.9991 -- iter: 064/653
[A[ATraining Step: 297  | total loss: [1m[32m0.01207[0m[0m | time: 15.286s
[2K
| Adam | epoch: 015 | loss: 0.01207 - acc: 0.9992 -- iter: 096/653
[A[ATraining Step: 298  | total loss: [1m[32m0.08586[0m[0m | time: 16.643s
[2K
| Adam | epoch: 015 | loss: 0.08586 - acc: 0.9868 -- iter: 128/653
[A[ATraining Step: 299  | total loss: [1m[32m0.07758[0m[0m | time: 24.636s
[2K
| Adam | epoch: 015 | loss: 0.07758 - acc: 0.9881 -- iter: 160/653
[A[ATraining Step: 300  | total loss: [1m[32m0.07184[0m[0m | time: 28.365s
[2K
| Adam | epoch: 015 | loss: 0.07184 - acc: 0.9893 -- iter: 192/653
[A[ATraining Step: 301  | total loss: [1m[32m0.07456[0m[0m | time: 29.545s
[2K
| Adam | epoch: 015 | loss: 0.07456 - acc: 0.9872 -- iter: 224/653
[A[ATraining Step: 302  | total loss: [1m[32m0.06822[0m[0m | time: 30.771s
[2K
| Adam | epoch: 015 | loss: 0.06822 - acc: 0.9885 -- iter: 256/653
[A[ATraining Step: 303  | total loss: [1m[32m0.06192[0m[0m | time: 32.272s
[2K
| Adam | epoch: 015 | loss: 0.06192 - acc: 0.9897 -- iter: 288/653
[A[ATraining Step: 304  | total loss: [1m[32m0.05683[0m[0m | time: 33.610s
[2K
| Adam | epoch: 015 | loss: 0.05683 - acc: 0.9907 -- iter: 320/653
[A[ATraining Step: 305  | total loss: [1m[32m0.05457[0m[0m | time: 34.950s
[2K
| Adam | epoch: 015 | loss: 0.05457 - acc: 0.9916 -- iter: 352/653
[A[ATraining Step: 306  | total loss: [1m[32m0.05499[0m[0m | time: 36.453s
[2K
| Adam | epoch: 015 | loss: 0.05499 - acc: 0.9925 -- iter: 384/653
[A[ATraining Step: 307  | total loss: [1m[32m0.04979[0m[0m | time: 37.180s
[2K
| Adam | epoch: 015 | loss: 0.04979 - acc: 0.9932 -- iter: 416/653
[A[ATraining Step: 308  | total loss: [1m[32m0.04527[0m[0m | time: 37.872s
[2K
| Adam | epoch: 015 | loss: 0.04527 - acc: 0.9939 -- iter: 448/653
[A[ATraining Step: 309  | total loss: [1m[32m0.04138[0m[0m | time: 42.050s
[2K
| Adam | epoch: 015 | loss: 0.04138 - acc: 0.9945 -- iter: 480/653
[A[ATraining Step: 310  | total loss: [1m[32m0.03827[0m[0m | time: 44.258s
[2K
| Adam | epoch: 015 | loss: 0.03827 - acc: 0.9951 -- iter: 512/653
[A[ATraining Step: 311  | total loss: [1m[32m0.03848[0m[0m | time: 45.532s
[2K
| Adam | epoch: 015 | loss: 0.03848 - acc: 0.9956 -- iter: 544/653
[A[ATraining Step: 312  | total loss: [1m[32m0.03558[0m[0m | time: 46.925s
[2K
| Adam | epoch: 015 | loss: 0.03558 - acc: 0.9960 -- iter: 576/653
[A[ATraining Step: 313  | total loss: [1m[32m0.03284[0m[0m | time: 48.325s
[2K
| Adam | epoch: 015 | loss: 0.03284 - acc: 0.9964 -- iter: 608/653
[A[ATraining Step: 314  | total loss: [1m[32m0.04414[0m[0m | time: 49.589s
[2K
| Adam | epoch: 015 | loss: 0.04414 - acc: 0.9905 -- iter: 640/653
[A[ATraining Step: 315  | total loss: [1m[32m0.04021[0m[0m | time: 52.751s
[2K
| Adam | epoch: 015 | loss: 0.04021 - acc: 0.9915 | val_loss: 0.33239 - val_acc: 0.9073 -- iter: 653/653
--
Validation AUC:0.971930846930847
Validation AUPRC:0.9774299130933687
Test AUC:0.9763952599388379
Test AUPRC:0.9728102629854464
BestTestF1Score	0.95	0.9	0.95	0.96	0.94	90	4	105	6	0.99
BestTestMCCScore	0.95	0.9	0.95	0.96	0.94	90	4	105	6	0.99
BestTestAccuracyScore	0.95	0.9	0.95	0.96	0.94	90	4	105	6	0.99
BestValidationF1Score	0.94	0.89	0.95	0.96	0.91	80	3	114	8	0.99
BestValidationMCC	0.94	0.89	0.95	0.96	0.91	80	3	114	8	0.99
BestValidationAccuracy	0.94	0.89	0.95	0.96	0.91	80	3	114	8	0.99
TestPredictions (Threshold:0.99)
CHEMBL296908,TN,INACT,0.5600000023841858	CHEMBL311781,TN,INACT,0.0	CHEMBL2370511,TN,INACT,0.12999999523162842	CHEMBL227600,TP,ACT,1.0	CHEMBL2372076,TN,INACT,0.05999999865889549	CHEMBL50208,TP,ACT,1.0	CHEMBL201107,FN,ACT,0.9700000286102295	CHEMBL415849,TP,ACT,1.0	CHEMBL45456,TN,INACT,0.0	CHEMBL452331,TP,ACT,1.0	CHEMBL172788,TN,INACT,0.0	CHEMBL3665436,TN,INACT,0.7900000214576721	CHEMBL389094,TP,ACT,1.0	CHEMBL207377,TP,ACT,1.0	CHEMBL316648,TN,INACT,0.009999999776482582	CHEMBL240001,TN,INACT,0.009999999776482582	CHEMBL1907840,FP,INACT,1.0	CHEMBL168632,TN,INACT,0.8100000023841858	CHEMBL344154,TN,INACT,0.03999999910593033	CHEMBL1934262,TP,ACT,1.0	CHEMBL141048,TN,INACT,0.8999999761581421	CHEMBL209121,TN,INACT,0.0	CHEMBL314320,TN,INACT,0.8500000238418579	CHEMBL330885,TN,INACT,0.0	CHEMBL312266,TN,INACT,0.019999999552965164	CHEMBL498489,TP,ACT,1.0	CHEMBL320569,TN,INACT,0.0	CHEMBL208006,TP,ACT,1.0	CHEMBL438915,TN,INACT,0.0	CHEMBL427208,TP,ACT,0.9900000095367432	CHEMBL108417,TN,INACT,0.009999999776482582	CHEMBL404280,TP,ACT,1.0	CHEMBL521454,TP,ACT,1.0	CHEMBL2163920,TN,INACT,0.9599999785423279	CHEMBL312567,TN,INACT,0.009999999776482582	CHEMBL220657,TP,ACT,1.0	CHEMBL196352,TP,ACT,1.0	CHEMBL385741,TP,ACT,1.0	CHEMBL222038,TP,ACT,1.0	CHEMBL309397,TN,INACT,0.019999999552965164	CHEMBL112877,TN,INACT,0.0	CHEMBL232946,TP,ACT,1.0	CHEMBL76860,TN,INACT,0.0	CHEMBL72841,TN,INACT,0.009999999776482582	CHEMBL227697,TP,ACT,1.0	CHEMBL2087418,TP,ACT,1.0	CHEMBL3735797,TN,INACT,0.5600000023841858	CHEMBL201210,FN,ACT,0.9800000190734863	CHEMBL496530,TP,ACT,1.0	CHEMBL177546,TN,INACT,0.009999999776482582	CHEMBL530554,TP,ACT,1.0	CHEMBL3218121,TN,INACT,0.0	CHEMBL160547,TP,ACT,1.0	CHEMBL390667,FP,INACT,1.0	CHEMBL306645,TN,INACT,0.0	CHEMBL227713,TP,ACT,1.0	CHEMBL3657631,TP,ACT,1.0	CHEMBL454086,TP,ACT,1.0	CHEMBL18797,TN,INACT,0.10000000149011612	CHEMBL314364,TN,INACT,0.5699999928474426	CHEMBL2324200,TN,INACT,0.0	CHEMBL2087435,TP,ACT,1.0	CHEMBL389054,TP,ACT,1.0	CHEMBL537834,TN,INACT,0.009999999776482582	CHEMBL442056,TP,ACT,1.0	CHEMBL1180343,TN,INACT,0.6399999856948853	CHEMBL402114,TP,ACT,1.0	CHEMBL404705,TP,ACT,1.0	CHEMBL272491,TP,ACT,1.0	CHEMBL233957,TN,INACT,0.17000000178813934	CHEMBL2018873,TP,ACT,1.0	CHEMBL42065,TN,INACT,0.7300000190734863	CHEMBL2018872,TP,ACT,1.0	CHEMBL3657628,TP,ACT,1.0	CHEMBL79030,TN,INACT,0.8600000143051147	CHEMBL2087409,TP,ACT,1.0	CHEMBL390540,TP,ACT,1.0	CHEMBL168223,TN,INACT,0.009999999776482582	CHEMBL2391356,TN,INACT,0.05000000074505806	CHEMBL450541,TP,ACT,1.0	CHEMBL1254945,TP,ACT,0.9900000095367432	CHEMBL281232,TN,INACT,0.019999999552965164	CHEMBL241514,TN,INACT,0.009999999776482582	CHEMBL2018870,TP,ACT,1.0	CHEMBL70728,TN,INACT,0.0	CHEMBL147365,TN,INACT,0.6299999952316284	CHEMBL315096,TN,INACT,0.029999999329447746	CHEMBL498488,TP,ACT,1.0	CHEMBL343969,FP,INACT,1.0	CHEMBL297473,TN,INACT,0.0	CHEMBL380117,TP,ACT,1.0	CHEMBL30525,TP,ACT,1.0	CHEMBL3657638,TP,ACT,1.0	CHEMBL1161419,TN,INACT,0.8199999928474426	CHEMBL429074,TP,ACT,1.0	CHEMBL2087412,TP,ACT,1.0	CHEMBL3657647,TP,ACT,0.9900000095367432	CHEMBL413775,TP,ACT,1.0	CHEMBL195617,TP,ACT,1.0	CHEMBL270017,TP,ACT,1.0	CHEMBL524026,TN,INACT,0.0	CHEMBL111023,TN,INACT,0.0	CHEMBL218267,TP,ACT,1.0	CHEMBL156814,TN,INACT,0.05999999865889549	CHEMBL269948,TP,ACT,1.0	CHEMBL353304,TN,INACT,0.9599999785423279	CHEMBL291293,TN,INACT,0.029999999329447746	CHEMBL309310,TN,INACT,0.0	CHEMBL1210753,TP,ACT,1.0	CHEMBL288967,TN,INACT,0.550000011920929	CHEMBL2087420,TP,ACT,1.0	CHEMBL208247,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.019999999552965164	CHEMBL1939760,TP,ACT,1.0	CHEMBL286214,TN,INACT,0.0	CHEMBL232237,TP,ACT,1.0	CHEMBL441188,TP,ACT,1.0	CHEMBL233968,TP,ACT,1.0	CHEMBL269963,TP,ACT,1.0	CHEMBL459532,FN,ACT,0.11999999731779099	CHEMBL72738,TN,INACT,0.019999999552965164	CHEMBL195883,TP,ACT,1.0	CHEMBL1210744,TP,ACT,1.0	CHEMBL297173,TN,INACT,0.6700000166893005	CHEMBL429238,TN,INACT,0.14000000059604645	CHEMBL1210750,TP,ACT,1.0	CHEMBL110695,TN,INACT,0.0	CHEMBL516024,TN,INACT,0.009999999776482582	CHEMBL307659,TN,INACT,0.009999999776482582	CHEMBL241099,TN,INACT,0.9599999785423279	CHEMBL403202,TP,ACT,1.0	CHEMBL107574,TN,INACT,0.0	CHEMBL21508,TN,INACT,0.7599999904632568	CHEMBL174463,TN,INACT,0.009999999776482582	CHEMBL423405,TN,INACT,0.05999999865889549	CHEMBL437509,TP,ACT,1.0	CHEMBL370704,TP,ACT,1.0	CHEMBL207178,TP,ACT,1.0	CHEMBL173059,TN,INACT,0.7200000286102295	CHEMBL309194,TN,INACT,0.0	CHEMBL1076554,TN,INACT,0.019999999552965164	CHEMBL104,TN,INACT,0.0	CHEMBL1777958,TP,ACT,1.0	CHEMBL452238,TP,ACT,0.9900000095367432	CHEMBL208086,TP,ACT,1.0	CHEMBL78669,TN,INACT,0.019999999552965164	CHEMBL228030,TP,ACT,1.0	CHEMBL633,TN,INACT,0.9800000190734863	CHEMBL197462,TP,ACT,1.0	CHEMBL21509,TN,INACT,0.7599999904632568	CHEMBL164968,TN,INACT,0.0	CHEMBL453340,TP,ACT,1.0	CHEMBL202090,FN,ACT,0.9800000190734863	CHEMBL171108,TN,INACT,0.9100000262260437	CHEMBL185693,TP,ACT,0.9900000095367432	CHEMBL201310,TP,ACT,1.0	CHEMBL452057,TP,ACT,1.0	CHEMBL469875,TP,ACT,1.0	CHEMBL254500,TN,INACT,0.0	CHEMBL488662,TP,ACT,1.0	CHEMBL381009,TP,ACT,0.9900000095367432	CHEMBL308414,TN,INACT,0.49000000953674316	CHEMBL2087036,TP,ACT,1.0	CHEMBL77962,TN,INACT,0.0	CHEMBL110064,TN,INACT,0.0	CHEMBL3633663,TN,INACT,0.41999998688697815	CHEMBL298203,TN,INACT,0.0	CHEMBL76949,TN,INACT,0.1599999964237213	CHEMBL3350741,TN,INACT,0.009999999776482582	CHEMBL26522,TN,INACT,0.0	CHEMBL123099,TN,INACT,0.009999999776482582	CHEMBL515170,TN,INACT,0.0	CHEMBL208387,TP,ACT,1.0	CHEMBL80945,TN,INACT,0.4000000059604645	CHEMBL2087421,TP,ACT,1.0	CHEMBL227655,TP,ACT,1.0	CHEMBL300926,TN,INACT,0.0	CHEMBL78929,TN,INACT,0.07000000029802322	CHEMBL44134,TN,INACT,0.0	CHEMBL2113087,TP,ACT,1.0	CHEMBL148967,TN,INACT,0.0	CHEMBL233721,TN,INACT,0.10999999940395355	CHEMBL170335,TN,INACT,0.6800000071525574	CHEMBL310425,TN,INACT,0.0	CHEMBL2087027,FN,ACT,0.0	CHEMBL3657617,TP,ACT,1.0	CHEMBL2398752,FP,INACT,0.9900000095367432	CHEMBL328476,TN,INACT,0.019999999552965164	CHEMBL413040,TN,INACT,0.019999999552965164	CHEMBL408846,TP,ACT,1.0	CHEMBL608811,TN,INACT,0.029999999329447746	CHEMBL272278,TP,ACT,1.0	CHEMBL319910,TN,INACT,0.0	CHEMBL460470,TN,INACT,0.009999999776482582	CHEMBL20168,TN,INACT,0.0	CHEMBL207947,TP,ACT,1.0	CHEMBL2042551,TN,INACT,0.0	CHEMBL282426,TN,INACT,0.009999999776482582	CHEMBL1934259,TP,ACT,1.0	CHEMBL109778,TN,INACT,0.0	CHEMBL76576,TN,INACT,0.009999999776482582	CHEMBL182177,TP,ACT,1.0	CHEMBL208538,FN,ACT,0.9300000071525574	CHEMBL2018866,TP,ACT,0.9900000095367432	CHEMBL78853,TN,INACT,0.029999999329447746	

