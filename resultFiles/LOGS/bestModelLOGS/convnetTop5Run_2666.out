ImageNetInceptionV2 CHEMBL5413 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	189
Number of inactive compounds :	189
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5413_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5413_adam_0.0005_15_0.6/
---------------------------------
Training samples: 240
Validation samples: 76
--
Training Step: 1  | time: 42.048s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/240
[A[ATraining Step: 2  | total loss: [1m[32m0.61682[0m[0m | time: 51.194s
[2K
| Adam | epoch: 001 | loss: 0.61682 - acc: 0.4500 -- iter: 064/240
[A[ATraining Step: 3  | total loss: [1m[32m0.95616[0m[0m | time: 60.035s
[2K
| Adam | epoch: 001 | loss: 0.95616 - acc: 0.7722 -- iter: 096/240
[A[ATraining Step: 4  | total loss: [1m[32m0.66963[0m[0m | time: 69.310s
[2K
| Adam | epoch: 001 | loss: 0.66963 - acc: 0.7321 -- iter: 128/240
[A[ATraining Step: 5  | total loss: [1m[32m0.47371[0m[0m | time: 77.848s
[2K
| Adam | epoch: 001 | loss: 0.47371 - acc: 0.8310 -- iter: 160/240
[A[ATraining Step: 6  | total loss: [1m[32m0.43518[0m[0m | time: 86.916s
[2K
| Adam | epoch: 001 | loss: 0.43518 - acc: 0.8995 -- iter: 192/240
[A[ATraining Step: 7  | total loss: [1m[32m0.33206[0m[0m | time: 95.408s
[2K
| Adam | epoch: 001 | loss: 0.33206 - acc: 0.9035 -- iter: 224/240
[A[ATraining Step: 8  | total loss: [1m[32m0.28355[0m[0m | time: 109.372s
[2K
| Adam | epoch: 001 | loss: 0.28355 - acc: 0.8875 | val_loss: 1.08962 - val_acc: 0.4342 -- iter: 240/240
--
Training Step: 9  | total loss: [1m[32m0.25431[0m[0m | time: 4.841s
[2K
| Adam | epoch: 002 | loss: 0.25431 - acc: 0.9140 -- iter: 032/240
[A[ATraining Step: 10  | total loss: [1m[32m0.16527[0m[0m | time: 20.468s
[2K
| Adam | epoch: 002 | loss: 0.16527 - acc: 0.9570 -- iter: 064/240
[A[ATraining Step: 11  | total loss: [1m[32m0.35204[0m[0m | time: 31.341s
[2K
| Adam | epoch: 002 | loss: 0.35204 - acc: 0.8737 -- iter: 096/240
[A[ATraining Step: 12  | total loss: [1m[32m0.44970[0m[0m | time: 42.268s
[2K
| Adam | epoch: 002 | loss: 0.44970 - acc: 0.8181 -- iter: 128/240
[A[ATraining Step: 13  | total loss: [1m[32m0.30486[0m[0m | time: 56.799s
[2K
| Adam | epoch: 002 | loss: 0.30486 - acc: 0.8826 -- iter: 160/240
[A[ATraining Step: 14  | total loss: [1m[32m0.20983[0m[0m | time: 72.595s
[2K
| Adam | epoch: 002 | loss: 0.20983 - acc: 0.9307 -- iter: 192/240
[A[ATraining Step: 15  | total loss: [1m[32m0.17562[0m[0m | time: 81.375s
[2K
| Adam | epoch: 002 | loss: 0.17562 - acc: 0.9456 -- iter: 224/240
[A[ATraining Step: 16  | total loss: [1m[32m0.15012[0m[0m | time: 95.513s
[2K
| Adam | epoch: 002 | loss: 0.15012 - acc: 0.9543 | val_loss: 1.36861 - val_acc: 0.5658 -- iter: 240/240
--
Training Step: 17  | total loss: [1m[32m0.15751[0m[0m | time: 6.132s
[2K
| Adam | epoch: 003 | loss: 0.15751 - acc: 0.9482 -- iter: 032/240
[A[ATraining Step: 18  | total loss: [1m[32m0.11880[0m[0m | time: 12.232s
[2K
| Adam | epoch: 003 | loss: 0.11880 - acc: 0.9661 -- iter: 064/240
[A[ATraining Step: 19  | total loss: [1m[32m0.08478[0m[0m | time: 49.367s
[2K
| Adam | epoch: 003 | loss: 0.08478 - acc: 0.9774 -- iter: 096/240
[A[ATraining Step: 20  | total loss: [1m[32m0.08577[0m[0m | time: 110.343s
[2K
| Adam | epoch: 003 | loss: 0.08577 - acc: 0.9646 -- iter: 128/240
[A[ATraining Step: 21  | total loss: [1m[32m0.07194[0m[0m | time: 153.369s
[2K
| Adam | epoch: 003 | loss: 0.07194 - acc: 0.9659 -- iter: 160/240
[A[ATraining Step: 22  | total loss: [1m[32m0.10487[0m[0m | time: 216.605s
[2K
| Adam | epoch: 003 | loss: 0.10487 - acc: 0.9667 -- iter: 192/240
[A[ATraining Step: 23  | total loss: [1m[32m0.08312[0m[0m | time: 296.102s
[2K
| Adam | epoch: 003 | loss: 0.08312 - acc: 0.9764 -- iter: 224/240
[A[ATraining Step: 24  | total loss: [1m[32m0.08967[0m[0m | time: 375.413s
[2K
| Adam | epoch: 003 | loss: 0.08967 - acc: 0.9655 | val_loss: 0.74753 - val_acc: 0.5658 -- iter: 240/240
--
Training Step: 25  | total loss: [1m[32m0.06859[0m[0m | time: 27.141s
[2K
| Adam | epoch: 004 | loss: 0.06859 - acc: 0.9749 -- iter: 032/240
[A[ATraining Step: 26  | total loss: [1m[32m0.05237[0m[0m | time: 32.798s
[2K
| Adam | epoch: 004 | loss: 0.05237 - acc: 0.9815 -- iter: 064/240
[A[ATraining Step: 27  | total loss: [1m[32m0.04110[0m[0m | time: 38.690s
[2K
| Adam | epoch: 004 | loss: 0.04110 - acc: 0.9863 -- iter: 096/240
[A[ATraining Step: 28  | total loss: [1m[32m0.03235[0m[0m | time: 95.207s
[2K
| Adam | epoch: 004 | loss: 0.03235 - acc: 0.9897 -- iter: 128/240
[A[ATraining Step: 29  | total loss: [1m[32m0.03966[0m[0m | time: 147.120s
[2K
| Adam | epoch: 004 | loss: 0.03966 - acc: 0.9846 -- iter: 160/240
[A[ATraining Step: 30  | total loss: [1m[32m0.03140[0m[0m | time: 189.746s
[2K
| Adam | epoch: 004 | loss: 0.03140 - acc: 0.9883 -- iter: 192/240
[A[ATraining Step: 31  | total loss: [1m[32m0.03136[0m[0m | time: 232.873s
[2K
| Adam | epoch: 004 | loss: 0.03136 - acc: 0.9910 -- iter: 224/240
[A[ATraining Step: 32  | total loss: [1m[32m0.03237[0m[0m | time: 260.177s
[2K
| Adam | epoch: 004 | loss: 0.03237 - acc: 0.9860 | val_loss: 0.91511 - val_acc: 0.5526 -- iter: 240/240
--
Training Step: 33  | total loss: [1m[32m0.02889[0m[0m | time: 35.505s
[2K
| Adam | epoch: 005 | loss: 0.02889 - acc: 0.9890 -- iter: 032/240
[A[ATraining Step: 34  | total loss: [1m[32m0.02462[0m[0m | time: 59.220s
[2K
| Adam | epoch: 005 | loss: 0.02462 - acc: 0.9914 -- iter: 064/240
[A[ATraining Step: 35  | total loss: [1m[32m0.02913[0m[0m | time: 65.008s
[2K
| Adam | epoch: 005 | loss: 0.02913 - acc: 0.9867 -- iter: 096/240
[A[ATraining Step: 36  | total loss: [1m[32m0.02574[0m[0m | time: 70.577s
[2K
| Adam | epoch: 005 | loss: 0.02574 - acc: 0.9894 -- iter: 128/240
[A[ATraining Step: 37  | total loss: [1m[32m0.02097[0m[0m | time: 92.924s
[2K
| Adam | epoch: 005 | loss: 0.02097 - acc: 0.9915 -- iter: 160/240
[A[ATraining Step: 38  | total loss: [1m[32m0.01778[0m[0m | time: 123.199s
[2K
| Adam | epoch: 005 | loss: 0.01778 - acc: 0.9932 -- iter: 192/240
[A[ATraining Step: 39  | total loss: [1m[32m0.03850[0m[0m | time: 137.367s
[2K
| Adam | epoch: 005 | loss: 0.03850 - acc: 0.9885 -- iter: 224/240
[A[ATraining Step: 40  | total loss: [1m[32m0.08440[0m[0m | time: 181.825s
[2K
| Adam | epoch: 005 | loss: 0.08440 - acc: 0.9848 | val_loss: 2.73575 - val_acc: 0.2500 -- iter: 240/240
--
Training Step: 41  | total loss: [1m[32m0.07008[0m[0m | time: 20.621s
[2K
| Adam | epoch: 006 | loss: 0.07008 - acc: 0.9876 -- iter: 032/240
[A[ATraining Step: 42  | total loss: [1m[32m0.05895[0m[0m | time: 41.228s
[2K
| Adam | epoch: 006 | loss: 0.05895 - acc: 0.9898 -- iter: 064/240
[A[ATraining Step: 43  | total loss: [1m[32m0.05255[0m[0m | time: 51.666s
[2K
| Adam | epoch: 006 | loss: 0.05255 - acc: 0.9916 -- iter: 096/240
[A[ATraining Step: 44  | total loss: [1m[32m0.08821[0m[0m | time: 57.313s
[2K
| Adam | epoch: 006 | loss: 0.08821 - acc: 0.9877 -- iter: 128/240
[A[ATraining Step: 45  | total loss: [1m[32m0.07407[0m[0m | time: 62.937s
[2K
| Adam | epoch: 006 | loss: 0.07407 - acc: 0.9898 -- iter: 160/240
[A[ATraining Step: 46  | total loss: [1m[32m0.06374[0m[0m | time: 80.619s
[2K
| Adam | epoch: 006 | loss: 0.06374 - acc: 0.9915 -- iter: 192/240
[A[ATraining Step: 47  | total loss: [1m[32m0.06841[0m[0m | time: 99.553s
[2K
| Adam | epoch: 006 | loss: 0.06841 - acc: 0.9826 -- iter: 224/240
[A[ATraining Step: 48  | total loss: [1m[32m0.07492[0m[0m | time: 113.881s
[2K
| Adam | epoch: 006 | loss: 0.07492 - acc: 0.9754 | val_loss: 2.30073 - val_acc: 0.4342 -- iter: 240/240
--
Training Step: 49  | total loss: [1m[32m0.09462[0m[0m | time: 15.369s
[2K
| Adam | epoch: 007 | loss: 0.09462 - acc: 0.9743 -- iter: 032/240
[A[ATraining Step: 50  | total loss: [1m[32m0.08084[0m[0m | time: 31.638s
[2K
| Adam | epoch: 007 | loss: 0.08084 - acc: 0.9783 -- iter: 064/240
[A[ATraining Step: 51  | total loss: [1m[32m0.06952[0m[0m | time: 43.058s
[2K
| Adam | epoch: 007 | loss: 0.06952 - acc: 0.9816 -- iter: 096/240
[A[ATraining Step: 52  | total loss: [1m[32m0.06048[0m[0m | time: 67.523s
[2K
| Adam | epoch: 007 | loss: 0.06048 - acc: 0.9844 -- iter: 128/240
[A[ATraining Step: 53  | total loss: [1m[32m0.05648[0m[0m | time: 73.333s
[2K
| Adam | epoch: 007 | loss: 0.05648 - acc: 0.9821 -- iter: 160/240
[A[ATraining Step: 54  | total loss: [1m[32m0.05616[0m[0m | time: 79.484s
[2K
| Adam | epoch: 007 | loss: 0.05616 - acc: 0.9847 -- iter: 192/240
[A[ATraining Step: 55  | total loss: [1m[32m0.05239[0m[0m | time: 89.665s
[2K
| Adam | epoch: 007 | loss: 0.05239 - acc: 0.9869 -- iter: 224/240
[A[ATraining Step: 56  | total loss: [1m[32m0.07305[0m[0m | time: 103.930s
[2K
| Adam | epoch: 007 | loss: 0.07305 - acc: 0.9843 | val_loss: 0.56152 - val_acc: 0.8684 -- iter: 240/240
--
Training Step: 57  | total loss: [1m[32m0.07266[0m[0m | time: 10.270s
[2K
| Adam | epoch: 008 | loss: 0.07266 - acc: 0.9822 -- iter: 032/240
[A[ATraining Step: 58  | total loss: [1m[32m0.09670[0m[0m | time: 37.093s
[2K
| Adam | epoch: 008 | loss: 0.09670 - acc: 0.9803 -- iter: 064/240
[A[ATraining Step: 59  | total loss: [1m[32m0.08555[0m[0m | time: 47.427s
[2K
| Adam | epoch: 008 | loss: 0.08555 - acc: 0.9830 -- iter: 096/240
[A[ATraining Step: 60  | total loss: [1m[32m0.07661[0m[0m | time: 58.184s
[2K
| Adam | epoch: 008 | loss: 0.07661 - acc: 0.9852 -- iter: 128/240
[A[ATraining Step: 61  | total loss: [1m[32m0.07256[0m[0m | time: 68.330s
[2K
| Adam | epoch: 008 | loss: 0.07256 - acc: 0.9831 -- iter: 160/240
[A[ATraining Step: 62  | total loss: [1m[32m0.07361[0m[0m | time: 74.421s
[2K
| Adam | epoch: 008 | loss: 0.07361 - acc: 0.9812 -- iter: 192/240
[A[ATraining Step: 63  | total loss: [1m[32m0.06495[0m[0m | time: 79.308s
[2K
| Adam | epoch: 008 | loss: 0.06495 - acc: 0.9836 -- iter: 224/240
[A[ATraining Step: 64  | total loss: [1m[32m0.05748[0m[0m | time: 94.834s
[2K
| Adam | epoch: 008 | loss: 0.05748 - acc: 0.9857 | val_loss: 2.41022 - val_acc: 0.6447 -- iter: 240/240
--
Training Step: 65  | total loss: [1m[32m0.05258[0m[0m | time: 10.374s
[2K
| Adam | epoch: 009 | loss: 0.05258 - acc: 0.9874 -- iter: 032/240
[A[ATraining Step: 66  | total loss: [1m[32m0.04828[0m[0m | time: 20.743s
[2K
| Adam | epoch: 009 | loss: 0.04828 - acc: 0.9890 -- iter: 064/240
[A[ATraining Step: 67  | total loss: [1m[32m0.10372[0m[0m | time: 49.444s
[2K
| Adam | epoch: 009 | loss: 0.10372 - acc: 0.9790 -- iter: 096/240
[A[ATraining Step: 68  | total loss: [1m[32m0.09755[0m[0m | time: 59.926s
[2K
| Adam | epoch: 009 | loss: 0.09755 - acc: 0.9778 -- iter: 128/240
[A[ATraining Step: 69  | total loss: [1m[32m0.08891[0m[0m | time: 94.962s
[2K
| Adam | epoch: 009 | loss: 0.08891 - acc: 0.9804 -- iter: 160/240
[A[ATraining Step: 70  | total loss: [1m[32m0.08161[0m[0m | time: 121.902s
[2K
| Adam | epoch: 009 | loss: 0.08161 - acc: 0.9827 -- iter: 192/240
[A[ATraining Step: 71  | total loss: [1m[32m0.08903[0m[0m | time: 127.626s
[2K
| Adam | epoch: 009 | loss: 0.08903 - acc: 0.9811 -- iter: 224/240
[A[ATraining Step: 72  | total loss: [1m[32m0.08087[0m[0m | time: 137.552s
[2K
| Adam | epoch: 009 | loss: 0.08087 - acc: 0.9832 | val_loss: 1.64971 - val_acc: 0.6842 -- iter: 240/240
--
Training Step: 73  | total loss: [1m[32m0.07344[0m[0m | time: 10.269s
[2K
| Adam | epoch: 010 | loss: 0.07344 - acc: 0.9851 -- iter: 032/240
[A[ATraining Step: 74  | total loss: [1m[32m0.07620[0m[0m | time: 26.524s
[2K
| Adam | epoch: 010 | loss: 0.07620 - acc: 0.9799 -- iter: 064/240
[A[ATraining Step: 75  | total loss: [1m[32m0.07133[0m[0m | time: 36.940s
[2K
| Adam | epoch: 010 | loss: 0.07133 - acc: 0.9820 -- iter: 096/240
[A[ATraining Step: 76  | total loss: [1m[32m0.08872[0m[0m | time: 46.998s
[2K
| Adam | epoch: 010 | loss: 0.08872 - acc: 0.9806 -- iter: 128/240
[A[ATraining Step: 77  | total loss: [1m[32m0.08024[0m[0m | time: 57.278s
[2K
| Adam | epoch: 010 | loss: 0.08024 - acc: 0.9827 -- iter: 160/240
[A[ATraining Step: 78  | total loss: [1m[32m0.08387[0m[0m | time: 76.057s
[2K
| Adam | epoch: 010 | loss: 0.08387 - acc: 0.9812 -- iter: 192/240
[A[ATraining Step: 79  | total loss: [1m[32m0.07788[0m[0m | time: 85.664s
[2K
| Adam | epoch: 010 | loss: 0.07788 - acc: 0.9832 -- iter: 224/240
[A[ATraining Step: 80  | total loss: [1m[32m0.07460[0m[0m | time: 95.585s
[2K
| Adam | epoch: 010 | loss: 0.07460 - acc: 0.9817 | val_loss: 0.65842 - val_acc: 0.8421 -- iter: 240/240
--
Training Step: 81  | total loss: [1m[32m0.07189[0m[0m | time: 4.953s
[2K
| Adam | epoch: 011 | loss: 0.07189 - acc: 0.9835 -- iter: 032/240
[A[ATraining Step: 82  | total loss: [1m[32m0.06651[0m[0m | time: 15.661s
[2K
| Adam | epoch: 011 | loss: 0.06651 - acc: 0.9852 -- iter: 064/240
[A[ATraining Step: 83  | total loss: [1m[32m0.07467[0m[0m | time: 35.776s
[2K
| Adam | epoch: 011 | loss: 0.07467 - acc: 0.9835 -- iter: 096/240
[A[ATraining Step: 84  | total loss: [1m[32m0.06920[0m[0m | time: 52.310s
[2K
| Adam | epoch: 011 | loss: 0.06920 - acc: 0.9852 -- iter: 128/240
[A[ATraining Step: 85  | total loss: [1m[32m0.08019[0m[0m | time: 62.197s
[2K
| Adam | epoch: 011 | loss: 0.08019 - acc: 0.9835 -- iter: 160/240
[A[ATraining Step: 86  | total loss: [1m[32m0.07363[0m[0m | time: 72.714s
[2K
| Adam | epoch: 011 | loss: 0.07363 - acc: 0.9852 -- iter: 192/240
[A[ATraining Step: 87  | total loss: [1m[32m0.06738[0m[0m | time: 82.352s
[2K
| Adam | epoch: 011 | loss: 0.06738 - acc: 0.9867 -- iter: 224/240
[A[ATraining Step: 88  | total loss: [1m[32m0.06436[0m[0m | time: 96.959s
[2K
| Adam | epoch: 011 | loss: 0.06436 - acc: 0.9880 | val_loss: 0.36026 - val_acc: 0.9079 -- iter: 240/240
--
Training Step: 89  | total loss: [1m[32m0.06447[0m[0m | time: 5.837s
[2K
| Adam | epoch: 012 | loss: 0.06447 - acc: 0.9861 -- iter: 032/240
[A[ATraining Step: 90  | total loss: [1m[32m0.05840[0m[0m | time: 11.678s
[2K
| Adam | epoch: 012 | loss: 0.05840 - acc: 0.9875 -- iter: 064/240
[A[ATraining Step: 91  | total loss: [1m[32m0.05294[0m[0m | time: 22.058s
[2K
| Adam | epoch: 012 | loss: 0.05294 - acc: 0.9887 -- iter: 096/240
[A[ATraining Step: 92  | total loss: [1m[32m0.06207[0m[0m | time: 35.032s
[2K
| Adam | epoch: 012 | loss: 0.06207 - acc: 0.9805 -- iter: 128/240
[A[ATraining Step: 93  | total loss: [1m[32m0.05833[0m[0m | time: 61.419s
[2K
| Adam | epoch: 012 | loss: 0.05833 - acc: 0.9824 -- iter: 160/240
[A[ATraining Step: 94  | total loss: [1m[32m0.05290[0m[0m | time: 71.419s
[2K
| Adam | epoch: 012 | loss: 0.05290 - acc: 0.9842 -- iter: 192/240
[A[ATraining Step: 95  | total loss: [1m[32m0.05054[0m[0m | time: 85.005s
[2K
| Adam | epoch: 012 | loss: 0.05054 - acc: 0.9858 -- iter: 224/240
[A[ATraining Step: 96  | total loss: [1m[32m0.04669[0m[0m | time: 99.343s
[2K
| Adam | epoch: 012 | loss: 0.04669 - acc: 0.9872 | val_loss: 0.88291 - val_acc: 0.7368 -- iter: 240/240
--
Training Step: 97  | total loss: [1m[32m0.04998[0m[0m | time: 10.160s
[2K
| Adam | epoch: 013 | loss: 0.04998 - acc: 0.9853 -- iter: 032/240
[A[ATraining Step: 98  | total loss: [1m[32m0.04608[0m[0m | time: 15.874s
[2K
| Adam | epoch: 013 | loss: 0.04608 - acc: 0.9868 -- iter: 064/240
[A[ATraining Step: 99  | total loss: [1m[32m0.04167[0m[0m | time: 21.645s
[2K
| Adam | epoch: 013 | loss: 0.04167 - acc: 0.9881 -- iter: 096/240
[A[ATraining Step: 100  | total loss: [1m[32m0.03769[0m[0m | time: 45.013s
[2K
| Adam | epoch: 013 | loss: 0.03769 - acc: 0.9893 -- iter: 128/240
[A[ATraining Step: 101  | total loss: [1m[32m0.03623[0m[0m | time: 62.037s
[2K
| Adam | epoch: 013 | loss: 0.03623 - acc: 0.9904 -- iter: 160/240
[A[ATraining Step: 102  | total loss: [1m[32m0.03319[0m[0m | time: 71.770s
[2K
| Adam | epoch: 013 | loss: 0.03319 - acc: 0.9913 -- iter: 192/240
[A[ATraining Step: 103  | total loss: [1m[32m0.05437[0m[0m | time: 81.676s
[2K
| Adam | epoch: 013 | loss: 0.05437 - acc: 0.9891 -- iter: 224/240
[A[ATraining Step: 104  | total loss: [1m[32m0.05072[0m[0m | time: 95.989s
[2K
| Adam | epoch: 013 | loss: 0.05072 - acc: 0.9902 | val_loss: 0.60352 - val_acc: 0.8553 -- iter: 240/240
--
Training Step: 105  | total loss: [1m[32m0.07023[0m[0m | time: 11.523s
[2K
| Adam | epoch: 014 | loss: 0.07023 - acc: 0.9818 -- iter: 032/240
[A[ATraining Step: 106  | total loss: [1m[32m0.06445[0m[0m | time: 23.071s
[2K
| Adam | epoch: 014 | loss: 0.06445 - acc: 0.9836 -- iter: 064/240
[A[ATraining Step: 107  | total loss: [1m[32m0.05848[0m[0m | time: 28.630s
[2K
| Adam | epoch: 014 | loss: 0.05848 - acc: 0.9852 -- iter: 096/240
[A[ATraining Step: 108  | total loss: [1m[32m0.05338[0m[0m | time: 34.404s
[2K
| Adam | epoch: 014 | loss: 0.05338 - acc: 0.9867 -- iter: 128/240
[A[ATraining Step: 109  | total loss: [1m[32m0.04897[0m[0m | time: 44.652s
[2K
| Adam | epoch: 014 | loss: 0.04897 - acc: 0.9880 -- iter: 160/240
[A[ATraining Step: 110  | total loss: [1m[32m0.04479[0m[0m | time: 54.603s
[2K
| Adam | epoch: 014 | loss: 0.04479 - acc: 0.9892 -- iter: 192/240
[A[ATraining Step: 111  | total loss: [1m[32m0.04076[0m[0m | time: 65.913s
[2K
| Adam | epoch: 014 | loss: 0.04076 - acc: 0.9903 -- iter: 224/240
[A[ATraining Step: 112  | total loss: [1m[32m0.03822[0m[0m | time: 89.192s
[2K
| Adam | epoch: 014 | loss: 0.03822 - acc: 0.9913 | val_loss: 1.89535 - val_acc: 0.5526 -- iter: 240/240
--
Training Step: 113  | total loss: [1m[32m0.03504[0m[0m | time: 10.324s
[2K
| Adam | epoch: 015 | loss: 0.03504 - acc: 0.9922 -- iter: 032/240
[A[ATraining Step: 114  | total loss: [1m[32m0.03769[0m[0m | time: 20.424s
[2K
| Adam | epoch: 015 | loss: 0.03769 - acc: 0.9929 -- iter: 064/240
[A[ATraining Step: 115  | total loss: [1m[32m0.03515[0m[0m | time: 34.200s
[2K
| Adam | epoch: 015 | loss: 0.03515 - acc: 0.9936 -- iter: 096/240
[A[ATraining Step: 116  | total loss: [1m[32m0.03253[0m[0m | time: 40.315s
[2K
| Adam | epoch: 015 | loss: 0.03253 - acc: 0.9943 -- iter: 128/240
[A[ATraining Step: 117  | total loss: [1m[32m0.02999[0m[0m | time: 45.408s
[2K
| Adam | epoch: 015 | loss: 0.02999 - acc: 0.9949 -- iter: 160/240
[A[ATraining Step: 118  | total loss: [1m[32m0.02756[0m[0m | time: 55.536s
[2K
| Adam | epoch: 015 | loss: 0.02756 - acc: 0.9954 -- iter: 192/240
[A[ATraining Step: 119  | total loss: [1m[32m0.02523[0m[0m | time: 65.734s
[2K
| Adam | epoch: 015 | loss: 0.02523 - acc: 0.9958 -- iter: 224/240
[A[ATraining Step: 120  | total loss: [1m[32m0.02335[0m[0m | time: 80.556s
[2K
| Adam | epoch: 015 | loss: 0.02335 - acc: 0.9962 | val_loss: 0.39757 - val_acc: 0.9211 -- iter: 240/240
--
Validation AUC:0.9640591966173362
Validation AUPRC:0.9769936734606065
Test AUC:0.9916376306620209
Test AUPRC:0.9936160384331117
BestTestF1Score	0.96	0.92	0.96	0.98	0.95	39	1	34	2	0.87
BestTestMCCScore	0.96	0.92	0.96	0.98	0.95	39	1	34	2	0.87
BestTestAccuracyScore	0.96	0.92	0.96	0.98	0.95	39	1	34	2	0.87
BestValidationF1Score	0.93	0.84	0.92	0.95	0.91	39	2	31	4	0.87
BestValidationMCC	0.93	0.84	0.92	0.95	0.91	39	2	31	4	0.87
BestValidationAccuracy	0.93	0.84	0.92	0.95	0.91	39	2	31	4	0.87
TestPredictions (Threshold:0.87)
CHEMBL233552,TN,INACT,0.0	CHEMBL3422410,TP,ACT,1.0	CHEMBL3085811,FN,ACT,0.03999999910593033	CHEMBL1171484,TP,ACT,1.0	CHEMBL545363,TN,INACT,0.0	CHEMBL3645501,FN,ACT,0.0	CHEMBL80317,TN,INACT,0.0	CHEMBL1163736,TP,ACT,1.0	CHEMBL453,TN,INACT,0.0	CHEMBL374295,TP,ACT,1.0	CHEMBL76949,TN,INACT,0.0	CHEMBL3314207,TP,ACT,1.0	CHEMBL374748,TP,ACT,1.0	CHEMBL40317,TN,INACT,0.0	CHEMBL39879,TN,INACT,0.0	CHEMBL2113072,TN,INACT,0.05999999865889549	CHEMBL441305,TN,INACT,0.0	CHEMBL172788,TN,INACT,0.0	CHEMBL3314223,TP,ACT,1.0	CHEMBL2042403,TN,INACT,0.0	CHEMBL3645503,TP,ACT,0.9399999976158142	CHEMBL2370511,TN,INACT,0.0	CHEMBL109206,TN,INACT,0.07000000029802322	CHEMBL162095,TN,INACT,0.0	CHEMBL2151651,TP,ACT,1.0	CHEMBL40986,TN,INACT,0.0	CHEMBL322537,TN,INACT,0.009999999776482582	CHEMBL15936,TN,INACT,0.0	CHEMBL112877,TN,INACT,0.0	CHEMBL2151655,TP,ACT,1.0	CHEMBL3086284,TP,ACT,0.949999988079071	CHEMBL462650,TN,INACT,0.0	CHEMBL59597,TN,INACT,0.0	CHEMBL1164153,TP,ACT,1.0	CHEMBL26522,TN,INACT,0.0	CHEMBL175698,FP,INACT,0.8899999856948853	CHEMBL1164673,TP,ACT,1.0	CHEMBL1170684,TP,ACT,0.9800000190734863	CHEMBL3109772,TN,INACT,0.0	CHEMBL1163808,TP,ACT,0.9399999976158142	CHEMBL1165432,TP,ACT,1.0	CHEMBL2151645,TP,ACT,1.0	CHEMBL3086283,TP,ACT,1.0	CHEMBL1173512,TP,ACT,0.949999988079071	CHEMBL3633656,TN,INACT,0.0	CHEMBL220855,TP,ACT,1.0	CHEMBL1164939,TP,ACT,1.0	CHEMBL3314213,TP,ACT,1.0	CHEMBL3314208,TP,ACT,1.0	CHEMBL415879,TN,INACT,0.0	CHEMBL320254,TN,INACT,0.0	CHEMBL3087929,TP,ACT,1.0	CHEMBL1165100,TP,ACT,1.0	CHEMBL1164154,TN,INACT,0.3100000023841858	CHEMBL374260,TP,ACT,1.0	CHEMBL594801,TN,INACT,0.0	CHEMBL3085808,TP,ACT,1.0	CHEMBL42065,TN,INACT,0.009999999776482582	CHEMBL1170904,TP,ACT,1.0	CHEMBL3085807,TP,ACT,1.0	CHEMBL95727,TN,INACT,0.009999999776482582	CHEMBL3422413,TP,ACT,1.0	CHEMBL310427,TN,INACT,0.0	CHEMBL128360,TN,INACT,0.0	CHEMBL421523,TN,INACT,0.0	CHEMBL373854,TP,ACT,1.0	CHEMBL2151647,TP,ACT,0.8700000047683716	CHEMBL386958,TP,ACT,1.0	CHEMBL435922,TP,ACT,1.0	CHEMBL297173,TN,INACT,0.0	CHEMBL221817,TP,ACT,1.0	CHEMBL1163809,TP,ACT,1.0	CHEMBL2151643,TP,ACT,1.0	CHEMBL1164988,TP,ACT,1.0	CHEMBL9746,TN,INACT,0.0	CHEMBL450923,TP,ACT,1.0	

