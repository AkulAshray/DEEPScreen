CNNModel CHEMBL2801 adam 0.0005 30 128 0 0.6 False True
Number of active compounds :	119
Number of inactive compounds :	119
---------------------------------
Run id: CNNModel_CHEMBL2801_adam_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2801_adam_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 150
Validation samples: 47
--
Training Step: 1  | time: 0.786s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/150
[A[ATraining Step: 2  | total loss: [1m[32m0.62416[0m[0m | time: 1.403s
[2K
| Adam | epoch: 001 | loss: 0.62416 - acc: 0.3375 -- iter: 064/150
[A[ATraining Step: 3  | total loss: [1m[32m0.68059[0m[0m | time: 2.008s
[2K
| Adam | epoch: 001 | loss: 0.68059 - acc: 0.4960 -- iter: 096/150
[A[ATraining Step: 4  | total loss: [1m[32m0.69081[0m[0m | time: 2.639s
[2K
| Adam | epoch: 001 | loss: 0.69081 - acc: 0.4521 -- iter: 128/150
[A[ATraining Step: 5  | total loss: [1m[32m0.69117[0m[0m | time: 4.112s
[2K
| Adam | epoch: 001 | loss: 0.69117 - acc: 0.6151 | val_loss: 0.69420 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 6  | total loss: [1m[32m0.69043[0m[0m | time: 0.458s
[2K
| Adam | epoch: 002 | loss: 0.69043 - acc: 0.6580 -- iter: 032/150
[A[ATraining Step: 7  | total loss: [1m[32m0.68823[0m[0m | time: 1.113s
[2K
| Adam | epoch: 002 | loss: 0.68823 - acc: 0.6723 -- iter: 064/150
[A[ATraining Step: 8  | total loss: [1m[32m0.69714[0m[0m | time: 1.744s
[2K
| Adam | epoch: 002 | loss: 0.69714 - acc: 0.4875 -- iter: 096/150
[A[ATraining Step: 9  | total loss: [1m[32m0.69648[0m[0m | time: 2.377s
[2K
| Adam | epoch: 002 | loss: 0.69648 - acc: 0.4776 -- iter: 128/150
[A[ATraining Step: 10  | total loss: [1m[32m0.69309[0m[0m | time: 3.991s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5200 | val_loss: 0.69516 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 11  | total loss: [1m[32m0.69215[0m[0m | time: 0.971s
[2K
| Adam | epoch: 003 | loss: 0.69215 - acc: 0.5253 -- iter: 032/150
[A[ATraining Step: 12  | total loss: [1m[32m0.69029[0m[0m | time: 1.839s
[2K
| Adam | epoch: 003 | loss: 0.69029 - acc: 0.5548 -- iter: 064/150
[A[ATraining Step: 13  | total loss: [1m[32m0.68939[0m[0m | time: 3.006s
[2K
| Adam | epoch: 003 | loss: 0.68939 - acc: 0.5703 -- iter: 096/150
[A[ATraining Step: 14  | total loss: [1m[32m0.69106[0m[0m | time: 4.042s
[2K
| Adam | epoch: 003 | loss: 0.69106 - acc: 0.5415 -- iter: 128/150
[A[ATraining Step: 15  | total loss: [1m[32m0.69595[0m[0m | time: 6.168s
[2K
| Adam | epoch: 003 | loss: 0.69595 - acc: 0.4886 | val_loss: 0.69639 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 16  | total loss: [1m[32m0.69273[0m[0m | time: 1.084s
[2K
| Adam | epoch: 004 | loss: 0.69273 - acc: 0.5163 -- iter: 032/150
[A[ATraining Step: 17  | total loss: [1m[32m0.69507[0m[0m | time: 1.851s
[2K
| Adam | epoch: 004 | loss: 0.69507 - acc: 0.4879 -- iter: 064/150
[A[ATraining Step: 18  | total loss: [1m[32m0.69064[0m[0m | time: 2.667s
[2K
| Adam | epoch: 004 | loss: 0.69064 - acc: 0.5393 -- iter: 096/150
[A[ATraining Step: 19  | total loss: [1m[32m0.68759[0m[0m | time: 3.813s
[2K
| Adam | epoch: 004 | loss: 0.68759 - acc: 0.5717 -- iter: 128/150
[A[ATraining Step: 20  | total loss: [1m[32m0.69047[0m[0m | time: 5.855s
[2K
| Adam | epoch: 004 | loss: 0.69047 - acc: 0.5386 | val_loss: 0.69733 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 21  | total loss: [1m[32m0.69178[0m[0m | time: 0.610s
[2K
| Adam | epoch: 005 | loss: 0.69178 - acc: 0.5266 -- iter: 032/150
[A[ATraining Step: 22  | total loss: [1m[32m0.69329[0m[0m | time: 1.233s
[2K
| Adam | epoch: 005 | loss: 0.69329 - acc: 0.5093 -- iter: 064/150
[A[ATraining Step: 23  | total loss: [1m[32m0.69162[0m[0m | time: 1.669s
[2K
| Adam | epoch: 005 | loss: 0.69162 - acc: 0.5247 -- iter: 096/150
[A[ATraining Step: 24  | total loss: [1m[32m0.69929[0m[0m | time: 2.108s
[2K
| Adam | epoch: 005 | loss: 0.69929 - acc: 0.4538 -- iter: 128/150
[A[ATraining Step: 25  | total loss: [1m[32m0.70313[0m[0m | time: 3.771s
[2K
| Adam | epoch: 005 | loss: 0.70313 - acc: 0.4044 | val_loss: 0.69429 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 26  | total loss: [1m[32m0.69786[0m[0m | time: 0.643s
[2K
| Adam | epoch: 006 | loss: 0.69786 - acc: 0.4711 -- iter: 032/150
[A[ATraining Step: 27  | total loss: [1m[32m0.69612[0m[0m | time: 1.259s
[2K
| Adam | epoch: 006 | loss: 0.69612 - acc: 0.4866 -- iter: 064/150
[A[ATraining Step: 28  | total loss: [1m[32m0.69580[0m[0m | time: 1.878s
[2K
| Adam | epoch: 006 | loss: 0.69580 - acc: 0.4743 -- iter: 096/150
[A[ATraining Step: 29  | total loss: [1m[32m0.69442[0m[0m | time: 2.292s
[2K
| Adam | epoch: 006 | loss: 0.69442 - acc: 0.4958 -- iter: 128/150
[A[ATraining Step: 30  | total loss: [1m[32m0.69406[0m[0m | time: 3.746s
[2K
| Adam | epoch: 006 | loss: 0.69406 - acc: 0.4968 | val_loss: 0.69354 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 31  | total loss: [1m[32m0.69374[0m[0m | time: 0.607s
[2K
| Adam | epoch: 007 | loss: 0.69374 - acc: 0.4975 -- iter: 032/150
[A[ATraining Step: 32  | total loss: [1m[32m0.69297[0m[0m | time: 1.224s
[2K
| Adam | epoch: 007 | loss: 0.69297 - acc: 0.5192 -- iter: 064/150
[A[ATraining Step: 33  | total loss: [1m[32m0.69305[0m[0m | time: 1.859s
[2K
| Adam | epoch: 007 | loss: 0.69305 - acc: 0.5081 -- iter: 096/150
[A[ATraining Step: 34  | total loss: [1m[32m0.69350[0m[0m | time: 2.470s
[2K
| Adam | epoch: 007 | loss: 0.69350 - acc: 0.4863 -- iter: 128/150
[A[ATraining Step: 35  | total loss: [1m[32m0.69309[0m[0m | time: 3.905s
[2K
| Adam | epoch: 007 | loss: 0.69309 - acc: 0.4957 | val_loss: 0.69312 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 36  | total loss: [1m[32m0.69200[0m[0m | time: 0.431s
[2K
| Adam | epoch: 008 | loss: 0.69200 - acc: 0.5431 -- iter: 032/150
[A[ATraining Step: 37  | total loss: [1m[32m0.69093[0m[0m | time: 1.041s
[2K
| Adam | epoch: 008 | loss: 0.69093 - acc: 0.5799 -- iter: 064/150
[A[ATraining Step: 38  | total loss: [1m[32m0.69115[0m[0m | time: 1.659s
[2K
| Adam | epoch: 008 | loss: 0.69115 - acc: 0.5643 -- iter: 096/150
[A[ATraining Step: 39  | total loss: [1m[32m0.69154[0m[0m | time: 2.286s
[2K
| Adam | epoch: 008 | loss: 0.69154 - acc: 0.5460 -- iter: 128/150
[A[ATraining Step: 40  | total loss: [1m[32m0.69023[0m[0m | time: 3.921s
[2K
| Adam | epoch: 008 | loss: 0.69023 - acc: 0.5725 | val_loss: 0.69354 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 41  | total loss: [1m[32m0.69045[0m[0m | time: 0.481s
[2K
| Adam | epoch: 009 | loss: 0.69045 - acc: 0.5592 -- iter: 032/150
[A[ATraining Step: 42  | total loss: [1m[32m0.69198[0m[0m | time: 0.921s
[2K
| Adam | epoch: 009 | loss: 0.69198 - acc: 0.5240 -- iter: 064/150
[A[ATraining Step: 43  | total loss: [1m[32m0.69323[0m[0m | time: 1.531s
[2K
| Adam | epoch: 009 | loss: 0.69323 - acc: 0.4957 -- iter: 096/150
[A[ATraining Step: 44  | total loss: [1m[32m0.69338[0m[0m | time: 2.145s
[2K
| Adam | epoch: 009 | loss: 0.69338 - acc: 0.4856 -- iter: 128/150
[A[ATraining Step: 45  | total loss: [1m[32m0.69278[0m[0m | time: 3.774s
[2K
| Adam | epoch: 009 | loss: 0.69278 - acc: 0.4934 | val_loss: 0.69147 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 46  | total loss: [1m[32m0.69301[0m[0m | time: 0.638s
[2K
| Adam | epoch: 010 | loss: 0.69301 - acc: 0.4736 -- iter: 032/150
[A[ATraining Step: 47  | total loss: [1m[32m0.69271[0m[0m | time: 1.073s
[2K
| Adam | epoch: 010 | loss: 0.69271 - acc: 0.4780 -- iter: 064/150
[A[ATraining Step: 48  | total loss: [1m[32m0.69257[0m[0m | time: 1.501s
[2K
| Adam | epoch: 010 | loss: 0.69257 - acc: 0.4742 -- iter: 096/150
[A[ATraining Step: 49  | total loss: [1m[32m0.69240[0m[0m | time: 2.146s
[2K
| Adam | epoch: 010 | loss: 0.69240 - acc: 0.4854 -- iter: 128/150
[A[ATraining Step: 50  | total loss: [1m[32m0.69190[0m[0m | time: 3.776s
[2K
| Adam | epoch: 010 | loss: 0.69190 - acc: 0.5119 | val_loss: 0.68801 - val_acc: 0.4894 -- iter: 150/150
--
Training Step: 51  | total loss: [1m[32m0.69074[0m[0m | time: 0.631s
[2K
| Adam | epoch: 011 | loss: 0.69074 - acc: 0.5530 -- iter: 032/150
[A[ATraining Step: 52  | total loss: [1m[32m0.69059[0m[0m | time: 1.247s
[2K
| Adam | epoch: 011 | loss: 0.69059 - acc: 0.5591 -- iter: 064/150
[A[ATraining Step: 53  | total loss: [1m[32m0.69002[0m[0m | time: 1.687s
[2K
| Adam | epoch: 011 | loss: 0.69002 - acc: 0.5458 -- iter: 096/150
[A[ATraining Step: 54  | total loss: [1m[32m0.68975[0m[0m | time: 2.120s
[2K
| Adam | epoch: 011 | loss: 0.68975 - acc: 0.5326 -- iter: 128/150
[A[ATraining Step: 55  | total loss: [1m[32m0.68914[0m[0m | time: 3.738s
[2K
| Adam | epoch: 011 | loss: 0.68914 - acc: 0.5214 | val_loss: 0.67896 - val_acc: 0.5957 -- iter: 150/150
--
Training Step: 56  | total loss: [1m[32m0.68666[0m[0m | time: 0.639s
[2K
| Adam | epoch: 012 | loss: 0.68666 - acc: 0.5580 -- iter: 032/150
[A[ATraining Step: 57  | total loss: [1m[32m0.68577[0m[0m | time: 1.250s
[2K
| Adam | epoch: 012 | loss: 0.68577 - acc: 0.5586 -- iter: 064/150
[A[ATraining Step: 58  | total loss: [1m[32m0.68318[0m[0m | time: 1.863s
[2K
| Adam | epoch: 012 | loss: 0.68318 - acc: 0.5847 -- iter: 096/150
[A[ATraining Step: 59  | total loss: [1m[32m0.67936[0m[0m | time: 2.298s
[2K
| Adam | epoch: 012 | loss: 0.67936 - acc: 0.6111 -- iter: 128/150
[A[ATraining Step: 60  | total loss: [1m[32m0.67470[0m[0m | time: 3.743s
[2K
| Adam | epoch: 012 | loss: 0.67470 - acc: 0.6445 | val_loss: 0.67415 - val_acc: 0.4681 -- iter: 150/150
--
Training Step: 61  | total loss: [1m[32m0.66838[0m[0m | time: 0.615s
[2K
| Adam | epoch: 013 | loss: 0.66838 - acc: 0.6494 -- iter: 032/150
[A[ATraining Step: 62  | total loss: [1m[32m0.67075[0m[0m | time: 1.204s
[2K
| Adam | epoch: 013 | loss: 0.67075 - acc: 0.6221 -- iter: 064/150
[A[ATraining Step: 63  | total loss: [1m[32m0.67085[0m[0m | time: 1.809s
[2K
| Adam | epoch: 013 | loss: 0.67085 - acc: 0.6185 -- iter: 096/150
[A[ATraining Step: 64  | total loss: [1m[32m0.66300[0m[0m | time: 2.433s
[2K
| Adam | epoch: 013 | loss: 0.66300 - acc: 0.6272 -- iter: 128/150
[A[ATraining Step: 65  | total loss: [1m[32m0.65860[0m[0m | time: 3.892s
[2K
| Adam | epoch: 013 | loss: 0.65860 - acc: 0.6385 | val_loss: 0.60875 - val_acc: 0.7234 -- iter: 150/150
--
Training Step: 66  | total loss: [1m[32m0.65040[0m[0m | time: 0.455s
[2K
| Adam | epoch: 014 | loss: 0.65040 - acc: 0.6493 -- iter: 032/150
[A[ATraining Step: 67  | total loss: [1m[32m0.64049[0m[0m | time: 1.070s
[2K
| Adam | epoch: 014 | loss: 0.64049 - acc: 0.6532 -- iter: 064/150
[A[ATraining Step: 68  | total loss: [1m[32m0.64477[0m[0m | time: 1.740s
[2K
| Adam | epoch: 014 | loss: 0.64477 - acc: 0.6572 -- iter: 096/150
[A[ATraining Step: 69  | total loss: [1m[32m0.63744[0m[0m | time: 2.347s
[2K
| Adam | epoch: 014 | loss: 0.63744 - acc: 0.6754 -- iter: 128/150
[A[ATraining Step: 70  | total loss: [1m[32m0.63157[0m[0m | time: 3.963s
[2K
| Adam | epoch: 014 | loss: 0.63157 - acc: 0.6696 | val_loss: 0.55160 - val_acc: 0.7660 -- iter: 150/150
--
Training Step: 71  | total loss: [1m[32m0.62480[0m[0m | time: 0.448s
[2K
| Adam | epoch: 015 | loss: 0.62480 - acc: 0.6716 -- iter: 032/150
[A[ATraining Step: 72  | total loss: [1m[32m0.61312[0m[0m | time: 0.872s
[2K
| Adam | epoch: 015 | loss: 0.61312 - acc: 0.6779 -- iter: 064/150
[A[ATraining Step: 73  | total loss: [1m[32m0.60063[0m[0m | time: 1.467s
[2K
| Adam | epoch: 015 | loss: 0.60063 - acc: 0.6884 -- iter: 096/150
[A[ATraining Step: 74  | total loss: [1m[32m0.58483[0m[0m | time: 2.086s
[2K
| Adam | epoch: 015 | loss: 0.58483 - acc: 0.7020 -- iter: 128/150
[A[ATraining Step: 75  | total loss: [1m[32m0.58176[0m[0m | time: 3.703s
[2K
| Adam | epoch: 015 | loss: 0.58176 - acc: 0.7072 | val_loss: 0.55898 - val_acc: 0.7234 -- iter: 150/150
--
Training Step: 76  | total loss: [1m[32m0.56996[0m[0m | time: 0.619s
[2K
| Adam | epoch: 016 | loss: 0.56996 - acc: 0.7118 -- iter: 032/150
[A[ATraining Step: 77  | total loss: [1m[32m0.56848[0m[0m | time: 1.067s
[2K
| Adam | epoch: 016 | loss: 0.56848 - acc: 0.7125 -- iter: 064/150
[A[ATraining Step: 78  | total loss: [1m[32m0.57560[0m[0m | time: 1.508s
[2K
| Adam | epoch: 016 | loss: 0.57560 - acc: 0.6998 -- iter: 096/150
[A[ATraining Step: 79  | total loss: [1m[32m0.56114[0m[0m | time: 2.115s
[2K
| Adam | epoch: 016 | loss: 0.56114 - acc: 0.7074 -- iter: 128/150
[A[ATraining Step: 80  | total loss: [1m[32m0.58283[0m[0m | time: 3.757s
[2K
| Adam | epoch: 016 | loss: 0.58283 - acc: 0.6957 | val_loss: 0.81002 - val_acc: 0.5745 -- iter: 150/150
--
Training Step: 81  | total loss: [1m[32m0.58904[0m[0m | time: 0.733s
[2K
| Adam | epoch: 017 | loss: 0.58904 - acc: 0.6981 -- iter: 032/150
[A[ATraining Step: 82  | total loss: [1m[32m0.57550[0m[0m | time: 1.350s
[2K
| Adam | epoch: 017 | loss: 0.57550 - acc: 0.7033 -- iter: 064/150
[A[ATraining Step: 83  | total loss: [1m[32m0.58161[0m[0m | time: 1.774s
[2K
| Adam | epoch: 017 | loss: 0.58161 - acc: 0.6986 -- iter: 096/150
[A[ATraining Step: 84  | total loss: [1m[32m0.56967[0m[0m | time: 2.201s
[2K
| Adam | epoch: 017 | loss: 0.56967 - acc: 0.7151 -- iter: 128/150
[A[ATraining Step: 85  | total loss: [1m[32m0.56390[0m[0m | time: 3.827s
[2K
| Adam | epoch: 017 | loss: 0.56390 - acc: 0.7163 | val_loss: 0.51579 - val_acc: 0.7872 -- iter: 150/150
--
Training Step: 86  | total loss: [1m[32m0.55836[0m[0m | time: 0.631s
[2K
| Adam | epoch: 018 | loss: 0.55836 - acc: 0.7165 -- iter: 032/150
[A[ATraining Step: 87  | total loss: [1m[32m0.53996[0m[0m | time: 1.239s
[2K
| Adam | epoch: 018 | loss: 0.53996 - acc: 0.7355 -- iter: 064/150
[A[ATraining Step: 88  | total loss: [1m[32m0.53075[0m[0m | time: 1.866s
[2K
| Adam | epoch: 018 | loss: 0.53075 - acc: 0.7432 -- iter: 096/150
[A[ATraining Step: 89  | total loss: [1m[32m0.51345[0m[0m | time: 2.295s
[2K
| Adam | epoch: 018 | loss: 0.51345 - acc: 0.7595 -- iter: 128/150
[A[ATraining Step: 90  | total loss: [1m[32m0.50189[0m[0m | time: 3.743s
[2K
| Adam | epoch: 018 | loss: 0.50189 - acc: 0.7654 | val_loss: 0.56066 - val_acc: 0.7234 -- iter: 150/150
--
Training Step: 91  | total loss: [1m[32m0.48993[0m[0m | time: 0.618s
[2K
| Adam | epoch: 019 | loss: 0.48993 - acc: 0.7707 -- iter: 032/150
[A[ATraining Step: 92  | total loss: [1m[32m0.48267[0m[0m | time: 1.235s
[2K
| Adam | epoch: 019 | loss: 0.48267 - acc: 0.7780 -- iter: 064/150
[A[ATraining Step: 93  | total loss: [1m[32m0.47008[0m[0m | time: 1.840s
[2K
| Adam | epoch: 019 | loss: 0.47008 - acc: 0.7814 -- iter: 096/150
[A[ATraining Step: 94  | total loss: [1m[32m0.47628[0m[0m | time: 2.441s
[2K
| Adam | epoch: 019 | loss: 0.47628 - acc: 0.7814 -- iter: 128/150
[A[ATraining Step: 95  | total loss: [1m[32m0.45854[0m[0m | time: 3.872s
[2K
| Adam | epoch: 019 | loss: 0.45854 - acc: 0.7876 | val_loss: 0.50055 - val_acc: 0.7447 -- iter: 150/150
--
Training Step: 96  | total loss: [1m[32m0.46896[0m[0m | time: 0.443s
[2K
| Adam | epoch: 020 | loss: 0.46896 - acc: 0.7816 -- iter: 032/150
[A[ATraining Step: 97  | total loss: [1m[32m0.46689[0m[0m | time: 1.083s
[2K
| Adam | epoch: 020 | loss: 0.46689 - acc: 0.7807 -- iter: 064/150
[A[ATraining Step: 98  | total loss: [1m[32m0.44922[0m[0m | time: 1.718s
[2K
| Adam | epoch: 020 | loss: 0.44922 - acc: 0.7933 -- iter: 096/150
[A[ATraining Step: 99  | total loss: [1m[32m0.43945[0m[0m | time: 2.332s
[2K
| Adam | epoch: 020 | loss: 0.43945 - acc: 0.7983 -- iter: 128/150
[A[ATraining Step: 100  | total loss: [1m[32m0.42971[0m[0m | time: 3.944s
[2K
| Adam | epoch: 020 | loss: 0.42971 - acc: 0.8029 | val_loss: 0.64559 - val_acc: 0.7234 -- iter: 150/150
--
Training Step: 101  | total loss: [1m[32m0.41460[0m[0m | time: 0.437s
[2K
| Adam | epoch: 021 | loss: 0.41460 - acc: 0.8101 -- iter: 032/150
[A[ATraining Step: 102  | total loss: [1m[32m0.40420[0m[0m | time: 0.879s
[2K
| Adam | epoch: 021 | loss: 0.40420 - acc: 0.8109 -- iter: 064/150
[A[ATraining Step: 103  | total loss: [1m[32m0.38566[0m[0m | time: 1.499s
[2K
| Adam | epoch: 021 | loss: 0.38566 - acc: 0.8253 -- iter: 096/150
[A[ATraining Step: 104  | total loss: [1m[32m0.37309[0m[0m | time: 2.140s
[2K
| Adam | epoch: 021 | loss: 0.37309 - acc: 0.8302 -- iter: 128/150
[A[ATraining Step: 105  | total loss: [1m[32m0.36271[0m[0m | time: 3.746s
[2K
| Adam | epoch: 021 | loss: 0.36271 - acc: 0.8378 | val_loss: 0.44987 - val_acc: 0.8298 -- iter: 150/150
--
Training Step: 106  | total loss: [1m[32m0.36424[0m[0m | time: 0.623s
[2K
| Adam | epoch: 022 | loss: 0.36424 - acc: 0.8384 -- iter: 032/150
[A[ATraining Step: 107  | total loss: [1m[32m0.34602[0m[0m | time: 1.055s
[2K
| Adam | epoch: 022 | loss: 0.34602 - acc: 0.8483 -- iter: 064/150
[A[ATraining Step: 108  | total loss: [1m[32m0.33274[0m[0m | time: 1.501s
[2K
| Adam | epoch: 022 | loss: 0.33274 - acc: 0.8635 -- iter: 096/150
[A[ATraining Step: 109  | total loss: [1m[32m0.32156[0m[0m | time: 2.106s
[2K
| Adam | epoch: 022 | loss: 0.32156 - acc: 0.8726 -- iter: 128/150
[A[ATraining Step: 110  | total loss: [1m[32m0.30891[0m[0m | time: 3.703s
[2K
| Adam | epoch: 022 | loss: 0.30891 - acc: 0.8791 | val_loss: 0.44127 - val_acc: 0.7447 -- iter: 150/150
--
Training Step: 111  | total loss: [1m[32m0.29197[0m[0m | time: 0.648s
[2K
| Adam | epoch: 023 | loss: 0.29197 - acc: 0.8881 -- iter: 032/150
[A[ATraining Step: 112  | total loss: [1m[32m0.29709[0m[0m | time: 1.276s
[2K
| Adam | epoch: 023 | loss: 0.29709 - acc: 0.8930 -- iter: 064/150
[A[ATraining Step: 113  | total loss: [1m[32m0.28078[0m[0m | time: 1.707s
[2K
| Adam | epoch: 023 | loss: 0.28078 - acc: 0.8975 -- iter: 096/150
[A[ATraining Step: 114  | total loss: [1m[32m0.26941[0m[0m | time: 2.157s
[2K
| Adam | epoch: 023 | loss: 0.26941 - acc: 0.8986 -- iter: 128/150
[A[ATraining Step: 115  | total loss: [1m[32m0.25240[0m[0m | time: 3.766s
[2K
| Adam | epoch: 023 | loss: 0.25240 - acc: 0.9088 | val_loss: 0.73406 - val_acc: 0.7234 -- iter: 150/150
--
Training Step: 116  | total loss: [1m[32m0.24977[0m[0m | time: 0.622s
[2K
| Adam | epoch: 024 | loss: 0.24977 - acc: 0.9085 -- iter: 032/150
[A[ATraining Step: 117  | total loss: [1m[32m0.25726[0m[0m | time: 1.230s
[2K
| Adam | epoch: 024 | loss: 0.25726 - acc: 0.8989 -- iter: 064/150
[A[ATraining Step: 118  | total loss: [1m[32m0.23638[0m[0m | time: 1.835s
[2K
| Adam | epoch: 024 | loss: 0.23638 - acc: 0.9090 -- iter: 096/150
[A[ATraining Step: 119  | total loss: [1m[32m0.22061[0m[0m | time: 2.273s
[2K
| Adam | epoch: 024 | loss: 0.22061 - acc: 0.9150 -- iter: 128/150
[A[ATraining Step: 120  | total loss: [1m[32m0.21420[0m[0m | time: 3.714s
[2K
| Adam | epoch: 024 | loss: 0.21420 - acc: 0.9189 | val_loss: 0.41747 - val_acc: 0.8085 -- iter: 150/150
--
Training Step: 121  | total loss: [1m[32m0.20866[0m[0m | time: 0.614s
[2K
| Adam | epoch: 025 | loss: 0.20866 - acc: 0.9225 -- iter: 032/150
[A[ATraining Step: 122  | total loss: [1m[32m0.19537[0m[0m | time: 1.232s
[2K
| Adam | epoch: 025 | loss: 0.19537 - acc: 0.9303 -- iter: 064/150
[A[ATraining Step: 123  | total loss: [1m[32m0.18248[0m[0m | time: 1.842s
[2K
| Adam | epoch: 025 | loss: 0.18248 - acc: 0.9372 -- iter: 096/150
[A[ATraining Step: 124  | total loss: [1m[32m0.19441[0m[0m | time: 2.439s
[2K
| Adam | epoch: 025 | loss: 0.19441 - acc: 0.9373 -- iter: 128/150
[A[ATraining Step: 125  | total loss: [1m[32m0.17795[0m[0m | time: 3.871s
[2K
| Adam | epoch: 025 | loss: 0.17795 - acc: 0.9435 | val_loss: 0.46746 - val_acc: 0.7872 -- iter: 150/150
--
Training Step: 126  | total loss: [1m[32m0.16573[0m[0m | time: 0.450s
[2K
| Adam | epoch: 026 | loss: 0.16573 - acc: 0.9492 -- iter: 032/150
[A[ATraining Step: 127  | total loss: [1m[32m0.15499[0m[0m | time: 1.063s
[2K
| Adam | epoch: 026 | loss: 0.15499 - acc: 0.9543 -- iter: 064/150
[A[ATraining Step: 128  | total loss: [1m[32m0.14322[0m[0m | time: 1.675s
[2K
| Adam | epoch: 026 | loss: 0.14322 - acc: 0.9588 -- iter: 096/150
[A[ATraining Step: 129  | total loss: [1m[32m0.13247[0m[0m | time: 2.287s
[2K
| Adam | epoch: 026 | loss: 0.13247 - acc: 0.9629 -- iter: 128/150
[A[ATraining Step: 130  | total loss: [1m[32m0.13539[0m[0m | time: 3.895s
[2K
| Adam | epoch: 026 | loss: 0.13539 - acc: 0.9635 | val_loss: 0.71259 - val_acc: 0.7872 -- iter: 150/150
--
Training Step: 131  | total loss: [1m[32m0.12506[0m[0m | time: 0.443s
[2K
| Adam | epoch: 027 | loss: 0.12506 - acc: 0.9672 -- iter: 032/150
[A[ATraining Step: 132  | total loss: [1m[32m0.11538[0m[0m | time: 0.888s
[2K
| Adam | epoch: 027 | loss: 0.11538 - acc: 0.9705 -- iter: 064/150
[A[ATraining Step: 133  | total loss: [1m[32m0.10575[0m[0m | time: 1.498s
[2K
| Adam | epoch: 027 | loss: 0.10575 - acc: 0.9734 -- iter: 096/150
[A[ATraining Step: 134  | total loss: [1m[32m0.09774[0m[0m | time: 2.113s
[2K
| Adam | epoch: 027 | loss: 0.09774 - acc: 0.9761 -- iter: 128/150
[A[ATraining Step: 135  | total loss: [1m[32m0.09009[0m[0m | time: 3.732s
[2K
| Adam | epoch: 027 | loss: 0.09009 - acc: 0.9785 | val_loss: 0.50359 - val_acc: 0.7660 -- iter: 150/150
--
Training Step: 136  | total loss: [1m[32m0.11139[0m[0m | time: 0.642s
[2K
| Adam | epoch: 028 | loss: 0.11139 - acc: 0.9775 -- iter: 032/150
[A[ATraining Step: 137  | total loss: [1m[32m0.10324[0m[0m | time: 1.088s
[2K
| Adam | epoch: 028 | loss: 0.10324 - acc: 0.9797 -- iter: 064/150
[A[ATraining Step: 138  | total loss: [1m[32m0.09811[0m[0m | time: 1.545s
[2K
| Adam | epoch: 028 | loss: 0.09811 - acc: 0.9818 -- iter: 096/150
[A[ATraining Step: 139  | total loss: [1m[32m0.08966[0m[0m | time: 2.163s
[2K
| Adam | epoch: 028 | loss: 0.08966 - acc: 0.9836 -- iter: 128/150
[A[ATraining Step: 140  | total loss: [1m[32m0.08273[0m[0m | time: 3.773s
[2K
| Adam | epoch: 028 | loss: 0.08273 - acc: 0.9852 | val_loss: 0.63618 - val_acc: 0.7872 -- iter: 150/150
--
Training Step: 141  | total loss: [1m[32m0.07665[0m[0m | time: 0.626s
[2K
| Adam | epoch: 029 | loss: 0.07665 - acc: 0.9867 -- iter: 032/150
[A[ATraining Step: 142  | total loss: [1m[32m0.07180[0m[0m | time: 1.227s
[2K
| Adam | epoch: 029 | loss: 0.07180 - acc: 0.9880 -- iter: 064/150
[A[ATraining Step: 143  | total loss: [1m[32m0.06622[0m[0m | time: 1.655s
[2K
| Adam | epoch: 029 | loss: 0.06622 - acc: 0.9892 -- iter: 096/150
[A[ATraining Step: 144  | total loss: [1m[32m0.06020[0m[0m | time: 2.091s
[2K
| Adam | epoch: 029 | loss: 0.06020 - acc: 0.9903 -- iter: 128/150
[A[ATraining Step: 145  | total loss: [1m[32m0.05470[0m[0m | time: 3.726s
[2K
| Adam | epoch: 029 | loss: 0.05470 - acc: 0.9913 | val_loss: 0.55615 - val_acc: 0.7872 -- iter: 150/150
--
Training Step: 146  | total loss: [1m[32m0.04991[0m[0m | time: 0.651s
[2K
| Adam | epoch: 030 | loss: 0.04991 - acc: 0.9922 -- iter: 032/150
[A[ATraining Step: 147  | total loss: [1m[32m0.04638[0m[0m | time: 1.252s
[2K
| Adam | epoch: 030 | loss: 0.04638 - acc: 0.9929 -- iter: 064/150
[A[ATraining Step: 148  | total loss: [1m[32m0.05836[0m[0m | time: 1.862s
[2K
| Adam | epoch: 030 | loss: 0.05836 - acc: 0.9905 -- iter: 096/150
[A[ATraining Step: 149  | total loss: [1m[32m0.05373[0m[0m | time: 2.292s
[2K
| Adam | epoch: 030 | loss: 0.05373 - acc: 0.9915 -- iter: 128/150
[A[ATraining Step: 150  | total loss: [1m[32m0.04894[0m[0m | time: 3.720s
[2K
| Adam | epoch: 030 | loss: 0.04894 - acc: 0.9923 | val_loss: 0.52605 - val_acc: 0.7872 -- iter: 150/150
--
Validation AUC:0.9072727272727273
Validation AUPRC:0.9012176015557847
Test AUC:0.9548872180451129
Test AUPRC:0.9467711267332415
BestTestF1Score	0.89	0.82	0.91	0.94	0.84	16	1	27	3	0.62
BestTestMCCScore	0.89	0.82	0.91	0.94	0.84	16	1	27	3	0.62
BestTestAccuracyScore	0.89	0.82	0.91	0.94	0.84	16	1	27	3	0.62
BestValidationF1Score	0.83	0.66	0.83	0.79	0.86	19	5	20	3	0.62
BestValidationMCC	0.83	0.66	0.83	0.79	0.86	19	5	20	3	0.62
BestValidationAccuracy	0.83	0.66	0.83	0.79	0.86	19	5	20	3	0.62
TestPredictions (Threshold:0.62)
CHEMBL498705,TN,INACT,0.41999998688697815	CHEMBL271278,TP,ACT,0.7099999785423279	CHEMBL271699,TP,ACT,0.8399999737739563	CHEMBL3699624,TP,ACT,1.0	CHEMBL490053,TN,INACT,0.1599999964237213	CHEMBL271043,TP,ACT,1.0	CHEMBL271902,TP,ACT,1.0	CHEMBL446199,TP,ACT,0.9800000190734863	CHEMBL558849,TN,INACT,0.0	CHEMBL256452,TP,ACT,1.0	CHEMBL256872,TP,ACT,1.0	CHEMBL457191,TN,INACT,0.0	CHEMBL1922121,TN,INACT,0.0	CHEMBL1933802,TN,INACT,0.25999999046325684	CHEMBL256265,FN,ACT,0.14000000059604645	CHEMBL463384,TN,INACT,0.009999999776482582	CHEMBL549792,TN,INACT,0.0	CHEMBL1801932,TN,INACT,0.5600000023841858	CHEMBL559882,TN,INACT,0.0	CHEMBL497454,TN,INACT,0.0	CHEMBL427724,TP,ACT,0.6200000047683716	CHEMBL1734241,TN,INACT,0.07999999821186066	CHEMBL1784660,TN,INACT,0.14000000059604645	CHEMBL525530,TN,INACT,0.0	CHEMBL509499,TN,INACT,0.0	CHEMBL1789941,FN,ACT,0.05000000074505806	CHEMBL409856,TP,ACT,1.0	CHEMBL3699631,TP,ACT,0.9900000095367432	CHEMBL255633,TP,ACT,0.9900000095367432	CHEMBL3421968,TN,INACT,0.09000000357627869	CHEMBL300549,TP,ACT,1.0	CHEMBL270141,TP,ACT,1.0	CHEMBL2392375,TN,INACT,0.0	CHEMBL482919,TN,INACT,0.019999999552965164	CHEMBL379218,FN,ACT,0.49000000953674316	CHEMBL1288067,TN,INACT,0.019999999552965164	CHEMBL1922210,TN,INACT,0.0	CHEMBL102622,TN,INACT,0.10999999940395355	CHEMBL3746916,FP,INACT,0.9599999785423279	CHEMBL1087421,TN,INACT,0.4099999964237213	CHEMBL557525,TN,INACT,0.0	CHEMBL2392366,TN,INACT,0.1899999976158142	CHEMBL525538,TN,INACT,0.009999999776482582	CHEMBL515356,TN,INACT,0.0	CHEMBL3699628,TP,ACT,0.8500000238418579	CHEMBL403887,TP,ACT,0.9900000095367432	CHEMBL515051,TN,INACT,0.019999999552965164	

