CNNModel CHEMBL4016 adam 0.0005 30 128 0 0.8 False True
Number of active compounds :	151
Number of inactive compounds :	151
---------------------------------
Run id: CNNModel_CHEMBL4016_adam_0.0005_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4016_adam_0.0005_30_128_0.8_True/
---------------------------------
Training samples: 192
Validation samples: 61
--
Training Step: 1  | time: 0.796s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/192
[A[ATraining Step: 2  | total loss: [1m[32m0.62382[0m[0m | time: 1.393s
[2K
| Adam | epoch: 001 | loss: 0.62382 - acc: 0.5062 -- iter: 064/192
[A[ATraining Step: 3  | total loss: [1m[32m0.67958[0m[0m | time: 2.021s
[2K
| Adam | epoch: 001 | loss: 0.67958 - acc: 0.5778 -- iter: 096/192
[A[ATraining Step: 4  | total loss: [1m[32m0.68675[0m[0m | time: 2.631s
[2K
| Adam | epoch: 001 | loss: 0.68675 - acc: 0.5898 -- iter: 128/192
[A[ATraining Step: 5  | total loss: [1m[32m0.69986[0m[0m | time: 3.257s
[2K
| Adam | epoch: 001 | loss: 0.69986 - acc: 0.4411 -- iter: 160/192
[A[ATraining Step: 6  | total loss: [1m[32m0.69444[0m[0m | time: 4.908s
[2K
| Adam | epoch: 001 | loss: 0.69444 - acc: 0.4990 | val_loss: 0.69288 - val_acc: 0.5082 -- iter: 192/192
--
Training Step: 7  | total loss: [1m[32m0.69398[0m[0m | time: 0.642s
[2K
| Adam | epoch: 002 | loss: 0.69398 - acc: 0.4996 -- iter: 032/192
[A[ATraining Step: 8  | total loss: [1m[32m0.69331[0m[0m | time: 1.271s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4998 -- iter: 064/192
[A[ATraining Step: 9  | total loss: [1m[32m0.69603[0m[0m | time: 1.877s
[2K
| Adam | epoch: 002 | loss: 0.69603 - acc: 0.4337 -- iter: 096/192
[A[ATraining Step: 10  | total loss: [1m[32m0.69498[0m[0m | time: 2.514s
[2K
| Adam | epoch: 002 | loss: 0.69498 - acc: 0.4512 -- iter: 128/192
[A[ATraining Step: 11  | total loss: [1m[32m0.69427[0m[0m | time: 3.125s
[2K
| Adam | epoch: 002 | loss: 0.69427 - acc: 0.4595 -- iter: 160/192
[A[ATraining Step: 12  | total loss: [1m[32m0.69373[0m[0m | time: 4.751s
[2K
| Adam | epoch: 002 | loss: 0.69373 - acc: 0.4918 | val_loss: 0.69320 - val_acc: 0.4918 -- iter: 192/192
--
Training Step: 13  | total loss: [1m[32m0.69357[0m[0m | time: 0.614s
[2K
| Adam | epoch: 003 | loss: 0.69357 - acc: 0.4819 -- iter: 032/192
[A[ATraining Step: 14  | total loss: [1m[32m0.69382[0m[0m | time: 1.227s
[2K
| Adam | epoch: 003 | loss: 0.69382 - acc: 0.3998 -- iter: 064/192
[A[ATraining Step: 15  | total loss: [1m[32m0.69361[0m[0m | time: 1.882s
[2K
| Adam | epoch: 003 | loss: 0.69361 - acc: 0.4023 -- iter: 096/192
[A[ATraining Step: 16  | total loss: [1m[32m0.69380[0m[0m | time: 2.502s
[2K
| Adam | epoch: 003 | loss: 0.69380 - acc: 0.3804 -- iter: 128/192
[A[ATraining Step: 17  | total loss: [1m[32m0.69342[0m[0m | time: 3.124s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.4347 -- iter: 160/192
[A[ATraining Step: 18  | total loss: [1m[32m0.69311[0m[0m | time: 4.747s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.4897 | val_loss: 0.69308 - val_acc: 0.5082 -- iter: 192/192
--
Training Step: 19  | total loss: [1m[32m0.69338[0m[0m | time: 0.616s
[2K
| Adam | epoch: 004 | loss: 0.69338 - acc: 0.4619 -- iter: 032/192
[A[ATraining Step: 20  | total loss: [1m[32m0.69338[0m[0m | time: 1.251s
[2K
| Adam | epoch: 004 | loss: 0.69338 - acc: 0.4641 -- iter: 064/192
[A[ATraining Step: 21  | total loss: [1m[32m0.69336[0m[0m | time: 1.880s
[2K
| Adam | epoch: 004 | loss: 0.69336 - acc: 0.4656 -- iter: 096/192
[A[ATraining Step: 22  | total loss: [1m[32m0.69332[0m[0m | time: 2.488s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.4665 -- iter: 128/192
[A[ATraining Step: 23  | total loss: [1m[32m0.69329[0m[0m | time: 3.103s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.4762 -- iter: 160/192
[A[ATraining Step: 24  | total loss: [1m[32m0.69319[0m[0m | time: 4.741s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.5005 | val_loss: 0.69310 - val_acc: 0.5082 -- iter: 192/192
--
Training Step: 25  | total loss: [1m[32m0.69319[0m[0m | time: 0.612s
[2K
| Adam | epoch: 005 | loss: 0.69319 - acc: 0.4918 -- iter: 032/192
[A[ATraining Step: 26  | total loss: [1m[32m0.69311[0m[0m | time: 1.229s
[2K
| Adam | epoch: 005 | loss: 0.69311 - acc: 0.5023 -- iter: 064/192
[A[ATraining Step: 27  | total loss: [1m[32m0.69311[0m[0m | time: 1.840s
[2K
| Adam | epoch: 005 | loss: 0.69311 - acc: 0.4937 -- iter: 096/192
[A[ATraining Step: 28  | total loss: [1m[32m0.69316[0m[0m | time: 2.464s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.4874 -- iter: 128/192
[A[ATraining Step: 29  | total loss: [1m[32m0.69311[0m[0m | time: 3.094s
[2K
| Adam | epoch: 005 | loss: 0.69311 - acc: 0.4905 -- iter: 160/192
[A[ATraining Step: 30  | total loss: [1m[32m0.69315[0m[0m | time: 4.728s
[2K
| Adam | epoch: 005 | loss: 0.69315 - acc: 0.4705 | val_loss: 0.69312 - val_acc: 0.5574 -- iter: 192/192
--
Training Step: 31  | total loss: [1m[32m0.69316[0m[0m | time: 0.620s
[2K
| Adam | epoch: 006 | loss: 0.69316 - acc: 0.4629 -- iter: 032/192
[A[ATraining Step: 32  | total loss: [1m[32m0.69313[0m[0m | time: 1.237s
[2K
| Adam | epoch: 006 | loss: 0.69313 - acc: 0.4923 -- iter: 064/192
[A[ATraining Step: 33  | total loss: [1m[32m0.69307[0m[0m | time: 1.852s
[2K
| Adam | epoch: 006 | loss: 0.69307 - acc: 0.5077 -- iter: 096/192
[A[ATraining Step: 34  | total loss: [1m[32m0.69309[0m[0m | time: 2.475s
[2K
| Adam | epoch: 006 | loss: 0.69309 - acc: 0.4994 -- iter: 128/192
[A[ATraining Step: 35  | total loss: [1m[32m0.69302[0m[0m | time: 3.089s
[2K
| Adam | epoch: 006 | loss: 0.69302 - acc: 0.5061 -- iter: 160/192
[A[ATraining Step: 36  | total loss: [1m[32m0.69300[0m[0m | time: 4.707s
[2K
| Adam | epoch: 006 | loss: 0.69300 - acc: 0.5112 | val_loss: 0.69308 - val_acc: 0.4918 -- iter: 192/192
--
Training Step: 37  | total loss: [1m[32m0.69310[0m[0m | time: 0.654s
[2K
| Adam | epoch: 007 | loss: 0.69310 - acc: 0.4965 -- iter: 032/192
[A[ATraining Step: 38  | total loss: [1m[32m0.69294[0m[0m | time: 1.293s
[2K
| Adam | epoch: 007 | loss: 0.69294 - acc: 0.5216 -- iter: 064/192
[A[ATraining Step: 39  | total loss: [1m[32m0.69282[0m[0m | time: 1.911s
[2K
| Adam | epoch: 007 | loss: 0.69282 - acc: 0.5294 -- iter: 096/192
[A[ATraining Step: 40  | total loss: [1m[32m0.69283[0m[0m | time: 2.520s
[2K
| Adam | epoch: 007 | loss: 0.69283 - acc: 0.5181 -- iter: 128/192
[A[ATraining Step: 41  | total loss: [1m[32m0.69317[0m[0m | time: 3.128s
[2K
| Adam | epoch: 007 | loss: 0.69317 - acc: 0.4918 -- iter: 160/192
[A[ATraining Step: 42  | total loss: [1m[32m0.69298[0m[0m | time: 4.769s
[2K
| Adam | epoch: 007 | loss: 0.69298 - acc: 0.4989 | val_loss: 0.69285 - val_acc: 0.4918 -- iter: 192/192
--
Training Step: 43  | total loss: [1m[32m0.69291[0m[0m | time: 0.645s
[2K
| Adam | epoch: 008 | loss: 0.69291 - acc: 0.5046 -- iter: 032/192
[A[ATraining Step: 44  | total loss: [1m[32m0.69292[0m[0m | time: 1.251s
[2K
| Adam | epoch: 008 | loss: 0.69292 - acc: 0.5038 -- iter: 064/192
[A[ATraining Step: 45  | total loss: [1m[32m0.69278[0m[0m | time: 1.864s
[2K
| Adam | epoch: 008 | loss: 0.69278 - acc: 0.5350 -- iter: 096/192
[A[ATraining Step: 46  | total loss: [1m[32m0.69282[0m[0m | time: 2.494s
[2K
| Adam | epoch: 008 | loss: 0.69282 - acc: 0.5187 -- iter: 128/192
[A[ATraining Step: 47  | total loss: [1m[32m0.69264[0m[0m | time: 3.119s
[2K
| Adam | epoch: 008 | loss: 0.69264 - acc: 0.5464 -- iter: 160/192
[A[ATraining Step: 48  | total loss: [1m[32m0.69250[0m[0m | time: 4.739s
[2K
| Adam | epoch: 008 | loss: 0.69250 - acc: 0.5690 | val_loss: 0.69224 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 49  | total loss: [1m[32m0.69226[0m[0m | time: 0.617s
[2K
| Adam | epoch: 009 | loss: 0.69226 - acc: 0.5927 -- iter: 032/192
[A[ATraining Step: 50  | total loss: [1m[32m0.69198[0m[0m | time: 1.222s
[2K
| Adam | epoch: 009 | loss: 0.69198 - acc: 0.6171 -- iter: 064/192
[A[ATraining Step: 51  | total loss: [1m[32m0.69213[0m[0m | time: 1.860s
[2K
| Adam | epoch: 009 | loss: 0.69213 - acc: 0.6088 -- iter: 096/192
[A[ATraining Step: 52  | total loss: [1m[32m0.69158[0m[0m | time: 2.476s
[2K
| Adam | epoch: 009 | loss: 0.69158 - acc: 0.6300 -- iter: 128/192
[A[ATraining Step: 53  | total loss: [1m[32m0.69147[0m[0m | time: 3.088s
[2K
| Adam | epoch: 009 | loss: 0.69147 - acc: 0.6384 -- iter: 160/192
[A[ATraining Step: 54  | total loss: [1m[32m0.69076[0m[0m | time: 4.687s
[2K
| Adam | epoch: 009 | loss: 0.69076 - acc: 0.6546 | val_loss: 0.69011 - val_acc: 0.5082 -- iter: 192/192
--
Training Step: 55  | total loss: [1m[32m0.69112[0m[0m | time: 0.632s
[2K
| Adam | epoch: 010 | loss: 0.69112 - acc: 0.6236 -- iter: 032/192
[A[ATraining Step: 56  | total loss: [1m[32m0.69080[0m[0m | time: 1.243s
[2K
| Adam | epoch: 010 | loss: 0.69080 - acc: 0.6062 -- iter: 064/192
[A[ATraining Step: 57  | total loss: [1m[32m0.69031[0m[0m | time: 1.861s
[2K
| Adam | epoch: 010 | loss: 0.69031 - acc: 0.5915 -- iter: 096/192
[A[ATraining Step: 58  | total loss: [1m[32m0.69026[0m[0m | time: 2.494s
[2K
| Adam | epoch: 010 | loss: 0.69026 - acc: 0.6004 -- iter: 128/192
[A[ATraining Step: 59  | total loss: [1m[32m0.68874[0m[0m | time: 3.108s
[2K
| Adam | epoch: 010 | loss: 0.68874 - acc: 0.6205 -- iter: 160/192
[A[ATraining Step: 60  | total loss: [1m[32m0.68766[0m[0m | time: 4.735s
[2K
| Adam | epoch: 010 | loss: 0.68766 - acc: 0.6376 | val_loss: 0.68612 - val_acc: 0.5410 -- iter: 192/192
--
Training Step: 61  | total loss: [1m[32m0.68616[0m[0m | time: 0.612s
[2K
| Adam | epoch: 011 | loss: 0.68616 - acc: 0.6319 -- iter: 032/192
[A[ATraining Step: 62  | total loss: [1m[32m0.68522[0m[0m | time: 1.241s
[2K
| Adam | epoch: 011 | loss: 0.68522 - acc: 0.6149 -- iter: 064/192
[A[ATraining Step: 63  | total loss: [1m[32m0.68750[0m[0m | time: 1.841s
[2K
| Adam | epoch: 011 | loss: 0.68750 - acc: 0.5845 -- iter: 096/192
[A[ATraining Step: 64  | total loss: [1m[32m0.68615[0m[0m | time: 2.450s
[2K
| Adam | epoch: 011 | loss: 0.68615 - acc: 0.5857 -- iter: 128/192
[A[ATraining Step: 65  | total loss: [1m[32m0.68602[0m[0m | time: 3.056s
[2K
| Adam | epoch: 011 | loss: 0.68602 - acc: 0.5867 -- iter: 160/192
[A[ATraining Step: 66  | total loss: [1m[32m0.68353[0m[0m | time: 4.670s
[2K
| Adam | epoch: 011 | loss: 0.68353 - acc: 0.5951 | val_loss: 0.70659 - val_acc: 0.4918 -- iter: 192/192
--
Training Step: 67  | total loss: [1m[32m0.68280[0m[0m | time: 0.656s
[2K
| Adam | epoch: 012 | loss: 0.68280 - acc: 0.5912 -- iter: 032/192
[A[ATraining Step: 68  | total loss: [1m[32m0.68415[0m[0m | time: 1.274s
[2K
| Adam | epoch: 012 | loss: 0.68415 - acc: 0.5804 -- iter: 064/192
[A[ATraining Step: 69  | total loss: [1m[32m0.69021[0m[0m | time: 1.879s
[2K
| Adam | epoch: 012 | loss: 0.69021 - acc: 0.5564 -- iter: 096/192
[A[ATraining Step: 70  | total loss: [1m[32m0.68954[0m[0m | time: 2.489s
[2K
| Adam | epoch: 012 | loss: 0.68954 - acc: 0.5535 -- iter: 128/192
[A[ATraining Step: 71  | total loss: [1m[32m0.68791[0m[0m | time: 3.110s
[2K
| Adam | epoch: 012 | loss: 0.68791 - acc: 0.5545 -- iter: 160/192
[A[ATraining Step: 72  | total loss: [1m[32m0.68596[0m[0m | time: 4.767s
[2K
| Adam | epoch: 012 | loss: 0.68596 - acc: 0.5730 | val_loss: 0.68226 - val_acc: 0.6066 -- iter: 192/192
--
Training Step: 73  | total loss: [1m[32m0.68389[0m[0m | time: 0.606s
[2K
| Adam | epoch: 013 | loss: 0.68389 - acc: 0.5753 -- iter: 032/192
[A[ATraining Step: 74  | total loss: [1m[32m0.68410[0m[0m | time: 1.227s
[2K
| Adam | epoch: 013 | loss: 0.68410 - acc: 0.5705 -- iter: 064/192
[A[ATraining Step: 75  | total loss: [1m[32m0.68201[0m[0m | time: 1.852s
[2K
| Adam | epoch: 013 | loss: 0.68201 - acc: 0.5628 -- iter: 096/192
[A[ATraining Step: 76  | total loss: [1m[32m0.67697[0m[0m | time: 2.465s
[2K
| Adam | epoch: 013 | loss: 0.67697 - acc: 0.5795 -- iter: 128/192
[A[ATraining Step: 77  | total loss: [1m[32m0.67277[0m[0m | time: 3.097s
[2K
| Adam | epoch: 013 | loss: 0.67277 - acc: 0.5943 -- iter: 160/192
[A[ATraining Step: 78  | total loss: [1m[32m0.66729[0m[0m | time: 4.702s
[2K
| Adam | epoch: 013 | loss: 0.66729 - acc: 0.6008 | val_loss: 0.68187 - val_acc: 0.5410 -- iter: 192/192
--
Training Step: 79  | total loss: [1m[32m0.66250[0m[0m | time: 0.634s
[2K
| Adam | epoch: 014 | loss: 0.66250 - acc: 0.6065 -- iter: 032/192
[A[ATraining Step: 80  | total loss: [1m[32m0.65286[0m[0m | time: 1.258s
[2K
| Adam | epoch: 014 | loss: 0.65286 - acc: 0.6212 -- iter: 064/192
[A[ATraining Step: 81  | total loss: [1m[32m0.64982[0m[0m | time: 1.910s
[2K
| Adam | epoch: 014 | loss: 0.64982 - acc: 0.6247 -- iter: 096/192
[A[ATraining Step: 82  | total loss: [1m[32m0.64992[0m[0m | time: 2.520s
[2K
| Adam | epoch: 014 | loss: 0.64992 - acc: 0.6310 -- iter: 128/192
[A[ATraining Step: 83  | total loss: [1m[32m0.64630[0m[0m | time: 3.127s
[2K
| Adam | epoch: 014 | loss: 0.64630 - acc: 0.6273 -- iter: 160/192
[A[ATraining Step: 84  | total loss: [1m[32m0.64003[0m[0m | time: 4.730s
[2K
| Adam | epoch: 014 | loss: 0.64003 - acc: 0.6333 | val_loss: 0.70407 - val_acc: 0.5410 -- iter: 192/192
--
Training Step: 85  | total loss: [1m[32m0.63570[0m[0m | time: 0.616s
[2K
| Adam | epoch: 015 | loss: 0.63570 - acc: 0.6387 -- iter: 032/192
[A[ATraining Step: 86  | total loss: [1m[32m0.62508[0m[0m | time: 1.231s
[2K
| Adam | epoch: 015 | loss: 0.62508 - acc: 0.6467 -- iter: 064/192
[A[ATraining Step: 87  | total loss: [1m[32m0.62118[0m[0m | time: 1.854s
[2K
| Adam | epoch: 015 | loss: 0.62118 - acc: 0.6539 -- iter: 096/192
[A[ATraining Step: 88  | total loss: [1m[32m0.62185[0m[0m | time: 2.466s
[2K
| Adam | epoch: 015 | loss: 0.62185 - acc: 0.6510 -- iter: 128/192
[A[ATraining Step: 89  | total loss: [1m[32m0.61779[0m[0m | time: 3.088s
[2K
| Adam | epoch: 015 | loss: 0.61779 - acc: 0.6609 -- iter: 160/192
[A[ATraining Step: 90  | total loss: [1m[32m0.60573[0m[0m | time: 4.710s
[2K
| Adam | epoch: 015 | loss: 0.60573 - acc: 0.6730 | val_loss: 0.85025 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 91  | total loss: [1m[32m0.58949[0m[0m | time: 0.606s
[2K
| Adam | epoch: 016 | loss: 0.58949 - acc: 0.6932 -- iter: 032/192
[A[ATraining Step: 92  | total loss: [1m[32m0.58146[0m[0m | time: 1.217s
[2K
| Adam | epoch: 016 | loss: 0.58146 - acc: 0.7051 -- iter: 064/192
[A[ATraining Step: 93  | total loss: [1m[32m0.57834[0m[0m | time: 1.833s
[2K
| Adam | epoch: 016 | loss: 0.57834 - acc: 0.7033 -- iter: 096/192
[A[ATraining Step: 94  | total loss: [1m[32m0.56635[0m[0m | time: 2.467s
[2K
| Adam | epoch: 016 | loss: 0.56635 - acc: 0.7174 -- iter: 128/192
[A[ATraining Step: 95  | total loss: [1m[32m0.56052[0m[0m | time: 3.084s
[2K
| Adam | epoch: 016 | loss: 0.56052 - acc: 0.7206 -- iter: 160/192
[A[ATraining Step: 96  | total loss: [1m[32m0.56480[0m[0m | time: 4.715s
[2K
| Adam | epoch: 016 | loss: 0.56480 - acc: 0.7111 | val_loss: 0.67732 - val_acc: 0.5410 -- iter: 192/192
--
Training Step: 97  | total loss: [1m[32m0.55542[0m[0m | time: 0.650s
[2K
| Adam | epoch: 017 | loss: 0.55542 - acc: 0.7150 -- iter: 032/192
[A[ATraining Step: 98  | total loss: [1m[32m0.55034[0m[0m | time: 1.274s
[2K
| Adam | epoch: 017 | loss: 0.55034 - acc: 0.7247 -- iter: 064/192
[A[ATraining Step: 99  | total loss: [1m[32m0.54547[0m[0m | time: 1.898s
[2K
| Adam | epoch: 017 | loss: 0.54547 - acc: 0.7335 -- iter: 096/192
[A[ATraining Step: 100  | total loss: [1m[32m0.54362[0m[0m | time: 2.512s
[2K
| Adam | epoch: 017 | loss: 0.54362 - acc: 0.7352 -- iter: 128/192
[A[ATraining Step: 101  | total loss: [1m[32m0.54219[0m[0m | time: 3.123s
[2K
| Adam | epoch: 017 | loss: 0.54219 - acc: 0.7429 -- iter: 160/192
[A[ATraining Step: 102  | total loss: [1m[32m0.52677[0m[0m | time: 4.763s
[2K
| Adam | epoch: 017 | loss: 0.52677 - acc: 0.7530 | val_loss: 0.66815 - val_acc: 0.6230 -- iter: 192/192
--
Training Step: 103  | total loss: [1m[32m0.52094[0m[0m | time: 0.616s
[2K
| Adam | epoch: 018 | loss: 0.52094 - acc: 0.7464 -- iter: 032/192
[A[ATraining Step: 104  | total loss: [1m[32m0.51408[0m[0m | time: 1.225s
[2K
| Adam | epoch: 018 | loss: 0.51408 - acc: 0.7499 -- iter: 064/192
[A[ATraining Step: 105  | total loss: [1m[32m0.50720[0m[0m | time: 1.836s
[2K
| Adam | epoch: 018 | loss: 0.50720 - acc: 0.7499 -- iter: 096/192
[A[ATraining Step: 106  | total loss: [1m[32m0.49977[0m[0m | time: 2.444s
[2K
| Adam | epoch: 018 | loss: 0.49977 - acc: 0.7530 -- iter: 128/192
[A[ATraining Step: 107  | total loss: [1m[32m0.49073[0m[0m | time: 3.068s
[2K
| Adam | epoch: 018 | loss: 0.49073 - acc: 0.7496 -- iter: 160/192
[A[ATraining Step: 108  | total loss: [1m[32m0.47785[0m[0m | time: 4.704s
[2K
| Adam | epoch: 018 | loss: 0.47785 - acc: 0.7653 | val_loss: 0.75212 - val_acc: 0.5902 -- iter: 192/192
--
Training Step: 109  | total loss: [1m[32m0.46771[0m[0m | time: 0.606s
[2K
| Adam | epoch: 019 | loss: 0.46771 - acc: 0.7731 -- iter: 032/192
[A[ATraining Step: 110  | total loss: [1m[32m0.44624[0m[0m | time: 1.224s
[2K
| Adam | epoch: 019 | loss: 0.44624 - acc: 0.7864 -- iter: 064/192
[A[ATraining Step: 111  | total loss: [1m[32m0.43996[0m[0m | time: 1.844s
[2K
| Adam | epoch: 019 | loss: 0.43996 - acc: 0.7890 -- iter: 096/192
[A[ATraining Step: 112  | total loss: [1m[32m0.43692[0m[0m | time: 2.445s
[2K
| Adam | epoch: 019 | loss: 0.43692 - acc: 0.7914 -- iter: 128/192
[A[ATraining Step: 113  | total loss: [1m[32m0.43714[0m[0m | time: 3.058s
[2K
| Adam | epoch: 019 | loss: 0.43714 - acc: 0.7966 -- iter: 160/192
[A[ATraining Step: 114  | total loss: [1m[32m0.42982[0m[0m | time: 4.696s
[2K
| Adam | epoch: 019 | loss: 0.42982 - acc: 0.8045 | val_loss: 0.65595 - val_acc: 0.6885 -- iter: 192/192
--
Training Step: 115  | total loss: [1m[32m0.41622[0m[0m | time: 0.610s
[2K
| Adam | epoch: 020 | loss: 0.41622 - acc: 0.8115 -- iter: 032/192
[A[ATraining Step: 116  | total loss: [1m[32m0.40237[0m[0m | time: 1.219s
[2K
| Adam | epoch: 020 | loss: 0.40237 - acc: 0.8241 -- iter: 064/192
[A[ATraining Step: 117  | total loss: [1m[32m0.41605[0m[0m | time: 1.856s
[2K
| Adam | epoch: 020 | loss: 0.41605 - acc: 0.8136 -- iter: 096/192
[A[ATraining Step: 118  | total loss: [1m[32m0.40802[0m[0m | time: 2.478s
[2K
| Adam | epoch: 020 | loss: 0.40802 - acc: 0.8166 -- iter: 128/192
[A[ATraining Step: 119  | total loss: [1m[32m0.38099[0m[0m | time: 3.106s
[2K
| Adam | epoch: 020 | loss: 0.38099 - acc: 0.8349 -- iter: 160/192
[A[ATraining Step: 120  | total loss: [1m[32m0.36000[0m[0m | time: 4.731s
[2K
| Adam | epoch: 020 | loss: 0.36000 - acc: 0.8483 | val_loss: 0.62857 - val_acc: 0.7213 -- iter: 192/192
--
Training Step: 121  | total loss: [1m[32m0.34714[0m[0m | time: 0.616s
[2K
| Adam | epoch: 021 | loss: 0.34714 - acc: 0.8479 -- iter: 032/192
[A[ATraining Step: 122  | total loss: [1m[32m0.33883[0m[0m | time: 1.219s
[2K
| Adam | epoch: 021 | loss: 0.33883 - acc: 0.8537 -- iter: 064/192
[A[ATraining Step: 123  | total loss: [1m[32m0.31861[0m[0m | time: 1.849s
[2K
| Adam | epoch: 021 | loss: 0.31861 - acc: 0.8652 -- iter: 096/192
[A[ATraining Step: 124  | total loss: [1m[32m0.30523[0m[0m | time: 2.485s
[2K
| Adam | epoch: 021 | loss: 0.30523 - acc: 0.8756 -- iter: 128/192
[A[ATraining Step: 125  | total loss: [1m[32m0.29356[0m[0m | time: 3.116s
[2K
| Adam | epoch: 021 | loss: 0.29356 - acc: 0.8818 -- iter: 160/192
[A[ATraining Step: 126  | total loss: [1m[32m0.29804[0m[0m | time: 4.731s
[2K
| Adam | epoch: 021 | loss: 0.29804 - acc: 0.8748 | val_loss: 0.73808 - val_acc: 0.7377 -- iter: 192/192
--
Training Step: 127  | total loss: [1m[32m0.29658[0m[0m | time: 0.614s
[2K
| Adam | epoch: 022 | loss: 0.29658 - acc: 0.8717 -- iter: 032/192
[A[ATraining Step: 128  | total loss: [1m[32m0.28091[0m[0m | time: 1.253s
[2K
| Adam | epoch: 022 | loss: 0.28091 - acc: 0.8814 -- iter: 064/192
[A[ATraining Step: 129  | total loss: [1m[32m0.28362[0m[0m | time: 1.868s
[2K
| Adam | epoch: 022 | loss: 0.28362 - acc: 0.8714 -- iter: 096/192
[A[ATraining Step: 130  | total loss: [1m[32m0.28951[0m[0m | time: 2.487s
[2K
| Adam | epoch: 022 | loss: 0.28951 - acc: 0.8718 -- iter: 128/192
[A[ATraining Step: 131  | total loss: [1m[32m0.28039[0m[0m | time: 3.124s
[2K
| Adam | epoch: 022 | loss: 0.28039 - acc: 0.8783 -- iter: 160/192
[A[ATraining Step: 132  | total loss: [1m[32m0.26406[0m[0m | time: 4.737s
[2K
| Adam | epoch: 022 | loss: 0.26406 - acc: 0.8874 | val_loss: 1.00227 - val_acc: 0.6393 -- iter: 192/192
--
Training Step: 133  | total loss: [1m[32m0.25595[0m[0m | time: 0.632s
[2K
| Adam | epoch: 023 | loss: 0.25595 - acc: 0.8893 -- iter: 032/192
[A[ATraining Step: 134  | total loss: [1m[32m0.24621[0m[0m | time: 1.241s
[2K
| Adam | epoch: 023 | loss: 0.24621 - acc: 0.8910 -- iter: 064/192
[A[ATraining Step: 135  | total loss: [1m[32m0.24680[0m[0m | time: 1.848s
[2K
| Adam | epoch: 023 | loss: 0.24680 - acc: 0.8925 -- iter: 096/192
[A[ATraining Step: 136  | total loss: [1m[32m0.23795[0m[0m | time: 2.460s
[2K
| Adam | epoch: 023 | loss: 0.23795 - acc: 0.8970 -- iter: 128/192
[A[ATraining Step: 137  | total loss: [1m[32m0.24411[0m[0m | time: 3.070s
[2K
| Adam | epoch: 023 | loss: 0.24411 - acc: 0.8979 -- iter: 160/192
[A[ATraining Step: 138  | total loss: [1m[32m0.27302[0m[0m | time: 4.670s
[2K
| Adam | epoch: 023 | loss: 0.27302 - acc: 0.8831 | val_loss: 0.79300 - val_acc: 0.7213 -- iter: 192/192
--
Training Step: 139  | total loss: [1m[32m0.28368[0m[0m | time: 0.602s
[2K
| Adam | epoch: 024 | loss: 0.28368 - acc: 0.8823 -- iter: 032/192
[A[ATraining Step: 140  | total loss: [1m[32m0.26850[0m[0m | time: 1.217s
[2K
| Adam | epoch: 024 | loss: 0.26850 - acc: 0.8878 -- iter: 064/192
[A[ATraining Step: 141  | total loss: [1m[32m0.25528[0m[0m | time: 1.827s
[2K
| Adam | epoch: 024 | loss: 0.25528 - acc: 0.8959 -- iter: 096/192
[A[ATraining Step: 142  | total loss: [1m[32m0.25914[0m[0m | time: 2.447s
[2K
| Adam | epoch: 024 | loss: 0.25914 - acc: 0.8876 -- iter: 128/192
[A[ATraining Step: 143  | total loss: [1m[32m0.25585[0m[0m | time: 3.060s
[2K
| Adam | epoch: 024 | loss: 0.25585 - acc: 0.8926 -- iter: 160/192
[A[ATraining Step: 144  | total loss: [1m[32m0.24418[0m[0m | time: 4.679s
[2K
| Adam | epoch: 024 | loss: 0.24418 - acc: 0.8971 | val_loss: 0.78347 - val_acc: 0.7049 -- iter: 192/192
--
Training Step: 145  | total loss: [1m[32m0.22782[0m[0m | time: 0.627s
[2K
| Adam | epoch: 025 | loss: 0.22782 - acc: 0.9074 -- iter: 032/192
[A[ATraining Step: 146  | total loss: [1m[32m0.21275[0m[0m | time: 1.233s
[2K
| Adam | epoch: 025 | loss: 0.21275 - acc: 0.9135 -- iter: 064/192
[A[ATraining Step: 147  | total loss: [1m[32m0.22188[0m[0m | time: 1.838s
[2K
| Adam | epoch: 025 | loss: 0.22188 - acc: 0.9128 -- iter: 096/192
[A[ATraining Step: 148  | total loss: [1m[32m0.22287[0m[0m | time: 2.460s
[2K
| Adam | epoch: 025 | loss: 0.22287 - acc: 0.9121 -- iter: 128/192
[A[ATraining Step: 149  | total loss: [1m[32m0.21208[0m[0m | time: 3.087s
[2K
| Adam | epoch: 025 | loss: 0.21208 - acc: 0.9178 -- iter: 160/192
[A[ATraining Step: 150  | total loss: [1m[32m0.20461[0m[0m | time: 4.725s
[2K
| Adam | epoch: 025 | loss: 0.20461 - acc: 0.9229 | val_loss: 0.78336 - val_acc: 0.7541 -- iter: 192/192
--
Training Step: 151  | total loss: [1m[32m0.20049[0m[0m | time: 0.637s
[2K
| Adam | epoch: 026 | loss: 0.20049 - acc: 0.9181 -- iter: 032/192
[A[ATraining Step: 152  | total loss: [1m[32m0.18628[0m[0m | time: 1.247s
[2K
| Adam | epoch: 026 | loss: 0.18628 - acc: 0.9263 -- iter: 064/192
[A[ATraining Step: 153  | total loss: [1m[32m0.17150[0m[0m | time: 1.912s
[2K
| Adam | epoch: 026 | loss: 0.17150 - acc: 0.9337 -- iter: 096/192
[A[ATraining Step: 154  | total loss: [1m[32m0.15956[0m[0m | time: 2.514s
[2K
| Adam | epoch: 026 | loss: 0.15956 - acc: 0.9403 -- iter: 128/192
[A[ATraining Step: 155  | total loss: [1m[32m0.14934[0m[0m | time: 3.133s
[2K
| Adam | epoch: 026 | loss: 0.14934 - acc: 0.9463 -- iter: 160/192
[A[ATraining Step: 156  | total loss: [1m[32m0.14782[0m[0m | time: 4.749s
[2K
| Adam | epoch: 026 | loss: 0.14782 - acc: 0.9454 | val_loss: 0.82270 - val_acc: 0.7869 -- iter: 192/192
--
Training Step: 157  | total loss: [1m[32m0.18144[0m[0m | time: 0.611s
[2K
| Adam | epoch: 027 | loss: 0.18144 - acc: 0.9383 -- iter: 032/192
[A[ATraining Step: 158  | total loss: [1m[32m0.16749[0m[0m | time: 1.231s
[2K
| Adam | epoch: 027 | loss: 0.16749 - acc: 0.9445 -- iter: 064/192
[A[ATraining Step: 159  | total loss: [1m[32m0.15495[0m[0m | time: 1.852s
[2K
| Adam | epoch: 027 | loss: 0.15495 - acc: 0.9501 -- iter: 096/192
[A[ATraining Step: 160  | total loss: [1m[32m0.14752[0m[0m | time: 2.460s
[2K
| Adam | epoch: 027 | loss: 0.14752 - acc: 0.9519 -- iter: 128/192
[A[ATraining Step: 161  | total loss: [1m[32m0.13939[0m[0m | time: 3.063s
[2K
| Adam | epoch: 027 | loss: 0.13939 - acc: 0.9567 -- iter: 160/192
[A[ATraining Step: 162  | total loss: [1m[32m0.13091[0m[0m | time: 4.682s
[2K
| Adam | epoch: 027 | loss: 0.13091 - acc: 0.9611 | val_loss: 0.88097 - val_acc: 0.7705 -- iter: 192/192
--
Training Step: 163  | total loss: [1m[32m0.13729[0m[0m | time: 0.621s
[2K
| Adam | epoch: 028 | loss: 0.13729 - acc: 0.9587 -- iter: 032/192
[A[ATraining Step: 164  | total loss: [1m[32m0.13710[0m[0m | time: 1.233s
[2K
| Adam | epoch: 028 | loss: 0.13710 - acc: 0.9597 -- iter: 064/192
[A[ATraining Step: 165  | total loss: [1m[32m0.13736[0m[0m | time: 1.859s
[2K
| Adam | epoch: 028 | loss: 0.13736 - acc: 0.9575 -- iter: 096/192
[A[ATraining Step: 166  | total loss: [1m[32m0.12749[0m[0m | time: 2.476s
[2K
| Adam | epoch: 028 | loss: 0.12749 - acc: 0.9617 -- iter: 128/192
[A[ATraining Step: 167  | total loss: [1m[32m0.11851[0m[0m | time: 3.085s
[2K
| Adam | epoch: 028 | loss: 0.11851 - acc: 0.9656 -- iter: 160/192
[A[ATraining Step: 168  | total loss: [1m[32m0.11064[0m[0m | time: 4.692s
[2K
| Adam | epoch: 028 | loss: 0.11064 - acc: 0.9690 | val_loss: 0.83495 - val_acc: 0.8197 -- iter: 192/192
--
Training Step: 169  | total loss: [1m[32m0.10384[0m[0m | time: 0.574s
[2K
| Adam | epoch: 029 | loss: 0.10384 - acc: 0.9721 -- iter: 032/192
[A[ATraining Step: 170  | total loss: [1m[32m0.10055[0m[0m | time: 1.169s
[2K
| Adam | epoch: 029 | loss: 0.10055 - acc: 0.9718 -- iter: 064/192
[A[ATraining Step: 171  | total loss: [1m[32m0.09185[0m[0m | time: 1.772s
[2K
| Adam | epoch: 029 | loss: 0.09185 - acc: 0.9746 -- iter: 096/192
[A[ATraining Step: 172  | total loss: [1m[32m0.08651[0m[0m | time: 2.372s
[2K
| Adam | epoch: 029 | loss: 0.08651 - acc: 0.9771 -- iter: 128/192
[A[ATraining Step: 173  | total loss: [1m[32m0.08066[0m[0m | time: 2.989s
[2K
| Adam | epoch: 029 | loss: 0.08066 - acc: 0.9794 -- iter: 160/192
[A[ATraining Step: 174  | total loss: [1m[32m0.07620[0m[0m | time: 4.601s
[2K
| Adam | epoch: 029 | loss: 0.07620 - acc: 0.9815 | val_loss: 0.88928 - val_acc: 0.8033 -- iter: 192/192
--
Training Step: 175  | total loss: [1m[32m0.08365[0m[0m | time: 0.615s
[2K
| Adam | epoch: 030 | loss: 0.08365 - acc: 0.9802 -- iter: 032/192
[A[ATraining Step: 176  | total loss: [1m[32m0.08648[0m[0m | time: 1.216s
[2K
| Adam | epoch: 030 | loss: 0.08648 - acc: 0.9728 -- iter: 064/192
[A[ATraining Step: 177  | total loss: [1m[32m0.07895[0m[0m | time: 1.838s
[2K
| Adam | epoch: 030 | loss: 0.07895 - acc: 0.9755 -- iter: 096/192
[A[ATraining Step: 178  | total loss: [1m[32m0.07874[0m[0m | time: 2.444s
[2K
| Adam | epoch: 030 | loss: 0.07874 - acc: 0.9717 -- iter: 128/192
[A[ATraining Step: 179  | total loss: [1m[32m0.07368[0m[0m | time: 3.067s
[2K
| Adam | epoch: 030 | loss: 0.07368 - acc: 0.9746 -- iter: 160/192
[A[ATraining Step: 180  | total loss: [1m[32m0.07304[0m[0m | time: 4.686s
[2K
| Adam | epoch: 030 | loss: 0.07304 - acc: 0.9740 | val_loss: 0.93630 - val_acc: 0.7541 -- iter: 192/192
--
Validation AUC:0.7881720430107527
Validation AUPRC:0.7029687813091295
Test AUC:0.8825431034482758
Test AUPRC:0.8969096820772182
BestTestF1Score	0.83	0.61	0.8	0.76	0.91	29	9	20	3	0.07
BestTestMCCScore	0.83	0.61	0.8	0.76	0.91	29	9	20	3	0.07
BestTestAccuracyScore	0.75	0.57	0.77	0.88	0.66	21	3	26	11	0.85
BestValidationF1Score	0.79	0.55	0.75	0.68	0.93	28	13	18	2	0.07
BestValidationMCC	0.79	0.55	0.75	0.68	0.93	28	13	18	2	0.07
BestValidationAccuracy	0.73	0.51	0.75	0.8	0.67	20	5	26	10	0.85
TestPredictions (Threshold:0.07)
CHEMBL3088065,TP,ACT,0.8299999833106995	CHEMBL575060,FN,ACT,0.009999999776482582	CHEMBL3798907,FP,INACT,0.9900000095367432	CHEMBL372643,TP,ACT,0.9900000095367432	CHEMBL557092,TN,INACT,0.0	CHEMBL504772,TN,INACT,0.0	CHEMBL1649675,TP,ACT,0.6000000238418579	CHEMBL493892,TN,INACT,0.009999999776482582	CHEMBL1649673,TP,ACT,0.7699999809265137	CHEMBL1642171,TP,ACT,0.49000000953674316	CHEMBL1649676,TP,ACT,0.9800000190734863	CHEMBL121915,TP,ACT,1.0	CHEMBL96281,TN,INACT,0.0	CHEMBL299291,FP,INACT,0.7900000214576721	CHEMBL120808,FN,ACT,0.009999999776482582	CHEMBL63861,TN,INACT,0.0	CHEMBL3759959,FP,INACT,0.1899999976158142	CHEMBL1642155,TP,ACT,1.0	CHEMBL1214447,TP,ACT,1.0	CHEMBL1214448,TP,ACT,1.0	CHEMBL1289063,TP,ACT,0.9300000071525574	CHEMBL77362,FP,INACT,0.8700000047683716	CHEMBL1098104,TN,INACT,0.009999999776482582	CHEMBL3799325,TN,INACT,0.029999999329447746	CHEMBL2440701,TN,INACT,0.029999999329447746	CHEMBL122656,TP,ACT,1.0	CHEMBL267929,TN,INACT,0.009999999776482582	CHEMBL1290731,TP,ACT,0.9800000190734863	CHEMBL154700,TN,INACT,0.0	CHEMBL442165,TN,INACT,0.0	CHEMBL1649664,TP,ACT,0.8100000023841858	CHEMBL331644,TP,ACT,1.0	CHEMBL3797378,TP,ACT,0.1599999964237213	CHEMBL1289410,TP,ACT,0.9900000095367432	CHEMBL1649681,TP,ACT,0.9399999976158142	CHEMBL1649661,TN,INACT,0.05999999865889549	CHEMBL302402,TN,INACT,0.029999999329447746	CHEMBL3799732,TP,ACT,0.9900000095367432	CHEMBL156519,TN,INACT,0.009999999776482582	CHEMBL58027,FP,INACT,0.6700000166893005	CHEMBL2440691,FP,INACT,0.10000000149011612	CHEMBL3800265,TP,ACT,0.20000000298023224	CHEMBL260328,TN,INACT,0.009999999776482582	CHEMBL303415,FP,INACT,0.3799999952316284	CHEMBL8967,TN,INACT,0.0	CHEMBL1214259,TP,ACT,0.9900000095367432	CHEMBL3088072,TP,ACT,1.0	CHEMBL1555332,FP,INACT,0.9900000095367432	CHEMBL346524,TN,INACT,0.0	CHEMBL116915,TN,INACT,0.009999999776482582	CHEMBL1642161,TP,ACT,1.0	CHEMBL1642166,TP,ACT,1.0	CHEMBL3088060,TP,ACT,0.9900000095367432	CHEMBL112014,FP,INACT,0.5899999737739563	CHEMBL1214203,TP,ACT,0.9900000095367432	CHEMBL435582,TP,ACT,1.0	CHEMBL506543,FN,ACT,0.009999999776482582	CHEMBL155527,TN,INACT,0.0	CHEMBL1289408,TP,ACT,0.15000000596046448	CHEMBL1214395,TN,INACT,0.029999999329447746	CHEMBL121388,TP,ACT,1.0	

