ImageNetInceptionV2 CHEMBL262 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	1872
Number of inactive compounds :	1872
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL262_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL262_adam_0.001_15_0.8/
---------------------------------
Training samples: 2395
Validation samples: 749
--
Training Step: 1  | time: 464.713s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2395
[A[ATraining Step: 2  | total loss: [1m[32m0.71560[0m[0m | time: 1060.315s
[2K
| Adam | epoch: 001 | loss: 0.71560 - acc: 0.3937 -- iter: 0064/2395
[A[ATraining Step: 3  | total loss: [1m[32m0.89406[0m[0m | time: 1451.081s
[2K
| Adam | epoch: 001 | loss: 0.89406 - acc: 0.4807 -- iter: 0096/2395
[A[ATraining Step: 4  | total loss: [1m[32m1.07363[0m[0m | time: 1714.640s
[2K
| Adam | epoch: 001 | loss: 1.07363 - acc: 0.5186 -- iter: 0128/2395
[A[ATraining Step: 5  | total loss: [1m[32m0.94300[0m[0m | time: 2099.935s
[2K
| Adam | epoch: 001 | loss: 0.94300 - acc: 0.4192 -- iter: 0160/2395
[A[ATraining Step: 6  | total loss: [1m[32m0.80192[0m[0m | time: 2592.992s
[2K
| Adam | epoch: 001 | loss: 0.80192 - acc: 0.5113 -- iter: 0192/2395
[A[ATraining Step: 7  | total loss: [1m[32m0.77955[0m[0m | time: 3052.331s
[2K
| Adam | epoch: 001 | loss: 0.77955 - acc: 0.4858 -- iter: 0224/2395
[A[ATraining Step: 8  | total loss: [1m[32m0.77247[0m[0m | time: 3714.200s
[2K
| Adam | epoch: 001 | loss: 0.77247 - acc: 0.4762 -- iter: 0256/2395
[A[ATraining Step: 9  | total loss: [1m[32m0.77292[0m[0m | time: 4147.763s
[2K
| Adam | epoch: 001 | loss: 0.77292 - acc: 0.4723 -- iter: 0288/2395
[A[ATraining Step: 10  | total loss: [1m[32m0.73218[0m[0m | time: 4209.200s
[2K
| Adam | epoch: 001 | loss: 0.73218 - acc: 0.5174 -- iter: 0320/2395
[A[ATraining Step: 11  | total loss: [1m[32m0.74244[0m[0m | time: 4249.855s
[2K
| Adam | epoch: 001 | loss: 0.74244 - acc: 0.5091 -- iter: 0352/2395
[A[ATraining Step: 12  | total loss: [1m[32m0.76620[0m[0m | time: 4275.396s
[2K
| Adam | epoch: 001 | loss: 0.76620 - acc: 0.5050 -- iter: 0384/2395
[A[ATraining Step: 13  | total loss: [1m[32m0.74271[0m[0m | time: 4292.191s
[2K
| Adam | epoch: 001 | loss: 0.74271 - acc: 0.4627 -- iter: 0416/2395
[A[ATraining Step: 14  | total loss: [1m[32m0.72698[0m[0m | time: 4313.149s
[2K
| Adam | epoch: 001 | loss: 0.72698 - acc: 0.5035 -- iter: 0448/2395
[A[ATraining Step: 15  | total loss: [1m[32m0.73673[0m[0m | time: 4332.812s
[2K
| Adam | epoch: 001 | loss: 0.73673 - acc: 0.4532 -- iter: 0480/2395
[A[ATraining Step: 16  | total loss: [1m[32m0.73710[0m[0m | time: 4354.945s
[2K
| Adam | epoch: 001 | loss: 0.73710 - acc: 0.4708 -- iter: 0512/2395
[A[ATraining Step: 17  | total loss: [1m[32m0.73555[0m[0m | time: 4372.032s
[2K
| Adam | epoch: 001 | loss: 0.73555 - acc: 0.4813 -- iter: 0544/2395
[A[ATraining Step: 18  | total loss: [1m[32m0.73236[0m[0m | time: 4391.226s
[2K
| Adam | epoch: 001 | loss: 0.73236 - acc: 0.4445 -- iter: 0576/2395
[A[ATraining Step: 19  | total loss: [1m[32m0.71881[0m[0m | time: 4411.542s
[2K
| Adam | epoch: 001 | loss: 0.71881 - acc: 0.4838 -- iter: 0608/2395
[A[ATraining Step: 20  | total loss: [1m[32m0.72019[0m[0m | time: 4435.233s
[2K
| Adam | epoch: 001 | loss: 0.72019 - acc: 0.4991 -- iter: 0640/2395
[A[ATraining Step: 21  | total loss: [1m[32m0.68963[0m[0m | time: 4469.142s
[2K
| Adam | epoch: 001 | loss: 0.68963 - acc: 0.5672 -- iter: 0672/2395
[A[ATraining Step: 22  | total loss: [1m[32m0.77075[0m[0m | time: 4493.524s
[2K
| Adam | epoch: 001 | loss: 0.77075 - acc: 0.5189 -- iter: 0704/2395
[A[ATraining Step: 23  | total loss: [1m[32m0.78503[0m[0m | time: 4514.008s
[2K
| Adam | epoch: 001 | loss: 0.78503 - acc: 0.5044 -- iter: 0736/2395
[A[ATraining Step: 24  | total loss: [1m[32m0.79380[0m[0m | time: 4545.131s
[2K
| Adam | epoch: 001 | loss: 0.79380 - acc: 0.5031 -- iter: 0768/2395
[A[ATraining Step: 25  | total loss: [1m[32m0.76712[0m[0m | time: 4567.939s
[2K
| Adam | epoch: 001 | loss: 0.76712 - acc: 0.4852 -- iter: 0800/2395
[A[ATraining Step: 26  | total loss: [1m[32m0.74838[0m[0m | time: 4587.836s
[2K
| Adam | epoch: 001 | loss: 0.74838 - acc: 0.4726 -- iter: 0832/2395
[A[ATraining Step: 27  | total loss: [1m[32m0.72336[0m[0m | time: 4607.527s
[2K
| Adam | epoch: 001 | loss: 0.72336 - acc: 0.5198 -- iter: 0864/2395
[A[ATraining Step: 28  | total loss: [1m[32m0.75985[0m[0m | time: 4623.290s
[2K
| Adam | epoch: 001 | loss: 0.75985 - acc: 0.5071 -- iter: 0896/2395
[A[ATraining Step: 29  | total loss: [1m[32m0.80298[0m[0m | time: 4638.966s
[2K
| Adam | epoch: 001 | loss: 0.80298 - acc: 0.4901 -- iter: 0928/2395
[A[ATraining Step: 30  | total loss: [1m[32m0.82855[0m[0m | time: 4680.809s
[2K
| Adam | epoch: 001 | loss: 0.82855 - acc: 0.4703 -- iter: 0960/2395
[A[ATraining Step: 31  | total loss: [1m[32m0.81158[0m[0m | time: 4709.998s
[2K
| Adam | epoch: 001 | loss: 0.81158 - acc: 0.4843 -- iter: 0992/2395
[A[ATraining Step: 32  | total loss: [1m[32m0.79416[0m[0m | time: 4726.529s
[2K
| Adam | epoch: 001 | loss: 0.79416 - acc: 0.4879 -- iter: 1024/2395
[A[ATraining Step: 33  | total loss: [1m[32m0.77682[0m[0m | time: 4748.470s
[2K
| Adam | epoch: 001 | loss: 0.77682 - acc: 0.4905 -- iter: 1056/2395
[A[ATraining Step: 34  | total loss: [1m[32m0.75238[0m[0m | time: 4764.220s
[2K
| Adam | epoch: 001 | loss: 0.75238 - acc: 0.5193 -- iter: 1088/2395
[A[ATraining Step: 35  | total loss: [1m[32m0.77380[0m[0m | time: 4779.834s
[2K
| Adam | epoch: 001 | loss: 0.77380 - acc: 0.4761 -- iter: 1120/2395
[A[ATraining Step: 36  | total loss: [1m[32m0.77215[0m[0m | time: 4799.248s
[2K
| Adam | epoch: 001 | loss: 0.77215 - acc: 0.4809 -- iter: 1152/2395
[A[ATraining Step: 37  | total loss: [1m[32m0.78067[0m[0m | time: 4828.859s
[2K
| Adam | epoch: 001 | loss: 0.78067 - acc: 0.4660 -- iter: 1184/2395
[A[ATraining Step: 38  | total loss: [1m[32m0.76547[0m[0m | time: 4854.207s
[2K
| Adam | epoch: 001 | loss: 0.76547 - acc: 0.4910 -- iter: 1216/2395
[A[ATraining Step: 39  | total loss: [1m[32m0.75219[0m[0m | time: 4886.911s
[2K
| Adam | epoch: 001 | loss: 0.75219 - acc: 0.4927 -- iter: 1248/2395
[A[ATraining Step: 40  | total loss: [1m[32m0.74146[0m[0m | time: 4902.932s
[2K
| Adam | epoch: 001 | loss: 0.74146 - acc: 0.4999 -- iter: 1280/2395
[A[ATraining Step: 41  | total loss: [1m[32m0.73122[0m[0m | time: 4925.132s
[2K
| Adam | epoch: 001 | loss: 0.73122 - acc: 0.5000 -- iter: 1312/2395
[A[ATraining Step: 42  | total loss: [1m[32m0.74126[0m[0m | time: 4957.691s
[2K
| Adam | epoch: 001 | loss: 0.74126 - acc: 0.4831 -- iter: 1344/2395
[A[ATraining Step: 43  | total loss: [1m[32m0.75460[0m[0m | time: 4973.295s
[2K
| Adam | epoch: 001 | loss: 0.75460 - acc: 0.4640 -- iter: 1376/2395
[A[ATraining Step: 44  | total loss: [1m[32m0.75671[0m[0m | time: 4989.284s
[2K
| Adam | epoch: 001 | loss: 0.75671 - acc: 0.4486 -- iter: 1408/2395
[A[ATraining Step: 45  | total loss: [1m[32m0.74373[0m[0m | time: 5005.295s
[2K
| Adam | epoch: 001 | loss: 0.74373 - acc: 0.4520 -- iter: 1440/2395
[A[ATraining Step: 46  | total loss: [1m[32m0.73511[0m[0m | time: 5020.875s
[2K
| Adam | epoch: 001 | loss: 0.73511 - acc: 0.4548 -- iter: 1472/2395
[A[ATraining Step: 47  | total loss: [1m[32m0.73305[0m[0m | time: 5037.127s
[2K
| Adam | epoch: 001 | loss: 0.73305 - acc: 0.4724 -- iter: 1504/2395
[A[ATraining Step: 48  | total loss: [1m[32m0.72759[0m[0m | time: 5053.679s
[2K
| Adam | epoch: 001 | loss: 0.72759 - acc: 0.4819 -- iter: 1536/2395
[A[ATraining Step: 49  | total loss: [1m[32m0.72937[0m[0m | time: 5069.167s
[2K
| Adam | epoch: 001 | loss: 0.72937 - acc: 0.5094 -- iter: 1568/2395
[A[ATraining Step: 50  | total loss: [1m[32m0.74427[0m[0m | time: 5087.149s
[2K
| Adam | epoch: 001 | loss: 0.74427 - acc: 0.5031 -- iter: 1600/2395
[A[ATraining Step: 51  | total loss: [1m[32m0.75368[0m[0m | time: 5104.086s
[2K
| Adam | epoch: 001 | loss: 0.75368 - acc: 0.4979 -- iter: 1632/2395
[A[ATraining Step: 52  | total loss: [1m[32m0.77345[0m[0m | time: 5125.535s
[2K
| Adam | epoch: 001 | loss: 0.77345 - acc: 0.4654 -- iter: 1664/2395
[A[ATraining Step: 53  | total loss: [1m[32m0.76408[0m[0m | time: 5140.967s
[2K
| Adam | epoch: 001 | loss: 0.76408 - acc: 0.4613 -- iter: 1696/2395
[A[ATraining Step: 54  | total loss: [1m[32m0.76243[0m[0m | time: 5160.155s
[2K
| Adam | epoch: 001 | loss: 0.76243 - acc: 0.4487 -- iter: 1728/2395
[A[ATraining Step: 55  | total loss: [1m[32m0.74813[0m[0m | time: 5178.217s
[2K
| Adam | epoch: 001 | loss: 0.74813 - acc: 0.4739 -- iter: 1760/2395
[A[ATraining Step: 56  | total loss: [1m[32m0.75286[0m[0m | time: 5194.028s
[2K
| Adam | epoch: 001 | loss: 0.75286 - acc: 0.4732 -- iter: 1792/2395
[A[ATraining Step: 57  | total loss: [1m[32m0.76316[0m[0m | time: 5209.387s
[2K
| Adam | epoch: 001 | loss: 0.76316 - acc: 0.4856 -- iter: 1824/2395
[A[ATraining Step: 58  | total loss: [1m[32m0.77031[0m[0m | time: 5224.551s
[2K
| Adam | epoch: 001 | loss: 0.77031 - acc: 0.4662 -- iter: 1856/2395
[A[ATraining Step: 59  | total loss: [1m[32m0.78631[0m[0m | time: 5240.128s
[2K
| Adam | epoch: 001 | loss: 0.78631 - acc: 0.4498 -- iter: 1888/2395
[A[ATraining Step: 60  | total loss: [1m[32m0.77587[0m[0m | time: 5256.710s
[2K
| Adam | epoch: 001 | loss: 0.77587 - acc: 0.4606 -- iter: 1920/2395
[A[ATraining Step: 61  | total loss: [1m[32m0.76613[0m[0m | time: 5272.286s
[2K
| Adam | epoch: 001 | loss: 0.76613 - acc: 0.4739 -- iter: 1952/2395
[A[ATraining Step: 62  | total loss: [1m[32m0.75307[0m[0m | time: 5287.694s
[2K
| Adam | epoch: 001 | loss: 0.75307 - acc: 0.4852 -- iter: 1984/2395
[A[ATraining Step: 63  | total loss: [1m[32m0.73905[0m[0m | time: 5304.925s
[2K
| Adam | epoch: 001 | loss: 0.73905 - acc: 0.5030 -- iter: 2016/2395
[A[ATraining Step: 64  | total loss: [1m[32m0.73967[0m[0m | time: 5323.826s
[2K
| Adam | epoch: 001 | loss: 0.73967 - acc: 0.4948 -- iter: 2048/2395
[A[ATraining Step: 65  | total loss: [1m[32m0.74819[0m[0m | time: 5340.517s
[2K
| Adam | epoch: 001 | loss: 0.74819 - acc: 0.4877 -- iter: 2080/2395
[A[ATraining Step: 66  | total loss: [1m[32m0.73595[0m[0m | time: 5356.982s
[2K
| Adam | epoch: 001 | loss: 0.73595 - acc: 0.5006 -- iter: 2112/2395
[A[ATraining Step: 67  | total loss: [1m[32m0.74581[0m[0m | time: 5372.769s
[2K
| Adam | epoch: 001 | loss: 0.74581 - acc: 0.4893 -- iter: 2144/2395
[A[ATraining Step: 68  | total loss: [1m[32m0.73736[0m[0m | time: 5389.016s
[2K
| Adam | epoch: 001 | loss: 0.73736 - acc: 0.5054 -- iter: 2176/2395
[A[ATraining Step: 69  | total loss: [1m[32m0.74388[0m[0m | time: 5404.829s
[2K
| Adam | epoch: 001 | loss: 0.74388 - acc: 0.5047 -- iter: 2208/2395
[A[ATraining Step: 70  | total loss: [1m[32m0.73454[0m[0m | time: 5420.625s
[2K
| Adam | epoch: 001 | loss: 0.73454 - acc: 0.5078 -- iter: 2240/2395
[A[ATraining Step: 71  | total loss: [1m[32m0.72997[0m[0m | time: 5447.650s
[2K
| Adam | epoch: 001 | loss: 0.72997 - acc: 0.5176 -- iter: 2272/2395
[A[ATraining Step: 72  | total loss: [1m[32m0.72224[0m[0m | time: 5471.210s
[2K
| Adam | epoch: 001 | loss: 0.72224 - acc: 0.5156 -- iter: 2304/2395
[A[ATraining Step: 73  | total loss: [1m[32m0.72265[0m[0m | time: 5488.892s
[2K
| Adam | epoch: 001 | loss: 0.72265 - acc: 0.5069 -- iter: 2336/2395
[A[ATraining Step: 74  | total loss: [1m[32m0.72256[0m[0m | time: 5504.172s
[2K
| Adam | epoch: 001 | loss: 0.72256 - acc: 0.5027 -- iter: 2368/2395
[A[ATraining Step: 75  | total loss: [1m[32m0.71937[0m[0m | time: 5600.020s
[2K
| Adam | epoch: 001 | loss: 0.71937 - acc: 0.5058 | val_loss: 0.69604 - val_acc: 0.4913 -- iter: 2395/2395
--
Training Step: 76  | total loss: [1m[32m0.71364[0m[0m | time: 18.980s
[2K
| Adam | epoch: 002 | loss: 0.71364 - acc: 0.5072 -- iter: 0032/2395
[A[ATraining Step: 77  | total loss: [1m[32m0.70876[0m[0m | time: 42.245s
[2K
| Adam | epoch: 002 | loss: 0.70876 - acc: 0.5123 -- iter: 0064/2395
[A[ATraining Step: 78  | total loss: [1m[32m0.70532[0m[0m | time: 75.862s
[2K
| Adam | epoch: 002 | loss: 0.70532 - acc: 0.5143 -- iter: 0096/2395
[A[ATraining Step: 79  | total loss: [1m[32m0.70807[0m[0m | time: 104.320s
[2K
| Adam | epoch: 002 | loss: 0.70807 - acc: 0.5096 -- iter: 0128/2395
[A[ATraining Step: 80  | total loss: [1m[32m0.71044[0m[0m | time: 119.796s
[2K
| Adam | epoch: 002 | loss: 0.71044 - acc: 0.5022 -- iter: 0160/2395
[A[ATraining Step: 81  | total loss: [1m[32m0.70977[0m[0m | time: 136.102s
[2K
| Adam | epoch: 002 | loss: 0.70977 - acc: 0.4988 -- iter: 0192/2395
[A[ATraining Step: 82  | total loss: [1m[32m0.70962[0m[0m | time: 151.773s
[2K
| Adam | epoch: 002 | loss: 0.70962 - acc: 0.4927 -- iter: 0224/2395
[A[ATraining Step: 83  | total loss: [1m[32m0.71015[0m[0m | time: 167.689s
[2K
| Adam | epoch: 002 | loss: 0.71015 - acc: 0.4840 -- iter: 0256/2395
[A[ATraining Step: 84  | total loss: [1m[32m0.71377[0m[0m | time: 188.353s
[2K
| Adam | epoch: 002 | loss: 0.71377 - acc: 0.4731 -- iter: 0288/2395
[A[ATraining Step: 85  | total loss: [1m[32m0.70752[0m[0m | time: 204.480s
[2K
| Adam | epoch: 002 | loss: 0.70752 - acc: 0.4821 -- iter: 0320/2395
[A[ATraining Step: 86  | total loss: [1m[32m0.71623[0m[0m | time: 221.588s
[2K
| Adam | epoch: 002 | loss: 0.71623 - acc: 0.4620 -- iter: 0352/2395
[A[ATraining Step: 87  | total loss: [1m[32m0.71689[0m[0m | time: 247.577s
[2K
| Adam | epoch: 002 | loss: 0.71689 - acc: 0.4627 -- iter: 0384/2395
[A[ATraining Step: 88  | total loss: [1m[32m0.72105[0m[0m | time: 264.712s
[2K
| Adam | epoch: 002 | loss: 0.72105 - acc: 0.4570 -- iter: 0416/2395
[A[ATraining Step: 89  | total loss: [1m[32m0.71658[0m[0m | time: 284.060s
[2K
| Adam | epoch: 002 | loss: 0.71658 - acc: 0.4613 -- iter: 0448/2395
[A[ATraining Step: 90  | total loss: [1m[32m0.71712[0m[0m | time: 326.156s
[2K
| Adam | epoch: 002 | loss: 0.71712 - acc: 0.4558 -- iter: 0480/2395
[A[ATraining Step: 91  | total loss: [1m[32m0.71585[0m[0m | time: 343.650s
[2K
| Adam | epoch: 002 | loss: 0.71585 - acc: 0.4571 -- iter: 0512/2395
[A[ATraining Step: 92  | total loss: [1m[32m0.71404[0m[0m | time: 363.731s
[2K
| Adam | epoch: 002 | loss: 0.71404 - acc: 0.4583 -- iter: 0544/2395
[A[ATraining Step: 93  | total loss: [1m[32m0.71662[0m[0m | time: 374.718s
[2K
| Adam | epoch: 002 | loss: 0.71662 - acc: 0.4624 -- iter: 0576/2395
[A[ATraining Step: 94  | total loss: [1m[32m0.71593[0m[0m | time: 385.655s
[2K
| Adam | epoch: 002 | loss: 0.71593 - acc: 0.4662 -- iter: 0608/2395
[A[ATraining Step: 95  | total loss: [1m[32m0.71350[0m[0m | time: 397.360s
[2K
| Adam | epoch: 002 | loss: 0.71350 - acc: 0.4696 -- iter: 0640/2395
[A[ATraining Step: 96  | total loss: [1m[32m0.70863[0m[0m | time: 442.944s
[2K
| Adam | epoch: 002 | loss: 0.70863 - acc: 0.4757 -- iter: 0672/2395
[A[ATraining Step: 97  | total loss: [1m[32m0.70821[0m[0m | time: 484.858s
[2K
| Adam | epoch: 002 | loss: 0.70821 - acc: 0.4782 -- iter: 0704/2395
[A[ATraining Step: 98  | total loss: [1m[32m0.71323[0m[0m | time: 542.633s
[2K
| Adam | epoch: 002 | loss: 0.71323 - acc: 0.4679 -- iter: 0736/2395
[A[ATraining Step: 99  | total loss: [1m[32m0.71868[0m[0m | time: 562.432s
[2K
| Adam | epoch: 002 | loss: 0.71868 - acc: 0.4554 -- iter: 0768/2395
[A[ATraining Step: 100  | total loss: [1m[32m0.71861[0m[0m | time: 575.075s
[2K
| Adam | epoch: 002 | loss: 0.71861 - acc: 0.4662 -- iter: 0800/2395
[A[ATraining Step: 101  | total loss: [1m[32m0.71615[0m[0m | time: 587.563s
[2K
| Adam | epoch: 002 | loss: 0.71615 - acc: 0.4633 -- iter: 0832/2395
[A[ATraining Step: 102  | total loss: [1m[32m0.71340[0m[0m | time: 600.484s
[2K
| Adam | epoch: 002 | loss: 0.71340 - acc: 0.4701 -- iter: 0864/2395
[A[ATraining Step: 103  | total loss: [1m[32m0.71069[0m[0m | time: 613.230s
[2K
| Adam | epoch: 002 | loss: 0.71069 - acc: 0.4731 -- iter: 0896/2395
[A[ATraining Step: 104  | total loss: [1m[32m0.71376[0m[0m | time: 626.064s
[2K
| Adam | epoch: 002 | loss: 0.71376 - acc: 0.4695 -- iter: 0928/2395
[A[ATraining Step: 105  | total loss: [1m[32m0.71950[0m[0m | time: 638.329s
[2K
| Adam | epoch: 002 | loss: 0.71950 - acc: 0.4726 -- iter: 0960/2395
[A[ATraining Step: 106  | total loss: [1m[32m0.72170[0m[0m | time: 650.977s
[2K
| Adam | epoch: 002 | loss: 0.72170 - acc: 0.4691 -- iter: 0992/2395
[A[ATraining Step: 107  | total loss: [1m[32m0.72391[0m[0m | time: 663.750s
[2K
| Adam | epoch: 002 | loss: 0.72391 - acc: 0.4659 -- iter: 1024/2395
[A[ATraining Step: 108  | total loss: [1m[32m0.72220[0m[0m | time: 676.498s
[2K
| Adam | epoch: 002 | loss: 0.72220 - acc: 0.4662 -- iter: 1056/2395
[A[ATraining Step: 109  | total loss: [1m[32m0.71603[0m[0m | time: 688.987s
[2K
| Adam | epoch: 002 | loss: 0.71603 - acc: 0.4789 -- iter: 1088/2395
[A[ATraining Step: 110  | total loss: [1m[32m0.71565[0m[0m | time: 701.562s
[2K
| Adam | epoch: 002 | loss: 0.71565 - acc: 0.4873 -- iter: 1120/2395
[A[ATraining Step: 111  | total loss: [1m[32m0.71443[0m[0m | time: 714.038s
[2K
| Adam | epoch: 002 | loss: 0.71443 - acc: 0.4854 -- iter: 1152/2395
[A[ATraining Step: 112  | total loss: [1m[32m0.71327[0m[0m | time: 727.170s
[2K
| Adam | epoch: 002 | loss: 0.71327 - acc: 0.4869 -- iter: 1184/2395
[A[ATraining Step: 113  | total loss: [1m[32m0.71404[0m[0m | time: 740.162s
[2K
| Adam | epoch: 002 | loss: 0.71404 - acc: 0.4788 -- iter: 1216/2395
[A[ATraining Step: 114  | total loss: [1m[32m0.71156[0m[0m | time: 752.937s
[2K
| Adam | epoch: 002 | loss: 0.71156 - acc: 0.4966 -- iter: 1248/2395
[A[ATraining Step: 115  | total loss: [1m[32m0.70848[0m[0m | time: 765.847s
[2K
| Adam | epoch: 002 | loss: 0.70848 - acc: 0.4969 -- iter: 1280/2395
[A[ATraining Step: 116  | total loss: [1m[32m0.70614[0m[0m | time: 778.694s
[2K
| Adam | epoch: 002 | loss: 0.70614 - acc: 0.5129 -- iter: 1312/2395
[A[ATraining Step: 117  | total loss: [1m[32m0.71120[0m[0m | time: 791.116s
[2K
| Adam | epoch: 002 | loss: 0.71120 - acc: 0.5053 -- iter: 1344/2395
[A[ATraining Step: 118  | total loss: [1m[32m0.71362[0m[0m | time: 804.405s
[2K
| Adam | epoch: 002 | loss: 0.71362 - acc: 0.4954 -- iter: 1376/2395
[A[ATraining Step: 119  | total loss: [1m[32m0.70966[0m[0m | time: 817.162s
[2K
| Adam | epoch: 002 | loss: 0.70966 - acc: 0.5177 -- iter: 1408/2395
[A[ATraining Step: 120  | total loss: [1m[32m0.70990[0m[0m | time: 829.952s
[2K
| Adam | epoch: 002 | loss: 0.70990 - acc: 0.5160 -- iter: 1440/2395
[A[ATraining Step: 121  | total loss: [1m[32m0.70580[0m[0m | time: 842.700s
[2K
| Adam | epoch: 002 | loss: 0.70580 - acc: 0.5331 -- iter: 1472/2395
[A[ATraining Step: 122  | total loss: [1m[32m0.70343[0m[0m | time: 855.981s
[2K
| Adam | epoch: 002 | loss: 0.70343 - acc: 0.5392 -- iter: 1504/2395
[A[ATraining Step: 123  | total loss: [1m[32m0.70713[0m[0m | time: 868.886s
[2K
| Adam | epoch: 002 | loss: 0.70713 - acc: 0.5290 -- iter: 1536/2395
[A[ATraining Step: 124  | total loss: [1m[32m0.70154[0m[0m | time: 882.012s
[2K
| Adam | epoch: 002 | loss: 0.70154 - acc: 0.5417 -- iter: 1568/2395
[A[ATraining Step: 125  | total loss: [1m[32m0.70696[0m[0m | time: 894.666s
[2K
| Adam | epoch: 002 | loss: 0.70696 - acc: 0.5438 -- iter: 1600/2395
[A[ATraining Step: 126  | total loss: [1m[32m0.71392[0m[0m | time: 907.487s
[2K
| Adam | epoch: 002 | loss: 0.71392 - acc: 0.5394 -- iter: 1632/2395
[A[ATraining Step: 127  | total loss: [1m[32m0.71377[0m[0m | time: 919.943s
[2K
| Adam | epoch: 002 | loss: 0.71377 - acc: 0.5199 -- iter: 1664/2395
[A[ATraining Step: 128  | total loss: [1m[32m0.70954[0m[0m | time: 932.764s
[2K
| Adam | epoch: 002 | loss: 0.70954 - acc: 0.5304 -- iter: 1696/2395
[A[ATraining Step: 129  | total loss: [1m[32m0.70637[0m[0m | time: 945.514s
[2K
| Adam | epoch: 002 | loss: 0.70637 - acc: 0.5367 -- iter: 1728/2395
[A[ATraining Step: 130  | total loss: [1m[32m0.70365[0m[0m | time: 958.295s
[2K
| Adam | epoch: 002 | loss: 0.70365 - acc: 0.5362 -- iter: 1760/2395
[A[ATraining Step: 131  | total loss: [1m[32m0.70692[0m[0m | time: 971.195s
[2K
| Adam | epoch: 002 | loss: 0.70692 - acc: 0.5169 -- iter: 1792/2395
[A[ATraining Step: 132  | total loss: [1m[32m0.70460[0m[0m | time: 984.078s
[2K
| Adam | epoch: 002 | loss: 0.70460 - acc: 0.5121 -- iter: 1824/2395
[A[ATraining Step: 133  | total loss: [1m[32m0.70297[0m[0m | time: 997.349s
[2K
| Adam | epoch: 002 | loss: 0.70297 - acc: 0.5109 -- iter: 1856/2395
[A[ATraining Step: 134  | total loss: [1m[32m0.70053[0m[0m | time: 1010.004s
[2K
| Adam | epoch: 002 | loss: 0.70053 - acc: 0.5161 -- iter: 1888/2395
[A[ATraining Step: 135  | total loss: [1m[32m0.70063[0m[0m | time: 1022.826s
[2K
| Adam | epoch: 002 | loss: 0.70063 - acc: 0.5113 -- iter: 1920/2395
[A[ATraining Step: 136  | total loss: [1m[32m0.69636[0m[0m | time: 1035.769s
[2K
| Adam | epoch: 002 | loss: 0.69636 - acc: 0.5258 -- iter: 1952/2395
[A[ATraining Step: 137  | total loss: [1m[32m0.69878[0m[0m | time: 1048.799s
[2K
| Adam | epoch: 002 | loss: 0.69878 - acc: 0.5201 -- iter: 1984/2395
[A[ATraining Step: 138  | total loss: [1m[32m0.69666[0m[0m | time: 1061.567s
[2K
| Adam | epoch: 002 | loss: 0.69666 - acc: 0.5244 -- iter: 2016/2395
[A[ATraining Step: 139  | total loss: [1m[32m0.69793[0m[0m | time: 1074.338s
[2K
| Adam | epoch: 002 | loss: 0.69793 - acc: 0.5188 -- iter: 2048/2395
[A[ATraining Step: 140  | total loss: [1m[32m0.69818[0m[0m | time: 1087.312s
[2K
| Adam | epoch: 002 | loss: 0.69818 - acc: 0.5325 -- iter: 2080/2395
[A[ATraining Step: 141  | total loss: [1m[32m0.69820[0m[0m | time: 1100.079s
[2K
| Adam | epoch: 002 | loss: 0.69820 - acc: 0.5387 -- iter: 2112/2395
[A[ATraining Step: 142  | total loss: [1m[32m0.69439[0m[0m | time: 1112.878s
[2K
| Adam | epoch: 002 | loss: 0.69439 - acc: 0.5567 -- iter: 2144/2395
[A[ATraining Step: 143  | total loss: [1m[32m0.69370[0m[0m | time: 1126.089s
[2K
| Adam | epoch: 002 | loss: 0.69370 - acc: 0.5573 -- iter: 2176/2395
[A[ATraining Step: 144  | total loss: [1m[32m0.68999[0m[0m | time: 1139.080s
[2K
| Adam | epoch: 002 | loss: 0.68999 - acc: 0.5640 -- iter: 2208/2395
[A[ATraining Step: 145  | total loss: [1m[32m0.68912[0m[0m | time: 1151.451s
[2K
| Adam | epoch: 002 | loss: 0.68912 - acc: 0.5670 -- iter: 2240/2395
[A[ATraining Step: 146  | total loss: [1m[32m0.68533[0m[0m | time: 1164.208s
[2K
| Adam | epoch: 002 | loss: 0.68533 - acc: 0.5759 -- iter: 2272/2395
[A[ATraining Step: 147  | total loss: [1m[32m0.67787[0m[0m | time: 1176.672s
[2K
| Adam | epoch: 002 | loss: 0.67787 - acc: 0.5777 -- iter: 2304/2395
[A[ATraining Step: 148  | total loss: [1m[32m0.68919[0m[0m | time: 1189.413s
[2K
| Adam | epoch: 002 | loss: 0.68919 - acc: 0.5637 -- iter: 2336/2395
[A[ATraining Step: 149  | total loss: [1m[32m0.68818[0m[0m | time: 1201.699s
[2K
| Adam | epoch: 002 | loss: 0.68818 - acc: 0.5729 -- iter: 2368/2395
[A[ATraining Step: 150  | total loss: [1m[32m0.69111[0m[0m | time: 1270.139s
[2K
| Adam | epoch: 002 | loss: 0.69111 - acc: 0.5813 | val_loss: 0.77598 - val_acc: 0.5220 -- iter: 2395/2395
--
Training Step: 151  | total loss: [1m[32m0.69015[0m[0m | time: 11.232s
[2K
| Adam | epoch: 003 | loss: 0.69015 - acc: 0.5825 -- iter: 0032/2395
[A[ATraining Step: 152  | total loss: [1m[32m0.68091[0m[0m | time: 23.138s
[2K
| Adam | epoch: 003 | loss: 0.68091 - acc: 0.5909 -- iter: 0064/2395
[A[ATraining Step: 153  | total loss: [1m[32m0.67271[0m[0m | time: 36.335s
[2K
| Adam | epoch: 003 | loss: 0.67271 - acc: 0.6059 -- iter: 0096/2395
[A[ATraining Step: 154  | total loss: [1m[32m0.67184[0m[0m | time: 49.732s
[2K
| Adam | epoch: 003 | loss: 0.67184 - acc: 0.6078 -- iter: 0128/2395
[A[ATraining Step: 155  | total loss: [1m[32m0.68084[0m[0m | time: 62.739s
[2K
| Adam | epoch: 003 | loss: 0.68084 - acc: 0.5877 -- iter: 0160/2395
[A[ATraining Step: 156  | total loss: [1m[32m0.67851[0m[0m | time: 75.887s
[2K
| Adam | epoch: 003 | loss: 0.67851 - acc: 0.5883 -- iter: 0192/2395
[A[ATraining Step: 157  | total loss: [1m[32m0.67580[0m[0m | time: 88.348s
[2K
| Adam | epoch: 003 | loss: 0.67580 - acc: 0.5919 -- iter: 0224/2395
[A[ATraining Step: 158  | total loss: [1m[32m0.67580[0m[0m | time: 101.658s
[2K
| Adam | epoch: 003 | loss: 0.67580 - acc: 0.5859 -- iter: 0256/2395
[A[ATraining Step: 159  | total loss: [1m[32m0.66997[0m[0m | time: 114.561s
[2K
| Adam | epoch: 003 | loss: 0.66997 - acc: 0.5929 -- iter: 0288/2395
[A[ATraining Step: 160  | total loss: [1m[32m0.67094[0m[0m | time: 127.260s
[2K
| Adam | epoch: 003 | loss: 0.67094 - acc: 0.5899 -- iter: 0320/2395
[A[ATraining Step: 161  | total loss: [1m[32m0.67920[0m[0m | time: 140.110s
[2K
| Adam | epoch: 003 | loss: 0.67920 - acc: 0.5840 -- iter: 0352/2395
[A[ATraining Step: 162  | total loss: [1m[32m0.69020[0m[0m | time: 153.071s
[2K
| Adam | epoch: 003 | loss: 0.69020 - acc: 0.5569 -- iter: 0384/2395
[A[ATraining Step: 163  | total loss: [1m[32m0.68574[0m[0m | time: 166.017s
[2K
| Adam | epoch: 003 | loss: 0.68574 - acc: 0.5668 -- iter: 0416/2395
[A[ATraining Step: 164  | total loss: [1m[32m0.68372[0m[0m | time: 178.882s
[2K
| Adam | epoch: 003 | loss: 0.68372 - acc: 0.5757 -- iter: 0448/2395
[A[ATraining Step: 165  | total loss: [1m[32m0.68471[0m[0m | time: 192.131s
[2K
| Adam | epoch: 003 | loss: 0.68471 - acc: 0.5682 -- iter: 0480/2395
[A[ATraining Step: 166  | total loss: [1m[32m0.68593[0m[0m | time: 205.000s
[2K
| Adam | epoch: 003 | loss: 0.68593 - acc: 0.5676 -- iter: 0512/2395
[A[ATraining Step: 167  | total loss: [1m[32m0.68091[0m[0m | time: 217.970s
[2K
| Adam | epoch: 003 | loss: 0.68091 - acc: 0.5733 -- iter: 0544/2395
[A[ATraining Step: 168  | total loss: [1m[32m0.67845[0m[0m | time: 231.367s
[2K
| Adam | epoch: 003 | loss: 0.67845 - acc: 0.5785 -- iter: 0576/2395
[A[ATraining Step: 169  | total loss: [1m[32m0.67457[0m[0m | time: 244.582s
[2K
| Adam | epoch: 003 | loss: 0.67457 - acc: 0.5863 -- iter: 0608/2395
[A[ATraining Step: 170  | total loss: [1m[32m0.67772[0m[0m | time: 257.946s
[2K
| Adam | epoch: 003 | loss: 0.67772 - acc: 0.5808 -- iter: 0640/2395
[A[ATraining Step: 171  | total loss: [1m[32m0.67735[0m[0m | time: 270.873s
[2K
| Adam | epoch: 003 | loss: 0.67735 - acc: 0.5758 -- iter: 0672/2395
[A[ATraining Step: 172  | total loss: [1m[32m0.67900[0m[0m | time: 283.948s
[2K
| Adam | epoch: 003 | loss: 0.67900 - acc: 0.5776 -- iter: 0704/2395
[A[ATraining Step: 173  | total loss: [1m[32m0.68508[0m[0m | time: 297.071s
[2K
| Adam | epoch: 003 | loss: 0.68508 - acc: 0.5605 -- iter: 0736/2395
[A[ATraining Step: 174  | total loss: [1m[32m0.68826[0m[0m | time: 310.138s
[2K
| Adam | epoch: 003 | loss: 0.68826 - acc: 0.5482 -- iter: 0768/2395
[A[ATraining Step: 175  | total loss: [1m[32m0.68713[0m[0m | time: 323.223s
[2K
| Adam | epoch: 003 | loss: 0.68713 - acc: 0.5402 -- iter: 0800/2395
[A[ATraining Step: 176  | total loss: [1m[32m0.68857[0m[0m | time: 336.119s
[2K
| Adam | epoch: 003 | loss: 0.68857 - acc: 0.5300 -- iter: 0832/2395
[A[ATraining Step: 177  | total loss: [1m[32m0.68498[0m[0m | time: 348.966s
[2K
| Adam | epoch: 003 | loss: 0.68498 - acc: 0.5457 -- iter: 0864/2395
[A[ATraining Step: 178  | total loss: [1m[32m0.69285[0m[0m | time: 361.567s
[2K
| Adam | epoch: 003 | loss: 0.69285 - acc: 0.5318 -- iter: 0896/2395
[A[ATraining Step: 179  | total loss: [1m[32m0.69139[0m[0m | time: 374.305s
[2K
| Adam | epoch: 003 | loss: 0.69139 - acc: 0.5473 -- iter: 0928/2395
[A[ATraining Step: 180  | total loss: [1m[32m0.68716[0m[0m | time: 386.992s
[2K
| Adam | epoch: 003 | loss: 0.68716 - acc: 0.5520 -- iter: 0960/2395
[A[ATraining Step: 181  | total loss: [1m[32m0.68691[0m[0m | time: 399.609s
[2K
| Adam | epoch: 003 | loss: 0.68691 - acc: 0.5593 -- iter: 0992/2395
[A[ATraining Step: 182  | total loss: [1m[32m0.68441[0m[0m | time: 412.323s
[2K
| Adam | epoch: 003 | loss: 0.68441 - acc: 0.5659 -- iter: 1024/2395
[A[ATraining Step: 183  | total loss: [1m[32m0.67851[0m[0m | time: 425.024s
[2K
| Adam | epoch: 003 | loss: 0.67851 - acc: 0.5780 -- iter: 1056/2395
[A[ATraining Step: 184  | total loss: [1m[32m0.67769[0m[0m | time: 437.962s
[2K
| Adam | epoch: 003 | loss: 0.67769 - acc: 0.5827 -- iter: 1088/2395
[A[ATraining Step: 185  | total loss: [1m[32m0.67755[0m[0m | time: 450.472s
[2K
| Adam | epoch: 003 | loss: 0.67755 - acc: 0.5807 -- iter: 1120/2395
[A[ATraining Step: 186  | total loss: [1m[32m0.67692[0m[0m | time: 463.270s
[2K
| Adam | epoch: 003 | loss: 0.67692 - acc: 0.5820 -- iter: 1152/2395
[A[ATraining Step: 187  | total loss: [1m[32m0.67957[0m[0m | time: 477.449s
[2K
| Adam | epoch: 003 | loss: 0.67957 - acc: 0.5738 -- iter: 1184/2395
[A[ATraining Step: 188  | total loss: [1m[32m0.67440[0m[0m | time: 490.768s
[2K
| Adam | epoch: 003 | loss: 0.67440 - acc: 0.5852 -- iter: 1216/2395
[A[ATraining Step: 189  | total loss: [1m[32m0.67653[0m[0m | time: 504.904s
[2K
| Adam | epoch: 003 | loss: 0.67653 - acc: 0.5767 -- iter: 1248/2395
[A[ATraining Step: 190  | total loss: [1m[32m0.69212[0m[0m | time: 519.201s
[2K
| Adam | epoch: 003 | loss: 0.69212 - acc: 0.5565 -- iter: 1280/2395
[A[ATraining Step: 191  | total loss: [1m[32m0.69173[0m[0m | time: 533.255s
[2K
| Adam | epoch: 003 | loss: 0.69173 - acc: 0.5540 -- iter: 1312/2395
[A[ATraining Step: 192  | total loss: [1m[32m0.68985[0m[0m | time: 542.535s
[2K
| Adam | epoch: 003 | loss: 0.68985 - acc: 0.5454 -- iter: 1344/2395
[A[ATraining Step: 193  | total loss: [1m[32m0.68760[0m[0m | time: 553.616s
[2K
| Adam | epoch: 003 | loss: 0.68760 - acc: 0.5472 -- iter: 1376/2395
[A[ATraining Step: 194  | total loss: [1m[32m0.68148[0m[0m | time: 566.286s
[2K
| Adam | epoch: 003 | loss: 0.68148 - acc: 0.5581 -- iter: 1408/2395
[A[ATraining Step: 195  | total loss: [1m[32m0.68863[0m[0m | time: 579.031s
[2K
| Adam | epoch: 003 | loss: 0.68863 - acc: 0.5585 -- iter: 1440/2395
[A[ATraining Step: 196  | total loss: [1m[32m0.69810[0m[0m | time: 591.949s
[2K
| Adam | epoch: 003 | loss: 0.69810 - acc: 0.5589 -- iter: 1472/2395
[A[ATraining Step: 197  | total loss: [1m[32m0.69629[0m[0m | time: 605.202s
[2K
| Adam | epoch: 003 | loss: 0.69629 - acc: 0.5530 -- iter: 1504/2395
[A[ATraining Step: 198  | total loss: [1m[32m0.69538[0m[0m | time: 620.088s
[2K
| Adam | epoch: 003 | loss: 0.69538 - acc: 0.5571 -- iter: 1536/2395
[A[ATraining Step: 199  | total loss: [1m[32m0.69623[0m[0m | time: 634.773s
[2K
| Adam | epoch: 003 | loss: 0.69623 - acc: 0.5545 -- iter: 1568/2395
[A[ATraining Step: 200  | total loss: [1m[32m0.69305[0m[0m | time: 695.693s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5678 | val_loss: 0.70085 - val_acc: 0.5100 -- iter: 1600/2395
--
Training Step: 201  | total loss: [1m[32m0.69295[0m[0m | time: 709.040s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5704 -- iter: 1632/2395
[A[ATraining Step: 202  | total loss: [1m[32m0.69257[0m[0m | time: 722.366s
[2K
| Adam | epoch: 003 | loss: 0.69257 - acc: 0.5634 -- iter: 1664/2395
[A[ATraining Step: 203  | total loss: [1m[32m0.69336[0m[0m | time: 735.511s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.5664 -- iter: 1696/2395
[A[ATraining Step: 204  | total loss: [1m[32m0.69335[0m[0m | time: 748.414s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.5660 -- iter: 1728/2395
[A[ATraining Step: 205  | total loss: [1m[32m0.68857[0m[0m | time: 761.896s
[2K
| Adam | epoch: 003 | loss: 0.68857 - acc: 0.5750 -- iter: 1760/2395
[A[ATraining Step: 206  | total loss: [1m[32m0.68337[0m[0m | time: 775.230s
[2K
| Adam | epoch: 003 | loss: 0.68337 - acc: 0.5738 -- iter: 1792/2395
[A[ATraining Step: 207  | total loss: [1m[32m0.68546[0m[0m | time: 788.559s
[2K
| Adam | epoch: 003 | loss: 0.68546 - acc: 0.5695 -- iter: 1824/2395
[A[ATraining Step: 208  | total loss: [1m[32m0.68377[0m[0m | time: 801.623s
[2K
| Adam | epoch: 003 | loss: 0.68377 - acc: 0.5657 -- iter: 1856/2395
[A[ATraining Step: 209  | total loss: [1m[32m0.68648[0m[0m | time: 814.632s
[2K
| Adam | epoch: 003 | loss: 0.68648 - acc: 0.5591 -- iter: 1888/2395
[A[ATraining Step: 210  | total loss: [1m[32m0.68885[0m[0m | time: 827.436s
[2K
| Adam | epoch: 003 | loss: 0.68885 - acc: 0.5532 -- iter: 1920/2395
[A[ATraining Step: 211  | total loss: [1m[32m0.68543[0m[0m | time: 840.136s
[2K
| Adam | epoch: 003 | loss: 0.68543 - acc: 0.5541 -- iter: 1952/2395
[A[ATraining Step: 212  | total loss: [1m[32m0.68671[0m[0m | time: 853.366s
[2K
| Adam | epoch: 003 | loss: 0.68671 - acc: 0.5675 -- iter: 1984/2395
[A[ATraining Step: 213  | total loss: [1m[32m0.69227[0m[0m | time: 866.428s
[2K
| Adam | epoch: 003 | loss: 0.69227 - acc: 0.5545 -- iter: 2016/2395
[A[ATraining Step: 214  | total loss: [1m[32m0.69021[0m[0m | time: 879.461s
[2K
| Adam | epoch: 003 | loss: 0.69021 - acc: 0.5584 -- iter: 2048/2395
[A[ATraining Step: 215  | total loss: [1m[32m0.68342[0m[0m | time: 892.005s
[2K
| Adam | epoch: 003 | loss: 0.68342 - acc: 0.5744 -- iter: 2080/2395
[A[ATraining Step: 216  | total loss: [1m[32m0.67796[0m[0m | time: 919.819s
[2K
| Adam | epoch: 003 | loss: 0.67796 - acc: 0.5764 -- iter: 2112/2395
[A[ATraining Step: 217  | total loss: [1m[32m0.67477[0m[0m | time: 932.927s
[2K
| Adam | epoch: 003 | loss: 0.67477 - acc: 0.5844 -- iter: 2144/2395
[A[ATraining Step: 218  | total loss: [1m[32m0.67249[0m[0m | time: 948.475s
[2K
| Adam | epoch: 003 | loss: 0.67249 - acc: 0.5853 -- iter: 2176/2395
[A[ATraining Step: 219  | total loss: [1m[32m0.66236[0m[0m | time: 961.209s
[2K
| Adam | epoch: 003 | loss: 0.66236 - acc: 0.5986 -- iter: 2208/2395
[A[ATraining Step: 220  | total loss: [1m[32m0.66475[0m[0m | time: 974.233s
[2K
| Adam | epoch: 003 | loss: 0.66475 - acc: 0.5982 -- iter: 2240/2395
[A[ATraining Step: 221  | total loss: [1m[32m0.66215[0m[0m | time: 986.912s
[2K
| Adam | epoch: 003 | loss: 0.66215 - acc: 0.5946 -- iter: 2272/2395
[A[ATraining Step: 222  | total loss: [1m[32m0.67402[0m[0m | time: 1000.032s
[2K
| Adam | epoch: 003 | loss: 0.67402 - acc: 0.5789 -- iter: 2304/2395
[A[ATraining Step: 223  | total loss: [1m[32m0.66848[0m[0m | time: 1013.197s
[2K
| Adam | epoch: 003 | loss: 0.66848 - acc: 0.5897 -- iter: 2336/2395
[A[ATraining Step: 224  | total loss: [1m[32m0.65984[0m[0m | time: 1025.905s
[2K
| Adam | epoch: 003 | loss: 0.65984 - acc: 0.6058 -- iter: 2368/2395
[A[ATraining Step: 225  | total loss: [1m[32m0.65601[0m[0m | time: 1093.334s
[2K
| Adam | epoch: 003 | loss: 0.65601 - acc: 0.6014 | val_loss: 0.70639 - val_acc: 0.5407 -- iter: 2395/2395
--
Training Step: 226  | total loss: [1m[32m0.65229[0m[0m | time: 23.936s
[2K
| Adam | epoch: 004 | loss: 0.65229 - acc: 0.6038 -- iter: 0032/2395
[A[ATraining Step: 227  | total loss: [1m[32m0.65406[0m[0m | time: 34.644s
[2K
| Adam | epoch: 004 | loss: 0.65406 - acc: 0.6090 -- iter: 0064/2395
[A[ATraining Step: 228  | total loss: [1m[32m0.65555[0m[0m | time: 46.230s
[2K
| Adam | epoch: 004 | loss: 0.65555 - acc: 0.6148 -- iter: 0096/2395
[A[ATraining Step: 229  | total loss: [1m[32m0.65078[0m[0m | time: 59.450s
[2K
| Adam | epoch: 004 | loss: 0.65078 - acc: 0.6126 -- iter: 0128/2395
[A[ATraining Step: 230  | total loss: [1m[32m0.65222[0m[0m | time: 72.941s
[2K
| Adam | epoch: 004 | loss: 0.65222 - acc: 0.6170 -- iter: 0160/2395
[A[ATraining Step: 231  | total loss: [1m[32m0.64862[0m[0m | time: 86.141s
[2K
| Adam | epoch: 004 | loss: 0.64862 - acc: 0.6365 -- iter: 0192/2395
[A[ATraining Step: 232  | total loss: [1m[32m0.65825[0m[0m | time: 98.808s
[2K
| Adam | epoch: 004 | loss: 0.65825 - acc: 0.6229 -- iter: 0224/2395
[A[ATraining Step: 233  | total loss: [1m[32m0.65619[0m[0m | time: 111.968s
[2K
| Adam | epoch: 004 | loss: 0.65619 - acc: 0.6137 -- iter: 0256/2395
[A[ATraining Step: 234  | total loss: [1m[32m0.65336[0m[0m | time: 125.405s
[2K
| Adam | epoch: 004 | loss: 0.65336 - acc: 0.6117 -- iter: 0288/2395
[A[ATraining Step: 235  | total loss: [1m[32m0.66184[0m[0m | time: 138.294s
[2K
| Adam | epoch: 004 | loss: 0.66184 - acc: 0.6037 -- iter: 0320/2395
[A[ATraining Step: 236  | total loss: [1m[32m0.66074[0m[0m | time: 151.206s
[2K
| Adam | epoch: 004 | loss: 0.66074 - acc: 0.6120 -- iter: 0352/2395
[A[ATraining Step: 237  | total loss: [1m[32m0.66838[0m[0m | time: 164.524s
[2K
| Adam | epoch: 004 | loss: 0.66838 - acc: 0.5883 -- iter: 0384/2395
[A[ATraining Step: 238  | total loss: [1m[32m0.66398[0m[0m | time: 177.576s
[2K
| Adam | epoch: 004 | loss: 0.66398 - acc: 0.6014 -- iter: 0416/2395
[A[ATraining Step: 239  | total loss: [1m[32m0.67087[0m[0m | time: 190.397s
[2K
| Adam | epoch: 004 | loss: 0.67087 - acc: 0.5944 -- iter: 0448/2395
[A[ATraining Step: 240  | total loss: [1m[32m0.67459[0m[0m | time: 203.883s
[2K
| Adam | epoch: 004 | loss: 0.67459 - acc: 0.5881 -- iter: 0480/2395
[A[ATraining Step: 241  | total loss: [1m[32m0.67842[0m[0m | time: 217.040s
[2K
| Adam | epoch: 004 | loss: 0.67842 - acc: 0.5761 -- iter: 0512/2395
[A[ATraining Step: 242  | total loss: [1m[32m0.67671[0m[0m | time: 230.225s
[2K
| Adam | epoch: 004 | loss: 0.67671 - acc: 0.5748 -- iter: 0544/2395
[A[ATraining Step: 243  | total loss: [1m[32m0.67651[0m[0m | time: 242.972s
[2K
| Adam | epoch: 004 | loss: 0.67651 - acc: 0.5798 -- iter: 0576/2395
[A[ATraining Step: 244  | total loss: [1m[32m0.66849[0m[0m | time: 255.721s
[2K
| Adam | epoch: 004 | loss: 0.66849 - acc: 0.5843 -- iter: 0608/2395
[A[ATraining Step: 245  | total loss: [1m[32m0.67127[0m[0m | time: 268.841s
[2K
| Adam | epoch: 004 | loss: 0.67127 - acc: 0.5884 -- iter: 0640/2395
[A[ATraining Step: 246  | total loss: [1m[32m0.66958[0m[0m | time: 281.592s
[2K
| Adam | epoch: 004 | loss: 0.66958 - acc: 0.5889 -- iter: 0672/2395
[A[ATraining Step: 247  | total loss: [1m[32m0.67047[0m[0m | time: 293.989s
[2K
| Adam | epoch: 004 | loss: 0.67047 - acc: 0.5925 -- iter: 0704/2395
[A[ATraining Step: 248  | total loss: [1m[32m0.66814[0m[0m | time: 306.901s
[2K
| Adam | epoch: 004 | loss: 0.66814 - acc: 0.5958 -- iter: 0736/2395
[A[ATraining Step: 249  | total loss: [1m[32m0.67825[0m[0m | time: 320.100s
[2K
| Adam | epoch: 004 | loss: 0.67825 - acc: 0.5862 -- iter: 0768/2395
[A[ATraining Step: 250  | total loss: [1m[32m0.67453[0m[0m | time: 332.581s
[2K
| Adam | epoch: 004 | loss: 0.67453 - acc: 0.5932 -- iter: 0800/2395
[A[ATraining Step: 251  | total loss: [1m[32m0.67245[0m[0m | time: 345.402s
[2K
| Adam | epoch: 004 | loss: 0.67245 - acc: 0.5933 -- iter: 0832/2395
[A[ATraining Step: 252  | total loss: [1m[32m0.67413[0m[0m | time: 358.112s
[2K
| Adam | epoch: 004 | loss: 0.67413 - acc: 0.5808 -- iter: 0864/2395
[A[ATraining Step: 253  | total loss: [1m[32m0.67589[0m[0m | time: 371.125s
[2K
| Adam | epoch: 004 | loss: 0.67589 - acc: 0.5790 -- iter: 0896/2395
[A[ATraining Step: 254  | total loss: [1m[32m0.68128[0m[0m | time: 384.166s
[2K
| Adam | epoch: 004 | loss: 0.68128 - acc: 0.5680 -- iter: 0928/2395
[A[ATraining Step: 255  | total loss: [1m[32m0.68375[0m[0m | time: 397.463s
[2K
| Adam | epoch: 004 | loss: 0.68375 - acc: 0.5612 -- iter: 0960/2395
[A[ATraining Step: 256  | total loss: [1m[32m0.66987[0m[0m | time: 409.962s
[2K
| Adam | epoch: 004 | loss: 0.66987 - acc: 0.5800 -- iter: 0992/2395
[A[ATraining Step: 257  | total loss: [1m[32m0.67669[0m[0m | time: 423.121s
[2K
| Adam | epoch: 004 | loss: 0.67669 - acc: 0.5627 -- iter: 1024/2395
[A[ATraining Step: 258  | total loss: [1m[32m0.67405[0m[0m | time: 436.213s
[2K
| Adam | epoch: 004 | loss: 0.67405 - acc: 0.5720 -- iter: 1056/2395
[A[ATraining Step: 259  | total loss: [1m[32m0.66862[0m[0m | time: 449.389s
[2K
| Adam | epoch: 004 | loss: 0.66862 - acc: 0.5867 -- iter: 1088/2395
[A[ATraining Step: 260  | total loss: [1m[32m0.67890[0m[0m | time: 461.963s
[2K
| Adam | epoch: 004 | loss: 0.67890 - acc: 0.5811 -- iter: 1120/2395
[A[ATraining Step: 261  | total loss: [1m[32m0.67675[0m[0m | time: 475.321s
[2K
| Adam | epoch: 004 | loss: 0.67675 - acc: 0.5793 -- iter: 1152/2395
[A[ATraining Step: 262  | total loss: [1m[32m0.67774[0m[0m | time: 488.410s
[2K
| Adam | epoch: 004 | loss: 0.67774 - acc: 0.5839 -- iter: 1184/2395
[A[ATraining Step: 263  | total loss: [1m[32m0.68310[0m[0m | time: 501.415s
[2K
| Adam | epoch: 004 | loss: 0.68310 - acc: 0.5817 -- iter: 1216/2395
[A[ATraining Step: 264  | total loss: [1m[32m0.68478[0m[0m | time: 514.510s
[2K
| Adam | epoch: 004 | loss: 0.68478 - acc: 0.5673 -- iter: 1248/2395
[A[ATraining Step: 265  | total loss: [1m[32m0.68528[0m[0m | time: 527.293s
[2K
| Adam | epoch: 004 | loss: 0.68528 - acc: 0.5668 -- iter: 1280/2395
[A[ATraining Step: 266  | total loss: [1m[32m0.68657[0m[0m | time: 540.208s
[2K
| Adam | epoch: 004 | loss: 0.68657 - acc: 0.5633 -- iter: 1312/2395
[A[ATraining Step: 267  | total loss: [1m[32m0.68594[0m[0m | time: 553.125s
[2K
| Adam | epoch: 004 | loss: 0.68594 - acc: 0.5569 -- iter: 1344/2395
[A[ATraining Step: 268  | total loss: [1m[32m0.69089[0m[0m | time: 566.433s
[2K
| Adam | epoch: 004 | loss: 0.69089 - acc: 0.5419 -- iter: 1376/2395
[A[ATraining Step: 269  | total loss: [1m[32m0.68590[0m[0m | time: 579.214s
[2K
| Adam | epoch: 004 | loss: 0.68590 - acc: 0.5533 -- iter: 1408/2395
[A[ATraining Step: 270  | total loss: [1m[32m0.68527[0m[0m | time: 591.862s
[2K
| Adam | epoch: 004 | loss: 0.68527 - acc: 0.5605 -- iter: 1440/2395
[A[ATraining Step: 271  | total loss: [1m[32m0.68795[0m[0m | time: 604.920s
[2K
| Adam | epoch: 004 | loss: 0.68795 - acc: 0.5544 -- iter: 1472/2395
[A[ATraining Step: 272  | total loss: [1m[32m0.69047[0m[0m | time: 618.344s
[2K
| Adam | epoch: 004 | loss: 0.69047 - acc: 0.5459 -- iter: 1504/2395
[A[ATraining Step: 273  | total loss: [1m[32m0.68491[0m[0m | time: 630.787s
[2K
| Adam | epoch: 004 | loss: 0.68491 - acc: 0.5538 -- iter: 1536/2395
[A[ATraining Step: 274  | total loss: [1m[32m0.68401[0m[0m | time: 643.406s
[2K
| Adam | epoch: 004 | loss: 0.68401 - acc: 0.5515 -- iter: 1568/2395
[A[ATraining Step: 275  | total loss: [1m[32m0.68327[0m[0m | time: 656.022s
[2K
| Adam | epoch: 004 | loss: 0.68327 - acc: 0.5464 -- iter: 1600/2395
[A[ATraining Step: 276  | total loss: [1m[32m0.67838[0m[0m | time: 668.995s
[2K
| Adam | epoch: 004 | loss: 0.67838 - acc: 0.5449 -- iter: 1632/2395
[A[ATraining Step: 277  | total loss: [1m[32m0.68119[0m[0m | time: 682.068s
[2K
| Adam | epoch: 004 | loss: 0.68119 - acc: 0.5279 -- iter: 1664/2395
[A[ATraining Step: 278  | total loss: [1m[32m0.67559[0m[0m | time: 695.045s
[2K
| Adam | epoch: 004 | loss: 0.67559 - acc: 0.5313 -- iter: 1696/2395
[A[ATraining Step: 279  | total loss: [1m[32m0.67097[0m[0m | time: 708.025s
[2K
| Adam | epoch: 004 | loss: 0.67097 - acc: 0.5532 -- iter: 1728/2395
[A[ATraining Step: 280  | total loss: [1m[32m0.67021[0m[0m | time: 721.276s
[2K
| Adam | epoch: 004 | loss: 0.67021 - acc: 0.5604 -- iter: 1760/2395
[A[ATraining Step: 281  | total loss: [1m[32m0.66827[0m[0m | time: 734.629s
[2K
| Adam | epoch: 004 | loss: 0.66827 - acc: 0.5668 -- iter: 1792/2395
[A[ATraining Step: 282  | total loss: [1m[32m0.66226[0m[0m | time: 747.551s
[2K
| Adam | epoch: 004 | loss: 0.66226 - acc: 0.5789 -- iter: 1824/2395
[A[ATraining Step: 283  | total loss: [1m[32m0.65354[0m[0m | time: 760.464s
[2K
| Adam | epoch: 004 | loss: 0.65354 - acc: 0.5835 -- iter: 1856/2395
[A[ATraining Step: 284  | total loss: [1m[32m0.65814[0m[0m | time: 773.854s
[2K
| Adam | epoch: 004 | loss: 0.65814 - acc: 0.5783 -- iter: 1888/2395
[A[ATraining Step: 285  | total loss: [1m[32m0.64922[0m[0m | time: 787.019s
[2K
| Adam | epoch: 004 | loss: 0.64922 - acc: 0.5986 -- iter: 1920/2395
[A[ATraining Step: 286  | total loss: [1m[32m0.64288[0m[0m | time: 799.960s
[2K
| Adam | epoch: 004 | loss: 0.64288 - acc: 0.6106 -- iter: 1952/2395
[A[ATraining Step: 287  | total loss: [1m[32m0.63951[0m[0m | time: 813.133s
[2K
| Adam | epoch: 004 | loss: 0.63951 - acc: 0.6214 -- iter: 1984/2395
[A[ATraining Step: 288  | total loss: [1m[32m0.63850[0m[0m | time: 825.981s
[2K
| Adam | epoch: 004 | loss: 0.63850 - acc: 0.6249 -- iter: 2016/2395
[A[ATraining Step: 289  | total loss: [1m[32m0.63246[0m[0m | time: 842.496s
[2K
| Adam | epoch: 004 | loss: 0.63246 - acc: 0.6280 -- iter: 2048/2395
[A[ATraining Step: 290  | total loss: [1m[32m0.64370[0m[0m | time: 855.592s
[2K
| Adam | epoch: 004 | loss: 0.64370 - acc: 0.6152 -- iter: 2080/2395
[A[ATraining Step: 291  | total loss: [1m[32m0.63150[0m[0m | time: 868.677s
[2K
| Adam | epoch: 004 | loss: 0.63150 - acc: 0.6350 -- iter: 2112/2395
[A[ATraining Step: 292  | total loss: [1m[32m0.63127[0m[0m | time: 881.562s
[2K
| Adam | epoch: 004 | loss: 0.63127 - acc: 0.6340 -- iter: 2144/2395
[A[ATraining Step: 293  | total loss: [1m[32m0.63268[0m[0m | time: 894.182s
[2K
| Adam | epoch: 004 | loss: 0.63268 - acc: 0.6424 -- iter: 2176/2395
[A[ATraining Step: 294  | total loss: [1m[32m0.64534[0m[0m | time: 909.417s
[2K
| Adam | epoch: 004 | loss: 0.64534 - acc: 0.6282 -- iter: 2208/2395
[A[ATraining Step: 295  | total loss: [1m[32m0.63795[0m[0m | time: 924.577s
[2K
| Adam | epoch: 004 | loss: 0.63795 - acc: 0.6404 -- iter: 2240/2395
[A[ATraining Step: 296  | total loss: [1m[32m0.63665[0m[0m | time: 939.505s
[2K
| Adam | epoch: 004 | loss: 0.63665 - acc: 0.6451 -- iter: 2272/2395
[A[ATraining Step: 297  | total loss: [1m[32m0.64024[0m[0m | time: 954.114s
[2K
| Adam | epoch: 004 | loss: 0.64024 - acc: 0.6400 -- iter: 2304/2395
[A[ATraining Step: 298  | total loss: [1m[32m0.64373[0m[0m | time: 968.692s
[2K
| Adam | epoch: 004 | loss: 0.64373 - acc: 0.6291 -- iter: 2336/2395
[A[ATraining Step: 299  | total loss: [1m[32m0.63811[0m[0m | time: 978.037s
[2K
| Adam | epoch: 004 | loss: 0.63811 - acc: 0.6256 -- iter: 2368/2395
[A[ATraining Step: 300  | total loss: [1m[32m0.62842[0m[0m | time: 1038.101s
[2K
| Adam | epoch: 004 | loss: 0.62842 - acc: 0.6474 | val_loss: 0.92637 - val_acc: 0.4940 -- iter: 2395/2395
--
Training Step: 301  | total loss: [1m[32m0.62611[0m[0m | time: 14.048s
[2K
| Adam | epoch: 005 | loss: 0.62611 - acc: 0.6483 -- iter: 0032/2395
[A[ATraining Step: 302  | total loss: [1m[32m0.63336[0m[0m | time: 27.545s
[2K
| Adam | epoch: 005 | loss: 0.63336 - acc: 0.6366 -- iter: 0064/2395
[A[ATraining Step: 303  | total loss: [1m[32m0.63428[0m[0m | time: 39.058s
[2K
| Adam | epoch: 005 | loss: 0.63428 - acc: 0.6292 -- iter: 0096/2395
[A[ATraining Step: 304  | total loss: [1m[32m0.63280[0m[0m | time: 50.523s
[2K
| Adam | epoch: 005 | loss: 0.63280 - acc: 0.6440 -- iter: 0128/2395
[A[ATraining Step: 305  | total loss: [1m[32m0.62732[0m[0m | time: 64.119s
[2K
| Adam | epoch: 005 | loss: 0.62732 - acc: 0.6611 -- iter: 0160/2395
[A[ATraining Step: 306  | total loss: [1m[32m0.62933[0m[0m | time: 77.939s
[2K
| Adam | epoch: 005 | loss: 0.62933 - acc: 0.6669 -- iter: 0192/2395
[A[ATraining Step: 307  | total loss: [1m[32m0.62759[0m[0m | time: 91.590s
[2K
| Adam | epoch: 005 | loss: 0.62759 - acc: 0.6658 -- iter: 0224/2395
[A[ATraining Step: 308  | total loss: [1m[32m0.64084[0m[0m | time: 104.908s
[2K
| Adam | epoch: 005 | loss: 0.64084 - acc: 0.6523 -- iter: 0256/2395
[A[ATraining Step: 309  | total loss: [1m[32m0.63491[0m[0m | time: 118.479s
[2K
| Adam | epoch: 005 | loss: 0.63491 - acc: 0.6527 -- iter: 0288/2395
[A[ATraining Step: 310  | total loss: [1m[32m0.64229[0m[0m | time: 131.874s
[2K
| Adam | epoch: 005 | loss: 0.64229 - acc: 0.6375 -- iter: 0320/2395
[A[ATraining Step: 311  | total loss: [1m[32m0.64268[0m[0m | time: 144.879s
[2K
| Adam | epoch: 005 | loss: 0.64268 - acc: 0.6331 -- iter: 0352/2395
[A[ATraining Step: 312  | total loss: [1m[32m0.64116[0m[0m | time: 158.806s
[2K
| Adam | epoch: 005 | loss: 0.64116 - acc: 0.6323 -- iter: 0384/2395
[A[ATraining Step: 313  | total loss: [1m[32m0.63450[0m[0m | time: 172.391s
[2K
| Adam | epoch: 005 | loss: 0.63450 - acc: 0.6441 -- iter: 0416/2395
[A[ATraining Step: 314  | total loss: [1m[32m0.63060[0m[0m | time: 185.660s
[2K
| Adam | epoch: 005 | loss: 0.63060 - acc: 0.6484 -- iter: 0448/2395
[A[ATraining Step: 315  | total loss: [1m[32m0.62514[0m[0m | time: 199.302s
[2K
| Adam | epoch: 005 | loss: 0.62514 - acc: 0.6586 -- iter: 0480/2395
[A[ATraining Step: 316  | total loss: [1m[32m0.62581[0m[0m | time: 212.881s
[2K
| Adam | epoch: 005 | loss: 0.62581 - acc: 0.6552 -- iter: 0512/2395
[A[ATraining Step: 317  | total loss: [1m[32m0.61571[0m[0m | time: 226.065s
[2K
| Adam | epoch: 005 | loss: 0.61571 - acc: 0.6678 -- iter: 0544/2395
[A[ATraining Step: 318  | total loss: [1m[32m0.62618[0m[0m | time: 239.558s
[2K
| Adam | epoch: 005 | loss: 0.62618 - acc: 0.6604 -- iter: 0576/2395
[A[ATraining Step: 319  | total loss: [1m[32m0.63340[0m[0m | time: 252.904s
[2K
| Adam | epoch: 005 | loss: 0.63340 - acc: 0.6506 -- iter: 0608/2395
[A[ATraining Step: 320  | total loss: [1m[32m0.62883[0m[0m | time: 266.082s
[2K
| Adam | epoch: 005 | loss: 0.62883 - acc: 0.6512 -- iter: 0640/2395
[A[ATraining Step: 321  | total loss: [1m[32m0.63323[0m[0m | time: 289.970s
[2K
| Adam | epoch: 005 | loss: 0.63323 - acc: 0.6392 -- iter: 0672/2395
[A[ATraining Step: 322  | total loss: [1m[32m0.63414[0m[0m | time: 303.173s
[2K
| Adam | epoch: 005 | loss: 0.63414 - acc: 0.6471 -- iter: 0704/2395
[A[ATraining Step: 323  | total loss: [1m[32m0.63363[0m[0m | time: 316.539s
[2K
| Adam | epoch: 005 | loss: 0.63363 - acc: 0.6449 -- iter: 0736/2395
[A[ATraining Step: 324  | total loss: [1m[32m0.63406[0m[0m | time: 330.064s
[2K
| Adam | epoch: 005 | loss: 0.63406 - acc: 0.6398 -- iter: 0768/2395
[A[ATraining Step: 325  | total loss: [1m[32m0.63650[0m[0m | time: 343.439s
[2K
| Adam | epoch: 005 | loss: 0.63650 - acc: 0.6477 -- iter: 0800/2395
[A[ATraining Step: 326  | total loss: [1m[32m0.63607[0m[0m | time: 357.041s
[2K
| Adam | epoch: 005 | loss: 0.63607 - acc: 0.6486 -- iter: 0832/2395
[A[ATraining Step: 327  | total loss: [1m[32m0.63418[0m[0m | time: 370.088s
[2K
| Adam | epoch: 005 | loss: 0.63418 - acc: 0.6493 -- iter: 0864/2395
[A[ATraining Step: 328  | total loss: [1m[32m0.63879[0m[0m | time: 383.573s
[2K
| Adam | epoch: 005 | loss: 0.63879 - acc: 0.6406 -- iter: 0896/2395
[A[ATraining Step: 329  | total loss: [1m[32m0.63681[0m[0m | time: 396.391s
[2K
| Adam | epoch: 005 | loss: 0.63681 - acc: 0.6391 -- iter: 0928/2395
[A[ATraining Step: 330  | total loss: [1m[32m0.63314[0m[0m | time: 409.783s
[2K
| Adam | epoch: 005 | loss: 0.63314 - acc: 0.6502 -- iter: 0960/2395
[A[ATraining Step: 331  | total loss: [1m[32m0.64048[0m[0m | time: 423.098s
[2K
| Adam | epoch: 005 | loss: 0.64048 - acc: 0.6508 -- iter: 0992/2395
[A[ATraining Step: 332  | total loss: [1m[32m0.64309[0m[0m | time: 436.774s
[2K
| Adam | epoch: 005 | loss: 0.64309 - acc: 0.6482 -- iter: 1024/2395
[A[ATraining Step: 333  | total loss: [1m[32m0.64256[0m[0m | time: 451.923s
[2K
| Adam | epoch: 005 | loss: 0.64256 - acc: 0.6396 -- iter: 1056/2395
[A[ATraining Step: 334  | total loss: [1m[32m0.64862[0m[0m | time: 465.153s
[2K
| Adam | epoch: 005 | loss: 0.64862 - acc: 0.6257 -- iter: 1088/2395
[A[ATraining Step: 335  | total loss: [1m[32m0.66067[0m[0m | time: 478.358s
[2K
| Adam | epoch: 005 | loss: 0.66067 - acc: 0.6100 -- iter: 1120/2395
[A[ATraining Step: 336  | total loss: [1m[32m0.66338[0m[0m | time: 491.570s
[2K
| Adam | epoch: 005 | loss: 0.66338 - acc: 0.5990 -- iter: 1152/2395
[A[ATraining Step: 337  | total loss: [1m[32m0.67170[0m[0m | time: 504.512s
[2K
| Adam | epoch: 005 | loss: 0.67170 - acc: 0.5891 -- iter: 1184/2395
[A[ATraining Step: 338  | total loss: [1m[32m0.66774[0m[0m | time: 517.708s
[2K
| Adam | epoch: 005 | loss: 0.66774 - acc: 0.5958 -- iter: 1216/2395
[A[ATraining Step: 339  | total loss: [1m[32m0.67468[0m[0m | time: 538.512s
[2K
| Adam | epoch: 005 | loss: 0.67468 - acc: 0.5893 -- iter: 1248/2395
[A[ATraining Step: 340  | total loss: [1m[32m0.68038[0m[0m | time: 551.919s
[2K
| Adam | epoch: 005 | loss: 0.68038 - acc: 0.5773 -- iter: 1280/2395
[A[ATraining Step: 341  | total loss: [1m[32m0.67919[0m[0m | time: 564.645s
[2K
| Adam | epoch: 005 | loss: 0.67919 - acc: 0.5758 -- iter: 1312/2395
[A[ATraining Step: 342  | total loss: [1m[32m0.68135[0m[0m | time: 589.902s
[2K
| Adam | epoch: 005 | loss: 0.68135 - acc: 0.5682 -- iter: 1344/2395
[A[ATraining Step: 343  | total loss: [1m[32m0.67963[0m[0m | time: 603.186s
[2K
| Adam | epoch: 005 | loss: 0.67963 - acc: 0.5645 -- iter: 1376/2395
[A[ATraining Step: 344  | total loss: [1m[32m0.67329[0m[0m | time: 615.686s
[2K
| Adam | epoch: 005 | loss: 0.67329 - acc: 0.5831 -- iter: 1408/2395
[A[ATraining Step: 345  | total loss: [1m[32m0.67591[0m[0m | time: 628.665s
[2K
| Adam | epoch: 005 | loss: 0.67591 - acc: 0.5873 -- iter: 1440/2395
[A[ATraining Step: 346  | total loss: [1m[32m0.67586[0m[0m | time: 641.620s
[2K
| Adam | epoch: 005 | loss: 0.67586 - acc: 0.5910 -- iter: 1472/2395
[A[ATraining Step: 347  | total loss: [1m[32m0.67182[0m[0m | time: 654.600s
[2K
| Adam | epoch: 005 | loss: 0.67182 - acc: 0.5913 -- iter: 1504/2395
[A[ATraining Step: 348  | total loss: [1m[32m0.66966[0m[0m | time: 667.229s
[2K
| Adam | epoch: 005 | loss: 0.66966 - acc: 0.5978 -- iter: 1536/2395
[A[ATraining Step: 349  | total loss: [1m[32m0.66849[0m[0m | time: 680.101s
[2K
| Adam | epoch: 005 | loss: 0.66849 - acc: 0.5974 -- iter: 1568/2395
[A[ATraining Step: 350  | total loss: [1m[32m0.66698[0m[0m | time: 692.704s
[2K
| Adam | epoch: 005 | loss: 0.66698 - acc: 0.6002 -- iter: 1600/2395
[A[ATraining Step: 351  | total loss: [1m[32m0.66826[0m[0m | time: 706.176s
[2K
| Adam | epoch: 005 | loss: 0.66826 - acc: 0.6058 -- iter: 1632/2395
[A[ATraining Step: 352  | total loss: [1m[32m0.67034[0m[0m | time: 719.161s
[2K
| Adam | epoch: 005 | loss: 0.67034 - acc: 0.5983 -- iter: 1664/2395
[A[ATraining Step: 353  | total loss: [1m[32m0.66567[0m[0m | time: 732.442s
[2K
| Adam | epoch: 005 | loss: 0.66567 - acc: 0.5979 -- iter: 1696/2395
[A[ATraining Step: 354  | total loss: [1m[32m0.66854[0m[0m | time: 745.008s
[2K
| Adam | epoch: 005 | loss: 0.66854 - acc: 0.6006 -- iter: 1728/2395
[A[ATraining Step: 355  | total loss: [1m[32m0.66349[0m[0m | time: 758.311s
[2K
| Adam | epoch: 005 | loss: 0.66349 - acc: 0.6155 -- iter: 1760/2395
[A[ATraining Step: 356  | total loss: [1m[32m0.66808[0m[0m | time: 771.285s
[2K
| Adam | epoch: 005 | loss: 0.66808 - acc: 0.6008 -- iter: 1792/2395
[A[ATraining Step: 357  | total loss: [1m[32m0.65924[0m[0m | time: 783.818s
[2K
| Adam | epoch: 005 | loss: 0.65924 - acc: 0.6158 -- iter: 1824/2395
[A[ATraining Step: 358  | total loss: [1m[32m0.66143[0m[0m | time: 797.105s
[2K
| Adam | epoch: 005 | loss: 0.66143 - acc: 0.6073 -- iter: 1856/2395
[A[ATraining Step: 359  | total loss: [1m[32m0.65620[0m[0m | time: 809.987s
[2K
| Adam | epoch: 005 | loss: 0.65620 - acc: 0.6216 -- iter: 1888/2395
[A[ATraining Step: 360  | total loss: [1m[32m0.65587[0m[0m | time: 822.701s
[2K
| Adam | epoch: 005 | loss: 0.65587 - acc: 0.6188 -- iter: 1920/2395
[A[ATraining Step: 361  | total loss: [1m[32m0.65511[0m[0m | time: 835.718s
[2K
| Adam | epoch: 005 | loss: 0.65511 - acc: 0.6163 -- iter: 1952/2395
[A[ATraining Step: 362  | total loss: [1m[32m0.64454[0m[0m | time: 848.779s
[2K
| Adam | epoch: 005 | loss: 0.64454 - acc: 0.6328 -- iter: 1984/2395
[A[ATraining Step: 363  | total loss: [1m[32m0.64245[0m[0m | time: 862.129s
[2K
| Adam | epoch: 005 | loss: 0.64245 - acc: 0.6445 -- iter: 2016/2395
[A[ATraining Step: 364  | total loss: [1m[32m0.64504[0m[0m | time: 875.348s
[2K
| Adam | epoch: 005 | loss: 0.64504 - acc: 0.6426 -- iter: 2048/2395
[A[ATraining Step: 365  | total loss: [1m[32m0.63903[0m[0m | time: 888.166s
[2K
| Adam | epoch: 005 | loss: 0.63903 - acc: 0.6439 -- iter: 2080/2395
[A[ATraining Step: 366  | total loss: [1m[32m0.62539[0m[0m | time: 900.856s
[2K
| Adam | epoch: 005 | loss: 0.62539 - acc: 0.6545 -- iter: 2112/2395
[A[ATraining Step: 367  | total loss: [1m[32m0.63516[0m[0m | time: 914.315s
[2K
| Adam | epoch: 005 | loss: 0.63516 - acc: 0.6360 -- iter: 2144/2395
[A[ATraining Step: 368  | total loss: [1m[32m0.64969[0m[0m | time: 927.040s
[2K
| Adam | epoch: 005 | loss: 0.64969 - acc: 0.6255 -- iter: 2176/2395
[A[ATraining Step: 369  | total loss: [1m[32m0.65023[0m[0m | time: 940.201s
[2K
| Adam | epoch: 005 | loss: 0.65023 - acc: 0.6223 -- iter: 2208/2395
[A[ATraining Step: 370  | total loss: [1m[32m0.63690[0m[0m | time: 952.933s
[2K
| Adam | epoch: 005 | loss: 0.63690 - acc: 0.6382 -- iter: 2240/2395
[A[ATraining Step: 371  | total loss: [1m[32m0.63542[0m[0m | time: 965.694s
[2K
| Adam | epoch: 005 | loss: 0.63542 - acc: 0.6369 -- iter: 2272/2395
[A[ATraining Step: 372  | total loss: [1m[32m0.64356[0m[0m | time: 978.591s
[2K
| Adam | epoch: 005 | loss: 0.64356 - acc: 0.6326 -- iter: 2304/2395
[A[ATraining Step: 373  | total loss: [1m[32m0.64800[0m[0m | time: 991.787s
[2K
| Adam | epoch: 005 | loss: 0.64800 - acc: 0.6287 -- iter: 2336/2395
[A[ATraining Step: 374  | total loss: [1m[32m0.64333[0m[0m | time: 1004.767s
[2K
| Adam | epoch: 005 | loss: 0.64333 - acc: 0.6346 -- iter: 2368/2395
[A[ATraining Step: 375  | total loss: [1m[32m0.64333[0m[0m | time: 1072.268s
[2K
| Adam | epoch: 005 | loss: 0.64333 - acc: 0.6430 | val_loss: 0.75799 - val_acc: 0.5287 -- iter: 2395/2395
--
Training Step: 376  | total loss: [1m[32m0.63327[0m[0m | time: 12.548s
[2K
| Adam | epoch: 006 | loss: 0.63327 - acc: 0.6506 -- iter: 0032/2395
[A[ATraining Step: 377  | total loss: [1m[32m0.62986[0m[0m | time: 25.675s
[2K
| Adam | epoch: 006 | loss: 0.62986 - acc: 0.6543 -- iter: 0064/2395
[A[ATraining Step: 378  | total loss: [1m[32m0.62474[0m[0m | time: 38.657s
[2K
| Adam | epoch: 006 | loss: 0.62474 - acc: 0.6607 -- iter: 0096/2395
[A[ATraining Step: 379  | total loss: [1m[32m0.63574[0m[0m | time: 49.523s
[2K
| Adam | epoch: 006 | loss: 0.63574 - acc: 0.6571 -- iter: 0128/2395
[A[ATraining Step: 380  | total loss: [1m[32m0.62926[0m[0m | time: 60.815s
[2K
| Adam | epoch: 006 | loss: 0.62926 - acc: 0.6692 -- iter: 0160/2395
[A[ATraining Step: 381  | total loss: [1m[32m0.61997[0m[0m | time: 73.725s
[2K
| Adam | epoch: 006 | loss: 0.61997 - acc: 0.6838 -- iter: 0192/2395
[A[ATraining Step: 382  | total loss: [1m[32m0.62448[0m[0m | time: 87.667s
[2K
| Adam | epoch: 006 | loss: 0.62448 - acc: 0.6779 -- iter: 0224/2395
[A[ATraining Step: 383  | total loss: [1m[32m0.62451[0m[0m | time: 102.444s
[2K
| Adam | epoch: 006 | loss: 0.62451 - acc: 0.6726 -- iter: 0256/2395
[A[ATraining Step: 384  | total loss: [1m[32m0.62184[0m[0m | time: 116.473s
[2K
| Adam | epoch: 006 | loss: 0.62184 - acc: 0.6741 -- iter: 0288/2395
[A[ATraining Step: 385  | total loss: [1m[32m0.61531[0m[0m | time: 130.774s
[2K
| Adam | epoch: 006 | loss: 0.61531 - acc: 0.6692 -- iter: 0320/2395
[A[ATraining Step: 386  | total loss: [1m[32m0.62790[0m[0m | time: 144.864s
[2K
| Adam | epoch: 006 | loss: 0.62790 - acc: 0.6554 -- iter: 0352/2395
[A[ATraining Step: 387  | total loss: [1m[32m0.63303[0m[0m | time: 156.858s
[2K
| Adam | epoch: 006 | loss: 0.63303 - acc: 0.6461 -- iter: 0384/2395
[A[ATraining Step: 388  | total loss: [1m[32m0.63061[0m[0m | time: 165.893s
[2K
| Adam | epoch: 006 | loss: 0.63061 - acc: 0.6502 -- iter: 0416/2395
[A[ATraining Step: 389  | total loss: [1m[32m0.62903[0m[0m | time: 175.620s
[2K
| Adam | epoch: 006 | loss: 0.62903 - acc: 0.6415 -- iter: 0448/2395
[A[ATraining Step: 390  | total loss: [1m[32m0.62464[0m[0m | time: 187.900s
[2K
| Adam | epoch: 006 | loss: 0.62464 - acc: 0.6398 -- iter: 0480/2395
[A[ATraining Step: 391  | total loss: [1m[32m0.62399[0m[0m | time: 201.229s
[2K
| Adam | epoch: 006 | loss: 0.62399 - acc: 0.6383 -- iter: 0512/2395
[A[ATraining Step: 392  | total loss: [1m[32m0.62859[0m[0m | time: 214.202s
[2K
| Adam | epoch: 006 | loss: 0.62859 - acc: 0.6308 -- iter: 0544/2395
[A[ATraining Step: 393  | total loss: [1m[32m0.63221[0m[0m | time: 226.630s
[2K
| Adam | epoch: 006 | loss: 0.63221 - acc: 0.6239 -- iter: 0576/2395
[A[ATraining Step: 394  | total loss: [1m[32m0.62199[0m[0m | time: 239.133s
[2K
| Adam | epoch: 006 | loss: 0.62199 - acc: 0.6397 -- iter: 0608/2395
[A[ATraining Step: 395  | total loss: [1m[32m0.62032[0m[0m | time: 251.583s
[2K
| Adam | epoch: 006 | loss: 0.62032 - acc: 0.6351 -- iter: 0640/2395
[A[ATraining Step: 396  | total loss: [1m[32m0.62159[0m[0m | time: 264.527s
[2K
| Adam | epoch: 006 | loss: 0.62159 - acc: 0.6403 -- iter: 0672/2395
[A[ATraining Step: 397  | total loss: [1m[32m0.61850[0m[0m | time: 277.357s
[2K
| Adam | epoch: 006 | loss: 0.61850 - acc: 0.6513 -- iter: 0704/2395
[A[ATraining Step: 398  | total loss: [1m[32m0.60880[0m[0m | time: 290.978s
[2K
| Adam | epoch: 006 | loss: 0.60880 - acc: 0.6674 -- iter: 0736/2395
[A[ATraining Step: 399  | total loss: [1m[32m0.61759[0m[0m | time: 304.842s
[2K
| Adam | epoch: 006 | loss: 0.61759 - acc: 0.6725 -- iter: 0768/2395
[A[ATraining Step: 400  | total loss: [1m[32m0.61769[0m[0m | time: 370.936s
[2K
| Adam | epoch: 006 | loss: 0.61769 - acc: 0.6740 | val_loss: 0.66869 - val_acc: 0.6128 -- iter: 0800/2395
--
Training Step: 401  | total loss: [1m[32m0.60758[0m[0m | time: 383.069s
[2K
| Adam | epoch: 006 | loss: 0.60758 - acc: 0.6879 -- iter: 0832/2395
[A[ATraining Step: 402  | total loss: [1m[32m0.60362[0m[0m | time: 395.857s
[2K
| Adam | epoch: 006 | loss: 0.60362 - acc: 0.6910 -- iter: 0864/2395
[A[ATraining Step: 403  | total loss: [1m[32m0.59538[0m[0m | time: 408.876s
[2K
| Adam | epoch: 006 | loss: 0.59538 - acc: 0.6937 -- iter: 0896/2395
[A[ATraining Step: 404  | total loss: [1m[32m0.59177[0m[0m | time: 421.911s
[2K
| Adam | epoch: 006 | loss: 0.59177 - acc: 0.6931 -- iter: 0928/2395
[A[ATraining Step: 405  | total loss: [1m[32m0.59203[0m[0m | time: 434.325s
[2K
| Adam | epoch: 006 | loss: 0.59203 - acc: 0.6832 -- iter: 0960/2395
[A[ATraining Step: 406  | total loss: [1m[32m0.59216[0m[0m | time: 446.907s
[2K
| Adam | epoch: 006 | loss: 0.59216 - acc: 0.6899 -- iter: 0992/2395
[A[ATraining Step: 407  | total loss: [1m[32m0.59734[0m[0m | time: 459.786s
[2K
| Adam | epoch: 006 | loss: 0.59734 - acc: 0.6834 -- iter: 1024/2395
[A[ATraining Step: 408  | total loss: [1m[32m0.60703[0m[0m | time: 472.595s
[2K
| Adam | epoch: 006 | loss: 0.60703 - acc: 0.6650 -- iter: 1056/2395
[A[ATraining Step: 409  | total loss: [1m[32m0.62662[0m[0m | time: 485.356s
[2K
| Adam | epoch: 006 | loss: 0.62662 - acc: 0.6610 -- iter: 1088/2395
[A[ATraining Step: 410  | total loss: [1m[32m0.62541[0m[0m | time: 497.757s
[2K
| Adam | epoch: 006 | loss: 0.62541 - acc: 0.6543 -- iter: 1120/2395
[A[ATraining Step: 411  | total loss: [1m[32m0.62139[0m[0m | time: 510.524s
[2K
| Adam | epoch: 006 | loss: 0.62139 - acc: 0.6514 -- iter: 1152/2395
[A[ATraining Step: 412  | total loss: [1m[32m0.61697[0m[0m | time: 523.022s
[2K
| Adam | epoch: 006 | loss: 0.61697 - acc: 0.6550 -- iter: 1184/2395
[A[ATraining Step: 413  | total loss: [1m[32m0.61022[0m[0m | time: 535.677s
[2K
| Adam | epoch: 006 | loss: 0.61022 - acc: 0.6582 -- iter: 1216/2395
[A[ATraining Step: 414  | total loss: [1m[32m0.60427[0m[0m | time: 548.433s
[2K
| Adam | epoch: 006 | loss: 0.60427 - acc: 0.6643 -- iter: 1248/2395
[A[ATraining Step: 415  | total loss: [1m[32m0.59583[0m[0m | time: 561.064s
[2K
| Adam | epoch: 006 | loss: 0.59583 - acc: 0.6760 -- iter: 1280/2395
[A[ATraining Step: 416  | total loss: [1m[32m0.60074[0m[0m | time: 574.042s
[2K
| Adam | epoch: 006 | loss: 0.60074 - acc: 0.6740 -- iter: 1312/2395
[A[ATraining Step: 417  | total loss: [1m[32m0.61503[0m[0m | time: 586.746s
[2K
| Adam | epoch: 006 | loss: 0.61503 - acc: 0.6660 -- iter: 1344/2395
[A[ATraining Step: 418  | total loss: [1m[32m0.61375[0m[0m | time: 599.483s
[2K
| Adam | epoch: 006 | loss: 0.61375 - acc: 0.6650 -- iter: 1376/2395
[A[ATraining Step: 419  | total loss: [1m[32m0.61262[0m[0m | time: 611.791s
[2K
| Adam | epoch: 006 | loss: 0.61262 - acc: 0.6548 -- iter: 1408/2395
[A[ATraining Step: 420  | total loss: [1m[32m0.61535[0m[0m | time: 624.486s
[2K
| Adam | epoch: 006 | loss: 0.61535 - acc: 0.6518 -- iter: 1440/2395
[A[ATraining Step: 421  | total loss: [1m[32m0.60579[0m[0m | time: 637.314s
[2K
| Adam | epoch: 006 | loss: 0.60579 - acc: 0.6679 -- iter: 1472/2395
[A[ATraining Step: 422  | total loss: [1m[32m0.61762[0m[0m | time: 650.110s
[2K
| Adam | epoch: 006 | loss: 0.61762 - acc: 0.6636 -- iter: 1504/2395
[A[ATraining Step: 423  | total loss: [1m[32m0.62414[0m[0m | time: 663.253s
[2K
| Adam | epoch: 006 | loss: 0.62414 - acc: 0.6535 -- iter: 1536/2395
[A[ATraining Step: 424  | total loss: [1m[32m0.63210[0m[0m | time: 676.266s
[2K
| Adam | epoch: 006 | loss: 0.63210 - acc: 0.6537 -- iter: 1568/2395
[A[ATraining Step: 425  | total loss: [1m[32m0.62340[0m[0m | time: 688.873s
[2K
| Adam | epoch: 006 | loss: 0.62340 - acc: 0.6540 -- iter: 1600/2395
[A[ATraining Step: 426  | total loss: [1m[32m0.61414[0m[0m | time: 701.684s
[2K
| Adam | epoch: 006 | loss: 0.61414 - acc: 0.6698 -- iter: 1632/2395
[A[ATraining Step: 427  | total loss: [1m[32m0.61580[0m[0m | time: 714.243s
[2K
| Adam | epoch: 006 | loss: 0.61580 - acc: 0.6685 -- iter: 1664/2395
[A[ATraining Step: 428  | total loss: [1m[32m0.61161[0m[0m | time: 726.991s
[2K
| Adam | epoch: 006 | loss: 0.61161 - acc: 0.6704 -- iter: 1696/2395
[A[ATraining Step: 429  | total loss: [1m[32m0.60712[0m[0m | time: 739.524s
[2K
| Adam | epoch: 006 | loss: 0.60712 - acc: 0.6815 -- iter: 1728/2395
[A[ATraining Step: 430  | total loss: [1m[32m0.60115[0m[0m | time: 751.955s
[2K
| Adam | epoch: 006 | loss: 0.60115 - acc: 0.6821 -- iter: 1760/2395
[A[ATraining Step: 431  | total loss: [1m[32m0.60011[0m[0m | time: 764.546s
[2K
| Adam | epoch: 006 | loss: 0.60011 - acc: 0.6889 -- iter: 1792/2395
[A[ATraining Step: 432  | total loss: [1m[32m0.60157[0m[0m | time: 785.846s
[2K
| Adam | epoch: 006 | loss: 0.60157 - acc: 0.6887 -- iter: 1824/2395
[A[ATraining Step: 433  | total loss: [1m[32m0.60297[0m[0m | time: 798.562s
[2K
| Adam | epoch: 006 | loss: 0.60297 - acc: 0.6792 -- iter: 1856/2395
[A[ATraining Step: 434  | total loss: [1m[32m0.59042[0m[0m | time: 811.343s
[2K
| Adam | epoch: 006 | loss: 0.59042 - acc: 0.6957 -- iter: 1888/2395
[A[ATraining Step: 435  | total loss: [1m[32m0.57925[0m[0m | time: 824.462s
[2K
| Adam | epoch: 006 | loss: 0.57925 - acc: 0.7074 -- iter: 1920/2395
[A[ATraining Step: 436  | total loss: [1m[32m0.57460[0m[0m | time: 836.771s
[2K
| Adam | epoch: 006 | loss: 0.57460 - acc: 0.7116 -- iter: 1952/2395
[A[ATraining Step: 437  | total loss: [1m[32m0.58071[0m[0m | time: 849.547s
[2K
| Adam | epoch: 006 | loss: 0.58071 - acc: 0.7030 -- iter: 1984/2395
[A[ATraining Step: 438  | total loss: [1m[32m0.57808[0m[0m | time: 862.501s
[2K
| Adam | epoch: 006 | loss: 0.57808 - acc: 0.7014 -- iter: 2016/2395
[A[ATraining Step: 439  | total loss: [1m[32m0.58228[0m[0m | time: 875.503s
[2K
| Adam | epoch: 006 | loss: 0.58228 - acc: 0.7000 -- iter: 2048/2395
[A[ATraining Step: 440  | total loss: [1m[32m0.57923[0m[0m | time: 888.331s
[2K
| Adam | epoch: 006 | loss: 0.57923 - acc: 0.6925 -- iter: 2080/2395
[A[ATraining Step: 441  | total loss: [1m[32m0.58009[0m[0m | time: 901.213s
[2K
| Adam | epoch: 006 | loss: 0.58009 - acc: 0.6858 -- iter: 2112/2395
[A[ATraining Step: 442  | total loss: [1m[32m0.57254[0m[0m | time: 913.539s
[2K
| Adam | epoch: 006 | loss: 0.57254 - acc: 0.6891 -- iter: 2144/2395
[A[ATraining Step: 443  | total loss: [1m[32m0.57955[0m[0m | time: 926.332s
[2K
| Adam | epoch: 006 | loss: 0.57955 - acc: 0.6858 -- iter: 2176/2395
[A[ATraining Step: 444  | total loss: [1m[32m0.59375[0m[0m | time: 939.526s
[2K
| Adam | epoch: 006 | loss: 0.59375 - acc: 0.6891 -- iter: 2208/2395
[A[ATraining Step: 445  | total loss: [1m[32m0.59031[0m[0m | time: 952.053s
[2K
| Adam | epoch: 006 | loss: 0.59031 - acc: 0.6952 -- iter: 2240/2395
[A[ATraining Step: 446  | total loss: [1m[32m0.59392[0m[0m | time: 964.952s
[2K
| Adam | epoch: 006 | loss: 0.59392 - acc: 0.6850 -- iter: 2272/2395
[A[ATraining Step: 447  | total loss: [1m[32m0.58578[0m[0m | time: 977.850s
[2K
| Adam | epoch: 006 | loss: 0.58578 - acc: 0.6978 -- iter: 2304/2395
[A[ATraining Step: 448  | total loss: [1m[32m0.59523[0m[0m | time: 991.177s
[2K
| Adam | epoch: 006 | loss: 0.59523 - acc: 0.6874 -- iter: 2336/2395
[A[ATraining Step: 449  | total loss: [1m[32m0.60003[0m[0m | time: 1004.078s
[2K
| Adam | epoch: 006 | loss: 0.60003 - acc: 0.6780 -- iter: 2368/2395
[A[ATraining Step: 450  | total loss: [1m[32m0.59940[0m[0m | time: 1072.680s
[2K
| Adam | epoch: 006 | loss: 0.59940 - acc: 0.6758 | val_loss: 0.74603 - val_acc: 0.5541 -- iter: 2395/2395
--
Training Step: 451  | total loss: [1m[32m0.59620[0m[0m | time: 12.892s
[2K
| Adam | epoch: 007 | loss: 0.59620 - acc: 0.6833 -- iter: 0032/2395
[A[ATraining Step: 452  | total loss: [1m[32m0.59167[0m[0m | time: 26.514s
[2K
| Adam | epoch: 007 | loss: 0.59167 - acc: 0.6837 -- iter: 0064/2395
[A[ATraining Step: 453  | total loss: [1m[32m0.59051[0m[0m | time: 39.706s
[2K
| Adam | epoch: 007 | loss: 0.59051 - acc: 0.6778 -- iter: 0096/2395
[A[ATraining Step: 454  | total loss: [1m[32m0.58873[0m[0m | time: 53.004s
[2K
| Adam | epoch: 007 | loss: 0.58873 - acc: 0.6757 -- iter: 0128/2395
[A[ATraining Step: 455  | total loss: [1m[32m0.58017[0m[0m | time: 63.883s
[2K
| Adam | epoch: 007 | loss: 0.58017 - acc: 0.6831 -- iter: 0160/2395
[A[ATraining Step: 456  | total loss: [1m[32m0.59079[0m[0m | time: 75.716s
[2K
| Adam | epoch: 007 | loss: 0.59079 - acc: 0.6777 -- iter: 0192/2395
[A[ATraining Step: 457  | total loss: [1m[32m0.59192[0m[0m | time: 88.909s
[2K
| Adam | epoch: 007 | loss: 0.59192 - acc: 0.6803 -- iter: 0224/2395
[A[ATraining Step: 458  | total loss: [1m[32m0.61300[0m[0m | time: 101.726s
[2K
| Adam | epoch: 007 | loss: 0.61300 - acc: 0.6592 -- iter: 0256/2395
[A[ATraining Step: 459  | total loss: [1m[32m0.60967[0m[0m | time: 114.793s
[2K
| Adam | epoch: 007 | loss: 0.60967 - acc: 0.6589 -- iter: 0288/2395
[A[ATraining Step: 460  | total loss: [1m[32m0.61229[0m[0m | time: 127.865s
[2K
| Adam | epoch: 007 | loss: 0.61229 - acc: 0.6586 -- iter: 0320/2395
[A[ATraining Step: 461  | total loss: [1m[32m0.60544[0m[0m | time: 141.303s
[2K
| Adam | epoch: 007 | loss: 0.60544 - acc: 0.6678 -- iter: 0352/2395
[A[ATraining Step: 462  | total loss: [1m[32m0.60590[0m[0m | time: 154.663s
[2K
| Adam | epoch: 007 | loss: 0.60590 - acc: 0.6604 -- iter: 0384/2395
[A[ATraining Step: 463  | total loss: [1m[32m0.61201[0m[0m | time: 167.838s
[2K
| Adam | epoch: 007 | loss: 0.61201 - acc: 0.6568 -- iter: 0416/2395
[A[ATraining Step: 464  | total loss: [1m[32m0.60867[0m[0m | time: 180.781s
[2K
| Adam | epoch: 007 | loss: 0.60867 - acc: 0.6693 -- iter: 0448/2395
[A[ATraining Step: 465  | total loss: [1m[32m0.61520[0m[0m | time: 194.010s
[2K
| Adam | epoch: 007 | loss: 0.61520 - acc: 0.6586 -- iter: 0480/2395
[A[ATraining Step: 466  | total loss: [1m[32m0.61750[0m[0m | time: 206.751s
[2K
| Adam | epoch: 007 | loss: 0.61750 - acc: 0.6584 -- iter: 0512/2395
[A[ATraining Step: 467  | total loss: [1m[32m0.62752[0m[0m | time: 219.571s
[2K
| Adam | epoch: 007 | loss: 0.62752 - acc: 0.6706 -- iter: 0544/2395
[A[ATraining Step: 468  | total loss: [1m[32m0.61693[0m[0m | time: 232.280s
[2K
| Adam | epoch: 007 | loss: 0.61693 - acc: 0.6880 -- iter: 0576/2395
[A[ATraining Step: 469  | total loss: [1m[32m0.61425[0m[0m | time: 245.502s
[2K
| Adam | epoch: 007 | loss: 0.61425 - acc: 0.6879 -- iter: 0608/2395
[A[ATraining Step: 470  | total loss: [1m[32m0.61811[0m[0m | time: 258.775s
[2K
| Adam | epoch: 007 | loss: 0.61811 - acc: 0.6816 -- iter: 0640/2395
[A[ATraining Step: 471  | total loss: [1m[32m0.61961[0m[0m | time: 271.758s
[2K
| Adam | epoch: 007 | loss: 0.61961 - acc: 0.6822 -- iter: 0672/2395
[A[ATraining Step: 472  | total loss: [1m[32m0.60986[0m[0m | time: 284.997s
[2K
| Adam | epoch: 007 | loss: 0.60986 - acc: 0.6890 -- iter: 0704/2395
[A[ATraining Step: 473  | total loss: [1m[32m0.61387[0m[0m | time: 297.563s
[2K
| Adam | epoch: 007 | loss: 0.61387 - acc: 0.6763 -- iter: 0736/2395
[A[ATraining Step: 474  | total loss: [1m[32m0.61925[0m[0m | time: 310.514s
[2K
| Adam | epoch: 007 | loss: 0.61925 - acc: 0.6743 -- iter: 0768/2395
[A[ATraining Step: 475  | total loss: [1m[32m0.61824[0m[0m | time: 324.130s
[2K
| Adam | epoch: 007 | loss: 0.61824 - acc: 0.6756 -- iter: 0800/2395
[A[ATraining Step: 476  | total loss: [1m[32m0.62357[0m[0m | time: 337.279s
[2K
| Adam | epoch: 007 | loss: 0.62357 - acc: 0.6643 -- iter: 0832/2395
[A[ATraining Step: 477  | total loss: [1m[32m0.62092[0m[0m | time: 350.410s
[2K
| Adam | epoch: 007 | loss: 0.62092 - acc: 0.6729 -- iter: 0864/2395
[A[ATraining Step: 478  | total loss: [1m[32m0.62462[0m[0m | time: 363.207s
[2K
| Adam | epoch: 007 | loss: 0.62462 - acc: 0.6744 -- iter: 0896/2395
[A[ATraining Step: 479  | total loss: [1m[32m0.61581[0m[0m | time: 376.054s
[2K
| Adam | epoch: 007 | loss: 0.61581 - acc: 0.6757 -- iter: 0928/2395
[A[ATraining Step: 480  | total loss: [1m[32m0.61443[0m[0m | time: 389.026s
[2K
| Adam | epoch: 007 | loss: 0.61443 - acc: 0.6737 -- iter: 0960/2395
[A[ATraining Step: 481  | total loss: [1m[32m0.60554[0m[0m | time: 402.448s
[2K
| Adam | epoch: 007 | loss: 0.60554 - acc: 0.6939 -- iter: 0992/2395
[A[ATraining Step: 482  | total loss: [1m[32m0.60747[0m[0m | time: 415.855s
[2K
| Adam | epoch: 007 | loss: 0.60747 - acc: 0.6901 -- iter: 1024/2395
[A[ATraining Step: 483  | total loss: [1m[32m0.61293[0m[0m | time: 429.094s
[2K
| Adam | epoch: 007 | loss: 0.61293 - acc: 0.6930 -- iter: 1056/2395
[A[ATraining Step: 484  | total loss: [1m[32m0.60958[0m[0m | time: 442.114s
[2K
| Adam | epoch: 007 | loss: 0.60958 - acc: 0.6955 -- iter: 1088/2395
[A[ATraining Step: 485  | total loss: [1m[32m0.59519[0m[0m | time: 455.305s
[2K
| Adam | epoch: 007 | loss: 0.59519 - acc: 0.7104 -- iter: 1120/2395
[A[ATraining Step: 486  | total loss: [1m[32m0.59272[0m[0m | time: 468.259s
[2K
| Adam | epoch: 007 | loss: 0.59272 - acc: 0.7050 -- iter: 1152/2395
[A[ATraining Step: 487  | total loss: [1m[32m0.60038[0m[0m | time: 481.123s
[2K
| Adam | epoch: 007 | loss: 0.60038 - acc: 0.6970 -- iter: 1184/2395
[A[ATraining Step: 488  | total loss: [1m[32m0.60620[0m[0m | time: 494.332s
[2K
| Adam | epoch: 007 | loss: 0.60620 - acc: 0.6929 -- iter: 1216/2395
[A[ATraining Step: 489  | total loss: [1m[32m0.60408[0m[0m | time: 507.676s
[2K
| Adam | epoch: 007 | loss: 0.60408 - acc: 0.6986 -- iter: 1248/2395
[A[ATraining Step: 490  | total loss: [1m[32m0.60601[0m[0m | time: 520.362s
[2K
| Adam | epoch: 007 | loss: 0.60601 - acc: 0.6975 -- iter: 1280/2395
[A[ATraining Step: 491  | total loss: [1m[32m0.59542[0m[0m | time: 533.707s
[2K
| Adam | epoch: 007 | loss: 0.59542 - acc: 0.7027 -- iter: 1312/2395
[A[ATraining Step: 492  | total loss: [1m[32m0.60446[0m[0m | time: 546.608s
[2K
| Adam | epoch: 007 | loss: 0.60446 - acc: 0.6950 -- iter: 1344/2395
[A[ATraining Step: 493  | total loss: [1m[32m0.60529[0m[0m | time: 559.827s
[2K
| Adam | epoch: 007 | loss: 0.60529 - acc: 0.6880 -- iter: 1376/2395
[A[ATraining Step: 494  | total loss: [1m[32m0.60189[0m[0m | time: 574.821s
[2K
| Adam | epoch: 007 | loss: 0.60189 - acc: 0.6910 -- iter: 1408/2395
[A[ATraining Step: 495  | total loss: [1m[32m0.59302[0m[0m | time: 589.906s
[2K
| Adam | epoch: 007 | loss: 0.59302 - acc: 0.6969 -- iter: 1440/2395
[A[ATraining Step: 496  | total loss: [1m[32m0.59497[0m[0m | time: 604.548s
[2K
| Adam | epoch: 007 | loss: 0.59497 - acc: 0.6897 -- iter: 1472/2395
[A[ATraining Step: 497  | total loss: [1m[32m0.60514[0m[0m | time: 619.229s
[2K
| Adam | epoch: 007 | loss: 0.60514 - acc: 0.6833 -- iter: 1504/2395
[A[ATraining Step: 498  | total loss: [1m[32m0.59802[0m[0m | time: 634.236s
[2K
| Adam | epoch: 007 | loss: 0.59802 - acc: 0.6931 -- iter: 1536/2395
[A[ATraining Step: 499  | total loss: [1m[32m0.60308[0m[0m | time: 644.150s
[2K
| Adam | epoch: 007 | loss: 0.60308 - acc: 0.6894 -- iter: 1568/2395
[A[ATraining Step: 500  | total loss: [1m[32m0.62955[0m[0m | time: 653.110s
[2K
| Adam | epoch: 007 | loss: 0.62955 - acc: 0.6736 -- iter: 1600/2395
[A[ATraining Step: 501  | total loss: [1m[32m0.62092[0m[0m | time: 662.073s
[2K
| Adam | epoch: 007 | loss: 0.62092 - acc: 0.6750 -- iter: 1632/2395
[A[ATraining Step: 502  | total loss: [1m[32m0.61725[0m[0m | time: 671.887s
[2K
| Adam | epoch: 007 | loss: 0.61725 - acc: 0.6606 -- iter: 1664/2395
[A[ATraining Step: 503  | total loss: [1m[32m0.61277[0m[0m | time: 684.461s
[2K
| Adam | epoch: 007 | loss: 0.61277 - acc: 0.6695 -- iter: 1696/2395
[A[ATraining Step: 504  | total loss: [1m[32m0.60601[0m[0m | time: 697.131s
[2K
| Adam | epoch: 007 | loss: 0.60601 - acc: 0.6713 -- iter: 1728/2395
[A[ATraining Step: 505  | total loss: [1m[32m0.60416[0m[0m | time: 710.090s
[2K
| Adam | epoch: 007 | loss: 0.60416 - acc: 0.6761 -- iter: 1760/2395
[A[ATraining Step: 506  | total loss: [1m[32m0.60840[0m[0m | time: 722.003s
[2K
| Adam | epoch: 007 | loss: 0.60840 - acc: 0.6678 -- iter: 1792/2395
[A[ATraining Step: 507  | total loss: [1m[32m0.60754[0m[0m | time: 735.010s
[2K
| Adam | epoch: 007 | loss: 0.60754 - acc: 0.6636 -- iter: 1824/2395
[A[ATraining Step: 508  | total loss: [1m[32m0.60422[0m[0m | time: 748.279s
[2K
| Adam | epoch: 007 | loss: 0.60422 - acc: 0.6753 -- iter: 1856/2395
[A[ATraining Step: 509  | total loss: [1m[32m0.59522[0m[0m | time: 761.128s
[2K
| Adam | epoch: 007 | loss: 0.59522 - acc: 0.6859 -- iter: 1888/2395
[A[ATraining Step: 510  | total loss: [1m[32m0.60789[0m[0m | time: 773.758s
[2K
| Adam | epoch: 007 | loss: 0.60789 - acc: 0.6767 -- iter: 1920/2395
[A[ATraining Step: 511  | total loss: [1m[32m0.61743[0m[0m | time: 786.937s
[2K
| Adam | epoch: 007 | loss: 0.61743 - acc: 0.6747 -- iter: 1952/2395
[A[ATraining Step: 512  | total loss: [1m[32m0.60953[0m[0m | time: 799.960s
[2K
| Adam | epoch: 007 | loss: 0.60953 - acc: 0.6791 -- iter: 1984/2395
[A[ATraining Step: 513  | total loss: [1m[32m0.60911[0m[0m | time: 813.017s
[2K
| Adam | epoch: 007 | loss: 0.60911 - acc: 0.6705 -- iter: 2016/2395
[A[ATraining Step: 514  | total loss: [1m[32m0.59798[0m[0m | time: 825.923s
[2K
| Adam | epoch: 007 | loss: 0.59798 - acc: 0.6785 -- iter: 2048/2395
[A[ATraining Step: 515  | total loss: [1m[32m0.59439[0m[0m | time: 838.744s
[2K
| Adam | epoch: 007 | loss: 0.59439 - acc: 0.6794 -- iter: 2080/2395
[A[ATraining Step: 516  | total loss: [1m[32m0.58827[0m[0m | time: 851.457s
[2K
| Adam | epoch: 007 | loss: 0.58827 - acc: 0.6896 -- iter: 2112/2395
[A[ATraining Step: 517  | total loss: [1m[32m0.58321[0m[0m | time: 864.519s
[2K
| Adam | epoch: 007 | loss: 0.58321 - acc: 0.6987 -- iter: 2144/2395
[A[ATraining Step: 518  | total loss: [1m[32m0.59209[0m[0m | time: 877.331s
[2K
| Adam | epoch: 007 | loss: 0.59209 - acc: 0.6882 -- iter: 2176/2395
[A[ATraining Step: 519  | total loss: [1m[32m0.59494[0m[0m | time: 890.099s
[2K
| Adam | epoch: 007 | loss: 0.59494 - acc: 0.6882 -- iter: 2208/2395
[A[ATraining Step: 520  | total loss: [1m[32m0.59721[0m[0m | time: 903.126s
[2K
| Adam | epoch: 007 | loss: 0.59721 - acc: 0.6912 -- iter: 2240/2395
[A[ATraining Step: 521  | total loss: [1m[32m0.59167[0m[0m | time: 916.049s
[2K
| Adam | epoch: 007 | loss: 0.59167 - acc: 0.6940 -- iter: 2272/2395
[A[ATraining Step: 522  | total loss: [1m[32m0.57729[0m[0m | time: 929.161s
[2K
| Adam | epoch: 007 | loss: 0.57729 - acc: 0.7027 -- iter: 2304/2395
[A[ATraining Step: 523  | total loss: [1m[32m0.57800[0m[0m | time: 942.090s
[2K
| Adam | epoch: 007 | loss: 0.57800 - acc: 0.6981 -- iter: 2336/2395
[A[ATraining Step: 524  | total loss: [1m[32m0.57822[0m[0m | time: 954.713s
[2K
| Adam | epoch: 007 | loss: 0.57822 - acc: 0.7001 -- iter: 2368/2395
[A[ATraining Step: 525  | total loss: [1m[32m0.57563[0m[0m | time: 1022.471s
[2K
| Adam | epoch: 007 | loss: 0.57563 - acc: 0.6989 | val_loss: 1.29791 - val_acc: 0.4927 -- iter: 2395/2395
--
Training Step: 526  | total loss: [1m[32m0.56871[0m[0m | time: 12.959s
[2K
| Adam | epoch: 008 | loss: 0.56871 - acc: 0.7040 -- iter: 0032/2395
[A[ATraining Step: 527  | total loss: [1m[32m0.56465[0m[0m | time: 25.940s
[2K
| Adam | epoch: 008 | loss: 0.56465 - acc: 0.7055 -- iter: 0064/2395
[A[ATraining Step: 528  | total loss: [1m[32m0.56850[0m[0m | time: 38.667s
[2K
| Adam | epoch: 008 | loss: 0.56850 - acc: 0.6974 -- iter: 0096/2395
[A[ATraining Step: 529  | total loss: [1m[32m0.56622[0m[0m | time: 51.680s
[2K
| Adam | epoch: 008 | loss: 0.56622 - acc: 0.7058 -- iter: 0128/2395
[A[ATraining Step: 530  | total loss: [1m[32m0.57351[0m[0m | time: 64.574s
[2K
| Adam | epoch: 008 | loss: 0.57351 - acc: 0.7071 -- iter: 0160/2395
[A[ATraining Step: 531  | total loss: [1m[32m0.56592[0m[0m | time: 75.913s
[2K
| Adam | epoch: 008 | loss: 0.56592 - acc: 0.7083 -- iter: 0192/2395
[A[ATraining Step: 532  | total loss: [1m[32m0.57391[0m[0m | time: 87.492s
[2K
| Adam | epoch: 008 | loss: 0.57391 - acc: 0.6893 -- iter: 0224/2395
[A[ATraining Step: 533  | total loss: [1m[32m0.56882[0m[0m | time: 100.183s
[2K
| Adam | epoch: 008 | loss: 0.56882 - acc: 0.6759 -- iter: 0256/2395
[A[ATraining Step: 534  | total loss: [1m[32m0.55473[0m[0m | time: 113.261s
[2K
| Adam | epoch: 008 | loss: 0.55473 - acc: 0.6896 -- iter: 0288/2395
[A[ATraining Step: 535  | total loss: [1m[32m0.55917[0m[0m | time: 126.120s
[2K
| Adam | epoch: 008 | loss: 0.55917 - acc: 0.6769 -- iter: 0320/2395
[A[ATraining Step: 536  | total loss: [1m[32m0.55918[0m[0m | time: 139.244s
[2K
| Adam | epoch: 008 | loss: 0.55918 - acc: 0.6748 -- iter: 0352/2395
[A[ATraining Step: 537  | total loss: [1m[32m0.57688[0m[0m | time: 152.369s
[2K
| Adam | epoch: 008 | loss: 0.57688 - acc: 0.6636 -- iter: 0384/2395
[A[ATraining Step: 538  | total loss: [1m[32m0.57930[0m[0m | time: 165.227s
[2K
| Adam | epoch: 008 | loss: 0.57930 - acc: 0.6628 -- iter: 0416/2395
[A[ATraining Step: 539  | total loss: [1m[32m0.58219[0m[0m | time: 178.249s
[2K
| Adam | epoch: 008 | loss: 0.58219 - acc: 0.6653 -- iter: 0448/2395
[A[ATraining Step: 540  | total loss: [1m[32m0.58458[0m[0m | time: 191.251s
[2K
| Adam | epoch: 008 | loss: 0.58458 - acc: 0.6613 -- iter: 0480/2395
[A[ATraining Step: 541  | total loss: [1m[32m0.59008[0m[0m | time: 204.180s
[2K
| Adam | epoch: 008 | loss: 0.59008 - acc: 0.6608 -- iter: 0512/2395
[A[ATraining Step: 542  | total loss: [1m[32m0.58807[0m[0m | time: 216.717s
[2K
| Adam | epoch: 008 | loss: 0.58807 - acc: 0.6634 -- iter: 0544/2395
[A[ATraining Step: 543  | total loss: [1m[32m0.59273[0m[0m | time: 230.076s
[2K
| Adam | epoch: 008 | loss: 0.59273 - acc: 0.6659 -- iter: 0576/2395
[A[ATraining Step: 544  | total loss: [1m[32m0.58511[0m[0m | time: 242.891s
[2K
| Adam | epoch: 008 | loss: 0.58511 - acc: 0.6774 -- iter: 0608/2395
[A[ATraining Step: 545  | total loss: [1m[32m0.58455[0m[0m | time: 255.288s
[2K
| Adam | epoch: 008 | loss: 0.58455 - acc: 0.6815 -- iter: 0640/2395
[A[ATraining Step: 546  | total loss: [1m[32m0.59009[0m[0m | time: 267.685s
[2K
| Adam | epoch: 008 | loss: 0.59009 - acc: 0.6852 -- iter: 0672/2395
[A[ATraining Step: 547  | total loss: [1m[32m0.58538[0m[0m | time: 288.792s
[2K
| Adam | epoch: 008 | loss: 0.58538 - acc: 0.6792 -- iter: 0704/2395
[A[ATraining Step: 548  | total loss: [1m[32m0.58647[0m[0m | time: 301.946s
[2K
| Adam | epoch: 008 | loss: 0.58647 - acc: 0.6801 -- iter: 0736/2395
[A[ATraining Step: 549  | total loss: [1m[32m0.59632[0m[0m | time: 314.663s
[2K
| Adam | epoch: 008 | loss: 0.59632 - acc: 0.6683 -- iter: 0768/2395
[A[ATraining Step: 550  | total loss: [1m[32m0.59897[0m[0m | time: 327.757s
[2K
| Adam | epoch: 008 | loss: 0.59897 - acc: 0.6640 -- iter: 0800/2395
[A[ATraining Step: 551  | total loss: [1m[32m0.59769[0m[0m | time: 340.723s
[2K
| Adam | epoch: 008 | loss: 0.59769 - acc: 0.6569 -- iter: 0832/2395
[A[ATraining Step: 552  | total loss: [1m[32m0.58876[0m[0m | time: 353.862s
[2K
| Adam | epoch: 008 | loss: 0.58876 - acc: 0.6725 -- iter: 0864/2395
[A[ATraining Step: 553  | total loss: [1m[32m0.58686[0m[0m | time: 366.567s
[2K
| Adam | epoch: 008 | loss: 0.58686 - acc: 0.6678 -- iter: 0896/2395
[A[ATraining Step: 554  | total loss: [1m[32m0.58048[0m[0m | time: 379.262s
[2K
| Adam | epoch: 008 | loss: 0.58048 - acc: 0.6791 -- iter: 0928/2395
[A[ATraining Step: 555  | total loss: [1m[32m0.57471[0m[0m | time: 392.228s
[2K
| Adam | epoch: 008 | loss: 0.57471 - acc: 0.6831 -- iter: 0960/2395
[A[ATraining Step: 556  | total loss: [1m[32m0.57846[0m[0m | time: 405.297s
[2K
| Adam | epoch: 008 | loss: 0.57846 - acc: 0.6866 -- iter: 0992/2395
[A[ATraining Step: 557  | total loss: [1m[32m0.58449[0m[0m | time: 418.176s
[2K
| Adam | epoch: 008 | loss: 0.58449 - acc: 0.6836 -- iter: 1024/2395
[A[ATraining Step: 558  | total loss: [1m[32m0.58189[0m[0m | time: 430.960s
[2K
| Adam | epoch: 008 | loss: 0.58189 - acc: 0.6902 -- iter: 1056/2395
[A[ATraining Step: 559  | total loss: [1m[32m0.58436[0m[0m | time: 444.046s
[2K
| Adam | epoch: 008 | loss: 0.58436 - acc: 0.6931 -- iter: 1088/2395
[A[ATraining Step: 560  | total loss: [1m[32m0.57647[0m[0m | time: 456.788s
[2K
| Adam | epoch: 008 | loss: 0.57647 - acc: 0.7050 -- iter: 1120/2395
[A[ATraining Step: 561  | total loss: [1m[32m0.57967[0m[0m | time: 469.688s
[2K
| Adam | epoch: 008 | loss: 0.57967 - acc: 0.6939 -- iter: 1152/2395
[A[ATraining Step: 562  | total loss: [1m[32m0.58323[0m[0m | time: 483.003s
[2K
| Adam | epoch: 008 | loss: 0.58323 - acc: 0.6870 -- iter: 1184/2395
[A[ATraining Step: 563  | total loss: [1m[32m0.57972[0m[0m | time: 496.495s
[2K
| Adam | epoch: 008 | loss: 0.57972 - acc: 0.6871 -- iter: 1216/2395
[A[ATraining Step: 564  | total loss: [1m[32m0.58245[0m[0m | time: 516.830s
[2K
| Adam | epoch: 008 | loss: 0.58245 - acc: 0.6902 -- iter: 1248/2395
[A[ATraining Step: 565  | total loss: [1m[32m0.57274[0m[0m | time: 529.919s
[2K
| Adam | epoch: 008 | loss: 0.57274 - acc: 0.6993 -- iter: 1280/2395
[A[ATraining Step: 566  | total loss: [1m[32m0.58045[0m[0m | time: 542.947s
[2K
| Adam | epoch: 008 | loss: 0.58045 - acc: 0.6950 -- iter: 1312/2395
[A[ATraining Step: 567  | total loss: [1m[32m0.58974[0m[0m | time: 555.780s
[2K
| Adam | epoch: 008 | loss: 0.58974 - acc: 0.6911 -- iter: 1344/2395
[A[ATraining Step: 568  | total loss: [1m[32m0.59040[0m[0m | time: 568.284s
[2K
| Adam | epoch: 008 | loss: 0.59040 - acc: 0.6970 -- iter: 1376/2395
[A[ATraining Step: 569  | total loss: [1m[32m0.58810[0m[0m | time: 581.300s
[2K
| Adam | epoch: 008 | loss: 0.58810 - acc: 0.6930 -- iter: 1408/2395
[A[ATraining Step: 570  | total loss: [1m[32m0.58896[0m[0m | time: 594.224s
[2K
| Adam | epoch: 008 | loss: 0.58896 - acc: 0.6924 -- iter: 1440/2395
[A[ATraining Step: 571  | total loss: [1m[32m0.59674[0m[0m | time: 607.275s
[2K
| Adam | epoch: 008 | loss: 0.59674 - acc: 0.6888 -- iter: 1472/2395
[A[ATraining Step: 572  | total loss: [1m[32m0.60921[0m[0m | time: 620.017s
[2K
| Adam | epoch: 008 | loss: 0.60921 - acc: 0.6762 -- iter: 1504/2395
[A[ATraining Step: 573  | total loss: [1m[32m0.61047[0m[0m | time: 632.928s
[2K
| Adam | epoch: 008 | loss: 0.61047 - acc: 0.6710 -- iter: 1536/2395
[A[ATraining Step: 574  | total loss: [1m[32m0.60745[0m[0m | time: 645.818s
[2K
| Adam | epoch: 008 | loss: 0.60745 - acc: 0.6664 -- iter: 1568/2395
[A[ATraining Step: 575  | total loss: [1m[32m0.61094[0m[0m | time: 658.275s
[2K
| Adam | epoch: 008 | loss: 0.61094 - acc: 0.6654 -- iter: 1600/2395
[A[ATraining Step: 576  | total loss: [1m[32m0.59796[0m[0m | time: 670.849s
[2K
| Adam | epoch: 008 | loss: 0.59796 - acc: 0.6801 -- iter: 1632/2395
[A[ATraining Step: 577  | total loss: [1m[32m0.58559[0m[0m | time: 683.685s
[2K
| Adam | epoch: 008 | loss: 0.58559 - acc: 0.6902 -- iter: 1664/2395
[A[ATraining Step: 578  | total loss: [1m[32m0.57333[0m[0m | time: 696.504s
[2K
| Adam | epoch: 008 | loss: 0.57333 - acc: 0.7025 -- iter: 1696/2395
[A[ATraining Step: 579  | total loss: [1m[32m0.55959[0m[0m | time: 709.551s
[2K
| Adam | epoch: 008 | loss: 0.55959 - acc: 0.7166 -- iter: 1728/2395
[A[ATraining Step: 580  | total loss: [1m[32m0.55902[0m[0m | time: 722.494s
[2K
| Adam | epoch: 008 | loss: 0.55902 - acc: 0.7137 -- iter: 1760/2395
[A[ATraining Step: 581  | total loss: [1m[32m0.54896[0m[0m | time: 735.402s
[2K
| Adam | epoch: 008 | loss: 0.54896 - acc: 0.7173 -- iter: 1792/2395
[A[ATraining Step: 582  | total loss: [1m[32m0.54138[0m[0m | time: 748.566s
[2K
| Adam | epoch: 008 | loss: 0.54138 - acc: 0.7206 -- iter: 1824/2395
[A[ATraining Step: 583  | total loss: [1m[32m0.53852[0m[0m | time: 761.340s
[2K
| Adam | epoch: 008 | loss: 0.53852 - acc: 0.7173 -- iter: 1856/2395
[A[ATraining Step: 584  | total loss: [1m[32m0.52833[0m[0m | time: 774.238s
[2K
| Adam | epoch: 008 | loss: 0.52833 - acc: 0.7237 -- iter: 1888/2395
[A[ATraining Step: 585  | total loss: [1m[32m0.52450[0m[0m | time: 788.124s
[2K
| Adam | epoch: 008 | loss: 0.52450 - acc: 0.7294 -- iter: 1920/2395
[A[ATraining Step: 586  | total loss: [1m[32m0.53215[0m[0m | time: 802.456s
[2K
| Adam | epoch: 008 | loss: 0.53215 - acc: 0.7252 -- iter: 1952/2395
[A[ATraining Step: 587  | total loss: [1m[32m0.52434[0m[0m | time: 816.141s
[2K
| Adam | epoch: 008 | loss: 0.52434 - acc: 0.7246 -- iter: 1984/2395
[A[ATraining Step: 588  | total loss: [1m[32m0.52560[0m[0m | time: 830.568s
[2K
| Adam | epoch: 008 | loss: 0.52560 - acc: 0.7240 -- iter: 2016/2395
[A[ATraining Step: 589  | total loss: [1m[32m0.51008[0m[0m | time: 844.802s
[2K
| Adam | epoch: 008 | loss: 0.51008 - acc: 0.7391 -- iter: 2048/2395
[A[ATraining Step: 590  | total loss: [1m[32m0.50231[0m[0m | time: 855.547s
[2K
| Adam | epoch: 008 | loss: 0.50231 - acc: 0.7464 -- iter: 2080/2395
[A[ATraining Step: 591  | total loss: [1m[32m0.51556[0m[0m | time: 866.158s
[2K
| Adam | epoch: 008 | loss: 0.51556 - acc: 0.7437 -- iter: 2112/2395
[A[ATraining Step: 592  | total loss: [1m[32m0.51855[0m[0m | time: 879.279s
[2K
| Adam | epoch: 008 | loss: 0.51855 - acc: 0.7412 -- iter: 2144/2395
[A[ATraining Step: 593  | total loss: [1m[32m0.51337[0m[0m | time: 892.057s
[2K
| Adam | epoch: 008 | loss: 0.51337 - acc: 0.7483 -- iter: 2176/2395
[A[ATraining Step: 594  | total loss: [1m[32m0.52249[0m[0m | time: 904.743s
[2K
| Adam | epoch: 008 | loss: 0.52249 - acc: 0.7485 -- iter: 2208/2395
[A[ATraining Step: 595  | total loss: [1m[32m0.53063[0m[0m | time: 917.739s
[2K
| Adam | epoch: 008 | loss: 0.53063 - acc: 0.7580 -- iter: 2240/2395
[A[ATraining Step: 596  | total loss: [1m[32m0.54231[0m[0m | time: 931.052s
[2K
| Adam | epoch: 008 | loss: 0.54231 - acc: 0.7572 -- iter: 2272/2395
[A[ATraining Step: 597  | total loss: [1m[32m0.55181[0m[0m | time: 943.837s
[2K
| Adam | epoch: 008 | loss: 0.55181 - acc: 0.7409 -- iter: 2304/2395
[A[ATraining Step: 598  | total loss: [1m[32m0.57025[0m[0m | time: 956.679s
[2K
| Adam | epoch: 008 | loss: 0.57025 - acc: 0.7199 -- iter: 2336/2395
[A[ATraining Step: 599  | total loss: [1m[32m0.56882[0m[0m | time: 969.505s
[2K
| Adam | epoch: 008 | loss: 0.56882 - acc: 0.7198 -- iter: 2368/2395
[A[ATraining Step: 600  | total loss: [1m[32m0.57430[0m[0m | time: 1039.472s
[2K
| Adam | epoch: 008 | loss: 0.57430 - acc: 0.7103 | val_loss: 1.35577 - val_acc: 0.5394 -- iter: 2395/2395
--
Training Step: 601  | total loss: [1m[32m0.58150[0m[0m | time: 14.849s
[2K
| Adam | epoch: 009 | loss: 0.58150 - acc: 0.7018 -- iter: 0032/2395
[A[ATraining Step: 602  | total loss: [1m[32m0.57836[0m[0m | time: 26.193s
[2K
| Adam | epoch: 009 | loss: 0.57836 - acc: 0.7066 -- iter: 0064/2395
[A[ATraining Step: 603  | total loss: [1m[32m0.59324[0m[0m | time: 34.962s
[2K
| Adam | epoch: 009 | loss: 0.59324 - acc: 0.6859 -- iter: 0096/2395
[A[ATraining Step: 604  | total loss: [1m[32m0.58824[0m[0m | time: 44.256s
[2K
| Adam | epoch: 009 | loss: 0.58824 - acc: 0.6892 -- iter: 0128/2395
[A[ATraining Step: 605  | total loss: [1m[32m0.58289[0m[0m | time: 57.490s
[2K
| Adam | epoch: 009 | loss: 0.58289 - acc: 0.6984 -- iter: 0160/2395
[A[ATraining Step: 606  | total loss: [1m[32m0.59269[0m[0m | time: 71.665s
[2K
| Adam | epoch: 009 | loss: 0.59269 - acc: 0.6848 -- iter: 0192/2395
[A[ATraining Step: 607  | total loss: [1m[32m0.58153[0m[0m | time: 82.653s
[2K
| Adam | epoch: 009 | loss: 0.58153 - acc: 0.6976 -- iter: 0224/2395
[A[ATraining Step: 608  | total loss: [1m[32m0.57705[0m[0m | time: 94.503s
[2K
| Adam | epoch: 009 | loss: 0.57705 - acc: 0.7056 -- iter: 0256/2395
[A[ATraining Step: 609  | total loss: [1m[32m0.56978[0m[0m | time: 106.576s
[2K
| Adam | epoch: 009 | loss: 0.56978 - acc: 0.7128 -- iter: 0288/2395
[A[ATraining Step: 610  | total loss: [1m[32m0.56690[0m[0m | time: 119.578s
[2K
| Adam | epoch: 009 | loss: 0.56690 - acc: 0.7228 -- iter: 0320/2395
[A[ATraining Step: 611  | total loss: [1m[32m0.56645[0m[0m | time: 132.828s
[2K
| Adam | epoch: 009 | loss: 0.56645 - acc: 0.7255 -- iter: 0352/2395
[A[ATraining Step: 612  | total loss: [1m[32m0.56619[0m[0m | time: 145.817s
[2K
| Adam | epoch: 009 | loss: 0.56619 - acc: 0.7248 -- iter: 0384/2395
[A[ATraining Step: 613  | total loss: [1m[32m0.57063[0m[0m | time: 158.939s
[2K
| Adam | epoch: 009 | loss: 0.57063 - acc: 0.7117 -- iter: 0416/2395
[A[ATraining Step: 614  | total loss: [1m[32m0.56396[0m[0m | time: 172.027s
[2K
| Adam | epoch: 009 | loss: 0.56396 - acc: 0.7281 -- iter: 0448/2395
[A[ATraining Step: 615  | total loss: [1m[32m0.55628[0m[0m | time: 184.748s
[2K
| Adam | epoch: 009 | loss: 0.55628 - acc: 0.7396 -- iter: 0480/2395
[A[ATraining Step: 616  | total loss: [1m[32m0.54950[0m[0m | time: 197.829s
[2K
| Adam | epoch: 009 | loss: 0.54950 - acc: 0.7407 -- iter: 0512/2395
[A[ATraining Step: 617  | total loss: [1m[32m0.55617[0m[0m | time: 210.909s
[2K
| Adam | epoch: 009 | loss: 0.55617 - acc: 0.7291 -- iter: 0544/2395
[A[ATraining Step: 618  | total loss: [1m[32m0.56475[0m[0m | time: 223.340s
[2K
| Adam | epoch: 009 | loss: 0.56475 - acc: 0.7249 -- iter: 0576/2395
[A[ATraining Step: 619  | total loss: [1m[32m0.57315[0m[0m | time: 236.936s
[2K
| Adam | epoch: 009 | loss: 0.57315 - acc: 0.7243 -- iter: 0608/2395
[A[ATraining Step: 620  | total loss: [1m[32m0.56746[0m[0m | time: 249.587s
[2K
| Adam | epoch: 009 | loss: 0.56746 - acc: 0.7331 -- iter: 0640/2395
[A[ATraining Step: 621  | total loss: [1m[32m0.55830[0m[0m | time: 262.515s
[2K
| Adam | epoch: 009 | loss: 0.55830 - acc: 0.7286 -- iter: 0672/2395
[A[ATraining Step: 622  | total loss: [1m[32m0.55879[0m[0m | time: 275.527s
[2K
| Adam | epoch: 009 | loss: 0.55879 - acc: 0.7213 -- iter: 0704/2395
[A[ATraining Step: 623  | total loss: [1m[32m0.54561[0m[0m | time: 288.335s
[2K
| Adam | epoch: 009 | loss: 0.54561 - acc: 0.7305 -- iter: 0736/2395
[A[ATraining Step: 624  | total loss: [1m[32m0.55156[0m[0m | time: 301.654s
[2K
| Adam | epoch: 009 | loss: 0.55156 - acc: 0.7199 -- iter: 0768/2395
[A[ATraining Step: 625  | total loss: [1m[32m0.54319[0m[0m | time: 315.232s
[2K
| Adam | epoch: 009 | loss: 0.54319 - acc: 0.7229 -- iter: 0800/2395
[A[ATraining Step: 626  | total loss: [1m[32m0.53944[0m[0m | time: 328.575s
[2K
| Adam | epoch: 009 | loss: 0.53944 - acc: 0.7256 -- iter: 0832/2395
[A[ATraining Step: 627  | total loss: [1m[32m0.52977[0m[0m | time: 340.975s
[2K
| Adam | epoch: 009 | loss: 0.52977 - acc: 0.7343 -- iter: 0864/2395
[A[ATraining Step: 628  | total loss: [1m[32m0.52630[0m[0m | time: 354.201s
[2K
| Adam | epoch: 009 | loss: 0.52630 - acc: 0.7390 -- iter: 0896/2395
[A[ATraining Step: 629  | total loss: [1m[32m0.50873[0m[0m | time: 367.138s
[2K
| Adam | epoch: 009 | loss: 0.50873 - acc: 0.7557 -- iter: 0928/2395
[A[ATraining Step: 630  | total loss: [1m[32m0.52923[0m[0m | time: 379.943s
[2K
| Adam | epoch: 009 | loss: 0.52923 - acc: 0.7364 -- iter: 0960/2395
[A[ATraining Step: 631  | total loss: [1m[32m0.51892[0m[0m | time: 393.058s
[2K
| Adam | epoch: 009 | loss: 0.51892 - acc: 0.7378 -- iter: 0992/2395
[A[ATraining Step: 632  | total loss: [1m[32m0.49624[0m[0m | time: 405.903s
[2K
| Adam | epoch: 009 | loss: 0.49624 - acc: 0.7609 -- iter: 1024/2395
[A[ATraining Step: 633  | total loss: [1m[32m0.49842[0m[0m | time: 419.045s
[2K
| Adam | epoch: 009 | loss: 0.49842 - acc: 0.7629 -- iter: 1056/2395
[A[ATraining Step: 634  | total loss: [1m[32m0.51509[0m[0m | time: 431.712s
[2K
| Adam | epoch: 009 | loss: 0.51509 - acc: 0.7491 -- iter: 1088/2395
[A[ATraining Step: 635  | total loss: [1m[32m0.52379[0m[0m | time: 444.741s
[2K
| Adam | epoch: 009 | loss: 0.52379 - acc: 0.7398 -- iter: 1120/2395
[A[ATraining Step: 636  | total loss: [1m[32m0.54081[0m[0m | time: 457.743s
[2K
| Adam | epoch: 009 | loss: 0.54081 - acc: 0.7377 -- iter: 1152/2395
[A[ATraining Step: 637  | total loss: [1m[32m0.53318[0m[0m | time: 470.545s
[2K
| Adam | epoch: 009 | loss: 0.53318 - acc: 0.7452 -- iter: 1184/2395
[A[ATraining Step: 638  | total loss: [1m[32m0.52483[0m[0m | time: 483.688s
[2K
| Adam | epoch: 009 | loss: 0.52483 - acc: 0.7488 -- iter: 1216/2395
[A[ATraining Step: 639  | total loss: [1m[32m0.51835[0m[0m | time: 497.065s
[2K
| Adam | epoch: 009 | loss: 0.51835 - acc: 0.7520 -- iter: 1248/2395
[A[ATraining Step: 640  | total loss: [1m[32m0.51167[0m[0m | time: 509.961s
[2K
| Adam | epoch: 009 | loss: 0.51167 - acc: 0.7550 -- iter: 1280/2395
[A[ATraining Step: 641  | total loss: [1m[32m0.51149[0m[0m | time: 522.938s
[2K
| Adam | epoch: 009 | loss: 0.51149 - acc: 0.7607 -- iter: 1312/2395
[A[ATraining Step: 642  | total loss: [1m[32m0.53355[0m[0m | time: 536.239s
[2K
| Adam | epoch: 009 | loss: 0.53355 - acc: 0.7471 -- iter: 1344/2395
[A[ATraining Step: 643  | total loss: [1m[32m0.53690[0m[0m | time: 549.334s
[2K
| Adam | epoch: 009 | loss: 0.53690 - acc: 0.7412 -- iter: 1376/2395
[A[ATraining Step: 644  | total loss: [1m[32m0.56999[0m[0m | time: 562.448s
[2K
| Adam | epoch: 009 | loss: 0.56999 - acc: 0.7202 -- iter: 1408/2395
[A[ATraining Step: 645  | total loss: [1m[32m0.55989[0m[0m | time: 579.969s
[2K
| Adam | epoch: 009 | loss: 0.55989 - acc: 0.7294 -- iter: 1440/2395
[A[ATraining Step: 646  | total loss: [1m[32m0.54882[0m[0m | time: 592.543s
[2K
| Adam | epoch: 009 | loss: 0.54882 - acc: 0.7409 -- iter: 1472/2395
[A[ATraining Step: 647  | total loss: [1m[32m0.54334[0m[0m | time: 605.594s
[2K
| Adam | epoch: 009 | loss: 0.54334 - acc: 0.7418 -- iter: 1504/2395
[A[ATraining Step: 648  | total loss: [1m[32m0.54968[0m[0m | time: 618.179s
[2K
| Adam | epoch: 009 | loss: 0.54968 - acc: 0.7363 -- iter: 1536/2395
[A[ATraining Step: 649  | total loss: [1m[32m0.53708[0m[0m | time: 630.963s
[2K
| Adam | epoch: 009 | loss: 0.53708 - acc: 0.7533 -- iter: 1568/2395
[A[ATraining Step: 650  | total loss: [1m[32m0.54302[0m[0m | time: 644.195s
[2K
| Adam | epoch: 009 | loss: 0.54302 - acc: 0.7405 -- iter: 1600/2395
[A[ATraining Step: 651  | total loss: [1m[32m0.54781[0m[0m | time: 664.935s
[2K
| Adam | epoch: 009 | loss: 0.54781 - acc: 0.7321 -- iter: 1632/2395
[A[ATraining Step: 652  | total loss: [1m[32m0.55017[0m[0m | time: 677.778s
[2K
| Adam | epoch: 009 | loss: 0.55017 - acc: 0.7214 -- iter: 1664/2395
[A[ATraining Step: 653  | total loss: [1m[32m0.54395[0m[0m | time: 691.174s
[2K
| Adam | epoch: 009 | loss: 0.54395 - acc: 0.7305 -- iter: 1696/2395
[A[ATraining Step: 654  | total loss: [1m[32m0.53382[0m[0m | time: 704.198s
[2K
| Adam | epoch: 009 | loss: 0.53382 - acc: 0.7356 -- iter: 1728/2395
[A[ATraining Step: 655  | total loss: [1m[32m0.53071[0m[0m | time: 717.174s
[2K
| Adam | epoch: 009 | loss: 0.53071 - acc: 0.7370 -- iter: 1760/2395
[A[ATraining Step: 656  | total loss: [1m[32m0.53899[0m[0m | time: 730.444s
[2K
| Adam | epoch: 009 | loss: 0.53899 - acc: 0.7289 -- iter: 1792/2395
[A[ATraining Step: 657  | total loss: [1m[32m0.52195[0m[0m | time: 743.668s
[2K
| Adam | epoch: 009 | loss: 0.52195 - acc: 0.7467 -- iter: 1824/2395
[A[ATraining Step: 658  | total loss: [1m[32m0.52854[0m[0m | time: 757.289s
[2K
| Adam | epoch: 009 | loss: 0.52854 - acc: 0.7376 -- iter: 1856/2395
[A[ATraining Step: 659  | total loss: [1m[32m0.51514[0m[0m | time: 769.868s
[2K
| Adam | epoch: 009 | loss: 0.51514 - acc: 0.7514 -- iter: 1888/2395
[A[ATraining Step: 660  | total loss: [1m[32m0.51878[0m[0m | time: 783.454s
[2K
| Adam | epoch: 009 | loss: 0.51878 - acc: 0.7387 -- iter: 1920/2395
[A[ATraining Step: 661  | total loss: [1m[32m0.51723[0m[0m | time: 796.504s
[2K
| Adam | epoch: 009 | loss: 0.51723 - acc: 0.7430 -- iter: 1952/2395
[A[ATraining Step: 662  | total loss: [1m[32m0.51261[0m[0m | time: 814.403s
[2K
| Adam | epoch: 009 | loss: 0.51261 - acc: 0.7406 -- iter: 1984/2395
[A[ATraining Step: 663  | total loss: [1m[32m0.50214[0m[0m | time: 827.387s
[2K
| Adam | epoch: 009 | loss: 0.50214 - acc: 0.7477 -- iter: 2016/2395
[A[ATraining Step: 664  | total loss: [1m[32m0.51433[0m[0m | time: 840.689s
[2K
| Adam | epoch: 009 | loss: 0.51433 - acc: 0.7386 -- iter: 2048/2395
[A[ATraining Step: 665  | total loss: [1m[32m0.49784[0m[0m | time: 853.438s
[2K
| Adam | epoch: 009 | loss: 0.49784 - acc: 0.7554 -- iter: 2080/2395
[A[ATraining Step: 666  | total loss: [1m[32m0.49430[0m[0m | time: 866.582s
[2K
| Adam | epoch: 009 | loss: 0.49430 - acc: 0.7580 -- iter: 2112/2395
[A[ATraining Step: 667  | total loss: [1m[32m0.49630[0m[0m | time: 882.643s
[2K
| Adam | epoch: 009 | loss: 0.49630 - acc: 0.7572 -- iter: 2144/2395
[A[ATraining Step: 668  | total loss: [1m[32m0.49263[0m[0m | time: 895.567s
[2K
| Adam | epoch: 009 | loss: 0.49263 - acc: 0.7596 -- iter: 2176/2395
[A[ATraining Step: 669  | total loss: [1m[32m0.48008[0m[0m | time: 908.301s
[2K
| Adam | epoch: 009 | loss: 0.48008 - acc: 0.7711 -- iter: 2208/2395
[A[ATraining Step: 670  | total loss: [1m[32m0.46912[0m[0m | time: 921.324s
[2K
| Adam | epoch: 009 | loss: 0.46912 - acc: 0.7784 -- iter: 2240/2395
[A[ATraining Step: 671  | total loss: [1m[32m0.46037[0m[0m | time: 934.441s
[2K
| Adam | epoch: 009 | loss: 0.46037 - acc: 0.7818 -- iter: 2272/2395
[A[ATraining Step: 672  | total loss: [1m[32m0.46972[0m[0m | time: 947.151s
[2K
| Adam | epoch: 009 | loss: 0.46972 - acc: 0.7817 -- iter: 2304/2395
[A[ATraining Step: 673  | total loss: [1m[32m0.45784[0m[0m | time: 960.115s
[2K
| Adam | epoch: 009 | loss: 0.45784 - acc: 0.7911 -- iter: 2336/2395
[A[ATraining Step: 674  | total loss: [1m[32m0.44455[0m[0m | time: 973.338s
[2K
| Adam | epoch: 009 | loss: 0.44455 - acc: 0.8057 -- iter: 2368/2395
[A[ATraining Step: 675  | total loss: [1m[32m0.44209[0m[0m | time: 1041.605s
[2K
| Adam | epoch: 009 | loss: 0.44209 - acc: 0.8033 | val_loss: 0.64718 - val_acc: 0.6809 -- iter: 2395/2395
--
Training Step: 676  | total loss: [1m[32m0.46131[0m[0m | time: 13.155s
[2K
| Adam | epoch: 010 | loss: 0.46131 - acc: 0.7886 -- iter: 0032/2395
[A[ATraining Step: 677  | total loss: [1m[32m0.47740[0m[0m | time: 26.196s
[2K
| Adam | epoch: 010 | loss: 0.47740 - acc: 0.7691 -- iter: 0064/2395
[A[ATraining Step: 678  | total loss: [1m[32m0.47973[0m[0m | time: 39.268s
[2K
| Adam | epoch: 010 | loss: 0.47973 - acc: 0.7703 -- iter: 0096/2395
[A[ATraining Step: 679  | total loss: [1m[32m0.48747[0m[0m | time: 52.213s
[2K
| Adam | epoch: 010 | loss: 0.48747 - acc: 0.7651 -- iter: 0128/2395
[A[ATraining Step: 680  | total loss: [1m[32m0.47312[0m[0m | time: 65.253s
[2K
| Adam | epoch: 010 | loss: 0.47312 - acc: 0.7793 -- iter: 0160/2395
[A[ATraining Step: 681  | total loss: [1m[32m0.49434[0m[0m | time: 78.332s
[2K
| Adam | epoch: 010 | loss: 0.49434 - acc: 0.7576 -- iter: 0192/2395
[A[ATraining Step: 682  | total loss: [1m[32m0.49687[0m[0m | time: 91.252s
[2K
| Adam | epoch: 010 | loss: 0.49687 - acc: 0.7568 -- iter: 0224/2395
[A[ATraining Step: 683  | total loss: [1m[32m0.49542[0m[0m | time: 102.656s
[2K
| Adam | epoch: 010 | loss: 0.49542 - acc: 0.7624 -- iter: 0256/2395
[A[ATraining Step: 684  | total loss: [1m[32m0.48339[0m[0m | time: 114.082s
[2K
| Adam | epoch: 010 | loss: 0.48339 - acc: 0.7639 -- iter: 0288/2395
[A[ATraining Step: 685  | total loss: [1m[32m0.46643[0m[0m | time: 126.651s
[2K
| Adam | epoch: 010 | loss: 0.46643 - acc: 0.7764 -- iter: 0320/2395
[A[ATraining Step: 686  | total loss: [1m[32m0.47638[0m[0m | time: 139.766s
[2K
| Adam | epoch: 010 | loss: 0.47638 - acc: 0.7644 -- iter: 0352/2395
[A[ATraining Step: 687  | total loss: [1m[32m0.48766[0m[0m | time: 152.583s
[2K
| Adam | epoch: 010 | loss: 0.48766 - acc: 0.7473 -- iter: 0384/2395
[A[ATraining Step: 688  | total loss: [1m[32m0.52001[0m[0m | time: 165.554s
[2K
| Adam | epoch: 010 | loss: 0.52001 - acc: 0.7320 -- iter: 0416/2395
[A[ATraining Step: 689  | total loss: [1m[32m0.52952[0m[0m | time: 178.527s
[2K
| Adam | epoch: 010 | loss: 0.52952 - acc: 0.7275 -- iter: 0448/2395
[A[ATraining Step: 690  | total loss: [1m[32m0.53443[0m[0m | time: 191.457s
[2K
| Adam | epoch: 010 | loss: 0.53443 - acc: 0.7204 -- iter: 0480/2395
[A[ATraining Step: 691  | total loss: [1m[32m0.53098[0m[0m | time: 204.489s
[2K
| Adam | epoch: 010 | loss: 0.53098 - acc: 0.7202 -- iter: 0512/2395
[A[ATraining Step: 692  | total loss: [1m[32m0.52370[0m[0m | time: 217.574s
[2K
| Adam | epoch: 010 | loss: 0.52370 - acc: 0.7232 -- iter: 0544/2395
[A[ATraining Step: 693  | total loss: [1m[32m0.53292[0m[0m | time: 230.577s
[2K
| Adam | epoch: 010 | loss: 0.53292 - acc: 0.7134 -- iter: 0576/2395
[A[ATraining Step: 694  | total loss: [1m[32m0.53519[0m[0m | time: 243.474s
[2K
| Adam | epoch: 010 | loss: 0.53519 - acc: 0.7202 -- iter: 0608/2395
[A[ATraining Step: 695  | total loss: [1m[32m0.54988[0m[0m | time: 256.509s
[2K
| Adam | epoch: 010 | loss: 0.54988 - acc: 0.7013 -- iter: 0640/2395
[A[ATraining Step: 696  | total loss: [1m[32m0.55466[0m[0m | time: 269.649s
[2K
| Adam | epoch: 010 | loss: 0.55466 - acc: 0.7030 -- iter: 0672/2395
[A[ATraining Step: 697  | total loss: [1m[32m0.55427[0m[0m | time: 282.824s
[2K
| Adam | epoch: 010 | loss: 0.55427 - acc: 0.7046 -- iter: 0704/2395
[A[ATraining Step: 698  | total loss: [1m[32m0.54728[0m[0m | time: 296.741s
[2K
| Adam | epoch: 010 | loss: 0.54728 - acc: 0.7154 -- iter: 0736/2395
[A[ATraining Step: 699  | total loss: [1m[32m0.53995[0m[0m | time: 310.733s
[2K
| Adam | epoch: 010 | loss: 0.53995 - acc: 0.7220 -- iter: 0768/2395
[A[ATraining Step: 700  | total loss: [1m[32m0.55402[0m[0m | time: 325.190s
[2K
| Adam | epoch: 010 | loss: 0.55402 - acc: 0.7154 -- iter: 0800/2395
[A[ATraining Step: 701  | total loss: [1m[32m0.56303[0m[0m | time: 339.762s
[2K
| Adam | epoch: 010 | loss: 0.56303 - acc: 0.7126 -- iter: 0832/2395
[A[ATraining Step: 702  | total loss: [1m[32m0.56314[0m[0m | time: 353.954s
[2K
| Adam | epoch: 010 | loss: 0.56314 - acc: 0.7164 -- iter: 0864/2395
[A[ATraining Step: 703  | total loss: [1m[32m0.55759[0m[0m | time: 365.510s
[2K
| Adam | epoch: 010 | loss: 0.55759 - acc: 0.7197 -- iter: 0896/2395
[A[ATraining Step: 704  | total loss: [1m[32m0.55769[0m[0m | time: 374.182s
[2K
| Adam | epoch: 010 | loss: 0.55769 - acc: 0.7227 -- iter: 0928/2395
[A[ATraining Step: 705  | total loss: [1m[32m0.55238[0m[0m | time: 383.416s
[2K
| Adam | epoch: 010 | loss: 0.55238 - acc: 0.7286 -- iter: 0960/2395
[A[ATraining Step: 706  | total loss: [1m[32m0.56917[0m[0m | time: 396.373s
[2K
| Adam | epoch: 010 | loss: 0.56917 - acc: 0.7182 -- iter: 0992/2395
[A[ATraining Step: 707  | total loss: [1m[32m0.57030[0m[0m | time: 409.501s
[2K
| Adam | epoch: 010 | loss: 0.57030 - acc: 0.7214 -- iter: 1024/2395
[A[ATraining Step: 708  | total loss: [1m[32m0.56129[0m[0m | time: 422.850s
[2K
| Adam | epoch: 010 | loss: 0.56129 - acc: 0.7274 -- iter: 1056/2395
[A[ATraining Step: 709  | total loss: [1m[32m0.54829[0m[0m | time: 435.972s
[2K
| Adam | epoch: 010 | loss: 0.54829 - acc: 0.7359 -- iter: 1088/2395
[A[ATraining Step: 710  | total loss: [1m[32m0.55424[0m[0m | time: 448.099s
[2K
| Adam | epoch: 010 | loss: 0.55424 - acc: 0.7279 -- iter: 1120/2395
[A[ATraining Step: 711  | total loss: [1m[32m0.55157[0m[0m | time: 460.164s
[2K
| Adam | epoch: 010 | loss: 0.55157 - acc: 0.7270 -- iter: 1152/2395
[A[ATraining Step: 712  | total loss: [1m[32m0.53723[0m[0m | time: 473.070s
[2K
| Adam | epoch: 010 | loss: 0.53723 - acc: 0.7356 -- iter: 1184/2395
[A[ATraining Step: 713  | total loss: [1m[32m0.51966[0m[0m | time: 486.201s
[2K
| Adam | epoch: 010 | loss: 0.51966 - acc: 0.7526 -- iter: 1216/2395
[A[ATraining Step: 714  | total loss: [1m[32m0.52824[0m[0m | time: 499.191s
[2K
| Adam | epoch: 010 | loss: 0.52824 - acc: 0.7399 -- iter: 1248/2395
[A[ATraining Step: 715  | total loss: [1m[32m0.51721[0m[0m | time: 512.189s
[2K
| Adam | epoch: 010 | loss: 0.51721 - acc: 0.7471 -- iter: 1280/2395
[A[ATraining Step: 716  | total loss: [1m[32m0.51325[0m[0m | time: 524.801s
[2K
| Adam | epoch: 010 | loss: 0.51325 - acc: 0.7474 -- iter: 1312/2395
[A[ATraining Step: 717  | total loss: [1m[32m0.50609[0m[0m | time: 537.636s
[2K
| Adam | epoch: 010 | loss: 0.50609 - acc: 0.7539 -- iter: 1344/2395
[A[ATraining Step: 718  | total loss: [1m[32m0.51005[0m[0m | time: 550.209s
[2K
| Adam | epoch: 010 | loss: 0.51005 - acc: 0.7473 -- iter: 1376/2395
[A[ATraining Step: 719  | total loss: [1m[32m0.50427[0m[0m | time: 563.060s
[2K
| Adam | epoch: 010 | loss: 0.50427 - acc: 0.7538 -- iter: 1408/2395
[A[ATraining Step: 720  | total loss: [1m[32m0.50100[0m[0m | time: 575.809s
[2K
| Adam | epoch: 010 | loss: 0.50100 - acc: 0.7534 -- iter: 1440/2395
[A[ATraining Step: 721  | total loss: [1m[32m0.51430[0m[0m | time: 588.544s
[2K
| Adam | epoch: 010 | loss: 0.51430 - acc: 0.7500 -- iter: 1472/2395
[A[ATraining Step: 722  | total loss: [1m[32m0.50634[0m[0m | time: 601.451s
[2K
| Adam | epoch: 010 | loss: 0.50634 - acc: 0.7468 -- iter: 1504/2395
[A[ATraining Step: 723  | total loss: [1m[32m0.49842[0m[0m | time: 614.430s
[2K
| Adam | epoch: 010 | loss: 0.49842 - acc: 0.7565 -- iter: 1536/2395
[A[ATraining Step: 724  | total loss: [1m[32m0.49698[0m[0m | time: 627.613s
[2K
| Adam | epoch: 010 | loss: 0.49698 - acc: 0.7621 -- iter: 1568/2395
[A[ATraining Step: 725  | total loss: [1m[32m0.49868[0m[0m | time: 639.923s
[2K
| Adam | epoch: 010 | loss: 0.49868 - acc: 0.7640 -- iter: 1600/2395
[A[ATraining Step: 726  | total loss: [1m[32m0.49691[0m[0m | time: 652.552s
[2K
| Adam | epoch: 010 | loss: 0.49691 - acc: 0.7595 -- iter: 1632/2395
[A[ATraining Step: 727  | total loss: [1m[32m0.51217[0m[0m | time: 665.566s
[2K
| Adam | epoch: 010 | loss: 0.51217 - acc: 0.7523 -- iter: 1664/2395
[A[ATraining Step: 728  | total loss: [1m[32m0.49319[0m[0m | time: 678.606s
[2K
| Adam | epoch: 010 | loss: 0.49319 - acc: 0.7646 -- iter: 1696/2395
[A[ATraining Step: 729  | total loss: [1m[32m0.48223[0m[0m | time: 691.519s
[2K
| Adam | epoch: 010 | loss: 0.48223 - acc: 0.7694 -- iter: 1728/2395
[A[ATraining Step: 730  | total loss: [1m[32m0.47736[0m[0m | time: 704.373s
[2K
| Adam | epoch: 010 | loss: 0.47736 - acc: 0.7706 -- iter: 1760/2395
[A[ATraining Step: 731  | total loss: [1m[32m0.45894[0m[0m | time: 717.656s
[2K
| Adam | epoch: 010 | loss: 0.45894 - acc: 0.7810 -- iter: 1792/2395
[A[ATraining Step: 732  | total loss: [1m[32m0.45758[0m[0m | time: 730.688s
[2K
| Adam | epoch: 010 | loss: 0.45758 - acc: 0.7873 -- iter: 1824/2395
[A[ATraining Step: 733  | total loss: [1m[32m0.46580[0m[0m | time: 743.253s
[2K
| Adam | epoch: 010 | loss: 0.46580 - acc: 0.7867 -- iter: 1856/2395
[A[ATraining Step: 734  | total loss: [1m[32m0.44683[0m[0m | time: 756.150s
[2K
| Adam | epoch: 010 | loss: 0.44683 - acc: 0.8018 -- iter: 1888/2395
[A[ATraining Step: 735  | total loss: [1m[32m0.44880[0m[0m | time: 768.950s
[2K
| Adam | epoch: 010 | loss: 0.44880 - acc: 0.7966 -- iter: 1920/2395
[A[ATraining Step: 736  | total loss: [1m[32m0.43493[0m[0m | time: 781.842s
[2K
| Adam | epoch: 010 | loss: 0.43493 - acc: 0.8044 -- iter: 1952/2395
[A[ATraining Step: 737  | total loss: [1m[32m0.41265[0m[0m | time: 794.683s
[2K
| Adam | epoch: 010 | loss: 0.41265 - acc: 0.8240 -- iter: 1984/2395
[A[ATraining Step: 738  | total loss: [1m[32m0.42249[0m[0m | time: 807.542s
[2K
| Adam | epoch: 010 | loss: 0.42249 - acc: 0.8166 -- iter: 2016/2395
[A[ATraining Step: 739  | total loss: [1m[32m0.43455[0m[0m | time: 820.581s
[2K
| Adam | epoch: 010 | loss: 0.43455 - acc: 0.8130 -- iter: 2048/2395
[A[ATraining Step: 740  | total loss: [1m[32m0.43728[0m[0m | time: 833.151s
[2K
| Adam | epoch: 010 | loss: 0.43728 - acc: 0.8130 -- iter: 2080/2395
[A[ATraining Step: 741  | total loss: [1m[32m0.42416[0m[0m | time: 846.119s
[2K
| Adam | epoch: 010 | loss: 0.42416 - acc: 0.8192 -- iter: 2112/2395
[A[ATraining Step: 742  | total loss: [1m[32m0.42238[0m[0m | time: 859.035s
[2K
| Adam | epoch: 010 | loss: 0.42238 - acc: 0.8248 -- iter: 2144/2395
[A[ATraining Step: 743  | total loss: [1m[32m0.42133[0m[0m | time: 871.816s
[2K
| Adam | epoch: 010 | loss: 0.42133 - acc: 0.8173 -- iter: 2176/2395
[A[ATraining Step: 744  | total loss: [1m[32m0.46321[0m[0m | time: 885.044s
[2K
| Adam | epoch: 010 | loss: 0.46321 - acc: 0.7918 -- iter: 2208/2395
[A[ATraining Step: 745  | total loss: [1m[32m0.45030[0m[0m | time: 898.525s
[2K
| Adam | epoch: 010 | loss: 0.45030 - acc: 0.7970 -- iter: 2240/2395
[A[ATraining Step: 746  | total loss: [1m[32m0.46262[0m[0m | time: 911.719s
[2K
| Adam | epoch: 010 | loss: 0.46262 - acc: 0.7861 -- iter: 2272/2395
[A[ATraining Step: 747  | total loss: [1m[32m0.45986[0m[0m | time: 924.694s
[2K
| Adam | epoch: 010 | loss: 0.45986 - acc: 0.7887 -- iter: 2304/2395
[A[ATraining Step: 748  | total loss: [1m[32m0.46720[0m[0m | time: 938.033s
[2K
| Adam | epoch: 010 | loss: 0.46720 - acc: 0.7848 -- iter: 2336/2395
[A[ATraining Step: 749  | total loss: [1m[32m0.46161[0m[0m | time: 950.904s
[2K
| Adam | epoch: 010 | loss: 0.46161 - acc: 0.7876 -- iter: 2368/2395
[A[ATraining Step: 750  | total loss: [1m[32m0.47201[0m[0m | time: 1018.189s
[2K
| Adam | epoch: 010 | loss: 0.47201 - acc: 0.7745 | val_loss: 1.15945 - val_acc: 0.5461 -- iter: 2395/2395
--
Training Step: 751  | total loss: [1m[32m0.46315[0m[0m | time: 13.287s
[2K
| Adam | epoch: 011 | loss: 0.46315 - acc: 0.7814 -- iter: 0032/2395
[A[ATraining Step: 752  | total loss: [1m[32m0.45297[0m[0m | time: 26.304s
[2K
| Adam | epoch: 011 | loss: 0.45297 - acc: 0.7939 -- iter: 0064/2395
[A[ATraining Step: 753  | total loss: [1m[32m0.44776[0m[0m | time: 38.935s
[2K
| Adam | epoch: 011 | loss: 0.44776 - acc: 0.7957 -- iter: 0096/2395
[A[ATraining Step: 754  | total loss: [1m[32m0.44384[0m[0m | time: 51.404s
[2K
| Adam | epoch: 011 | loss: 0.44384 - acc: 0.7974 -- iter: 0128/2395
[A[ATraining Step: 755  | total loss: [1m[32m0.43526[0m[0m | time: 64.154s
[2K
| Adam | epoch: 011 | loss: 0.43526 - acc: 0.8052 -- iter: 0160/2395
[A[ATraining Step: 756  | total loss: [1m[32m0.42372[0m[0m | time: 77.311s
[2K
| Adam | epoch: 011 | loss: 0.42372 - acc: 0.8090 -- iter: 0192/2395
[A[ATraining Step: 757  | total loss: [1m[32m0.41053[0m[0m | time: 91.206s
[2K
| Adam | epoch: 011 | loss: 0.41053 - acc: 0.8156 -- iter: 0224/2395
[A[ATraining Step: 758  | total loss: [1m[32m0.40668[0m[0m | time: 104.175s
[2K
| Adam | epoch: 011 | loss: 0.40668 - acc: 0.8184 -- iter: 0256/2395
[A[ATraining Step: 759  | total loss: [1m[32m0.40181[0m[0m | time: 115.535s
[2K
| Adam | epoch: 011 | loss: 0.40181 - acc: 0.8178 -- iter: 0288/2395
[A[ATraining Step: 760  | total loss: [1m[32m0.41578[0m[0m | time: 126.839s
[2K
| Adam | epoch: 011 | loss: 0.41578 - acc: 0.8027 -- iter: 0320/2395
[A[ATraining Step: 761  | total loss: [1m[32m0.41234[0m[0m | time: 140.049s
[2K
| Adam | epoch: 011 | loss: 0.41234 - acc: 0.7965 -- iter: 0352/2395
[A[ATraining Step: 762  | total loss: [1m[32m0.44628[0m[0m | time: 152.897s
[2K
| Adam | epoch: 011 | loss: 0.44628 - acc: 0.7919 -- iter: 0384/2395
[A[ATraining Step: 763  | total loss: [1m[32m0.46199[0m[0m | time: 165.934s
[2K
| Adam | epoch: 011 | loss: 0.46199 - acc: 0.7814 -- iter: 0416/2395
[A[ATraining Step: 764  | total loss: [1m[32m0.45125[0m[0m | time: 178.948s
[2K
| Adam | epoch: 011 | loss: 0.45125 - acc: 0.7877 -- iter: 0448/2395
[A[ATraining Step: 765  | total loss: [1m[32m0.43733[0m[0m | time: 191.745s
[2K
| Adam | epoch: 011 | loss: 0.43733 - acc: 0.8027 -- iter: 0480/2395
[A[ATraining Step: 766  | total loss: [1m[32m0.44476[0m[0m | time: 204.612s
[2K
| Adam | epoch: 011 | loss: 0.44476 - acc: 0.7943 -- iter: 0512/2395
[A[ATraining Step: 767  | total loss: [1m[32m0.43838[0m[0m | time: 217.713s
[2K
| Adam | epoch: 011 | loss: 0.43838 - acc: 0.7961 -- iter: 0544/2395
[A[ATraining Step: 768  | total loss: [1m[32m0.43328[0m[0m | time: 230.384s
[2K
| Adam | epoch: 011 | loss: 0.43328 - acc: 0.8009 -- iter: 0576/2395
[A[ATraining Step: 769  | total loss: [1m[32m0.42665[0m[0m | time: 242.490s
[2K
| Adam | epoch: 011 | loss: 0.42665 - acc: 0.8051 -- iter: 0608/2395
[A[ATraining Step: 770  | total loss: [1m[32m0.44890[0m[0m | time: 255.864s
[2K
| Adam | epoch: 011 | loss: 0.44890 - acc: 0.7996 -- iter: 0640/2395
[A[ATraining Step: 771  | total loss: [1m[32m0.45988[0m[0m | time: 268.532s
[2K
| Adam | epoch: 011 | loss: 0.45988 - acc: 0.7978 -- iter: 0672/2395
[A[ATraining Step: 772  | total loss: [1m[32m0.44501[0m[0m | time: 281.159s
[2K
| Adam | epoch: 011 | loss: 0.44501 - acc: 0.8024 -- iter: 0704/2395
[A[ATraining Step: 773  | total loss: [1m[32m0.45788[0m[0m | time: 293.894s
[2K
| Adam | epoch: 011 | loss: 0.45788 - acc: 0.8003 -- iter: 0736/2395
[A[ATraining Step: 774  | total loss: [1m[32m0.45484[0m[0m | time: 306.848s
[2K
| Adam | epoch: 011 | loss: 0.45484 - acc: 0.8015 -- iter: 0768/2395
[A[ATraining Step: 775  | total loss: [1m[32m0.44623[0m[0m | time: 319.598s
[2K
| Adam | epoch: 011 | loss: 0.44623 - acc: 0.8057 -- iter: 0800/2395
[A[ATraining Step: 776  | total loss: [1m[32m0.44296[0m[0m | time: 332.518s
[2K
| Adam | epoch: 011 | loss: 0.44296 - acc: 0.8126 -- iter: 0832/2395
[A[ATraining Step: 777  | total loss: [1m[32m0.44201[0m[0m | time: 345.419s
[2K
| Adam | epoch: 011 | loss: 0.44201 - acc: 0.8064 -- iter: 0864/2395
[A[ATraining Step: 778  | total loss: [1m[32m0.44466[0m[0m | time: 358.145s
[2K
| Adam | epoch: 011 | loss: 0.44466 - acc: 0.8101 -- iter: 0896/2395
[A[ATraining Step: 779  | total loss: [1m[32m0.43944[0m[0m | time: 370.866s
[2K
| Adam | epoch: 011 | loss: 0.43944 - acc: 0.8104 -- iter: 0928/2395
[A[ATraining Step: 780  | total loss: [1m[32m0.44462[0m[0m | time: 386.762s
[2K
| Adam | epoch: 011 | loss: 0.44462 - acc: 0.8074 -- iter: 0960/2395
[A[ATraining Step: 781  | total loss: [1m[32m0.43665[0m[0m | time: 399.816s
[2K
| Adam | epoch: 011 | loss: 0.43665 - acc: 0.8142 -- iter: 0992/2395
[A[ATraining Step: 782  | total loss: [1m[32m0.43045[0m[0m | time: 412.875s
[2K
| Adam | epoch: 011 | loss: 0.43045 - acc: 0.8078 -- iter: 1024/2395
[A[ATraining Step: 783  | total loss: [1m[32m0.43434[0m[0m | time: 425.837s
[2K
| Adam | epoch: 011 | loss: 0.43434 - acc: 0.7958 -- iter: 1056/2395
[A[ATraining Step: 784  | total loss: [1m[32m0.43904[0m[0m | time: 439.534s
[2K
| Adam | epoch: 011 | loss: 0.43904 - acc: 0.7943 -- iter: 1088/2395
[A[ATraining Step: 785  | total loss: [1m[32m0.45594[0m[0m | time: 453.620s
[2K
| Adam | epoch: 011 | loss: 0.45594 - acc: 0.7805 -- iter: 1120/2395
[A[ATraining Step: 786  | total loss: [1m[32m0.45492[0m[0m | time: 468.138s
[2K
| Adam | epoch: 011 | loss: 0.45492 - acc: 0.7837 -- iter: 1152/2395
[A[ATraining Step: 787  | total loss: [1m[32m0.45334[0m[0m | time: 482.574s
[2K
| Adam | epoch: 011 | loss: 0.45334 - acc: 0.7866 -- iter: 1184/2395
[A[ATraining Step: 788  | total loss: [1m[32m0.45655[0m[0m | time: 497.229s
[2K
| Adam | epoch: 011 | loss: 0.45655 - acc: 0.7829 -- iter: 1216/2395
[A[ATraining Step: 789  | total loss: [1m[32m0.47001[0m[0m | time: 507.722s
[2K
| Adam | epoch: 011 | loss: 0.47001 - acc: 0.7796 -- iter: 1248/2395
[A[ATraining Step: 790  | total loss: [1m[32m0.47727[0m[0m | time: 516.570s
[2K
| Adam | epoch: 011 | loss: 0.47727 - acc: 0.7735 -- iter: 1280/2395
[A[ATraining Step: 791  | total loss: [1m[32m0.46866[0m[0m | time: 526.699s
[2K
| Adam | epoch: 011 | loss: 0.46866 - acc: 0.7806 -- iter: 1312/2395
[A[ATraining Step: 792  | total loss: [1m[32m0.45629[0m[0m | time: 539.544s
[2K
| Adam | epoch: 011 | loss: 0.45629 - acc: 0.7838 -- iter: 1344/2395
[A[ATraining Step: 793  | total loss: [1m[32m0.43266[0m[0m | time: 552.451s
[2K
| Adam | epoch: 011 | loss: 0.43266 - acc: 0.7991 -- iter: 1376/2395
[A[ATraining Step: 794  | total loss: [1m[32m0.43060[0m[0m | time: 564.964s
[2K
| Adam | epoch: 011 | loss: 0.43060 - acc: 0.7911 -- iter: 1408/2395
[A[ATraining Step: 795  | total loss: [1m[32m0.42781[0m[0m | time: 578.059s
[2K
| Adam | epoch: 011 | loss: 0.42781 - acc: 0.7932 -- iter: 1440/2395
[A[ATraining Step: 796  | total loss: [1m[32m0.43066[0m[0m | time: 590.652s
[2K
| Adam | epoch: 011 | loss: 0.43066 - acc: 0.7920 -- iter: 1472/2395
[A[ATraining Step: 797  | total loss: [1m[32m0.45707[0m[0m | time: 603.453s
[2K
| Adam | epoch: 011 | loss: 0.45707 - acc: 0.7722 -- iter: 1504/2395
[A[ATraining Step: 798  | total loss: [1m[32m0.46111[0m[0m | time: 616.106s
[2K
| Adam | epoch: 011 | loss: 0.46111 - acc: 0.7669 -- iter: 1536/2395
[A[ATraining Step: 799  | total loss: [1m[32m0.46704[0m[0m | time: 629.006s
[2K
| Adam | epoch: 011 | loss: 0.46704 - acc: 0.7745 -- iter: 1568/2395
[A[ATraining Step: 800  | total loss: [1m[32m0.46170[0m[0m | time: 696.511s
[2K
| Adam | epoch: 011 | loss: 0.46170 - acc: 0.7721 | val_loss: 1.30113 - val_acc: 0.5113 -- iter: 1600/2395
--
Training Step: 801  | total loss: [1m[32m0.46461[0m[0m | time: 709.651s
[2K
| Adam | epoch: 011 | loss: 0.46461 - acc: 0.7699 -- iter: 1632/2395
[A[ATraining Step: 802  | total loss: [1m[32m0.44643[0m[0m | time: 722.566s
[2K
| Adam | epoch: 011 | loss: 0.44643 - acc: 0.7835 -- iter: 1664/2395
[A[ATraining Step: 803  | total loss: [1m[32m0.44611[0m[0m | time: 737.502s
[2K
| Adam | epoch: 011 | loss: 0.44611 - acc: 0.7864 -- iter: 1696/2395
[A[ATraining Step: 804  | total loss: [1m[32m0.42909[0m[0m | time: 751.820s
[2K
| Adam | epoch: 011 | loss: 0.42909 - acc: 0.7984 -- iter: 1728/2395
[A[ATraining Step: 805  | total loss: [1m[32m0.41626[0m[0m | time: 766.701s
[2K
| Adam | epoch: 011 | loss: 0.41626 - acc: 0.8029 -- iter: 1760/2395
[A[ATraining Step: 806  | total loss: [1m[32m0.40066[0m[0m | time: 780.760s
[2K
| Adam | epoch: 011 | loss: 0.40066 - acc: 0.8101 -- iter: 1792/2395
[A[ATraining Step: 807  | total loss: [1m[32m0.40195[0m[0m | time: 795.597s
[2K
| Adam | epoch: 011 | loss: 0.40195 - acc: 0.8104 -- iter: 1824/2395
[A[ATraining Step: 808  | total loss: [1m[32m0.39372[0m[0m | time: 804.363s
[2K
| Adam | epoch: 011 | loss: 0.39372 - acc: 0.8168 -- iter: 1856/2395
[A[ATraining Step: 809  | total loss: [1m[32m0.37542[0m[0m | time: 813.259s
[2K
| Adam | epoch: 011 | loss: 0.37542 - acc: 0.8258 -- iter: 1888/2395
[A[ATraining Step: 810  | total loss: [1m[32m0.37167[0m[0m | time: 822.743s
[2K
| Adam | epoch: 011 | loss: 0.37167 - acc: 0.8276 -- iter: 1920/2395
[A[ATraining Step: 811  | total loss: [1m[32m0.36639[0m[0m | time: 835.814s
[2K
| Adam | epoch: 011 | loss: 0.36639 - acc: 0.8292 -- iter: 1952/2395
[A[ATraining Step: 812  | total loss: [1m[32m0.36075[0m[0m | time: 848.742s
[2K
| Adam | epoch: 011 | loss: 0.36075 - acc: 0.8307 -- iter: 1984/2395
[A[ATraining Step: 813  | total loss: [1m[32m0.36652[0m[0m | time: 861.783s
[2K
| Adam | epoch: 011 | loss: 0.36652 - acc: 0.8382 -- iter: 2016/2395
[A[ATraining Step: 814  | total loss: [1m[32m0.35117[0m[0m | time: 874.578s
[2K
| Adam | epoch: 011 | loss: 0.35117 - acc: 0.8481 -- iter: 2048/2395
[A[ATraining Step: 815  | total loss: [1m[32m0.36252[0m[0m | time: 887.575s
[2K
| Adam | epoch: 011 | loss: 0.36252 - acc: 0.8446 -- iter: 2080/2395
[A[ATraining Step: 816  | total loss: [1m[32m0.35369[0m[0m | time: 900.310s
[2K
| Adam | epoch: 011 | loss: 0.35369 - acc: 0.8476 -- iter: 2112/2395
[A[ATraining Step: 817  | total loss: [1m[32m0.36211[0m[0m | time: 912.920s
[2K
| Adam | epoch: 011 | loss: 0.36211 - acc: 0.8410 -- iter: 2144/2395
[A[ATraining Step: 818  | total loss: [1m[32m0.35586[0m[0m | time: 926.238s
[2K
| Adam | epoch: 011 | loss: 0.35586 - acc: 0.8381 -- iter: 2176/2395
[A[ATraining Step: 819  | total loss: [1m[32m0.35996[0m[0m | time: 939.379s
[2K
| Adam | epoch: 011 | loss: 0.35996 - acc: 0.8356 -- iter: 2208/2395
[A[ATraining Step: 820  | total loss: [1m[32m0.35702[0m[0m | time: 952.170s
[2K
| Adam | epoch: 011 | loss: 0.35702 - acc: 0.8333 -- iter: 2240/2395
[A[ATraining Step: 821  | total loss: [1m[32m0.35842[0m[0m | time: 965.225s
[2K
| Adam | epoch: 011 | loss: 0.35842 - acc: 0.8343 -- iter: 2272/2395
[A[ATraining Step: 822  | total loss: [1m[32m0.35835[0m[0m | time: 978.277s
[2K
| Adam | epoch: 011 | loss: 0.35835 - acc: 0.8259 -- iter: 2304/2395
[A[ATraining Step: 823  | total loss: [1m[32m0.35789[0m[0m | time: 991.562s
[2K
| Adam | epoch: 011 | loss: 0.35789 - acc: 0.8277 -- iter: 2336/2395
[A[ATraining Step: 824  | total loss: [1m[32m0.36269[0m[0m | time: 1005.003s
[2K
| Adam | epoch: 011 | loss: 0.36269 - acc: 0.8262 -- iter: 2368/2395
[A[ATraining Step: 825  | total loss: [1m[32m0.35961[0m[0m | time: 1074.943s
[2K
| Adam | epoch: 011 | loss: 0.35961 - acc: 0.8279 | val_loss: 0.87723 - val_acc: 0.6569 -- iter: 2395/2395
--
Training Step: 826  | total loss: [1m[32m0.35166[0m[0m | time: 13.003s
[2K
| Adam | epoch: 012 | loss: 0.35166 - acc: 0.8357 -- iter: 0032/2395
[A[ATraining Step: 827  | total loss: [1m[32m0.33454[0m[0m | time: 26.101s
[2K
| Adam | epoch: 012 | loss: 0.33454 - acc: 0.8490 -- iter: 0064/2395
[A[ATraining Step: 828  | total loss: [1m[32m0.32243[0m[0m | time: 39.079s
[2K
| Adam | epoch: 012 | loss: 0.32243 - acc: 0.8548 -- iter: 0096/2395
[A[ATraining Step: 829  | total loss: [1m[32m0.32111[0m[0m | time: 52.559s
[2K
| Adam | epoch: 012 | loss: 0.32111 - acc: 0.8568 -- iter: 0128/2395
[A[ATraining Step: 830  | total loss: [1m[32m0.32929[0m[0m | time: 65.306s
[2K
| Adam | epoch: 012 | loss: 0.32929 - acc: 0.8524 -- iter: 0160/2395
[A[ATraining Step: 831  | total loss: [1m[32m0.32414[0m[0m | time: 78.401s
[2K
| Adam | epoch: 012 | loss: 0.32414 - acc: 0.8546 -- iter: 0192/2395
[A[ATraining Step: 832  | total loss: [1m[32m0.34318[0m[0m | time: 91.807s
[2K
| Adam | epoch: 012 | loss: 0.34318 - acc: 0.8410 -- iter: 0224/2395
[A[ATraining Step: 833  | total loss: [1m[32m0.34258[0m[0m | time: 104.504s
[2K
| Adam | epoch: 012 | loss: 0.34258 - acc: 0.8351 -- iter: 0256/2395
[A[ATraining Step: 834  | total loss: [1m[32m0.34391[0m[0m | time: 117.796s
[2K
| Adam | epoch: 012 | loss: 0.34391 - acc: 0.8422 -- iter: 0288/2395
[A[ATraining Step: 835  | total loss: [1m[32m0.35772[0m[0m | time: 129.402s
[2K
| Adam | epoch: 012 | loss: 0.35772 - acc: 0.8392 -- iter: 0320/2395
[A[ATraining Step: 836  | total loss: [1m[32m0.34041[0m[0m | time: 140.966s
[2K
| Adam | epoch: 012 | loss: 0.34041 - acc: 0.8516 -- iter: 0352/2395
[A[ATraining Step: 837  | total loss: [1m[32m0.31751[0m[0m | time: 154.248s
[2K
| Adam | epoch: 012 | loss: 0.31751 - acc: 0.8664 -- iter: 0384/2395
[A[ATraining Step: 838  | total loss: [1m[32m0.31219[0m[0m | time: 167.362s
[2K
| Adam | epoch: 012 | loss: 0.31219 - acc: 0.8673 -- iter: 0416/2395
[A[ATraining Step: 839  | total loss: [1m[32m0.31560[0m[0m | time: 180.451s
[2K
| Adam | epoch: 012 | loss: 0.31560 - acc: 0.8587 -- iter: 0448/2395
[A[ATraining Step: 840  | total loss: [1m[32m0.31474[0m[0m | time: 193.179s
[2K
| Adam | epoch: 012 | loss: 0.31474 - acc: 0.8634 -- iter: 0480/2395
[A[ATraining Step: 841  | total loss: [1m[32m0.34196[0m[0m | time: 206.320s
[2K
| Adam | epoch: 012 | loss: 0.34196 - acc: 0.8521 -- iter: 0512/2395
[A[ATraining Step: 842  | total loss: [1m[32m0.36298[0m[0m | time: 218.925s
[2K
| Adam | epoch: 012 | loss: 0.36298 - acc: 0.8356 -- iter: 0544/2395
[A[ATraining Step: 843  | total loss: [1m[32m0.37943[0m[0m | time: 232.307s
[2K
| Adam | epoch: 012 | loss: 0.37943 - acc: 0.8239 -- iter: 0576/2395
[A[ATraining Step: 844  | total loss: [1m[32m0.38755[0m[0m | time: 245.565s
[2K
| Adam | epoch: 012 | loss: 0.38755 - acc: 0.8166 -- iter: 0608/2395
[A[ATraining Step: 845  | total loss: [1m[32m0.40439[0m[0m | time: 258.371s
[2K
| Adam | epoch: 012 | loss: 0.40439 - acc: 0.8099 -- iter: 0640/2395
[A[ATraining Step: 846  | total loss: [1m[32m0.41031[0m[0m | time: 271.662s
[2K
| Adam | epoch: 012 | loss: 0.41031 - acc: 0.8102 -- iter: 0672/2395
[A[ATraining Step: 847  | total loss: [1m[32m0.39974[0m[0m | time: 285.070s
[2K
| Adam | epoch: 012 | loss: 0.39974 - acc: 0.8166 -- iter: 0704/2395
[A[ATraining Step: 848  | total loss: [1m[32m0.39244[0m[0m | time: 298.076s
[2K
| Adam | epoch: 012 | loss: 0.39244 - acc: 0.8256 -- iter: 0736/2395
[A[ATraining Step: 849  | total loss: [1m[32m0.39316[0m[0m | time: 311.264s
[2K
| Adam | epoch: 012 | loss: 0.39316 - acc: 0.8274 -- iter: 0768/2395
[A[ATraining Step: 850  | total loss: [1m[32m0.38645[0m[0m | time: 324.019s
[2K
| Adam | epoch: 012 | loss: 0.38645 - acc: 0.8322 -- iter: 0800/2395
[A[ATraining Step: 851  | total loss: [1m[32m0.37606[0m[0m | time: 337.101s
[2K
| Adam | epoch: 012 | loss: 0.37606 - acc: 0.8333 -- iter: 0832/2395
[A[ATraining Step: 852  | total loss: [1m[32m0.38616[0m[0m | time: 350.498s
[2K
| Adam | epoch: 012 | loss: 0.38616 - acc: 0.8281 -- iter: 0864/2395
[A[ATraining Step: 853  | total loss: [1m[32m0.37712[0m[0m | time: 363.327s
[2K
| Adam | epoch: 012 | loss: 0.37712 - acc: 0.8359 -- iter: 0896/2395
[A[ATraining Step: 854  | total loss: [1m[32m0.38422[0m[0m | time: 376.278s
[2K
| Adam | epoch: 012 | loss: 0.38422 - acc: 0.8336 -- iter: 0928/2395
[A[ATraining Step: 855  | total loss: [1m[32m0.38085[0m[0m | time: 389.394s
[2K
| Adam | epoch: 012 | loss: 0.38085 - acc: 0.8377 -- iter: 0960/2395
[A[ATraining Step: 856  | total loss: [1m[32m0.38541[0m[0m | time: 402.704s
[2K
| Adam | epoch: 012 | loss: 0.38541 - acc: 0.8196 -- iter: 0992/2395
[A[ATraining Step: 857  | total loss: [1m[32m0.39890[0m[0m | time: 416.580s
[2K
| Adam | epoch: 012 | loss: 0.39890 - acc: 0.8126 -- iter: 1024/2395
[A[ATraining Step: 858  | total loss: [1m[32m0.39942[0m[0m | time: 429.244s
[2K
| Adam | epoch: 012 | loss: 0.39942 - acc: 0.8126 -- iter: 1056/2395
[A[ATraining Step: 859  | total loss: [1m[32m0.40493[0m[0m | time: 442.110s
[2K
| Adam | epoch: 012 | loss: 0.40493 - acc: 0.8064 -- iter: 1088/2395
[A[ATraining Step: 860  | total loss: [1m[32m0.39819[0m[0m | time: 455.119s
[2K
| Adam | epoch: 012 | loss: 0.39819 - acc: 0.8101 -- iter: 1120/2395
[A[ATraining Step: 861  | total loss: [1m[32m0.40344[0m[0m | time: 468.380s
[2K
| Adam | epoch: 012 | loss: 0.40344 - acc: 0.8135 -- iter: 1152/2395
[A[ATraining Step: 862  | total loss: [1m[32m0.39590[0m[0m | time: 481.517s
[2K
| Adam | epoch: 012 | loss: 0.39590 - acc: 0.8196 -- iter: 1184/2395
[A[ATraining Step: 863  | total loss: [1m[32m0.40573[0m[0m | time: 494.919s
[2K
| Adam | epoch: 012 | loss: 0.40573 - acc: 0.8158 -- iter: 1216/2395
[A[ATraining Step: 864  | total loss: [1m[32m0.42042[0m[0m | time: 507.995s
[2K
| Adam | epoch: 012 | loss: 0.42042 - acc: 0.8092 -- iter: 1248/2395
[A[ATraining Step: 865  | total loss: [1m[32m0.40377[0m[0m | time: 521.089s
[2K
| Adam | epoch: 012 | loss: 0.40377 - acc: 0.8252 -- iter: 1280/2395
[A[ATraining Step: 866  | total loss: [1m[32m0.41191[0m[0m | time: 534.094s
[2K
| Adam | epoch: 012 | loss: 0.41191 - acc: 0.8176 -- iter: 1312/2395
[A[ATraining Step: 867  | total loss: [1m[32m0.41408[0m[0m | time: 554.991s
[2K
| Adam | epoch: 012 | loss: 0.41408 - acc: 0.8171 -- iter: 1344/2395
[A[ATraining Step: 868  | total loss: [1m[32m0.40961[0m[0m | time: 568.323s
[2K
| Adam | epoch: 012 | loss: 0.40961 - acc: 0.8073 -- iter: 1376/2395
[A[ATraining Step: 869  | total loss: [1m[32m0.42496[0m[0m | time: 581.541s
[2K
| Adam | epoch: 012 | loss: 0.42496 - acc: 0.8016 -- iter: 1408/2395
[A[ATraining Step: 870  | total loss: [1m[32m0.43223[0m[0m | time: 594.703s
[2K
| Adam | epoch: 012 | loss: 0.43223 - acc: 0.7995 -- iter: 1440/2395
[A[ATraining Step: 871  | total loss: [1m[32m0.42019[0m[0m | time: 608.235s
[2K
| Adam | epoch: 012 | loss: 0.42019 - acc: 0.8071 -- iter: 1472/2395
[A[ATraining Step: 872  | total loss: [1m[32m0.43441[0m[0m | time: 621.173s
[2K
| Adam | epoch: 012 | loss: 0.43441 - acc: 0.7982 -- iter: 1504/2395
[A[ATraining Step: 873  | total loss: [1m[32m0.42883[0m[0m | time: 634.306s
[2K
| Adam | epoch: 012 | loss: 0.42883 - acc: 0.7997 -- iter: 1536/2395
[A[ATraining Step: 874  | total loss: [1m[32m0.42471[0m[0m | time: 647.643s
[2K
| Adam | epoch: 012 | loss: 0.42471 - acc: 0.8010 -- iter: 1568/2395
[A[ATraining Step: 875  | total loss: [1m[32m0.41741[0m[0m | time: 660.735s
[2K
| Adam | epoch: 012 | loss: 0.41741 - acc: 0.8021 -- iter: 1600/2395
[A[ATraining Step: 876  | total loss: [1m[32m0.40350[0m[0m | time: 674.168s
[2K
| Adam | epoch: 012 | loss: 0.40350 - acc: 0.8063 -- iter: 1632/2395
[A[ATraining Step: 877  | total loss: [1m[32m0.38642[0m[0m | time: 686.792s
[2K
| Adam | epoch: 012 | loss: 0.38642 - acc: 0.8194 -- iter: 1664/2395
[A[ATraining Step: 878  | total loss: [1m[32m0.37465[0m[0m | time: 699.941s
[2K
| Adam | epoch: 012 | loss: 0.37465 - acc: 0.8250 -- iter: 1696/2395
[A[ATraining Step: 879  | total loss: [1m[32m0.35517[0m[0m | time: 713.406s
[2K
| Adam | epoch: 012 | loss: 0.35517 - acc: 0.8393 -- iter: 1728/2395
[A[ATraining Step: 880  | total loss: [1m[32m0.33935[0m[0m | time: 726.357s
[2K
| Adam | epoch: 012 | loss: 0.33935 - acc: 0.8492 -- iter: 1760/2395
[A[ATraining Step: 881  | total loss: [1m[32m0.33389[0m[0m | time: 739.988s
[2K
| Adam | epoch: 012 | loss: 0.33389 - acc: 0.8517 -- iter: 1792/2395
[A[ATraining Step: 882  | total loss: [1m[32m0.33041[0m[0m | time: 753.306s
[2K
| Adam | epoch: 012 | loss: 0.33041 - acc: 0.8572 -- iter: 1824/2395
[A[ATraining Step: 883  | total loss: [1m[32m0.32652[0m[0m | time: 766.530s
[2K
| Adam | epoch: 012 | loss: 0.32652 - acc: 0.8590 -- iter: 1856/2395
[A[ATraining Step: 884  | total loss: [1m[32m0.33929[0m[0m | time: 780.023s
[2K
| Adam | epoch: 012 | loss: 0.33929 - acc: 0.8543 -- iter: 1888/2395
[A[ATraining Step: 885  | total loss: [1m[32m0.34514[0m[0m | time: 793.097s
[2K
| Adam | epoch: 012 | loss: 0.34514 - acc: 0.8501 -- iter: 1920/2395
[A[ATraining Step: 886  | total loss: [1m[32m0.34612[0m[0m | time: 806.425s
[2K
| Adam | epoch: 012 | loss: 0.34612 - acc: 0.8495 -- iter: 1952/2395
[A[ATraining Step: 887  | total loss: [1m[32m0.33251[0m[0m | time: 819.802s
[2K
| Adam | epoch: 012 | loss: 0.33251 - acc: 0.8583 -- iter: 1984/2395
[A[ATraining Step: 888  | total loss: [1m[32m0.31977[0m[0m | time: 833.390s
[2K
| Adam | epoch: 012 | loss: 0.31977 - acc: 0.8631 -- iter: 2016/2395
[A[ATraining Step: 889  | total loss: [1m[32m0.30135[0m[0m | time: 846.629s
[2K
| Adam | epoch: 012 | loss: 0.30135 - acc: 0.8737 -- iter: 2048/2395
[A[ATraining Step: 890  | total loss: [1m[32m0.29865[0m[0m | time: 859.876s
[2K
| Adam | epoch: 012 | loss: 0.29865 - acc: 0.8738 -- iter: 2080/2395
[A[ATraining Step: 891  | total loss: [1m[32m0.29275[0m[0m | time: 873.339s
[2K
| Adam | epoch: 012 | loss: 0.29275 - acc: 0.8770 -- iter: 2112/2395
[A[ATraining Step: 892  | total loss: [1m[32m0.28494[0m[0m | time: 886.471s
[2K
| Adam | epoch: 012 | loss: 0.28494 - acc: 0.8831 -- iter: 2144/2395
[A[ATraining Step: 893  | total loss: [1m[32m0.28510[0m[0m | time: 899.628s
[2K
| Adam | epoch: 012 | loss: 0.28510 - acc: 0.8760 -- iter: 2176/2395
[A[ATraining Step: 894  | total loss: [1m[32m0.28125[0m[0m | time: 912.451s
[2K
| Adam | epoch: 012 | loss: 0.28125 - acc: 0.8790 -- iter: 2208/2395
[A[ATraining Step: 895  | total loss: [1m[32m0.26877[0m[0m | time: 925.794s
[2K
| Adam | epoch: 012 | loss: 0.26877 - acc: 0.8880 -- iter: 2240/2395
[A[ATraining Step: 896  | total loss: [1m[32m0.27498[0m[0m | time: 939.128s
[2K
| Adam | epoch: 012 | loss: 0.27498 - acc: 0.8867 -- iter: 2272/2395
[A[ATraining Step: 897  | total loss: [1m[32m0.27835[0m[0m | time: 952.069s
[2K
| Adam | epoch: 012 | loss: 0.27835 - acc: 0.8887 -- iter: 2304/2395
[A[ATraining Step: 898  | total loss: [1m[32m0.27782[0m[0m | time: 965.109s
[2K
| Adam | epoch: 012 | loss: 0.27782 - acc: 0.8842 -- iter: 2336/2395
[A[ATraining Step: 899  | total loss: [1m[32m0.27669[0m[0m | time: 977.848s
[2K
| Adam | epoch: 012 | loss: 0.27669 - acc: 0.8864 -- iter: 2368/2395
[A[ATraining Step: 900  | total loss: [1m[32m0.27261[0m[0m | time: 1047.498s
[2K
| Adam | epoch: 012 | loss: 0.27261 - acc: 0.8884 | val_loss: 0.70566 - val_acc: 0.7170 -- iter: 2395/2395
--
Training Step: 901  | total loss: [1m[32m0.29394[0m[0m | time: 15.192s
[2K
| Adam | epoch: 013 | loss: 0.29394 - acc: 0.8839 -- iter: 0032/2395
[A[ATraining Step: 902  | total loss: [1m[32m0.29553[0m[0m | time: 29.293s
[2K
| Adam | epoch: 013 | loss: 0.29553 - acc: 0.8861 -- iter: 0064/2395
[A[ATraining Step: 903  | total loss: [1m[32m0.30194[0m[0m | time: 38.629s
[2K
| Adam | epoch: 013 | loss: 0.30194 - acc: 0.8819 -- iter: 0096/2395
[A[ATraining Step: 904  | total loss: [1m[32m0.29453[0m[0m | time: 47.753s
[2K
| Adam | epoch: 013 | loss: 0.29453 - acc: 0.8812 -- iter: 0128/2395
[A[ATraining Step: 905  | total loss: [1m[32m0.29845[0m[0m | time: 60.873s
[2K
| Adam | epoch: 013 | loss: 0.29845 - acc: 0.8806 -- iter: 0160/2395
[A[ATraining Step: 906  | total loss: [1m[32m0.31678[0m[0m | time: 74.418s
[2K
| Adam | epoch: 013 | loss: 0.31678 - acc: 0.8738 -- iter: 0192/2395
[A[ATraining Step: 907  | total loss: [1m[32m0.31621[0m[0m | time: 87.058s
[2K
| Adam | epoch: 013 | loss: 0.31621 - acc: 0.8708 -- iter: 0224/2395
[A[ATraining Step: 908  | total loss: [1m[32m0.30662[0m[0m | time: 100.219s
[2K
| Adam | epoch: 013 | loss: 0.30662 - acc: 0.8743 -- iter: 0256/2395
[A[ATraining Step: 909  | total loss: [1m[32m0.30788[0m[0m | time: 113.317s
[2K
| Adam | epoch: 013 | loss: 0.30788 - acc: 0.8744 -- iter: 0288/2395
[A[ATraining Step: 910  | total loss: [1m[32m0.30954[0m[0m | time: 126.815s
[2K
| Adam | epoch: 013 | loss: 0.30954 - acc: 0.8713 -- iter: 0320/2395
[A[ATraining Step: 911  | total loss: [1m[32m0.30245[0m[0m | time: 138.330s
[2K
| Adam | epoch: 013 | loss: 0.30245 - acc: 0.8779 -- iter: 0352/2395
[A[ATraining Step: 912  | total loss: [1m[32m0.29524[0m[0m | time: 148.848s
[2K
| Adam | epoch: 013 | loss: 0.29524 - acc: 0.8790 -- iter: 0384/2395
[A[ATraining Step: 913  | total loss: [1m[32m0.27918[0m[0m | time: 162.201s
[2K
| Adam | epoch: 013 | loss: 0.27918 - acc: 0.8911 -- iter: 0416/2395
[A[ATraining Step: 914  | total loss: [1m[32m0.29916[0m[0m | time: 175.426s
[2K
| Adam | epoch: 013 | loss: 0.29916 - acc: 0.8708 -- iter: 0448/2395
[A[ATraining Step: 915  | total loss: [1m[32m0.31783[0m[0m | time: 188.201s
[2K
| Adam | epoch: 013 | loss: 0.31783 - acc: 0.8556 -- iter: 0480/2395
[A[ATraining Step: 916  | total loss: [1m[32m0.31344[0m[0m | time: 201.504s
[2K
| Adam | epoch: 013 | loss: 0.31344 - acc: 0.8575 -- iter: 0512/2395
[A[ATraining Step: 917  | total loss: [1m[32m0.29596[0m[0m | time: 214.559s
[2K
| Adam | epoch: 013 | loss: 0.29596 - acc: 0.8655 -- iter: 0544/2395
[A[ATraining Step: 918  | total loss: [1m[32m0.31816[0m[0m | time: 227.465s
[2K
| Adam | epoch: 013 | loss: 0.31816 - acc: 0.8602 -- iter: 0576/2395
[A[ATraining Step: 919  | total loss: [1m[32m0.32283[0m[0m | time: 240.741s
[2K
| Adam | epoch: 013 | loss: 0.32283 - acc: 0.8586 -- iter: 0608/2395
[A[ATraining Step: 920  | total loss: [1m[32m0.35624[0m[0m | time: 253.335s
[2K
| Adam | epoch: 013 | loss: 0.35624 - acc: 0.8415 -- iter: 0640/2395
[A[ATraining Step: 921  | total loss: [1m[32m0.35495[0m[0m | time: 266.267s
[2K
| Adam | epoch: 013 | loss: 0.35495 - acc: 0.8417 -- iter: 0672/2395
[A[ATraining Step: 922  | total loss: [1m[32m0.38579[0m[0m | time: 278.964s
[2K
| Adam | epoch: 013 | loss: 0.38579 - acc: 0.8231 -- iter: 0704/2395
[A[ATraining Step: 923  | total loss: [1m[32m0.38088[0m[0m | time: 291.837s
[2K
| Adam | epoch: 013 | loss: 0.38088 - acc: 0.8283 -- iter: 0736/2395
[A[ATraining Step: 924  | total loss: [1m[32m0.39016[0m[0m | time: 305.420s
[2K
| Adam | epoch: 013 | loss: 0.39016 - acc: 0.8205 -- iter: 0768/2395
[A[ATraining Step: 925  | total loss: [1m[32m0.40203[0m[0m | time: 318.428s
[2K
| Adam | epoch: 013 | loss: 0.40203 - acc: 0.8166 -- iter: 0800/2395
[A[ATraining Step: 926  | total loss: [1m[32m0.39849[0m[0m | time: 331.662s
[2K
| Adam | epoch: 013 | loss: 0.39849 - acc: 0.8193 -- iter: 0832/2395
[A[ATraining Step: 927  | total loss: [1m[32m0.40845[0m[0m | time: 344.086s
[2K
| Adam | epoch: 013 | loss: 0.40845 - acc: 0.8217 -- iter: 0864/2395
[A[ATraining Step: 928  | total loss: [1m[32m0.43483[0m[0m | time: 357.168s
[2K
| Adam | epoch: 013 | loss: 0.43483 - acc: 0.8083 -- iter: 0896/2395
[A[ATraining Step: 929  | total loss: [1m[32m0.43716[0m[0m | time: 370.577s
[2K
| Adam | epoch: 013 | loss: 0.43716 - acc: 0.8119 -- iter: 0928/2395
[A[ATraining Step: 930  | total loss: [1m[32m0.42220[0m[0m | time: 383.489s
[2K
| Adam | epoch: 013 | loss: 0.42220 - acc: 0.8182 -- iter: 0960/2395
[A[ATraining Step: 931  | total loss: [1m[32m0.41344[0m[0m | time: 396.479s
[2K
| Adam | epoch: 013 | loss: 0.41344 - acc: 0.8176 -- iter: 0992/2395
[A[ATraining Step: 932  | total loss: [1m[32m0.41356[0m[0m | time: 409.133s
[2K
| Adam | epoch: 013 | loss: 0.41356 - acc: 0.8077 -- iter: 1024/2395
[A[ATraining Step: 933  | total loss: [1m[32m0.41797[0m[0m | time: 422.448s
[2K
| Adam | epoch: 013 | loss: 0.41797 - acc: 0.8051 -- iter: 1056/2395
[A[ATraining Step: 934  | total loss: [1m[32m0.41757[0m[0m | time: 435.567s
[2K
| Adam | epoch: 013 | loss: 0.41757 - acc: 0.8027 -- iter: 1088/2395
[A[ATraining Step: 935  | total loss: [1m[32m0.42148[0m[0m | time: 448.273s
[2K
| Adam | epoch: 013 | loss: 0.42148 - acc: 0.8037 -- iter: 1120/2395
[A[ATraining Step: 936  | total loss: [1m[32m0.40406[0m[0m | time: 461.341s
[2K
| Adam | epoch: 013 | loss: 0.40406 - acc: 0.8139 -- iter: 1152/2395
[A[ATraining Step: 937  | total loss: [1m[32m0.39500[0m[0m | time: 474.316s
[2K
| Adam | epoch: 013 | loss: 0.39500 - acc: 0.8169 -- iter: 1184/2395
[A[ATraining Step: 938  | total loss: [1m[32m0.40135[0m[0m | time: 487.383s
[2K
| Adam | epoch: 013 | loss: 0.40135 - acc: 0.8258 -- iter: 1216/2395
[A[ATraining Step: 939  | total loss: [1m[32m0.38924[0m[0m | time: 500.494s
[2K
| Adam | epoch: 013 | loss: 0.38924 - acc: 0.8339 -- iter: 1248/2395
[A[ATraining Step: 940  | total loss: [1m[32m0.38004[0m[0m | time: 513.629s
[2K
| Adam | epoch: 013 | loss: 0.38004 - acc: 0.8349 -- iter: 1280/2395
[A[ATraining Step: 941  | total loss: [1m[32m0.38646[0m[0m | time: 526.619s
[2K
| Adam | epoch: 013 | loss: 0.38646 - acc: 0.8295 -- iter: 1312/2395
[A[ATraining Step: 942  | total loss: [1m[32m0.39128[0m[0m | time: 539.702s
[2K
| Adam | epoch: 013 | loss: 0.39128 - acc: 0.8278 -- iter: 1344/2395
[A[ATraining Step: 943  | total loss: [1m[32m0.37601[0m[0m | time: 552.414s
[2K
| Adam | epoch: 013 | loss: 0.37601 - acc: 0.8357 -- iter: 1376/2395
[A[ATraining Step: 944  | total loss: [1m[32m0.36652[0m[0m | time: 565.376s
[2K
| Adam | epoch: 013 | loss: 0.36652 - acc: 0.8458 -- iter: 1408/2395
[A[ATraining Step: 945  | total loss: [1m[32m0.36635[0m[0m | time: 578.199s
[2K
| Adam | epoch: 013 | loss: 0.36635 - acc: 0.8425 -- iter: 1440/2395
[A[ATraining Step: 946  | total loss: [1m[32m0.40145[0m[0m | time: 590.587s
[2K
| Adam | epoch: 013 | loss: 0.40145 - acc: 0.8301 -- iter: 1472/2395
[A[ATraining Step: 947  | total loss: [1m[32m0.38606[0m[0m | time: 603.660s
[2K
| Adam | epoch: 013 | loss: 0.38606 - acc: 0.8377 -- iter: 1504/2395
[A[ATraining Step: 948  | total loss: [1m[32m0.38267[0m[0m | time: 616.888s
[2K
| Adam | epoch: 013 | loss: 0.38267 - acc: 0.8415 -- iter: 1536/2395
[A[ATraining Step: 949  | total loss: [1m[32m0.41065[0m[0m | time: 629.818s
[2K
| Adam | epoch: 013 | loss: 0.41065 - acc: 0.8292 -- iter: 1568/2395
[A[ATraining Step: 950  | total loss: [1m[32m0.41190[0m[0m | time: 642.930s
[2K
| Adam | epoch: 013 | loss: 0.41190 - acc: 0.8275 -- iter: 1600/2395
[A[ATraining Step: 951  | total loss: [1m[32m0.40482[0m[0m | time: 655.991s
[2K
| Adam | epoch: 013 | loss: 0.40482 - acc: 0.8291 -- iter: 1632/2395
[A[ATraining Step: 952  | total loss: [1m[32m0.40033[0m[0m | time: 669.423s
[2K
| Adam | epoch: 013 | loss: 0.40033 - acc: 0.8275 -- iter: 1664/2395
[A[ATraining Step: 953  | total loss: [1m[32m0.40590[0m[0m | time: 682.376s
[2K
| Adam | epoch: 013 | loss: 0.40590 - acc: 0.8229 -- iter: 1696/2395
[A[ATraining Step: 954  | total loss: [1m[32m0.38560[0m[0m | time: 695.243s
[2K
| Adam | epoch: 013 | loss: 0.38560 - acc: 0.8343 -- iter: 1728/2395
[A[ATraining Step: 955  | total loss: [1m[32m0.39184[0m[0m | time: 708.460s
[2K
| Adam | epoch: 013 | loss: 0.39184 - acc: 0.8321 -- iter: 1760/2395
[A[ATraining Step: 956  | total loss: [1m[32m0.38996[0m[0m | time: 721.410s
[2K
| Adam | epoch: 013 | loss: 0.38996 - acc: 0.8396 -- iter: 1792/2395
[A[ATraining Step: 957  | total loss: [1m[32m0.36987[0m[0m | time: 734.707s
[2K
| Adam | epoch: 013 | loss: 0.36987 - acc: 0.8493 -- iter: 1824/2395
[A[ATraining Step: 958  | total loss: [1m[32m0.36241[0m[0m | time: 747.660s
[2K
| Adam | epoch: 013 | loss: 0.36241 - acc: 0.8488 -- iter: 1856/2395
[A[ATraining Step: 959  | total loss: [1m[32m0.34890[0m[0m | time: 760.169s
[2K
| Adam | epoch: 013 | loss: 0.34890 - acc: 0.8545 -- iter: 1888/2395
[A[ATraining Step: 960  | total loss: [1m[32m0.33772[0m[0m | time: 773.211s
[2K
| Adam | epoch: 013 | loss: 0.33772 - acc: 0.8566 -- iter: 1920/2395
[A[ATraining Step: 961  | total loss: [1m[32m0.33370[0m[0m | time: 785.892s
[2K
| Adam | epoch: 013 | loss: 0.33370 - acc: 0.8553 -- iter: 1952/2395
[A[ATraining Step: 962  | total loss: [1m[32m0.31915[0m[0m | time: 799.051s
[2K
| Adam | epoch: 013 | loss: 0.31915 - acc: 0.8666 -- iter: 1984/2395
[A[ATraining Step: 963  | total loss: [1m[32m0.30353[0m[0m | time: 811.982s
[2K
| Adam | epoch: 013 | loss: 0.30353 - acc: 0.8769 -- iter: 2016/2395
[A[ATraining Step: 964  | total loss: [1m[32m0.29604[0m[0m | time: 825.086s
[2K
| Adam | epoch: 013 | loss: 0.29604 - acc: 0.8798 -- iter: 2048/2395
[A[ATraining Step: 965  | total loss: [1m[32m0.28780[0m[0m | time: 838.137s
[2K
| Adam | epoch: 013 | loss: 0.28780 - acc: 0.8762 -- iter: 2080/2395
[A[ATraining Step: 966  | total loss: [1m[32m0.27837[0m[0m | time: 850.904s
[2K
| Adam | epoch: 013 | loss: 0.27837 - acc: 0.8792 -- iter: 2112/2395
[A[ATraining Step: 967  | total loss: [1m[32m0.27125[0m[0m | time: 863.646s
[2K
| Adam | epoch: 013 | loss: 0.27125 - acc: 0.8850 -- iter: 2144/2395
[A[ATraining Step: 968  | total loss: [1m[32m0.27409[0m[0m | time: 877.271s
[2K
| Adam | epoch: 013 | loss: 0.27409 - acc: 0.8809 -- iter: 2176/2395
[A[ATraining Step: 969  | total loss: [1m[32m0.27293[0m[0m | time: 890.210s
[2K
| Adam | epoch: 013 | loss: 0.27293 - acc: 0.8834 -- iter: 2208/2395
[A[ATraining Step: 970  | total loss: [1m[32m0.26242[0m[0m | time: 903.211s
[2K
| Adam | epoch: 013 | loss: 0.26242 - acc: 0.8888 -- iter: 2240/2395
[A[ATraining Step: 971  | total loss: [1m[32m0.25309[0m[0m | time: 915.499s
[2K
| Adam | epoch: 013 | loss: 0.25309 - acc: 0.8906 -- iter: 2272/2395
[A[ATraining Step: 972  | total loss: [1m[32m0.24690[0m[0m | time: 928.126s
[2K
| Adam | epoch: 013 | loss: 0.24690 - acc: 0.8953 -- iter: 2304/2395
[A[ATraining Step: 973  | total loss: [1m[32m0.24282[0m[0m | time: 940.497s
[2K
| Adam | epoch: 013 | loss: 0.24282 - acc: 0.8964 -- iter: 2336/2395
[A[ATraining Step: 974  | total loss: [1m[32m0.24510[0m[0m | time: 953.911s
[2K
| Adam | epoch: 013 | loss: 0.24510 - acc: 0.8942 -- iter: 2368/2395
[A[ATraining Step: 975  | total loss: [1m[32m0.25404[0m[0m | time: 1021.894s
[2K
| Adam | epoch: 013 | loss: 0.25404 - acc: 0.8892 | val_loss: 1.47587 - val_acc: 0.6475 -- iter: 2395/2395
--
Training Step: 976  | total loss: [1m[32m0.24886[0m[0m | time: 13.263s
[2K
| Adam | epoch: 014 | loss: 0.24886 - acc: 0.8940 -- iter: 0032/2395
[A[ATraining Step: 977  | total loss: [1m[32m0.24404[0m[0m | time: 26.204s
[2K
| Adam | epoch: 014 | loss: 0.24404 - acc: 0.8984 -- iter: 0064/2395
[A[ATraining Step: 978  | total loss: [1m[32m0.23584[0m[0m | time: 39.149s
[2K
| Adam | epoch: 014 | loss: 0.23584 - acc: 0.9023 -- iter: 0096/2395
[A[ATraining Step: 979  | total loss: [1m[32m0.23663[0m[0m | time: 53.025s
[2K
| Adam | epoch: 014 | loss: 0.23663 - acc: 0.9027 -- iter: 0128/2395
[A[ATraining Step: 980  | total loss: [1m[32m0.26654[0m[0m | time: 67.166s
[2K
| Adam | epoch: 014 | loss: 0.26654 - acc: 0.8905 -- iter: 0160/2395
[A[ATraining Step: 981  | total loss: [1m[32m0.26698[0m[0m | time: 81.604s
[2K
| Adam | epoch: 014 | loss: 0.26698 - acc: 0.8921 -- iter: 0192/2395
[A[ATraining Step: 982  | total loss: [1m[32m0.25715[0m[0m | time: 96.420s
[2K
| Adam | epoch: 014 | loss: 0.25715 - acc: 0.8966 -- iter: 0224/2395
[A[ATraining Step: 983  | total loss: [1m[32m0.25569[0m[0m | time: 110.916s
[2K
| Adam | epoch: 014 | loss: 0.25569 - acc: 0.8914 -- iter: 0256/2395
[A[ATraining Step: 984  | total loss: [1m[32m0.24761[0m[0m | time: 123.332s
[2K
| Adam | epoch: 014 | loss: 0.24761 - acc: 0.8928 -- iter: 0288/2395
[A[ATraining Step: 985  | total loss: [1m[32m0.24228[0m[0m | time: 131.895s
[2K
| Adam | epoch: 014 | loss: 0.24228 - acc: 0.8942 -- iter: 0320/2395
[A[ATraining Step: 986  | total loss: [1m[32m0.25710[0m[0m | time: 140.573s
[2K
| Adam | epoch: 014 | loss: 0.25710 - acc: 0.8923 -- iter: 0352/2395
[A[ATraining Step: 987  | total loss: [1m[32m0.27440[0m[0m | time: 151.328s
[2K
| Adam | epoch: 014 | loss: 0.27440 - acc: 0.8874 -- iter: 0384/2395
[A[ATraining Step: 988  | total loss: [1m[32m0.26902[0m[0m | time: 162.780s
[2K
| Adam | epoch: 014 | loss: 0.26902 - acc: 0.8876 -- iter: 0416/2395
[A[ATraining Step: 989  | total loss: [1m[32m0.24962[0m[0m | time: 175.887s
[2K
| Adam | epoch: 014 | loss: 0.24962 - acc: 0.8988 -- iter: 0448/2395
[A[ATraining Step: 990  | total loss: [1m[32m0.25525[0m[0m | time: 188.828s
[2K
| Adam | epoch: 014 | loss: 0.25525 - acc: 0.8996 -- iter: 0480/2395
[A[ATraining Step: 991  | total loss: [1m[32m0.28408[0m[0m | time: 201.563s
[2K
| Adam | epoch: 014 | loss: 0.28408 - acc: 0.8877 -- iter: 0512/2395
[A[ATraining Step: 992  | total loss: [1m[32m0.28349[0m[0m | time: 214.400s
[2K
| Adam | epoch: 014 | loss: 0.28349 - acc: 0.8833 -- iter: 0544/2395
[A[ATraining Step: 993  | total loss: [1m[32m0.28049[0m[0m | time: 226.941s
[2K
| Adam | epoch: 014 | loss: 0.28049 - acc: 0.8856 -- iter: 0576/2395
[A[ATraining Step: 994  | total loss: [1m[32m0.29364[0m[0m | time: 240.047s
[2K
| Adam | epoch: 014 | loss: 0.29364 - acc: 0.8783 -- iter: 0608/2395
[A[ATraining Step: 995  | total loss: [1m[32m0.29670[0m[0m | time: 252.582s
[2K
| Adam | epoch: 014 | loss: 0.29670 - acc: 0.8717 -- iter: 0640/2395
[A[ATraining Step: 996  | total loss: [1m[32m0.32657[0m[0m | time: 265.718s
[2K
| Adam | epoch: 014 | loss: 0.32657 - acc: 0.8564 -- iter: 0672/2395
[A[ATraining Step: 997  | total loss: [1m[32m0.31396[0m[0m | time: 278.858s
[2K
| Adam | epoch: 014 | loss: 0.31396 - acc: 0.8677 -- iter: 0704/2395
[A[ATraining Step: 998  | total loss: [1m[32m0.31809[0m[0m | time: 291.475s
[2K
| Adam | epoch: 014 | loss: 0.31809 - acc: 0.8684 -- iter: 0736/2395
[A[ATraining Step: 999  | total loss: [1m[32m0.29926[0m[0m | time: 304.371s
[2K
| Adam | epoch: 014 | loss: 0.29926 - acc: 0.8784 -- iter: 0768/2395
[A[ATraining Step: 1000  | total loss: [1m[32m0.29766[0m[0m | time: 372.270s
[2K
| Adam | epoch: 014 | loss: 0.29766 - acc: 0.8843 | val_loss: 2.81307 - val_acc: 0.5007 -- iter: 0800/2395
--
Training Step: 1001  | total loss: [1m[32m0.28514[0m[0m | time: 385.376s
[2K
| Adam | epoch: 014 | loss: 0.28514 - acc: 0.8897 -- iter: 0832/2395
[A[ATraining Step: 1002  | total loss: [1m[32m0.29886[0m[0m | time: 398.975s
[2K
| Adam | epoch: 014 | loss: 0.29886 - acc: 0.8851 -- iter: 0864/2395
[A[ATraining Step: 1003  | total loss: [1m[32m0.29445[0m[0m | time: 412.968s
[2K
| Adam | epoch: 014 | loss: 0.29445 - acc: 0.8872 -- iter: 0896/2395
[A[ATraining Step: 1004  | total loss: [1m[32m0.29615[0m[0m | time: 427.304s
[2K
| Adam | epoch: 014 | loss: 0.29615 - acc: 0.8891 -- iter: 0928/2395
[A[ATraining Step: 1005  | total loss: [1m[32m0.28479[0m[0m | time: 440.851s
[2K
| Adam | epoch: 014 | loss: 0.28479 - acc: 0.8939 -- iter: 0960/2395
[A[ATraining Step: 1006  | total loss: [1m[32m0.30441[0m[0m | time: 454.595s
[2K
| Adam | epoch: 014 | loss: 0.30441 - acc: 0.8827 -- iter: 0992/2395
[A[ATraining Step: 1007  | total loss: [1m[32m0.31124[0m[0m | time: 467.586s
[2K
| Adam | epoch: 014 | loss: 0.31124 - acc: 0.8756 -- iter: 1024/2395
[A[ATraining Step: 1008  | total loss: [1m[32m0.31628[0m[0m | time: 476.333s
[2K
| Adam | epoch: 014 | loss: 0.31628 - acc: 0.8787 -- iter: 1056/2395
[A[ATraining Step: 1009  | total loss: [1m[32m0.31955[0m[0m | time: 485.059s
[2K
| Adam | epoch: 014 | loss: 0.31955 - acc: 0.8783 -- iter: 1088/2395
[A[ATraining Step: 1010  | total loss: [1m[32m0.31670[0m[0m | time: 495.358s
[2K
| Adam | epoch: 014 | loss: 0.31670 - acc: 0.8811 -- iter: 1120/2395
[A[ATraining Step: 1011  | total loss: [1m[32m0.31653[0m[0m | time: 507.791s
[2K
| Adam | epoch: 014 | loss: 0.31653 - acc: 0.8774 -- iter: 1152/2395
[A[ATraining Step: 1012  | total loss: [1m[32m0.31478[0m[0m | time: 520.469s
[2K
| Adam | epoch: 014 | loss: 0.31478 - acc: 0.8740 -- iter: 1184/2395
[A[ATraining Step: 1013  | total loss: [1m[32m0.31218[0m[0m | time: 533.209s
[2K
| Adam | epoch: 014 | loss: 0.31218 - acc: 0.8710 -- iter: 1216/2395
[A[ATraining Step: 1014  | total loss: [1m[32m0.30930[0m[0m | time: 546.058s
[2K
| Adam | epoch: 014 | loss: 0.30930 - acc: 0.8683 -- iter: 1248/2395
[A[ATraining Step: 1015  | total loss: [1m[32m0.29887[0m[0m | time: 559.049s
[2K
| Adam | epoch: 014 | loss: 0.29887 - acc: 0.8689 -- iter: 1280/2395
[A[ATraining Step: 1016  | total loss: [1m[32m0.28832[0m[0m | time: 571.862s
[2K
| Adam | epoch: 014 | loss: 0.28832 - acc: 0.8789 -- iter: 1312/2395
[A[ATraining Step: 1017  | total loss: [1m[32m0.27728[0m[0m | time: 584.684s
[2K
| Adam | epoch: 014 | loss: 0.27728 - acc: 0.8817 -- iter: 1344/2395
[A[ATraining Step: 1018  | total loss: [1m[32m0.27867[0m[0m | time: 597.197s
[2K
| Adam | epoch: 014 | loss: 0.27867 - acc: 0.8810 -- iter: 1376/2395
[A[ATraining Step: 1019  | total loss: [1m[32m0.27962[0m[0m | time: 609.859s
[2K
| Adam | epoch: 014 | loss: 0.27962 - acc: 0.8773 -- iter: 1408/2395
[A[ATraining Step: 1020  | total loss: [1m[32m0.27158[0m[0m | time: 622.753s
[2K
| Adam | epoch: 014 | loss: 0.27158 - acc: 0.8864 -- iter: 1440/2395
[A[ATraining Step: 1021  | total loss: [1m[32m0.26891[0m[0m | time: 635.456s
[2K
| Adam | epoch: 014 | loss: 0.26891 - acc: 0.8915 -- iter: 1472/2395
[A[ATraining Step: 1022  | total loss: [1m[32m0.29800[0m[0m | time: 648.403s
[2K
| Adam | epoch: 014 | loss: 0.29800 - acc: 0.8805 -- iter: 1504/2395
[A[ATraining Step: 1023  | total loss: [1m[32m0.30282[0m[0m | time: 661.354s
[2K
| Adam | epoch: 014 | loss: 0.30282 - acc: 0.8706 -- iter: 1536/2395
[A[ATraining Step: 1024  | total loss: [1m[32m0.29878[0m[0m | time: 674.184s
[2K
| Adam | epoch: 014 | loss: 0.29878 - acc: 0.8741 -- iter: 1568/2395
[A[ATraining Step: 1025  | total loss: [1m[32m0.29841[0m[0m | time: 686.888s
[2K
| Adam | epoch: 014 | loss: 0.29841 - acc: 0.8774 -- iter: 1600/2395
[A[ATraining Step: 1026  | total loss: [1m[32m0.29878[0m[0m | time: 699.749s
[2K
| Adam | epoch: 014 | loss: 0.29878 - acc: 0.8771 -- iter: 1632/2395
[A[ATraining Step: 1027  | total loss: [1m[32m0.30519[0m[0m | time: 712.666s
[2K
| Adam | epoch: 014 | loss: 0.30519 - acc: 0.8738 -- iter: 1664/2395
[A[ATraining Step: 1028  | total loss: [1m[32m0.31270[0m[0m | time: 725.401s
[2K
| Adam | epoch: 014 | loss: 0.31270 - acc: 0.8583 -- iter: 1696/2395
[A[ATraining Step: 1029  | total loss: [1m[32m0.29562[0m[0m | time: 738.200s
[2K
| Adam | epoch: 014 | loss: 0.29562 - acc: 0.8662 -- iter: 1728/2395
[A[ATraining Step: 1030  | total loss: [1m[32m0.30612[0m[0m | time: 751.125s
[2K
| Adam | epoch: 014 | loss: 0.30612 - acc: 0.8608 -- iter: 1760/2395
[A[ATraining Step: 1031  | total loss: [1m[32m0.28900[0m[0m | time: 763.990s
[2K
| Adam | epoch: 014 | loss: 0.28900 - acc: 0.8716 -- iter: 1792/2395
[A[ATraining Step: 1032  | total loss: [1m[32m0.29597[0m[0m | time: 777.079s
[2K
| Adam | epoch: 014 | loss: 0.29597 - acc: 0.8782 -- iter: 1824/2395
[A[ATraining Step: 1033  | total loss: [1m[32m0.28082[0m[0m | time: 789.904s
[2K
| Adam | epoch: 014 | loss: 0.28082 - acc: 0.8873 -- iter: 1856/2395
[A[ATraining Step: 1034  | total loss: [1m[32m0.28696[0m[0m | time: 802.788s
[2K
| Adam | epoch: 014 | loss: 0.28696 - acc: 0.8892 -- iter: 1888/2395
[A[ATraining Step: 1035  | total loss: [1m[32m0.26411[0m[0m | time: 815.883s
[2K
| Adam | epoch: 014 | loss: 0.26411 - acc: 0.9002 -- iter: 1920/2395
[A[ATraining Step: 1036  | total loss: [1m[32m0.25344[0m[0m | time: 828.057s
[2K
| Adam | epoch: 014 | loss: 0.25344 - acc: 0.9071 -- iter: 1952/2395
[A[ATraining Step: 1037  | total loss: [1m[32m0.25307[0m[0m | time: 841.622s
[2K
| Adam | epoch: 014 | loss: 0.25307 - acc: 0.9070 -- iter: 1984/2395
[A[ATraining Step: 1038  | total loss: [1m[32m0.26486[0m[0m | time: 854.066s
[2K
| Adam | epoch: 014 | loss: 0.26486 - acc: 0.9038 -- iter: 2016/2395
[A[ATraining Step: 1039  | total loss: [1m[32m0.25058[0m[0m | time: 866.761s
[2K
| Adam | epoch: 014 | loss: 0.25058 - acc: 0.9103 -- iter: 2048/2395
[A[ATraining Step: 1040  | total loss: [1m[32m0.24663[0m[0m | time: 879.655s
[2K
| Adam | epoch: 014 | loss: 0.24663 - acc: 0.9068 -- iter: 2080/2395
[A[ATraining Step: 1041  | total loss: [1m[32m0.24249[0m[0m | time: 892.252s
[2K
| Adam | epoch: 014 | loss: 0.24249 - acc: 0.9067 -- iter: 2112/2395
[A[ATraining Step: 1042  | total loss: [1m[32m0.22786[0m[0m | time: 905.148s
[2K
| Adam | epoch: 014 | loss: 0.22786 - acc: 0.9129 -- iter: 2144/2395
[A[ATraining Step: 1043  | total loss: [1m[32m0.21692[0m[0m | time: 917.656s
[2K
| Adam | epoch: 014 | loss: 0.21692 - acc: 0.9185 -- iter: 2176/2395
[A[ATraining Step: 1044  | total loss: [1m[32m0.21066[0m[0m | time: 930.563s
[2K
| Adam | epoch: 014 | loss: 0.21066 - acc: 0.9173 -- iter: 2208/2395
[A[ATraining Step: 1045  | total loss: [1m[32m0.20364[0m[0m | time: 943.236s
[2K
| Adam | epoch: 014 | loss: 0.20364 - acc: 0.9193 -- iter: 2240/2395
[A[ATraining Step: 1046  | total loss: [1m[32m0.19820[0m[0m | time: 956.186s
[2K
| Adam | epoch: 014 | loss: 0.19820 - acc: 0.9211 -- iter: 2272/2395
[A[ATraining Step: 1047  | total loss: [1m[32m0.19586[0m[0m | time: 969.152s
[2K
| Adam | epoch: 014 | loss: 0.19586 - acc: 0.9228 -- iter: 2304/2395
[A[ATraining Step: 1048  | total loss: [1m[32m0.19459[0m[0m | time: 981.542s
[2K
| Adam | epoch: 014 | loss: 0.19459 - acc: 0.9180 -- iter: 2336/2395
[A[ATraining Step: 1049  | total loss: [1m[32m0.18934[0m[0m | time: 994.434s
[2K
| Adam | epoch: 014 | loss: 0.18934 - acc: 0.9231 -- iter: 2368/2395
[A[ATraining Step: 1050  | total loss: [1m[32m0.18282[0m[0m | time: 1062.396s
[2K
| Adam | epoch: 014 | loss: 0.18282 - acc: 0.9245 | val_loss: 0.75671 - val_acc: 0.7597 -- iter: 2395/2395
--
Training Step: 1051  | total loss: [1m[32m0.17391[0m[0m | time: 12.778s
[2K
| Adam | epoch: 015 | loss: 0.17391 - acc: 0.9289 -- iter: 0032/2395
[A[ATraining Step: 1052  | total loss: [1m[32m0.16445[0m[0m | time: 25.886s
[2K
| Adam | epoch: 015 | loss: 0.16445 - acc: 0.9329 -- iter: 0064/2395
[A[ATraining Step: 1053  | total loss: [1m[32m0.15847[0m[0m | time: 39.338s
[2K
| Adam | epoch: 015 | loss: 0.15847 - acc: 0.9334 -- iter: 0096/2395
[A[ATraining Step: 1054  | total loss: [1m[32m0.14788[0m[0m | time: 52.133s
[2K
| Adam | epoch: 015 | loss: 0.14788 - acc: 0.9369 -- iter: 0128/2395
[A[ATraining Step: 1055  | total loss: [1m[32m0.13940[0m[0m | time: 65.440s
[2K
| Adam | epoch: 015 | loss: 0.13940 - acc: 0.9432 -- iter: 0160/2395
[A[ATraining Step: 1056  | total loss: [1m[32m0.15875[0m[0m | time: 78.208s
[2K
| Adam | epoch: 015 | loss: 0.15875 - acc: 0.9333 -- iter: 0192/2395
[A[ATraining Step: 1057  | total loss: [1m[32m0.15170[0m[0m | time: 91.293s
[2K
| Adam | epoch: 015 | loss: 0.15170 - acc: 0.9337 -- iter: 0224/2395
[A[ATraining Step: 1058  | total loss: [1m[32m0.14702[0m[0m | time: 103.994s
[2K
| Adam | epoch: 015 | loss: 0.14702 - acc: 0.9341 -- iter: 0256/2395
[A[ATraining Step: 1059  | total loss: [1m[32m0.14702[0m[0m | time: 116.999s
[2K
| Adam | epoch: 015 | loss: 0.14702 - acc: 0.9344 -- iter: 0288/2395
[A[ATraining Step: 1060  | total loss: [1m[32m0.14486[0m[0m | time: 129.793s
[2K
| Adam | epoch: 015 | loss: 0.14486 - acc: 0.9379 -- iter: 0320/2395
[A[ATraining Step: 1061  | total loss: [1m[32m0.13858[0m[0m | time: 142.713s
[2K
| Adam | epoch: 015 | loss: 0.13858 - acc: 0.9378 -- iter: 0352/2395
[A[ATraining Step: 1062  | total loss: [1m[32m0.13679[0m[0m | time: 155.832s
[2K
| Adam | epoch: 015 | loss: 0.13679 - acc: 0.9409 -- iter: 0384/2395
[A[ATraining Step: 1063  | total loss: [1m[32m0.16727[0m[0m | time: 167.304s
[2K
| Adam | epoch: 015 | loss: 0.16727 - acc: 0.9312 -- iter: 0416/2395
[A[ATraining Step: 1064  | total loss: [1m[32m0.16282[0m[0m | time: 178.472s
[2K
| Adam | epoch: 015 | loss: 0.16282 - acc: 0.9307 -- iter: 0448/2395
[A[ATraining Step: 1065  | total loss: [1m[32m0.15169[0m[0m | time: 191.184s
[2K
| Adam | epoch: 015 | loss: 0.15169 - acc: 0.9376 -- iter: 0480/2395
[A[ATraining Step: 1066  | total loss: [1m[32m0.14463[0m[0m | time: 204.498s
[2K
| Adam | epoch: 015 | loss: 0.14463 - acc: 0.9376 -- iter: 0512/2395
[A[ATraining Step: 1067  | total loss: [1m[32m0.14721[0m[0m | time: 217.281s
[2K
| Adam | epoch: 015 | loss: 0.14721 - acc: 0.9376 -- iter: 0544/2395
[A[ATraining Step: 1068  | total loss: [1m[32m0.15118[0m[0m | time: 230.279s
[2K
| Adam | epoch: 015 | loss: 0.15118 - acc: 0.9344 -- iter: 0576/2395
[A[ATraining Step: 1069  | total loss: [1m[32m0.16289[0m[0m | time: 243.230s
[2K
| Adam | epoch: 015 | loss: 0.16289 - acc: 0.9316 -- iter: 0608/2395
[A[ATraining Step: 1070  | total loss: [1m[32m0.15398[0m[0m | time: 256.010s
[2K
| Adam | epoch: 015 | loss: 0.15398 - acc: 0.9353 -- iter: 0640/2395
[A[ATraining Step: 1071  | total loss: [1m[32m0.15256[0m[0m | time: 269.037s
[2K
| Adam | epoch: 015 | loss: 0.15256 - acc: 0.9387 -- iter: 0672/2395
[A[ATraining Step: 1072  | total loss: [1m[32m0.14986[0m[0m | time: 281.775s
[2K
| Adam | epoch: 015 | loss: 0.14986 - acc: 0.9354 -- iter: 0704/2395
[A[ATraining Step: 1073  | total loss: [1m[32m0.16839[0m[0m | time: 294.977s
[2K
| Adam | epoch: 015 | loss: 0.16839 - acc: 0.9294 -- iter: 0736/2395
[A[ATraining Step: 1074  | total loss: [1m[32m0.19049[0m[0m | time: 308.206s
[2K
| Adam | epoch: 015 | loss: 0.19049 - acc: 0.9240 -- iter: 0768/2395
[A[ATraining Step: 1075  | total loss: [1m[32m0.20442[0m[0m | time: 321.565s
[2K
| Adam | epoch: 015 | loss: 0.20442 - acc: 0.9222 -- iter: 0800/2395
[A[ATraining Step: 1076  | total loss: [1m[32m0.21008[0m[0m | time: 334.243s
[2K
| Adam | epoch: 015 | loss: 0.21008 - acc: 0.9175 -- iter: 0832/2395
[A[ATraining Step: 1077  | total loss: [1m[32m0.21286[0m[0m | time: 346.982s
[2K
| Adam | epoch: 015 | loss: 0.21286 - acc: 0.9132 -- iter: 0864/2395
[A[ATraining Step: 1078  | total loss: [1m[32m0.23607[0m[0m | time: 360.079s
[2K
| Adam | epoch: 015 | loss: 0.23607 - acc: 0.9063 -- iter: 0896/2395
[A[ATraining Step: 1079  | total loss: [1m[32m0.24315[0m[0m | time: 372.891s
[2K
| Adam | epoch: 015 | loss: 0.24315 - acc: 0.9031 -- iter: 0928/2395
[A[ATraining Step: 1080  | total loss: [1m[32m0.23412[0m[0m | time: 385.814s
[2K
| Adam | epoch: 015 | loss: 0.23412 - acc: 0.9035 -- iter: 0960/2395
[A[ATraining Step: 1081  | total loss: [1m[32m0.25365[0m[0m | time: 398.814s
[2K
| Adam | epoch: 015 | loss: 0.25365 - acc: 0.8912 -- iter: 0992/2395
[A[ATraining Step: 1082  | total loss: [1m[32m0.27954[0m[0m | time: 412.131s
[2K
| Adam | epoch: 015 | loss: 0.27954 - acc: 0.8896 -- iter: 1024/2395
[A[ATraining Step: 1083  | total loss: [1m[32m0.27953[0m[0m | time: 424.823s
[2K
| Adam | epoch: 015 | loss: 0.27953 - acc: 0.8913 -- iter: 1056/2395
[A[ATraining Step: 1084  | total loss: [1m[32m0.27861[0m[0m | time: 438.089s
[2K
| Adam | epoch: 015 | loss: 0.27861 - acc: 0.8865 -- iter: 1088/2395
[A[ATraining Step: 1085  | total loss: [1m[32m0.28150[0m[0m | time: 450.610s
[2K
| Adam | epoch: 015 | loss: 0.28150 - acc: 0.8822 -- iter: 1120/2395
[A[ATraining Step: 1086  | total loss: [1m[32m0.27843[0m[0m | time: 463.532s
[2K
| Adam | epoch: 015 | loss: 0.27843 - acc: 0.8878 -- iter: 1152/2395
[A[ATraining Step: 1087  | total loss: [1m[32m0.30196[0m[0m | time: 476.710s
[2K
| Adam | epoch: 015 | loss: 0.30196 - acc: 0.8865 -- iter: 1184/2395
[A[ATraining Step: 1088  | total loss: [1m[32m0.29844[0m[0m | time: 489.553s
[2K
| Adam | epoch: 015 | loss: 0.29844 - acc: 0.8885 -- iter: 1216/2395
[A[ATraining Step: 1089  | total loss: [1m[32m0.30718[0m[0m | time: 503.145s
[2K
| Adam | epoch: 015 | loss: 0.30718 - acc: 0.8840 -- iter: 1248/2395
[A[ATraining Step: 1090  | total loss: [1m[32m0.30254[0m[0m | time: 516.223s
[2K
| Adam | epoch: 015 | loss: 0.30254 - acc: 0.8831 -- iter: 1280/2395
[A[ATraining Step: 1091  | total loss: [1m[32m0.30925[0m[0m | time: 528.645s
[2K
| Adam | epoch: 015 | loss: 0.30925 - acc: 0.8729 -- iter: 1312/2395
[A[ATraining Step: 1092  | total loss: [1m[32m0.29550[0m[0m | time: 541.628s
[2K
| Adam | epoch: 015 | loss: 0.29550 - acc: 0.8794 -- iter: 1344/2395
[A[ATraining Step: 1093  | total loss: [1m[32m0.28991[0m[0m | time: 554.280s
[2K
| Adam | epoch: 015 | loss: 0.28991 - acc: 0.8821 -- iter: 1376/2395
[A[ATraining Step: 1094  | total loss: [1m[32m0.28850[0m[0m | time: 566.789s
[2K
| Adam | epoch: 015 | loss: 0.28850 - acc: 0.8782 -- iter: 1408/2395
[A[ATraining Step: 1095  | total loss: [1m[32m0.27969[0m[0m | time: 579.410s
[2K
| Adam | epoch: 015 | loss: 0.27969 - acc: 0.8873 -- iter: 1440/2395
[A[ATraining Step: 1096  | total loss: [1m[32m0.27759[0m[0m | time: 592.296s
[2K
| Adam | epoch: 015 | loss: 0.27759 - acc: 0.8861 -- iter: 1472/2395
[A[ATraining Step: 1097  | total loss: [1m[32m0.26657[0m[0m | time: 605.296s
[2K
| Adam | epoch: 015 | loss: 0.26657 - acc: 0.8912 -- iter: 1504/2395
[A[ATraining Step: 1098  | total loss: [1m[32m0.27232[0m[0m | time: 618.483s
[2K
| Adam | epoch: 015 | loss: 0.27232 - acc: 0.8833 -- iter: 1536/2395
[A[ATraining Step: 1099  | total loss: [1m[32m0.26861[0m[0m | time: 631.376s
[2K
| Adam | epoch: 015 | loss: 0.26861 - acc: 0.8887 -- iter: 1568/2395
[A[ATraining Step: 1100  | total loss: [1m[32m0.26051[0m[0m | time: 643.846s
[2K
| Adam | epoch: 015 | loss: 0.26051 - acc: 0.8936 -- iter: 1600/2395
[A[ATraining Step: 1101  | total loss: [1m[32m0.28012[0m[0m | time: 656.668s
[2K
| Adam | epoch: 015 | loss: 0.28012 - acc: 0.8824 -- iter: 1632/2395
[A[ATraining Step: 1102  | total loss: [1m[32m0.31377[0m[0m | time: 669.638s
[2K
| Adam | epoch: 015 | loss: 0.31377 - acc: 0.8660 -- iter: 1664/2395
[A[ATraining Step: 1103  | total loss: [1m[32m0.33065[0m[0m | time: 683.855s
[2K
| Adam | epoch: 015 | loss: 0.33065 - acc: 0.8544 -- iter: 1696/2395
[A[ATraining Step: 1104  | total loss: [1m[32m0.31819[0m[0m | time: 697.905s
[2K
| Adam | epoch: 015 | loss: 0.31819 - acc: 0.8627 -- iter: 1728/2395
[A[ATraining Step: 1105  | total loss: [1m[32m0.31059[0m[0m | time: 711.954s
[2K
| Adam | epoch: 015 | loss: 0.31059 - acc: 0.8702 -- iter: 1760/2395
[A[ATraining Step: 1106  | total loss: [1m[32m0.30415[0m[0m | time: 726.234s
[2K
| Adam | epoch: 015 | loss: 0.30415 - acc: 0.8707 -- iter: 1792/2395
[A[ATraining Step: 1107  | total loss: [1m[32m0.30156[0m[0m | time: 740.057s
[2K
| Adam | epoch: 015 | loss: 0.30156 - acc: 0.8711 -- iter: 1824/2395
[A[ATraining Step: 1108  | total loss: [1m[32m0.30713[0m[0m | time: 751.032s
[2K
| Adam | epoch: 015 | loss: 0.30713 - acc: 0.8684 -- iter: 1856/2395
[A[ATraining Step: 1109  | total loss: [1m[32m0.29061[0m[0m | time: 759.811s
[2K
| Adam | epoch: 015 | loss: 0.29061 - acc: 0.8753 -- iter: 1888/2395
[A[ATraining Step: 1110  | total loss: [1m[32m0.27184[0m[0m | time: 769.828s
[2K
| Adam | epoch: 015 | loss: 0.27184 - acc: 0.8878 -- iter: 1920/2395
[A[ATraining Step: 1111  | total loss: [1m[32m0.26239[0m[0m | time: 782.931s
[2K
| Adam | epoch: 015 | loss: 0.26239 - acc: 0.8865 -- iter: 1952/2395
[A[ATraining Step: 1112  | total loss: [1m[32m0.24417[0m[0m | time: 795.874s
[2K
| Adam | epoch: 015 | loss: 0.24417 - acc: 0.8978 -- iter: 1984/2395
[A[ATraining Step: 1113  | total loss: [1m[32m0.23126[0m[0m | time: 808.840s
[2K
| Adam | epoch: 015 | loss: 0.23126 - acc: 0.9049 -- iter: 2016/2395
[A[ATraining Step: 1114  | total loss: [1m[32m0.22246[0m[0m | time: 821.795s
[2K
| Adam | epoch: 015 | loss: 0.22246 - acc: 0.9082 -- iter: 2048/2395
[A[ATraining Step: 1115  | total loss: [1m[32m0.21177[0m[0m | time: 834.540s
[2K
| Adam | epoch: 015 | loss: 0.21177 - acc: 0.9142 -- iter: 2080/2395
[A[ATraining Step: 1116  | total loss: [1m[32m0.19444[0m[0m | time: 847.302s
[2K
| Adam | epoch: 015 | loss: 0.19444 - acc: 0.9228 -- iter: 2112/2395
[A[ATraining Step: 1117  | total loss: [1m[32m0.20136[0m[0m | time: 859.679s
[2K
| Adam | epoch: 015 | loss: 0.20136 - acc: 0.9180 -- iter: 2144/2395
[A[ATraining Step: 1118  | total loss: [1m[32m0.19507[0m[0m | time: 872.779s
[2K
| Adam | epoch: 015 | loss: 0.19507 - acc: 0.9200 -- iter: 2176/2395
[A[ATraining Step: 1119  | total loss: [1m[32m0.18877[0m[0m | time: 885.244s
[2K
| Adam | epoch: 015 | loss: 0.18877 - acc: 0.9249 -- iter: 2208/2395
[A[ATraining Step: 1120  | total loss: [1m[32m0.19990[0m[0m | time: 896.943s
[2K
| Adam | epoch: 015 | loss: 0.19990 - acc: 0.9199 -- iter: 2240/2395
[A[ATraining Step: 1121  | total loss: [1m[32m0.19108[0m[0m | time: 909.720s
[2K
| Adam | epoch: 015 | loss: 0.19108 - acc: 0.9216 -- iter: 2272/2395
[A[ATraining Step: 1122  | total loss: [1m[32m0.18598[0m[0m | time: 922.786s
[2K
| Adam | epoch: 015 | loss: 0.18598 - acc: 0.9232 -- iter: 2304/2395
[A[ATraining Step: 1123  | total loss: [1m[32m0.17495[0m[0m | time: 935.813s
[2K
| Adam | epoch: 015 | loss: 0.17495 - acc: 0.9309 -- iter: 2336/2395
[A[ATraining Step: 1124  | total loss: [1m[32m0.16989[0m[0m | time: 948.818s
[2K
| Adam | epoch: 015 | loss: 0.16989 - acc: 0.9347 -- iter: 2368/2395
[A[ATraining Step: 1125  | total loss: [1m[32m0.16891[0m[0m | time: 1016.451s
[2K
| Adam | epoch: 015 | loss: 0.16891 - acc: 0.9381 | val_loss: 0.80980 - val_acc: 0.7356 -- iter: 2395/2395
--
Validation AUC:0.8058539856468205
Validation AUPRC:0.8075164446460071
Test AUC:0.8381423998170696
Test AUPRC:0.8476703447651468
BestTestF1Score	0.78	0.49	0.74	0.7	0.88	344	147	210	48	0.14
BestTestMCCScore	0.76	0.51	0.76	0.78	0.75	295	85	272	97	0.54
BestTestAccuracyScore	0.76	0.51	0.76	0.78	0.75	295	85	272	97	0.54
BestValidationF1Score	0.75	0.44	0.71	0.67	0.85	327	160	206	56	0.14
BestValidationMCC	0.74	0.49	0.74	0.77	0.71	273	81	285	110	0.54
BestValidationAccuracy	0.74	0.49	0.74	0.77	0.71	273	81	285	110	0.54
TestPredictions (Threshold:0.54)
CHEMBL26372,FP,INACT,0.5699999928474426	CHEMBL2024363,TP,ACT,0.9900000095367432	CHEMBL611127,FP,INACT,0.6299999952316284	CHEMBL426587,TP,ACT,0.699999988079071	CHEMBL1488035,TN,INACT,0.0	CHEMBL258818,TN,INACT,0.0	CHEMBL202695,FP,INACT,0.949999988079071	CHEMBL67655,FP,INACT,0.9800000190734863	CHEMBL2407917,TN,INACT,0.019999999552965164	CHEMBL3652543,TP,ACT,1.0	CHEMBL149401,TN,INACT,0.0	CHEMBL3828491,TP,ACT,0.9900000095367432	CHEMBL3735459,TP,ACT,0.9900000095367432	CHEMBL2071613,TN,INACT,0.15000000596046448	CHEMBL404242,FN,ACT,0.10999999940395355	CHEMBL410926,TP,ACT,0.800000011920929	CHEMBL596073,TP,ACT,1.0	CHEMBL3236668,TN,INACT,0.0	CHEMBL1086734,TP,ACT,0.9800000190734863	CHEMBL402355,TN,INACT,0.019999999552965164	CHEMBL1830265,TN,INACT,0.05000000074505806	CHEMBL3735061,TP,ACT,0.9300000071525574	CHEMBL359554,TP,ACT,1.0	CHEMBL1630458,FN,ACT,0.3199999928474426	CHEMBL411931,FP,INACT,0.8100000023841858	CHEMBL250369,TP,ACT,0.9700000286102295	CHEMBL2386095,TP,ACT,0.9900000095367432	CHEMBL1957089,TP,ACT,0.9599999785423279	CHEMBL77303,FP,INACT,0.6800000071525574	CHEMBL1929555,TN,INACT,0.05999999865889549	CHEMBL3314282,TN,INACT,0.019999999552965164	CHEMBL259804,FP,INACT,0.7900000214576721	CHEMBL160231,TP,ACT,0.8799999952316284	CHEMBL589590,TN,INACT,0.0	CHEMBL1241679,TN,INACT,0.009999999776482582	CHEMBL470380,TP,ACT,1.0	CHEMBL552038,TP,ACT,0.9300000071525574	CHEMBL1957086,TP,ACT,1.0	CHEMBL62701,TN,INACT,0.0	CHEMBL493169,FN,ACT,0.44999998807907104	CHEMBL1682346,TP,ACT,0.6700000166893005	CHEMBL489407,TP,ACT,0.6700000166893005	CHEMBL1241946,TN,INACT,0.0	CHEMBL3398191,TP,ACT,0.9900000095367432	CHEMBL1076682,TP,ACT,1.0	CHEMBL1494345,TN,INACT,0.03999999910593033	CHEMBL1682339,TP,ACT,1.0	CHEMBL1319281,FP,INACT,0.75	CHEMBL261882,TP,ACT,0.5400000214576721	CHEMBL470168,TP,ACT,0.9900000095367432	CHEMBL3358984,TN,INACT,0.05999999865889549	CHEMBL317281,TN,INACT,0.30000001192092896	CHEMBL150573,TN,INACT,0.0	CHEMBL469770,TN,INACT,0.029999999329447746	CHEMBL328164,TP,ACT,0.8700000047683716	CHEMBL2337372,TN,INACT,0.0	CHEMBL334031,TP,ACT,0.9800000190734863	CHEMBL2334794,TN,INACT,0.09000000357627869	CHEMBL3735176,TP,ACT,0.9399999976158142	CHEMBL2335722,FP,INACT,0.9100000262260437	CHEMBL1400863,TN,INACT,0.38999998569488525	CHEMBL308455,FN,ACT,0.05999999865889549	CHEMBL2322988,TN,INACT,0.0	CHEMBL431933,TP,ACT,0.9599999785423279	CHEMBL1241680,TN,INACT,0.2199999988079071	CHEMBL3358980,FP,INACT,1.0	CHEMBL2064400,TN,INACT,0.4099999964237213	CHEMBL2386103,TP,ACT,1.0	CHEMBL1084117,TN,INACT,0.12999999523162842	CHEMBL1940976,TP,ACT,1.0	CHEMBL76642,FP,INACT,0.5899999737739563	CHEMBL312451,TN,INACT,0.0	CHEMBL1940987,TP,ACT,1.0	CHEMBL2336574,TN,INACT,0.009999999776482582	CHEMBL488101,TN,INACT,0.0	CHEMBL67310,TP,ACT,1.0	CHEMBL1242031,TN,INACT,0.0	CHEMBL116545,TP,ACT,0.9700000286102295	CHEMBL565205,TP,ACT,0.9399999976158142	CHEMBL456219,TP,ACT,0.800000011920929	CHEMBL1973073,TN,INACT,0.05000000074505806	CHEMBL1945644,TN,INACT,0.0	CHEMBL2386092,TP,ACT,0.800000011920929	CHEMBL392876,TN,INACT,0.0	CHEMBL2407906,TN,INACT,0.0	CHEMBL2064539,TP,ACT,1.0	CHEMBL1801635,TP,ACT,0.8799999952316284	CHEMBL304172,TP,ACT,1.0	CHEMBL482632,FN,ACT,0.3799999952316284	CHEMBL3735796,TP,ACT,0.8600000143051147	CHEMBL1547186,FN,ACT,0.38999998569488525	CHEMBL1170126,TP,ACT,0.9100000262260437	CHEMBL427909,FN,ACT,0.10000000149011612	CHEMBL3098313,TN,INACT,0.0	CHEMBL1821886,TN,INACT,0.0	CHEMBL109981,TP,ACT,0.9900000095367432	CHEMBL261660,TP,ACT,1.0	CHEMBL3609569,TN,INACT,0.49000000953674316	CHEMBL23840,FN,ACT,0.15000000596046448	CHEMBL251375,TP,ACT,0.9700000286102295	CHEMBL457401,FP,INACT,0.9700000286102295	CHEMBL361833,TP,ACT,0.9800000190734863	CHEMBL498248,TN,INACT,0.28999999165534973	CHEMBL2391102,TP,ACT,0.5400000214576721	CHEMBL1458559,TN,INACT,0.3400000035762787	CHEMBL571486,FN,ACT,0.009999999776482582	CHEMBL85129,TN,INACT,0.009999999776482582	CHEMBL383104,TP,ACT,0.9700000286102295	CHEMBL2163771,FN,ACT,0.0	CHEMBL1078219,TN,INACT,0.0	CHEMBL2401960,TN,INACT,0.019999999552965164	CHEMBL261549,TP,ACT,1.0	CHEMBL1374352,TN,INACT,0.3100000023841858	CHEMBL1767275,TN,INACT,0.029999999329447746	CHEMBL1276127,FN,ACT,0.10999999940395355	CHEMBL160938,TP,ACT,0.9900000095367432	CHEMBL318471,TP,ACT,0.9100000262260437	CHEMBL456378,TN,INACT,0.0	CHEMBL3659984,TN,INACT,0.05000000074505806	CHEMBL2337362,TN,INACT,0.18000000715255737	CHEMBL552500,FN,ACT,0.44999998807907104	CHEMBL1684800,FN,ACT,0.0	CHEMBL576353,TN,INACT,0.0	CHEMBL1172602,TN,INACT,0.009999999776482582	CHEMBL1586967,FP,INACT,0.6899999976158142	CHEMBL496779,TP,ACT,0.7200000286102295	CHEMBL191384,TP,ACT,0.9800000190734863	CHEMBL1682545,TP,ACT,0.9800000190734863	CHEMBL3093051,FN,ACT,0.4000000059604645	CHEMBL248312,TN,INACT,0.009999999776482582	CHEMBL3110142,TP,ACT,1.0	CHEMBL1222565,TN,INACT,0.009999999776482582	CHEMBL1870845,TP,ACT,1.0	CHEMBL280074,TN,INACT,0.14000000059604645	CHEMBL3680464,TN,INACT,0.0	CHEMBL1896181,FN,ACT,0.0	CHEMBL606039,TN,INACT,0.029999999329447746	CHEMBL1682544,TP,ACT,0.8600000143051147	CHEMBL103506,TP,ACT,0.8500000238418579	CHEMBL2205454,TN,INACT,0.0	CHEMBL3735246,TP,ACT,1.0	CHEMBL256307,TP,ACT,0.949999988079071	CHEMBL474807,FP,INACT,0.8100000023841858	CHEMBL95477,TP,ACT,1.0	CHEMBL3735220,TP,ACT,1.0	CHEMBL2386096,TP,ACT,0.9900000095367432	CHEMBL334439,FP,INACT,0.6399999856948853	CHEMBL401056,TP,ACT,0.7900000214576721	CHEMBL516640,TP,ACT,0.9700000286102295	CHEMBL1957949,TP,ACT,1.0	CHEMBL63595,TP,ACT,0.9900000095367432	CHEMBL502585,TN,INACT,0.009999999776482582	CHEMBL1210310,TP,ACT,1.0	CHEMBL188938,TP,ACT,0.9900000095367432	CHEMBL3356449,TN,INACT,0.3499999940395355	CHEMBL1371386,TN,INACT,0.0	CHEMBL3401123,FN,ACT,0.20999999344348907	CHEMBL2348180,FP,INACT,0.7200000286102295	CHEMBL582853,FN,ACT,0.27000001072883606	CHEMBL1957094,TP,ACT,0.9900000095367432	CHEMBL457179,TN,INACT,0.0	CHEMBL520515,TN,INACT,0.0	CHEMBL396614,TP,ACT,1.0	CHEMBL2391129,TP,ACT,1.0	CHEMBL1454635,TN,INACT,0.3100000023841858	CHEMBL3734776,TP,ACT,0.9599999785423279	CHEMBL142824,TP,ACT,0.9599999785423279	CHEMBL255735,FN,ACT,0.28999999165534973	CHEMBL486302,TN,INACT,0.20000000298023224	CHEMBL3099839,TP,ACT,0.9700000286102295	CHEMBL160598,TP,ACT,0.9599999785423279	CHEMBL1834315,TP,ACT,0.9200000166893005	CHEMBL1682352,TP,ACT,0.9900000095367432	CHEMBL2310935,TN,INACT,0.0	CHEMBL2163985,TN,INACT,0.07000000029802322	CHEMBL3805409,TN,INACT,0.009999999776482582	CHEMBL450383,TN,INACT,0.0	CHEMBL486487,TN,INACT,0.0	CHEMBL395132,TN,INACT,0.019999999552965164	CHEMBL1480110,TN,INACT,0.029999999329447746	CHEMBL74645,TN,INACT,0.019999999552965164	CHEMBL1957946,TP,ACT,1.0	CHEMBL2022282,TN,INACT,0.0	CHEMBL1957079,TP,ACT,0.8899999856948853	CHEMBL2334799,TN,INACT,0.0	CHEMBL398243,TN,INACT,0.009999999776482582	CHEMBL3221395,TP,ACT,1.0	CHEMBL2203556,FN,ACT,0.2800000011920929	CHEMBL1084684,TP,ACT,0.9800000190734863	CHEMBL3190499,TN,INACT,0.009999999776482582	CHEMBL160743,TP,ACT,0.7099999785423279	CHEMBL498203,TN,INACT,0.1599999964237213	CHEMBL1086174,TP,ACT,1.0	CHEMBL1630488,TP,ACT,0.9800000190734863	CHEMBL3810033,TN,INACT,0.0	CHEMBL325353,TP,ACT,0.9399999976158142	CHEMBL300936,FP,INACT,0.9900000095367432	CHEMBL596290,TP,ACT,0.9900000095367432	CHEMBL187431,TN,INACT,0.009999999776482582	CHEMBL151823,TN,INACT,0.019999999552965164	CHEMBL1521195,TP,ACT,0.8600000143051147	CHEMBL256306,TP,ACT,0.9900000095367432	CHEMBL2029520,TN,INACT,0.029999999329447746	CHEMBL304271,TN,INACT,0.46000000834465027	CHEMBL77243,TN,INACT,0.3100000023841858	CHEMBL2409596,TN,INACT,0.0	CHEMBL88962,FP,INACT,0.550000011920929	CHEMBL1081446,FN,ACT,0.10000000149011612	CHEMBL325403,TP,ACT,1.0	CHEMBL1086782,TP,ACT,1.0	CHEMBL1821881,TN,INACT,0.0	CHEMBL3421968,TN,INACT,0.46000000834465027	CHEMBL254155,FN,ACT,0.03999999910593033	CHEMBL453336,FP,INACT,0.9800000190734863	CHEMBL504416,TN,INACT,0.0	CHEMBL2062565,TP,ACT,0.9800000190734863	CHEMBL1077085,TN,INACT,0.009999999776482582	CHEMBL1957088,TP,ACT,0.9599999785423279	CHEMBL3609656,TN,INACT,0.3100000023841858	CHEMBL34704,TN,INACT,0.0	CHEMBL343821,TN,INACT,0.019999999552965164	CHEMBL2391615,FP,INACT,0.9900000095367432	CHEMBL333829,FN,ACT,0.23000000417232513	CHEMBL103055,TP,ACT,0.9700000286102295	CHEMBL560245,TN,INACT,0.12999999523162842	CHEMBL260463,TP,ACT,0.9100000262260437	CHEMBL3736167,TP,ACT,0.9900000095367432	CHEMBL86631,TN,INACT,0.009999999776482582	CHEMBL1242379,TN,INACT,0.33000001311302185	CHEMBL523747,TN,INACT,0.4399999976158142	CHEMBL2391118,TP,ACT,1.0	CHEMBL503074,FP,INACT,0.9399999976158142	CHEMBL469346,FP,INACT,0.7699999809265137	CHEMBL2062581,TP,ACT,0.9900000095367432	CHEMBL109525,TN,INACT,0.5	CHEMBL1210405,TP,ACT,0.9700000286102295	CHEMBL2391119,TP,ACT,1.0	CHEMBL1682550,TP,ACT,0.9300000071525574	CHEMBL1630434,TP,ACT,0.8899999856948853	CHEMBL287864,TP,ACT,0.5699999928474426	CHEMBL1834125,TP,ACT,0.9599999785423279	CHEMBL178737,TP,ACT,0.9399999976158142	CHEMBL1630578,TN,INACT,0.0	CHEMBL3401117,TP,ACT,0.9900000095367432	CHEMBL1242025,FP,INACT,0.7799999713897705	CHEMBL3134612,TN,INACT,0.009999999776482582	CHEMBL76559,FN,ACT,0.49000000953674316	CHEMBL150825,FP,INACT,0.9599999785423279	CHEMBL3735529,TP,ACT,1.0	CHEMBL599027,TN,INACT,0.0	CHEMBL134354,TN,INACT,0.0	CHEMBL306865,TP,ACT,1.0	CHEMBL1088145,FN,ACT,0.18000000715255737	CHEMBL25927,TN,INACT,0.4399999976158142	CHEMBL513354,TP,ACT,0.9700000286102295	CHEMBL598025,FP,INACT,0.8199999928474426	CHEMBL1403868,TN,INACT,0.27000001072883606	CHEMBL2337363,TN,INACT,0.0	CHEMBL345212,TP,ACT,1.0	CHEMBL474015,TN,INACT,0.4699999988079071	CHEMBL189617,TP,ACT,0.9900000095367432	CHEMBL2216905,TN,INACT,0.0	CHEMBL188087,TN,INACT,0.0	CHEMBL1809120,TP,ACT,0.9900000095367432	CHEMBL1524458,FP,INACT,0.9800000190734863	CHEMBL3401121,TP,ACT,0.9800000190734863	CHEMBL2048679,TP,ACT,0.9599999785423279	CHEMBL203407,TP,ACT,0.5799999833106995	CHEMBL328623,TN,INACT,0.5099999904632568	CHEMBL3652541,FN,ACT,0.27000001072883606	CHEMBL470567,TP,ACT,0.6700000166893005	CHEMBL2322993,TN,INACT,0.009999999776482582	CHEMBL2163627,TN,INACT,0.03999999910593033	CHEMBL3421636,FP,INACT,0.9599999785423279	CHEMBL2177167,TP,ACT,0.9900000095367432	CHEMBL1536681,FP,INACT,0.9300000071525574	CHEMBL560585,FN,ACT,0.1599999964237213	CHEMBL1525418,TN,INACT,0.009999999776482582	CHEMBL1257164,TN,INACT,0.009999999776482582	CHEMBL1538986,TP,ACT,0.9399999976158142	CHEMBL3197413,TN,INACT,0.15000000596046448	CHEMBL1095038,TP,ACT,1.0	CHEMBL1682341,TP,ACT,0.9900000095367432	CHEMBL76985,TN,INACT,0.019999999552965164	CHEMBL578628,TP,ACT,0.9599999785423279	CHEMBL24494,FN,ACT,0.0	CHEMBL175956,TP,ACT,1.0	CHEMBL523938,TN,INACT,0.10000000149011612	CHEMBL3099834,TP,ACT,0.9900000095367432	CHEMBL2062585,FN,ACT,0.5099999904632568	CHEMBL3099837,TP,ACT,1.0	CHEMBL68418,FP,INACT,0.7799999713897705	CHEMBL459575,FN,ACT,0.029999999329447746	CHEMBL3093045,TP,ACT,0.9700000286102295	CHEMBL487190,FP,INACT,0.5699999928474426	CHEMBL1956892,TN,INACT,0.0	CHEMBL366668,TP,ACT,0.8799999952316284	CHEMBL360878,TP,ACT,0.9300000071525574	CHEMBL1682359,TP,ACT,1.0	CHEMBL2334797,TN,INACT,0.0	CHEMBL3214457,FP,INACT,0.7400000095367432	CHEMBL349810,TP,ACT,0.8399999737739563	CHEMBL1922210,TN,INACT,0.019999999552965164	CHEMBL456964,TN,INACT,0.0	CHEMBL111443,TN,INACT,0.27000001072883606	CHEMBL1910755,TN,INACT,0.3100000023841858	CHEMBL3398195,FN,ACT,0.07999999821186066	CHEMBL1938953,FN,ACT,0.029999999329447746	CHEMBL228862,TN,INACT,0.18000000715255737	CHEMBL324399,FP,INACT,0.8999999761581421	CHEMBL2064518,TP,ACT,0.9900000095367432	CHEMBL522751,TP,ACT,0.7900000214576721	CHEMBL1801612,TN,INACT,0.0	CHEMBL590962,TN,INACT,0.0	CHEMBL342280,TN,INACT,0.0	CHEMBL466701,TN,INACT,0.019999999552965164	CHEMBL63348,TP,ACT,1.0	CHEMBL138041,TN,INACT,0.009999999776482582	CHEMBL2437484,FP,INACT,0.7200000286102295	CHEMBL3735603,TP,ACT,0.7099999785423279	CHEMBL438075,TN,INACT,0.009999999776482582	CHEMBL77540,FN,ACT,0.0	CHEMBL558601,TN,INACT,0.0	CHEMBL3197885,TN,INACT,0.0	CHEMBL1828880,FP,INACT,0.6399999856948853	CHEMBL3633690,TN,INACT,0.38999998569488525	CHEMBL2011305,FP,INACT,0.6299999952316284	CHEMBL253956,FN,ACT,0.03999999910593033	CHEMBL223147,FN,ACT,0.029999999329447746	CHEMBL2023161,FP,INACT,0.5600000023841858	CHEMBL398621,TP,ACT,0.9399999976158142	CHEMBL109944,TP,ACT,0.9900000095367432	CHEMBL2392240,TN,INACT,0.0	CHEMBL3639599,TN,INACT,0.2199999988079071	CHEMBL522760,TP,ACT,0.699999988079071	CHEMBL3410097,TP,ACT,0.9200000166893005	CHEMBL143743,FN,ACT,0.1599999964237213	CHEMBL2036728,TN,INACT,0.38999998569488525	CHEMBL573487,TP,ACT,0.8299999833106995	CHEMBL1162963,TP,ACT,1.0	CHEMBL1171329,TN,INACT,0.009999999776482582	CHEMBL192489,TN,INACT,0.009999999776482582	CHEMBL1630466,TP,ACT,0.9900000095367432	CHEMBL254794,TP,ACT,1.0	CHEMBL2024368,TP,ACT,0.5699999928474426	CHEMBL495751,FN,ACT,0.1899999976158142	CHEMBL2334791,TN,INACT,0.0	CHEMBL2377825,TP,ACT,0.800000011920929	CHEMBL3735382,TP,ACT,0.6200000047683716	CHEMBL1958321,TN,INACT,0.07999999821186066	CHEMBL550950,FN,ACT,0.15000000596046448	CHEMBL307179,TN,INACT,0.1599999964237213	CHEMBL1081632,TP,ACT,0.7200000286102295	CHEMBL112819,TP,ACT,1.0	CHEMBL207297,TN,INACT,0.44999998807907104	CHEMBL3355540,TN,INACT,0.3799999952316284	CHEMBL1957948,TP,ACT,1.0	CHEMBL257992,TP,ACT,0.8700000047683716	CHEMBL2047252,TN,INACT,0.0	CHEMBL1241659,TP,ACT,0.800000011920929	CHEMBL1375423,TN,INACT,0.0	CHEMBL561929,FN,ACT,0.20000000298023224	CHEMBL188417,TP,ACT,1.0	CHEMBL158835,TP,ACT,1.0	CHEMBL407958,TP,ACT,1.0	CHEMBL77590,FN,ACT,0.09000000357627869	CHEMBL1414543,TN,INACT,0.1599999964237213	CHEMBL2022423,TP,ACT,0.8999999761581421	CHEMBL2312649,FP,INACT,0.8700000047683716	CHEMBL1688206,FP,INACT,0.6299999952316284	CHEMBL1076721,TP,ACT,0.9599999785423279	CHEMBL259380,FP,INACT,0.5899999737739563	CHEMBL63803,TP,ACT,1.0	CHEMBL111005,TP,ACT,0.9200000166893005	CHEMBL89697,TN,INACT,0.05000000074505806	CHEMBL3647951,TP,ACT,0.550000011920929	CHEMBL1098943,FN,ACT,0.3100000023841858	CHEMBL1956885,TN,INACT,0.029999999329447746	CHEMBL941,TN,INACT,0.009999999776482582	CHEMBL3093040,FN,ACT,0.0	CHEMBL2425628,TP,ACT,0.949999988079071	CHEMBL321315,FN,ACT,0.1899999976158142	CHEMBL2386090,TP,ACT,0.9900000095367432	CHEMBL305901,FN,ACT,0.27000001072883606	CHEMBL334084,TP,ACT,1.0	CHEMBL405145,TP,ACT,1.0	CHEMBL26274,TP,ACT,0.8999999761581421	CHEMBL3700566,TN,INACT,0.029999999329447746	CHEMBL346200,TN,INACT,0.07999999821186066	CHEMBL489646,TN,INACT,0.4099999964237213	CHEMBL1688209,TN,INACT,0.009999999776482582	CHEMBL98554,FN,ACT,0.10000000149011612	CHEMBL497454,TN,INACT,0.0	CHEMBL1957230,FN,ACT,0.5199999809265137	CHEMBL2335379,TN,INACT,0.0	CHEMBL2386101,TP,ACT,1.0	CHEMBL3680482,FP,INACT,0.8100000023841858	CHEMBL1423507,TN,INACT,0.1599999964237213	CHEMBL300817,TN,INACT,0.009999999776482582	CHEMBL552136,TN,INACT,0.0	CHEMBL187139,TP,ACT,0.9300000071525574	CHEMBL3735837,TP,ACT,1.0	CHEMBL2425110,FP,INACT,0.6000000238418579	CHEMBL522916,FP,INACT,0.8999999761581421	CHEMBL3091534,TP,ACT,1.0	CHEMBL186054,FN,ACT,0.5	CHEMBL538798,TN,INACT,0.0	CHEMBL2205467,FP,INACT,0.8899999856948853	CHEMBL2048664,TP,ACT,0.9599999785423279	CHEMBL1688204,TN,INACT,0.0	CHEMBL490053,FP,INACT,0.8299999833106995	CHEMBL1630431,FN,ACT,0.05000000074505806	CHEMBL3314279,TN,INACT,0.0	CHEMBL1682842,TP,ACT,0.8700000047683716	CHEMBL1082010,TP,ACT,1.0	CHEMBL523780,TN,INACT,0.019999999552965164	CHEMBL490860,TP,ACT,1.0	CHEMBL1630436,FN,ACT,0.0	CHEMBL470167,TP,ACT,0.9900000095367432	CHEMBL1830266,TN,INACT,0.03999999910593033	CHEMBL3110138,TP,ACT,1.0	CHEMBL2391117,TP,ACT,1.0	CHEMBL2032373,TN,INACT,0.09000000357627869	CHEMBL3800262,TN,INACT,0.019999999552965164	CHEMBL3393897,TN,INACT,0.5099999904632568	CHEMBL3736196,FN,ACT,0.3799999952316284	CHEMBL300138,TP,ACT,0.9800000190734863	CHEMBL362086,TP,ACT,0.9900000095367432	CHEMBL1208823,TN,INACT,0.0	CHEMBL3735962,TP,ACT,1.0	CHEMBL1241772,TN,INACT,0.30000001192092896	CHEMBL156263,TP,ACT,0.9900000095367432	CHEMBL2047250,TN,INACT,0.0	CHEMBL2426377,FP,INACT,1.0	CHEMBL401654,TP,ACT,1.0	CHEMBL175845,FN,ACT,0.0	CHEMBL1570672,TN,INACT,0.03999999910593033	CHEMBL1088348,TN,INACT,0.05000000074505806	CHEMBL425615,TN,INACT,0.47999998927116394	CHEMBL278287,FP,INACT,0.9700000286102295	CHEMBL2047246,TN,INACT,0.0	CHEMBL80785,FN,ACT,0.05000000074505806	CHEMBL404689,TP,ACT,0.9399999976158142	CHEMBL1956888,TN,INACT,0.0	CHEMBL98501,TP,ACT,0.9700000286102295	CHEMBL2437477,TN,INACT,0.05000000074505806	CHEMBL2048663,TP,ACT,0.9800000190734863	CHEMBL1241299,TN,INACT,0.029999999329447746	CHEMBL1519409,TN,INACT,0.009999999776482582	CHEMBL3410087,TP,ACT,1.0	CHEMBL1809197,TN,INACT,0.0	CHEMBL470565,TP,ACT,0.8500000238418579	CHEMBL726,FP,INACT,0.5899999737739563	CHEMBL2420911,TN,INACT,0.38999998569488525	CHEMBL1452914,TN,INACT,0.0	CHEMBL259381,FP,INACT,0.9200000166893005	CHEMBL575021,TP,ACT,0.9900000095367432	CHEMBL1834118,TP,ACT,0.9399999976158142	CHEMBL1454264,FP,INACT,0.949999988079071	CHEMBL1944931,FP,INACT,1.0	CHEMBL2048676,TP,ACT,0.5400000214576721	CHEMBL1630442,TP,ACT,0.75	CHEMBL523487,TN,INACT,0.05999999865889549	CHEMBL3645543,TN,INACT,0.0	CHEMBL189459,TP,ACT,0.5799999833106995	CHEMBL3661096,TN,INACT,0.0	CHEMBL2391101,FN,ACT,0.10000000149011612	CHEMBL1682343,FN,ACT,0.3400000035762787	CHEMBL254350,FN,ACT,0.5299999713897705	CHEMBL1426468,TN,INACT,0.0	CHEMBL399914,TN,INACT,0.0	CHEMBL85403,TN,INACT,0.009999999776482582	CHEMBL3314285,TN,INACT,0.10000000149011612	CHEMBL261661,TP,ACT,1.0	CHEMBL142711,TP,ACT,0.7300000190734863	CHEMBL1956894,TN,INACT,0.0	CHEMBL2426289,FP,INACT,0.8799999952316284	CHEMBL181959,TP,ACT,0.949999988079071	CHEMBL2024375,TP,ACT,0.9300000071525574	CHEMBL318522,TP,ACT,1.0	CHEMBL1630452,TP,ACT,0.9300000071525574	CHEMBL1527654,TN,INACT,0.0	CHEMBL99280,TP,ACT,1.0	CHEMBL158559,TP,ACT,0.6899999976158142	CHEMBL111298,TP,ACT,0.9900000095367432	CHEMBL1241864,TN,INACT,0.03999999910593033	CHEMBL284365,TP,ACT,1.0	CHEMBL257188,TP,ACT,0.9800000190734863	CHEMBL1428357,TN,INACT,0.0	CHEMBL584640,TN,INACT,0.009999999776482582	CHEMBL481248,TN,INACT,0.0	CHEMBL69151,FP,INACT,0.949999988079071	CHEMBL1809113,FN,ACT,0.3499999940395355	CHEMBL419273,TP,ACT,0.8299999833106995	CHEMBL140061,TP,ACT,0.9700000286102295	CHEMBL185922,TP,ACT,0.9100000262260437	CHEMBL3673983,FN,ACT,0.10999999940395355	CHEMBL74015,FN,ACT,0.029999999329447746	CHEMBL261596,TP,ACT,1.0	CHEMBL2011299,TN,INACT,0.05999999865889549	CHEMBL367625,TN,INACT,0.23999999463558197	CHEMBL1087243,TP,ACT,0.9300000071525574	CHEMBL569998,TP,ACT,0.7699999809265137	CHEMBL187750,TP,ACT,1.0	CHEMBL345364,TP,ACT,0.8500000238418579	CHEMBL2182002,TP,ACT,1.0	CHEMBL563387,TN,INACT,0.0	CHEMBL368248,TP,ACT,1.0	CHEMBL1241682,TN,INACT,0.0	CHEMBL486285,TN,INACT,0.1899999976158142	CHEMBL105348,TP,ACT,0.9300000071525574	CHEMBL561066,FN,ACT,0.05999999865889549	CHEMBL543600,TN,INACT,0.41999998688697815	CHEMBL3586175,FP,INACT,0.7699999809265137	CHEMBL218301,FN,ACT,0.029999999329447746	CHEMBL332342,TN,INACT,0.009999999776482582	CHEMBL3673434,FN,ACT,0.11999999731779099	CHEMBL401918,FN,ACT,0.07000000029802322	CHEMBL87746,TN,INACT,0.019999999552965164	CHEMBL3673435,FN,ACT,0.1899999976158142	CHEMBL256559,TP,ACT,0.949999988079071	CHEMBL501709,TN,INACT,0.25	CHEMBL381932,TN,INACT,0.0	CHEMBL1831216,TN,INACT,0.009999999776482582	CHEMBL478798,TN,INACT,0.019999999552965164	CHEMBL296468,FN,ACT,0.17000000178813934	CHEMBL3218291,TN,INACT,0.03999999910593033	CHEMBL1081429,TP,ACT,1.0	CHEMBL280998,FP,INACT,0.8899999856948853	CHEMBL57690,TN,INACT,0.05000000074505806	CHEMBL1821888,TN,INACT,0.0	CHEMBL1288067,TN,INACT,0.07999999821186066	CHEMBL1254199,TN,INACT,0.029999999329447746	CHEMBL1630477,TP,ACT,0.9900000095367432	CHEMBL1809110,FN,ACT,0.25	CHEMBL1370652,TN,INACT,0.23000000417232513	CHEMBL1762119,TN,INACT,0.07000000029802322	CHEMBL120664,FN,ACT,0.0	CHEMBL157348,TP,ACT,0.9700000286102295	CHEMBL507249,TP,ACT,0.9800000190734863	CHEMBL2180881,FN,ACT,0.28999999165534973	CHEMBL1910373,FP,INACT,0.949999988079071	CHEMBL3827727,TP,ACT,0.9900000095367432	CHEMBL3616869,FP,INACT,0.8700000047683716	CHEMBL101052,FP,INACT,0.949999988079071	CHEMBL3398192,FN,ACT,0.5299999713897705	CHEMBL2386274,FN,ACT,0.4699999988079071	CHEMBL331783,TP,ACT,0.949999988079071	CHEMBL2063002,TP,ACT,0.7699999809265137	CHEMBL1087499,TP,ACT,0.9300000071525574	CHEMBL187081,TP,ACT,0.7900000214576721	CHEMBL156524,FN,ACT,0.46000000834465027	CHEMBL3110135,TP,ACT,1.0	CHEMBL48614,TN,INACT,0.0	CHEMBL584,TN,INACT,0.029999999329447746	CHEMBL264161,TP,ACT,0.9900000095367432	CHEMBL457180,TN,INACT,0.1899999976158142	CHEMBL3093054,TP,ACT,1.0	CHEMBL3091539,TP,ACT,1.0	CHEMBL25820,TP,ACT,0.949999988079071	CHEMBL3765711,TP,ACT,0.5600000023841858	CHEMBL3633278,TN,INACT,0.10000000149011612	CHEMBL2011301,TN,INACT,0.05999999865889549	CHEMBL100811,TN,INACT,0.10999999940395355	CHEMBL154969,TN,INACT,0.0	CHEMBL458210,TP,ACT,0.9700000286102295	CHEMBL1975622,TN,INACT,0.029999999329447746	CHEMBL521201,FP,INACT,0.7200000286102295	CHEMBL2334723,FP,INACT,0.8799999952316284	CHEMBL3398197,FN,ACT,0.25999999046325684	CHEMBL351801,TP,ACT,0.9100000262260437	CHEMBL471015,TP,ACT,0.9800000190734863	CHEMBL1080271,TN,INACT,0.0	CHEMBL1414671,FP,INACT,0.6100000143051147	CHEMBL186288,TP,ACT,1.0	CHEMBL1080901,FN,ACT,0.03999999910593033	CHEMBL3735772,TP,ACT,0.9800000190734863	CHEMBL104,FP,INACT,1.0	CHEMBL101868,FP,INACT,0.9700000286102295	CHEMBL77217,TP,ACT,0.9800000190734863	CHEMBL1555880,FP,INACT,0.9800000190734863	CHEMBL319709,TN,INACT,0.0	CHEMBL2064532,TP,ACT,1.0	CHEMBL2322141,FP,INACT,0.9800000190734863	CHEMBL3661093,TN,INACT,0.019999999552965164	CHEMBL2022420,TP,ACT,0.9599999785423279	CHEMBL1783682,TN,INACT,0.07999999821186066	CHEMBL595944,TP,ACT,1.0	CHEMBL3665666,TN,INACT,0.009999999776482582	CHEMBL402541,TP,ACT,0.8199999928474426	CHEMBL1242029,TN,INACT,0.009999999776482582	CHEMBL2064521,TP,ACT,0.9599999785423279	CHEMBL2283258,TN,INACT,0.07999999821186066	CHEMBL149458,FP,INACT,0.8799999952316284	CHEMBL1577147,FP,INACT,0.9700000286102295	CHEMBL1081070,FN,ACT,0.11999999731779099	CHEMBL67733,TP,ACT,0.9900000095367432	CHEMBL588859,FN,ACT,0.5	CHEMBL3609564,TN,INACT,0.41999998688697815	CHEMBL522892,TP,ACT,0.949999988079071	CHEMBL123046,FP,INACT,1.0	CHEMBL245934,TN,INACT,0.05000000074505806	CHEMBL408634,FN,ACT,0.0	CHEMBL445757,FP,INACT,0.9900000095367432	CHEMBL489246,FP,INACT,0.9900000095367432	CHEMBL513330,FN,ACT,0.009999999776482582	CHEMBL24693,TP,ACT,0.8799999952316284	CHEMBL3218002,TN,INACT,0.25	CHEMBL1208885,TN,INACT,0.15000000596046448	CHEMBL3780912,TN,INACT,0.0	CHEMBL495696,TP,ACT,0.9399999976158142	CHEMBL1956896,TN,INACT,0.07999999821186066	CHEMBL1834116,TP,ACT,0.5600000023841858	CHEMBL1331525,FP,INACT,0.7799999713897705	CHEMBL1650951,FN,ACT,0.029999999329447746	CHEMBL509553,TN,INACT,0.0	CHEMBL256518,FN,ACT,0.0	CHEMBL156563,TP,ACT,0.9800000190734863	CHEMBL113356,TN,INACT,0.05999999865889549	CHEMBL2391621,TN,INACT,0.2199999988079071	CHEMBL3093035,FN,ACT,0.0	CHEMBL1095465,FP,INACT,0.9700000286102295	CHEMBL1077670,FN,ACT,0.09000000357627869	CHEMBL101557,FP,INACT,0.9599999785423279	CHEMBL277931,TN,INACT,0.0	CHEMBL2177179,TP,ACT,0.6100000143051147	CHEMBL3673984,FN,ACT,0.14000000059604645	CHEMBL1172418,TN,INACT,0.10999999940395355	CHEMBL2386094,FN,ACT,0.4399999976158142	CHEMBL2024359,TP,ACT,1.0	CHEMBL117114,TN,INACT,0.2199999988079071	CHEMBL294037,TN,INACT,0.4099999964237213	CHEMBL260662,FN,ACT,0.49000000953674316	CHEMBL1834328,FN,ACT,0.3400000035762787	CHEMBL6291,TP,ACT,0.9700000286102295	CHEMBL88466,TN,INACT,0.0	CHEMBL3358993,TN,INACT,0.14000000059604645	CHEMBL134501,TP,ACT,1.0	CHEMBL2392379,TN,INACT,0.05000000074505806	CHEMBL3828150,TP,ACT,0.6299999952316284	CHEMBL484950,TP,ACT,0.8299999833106995	CHEMBL3104854,TN,INACT,0.009999999776482582	CHEMBL3746351,FP,INACT,1.0	CHEMBL261883,TP,ACT,0.9100000262260437	CHEMBL1600077,TN,INACT,0.10000000149011612	CHEMBL347632,TP,ACT,0.5400000214576721	CHEMBL1080114,TN,INACT,0.029999999329447746	CHEMBL2047245,TN,INACT,0.0	CHEMBL2022413,FN,ACT,0.44999998807907104	CHEMBL56964,TN,INACT,0.5	CHEMBL2048670,TP,ACT,0.9599999785423279	CHEMBL1940977,TP,ACT,1.0	CHEMBL62843,TN,INACT,0.0	CHEMBL2391132,TP,ACT,1.0	CHEMBL593628,TP,ACT,0.8999999761581421	CHEMBL359482,FN,ACT,0.03999999910593033	CHEMBL434484,TP,ACT,0.9900000095367432	CHEMBL69526,TP,ACT,0.7900000214576721	CHEMBL299987,TN,INACT,0.0	CHEMBL395077,FP,INACT,0.8700000047683716	CHEMBL559683,TN,INACT,0.0	CHEMBL489413,TP,ACT,0.9900000095367432	CHEMBL187007,FP,INACT,0.8100000023841858	CHEMBL305718,TN,INACT,0.0	CHEMBL1464354,FN,ACT,0.019999999552965164	CHEMBL1536771,TN,INACT,0.019999999552965164	CHEMBL112564,TP,ACT,0.5799999833106995	CHEMBL66004,FN,ACT,0.14000000059604645	CHEMBL1731237,FN,ACT,0.03999999910593033	CHEMBL1086780,TP,ACT,0.7900000214576721	CHEMBL2177668,TN,INACT,0.019999999552965164	CHEMBL183504,TP,ACT,0.8399999737739563	CHEMBL2037482,TP,ACT,0.8500000238418579	CHEMBL3746387,TN,INACT,0.3799999952316284	CHEMBL552265,TP,ACT,0.9700000286102295	CHEMBL253769,TP,ACT,0.6899999976158142	CHEMBL398622,TP,ACT,0.9200000166893005	CHEMBL58436,TN,INACT,0.0	CHEMBL2048678,TP,ACT,1.0	CHEMBL3735527,TP,ACT,0.9200000166893005	CHEMBL1087421,FP,INACT,0.9200000166893005	CHEMBL410485,TN,INACT,0.4699999988079071	CHEMBL256139,FN,ACT,0.019999999552965164	CHEMBL24753,TP,ACT,0.949999988079071	CHEMBL2064531,TP,ACT,1.0	CHEMBL158719,TP,ACT,1.0	CHEMBL1940909,TP,ACT,0.9800000190734863	CHEMBL3091542,TP,ACT,0.5400000214576721	CHEMBL151,FN,ACT,0.009999999776482582	CHEMBL3358991,TN,INACT,0.03999999910593033	CHEMBL1085927,TP,ACT,0.6299999952316284	CHEMBL1433424,TP,ACT,0.9900000095367432	CHEMBL3735681,TP,ACT,1.0	CHEMBL3401115,TP,ACT,0.9900000095367432	CHEMBL361723,FN,ACT,0.41999998688697815	CHEMBL2425139,FP,INACT,0.8799999952316284	CHEMBL1242663,FP,INACT,0.6600000262260437	CHEMBL285527,TN,INACT,0.5199999809265137	CHEMBL2392392,TN,INACT,0.0	CHEMBL2086738,TN,INACT,0.009999999776482582	CHEMBL3109404,FP,INACT,0.8399999737739563	CHEMBL604748,TN,INACT,0.0	CHEMBL2386105,TP,ACT,0.8799999952316284	CHEMBL1828881,TN,INACT,0.14000000059604645	CHEMBL3735779,TP,ACT,1.0	CHEMBL1505364,FP,INACT,0.7300000190734863	CHEMBL1809116,FN,ACT,0.0	CHEMBL3093050,TP,ACT,1.0	CHEMBL1933806,TN,INACT,0.2800000011920929	CHEMBL392167,TP,ACT,0.9200000166893005	CHEMBL597628,TN,INACT,0.10999999940395355	CHEMBL451857,TP,ACT,0.9800000190734863	CHEMBL2393377,TN,INACT,0.0	CHEMBL406644,TP,ACT,0.949999988079071	CHEMBL1940905,TP,ACT,0.9700000286102295	CHEMBL549303,TN,INACT,0.0	CHEMBL1092013,FP,INACT,0.8999999761581421	CHEMBL325817,TP,ACT,1.0	CHEMBL75637,FP,INACT,0.8899999856948853	CHEMBL2048659,FN,ACT,0.1599999964237213	CHEMBL2322677,TP,ACT,0.699999988079071	CHEMBL182007,TP,ACT,0.8100000023841858	CHEMBL26101,TN,INACT,0.009999999776482582	CHEMBL77085,FP,INACT,0.9300000071525574	CHEMBL1241775,TN,INACT,0.0	CHEMBL3651966,FN,ACT,0.3199999928474426	CHEMBL399696,FN,ACT,0.03999999910593033	CHEMBL2036725,FP,INACT,0.7699999809265137	CHEMBL498130,TN,INACT,0.0	CHEMBL3691604,TN,INACT,0.009999999776482582	CHEMBL318208,TP,ACT,0.9900000095367432	CHEMBL7463,TP,ACT,0.9700000286102295	CHEMBL56319,TN,INACT,0.0	CHEMBL1095463,TN,INACT,0.019999999552965164	CHEMBL3109401,TN,INACT,0.0	CHEMBL63414,TP,ACT,1.0	CHEMBL3639713,FP,INACT,0.8600000143051147	CHEMBL3647952,FN,ACT,0.1899999976158142	CHEMBL186476,TP,ACT,0.9800000190734863	CHEMBL559559,TP,ACT,1.0	CHEMBL308430,TP,ACT,1.0	CHEMBL3410103,TP,ACT,1.0	CHEMBL3091547,TP,ACT,0.949999988079071	CHEMBL3360318,FN,ACT,0.009999999776482582	CHEMBL3098319,TN,INACT,0.0	CHEMBL1809111,TP,ACT,0.8399999737739563	CHEMBL3665657,TN,INACT,0.009999999776482582	CHEMBL186116,TP,ACT,1.0	CHEMBL3665665,TN,INACT,0.0	

