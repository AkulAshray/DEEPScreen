CNNModel CHEMBL1951 adam 0.0005 30 128 0 0.8 False True
Number of active compounds :	1005
Number of inactive compounds :	1005
---------------------------------
Run id: CNNModel_CHEMBL1951_adam_0.0005_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1951_adam_0.0005_30_128_0.8_True/
---------------------------------
Training samples: 1263
Validation samples: 395
--
Training Step: 1  | time: 0.859s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1263
[A[ATraining Step: 2  | total loss: [1m[32m0.62381[0m[0m | time: 1.893s
[2K
| Adam | epoch: 001 | loss: 0.62381 - acc: 0.4500 -- iter: 0064/1263
[A[ATraining Step: 3  | total loss: [1m[32m0.68063[0m[0m | time: 2.946s
[2K
| Adam | epoch: 001 | loss: 0.68063 - acc: 0.4653 -- iter: 0096/1263
[A[ATraining Step: 4  | total loss: [1m[32m0.68994[0m[0m | time: 6.438s
[2K
| Adam | epoch: 001 | loss: 0.68994 - acc: 0.6085 -- iter: 0128/1263
[A[ATraining Step: 5  | total loss: [1m[32m0.69196[0m[0m | time: 9.849s
[2K
| Adam | epoch: 001 | loss: 0.69196 - acc: 0.5767 -- iter: 0160/1263
[A[ATraining Step: 6  | total loss: [1m[32m0.69358[0m[0m | time: 13.327s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.4470 -- iter: 0192/1263
[A[ATraining Step: 7  | total loss: [1m[32m0.69391[0m[0m | time: 14.159s
[2K
| Adam | epoch: 001 | loss: 0.69391 - acc: 0.4601 -- iter: 0224/1263
[A[ATraining Step: 8  | total loss: [1m[32m0.69333[0m[0m | time: 15.089s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.4825 -- iter: 0256/1263
[A[ATraining Step: 9  | total loss: [1m[32m0.69339[0m[0m | time: 16.093s
[2K
| Adam | epoch: 001 | loss: 0.69339 - acc: 0.4752 -- iter: 0288/1263
[A[ATraining Step: 10  | total loss: [1m[32m0.69293[0m[0m | time: 17.017s
[2K
| Adam | epoch: 001 | loss: 0.69293 - acc: 0.5501 -- iter: 0320/1263
[A[ATraining Step: 11  | total loss: [1m[32m0.69259[0m[0m | time: 18.020s
[2K
| Adam | epoch: 001 | loss: 0.69259 - acc: 0.5412 -- iter: 0352/1263
[A[ATraining Step: 12  | total loss: [1m[32m0.69293[0m[0m | time: 18.999s
[2K
| Adam | epoch: 001 | loss: 0.69293 - acc: 0.5226 -- iter: 0384/1263
[A[ATraining Step: 13  | total loss: [1m[32m0.69317[0m[0m | time: 19.806s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.5129 -- iter: 0416/1263
[A[ATraining Step: 14  | total loss: [1m[32m0.69659[0m[0m | time: 20.945s
[2K
| Adam | epoch: 001 | loss: 0.69659 - acc: 0.4309 -- iter: 0448/1263
[A[ATraining Step: 15  | total loss: [1m[32m0.69479[0m[0m | time: 22.128s
[2K
| Adam | epoch: 001 | loss: 0.69479 - acc: 0.4702 -- iter: 0480/1263
[A[ATraining Step: 16  | total loss: [1m[32m0.69580[0m[0m | time: 26.749s
[2K
| Adam | epoch: 001 | loss: 0.69580 - acc: 0.4345 -- iter: 0512/1263
[A[ATraining Step: 17  | total loss: [1m[32m0.69465[0m[0m | time: 30.853s
[2K
| Adam | epoch: 001 | loss: 0.69465 - acc: 0.4693 -- iter: 0544/1263
[A[ATraining Step: 18  | total loss: [1m[32m0.69335[0m[0m | time: 31.694s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.5340 -- iter: 0576/1263
[A[ATraining Step: 19  | total loss: [1m[32m0.69274[0m[0m | time: 32.538s
[2K
| Adam | epoch: 001 | loss: 0.69274 - acc: 0.5539 -- iter: 0608/1263
[A[ATraining Step: 20  | total loss: [1m[32m0.69219[0m[0m | time: 33.408s
[2K
| Adam | epoch: 001 | loss: 0.69219 - acc: 0.5768 -- iter: 0640/1263
[A[ATraining Step: 21  | total loss: [1m[32m0.69213[0m[0m | time: 34.309s
[2K
| Adam | epoch: 001 | loss: 0.69213 - acc: 0.5723 -- iter: 0672/1263
[A[ATraining Step: 22  | total loss: [1m[32m0.69315[0m[0m | time: 35.244s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.5225 -- iter: 0704/1263
[A[ATraining Step: 23  | total loss: [1m[32m0.69216[0m[0m | time: 36.199s
[2K
| Adam | epoch: 001 | loss: 0.69216 - acc: 0.5613 -- iter: 0736/1263
[A[ATraining Step: 24  | total loss: [1m[32m0.69163[0m[0m | time: 37.137s
[2K
| Adam | epoch: 001 | loss: 0.69163 - acc: 0.5792 -- iter: 0768/1263
[A[ATraining Step: 25  | total loss: [1m[32m0.69280[0m[0m | time: 37.967s
[2K
| Adam | epoch: 001 | loss: 0.69280 - acc: 0.5321 -- iter: 0800/1263
[A[ATraining Step: 26  | total loss: [1m[32m0.69441[0m[0m | time: 38.883s
[2K
| Adam | epoch: 001 | loss: 0.69441 - acc: 0.4739 -- iter: 0832/1263
[A[ATraining Step: 27  | total loss: [1m[32m0.69440[0m[0m | time: 39.698s
[2K
| Adam | epoch: 001 | loss: 0.69440 - acc: 0.4726 -- iter: 0864/1263
[A[ATraining Step: 28  | total loss: [1m[32m0.69347[0m[0m | time: 40.625s
[2K
| Adam | epoch: 001 | loss: 0.69347 - acc: 0.5029 -- iter: 0896/1263
[A[ATraining Step: 29  | total loss: [1m[32m0.69341[0m[0m | time: 41.477s
[2K
| Adam | epoch: 001 | loss: 0.69341 - acc: 0.5022 -- iter: 0928/1263
[A[ATraining Step: 30  | total loss: [1m[32m0.69278[0m[0m | time: 42.344s
[2K
| Adam | epoch: 001 | loss: 0.69278 - acc: 0.5239 -- iter: 0960/1263
[A[ATraining Step: 31  | total loss: [1m[32m0.69326[0m[0m | time: 43.216s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.5039 -- iter: 0992/1263
[A[ATraining Step: 32  | total loss: [1m[32m0.69266[0m[0m | time: 43.970s
[2K
| Adam | epoch: 001 | loss: 0.69266 - acc: 0.5241 -- iter: 1024/1263
[A[ATraining Step: 33  | total loss: [1m[32m0.69176[0m[0m | time: 44.830s
[2K
| Adam | epoch: 001 | loss: 0.69176 - acc: 0.5531 -- iter: 1056/1263
[A[ATraining Step: 34  | total loss: [1m[32m0.69076[0m[0m | time: 45.665s
[2K
| Adam | epoch: 001 | loss: 0.69076 - acc: 0.5819 -- iter: 1088/1263
[A[ATraining Step: 35  | total loss: [1m[32m0.69162[0m[0m | time: 46.478s
[2K
| Adam | epoch: 001 | loss: 0.69162 - acc: 0.5582 -- iter: 1120/1263
[A[ATraining Step: 36  | total loss: [1m[32m0.69092[0m[0m | time: 47.512s
[2K
| Adam | epoch: 001 | loss: 0.69092 - acc: 0.5719 -- iter: 1152/1263
[A[ATraining Step: 37  | total loss: [1m[32m0.69310[0m[0m | time: 48.610s
[2K
| Adam | epoch: 001 | loss: 0.69310 - acc: 0.5200 -- iter: 1184/1263
[A[ATraining Step: 38  | total loss: [1m[32m0.69435[0m[0m | time: 50.028s
[2K
| Adam | epoch: 001 | loss: 0.69435 - acc: 0.4916 -- iter: 1216/1263
[A[ATraining Step: 39  | total loss: [1m[32m0.69523[0m[0m | time: 53.352s
[2K
| Adam | epoch: 001 | loss: 0.69523 - acc: 0.4693 -- iter: 1248/1263
[A[ATraining Step: 40  | total loss: [1m[32m0.69586[0m[0m | time: 57.379s
[2K
| Adam | epoch: 001 | loss: 0.69586 - acc: 0.4516 | val_loss: 0.69378 - val_acc: 0.4861 -- iter: 1263/1263
--
Training Step: 41  | total loss: [1m[32m0.69517[0m[0m | time: 0.518s
[2K
| Adam | epoch: 002 | loss: 0.69517 - acc: 0.4666 -- iter: 0032/1263
[A[ATraining Step: 42  | total loss: [1m[32m0.69463[0m[0m | time: 1.494s
[2K
| Adam | epoch: 002 | loss: 0.69463 - acc: 0.4786 -- iter: 0064/1263
[A[ATraining Step: 43  | total loss: [1m[32m0.69474[0m[0m | time: 2.479s
[2K
| Adam | epoch: 002 | loss: 0.69474 - acc: 0.4714 -- iter: 0096/1263
[A[ATraining Step: 44  | total loss: [1m[32m0.69450[0m[0m | time: 3.320s
[2K
| Adam | epoch: 002 | loss: 0.69450 - acc: 0.4763 -- iter: 0128/1263
[A[ATraining Step: 45  | total loss: [1m[32m0.69384[0m[0m | time: 4.322s
[2K
| Adam | epoch: 002 | loss: 0.69384 - acc: 0.4963 -- iter: 0160/1263
[A[ATraining Step: 46  | total loss: [1m[32m0.69372[0m[0m | time: 5.470s
[2K
| Adam | epoch: 002 | loss: 0.69372 - acc: 0.4969 -- iter: 0192/1263
[A[ATraining Step: 47  | total loss: [1m[32m0.69379[0m[0m | time: 8.491s
[2K
| Adam | epoch: 002 | loss: 0.69379 - acc: 0.4923 -- iter: 0224/1263
[A[ATraining Step: 48  | total loss: [1m[32m0.69407[0m[0m | time: 12.140s
[2K
| Adam | epoch: 002 | loss: 0.69407 - acc: 0.4785 -- iter: 0256/1263
[A[ATraining Step: 49  | total loss: [1m[32m0.69405[0m[0m | time: 14.777s
[2K
| Adam | epoch: 002 | loss: 0.69405 - acc: 0.4769 -- iter: 0288/1263
[A[ATraining Step: 50  | total loss: [1m[32m0.69393[0m[0m | time: 17.881s
[2K
| Adam | epoch: 002 | loss: 0.69393 - acc: 0.4805 -- iter: 0320/1263
[A[ATraining Step: 51  | total loss: [1m[32m0.69351[0m[0m | time: 18.858s
[2K
| Adam | epoch: 002 | loss: 0.69351 - acc: 0.4978 -- iter: 0352/1263
[A[ATraining Step: 52  | total loss: [1m[32m0.69306[0m[0m | time: 19.832s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5169 -- iter: 0384/1263
[A[ATraining Step: 53  | total loss: [1m[32m0.69289[0m[0m | time: 20.790s
[2K
| Adam | epoch: 002 | loss: 0.69289 - acc: 0.5236 -- iter: 0416/1263
[A[ATraining Step: 54  | total loss: [1m[32m0.69284[0m[0m | time: 21.792s
[2K
| Adam | epoch: 002 | loss: 0.69284 - acc: 0.5247 -- iter: 0448/1263
[A[ATraining Step: 55  | total loss: [1m[32m0.69300[0m[0m | time: 22.882s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5167 -- iter: 0480/1263
[A[ATraining Step: 56  | total loss: [1m[32m0.69332[0m[0m | time: 23.892s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.5012 -- iter: 0512/1263
[A[ATraining Step: 57  | total loss: [1m[32m0.69369[0m[0m | time: 24.800s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.4837 -- iter: 0544/1263
[A[ATraining Step: 58  | total loss: [1m[32m0.69353[0m[0m | time: 25.844s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.4902 -- iter: 0576/1263
[A[ATraining Step: 59  | total loss: [1m[32m0.69365[0m[0m | time: 26.901s
[2K
| Adam | epoch: 002 | loss: 0.69365 - acc: 0.4831 -- iter: 0608/1263
[A[ATraining Step: 60  | total loss: [1m[32m0.69344[0m[0m | time: 30.223s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.4936 -- iter: 0640/1263
[A[ATraining Step: 61  | total loss: [1m[32m0.69318[0m[0m | time: 33.359s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5067 -- iter: 0672/1263
[A[ATraining Step: 62  | total loss: [1m[32m0.69325[0m[0m | time: 36.860s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5018 -- iter: 0704/1263
[A[ATraining Step: 63  | total loss: [1m[32m0.69361[0m[0m | time: 41.467s
[2K
| Adam | epoch: 002 | loss: 0.69361 - acc: 0.4818 -- iter: 0736/1263
[A[ATraining Step: 64  | total loss: [1m[32m0.69376[0m[0m | time: 42.422s
[2K
| Adam | epoch: 002 | loss: 0.69376 - acc: 0.4723 -- iter: 0768/1263
[A[ATraining Step: 65  | total loss: [1m[32m0.69358[0m[0m | time: 43.451s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.4834 -- iter: 0800/1263
[A[ATraining Step: 66  | total loss: [1m[32m0.69352[0m[0m | time: 44.363s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4855 -- iter: 0832/1263
[A[ATraining Step: 67  | total loss: [1m[32m0.69353[0m[0m | time: 45.370s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.4835 -- iter: 0864/1263
[A[ATraining Step: 68  | total loss: [1m[32m0.69353[0m[0m | time: 46.347s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.4817 -- iter: 0896/1263
[A[ATraining Step: 69  | total loss: [1m[32m0.69321[0m[0m | time: 47.285s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5094 -- iter: 0928/1263
[A[ATraining Step: 70  | total loss: [1m[32m0.69311[0m[0m | time: 48.102s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5155 -- iter: 0960/1263
[A[ATraining Step: 71  | total loss: [1m[32m0.69321[0m[0m | time: 49.088s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5067 -- iter: 0992/1263
[A[ATraining Step: 72  | total loss: [1m[32m0.69307[0m[0m | time: 50.240s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5165 -- iter: 1024/1263
[A[ATraining Step: 73  | total loss: [1m[32m0.69308[0m[0m | time: 51.820s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5146 -- iter: 1056/1263
[A[ATraining Step: 74  | total loss: [1m[32m0.69322[0m[0m | time: 55.805s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5027 -- iter: 1088/1263
[A[ATraining Step: 75  | total loss: [1m[32m0.69335[0m[0m | time: 58.516s
[2K
| Adam | epoch: 002 | loss: 0.69335 - acc: 0.4923 -- iter: 1120/1263
[A[ATraining Step: 76  | total loss: [1m[32m0.69327[0m[0m | time: 59.458s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4964 -- iter: 1152/1263
[A[ATraining Step: 77  | total loss: [1m[32m0.69310[0m[0m | time: 60.386s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5101 -- iter: 1184/1263
[A[ATraining Step: 78  | total loss: [1m[32m0.69319[0m[0m | time: 61.293s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5025 -- iter: 1216/1263
[A[ATraining Step: 79  | total loss: [1m[32m0.69303[0m[0m | time: 62.206s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5151 -- iter: 1248/1263
[A[ATraining Step: 80  | total loss: [1m[32m0.69305[0m[0m | time: 65.289s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5136 | val_loss: 0.69335 - val_acc: 0.4861 -- iter: 1263/1263
--
Training Step: 81  | total loss: [1m[32m0.69319[0m[0m | time: 0.500s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5027 -- iter: 0032/1263
[A[ATraining Step: 82  | total loss: [1m[32m0.69323[0m[0m | time: 1.030s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.4991 -- iter: 0064/1263
[A[ATraining Step: 83  | total loss: [1m[32m0.69326[0m[0m | time: 2.150s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.4959 -- iter: 0096/1263
[A[ATraining Step: 84  | total loss: [1m[32m0.69312[0m[0m | time: 2.763s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.5057 -- iter: 0128/1263
[A[ATraining Step: 85  | total loss: [1m[32m0.69305[0m[0m | time: 3.432s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5114 -- iter: 0160/1263
[A[ATraining Step: 86  | total loss: [1m[32m0.69294[0m[0m | time: 4.081s
[2K
| Adam | epoch: 003 | loss: 0.69294 - acc: 0.5196 -- iter: 0192/1263
[A[ATraining Step: 87  | total loss: [1m[32m0.69310[0m[0m | time: 4.718s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5083 -- iter: 0224/1263
[A[ATraining Step: 88  | total loss: [1m[32m0.69306[0m[0m | time: 5.326s
[2K
| Adam | epoch: 003 | loss: 0.69306 - acc: 0.5106 -- iter: 0256/1263
[A[ATraining Step: 89  | total loss: [1m[32m0.69299[0m[0m | time: 5.997s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5158 -- iter: 0288/1263
[A[ATraining Step: 90  | total loss: [1m[32m0.69314[0m[0m | time: 6.621s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.5048 -- iter: 0320/1263
[A[ATraining Step: 91  | total loss: [1m[32m0.69324[0m[0m | time: 7.230s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4981 -- iter: 0352/1263
[A[ATraining Step: 92  | total loss: [1m[32m0.69323[0m[0m | time: 7.866s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.4983 -- iter: 0384/1263
[A[ATraining Step: 93  | total loss: [1m[32m0.69323[0m[0m | time: 8.486s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.4984 -- iter: 0416/1263
[A[ATraining Step: 94  | total loss: [1m[32m0.69327[0m[0m | time: 9.138s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.4955 -- iter: 0448/1263
[A[ATraining Step: 95  | total loss: [1m[32m0.69313[0m[0m | time: 9.816s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5053 -- iter: 0480/1263
[A[ATraining Step: 96  | total loss: [1m[32m0.69292[0m[0m | time: 10.438s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5204 -- iter: 0512/1263
[A[ATraining Step: 97  | total loss: [1m[32m0.69295[0m[0m | time: 11.091s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5184 -- iter: 0544/1263
[A[ATraining Step: 98  | total loss: [1m[32m0.69297[0m[0m | time: 11.705s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5165 -- iter: 0576/1263
[A[ATraining Step: 99  | total loss: [1m[32m0.69315[0m[0m | time: 12.349s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5055 -- iter: 0608/1263
[A[ATraining Step: 100  | total loss: [1m[32m0.69320[0m[0m | time: 13.027s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.5018 -- iter: 0640/1263
[A[ATraining Step: 101  | total loss: [1m[32m0.69325[0m[0m | time: 13.659s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.4985 -- iter: 0672/1263
[A[ATraining Step: 102  | total loss: [1m[32m0.69289[0m[0m | time: 14.256s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.5205 -- iter: 0704/1263
[A[ATraining Step: 103  | total loss: [1m[32m0.69302[0m[0m | time: 14.924s
[2K
| Adam | epoch: 003 | loss: 0.69302 - acc: 0.5122 -- iter: 0736/1263
[A[ATraining Step: 104  | total loss: [1m[32m0.69315[0m[0m | time: 15.568s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5048 -- iter: 0768/1263
[A[ATraining Step: 105  | total loss: [1m[32m0.69315[0m[0m | time: 16.185s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5043 -- iter: 0800/1263
[A[ATraining Step: 106  | total loss: [1m[32m0.69284[0m[0m | time: 16.790s
[2K
| Adam | epoch: 003 | loss: 0.69284 - acc: 0.5226 -- iter: 0832/1263
[A[ATraining Step: 107  | total loss: [1m[32m0.69271[0m[0m | time: 17.412s
[2K
| Adam | epoch: 003 | loss: 0.69271 - acc: 0.5297 -- iter: 0864/1263
[A[ATraining Step: 108  | total loss: [1m[32m0.69282[0m[0m | time: 18.073s
[2K
| Adam | epoch: 003 | loss: 0.69282 - acc: 0.5236 -- iter: 0896/1263
[A[ATraining Step: 109  | total loss: [1m[32m0.69286[0m[0m | time: 18.682s
[2K
| Adam | epoch: 003 | loss: 0.69286 - acc: 0.5213 -- iter: 0928/1263
[A[ATraining Step: 110  | total loss: [1m[32m0.69270[0m[0m | time: 19.301s
[2K
| Adam | epoch: 003 | loss: 0.69270 - acc: 0.5285 -- iter: 0960/1263
[A[ATraining Step: 111  | total loss: [1m[32m0.69274[0m[0m | time: 19.918s
[2K
| Adam | epoch: 003 | loss: 0.69274 - acc: 0.5257 -- iter: 0992/1263
[A[ATraining Step: 112  | total loss: [1m[32m0.69307[0m[0m | time: 20.559s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5106 -- iter: 1024/1263
[A[ATraining Step: 113  | total loss: [1m[32m0.69285[0m[0m | time: 21.271s
[2K
| Adam | epoch: 003 | loss: 0.69285 - acc: 0.5189 -- iter: 1056/1263
[A[ATraining Step: 114  | total loss: [1m[32m0.69265[0m[0m | time: 21.919s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5264 -- iter: 1088/1263
[A[ATraining Step: 115  | total loss: [1m[32m0.69269[0m[0m | time: 22.585s
[2K
| Adam | epoch: 003 | loss: 0.69269 - acc: 0.5238 -- iter: 1120/1263
[A[ATraining Step: 116  | total loss: [1m[32m0.69249[0m[0m | time: 23.747s
[2K
| Adam | epoch: 003 | loss: 0.69249 - acc: 0.5308 -- iter: 1152/1263
[A[ATraining Step: 117  | total loss: [1m[32m0.69275[0m[0m | time: 24.970s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5214 -- iter: 1184/1263
[A[ATraining Step: 118  | total loss: [1m[32m0.69323[0m[0m | time: 26.417s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.5037 -- iter: 1216/1263
[A[ATraining Step: 119  | total loss: [1m[32m0.69305[0m[0m | time: 27.353s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5095 -- iter: 1248/1263
[A[ATraining Step: 120  | total loss: [1m[32m0.69306[0m[0m | time: 30.417s
[2K
| Adam | epoch: 003 | loss: 0.69306 - acc: 0.5086 | val_loss: 0.69366 - val_acc: 0.4861 -- iter: 1263/1263
--
Training Step: 121  | total loss: [1m[32m0.69291[0m[0m | time: 1.013s
[2K
| Adam | epoch: 004 | loss: 0.69291 - acc: 0.5140 -- iter: 0032/1263
[A[ATraining Step: 122  | total loss: [1m[32m0.69312[0m[0m | time: 1.459s
[2K
| Adam | epoch: 004 | loss: 0.69312 - acc: 0.5063 -- iter: 0064/1263
[A[ATraining Step: 123  | total loss: [1m[32m0.69358[0m[0m | time: 1.906s
[2K
| Adam | epoch: 004 | loss: 0.69358 - acc: 0.4890 -- iter: 0096/1263
[A[ATraining Step: 124  | total loss: [1m[32m0.69401[0m[0m | time: 2.911s
[2K
| Adam | epoch: 004 | loss: 0.69401 - acc: 0.4735 -- iter: 0128/1263
[A[ATraining Step: 125  | total loss: [1m[32m0.69370[0m[0m | time: 4.141s
[2K
| Adam | epoch: 004 | loss: 0.69370 - acc: 0.4855 -- iter: 0160/1263
[A[ATraining Step: 126  | total loss: [1m[32m0.69357[0m[0m | time: 8.904s
[2K
| Adam | epoch: 004 | loss: 0.69357 - acc: 0.4901 -- iter: 0192/1263
[A[ATraining Step: 127  | total loss: [1m[32m0.69353[0m[0m | time: 11.439s
[2K
| Adam | epoch: 004 | loss: 0.69353 - acc: 0.4911 -- iter: 0224/1263
[A[ATraining Step: 128  | total loss: [1m[32m0.69363[0m[0m | time: 14.086s
[2K
| Adam | epoch: 004 | loss: 0.69363 - acc: 0.4857 -- iter: 0256/1263
[A[ATraining Step: 129  | total loss: [1m[32m0.69378[0m[0m | time: 15.141s
[2K
| Adam | epoch: 004 | loss: 0.69378 - acc: 0.4778 -- iter: 0288/1263
[A[ATraining Step: 130  | total loss: [1m[32m0.69354[0m[0m | time: 16.177s
[2K
| Adam | epoch: 004 | loss: 0.69354 - acc: 0.4894 -- iter: 0320/1263
[A[ATraining Step: 131  | total loss: [1m[32m0.69375[0m[0m | time: 17.210s
[2K
| Adam | epoch: 004 | loss: 0.69375 - acc: 0.4779 -- iter: 0352/1263
[A[ATraining Step: 132  | total loss: [1m[32m0.69359[0m[0m | time: 18.251s
[2K
| Adam | epoch: 004 | loss: 0.69359 - acc: 0.4864 -- iter: 0384/1263
[A[ATraining Step: 133  | total loss: [1m[32m0.69356[0m[0m | time: 19.313s
[2K
| Adam | epoch: 004 | loss: 0.69356 - acc: 0.4877 -- iter: 0416/1263
[A[ATraining Step: 134  | total loss: [1m[32m0.69363[0m[0m | time: 20.296s
[2K
| Adam | epoch: 004 | loss: 0.69363 - acc: 0.4827 -- iter: 0448/1263
[A[ATraining Step: 135  | total loss: [1m[32m0.69358[0m[0m | time: 21.369s
[2K
| Adam | epoch: 004 | loss: 0.69358 - acc: 0.4844 -- iter: 0480/1263
[A[ATraining Step: 136  | total loss: [1m[32m0.69350[0m[0m | time: 22.598s
[2K
| Adam | epoch: 004 | loss: 0.69350 - acc: 0.4891 -- iter: 0512/1263
[A[ATraining Step: 137  | total loss: [1m[32m0.69322[0m[0m | time: 24.696s
[2K
| Adam | epoch: 004 | loss: 0.69322 - acc: 0.5090 -- iter: 0544/1263
[A[ATraining Step: 138  | total loss: [1m[32m0.69326[0m[0m | time: 27.926s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.5049 -- iter: 0576/1263
[A[ATraining Step: 139  | total loss: [1m[32m0.69343[0m[0m | time: 28.805s
[2K
| Adam | epoch: 004 | loss: 0.69343 - acc: 0.4919 -- iter: 0608/1263
[A[ATraining Step: 140  | total loss: [1m[32m0.69336[0m[0m | time: 29.779s
[2K
| Adam | epoch: 004 | loss: 0.69336 - acc: 0.4959 -- iter: 0640/1263
[A[ATraining Step: 141  | total loss: [1m[32m0.69329[0m[0m | time: 30.729s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.4994 -- iter: 0672/1263
[A[ATraining Step: 142  | total loss: [1m[32m0.69338[0m[0m | time: 31.687s
[2K
| Adam | epoch: 004 | loss: 0.69338 - acc: 0.4901 -- iter: 0704/1263
[A[ATraining Step: 143  | total loss: [1m[32m0.69340[0m[0m | time: 32.646s
[2K
| Adam | epoch: 004 | loss: 0.69340 - acc: 0.4880 -- iter: 0736/1263
[A[ATraining Step: 144  | total loss: [1m[32m0.69341[0m[0m | time: 33.754s
[2K
| Adam | epoch: 004 | loss: 0.69341 - acc: 0.4860 -- iter: 0768/1263
[A[ATraining Step: 145  | total loss: [1m[32m0.69331[0m[0m | time: 34.719s
[2K
| Adam | epoch: 004 | loss: 0.69331 - acc: 0.4937 -- iter: 0800/1263
[A[ATraining Step: 146  | total loss: [1m[32m0.69326[0m[0m | time: 35.703s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.4974 -- iter: 0832/1263
[A[ATraining Step: 147  | total loss: [1m[32m0.69312[0m[0m | time: 36.519s
[2K
| Adam | epoch: 004 | loss: 0.69312 - acc: 0.5102 -- iter: 0864/1263
[A[ATraining Step: 148  | total loss: [1m[32m0.69300[0m[0m | time: 37.442s
[2K
| Adam | epoch: 004 | loss: 0.69300 - acc: 0.5217 -- iter: 0896/1263
[A[ATraining Step: 149  | total loss: [1m[32m0.69292[0m[0m | time: 38.441s
[2K
| Adam | epoch: 004 | loss: 0.69292 - acc: 0.5289 -- iter: 0928/1263
[A[ATraining Step: 150  | total loss: [1m[32m0.69278[0m[0m | time: 39.464s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.5385 -- iter: 0960/1263
[A[ATraining Step: 151  | total loss: [1m[32m0.69297[0m[0m | time: 40.392s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5253 -- iter: 0992/1263
[A[ATraining Step: 152  | total loss: [1m[32m0.69300[0m[0m | time: 41.317s
[2K
| Adam | epoch: 004 | loss: 0.69300 - acc: 0.5227 -- iter: 1024/1263
[A[ATraining Step: 153  | total loss: [1m[32m0.69297[0m[0m | time: 42.278s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5236 -- iter: 1056/1263
[A[ATraining Step: 154  | total loss: [1m[32m0.69293[0m[0m | time: 43.191s
[2K
| Adam | epoch: 004 | loss: 0.69293 - acc: 0.5244 -- iter: 1088/1263
[A[ATraining Step: 155  | total loss: [1m[32m0.69302[0m[0m | time: 44.448s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5188 -- iter: 1120/1263
[A[ATraining Step: 156  | total loss: [1m[32m0.69280[0m[0m | time: 45.735s
[2K
| Adam | epoch: 004 | loss: 0.69280 - acc: 0.5294 -- iter: 1152/1263
[A[ATraining Step: 157  | total loss: [1m[32m0.69303[0m[0m | time: 47.963s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5171 -- iter: 1184/1263
[A[ATraining Step: 158  | total loss: [1m[32m0.69318[0m[0m | time: 48.884s
[2K
| Adam | epoch: 004 | loss: 0.69318 - acc: 0.5091 -- iter: 1216/1263
[A[ATraining Step: 159  | total loss: [1m[32m0.69310[0m[0m | time: 49.880s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.5114 -- iter: 1248/1263
[A[ATraining Step: 160  | total loss: [1m[32m0.69304[0m[0m | time: 52.933s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5133 | val_loss: 0.69352 - val_acc: 0.4861 -- iter: 1263/1263
--
Training Step: 161  | total loss: [1m[32m0.69299[0m[0m | time: 1.188s
[2K
| Adam | epoch: 005 | loss: 0.69299 - acc: 0.5151 -- iter: 0032/1263
[A[ATraining Step: 162  | total loss: [1m[32m0.69309[0m[0m | time: 2.756s
[2K
| Adam | epoch: 005 | loss: 0.69309 - acc: 0.5105 -- iter: 0064/1263
[A[ATraining Step: 163  | total loss: [1m[32m0.69325[0m[0m | time: 4.622s
[2K
| Adam | epoch: 005 | loss: 0.69325 - acc: 0.5032 -- iter: 0096/1263
[A[ATraining Step: 164  | total loss: [1m[32m0.69333[0m[0m | time: 6.214s
[2K
| Adam | epoch: 005 | loss: 0.69333 - acc: 0.4995 -- iter: 0128/1263
[A[ATraining Step: 165  | total loss: [1m[32m0.69337[0m[0m | time: 9.728s
[2K
| Adam | epoch: 005 | loss: 0.69337 - acc: 0.4963 -- iter: 0160/1263
[A[ATraining Step: 166  | total loss: [1m[32m0.69335[0m[0m | time: 13.323s
[2K
| Adam | epoch: 005 | loss: 0.69335 - acc: 0.4966 -- iter: 0192/1263
[A[ATraining Step: 167  | total loss: [1m[32m0.69342[0m[0m | time: 16.194s
[2K
| Adam | epoch: 005 | loss: 0.69342 - acc: 0.4938 -- iter: 0224/1263
[A[ATraining Step: 168  | total loss: [1m[32m0.69347[0m[0m | time: 17.290s
[2K
| Adam | epoch: 005 | loss: 0.69347 - acc: 0.4913 -- iter: 0256/1263
[A[ATraining Step: 169  | total loss: [1m[32m0.69344[0m[0m | time: 18.268s
[2K
| Adam | epoch: 005 | loss: 0.69344 - acc: 0.4922 -- iter: 0288/1263
[A[ATraining Step: 170  | total loss: [1m[32m0.69331[0m[0m | time: 19.192s
[2K
| Adam | epoch: 005 | loss: 0.69331 - acc: 0.4992 -- iter: 0320/1263
[A[ATraining Step: 171  | total loss: [1m[32m0.69358[0m[0m | time: 20.110s
[2K
| Adam | epoch: 005 | loss: 0.69358 - acc: 0.4837 -- iter: 0352/1263
[A[ATraining Step: 172  | total loss: [1m[32m0.69350[0m[0m | time: 21.063s
[2K
| Adam | epoch: 005 | loss: 0.69350 - acc: 0.4884 -- iter: 0384/1263
[A[ATraining Step: 173  | total loss: [1m[32m0.69333[0m[0m | time: 22.167s
[2K
| Adam | epoch: 005 | loss: 0.69333 - acc: 0.4990 -- iter: 0416/1263
[A[ATraining Step: 174  | total loss: [1m[32m0.69335[0m[0m | time: 23.234s
[2K
| Adam | epoch: 005 | loss: 0.69335 - acc: 0.4959 -- iter: 0448/1263
[A[ATraining Step: 175  | total loss: [1m[32m0.69348[0m[0m | time: 24.111s
[2K
| Adam | epoch: 005 | loss: 0.69348 - acc: 0.4870 -- iter: 0480/1263
[A[ATraining Step: 176  | total loss: [1m[32m0.69332[0m[0m | time: 25.223s
[2K
| Adam | epoch: 005 | loss: 0.69332 - acc: 0.4977 -- iter: 0512/1263
[A[ATraining Step: 177  | total loss: [1m[32m0.69339[0m[0m | time: 26.559s
[2K
| Adam | epoch: 005 | loss: 0.69339 - acc: 0.4916 -- iter: 0544/1263
[A[ATraining Step: 178  | total loss: [1m[32m0.69337[0m[0m | time: 28.905s
[2K
| Adam | epoch: 005 | loss: 0.69337 - acc: 0.4925 -- iter: 0576/1263
[A[ATraining Step: 179  | total loss: [1m[32m0.69334[0m[0m | time: 32.276s
[2K
| Adam | epoch: 005 | loss: 0.69334 - acc: 0.4932 -- iter: 0608/1263
[A[ATraining Step: 180  | total loss: [1m[32m0.69319[0m[0m | time: 36.701s
[2K
| Adam | epoch: 005 | loss: 0.69319 - acc: 0.5033 -- iter: 0640/1263
[A[ATraining Step: 181  | total loss: [1m[32m0.69301[0m[0m | time: 39.240s
[2K
| Adam | epoch: 005 | loss: 0.69301 - acc: 0.5186 -- iter: 0672/1263
[A[ATraining Step: 182  | total loss: [1m[32m0.69305[0m[0m | time: 40.122s
[2K
| Adam | epoch: 005 | loss: 0.69305 - acc: 0.5136 -- iter: 0704/1263
[A[ATraining Step: 183  | total loss: [1m[32m0.69314[0m[0m | time: 41.077s
[2K
| Adam | epoch: 005 | loss: 0.69314 - acc: 0.5060 -- iter: 0736/1263
[A[ATraining Step: 184  | total loss: [1m[32m0.69332[0m[0m | time: 41.981s
[2K
| Adam | epoch: 005 | loss: 0.69332 - acc: 0.4929 -- iter: 0768/1263
[A[ATraining Step: 185  | total loss: [1m[32m0.69337[0m[0m | time: 42.965s
[2K
| Adam | epoch: 005 | loss: 0.69337 - acc: 0.4873 -- iter: 0800/1263
[A[ATraining Step: 186  | total loss: [1m[32m0.69345[0m[0m | time: 44.035s
[2K
| Adam | epoch: 005 | loss: 0.69345 - acc: 0.4792 -- iter: 0832/1263
[A[ATraining Step: 187  | total loss: [1m[32m0.69363[0m[0m | time: 45.172s
[2K
| Adam | epoch: 005 | loss: 0.69363 - acc: 0.4626 -- iter: 0864/1263
[A[ATraining Step: 188  | total loss: [1m[32m0.69353[0m[0m | time: 46.131s
[2K
| Adam | epoch: 005 | loss: 0.69353 - acc: 0.4726 -- iter: 0896/1263
[A[ATraining Step: 189  | total loss: [1m[32m0.69339[0m[0m | time: 47.127s
[2K
| Adam | epoch: 005 | loss: 0.69339 - acc: 0.4878 -- iter: 0928/1263
[A[ATraining Step: 190  | total loss: [1m[32m0.69331[0m[0m | time: 48.162s
[2K
| Adam | epoch: 005 | loss: 0.69331 - acc: 0.4953 -- iter: 0960/1263
[A[ATraining Step: 191  | total loss: [1m[32m0.69333[0m[0m | time: 49.206s
[2K
| Adam | epoch: 005 | loss: 0.69333 - acc: 0.4895 -- iter: 0992/1263
[A[ATraining Step: 192  | total loss: [1m[32m0.69323[0m[0m | time: 50.224s
[2K
| Adam | epoch: 005 | loss: 0.69323 - acc: 0.5093 -- iter: 1024/1263
[A[ATraining Step: 193  | total loss: [1m[32m0.69321[0m[0m | time: 51.018s
[2K
| Adam | epoch: 005 | loss: 0.69321 - acc: 0.5115 -- iter: 1056/1263
[A[ATraining Step: 194  | total loss: [1m[32m0.69316[0m[0m | time: 51.743s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.5166 -- iter: 1088/1263
[A[ATraining Step: 195  | total loss: [1m[32m0.69308[0m[0m | time: 52.428s
[2K
| Adam | epoch: 005 | loss: 0.69308 - acc: 0.5274 -- iter: 1120/1263
[A[ATraining Step: 196  | total loss: [1m[32m0.69300[0m[0m | time: 53.113s
[2K
| Adam | epoch: 005 | loss: 0.69300 - acc: 0.5341 -- iter: 1152/1263
[A[ATraining Step: 197  | total loss: [1m[32m0.69295[0m[0m | time: 53.808s
[2K
| Adam | epoch: 005 | loss: 0.69295 - acc: 0.5369 -- iter: 1184/1263
[A[ATraining Step: 198  | total loss: [1m[32m0.69314[0m[0m | time: 54.489s
[2K
| Adam | epoch: 005 | loss: 0.69314 - acc: 0.5207 -- iter: 1216/1263
[A[ATraining Step: 199  | total loss: [1m[32m0.69288[0m[0m | time: 55.194s
[2K
| Adam | epoch: 005 | loss: 0.69288 - acc: 0.5374 -- iter: 1248/1263
[A[ATraining Step: 200  | total loss: [1m[32m0.69296[0m[0m | time: 57.369s
[2K
| Adam | epoch: 005 | loss: 0.69296 - acc: 0.5305 | val_loss: 0.69344 - val_acc: 0.4861 -- iter: 1263/1263
--
Training Step: 201  | total loss: [1m[32m0.69298[0m[0m | time: 0.651s
[2K
| Adam | epoch: 006 | loss: 0.69298 - acc: 0.5275 -- iter: 0032/1263
[A[ATraining Step: 202  | total loss: [1m[32m0.69307[0m[0m | time: 1.344s
[2K
| Adam | epoch: 006 | loss: 0.69307 - acc: 0.5216 -- iter: 0064/1263
[A[ATraining Step: 203  | total loss: [1m[32m0.69292[0m[0m | time: 2.085s
[2K
| Adam | epoch: 006 | loss: 0.69292 - acc: 0.5288 -- iter: 0096/1263
[A[ATraining Step: 204  | total loss: [1m[32m0.69301[0m[0m | time: 2.409s
[2K
| Adam | epoch: 006 | loss: 0.69301 - acc: 0.5228 -- iter: 0128/1263
[A[ATraining Step: 205  | total loss: [1m[32m0.69295[0m[0m | time: 2.737s
[2K
| Adam | epoch: 006 | loss: 0.69295 - acc: 0.5239 -- iter: 0160/1263
[A[ATraining Step: 206  | total loss: [1m[32m0.69292[0m[0m | time: 3.407s
[2K
| Adam | epoch: 006 | loss: 0.69292 - acc: 0.5248 -- iter: 0192/1263
[A[ATraining Step: 207  | total loss: [1m[32m0.69323[0m[0m | time: 4.080s
[2K
| Adam | epoch: 006 | loss: 0.69323 - acc: 0.5098 -- iter: 0224/1263
[A[ATraining Step: 208  | total loss: [1m[32m0.69326[0m[0m | time: 4.767s
[2K
| Adam | epoch: 006 | loss: 0.69326 - acc: 0.5088 -- iter: 0256/1263
[A[ATraining Step: 209  | total loss: [1m[32m0.69317[0m[0m | time: 5.452s
[2K
| Adam | epoch: 006 | loss: 0.69317 - acc: 0.5111 -- iter: 0288/1263
[A[ATraining Step: 210  | total loss: [1m[32m0.69326[0m[0m | time: 6.138s
[2K
| Adam | epoch: 006 | loss: 0.69326 - acc: 0.5069 -- iter: 0320/1263
[A[ATraining Step: 211  | total loss: [1m[32m0.69332[0m[0m | time: 6.763s
[2K
| Adam | epoch: 006 | loss: 0.69332 - acc: 0.5030 -- iter: 0352/1263
[A[ATraining Step: 212  | total loss: [1m[32m0.69339[0m[0m | time: 7.440s
[2K
| Adam | epoch: 006 | loss: 0.69339 - acc: 0.4996 -- iter: 0384/1263
[A[ATraining Step: 213  | total loss: [1m[32m0.69343[0m[0m | time: 8.103s
[2K
| Adam | epoch: 006 | loss: 0.69343 - acc: 0.4965 -- iter: 0416/1263
[A[ATraining Step: 214  | total loss: [1m[32m0.69287[0m[0m | time: 8.773s
[2K
| Adam | epoch: 006 | loss: 0.69287 - acc: 0.5219 -- iter: 0448/1263
[A[ATraining Step: 215  | total loss: [1m[32m0.69295[0m[0m | time: 9.490s
[2K
| Adam | epoch: 006 | loss: 0.69295 - acc: 0.5166 -- iter: 0480/1263
[A[ATraining Step: 216  | total loss: [1m[32m0.69282[0m[0m | time: 10.537s
[2K
| Adam | epoch: 006 | loss: 0.69282 - acc: 0.5212 -- iter: 0512/1263
[A[ATraining Step: 217  | total loss: [1m[32m0.69268[0m[0m | time: 11.707s
[2K
| Adam | epoch: 006 | loss: 0.69268 - acc: 0.5253 -- iter: 0544/1263
[A[ATraining Step: 218  | total loss: [1m[32m0.69268[0m[0m | time: 13.778s
[2K
| Adam | epoch: 006 | loss: 0.69268 - acc: 0.5259 -- iter: 0576/1263
[A[ATraining Step: 219  | total loss: [1m[32m0.69291[0m[0m | time: 16.225s
[2K
| Adam | epoch: 006 | loss: 0.69291 - acc: 0.5170 -- iter: 0608/1263
[A[ATraining Step: 220  | total loss: [1m[32m0.69270[0m[0m | time: 19.904s
[2K
| Adam | epoch: 006 | loss: 0.69270 - acc: 0.5247 -- iter: 0640/1263
[A[ATraining Step: 221  | total loss: [1m[32m0.69274[0m[0m | time: 22.135s
[2K
| Adam | epoch: 006 | loss: 0.69274 - acc: 0.5222 -- iter: 0672/1263
[A[ATraining Step: 222  | total loss: [1m[32m0.69270[0m[0m | time: 25.483s
[2K
| Adam | epoch: 006 | loss: 0.69270 - acc: 0.5231 -- iter: 0704/1263
[A[ATraining Step: 223  | total loss: [1m[32m0.69232[0m[0m | time: 26.285s
[2K
| Adam | epoch: 006 | loss: 0.69232 - acc: 0.5333 -- iter: 0736/1263
[A[ATraining Step: 224  | total loss: [1m[32m0.69240[0m[0m | time: 27.319s
[2K
| Adam | epoch: 006 | loss: 0.69240 - acc: 0.5300 -- iter: 0768/1263
[A[ATraining Step: 225  | total loss: [1m[32m0.69298[0m[0m | time: 28.227s
[2K
| Adam | epoch: 006 | loss: 0.69298 - acc: 0.5145 -- iter: 0800/1263
[A[ATraining Step: 226  | total loss: [1m[32m0.69310[0m[0m | time: 29.247s
[2K
| Adam | epoch: 006 | loss: 0.69310 - acc: 0.5099 -- iter: 0832/1263
[A[ATraining Step: 227  | total loss: [1m[32m0.69297[0m[0m | time: 30.254s
[2K
| Adam | epoch: 006 | loss: 0.69297 - acc: 0.5121 -- iter: 0864/1263
[A[ATraining Step: 228  | total loss: [1m[32m0.69303[0m[0m | time: 31.297s
[2K
| Adam | epoch: 006 | loss: 0.69303 - acc: 0.5077 -- iter: 0896/1263
[A[ATraining Step: 229  | total loss: [1m[32m0.69276[0m[0m | time: 32.361s
[2K
| Adam | epoch: 006 | loss: 0.69276 - acc: 0.5163 -- iter: 0928/1263
[A[ATraining Step: 230  | total loss: [1m[32m0.69295[0m[0m | time: 33.253s
[2K
| Adam | epoch: 006 | loss: 0.69295 - acc: 0.5084 -- iter: 0960/1263
[A[ATraining Step: 231  | total loss: [1m[32m0.69307[0m[0m | time: 34.417s
[2K
| Adam | epoch: 006 | loss: 0.69307 - acc: 0.5014 -- iter: 0992/1263
[A[ATraining Step: 232  | total loss: [1m[32m0.69340[0m[0m | time: 35.605s
[2K
| Adam | epoch: 006 | loss: 0.69340 - acc: 0.4887 -- iter: 1024/1263
[A[ATraining Step: 233  | total loss: [1m[32m0.69337[0m[0m | time: 39.547s
[2K
| Adam | epoch: 006 | loss: 0.69337 - acc: 0.4898 -- iter: 1056/1263
[A[ATraining Step: 234  | total loss: [1m[32m0.69331[0m[0m | time: 40.525s
[2K
| Adam | epoch: 006 | loss: 0.69331 - acc: 0.4909 -- iter: 1088/1263
[A[ATraining Step: 235  | total loss: [1m[32m0.69324[0m[0m | time: 41.544s
[2K
| Adam | epoch: 006 | loss: 0.69324 - acc: 0.5011 -- iter: 1120/1263
[A[ATraining Step: 236  | total loss: [1m[32m0.69327[0m[0m | time: 42.499s
[2K
| Adam | epoch: 006 | loss: 0.69327 - acc: 0.4885 -- iter: 1152/1263
[A[ATraining Step: 237  | total loss: [1m[32m0.69314[0m[0m | time: 43.519s
[2K
| Adam | epoch: 006 | loss: 0.69314 - acc: 0.5178 -- iter: 1184/1263
[A[ATraining Step: 238  | total loss: [1m[32m0.69319[0m[0m | time: 44.605s
[2K
| Adam | epoch: 006 | loss: 0.69319 - acc: 0.5098 -- iter: 1216/1263
[A[ATraining Step: 239  | total loss: [1m[32m0.69336[0m[0m | time: 45.651s
[2K
| Adam | epoch: 006 | loss: 0.69336 - acc: 0.4963 -- iter: 1248/1263
[A[ATraining Step: 240  | total loss: [1m[32m0.69325[0m[0m | time: 49.062s
[2K
| Adam | epoch: 006 | loss: 0.69325 - acc: 0.4967 | val_loss: 0.69307 - val_acc: 0.4861 -- iter: 1263/1263
--
Training Step: 241  | total loss: [1m[32m0.69318[0m[0m | time: 2.289s
[2K
| Adam | epoch: 007 | loss: 0.69318 - acc: 0.4939 -- iter: 0032/1263
[A[ATraining Step: 242  | total loss: [1m[32m0.69300[0m[0m | time: 3.313s
[2K
| Adam | epoch: 007 | loss: 0.69300 - acc: 0.4914 -- iter: 0064/1263
[A[ATraining Step: 243  | total loss: [1m[32m0.69304[0m[0m | time: 4.334s
[2K
| Adam | epoch: 007 | loss: 0.69304 - acc: 0.4860 -- iter: 0096/1263
[A[ATraining Step: 244  | total loss: [1m[32m0.69287[0m[0m | time: 5.441s
[2K
| Adam | epoch: 007 | loss: 0.69287 - acc: 0.4905 -- iter: 0128/1263
[A[ATraining Step: 245  | total loss: [1m[32m0.69274[0m[0m | time: 6.019s
[2K
| Adam | epoch: 007 | loss: 0.69274 - acc: 0.4946 -- iter: 0160/1263
[A[ATraining Step: 246  | total loss: [1m[32m0.69226[0m[0m | time: 6.604s
[2K
| Adam | epoch: 007 | loss: 0.69226 - acc: 0.5118 -- iter: 0192/1263
[A[ATraining Step: 247  | total loss: [1m[32m0.69113[0m[0m | time: 7.743s
[2K
| Adam | epoch: 007 | loss: 0.69113 - acc: 0.5473 -- iter: 0224/1263
[A[ATraining Step: 248  | total loss: [1m[32m0.69076[0m[0m | time: 8.667s
[2K
| Adam | epoch: 007 | loss: 0.69076 - acc: 0.5519 -- iter: 0256/1263
[A[ATraining Step: 249  | total loss: [1m[32m0.69052[0m[0m | time: 9.862s
[2K
| Adam | epoch: 007 | loss: 0.69052 - acc: 0.5530 -- iter: 0288/1263
[A[ATraining Step: 250  | total loss: [1m[32m0.69123[0m[0m | time: 11.054s
[2K
| Adam | epoch: 007 | loss: 0.69123 - acc: 0.5477 -- iter: 0320/1263
[A[ATraining Step: 251  | total loss: [1m[32m0.69046[0m[0m | time: 13.961s
[2K
| Adam | epoch: 007 | loss: 0.69046 - acc: 0.5492 -- iter: 0352/1263
[A[ATraining Step: 252  | total loss: [1m[32m0.69076[0m[0m | time: 17.474s
[2K
| Adam | epoch: 007 | loss: 0.69076 - acc: 0.5474 -- iter: 0384/1263
[A[ATraining Step: 253  | total loss: [1m[32m0.69199[0m[0m | time: 20.133s
[2K
| Adam | epoch: 007 | loss: 0.69199 - acc: 0.5426 -- iter: 0416/1263
[A[ATraining Step: 254  | total loss: [1m[32m0.69648[0m[0m | time: 22.745s
[2K
| Adam | epoch: 007 | loss: 0.69648 - acc: 0.5196 -- iter: 0448/1263
[A[ATraining Step: 255  | total loss: [1m[32m0.69352[0m[0m | time: 23.672s
[2K
| Adam | epoch: 007 | loss: 0.69352 - acc: 0.5427 -- iter: 0480/1263
[A[ATraining Step: 256  | total loss: [1m[32m0.69423[0m[0m | time: 24.735s
[2K
| Adam | epoch: 007 | loss: 0.69423 - acc: 0.5290 -- iter: 0512/1263
[A[ATraining Step: 257  | total loss: [1m[32m0.69369[0m[0m | time: 25.767s
[2K
| Adam | epoch: 007 | loss: 0.69369 - acc: 0.5324 -- iter: 0544/1263
[A[ATraining Step: 258  | total loss: [1m[32m0.69385[0m[0m | time: 26.861s
[2K
| Adam | epoch: 007 | loss: 0.69385 - acc: 0.5260 -- iter: 0576/1263
[A[ATraining Step: 259  | total loss: [1m[32m0.69356[0m[0m | time: 27.878s
[2K
| Adam | epoch: 007 | loss: 0.69356 - acc: 0.5265 -- iter: 0608/1263
[A[ATraining Step: 260  | total loss: [1m[32m0.69369[0m[0m | time: 28.849s
[2K
| Adam | epoch: 007 | loss: 0.69369 - acc: 0.5176 -- iter: 0640/1263
[A[ATraining Step: 261  | total loss: [1m[32m0.69367[0m[0m | time: 29.805s
[2K
| Adam | epoch: 007 | loss: 0.69367 - acc: 0.5096 -- iter: 0672/1263
[A[ATraining Step: 262  | total loss: [1m[32m0.69340[0m[0m | time: 30.733s
[2K
| Adam | epoch: 007 | loss: 0.69340 - acc: 0.5118 -- iter: 0704/1263
[A[ATraining Step: 263  | total loss: [1m[32m0.69319[0m[0m | time: 31.665s
[2K
| Adam | epoch: 007 | loss: 0.69319 - acc: 0.5106 -- iter: 0736/1263
[A[ATraining Step: 264  | total loss: [1m[32m0.69303[0m[0m | time: 32.595s
[2K
| Adam | epoch: 007 | loss: 0.69303 - acc: 0.5220 -- iter: 0768/1263
[A[ATraining Step: 265  | total loss: [1m[32m0.69285[0m[0m | time: 33.529s
[2K
| Adam | epoch: 007 | loss: 0.69285 - acc: 0.5386 -- iter: 0800/1263
[A[ATraining Step: 266  | total loss: [1m[32m0.69278[0m[0m | time: 34.522s
[2K
| Adam | epoch: 007 | loss: 0.69278 - acc: 0.5441 -- iter: 0832/1263
[A[ATraining Step: 267  | total loss: [1m[32m0.69252[0m[0m | time: 35.388s
[2K
| Adam | epoch: 007 | loss: 0.69252 - acc: 0.5491 -- iter: 0864/1263
[A[ATraining Step: 268  | total loss: [1m[32m0.69238[0m[0m | time: 36.325s
[2K
| Adam | epoch: 007 | loss: 0.69238 - acc: 0.5535 -- iter: 0896/1263
[A[ATraining Step: 269  | total loss: [1m[32m0.69175[0m[0m | time: 37.190s
[2K
| Adam | epoch: 007 | loss: 0.69175 - acc: 0.5732 -- iter: 0928/1263
[A[ATraining Step: 270  | total loss: [1m[32m0.69192[0m[0m | time: 38.109s
[2K
| Adam | epoch: 007 | loss: 0.69192 - acc: 0.5627 -- iter: 0960/1263
[A[ATraining Step: 271  | total loss: [1m[32m0.69093[0m[0m | time: 39.318s
[2K
| Adam | epoch: 007 | loss: 0.69093 - acc: 0.5783 -- iter: 0992/1263
[A[ATraining Step: 272  | total loss: [1m[32m0.69157[0m[0m | time: 40.434s
[2K
| Adam | epoch: 007 | loss: 0.69157 - acc: 0.5549 -- iter: 1024/1263
[A[ATraining Step: 273  | total loss: [1m[32m0.69149[0m[0m | time: 41.331s
[2K
| Adam | epoch: 007 | loss: 0.69149 - acc: 0.5588 -- iter: 1056/1263
[A[ATraining Step: 274  | total loss: [1m[32m0.69139[0m[0m | time: 42.266s
[2K
| Adam | epoch: 007 | loss: 0.69139 - acc: 0.5529 -- iter: 1088/1263
[A[ATraining Step: 275  | total loss: [1m[32m0.69089[0m[0m | time: 43.370s
[2K
| Adam | epoch: 007 | loss: 0.69089 - acc: 0.5570 -- iter: 1120/1263
[A[ATraining Step: 276  | total loss: [1m[32m0.69116[0m[0m | time: 44.376s
[2K
| Adam | epoch: 007 | loss: 0.69116 - acc: 0.5482 -- iter: 1152/1263
[A[ATraining Step: 277  | total loss: [1m[32m0.69029[0m[0m | time: 45.355s
[2K
| Adam | epoch: 007 | loss: 0.69029 - acc: 0.5590 -- iter: 1184/1263
[A[ATraining Step: 278  | total loss: [1m[32m0.69009[0m[0m | time: 46.398s
[2K
| Adam | epoch: 007 | loss: 0.69009 - acc: 0.5624 -- iter: 1216/1263
[A[ATraining Step: 279  | total loss: [1m[32m0.68987[0m[0m | time: 47.463s
[2K
| Adam | epoch: 007 | loss: 0.68987 - acc: 0.5656 -- iter: 1248/1263
[A[ATraining Step: 280  | total loss: [1m[32m0.68731[0m[0m | time: 51.096s
[2K
| Adam | epoch: 007 | loss: 0.68731 - acc: 0.5903 | val_loss: 0.69066 - val_acc: 0.5165 -- iter: 1263/1263
--
Training Step: 281  | total loss: [1m[32m0.68786[0m[0m | time: 1.849s
[2K
| Adam | epoch: 008 | loss: 0.68786 - acc: 0.5781 -- iter: 0032/1263
[A[ATraining Step: 282  | total loss: [1m[32m0.68869[0m[0m | time: 4.709s
[2K
| Adam | epoch: 008 | loss: 0.68869 - acc: 0.5703 -- iter: 0064/1263
[A[ATraining Step: 283  | total loss: [1m[32m0.68680[0m[0m | time: 6.086s
[2K
| Adam | epoch: 008 | loss: 0.68680 - acc: 0.5851 -- iter: 0096/1263
[A[ATraining Step: 284  | total loss: [1m[32m0.68821[0m[0m | time: 7.792s
[2K
| Adam | epoch: 008 | loss: 0.68821 - acc: 0.5829 -- iter: 0128/1263
[A[ATraining Step: 285  | total loss: [1m[32m0.68669[0m[0m | time: 8.787s
[2K
| Adam | epoch: 008 | loss: 0.68669 - acc: 0.5840 -- iter: 0160/1263
[A[ATraining Step: 286  | total loss: [1m[32m0.68426[0m[0m | time: 9.302s
[2K
| Adam | epoch: 008 | loss: 0.68426 - acc: 0.5912 -- iter: 0192/1263
[A[ATraining Step: 287  | total loss: [1m[32m0.68049[0m[0m | time: 9.831s
[2K
| Adam | epoch: 008 | loss: 0.68049 - acc: 0.5987 -- iter: 0224/1263
[A[ATraining Step: 288  | total loss: [1m[32m0.67419[0m[0m | time: 10.871s
[2K
| Adam | epoch: 008 | loss: 0.67419 - acc: 0.6055 -- iter: 0256/1263
[A[ATraining Step: 289  | total loss: [1m[32m0.68531[0m[0m | time: 11.951s
[2K
| Adam | epoch: 008 | loss: 0.68531 - acc: 0.5950 -- iter: 0288/1263
[A[ATraining Step: 290  | total loss: [1m[32m0.69156[0m[0m | time: 13.016s
[2K
| Adam | epoch: 008 | loss: 0.69156 - acc: 0.5886 -- iter: 0320/1263
[A[ATraining Step: 291  | total loss: [1m[32m0.69979[0m[0m | time: 14.011s
[2K
| Adam | epoch: 008 | loss: 0.69979 - acc: 0.5641 -- iter: 0352/1263
[A[ATraining Step: 292  | total loss: [1m[32m0.69737[0m[0m | time: 15.100s
[2K
| Adam | epoch: 008 | loss: 0.69737 - acc: 0.5671 -- iter: 0384/1263
[A[ATraining Step: 293  | total loss: [1m[32m0.69472[0m[0m | time: 16.190s
[2K
| Adam | epoch: 008 | loss: 0.69472 - acc: 0.5604 -- iter: 0416/1263
[A[ATraining Step: 294  | total loss: [1m[32m0.69216[0m[0m | time: 17.297s
[2K
| Adam | epoch: 008 | loss: 0.69216 - acc: 0.5793 -- iter: 0448/1263
[A[ATraining Step: 295  | total loss: [1m[32m0.69103[0m[0m | time: 18.353s
[2K
| Adam | epoch: 008 | loss: 0.69103 - acc: 0.5777 -- iter: 0480/1263
[A[ATraining Step: 296  | total loss: [1m[32m0.68971[0m[0m | time: 19.071s
[2K
| Adam | epoch: 008 | loss: 0.68971 - acc: 0.5886 -- iter: 0512/1263
[A[ATraining Step: 297  | total loss: [1m[32m0.69013[0m[0m | time: 19.737s
[2K
| Adam | epoch: 008 | loss: 0.69013 - acc: 0.5735 -- iter: 0544/1263
[A[ATraining Step: 298  | total loss: [1m[32m0.68784[0m[0m | time: 20.395s
[2K
| Adam | epoch: 008 | loss: 0.68784 - acc: 0.5818 -- iter: 0576/1263
[A[ATraining Step: 299  | total loss: [1m[32m0.68702[0m[0m | time: 21.089s
[2K
| Adam | epoch: 008 | loss: 0.68702 - acc: 0.5924 -- iter: 0608/1263
[A[ATraining Step: 300  | total loss: [1m[32m0.68944[0m[0m | time: 21.800s
[2K
| Adam | epoch: 008 | loss: 0.68944 - acc: 0.5644 -- iter: 0640/1263
[A[ATraining Step: 301  | total loss: [1m[32m0.68761[0m[0m | time: 22.502s
[2K
| Adam | epoch: 008 | loss: 0.68761 - acc: 0.5736 -- iter: 0672/1263
[A[ATraining Step: 302  | total loss: [1m[32m0.68720[0m[0m | time: 23.197s
[2K
| Adam | epoch: 008 | loss: 0.68720 - acc: 0.5756 -- iter: 0704/1263
[A[ATraining Step: 303  | total loss: [1m[32m0.68618[0m[0m | time: 23.890s
[2K
| Adam | epoch: 008 | loss: 0.68618 - acc: 0.5837 -- iter: 0736/1263
[A[ATraining Step: 304  | total loss: [1m[32m0.68298[0m[0m | time: 24.547s
[2K
| Adam | epoch: 008 | loss: 0.68298 - acc: 0.6097 -- iter: 0768/1263
[A[ATraining Step: 305  | total loss: [1m[32m0.68204[0m[0m | time: 25.249s
[2K
| Adam | epoch: 008 | loss: 0.68204 - acc: 0.6174 -- iter: 0800/1263
[A[ATraining Step: 306  | total loss: [1m[32m0.68122[0m[0m | time: 25.945s
[2K
| Adam | epoch: 008 | loss: 0.68122 - acc: 0.6182 -- iter: 0832/1263
[A[ATraining Step: 307  | total loss: [1m[32m0.68095[0m[0m | time: 26.629s
[2K
| Adam | epoch: 008 | loss: 0.68095 - acc: 0.6064 -- iter: 0864/1263
[A[ATraining Step: 308  | total loss: [1m[32m0.67819[0m[0m | time: 27.337s
[2K
| Adam | epoch: 008 | loss: 0.67819 - acc: 0.6239 -- iter: 0896/1263
[A[ATraining Step: 309  | total loss: [1m[32m0.67748[0m[0m | time: 28.030s
[2K
| Adam | epoch: 008 | loss: 0.67748 - acc: 0.6271 -- iter: 0928/1263
[A[ATraining Step: 310  | total loss: [1m[32m0.67333[0m[0m | time: 28.726s
[2K
| Adam | epoch: 008 | loss: 0.67333 - acc: 0.6456 -- iter: 0960/1263
[A[ATraining Step: 311  | total loss: [1m[32m0.67364[0m[0m | time: 29.446s
[2K
| Adam | epoch: 008 | loss: 0.67364 - acc: 0.6373 -- iter: 0992/1263
[A[ATraining Step: 312  | total loss: [1m[32m0.66819[0m[0m | time: 30.136s
[2K
| Adam | epoch: 008 | loss: 0.66819 - acc: 0.6548 -- iter: 1024/1263
[A[ATraining Step: 313  | total loss: [1m[32m0.66708[0m[0m | time: 30.812s
[2K
| Adam | epoch: 008 | loss: 0.66708 - acc: 0.6581 -- iter: 1056/1263
[A[ATraining Step: 314  | total loss: [1m[32m0.66674[0m[0m | time: 31.466s
[2K
| Adam | epoch: 008 | loss: 0.66674 - acc: 0.6611 -- iter: 1088/1263
[A[ATraining Step: 315  | total loss: [1m[32m0.67122[0m[0m | time: 32.125s
[2K
| Adam | epoch: 008 | loss: 0.67122 - acc: 0.6512 -- iter: 1120/1263
[A[ATraining Step: 316  | total loss: [1m[32m0.67311[0m[0m | time: 32.811s
[2K
| Adam | epoch: 008 | loss: 0.67311 - acc: 0.6455 -- iter: 1152/1263
[A[ATraining Step: 317  | total loss: [1m[32m0.66729[0m[0m | time: 33.505s
[2K
| Adam | epoch: 008 | loss: 0.66729 - acc: 0.6465 -- iter: 1184/1263
[A[ATraining Step: 318  | total loss: [1m[32m0.67345[0m[0m | time: 34.177s
[2K
| Adam | epoch: 008 | loss: 0.67345 - acc: 0.6256 -- iter: 1216/1263
[A[ATraining Step: 319  | total loss: [1m[32m0.67387[0m[0m | time: 34.854s
[2K
| Adam | epoch: 008 | loss: 0.67387 - acc: 0.6224 -- iter: 1248/1263
[A[ATraining Step: 320  | total loss: [1m[32m0.67051[0m[0m | time: 37.214s
[2K
| Adam | epoch: 008 | loss: 0.67051 - acc: 0.6258 | val_loss: 0.68590 - val_acc: 0.6000 -- iter: 1263/1263
--
Training Step: 321  | total loss: [1m[32m0.66798[0m[0m | time: 0.704s
[2K
| Adam | epoch: 009 | loss: 0.66798 - acc: 0.6320 -- iter: 0032/1263
[A[ATraining Step: 322  | total loss: [1m[32m0.65874[0m[0m | time: 1.627s
[2K
| Adam | epoch: 009 | loss: 0.65874 - acc: 0.6407 -- iter: 0064/1263
[A[ATraining Step: 323  | total loss: [1m[32m0.65592[0m[0m | time: 2.798s
[2K
| Adam | epoch: 009 | loss: 0.65592 - acc: 0.6360 -- iter: 0096/1263
[A[ATraining Step: 324  | total loss: [1m[32m0.65422[0m[0m | time: 3.707s
[2K
| Adam | epoch: 009 | loss: 0.65422 - acc: 0.6411 -- iter: 0128/1263
[A[ATraining Step: 325  | total loss: [1m[32m0.65264[0m[0m | time: 6.364s
[2K
| Adam | epoch: 009 | loss: 0.65264 - acc: 0.6426 -- iter: 0160/1263
[A[ATraining Step: 326  | total loss: [1m[32m0.65004[0m[0m | time: 8.949s
[2K
| Adam | epoch: 009 | loss: 0.65004 - acc: 0.6346 -- iter: 0192/1263
[A[ATraining Step: 327  | total loss: [1m[32m0.64718[0m[0m | time: 10.403s
[2K
| Adam | epoch: 009 | loss: 0.64718 - acc: 0.6399 -- iter: 0224/1263
[A[ATraining Step: 328  | total loss: [1m[32m0.65271[0m[0m | time: 12.505s
[2K
| Adam | epoch: 009 | loss: 0.65271 - acc: 0.6359 -- iter: 0256/1263
[A[ATraining Step: 329  | total loss: [1m[32m0.65514[0m[0m | time: 15.573s
[2K
| Adam | epoch: 009 | loss: 0.65514 - acc: 0.6323 -- iter: 0288/1263
[A[ATraining Step: 330  | total loss: [1m[32m0.65780[0m[0m | time: 16.628s
[2K
| Adam | epoch: 009 | loss: 0.65780 - acc: 0.6285 -- iter: 0320/1263
[A[ATraining Step: 331  | total loss: [1m[32m0.67972[0m[0m | time: 17.638s
[2K
| Adam | epoch: 009 | loss: 0.67972 - acc: 0.6125 -- iter: 0352/1263
[A[ATraining Step: 332  | total loss: [1m[32m0.67355[0m[0m | time: 18.597s
[2K
| Adam | epoch: 009 | loss: 0.67355 - acc: 0.6262 -- iter: 0384/1263
[A[ATraining Step: 333  | total loss: [1m[32m0.66950[0m[0m | time: 19.611s
[2K
| Adam | epoch: 009 | loss: 0.66950 - acc: 0.6292 -- iter: 0416/1263
[A[ATraining Step: 334  | total loss: [1m[32m0.67725[0m[0m | time: 20.682s
[2K
| Adam | epoch: 009 | loss: 0.67725 - acc: 0.6069 -- iter: 0448/1263
[A[ATraining Step: 335  | total loss: [1m[32m0.67426[0m[0m | time: 21.808s
[2K
| Adam | epoch: 009 | loss: 0.67426 - acc: 0.6056 -- iter: 0480/1263
[A[ATraining Step: 336  | total loss: [1m[32m0.67183[0m[0m | time: 22.730s
[2K
| Adam | epoch: 009 | loss: 0.67183 - acc: 0.6076 -- iter: 0512/1263
[A[ATraining Step: 337  | total loss: [1m[32m0.67127[0m[0m | time: 23.772s
[2K
| Adam | epoch: 009 | loss: 0.67127 - acc: 0.6062 -- iter: 0544/1263
[A[ATraining Step: 338  | total loss: [1m[32m0.67400[0m[0m | time: 24.871s
[2K
| Adam | epoch: 009 | loss: 0.67400 - acc: 0.5956 -- iter: 0576/1263
[A[ATraining Step: 339  | total loss: [1m[32m0.67754[0m[0m | time: 25.926s
[2K
| Adam | epoch: 009 | loss: 0.67754 - acc: 0.5766 -- iter: 0608/1263
[A[ATraining Step: 340  | total loss: [1m[32m0.67678[0m[0m | time: 26.813s
[2K
| Adam | epoch: 009 | loss: 0.67678 - acc: 0.5783 -- iter: 0640/1263
[A[ATraining Step: 341  | total loss: [1m[32m0.67706[0m[0m | time: 27.881s
[2K
| Adam | epoch: 009 | loss: 0.67706 - acc: 0.5736 -- iter: 0672/1263
[A[ATraining Step: 342  | total loss: [1m[32m0.67476[0m[0m | time: 28.912s
[2K
| Adam | epoch: 009 | loss: 0.67476 - acc: 0.5850 -- iter: 0704/1263
[A[ATraining Step: 343  | total loss: [1m[32m0.67505[0m[0m | time: 29.937s
[2K
| Adam | epoch: 009 | loss: 0.67505 - acc: 0.5859 -- iter: 0736/1263
[A[ATraining Step: 344  | total loss: [1m[32m0.67308[0m[0m | time: 31.003s
[2K
| Adam | epoch: 009 | loss: 0.67308 - acc: 0.5961 -- iter: 0768/1263
[A[ATraining Step: 345  | total loss: [1m[32m0.67166[0m[0m | time: 32.000s
[2K
| Adam | epoch: 009 | loss: 0.67166 - acc: 0.6052 -- iter: 0800/1263
[A[ATraining Step: 346  | total loss: [1m[32m0.67021[0m[0m | time: 32.900s
[2K
| Adam | epoch: 009 | loss: 0.67021 - acc: 0.6072 -- iter: 0832/1263
[A[ATraining Step: 347  | total loss: [1m[32m0.67008[0m[0m | time: 34.039s
[2K
| Adam | epoch: 009 | loss: 0.67008 - acc: 0.6090 -- iter: 0864/1263
[A[ATraining Step: 348  | total loss: [1m[32m0.66947[0m[0m | time: 35.237s
[2K
| Adam | epoch: 009 | loss: 0.66947 - acc: 0.6043 -- iter: 0896/1263
[A[ATraining Step: 349  | total loss: [1m[32m0.67099[0m[0m | time: 36.192s
[2K
| Adam | epoch: 009 | loss: 0.67099 - acc: 0.6033 -- iter: 0928/1263
[A[ATraining Step: 350  | total loss: [1m[32m0.66728[0m[0m | time: 37.193s
[2K
| Adam | epoch: 009 | loss: 0.66728 - acc: 0.6179 -- iter: 0960/1263
[A[ATraining Step: 351  | total loss: [1m[32m0.66757[0m[0m | time: 38.230s
[2K
| Adam | epoch: 009 | loss: 0.66757 - acc: 0.6124 -- iter: 0992/1263
[A[ATraining Step: 352  | total loss: [1m[32m0.66463[0m[0m | time: 39.258s
[2K
| Adam | epoch: 009 | loss: 0.66463 - acc: 0.6199 -- iter: 1024/1263
[A[ATraining Step: 353  | total loss: [1m[32m0.66381[0m[0m | time: 40.202s
[2K
| Adam | epoch: 009 | loss: 0.66381 - acc: 0.6235 -- iter: 1056/1263
[A[ATraining Step: 354  | total loss: [1m[32m0.66307[0m[0m | time: 41.213s
[2K
| Adam | epoch: 009 | loss: 0.66307 - acc: 0.6237 -- iter: 1088/1263
[A[ATraining Step: 355  | total loss: [1m[32m0.65694[0m[0m | time: 42.299s
[2K
| Adam | epoch: 009 | loss: 0.65694 - acc: 0.6363 -- iter: 1120/1263
[A[ATraining Step: 356  | total loss: [1m[32m0.65632[0m[0m | time: 43.235s
[2K
| Adam | epoch: 009 | loss: 0.65632 - acc: 0.6289 -- iter: 1152/1263
[A[ATraining Step: 357  | total loss: [1m[32m0.66371[0m[0m | time: 44.361s
[2K
| Adam | epoch: 009 | loss: 0.66371 - acc: 0.6098 -- iter: 1184/1263
[A[ATraining Step: 358  | total loss: [1m[32m0.66080[0m[0m | time: 45.450s
[2K
| Adam | epoch: 009 | loss: 0.66080 - acc: 0.6082 -- iter: 1216/1263
[A[ATraining Step: 359  | total loss: [1m[32m0.65013[0m[0m | time: 46.313s
[2K
| Adam | epoch: 009 | loss: 0.65013 - acc: 0.6317 -- iter: 1248/1263
[A[ATraining Step: 360  | total loss: [1m[32m0.65552[0m[0m | time: 49.656s
[2K
| Adam | epoch: 009 | loss: 0.65552 - acc: 0.6248 | val_loss: 0.69174 - val_acc: 0.5494 -- iter: 1263/1263
--
Training Step: 361  | total loss: [1m[32m0.65853[0m[0m | time: 1.008s
[2K
| Adam | epoch: 010 | loss: 0.65853 - acc: 0.6217 -- iter: 0032/1263
[A[ATraining Step: 362  | total loss: [1m[32m0.65277[0m[0m | time: 2.128s
[2K
| Adam | epoch: 010 | loss: 0.65277 - acc: 0.6314 -- iter: 0064/1263
[A[ATraining Step: 363  | total loss: [1m[32m0.64982[0m[0m | time: 3.141s
[2K
| Adam | epoch: 010 | loss: 0.64982 - acc: 0.6339 -- iter: 0096/1263
[A[ATraining Step: 364  | total loss: [1m[32m0.63970[0m[0m | time: 4.091s
[2K
| Adam | epoch: 010 | loss: 0.63970 - acc: 0.6455 -- iter: 0128/1263
[A[ATraining Step: 365  | total loss: [1m[32m0.63347[0m[0m | time: 5.236s
[2K
| Adam | epoch: 010 | loss: 0.63347 - acc: 0.6560 -- iter: 0160/1263
[A[ATraining Step: 366  | total loss: [1m[32m0.63189[0m[0m | time: 6.266s
[2K
| Adam | epoch: 010 | loss: 0.63189 - acc: 0.6591 -- iter: 0192/1263
[A[ATraining Step: 367  | total loss: [1m[32m0.62602[0m[0m | time: 8.097s
[2K
| Adam | epoch: 010 | loss: 0.62602 - acc: 0.6620 -- iter: 0224/1263
[A[ATraining Step: 368  | total loss: [1m[32m0.62664[0m[0m | time: 9.665s
[2K
| Adam | epoch: 010 | loss: 0.62664 - acc: 0.6489 -- iter: 0256/1263
[A[ATraining Step: 369  | total loss: [1m[32m0.60839[0m[0m | time: 10.343s
[2K
| Adam | epoch: 010 | loss: 0.60839 - acc: 0.6773 -- iter: 0288/1263
[A[ATraining Step: 370  | total loss: [1m[32m0.58736[0m[0m | time: 13.031s
[2K
| Adam | epoch: 010 | loss: 0.58736 - acc: 0.7029 -- iter: 0320/1263
[A[ATraining Step: 371  | total loss: [1m[32m0.58944[0m[0m | time: 14.045s
[2K
| Adam | epoch: 010 | loss: 0.58944 - acc: 0.7045 -- iter: 0352/1263
[A[ATraining Step: 372  | total loss: [1m[32m0.59799[0m[0m | time: 15.009s
[2K
| Adam | epoch: 010 | loss: 0.59799 - acc: 0.7028 -- iter: 0384/1263
[A[ATraining Step: 373  | total loss: [1m[32m0.58445[0m[0m | time: 16.050s
[2K
| Adam | epoch: 010 | loss: 0.58445 - acc: 0.7107 -- iter: 0416/1263
[A[ATraining Step: 374  | total loss: [1m[32m0.57482[0m[0m | time: 17.072s
[2K
| Adam | epoch: 010 | loss: 0.57482 - acc: 0.7115 -- iter: 0448/1263
[A[ATraining Step: 375  | total loss: [1m[32m0.60400[0m[0m | time: 18.111s
[2K
| Adam | epoch: 010 | loss: 0.60400 - acc: 0.6934 -- iter: 0480/1263
[A[ATraining Step: 376  | total loss: [1m[32m0.62104[0m[0m | time: 19.115s
[2K
| Adam | epoch: 010 | loss: 0.62104 - acc: 0.6835 -- iter: 0512/1263
[A[ATraining Step: 377  | total loss: [1m[32m0.61785[0m[0m | time: 20.158s
[2K
| Adam | epoch: 010 | loss: 0.61785 - acc: 0.6776 -- iter: 0544/1263
[A[ATraining Step: 378  | total loss: [1m[32m0.63372[0m[0m | time: 21.098s
[2K
| Adam | epoch: 010 | loss: 0.63372 - acc: 0.6661 -- iter: 0576/1263
[A[ATraining Step: 379  | total loss: [1m[32m0.62863[0m[0m | time: 22.015s
[2K
| Adam | epoch: 010 | loss: 0.62863 - acc: 0.6683 -- iter: 0608/1263
[A[ATraining Step: 380  | total loss: [1m[32m0.61846[0m[0m | time: 22.878s
[2K
| Adam | epoch: 010 | loss: 0.61846 - acc: 0.6764 -- iter: 0640/1263
[A[ATraining Step: 381  | total loss: [1m[32m0.61226[0m[0m | time: 23.796s
[2K
| Adam | epoch: 010 | loss: 0.61226 - acc: 0.6838 -- iter: 0672/1263
[A[ATraining Step: 382  | total loss: [1m[32m0.61431[0m[0m | time: 24.709s
[2K
| Adam | epoch: 010 | loss: 0.61431 - acc: 0.6779 -- iter: 0704/1263
[A[ATraining Step: 383  | total loss: [1m[32m0.61208[0m[0m | time: 25.636s
[2K
| Adam | epoch: 010 | loss: 0.61208 - acc: 0.6757 -- iter: 0736/1263
[A[ATraining Step: 384  | total loss: [1m[32m0.60701[0m[0m | time: 26.619s
[2K
| Adam | epoch: 010 | loss: 0.60701 - acc: 0.6894 -- iter: 0768/1263
[A[ATraining Step: 385  | total loss: [1m[32m0.61594[0m[0m | time: 27.621s
[2K
| Adam | epoch: 010 | loss: 0.61594 - acc: 0.6830 -- iter: 0800/1263
[A[ATraining Step: 386  | total loss: [1m[32m0.60993[0m[0m | time: 28.564s
[2K
| Adam | epoch: 010 | loss: 0.60993 - acc: 0.6959 -- iter: 0832/1263
[A[ATraining Step: 387  | total loss: [1m[32m0.60480[0m[0m | time: 29.579s
[2K
| Adam | epoch: 010 | loss: 0.60480 - acc: 0.7013 -- iter: 0864/1263
[A[ATraining Step: 388  | total loss: [1m[32m0.61135[0m[0m | time: 30.755s
[2K
| Adam | epoch: 010 | loss: 0.61135 - acc: 0.6843 -- iter: 0896/1263
[A[ATraining Step: 389  | total loss: [1m[32m0.60986[0m[0m | time: 31.883s
[2K
| Adam | epoch: 010 | loss: 0.60986 - acc: 0.6909 -- iter: 0928/1263
[A[ATraining Step: 390  | total loss: [1m[32m0.60925[0m[0m | time: 32.791s
[2K
| Adam | epoch: 010 | loss: 0.60925 - acc: 0.6906 -- iter: 0960/1263
[A[ATraining Step: 391  | total loss: [1m[32m0.60863[0m[0m | time: 33.768s
[2K
| Adam | epoch: 010 | loss: 0.60863 - acc: 0.6809 -- iter: 0992/1263
[A[ATraining Step: 392  | total loss: [1m[32m0.61113[0m[0m | time: 34.744s
[2K
| Adam | epoch: 010 | loss: 0.61113 - acc: 0.6784 -- iter: 1024/1263
[A[ATraining Step: 393  | total loss: [1m[32m0.61084[0m[0m | time: 35.660s
[2K
| Adam | epoch: 010 | loss: 0.61084 - acc: 0.6762 -- iter: 1056/1263
[A[ATraining Step: 394  | total loss: [1m[32m0.60575[0m[0m | time: 36.655s
[2K
| Adam | epoch: 010 | loss: 0.60575 - acc: 0.6836 -- iter: 1088/1263
[A[ATraining Step: 395  | total loss: [1m[32m0.60390[0m[0m | time: 37.743s
[2K
| Adam | epoch: 010 | loss: 0.60390 - acc: 0.6777 -- iter: 1120/1263
[A[ATraining Step: 396  | total loss: [1m[32m0.59658[0m[0m | time: 38.772s
[2K
| Adam | epoch: 010 | loss: 0.59658 - acc: 0.6756 -- iter: 1152/1263
[A[ATraining Step: 397  | total loss: [1m[32m0.60164[0m[0m | time: 39.673s
[2K
| Adam | epoch: 010 | loss: 0.60164 - acc: 0.6705 -- iter: 1184/1263
[A[ATraining Step: 398  | total loss: [1m[32m0.59482[0m[0m | time: 40.748s
[2K
| Adam | epoch: 010 | loss: 0.59482 - acc: 0.6816 -- iter: 1216/1263
[A[ATraining Step: 399  | total loss: [1m[32m0.58571[0m[0m | time: 41.875s
[2K
| Adam | epoch: 010 | loss: 0.58571 - acc: 0.6947 -- iter: 1248/1263
[A[ATraining Step: 400  | total loss: [1m[32m0.58697[0m[0m | time: 44.978s
[2K
| Adam | epoch: 010 | loss: 0.58697 - acc: 0.6908 | val_loss: 0.69470 - val_acc: 0.5747 -- iter: 1263/1263
--
Training Step: 401  | total loss: [1m[32m0.59746[0m[0m | time: 0.726s
[2K
| Adam | epoch: 011 | loss: 0.59746 - acc: 0.6749 -- iter: 0032/1263
[A[ATraining Step: 402  | total loss: [1m[32m0.59417[0m[0m | time: 1.424s
[2K
| Adam | epoch: 011 | loss: 0.59417 - acc: 0.6855 -- iter: 0064/1263
[A[ATraining Step: 403  | total loss: [1m[32m0.59177[0m[0m | time: 2.124s
[2K
| Adam | epoch: 011 | loss: 0.59177 - acc: 0.6920 -- iter: 0096/1263
[A[ATraining Step: 404  | total loss: [1m[32m0.60335[0m[0m | time: 2.824s
[2K
| Adam | epoch: 011 | loss: 0.60335 - acc: 0.6821 -- iter: 0128/1263
[A[ATraining Step: 405  | total loss: [1m[32m0.60288[0m[0m | time: 3.534s
[2K
| Adam | epoch: 011 | loss: 0.60288 - acc: 0.6827 -- iter: 0160/1263
[A[ATraining Step: 406  | total loss: [1m[32m0.59925[0m[0m | time: 4.254s
[2K
| Adam | epoch: 011 | loss: 0.59925 - acc: 0.6894 -- iter: 0192/1263
[A[ATraining Step: 407  | total loss: [1m[32m0.59669[0m[0m | time: 5.043s
[2K
| Adam | epoch: 011 | loss: 0.59669 - acc: 0.6923 -- iter: 0224/1263
[A[ATraining Step: 408  | total loss: [1m[32m0.59122[0m[0m | time: 5.842s
[2K
| Adam | epoch: 011 | loss: 0.59122 - acc: 0.6981 -- iter: 0256/1263
[A[ATraining Step: 409  | total loss: [1m[32m0.59673[0m[0m | time: 6.230s
[2K
| Adam | epoch: 011 | loss: 0.59673 - acc: 0.6877 -- iter: 0288/1263
[A[ATraining Step: 410  | total loss: [1m[32m0.59233[0m[0m | time: 6.692s
[2K
| Adam | epoch: 011 | loss: 0.59233 - acc: 0.6922 -- iter: 0320/1263
[A[ATraining Step: 411  | total loss: [1m[32m0.58152[0m[0m | time: 7.522s
[2K
| Adam | epoch: 011 | loss: 0.58152 - acc: 0.6963 -- iter: 0352/1263
[A[ATraining Step: 412  | total loss: [1m[32m0.58928[0m[0m | time: 8.345s
[2K
| Adam | epoch: 011 | loss: 0.58928 - acc: 0.6892 -- iter: 0384/1263
[A[ATraining Step: 413  | total loss: [1m[32m0.59570[0m[0m | time: 9.184s
[2K
| Adam | epoch: 011 | loss: 0.59570 - acc: 0.6765 -- iter: 0416/1263
[A[ATraining Step: 414  | total loss: [1m[32m0.60598[0m[0m | time: 10.039s
[2K
| Adam | epoch: 011 | loss: 0.60598 - acc: 0.6683 -- iter: 0448/1263
[A[ATraining Step: 415  | total loss: [1m[32m0.59098[0m[0m | time: 10.878s
[2K
| Adam | epoch: 011 | loss: 0.59098 - acc: 0.6858 -- iter: 0480/1263
[A[ATraining Step: 416  | total loss: [1m[32m0.60366[0m[0m | time: 11.753s
[2K
| Adam | epoch: 011 | loss: 0.60366 - acc: 0.6735 -- iter: 0512/1263
[A[ATraining Step: 417  | total loss: [1m[32m0.60176[0m[0m | time: 12.595s
[2K
| Adam | epoch: 011 | loss: 0.60176 - acc: 0.6749 -- iter: 0544/1263
[A[ATraining Step: 418  | total loss: [1m[32m0.60386[0m[0m | time: 13.440s
[2K
| Adam | epoch: 011 | loss: 0.60386 - acc: 0.6730 -- iter: 0576/1263
[A[ATraining Step: 419  | total loss: [1m[32m0.59719[0m[0m | time: 14.261s
[2K
| Adam | epoch: 011 | loss: 0.59719 - acc: 0.6776 -- iter: 0608/1263
[A[ATraining Step: 420  | total loss: [1m[32m0.58568[0m[0m | time: 15.053s
[2K
| Adam | epoch: 011 | loss: 0.58568 - acc: 0.6911 -- iter: 0640/1263
[A[ATraining Step: 421  | total loss: [1m[32m0.58442[0m[0m | time: 15.907s
[2K
| Adam | epoch: 011 | loss: 0.58442 - acc: 0.6938 -- iter: 0672/1263
[A[ATraining Step: 422  | total loss: [1m[32m0.58394[0m[0m | time: 16.716s
[2K
| Adam | epoch: 011 | loss: 0.58394 - acc: 0.6901 -- iter: 0704/1263
[A[ATraining Step: 423  | total loss: [1m[32m0.57919[0m[0m | time: 17.610s
[2K
| Adam | epoch: 011 | loss: 0.57919 - acc: 0.6992 -- iter: 0736/1263
[A[ATraining Step: 424  | total loss: [1m[32m0.58895[0m[0m | time: 18.503s
[2K
| Adam | epoch: 011 | loss: 0.58895 - acc: 0.6887 -- iter: 0768/1263
[A[ATraining Step: 425  | total loss: [1m[32m0.57874[0m[0m | time: 19.771s
[2K
| Adam | epoch: 011 | loss: 0.57874 - acc: 0.7010 -- iter: 0800/1263
[A[ATraining Step: 426  | total loss: [1m[32m0.57712[0m[0m | time: 22.045s
[2K
| Adam | epoch: 011 | loss: 0.57712 - acc: 0.7028 -- iter: 0832/1263
[A[ATraining Step: 427  | total loss: [1m[32m0.57014[0m[0m | time: 25.751s
[2K
| Adam | epoch: 011 | loss: 0.57014 - acc: 0.7075 -- iter: 0864/1263
[A[ATraining Step: 428  | total loss: [1m[32m0.56183[0m[0m | time: 28.556s
[2K
| Adam | epoch: 011 | loss: 0.56183 - acc: 0.7180 -- iter: 0896/1263
[A[ATraining Step: 429  | total loss: [1m[32m0.55475[0m[0m | time: 31.648s
[2K
| Adam | epoch: 011 | loss: 0.55475 - acc: 0.7275 -- iter: 0928/1263
[A[ATraining Step: 430  | total loss: [1m[32m0.54569[0m[0m | time: 34.866s
[2K
| Adam | epoch: 011 | loss: 0.54569 - acc: 0.7329 -- iter: 0960/1263
[A[ATraining Step: 431  | total loss: [1m[32m0.54594[0m[0m | time: 37.293s
[2K
| Adam | epoch: 011 | loss: 0.54594 - acc: 0.7283 -- iter: 0992/1263
[A[ATraining Step: 432  | total loss: [1m[32m0.54435[0m[0m | time: 40.416s
[2K
| Adam | epoch: 011 | loss: 0.54435 - acc: 0.7274 -- iter: 1024/1263
[A[ATraining Step: 433  | total loss: [1m[32m0.55355[0m[0m | time: 43.977s
[2K
| Adam | epoch: 011 | loss: 0.55355 - acc: 0.7203 -- iter: 1056/1263
[A[ATraining Step: 434  | total loss: [1m[32m0.54888[0m[0m | time: 45.291s
[2K
| Adam | epoch: 011 | loss: 0.54888 - acc: 0.7264 -- iter: 1088/1263
[A[ATraining Step: 435  | total loss: [1m[32m0.54339[0m[0m | time: 46.367s
[2K
| Adam | epoch: 011 | loss: 0.54339 - acc: 0.7287 -- iter: 1120/1263
[A[ATraining Step: 436  | total loss: [1m[32m0.54452[0m[0m | time: 47.629s
[2K
| Adam | epoch: 011 | loss: 0.54452 - acc: 0.7340 -- iter: 1152/1263
[A[ATraining Step: 437  | total loss: [1m[32m0.54954[0m[0m | time: 48.785s
[2K
| Adam | epoch: 011 | loss: 0.54954 - acc: 0.7293 -- iter: 1184/1263
[A[ATraining Step: 438  | total loss: [1m[32m0.56546[0m[0m | time: 49.945s
[2K
| Adam | epoch: 011 | loss: 0.56546 - acc: 0.7126 -- iter: 1216/1263
[A[ATraining Step: 439  | total loss: [1m[32m0.59509[0m[0m | time: 51.156s
[2K
| Adam | epoch: 011 | loss: 0.59509 - acc: 0.6914 -- iter: 1248/1263
[A[ATraining Step: 440  | total loss: [1m[32m0.58744[0m[0m | time: 55.262s
[2K
| Adam | epoch: 011 | loss: 0.58744 - acc: 0.7004 | val_loss: 0.68769 - val_acc: 0.6405 -- iter: 1263/1263
--
Training Step: 441  | total loss: [1m[32m0.57749[0m[0m | time: 2.622s
[2K
| Adam | epoch: 012 | loss: 0.57749 - acc: 0.7053 -- iter: 0032/1263
[A[ATraining Step: 442  | total loss: [1m[32m0.58369[0m[0m | time: 6.591s
[2K
| Adam | epoch: 012 | loss: 0.58369 - acc: 0.7035 -- iter: 0064/1263
[A[ATraining Step: 443  | total loss: [1m[32m0.57380[0m[0m | time: 9.174s
[2K
| Adam | epoch: 012 | loss: 0.57380 - acc: 0.7113 -- iter: 0096/1263
[A[ATraining Step: 444  | total loss: [1m[32m0.57906[0m[0m | time: 12.059s
[2K
| Adam | epoch: 012 | loss: 0.57906 - acc: 0.7058 -- iter: 0128/1263
[A[ATraining Step: 445  | total loss: [1m[32m0.58295[0m[0m | time: 15.386s
[2K
| Adam | epoch: 012 | loss: 0.58295 - acc: 0.6977 -- iter: 0160/1263
[A[ATraining Step: 446  | total loss: [1m[32m0.59068[0m[0m | time: 20.256s
[2K
| Adam | epoch: 012 | loss: 0.59068 - acc: 0.6905 -- iter: 0192/1263
[A[ATraining Step: 447  | total loss: [1m[32m0.57940[0m[0m | time: 22.913s
[2K
| Adam | epoch: 012 | loss: 0.57940 - acc: 0.7027 -- iter: 0224/1263
[A[ATraining Step: 448  | total loss: [1m[32m0.56574[0m[0m | time: 24.109s
[2K
| Adam | epoch: 012 | loss: 0.56574 - acc: 0.7230 -- iter: 0256/1263
[A[ATraining Step: 449  | total loss: [1m[32m0.56980[0m[0m | time: 25.186s
[2K
| Adam | epoch: 012 | loss: 0.56980 - acc: 0.7132 -- iter: 0288/1263
[A[ATraining Step: 450  | total loss: [1m[32m0.57585[0m[0m | time: 25.785s
[2K
| Adam | epoch: 012 | loss: 0.57585 - acc: 0.7075 -- iter: 0320/1263
[A[ATraining Step: 451  | total loss: [1m[32m0.56741[0m[0m | time: 26.430s
[2K
| Adam | epoch: 012 | loss: 0.56741 - acc: 0.7101 -- iter: 0352/1263
[A[ATraining Step: 452  | total loss: [1m[32m0.55775[0m[0m | time: 27.534s
[2K
| Adam | epoch: 012 | loss: 0.55775 - acc: 0.7191 -- iter: 0384/1263
[A[ATraining Step: 453  | total loss: [1m[32m0.56351[0m[0m | time: 28.741s
[2K
| Adam | epoch: 012 | loss: 0.56351 - acc: 0.7128 -- iter: 0416/1263
[A[ATraining Step: 454  | total loss: [1m[32m0.55976[0m[0m | time: 29.941s
[2K
| Adam | epoch: 012 | loss: 0.55976 - acc: 0.7134 -- iter: 0448/1263
[A[ATraining Step: 455  | total loss: [1m[32m0.55368[0m[0m | time: 31.154s
[2K
| Adam | epoch: 012 | loss: 0.55368 - acc: 0.7233 -- iter: 0480/1263
[A[ATraining Step: 456  | total loss: [1m[32m0.54210[0m[0m | time: 32.409s
[2K
| Adam | epoch: 012 | loss: 0.54210 - acc: 0.7291 -- iter: 0512/1263
[A[ATraining Step: 457  | total loss: [1m[32m0.54174[0m[0m | time: 35.206s
[2K
| Adam | epoch: 012 | loss: 0.54174 - acc: 0.7312 -- iter: 0544/1263
[A[ATraining Step: 458  | total loss: [1m[32m0.53776[0m[0m | time: 37.703s
[2K
| Adam | epoch: 012 | loss: 0.53776 - acc: 0.7362 -- iter: 0576/1263
[A[ATraining Step: 459  | total loss: [1m[32m0.54152[0m[0m | time: 40.555s
[2K
| Adam | epoch: 012 | loss: 0.54152 - acc: 0.7282 -- iter: 0608/1263
[A[ATraining Step: 460  | total loss: [1m[32m0.55266[0m[0m | time: 43.473s
[2K
| Adam | epoch: 012 | loss: 0.55266 - acc: 0.7148 -- iter: 0640/1263
[A[ATraining Step: 461  | total loss: [1m[32m0.54598[0m[0m | time: 47.053s
[2K
| Adam | epoch: 012 | loss: 0.54598 - acc: 0.7120 -- iter: 0672/1263
[A[ATraining Step: 462  | total loss: [1m[32m0.54364[0m[0m | time: 50.548s
[2K
| Adam | epoch: 012 | loss: 0.54364 - acc: 0.7158 -- iter: 0704/1263
[A[ATraining Step: 463  | total loss: [1m[32m0.54342[0m[0m | time: 53.637s
[2K
| Adam | epoch: 012 | loss: 0.54342 - acc: 0.7224 -- iter: 0736/1263
[A[ATraining Step: 464  | total loss: [1m[32m0.53698[0m[0m | time: 54.714s
[2K
| Adam | epoch: 012 | loss: 0.53698 - acc: 0.7251 -- iter: 0768/1263
[A[ATraining Step: 465  | total loss: [1m[32m0.54629[0m[0m | time: 56.010s
[2K
| Adam | epoch: 012 | loss: 0.54629 - acc: 0.7214 -- iter: 0800/1263
[A[ATraining Step: 466  | total loss: [1m[32m0.53525[0m[0m | time: 57.203s
[2K
| Adam | epoch: 012 | loss: 0.53525 - acc: 0.7242 -- iter: 0832/1263
[A[ATraining Step: 467  | total loss: [1m[32m0.52567[0m[0m | time: 58.395s
[2K
| Adam | epoch: 012 | loss: 0.52567 - acc: 0.7362 -- iter: 0864/1263
[A[ATraining Step: 468  | total loss: [1m[32m0.51174[0m[0m | time: 59.725s
[2K
| Adam | epoch: 012 | loss: 0.51174 - acc: 0.7501 -- iter: 0896/1263
[A[ATraining Step: 469  | total loss: [1m[32m0.52067[0m[0m | time: 60.941s
[2K
| Adam | epoch: 012 | loss: 0.52067 - acc: 0.7438 -- iter: 0928/1263
[A[ATraining Step: 470  | total loss: [1m[32m0.51285[0m[0m | time: 62.000s
[2K
| Adam | epoch: 012 | loss: 0.51285 - acc: 0.7476 -- iter: 0960/1263
[A[ATraining Step: 471  | total loss: [1m[32m0.52675[0m[0m | time: 63.284s
[2K
| Adam | epoch: 012 | loss: 0.52675 - acc: 0.7353 -- iter: 0992/1263
[A[ATraining Step: 472  | total loss: [1m[32m0.51644[0m[0m | time: 64.914s
[2K
| Adam | epoch: 012 | loss: 0.51644 - acc: 0.7461 -- iter: 1024/1263
[A[ATraining Step: 473  | total loss: [1m[32m0.52474[0m[0m | time: 68.538s
[2K
| Adam | epoch: 012 | loss: 0.52474 - acc: 0.7465 -- iter: 1056/1263
[A[ATraining Step: 474  | total loss: [1m[32m0.51569[0m[0m | time: 73.087s
[2K
| Adam | epoch: 012 | loss: 0.51569 - acc: 0.7563 -- iter: 1088/1263
[A[ATraining Step: 475  | total loss: [1m[32m0.49893[0m[0m | time: 77.473s
[2K
| Adam | epoch: 012 | loss: 0.49893 - acc: 0.7619 -- iter: 1120/1263
[A[ATraining Step: 476  | total loss: [1m[32m0.50795[0m[0m | time: 79.314s
[2K
| Adam | epoch: 012 | loss: 0.50795 - acc: 0.7576 -- iter: 1152/1263
[A[ATraining Step: 477  | total loss: [1m[32m0.50299[0m[0m | time: 82.563s
[2K
| Adam | epoch: 012 | loss: 0.50299 - acc: 0.7599 -- iter: 1184/1263
[A[ATraining Step: 478  | total loss: [1m[32m0.52096[0m[0m | time: 84.736s
[2K
| Adam | epoch: 012 | loss: 0.52096 - acc: 0.7433 -- iter: 1216/1263
[A[ATraining Step: 479  | total loss: [1m[32m0.51037[0m[0m | time: 86.029s
[2K
| Adam | epoch: 012 | loss: 0.51037 - acc: 0.7502 -- iter: 1248/1263
[A[ATraining Step: 480  | total loss: [1m[32m0.49475[0m[0m | time: 89.991s
[2K
| Adam | epoch: 012 | loss: 0.49475 - acc: 0.7627 | val_loss: 0.67714 - val_acc: 0.6481 -- iter: 1263/1263
--
Training Step: 481  | total loss: [1m[32m0.48990[0m[0m | time: 1.237s
[2K
| Adam | epoch: 013 | loss: 0.48990 - acc: 0.7677 -- iter: 0032/1263
[A[ATraining Step: 482  | total loss: [1m[32m0.49374[0m[0m | time: 2.393s
[2K
| Adam | epoch: 013 | loss: 0.49374 - acc: 0.7659 -- iter: 0064/1263
[A[ATraining Step: 483  | total loss: [1m[32m0.48361[0m[0m | time: 3.612s
[2K
| Adam | epoch: 013 | loss: 0.48361 - acc: 0.7768 -- iter: 0096/1263
[A[ATraining Step: 484  | total loss: [1m[32m0.48021[0m[0m | time: 4.582s
[2K
| Adam | epoch: 013 | loss: 0.48021 - acc: 0.7804 -- iter: 0128/1263
[A[ATraining Step: 485  | total loss: [1m[32m0.47706[0m[0m | time: 6.763s
[2K
| Adam | epoch: 013 | loss: 0.47706 - acc: 0.7836 -- iter: 0160/1263
[A[ATraining Step: 486  | total loss: [1m[32m0.47128[0m[0m | time: 9.818s
[2K
| Adam | epoch: 013 | loss: 0.47128 - acc: 0.7896 -- iter: 0192/1263
[A[ATraining Step: 487  | total loss: [1m[32m0.47142[0m[0m | time: 14.657s
[2K
| Adam | epoch: 013 | loss: 0.47142 - acc: 0.7888 -- iter: 0224/1263
[A[ATraining Step: 488  | total loss: [1m[32m0.47209[0m[0m | time: 18.430s
[2K
| Adam | epoch: 013 | loss: 0.47209 - acc: 0.7880 -- iter: 0256/1263
[A[ATraining Step: 489  | total loss: [1m[32m0.47824[0m[0m | time: 21.378s
[2K
| Adam | epoch: 013 | loss: 0.47824 - acc: 0.7842 -- iter: 0288/1263
[A[ATraining Step: 490  | total loss: [1m[32m0.48060[0m[0m | time: 23.602s
[2K
| Adam | epoch: 013 | loss: 0.48060 - acc: 0.7839 -- iter: 0320/1263
[A[ATraining Step: 491  | total loss: [1m[32m0.47113[0m[0m | time: 24.155s
[2K
| Adam | epoch: 013 | loss: 0.47113 - acc: 0.7930 -- iter: 0352/1263
[A[ATraining Step: 492  | total loss: [1m[32m0.45705[0m[0m | time: 24.758s
[2K
| Adam | epoch: 013 | loss: 0.45705 - acc: 0.7937 -- iter: 0384/1263
[A[ATraining Step: 493  | total loss: [1m[32m0.42858[0m[0m | time: 25.937s
[2K
| Adam | epoch: 013 | loss: 0.42858 - acc: 0.8144 -- iter: 0416/1263
[A[ATraining Step: 494  | total loss: [1m[32m0.45129[0m[0m | time: 27.187s
[2K
| Adam | epoch: 013 | loss: 0.45129 - acc: 0.7954 -- iter: 0448/1263
[A[ATraining Step: 495  | total loss: [1m[32m0.51023[0m[0m | time: 28.378s
[2K
| Adam | epoch: 013 | loss: 0.51023 - acc: 0.7721 -- iter: 0480/1263
[A[ATraining Step: 496  | total loss: [1m[32m0.51047[0m[0m | time: 29.708s
[2K
| Adam | epoch: 013 | loss: 0.51047 - acc: 0.7730 -- iter: 0512/1263
[A[ATraining Step: 497  | total loss: [1m[32m0.51849[0m[0m | time: 30.907s
[2K
| Adam | epoch: 013 | loss: 0.51849 - acc: 0.7645 -- iter: 0544/1263
[A[ATraining Step: 498  | total loss: [1m[32m0.50075[0m[0m | time: 31.979s
[2K
| Adam | epoch: 013 | loss: 0.50075 - acc: 0.7755 -- iter: 0576/1263
[A[ATraining Step: 499  | total loss: [1m[32m0.49148[0m[0m | time: 33.167s
[2K
| Adam | epoch: 013 | loss: 0.49148 - acc: 0.7792 -- iter: 0608/1263
[A[ATraining Step: 500  | total loss: [1m[32m0.51289[0m[0m | time: 35.925s
[2K
| Adam | epoch: 013 | loss: 0.51289 - acc: 0.7669 -- iter: 0640/1263
[A[ATraining Step: 501  | total loss: [1m[32m0.53563[0m[0m | time: 40.138s
[2K
| Adam | epoch: 013 | loss: 0.53563 - acc: 0.7527 -- iter: 0672/1263
[A[ATraining Step: 502  | total loss: [1m[32m0.52247[0m[0m | time: 43.657s
[2K
| Adam | epoch: 013 | loss: 0.52247 - acc: 0.7556 -- iter: 0704/1263
[A[ATraining Step: 503  | total loss: [1m[32m0.51561[0m[0m | time: 46.882s
[2K
| Adam | epoch: 013 | loss: 0.51561 - acc: 0.7582 -- iter: 0736/1263
[A[ATraining Step: 504  | total loss: [1m[32m0.52368[0m[0m | time: 50.285s
[2K
| Adam | epoch: 013 | loss: 0.52368 - acc: 0.7573 -- iter: 0768/1263
[A[ATraining Step: 505  | total loss: [1m[32m0.51183[0m[0m | time: 53.595s
[2K
| Adam | epoch: 013 | loss: 0.51183 - acc: 0.7660 -- iter: 0800/1263
[A[ATraining Step: 506  | total loss: [1m[32m0.51296[0m[0m | time: 56.318s
[2K
| Adam | epoch: 013 | loss: 0.51296 - acc: 0.7644 -- iter: 0832/1263
[A[ATraining Step: 507  | total loss: [1m[32m0.50178[0m[0m | time: 57.299s
[2K
| Adam | epoch: 013 | loss: 0.50178 - acc: 0.7754 -- iter: 0864/1263
[A[ATraining Step: 508  | total loss: [1m[32m0.49398[0m[0m | time: 58.361s
[2K
| Adam | epoch: 013 | loss: 0.49398 - acc: 0.7792 -- iter: 0896/1263
[A[ATraining Step: 509  | total loss: [1m[32m0.47980[0m[0m | time: 59.501s
[2K
| Adam | epoch: 013 | loss: 0.47980 - acc: 0.7919 -- iter: 0928/1263
[A[ATraining Step: 510  | total loss: [1m[32m0.46840[0m[0m | time: 60.913s
[2K
| Adam | epoch: 013 | loss: 0.46840 - acc: 0.8002 -- iter: 0960/1263
[A[ATraining Step: 511  | total loss: [1m[32m0.46011[0m[0m | time: 62.124s
[2K
| Adam | epoch: 013 | loss: 0.46011 - acc: 0.8077 -- iter: 0992/1263
[A[ATraining Step: 512  | total loss: [1m[32m0.45614[0m[0m | time: 63.407s
[2K
| Adam | epoch: 013 | loss: 0.45614 - acc: 0.8113 -- iter: 1024/1263
[A[ATraining Step: 513  | total loss: [1m[32m0.44237[0m[0m | time: 64.551s
[2K
| Adam | epoch: 013 | loss: 0.44237 - acc: 0.8239 -- iter: 1056/1263
[A[ATraining Step: 514  | total loss: [1m[32m0.45166[0m[0m | time: 65.665s
[2K
| Adam | epoch: 013 | loss: 0.45166 - acc: 0.8165 -- iter: 1088/1263
[A[ATraining Step: 515  | total loss: [1m[32m0.43555[0m[0m | time: 66.734s
[2K
| Adam | epoch: 013 | loss: 0.43555 - acc: 0.8286 -- iter: 1120/1263
[A[ATraining Step: 516  | total loss: [1m[32m0.42879[0m[0m | time: 67.765s
[2K
| Adam | epoch: 013 | loss: 0.42879 - acc: 0.8270 -- iter: 1152/1263
[A[ATraining Step: 517  | total loss: [1m[32m0.41637[0m[0m | time: 68.747s
[2K
| Adam | epoch: 013 | loss: 0.41637 - acc: 0.8349 -- iter: 1184/1263
[A[ATraining Step: 518  | total loss: [1m[32m0.40714[0m[0m | time: 69.814s
[2K
| Adam | epoch: 013 | loss: 0.40714 - acc: 0.8389 -- iter: 1216/1263
[A[ATraining Step: 519  | total loss: [1m[32m0.40336[0m[0m | time: 70.850s
[2K
| Adam | epoch: 013 | loss: 0.40336 - acc: 0.8425 -- iter: 1248/1263
[A[ATraining Step: 520  | total loss: [1m[32m0.39809[0m[0m | time: 74.432s
[2K
| Adam | epoch: 013 | loss: 0.39809 - acc: 0.8458 | val_loss: 0.73435 - val_acc: 0.6532 -- iter: 1263/1263
--
Training Step: 521  | total loss: [1m[32m0.38582[0m[0m | time: 1.310s
[2K
| Adam | epoch: 014 | loss: 0.38582 - acc: 0.8487 -- iter: 0032/1263
[A[ATraining Step: 522  | total loss: [1m[32m0.39153[0m[0m | time: 2.563s
[2K
| Adam | epoch: 014 | loss: 0.39153 - acc: 0.8451 -- iter: 0064/1263
[A[ATraining Step: 523  | total loss: [1m[32m0.38980[0m[0m | time: 3.821s
[2K
| Adam | epoch: 014 | loss: 0.38980 - acc: 0.8481 -- iter: 0096/1263
[A[ATraining Step: 524  | total loss: [1m[32m0.38809[0m[0m | time: 5.076s
[2K
| Adam | epoch: 014 | loss: 0.38809 - acc: 0.8476 -- iter: 0128/1263
[A[ATraining Step: 525  | total loss: [1m[32m0.37280[0m[0m | time: 6.104s
[2K
| Adam | epoch: 014 | loss: 0.37280 - acc: 0.8535 -- iter: 0160/1263
[A[ATraining Step: 526  | total loss: [1m[32m0.37308[0m[0m | time: 6.913s
[2K
| Adam | epoch: 014 | loss: 0.37308 - acc: 0.8525 -- iter: 0192/1263
[A[ATraining Step: 527  | total loss: [1m[32m0.36355[0m[0m | time: 7.754s
[2K
| Adam | epoch: 014 | loss: 0.36355 - acc: 0.8579 -- iter: 0224/1263
[A[ATraining Step: 528  | total loss: [1m[32m0.38224[0m[0m | time: 8.560s
[2K
| Adam | epoch: 014 | loss: 0.38224 - acc: 0.8440 -- iter: 0256/1263
[A[ATraining Step: 529  | total loss: [1m[32m0.37408[0m[0m | time: 9.361s
[2K
| Adam | epoch: 014 | loss: 0.37408 - acc: 0.8502 -- iter: 0288/1263
[A[ATraining Step: 530  | total loss: [1m[32m0.38955[0m[0m | time: 10.211s
[2K
| Adam | epoch: 014 | loss: 0.38955 - acc: 0.8371 -- iter: 0320/1263
[A[ATraining Step: 531  | total loss: [1m[32m0.38955[0m[0m | time: 11.026s
[2K
| Adam | epoch: 014 | loss: 0.38955 - acc: 0.8377 -- iter: 0352/1263
[A[ATraining Step: 532  | total loss: [1m[32m0.41481[0m[0m | time: 11.503s
[2K
| Adam | epoch: 014 | loss: 0.41481 - acc: 0.8258 -- iter: 0384/1263
[A[ATraining Step: 533  | total loss: [1m[32m0.40563[0m[0m | time: 11.945s
[2K
| Adam | epoch: 014 | loss: 0.40563 - acc: 0.8233 -- iter: 0416/1263
[A[ATraining Step: 534  | total loss: [1m[32m0.38958[0m[0m | time: 12.774s
[2K
| Adam | epoch: 014 | loss: 0.38958 - acc: 0.8209 -- iter: 0448/1263
[A[ATraining Step: 535  | total loss: [1m[32m0.38029[0m[0m | time: 13.587s
[2K
| Adam | epoch: 014 | loss: 0.38029 - acc: 0.8263 -- iter: 0480/1263
[A[ATraining Step: 536  | total loss: [1m[32m0.40707[0m[0m | time: 14.412s
[2K
| Adam | epoch: 014 | loss: 0.40707 - acc: 0.8156 -- iter: 0512/1263
[A[ATraining Step: 537  | total loss: [1m[32m0.40332[0m[0m | time: 15.209s
[2K
| Adam | epoch: 014 | loss: 0.40332 - acc: 0.8184 -- iter: 0544/1263
[A[ATraining Step: 538  | total loss: [1m[32m0.41801[0m[0m | time: 15.976s
[2K
| Adam | epoch: 014 | loss: 0.41801 - acc: 0.8084 -- iter: 0576/1263
[A[ATraining Step: 539  | total loss: [1m[32m0.43226[0m[0m | time: 16.798s
[2K
| Adam | epoch: 014 | loss: 0.43226 - acc: 0.7963 -- iter: 0608/1263
[A[ATraining Step: 540  | total loss: [1m[32m0.45617[0m[0m | time: 17.608s
[2K
| Adam | epoch: 014 | loss: 0.45617 - acc: 0.7823 -- iter: 0640/1263
[A[ATraining Step: 541  | total loss: [1m[32m0.46445[0m[0m | time: 18.409s
[2K
| Adam | epoch: 014 | loss: 0.46445 - acc: 0.7666 -- iter: 0672/1263
[A[ATraining Step: 542  | total loss: [1m[32m0.46774[0m[0m | time: 19.204s
[2K
| Adam | epoch: 014 | loss: 0.46774 - acc: 0.7681 -- iter: 0704/1263
[A[ATraining Step: 543  | total loss: [1m[32m0.47821[0m[0m | time: 20.016s
[2K
| Adam | epoch: 014 | loss: 0.47821 - acc: 0.7631 -- iter: 0736/1263
[A[ATraining Step: 544  | total loss: [1m[32m0.47287[0m[0m | time: 20.857s
[2K
| Adam | epoch: 014 | loss: 0.47287 - acc: 0.7681 -- iter: 0768/1263
[A[ATraining Step: 545  | total loss: [1m[32m0.45867[0m[0m | time: 21.675s
[2K
| Adam | epoch: 014 | loss: 0.45867 - acc: 0.7725 -- iter: 0800/1263
[A[ATraining Step: 546  | total loss: [1m[32m0.44079[0m[0m | time: 22.705s
[2K
| Adam | epoch: 014 | loss: 0.44079 - acc: 0.7890 -- iter: 0832/1263
[A[ATraining Step: 547  | total loss: [1m[32m0.43728[0m[0m | time: 23.806s
[2K
| Adam | epoch: 014 | loss: 0.43728 - acc: 0.7945 -- iter: 0864/1263
[A[ATraining Step: 548  | total loss: [1m[32m0.42691[0m[0m | time: 24.878s
[2K
| Adam | epoch: 014 | loss: 0.42691 - acc: 0.7963 -- iter: 0896/1263
[A[ATraining Step: 549  | total loss: [1m[32m0.41965[0m[0m | time: 25.723s
[2K
| Adam | epoch: 014 | loss: 0.41965 - acc: 0.8042 -- iter: 0928/1263
[A[ATraining Step: 550  | total loss: [1m[32m0.42887[0m[0m | time: 26.656s
[2K
| Adam | epoch: 014 | loss: 0.42887 - acc: 0.7925 -- iter: 0960/1263
[A[ATraining Step: 551  | total loss: [1m[32m0.42366[0m[0m | time: 27.875s
[2K
| Adam | epoch: 014 | loss: 0.42366 - acc: 0.7914 -- iter: 0992/1263
[A[ATraining Step: 552  | total loss: [1m[32m0.41408[0m[0m | time: 30.799s
[2K
| Adam | epoch: 014 | loss: 0.41408 - acc: 0.7966 -- iter: 1024/1263
[A[ATraining Step: 553  | total loss: [1m[32m0.41319[0m[0m | time: 34.271s
[2K
| Adam | epoch: 014 | loss: 0.41319 - acc: 0.8013 -- iter: 1056/1263
[A[ATraining Step: 554  | total loss: [1m[32m0.40017[0m[0m | time: 38.230s
[2K
| Adam | epoch: 014 | loss: 0.40017 - acc: 0.8118 -- iter: 1088/1263
[A[ATraining Step: 555  | total loss: [1m[32m0.38637[0m[0m | time: 41.248s
[2K
| Adam | epoch: 014 | loss: 0.38637 - acc: 0.8275 -- iter: 1120/1263
[A[ATraining Step: 556  | total loss: [1m[32m0.39214[0m[0m | time: 43.290s
[2K
| Adam | epoch: 014 | loss: 0.39214 - acc: 0.8229 -- iter: 1152/1263
[A[ATraining Step: 557  | total loss: [1m[32m0.38840[0m[0m | time: 47.383s
[2K
| Adam | epoch: 014 | loss: 0.38840 - acc: 0.8218 -- iter: 1184/1263
[A[ATraining Step: 558  | total loss: [1m[32m0.40356[0m[0m | time: 51.047s
[2K
| Adam | epoch: 014 | loss: 0.40356 - acc: 0.8115 -- iter: 1216/1263
[A[ATraining Step: 559  | total loss: [1m[32m0.38828[0m[0m | time: 56.146s
[2K
| Adam | epoch: 014 | loss: 0.38828 - acc: 0.8273 -- iter: 1248/1263
[A[ATraining Step: 560  | total loss: [1m[32m0.39297[0m[0m | time: 65.873s
[2K
| Adam | epoch: 014 | loss: 0.39297 - acc: 0.8320 | val_loss: 0.69302 - val_acc: 0.6861 -- iter: 1263/1263
--
Training Step: 561  | total loss: [1m[32m0.40574[0m[0m | time: 1.085s
[2K
| Adam | epoch: 015 | loss: 0.40574 - acc: 0.8207 -- iter: 0032/1263
[A[ATraining Step: 562  | total loss: [1m[32m0.39701[0m[0m | time: 2.080s
[2K
| Adam | epoch: 015 | loss: 0.39701 - acc: 0.8261 -- iter: 0064/1263
[A[ATraining Step: 563  | total loss: [1m[32m0.38869[0m[0m | time: 3.302s
[2K
| Adam | epoch: 015 | loss: 0.38869 - acc: 0.8248 -- iter: 0096/1263
[A[ATraining Step: 564  | total loss: [1m[32m0.40657[0m[0m | time: 4.530s
[2K
| Adam | epoch: 015 | loss: 0.40657 - acc: 0.8142 -- iter: 0128/1263
[A[ATraining Step: 565  | total loss: [1m[32m0.40814[0m[0m | time: 5.791s
[2K
| Adam | epoch: 015 | loss: 0.40814 - acc: 0.8202 -- iter: 0160/1263
[A[ATraining Step: 566  | total loss: [1m[32m0.39413[0m[0m | time: 6.883s
[2K
| Adam | epoch: 015 | loss: 0.39413 - acc: 0.8288 -- iter: 0192/1263
[A[ATraining Step: 567  | total loss: [1m[32m0.37975[0m[0m | time: 8.358s
[2K
| Adam | epoch: 015 | loss: 0.37975 - acc: 0.8366 -- iter: 0224/1263
[A[ATraining Step: 568  | total loss: [1m[32m0.37013[0m[0m | time: 11.808s
[2K
| Adam | epoch: 015 | loss: 0.37013 - acc: 0.8436 -- iter: 0256/1263
[A[ATraining Step: 569  | total loss: [1m[32m0.36620[0m[0m | time: 16.139s
[2K
| Adam | epoch: 015 | loss: 0.36620 - acc: 0.8467 -- iter: 0288/1263
[A[ATraining Step: 570  | total loss: [1m[32m0.36270[0m[0m | time: 19.474s
[2K
| Adam | epoch: 015 | loss: 0.36270 - acc: 0.8433 -- iter: 0320/1263
[A[ATraining Step: 571  | total loss: [1m[32m0.36673[0m[0m | time: 23.513s
[2K
| Adam | epoch: 015 | loss: 0.36673 - acc: 0.8433 -- iter: 0352/1263
[A[ATraining Step: 572  | total loss: [1m[32m0.37278[0m[0m | time: 29.791s
[2K
| Adam | epoch: 015 | loss: 0.37278 - acc: 0.8402 -- iter: 0384/1263
[A[ATraining Step: 573  | total loss: [1m[32m0.36816[0m[0m | time: 32.587s
[2K
| Adam | epoch: 015 | loss: 0.36816 - acc: 0.8406 -- iter: 0416/1263
[A[ATraining Step: 574  | total loss: [1m[32m0.35706[0m[0m | time: 36.101s
[2K
| Adam | epoch: 015 | loss: 0.35706 - acc: 0.8499 -- iter: 0448/1263
[A[ATraining Step: 575  | total loss: [1m[32m0.33976[0m[0m | time: 38.590s
[2K
| Adam | epoch: 015 | loss: 0.33976 - acc: 0.8649 -- iter: 0480/1263
[A[ATraining Step: 576  | total loss: [1m[32m0.33374[0m[0m | time: 40.370s
[2K
| Adam | epoch: 015 | loss: 0.33374 - acc: 0.8659 -- iter: 0512/1263
[A[ATraining Step: 577  | total loss: [1m[32m0.32524[0m[0m | time: 41.573s
[2K
| Adam | epoch: 015 | loss: 0.32524 - acc: 0.8668 -- iter: 0544/1263
[A[ATraining Step: 578  | total loss: [1m[32m0.32306[0m[0m | time: 42.799s
[2K
| Adam | epoch: 015 | loss: 0.32306 - acc: 0.8707 -- iter: 0576/1263
[A[ATraining Step: 579  | total loss: [1m[32m0.32030[0m[0m | time: 44.017s
[2K
| Adam | epoch: 015 | loss: 0.32030 - acc: 0.8712 -- iter: 0608/1263
[A[ATraining Step: 580  | total loss: [1m[32m0.31130[0m[0m | time: 45.034s
[2K
| Adam | epoch: 015 | loss: 0.31130 - acc: 0.8747 -- iter: 0640/1263
[A[ATraining Step: 581  | total loss: [1m[32m0.31053[0m[0m | time: 46.211s
[2K
| Adam | epoch: 015 | loss: 0.31053 - acc: 0.8810 -- iter: 0672/1263
[A[ATraining Step: 582  | total loss: [1m[32m0.31388[0m[0m | time: 47.360s
[2K
| Adam | epoch: 015 | loss: 0.31388 - acc: 0.8772 -- iter: 0704/1263
[A[ATraining Step: 583  | total loss: [1m[32m0.33036[0m[0m | time: 48.526s
[2K
| Adam | epoch: 015 | loss: 0.33036 - acc: 0.8708 -- iter: 0736/1263
[A[ATraining Step: 584  | total loss: [1m[32m0.32018[0m[0m | time: 49.772s
[2K
| Adam | epoch: 015 | loss: 0.32018 - acc: 0.8743 -- iter: 0768/1263
[A[ATraining Step: 585  | total loss: [1m[32m0.30348[0m[0m | time: 52.416s
[2K
| Adam | epoch: 015 | loss: 0.30348 - acc: 0.8838 -- iter: 0800/1263
[A[ATraining Step: 586  | total loss: [1m[32m0.29850[0m[0m | time: 54.166s
[2K
| Adam | epoch: 015 | loss: 0.29850 - acc: 0.8829 -- iter: 0832/1263
[A[ATraining Step: 587  | total loss: [1m[32m0.30589[0m[0m | time: 57.123s
[2K
| Adam | epoch: 015 | loss: 0.30589 - acc: 0.8758 -- iter: 0864/1263
[A[ATraining Step: 588  | total loss: [1m[32m0.29534[0m[0m | time: 60.120s
[2K
| Adam | epoch: 015 | loss: 0.29534 - acc: 0.8789 -- iter: 0896/1263
[A[ATraining Step: 589  | total loss: [1m[32m0.29724[0m[0m | time: 64.835s
[2K
| Adam | epoch: 015 | loss: 0.29724 - acc: 0.8785 -- iter: 0928/1263
[A[ATraining Step: 590  | total loss: [1m[32m0.28265[0m[0m | time: 68.712s
[2K
| Adam | epoch: 015 | loss: 0.28265 - acc: 0.8875 -- iter: 0960/1263
[A[ATraining Step: 591  | total loss: [1m[32m0.28213[0m[0m | time: 71.296s
[2K
| Adam | epoch: 015 | loss: 0.28213 - acc: 0.8863 -- iter: 0992/1263
[A[ATraining Step: 592  | total loss: [1m[32m0.28566[0m[0m | time: 73.995s
[2K
| Adam | epoch: 015 | loss: 0.28566 - acc: 0.8883 -- iter: 1024/1263
[A[ATraining Step: 593  | total loss: [1m[32m0.27343[0m[0m | time: 77.676s
[2K
| Adam | epoch: 015 | loss: 0.27343 - acc: 0.8932 -- iter: 1056/1263
[A[ATraining Step: 594  | total loss: [1m[32m0.26402[0m[0m | time: 81.465s
[2K
| Adam | epoch: 015 | loss: 0.26402 - acc: 0.8976 -- iter: 1088/1263
[A[ATraining Step: 595  | total loss: [1m[32m0.25239[0m[0m | time: 82.955s
[2K
| Adam | epoch: 015 | loss: 0.25239 - acc: 0.9047 -- iter: 1120/1263
[A[ATraining Step: 596  | total loss: [1m[32m0.26351[0m[0m | time: 84.107s
[2K
| Adam | epoch: 015 | loss: 0.26351 - acc: 0.8986 -- iter: 1152/1263
[A[ATraining Step: 597  | total loss: [1m[32m0.27273[0m[0m | time: 85.246s
[2K
| Adam | epoch: 015 | loss: 0.27273 - acc: 0.8963 -- iter: 1184/1263
[A[ATraining Step: 598  | total loss: [1m[32m0.28422[0m[0m | time: 86.391s
[2K
| Adam | epoch: 015 | loss: 0.28422 - acc: 0.8879 -- iter: 1216/1263
[A[ATraining Step: 599  | total loss: [1m[32m0.27764[0m[0m | time: 87.555s
[2K
| Adam | epoch: 015 | loss: 0.27764 - acc: 0.8897 -- iter: 1248/1263
[A[ATraining Step: 600  | total loss: [1m[32m0.28733[0m[0m | time: 91.889s
[2K
| Adam | epoch: 015 | loss: 0.28733 - acc: 0.8820 | val_loss: 0.77412 - val_acc: 0.7013 -- iter: 1263/1263
--
Training Step: 601  | total loss: [1m[32m0.26691[0m[0m | time: 5.714s
[2K
| Adam | epoch: 016 | loss: 0.26691 - acc: 0.8938 -- iter: 0032/1263
[A[ATraining Step: 602  | total loss: [1m[32m0.26788[0m[0m | time: 9.556s
[2K
| Adam | epoch: 016 | loss: 0.26788 - acc: 0.8888 -- iter: 0064/1263
[A[ATraining Step: 603  | total loss: [1m[32m0.29424[0m[0m | time: 12.952s
[2K
| Adam | epoch: 016 | loss: 0.29424 - acc: 0.8718 -- iter: 0096/1263
[A[ATraining Step: 604  | total loss: [1m[32m0.28905[0m[0m | time: 15.470s
[2K
| Adam | epoch: 016 | loss: 0.28905 - acc: 0.8784 -- iter: 0128/1263
[A[ATraining Step: 605  | total loss: [1m[32m0.28567[0m[0m | time: 18.847s
[2K
| Adam | epoch: 016 | loss: 0.28567 - acc: 0.8812 -- iter: 0160/1263
[A[ATraining Step: 606  | total loss: [1m[32m0.27396[0m[0m | time: 21.650s
[2K
| Adam | epoch: 016 | loss: 0.27396 - acc: 0.8899 -- iter: 0192/1263
[A[ATraining Step: 607  | total loss: [1m[32m0.29742[0m[0m | time: 24.595s
[2K
| Adam | epoch: 016 | loss: 0.29742 - acc: 0.8790 -- iter: 0224/1263
[A[ATraining Step: 608  | total loss: [1m[32m0.30703[0m[0m | time: 27.525s
[2K
| Adam | epoch: 016 | loss: 0.30703 - acc: 0.8724 -- iter: 0256/1263
[A[ATraining Step: 609  | total loss: [1m[32m0.30645[0m[0m | time: 28.691s
[2K
| Adam | epoch: 016 | loss: 0.30645 - acc: 0.8695 -- iter: 0288/1263
[A[ATraining Step: 610  | total loss: [1m[32m0.29951[0m[0m | time: 29.974s
[2K
| Adam | epoch: 016 | loss: 0.29951 - acc: 0.8732 -- iter: 0320/1263
[A[ATraining Step: 611  | total loss: [1m[32m0.29443[0m[0m | time: 31.305s
[2K
| Adam | epoch: 016 | loss: 0.29443 - acc: 0.8796 -- iter: 0352/1263
[A[ATraining Step: 612  | total loss: [1m[32m0.30322[0m[0m | time: 32.398s
[2K
| Adam | epoch: 016 | loss: 0.30322 - acc: 0.8823 -- iter: 0384/1263
[A[ATraining Step: 613  | total loss: [1m[32m0.29212[0m[0m | time: 33.497s
[2K
| Adam | epoch: 016 | loss: 0.29212 - acc: 0.8909 -- iter: 0416/1263
[A[ATraining Step: 614  | total loss: [1m[32m0.29689[0m[0m | time: 34.030s
[2K
| Adam | epoch: 016 | loss: 0.29689 - acc: 0.8862 -- iter: 0448/1263
[A[ATraining Step: 615  | total loss: [1m[32m0.28790[0m[0m | time: 34.648s
[2K
| Adam | epoch: 016 | loss: 0.28790 - acc: 0.8909 -- iter: 0480/1263
[A[ATraining Step: 616  | total loss: [1m[32m0.26881[0m[0m | time: 35.842s
[2K
| Adam | epoch: 016 | loss: 0.26881 - acc: 0.9018 -- iter: 0512/1263
[A[ATraining Step: 617  | total loss: [1m[32m0.27844[0m[0m | time: 36.907s
[2K
| Adam | epoch: 016 | loss: 0.27844 - acc: 0.8960 -- iter: 0544/1263
[A[ATraining Step: 618  | total loss: [1m[32m0.30476[0m[0m | time: 38.058s
[2K
| Adam | epoch: 016 | loss: 0.30476 - acc: 0.8814 -- iter: 0576/1263
[A[ATraining Step: 619  | total loss: [1m[32m0.31554[0m[0m | time: 39.165s
[2K
| Adam | epoch: 016 | loss: 0.31554 - acc: 0.8808 -- iter: 0608/1263
[A[ATraining Step: 620  | total loss: [1m[32m0.32862[0m[0m | time: 40.615s
[2K
| Adam | epoch: 016 | loss: 0.32862 - acc: 0.8740 -- iter: 0640/1263
[A[ATraining Step: 621  | total loss: [1m[32m0.32464[0m[0m | time: 44.181s
[2K
| Adam | epoch: 016 | loss: 0.32464 - acc: 0.8741 -- iter: 0672/1263
[A[ATraining Step: 622  | total loss: [1m[32m0.31851[0m[0m | time: 45.479s
[2K
| Adam | epoch: 016 | loss: 0.31851 - acc: 0.8773 -- iter: 0704/1263
[A[ATraining Step: 623  | total loss: [1m[32m0.32691[0m[0m | time: 48.623s
[2K
| Adam | epoch: 016 | loss: 0.32691 - acc: 0.8677 -- iter: 0736/1263
[A[ATraining Step: 624  | total loss: [1m[32m0.33705[0m[0m | time: 53.802s
[2K
| Adam | epoch: 016 | loss: 0.33705 - acc: 0.8653 -- iter: 0768/1263
[A[ATraining Step: 625  | total loss: [1m[32m0.31603[0m[0m | time: 57.081s
[2K
| Adam | epoch: 016 | loss: 0.31603 - acc: 0.8756 -- iter: 0800/1263
[A[ATraining Step: 626  | total loss: [1m[32m0.29664[0m[0m | time: 60.759s
[2K
| Adam | epoch: 016 | loss: 0.29664 - acc: 0.8881 -- iter: 0832/1263
[A[ATraining Step: 627  | total loss: [1m[32m0.27966[0m[0m | time: 61.925s
[2K
| Adam | epoch: 016 | loss: 0.27966 - acc: 0.8961 -- iter: 0864/1263
[A[ATraining Step: 628  | total loss: [1m[32m0.27358[0m[0m | time: 63.258s
[2K
| Adam | epoch: 016 | loss: 0.27358 - acc: 0.8971 -- iter: 0896/1263
[A[ATraining Step: 629  | total loss: [1m[32m0.26600[0m[0m | time: 64.552s
[2K
| Adam | epoch: 016 | loss: 0.26600 - acc: 0.9012 -- iter: 0928/1263
[A[ATraining Step: 630  | total loss: [1m[32m0.26188[0m[0m | time: 65.666s
[2K
| Adam | epoch: 016 | loss: 0.26188 - acc: 0.9017 -- iter: 0960/1263
[A[ATraining Step: 631  | total loss: [1m[32m0.24829[0m[0m | time: 66.815s
[2K
| Adam | epoch: 016 | loss: 0.24829 - acc: 0.9084 -- iter: 0992/1263
[A[ATraining Step: 632  | total loss: [1m[32m0.24650[0m[0m | time: 68.041s
[2K
| Adam | epoch: 016 | loss: 0.24650 - acc: 0.9051 -- iter: 1024/1263
[A[ATraining Step: 633  | total loss: [1m[32m0.24291[0m[0m | time: 69.365s
[2K
| Adam | epoch: 016 | loss: 0.24291 - acc: 0.9020 -- iter: 1056/1263
[A[ATraining Step: 634  | total loss: [1m[32m0.26736[0m[0m | time: 70.521s
[2K
| Adam | epoch: 016 | loss: 0.26736 - acc: 0.8868 -- iter: 1088/1263
[A[ATraining Step: 635  | total loss: [1m[32m0.28374[0m[0m | time: 71.680s
[2K
| Adam | epoch: 016 | loss: 0.28374 - acc: 0.8732 -- iter: 1120/1263
[A[ATraining Step: 636  | total loss: [1m[32m0.27086[0m[0m | time: 73.007s
[2K
| Adam | epoch: 016 | loss: 0.27086 - acc: 0.8796 -- iter: 1152/1263
[A[ATraining Step: 637  | total loss: [1m[32m0.25545[0m[0m | time: 74.398s
[2K
| Adam | epoch: 016 | loss: 0.25545 - acc: 0.8854 -- iter: 1184/1263
[A[ATraining Step: 638  | total loss: [1m[32m0.25522[0m[0m | time: 80.766s
[2K
| Adam | epoch: 016 | loss: 0.25522 - acc: 0.8906 -- iter: 1216/1263
[A[ATraining Step: 639  | total loss: [1m[32m0.25561[0m[0m | time: 82.761s
[2K
| Adam | epoch: 016 | loss: 0.25561 - acc: 0.8890 -- iter: 1248/1263
[A[ATraining Step: 640  | total loss: [1m[32m0.25345[0m[0m | time: 87.390s
[2K
| Adam | epoch: 016 | loss: 0.25345 - acc: 0.8908 | val_loss: 0.79290 - val_acc: 0.6911 -- iter: 1263/1263
--
Training Step: 641  | total loss: [1m[32m0.25130[0m[0m | time: 1.228s
[2K
| Adam | epoch: 017 | loss: 0.25130 - acc: 0.8986 -- iter: 0032/1263
[A[ATraining Step: 642  | total loss: [1m[32m0.23710[0m[0m | time: 2.430s
[2K
| Adam | epoch: 017 | loss: 0.23710 - acc: 0.9087 -- iter: 0064/1263
[A[ATraining Step: 643  | total loss: [1m[32m0.22567[0m[0m | time: 3.645s
[2K
| Adam | epoch: 017 | loss: 0.22567 - acc: 0.9147 -- iter: 0096/1263
[A[ATraining Step: 644  | total loss: [1m[32m0.22465[0m[0m | time: 4.809s
[2K
| Adam | epoch: 017 | loss: 0.22465 - acc: 0.9139 -- iter: 0128/1263
[A[ATraining Step: 645  | total loss: [1m[32m0.21442[0m[0m | time: 6.057s
[2K
| Adam | epoch: 017 | loss: 0.21442 - acc: 0.9193 -- iter: 0160/1263
[A[ATraining Step: 646  | total loss: [1m[32m0.20477[0m[0m | time: 7.338s
[2K
| Adam | epoch: 017 | loss: 0.20477 - acc: 0.9243 -- iter: 0192/1263
[A[ATraining Step: 647  | total loss: [1m[32m0.20303[0m[0m | time: 11.908s
[2K
| Adam | epoch: 017 | loss: 0.20303 - acc: 0.9256 -- iter: 0224/1263
[A[ATraining Step: 648  | total loss: [1m[32m0.19441[0m[0m | time: 15.637s
[2K
| Adam | epoch: 017 | loss: 0.19441 - acc: 0.9268 -- iter: 0256/1263
[A[ATraining Step: 649  | total loss: [1m[32m0.20719[0m[0m | time: 20.116s
[2K
| Adam | epoch: 017 | loss: 0.20719 - acc: 0.9185 -- iter: 0288/1263
[A[ATraining Step: 650  | total loss: [1m[32m0.20646[0m[0m | time: 23.795s
[2K
| Adam | epoch: 017 | loss: 0.20646 - acc: 0.9204 -- iter: 0320/1263
[A[ATraining Step: 651  | total loss: [1m[32m0.21043[0m[0m | time: 26.477s
[2K
| Adam | epoch: 017 | loss: 0.21043 - acc: 0.9159 -- iter: 0352/1263
[A[ATraining Step: 652  | total loss: [1m[32m0.20046[0m[0m | time: 28.681s
[2K
| Adam | epoch: 017 | loss: 0.20046 - acc: 0.9211 -- iter: 0384/1263
[A[ATraining Step: 653  | total loss: [1m[32m0.21321[0m[0m | time: 30.012s
[2K
| Adam | epoch: 017 | loss: 0.21321 - acc: 0.9134 -- iter: 0416/1263
[A[ATraining Step: 654  | total loss: [1m[32m0.20727[0m[0m | time: 31.198s
[2K
| Adam | epoch: 017 | loss: 0.20727 - acc: 0.9189 -- iter: 0448/1263
[A[ATraining Step: 655  | total loss: [1m[32m0.21024[0m[0m | time: 31.841s
[2K
| Adam | epoch: 017 | loss: 0.21024 - acc: 0.9208 -- iter: 0480/1263
[A[ATraining Step: 656  | total loss: [1m[32m0.21646[0m[0m | time: 32.399s
[2K
| Adam | epoch: 017 | loss: 0.21646 - acc: 0.9087 -- iter: 0512/1263
[A[ATraining Step: 657  | total loss: [1m[32m0.20994[0m[0m | time: 33.521s
[2K
| Adam | epoch: 017 | loss: 0.20994 - acc: 0.9112 -- iter: 0544/1263
[A[ATraining Step: 658  | total loss: [1m[32m0.20220[0m[0m | time: 34.635s
[2K
| Adam | epoch: 017 | loss: 0.20220 - acc: 0.9169 -- iter: 0576/1263
[A[ATraining Step: 659  | total loss: [1m[32m0.20852[0m[0m | time: 35.882s
[2K
| Adam | epoch: 017 | loss: 0.20852 - acc: 0.9190 -- iter: 0608/1263
[A[ATraining Step: 660  | total loss: [1m[32m0.20053[0m[0m | time: 37.102s
[2K
| Adam | epoch: 017 | loss: 0.20053 - acc: 0.9208 -- iter: 0640/1263
[A[ATraining Step: 661  | total loss: [1m[32m0.20025[0m[0m | time: 38.212s
[2K
| Adam | epoch: 017 | loss: 0.20025 - acc: 0.9225 -- iter: 0672/1263
[A[ATraining Step: 662  | total loss: [1m[32m0.21147[0m[0m | time: 39.266s
[2K
| Adam | epoch: 017 | loss: 0.21147 - acc: 0.9209 -- iter: 0704/1263
[A[ATraining Step: 663  | total loss: [1m[32m0.21304[0m[0m | time: 40.354s
[2K
| Adam | epoch: 017 | loss: 0.21304 - acc: 0.9257 -- iter: 0736/1263
[A[ATraining Step: 664  | total loss: [1m[32m0.22127[0m[0m | time: 41.382s
[2K
| Adam | epoch: 017 | loss: 0.22127 - acc: 0.9175 -- iter: 0768/1263
[A[ATraining Step: 665  | total loss: [1m[32m0.21879[0m[0m | time: 42.429s
[2K
| Adam | epoch: 017 | loss: 0.21879 - acc: 0.9195 -- iter: 0800/1263
[A[ATraining Step: 666  | total loss: [1m[32m0.22880[0m[0m | time: 43.465s
[2K
| Adam | epoch: 017 | loss: 0.22880 - acc: 0.9150 -- iter: 0832/1263
[A[ATraining Step: 667  | total loss: [1m[32m0.22071[0m[0m | time: 44.554s
[2K
| Adam | epoch: 017 | loss: 0.22071 - acc: 0.9173 -- iter: 0864/1263
[A[ATraining Step: 668  | total loss: [1m[32m0.22705[0m[0m | time: 45.825s
[2K
| Adam | epoch: 017 | loss: 0.22705 - acc: 0.9162 -- iter: 0896/1263
[A[ATraining Step: 669  | total loss: [1m[32m0.21160[0m[0m | time: 47.066s
[2K
| Adam | epoch: 017 | loss: 0.21160 - acc: 0.9246 -- iter: 0928/1263
[A[ATraining Step: 670  | total loss: [1m[32m0.20127[0m[0m | time: 48.293s
[2K
| Adam | epoch: 017 | loss: 0.20127 - acc: 0.9321 -- iter: 0960/1263
[A[ATraining Step: 671  | total loss: [1m[32m0.19684[0m[0m | time: 49.532s
[2K
| Adam | epoch: 017 | loss: 0.19684 - acc: 0.9326 -- iter: 0992/1263
[A[ATraining Step: 672  | total loss: [1m[32m0.18963[0m[0m | time: 50.460s
[2K
| Adam | epoch: 017 | loss: 0.18963 - acc: 0.9331 -- iter: 1024/1263
[A[ATraining Step: 673  | total loss: [1m[32m0.19616[0m[0m | time: 51.304s
[2K
| Adam | epoch: 017 | loss: 0.19616 - acc: 0.9336 -- iter: 1056/1263
[A[ATraining Step: 674  | total loss: [1m[32m0.19064[0m[0m | time: 52.161s
[2K
| Adam | epoch: 017 | loss: 0.19064 - acc: 0.9371 -- iter: 1088/1263
[A[ATraining Step: 675  | total loss: [1m[32m0.19134[0m[0m | time: 53.006s
[2K
| Adam | epoch: 017 | loss: 0.19134 - acc: 0.9340 -- iter: 1120/1263
[A[ATraining Step: 676  | total loss: [1m[32m0.18435[0m[0m | time: 53.809s
[2K
| Adam | epoch: 017 | loss: 0.18435 - acc: 0.9375 -- iter: 1152/1263
[A[ATraining Step: 677  | total loss: [1m[32m0.18370[0m[0m | time: 54.641s
[2K
| Adam | epoch: 017 | loss: 0.18370 - acc: 0.9375 -- iter: 1184/1263
[A[ATraining Step: 678  | total loss: [1m[32m0.18822[0m[0m | time: 55.491s
[2K
| Adam | epoch: 017 | loss: 0.18822 - acc: 0.9344 -- iter: 1216/1263
[A[ATraining Step: 679  | total loss: [1m[32m0.17534[0m[0m | time: 56.349s
[2K
| Adam | epoch: 017 | loss: 0.17534 - acc: 0.9409 -- iter: 1248/1263
[A[ATraining Step: 680  | total loss: [1m[32m0.18490[0m[0m | time: 59.236s
[2K
| Adam | epoch: 017 | loss: 0.18490 - acc: 0.9406 | val_loss: 0.91366 - val_acc: 0.7063 -- iter: 1263/1263
--
Training Step: 681  | total loss: [1m[32m0.17892[0m[0m | time: 0.883s
[2K
| Adam | epoch: 018 | loss: 0.17892 - acc: 0.9403 -- iter: 0032/1263
[A[ATraining Step: 682  | total loss: [1m[32m0.16916[0m[0m | time: 1.698s
[2K
| Adam | epoch: 018 | loss: 0.16916 - acc: 0.9431 -- iter: 0064/1263
[A[ATraining Step: 683  | total loss: [1m[32m0.19627[0m[0m | time: 2.558s
[2K
| Adam | epoch: 018 | loss: 0.19627 - acc: 0.9332 -- iter: 0096/1263
[A[ATraining Step: 684  | total loss: [1m[32m0.18583[0m[0m | time: 3.433s
[2K
| Adam | epoch: 018 | loss: 0.18583 - acc: 0.9367 -- iter: 0128/1263
[A[ATraining Step: 685  | total loss: [1m[32m0.19263[0m[0m | time: 4.258s
[2K
| Adam | epoch: 018 | loss: 0.19263 - acc: 0.9337 -- iter: 0160/1263
[A[ATraining Step: 686  | total loss: [1m[32m0.20139[0m[0m | time: 5.101s
[2K
| Adam | epoch: 018 | loss: 0.20139 - acc: 0.9309 -- iter: 0192/1263
[A[ATraining Step: 687  | total loss: [1m[32m0.19384[0m[0m | time: 5.920s
[2K
| Adam | epoch: 018 | loss: 0.19384 - acc: 0.9316 -- iter: 0224/1263
[A[ATraining Step: 688  | total loss: [1m[32m0.19652[0m[0m | time: 6.808s
[2K
| Adam | epoch: 018 | loss: 0.19652 - acc: 0.9291 -- iter: 0256/1263
[A[ATraining Step: 689  | total loss: [1m[32m0.19314[0m[0m | time: 7.622s
[2K
| Adam | epoch: 018 | loss: 0.19314 - acc: 0.9330 -- iter: 0288/1263
[A[ATraining Step: 690  | total loss: [1m[32m0.18578[0m[0m | time: 8.439s
[2K
| Adam | epoch: 018 | loss: 0.18578 - acc: 0.9335 -- iter: 0320/1263
[A[ATraining Step: 691  | total loss: [1m[32m0.17927[0m[0m | time: 9.446s
[2K
| Adam | epoch: 018 | loss: 0.17927 - acc: 0.9339 -- iter: 0352/1263
[A[ATraining Step: 692  | total loss: [1m[32m0.16577[0m[0m | time: 10.459s
[2K
| Adam | epoch: 018 | loss: 0.16577 - acc: 0.9405 -- iter: 0384/1263
[A[ATraining Step: 693  | total loss: [1m[32m0.16967[0m[0m | time: 11.506s
[2K
| Adam | epoch: 018 | loss: 0.16967 - acc: 0.9433 -- iter: 0416/1263
[A[ATraining Step: 694  | total loss: [1m[32m0.16122[0m[0m | time: 12.592s
[2K
| Adam | epoch: 018 | loss: 0.16122 - acc: 0.9490 -- iter: 0448/1263
[A[ATraining Step: 695  | total loss: [1m[32m0.15552[0m[0m | time: 13.656s
[2K
| Adam | epoch: 018 | loss: 0.15552 - acc: 0.9478 -- iter: 0480/1263
[A[ATraining Step: 696  | total loss: [1m[32m0.17216[0m[0m | time: 14.283s
[2K
| Adam | epoch: 018 | loss: 0.17216 - acc: 0.9406 -- iter: 0512/1263
[A[ATraining Step: 697  | total loss: [1m[32m0.17901[0m[0m | time: 15.043s
[2K
| Adam | epoch: 018 | loss: 0.17901 - acc: 0.9332 -- iter: 0544/1263
[A[ATraining Step: 698  | total loss: [1m[32m0.17350[0m[0m | time: 16.430s
[2K
| Adam | epoch: 018 | loss: 0.17350 - acc: 0.9332 -- iter: 0576/1263
[A[ATraining Step: 699  | total loss: [1m[32m0.18246[0m[0m | time: 21.327s
[2K
| Adam | epoch: 018 | loss: 0.18246 - acc: 0.9336 -- iter: 0608/1263
[A[ATraining Step: 700  | total loss: [1m[32m0.17689[0m[0m | time: 25.487s
[2K
| Adam | epoch: 018 | loss: 0.17689 - acc: 0.9340 -- iter: 0640/1263
[A[ATraining Step: 701  | total loss: [1m[32m0.16893[0m[0m | time: 31.220s
[2K
| Adam | epoch: 018 | loss: 0.16893 - acc: 0.9344 -- iter: 0672/1263
[A[ATraining Step: 702  | total loss: [1m[32m0.16741[0m[0m | time: 34.033s
[2K
| Adam | epoch: 018 | loss: 0.16741 - acc: 0.9315 -- iter: 0704/1263
[A[ATraining Step: 703  | total loss: [1m[32m0.15734[0m[0m | time: 37.007s
[2K
| Adam | epoch: 018 | loss: 0.15734 - acc: 0.9384 -- iter: 0736/1263
[A[ATraining Step: 704  | total loss: [1m[32m0.15790[0m[0m | time: 39.771s
[2K
| Adam | epoch: 018 | loss: 0.15790 - acc: 0.9383 -- iter: 0768/1263
[A[ATraining Step: 705  | total loss: [1m[32m0.18642[0m[0m | time: 44.459s
[2K
| Adam | epoch: 018 | loss: 0.18642 - acc: 0.9226 -- iter: 0800/1263
[A[ATraining Step: 706  | total loss: [1m[32m0.28766[0m[0m | time: 46.724s
[2K
| Adam | epoch: 018 | loss: 0.28766 - acc: 0.9022 -- iter: 0832/1263
[A[ATraining Step: 707  | total loss: [1m[32m0.26704[0m[0m | time: 47.767s
[2K
| Adam | epoch: 018 | loss: 0.26704 - acc: 0.9120 -- iter: 0864/1263
[A[ATraining Step: 708  | total loss: [1m[32m0.25659[0m[0m | time: 48.987s
[2K
| Adam | epoch: 018 | loss: 0.25659 - acc: 0.9177 -- iter: 0896/1263
[A[ATraining Step: 709  | total loss: [1m[32m0.23445[0m[0m | time: 50.129s
[2K
| Adam | epoch: 018 | loss: 0.23445 - acc: 0.9259 -- iter: 0928/1263
[A[ATraining Step: 710  | total loss: [1m[32m0.22710[0m[0m | time: 51.303s
[2K
| Adam | epoch: 018 | loss: 0.22710 - acc: 0.9302 -- iter: 0960/1263
[A[ATraining Step: 711  | total loss: [1m[32m0.20812[0m[0m | time: 52.538s
[2K
| Adam | epoch: 018 | loss: 0.20812 - acc: 0.9372 -- iter: 0992/1263
[A[ATraining Step: 712  | total loss: [1m[32m0.20277[0m[0m | time: 53.773s
[2K
| Adam | epoch: 018 | loss: 0.20277 - acc: 0.9372 -- iter: 1024/1263
[A[ATraining Step: 713  | total loss: [1m[32m0.19355[0m[0m | time: 54.917s
[2K
| Adam | epoch: 018 | loss: 0.19355 - acc: 0.9372 -- iter: 1056/1263
[A[ATraining Step: 714  | total loss: [1m[32m0.17983[0m[0m | time: 56.115s
[2K
| Adam | epoch: 018 | loss: 0.17983 - acc: 0.9435 -- iter: 1088/1263
[A[ATraining Step: 715  | total loss: [1m[32m0.17115[0m[0m | time: 57.392s
[2K
| Adam | epoch: 018 | loss: 0.17115 - acc: 0.9460 -- iter: 1120/1263
[A[ATraining Step: 716  | total loss: [1m[32m0.17883[0m[0m | time: 60.652s
[2K
| Adam | epoch: 018 | loss: 0.17883 - acc: 0.9452 -- iter: 1152/1263
[A[ATraining Step: 717  | total loss: [1m[32m0.18053[0m[0m | time: 63.291s
[2K
| Adam | epoch: 018 | loss: 0.18053 - acc: 0.9413 -- iter: 1184/1263
[A[ATraining Step: 718  | total loss: [1m[32m0.17057[0m[0m | time: 66.993s
[2K
| Adam | epoch: 018 | loss: 0.17057 - acc: 0.9440 -- iter: 1216/1263
[A[ATraining Step: 719  | total loss: [1m[32m0.16514[0m[0m | time: 70.931s
[2K
| Adam | epoch: 018 | loss: 0.16514 - acc: 0.9403 -- iter: 1248/1263
[A[ATraining Step: 720  | total loss: [1m[32m0.17686[0m[0m | time: 76.525s
[2K
| Adam | epoch: 018 | loss: 0.17686 - acc: 0.9400 | val_loss: 0.91834 - val_acc: 0.6886 -- iter: 1263/1263
--
Training Step: 721  | total loss: [1m[32m0.17057[0m[0m | time: 1.258s
[2K
| Adam | epoch: 019 | loss: 0.17057 - acc: 0.9429 -- iter: 0032/1263
[A[ATraining Step: 722  | total loss: [1m[32m0.16918[0m[0m | time: 2.437s
[2K
| Adam | epoch: 019 | loss: 0.16918 - acc: 0.9423 -- iter: 0064/1263
[A[ATraining Step: 723  | total loss: [1m[32m0.18199[0m[0m | time: 3.656s
[2K
| Adam | epoch: 019 | loss: 0.18199 - acc: 0.9387 -- iter: 0096/1263
[A[ATraining Step: 724  | total loss: [1m[32m0.18417[0m[0m | time: 4.844s
[2K
| Adam | epoch: 019 | loss: 0.18417 - acc: 0.9323 -- iter: 0128/1263
[A[ATraining Step: 725  | total loss: [1m[32m0.20531[0m[0m | time: 5.938s
[2K
| Adam | epoch: 019 | loss: 0.20531 - acc: 0.9297 -- iter: 0160/1263
[A[ATraining Step: 726  | total loss: [1m[32m0.19056[0m[0m | time: 7.119s
[2K
| Adam | epoch: 019 | loss: 0.19056 - acc: 0.9368 -- iter: 0192/1263
[A[ATraining Step: 727  | total loss: [1m[32m0.20717[0m[0m | time: 8.533s
[2K
| Adam | epoch: 019 | loss: 0.20717 - acc: 0.9275 -- iter: 0224/1263
[A[ATraining Step: 728  | total loss: [1m[32m0.19269[0m[0m | time: 12.848s
[2K
| Adam | epoch: 019 | loss: 0.19269 - acc: 0.9347 -- iter: 0256/1263
[A[ATraining Step: 729  | total loss: [1m[32m0.19222[0m[0m | time: 16.884s
[2K
| Adam | epoch: 019 | loss: 0.19222 - acc: 0.9381 -- iter: 0288/1263
[A[ATraining Step: 730  | total loss: [1m[32m0.18210[0m[0m | time: 19.136s
[2K
| Adam | epoch: 019 | loss: 0.18210 - acc: 0.9412 -- iter: 0320/1263
[A[ATraining Step: 731  | total loss: [1m[32m0.18094[0m[0m | time: 21.442s
[2K
| Adam | epoch: 019 | loss: 0.18094 - acc: 0.9377 -- iter: 0352/1263
[A[ATraining Step: 732  | total loss: [1m[32m0.18137[0m[0m | time: 24.392s
[2K
| Adam | epoch: 019 | loss: 0.18137 - acc: 0.9377 -- iter: 0384/1263
[A[ATraining Step: 733  | total loss: [1m[32m0.20333[0m[0m | time: 27.142s
[2K
| Adam | epoch: 019 | loss: 0.20333 - acc: 0.9314 -- iter: 0416/1263
[A[ATraining Step: 734  | total loss: [1m[32m0.18917[0m[0m | time: 29.272s
[2K
| Adam | epoch: 019 | loss: 0.18917 - acc: 0.9383 -- iter: 0448/1263
[A[ATraining Step: 735  | total loss: [1m[32m0.21300[0m[0m | time: 31.297s
[2K
| Adam | epoch: 019 | loss: 0.21300 - acc: 0.9319 -- iter: 0480/1263
[A[ATraining Step: 736  | total loss: [1m[32m0.21133[0m[0m | time: 34.463s
[2K
| Adam | epoch: 019 | loss: 0.21133 - acc: 0.9356 -- iter: 0512/1263
[A[ATraining Step: 737  | total loss: [1m[32m0.21631[0m[0m | time: 36.376s
[2K
| Adam | epoch: 019 | loss: 0.21631 - acc: 0.9327 -- iter: 0544/1263
[A[ATraining Step: 738  | total loss: [1m[32m0.21667[0m[0m | time: 37.797s
[2K
| Adam | epoch: 019 | loss: 0.21667 - acc: 0.9327 -- iter: 0576/1263
[A[ATraining Step: 739  | total loss: [1m[32m0.20791[0m[0m | time: 38.730s
[2K
| Adam | epoch: 019 | loss: 0.20791 - acc: 0.9328 -- iter: 0608/1263
[A[ATraining Step: 740  | total loss: [1m[32m0.20118[0m[0m | time: 39.819s
[2K
| Adam | epoch: 019 | loss: 0.20118 - acc: 0.9333 -- iter: 0640/1263
[A[ATraining Step: 741  | total loss: [1m[32m0.20323[0m[0m | time: 40.950s
[2K
| Adam | epoch: 019 | loss: 0.20323 - acc: 0.9306 -- iter: 0672/1263
[A[ATraining Step: 742  | total loss: [1m[32m0.20943[0m[0m | time: 42.131s
[2K
| Adam | epoch: 019 | loss: 0.20943 - acc: 0.9250 -- iter: 0704/1263
[A[ATraining Step: 743  | total loss: [1m[32m0.20803[0m[0m | time: 43.275s
[2K
| Adam | epoch: 019 | loss: 0.20803 - acc: 0.9231 -- iter: 0736/1263
[A[ATraining Step: 744  | total loss: [1m[32m0.19883[0m[0m | time: 44.480s
[2K
| Adam | epoch: 019 | loss: 0.19883 - acc: 0.9277 -- iter: 0768/1263
[A[ATraining Step: 745  | total loss: [1m[32m0.18956[0m[0m | time: 45.685s
[2K
| Adam | epoch: 019 | loss: 0.18956 - acc: 0.9318 -- iter: 0800/1263
[A[ATraining Step: 746  | total loss: [1m[32m0.18171[0m[0m | time: 46.831s
[2K
| Adam | epoch: 019 | loss: 0.18171 - acc: 0.9355 -- iter: 0832/1263
[A[ATraining Step: 747  | total loss: [1m[32m0.18248[0m[0m | time: 47.930s
[2K
| Adam | epoch: 019 | loss: 0.18248 - acc: 0.9357 -- iter: 0864/1263
[A[ATraining Step: 748  | total loss: [1m[32m0.17669[0m[0m | time: 49.227s
[2K
| Adam | epoch: 019 | loss: 0.17669 - acc: 0.9359 -- iter: 0896/1263
[A[ATraining Step: 749  | total loss: [1m[32m0.16326[0m[0m | time: 53.568s
[2K
| Adam | epoch: 019 | loss: 0.16326 - acc: 0.9423 -- iter: 0928/1263
[A[ATraining Step: 750  | total loss: [1m[32m0.14897[0m[0m | time: 57.825s
[2K
| Adam | epoch: 019 | loss: 0.14897 - acc: 0.9481 -- iter: 0960/1263
[A[ATraining Step: 751  | total loss: [1m[32m0.14281[0m[0m | time: 61.388s
[2K
| Adam | epoch: 019 | loss: 0.14281 - acc: 0.9501 -- iter: 0992/1263
[A[ATraining Step: 752  | total loss: [1m[32m0.13444[0m[0m | time: 63.519s
[2K
| Adam | epoch: 019 | loss: 0.13444 - acc: 0.9520 -- iter: 1024/1263
[A[ATraining Step: 753  | total loss: [1m[32m0.14805[0m[0m | time: 64.589s
[2K
| Adam | epoch: 019 | loss: 0.14805 - acc: 0.9505 -- iter: 1056/1263
[A[ATraining Step: 754  | total loss: [1m[32m0.14432[0m[0m | time: 65.755s
[2K
| Adam | epoch: 019 | loss: 0.14432 - acc: 0.9524 -- iter: 1088/1263
[A[ATraining Step: 755  | total loss: [1m[32m0.13862[0m[0m | time: 66.842s
[2K
| Adam | epoch: 019 | loss: 0.13862 - acc: 0.9540 -- iter: 1120/1263
[A[ATraining Step: 756  | total loss: [1m[32m0.13019[0m[0m | time: 68.013s
[2K
| Adam | epoch: 019 | loss: 0.13019 - acc: 0.9586 -- iter: 1152/1263
[A[ATraining Step: 757  | total loss: [1m[32m0.12492[0m[0m | time: 69.215s
[2K
| Adam | epoch: 019 | loss: 0.12492 - acc: 0.9596 -- iter: 1184/1263
[A[ATraining Step: 758  | total loss: [1m[32m0.12125[0m[0m | time: 70.416s
[2K
| Adam | epoch: 019 | loss: 0.12125 - acc: 0.9605 -- iter: 1216/1263
[A[ATraining Step: 759  | total loss: [1m[32m0.13537[0m[0m | time: 71.540s
[2K
| Adam | epoch: 019 | loss: 0.13537 - acc: 0.9551 -- iter: 1248/1263
[A[ATraining Step: 760  | total loss: [1m[32m0.12442[0m[0m | time: 92.963s
[2K
| Adam | epoch: 019 | loss: 0.12442 - acc: 0.9596 | val_loss: 1.04420 - val_acc: 0.6785 -- iter: 1263/1263
--
Training Step: 761  | total loss: [1m[32m0.11514[0m[0m | time: 1.110s
[2K
| Adam | epoch: 020 | loss: 0.11514 - acc: 0.9636 -- iter: 0032/1263
[A[ATraining Step: 762  | total loss: [1m[32m0.11839[0m[0m | time: 2.441s
[2K
| Adam | epoch: 020 | loss: 0.11839 - acc: 0.9579 -- iter: 0064/1263
[A[ATraining Step: 763  | total loss: [1m[32m0.13604[0m[0m | time: 3.791s
[2K
| Adam | epoch: 020 | loss: 0.13604 - acc: 0.9559 -- iter: 0096/1263
[A[ATraining Step: 764  | total loss: [1m[32m0.12684[0m[0m | time: 5.065s
[2K
| Adam | epoch: 020 | loss: 0.12684 - acc: 0.9603 -- iter: 0128/1263
[A[ATraining Step: 765  | total loss: [1m[32m0.13561[0m[0m | time: 6.338s
[2K
| Adam | epoch: 020 | loss: 0.13561 - acc: 0.9549 -- iter: 0160/1263
[A[ATraining Step: 766  | total loss: [1m[32m0.13162[0m[0m | time: 7.439s
[2K
| Adam | epoch: 020 | loss: 0.13162 - acc: 0.9563 -- iter: 0192/1263
[A[ATraining Step: 767  | total loss: [1m[32m0.14267[0m[0m | time: 8.635s
[2K
| Adam | epoch: 020 | loss: 0.14267 - acc: 0.9575 -- iter: 0224/1263
[A[ATraining Step: 768  | total loss: [1m[32m0.13795[0m[0m | time: 9.720s
[2K
| Adam | epoch: 020 | loss: 0.13795 - acc: 0.9586 -- iter: 0256/1263
[A[ATraining Step: 769  | total loss: [1m[32m0.14192[0m[0m | time: 10.877s
[2K
| Adam | epoch: 020 | loss: 0.14192 - acc: 0.9534 -- iter: 0288/1263
[A[ATraining Step: 770  | total loss: [1m[32m0.14708[0m[0m | time: 12.198s
[2K
| Adam | epoch: 020 | loss: 0.14708 - acc: 0.9518 -- iter: 0320/1263
[A[ATraining Step: 771  | total loss: [1m[32m0.13927[0m[0m | time: 20.613s
[2K
| Adam | epoch: 020 | loss: 0.13927 - acc: 0.9535 -- iter: 0352/1263
[A[ATraining Step: 772  | total loss: [1m[32m0.12820[0m[0m | time: 23.403s
[2K
| Adam | epoch: 020 | loss: 0.12820 - acc: 0.9581 -- iter: 0384/1263
[A[ATraining Step: 773  | total loss: [1m[32m0.12780[0m[0m | time: 26.593s
[2K
| Adam | epoch: 020 | loss: 0.12780 - acc: 0.9592 -- iter: 0416/1263
[A[ATraining Step: 774  | total loss: [1m[32m0.12329[0m[0m | time: 28.843s
[2K
| Adam | epoch: 020 | loss: 0.12329 - acc: 0.9602 -- iter: 0448/1263
[A[ATraining Step: 775  | total loss: [1m[32m0.12897[0m[0m | time: 29.832s
[2K
| Adam | epoch: 020 | loss: 0.12897 - acc: 0.9548 -- iter: 0480/1263
[A[ATraining Step: 776  | total loss: [1m[32m0.14652[0m[0m | time: 31.010s
[2K
| Adam | epoch: 020 | loss: 0.14652 - acc: 0.9499 -- iter: 0512/1263
[A[ATraining Step: 777  | total loss: [1m[32m0.14333[0m[0m | time: 32.155s
[2K
| Adam | epoch: 020 | loss: 0.14333 - acc: 0.9487 -- iter: 0544/1263
[A[ATraining Step: 778  | total loss: [1m[32m0.14755[0m[0m | time: 32.734s
[2K
| Adam | epoch: 020 | loss: 0.14755 - acc: 0.9444 -- iter: 0576/1263
[A[ATraining Step: 779  | total loss: [1m[32m0.14558[0m[0m | time: 33.328s
[2K
| Adam | epoch: 020 | loss: 0.14558 - acc: 0.9500 -- iter: 0608/1263
[A[ATraining Step: 780  | total loss: [1m[32m0.13860[0m[0m | time: 34.481s
[2K
| Adam | epoch: 020 | loss: 0.13860 - acc: 0.9550 -- iter: 0640/1263
[A[ATraining Step: 781  | total loss: [1m[32m0.14024[0m[0m | time: 35.626s
[2K
| Adam | epoch: 020 | loss: 0.14024 - acc: 0.9564 -- iter: 0672/1263
[A[ATraining Step: 782  | total loss: [1m[32m0.13124[0m[0m | time: 36.876s
[2K
| Adam | epoch: 020 | loss: 0.13124 - acc: 0.9607 -- iter: 0704/1263
[A[ATraining Step: 783  | total loss: [1m[32m0.14441[0m[0m | time: 38.033s
[2K
| Adam | epoch: 020 | loss: 0.14441 - acc: 0.9522 -- iter: 0736/1263
[A[ATraining Step: 784  | total loss: [1m[32m0.15303[0m[0m | time: 39.390s
[2K
| Adam | epoch: 020 | loss: 0.15303 - acc: 0.9476 -- iter: 0768/1263
[A[ATraining Step: 785  | total loss: [1m[32m0.15547[0m[0m | time: 44.244s
[2K
| Adam | epoch: 020 | loss: 0.15547 - acc: 0.9466 -- iter: 0800/1263
[A[ATraining Step: 786  | total loss: [1m[32m0.15532[0m[0m | time: 48.672s
[2K
| Adam | epoch: 020 | loss: 0.15532 - acc: 0.9457 -- iter: 0832/1263
[A[ATraining Step: 787  | total loss: [1m[32m0.16239[0m[0m | time: 51.931s
[2K
| Adam | epoch: 020 | loss: 0.16239 - acc: 0.9448 -- iter: 0864/1263
[A[ATraining Step: 788  | total loss: [1m[32m0.15143[0m[0m | time: 53.745s
[2K
| Adam | epoch: 020 | loss: 0.15143 - acc: 0.9504 -- iter: 0896/1263
[A[ATraining Step: 789  | total loss: [1m[32m0.15436[0m[0m | time: 56.518s
[2K
| Adam | epoch: 020 | loss: 0.15436 - acc: 0.9522 -- iter: 0928/1263
[A[ATraining Step: 790  | total loss: [1m[32m0.14377[0m[0m | time: 59.623s
[2K
| Adam | epoch: 020 | loss: 0.14377 - acc: 0.9570 -- iter: 0960/1263
[A[ATraining Step: 791  | total loss: [1m[32m0.13175[0m[0m | time: 61.064s
[2K
| Adam | epoch: 020 | loss: 0.13175 - acc: 0.9613 -- iter: 0992/1263
[A[ATraining Step: 792  | total loss: [1m[32m0.13793[0m[0m | time: 62.176s
[2K
| Adam | epoch: 020 | loss: 0.13793 - acc: 0.9589 -- iter: 1024/1263
[A[ATraining Step: 793  | total loss: [1m[32m0.14838[0m[0m | time: 63.224s
[2K
| Adam | epoch: 020 | loss: 0.14838 - acc: 0.9536 -- iter: 1056/1263
[A[ATraining Step: 794  | total loss: [1m[32m0.14287[0m[0m | time: 64.333s
[2K
| Adam | epoch: 020 | loss: 0.14287 - acc: 0.9583 -- iter: 1088/1263
[A[ATraining Step: 795  | total loss: [1m[32m0.15366[0m[0m | time: 65.490s
[2K
| Adam | epoch: 020 | loss: 0.15366 - acc: 0.9531 -- iter: 1120/1263
[A[ATraining Step: 796  | total loss: [1m[32m0.15561[0m[0m | time: 66.744s
[2K
| Adam | epoch: 020 | loss: 0.15561 - acc: 0.9546 -- iter: 1152/1263
[A[ATraining Step: 797  | total loss: [1m[32m0.14474[0m[0m | time: 68.101s
[2K
| Adam | epoch: 020 | loss: 0.14474 - acc: 0.9592 -- iter: 1184/1263
[A[ATraining Step: 798  | total loss: [1m[32m0.13692[0m[0m | time: 69.233s
[2K
| Adam | epoch: 020 | loss: 0.13692 - acc: 0.9601 -- iter: 1216/1263
[A[ATraining Step: 799  | total loss: [1m[32m0.13454[0m[0m | time: 70.481s
[2K
| Adam | epoch: 020 | loss: 0.13454 - acc: 0.9579 -- iter: 1248/1263
[A[ATraining Step: 800  | total loss: [1m[32m0.13503[0m[0m | time: 74.912s
[2K
| Adam | epoch: 020 | loss: 0.13503 - acc: 0.9558 | val_loss: 0.91866 - val_acc: 0.6987 -- iter: 1263/1263
--
Training Step: 801  | total loss: [1m[32m0.12838[0m[0m | time: 0.854s
[2K
| Adam | epoch: 021 | loss: 0.12838 - acc: 0.9602 -- iter: 0032/1263
[A[ATraining Step: 802  | total loss: [1m[32m0.11918[0m[0m | time: 1.697s
[2K
| Adam | epoch: 021 | loss: 0.11918 - acc: 0.9642 -- iter: 0064/1263
[A[ATraining Step: 803  | total loss: [1m[32m0.11077[0m[0m | time: 2.570s
[2K
| Adam | epoch: 021 | loss: 0.11077 - acc: 0.9678 -- iter: 0096/1263
[A[ATraining Step: 804  | total loss: [1m[32m0.10959[0m[0m | time: 3.444s
[2K
| Adam | epoch: 021 | loss: 0.10959 - acc: 0.9679 -- iter: 0128/1263
[A[ATraining Step: 805  | total loss: [1m[32m0.12399[0m[0m | time: 4.306s
[2K
| Adam | epoch: 021 | loss: 0.12399 - acc: 0.9617 -- iter: 0160/1263
[A[ATraining Step: 806  | total loss: [1m[32m0.12037[0m[0m | time: 5.122s
[2K
| Adam | epoch: 021 | loss: 0.12037 - acc: 0.9624 -- iter: 0192/1263
[A[ATraining Step: 807  | total loss: [1m[32m0.12866[0m[0m | time: 5.968s
[2K
| Adam | epoch: 021 | loss: 0.12866 - acc: 0.9568 -- iter: 0224/1263
[A[ATraining Step: 808  | total loss: [1m[32m0.11989[0m[0m | time: 6.821s
[2K
| Adam | epoch: 021 | loss: 0.11989 - acc: 0.9611 -- iter: 0256/1263
[A[ATraining Step: 809  | total loss: [1m[32m0.11057[0m[0m | time: 7.666s
[2K
| Adam | epoch: 021 | loss: 0.11057 - acc: 0.9650 -- iter: 0288/1263
[A[ATraining Step: 810  | total loss: [1m[32m0.11878[0m[0m | time: 8.512s
[2K
| Adam | epoch: 021 | loss: 0.11878 - acc: 0.9654 -- iter: 0320/1263
[A[ATraining Step: 811  | total loss: [1m[32m0.11211[0m[0m | time: 9.393s
[2K
| Adam | epoch: 021 | loss: 0.11211 - acc: 0.9689 -- iter: 0352/1263
[A[ATraining Step: 812  | total loss: [1m[32m0.11860[0m[0m | time: 10.215s
[2K
| Adam | epoch: 021 | loss: 0.11860 - acc: 0.9688 -- iter: 0384/1263
[A[ATraining Step: 813  | total loss: [1m[32m0.11009[0m[0m | time: 11.047s
[2K
| Adam | epoch: 021 | loss: 0.11009 - acc: 0.9720 -- iter: 0416/1263
[A[ATraining Step: 814  | total loss: [1m[32m0.11011[0m[0m | time: 11.936s
[2K
| Adam | epoch: 021 | loss: 0.11011 - acc: 0.9716 -- iter: 0448/1263
[A[ATraining Step: 815  | total loss: [1m[32m0.10158[0m[0m | time: 13.006s
[2K
| Adam | epoch: 021 | loss: 0.10158 - acc: 0.9745 -- iter: 0480/1263
[A[ATraining Step: 816  | total loss: [1m[32m0.09718[0m[0m | time: 14.074s
[2K
| Adam | epoch: 021 | loss: 0.09718 - acc: 0.9770 -- iter: 0512/1263
[A[ATraining Step: 817  | total loss: [1m[32m0.09976[0m[0m | time: 15.107s
[2K
| Adam | epoch: 021 | loss: 0.09976 - acc: 0.9762 -- iter: 0544/1263
[A[ATraining Step: 818  | total loss: [1m[32m0.11953[0m[0m | time: 15.807s
[2K
| Adam | epoch: 021 | loss: 0.11953 - acc: 0.9692 -- iter: 0576/1263
[A[ATraining Step: 819  | total loss: [1m[32m0.10897[0m[0m | time: 16.239s
[2K
| Adam | epoch: 021 | loss: 0.10897 - acc: 0.9723 -- iter: 0608/1263
[A[ATraining Step: 820  | total loss: [1m[32m0.10119[0m[0m | time: 16.649s
[2K
| Adam | epoch: 021 | loss: 0.10119 - acc: 0.9751 -- iter: 0640/1263
[A[ATraining Step: 821  | total loss: [1m[32m0.09404[0m[0m | time: 17.489s
[2K
| Adam | epoch: 021 | loss: 0.09404 - acc: 0.9775 -- iter: 0672/1263
[A[ATraining Step: 822  | total loss: [1m[32m0.11323[0m[0m | time: 18.328s
[2K
| Adam | epoch: 021 | loss: 0.11323 - acc: 0.9735 -- iter: 0704/1263
[A[ATraining Step: 823  | total loss: [1m[32m0.11592[0m[0m | time: 19.152s
[2K
| Adam | epoch: 021 | loss: 0.11592 - acc: 0.9699 -- iter: 0736/1263
[A[ATraining Step: 824  | total loss: [1m[32m0.11200[0m[0m | time: 20.027s
[2K
| Adam | epoch: 021 | loss: 0.11200 - acc: 0.9698 -- iter: 0768/1263
[A[ATraining Step: 825  | total loss: [1m[32m0.11386[0m[0m | time: 21.200s
[2K
| Adam | epoch: 021 | loss: 0.11386 - acc: 0.9697 -- iter: 0800/1263
[A[ATraining Step: 826  | total loss: [1m[32m0.12744[0m[0m | time: 22.116s
[2K
| Adam | epoch: 021 | loss: 0.12744 - acc: 0.9634 -- iter: 0832/1263
[A[ATraining Step: 827  | total loss: [1m[32m0.12427[0m[0m | time: 23.181s
[2K
| Adam | epoch: 021 | loss: 0.12427 - acc: 0.9639 -- iter: 0864/1263
[A[ATraining Step: 828  | total loss: [1m[32m0.12440[0m[0m | time: 24.268s
[2K
| Adam | epoch: 021 | loss: 0.12440 - acc: 0.9613 -- iter: 0896/1263
[A[ATraining Step: 829  | total loss: [1m[32m0.17294[0m[0m | time: 25.349s
[2K
| Adam | epoch: 021 | loss: 0.17294 - acc: 0.9495 -- iter: 0928/1263
[A[ATraining Step: 830  | total loss: [1m[32m0.15767[0m[0m | time: 26.546s
[2K
| Adam | epoch: 021 | loss: 0.15767 - acc: 0.9546 -- iter: 0960/1263
[A[ATraining Step: 831  | total loss: [1m[32m0.16767[0m[0m | time: 27.497s
[2K
| Adam | epoch: 021 | loss: 0.16767 - acc: 0.9529 -- iter: 0992/1263
[A[ATraining Step: 832  | total loss: [1m[32m0.15319[0m[0m | time: 28.477s
[2K
| Adam | epoch: 021 | loss: 0.15319 - acc: 0.9576 -- iter: 1024/1263
[A[ATraining Step: 833  | total loss: [1m[32m0.15201[0m[0m | time: 29.501s
[2K
| Adam | epoch: 021 | loss: 0.15201 - acc: 0.9556 -- iter: 1056/1263
[A[ATraining Step: 834  | total loss: [1m[32m0.14270[0m[0m | time: 30.568s
[2K
| Adam | epoch: 021 | loss: 0.14270 - acc: 0.9569 -- iter: 1088/1263
[A[ATraining Step: 835  | total loss: [1m[32m0.13339[0m[0m | time: 31.622s
[2K
| Adam | epoch: 021 | loss: 0.13339 - acc: 0.9612 -- iter: 1120/1263
[A[ATraining Step: 836  | total loss: [1m[32m0.13265[0m[0m | time: 32.907s
[2K
| Adam | epoch: 021 | loss: 0.13265 - acc: 0.9588 -- iter: 1152/1263
[A[ATraining Step: 837  | total loss: [1m[32m0.12703[0m[0m | time: 37.745s
[2K
| Adam | epoch: 021 | loss: 0.12703 - acc: 0.9598 -- iter: 1184/1263
[A[ATraining Step: 838  | total loss: [1m[32m0.12541[0m[0m | time: 43.887s
[2K
| Adam | epoch: 021 | loss: 0.12541 - acc: 0.9576 -- iter: 1216/1263
[A[ATraining Step: 839  | total loss: [1m[32m0.11937[0m[0m | time: 47.720s
[2K
| Adam | epoch: 021 | loss: 0.11937 - acc: 0.9587 -- iter: 1248/1263
[A[ATraining Step: 840  | total loss: [1m[32m0.11446[0m[0m | time: 58.004s
[2K
| Adam | epoch: 021 | loss: 0.11446 - acc: 0.9597 | val_loss: 0.94809 - val_acc: 0.6987 -- iter: 1263/1263
--
Training Step: 841  | total loss: [1m[32m0.10728[0m[0m | time: 1.012s
[2K
| Adam | epoch: 022 | loss: 0.10728 - acc: 0.9637 -- iter: 0032/1263
[A[ATraining Step: 842  | total loss: [1m[32m0.10266[0m[0m | time: 2.142s
[2K
| Adam | epoch: 022 | loss: 0.10266 - acc: 0.9642 -- iter: 0064/1263
[A[ATraining Step: 843  | total loss: [1m[32m0.10834[0m[0m | time: 3.391s
[2K
| Adam | epoch: 022 | loss: 0.10834 - acc: 0.9647 -- iter: 0096/1263
[A[ATraining Step: 844  | total loss: [1m[32m0.10049[0m[0m | time: 4.659s
[2K
| Adam | epoch: 022 | loss: 0.10049 - acc: 0.9682 -- iter: 0128/1263
[A[ATraining Step: 845  | total loss: [1m[32m0.09703[0m[0m | time: 5.796s
[2K
| Adam | epoch: 022 | loss: 0.09703 - acc: 0.9683 -- iter: 0160/1263
[A[ATraining Step: 846  | total loss: [1m[32m0.10816[0m[0m | time: 6.852s
[2K
| Adam | epoch: 022 | loss: 0.10816 - acc: 0.9652 -- iter: 0192/1263
[A[ATraining Step: 847  | total loss: [1m[32m0.11424[0m[0m | time: 8.200s
[2K
| Adam | epoch: 022 | loss: 0.11424 - acc: 0.9656 -- iter: 0224/1263
[A[ATraining Step: 848  | total loss: [1m[32m0.10667[0m[0m | time: 12.013s
[2K
| Adam | epoch: 022 | loss: 0.10667 - acc: 0.9690 -- iter: 0256/1263
[A[ATraining Step: 849  | total loss: [1m[32m0.10266[0m[0m | time: 13.402s
[2K
| Adam | epoch: 022 | loss: 0.10266 - acc: 0.9690 -- iter: 0288/1263
[A[ATraining Step: 850  | total loss: [1m[32m0.09515[0m[0m | time: 16.256s
[2K
| Adam | epoch: 022 | loss: 0.09515 - acc: 0.9721 -- iter: 0320/1263
[A[ATraining Step: 851  | total loss: [1m[32m0.09776[0m[0m | time: 19.028s
[2K
| Adam | epoch: 022 | loss: 0.09776 - acc: 0.9655 -- iter: 0352/1263
[A[ATraining Step: 852  | total loss: [1m[32m0.09395[0m[0m | time: 21.595s
[2K
| Adam | epoch: 022 | loss: 0.09395 - acc: 0.9689 -- iter: 0384/1263
[A[ATraining Step: 853  | total loss: [1m[32m0.08911[0m[0m | time: 26.187s
[2K
| Adam | epoch: 022 | loss: 0.08911 - acc: 0.9720 -- iter: 0416/1263
[A[ATraining Step: 854  | total loss: [1m[32m0.08659[0m[0m | time: 30.414s
[2K
| Adam | epoch: 022 | loss: 0.08659 - acc: 0.9748 -- iter: 0448/1263
[A[ATraining Step: 855  | total loss: [1m[32m0.09514[0m[0m | time: 32.434s
[2K
| Adam | epoch: 022 | loss: 0.09514 - acc: 0.9711 -- iter: 0480/1263
[A[ATraining Step: 856  | total loss: [1m[32m0.10128[0m[0m | time: 35.820s
[2K
| Adam | epoch: 022 | loss: 0.10128 - acc: 0.9677 -- iter: 0512/1263
[A[ATraining Step: 857  | total loss: [1m[32m0.11436[0m[0m | time: 37.608s
[2K
| Adam | epoch: 022 | loss: 0.11436 - acc: 0.9616 -- iter: 0544/1263
[A[ATraining Step: 858  | total loss: [1m[32m0.10919[0m[0m | time: 38.942s
[2K
| Adam | epoch: 022 | loss: 0.10919 - acc: 0.9623 -- iter: 0576/1263
[A[ATraining Step: 859  | total loss: [1m[32m0.11567[0m[0m | time: 40.022s
[2K
| Adam | epoch: 022 | loss: 0.11567 - acc: 0.9598 -- iter: 0608/1263
[A[ATraining Step: 860  | total loss: [1m[32m0.12687[0m[0m | time: 40.675s
[2K
| Adam | epoch: 022 | loss: 0.12687 - acc: 0.9513 -- iter: 0640/1263
[A[ATraining Step: 861  | total loss: [1m[32m0.13052[0m[0m | time: 41.226s
[2K
| Adam | epoch: 022 | loss: 0.13052 - acc: 0.9495 -- iter: 0672/1263
[A[ATraining Step: 862  | total loss: [1m[32m0.12850[0m[0m | time: 42.334s
[2K
| Adam | epoch: 022 | loss: 0.12850 - acc: 0.9479 -- iter: 0704/1263
[A[ATraining Step: 863  | total loss: [1m[32m0.13743[0m[0m | time: 43.521s
[2K
| Adam | epoch: 022 | loss: 0.13743 - acc: 0.9469 -- iter: 0736/1263
[A[ATraining Step: 864  | total loss: [1m[32m0.14262[0m[0m | time: 44.833s
[2K
| Adam | epoch: 022 | loss: 0.14262 - acc: 0.9459 -- iter: 0768/1263
[A[ATraining Step: 865  | total loss: [1m[32m0.13255[0m[0m | time: 46.044s
[2K
| Adam | epoch: 022 | loss: 0.13255 - acc: 0.9482 -- iter: 0800/1263
[A[ATraining Step: 866  | total loss: [1m[32m0.12399[0m[0m | time: 47.188s
[2K
| Adam | epoch: 022 | loss: 0.12399 - acc: 0.9534 -- iter: 0832/1263
[A[ATraining Step: 867  | total loss: [1m[32m0.12617[0m[0m | time: 48.389s
[2K
| Adam | epoch: 022 | loss: 0.12617 - acc: 0.9549 -- iter: 0864/1263
[A[ATraining Step: 868  | total loss: [1m[32m0.16588[0m[0m | time: 53.478s
[2K
| Adam | epoch: 022 | loss: 0.16588 - acc: 0.9438 -- iter: 0896/1263
[A[ATraining Step: 869  | total loss: [1m[32m0.15892[0m[0m | time: 55.915s
[2K
| Adam | epoch: 022 | loss: 0.15892 - acc: 0.9463 -- iter: 0928/1263
[A[ATraining Step: 870  | total loss: [1m[32m0.16636[0m[0m | time: 58.078s
[2K
| Adam | epoch: 022 | loss: 0.16636 - acc: 0.9454 -- iter: 0960/1263
[A[ATraining Step: 871  | total loss: [1m[32m0.15529[0m[0m | time: 61.618s
[2K
| Adam | epoch: 022 | loss: 0.15529 - acc: 0.9478 -- iter: 0992/1263
[A[ATraining Step: 872  | total loss: [1m[32m0.14304[0m[0m | time: 65.900s
[2K
| Adam | epoch: 022 | loss: 0.14304 - acc: 0.9530 -- iter: 1024/1263
[A[ATraining Step: 873  | total loss: [1m[32m0.14650[0m[0m | time: 66.840s
[2K
| Adam | epoch: 022 | loss: 0.14650 - acc: 0.9546 -- iter: 1056/1263
[A[ATraining Step: 874  | total loss: [1m[32m0.14819[0m[0m | time: 67.914s
[2K
| Adam | epoch: 022 | loss: 0.14819 - acc: 0.9529 -- iter: 1088/1263
[A[ATraining Step: 875  | total loss: [1m[32m0.14603[0m[0m | time: 69.015s
[2K
| Adam | epoch: 022 | loss: 0.14603 - acc: 0.9513 -- iter: 1120/1263
[A[ATraining Step: 876  | total loss: [1m[32m0.15821[0m[0m | time: 70.150s
[2K
| Adam | epoch: 022 | loss: 0.15821 - acc: 0.9499 -- iter: 1152/1263
[A[ATraining Step: 877  | total loss: [1m[32m0.15415[0m[0m | time: 71.243s
[2K
| Adam | epoch: 022 | loss: 0.15415 - acc: 0.9518 -- iter: 1184/1263
[A[ATraining Step: 878  | total loss: [1m[32m0.15088[0m[0m | time: 72.406s
[2K
| Adam | epoch: 022 | loss: 0.15088 - acc: 0.9535 -- iter: 1216/1263
[A[ATraining Step: 879  | total loss: [1m[32m0.13965[0m[0m | time: 73.548s
[2K
| Adam | epoch: 022 | loss: 0.13965 - acc: 0.9582 -- iter: 1248/1263
[A[ATraining Step: 880  | total loss: [1m[32m0.13610[0m[0m | time: 80.980s
[2K
| Adam | epoch: 022 | loss: 0.13610 - acc: 0.9561 | val_loss: 0.92191 - val_acc: 0.7114 -- iter: 1263/1263
--
Training Step: 881  | total loss: [1m[32m0.12597[0m[0m | time: 4.092s
[2K
| Adam | epoch: 023 | loss: 0.12597 - acc: 0.9605 -- iter: 0032/1263
[A[ATraining Step: 882  | total loss: [1m[32m0.12096[0m[0m | time: 7.705s
[2K
| Adam | epoch: 023 | loss: 0.12096 - acc: 0.9613 -- iter: 0064/1263
[A[ATraining Step: 883  | total loss: [1m[32m0.11115[0m[0m | time: 9.676s
[2K
| Adam | epoch: 023 | loss: 0.11115 - acc: 0.9652 -- iter: 0096/1263
[A[ATraining Step: 884  | total loss: [1m[32m0.11144[0m[0m | time: 12.116s
[2K
| Adam | epoch: 023 | loss: 0.11144 - acc: 0.9655 -- iter: 0128/1263
[A[ATraining Step: 885  | total loss: [1m[32m0.10371[0m[0m | time: 15.541s
[2K
| Adam | epoch: 023 | loss: 0.10371 - acc: 0.9690 -- iter: 0160/1263
[A[ATraining Step: 886  | total loss: [1m[32m0.10333[0m[0m | time: 18.239s
[2K
| Adam | epoch: 023 | loss: 0.10333 - acc: 0.9690 -- iter: 0192/1263
[A[ATraining Step: 887  | total loss: [1m[32m0.12023[0m[0m | time: 21.560s
[2K
| Adam | epoch: 023 | loss: 0.12023 - acc: 0.9658 -- iter: 0224/1263
[A[ATraining Step: 888  | total loss: [1m[32m0.11039[0m[0m | time: 24.433s
[2K
| Adam | epoch: 023 | loss: 0.11039 - acc: 0.9692 -- iter: 0256/1263
[A[ATraining Step: 889  | total loss: [1m[32m0.11072[0m[0m | time: 26.259s
[2K
| Adam | epoch: 023 | loss: 0.11072 - acc: 0.9692 -- iter: 0288/1263
[A[ATraining Step: 890  | total loss: [1m[32m0.11137[0m[0m | time: 27.317s
[2K
| Adam | epoch: 023 | loss: 0.11137 - acc: 0.9691 -- iter: 0320/1263
[A[ATraining Step: 891  | total loss: [1m[32m0.13064[0m[0m | time: 28.448s
[2K
| Adam | epoch: 023 | loss: 0.13064 - acc: 0.9629 -- iter: 0352/1263
[A[ATraining Step: 892  | total loss: [1m[32m0.12456[0m[0m | time: 29.660s
[2K
| Adam | epoch: 023 | loss: 0.12456 - acc: 0.9634 -- iter: 0384/1263
[A[ATraining Step: 893  | total loss: [1m[32m0.11816[0m[0m | time: 30.790s
[2K
| Adam | epoch: 023 | loss: 0.11816 - acc: 0.9640 -- iter: 0416/1263
[A[ATraining Step: 894  | total loss: [1m[32m0.10928[0m[0m | time: 31.999s
[2K
| Adam | epoch: 023 | loss: 0.10928 - acc: 0.9676 -- iter: 0448/1263
[A[ATraining Step: 895  | total loss: [1m[32m0.11531[0m[0m | time: 33.171s
[2K
| Adam | epoch: 023 | loss: 0.11531 - acc: 0.9646 -- iter: 0480/1263
[A[ATraining Step: 896  | total loss: [1m[32m0.10681[0m[0m | time: 34.352s
[2K
| Adam | epoch: 023 | loss: 0.10681 - acc: 0.9681 -- iter: 0512/1263
[A[ATraining Step: 897  | total loss: [1m[32m0.11053[0m[0m | time: 35.579s
[2K
| Adam | epoch: 023 | loss: 0.11053 - acc: 0.9682 -- iter: 0544/1263
[A[ATraining Step: 898  | total loss: [1m[32m0.10220[0m[0m | time: 36.916s
[2K
| Adam | epoch: 023 | loss: 0.10220 - acc: 0.9714 -- iter: 0576/1263
[A[ATraining Step: 899  | total loss: [1m[32m0.09355[0m[0m | time: 40.390s
[2K
| Adam | epoch: 023 | loss: 0.09355 - acc: 0.9742 -- iter: 0608/1263
[A[ATraining Step: 900  | total loss: [1m[32m0.11025[0m[0m | time: 44.694s
[2K
| Adam | epoch: 023 | loss: 0.11025 - acc: 0.9674 -- iter: 0640/1263
[A[ATraining Step: 901  | total loss: [1m[32m0.11483[0m[0m | time: 45.172s
[2K
| Adam | epoch: 023 | loss: 0.11483 - acc: 0.9613 -- iter: 0672/1263
[A[ATraining Step: 902  | total loss: [1m[32m0.12758[0m[0m | time: 45.700s
[2K
| Adam | epoch: 023 | loss: 0.12758 - acc: 0.9585 -- iter: 0704/1263
[A[ATraining Step: 903  | total loss: [1m[32m0.12762[0m[0m | time: 46.849s
[2K
| Adam | epoch: 023 | loss: 0.12762 - acc: 0.9560 -- iter: 0736/1263
[A[ATraining Step: 904  | total loss: [1m[32m0.12805[0m[0m | time: 48.019s
[2K
| Adam | epoch: 023 | loss: 0.12805 - acc: 0.9573 -- iter: 0768/1263
[A[ATraining Step: 905  | total loss: [1m[32m0.12402[0m[0m | time: 49.153s
[2K
| Adam | epoch: 023 | loss: 0.12402 - acc: 0.9615 -- iter: 0800/1263
[A[ATraining Step: 906  | total loss: [1m[32m0.11362[0m[0m | time: 50.313s
[2K
| Adam | epoch: 023 | loss: 0.11362 - acc: 0.9654 -- iter: 0832/1263
[A[ATraining Step: 907  | total loss: [1m[32m0.12627[0m[0m | time: 51.487s
[2K
| Adam | epoch: 023 | loss: 0.12627 - acc: 0.9657 -- iter: 0864/1263
[A[ATraining Step: 908  | total loss: [1m[32m0.13279[0m[0m | time: 52.618s
[2K
| Adam | epoch: 023 | loss: 0.13279 - acc: 0.9598 -- iter: 0896/1263
[A[ATraining Step: 909  | total loss: [1m[32m0.13178[0m[0m | time: 53.749s
[2K
| Adam | epoch: 023 | loss: 0.13178 - acc: 0.9575 -- iter: 0928/1263
[A[ATraining Step: 910  | total loss: [1m[32m0.12267[0m[0m | time: 55.059s
[2K
| Adam | epoch: 023 | loss: 0.12267 - acc: 0.9618 -- iter: 0960/1263
[A[ATraining Step: 911  | total loss: [1m[32m0.18265[0m[0m | time: 57.547s
[2K
| Adam | epoch: 023 | loss: 0.18265 - acc: 0.9500 -- iter: 0992/1263
[A[ATraining Step: 912  | total loss: [1m[32m0.17249[0m[0m | time: 61.383s
[2K
| Adam | epoch: 023 | loss: 0.17249 - acc: 0.9487 -- iter: 1024/1263
[A[ATraining Step: 913  | total loss: [1m[32m0.16691[0m[0m | time: 63.703s
[2K
| Adam | epoch: 023 | loss: 0.16691 - acc: 0.9476 -- iter: 1056/1263
[A[ATraining Step: 914  | total loss: [1m[32m0.15502[0m[0m | time: 67.586s
[2K
| Adam | epoch: 023 | loss: 0.15502 - acc: 0.9529 -- iter: 1088/1263
[A[ATraining Step: 915  | total loss: [1m[32m0.14199[0m[0m | time: 69.821s
[2K
| Adam | epoch: 023 | loss: 0.14199 - acc: 0.9576 -- iter: 1120/1263
[A[ATraining Step: 916  | total loss: [1m[32m0.13865[0m[0m | time: 71.278s
[2K
| Adam | epoch: 023 | loss: 0.13865 - acc: 0.9587 -- iter: 1152/1263
[A[ATraining Step: 917  | total loss: [1m[32m0.13366[0m[0m | time: 72.330s
[2K
| Adam | epoch: 023 | loss: 0.13366 - acc: 0.9566 -- iter: 1184/1263
[A[ATraining Step: 918  | total loss: [1m[32m0.12863[0m[0m | time: 73.494s
[2K
| Adam | epoch: 023 | loss: 0.12863 - acc: 0.9578 -- iter: 1216/1263
[A[ATraining Step: 919  | total loss: [1m[32m0.13102[0m[0m | time: 74.637s
[2K
| Adam | epoch: 023 | loss: 0.13102 - acc: 0.9589 -- iter: 1248/1263
[A[ATraining Step: 920  | total loss: [1m[32m0.13474[0m[0m | time: 78.810s
[2K
| Adam | epoch: 023 | loss: 0.13474 - acc: 0.9599 | val_loss: 0.88556 - val_acc: 0.7038 -- iter: 1263/1263
--
Training Step: 921  | total loss: [1m[32m0.12655[0m[0m | time: 1.118s
[2K
| Adam | epoch: 024 | loss: 0.12655 - acc: 0.9639 -- iter: 0032/1263
[A[ATraining Step: 922  | total loss: [1m[32m0.11866[0m[0m | time: 2.309s
[2K
| Adam | epoch: 024 | loss: 0.11866 - acc: 0.9675 -- iter: 0064/1263
[A[ATraining Step: 923  | total loss: [1m[32m0.11836[0m[0m | time: 3.504s
[2K
| Adam | epoch: 024 | loss: 0.11836 - acc: 0.9645 -- iter: 0096/1263
[A[ATraining Step: 924  | total loss: [1m[32m0.13795[0m[0m | time: 4.713s
[2K
| Adam | epoch: 024 | loss: 0.13795 - acc: 0.9649 -- iter: 0128/1263
[A[ATraining Step: 925  | total loss: [1m[32m0.12662[0m[0m | time: 5.911s
[2K
| Adam | epoch: 024 | loss: 0.12662 - acc: 0.9684 -- iter: 0160/1263
[A[ATraining Step: 926  | total loss: [1m[32m0.12023[0m[0m | time: 6.966s
[2K
| Adam | epoch: 024 | loss: 0.12023 - acc: 0.9685 -- iter: 0192/1263
[A[ATraining Step: 927  | total loss: [1m[32m0.11484[0m[0m | time: 7.807s
[2K
| Adam | epoch: 024 | loss: 0.11484 - acc: 0.9716 -- iter: 0224/1263
[A[ATraining Step: 928  | total loss: [1m[32m0.11449[0m[0m | time: 8.654s
[2K
| Adam | epoch: 024 | loss: 0.11449 - acc: 0.9682 -- iter: 0256/1263
[A[ATraining Step: 929  | total loss: [1m[32m0.11878[0m[0m | time: 9.470s
[2K
| Adam | epoch: 024 | loss: 0.11878 - acc: 0.9620 -- iter: 0288/1263
[A[ATraining Step: 930  | total loss: [1m[32m0.11093[0m[0m | time: 10.284s
[2K
| Adam | epoch: 024 | loss: 0.11093 - acc: 0.9658 -- iter: 0320/1263
[A[ATraining Step: 931  | total loss: [1m[32m0.11126[0m[0m | time: 11.162s
[2K
| Adam | epoch: 024 | loss: 0.11126 - acc: 0.9661 -- iter: 0352/1263
[A[ATraining Step: 932  | total loss: [1m[32m0.10339[0m[0m | time: 12.006s
[2K
| Adam | epoch: 024 | loss: 0.10339 - acc: 0.9695 -- iter: 0384/1263
[A[ATraining Step: 933  | total loss: [1m[32m0.10261[0m[0m | time: 12.871s
[2K
| Adam | epoch: 024 | loss: 0.10261 - acc: 0.9663 -- iter: 0416/1263
[A[ATraining Step: 934  | total loss: [1m[32m0.09785[0m[0m | time: 13.661s
[2K
| Adam | epoch: 024 | loss: 0.09785 - acc: 0.9665 -- iter: 0448/1263
[A[ATraining Step: 935  | total loss: [1m[32m0.10384[0m[0m | time: 14.477s
[2K
| Adam | epoch: 024 | loss: 0.10384 - acc: 0.9636 -- iter: 0480/1263
[A[ATraining Step: 936  | total loss: [1m[32m0.09859[0m[0m | time: 15.341s
[2K
| Adam | epoch: 024 | loss: 0.09859 - acc: 0.9673 -- iter: 0512/1263
[A[ATraining Step: 937  | total loss: [1m[32m0.09525[0m[0m | time: 16.222s
[2K
| Adam | epoch: 024 | loss: 0.09525 - acc: 0.9674 -- iter: 0544/1263
[A[ATraining Step: 938  | total loss: [1m[32m0.08825[0m[0m | time: 17.132s
[2K
| Adam | epoch: 024 | loss: 0.08825 - acc: 0.9707 -- iter: 0576/1263
[A[ATraining Step: 939  | total loss: [1m[32m0.09567[0m[0m | time: 17.985s
[2K
| Adam | epoch: 024 | loss: 0.09567 - acc: 0.9642 -- iter: 0608/1263
[A[ATraining Step: 940  | total loss: [1m[32m0.08923[0m[0m | time: 18.874s
[2K
| Adam | epoch: 024 | loss: 0.08923 - acc: 0.9678 -- iter: 0640/1263
[A[ATraining Step: 941  | total loss: [1m[32m0.08638[0m[0m | time: 19.709s
[2K
| Adam | epoch: 024 | loss: 0.08638 - acc: 0.9679 -- iter: 0672/1263
[A[ATraining Step: 942  | total loss: [1m[32m0.08100[0m[0m | time: 20.170s
[2K
| Adam | epoch: 024 | loss: 0.08100 - acc: 0.9711 -- iter: 0704/1263
[A[ATraining Step: 943  | total loss: [1m[32m0.13924[0m[0m | time: 20.579s
[2K
| Adam | epoch: 024 | loss: 0.13924 - acc: 0.9607 -- iter: 0736/1263
[A[ATraining Step: 944  | total loss: [1m[32m0.17800[0m[0m | time: 21.458s
[2K
| Adam | epoch: 024 | loss: 0.17800 - acc: 0.9513 -- iter: 0768/1263
[A[ATraining Step: 945  | total loss: [1m[32m0.17073[0m[0m | time: 22.328s
[2K
| Adam | epoch: 024 | loss: 0.17073 - acc: 0.9499 -- iter: 0800/1263
[A[ATraining Step: 946  | total loss: [1m[32m0.15923[0m[0m | time: 23.338s
[2K
| Adam | epoch: 024 | loss: 0.15923 - acc: 0.9518 -- iter: 0832/1263
[A[ATraining Step: 947  | total loss: [1m[32m0.14956[0m[0m | time: 24.223s
[2K
| Adam | epoch: 024 | loss: 0.14956 - acc: 0.9566 -- iter: 0864/1263
[A[ATraining Step: 948  | total loss: [1m[32m0.13548[0m[0m | time: 25.043s
[2K
| Adam | epoch: 024 | loss: 0.13548 - acc: 0.9609 -- iter: 0896/1263
[A[ATraining Step: 949  | total loss: [1m[32m0.13671[0m[0m | time: 25.899s
[2K
| Adam | epoch: 024 | loss: 0.13671 - acc: 0.9586 -- iter: 0928/1263
[A[ATraining Step: 950  | total loss: [1m[32m0.12756[0m[0m | time: 26.741s
[2K
| Adam | epoch: 024 | loss: 0.12756 - acc: 0.9596 -- iter: 0960/1263
[A[ATraining Step: 951  | total loss: [1m[32m0.12943[0m[0m | time: 27.594s
[2K
| Adam | epoch: 024 | loss: 0.12943 - acc: 0.9574 -- iter: 0992/1263
[A[ATraining Step: 952  | total loss: [1m[32m0.12201[0m[0m | time: 28.559s
[2K
| Adam | epoch: 024 | loss: 0.12201 - acc: 0.9585 -- iter: 1024/1263
[A[ATraining Step: 953  | total loss: [1m[32m0.11544[0m[0m | time: 29.759s
[2K
| Adam | epoch: 024 | loss: 0.11544 - acc: 0.9627 -- iter: 1056/1263
[A[ATraining Step: 954  | total loss: [1m[32m0.10805[0m[0m | time: 33.298s
[2K
| Adam | epoch: 024 | loss: 0.10805 - acc: 0.9633 -- iter: 1088/1263
[A[ATraining Step: 955  | total loss: [1m[32m0.09935[0m[0m | time: 37.628s
[2K
| Adam | epoch: 024 | loss: 0.09935 - acc: 0.9670 -- iter: 1120/1263
[A[ATraining Step: 956  | total loss: [1m[32m0.09063[0m[0m | time: 40.902s
[2K
| Adam | epoch: 024 | loss: 0.09063 - acc: 0.9703 -- iter: 1152/1263
[A[ATraining Step: 957  | total loss: [1m[32m0.08548[0m[0m | time: 43.976s
[2K
| Adam | epoch: 024 | loss: 0.08548 - acc: 0.9732 -- iter: 1184/1263
[A[ATraining Step: 958  | total loss: [1m[32m0.09901[0m[0m | time: 47.294s
[2K
| Adam | epoch: 024 | loss: 0.09901 - acc: 0.9697 -- iter: 1216/1263
[A[ATraining Step: 959  | total loss: [1m[32m0.09199[0m[0m | time: 48.901s
[2K
| Adam | epoch: 024 | loss: 0.09199 - acc: 0.9727 -- iter: 1248/1263
[A[ATraining Step: 960  | total loss: [1m[32m0.10460[0m[0m | time: 53.242s
[2K
| Adam | epoch: 024 | loss: 0.10460 - acc: 0.9692 | val_loss: 1.05834 - val_acc: 0.6911 -- iter: 1263/1263
--
Training Step: 961  | total loss: [1m[32m0.09676[0m[0m | time: 1.689s
[2K
| Adam | epoch: 025 | loss: 0.09676 - acc: 0.9723 -- iter: 0032/1263
[A[ATraining Step: 962  | total loss: [1m[32m0.10924[0m[0m | time: 2.912s
[2K
| Adam | epoch: 025 | loss: 0.10924 - acc: 0.9688 -- iter: 0064/1263
[A[ATraining Step: 963  | total loss: [1m[32m0.10377[0m[0m | time: 4.191s
[2K
| Adam | epoch: 025 | loss: 0.10377 - acc: 0.9688 -- iter: 0096/1263
[A[ATraining Step: 964  | total loss: [1m[32m0.10723[0m[0m | time: 5.339s
[2K
| Adam | epoch: 025 | loss: 0.10723 - acc: 0.9657 -- iter: 0128/1263
[A[ATraining Step: 965  | total loss: [1m[32m0.10001[0m[0m | time: 6.544s
[2K
| Adam | epoch: 025 | loss: 0.10001 - acc: 0.9691 -- iter: 0160/1263
[A[ATraining Step: 966  | total loss: [1m[32m0.09137[0m[0m | time: 7.567s
[2K
| Adam | epoch: 025 | loss: 0.09137 - acc: 0.9722 -- iter: 0192/1263
[A[ATraining Step: 967  | total loss: [1m[32m0.11999[0m[0m | time: 8.763s
[2K
| Adam | epoch: 025 | loss: 0.11999 - acc: 0.9625 -- iter: 0224/1263
[A[ATraining Step: 968  | total loss: [1m[32m0.10999[0m[0m | time: 9.900s
[2K
| Adam | epoch: 025 | loss: 0.10999 - acc: 0.9662 -- iter: 0256/1263
[A[ATraining Step: 969  | total loss: [1m[32m0.10553[0m[0m | time: 11.007s
[2K
| Adam | epoch: 025 | loss: 0.10553 - acc: 0.9665 -- iter: 0288/1263
[A[ATraining Step: 970  | total loss: [1m[32m0.09896[0m[0m | time: 12.191s
[2K
| Adam | epoch: 025 | loss: 0.09896 - acc: 0.9698 -- iter: 0320/1263
[A[ATraining Step: 971  | total loss: [1m[32m0.10632[0m[0m | time: 13.275s
[2K
| Adam | epoch: 025 | loss: 0.10632 - acc: 0.9697 -- iter: 0352/1263
[A[ATraining Step: 972  | total loss: [1m[32m0.09925[0m[0m | time: 14.333s
[2K
| Adam | epoch: 025 | loss: 0.09925 - acc: 0.9727 -- iter: 0384/1263
[A[ATraining Step: 973  | total loss: [1m[32m0.09598[0m[0m | time: 15.427s
[2K
| Adam | epoch: 025 | loss: 0.09598 - acc: 0.9723 -- iter: 0416/1263
[A[ATraining Step: 974  | total loss: [1m[32m0.08897[0m[0m | time: 16.537s
[2K
| Adam | epoch: 025 | loss: 0.08897 - acc: 0.9751 -- iter: 0448/1263
[A[ATraining Step: 975  | total loss: [1m[32m0.08340[0m[0m | time: 17.951s
[2K
| Adam | epoch: 025 | loss: 0.08340 - acc: 0.9776 -- iter: 0480/1263
[A[ATraining Step: 976  | total loss: [1m[32m0.08845[0m[0m | time: 19.675s
[2K
| Adam | epoch: 025 | loss: 0.08845 - acc: 0.9736 -- iter: 0512/1263
[A[ATraining Step: 977  | total loss: [1m[32m0.09622[0m[0m | time: 23.441s
[2K
| Adam | epoch: 025 | loss: 0.09622 - acc: 0.9731 -- iter: 0544/1263
[A[ATraining Step: 978  | total loss: [1m[32m0.09315[0m[0m | time: 25.433s
[2K
| Adam | epoch: 025 | loss: 0.09315 - acc: 0.9727 -- iter: 0576/1263
[A[ATraining Step: 979  | total loss: [1m[32m0.09001[0m[0m | time: 27.801s
[2K
| Adam | epoch: 025 | loss: 0.09001 - acc: 0.9723 -- iter: 0608/1263
[A[ATraining Step: 980  | total loss: [1m[32m0.08364[0m[0m | time: 32.192s
[2K
| Adam | epoch: 025 | loss: 0.08364 - acc: 0.9750 -- iter: 0640/1263
[A[ATraining Step: 981  | total loss: [1m[32m0.08245[0m[0m | time: 34.993s
[2K
| Adam | epoch: 025 | loss: 0.08245 - acc: 0.9744 -- iter: 0672/1263
[A[ATraining Step: 982  | total loss: [1m[32m0.08864[0m[0m | time: 37.637s
[2K
| Adam | epoch: 025 | loss: 0.08864 - acc: 0.9739 -- iter: 0704/1263
[A[ATraining Step: 983  | total loss: [1m[32m0.10360[0m[0m | time: 38.283s
[2K
| Adam | epoch: 025 | loss: 0.10360 - acc: 0.9671 -- iter: 0736/1263
[A[ATraining Step: 984  | total loss: [1m[32m0.10528[0m[0m | time: 38.961s
[2K
| Adam | epoch: 025 | loss: 0.10528 - acc: 0.9637 -- iter: 0768/1263
[A[ATraining Step: 985  | total loss: [1m[32m0.09818[0m[0m | time: 40.241s
[2K
| Adam | epoch: 025 | loss: 0.09818 - acc: 0.9673 -- iter: 0800/1263
[A[ATraining Step: 986  | total loss: [1m[32m0.08972[0m[0m | time: 41.251s
[2K
| Adam | epoch: 025 | loss: 0.08972 - acc: 0.9706 -- iter: 0832/1263
[A[ATraining Step: 987  | total loss: [1m[32m0.09659[0m[0m | time: 42.362s
[2K
| Adam | epoch: 025 | loss: 0.09659 - acc: 0.9673 -- iter: 0864/1263
[A[ATraining Step: 988  | total loss: [1m[32m0.11054[0m[0m | time: 43.481s
[2K
| Adam | epoch: 025 | loss: 0.11054 - acc: 0.9612 -- iter: 0896/1263
[A[ATraining Step: 989  | total loss: [1m[32m0.15736[0m[0m | time: 44.703s
[2K
| Adam | epoch: 025 | loss: 0.15736 - acc: 0.9526 -- iter: 0928/1263
[A[ATraining Step: 990  | total loss: [1m[32m0.17286[0m[0m | time: 45.893s
[2K
| Adam | epoch: 025 | loss: 0.17286 - acc: 0.9448 -- iter: 0960/1263
[A[ATraining Step: 991  | total loss: [1m[32m0.15879[0m[0m | time: 46.919s
[2K
| Adam | epoch: 025 | loss: 0.15879 - acc: 0.9503 -- iter: 0992/1263
[A[ATraining Step: 992  | total loss: [1m[32m0.15963[0m[0m | time: 48.151s
[2K
| Adam | epoch: 025 | loss: 0.15963 - acc: 0.9491 -- iter: 1024/1263
[A[ATraining Step: 993  | total loss: [1m[32m0.16563[0m[0m | time: 51.386s
[2K
| Adam | epoch: 025 | loss: 0.16563 - acc: 0.9479 -- iter: 1056/1263
[A[ATraining Step: 994  | total loss: [1m[32m0.15067[0m[0m | time: 55.069s
[2K
| Adam | epoch: 025 | loss: 0.15067 - acc: 0.9531 -- iter: 1088/1263
[A[ATraining Step: 995  | total loss: [1m[32m0.14409[0m[0m | time: 57.224s
[2K
| Adam | epoch: 025 | loss: 0.14409 - acc: 0.9547 -- iter: 1120/1263
[A[ATraining Step: 996  | total loss: [1m[32m0.15889[0m[0m | time: 58.248s
[2K
| Adam | epoch: 025 | loss: 0.15889 - acc: 0.9467 -- iter: 1152/1263
[A[ATraining Step: 997  | total loss: [1m[32m0.14889[0m[0m | time: 59.419s
[2K
| Adam | epoch: 025 | loss: 0.14889 - acc: 0.9520 -- iter: 1184/1263
[A[ATraining Step: 998  | total loss: [1m[32m0.15578[0m[0m | time: 60.522s
[2K
| Adam | epoch: 025 | loss: 0.15578 - acc: 0.9506 -- iter: 1216/1263
[A[ATraining Step: 999  | total loss: [1m[32m0.14248[0m[0m | time: 61.651s
[2K
| Adam | epoch: 025 | loss: 0.14248 - acc: 0.9555 -- iter: 1248/1263
[A[ATraining Step: 1000  | total loss: [1m[32m0.13621[0m[0m | time: 65.929s
[2K
| Adam | epoch: 025 | loss: 0.13621 - acc: 0.9568 | val_loss: 0.92144 - val_acc: 0.7139 -- iter: 1263/1263
--
Training Step: 1001  | total loss: [1m[32m0.14148[0m[0m | time: 1.213s
[2K
| Adam | epoch: 026 | loss: 0.14148 - acc: 0.9580 -- iter: 0032/1263
[A[ATraining Step: 1002  | total loss: [1m[32m0.14024[0m[0m | time: 2.339s
[2K
| Adam | epoch: 026 | loss: 0.14024 - acc: 0.9560 -- iter: 0064/1263
[A[ATraining Step: 1003  | total loss: [1m[32m0.15591[0m[0m | time: 3.322s
[2K
| Adam | epoch: 026 | loss: 0.15591 - acc: 0.9573 -- iter: 0096/1263
[A[ATraining Step: 1004  | total loss: [1m[32m0.15387[0m[0m | time: 4.494s
[2K
| Adam | epoch: 026 | loss: 0.15387 - acc: 0.9522 -- iter: 0128/1263
[A[ATraining Step: 1005  | total loss: [1m[32m0.15010[0m[0m | time: 5.614s
[2K
| Adam | epoch: 026 | loss: 0.15010 - acc: 0.9476 -- iter: 0160/1263
[A[ATraining Step: 1006  | total loss: [1m[32m0.14200[0m[0m | time: 6.726s
[2K
| Adam | epoch: 026 | loss: 0.14200 - acc: 0.9497 -- iter: 0192/1263
[A[ATraining Step: 1007  | total loss: [1m[32m0.13263[0m[0m | time: 7.879s
[2K
| Adam | epoch: 026 | loss: 0.13263 - acc: 0.9547 -- iter: 0224/1263
[A[ATraining Step: 1008  | total loss: [1m[32m0.12277[0m[0m | time: 9.131s
[2K
| Adam | epoch: 026 | loss: 0.12277 - acc: 0.9592 -- iter: 0256/1263
[A[ATraining Step: 1009  | total loss: [1m[32m0.11326[0m[0m | time: 10.393s
[2K
| Adam | epoch: 026 | loss: 0.11326 - acc: 0.9633 -- iter: 0288/1263
[A[ATraining Step: 1010  | total loss: [1m[32m0.10668[0m[0m | time: 11.562s
[2K
| Adam | epoch: 026 | loss: 0.10668 - acc: 0.9639 -- iter: 0320/1263
[A[ATraining Step: 1011  | total loss: [1m[32m0.09908[0m[0m | time: 12.753s
[2K
| Adam | epoch: 026 | loss: 0.09908 - acc: 0.9675 -- iter: 0352/1263
[A[ATraining Step: 1012  | total loss: [1m[32m0.09295[0m[0m | time: 14.058s
[2K
| Adam | epoch: 026 | loss: 0.09295 - acc: 0.9707 -- iter: 0384/1263
[A[ATraining Step: 1013  | total loss: [1m[32m0.09292[0m[0m | time: 15.198s
[2K
| Adam | epoch: 026 | loss: 0.09292 - acc: 0.9705 -- iter: 0416/1263
[A[ATraining Step: 1014  | total loss: [1m[32m0.10347[0m[0m | time: 16.263s
[2K
| Adam | epoch: 026 | loss: 0.10347 - acc: 0.9704 -- iter: 0448/1263
[A[ATraining Step: 1015  | total loss: [1m[32m0.10543[0m[0m | time: 17.420s
[2K
| Adam | epoch: 026 | loss: 0.10543 - acc: 0.9702 -- iter: 0480/1263
[A[ATraining Step: 1016  | total loss: [1m[32m0.09675[0m[0m | time: 18.585s
[2K
| Adam | epoch: 026 | loss: 0.09675 - acc: 0.9732 -- iter: 0512/1263
[A[ATraining Step: 1017  | total loss: [1m[32m0.08873[0m[0m | time: 19.797s
[2K
| Adam | epoch: 026 | loss: 0.08873 - acc: 0.9759 -- iter: 0544/1263
[A[ATraining Step: 1018  | total loss: [1m[32m0.08217[0m[0m | time: 21.028s
[2K
| Adam | epoch: 026 | loss: 0.08217 - acc: 0.9783 -- iter: 0576/1263
[A[ATraining Step: 1019  | total loss: [1m[32m0.07609[0m[0m | time: 22.227s
[2K
| Adam | epoch: 026 | loss: 0.07609 - acc: 0.9804 -- iter: 0608/1263
[A[ATraining Step: 1020  | total loss: [1m[32m0.07052[0m[0m | time: 23.406s
[2K
| Adam | epoch: 026 | loss: 0.07052 - acc: 0.9824 -- iter: 0640/1263
[A[ATraining Step: 1021  | total loss: [1m[32m0.08293[0m[0m | time: 24.518s
[2K
| Adam | epoch: 026 | loss: 0.08293 - acc: 0.9779 -- iter: 0672/1263
[A[ATraining Step: 1022  | total loss: [1m[32m0.08036[0m[0m | time: 25.858s
[2K
| Adam | epoch: 026 | loss: 0.08036 - acc: 0.9801 -- iter: 0704/1263
[A[ATraining Step: 1023  | total loss: [1m[32m0.07642[0m[0m | time: 27.373s
[2K
| Adam | epoch: 026 | loss: 0.07642 - acc: 0.9821 -- iter: 0736/1263
[A[ATraining Step: 1024  | total loss: [1m[32m0.08281[0m[0m | time: 28.067s
[2K
| Adam | epoch: 026 | loss: 0.08281 - acc: 0.9808 -- iter: 0768/1263
[A[ATraining Step: 1025  | total loss: [1m[32m0.07615[0m[0m | time: 28.638s
[2K
| Adam | epoch: 026 | loss: 0.07615 - acc: 0.9827 -- iter: 0800/1263
[A[ATraining Step: 1026  | total loss: [1m[32m0.06971[0m[0m | time: 29.892s
[2K
| Adam | epoch: 026 | loss: 0.06971 - acc: 0.9844 -- iter: 0832/1263
[A[ATraining Step: 1027  | total loss: [1m[32m0.06564[0m[0m | time: 31.021s
[2K
| Adam | epoch: 026 | loss: 0.06564 - acc: 0.9860 -- iter: 0864/1263
[A[ATraining Step: 1028  | total loss: [1m[32m0.06126[0m[0m | time: 32.179s
[2K
| Adam | epoch: 026 | loss: 0.06126 - acc: 0.9874 -- iter: 0896/1263
[A[ATraining Step: 1029  | total loss: [1m[32m0.06719[0m[0m | time: 33.276s
[2K
| Adam | epoch: 026 | loss: 0.06719 - acc: 0.9855 -- iter: 0928/1263
[A[ATraining Step: 1030  | total loss: [1m[32m0.07481[0m[0m | time: 34.372s
[2K
| Adam | epoch: 026 | loss: 0.07481 - acc: 0.9838 -- iter: 0960/1263
[A[ATraining Step: 1031  | total loss: [1m[32m0.07960[0m[0m | time: 35.632s
[2K
| Adam | epoch: 026 | loss: 0.07960 - acc: 0.9823 -- iter: 0992/1263
[A[ATraining Step: 1032  | total loss: [1m[32m0.07416[0m[0m | time: 36.796s
[2K
| Adam | epoch: 026 | loss: 0.07416 - acc: 0.9841 -- iter: 1024/1263
[A[ATraining Step: 1033  | total loss: [1m[32m0.06955[0m[0m | time: 37.866s
[2K
| Adam | epoch: 026 | loss: 0.06955 - acc: 0.9857 -- iter: 1056/1263
[A[ATraining Step: 1034  | total loss: [1m[32m0.07129[0m[0m | time: 38.937s
[2K
| Adam | epoch: 026 | loss: 0.07129 - acc: 0.9809 -- iter: 1088/1263
[A[ATraining Step: 1035  | total loss: [1m[32m0.06576[0m[0m | time: 40.237s
[2K
| Adam | epoch: 026 | loss: 0.06576 - acc: 0.9828 -- iter: 1120/1263
[A[ATraining Step: 1036  | total loss: [1m[32m0.06162[0m[0m | time: 41.486s
[2K
| Adam | epoch: 026 | loss: 0.06162 - acc: 0.9845 -- iter: 1152/1263
[A[ATraining Step: 1037  | total loss: [1m[32m0.06323[0m[0m | time: 42.742s
[2K
| Adam | epoch: 026 | loss: 0.06323 - acc: 0.9829 -- iter: 1184/1263
[A[ATraining Step: 1038  | total loss: [1m[32m0.06411[0m[0m | time: 43.968s
[2K
| Adam | epoch: 026 | loss: 0.06411 - acc: 0.9815 -- iter: 1216/1263
[A[ATraining Step: 1039  | total loss: [1m[32m0.06559[0m[0m | time: 44.864s
[2K
| Adam | epoch: 026 | loss: 0.06559 - acc: 0.9802 -- iter: 1248/1263
[A[ATraining Step: 1040  | total loss: [1m[32m0.06200[0m[0m | time: 47.765s
[2K
| Adam | epoch: 026 | loss: 0.06200 - acc: 0.9822 | val_loss: 1.08112 - val_acc: 0.7165 -- iter: 1263/1263
--
Training Step: 1041  | total loss: [1m[32m0.05907[0m[0m | time: 0.840s
[2K
| Adam | epoch: 027 | loss: 0.05907 - acc: 0.9840 -- iter: 0032/1263
[A[ATraining Step: 1042  | total loss: [1m[32m0.05506[0m[0m | time: 1.693s
[2K
| Adam | epoch: 027 | loss: 0.05506 - acc: 0.9856 -- iter: 0064/1263
[A[ATraining Step: 1043  | total loss: [1m[32m0.05213[0m[0m | time: 2.535s
[2K
| Adam | epoch: 027 | loss: 0.05213 - acc: 0.9870 -- iter: 0096/1263
[A[ATraining Step: 1044  | total loss: [1m[32m0.04887[0m[0m | time: 3.368s
[2K
| Adam | epoch: 027 | loss: 0.04887 - acc: 0.9883 -- iter: 0128/1263
[A[ATraining Step: 1045  | total loss: [1m[32m0.05435[0m[0m | time: 4.172s
[2K
| Adam | epoch: 027 | loss: 0.05435 - acc: 0.9864 -- iter: 0160/1263
[A[ATraining Step: 1046  | total loss: [1m[32m0.07525[0m[0m | time: 4.979s
[2K
| Adam | epoch: 027 | loss: 0.07525 - acc: 0.9784 -- iter: 0192/1263
[A[ATraining Step: 1047  | total loss: [1m[32m0.06822[0m[0m | time: 5.799s
[2K
| Adam | epoch: 027 | loss: 0.06822 - acc: 0.9805 -- iter: 0224/1263
[A[ATraining Step: 1048  | total loss: [1m[32m0.06221[0m[0m | time: 6.679s
[2K
| Adam | epoch: 027 | loss: 0.06221 - acc: 0.9825 -- iter: 0256/1263
[A[ATraining Step: 1049  | total loss: [1m[32m0.06503[0m[0m | time: 7.525s
[2K
| Adam | epoch: 027 | loss: 0.06503 - acc: 0.9811 -- iter: 0288/1263
[A[ATraining Step: 1050  | total loss: [1m[32m0.05889[0m[0m | time: 8.376s
[2K
| Adam | epoch: 027 | loss: 0.05889 - acc: 0.9830 -- iter: 0320/1263
[A[ATraining Step: 1051  | total loss: [1m[32m0.05414[0m[0m | time: 9.222s
[2K
| Adam | epoch: 027 | loss: 0.05414 - acc: 0.9847 -- iter: 0352/1263
[A[ATraining Step: 1052  | total loss: [1m[32m0.04995[0m[0m | time: 10.048s
[2K
| Adam | epoch: 027 | loss: 0.04995 - acc: 0.9862 -- iter: 0384/1263
[A[ATraining Step: 1053  | total loss: [1m[32m0.04906[0m[0m | time: 10.883s
[2K
| Adam | epoch: 027 | loss: 0.04906 - acc: 0.9845 -- iter: 0416/1263
[A[ATraining Step: 1054  | total loss: [1m[32m0.04572[0m[0m | time: 11.732s
[2K
| Adam | epoch: 027 | loss: 0.04572 - acc: 0.9860 -- iter: 0448/1263
[A[ATraining Step: 1055  | total loss: [1m[32m0.04164[0m[0m | time: 12.778s
[2K
| Adam | epoch: 027 | loss: 0.04164 - acc: 0.9874 -- iter: 0480/1263
[A[ATraining Step: 1056  | total loss: [1m[32m0.04110[0m[0m | time: 13.892s
[2K
| Adam | epoch: 027 | loss: 0.04110 - acc: 0.9887 -- iter: 0512/1263
[A[ATraining Step: 1057  | total loss: [1m[32m0.04051[0m[0m | time: 15.051s
[2K
| Adam | epoch: 027 | loss: 0.04051 - acc: 0.9898 -- iter: 0544/1263
[A[ATraining Step: 1058  | total loss: [1m[32m0.03902[0m[0m | time: 16.393s
[2K
| Adam | epoch: 027 | loss: 0.03902 - acc: 0.9908 -- iter: 0576/1263
[A[ATraining Step: 1059  | total loss: [1m[32m0.05612[0m[0m | time: 18.893s
[2K
| Adam | epoch: 027 | loss: 0.05612 - acc: 0.9855 -- iter: 0608/1263
[A[ATraining Step: 1060  | total loss: [1m[32m0.05157[0m[0m | time: 21.971s
[2K
| Adam | epoch: 027 | loss: 0.05157 - acc: 0.9869 -- iter: 0640/1263
[A[ATraining Step: 1061  | total loss: [1m[32m0.04779[0m[0m | time: 26.880s
[2K
| Adam | epoch: 027 | loss: 0.04779 - acc: 0.9883 -- iter: 0672/1263
[A[ATraining Step: 1062  | total loss: [1m[32m0.04519[0m[0m | time: 30.870s
[2K
| Adam | epoch: 027 | loss: 0.04519 - acc: 0.9894 -- iter: 0704/1263
[A[ATraining Step: 1063  | total loss: [1m[32m0.05123[0m[0m | time: 35.598s
[2K
| Adam | epoch: 027 | loss: 0.05123 - acc: 0.9842 -- iter: 0736/1263
[A[ATraining Step: 1064  | total loss: [1m[32m0.04971[0m[0m | time: 38.398s
[2K
| Adam | epoch: 027 | loss: 0.04971 - acc: 0.9858 -- iter: 0768/1263
[A[ATraining Step: 1065  | total loss: [1m[32m0.05748[0m[0m | time: 40.777s
[2K
| Adam | epoch: 027 | loss: 0.05748 - acc: 0.9810 -- iter: 0800/1263
[A[ATraining Step: 1066  | total loss: [1m[32m0.08842[0m[0m | time: 41.836s
[2K
| Adam | epoch: 027 | loss: 0.08842 - acc: 0.9762 -- iter: 0832/1263
[A[ATraining Step: 1067  | total loss: [1m[32m0.10158[0m[0m | time: 43.489s
[2K
| Adam | epoch: 027 | loss: 0.10158 - acc: 0.9719 -- iter: 0864/1263
[A[ATraining Step: 1068  | total loss: [1m[32m0.09290[0m[0m | time: 45.969s
[2K
| Adam | epoch: 027 | loss: 0.09290 - acc: 0.9747 -- iter: 0896/1263
[A[ATraining Step: 1069  | total loss: [1m[32m0.08776[0m[0m | time: 47.031s
[2K
| Adam | epoch: 027 | loss: 0.08776 - acc: 0.9773 -- iter: 0928/1263
[A[ATraining Step: 1070  | total loss: [1m[32m0.11746[0m[0m | time: 48.138s
[2K
| Adam | epoch: 027 | loss: 0.11746 - acc: 0.9639 -- iter: 0960/1263
[A[ATraining Step: 1071  | total loss: [1m[32m0.16788[0m[0m | time: 49.310s
[2K
| Adam | epoch: 027 | loss: 0.16788 - acc: 0.9425 -- iter: 0992/1263
[A[ATraining Step: 1072  | total loss: [1m[32m0.17342[0m[0m | time: 50.382s
[2K
| Adam | epoch: 027 | loss: 0.17342 - acc: 0.9389 -- iter: 1024/1263
[A[ATraining Step: 1073  | total loss: [1m[32m0.19137[0m[0m | time: 51.526s
[2K
| Adam | epoch: 027 | loss: 0.19137 - acc: 0.9325 -- iter: 1056/1263
[A[ATraining Step: 1074  | total loss: [1m[32m0.19231[0m[0m | time: 52.754s
[2K
| Adam | epoch: 027 | loss: 0.19231 - acc: 0.9330 -- iter: 1088/1263
[A[ATraining Step: 1075  | total loss: [1m[32m0.21321[0m[0m | time: 53.995s
[2K
| Adam | epoch: 027 | loss: 0.21321 - acc: 0.9335 -- iter: 1120/1263
[A[ATraining Step: 1076  | total loss: [1m[32m0.19507[0m[0m | time: 55.108s
[2K
| Adam | epoch: 027 | loss: 0.19507 - acc: 0.9401 -- iter: 1152/1263
[A[ATraining Step: 1077  | total loss: [1m[32m0.19463[0m[0m | time: 56.492s
[2K
| Adam | epoch: 027 | loss: 0.19463 - acc: 0.9398 -- iter: 1184/1263
[A[ATraining Step: 1078  | total loss: [1m[32m0.19746[0m[0m | time: 57.583s
[2K
| Adam | epoch: 027 | loss: 0.19746 - acc: 0.9334 -- iter: 1216/1263
[A[ATraining Step: 1079  | total loss: [1m[32m0.22216[0m[0m | time: 59.449s
[2K
| Adam | epoch: 027 | loss: 0.22216 - acc: 0.9244 -- iter: 1248/1263
[A[ATraining Step: 1080  | total loss: [1m[32m0.23327[0m[0m | time: 69.507s
[2K
| Adam | epoch: 027 | loss: 0.23327 - acc: 0.9226 | val_loss: 0.95145 - val_acc: 0.7013 -- iter: 1263/1263
--
Training Step: 1081  | total loss: [1m[32m0.21510[0m[0m | time: 1.240s
[2K
| Adam | epoch: 028 | loss: 0.21510 - acc: 0.9272 -- iter: 0032/1263
[A[ATraining Step: 1082  | total loss: [1m[32m0.20259[0m[0m | time: 2.440s
[2K
| Adam | epoch: 028 | loss: 0.20259 - acc: 0.9314 -- iter: 0064/1263
[A[ATraining Step: 1083  | total loss: [1m[32m0.18600[0m[0m | time: 3.634s
[2K
| Adam | epoch: 028 | loss: 0.18600 - acc: 0.9382 -- iter: 0096/1263
[A[ATraining Step: 1084  | total loss: [1m[32m0.19137[0m[0m | time: 4.904s
[2K
| Adam | epoch: 028 | loss: 0.19137 - acc: 0.9381 -- iter: 0128/1263
[A[ATraining Step: 1085  | total loss: [1m[32m0.21734[0m[0m | time: 6.043s
[2K
| Adam | epoch: 028 | loss: 0.21734 - acc: 0.9256 -- iter: 0160/1263
[A[ATraining Step: 1086  | total loss: [1m[32m0.20268[0m[0m | time: 7.294s
[2K
| Adam | epoch: 028 | loss: 0.20268 - acc: 0.9299 -- iter: 0192/1263
[A[ATraining Step: 1087  | total loss: [1m[32m0.19841[0m[0m | time: 8.352s
[2K
| Adam | epoch: 028 | loss: 0.19841 - acc: 0.9275 -- iter: 0224/1263
[A[ATraining Step: 1088  | total loss: [1m[32m0.18237[0m[0m | time: 9.473s
[2K
| Adam | epoch: 028 | loss: 0.18237 - acc: 0.9348 -- iter: 0256/1263
[A[ATraining Step: 1089  | total loss: [1m[32m0.18530[0m[0m | time: 10.527s
[2K
| Adam | epoch: 028 | loss: 0.18530 - acc: 0.9351 -- iter: 0288/1263
[A[ATraining Step: 1090  | total loss: [1m[32m0.16829[0m[0m | time: 11.654s
[2K
| Adam | epoch: 028 | loss: 0.16829 - acc: 0.9415 -- iter: 0320/1263
[A[ATraining Step: 1091  | total loss: [1m[32m0.16418[0m[0m | time: 12.761s
[2K
| Adam | epoch: 028 | loss: 0.16418 - acc: 0.9443 -- iter: 0352/1263
[A[ATraining Step: 1092  | total loss: [1m[32m0.16029[0m[0m | time: 13.901s
[2K
| Adam | epoch: 028 | loss: 0.16029 - acc: 0.9436 -- iter: 0384/1263
[A[ATraining Step: 1093  | total loss: [1m[32m0.16719[0m[0m | time: 14.913s
[2K
| Adam | epoch: 028 | loss: 0.16719 - acc: 0.9367 -- iter: 0416/1263
[A[ATraining Step: 1094  | total loss: [1m[32m0.16025[0m[0m | time: 15.886s
[2K
| Adam | epoch: 028 | loss: 0.16025 - acc: 0.9399 -- iter: 0448/1263
[A[ATraining Step: 1095  | total loss: [1m[32m0.15630[0m[0m | time: 16.939s
[2K
| Adam | epoch: 028 | loss: 0.15630 - acc: 0.9366 -- iter: 0480/1263
[A[ATraining Step: 1096  | total loss: [1m[32m0.14944[0m[0m | time: 17.990s
[2K
| Adam | epoch: 028 | loss: 0.14944 - acc: 0.9398 -- iter: 0512/1263
[A[ATraining Step: 1097  | total loss: [1m[32m0.13633[0m[0m | time: 19.266s
[2K
| Adam | epoch: 028 | loss: 0.13633 - acc: 0.9458 -- iter: 0544/1263
[A[ATraining Step: 1098  | total loss: [1m[32m0.12675[0m[0m | time: 20.608s
[2K
| Adam | epoch: 028 | loss: 0.12675 - acc: 0.9481 -- iter: 0576/1263
[A[ATraining Step: 1099  | total loss: [1m[32m0.12610[0m[0m | time: 30.180s
[2K
| Adam | epoch: 028 | loss: 0.12610 - acc: 0.9502 -- iter: 0608/1263
[A[ATraining Step: 1100  | total loss: [1m[32m0.13076[0m[0m | time: 35.709s
[2K
| Adam | epoch: 028 | loss: 0.13076 - acc: 0.9520 -- iter: 0640/1263
[A[ATraining Step: 1101  | total loss: [1m[32m0.12048[0m[0m | time: 36.760s
[2K
| Adam | epoch: 028 | loss: 0.12048 - acc: 0.9568 -- iter: 0672/1263
[A[ATraining Step: 1102  | total loss: [1m[32m0.11487[0m[0m | time: 37.940s
[2K
| Adam | epoch: 028 | loss: 0.11487 - acc: 0.9580 -- iter: 0704/1263
[A[ATraining Step: 1103  | total loss: [1m[32m0.10839[0m[0m | time: 39.062s
[2K
| Adam | epoch: 028 | loss: 0.10839 - acc: 0.9591 -- iter: 0736/1263
[A[ATraining Step: 1104  | total loss: [1m[32m0.09960[0m[0m | time: 40.203s
[2K
| Adam | epoch: 028 | loss: 0.09960 - acc: 0.9632 -- iter: 0768/1263
[A[ATraining Step: 1105  | total loss: [1m[32m0.09311[0m[0m | time: 41.347s
[2K
| Adam | epoch: 028 | loss: 0.09311 - acc: 0.9669 -- iter: 0800/1263
[A[ATraining Step: 1106  | total loss: [1m[32m0.10586[0m[0m | time: 41.903s
[2K
| Adam | epoch: 028 | loss: 0.10586 - acc: 0.9608 -- iter: 0832/1263
[A[ATraining Step: 1107  | total loss: [1m[32m0.09689[0m[0m | time: 42.556s
[2K
| Adam | epoch: 028 | loss: 0.09689 - acc: 0.9647 -- iter: 0864/1263
[A[ATraining Step: 1108  | total loss: [1m[32m0.08872[0m[0m | time: 43.694s
[2K
| Adam | epoch: 028 | loss: 0.08872 - acc: 0.9682 -- iter: 0896/1263
[A[ATraining Step: 1109  | total loss: [1m[32m0.08111[0m[0m | time: 44.792s
[2K
| Adam | epoch: 028 | loss: 0.08111 - acc: 0.9714 -- iter: 0928/1263
[A[ATraining Step: 1110  | total loss: [1m[32m0.07424[0m[0m | time: 46.016s
[2K
| Adam | epoch: 028 | loss: 0.07424 - acc: 0.9743 -- iter: 0960/1263
[A[ATraining Step: 1111  | total loss: [1m[32m0.07439[0m[0m | time: 51.661s
[2K
| Adam | epoch: 028 | loss: 0.07439 - acc: 0.9737 -- iter: 0992/1263
[A[ATraining Step: 1112  | total loss: [1m[32m0.06889[0m[0m | time: 55.503s
[2K
| Adam | epoch: 028 | loss: 0.06889 - acc: 0.9764 -- iter: 1024/1263
[A[ATraining Step: 1113  | total loss: [1m[32m0.07398[0m[0m | time: 59.631s
[2K
| Adam | epoch: 028 | loss: 0.07398 - acc: 0.9756 -- iter: 1056/1263
[A[ATraining Step: 1114  | total loss: [1m[32m0.08163[0m[0m | time: 62.922s
[2K
| Adam | epoch: 028 | loss: 0.08163 - acc: 0.9718 -- iter: 1088/1263
[A[ATraining Step: 1115  | total loss: [1m[32m0.07531[0m[0m | time: 65.128s
[2K
| Adam | epoch: 028 | loss: 0.07531 - acc: 0.9746 -- iter: 1120/1263
[A[ATraining Step: 1116  | total loss: [1m[32m0.11197[0m[0m | time: 66.256s
[2K
| Adam | epoch: 028 | loss: 0.11197 - acc: 0.9678 -- iter: 1152/1263
[A[ATraining Step: 1117  | total loss: [1m[32m0.11853[0m[0m | time: 67.347s
[2K
| Adam | epoch: 028 | loss: 0.11853 - acc: 0.9679 -- iter: 1184/1263
[A[ATraining Step: 1118  | total loss: [1m[32m0.12078[0m[0m | time: 68.441s
[2K
| Adam | epoch: 028 | loss: 0.12078 - acc: 0.9680 -- iter: 1216/1263
[A[ATraining Step: 1119  | total loss: [1m[32m0.11030[0m[0m | time: 69.552s
[2K
| Adam | epoch: 028 | loss: 0.11030 - acc: 0.9712 -- iter: 1248/1263
[A[ATraining Step: 1120  | total loss: [1m[32m0.11624[0m[0m | time: 73.805s
[2K
| Adam | epoch: 028 | loss: 0.11624 - acc: 0.9678 | val_loss: 0.92810 - val_acc: 0.7063 -- iter: 1263/1263
--
Training Step: 1121  | total loss: [1m[32m0.10594[0m[0m | time: 1.172s
[2K
| Adam | epoch: 029 | loss: 0.10594 - acc: 0.9710 -- iter: 0032/1263
[A[ATraining Step: 1122  | total loss: [1m[32m0.09678[0m[0m | time: 2.819s
[2K
| Adam | epoch: 029 | loss: 0.09678 - acc: 0.9739 -- iter: 0064/1263
[A[ATraining Step: 1123  | total loss: [1m[32m0.09316[0m[0m | time: 8.128s
[2K
| Adam | epoch: 029 | loss: 0.09316 - acc: 0.9734 -- iter: 0096/1263
[A[ATraining Step: 1124  | total loss: [1m[32m0.08569[0m[0m | time: 11.966s
[2K
| Adam | epoch: 029 | loss: 0.08569 - acc: 0.9761 -- iter: 0128/1263
[A[ATraining Step: 1125  | total loss: [1m[32m0.08176[0m[0m | time: 15.760s
[2K
| Adam | epoch: 029 | loss: 0.08176 - acc: 0.9785 -- iter: 0160/1263
[A[ATraining Step: 1126  | total loss: [1m[32m0.07672[0m[0m | time: 19.277s
[2K
| Adam | epoch: 029 | loss: 0.07672 - acc: 0.9806 -- iter: 0192/1263
[A[ATraining Step: 1127  | total loss: [1m[32m0.07866[0m[0m | time: 24.607s
[2K
| Adam | epoch: 029 | loss: 0.07866 - acc: 0.9794 -- iter: 0224/1263
[A[ATraining Step: 1128  | total loss: [1m[32m0.07422[0m[0m | time: 25.901s
[2K
| Adam | epoch: 029 | loss: 0.07422 - acc: 0.9815 -- iter: 0256/1263
[A[ATraining Step: 1129  | total loss: [1m[32m0.07072[0m[0m | time: 27.141s
[2K
| Adam | epoch: 029 | loss: 0.07072 - acc: 0.9802 -- iter: 0288/1263
[A[ATraining Step: 1130  | total loss: [1m[32m0.06507[0m[0m | time: 28.120s
[2K
| Adam | epoch: 029 | loss: 0.06507 - acc: 0.9822 -- iter: 0320/1263
[A[ATraining Step: 1131  | total loss: [1m[32m0.05985[0m[0m | time: 29.217s
[2K
| Adam | epoch: 029 | loss: 0.05985 - acc: 0.9840 -- iter: 0352/1263
[A[ATraining Step: 1132  | total loss: [1m[32m0.05549[0m[0m | time: 30.426s
[2K
| Adam | epoch: 029 | loss: 0.05549 - acc: 0.9856 -- iter: 0384/1263
[A[ATraining Step: 1133  | total loss: [1m[32m0.06584[0m[0m | time: 31.676s
[2K
| Adam | epoch: 029 | loss: 0.06584 - acc: 0.9808 -- iter: 0416/1263
[A[ATraining Step: 1134  | total loss: [1m[32m0.06151[0m[0m | time: 32.756s
[2K
| Adam | epoch: 029 | loss: 0.06151 - acc: 0.9827 -- iter: 0448/1263
[A[ATraining Step: 1135  | total loss: [1m[32m0.05679[0m[0m | time: 34.072s
[2K
| Adam | epoch: 029 | loss: 0.05679 - acc: 0.9844 -- iter: 0480/1263
[A[ATraining Step: 1136  | total loss: [1m[32m0.06633[0m[0m | time: 35.271s
[2K
| Adam | epoch: 029 | loss: 0.06633 - acc: 0.9797 -- iter: 0512/1263
[A[ATraining Step: 1137  | total loss: [1m[32m0.08123[0m[0m | time: 41.226s
[2K
| Adam | epoch: 029 | loss: 0.08123 - acc: 0.9755 -- iter: 0544/1263
[A[ATraining Step: 1138  | total loss: [1m[32m0.07797[0m[0m | time: 43.304s
[2K
| Adam | epoch: 029 | loss: 0.07797 - acc: 0.9748 -- iter: 0576/1263
[A[ATraining Step: 1139  | total loss: [1m[32m0.07958[0m[0m | time: 46.668s
[2K
| Adam | epoch: 029 | loss: 0.07958 - acc: 0.9742 -- iter: 0608/1263
[A[ATraining Step: 1140  | total loss: [1m[32m0.07478[0m[0m | time: 47.621s
[2K
| Adam | epoch: 029 | loss: 0.07478 - acc: 0.9768 -- iter: 0640/1263
[A[ATraining Step: 1141  | total loss: [1m[32m0.06840[0m[0m | time: 48.640s
[2K
| Adam | epoch: 029 | loss: 0.06840 - acc: 0.9791 -- iter: 0672/1263
[A[ATraining Step: 1142  | total loss: [1m[32m0.06317[0m[0m | time: 49.671s
[2K
| Adam | epoch: 029 | loss: 0.06317 - acc: 0.9812 -- iter: 0704/1263
[A[ATraining Step: 1143  | total loss: [1m[32m0.06886[0m[0m | time: 50.742s
[2K
| Adam | epoch: 029 | loss: 0.06886 - acc: 0.9800 -- iter: 0736/1263
[A[ATraining Step: 1144  | total loss: [1m[32m0.06309[0m[0m | time: 51.839s
[2K
| Adam | epoch: 029 | loss: 0.06309 - acc: 0.9820 -- iter: 0768/1263
[A[ATraining Step: 1145  | total loss: [1m[32m0.06995[0m[0m | time: 52.985s
[2K
| Adam | epoch: 029 | loss: 0.06995 - acc: 0.9806 -- iter: 0800/1263
[A[ATraining Step: 1146  | total loss: [1m[32m0.06553[0m[0m | time: 54.164s
[2K
| Adam | epoch: 029 | loss: 0.06553 - acc: 0.9826 -- iter: 0832/1263
[A[ATraining Step: 1147  | total loss: [1m[32m0.06387[0m[0m | time: 54.665s
[2K
| Adam | epoch: 029 | loss: 0.06387 - acc: 0.9843 -- iter: 0864/1263
[A[ATraining Step: 1148  | total loss: [1m[32m0.07481[0m[0m | time: 55.363s
[2K
| Adam | epoch: 029 | loss: 0.07481 - acc: 0.9792 -- iter: 0896/1263
[A[ATraining Step: 1149  | total loss: [1m[32m0.07527[0m[0m | time: 56.459s
[2K
| Adam | epoch: 029 | loss: 0.07527 - acc: 0.9746 -- iter: 0928/1263
[A[ATraining Step: 1150  | total loss: [1m[32m0.07493[0m[0m | time: 57.606s
[2K
| Adam | epoch: 029 | loss: 0.07493 - acc: 0.9709 -- iter: 0960/1263
[A[ATraining Step: 1151  | total loss: [1m[32m0.08983[0m[0m | time: 58.865s
[2K
| Adam | epoch: 029 | loss: 0.08983 - acc: 0.9676 -- iter: 0992/1263
[A[ATraining Step: 1152  | total loss: [1m[32m0.08351[0m[0m | time: 60.171s
[2K
| Adam | epoch: 029 | loss: 0.08351 - acc: 0.9708 -- iter: 1024/1263
[A[ATraining Step: 1153  | total loss: [1m[32m0.07792[0m[0m | time: 61.413s
[2K
| Adam | epoch: 029 | loss: 0.07792 - acc: 0.9706 -- iter: 1056/1263
[A[ATraining Step: 1154  | total loss: [1m[32m0.07200[0m[0m | time: 62.488s
[2K
| Adam | epoch: 029 | loss: 0.07200 - acc: 0.9736 -- iter: 1088/1263
[A[ATraining Step: 1155  | total loss: [1m[32m0.07385[0m[0m | time: 63.321s
[2K
| Adam | epoch: 029 | loss: 0.07385 - acc: 0.9731 -- iter: 1120/1263
[A[ATraining Step: 1156  | total loss: [1m[32m0.07160[0m[0m | time: 64.108s
[2K
| Adam | epoch: 029 | loss: 0.07160 - acc: 0.9726 -- iter: 1152/1263
[A[ATraining Step: 1157  | total loss: [1m[32m0.11641[0m[0m | time: 64.962s
[2K
| Adam | epoch: 029 | loss: 0.11641 - acc: 0.9629 -- iter: 1184/1263
[A[ATraining Step: 1158  | total loss: [1m[32m0.10588[0m[0m | time: 65.780s
[2K
| Adam | epoch: 029 | loss: 0.10588 - acc: 0.9666 -- iter: 1216/1263
[A[ATraining Step: 1159  | total loss: [1m[32m0.09627[0m[0m | time: 66.599s
[2K
| Adam | epoch: 029 | loss: 0.09627 - acc: 0.9699 -- iter: 1248/1263
[A[ATraining Step: 1160  | total loss: [1m[32m0.10589[0m[0m | time: 69.444s
[2K
| Adam | epoch: 029 | loss: 0.10589 - acc: 0.9698 | val_loss: 1.06925 - val_acc: 0.6962 -- iter: 1263/1263
--
Training Step: 1161  | total loss: [1m[32m0.10448[0m[0m | time: 0.877s
[2K
| Adam | epoch: 030 | loss: 0.10448 - acc: 0.9697 -- iter: 0032/1263
[A[ATraining Step: 1162  | total loss: [1m[32m0.09551[0m[0m | time: 1.714s
[2K
| Adam | epoch: 030 | loss: 0.09551 - acc: 0.9727 -- iter: 0064/1263
[A[ATraining Step: 1163  | total loss: [1m[32m0.10996[0m[0m | time: 2.544s
[2K
| Adam | epoch: 030 | loss: 0.10996 - acc: 0.9723 -- iter: 0096/1263
[A[ATraining Step: 1164  | total loss: [1m[32m0.11543[0m[0m | time: 3.414s
[2K
| Adam | epoch: 030 | loss: 0.11543 - acc: 0.9657 -- iter: 0128/1263
[A[ATraining Step: 1165  | total loss: [1m[32m0.11233[0m[0m | time: 4.238s
[2K
| Adam | epoch: 030 | loss: 0.11233 - acc: 0.9660 -- iter: 0160/1263
[A[ATraining Step: 1166  | total loss: [1m[32m0.11272[0m[0m | time: 5.131s
[2K
| Adam | epoch: 030 | loss: 0.11272 - acc: 0.9663 -- iter: 0192/1263
[A[ATraining Step: 1167  | total loss: [1m[32m0.10757[0m[0m | time: 5.938s
[2K
| Adam | epoch: 030 | loss: 0.10757 - acc: 0.9665 -- iter: 0224/1263
[A[ATraining Step: 1168  | total loss: [1m[32m0.11325[0m[0m | time: 6.781s
[2K
| Adam | epoch: 030 | loss: 0.11325 - acc: 0.9668 -- iter: 0256/1263
[A[ATraining Step: 1169  | total loss: [1m[32m0.10580[0m[0m | time: 7.575s
[2K
| Adam | epoch: 030 | loss: 0.10580 - acc: 0.9670 -- iter: 0288/1263
[A[ATraining Step: 1170  | total loss: [1m[32m0.09713[0m[0m | time: 8.446s
[2K
| Adam | epoch: 030 | loss: 0.09713 - acc: 0.9703 -- iter: 0320/1263
[A[ATraining Step: 1171  | total loss: [1m[32m0.10179[0m[0m | time: 9.268s
[2K
| Adam | epoch: 030 | loss: 0.10179 - acc: 0.9670 -- iter: 0352/1263
[A[ATraining Step: 1172  | total loss: [1m[32m0.09295[0m[0m | time: 10.117s
[2K
| Adam | epoch: 030 | loss: 0.09295 - acc: 0.9703 -- iter: 0384/1263
[A[ATraining Step: 1173  | total loss: [1m[32m0.08896[0m[0m | time: 11.943s
[2K
| Adam | epoch: 030 | loss: 0.08896 - acc: 0.9733 -- iter: 0416/1263
[A[ATraining Step: 1174  | total loss: [1m[32m0.10992[0m[0m | time: 13.290s
[2K
| Adam | epoch: 030 | loss: 0.10992 - acc: 0.9697 -- iter: 0448/1263
[A[ATraining Step: 1175  | total loss: [1m[32m0.12102[0m[0m | time: 16.319s
[2K
| Adam | epoch: 030 | loss: 0.12102 - acc: 0.9696 -- iter: 0480/1263
[A[ATraining Step: 1176  | total loss: [1m[32m0.11305[0m[0m | time: 18.196s
[2K
| Adam | epoch: 030 | loss: 0.11305 - acc: 0.9695 -- iter: 0512/1263
[A[ATraining Step: 1177  | total loss: [1m[32m0.10561[0m[0m | time: 19.282s
[2K
| Adam | epoch: 030 | loss: 0.10561 - acc: 0.9726 -- iter: 0544/1263
[A[ATraining Step: 1178  | total loss: [1m[32m0.09970[0m[0m | time: 20.426s
[2K
| Adam | epoch: 030 | loss: 0.09970 - acc: 0.9753 -- iter: 0576/1263
[A[ATraining Step: 1179  | total loss: [1m[32m0.09097[0m[0m | time: 21.583s
[2K
| Adam | epoch: 030 | loss: 0.09097 - acc: 0.9778 -- iter: 0608/1263
[A[ATraining Step: 1180  | total loss: [1m[32m0.09056[0m[0m | time: 22.738s
[2K
| Adam | epoch: 030 | loss: 0.09056 - acc: 0.9737 -- iter: 0640/1263
[A[ATraining Step: 1181  | total loss: [1m[32m0.09060[0m[0m | time: 23.938s
[2K
| Adam | epoch: 030 | loss: 0.09060 - acc: 0.9732 -- iter: 0672/1263
[A[ATraining Step: 1182  | total loss: [1m[32m0.08369[0m[0m | time: 25.105s
[2K
| Adam | epoch: 030 | loss: 0.08369 - acc: 0.9759 -- iter: 0704/1263
[A[ATraining Step: 1183  | total loss: [1m[32m0.08758[0m[0m | time: 26.264s
[2K
| Adam | epoch: 030 | loss: 0.08758 - acc: 0.9752 -- iter: 0736/1263
[A[ATraining Step: 1184  | total loss: [1m[32m0.09184[0m[0m | time: 27.360s
[2K
| Adam | epoch: 030 | loss: 0.09184 - acc: 0.9746 -- iter: 0768/1263
[A[ATraining Step: 1185  | total loss: [1m[32m0.09423[0m[0m | time: 28.643s
[2K
| Adam | epoch: 030 | loss: 0.09423 - acc: 0.9740 -- iter: 0800/1263
[A[ATraining Step: 1186  | total loss: [1m[32m0.08739[0m[0m | time: 29.832s
[2K
| Adam | epoch: 030 | loss: 0.08739 - acc: 0.9766 -- iter: 0832/1263
[A[ATraining Step: 1187  | total loss: [1m[32m0.08478[0m[0m | time: 30.798s
[2K
| Adam | epoch: 030 | loss: 0.08478 - acc: 0.9758 -- iter: 0864/1263
[A[ATraining Step: 1188  | total loss: [1m[32m0.07880[0m[0m | time: 31.308s
[2K
| Adam | epoch: 030 | loss: 0.07880 - acc: 0.9782 -- iter: 0896/1263
[A[ATraining Step: 1189  | total loss: [1m[32m0.07495[0m[0m | time: 31.880s
[2K
| Adam | epoch: 030 | loss: 0.07495 - acc: 0.9804 -- iter: 0928/1263
[A[ATraining Step: 1190  | total loss: [1m[32m0.06970[0m[0m | time: 32.994s
[2K
| Adam | epoch: 030 | loss: 0.06970 - acc: 0.9824 -- iter: 0960/1263
[A[ATraining Step: 1191  | total loss: [1m[32m0.07147[0m[0m | time: 34.175s
[2K
| Adam | epoch: 030 | loss: 0.07147 - acc: 0.9810 -- iter: 0992/1263
[A[ATraining Step: 1192  | total loss: [1m[32m0.06671[0m[0m | time: 35.350s
[2K
| Adam | epoch: 030 | loss: 0.06671 - acc: 0.9829 -- iter: 1024/1263
[A[ATraining Step: 1193  | total loss: [1m[32m0.07819[0m[0m | time: 36.566s
[2K
| Adam | epoch: 030 | loss: 0.07819 - acc: 0.9784 -- iter: 1056/1263
[A[ATraining Step: 1194  | total loss: [1m[32m0.07200[0m[0m | time: 37.741s
[2K
| Adam | epoch: 030 | loss: 0.07200 - acc: 0.9805 -- iter: 1088/1263
[A[ATraining Step: 1195  | total loss: [1m[32m0.06950[0m[0m | time: 38.942s
[2K
| Adam | epoch: 030 | loss: 0.06950 - acc: 0.9793 -- iter: 1120/1263
[A[ATraining Step: 1196  | total loss: [1m[32m0.06441[0m[0m | time: 40.047s
[2K
| Adam | epoch: 030 | loss: 0.06441 - acc: 0.9814 -- iter: 1152/1263
[A[ATraining Step: 1197  | total loss: [1m[32m0.07422[0m[0m | time: 41.420s
[2K
| Adam | epoch: 030 | loss: 0.07422 - acc: 0.9801 -- iter: 1184/1263
[A[ATraining Step: 1198  | total loss: [1m[32m0.09957[0m[0m | time: 42.629s
[2K
| Adam | epoch: 030 | loss: 0.09957 - acc: 0.9759 -- iter: 1216/1263
[A[ATraining Step: 1199  | total loss: [1m[32m0.09084[0m[0m | time: 50.507s
[2K
| Adam | epoch: 030 | loss: 0.09084 - acc: 0.9783 -- iter: 1248/1263
[A[ATraining Step: 1200  | total loss: [1m[32m0.09658[0m[0m | time: 63.789s
[2K
| Adam | epoch: 030 | loss: 0.09658 - acc: 0.9773 | val_loss: 0.96152 - val_acc: 0.7038 -- iter: 1263/1263
--
Validation AUC:0.7654710591133005
Validation AUPRC:0.7496745282687625
Test AUC:0.7615436034553681
Test AUPRC:0.7289944333683849
BestTestF1Score	0.71	0.36	0.65	0.59	0.89	166	117	91	21	0.05
BestTestMCCScore	0.67	0.39	0.7	0.69	0.66	123	56	152	64	0.69
BestTestAccuracyScore	0.67	0.39	0.7	0.69	0.66	123	56	152	64	0.69
BestValidationF1Score	0.74	0.39	0.68	0.64	0.88	179	101	91	24	0.05
BestValidationMCC	0.71	0.44	0.72	0.76	0.66	134	42	150	69	0.69
BestValidationAccuracy	0.71	0.44	0.72	0.76	0.66	134	42	150	69	0.69
TestPredictions (Threshold:0.69)
CHEMBL347527,FP,INACT,0.8100000023841858	CHEMBL434510,TN,INACT,0.029999999329447746	CHEMBL2238457,FN,ACT,0.0	CHEMBL1258500,TP,ACT,1.0	CHEMBL1254623,TN,INACT,0.009999999776482582	CHEMBL48556,FP,INACT,0.7599999904632568	CHEMBL2372410,FN,ACT,0.009999999776482582	CHEMBL2409538,FP,INACT,1.0	CHEMBL3415781,TP,ACT,1.0	CHEMBL434261,TN,INACT,0.009999999776482582	CHEMBL42965,FP,INACT,0.949999988079071	CHEMBL3415614,TP,ACT,0.9800000190734863	CHEMBL3764408,TN,INACT,0.009999999776482582	CHEMBL3297870,TN,INACT,0.009999999776482582	CHEMBL1222282,FP,INACT,0.9800000190734863	CHEMBL2204764,TP,ACT,0.9900000095367432	CHEMBL600856,TN,INACT,0.009999999776482582	CHEMBL2420786,TN,INACT,0.019999999552965164	CHEMBL3398526,TP,ACT,0.9700000286102295	CHEMBL420523,TN,INACT,0.0	CHEMBL1766622,TN,INACT,0.47999998927116394	CHEMBL158946,TP,ACT,0.800000011920929	CHEMBL3415819,TP,ACT,1.0	CHEMBL325761,FN,ACT,0.6200000047683716	CHEMBL2420792,TN,INACT,0.019999999552965164	CHEMBL187801,TN,INACT,0.009999999776482582	CHEMBL3775613,TN,INACT,0.03999999910593033	CHEMBL1830809,FP,INACT,0.9900000095367432	CHEMBL3134350,TN,INACT,0.009999999776482582	CHEMBL1830832,TN,INACT,0.009999999776482582	CHEMBL2440538,TN,INACT,0.0	CHEMBL2440576,TN,INACT,0.009999999776482582	CHEMBL3771168,TP,ACT,0.9900000095367432	CHEMBL3786282,TP,ACT,1.0	CHEMBL1642682,FP,INACT,0.8199999928474426	CHEMBL1830144,TN,INACT,0.009999999776482582	CHEMBL3113638,FN,ACT,0.11999999731779099	CHEMBL18390,TN,INACT,0.3100000023841858	CHEMBL1917532,TP,ACT,0.9900000095367432	CHEMBL123894,TN,INACT,0.6000000238418579	CHEMBL1258387,TP,ACT,0.9800000190734863	CHEMBL3408925,TN,INACT,0.6499999761581421	CHEMBL1987137,TP,ACT,0.9900000095367432	CHEMBL2252336,FP,INACT,0.9900000095367432	CHEMBL2177463,FP,INACT,0.9200000166893005	CHEMBL1796447,FN,ACT,0.28999999165534973	CHEMBL571712,TN,INACT,0.5	CHEMBL185960,FN,ACT,0.019999999552965164	CHEMBL508324,TP,ACT,0.7900000214576721	CHEMBL3651092,TP,ACT,1.0	CHEMBL3261199,TN,INACT,0.05999999865889549	CHEMBL2206094,TP,ACT,0.9700000286102295	CHEMBL229472,TP,ACT,0.9900000095367432	CHEMBL3134367,FN,ACT,0.019999999552965164	CHEMBL65761,TP,ACT,0.7200000286102295	CHEMBL488917,TP,ACT,0.9800000190734863	CHEMBL3799699,FN,ACT,0.10999999940395355	CHEMBL3218168,TP,ACT,1.0	CHEMBL575735,TN,INACT,0.019999999552965164	CHEMBL3121774,TP,ACT,0.9700000286102295	CHEMBL2204756,TP,ACT,1.0	CHEMBL3651148,FN,ACT,0.6299999952316284	CHEMBL1830799,TN,INACT,0.18000000715255737	CHEMBL519241,TN,INACT,0.4300000071525574	CHEMBL3781838,TP,ACT,0.9900000095367432	CHEMBL3134358,TN,INACT,0.05000000074505806	CHEMBL1823814,TN,INACT,0.0	CHEMBL3288294,TP,ACT,0.9900000095367432	CHEMBL472713,TN,INACT,0.029999999329447746	CHEMBL568385,TN,INACT,0.5199999809265137	CHEMBL1760714,TP,ACT,1.0	CHEMBL6616,TN,INACT,0.03999999910593033	CHEMBL2332170,TP,ACT,0.9700000286102295	CHEMBL3113639,TN,INACT,0.009999999776482582	CHEMBL972,TN,INACT,0.0	CHEMBL543216,FP,INACT,0.9900000095367432	CHEMBL3417297,TN,INACT,0.07000000029802322	CHEMBL3585814,TN,INACT,0.07000000029802322	CHEMBL3415542,FP,INACT,0.9399999976158142	CHEMBL1080448,TN,INACT,0.019999999552965164	CHEMBL2252333,FP,INACT,0.9800000190734863	CHEMBL374237,TN,INACT,0.38999998569488525	CHEMBL3288300,TP,ACT,0.9900000095367432	CHEMBL461973,TN,INACT,0.019999999552965164	CHEMBL455181,TN,INACT,0.3100000023841858	CHEMBL1594810,TN,INACT,0.019999999552965164	CHEMBL457766,TN,INACT,0.009999999776482582	CHEMBL124867,TN,INACT,0.0	CHEMBL3134373,TN,INACT,0.029999999329447746	CHEMBL471348,TN,INACT,0.05000000074505806	CHEMBL1196,FN,ACT,0.009999999776482582	CHEMBL1243212,TN,INACT,0.009999999776482582	CHEMBL3759239,FN,ACT,0.6200000047683716	CHEMBL1243026,TN,INACT,0.05000000074505806	CHEMBL3132866,TN,INACT,0.05000000074505806	CHEMBL3394518,TN,INACT,0.009999999776482582	CHEMBL1796457,TP,ACT,1.0	CHEMBL340701,TN,INACT,0.2800000011920929	CHEMBL3288306,TN,INACT,0.20999999344348907	CHEMBL3417293,FP,INACT,0.7200000286102295	CHEMBL69728,TN,INACT,0.09000000357627869	CHEMBL1254934,FP,INACT,0.9599999785423279	CHEMBL187044,FN,ACT,0.20999999344348907	CHEMBL156994,TN,INACT,0.009999999776482582	CHEMBL14355,TP,ACT,0.9900000095367432	CHEMBL186609,FN,ACT,0.009999999776482582	CHEMBL1645545,TP,ACT,0.7200000286102295	CHEMBL1830129,TN,INACT,0.03999999910593033	CHEMBL3652418,TP,ACT,1.0	CHEMBL3330338,TP,ACT,1.0	CHEMBL1946827,FP,INACT,0.9200000166893005	CHEMBL564763,FP,INACT,0.9900000095367432	CHEMBL2334190,TN,INACT,0.009999999776482582	CHEMBL2088315,FP,INACT,0.9900000095367432	CHEMBL2391877,FN,ACT,0.3799999952316284	CHEMBL3218134,TP,ACT,1.0	CHEMBL3218155,TP,ACT,0.949999988079071	CHEMBL2062881,FP,INACT,0.9900000095367432	CHEMBL2391874,TP,ACT,1.0	CHEMBL2023193,FN,ACT,0.009999999776482582	CHEMBL274548,TN,INACT,0.009999999776482582	CHEMBL1193327,TN,INACT,0.019999999552965164	CHEMBL3394494,TP,ACT,0.7900000214576721	CHEMBL79512,TN,INACT,0.10000000149011612	CHEMBL2402067,FN,ACT,0.009999999776482582	CHEMBL2204765,TP,ACT,0.800000011920929	CHEMBL1243214,TN,INACT,0.009999999776482582	CHEMBL3605360,TP,ACT,1.0	CHEMBL3127976,TP,ACT,0.7400000095367432	CHEMBL3402051,TN,INACT,0.5400000214576721	CHEMBL185776,FN,ACT,0.36000001430511475	CHEMBL1806759,TP,ACT,0.9800000190734863	CHEMBL192944,FP,INACT,0.9800000190734863	CHEMBL3651095,TN,INACT,0.23999999463558197	CHEMBL457038,FP,INACT,0.7699999809265137	CHEMBL1200904,FN,ACT,0.009999999776482582	CHEMBL365640,FN,ACT,0.41999998688697815	CHEMBL2058700,TP,ACT,1.0	CHEMBL3218132,TP,ACT,0.8399999737739563	CHEMBL497675,TP,ACT,0.9900000095367432	CHEMBL2158242,TP,ACT,1.0	CHEMBL1253613,TP,ACT,0.9800000190734863	CHEMBL903,FN,ACT,0.009999999776482582	CHEMBL3652411,TP,ACT,0.9900000095367432	CHEMBL3734767,FN,ACT,0.27000001072883606	CHEMBL220677,TN,INACT,0.009999999776482582	CHEMBL1946643,TN,INACT,0.019999999552965164	CHEMBL3394521,FN,ACT,0.12999999523162842	CHEMBL1257051,TP,ACT,0.9800000190734863	CHEMBL3133308,TN,INACT,0.009999999776482582	CHEMBL472569,FP,INACT,0.9399999976158142	CHEMBL2151663,TP,ACT,0.9300000071525574	CHEMBL201250,FN,ACT,0.07000000029802322	CHEMBL247833,TP,ACT,0.9300000071525574	CHEMBL1222279,FP,INACT,0.8700000047683716	CHEMBL3687960,TP,ACT,0.7900000214576721	CHEMBL7002,TN,INACT,0.03999999910593033	CHEMBL3219617,TN,INACT,0.0	CHEMBL537406,TN,INACT,0.3499999940395355	CHEMBL361190,FN,ACT,0.1599999964237213	CHEMBL2252341,TN,INACT,0.0	CHEMBL2151680,TN,INACT,0.019999999552965164	CHEMBL3787230,TN,INACT,0.6000000238418579	CHEMBL524447,TP,ACT,0.9200000166893005	CHEMBL188014,TP,ACT,0.8799999952316284	CHEMBL3415817,TP,ACT,1.0	CHEMBL3651598,FP,INACT,0.8600000143051147	CHEMBL3133246,TN,INACT,0.0	CHEMBL50,FN,ACT,0.14000000059604645	CHEMBL1950701,FN,ACT,0.0	CHEMBL2058409,FN,ACT,0.10000000149011612	CHEMBL123609,TP,ACT,0.9399999976158142	CHEMBL3219618,TP,ACT,0.9800000190734863	CHEMBL2058697,TP,ACT,1.0	CHEMBL567517,FP,INACT,0.9900000095367432	CHEMBL2177462,FP,INACT,0.8199999928474426	CHEMBL344277,TN,INACT,0.550000011920929	CHEMBL361025,FN,ACT,0.14000000059604645	CHEMBL1938479,TP,ACT,0.9599999785423279	CHEMBL3651108,FN,ACT,0.4300000071525574	CHEMBL16530,TN,INACT,0.019999999552965164	CHEMBL3219205,TP,ACT,1.0	CHEMBL394347,TN,INACT,0.0	CHEMBL3416433,TP,ACT,0.9900000095367432	CHEMBL3261213,TN,INACT,0.03999999910593033	CHEMBL3094020,FP,INACT,0.7699999809265137	CHEMBL269538,FN,ACT,0.44999998807907104	CHEMBL340952,FP,INACT,0.9200000166893005	CHEMBL472568,FP,INACT,1.0	CHEMBL3407583,TP,ACT,0.8799999952316284	CHEMBL3786420,TN,INACT,0.6600000262260437	CHEMBL513995,TN,INACT,0.03999999910593033	CHEMBL63456,TN,INACT,0.07000000029802322	CHEMBL1823807,TN,INACT,0.05000000074505806	CHEMBL2151681,FN,ACT,0.029999999329447746	CHEMBL1938475,FP,INACT,0.7400000095367432	CHEMBL3402199,TN,INACT,0.009999999776482582	CHEMBL488266,TN,INACT,0.0	CHEMBL461133,TP,ACT,0.9399999976158142	CHEMBL1070,TP,ACT,1.0	CHEMBL233347,TN,INACT,0.009999999776482582	CHEMBL339445,TN,INACT,0.019999999552965164	CHEMBL1835233,TN,INACT,0.33000001311302185	CHEMBL3218150,TP,ACT,1.0	CHEMBL1213778,FN,ACT,0.6899999976158142	CHEMBL3218149,TP,ACT,1.0	CHEMBL3652416,TP,ACT,0.8100000023841858	CHEMBL3605357,TP,ACT,0.8500000238418579	CHEMBL534467,FP,INACT,0.9900000095367432	CHEMBL462229,TN,INACT,0.05999999865889549	CHEMBL1255020,TP,ACT,0.8600000143051147	CHEMBL2430709,FP,INACT,0.9900000095367432	CHEMBL2437018,FN,ACT,0.25	CHEMBL1823808,FP,INACT,0.75	CHEMBL1272000,TN,INACT,0.009999999776482582	CHEMBL3799798,TP,ACT,1.0	CHEMBL3740394,TN,INACT,0.07000000029802322	CHEMBL600579,TN,INACT,0.14000000059604645	CHEMBL2376891,FP,INACT,0.800000011920929	CHEMBL2440567,TN,INACT,0.0	CHEMBL2440540,TN,INACT,0.0	CHEMBL239490,TN,INACT,0.009999999776482582	CHEMBL145044,TN,INACT,0.009999999776482582	CHEMBL1796448,FN,ACT,0.4399999976158142	CHEMBL3402189,FP,INACT,0.9300000071525574	CHEMBL3134359,TN,INACT,0.009999999776482582	CHEMBL3781885,TP,ACT,0.8999999761581421	CHEMBL1253700,FP,INACT,0.9900000095367432	CHEMBL3360732,FN,ACT,0.1599999964237213	CHEMBL1254850,FP,INACT,0.9900000095367432	CHEMBL2332173,TP,ACT,0.8100000023841858	CHEMBL2058698,TP,ACT,0.9900000095367432	CHEMBL3394516,FN,ACT,0.029999999329447746	CHEMBL3309738,TP,ACT,0.9700000286102295	CHEMBL3127968,FN,ACT,0.009999999776482582	CHEMBL151,TP,ACT,1.0	CHEMBL1235738,FP,INACT,0.9900000095367432	CHEMBL506,FP,INACT,0.9700000286102295	CHEMBL3799006,FN,ACT,0.019999999552965164	CHEMBL2376886,TN,INACT,0.2800000011920929	CHEMBL1253606,FN,ACT,0.6399999856948853	CHEMBL3218135,FN,ACT,0.6200000047683716	CHEMBL3605365,TN,INACT,0.009999999776482582	CHEMBL544166,TN,INACT,0.05999999865889549	CHEMBL31184,FN,ACT,0.10999999940395355	CHEMBL3134343,TN,INACT,0.0	CHEMBL828,TP,ACT,1.0	CHEMBL46601,TN,INACT,0.28999999165534973	CHEMBL1642678,FN,ACT,0.09000000357627869	CHEMBL511011,FP,INACT,0.9800000190734863	CHEMBL3763320,TP,ACT,0.9800000190734863	CHEMBL2312488,TN,INACT,0.009999999776482582	CHEMBL3134310,TN,INACT,0.009999999776482582	CHEMBL3585851,FN,ACT,0.10000000149011612	CHEMBL2206099,TN,INACT,0.009999999776482582	CHEMBL2151679,FN,ACT,0.6000000238418579	CHEMBL185138,TN,INACT,0.23000000417232513	CHEMBL1213912,TP,ACT,1.0	CHEMBL187265,TN,INACT,0.05000000074505806	CHEMBL3651140,TP,ACT,0.9900000095367432	CHEMBL3764166,TN,INACT,0.019999999552965164	CHEMBL2420791,TN,INACT,0.6299999952316284	CHEMBL2058704,TP,ACT,1.0	CHEMBL13633,TN,INACT,0.3799999952316284	CHEMBL2058424,TP,ACT,1.0	CHEMBL1198953,TP,ACT,0.9900000095367432	CHEMBL387669,TN,INACT,0.0	CHEMBL3261202,TN,INACT,0.009999999776482582	CHEMBL2333929,TP,ACT,0.9399999976158142	CHEMBL2151664,FN,ACT,0.019999999552965164	CHEMBL3134354,TP,ACT,0.9800000190734863	CHEMBL3585853,TP,ACT,1.0	CHEMBL3698281,TN,INACT,0.0	CHEMBL114900,TN,INACT,0.0	CHEMBL2440536,TN,INACT,0.0	CHEMBL1213968,TP,ACT,1.0	CHEMBL518184,FP,INACT,1.0	CHEMBL3319268,TP,ACT,0.9399999976158142	CHEMBL3401325,TN,INACT,0.0	CHEMBL46602,TN,INACT,0.0	CHEMBL3219203,TP,ACT,1.0	CHEMBL1243401,FN,ACT,0.12999999523162842	CHEMBL165,FN,ACT,0.15000000596046448	CHEMBL3655326,TN,INACT,0.5699999928474426	CHEMBL2334501,TN,INACT,0.0	CHEMBL575738,TN,INACT,0.0	CHEMBL2058699,TP,ACT,0.9900000095367432	CHEMBL1945157,TP,ACT,1.0	CHEMBL3394493,FN,ACT,0.05999999865889549	CHEMBL2206107,FN,ACT,0.6899999976158142	CHEMBL1830819,TN,INACT,0.3700000047683716	CHEMBL544715,TN,INACT,0.05000000074505806	CHEMBL126133,TN,INACT,0.009999999776482582	CHEMBL3655321,FN,ACT,0.009999999776482582	CHEMBL3134355,FP,INACT,0.9900000095367432	CHEMBL1830801,FP,INACT,0.949999988079071	CHEMBL341240,TN,INACT,0.23000000417232513	CHEMBL3218144,TP,ACT,1.0	CHEMBL519426,FN,ACT,0.36000001430511475	CHEMBL470307,FP,INACT,1.0	CHEMBL177305,TN,INACT,0.07000000029802322	CHEMBL1253357,TN,INACT,0.009999999776482582	CHEMBL3218167,TP,ACT,1.0	CHEMBL1222283,TN,INACT,0.0	CHEMBL2312981,TP,ACT,0.9800000190734863	CHEMBL491276,TN,INACT,0.0	CHEMBL3770053,FP,INACT,0.8100000023841858	CHEMBL1796451,TP,ACT,0.7900000214576721	CHEMBL3134363,FP,INACT,0.9599999785423279	CHEMBL3774476,FP,INACT,0.7799999713897705	CHEMBL257368,FP,INACT,0.9800000190734863	CHEMBL3394508,TN,INACT,0.019999999552965164	CHEMBL1830138,TN,INACT,0.03999999910593033	CHEMBL3218139,TP,ACT,0.9900000095367432	CHEMBL1254625,TP,ACT,0.9900000095367432	CHEMBL3415615,TP,ACT,0.9900000095367432	CHEMBL3780057,TP,ACT,0.9900000095367432	CHEMBL3651581,TN,INACT,0.03999999910593033	CHEMBL1080035,TP,ACT,1.0	CHEMBL339561,TN,INACT,0.009999999776482582	CHEMBL1797640,TP,ACT,0.9900000095367432	CHEMBL1945159,TP,ACT,1.0	CHEMBL960,FP,INACT,0.9399999976158142	CHEMBL488075,FN,ACT,0.23000000417232513	CHEMBL3651110,TP,ACT,0.9900000095367432	CHEMBL562142,TN,INACT,0.3700000047683716	CHEMBL230864,TP,ACT,0.9900000095367432	CHEMBL170087,TN,INACT,0.5600000023841858	CHEMBL145760,TN,INACT,0.0	CHEMBL3113647,FN,ACT,0.019999999552965164	CHEMBL129795,TN,INACT,0.5099999904632568	CHEMBL2426053,TN,INACT,0.3799999952316284	CHEMBL3652417,TP,ACT,1.0	CHEMBL249550,TN,INACT,0.18000000715255737	CHEMBL416055,TP,ACT,0.8100000023841858	CHEMBL3652427,FN,ACT,0.05000000074505806	CHEMBL1830818,TN,INACT,0.10999999940395355	CHEMBL2058706,TP,ACT,1.0	CHEMBL3781329,FN,ACT,0.28999999165534973	CHEMBL3655332,TN,INACT,0.009999999776482582	CHEMBL3736060,TN,INACT,0.1599999964237213	CHEMBL1795973,TN,INACT,0.5	CHEMBL3586595,TP,ACT,0.9900000095367432	CHEMBL231481,TN,INACT,0.38999998569488525	CHEMBL404505,FP,INACT,0.9900000095367432	CHEMBL1766620,TN,INACT,0.23000000417232513	CHEMBL1242936,TN,INACT,0.10000000149011612	CHEMBL1795972,TN,INACT,0.009999999776482582	CHEMBL1254552,TP,ACT,0.8799999952316284	CHEMBL239491,FP,INACT,0.9800000190734863	CHEMBL462549,FN,ACT,0.019999999552965164	CHEMBL186368,TP,ACT,0.8100000023841858	CHEMBL342916,TN,INACT,0.0	CHEMBL190268,TN,INACT,0.009999999776482582	CHEMBL1760717,TP,ACT,1.0	CHEMBL3781125,TP,ACT,0.9900000095367432	CHEMBL1269721,FP,INACT,1.0	CHEMBL3310027,TP,ACT,1.0	CHEMBL3651096,TN,INACT,0.019999999552965164	CHEMBL3605366,TP,ACT,0.8799999952316284	CHEMBL3415791,FP,INACT,0.9700000286102295	CHEMBL1253763,TP,ACT,0.8700000047683716	CHEMBL3415529,FP,INACT,0.9900000095367432	CHEMBL3191757,FN,ACT,0.4399999976158142	CHEMBL3309739,TP,ACT,1.0	CHEMBL3218163,TP,ACT,1.0	CHEMBL508175,TN,INACT,0.6399999856948853	CHEMBL3121788,TP,ACT,0.9800000190734863	CHEMBL18116,FN,ACT,0.009999999776482582	CHEMBL3781494,TP,ACT,0.9800000190734863	CHEMBL3219200,TP,ACT,0.9900000095367432	CHEMBL156861,TP,ACT,0.9900000095367432	CHEMBL3586577,FN,ACT,0.009999999776482582	CHEMBL1830146,TN,INACT,0.36000001430511475	CHEMBL1242938,TP,ACT,0.699999988079071	CHEMBL3770129,FP,INACT,1.0	CHEMBL1253283,TN,INACT,0.15000000596046448	CHEMBL512675,FP,INACT,0.9700000286102295	CHEMBL2417757,FN,ACT,0.4000000059604645	CHEMBL246809,TP,ACT,0.9599999785423279	CHEMBL125541,TP,ACT,0.9100000262260437	CHEMBL2437016,FN,ACT,0.1899999976158142	CHEMBL2437022,FN,ACT,0.12999999523162842	CHEMBL1797639,TN,INACT,0.18000000715255737	CHEMBL243058,TN,INACT,0.0	CHEMBL2058407,TN,INACT,0.38999998569488525	CHEMBL3310029,TP,ACT,0.8999999761581421	CHEMBL420,FN,ACT,0.05000000074505806	CHEMBL3134332,TN,INACT,0.009999999776482582	CHEMBL3415788,TP,ACT,0.9700000286102295	CHEMBL3402190,FP,INACT,0.9399999976158142	CHEMBL2158244,TP,ACT,1.0	CHEMBL577614,TN,INACT,0.0	CHEMBL244771,TN,INACT,0.0	CHEMBL233227,FN,ACT,0.3400000035762787	

