CNNModel CHEMBL4652 adam 0.001 30 128 0 0.8 False True
Number of active compounds :	146
Number of inactive compounds :	146
---------------------------------
Run id: CNNModel_CHEMBL4652_adam_0.001_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4652_adam_0.001_30_128_0.8_True/
---------------------------------
Training samples: 182
Validation samples: 57
--
Training Step: 1  | time: 0.751s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/182
[A[ATraining Step: 2  | total loss: [1m[32m0.62381[0m[0m | time: 1.367s
[2K
| Adam | epoch: 001 | loss: 0.62381 - acc: 0.4500 -- iter: 064/182
[A[ATraining Step: 3  | total loss: [1m[32m0.67992[0m[0m | time: 1.971s
[2K
| Adam | epoch: 001 | loss: 0.67992 - acc: 0.5165 -- iter: 096/182
[A[ATraining Step: 4  | total loss: [1m[32m0.67860[0m[0m | time: 2.575s
[2K
| Adam | epoch: 001 | loss: 0.67860 - acc: 0.6213 -- iter: 128/182
[A[ATraining Step: 5  | total loss: [1m[32m0.67679[0m[0m | time: 3.198s
[2K
| Adam | epoch: 001 | loss: 0.67679 - acc: 0.6022 -- iter: 160/182
[A[ATraining Step: 6  | total loss: [1m[32m0.80214[0m[0m | time: 4.665s
[2K
| Adam | epoch: 001 | loss: 0.80214 - acc: 0.4562 | val_loss: 0.72135 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 7  | total loss: [1m[32m0.75981[0m[0m | time: 0.441s
[2K
| Adam | epoch: 002 | loss: 0.75981 - acc: 0.4552 -- iter: 032/182
[A[ATraining Step: 8  | total loss: [1m[32m0.72794[0m[0m | time: 1.043s
[2K
| Adam | epoch: 002 | loss: 0.72794 - acc: 0.4548 -- iter: 064/182
[A[ATraining Step: 9  | total loss: [1m[32m0.70451[0m[0m | time: 1.644s
[2K
| Adam | epoch: 002 | loss: 0.70451 - acc: 0.5449 -- iter: 096/182
[A[ATraining Step: 10  | total loss: [1m[32m0.69690[0m[0m | time: 2.249s
[2K
| Adam | epoch: 002 | loss: 0.69690 - acc: 0.5693 -- iter: 128/182
[A[ATraining Step: 11  | total loss: [1m[32m0.69519[0m[0m | time: 2.864s
[2K
| Adam | epoch: 002 | loss: 0.69519 - acc: 0.5365 -- iter: 160/182
[A[ATraining Step: 12  | total loss: [1m[32m0.69283[0m[0m | time: 4.472s
[2K
| Adam | epoch: 002 | loss: 0.69283 - acc: 0.5904 | val_loss: 0.69606 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 13  | total loss: [1m[32m0.69292[0m[0m | time: 0.426s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5516 -- iter: 032/182
[A[ATraining Step: 14  | total loss: [1m[32m0.69371[0m[0m | time: 0.851s
[2K
| Adam | epoch: 003 | loss: 0.69371 - acc: 0.4933 -- iter: 064/182
[A[ATraining Step: 15  | total loss: [1m[32m0.69415[0m[0m | time: 1.474s
[2K
| Adam | epoch: 003 | loss: 0.69415 - acc: 0.4604 -- iter: 096/182
[A[ATraining Step: 16  | total loss: [1m[32m0.69344[0m[0m | time: 2.080s
[2K
| Adam | epoch: 003 | loss: 0.69344 - acc: 0.4987 -- iter: 128/182
[A[ATraining Step: 17  | total loss: [1m[32m0.69368[0m[0m | time: 2.669s
[2K
| Adam | epoch: 003 | loss: 0.69368 - acc: 0.4766 -- iter: 160/182
[A[ATraining Step: 18  | total loss: [1m[32m0.69318[0m[0m | time: 4.268s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.5064 | val_loss: 0.69511 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 19  | total loss: [1m[32m0.69264[0m[0m | time: 0.602s
[2K
| Adam | epoch: 004 | loss: 0.69264 - acc: 0.5459 -- iter: 032/182
[A[ATraining Step: 20  | total loss: [1m[32m0.69265[0m[0m | time: 1.025s
[2K
| Adam | epoch: 004 | loss: 0.69265 - acc: 0.5412 -- iter: 064/182
[A[ATraining Step: 21  | total loss: [1m[32m0.69221[0m[0m | time: 1.450s
[2K
| Adam | epoch: 004 | loss: 0.69221 - acc: 0.5707 -- iter: 096/182
[A[ATraining Step: 22  | total loss: [1m[32m0.69178[0m[0m | time: 2.054s
[2K
| Adam | epoch: 004 | loss: 0.69178 - acc: 0.5904 -- iter: 128/182
[A[ATraining Step: 23  | total loss: [1m[32m0.69213[0m[0m | time: 2.656s
[2K
| Adam | epoch: 004 | loss: 0.69213 - acc: 0.5642 -- iter: 160/182
[A[ATraining Step: 24  | total loss: [1m[32m0.69242[0m[0m | time: 4.256s
[2K
| Adam | epoch: 004 | loss: 0.69242 - acc: 0.5461 | val_loss: 0.69707 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 25  | total loss: [1m[32m0.69309[0m[0m | time: 0.612s
[2K
| Adam | epoch: 005 | loss: 0.69309 - acc: 0.5165 -- iter: 032/182
[A[ATraining Step: 26  | total loss: [1m[32m0.69250[0m[0m | time: 1.210s
[2K
| Adam | epoch: 005 | loss: 0.69250 - acc: 0.5369 -- iter: 064/182
[A[ATraining Step: 27  | total loss: [1m[32m0.69198[0m[0m | time: 1.639s
[2K
| Adam | epoch: 005 | loss: 0.69198 - acc: 0.5516 -- iter: 096/182
[A[ATraining Step: 28  | total loss: [1m[32m0.69166[0m[0m | time: 2.089s
[2K
| Adam | epoch: 005 | loss: 0.69166 - acc: 0.5614 -- iter: 128/182
[A[ATraining Step: 29  | total loss: [1m[32m0.69125[0m[0m | time: 2.685s
[2K
| Adam | epoch: 005 | loss: 0.69125 - acc: 0.5686 -- iter: 160/182
[A[ATraining Step: 30  | total loss: [1m[32m0.69116[0m[0m | time: 4.305s
[2K
| Adam | epoch: 005 | loss: 0.69116 - acc: 0.5671 | val_loss: 0.70042 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 31  | total loss: [1m[32m0.69228[0m[0m | time: 0.611s
[2K
| Adam | epoch: 006 | loss: 0.69228 - acc: 0.5372 -- iter: 032/182
[A[ATraining Step: 32  | total loss: [1m[32m0.69177[0m[0m | time: 1.204s
[2K
| Adam | epoch: 006 | loss: 0.69177 - acc: 0.5429 -- iter: 064/182
[A[ATraining Step: 33  | total loss: [1m[32m0.69044[0m[0m | time: 1.808s
[2K
| Adam | epoch: 006 | loss: 0.69044 - acc: 0.5678 -- iter: 096/182
[A[ATraining Step: 34  | total loss: [1m[32m0.69114[0m[0m | time: 2.265s
[2K
| Adam | epoch: 006 | loss: 0.69114 - acc: 0.5533 -- iter: 128/182
[A[ATraining Step: 35  | total loss: [1m[32m0.69228[0m[0m | time: 2.708s
[2K
| Adam | epoch: 006 | loss: 0.69228 - acc: 0.5326 -- iter: 160/182
[A[ATraining Step: 36  | total loss: [1m[32m0.69326[0m[0m | time: 4.310s
[2K
| Adam | epoch: 006 | loss: 0.69326 - acc: 0.5166 | val_loss: 0.70427 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 37  | total loss: [1m[32m0.69172[0m[0m | time: 0.599s
[2K
| Adam | epoch: 007 | loss: 0.69172 - acc: 0.5383 -- iter: 032/182
[A[ATraining Step: 38  | total loss: [1m[32m0.69162[0m[0m | time: 1.196s
[2K
| Adam | epoch: 007 | loss: 0.69162 - acc: 0.5369 -- iter: 064/182
[A[ATraining Step: 39  | total loss: [1m[32m0.69117[0m[0m | time: 1.784s
[2K
| Adam | epoch: 007 | loss: 0.69117 - acc: 0.5418 -- iter: 096/182
[A[ATraining Step: 40  | total loss: [1m[32m0.69068[0m[0m | time: 2.379s
[2K
| Adam | epoch: 007 | loss: 0.69068 - acc: 0.5457 -- iter: 128/182
[A[ATraining Step: 41  | total loss: [1m[32m0.69070[0m[0m | time: 2.803s
[2K
| Adam | epoch: 007 | loss: 0.69070 - acc: 0.5430 -- iter: 160/182
[A[ATraining Step: 42  | total loss: [1m[32m0.69207[0m[0m | time: 4.228s
[2K
| Adam | epoch: 007 | loss: 0.69207 - acc: 0.5271 | val_loss: 0.70855 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 43  | total loss: [1m[32m0.69334[0m[0m | time: 0.582s
[2K
| Adam | epoch: 008 | loss: 0.69334 - acc: 0.5143 -- iter: 032/182
[A[ATraining Step: 44  | total loss: [1m[32m0.69189[0m[0m | time: 1.180s
[2K
| Adam | epoch: 008 | loss: 0.69189 - acc: 0.5281 -- iter: 064/182
[A[ATraining Step: 45  | total loss: [1m[32m0.69112[0m[0m | time: 1.809s
[2K
| Adam | epoch: 008 | loss: 0.69112 - acc: 0.5339 -- iter: 096/182
[A[ATraining Step: 46  | total loss: [1m[32m0.69111[0m[0m | time: 2.410s
[2K
| Adam | epoch: 008 | loss: 0.69111 - acc: 0.5335 -- iter: 128/182
[A[ATraining Step: 47  | total loss: [1m[32m0.69094[0m[0m | time: 3.021s
[2K
| Adam | epoch: 008 | loss: 0.69094 - acc: 0.5331 -- iter: 160/182
[A[ATraining Step: 48  | total loss: [1m[32m0.69222[0m[0m | time: 4.468s
[2K
| Adam | epoch: 008 | loss: 0.69222 - acc: 0.5228 | val_loss: 0.71434 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 49  | total loss: [1m[32m0.69072[0m[0m | time: 0.423s
[2K
| Adam | epoch: 009 | loss: 0.69072 - acc: 0.5335 -- iter: 032/182
[A[ATraining Step: 50  | total loss: [1m[32m0.68935[0m[0m | time: 1.015s
[2K
| Adam | epoch: 009 | loss: 0.68935 - acc: 0.5424 -- iter: 064/182
[A[ATraining Step: 51  | total loss: [1m[32m0.68782[0m[0m | time: 1.616s
[2K
| Adam | epoch: 009 | loss: 0.68782 - acc: 0.5503 -- iter: 096/182
[A[ATraining Step: 52  | total loss: [1m[32m0.68447[0m[0m | time: 2.215s
[2K
| Adam | epoch: 009 | loss: 0.68447 - acc: 0.5662 -- iter: 128/182
[A[ATraining Step: 53  | total loss: [1m[32m0.68468[0m[0m | time: 2.848s
[2K
| Adam | epoch: 009 | loss: 0.68468 - acc: 0.5656 -- iter: 160/182
[A[ATraining Step: 54  | total loss: [1m[32m0.67782[0m[0m | time: 4.457s
[2K
| Adam | epoch: 009 | loss: 0.67782 - acc: 0.5833 | val_loss: 0.80467 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 55  | total loss: [1m[32m0.68463[0m[0m | time: 0.420s
[2K
| Adam | epoch: 010 | loss: 0.68463 - acc: 0.5714 -- iter: 032/182
[A[ATraining Step: 56  | total loss: [1m[32m0.69803[0m[0m | time: 0.828s
[2K
| Adam | epoch: 010 | loss: 0.69803 - acc: 0.5486 -- iter: 064/182
[A[ATraining Step: 57  | total loss: [1m[32m0.70481[0m[0m | time: 1.429s
[2K
| Adam | epoch: 010 | loss: 0.70481 - acc: 0.5293 -- iter: 096/182
[A[ATraining Step: 58  | total loss: [1m[32m0.70748[0m[0m | time: 2.025s
[2K
| Adam | epoch: 010 | loss: 0.70748 - acc: 0.5125 -- iter: 128/182
[A[ATraining Step: 59  | total loss: [1m[32m0.70615[0m[0m | time: 2.623s
[2K
| Adam | epoch: 010 | loss: 0.70615 - acc: 0.5108 -- iter: 160/182
[A[ATraining Step: 60  | total loss: [1m[32m0.70248[0m[0m | time: 4.227s
[2K
| Adam | epoch: 010 | loss: 0.70248 - acc: 0.5259 | val_loss: 0.70616 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 61  | total loss: [1m[32m0.70103[0m[0m | time: 0.593s
[2K
| Adam | epoch: 011 | loss: 0.70103 - acc: 0.5266 -- iter: 032/182
[A[ATraining Step: 62  | total loss: [1m[32m0.69874[0m[0m | time: 1.032s
[2K
| Adam | epoch: 011 | loss: 0.69874 - acc: 0.5393 -- iter: 064/182
[A[ATraining Step: 63  | total loss: [1m[32m0.69714[0m[0m | time: 1.456s
[2K
| Adam | epoch: 011 | loss: 0.69714 - acc: 0.5458 -- iter: 096/182
[A[ATraining Step: 64  | total loss: [1m[32m0.69589[0m[0m | time: 2.048s
[2K
| Adam | epoch: 011 | loss: 0.69589 - acc: 0.5515 -- iter: 128/182
[A[ATraining Step: 65  | total loss: [1m[32m0.69638[0m[0m | time: 2.660s
[2K
| Adam | epoch: 011 | loss: 0.69638 - acc: 0.5336 -- iter: 160/182
[A[ATraining Step: 66  | total loss: [1m[32m0.69527[0m[0m | time: 4.254s
[2K
| Adam | epoch: 011 | loss: 0.69527 - acc: 0.5409 | val_loss: 0.70422 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 67  | total loss: [1m[32m0.69400[0m[0m | time: 0.597s
[2K
| Adam | epoch: 012 | loss: 0.69400 - acc: 0.5510 -- iter: 032/182
[A[ATraining Step: 68  | total loss: [1m[32m0.69267[0m[0m | time: 1.196s
[2K
| Adam | epoch: 012 | loss: 0.69267 - acc: 0.5634 -- iter: 064/182
[A[ATraining Step: 69  | total loss: [1m[32m0.69335[0m[0m | time: 1.613s
[2K
| Adam | epoch: 012 | loss: 0.69335 - acc: 0.5487 -- iter: 096/182
[A[ATraining Step: 70  | total loss: [1m[32m0.69494[0m[0m | time: 2.060s
[2K
| Adam | epoch: 012 | loss: 0.69494 - acc: 0.5221 -- iter: 128/182
[A[ATraining Step: 71  | total loss: [1m[32m0.69633[0m[0m | time: 2.674s
[2K
| Adam | epoch: 012 | loss: 0.69633 - acc: 0.4989 -- iter: 160/182
[A[ATraining Step: 72  | total loss: [1m[32m0.69555[0m[0m | time: 4.278s
[2K
| Adam | epoch: 012 | loss: 0.69555 - acc: 0.5060 | val_loss: 0.70332 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 73  | total loss: [1m[32m0.69419[0m[0m | time: 0.613s
[2K
| Adam | epoch: 013 | loss: 0.69419 - acc: 0.5227 -- iter: 032/182
[A[ATraining Step: 74  | total loss: [1m[32m0.69323[0m[0m | time: 1.207s
[2K
| Adam | epoch: 013 | loss: 0.69323 - acc: 0.5340 -- iter: 064/182
[A[ATraining Step: 75  | total loss: [1m[32m0.69347[0m[0m | time: 1.792s
[2K
| Adam | epoch: 013 | loss: 0.69347 - acc: 0.5269 -- iter: 096/182
[A[ATraining Step: 76  | total loss: [1m[32m0.69302[0m[0m | time: 2.237s
[2K
| Adam | epoch: 013 | loss: 0.69302 - acc: 0.5307 -- iter: 128/182
[A[ATraining Step: 77  | total loss: [1m[32m0.69242[0m[0m | time: 2.662s
[2K
| Adam | epoch: 013 | loss: 0.69242 - acc: 0.5371 -- iter: 160/182
[A[ATraining Step: 78  | total loss: [1m[32m0.69191[0m[0m | time: 4.300s
[2K
| Adam | epoch: 013 | loss: 0.69191 - acc: 0.5427 | val_loss: 0.70396 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 79  | total loss: [1m[32m0.69298[0m[0m | time: 0.599s
[2K
| Adam | epoch: 014 | loss: 0.69298 - acc: 0.5254 -- iter: 032/182
[A[ATraining Step: 80  | total loss: [1m[32m0.69243[0m[0m | time: 1.186s
[2K
| Adam | epoch: 014 | loss: 0.69243 - acc: 0.5324 -- iter: 064/182
[A[ATraining Step: 81  | total loss: [1m[32m0.69212[0m[0m | time: 1.777s
[2K
| Adam | epoch: 014 | loss: 0.69212 - acc: 0.5354 -- iter: 096/182
[A[ATraining Step: 82  | total loss: [1m[32m0.69295[0m[0m | time: 2.366s
[2K
| Adam | epoch: 014 | loss: 0.69295 - acc: 0.5225 -- iter: 128/182
[A[ATraining Step: 83  | total loss: [1m[32m0.69368[0m[0m | time: 2.782s
[2K
| Adam | epoch: 014 | loss: 0.69368 - acc: 0.5109 -- iter: 160/182
[A[ATraining Step: 84  | total loss: [1m[32m0.69211[0m[0m | time: 4.210s
[2K
| Adam | epoch: 014 | loss: 0.69211 - acc: 0.5325 | val_loss: 0.70456 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 85  | total loss: [1m[32m0.69067[0m[0m | time: 0.599s
[2K
| Adam | epoch: 015 | loss: 0.69067 - acc: 0.5520 -- iter: 032/182
[A[ATraining Step: 86  | total loss: [1m[32m0.69007[0m[0m | time: 1.197s
[2K
| Adam | epoch: 015 | loss: 0.69007 - acc: 0.5593 -- iter: 064/182
[A[ATraining Step: 87  | total loss: [1m[32m0.69015[0m[0m | time: 1.783s
[2K
| Adam | epoch: 015 | loss: 0.69015 - acc: 0.5565 -- iter: 096/182
[A[ATraining Step: 88  | total loss: [1m[32m0.68979[0m[0m | time: 2.372s
[2K
| Adam | epoch: 015 | loss: 0.68979 - acc: 0.5602 -- iter: 128/182
[A[ATraining Step: 89  | total loss: [1m[32m0.69047[0m[0m | time: 2.976s
[2K
| Adam | epoch: 015 | loss: 0.69047 - acc: 0.5511 -- iter: 160/182
[A[ATraining Step: 90  | total loss: [1m[32m0.69026[0m[0m | time: 4.396s
[2K
| Adam | epoch: 015 | loss: 0.69026 - acc: 0.5522 | val_loss: 0.70852 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 91  | total loss: [1m[32m0.68938[0m[0m | time: 0.421s
[2K
| Adam | epoch: 016 | loss: 0.68938 - acc: 0.5606 -- iter: 032/182
[A[ATraining Step: 92  | total loss: [1m[32m0.68850[0m[0m | time: 1.016s
[2K
| Adam | epoch: 016 | loss: 0.68850 - acc: 0.5682 -- iter: 064/182
[A[ATraining Step: 93  | total loss: [1m[32m0.68905[0m[0m | time: 1.624s
[2K
| Adam | epoch: 016 | loss: 0.68905 - acc: 0.5614 -- iter: 096/182
[A[ATraining Step: 94  | total loss: [1m[32m0.68785[0m[0m | time: 2.246s
[2K
| Adam | epoch: 016 | loss: 0.68785 - acc: 0.5709 -- iter: 128/182
[A[ATraining Step: 95  | total loss: [1m[32m0.68776[0m[0m | time: 2.836s
[2K
| Adam | epoch: 016 | loss: 0.68776 - acc: 0.5700 -- iter: 160/182
[A[ATraining Step: 96  | total loss: [1m[32m0.68881[0m[0m | time: 4.437s
[2K
| Adam | epoch: 016 | loss: 0.68881 - acc: 0.5599 | val_loss: 0.71418 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 97  | total loss: [1m[32m0.68975[0m[0m | time: 0.414s
[2K
| Adam | epoch: 017 | loss: 0.68975 - acc: 0.5508 -- iter: 032/182
[A[ATraining Step: 98  | total loss: [1m[32m0.68767[0m[0m | time: 0.829s
[2K
| Adam | epoch: 017 | loss: 0.68767 - acc: 0.5639 -- iter: 064/182
[A[ATraining Step: 99  | total loss: [1m[32m0.68568[0m[0m | time: 1.428s
[2K
| Adam | epoch: 017 | loss: 0.68568 - acc: 0.5757 -- iter: 096/182
[A[ATraining Step: 100  | total loss: [1m[32m0.68701[0m[0m | time: 2.013s
[2K
| Adam | epoch: 017 | loss: 0.68701 - acc: 0.5650 -- iter: 128/182
[A[ATraining Step: 101  | total loss: [1m[32m0.68587[0m[0m | time: 2.604s
[2K
| Adam | epoch: 017 | loss: 0.68587 - acc: 0.5679 -- iter: 160/182
[A[ATraining Step: 102  | total loss: [1m[32m0.68767[0m[0m | time: 4.205s
[2K
| Adam | epoch: 017 | loss: 0.68767 - acc: 0.5580 | val_loss: 0.72546 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 103  | total loss: [1m[32m0.68913[0m[0m | time: 0.607s
[2K
| Adam | epoch: 018 | loss: 0.68913 - acc: 0.5490 -- iter: 032/182
[A[ATraining Step: 104  | total loss: [1m[32m0.68919[0m[0m | time: 1.025s
[2K
| Adam | epoch: 018 | loss: 0.68919 - acc: 0.5473 -- iter: 064/182
[A[ATraining Step: 105  | total loss: [1m[32m0.68529[0m[0m | time: 1.446s
[2K
| Adam | epoch: 018 | loss: 0.68529 - acc: 0.5653 -- iter: 096/182
[A[ATraining Step: 106  | total loss: [1m[32m0.68141[0m[0m | time: 2.042s
[2K
| Adam | epoch: 018 | loss: 0.68141 - acc: 0.5815 -- iter: 128/182
[A[ATraining Step: 107  | total loss: [1m[32m0.68185[0m[0m | time: 2.650s
[2K
| Adam | epoch: 018 | loss: 0.68185 - acc: 0.5764 -- iter: 160/182
[A[ATraining Step: 108  | total loss: [1m[32m0.68334[0m[0m | time: 4.252s
[2K
| Adam | epoch: 018 | loss: 0.68334 - acc: 0.5688 | val_loss: 0.73271 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 109  | total loss: [1m[32m0.68657[0m[0m | time: 0.617s
[2K
| Adam | epoch: 019 | loss: 0.68657 - acc: 0.5557 -- iter: 032/182
[A[ATraining Step: 110  | total loss: [1m[32m0.68477[0m[0m | time: 1.215s
[2K
| Adam | epoch: 019 | loss: 0.68477 - acc: 0.5563 -- iter: 064/182
[A[ATraining Step: 111  | total loss: [1m[32m0.68333[0m[0m | time: 1.639s
[2K
| Adam | epoch: 019 | loss: 0.68333 - acc: 0.5570 -- iter: 096/182
[A[ATraining Step: 112  | total loss: [1m[32m0.68065[0m[0m | time: 2.084s
[2K
| Adam | epoch: 019 | loss: 0.68065 - acc: 0.5604 -- iter: 128/182
[A[ATraining Step: 113  | total loss: [1m[32m0.67749[0m[0m | time: 2.692s
[2K
| Adam | epoch: 019 | loss: 0.67749 - acc: 0.5634 -- iter: 160/182
[A[ATraining Step: 114  | total loss: [1m[32m0.67285[0m[0m | time: 4.299s
[2K
| Adam | epoch: 019 | loss: 0.67285 - acc: 0.5696 | val_loss: 0.73422 - val_acc: 0.3509 -- iter: 182/182
--
Training Step: 115  | total loss: [1m[32m0.67290[0m[0m | time: 0.612s
[2K
| Adam | epoch: 020 | loss: 0.67290 - acc: 0.5626 -- iter: 032/182
[A[ATraining Step: 116  | total loss: [1m[32m0.67305[0m[0m | time: 1.212s
[2K
| Adam | epoch: 020 | loss: 0.67305 - acc: 0.5532 -- iter: 064/182
[A[ATraining Step: 117  | total loss: [1m[32m0.67129[0m[0m | time: 1.812s
[2K
| Adam | epoch: 020 | loss: 0.67129 - acc: 0.5417 -- iter: 096/182
[A[ATraining Step: 118  | total loss: [1m[32m0.66705[0m[0m | time: 2.223s
[2K
| Adam | epoch: 020 | loss: 0.66705 - acc: 0.5562 -- iter: 128/182
[A[ATraining Step: 119  | total loss: [1m[32m0.65482[0m[0m | time: 2.642s
[2K
| Adam | epoch: 020 | loss: 0.65482 - acc: 0.5643 -- iter: 160/182
[A[ATraining Step: 120  | total loss: [1m[32m0.63967[0m[0m | time: 4.234s
[2K
| Adam | epoch: 020 | loss: 0.63967 - acc: 0.5715 | val_loss: 0.65160 - val_acc: 0.5439 -- iter: 182/182
--
Training Step: 121  | total loss: [1m[32m0.63823[0m[0m | time: 0.586s
[2K
| Adam | epoch: 021 | loss: 0.63823 - acc: 0.5706 -- iter: 032/182
[A[ATraining Step: 122  | total loss: [1m[32m0.63354[0m[0m | time: 1.187s
[2K
| Adam | epoch: 021 | loss: 0.63354 - acc: 0.5854 -- iter: 064/182
[A[ATraining Step: 123  | total loss: [1m[32m0.62194[0m[0m | time: 1.780s
[2K
| Adam | epoch: 021 | loss: 0.62194 - acc: 0.6206 -- iter: 096/182
[A[ATraining Step: 124  | total loss: [1m[32m0.61025[0m[0m | time: 2.388s
[2K
| Adam | epoch: 021 | loss: 0.61025 - acc: 0.6492 -- iter: 128/182
[A[ATraining Step: 125  | total loss: [1m[32m0.59722[0m[0m | time: 2.803s
[2K
| Adam | epoch: 021 | loss: 0.59722 - acc: 0.6717 -- iter: 160/182
[A[ATraining Step: 126  | total loss: [1m[32m0.60161[0m[0m | time: 4.223s
[2K
| Adam | epoch: 021 | loss: 0.60161 - acc: 0.6682 | val_loss: 0.44988 - val_acc: 0.8246 -- iter: 182/182
--
Training Step: 127  | total loss: [1m[32m0.59250[0m[0m | time: 0.597s
[2K
| Adam | epoch: 022 | loss: 0.59250 - acc: 0.6878 -- iter: 032/182
[A[ATraining Step: 128  | total loss: [1m[32m0.57725[0m[0m | time: 1.192s
[2K
| Adam | epoch: 022 | loss: 0.57725 - acc: 0.6940 -- iter: 064/182
[A[ATraining Step: 129  | total loss: [1m[32m0.55635[0m[0m | time: 1.790s
[2K
| Adam | epoch: 022 | loss: 0.55635 - acc: 0.7121 -- iter: 096/182
[A[ATraining Step: 130  | total loss: [1m[32m0.52912[0m[0m | time: 2.431s
[2K
| Adam | epoch: 022 | loss: 0.52912 - acc: 0.7315 -- iter: 128/182
[A[ATraining Step: 131  | total loss: [1m[32m0.52027[0m[0m | time: 3.025s
[2K
| Adam | epoch: 022 | loss: 0.52027 - acc: 0.7365 -- iter: 160/182
[A[ATraining Step: 132  | total loss: [1m[32m0.50967[0m[0m | time: 4.450s
[2K
| Adam | epoch: 022 | loss: 0.50967 - acc: 0.7472 | val_loss: 0.39041 - val_acc: 0.8246 -- iter: 182/182
--
Training Step: 133  | total loss: [1m[32m0.48090[0m[0m | time: 0.421s
[2K
| Adam | epoch: 023 | loss: 0.48090 - acc: 0.7679 -- iter: 032/182
[A[ATraining Step: 134  | total loss: [1m[32m0.46245[0m[0m | time: 1.013s
[2K
| Adam | epoch: 023 | loss: 0.46245 - acc: 0.7775 -- iter: 064/182
[A[ATraining Step: 135  | total loss: [1m[32m0.44703[0m[0m | time: 1.615s
[2K
| Adam | epoch: 023 | loss: 0.44703 - acc: 0.7873 -- iter: 096/182
[A[ATraining Step: 136  | total loss: [1m[32m0.41150[0m[0m | time: 2.210s
[2K
| Adam | epoch: 023 | loss: 0.41150 - acc: 0.8054 -- iter: 128/182
[A[ATraining Step: 137  | total loss: [1m[32m0.39454[0m[0m | time: 2.807s
[2K
| Adam | epoch: 023 | loss: 0.39454 - acc: 0.8186 -- iter: 160/182
[A[ATraining Step: 138  | total loss: [1m[32m0.37963[0m[0m | time: 4.426s
[2K
| Adam | epoch: 023 | loss: 0.37963 - acc: 0.8243 | val_loss: 0.32281 - val_acc: 0.8246 -- iter: 182/182
--
Training Step: 139  | total loss: [1m[32m0.35404[0m[0m | time: 0.419s
[2K
| Adam | epoch: 024 | loss: 0.35404 - acc: 0.8356 -- iter: 032/182
[A[ATraining Step: 140  | total loss: [1m[32m0.34907[0m[0m | time: 0.842s
[2K
| Adam | epoch: 024 | loss: 0.34907 - acc: 0.8384 -- iter: 064/182
[A[ATraining Step: 141  | total loss: [1m[32m0.35426[0m[0m | time: 1.433s
[2K
| Adam | epoch: 024 | loss: 0.35426 - acc: 0.8364 -- iter: 096/182
[A[ATraining Step: 142  | total loss: [1m[32m0.34271[0m[0m | time: 2.054s
[2K
| Adam | epoch: 024 | loss: 0.34271 - acc: 0.8434 -- iter: 128/182
[A[ATraining Step: 143  | total loss: [1m[32m0.32709[0m[0m | time: 2.653s
[2K
| Adam | epoch: 024 | loss: 0.32709 - acc: 0.8559 -- iter: 160/182
[A[ATraining Step: 144  | total loss: [1m[32m0.31572[0m[0m | time: 4.259s
[2K
| Adam | epoch: 024 | loss: 0.31572 - acc: 0.8609 | val_loss: 0.35838 - val_acc: 0.7895 -- iter: 182/182
--
Training Step: 145  | total loss: [1m[32m0.31759[0m[0m | time: 0.601s
[2K
| Adam | epoch: 025 | loss: 0.31759 - acc: 0.8623 -- iter: 032/182
[A[ATraining Step: 146  | total loss: [1m[32m0.29699[0m[0m | time: 1.020s
[2K
| Adam | epoch: 025 | loss: 0.29699 - acc: 0.8730 -- iter: 064/182
[A[ATraining Step: 147  | total loss: [1m[32m0.27087[0m[0m | time: 1.437s
[2K
| Adam | epoch: 025 | loss: 0.27087 - acc: 0.8857 -- iter: 096/182
[A[ATraining Step: 148  | total loss: [1m[32m0.24713[0m[0m | time: 2.039s
[2K
| Adam | epoch: 025 | loss: 0.24713 - acc: 0.8971 -- iter: 128/182
[A[ATraining Step: 149  | total loss: [1m[32m0.22884[0m[0m | time: 2.628s
[2K
| Adam | epoch: 025 | loss: 0.22884 - acc: 0.9074 -- iter: 160/182
[A[ATraining Step: 150  | total loss: [1m[32m0.25417[0m[0m | time: 4.234s
[2K
| Adam | epoch: 025 | loss: 0.25417 - acc: 0.8979 | val_loss: 0.17288 - val_acc: 0.8947 -- iter: 182/182
--
Training Step: 151  | total loss: [1m[32m0.23736[0m[0m | time: 0.608s
[2K
| Adam | epoch: 026 | loss: 0.23736 - acc: 0.9050 -- iter: 032/182
[A[ATraining Step: 152  | total loss: [1m[32m0.21882[0m[0m | time: 1.221s
[2K
| Adam | epoch: 026 | loss: 0.21882 - acc: 0.9145 -- iter: 064/182
[A[ATraining Step: 153  | total loss: [1m[32m0.19922[0m[0m | time: 1.651s
[2K
| Adam | epoch: 026 | loss: 0.19922 - acc: 0.9230 -- iter: 096/182
[A[ATraining Step: 154  | total loss: [1m[32m0.18517[0m[0m | time: 2.084s
[2K
| Adam | epoch: 026 | loss: 0.18517 - acc: 0.9307 -- iter: 128/182
[A[ATraining Step: 155  | total loss: [1m[32m0.16885[0m[0m | time: 2.673s
[2K
| Adam | epoch: 026 | loss: 0.16885 - acc: 0.9377 -- iter: 160/182
[A[ATraining Step: 156  | total loss: [1m[32m0.15523[0m[0m | time: 4.276s
[2K
| Adam | epoch: 026 | loss: 0.15523 - acc: 0.9439 | val_loss: 0.12202 - val_acc: 0.9649 -- iter: 182/182
--
Training Step: 157  | total loss: [1m[32m0.15834[0m[0m | time: 0.595s
[2K
| Adam | epoch: 027 | loss: 0.15834 - acc: 0.9464 -- iter: 032/182
[A[ATraining Step: 158  | total loss: [1m[32m0.14421[0m[0m | time: 1.213s
[2K
| Adam | epoch: 027 | loss: 0.14421 - acc: 0.9517 -- iter: 064/182
[A[ATraining Step: 159  | total loss: [1m[32m0.13163[0m[0m | time: 1.808s
[2K
| Adam | epoch: 027 | loss: 0.13163 - acc: 0.9566 -- iter: 096/182
[A[ATraining Step: 160  | total loss: [1m[32m0.12640[0m[0m | time: 2.250s
[2K
| Adam | epoch: 027 | loss: 0.12640 - acc: 0.9578 -- iter: 128/182
[A[ATraining Step: 161  | total loss: [1m[32m0.11419[0m[0m | time: 2.675s
[2K
| Adam | epoch: 027 | loss: 0.11419 - acc: 0.9620 -- iter: 160/182
[A[ATraining Step: 162  | total loss: [1m[32m0.10326[0m[0m | time: 4.277s
[2K
| Adam | epoch: 027 | loss: 0.10326 - acc: 0.9658 | val_loss: 0.12175 - val_acc: 0.9825 -- iter: 182/182
--
Training Step: 163  | total loss: [1m[32m0.09436[0m[0m | time: 0.598s
[2K
| Adam | epoch: 028 | loss: 0.09436 - acc: 0.9692 -- iter: 032/182
[A[ATraining Step: 164  | total loss: [1m[32m0.10710[0m[0m | time: 1.199s
[2K
| Adam | epoch: 028 | loss: 0.10710 - acc: 0.9692 -- iter: 064/182
[A[ATraining Step: 165  | total loss: [1m[32m0.09722[0m[0m | time: 1.802s
[2K
| Adam | epoch: 028 | loss: 0.09722 - acc: 0.9723 -- iter: 096/182
[A[ATraining Step: 166  | total loss: [1m[32m0.08943[0m[0m | time: 2.405s
[2K
| Adam | epoch: 028 | loss: 0.08943 - acc: 0.9750 -- iter: 128/182
[A[ATraining Step: 167  | total loss: [1m[32m0.08139[0m[0m | time: 2.826s
[2K
| Adam | epoch: 028 | loss: 0.08139 - acc: 0.9775 -- iter: 160/182
[A[ATraining Step: 168  | total loss: [1m[32m0.07393[0m[0m | time: 4.253s
[2K
| Adam | epoch: 028 | loss: 0.07393 - acc: 0.9798 | val_loss: 0.12040 - val_acc: 0.9474 -- iter: 182/182
--
Training Step: 169  | total loss: [1m[32m0.06716[0m[0m | time: 0.605s
[2K
| Adam | epoch: 029 | loss: 0.06716 - acc: 0.9818 -- iter: 032/182
[A[ATraining Step: 170  | total loss: [1m[32m0.06191[0m[0m | time: 1.204s
[2K
| Adam | epoch: 029 | loss: 0.06191 - acc: 0.9836 -- iter: 064/182
[A[ATraining Step: 171  | total loss: [1m[32m0.08443[0m[0m | time: 1.811s
[2K
| Adam | epoch: 029 | loss: 0.08443 - acc: 0.9790 -- iter: 096/182
[A[ATraining Step: 172  | total loss: [1m[32m0.07673[0m[0m | time: 2.404s
[2K
| Adam | epoch: 029 | loss: 0.07673 - acc: 0.9811 -- iter: 128/182
[A[ATraining Step: 173  | total loss: [1m[32m0.06980[0m[0m | time: 2.997s
[2K
| Adam | epoch: 029 | loss: 0.06980 - acc: 0.9830 -- iter: 160/182
[A[ATraining Step: 174  | total loss: [1m[32m0.06317[0m[0m | time: 4.423s
[2K
| Adam | epoch: 029 | loss: 0.06317 - acc: 0.9847 | val_loss: 0.15474 - val_acc: 0.8947 -- iter: 182/182
--
Training Step: 175  | total loss: [1m[32m0.05721[0m[0m | time: 0.422s
[2K
| Adam | epoch: 030 | loss: 0.05721 - acc: 0.9862 -- iter: 032/182
[A[ATraining Step: 176  | total loss: [1m[32m0.05182[0m[0m | time: 1.028s
[2K
| Adam | epoch: 030 | loss: 0.05182 - acc: 0.9876 -- iter: 064/182
[A[ATraining Step: 177  | total loss: [1m[32m0.05302[0m[0m | time: 1.654s
[2K
| Adam | epoch: 030 | loss: 0.05302 - acc: 0.9857 -- iter: 096/182
[A[ATraining Step: 178  | total loss: [1m[32m0.04809[0m[0m | time: 2.251s
[2K
| Adam | epoch: 030 | loss: 0.04809 - acc: 0.9871 -- iter: 128/182
[A[ATraining Step: 179  | total loss: [1m[32m0.04373[0m[0m | time: 2.840s
[2K
| Adam | epoch: 030 | loss: 0.04373 - acc: 0.9884 -- iter: 160/182
[A[ATraining Step: 180  | total loss: [1m[32m0.04038[0m[0m | time: 4.474s
[2K
| Adam | epoch: 030 | loss: 0.04038 - acc: 0.9896 | val_loss: 0.21772 - val_acc: 0.9123 -- iter: 182/182
--
Validation AUC:0.995945945945946
Validation AUPRC:0.9978835384240785
Test AUC:0.9790123456790123
Test AUPRC:0.9804521112344701
BestTestF1Score	0.97	0.93	0.96	0.97	0.97	29	1	26	1	0.95
BestTestMCCScore	0.97	0.93	0.96	0.97	0.97	29	1	26	1	0.95
BestTestAccuracyScore	0.97	0.93	0.96	0.97	0.97	29	1	26	1	0.95
BestValidationF1Score	0.97	0.92	0.96	0.95	1.0	37	2	18	0	0.95
BestValidationMCC	0.97	0.92	0.96	0.95	1.0	37	2	18	0	0.95
BestValidationAccuracy	0.97	0.92	0.96	0.95	1.0	37	2	18	0	0.95
TestPredictions (Threshold:0.95)
CHEMBL1258999,TN,INACT,0.75	CHEMBL279520,TN,INACT,0.0	CHEMBL440236,TP,ACT,1.0	CHEMBL42411,TN,INACT,0.0	CHEMBL254499,TP,ACT,1.0	CHEMBL351183,TN,INACT,0.0	CHEMBL401091,TP,ACT,0.9900000095367432	CHEMBL400136,TP,ACT,1.0	CHEMBL252428,TP,ACT,1.0	CHEMBL472751,TP,ACT,1.0	CHEMBL1259241,TN,INACT,0.8500000238418579	CHEMBL516837,TP,ACT,0.9900000095367432	CHEMBL420359,TN,INACT,0.019999999552965164	CHEMBL9746,TN,INACT,0.0	CHEMBL251753,TP,ACT,0.9900000095367432	CHEMBL248715,TP,ACT,1.0	CHEMBL248908,TP,ACT,1.0	CHEMBL252617,TP,ACT,1.0	CHEMBL400709,TP,ACT,1.0	CHEMBL593861,TN,INACT,0.75	CHEMBL460470,TN,INACT,0.0	CHEMBL42586,TN,INACT,0.0	CHEMBL401130,TP,ACT,1.0	CHEMBL95727,TN,INACT,0.009999999776482582	CHEMBL250498,TP,ACT,1.0	CHEMBL297335,TN,INACT,0.0	CHEMBL250715,TP,ACT,1.0	CHEMBL461088,TN,INACT,0.0	CHEMBL249894,FP,INACT,1.0	CHEMBL251835,TP,ACT,1.0	CHEMBL44463,TN,INACT,0.0	CHEMBL39879,TN,INACT,0.0	CHEMBL401309,TP,ACT,1.0	CHEMBL279225,TN,INACT,0.019999999552965164	CHEMBL602474,TN,INACT,0.029999999329447746	CHEMBL44134,TN,INACT,0.07000000029802322	CHEMBL248907,TP,ACT,1.0	CHEMBL440233,TP,ACT,1.0	CHEMBL252002,TP,ACT,1.0	CHEMBL15936,TN,INACT,0.009999999776482582	CHEMBL1076622,FN,ACT,0.1599999964237213	CHEMBL42360,TN,INACT,0.0	CHEMBL248717,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.6100000143051147	CHEMBL253438,TP,ACT,1.0	CHEMBL460934,TP,ACT,0.9900000095367432	CHEMBL302038,TN,INACT,0.019999999552965164	CHEMBL209121,TN,INACT,0.0	CHEMBL254500,TP,ACT,1.0	CHEMBL400386,TP,ACT,0.9900000095367432	CHEMBL522135,TP,ACT,1.0	CHEMBL394642,TN,INACT,0.8199999928474426	CHEMBL2391353,TN,INACT,0.2199999988079071	CHEMBL472752,TP,ACT,1.0	CHEMBL470500,TP,ACT,1.0	CHEMBL424214,TN,INACT,0.0	CHEMBL249723,TP,ACT,1.0	

