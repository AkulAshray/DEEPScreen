ImageNetInceptionV2 CHEMBL3884 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	447
Number of inactive compounds :	298
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3884_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3884_adam_0.0001_15_0.6/
---------------------------------
Training samples: 473
Validation samples: 148
--
Training Step: 1  | time: 287.746s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/473
[A[ATraining Step: 2  | total loss: [1m[32m0.61831[0m[0m | time: 425.549s
[2K
| Adam | epoch: 001 | loss: 0.61831 - acc: 0.4781 -- iter: 064/473
[A[ATraining Step: 3  | total loss: [1m[32m0.54311[0m[0m | time: 637.843s
[2K
| Adam | epoch: 001 | loss: 0.54311 - acc: 0.7261 -- iter: 096/473
[A[ATraining Step: 4  | total loss: [1m[32m0.68179[0m[0m | time: 757.517s
[2K
| Adam | epoch: 001 | loss: 0.68179 - acc: 0.6737 -- iter: 128/473
[A[ATraining Step: 5  | total loss: [1m[32m0.66604[0m[0m | time: 906.784s
[2K
| Adam | epoch: 001 | loss: 0.66604 - acc: 0.6184 -- iter: 160/473
[A[ATraining Step: 6  | total loss: [1m[32m0.53295[0m[0m | time: 1025.987s
[2K
| Adam | epoch: 001 | loss: 0.53295 - acc: 0.7432 -- iter: 192/473
[A[ATraining Step: 7  | total loss: [1m[32m0.47518[0m[0m | time: 1197.150s
[2K
| Adam | epoch: 001 | loss: 0.47518 - acc: 0.7660 -- iter: 224/473
[A[ATraining Step: 8  | total loss: [1m[32m0.46038[0m[0m | time: 1383.758s
[2K
| Adam | epoch: 001 | loss: 0.46038 - acc: 0.8097 -- iter: 256/473
[A[ATraining Step: 9  | total loss: [1m[32m0.55679[0m[0m | time: 1485.173s
[2K
| Adam | epoch: 001 | loss: 0.55679 - acc: 0.7450 -- iter: 288/473
[A[ATraining Step: 10  | total loss: [1m[32m0.57874[0m[0m | time: 1555.921s
[2K
| Adam | epoch: 001 | loss: 0.57874 - acc: 0.7631 -- iter: 320/473
[A[ATraining Step: 11  | total loss: [1m[32m0.72642[0m[0m | time: 1609.165s
[2K
| Adam | epoch: 001 | loss: 0.72642 - acc: 0.6977 -- iter: 352/473
[A[ATraining Step: 12  | total loss: [1m[32m0.62356[0m[0m | time: 1636.486s
[2K
| Adam | epoch: 001 | loss: 0.62356 - acc: 0.7353 -- iter: 384/473
[A[ATraining Step: 13  | total loss: [1m[32m0.60885[0m[0m | time: 1678.139s
[2K
| Adam | epoch: 001 | loss: 0.60885 - acc: 0.7818 -- iter: 416/473
[A[ATraining Step: 14  | total loss: [1m[32m0.57947[0m[0m | time: 1704.523s
[2K
| Adam | epoch: 001 | loss: 0.57947 - acc: 0.7816 -- iter: 448/473
[A[ATraining Step: 15  | total loss: [1m[32m0.52781[0m[0m | time: 1751.145s
[2K
| Adam | epoch: 001 | loss: 0.52781 - acc: 0.7814 | val_loss: 0.94146 - val_acc: 0.3851 -- iter: 473/473
--
Training Step: 16  | total loss: [1m[32m0.43486[0m[0m | time: 19.301s
[2K
| Adam | epoch: 002 | loss: 0.43486 - acc: 0.8184 -- iter: 032/473
[A[ATraining Step: 17  | total loss: [1m[32m0.36790[0m[0m | time: 87.025s
[2K
| Adam | epoch: 002 | loss: 0.36790 - acc: 0.8838 -- iter: 064/473
[A[ATraining Step: 18  | total loss: [1m[32m0.36596[0m[0m | time: 122.036s
[2K
| Adam | epoch: 002 | loss: 0.36596 - acc: 0.8916 -- iter: 096/473
[A[ATraining Step: 19  | total loss: [1m[32m0.34421[0m[0m | time: 192.920s
[2K
| Adam | epoch: 002 | loss: 0.34421 - acc: 0.8965 -- iter: 128/473
[A[ATraining Step: 20  | total loss: [1m[32m0.36679[0m[0m | time: 218.893s
[2K
| Adam | epoch: 002 | loss: 0.36679 - acc: 0.8795 -- iter: 160/473
[A[ATraining Step: 21  | total loss: [1m[32m0.33436[0m[0m | time: 256.999s
[2K
| Adam | epoch: 002 | loss: 0.33436 - acc: 0.8878 -- iter: 192/473
[A[ATraining Step: 22  | total loss: [1m[32m0.31727[0m[0m | time: 313.365s
[2K
| Adam | epoch: 002 | loss: 0.31727 - acc: 0.8840 -- iter: 224/473
[A[ATraining Step: 23  | total loss: [1m[32m0.33752[0m[0m | time: 340.722s
[2K
| Adam | epoch: 002 | loss: 0.33752 - acc: 0.8904 -- iter: 256/473
[A[ATraining Step: 24  | total loss: [1m[32m0.37025[0m[0m | time: 359.978s
[2K
| Adam | epoch: 002 | loss: 0.37025 - acc: 0.8685 -- iter: 288/473
[A[ATraining Step: 25  | total loss: [1m[32m0.31917[0m[0m | time: 386.483s
[2K
| Adam | epoch: 002 | loss: 0.31917 - acc: 0.8959 -- iter: 320/473
[A[ATraining Step: 26  | total loss: [1m[32m0.28905[0m[0m | time: 401.667s
[2K
| Adam | epoch: 002 | loss: 0.28905 - acc: 0.8986 -- iter: 352/473
[A[ATraining Step: 27  | total loss: [1m[32m0.25677[0m[0m | time: 420.620s
[2K
| Adam | epoch: 002 | loss: 0.25677 - acc: 0.9166 -- iter: 384/473
[A[ATraining Step: 28  | total loss: [1m[32m0.27973[0m[0m | time: 438.901s
[2K
| Adam | epoch: 002 | loss: 0.27973 - acc: 0.9062 -- iter: 416/473
[A[ATraining Step: 29  | total loss: [1m[32m0.27587[0m[0m | time: 458.750s
[2K
| Adam | epoch: 002 | loss: 0.27587 - acc: 0.8986 -- iter: 448/473
[A[ATraining Step: 30  | total loss: [1m[32m0.26287[0m[0m | time: 493.800s
[2K
| Adam | epoch: 002 | loss: 0.26287 - acc: 0.9078 | val_loss: 0.95619 - val_acc: 0.3851 -- iter: 473/473
--
Training Step: 31  | total loss: [1m[32m0.27197[0m[0m | time: 10.226s
[2K
| Adam | epoch: 003 | loss: 0.27197 - acc: 0.9003 -- iter: 032/473
[A[ATraining Step: 32  | total loss: [1m[32m0.34711[0m[0m | time: 19.929s
[2K
| Adam | epoch: 003 | loss: 0.34711 - acc: 0.8777 -- iter: 064/473
[A[ATraining Step: 33  | total loss: [1m[32m0.29577[0m[0m | time: 41.133s
[2K
| Adam | epoch: 003 | loss: 0.29577 - acc: 0.8958 -- iter: 096/473
[A[ATraining Step: 34  | total loss: [1m[32m0.26518[0m[0m | time: 102.118s
[2K
| Adam | epoch: 003 | loss: 0.26518 - acc: 0.9114 -- iter: 128/473
[A[ATraining Step: 35  | total loss: [1m[32m0.23254[0m[0m | time: 120.983s
[2K
| Adam | epoch: 003 | loss: 0.23254 - acc: 0.9299 -- iter: 160/473
[A[ATraining Step: 36  | total loss: [1m[32m0.21145[0m[0m | time: 140.825s
[2K
| Adam | epoch: 003 | loss: 0.21145 - acc: 0.9443 -- iter: 192/473
[A[ATraining Step: 37  | total loss: [1m[32m0.19271[0m[0m | time: 172.905s
[2K
| Adam | epoch: 003 | loss: 0.19271 - acc: 0.9492 -- iter: 224/473
[A[ATraining Step: 38  | total loss: [1m[32m0.17622[0m[0m | time: 199.708s
[2K
| Adam | epoch: 003 | loss: 0.17622 - acc: 0.9591 -- iter: 256/473
[A[ATraining Step: 39  | total loss: [1m[32m0.15493[0m[0m | time: 212.839s
[2K
| Adam | epoch: 003 | loss: 0.15493 - acc: 0.9669 -- iter: 288/473
[A[ATraining Step: 40  | total loss: [1m[32m0.13842[0m[0m | time: 225.478s
[2K
| Adam | epoch: 003 | loss: 0.13842 - acc: 0.9731 -- iter: 320/473
[A[ATraining Step: 41  | total loss: [1m[32m0.12650[0m[0m | time: 249.241s
[2K
| Adam | epoch: 003 | loss: 0.12650 - acc: 0.9781 -- iter: 352/473
[A[ATraining Step: 42  | total loss: [1m[32m0.11105[0m[0m | time: 278.192s
[2K
| Adam | epoch: 003 | loss: 0.11105 - acc: 0.9820 -- iter: 384/473
[A[ATraining Step: 43  | total loss: [1m[32m0.10226[0m[0m | time: 305.652s
[2K
| Adam | epoch: 003 | loss: 0.10226 - acc: 0.9797 -- iter: 416/473
[A[ATraining Step: 44  | total loss: [1m[32m0.09087[0m[0m | time: 318.778s
[2K
| Adam | epoch: 003 | loss: 0.09087 - acc: 0.9832 -- iter: 448/473
[A[ATraining Step: 45  | total loss: [1m[32m0.08218[0m[0m | time: 341.964s
[2K
| Adam | epoch: 003 | loss: 0.08218 - acc: 0.9861 | val_loss: 1.60966 - val_acc: 0.3851 -- iter: 473/473
--
Training Step: 46  | total loss: [1m[32m0.07877[0m[0m | time: 14.651s
[2K
| Adam | epoch: 004 | loss: 0.07877 - acc: 0.9884 -- iter: 032/473
[A[ATraining Step: 47  | total loss: [1m[32m0.07798[0m[0m | time: 27.880s
[2K
| Adam | epoch: 004 | loss: 0.07798 - acc: 0.9852 -- iter: 064/473
[A[ATraining Step: 48  | total loss: [1m[32m0.29689[0m[0m | time: 54.965s
[2K
| Adam | epoch: 004 | loss: 0.29689 - acc: 0.9490 -- iter: 096/473
[A[ATraining Step: 49  | total loss: [1m[32m0.25371[0m[0m | time: 81.041s
[2K
| Adam | epoch: 004 | loss: 0.25371 - acc: 0.9570 -- iter: 128/473
[A[ATraining Step: 50  | total loss: [1m[32m0.22356[0m[0m | time: 98.408s
[2K
| Adam | epoch: 004 | loss: 0.22356 - acc: 0.9589 -- iter: 160/473
[A[ATraining Step: 51  | total loss: [1m[32m0.19377[0m[0m | time: 119.478s
[2K
| Adam | epoch: 004 | loss: 0.19377 - acc: 0.9651 -- iter: 192/473
[A[ATraining Step: 52  | total loss: [1m[32m0.16890[0m[0m | time: 132.179s
[2K
| Adam | epoch: 004 | loss: 0.16890 - acc: 0.9704 -- iter: 224/473
[A[ATraining Step: 53  | total loss: [1m[32m0.14602[0m[0m | time: 143.187s
[2K
| Adam | epoch: 004 | loss: 0.14602 - acc: 0.9747 -- iter: 256/473
[A[ATraining Step: 54  | total loss: [1m[32m0.12862[0m[0m | time: 154.127s
[2K
| Adam | epoch: 004 | loss: 0.12862 - acc: 0.9784 -- iter: 288/473
[A[ATraining Step: 55  | total loss: [1m[32m0.11710[0m[0m | time: 168.112s
[2K
| Adam | epoch: 004 | loss: 0.11710 - acc: 0.9770 -- iter: 320/473
[A[ATraining Step: 56  | total loss: [1m[32m0.10294[0m[0m | time: 182.247s
[2K
| Adam | epoch: 004 | loss: 0.10294 - acc: 0.9803 -- iter: 352/473
[A[ATraining Step: 57  | total loss: [1m[32m0.10413[0m[0m | time: 212.980s
[2K
| Adam | epoch: 004 | loss: 0.10413 - acc: 0.9787 -- iter: 384/473
[A[ATraining Step: 58  | total loss: [1m[32m0.09650[0m[0m | time: 231.865s
[2K
| Adam | epoch: 004 | loss: 0.09650 - acc: 0.9816 -- iter: 416/473
[A[ATraining Step: 59  | total loss: [1m[32m0.08516[0m[0m | time: 245.525s
[2K
| Adam | epoch: 004 | loss: 0.08516 - acc: 0.9840 -- iter: 448/473
[A[ATraining Step: 60  | total loss: [1m[32m0.07561[0m[0m | time: 270.376s
[2K
| Adam | epoch: 004 | loss: 0.07561 - acc: 0.9862 | val_loss: 0.53353 - val_acc: 0.7973 -- iter: 473/473
--
Training Step: 61  | total loss: [1m[32m0.06894[0m[0m | time: 19.692s
[2K
| Adam | epoch: 005 | loss: 0.06894 - acc: 0.9880 -- iter: 032/473
[A[ATraining Step: 62  | total loss: [1m[32m0.06263[0m[0m | time: 38.591s
[2K
| Adam | epoch: 005 | loss: 0.06263 - acc: 0.9895 -- iter: 064/473
[A[ATraining Step: 63  | total loss: [1m[32m0.05588[0m[0m | time: 45.776s
[2K
| Adam | epoch: 005 | loss: 0.05588 - acc: 0.9908 -- iter: 096/473
[A[ATraining Step: 64  | total loss: [1m[32m0.20193[0m[0m | time: 52.924s
[2K
| Adam | epoch: 005 | loss: 0.20193 - acc: 0.9720 -- iter: 128/473
[A[ATraining Step: 65  | total loss: [1m[32m0.17787[0m[0m | time: 63.413s
[2K
| Adam | epoch: 005 | loss: 0.17787 - acc: 0.9754 -- iter: 160/473
[A[ATraining Step: 66  | total loss: [1m[32m0.15817[0m[0m | time: 88.255s
[2K
| Adam | epoch: 005 | loss: 0.15817 - acc: 0.9784 -- iter: 192/473
[A[ATraining Step: 67  | total loss: [1m[32m0.14072[0m[0m | time: 105.851s
[2K
| Adam | epoch: 005 | loss: 0.14072 - acc: 0.9810 -- iter: 224/473
[A[ATraining Step: 68  | total loss: [1m[32m0.12483[0m[0m | time: 124.770s
[2K
| Adam | epoch: 005 | loss: 0.12483 - acc: 0.9833 -- iter: 256/473
[A[ATraining Step: 69  | total loss: [1m[32m0.11418[0m[0m | time: 142.023s
[2K
| Adam | epoch: 005 | loss: 0.11418 - acc: 0.9852 -- iter: 288/473
[A[ATraining Step: 70  | total loss: [1m[32m0.10184[0m[0m | time: 156.664s
[2K
| Adam | epoch: 005 | loss: 0.10184 - acc: 0.9869 -- iter: 320/473
[A[ATraining Step: 71  | total loss: [1m[32m0.09135[0m[0m | time: 169.701s
[2K
| Adam | epoch: 005 | loss: 0.09135 - acc: 0.9884 -- iter: 352/473
[A[ATraining Step: 72  | total loss: [1m[32m0.08403[0m[0m | time: 193.315s
[2K
| Adam | epoch: 005 | loss: 0.08403 - acc: 0.9897 -- iter: 384/473
[A[ATraining Step: 73  | total loss: [1m[32m0.07678[0m[0m | time: 215.917s
[2K
| Adam | epoch: 005 | loss: 0.07678 - acc: 0.9909 -- iter: 416/473
[A[ATraining Step: 74  | total loss: [1m[32m0.09065[0m[0m | time: 234.385s
[2K
| Adam | epoch: 005 | loss: 0.09065 - acc: 0.9884 -- iter: 448/473
[A[ATraining Step: 75  | total loss: [1m[32m0.09313[0m[0m | time: 261.301s
[2K
| Adam | epoch: 005 | loss: 0.09313 - acc: 0.9863 | val_loss: 0.38162 - val_acc: 0.8581 -- iter: 473/473
--
Training Step: 76  | total loss: [1m[32m0.08427[0m[0m | time: 12.403s
[2K
| Adam | epoch: 006 | loss: 0.08427 - acc: 0.9878 -- iter: 032/473
[A[ATraining Step: 77  | total loss: [1m[32m0.07595[0m[0m | time: 28.443s
[2K
| Adam | epoch: 006 | loss: 0.07595 - acc: 0.9891 -- iter: 064/473
[A[ATraining Step: 78  | total loss: [1m[32m0.06899[0m[0m | time: 41.054s
[2K
| Adam | epoch: 006 | loss: 0.06899 - acc: 0.9902 -- iter: 096/473
[A[ATraining Step: 79  | total loss: [1m[32m0.06239[0m[0m | time: 51.133s
[2K
| Adam | epoch: 006 | loss: 0.06239 - acc: 0.9912 -- iter: 128/473
[A[ATraining Step: 80  | total loss: [1m[32m0.06290[0m[0m | time: 60.677s
[2K
| Adam | epoch: 006 | loss: 0.06290 - acc: 0.9880 -- iter: 160/473
[A[ATraining Step: 81  | total loss: [1m[32m0.05774[0m[0m | time: 73.351s
[2K
| Adam | epoch: 006 | loss: 0.05774 - acc: 0.9892 -- iter: 192/473
[A[ATraining Step: 82  | total loss: [1m[32m0.05273[0m[0m | time: 86.043s
[2K
| Adam | epoch: 006 | loss: 0.05273 - acc: 0.9903 -- iter: 224/473
[A[ATraining Step: 83  | total loss: [1m[32m0.05079[0m[0m | time: 97.975s
[2K
| Adam | epoch: 006 | loss: 0.05079 - acc: 0.9913 -- iter: 256/473
[A[ATraining Step: 84  | total loss: [1m[32m0.07015[0m[0m | time: 106.458s
[2K
| Adam | epoch: 006 | loss: 0.07015 - acc: 0.9890 -- iter: 288/473
[A[ATraining Step: 85  | total loss: [1m[32m0.06486[0m[0m | time: 115.016s
[2K
| Adam | epoch: 006 | loss: 0.06486 - acc: 0.9901 -- iter: 320/473
[A[ATraining Step: 86  | total loss: [1m[32m0.05905[0m[0m | time: 125.844s
[2K
| Adam | epoch: 006 | loss: 0.05905 - acc: 0.9911 -- iter: 352/473
[A[ATraining Step: 87  | total loss: [1m[32m0.05423[0m[0m | time: 138.796s
[2K
| Adam | epoch: 006 | loss: 0.05423 - acc: 0.9920 -- iter: 384/473
[A[ATraining Step: 88  | total loss: [1m[32m0.05002[0m[0m | time: 151.575s
[2K
| Adam | epoch: 006 | loss: 0.05002 - acc: 0.9928 -- iter: 416/473
[A[ATraining Step: 89  | total loss: [1m[32m0.04596[0m[0m | time: 164.612s
[2K
| Adam | epoch: 006 | loss: 0.04596 - acc: 0.9935 -- iter: 448/473
[A[ATraining Step: 90  | total loss: [1m[32m0.04183[0m[0m | time: 188.343s
[2K
| Adam | epoch: 006 | loss: 0.04183 - acc: 0.9942 | val_loss: 0.44741 - val_acc: 0.8514 -- iter: 473/473
--
Training Step: 91  | total loss: [1m[32m0.03994[0m[0m | time: 12.367s
[2K
| Adam | epoch: 007 | loss: 0.03994 - acc: 0.9948 -- iter: 032/473
[A[ATraining Step: 92  | total loss: [1m[32m0.04155[0m[0m | time: 25.518s
[2K
| Adam | epoch: 007 | loss: 0.04155 - acc: 0.9953 -- iter: 064/473
[A[ATraining Step: 93  | total loss: [1m[32m0.03841[0m[0m | time: 34.209s
[2K
| Adam | epoch: 007 | loss: 0.03841 - acc: 0.9957 -- iter: 096/473
[A[ATraining Step: 94  | total loss: [1m[32m0.03513[0m[0m | time: 43.072s
[2K
| Adam | epoch: 007 | loss: 0.03513 - acc: 0.9962 -- iter: 128/473
[A[ATraining Step: 95  | total loss: [1m[32m0.03257[0m[0m | time: 50.021s
[2K
| Adam | epoch: 007 | loss: 0.03257 - acc: 0.9966 -- iter: 160/473
[A[ATraining Step: 96  | total loss: [1m[32m0.05286[0m[0m | time: 60.063s
[2K
| Adam | epoch: 007 | loss: 0.05286 - acc: 0.9929 -- iter: 192/473
[A[ATraining Step: 97  | total loss: [1m[32m0.04806[0m[0m | time: 72.879s
[2K
| Adam | epoch: 007 | loss: 0.04806 - acc: 0.9936 -- iter: 224/473
[A[ATraining Step: 98  | total loss: [1m[32m0.04600[0m[0m | time: 85.384s
[2K
| Adam | epoch: 007 | loss: 0.04600 - acc: 0.9943 -- iter: 256/473
[A[ATraining Step: 99  | total loss: [1m[32m0.04191[0m[0m | time: 97.745s
[2K
| Adam | epoch: 007 | loss: 0.04191 - acc: 0.9948 -- iter: 288/473
[A[ATraining Step: 100  | total loss: [1m[32m0.04169[0m[0m | time: 111.201s
[2K
| Adam | epoch: 007 | loss: 0.04169 - acc: 0.9922 -- iter: 320/473
[A[ATraining Step: 101  | total loss: [1m[32m0.03793[0m[0m | time: 123.889s
[2K
| Adam | epoch: 007 | loss: 0.03793 - acc: 0.9930 -- iter: 352/473
[A[ATraining Step: 102  | total loss: [1m[32m0.03453[0m[0m | time: 136.735s
[2K
| Adam | epoch: 007 | loss: 0.03453 - acc: 0.9937 -- iter: 384/473
[A[ATraining Step: 103  | total loss: [1m[32m0.03142[0m[0m | time: 149.977s
[2K
| Adam | epoch: 007 | loss: 0.03142 - acc: 0.9943 -- iter: 416/473
[A[ATraining Step: 104  | total loss: [1m[32m0.02984[0m[0m | time: 164.351s
[2K
| Adam | epoch: 007 | loss: 0.02984 - acc: 0.9949 -- iter: 448/473
[A[ATraining Step: 105  | total loss: [1m[32m0.02727[0m[0m | time: 184.359s
[2K
| Adam | epoch: 007 | loss: 0.02727 - acc: 0.9954 | val_loss: 0.38691 - val_acc: 0.8851 -- iter: 473/473
--
Training Step: 106  | total loss: [1m[32m0.02508[0m[0m | time: 12.133s
[2K
| Adam | epoch: 008 | loss: 0.02508 - acc: 0.9959 -- iter: 032/473
[A[ATraining Step: 107  | total loss: [1m[32m0.04009[0m[0m | time: 33.865s
[2K
| Adam | epoch: 008 | loss: 0.04009 - acc: 0.9932 -- iter: 064/473
[A[ATraining Step: 108  | total loss: [1m[32m0.03727[0m[0m | time: 46.153s
[2K
| Adam | epoch: 008 | loss: 0.03727 - acc: 0.9938 -- iter: 096/473
[A[ATraining Step: 109  | total loss: [1m[32m0.06364[0m[0m | time: 63.464s
[2K
| Adam | epoch: 008 | loss: 0.06364 - acc: 0.9913 -- iter: 128/473
[A[ATraining Step: 110  | total loss: [1m[32m0.05771[0m[0m | time: 84.474s
[2K
| Adam | epoch: 008 | loss: 0.05771 - acc: 0.9922 -- iter: 160/473
[A[ATraining Step: 111  | total loss: [1m[32m0.05218[0m[0m | time: 95.016s
[2K
| Adam | epoch: 008 | loss: 0.05218 - acc: 0.9930 -- iter: 192/473
[A[ATraining Step: 112  | total loss: [1m[32m0.12952[0m[0m | time: 105.585s
[2K
| Adam | epoch: 008 | loss: 0.12952 - acc: 0.9817 -- iter: 224/473
[A[ATraining Step: 113  | total loss: [1m[32m0.13357[0m[0m | time: 118.038s
[2K
| Adam | epoch: 008 | loss: 0.13357 - acc: 0.9795 -- iter: 256/473
[A[ATraining Step: 114  | total loss: [1m[32m0.12057[0m[0m | time: 129.482s
[2K
| Adam | epoch: 008 | loss: 0.12057 - acc: 0.9816 -- iter: 288/473
[A[ATraining Step: 115  | total loss: [1m[32m0.10911[0m[0m | time: 138.083s
[2K
| Adam | epoch: 008 | loss: 0.10911 - acc: 0.9834 -- iter: 320/473
[A[ATraining Step: 116  | total loss: [1m[32m0.09992[0m[0m | time: 146.557s
[2K
| Adam | epoch: 008 | loss: 0.09992 - acc: 0.9851 -- iter: 352/473
[A[ATraining Step: 117  | total loss: [1m[32m0.09109[0m[0m | time: 158.530s
[2K
| Adam | epoch: 008 | loss: 0.09109 - acc: 0.9866 -- iter: 384/473
[A[ATraining Step: 118  | total loss: [1m[32m0.08774[0m[0m | time: 170.984s
[2K
| Adam | epoch: 008 | loss: 0.08774 - acc: 0.9848 -- iter: 416/473
[A[ATraining Step: 119  | total loss: [1m[32m0.09397[0m[0m | time: 184.902s
[2K
| Adam | epoch: 008 | loss: 0.09397 - acc: 0.9832 -- iter: 448/473
[A[ATraining Step: 120  | total loss: [1m[32m0.08638[0m[0m | time: 207.654s
[2K
| Adam | epoch: 008 | loss: 0.08638 - acc: 0.9849 | val_loss: 3.29046 - val_acc: 0.6419 -- iter: 473/473
--
Training Step: 121  | total loss: [1m[32m0.08008[0m[0m | time: 12.778s
[2K
| Adam | epoch: 009 | loss: 0.08008 - acc: 0.9864 -- iter: 032/473
[A[ATraining Step: 122  | total loss: [1m[32m0.07329[0m[0m | time: 25.122s
[2K
| Adam | epoch: 009 | loss: 0.07329 - acc: 0.9877 -- iter: 064/473
[A[ATraining Step: 123  | total loss: [1m[32m0.06976[0m[0m | time: 38.245s
[2K
| Adam | epoch: 009 | loss: 0.06976 - acc: 0.9890 -- iter: 096/473
[A[ATraining Step: 124  | total loss: [1m[32m0.06612[0m[0m | time: 46.589s
[2K
| Adam | epoch: 009 | loss: 0.06612 - acc: 0.9901 -- iter: 128/473
[A[ATraining Step: 125  | total loss: [1m[32m0.07654[0m[0m | time: 55.278s
[2K
| Adam | epoch: 009 | loss: 0.07654 - acc: 0.9879 -- iter: 160/473
[A[ATraining Step: 126  | total loss: [1m[32m0.07689[0m[0m | time: 65.088s
[2K
| Adam | epoch: 009 | loss: 0.07689 - acc: 0.9860 -- iter: 192/473
[A[ATraining Step: 127  | total loss: [1m[32m0.07078[0m[0m | time: 74.969s
[2K
| Adam | epoch: 009 | loss: 0.07078 - acc: 0.9874 -- iter: 224/473
[A[ATraining Step: 128  | total loss: [1m[32m0.06467[0m[0m | time: 85.562s
[2K
| Adam | epoch: 009 | loss: 0.06467 - acc: 0.9887 -- iter: 256/473
[A[ATraining Step: 129  | total loss: [1m[32m0.05903[0m[0m | time: 98.531s
[2K
| Adam | epoch: 009 | loss: 0.05903 - acc: 0.9898 -- iter: 288/473
[A[ATraining Step: 130  | total loss: [1m[32m0.05386[0m[0m | time: 111.310s
[2K
| Adam | epoch: 009 | loss: 0.05386 - acc: 0.9908 -- iter: 320/473
[A[ATraining Step: 131  | total loss: [1m[32m0.04960[0m[0m | time: 123.902s
[2K
| Adam | epoch: 009 | loss: 0.04960 - acc: 0.9917 -- iter: 352/473
[A[ATraining Step: 132  | total loss: [1m[32m0.04851[0m[0m | time: 137.134s
[2K
| Adam | epoch: 009 | loss: 0.04851 - acc: 0.9926 -- iter: 384/473
[A[ATraining Step: 133  | total loss: [1m[32m0.04421[0m[0m | time: 150.162s
[2K
| Adam | epoch: 009 | loss: 0.04421 - acc: 0.9933 -- iter: 416/473
[A[ATraining Step: 134  | total loss: [1m[32m0.04150[0m[0m | time: 163.147s
[2K
| Adam | epoch: 009 | loss: 0.04150 - acc: 0.9940 -- iter: 448/473
[A[ATraining Step: 135  | total loss: [1m[32m0.03794[0m[0m | time: 186.824s
[2K
| Adam | epoch: 009 | loss: 0.03794 - acc: 0.9946 | val_loss: 0.56523 - val_acc: 0.7770 -- iter: 473/473
--
Training Step: 136  | total loss: [1m[32m0.03503[0m[0m | time: 15.138s
[2K
| Adam | epoch: 010 | loss: 0.03503 - acc: 0.9951 -- iter: 032/473
[A[ATraining Step: 137  | total loss: [1m[32m0.03295[0m[0m | time: 27.023s
[2K
| Adam | epoch: 010 | loss: 0.03295 - acc: 0.9956 -- iter: 064/473
[A[ATraining Step: 138  | total loss: [1m[32m0.03184[0m[0m | time: 39.361s
[2K
| Adam | epoch: 010 | loss: 0.03184 - acc: 0.9961 -- iter: 096/473
[A[ATraining Step: 139  | total loss: [1m[32m0.03012[0m[0m | time: 53.154s
[2K
| Adam | epoch: 010 | loss: 0.03012 - acc: 0.9964 -- iter: 128/473
[A[ATraining Step: 140  | total loss: [1m[32m0.02816[0m[0m | time: 64.989s
[2K
| Adam | epoch: 010 | loss: 0.02816 - acc: 0.9968 -- iter: 160/473
[A[ATraining Step: 141  | total loss: [1m[32m0.02981[0m[0m | time: 77.429s
[2K
| Adam | epoch: 010 | loss: 0.02981 - acc: 0.9940 -- iter: 192/473
[A[ATraining Step: 142  | total loss: [1m[32m0.02726[0m[0m | time: 90.024s
[2K
| Adam | epoch: 010 | loss: 0.02726 - acc: 0.9946 -- iter: 224/473
[A[ATraining Step: 143  | total loss: [1m[32m0.02574[0m[0m | time: 100.658s
[2K
| Adam | epoch: 010 | loss: 0.02574 - acc: 0.9951 -- iter: 256/473
[A[ATraining Step: 144  | total loss: [1m[32m0.05979[0m[0m | time: 111.759s
[2K
| Adam | epoch: 010 | loss: 0.05979 - acc: 0.9916 -- iter: 288/473
[A[ATraining Step: 145  | total loss: [1m[32m0.05461[0m[0m | time: 125.675s
[2K
| Adam | epoch: 010 | loss: 0.05461 - acc: 0.9925 -- iter: 320/473
[A[ATraining Step: 146  | total loss: [1m[32m0.04935[0m[0m | time: 135.384s
[2K
| Adam | epoch: 010 | loss: 0.04935 - acc: 0.9932 -- iter: 352/473
[A[ATraining Step: 147  | total loss: [1m[32m0.04538[0m[0m | time: 143.974s
[2K
| Adam | epoch: 010 | loss: 0.04538 - acc: 0.9939 -- iter: 384/473
[A[ATraining Step: 148  | total loss: [1m[32m0.04104[0m[0m | time: 152.605s
[2K
| Adam | epoch: 010 | loss: 0.04104 - acc: 0.9945 -- iter: 416/473
[A[ATraining Step: 149  | total loss: [1m[32m0.03730[0m[0m | time: 163.375s
[2K
| Adam | epoch: 010 | loss: 0.03730 - acc: 0.9951 -- iter: 448/473
[A[ATraining Step: 150  | total loss: [1m[32m0.03409[0m[0m | time: 361.301s
[2K
| Adam | epoch: 010 | loss: 0.03409 - acc: 0.9955 | val_loss: 0.73459 - val_acc: 0.7095 -- iter: 473/473
--
Training Step: 151  | total loss: [1m[32m0.03111[0m[0m | time: 113.757s
[2K
| Adam | epoch: 011 | loss: 0.03111 - acc: 0.9960 -- iter: 032/473
[A[ATraining Step: 152  | total loss: [1m[32m0.02950[0m[0m | time: 254.690s
[2K
| Adam | epoch: 011 | loss: 0.02950 - acc: 0.9964 -- iter: 064/473
[A[ATraining Step: 153  | total loss: [1m[32m0.02838[0m[0m | time: 372.709s
[2K
| Adam | epoch: 011 | loss: 0.02838 - acc: 0.9968 -- iter: 096/473
[A[ATraining Step: 154  | total loss: [1m[32m0.02918[0m[0m | time: 427.691s
[2K
| Adam | epoch: 011 | loss: 0.02918 - acc: 0.9940 -- iter: 128/473
[A[ATraining Step: 155  | total loss: [1m[32m0.03469[0m[0m | time: 455.707s
[2K
| Adam | epoch: 011 | loss: 0.03469 - acc: 0.9914 -- iter: 160/473
[A[ATraining Step: 156  | total loss: [1m[32m0.03221[0m[0m | time: 539.341s
[2K
| Adam | epoch: 011 | loss: 0.03221 - acc: 0.9923 -- iter: 192/473
[A[ATraining Step: 157  | total loss: [1m[32m0.02922[0m[0m | time: 547.940s
[2K
| Adam | epoch: 011 | loss: 0.02922 - acc: 0.9931 -- iter: 224/473
[A[ATraining Step: 158  | total loss: [1m[32m0.02665[0m[0m | time: 558.642s
[2K
| Adam | epoch: 011 | loss: 0.02665 - acc: 0.9938 -- iter: 256/473
[A[ATraining Step: 159  | total loss: [1m[32m0.07924[0m[0m | time: 565.526s
[2K
| Adam | epoch: 011 | loss: 0.07924 - acc: 0.9913 -- iter: 288/473
[A[ATraining Step: 160  | total loss: [1m[32m0.09881[0m[0m | time: 572.316s
[2K
| Adam | epoch: 011 | loss: 0.09881 - acc: 0.9881 -- iter: 320/473
[A[ATraining Step: 161  | total loss: [1m[32m0.08999[0m[0m | time: 580.474s
[2K
| Adam | epoch: 011 | loss: 0.08999 - acc: 0.9893 -- iter: 352/473
[A[ATraining Step: 162  | total loss: [1m[32m0.08390[0m[0m | time: 588.875s
[2K
| Adam | epoch: 011 | loss: 0.08390 - acc: 0.9904 -- iter: 384/473
[A[ATraining Step: 163  | total loss: [1m[32m0.07633[0m[0m | time: 601.086s
[2K
| Adam | epoch: 011 | loss: 0.07633 - acc: 0.9913 -- iter: 416/473
[A[ATraining Step: 164  | total loss: [1m[32m0.07208[0m[0m | time: 652.086s
[2K
| Adam | epoch: 011 | loss: 0.07208 - acc: 0.9891 -- iter: 448/473
[A[ATraining Step: 165  | total loss: [1m[32m0.06610[0m[0m | time: 731.578s
[2K
| Adam | epoch: 011 | loss: 0.06610 - acc: 0.9902 | val_loss: 2.89578 - val_acc: 0.6757 -- iter: 473/473
--
Training Step: 166  | total loss: [1m[32m0.05980[0m[0m | time: 47.300s
[2K
| Adam | epoch: 012 | loss: 0.05980 - acc: 0.9912 -- iter: 032/473
[A[ATraining Step: 167  | total loss: [1m[32m0.05519[0m[0m | time: 125.624s
[2K
| Adam | epoch: 012 | loss: 0.05519 - acc: 0.9920 -- iter: 064/473
[A[ATraining Step: 168  | total loss: [1m[32m0.05006[0m[0m | time: 144.202s
[2K
| Adam | epoch: 012 | loss: 0.05006 - acc: 0.9928 -- iter: 096/473
[A[ATraining Step: 169  | total loss: [1m[32m0.04603[0m[0m | time: 156.836s
[2K
| Adam | epoch: 012 | loss: 0.04603 - acc: 0.9936 -- iter: 128/473
[A[ATraining Step: 170  | total loss: [1m[32m0.04376[0m[0m | time: 165.381s
[2K
| Adam | epoch: 012 | loss: 0.04376 - acc: 0.9942 -- iter: 160/473
[A[ATraining Step: 171  | total loss: [1m[32m0.03995[0m[0m | time: 174.181s
[2K
| Adam | epoch: 012 | loss: 0.03995 - acc: 0.9948 -- iter: 192/473
[A[ATraining Step: 172  | total loss: [1m[32m0.03645[0m[0m | time: 186.329s
[2K
| Adam | epoch: 012 | loss: 0.03645 - acc: 0.9953 -- iter: 224/473
[A[ATraining Step: 173  | total loss: [1m[32m0.03373[0m[0m | time: 202.817s
[2K
| Adam | epoch: 012 | loss: 0.03373 - acc: 0.9958 -- iter: 256/473
[A[ATraining Step: 174  | total loss: [1m[32m0.05007[0m[0m | time: 254.219s
[2K
| Adam | epoch: 012 | loss: 0.05007 - acc: 0.9931 -- iter: 288/473
[A[ATraining Step: 175  | total loss: [1m[32m0.04556[0m[0m | time: 316.911s
[2K
| Adam | epoch: 012 | loss: 0.04556 - acc: 0.9938 -- iter: 320/473
[A[ATraining Step: 176  | total loss: [1m[32m0.07794[0m[0m | time: 338.971s
[2K
| Adam | epoch: 012 | loss: 0.07794 - acc: 0.9904 -- iter: 352/473
[A[ATraining Step: 177  | total loss: [1m[32m0.07202[0m[0m | time: 356.765s
[2K
| Adam | epoch: 012 | loss: 0.07202 - acc: 0.9913 -- iter: 384/473
[A[ATraining Step: 178  | total loss: [1m[32m0.06925[0m[0m | time: 430.931s
[2K
| Adam | epoch: 012 | loss: 0.06925 - acc: 0.9891 -- iter: 416/473
[A[ATraining Step: 179  | total loss: [1m[32m0.06418[0m[0m | time: 443.626s
[2K
| Adam | epoch: 012 | loss: 0.06418 - acc: 0.9902 -- iter: 448/473
[A[ATraining Step: 180  | total loss: [1m[32m0.05853[0m[0m | time: 459.132s
[2K
| Adam | epoch: 012 | loss: 0.05853 - acc: 0.9912 | val_loss: 0.36013 - val_acc: 0.8716 -- iter: 473/473
--
Training Step: 181  | total loss: [1m[32m0.05419[0m[0m | time: 20.765s
[2K
| Adam | epoch: 013 | loss: 0.05419 - acc: 0.9920 -- iter: 032/473
[A[ATraining Step: 182  | total loss: [1m[32m0.05281[0m[0m | time: 68.765s
[2K
| Adam | epoch: 013 | loss: 0.05281 - acc: 0.9897 -- iter: 064/473
[A[ATraining Step: 183  | total loss: [1m[32m0.05128[0m[0m | time: 82.666s
[2K
| Adam | epoch: 013 | loss: 0.05128 - acc: 0.9876 -- iter: 096/473
[A[ATraining Step: 184  | total loss: [1m[32m0.04750[0m[0m | time: 95.474s
[2K
| Adam | epoch: 013 | loss: 0.04750 - acc: 0.9889 -- iter: 128/473
[A[ATraining Step: 185  | total loss: [1m[32m0.04378[0m[0m | time: 104.080s
[2K
| Adam | epoch: 013 | loss: 0.04378 - acc: 0.9900 -- iter: 160/473
[A[ATraining Step: 186  | total loss: [1m[32m0.04064[0m[0m | time: 112.717s
[2K
| Adam | epoch: 013 | loss: 0.04064 - acc: 0.9910 -- iter: 192/473
[A[ATraining Step: 187  | total loss: [1m[32m0.03718[0m[0m | time: 128.053s
[2K
| Adam | epoch: 013 | loss: 0.03718 - acc: 0.9919 -- iter: 224/473
[A[ATraining Step: 188  | total loss: [1m[32m0.03691[0m[0m | time: 162.440s
[2K
| Adam | epoch: 013 | loss: 0.03691 - acc: 0.9927 -- iter: 256/473
[A[ATraining Step: 189  | total loss: [1m[32m0.03417[0m[0m | time: 199.524s
[2K
| Adam | epoch: 013 | loss: 0.03417 - acc: 0.9934 -- iter: 288/473
[A[ATraining Step: 190  | total loss: [1m[32m0.03178[0m[0m | time: 220.701s
[2K
| Adam | epoch: 013 | loss: 0.03178 - acc: 0.9941 -- iter: 320/473
[A[ATraining Step: 191  | total loss: [1m[32m0.02937[0m[0m | time: 234.985s
[2K
| Adam | epoch: 013 | loss: 0.02937 - acc: 0.9947 -- iter: 352/473
[A[ATraining Step: 192  | total loss: [1m[32m0.04845[0m[0m | time: 246.419s
[2K
| Adam | epoch: 013 | loss: 0.04845 - acc: 0.9912 -- iter: 384/473
[A[ATraining Step: 193  | total loss: [1m[32m0.04402[0m[0m | time: 259.893s
[2K
| Adam | epoch: 013 | loss: 0.04402 - acc: 0.9921 -- iter: 416/473
[A[ATraining Step: 194  | total loss: [1m[32m0.04018[0m[0m | time: 268.849s
[2K
| Adam | epoch: 013 | loss: 0.04018 - acc: 0.9929 -- iter: 448/473
[A[ATraining Step: 195  | total loss: [1m[32m0.03760[0m[0m | time: 285.656s
[2K
| Adam | epoch: 013 | loss: 0.03760 - acc: 0.9936 | val_loss: 0.65929 - val_acc: 0.7770 -- iter: 473/473
--
Training Step: 196  | total loss: [1m[32m0.03454[0m[0m | time: 19.527s
[2K
| Adam | epoch: 014 | loss: 0.03454 - acc: 0.9942 -- iter: 032/473
[A[ATraining Step: 197  | total loss: [1m[32m0.03196[0m[0m | time: 33.839s
[2K
| Adam | epoch: 014 | loss: 0.03196 - acc: 0.9948 -- iter: 064/473
[A[ATraining Step: 198  | total loss: [1m[32m0.05182[0m[0m | time: 67.149s
[2K
| Adam | epoch: 014 | loss: 0.05182 - acc: 0.9922 -- iter: 096/473
[A[ATraining Step: 199  | total loss: [1m[32m0.04750[0m[0m | time: 86.673s
[2K
| Adam | epoch: 014 | loss: 0.04750 - acc: 0.9930 -- iter: 128/473
[A[ATraining Step: 200  | total loss: [1m[32m0.04307[0m[0m | time: 139.926s
[2K
| Adam | epoch: 014 | loss: 0.04307 - acc: 0.9937 | val_loss: 1.01824 - val_acc: 0.7365 -- iter: 160/473
--
Training Step: 201  | total loss: [1m[32m0.03914[0m[0m | time: 148.683s
[2K
| Adam | epoch: 014 | loss: 0.03914 - acc: 0.9943 -- iter: 192/473
[A[ATraining Step: 202  | total loss: [1m[32m0.03675[0m[0m | time: 157.362s
[2K
| Adam | epoch: 014 | loss: 0.03675 - acc: 0.9949 -- iter: 224/473
[A[ATraining Step: 203  | total loss: [1m[32m0.03400[0m[0m | time: 197.908s
[2K
| Adam | epoch: 014 | loss: 0.03400 - acc: 0.9954 -- iter: 256/473
[A[ATraining Step: 204  | total loss: [1m[32m0.03124[0m[0m | time: 221.472s
[2K
| Adam | epoch: 014 | loss: 0.03124 - acc: 0.9959 -- iter: 288/473
[A[ATraining Step: 205  | total loss: [1m[32m0.02892[0m[0m | time: 235.699s
[2K
| Adam | epoch: 014 | loss: 0.02892 - acc: 0.9963 -- iter: 320/473
[A[ATraining Step: 206  | total loss: [1m[32m0.02694[0m[0m | time: 307.065s
[2K
| Adam | epoch: 014 | loss: 0.02694 - acc: 0.9966 -- iter: 352/473
[A[ATraining Step: 207  | total loss: [1m[32m0.02718[0m[0m | time: 338.515s
[2K
| Adam | epoch: 014 | loss: 0.02718 - acc: 0.9939 -- iter: 384/473
[A[ATraining Step: 208  | total loss: [1m[32m0.05024[0m[0m | time: 349.327s
[2K
| Adam | epoch: 014 | loss: 0.05024 - acc: 0.9905 -- iter: 416/473
[A[ATraining Step: 209  | total loss: [1m[32m0.04559[0m[0m | time: 409.178s
[2K
| Adam | epoch: 014 | loss: 0.04559 - acc: 0.9914 -- iter: 448/473
[A[ATraining Step: 210  | total loss: [1m[32m0.04280[0m[0m | time: 426.014s
[2K
| Adam | epoch: 014 | loss: 0.04280 - acc: 0.9923 | val_loss: 0.57410 - val_acc: 0.7568 -- iter: 473/473
--
Training Step: 211  | total loss: [1m[32m0.03939[0m[0m | time: 70.771s
[2K
| Adam | epoch: 015 | loss: 0.03939 - acc: 0.9931 -- iter: 032/473
[A[ATraining Step: 212  | total loss: [1m[32m0.03577[0m[0m | time: 117.663s
[2K
| Adam | epoch: 015 | loss: 0.03577 - acc: 0.9937 -- iter: 064/473
[A[ATraining Step: 213  | total loss: [1m[32m0.03282[0m[0m | time: 160.001s
[2K
| Adam | epoch: 015 | loss: 0.03282 - acc: 0.9944 -- iter: 096/473
[A[ATraining Step: 214  | total loss: [1m[32m0.04983[0m[0m | time: 194.760s
[2K
| Adam | epoch: 015 | loss: 0.04983 - acc: 0.9918 -- iter: 128/473
[A[ATraining Step: 215  | total loss: [1m[32m0.04518[0m[0m | time: 213.815s
[2K
| Adam | epoch: 015 | loss: 0.04518 - acc: 0.9926 -- iter: 160/473
[A[ATraining Step: 216  | total loss: [1m[32m0.04166[0m[0m | time: 225.742s
[2K
| Adam | epoch: 015 | loss: 0.04166 - acc: 0.9934 -- iter: 192/473
[A[ATraining Step: 217  | total loss: [1m[32m0.03785[0m[0m | time: 234.179s
[2K
| Adam | epoch: 015 | loss: 0.03785 - acc: 0.9940 -- iter: 224/473
[A[ATraining Step: 218  | total loss: [1m[32m0.03448[0m[0m | time: 242.652s
[2K
| Adam | epoch: 015 | loss: 0.03448 - acc: 0.9946 -- iter: 256/473
[A[ATraining Step: 219  | total loss: [1m[32m0.03237[0m[0m | time: 251.360s
[2K
| Adam | epoch: 015 | loss: 0.03237 - acc: 0.9952 -- iter: 288/473
[A[ATraining Step: 220  | total loss: [1m[32m0.02946[0m[0m | time: 263.968s
[2K
| Adam | epoch: 015 | loss: 0.02946 - acc: 0.9956 -- iter: 320/473
[A[ATraining Step: 221  | total loss: [1m[32m0.02689[0m[0m | time: 305.600s
[2K
| Adam | epoch: 015 | loss: 0.02689 - acc: 0.9961 -- iter: 352/473
[A[ATraining Step: 222  | total loss: [1m[32m0.02456[0m[0m | time: 334.123s
[2K
| Adam | epoch: 015 | loss: 0.02456 - acc: 0.9965 -- iter: 384/473
[A[ATraining Step: 223  | total loss: [1m[32m0.02536[0m[0m | time: 344.782s
[2K
| Adam | epoch: 015 | loss: 0.02536 - acc: 0.9937 -- iter: 416/473
[A[ATraining Step: 224  | total loss: [1m[32m0.02986[0m[0m | time: 398.860s
[2K
| Adam | epoch: 015 | loss: 0.02986 - acc: 0.9943 -- iter: 448/473
[A[ATraining Step: 225  | total loss: [1m[32m0.02932[0m[0m | time: 463.344s
[2K
| Adam | epoch: 015 | loss: 0.02932 - acc: 0.9949 | val_loss: 0.39166 - val_acc: 0.8919 -- iter: 473/473
--
Validation AUC:0.9627915943705417
Validation AUPRC:0.9707176344551786
Test AUC:0.9698660714285714
Test AUPRC:0.9750974526690156
BestTestF1Score	0.93	0.84	0.92	0.9	0.96	81	9	55	3	0.97
BestTestMCCScore	0.93	0.84	0.92	0.9	0.96	81	9	55	3	0.97
BestTestAccuracyScore	0.93	0.84	0.92	0.9	0.96	81	9	55	3	0.97
BestValidationF1Score	0.93	0.83	0.92	0.95	0.91	83	4	53	8	0.97
BestValidationMCC	0.93	0.83	0.92	0.95	0.91	83	4	53	8	0.97
BestValidationAccuracy	0.93	0.83	0.92	0.95	0.91	83	4	53	8	0.97
TestPredictions (Threshold:0.97)
CHEMBL1784285,TP,ACT,1.0	CHEMBL2424809,TN,INACT,0.0	CHEMBL1215522,TN,INACT,0.0	CHEMBL1616222,TN,INACT,0.009999999776482582	CHEMBL1779209,TP,ACT,0.9700000286102295	CHEMBL3623004,FP,INACT,1.0	CHEMBL309357,TN,INACT,0.25	CHEMBL1094714,TP,ACT,1.0	CHEMBL3654334,TP,ACT,1.0	CHEMBL3289574,TN,INACT,0.2199999988079071	CHEMBL3703936,TP,ACT,1.0	CHEMBL1917035,TN,INACT,0.029999999329447746	CHEMBL1819198,TP,ACT,1.0	CHEMBL3109018,TP,ACT,0.9800000190734863	CHEMBL2424811,TN,INACT,0.0	CHEMBL1782543,TN,INACT,0.019999999552965164	CHEMBL3654331,TP,ACT,1.0	CHEMBL1093778,TP,ACT,1.0	CHEMBL1650471,FP,INACT,1.0	CHEMBL1807542,TP,ACT,1.0	CHEMBL419823,TN,INACT,0.0	CHEMBL3703839,TP,ACT,1.0	CHEMBL2048494,TP,ACT,1.0	CHEMBL3703868,TP,ACT,1.0	CHEMBL45068,TN,INACT,0.4699999988079071	CHEMBL1289947,TP,ACT,1.0	CHEMBL1782373,FN,ACT,0.3400000035762787	CHEMBL592521,FP,INACT,1.0	CHEMBL3654904,TP,ACT,1.0	CHEMBL3109017,TP,ACT,1.0	CHEMBL2414190,TN,INACT,0.009999999776482582	CHEMBL1762502,TP,ACT,0.9900000095367432	CHEMBL3775498,TN,INACT,0.05999999865889549	CHEMBL1617679,TN,INACT,0.05999999865889549	CHEMBL1762497,TP,ACT,0.9700000286102295	CHEMBL3288740,TP,ACT,1.0	CHEMBL1830355,TP,ACT,1.0	CHEMBL382302,TP,ACT,1.0	CHEMBL473310,TN,INACT,0.0	CHEMBL3634949,FP,INACT,0.9800000190734863	CHEMBL2172385,TP,ACT,1.0	CHEMBL2172384,TP,ACT,1.0	CHEMBL2160190,FP,INACT,0.9900000095367432	CHEMBL2424812,TN,INACT,0.0	CHEMBL3703824,TP,ACT,1.0	CHEMBL3703919,TP,ACT,1.0	CHEMBL3775354,FP,INACT,0.9900000095367432	CHEMBL1672784,TP,ACT,1.0	CHEMBL2414180,TN,INACT,0.12999999523162842	CHEMBL1091547,TP,ACT,1.0	CHEMBL269439,TN,INACT,0.05000000074505806	CHEMBL1085770,TP,ACT,1.0	CHEMBL2413090,TN,INACT,0.699999988079071	CHEMBL1917041,TN,INACT,0.7300000190734863	CHEMBL206724,TP,ACT,1.0	CHEMBL1822155,TN,INACT,0.25	CHEMBL600982,TP,ACT,1.0	CHEMBL2018091,TP,ACT,1.0	CHEMBL3654918,TP,ACT,1.0	CHEMBL75800,TN,INACT,0.2199999988079071	CHEMBL2424814,TN,INACT,0.0	CHEMBL1163692,TP,ACT,1.0	CHEMBL3654349,TP,ACT,1.0	CHEMBL3775110,TN,INACT,0.0	CHEMBL126202,TN,INACT,0.0	CHEMBL2303994,TN,INACT,0.9200000166893005	CHEMBL2415009,TN,INACT,0.17000000178813934	CHEMBL566940,TP,ACT,1.0	CHEMBL2387659,TN,INACT,0.6700000166893005	CHEMBL1300185,TN,INACT,0.8700000047683716	CHEMBL1784428,TP,ACT,1.0	CHEMBL18797,FP,INACT,0.9900000095367432	CHEMBL566484,TP,ACT,1.0	CHEMBL1808389,FP,INACT,1.0	CHEMBL2424813,TN,INACT,0.0	CHEMBL504484,TP,ACT,1.0	CHEMBL2172493,TP,ACT,1.0	CHEMBL2316565,TN,INACT,0.019999999552965164	CHEMBL2414178,TN,INACT,0.1599999964237213	CHEMBL2387662,TN,INACT,0.019999999552965164	CHEMBL3132993,TN,INACT,0.2199999988079071	CHEMBL3775673,TN,INACT,0.4699999988079071	CHEMBL2440381,FP,INACT,0.9800000190734863	CHEMBL3318048,TN,INACT,0.019999999552965164	CHEMBL3786426,TN,INACT,0.949999988079071	CHEMBL3654897,TP,ACT,1.0	CHEMBL2424816,TN,INACT,0.009999999776482582	CHEMBL3703864,TP,ACT,1.0	CHEMBL3679705,TP,ACT,1.0	CHEMBL381370,TP,ACT,1.0	CHEMBL3288755,TP,ACT,1.0	CHEMBL603166,TP,ACT,1.0	CHEMBL3775704,TN,INACT,0.8199999928474426	CHEMBL3590425,TN,INACT,0.0	CHEMBL2048492,TP,ACT,1.0	CHEMBL1672780,TP,ACT,0.9900000095367432	CHEMBL3590428,TN,INACT,0.0	CHEMBL3679700,TP,ACT,1.0	CHEMBL1352532,TN,INACT,0.10000000149011612	CHEMBL3775918,TN,INACT,0.0	CHEMBL3654888,TP,ACT,1.0	CHEMBL2430319,TP,ACT,1.0	CHEMBL3703791,TP,ACT,1.0	CHEMBL3703848,TP,ACT,1.0	CHEMBL1762492,FN,ACT,0.8100000023841858	CHEMBL2414184,TN,INACT,0.05999999865889549	CHEMBL3648651,TP,ACT,1.0	CHEMBL2159110,TP,ACT,1.0	CHEMBL3785439,TP,ACT,0.9900000095367432	CHEMBL1650491,TP,ACT,1.0	CHEMBL2403791,TN,INACT,0.03999999910593033	CHEMBL1083978,TP,ACT,1.0	CHEMBL591937,TP,ACT,1.0	CHEMBL2159094,TN,INACT,0.05000000074505806	CHEMBL1213936,TP,ACT,1.0	CHEMBL3289573,TN,INACT,0.03999999910593033	CHEMBL2062848,TN,INACT,0.9300000071525574	CHEMBL3774606,TN,INACT,0.8899999856948853	CHEMBL41632,TN,INACT,0.18000000715255737	CHEMBL1819098,TP,ACT,1.0	CHEMBL1083079,TP,ACT,1.0	CHEMBL2018085,TP,ACT,1.0	CHEMBL3659998,TP,ACT,1.0	CHEMBL1289832,TP,ACT,1.0	CHEMBL2414079,TN,INACT,0.11999999731779099	CHEMBL606689,TP,ACT,1.0	CHEMBL2103841,TP,ACT,1.0	CHEMBL1085844,TP,ACT,1.0	CHEMBL1779345,FN,ACT,0.8700000047683716	CHEMBL2424815,TN,INACT,0.0	CHEMBL3703823,TP,ACT,1.0	CHEMBL3703786,TP,ACT,1.0	CHEMBL3125149,TP,ACT,1.0	CHEMBL3125148,TP,ACT,1.0	CHEMBL2159102,TP,ACT,1.0	CHEMBL3590421,TN,INACT,0.0	CHEMBL3703866,TP,ACT,1.0	CHEMBL509278,TP,ACT,1.0	CHEMBL3703836,TP,ACT,1.0	CHEMBL1782368,TP,ACT,1.0	CHEMBL1090414,TP,ACT,1.0	CHEMBL3703931,TP,ACT,1.0	CHEMBL2414167,TN,INACT,0.25	CHEMBL1649593,TP,ACT,1.0	CHEMBL1459860,TN,INACT,0.17000000178813934	CHEMBL11592,TN,INACT,0.09000000357627869	CHEMBL2018084,TP,ACT,1.0	CHEMBL382293,TP,ACT,1.0	

