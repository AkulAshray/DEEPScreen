ImageNetInceptionV2 CHEMBL4430 adam 0.001 30 0 0 0.8 False True
Number of active compounds :	141
Number of inactive compounds :	141
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4430_adam_0.001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4430_adam_0.001_30_0.8/
---------------------------------
Training samples: 180
Validation samples: 57
--
Training Step: 1  | time: 36.785s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/180
[A[ATraining Step: 2  | total loss: [1m[32m0.64835[0m[0m | time: 44.826s
[2K
| Adam | epoch: 001 | loss: 0.64835 - acc: 0.3375 -- iter: 064/180
[A[ATraining Step: 3  | total loss: [1m[32m0.72157[0m[0m | time: 53.032s
[2K
| Adam | epoch: 001 | loss: 0.72157 - acc: 0.5727 -- iter: 096/180
[A[ATraining Step: 4  | total loss: [1m[32m0.51553[0m[0m | time: 61.146s
[2K
| Adam | epoch: 001 | loss: 0.51553 - acc: 0.7057 -- iter: 128/180
[A[ATraining Step: 5  | total loss: [1m[32m0.72589[0m[0m | time: 69.160s
[2K
| Adam | epoch: 001 | loss: 0.72589 - acc: 0.6931 -- iter: 160/180
[A[ATraining Step: 6  | total loss: [1m[32m0.63962[0m[0m | time: 82.905s
[2K
| Adam | epoch: 001 | loss: 0.63962 - acc: 0.6292 | val_loss: 2.46504 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 7  | total loss: [1m[32m0.48069[0m[0m | time: 5.477s
[2K
| Adam | epoch: 002 | loss: 0.48069 - acc: 0.8217 -- iter: 032/180
[A[ATraining Step: 8  | total loss: [1m[32m0.28154[0m[0m | time: 13.679s
[2K
| Adam | epoch: 002 | loss: 0.28154 - acc: 0.9220 -- iter: 064/180
[A[ATraining Step: 9  | total loss: [1m[32m0.45507[0m[0m | time: 21.911s
[2K
| Adam | epoch: 002 | loss: 0.45507 - acc: 0.8144 -- iter: 096/180
[A[ATraining Step: 10  | total loss: [1m[32m0.35000[0m[0m | time: 30.143s
[2K
| Adam | epoch: 002 | loss: 0.35000 - acc: 0.8603 -- iter: 128/180
[A[ATraining Step: 11  | total loss: [1m[32m0.37621[0m[0m | time: 38.440s
[2K
| Adam | epoch: 002 | loss: 0.37621 - acc: 0.8525 -- iter: 160/180
[A[ATraining Step: 12  | total loss: [1m[32m0.35933[0m[0m | time: 49.399s
[2K
| Adam | epoch: 002 | loss: 0.35933 - acc: 0.8626 | val_loss: 4.72703 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 13  | total loss: [1m[32m0.24450[0m[0m | time: 5.519s
[2K
| Adam | epoch: 003 | loss: 0.24450 - acc: 0.9081 -- iter: 032/180
[A[ATraining Step: 14  | total loss: [1m[32m0.36966[0m[0m | time: 10.983s
[2K
| Adam | epoch: 003 | loss: 0.36966 - acc: 0.8434 -- iter: 064/180
[A[ATraining Step: 15  | total loss: [1m[32m0.30176[0m[0m | time: 19.567s
[2K
| Adam | epoch: 003 | loss: 0.30176 - acc: 0.8656 -- iter: 096/180
[A[ATraining Step: 16  | total loss: [1m[32m0.45258[0m[0m | time: 27.979s
[2K
| Adam | epoch: 003 | loss: 0.45258 - acc: 0.8457 -- iter: 128/180
[A[ATraining Step: 17  | total loss: [1m[32m0.43947[0m[0m | time: 36.510s
[2K
| Adam | epoch: 003 | loss: 0.43947 - acc: 0.8112 -- iter: 160/180
[A[ATraining Step: 18  | total loss: [1m[32m0.35516[0m[0m | time: 47.538s
[2K
| Adam | epoch: 003 | loss: 0.35516 - acc: 0.8441 | val_loss: 2.24172 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 19  | total loss: [1m[32m0.31828[0m[0m | time: 8.488s
[2K
| Adam | epoch: 004 | loss: 0.31828 - acc: 0.8544 -- iter: 032/180
[A[ATraining Step: 20  | total loss: [1m[32m0.30429[0m[0m | time: 13.893s
[2K
| Adam | epoch: 004 | loss: 0.30429 - acc: 0.8309 -- iter: 064/180
[A[ATraining Step: 21  | total loss: [1m[32m0.24908[0m[0m | time: 19.248s
[2K
| Adam | epoch: 004 | loss: 0.24908 - acc: 0.8679 -- iter: 096/180
[A[ATraining Step: 22  | total loss: [1m[32m0.20387[0m[0m | time: 27.738s
[2K
| Adam | epoch: 004 | loss: 0.20387 - acc: 0.9075 -- iter: 128/180
[A[ATraining Step: 23  | total loss: [1m[32m0.25291[0m[0m | time: 36.218s
[2K
| Adam | epoch: 004 | loss: 0.25291 - acc: 0.8981 -- iter: 160/180
[A[ATraining Step: 24  | total loss: [1m[32m0.23076[0m[0m | time: 47.316s
[2K
| Adam | epoch: 004 | loss: 0.23076 - acc: 0.9179 | val_loss: 1.93626 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 25  | total loss: [1m[32m0.21564[0m[0m | time: 8.657s
[2K
| Adam | epoch: 005 | loss: 0.21564 - acc: 0.9233 -- iter: 032/180
[A[ATraining Step: 26  | total loss: [1m[32m0.22122[0m[0m | time: 17.021s
[2K
| Adam | epoch: 005 | loss: 0.22122 - acc: 0.9188 -- iter: 064/180
[A[ATraining Step: 27  | total loss: [1m[32m0.20129[0m[0m | time: 22.492s
[2K
| Adam | epoch: 005 | loss: 0.20129 - acc: 0.9316 -- iter: 096/180
[A[ATraining Step: 28  | total loss: [1m[32m0.24626[0m[0m | time: 28.095s
[2K
| Adam | epoch: 005 | loss: 0.24626 - acc: 0.8862 -- iter: 128/180
[A[ATraining Step: 29  | total loss: [1m[32m0.22185[0m[0m | time: 36.294s
[2K
| Adam | epoch: 005 | loss: 0.22185 - acc: 0.9017 -- iter: 160/180
[A[ATraining Step: 30  | total loss: [1m[32m0.22001[0m[0m | time: 47.401s
[2K
| Adam | epoch: 005 | loss: 0.22001 - acc: 0.9028 | val_loss: 0.93217 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 31  | total loss: [1m[32m0.20981[0m[0m | time: 8.270s
[2K
| Adam | epoch: 006 | loss: 0.20981 - acc: 0.9108 -- iter: 032/180
[A[ATraining Step: 32  | total loss: [1m[32m0.19895[0m[0m | time: 16.555s
[2K
| Adam | epoch: 006 | loss: 0.19895 - acc: 0.9238 -- iter: 064/180
[A[ATraining Step: 33  | total loss: [1m[32m0.20886[0m[0m | time: 24.885s
[2K
| Adam | epoch: 006 | loss: 0.20886 - acc: 0.9131 -- iter: 096/180
[A[ATraining Step: 34  | total loss: [1m[32m0.19452[0m[0m | time: 30.402s
[2K
| Adam | epoch: 006 | loss: 0.19452 - acc: 0.9250 -- iter: 128/180
[A[ATraining Step: 35  | total loss: [1m[32m0.16643[0m[0m | time: 35.847s
[2K
| Adam | epoch: 006 | loss: 0.16643 - acc: 0.9303 -- iter: 160/180
[A[ATraining Step: 36  | total loss: [1m[32m0.13513[0m[0m | time: 46.771s
[2K
| Adam | epoch: 006 | loss: 0.13513 - acc: 0.9445 | val_loss: 1.12101 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 37  | total loss: [1m[32m0.11947[0m[0m | time: 8.344s
[2K
| Adam | epoch: 007 | loss: 0.11947 - acc: 0.9494 -- iter: 032/180
[A[ATraining Step: 38  | total loss: [1m[32m0.18079[0m[0m | time: 16.769s
[2K
| Adam | epoch: 007 | loss: 0.18079 - acc: 0.9471 -- iter: 064/180
[A[ATraining Step: 39  | total loss: [1m[32m0.17321[0m[0m | time: 25.134s
[2K
| Adam | epoch: 007 | loss: 0.17321 - acc: 0.9512 -- iter: 096/180
[A[ATraining Step: 40  | total loss: [1m[32m0.14725[0m[0m | time: 33.548s
[2K
| Adam | epoch: 007 | loss: 0.14725 - acc: 0.9604 -- iter: 128/180
[A[ATraining Step: 41  | total loss: [1m[32m0.12547[0m[0m | time: 38.993s
[2K
| Adam | epoch: 007 | loss: 0.12547 - acc: 0.9676 -- iter: 160/180
[A[ATraining Step: 42  | total loss: [1m[32m0.14044[0m[0m | time: 47.105s
[2K
| Adam | epoch: 007 | loss: 0.14044 - acc: 0.9645 | val_loss: 1.41589 - val_acc: 0.4912 -- iter: 180/180
--
Training Step: 43  | total loss: [1m[32m0.12261[0m[0m | time: 8.331s
[2K
| Adam | epoch: 008 | loss: 0.12261 - acc: 0.9707 -- iter: 032/180
[A[ATraining Step: 44  | total loss: [1m[32m0.15400[0m[0m | time: 16.588s
[2K
| Adam | epoch: 008 | loss: 0.15400 - acc: 0.9433 -- iter: 064/180
[A[ATraining Step: 45  | total loss: [1m[32m0.25888[0m[0m | time: 24.913s
[2K
| Adam | epoch: 008 | loss: 0.25888 - acc: 0.9264 -- iter: 096/180
[A[ATraining Step: 46  | total loss: [1m[32m0.22728[0m[0m | time: 33.267s
[2K
| Adam | epoch: 008 | loss: 0.22728 - acc: 0.9387 -- iter: 128/180
[A[ATraining Step: 47  | total loss: [1m[32m0.24558[0m[0m | time: 41.675s
[2K
| Adam | epoch: 008 | loss: 0.24558 - acc: 0.9078 -- iter: 160/180
[A[ATraining Step: 48  | total loss: [1m[32m0.24589[0m[0m | time: 49.643s
[2K
| Adam | epoch: 008 | loss: 0.24589 - acc: 0.8975 | val_loss: 0.92216 - val_acc: 0.5439 -- iter: 180/180
--
Training Step: 49  | total loss: [1m[32m0.23031[0m[0m | time: 5.424s
[2K
| Adam | epoch: 009 | loss: 0.23031 - acc: 0.9058 -- iter: 032/180
[A[ATraining Step: 50  | total loss: [1m[32m0.21260[0m[0m | time: 13.864s
[2K
| Adam | epoch: 009 | loss: 0.21260 - acc: 0.9127 -- iter: 064/180
[A[ATraining Step: 51  | total loss: [1m[32m0.19274[0m[0m | time: 22.261s
[2K
| Adam | epoch: 009 | loss: 0.19274 - acc: 0.9260 -- iter: 096/180
[A[ATraining Step: 52  | total loss: [1m[32m0.20661[0m[0m | time: 30.521s
[2K
| Adam | epoch: 009 | loss: 0.20661 - acc: 0.9230 -- iter: 128/180
[A[ATraining Step: 53  | total loss: [1m[32m0.19347[0m[0m | time: 38.791s
[2K
| Adam | epoch: 009 | loss: 0.19347 - acc: 0.9298 -- iter: 160/180
[A[ATraining Step: 54  | total loss: [1m[32m0.18336[0m[0m | time: 49.772s
[2K
| Adam | epoch: 009 | loss: 0.18336 - acc: 0.9354 | val_loss: 0.74152 - val_acc: 0.6140 -- iter: 180/180
--
Training Step: 55  | total loss: [1m[32m0.16417[0m[0m | time: 5.588s
[2K
| Adam | epoch: 010 | loss: 0.16417 - acc: 0.9447 -- iter: 032/180
[A[ATraining Step: 56  | total loss: [1m[32m0.14848[0m[0m | time: 10.977s
[2K
| Adam | epoch: 010 | loss: 0.14848 - acc: 0.9524 -- iter: 064/180
[A[ATraining Step: 57  | total loss: [1m[32m0.13278[0m[0m | time: 19.435s
[2K
| Adam | epoch: 010 | loss: 0.13278 - acc: 0.9590 -- iter: 096/180
[A[ATraining Step: 58  | total loss: [1m[32m0.11964[0m[0m | time: 27.956s
[2K
| Adam | epoch: 010 | loss: 0.11964 - acc: 0.9646 -- iter: 128/180
[A[ATraining Step: 59  | total loss: [1m[32m0.18287[0m[0m | time: 36.337s
[2K
| Adam | epoch: 010 | loss: 0.18287 - acc: 0.9568 -- iter: 160/180
[A[ATraining Step: 60  | total loss: [1m[32m0.16203[0m[0m | time: 47.300s
[2K
| Adam | epoch: 010 | loss: 0.16203 - acc: 0.9625 | val_loss: 0.66858 - val_acc: 0.8421 -- iter: 180/180
--
Training Step: 61  | total loss: [1m[32m0.14226[0m[0m | time: 8.460s
[2K
| Adam | epoch: 011 | loss: 0.14226 - acc: 0.9674 -- iter: 032/180
[A[ATraining Step: 62  | total loss: [1m[32m0.13393[0m[0m | time: 13.918s
[2K
| Adam | epoch: 011 | loss: 0.13393 - acc: 0.9676 -- iter: 064/180
[A[ATraining Step: 63  | total loss: [1m[32m0.12909[0m[0m | time: 19.485s
[2K
| Adam | epoch: 011 | loss: 0.12909 - acc: 0.9653 -- iter: 096/180
[A[ATraining Step: 64  | total loss: [1m[32m0.11545[0m[0m | time: 27.778s
[2K
| Adam | epoch: 011 | loss: 0.11545 - acc: 0.9697 -- iter: 128/180
[A[ATraining Step: 65  | total loss: [1m[32m0.13117[0m[0m | time: 36.070s
[2K
| Adam | epoch: 011 | loss: 0.13117 - acc: 0.9618 -- iter: 160/180
[A[ATraining Step: 66  | total loss: [1m[32m0.13790[0m[0m | time: 46.859s
[2K
| Adam | epoch: 011 | loss: 0.13790 - acc: 0.9627 | val_loss: 1.38803 - val_acc: 0.6316 -- iter: 180/180
--
Training Step: 67  | total loss: [1m[32m0.12383[0m[0m | time: 8.276s
[2K
| Adam | epoch: 012 | loss: 0.12383 - acc: 0.9672 -- iter: 032/180
[A[ATraining Step: 68  | total loss: [1m[32m0.12417[0m[0m | time: 16.530s
[2K
| Adam | epoch: 012 | loss: 0.12417 - acc: 0.9637 -- iter: 064/180
[A[ATraining Step: 69  | total loss: [1m[32m0.12719[0m[0m | time: 21.848s
[2K
| Adam | epoch: 012 | loss: 0.12719 - acc: 0.9606 -- iter: 096/180
[A[ATraining Step: 70  | total loss: [1m[32m0.12654[0m[0m | time: 27.219s
[2K
| Adam | epoch: 012 | loss: 0.12654 - acc: 0.9536 -- iter: 128/180
[A[ATraining Step: 71  | total loss: [1m[32m0.11625[0m[0m | time: 35.595s
[2K
| Adam | epoch: 012 | loss: 0.11625 - acc: 0.9589 -- iter: 160/180
[A[ATraining Step: 72  | total loss: [1m[32m0.10847[0m[0m | time: 46.411s
[2K
| Adam | epoch: 012 | loss: 0.10847 - acc: 0.9635 | val_loss: 0.73173 - val_acc: 0.8070 -- iter: 180/180
--
Training Step: 73  | total loss: [1m[32m0.13216[0m[0m | time: 8.261s
[2K
| Adam | epoch: 013 | loss: 0.13216 - acc: 0.9641 -- iter: 032/180
[A[ATraining Step: 74  | total loss: [1m[32m0.12106[0m[0m | time: 16.588s
[2K
| Adam | epoch: 013 | loss: 0.12106 - acc: 0.9680 -- iter: 064/180
[A[ATraining Step: 75  | total loss: [1m[32m0.11448[0m[0m | time: 24.818s
[2K
| Adam | epoch: 013 | loss: 0.11448 - acc: 0.9647 -- iter: 096/180
[A[ATraining Step: 76  | total loss: [1m[32m0.10647[0m[0m | time: 30.135s
[2K
| Adam | epoch: 013 | loss: 0.10647 - acc: 0.9685 -- iter: 128/180
[A[ATraining Step: 77  | total loss: [1m[32m0.10947[0m[0m | time: 35.498s
[2K
| Adam | epoch: 013 | loss: 0.10947 - acc: 0.9665 -- iter: 160/180
[A[ATraining Step: 78  | total loss: [1m[32m0.10097[0m[0m | time: 46.303s
[2K
| Adam | epoch: 013 | loss: 0.10097 - acc: 0.9700 | val_loss: 0.97577 - val_acc: 0.6667 -- iter: 180/180
--
Training Step: 79  | total loss: [1m[32m0.09160[0m[0m | time: 8.371s
[2K
| Adam | epoch: 014 | loss: 0.09160 - acc: 0.9731 -- iter: 032/180
[A[ATraining Step: 80  | total loss: [1m[32m0.14383[0m[0m | time: 16.505s
[2K
| Adam | epoch: 014 | loss: 0.14383 - acc: 0.9663 -- iter: 064/180
[A[ATraining Step: 81  | total loss: [1m[32m0.14844[0m[0m | time: 24.702s
[2K
| Adam | epoch: 014 | loss: 0.14844 - acc: 0.9666 -- iter: 096/180
[A[ATraining Step: 82  | total loss: [1m[32m0.14189[0m[0m | time: 32.965s
[2K
| Adam | epoch: 014 | loss: 0.14189 - acc: 0.9699 -- iter: 128/180
[A[ATraining Step: 83  | total loss: [1m[32m0.13620[0m[0m | time: 38.474s
[2K
| Adam | epoch: 014 | loss: 0.13620 - acc: 0.9698 -- iter: 160/180
[A[ATraining Step: 84  | total loss: [1m[32m0.14219[0m[0m | time: 46.410s
[2K
| Adam | epoch: 014 | loss: 0.14219 - acc: 0.9678 | val_loss: 4.11252 - val_acc: 0.5263 -- iter: 180/180
--
Training Step: 85  | total loss: [1m[32m0.14297[0m[0m | time: 8.403s
[2K
| Adam | epoch: 015 | loss: 0.14297 - acc: 0.9660 -- iter: 032/180
[A[ATraining Step: 86  | total loss: [1m[32m0.13100[0m[0m | time: 16.695s
[2K
| Adam | epoch: 015 | loss: 0.13100 - acc: 0.9694 -- iter: 064/180
[A[ATraining Step: 87  | total loss: [1m[32m0.13268[0m[0m | time: 25.036s
[2K
| Adam | epoch: 015 | loss: 0.13268 - acc: 0.9694 -- iter: 096/180
[A[ATraining Step: 88  | total loss: [1m[32m0.12334[0m[0m | time: 33.202s
[2K
| Adam | epoch: 015 | loss: 0.12334 - acc: 0.9724 -- iter: 128/180
[A[ATraining Step: 89  | total loss: [1m[32m0.11576[0m[0m | time: 41.521s
[2K
| Adam | epoch: 015 | loss: 0.11576 - acc: 0.9752 -- iter: 160/180
[A[ATraining Step: 90  | total loss: [1m[32m0.11367[0m[0m | time: 49.362s
[2K
| Adam | epoch: 015 | loss: 0.11367 - acc: 0.9745 | val_loss: 1.07191 - val_acc: 0.8246 -- iter: 180/180
--
Training Step: 91  | total loss: [1m[32m0.11190[0m[0m | time: 5.472s
[2K
| Adam | epoch: 016 | loss: 0.11190 - acc: 0.9721 -- iter: 032/180
[A[ATraining Step: 92  | total loss: [1m[32m0.10564[0m[0m | time: 13.541s
[2K
| Adam | epoch: 016 | loss: 0.10564 - acc: 0.9749 -- iter: 064/180
[A[ATraining Step: 93  | total loss: [1m[32m0.10157[0m[0m | time: 21.766s
[2K
| Adam | epoch: 016 | loss: 0.10157 - acc: 0.9743 -- iter: 096/180
[A[ATraining Step: 94  | total loss: [1m[32m0.11886[0m[0m | time: 30.053s
[2K
| Adam | epoch: 016 | loss: 0.11886 - acc: 0.9706 -- iter: 128/180
[A[ATraining Step: 95  | total loss: [1m[32m0.10846[0m[0m | time: 38.319s
[2K
| Adam | epoch: 016 | loss: 0.10846 - acc: 0.9735 -- iter: 160/180
[A[ATraining Step: 96  | total loss: [1m[32m0.09892[0m[0m | time: 49.106s
[2K
| Adam | epoch: 016 | loss: 0.09892 - acc: 0.9762 | val_loss: 1.01110 - val_acc: 0.8246 -- iter: 180/180
--
Training Step: 97  | total loss: [1m[32m0.09506[0m[0m | time: 5.340s
[2K
| Adam | epoch: 017 | loss: 0.09506 - acc: 0.9754 -- iter: 032/180
[A[ATraining Step: 98  | total loss: [1m[32m0.08743[0m[0m | time: 10.748s
[2K
| Adam | epoch: 017 | loss: 0.08743 - acc: 0.9779 -- iter: 064/180
[A[ATraining Step: 99  | total loss: [1m[32m0.08018[0m[0m | time: 18.732s
[2K
| Adam | epoch: 017 | loss: 0.08018 - acc: 0.9801 -- iter: 096/180
[A[ATraining Step: 100  | total loss: [1m[32m0.09110[0m[0m | time: 26.978s
[2K
| Adam | epoch: 017 | loss: 0.09110 - acc: 0.9758 -- iter: 128/180
[A[ATraining Step: 101  | total loss: [1m[32m0.19164[0m[0m | time: 35.200s
[2K
| Adam | epoch: 017 | loss: 0.19164 - acc: 0.9658 -- iter: 160/180
[A[ATraining Step: 102  | total loss: [1m[32m0.17953[0m[0m | time: 45.981s
[2K
| Adam | epoch: 017 | loss: 0.17953 - acc: 0.9629 | val_loss: 0.68485 - val_acc: 0.7895 -- iter: 180/180
--
Training Step: 103  | total loss: [1m[32m0.18630[0m[0m | time: 8.294s
[2K
| Adam | epoch: 018 | loss: 0.18630 - acc: 0.9604 -- iter: 032/180
[A[ATraining Step: 104  | total loss: [1m[32m0.17224[0m[0m | time: 13.631s
[2K
| Adam | epoch: 018 | loss: 0.17224 - acc: 0.9643 -- iter: 064/180
[A[ATraining Step: 105  | total loss: [1m[32m0.16833[0m[0m | time: 19.036s
[2K
| Adam | epoch: 018 | loss: 0.16833 - acc: 0.9629 -- iter: 096/180
[A[ATraining Step: 106  | total loss: [1m[32m0.16074[0m[0m | time: 27.310s
[2K
| Adam | epoch: 018 | loss: 0.16074 - acc: 0.9666 -- iter: 128/180
[A[ATraining Step: 107  | total loss: [1m[32m0.15351[0m[0m | time: 35.412s
[2K
| Adam | epoch: 018 | loss: 0.15351 - acc: 0.9668 -- iter: 160/180
[A[ATraining Step: 108  | total loss: [1m[32m0.14215[0m[0m | time: 46.118s
[2K
| Adam | epoch: 018 | loss: 0.14215 - acc: 0.9702 | val_loss: 2.59714 - val_acc: 0.4912 -- iter: 180/180
--
Training Step: 109  | total loss: [1m[32m0.14332[0m[0m | time: 8.169s
[2K
| Adam | epoch: 019 | loss: 0.14332 - acc: 0.9669 -- iter: 032/180
[A[ATraining Step: 110  | total loss: [1m[32m0.13521[0m[0m | time: 16.342s
[2K
| Adam | epoch: 019 | loss: 0.13521 - acc: 0.9702 -- iter: 064/180
[A[ATraining Step: 111  | total loss: [1m[32m0.12311[0m[0m | time: 21.782s
[2K
| Adam | epoch: 019 | loss: 0.12311 - acc: 0.9732 -- iter: 096/180
[A[ATraining Step: 112  | total loss: [1m[32m0.11194[0m[0m | time: 27.074s
[2K
| Adam | epoch: 019 | loss: 0.11194 - acc: 0.9759 -- iter: 128/180
[A[ATraining Step: 113  | total loss: [1m[32m0.10171[0m[0m | time: 35.345s
[2K
| Adam | epoch: 019 | loss: 0.10171 - acc: 0.9783 -- iter: 160/180
[A[ATraining Step: 114  | total loss: [1m[32m0.09298[0m[0m | time: 45.966s
[2K
| Adam | epoch: 019 | loss: 0.09298 - acc: 0.9804 | val_loss: 0.57346 - val_acc: 0.7895 -- iter: 180/180
--
Training Step: 115  | total loss: [1m[32m0.12097[0m[0m | time: 8.101s
[2K
| Adam | epoch: 020 | loss: 0.12097 - acc: 0.9762 -- iter: 032/180
[A[ATraining Step: 116  | total loss: [1m[32m0.10990[0m[0m | time: 16.069s
[2K
| Adam | epoch: 020 | loss: 0.10990 - acc: 0.9785 -- iter: 064/180
[A[ATraining Step: 117  | total loss: [1m[32m0.10070[0m[0m | time: 24.097s
[2K
| Adam | epoch: 020 | loss: 0.10070 - acc: 0.9807 -- iter: 096/180
[A[ATraining Step: 118  | total loss: [1m[32m0.09253[0m[0m | time: 29.384s
[2K
| Adam | epoch: 020 | loss: 0.09253 - acc: 0.9826 -- iter: 128/180
[A[ATraining Step: 119  | total loss: [1m[32m0.08501[0m[0m | time: 34.779s
[2K
| Adam | epoch: 020 | loss: 0.08501 - acc: 0.9844 -- iter: 160/180
[A[ATraining Step: 120  | total loss: [1m[32m0.07803[0m[0m | time: 45.514s
[2K
| Adam | epoch: 020 | loss: 0.07803 - acc: 0.9859 | val_loss: 0.84869 - val_acc: 0.7895 -- iter: 180/180
--
Training Step: 121  | total loss: [1m[32m0.07136[0m[0m | time: 8.054s
[2K
| Adam | epoch: 021 | loss: 0.07136 - acc: 0.9873 -- iter: 032/180
[A[ATraining Step: 122  | total loss: [1m[32m0.07480[0m[0m | time: 16.177s
[2K
| Adam | epoch: 021 | loss: 0.07480 - acc: 0.9855 -- iter: 064/180
[A[ATraining Step: 123  | total loss: [1m[32m0.07066[0m[0m | time: 24.152s
[2K
| Adam | epoch: 021 | loss: 0.07066 - acc: 0.9838 -- iter: 096/180
[A[ATraining Step: 124  | total loss: [1m[32m0.06438[0m[0m | time: 32.207s
[2K
| Adam | epoch: 021 | loss: 0.06438 - acc: 0.9854 -- iter: 128/180
[A[ATraining Step: 125  | total loss: [1m[32m0.07038[0m[0m | time: 37.510s
[2K
| Adam | epoch: 021 | loss: 0.07038 - acc: 0.9838 -- iter: 160/180
[A[ATraining Step: 126  | total loss: [1m[32m0.06703[0m[0m | time: 45.317s
[2K
| Adam | epoch: 021 | loss: 0.06703 - acc: 0.9854 | val_loss: 1.49730 - val_acc: 0.6667 -- iter: 180/180
--
Training Step: 127  | total loss: [1m[32m0.06189[0m[0m | time: 8.203s
[2K
| Adam | epoch: 022 | loss: 0.06189 - acc: 0.9868 -- iter: 032/180
[A[ATraining Step: 128  | total loss: [1m[32m0.06201[0m[0m | time: 16.324s
[2K
| Adam | epoch: 022 | loss: 0.06201 - acc: 0.9850 -- iter: 064/180
[A[ATraining Step: 129  | total loss: [1m[32m0.07901[0m[0m | time: 24.493s
[2K
| Adam | epoch: 022 | loss: 0.07901 - acc: 0.9834 -- iter: 096/180
[A[ATraining Step: 130  | total loss: [1m[32m0.07281[0m[0m | time: 32.787s
[2K
| Adam | epoch: 022 | loss: 0.07281 - acc: 0.9851 -- iter: 128/180
[A[ATraining Step: 131  | total loss: [1m[32m0.06703[0m[0m | time: 40.924s
[2K
| Adam | epoch: 022 | loss: 0.06703 - acc: 0.9866 -- iter: 160/180
[A[ATraining Step: 132  | total loss: [1m[32m0.06353[0m[0m | time: 48.742s
[2K
| Adam | epoch: 022 | loss: 0.06353 - acc: 0.9879 | val_loss: 0.76744 - val_acc: 0.8070 -- iter: 180/180
--
Training Step: 133  | total loss: [1m[32m0.07300[0m[0m | time: 5.255s
[2K
| Adam | epoch: 023 | loss: 0.07300 - acc: 0.9841 -- iter: 032/180
[A[ATraining Step: 134  | total loss: [1m[32m0.06690[0m[0m | time: 13.676s
[2K
| Adam | epoch: 023 | loss: 0.06690 - acc: 0.9857 -- iter: 064/180
[A[ATraining Step: 135  | total loss: [1m[32m0.06150[0m[0m | time: 21.955s
[2K
| Adam | epoch: 023 | loss: 0.06150 - acc: 0.9871 -- iter: 096/180
[A[ATraining Step: 136  | total loss: [1m[32m0.07637[0m[0m | time: 30.658s
[2K
| Adam | epoch: 023 | loss: 0.07637 - acc: 0.9853 -- iter: 128/180
[A[ATraining Step: 137  | total loss: [1m[32m0.07687[0m[0m | time: 38.778s
[2K
| Adam | epoch: 023 | loss: 0.07687 - acc: 0.9836 -- iter: 160/180
[A[ATraining Step: 138  | total loss: [1m[32m0.07761[0m[0m | time: 49.243s
[2K
| Adam | epoch: 023 | loss: 0.07761 - acc: 0.9821 | val_loss: 1.56200 - val_acc: 0.6140 -- iter: 180/180
--
Training Step: 139  | total loss: [1m[32m0.07152[0m[0m | time: 5.385s
[2K
| Adam | epoch: 024 | loss: 0.07152 - acc: 0.9839 -- iter: 032/180
[A[ATraining Step: 140  | total loss: [1m[32m0.06588[0m[0m | time: 10.879s
[2K
| Adam | epoch: 024 | loss: 0.06588 - acc: 0.9855 -- iter: 064/180
[A[ATraining Step: 141  | total loss: [1m[32m0.06107[0m[0m | time: 19.094s
[2K
| Adam | epoch: 024 | loss: 0.06107 - acc: 0.9870 -- iter: 096/180
[A[ATraining Step: 142  | total loss: [1m[32m0.05650[0m[0m | time: 27.573s
[2K
| Adam | epoch: 024 | loss: 0.05650 - acc: 0.9883 -- iter: 128/180
[A[ATraining Step: 143  | total loss: [1m[32m0.07730[0m[0m | time: 35.757s
[2K
| Adam | epoch: 024 | loss: 0.07730 - acc: 0.9863 -- iter: 160/180
[A[ATraining Step: 144  | total loss: [1m[32m0.06994[0m[0m | time: 46.474s
[2K
| Adam | epoch: 024 | loss: 0.06994 - acc: 0.9877 | val_loss: 1.62507 - val_acc: 0.5263 -- iter: 180/180
--
Training Step: 145  | total loss: [1m[32m0.06349[0m[0m | time: 7.970s
[2K
| Adam | epoch: 025 | loss: 0.06349 - acc: 0.9889 -- iter: 032/180
[A[ATraining Step: 146  | total loss: [1m[32m0.05760[0m[0m | time: 13.449s
[2K
| Adam | epoch: 025 | loss: 0.05760 - acc: 0.9900 -- iter: 064/180
[A[ATraining Step: 147  | total loss: [1m[32m0.05433[0m[0m | time: 18.823s
[2K
| Adam | epoch: 025 | loss: 0.05433 - acc: 0.9910 -- iter: 096/180
[A[ATraining Step: 148  | total loss: [1m[32m0.05102[0m[0m | time: 26.932s
[2K
| Adam | epoch: 025 | loss: 0.05102 - acc: 0.9919 -- iter: 128/180
[A[ATraining Step: 149  | total loss: [1m[32m0.04726[0m[0m | time: 34.761s
[2K
| Adam | epoch: 025 | loss: 0.04726 - acc: 0.9927 -- iter: 160/180
[A[ATraining Step: 150  | total loss: [1m[32m0.05174[0m[0m | time: 45.490s
[2K
| Adam | epoch: 025 | loss: 0.05174 - acc: 0.9903 | val_loss: 1.17554 - val_acc: 0.6667 -- iter: 180/180
--
Training Step: 151  | total loss: [1m[32m0.04696[0m[0m | time: 8.209s
[2K
| Adam | epoch: 026 | loss: 0.04696 - acc: 0.9913 -- iter: 032/180
[A[ATraining Step: 152  | total loss: [1m[32m0.06732[0m[0m | time: 16.431s
[2K
| Adam | epoch: 026 | loss: 0.06732 - acc: 0.9859 -- iter: 064/180
[A[ATraining Step: 153  | total loss: [1m[32m0.07070[0m[0m | time: 21.735s
[2K
| Adam | epoch: 026 | loss: 0.07070 - acc: 0.9811 -- iter: 096/180
[A[ATraining Step: 154  | total loss: [1m[32m0.06475[0m[0m | time: 27.178s
[2K
| Adam | epoch: 026 | loss: 0.06475 - acc: 0.9830 -- iter: 128/180
[A[ATraining Step: 155  | total loss: [1m[32m0.05912[0m[0m | time: 35.279s
[2K
| Adam | epoch: 026 | loss: 0.05912 - acc: 0.9847 -- iter: 160/180
[A[ATraining Step: 156  | total loss: [1m[32m0.05398[0m[0m | time: 45.870s
[2K
| Adam | epoch: 026 | loss: 0.05398 - acc: 0.9862 | val_loss: 0.69000 - val_acc: 0.8070 -- iter: 180/180
--
Training Step: 157  | total loss: [1m[32m0.08054[0m[0m | time: 8.157s
[2K
| Adam | epoch: 027 | loss: 0.08054 - acc: 0.9813 -- iter: 032/180
[A[ATraining Step: 158  | total loss: [1m[32m0.07290[0m[0m | time: 16.307s
[2K
| Adam | epoch: 027 | loss: 0.07290 - acc: 0.9832 -- iter: 064/180
[A[ATraining Step: 159  | total loss: [1m[32m0.06752[0m[0m | time: 24.520s
[2K
| Adam | epoch: 027 | loss: 0.06752 - acc: 0.9849 -- iter: 096/180
[A[ATraining Step: 160  | total loss: [1m[32m0.06115[0m[0m | time: 29.831s
[2K
| Adam | epoch: 027 | loss: 0.06115 - acc: 0.9864 -- iter: 128/180
[A[ATraining Step: 161  | total loss: [1m[32m0.05562[0m[0m | time: 35.224s
[2K
| Adam | epoch: 027 | loss: 0.05562 - acc: 0.9878 -- iter: 160/180
[A[ATraining Step: 162  | total loss: [1m[32m0.05082[0m[0m | time: 45.937s
[2K
| Adam | epoch: 027 | loss: 0.05082 - acc: 0.9890 | val_loss: 1.08943 - val_acc: 0.7719 -- iter: 180/180
--
Training Step: 163  | total loss: [1m[32m0.04665[0m[0m | time: 8.143s
[2K
| Adam | epoch: 028 | loss: 0.04665 - acc: 0.9901 -- iter: 032/180
[A[ATraining Step: 164  | total loss: [1m[32m0.08417[0m[0m | time: 16.245s
[2K
| Adam | epoch: 028 | loss: 0.08417 - acc: 0.9848 -- iter: 064/180
[A[ATraining Step: 165  | total loss: [1m[32m0.08961[0m[0m | time: 24.293s
[2K
| Adam | epoch: 028 | loss: 0.08961 - acc: 0.9832 -- iter: 096/180
[A[ATraining Step: 166  | total loss: [1m[32m0.08129[0m[0m | time: 32.498s
[2K
| Adam | epoch: 028 | loss: 0.08129 - acc: 0.9849 -- iter: 128/180
[A[ATraining Step: 167  | total loss: [1m[32m0.07852[0m[0m | time: 37.793s
[2K
| Adam | epoch: 028 | loss: 0.07852 - acc: 0.9833 -- iter: 160/180
[A[ATraining Step: 168  | total loss: [1m[32m0.07154[0m[0m | time: 46.931s
[2K
| Adam | epoch: 028 | loss: 0.07154 - acc: 0.9850 | val_loss: 0.85796 - val_acc: 0.8070 -- iter: 180/180
--
Training Step: 169  | total loss: [1m[32m0.06536[0m[0m | time: 14.457s
[2K
| Adam | epoch: 029 | loss: 0.06536 - acc: 0.9865 -- iter: 032/180
[A[ATraining Step: 170  | total loss: [1m[32m0.06262[0m[0m | time: 26.475s
[2K
| Adam | epoch: 029 | loss: 0.06262 - acc: 0.9878 -- iter: 064/180
[A[ATraining Step: 171  | total loss: [1m[32m0.08988[0m[0m | time: 40.720s
[2K
| Adam | epoch: 029 | loss: 0.08988 - acc: 0.9828 -- iter: 096/180
[A[ATraining Step: 172  | total loss: [1m[32m0.08468[0m[0m | time: 53.830s
[2K
| Adam | epoch: 029 | loss: 0.08468 - acc: 0.9845 -- iter: 128/180
[A[ATraining Step: 173  | total loss: [1m[32m0.07810[0m[0m | time: 66.625s
[2K
| Adam | epoch: 029 | loss: 0.07810 - acc: 0.9861 -- iter: 160/180
[A[ATraining Step: 174  | total loss: [1m[32m0.07149[0m[0m | time: 76.680s
[2K
| Adam | epoch: 029 | loss: 0.07149 - acc: 0.9874 | val_loss: 0.75482 - val_acc: 0.8070 -- iter: 180/180
--
Training Step: 175  | total loss: [1m[32m0.06913[0m[0m | time: 6.565s
[2K
| Adam | epoch: 030 | loss: 0.06913 - acc: 0.9887 -- iter: 032/180
[A[ATraining Step: 176  | total loss: [1m[32m0.06453[0m[0m | time: 16.879s
[2K
| Adam | epoch: 030 | loss: 0.06453 - acc: 0.9898 -- iter: 064/180
[A[ATraining Step: 177  | total loss: [1m[32m0.05899[0m[0m | time: 26.790s
[2K
| Adam | epoch: 030 | loss: 0.05899 - acc: 0.9908 -- iter: 096/180
[A[ATraining Step: 178  | total loss: [1m[32m0.06905[0m[0m | time: 36.721s
[2K
| Adam | epoch: 030 | loss: 0.06905 - acc: 0.9886 -- iter: 128/180
[A[ATraining Step: 179  | total loss: [1m[32m0.06332[0m[0m | time: 46.742s
[2K
| Adam | epoch: 030 | loss: 0.06332 - acc: 0.9898 -- iter: 160/180
[A[ATraining Step: 180  | total loss: [1m[32m0.05847[0m[0m | time: 60.529s
[2K
| Adam | epoch: 030 | loss: 0.05847 - acc: 0.9908 | val_loss: 0.81962 - val_acc: 0.7719 -- iter: 180/180
--
Validation AUC:0.8682266009852218
Validation AUPRC:0.8531332230609534
Test AUC:0.8876543209876543
Test AUPRC:0.8718085527801682
BestTestF1Score	0.86	0.73	0.86	0.81	0.93	25	6	24	2	0.82
BestTestMCCScore	0.86	0.73	0.86	0.81	0.93	25	6	24	2	0.94
BestTestAccuracyScore	0.86	0.73	0.86	0.81	0.93	25	6	24	2	0.94
BestValidationF1Score	0.85	0.68	0.84	0.83	0.86	25	5	23	4	0.82
BestValidationMCC	0.84	0.68	0.84	0.86	0.83	24	4	24	5	0.94
BestValidationAccuracy	0.84	0.68	0.84	0.86	0.83	24	4	24	5	0.94
TestPredictions (Threshold:0.94)
CHEMBL325307,TP,ACT,1.0	CHEMBL3264604,TP,ACT,1.0	CHEMBL8659,TN,INACT,0.07000000029802322	CHEMBL1766192,TP,ACT,0.9599999785423279	CHEMBL74661,TP,ACT,1.0	CHEMBL3664715,TN,INACT,0.009999999776482582	CHEMBL325895,TP,ACT,1.0	CHEMBL78395,TN,INACT,0.0	CHEMBL223983,TN,INACT,0.0	CHEMBL3264600,TP,ACT,1.0	CHEMBL454580,FP,INACT,0.9900000095367432	CHEMBL14192,TN,INACT,0.009999999776482582	CHEMBL3105527,TN,INACT,0.49000000953674316	CHEMBL1682905,TP,ACT,0.949999988079071	CHEMBL295698,FN,ACT,0.23999999463558197	CHEMBL2431525,TN,INACT,0.6200000047683716	CHEMBL1766184,TP,ACT,0.9800000190734863	CHEMBL3105521,TN,INACT,0.3100000023841858	CHEMBL465879,TN,INACT,0.7799999713897705	CHEMBL1222922,TP,ACT,0.949999988079071	CHEMBL1766187,TP,ACT,0.9900000095367432	CHEMBL3105520,TN,INACT,0.28999999165534973	CHEMBL1784790,FP,INACT,1.0	CHEMBL2112782,TP,ACT,1.0	CHEMBL1766173,TP,ACT,1.0	CHEMBL328546,TN,INACT,0.5199999809265137	CHEMBL1766176,TP,ACT,0.9900000095367432	CHEMBL377770,FP,INACT,1.0	CHEMBL3699082,FP,INACT,0.9900000095367432	CHEMBL361153,TN,INACT,0.0	CHEMBL3689756,FP,INACT,1.0	CHEMBL1915151,TN,INACT,0.019999999552965164	CHEMBL3664677,TN,INACT,0.029999999329447746	CHEMBL1682900,TP,ACT,0.9900000095367432	CHEMBL1766181,TP,ACT,1.0	CHEMBL419934,TP,ACT,1.0	CHEMBL39782,TN,INACT,0.10000000149011612	CHEMBL427399,TP,ACT,1.0	CHEMBL319026,FN,ACT,0.5199999809265137	CHEMBL113407,TP,ACT,1.0	CHEMBL1682901,TP,ACT,0.9700000286102295	CHEMBL3645513,TN,INACT,0.05999999865889549	CHEMBL1766189,TP,ACT,0.9900000095367432	CHEMBL1682903,TP,ACT,0.9900000095367432	CHEMBL3753182,TN,INACT,0.05000000074505806	CHEMBL78215,TP,ACT,1.0	CHEMBL310822,TP,ACT,1.0	CHEMBL2431524,TN,INACT,0.4099999964237213	CHEMBL115944,TP,ACT,1.0	CHEMBL565406,TN,INACT,0.0	CHEMBL1165711,FP,INACT,1.0	CHEMBL8273,TN,INACT,0.6200000047683716	CHEMBL1766178,TP,ACT,1.0	CHEMBL3702760,TN,INACT,0.029999999329447746	CHEMBL1824762,TN,INACT,0.029999999329447746	CHEMBL3702684,TN,INACT,0.009999999776482582	CHEMBL304903,TN,INACT,0.019999999552965164	

