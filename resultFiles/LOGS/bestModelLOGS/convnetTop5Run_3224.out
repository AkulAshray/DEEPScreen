ImageNetInceptionV2 CHEMBL2871 RMSprop 0.001 15 0 0 0.6 False True
Number of active compounds :	1011
Number of inactive compounds :	1011
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2871_RMSprop_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2871_RMSprop_0.001_15_0.6/
---------------------------------
Training samples: 1234
Validation samples: 386
--
Training Step: 1  | time: 72.022s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1234
[A[ATraining Step: 2  | total loss: [1m[32m0.63116[0m[0m | time: 92.314s
[2K
| RMSProp | epoch: 001 | loss: 0.63116 - acc: 0.4219 -- iter: 0064/1234
[A[ATraining Step: 3  | total loss: [1m[32m0.70664[0m[0m | time: 109.476s
[2K
| RMSProp | epoch: 001 | loss: 0.70664 - acc: 0.4602 -- iter: 0096/1234
[A[ATraining Step: 4  | total loss: [1m[32m0.71547[0m[0m | time: 130.842s
[2K
| RMSProp | epoch: 001 | loss: 0.71547 - acc: 0.4901 -- iter: 0128/1234
[A[ATraining Step: 5  | total loss: [1m[32m0.74486[0m[0m | time: 147.545s
[2K
| RMSProp | epoch: 001 | loss: 0.74486 - acc: 0.4104 -- iter: 0160/1234
[A[ATraining Step: 6  | total loss: [1m[32m0.71322[0m[0m | time: 166.033s
[2K
| RMSProp | epoch: 001 | loss: 0.71322 - acc: 0.5082 -- iter: 0192/1234
[A[ATraining Step: 7  | total loss: [1m[32m0.69462[0m[0m | time: 182.466s
[2K
| RMSProp | epoch: 001 | loss: 0.69462 - acc: 0.5783 -- iter: 0224/1234
[A[ATraining Step: 8  | total loss: [1m[32m0.73480[0m[0m | time: 199.773s
[2K
| RMSProp | epoch: 001 | loss: 0.73480 - acc: 0.4112 -- iter: 0256/1234
[A[ATraining Step: 9  | total loss: [1m[32m0.69313[0m[0m | time: 217.280s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5078 -- iter: 0288/1234
[A[ATraining Step: 10  | total loss: [1m[32m0.67962[0m[0m | time: 228.760s
[2K
| RMSProp | epoch: 001 | loss: 0.67962 - acc: 0.5664 -- iter: 0320/1234
[A[ATraining Step: 11  | total loss: [1m[32m0.68555[0m[0m | time: 236.913s
[2K
| RMSProp | epoch: 001 | loss: 0.68555 - acc: 0.5498 -- iter: 0352/1234
[A[ATraining Step: 12  | total loss: [1m[32m0.68573[0m[0m | time: 249.233s
[2K
| RMSProp | epoch: 001 | loss: 0.68573 - acc: 0.5555 -- iter: 0384/1234
[A[ATraining Step: 13  | total loss: [1m[32m0.70780[0m[0m | time: 257.756s
[2K
| RMSProp | epoch: 001 | loss: 0.70780 - acc: 0.5049 -- iter: 0416/1234
[A[ATraining Step: 14  | total loss: [1m[32m0.70081[0m[0m | time: 265.912s
[2K
| RMSProp | epoch: 001 | loss: 0.70081 - acc: 0.4901 -- iter: 0448/1234
[A[ATraining Step: 15  | total loss: [1m[32m0.70602[0m[0m | time: 274.102s
[2K
| RMSProp | epoch: 001 | loss: 0.70602 - acc: 0.4940 -- iter: 0480/1234
[A[ATraining Step: 16  | total loss: [1m[32m0.67151[0m[0m | time: 282.068s
[2K
| RMSProp | epoch: 001 | loss: 0.67151 - acc: 0.5666 -- iter: 0512/1234
[A[ATraining Step: 17  | total loss: [1m[32m0.67710[0m[0m | time: 290.645s
[2K
| RMSProp | epoch: 001 | loss: 0.67710 - acc: 0.5313 -- iter: 0544/1234
[A[ATraining Step: 18  | total loss: [1m[32m0.68374[0m[0m | time: 303.193s
[2K
| RMSProp | epoch: 001 | loss: 0.68374 - acc: 0.5421 -- iter: 0576/1234
[A[ATraining Step: 19  | total loss: [1m[32m0.69186[0m[0m | time: 316.282s
[2K
| RMSProp | epoch: 001 | loss: 0.69186 - acc: 0.5281 -- iter: 0608/1234
[A[ATraining Step: 20  | total loss: [1m[32m0.69524[0m[0m | time: 329.689s
[2K
| RMSProp | epoch: 001 | loss: 0.69524 - acc: 0.5391 -- iter: 0640/1234
[A[ATraining Step: 21  | total loss: [1m[32m0.68010[0m[0m | time: 343.107s
[2K
| RMSProp | epoch: 001 | loss: 0.68010 - acc: 0.5658 -- iter: 0672/1234
[A[ATraining Step: 22  | total loss: [1m[32m0.68573[0m[0m | time: 356.401s
[2K
| RMSProp | epoch: 001 | loss: 0.68573 - acc: 0.5367 -- iter: 0704/1234
[A[ATraining Step: 23  | total loss: [1m[32m0.70359[0m[0m | time: 369.612s
[2K
| RMSProp | epoch: 001 | loss: 0.70359 - acc: 0.5170 -- iter: 0736/1234
[A[ATraining Step: 24  | total loss: [1m[32m0.69690[0m[0m | time: 382.780s
[2K
| RMSProp | epoch: 001 | loss: 0.69690 - acc: 0.5473 -- iter: 0768/1234
[A[ATraining Step: 25  | total loss: [1m[32m0.70137[0m[0m | time: 396.629s
[2K
| RMSProp | epoch: 001 | loss: 0.70137 - acc: 0.5515 -- iter: 0800/1234
[A[ATraining Step: 26  | total loss: [1m[32m0.69730[0m[0m | time: 410.155s
[2K
| RMSProp | epoch: 001 | loss: 0.69730 - acc: 0.5461 -- iter: 0832/1234
[A[ATraining Step: 27  | total loss: [1m[32m0.66818[0m[0m | time: 424.646s
[2K
| RMSProp | epoch: 001 | loss: 0.66818 - acc: 0.5825 -- iter: 0864/1234
[A[ATraining Step: 28  | total loss: [1m[32m0.65885[0m[0m | time: 438.649s
[2K
| RMSProp | epoch: 001 | loss: 0.65885 - acc: 0.5853 -- iter: 0896/1234
[A[ATraining Step: 29  | total loss: [1m[32m0.66623[0m[0m | time: 452.537s
[2K
| RMSProp | epoch: 001 | loss: 0.66623 - acc: 0.5950 -- iter: 0928/1234
[A[ATraining Step: 30  | total loss: [1m[32m0.66967[0m[0m | time: 466.032s
[2K
| RMSProp | epoch: 001 | loss: 0.66967 - acc: 0.6021 -- iter: 0960/1234
[A[ATraining Step: 31  | total loss: [1m[32m0.65163[0m[0m | time: 479.477s
[2K
| RMSProp | epoch: 001 | loss: 0.65163 - acc: 0.6434 -- iter: 0992/1234
[A[ATraining Step: 32  | total loss: [1m[32m0.64213[0m[0m | time: 488.880s
[2K
| RMSProp | epoch: 001 | loss: 0.64213 - acc: 0.6604 -- iter: 1024/1234
[A[ATraining Step: 33  | total loss: [1m[32m0.63547[0m[0m | time: 497.341s
[2K
| RMSProp | epoch: 001 | loss: 0.63547 - acc: 0.6595 -- iter: 1056/1234
[A[ATraining Step: 34  | total loss: [1m[32m0.66005[0m[0m | time: 506.443s
[2K
| RMSProp | epoch: 001 | loss: 0.66005 - acc: 0.6119 -- iter: 1088/1234
[A[ATraining Step: 35  | total loss: [1m[32m0.66943[0m[0m | time: 518.506s
[2K
| RMSProp | epoch: 001 | loss: 0.66943 - acc: 0.5950 -- iter: 1120/1234
[A[ATraining Step: 36  | total loss: [1m[32m0.67005[0m[0m | time: 532.033s
[2K
| RMSProp | epoch: 001 | loss: 0.67005 - acc: 0.5820 -- iter: 1152/1234
[A[ATraining Step: 37  | total loss: [1m[32m0.67234[0m[0m | time: 545.379s
[2K
| RMSProp | epoch: 001 | loss: 0.67234 - acc: 0.5718 -- iter: 1184/1234
[A[ATraining Step: 38  | total loss: [1m[32m0.66342[0m[0m | time: 559.278s
[2K
| RMSProp | epoch: 001 | loss: 0.66342 - acc: 0.5761 -- iter: 1216/1234
[A[ATraining Step: 39  | total loss: [1m[32m0.66181[0m[0m | time: 610.709s
[2K
| RMSProp | epoch: 001 | loss: 0.66181 - acc: 0.5735 | val_loss: 0.72481 - val_acc: 0.5337 -- iter: 1234/1234
--
Training Step: 40  | total loss: [1m[32m0.65958[0m[0m | time: 8.686s
[2K
| RMSProp | epoch: 002 | loss: 0.65958 - acc: 0.5701 -- iter: 0032/1234
[A[ATraining Step: 41  | total loss: [1m[32m0.63126[0m[0m | time: 18.834s
[2K
| RMSProp | epoch: 002 | loss: 0.63126 - acc: 0.6185 -- iter: 0064/1234
[A[ATraining Step: 42  | total loss: [1m[32m0.63043[0m[0m | time: 27.459s
[2K
| RMSProp | epoch: 002 | loss: 0.63043 - acc: 0.6309 -- iter: 0096/1234
[A[ATraining Step: 43  | total loss: [1m[32m0.63107[0m[0m | time: 36.318s
[2K
| RMSProp | epoch: 002 | loss: 0.63107 - acc: 0.6299 -- iter: 0128/1234
[A[ATraining Step: 44  | total loss: [1m[32m0.62644[0m[0m | time: 48.004s
[2K
| RMSProp | epoch: 002 | loss: 0.62644 - acc: 0.6398 -- iter: 0160/1234
[A[ATraining Step: 45  | total loss: [1m[32m0.62927[0m[0m | time: 60.199s
[2K
| RMSProp | epoch: 002 | loss: 0.62927 - acc: 0.6373 -- iter: 0192/1234
[A[ATraining Step: 46  | total loss: [1m[32m0.63831[0m[0m | time: 72.846s
[2K
| RMSProp | epoch: 002 | loss: 0.63831 - acc: 0.6301 -- iter: 0224/1234
[A[ATraining Step: 47  | total loss: [1m[32m0.64879[0m[0m | time: 86.272s
[2K
| RMSProp | epoch: 002 | loss: 0.64879 - acc: 0.6190 -- iter: 0256/1234
[A[ATraining Step: 48  | total loss: [1m[32m0.63900[0m[0m | time: 100.210s
[2K
| RMSProp | epoch: 002 | loss: 0.63900 - acc: 0.6250 -- iter: 0288/1234
[A[ATraining Step: 49  | total loss: [1m[32m0.64081[0m[0m | time: 114.171s
[2K
| RMSProp | epoch: 002 | loss: 0.64081 - acc: 0.6151 -- iter: 0320/1234
[A[ATraining Step: 50  | total loss: [1m[32m0.62071[0m[0m | time: 127.499s
[2K
| RMSProp | epoch: 002 | loss: 0.62071 - acc: 0.6554 -- iter: 0352/1234
[A[ATraining Step: 51  | total loss: [1m[32m0.60563[0m[0m | time: 141.509s
[2K
| RMSProp | epoch: 002 | loss: 0.60563 - acc: 0.6651 -- iter: 0384/1234
[A[ATraining Step: 52  | total loss: [1m[32m0.62211[0m[0m | time: 155.094s
[2K
| RMSProp | epoch: 002 | loss: 0.62211 - acc: 0.6403 -- iter: 0416/1234
[A[ATraining Step: 53  | total loss: [1m[32m0.63878[0m[0m | time: 168.961s
[2K
| RMSProp | epoch: 002 | loss: 0.63878 - acc: 0.6242 -- iter: 0448/1234
[A[ATraining Step: 54  | total loss: [1m[32m0.63221[0m[0m | time: 182.427s
[2K
| RMSProp | epoch: 002 | loss: 0.63221 - acc: 0.6334 -- iter: 0480/1234
[A[ATraining Step: 55  | total loss: [1m[32m0.62936[0m[0m | time: 196.677s
[2K
| RMSProp | epoch: 002 | loss: 0.62936 - acc: 0.6278 -- iter: 0512/1234
[A[ATraining Step: 56  | total loss: [1m[32m0.62422[0m[0m | time: 210.724s
[2K
| RMSProp | epoch: 002 | loss: 0.62422 - acc: 0.6274 -- iter: 0544/1234
[A[ATraining Step: 57  | total loss: [1m[32m0.62537[0m[0m | time: 224.385s
[2K
| RMSProp | epoch: 002 | loss: 0.62537 - acc: 0.6141 -- iter: 0576/1234
[A[ATraining Step: 58  | total loss: [1m[32m0.62548[0m[0m | time: 234.630s
[2K
| RMSProp | epoch: 002 | loss: 0.62548 - acc: 0.6283 -- iter: 0608/1234
[A[ATraining Step: 59  | total loss: [1m[32m0.61869[0m[0m | time: 243.511s
[2K
| RMSProp | epoch: 002 | loss: 0.61869 - acc: 0.6321 -- iter: 0640/1234
[A[ATraining Step: 60  | total loss: [1m[32m0.61591[0m[0m | time: 252.271s
[2K
| RMSProp | epoch: 002 | loss: 0.61591 - acc: 0.6353 -- iter: 0672/1234
[A[ATraining Step: 61  | total loss: [1m[32m0.61738[0m[0m | time: 261.266s
[2K
| RMSProp | epoch: 002 | loss: 0.61738 - acc: 0.6462 -- iter: 0704/1234
[A[ATraining Step: 62  | total loss: [1m[32m0.63272[0m[0m | time: 274.195s
[2K
| RMSProp | epoch: 002 | loss: 0.63272 - acc: 0.6274 -- iter: 0736/1234
[A[ATraining Step: 63  | total loss: [1m[32m0.64267[0m[0m | time: 287.954s
[2K
| RMSProp | epoch: 002 | loss: 0.64267 - acc: 0.6271 -- iter: 0768/1234
[A[ATraining Step: 64  | total loss: [1m[32m0.63428[0m[0m | time: 299.944s
[2K
| RMSProp | epoch: 002 | loss: 0.63428 - acc: 0.6385 -- iter: 0800/1234
[A[ATraining Step: 65  | total loss: [1m[32m0.62340[0m[0m | time: 313.314s
[2K
| RMSProp | epoch: 002 | loss: 0.62340 - acc: 0.6484 -- iter: 0832/1234
[A[ATraining Step: 66  | total loss: [1m[32m0.61448[0m[0m | time: 327.064s
[2K
| RMSProp | epoch: 002 | loss: 0.61448 - acc: 0.6722 -- iter: 0864/1234
[A[ATraining Step: 67  | total loss: [1m[32m0.62335[0m[0m | time: 340.478s
[2K
| RMSProp | epoch: 002 | loss: 0.62335 - acc: 0.6665 -- iter: 0896/1234
[A[ATraining Step: 68  | total loss: [1m[32m0.59699[0m[0m | time: 354.145s
[2K
| RMSProp | epoch: 002 | loss: 0.59699 - acc: 0.6912 -- iter: 0928/1234
[A[ATraining Step: 69  | total loss: [1m[32m0.58922[0m[0m | time: 367.712s
[2K
| RMSProp | epoch: 002 | loss: 0.58922 - acc: 0.6944 -- iter: 0960/1234
[A[ATraining Step: 70  | total loss: [1m[32m0.58348[0m[0m | time: 381.375s
[2K
| RMSProp | epoch: 002 | loss: 0.58348 - acc: 0.7008 -- iter: 0992/1234
[A[ATraining Step: 71  | total loss: [1m[32m0.58932[0m[0m | time: 395.175s
[2K
| RMSProp | epoch: 002 | loss: 0.58932 - acc: 0.7029 -- iter: 1024/1234
[A[ATraining Step: 72  | total loss: [1m[32m0.58665[0m[0m | time: 409.091s
[2K
| RMSProp | epoch: 002 | loss: 0.58665 - acc: 0.7011 -- iter: 1056/1234
[A[ATraining Step: 73  | total loss: [1m[32m0.55739[0m[0m | time: 422.941s
[2K
| RMSProp | epoch: 002 | loss: 0.55739 - acc: 0.7274 -- iter: 1088/1234
[A[ATraining Step: 74  | total loss: [1m[32m0.57682[0m[0m | time: 437.028s
[2K
| RMSProp | epoch: 002 | loss: 0.57682 - acc: 0.7265 -- iter: 1120/1234
[A[ATraining Step: 75  | total loss: [1m[32m0.58841[0m[0m | time: 450.705s
[2K
| RMSProp | epoch: 002 | loss: 0.58841 - acc: 0.7121 -- iter: 1152/1234
[A[ATraining Step: 76  | total loss: [1m[32m0.56925[0m[0m | time: 461.045s
[2K
| RMSProp | epoch: 002 | loss: 0.56925 - acc: 0.7262 -- iter: 1184/1234
[A[ATraining Step: 77  | total loss: [1m[32m0.57511[0m[0m | time: 469.852s
[2K
| RMSProp | epoch: 002 | loss: 0.57511 - acc: 0.7320 -- iter: 1216/1234
[A[ATraining Step: 78  | total loss: [1m[32m0.57358[0m[0m | time: 499.034s
[2K
| RMSProp | epoch: 002 | loss: 0.57358 - acc: 0.7241 | val_loss: 0.62977 - val_acc: 0.6606 -- iter: 1234/1234
--
Training Step: 79  | total loss: [1m[32m0.56579[0m[0m | time: 8.845s
[2K
| RMSProp | epoch: 003 | loss: 0.56579 - acc: 0.7300 -- iter: 0032/1234
[A[ATraining Step: 80  | total loss: [1m[32m0.55123[0m[0m | time: 17.224s
[2K
| RMSProp | epoch: 003 | loss: 0.55123 - acc: 0.7406 -- iter: 0064/1234
[A[ATraining Step: 81  | total loss: [1m[32m0.51113[0m[0m | time: 33.065s
[2K
| RMSProp | epoch: 003 | loss: 0.51113 - acc: 0.7668 -- iter: 0096/1234
[A[ATraining Step: 82  | total loss: [1m[32m0.50207[0m[0m | time: 50.614s
[2K
| RMSProp | epoch: 003 | loss: 0.50207 - acc: 0.7714 -- iter: 0128/1234
[A[ATraining Step: 83  | total loss: [1m[32m0.49020[0m[0m | time: 78.369s
[2K
| RMSProp | epoch: 003 | loss: 0.49020 - acc: 0.7786 -- iter: 0160/1234
[A[ATraining Step: 84  | total loss: [1m[32m0.49695[0m[0m | time: 99.845s
[2K
| RMSProp | epoch: 003 | loss: 0.49695 - acc: 0.7789 -- iter: 0192/1234
[A[ATraining Step: 85  | total loss: [1m[32m0.52146[0m[0m | time: 141.888s
[2K
| RMSProp | epoch: 003 | loss: 0.52146 - acc: 0.7791 -- iter: 0224/1234
[A[ATraining Step: 86  | total loss: [1m[32m0.51798[0m[0m | time: 168.941s
[2K
| RMSProp | epoch: 003 | loss: 0.51798 - acc: 0.7762 -- iter: 0256/1234
[A[ATraining Step: 87  | total loss: [1m[32m0.52788[0m[0m | time: 190.923s
[2K
| RMSProp | epoch: 003 | loss: 0.52788 - acc: 0.7611 -- iter: 0288/1234
[A[ATraining Step: 88  | total loss: [1m[32m0.55763[0m[0m | time: 203.684s
[2K
| RMSProp | epoch: 003 | loss: 0.55763 - acc: 0.7412 -- iter: 0320/1234
[A[ATraining Step: 89  | total loss: [1m[32m0.55783[0m[0m | time: 212.411s
[2K
| RMSProp | epoch: 003 | loss: 0.55783 - acc: 0.7358 -- iter: 0352/1234
[A[ATraining Step: 90  | total loss: [1m[32m0.56580[0m[0m | time: 221.064s
[2K
| RMSProp | epoch: 003 | loss: 0.56580 - acc: 0.7248 -- iter: 0384/1234
[A[ATraining Step: 91  | total loss: [1m[32m0.54381[0m[0m | time: 232.494s
[2K
| RMSProp | epoch: 003 | loss: 0.54381 - acc: 0.7398 -- iter: 0416/1234
[A[ATraining Step: 92  | total loss: [1m[32m0.55633[0m[0m | time: 245.903s
[2K
| RMSProp | epoch: 003 | loss: 0.55633 - acc: 0.7346 -- iter: 0448/1234
[A[ATraining Step: 93  | total loss: [1m[32m0.55341[0m[0m | time: 259.256s
[2K
| RMSProp | epoch: 003 | loss: 0.55341 - acc: 0.7330 -- iter: 0480/1234
[A[ATraining Step: 94  | total loss: [1m[32m0.53787[0m[0m | time: 273.062s
[2K
| RMSProp | epoch: 003 | loss: 0.53787 - acc: 0.7441 -- iter: 0512/1234
[A[ATraining Step: 95  | total loss: [1m[32m0.54108[0m[0m | time: 285.840s
[2K
| RMSProp | epoch: 003 | loss: 0.54108 - acc: 0.7446 -- iter: 0544/1234
[A[ATraining Step: 96  | total loss: [1m[32m0.54009[0m[0m | time: 298.772s
[2K
| RMSProp | epoch: 003 | loss: 0.54009 - acc: 0.7452 -- iter: 0576/1234
[A[ATraining Step: 97  | total loss: [1m[32m0.54578[0m[0m | time: 312.344s
[2K
| RMSProp | epoch: 003 | loss: 0.54578 - acc: 0.7519 -- iter: 0608/1234
[A[ATraining Step: 98  | total loss: [1m[32m0.55156[0m[0m | time: 326.131s
[2K
| RMSProp | epoch: 003 | loss: 0.55156 - acc: 0.7392 -- iter: 0640/1234
[A[ATraining Step: 99  | total loss: [1m[32m0.59431[0m[0m | time: 339.668s
[2K
| RMSProp | epoch: 003 | loss: 0.59431 - acc: 0.7216 -- iter: 0672/1234
[A[ATraining Step: 100  | total loss: [1m[32m0.59093[0m[0m | time: 353.095s
[2K
| RMSProp | epoch: 003 | loss: 0.59093 - acc: 0.7181 -- iter: 0704/1234
[A[ATraining Step: 101  | total loss: [1m[32m0.57198[0m[0m | time: 366.690s
[2K
| RMSProp | epoch: 003 | loss: 0.57198 - acc: 0.7276 -- iter: 0736/1234
[A[ATraining Step: 102  | total loss: [1m[32m0.55294[0m[0m | time: 379.803s
[2K
| RMSProp | epoch: 003 | loss: 0.55294 - acc: 0.7392 -- iter: 0768/1234
[A[ATraining Step: 103  | total loss: [1m[32m0.53426[0m[0m | time: 392.979s
[2K
| RMSProp | epoch: 003 | loss: 0.53426 - acc: 0.7497 -- iter: 0800/1234
[A[ATraining Step: 104  | total loss: [1m[32m0.52923[0m[0m | time: 407.920s
[2K
| RMSProp | epoch: 003 | loss: 0.52923 - acc: 0.7434 -- iter: 0832/1234
[A[ATraining Step: 105  | total loss: [1m[32m0.51285[0m[0m | time: 423.825s
[2K
| RMSProp | epoch: 003 | loss: 0.51285 - acc: 0.7503 -- iter: 0864/1234
[A[ATraining Step: 106  | total loss: [1m[32m0.51231[0m[0m | time: 436.222s
[2K
| RMSProp | epoch: 003 | loss: 0.51231 - acc: 0.7566 -- iter: 0896/1234
[A[ATraining Step: 107  | total loss: [1m[32m0.50411[0m[0m | time: 450.411s
[2K
| RMSProp | epoch: 003 | loss: 0.50411 - acc: 0.7622 -- iter: 0928/1234
[A[ATraining Step: 108  | total loss: [1m[32m0.50003[0m[0m | time: 468.480s
[2K
| RMSProp | epoch: 003 | loss: 0.50003 - acc: 0.7578 -- iter: 0960/1234
[A[ATraining Step: 109  | total loss: [1m[32m0.48806[0m[0m | time: 486.027s
[2K
| RMSProp | epoch: 003 | loss: 0.48806 - acc: 0.7664 -- iter: 0992/1234
[A[ATraining Step: 110  | total loss: [1m[32m0.49740[0m[0m | time: 503.350s
[2K
| RMSProp | epoch: 003 | loss: 0.49740 - acc: 0.7554 -- iter: 1024/1234
[A[ATraining Step: 111  | total loss: [1m[32m0.49064[0m[0m | time: 520.903s
[2K
| RMSProp | epoch: 003 | loss: 0.49064 - acc: 0.7580 -- iter: 1056/1234
[A[ATraining Step: 112  | total loss: [1m[32m0.47249[0m[0m | time: 540.489s
[2K
| RMSProp | epoch: 003 | loss: 0.47249 - acc: 0.7666 -- iter: 1088/1234
[A[ATraining Step: 113  | total loss: [1m[32m0.48661[0m[0m | time: 557.916s
[2K
| RMSProp | epoch: 003 | loss: 0.48661 - acc: 0.7649 -- iter: 1120/1234
[A[ATraining Step: 114  | total loss: [1m[32m0.49499[0m[0m | time: 588.978s
[2K
| RMSProp | epoch: 003 | loss: 0.49499 - acc: 0.7665 -- iter: 1152/1234
[A[ATraining Step: 115  | total loss: [1m[32m0.47529[0m[0m | time: 627.990s
[2K
| RMSProp | epoch: 003 | loss: 0.47529 - acc: 0.7743 -- iter: 1184/1234
[A[ATraining Step: 116  | total loss: [1m[32m0.48273[0m[0m | time: 660.370s
[2K
| RMSProp | epoch: 003 | loss: 0.48273 - acc: 0.7812 -- iter: 1216/1234
[A[ATraining Step: 117  | total loss: [1m[32m0.47740[0m[0m | time: 734.196s
[2K
| RMSProp | epoch: 003 | loss: 0.47740 - acc: 0.7843 | val_loss: 8.36265 - val_acc: 0.5337 -- iter: 1234/1234
--
Training Step: 118  | total loss: [1m[32m0.48640[0m[0m | time: 11.721s
[2K
| RMSProp | epoch: 004 | loss: 0.48640 - acc: 0.7840 -- iter: 0032/1234
[A[ATraining Step: 119  | total loss: [1m[32m0.47991[0m[0m | time: 19.299s
[2K
| RMSProp | epoch: 004 | loss: 0.47991 - acc: 0.7900 -- iter: 0064/1234
[A[ATraining Step: 120  | total loss: [1m[32m0.49488[0m[0m | time: 29.812s
[2K
| RMSProp | epoch: 004 | loss: 0.49488 - acc: 0.7777 -- iter: 0096/1234
[A[ATraining Step: 121  | total loss: [1m[32m0.49956[0m[0m | time: 46.016s
[2K
| RMSProp | epoch: 004 | loss: 0.49956 - acc: 0.7888 -- iter: 0128/1234
[A[ATraining Step: 122  | total loss: [1m[32m0.52269[0m[0m | time: 62.640s
[2K
| RMSProp | epoch: 004 | loss: 0.52269 - acc: 0.7818 -- iter: 0160/1234
[A[ATraining Step: 123  | total loss: [1m[32m0.55894[0m[0m | time: 78.640s
[2K
| RMSProp | epoch: 004 | loss: 0.55894 - acc: 0.7567 -- iter: 0192/1234
[A[ATraining Step: 124  | total loss: [1m[32m0.55720[0m[0m | time: 95.054s
[2K
| RMSProp | epoch: 004 | loss: 0.55720 - acc: 0.7561 -- iter: 0224/1234
[A[ATraining Step: 125  | total loss: [1m[32m0.56109[0m[0m | time: 111.455s
[2K
| RMSProp | epoch: 004 | loss: 0.56109 - acc: 0.7492 -- iter: 0256/1234
[A[ATraining Step: 126  | total loss: [1m[32m0.56663[0m[0m | time: 126.562s
[2K
| RMSProp | epoch: 004 | loss: 0.56663 - acc: 0.7368 -- iter: 0288/1234
[A[ATraining Step: 127  | total loss: [1m[32m0.53830[0m[0m | time: 141.997s
[2K
| RMSProp | epoch: 004 | loss: 0.53830 - acc: 0.7569 -- iter: 0320/1234
[A[ATraining Step: 128  | total loss: [1m[32m0.51785[0m[0m | time: 158.763s
[2K
| RMSProp | epoch: 004 | loss: 0.51785 - acc: 0.7655 -- iter: 0352/1234
[A[ATraining Step: 129  | total loss: [1m[32m0.52275[0m[0m | time: 176.794s
[2K
| RMSProp | epoch: 004 | loss: 0.52275 - acc: 0.7640 -- iter: 0384/1234
[A[ATraining Step: 130  | total loss: [1m[32m0.51532[0m[0m | time: 193.247s
[2K
| RMSProp | epoch: 004 | loss: 0.51532 - acc: 0.7688 -- iter: 0416/1234
[A[ATraining Step: 131  | total loss: [1m[32m0.49107[0m[0m | time: 210.060s
[2K
| RMSProp | epoch: 004 | loss: 0.49107 - acc: 0.7857 -- iter: 0448/1234
[A[ATraining Step: 132  | total loss: [1m[32m0.46192[0m[0m | time: 226.399s
[2K
| RMSProp | epoch: 004 | loss: 0.46192 - acc: 0.8009 -- iter: 0480/1234
[A[ATraining Step: 133  | total loss: [1m[32m0.43936[0m[0m | time: 242.793s
[2K
| RMSProp | epoch: 004 | loss: 0.43936 - acc: 0.8114 -- iter: 0512/1234
[A[ATraining Step: 134  | total loss: [1m[32m0.42516[0m[0m | time: 256.315s
[2K
| RMSProp | epoch: 004 | loss: 0.42516 - acc: 0.8147 -- iter: 0544/1234
[A[ATraining Step: 135  | total loss: [1m[32m0.43883[0m[0m | time: 270.053s
[2K
| RMSProp | epoch: 004 | loss: 0.43883 - acc: 0.8113 -- iter: 0576/1234
[A[ATraining Step: 136  | total loss: [1m[32m0.47526[0m[0m | time: 281.588s
[2K
| RMSProp | epoch: 004 | loss: 0.47526 - acc: 0.8052 -- iter: 0608/1234
[A[ATraining Step: 137  | total loss: [1m[32m0.47327[0m[0m | time: 296.049s
[2K
| RMSProp | epoch: 004 | loss: 0.47327 - acc: 0.8059 -- iter: 0640/1234
[A[ATraining Step: 138  | total loss: [1m[32m0.47419[0m[0m | time: 313.145s
[2K
| RMSProp | epoch: 004 | loss: 0.47419 - acc: 0.8097 -- iter: 0672/1234
[A[ATraining Step: 139  | total loss: [1m[32m0.45519[0m[0m | time: 331.409s
[2K
| RMSProp | epoch: 004 | loss: 0.45519 - acc: 0.8100 -- iter: 0704/1234
[A[ATraining Step: 140  | total loss: [1m[32m0.44767[0m[0m | time: 348.422s
[2K
| RMSProp | epoch: 004 | loss: 0.44767 - acc: 0.8165 -- iter: 0736/1234
[A[ATraining Step: 141  | total loss: [1m[32m0.46583[0m[0m | time: 365.162s
[2K
| RMSProp | epoch: 004 | loss: 0.46583 - acc: 0.8130 -- iter: 0768/1234
[A[ATraining Step: 142  | total loss: [1m[32m0.46257[0m[0m | time: 382.061s
[2K
| RMSProp | epoch: 004 | loss: 0.46257 - acc: 0.8098 -- iter: 0800/1234
[A[ATraining Step: 143  | total loss: [1m[32m0.48279[0m[0m | time: 400.168s
[2K
| RMSProp | epoch: 004 | loss: 0.48279 - acc: 0.7944 -- iter: 0832/1234
[A[ATraining Step: 144  | total loss: [1m[32m0.49324[0m[0m | time: 415.824s
[2K
| RMSProp | epoch: 004 | loss: 0.49324 - acc: 0.7962 -- iter: 0864/1234
[A[ATraining Step: 145  | total loss: [1m[32m0.48833[0m[0m | time: 432.297s
[2K
| RMSProp | epoch: 004 | loss: 0.48833 - acc: 0.7979 -- iter: 0896/1234
[A[ATraining Step: 146  | total loss: [1m[32m0.48264[0m[0m | time: 449.493s
[2K
| RMSProp | epoch: 004 | loss: 0.48264 - acc: 0.7962 -- iter: 0928/1234
[A[ATraining Step: 147  | total loss: [1m[32m0.48686[0m[0m | time: 466.719s
[2K
| RMSProp | epoch: 004 | loss: 0.48686 - acc: 0.7947 -- iter: 0960/1234
[A[ATraining Step: 148  | total loss: [1m[32m0.46922[0m[0m | time: 485.444s
[2K
| RMSProp | epoch: 004 | loss: 0.46922 - acc: 0.8059 -- iter: 0992/1234
[A[ATraining Step: 149  | total loss: [1m[32m0.46451[0m[0m | time: 502.081s
[2K
| RMSProp | epoch: 004 | loss: 0.46451 - acc: 0.8065 -- iter: 1024/1234
[A[ATraining Step: 150  | total loss: [1m[32m0.46274[0m[0m | time: 518.522s
[2K
| RMSProp | epoch: 004 | loss: 0.46274 - acc: 0.8040 -- iter: 1056/1234
[A[ATraining Step: 151  | total loss: [1m[32m0.49137[0m[0m | time: 532.243s
[2K
| RMSProp | epoch: 004 | loss: 0.49137 - acc: 0.7955 -- iter: 1088/1234
[A[ATraining Step: 152  | total loss: [1m[32m0.50978[0m[0m | time: 544.990s
[2K
| RMSProp | epoch: 004 | loss: 0.50978 - acc: 0.7847 -- iter: 1120/1234
[A[ATraining Step: 153  | total loss: [1m[32m0.51813[0m[0m | time: 559.258s
[2K
| RMSProp | epoch: 004 | loss: 0.51813 - acc: 0.7843 -- iter: 1152/1234
[A[ATraining Step: 154  | total loss: [1m[32m0.52164[0m[0m | time: 576.276s
[2K
| RMSProp | epoch: 004 | loss: 0.52164 - acc: 0.7809 -- iter: 1184/1234
[A[ATraining Step: 155  | total loss: [1m[32m0.52199[0m[0m | time: 592.905s
[2K
| RMSProp | epoch: 004 | loss: 0.52199 - acc: 0.7809 -- iter: 1216/1234
[A[ATraining Step: 156  | total loss: [1m[32m0.49936[0m[0m | time: 646.601s
[2K
| RMSProp | epoch: 004 | loss: 0.49936 - acc: 0.7903 | val_loss: 0.81328 - val_acc: 0.6554 -- iter: 1234/1234
--
Training Step: 157  | total loss: [1m[32m0.48493[0m[0m | time: 14.889s
[2K
| RMSProp | epoch: 005 | loss: 0.48493 - acc: 0.7957 -- iter: 0032/1234
[A[ATraining Step: 158  | total loss: [1m[32m0.48630[0m[0m | time: 30.328s
[2K
| RMSProp | epoch: 005 | loss: 0.48630 - acc: 0.7942 -- iter: 0064/1234
[A[ATraining Step: 159  | total loss: [1m[32m0.47208[0m[0m | time: 41.191s
[2K
| RMSProp | epoch: 005 | loss: 0.47208 - acc: 0.7992 -- iter: 0096/1234
[A[ATraining Step: 160  | total loss: [1m[32m0.44182[0m[0m | time: 51.008s
[2K
| RMSProp | epoch: 005 | loss: 0.44182 - acc: 0.8137 -- iter: 0128/1234
[A[ATraining Step: 161  | total loss: [1m[32m0.40555[0m[0m | time: 67.050s
[2K
| RMSProp | epoch: 005 | loss: 0.40555 - acc: 0.8323 -- iter: 0160/1234
[A[ATraining Step: 162  | total loss: [1m[32m0.43692[0m[0m | time: 83.004s
[2K
| RMSProp | epoch: 005 | loss: 0.43692 - acc: 0.8272 -- iter: 0192/1234
[A[ATraining Step: 163  | total loss: [1m[32m0.44493[0m[0m | time: 98.407s
[2K
| RMSProp | epoch: 005 | loss: 0.44493 - acc: 0.8195 -- iter: 0224/1234
[A[ATraining Step: 164  | total loss: [1m[32m0.44639[0m[0m | time: 108.721s
[2K
| RMSProp | epoch: 005 | loss: 0.44639 - acc: 0.8219 -- iter: 0256/1234
[A[ATraining Step: 165  | total loss: [1m[32m0.45153[0m[0m | time: 120.657s
[2K
| RMSProp | epoch: 005 | loss: 0.45153 - acc: 0.8241 -- iter: 0288/1234
[A[ATraining Step: 166  | total loss: [1m[32m0.43849[0m[0m | time: 135.836s
[2K
| RMSProp | epoch: 005 | loss: 0.43849 - acc: 0.8292 -- iter: 0320/1234
[A[ATraining Step: 167  | total loss: [1m[32m0.42825[0m[0m | time: 152.922s
[2K
| RMSProp | epoch: 005 | loss: 0.42825 - acc: 0.8307 -- iter: 0352/1234
[A[ATraining Step: 168  | total loss: [1m[32m0.44611[0m[0m | time: 168.124s
[2K
| RMSProp | epoch: 005 | loss: 0.44611 - acc: 0.8320 -- iter: 0384/1234
[A[ATraining Step: 169  | total loss: [1m[32m0.45994[0m[0m | time: 183.857s
[2K
| RMSProp | epoch: 005 | loss: 0.45994 - acc: 0.8238 -- iter: 0416/1234
[A[ATraining Step: 170  | total loss: [1m[32m0.44851[0m[0m | time: 199.505s
[2K
| RMSProp | epoch: 005 | loss: 0.44851 - acc: 0.8258 -- iter: 0448/1234
[A[ATraining Step: 171  | total loss: [1m[32m0.42216[0m[0m | time: 215.431s
[2K
| RMSProp | epoch: 005 | loss: 0.42216 - acc: 0.8432 -- iter: 0480/1234
[A[ATraining Step: 172  | total loss: [1m[32m0.40784[0m[0m | time: 231.399s
[2K
| RMSProp | epoch: 005 | loss: 0.40784 - acc: 0.8401 -- iter: 0512/1234
[A[ATraining Step: 173  | total loss: [1m[32m0.38515[0m[0m | time: 247.093s
[2K
| RMSProp | epoch: 005 | loss: 0.38515 - acc: 0.8499 -- iter: 0544/1234
[A[ATraining Step: 174  | total loss: [1m[32m0.40438[0m[0m | time: 263.123s
[2K
| RMSProp | epoch: 005 | loss: 0.40438 - acc: 0.8461 -- iter: 0576/1234
[A[ATraining Step: 175  | total loss: [1m[32m0.44501[0m[0m | time: 279.438s
[2K
| RMSProp | epoch: 005 | loss: 0.44501 - acc: 0.8334 -- iter: 0608/1234
[A[ATraining Step: 176  | total loss: [1m[32m0.44691[0m[0m | time: 294.998s
[2K
| RMSProp | epoch: 005 | loss: 0.44691 - acc: 0.8344 -- iter: 0640/1234
[A[ATraining Step: 177  | total loss: [1m[32m0.44692[0m[0m | time: 311.310s
[2K
| RMSProp | epoch: 005 | loss: 0.44692 - acc: 0.8354 -- iter: 0672/1234
[A[ATraining Step: 178  | total loss: [1m[32m0.42734[0m[0m | time: 327.619s
[2K
| RMSProp | epoch: 005 | loss: 0.42734 - acc: 0.8456 -- iter: 0704/1234
[A[ATraining Step: 179  | total loss: [1m[32m0.44502[0m[0m | time: 343.928s
[2K
| RMSProp | epoch: 005 | loss: 0.44502 - acc: 0.8360 -- iter: 0736/1234
[A[ATraining Step: 180  | total loss: [1m[32m0.45775[0m[0m | time: 356.288s
[2K
| RMSProp | epoch: 005 | loss: 0.45775 - acc: 0.8274 -- iter: 0768/1234
[A[ATraining Step: 181  | total loss: [1m[32m0.46714[0m[0m | time: 366.813s
[2K
| RMSProp | epoch: 005 | loss: 0.46714 - acc: 0.8134 -- iter: 0800/1234
[A[ATraining Step: 182  | total loss: [1m[32m0.47212[0m[0m | time: 379.682s
[2K
| RMSProp | epoch: 005 | loss: 0.47212 - acc: 0.8165 -- iter: 0832/1234
[A[ATraining Step: 183  | total loss: [1m[32m0.46620[0m[0m | time: 395.902s
[2K
| RMSProp | epoch: 005 | loss: 0.46620 - acc: 0.8161 -- iter: 0864/1234
[A[ATraining Step: 184  | total loss: [1m[32m0.45128[0m[0m | time: 412.367s
[2K
| RMSProp | epoch: 005 | loss: 0.45128 - acc: 0.8251 -- iter: 0896/1234
[A[ATraining Step: 185  | total loss: [1m[32m0.44855[0m[0m | time: 430.698s
[2K
| RMSProp | epoch: 005 | loss: 0.44855 - acc: 0.8238 -- iter: 0928/1234
[A[ATraining Step: 186  | total loss: [1m[32m0.44612[0m[0m | time: 448.357s
[2K
| RMSProp | epoch: 005 | loss: 0.44612 - acc: 0.8133 -- iter: 0960/1234
[A[ATraining Step: 187  | total loss: [1m[32m0.44019[0m[0m | time: 464.783s
[2K
| RMSProp | epoch: 005 | loss: 0.44019 - acc: 0.8132 -- iter: 0992/1234
[A[ATraining Step: 188  | total loss: [1m[32m0.43625[0m[0m | time: 481.090s
[2K
| RMSProp | epoch: 005 | loss: 0.43625 - acc: 0.8163 -- iter: 1024/1234
[A[ATraining Step: 189  | total loss: [1m[32m0.44745[0m[0m | time: 497.416s
[2K
| RMSProp | epoch: 005 | loss: 0.44745 - acc: 0.8065 -- iter: 1056/1234
[A[ATraining Step: 190  | total loss: [1m[32m0.43501[0m[0m | time: 513.685s
[2K
| RMSProp | epoch: 005 | loss: 0.43501 - acc: 0.8196 -- iter: 1088/1234
[A[ATraining Step: 191  | total loss: [1m[32m0.43938[0m[0m | time: 529.998s
[2K
| RMSProp | epoch: 005 | loss: 0.43938 - acc: 0.8127 -- iter: 1120/1234
[A[ATraining Step: 192  | total loss: [1m[32m0.43115[0m[0m | time: 546.013s
[2K
| RMSProp | epoch: 005 | loss: 0.43115 - acc: 0.8126 -- iter: 1152/1234
[A[ATraining Step: 193  | total loss: [1m[32m0.43023[0m[0m | time: 559.706s
[2K
| RMSProp | epoch: 005 | loss: 0.43023 - acc: 0.8189 -- iter: 1184/1234
[A[ATraining Step: 194  | total loss: [1m[32m0.42403[0m[0m | time: 577.215s
[2K
| RMSProp | epoch: 005 | loss: 0.42403 - acc: 0.8245 -- iter: 1216/1234
[A[ATraining Step: 195  | total loss: [1m[32m0.41666[0m[0m | time: 625.382s
[2K
| RMSProp | epoch: 005 | loss: 0.41666 - acc: 0.8295 | val_loss: 2.36159 - val_acc: 0.5259 -- iter: 1234/1234
--
Training Step: 196  | total loss: [1m[32m0.40073[0m[0m | time: 17.079s
[2K
| RMSProp | epoch: 006 | loss: 0.40073 - acc: 0.8372 -- iter: 0032/1234
[A[ATraining Step: 197  | total loss: [1m[32m0.39387[0m[0m | time: 34.207s
[2K
| RMSProp | epoch: 006 | loss: 0.39387 - acc: 0.8379 -- iter: 0064/1234
[A[ATraining Step: 198  | total loss: [1m[32m0.43058[0m[0m | time: 51.241s
[2K
| RMSProp | epoch: 006 | loss: 0.43058 - acc: 0.8322 -- iter: 0096/1234
[A[ATraining Step: 199  | total loss: [1m[32m0.43103[0m[0m | time: 63.452s
[2K
| RMSProp | epoch: 006 | loss: 0.43103 - acc: 0.8271 -- iter: 0128/1234
[A[ATraining Step: 200  | total loss: [1m[32m0.40581[0m[0m | time: 113.889s
[2K
| RMSProp | epoch: 006 | loss: 0.40581 - acc: 0.8333 | val_loss: 0.50484 - val_acc: 0.7850 -- iter: 0160/1234
--
Training Step: 201  | total loss: [1m[32m0.36942[0m[0m | time: 131.412s
[2K
| RMSProp | epoch: 006 | loss: 0.36942 - acc: 0.8500 -- iter: 0192/1234
[A[ATraining Step: 202  | total loss: [1m[32m0.35102[0m[0m | time: 146.701s
[2K
| RMSProp | epoch: 006 | loss: 0.35102 - acc: 0.8556 -- iter: 0224/1234
[A[ATraining Step: 203  | total loss: [1m[32m0.32606[0m[0m | time: 163.655s
[2K
| RMSProp | epoch: 006 | loss: 0.32606 - acc: 0.8669 -- iter: 0256/1234
[A[ATraining Step: 204  | total loss: [1m[32m0.32307[0m[0m | time: 180.155s
[2K
| RMSProp | epoch: 006 | loss: 0.32307 - acc: 0.8646 -- iter: 0288/1234
[A[ATraining Step: 205  | total loss: [1m[32m0.31325[0m[0m | time: 191.379s
[2K
| RMSProp | epoch: 006 | loss: 0.31325 - acc: 0.8688 -- iter: 0320/1234
[A[ATraining Step: 206  | total loss: [1m[32m0.32441[0m[0m | time: 202.571s
[2K
| RMSProp | epoch: 006 | loss: 0.32441 - acc: 0.8663 -- iter: 0352/1234
[A[ATraining Step: 207  | total loss: [1m[32m0.31780[0m[0m | time: 215.663s
[2K
| RMSProp | epoch: 006 | loss: 0.31780 - acc: 0.8765 -- iter: 0384/1234
[A[ATraining Step: 208  | total loss: [1m[32m0.30832[0m[0m | time: 231.820s
[2K
| RMSProp | epoch: 006 | loss: 0.30832 - acc: 0.8795 -- iter: 0416/1234
[A[ATraining Step: 209  | total loss: [1m[32m0.30635[0m[0m | time: 248.455s
[2K
| RMSProp | epoch: 006 | loss: 0.30635 - acc: 0.8790 -- iter: 0448/1234
[A[ATraining Step: 210  | total loss: [1m[32m0.31265[0m[0m | time: 265.346s
[2K
| RMSProp | epoch: 006 | loss: 0.31265 - acc: 0.8724 -- iter: 0480/1234
[A[ATraining Step: 211  | total loss: [1m[32m0.32195[0m[0m | time: 283.227s
[2K
| RMSProp | epoch: 006 | loss: 0.32195 - acc: 0.8726 -- iter: 0512/1234
[A[ATraining Step: 212  | total loss: [1m[32m0.31992[0m[0m | time: 300.323s
[2K
| RMSProp | epoch: 006 | loss: 0.31992 - acc: 0.8760 -- iter: 0544/1234
[A[ATraining Step: 213  | total loss: [1m[32m0.33700[0m[0m | time: 313.920s
[2K
| RMSProp | epoch: 006 | loss: 0.33700 - acc: 0.8603 -- iter: 0576/1234
[A[ATraining Step: 214  | total loss: [1m[32m0.34417[0m[0m | time: 331.056s
[2K
| RMSProp | epoch: 006 | loss: 0.34417 - acc: 0.8586 -- iter: 0608/1234
[A[ATraining Step: 215  | total loss: [1m[32m0.31823[0m[0m | time: 348.364s
[2K
| RMSProp | epoch: 006 | loss: 0.31823 - acc: 0.8728 -- iter: 0640/1234
[A[ATraining Step: 216  | total loss: [1m[32m0.31051[0m[0m | time: 366.017s
[2K
| RMSProp | epoch: 006 | loss: 0.31051 - acc: 0.8730 -- iter: 0672/1234
[A[ATraining Step: 217  | total loss: [1m[32m0.32294[0m[0m | time: 384.901s
[2K
| RMSProp | epoch: 006 | loss: 0.32294 - acc: 0.8701 -- iter: 0704/1234
[A[ATraining Step: 218  | total loss: [1m[32m0.32598[0m[0m | time: 401.798s
[2K
| RMSProp | epoch: 006 | loss: 0.32598 - acc: 0.8612 -- iter: 0736/1234
[A[ATraining Step: 219  | total loss: [1m[32m0.34898[0m[0m | time: 418.952s
[2K
| RMSProp | epoch: 006 | loss: 0.34898 - acc: 0.8501 -- iter: 0768/1234
[A[ATraining Step: 220  | total loss: [1m[32m0.34543[0m[0m | time: 435.708s
[2K
| RMSProp | epoch: 006 | loss: 0.34543 - acc: 0.8494 -- iter: 0800/1234
[A[ATraining Step: 221  | total loss: [1m[32m0.33121[0m[0m | time: 452.865s
[2K
| RMSProp | epoch: 006 | loss: 0.33121 - acc: 0.8582 -- iter: 0832/1234
[A[ATraining Step: 222  | total loss: [1m[32m0.33247[0m[0m | time: 468.059s
[2K
| RMSProp | epoch: 006 | loss: 0.33247 - acc: 0.8568 -- iter: 0864/1234
[A[ATraining Step: 223  | total loss: [1m[32m0.32429[0m[0m | time: 484.647s
[2K
| RMSProp | epoch: 006 | loss: 0.32429 - acc: 0.8617 -- iter: 0896/1234
[A[ATraining Step: 224  | total loss: [1m[32m0.32203[0m[0m | time: 496.520s
[2K
| RMSProp | epoch: 006 | loss: 0.32203 - acc: 0.8693 -- iter: 0928/1234
[A[ATraining Step: 225  | total loss: [1m[32m0.31227[0m[0m | time: 507.957s
[2K
| RMSProp | epoch: 006 | loss: 0.31227 - acc: 0.8668 -- iter: 0960/1234
[A[ATraining Step: 226  | total loss: [1m[32m0.29816[0m[0m | time: 519.357s
[2K
| RMSProp | epoch: 006 | loss: 0.29816 - acc: 0.8738 -- iter: 0992/1234
[A[ATraining Step: 227  | total loss: [1m[32m0.29995[0m[0m | time: 537.153s
[2K
| RMSProp | epoch: 006 | loss: 0.29995 - acc: 0.8614 -- iter: 1024/1234
[A[ATraining Step: 228  | total loss: [1m[32m0.30333[0m[0m | time: 554.586s
[2K
| RMSProp | epoch: 006 | loss: 0.30333 - acc: 0.8566 -- iter: 1056/1234
[A[ATraining Step: 229  | total loss: [1m[32m0.30219[0m[0m | time: 565.021s
[2K
| RMSProp | epoch: 006 | loss: 0.30219 - acc: 0.8615 -- iter: 1088/1234
[A[ATraining Step: 230  | total loss: [1m[32m0.30328[0m[0m | time: 575.111s
[2K
| RMSProp | epoch: 006 | loss: 0.30328 - acc: 0.8566 -- iter: 1120/1234
[A[ATraining Step: 231  | total loss: [1m[32m0.29639[0m[0m | time: 585.347s
[2K
| RMSProp | epoch: 006 | loss: 0.29639 - acc: 0.8616 -- iter: 1152/1234
[A[ATraining Step: 232  | total loss: [1m[32m0.31215[0m[0m | time: 597.559s
[2K
| RMSProp | epoch: 006 | loss: 0.31215 - acc: 0.8504 -- iter: 1184/1234
[A[ATraining Step: 233  | total loss: [1m[32m0.29741[0m[0m | time: 607.769s
[2K
| RMSProp | epoch: 006 | loss: 0.29741 - acc: 0.8560 -- iter: 1216/1234
[A[ATraining Step: 234  | total loss: [1m[32m0.29549[0m[0m | time: 639.576s
[2K
| RMSProp | epoch: 006 | loss: 0.29549 - acc: 0.8610 | val_loss: 1.57079 - val_acc: 0.5984 -- iter: 1234/1234
--
Training Step: 235  | total loss: [1m[32m0.29521[0m[0m | time: 10.479s
[2K
| RMSProp | epoch: 007 | loss: 0.29521 - acc: 0.8593 -- iter: 0032/1234
[A[ATraining Step: 236  | total loss: [1m[32m0.33196[0m[0m | time: 20.774s
[2K
| RMSProp | epoch: 007 | loss: 0.33196 - acc: 0.8452 -- iter: 0064/1234
[A[ATraining Step: 237  | total loss: [1m[32m0.34398[0m[0m | time: 30.837s
[2K
| RMSProp | epoch: 007 | loss: 0.34398 - acc: 0.8451 -- iter: 0096/1234
[A[ATraining Step: 238  | total loss: [1m[32m0.33567[0m[0m | time: 40.885s
[2K
| RMSProp | epoch: 007 | loss: 0.33567 - acc: 0.8481 -- iter: 0128/1234
[A[ATraining Step: 239  | total loss: [1m[32m0.32926[0m[0m | time: 47.101s
[2K
| RMSProp | epoch: 007 | loss: 0.32926 - acc: 0.8508 -- iter: 0160/1234
[A[ATraining Step: 240  | total loss: [1m[32m0.33974[0m[0m | time: 53.422s
[2K
| RMSProp | epoch: 007 | loss: 0.33974 - acc: 0.8435 -- iter: 0192/1234
[A[ATraining Step: 241  | total loss: [1m[32m0.31437[0m[0m | time: 63.681s
[2K
| RMSProp | epoch: 007 | loss: 0.31437 - acc: 0.8591 -- iter: 0224/1234
[A[ATraining Step: 242  | total loss: [1m[32m0.30335[0m[0m | time: 74.063s
[2K
| RMSProp | epoch: 007 | loss: 0.30335 - acc: 0.8638 -- iter: 0256/1234
[A[ATraining Step: 243  | total loss: [1m[32m0.34351[0m[0m | time: 84.562s
[2K
| RMSProp | epoch: 007 | loss: 0.34351 - acc: 0.8462 -- iter: 0288/1234
[A[ATraining Step: 244  | total loss: [1m[32m0.32649[0m[0m | time: 94.827s
[2K
| RMSProp | epoch: 007 | loss: 0.32649 - acc: 0.8553 -- iter: 0320/1234
[A[ATraining Step: 245  | total loss: [1m[32m0.31791[0m[0m | time: 104.874s
[2K
| RMSProp | epoch: 007 | loss: 0.31791 - acc: 0.8542 -- iter: 0352/1234
[A[ATraining Step: 246  | total loss: [1m[32m0.34650[0m[0m | time: 116.796s
[2K
| RMSProp | epoch: 007 | loss: 0.34650 - acc: 0.8500 -- iter: 0384/1234
[A[ATraining Step: 247  | total loss: [1m[32m0.34234[0m[0m | time: 127.037s
[2K
| RMSProp | epoch: 007 | loss: 0.34234 - acc: 0.8556 -- iter: 0416/1234
[A[ATraining Step: 248  | total loss: [1m[32m0.32745[0m[0m | time: 137.645s
[2K
| RMSProp | epoch: 007 | loss: 0.32745 - acc: 0.8669 -- iter: 0448/1234
[A[ATraining Step: 249  | total loss: [1m[32m0.31786[0m[0m | time: 148.866s
[2K
| RMSProp | epoch: 007 | loss: 0.31786 - acc: 0.8740 -- iter: 0480/1234
[A[ATraining Step: 250  | total loss: [1m[32m0.29547[0m[0m | time: 159.079s
[2K
| RMSProp | epoch: 007 | loss: 0.29547 - acc: 0.8835 -- iter: 0512/1234
[A[ATraining Step: 251  | total loss: [1m[32m0.36126[0m[0m | time: 169.425s
[2K
| RMSProp | epoch: 007 | loss: 0.36126 - acc: 0.8733 -- iter: 0544/1234
[A[ATraining Step: 252  | total loss: [1m[32m0.33695[0m[0m | time: 179.595s
[2K
| RMSProp | epoch: 007 | loss: 0.33695 - acc: 0.8828 -- iter: 0576/1234
[A[ATraining Step: 253  | total loss: [1m[32m0.32677[0m[0m | time: 189.847s
[2K
| RMSProp | epoch: 007 | loss: 0.32677 - acc: 0.8820 -- iter: 0608/1234
[A[ATraining Step: 254  | total loss: [1m[32m0.32776[0m[0m | time: 200.002s
[2K
| RMSProp | epoch: 007 | loss: 0.32776 - acc: 0.8751 -- iter: 0640/1234
[A[ATraining Step: 255  | total loss: [1m[32m0.30837[0m[0m | time: 210.160s
[2K
| RMSProp | epoch: 007 | loss: 0.30837 - acc: 0.8813 -- iter: 0672/1234
[A[ATraining Step: 256  | total loss: [1m[32m0.31194[0m[0m | time: 220.321s
[2K
| RMSProp | epoch: 007 | loss: 0.31194 - acc: 0.8838 -- iter: 0704/1234
[A[ATraining Step: 257  | total loss: [1m[32m0.30062[0m[0m | time: 230.748s
[2K
| RMSProp | epoch: 007 | loss: 0.30062 - acc: 0.8861 -- iter: 0736/1234
[A[ATraining Step: 258  | total loss: [1m[32m0.29512[0m[0m | time: 242.896s
[2K
| RMSProp | epoch: 007 | loss: 0.29512 - acc: 0.8818 -- iter: 0768/1234
[A[ATraining Step: 259  | total loss: [1m[32m0.29568[0m[0m | time: 253.135s
[2K
| RMSProp | epoch: 007 | loss: 0.29568 - acc: 0.8780 -- iter: 0800/1234
[A[ATraining Step: 260  | total loss: [1m[32m0.30322[0m[0m | time: 263.572s
[2K
| RMSProp | epoch: 007 | loss: 0.30322 - acc: 0.8715 -- iter: 0832/1234
[A[ATraining Step: 261  | total loss: [1m[32m0.30147[0m[0m | time: 274.136s
[2K
| RMSProp | epoch: 007 | loss: 0.30147 - acc: 0.8749 -- iter: 0864/1234
[A[ATraining Step: 262  | total loss: [1m[32m0.29521[0m[0m | time: 284.493s
[2K
| RMSProp | epoch: 007 | loss: 0.29521 - acc: 0.8812 -- iter: 0896/1234
[A[ATraining Step: 263  | total loss: [1m[32m0.30714[0m[0m | time: 294.764s
[2K
| RMSProp | epoch: 007 | loss: 0.30714 - acc: 0.8806 -- iter: 0928/1234
[A[ATraining Step: 264  | total loss: [1m[32m0.29393[0m[0m | time: 304.897s
[2K
| RMSProp | epoch: 007 | loss: 0.29393 - acc: 0.8831 -- iter: 0960/1234
[A[ATraining Step: 265  | total loss: [1m[32m0.27457[0m[0m | time: 315.166s
[2K
| RMSProp | epoch: 007 | loss: 0.27457 - acc: 0.8917 -- iter: 0992/1234
[A[ATraining Step: 266  | total loss: [1m[32m0.28398[0m[0m | time: 325.539s
[2K
| RMSProp | epoch: 007 | loss: 0.28398 - acc: 0.8900 -- iter: 1024/1234
[A[ATraining Step: 267  | total loss: [1m[32m0.27295[0m[0m | time: 335.675s
[2K
| RMSProp | epoch: 007 | loss: 0.27295 - acc: 0.8948 -- iter: 1056/1234
[A[ATraining Step: 268  | total loss: [1m[32m0.27059[0m[0m | time: 345.875s
[2K
| RMSProp | epoch: 007 | loss: 0.27059 - acc: 0.8928 -- iter: 1088/1234
[A[ATraining Step: 269  | total loss: [1m[32m0.26346[0m[0m | time: 357.925s
[2K
| RMSProp | epoch: 007 | loss: 0.26346 - acc: 0.8973 -- iter: 1120/1234
[A[ATraining Step: 270  | total loss: [1m[32m0.24493[0m[0m | time: 370.040s
[2K
| RMSProp | epoch: 007 | loss: 0.24493 - acc: 0.9075 -- iter: 1152/1234
[A[ATraining Step: 271  | total loss: [1m[32m0.24029[0m[0m | time: 380.665s
[2K
| RMSProp | epoch: 007 | loss: 0.24029 - acc: 0.9105 -- iter: 1184/1234
[A[ATraining Step: 272  | total loss: [1m[32m0.24577[0m[0m | time: 390.962s
[2K
| RMSProp | epoch: 007 | loss: 0.24577 - acc: 0.9039 -- iter: 1216/1234
[A[ATraining Step: 273  | total loss: [1m[32m0.24843[0m[0m | time: 422.226s
[2K
| RMSProp | epoch: 007 | loss: 0.24843 - acc: 0.8979 | val_loss: 0.74053 - val_acc: 0.7746 -- iter: 1234/1234
--
Training Step: 274  | total loss: [1m[32m0.24523[0m[0m | time: 10.406s
[2K
| RMSProp | epoch: 008 | loss: 0.24523 - acc: 0.9018 -- iter: 0032/1234
[A[ATraining Step: 275  | total loss: [1m[32m0.24547[0m[0m | time: 20.802s
[2K
| RMSProp | epoch: 008 | loss: 0.24547 - acc: 0.9023 -- iter: 0064/1234
[A[ATraining Step: 276  | total loss: [1m[32m0.24770[0m[0m | time: 31.775s
[2K
| RMSProp | epoch: 008 | loss: 0.24770 - acc: 0.9027 -- iter: 0096/1234
[A[ATraining Step: 277  | total loss: [1m[32m0.23747[0m[0m | time: 43.197s
[2K
| RMSProp | epoch: 008 | loss: 0.23747 - acc: 0.9061 -- iter: 0128/1234
[A[ATraining Step: 278  | total loss: [1m[32m0.22605[0m[0m | time: 53.454s
[2K
| RMSProp | epoch: 008 | loss: 0.22605 - acc: 0.9124 -- iter: 0160/1234
[A[ATraining Step: 279  | total loss: [1m[32m0.22581[0m[0m | time: 60.082s
[2K
| RMSProp | epoch: 008 | loss: 0.22581 - acc: 0.9087 -- iter: 0192/1234
[A[ATraining Step: 280  | total loss: [1m[32m0.27198[0m[0m | time: 66.861s
[2K
| RMSProp | epoch: 008 | loss: 0.27198 - acc: 0.8956 -- iter: 0224/1234
[A[ATraining Step: 281  | total loss: [1m[32m0.26049[0m[0m | time: 77.464s
[2K
| RMSProp | epoch: 008 | loss: 0.26049 - acc: 0.9005 -- iter: 0256/1234
[A[ATraining Step: 282  | total loss: [1m[32m0.25345[0m[0m | time: 88.220s
[2K
| RMSProp | epoch: 008 | loss: 0.25345 - acc: 0.9010 -- iter: 0288/1234
[A[ATraining Step: 283  | total loss: [1m[32m0.27735[0m[0m | time: 98.611s
[2K
| RMSProp | epoch: 008 | loss: 0.27735 - acc: 0.8984 -- iter: 0320/1234
[A[ATraining Step: 284  | total loss: [1m[32m0.26486[0m[0m | time: 108.985s
[2K
| RMSProp | epoch: 008 | loss: 0.26486 - acc: 0.9055 -- iter: 0352/1234
[A[ATraining Step: 285  | total loss: [1m[32m0.26371[0m[0m | time: 119.944s
[2K
| RMSProp | epoch: 008 | loss: 0.26371 - acc: 0.9087 -- iter: 0384/1234
[A[ATraining Step: 286  | total loss: [1m[32m0.26237[0m[0m | time: 131.583s
[2K
| RMSProp | epoch: 008 | loss: 0.26237 - acc: 0.9053 -- iter: 0416/1234
[A[ATraining Step: 287  | total loss: [1m[32m0.26334[0m[0m | time: 142.815s
[2K
| RMSProp | epoch: 008 | loss: 0.26334 - acc: 0.9116 -- iter: 0448/1234
[A[ATraining Step: 288  | total loss: [1m[32m0.24785[0m[0m | time: 152.985s
[2K
| RMSProp | epoch: 008 | loss: 0.24785 - acc: 0.9142 -- iter: 0480/1234
[A[ATraining Step: 289  | total loss: [1m[32m0.23829[0m[0m | time: 165.087s
[2K
| RMSProp | epoch: 008 | loss: 0.23829 - acc: 0.9166 -- iter: 0512/1234
[A[ATraining Step: 290  | total loss: [1m[32m0.22343[0m[0m | time: 175.695s
[2K
| RMSProp | epoch: 008 | loss: 0.22343 - acc: 0.9218 -- iter: 0544/1234
[A[ATraining Step: 291  | total loss: [1m[32m0.21496[0m[0m | time: 185.826s
[2K
| RMSProp | epoch: 008 | loss: 0.21496 - acc: 0.9234 -- iter: 0576/1234
[A[ATraining Step: 292  | total loss: [1m[32m0.20422[0m[0m | time: 196.580s
[2K
| RMSProp | epoch: 008 | loss: 0.20422 - acc: 0.9279 -- iter: 0608/1234
[A[ATraining Step: 293  | total loss: [1m[32m0.22541[0m[0m | time: 207.176s
[2K
| RMSProp | epoch: 008 | loss: 0.22541 - acc: 0.9289 -- iter: 0640/1234
[A[ATraining Step: 294  | total loss: [1m[32m0.22186[0m[0m | time: 217.858s
[2K
| RMSProp | epoch: 008 | loss: 0.22186 - acc: 0.9266 -- iter: 0672/1234
[A[ATraining Step: 295  | total loss: [1m[32m0.21908[0m[0m | time: 228.273s
[2K
| RMSProp | epoch: 008 | loss: 0.21908 - acc: 0.9246 -- iter: 0704/1234
[A[ATraining Step: 296  | total loss: [1m[32m0.21803[0m[0m | time: 238.788s
[2K
| RMSProp | epoch: 008 | loss: 0.21803 - acc: 0.9259 -- iter: 0736/1234
[A[ATraining Step: 297  | total loss: [1m[32m0.22502[0m[0m | time: 249.170s
[2K
| RMSProp | epoch: 008 | loss: 0.22502 - acc: 0.9208 -- iter: 0768/1234
[A[ATraining Step: 298  | total loss: [1m[32m0.23841[0m[0m | time: 259.504s
[2K
| RMSProp | epoch: 008 | loss: 0.23841 - acc: 0.9224 -- iter: 0800/1234
[A[ATraining Step: 299  | total loss: [1m[32m0.22625[0m[0m | time: 269.855s
[2K
| RMSProp | epoch: 008 | loss: 0.22625 - acc: 0.9271 -- iter: 0832/1234
[A[ATraining Step: 300  | total loss: [1m[32m0.21479[0m[0m | time: 282.095s
[2K
| RMSProp | epoch: 008 | loss: 0.21479 - acc: 0.9312 -- iter: 0864/1234
[A[ATraining Step: 301  | total loss: [1m[32m0.20425[0m[0m | time: 292.611s
[2K
| RMSProp | epoch: 008 | loss: 0.20425 - acc: 0.9350 -- iter: 0896/1234
[A[ATraining Step: 302  | total loss: [1m[32m0.19970[0m[0m | time: 303.335s
[2K
| RMSProp | epoch: 008 | loss: 0.19970 - acc: 0.9352 -- iter: 0928/1234
[A[ATraining Step: 303  | total loss: [1m[32m0.19893[0m[0m | time: 313.793s
[2K
| RMSProp | epoch: 008 | loss: 0.19893 - acc: 0.9386 -- iter: 0960/1234
[A[ATraining Step: 304  | total loss: [1m[32m0.18457[0m[0m | time: 324.232s
[2K
| RMSProp | epoch: 008 | loss: 0.18457 - acc: 0.9447 -- iter: 0992/1234
[A[ATraining Step: 305  | total loss: [1m[32m0.17443[0m[0m | time: 334.753s
[2K
| RMSProp | epoch: 008 | loss: 0.17443 - acc: 0.9471 -- iter: 1024/1234
[A[ATraining Step: 306  | total loss: [1m[32m0.18022[0m[0m | time: 345.184s
[2K
| RMSProp | epoch: 008 | loss: 0.18022 - acc: 0.9430 -- iter: 1056/1234
[A[ATraining Step: 307  | total loss: [1m[32m0.19456[0m[0m | time: 357.221s
[2K
| RMSProp | epoch: 008 | loss: 0.19456 - acc: 0.9394 -- iter: 1088/1234
[A[ATraining Step: 308  | total loss: [1m[32m0.18575[0m[0m | time: 367.401s
[2K
| RMSProp | epoch: 008 | loss: 0.18575 - acc: 0.9423 -- iter: 1120/1234
[A[ATraining Step: 309  | total loss: [1m[32m0.17414[0m[0m | time: 377.702s
[2K
| RMSProp | epoch: 008 | loss: 0.17414 - acc: 0.9481 -- iter: 1152/1234
[A[ATraining Step: 310  | total loss: [1m[32m0.17317[0m[0m | time: 388.065s
[2K
| RMSProp | epoch: 008 | loss: 0.17317 - acc: 0.9501 -- iter: 1184/1234
[A[ATraining Step: 311  | total loss: [1m[32m0.16837[0m[0m | time: 398.385s
[2K
| RMSProp | epoch: 008 | loss: 0.16837 - acc: 0.9489 -- iter: 1216/1234
[A[ATraining Step: 312  | total loss: [1m[32m0.16517[0m[0m | time: 431.721s
[2K
| RMSProp | epoch: 008 | loss: 0.16517 - acc: 0.9509 | val_loss: 12.22133 - val_acc: 0.4663 -- iter: 1234/1234
--
Training Step: 313  | total loss: [1m[32m0.17759[0m[0m | time: 10.441s
[2K
| RMSProp | epoch: 009 | loss: 0.17759 - acc: 0.9464 -- iter: 0032/1234
[A[ATraining Step: 314  | total loss: [1m[32m0.18069[0m[0m | time: 20.516s
[2K
| RMSProp | epoch: 009 | loss: 0.18069 - acc: 0.9393 -- iter: 0064/1234
[A[ATraining Step: 315  | total loss: [1m[32m0.17561[0m[0m | time: 30.913s
[2K
| RMSProp | epoch: 009 | loss: 0.17561 - acc: 0.9422 -- iter: 0096/1234
[A[ATraining Step: 316  | total loss: [1m[32m0.16887[0m[0m | time: 41.125s
[2K
| RMSProp | epoch: 009 | loss: 0.16887 - acc: 0.9449 -- iter: 0128/1234
[A[ATraining Step: 317  | total loss: [1m[32m0.16388[0m[0m | time: 51.327s
[2K
| RMSProp | epoch: 009 | loss: 0.16388 - acc: 0.9441 -- iter: 0160/1234
[A[ATraining Step: 318  | total loss: [1m[32m0.16316[0m[0m | time: 62.777s
[2K
| RMSProp | epoch: 009 | loss: 0.16316 - acc: 0.9403 -- iter: 0192/1234
[A[ATraining Step: 319  | total loss: [1m[32m0.15317[0m[0m | time: 68.820s
[2K
| RMSProp | epoch: 009 | loss: 0.15317 - acc: 0.9463 -- iter: 0224/1234
[A[ATraining Step: 320  | total loss: [1m[32m0.13995[0m[0m | time: 74.799s
[2K
| RMSProp | epoch: 009 | loss: 0.13995 - acc: 0.9517 -- iter: 0256/1234
[A[ATraining Step: 321  | total loss: [1m[32m0.13100[0m[0m | time: 84.720s
[2K
| RMSProp | epoch: 009 | loss: 0.13100 - acc: 0.9565 -- iter: 0288/1234
[A[ATraining Step: 322  | total loss: [1m[32m0.12402[0m[0m | time: 94.483s
[2K
| RMSProp | epoch: 009 | loss: 0.12402 - acc: 0.9609 -- iter: 0320/1234
[A[ATraining Step: 323  | total loss: [1m[32m0.11509[0m[0m | time: 104.330s
[2K
| RMSProp | epoch: 009 | loss: 0.11509 - acc: 0.9648 -- iter: 0352/1234
[A[ATraining Step: 324  | total loss: [1m[32m0.12566[0m[0m | time: 116.407s
[2K
| RMSProp | epoch: 009 | loss: 0.12566 - acc: 0.9652 -- iter: 0384/1234
[A[ATraining Step: 325  | total loss: [1m[32m0.12795[0m[0m | time: 126.307s
[2K
| RMSProp | epoch: 009 | loss: 0.12795 - acc: 0.9624 -- iter: 0416/1234
[A[ATraining Step: 326  | total loss: [1m[32m0.13957[0m[0m | time: 136.213s
[2K
| RMSProp | epoch: 009 | loss: 0.13957 - acc: 0.9599 -- iter: 0448/1234
[A[ATraining Step: 327  | total loss: [1m[32m0.17076[0m[0m | time: 146.182s
[2K
| RMSProp | epoch: 009 | loss: 0.17076 - acc: 0.9389 -- iter: 0480/1234
[A[ATraining Step: 328  | total loss: [1m[32m0.16612[0m[0m | time: 156.090s
[2K
| RMSProp | epoch: 009 | loss: 0.16612 - acc: 0.9419 -- iter: 0512/1234
[A[ATraining Step: 329  | total loss: [1m[32m0.16495[0m[0m | time: 166.093s
[2K
| RMSProp | epoch: 009 | loss: 0.16495 - acc: 0.9415 -- iter: 0544/1234
[A[ATraining Step: 330  | total loss: [1m[32m0.16715[0m[0m | time: 175.930s
[2K
| RMSProp | epoch: 009 | loss: 0.16715 - acc: 0.9411 -- iter: 0576/1234
[A[ATraining Step: 331  | total loss: [1m[32m0.16142[0m[0m | time: 187.554s
[2K
| RMSProp | epoch: 009 | loss: 0.16142 - acc: 0.9438 -- iter: 0608/1234
[A[ATraining Step: 332  | total loss: [1m[32m0.16794[0m[0m | time: 197.855s
[2K
| RMSProp | epoch: 009 | loss: 0.16794 - acc: 0.9370 -- iter: 0640/1234
[A[ATraining Step: 333  | total loss: [1m[32m0.16304[0m[0m | time: 207.829s
[2K
| RMSProp | epoch: 009 | loss: 0.16304 - acc: 0.9370 -- iter: 0672/1234
[A[ATraining Step: 334  | total loss: [1m[32m0.16645[0m[0m | time: 218.217s
[2K
| RMSProp | epoch: 009 | loss: 0.16645 - acc: 0.9339 -- iter: 0704/1234
[A[ATraining Step: 335  | total loss: [1m[32m0.16603[0m[0m | time: 228.372s
[2K
| RMSProp | epoch: 009 | loss: 0.16603 - acc: 0.9343 -- iter: 0736/1234
[A[ATraining Step: 336  | total loss: [1m[32m0.15809[0m[0m | time: 238.647s
[2K
| RMSProp | epoch: 009 | loss: 0.15809 - acc: 0.9377 -- iter: 0768/1234
[A[ATraining Step: 337  | total loss: [1m[32m0.15603[0m[0m | time: 248.643s
[2K
| RMSProp | epoch: 009 | loss: 0.15603 - acc: 0.9346 -- iter: 0800/1234
[A[ATraining Step: 338  | total loss: [1m[32m0.15804[0m[0m | time: 258.627s
[2K
| RMSProp | epoch: 009 | loss: 0.15804 - acc: 0.9318 -- iter: 0832/1234
[A[ATraining Step: 339  | total loss: [1m[32m0.18244[0m[0m | time: 268.333s
[2K
| RMSProp | epoch: 009 | loss: 0.18244 - acc: 0.9230 -- iter: 0864/1234
[A[ATraining Step: 340  | total loss: [1m[32m0.18896[0m[0m | time: 278.312s
[2K
| RMSProp | epoch: 009 | loss: 0.18896 - acc: 0.9213 -- iter: 0896/1234
[A[ATraining Step: 341  | total loss: [1m[32m0.19978[0m[0m | time: 288.379s
[2K
| RMSProp | epoch: 009 | loss: 0.19978 - acc: 0.9198 -- iter: 0928/1234
[A[ATraining Step: 342  | total loss: [1m[32m0.19086[0m[0m | time: 299.999s
[2K
| RMSProp | epoch: 009 | loss: 0.19086 - acc: 0.9247 -- iter: 0960/1234
[A[ATraining Step: 343  | total loss: [1m[32m0.19833[0m[0m | time: 310.278s
[2K
| RMSProp | epoch: 009 | loss: 0.19833 - acc: 0.9260 -- iter: 0992/1234
[A[ATraining Step: 344  | total loss: [1m[32m0.18279[0m[0m | time: 320.528s
[2K
| RMSProp | epoch: 009 | loss: 0.18279 - acc: 0.9334 -- iter: 1024/1234
[A[ATraining Step: 345  | total loss: [1m[32m0.18874[0m[0m | time: 331.952s
[2K
| RMSProp | epoch: 009 | loss: 0.18874 - acc: 0.9275 -- iter: 1056/1234
[A[ATraining Step: 346  | total loss: [1m[32m0.18410[0m[0m | time: 341.877s
[2K
| RMSProp | epoch: 009 | loss: 0.18410 - acc: 0.9316 -- iter: 1088/1234
[A[ATraining Step: 347  | total loss: [1m[32m0.19335[0m[0m | time: 351.826s
[2K
| RMSProp | epoch: 009 | loss: 0.19335 - acc: 0.9260 -- iter: 1120/1234
[A[ATraining Step: 348  | total loss: [1m[32m0.23924[0m[0m | time: 361.929s
[2K
| RMSProp | epoch: 009 | loss: 0.23924 - acc: 0.9146 -- iter: 1152/1234
[A[ATraining Step: 349  | total loss: [1m[32m0.22699[0m[0m | time: 372.202s
[2K
| RMSProp | epoch: 009 | loss: 0.22699 - acc: 0.9200 -- iter: 1184/1234
[A[ATraining Step: 350  | total loss: [1m[32m0.21313[0m[0m | time: 381.977s
[2K
| RMSProp | epoch: 009 | loss: 0.21313 - acc: 0.9249 -- iter: 1216/1234
[A[ATraining Step: 351  | total loss: [1m[32m0.19364[0m[0m | time: 412.877s
[2K
| RMSProp | epoch: 009 | loss: 0.19364 - acc: 0.9324 | val_loss: 1.20337 - val_acc: 0.7513 -- iter: 1234/1234
--
Training Step: 352  | total loss: [1m[32m0.18578[0m[0m | time: 10.557s
[2K
| RMSProp | epoch: 010 | loss: 0.18578 - acc: 0.9329 -- iter: 0032/1234
[A[ATraining Step: 353  | total loss: [1m[32m0.17375[0m[0m | time: 20.851s
[2K
| RMSProp | epoch: 010 | loss: 0.17375 - acc: 0.9396 -- iter: 0064/1234
[A[ATraining Step: 354  | total loss: [1m[32m0.17963[0m[0m | time: 31.088s
[2K
| RMSProp | epoch: 010 | loss: 0.17963 - acc: 0.9332 -- iter: 0096/1234
[A[ATraining Step: 355  | total loss: [1m[32m0.17824[0m[0m | time: 41.421s
[2K
| RMSProp | epoch: 010 | loss: 0.17824 - acc: 0.9305 -- iter: 0128/1234
[A[ATraining Step: 356  | total loss: [1m[32m0.19020[0m[0m | time: 51.647s
[2K
| RMSProp | epoch: 010 | loss: 0.19020 - acc: 0.9249 -- iter: 0160/1234
[A[ATraining Step: 357  | total loss: [1m[32m0.18938[0m[0m | time: 61.779s
[2K
| RMSProp | epoch: 010 | loss: 0.18938 - acc: 0.9262 -- iter: 0192/1234
[A[ATraining Step: 358  | total loss: [1m[32m0.18211[0m[0m | time: 72.082s
[2K
| RMSProp | epoch: 010 | loss: 0.18211 - acc: 0.9304 -- iter: 0224/1234
[A[ATraining Step: 359  | total loss: [1m[32m0.17642[0m[0m | time: 78.459s
[2K
| RMSProp | epoch: 010 | loss: 0.17642 - acc: 0.9343 -- iter: 0256/1234
[A[ATraining Step: 360  | total loss: [1m[32m0.16573[0m[0m | time: 84.773s
[2K
| RMSProp | epoch: 010 | loss: 0.16573 - acc: 0.9353 -- iter: 0288/1234
[A[ATraining Step: 361  | total loss: [1m[32m0.15422[0m[0m | time: 96.071s
[2K
| RMSProp | epoch: 010 | loss: 0.15422 - acc: 0.9418 -- iter: 0320/1234
[A[ATraining Step: 362  | total loss: [1m[32m0.16907[0m[0m | time: 108.200s
[2K
| RMSProp | epoch: 010 | loss: 0.16907 - acc: 0.9382 -- iter: 0352/1234
[A[ATraining Step: 363  | total loss: [1m[32m0.17105[0m[0m | time: 118.474s
[2K
| RMSProp | epoch: 010 | loss: 0.17105 - acc: 0.9288 -- iter: 0384/1234
[A[ATraining Step: 364  | total loss: [1m[32m0.17941[0m[0m | time: 128.574s
[2K
| RMSProp | epoch: 010 | loss: 0.17941 - acc: 0.9234 -- iter: 0416/1234
[A[ATraining Step: 365  | total loss: [1m[32m0.17923[0m[0m | time: 138.574s
[2K
| RMSProp | epoch: 010 | loss: 0.17923 - acc: 0.9248 -- iter: 0448/1234
[A[ATraining Step: 366  | total loss: [1m[32m0.18046[0m[0m | time: 148.856s
[2K
| RMSProp | epoch: 010 | loss: 0.18046 - acc: 0.9292 -- iter: 0480/1234
[A[ATraining Step: 367  | total loss: [1m[32m0.18085[0m[0m | time: 158.901s
[2K
| RMSProp | epoch: 010 | loss: 0.18085 - acc: 0.9269 -- iter: 0512/1234
[A[ATraining Step: 368  | total loss: [1m[32m0.20711[0m[0m | time: 169.318s
[2K
| RMSProp | epoch: 010 | loss: 0.20711 - acc: 0.9248 -- iter: 0544/1234
[A[ATraining Step: 369  | total loss: [1m[32m0.19470[0m[0m | time: 179.270s
[2K
| RMSProp | epoch: 010 | loss: 0.19470 - acc: 0.9292 -- iter: 0576/1234
[A[ATraining Step: 370  | total loss: [1m[32m0.18924[0m[0m | time: 189.630s
[2K
| RMSProp | epoch: 010 | loss: 0.18924 - acc: 0.9332 -- iter: 0608/1234
[A[ATraining Step: 371  | total loss: [1m[32m0.18579[0m[0m | time: 199.800s
[2K
| RMSProp | epoch: 010 | loss: 0.18579 - acc: 0.9336 -- iter: 0640/1234
[A[ATraining Step: 372  | total loss: [1m[32m0.17981[0m[0m | time: 210.281s
[2K
| RMSProp | epoch: 010 | loss: 0.17981 - acc: 0.9340 -- iter: 0672/1234
[A[ATraining Step: 373  | total loss: [1m[32m0.17859[0m[0m | time: 222.285s
[2K
| RMSProp | epoch: 010 | loss: 0.17859 - acc: 0.9344 -- iter: 0704/1234
[A[ATraining Step: 374  | total loss: [1m[32m0.17308[0m[0m | time: 232.399s
[2K
| RMSProp | epoch: 010 | loss: 0.17308 - acc: 0.9378 -- iter: 0736/1234
[A[ATraining Step: 375  | total loss: [1m[32m0.17272[0m[0m | time: 242.968s
[2K
| RMSProp | epoch: 010 | loss: 0.17272 - acc: 0.9315 -- iter: 0768/1234
[A[ATraining Step: 376  | total loss: [1m[32m0.16552[0m[0m | time: 253.035s
[2K
| RMSProp | epoch: 010 | loss: 0.16552 - acc: 0.9352 -- iter: 0800/1234
[A[ATraining Step: 377  | total loss: [1m[32m0.15283[0m[0m | time: 262.996s
[2K
| RMSProp | epoch: 010 | loss: 0.15283 - acc: 0.9417 -- iter: 0832/1234
[A[ATraining Step: 378  | total loss: [1m[32m0.15415[0m[0m | time: 273.013s
[2K
| RMSProp | epoch: 010 | loss: 0.15415 - acc: 0.9444 -- iter: 0864/1234
[A[ATraining Step: 379  | total loss: [1m[32m0.14542[0m[0m | time: 283.186s
[2K
| RMSProp | epoch: 010 | loss: 0.14542 - acc: 0.9468 -- iter: 0896/1234
[A[ATraining Step: 380  | total loss: [1m[32m0.13679[0m[0m | time: 293.046s
[2K
| RMSProp | epoch: 010 | loss: 0.13679 - acc: 0.9522 -- iter: 0928/1234
[A[ATraining Step: 381  | total loss: [1m[32m0.14598[0m[0m | time: 303.157s
[2K
| RMSProp | epoch: 010 | loss: 0.14598 - acc: 0.9507 -- iter: 0960/1234
[A[ATraining Step: 382  | total loss: [1m[32m0.14066[0m[0m | time: 313.241s
[2K
| RMSProp | epoch: 010 | loss: 0.14066 - acc: 0.9525 -- iter: 0992/1234
[A[ATraining Step: 383  | total loss: [1m[32m0.13905[0m[0m | time: 325.248s
[2K
| RMSProp | epoch: 010 | loss: 0.13905 - acc: 0.9541 -- iter: 1024/1234
[A[ATraining Step: 384  | total loss: [1m[32m0.13028[0m[0m | time: 335.504s
[2K
| RMSProp | epoch: 010 | loss: 0.13028 - acc: 0.9587 -- iter: 1056/1234
[A[ATraining Step: 385  | total loss: [1m[32m0.12719[0m[0m | time: 347.357s
[2K
| RMSProp | epoch: 010 | loss: 0.12719 - acc: 0.9566 -- iter: 1088/1234
[A[ATraining Step: 386  | total loss: [1m[32m0.11662[0m[0m | time: 357.641s
[2K
| RMSProp | epoch: 010 | loss: 0.11662 - acc: 0.9609 -- iter: 1120/1234
[A[ATraining Step: 387  | total loss: [1m[32m0.11535[0m[0m | time: 367.861s
[2K
| RMSProp | epoch: 010 | loss: 0.11535 - acc: 0.9617 -- iter: 1152/1234
[A[ATraining Step: 388  | total loss: [1m[32m0.11752[0m[0m | time: 378.115s
[2K
| RMSProp | epoch: 010 | loss: 0.11752 - acc: 0.9593 -- iter: 1184/1234
[A[ATraining Step: 389  | total loss: [1m[32m0.12889[0m[0m | time: 388.306s
[2K
| RMSProp | epoch: 010 | loss: 0.12889 - acc: 0.9540 -- iter: 1216/1234
[A[ATraining Step: 390  | total loss: [1m[32m0.13538[0m[0m | time: 419.732s
[2K
| RMSProp | epoch: 010 | loss: 0.13538 - acc: 0.9461 | val_loss: 2.45112 - val_acc: 0.6192 -- iter: 1234/1234
--
Training Step: 391  | total loss: [1m[32m0.13738[0m[0m | time: 10.702s
[2K
| RMSProp | epoch: 011 | loss: 0.13738 - acc: 0.9452 -- iter: 0032/1234
[A[ATraining Step: 392  | total loss: [1m[32m0.15372[0m[0m | time: 26.807s
[2K
| RMSProp | epoch: 011 | loss: 0.15372 - acc: 0.9382 -- iter: 0064/1234
[A[ATraining Step: 393  | total loss: [1m[32m0.15725[0m[0m | time: 34.541s
[2K
| RMSProp | epoch: 011 | loss: 0.15725 - acc: 0.9381 -- iter: 0096/1234
[A[ATraining Step: 394  | total loss: [1m[32m0.16019[0m[0m | time: 42.289s
[2K
| RMSProp | epoch: 011 | loss: 0.16019 - acc: 0.9381 -- iter: 0128/1234
[A[ATraining Step: 395  | total loss: [1m[32m0.15873[0m[0m | time: 50.124s
[2K
| RMSProp | epoch: 011 | loss: 0.15873 - acc: 0.9411 -- iter: 0160/1234
[A[ATraining Step: 396  | total loss: [1m[32m0.15550[0m[0m | time: 57.828s
[2K
| RMSProp | epoch: 011 | loss: 0.15550 - acc: 0.9408 -- iter: 0192/1234
[A[ATraining Step: 397  | total loss: [1m[32m0.15477[0m[0m | time: 65.771s
[2K
| RMSProp | epoch: 011 | loss: 0.15477 - acc: 0.9404 -- iter: 0224/1234
[A[ATraining Step: 398  | total loss: [1m[32m0.14904[0m[0m | time: 73.552s
[2K
| RMSProp | epoch: 011 | loss: 0.14904 - acc: 0.9433 -- iter: 0256/1234
[A[ATraining Step: 399  | total loss: [1m[32m0.14241[0m[0m | time: 78.615s
[2K
| RMSProp | epoch: 011 | loss: 0.14241 - acc: 0.9458 -- iter: 0288/1234
[A[ATraining Step: 400  | total loss: [1m[32m0.17566[0m[0m | time: 100.376s
[2K
| RMSProp | epoch: 011 | loss: 0.17566 - acc: 0.9290 | val_loss: 4.58299 - val_acc: 0.5363 -- iter: 0320/1234
--
Training Step: 401  | total loss: [1m[32m0.16550[0m[0m | time: 108.200s
[2K
| RMSProp | epoch: 011 | loss: 0.16550 - acc: 0.9361 -- iter: 0352/1234
[A[ATraining Step: 402  | total loss: [1m[32m0.16141[0m[0m | time: 115.967s
[2K
| RMSProp | epoch: 011 | loss: 0.16141 - acc: 0.9394 -- iter: 0384/1234
[A[ATraining Step: 403  | total loss: [1m[32m0.16574[0m[0m | time: 123.828s
[2K
| RMSProp | epoch: 011 | loss: 0.16574 - acc: 0.9361 -- iter: 0416/1234
[A[ATraining Step: 404  | total loss: [1m[32m0.15104[0m[0m | time: 131.695s
[2K
| RMSProp | epoch: 011 | loss: 0.15104 - acc: 0.9425 -- iter: 0448/1234
[A[ATraining Step: 405  | total loss: [1m[32m0.13865[0m[0m | time: 139.489s
[2K
| RMSProp | epoch: 011 | loss: 0.13865 - acc: 0.9482 -- iter: 0480/1234
[A[ATraining Step: 406  | total loss: [1m[32m0.12921[0m[0m | time: 147.356s
[2K
| RMSProp | epoch: 011 | loss: 0.12921 - acc: 0.9534 -- iter: 0512/1234
[A[ATraining Step: 407  | total loss: [1m[32m0.12296[0m[0m | time: 155.207s
[2K
| RMSProp | epoch: 011 | loss: 0.12296 - acc: 0.9549 -- iter: 0544/1234
[A[ATraining Step: 408  | total loss: [1m[32m0.15219[0m[0m | time: 162.892s
[2K
| RMSProp | epoch: 011 | loss: 0.15219 - acc: 0.9532 -- iter: 0576/1234
[A[ATraining Step: 409  | total loss: [1m[32m0.13843[0m[0m | time: 170.905s
[2K
| RMSProp | epoch: 011 | loss: 0.13843 - acc: 0.9579 -- iter: 0608/1234
[A[ATraining Step: 410  | total loss: [1m[32m0.13153[0m[0m | time: 178.552s
[2K
| RMSProp | epoch: 011 | loss: 0.13153 - acc: 0.9590 -- iter: 0640/1234
[A[ATraining Step: 411  | total loss: [1m[32m0.11920[0m[0m | time: 186.328s
[2K
| RMSProp | epoch: 011 | loss: 0.11920 - acc: 0.9631 -- iter: 0672/1234
[A[ATraining Step: 412  | total loss: [1m[32m0.11346[0m[0m | time: 194.222s
[2K
| RMSProp | epoch: 011 | loss: 0.11346 - acc: 0.9636 -- iter: 0704/1234
[A[ATraining Step: 413  | total loss: [1m[32m0.11909[0m[0m | time: 201.934s
[2K
| RMSProp | epoch: 011 | loss: 0.11909 - acc: 0.9610 -- iter: 0736/1234
[A[ATraining Step: 414  | total loss: [1m[32m0.13944[0m[0m | time: 209.892s
[2K
| RMSProp | epoch: 011 | loss: 0.13944 - acc: 0.9587 -- iter: 0768/1234
[A[ATraining Step: 415  | total loss: [1m[32m0.14325[0m[0m | time: 217.629s
[2K
| RMSProp | epoch: 011 | loss: 0.14325 - acc: 0.9534 -- iter: 0800/1234
[A[ATraining Step: 416  | total loss: [1m[32m0.15108[0m[0m | time: 225.301s
[2K
| RMSProp | epoch: 011 | loss: 0.15108 - acc: 0.9487 -- iter: 0832/1234
[A[ATraining Step: 417  | total loss: [1m[32m0.15237[0m[0m | time: 233.004s
[2K
| RMSProp | epoch: 011 | loss: 0.15237 - acc: 0.9507 -- iter: 0864/1234
[A[ATraining Step: 418  | total loss: [1m[32m0.14222[0m[0m | time: 240.851s
[2K
| RMSProp | epoch: 011 | loss: 0.14222 - acc: 0.9556 -- iter: 0896/1234
[A[ATraining Step: 419  | total loss: [1m[32m0.14429[0m[0m | time: 248.702s
[2K
| RMSProp | epoch: 011 | loss: 0.14429 - acc: 0.9538 -- iter: 0928/1234
[A[ATraining Step: 420  | total loss: [1m[32m0.13327[0m[0m | time: 256.388s
[2K
| RMSProp | epoch: 011 | loss: 0.13327 - acc: 0.9584 -- iter: 0960/1234
[A[ATraining Step: 421  | total loss: [1m[32m0.15833[0m[0m | time: 264.145s
[2K
| RMSProp | epoch: 011 | loss: 0.15833 - acc: 0.9532 -- iter: 0992/1234
[A[ATraining Step: 422  | total loss: [1m[32m0.14791[0m[0m | time: 272.071s
[2K
| RMSProp | epoch: 011 | loss: 0.14791 - acc: 0.9579 -- iter: 1024/1234
[A[ATraining Step: 423  | total loss: [1m[32m0.15333[0m[0m | time: 279.958s
[2K
| RMSProp | epoch: 011 | loss: 0.15333 - acc: 0.9527 -- iter: 1056/1234
[A[ATraining Step: 424  | total loss: [1m[32m0.16160[0m[0m | time: 287.727s
[2K
| RMSProp | epoch: 011 | loss: 0.16160 - acc: 0.9543 -- iter: 1088/1234
[A[ATraining Step: 425  | total loss: [1m[32m0.15110[0m[0m | time: 295.488s
[2K
| RMSProp | epoch: 011 | loss: 0.15110 - acc: 0.9589 -- iter: 1120/1234
[A[ATraining Step: 426  | total loss: [1m[32m0.15253[0m[0m | time: 303.365s
[2K
| RMSProp | epoch: 011 | loss: 0.15253 - acc: 0.9568 -- iter: 1152/1234
[A[ATraining Step: 427  | total loss: [1m[32m0.14722[0m[0m | time: 311.243s
[2K
| RMSProp | epoch: 011 | loss: 0.14722 - acc: 0.9580 -- iter: 1184/1234
[A[ATraining Step: 428  | total loss: [1m[32m0.14849[0m[0m | time: 318.922s
[2K
| RMSProp | epoch: 011 | loss: 0.14849 - acc: 0.9559 -- iter: 1216/1234
[A[ATraining Step: 429  | total loss: [1m[32m0.16317[0m[0m | time: 343.622s
[2K
| RMSProp | epoch: 011 | loss: 0.16317 - acc: 0.9509 | val_loss: 0.47593 - val_acc: 0.7746 -- iter: 1234/1234
--
Training Step: 430  | total loss: [1m[32m0.16372[0m[0m | time: 7.630s
[2K
| RMSProp | epoch: 012 | loss: 0.16372 - acc: 0.9496 -- iter: 0032/1234
[A[ATraining Step: 431  | total loss: [1m[32m0.16330[0m[0m | time: 15.438s
[2K
| RMSProp | epoch: 012 | loss: 0.16330 - acc: 0.9515 -- iter: 0064/1234
[A[ATraining Step: 432  | total loss: [1m[32m0.15828[0m[0m | time: 23.292s
[2K
| RMSProp | epoch: 012 | loss: 0.15828 - acc: 0.9501 -- iter: 0096/1234
[A[ATraining Step: 433  | total loss: [1m[32m0.14630[0m[0m | time: 31.177s
[2K
| RMSProp | epoch: 012 | loss: 0.14630 - acc: 0.9551 -- iter: 0128/1234
[A[ATraining Step: 434  | total loss: [1m[32m0.13518[0m[0m | time: 38.822s
[2K
| RMSProp | epoch: 012 | loss: 0.13518 - acc: 0.9596 -- iter: 0160/1234
[A[ATraining Step: 435  | total loss: [1m[32m0.13332[0m[0m | time: 46.570s
[2K
| RMSProp | epoch: 012 | loss: 0.13332 - acc: 0.9605 -- iter: 0192/1234
[A[ATraining Step: 436  | total loss: [1m[32m0.12494[0m[0m | time: 54.382s
[2K
| RMSProp | epoch: 012 | loss: 0.12494 - acc: 0.9613 -- iter: 0224/1234
[A[ATraining Step: 437  | total loss: [1m[32m0.11980[0m[0m | time: 62.117s
[2K
| RMSProp | epoch: 012 | loss: 0.11980 - acc: 0.9621 -- iter: 0256/1234
[A[ATraining Step: 438  | total loss: [1m[32m0.12012[0m[0m | time: 69.778s
[2K
| RMSProp | epoch: 012 | loss: 0.12012 - acc: 0.9596 -- iter: 0288/1234
[A[ATraining Step: 439  | total loss: [1m[32m0.11814[0m[0m | time: 74.658s
[2K
| RMSProp | epoch: 012 | loss: 0.11814 - acc: 0.9605 -- iter: 0320/1234
[A[ATraining Step: 440  | total loss: [1m[32m0.11285[0m[0m | time: 79.686s
[2K
| RMSProp | epoch: 012 | loss: 0.11285 - acc: 0.9645 -- iter: 0352/1234
[A[ATraining Step: 441  | total loss: [1m[32m0.10348[0m[0m | time: 87.491s
[2K
| RMSProp | epoch: 012 | loss: 0.10348 - acc: 0.9680 -- iter: 0384/1234
[A[ATraining Step: 442  | total loss: [1m[32m0.10164[0m[0m | time: 95.252s
[2K
| RMSProp | epoch: 012 | loss: 0.10164 - acc: 0.9681 -- iter: 0416/1234
[A[ATraining Step: 443  | total loss: [1m[32m0.11015[0m[0m | time: 103.043s
[2K
| RMSProp | epoch: 012 | loss: 0.11015 - acc: 0.9619 -- iter: 0448/1234
[A[ATraining Step: 444  | total loss: [1m[32m0.10186[0m[0m | time: 110.765s
[2K
| RMSProp | epoch: 012 | loss: 0.10186 - acc: 0.9657 -- iter: 0480/1234
[A[ATraining Step: 445  | total loss: [1m[32m0.09822[0m[0m | time: 118.595s
[2K
| RMSProp | epoch: 012 | loss: 0.09822 - acc: 0.9660 -- iter: 0512/1234
[A[ATraining Step: 446  | total loss: [1m[32m0.10999[0m[0m | time: 126.377s
[2K
| RMSProp | epoch: 012 | loss: 0.10999 - acc: 0.9601 -- iter: 0544/1234
[A[ATraining Step: 447  | total loss: [1m[32m0.12459[0m[0m | time: 134.266s
[2K
| RMSProp | epoch: 012 | loss: 0.12459 - acc: 0.9515 -- iter: 0576/1234
[A[ATraining Step: 448  | total loss: [1m[32m0.13915[0m[0m | time: 141.908s
[2K
| RMSProp | epoch: 012 | loss: 0.13915 - acc: 0.9470 -- iter: 0608/1234
[A[ATraining Step: 449  | total loss: [1m[32m0.17527[0m[0m | time: 149.816s
[2K
| RMSProp | epoch: 012 | loss: 0.17527 - acc: 0.9336 -- iter: 0640/1234
[A[ATraining Step: 450  | total loss: [1m[32m0.17175[0m[0m | time: 157.531s
[2K
| RMSProp | epoch: 012 | loss: 0.17175 - acc: 0.9371 -- iter: 0672/1234
[A[ATraining Step: 451  | total loss: [1m[32m0.16417[0m[0m | time: 165.475s
[2K
| RMSProp | epoch: 012 | loss: 0.16417 - acc: 0.9402 -- iter: 0704/1234
[A[ATraining Step: 452  | total loss: [1m[32m0.17324[0m[0m | time: 173.250s
[2K
| RMSProp | epoch: 012 | loss: 0.17324 - acc: 0.9368 -- iter: 0736/1234
[A[ATraining Step: 453  | total loss: [1m[32m0.16016[0m[0m | time: 181.092s
[2K
| RMSProp | epoch: 012 | loss: 0.16016 - acc: 0.9432 -- iter: 0768/1234
[A[ATraining Step: 454  | total loss: [1m[32m0.14575[0m[0m | time: 188.880s
[2K
| RMSProp | epoch: 012 | loss: 0.14575 - acc: 0.9488 -- iter: 0800/1234
[A[ATraining Step: 455  | total loss: [1m[32m0.13432[0m[0m | time: 196.691s
[2K
| RMSProp | epoch: 012 | loss: 0.13432 - acc: 0.9540 -- iter: 0832/1234
[A[ATraining Step: 456  | total loss: [1m[32m0.12794[0m[0m | time: 204.516s
[2K
| RMSProp | epoch: 012 | loss: 0.12794 - acc: 0.9554 -- iter: 0864/1234
[A[ATraining Step: 457  | total loss: [1m[32m0.12807[0m[0m | time: 212.390s
[2K
| RMSProp | epoch: 012 | loss: 0.12807 - acc: 0.9536 -- iter: 0896/1234
[A[ATraining Step: 458  | total loss: [1m[32m0.12148[0m[0m | time: 220.087s
[2K
| RMSProp | epoch: 012 | loss: 0.12148 - acc: 0.9552 -- iter: 0928/1234
[A[ATraining Step: 459  | total loss: [1m[32m0.11444[0m[0m | time: 227.830s
[2K
| RMSProp | epoch: 012 | loss: 0.11444 - acc: 0.9596 -- iter: 0960/1234
[A[ATraining Step: 460  | total loss: [1m[32m0.10630[0m[0m | time: 235.642s
[2K
| RMSProp | epoch: 012 | loss: 0.10630 - acc: 0.9637 -- iter: 0992/1234
[A[ATraining Step: 461  | total loss: [1m[32m0.12521[0m[0m | time: 243.439s
[2K
| RMSProp | epoch: 012 | loss: 0.12521 - acc: 0.9548 -- iter: 1024/1234
[A[ATraining Step: 462  | total loss: [1m[32m0.11530[0m[0m | time: 251.192s
[2K
| RMSProp | epoch: 012 | loss: 0.11530 - acc: 0.9593 -- iter: 1056/1234
[A[ATraining Step: 463  | total loss: [1m[32m0.10952[0m[0m | time: 259.138s
[2K
| RMSProp | epoch: 012 | loss: 0.10952 - acc: 0.9603 -- iter: 1088/1234
[A[ATraining Step: 464  | total loss: [1m[32m0.09947[0m[0m | time: 266.927s
[2K
| RMSProp | epoch: 012 | loss: 0.09947 - acc: 0.9642 -- iter: 1120/1234
[A[ATraining Step: 465  | total loss: [1m[32m0.10158[0m[0m | time: 274.617s
[2K
| RMSProp | epoch: 012 | loss: 0.10158 - acc: 0.9616 -- iter: 1152/1234
[A[ATraining Step: 466  | total loss: [1m[32m0.09969[0m[0m | time: 282.535s
[2K
| RMSProp | epoch: 012 | loss: 0.09969 - acc: 0.9592 -- iter: 1184/1234
[A[ATraining Step: 467  | total loss: [1m[32m0.10934[0m[0m | time: 290.187s
[2K
| RMSProp | epoch: 012 | loss: 0.10934 - acc: 0.9507 -- iter: 1216/1234
[A[ATraining Step: 468  | total loss: [1m[32m0.10291[0m[0m | time: 314.537s
[2K
| RMSProp | epoch: 012 | loss: 0.10291 - acc: 0.9525 | val_loss: 8.37757 - val_acc: 0.4845 -- iter: 1234/1234
--
Training Step: 469  | total loss: [1m[32m0.09759[0m[0m | time: 7.821s
[2K
| RMSProp | epoch: 013 | loss: 0.09759 - acc: 0.9542 -- iter: 0032/1234
[A[ATraining Step: 470  | total loss: [1m[32m0.10078[0m[0m | time: 15.553s
[2K
| RMSProp | epoch: 013 | loss: 0.10078 - acc: 0.9525 -- iter: 0064/1234
[A[ATraining Step: 471  | total loss: [1m[32m0.09858[0m[0m | time: 23.346s
[2K
| RMSProp | epoch: 013 | loss: 0.09858 - acc: 0.9541 -- iter: 0096/1234
[A[ATraining Step: 472  | total loss: [1m[32m0.09035[0m[0m | time: 31.278s
[2K
| RMSProp | epoch: 013 | loss: 0.09035 - acc: 0.9587 -- iter: 0128/1234
[A[ATraining Step: 473  | total loss: [1m[32m0.09541[0m[0m | time: 38.938s
[2K
| RMSProp | epoch: 013 | loss: 0.09541 - acc: 0.9566 -- iter: 0160/1234
[A[ATraining Step: 474  | total loss: [1m[32m0.09766[0m[0m | time: 46.903s
[2K
| RMSProp | epoch: 013 | loss: 0.09766 - acc: 0.9578 -- iter: 0192/1234
[A[ATraining Step: 475  | total loss: [1m[32m0.09626[0m[0m | time: 54.661s
[2K
| RMSProp | epoch: 013 | loss: 0.09626 - acc: 0.9558 -- iter: 0224/1234
[A[ATraining Step: 476  | total loss: [1m[32m0.09144[0m[0m | time: 62.514s
[2K
| RMSProp | epoch: 013 | loss: 0.09144 - acc: 0.9571 -- iter: 0256/1234
[A[ATraining Step: 477  | total loss: [1m[32m0.08789[0m[0m | time: 70.277s
[2K
| RMSProp | epoch: 013 | loss: 0.08789 - acc: 0.9582 -- iter: 0288/1234
[A[ATraining Step: 478  | total loss: [1m[32m0.10020[0m[0m | time: 78.183s
[2K
| RMSProp | epoch: 013 | loss: 0.10020 - acc: 0.9530 -- iter: 0320/1234
[A[ATraining Step: 479  | total loss: [1m[32m0.12046[0m[0m | time: 83.127s
[2K
| RMSProp | epoch: 013 | loss: 0.12046 - acc: 0.9484 -- iter: 0352/1234
[A[ATraining Step: 480  | total loss: [1m[32m0.16164[0m[0m | time: 88.074s
[2K
| RMSProp | epoch: 013 | loss: 0.16164 - acc: 0.9424 -- iter: 0384/1234
[A[ATraining Step: 481  | total loss: [1m[32m0.14617[0m[0m | time: 95.720s
[2K
| RMSProp | epoch: 013 | loss: 0.14617 - acc: 0.9482 -- iter: 0416/1234
[A[ATraining Step: 482  | total loss: [1m[32m0.13636[0m[0m | time: 103.522s
[2K
| RMSProp | epoch: 013 | loss: 0.13636 - acc: 0.9502 -- iter: 0448/1234
[A[ATraining Step: 483  | total loss: [1m[32m0.13493[0m[0m | time: 111.292s
[2K
| RMSProp | epoch: 013 | loss: 0.13493 - acc: 0.9521 -- iter: 0480/1234
[A[ATraining Step: 484  | total loss: [1m[32m0.12416[0m[0m | time: 119.210s
[2K
| RMSProp | epoch: 013 | loss: 0.12416 - acc: 0.9569 -- iter: 0512/1234
[A[ATraining Step: 485  | total loss: [1m[32m0.18186[0m[0m | time: 126.878s
[2K
| RMSProp | epoch: 013 | loss: 0.18186 - acc: 0.9331 -- iter: 0544/1234
[A[ATraining Step: 486  | total loss: [1m[32m0.16505[0m[0m | time: 134.694s
[2K
| RMSProp | epoch: 013 | loss: 0.16505 - acc: 0.9398 -- iter: 0576/1234
[A[ATraining Step: 487  | total loss: [1m[32m0.16237[0m[0m | time: 142.475s
[2K
| RMSProp | epoch: 013 | loss: 0.16237 - acc: 0.9427 -- iter: 0608/1234
[A[ATraining Step: 488  | total loss: [1m[32m0.18968[0m[0m | time: 150.230s
[2K
| RMSProp | epoch: 013 | loss: 0.18968 - acc: 0.9421 -- iter: 0640/1234
[A[ATraining Step: 489  | total loss: [1m[32m0.20327[0m[0m | time: 157.996s
[2K
| RMSProp | epoch: 013 | loss: 0.20327 - acc: 0.9323 -- iter: 0672/1234
[A[ATraining Step: 490  | total loss: [1m[32m0.19387[0m[0m | time: 165.842s
[2K
| RMSProp | epoch: 013 | loss: 0.19387 - acc: 0.9359 -- iter: 0704/1234
[A[ATraining Step: 491  | total loss: [1m[32m0.19312[0m[0m | time: 173.809s
[2K
| RMSProp | epoch: 013 | loss: 0.19312 - acc: 0.9330 -- iter: 0736/1234
[A[ATraining Step: 492  | total loss: [1m[32m0.18993[0m[0m | time: 181.607s
[2K
| RMSProp | epoch: 013 | loss: 0.18993 - acc: 0.9334 -- iter: 0768/1234
[A[ATraining Step: 493  | total loss: [1m[32m0.17828[0m[0m | time: 189.496s
[2K
| RMSProp | epoch: 013 | loss: 0.17828 - acc: 0.9370 -- iter: 0800/1234
[A[ATraining Step: 494  | total loss: [1m[32m0.16223[0m[0m | time: 197.217s
[2K
| RMSProp | epoch: 013 | loss: 0.16223 - acc: 0.9433 -- iter: 0832/1234
[A[ATraining Step: 495  | total loss: [1m[32m0.15030[0m[0m | time: 205.050s
[2K
| RMSProp | epoch: 013 | loss: 0.15030 - acc: 0.9489 -- iter: 0864/1234
[A[ATraining Step: 496  | total loss: [1m[32m0.14169[0m[0m | time: 212.899s
[2K
| RMSProp | epoch: 013 | loss: 0.14169 - acc: 0.9509 -- iter: 0896/1234
[A[ATraining Step: 497  | total loss: [1m[32m0.13348[0m[0m | time: 220.634s
[2K
| RMSProp | epoch: 013 | loss: 0.13348 - acc: 0.9527 -- iter: 0928/1234
[A[ATraining Step: 498  | total loss: [1m[32m0.12251[0m[0m | time: 228.306s
[2K
| RMSProp | epoch: 013 | loss: 0.12251 - acc: 0.9574 -- iter: 0960/1234
[A[ATraining Step: 499  | total loss: [1m[32m0.11851[0m[0m | time: 236.094s
[2K
| RMSProp | epoch: 013 | loss: 0.11851 - acc: 0.9586 -- iter: 0992/1234
[A[ATraining Step: 500  | total loss: [1m[32m0.12069[0m[0m | time: 243.834s
[2K
| RMSProp | epoch: 013 | loss: 0.12069 - acc: 0.9596 -- iter: 1024/1234
[A[ATraining Step: 501  | total loss: [1m[32m0.11094[0m[0m | time: 251.631s
[2K
| RMSProp | epoch: 013 | loss: 0.11094 - acc: 0.9636 -- iter: 1056/1234
[A[ATraining Step: 502  | total loss: [1m[32m0.10224[0m[0m | time: 259.481s
[2K
| RMSProp | epoch: 013 | loss: 0.10224 - acc: 0.9673 -- iter: 1088/1234
[A[ATraining Step: 503  | total loss: [1m[32m0.11054[0m[0m | time: 267.348s
[2K
| RMSProp | epoch: 013 | loss: 0.11054 - acc: 0.9674 -- iter: 1120/1234
[A[ATraining Step: 504  | total loss: [1m[32m0.10874[0m[0m | time: 275.037s
[2K
| RMSProp | epoch: 013 | loss: 0.10874 - acc: 0.9675 -- iter: 1152/1234
[A[ATraining Step: 505  | total loss: [1m[32m0.09986[0m[0m | time: 282.812s
[2K
| RMSProp | epoch: 013 | loss: 0.09986 - acc: 0.9708 -- iter: 1184/1234
[A[ATraining Step: 506  | total loss: [1m[32m0.09052[0m[0m | time: 290.641s
[2K
| RMSProp | epoch: 013 | loss: 0.09052 - acc: 0.9737 -- iter: 1216/1234
[A[ATraining Step: 507  | total loss: [1m[32m0.08553[0m[0m | time: 315.240s
[2K
| RMSProp | epoch: 013 | loss: 0.08553 - acc: 0.9732 | val_loss: 1.01781 - val_acc: 0.7694 -- iter: 1234/1234
--
Training Step: 508  | total loss: [1m[32m0.08388[0m[0m | time: 7.551s
[2K
| RMSProp | epoch: 014 | loss: 0.08388 - acc: 0.9728 -- iter: 0032/1234
[A[ATraining Step: 509  | total loss: [1m[32m0.08569[0m[0m | time: 15.625s
[2K
| RMSProp | epoch: 014 | loss: 0.08569 - acc: 0.9724 -- iter: 0064/1234
[A[ATraining Step: 510  | total loss: [1m[32m0.08720[0m[0m | time: 23.728s
[2K
| RMSProp | epoch: 014 | loss: 0.08720 - acc: 0.9689 -- iter: 0096/1234
[A[ATraining Step: 511  | total loss: [1m[32m0.10557[0m[0m | time: 31.689s
[2K
| RMSProp | epoch: 014 | loss: 0.10557 - acc: 0.9626 -- iter: 0128/1234
[A[ATraining Step: 512  | total loss: [1m[32m0.10575[0m[0m | time: 39.659s
[2K
| RMSProp | epoch: 014 | loss: 0.10575 - acc: 0.9632 -- iter: 0160/1234
[A[ATraining Step: 513  | total loss: [1m[32m0.09912[0m[0m | time: 47.553s
[2K
| RMSProp | epoch: 014 | loss: 0.09912 - acc: 0.9669 -- iter: 0192/1234
[A[ATraining Step: 514  | total loss: [1m[32m0.09917[0m[0m | time: 55.416s
[2K
| RMSProp | epoch: 014 | loss: 0.09917 - acc: 0.9671 -- iter: 0224/1234
[A[ATraining Step: 515  | total loss: [1m[32m0.09253[0m[0m | time: 63.230s
[2K
| RMSProp | epoch: 014 | loss: 0.09253 - acc: 0.9673 -- iter: 0256/1234
[A[ATraining Step: 516  | total loss: [1m[32m0.08700[0m[0m | time: 70.866s
[2K
| RMSProp | epoch: 014 | loss: 0.08700 - acc: 0.9705 -- iter: 0288/1234
[A[ATraining Step: 517  | total loss: [1m[32m0.07873[0m[0m | time: 78.754s
[2K
| RMSProp | epoch: 014 | loss: 0.07873 - acc: 0.9735 -- iter: 0320/1234
[A[ATraining Step: 518  | total loss: [1m[32m0.07313[0m[0m | time: 86.468s
[2K
| RMSProp | epoch: 014 | loss: 0.07313 - acc: 0.9761 -- iter: 0352/1234
[A[ATraining Step: 519  | total loss: [1m[32m0.07086[0m[0m | time: 91.317s
[2K
| RMSProp | epoch: 014 | loss: 0.07086 - acc: 0.9785 -- iter: 0384/1234
[A[ATraining Step: 520  | total loss: [1m[32m0.06556[0m[0m | time: 96.285s
[2K
| RMSProp | epoch: 014 | loss: 0.06556 - acc: 0.9807 -- iter: 0416/1234
[A[ATraining Step: 521  | total loss: [1m[32m0.05906[0m[0m | time: 104.195s
[2K
| RMSProp | epoch: 014 | loss: 0.05906 - acc: 0.9826 -- iter: 0448/1234
[A[ATraining Step: 522  | total loss: [1m[32m0.05480[0m[0m | time: 112.084s
[2K
| RMSProp | epoch: 014 | loss: 0.05480 - acc: 0.9843 -- iter: 0480/1234
[A[ATraining Step: 523  | total loss: [1m[32m0.05530[0m[0m | time: 119.882s
[2K
| RMSProp | epoch: 014 | loss: 0.05530 - acc: 0.9828 -- iter: 0512/1234
[A[ATraining Step: 524  | total loss: [1m[32m0.07072[0m[0m | time: 127.437s
[2K
| RMSProp | epoch: 014 | loss: 0.07072 - acc: 0.9783 -- iter: 0544/1234
[A[ATraining Step: 525  | total loss: [1m[32m0.06564[0m[0m | time: 135.312s
[2K
| RMSProp | epoch: 014 | loss: 0.06564 - acc: 0.9804 -- iter: 0576/1234
[A[ATraining Step: 526  | total loss: [1m[32m0.06207[0m[0m | time: 142.926s
[2K
| RMSProp | epoch: 014 | loss: 0.06207 - acc: 0.9824 -- iter: 0608/1234
[A[ATraining Step: 527  | total loss: [1m[32m0.05823[0m[0m | time: 150.754s
[2K
| RMSProp | epoch: 014 | loss: 0.05823 - acc: 0.9841 -- iter: 0640/1234
[A[ATraining Step: 528  | total loss: [1m[32m0.07139[0m[0m | time: 158.511s
[2K
| RMSProp | epoch: 014 | loss: 0.07139 - acc: 0.9764 -- iter: 0672/1234
[A[ATraining Step: 529  | total loss: [1m[32m0.10056[0m[0m | time: 166.314s
[2K
| RMSProp | epoch: 014 | loss: 0.10056 - acc: 0.9662 -- iter: 0704/1234
[A[ATraining Step: 530  | total loss: [1m[32m0.09929[0m[0m | time: 173.966s
[2K
| RMSProp | epoch: 014 | loss: 0.09929 - acc: 0.9665 -- iter: 0736/1234
[A[ATraining Step: 531  | total loss: [1m[32m0.09449[0m[0m | time: 181.646s
[2K
| RMSProp | epoch: 014 | loss: 0.09449 - acc: 0.9667 -- iter: 0768/1234
[A[ATraining Step: 532  | total loss: [1m[32m0.09329[0m[0m | time: 189.379s
[2K
| RMSProp | epoch: 014 | loss: 0.09329 - acc: 0.9669 -- iter: 0800/1234
[A[ATraining Step: 533  | total loss: [1m[32m0.08635[0m[0m | time: 197.062s
[2K
| RMSProp | epoch: 014 | loss: 0.08635 - acc: 0.9702 -- iter: 0832/1234
[A[ATraining Step: 534  | total loss: [1m[32m0.07850[0m[0m | time: 204.929s
[2K
| RMSProp | epoch: 014 | loss: 0.07850 - acc: 0.9732 -- iter: 0864/1234
[A[ATraining Step: 535  | total loss: [1m[32m0.07518[0m[0m | time: 212.635s
[2K
| RMSProp | epoch: 014 | loss: 0.07518 - acc: 0.9759 -- iter: 0896/1234
[A[ATraining Step: 536  | total loss: [1m[32m0.07198[0m[0m | time: 220.547s
[2K
| RMSProp | epoch: 014 | loss: 0.07198 - acc: 0.9783 -- iter: 0928/1234
[A[ATraining Step: 537  | total loss: [1m[32m0.06977[0m[0m | time: 228.386s
[2K
| RMSProp | epoch: 014 | loss: 0.06977 - acc: 0.9805 -- iter: 0960/1234
[A[ATraining Step: 538  | total loss: [1m[32m0.07593[0m[0m | time: 236.094s
[2K
| RMSProp | epoch: 014 | loss: 0.07593 - acc: 0.9793 -- iter: 0992/1234
[A[ATraining Step: 539  | total loss: [1m[32m0.07695[0m[0m | time: 243.935s
[2K
| RMSProp | epoch: 014 | loss: 0.07695 - acc: 0.9782 -- iter: 1024/1234
[A[ATraining Step: 540  | total loss: [1m[32m0.08169[0m[0m | time: 251.558s
[2K
| RMSProp | epoch: 014 | loss: 0.08169 - acc: 0.9773 -- iter: 1056/1234
[A[ATraining Step: 541  | total loss: [1m[32m0.08100[0m[0m | time: 259.392s
[2K
| RMSProp | epoch: 014 | loss: 0.08100 - acc: 0.9764 -- iter: 1088/1234
[A[ATraining Step: 542  | total loss: [1m[32m0.08149[0m[0m | time: 267.210s
[2K
| RMSProp | epoch: 014 | loss: 0.08149 - acc: 0.9725 -- iter: 1120/1234
[A[ATraining Step: 543  | total loss: [1m[32m0.07499[0m[0m | time: 274.883s
[2K
| RMSProp | epoch: 014 | loss: 0.07499 - acc: 0.9753 -- iter: 1152/1234
[A[ATraining Step: 544  | total loss: [1m[32m0.06823[0m[0m | time: 282.623s
[2K
| RMSProp | epoch: 014 | loss: 0.06823 - acc: 0.9778 -- iter: 1184/1234
[A[ATraining Step: 545  | total loss: [1m[32m0.06626[0m[0m | time: 290.445s
[2K
| RMSProp | epoch: 014 | loss: 0.06626 - acc: 0.9800 -- iter: 1216/1234
[A[ATraining Step: 546  | total loss: [1m[32m0.07255[0m[0m | time: 315.102s
[2K
| RMSProp | epoch: 014 | loss: 0.07255 - acc: 0.9789 | val_loss: 1.91777 - val_acc: 0.7254 -- iter: 1234/1234
--
Training Step: 547  | total loss: [1m[32m0.06663[0m[0m | time: 7.814s
[2K
| RMSProp | epoch: 015 | loss: 0.06663 - acc: 0.9810 -- iter: 0032/1234
[A[ATraining Step: 548  | total loss: [1m[32m0.06594[0m[0m | time: 15.412s
[2K
| RMSProp | epoch: 015 | loss: 0.06594 - acc: 0.9797 -- iter: 0064/1234
[A[ATraining Step: 549  | total loss: [1m[32m0.06608[0m[0m | time: 23.183s
[2K
| RMSProp | epoch: 015 | loss: 0.06608 - acc: 0.9786 -- iter: 0096/1234
[A[ATraining Step: 550  | total loss: [1m[32m0.06005[0m[0m | time: 30.962s
[2K
| RMSProp | epoch: 015 | loss: 0.06005 - acc: 0.9808 -- iter: 0128/1234
[A[ATraining Step: 551  | total loss: [1m[32m0.10163[0m[0m | time: 38.687s
[2K
| RMSProp | epoch: 015 | loss: 0.10163 - acc: 0.9796 -- iter: 0160/1234
[A[ATraining Step: 552  | total loss: [1m[32m0.10822[0m[0m | time: 46.337s
[2K
| RMSProp | epoch: 015 | loss: 0.10822 - acc: 0.9722 -- iter: 0192/1234
[A[ATraining Step: 553  | total loss: [1m[32m0.10608[0m[0m | time: 53.968s
[2K
| RMSProp | epoch: 015 | loss: 0.10608 - acc: 0.9688 -- iter: 0224/1234
[A[ATraining Step: 554  | total loss: [1m[32m0.10250[0m[0m | time: 62.010s
[2K
| RMSProp | epoch: 015 | loss: 0.10250 - acc: 0.9688 -- iter: 0256/1234
[A[ATraining Step: 555  | total loss: [1m[32m0.09643[0m[0m | time: 69.818s
[2K
| RMSProp | epoch: 015 | loss: 0.09643 - acc: 0.9688 -- iter: 0288/1234
[A[ATraining Step: 556  | total loss: [1m[32m0.09162[0m[0m | time: 77.706s
[2K
| RMSProp | epoch: 015 | loss: 0.09162 - acc: 0.9688 -- iter: 0320/1234
[A[ATraining Step: 557  | total loss: [1m[32m0.08355[0m[0m | time: 85.461s
[2K
| RMSProp | epoch: 015 | loss: 0.08355 - acc: 0.9719 -- iter: 0352/1234
[A[ATraining Step: 558  | total loss: [1m[32m0.07756[0m[0m | time: 93.111s
[2K
| RMSProp | epoch: 015 | loss: 0.07756 - acc: 0.9747 -- iter: 0384/1234
[A[ATraining Step: 559  | total loss: [1m[32m0.07385[0m[0m | time: 98.167s
[2K
| RMSProp | epoch: 015 | loss: 0.07385 - acc: 0.9772 -- iter: 0416/1234
[A[ATraining Step: 560  | total loss: [1m[32m0.06770[0m[0m | time: 103.112s
[2K
| RMSProp | epoch: 015 | loss: 0.06770 - acc: 0.9795 -- iter: 0448/1234
[A[ATraining Step: 561  | total loss: [1m[32m0.06112[0m[0m | time: 110.988s
[2K
| RMSProp | epoch: 015 | loss: 0.06112 - acc: 0.9816 -- iter: 0480/1234
[A[ATraining Step: 562  | total loss: [1m[32m0.05606[0m[0m | time: 118.734s
[2K
| RMSProp | epoch: 015 | loss: 0.05606 - acc: 0.9834 -- iter: 0512/1234
[A[ATraining Step: 563  | total loss: [1m[32m0.07558[0m[0m | time: 126.548s
[2K
| RMSProp | epoch: 015 | loss: 0.07558 - acc: 0.9819 -- iter: 0544/1234
[A[ATraining Step: 564  | total loss: [1m[32m0.07418[0m[0m | time: 134.298s
[2K
| RMSProp | epoch: 015 | loss: 0.07418 - acc: 0.9806 -- iter: 0576/1234
[A[ATraining Step: 565  | total loss: [1m[32m0.08931[0m[0m | time: 142.113s
[2K
| RMSProp | epoch: 015 | loss: 0.08931 - acc: 0.9794 -- iter: 0608/1234
[A[ATraining Step: 566  | total loss: [1m[32m0.08115[0m[0m | time: 149.896s
[2K
| RMSProp | epoch: 015 | loss: 0.08115 - acc: 0.9815 -- iter: 0640/1234
[A[ATraining Step: 567  | total loss: [1m[32m0.07616[0m[0m | time: 157.727s
[2K
| RMSProp | epoch: 015 | loss: 0.07616 - acc: 0.9833 -- iter: 0672/1234
[A[ATraining Step: 568  | total loss: [1m[32m0.09295[0m[0m | time: 165.634s
[2K
| RMSProp | epoch: 015 | loss: 0.09295 - acc: 0.9788 -- iter: 0704/1234
[A[ATraining Step: 569  | total loss: [1m[32m0.10339[0m[0m | time: 173.510s
[2K
| RMSProp | epoch: 015 | loss: 0.10339 - acc: 0.9684 -- iter: 0736/1234
[A[ATraining Step: 570  | total loss: [1m[32m0.09907[0m[0m | time: 181.461s
[2K
| RMSProp | epoch: 015 | loss: 0.09907 - acc: 0.9684 -- iter: 0768/1234
[A[ATraining Step: 571  | total loss: [1m[32m0.10904[0m[0m | time: 189.102s
[2K
| RMSProp | epoch: 015 | loss: 0.10904 - acc: 0.9622 -- iter: 0800/1234
[A[ATraining Step: 572  | total loss: [1m[32m0.10554[0m[0m | time: 196.970s
[2K
| RMSProp | epoch: 015 | loss: 0.10554 - acc: 0.9629 -- iter: 0832/1234
[A[ATraining Step: 573  | total loss: [1m[32m0.09956[0m[0m | time: 204.756s
[2K
| RMSProp | epoch: 015 | loss: 0.09956 - acc: 0.9634 -- iter: 0864/1234
[A[ATraining Step: 574  | total loss: [1m[32m0.11076[0m[0m | time: 212.606s
[2K
| RMSProp | epoch: 015 | loss: 0.11076 - acc: 0.9609 -- iter: 0896/1234
[A[ATraining Step: 575  | total loss: [1m[32m0.10299[0m[0m | time: 220.431s
[2K
| RMSProp | epoch: 015 | loss: 0.10299 - acc: 0.9648 -- iter: 0928/1234
[A[ATraining Step: 576  | total loss: [1m[32m0.09826[0m[0m | time: 228.381s
[2K
| RMSProp | epoch: 015 | loss: 0.09826 - acc: 0.9652 -- iter: 0960/1234
[A[ATraining Step: 577  | total loss: [1m[32m0.13488[0m[0m | time: 236.199s
[2K
| RMSProp | epoch: 015 | loss: 0.13488 - acc: 0.9499 -- iter: 0992/1234
[A[ATraining Step: 578  | total loss: [1m[32m0.13215[0m[0m | time: 243.942s
[2K
| RMSProp | epoch: 015 | loss: 0.13215 - acc: 0.9487 -- iter: 1024/1234
[A[ATraining Step: 579  | total loss: [1m[32m0.12386[0m[0m | time: 251.699s
[2K
| RMSProp | epoch: 015 | loss: 0.12386 - acc: 0.9507 -- iter: 1056/1234
[A[ATraining Step: 580  | total loss: [1m[32m0.12568[0m[0m | time: 259.612s
[2K
| RMSProp | epoch: 015 | loss: 0.12568 - acc: 0.9494 -- iter: 1088/1234
[A[ATraining Step: 581  | total loss: [1m[32m0.11881[0m[0m | time: 267.580s
[2K
| RMSProp | epoch: 015 | loss: 0.11881 - acc: 0.9513 -- iter: 1120/1234
[A[ATraining Step: 582  | total loss: [1m[32m0.11600[0m[0m | time: 275.342s
[2K
| RMSProp | epoch: 015 | loss: 0.11600 - acc: 0.9530 -- iter: 1152/1234
[A[ATraining Step: 583  | total loss: [1m[32m0.10542[0m[0m | time: 283.247s
[2K
| RMSProp | epoch: 015 | loss: 0.10542 - acc: 0.9577 -- iter: 1184/1234
[A[ATraining Step: 584  | total loss: [1m[32m0.10934[0m[0m | time: 291.077s
[2K
| RMSProp | epoch: 015 | loss: 0.10934 - acc: 0.9557 -- iter: 1216/1234
[A[ATraining Step: 585  | total loss: [1m[32m0.09917[0m[0m | time: 315.580s
[2K
| RMSProp | epoch: 015 | loss: 0.09917 - acc: 0.9601 | val_loss: 0.30732 - val_acc: 0.9093 -- iter: 1234/1234
--
Validation AUC:0.9653451995685005
Validation AUPRC:0.9600941548343052
Test AUC:0.9672669520040916
Test AUPRC:0.9644892201574562
BestTestF1Score	0.91	0.82	0.91	0.89	0.92	169	20	183	14	0.21
BestTestMCCScore	0.91	0.82	0.91	0.89	0.92	169	20	183	14	0.21
BestTestAccuracyScore	0.91	0.82	0.91	0.89	0.92	169	20	183	14	0.21
BestValidationF1Score	0.92	0.84	0.92	0.92	0.92	165	15	191	15	0.21
BestValidationMCC	0.92	0.84	0.92	0.92	0.92	165	15	191	15	0.21
BestValidationAccuracy	0.92	0.84	0.92	0.92	0.92	165	15	191	15	0.21
TestPredictions (Threshold:0.21)
CHEMBL228738,TN,INACT,0.029999999329447746	CHEMBL240888,TN,INACT,0.009999999776482582	CHEMBL328476,TN,INACT,0.009999999776482582	CHEMBL65461,TN,INACT,0.0	CHEMBL125703,TN,INACT,0.0	CHEMBL309575,TP,ACT,0.949999988079071	CHEMBL578650,TP,ACT,1.0	CHEMBL241082,TN,INACT,0.009999999776482582	CHEMBL318963,TP,ACT,1.0	CHEMBL3350849,TP,ACT,1.0	CHEMBL355532,TP,ACT,1.0	CHEMBL140974,TP,ACT,0.6399999856948853	CHEMBL344882,TP,ACT,1.0	CHEMBL1762308,TN,INACT,0.029999999329447746	CHEMBL59561,FN,ACT,0.1599999964237213	CHEMBL438911,TP,ACT,1.0	CHEMBL60189,TN,INACT,0.0	CHEMBL2112752,TP,ACT,1.0	CHEMBL311061,TP,ACT,0.9300000071525574	CHEMBL2324200,TN,INACT,0.0	CHEMBL340107,TP,ACT,0.6899999976158142	CHEMBL48024,TN,INACT,0.009999999776482582	CHEMBL344602,TN,INACT,0.05999999865889549	CHEMBL169398,TP,ACT,0.6399999856948853	CHEMBL368380,TP,ACT,0.7400000095367432	CHEMBL349505,TN,INACT,0.0	CHEMBL135618,TP,ACT,0.6499999761581421	CHEMBL556506,TN,INACT,0.0	CHEMBL410531,TN,INACT,0.009999999776482582	CHEMBL1170027,FP,INACT,0.27000001072883606	CHEMBL574597,TN,INACT,0.0	CHEMBL2436717,TN,INACT,0.019999999552965164	CHEMBL2114084,TP,ACT,0.5	CHEMBL73522,TP,ACT,0.5	CHEMBL305313,TN,INACT,0.0	CHEMBL328089,TN,INACT,0.009999999776482582	CHEMBL296927,TN,INACT,0.0	CHEMBL188667,TP,ACT,0.800000011920929	CHEMBL291821,TN,INACT,0.0	CHEMBL460470,TN,INACT,0.009999999776482582	CHEMBL3577344,TN,INACT,0.0	CHEMBL3410301,TN,INACT,0.0	CHEMBL132233,TP,ACT,1.0	CHEMBL2111825,FP,INACT,0.4300000071525574	CHEMBL2111922,TP,ACT,1.0	CHEMBL3735797,TN,INACT,0.0	CHEMBL140320,TP,ACT,1.0	CHEMBL139101,TP,ACT,1.0	CHEMBL313813,TP,ACT,0.9800000190734863	CHEMBL328925,TN,INACT,0.0	CHEMBL337065,TP,ACT,1.0	CHEMBL281206,TP,ACT,0.9100000262260437	CHEMBL308414,TP,ACT,0.27000001072883606	CHEMBL48563,TP,ACT,1.0	CHEMBL153095,TP,ACT,1.0	CHEMBL331244,TP,ACT,1.0	CHEMBL324685,TN,INACT,0.05000000074505806	CHEMBL8954,TP,ACT,1.0	CHEMBL115121,TP,ACT,1.0	CHEMBL273693,TP,ACT,1.0	CHEMBL284361,TP,ACT,0.28999999165534973	CHEMBL434113,TP,ACT,0.4699999988079071	CHEMBL451335,TN,INACT,0.0	CHEMBL137483,TN,INACT,0.0	CHEMBL2110201,TP,ACT,1.0	CHEMBL2093084,TN,INACT,0.0	CHEMBL71079,TP,ACT,0.8299999833106995	CHEMBL104994,TN,INACT,0.0	CHEMBL2436714,TN,INACT,0.03999999910593033	CHEMBL83244,TP,ACT,0.949999988079071	CHEMBL86879,TP,ACT,1.0	CHEMBL116127,TP,ACT,1.0	CHEMBL332902,TP,ACT,0.8500000238418579	CHEMBL316792,TN,INACT,0.03999999910593033	CHEMBL408493,TN,INACT,0.0	CHEMBL162095,TN,INACT,0.029999999329447746	CHEMBL402473,TN,INACT,0.0	CHEMBL169794,FP,INACT,0.9900000095367432	CHEMBL345951,TN,INACT,0.0	CHEMBL105775,TP,ACT,0.25999999046325684	CHEMBL2112749,TP,ACT,1.0	CHEMBL413040,FP,INACT,0.5699999928474426	CHEMBL2079550,TP,ACT,0.9900000095367432	CHEMBL363916,TP,ACT,1.0	CHEMBL252198,TN,INACT,0.0	CHEMBL131754,TP,ACT,1.0	CHEMBL1808398,TP,ACT,1.0	CHEMBL295651,TN,INACT,0.0	CHEMBL589,TN,INACT,0.0	CHEMBL177546,TN,INACT,0.009999999776482582	CHEMBL561262,TN,INACT,0.0	CHEMBL3290986,TN,INACT,0.019999999552965164	CHEMBL199186,TN,INACT,0.0	CHEMBL1907848,TP,ACT,1.0	CHEMBL312252,TP,ACT,0.9300000071525574	CHEMBL21509,TN,INACT,0.019999999552965164	CHEMBL64043,TN,INACT,0.0	CHEMBL2369493,TN,INACT,0.0	CHEMBL2311547,TN,INACT,0.019999999552965164	CHEMBL288892,FN,ACT,0.0	CHEMBL1223277,TN,INACT,0.0	CHEMBL329861,TN,INACT,0.0	CHEMBL343969,TN,INACT,0.029999999329447746	CHEMBL333459,TP,ACT,1.0	CHEMBL1258999,TN,INACT,0.0	CHEMBL227378,TN,INACT,0.0	CHEMBL477,TN,INACT,0.0	CHEMBL141629,TP,ACT,0.9800000190734863	CHEMBL132179,TN,INACT,0.07999999821186066	CHEMBL2436824,TN,INACT,0.0	CHEMBL136096,TP,ACT,1.0	CHEMBL538912,TP,ACT,1.0	CHEMBL72841,TP,ACT,0.7699999809265137	CHEMBL357749,TP,ACT,0.699999988079071	CHEMBL1263,TN,INACT,0.0	CHEMBL168386,TP,ACT,0.9100000262260437	CHEMBL354631,TP,ACT,0.7900000214576721	CHEMBL3143400,FP,INACT,0.9800000190734863	CHEMBL340630,FN,ACT,0.029999999329447746	CHEMBL3665433,TN,INACT,0.0	CHEMBL3403333,TN,INACT,0.019999999552965164	CHEMBL72727,TP,ACT,0.6700000166893005	CHEMBL1808403,TP,ACT,1.0	CHEMBL377157,TP,ACT,0.9900000095367432	CHEMBL83591,TP,ACT,0.9700000286102295	CHEMBL2042401,TN,INACT,0.0	CHEMBL2436822,TN,INACT,0.009999999776482582	CHEMBL135371,TP,ACT,1.0	CHEMBL3764246,TN,INACT,0.0	CHEMBL336256,FP,INACT,0.2199999988079071	CHEMBL2111827,TN,INACT,0.009999999776482582	CHEMBL434020,TP,ACT,0.4000000059604645	CHEMBL291033,TP,ACT,1.0	CHEMBL1621896,TN,INACT,0.0	CHEMBL135060,TP,ACT,0.9900000095367432	CHEMBL72570,TP,ACT,0.8199999928474426	CHEMBL355319,TP,ACT,0.949999988079071	CHEMBL87470,TP,ACT,0.23999999463558197	CHEMBL64406,TN,INACT,0.0	CHEMBL34335,TP,ACT,0.6600000262260437	CHEMBL3590085,TN,INACT,0.0	CHEMBL114478,TN,INACT,0.0	CHEMBL170068,FP,INACT,0.9900000095367432	CHEMBL149592,TN,INACT,0.019999999552965164	CHEMBL420320,TP,ACT,0.9700000286102295	CHEMBL2111789,TN,INACT,0.019999999552965164	CHEMBL303227,TP,ACT,0.5	CHEMBL1808419,TP,ACT,0.9399999976158142	CHEMBL353157,TP,ACT,1.0	CHEMBL415965,TP,ACT,1.0	CHEMBL9308,TP,ACT,0.9100000262260437	CHEMBL42411,TN,INACT,0.0	CHEMBL437842,TN,INACT,0.0	CHEMBL450463,TN,INACT,0.019999999552965164	CHEMBL2370120,TP,ACT,1.0	CHEMBL88090,TP,ACT,0.9900000095367432	CHEMBL2114081,TP,ACT,0.9900000095367432	CHEMBL137213,FN,ACT,0.10999999940395355	CHEMBL1083787,TN,INACT,0.10000000149011612	CHEMBL345303,TP,ACT,0.28999999165534973	CHEMBL267094,TN,INACT,0.009999999776482582	CHEMBL331405,TP,ACT,1.0	CHEMBL70883,FN,ACT,0.07000000029802322	CHEMBL216166,TP,ACT,1.0	CHEMBL145133,TP,ACT,0.9900000095367432	CHEMBL2436718,TN,INACT,0.019999999552965164	CHEMBL71996,TP,ACT,0.9800000190734863	CHEMBL80438,TN,INACT,0.0	CHEMBL413644,FP,INACT,0.5199999809265137	CHEMBL105567,TN,INACT,0.0	CHEMBL646,TN,INACT,0.009999999776482582	CHEMBL314846,TP,ACT,1.0	CHEMBL48031,TN,INACT,0.009999999776482582	CHEMBL59597,TN,INACT,0.0	CHEMBL45160,TN,INACT,0.009999999776482582	CHEMBL233501,TN,INACT,0.009999999776482582	CHEMBL352217,TP,ACT,1.0	CHEMBL153760,TP,ACT,1.0	CHEMBL299800,TP,ACT,0.550000011920929	CHEMBL2205808,TN,INACT,0.0	CHEMBL152682,TP,ACT,1.0	CHEMBL3290984,TN,INACT,0.0	CHEMBL297215,TN,INACT,0.009999999776482582	CHEMBL1808416,TP,ACT,0.30000001192092896	CHEMBL2079547,TP,ACT,1.0	CHEMBL2335158,TN,INACT,0.0	CHEMBL7505,TN,INACT,0.0	CHEMBL37983,TP,ACT,1.0	CHEMBL608831,TN,INACT,0.0	CHEMBL165462,TN,INACT,0.0	CHEMBL469856,TN,INACT,0.0	CHEMBL262787,TN,INACT,0.009999999776482582	CHEMBL2112824,TP,ACT,1.0	CHEMBL345327,FN,ACT,0.12999999523162842	CHEMBL608816,TN,INACT,0.0	CHEMBL456675,TN,INACT,0.029999999329447746	CHEMBL351183,FP,INACT,0.9800000190734863	CHEMBL537171,FN,ACT,0.009999999776482582	CHEMBL189634,TP,ACT,1.0	CHEMBL63905,TN,INACT,0.0	CHEMBL59733,TN,INACT,0.0	CHEMBL289310,TN,INACT,0.0	CHEMBL246585,TN,INACT,0.019999999552965164	CHEMBL3335536,TN,INACT,0.0	CHEMBL168372,FP,INACT,0.8199999928474426	CHEMBL432897,TN,INACT,0.0	CHEMBL320174,TN,INACT,0.0	CHEMBL3604304,TN,INACT,0.07000000029802322	CHEMBL73892,FN,ACT,0.09000000357627869	CHEMBL437,TN,INACT,0.0	CHEMBL552615,TN,INACT,0.0	CHEMBL413267,TP,ACT,0.9700000286102295	CHEMBL40317,TN,INACT,0.0	CHEMBL304546,TP,ACT,1.0	CHEMBL22918,FN,ACT,0.009999999776482582	CHEMBL337661,TP,ACT,1.0	CHEMBL173708,TN,INACT,0.029999999329447746	CHEMBL321644,TN,INACT,0.0	CHEMBL38404,TP,ACT,0.8799999952316284	CHEMBL294087,TN,INACT,0.0	CHEMBL295207,TN,INACT,0.0	CHEMBL366344,TP,ACT,1.0	CHEMBL74342,TN,INACT,0.0	CHEMBL177524,TN,INACT,0.009999999776482582	CHEMBL574488,TP,ACT,1.0	CHEMBL74580,TP,ACT,1.0	CHEMBL420722,TP,ACT,0.8999999761581421	CHEMBL573561,TP,ACT,1.0	CHEMBL58241,TN,INACT,0.0	CHEMBL286682,TN,INACT,0.009999999776482582	CHEMBL1082036,TN,INACT,0.0	CHEMBL3350686,TP,ACT,1.0	CHEMBL308111,TP,ACT,1.0	CHEMBL2436722,TN,INACT,0.009999999776482582	CHEMBL2111549,TP,ACT,1.0	CHEMBL2115544,TP,ACT,1.0	CHEMBL1222983,TN,INACT,0.0	CHEMBL543251,TN,INACT,0.0	CHEMBL119608,TP,ACT,0.9200000166893005	CHEMBL166941,TP,ACT,0.9300000071525574	CHEMBL120031,TP,ACT,1.0	CHEMBL145584,TN,INACT,0.009999999776482582	CHEMBL169631,TN,INACT,0.05999999865889549	CHEMBL2391352,TN,INACT,0.0	CHEMBL9188,TP,ACT,1.0	CHEMBL303724,TP,ACT,0.9900000095367432	CHEMBL446693,TN,INACT,0.0	CHEMBL1907856,FP,INACT,0.30000001192092896	CHEMBL62066,TN,INACT,0.0	CHEMBL62421,TN,INACT,0.0	CHEMBL1076554,TN,INACT,0.0	CHEMBL2042400,TN,INACT,0.0	CHEMBL9354,TP,ACT,1.0	CHEMBL147340,TN,INACT,0.0	CHEMBL549638,TN,INACT,0.0	CHEMBL73272,TP,ACT,0.44999998807907104	CHEMBL337722,TP,ACT,0.5899999737739563	CHEMBL112314,TN,INACT,0.0	CHEMBL104981,TN,INACT,0.0	CHEMBL228686,TN,INACT,0.0	CHEMBL302194,TP,ACT,0.9100000262260437	CHEMBL375781,TN,INACT,0.05999999865889549	CHEMBL356446,TP,ACT,1.0	CHEMBL320763,TN,INACT,0.0	CHEMBL100874,FP,INACT,0.3499999940395355	CHEMBL453,TN,INACT,0.0	CHEMBL1907849,TP,ACT,0.9800000190734863	CHEMBL73946,TP,ACT,0.9800000190734863	CHEMBL422941,FN,ACT,0.1599999964237213	CHEMBL349473,TP,ACT,1.0	CHEMBL380054,TN,INACT,0.0	CHEMBL106163,TN,INACT,0.0	CHEMBL138952,TP,ACT,1.0	CHEMBL3735036,FP,INACT,0.2800000011920929	CHEMBL124798,TP,ACT,0.8199999928474426	CHEMBL100618,TP,ACT,0.9900000095367432	CHEMBL124459,TN,INACT,0.03999999910593033	CHEMBL68870,TP,ACT,1.0	CHEMBL170664,TP,ACT,0.9599999785423279	CHEMBL44134,TN,INACT,0.0	CHEMBL122438,FN,ACT,0.029999999329447746	CHEMBL354442,TP,ACT,1.0	CHEMBL2112237,TP,ACT,0.5	CHEMBL115612,TP,ACT,1.0	CHEMBL389129,TN,INACT,0.009999999776482582	CHEMBL1945683,TN,INACT,0.0	CHEMBL168541,TN,INACT,0.009999999776482582	CHEMBL429238,TN,INACT,0.0	CHEMBL334020,TP,ACT,0.9399999976158142	CHEMBL70361,TP,ACT,0.3400000035762787	CHEMBL105273,TP,ACT,1.0	CHEMBL419764,TP,ACT,1.0	CHEMBL2079606,TP,ACT,1.0	CHEMBL2115133,TP,ACT,1.0	CHEMBL106602,TN,INACT,0.0	CHEMBL114072,TP,ACT,1.0	CHEMBL101063,TP,ACT,0.9599999785423279	CHEMBL245319,FP,INACT,0.9800000190734863	CHEMBL337529,TP,ACT,1.0	CHEMBL72295,TN,INACT,0.11999999731779099	CHEMBL137208,TP,ACT,0.9900000095367432	CHEMBL106235,TN,INACT,0.05000000074505806	CHEMBL339879,TP,ACT,1.0	CHEMBL326102,TP,ACT,1.0	CHEMBL354632,TP,ACT,0.8399999737739563	CHEMBL62115,TN,INACT,0.0	CHEMBL3818303,FN,ACT,0.0	CHEMBL1576791,TN,INACT,0.009999999776482582	CHEMBL2112451,TN,INACT,0.0	CHEMBL363106,TP,ACT,0.5199999809265137	CHEMBL125874,FP,INACT,0.4399999976158142	CHEMBL2042551,TN,INACT,0.0	CHEMBL575814,TP,ACT,0.9599999785423279	CHEMBL33554,TP,ACT,1.0	CHEMBL541424,TN,INACT,0.0	CHEMBL593443,TN,INACT,0.0	CHEMBL241514,TN,INACT,0.09000000357627869	CHEMBL272873,TN,INACT,0.0	CHEMBL341762,TP,ACT,1.0	CHEMBL1907851,TP,ACT,0.9900000095367432	CHEMBL3142373,TP,ACT,1.0	CHEMBL435784,TN,INACT,0.09000000357627869	CHEMBL2079551,TP,ACT,1.0	CHEMBL75514,TN,INACT,0.0	CHEMBL469855,TN,INACT,0.009999999776482582	CHEMBL163049,TP,ACT,1.0	CHEMBL3142366,TP,ACT,1.0	CHEMBL120513,TN,INACT,0.07999999821186066	CHEMBL2436814,TN,INACT,0.0	CHEMBL45176,TN,INACT,0.0	CHEMBL2387335,TN,INACT,0.009999999776482582	CHEMBL308404,TP,ACT,1.0	CHEMBL286800,TN,INACT,0.0	CHEMBL165012,TN,INACT,0.0	CHEMBL2111261,TP,ACT,1.0	CHEMBL1093044,TN,INACT,0.0	CHEMBL2367718,TP,ACT,0.7300000190734863	CHEMBL285850,TP,ACT,1.0	CHEMBL63289,TN,INACT,0.0	CHEMBL317108,TP,ACT,0.9900000095367432	CHEMBL343381,TN,INACT,0.0	CHEMBL104,FP,INACT,0.3799999952316284	CHEMBL378173,TN,INACT,0.0	CHEMBL283320,TN,INACT,0.0	CHEMBL34300,TP,ACT,0.9900000095367432	CHEMBL2079548,TP,ACT,1.0	CHEMBL70246,TN,INACT,0.0	CHEMBL11629,TN,INACT,0.0	CHEMBL419663,TP,ACT,1.0	CHEMBL136608,TP,ACT,0.9900000095367432	CHEMBL349689,TN,INACT,0.0	CHEMBL3577345,TN,INACT,0.0	CHEMBL3114143,FP,INACT,0.23000000417232513	CHEMBL84864,TP,ACT,0.6299999952316284	CHEMBL2203713,TN,INACT,0.009999999776482582	CHEMBL390667,TN,INACT,0.009999999776482582	CHEMBL72738,TN,INACT,0.009999999776482582	CHEMBL254500,TN,INACT,0.0	CHEMBL117281,FN,ACT,0.009999999776482582	CHEMBL3577342,TN,INACT,0.0	CHEMBL295698,TN,INACT,0.0	CHEMBL2111550,TP,ACT,0.9200000166893005	CHEMBL101125,TP,ACT,0.8299999833106995	CHEMBL140984,FP,INACT,0.4399999976158142	CHEMBL34422,TP,ACT,0.9900000095367432	CHEMBL2436817,TN,INACT,0.009999999776482582	CHEMBL73096,TN,INACT,0.0	CHEMBL1907666,TP,ACT,0.3799999952316284	CHEMBL336881,FP,INACT,0.8100000023841858	CHEMBL120021,TP,ACT,1.0	CHEMBL554692,TN,INACT,0.0	CHEMBL277661,FN,ACT,0.05000000074505806	CHEMBL9267,TP,ACT,1.0	CHEMBL3143394,TN,INACT,0.03999999910593033	CHEMBL276837,TP,ACT,0.8299999833106995	CHEMBL54246,TN,INACT,0.0	CHEMBL1269257,TP,ACT,1.0	CHEMBL408492,FP,INACT,0.9900000095367432	CHEMBL8779,TP,ACT,0.949999988079071	CHEMBL3734955,TN,INACT,0.019999999552965164	CHEMBL89689,TN,INACT,0.009999999776482582	CHEMBL2304151,TP,ACT,1.0	CHEMBL13095,TN,INACT,0.009999999776482582	CHEMBL422873,TP,ACT,0.6200000047683716	CHEMBL298948,TP,ACT,0.6399999856948853	CHEMBL240657,TN,INACT,0.0	

