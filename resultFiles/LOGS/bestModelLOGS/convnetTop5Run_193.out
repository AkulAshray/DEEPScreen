ImageNetInceptionV2 CHEMBL6166 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	120
Number of inactive compounds :	120
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL6166_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL6166_adam_0.001_15_0.6/
---------------------------------
Training samples: 149
Validation samples: 47
--
Training Step: 1  | time: 432.868s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/149
[A[ATraining Step: 2  | total loss: [1m[32m0.60940[0m[0m | time: 827.943s
[2K
| Adam | epoch: 001 | loss: 0.60940 - acc: 0.5062 -- iter: 064/149
[A[ATraining Step: 3  | total loss: [1m[32m0.84641[0m[0m | time: 1150.750s
[2K
| Adam | epoch: 001 | loss: 0.84641 - acc: 0.3733 -- iter: 096/149
[A[ATraining Step: 4  | total loss: [1m[32m0.75279[0m[0m | time: 1427.164s
[2K
| Adam | epoch: 001 | loss: 0.75279 - acc: 0.4683 -- iter: 128/149
[A[ATraining Step: 5  | total loss: [1m[32m0.64587[0m[0m | time: 1660.266s
[2K
| Adam | epoch: 001 | loss: 0.64587 - acc: 0.5984 | val_loss: 1.08132 - val_acc: 0.5106 -- iter: 149/149
--
Training Step: 6  | total loss: [1m[32m0.56661[0m[0m | time: 88.032s
[2K
| Adam | epoch: 002 | loss: 0.56661 - acc: 0.6729 -- iter: 032/149
[A[ATraining Step: 7  | total loss: [1m[32m0.29442[0m[0m | time: 321.896s
[2K
| Adam | epoch: 002 | loss: 0.29442 - acc: 0.8692 -- iter: 064/149
[A[ATraining Step: 8  | total loss: [1m[32m0.59950[0m[0m | time: 592.061s
[2K
| Adam | epoch: 002 | loss: 0.59950 - acc: 0.7670 -- iter: 096/149
[A[ATraining Step: 9  | total loss: [1m[32m0.82042[0m[0m | time: 928.127s
[2K
| Adam | epoch: 002 | loss: 0.82042 - acc: 0.6587 -- iter: 128/149
[A[ATraining Step: 10  | total loss: [1m[32m0.59283[0m[0m | time: 1312.754s
[2K
| Adam | epoch: 002 | loss: 0.59283 - acc: 0.7825 | val_loss: 0.75771 - val_acc: 0.5106 -- iter: 149/149
--
Training Step: 11  | total loss: [1m[32m0.45753[0m[0m | time: 17.001s
[2K
| Adam | epoch: 003 | loss: 0.45753 - acc: 0.8411 -- iter: 032/149
[A[ATraining Step: 12  | total loss: [1m[32m0.38980[0m[0m | time: 156.209s
[2K
| Adam | epoch: 003 | loss: 0.38980 - acc: 0.8483 -- iter: 064/149
[A[ATraining Step: 13  | total loss: [1m[32m0.27823[0m[0m | time: 352.694s
[2K
| Adam | epoch: 003 | loss: 0.27823 - acc: 0.9133 -- iter: 096/149
[A[ATraining Step: 14  | total loss: [1m[32m0.41849[0m[0m | time: 468.222s
[2K
| Adam | epoch: 003 | loss: 0.41849 - acc: 0.8465 -- iter: 128/149
[A[ATraining Step: 15  | total loss: [1m[32m0.42222[0m[0m | time: 676.424s
[2K
| Adam | epoch: 003 | loss: 0.42222 - acc: 0.8454 | val_loss: 0.71431 - val_acc: 0.5106 -- iter: 149/149
--
Training Step: 16  | total loss: [1m[32m0.33322[0m[0m | time: 123.112s
[2K
| Adam | epoch: 004 | loss: 0.33322 - acc: 0.8917 -- iter: 032/149
[A[ATraining Step: 17  | total loss: [1m[32m0.31841[0m[0m | time: 199.975s
[2K
| Adam | epoch: 004 | loss: 0.31841 - acc: 0.8744 -- iter: 064/149
[A[ATraining Step: 18  | total loss: [1m[32m0.31498[0m[0m | time: 233.566s
[2K
| Adam | epoch: 004 | loss: 0.31498 - acc: 0.8684 -- iter: 096/149
[A[ATraining Step: 19  | total loss: [1m[32m0.24536[0m[0m | time: 350.698s
[2K
| Adam | epoch: 004 | loss: 0.24536 - acc: 0.9123 -- iter: 128/149
[A[ATraining Step: 20  | total loss: [1m[32m0.24955[0m[0m | time: 561.919s
[2K
| Adam | epoch: 004 | loss: 0.24955 - acc: 0.9104 | val_loss: 0.70489 - val_acc: 0.4894 -- iter: 149/149
--
Training Step: 21  | total loss: [1m[32m0.23317[0m[0m | time: 24.299s
[2K
| Adam | epoch: 005 | loss: 0.23317 - acc: 0.9091 -- iter: 032/149
[A[ATraining Step: 22  | total loss: [1m[32m0.18942[0m[0m | time: 74.220s
[2K
| Adam | epoch: 005 | loss: 0.18942 - acc: 0.9364 -- iter: 064/149
[A[ATraining Step: 23  | total loss: [1m[32m0.17875[0m[0m | time: 82.256s
[2K
| Adam | epoch: 005 | loss: 0.17875 - acc: 0.9367 -- iter: 096/149
[A[ATraining Step: 24  | total loss: [1m[32m0.17706[0m[0m | time: 88.228s
[2K
| Adam | epoch: 005 | loss: 0.17706 - acc: 0.9277 -- iter: 128/149
[A[ATraining Step: 25  | total loss: [1m[32m0.14827[0m[0m | time: 158.570s
[2K
| Adam | epoch: 005 | loss: 0.14827 - acc: 0.9474 | val_loss: 0.69926 - val_acc: 0.4894 -- iter: 149/149
--
Training Step: 26  | total loss: [1m[32m0.19776[0m[0m | time: 8.510s
[2K
| Adam | epoch: 006 | loss: 0.19776 - acc: 0.9283 -- iter: 032/149
[A[ATraining Step: 27  | total loss: [1m[32m0.30244[0m[0m | time: 17.265s
[2K
| Adam | epoch: 006 | loss: 0.30244 - acc: 0.8744 -- iter: 064/149
[A[ATraining Step: 28  | total loss: [1m[32m0.26473[0m[0m | time: 26.043s
[2K
| Adam | epoch: 006 | loss: 0.26473 - acc: 0.8823 -- iter: 096/149
[A[ATraining Step: 29  | total loss: [1m[32m0.22323[0m[0m | time: 32.315s
[2K
| Adam | epoch: 006 | loss: 0.22323 - acc: 0.9034 -- iter: 128/149
[A[ATraining Step: 30  | total loss: [1m[32m0.20804[0m[0m | time: 41.157s
[2K
| Adam | epoch: 006 | loss: 0.20804 - acc: 0.9037 | val_loss: 1.17632 - val_acc: 0.4894 -- iter: 149/149
--
Training Step: 31  | total loss: [1m[32m0.17183[0m[0m | time: 9.244s
[2K
| Adam | epoch: 007 | loss: 0.17183 - acc: 0.9259 -- iter: 032/149
[A[ATraining Step: 32  | total loss: [1m[32m0.19450[0m[0m | time: 18.690s
[2K
| Adam | epoch: 007 | loss: 0.19450 - acc: 0.9074 -- iter: 064/149
[A[ATraining Step: 33  | total loss: [1m[32m0.15884[0m[0m | time: 27.514s
[2K
| Adam | epoch: 007 | loss: 0.15884 - acc: 0.9278 -- iter: 096/149
[A[ATraining Step: 34  | total loss: [1m[32m0.16386[0m[0m | time: 36.132s
[2K
| Adam | epoch: 007 | loss: 0.16386 - acc: 0.9298 -- iter: 128/149
[A[ATraining Step: 35  | total loss: [1m[32m0.13967[0m[0m | time: 44.911s
[2K
| Adam | epoch: 007 | loss: 0.13967 - acc: 0.9445 | val_loss: 0.67180 - val_acc: 0.5319 -- iter: 149/149
--
Training Step: 36  | total loss: [1m[32m0.20020[0m[0m | time: 5.982s
[2K
| Adam | epoch: 008 | loss: 0.20020 - acc: 0.9364 -- iter: 032/149
[A[ATraining Step: 37  | total loss: [1m[32m0.19235[0m[0m | time: 15.047s
[2K
| Adam | epoch: 008 | loss: 0.19235 - acc: 0.9396 -- iter: 064/149
[A[ATraining Step: 38  | total loss: [1m[32m0.18170[0m[0m | time: 23.652s
[2K
| Adam | epoch: 008 | loss: 0.18170 - acc: 0.9392 -- iter: 096/149
[A[ATraining Step: 39  | total loss: [1m[32m0.18667[0m[0m | time: 32.874s
[2K
| Adam | epoch: 008 | loss: 0.18667 - acc: 0.9389 -- iter: 128/149
[A[ATraining Step: 40  | total loss: [1m[32m0.23242[0m[0m | time: 44.151s
[2K
| Adam | epoch: 008 | loss: 0.23242 - acc: 0.9210 | val_loss: 1.59485 - val_acc: 0.5106 -- iter: 149/149
--
Training Step: 41  | total loss: [1m[32m0.21529[0m[0m | time: 6.212s
[2K
| Adam | epoch: 009 | loss: 0.21529 - acc: 0.9241 -- iter: 032/149
[A[ATraining Step: 42  | total loss: [1m[32m0.19263[0m[0m | time: 12.502s
[2K
| Adam | epoch: 009 | loss: 0.19263 - acc: 0.9377 -- iter: 064/149
[A[ATraining Step: 43  | total loss: [1m[32m0.16981[0m[0m | time: 21.203s
[2K
| Adam | epoch: 009 | loss: 0.16981 - acc: 0.9487 -- iter: 096/149
[A[ATraining Step: 44  | total loss: [1m[32m0.18088[0m[0m | time: 29.888s
[2K
| Adam | epoch: 009 | loss: 0.18088 - acc: 0.9468 -- iter: 128/149
[A[ATraining Step: 45  | total loss: [1m[32m0.16951[0m[0m | time: 41.014s
[2K
| Adam | epoch: 009 | loss: 0.16951 - acc: 0.9452 | val_loss: 1.51680 - val_acc: 0.5319 -- iter: 149/149
--
Training Step: 46  | total loss: [1m[32m0.18405[0m[0m | time: 8.934s
[2K
| Adam | epoch: 010 | loss: 0.18405 - acc: 0.9491 -- iter: 032/149
[A[ATraining Step: 47  | total loss: [1m[32m0.18447[0m[0m | time: 15.329s
[2K
| Adam | epoch: 010 | loss: 0.18447 - acc: 0.9523 -- iter: 064/149
[A[ATraining Step: 48  | total loss: [1m[32m0.19188[0m[0m | time: 21.795s
[2K
| Adam | epoch: 010 | loss: 0.19188 - acc: 0.9523 -- iter: 096/149
[A[ATraining Step: 49  | total loss: [1m[32m0.17095[0m[0m | time: 30.663s
[2K
| Adam | epoch: 010 | loss: 0.17095 - acc: 0.9599 -- iter: 128/149
[A[ATraining Step: 50  | total loss: [1m[32m0.15195[0m[0m | time: 42.311s
[2K
| Adam | epoch: 010 | loss: 0.15195 - acc: 0.9612 | val_loss: 0.51037 - val_acc: 0.8298 -- iter: 149/149
--
Training Step: 51  | total loss: [1m[32m0.14406[0m[0m | time: 8.833s
[2K
| Adam | epoch: 011 | loss: 0.14406 - acc: 0.9576 -- iter: 032/149
[A[ATraining Step: 52  | total loss: [1m[32m0.14237[0m[0m | time: 17.908s
[2K
| Adam | epoch: 011 | loss: 0.14237 - acc: 0.9593 -- iter: 064/149
[A[ATraining Step: 53  | total loss: [1m[32m0.13872[0m[0m | time: 24.282s
[2K
| Adam | epoch: 011 | loss: 0.13872 - acc: 0.9607 -- iter: 096/149
[A[ATraining Step: 54  | total loss: [1m[32m0.12403[0m[0m | time: 30.659s
[2K
| Adam | epoch: 011 | loss: 0.12403 - acc: 0.9664 -- iter: 128/149
[A[ATraining Step: 55  | total loss: [1m[32m0.11008[0m[0m | time: 42.081s
[2K
| Adam | epoch: 011 | loss: 0.11008 - acc: 0.9712 | val_loss: 0.73526 - val_acc: 0.6809 -- iter: 149/149
--
Training Step: 56  | total loss: [1m[32m0.10232[0m[0m | time: 8.579s
[2K
| Adam | epoch: 012 | loss: 0.10232 - acc: 0.9709 -- iter: 032/149
[A[ATraining Step: 57  | total loss: [1m[32m0.10636[0m[0m | time: 17.684s
[2K
| Adam | epoch: 012 | loss: 0.10636 - acc: 0.9706 -- iter: 064/149
[A[ATraining Step: 58  | total loss: [1m[32m0.11860[0m[0m | time: 26.501s
[2K
| Adam | epoch: 012 | loss: 0.11860 - acc: 0.9661 -- iter: 096/149
[A[ATraining Step: 59  | total loss: [1m[32m0.10487[0m[0m | time: 32.600s
[2K
| Adam | epoch: 012 | loss: 0.10487 - acc: 0.9706 -- iter: 128/149
[A[ATraining Step: 60  | total loss: [1m[32m0.12331[0m[0m | time: 41.064s
[2K
| Adam | epoch: 012 | loss: 0.12331 - acc: 0.9682 | val_loss: 1.46522 - val_acc: 0.5319 -- iter: 149/149
--
Training Step: 61  | total loss: [1m[32m0.12652[0m[0m | time: 8.807s
[2K
| Adam | epoch: 013 | loss: 0.12652 - acc: 0.9661 -- iter: 032/149
[A[ATraining Step: 62  | total loss: [1m[32m0.13565[0m[0m | time: 17.496s
[2K
| Adam | epoch: 013 | loss: 0.13565 - acc: 0.9625 -- iter: 064/149
[A[ATraining Step: 63  | total loss: [1m[32m0.12206[0m[0m | time: 26.818s
[2K
| Adam | epoch: 013 | loss: 0.12206 - acc: 0.9672 -- iter: 096/149
[A[ATraining Step: 64  | total loss: [1m[32m0.11223[0m[0m | time: 35.597s
[2K
| Adam | epoch: 013 | loss: 0.11223 - acc: 0.9713 -- iter: 128/149
[A[ATraining Step: 65  | total loss: [1m[32m0.10841[0m[0m | time: 44.026s
[2K
| Adam | epoch: 013 | loss: 0.10841 - acc: 0.9710 | val_loss: 3.77856 - val_acc: 0.4894 -- iter: 149/149
--
Training Step: 66  | total loss: [1m[32m0.10756[0m[0m | time: 5.969s
[2K
| Adam | epoch: 014 | loss: 0.10756 - acc: 0.9687 -- iter: 032/149
[A[ATraining Step: 67  | total loss: [1m[32m0.10191[0m[0m | time: 15.028s
[2K
| Adam | epoch: 014 | loss: 0.10191 - acc: 0.9668 -- iter: 064/149
[A[ATraining Step: 68  | total loss: [1m[32m0.09718[0m[0m | time: 23.633s
[2K
| Adam | epoch: 014 | loss: 0.09718 - acc: 0.9670 -- iter: 096/149
[A[ATraining Step: 69  | total loss: [1m[32m0.08969[0m[0m | time: 32.478s
[2K
| Adam | epoch: 014 | loss: 0.08969 - acc: 0.9709 -- iter: 128/149
[A[ATraining Step: 70  | total loss: [1m[32m0.08226[0m[0m | time: 43.978s
[2K
| Adam | epoch: 014 | loss: 0.08226 - acc: 0.9742 | val_loss: 1.74925 - val_acc: 0.5957 -- iter: 149/149
--
Training Step: 71  | total loss: [1m[32m0.07973[0m[0m | time: 6.120s
[2K
| Adam | epoch: 015 | loss: 0.07973 - acc: 0.9772 -- iter: 032/149
[A[ATraining Step: 72  | total loss: [1m[32m0.07192[0m[0m | time: 12.431s
[2K
| Adam | epoch: 015 | loss: 0.07192 - acc: 0.9797 -- iter: 064/149
[A[ATraining Step: 73  | total loss: [1m[32m0.06504[0m[0m | time: 21.759s
[2K
| Adam | epoch: 015 | loss: 0.06504 - acc: 0.9820 -- iter: 096/149
[A[ATraining Step: 74  | total loss: [1m[32m0.06684[0m[0m | time: 30.652s
[2K
| Adam | epoch: 015 | loss: 0.06684 - acc: 0.9805 -- iter: 128/149
[A[ATraining Step: 75  | total loss: [1m[32m0.06679[0m[0m | time: 41.812s
[2K
| Adam | epoch: 015 | loss: 0.06679 - acc: 0.9793 | val_loss: 0.49172 - val_acc: 0.8298 -- iter: 149/149
--
Validation AUC:0.907608695652174
Validation AUPRC:0.9250997547708495
Test AUC:0.9184782608695652
Test AUPRC:0.9274408176572577
BestTestF1Score	0.85	0.68	0.83	0.76	0.96	22	7	17	1	0.66
BestTestMCCScore	0.85	0.68	0.83	0.76	0.96	22	7	17	1	0.66
BestTestAccuracyScore	0.85	0.68	0.83	0.76	0.96	22	7	17	1	0.66
BestValidationF1Score	0.88	0.74	0.87	0.88	0.88	21	3	20	3	0.66
BestValidationMCC	0.88	0.74	0.87	0.88	0.88	21	3	20	3	0.66
BestValidationAccuracy	0.88	0.74	0.87	0.88	0.88	21	3	20	3	0.66
TestPredictions (Threshold:0.66)
CHEMBL3326656,FP,INACT,0.9800000190734863	CHEMBL3754730,TP,ACT,1.0	CHEMBL3623139,TP,ACT,1.0	CHEMBL3326654,FP,INACT,0.9900000095367432	CHEMBL477772,TP,ACT,0.6899999976158142	CHEMBL3326651,TN,INACT,0.1599999964237213	CHEMBL549792,TN,INACT,0.0	CHEMBL3326804,TP,ACT,1.0	CHEMBL3752670,TP,ACT,1.0	CHEMBL607707,TP,ACT,0.8600000143051147	CHEMBL1721885,TP,ACT,1.0	CHEMBL3623136,TP,ACT,1.0	CHEMBL561136,TN,INACT,0.3100000023841858	CHEMBL3754515,TP,ACT,1.0	CHEMBL3262587,TP,ACT,1.0	CHEMBL3262567,TN,INACT,0.15000000596046448	CHEMBL527039,TN,INACT,0.1899999976158142	CHEMBL497454,TN,INACT,0.009999999776482582	CHEMBL3335362,TN,INACT,0.019999999552965164	CHEMBL1241674,TP,ACT,0.9900000095367432	CHEMBL524820,FP,INACT,0.9800000190734863	CHEMBL3623131,TP,ACT,0.9300000071525574	CHEMBL1767275,TN,INACT,0.029999999329447746	CHEMBL3754283,TP,ACT,1.0	CHEMBL3623138,TP,ACT,0.9599999785423279	CHEMBL3623130,TP,ACT,1.0	CHEMBL24828,TP,ACT,0.8700000047683716	CHEMBL509499,TN,INACT,0.0	CHEMBL103667,FN,ACT,0.10000000149011612	CHEMBL558601,TN,INACT,0.25999999046325684	CHEMBL3326650,FP,INACT,0.9800000190734863	CHEMBL457401,TN,INACT,0.0	CHEMBL558752,TP,ACT,1.0	CHEMBL318461,TN,INACT,0.009999999776482582	CHEMBL498248,FP,INACT,0.8700000047683716	CHEMBL3262566,FP,INACT,0.7099999785423279	CHEMBL2312654,TP,ACT,0.9900000095367432	CHEMBL3262568,FP,INACT,0.6700000166893005	CHEMBL3326761,TP,ACT,1.0	CHEMBL3326765,TP,ACT,1.0	CHEMBL557456,TN,INACT,0.0	CHEMBL487526,TN,INACT,0.6399999856948853	CHEMBL1922120,TN,INACT,0.4300000071525574	CHEMBL1922121,TN,INACT,0.15000000596046448	CHEMBL180022,TP,ACT,1.0	CHEMBL3326742,TP,ACT,0.949999988079071	CHEMBL560278,TN,INACT,0.009999999776482582	

